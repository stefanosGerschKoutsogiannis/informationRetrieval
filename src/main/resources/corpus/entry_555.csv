2012,Ancestor Sampling for Particle Gibbs,We present a novel method in the family of particle MCMC methods that we refer to as particle Gibbs with ancestor sampling (PG-AS). Similarly to the existing PG with backward simulation (PG-BS) procedure  we use backward sampling to (considerably) improve the mixing of the PG kernel. Instead of using separate forward and backward sweeps as in PG-BS  however  we achieve the same effect in a single forward sweep. We apply the PG-AS framework to the challenging class of non-Markovian state-space models. We develop a truncation strategy of these models that is applicable in principle to any backward-simulation-based method  but which is particularly well suited to the PG-AS framework. In particular  as we show in a simulation study  PG-AS can yield an order-of-magnitude improved accuracy relative to PG-BS due to its robustness to the truncation error. Several application examples are discussed  including Rao-Blackwellized particle smoothing and inference in degenerate state-space models.,Ancestor Sampling for Particle Gibbs

Fredrik Lindsten

Div. of Automatic Control

Link¨oping University

lindsten@isy.liu.se

Michael I. Jordan

Dept. of EECS and Statistics

University of California  Berkeley
jordan@cs.berkeley.edu

Thomas B. Sch¨on

Div. of Automatic Control

Link¨oping University
schon@isy.liu.se

Abstract

We present a novel method in the family of particle MCMC methods that we refer
to as particle Gibbs with ancestor sampling (PG-AS). Similarly to the existing
PG with backward simulation (PG-BS) procedure  we use backward sampling
to (considerably) improve the mixing of the PG kernel. Instead of using sepa-
rate forward and backward sweeps as in PG-BS  however  we achieve the same
effect in a single forward sweep. We apply the PG-AS framework to the challeng-
ing class of non-Markovian state-space models. We develop a truncation strategy
of these models that is applicable in principle to any backward-simulation-based
method  but which is particularly well suited to the PG-AS framework. In partic-
ular  as we show in a simulation study  PG-AS can yield an order-of-magnitude
improved accuracy relative to PG-BS due to its robustness to the truncation error.
Several application examples are discussed  including Rao-Blackwellized particle
smoothing and inference in degenerate state-space models.

1

Introduction

State-space models (SSMs) are widely used to model time series and dynamical systems. The
strong assumptions of linearity and Gaussianity that were originally invoked in state-space inference
have been weakened by two decades of research on sequential Monte Carlo (SMC) and Markov
chain Monte Carlo (MCMC). These Monte Carlo methods have not  however  led to substantial
weakening of a further strong assumption  that of Markovianity. It remains a major challenge to
develop inference algorithms for non-Markovian SSMs:

yt ∼ g(yt | θ  x1:t) 

xt+1 ∼ f (xt+1 | θ  x1:t) 

(1)
where θ ∈ Θ is a static parameter with prior density p(θ)  xt is the latent state and yt is the ob-
servation at time t  respectively. Models of this form arise in many different application scenarios 
either from direct modeling or via a transformation or marginalization of a larger model. We provide
several examples in Section 5.
To tackle the challenging problem of inference for non-Markovian SSMs  we work within the frame-
work of particle MCMC (PMCMC)  a family of inferential methods introduced in [1]. The basic idea
in PMCMC is to use SMC to construct a proposal kernel for an MCMC sampler. Assume that we
observe a sequence of measurements y1:T . We are interested in ﬁnding the density p(x1:T   θ | y1:T ) 
i.e.  the joint posterior density of the state sequence and the parameter. In an idealized Gibbs sam-
pler we would target this density by sampling as follows: (i) Draw θ(cid:63) | x1:T ∼ p(θ | x1:T   y1:T );
1:T | θ(cid:63) ∼ p(x1:T | θ(cid:63)  y1:T ). The ﬁrst step of this procedure can be carried out
(ii) Draw x(cid:63)
exactly if conjugate priors are used. For non-conjugate models  one option is to replace Step (i)
with a Metropolis-Hastings step. However  Step (ii)—sampling from the joint smoothing density
p(x1:T | θ  y1:T )—is in most cases very difﬁcult. In PMCMC  this is addressed by instead sampling
a particle trajectory x(cid:63)
1:T based on an SMC approximation of the joint smoothing density. More
precisely  we run an SMC sampler targeting p(x1:T | θ(cid:63)  y1:T ). We then sample one of the particles

1

1:T . This overall procedure is referred to as particle Gibbs (PG).

at the ﬁnal time T   according to their importance weights  and trace the ancestral lineage of this
particle to obtain the trajectory x(cid:63)
The ﬂexibility provided by the use of SMC as a proposal mechanism for MCMC seems promising for
tackling inference in non-Markovian models. To exploit this ﬂexibility we must address a drawback
of PG in the high-dimensional setting  which is that the mixing of the PG kernel can be very poor
when there is path degeneracy in the SMC sampler [2  3]. This problem has been addressed in the
generic setting of SSMs by adding a backward simulation step to the PG sampler  yielding a method
denoted PG with backward simulation (PG-BS). It has been found that this considerably improves
mixing  making the method much more robust to a small number of particles as well as larger data
records [2  3].
Unfortunately  however  the application of backward simulation is problematic for non-Markovian
models. The reason is that we need to consider full state trajectories during the backward simulation
pass  leading to O(T 2) computational complexity (see Section 4 for details). To address this issue 
we develop a novel PMCMC method which we refer to as particle Gibbs with ancestor sampling
(PG-AS) that achieves the effect of backward sampling without an explicit backward pass. As part
of our development  we also develop a truncation method geared to non-Markovian models. This
method is a generic method that is also applicable to PG-BS  but  as we show in a simulation study in
Section 6  the effect of the truncation error is much less severe for PG-AS than for PG-BS. Indeed 
we obtain up to an order of magnitude increase in accuracy in using PG-AS when compared to
PG-BS in this study.
Since we assume that it is straightforward to sample the parameter θ of the idealized Gibbs sampler 
we will not explicitly include sampling of θ in the subsequent sections to simplify our presentation.

2 Sequential Monte Carlo

We ﬁrst review the standard auxiliary SMC sampler  see e.g. [4 5]. Let γt(x1:t) for t = 1  . . .   T be
a sequence of unnormalized densities on Xt  which we assume can be evaluated pointwise in linear
time. Let ¯γt(x1:t) be the corresponding normalized probability densities. For an SSM we would typ-
ically have ¯γt(x1:t) = p(x1:t | y1:t) and γt(x1:t) = p(x1:t  y1:t). Assume that {xm
m=1
is a weighted particle system targeting ¯γt−1(x1:t−1). This particle system is propagated to time t by
sampling independently from a proposal kernel 
wat
t−1νat
t−1
l wl
t−1νl

Rt(xt | xat

Mt(at  xt) =

1:t−1  wm

t−1}N

(cid:80)

1:t−1).

t−1

(2)

In this formulation  the resampling step is implicit and corresponds to sampling the ancestor indices
at. Note that am
1:t we refer to the
t
ancestral path of xm
1:t)  known as adjustment multiplier weights  are
used in the auxiliary SMC sampler to increase the probability of sampling ancestors that better can
1:t) 
describe the current observation [5]. The particles are then weighted according to wm
where the weight function is given by

is the index of the ancestor particle of xm
t . The factors νm

t . When we write xm

t = Wt(xm

t = νt(xm

Wt(x1:t) =

(3)
1 ∼ R1(x1) and
for t ≥ 2. The procedure is initiated by sampling from a proposal density xm
1 ) with W1(x1) = γ1(x1)/R1(x1). In PMCMC it is
assigning importance weights wm
instructive to view this sampling procedure as a way of generating a single sample from the density

γt−1(x1:t−1)νt−1(x1:t−1)Rt(xt | x1:t−1)

1 = W1(xm

 

γt(x1:t)

ψ(x1:T   a2:T ) (cid:44) N(cid:89)

T(cid:89)

N(cid:89)

(4)
on the space XN T × {1  . . .   N}N (T−1). Here we have introduced the boldface notation xt =
{x1

t } and similarly for the ancestor indices.

t   . . .   xN

R1(xm
1 )

t   xm
t )

Mt(am

m=1

m=1

t=2

3 Particle Gibbs with ancestor sampling

PMCMC methods is a class of MCMC samplers in which SMC is used to construct proposal ker-
nels [1]. The validity of these methods can be assessed by viewing them as MCMC samplers on an

2

extended state space in which all the random variables generated by the SMC sampler are seen as
auxiliary variables. The target density on this extended space is given by
ψ(x1:T   a2:T )
t=2 Mt(abt

φ(x1:T   a2:T   k) (cid:44) ¯γT (xk
N T
1:T ) as a marginal  and can thus be used as a surrogate for
By construction  this density admits ¯γT (xk
the original target density ¯γT [1]. Here k is a variable indexing one of the particles at the ﬁnal time
1:T = {xb1
T }.
point and b1:T corresponds to the ancestral path of this particle: xk
1   . . .   xbT
These indices are given recursively from the ancestor indices by bT = k and bt = abt+1
t+1 . The PG
2:T   bT}) 
sampler [1] is a Gibbs sampler targeting φ using the following sweep (note that b1:T = {ab2:T

1 )(cid:81)T

1:T = xb1:T

t   xbt
t )

R1(xb1

1:T )

(5)

.

1. Draw x(cid:63) −b1:T
2. Draw k(cid:63) ∼ φ(k | x(cid:63) −b1:T

  a(cid:63) −b2:T

∼ φ(x
−b1:T
1:T
  a(cid:63) −b2:T

1:T

2:T

1:T

2:T

1:T   b1:T ).

−b2:T
  a
2:T
1:T   ab2:T
  xb1:T
= {x1

| xb1:T
2:T ).
t   . . .   xm−1

t

t

t

−b1
1

−bT
T

  . . .   x

  xm+1

−b1:T
1:T

t }  x

  . . .   xN

1:T = x(cid:48)

T   and it can thus straightforwardly be sampled from.

Here we have introduced the notation x−m
=
} and similarly for the ancestor indices. In [1]  a sequential procedure for sampling
{x
from the conditional density appearing in Step 1 is given. This method is known as conditional SMC
(CSMC). It takes the form of an SMC sampler in which we condition on the event that a prespeciﬁed
1:T   with indices b1:T   is maintained throughout the sampler (see Algorithm 1 for a
path xb1:T
related procedure). Furthermore  the conditional distribution appearing in Step 2 of the PG sampler
is shown to be proportional to wk
1:T   b1:T−1} in this sweep. Hence  the PG
Note that we never sample new values for the variables {xb1:T
sampler is an “incomplete” Gibbs sampler  since it does not loop over all the variables of the model.
It still holds that the PG sampler is ergodic  which intuitively can be explained by the fact that the
collection of variables that is left out is chosen randomly at each iteration. However  it has been
observed that the PG sampler can have very poor mixing  especially when N is small and/or T is
large [2  3]. The reason for this poor mixing is that the SMC path degeneracy causes the collections
of variables that are left out at any two consecutive iterations to be strongly dependent.
We now turn to our new procedure  PG-AS  which aims to address this fundamental issue. Our
idea is to sample new values for the ancestor indices b1:T−1 as part of the CSMC procedure1. By
adding these variables to the Gibbs sweep  we can considerably improve the mixing of the PG
| xb1:T
kernel. The CSMC method is a sequential procedure to sample from φ(x
1:T   b1:T )
| x(cid:63) −b1:t−1
by sampling according to {x(cid:63) −bt
1:T   b1:T )  for
t = 1  . . .   T . After having sampled these variables at time t  we add a step in which we generate a
new value for bt−1(= abt

t )  resulting in the following sweep:

−b1:T
  a
1:T
  a(cid:63) −b2:t−1
2:t−1

} ∼ φ(x

  a(cid:63) −bt

−bt
  a
t

−b2:T
2:T

  xb1:T

−bt
t

1:t−1

t

t

1(cid:48). (CSMC with ancestor sampling) For t = 1  . . .   T   draw
| x(cid:63) −b1:t−1
  a(cid:63)

x(cid:63) −bt
  a(cid:63) −bt
t
(a(cid:63) bt
t =) b(cid:63)
T ∼ φ(bT | x(cid:63) −b1:T
2(cid:48). Draw (k(cid:63) =) b(cid:63)

−bt
  a
t
t−1 ∼ φ(bt−1 | x(cid:63) −b1:t−1
1:t−1
1:T ).
2:T   xb1:T

1:t−1
  a(cid:63)

∼ φ(x

−bt
t

  a(cid:63)

1:T

t

2:t−1  xb1:T
1:T   bt:T ).

2:t−1  xb1:T

1:T   bt−1:T ) 

It can be veriﬁed that this corresponds to a partially collapsed Gibbs sampler [6] and will thus leave
φ invariant. To determine the conditional densities from which the ancestor indices are drawn 
consider the following factorization  following directly from (3) 

γt(x1:t) = Wt(x1:t)νt−1(x1:t−1)Rt(xt | x1:t−1)γt−1(x1:t−1)

wl

sνl
s

R1(xb1
1 )

Mt(abs

s   xbs

s ).

(6)

1Ideally  we would like to include the variables xb1:T

1:T as well  but this is in general not possible since it

would be similar to sampling from the original target density (which we assume is infeasible).

s=1

l

s=2

3

(cid:80)
(cid:32)t−1(cid:89)

t−1νl
l wl
wbt−1
t−1

(cid:88)

(cid:80)
(cid:33)

t−1

t−1 νbt−1
wbt−1
t−1
l wl
t−1νl
t−1

t(cid:89)

⇒ γt(xbt

1:t) = wbt

t

= . . . = wbt
t

Rt(xbt
t

| xbt−1

1:t−1)γt−1(xbt−1

1:t−1)

Furthermore  we have

φ(bt | x1:t  a2:t  xbt+1:T

t+1:T   bt+1:T ) ∝ φ(x1:t  a2:t  xbt+1:T
1:T )ψ(x1:t  a2:t)

t+1:T   bt:T )

∝

γT (xk

1 )(cid:81)t

s=2 Ms(abs
By plugging (6) into the numerator we get 

R1(xb1

s   xbs
s )

∝ γt(xbt
1:t)
γt(xbt
1:t)

R1(xb1

1:T )

γT (xk
s=2 Ms(abs

s   xbs
s )

1 )(cid:81)t

φ(bt | x1:t  a2:t  xbt+1:T

t+1:T   bt+1:T ) ∝ wbt

t

γT (xk
γt(xbt

1:T )
1:t)

.

.

(7)

(8)

Hence  to sample a new ancestor index for the conditioned path at time t + 1  we proceed as follows.
Given x(cid:48)

t+1:T ) we compute the backward sampling weights 

t+1:T (= xbt+1:T

wm

t|T = wm
t

γT ({xm

t+1:T})
1:t  x(cid:48)
γt(xm
1:t)

 

(9)

for m = 1  . . .   N. We then set bt = m with probability proportional to wm
t|T .
1:T   b1:T} 
It follows that the proposed CSMC with ancestor sampling (Step 1(cid:48))  conditioned on {x(cid:48)
can be realized as in Algorithm 1. The difference between this algorithm and the CSMC sampler
derived in [1] lies in the ancestor sampling step 2(b) (where instead  they set abt
t = bt−1). By
introducing the ancestor sampling  we break the strong dependence between the generated particle
trajectories and the path on which we condition. We call the resulting method  deﬁned by Steps 1(cid:48)
and 2(cid:48) above  PG with ancestor sampling (PG-AS).
Algorithm 1 CSMC with ancestor sampling  conditioned on {x(cid:48)

1:T   b1:T}

1. Initialize (t = 1):

(a) Draw xm
(b) Set wm

1 ∼ R1(x1) for m (cid:54)= b1 and set xb1
1 = W1(xm

1 ) for m = 1  . . .   N.

1 = x(cid:48)
1.

(a) Draw {am
(b) Draw abt

2. for t = 2  . . .   T :
t   xm
t with P (abt
1:t = {xam

(c) Set xm

t

1:t−1  xm

t = m) ∝ wm
t } and wm

t−1|T .
t = Wt(xm

t } ∼ Mt(at  xt) for m (cid:54)= bt and set xbt

t = x(cid:48)
t.

1:t) for m = 1  . . .   N.

The idea of including the variables b1:T−1 in the PG sampler has previously been suggested by
Whiteley [7] and further explored in [2  3]. This previous work  however  accomplishes this with
a explicit backward simulation pass  which  as we discuss in the following section  is problematic
for our applications to non-Markovian SSMs. In the PG-AS sampler  instead of requiring distinct
forward and backward sequences of Gibbs steps as in PG with backward simulation (PG-BS)  we
obtain a similar effect via a single forward sweep.

4 Truncation for non-Markovian state-space models

We return to the problem of inference in non-Markovian SSMs of the form shown in (1). To employ
backward sampling  we need to evaluate the ratio

T(cid:89)

s=t+1

γT (x1:T )
γt(x1:t)

=

p(x1:T   y1:T )
p(x1:t  y1:t)

=

g(ys | x1:s)f (xs | x1:s−1).

(10)

In general  the computational cost of computing the backward sampling weights will thus be O(T ).
This implies that the cost of generating a full backward trajectory is O(T 2). It is therefore compu-
tationally prohibitive to employ backward simulation type of particle smoothers  as well as the PG
samplers discussed above  for general non-Markovian models.

4

Figure 1: Probability under (cid:101)Pp as a function of the truncation level p for two different systems; one
5 dimensional (left) and one 20 dimensional (right). The N = 5 dotted lines correspond to (cid:101)Pp(m)

for m ∈ {1  . . .   N}  respectively (N.B. two of the lines overlap in the left ﬁgure). The dashed
vertical lines show the value of the truncation level padpt.  resulting from the adaption scheme with
γ = 0.1 and τ = 10−2. See Section 6.2 for details on the experiments.

To make progress  we consider non-Markovian models in which there is a decay in the inﬂuence
of the past on the present  akin to that in Markovian models but without the strong Markovian
assumption. Hence  it is possible to obtain a useful approximation when the product in (10) is
truncated to a smaller number of factors  say p. We then replace (9) with the approximation 

(cid:101)wp m

t|T = wm

t

γt+p({xm

t+1:t+p})
1:t  x(cid:48)
γt(xm
1:t)

.

(11)

The following proposition formalizes our assumption.

Proposition 1. Let P and (cid:101)Pp be the probability distributions on {1  . . .   N}  deﬁned by
maxk l (hs(k)/hs(l) − 1) ≤ A exp(−cs)  for some constants A and c > 0. Then  DKLD(P(cid:107)(cid:101)Pp) ≤

the backward sampling weight (9) and the truncated backward sampling weights (11)  re-
spectively. Let hs(k) = g(yt+s
t+1:t−s) and assume that
C exp(−cp) for some constant C  where DKLD is the Kullback-Leibler divergence (KLD).

t+1:t+s)f (x(cid:48)

1:t  x(cid:48)

| xk

1:t  x(cid:48)

| xk

t+s

Proof. Provided in the supplemental material.

From (11)  we see that we can compute the backward weights in constant time under the truncation
within the PG-AS framework. The resulting approximation can be quite useful; indeed  in our
experiments we have seen that even p = 1 can lead to very accurate inferential results. In general 
however  it will not be known a priori how to set the truncation level p for any given problem. To
address this problem  we propose to use an adaption of the truncation level. Since the approximative
weights (11) can be evaluated sequentially  the idea is to start with p = 1 and then increase p until
the weights have  in some sense  converged. In particular  in our experimental work  we have used
the following simple approach.

Let (cid:101)Pp be the discrete probability measure deﬁned by (11). Let εp = DTV((cid:101)Pp (cid:101)Pp−1) be the total

variation (TV) distance between the distributions for two consecutive truncation levels. We then
compute the exponentially decaying moving average of the sequence εp  with forgetting factor γ ∈
[0  1]  and stop when this falls below some threshold τ ∈ [0  1]. This adaption scheme removes the
requirement to specify p directly  but instead introduces the design parameters γ and τ. However 
these parameters are much easier to reason about – a small value for γ gives a rapid response to
changes in εp whereas a large value gives a more conservative stopping rule  improving the accuracy
of the approximation at the cost of higher computational complexity. A similar trade off holds for
the threshold τ as well. Most importantly  we have found that the same values for γ and τ can be
used for a wide range of models  with very different mixing properties.

To illustrate the effect of the adaption rule  and how the distribution (cid:101)Pp typically evolves as we

increase p  we provide two examples in Figure 1. These examples are taken from the simulation
study provided in Section 6.2. Note that the untruncated distribution P is given for the maximal
value of p  i.e.  furthest to the right in the ﬁgures. By using the adaptive truncation  we can stop the
evaluation of the weights at a much earlier stage  and still obtain an accurate approximation of P .

5

05010015020000.20.40.60.81padpt.=5Probability050100150200padpt.=125 Application areas

In this section we present examples of problem classes involving non-Markovian SSMs for which
the proposed PG-AS sampler can be applied. Numerical illustrations are provided in Section 6.

5.1 Rao-Blackwellized particle smoothing

One popular approach to increase the efﬁciency of SMC samplers for SSMs is to marginalize over
one component of the state  and apply an SMC sampler in the lower-dimensional marginal space.
This leads to what is known as the Rao-Blackwellized particle ﬁlter (RBPF) [8–10]. The same
approach has also been applied to state smoothing [11 12]  but it turns out that Rao-Blackwellization
is less straightforward in this case  since the marginal state-process will be non-Markovian. As an
example  a mixed linear/nonlinear Gaussian SSM (see  e.g.  [10]) with “nonlinear state” xt and
“linear state” zt  can be reduced to xt ∼ p(xt | x1:t−1  y1:t−1) and yt ∼ p(yt | x1:t  y1:t−1). These
conditional densities are Gaussian and can be evaluated for any ﬁxed marginal state trajectory x1:t−1
by running a conditional Kalman ﬁlter to marginalize the zt-process.
In order to apply a backward-simulation-based method (e.g.  a particle smoother) for this model  we
need to evaluate the backward sampling weights (9). In a straightforward implementation2  we thus
need to run N Kalman ﬁlters for T − t time steps  for each t = 1  . . .   T − 1. The computational
complexity of this calculation can be reduced by employing the truncation proposed in Section 4.

5.2 Particle smoothing for degenerate state-space models

Many dynamical systems are most naturally modelled as degenerate in the sense that the transi-
tion kernel of the state process does not admit any dominating measure. For instance  consider a
nonlinear system with additive noise of the form 

yt = g(ξt) + et 

ξt = f (ξt−1) + Gωt−1 

(12)
where G is a tall matrix  and consequently rank(G) < dim(ξt). That is  the process noise covariance
matrix is singular. SMC samplers can straightforwardly be applied to this type of models  but it is
more problematic to address the smoothing problem using particle methods. The reason is that the
backward kernel also will be degenerate and it cannot be approximated in a natural way by the
forward ﬁlter particles  as is normally done in backward-simulation-based particle smoothers.
A possible remedy for this issue is to recast the degenerate SSM as a non-Markovian model in
T
a lower-dimensional space. Let G = U [Σ 0]
V T with unitary U and V be a singular value

(cid:44) U Tξt = U Tf (U U Tξt−1) +

ΣV Tωt−1

0

.

(13)

For simplicity we assume that z1 is known. If this is not the case  it can be included in the system
state or seen as a static parameter of the model. Hence  the sequence z1:t is σ(x1:t−1)-measurable
and we can write zt = zt(x1:t−1). With vt (cid:44) ΣV Tωt and by appropriate deﬁnitions of the functions
fx and h  the model (12) can thus be rewritten as  xt = fx(x1:t−1) + vt−1 and yt = h(x1:t) + et 
which is a non-degenerate  non-Markovian SSM. By exploiting the truncation proposed in Section 4
we can thus apply PG-AS to do inference in this model.

5.3 Additional problem classes

There are many more problem classes in which non-Markovian models arise and in which backward-
simulation-based methods can be of interest. For instance  the Dirichlet process mixture model
(DPMM  see  e.g.  [13]) is a popular nonparametric Bayesian model for mixtures with an unknown
number of components. Using a Polya urn representation  the mixture labels are given by a non-
Markovian stochastic process  and the DPMM can thus be seen as a non-Markovian SSM. SMC has

2For the speciﬁc problem of Rao-Blackwellized smoothing in conditionally Gaussian models  a backward
simulator which can be implemented in O(T ) computational complexity has recently been proposed in [11].
This is based on the idea of propagating information backward in time as the backward samples are generated.

6

decomposition of G and let (cid:20)xt
(cid:21)

zt

(cid:20)

(cid:21)

Figure 2: Rao-Blackwellized state smoothing using PG. Running RMSEs for ﬁve independent runs
of PG-AS (•) and PG-BS (◦)  respectively. The truncation level is set to p = 1. The solid line
corresponds to a run of an untruncated FF-BS.

previously been used for inference in DPMMs [14  15]. An interesting venue for future work is to
use the PG-AS sampler for these models. A second example in Bayesian nonparametrics is Gaussian
process (GP) regression and classiﬁcation (see  e.g.  [16]). The sample path of the GP can be seen as
the state-process in a non-Markovian SSM. We can thus employ PMCMC  and in particular PG-AS 
to address these inference problems.
An application in genetics  for which SMC has been been successfully applied  is reconstruction
of phylogenetic trees [17]. A phylogenetic tree is a binary tree with observation at the leaf nodes.
SMC is used to construct the tree in a bottom up fashion. A similar approach has also been used
for Bayesian agglomerative clustering  in which SMC is used to construct a binary clustering tree
based on Kingman’s coalescent [18]. The generative models for the trees used in [17  18] are in fact
Markovian  but the observations give rise to a conditional dependence which destroys the Markov
property. To employ backward simulation to these models  we are thus faced with problems of a
similar nature as those discussed in Section 4.

6 Numerical evaluation

This section contains a numerical evaluation of the proposed method. We consider linear Gaussian
systems  which is instructive since the exact smoothing density then is available  e.g.  by running
a modiﬁed Bryson-Frazier (MBF) smoother [19]. For more details on the experiments  and for
additional (nonlinear) examples  see [20].

6.1 RBPS: Linear Gaussian state-space model

As a ﬁrst example  we consider Rao-Blackwellized particle smoothing (RBPS) in a single-output
4th-order linear Gaussian SSM. We generate T = 100 samples from the system and run PG-AS and
PG-BS  marginalizing three out of the four states using an RBPF  i.e.  dim(xt) = 1. Both methods
are run for R = 10000 iterations using N = 5 particles. The truncation level is set to p = 1  leading
to a coarse approximation. We discard the ﬁrst 1000 iterations and then compute running means
of the state trajectory x1:T . From these  we then compute the running root mean squared errors
(RMSEs) r relative to the true posterior means (computed with an MBF smoother). Hence  if no
approximation would have been made  we would expect r → 0  so any static error can be seen as
the effect of the truncation. The results for ﬁve independent runs from both PG samplers are shown
in Figure 2. First  we note that both methods give accurate results. Still  the error for PG-AS is close
to an order of magnitude less than for PG-BS. Furthermore  it appears as if the error for PG-AS
would decrease further  given more iterations  suggesting that the bias caused by the truncation is
dominated by the Monte Carlo variance  even after R = 10000 iterations.
For further comparison  we also run an untruncated forward ﬁlter/backward simulator (FF-BS) par-
ticle smoother [21]  using N = 5000 forward ﬁlter particles and M = 500 backward trajectories
(with a computational complexity of O(N M T 2)). The resulting RMSE value is shown as a solid
line in Figure 2. These results suggest that PMCMC samplers  such as the PG-AS  indeed can be
serious competitors to more “standard” particle smoothers. Even with p = 1  PG-AS outperforms

7

1000200030004000500060007000800090001000010−210−1  PG w. ancestral samplingPG w. backward simulationFigure 3: Box plots of the RMSE errors for PG-AS (black) and PG-BS (gray)  for 150 random
systems of different dimensions d (left  d = 2; middle  d = 5; right  d = 20). Different values for
the truncation level p are considered. The rightmost boxes correspond to an adaptive threshold and
the values in parentheses are the average over all systems and MCMC iterations (the same for both
methods). The dots within the boxes show the median errors.

FF-BS in terms of accuracy and  due to the fact that the ancestor sampling allows us to use as few
as N = 5 particles at each iteration  at a lower computational cost.

6.2 Random linear Gaussian systems with rank deﬁcient process noise covariances

To see how the PG samplers are affected by the choice of truncation level p and by the mixing
properties of the system  we evaluate them on random linear Gaussian SSMs of different orders.
We generate 150 random systems  using the MATLAB function drss from the Control Systems
Toolbox  with model orders 2  5 and 20 (50 systems for each model order). The number of outputs
are taken as 1  2 and 4 for the different model orders  respectively. The systems are then simulated
for T = 200 time steps  driven by Gaussian process noise entering only on the ﬁrst state component.
Hence  the rank of the process noise covariance is 1 for all systems.
We run the PG-AS and PG-BS samplers for 10000 iterations using N = 5 particles. We consider
different ﬁxed truncation levels  as well as an adaptive level with γ = 0.1 and τ = 10−2. Again 
we compute running posterior means (discarding 1000 samples) and RMSE values relative the true
posterior mean. Box plots are shown in Figure 3. Since the process noise only enters on one of the
state components  the mixing tends to deteriorate as we increase the model order. Figure 1 shows
how the probability distributions on {1  . . .   N} change as we increase the truncation level  in two
representative cases for a 5th and a 20th order system  respectively. By using an adapted level 
we can obtain accurate results for systems of different dimensions  without having to change any
settings between the runs.

7 Discussion

PG-AS is a novel approach to PMCMC that makes use of backward simulation ideas without need-
ing an explicit backward pass. Compared to PG-BS  a conceptually similar method that does require
an explicit backward pass  PG-AS has advantages  most notably for inference in the non-Markovian
SSMs that have been our focus here. When using the proposed truncation of the backward weights 
we have found PG-AS to be more robust to the approximation error than PG-BS. Furthermore  for
non-Markovian models  PG-AS is easier to implement than PG-BS  since it requires less bookkeep-
ing. It can also be more memory efﬁcient  since it does not require us to store intermediate quantities
that are needed for a separate backward simulation pass  as is done in PG-BS. Finally  we note that
PG-AS can be used as an alternative to PG-BS for other inference problems to which PMCMC can
be applied  and we believe that it will prove attractive in problems beyond the non-Markovian SSMs
that we have discussed here.

Acknowledgments

This work was supported by: the project Calibrating Nonlinear Dynamical Models (Contract num-
ber: 621-2010-5876) funded by the Swedish Research Council and CADICS  a Linneaus Center
also funded by the Swedish Research Council.

8

10−310−210−1p=1p=2p=3Adapt.(3.8)d=210−310−210−1p=1p=5p=10Adapt.(5.9)d=510−310−210−1p=1p=5p=10Adapt.(10.6)d=20  PG w. ancestral samplingPG w. backward simulationReferences
[1] C. Andrieu  A. Doucet  and R. Holenstein  “Particle Markov chain Monte Carlo methods ”

Journal of the Royal Statistical Society: Series B  vol. 72  no. 3  pp. 269–342  2010.

[2] N. Whiteley  C. Andrieu  and A. Doucet  “Efﬁcient Bayesian inference for switching state-
space models using discrete particle Markov chain Monte Carlo methods ” Bristol Statistics
Research Report 10:04  Tech. Rep.  2010.

[3] F. Lindsten and T. B. Sch¨on  “On the use of backward simulation in the particle Gibbs sampler ”
in Proceedings of the 2012 IEEE International Conference on Acoustics  Speech and Signal
Processing (ICASSP)  Kyoto  Japan  Mar. 2012.

[4] A. Doucet and A. Johansen  “A tutorial on particle ﬁltering and smoothing: Fifteen years later ”
in The Oxford Handbook of Nonlinear Filtering  D. Crisan and B. Rozovsky  Eds. Oxford
University Press  2011.

[5] M. K. Pitt and N. Shephard  “Filtering via simulation: Auxiliary particle ﬁlters ” Journal of the

American Statistical Association  vol. 94  no. 446  pp. 590–599  1999.

[6] D. A. V. Dyk and T. Park  “Partially collapsed Gibbs samplers: Theory and methods ” Journal

of the American Statistical Association  vol. 103  no. 482  pp. 790–796  2008.

[7] N. Whiteley  “Discussion on Particle Markov chain Monte Carlo methods ” Journal of the

Royal Statistical Society: Series B  72(3)  p 306–307  2010.

[8] R. Chen and J. S. Liu  “Mixture Kalman ﬁlters ” Journal of the Royal Statistical Society: Series

B  vol. 62  no. 3  pp. 493–508  2000.

[9] A. Doucet  S. J. Godsill  and C. Andrieu  “On sequential Monte Carlo sampling methods for

Bayesian ﬁltering ” Statistics and Computing  vol. 10  no. 3  pp. 197–208  2000.

[10] T. Sch¨on  F. Gustafsson  and P.-J. Nordlund  “Marginalized particle ﬁlters for mixed lin-
ear/nonlinear state-space models ” IEEE Transactions on Signal Processing  vol. 53  no. 7 
pp. 2279–2289  Jul. 2005.

[11] S. S¨arkk¨a  P. Bunch  and S. Godsill  “A backward-simulation based Rao-Blackwellized par-
ticle smoother for conditionally linear Gaussian models ” in Proceedings of the 16th IFAC
Symposium on System Identiﬁcation  Brussels  Belgium  Jul. 2012.

[12] W. Fong  S. J. Godsill  A. Doucet  and M. West  “Monte Carlo smoothing with application
to audio signal enhancement ” IEEE Transactions on Signal Processing  vol. 50  no. 2  pp.
438–449  Feb. 2002.

[13] N. L. Hjort  C. Holmes  P. Mller  and S. G. Walker  Eds.  Bayesian Nonparametrics. Cam-

bridge University Press  2010.

[14] S. N. MacEachern  M. Clyde  and J. S. Liu  “Sequential importance sampling for nonparamet-
ric Bayes models: The next generation ” The Canadian Journal of Statistics  vol. 27  no. 2  pp.
251–267  1999.

[15] P. Fearnhead  “Particle ﬁlters for mixture models with an unknown number of components ”

Statistics and Computing  vol. 14  pp. 11–21  2004.

[16] C. E. Rasmussen and C. K. I. Williams  Gaussian Processes for Machine Learning. MIT

Press  2006.

[17] A. Bouchard-Cˆot´e  S. Sankararaman  and M. I. Jordan  “Phylogenetic inference via sequential

Monte Carlo ” Systematic Biology  vol. 61  no. 4  pp. 579–593  2012.

[18] Y. W. Teh  H. Daum´e III  and D. Roy  “Bayesian agglomerative clustering with coalescents ”

Advances in Neural Information Processing  pp. 1473–1480  2008.

[19] G. J. Bierman  “Fixed interval smoothing with discrete measurements ” International Journal

of Control  vol. 18  no. 1  pp. 65–75  1973.

[20] F. Lindsten  M. I. Jordan  and T. B. Sch¨on  “Ancestor sampling for particle Gibbs ” arXiv.org 

arXiv:1210.6911  Oct. 2012.

[21] S. J. Godsill  A. Doucet  and M. West  “Monte Carlo smoothing for nonlinear time series ”

Journal of the American Statistical Association  vol. 99  no. 465  pp. 156–168  Mar. 2004.

9

,Sinead Williamson
Steve MacEachern
Eric Xing
Scott Linderman
Christopher Stock
Ryan Adams