2019,Catastrophic Forgetting Meets Negative Transfer: Batch Spectral Shrinkage for Safe Transfer Learning,Before sufficient training data is available  fine-tuning neural networks pre-trained on large-scale datasets substantially outperforms training from random initialization. However  fine-tuning methods suffer from two dilemmas  catastrophic forgetting and negative transfer. While several methods with explicit attempts to overcome catastrophic forgetting have been proposed  negative transfer is rarely delved into. In this paper  we launch an in-depth empirical investigation into negative transfer in fine-tuning and find that  for the weight parameters and feature representations  transferability of their spectral components is diverse. For safe transfer learning  we present Batch Spectral Shrinkage (BSS)  a novel regularization approach to penalizing smaller singular values so that untransferable spectral components are suppressed. BSS is orthogonal to existing fine-tuning methods and is readily pluggable to them. Experimental results show that BSS can significantly enhance the performance of representative methods  especially with limited training data.,Catastrophic Forgetting Meets Negative Transfer:
Batch Spectral Shrinkage for Safe Transfer Learning

Xinyang Chen‚àó  Sinan Wang‚àó  Bo Fu  Mingsheng Long ((cid:66))‚Ä†  and Jianmin Wang

School of Software  BNRist  Tsinghua University  China
Research Center for Big Data  Tsinghua University  China
National Engineering Laboratory for Big Data Software

{chenxiny17 wang-sn17}@mails.tsinghua.edu.cn  {mingsheng jimwang}@tsinghua.edu.cn

Abstract

Before sufÔ¨Åcient training data is available  Ô¨Åne-tuning neural networks pre-trained
on large-scale datasets substantially outperforms training from random initialization.
However  Ô¨Åne-tuning methods suffer from a dilemma across catastrophic forgetting
and negative transfer. While several methods with explicit attempts to overcome
catastrophic forgetting have been proposed  negative transfer is rarely delved into.
In this paper  we launch an in-depth empirical investigation into negative transfer
in Ô¨Åne-tuning and Ô¨Ånd that  for the weight parameters and feature representations 
transferability of their spectral components is diverse. For safe transfer learning 
we present Batch Spectral Shrinkage (BSS)  a novel regularization approach
to penalizing smaller singular values so that untransferable spectral components
are suppressed. BSS is orthogonal to existing Ô¨Åne-tuning methods and is readily
pluggable into them. Experimental results show that BSS can signiÔ¨Åcantly enhance
the performance of state-of-the-art methods  especially in few training data regime.

1

Introduction

Deep learning has made revolutionary changes to diverse machine learning problems and applications.
During the past few years  signiÔ¨Åcant improvements on various tasks have been achieved by deep
neural networks [17  33  10  35]. However  training deep neural networks from scratch is time-
consuming and laborious  and the excellent performance of such deep neural networks depends on
large-scale labeled datasets which we may have no access to in many practical scenarios.
Fortunately  deep feature representations learned on large-scale datasets are transferable across several
tasks and domains [25  7  45]. Thus  Ô¨Åne-tuning  a simple yet effective method that exploits this
nice property of deep representations  is widely adopted  especially before sufÔ¨Åcient training data is
available [9]. Under this well-established paradigm  deep neural networks are Ô¨Årstly pre-trained on
large-scale datasets and then Ô¨Åne-tuned to target tasks  requiring relatively smaller training samples.
To a certain extent  Ô¨Åne-tuning alleviates deep neural networks‚Äô hunger for data. However  adequate
amount of training data for target tasks is still a prerequisite for the effectiveness of vanilla Ô¨Åne-tuning
methods. When the requirement of training data cannot be satisÔ¨Åed  two hidden issues of Ô¨Åne-tuning
will become extremely severe  seriously hampering the generalization performance of deep models.
The Ô¨Årst is catastrophic forgetting [14]  which is the tendency of the model to lose previous learnt
knowledge abruptly while it may incorporate information relevant to target tasks  leading to overÔ¨Åtting.
The second is negative transfer [37]. Not all pre-trained knowledge is transferable across domains 
and an indiscriminate transfer of all knowledge is detrimental to the model.

‚àóAuthors contributed equally
‚Ä†Corresponding author: Mingsheng Long (mingsheng@tsinghua.edu.cn)

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

Table 1: Comparison of Different Fine-Tuning Methods ((cid:150): unknown)
Technical Challenge

Target Dataset Size

Method

large medium small

catastrophic forgetting

negative transfer

L2

L2-SP [20]
DELTA [19]

BSS (Proposed)






(cid:150)
(cid:150)
(cid:150)

















Incremental learning [30  18  21  32  44] extends the existing model‚Äôs knowledge continuously with
gradually available training data. Various measures have been taken to curb the tendency of forgetting
previously learnt knowledge while acquiring new knowledge. Note that the original motivation of
mitigating catastrophic forgetting for incremental learning and Ô¨Åne-tuning is quite different. In the
context of incremental learning  the model performance on both old and new tasks makes sense  while
when it comes to Ô¨Åne-tuning  only target tasks are concerned. In this paper  catastrophic forgetting
refers speciÔ¨Åcally to forgetting the pre-trained knowledge beneÔ¨Åcial to target tasks. During the past
few years  a few transfer learning penalties [20  19] have been proposed to constrain parameters on
maintaining pre-trained knowledge. Specially  L2-SP [20] considers that weight parameters should be
driven to pre-trained values instead of the origin and takes the advantage of all pre-trained weights to
refrain networks from forgetting useful information. DELTA [19] utilizes discriminative knowledge
in feature maps and imposes feature map regularization by the attention mechanism.
Methods above largely alleviate the problem of catastrophic forgetting by drawing weight parameters
close to pre-trained values or aligning transferable channels in feature maps. Still  negative transfer
has not been attached with enough importance and is often overlooked in deep methods. However 
when the amount of training examples on the target domain is limited  overly retaining pre-trained
knowledge will deteriorate target performance and negative transfer will become prominent. It is
thereby apparent that catastrophic forgetting and negative transfer constitute a dilemma  which should
be solved jointly for safe transfer learning. In this paper  we explore Ô¨Åne-tuning against negative
transfer and propose a novel regularization approach to restraining detrimental pre-trained knowledge
during Ô¨Åne-tuning. A comparison of these Ô¨Åne-tuning methods is presented in Table 1.
Based on Singular Value Decomposition (SVD)  we investigate which spectral components of weight
parameters and feature representations are untransferable across domains  and make two observations.
For weight parameters  in high layers  the spectral components with small singular values are not
transferable. For feature representations  an interesting Ô¨Ånding is that with sufÔ¨Åcient training data 
the spectral components with small singular values are decayed autonomously during Ô¨Åne-tuning.
Inspired by this inherent mechanism  we propose Batch Spectral Shrinkage (BSS)  a general
approach to inhibiting negative transfer by suppressing the spectral components with small singular
values that correspond to detrimental pre-trained knowledge. BSS is orthogonal to existing methods
for mitigating catastrophic forgetting  and can be easily embedded into them to tackle the dilemma.
Experiments conÔ¨Årm the effectiveness of BSS in mitigating negative transfer  especially when the
amount of available training data is limited  yielding state-of-the-art results on several benchmarks.

2 Related Work

Transfer learning  an important machine learning paradigm  is committed to transferring knowledge
obtained on a source domain to a target domain [2  26]. There are several different scenarios of
transfer learning  such as domain adaptation [31] and multi-task learning [2]  while inductive transfer
learning is the most practical one. In inductive transfer learning  1) the target task is different from
the source task (different label spaces)  and 2) there is labeled data in the target domain.
Fine-tuning is the de facto approach to inductive transfer of deep models  where we have a pre-trained
model from the source domain but have no access to the source data. To utilize pre-trained knowledge
obtained on the source domain  Donahue et al. [7] employed a label predictor to classify features
extracted by the pre-trained model. This method directly reused a substantial part of the weight
parameters  which inhibits catastrophic forgetting (relevant information eliminated) but exacerbates
the risk of negative transfer (irrelevant information retained). Later  deep networks proved to be able

2

to learn transferable representations [45]. To explore potential factors affecting deep transfer learning
performance  Huh et al.[12] empirically analyzed features extracted by various networks pre-trained
on ImageNet. Recently  numerous approaches were proposed to advance this Ô¨Åeld  including Ô¨Ålter
distribution constraining [1]  sparse transfer [22]  and Ô¨Ålter subset selection [8  4]. Further  Simon et
al. [15] empirically studied what factors impact inductive transfer of deep models.
Catastrophic forgetting is an inevitable problem of incremental learning or lifelong learning [36]. To
overcome this limitation  incremental moment matching [18] and ‚Äúhard attention to the task‚Äù [32]
have been proposed. In inductive transfer learning  the pre-trained networks also have the tendency to
lose previous learnt knowledge abruptly while incorporating information relevant to target tasks. By
driving weight parameters to initial pre-trained values  L2-SP [20] enhances model performance for
target tasks while avoiding degradation in accuracy on pre-trained datasets. Inspired by knowledge
distillation for model compression [29  11  46  43]  Li et al. [19] proposed the idea of ‚Äúunactivated
channel re-usage‚Äù and presented DELTA  a feature map regularization with attention.
Above methods have achieved remarkable performance gains and alleviated catastrophic forgetting to
varying degrees. However  negative transfer  a major challenge in domain adaptation [31  34  38  40 
41]  has rarely been considered in inductive transfer learning. In this paper  from the perspective of
inhibiting negative transfer during Ô¨Åne-tuning  we propose Batch Spectral Shrinkage (BSS)  a novel
regularization approach orthogonal to existing methods  to enhance Ô¨Åne-tuned models‚Äô performance.

3 Catastrophic Forgetting Meets Negative Transfer

In inductive transfer learning (Ô¨Åne-tuning)  we have access to a target domain with n labeled examples
and a network pre-trained on a source domain. Different from domain adaptation [26]  in Ô¨Åne-tuning
the source domain is inaccessible at training. For classiÔ¨Åcation tasks  typically  the network consists
of two parts: the shared sub-network (feature extractor F ) and the task-speciÔ¨Åc architecture (classiÔ¨Åer
G). We denote by F 0 and G0 the corresponding parts with pre-trained weights respectively.
There are two potential pitfalls inductive transfer learning may have. The Ô¨Årst one is catastrophic
forgetting  which refers to a tendency of the model to abruptly forget previously learnt knowledge
upon acquiring new knowledge. The second is negative transfer  a process where the model transfers
knowledge irrelevant to target tasks  and leads to negative impacts on model performance. Almost all
existing deep methods concentrate on the former. It is natural to raise the following questions: 1)
Does negative transfer really exist in Ô¨Åne-tuning? 2) If it does  how does it affect model performance?

3.1 Regularizations for Transfer Learning

n(cid:88)

We Ô¨Årst review existing inductive transfer learning methods. Almost all Ô¨Åne-tuning methods can be
formulated as follows:

(1)
where W refers to the weight parameters of models  L(¬∑ ¬∑) denotes the loss function and ‚Ñ¶(¬∑) is the
regularization term on the weights or on the features extracted by the model. Next we will discuss
three Ô¨Åne-tuning penalties and their corresponding effects on mitigating catastrophic forgetting.

min
W

i=1

L(G(F (xi))  yi) + ‚Ñ¶(¬∑) 

L2 penalty. The common penalty for transfer learning is L2 penalty  also known as weight decay:

‚Ñ¶(W) =

(cid:107)W(cid:107)2
2  

Œ±
2

(2)

where Œ± is a hyperparameter to control the strength of this regularization term. L2 penalty tries to
drive the network parameters to zero  without considering catastrophic forgetting or negative transfer.

L2-SP. The key concept of L2-SP penalty [19] is ‚Äústarting point as reference‚Äù:

(cid:13)(cid:13)WS ‚àí W0

S

(cid:13)(cid:13)2

‚Ñ¶(W) = ‚Ñ¶(W  W0) =

Œ≤
2

2 +

(cid:107)WS(cid:107)2
2  

Œ±
2

(3)

where W0
S is the pre-trained weight parameters of the shared architecture (feature extractor F0)  WS
is weight parameters of F   WS is weight parameters of the task-speciÔ¨Åc classiÔ¨Åer G  Œ≤ is a trade-off

3

hyperparameter to control the strength of the penalty. L2-SP penalty tries to drive weight parameters
to pre-trained values. Xuhong et al. [20] empirically proved that L2-SP reduces drop in accuracy of
networks on source tasks after Ô¨Åne-tuning  revealing that L2-SP can alleviate catastrophic forgetting.

DELTA. Based on the key insight of ‚Äúunactivated channel re-usage‚Äù  Li et al. [19] proposed a
regularized transfer learning framework  DELTA. SpeciÔ¨Åcally  DELTA selects the discriminative
features from higher layer outputs with a supervised attention mechanism. ‚Ñ¶(W) is formulated as:

‚Ñ¶(W) = ‚Ñ¶(W  W0  xi  yi  z) = Œ≥ ¬∑ ‚Ñ¶(cid:48)(W  W0  xi  yi  z) + Œ∫ ¬∑ ‚Ñ¶(cid:48)(cid:48)(W\W0)
‚Ñ¶(cid:48)(W  W0  xi  yi  z) =

Dj(z  W0  xi  yi) ¬∑(cid:13)(cid:13)(cid:13)FMj(z  W  xi) ‚àí FMj(z  W0  xi)

N(cid:88)

(cid:13)(cid:13)(cid:13)2

2

(4)

j=1

Dj(z  W0  xi  yi) = softmax(L(z(xi  W0\j)  yi) ‚àí L(z(xi  W0)  yi))

where z is the model  ‚Ñ¶(cid:48) is behavioral regularizer  ‚Ñ¶(cid:48)(cid:48) constrains the L2-norm of the private parameters
in W; Dj(z  W0  xi  yi) refers to the behavioral difference between the two feature maps (FM) and
the weight assigned to the jth Ô¨Ålter and the ith image (for 1 < j < N); Œ≥ and Œ∫ are trade-off hyper-
parameters to control the strength of the two regularization terms. DELTA alleviates catastrophic
forgetting by aligning the behaviors of certain higher layers of the target network to the source one.

3.2 Negative Transfer in Fine-tuning

In this section  we will investigate whether negative transfer exists and whether it has a negative
impact on the model‚Äôs performance. We design an experiment based on L2 penalty and L2-SP penalty.
ResNet-50 [10] pre-trained on ImageNet is chosen as the backbone and MIT Indoors 67 [28] is the
target dataset. The training details are consistent with Section 5. We sample the training datasets at
the rates of 15%  30%  50% and 100% to construct new training datasets of different sizes.
Contrary to what one might suppose  as shown in Figure 1(a)  L2-SP penalty worsens the model‚Äôs
performance  compared with L2 penalty  especially when the amount of training data is limited. L2-
SP penalty explicitly promotes the similarity of the Ô¨Ånal solution with the initial model to alleviate
catastrophic forgetting  while L2 does not. Although only the behaviors of certain higher layers of
the target network are aligned to the source one  L2-SP still aggravates negative transfer  in that the
pre-trained knowledge irrelevant to the target tasks is still transferred forcefully.
As negative transfer does exist  further  we want to answer two questions: 1) Which part of weight
parameters and feature representations causes negative transfer? 2) How to mitigate this problem?

3.3 Why Negative Transfer?

In this section  we will explore which part of the weight parameters W and feature representations
f = F (x) may not be transferable and may negatively impact the model accuracy. ResNet-50 [10]
pre-trained on ImageNet is chosen as the backbone and MIT Indoors 67 is the target dataset. Weight
parameters and feature representations of both pre-trained and Ô¨Åne-tuned networks are analyzed.

Corresponding Angle. Principal angles [24] have been introduced to measure the similarity of
subspaces. However  it is unreasonable to calculate the principal angles by completing the pairing
between whole eigenvectors in subspaces with the smallest angle  regardless of their relative singular
values  because eigenvectors with large singular values and small singular values have different roles
in matrices. Inspired by [3]  we use corresponding angles  denoted by Œ∏. DeÔ¨Ånitions are as follows:

DeÔ¨Ånition 1 (Corresponding Angle) It is the angle between two eigenvectors which are equally
important in their matrices. That is  they are related to the same index in the singular value matrices.

The cosine value of the corresponding angle is calculated as
(cid:104)u1 i  u2 i(cid:105)
(cid:107)u1 i(cid:107)(cid:107)u2 i(cid:107)  

cos(Œ∏i) =

(5)

where u1 i is the ith eigenvector with the ith largest singular value in one matrix  and similarly for
u2 i in another matrix. We will use Œ∏ to measure the transferability of eigenvectors in weight matrices.
Intuitively  eigenvectors with smaller corresponding angle across domains imply better transferability.

4

(a) error rate

(b) cos(Œ∏)

(c) singular value œÉ

(d) smaller half of œÉ

Figure 1: Analysis of negative transfer: (a) Error rates of Ô¨Åne-tuned models with L2 and L2-SP
penalties; (b) Cosine values of the corresponding angles between W and W0; (c) All singular values
of feature matrices extracted on four conÔ¨Ågurations for the dataset MIT Indoors 67  with random
sampling rates 15%  30%  50% and 100% respectively; (d) The smaller half of singular values in (c).

Weights. We denote by W0 and W the pre-trained weight parameters of ResNet-50 on ImageNet
and Ô¨Åne-tuned weight parameters on MIT Indoors 67 respectively. For a conv2d layer  its parameters
form a four-dimensional tensor with the shape of (ci+1  ci  kh  kw). We unfold this tensor to a matrix
with the shape (ci+1  ci ¬∑ kh ¬∑ kw) and perform SVD to obtain eigenvectors U and singular values Œ£:
(6)
Then  following Equation (5)  relative angles Œ∏ are calculated in every layers between W and W0.
Corresponding angles in four lower layers (the Ô¨Årst convolutional layer and three convolutional layers
in the Ô¨Årst residual block) and three higher layers (three convolutional layers in the last residual block)
are shown in Figure 1(b)  the former with solid lines and the latter with dotted lines. We can observe
that for the lower layers  eigenvectors in W and W0 have small relative angles  which means these
weight parameters are transferable. However  in the higher layers  only eigenvectors corresponding to
relatively larger singular values have small corresponding angles. So aligning all weight parameters
indiscriminately to the initial pre-trained values is risky to negative transfer.

W = UŒ£VT.

Features. Analyzing feature representations  rather than weight parameters  is more straightforward.
We will analyze the characteristics of feature representations produced by models with different
generalization performance. As the size of training dataset has a profound impact on model per-
formance  we sample MIT Indoors 67 at the rates of 15%  30%  50% and 100% to construct new
training datasets. We Ô¨Åne-tune ImageNet pre-trained ResNet-50 on these four datasets and then
obtain four models.
The feature extractor Ô¨Åne-tuned on target datasets is denoted by F and the feature vector is calculated
by fi = F (xi). Every feature matrix F = [f1 . . . fb] is composed of a batch size b of feature vectors.
Again  we apply SVD to compute all singular eigenvectors U and values Œ£ of the feature matrices:
(7)
The main diagonal elements [œÉ1  œÉ2...  œÉb] of the singular value matrix Œ£ (a rectangular diagonal
matrix) are drawn in Figure 1(c) and Figure 1(d) in descending order  measuring the importance of
eigenvectors. Figure 1(c) contains all these singular values  and Figure 1(d) contains the smaller half
of them. As justiÔ¨Åed by [9]  with sufÔ¨Åcient labeled data  Ô¨Åne-tuning and training from scratch achieve
comparably best results. Hence models Ô¨Åne-tuned on larger datasets can have stronger generalization
performance. It is important to observe that the relatively small singular values of features extracted
by such models are suppressed signiÔ¨Åcantly  indicating that the spectral components corresponding to
relatively small singular values are relevant to the variation of training data that are less transferable.
Consequently  promoting the similarity between these components will give rise to negative transfer.

F = UŒ£VT.

4 Approach

We stress that catastrophic forgetting and negative transfer are equally important and constitute an
inherent dilemma for Ô¨Åne-tuning. While the previous section focuses on why negative transfer occurs 
this section presents how to alleviate negative transfer without casting aside pre-trained knowledge.

5

15%30%50%100%0.200.250.300.350.40Error RateL2L2-SP0510152025303540Index0.00.20.40.60.81.0Corresponding anglescosine values of corresponding anglesconv1layer0.0.conv1layer0.0.conv2layer0.0.conv3layer4.2.conv1layer4.2.conv2layer4.2.conv301020304050Index4681012141618Singular ValuesSingular Values15%30%50%100%253035404550Index345678Singular ValuesSingular Values15%30%50%100%Figure 2: The architecture of Batch Spectral Shrinkage (BSS). BSS is a new regularization approach
to overcoming negative transfer in Ô¨Åne-tuning  which is readily pluggable into existing methods and is
end-to-end trainable with differentiable SVD natively supported in PyTorch (best viewed in color).

The analysis above shows that both weight parameters and feature representations are partially
transferable. For weight parameters  almost all eigenvectors in lower layers are transferable  while in
higher layers only eigenvectors with large singular values are transferable. For feature representations 
an expanded dataset can enhance the performance of models and suppress the eigenvectors with
small singular values of the feature matrices. This inspires us to suppress the importance of spectral
components that are untransferable  especially when the number of training data examples is limited.
As applying SVD to high-dimensional weight matrices is extremely costly  for untransferable layers
with huge weight parameters  we perform spectral component shrinkage on the feature matrices only.

4.1 Batch Spectral Shrinkage

The above decomposition analysis of feature matrices brings us the key inspiration. We propose a
new regularization approach  Batch Spectral Shrinkage (BSS)  to restrain negative transfer during
Ô¨Åne-tuning through directly suppressing the small singular values of the feature matrices. Detailed
procedures are as follows: 1) Constructing a feature matrix F from a batch size b of feature vectors f;
2) Applying SVD to compute all singular values of F as Equation (7); 3) Penalizing the smallest k
singular values [œÉ1  œÉ2...  œÉb] in the diagonal of singular value matrix Œ£ to mitigate negative transfer:

Lbss(F ) = Œ∑

œÉ2‚àíi 

(8)

i=1

where Œ∑ is a trade-off hyperparameter to control the strength of spectral shrinkage  k is the number of
singular values to be penalized  and œÉ‚àíi refers to the i-th smallest singular value.
Computational Complexity. For a p √ó q matrix  the time complexity of full SVD that computes
all singular values is O(min(p2q  pq2)). The time cost of performing SVD on a nearly squared matrix
is unacceptable  e.g. weight matrices of deep networks. The complexity of BSS is O(b2d) where d is
the dimension of features and b is the batch size. Typically  as b is relatively small  say b = 48  the
overall computational budget of BSS is nearly negligible in Ô¨Åne-tuning through the mini-batch SGD.

4.2 Models with Batch Spectral Shrinkage

Almost all of existing Ô¨Åne-tuning methods concentrate on catastrophic forgetting. BSS  as a novel
regularization approach we propose from another perspective  boosts Ô¨Åne-tuning through inhibiting
negative transfer  making itself orthogonal to previous methods. BSS is lightweight and pluggable
readily into existing Ô¨Åne-tuning methods  e.g. L2  L2-SP [20] and DELTA [19]. Figure 2 showcases
the architecture of L2+BSS. BSS embedded into existing Ô¨Åne-tuning scenarios can be formulated as:

k(cid:88)

n(cid:88)

min
W

i=1

6

L(G(F (xi))  yi) + ‚Ñ¶(W) + Lbss(F ).

(9)

cross-entropyLSVDbatchùíö"ùíôFfFBSSLbssG5 Experiments

We embed BSS into representative inductive transfer learning methods mentioned above  including L2 
L2-SP and DELTA  and evaluate these methods on several visual recognition benchmarks. Except
that  BSS is also explored in other scenarios  such as incremental learning and natural language
processing. Code and datasets are available at github.com/thuml/Batch-Spectral-Shrinkage.

5.1 Setup

Stanford Dogs [13] contains 20 580 images of 120 breeds of dogs from around the world. Each
category is composed of exactly 100 training examples and around 72 testing examples.
Oxford-IIIT Pet [27] is a 37-category pet dataset with roughly 200 images for each class.
CUB-200-2011 [42] is a dataset for Ô¨Åne-grained visual recognition with 11 788 images in 200 bird
species. It is an extended version of the CUB-200 dataset  roughly doubling the number of images.
Stanford Cars [16] contains 16 185 images of 196 classes of cars. Each category has been split
roughly in a 50-50 split. There are 8 144 images for training and 8 041 images for testing.
FGVC Aircraft [23] is a benchmark for the Ô¨Åne-grained visual categorization of aircraft. The dataset
contains 10 200 images of aircraft  with 100 images for each of the 102 different aircraft variants.
To explore the impact of negative transfer with different numbers of training examples  we create
four conÔ¨Ågurations for each dataset  which respectively have 15%  30%  50%  and 100% randomly
sampled training examples for each category. Following the previous protocols [20  19]  we employ
ResNet-50 [10] pre-trained on ImageNet [5] as the source model. The last fully connected layer is
trained from scratch  with learning rate set to be 10 times those of the Ô¨Åne-tuned layers  which is
a de facto conÔ¨Åguration in Ô¨Åne-tuning. We adopt mini-batch SGD with momentum of 0.95 using
the progressive training strategies in [20] except that the initial learning rate for the last layer is set
to 0.01 or 0.001  depending on the tasks. We set batch size to 48. In all experiments with BSS  the
trade-off hyperparameter Œ∑ is Ô¨Åxed to 0.001 and k is set to 1. Each experiment is repeated Ô¨Åve times 
and the average top-1 accuracy is reported in Table 2.

5.2 Results and Analyses

Results. The top-1 classiÔ¨Åcation accuracies are shown in Table 2. It is observed that BSS produces
boosts in accuracy with fewer training data for most methods on most datasets. However  performance
gains on Stanford Dogs and Oxford-IIIT Pet are not very obvious  indicating that the transferability of
pre-trained knowledge across these datasets plays a major role and thus negative transfer impact is not
as serious as expected. Embedding BSS into L2-SP and DELTA  L2-SP+BSS and DELTA+BSS
alleviate negative transfer and catastrophic forgetting simultaneously to yield state-of-the-art results.
Negative Transfer. To delve into BSS  we remove the spectral components corresponding to the
smallest r singular values  named Truncated SVD (TSVD). Formally  SVD is performed on mini-
batch feature matrix F  yielding b singular vectors and values. Then only the b ‚àí r column vectors of
U and b‚àí r row vectors of VT corresponding to the b‚àí r largest singular values Œ£b‚àír are calculated.
Finally  the rest of the matrix F is discarded  with an approximate feature matrix Fb‚àír reconstructed:
(10)
ResNet-50 pre-trained on ImageNet is employed as the base model and Stanford Dogs is the target
dataset. We analyze the performance of TSVD (r = 1  2  4  8) with L2 penalty. Results are shown in
Figure 3(a). We Ô¨Ånd that when the dataset is relatively small  TSVD with a larger r leads to better
performance  which proves that spectral components corresponding to relatively small singular values
have negative impact on transfer learning. Thus  BSS is a reasonable approach to inhibiting negative
transfer. However  when sufÔ¨Åcient training data is available  a larger r may deteriorate the accuracy.
Singular Values. Singular values of features extracted by the networks Ô¨Åne-tuned with regulariza-
tion L2+BSS and L2 are shown in Figure 3(b)‚Äì3(c). The former is with dotted line and the latter is
with solid line. Although k in Equation (8) is set to 1  more than one singular values are suppressed 
indicating that feature matrices are capable of automatically adjusting singular value distributions.
k = 1 is adequate for most cases  and a larger k may display equal effect with a larger trade-off
hyperparameter Œ∑. BSS is effective in suppressing small singular values to combat negative transfer.

F = UŒ£VT  Fb‚àír = Ub‚àírŒ£b‚àírVT

b‚àír.

7

Table 2: Comparison of Top-1 Accuracy with Different Methods (Backbone: ResNet-50)

Dataset

Method

Stanford Dogs

CUB-200-2011

Stanford Cars

Oxford-IIIT Pet

FGVC Aircraft

L2

L2+BSS
L2-SP [20]
L2-SP+BSS
DELTA [19]
DELTA+BSS

L2

L2+BSS
L2-SP [20]
L2-SP+BSS
DELTA [19]
DELTA+BSS

L2

L2+BSS
L2-SP [20]
L2-SP+BSS
DELTA [19]
DELTA+BSS

L2

L2+BSS
L2-SP [20]
L2-SP+BSS
DELTA [19]
DELTA+BSS

L2

L2+BSS
L2-SP [20]
L2-SP+BSS
DELTA [19]
DELTA+BSS

Sampling Rates

15%

81.05¬±0.18
81.86¬±0.19
81.41¬±0.23
82.20¬±0.27
81.46¬±0.18
81.93¬±0.29
45.25¬±0.12
47.74¬±0.23
45.08¬±0.19
46.77¬±0.19
46.83¬±0.21
49.77¬±0.07
36.77¬±0.12
40.57¬±0.12
36.10¬±0.30
39.44¬±0.18
39.37¬±0.34
41.92¬±0.16
86.56¬±0.21
87.57¬±0.13
86.78¬±0.21
87.53¬±0.36
87.17¬±0.23
87.30¬±0.23
39.57¬±0.20
40.41¬±0.12
39.27¬±0.24
40.02¬±0.15
42.16¬±0.21
43.79¬±0.19

30%

84.47¬±0.23
84.79¬±0.18
84.88¬±0.15
85.06¬±0.17
83.66¬±0.29
84.33¬±0.16
59.68¬±0.21
63.38¬±0.29
57.78¬±0.24
60.89¬±0.28
60.37¬±0.25
62.95¬±0.18
60.63¬±0.18
64.13¬±0.18
60.30¬±0.28
64.41¬±0.19
63.28¬±0.27
64.67¬±0.28
89.99¬±0.35
90.46¬±0.21
90.00¬±0.23
90.13¬±0.21
89.95¬±0.25
90.44¬±0.12
57.46¬±0.12
59.23¬±0.31
57.12¬±0.27
58.78¬±0.26
58.60¬±0.29
61.58¬±0.17

50%

85.69¬±0.21
86.00¬±0.22
85.99¬±0.18
86.18¬±0.05
84.73¬±0.16
85.30¬±0.30
70.12¬±0.29
72.56¬±0.17
69.47¬±0.29
72.33¬±0.26
71.38¬±0.20
72.31¬±0.38
75.10¬±0.21
76.78¬±0.21
75.48¬±0.22
76.56¬±0.28
76.53¬±0.24
77.58¬±0.33
91.22¬±0.19
92.07¬±0.29
90.65¬±0.18
91.03¬±0.09
91.17¬±0.19
91.70¬±0.30
67.93¬±0.28
69.19¬±0.13
67.46¬±0.26
68.96¬±0.21
68.51¬±0.25
69.46¬±0.29

100%

86.89¬±0.32
87.18¬±0.14
86.72¬±0.20
86.91¬±0.19
86.01¬±0.22
86.54¬±0.14
78.01¬±0.16
78.85¬±0.31
78.44¬±0.17
79.36¬±0.12
78.63¬±0.18
79.02¬±0.21
87.20¬±0.19
87.63¬±0.27
86.58¬±0.26
87.38¬±0.23
86.32¬±0.20
86.32¬±0.25
92.75¬±0.25
93.30¬±0.14
92.29¬±0.22
92.41¬±0.18
92.29¬±0.12
92.62¬±0.27
81.13¬±0.21
81.48¬±0.18
80.98¬±0.29
81.27¬±0.31
80.44¬±0.20
80.85¬±0.17

Sensitivity Analysis. Sensitivity analysis of a larger k in Equation (8) is conducted on the Stanford
Dogs dataset  with results shown in Figure 3(d). When the amount of training data examples is small 
a larger k enhances the performance of Ô¨Åne-tuned models. However  with relatively sufÔ¨Åcient training
data examples  a larger k leads to a slight decline in classiÔ¨Åcation accuracy. Thus k = 1 is generally
a good choice  since we always have difÔ¨Åculty in determining the relative size of the training dataset.

5.3 More Scenarios

Incremental Learning. The Ô¨Åne-tuning step is a special case of incremental learning that has only
one additional stage. Though source task is not considered by BSS  it is interesting to Ô¨Ånd how BSS
inÔ¨Çuences the performance of incremental learning methods. We evaluate BSS embeded with EWC
[14] on the permuted MNIST dataset. For this task  we use the same training strategies of [14] and
test the accuracy of both the source task and target task. Top-1 classiÔ¨Åcation accuracies are shown in
Table 3. It is observed that BSS promotes the target task while slightly hurts the source task. This is
an intuitive and reasonable result because BSS tries to alleviate the risk of negative transfer and does
not focus on remembering the previously-learnt knowledge of the source task.

8

(a) TSVD

(b) œÉ

(c) smaller half of œÉ

(d) sensitivity analysis

Figure 3: Analysis of TSVD  singular values and hyperparameter sensitivity: (a) Error rate of TSVD
with different r; (b) All singular values of feature matrices in four conÔ¨Ågurations for Stanford Dogs 
which have random sampling rates 15%  30%  50% and 100% respectively  either with (w/) BSS and
without (w/o) BSS; (c) Smaller half of singular values in (b); (d) Sensitivity analysis of different k.

Table 3: BSS Embedded into EWC for Incremental Learning

Method (incremental learning)

Ô¨Åne-tuning + EWC [14]

Ô¨Åne-tuning + EWC [14] + BSS

task A
96.60
96.46

task B
97.42
98.04

Avg
97.01
97.25

Table 4: BSS Embedded into BERT for Nature Language Processing

Method (text classiÔ¨Åcation) MNLI-m

BERTbase [6]

BERTbase [6] + BSS

84.4
85.0

QNLI MRPC
86.7
88.4
89.6
87.9

SST-2
92.7
93.2

Avg
88.0
88.9

Natural Language Processing. Fine-tuning is an important technique to transfer knowledge from
other sources or pre-trained models. Its effectiveness in visual recognition applications is shown
in section 5.2. We further justify its power in natural language processing. The General Language
Understanding Evaluation (GLUE) benchmark [39] is a collection of diverse natural language
understanding tasks. MNLI-m  QNLI  MRPC and SST-2 in GLUE [39] are used to evaluate the effect
of BSS. Considering that BERT [6] is a state-of-the-art NLP pre-trained model  we embed BSS into
BERTbase. We use a batch size of 32 and Ô¨Åne-tune for 3 epochs over the data for these four tasks.
For learning rate  we use the same strategies as [6]. Results on four tasks in the Dev sets are listed in
Table 4. From the Table we Ô¨Ånd that BSS can also help Ô¨Åne-tuning in natural language processing.

6 Conclusion

In this paper  we studied Ô¨Åne-tuning of deep models pre-trained on source tasks to substantially
different target tasks. We delved into this widely-successful inductive transfer learning scenario from
a new perspective: negative transfer. While existing deep methods mainly focus on alleviating the
problem of catastrophic forgetting for reusing pre-trained knowledge  we Ô¨Ånd that not all weight
parameters or feature matrices are transferable and some spectral components in them are detrimental
to the target tasks  especially with limited training data. Based on this observation  Batch Spectral
Shrinkage (BSS)  a regularization approach based on spectral analysis of feature representations 
is proposed to actively inhibit untransferable spectral components. BSS is pluggable into existing
Ô¨Åne-tuning methods and yields signiÔ¨Åcant performance gains. We expect that BSS will shed light
into potential future directions for safe transfer learning towards making inductive transfer never hurt.

Acknowledgments

We thank Dr. Yuchen Zhang at Tsinghua University for helpful discussions. This work was supported
by the National Key R&D Program of China (2017YFC1502003) and Natural Science Foundation of
China (61772299 and 71690231).

9

15%30%50%100%0.130.140.150.160.170.180.190.20Error Rate of Truncated SVDoriginTSVD r=1TSVD r=2TSVD r=4TSVD r=801020304050Index5101520253035Singular ValuesSingular Valuesw/o BSS:15%w/o BSS:30%w/o BSS:50%w/o BSS:100%BSS:15%BSS:30%BSS:50%BSS:100%253035404550Index46810121416Singular ValuesSingular Valuesw/o BSS:15%w/o BSS:30%w/o BSS:50%w/o BSS:100%BSS:15%BSS:30%BSS:50%BSS:100%15%30%50%100%0.120.130.140.150.160.170.180.19Error Rate (sensitivity analysis)k=1k=2k=4k=8References

[1] M. Aygun  Y. Aytar  and H. Kemal Ekenel. Exploiting convolution Ô¨Ålter patterns for transfer

learning. In International Conference on Computer Vision (ICCV)  pages 2674‚Äì2680  2017.

[2] R. Caruana. Multitask learning. Machine learning  28(1):41‚Äì75  1997.
[3] X. Chen  S. Wang  M. Long  and J. Wang. Transferability vs. discriminability: Batch spectral
In International Conference on Machine

penalization for adversarial domain adaptation.
Learning (ICML)  pages 1081‚Äì1090  2019.

[4] Y. Cui  Y. Song  C. Sun  A. Howard  and S. Belongie. Large scale Ô¨Åne-grained categorization
and domain-speciÔ¨Åc transfer learning. In IEEE conference on computer vision and pattern
recognition (CVPR)  pages 4109‚Äì4118  2018.

[5] J. Deng  W. Dong  R. Socher  L.-J. Li  K. Li  and L. Fei-Fei. Imagenet: A large-scale hierarchical
image database. In IEEE conference on computer vision and pattern recognition (CVPR)  pages
248‚Äì255. Ieee  2009.

[6] J. Devlin  M.-W. Chang  K. Lee  and K. Toutanova. Bert: Pre-training of deep bidirectional
transformers for language understanding. In Annual Conference of the North American Chapter
of the Association for Computational Linguistics (NAACL)  2019.

[7] J. Donahue  Y. Jia  O. Vinyals  J. Hoffman  N. Zhang  E. Tzeng  and T. Darrell. Decaf: A deep
convolutional activation feature for generic visual recognition. In International conference on
machine learning (ICML)  pages 647‚Äì655  2014.

[8] W. Ge and Y. Yu. Borrowing treasures from the wealthy: Deep transfer learning through
selective joint Ô¨Åne-tuning. In IEEE conference on computer vision and pattern recognition
(CVPR)  pages 1086‚Äì1095  2017.

[9] K. He  R. Girshick  and P. Doll√°r. Rethinking imagenet pre-training. International Conference

on Computer Vision (ICCV)  2019.

[10] K. He  X. Zhang  S. Ren  and J. Sun. Deep residual learning for image recognition. In IEEE

conference on computer vision and pattern recognition (CVPR)  pages 770‚Äì778  2016.

[11] G. Hinton  O. Vinyals  and J. Dean. Distilling the knowledge in a neural network. arXiv preprint

arXiv:1503.02531  2015.

[12] M. Huh  P. Agrawal  and A. A. Efros. What makes imagenet good for transfer learning? arXiv

preprint arXiv:1608.08614  2016.

[13] A. Khosla  N. Jayadevaprakash  B. Yao  and L. Fei-Fei. Novel dataset for Ô¨Åne-grained image
categorization. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 
Colorado Springs  CO  June 2011.

[14] J. Kirkpatrick  R. Pascanu  N. Rabinowitz  J. Veness  G. Desjardins  A. A. Rusu  K. Milan 
J. Quan  T. Ramalho  A. Grabska-Barwinska  et al. Overcoming catastrophic forgetting in neural
networks. Proceedings of the national academy of sciences (PNAS)  114(13):3521‚Äì3526  2017.
IEEE

[15] S. Kornblith  J. Shlens  and Q. V. Le. Do better imagenet models transfer better?

Conference on Computer Vision and Pattern Recognition (CVPR)  2019.

[16] J. Krause  M. Stark  J. Deng  and L. Fei-Fei. 3d object representations for Ô¨Åne-grained
categorization. In 4th International IEEE Workshop on 3D Representation and Recognition
(3dRR-13)  Sydney  Australia  2013.

[17] A. Krizhevsky  I. Sutskever  and G. E. Hinton. Imagenet classiÔ¨Åcation with deep convolutional
neural networks. In Advances in neural information processing systems (NeurIPS)  pages
1097‚Äì1105  2012.

[18] S.-W. Lee  J.-H. Kim  J. Jun  J.-W. Ha  and B.-T. Zhang. Overcoming catastrophic forgetting
In Advances in neural information processing systems

by incremental moment matching.
(NeurIPS)  pages 4652‚Äì4662  2017.

[19] X. Li  H. Xiong  H. Wang  Y. Rao  L. Liu  and J. Huan. Delta: Deep learning transfer using
feature map with attention for convolutional networks. In International Conference on Learning
Representations (ICLR)  2019.

[20] X. Li  G. Yves  and D. Franck. Explicit inductive bias for transfer learning with convolutional
networks. In International Conference on Machine Learning (ICML)  pages 2830‚Äì2839  2018.
[21] Z. Li and D. Hoiem. Learning without forgetting. IEEE transactions on pattern analysis and

machine intelligence (TPAMI)  40(12):2935‚Äì2947  2018.

[22] J. Liu  Y. Wang  and Y. Qiao. Sparse deep transfer learning for convolutional neural network.

In AAAI Conference on ArtiÔ¨Åcial Intelligence (AAAI)  2017.

10

[23] S. Maji  E. Rahtu  J. Kannala  M. Blaschko  and A. Vedaldi. Fine-grained visual classiÔ¨Åcation

[24] J. Miao and A. Ben-Israel. On principal angles between subspaces in rn. Linear algebra and its

of aircraft. Technical report  2013.

applications  171:81‚Äì98  1992.

[25] M. Oquab  L. Bottou  I. Laptev  and J. Sivic. Learning and transferring mid-level image
representations using convolutional neural networks. In IEEE conference on computer vision
and pattern recognition (CVPR)  pages 1717‚Äì1724  2014.

[26] S. J. Pan and Q. Yang. A survey on transfer learning. IEEE Transactions on knowledge and

data engineering (TKDE)  22(10):1345‚Äì1359  2009.

[27] O. M. Parkhi  A. Vedaldi  A. Zisserman  and C. Jawahar. Cats and dogs. In IEEE conference on

computer vision and pattern recognition (CVPR)  pages 3498‚Äì3505. IEEE  2012.

[28] A. Quattoni and A. Torralba. Recognizing indoor scenes. In IEEE Conference on Computer

Vision and Pattern Recognition (CVPR)  pages 413‚Äì420. IEEE  2009.

[29] A. Romero  N. Ballas  S. E. Kahou  A. Chassang  C. Gatta  and Y. Bengio. Fitnets: Hints for

thin deep nets. arXiv preprint arXiv:1412.6550  2014.

[30] A. A. Rusu  N. C. Rabinowitz  G. Desjardins  H. Soyer  J. Kirkpatrick  K. Kavukcuoglu 
R. Pascanu  and R. Hadsell. Progressive neural networks. arXiv preprint arXiv:1606.04671 
2016.

[31] K. Saenko  B. Kulis  M. Fritz  and T. Darrell. Adapting visual category models to new domains.

In European conference on computer vision (ECCV)  pages 213‚Äì226. Springer  2010.

[32] J. Serra  D. Suris  M. Miron  and A. Karatzoglou. Overcoming catastrophic forgetting with
hard attention to the task. In International Conference on Machine Learning (ICML)  pages
4555‚Äì4564  2018.

[33] K. Simonyan and A. Zisserman. Very deep convolutional networks for large-scale image

recognition. In International Conference on Learning Representations (ICLR)  2015.

[34] B. Sun and K. Saenko. Deep coral: Correlation alignment for deep domain adaptation. In

European Conference on Computer Vision (ECCV)  pages 443‚Äì450. Springer  2016.

[35] C. Szegedy  V. Vanhoucke  S. Ioffe  J. Shlens  and Z. Wojna. Rethinking the inception archi-
tecture for computer vision. In IEEE conference on computer vision and pattern recognition
(CVPR)  pages 2818‚Äì2826  2016.

[36] S. Thrun. A lifelong learning perspective for mobile robot control. In International Conference

on Intelligent Robots and Systems (IROS)  pages 201‚Äì214. Elsevier  1995.

[37] L. Torrey and J. Shavlik. Transfer learning. In Handbook of research on machine learning
applications and trends: algorithms  methods  and techniques  pages 242‚Äì264. IGI Global 
2010.

[38] E. Tzeng  J. Hoffman  K. Saenko  and T. Darrell. Adversarial discriminative domain adaptation.
In IEEE Conference on Computer Vision and Pattern Recognition (CVPR)  pages 7167‚Äì7176 
2017.

[39] A. Wang  A. Singh  J. Michael  F. Hill  O. Levy  and S. R. Bowman. Glue: A multi-task
benchmark and analysis platform for natural language understanding. Conference on Empirical
Methods in Natural Language Processing (EMNLP)  page 353  2018.

[40] X. Wang  L. Li  W. Ye  M. Long  and J. Wang. Transferable attention for domain adaptation. In

AAAI Conference on ArtiÔ¨Åcial Intelligence (AAAI)  2019.

[41] Z. Wang  Z. Dai  B. P√≥czos  and J. Carbonell. Characterizing and avoiding negative transfer.

IEEE conference on computer vision and pattern recognition (CVPR)  2019.

[42] P. Welinder  S. Branson  T. Mita  C. Wah  F. Schroff  S. Belongie  and P. Perona. Caltech-UCSD

Birds 200. Technical Report CNS-TR-2010-001  California Institute of Technology  2010.

[43] J. Yim  D. Joo  J. Bae  and J. Kim. A gift from knowledge distillation: Fast optimization 
network minimization and transfer learning. In IEEE Conference on Computer Vision and
Pattern Recognition (CVPR)  pages 4133‚Äì4141  2017.

[44] J. Yoon  E. Yang  J. Lee  and S. J. Hwang. Lifelong learning with dynamically expandable

networks. In International Conference on Learning Representations (ICLR)  2018.

[45] J. Yosinski  J. Clune  Y. Bengio  and H. Lipson. How transferable are features in deep neural

networks? In Advances in Neural Information Processing Systems (NeurIPS)  2014.

[46] S. Zagoruyko and N. Komodakis. Paying more attention to attention: Improving the performance
of convolutional neural networks via attention transfer. International Conference on Learning
Representations (ICLR)  2017.

11

,Xinyang Chen
Sinan Wang
Bo Fu
Mingsheng Long
Jianmin Wang