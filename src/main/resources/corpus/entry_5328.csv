2018,Submodular Field Grammars: Representation  Inference  and Application to Image Parsing,Natural scenes contain many layers of part-subpart structure  and distributions over them are thus naturally represented by stochastic image grammars  with one production per decomposition of a part. Unfortunately  in contrast to language grammars  where the number of possible split points for a production $A \rightarrow BC$ is linear in the length of $A$  in an image there are an exponential number of ways to split a region into subregions. This makes parsing intractable and requires image grammars to be severely restricted in practice  for example by allowing only rectangular regions. In this paper  we address this problem by associating with each production a submodular Markov random field whose labels are the subparts and whose labeling segments the current object into these subparts. We call the result a submodular field grammar (SFG). Finding the MAP split of a region into subregions is now tractable  and by exploiting this we develop an efficient approximate algorithm for MAP parsing of images with SFGs. Empirically  we present promising improvements in accuracy when using SFGs for scene understanding  and show exponential improvements in inference time compared to traditional methods  while returning comparable minima.,Submodular Field Grammars: Representation 
Inference  and Application to Image Parsing

Abram L. Friesen and Pedro Domingos

Paul G. Allen School of Computer Science and Engineering

University of Washington

Seattle  WA 98195

{afriesen pedrod}@cs.washington.edu

Abstract

Natural scenes contain many layers of part-subpart structure  and distributions
over them are thus naturally represented by stochastic image grammars  with one
production per decomposition of a part. Unfortunately  in contrast to language
grammars  where the number of possible split points for a production A → BC
is linear in the length of A  in an image there are an exponential number of ways
to split a region into subregions. This makes parsing intractable and requires
image grammars to be severely restricted in practice  for example by allowing
only rectangular regions. In this paper  we address this problem by associating
with each production a submodular Markov random ﬁeld whose labels are the
subparts and whose labeling segments the current object into these subparts. We
call the resulting model a submodular ﬁeld grammar (SFG). Finding the MAP
split of a region into subregions is now tractable  and by exploiting this we de-
velop an efﬁcient approximate algorithm for MAP parsing of images with SFGs.
Empirically  we show promising improvements in accuracy when using SFGs for
scene understanding  and demonstrate exponential improvements in inference time
compared to traditional methods  while returning comparable minima.

Introduction

1
Understanding natural scenes is a challenging problem that requires simultaneously detecting  seg-
menting  and recognizing each object in a scene despite noise  distractors  and ambiguity. Fortunately 
natural scenes possess inherent structure in the form of contextual and part-subpart relationships
between objects. Such relationships are well modeled by a grammar  which deﬁnes a set of production
rules that specify the decomposition of objects into their parts. Natural language is the most common
application of such grammars  but the compositional structure of natural scenes makes stochastic
image grammars a natural candidate for representing distributions over images (see Zhu and Mumford
[1] for a review). Importantly  natural language can be parsed efﬁciently with respect to a grammar
because the number of possible split points for each production A → BC is linear in the length of
the constituent corresponding to A. However  images cannot be parsed efﬁciently in this way because
there are an exponential number of ways to split an image into arbitrarily-shaped subregions. As
such  previous image-grammar approaches could only ensure tractability by severely limiting the
possible decompositions of each region either explicitly  for example by allowing only rectangular
regions  or by sampling (e.g.  Poon and Domingos [2]  Zhao and Zhu [3]).
Due to these limitations  many approaches to scene understanding instead use a Markov random
ﬁeld (MRF) to deﬁne a probabilistic model over pixel labels (e.g.  Shotton et al. [4]  Gould et al.
[5])  thereby capturing some natural structure while still permitting objects to have arbitrary shapes.
Most such MRFs use planar- or tree-structured graphs in the label space [6  7]. While these models
can improve labeling accuracy  their restricted structures mean that they can capture little of the
compositional structure present in natural images without an exponential number of labels. Inference
in MRFs is intractable in general [8] but is tractable under certain restrictions. For pairwise binary
MRFs  if the energy is submodular [9]  meaning that each pair of neighboring pixels prefers to have
32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

the same label – a natural assumption for images – then the exact MAP labeling of the MRF can be
efﬁciently recovered with a graph-cut algorithm [10–12]. For multi-label problems  a constant-factor
approximation can be found efﬁciently using a move-making algorithm  such as α-expansion [13].
In this work  we deﬁne a powerful new class of tractable models that combines the tractability and
region-shape ﬂexibility afforded by submodular MRFs with the high-level compositional structure of
an image grammar. We associate with each production A → BC a submodular MRF whose labels
are the subconstituents (i.e.  B  C) of that production. We call the resulting model a submodular ﬁeld
grammar (SFG). Finding the MAP labeling to split a region into arbitrarily-shaped subregions is
now tractable and we exploit this to develop an efﬁcient approximate algorithm for MAP parsing of
images with SFGs. Our algorithm  SFG-PARSE  is an iterative move-making algorithm that provably
converges to a local minimum of the energy and reduces to α-expansion for trivial grammars. Like
other move-making algorithms  each step of SFG-PARSE chooses the best move from an exponentially
large set of neighbors  thus overcoming many of the main issues with local minima [13]. Empirically 
we compare SFG-PARSE to belief propagation and α-expansion. We show that SFG-PARSE parses
images in exponentially less time than both of these while returning comparable minima. Using deep
convolutional neural network features as inputs  we investigate the modeling capability of SFGs.
We show promising improvements in semantic segmentation accuracy when using SFGs in place of
standard MRFs and when compared to the neural network features on their own.
Like SFGs  associative hierarchical MRFs [14  15] also deﬁne multi-level MRFs  but use precomputed
segmentations to set the regions of the non-terminal variables and thus do not permit arbitrary image
regions. Neural parsing methods [16  17] are grammar-like models for scene understanding  but use
precomputed superpixels and thus also do not permit arbitrary region shapes. Most relevant is the work
of Kumar and Koller [6] and Delong et al. [7]  who deﬁne tree-structured submodular cost functions
and use iterative fusion-style graph-cut algorithms for inference  much like SFG-PARSE. SFGs
can be seen as an extension of these works that interprets the labelings at each level as productions
in a grammar and permits multiple different productions of each symbol  thus deﬁning a directed-
acyclic-graph (DAG) cost function. This allows SFGs to be exponentially more expressive than these
models with only a low-order polynomial increase in inference complexity. In the simple case of a
tree-structured grammar (i.e.  a non-recursive grammar in which each symbol only appears in the body
of at most one production)  SFGs and SFG-PARSE reduce to these existing approaches albeit without
the label costs of Delong et al. [7]; however  it should be possible to extend SFGs in a similar manner.
In order to clearly describe and motivate SFGs  we present them here in the context of image parsing.
However  SFGs are a general and ﬂexible model class that is applicable anywhere grammars or MRFs
are used  including social network modeling and probabilistic knowledge bases.
2 Preliminaries
2.1 Submodular MRFs
A Markov random ﬁeld (MRF)
p(y I) = 1

for scene understanding deﬁnes a probabilistic model
Z exp(−E(y I)) over labeling y ∈ Y n and image I  where n = |I| is the number of pix-
y(cid:48)∈Y n exp(−E(y(cid:48) I)) is the partition function  and Y is the set of labels  which encode
semantic classes such as Sky or Ground. MRFs for computer vision typically use pairwise energies
(p q)∈I θpq(yp  yq)  where y = (y0  . . .   yn) is a vector of labels;
op is the intensity value of pixel p; θp and θpq are the unary and pairwise energy terms for pixels p and
edges (p  q)  respectively; and  with a slight abuse of notation  we say that I contains both the nodes
and edges in the MRF over the image. For binary labels Y = {Y1  Y2}  an MRF is submodular if its
energy satisﬁes θpq(Y1  Y1)+θpq(Y2  Y2) ≤ θpq(Y1  Y2)+θpq(Y2  Y1) for all edges (p  q) ∈ I. If the
energy is submodular  the MAP labeling y∗ = arg maxy∈Y n p(y I) can be computed exactly with
a single graph cut in time c(n)  where c(n) is worst-case low-order polynomial (the true complexity
depends on the chosen min-cut/max-ﬂow algorithm)  but nearly linear time in practice [12  13]. Thus 
submodularity reduces the complexity of an optimization over 2n states to nearly-linear time. While
submodularity is useful for MAP inference  it also captures the fact that neighboring pixels in natural
images tend to have the same label (e.g.  Sky pixels appear next to other Sky pixels)  which means
that the MAP labeling in general partitions the image into contiguous regions of each label.
2.2
A context-free grammar (CFG) is a tuple G = (N  Σ  R  S) containing a ﬁnite set of nonterminal
symbols N; a ﬁnite set of terminal symbols Σ; a ﬁnite set of productions R = {v : X → Y1 . . . Yk}

Image grammars

els  Z =(cid:80)
E(y I) =(cid:80)

p∈I θp(yp  op) +(cid:80)

2

p(t I) =(cid:81)

p = Yi} for any i ∈ {1  . . .   k}.

with head symbol X ∈ N and subconstituent symbols Yi ∈ N ∪ Σ for i = 1 . . . k; and a special
start symbol S ∈ N that does not appear on the right-hand side of any production. For scene
understanding  a grammar for outdoor scenes might contain a production S → Sky Ground  which
would partition the image into Sky and Ground subregions.
To extend CFGs to images  we introduce the notion of a region R ⊆ I  which speciﬁes a subset
of the pixels and can have arbitrary shape. A parse (tree) t ∈ TG(I) of image I with respect to
grammar G is a tree of nodes n = (v R)  each containing a production v ∈ R and a corresponding
image region R ⊆ I  where TG(I) is the set of valid parse trees for I under G  which we will
write as T to simplify notation. For each node n = (v R) in a parse tree  the regions of its children
{ci = (vi Ri) : ci ∈ ch(n)} partition (segment) their parent’s region such that R = ∪iRi and
∩iRi = ∅. If we let v = X → Y1 . . . Yk  then this partition is equivalently deﬁned by a labeling
yv ∈ Y|R|
v where Yv = {Y1  . . .   Yk}  as there is a one-to-one correspondence between labelings and
partitions of R. Given a labeling for a production  the region of a subconstituent is simply the subset
of pixels labeled as that subconstituent Ri = {p : yv
A stochastic image grammar deﬁnes a generative probabilistic model of images by associating with
each nonterminal a categorical distribution over the productions of that nonterminal. The generative
process samples a production of the current nonterminal from this distribution  starting with the
start symbol S with the entire image as its region  and then partitions the current region into disjoint
subregions – one for each subconstituent of the production. This process then recurses on each
subconstituent-subregion pair  and terminates when a terminal symbol is produced  at which point
the pixels for that region are generated. Formally  the probability of a parse t ∈ T of an image is
(v R)∈t p(v|head(v)) · p(yv|v R)  where p(yv|v R) speciﬁes the probability of each
labeling yv ∈ Y|R|
(i.e.  partition) of R. Note that the above distribution over productions is the
same categorical distribution as that used in PCFGs for natural language [18]  but the distribution
over segmentations is assumed to be uniform in PCFGs for natural language and is typically not
made explicit. It is this latter distribution that causes representational challenges  as we must now
specify a distribution p(yv|v R) for each production and for each of the 2n possible image regions.
We show how this can be achieved efﬁciently in the following section.
3 Submodular Field Grammars
As the main contribution of this work  we deﬁne (submodular) ﬁeld grammars by combining the image
grammars deﬁned above with (submodular) MRFs. We do this by deﬁning for each production v an
q ). A copy of
this MRF is instantiated each time an instance (equivalently  a token  as this relates to the well-known
type-token distinction) of X is parsed as v  in the same way that each instance of a symbol in a
grammar uses the same categorical distribution to select productions. In particular  an instance of
a symbol has an associated region R ⊆ I and the MRF instantiated for that instance is simply the
subset of the full-image MRF containing all of the nodes in R and all of the edges between the
q ). We
(p q)∈R θv
thus write the labeling distribution as p(yv|v R) ∝ exp(−Ev(yv R)) and we write the energy of a
(v R)∈t wv + Ev(yv R) 
where the weights {wv} parameterize each symbol’s categorical distribution over productions and
the probability of a parse tree is p(t I) ∝ exp(−E(t I)). To simplify notation  we will omit v I 
and R when clear from context and sum over just v.
We refer to this model as a ﬁeld grammar G = (N  Σ  R  S  Θ) parameterized by Θ  which contains
both the categorical weights and the MRF parameters. As in the image grammar formulation above 
the pixels are generated when a terminal symbol is produced. Conversely  when parsing a given
image  the unary terms {θv
p} can depend directly on the pixels of the image being parsed or on
features of the image  as in a conditional random ﬁeld. In our experiments  however  only the unary
terms of the terminal symbols depend on the pixel values.
The MRFs in a ﬁeld grammar can be parameterized arbitrarily but  in order to permit efﬁcient MAP
inference  we require that each term θv
pq satisfy the previously-stated binary submodularity condition
for all edges (p  q) and all productions v : X → Y1Y2 once the grammar has been converted to one in
which each production has only two subconstituents  which is always possible and in the worst case
increases the grammar size quadratically [18]. Note that it is easy to extend this to the non-binary case
by requiring that the pairwise terms satisfy the α-expansion or αβ-swap conditions [13]  for example 

p) +(cid:80)
nodes in R. The energy of this instance is Ev(yv R) =(cid:80)
parse tree (where each node contains production instances) as E(t I) =(cid:80)

associated MRF over the full image Ev(yv I) =(cid:80)

p) +(cid:80)

p∈R θv

p(yv

pq(yv

p  yv

v

p∈I θv

p(yv

(p q)∈I θv

pq(yv

p  yv

3

q ) ≥ θc

p  yv

pq(yc

p  yc

p  yv

p  yv

q   yc

p  yc

pq(yv

p  yv

q)  where yv

ergy E(t R) = (cid:80)
can rewrite this as E(t R) = w(t) +(cid:80)
(cid:80)

pq  where w(t) =(cid:80)
p =(cid:80)

(p q)∈R θt

pq = (cid:80)

but we focus on the binary case here for simplicity. We also require that θv
p  yc
pq(yv
q)
for every production v ∈ R  for every production c that is a descendant of v in the grammar 
q ∈ Yv and yc
q ∈ Yc. This ensures
and for all possible labelings (yv
that segmentations of higher-level productions are submodular relative to their descendants  and
captures a natural property of composition in images: that objects have larger regions than their
parts. This means that the ratio of boundary length to region area is smaller for a symbol relative
to its descendants  and thus its pairwise terms should be stronger. A grammar that satisﬁes these
conditions is a submodular ﬁeld grammar (SFG). Figure 1 shows a partial example of a (submodular)
ﬁeld grammar applied to image parsing  demonstrating the interleaved choices of productions and
labelings  and the subregion decompositions resulting from these choices.
3.1 Relationship to other models
Above  we deﬁned an SFG as an image grammar
with an MRF at each production. An SFG can be
equivalently reformulated as a planar MRF with
one label for each path in the grammar. The num-
ber of such paths is exponential in the height of
the grammar. This reformulation can be seen as
follows. A parse tree over a region R has en-
v∈t wv + Ev(yv Rv). We
p∈R θt
p +
v∈t wv  1[·] is the
p)·1[p ∈ Rv] 
indicator function  θt
p(yv
v∈t θv
q ) · 1[(p  q) ∈ Rv].
and θt
v∈t θv
This describes a ﬂat MRF in which θt
p and θt
pq
are the unary and pairwise terms. Inference in
this ﬂat MRF is not easier  and is likely harder 
because it requires an exponentially-large set of la-
bels and the hard constraints of the grammar must
be enforced explicitly. However  this formulation
will prove useful for our parsing algorithm.
Another key beneﬁt of our grammar-based formu-
lation is sub-parse reuse  which enables exponen-
tial reductions in inference complexity and better
sample complexity. For example  consider reusing
a Wheel symbol among many vehicle types. In-
stead of having to learn and perform inference for
each Wheel symbol (once per vehicle type and per vehicle-parent type  etc.)  only one Wheel need be
learned and inference on it performed only once.
Beyond PCFGs and MRFs  SFGs also generalize sum-product networks (SPNs) [19  2]. Details on
this mapping are given in the supplement. 1 Figure 1 shows a partial mapping of an SFG to an SPN.
4
When trying to understand natural scenes  it is important to recognize and reason about the relation-
ships between objects. These relationships can be identiﬁed by ﬁnding the MAP parse of an image
with respect to a grammar that encodes them  such as a submodular ﬁeld grammar. The ﬂat semantic
labels traditionally used in scene understanding can also be recovered from this parse if they are
encoded in the grammar  e.g.  as the terminal symbols. We exploit this ability in our experiments.
For natural language  the optimal parse of a PCFG can be recovered exactly in time cubic in the
length of the sentence with the CYK algorithm [20]  which uses dynamic programming to efﬁciently
parse a sentence in a bottom-up pass through the grammar. This is possible because each sentence
only has a linear number of split points  meaning that all sub-spans of the sentence can be efﬁciently
represented and enumerated. The key operation in the CYK algorithm is to compute the optimal parse
of a given span s (i.e.  contiguous sub-sentence) as a given production v : X → Y Z by explicitly
iterating over all split points i of that span  computing the probability of parsing s as v with split i 

Figure 1: A DAG representing some of the possible
production and labeling choices when parsing an im-
age with an SFG. Each sum node represents either a
choice of production for a particular region or a choice
of labeling for the MRF representing a particular pro-
duction of a region. Product nodes denote the partition
of a region as deﬁned by its labeling  where an MRF
node’s color denotes its label. Red edges denote a
partial parse tree for the image shown at the bottom.
Best viewed in color.

Inference

1Supplementary material is available at https://homes.cs.washington.edu/~pedrod/papers/neurips18sp.pdf.

4

+×++×××…××××…S➞ABS➞BC++…+++++…++…B➞GHB➞JK……++A➞DEA➞FG…××…××……+++++++…………C➞LM+…(a)

(b)

E(y R) =(cid:80)

p θp(yp) +(cid:80)

n) iff each label in yc is taken either from y0 or y1 such that yc

n) is a combination of y0 = (y0
p ∈ {y0

Figure 2: The main components of SFG-PARSE: (a) Parsing a region R as X → Y Z by fusing a parse of R
as Y → AB with a parse of R as Z → CD  and (b) Subsequently improving the parse of R as X → Y Z by
independently (re)parsing each of its subregions and then fusing these new parses. See text for more detail.
and choosing the split point with highest probability. The probability of parsing s as v with split i
is deﬁned recursively as the product of p(v|head(v)) and the respective probabilities of the optimal
parses of the two sub-spans as Y and Z  respectively. CYK uses dynamic programming to cache the
optimal parse of each sub-span as each symbol to avoid re-computing these unnecessarily.
Unfortunately  CYK applied to images is intractable because it is infeasible to enumerate all subre-
gions of an image. Instead  we propose to construct (and cache) a parse of the entire image as each
production and then use subregions of this parse to deﬁne the parse of each subregion  mirroring how
distributions over subregions are deﬁned in SFGs. We then exploit submodularity to ﬁnd a locally
optimal parse from an exponentially large set  without enumerating all such parses. Speciﬁcally  we
optimally combine the parses of the subconstituents of a production to create a parse as that production.
We refer to this procedure as fusion as it is analogous to the fusion moves of Lempitsky et al. [21].
4.1 Parse tree construction
Following Lempitsky et al. [21]  let y0  y1 ∈ Y n be two labelings of a submodular MRF with energy
pq θpq(yp  yq) and let C(y0  y1) = {yc} denote the set of combinations
of y0 and y1. A labeling yc = (yc
n) and y1 =
p} for all pixels
(y1
0  . . .   y1
p = 1 . . . n. The fusion y∗ of y0 and y1 is then deﬁned as the minimum energy combination y∗ =
arg miny∈C(y0 y1) E(y R). Under certain conditions on E  fusion is a submodular minimization.
Recall that each parse tree t equivalently corresponds to a particular labeling of a planar MRF with
one label per path in the grammar. With a slight abuse of notation  we use t to represent both the full
parse tree and the corresponding planar MRF labeling. Let v : X → Y1Y2 be a production and t1  t2
be parses of some region R ⊆ I as productions u1 : Y1 → Z1Z2 and u2 : Y2 → Z3Z4  respectively.
Deﬁnition 1. For production v : X → Y1Y2 and parse trees t1  t2 over region R with head symbols
Y1  Y2  the fusion of t1 and t2 as v is the minimum energy parse tree tv = arg mint∈C(t1 t2) E(t R)
constructed from the combination of t1 and t2  with (v R) appended as root.
Because t1 and t2 are MRF labelings  we can fuse them to create a new parse tree tv in which each
pixel in R is labeled with the same path that it had in either t1 or t2. When we do this  we prepend
v to each pixel’s label  which is equivalent to adding (v R) as the new root node of tv. Figure 2a
shows an example of fusing two parse trees to create a new parse tree.
Proposition 1. The fusion of two parse trees is a submodular minimization.
Although fusion requires ﬁnding the optimal labeling from an exponentially large set  two parse trees
can be fused with a single graph cut by exploiting submodularity. Proofs are given in the supplement.
Finally  we deﬁne the union of two parse trees t = t1 ∪ t2 that have the same productions but are
over disjoint regions (i.e.  R1 ∩ R2 = ∅) as the parse tree t in which the region of each node in t is
the union of the regions of the corresponding nodes in t1 and t2.
4.2 SFG-Parse
Pseudocode for our parsing algorithm  SFG-PARSE  is presented in Algorithm 1. SFG-PARSE is an
iterative move-making algorithm that efﬁciently and provably converges to a local minimum of the
energy function. Currently  SFG-PARSE applies only to non-recursive grammars  but we believe it
will be straightforward to extend it to recursive ones.
To parse an image with respect to a given non-recursive grammar  SFG-PARSE starts at the terminal

0  . . .   y0

p  y1

0  . . .   yc

5

To improve parse of 1. (re)parse as Y 2. (re)parse as Y given 3. (re)parse as Z 4. (re)parse as Z given 5. fuse with ××××YZABCDfuseX➞YZ×ABCDYZ××CDAB××CBYZZYYYZZEFHGEFGHABCD- confusing part: not clear that X->Y->AB in subregion of LHS ﬁgure is just sub-selecting from existing parse of Y->AB over entire region - need to explain clearly what’s happening…DATo improve parse of 1. (re)parse as Y 2. (re)parse as Y given 3. (re)parse as Z 4. (re)parse as Z given 5. fuse with ××××YZABCDfuseX➞YZ×ABCDYZ××CDAB××CBYZZYYYZZEFHGEFGHABCD- confusing part: not clear that X->Y->AB in subregion of LHS ﬁgure is just sub-selecting from existing parse of Y->AB over entire region - need to explain clearly what’s happening…DAFigure 3: One iteration of SFG-PARSE applied to the image shown on the right with respect to the simple
grammar on the left. Proceeding from bottom to top  SFG-PARSE ﬁrst parses the image as each of the terminal
symbols (i.e.  each pixel in the image is labeled as that terminal symbol)  and then fuses these to create parses of
the image as symbols B  C  and D. These parses are then fused in turn to create parses of the image as A and
ﬁnally S. The ﬁnal full parse tree returned is the parse of S.

symbols and moves backwards through the productions towards the start symbol (line 9)  constructing
and caching a parse of the full image as each production. The parse for each production is constructed
by fusing the cached parses of that production’s subconstituents (lines 13 and 14). An example of this
procedure is shown in Figure 3  where the parses of symbols S  A  B  C  and D are constructed by
fusing the parses of the subconstituents of their respective productions. For simplicity  the grammar
in Figure 3 only contains a single production for each symbol  and no symbol is a subconstituent
of multiple productions; in general  however  most symbols in the grammar appear on both the
left- and right-hand sides of multiple productions. To accommodate this  SFG-PARSE maintains
multiple instances (aka. tokens) of each symbol and chooses the appropriate production and instance
during parsing. This is discussed in more detail below. Subsequent iterations of SFG-PARSE simply
repeat this bottom-up procedure while ensuring that for each (re)parse of a production  the previous
iteration’s parse of that production (or a guaranteed lower energy alternative) can be constructed via
fusion. This guarantees convergence of SFG-PARSE.
In CYK  each span of a sentence is explicitly parsed as each production  making it straightforward to
have multiple instances of a symbol. However  since there are an exponential number of subregions
of an image  SFG-PARSE instead constructs a parse of the entire image for each production and
reuses that parse for each of these subregions. To ensure consistency of this parse  if only one parse
were allowed per production then each instance would have to be parsed with the exact same set of
productions  a severe restriction on the expressivity of the model. To avoid this  SFG-PARSE permits
multiple instances of a symbol X  one per unique path from the root to a production of X in ˆt  where
ˆt is the best parse of S from the previous iteration. This allows the number of instances of each
symbol to grow or shrink at each iteration according to the parse constructed in the previous iteration.
Processing of instances and their corresponding regions occurs on lines 5-6. For each instance x of
symbol X in ˆt for a production v : X → Y Z  SFG-PARSE records pointers to x’s child instances y
and z  which are later (line 12) used to determine which instances of Y and Z to fuse when parsing v.
In the common scenario that a symbol has no instances – either because it doesn’t appear in ˆt or
because ˆt was not provided – then that symbol is assigned the region containing the entire image as
an instance (line 7)  which serves as a powerful initialization method. If a symbol has no instances 
then it did not appear in ˆt and its parse can be constructed by fusing any instances of its production’s
subconstituents without affecting convergence. In the rare case that a symbol has multiple instances 
one can be chosen either by estimating a bound on the energy or even randomly (line 12).

6

for each region RX in region list R[X] do

// each region is an instance (token) of X
RY  RZ ← the child regions of v for RX if they exist  else choose heuristically
tv  ev ← fuse tRY and tRZ as production v over region RX
tv  ev ← fuse tRY and tRZ as production v over region RX = I\RX given tv
tRX   eRX ← the full parse tv ∪ tv with lowest energy ev // choose best parse of RX
// S only ever has a single region  which contains all of the pixels

ˆt  ˆe ← tRS   eRS

for each terminal T ∈ Σ do tRT ← the trivial parse with all pixels parsed as T
while the energy of any production of the start symbol S has not converged do

// record the instances (i.e.  regions) of each symbol in ˆt and initialize instance-less symbols
for each node in ˆt with production u : X → Y Z  region RX  and subregions RY  RZ do
append RY  RZ to region lists R[Y ] R[Z] and set as the child regions of u for RX
for each symbol X ∈ N with no regions in R[X] do append RX = I to R[X]
// perform the upward pass to parse with the SFG at this iteration
for each symbol X ∈ N  in reverse topological order do
for each production v : X → Y Z of symbol X do

Algorithm 1 Compute the (approximate) MAP parse of an image with respect to an SFG.
Input: The image I  a non-recursive SFG G = (N  Σ  R  S  Θ)  and an (optional) input parse ˆt.
Output: A parse of the image  t∗  with energy E(t∗ I) ≤ E(ˆt I).
1: function SFG-PARSE(I  G  ˆt)
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
If a symbol X does have an instance in ˆt  SFG-PARSE ﬁrst parses only that instance’s region RX
into tree tv (line 13) and then parses the remainder of the image RX as v given the partial parse tv
(line 14). The union of these gives a full parse of the entire image as v for this instance. Parsing an
instance in two parts is necessary to ensure that SFG-PARSE never returns a worse parse. Figure 2b
shows an inefﬁcient version of the process for re-parsing an instance of X  where ﬁrst the subregions
labeled as Y and Z are re-parsed (steps 1-2)  then the remaining pixels are re-parsed given the other
parses (steps 3-4)  and ﬁnally the unions of these parses are fused to get a parse of the region as X
(step 5). For efﬁciency reasons  SFG-PARSE does not actually reparse Y and Z for each production
that produces them; instead  their parses are cached and re-used. We deﬁne parsing a region RX given
a parse tv of another region RX to mean that each pairwise term with a pixel in each region already
has the label of the pixel in RX set to its value in tv (i.e.  like conditioning in a probabilistic model).
Finally  the parse of the production u with the lowest energy over RX is then chosen as its parse
(line 15). At the end of the upward pass  the parse of the full image ˆt is simply the parse of the start
symbol’s region  which always contains all pixels (line 16).
4.3 Analysis
In this section  we analyze the convergence and computational complexity of SFG-PARSE.
Theorem 1. Given a parse ˆt of S over the entire image with energy E(ˆt)  each iteration of SFG-
PARSE constructs a parse t of S over the entire image with energy E(t) ≤ E(ˆt) and  since the
minimum energy of an image parse is ﬁnite  SFG-PARSE will always converge.

return ˆt  ˆe

Theorem 1 shows that SFG-PARSE always converges to a local minimum of the energy function.
Like other move-making algorithms  SFG-PARSE explores an exponentially large set of moves at
each step  so the returned local minimum is generally much better than those returned by more local
procedures [13]. Further  we typically observe convergence in fewer than ten iterations  with the
majority of the energy improvement occurring in the ﬁrst iteration.
Proposition 2. Let c(n) be the time complexity of computing a graph cut on n pixels and |G| be the
size of the grammar deﬁning the SFG. Then each iteration of SFG-PARSE takes time O(|G|c(n)n).
Proposition 2 shows that each iteration of SFG-PARSE has complexity O(|G|c(n)n)  where n is the
number of pixels and c(n) is the complexity of the graph-cut algorithm  which is low-order polynomial
in n in the worst case  but nearly linear-time in practice [12  13]. The additional factor of n is due to
the number of regions (i.e.  instances) of each symbol  which in the worst case is O(n) but in practice
is almost always a small constant (often one). Thus  SFG-PARSE typically runs in time O(|G|c(n)).
Note that directly applying α-expansion to parsing an SFG requires optimizing an MRF with one

7

Inference evaluation

label for each path in the grammar  which would take time exponential in the height of the grammar.
SFG-PARSE can be extended to productions with more than two subconstituents by replacing the
internal graph cut used to fuse subtrees with a multi-label algorithm such as α-expansion. SFG-
PARSE would still converge because each subtree would still never increase in energy. Alternatively 
an algorithm such as QPBO [22] could be used  which would obviate the submodularity requirement.
5 Experiments
We evaluated our model and inference algorithm in two experiments  both using unary features from
DeepLab [23  24]  a state-of-the-art convolutional semantic segmentation network. First  to evaluate
the performance of SFG-PARSE  we programmatically generated SFGs and compared the runtime
of and minimum energy returned by SFG-PARSE to that of α-expansion and max-product belief
propagation (BP)  two standard MRF inference algorithms. Second  to evaluate SFGs as a model of
natural scenes  we segmented images at multiple levels of granularity  used these segmentations to
generate SFGs over the DeepLab features (in place of the raw pixel intensities)  and compared the
segmentation accuracy resulting from parsing the generated SFGs using SFG-PARSE to that of using
(a) DeepLab features alone and (b) a planar submodular MRF on the DeepLab features.
The DeepLab features are trained on the Stanford Background Dataset (SBD) [5] training set. Evalua-
tions are performed on images from the SBD test set. In all MRFs (planar and in each SFG)  the pair-
wise terms are standard contrast-dependent boundary terms [25] multiplied by a single weight  wBF.
5.1
To evaluate the performance of SFG-PARSE  we programmatically generated SFGs while varying
their height  number of productions per nonterminal (#prods)  and strength of the pairwise (boundary)
terms. Each algorithm was evaluated using the same grammars  DeepLab features  and randomly
selected images. We compared the performance of SFG-PARSE to that of running α-expansion on a
ﬂat pairwise MRF containing one label for each possible parse path in the grammar and also to running
BP on a multi-level (3-D) pairwise MRF with the same height as the grammar. These are the natural
comparisons  as existing hierarchical MRF algorithms do not support the DAG structure that makes
SFGs so powerful. Details of these models and additional ﬁgures are provided in the supplement.
Increasing boundary strength  grammar height  and #prods each make inference more challenging.
Individual pixels cannot be ﬂipped easily with stronger boundary terms  while grammar height and
#prods both determine the number of paths in the grammar. Figure 4a plots the average minimum
energy of the parses found by each algorithm versus the boundary factor  wBF (x-axis is log scale) and
Figure 4d plots inference time versus boundary factor. As shown  SFG-PARSE returns comparable
or better parses to both BP and α-expansion and in less time. In Figure 4e  we set wBF to 20 and
plot inference time versus grammar height. The energies are shown in Figure 4b. As expected 
inference time for SFG-PARSE scales linearly with height  whereas it scales exponentially for both
α-expansion and BP. Again  the energies and accuracies of the parses returned by SFG-PARSE
are nearly identical to those of α-expansion. Finally  we set wBF to 20 and plot inference time
versus #prods in Figure 4f  and energy versus #prods in Figure 4c. Once again  SFG-PARSE returns
equivalent parses to α-expansion and BP but in much less time.
5.2 Model evaluation
To evaluate whether natural scenes exhibit the compositional part-subpart structure over arbitrarily-
shaped regions that SFGs can capture but previous methods cannot  we generated grammars on SBD
images where the semantic labels were the terminals. We then computed the mean pixel accuracy of
the terminal labeling from the parse tree returned by SFG-PARSE.
Grammars were generated (not learned) as follows. We ﬁrst over-segmented each of the 143 test
images at 4 different levels of granularity and intersected the most ﬁne-grained of these with the label
regions. We created a unique grammar for each image by taking that image’s over-segmentations
and the over-segmentations of four other randomly chosen images and adding a symbol for each
contiguous region in each segmentation. We then added productions between overlapping segments
for each subsequent pair of granularity levels within each image and across images. Finally  we added
terminal productions from the symbols in the most granular level  where each terminal production
can produce only those labels that occur in its head symbol’s corresponding segment (note that we
similarly restricted the possible labels produced by other models to ensure the comparison was fair).
On average  each induced grammar had 860 symbols and 1250 productions with 5 subconstituents
each. The features output by DeepLab were used as the unaries in the MRFs of the terminal

8

(a)

(d)

(b)

(e)

(c)

(f)

Figure 4: The energy of the returned parse (a b c) and total running time (d e f) when evaluating MAP inference
using belief propagation  α-expansion  and SFG-PARSE while varying (a d) boundary strength  (b e) grammar
height  and (c f) number of productions. In all ﬁgures  lower is better. Each data point is the average over
the same 10 randomly-selected images. Missing data points for BP indicate that it returned an inconsistent
parse with inﬁnite energy. Missing data points for α-expansion indicate that it ran out of time or memory.
Figures S1  S2  and S3 in the supplement show the mean pixel accuracies for each experiment.

87.77

87.93

90.03

DeepLab DeepLab+MRF DeepLab+SFG

Table 1: Mean pixel accuracy on 143 SBD test images.

productions. All productions had uniform probability and the same MRF parameters were used across
all images. This ensured that any improvement in performance was due solely to the structure of the
underlying grammar. Further details about the induced grammars are provided in the supplement.
After parsing each image with respect to its
grammar  we computed the mean pixel accu-
racy of the terminal labeling of the parse. We
compared this to the accuracy of the DeepLab
features alone and to the accuracy of a standard
ﬂat submodular MRF over the DeepLab features 
with pairwise terms set in the same way as in the SFGs. These results are shown in Table 1  which
shows a 20% relative decrease in error for SFGs  which is quite remarkable given how well the
DeepLab features do on their own and how little the ﬂat MRF helps. While this does not constitute a
full evaluation of SFGs for semantic segmentation as we did not learn the SFGs  it provides evidence
that SFGs are a compelling model class. In the supplement  we propose an approach for learning
SFGs but we leave its implementation and evaluation for future work as it requires the creation of new
datasets of parsed images  which is outside the scope of this paper. Even without learning  however 
this experiment demonstrates that natural scenes do exhibit high-level compositional structure and that
SFGs are able to efﬁciently exploit this structure to improve scene understanding and image parsing.
6 Conclusion
This paper proposed submodular ﬁeld grammars (SFGs)  a novel stochastic image grammar formula-
tion that combines the expressivity of image grammars with the efﬁcient combinatorial optimization
capabilities of submodular MRFs. SFGs are the ﬁrst image grammars to enable efﬁcient parsing of
objects with arbitrary region shapes. To achieve this  we presented SFG-PARSE  a move-making
algorithm that exploits submodularity to ﬁnd the (approximate) MAP parse of an SFG. Analytically 
we showed that SFG-PARSE is both convergent and fast. Empirically  we showed (i) that SFG-PARSE
achieves accuracies and energies comparable to α-expansion – which returns optima within a constant
factor of the global optimum – while taking exponentially less time to do so and (ii) that SFGs are
able to represent the compositional structure of images to better parse and understand natural scenes.
In future work  we plan to focus on learning the parameters and structure of SFGs  as we believe
that their unique combination of tractability and expressivity will lead to better understanding of
natural scenes. We also plan to apply SFGs to other domains  such as activity recognition  social
network modeling  and probabilistic knowledge bases.

9

0.10.31 3 10 30 100Boundary scale factor-8.8-8.6-8.4-8.2-8-7.8-7.6Minimum energy105BP-expSFG0123456Grammar height-8-6-4Minimum energy105BP-expSFG123456#productions per nonterminal-8-7-6-5Minimum energy105BP-expSFG0.10.31 3 10 30 100Boundary scale factor2000400060008000Time (s)BP-expSFG0123456Grammar height123Time (s)104BP-expSFG246#productions per nonterminal200040006000800010000Time (s)BP-expSFGAcknowledgements
AF would like to thank Robert Gens  Rahul Kidambi  and Gena Barnabee for useful discussions 
insights  and assistance with this document. The DGX-1 used for this research was donated by
NVIDIA. This research was partly funded by ONR grant N00014-16-1-2697 and AFRL contract
FA8750-13-2-0019. The views and conclusions contained in this document are those of the authors
and should not be interpreted as necessarily representing the ofﬁcial policies  either expressed or
implied  of ONR  AFRL  or the United States Government.
References
[1] Song-Chun Zhu and David Mumford. A stochastic grammar of images. Foundations and Trends in

Computer Graphics and Vision  2(4):259–362  2006.

[2] Hoifung Poon and Pedro Domingos. Sum-product networks: A new deep architecture. In Proceedings of

the 27th Conference on Uncertainty in Artiﬁcial Intelligence  pages 337–346. AUAI Press  2011.

[3] Yibiao Zhao and Song-Chun Zhu. Image parsing via stochastic scene grammar. In Advances in Neural

Information Processing Systems  2011.

[4] Jamie Shotton  John Winn  Carsten Rother  and Antonio Criminisi. TextonBoost for image understand-
ing: Multi-class object recognition and segmentation by jointly modeling texture  layout  and context.
International Journal of Computer Vision  81(1):2–23  2009.

[5] Stephen Gould  Richard Fulton  and Daphne Koller. Decomposing a scene into geometric and semantically

consistent regions. In Proceedings of the IEEE International Conference on Computer Vision  2009.

[6] M. Pawan Kumar and Daphne Koller. MAP estimation of semi-metric MRFs via hierarchical graph cuts.

In Proceedings of the 25th Conference on Uncertainty in Artiﬁcial Intelligence  pages 313–320  2009.

[7] Andrew Delong  Lena Gorelick  Olga Veksler  and Yuri Boykov. Minimizing energies with hierarchical

costs. International Journal of Computer Vision  100(1):38–58  2012.

[8] V. Chandrasekaran  N. Srebro  and P. Harsha. Complexity of inference in graphical models. In Proceedings

of the 24th Conference on Uncertainty in Artiﬁcial Intelligence  pages 70–78  2008.

[9] Vladimir Kolmogorov and Ramin Zabih. What energy functions can be minimized via graph cuts? IEEE

Transactions on Pattern Analysis and Machine Intelligence  26(2):147–159  2004.

[10] P. L. Hammer. Some network ﬂow problems solved with pseudo-Boolean programming. Operations

Research  13:388–399  1965.

[11] D. M. Greig  B.T. Porteous  and A. H. Seheult. Exact maximum a posteriori estimation for binary images.

Journal of the Royal Statistical Society. Series B (Methodological)  51(2):271–279  1989.

[12] Yuri Boykov and Vladimir Kolmogorov. An experimental comparison of min-cut/max-ﬂow algorithms for
energy minimization in vision. IEEE Transactions on Pattern Analysis and Machine Intelligence  26(9):
1124–1137  2004.

[13] Yuri Boykov  Olga Veksler  and Ramin Zabih. Fast approximate energy minimization via graph cuts. IEEE

Transactions on Pattern Analysis and Machine Intelligence  23(11):1222–1239  2001.

[14] Chris Russell  Lubor Ladický  Pushmeet Kohli  and Philip H.S. Torr. Exact and approximate inference
in associative hierarchical networks using graph cuts. The 26th Conference on Uncertainty in Artiﬁcial
Intelligence  2010.

[15] Victor Lempitsky  Andrea Vedaldi  and Andrew Zisserman. A pylon model for semantic segmentation. In

Neural Information Processing Systems  2011.

[16] Richard Socher  Cliff C. Lin  Chris Manning  and Andrew Y. Ng. Parsing natural scenes and natural

10

language with recursive neural networks. In Proceedings of the 28th International Conference on Machine
Learning  pages 129–136  2011.

[17] Abhishek Sharma  Oncel Tuzel  and Ming-Yu Liu. Recursive context propagation network for semantic

scene labeling. In Advances in Neural Information Processing Systems  pages 2447–2455  2014.

[18] Daniel S. Jurafsky and James H. Martin. Speech and Language Processing: An Introduction to Natural

Language Processing  Computational Linguistics  and Speech Recognition. Prentice Hall  2000.

[19] Robert Gens and Pedro Domingos. Learning the structure of sum-product networks. In Proceedings of the

30th International Conference on Machine Learning  pages 873–880. Omnipress  2013.

[20] John Hopcroft and Jeffrey Ullman. Introduction to Automata Theory  Languages  and Computation.

Addison-Wesley  Reading MA  1979.

[21] Victor Lempitsky  Carsten Rother  Stefan Roth  and Andrew Blake. Fusion moves for Markov random ﬁeld
optimization. IEEE Transactions on Pattern Analysis and Machine Intelligence  32(8):1392–1405  2010.

[22] Vladimir Kolmogorov and Carsten Rother. Minimizing nonsubmodular functions with graph cuts - a

review. IEEE transactions on pattern analysis and machine intelligence  29(7):1274–9  2007.

[23] Liang-Chieh Chen  George Papandreou  Iasonas Kokkinos  Kevin Murphy  and Alan L. Yuille. Semantic
In Proceedings of the

image segmentation with deep convolutional nets and fully connected CRFs.
International Conference on Learning Representations  2015.

[24] Liang-Chieh Chen  George Papandreou  Iasonas Kokkinos  Kevin Murphy  and Alan L. Yuille. DeepLab:
Semantic image segmentation with deep convolutional nets  atrous convolution  and fully connected CRFs.
arXiv preprint arXiv:1606.00915 [cs.CV]  2016.

[25] Jamie Shotton  John Winn  Carsten Rother  and Antonio Criminisi. TextonBoost: Joint appearance 
shape and context modeling for multi-class object recognition and segmentation. Proceedings European
Conference on Computer Vision (ECCV)  3951  2006.

11

,Abram Friesen
Pedro Domingos