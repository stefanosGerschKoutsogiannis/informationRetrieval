2015,Particle Gibbs for Infinite Hidden Markov Models,Infinite Hidden Markov Models (iHMM's) are an attractive  nonparametric generalization of the classical Hidden Markov Model which can automatically infer the number of hidden states in the system.  However  due to the infinite-dimensional nature of the transition dynamics  performing inference in the iHMM is difficult. In this paper  we present an infinite-state Particle Gibbs (PG) algorithm to resample state trajectories for the iHMM. The proposed algorithm uses an efficient proposal optimized for iHMMs  and leverages ancestor sampling to improve the mixing of the standard PG algorithm. Our algorithm demonstrates significant convergence improvements on synthetic and real world data sets.,Particle Gibbs for Inﬁnite Hidden Markov Models

Nilesh Tripuraneni*
University of Cambridge
nt357@cam.ac.uk

Shixiang Gu*

University of Cambridge
MPI for Intelligent Systems

sg717@cam.ac.uk

Hong Ge

University of Cambridge
hg344@cam.ac.uk

Zoubin Ghahramani
University of Cambridge

zoubin@eng.cam.ac.uk

Abstract

Inﬁnite Hidden Markov Models (iHMM’s) are an attractive  nonparametric gener-
alization of the classical Hidden Markov Model which can automatically infer the
number of hidden states in the system. However  due to the inﬁnite-dimensional
nature of the transition dynamics  performing inference in the iHMM is difﬁcult.
In this paper  we present an inﬁnite-state Particle Gibbs (PG) algorithm to re-
sample state trajectories for the iHMM. The proposed algorithm uses an efﬁcient
proposal optimized for iHMMs and leverages ancestor sampling to improve the
mixing of the standard PG algorithm. Our algorithm demonstrates signiﬁcant con-
vergence improvements on synthetic and real world data sets.

Introduction

1
Hidden Markov Models (HMM’s) are among the most widely adopted latent-variable models used
to model time-series datasets in the statistics and machine learning communities. They have also
been successfully applied in a variety of domains including genomics  language  and ﬁnance where
sequential data naturally arises [Rabiner  1989; Bishop  2006].
One possible disadvantage of the ﬁnite-state space HMM framework is that one must a-priori spec-
ify the number of latent states K. Standard model selection techniques can be applied to the ﬁ-
nite state-space HMM but bear a high computational overhead since they require the repetitive

training(cid:14)exploration of many HMM’s of different sizes.
over the latent states  transition(cid:14)emission distributions and hyperparameters since it is impossible

Bayesian nonparametric methods offer an attractive alternative to this problem by adapting their
effective model complexity to ﬁt the data. In particular  Beal et al. [2001] constructed an HMM over
a countably inﬁnite state-space using a Hierarchical Dirichlet Process (HDP) prior over the rows
of the transition matrix. Various approaches have been taken to perform full posterior inference

to directly apply the forward-backwards algorithm due to the inﬁnite-dimensional size of the state
space. The original Gibbs sampling approach proposed in Teh et al. [2006] suffered from slow
mixing due to the strong correlations between nearby time steps often present in time-series data
[Scott  2002]. However  Van Gael et al. [2008] introduced a set of auxiliary slice variables to
dynamically “truncate” the state space to be ﬁnite (referred to as beam sampling)  allowing them
to use dynamic programming to jointly resample the latent states thus circumventing the problem.
Despite the power of the beam-sampling scheme  Fox et al. [2008] found that application of the
beam sampler to the (sticky) iHMM resulted in slow mixing relative to an inexact  blocked sampler
due to the introduction of auxiliary slice variables in the sampler.

*equal contribution.

1

The main contributions of this paper are to derive an inﬁnite-state PG algorithm for the iHMM
using the stick-breaking construction for the HDP  and constructing an optimal importance proposal
to efﬁciently resample its latent state trajectories. The proposed algorithm is compared to existing
state-of-the-art inference algorithms for iHMMs  and empirical evidence suggests that the inﬁnite-
state PG algorithm consistently outperforms its alternatives. Furthermore  by construction the time
complexity of the proposed algorithm is O(T N K). Here T denotes the length of the sequence  N
denotes the number of particles in the PG sampler  and K denotes the number of “active” states
in the model. Despite the simplicity of sampler  we ﬁnd in a variety of synthetic and real-world
experiments that these particle methods dramatically improve convergence of the sampler  while
being more scalable.
We will ﬁrst deﬁne the iHMM/sticky iHMM in Section 2  and review the Dirichlet Process (DP) and
Hierarchical Dirichlet Process (HDP) in our appendix. Then we move onto the description of our
MCMC sampling scheme in Section 3. In Section 4 we present our results on a variety of synthetic
and real-world datasets.
2 Model and Notation
2.1
We can formally deﬁne the iHMM (we review the theory of the HDP in our appendix) as follows:

Inﬁnite Hidden Markov Models

β ∼ GEM(γ) 

πj|β iid∼ DP(α  β)  φj
st|st−1 ∼ Cat(·|πst−1 ) 

j = 1  . . .  ∞

iid∼ H 
yt|st ∼ f (·|φst) 

t = 1  . . .   T.

(1)

(2)

connect the HDP with the iHMM  note that given a draw from the HDP Gk = (cid:80)∞

Here β is the shared DP measure deﬁned on integers Z. Here s1:T = (s1  ...  sT ) are the latent
states of the iHMM  y1:T = (y1  ...  yT ) are the observed data  and φj parametrizes the emission
distribution f. Usually H and f are chosen to be conjugate to simplify the inference. βk(cid:48) can be
interpreted as the prior mean for transition probabilities into state k(cid:48)  with α governing the variability
of the prior mean across the rows of the transition matrix. The hyper-parameter γ controls how
concentrated or diffuse the probability mass of β will be over the states of the transition matrix. To
k(cid:48)=1 πkk(cid:48)δφk(cid:48)
we identify πkk(cid:48) with the transition probability from state k to state k(cid:48) where φk(cid:48) parametrize the
emission distributions.
Note that ﬁxing β = ( 1
K   0  0...) implies only transitions between the ﬁrst K states of the
transition matrix are ever possible  leaving us with the ﬁnite Bayesian HMM. If we deﬁne a ﬁnite 
hierarchical Bayesian HMM by drawing

K   ....  1

β ∼ Dir(γ/K  ...  γ/K)
πk ∼ Dir(αβ)

with joint density over the latent/hidden states as
pφ(s1:T   y1:T ) = ΠT

t=1π(st|st−1)fφ(yt|st)

then after taking K → ∞  the hierarchical prior in Equation (2) approaches the HDP.

Figure 1: Graphical Model for the sticky HDP-HMM (setting κ = 0 recovers the HDP-HMM)

2

2.2 Prior and Emission Distribution Speciﬁcation
The hyperparameter α governs the variability of the prior mean across the rows of the transition
matrix and γ controls how concentrated or diffuse the probability mass of β will be over the states
of the transition matrix. However  in the HDP-HMM we have each row of the transition matrix
is drawn as πj ∼ DP(α  β). Thus the HDP prior doesn’t differentiate self-transitions from jumps
between different states. This can be especially problematic in the non-parametric setting  since
non-Markovian state persistence in data can lead to the creation of unnecessary extra states and un-
realistically  rapid switching dynamics in our model. In Fox et al. [2008]  this problem is addressed
by including a self-transition bias parameter into the distribution of transitioning probability vector
πj:

πj ∼ DP(α + κ 

αβ + κδj

α + κ

)

(3)

to incorporate prior beliefs that smooth  state-persistent dynamics are more probable. Such a con-
struction only involves the introduction of one further hyperparameter κ which controls the “sticki-
ness” of the transition matrix (note a similar self-transition was explored in Beal et al. [2001]).
For the standard iHMM  most approaches to inference have placed vague gamma hyper-priors on
the hyper-parameters α and γ  which can be resampled efﬁciently as in Teh et al. [2006]. Similarly
in the sticky iHMM  in order to maintain tractable resampling of hyper-parameters Fox et al. [2008]
chose to place vague gamma priors on γ  α+κ  and a beta prior on κ/(α+κ). In this work we follow
Teh et al. [2006]; Fox et al. [2008] and place priors γ ∼ Gamma(aγ  bγ)  α + κ ∼ Gamma(as  bs) 
and κ ∼ Beta(aκ  bκ) on the hyper-parameters.
We consider two conjugate emission models for the output states of the iHMM – a multinomial
emission distribution for discrete data  and a normal emission distribution for continuous data. For
discrete data we choose φk ∼ Dir(αφ) with f (·| φst) = Cat(·|φk). For continuous data we choose
φk = (µ  σ2) ∼ N IG(µ  λ  αφ  βφ) with f (·| φst) = N (·|φk = (µ  σ2)).
3 Posterior Inference for the iHMM
Let us ﬁrst recall the collection of variables we need to sample: β is a shared DP base measure  (πk)
is the transition matrix acting on the latent states  while φk parametrizes the emission distribution
f  k = 1  . . .   K. We can then resample the variables of the iHMM in a series of Gibbs steps:
Step 1: Sample s1:T | y1:T   φ1:K  β  π1:K.
Step 2: Sample β | s1:T   γ.
Step 3: Sample π1:K | β  α  κ  s1:T .
Step 4: Sample φ1:K | y1:T   s1:T   H.
Step 5: Sample (α  γ  κ)| s1:T   β  π1:K.
Due to the strongly correlated nature of time-series data  resampling the latent hidden states in Step
1  is often the most difﬁcult since the other variables can be sampled via the Gibbs sampler once a
sample of s1:T has been obtained. In the following section  we describe a novel efﬁcient sampler for
the latent states s1:T of the iHMM  and refer the reader to our appendix and Teh et al. [2006]; Fox
et al. [2008] for a detailed discussion on steps for sampling variables α  γ  κ  β  π1:K  φ1:K.
3.1
Within the Particle MCMC framework of Andrieu et al. [2010]  Sequential Monte Carlo (or particle
ﬁltering) is used as a complex  high-dimensional proposal for the Metropolis-Hastings algorithm.
The Particle Gibbs sampler is a conditional SMC algorithm resulting from clamping one particle to
an apriori ﬁxed trajectory. In particular  it is a transition kernel that has p(s1:T|y1:T ) as its stationary
distribution.
The key to constructing a generic  truncation-free sampler for the iHMM to resample the latent
states  s1:T   is to note that the ﬁnite number of particles in the sampler are “localized” in the latent
space to a ﬁnite subset of the inﬁnite set of possible states. Moreover  they can only transition
to ﬁnitely many new states as they are propagated through the forward pass. Thus the “inﬁnite”
measure β  and “inﬁnite” transition matrix π only need to be instantiated to support the number of
“active” states (deﬁned as being {1  ...  K}) in the state space. In the particle Gibbs algorithm  if a
particle transitions to a state outside the “active” set  the objects β and π can be lazily expanded via

Inﬁnite State Particle Gibbs Sampler

3

the stick-breaking constructions derived for both objects in Teh et al. [2006] and stated in equations
(2)  (4) and (5). Thus due to the properties of both the stick-breaking construction and the PGAS
kernel  this resampling procedure will leave the target distribution p(s1:T|y1:T ) invariant. Below we
ﬁrst describe our inﬁnite-state particle Gibbs algorithm for the iHMM then detail our notation (we
provide further background on SMC in our supplement):

1 = p(s1)f1(y1|s1)(cid:14)q1(s1) for i ∈ 1  ...  N.

Step 1: For iteration t = 1 initialize as:
1 ∼ q1(·)  for i ∈ 1  ...  N.
(a) sample si
(b) initialize weights wi
Step 2: For iteration t > 1 use trajectory s(cid:48)
t−1 ∼ Cat(·|W 1:N
(a) sample the index ai
t ∼ qt(·| s
t−1 ) for i ∈ 1  ...  N − 1. If si
(b) sample si

ai
t−1

1:T from t − 1  β  π  φ  and K:

t−1 ) of the ancestor of particle i for i ∈ 1  ...  N − 1.

t = K + 1 then create a new state using the

stick-breaking construction for the HDP:
(i) Sample a new transition probability vector πK+1 ∼ Dir(αβ).
(ii) Use stick-breaking construction to iteratively expand β ← [β  βK+1] as:

β(cid:48)

K+1

iid∼ Beta(1  γ) 

βK+1 = β(cid:48)

K+1ΠK

(cid:96)=1(1 − β(cid:48)
(cid:96)).

(iii) Expand transition probability vectors (πk)  k = 1  . . .   K + 1  to include transitions

to K + 1st state via the HDP stick-breaking construction as:

πj ← [πj1  πj2  . . .   πj K+1] 

∀j = 1  . . .   K + 1.

where

jK+1 ∼ Beta(cid:0)α0βK  α0(1 − K+1(cid:88)

π(cid:48)

βl)(cid:1)  πjK+1 = π(cid:48)

jK+1ΠK

(cid:96)=1(1 − π(cid:48)

j(cid:96)).

(iv) Sample a new emission parameter φK+1 ∼ H.

(cid:96)=1

(c) compute the ancestor weights ˜wi

t−1|T = wi
P(aN

t|si

t−1π(s(cid:48)
t = i) ∝ ˜wi

t−1|T .

t−1) and resample aN

t as

(d) recompute and normalize particle weights using:

wt(si

t) = π(si

t | s

ai

t−1

t−1 )f (yt | si
N(cid:88)

t)/qt(si

t | s

ai
t−1
t−1 )

t))

1:T .

t  wi

wt(si

i=1
1:T = sk

t) = wt(si
t)/(
T and return s∗

Wt(si
Step 3: Sample k with P(k = i) ∝ wi
In the particle Gibbs sampler  at each step t a weighted particle system {si
t}N
i=1 serves as an
empirical point-mass approximation to the distribution p(s1:T )  with the variables ai
t denoting the
t. Here we have used π(st|st−1) to denote the latent transition distribution 
‘ancestor’ particles of si
f (yt|st) the emission distribution  and p(s1) the prior over the initial state s1.
3.2 More Efﬁcient Importance Proposal qt(·)
In the PG algorithm described above  we have a choice of the importance sampling density qt(·) to
use at every time step. The simplest choice is to sample from the “prior” – qt(·|s
ai
t−1
t−1 )
– which can lead to satisfactory performance when then observations are not too informative and the
dimension of the latent variables are not too large. However using the prior as importance proposal
in particle MCMC is known to be suboptimal. In order to improve the mixing rate of the sampler  it
is desirable to sample from the partial “posterior” – qt(·| s
t) – whenever
possible.
In general  sampling from the “posterior”  qt(·| s
t )  may be impossible 
but in the iHMM we can show that it is analytically tractable. To see this  note that we have lazily

t−1 ) ∝ π(sn
t |s

t−1 ) ∝ π(si
t|s

t|s
ai
t−1
t−1 ) = π(si

ai
t−1

t−1 )f (yt|si

an
t−1

t−1 )f (yt|sn

ai
t−1

an

t−1

4

t−1 1:K  πsn

t |sn

t |sn

k=1 π(k | sn

t where n ∈ 1  ...  N − 1.

t ∈ 1  ...  K. However  if sn

t−1) = (cid:80)K+1

t−1) as a ﬁnite vector – [πsn
t |sn

t   φ1:K) for all sn

t = K + 1) =(cid:82) f (yn

represented π(·|sn
t−1 K+1]. Moreover  we can easily evaluate
t = K + 1  we need to compute
the likelihood f (yn
t = K + 1  φ)H(φ)dφ. If f and H are conjugate  we can analyt-
f (yn
ically compute the marginal likelihood of the K + 1st state  but this can also be approximated by
Monte Carlo sampling for non-conjugate likelihoods – see Neal [2000] for a more detailed discus-
t−1)f (yt | φk) for each
sion of this argument. Thus  we can compute p(yt|sn
particle sn
We investigate the impact of “posterior” vs. “prior” proposals in Figure 5. Based on the convergence
of the number of states and joint log-likelihood  we can see that sampling from the “posterior”
improves the mixing of the sampler. Indeed  we see from the “prior” sampling experiments that
increasing the number of particles from N = 10 to N = 50 does seem to marginally improve the
mixing the sampler  but have found N = 10 particles sufﬁcient to obtain good results. However 
we found no appreciable gain when increasing the number of particles from N = 10 to N = 50
when sampling from the “posterior” and omitted the curves for clarity. It is worth noting that the
PG sampler (with ancestor resampling) does still perform reasonably even when sampling from the
“prior”.
3.3
It has been recognized that the mixing properties of the PG kernel can be poor due to path degeneracy
[Lindsten et al.  2014]. A variant of PG that is presented in Lindsten et al. [2014] attempts to
address this problem for any non-Markovian state-space model with a modiﬁcation – resample a new
in an “ancestor sampling” step at every time step  which can signiﬁcantly
value for the variable aN
t
improve the mixing of the PG kernel with little extra computation in the case of Markovian systems.
To understand ancestor sampling  for t ≥ 2 consider the reference trajectory s(cid:48)
t:T ranging from the
current time step t to the ﬁnal time T . Now  artiﬁcially assign a candidate history to this partial path 
by connecting s(cid:48)
i=1 which can be
t ∈ 1  ...  N. To do this  we ﬁrst compute
achieved by simply assigning a new value to the variable aN
the weights:
t:T|y1:T )
1:t−1|y1:T )

t:T to one of the other particles history up until that point {si

Improving Mixing via Ancestor Resampling

t−1|T ≡ wi
˜wi

pT (si

1:t−1  s(cid:48)

 

i = 1  ...  N

1:t−1}N

(4)

t−1

pt−1(si
t = i) ∝ ˜wi

is sampled according to P(aN

Then aN
t−1|T . Remarkably  this ancestor sampling
t
step leaves the density p(s1:T | y1:T ) invariant as shown in Lindsten et al. [2014] for arbitrary  non-
Markovian state-space models. However since the inﬁnite HMM is Markovian  we can show the
computation of the ancestor sampling weights simpliﬁes to
t|si

t−1π(s(cid:48)

t−1|T = wi

t−1)

(5)

˜wi

Note that the ancestor sampling step does not change the O(T N K) time complexity of the inﬁnite-
state PG sampler.
3.4 Resampling π  φ  β  α  γ  and κ
Our resampling scheme for π  β  φ  α  γ  and κ will follow straightforwardly from this scheme in
Fox et al. [2008]; Teh et al. [2006]. We present a review of their methods and related work in our
appendix for completeness.
4 Empirical Study
In the following experiments we explore the performance of the PG sampler on both the iHMM
and the sticky iHMM. Note that throughout this section we have only taken N = 10 and N =
50 particles for the PG sampler which has time complexity O(T N K) when sampling from the
“posterior” compared to the time complexity of O(T K 2) of the beam sampler. For completeness 
we also compare to the Gibbs sampler  which has been shown perform worse than the beam sampler
[Van Gael et al.  2008]  due to strong correlations in the latent states.
4.1 Convergence on Synthetic Data
To study the mixing properties of the PG sampler on the iHMM and sticky iHMM  we consider
two synthetic examples with strongly positively correlated latent states. First as in Van Gael et al.

5

Figure 2: Comparing the performance of the PG
sampler  PG sampler on sticky iHMM (PG-S)  beam
sampler  and Gibbs sampler on inferring data from
a 4 state strongly correlated HMM. Left: Number
of “Active” States K vs. Iterations Right: Joint-Log
Likelihood vs. Iterations (Best viewed in color)

Figure 3: Learned Latent Transition Matri-
ces for the PG sampler and Beam Sampler
vs Ground Truth (Transition Matrix for Gibbs
Sampler omitted for clarity). PG correctly re-
covers strongly correlated self-transition ma-
trix  while the Beam Sampler supports extra
“spurious” states in the latent space.

[2008]  we generate sequences of length 4000 from a 4 state HMM with self-transition probability
of 0.75  and residual probability mass distributed uniformly over the remaining states where the
emission distributions are taken to be normal with ﬁxed standard deviation 0.5 and emission means
of −2.0 −0.5  1.0  4.0 for the 4 states. The base distribution  H for the iHMM is taken to be normal
with mean 0 and standard deviation 2  and we initialized the sampler with K = 10 “active” states.
In the 4-state case  we see in Figure 2 that the PG sampler applied to both the iHMM and the
sticky iHMM converges to the “true” value of K = 4 much quicker than both the beam sampler
and Gibbs sampler – uncovering the model dimensionality  and structure of the transition matrix
by more rapidly eliminating spurious “active” states from the space as evidenced in the learned
transition matrix plots in Figure 3. Moreover  as evidenced by the joint log-likelihood in Figure 2 
we see that the PG sampler applied to both the iHMM and the sticky iHMM converges quickly to a
good mode  while the beam sampler has not fully converged within a 1000 iterations  and the Gibbs
sampler is performing poorly.
To further explore the mixing of the PG sampler vs. the beam sampler we consider a similar infer-
ence problem on synthetic data over a larger state space. We generate data from sequences of length
4000 from a 10 state HMM with self-transition probability of 0.75  and residual probability mass
distributed uniformly over the remaining states  and take the emission distributions to be normal
with ﬁxed standard deviation 0.5 and means equally spaced 2.0 apart between −10 and 10. The
base distribution  H  for the iHMM is also taken to be normal with mean 0 and standard deviation
2. The samplers were initialized with K = 3 and K = 30 states to explore the convergence and
robustness of the inﬁnite-state PG sampler vs. the beam sampler.

Figure 4: Comparing the performance of the
PG sampler vs. beam sampler on inferring data
from a 10 state strongly correlated HMM with
different initializations. Left: Number of “Ac-
tive” States K from different Initial K vs. Iter-
ations Right: Joint-Log Likelihood from differ-
ent Initial K vs. Iterations

Figure 5: Inﬂuence of “Posterior” vs. “Prior”
proposal and Number of Particles in PG sam-
pler on iHMM. Left: Number of “Active” States
K from different Initial K  Numbers of Parti-
cles  and “Prior”/“Posterior” proposal vs.
It-
erations Right: Joint-Log Likelihood from dif-
ferent Initial K  Numbers of Particles  and
“Prior”/”Posterior” proposal vs. Iterations

6

iteration050010000510152025303540 4-State: KPGAS-SPGASBeamGibbsiteration05001000-10000-9000-8000-7000-6000-5000 4-State: JLLPGAS-SPGASBeamGibbsPGBeamTruth0200400600800100005101520253010-State: KPGAS-initK30PGAS-initK30-SPGAS-initK3PGAS-initK3-SBeam-initK30Beam-initK302004006008001000-10000-9500-9000-8500-8000-7500-7000 10-State: JLLPGAS-initK30PGAS-initK30-SPGAS-initK3PGAS-initK3-SBeam-initK30Beam-initK302004006008001000051015202530 10-State: KPGAS-n10-post-initK30PGAS-n10-post-initK3PGAS-n10-pri-initK30PGAS-n10-pri-initK3PGAS-n50-pri-initK30PGAS-n50-pri-initK302004006008001000-10000-9500-9000-8500-8000-7500-7000 10-State: JLLPGAS-n10-post-initK30PGAS-n10-post-initK3PGAS-n10-pri-initK30PGAS-n10-pri-initK3PGAS-n50-pri-initK30PGAS-n50-pri-initK3Ion Channel Recordings

As observed in Figure 4  we see that the PG sampler applied to the iHMM and sticky iHMM 
converges far more quickly from both “small” and “large” initialization of K = 3 and K = 30
“active” states to the true value of K = 10 hidden states  as well as converging in JLL more quickly.
Indeed  as noted in Fox et al. [2008]  the introduction of the extra slice variables in the beam
sampler can inhibit the mixing of the sampler  since for the beam sampler to consider transitions
with low prior probability one must also have sampled an unlikely corresponding slice variable so
as not to have truncated that state out of the space. This can become particularly problematic if
one needs to consider several of these transitions in succession. We believe this provides evidence
that the inﬁnite-state Particle Gibbs sampler presented here  which does not introduce extra slice
variables  is mixing better than beam sampling in the iHMM.
4.2
For our ﬁrst real dataset  we investigate the behavior of the PG sampler and beam sampler on an ion
channel recording. In particular  we consider a 1MHz recording from Rosenstein et al. [2013] of
a single alamethicin channel previously investigated in Palla et al. [2014]. We subsample the time
series by a factor of 100  truncate it to be of length 2000  and further log transform and normalize it.
We ran both the beam and PG sampler on the iHMM for 1000 iterations (until we observed a con-
vergence in the joint log-likelihood). Due to the large ﬂuctuations in the observed time series  the
beam sampler infers the number of “active” hidden states to be K = 5 while the PG sampler infers
the number of “active” hidden states to be K = 4. However in Figure 6  we see that beam sampler
infers a solution for the latent states which rapidly oscillates between a subset of likely states during
temporal regions which intuitively seem to be better explained by a single state. However  the PG
sampler has converged to a mode which seems to better represent the latent transition dynamics  and
only seems to infer “extra” states in the regions of large ﬂuctuation. Indeed  this suggests that the
beam sampler is mixing worse with respect to the PG sampler.

Figure 6: Left: Observations colored by an inferred latent trajectory using beam sampling inference.
Right: Observations colored by an inferred latent state trajectory using PG inference.
4.3 Alice in Wonderland Data
For our next example we consider the task of predicting sequences of letters taken from Alice’s
Adventures in Wonderland. We trained an iHMM on the 1000 characters from the ﬁrst chapter of the
book  and tested on 4000 subsequent characters from the same chapter using a multinomial emission
model for the iHMM.
Once again  we see that the PG sampler applied to the iHMM/sticky iHMM converges quickly in
joint log-likelihood to a mode where it stably learns a value of K ≈ 10 as evidenced in Figure 7.
Though the performance of the PG and beam samplers appear to be roughly comparable here  we
would like to highlight two observations. Firstly  the inferred value of K obtained by the PG sam-
pler quickly converges independent of the initialization K in the rightmost of Figure 7. However 
the beam sampler’s prediction for the number of active states K still appears to be decreasing and
more rapidly ﬂuctuating than both the iHMM and sticky iHMM as evidenced by the error bars in
the middle plot in addition to being quite sensitive to the initialization K as shown in the right-
most plot. Based on the previous synthetic experiment (Section 4.1)  and this result we suspect
that although both the beam sampler and PG sampler are quickly converging to good solutions as
evidenced by the training joint log-likelihood  the beam sampler is learning a transition matrix with

unnecessary(cid:14)spurious “active” states. Next we calculate the predictive log-likelihood of the Alice

7

Beam: Latent Statest0500100015002000y-1.5-1-0.500.512345PG: Latent Statest0500100015002000y-1.5-1-0.500.51234Figure 7: Left: Comparing the Joint Log-Likelihood vs. Iterations for the PG sampler and Beam
sampler. Middle: Comparing the convergence of the “active” number of states for the iHMM and
sticky iHMM for the PG sampler and Beam sampler. Right: Trace plots of the number of states for
different initializations for K.

in Wonderland test data averaged over 2500 different realizations and ﬁnd that the inﬁnite-state PG
sampler with N = 10 particles achieves a predictive log-likelihood of −5918.4 ± 123.8 while the
beam sampler achieves a predictive log-likelihood of −6099.0 ± 106.0  showing the PG sampler
applied to the iHMM and Sticky iHMM learns hyperparameter and latent variable values that obtain
better predictive performance on the held-out dataset. We note that in this experiment as well  we
have only found it necessary to take N = 10 particles in the PG sampler achieve good mixing and
empirical performance  although increasing the number of particles to N = 50 does improve the
convergence of the sampler in this instance. Given that the PG sampler has a time complexity of
O(T N K) for a single pass  while the beam sampler (and truncated methods) have a time complex-
ity of O(T K 2) for a single pass  we believe that the PG sampler is a competitive alternative to the
beam sampler for the iHMM.
5 Discussions and Conclusions
In this work we derive a new inference algorithm for the iHMM using the particle MCMC frame-
work based on the stick-breaking construction for the HDP. We also develop an efﬁcient proposal
inside PG optimized for iHMM’s  to efﬁciently resample the latent state trajectories for iHMM’s.
The proposed algorithm is empirically compared to existing state-of-the-art inference algorithms
for iHMMs  and shown to be promising because it converges more quickly and robustly to the true
number of states  in addition to obtaining better predictive performance on several synthetic and
realworld datasets. Moreover  we argued that the PG sampler proposed here is a competitive alter-
native to the beam sampler since the time complexity of the particle samplers presented is O(T N K)
versus the O(T K 2) of the beam sampler.
Another advantage of the proposed method is the simplicity of the PG algorithm  which doesn’t
require truncation or the introduction of auxiliary variables  also making the algorithm easily adapt-
able to challenging inference tasks. In particular  the PG sampler can be directly applied to the sticky
HDP-HMM with DP emission model considered in Fox et al. [2008] for which no truncation-free
sampler exists. We leave this development and application as an avenue for future work.
References
Andrieu  C.  Doucet  A.  and Holenstein  R. (2010). Particle Markov chain Monte Carlo methods.

Journal of the Royal Statistical Society: Series B (Statistical Methodology)  72(3):269–342.

Beal  M. J.  Ghahramani  Z.  and Rasmussen  C. E. (2001). The inﬁnite hidden Markov model. In

Advances in neural information processing systems  pages 577–584.

Bishop  C. M. (2006). Pattern recognition and machine learning  volume 4. Springer New York.
Fox  E. B.  Sudderth  E. B.  Jordan  M. I.  and Willsky  A. S. (2008). An HDP–HMM for systems
with state persistence. In Proceedings of the 25th international conference on Machine learning 
pages 312–319. ACM.

Lindsten  F.  Jordan  M. I.  and Sch¨on  T. B. (2014). Particle Gibbs with ancestor sampling. The

Journal of Machine Learning Research  15(1):2145–2184.

8

JLLiteration sPGAS (N=50)PGAS (N=10)BeamKiterationPGAS (N=50)PGAS (N=10)Neal  R. M. (2000). Markov chain sampling methods for Dirichlet process mixture models. Journal

of Computational and Graphical Statistics  9:249–265.

Palla  K.  Knowles  D. A.  and Ghahramani  Z. (2014). A reversible inﬁnite hmm using normalised

random measures. arXiv preprint arXiv:1403.4206.

Rabiner  L. (1989). A tutorial on hidden markov models and selected applications in speech recog-

nition. Proceedings of the IEEE  77(2):257–286.

Rosenstein  J. K.  Ramakrishnan  S.  Roseman  J.  and Shepard  K. L. (2013). Single ion channel

recordings with cmos-anchored lipid membranes. Nano letters  13(6):2682–2686.

Scott  S. L. (2002). Bayesian methods for hidden Markov models. Journal of the American Statis-

tical Association  97(457).

Teh  Y. W.  Jordan  M. I.  Beal  M. J.  and Blei  D. M. (2006). Hierarchical Dirichlet processes.

Journal of the American Statistical Association  101(476):1566–1581.

Van Gael  J.  Saatci  Y.  Teh  Y. W.  and Ghahramani  Z. (2008). Beam sampling for the inﬁnite
hidden Markov model. In Proceedings of the International Conference on Machine Learning 
volume 25.

9

,Nilesh Tripuraneni
Shixiang (Shane) Gu
Hong Ge
Zoubin Ghahramani
Andrea Giovannucci
Johannes Friedrich
Matt Kaufman
Anne Churchland
Dmitri Chklovskii
Liam Paninski
Eftychios Pnevmatikakis