2017,Online Influence Maximization under Independent Cascade Model with Semi-Bandit Feedback,We study the online influence maximization problem in social networks under the independent cascade model. Specifically  we aim to learn the set of "best influencers" in a social network online while repeatedly interacting with it. We address the challenges of (i) combinatorial action space  since the number of feasible influencer sets grows exponentially with the maximum number of influencers  and (ii) limited feedback  since only the influenced portion of the network is observed. Under a stochastic semi-bandit feedback  we propose and analyze IMLinUCB  a computationally efficient UCB-based algorithm. Our bounds on the cumulative regret are polynomial in all quantities of interest  achieve near-optimal dependence on the number of interactions and reflect the topology of the network and the activation probabilities of its edges  thereby giving insights on the problem complexity. To the best of our knowledge  these are the first such results. Our experiments show that in several representative graph topologies  the regret of IMLinUCB scales as suggested by our upper bounds. IMLinUCB permits linear generalization and thus is both statistically and computationally suitable for large-scale problems. Our experiments also show that IMLinUCB with linear generalization can lead to low regret in real-world online influence maximization.,Online Inﬂuence Maximization under Independent

Cascade Model with Semi-Bandit Feedback

Zheng Wen

Adobe Research
zwen@adobe.com

Branislav Kveton
Adobe Research

kveton@adobe.com

Michal Valko

SequeL team  INRIA Lille - Nord Europe

michal.valko@inria.fr

Sharan Vaswani

University of British Columbia

sharanv@cs.ubc.ca

Abstract

We study the online inﬂuence maximization problem in social networks under
the independent cascade model. Speciﬁcally  we aim to learn the set of “best
inﬂuencers” in a social network online while repeatedly interacting with it. We ad-
dress the challenges of (i) combinatorial action space  since the number of feasible
inﬂuencer sets grows exponentially with the maximum number of inﬂuencers  and
(ii) limited feedback  since only the inﬂuenced portion of the network is observed.
Under a stochastic semi-bandit feedback  we propose and analyze IMLinUCB  a
computationally efﬁcient UCB-based algorithm. Our bounds on the cumulative
regret are polynomial in all quantities of interest  achieve near-optimal dependence
on the number of interactions and reﬂect the topology of the network and the acti-
vation probabilities of its edges  thereby giving insights on the problem complexity.
To the best of our knowledge  these are the ﬁrst such results. Our experiments show
that in several representative graph topologies  the regret of IMLinUCB scales as
suggested by our upper bounds. IMLinUCB permits linear generalization and thus
is both statistically and computationally suitable for large-scale problems. Our
experiments also show that IMLinUCB with linear generalization can lead to low
regret in real-world online inﬂuence maximization.

1

Introduction

Social networks are increasingly important as media for spreading information  ideas  and inﬂu-
ence. Computational advertising studies models of information propagation or diffusion in such
networks [16  6  10]. Viral marketing aims to use this information propagation to spread awareness
about a speciﬁc product. More precisely  agents (marketers) aim to select a ﬁxed number of inﬂu-
encers (called seeds or source nodes) and provide them with free products or discounts. They expect
that these users will inﬂuence their neighbours and  transitively  other users in the social network to
adopt the product. This will thus result in information propagating across the network as more users
adopt or become aware of the product. The marketer has a budget on the number of free products and
must choose seeds in order to maximize the inﬂuence spread  which is the expected number of users
that become aware of the product. This problem is referred to as inﬂuence maximization (IM) [16].
For IM  the social network is modeled as a directed graph with the nodes representing users  and
the edges representing relations (e.g.  friendships on Facebook  following on Twitter) between them.
Each directed edge (i  j) is associated with an activation probability w(i  j) that models the strength
of inﬂuence that user i has on user j. We say a node j is a downstream neighbor of node i if
there is a directed edge (i  j) from i to j. The IM problem has been studied under a number of

31st Conference on Neural Information Processing Systems (NIPS 2017)  Long Beach  CA  USA.

diffusion models [16  13  23]. The best known and studied are the models in [16]  and in particular
the independent cascade (IC) model. In this work  we assume that the diffusion follows the IC model
and describe it next.
After the agent chooses a set of source nodes S  the independent cascade model deﬁnes a diffusion
(inﬂuence) process: At the beginning  all nodes in S are activated (inﬂuenced); subsequently  every
activated node i can activate its downstream neighbor j with probability w(i  j) once  independently
of the history of the process. This process runs until no activations are possible. In the IM problem  the
goal of the agent is to maximize the expected number of the inﬂuenced nodes subject to a cardinality
constraint on S. Finding the best set S is an NP-hard problem  but under common diffusion models
including IC  it can be efﬁciently approximated to within a factor of 1 − 1/e [16].
In many social networks  however  the activation probabilities are unknown. One possibility is to
learn these from past propagation data [25  14  24]. However in practice  such data are hard to
obtain and the large number of parameters makes this learning challenging. This motivates the
learning framework of IM bandits [31  28  29]  where the agent needs to learn to choose a good set
of source nodes while repeatedly interacting with the network. Depending on the feedback to the
agent  the IM bandits can have (1) full-bandit feedback  where only the number of inﬂuenced nodes is
observed; (2) node semi-bandit feedback  where the identity of inﬂuenced nodes is observed; or (3)
edge semi-bandit feedback  where the identity of inﬂuenced edges (edges going out from inﬂuenced
nodes) is observed. In this paper  we give results for the edge semi-bandit feedback model  where we
observe for each inﬂuenced node  the downstream neighbors that this node inﬂuences. Such feedback
is feasible to obtain in most online social networks. These networks track activities of users  for
instance  when a user retweets a tweet of another user. They can thus trace the propagation (of the
tweet) through the network  thereby obtaining edge semi-bandit feedback.
The IM bandits problem combines two main challenges. First  the number of actions (possible
sets) S grows exponentially with the cardinality constraint on S. Second  the agent can only observe
the inﬂuenced portion of the network as feedback. Although IM bandits have been studied in the
past [21  8  31  5  29] (see Section 6 for an overview and comparison)  there are a number of open
challenges [28]. One challenge is to identify reasonable complexity metrics that depend on both
the topology and activation probabilities of the network and characterize the information-theoretic
complexity of the IM bandits problem. Another challenge is to develop learning algorithms such that
(i) their performance scales gracefully with these metrics and (ii) are computationally efﬁcient and
can be applied to large social networks with millions of users.
In this paper  we address these two challenges under the IC model with access to edge semi-bandit
feedback. We refer to our model as an independent cascade semi-bandit (ICSB). We make four
main contributions. First  we propose IMLinUCB  a UCB-like algorithm for ICSBs that permits linear
generalization and is suitable for large-scale problems. Second  we deﬁne a new complexity metric 
referred to as maximum observed relevance for ICSB  which depends on the topology of the network
and is a non-decreasing function of activation probabilities. The maximum observed relevance C∗
can also be upper bounded based on the network topology or the size of the network in the worst case.
However  in real-world social networks  due to the relatively low activation probabilities [14]  C∗
attains much smaller values as compared to the worst case upper bounds. Third  we bound the
cumulative regret of IMLinUCB. Our regret bounds are polynomial in all quantities of interest and
have near-optimal dependence on the number of interactions. They reﬂect the structure and activation
probabilities of the network through C∗ and do not depend on inherently large quantities  such as
the reciprocal of the minimum probability of being inﬂuenced (unlike [8]) and the cardinality of
the action set. Finally  we evaluate IMLinUCB on several problems. Our empirical results on simple
representative topologies show that the regret of IMLinUCB scales as suggested by our topology-
dependent regret bounds. We also show that IMLinUCB with linear generalization can lead to low
regret in real-world online inﬂuence maximization problems.

2

Inﬂuence Maximization under Independence Cascade Model

In this section  we deﬁne notation and give the formal problem statement for the IM problem under
the IC model. Consider a directed graph G = (V E) with a set V = {1  2  . . .   L} of L = |V| nodes 
a set E = {1  2  . . .  |E|} of directed edges  and an arbitrary binary weight function w : E → {0  1}.

2

We say that a node v2 ∈ V is reachable from a node v1 ∈ V under w if there is a directed path1
p = (e1  e2  . . .   el) from v1 to v2 in G satisfying w(ei) = 1 for all i = 1  2  . . .   l  where ei is the
i-th edge in p. For a given source node set S ⊆ V and w  we say that node v ∈ V is inﬂuenced if v is
reachable from at least one source node in S under w; and denote the number of inﬂuenced nodes in
G by f (S  w). By deﬁnition  the nodes in S are always inﬂuenced.
The inﬂuence maximization (IM) problem is characterized by a triple (G  K  w)  where G is a given
directed graph  K ≤ L is the cardinality of source nodes  and w : E → [0  1] is a probability weight
function mapping each edge e ∈ E to a real number w(e) ∈ [0  1]. The agent needs to choose a set
of K source nodes S ⊆ V based on (G  K  w). Then a random binary weight function w  which
encodes the diffusion process under the IC model  is obtained by independently sampling a Bernoulli
random variable w(e) ∼ Bern (w(e)) for each edge e ∈ E. The agent’s objective is to maximize the
expected number of the inﬂuenced nodes: maxS: |S|=K f (S  w)  where f (S  w) ∆= Ew [f (S  w)] is
the expected number of inﬂuenced nodes when the source node set is S and w is sampled according
to w.2
It is well-known that the (ofﬂine) IM problem is NP-hard [16]  but can be approximately solved
by approximation/randomized algorithms [6] under the IC model. In this paper  we refer to such
algorithms as oracles to distinguish them from the machine learning algorithms discussed in following
sections. Let S opt be the optimal solution of this problem  and S∗ = ORACLE(G  K  w) be the
(possibly random) solution of an oracle ORACLE. For any α  γ ∈ [0  1]  we say that ORACLE is
an (α  γ)-approximation oracle for a given (G  K) if for any w  f (S∗  w) ≥ γf (S opt  w) with
probability at least α. Notice that this further implies that E [f (S∗  w)] ≥ αγf (S opt  w). We say an
oracle is exact if α = γ = 1.

3

Inﬂuence Maximization Semi-Bandit

In this section  we ﬁrst describe the IM semi-bandit problem. Next  we state the linear generalization
assumption and describe IMLinUCB  our UCB-based semi-bandit algorithm.

3.1 Protocol
The independent cascade semi-bandit (ICSB) problem is also characterized by a triple (G  K  w)  but
w is unknown to the agent. The agent interacts with the independent cascade semi-bandit for n rounds.
At each round t = 1  2  . . .   n  the agent ﬁrst chooses a source node set St ⊆ V with cardinality K
based on its prior information and past observations. Inﬂuence then diffuses from the nodes in St
according to the IC model. Similarly to the previous section  this can be interpreted as the environment
generating a binary weight function wt by independently sampling wt(e) ∼ Bern (w(e)) for each
e ∈ E. At round t  the agent receives the reward f (St  wt)  that is equal to the number of nodes
inﬂuenced at that round. The agent also receives edge semi-bandit feedback from the diffusion
process. Speciﬁcally  for any edge e = (u1  u2) ∈ E  the agent observes the realization of wt(e) if
and only if the start node u1 of the directed edge e is inﬂuenced in the realization wt. The agent’s
objective is to maximize the expected cumulative reward over the n steps.

3.2 Linear generalization

Since the number of edges in real-world social networks tends to be in millions or even billions  we
need to exploit some generalization model across activation probabilities to develop efﬁcient and
deployable learning algorithms. In particular  we assume that there exists a linear-generalization
model for the probability weight function w. That is  each edge e ∈ E is associated with a known
feature vector xe ∈ (cid:60)d (here d is the dimension of the feature vector) and that there is an unknown
coefﬁcient vector θ∗ ∈ (cid:60)d such that for all e ∈ E  w(e) is “well approximated" by xT
eθ∗. Formally 
eθ∗| is small. In Section 5.2  we see that such a linear
we assume that ρ ∆= maxe∈E |w(e) − xT
generalization leads to efﬁcient learning in real-world networks. Note that all vectors in this paper
are column vectors.

1As is standard in graph theory  a directed path is a sequence of directed edges connecting a sequence of
2Notice that the deﬁnitions of f (S  w) and f (S  w) are consistent in the sense that if w ∈ {0  1}|E|  then

distinct nodes  under the restriction that all edges are directed in the same direction.
f (S  w) = f (S  w) with probability 1.

3

Algorithm 1 IMLinUCB: Inﬂuence Maximization Linear UCB

Input: graph G  source node set cardinality K  oracle ORACLE  feature vector xe’s  and algorithm
parameters σ  c > 0 
Initialization: B0 ← 0 ∈ (cid:60)d  M0 ← I ∈ (cid:60)d×d
for t = 1  2  . . .   n do

t−1Bt−1 and the UCBs as Ut(e) ← Proj[0 1]

1. set θt−1 ← σ−2M−1
for all e ∈ E
2. choose St ∈ ORACLE(G  K  Ut)  and observe the edge-level semi-bandit feedback
3. update statistics:

eθt−1 + c
xT

(a) initialize Mt ← Mt−1 and Bt ← Bt−1
(b) for all observed edges e ∈ E  update Mt ← Mt + σ−2xexT

e and Bt ← Bt + xewt(e)

eM−1
xT

t−1xe

(cid:18)

(cid:113)

(cid:19)

Similar to the existing approaches for linear bandits [1  9]  we exploit the linear generalization to
develop a learning algorithm for ICSB. Without loss of generality  we assume that (cid:107)xe(cid:107)2 ≤ 1 for
all e ∈ E. Moreover  we use X ∈ (cid:60)|E|×d to denote the feature matrix  i.e.  the row of X associated
with edge e is xT
e. Note that if a learning agent does not know how to construct good features  it can
always choose the naïve feature matrix X = I ∈ (cid:60)|E|×|E| and have no generalization model across
edges. We refer to the special case X = I ∈ (cid:60)|E|×|E| as the tabular case.

3.3 IMLinUCB algorithm

In this section  we propose Inﬂuence Maximization Linear UCB (IMLinUCB)  detailed in Algorithm 1.
Notice that IMLinUCB represents its past observations as a positive-deﬁnite matrix (Gram matrix)
Mt ∈ (cid:60)d×d and a vector Bt ∈ (cid:60)d. Speciﬁcally  let Xt be a matrix whose rows are the feature
vectors of all observed edges in t steps and Yt be a binary column vector encoding the realizations of
all observed edges in t steps. Then Mt = I + σ−2XT
At each round t  IMLinUCB operates in three steps: First  it computes an upper conﬁdence bound
Ut(e) for each edge e ∈ E. Note that Proj[0 1](·) projects a real number into interval [0  1] to ensure
that Ut ∈ [0  1]|E|. Second  it chooses a set of source nodes based on the given ORACLE and Ut  which
is also a probability-weight function. Finally  it receives the edge semi-bandit feedback and uses it to
update Mt and Bt. It is worth emphasizing that IMLinUCB is computationally efﬁcient as long as
ORACLE is computationally efﬁcient. Speciﬁcally  at each round t  the computational complexities of

both Step 1 and 3 of IMLinUCB are O(cid:0)|E|d2(cid:1).3

t Xt and Bt = XT

t Yt.

It is worth pointing out that in the tabular case  IMLinUCB reduces to CUCB [7]  in the sense that the
conﬁdence radii in IMLinUCB are the same as those in CUCB  up to logarithmic factors. That is  CUCB
can be viewed as a special case of IMLinUCB with X = I.

3.4 Performance metrics

Recall that the agent’s objective is to maximize the expected cumulative reward  which is equivalent to
minimizing the expected cumulative regret. The cumulative regret is the loss in reward (accumulated
over rounds) because of the lack of knowledge of the activation probabilities. Observe that in each
round t  IMLinUCB needs to use an approximation/randomized algorithm ORACLE for solving the
ofﬂine IM problem. Naturally  this can lead to O(n) cumulative regret  since at each round there is
a non-diminishing regret due to the approximation/randomized nature of ORACLE. To analyze the
performance of IMLinUCB in such cases  we deﬁne a more appropriate performance metric  the scaled
t ]  where n is the number of steps  η > 0 is the scale  and
t = f (S opt  wt) − 1
Rη
t at round t. When η = 1  Rη(n)
reduces to the standard expected cumulative regret R(n).

cumulative regret  as Rη(n) =(cid:80)n

η f (St  wt) is the η-scaled realized regret Rη

E [Rη

t=1

3Notice that in a practical implementation  we store M

is equivalent to M

t ← M
−1

t − M
−1

−1
t xexT
eM

−1
t xe+σ2 .
t
−1

eM

xT

−1
t

instead of Mt. Moreover  Mt ← Mt + σ−2xexT

e

4

Figure 1: a. Bar graph on 8 nodes. b. Star graph on 4 nodes. c. Ray graph on 10 nodes. d. Grid
graph on 9 nodes. Each undirected edge denotes two directed edges in opposite directions.

4 Analysis

eθ∗ for all e ∈ E 
In this section  we give a regret bound for IMLinUCB for the case when w(e) = xT
i.e.  the linear generalization is perfect. Our main contribution is a regret bound that scales with a new
complexity metric  maximum observed relevance  which depends on both the topology of G and the
probability weight function w  and is deﬁned in Section 4.1. We highlight this as most known results
for this problem are worst case  and some of them do not depend on probability weight function at all.

4.1 Maximum observed relevance
We start by deﬁning some terminology. For given directed graph G = (V E) and source node set
S ⊆ V  we say an edge e ∈ E is relevant to a node v ∈ V \ S under S if there exists a path p from a
source node s ∈ S to v such that (1) e ∈ p and (2) p does not contain another source node other than
s. Notice that with a given S  whether or not a node v ∈ V \ S is inﬂuenced only depends on the
binary weights w on its relevant edges. For any edge e ∈ E  we deﬁne NS e as the number of nodes
in V \ S it is relevant to  and deﬁne PS e as the conditional probability that e is observed given S 

v∈V\S 1{e is relevant to v under S}

(1)
Notice that NS e only depends on the topology of G  while PS e depends on both the topology of G
and the probability weight w. The maximum observed relevance C∗ is deﬁned as the maximum
(over S) 2-norm of NS e’s weighted by PS e’s 

∆= P (e is observed |S) .

and PS e

∆=(cid:80)

NS e

(cid:113)(cid:80)

C∗ ∆= maxS: |S|=K

e∈E N 2S ePS e.

(2)

(cid:113)(cid:80)
L(cid:112)|E|(cid:17)

= O(cid:0)L2(cid:1)  

e∈E N 2S e ≤ (L − K)(cid:112)|E| = O(cid:16)
(cid:113)(cid:80)

As is detailed in the proof of Lemma 1 in Appendix A  C∗ arises in the step where Cauchy-Schwarz
inequality is applied. Note that C∗ also depends on both the topology of G and the probability
weight w. However  C∗ can be bounded from above only based on the topology of G or the size of the
problem  i.e.  L = |V| and |E|. Speciﬁcally  by deﬁning CG ∆= maxS: |S|=K
e∈E N 2S e  we have

C∗ ≤ CG = maxS: |S|=K

(3)
where CG is the maximum/worst-case (over w) C∗ for the directed graph G  and the maximum is
obtained by setting w(e) = 1 for all e ∈ E. Since CG is worst-case  it might be very far away
from C∗ if the activation probabilities are small. Indeed  this is what we expect in typical real-
world situations. Notice also that if maxe∈E w(e) → 0  then PS e → 0 for all e /∈ E(S) and
PS e = 1 for all e ∈ E(S)  where E(S) is the set of edges with start node in S  hence we have
C∗ → C 0G ∆= maxS: |S|=K
e∈E(S) N 2S e. In particular  if K is small  C 0G is much less than CG in
many topologies. For example  in a complete graph with K = 1  CG = Θ(L2) while C 0G = Θ(L 3
2 ).
Finally  it is worth pointing out that there exist situations (G  w) such that C∗ = Θ(L2). One such
example is when G is a complete graph with L nodes and w(e) = L/(L + 1) for all edges e in this
graph.
To give more intuition  in the rest of this subsection  we illustrate how CG  the worst-case C∗  varies
with four graph topologies in Figure 1: bar  star  ray  and grid  as well as two other topologies:

(cid:113)(cid:80)

5

(a)(b)(c)(d)with k = (cid:6)√

L − 1(cid:7) arms  where node 1 is central and each arm contains either (cid:100)(L − 1)/k(cid:101) or

general tree and complete graph. We ﬁx the node set V = {1  2  . . .   L} for all graphs. The bar
graph (Figure 1a) is a graph where nodes i and i + 1 are connected when i is odd. The star graph
(Figure 1b) is a graph where node 1 is central and all remaining nodes i ∈ V \ {1} are connected
to it. The distance between any two of these nodes is 2. The ray graph (Figure 1c) is a star graph
(cid:98)(L − 1)/k(cid:99) nodes connected in a line. The distance between any two nodes in this graph is O(
The grid graph (Figure 1d) is a classical non-tree graph with O(L) edges.
To see how CG varies with the graph topology  we start with the simpliﬁed case when K = |S| = 1.
In the bar graph (Figure 1a)  only one edge is relevant to a node v ∈ V \ S and all the other edges
are not relevant to any nodes. Therefore  CG ≤ 1. In the star graph (Figure 1b)  for any s  at
most one edge is relevant to at most L − 1 nodes and the remaining edges are relevant to at most
one node. In this case  CG ≤ √
L2 + L = O(L). In the ray graph (Figure 1c)  for any s  at most
(cid:112)
√
O(
bound CG by O(L(cid:112)|E|)  regardless of K. Hence  for the grid graph (Figure 1d) and general tree
L)
nodes. In this case  CG = O(
4 ). Finally  recall that for all graphs we can
graph  CG = O(L 3
2 ) since |E| = O(L); for the complete graph CG = O(L2) since |E| = O(L2).
Clearly  CG varies widely with the topology of the graph. The second column of Table 1 summarizes
how CG varies with the above-mentioned graph topologies for general K = |S|.

L) edges are relevant to L − 1 nodes and the remaining edges are relevant to at most O(

2 L2 + LL) = O(L 5
L 1

L).

√

√

4.2 Regret guarantees

Consider C∗ deﬁned in Section 4.1 and recall the worst-case upper bound C∗ ≤ (L − K)(cid:112)|E|  we

have the following regret guarantees for IMLinUCB.

Theorem 1 Assume that (1) w(e) = xT
algorithm. Let D be a known upper bound on (cid:107)θ∗(cid:107)2  if we apply IMLinUCB with σ = 1 and

eθ∗ for all e ∈ E and (2) ORACLE is an (α  γ)-approximation

(cid:115)

(cid:18)

(cid:19)

n|E|
d

c =

d log

1 +

+ 2 log (n(L + 1 − K)) + D 

(cid:19)

+ 1 = (cid:101)O(cid:16)

(cid:17)
dC∗(cid:112)|E|n/(αγ)

(4)

(5)

(6)

(7)

(8)

then we have

(cid:115)
dn|E| log2

(cid:18)
n/(αγ)(cid:1) .

n|E|
d

1 +

Rαγ(n) ≤ 2cC∗
αγ

≤ (cid:101)O(cid:0)d(L − K)|E|√
≤ (cid:101)O(cid:16)

Rαγ(n) ≤ 2cC∗
αγ

(L − K)|E| 3

2

(cid:17)

√

n/(αγ)

.

Moreover  if the feature matrix X = I ∈ (cid:60)|E|×|E| (i.e.  the tabular case)  we have

(cid:112)n|E| log2 (1 + n) + 1 = (cid:101)O(cid:0)|E|C∗

n/(αγ)(cid:1)

√

Please refer to Appendix A for the proof of Theorem 1  that we outline in Section 4.3. We now brieﬂy
comment on the regret bounds in Theorem 1.
Topology-dependent bounds: Since C∗ is topology-dependent  the regret bounds in Equations 5
and 7 are also topology-dependent. Table 1 summarizes the regret bounds for each topology4
discussed in Section 4.1. Since the regret bounds in Table 1 are the worst-case regret bounds for a
given topology  more general topologies have larger regret bounds. For instance  the regret bounds
for tree are larger than their counterparts for star and ray  since star and ray are special trees. The grid
and tree can also be viewed as special complete graphs by setting w(e) = 0 for some e ∈ E  hence
complete graph has larger regret bounds. Again  in practice we expect C∗ to be far smaller due to
activation probabilities.

4The regret bound for bar graph is based on Theorem 2 in the appendix  which is a stronger version of

Theorem 1 for disconnected graph.

6

topology
bar graph

star graph

ray graph

tree graph

grid graph

complete graph

n/(αγ))

√
O(
K)
√
O(L
K)
√
O(L 5

CG (worst-case C∗) Rαγ(n) for general X Rαγ(n) for X = I
√
Kn/(αγ)
√
Kn/(αγ)
√
Kn/(αγ)
√
√

dL 3
dL 7

Kn/(αγ)

Kn/(αγ)

(cid:17)
(cid:17)

K)

4

2

2

L

(cid:101)O(cid:16)
(cid:101)O(cid:16)
(cid:101)O(cid:16)
(cid:101)O(cid:16)
(cid:101)O(cid:16)
(cid:101)O(cid:0)L4√

L2
L 9
L 5
L 5

4

2

(cid:17)
(cid:17)
(cid:17)
(cid:17)
(cid:17)
n/(αγ)(cid:1)

n/(αγ)

n/(αγ)

√
√
√

(cid:101)O (dK
(cid:101)O(cid:16)
(cid:101)O(cid:16)
(cid:101)O(cid:0)dL2√
(cid:101)O(cid:0)dL2√
(cid:101)O(cid:0)dL3√

4

n/(αγ)(cid:1)
n/(αγ)(cid:1)
n/(αγ)(cid:1)

O(L 3
2 )
O(L 3
2 )
O(L2)

Table 1: CG and worst-case regret bounds for different graph topologies.

Tighter bounds in tabular case and under exact oracle: Notice that for the tabular case with

feature matrix X = I and d = |E|  (cid:101)O((cid:112)|E|) tighter regret bounds are obtained in Equations 7 and 8.
Also notice that the (cid:101)O(1/(αγ)) factor is due to the fact that ORACLE is an (α  γ)-approximation

oracle. If ORACLE solves the IM problem exactly (i.e.  α = γ = 1)  then Rαγ(n) = R(n).
Tightness of our regret bounds: First  note that our regret bound in the bar case with K = 1 matches
the regret bound of the classic LinUCB algorithm. Speciﬁcally  with perfect linear generalization  this
case is equivalent to a linear bandit problem with L arms and feature dimension d. From Table 1 
n)  which matches the known regret bound of LinUCB that can
be obtained by the technique of [1]. Second  we brieﬂy discuss the tightness of the regret bound in
n)-dependence on time

our regret bound in this case is (cid:101)O (d
Equation 6 for a general graph with L nodes and |E| edges. Note that the (cid:101)O(
is near-optimal  and the (cid:101)O(d)-dependence on feature dimension is standard in linear bandits [1  33] 
since (cid:101)O(
d) results are only known for impractical algorithms. The (cid:101)O(L − K) factor is due to the
fact that the reward in this problem is from K to L  rather than from 0 to 1. To explain the (cid:101)O(|E|)
factor in this bound  notice that one (cid:101)O((cid:112)|E|) factor is due to the fact that at most (cid:101)O(|E|) edges might
semi-bandits [19]; another (cid:101)O((cid:112)|E|) factor is due to linear generalization (see Lemma 1) and might
be removed by better analysis. We conjecture that our (cid:101)O (d(L − K)|E|√
this case is at most (cid:101)O((cid:112)|E|d) away from being tight.

be observed at each round (see Theorem 3)  and is intrinsic to the problem similarly to combinatorial

n/(αγ)) regret bound in

√

√

√

(cid:113)

4.3 Proof sketch
We now outline the proof of Theorem 1. For each round t ≤ n  we deﬁne the favorable event
ξt−1 = {|xT
τ−1xe  ∀e ∈ E  ∀τ ≤ t}  and the unfavorable event ξt−1 as
the complement of ξt−1. If we decompose E[Rαγ
]  the (αγ)-scaled expected regret at round t  over
events ξt−1 and ξt−1  and bound Rαγ

t on event ξt−1 using the naïve bound Rαγ

t ≤ L − K  then 

e(θτ−1 − θ∗)| ≤ c

eM−1
xT

|ξt−1] + P(cid:0)ξt−1
By choosing c as speciﬁed by Equation 4  we have P(cid:0)ξt−1

] ≤ P (ξt−1) E [Rαγ

(cid:1) [L − K].
(cid:1) [L − K] < 1/n (see Lemma 2 in

the appendix). On the other hand  notice that by deﬁnition of ξt−1  w(e) ≤ Ut(e)  ∀e ∈ E under
event ξt−1. Using the monotonicity of f in the probability weight  and the fact that ORACLE is an
(α  γ)-approximation algorithm  we have

E[Rαγ

t

t

t

E [Rαγ

t

|ξt−1] ≤ E [f (St  Ut) − f (St  w)|ξt−1] /(αγ).

The next observation is that  from the linearity of expectation  the gap f (St  Ut) − f (St  w) decom-
poses over nodes v ∈ V \ St. Speciﬁcally  for any source node set S ⊆ V  any probability weight
function w : E → [0  1]  and any node v ∈ V  we deﬁne f (S  w  v) as the probability that node v is
inﬂuenced if the source node set is S and the probability weight is w. Hence  we have

f (St  Ut) − f (St  w) =(cid:80)

v∈V\St

[f (St  Ut  v) − f (St  w  v)] .

7

(a) Stars and rays: The log-log plots of the n-step regret of
IMLinUCB in two graph topologies after n = 104 steps. We vary
the number of nodes L and the mean edge weight ω.

(b) Subgraph of Facebook network

Figure 2: Experimental results

In the appendix  we show that under any weight function  the diffusion process from the source node
set St to the target node v can be modeled as a Markov chain. Hence  weight function Ut and w give
us two Markov chains with the same state space but different transition probabilities. f (St  Ut  v) −
f (St  w  v) can be recursively bounded based on the state diagram of the Markov chain under weight
function w. With some algebra  Theorem 3 in Appendix A bounds f (St  Ut  v) − f (St  w  v) by the
edge-level gap Ut(e) − w(e) on the observed relevant edges for node v 

(9)
for any t  any “history" (past observations) Ht−1 and St such that ξt−1 holds  and any v ∈ V \ St 
where ESt v is the set of edges relevant to v and Ot(e) is the event that edge e is observed at round
t. Based on Equation 9  we can prove Theorem 1 using the standard linear-bandit techniques (see
Appendix A).

E [1{Ot(e)} [Ut(e) − w(e)]|Ht−1 St]  

f (St  Ut  v) − f (St  w  v) ≤(cid:80)

e∈ESt v

5 Experiments

In this section  we present a synthetic experiment in order to empirically validate our upper bounds
on the regret. Next  we evaluate our algorithm on a real-world Facebook subgraph.

5.1 Stars and rays

In the ﬁrst experiment  we evaluate IMLinUCB on undirected stars and rays (Figure 1) and validate
that the regret grows with the number of nodes L and the maximum observed relevance C∗ as shown
in Table 1. We focus on the tabular case (X = I) with K = |S| = 1  where the IM problem can be
solved exactly. We vary the number of nodes L; and edge weight w(e) = ω  which is the same for all
edges e. We run IMLinUCB for n = 104 steps and verify that it converges to the optimal solution in
each experiment. We report the n-step regret of IMLinUCB for 8 ≤ L ≤ 32 in Figure 2a. Recall that

from Table 1  R(n) = (cid:101)O(L2) for star and R(n) = (cid:101)O(L 9

4 ) for ray.

We numerically estimate the growth of regret in L  the exponent of L  in the log-log space of L and
regret. In particular  since log(f (L)) = p log(L) + log(c) for any f (L) = cLp and c > 0  both p
and log(c) can be estimated by linear regression in the new space. For star graphs with ω = 0.8 and
ω = 0.7  our estimated growth are respectively O(L2.040) and O(L2.056)  which are close to the

expected (cid:101)O(L2). For ray graphs with ω = 0.8 and ω = 0.7  our estimated growth are respectively
O(L2.488) and O(L2.467)  which are again close to the expected (cid:101)O(L 9

4 ). This shows that maximum
observed relevance C∗ proposed in Section 4.1 is a reasonable complexity metric for these two
topologies.

5.2 Subgraph of Facebook network

In the second experiment  we demonstrate the potential performance gain of IMLinUCB in real-
world inﬂuence maximization semi-bandit problems by exploiting linear generalization across edges.
Speciﬁcally  we compare IMLinUCB with CUCB in a subgraph of Facebook network from [22]. The
subgraph has L = |V| = 327 nodes and |E| = 5038 directed edges. Since the true probability weight

8

8162432L210212214216Regret! = 0.8  X = IStarRay8162432L29211213215Regret! = 0.7  X = I8162432L2829210211Regret! = 0.8  X = X4010002000300040005000Number of Rounds00.511.522.5Cumulative Regret#105CUCBIMLinUCB with d=10function w is not available  we independently sample w(e)’s from the uniform distribution U (0  0.1)
and treat them as ground-truth. Note that this range of probabilities is guided by empirical evidence
in [14  3]. We set n = 5000 and K = 10 in this experiment. For IMLinUCB  we choose d = 10
and generate edge feature xe’s as follows: we ﬁrst use node2vec algorithm [15] to generate a node
feature in (cid:60)d for each node v ∈ V; then for each edge e  we generate xe as the element-wise product
of node features of the two nodes connected to e. Note that the linear generalization in this experiment
is imperfect in the sense that minθ∈(cid:60)d maxe∈E |w(e) − xT
e θ| > 0. For both CUCB and IMLinUCB 
we choose ORACLE as the state-of-the-art ofﬂine IM algorithm proposed in [27]. To compute the
cumulative regret  we compare against a ﬁxed seed set S∗ obtained by using the true w as input to the
oracle proposed in [27]. We average the empirical cumulative regret over 10 independent runs  and
plot the results in Figure 2b. The experimental results show that compared with CUCB  IMLinUCB can
signiﬁcantly reduce the cumulative regret by exploiting linear generalization across w(e)’s.

6 Related Work

There exist prior results on IM semi-bandits [21  8  31]. First  Lei et al. [21] gave algorithms for the
same feedback model as ours. The algorithms are not analyzed and cannot solve large-scale problems
because they estimate each edge weight independently. Second  our setting is a special case of
stochastic combinatorial semi-bandit with a submodular reward function and stochastically observed
edges [8]. Their work is the closest related work. Their gap-dependent and gap-free bounds are both
problematic because they depend on the reciprocal of the minimum observation probability p∗ of an
edge: Consider a line graph with |E| edges where all edge weights are 0.5. Then 1/p∗ is 2|E|−1. On
the other hand  our derived regret bounds in Theorem 1 are polynomial in all quantities of interest.
A very recent result of Wang and Chen [32] removes the 1/p∗ factor in [8] for the tabular case and
n)  which in the tabular complete graph case improves over

presents a worst-case bound of (cid:101)O(L|E|√
our result by (cid:101)O(L). On the other hand  their analysis does not give structural guarantees that we

provide with maximum observed relevance C∗ obtaining potentially much better results for the case
in hand and giving insights for the complexity of IM bandits. Moreover  both Chen et al. [8] and
Wang and Chen [32] do not consider generalization models across edges or nodes  and therefore
their proposed algorithms are unlikely to be practical for real-world social networks. In contrast  our
proposed algorithm scales to large problems by exploiting linear generalization across edges.
IM bandits for different inﬂuence models and settings: There exist a number of extensions and
related results for IM bandits. We only mention the most related ones (see [28] for a recent survey).
Vaswani et al. [31] proposed a learning algorithm for a different and more challenging feedback
model  where the learning agent observes inﬂuenced nodes but not the edges  but they do not give
any guarantees. Carpentier and Valko [5] give a minimax optimal algorithm for IM bandits but only
consider a local model of inﬂuence with a single source and a cascade of inﬂuences never happens.
In related networked bandits [11]  the learner chooses a node and its reward is the sum of the rewards
of the chosen node and its neighborhood. The problem gets more challenging when we allow the
inﬂuence probabilities to change [2]  when we allow the seed set to be chosen adaptively [30]  or
when we consider a continuous model [12]. Furthermore  Sigla et al. [26] treats the IM setting with an
additional observability constraints  where we face a restriction on which nodes we can choose at each
round. This setting is also related to the volatile multi-armed bandits where the set of possible arms
changes [4]. Vaswani et al. [29] proposed a diffusion-independent algorithm for IM semi-bandits with
a wide range of diffusion models  based on the maximum-reachability approximation. Despite its
wide applicability  the maximum reachability approximation introduces an additional approximation
factor to the scaled regret bounds. As they have discussed  this approximation factor can be large in
some cases. Lagrée et al. [20] treat a persistent extension of IM bandits when some nodes become
persistent over the rounds and no longer yield rewards. This work is also a generalization and
extension of recent work on cascading bandits [17  18  34]  since cascading bandits can be viewed as
variants of online inﬂuence maximization problems with special topologies (chains).

Acknowledgements The research presented was supported by French Ministry of Higher Education and
Research  Nord-Pas-de-Calais Regional Council and French National Research Agency projects ExTra-Learn
(n.ANR-14-CE24-0010-01) and BoB (n.ANR-16-CE23-0003). We would also like to thank Dr. Wei Chen and
Mr. Qinshi Wang for pointing out a mistake in an earlier version of this paper.

9

References
[1] Yasin Abbasi-Yadkori  Dávid Pál  and Csaba Szepesvári.

stochastic bandits. In Neural Information Processing Systems  2011.

Improved algorithms for linear

[2] Yixin Bao  Xiaoke Wang  Zhi Wang  Chuan Wu  and Francis C. M. Lau. Online inﬂuence
maximization in non-stationary social networks. In International Symposium on Quality of
Service  apr 2016.

[3] Nicola Barbieri  Francesco Bonchi  and Giuseppe Manco. Topic-aware social inﬂuence propa-

gation models. Knowledge and information systems  37(3):555–584  2013.

[4] Zahy Bnaya  Rami Puzis  Roni Stern  and Ariel Felner. Social network search as a volatile

multi-armed bandit problem. Human Journal  2(2):84–98  2013.

[5] Alexandra Carpentier and Michal Valko. Revealing graph bandits for maximizing local inﬂuence.

In International Conference on Artiﬁcial Intelligence and Statistics  2016.

[6] Wei Chen  Chi Wang  and Yajun Wang. Scalable inﬂuence maximization for prevalent viral

marketing in large-scale social networks. In Knowledge Discovery and Data Mining  2010.

[7] Wei Chen  Yajun Wang  and Yang Yuan. Combinatorial multi-armed bandit: General framework 

results and applications. In International Conference on Machine Learning  2013.

[8] Wei Chen  Yajun Wang  and Yang Yuan. Combinatorial multi-armed bandit and its extension to

probabilistically triggered arms. Journal of Machine Learning Research  17  2016.

[9] Varsha Dani  Thomas P Hayes  and Sham M Kakade. Stochastic linear optimization under

bandit feedback. In Conference on Learning Theory  2008.

[10] David Easley and Jon Kleinberg. Networks  Crowds  and Markets: Reasoning About a Highly

Connected World. Cambridge University Press  2010.

[11] Meng Fang and Dacheng Tao. Networked bandits with disjoint linear payoffs. In International

Conference on Knowledge Discovery and Data Mining  2014.

[12] Mehrdad Farajtabar  Xiaojing Ye  Sahar Harati  Le Song  and Hongyuan Zha. Multistage

campaigning in social networks. In Neural Information Processing Systems  2016.

[13] M Gomez Rodriguez  B Schölkopf  Langford J Pineau  et al.

Inﬂuence maximization in
continuous time diffusion networks. In International Conference on Machine Learning  2012.

[14] Amit Goyal  Francesco Bonchi  and Laks VS Lakshmanan. Learning inﬂuence probabilities in
social networks. In Proceedings of the third ACM international conference on Web search and
data mining  pages 241–250. ACM  2010.

[15] Aditya Grover and Jure Leskovec. node2vec: Scalable feature learning for networks.

Knowledge Discovery and Data Mining. ACM  2016.

In

[16] David Kempe  Jon Kleinberg  and Éva Tardos. Maximizing the spread of inﬂuence through a

social network. Knowledge Discovery and Data Mining  page 137  2003.

[17] Branislav Kveton  Csaba Szepesvari  Zheng Wen  and Azin Ashkan. Cascading bandits:
Learning to rank in the cascade model. In Proceedings of the 32nd International Conference on
Machine Learning  2015.

[18] Branislav Kveton  Zheng Wen  Azin Ashkan  and Csaba Szepesvari. Combinatorial cascading
bandits. In Advances in Neural Information Processing Systems 28  pages 1450–1458  2015.

[19] Branislav Kveton  Zheng Wen  Azin Ashkan  and Csaba Szepesvari. Tight regret bounds for
stochastic combinatorial semi-bandits. In Proceedings of the 18th International Conference on
Artiﬁcial Intelligence and Statistics  2015.

[20] Paul Lagrée  Olivier Cappé  Bogdan Cautis  and Silviu Maniu. Effective large-scale online

inﬂuence maximization. In International Conference on Data Mining  2017.

10

[21] Siyu Lei  Silviu Maniu  Luyi Mo  Reynold Cheng  and Pierre Senellart. Online inﬂuence

maximization. In Knowledge Discovery and Data mining  2015.

[22] Jure Leskovec and Andrej Krevl. Snap datasets: Stanford large network dataset collection.

http://snap.stanford.edu/data  jun 2014.

[23] Yanhua Li  Wei Chen  Yajun Wang  and Zhi-Li Zhang. Inﬂuence diffusion dynamics and inﬂu-
ence maximization in social networks with friend and foe relationships. In ACM international
conference on Web search and data mining. ACM  2013.

[24] Praneeth Netrapalli and Sujay Sanghavi. Learning the graph of epidemic cascades. In ACM

SIGMETRICS Performance Evaluation Review  volume 40  pages 211–222. ACM  2012.

[25] Kazumi Saito  Ryohei Nakano  and Masahiro Kimura. Prediction of information diffusion
probabilities for independent cascade model. In Knowledge-Based Intelligent Information and
Engineering Systems  pages 67–75  2008.

[26] Adish Singla  Eric Horvitz  Pushmeet Kohli  Ryen White  and Andreas Krause. Information
gathering in networks via active exploration. In International Joint Conferences on Artiﬁcial
Intelligence  2015.

[27] Youze Tang  Xiaokui Xiao  and Shi Yanchen. Inﬂuence maximization: Near-optimal time

complexity meets practical efﬁciency. 2014.

[28] Michal Valko. Bandits on graphs and structures. habilitation  École normale supérieure de

Cachan  2016.

[29] Sharan Vaswani  Branislav Kveton  Zheng Wen  Mohammad Ghavamzadeh  Laks VS Laksh-
manan  and Mark Schmidt. Model-independent online learning for inﬂuence maximization. In
International Conference on Machine Learning  2017.

[30] Sharan Vaswani and Laks V. S. Lakshmanan. Adaptive inﬂuence maximization in social

networks: Why commit when you can adapt? Technical report  2016.

[31] Sharan Vaswani  Laks. V. S. Lakshmanan  and Mark Schmidt. Inﬂuence maximization with

bandits. In NIPS workshop on Networks in the Social and Information Sciences 2015  2015.

[32] Qinshi Wang and Wei Chen. Improving regret bounds for combinatorial semi-bandits with
probabilistically triggered arms and its applications. In Neural Information Processing Systems 
mar 2017.

[33] Zheng Wen  Branislav Kveton  and Azin Ashkan. Efﬁcient learning in large-scale combinatorial

semi-bandits. In International Conference on Machine Learning  2015.

[34] Shi Zong  Hao Ni  Kenny Sung  Nan Rosemary Ke  Zheng Wen  and Branislav Kveton. Cascad-
ing bandits for large-scale recommendation problems. In Uncertainty in Artiﬁcial Intelligence 
2016.

11

,Andrew Dai
Quoc Le
Zheng Wen
Branislav Kveton
Michal Valko
Sharan Vaswani
Gedas Bertasius
Christoph Feichtenhofer
Du Tran
Jianbo Shi
Lorenzo Torresani