2018,Computationally and statistically efficient learning of causal Bayes nets using path queries,Causal discovery from empirical data is a fundamental problem in many scientific domains. Observational data allows for identifiability only up to Markov equivalence class. In this paper we first propose a polynomial time algorithm for learning the exact correctly-oriented structure of the transitive reduction of any causal Bayesian network with high probability  by using interventional path queries. Each path query takes as input an origin node and a target node  and answers whether there is a directed path from the origin to the target. This is done by intervening on the origin node and observing samples from the target node. We theoretically  show the logarithmic sample complexity for the size of interventional data per path query  for continuous and discrete networks. We then show how to learn the transitive edges using also logarithmic sample complexity (albeit in time exponential in the maximum number of parents for discrete networks)  which allows us to learn the full network. We further extend our work by reducing the number of interventional path queries for learning rooted trees. We also provide an analysis of imperfect interventions.,Computationally and statistically efﬁcient learning of

causal Bayes nets using path queries

Department of Computer Science

Department of Computer Science

Jean Honorio

Purdue University

West Lafayette  IN  USA
jhonorio@purdue.edu

Kevin Bello

Purdue University

West Lafayette  IN  USA
kbellome@purdue.edu

Abstract

Causal discovery from empirical data is a fundamental problem in many scien-
tiﬁc domains. Observational data allows for identiﬁability only up to Markov
equivalence class. In this paper we ﬁrst propose a polynomial time algorithm
for learning the exact correctly-oriented structure of the transitive reduction of
any causal Bayesian network with high probability  by using interventional path
queries. Each path query takes as input an origin node and a target node  and
answers whether there is a directed path from the origin to the target. This is done
by intervening on the origin node and observing samples from the target node. We
theoretically show the logarithmic sample complexity for the size of interventional
data per path query  for continuous and discrete networks. We then show how
to learn the transitive edges using also logarithmic sample complexity (albeit in
time exponential in the maximum number of parents for discrete networks)  which
allows us to learn the full network. We further extend our work by reducing the
number of interventional path queries for learning rooted trees. We also provide an
analysis of imperfect interventions.

1

Introduction

Motivation. Scientists in diverse areas (e.g.  epidemiology  economics  etc.) aim to unveil causal
relationships within variables from collected data. For instance  biologists try to discover the causal
relationships between genes. By providing a speciﬁc treatment to a particular gene (origin)  one can
observe whether there is an effect in another gene (target). This effect can be either direct (if the two
genes are connected with a directed edge) or indirect (if there is a directed path from the origin to the
target gene).
Bayesian networks (BNs) are powerful representations of joint probability distributions. BNs are also
used to describe causal relationships among variables [14]. The structure of a causal BN (CBN) is
represented by a directed acyclic graph (DAG)  where nodes represent random variables  and an edge
between two nodes X and Y (i.e.  X → Y ) represents that the former (X) is a direct cause of the
latter (Y ). Learning the DAG structure of a CBN is of much relevance in several domains  and is a
problem that has long been studied during the last decades.
From observational data alone (i.e.  passively observed data from an undisturbed system)  DAGs
are only identiﬁable up to Markov equivalence.1 However  since our goal is causal discovery  this
is inadequate as two BNs might be Markov equivalent and yet make different predictions about the

1Two graphs are Markov equivalent if they imply the same set of (conditional) independences. In general 
two graphs are Markov equivalent iff they have the same structure ignoring arc directions  and have the same v-
structures [31]. (A v-structure consists of converging directed edges into the same node  such as X → Y ← Z.)

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

consequences of interventions (e.g.  X ← Y and X → Y are Markov equivalent  but make very
different assertions about the effect of changing X on Y ). In general  the only way to distinguish
causal graphs from the same Markov equivalence class is to use interventional data [10  11  19]. This
data is produced after performing an experiment (intervention) [21]  in which one or several random
variables are forced to take some speciﬁc values  irrespective of their causal parents.

Related work. Several methods have been proposed for learning the structure of Bayesian networks
from observational data. Approaches ranging from score-maximizing heuristics  exact exponential-
time score-maximizing  ordering-based search methods using MCMC  and test-based methods have
been developed to name a few. The umbrella of tools for structure learning of Bayesian networks
go from exact methods (exponential-time with convergence/consistency guarantees) to heuristics
methods (polynomial-time without any convergence/consistency guarantee). [12] provide a score-
maximizing algorithm that is likelihood consistent  but that needs super-exponential time. [27  3]
provide polynomial-time test-based methods that are structure consistent  but results hold only in
the inﬁnite-sample limit (i.e.  when given an inﬁnite number of samples). [5] show that greedy hill-
climbing is structure consistent in the inﬁnite sample limit  with unbounded time. [34] show structure
consistency of a single network and do not provide uniform consistency for all candidate networks (the
authors discuss the issue of not using the union bound in their manuscript). From the active learning
literature  most of the works ﬁrst ﬁnd a Markov equivalence class (or assume that they have one)
from purely observational data and then orient the edges by using as few interventions as possible.
[19  28] propose an exponential-time Bayesian approach relying on structural priors and MCMC.
[10  11  25] present methods to ﬁnd an optimal set of interventions in polynomial time for a class of
chordal DAGs. Unfortunately  ﬁnding the initial Markov equivalence class remains exponential-time
for general DAGs [4  21]. [7] propose an exponential-time dynamic programming algorithm for
learning DAG structures exactly. [29] propose a constraint-based method to combine heterogeneous
(observational and interventional) datasets but rely on solving instances of the (NP-hard) boolean
satisﬁability problem. [8] analyzed the number of interventions sufﬁcient and in the worst-case
necessary to determine the structure of any DAG  although no algorithm or sample complexity
analysis was provided. Literature on learning structural equation models from observational data 
include the work on continuous [23  26] and discrete [22] additive noise models. Correctness was
shown for the continuous case [23] but only in the inﬁnite-sample limit. [13] propose a method to
learn the exact observable graph by using O(log n) multiple-vertex interventions  where n is the
number of variables  through the use of pairwise conditional independence test and assuming access
to the post-interventional graph. However the size of the intervened set is O(n/2) which leads to a
O(2n/2) number of experiments in the worst case. In contrast to this work  we perform single-vertex
interventions as a ﬁrst step and then multiple-vertex interventions while keeping a small sample
complexity. While this increments the number of interventions to n  we have a better control of the
number of experiments.
Remark 1. In this paper we consider one intervention as one selection of variables to intervene.
However  we consider an experiment as the actual setting of values to the variables. For example  if a
variable X takes p different values  then one experiment is X taking one speciﬁc value. To intervene
one binary variable  it is common to make 2 experiments  one under treatment  and one under no
treatment.

For a discussion of learning from purely interventional data  as well as availability of purely interven-
tional data  see Appendix A.

Contributions. We propose a polynomial time algorithm with provable guarantees for exact learn-
ing of the transitive reduction of any CBN by using interventional path queries. We emphasize that
modeling the problem of structure learning of CBNs as a problem of reconstructing a graph using
path queries is also part of our contributions. We analyze the sample complexity for answering
every interventional path query and show that for CBNs of discrete random variables with maximum
domain size r  the sample complexity is O(log(nr)); whereas for CBNs of sub-Gaussian random
variables  the sample complexity is O(σ2
ub is an upper bound of the variable vari-
ances (marginally as well as after interventions). Then  we introduce a new type of query to learn the
transitive edges (i.e.  the edges that are part of the true network but not of the transitive reduction) 
while the learning is not in polynomial-time for discrete CBNs in the worst case (exponential in the
maximum number of parents)  we show that the sample complexity is still polynomial. We also
present two extensions: for learning rooted trees the number of path queries is reduced to O(n log n) 

ub log n) where σ2

2

which is an improvement from the n2 for general DAGs. We also provide an analysis of imperfect
interventions. We summarize our main results in Table 1 and compare them to one of the closest
related work [13].

Table 1: Here n is the number of variables  σ2
ub is an upper bound of the variable variances (marginally
as well as after interventions)  t is the maximum number of parents  r is the maximum number of
values a discrete variable can take  and B denotes the time complexity of an independence-test
oracle. Note that B ∈ O(2n) in the worst case and not O(2t) because [13] can select an intervention
set of n/2 nodes (see for example Appendix F.2). In this table  novel indicates that no prior work
provided results on the respective subject. Finally  C and D denote continuous and discrete variables
respectively.

Graph

Var.

Algorithms

Sample complexity

General
DAGs

Rooted trees

D

C
D

1  5  3  7 (our work) O(n22t log(nr)) (Novel  see Thms. 1  3)

1  3 in [13]

1  6  3  8 (our work)

See Section 4

-

O(n2σ2
ub log n) (Novel  see Thms. 2  4)
O(n log2(nr)) (Novel  see Section 4)

O(Btn2 log2 n) (B ∈ O(2n))

Time complexity
O(n22t log(nr))
O(n2σ2
ub log n)
O(n log2(nr))

Graph

Var.

Algorithms

# of interventions

# of experiments

General
DAGs

Rooted trees

D
C
D

1  5  3  7 (our work)

1  3 in [13]

1  6  3  8 (our work)

See Section 4

O(n2)
O(log n)
O(n2)
O(n)

O(2n log n) (see Appendix F.2.)

O(n22t)
O(n2)
O(nr)

2 Preliminaries

In this section  we introduce our formal deﬁnitions and notations. Vectors and matrices are
denoted by lowercase and uppercase bold faced letters respectively. Random variables are de-
noted by italicized uppercase letters and their values by lowercase italicized letters. Vector
(cid:96)p-norms are denoted by (cid:107)·(cid:107)p. For matrices  (cid:107)·(cid:107)p q denotes the entrywise (cid:96)p q norm  i.e.  for
(cid:107)A(cid:107)p q = (cid:107)((cid:107)(A1 1  . . .   Am 1)(cid:107)p  . . .  (cid:107)(A1 n  . . .   Am n)(cid:107)p)(cid:107)q.
Let G = (V  E) be directed acyclic graph (DAG) with vertex set V = {1  . . .   n} and edge set
E ⊂ V × V  where (i  j) ∈ E implies the edge i → j. For a node i ∈ V  we denote πG(i) as the
parent set of the node i. In addition  a directed path of length k from node i to node j is a sequence
of nodes (i  v1  v2  . . .   vk−1  j) such that {(i  v1)  (v1  v2)  . . .   (vk−2  vk−1)  (vk−1  j)} is a subset
of the edge set E.
Let X = {X1  . . .   Xn} be a set of random variables  with each variable Xi taking values in some
domain Dom[Xi]. A Bayesian network (BN) over X is a pair B = (G PG) that represents a
distribution over the joint space of X. Here  G is a DAG  whose nodes correspond to the random
variables in X and whose structure encodes conditional independence properties about the joint
distribution  while PG quantiﬁes the network by specifying the conditional probability distributions
(CPDs) P (Xi|X πG(i)). We use X πG(i) to denote the set of random variables which are parents of
Xi. A Bayesian network represents a joint probability distribution over the set of variables X  i.e. 

P (X1  . . .   Xn) =(cid:81)n

i=1 P (Xi|X πG(i)).

Viewed as a probabilistic model  a BN can answer any “conditioning” query of the form P (Z|E = e)
where Z and E are sets of random variables and e is an assignment of values to E. Nonetheless  a
BN can also be viewed as a causal model or causal BN (CBN) [21]. Under this perspective  the CBN
can also be used to answer interventional queries  which specify probabilities after we intervene in the
model  forcibly setting one or more variables to take on particular values. The manipulation theorem
[27  21] states that one can compute the consequences of such interventions (perfect interventions) by
“cutting” all the arcs coming into the nodes which have been clamped by intervention  and then doing
typical probabilistic inference in the “mutilated” graph (see Figure 1 as an example). We follow the
standard notation [21] for denoting the probability distribution of a variable Xj after intervening
Xi  that is  P (Xj|do(Xi = xi)). In this case  the joint distribution after intervention is given by

P (X1  . . .   Xi−1  Xi+1  . . .   Xn|do(Xi = xi)) = 1[Xi = xi](cid:81)

j(cid:54)=i P (Xj|X πG(j)).

We refer to CBNs in which all random variables Xi have ﬁnite domain  Dom[Xi]  as discrete CBNs.
In this case  we will denote the probability mass function (PMF) of a random variable as a vector.

3

1

2

3

4

5

2

1

x4
4

3

5

6

6

Figure 1: (Left) A CBN of 6 variables  where the joint distribution  P (X)  is factorized as(cid:81)
x4](cid:81)

i P (Xi|X πG(i)).
(Right) The mutilated CBN after intervening X4 with value x4. Note that the edges {(1  4)  (2  4)} are
not part of the CBN after the intervention  thus  the new joint is P (X|do(X4 = x4)) = 1[X4 =

i(cid:54)=4 P (Xi|X πG(i)).

That is  a PMF  P (Y )  can be described as a vector p(Y ) ∈ [0  1]|Dom[Y ]| indexed by the elements
of Dom[Y ]  i.e.  pj(Y ) = P (Y = j) ∀j ∈ Dom[Y ]. We refer to networks with variables that have
continuous domains as continuous CBNs.
Next  we formally deﬁne transitive edges.
Deﬁnition 1 (Transitive edge). Let G = (V  E) be a DAG. We say that an edge (i  j) ∈ E is transitive
if there exists a directed path from i to j of length greater than 1.

The algorithm for removing transitive edges from a DAG is called transitive reduction and it was
introduced in [1]. The transitive reduction of a DAG G  TR(G)  is then G without any of its transitive
edges. Our proposed methods also make use of path queries  which we deﬁne as follows:
Deﬁnition 2 (Path query). Let G = (V  E) be a DAG. A path query is a function QG : V × V →
{0  1} such that QG(i  j) = 1 if there exists a directed path in G from i to j  and QG(i  j) = 0
otherwise.

General DAGs are identiﬁable only up to their transitive reduction by using path queries.
In
general  DAGs can be non-identiﬁable by using path queries. We will use Q(i  j) to denote QG(i  j)
since for our problem  the DAG G is ﬁxed (but unknown). For instance  consider the two graphs
shown in Figure 2. In both cases  we have that Q(1  2) = Q(1  3) = Q(2  3) = 1. Thus  by using
path queries  it is impossible to discern whether the edge (1  3) exists or not. Later in Subsection 3.3
we focus on the recovery of transitive edges  which requires a different type of query.

1

1

2

3

2

3

Figure 2: Two directed acyclic graphs that produce the same answers when using path queries.

How to answer path queries is a key step in this work. Since we answer path queries by using a ﬁnite
number of interventional samples  we require a noisy path query  which is deﬁned below.
Deﬁnition 3 (δ-noisy partially-correct path query). Let G = (V  E) be a DAG  and let QG be a path
query. Let δ ∈ (0  1) be a probability of error. A δ-noisy partially-correct path query is a function
˜QG : V × V → {0  1} such that ˜QG(i  j) = QG(i  j) with probability at least 1 − δ if i ∈ πG(j) or
if there is no directed path from i to j.

We will use the term noisy path query to refer to δ-noisy partially-correct path query. Note that
Deﬁnition 3 requires a noisy path query to be correct only in certain cases  when one variable is
parent of the other  or when there is no directed path between them. We do not require correctness
when there is a directed path between i and j and i is not a parent of j  that is  when the path length
is greater than 1. Note that the uncertainty of the exact recovery of the transitive reduction relies on
answering multiple noisy path queries.

2.1 Assumptions

Here we state the main set of assumptions used throughout our paper.
Assumption 1. Let G = (V  E) be a DAG. All nodes in G are observable  furthermore  we can
perform interventions on any node i ∈ V.

4

Assumption 2 (Causal Markov). The data is generated from an underlying CBN (G PG) over X.
Assumption 3 (Faithfulness). The distribution P over X induced by (G PG) satisﬁes no inde-
pendences beyond those implied by the structure of G. We also assume faithfulness in the post-
interventional distribution.

Assumption 1 implies the availability of purely interventional data  and has been widely used in
the literature [19  28  11  10  25  13]. We consider only observed variables because we perform
interventions on each node  thus  our method is robust to latent confounders. (See Appendix E for
more details). With Assumption 2  we assume that any population produced by a causal graph has the
independence relations obtained by applying d-separation to it  while with Assumption 3  we ensure
that the population has exactly these and no additional independences [27  28  25  11  29].

3 Algorithms and Sample Complexity

Next  we present our ﬁrst set of results and provide a formal analysis on the sample complexity.

3.1 Algorithm for Learning the Transitive Reduction of CBNs
[13] show that by using O (log n) multiple-vertex interventions  one can recover the transitive
reduction of a DAG. However  in this case  each set of intervened variables has a size of O(n/2) 
which means that the method of [13] has to perform a total of O(2n/2 log n) experiments  one for
each possible setting of the O(n/2) intervened variables (see an example of this in Appendix D). Thus 
in this part we work with single-vertex interventions to avoid the exponential number of experiments.
We can then learn the transitive reduction as follows (see mote details in Appendix B.1).
Algorithm 1. Start with a set of edges ˆE = ∅. Then for each pair of nodes i  j ∈ V  compute the
noisy path query ˜Q(i  j) and add the edge (i  j) to ˆE if the query returns 1. Finally  compute the
transitive reduction of ˆE in poly-time [1]  and return ˆE.

As seen in the next section  each query is computed using single-vertex interventions. In fact  for
each intervened node  we can compute n queries  i.e.  while the number of queries is n2  the number
of interventions is n. This number of single-vertex interventions is necessary in the worst case [8].
It is natural to ask what would be the beneﬁt of using path queries. A query ˜Q(i  j) can be interpreted
as observing the variable Xj after intervening Xi. Under this viewpoint  if one could reduce
the number of queries for learning certain classes of graphs  then not only might the number of
interventions decrease but the number of variables to observe too. That is  if one knows a priori that
the topology of the graph belongs to a certain family of graphs then it may be possible to reduce
the number of queries (see for example Section 4). This is important in practice as both performing
interventions and observing variables might be costly. We ﬁrst focus in learning general DAGs  in
which a number of Ω(n2) path queries is in the worst case necessary for any conceivable algorithm.
(See Theorems 7 and 8 in [32]). Later we show that a number of O (n log n) noisy path queries2
sufﬁces for learning rooted trees.

3.2 Noisy Path Query Algorithm

The next two propositions are important for answering a path query.
Proposition 1. Let B = (G PG) be a CBN with Xi  Xj ∈ X being any two random variables in G.
If there is no directed path from i to j in G  then P (Xj|do(Xi = xi)) = P (Xj).
Proposition 2. Let B = (G PG) be a CBN and let Xi and Xj be two random variables in G  such
that i ∈ πG(j). Then  there exists xi and x(cid:48)

i such that:

1. P (Xj) (cid:54)= P (Xj|do(Xi = xi)) and 2. P (Xj|do(Xi = xi)) (cid:54)= P (Xj|do(Xi = x(cid:48)
i))

See Appendix F for details of all proofs. Proposition 2 motivates the idea that we can search
for two different values of Xi to determine the causal dependence on Xj (Claim 2)  which is

2This path query requires a “stronger” version of Deﬁnition 3. See for instance Deﬁnition 6.

5

arguably useful for discrete CBNs. Alternatively  we can use the expected value of Xj  since
E[Xj] (cid:54)= E[Xj|do(Xi = xi)] implies that P (Xj) (cid:54)= P (Xj|do(Xi = xi)) (Claim 1).
Next  we propose a polynomial time algorithm for answering a noisy path query. Algorithm 2 presents
the procedure in an intuitive way. Here  the type of statistic is motivated by Lemmas 1 and 2  and
the value of interventions and threshold t are motivated by Theorems 1 and 2. See Appendix B.2
(Algorithms 5 and 6) for the speciﬁc details of the algorithms for discrete and continuous CBNs.

Algorithm 2 Noisy path query algorithm
Input: Nodes i and j  number of interventional samples m  and threshold t.
Output: ˜Q(i  j)
1: Intervene Xi by setting its value to xi ∈ Dom[Xi]  and observe m samples of Xj
2: Compute a statistic of Xj and return 1 if it is greater than t.

Discrete random variables.
In this paper we use conditional probability tables (CPTs) as the
representation of the CPDs for discrete CBNs. Next  we present a theorem that provides the sample
complexity of a noisy path query.
Theorem 1. Let B = (G PG) be a discrete CBN  such that each random variable Xj has a ﬁnite

domain Dom[Xj]  with(cid:12)(cid:12)Dom[Xj](cid:12)(cid:12) ≤ r. Furthermore  let

(cid:107)p(Xj|do(Xi = xi)) − p(Xj|do(Xi = x(cid:48)

i))(cid:107)∞ 

γ = min
j∈V
i∈πG(j)

xi x(cid:48)

min
i∈Dom[Xi]

p(Xj|do(Xi=xi))(cid:54)=p(Xj|do(Xi=x(cid:48)

and let ˆG = (V  ˆE) be the learned graph by using Algorithm 1. Then for γ > 0 and a ﬁxed probability
of error δ ∈ (0  1)  we have P
interventional samples are used per δ-noisy partially-correct path query in Algorithm 5.

TR(G) = ˆG

(cid:17) ≥ 1 − δ  provided that m ∈ O( 1

(cid:0)ln n + ln r

(cid:1))

(cid:16)

γ2

δ

i))

Intuitively  the value γ characterizes the minimum causal effect among all the pair of parent-child
nodes. Due to Assumption 3  and the fact that an edge represents a causal relationship  we have
γ > 0. This value is used for deciding whether two empirical PMFs are equal or not in our path query
algorithm (Algorithm 5)  which implements Claim 2 in Proposition 2. Finally  in practice  the value
of γ is unknown3. Fortunately  knowing a lower bound of γ sufﬁces for structure recovery.

Continuous random variables. For continuous CBNs  our algorithm compares two empirical
expected values for answering a path query. This is related to Claim 1 in Proposition 2  since
E[Xj] (cid:54)= E[Xj|do(Xi = xi)] implies P (Xj) (cid:54)= P (Xj|do(Xi = xi)). We analyze continuous CBNs
where every random variable is sub-Gaussian. The class of sub-Gaussian variates includes for instance
Gaussian variables  any bounded random variable (e.g.  uniform)  any random variable with strictly
log-concave density  and any ﬁnite mixture of sub-Gaussian variables. Note that sample complexity
using sub-Gaussian variables has been studied in the past for other models  such as Markov random
ﬁelds [24]. Next  we present a theorem that formally characterizes the class of continuous CBNs that
our algorithm can learn  and provides the sample complexity for each noisy path query.
Theorem 2. Let B = (G PG) be a continuous CBN such that each variable Xj is a sub-Gaussian
random variable with full support on R  with mean µj = 0 and variance σ2
j . Let µj|do(Xi=z) and
j|do(Xi=z) denote the expected value and variance of Xj after intervening Xi with value z  assuming
σ2
also that the variables remain sub-Gaussian after performing an intervention. Furthermore  let

µ(B  z) =

min

j∈V i∈πG(j)

(cid:32)

(cid:12)(cid:12)(cid:12)µj|do(Xi=z)
(cid:16)

σ2(B  z) = max

(cid:12)(cid:12)(cid:12)  
(cid:17) ≥ 1 − δ  provided that m ∈ O(σ2

j∈V i∈πG(j)

max

(cid:33)

σ2
j|do(Xi=z)  max
j∈V

σ2
j

 

and let ˆG = (V  ˆE) be the learned graph by using Algorithm 1. If there exist an upper bound σ2
ub and µ(B  z) ≥ 1  then for a ﬁxed probability of error
and a ﬁnite value z such that σ2(B  z) ≤ σ2
ub
δ ∈ (0  1)  we have P
δ ) interventional
samples are used per δ-noisy partially-correct path query in Algorithm 6.

TR(G) = ˆG

ub log n

3Several prior works from leading experts also have ˜O( 1

γ. See for instance  [2  20  24].

6

γ2 ) sample complexity for an unknowable constant

tuple (G P(W S)) where each variable Xi can be written as follows: Xi =(cid:80)

Note that the conditions µj = 0 ∀j ∈ V   and µ(B  z) ≥ 1 are set to offer clarity in the derivations.
One could for instance set an upper bound for the magnitude of µj  assume µ(B  z) to be greater than
this upper bound plus 1  and still have the same sample complexity. Finally  our motivation for giving
such conditions is that of guaranteeing a proper separation of the expected values in cases where
there is effect of a variable Xi over another variable Xj  versus cases where there is no effect at all.
Next  we deﬁne the additive sub-Gaussian noise model (ASGN).
Deﬁnition 4. Let G = (V  E) be a DAG  let W ∈ Rn×n be the matrix of edge weights and let
i ∈ R+|i ∈ V} be the set of noise variances. An additive sub-Gaussian noise network is a
S = {σ2
j∈πG(i) WijXj +
Ni  ∀i ∈ V  with Ni being an independent sub-Gaussian noise with full support on R  with zero
mean and variance σ2
Remark 2. Let B = (G P(W S)) be an ASGN network. We can rewrite the model in vector form as:
x = Wx + n or equivalently x = (I − W)−1n  where x = (X1  . . .   Xn) and n = (N1  . . .   Nn)
are the vector of random variables and the noise vector respectively. Additionally  we denote (cid:12)iW as
the weight matrix W with its i-th row set to 0. This means that we can interpret (cid:12)iW as the weight
matrix after performing and intervention on node i (mutilated graph).

i for all i ∈ V  and Wij (cid:54)= 0 iff (j  i) ∈ E.

We now present a corollary that fulﬁlls the conditions presented in Theorem 2.
Corollary 1 (Additive sub-Gaussian noise model). Let B = (G P(W S)) be an ASGN network
max ∀j ∈ V. Also  let wmin = min(i j)∈E |{(I − (cid:12)iW)−1}ji| 
as in Deﬁnition 4  such that σ2
and wmax = max((cid:107)(I − W)−1(cid:107)2∞ 2  maxi∈V(cid:107)(I − (cid:12)iW)−1(cid:107)2∞ 2). If z = 1/wmin and σ2
ub =
maxwmax  then for a ﬁxed probability of error δ ∈ (0  1)  we have P (TR(G) = ˆG) ≥ 1 − δ.
σ2
Where ˆG = (V  ˆE) is the learned graph by using Algorithm 1  and provided that m ∈ O(σ2
ub log n
δ )
interventional samples are used per δ-noisy partially-correct path query in Algorithm 6.

j ≤ σ2

The values of wmin and wmax follow the speciﬁcations of Theorem 2. In addition  the value of wmin
is guaranteed to be greater than 0 because of the faithfulness assumption (see Assumption 3). For an
example about our motivation to use the faithfulness assumption  see Appendix D.

3.3 Recovery of Transitive Edges

In this section  we show a method to recover the transitive edges by using multiple-vertex interventions.
This allows us to learn the full network. For this purpose  we present a new query deﬁned as follows.
Deﬁnition 5 (δ-noisy transitive query). Let G = (V  E) be a DAG  and let δ ∈ (0  1) be a probability
of error. A δ-noisy transitive query is a function ˜TG : V× V× 2V → {0  1} such that ˜TG(i  j  S) = 1
with probability at least 1 − δ if (i  j) ∈ E is a transitive edge (where the additional path from i to j
goes through S)  and 0 otherwise. Here S ⊆ πG(j) is an auxiliary set necessary to answer the query 
in order to block any inﬂuence from i to S  and to unveil the direct effect from i to j.

Algorithms 7 and 8 (see Appendix B.3) show how to answer a transitive query for discrete and
continuous CBNs respectively. Both algorithms are motivated on a property of CBNs  that is  ∀i ∈ V
and for every set S disjoint of {i  πG(i)}  we have P (Xi|do(XπG(i) = xπG(i))  do(XS = xS)) =
P (Xi|do(XπG(i) = xπG(i))). Thus  both algorithms intervene all the variables in S  if S is the parent
set of j  then i will have no effect on j and they return 0  and 1 otherwise.
Recall that by using Algorithm 1 we obtain the transitive reduction of the CBN  thus  we have the true
topological ordering of the CBN  and also for each node i ∈ V  we know its parent set or a subset
of it. Using these observations  we can cleverly set the input i  j  and S of a noisy transitive query 
as done in Algorithm 3. It is clear that Algorithm 3 makes O(n2) noisy transitive queries in total.
The time complexity to answer a transitive query for a discrete CBN is exponential in the maximum
number of parents in the worst case. However  the sample complexity for queries in discrete and
continuous CBNs remains polynomial in n as prescribed in the following theorems.
Theorem 3. Let B = (G PG) be a discrete CBN  such that each random variable Xj has a ﬁnite

domain Dom[Xj]  with(cid:12)(cid:12)Dom[Xj](cid:12)(cid:12) ≤ r. Furthermore  let

γ = min
j∈V

S⊆πG(j) |S|≥1

p(Xj|do(XS=xS))(cid:54)=p(Xj|do(XS=x(cid:48)

S))

min

xS x(cid:48)

S∈×i∈SDom[Xi]

(cid:107)p(Xj|do(XS = xS))−p(Xj|do(XS = x(cid:48)

S))(cid:107)∞ 

7

Algorithm 3 Learning the transitive edges by using noisy transitive queries
Input: Transitively reduced DAG ˆG = (V  ˆE) (output of Algorithm 1)
Output: DAG ˜G = (V  ˜E)
1: Ψ ← TopologicalOrder( ˆG); ˆπ(i) ← {u ∈ V|(u  i) ∈ ˆE} (current parents of i); ˜E ← ˆE
2: for j = 2 . . . n do
3:
4:

if ˜T (Ψi  Ψj  ˆπ(Ψj)) = 1 then ˜E ← ˜E ∪ {(Ψi  Ψj)} and ˆπ(Ψj) ← ˆπ(Ψj) ∪ Ψi

for i = j − 1  j − 2  . . . 1 do

(cid:32)

(cid:33)

(cid:16)

(cid:17) ≥ 1 − δ  provided that m ∈ O( 1

G = ˜G

and let ˜G = (V  ˜E) be the output of Algorithm 3. Then for γ > 0 and a ﬁxed probability of error
δ ∈ (0  1)  we have P
samples are used per δ-noisy transitive query in Algorithm 7.
Theorem 4. Let B = (G PG) be a continuous CBN such that each variable Xj is a sub-Gaussian
random variable with full support on R  with mean µj = 0 and variance σ2
j . Let µj|do(XS=1z) and
j|do(XS=1z) denote the expected value and variance of Xj after intervening each node of XS with
σ2
value z. Furthermore  let
µ(B  z1  z2) =

(cid:12)(cid:12)(cid:12)µj|do(XS−{i}=1z1 Xi=z2)

(cid:12)(cid:12)(cid:12)  

min

j∈V S⊆πG(j) |S|≥2 i∈S

γ2

(cid:0)ln n + ln r

(cid:1)) interventional

δ

σ2(B  z1  z2) = max

max
j∈V

σ2
j  

max

j∈V S⊆πG(j) |S|≥2 i∈S

σ2
j|do(XS−{i}=1z1 Xi=z2)

 

and let ˜G = (V  ˜E) be the output of Algorithm 3. If there exist an upper bound σ2
values z1  z2 such that σ2(B  z1  z2) ≤ σ2
δ ∈ (0  1)  we have P
are used per δ-noisy transitive query in Algorithm 8.

ub and ﬁnite
ub and µ(B  z1  z2) ≥ 1  then for a ﬁxed probability of error
δ ) interventional samples

(cid:17) ≥ 1 − δ  provided that m ∈ O(σ2

ub log n

G = ˜G

(cid:16)

Next  we show that ASGN networks can fulﬁll the conditions in Theorem 4.
Corollary 2. Let B = (G P(W S))  and σ2
max follow the same deﬁnition as in Corollary 1. Let
wmin = minij |Wij|  and wmax = max((cid:107)(I − W)−1(cid:107)2∞ 2  maxj∈V S⊆πG(j)(cid:107)(I − (cid:12)SW)−1(cid:107)2∞ 2).
maxwmax  then for a ﬁxed probability of error δ ∈ (0  1)  we
If z1 = 0  z2 = 1/wmin  and σ2
have P (G = ˜G) ≥ 1 − δ  provided that m ∈ O(σ2
δ ) interventional samples are used per
δ-noisy transitive query in Algorithm 8.

ub = σ2

ub log n

4 Extensions

δ

1

1

(1/2−)2 n log dn

(1/2−)2 dn log2 n log dn

Learning rooted trees. Here we make use of the results in [32]  for rooted trees of node degree
at most d. Theorem 4 in [32] states that for a ﬁxed probability error δ ∈ (0  1)  one can reconstruct
a rooted tree with probability 1 − δ in O( 1
δ ) time provided that a total of
O(
δ ) noisy path queries are used  where  relates to the conﬁdence of the noisy path
query. The number of queries is improved with respect to the n2 queries used for general DAGs in
the previous section. Finally  recall that in the previous section we made use of partially-correct path
queries  for this part we require a stronger version of noisy path query  which is deﬁned below.
Deﬁnition 6 (-noisy path query). Let G = (V  E) be a DAG  and let QG be a path query. Let
 ∈ (0  1/2) be a probability of error. A -noisy path query is a function ˜QG : V × V → {0  1}
such that ˜QG(i  j) = QG(i  j) with probability at least 1 −   and ˜QG(i  j) = 1 − QG(i  j) with
probability at most .

The following states the sample complexity for exact learning of rooted trees in the discrete case.
Proposition 3. Let B = (G PG) be a discrete CBN  such that each random variable Xj has a ﬁnite

domain Dom[Xj]  with(cid:12)(cid:12)Dom[Xj](cid:12)(cid:12) ≤ r. Furthermore  let

8

γ = min
j∈V
i∈V

xi x(cid:48)

min
i∈Dom[Xi]

p(Xj|do(Xi=xi))(cid:54)=p(Xj|do(Xi=x(cid:48)

i))

(cid:107)p(Xj|do(Xi = xi)) − p(Xj|do(Xi = x(cid:48)

i))(cid:107)∞ 

and let ˆG = (V  ˆE) be the learned graph by using Algorithm 7 in [32]. Then for γ > 0 and a ﬁxed
probability of error δ ∈ (0  1)  we have P
interventional samples are used per δ-noisy path query in Algorithm 5.

G = ˆG

γ2

δ

(cid:17) ≥ 1−δ  provided that m ∈ O( 1

(cid:0)ln n + ln r

(cid:1))

(cid:16)

We use the same Algorithm 5 to answer a -noisy path query. The difference is that now γ represents
the minimum causal effect among all pair nodes and not only parent-child nodes.

On Imperfect Interventions. Here we state some results on imperfect interventions. In Appendix
C  we show that the sample complexity for discrete CBNs is scaled by α−1  where α accounts for the
degree of uncertainty in the intervention. While for CBNs of sub-Gaussian random variables  the
sample complexity still has the same dependence on an upper bound of the variances.

5 Experiments

In Appendix G.1  we tested our algorithms for perfect and imperfect interventions in synthetic
networks  in order to empirically show the logarithmic phase transition of the number of interventional
samples (see Figure 3 as an example). Appendix G.2 shows that in several benchmark BNs  most
of the graph belongs to its transitive reduction  meaning that one can learn most of the network in
polynomial time. Appendix G.3 shows experiments on some of these benchmark networks  using the
aforementioned algorithms and also our algorithm for learning transitive edges  thus recovering the
full networks. Finally  in Appendix G.4  as an illustration of the availability of interventional data 
we show experimental evidence using three gene perturbation datasets from [33  9].

Figure 3:
(Left) Probability of correct structure recovery of the transitive reduction of a discrete CBN vs.
number of samples per query  where the latter was set to eC log nr  with all CBNs having r = 5 and γ ≥ 0.01.
(Right) Similarly  for continuous CBNs  the number of samples per query was set to eC log n  with all CBNs
2 ∞ ≤ 20. Finally  we observe that there is a sharp phase transition from recovery failure
having (cid:107)(I − W)−1(cid:107)2
to success in all cases  and the log n scaling holds in practice  as prescribed by Theorems 1  2.

6 Future Work

There are several ways of extending this work. For instance  it would be interesting to analyze other
classes of interventions with uncertainty  as in [7]. For continuous CBNs  we opted to use expected
values and not to compare continuous distributions directly. The fact that the conditioning is with
respect to a continuous random variable makes this task more complex than the typical comparison
of continuous distributions. Still  it would be interesting to see whether kernel density estimators [16]
could be beneﬁcial.

References
[1] Aho  A.  Garey  M.  and Ullman  J. The transitive reduction of a directed graph. SIAM Journal

on Computing  1(2):131–137  1972.

9

024681012141600.20.40.60.81012345678900.20.40.60.81[2] Brenner  E. and Sontag  D. SparsityBoost: A new scoring function for learning Bayesian

network structure. UAI  2013.

[3] Cheng  J.  Greiner  R.  Kelly  J.  Bell  D.  and Liu  W. Learning Bayesian networks from data:

An information-theory based approach. Artiﬁcial Intelligence Journal  2002.

[4] Chickering  D. Learning Bayesian networks is NP-complete.

121–130. Springer  1996.

In Learning from data  pp.

[5] Chickering  D. and Meek  C. Finding optimal Bayesian networks. UAI  2002.
[6] Dvoretzky  A.  Kiefer  J.  and Wolfowitz  J. Asymptotic minimax character of the sample
distribution function and of the classical multinomial estimator. The Annals of Mathematical
Statistics  pp. 642–669  1956.

[7] Eaton  D. and Murphy  K. Exact Bayesian structure learning from uncertain interventions. In

Artiﬁcial Intelligence and Statistics  pp. 107–114  2007.

[8] Eberhardt  F.  Glymour  C.  and Scheines  R. On the number of experiments sufﬁcient and in the
worst case necessary to identify all causal relations among N variables. In UAI  pp. 178–184.
AUAI Press  2005.

[9] Harbison  Christopher T  Gordon  D Benjamin  Lee  Tong Ihn  Rinaldi  Nicola J  Macisaac 
Kenzie D  Danford  Timothy W  Hannett  Nancy M  Tagne  Jean-Bosco  Reynolds  David B 
Yoo  Jane  et al. Transcriptional regulatory code of a eukaryotic genome. Nature  2004.

[10] Hauser  A. and Bühlmann  P. Two optimal strategies for active learning of causal models from
interventions. In Proceedings of the 6th European Workshop on Probabilistic Graphical Models 
2012.

[11] He  Y. and Geng  Z. Active learning of causal networks with intervention experiments and

optimal designs. Journal of Machine Learning Research  9(Nov)  2008.

[12] Höffgen  K. Learning and robust learning of product distributions. COLT  1993.
[13] Kocaoglu  Murat  Shanmugam  Karthikeyan  and Bareinboim  Elias. Experimental design for
learning causal graphs with latent variables. In Advances in Neural Information Processing
Systems  pp. 7021–7031  2017.

[14] Koller  D. and Friedman  N. Probabilistic Graphical Models: Principles and Techniques. The

MIT Press  2009.

[15] LeGall  F. Powers of tensors and fast matrix multiplication.

In Proceedings of the 39th
international symposium on symbolic and algebraic computation  pp. 296–303. ACM  2014.
[16] Liu  H.  Wasserman  L.  and Lafferty  J. Exponential concentration for mutual information
estimation with application to forests. In Advances in Neural Information Processing Systems 
pp. 2537–2545  2012.

[17] Louizos  Christos  Shalit  Uri  Mooij  Joris  Sontag  David  Zemel  Richard  and Welling  Max.

Causal effect inference with deep latent-variable models. NIPS  2017.

[18] Massart  P. The tight constant in the Dvoretzky-Kiefer-Wolfowitz inequality. The Annals of

Probability  pp. 1269–1283  1990.

[19] Murphy  K. Active learning of causal Bayes net structure. Technical report  2001.
[20] Obozinski  Guillaume R  Wainwright  Martin J  and Jordan  Michael I. High-dimensional
support union recovery in multivariate regression. In Advances in Neural Information Processing
Systems  2009.

[21] Pearl  J. Causality: Models  Reasoning and Inference. Cambridge University Press  2nd edition 

2009.

[22] Peters  J.  Janzing  D.  and Schölkopf  B. Identifying cause and effect on discrete data using

additive noise models. In AIStats  pp. 597–604  2010.

[23] Peters  J.  Mooij  J.  Janzing  D.  Schölkopf  B.  et al. Causal discovery with continuous additive

noise models. Journal of Machine Learning Research  15(1):2009–2053  2014.

[24] Ravikumar  P.  Wainwright  M.  Raskutti  G.  B.Yu  et al. High-dimensional covariance estima-
tion by minimizing (cid:96)1-penalized log-determinant divergence. Electronic Journal of Statistics  5:
935–980  2011.

10

[25] Shanmugam  K.  Kocaoglu  M.  Dimakis  A.  and Vishwanath  S. Learning causal graphs with
small interventions. In Advances in Neural Information Processing Systems  pp. 3195–3203 
2015.

[26] Shimizu  Shohei  Hoyer  Patrik O  Hyvärinen  Aapo  and Kerminen  Antti. A linear non-
gaussian acyclic model for causal discovery. Journal of Machine Learning Research  7(Oct):
2003–2030  2006.

[27] Spirtes  P.  Glymour  C.  and Scheines  R. Causation  Prediction and Search. The MIT Press 

second edition edition  2000.

[28] Tong  S. and Koller  D. Active learning for structure in Bayesian networks. In International

joint conference on artiﬁcial intelligence  2001.

[29] Triantaﬁllou  S. and Tsamardinos  I. Constraint-based causal discovery from multiple interven-
tions over overlapping variable sets. Journal of Machine Learning Research  16:2147–2205 
2015.

[30] Tsamardinos  I.  Brown  L.  and Aliferis  C. The max-min hill climbing Bayesian network

structure learning algorithm. Machine Learning  2006.

[31] Verma  T. and Pearl  J. Equivalence and synthesis of causal models. In Proceedings of the Sixth
Annual Conference on Uncertainty in Artiﬁcial Intelligence  UAI ’90. Elsevier Science Inc. 
1991.

[32] Wang  Z. and Honorio  J. Reconstructing a bounded-degree directed tree using path queries.

arXiv preprint arXiv:1606.05183  2016.

[33] Xiao  Yun  Gong  Yonghui  Lv  Yanling  Lan  Yujia  Hu  Jing  Li  Feng  Xu  Jinyuan  Bai 
Jing  Deng  Yulan  Liu  Ling  et al. Gene perturbation atlas (gpa): a single-gene perturbation
repository for characterizing functional mechanisms of coding and non-coding genes. Scientiﬁc
reports  2015.

[34] Zuk  O.  Margel  S.  and Domany  E. On the number of samples needed to learn the correct

structure of a Bayesian network. UAI  2006.

11

,Kevin Bello
Jean Honorio