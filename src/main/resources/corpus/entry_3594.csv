2018,Multi-objective Maximization of Monotone Submodular Functions with Cardinality Constraint,We consider the problem of multi-objective maximization of monotone submodular functions subject to cardinality constraint  often formulated as $\max_{|A|=k}\min_{i\in\{1 \dots m\}}f_i(A)$. While it is widely known that greedy methods work well for a single objective  the problem becomes much harder with multiple objectives. In fact  Krause et al.\ (2008) showed that when the number of objectives $m$ grows as the cardinality $k$ i.e.  $m=\Omega(k)$  the problem is inapproximable (unless $P=NP$). On the other hand  when $m$ is constant Chekuri et al.\ (2010) showed a randomized $(1-1/e)-\epsilon$ approximation with runtime (number of queries to function oracle) $n^{m/\epsilon^3}$. %In fact  the result of Chekuri et al.\ (2010) is for the far more general case of matroid constant. 
	
	We focus on finding a fast and practical algorithm that has (asymptotic) approximation guarantees even when $m$ is super constant. We first modify the algorithm of Chekuri et al.\ (2010) to achieve a $(1-1/e)$ approximation for $m=o(\frac{k}{\log^3 k})$. This demonstrates a steep transition from constant factor approximability to inapproximability around $m=\Omega(k)$. Then using Multiplicative-Weight-Updates (MWU)  we find a much faster $\tilde{O}(n/\delta^3)$ time asymptotic $(1-1/e)^2-\delta$ approximation. While the above results are all randomized  we also give a simple deterministic $(1-1/e)-\epsilon$ approximation with runtime $kn^{m/\epsilon^4}$. Finally  we run synthetic experiments using Kronecker graphs and find that our MWU inspired heuristic outperforms existing heuristics.,Multi-objective Maximization of Monotone

Submodular Functions with Cardinality Constraint

Rajan Udwani

Operations Research Center  M.I.T.

rudwani@alum.mit.edu

Abstract

functions subject

We consider the problem of multi-objective maximization of monotone sub-
modular
to cardinality constraint  often formulated as
max|A|=k mini∈{1 ... m} fi(A). While it is widely known that greedy methods
work well for a single objective  the problem becomes much harder with multiple
objectives. In fact  Krause et al. (2008) showed that when the number of objectives
m grows as the cardinality k i.e.  m = Ω(k)  the problem is inapproximable (unless
P = N P ). On the other hand  when m is constant Chekuri et al. (2010) showed
a randomized (1 − 1/e) −  approximation with runtime (number of queries to
function oracle) nm/3.
We focus on ﬁnding a fast and practical algorithm that has (asymptotic) approx-
imation guarantees even when m is super constant. We ﬁrst modify the algo-
rithm of Chekuri et al. (2010) to achieve a (1 − 1/e) −  approximation for
log3 k )  with  → 0 as k → ∞. This demonstrates a steep transition from
m = o(
constant factor approximability to inapproximability around m = Ω(k). Then
using Multiplicative-Weight-Updates (MWU)  we ﬁnd a much faster ˜O(n/δ3)
time asymptotic (1 − 1/e)2 − δ approximation. While the above results are all
randomized  we also give a simple deterministic (1 − 1/e) −  approximation with
runtime knm/4. Finally  we run synthetic experiments using Kronecker graphs
and ﬁnd that our MWU inspired heuristic outperforms existing heuristics.

k

1

Introduction

Several well known objectives in combinatorial optimization exhibit two common properties: the
marginal value of any given element is non-negative and it decreases as more and more elements are
selected. The notions of submodularity and monotonicity 1 nicely capture this property  resulting in the
appearance of constrained monotone submodular maximization in a wide and diverse array of modern
applications  including feature selection ([KG05  TCG+09])  network monitoring ([LKG+07])  news
article recommendation ([EAVSG09])  sensor placement and information gathering ([OUS+08 
GKS05  KGGK06  KLG+08])  viral marketing and inﬂuence maximization ([KKT03  HK16]) 
document summarization ([LB11]) and crowd teaching ([SB14]).
In this paper  we are interested in scenarios where multiple objectives  all monotone submodular  need
to be simultaneously maximized subject to a cardinality constraint. This problem has an established
line of work in both machine learning ([KMGG08]) and the theory community ([CVZ10]). Broadly
speaking  there are two ways in which this paradigm has been applied:

1A set function f : 2N → R on the ground set N is called submodular when f (A + a) − f (A) ≤ f (B +
a) − f (B) for all B ⊆ A ⊆ N and a ∈ N \ A.. The function is monotone if f (B) ≤ f (A) for all B ⊆ A.
We assume f (∅) = 0  then due to monotonicity we have that f is non-negative.

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

When there are several natural criteria that need to be simultaneously optimized:
such as in
network monitoring  sensor placement and information gathering [OUS+08  LKG+07  KLG+08 
KMGG08]. For example in the problem of intrusion detection [OUS+08]  one usually wants to
maximize the likelihood of detection while also minimizing the time until intrusion is detected  and
the population affected by intrusion. The ﬁrst objective is often monotone submodular and the latter
objectives are monotonically decreasing supermodular functions [LKG+07  KLG+08]. Therefore 
the problem is often formulated as an instance of cardinality constrained maximization with a small
number of submodular objectives.

When looking for solutions robust to the uncertainty in objective:
such as in feature selection
[KMGG08  GR06]  variable selection and experimental design [KMGG08]  robust inﬂuence maxi-
mization [HK16]. In these cases  there is often inherently just a single submodular objective which is
highly prone to uncertainty either due to dependence on a parameter that is estimated from data  or
due to multiple possible scenarios that each give rise to a different objective. Therefore  one often
seeks to optimize over the worst case realization of the uncertain objective  resulting in an instance of
multi-objective submodular maximization. In some applications the number of objectives is given by
the problem structure and can be larger even than the cardinality parameter. However  in applications
such as robust inﬂuence maximization  variable selection and experimental design  the number of
objectives is a design choice that trades off optimality with robustness.

1.1 Related Work

The problem of maximizing a monotone submodular function subject to a cardinality constraint 

P0 := max

A⊆N |A|≤k

f (A) 

goes back to the work of [NWF78  NW78]  where they showed that the greedy algorithm gives a
guarantee of (1 − 1/e) and this is best possible in the value-oracle model. Later  [Fei98] showed
that this is also the best possible approximation unless P=NP. While this settled the hardness and
approximability of the problem  ﬁnding faster approximations remained an open line of inquiry.
Notably  [BV14] found a faster algorithm for P0 that improved the quadratic O(nk) query complexity
of the classical greedy algorithm to nearly linear complexity  by trading off on the approximation
guarantee. This was later improved by [MBK+15].
For the more general problem maxA∈I f (A)  where I is the collection of independent sets of a
matroid; [CCPV11  Von08] in a breakthrough  achieved a (1−1/e) approximation by (approximately)
maximizing the multilinear extension of submodular functions  followed by suitable rounding. Based
on this framework  tremendous progress was made over the last decade for a variety of different
settings [CCPV11  Von08  FNS11  Von13  VCZ11  CVZ10  DV12].
In the multi-objective setting  [KMGG08] amalgamated various applications and formally introduced
the following problem 

P1 = max

A⊆N |A|≤k

min

i∈{1 2 ... m} fi(A) 

where fi(.) is monotone submodular for every i. They call this the Robust Submodular Observation
Selection (RSOS) problem and show that in general the problem is inapproximable unless P = N P .
Consequently  they proceeded to give a bi-criterion approximation algorithm  called SATURATE 
which achieves the optimal answer by violating the cardinality constraint. Note that their inapprox-
imability result only holds when m = Ω(k). Another bi-criterion approximation was given more
recently in [CLSS17].
On the other hand  [CVZ10] found a randomized (1 − 1/e) −  approximation for constant m in the
more general case of matroid constraint  as an application of a new technique for rounding over a
matroid polytope  called swap rounding. The runtime scales as O(nm/3
+ mn8) 2. Note  [CVZ10]
consider a different but equivalent formulation of the problem that stems from the inﬂuential paper
on multi-objective optimization [PY00]. The alternative formulation  which we introduce in Section
2  is the reason we call this a multi-objective maximization problem (same as [CVZ10]). For the
special case of cardinality constraint (which will be our focus here)  [OSU18] recently showed that
the greedy algorithm can be generalized to achieve a deterministic 1 − 1/e −  approximation for the

2The n8 term could potentially be improved to n5 by leveraging subsequent work [BV14  FW14].

2

special case of bi-objective maximization. Their runtime scales as n1+1/ and  ≤ 1/2. To the best
of our knowledge  when m = o(k) no constant factor approximation algorithms or inapproximability
results were known prior to this work.

1.2 Our Contributions

(cid:1) and  = min{ 1

8 ln m   4(cid:112) m

log3 k

δ3 log m log n

imation  which for m = o(cid:0) k

Our focus here is on the regime m = o(k). This setting is essential to understanding the approx-
imability of the problem for super-constant m and includes several of the applications we referred
to earlier. For instance  in network monitoring and sensor placement  the number of objectives is
usually a small constant ([KMGG08  LKG+07]). For robust inﬂuence maximization  the number of
objectives depends on the underlying uncertainty but is often small ([HK16]). And in settings like
variable selection and experimental design ([KMGG08])  where the number of objectives considered
is a design choice. We show three algorithmic results with asymptotic approximation guarantees for
m = o(k).
1. Asymptotically optimal approximation algorithm: We give a (1 − 1/e − )(1 − m

k3 ) approx-
k } tends to 1 − 1/e as k → ∞. The
algorithm is randomized and outputs such an approximation w.h.p. Observe that this implies a
steep transition around m  due to the inapproximability result (to within any non-trivial factor) for
m = Ω(k).
We obtain this via extending the algorithm of [CVZ10]  which relies on the continuous greedy
approach  resulting in a runtime of ˜O(mn8). Note that there is no  dependence in the runtime  unlike
the result from [CVZ10]. The key idea behind the result is quite simple  and relies on exploiting the
fact that we are dealing with a cardinality constraint  far more structured than matroids.
2. Fast and practical approximation algorithm: In practice  n can range from tens of thousands
to millions ([OUS+08  LKG+07])  which makes the above runtime intractable. To this end  we
δ ) time (1 − 1/e)2(1 − m/k3) −  − δ approximation. Under the
develop a fast O( n
same asymptotic conditions as above  the guarantee simpliﬁes to (1 − 1/e)2 − δ. We achieve this via
the Multiplicative-Weight-Updates (MWU) framework  which replaces the bottleneck continuous
greedy process. This costs us another factor of (1 − 1/e) in the guarantee but allows us to leverage
the runtime improvements for P0 achieved in [BV14  MBK+15].
MWU has proven to be a vital tool in the past few decades ([GK94  AK07  Bie06  Fle00  GK04 
GK07  KY07  You95  You01  PST91  AHK12]). Linear functions and constraints have been the
primary setting of interest in these works  but recent applications have shown its usefulness when
considering non-linear and in particular submodular objectives ([AG12  CJV15]). Unlike these recent
applications  we instead apply the MWU framework in vein of the Plotkin-Shmoys-Tardos scheme
for linear programming ([PST91])  essentially showing that the non-linearity only costs us a another
factor of (1−1/e) in the guarantee and yields a nearly linear time algorithm. Independently  [CLSS17]
applied the MWU framework in a similar manner and gave a new bi-criterion approximation. We
further discuss how our result differs from theirs in Section 3.2.
3. Finding a deterministic approximation for small m: While the above results are all randomized 
we also show a simple greedy based deterministic 1 − 1/e −  approximation with runtime knm/4.
This follows by establishing an upper bound on the increase in optimal solution value as a function of
cardinality k  which also resolves a weaker version of a conjecture posed in [OSU18].
Outline: We start with deﬁnitions and preliminaries in Section 2  where we also review relevant
parts of the algorithm in [CVZ10] that are essential for understanding the results here. In Section 3 
we state and prove the main results. Since the guarantees we present are asymptotic and technically
converge to the constant factors indicated as k becomes large  in Section 4 we test the performance of
a heuristic closely inspired by our MWU based algorithm on Kronecker graphs [LCK+10] of various
sizes and ﬁnd improved performance over previous heuristics even for small k and large m.

3

2 Preliminaries

2.1 Deﬁnitions & review

S⊆N f (S)(cid:81)

i∈S xi

extension over x = (x1  . . .   xn) ∈ [0  1]n is deﬁned as  F (x) =(cid:80)

We work with a ground set N of n elements and recall that we use P0 to denote the single objective
(classical) problem. [NWF78  NW78] showed that the natural greedy algorithm for P0 summarized
as  starting with ∅  at each step add to the current set an element which adds the maximum marginal
value until k elements are chosen  achieves a guarantee of 1− 1/e for P0 and that this is best possible.
Formally  given set A the marginal increase in value of function f due to inclusion of set X is given
by  f (X|A) = f (A ∪ X) − f (A).
(cid:81)
We use the notation xS for the support vector of a set S (1 along dimension i if i ∈ S and 0 otherwise).
We also use the short hand |x| to denote the (cid:96)1 norm of x. Given f : 2N → R  recall that its multilinear
j(cid:54)∈S(1 −
xj). This function acts as a natural replacement for the original function f in the continuous greedy
algorithm ([CCPV11]). Like the greedy algorithm  the continuous version always moves in a feasible
direction that best increases the value of function F . While evaluating the exact value of this
function is naturally hard in general  for the purpose of using this function in optimization algorithms 
approximations obtained using a sampling based oracle sufﬁce ([BV14  CVZ10  CCPV11]). Given
two vectors x  y ∈ [0  1]n  let x∨ y denote the component wise maximum. Then we deﬁne marginals
for this function as  F (x|y) = F (x ∨ y) − F (y).
Now  we brieﬂy discuss another formulation of the multi-objective maximization problem  call it P2 
introduced in [CVZ10]. In P2 we are given a target value Vi (positive real) with each function fi
and the goal is to ﬁnd a set S∗ of size at most k  such that fi(S∗) ≥ Vi  ∀i ∈ {1  . . .   m} or certify
that no S∗ exists. More feasibly one aims to efﬁciently ﬁnd a set S ∈ I such that fi(S) ≥ αVi for
all i and some factor α  or certify that there is no set S∗ such that fi(S∗) ≥ Vi  ∀i. Observe that
w.l.o.g. we can assume Vi = 1 ∀i (since we can consider functions fi(.)/Vi instead) and therefore
P2 is equivalent to the decision version of P1: Given t > 0  ﬁnd a set S∗ of size at most k such that
mini fi(S∗) ≥ t  or give a certiﬁcate of infeasibility.
When considering formulation P2  since we can always consider the modiﬁed submodular objectives
min{fi(.)  Vi}  we w.l.o.g. assume that fi(S) ≤ Vi for every set S and every function fi. Finally 
for both P1  P2 we use Sk to denote an optimal/feasible set (optimal for P1  and feasible for P2) to
the problem and OP Tk to denote the optimal solution value for formulation P1. We now give an
overview of the algorithm from [CVZ10] which is based on P2. To simplify the description we focus
on cardinality constraint  even though it is designed more generally for matroid constraint. We refer
to it as Algorithm 1 and it has three stages. Recall  the algorithm runs in time O(nm/3
Stage 1: Intuitively  this is a pre-processing stage with the purpose of picking a small initial set
consisting of elements with ’large’ marginal values  i.e. marginal value at least 3Vi for some function
fi. This is necessary for technical reasons due to the rounding procedure in Stage 3.
Given a set S of size k  ﬁx a function fi and index elements in S = {s1  . . .   sk} in the or-
der in which the greedy algorithm would pick them. There are at most 1/3 elements such
that fi(sj|{s1  . . .   sj−1}) ≥ 3Vi  since otherwise by monotonicity fi(S) > Vi (violating our
w.l.o.g. assumption that fi(S) ≤ Vi ∀i).
In fact  due to decreasing marginal values we have 
fi(sj|{s1  . . .   sj−1}) < 3Vi for every j > 1/3. Therefore  we focus on sets of size ≤ m/3
(at most 1/3 elements for each function) to ﬁnd an initial set such that the remaining elements have
marginal value ≤ 3Vi for fi  for every i. In particular  one can try all possible initial sets of this
size (i.e. run subsequent stages with different starting sets)  leading to the nm/3 term in the runtime.
Stages 2 3 have runtime polynomial in m (in fact Stage 3 has runtime independent of m)  hence Stage
1 is really the bottleneck. It is not obvious at all if one can do better than brute force enumeration
over all possible starting sets and still retain the approximation guarantee  since the ﬁnal solution
must be an independent set of a matroid. However  as we show later  for cardinality constraints one
can easily avoid enumeration.
Stage 2: Given a starting set S from stage one  this stage works with the ground set N − S and runs
the continuous greedy algorithm. If a feasible set Sk exists for the problem  then for the right starting
set S1 ∈ Sk  this stage outputs a fractional point x(k1) ∈ [0  1]n with |x(k1)| = k1 = k − |S| such
that Fi(x(k1)|xN−S) ≥ (1 − 1/e − )(Vi − fi(S1)) for every i  where  = 1/Ω(k). The stage is

+ mn8).

4

computationally expensive and takes time ˜O(mn8). We refer the interested reader to [CVZ10] for
further details (which will not be necessary for subsequent discussion).
Stage 3: For the right starting set S1 (if one exists)  Stage 2 successfully outputs a point x(k1). Stage
3 now follows a random process that converts x(k1) into a set S2 of size k1 such that  S2 ∈ N − S1
and fi(S1 ∪ S2) ≥ (1 − 1/e)(1 − )Vi ∀i as long as  < 1/8 ln m. The rounding procedure is called
swap rounding and we include a specialized version of the formal lemma below.
Lemma 1. ([CVZ10] Theorem 1.4  Theorem 7.2) Given m monotone submodular functions fi(.)
with the maximum value of singletons in [0  3Vi] for every i; a fractional point x and  < 1
8γ ln m .
Swap Rounding yields a set R with cardinality |x|  such that 

Pr[fi(R) < (1 − )Fi(x)] < me−1/8 < 1/mγ−1.

(cid:88)

i

Remark: For any γ > 1  the above can be converted to a result w.h.p. by standard repetition. Also
this is a simpliﬁed version of the matroid based result in [CVZ10].

3 Main Results

3.1 Asymptotic (1 − 1/e) approximation for m = o(cid:0) k

log3 k

(cid:1)

We replace the enumeration in Stage 1 with a single starting set  obtained by scanning once over
the ground set. The main idea is simply that for the cardinality constraint case  any starting set that
fulﬁlls the Stage 3 requirement of small marginals will be acceptable (not true for general matroids).
New Stage 1: Start with S1 = ∅ and pass over all elements once in arbitrary order. For each element
e  add it to S1 if for some i  fi(e|S1) ≥ 3Vi. Note that we add at most m/3 elements (at most
1/3 for each function). When the subroutine terminates  for every remaining element e ∈ N\S1 
fi(e|S1) < 3Vi ∀i (as required by Lemma 1). Let k1 = k − |S1| and note k1 ≥ k − m/3.
Stage 2 remains the same as Algorithm 1 and outputs a fractional point x(k1) with |x(k1)| = k1.
Using basic properties of the multilinear extension and the continuous greedy framework we show
for (cid:48) = 1/Ω(k) 

Fi(x(k1)|xS1) ≥ k1
k

(1 − 1/e − (cid:48))(Vi − fi(S1))∀i.

(1)

The details are deferred to the supplementary material. Stage 3 rounds x(k1) to S2 of size k1  and
ﬁnal output is S1 ∪ S2.
k } we have  fi(S1 ∪ S2) ≥ (1− )(1− 1/e)(1− m/k3)Vi ∀i
Theorem 2. For  = min{ 1

with constant probability. For m = o(cid:0)k/ log3 k(cid:1)  the guarantee approaches (1− 1/e) asymptotically

8 ln m   4(cid:112) m

and the algorithm makes ˜O(mn8) queries.
Proof. From (1) and applying Lemma 1 we have  fi(S2|S1) ≥ (1−)(1−1/e−(cid:48))(1−m/k3)(Vi−
fi(S1)) ∀i. Therefore  fi(S1∪S2) ≥ (1−)(1−1/e−(cid:48))(1−m/k3)Vi ∀i. To reﬁne the guarantee 
we choose  = min{ 1
k term is to balance
 and m/k3. Also (cid:48) = 1/Ω(k) therefore  the resulting guarantee becomes (1 − 1/e)(1 − h(k)) 

8 ln m is due to Lemma 1 and the 4(cid:112) m

where the function h(k) → 0 as k → ∞  so long as m = o(cid:0) k

8 ln m   4(cid:112) m

k }  where the

(cid:1).

1

log3 k

Note that the runtime is now independent of . The ﬁrst stage makes O(mn) oracle queries  the
second stage runs the continuous greedy algorithm on all functions simultaneously and makes ˜O(n8)
queries to each function oracle  contributing O(mn8) to the runtime. Stage 2 results in a fractional
solution that can be written as a convex combination of O(nk2) sets of cardinality k each (bases) (ref.
Appendix A in [CCPV11]). For cardinality constraint  swap rounding can merge two bases in O(k)
time hence  the last stage takes time O(nk3).

3.2 Fast  asymptotic (1 − 1/e)2 − δ approximation for m = o(cid:0) k

(cid:1)

log3 k

While the previous algorithm achieves the best possible asymptotic guarantee  it is infeasible to use
in practice. The main underlying issue was our usage of the continuous greedy algorithm in Stage 2

5

which has runtime ˜O(mn8)  but the ﬂexibility offered by continuous greedy was key to maximizing
the multilinear extensions of all functions at once. To improve the runtime we avoid continuous
greedy and ﬁnd an alternative in Multiplicative-Weight-Updates (MWU) instead. MWU allows us to
combine multiple submodular objectives together into a single submodular objective and utilize fast
algorithms for P0 at every step.
The algorithm consists of 3 stages as before. Stage 1 remains the same as the New Stage 1 introduced
in the previous section. Let S1 be the output of this stage as before. Stage 2 is replaced with a fast
MWU based subroutine that runs for T = O( ln m
δ2 ) rounds and solves an instance of SO during
each round. Here δ is an artifact of MWU and manifests as a subtractive term in the approximation
δ(cid:48) ) and
guarantee. The currently fastest algorithm for SO  in [MBK+15]  has runtime O(n log 1
an expected guarantee of (1 − 1/e) − δ(cid:48). However  the slightly slower  but still nearly linear
δ(cid:48) ) thresholding algorithm in [BV14]  has (the usual) deterministic guarantee of
time O( n
(1 − 1/e) − δ(cid:48). Both of these are known to perform well in practice and using either would lead to a
runtime of T × ˜O(n/δ) = ˜O( n
Now  ﬁx some algorithm A for P0 with guarantee α  and let A(f  k) denote the set it outputs given
monotone submodular function f and cardinality constraint k as input. Note that α can be as large as
1 − 1/e  and we have k1 = k − |S1| as before. Then the new Stage 2 is 

δ3 )  which is a vast improvement over the previous algorithm.

δ(cid:48) log n

i = 1/m  ˜fi(.) = fi(.|S1)
Vi−fi(S1)

δ2

2: while 1 ≤ t ≤ T do gt(.) =(cid:80)m

Algorithm 2 Stage 2: MWU
1: Input: δ  T = 2 ln m
  λ1
3: X t = A(gt  k1)
i = ˜fi(X t) − α
4: mt
(cid:80)T
i(1 − δmt
5: λt+1
i = λt
i)
6: t = t + 1
7: Output: x2 = 1
T

t=1 X t

i=1 λt
i

˜fi(.)

The point x2 obtained above is rounded to a set S2 in Stage 3 (which remains unchanged). The ﬁnal
output is S1 ∪ S2. Note that by abuse of notation we used the sets X t to also denote the respective
support vectors. We continue to use X t and xX t interchangeably in the below.
This application of MWU is unlike [AG12  CJV15]  where broadly speaking the MWU framework
is applied in a novel way to determine how an individual element is picked (or how a direction
for movement is chosen in case of continuous greedy). In contrast  we use standard algorithms
for P0 and pick an entire set before changing weights. Also  [CJV15] uses MWU along with the
continuous greedy framework to tackle harder settings  but for our setting using the continuous greedy
framework eliminates the need for MWU altogether and in fact  we use MWU as a replacement for
continuous greedy. Subsequent to our work we discovered a resembling application of MWU in
[CLSS17]. Their application differs from Stage 2 above only in minor details  but unlike our result
they give a bi-criterion approximation where the output is a set S of cardinality up to k log m
V 2 such
that fi(S) ≥ (1 − 1/e − 2)V .
Now  consider the following intuitive schema. We would like to ﬁnd a set X of size k such that
i λifi(.)  which is also
i λifi(Xλ) ≥
i λiVi  since this is a single objective problem and we have fast approximations for P0. However 
for a ﬁxed set of scalar weights λi  solving the P0 problem instance need not give a set that has
sufﬁcient value for every individual function fi(.). This is where MWU comes into the picture.
We start with uniform weights for functions  solve an instance of P0 to get a set X 1. Then we
change weights to undermine the functions for which fi(X 1) was closer to the target value and
stress more on functions for which fi(X 1) was small  and repeat now with new weights. After
running many rounds of this  we have a collection of sets X t for t ∈ {1  . . .   T}. Using tricks
from standard MWU analysis ([AHK12]) along with submodularity and monotonicity  we show that
(cid:39) (1 − 1/e)(Vi − fi(S1)). Thus far  this resembles how MWU has been used in the
literature for linear objectives  for instance the Plotkin-Shmoys-Tardos framework for solving LPs.

fi(X) ≥ αVi for every i. While this seems hard  consider the combination(cid:80)
monotone submodular for non-negative λi. We can easily ﬁnd a set Xλ such that(cid:80)
(cid:80)

fi(X t|S1)

(cid:80)

T

t

6

t

T

fi(X t|S1)

(cid:80)
that Fi(x2|xS1 ) ≥ β(cid:80)

However  a new issue now arises due to the non-linearity of functions fi. As an example  suppose
that by some coincidence x2 = 1
t=1 X t turns out to be a binary vector  so we easily obtain the
set S2 from x2. We want to lower bound fi(S2|S1)  and while we have a good lower bound on
T
  it is unclear how the two quantities are related. More generally  we would like to show
and this would then give us a βα = β(1 − 1/e) approximation
using Lemma 1. Indeed  we show that β ≥ (1 − 1/e)  resulting in a (1 − 1/e)2 approximation. In
the lemmas that follow  we state this more concretely (proofs deferred to supplementary material).
Lemma 3. gt(X t) ≥ k1
Lemma 4.

fi(X t|S1)

T

t

k α(cid:80)
i ∀t.
(cid:80)
{1  . . .   T}  and a point x =(cid:80)

i λt

t

Lemma 5. Given monotone submodular function f  its multilinear extension F   sets X t for t ∈

˜fi(X t)
T

≥ k1
k

(1 − 1/e) − δ  ∀i.

t X t/T   we have 
F (x) ≥ (1 − 1/e)

T(cid:88)

1
T

8 ln m   4(cid:112) m

f (X t).
k }  the algorithm makes O( n

t=1

Theorem 6. For  = min{ 1
constant probability outputs a feasible (1−)(1−1/e)2(1− m

(1 − 1/e)2 − δ approximate for m = o(cid:0)k/ log3 k(cid:1).

(cid:80)T

δ3 log m log n

δ ) queries  and with
k3 )−δ approximate set. Asymptotically 

(cid:80)

k (1 − 1/e)2 − δ  ∀i.
≥ k1
Proof. Combining Lemmas 4 & 5 we have  ˜Fi(x2) ≥ (1 − 1/e)
The asymptotic result follows just as in Theorem 2. For runtime  note that Stage 1 takes time O(n).
Stage 2 runs an instance of A(.)  T times  leading to an upper bound of O(( n
δ log n
δ2 ) =
δ )  if we use the thresholding algorithm in [BV14] (at the cost of a multiplicative
O( n
factor of (1 − δ) in the approximation guarantee). Finally  swap rounding proceeds in T rounds and
each round takes O(k) time  leading to total runtime O( k
δ2 log m) for Stage 3. Combining all three
we get a runtime of O( n

δ ) × log m

δ3 log m log n

˜fi(X t)
T

t

δ3 log m log n

δ ).

3.3 Variation in optimal solution value and derandomization

k OP Tk  and the bound is easily seen to be tight.

Consider the problem P0 with cardinality constraint k. Given an optimal solution Sk with value
OP Tk for the problem  it is not difﬁcult to see that for arbitrary k(cid:48) ≤ k  there is a subset Sk(cid:48) ⊆ Sk
of size k(cid:48)  such that f (Sk(cid:48)) ≥ k(cid:48)
k OP Tk. For instance  indexing the elements in Sk using the
greedy algorithm  and choosing the set given by the ﬁrst k(cid:48) elements gives such a set. This implies
OP Tk(cid:48) ≥ k(cid:48)
This raises a natural question: Can we generalize this bound on variation of optimal solution value
with varying k  for multi-objective maximization? A priori  this isn’t obvious even for modular
functions. In particular  note that indexing elements in order they are picked by the greedy algorithm
doesn’t sufﬁce since there are many functions and we need to balance values amongst all. We show
that one can indeed derive such a bound (proof in supplementary material).
Lemma 7. Given that there exists a set Sk such that fi(Sk) ≥ Vi ∀i and  < 1
k(cid:48) ∈ [m/3  k]  there exists Sk(cid:48) ⊆ Sk of size k(cid:48)  such that 

8 ln m . For every

fi(Sk(cid:48)) ≥ (1 − )

(cid:16) k(cid:48) − m/3

k − m/3

(cid:17)

Vi ∀i.

Conjecture in [OSU18]: Note that this resolves a slightly weaker version of the conjecture in
[OSU18] for constant m. The original conjecture states that for constant m and every k(cid:48) ≥ m 
there exists a set S of size k(cid:48)  such that fi(S) ≥ k(cid:48)−Θ(1)
Vi ∀i. Asymptotically  both k(cid:48)−m/3
k−m/3
and k(cid:48)−Θ(1)
k . This implies that for large enough k(cid:48)  we can choose sets of size k(cid:48) (k(cid:48)-
tuples) at each step to get a deterministic (asymptotically) (1 − 1/e) −  approximation with runtime
O(knm/4
) for the multi-objective maximization problem  when m is constant (all previously known
approximation algorithms  as well as the ones presented earlier  are randomized). We defer the proof
to supplementary material.

tend to k(cid:48)

k

k

7

Theorem 8. For k(cid:48) = m
(1 − 1/e)(1 − 2) approximate  while making knm/4 queries.

4   choosing k(cid:48)-tuples greedily w.r.t. h(.) = mini fi(.) is asymptotically

4 Experiments on Kronecker Graphs

We choose synthetic experiments where we can control the parameters to see how the algorithm
performs in various scenarios  esp. since we would like to test how the MWU algorithm performs
for small values of k and m = Ω(k). We work with formulation P1 of the problem and consider a
multi-objective version of the max-k-cover problem on graphs. Random graphs for our experiments
were generated using the Kronecker graph framework introduced in [LCK+10]. These graphs exhibit
several natural properties and are considered a good approximation for real networks (esp. social
networks [HK16]).
We compare three algorithms: (i) A baseline greedy heuristic  labeled GREEDY  which focuses on one
objective at a time and successively picks k/m elements greedily w.r.t. each function (formally stated
in supplementary material). (ii) A bi-criterion approximation called SATURATE from [KMGG08] 
to the best of our knowledge this is considered state-of-the-art for the problem. (iii) We compare these
algorithms to a heuristic inspired by our MWU algorithm. This heuristic differs from the algorithm
discussed earlier in two ways. Firstly  we eliminate Stage 1 which was key for technical analysis
but in practice makes the algorithm perform similar to GREEDY. Second  instead of simply using
the the swap rounded set S2  we output the best set out of {X 1  . . .   X T} and S2. Also  for both
SATURATE and MWU we estimate target value t using binary search and consider capped functions
min{fi(.)  t}. Also  for the MWU stage  we tested δ = 0.5 or 0.2.

Algorithm 3 GREEDY
1: Input: k  m  fi(.) for i ∈ [m]
2: S = ∅  i = 1
3: while |S| ≤ k − 1 do
4: S = S + arg maxx∈N−S fi(x|S)
5: i = i + 1 mod m + 1
6: Output: S

2: g(.) =(cid:80)

Algorithm 4 SATURATE
1: Input: k  t  f1  . . .   fm and set A = ∅
3: while |A| < k do A = A + argmax
x∈N−A
4: Output: A

i min{fi(.)  t}

g(x|A)

We pick Kronecker graphs of sizes n ∈ {64  512  1024} with random initiator matrix 3 and for each
n  we test for m ∈ {10  50  100}. Note that each graph here represents an objective  so for a ﬁxed
n  we generate m Kronecker graphs to get m max-cover objectives. For each setting of n  m we
evaluate the solution value for the heuristics as k increases and show the average performance over
30 trials for each setting. All experiments were done using MATLAB.

3To generate a Kronecker graph one needs a small initiator matrix. Using [LCK+10] as a guideline we use
random matrices of size 2 × 2  each entry chosen uniformly randomly (and independently) from [0  1]. Matrices
with sum of entries smaller than 1 are discarded to avoid highly disconnected graphs.

8

Figure 1: Plots for graphs of size 64. Number of objectives increases from left to right. The X axis
is the cardinality parameter k and Y axis is difference between # vertices covered by MWU and
SATURATE minus the # vertices covered by GREEDY for the same k. MWU outperforms the other
algorithms in all cases  with a max. gain (on SATURATE) of 9.80% for m = 10  12.14% for m = 50
and 16.12% for m = 100.

Figure 2: Plots for graphs of size 512. MWU outperforms SATURATE in all cases with a max. gain
(on SATURATE) of 7.95% for m = 10  10.08% for m = 50 and 10.01% for m = 100.

Figure 3: Plots for graphs of size 1024. MWU outperforms SATURATE in all cases  with max. gain
(on SATURATE) of 6.89% for m = 10  5.02% for m = 50 and 7.4% for m = 100.

5 Open Problems

A natural open question here is whether one can achieve similar approximations for a general matroid
constraint. Additionally  it also of interest to ask if there are fast algorithms with guarantee closer
to 1 − 1/e  in contrast to the guarantee of (1 − 1/e)2 shown here. Further  it is unclear if one can
extend the results right up to m = o(k).

9

Acknowledgments

The author gratefully acknowledges partial support from ONR Grant N00014-17-1-2194. The author
would also like to thank James B. Orlin and anonymous referees for their insightful comments and
feedback on early drafts of this work.

References

[AG12] Y. Azar and I. Gamzu. Efﬁcient submodular function maximization under linear packing

constraints. ICALP  pages 38–50  2012.

[AHK12] S. Arora  E. Hazan  and S. Kale. The multiplicative weights update method: a meta-

algorithm and applications. Theory of Computing  8:121–164  2012.

[AK07] S. Arora and S. Kale. A combinatorial  primal-dual approach to semideﬁnite programs.

In STOC  pages 227–236  2007.

[Bie06] D. Bienstock. Potential function methods for approximately solving linear programming

problems: theory and practice  volume 53. Springer  2006.

[BV14] A. Badanidiyuru and J. Vondrák. Fast algorithms for maximizing submodular functions.

In SODA ’14  pages 1497–1514. SIAM  2014.

[CCPV11] G. Calinescu  C. Chekuri  M. Pál  and J. Vondrák. Maximizing a monotone submodular
function subject to a matroid constraint. SIAM Journal on Computing  40(6):1740–1766 
2011.

[CJV15] C. Chekuri  T.S. Jayram  and J. Vondrak. On multiplicative weight updates for concave

and submodular function maximization. ITCS  pages 201–210  2015.

[CLSS17] R. S. Chen  B. Lucier  Y. Singer  and V. Syrgkanis. Robust optimization for non-convex
objectives. In Advances in Neural Information Processing Systems  pages 4705–4714 
2017.

[CVZ10] C. Chekuri  J. Vondrák  and R. Zenklusen. Dependent randomized rounding via
exchange properties of combinatorial structures. In FOCS 10  pages 575–584. IEEE 
2010.

[DV12] S. Dobzinski and J. Vondrák. From query complexity to computational complexity. In

STOC ’12  pages 1107–1116. ACM  2012.

[EAVSG09] K. El-Arini  G. Veda  D. Shahaf  and C. Guestrin. Turning down the noise in the

blogosphere. In ACM SIGKDD  pages 289–298  2009.

[Fei98] U. Feige. A threshold of ln n for approximating set cover. Journal of the ACM (JACM) 

45(4):634–652  1998.

[Fle00] L. Fleischer. Approximating fractional multicommodity ﬂow independent of the number

of commodities. SIAM Journal on Discrete Mathematics  13(4):505–520  2000.

[FNS11] M. Feldman  J.S. Naor  and R. Schwartz. A uniﬁed continuous greedy algorithm for

submodular maximization. In FOCS 11  pages 570–579  2011.

[FW14] Y. Filmus and J. Ward. Monotone submodular maximization over a matroid via non-

oblivious local search. SIAM Journal on Computing  43:514–542  2014.

[GK94] M. Grigoriadis and L. Khachiyan. Fast approximation schemes for convex programs
with many blocks and coupling constraints. SIAM Journal on Optimization  4(1):86–107 
1994.

[GK04] N. Garg and R. Khandekar. Fractional covering with upper bounds on the variables:
In European Symposium on Algorithms  pages

Solving lps with negative entries.
371–382  2004.

[GK07] N. Garg and J. Koenemann. Faster and simpler algorithms for multicommodity ﬂow
and other fractional packing problems. SIAM Journal on Computing  37(2):630–652 
2007.

[GKS05] C. Guestrin  A. Krause  and A.P. Singh. Near-optimal sensor placements in gaussian
processes. In Proceedings of the 22nd international conference on Machine learning 
pages 265–272. ACM  2005.

10

[GR06] A. Globerson and S. Roweis. Nightmare at test time: robust learning by feature
deletion. In Proceedings of the 23rd international conference on Machine learning 
pages 353–360. ACM  2006.

[HK16] X. He and D. Kempe. Robust inﬂuence maximization. In SIGKDD  pages 885–894 

2016.

[KG05] A. Krause and C. Guestrin. Near-optimal nonmyopic value of information in graphical

models. UAI’05  pages 324–331  2005.

[KGGK06] A. Krause  C. Guestrin  A. Gupta  and J. Kleinberg. Near-optimal sensor placements:
Maximizing information while minimizing communication cost. In Proceedings of the
5th international conference on Information processing in sensor networks  pages 2–10.
ACM  2006.

[KKT03] D. Kempe  J. Kleinberg  and É. Tardos. Maximizing the spread of inﬂuence through a

social network. In ACM SIGKDD  pages 137–146  2003.

[KLG+08] A. Krause  J. Leskovec  C. Guestrin  J. VanBriesen  and C. Faloutsos. Efﬁcient sensor
placement optimization for securing large water distribution networks. Journal of Water
Resources Planning and Management  134(6):516–526  2008.

[KMGG08] A. Krause  H B. McMahan  C. Guestrin  and A. Gupta. Robust submodular observation

selection. Journal of Machine Learning Research  9:2761–2801  2008.

[KY07] C. Koufogiannakis and N. Young. Beating simplex for fractional packing and covering

linear programs. In FOCS  pages 494–504  2007.

[LB11] H. Lin and J. Bilmes. A class of submodular functions for document summarization. In

ACL  pages 510–520  2011.

[LCK+10] J. Leskovec  D. Chakrabarti  J. Kleinberg  C. Faloutsos  and Z. Ghahramani. Kronecker

graphs: An approach to modeling networks. JMLR  11:985–1042  2010.

[LKG+07] J. Leskovec  A. Krause  C. Guestrin  C. Faloutsos  J. VanBriesen  and N. Glance. Cost-
effective outbreak detection in networks. In Proceedings of the 13th ACM SIGKDD
international conference on Knowledge discovery and data mining  pages 420–429.
ACM  2007.

[MBK+15] B. Mirzasoleiman  A. Badanidiyuru  A. Karbasi  J. Vondrák  and A. Krause. Lazier

than lazy greedy. In AAAI  2015.

[NW78] G.L. Nemhauser and L.A. Wolsey. Best algorithms for approximating the maximum of
a submodular set function. Mathematics of operations research  3(3):177–188  1978.
[NWF78] G.L. Nemhauser  L.A. Wolsey  and M.L. Fisher. An analysis of approximations for
maximizing submodular set functions—i. Mathematical Programming  14(1):265–294 
1978.

[OSU18] J. B. Orlin  A. S. Schulz  and R. Udwani. Robust monotone submodular function

maximization. Mathematical Programming  172(1):505–537  Nov 2018.

[OUS+08] A. Ostfeld  J.G. Uber  E. Salomons  J.W. Berry  Phillips C.A. Hart  W.E.  J.P. Watson 
G. Dorini  P. Jonkergouw  Z. Kapelan  and F. di Pierro. The battle of the water sensor
networks (BWSN): A design challenge for engineers and algorithms. Journal of Water
Resources Planning and Management  2008.

[PST91] S. Plotkin  D. Shmoys  and E. Tardos. Fast approximation algorithms for fractional

packing and covering problems. In FOCS  pages 495–504  1991.

[PY00] C. Papadimitriou and M. Yannakakis. On the approximability of trade-offs and optimal

access of web sources. In FOCS  pages 86–92  2000.

[SB14] A. Singla and I. Bogunovic. Near-optimally teaching the crowd to classify. In ICML 

pages 154–162  2014.

[TCG+09] M. Thoma  H. Cheng  A. Gretton  J. Han  HP. Kriegel  A.J. Smola  L. Song  S.Y. Philip 
X. Yan  and K.M. Borgwardt. Near-optimal supervised feature selection among frequent
subgraphs. In SDM  pages 1076–1087. SIAM  2009.

[VCZ11] J. Vondrák  C. Chekuri  and R. Zenklusen. Submodular function maximization via the
multilinear relaxation and contention resolution schemes. In STOC ’11  pages 783–792.
ACM  2011.

11

[Von08] J. Vondrák. Optimal approximation for the submodular welfare problem in the value

oracle model. In STOC  pages 67–74  2008.

[Von13] J. Vondrák. Symmetry and approximability of submodular maximization problems.

SIAM Journal on Computing  42(1):265–304  2013.

[You95] N. Young. Randomized rounding without solving the linear program.

volume 95  pages 170–178  1995.

In SODA 

[You01] Neal E Young. Sequential and parallel algorithms for mixed packing and covering. In

FOCS  pages 538–546  2001.

12

,Rajan Udwani