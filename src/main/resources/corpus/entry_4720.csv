2015,Revenue Optimization against Strategic Buyers,We present a revenue optimization algorithm for posted-price auctions when facing a buyer with random valuations who seeks to optimize his $\gamma$-discounted surplus. To analyze this problem  we introduce the notion of  epsilon-strategic buyer  a more natural notion of strategic behavior than what has been used in the past.  We improve upon the previous state-of-the-art and achieve an optimal regret bound in  $O\Big( \log T + \frac{1}{\log(1/\gamma)} \Big)$ when the seller can offer prices from a finite set $\cP$ and provide a regret bound in  $\widetilde O \Big(\sqrt{T} + \frac{T^{1/4}}{\log(1/\gamma)} \Big)$ when the buyer is offered prices from the interval $[0  1]$.,Revenue Optimization against

Strategic Buyers

Mehryar Mohri

Courant Institute of Mathematical Sciences

251 Mercer Street

New York  NY  10012

Andr´es Mu˜noz Medina⇤

Google Research
111 8th Avenue

New York  NY  10011

Abstract

We present a revenue optimization algorithm for posted-price auctions when fac-
ing a buyer with random valuations who seeks to optimize his -discounted sur-
plus. In order to analyze this problem we introduce the notion of ✏-strategic buyer 
a more natural notion of strategic behavior than what has been considered in the
past. We improve upon the previous state-of-the-art and achieve an optimal regret
bound in O(log T + 1/ log(1/)) when the seller selects prices from a ﬁnite set

and provide a regret bound in eO(pT + T 1/4/ log(1/)) when the prices offered

are selected out of the interval [0  1].

1

Introduction

Online advertisement is currently the fastest growing form of advertising. This growth has been
motivated  among other reasons  by the existence of well deﬁned metrics of effectiveness such as
click-through-rate and conversion rates. Moreover  online advertisement enables the design of better
targeted campaigns by allowing advertisers to decide which type of consumers should see their
advertisement. These advantages have promoted the fast pace development of a large number of
advertising platforms. Among them  AdExchanges have increased in popularity in recent years. In
contrast to traditional advertising  AdExchanges do not involve contracts between publishers and
advertisers. Instead  advertisers are allowed to bid in real-time for the right to display their ad.
An AdExchange works as follows: when a user visits a publisher’s website  the publisher sends
this information to the AdExchange which runs a second-price auction with reserve (Vickrey  1961;
Milgrom  2004) among all interested advertisers. Finally  the winner of the auction gets the right
to display his ad on the publisher’s website and pays the maximum of the second highest bid and
the reserve price. In practice  this process is performed in milliseconds  resulting in millions of
transactions recorded daily by the AdExchange. Thus  one might expect that the AdExchange could
beneﬁt from this information by learning how much an advertiser values the right to display his ad
and setting an optimal reserve price. This idea has recently motivated research in the learning com-
munity on revenue optimization in second-price auctions with reserve (Mohri and Medina  2014a;
Cui et al.  2011; Cesa-Bianchi et al.  2015).
The algorithms proposed by these authors heavily rely on the assumption that the advertisers’ bids
are drawn i.i.d. from some underlying distribution. However  if an advertiser is aware of the fact that
the AdExchange or publisher are using a revenue optimization algorithm  then  most likely  he would
adjust his behavior to trick the publisher into offering a more beneﬁcial price in the future. Under
this scenario  the assumptions of (Mohri and Medina  2014a) and (Cesa-Bianchi et al.  2015) would
be violated. In fact  empirical evidence of strategic behavior by advertisers has been documented by
Edelman and Ostrovsky (2007). It is therefore critical to analyze the interactions between publishers
and strategic advertisers.

⇤This work was partially done at the Courant Institute of Mathematical Sciences.

1

In this paper  we consider the simpler scenario of revenue optimization in posted-price auctions with
strategic buyers  ﬁrst analyzed by Amin et al. (2013). As pointed out by Amin et al. (2013)  the study
of this simpliﬁed problem is truly relevant since a large number of auctions run by AdExchanges
consist of only one buyer (or one buyer with a large bid and several buyers with negligible bids). In
this scenario  a second-price auction in fact reduces to a posted-price auction where the seller sets a
reserve price and the buyer decides to accept it (bid above it) or reject it (bid below).
To analyze the sequential nature of this problem  we can cast it as a repeated game between a buyer
and a seller where a strategic buyer seeks to optimize his surplus while the seller seeks to collect
the largest possible revenue from the buyer. This can be viewed as an instance of a repeated non-
zero sum game with incomplete information  which is a problem that has been well studied in the
Economics and Game Theory community (Nachbar  1997  2001). However  such previous work has
mostly concentrated on the characterization of different types of achievable equilibria as opposed to
the design of an algorithm for the seller. Furthermore  the problem we consider admits a particular
structure that can be exploited to derive learning algorithms with more favorable guarantees for the
speciﬁc task of revenue optimization.
The problem can also be viewed as an instance of a multi-armed bandit problem (Auer et al.  2002;
Lai and Robbins  1985)  more speciﬁcally  a particular type of continuous bandit problem previously
studied by Kleinberg and Leighton (2003). Indeed  at every time t the buyer can only observe the
revenue of the price he offered and his goal is to ﬁnd  as fast as possible  the price that would yield the
largest expected revenue. Unlike a bandit problem  however  here  the performance of an algorithm
cannot be measured in terms of the external regret. Indeed  as observed by Bubeck and Cesa-Bianchi
(2012) and Arora et al. (2012)  the notion of external regret becomes meaningless when facing an
adversary that reacts to the learner’s actions. In short  instead of comparing to the best achievable
revenue by a ﬁxed price over the sequence of rewards seen  one should compare against the simulated
sequence of rewards that would have been seen had the seller played a ﬁxed price. This notion of
regret is known as strategic regret and regret minimization algorithms have been proposed before
under different scenarios (Amin et al.  2013  2014; Mohri and Medina  2014a). In this paper we
provide a regret minimization algorithm for the stochastic scenario  where  at each round  the buyer
receives an i.i.d. valuation from an underlying distribution. While this random valuation might seems
surprising  it is in fact a standard assumption in the study of auctions (Milgrom and Weber  1982;
Milgrom  2004; Cole and Roughgarden  2014). Moreover  in practice  advertisers rarely interact
directly with an AdExchange. Instead  several advertisers are part of an ad network and it is that ad
network that bids on their behalf. Therefore  the valuation of the ad network is not likely to remain
ﬁxed. Our model is also motivated by the fact that the valuation of an advertiser depends on the
user visiting the publisher’s website. Since these visits can be considered random  it follows that the
buyer’s valuation is in fact a random variable.
A crucial component of our analysis is the deﬁnition of a strategic buyer. We consider a buyer who
seeks to optimize his cumulative discounted surplus. However  we show that a buyer who exactly
maximizes his surplus must have unlimited computational power  which is not a realistic assumption
in practice. Instead  we deﬁne the notion of an ✏-strategic buyer who seeks only to approximately
optimize his surplus. Our main contribution is to show that  when facing an ✏-strategic buyer  a seller
can achieve O(log T ) regret when the set of possible prices to offer is ﬁnite  and an O(pT ) regret
bound when the set of prices is [0  1]. Remarkably  these bounds on the regret match those given by
Kleinberg and Leighton (2003) in a truthful scenario where the buyer does not behave strategically.
The rest of this paper is organized as follows. In Section 2  we discuss in more detail related previous
work. Next  we deﬁne more formally the problem setup (Section 3). In particular  we give a precise
deﬁnition of the notion of ✏-strategic buyer (Section 3.2). Our main algorithm for a ﬁnite set of
prices is described in Section 4  where we also provide a regret analysis. In Section 5  we extend
our algorithm to the continuous case where we show that a regret in O(pT ) can be achieved.

2 Previous work
The problem of revenue optimization in auctions goes back to the seminal work of Myerson (1981) 
who showed that under some regularity assumptions over the distribution D  the revenue optimal 
incentive-compatible mechanism is a second-price auction with reserve. This result applies to single-
shot auctions where buyers and the seller interact only once and the underlying value distribution is

2

known to the seller. In practice  however it is not realistic to assume that the seller has access to this
distribution. Instead  in cases such as on-line advertisement  the seller interacts with the buyer a large
number of times and can therefore infer his behavior from historical data. This fact has motivated
the design of several learning algorithms such as that of (Cesa-Bianchi et al.  2015) who proposed
a bandit algorithm for revenue optimization in second-price auctions; and the work of (Mohri and
Medina  2014a)  who provided learning guarantees and an algorithm for revenue optimization where
each auction is associated with a feature vector.
The aforementioned algorithms are formulated under the assumption of buyers bidding in an i.i.d.
fashion and do not take into account the fact that buyers can in fact react to the use of revenue
optimization algorithms by the seller. This has motivated a series of publications focusing on this
particular problem. Bikhchandani and McCardle (2012) analyzed the same problem proposed here
when the buyer and seller interact for only two rounds. Kanoria and Nazerzadeh (2014) consid-
ered a repeated game of second-price auctions where the seller knows that the value distribution
can be either high  meaning it is concentrated around high values  or low; and his goal is to ﬁnd
out from which distribution the valuations are drawn under the assumption that buyers can behave
strategically.
Finally  the scenario considered here was ﬁrst introduced by Amin et al. (2013) where the authors
solve the problem of optimizing revenue against a strategic buyer with a ﬁxed valuation and showed

1. Mohri and Medina (2014b) later showed that one can
that a buyer can achieve regret in O pT
in fact achieve a regret in O( log T
1 ) closing the gap with the lower bound to a factor of log T . The
scenario of random valuations we consider here was also analyzed by Amin et al. (2013) where an
1/↵ was proposed when prices are offered
algorithm achieving regret in O|P|T ↵ +
from a ﬁnite set P  with  = minp2P p⇤D(v > p⇤)  pD(v > p) and ↵ a free parameter. Finally 
an extension of this algorithm to the contextual setting was presented by the same authors in (Amin
et al.  2014) where they provide an algorithm achieving O T 2/3

The algorithms proposed by Amin et al. (2013  2014) consist of alternating exploration and exploita-
tion. That is  there exist rounds where the seller only tries to estimate the value of the buyer and
other rounds where he uses this information to try to extract the largest possible revenue. It is well
known in the bandit literature (Dani and Hayes  2006; Abernethy et al.  2008) that algorithms that
ignore information obtained on exploitation rounds tend to be sub-optimal. Indeed  even in a truthful
scenario where the UCB algorithm (Auer et al.  2002) achieves regret in O( log T
 )  the algorithm pro-

1 regret.

(1)1/↵ + 1

1

of ↵ which  incidentally  requires also access to the unknown value .
We propose instead an algorithm inspired by the UCB strategy using exploration and exploitation

posed by Amin et al. (2013) achieves sub-optimal regret in Oeplog T log 1
simultaneously. We show that our algorithm admits a regret that is in O log T

 for the optimal choice
log(1/)  which
matches the UCB bound in the truthful scenario and which depends on  only through the additive
1 known to be unavoidable (Amin et al.  2013). Our results cannot be directly
term
compared with those of Amin et al. (2013) since they consider a fully strategic adversary whereas
we consider an ✏-strategic adversary. As we will see in the next section  however  the notion of ✏-
strategic adversary is in fact more natural than that of a buyer who exactly optimizes his discounted
surplus. Moreover  it is not hard to show that  when applied to our scenario  perhaps modulo a
constant  the algorithm of Amin et al. (2013) cannot achieve a better regret than in the fully strategic
adversary.

log(1/) ⇡ 1

 + |P|

1

3 Setup

We consider the following scenario  similar to the one introduced by Amin et al. (2013).

3.1 Scenario
A buyer and a seller interact for T rounds. At each round t 2 {1  . . .   T}  the seller attempts to sell
some good to the buyer  such as the right to display an ad. The buyer receives a valuation vt 2 [0  1]
which is unknown to the seller and is sampled from a distribution D. The seller offers a price pt 

3

in response to which the buyer selects an action at 2 {0  1}  with at = 1 indicating that he accepts
the price and at = 0 otherwise. We will say the buyer lies if he accepts the price at time t (at = 1)
while the price offered is above his valuation (vt  pt)  or when he rejects the price (at = 0) while
his valuation is above the price offered (vt > pt).
The seller seeks to optimize his expected revenue over the T rounds of interaction  that is 

Rev = E TXt=1

atpt.

Notice that  when facing a truthful buyer  for any price p  the expected revenue of the seller is given
by pD(v > p). Therefore  with knowledge of D  the seller could set all prices pt to p⇤  where
p⇤ 2 argmaxp2[0 1] pD(v > p). Since the actions of the buyer do not affect the choice of future
prices by the seller  the buyer has no incentive to lie and the seller will obtain an expected revenue
of T p⇤D(v > p⇤). It is therefore natural to measure the performance of any revenue optimization
algorithm in terms of the following notion of strategic regret:

RegT = T p⇤D(v > p⇤)  Rev = max
p2[0 1]

T pD(v > p)  E TXt=1

atpt.

The objective of the seller coincides with the one assumed by Kleinberg and Leighton (2003) in the
study of repeated interactions with buyers with a random valuation. However  here  we will allow
the buyer to behave strategically  which results in a harder problem. Nevertheless  the buyer is not
assumed to be fully adversarial as in (Kleinberg and Leighton  2003). Instead  we will assume  as
discussed in detail in the next section  that the buyer seeks to approximately optimize his surplus 
which can be viewed as a more natural assumption.

✏-strategic Buyers

3.2
Here  we deﬁne the family of buyers considered throughout this paper. We denote by x1:t 2 Rt
the vector (x1  . . .   xt) and deﬁne the history of the game up to time t by Ht := p1:t  v1:t  a1:t.
Before the ﬁrst round  the seller decides on an algorithm A for setting prices and this algorithm is
announced to the buyer. The buyer then selects a strategy B : (Ht1  vt  pt) 7! at. For any value
 2 (0  1) and strategy B  we deﬁne the buyer’s discounted expected surplus by

Sur(B) = E TXt=1

t1at(vt  pt).

A buyer minimizing this discounted surplus wishes to acquire the item as inexpensively as possible 
but does not wish to wait too long to obtain a favorable price.
In order to optimize his surplus  a buyer must then solve a non-homogeneous Markov decision pro-
cess (MDP). Indeed  consider the scenario where at time t the seller offers prices from a distribution
Dt 2 D  where D is a family of probability distributions over the interval [0  1]. The seller up-
dates his beliefs as follows: the current distribution Dt is selected as a function of the distribution
at the previous round as well as the history Ht1 (which is all the information available to the
seller). More formally  we let ft : (Dt  Ht) 7! Dt+1 be a transition function for the seller. Let
st = (Dt  Ht1  vt  pt) denote the state of the environment at time t  that is  all the information
available at time t to the buyer. Finally  let St(st) denote the maximum attainable expected surplus
of a buyer that is in state st at time t. It is clear that St will satisfy the following Bellman equations:
t1at(vt  pt) + E(vt+1 pt+1)⇠D⇥ft(Dt Ht)⇥St+1(ft(Dt  Ht)  Ht  vt+1  pt+1⇤ 
St(st) = max

with the boundary condition ST (sT ) = T1(vT  pT )1pT vT .
Deﬁnition 1. A buyer is said to be strategic if his action at time t is a solution of the Bellman
equation (1).

at2{0 1}

(1)

Notice that  depending on the choice of the family D  the number of states of the MDP solved by
a strategic buyer may be inﬁnite. Even for a deterministic algorithm that offers prices from a ﬁnite
set P  the number of states of this MDP would be in ⌦(T |P|)  which quickly becomes intractable.
Thus  in view of the prohibitive cost of computing his actions  the model of a fully strategic buyer
does not seem to be realistic. We introduce instead the concept of ✏-strategic buyers.

4

Deﬁnition 2. A buyer is said to be ✏-strategic if he behaves strategically  except when no sequence
of actions can improve upon the future surplus of the truthful sequence by more than t0✏  or except
for the ﬁrst 0 < t < t0 rounds  for some t0  0 depending only on the seller’s algorithm  in which
cases he acts truthfully.

We show in Section 4 that this deﬁnition implies the existence of t1 > t0 such that an ✏-strategic
buyer only solves an MDP over the interval [t0  t1] which becomes a tractable problem for t1 ⌧ T .
The parameter t0 used in the deﬁnition is introduced to consider the unlikely scenario where a
buyer’s algorithm deliberately ignores all information observed during the rounds 0 < t < t0  in
which case it is optimal for the buyer to behave truthfully.
Our deﬁnition is motivated by the fact that  for a buyer with bounded computational power  there is
no incentive in acting non-truthfully if the gain in surplus over a truthful behavior is negligible.

4 Regret Analysis

We now turn our attention to the problem faced by the seller. The seller’s goal is to maximize his
revenue. When the buyer is truthful  Kleinberg and Leighton (2003) have shown that this problem
can be cast as a continuous bandit problem. In that scenario  the strategic regret in fact coincides
with the pseudo-regret  which is the quantity commonly minimized in a stochastic bandit setting
(Auer et al.  2002; Bubeck and Cesa-Bianchi  2012). Thus  if the set of possible prices P is ﬁnite 
the seller can use the UCB algorithm Auer et al. (2002) to minimize his pseudo-regret.
In the presence of an ✏-strategic buyer  the rewards are no longer stochastic. Therefore  we need to
analyze the regret of a seller in the presence of lies. Let P denote a ﬁnite set of prices offered by
the seller. Deﬁne µp = pD(v > p) and p = µp⇤  µp. For every price p 2 P  deﬁne also Tp(t)
to be the number of times price p has been offered up to time t. We will denote by T ⇤ and µ⇤ the
corresponding quantities associated with the optimal price p⇤.
Lemma 1. Let L denote the number of times a buyer lies. For any  > 0  the strategic regret of a
seller can be bounded as follows:

RegT  E[L] + Xp : p>

E[Tp(t)]p + T .

Proof. Let Lt denote the event that the buyer lies at round t  then the expected revenue of a seller is
given by
t 

1vt>pp1pt=p1

atpt1pt=p(1

Lt + 1

where the last equality follows from the fact that when the buyer is truthful at = 1vt>p. Moreover 

TXt=1

Lc

1vt>pp1pt=p1

Lt

E TXt=1Xp2P
using the fact thatPT
EXp2P

TXt=1

t=1

1

Lt = L  we have

1vt>pp1pt=p1

Lc

Lc

atpt1pt=p1

t= EXp2P
1vt>pp1pt=p  EXp2P

TXt=1
µp E[Tp(T )]  E TXt=1

Lc

t ) E TXt=1Xp2P
t = EXp2P
=Xp2P
Xp2P

1vt>ptpt1

TXt=1
Lt

µp E[Tp(T )]  E[L].
Since the regret of offering prices for which p   is bounded by T   it follows that the regret of
the seller is bounded by E[L] +Pp : p> p E[Tp(T )] + T .
We now deﬁne a robust UCB (R-UCBL) algorithm for which we can bound the expectations
E[Tp(T )]. For every price p 2 P  deﬁne
bµp(t) =

pt1pt=p1vt>pt

tXi=1

Tp(t)

1

5

to be the true empirical mean of the reward that a seller would obtain when facing a truthful buyer.

the buyer lied. Notice that Lt(p) can be positive or negative. Finally  let

i=1at  1vt>p1pt=pp denote the revenue obtained by the seller in rounds where

Let Lt(p) =Pt

be the empirical mean obtained when offering price p that is observed by the seller. For the deﬁnition
of our algorithm  we will make use of the following upper conﬁdence bound:

Lt(p)
Tp(t)

µp(t) =bµp(t) +

Bp(t  L) =

Lp
Tp(t)

+s 2 log t

Tp(t)

.

µp(t) + Bp(t  L).

max
p2P

We will use B⇤ as a shorthand for Bp⇤. Our R-UCBL algorithm selects the price pt that maximizes
the quantity

We proceed to bound the expected number of times a sub-optimal price p is offered.

Proposition 1. Let Pt(p  L) := P Lt(p)

inequality holds:

Tp(t) + | Lt(p⇤)

32 log T

E[Tp(t)] 

4Lp
p

+

T ⇤(t)  L p
TXt=1

+ 2 +

2
p

Tp(t) + p⇤

T ⇤(t). Then  the following

Pt(p  L).

then

Proof. For any p and t deﬁne ⌘p(t) =q 2 log t
µp(t) + Bp(t  L)  µ⇤(t)  B⇤(t  L)  0

Tp(t) and let ⌘⇤ = ⌘p⇤. If at time t price p 6= p⇤ is offered

Lp⇤

Lt(p)

Tp(t) 

p + 32 log T

2
p

Lp
Tp(t) 

Lt(p⇤)
T ⇤(t)  0
Lt(p⇤)
T ⇤(t) 

This combined with the positivity of at least one of the four terms in (2) yields:

Tp(t) bµ⇤(t)  B⇤(t  L) 
  bµp(t) + Bp(t  L) +
  ⇥bµp(t)  µp  ⌘p(t)⇤ +⇥2Bp(t  L)  p⇤ +h Lt(p)

(2)
Therefore  if price p is selected  then at least one of the four terms in inequality (2) must be positive.
Let u = 4Lp

T ⇤(t)i
+⇥µ⇤ bµ⇤(t)  ⌘⇤(t)⇤  0.
. Notice that if Tp(t) > u then 2Bp(t  L)  p < 0. Thus  we can write
1pt=p(1Tp(t)u + 1Tp(t)>u)i = u +
TXt=u
T ⇤(t)⌘
Prbµp(t)  µp  ⌘p(t) + Pr⇣ Lt(p⇤)
Prbµp(t)  µp  ⌘p(t) + Prµ⇤ bµ⇤(t) > ⌘⇤(t) + Pt(p  L).
Tp(t)!  Pr 9s 2 [0  t] :
s !
p1vi>p  µp r 2 log t

E[Tp(T )] = Eh TXt=1
TXt=u
+ Prµ⇤ bµ⇤(t) > ⌘⇤(t)
TXt=u

We can now bound the probabilities appearing in (3) as follows:

E[Tp(T )]  u +

Pr(pt = p  Tp(t) > u).

Lt(p)
Tp(t) 

T ⇤(t) 

Lp
Tp(t)

 u +

Lp⇤

+

(3)

Pr bµp(t)  µp s 2 log t

1
s

sXi=1

t4 = t3 



tXs=1

6

where the last inequality follows from an application of Hoeffding’s inequality as well as the union
bound. A similar argument can be made to bound the other term in (3). Using the deﬁnition of u we
then have

32 log T

4Lp
p

+

+

2t3 +

E[Tp(T )] 
2
p
which completes the proof.
Corollary 1. Let L denote the number of times a buyer lies. Then  the strategic regret of R-UCBL
can be bounded as follows:

Pt(p  L) 

Pt(p  L) 

+ 2 +

2
p

+

32 log T

4Lp
p

TXt=1

TXt=u

TXt=1

RegT  L⇣4Xp2P

p⌘ + E[L] + Xp : p>✓ 32 log T

p

+ 2p +

Pt(p  L)◆ + T .

TXt=1

Notice that the choice of parameter L of R-UCBL is subject to a trade-off: on the one hand  L
should be small to minimize the ﬁrst term of this regret bound; on the other hand  function Pt(p  L)

t=1 Pt(p  L) is beneﬁcial for larger values of L.

is decreasing in T   therefore the termPT

We now show that an ✏-strategic buyer can only lie a ﬁnite number of times  which will imply
the existence of an appropriate choice of L for which we can ensure that Pt(p  L) = 0  thereby
recovering the standard logarithmic regret of UCB.
Proposition 2. If the discounting factor  satisﬁes   0 < 1  an ✏-strategic buyer stops lying
after S =l log(1/✏(10))

m rounds.

Proof. After S rounds  for any sequence of actions at the surplus that can be achieved by the buyer
in the remaining rounds is bounded by

log(1/0)

TXt=t0+S

E[at(vt  pt)] 

S+t0  T

1  



S+t0

1    ✏ 

for any sequence of actions. Thus  by deﬁnition  an ✏-strategic buyer does not lie after S rounds.
Corollary 2. If the discounting factor  satisﬁes   0 < 1 and the seller uses the R-UCBL
m  then the strategic regret of the seller is bounded by
algorithm with L =l log(1/✏(10))
'⇣4Xp2P

p + 1⌘ + Xp:p>

✏(10)
log 1
0

& log

+ 2p + T .

32 log T

log(1/0)

p

(4)

1

Proof. Follows trivially from Corollary 1 and the previous proposition  which implies that
Pt(p  L) ⌘ 0.
Let us compare our results with those of Amin et al. (2013). The regret bound given in (Amin et al. 
2013) is in O⇣|P|T ↵ + |P|2
rounds used for exploration and  = minp2P p. In particular  notice that the dependency of this
bound on the cardinality of P is quadratic instead of linear as in our case. Moreover  the dependency
1/↵). Therefore  even in a truthful scenario where  ⌧ 1. The dependency on T
on 0 is in O( 1
1
remains polynomial whereas we recover the standard logarithmic regret. Only when the seller has
access to   which is a strong requirement  can he set the optimal value of ↵ to achieve regret in

(10)1/↵⌘  where ↵ is a parameter controlling the fraction of

2/↵ +

|P|2

Oeplog T log 1
.

Of course  the algorithm proposed by Amin et al. (2013) assumes that the buyer is fully strategic
whereas we only require the buyer to be ✏-strategic. However  the authors assume that the distribu-
tion satisﬁes a Lipchitz condition which technically allows them to bound the number of lies in the
same way as in Proposition 2. Therefore  the regret bound achieved by their algorithm remains the
same in our scenario.

7

5 Continuous pricing strategy

Thus far  we have assumed that the prices offered by the buyer are selected out of a discrete set P.
In practice  however  the optimal price may not be within P and therefore the algorithm described in
the previous section might accumulate a large regret when compared against the best price in [0  1].
In order to solve this problem  we propose to discretize the interval [0  1] and run our R-UCBL algo-
rithm on the resulting discretization. This induces a trade-off since a better discretization implies a
larger regret term in (4). To ﬁnd the optimal size of the discretization we follow the ideas of Klein-
berg and Leighton (2003) and consider distributions D that satisfy the condition that the function
f : p 7! pD(v > p) admits a unique maximizer p⇤ such that f00(p) < 0.
Throughout this section  we let K 2 N and we consider the following ﬁnite set of prices
PK =  i
K|1  i  K ⇢ [0  1]. We also let pK be an optimal price in PK  that is pK 2
argmaxp2PK f (p) and we let p⇤ = argmaxp2[0 1] f (p). Finally  we denote by p = f (pK) f (p)
the sub-optimality gap with respect to price pK and by p = f (p⇤)  f (p) the corresponding
gap with respect to p⇤. The following theorem can be proven following similar ideas to those of
Kleinberg and Leighton (2003). We defer its proof to the appendix.
log T1/4  if the discounting factor  satisﬁes   0 < 1 and the seller
Theorem 1. Let K =  T
m  then the strategic
uses the R-UCBL algorithm with the set of prices PK and L =l log(1/✏(10))
'⇣ T
f (p)  E TXt=1
log T⌘1/4

atpt  CpT log T +& log

regret of the seller can be bounded as follows:

+ 1.

max
p2[0 1]

log(1/0)

1

✏(10)
log 1
0

6 Conclusion

We introduced a revenue optimization algorithm for posted-price auctions that is robust against ✏-
strategic buyers. Moreover  we showed that our notion of strategic behavior is more natural than

what has been previously studied. Our algorithm beneﬁts from the optimal O log T + 1
bound for a ﬁnite set of prices and admits regret in OT 1/2 + T 1/4

1 regret
1 when the buyer is offered prices

in [0  1]  a scenario that had not been considered previously in the literature of revenue optimization
against strategic buyers. It is known that a regret in o(T 1/2) is unattainable even in a truthful set-
ting  but it remains an open problem to verify that the dependency on  cannot be improved. Our
algorithm admits a simple analysis and we believe that the idea of making truthful algorithms robust
is general and can be extended to more complex auction mechanisms such as second-price auctions
with reserve.

7 Acknowledgments

We thank Afshin Rostamizadeh and Umar Syed for useful discussions about the topic of this paper
and the NIPS reviewers for their insightful comments. This work was partly funded by NSF IIS-
1117591 and NSF CCF-1535987.

8

References
Abernethy  J.  E. Hazan  and A. Rakhlin (2008). Competing in the dark: An efﬁcient algorithm for

bandit linear optimization. In Proceedings of COLT 2008  pp. 263–274.

Amin  K.  A. Rostamizadeh  and U. Syed (2013). Learning prices for repeated auctions with strategic

buyers. In Proceedings of NIPS  pp. 1169–1177.

Amin  K.  A. Rostamizadeh  and U. Syed (2014). Repeated contextual auctions with strategic buy-

ers. In Proceedings of NIPS 2014  pp. 622–630.

Arora  R.  O. Dekel  and A. Tewari (2012). Online bandit learning against an adaptive adversary:

from regret to policy regret. In Proceedings of ICML.

Auer  P.  N. Cesa-Bianchi  and P. Fischer (2002). Finite-time analysis of the multiarmed bandit

problem. Machine Learning 47(2-3)  235–256.

Bikhchandani  S. and K. McCardle (2012). Behaviour-based price discrimination by a patient seller.

The B.E. Journal of Theoretical Economics 12(1)  1935–1704.

Bubeck  S. and N. Cesa-Bianchi (2012). Regret analysis of stochastic and nonstochastic multi-armed

bandit problems. Foundations and Trends in Machine Learning 5(1)  1–122.

Cesa-Bianchi  N.  C. Gentile  and Y. Mansour (2015). Regret minimization for reserve prices in

second-price auctions. IEEE Transactions on Information Theory 61(1)  549–564.

Cole  R. and T. Roughgarden (2014). The sample complexity of revenue maximization. In Proceed-

ings of STOC 2014  pp. 243–252.

Cui  Y.  R. Zhang  W. Li  and J. Mao (2011). Bid landscape forecasting in online ad exchange

marketplace. In Proceedings of SIGKDD 2011  pp. 265–273.

Dani  V. and T. P. Hayes (2006). Robbing the bandit: less regret in online geometric optimization

against an adaptive adversary. In Proceedings of SODA 2006  pp. 937–943.

Edelman  B. and M. Ostrovsky (2007). Strategic bidder behavior in sponsored search auctions.

Decision Support Systems 43(1)  192–198.

Kanoria  Y. and H. Nazerzadeh (2014). Dynamic reserve prices for repeated auctions: Learning

from bids. In Proceedings of WINE 2014  pp. 232.

Kleinberg  R. D. and F. T. Leighton (2003). The value of knowing a demand curve: Bounds on

regret for online posted-price auctions. In Proceedings of FOCS 2003  pp. 594–605.

Lai  T. and H. Robbins (1985). Asymptotically efﬁcient adaptive allocation rules. Advances in

Applied Mathematics 6(1)  4 – 22.

Milgrom  P. and R. Weber (1982). A theory of auctions and competitive bidding. Econometrica:

Journal of the Econometric Society 50(5)  1089–1122.

Milgrom  P. R. (2004). Putting auction theory to work. Cambridge University Press.
Mohri  M. and A. M. Medina (2014a). Learning theory and algorithms for revenue optimization in

second price auctions with reserve. In Proceedings of ICML 2014  pp. 262–270.

Mohri  M. and A. M. Medina (2014b). Optimal regret minimization in posted-price auctions with

strategic buyers. In Proceedings of NIPS 2014  pp. 1871–1879.

Myerson  R. B. (1981). Optimal auction design. Mathematics of Operations Research 6(1)  pp.

58–73.

Nachbar  J. (2001). Bayesian learning in repeated games of incomplete information. Social Choice

and Welfare 18(2)  303–326.

Nachbar  J. H. (1997). Prediction  optimization  and learning in repeated games. Econometrica:

Journal of the Econometric Society 65(2)  275–309.

Vickrey  W. (1961). Counterspeculation  auctions  and competitive sealed tenders. The Journal of

ﬁnance 16(1)  8–37.

9

,Mehryar Mohri
Andres Munoz
Peng Xu
Jiyan Yang
Fred Roosta
Michael Mahoney