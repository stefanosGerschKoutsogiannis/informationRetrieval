2017,Stochastic Approximation for Canonical Correlation Analysis,We propose novel first-order stochastic approximation algorithms for canonical correlation analysis (CCA). Algorithms presented are instances of inexact matrix stochastic gradient (MSG) and inexact matrix exponentiated gradient (MEG)  and achieve $\epsilon$-suboptimality in the population objective in $\operatorname{poly}(\frac{1}{\epsilon})$ iterations. We also consider practical variants of the proposed algorithms and compare them with other methods for CCA both theoretically and empirically.,Stochastic Approximation

for Canonical Correlation Analysis

Raman Arora

Dept. of Computer Science
Johns Hopkins University

Baltimore  MD 21204
arora@cs.jhu.edu

Teodor V. Marinov

Dept. of Computer Science
Johns Hopkins University

Baltimore  MD 21204
tmarino2@jhu.edu

Nathan Srebro
TTI-Chicago

Chicago  Illinois 60637

nati@ttic.edu

Poorya Mianjy

Dept. of Computer Science
Johns Hopkins University

Baltimore  MD 21204

mianjy@jhu.edu

Abstract

We propose novel ﬁrst-order stochastic approximation algorithms for canonical
correlation analysis (CCA). Algorithms presented are instances of inexact matrix
stochastic gradient (MSG) and inexact matrix exponentiated gradient (MEG)  and
achieve ✏-suboptimality in the population objective in poly( 1
✏ ) iterations. We also
consider practical variants of the proposed algorithms and compare them with other
methods for CCA both theoretically and empirically.

1

Introduction

Canonical Correlation Analysis (CCA) [11] is a ubiquitous statistical technique for ﬁnding maximally
correlated linear components of two sets of random variables. CCA can be posed as the following
stochastic optimization problem: given a pair of random vectors (x  y) 2 Rdx ⇥ Rdy  with some
(unknown) joint distribution D  ﬁnd the k-dimensional subspaces where the projections of x and y
are maximally correlated  i.e. ﬁnd matrices ˜U 2 Rdx⇥k and ˜V 2 Rdy⇥k that

maximize Ex y[x> ˜U ˜V>y] subject to ˜U>Ex[xx>] ˜U = Ik  ˜V>Ey[yy>] ˜V = Ik.

(1)

CCA-based techniques have recently met with success at unsupervised representation learning where
multiple “views” of data are used to learn improved representations for each of the views [3  5  13 
23]. The different views often contain complementary information  and CCA-based “multiview”
representation learning methods can take advantage of this information to learn features that are
useful for understanding the structure of the data and that are beneﬁcial for downstream tasks.
Unsupervised learning techniques leverage unlabeled data which is often plentiful. Accordingly 
in this paper  we are interested in ﬁrst-order stochastic Approximation (SA) algorithms for solving
Problem (1) that can easily scale to very large datasets. A stochastic approximation algorithm is an
iterative algorithm  where in each iteration a single sample from the population is used to perform an
update  as in stochastic gradient descent (SGD)  the classic SA algorithm.
There are several computational challenges associated with solving Problem (1). A ﬁrst challenge
stems from the fact that Problem (1) is non-convex. Nevertheless  akin to related spectral methods
such as principal component analysis (PCA)  the solution to CCA can be given in terms of a
generalized eigenvalue problem. In other words  despite being non-convex  CCA admits a tractable

31st Conference on Neural Information Processing Systems (NIPS 2017)  Long Beach  CA  USA.

algorithm. In particular  numerical techniques based on power iteration method and its variants can
be applied to these problems to ﬁnd globally optimal solutions. Much recent work  therefore  has
focused on analyzing optimization error for power iteration method for the generalized eigenvalue
problem [1  8  24]. However  these analyses are on numerical (empirical) optimization error for
ﬁnding left and right singular vectors of a ﬁxed given matrix based on empirical estimates of the
covariance matrices  and not on the population ✏suboptimality (aka bound in terms of population
objective) of Problem (1) which is the focus here.
The second challenge  which is our main concern here  presents when designing ﬁrst order stochastic
approximation algorithms for CCA. The main difﬁculty here  compared to PCA  and most other
machine learning problems  is that the constraints also involve stochastic quantities that depend on the
unknown distribution D. Put differently  the CCA objective does not decompose over samples. To see
this  consider the case for k = 1. The CCA problem then can be posed equivalently as maximizing

the correlation objective ⇢(uT x  vT y) = Ex y⇥u>xy>v⇤/(pEx [u>xx>u]pEy [v>yy>v]). This

yields an unconstrained optimization problem. However  the objective is no longer an expectation 
but is instead a ratio of expectations. If we were to solve the empirical version of this problem 
it is easy to check that the objective ties all the samples together. This departs signiﬁcantly from
typical stochastic approximation scenario. Crucially  with a single sample  it is not possible to get an
unbiased estimate of the gradient of the objective ⇢(uT x  vT y). Therefore  we consider a ﬁrst-order
oracle that provides inexact estimates of the gradient with a norm bound on the additive noise  and
focus on inexact proximal gradient descent algorithms for CCA.
Finally  it can be shown that the CCA problem given in Problem (1) is ill-posed if the population

auto-covariance matrices Ex⇥xx>⇤ or Ey⇥yy>⇤ are ill-conditioned. This observation follows from
the fact that if there exists a direction in the kernel of Ex⇥xx>⇤ or Ey⇥yy>⇤ in which x and y
exhibit non-zero covariance  then the objective of Problem (1) is unbounded. We would like to avoid
recovering such directions of spurious correlation and therefore assume that the smallest eigenvalues
of the auto-covariance matrices and their empirical estimates are bounded below by some positive
constant. Formally  we assume that Cx ⌫ rxI and Cy ⌫ ryI. This is the typical assumption made in
analyzing CCA [1  7  8].

1.1 Notation
Scalars  vectors and matrices are represented by normal  Roman and capital Roman letters respectively 
e.g. x  x  and X. Ik denotes identity matrix of size k ⇥ k  where we drop the subscript whenever the
size is clear from the context. The `2-norm of a vector x is denoted by kxk. For any matrix X  spectral
norm  nuclear norm  and Frobenius norm are represented by kXk2  kXk⇤  and kXkF respectively.
The trace of a square matrix X is denoted by Tr (X). Given two matrices X 2 Rk⇥d  Y 2 Rk⇥d  the
standard inner-product between the two is given as hX  Yi = TrX>Y; we use the two notations
interchangeably. For symmetric matrices X and Y  we say X ⌫ Y if X  Y is positive semi-deﬁnite
(PSD). Let x 2 Rdx and y 2 Rdy denote two sets of centered random variables jointly distributed as
D with corresponding auto-covariance matrices Cx = Ex[xx>]  Cy = Ey[yy>]  and cross-covariance
matrix Cxy = E(x y)[xy>]  and deﬁne d := max{dx  dy}. Finally  X 2 Rdx⇥n and Y 2 Rdy⇥n
denote data matrices with n corresponding samples from view 1 and view 2  respectively.

1.2 Problem Formulation
Given paired samples (x1  y1)  . . .   (xT   yT )  drawn i.i.d. from D  the goal is to ﬁnd a maximally
correlated subspace of D  i.e. in terms of the population objective. A simple change of variables in
Problem (1)  with U = C1/2

y ˜V  yields the following equivalent problem:

x ˜U and V = C1/2

maximize Tr⇣U>C 1

y V⌘ s.t. U>U = I  V>V = I.

(2)
To ensure that Problem 2 is well-posed  we assume that r := min{rx  ry} > 0  where rx = min(Cx)
and ry = min(Cy) are smallest eigenvalues of the population auto-covariance matrices. Furthermore 
we assume that with probability one  for (x  y) ⇠ D  we have that max{kxk2  kyk2} B. Let
 2 Rdx⇥k and 2 Rdy⇥k denote the top-k left and right singular vectors  respectively  of the
population cross-covariance matrix of the whitened views T := C1/2
. It is easy to check
that the optimum of Problem (1) is achieved at U⇤ = C1/2
y . Therefore  a natural

x   V⇤ = C1/2

x CxyC1/2

y

x Cxy C 1

2

2

2

approach  given a training dataset  is to estimate empirical auto-covariance and cross-covariance

matrices to compute bT  an empirical estimate of T; matrices U⇤ and V⇤ can then be estimated
using the top-k left and right singular vectors ofbT. This approach is referred to as sample average
approximation (SAA) or empirical risk minimization (ERM).
In this paper  we consider the following equivalent re-parameterization of Problem (2) given by the
variable substitution M = UV>  also referred to as lifting. Find M 2 Rdx⇥dy that
maximize hM  C 1
We are interested in designing SA algorithms that  for any bounded distribution D with minimum
eigenvalue of the auto-covariance matrices bounded below by r  are guaranteed to ﬁnd an ✏-suboptimal
solution on the population objective (3)  from which  we can extract a good solution for Problem (1).

i s.t. i(M) 2{ 0  1}  i = 1  . . .   min{dx  dy}  rank (M)  k.

x CxyC 1

(3)

y

2

2

1.3 Related Work
There has been a ﬂurry of recent work on scalable approaches to the empirical CCA problem 
i.e. methods for numerical optimization of the empirical CCA objective on a ﬁxed data set [1  8  14 
15  24]. These are typically batch approaches which use the entire data set at each iteration  either for
performing a power iteration [1  8] or for optimizing the alternative empirical objective [14  15  24]:
minimize 1

F s.t. ˜U>Cx n ˜U = I  ˜V>Cy n ˜V = I 

(4)

2nk ˜U>X  ˜V>Yk2

F + xk ˜Uk2

F + yk ˜Vk2

where Cx n and Cy n are the empirical estimates of covariance matrices for the n samples stacked
in the matrices X 2 Rdx⇥n and Y 2 Rdy⇥n  using alternating least squares [14]  projected gradient
descent (AppaGrad  [15]) or alternating SVRG combined with shift-and-invert pre-conditioning [24].
However  all the works above focus only on the empirical problem  and can all be seen as instances of
SAA (ERM) approach to the stochastic optimization (learning) problem (1). In particular  the analyses
in these works bounds suboptimality on the training objective  not the population objective (1).
The only relevant work we are aware of that studies algorithms for CCA as a population problem is a
parallel work by [7]. However  there are several key differences. First  the objective considered in [7]
is different from ours. The focus in [7] is on ﬁnding a solution U  V that is very similar (has high
alignment with) the optimal population solution U⇤  V⇤. In order for this to be possible  [7] must rely
on an "eigengap" between the singular values of the cross-correlation matrix Cxy. In contrast  since
we are only concerned with ﬁnding a solution that is good in terms of the population objective (2) 
we need not  and do not  depend on such an eigengap. If there is no eigengap in the cross-correlation
matrix  the population optimal solution is not well-deﬁned  but that is ﬁne for us – we are happy to
return any optimal (or nearly optimal) solution.
Furthermore  given such an eigengap  the emphasis in [7] is on the guaranteed overall runtime of their
method. Their core algorithm is very efﬁcient in terms of runtime  but is not a streaming algorithm
and cannot be viewed as an SA algorithm. They do also provide a streaming version  which is runtime
and memory efﬁcient  but is still not a “natural” SA algorithm  in that it does not work by making
a small update to the solution at each iteration. In contrast  here we present a more “natural” SA
algorithm and put more emphasis on its iteration complexity  i.e. the number of samples processed.
We do provide polynomial runtime guarantees  but rely on a heuristic capping in order to achieve
good runtime performance in practice.
Finally  [7] only consider obtaining the top correlated direction (k = 1) and it is not clear how to
extend their approach to Problem (1) of ﬁnding the top k  1 correlated directions. Our methods
handle the general problem  with k  1  naturally and all our guarantees are valid for any number of
desired directions k.

1.4 Contributions
The goal in this paper is to directly optimize the CCA “population objective” based on i.i.d. draws
from the population rather than capturing the sample  i.e. the training objective. This view justiﬁes
and favors stochastic approximation approaches that are far from optimal on the sample but are
essentially as good as the sample average approximation approach on the population. Such a view

3

has been advocated in supervised machine learning [6  18]; here  we carry over the same view to the
rich world of unsupervised learning. The main contributions of the paper are as follows.

• We give a convex relaxation of the CCA optimization problem. We present two stochastic
approximation algorithms for solving the resulting problem. These algorithms work in a
streaming setting  i.e. they process one sample at a time  requiring only a single pass through
the data  and can easily scale to large datasets.

• The proposed algorithms are instances of inexact stochastic mirror descent with the choice
of potential function being Frobenius norm and von Neumann entropy  respectively. Prior
work on inexact proximal gradient descent suggests a lower bound on the size of the noise
required to guarantee convergence for inexact updates [16]. While that condition is violated
here for the CCA problem  we give a tighter analysis of our algorithms with noisy gradients
establishing sub-linear convergence rates.

• We give precise iteration complexity bounds for our algorithms  i.e. we give upper bounds
on iterations needed to guarantee a user-speciﬁed ✏-suboptimality (w.r.t. population) for
CCA. These bounds do not depend on the eigengap in the cross-correlation matrix. To the
best of our knowledge this is a ﬁrst such characterization of CCA in terms of generalization.
• We show empirically that the proposed algorithms outperform existing state-of-the-art
methods for CCA on a real dataset. We make our implementation of the proposed algorithms
and existing competing techniques available online1.

2 Matrix Stochastic Gradient for CCA (MSG-CCA)

Problem (3) is a non-convex optimization problem  however  it admits a simple convex relaxation.
Taking the convex hull of the constraint set in Problem 3 gives the following convex relaxation:

2

2

y

x CxyC 1

maximize hM  C 1

i s.t. kMk2  1  kMk⇤  k.

(5)
While our updates are designed for Problem (5)  our algorithm returns a rank-k solution  through a
simple rounding procedure ([27  Algorithm 4]; see more details below)  which has the same objective
in expectation. This allows us to guarantee ✏-suboptimality of the output of the algorithm on the
original non-convex Problem (3)  and equivalently Problem (2).
Similar relaxations have been considered previously to design stochastic approximation (SA) al-
gorithms for principal component analysis (PCA) [2] and partial least squares (PLS) [4]. These
SA algorithms are instances of stochastic gradient descent – a popular choice for convex learning
problems. However  designing similar updates for the CCA problem is challenging since the gradient
of the CCA objective (see Problem (5)) w.r.t. M is g := C1/2
  and it is not at all clear
how one can design an unbiased estimator  gt  of the gradient g unless one knows the marginal
distributions of x and y. Therefore  we consider an instance of inexact proximal gradient method [16]
which requires access to a ﬁrst-order oracle with noisy estimates  @t  of gt. We show that an oracle

x CxyC1/2

with bound on E[PT

t=1 kgt  @tk] of O(pT ) ensures convergence of the proximal gradient method.

Furthermore  we propose a ﬁrst order oracle with the above property which instantiates the inexact
gradient as

(6)
where Wx t  Wy t are empirical estimates of whitening transformation based on training data seen
until time t. This leads to the following stochastic inexact gradient update:

@t := Wx txty>t Wy t ⇡ gt 

y

Mt+1 = PF (Mt + ⌘t@t) 

(7)

where PF is the projection operator onto the constraint set of Problem (5).
Algorithm 1 provides the pseudocode for the proposed method which we term inexact matrix
stochastic gradient method for CCA (MSG-CCA). At each iteration  we receive a new sample
(xt  yt)  update the empirical estimates of the whitening transformations which deﬁne the inexact
gradient @t. This is followed by a gradient update with step-size ⌘  and projection onto the set of
constraints of Problem (5) with respect to the Frobenius norm through the operator PF (·) [2]. After
T iterations  the algorithm returns a rank-k matrix after a simple rounding procedure [27].
1https://www.dropbox.com/sh/dkz4zgkevfyzif3/AABK9JlUvIUYtHvLPCBXLlpha?dl=0

4

Algorithm 1 Matrix Stochastic Gradient for CCA (MSG-CCA)
Input: Training data {(xt  yt)}T
t=1  step size ⌘  auxiliary training data {(x0i  y0i)}⌧
Output: ˜M
⌧P⌧
⌧P⌧
i=1 x0ix0i>  Cy 0 1
1: Initialize: M1 0  Cx 0 1
2: for t = 1 ···   T do
t+⌧ xtx>t   Wx t C 1
t+⌧ Cx t1 + 1
3:
t+⌧ yty>t   Wy t C 1
t+⌧ Cy t1 + 1
4:

i=1 y0iy0i>

2
y t

2
x t

i=1

Cx t t+⌧1
Cy t t+⌧1
@t Wx txty>t Wy t

5:
6: Mt+1 PF (Mt + ⌘@t)
7: end for
8: ¯M = 1
9: ˜M = rounding( ¯M)

T PT

t=1 Mt

% Projection given in [2]

% Algorithm 2 in [27]

⌧  max{

1
cx

1
c y

log (2dy)}.

We denote the empirical estimates of auto-covariance matrices based on the ﬁrst t samples by Cx t
and Cy t. Our analysis of MSG-CCA follows a two-step procedure. First  we show that the empirical
estimates of the whitening transform matrices  i.e. Wx t := C1/2
  guarantee that the
expected error in the “inexact” estimate  @t  converges to zero as O(1/pt). Next  we show that the
resulting noisy stochastic gradient method converges to the optimum as O(1/pT ). In what follows 
we will denote the true whitening transforms by Wx := C1/2
Since Algorithm 1 requires inverting empirical auto-covariance matrices  we need to ensure that the
smallest eigenvalues of Cx t and Cy t are bounded away from zero. Our ﬁrst technical result shows
that in this happens with high probability for all iterates.
Lemma 2.1. With probability 1   with respect to training data drawn i.i.d.
uniformly for all t that min(Cx t)  rx

and Wy := C1/2

from D  it holds

  Wy t := C1/2

2 whenever:

x t

y t

.

x

y

log0@ 2dx
log⇣ 1
1⌘

1A  1 

2 and min(Cy t)  ry
1
c x

log (2dx)  

1
cy

log0@ 2dy
log⇣ 1
1⌘

1A  1 

y

x

.

6B2+Bry

6B2+Brx

  cy = 3r2

Here cx = 3r2
We denote by At the event that for all j = 1  ..  t  1 the empirical cross-covariance matrices
Cx j and Cy j have their smallest eigenvalues bounded from below by rx and ry  respectively.
Lemma 2.1 above  guarantees that this event occurs with probability at least 1    as long as there
are ⌧ =⌦ ✓ B2
Lemma 2.2. Assume that the event At occurs  and that with probability one  for (x  y) ⇠ D  we
have max{kxk2  kyk2} B. Then  for  := 8B2p2 log(d)
ED [kgt  @tk2 | At] 

1 )◆◆ samples in the auxiliary dataset.

  the following holds for all t:

pt

r2 log✓ 2d

log( 1

r2

.

The result above bounds the size of the expected noise in the estimate of the inexact gradient. Not
surprisingly  the error decays as our estimates of the whitening transformation improve with more
data. Moreover  the rate at which the error decreases is sufﬁcient to bound the suboptimality of the
MSG-CCA algorithm even with noisy biased stochastic gradients.
Theorem 2.3. After T iterations of MSG-CCA (Algorithm 1) with step size ⌘ = 2pk
GpT
sample of size ⌧ =⌦( B2
))  and initializing M1 = 0  the following holds:
2pkG + 2k + kB/r

  auxiliary

r2 log(

log(

2d

hM⇤  C 1

2

x CxyC 1

y

2

x CxyC 1

y

2

i] 

pT

)

pTpT1
i  E[h ˜M  C 1

2

 

(8)

5

where the expectation is with respect to the i.i.d. samples and rounding   is as deﬁned in Lemma 2.2 
M⇤ is the optimum of (3)  ˜M is the rank-k output of MSG-CCA  and G = 2Bprxry
While Theorem 2.3 gives a bound on the objective of Problem (3)  it implies a bound on the original
CCA objective of Problem (1). In particular  given a rank-k factorization of ˜M := UV>  such that
U>U = Ik and V>V = Ik  we construct

.

˜U = C 1

x T U  ˜V := C 1

y T V.

2

2

We then have the following generalization bound.
Theorem 2.4. After T iterations of MSG-CCA (Algorithm 1) with step size ⌘ = 2pk
GpT
sample of size ⌧ =⌦( B2
T1 ) ))  and initializing M1 = 0  the following holds

r2 log(

2d
log( T

(9)

  auxiliary

Tr(U>

⇤ CxyV⇤)E[Tr( ˜U>Cxy ˜V)] 

E[k ˜U>Cx ˜U  Ik2] 

E[k ˜V>Cy ˜V  Ik2] 

2pkG + 2k

pT

T

x r 2B2
y r 2B2

T

B
r2

B
r2

2kB

+

kB
rT

+

log (dx) +

log (dy) +

log (d) +

log (d)! 

2B
3T

T

r2 r 2B2
log (dx)! +
log (dy)! +

2B
3T

2B
3T

B + 1

T

B + 1

T

 

 

.

where the expectation is with respect to the i.i.d. samples and rounding  the pair (U⇤  V⇤) is
the optimum of (1)  ( ˜U   ˜V ) are the factors (deﬁned in (9)) of the rank-k output of MSG-CCA 
r := min{rx  ry}  d := max{dx  dy}   is as given in Lemma 2.2  and G = 2Bprxry
All proofs are deferred to the Appendix in the supplementary material. Few remarks are in order.
Convexity: In our design and analysis of MSG-CCA  we have leveraged the following observations:
(i) since the objective is linear  an optimum of (5) is always attained at an extreme point  corresponding
to an optimum of (3); (ii) the exact convex relaxation (5) is tractable (this is not often the case for
non-convex problems); and (iii) although (5) might also have optima not on extreme points  we have
an efﬁcient randomized method  called rounding  to extract from any feasible point of (5) a solution
of (3) that has the same value in expectation [27].
Eigengap free bound: Theorem 2.3 and 2.4 do not require an eigengap in the cross-correlation
matrix Cxy  and in particular the error bound  and thus the implied iteration complexity to achieve a
desired suboptimality does not depend on an eigengap.
Comparison with [7]: It is not straightforward to compare with the results of [7]. As discussed in
Section 1.3  authors in [7] consider only the case k = 1 and their objective is different than ours. They
seek (u  v) that have high alignment with the optimal (u⇤  v⇤) as measured through the alignment
2¯u>Cxu⇤ + ¯v>Cyv⇤. Furthermore  the analysis in [7] is dependent on the eigengap
(¯u  ¯v) := 1
 = 1  2 between the top two singular values 1  2 of the population cross-correlation matrix T.
Nevertheless  one can relate their objective (u  v) to ours and ask what their guarantees ensure in
terms of our objective  namely achieving ✏-suboptimality for Problem (3). For the case k = 1  and
in the presence of an eigengap   the method of [7] can be used to ﬁnd an ✏-suboptimal solution to
Problem (3) with O( log2(d)
Capped MSG-CCA: Although MSG-CCA comes with good theoretical guarantees  the compu-
tational cost per iteration can be O(d3). Therefore  we consider a practical variant of MSG-CCA
that explicitly controls the rank of the iterates. To ensure computational efﬁciency  we recommend
imposing a hard constraint on the rank of the iterates of MSG-CCA  following an approach similar to
previous works on PCA [2] and PLS [4]:
x CxyC 1

(10)
For estimates of the whitening transformations  at each iteration  we set the smallest dK eigenvalues
of the covariance matrices to a constant (of the order of the estimated smallest eigenvalue of the

i s.t. kMk2  1  kMk⇤  k  rank (M)  K.

maximize hM  C 1

✏2 ) samples.

y

2

2

6

covariance matrix). This allows us to efﬁciently compute the whitening transformations since the
covariance matrices decompose into a sum of a low-rank matrix and a scaled identity matrix  bringing
down the computational cost per iteration to O(dK2). We observe empirically on a real dataset
(see Section 4) that this procedure along with capping the rank of MSG iterates does not hurt the
convergence of MSG-CCA.

3 Matrix Exponentiated Gradient for CCA (MEG-CCA)

In this section  we consider matrix multiplicative weight updates for CCA. Multiplicative weights
method is a generic algorithmic technique in which one updates a distribution over a set of interest
by iteratively multiplying probability mass of elements [12]. In our setting  the set is that of d k-
dimensional (paired) subspaces and the multiplicative algorithm is an instance of matrix exponentiated
gradient (MEG) update. A motivation for considering MEG is the fact that for related problems 
including principal component analysis (PCA) and partial least squares (PLS)  MEG has been shown
to yield fast optimistic rates [4  22  26]. Unfortunately we are not able to recover such optimistic
rates for CCA as the error in the inexact gradient decreases too slowly.
Our development of MEG requires the symmetrization of Problem (3). Recall that g :=
C1/2
d = dx + dy. The matrix C is referred to as the self-adjoint dilation of the matrix g [20]. Given the
SVD of g = U⌃V> with no repeated singular values  the eigen-decomposition of C is given as

. Consider the following symmetric matrix C := 0
0 ⌃◆✓U U
V V◆>

0  of size d ⇥ d  where

2✓U U
V V◆✓⌃0

x CxyC1/2

C =

1

g

g

y

.

In other words  the top-k left and right singular vectors of C1/2
  which comprise the CCA
solution we seek  are encoded in top and bottom rows  respectively  of the top-k eigenvectors of its
dilation. This suggests the following scaled re-parameterization of Problem (3): ﬁnd M 2 Rd⇥d that
(11)

maximize hM  Ci s.t. i(M) 2{ 0  1}  i = 1  . . .   d  rank (M) = k.

x CxyC1/2

y

As in Section 2  we take the convex hull of the constraint set to get a convex relaxation to Problem (11).

(12)
Stochastic mirror descent on Problem (12) with the choice of potential function being the quantum
relative entropy gives the following updates [4  27]:

maximize hM  Ci s.t. M ⌫ 0 kMk2  1  Tr (M) = k.

  Mt = P⇣bMt⌘  

(13)

exp (log (Mt1) + ⌘Ct)

Tr (exp (log (Mt1) + ⌘Ct))

bMt =

where Ct is the self-adjoint dilation of unbiased instantaneous gradient gt  and P denotes the Bregman
projection [10] onto the convex set of constraints in Problem (12). As discussed in Section 2 we

t=1 kCt  ˜Ctk|AT ] of O(pT ).
only need an inexact gradient estimate ˜Ct of Ct with a bound on E[PT
Setting ˜Ct to be the self-adjoint dilation of @t  deﬁned in Section 2  guarantees such a bound.
Lemma 3.1. Assume that the event At occurs gt  @t has no repeated singular values and that with
probability one  for (x  y) ⇠ D  we have max{kxk2  kyk2} B. Then  for  deﬁned in lemma 2.2 
we have that  Ext ythMt1  M⇤  Ct  ˜Ct|Ati  2kpt
  where M⇤ is the optimum of Problem (11).
Using the bound above  we can bound the suboptimality gap in the population objective between the
true rank-k CCA solution and the rank-k solution returned by MEG-CCA.
Theorem 3.2. After T iterations of MEG-CCA (see Algorithm 2 in Appendix) with step size ⌘ =
)) and initializing M0 = 1
d I 
1

GT ◆  auxiliary sample of size ⌧ =⌦( B2

G log✓1 +q log(d)

r2 log(

pTpT1

log(

2d

)

the following holds:

hM⇤  Ci  E[h ˜M  Ci]  2kr G2 log (d)

T

+ 2

k
pT

 

7

where the conditional expectation is taken with respect to the distribution and the internal randomiza-
tion of the algorithm  M⇤ is the optimum of Problem (11)  ˜M is the rank-k output of MEG-CCA after
rounding  G = 2Bprxry

and  is deﬁned in Lemma 2.2.

All of our remarks regarding latent convexity of the problem and practical variants from Section 2
apply to MEG-CCA as well. We note  however  that without additional assumptions like eigengap for
T we are not able to recover projections to the canonical subspaces as done in Theorem 2.4.

4 Experiments

We provide experimental results for our proposed methods  in particular we compare capped-MSG
which is the practical variant of Algorithm 1 with capping as deﬁned in equation (10)  and MEG
(Algorithm 2 in the Appendix)  on a real dataset  Mediamill [19]  consisting of paired observations
of videos and corresponding commentary. We compare our algorithms against CCALin of [8]  ALS
CCA of [24]2  and SAA  which is denoted by “batch” in Figure 1. All of the comparisons are given
in terms of the CCA objective as a function of either CPU runtime or number of iterations. The
target dimensionality in our experiments is k 2{ 1  2  4}. The choice of k is dictated largely by the
fact that the spectrum of the Mediamill dataset decays exponentially. To ensure that the problem
is well-conditioned  we add I for  = 0.1 to the empirical estimates of the covariance matrices on
Mediamill dataset. For both MSG and MEG we set the step size at iteration t to be ⌘t = 0.1pt .
Mediamill is a multiview dataset consisting of n = 10  000 corresponding videos and text annota-
tions with labels representing semantic concepts [19]. The image view consists of 120-dimensional
visual features extracted from representative frames selected from videos  and the textual features are
100-dimensional. We give the competing algorithms  both CCALin and ALS CCA  the advantage of

the knowledge of the eigengap at k. In particular  we estimate the spectrum of the matrixbT for the

Mediamill dataset and set the gap-dependent parameters in CCALin and ALS CCA accordingly.
We note  however  that estimating the eigengap to set the parameters is impractical in real scenarios.
Both CCALin and ALS CCA will therefore require additional tuning compared to MSG and MEG
algorithms proposed here. In the experiments  we observe that CCALin and ALS CCA outperform
MEG and capped-MSG when recovering the top CCA component  in terms of progress per-iteration.
However  capped-MSG is the best in terms of the overall runtime. The plots are shown in Figure 1.

5 Discussion

✏2 ).

We study CCA as a stochastic optimization problem and show that it is efﬁciently learnable by
providing analysis for two stochastic approximation algorithms. In particular  the proposed algorithms
achieve ✏-suboptimality in population objective in iterations O( 1
Note that both of our Algorithms  MSG-CCA in Algorithm 1 and MEG-CCA in Algorithm 2
in Appendix B are instances of inexact proximal-gradient method which was studied in [16]. In
particular  both algorithms receive a noisy gradient @t = gt + Et at iteration t and perform exact
proximal steps (Bregman projections in equations (7) and (13)). The main result in [16] provides an
O(E2/T ) convergence rate  where E =PT
t=1 kEtk is the partial sum of the errors in the gradients.
It is shown that E = o(pT ) is a necessary condition to obtain convergence. However  for the CCA
problem that we are considering in this paper  our lemma A.6 shows that E = O(pT ). In fact  it is
easy to see that E =⇥( pT ). Our analysis yields O( 1pT
) convergence rates for both Algorithms 1
and 2. This perhaps warrants further investigation into the more general problem of inexact proximal
gradient method.
In empirical comparisons  we found the capped version of the proposed MSG algorithm to outperform
other methods including MEG in terms of overall runtime needed to reach an ✏-suboptimal solution.
Future work will focus on gaining a better theoretical understanding of capped MSG.

2We run ALS only for k = 1 as the algorithm and the current implementation from the authors does not

handle k  1.

8

(a) k = 1

(b) k = 2

(c) k = 4

0.35

0.3

0.25

0.2

0.15

0.1

0.05

e
v
i
t
c
e
b
O

j

0

102

0.35

0.3

0.25

0.2

0.15

0.1

0.05

0

e
v
i
t
c
e
b
O

j

0.5

0.4

0.3

0.2

0.1

e
v
i
t
c
e
b
O

j

0

102

e
v
i
t
c
e
b
O

j

0.5

0.4

0.3

0.2

0.1

0

103
Iteration

100

Runtime (in seconds)

102

e
v
i
t
c
e
b
O

j

e
v
i
t
c
e
b
O

j

0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

CAPPED-MSG
MEG
CCALin
batch
ALSCCA
Max Objective

103
Iteration

100

Runtime (in seconds)

102

102

103
Iteration

100

101

Runtime (in seconds)

102

Figure 1: Comparisons of CCA-Lin  CCA-ALS  MSG  and MEG for CCA optimization on the MediaMill
dataset  in terms of the objective value as a function of iteration (top) and as a function of CPU runtime (bottom).

Acknowledgements

This research was supported in part by NSF BIGDATA grant IIS-1546482.

References
[1] Z. Allen-Zhu and Y. Li. Doubly Accelerated Methods for Faster CCA and Generalized Eigen-
decomposition. In Proceedings of the 34th International Conference on Machine Learning 
ICML  2017. Full version available at http://arxiv.org/abs/1607.06017.

[2] R. Arora  A. Cotter  and N. Srebro. Stochastic optimization of PCA with capped MSG. In

Advances in Neural Information Processing Systems  NIPS  2013.

[3] R. Arora and K. Livescu. Multi-view CCA-based acoustic features for phonetic recognition
across speakers and domains. In Acoustics  Speech and Signal Processing (ICASSP)  2013
IEEE International Conference on  pages 7135–7139. IEEE  2013.

[4] R. Arora  P. Mianjy  and T. Marinov. Stochastic optimization for multiview representation
learning using partial least squares. In Proceedings of The 33rd International Conference on
Machine Learning  ICML  pages 1786–1794  2016.

[5] A. Benton  R. Arora  and M. Dredze. Learning multiview embeddings of twitter users. In
Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics 
volume 2  pages 14–19  2016.

[6] O. Bousquet and L. Bottou. The tradeoffs of large scale learning. In Advances in neural

information processing systems  pages 161–168  2008.

[7] C. Gao  D. Garber  N. Srebro  J. Wang  and W. Wang. Stochastic canonical correlation analysis.

arXiv preprint arXiv:1702.06533  2017.

[8] R. Ge  C. Jin  P. Netrapalli  A. Sidford  et al. Efﬁcient algorithms for large-scale generalized
eigenvector computation and canonical correlation analysis. In International Conference on
Machine Learning  pages 2741–2750  2016.

[9] S. Golden. Lower bounds for the helmholtz function. Physical Review  137(4B):B1127  1965.

9

[10] M. Herbster and M. K. Warmuth. Tracking the best linear predictor. Journal of Machine

Learning Research  1(Sep):281–309  2001.

[11] H. Hotelling. Relations between two sets of variates. Biometrika  28(3/4):321–377  1936.
[12] S. Kale. Efﬁcient algorithms using the multiplicative weights update method. Princeton

University  2007.

[13] E. Kidron  Y. Y. Schechner  and M. Elad. Pixels that sound. In Computer Vision and Pattern
Recognition  2005. CVPR 2005. IEEE Computer Society Conference on  volume 1  pages 88–95.
IEEE  2005.

[14] Y. Lu and D. P. Foster. Large scale canonical correlation analysis with iterative least squares. In

Advances in Neural Information Processing Systems  pages 91–99  2014.

[15] Z. Ma  Y. Lu  and D. Foster. Finding linear structure in large datasets with scalable canonical
correlation analysis. In Proceedings of The 32nd International Conference on Machine Learning 
pages 169–178  2015.

[16] M. Schmidt  N. L. Roux  and F. R. Bach. Convergence rates of inexact proximal-gradient
methods for convex optimization. In Advances in neural information processing systems  pages
1458–1466  2011.

[17] B. A. Schmitt. Perturbation bounds for matrix square roots and pythagorean sums. Linear

algebra and its applications  174:215–227  1992.

[18] S. Shalev-Shwartz and N. Srebro. Svm optimization: inverse dependence on training set size. In
Proceedings of the 25th international conference on Machine learning  pages 928–935. ACM 
2008.

[19] C. G. Snoek  M. Worring  J. C. Van Gemert  J.-M. Geusebroek  and A. W. Smeulders. The chal-
lenge problem for automated detection of 101 semantic concepts in multimedia. In Proceedings
of the 14th ACM international conference on Multimedia  pages 421–430. ACM  2006.

[20] J. A. Tropp. User-friendly tail bounds for sums of random matrices. Foundations of Computa-

tional Mathematics  12(4):389–434  2012.

[21] J. A. Tropp et al. An introduction to matrix concentration inequalities. Foundations and

Trends R in Machine Learning  8(1-2):1–230  2015.

[22] K. Tsuda  G. Rätsch  and M. K. Warmuth. Matrix exponentiated gradient updates for on-line
learning and bregman projection. In Journal of Machine Learning Research  pages 995–1018 
2005.

[23] A. Vinokourov  N. Cristianini  and J. Shawe-Taylor. Inferring a semantic representation of text
via cross-language correlation analysis. In Advances in neural information processing systems 
pages 1497–1504  2003.

[24] W. Wang  J. Wang  D. Garber  and N. Srebro. Efﬁcient globally convergent stochastic optimiza-
tion for canonical correlation analysis. In Advances in Neural Information Processing Systems 
pages 766–774  2016.

[25] M. K. Warmuth and D. Kuzmin. Online variance minimization. In Learning theory  pages

514–528. Springer  2006.

[26] M. K. Warmuth and D. Kuzmin. Randomized PCA algorithms with regret bounds that are

logarithmic in the dimension. In NIPS’06  2006.

[27] M. K. Warmuth and D. Kuzmin. Randomized online PCA algorithms with regret bounds that

are logarithmic in the dimension. Journal of Machine Learning Research  9(10)  2008.

10

,Raman Arora
Teodor Vanislavov Marinov
Poorya Mianjy
Nati Srebro