2019,Cascade RPN: Delving into High-Quality Region Proposal Network with Adaptive Convolution,This paper considers an architecture referred to as Cascade Region Proposal Network (Cascade RPN) for improving the region-proposal quality and detection performance by systematically addressing the limitation of the conventional RPN that heuristically defines the anchors and aligns the features to the anchors. First  instead of using multiple anchors with predefined scales and aspect ratios  Cascade RPN relies on a single anchor per location and performs multi-stage refinement. Each stage is progressively more stringent in defining positive samples by starting out with an anchor-free metric followed by anchor-based metrics in the ensuing stages. Second  to attain alignment between the features and the anchors throughout the stages  adaptive convolution is proposed that takes the anchors in addition to the image features as its input and learns the sampled features guided by the anchors. A simple implementation of a two-stage Cascade RPN achieves 13.4 point AR higher than that of the conventional RPN  surpassing any existing region proposal methods. When adopting to Fast R-CNN and Faster R-CNN  Cascade RPN can improve the detection mAP by 3.1 and 3.5 points  respectively.  The code will be made publicly available at https://github.com/thangvubk/Cascade-RPN.,Cascade RPN: Delving into High-Quality Region

Proposal Network with Adaptive Convolution

Thang Vu  Hyunjun Jang  Trung X. Pham  Chang D. Yoo

Department of Electrical Engineering

Korea Advanced Institute of Science and Technology

{thangvubk wiseholi trungpx cd_yoo}@kaist.ac.kr

Abstract

This paper considers an architecture referred to as Cascade Region Proposal Net-
work (Cascade RPN) for improving the region-proposal quality and detection
performance by systematically addressing the limitation of the conventional RPN
that heuristically deÔ¨Ånes the anchors and aligns the features to the anchors. First 
instead of using multiple anchors with predeÔ¨Åned scales and aspect ratios  Cascade
RPN relies on a single anchor per location and performs multi-stage reÔ¨Ånement.
Each stage is progressively more stringent in deÔ¨Åning positive samples by starting
out with an anchor-free metric followed by anchor-based metrics in the ensuing
stages. Second  to attain alignment between the features and the anchors throughout
the stages  adaptive convolution is proposed that takes the anchors in addition to the
image features as its input and learns the sampled features guided by the anchors.
A simple implementation of a two-stage Cascade RPN achieves AR 13.4 points
higher than that of the conventional RPN  surpassing any existing region proposal
methods. When adopting to Fast R-CNN and Faster R-CNN  Cascade RPN can
improve the detection mAP by 3.1 and 3.5 points  respectively. The code is made
publicly available at https://github.com/thangvubk/Cascade-RPN.

1

Introduction

Object detection has received considerable attention in recent years for its applications in autonomous
driving [13  17]  robotics [3  11] and surveillance [9  23]. Given an image  object detectors aim to
detect known object instances  each of which is assigned to a bounding box and a class label. Recent
high-performing object detectors  such as Faster R-CNN [34]  formulate the detection problem as
a two-stage pipeline. At the Ô¨Årst stage  a region proposal network (RPN) produces a sparse set of
proposal boxes by reÔ¨Åning and pruning a set of anchors  and at the second stage  a region-wise
CNN detector (R-CNN) reÔ¨Ånes and classiÔ¨Åes the proposals produced by RPN. Compared to R-CNN 
RPN has received relatively less attention for improving its performance. This paper will focus on
improving RPN by addressing its limitations that arise from heuristically deÔ¨Åning the anchors and
heuristically aligning the features to the anchors.
An anchor is deÔ¨Åned by its scale and aspect ratio  and a set of anchors with different scales and aspect
ratios are required to obtain a sufÔ¨Åcient number of positive samples that have high overlap with the
target objects. Setting appropriate scales and aspect ratios is important in achieving high detection
performance  and it requires a fair amount of tuning [25  34].
An alignment rule is ‚Äúimplicitly‚Äù deÔ¨Åned to set up a correspondence between the image features
and the reference boxes. The input features of RPN and R-CNN should be well-aligned with the
bounding boxes that are to be regressed. The alignment is guaranteed in R-CNN by the RoIPool [34]
or RoIAlign [18] layer . The alignment in RPN is heuristically guaranteed: the anchor boxes are
uniformly initialized  leveraging the observation that the convolutional kernel of the RPN uniformly

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

(a)

(b)

(c)

Figure 1: Iterative RPN shows limitations in improving RPN performance. (a) The target regression
distribution to be learned at stage 1 and 2. The stage 2 distribution represents the error after the stage
1 distribution is learned. (b) Iterative RPN fails in learning stage-2 distribution as the average recall
(AR) improvement is marginal compared to the of RPN. (c) In Iterative RPN  the anchor at stage 2 
which is regressed in stage 1  breaks the alignment rule in detection.

strides over the feature maps. Such a heuristic introduces limitations for further improving detection
performance as described below.
A number of studies have attempted to improve RPN by iterative reÔ¨Ånement [14  41]. Henceforth 
this paper will refer to it as Iterative RPN. The motivation behind this idea is illustrated in Figure 1a.
Anchor boxes which are references for regression are uniformly initialized  and the target ground
truth boxes are arbitrarily located. Thus  RPN needs to learn a regression distribution of high variance 
as shown in Figure 1a. If this regression distribution is perfectly learned  the regression distribution
at stage 2 should be close to a Dirac Delta distribution. However  such a high-variance distribution at
stage 1 is difÔ¨Åcult to learn  requiring stage 2 regression. Stage 2 distribution has a lower variance
compared to that of stage 1  and thus should be easier to learn but fails with Iterative RPN. The
failure is implied by the observation in which the performance improvement of Iterative RPN is
negligible compared to that of RPN  as shown in Figure 1b. It is explained intuitively in Figure 1c.
Here  after stage 1  the anchor is regressed to be closer to the ground truth box; however  this breaks
the alignment rule in detection.
This paper proposes an architecture referred to as Cascade RPN to systematically address the
aforementioned problem arising from heuristically deÔ¨Åning the anchors and aligning the features to
the anchors. First  instead of using multiple anchors with different scales and aspect ratios  Cascade
RPN relies on a single anchor and incorporates both anchor-based and anchor-free criteria in deÔ¨Åning
positive boxes to achieve high performance. Second  to beneÔ¨Åt from multi-stage reÔ¨Ånement while
maintaining the alignment between anchor boxes and features  Cascade RPN relies on the proposed
adaptive convolution that adapts to the reÔ¨Åned anchors after each stage. Adaptive convolution serves
as an extremely light-weight RoIAlign layer [18] to learn the features sampled within the anchors.
Cascade RPN is conceptually simple and easy to implement. Without bells and whistles  a simple
two-stage Cascade RPN achieves AR 13.4 points improvement compared to RPN baseline on the
COCO dataset [26]  surpassing any existing region proposal methods by a large margin. Cascade
RPN can also be integrated into two-stage detectors to improve detection performance. In particular 
integrating Cascade RPN into Fast R-CNN and Faster R-CNN achieves 3.1 and 3.5 points mAP
improvement  respectively.

2 Related Work

Object Detection. Object detection can be roughly categorized into two main streams: one-stage
and two-stage detection. Here  one-stage detectors are proposed to enhance computational efÔ¨Åciency.
Examples falling in this stream are SSD [27]  YOLO [31  32  33]  RetinaNet [25]  and CornerNet
[21]. Meanwhile  two-stage detectors aim to produce accurate bounding boxes  where the Ô¨Årst stage

2

1000≈¶≈¶≈¶9-f9-f¬ænf9-Ground TruthAnchor s2Anchor s1generates region proposals followed by region-wise reÔ¨Ånement and classiÔ¨Åcation at the second stage 
e.g.  R-CNN [15]  Fast R-CNN [16]  Faster R-CNN [34]  Cascade R-CNN [4]  and HTC [7].

Region Proposals. Region proposals have become the de-facto paradigm for high-quality object
detectors [6  19  20]. Region proposals serve as the attention mechanism that enables the detector
to produce accurate bounding boxes while maintaining computation tractability. Early methods
are based on grouping super-pixel (e.g.  Selective Search [36]  CPMC [5]  MCG [2]) and window
scoring (e.g.  objectness in windows [1]  EdgeBoxes [43]). Although these methods dominate the
Ô¨Åeld of object detection in classical computer vision  they exhibit limitations as they are external
modules independent of the detector and not computationally friendly. To overcome these limitations 
Shaoqing et al. [34] propose Region Proposal Network (RPN) that shares full-image convolutional
features with the detection network  enabling nearly cost-free region proposals.

Multi-Stage RPN. There have been a number of studies attempting to improve the performance of
RPN [14  37  38  41]. The general trend is to perform multi-stage reÔ¨Ånement that takes the output of
a stage as the input of the next stage and repeats until accurate localization is obtained  as presented
in [14]. However  this approach ignores the problem that the regressed boxes are misaligned to the
image features  breaking the alignment rule required for object detection. To alleviate this problem 
recent advanced methods [12  37] rely on deformable convolution [10] to perform feature spatial
transformations and expect the learned transformations to align to the changes of anchor geometry.
However  as there is no explicit supervision to learn the feature transformation  it is difÔ¨Åcult to
determine whether the improvement originates from conforming to the alignment rule or from the
beneÔ¨Åts of deformable convolution  thus making it less interpretable.

Anchor-based vs. Anchor-free Criterion for Sample Discrimination. As a bounding box usu-
ally includes an object with some amount of background  it is difÔ¨Åcult to determine if the box is a
positive or a negative sample. This problem is usually addressed by comparing the Intersection over
Union (IoU) between an anchor and a ground truth box to a predeÔ¨Åned threshold; thus  it is referred
to as the anchor-based criterion. However  as the anchor is uniformly initialized  multiple anchors
with different scales and aspect ratios are required at each location to ensure that there are enough
positive samples [34]. The hyperparameters  such as scales and aspect ratios  are usually heuristically
tuned and have a large impact on the Ô¨Ånal accuracy [25  34]. Rather than relying on anchors  there
have been studies that deÔ¨Åne positive samples by the distance between the prediction points and the
center region of objects  referred to as anchor-free [35  40  42]. This method is simple and requires
fewer hyperparameters but usually exhibits limitations in dealing with complex scenes.

3 Region Proposal Network and Variants

3.1 Region Proposal Network
2 )s ‚â§ W  0 <
Given an image I of size W √ó H  a set of anchor boxes A = {aij |0 < (i + 1
2 )s ‚â§ H} is uniformly initialized over the image  with stride s. Unless otherwise speciÔ¨Åed  i
(j + 1
and j are omitted to simplify the notation. Each anchor box a is represented by a 4-tuple in the form
of a = (ax  ay  aw  ah)  where (ax  ay) is the center location of the anchor with the dimension of
(aw  ah). The regression branch aims to predict the transformation Œ¥ from the anchor a to the target
ground truth box t represented as follows:

Œ¥x = (tx ‚àí ax) /aw 
Œ¥w = log (tw/aw)  

Œ¥y = (ty ‚àí ay) /ah 
Œ¥h = log (th/ah) .

(1)

(cid:88)

L(ÀÜŒ¥  Œ¥) =

(cid:16)ÀÜŒ¥k ‚àí Œ¥k

(cid:17)

 

Here  the regressor f takes as input the image feature x to output a prediction ÀÜŒ¥ = f (x) that
minimizes the bounding box loss:

smoothL1

(2)
where smoothL1(¬∑) is the robust L1 loss deÔ¨Åned in [16]. The regressed anchor is simply inferred
based on the inverse transformation of (1) as follows:
a(cid:48)
y = ÀÜŒ¥yah + ay 
a(cid:48)
h = ah exp(ÀÜŒ¥h).

a(cid:48)
x = ÀÜŒ¥xaw + ax 
a(cid:48)
w = aw exp(ÀÜŒ¥w) 

k‚àà{x y w h}

(3)

3

(a) RPN

(b) Iterative RPN

(c) Iterative RPN+

(d) GA-RPN

(e) Cascade RPN

Figure 2: The architectures of different networks. ‚ÄúI‚Äù  ‚ÄúH‚Äù  ‚ÄúC‚Äù  and ‚ÄúA‚Äù denote input image  network
head  classiÔ¨Åer  and anchor regressor  respectively. ‚ÄúConv‚Äù  ‚ÄúDefConv‚Äù  ‚ÄúDilConv‚Äù and ‚ÄúAdaConv‚Äù
indicate conventional convolution  deformable convolution [10]  dilated convolution [39] and the
proposed adaptive convolution layers  respectively.

Then the set of regressed anchor A(cid:48) = {a(cid:48)} is Ô¨Åltered by non-maximum suppression (NMS) to
produce a sparse set of proposal boxes P:

P = NMS(A(cid:48)  S) 

(4)

where S is the set of objectness scores learned by the classiÔ¨Åcation branch.

3.2

Iterative RPN and Variants

Some previous studies [14  41] have proposed iterative reÔ¨Ånement which is referred to as Iterative
RPN  as shown in Figure 2b. Iterative RPN iteratively reÔ¨Ånes the anchors by treating A(cid:48) as the new
initial anchor set for the next stage and repeats Eqs. (1) to (3) until obtaining accurate localization.
However  this approach exhibits mismatch between anchors and their represented features as the
anchor positions and shapes change after each iteration.
To alleviate this problem  recent advanced methods [12  37] use deformable convolution [10] to
perform spatial transformations on the features as shown in Figure 2c and 2d and expect transformed
features to align to the change in anchor geometry. However  this idea ignores the problem that there
is no constraint to enforce the features to align with the changes in anchors: it is difÔ¨Åcult to determine
whether the deformable convolution produces feature transformation leading to alignment. Instead 
the proposed Cascade RPN systematically ensures the alignment rule by using the proposed adaptive
convolution.

4 Cascade RPN

4.1 Adaptive Convolution

Given a feature map x  in the standard 2D convolution  the feature map is Ô¨Årst sampled using a
regular grid R = {(rx  ry)}  and the samples are summed up with the weight w. Here  the grid R
is deÔ¨Åned by the kernel size and dilation. For example  R = {(‚àí1 ‚àí1)  (‚àí1  0)  . . .   (0  1)  (1  1)}
corresponds to kernel size 3√ó 3 and dilation 1. For each location p on the output feature y  we have:
(5)

w[r] ¬∑ x[p + r].

(cid:88)

y[p] =

In adaptive convolution  the regular grid R is replaced by the offset Ô¨Åeld O that is directly inferred
from the input anchor.

y[p] =

w[o] ¬∑ x[p + o].

(6)

r‚ààR

(cid:88)

o‚ààO

4

IAConvBackboneHConvCConvIA1ConvBackboneH1ConvC1ConvA2ConvH2ConvC2ConvIA1ConvBackboneH1ConvC1ConvA2ConvH2DefConvC2ConvOffsetConvIShapeConvBackboneH1ConvLocConvAConvH2DefConvCConvOffsetConvIA1ConvBackboneH1DilConvA2ConvC2ConvBridged featureH2AdaConvPredefined anchorRegressed anchorConvolution

Dilated Convolution

Deformable convolution

Adaptive convolution

Figure 3: Illustrations of the sampling locations in different convolutional layers with 3 √ó 3 kernel.

Let ¬Øa denote the projection of anchor a onto the feature map. The offset o can be decoupled into
center offset and shape offset (shown in Figure 2e):

(7)
where octr = (¬Øax ‚àí px  ¬Øay ‚àí py) and oshp is deÔ¨Åned by the anchor shape and kernel size. For example 

if kernel size is 3 √ó 3  then oshp ‚àà(cid:8)(‚àí ¬Øaw

2 )(cid:9). As the offsets

2  ‚àí ¬Øah

2 )  (‚àí ¬Øaw

are typically fractional  sampling is performed with bilinear interpolation analogous to [10].

o = octr + oshp 

2   0)  . . .   (0  ¬Øah

2 )  ( ¬Øaw

2   ¬Øah

Relation to other Convolutions.
The illustrations of sampling locations in adaptive and other
related convolutions are shown in Figure 3. Conventional convolution samples the features at
contiguous locations with a dilation factor of 1. The dilated convolution [39] increases the dilation
factor  aiming to enhance the semantic scope with unchanged computational cost. The deformable
convolution [10] augments the spatial sampling locations by learning the offsets. Meanwhile  the
proposed adaptive convolution performs sampling within the anchors to ensure alignment between
the anchors and features. Adaptive convolution is closely related to the others. Adaptive convolution
becomes dilated convolution if the center offsets are zeros. Deformable convolution becomes adaptive
convolution if the offsets are deterministically derived from the anchors.

4.2 Sample Discrimination Metrics

Instead of using multiple anchors with predeÔ¨Åned scales and aspect ratios  Cascade RPN relies on a
single anchor per location and performs multi-stage reÔ¨Ånement. However  this reliance creates a new
challenge in determining whether a training sample is positive or negative as the use of anchor-free or
anchor-based metric is highly adversarial. The anchor-free metric establishes a loose requirement for
positive samples in the second stage and the anchor-based metric results in an insufÔ¨Åcient number of
positive training examples at the Ô¨Årst stage. To overcome this challenge  Cascade RPN progressively
strengthens the requirements through the stages by starting out with an anchor-free metric followed
by anchor-based metrics in the ensuing stages. In particular  at the Ô¨Årst stage  an anchor is a positive
sample if its center is inside the center region of an object. In the following stages  an anchor is a
positive sample if its IoU with an object is greater than the IoU threshold.

4.3 Cascade RPN

The architecture of a two-stage Cascade RPN is illustrated in Figure 2e. Here  Cascade RPN relies on
adaptive convolution to systematically align the features to the anchors. In the Ô¨Årst stage  the adaptive
convolution is set to perform dilated convolution since anchor center offsets are zeros. The features of
the Ô¨Årst stage are ‚Äúbridged‚Äù to the next stages since the spatial order of the features is maintained by
the dilated convolution. The pipeline of the proposed Cascade RPN can be described mathematically
in Algorithm 1. The anchor set at the Ô¨Årst stage A1 is uniformly initialized over the image. At stage
œÑ  the anchor offset oœÑ is computed and fed into the regressor f œÑ to produce the regression prediction
œÑ . The prediction ÀÜŒ¥
œÑ is used to produce regressed anchors aœÑ +1. At the Ô¨Ånal stage  the objectness
ÀÜŒ¥
scores are derived from the classiÔ¨Åer  followed by NMS to produce the region proposals.

5

Algorithm 1. Cascade RPN

1 Input: sequence of regressors f œÑ   classiÔ¨Åer g  feature x of image I.
2 Output: proposal set P.
3 Uniformly initialize anchor set A1 = {a1} over image I.
4 for œÑ ‚Üê 1 to T do
5

Compute offset oœÑ of input anchor aœÑ on feature map using (7).
Compute regression prediction ÀÜŒ¥
Compute regressed anchor aœÑ +1 from ÀÜŒ¥

7
8 end
9 Compute objectness score s = g(x  oT ).
10 Derive proposals P from AœÑ +1 = {aœÑ +1} and S = {s} using NMS (4).

œÑ

= f œÑ (x  oœÑ ).

œÑ using (3).

6

4.4 Learning

T(cid:88)

Cascade RPN can be trained in an end-to-end manner using multi-task loss as follows:

L = Œª

Œ±œÑLœÑ

reg + Lcls.

(8)

œÑ =1

Here  LœÑ
reg is the regression loss at stage œÑ with the weight of Œ±œÑ   and Lcls is the classiÔ¨Åcation loss.
The two loss terms are balanced by Œª. In the implementation  binary cross entropy loss and IoU loss
[40] are used as the classiÔ¨Åcation loss and regression loss  respectively.

5 Experiments

5.1 Experimental Setting

The experiments are performed on the COCO 2017 detection dataset [26]. All the models are trained
on the train split (115k images). The region proposal performance and ablation analysis are reported
on val split (5k images)  and the benchmarking detection performance is reported on test-dev split
(20k images).
Unless otherwise speciÔ¨Åed  the default model of the experiment is as follows. The model consists
of two stages  with ResNet50-FPN [24] being its backbone. The use of two stages is to balance
accuracy and computational efÔ¨Åciency. A single anchor per location is used with size of 322  642 
1282  2562  and 5122 corresponding to the feature levels C2  C3  C4  C5  and C6  respectively [24].
The Ô¨Årst stage uses the anchor-free metric for sample discrimination with the thresholds of the
center-region œÉctr and ignore-region œÉign  which are adopted from [40  37]  being 0.2 and 0.5. The
second stage uses the anchor-based metric with the IoU threshold of 0.7. The multi-task loss is set
with the stage-wise weight Œ±1 = Œ±2 = 1 and the balance term Œª = 10. The NMS threshold is set
to 0.8. In all experiments  the long edge and the short edge of the images are resized to 1333 and
800 respectively without changing the aspect ratio. No data augmentation is used except for standard
horizontal image Ô¨Çipping. The models are implemented with PyTorch [29] and mmdetection [8]. The
models are trained with 8 GPUs with a batch size of 16 (two images per GPU) for 12 epochs using
SGD optimizer. The learning rate is initialized to 0.02 and divided by 10 after 8 and 11 epochs. It
takes about 12 hours for the models to converge on 8 Tesla V100 GPUs.
The quality of region proposals is measured with Average Recall (AR)  which is the average of recalls
across IoU thresholds from 0.5 to 0.95 with a step of 0.05. The AR for 100  300  and 1000 proposals
per image are denoted as AR100  AR300  and AR1000. The AR for small  medium  and large objects
computed at 100 proposals are denoted as ARS  ARM   and ARL  respectively. Detection results are
evaluated with the standard COCO-style Average Precision (AP) measured at IoUs from 0.5 to 0.95.
The runtime is measured on a single Tesla V100 GPU.

6

Table 1: Region proposal results on COCO 2017 val.

Backbone
ResNet-50

VGG-16 (Sync BN)

VGG-16

BN-inception

ResNet-50-FPN

-
-

-
-

-
-
-
-

AR100 AR300 AR1000 ARS ARM ARL
36.4
31.6
53.3
53.9
44.6
48.5
54.0
59.1
61.1

48.2
60.7
66.2
67.0
58.3
58.8
63.0
68.5
71.7

62.2
63.0
51.7
56.9
62.7
68.2
69.3

77.7
78.5
61.4
65.4
73.9
78.4
82.8

31.5
31.9
29.5
32.1
35.6
40.7
42.1

52.9
55.4
60.4
65.1
67.6

-
-

Time (s)

0.76
0.10
4.00
1.13
0.04
0.05
0.06
0.06
0.06

Method

SharpMask [30]
GCN-NS [28]

AttractioNet [14]

ZIP [22]
RPN [34]

Iterative RPN
Iterative RPN+
GA-RPN [37]
Cascade RPN

Table 2: Detection results on COCO 2017 test-dev

Method

Proposal method

# proposals

Fast R-CNN

Faster R-CNN

RPN

Cascade RPN

RPN

Iterative RPN+

GA-RPN

Cascade RPN

RPN

Cascade RPN

RPN

Iterative RPN+

GA-RPN

Cascade RPN

1000

300

1000

300

AP
37.0
40.1
36.6
38.6
39.5
40.1
37.1
40.5
36.9
39.2
39.9
40.6

AP50 AP75 APS APM APL
59.5
47.0
50.9
59.5
47.0
58.6
50.0
58.8
50.7
59.3
59.4
51.6
59.3
46.5
51.5
59.3
46.5
58.9
58.2
50.4
59.4
50.9
52.6
58.9

39.4
42.4
39.1
41.5
42.0
42.4
39.8
42.9
39.6
42.0
42.6
42.8

21.1
22.8
20.3
21.1
21.8
22.1
21.4
22.6
21.1
21.5
22.0
22.0

39.9
43.7
39.5
42.2
43.2
43.8
40.1
44.2
39.9
43.0
43.6
44.5

5.2 Benchmarking Results

Region Proposal Performance. The performance of Cascade RPN is compared to those of recent
state-of-the-art region proposal methods  including RPN [34]  SharpMask [30]  GCN-NS [28] 
AttractioNet [14]  ZIP [22]  and GA-RPN [37]. In addition  Iterative RPN and Iterative RPN+ 
which are referred to in Figure 2  are also benchmarked. The results of Sharp Mask  GCN-NS 
AttractioNet  ZIP are cited from the papers. The results of the remaining methods are reproduced
using mmdetection [8]. Table 1 summarizes the benchmarking results.
In particular  Cascade
RPN achieves AR 13.4 points higher than that of the conventional RPN. Cascade RPN consistently
outperforms the other methods in terms of AR under different settings of proposal thresholds
and object scales. The alignment rule is typically missing or loosely conformed to in the other
methods; thus  their performance improvements are limited. The alignment rule in Cascade RPN is
systematically ensured such that the performance gain is greater and more reliable.

Detection Performance. To investigate the beneÔ¨Åt of high-quality proposals  Cascade RPN and
the baselines are integrated into common two-stage object detectors  including Fast R-CNN and
Faster R-CNN. Here  Fast R-CNN is trained on precomputed region proposals while Faster R-CNN
is trained in an end-to-end manner. As studied in [37]  despite high-quality region proposals  training
a good detector is still a non-trivial problem  and simply replacing RPN by Cascade RPN without
changes in the settings only brings limited gain. Following [37]  the IoU threshold in R-CNN is
increased and the number of proposals is decreased. In particular  the IoU threshold and the number
of proposals are set to 0.65 and 300  respectively. The experimental results are reported in Table 2.
Here  integrating RPN into Fast R-CNN and Faster R-CNN yields 37.0 and 37.1 mAP  respectively.
From the results  the recall improvement is correlated with improvements in detection performance.
As it has the highest recall  Cascade RPN boosts the performance for Fast R-CNN and Faster R-CNN
to 40.1 and 40.6 mAP  respectively.

7

1

e
g
a
t
S

2

e
g
a
t
S

Figure 4: Examples of region proposal results at stage 1 (Ô¨Årst row) and stage 2 (second row) of
Cascade RPN.

Table 3: Ablation analysis of Cascade RPN. Here  Align.  AFAB  and Stats. denote the use of
alignments  anchor-free and anchor-based metrics  and regression statistics  respectively.

Baseline

(cid:88)

1 anchor

Cascade Align. AFAB Stats.

(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)

(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)

(cid:88)
(cid:88)
(cid:88)
(cid:88)
Overall Improvement

(cid:88)
(cid:88)
(cid:88)

(cid:88)
(cid:88)

IoU loss AR100 AR300 AR1000
58.3
55.8
58.0
67.8
68.6
71.5
71.7
+13.4

44.6
44.7
48.2
57.4
57.3
60.8
61.1
+16.5

52.9
51.2
54.4
63.7
64.2
67.3
67.6
+14.7

(cid:88)

Table 4: The effects of alignment

Table 5: The effects of sample metrics

Center

(cid:88)
(cid:88)

Shape AR100 AR300 AR1000
58.0
64.1
67.8

48.2
52.5
57.4

54.4
59.4
63.7

(cid:88)

AF AB AR100 AR300 AR1000
(cid:88)
66.4
67.8
68.6

61.8
63.7
64.2

55.2
57.4
57.3

(cid:88)
(cid:88)

(cid:88)

5.3 Ablation Study

Component-wise Analysis.
To demonstrate the effectiveness of Cascade RPN  a comprehensive
component-wise analysis is performed in which different components are omitted. The results are
reported in Table 3. Here  the baseline is RPN with 3 anchors per location yielding AR1000 of 58.3.
When the number of anchors per location is reduced to 1  the AR1000 drops to 55.8  implying that
the number of positive samples dramatically decreases. Even when the multi-stage cascade is added 
the performance is 58.0  which is still lower than that of the baseline. However  when adaptive
convolution is applied to ensure alignment  the performance surges to 67.8  showing the importance
of alignment in multi-stage reÔ¨Ånement. The incorporation of anchor-free and anchor-based metrics
for sample discrimination incrementally improves AR1000 to 68.6. The use of regression statistics
(shown in Figure 1a) increases the performance to 71.5. Finally  applying IoU loss yields a slight
improvement of 0.2 points. Overall  Cascade RPN achieves 16.5  14.7  and 13.4 points improvement
in terms of AR100  AR300  and AR1000 respectively  compared to the conventional RPN.

Acquisition of Alignment.
To demonstrate the effectiveness of the proposed adaptive convolution 
the center and shape alignments  represented by the offsets in Eq. (7)  are progressively applied. Here 
the center and shape offsets maintain the alignments in position and semantic scope  respectively.
Table 4 shows that the AR1000 improves from 58.0 to 64.1 using only the center alignment. When
both the center and shape alignments are ensured  the performance increases to 67.8.

8

Figure 5: More examples of region proposal results of Cascade RPN.

Table 6: Ablation study on # stages.

Table 7: Detection results of Cascade R-CNN with
RPN and Cascade RPN (denoted by CRPN).

# stages

1
2
3

AR100
56.0
61.1
60.9

AR300
62.2
67.6
67.9

AR1000

Time (s)

66.3
71.7
72.2

0.04
0.06
0.08

Method

RPN
CRPN

AP

40.8
41.6

AP50
59.3
59.0

AP75
44.3
45.5

AP75
22.0
23.0

APS
44.2
45.0

APM
54.2
55.2

Sample Discrimination Metrics.
The experimental results with different combinations of sample
discrimination metrics are shown in Table 5. Here  AF and AB denote that the anchor-free and
anchor-based metrics are applied for all stages  respectively. Meanwhile  AFAB indicates that the
anchor-free metric is applied at stage 1 followed by anchor-based metric at stage 2. Here  AF and
AB yield the AR1000 of 66.4 and 67.8 respectively  both of which are signiÔ¨Åcantly less than that of
AFAB. It is noted that the thresholds for each metric are already adapted through stages. The results
imply that applying only one of either anchor-free or anchor-based metric is highly adversarial. The
both metrics should be incorporated to achieve the best results.

Qualitative Evaluation. The examples of region proposal results at the Ô¨Årst and second stages are
illustrated in the Ô¨Årst and second row of Figure 4  respectively. The results show that the output
proposals at the second stage are more accurate and cover a larger number of objects.

Number of Stages. Table 6 shows the proposal performance on different number of stages. In the
3-stage Cascade RPN  an IoU threshold of 0.75 is used for the third stage. The 2-stage Cascade RPN
achieves the best trade-off between AR1000 and inference time.

Extension with Cascade R-CNN. Table 7 reports the detection results of the Cascade R-CNN [4]
with different proposal methods. The Cascade RPN improves AP by 0.8 points compared to RPN.
The improvement is mainly from AP75  where the objects have high IoU with the ground truth.

6 Conclusion

This paper introduces Cascade RPN  a simple yet effective network architecture for improving
region proposal quality and object detection performance. Cascade RPN systematically addresses
the limitations that conventional RPN heuristically deÔ¨Ånes the anchors and aligns the features to the
anchors. A simple implementation of a two-stage Cascade RPN achieves AR 13.4 points higher than
the baseline  surpassing any existing region proposal methods. When adopting to Fast R-CNN and
Faster R-CNN  Cascade RPN can improve the detection mAP by 3.1 and 3.5 points  respectively.

9

Acknowledgment. This work was supported by Institute for Information & communications Tech-
nology Planning & Evaluation(IITP) grant funded by the Korea government (MSIT) (2017-0-01780 
The technology development for event recognition/relational reasoning and learning knowledge-based
system for video understanding) and (No. 2019-0-01396  Development of framework for analyzing 
detecting  mitigating of bias in AI model and training data)

References
[1] Bogdan Alexe  Thomas Deselaers  and Vittorio Ferrari. Measuring the objectness of image windows.

TPAMI  2012. 3

[2] Pablo Arbel√°ez  Jordi Pont-Tuset  Jonathan T Barron  Ferran Marques  and Jitendra Malik. Multiscale

combinatorial grouping. In CVPR  2014. 3

[3] Carlos Astua  Ramon Barber  Jonathan Crespo  and Alberto Jardon. Object detection techniques applied

on mobile robot semantic navigation. Sensors  2014. 1

[4] Zhaowei Cai and Nuno Vasconcelos. Cascade r-cnn: Delving into high quality object detection. In CVPR 

2018. 3  9

[5] Joao Carreira and Cristian Sminchisescu. Cpmc: Automatic object segmentation using constrained

parametric min-cuts. TPAMI  2011. 3

[6] Neelima Chavali  Harsh Agrawal  Aroma Mahendru  and Dhruv Batra. Object-proposal evaluation protocol

is ‚Äôgameable‚Äô. In CVPR  2016. 3

[7] Kai Chen  Jiangmiao Pang  Jiaqi Wang  Yu Xiong  Xiaoxiao Li  Shuyang Sun  Wansen Feng  Ziwei Liu 

Jianping Shi  Wanli Ouyang  et al. Hybrid task cascade for instance segmentation. In CVPR  2019. 3

[8] Kai Chen  Jiaqi Wang  Jiangmiao Pang  Yuhang Cao  Yu Xiong  Xiaoxiao Li  Shuyang Sun  Wansen Feng 
Ziwei Liu  Jiarui Xu  Zheng Zhang  Dazhi Cheng  Chenchen Zhu  Tianheng Cheng  Qijie Zhao  Buyu Li 
Xin Lu  Rui Zhu  Yue Wu  Jifeng Dai  Jingdong Wang  Jianping Shi  Wanli Ouyang  Chen Change Loy 
and Dahua Lin. MMDetection: Open mmlab detection toolbox and benchmark. arXiv:1906.07155  2019.
6  7

[9] Donatello Conte  Pasquale Foggia  Michele Petretta  Francesco Tufano  and Mario Vento. Meeting
the application requirements of intelligent video surveillance systems in moving object detection. In
International Conference on Pattern Recognition and Image Analysis  2005. 1

[10] Jifeng Dai  Haozhi Qi  Yuwen Xiong  Yi Li  Guodong Zhang  Han Hu  and Yichen Wei. Deformable

convolutional networks. In ICCV  2017. 3  4  5

[11] Michael Danielczuk  Matthew Matl  Saurabh Gupta  Andrew Li  Andrew Lee  Jeffrey Mahler  and Ken
Goldberg. Segmenting unknown 3d objects from real depth images using mask r-cnn trained on synthetic
point clouds. arXiv:1809.05825  2018. 1

[12] Heng Fan and Haibin Ling. Siamese cascaded region proposal networks for real-time visual tracking. In

CVPR  2019. 3  4

[13] Paul Furgale  Ulrich Schwesinger  Martin RuÔ¨Çi  Wojciech Derendarz  Hugo Grimmett  Peter M√ºhlfellner 
Stefan Wonneberger  Julian Timpner  Stephan Rottmann  Bo Li  et al. Toward automated driving in
cities using close-to-market sensors: An overview of the v-charge project. In IEEE Intelligent Vehicles
Symposium (IV)  2013. 1

[14] Spyros Gidaris and Nikos Komodakis. Attend reÔ¨Åne repeat: Active box proposal generation via in-out

localization. arXiv:1606.04446  2016. 2  3  4  7

[15] Ross Girshick  Jeff Donahue  Trevor Darrell  and Jitendra Malik. Rich feature hierarchies for accurate

object detection and semantic segmentation. In CVPR  2014. 3

[16] Ross B. Girshick. Fast R-CNN. In ICCV  2015. 3

[17] Christian H√§ne  Torsten Sattler  and Marc Pollefeys. Obstacle detection for self-driving cars using only

monocular cameras and wheel odometry. In IROS  2015. 1

[18] Kaiming He  Georgia Gkioxari  Piotr Dollar  and Ross Girshick. Mask r-cnn. In ICCV  2017. 1  2

10

[19] J. Hosang  R. Benenson  P. Doll√°r  and B. Schiele. What makes for effective detection proposals? TPAMI 

2016. 3

[20] Jan Hosang  Rodrigo Benenson  and Bernt Schiele. How good are detection proposals  really?

arXiv:1406.6962  2014. 3

[21] Hei Law and Jia Deng. Cornernet: Detecting objects as paired keypoints. In ECCV  2018. 2

[22] Hongyang Li  Yu Liu  Wanli Ouyang  and Xiaogang Wang. Zoom out-and-in network with map attention

decision for region proposal and object detection. IJCV  2019. 7

[23] Wentong Liao  Chun Yang  Michael Ying Yang  and Bodo Rosenhahn. Security event recognition for visual
surveillance. ISPRS Annals of the Photogrammetry  Remote Sensing and Spatial Information Sciences 
2017. 1

[24] Tsung-Yi Lin  Piotr Dollar  Ross Girshick  Kaiming He  Bharath Hariharan  and Serge Belongie. Feature

pyramid networks for object detection. In CVPR  2017. 6

[25] Tsung-Yi Lin  Priya Goyal  Ross Girshick  Kaiming He  and Piotr Dollar. Focal loss for dense object

detection. In ICCV  2017. 1  2  3

[26] Tsung-Yi Lin  Michael Maire  Serge Belongie  James Hays  Pietro Perona  Deva Ramanan  Piotr Doll√°r 

and C Lawrence Zitnick. Microsoft COCO: Common objects in context. In ECCV  2014. 2  6

[27] Wei Liu  Dragomir Anguelov  Dumitru Erhan  Christian Szegedy  Scott E. Reed  Cheng-Yang Fu  and

Alexander C. Berg. Ssd: Single shot multibox detector. In ECCV  2016. 2

[28] Hsueh-Fu Lu  Xiaofei Du  and Ping-Lin Chang. Toward scale-invariance and position-sensitive region

proposal networks. In ECCV  2018. 7

[29] Adam Paszke  Sam Gross  Soumith Chintala  Gregory Chanan  Edward Yang  Zachary DeVito  Zeming
Lin  Alban Desmaison  Luca Antiga  and Adam Lerer. Automatic differentiation in pytorch. In NIPS-W 
2017. 6

[30] Pedro O Pinheiro  Tsung-Yi Lin  Ronan Collobert  and Piotr Doll√°r. Learning to reÔ¨Åne object segments. In

ECCV  2016. 7

[31] Joseph Redmon  Santosh Divvala  Ross Girshick  and Ali Farhadi. You only look once: UniÔ¨Åed  real-time

object detection. In CVPR  2016. 2

[32] Joseph Redmon and Ali Farhadi. Yolo9000: Better  faster  stronger. In CVPR  2017. 2

[33] Joseph Redmon and Ali Farhadi. Yolov3: An incremental improvement. arXiv:1804.02767  2018. 2

[34] Shaoqing Ren  Kaiming He  Ross Girshick  and Jian Sun. Faster r-cnn: Towards real-time object detection

with region proposal networks. In NeurIPS  2015. 1  3  7

[35] Zhi Tian  Chunhua Shen  Hao Chen  and Tong He. FCOS: fully convolutional one-stage object detection.

In ICCV  2019. 3

[36] Jasper RR Uijlings  Koen EA Van De Sande  Theo Gevers  and Arnold WM Smeulders. Selective search

for object recognition. IJCV  2013. 3

[37] Jiaqi Wang  Kai Chen  Shuo Yang  Chen Change Loy  and Dahua Lin. Region proposal by guided

anchoring. In CVPR  2019. 3  4  6  7

[38] Bin Yang  Junjie Yan  Zhen Lei  and Stan Z Li. Craft objects from images. In CVPR  2016. 3

[39] Fisher Yu and Vladlen Koltun. Multi-scale context aggregation by dilated convolutions. In ICLR  2016. 4 

5

[40] Jiahui Yu  Yuning Jiang  Zhangyang Wang  Zhimin Cao  and Thomas Huang. Unitbox: An advanced

object detection network. In 24th ACM international conference on Multimedia  2016. 3  6

[41] Qiaoyong Zhong  Chao Li  Yingying Zhang  Di Xie  Shicai Yang  and Shiliang Pu. Cascade region

proposal and global context for deep object detection. arXiv:1710.10749  2017. 2  3  4

[42] Chenchen Zhu  Yihui He  and Marios Savvides. Feature selective anchor-free module for single-shot object

detection. In CVPR  2019. 3

[43] C Lawrence Zitnick and Piotr Doll√°r. Edge boxes: Locating object proposals from edges. In ECCV  2014.

3

11

,Daniele Durante
Bruno Scarpa
David Dunson
Atsushi Nitanda
Jiaji Huang
Qiang Qiu
Robert Calderbank
Robert Gower
Filip Hanzely
Peter Richtarik
Sebastian Stich
Thang Vu
Hyunjun Jang
Trung Pham
Chang Yoo