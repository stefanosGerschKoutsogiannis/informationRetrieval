2012,Recognizing Activities by Attribute Dynamics,In this work  we consider the problem of modeling the dynamic structure of human activities in  the attributes space. A video sequence is first represented in a semantic feature space  where each feature encodes the probability of  occurrence of an activity attribute at a given time. A generative model   denoted the binary dynamic system (BDS)  is proposed to learn both the distribution and dynamics of different activities in this  space. The BDS is a non-linear dynamic system  which extends both the binary  principal component analysis (PCA) and classical linear dynamic systems (LDS)  by combining binary observation variables with a hidden Gauss-Markov state  process. In this way  it integrates the representation power of semantic  modeling with the ability of dynamic systems to capture the temporal structure of time-varying processes. An algorithm for learning BDS  parameters  inspired by a popular LDS  learning method from dynamic textures  is proposed. A similarity measure between BDSs  which generalizes  the Binet-Cauchy kernel for LDS  is then introduced and used to design  activity classifiers. The proposed method is shown to outperform similar classifiers  derived from the kernel dynamic system (KDS) and state-of-the-art approaches for  dynamics-based or attribute-based action recognition.,Recognizing Activities by Attribute Dynamics

Weixin Li

Nuno Vasconcelos

Department of Electrical and Computer Engineering

University of California  San Diego
La Jolla  CA 92093  United States

{wel017  nvasconcelos}@ucsd.edu

Abstract

In this work  we consider the problem of modeling the dynamic structure of hu-
man activities in the attributes space. A video sequence is ï¬rst represented in a
semantic feature space  where each feature encodes the probability of occurrence
of an activity attribute at a given time. A generative model  denoted the binary
dynamic system (BDS)  is proposed to learn both the distribution and dynamics
of different activities in this space. The BDS is a non-linear dynamic system 
which extends both the binary principal component analysis (PCA) and classical
linear dynamic systems (LDS)  by combining binary observation variables with
a hidden Gauss-Markov state process. In this way  it integrates the representa-
tion power of semantic modeling with the ability of dynamic systems to capture
the temporal structure of time-varying processes. An algorithm for learning BDS
parameters  inspired by a popular LDS learning method from dynamic textures 
is proposed. A similarity measure between BDSs  which generalizes the Binet-
Cauchy kernel for LDS  is then introduced and used to design activity classiï¬ers.
The proposed method is shown to outperform similar classiï¬ers derived from the
kernel dynamic system (KDS) and state-of-the-art approaches for dynamics-based
or attribute-based action recognition.

1

Introduction

Human activity understanding has been a research topic of substantial interest in computer vision [1].
Inspired by the success of the popular bag-of-features (BoF) representation on image classiï¬cation
problems  it is frequently based on the characterization of video as a collection of orderless spa-
tiotemporal features [2  3]. Recently  there have been attempts to extend this representation along
two dimensions that we explore in this work. The ï¬rst is to introduce richer models for the temporal
structure  also known as dynamics  of human actions [4  5  6  7]. This aims to exploit the fact that
actions are usually deï¬ned as sequences of poses  gestures  or other events over time. While desir-
able  modeling action dynamics can be a complex proposition  and this can sometimes compromise
the robustness of recognition algorithms  or sacriï¬ce their generality  e.g.  it is not uncommon for
dynamic models to require features speciï¬c to certain datasets or action classes [5  6]  or non-trivial
forms of pre-processing  such as tracking [8]  manual annotation [7]  etc. The second dimension 
again inspired by recent developments in image classiï¬cation [9  10]  is to represent actions in
terms of intermediate-level semantic concepts  or attributes [11  12]. This introduces a layer of
abstraction that improves the generalization of the representation  enables modeling of contextual
relationships [13]  and simpliï¬es knowledge transfer across activity classes [11].
In this work  we propose a representation that combines the beneï¬ts of these two types of extensions.
This consists of modeling the dynamics of human activities in the attributes space. The idea is to
exploit the fact that an activity is usually deï¬ned as a sequence of semantic events. For example  the
activity â€œstoring an object in a boxâ€ is deï¬ned as the sequence of the action attributes â€œremove (hand
from box)â€  â€œgrab (object)â€  â€œinsert (hand in box)â€  and â€œdrop (object)â€. The representation of

1

the action as a sequence of these attributes makes the characterization of the â€œstoring object in
boxâ€ activity more robust (to confounding factors such as diversity of grabbing styles  hand motion
speeds  or camera motions) than dynamic representations based on low-level features. It is also
more discriminant than semantic representations that ignore dynamics  i.e.  that simply record the
occurrence (or frequency) of the action attributes â€œremoveâ€  â€œgrabâ€  â€œinsertâ€  and â€œdropâ€. In the
absence of information about the sequence in which these attributes occur  the â€œstore object in boxâ€
activity cannot be distinguished from the â€œretrieve object from boxâ€ activity  deï¬ned as the sequence
â€œinsert (hand in box)â€  â€œgrab (object)â€  â€œremove (hand from box)â€  and â€œdrop (object)â€. In summary 
the modeling of attribute dynamics is 1) more robust and ï¬‚exible than the modeling of visual (low-
level) dynamics  and 2) more discriminant than the modeling of attribute frequencies.
In this work  we address the problem of modeling attribute dynamics for activities. As is usual in
semantics-based recognition [11]  we start by representing video in a semantic feature space  where
each feature encodes the probability of occurrence of an action attribute in the video  at a given
time. We then propose a generative model  denoted the binary dynamic system (BDS)  to learn both
the distribution and dynamics of different activities in this space. The BDS is a non-linear dynamic
system  which combines binary observation variables with a hidden Gauss-Markov state process.
It can be interpreted as either 1) a generalization of binary principal component analysis (binary
PCA) [14]  which accounts for data dynamics  or 2) an extension of the classical linear dynamic
system (LDS)  which operates on a binary observation space. For activity recognition  the BDS has
the appeal of accounting for the two distinguishing properties of the semantic activity representation:
1) that semantic vectors deï¬ne probability distributions over a space of binary attributes; and 2) that
these distributions evolve according to smooth trajectories that reï¬‚ect the dynamics of the underlying
activity. Its advantages over previous representations are illustrated by the introduction of BDS-
based activity classiï¬ers. For this  we start by proposing an efï¬cient BDS learning algorithm  which
combines binary PCA and a least squares problem  inspired by the learning procedure in dynamic
textures [15]. We then derive a similarity measure between BDSs  which generalizes the Binet-
Cauchy kernel from the LDS literature [16]. This is ï¬nally used to design activity classiï¬ers  which
are shown to outperform similar classiï¬ers derived from the kernel dynamic systems (KDS) [6]  and
state-of-the-art approaches for dynamics-based [4] and attribute-based [11] action recognition.

2 Prior Work
One of the most popular representations for activity recognition is the BoF  which reduces video to
an collection of orderless spatiotemporal descriptors [2  3]. While robust  the BoF ignores the tem-
poral structure of activities  and has limited power for ï¬ne-grained activity discrimination. A number
of approaches have been proposed to characterize this structure. One possibility is to represent ac-
tions in terms of limb or torso motions  spatiotemporal shape models  or motion templates [17  18].
Since they require detection  segmentation  tracking  or 3D structure recovery of body parts  these
representations can be fragile. A robust alternative is to model the temporal structure of the BoF.
This can be achieved with generalizations of popular still image recognition methods. For example 
Laptev et al. extend pyramid matching to video  using a 3D binning scheme that roughly character-
izes the spatio-temporal structure of video [3]. Niebles et al. employ a latent SVM that augments
the BoF with temporal context  which they show to be critical for understanding realistic motion [4].
All these approaches have relatively coarse modeling of dynamics. More elaborate models are usu-
ally based on generative representations. For example  Laxton et al. model a combination of object
contexts and action sequences with a dynamic Bayesian network [5]  while Gaidon et al. reduce
each activity to three atomic actions and model their temporal distributions [7]. These methods
rely on action-class speciï¬c features and require detailed manual supervision. Alternatively  sev-
eral researchers have proposed to model BoF dynamics with LDSs. For example  Kellokumpu et al.
combine dynamic textures [15] and local binary patterns [19]  Li et al. perform a discriminant canon-
ical correlation analysis on the space of action dynamics [8]  and Chaudhry et al. map frame-wise
motion histograms to a reproducing kernel Hilbert space (RKHS)  where they learn a KDS [6].
Recent research in image recognition has shown that various limitations of the BoF can be overcome
with representations of higher semantic level [10]. The features that underly these representations
are conï¬dence scores for the appearance of pre-deï¬ned visual concepts in images. These concepts
can be object attributes [9]  object classes [20  21]  contextual classes [13]  or generic visual con-
cepts [22]. Lately  semantic attributes have also been used for action recognition [11]  demonstrating
the beneï¬ts of a mid-level semantic characterization for the analysis of complex human activities.

2

Figure 1: Left: key frames of activities â€œhurdle raceâ€ (top) and â€œlong jumpâ€ (bottom); Right: attribute transi-
tion probabilities of the two activities (â€œhurdle raceâ€ / â€œlong jumpâ€) for attributes â€œrunâ€  â€œjumpâ€  and â€œlandâ€.

The work also suggests that  for action categorization  supervised attribute learning is far more useful
than unsupervised learning  resembling a similar observation from image recognition [20]. How-
ever  all of these representations are BoF-like  in the sense that they represent actions as orderless
feature collections  reducing an entire video sequence to an attribute vector. For this reason  we
denote them holistic attribute representations.
The temporal evolution of semantic concepts  throughout a video sequence  has not yet been ex-
ploited as a cue for action understanding. There has  however  been some progress towards this
type of modeling in the text analysis literature  where temporal extensions of latent Dirichlet allo-
cation (LDA) have been proposed. Two representatives are the dynamic topic model (DTM) [23]
and the topic over time (TOT) model [24]. Although modeling topic dynamics  these models are not
necessarily applicable to semantic action recognition. First  like the underlying LDA  they are un-
supervised models  and thus likely to underperform in recognition tasks [11  10]. Second  the joint
goal of topic discovery and modeling topic dynamics requires a complex graphical model. This is
at odds with tractability  which is usually achieved by sacriï¬cing the expressiveness of the temporal
model component.

3 Modeling the Dynamics of Activity Attributes

In this section  we introduce a new model  the binary dynamic system  for joint representation of the
distribution and dynamics of activities in action attribute space.

3.1 Semantic Representation
Semantic representations characterize video as a collection of descriptors with explicit seman-
tics [10  11]. They are obtained by deï¬ning a set of semantic concepts (or attributes  scene classes 
etc)  and learning a classiï¬er to detect each of those concepts. Given a video v âˆˆ X to analyze  each
classiï¬er produces a conï¬dence score for the presence of the associated concept. The ensemble of
classiï¬ers maps the video to a semantic space S  according to Ï€ : X â†’ S = [0  1]K  Ï€(v) =
(Ï€1(v) Â·Â·Â·   Ï€K(v))T   where Ï€i(v) is the conï¬dence score for the presence of the i-th concept.
In this work  the classiï¬cation score is the posterior probability of a concept c given video v 
i.e.  Ï€c(v) = p(c|v) under a certain video representation  e.g.  the popular BoF histogram of spatio-
temporal descriptors. As the video sequence v progresses with time t  the semantic encoding deï¬nes
a trajectory {Ï€t(v)} âŠ‚ S. The beneï¬ts of semantic representations for recognition  namely a higher
level of abstraction (which leads to better generalization than appearance-based representations) 
substantial robustness to the performance of the visual classiï¬ers Ï€i(v)  and intrinsic ability to ac-
count for contextual relationships between concepts  have been previously documented in the litera-
ture [13]. No attention has  however  been devoted to modeling the dynamics of semantic encodings
of video. Figure 1 motivates the importance of such modeling for action recognition  by considering
two activity categories (â€œlong jumpâ€ and â€œhurdle raceâ€)  which involve the same attributes  with
roughy the same probabilities  but span very different trajectories in S. Modeling these dynamics
can substantially enhance the ability of a classiï¬er to discriminate between complex activities.

3.2 Binary PCA
The proposed representation is a generalization of binary PCA [14]  a dimensionality reduction
technique for binary data  belonging to the generalized exponential family PCA [25]. It ï¬ts a linear
model to binary observations  by embedding the natural parameters of Bernoulli distributions in a
low-dimensional subspace. Let Y denote a K Ã— Ï„ binary matrix (Ykt âˆˆ {0  1}  e.g.  the indicator of

3

.  .  .    .  .  .    .  .  .    .  .  .           .  .  .    .  .  .    .  .  .    .  .  .    .  .  .    .  .  .    .  .  .    .  .  .    .  .  .    .  .  .         run land jump 0.5/0.8 0.5/0.2 0.2/0.7 0.8/0.3 1/0 occurrence of attribute k at time t) where each column is a vector of K binary observations sampled
from a multivariate Bernoulli distribution

Ykt âˆ¼ B(ykt; Ï€kt) = Ï€ykt

(1)
The log-odds Î¸ = log( Ï€
1âˆ’Ï€ ) is the natural parameter of the Bernoulli distribution  and Ïƒ(Î¸) =
(1 + eâˆ’Î¸)âˆ’1 is the logistic function. Binary PCA ï¬nds a L-dimensional (L (cid:28) K) embedding of the
natural parameters  by maximizing the log-likelihood of the binary matrix Y

kt (1 âˆ’ Ï€kt)1âˆ’ykt = Ïƒ(Î¸kt)ykt Ïƒ(âˆ’Î¸kt)1âˆ’ykt   ykt âˆˆ {0  1}.
(cid:88)

Ykt log Ïƒ(Î˜kt) + (1 âˆ’ Ykt) log Ïƒ(âˆ’Î˜kt)

L = log P (Y ; Î˜) =

(cid:104)

(cid:105)

(2)

k t

under the constraint

Î˜ = CX + u1T  

(3)
where C âˆˆ RKÃ—L  X âˆˆ RLÃ—Ï„   u âˆˆ RK and 1 âˆˆ RÏ„ is the vector of all ones. Each column of C
is a basis vector of a latent subspace and the t-th column of X contains the coordinates of the t-th
binary vector in this basis (up to a translation by u).
Binary PCA is not directly applicable to attribute-based recognition  where the goal is to ï¬t the
vectors of conï¬dence scores {Ï€t} produced by a set of K attribute classiï¬ers (and not a sample of
binary attribute vectors per se). To overcome this problem  we maximize the expected log-likelihood
of the data Y (which is the lower bound to the log expected likelihood of the data Y   by Jensenâ€™s
inequality). Since E[yt] = Ï€t  it follows from (2) that

EY [L] =

Ï€kt log Ïƒ(Î˜kt) + (1 âˆ’ Ï€kt) log Ïƒ(âˆ’Î˜kt)

.

(4)

(cid:105)

(cid:88)

(cid:104)

k t

E[âˆ†L({Ï€t};{Ïƒ(Î¸t)})] = EY

The proposed extension of binary PCA consists of maximizing this expected log-likelihood under
the constraint of (3). It can be shown that  in the absence of the constraint  the maximum occurs
when Ïƒ(Î˜kt) = Ï€kt âˆ€k  t. As in PCA  (3) forces Ïƒ(Î˜kt) to lie on a subspace of S  i.e. 

(5)
The difference between the expected log-likelihood of the true scores {Ï€t} and the binary PCA
scores {Ïƒ(Î¸t) = Ïƒ(Cxt + u)} (Ïƒ(Î¸) â‰¡ [Ïƒ(Î¸1) Â·Â·Â·   Ïƒ(Î¸K)]T ) is

Ïƒ(Î˜kt) = Ë†Ï€kt â‰ˆ Ï€kt.

(cid:2) log(P (Y ;{Ï€t}))(cid:3) âˆ’ EY
(cid:20)
(cid:88)
(cid:88)

Ïƒ(Î˜kt)

Ï€kt log

Ï€kt

k t

KL[B(y; Ï€t)||B(y; Ïƒ(Î¸t))] 

(cid:2) log(P (Y ;{Ïƒ(Î¸t)}))(cid:3)
(cid:21)

1 âˆ’ Ï€kt
Ïƒ(âˆ’Î˜kt)

+ (1 âˆ’ Ï€kt) log

=

(6)

(7)

t

=

(8)
where KL(B(y; Ï€)||B(y; Ï€(cid:48))) is the Kullback-Leibler (KL) divergence between two multivariate
Bernoulli distributions of parameters Ï€ and Ï€(cid:48). By maximizing the expected log-likelihood (4)  the
t} of the attribute score vectors {Ï€t} on the subspace of (3) also minimizes the
optimal projection {Î¸
âˆ—
t}  the approximation of (5) is the
KL divergence of (8). Hence  for the optimal natural parameters {Î¸
âˆ—
best in the sense of KL divergence  the natural similarity measure between probability distributions.
3.3 Binary Dynamic Systems
A discrete time linear dynamic system (LDS) is deï¬ned by

(cid:26) xt+1 = Axt + vt

yt = Cxt + wt + u

 

(9)

where xt âˆˆ RL and yt âˆˆ RK (of mean u) are the hidden state and observation variable at
time t  respectively; A âˆˆ RLÃ—L is the state transition matrix that encodes the underlying dynam-
ics; C âˆˆ RKÃ—L the observation matrix that linearly maps the state to the observation space; and
x1 = Âµ0 + v0 âˆ¼ N (Âµ0  S0) an initial condition. Both state and observations are subject to addi-
tive Gaussian noise processes vt âˆ¼ N (0  Q) and wt âˆ¼ N (0  R). Since the noise is Gaussian and
L < K  the matrix C can be interpreted as a PCA basis for the observation space (L eigenvectors
of the observation covariance). The state vector xt then encodes the trajectory of the PCA coefï¬-
cients (projection on this basis) of the observed data over time. This interpretation is  in fact  at the
core of the popular dynamic texture (DT) [15] representation for video. While the LDS parameters

4

Algorithm 1: Learning a binary dynamic system
Input

: a sequence of attribute score vectors {Ï€t}Ï„

Binary PCA: {C  X  u} = B-PCA({Ï€t}Ï„
Estimate state parameters (X t2

t1 â‰¡(cid:2)xt1  Â·Â·Â·   xt2

(cid:3)):

t=1  state space dimension n.

t=1  n) using the method of [14].

(cid:80)Ï„
2 (X Ï„âˆ’1

)â€ ;
t=1 xt;

1

A = X Ï„
Âµ0 = 1
Ï„

(cid:80)Ï„
2 âˆ’ A(X)Ï„âˆ’1
t=1(xt âˆ’ Âµ0)(xt âˆ’ Âµ0)T .

; Q = 1

1

Ï„âˆ’1 V (V )T ;

V = (X)Ï„
S0 = 1
Ï„âˆ’1

Output: {A  C  Q  u  Âµ0  S0}

can be learned by maximum likelihood  using an expectation-maximization (EM) algorithm [26] 
the DT decouples the learning of observation and state variables. Observation parameters are ï¬rst
learned by PCA  and state parameters are then learned with a least squares procedure. This simple
approximate learning algorithm tends to perform very well  and is widely used in computer vision.
The proposed binary dynamic system (BDS) is deï¬ned as

(cid:26) xt+1 = Axt + vt

 

yt âˆ¼ B(y; Ïƒ(Cxt + u))

(10)
where xt âˆˆ RL and u âˆˆ RK are the hidden state variable and observation bias  respectively; A âˆˆ
RLÃ—L is the state transition matrix; and C âˆˆ RKÃ—L the observation matrix. The initial condition is
given by x1 = Âµ0 + v0 âˆ¼ N (Âµ0  S0); and the state noise process is vt âˆ¼ N (0  Q). Like the LDS
of (9)  the BDS can be interpreted as combining a (now binary) PCA observation component with
a Gauss-Markov process for the state sequence. As in binary PCA  for attribute-based recognition
the binary observations yt are replaced by the attribute scores Ï€t  their log-likelihood under (10)
by the expected log-likelihood  and the optimal solution minimizes the approximation of (5) for
the most natural deï¬nition of similarity (KL divergence) between probability distributions. This is
conceptually equivalent to the behavior of the canonical LDS of (9)  which determines the subspace
that best approximates the observations in the Euclidean sense  the natural similarity measure for
Gaussian data. Note that other extensions of the LDS  e.g.  kernel dynamic systems (KDS) that rely
on a non-linear kernel PCA (KPCA) [27] of the observation space but still assume an Euclidean
measure (Gaussian noise) [28  6]  do not share this property. We will see  in the experimental
section  that the BDS is a better model of attribute dynamics.

3.4 Learning
Since the Gaussian state distribution of an LDS is a conjugate prior for the (Gaussian) conditional-
distribution of its observations given the state  maximum-likelihood estimates of LDS parameters
are tractable. The LDS parameters â„¦LDS = {A  C  Q  R  Âµ0  S0  u} of (9) can thus be estimated
with an EM algorithm [26]. For the BDS  where the state is Gaussian but the observations are not 
the expectation step is intractable. Hence  approximate inference is required to learn the parameters
â„¦BDS = {A  C  Q  Âµ0  S0  u} of (10). In this work  we resort to the approximate DT learning
procedure  where observation and state components are learned separately [15]. The binary PCA
basis is learned ï¬rst  by maximizing the expected log-likelihood of (4) subject to the constraint
of (3). Since the Bernoulli distribution is a member of exponential family  (4) is concave in Î˜  but
not in C  X and u jointly. We rely on a procedure introduced by [14]  which iterates between the
optimization with respect to one of the variables C  X and u  with the remaining two held constant.
Each iteration is a convex sub-problem that can be solved efï¬ciently with a ï¬xed-point auxiliary
function (see [14] for details). Once the latent embedding Câˆ—  Xâˆ— and uâˆ— of the attribute sequence
in the optimal subspace is recovered  the remaining parameters are estimated by solving a least-
squares problem for A and Q  and using standard maximum likelihood estimates for the Gaussian
parameters of the initial condition (Âµ0 and S0) [15]. The procedure is summarized in Algorithm 1.

4 Measuring Distances between BDSs

The design of classiï¬ers that account for attribute dynamics requires the ability to quantify similarity
between BDSs. In this section  we derive the BDS counterpart to the popular Binet-Cauchy ker-
nel (BCK) for the LDS  which evaluates the similarity of the output sequences of two LDSs. Given

5

(cid:104)(cid:88)âˆ

LDSs â„¦a and â„¦b driven by identical noise processes vt and wt with observation sequences y(a)
and y(b)  [16] propose a family of BCKs

eâˆ’Î»t(y(a)

KBC(â„¦a  â„¦b) = Ev w

(11)
where W is a semi-deï¬nite positive weight matrix and Î» (cid:62) 0 a temporal discounting factor. To
extend (11) to BDSs â„¦a and â„¦b  we note that (y(a)
is the inner product of an Euclidean
t âˆ’ y(b)
t âˆ’ y(b)
output space of metric d2(y(a)
t ). For BDSs  whose obser-
)}  for â„¦a  and {Ïƒ(Î¸(b)
vations yt are Bernouli distributed with parameters {Ïƒ(Î¸(a)
t )}  for â„¦b  this
distance measure is naturally replaced by the KL divergence between Bernoulli distributions

)T W y(b)
t )T W (y(a)

t ) = (y(a)

  y(b)

)T W y(b)

t=0

 

t

t

t

t

t

t

(cid:105)

(cid:17)(cid:35)

(cid:34) âˆ(cid:88)
(cid:20)(cid:88)âˆ

t=0

e

âˆ’Î»t(cid:16)
âˆ’Î»t(cid:16)

e

t=0

DBC (â„¦a  â„¦b) = Ev

= Ev

KL(B(Ïƒ(Î¸(a)

t

))||B(Ïƒ(Î¸(b)

t ))) + KL(B(Ïƒ(Î¸(b)

t ))||B(Ïƒ(Î¸(a)

t

)))

(cid:17)T(cid:16)

(cid:17)(cid:21)

Ïƒ(Î¸(a)

t

) âˆ’ Ïƒ(Î¸(b)
t )

t âˆ’ Î¸(b)
Î¸(a)

t

 

(12)

where Î¸t = Cxt + u. The distance term at time t can be rewritten as

t

(Ïƒ(Î¸(a)

t ))T (Î¸(a)

) âˆ’ Ïƒ(Î¸(b)

t âˆ’ Î¸(b)

(13)
t k âˆ’
with Ë†Wt a diagonal matrix whose k-th diagonal element is Ë†Wt k = (Ïƒ(Î˜(a)
t k) = Ïƒ(cid:48)( Ë†Î˜(a b)
Î˜(b)
t k and
Ë†Î˜(b)
t k). This reduces (13) to a form similar to (11)  although with a time varying weight matrix Wt.
It is unclear whether (12) can be computed in closed-form. We currently rely on the approximation

t k))/(Î˜(a)
is some real value between Ë†Î˜(a)

t k ) (where  by the mean value theorem  Ë†Î˜(a b)

t âˆ’ Î¸(b)
t ) 
t k ) âˆ’ Ïƒ(Î˜(b)

t )T Ë†Wt(Î¸(a)

t âˆ’ Î¸(b)

t ) = (Î¸(a)

t k

t=0 eâˆ’Î»t(Ïƒ(Â¯Î¸(a)

t

) âˆ’ Ïƒ(Â¯Î¸(b)

t ))T (Â¯Î¸(a)

t âˆ’ Â¯Î¸(b)

t )  where Â¯Î¸ is the mean of Î¸.

DBC(â„¦a  â„¦b) â‰ˆ(cid:80)âˆ

5 Experiments

Several experiments were conducted to evaluate the BDS as a model of activity attribute dynam-
ics. In all cases  the BoF was used as low-level video representation  interest points were detected
with [2]  and HoG/HoF descriptors [3] computed at their locations. A codebook of 3000 visual
words was learned via k-means  from the entire training set  and a binary SVM with histogram
intersection kernel (HIK) and probability outputs [29] trained to detect each attribute using the at-
tribute deï¬nition same as [11]. The probability for attribute k at time t was used as attribute score
Ï€tk  which was computed over a window of 20 frames  sliding across a video.

5.1 Weizmann Activities
To obtain some intuition on the performance of different algorithms considered  we ï¬rst used com-
plex activity sequences synthesized from the Weizmann dataset [17]. This contains 10 atomic action
classes (e.g.  skipping  walking) annotated with respect to 30 lower-level attributes (e.g.  â€œone-arm-
motionâ€)  and performed by 9 people. We created activity sequences by concatenating Weizmann
actions. A sequence of degree n (n = 4  5  6) is composed of n atomic actions  performed by the
same person. The row of images at the top of Figure 2 presents an example of an activity sequence of
degree 5. The images shown at the top of the ï¬gure are keyframes from the atomic actions (â€œwalkâ€ 
â€œpjumpâ€  â€œwave1â€  â€œwave2â€  â€œwave2â€) that compose this activity sequence. The black curve (la-
beled â€œSem. Seqâ€) in the plot at the bottom of the ï¬gure shows the score of the â€œtwo-arms-motionâ€
attribute  as a function of time. 40 activity categories were deï¬ned per degree n (total of 120 activity
categories) and a dataset was assembled per category  containing one activity sequence per person (9
people  1080 sequences in total). Overall  the activity sequences differ in the number  category  and
temporal order of atomic actions. Since the attribute ground truth is available for all atomic actions
in this dataset  it is possible to train clean attribute models. Hence  all performance variations can
be attributed to the quality of the attribute-based inference of different approaches.
We started by comparing the binary PCA representation that underlies the BDS to the PCA and
KPCA decompositions of the LDS and KDS. In all cases we projected a set of attribute score vectors
{Ï€t} into the low-dimensional PCA subspace  computed the reconstructed score vectors { Ë†Ï€t}  and
the KL divergence KL(B(y  Ï€t)||B(y  Ë†Ï€t)  as reported in Figure 3. The kernel used for KPCA was

6

Figure 2: Top: key frames from the activity sequence class â€œwalk-
pjump-wave1-wave2-wave2â€. Bottom: score of â€œtwo-arms-motionâ€
attribute for video of this activity. True scores in black  and scores
sampled from the BDS (red) and KDS (blue). Also shown is the KL-
divergence between sampled and original scores  for both models.

Figure 3:
Log KL-divergence be-
tween original and reconstructed at-
tribute scores  v.s. number of PCA com-
ponents n  on Weizmann activities for
PCA  kernel PCA  and binary PCA.

Table 1: Classiï¬cation Accuracy on Weizmann Activities and Olympic Sports Datasets

Dataset

Weizmann Activities

Olympic Sports

BoF
57.8%
56.8%

Holistic Attri.

72.6%
63.5%

TOT

DTM
BDS
84.6% 88.2% 90.2% 94.8%
47.1% 53.3% 62.3% 65.7%

KDS

the logit kernel K(Ï€1  Ï€2) = Ïƒâˆ’1(Ï€1)T Ïƒâˆ’1(Ï€2)  where Ïƒâˆ’1(Â·) is the element-wise logit function.
Figure 3 shows the average log-KL divergence  over the entire dataset  as a function of the number of
PCA components used in the reconstruction. Binary PCA outperformed both PCA and KPCA. The
improvements over KPCA are particularly interesting since the latter uses the logistic transformation
that distinguishes binary PCA from PCA. This is explained by the Euclidean similarity measure that
underlies the assumption of Gaussian noise in KPCA  as discussed in Section 3.3. To gain some
more insight on the different models  a KDS and a BDS were learned from the 30 dimensional
attribute score vectors of the activity sequence in Figure 2. A new set of attribute score vectors were
then sampled from each model. The evolution of the scores sampled for the â€œtwo-arms-motionâ€
attribute are shown in the ï¬gure (in red/blue for BDS/KDS). Note how the scores sampled from the
BDS approximate the original attribute scores better than those sampled from the KDS  which is
conï¬rmed by the KL-divergences between the original attribute scores and those sampled from the
two models (also shown in the ï¬gure).
We next evaluated the beneï¬ts of different dynamics representations for activity recognition. Recog-
nition rates were obtained with a 9-fold leave-one-out-cross-validation (LOOCV)  where  per trial 
the activities of one subject were used as test set and those of the remaining 8 as training set. We
compared the performance of classiï¬ers based on the KDS and BDS with a BoF classiï¬er  a holistic
attribute classiï¬er that ignores attribute dynamics (using a single attribute score vector computed
from the entire video sequence) and the dynamic topic models DTM [23] and TOT [24] from the
text literature. For the latter  the topics were equated to the activity attributes and learned with su-
pervision (using the SVMs discussed above). Unsupervised versions of the topic models had worse
performance and are omitted. Classiï¬cation was performed with Bayes rule for topic models  and a
nearest-neighbor classiï¬er for the remaining methods. For BDS  distances were measured with (12) 
while for the KDS we tried the Binet-Cauchy  X 2  intersection and logit kernels  and reported the
best results. X 2 distance was used for the BoF and holistic attribute classiï¬ers. The classiï¬cation
accuracy of all classiï¬ers is shown in Table 1. BDS and KDS had the best performance  followed by
the dynamic topic models  and the dynamics insensitive methods (BoF and holistic). Note that the
difference between the holistic classiï¬er and the best dynamic model is of approximately 22%. This
shows that while attributes are important (14.8% improvement over BoF) they are not the whole
story. Problems involving ï¬ne-grained activity classiï¬cation  i.e.  discrimination between activities
composed of similar actions executed in different sequence  requires modeling of attribute dynamics.
Among dynamic models  the BDS outperformed the KDS  and topic models DTM and TOT.

5.2 Olympic Sports
The second set of experiments was performed on the Olympic Sports dataset [4]. This contains
YouTuBe videos of 16 sport activities  with a total of 783 sequences. Some activities are sequences

7

	
	01234567âˆ’4âˆ’20246nlog KLâˆ’div  PCAkernelâˆ’PCAbinaryâˆ’PCATable 2: Fine-grained Classiï¬cation Accuracy on Olympic Sports by BDS

Method

BDS

Holistic

clean&jerk

(snatch)
85% (9%)
73% (21%)

long-jump
(triple-jump)
80% (2%)
72% (20%)

snatch

(clean&jerk)
78% (10%)
65% (27%)

triple-jump
(long-jump)
62% (14%)
38% (43%)

Table 3: Mean Average Precision on Olympic Sports Dataset

Laptev et al. [3]

( BoF )
62.0%
( 67.8% )

Niebles et al. [4]

( BDS )
72.1%
(73.2%)

Liu et al. [11]
( Attr. / B+A )

74.4%

(72.9% / 73.3%)

B+A+D

76.5%

Figure 4:
gain on Olympic Sports by BDS.

Scatter plot of accuracy

of atomic actions  whose temporal structure is critical for discrimination from other classes (e.g. 
â€œclean and jerkâ€ v.s.â€œsnatchâ€  and â€œlong-jumpâ€ v.s.â€œtriple-jumpâ€). Since attribute labels are only
available for whole sequences  the training sets of the attribute classiï¬ers are much noisier than
in the previous experiment. This degrades the quality of attribute models. The dataset was split
into 5 subsets  of roughly the same size  and results reported by 5-fold cross-validation. The
DTM and TOT classiï¬ers were as above  and all others were implemented with an SVM of ker-
nel KÎ±(i  j) = exp(âˆ’ 1
Î± d2(i  j))  based on the distance measures d(i  j) of the previous section.
Table 1 shows that dynamic modeling again has the best performance. However  the gains over the
holistic attribute classiï¬er are smaller than in Weizmann. This is due to two factors. First  the noisy
attributes make the dynamics harder to model. Note that the robustness of the dynamic models to
this noise varies substantially. As before  topic models have the weakest performance and the BDS
outperforms the KDS. Second  since ï¬ne grained discrimination is not needed for all categories 
attribute dynamics are not always necessary. This is conï¬rmed by Figure 4  which presents a scatter
plot of the gain (difference in accuracy) of the BDS classiï¬er over the holistic classiï¬er  as a func-
tion of the accuracy of the latter. Each point corresponds to an activity. Note the strongly negative
correlation between the two factors: the largest gains occur for the most difï¬cult classes for the
holistic classiï¬er. Table 2 details these results for the two pairs of classes with most confusable at-
tributes. Numbers outside brackets correspond to ground-truth category  numbers in brackets to the
confusing class (percentage of ground-truth examples assigned to it). BDS has dramatically better
performance for these classes. Overall  despite the attribute noise and the fact that dynamics are not
always required for discrimination  the BDS achieves the best performance on this dataset.
Finally  we compare the BDS classiï¬er to classiï¬ers from the literature. Three approaches  rep-
resentative of the state-of-the art in classiï¬cation with the BoF [3]  dynamic representations [4] 
and attributes [11]  were selected as benchmarks. These were compared to our implementation
of BoF (kernel using only word histograms)  attributes (the holistic classiï¬er of Table 1)  dynam-
ics (the BDS classiï¬er)  and multiple kernel classiï¬ers combining 1) BoF and attributes (B+A)  and
2) BoF  attributes  and dynamics (B+A+D). All multiple kernels combinations were achieved by
cross-validation. The mean average precisions of all 1-vs-all classiï¬ers are reported in Table 3. The
numbers in each column report to directly comparable classiï¬ers  e.g.  B+A is directly comparable
to [11]  which jointly classiï¬es BoF histograms and hollistic attribute vectors with a latent SVM.
Note that the BDS classiï¬er outperforms the state-of-the-art in dynamic classiï¬ers (Niebles et al.
[4])  which accounts for the dynamics of the BoF but not action attributes. This holds despite the fact
that our attribute categories (only 40 speciï¬ed attributes) and classiï¬ers (simple SVMs) are much
simpler than the best in the literature [11]   which uses both the data-driven and the 40 speciï¬ed
attributes as ours  plus a latent SVM as the classiï¬er. The use of a stronger attribute detection archi-
tecture could potentially further improve these results. Note also that the addition of the BDS kernel
to the simple attribute representation (B+A+D) far outperforms the use of the more sophisticated at-
tribute classiï¬er of [11]  which does not account for attribute dynamics. This illustrates the beneï¬ts
of modeling the dynamics of attributes. The combination of BoF  attributes  and attribute dynamics
achieves the overall best performance on this dataset.

Acknowledgements

This work was partially supported by the NSF award under Grant CCF-0830535. We also thank
Jingen Liu for providing the attribute annotations.

8

		

!#   ! !# ! "! " !"! References
[1] J. K. Aggarwal and M. S. Ryoo  â€œHuman activity analysis: A review â€ ACM Computing Surveys  vol. 43 

no. 16  pp. 1â€“16  2011.

[2] P. DollÂ´ar  V. Rabaud  G. Cottrell  and S. Belongie  â€œBehavior recognition via sparse spatio-temporal

features â€ ICCV VS-PETS  2005.

[3] I. Laptev  M. MarszaÅ‚ek  C. Schmid  and B. Rozenfeld  â€œLearning realistic human actions from movies â€

CVPR  2008.

[4] J. C. Niebles  C.-W. Chen  and L. Fei-Fei  â€œModeling temporal structure of decomposable motion seg-

ments for activity classiï¬cation â€ ECCV  2010.

[5] B. Laxton  J. Lim  and D. Kriegman  â€œLeveraging temporal  contextual and ordering constraints for rec-

ognizing complex activities in video â€ CVPR  2007.

[6] R. Chaudhry  A. Ravichandran  G. Hager  and R. Vidal  â€œHistograms of oriented optical ï¬‚ow and binet-

cauchy kernels on nonlinear dynamical systems for the recognition of human actions â€ CVPR  2009.

[7] A. Gaidon  Z. Harchaoui  and C. Schmid  â€œActom sequence models for efï¬cient action detection â€ CVPR 

2011.

[8] B. Li  M. Ayazoglu  T. Mao  O. Camps  and M. Sznaier  â€œActivity recognition using dynamic subspace

angles â€ CVPR  2011.

[9] C. H. Lampert  H. Nickisch  and S. Harmeling  â€œLearning to detect unseen object classes by between-class

attribute transfer â€ CVPR  2009.

[10] N. Rasiwasia and N. Vasconcelos  â€œHolistic context models for visual recognition â€ IEEE Trans. Pattern

Analysis and Machine Intelligence  vol. 34  no. 5  pp. 902â€“917  2012.

[11] J. Liu  B. Kuipers  and S. Savarese  â€œRecognizing human actions by attributes â€ CVPR  2011.
[12] A. Fathi and G. Mori  â€œAction recognition by learning mid-level motion features â€ CVPR  2008.
[13] N. Rasiwasia and N. Vasconcelos  â€œHolistic context modeling using semantic co-occurrences â€ CVPR 

2009.

[14] A. I. Schein  L. K. Saul  and L. H. Ungar  â€œA generalized linear model for principal component analysis

of binary data â€ AISTATS  2003.

[15] G. Doretto  A. Chiuso  Y. N. Wu  and S. Soatto  â€œDynamic textures â€ Intâ€™l J. Computer Vision  vol. 51 

no. 2  pp. 91â€“109  2003.

[16] S. V. N. Vishwanathan  A. J. Smola  and R. Vidal  â€œBinet-cauchy kernels on dynamical systems and its
application to the analysis of dynamic scenes â€ Intâ€™l J. Computer Vision  vol. 73  no. 1  pp. 95â€“119  2006.
[17] L. Gorelick  M. Blank  E. Shechtman  M. Irani  and R. Basri  â€œActions as space-time shapes â€ IEEE Trans.

Pattern Analysis and Machine Intelligence  vol. 29  no. 12  pp. 2247â€“2253  2007.

[18] N. Ë™Ikizler and D. A. Forsyth  â€œSearching for complex human activities with no visual examples â€ Intâ€™l J.

Computer Vision  vol. 80  no. 3  pp. 337â€“357  2008.

[19] V. Kellokumpu  G. Zhao  and M. PietikÂ¨ainen  â€œHuman activity recognition using a dynamic texture based

method â€ BMVC  2008.

[20] N. Rasiwasia and N. Vasconcelos  â€œScene classiï¬cation with low-dimensional semantic spaces and weak

supervision â€ CVPR  2008.

[21] A. Quattoni  M. Collins  and T. Darrell  â€œLearning visual representations using images with captions â€

CVPR  2007.

[22] N. Rasiwasi  P. J. Moreno  and N. Vasconcelos  â€œBridging the gap: Query by semantic example â€ IEEE

Trans. Multimedia  vol. 9  no. 5  pp. 923â€“938  2007.

[23] D. M. Blei and J. D. Lafferty  â€œDynamic topic models â€ ICML  2006.
[24] X. Wang and A. McCallum  â€œTopics over time: a non-markov continuous-time model of topical trends â€

ACM SIGKDD  2006.

[25] M. Collins  S. Dasgupta  and R. E. Schapire  â€œA generalization of principal component analysis to the

exponential family â€ NIPS  2002.

[26] R. H. Shumway and D. S. Stoffer  â€œAn approach to time series smoothing and forecasting using the em

algorithm â€ Journal of Time Series Analysis  vol. 3  no. 4  pp. 253â€“264  1982.

[27] B. SchÂ¨olkopf  A. Smola  and K.-R. MÂ¨uller  â€œNonlinear component analysis as a kernel eigenvalue prob-

lem â€ Neural Computation  vol. 10  pp. 1299â€“1319  1998.

[28] A. B. Chan and N. Vasconcelos  â€œClassifying video with kernel dynamic textures â€ CVPR  2007.
[29] C.-C. Chang and C.-J. Lin  â€œLIBSVM: A library for support vector machines â€ ACM Trans. on Intelligent

Systems and Technology  vol. 2  no. 3  pp. 27:1â€“27:27  2011.

9

,Raif Rustamov
Leonidas Guibas
Shuhang Gu
Lei Zhang
Xiangchu Feng
Peter Flach
Meelis Kull
Arsenii Vanunts
Alexey Drutsa