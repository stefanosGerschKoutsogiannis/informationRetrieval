2014,Beyond Disagreement-Based Agnostic Active Learning,We study agnostic active learning  where the goal is to learn a classifier in a pre-specified hypothesis class interactively with as few label queries as possible  while making no assumptions on the true function generating the labels. The main algorithms for this problem are {\em{disagreement-based active learning}}  which has a high label requirement  and {\em{margin-based active learning}}  which only applies to fairly restricted settings. A major challenge is to find an algorithm which achieves better label complexity  is consistent in an agnostic setting  and applies to general classification problems. In this paper  we provide such an algorithm. Our solution is based on two novel contributions -- a reduction from consistent active learning to confidence-rated prediction with guaranteed error  and a novel confidence-rated predictor.,Beyond Disagreement-based Agnostic Active

Learning

Chicheng Zhang

University of California  San Diego

9500 Gilman Drive  La Jolla  CA 92093

Kamalika Chaudhuri

University of California  San Diego

9500 Gilman Drive  La Jolla  CA 92093

chichengzhang@ucsd.edu

kamalika@cs.ucsd.edu

Abstract

We study agnostic active learning  where the goal is to learn a classiﬁer in a pre-
speciﬁed hypothesis class interactively with as few label queries as possible  while
making no assumptions on the true function generating the labels. The main al-
gorithm for this problem is disagreement-based active learning  which has a high
label requirement. Thus a major challenge is to ﬁnd an algorithm which achieves
better label complexity  is consistent in an agnostic setting  and applies to general
classiﬁcation problems.
In this paper  we provide such an algorithm. Our solution is based on two novel
contributions; ﬁrst  a reduction from consistent active learning to conﬁdence-rated
prediction with guaranteed error  and second  a novel conﬁdence-rated predictor.

1

Introduction

In this paper  we study active learning of classiﬁers in an agnostic setting  where no assumptions
are made on the true function that generates the labels. The learner has access to a large pool of
unlabelled examples  and can interactively request labels for a small subset of these; the goal is to
learn an accurate classiﬁer in a pre-speciﬁed class with as few label queries as possible. Speciﬁcally 
we are given a hypothesis class H and a target �  and our aim is to ﬁnd a binary classiﬁer in H
whose error is at most � more than that of the best classiﬁer in H  while minimizing the number of
requested labels.
There has been a large body of previous work on active learning; see the surveys by [10  28] for
overviews. The main challenge in active learning is ensuring consistency in the agnostic setting
while still maintaining low label complexity. In particular  a very natural approach to active learning
is to view it as a generalization of binary search [17  9  27]. While this strategy has been extended
to several different noise models [23  27  26]  it is generally inconsistent in the agnostic case [11].
The primary algorithm for agnostic active learning is called disagreement-based active learning.
The main idea is as follows. A set Vk of possible risk minimizers is maintained with time  and the
label of an example x is queried if there exist two hypotheses h1 and h2 in Vk such that h1(x) �=
h2(x). This algorithm is consistent in the agnostic setting [7  2  12  18  5  19  6  24]; however  due
to the conservative label query policy  its label requirement is high. A line of work due to [3  4  1]
have provided algorithms that achieve better label complexity for linear classiﬁcation on the uniform
distribution over the unit sphere as well as log-concave distributions; however  their algorithms are
limited to these speciﬁc cases  and it is unclear how to apply them more generally.
Thus  a major challenge in the agnostic active learning literature has been to ﬁnd a general active
learning strategy that applies to any hypothesis class and data distribution  is consistent in the agnos-
tic case  and has a better label requirement than disagreement based active learning. This has been
mentioned as an open problem by several works  such as [2  10  4].

1

In this paper  we provide such an algorithm. Our solution is based on two key contributions  which
may be of independent interest. The ﬁrst is a general connection between conﬁdence-rated pre-
dictors and active learning. A conﬁdence-rated predictor is one that is allowed to abstain from
prediction on occasion  and as a result  can guarantee a target prediction error. Given a conﬁdence-
rated predictor with guaranteed error  we show how to to construct an active label query algorithm
consistent in the agnostic setting. Our second key contribution is a novel conﬁdence-rated predictor
with guaranteed error that applies to any general classiﬁcation problem. We show that our predictor
is optimal in the realizable case  in the sense that it has the lowest abstention rate out of all predictors
guaranteeing a certain error. Moreover  we show how to extend our predictor to the agnostic setting.
Combining the label query algorithm with our novel conﬁdence-rated predictor  we get a general
active learning algorithm consistent in the agnostic setting. We provide a characterization of the label
complexity of our algorithm  and show that this is better than the bounds known for disagreement-
based active learning in general. Finally  we show that for linear classiﬁcation with respect to the
uniform distribution and log-concave distributions  our bounds reduce to those of [3  4].

2 Algorithm

2.1 The Setting

We study active learning for binary classiﬁcation. Examples belong to an instance space X   and
their labels lie in a label space Y = {−1  1}; labelled examples are drawn from an underlying data
distribution D on X × Y. We use DX to denote the marginal on D on X   and DY |X to denote the
conditional distribution on Y |X = x induced by D. Our algorithm has access to examples through
two oracles – an example oracle U which returns an unlabelled example x ∈ X drawn from DX and
a labelling oracle O which returns the label y of an input x ∈ X drawn from DY |X.
Given a hypothesis class H of VC dimension d  the error of any h ∈ H with respect to a
data distribution Π over X × Y is deﬁned as errΠ(h) = P(x y)∼Π(h(x) �= y). We deﬁne:
errΠ(h)  ν∗(Π) = errΠ(h∗(Π)). For a set S  we abuse notation and use S
h∗(Π) = argminh∈H
to also denote the uniform distribution over the elements of S. We deﬁne PΠ(·) := P(x y)∼Π(·) 
EΠ(·) := E(x y)∼Π(·).
Given access to examples from a data distribution D through an example oracle U and a labeling
oracle O  we aim to provide a classiﬁer ˆh ∈ H such that with probability ≥ 1 − δ  errD(ˆh) ≤
ν∗(D) + �  for some target values of � and δ; this is achieved in an adaptive manner by making
as few queries to the labelling oracle O as possible. When ν∗(D) = 0  we are said to be in the
realizable case; in the more general agnostic case  we make no assumptions on the labels  and thus
ν∗(D) can be positive.
Previous approaches to agnostic active learning have frequently used the notion of disagreements.
The disagreement between two hypotheses h1 and h2 with respect to a data distribution Π is
the fraction of examples according to Π to which h1 and h2 assign different labels; formally:
ρΠ(h1  h2) = P(x y)∼Π(h1(x) �= h2(x)). Observe that a data distribution Π induces a pseudo-
metric ρΠ on the elements of H; this is called the disagreement metric. For any r and any h ∈ H 
deﬁne BΠ(h  r) to be the disagreement ball of radius r around h with respect to the data distribution
Π. Formally: BΠ(h  r) = {h� ∈ H : ρΠ(h  h�) ≤ r}.
For notational simplicity  we assume that the hypothesis space is “dense” with repsect to the data
distribution D  in the sense that ∀r > 0  suph∈BD(h∗(D) r) ρD(h  h∗(D)) = r. Our analysis will
still apply without the denseness assumption  but will be signiﬁcantly more messy. Finally  given a
set of hypotheses V ⊆ H  the disagreement region of V is the set of all examples x such that there
exist two hypotheses h1  h2 ∈ V for which h1(x) �= h2(x).
This paper establishes a connection between active learning and conﬁdence-rated predictors with
guaranteed error. A conﬁdence-rated predictor is a prediction algorithm that is occasionally al-
lowed to abstain from classiﬁcation. We will consider such predictors in the transductive setting.
Given a set V of candidate hypotheses  an error guarantee η  and a set U of unlabelled examples 
a conﬁdence-rated predictor P either assigns a label or abstains from prediction on each unlabelled

2

x ∈ U. The labels are assigned with the guarantee that the expected disagreement1 between the
label assigned by P and any h ∈ V is ≤ η. Speciﬁcally 

for all h ∈ V  Px∼U (h(x) �= P (x)  P (x) �= 0) ≤ η

(1)
This ensures that if some h∗ ∈ V is the true risk minimizer  then  the labels predicted by P on U do
not differ very much from those predicted by h∗. The performance of a conﬁdence-rated predictor
which has a guarantee such as in Equation (1) is measured by its coverage  or the probability of
non-abstention Px∼U (P (x) �= 0); higher coverage implies better performance.
2.2 Main Algorithm

Our active learning algorithm proceeds in epochs  where the goal of epoch k is to achieve excess
generalization error �k = �2k0−k+1  by querying a fresh batch of labels. The algorithm maintains a
candidate set Vk that is guaranteed to contain the true risk minimizer.
The critical decision at each epoch is how to select a subset of unlabelled examples whose labels
should be queried. We make this decision using a conﬁdence-rated predictor P . At epoch k  we run
P with candidate hypothesis set V = Vk and error guarantee η = �k/64. Whenever P abstains  we
query the label of the example. The number of labels mk queried is adjusted so that it is enough to
achieve excess generalization error �k+1.
An outline is described in Algorithm 1; we next discuss each individual component in detail.

conﬁdence-rated predictor P   target excess error � and target conﬁdence δ.

Algorithm 1 Active Learning Algorithm: Outline
1: Inputs: Example oracle U  Labelling oracle O  hypothesis class H of VC dimension d 
2: Set k0 = �log 1/��. Initialize candidate set V1 = H.
3: for k = 1  2  ..k0 do
4:
5:

Set �k = �2k0−k+1  δk =
Call U to generate a fresh unlabelled sample Uk = {zk 1  ...  zk nk} of size nk =
192( 512
�k
Run conﬁdence-rated predictor P with inpuy V = Vk  U = Uk and error guarantee
η = �k/64 to get abstention probabilities γk 1  . . .   γk nk on the examples in Uk. These
probabilities induce a distribution Γk on Uk. Let φk = Px∼Uk (P (x) = 0) = 1
i=1 γk i.
if in the Realizable Case then

2(k0−k+1)2 .
).
)2 + ln 288
δk

)2(d ln 192( 512
�k

δ

nk�nk

�k

�k

+ ln 48
δk

(d ln 1536φk

Let mk = 1536φk
). Draw mk i.i.d examples from Γk and query
O for labels of these examples to get a labelled data set Sk. Update Vk+1 using Sk:
Vk+1 := {h ∈ Vk : h(x) = y  for all (x  y) ∈ Sk}.
In the non-realizable case  use Algorithm 2 with inputs hypothesis set Vk  distribution
Γk  target excess error �k
2   and the labeling oracle O to get a new
8φk
hypothesis set Vk+1.

  target conﬁdence δk

6:

7:
8:

9:
10:

else

11: return an arbitrary ˆh ∈ Vk0+1.

Candidate Sets. At epoch k  we maintain a set Vk of candidate hypotheses guaranteed to contain
the true risk minimizer h∗(D) (w.h.p). In the realizable case  we use a version space as our candidate
set. The version space with respect to a set S of labelled examples is the set of all h ∈ H such that
h(xi) = yi for all (xi  yi) ∈ S.
Lemma 1. Suppose we run Algorithm 1 in the realizable case with inputs example oracle U  la-
belling oracle O  hypothesis class H  conﬁdence-rated predictor P   target excess error � and target
conﬁdence δ. Then  with probability 1  h∗(D) ∈ Vk  for all k = 1  2  . . .   k0 + 1.
In the non-realizable case  the version space is usually empty; we use instead a (1 − α)-conﬁdence
set for the true risk minimizer. Given a set S of n labelled examples  let C(S) ⊆ H be a function of

1where the expectation is with respect to the random choices made by P

3

S; C(S) is said to be a (1 − α)-conﬁdence set for the true risk minimizer if for all data distributions
Δ over X × Y 
PS∼Δn [h∗(Δ) ∈ C(S)] ≥ 1 − α 
Recall that h∗(Δ) = argminh∈H
errΔ(h). In the non-realizable case  our candidate sets are (1 − α)-
conﬁdence sets for h∗(D)  for α = δ. The precise setting of Vk is explained in Algorithm 2.
Lemma 2. Suppose we run Algorithm 1 in the non-realizable case with inputs example oracle U 
labelling oracle O  hypothesis class H  conﬁdence-rated predictor P   target excess error � and
target conﬁdence δ. Then with probability 1 − δ  h∗(D) ∈ Vk  for all k = 1  2  . . .   k0 + 1.
Label Query. We next discuss our label query procedure – which examples should we query labels
for  and how many labels should we query at each epoch?

Which Labels to Query? Our goal is to query the labels of the most informative examples. To
choose these examples while still maintaining consistency  we use a conﬁdence-rated predictor P
with guaranteed error. The inputs to the predictor are our candidate hypothesis set Vk which contains
(w.h.p) the true risk minimizer  a fresh set Uk of unlabelled examples  and an error guarantee η =
�k/64. For notation simplicity  assume the elements in Uk are distinct. The output is a sequence of
abstention probabilities {γk 1  γk 2  . . .   γk nk}  for each example in Uk. It induces a distribution Γk
over Uk  from which we independently draw examples for label queries.

(d ln 1536φk

�k

+ ln 48
δk

�k

How Many Labels to Query? The goal of epoch k is to achieve excess generalization error �k.
To achieve this  passive learning requires ˜O(d/�k) labelled examples2 in the realizable case  and
˜O(d(ν∗(D) + �k)/�2
k) examples in the agnostic case. A key observation in this paper is that in
order to achieve excess generalization error �k on D  it sufﬁces to achieve a much larger excess
generalization error O(�k/φk) on the data distribution induced by Γk and DY |X  where φk is the
fraction of examples on which the conﬁdence-rated predictor abstains.
In the realizable case  we achieve this by sampling mk = 1536φk
) i.i.d examples
from Γk  and querying their labels to get a labelled dataset Sk. Observe that as φk is the abstention
probability of P with guaranteed error ≤ �k/64  it is generally smaller than the measure of the
disagreement region of the version space; this key fact results in improved label complexity over
disagreement-based active learning. This sampling procedure has the following property:
Lemma 3. Suppose we run Algorithm 1 in the realizable case with inputs example oracle U  la-
belling oracle O  hypothesis class H  conﬁdence-rated predictor P   target excess error � and target
conﬁdence δ. Then with probability 1 − δ  for all k = 1  2  . . .   k0 + 1  and for all h ∈ Vk 
errD(h) ≤ �k. In particular  the ˆh returned at the end of the algorithm satisﬁes errD(ˆh) ≤ �.
The agnostic case has an added complication – in practice  the value of ν∗ is not known ahead of
time. Inspired by [24]  we use a doubling procedure(stated in Algorithm 2) which adaptively ﬁnds
the number mk of labelled examples to be queried and queries them. The following two lemmas
illustrate its properties – that it is consistent  and that it does not use too many label queries.
Lemma 4. Suppose we run Algorithm 2 with inputs hypothesis set V   example distribution Δ 
labelling oracle O  target excess error ˜� and target conﬁdence ˜δ. Let ˜Δ be the joint distribution on
X × Y induced by Δ and DY |X. Then there exists an event ˜E  P( ˜E) ≥ 1 − ˜δ  such that on ˜E  (1)
Algorithm 2 halts and (2) the set Vj0 has the following properties:
(2.1) If for h ∈ H  err ˜Δ(h) − err ˜Δ(h∗( ˜Δ)) ≤ ˜�/2  then h ∈ Vj0.
(2.2) On the other hand  if h ∈ Vj0  then err ˜Δ(h) − err ˜Δ(h∗( ˜Δ)) ≤ ˜�.
When event ˜E happens  we say Algorithm 2 succeeds.
Lemma 5. Suppose we run Algorithm 2 with inputs hypothesis set V   example distribution Δ 
labelling oracle O  target excess error ˜� and target conﬁdence ˜δ. There exists some absolute constant
c1 > 0  such that on the event that Algorithm 2 succeeds  nj0 ≤ c1((d ln 1
). Thus
the total number of labels queried is�j0
˜� + ln 1
˜δ

j=1 nj ≤ 2nj0 ≤ 2c1((d ln 1

˜� + ln 1
˜δ
) ν∗( ˜Δ)+˜�

) ν∗( ˜Δ)+˜�

˜�2

).

˜�2

2 ˜O(·) hides logarithmic factors

4

A naive approach (see Algorithm 4 in the Appendix) which uses an additive VC bound gives a
sample complexity of O((d ln(1/˜�) + ln(1/˜δ))˜�−2); Algorithm 2 gives a better sample complexity.
The following lemma is a consequence of our label query procedure in the non-realizable case.
Lemma 6. Suppose we run Algorithm 1 in the non-realizable case with inputs example oracle U 
labelling oracle O  hypothesis class H  conﬁdence-rated predictor P   target excess error � and
target conﬁdence δ. Then with probability 1 − δ  for all k = 1  2  . . .   k0 + 1  and for all h ∈ Vk 
errD(h) ≤ errD(h∗(D)) + �k. In particular  the ˆh returned at the end of the algorithm satisﬁes
errD(ˆh) ≤ errD(h∗(D)) + �.
Algorithm 2 An Adaptive Algorithm for Label Query Given Target Excess Error
1: Inputs: Hypothesis set V of VC dimension d  Example distribution Δ  Labeling oracle O 
2: for j = 1  2  . . . do
3:

target excess error ˜�  target conﬁdence ˜δ.

Draw nj = 2j i.i.d examples from Δ; query their labels from O to get a labelled dataset
Sj. Denote ˜δj := ˜δ/(j(j + 1)).
Train an ERM classiﬁer ˆhj ∈ V over Sj.
Deﬁne the set Vj as follows:
Vj =�h ∈ V : errSj (h) ≤ errSj (ˆhj) +
if suph∈Vj (σ(nj  ˜δj) +�σ(nj  ˜δj)ρSj (h  ˆhj)) ≤ ˜�

+ σ(nj  ˜δj) +�σ(nj  ˜δj)ρSj (h  ˆhj)�

Where σ(n  δ) := 16

j0 = j  break

6 then

˜�
2

n (2d ln 2en

d + ln 24

δ ).

4:
5:

6:
7:
8: return Vj0.

2.3 Conﬁdence-Rated Predictor

Our active learning algorithm uses a conﬁdence-rated predictor with guaranteed error to make its
label query decisions. In this section  we provide a novel conﬁdence-rated predictor with guaranteed
error. This predictor has optimal coverage in the realizable case  and may be of independent interest.
The predictor P receives as input a set V ⊆ H of hypotheses (which is likely to contain the true
risk minimizer)  an error guarantee η  and a set of U of unlabelled examples. We consider a soft
prediction algorithm; so  for each example in U  the predictor P outputs three probabilities that add
up to 1 – the probability of predicting 1  −1 and 0. This output is subject to the constraint that the
expected disagreement3 between the ±1 labels assigned by P and those assigned by any h ∈ V is
at most η  and the goal is to maximize the coverage  or the expected fraction of non-abstentions.
Our key insight is that this problem can be written as a linear program  which is described in Algo-
rithm 3. There are three variables  ξi  ζi and γi  for each unlabelled zi ∈ U; there are the probabil-
ities with which we predict 1  −1 and 0 on zi respectively. Constraint (2) ensures that the expected
disagreement between the label predicted and any h ∈ V is no more than η  while the LP objective
maximizes the coverage under these constraints. Observe that the LP is always feasible. Although
the LP has inﬁnitely many constraints  the number of constraints in Equation (2) distinguishable by
Uk is at most (em/d)d  where d is the VC dimension of the hypothesis class H.
The performance of a conﬁdence-rated predictor is measured by its error and coverage. The error of
a conﬁdence-rated predictor is the probability with which it predicts the wrong label on an example 
while the coverage is its probability of non-abstention. We can show the following guarantee on the
performance of the predictor in Algorithm 3.
Theorem 1. In the realizable case  if the hypothesis set V is the version space with respect to
a training set  then Px∼U (P (x) �= h∗(x)  P (x) �= 0) ≤ η.
In the non-realizable case  if the
hypothesis set V is an (1 − α)-conﬁdence set for the true risk minimizer h∗  then  w.p ≥ 1 − α 
Px∼U (P (x) �= y  P (x) �= 0) ≤ Px∼U (h∗(x) �= y) + η.

3where the expectation is taken over the random choices made by P

5

Algorithm 3 Conﬁdence-rated Predictor
1: Inputs: hypothesis set V   unlabelled data U = {z1  . . .   zm}  error bound η.
2: Solve the linear program:

subject to: ∀i  ξi + ζi + γi = 1

γi

min

m�i=1
∀h ∈ V  �i:h(zi)=1

∀i  ξi  ζi  γi ≥ 0

ζi + �i:h(zi)=−1

ξi ≤ ηm

(2)

3: For each zi ∈ U  output probabilities for predicting 1  −1 and 0: ξi  ζi  and γi.

In the realizable case  we can also show that our conﬁdence rated predictor has optimal coverage.
Observe that we cannot directly show optimality in the non-realizable case  as the performance
depends on the exact choice of the (1 − α)-conﬁdence set.
Theorem 2. In the realizable case  suppose that the hypothesis set V is the version space with
respect to a training set. If P � is any conﬁdence rated predictor with error guarantee η  and if P is
the predictor in Algorithm 3  then  the coverage of P is at least much as the coverage of P �.

3 Performance Guarantees

An essential property of any active learning algorithm is consistency – that it converges to the true
risk minimizer given enough labelled examples. We observe that our algorithm is consistent pro-
vided we use any conﬁdence-rated predictor P with guaranteed error as a subroutine. The consis-
tency of our algorithm is a consequence of Lemmas 3 and 6 and is shown in Theorem 3.
Theorem 3 (Consistency). Suppose we run Algorithm 1 with inputs example oracle U  labelling
oracle O  hypothesis class H  conﬁdence-rated predictor P   target excess error � and target
conﬁdence δ. Then with probability 1 − δ  the classiﬁer ˆh returned by Algorithm 1 satisﬁes
errD(ˆh) − errD(h∗(D)) ≤ �.
We now establish a label complexity bound for our algorithm; however  this label complexity bound
applies only if we use the predictor described in Algorithm 3 as a subroutine.
For any hypothesis set V   data distribution D  and η  deﬁne ΦD(V  η) to be the minimum absten-
tion probability of a conﬁdence-rated predictor which guarantees that the disagreement between its
predicted labels and any h ∈ V under DX is at most η.
Formally  ΦD(V  η) = min{EDγ(x) : ED[I(h(x) = +1)ζ(x) + I(h(x) = −1)ξ(x)] ≤
η for all h ∈ V  γ(x) + ξ(x) + ζ(x) ≡ 1  γ(x)  ξ(x)  ζ(x) ≥ 0}. Deﬁne φ(r  η)
:=
ΦD(BD(h∗  r)  η). The label complexity of our active learning algorithm can be stated as follows.
Theorem 4 (Label Complexity). Suppose we run Algorithm 1 with inputs example oracle U  la-
belling oracle O  hypothesis class H  conﬁdence-rated predictor P of Algorithm 3  target excess
error � and target conﬁdence δ. Then there exist constants c3  c4 > 0 such that with probability
1 − δ:
(1) In the realizable case  the total number of labels queried by Algorithm 1 is at most:

c3

�log 1

� ��k=1

(d ln

φ(�k  �k/256)

�k

+ ln(�log(1/�)� − k + 1

δ

))

φ(�k  �k/256)

�k

(2) In the agnostic case  the total number of labels queried by Algorithm 1 is at most:

c4

�log 1

� ��k=1

(d ln

φ(2ν∗(D) + �k  �k/256)

�k

+ln(�log(1/�)� − k + 1

δ

))

φ(2ν∗(D) + �k  �k/256)

�k

(1+

ν∗(D)

�k

)

6

Comparison. The label complexity of disagreement-based active learning is characterized in
terms of the disagreement coefﬁcient. Given a radius r  the disagreement coefﬁcent θ(r) is deﬁned
as:

θ(r) = sup
r�≥r

P(DIS(BD(h∗  r�)))

 

r�

φ(r� 0)

where for any V ⊆ H  DIS(V ) is the disagreement region of V . As P(DIS(BD(h∗  r))) =
φ(r  0) [13]  in our notation  θ(r) = supr�≥r
In the realizable case  the best known bound for label complexity of disagreement-based active
learning is ˜O(θ(�) · ln(1/�) · (d ln θ(�) + ln ln(1/�))) [20]4. Our label complexity bound may be
simpliﬁed to:
���  
˜O�ln

·�d ln� sup

� + ln ln

φ(�k  �k/256)

φ(�k  �k/256)

1
� ·

sup

�k

�k

.

r�

1

k≤�log(1/�)�

k≤�log(1/�)�

. As en-
which is essentially the bound of [20] with θ(�) replaced by supk≤�log(1/�)�
forcing a lower error guarantee requires more abstention  φ(r  η) is a decreasing function of η; as a
result 

�k

φ(�k �k/256)

sup

k≤�log(1/�)�

φ(�k  �k/256)

�k

≤ θ(�) 

and our label complexity bound is better.
In the agnostic case  [12] provides a label complexity bound of ˜O(θ(2ν∗(D)+�)·(d ν∗(D)2
ln(1/�)+
d ln2(1/�))) for disagreement-based active-learning. In contrast  by Proposition 1 our label com-
plexity is at most:
ln(1/�) + d ln2(1/�)��

˜O� sup

φ(2ν∗(D) + �k  �k/256)

·�d

2ν∗(D) + �k

k≤�log(1/�)�

ν∗(D)2

�2

�2

Again  this is essentially the bound of [12] with θ(2ν∗(D) + �) replaced by the smaller quantity

sup

k≤�log(1/�)�

φ(2ν∗(D) + �k  �k/256)

2ν∗(D) + �k

 

[20] has provided a more reﬁned analysis of disagreement-based active learning that gives a label
complexity of ˜O(θ(ν∗(D) + �)( ν∗(D)2
� )); observe that their
dependence is still on θ(ν∗(D) + �). We leave a more reﬁned label complexity analysis of our
algorithm for future work.
An important sub-case of learning from noisy data is learning under the Tsybakov noise condi-
tions [30]. We defer the discussion into the Appendix.

� )(d ln θ(ν∗(D) + �) + ln ln 1

�2 + ln 1

3.1 Case Study: Linear Classiﬁcation under the Log-concave Distribution

We now consider learning linear classiﬁers with respect to log-concave data distribution on Rd. In

this case  for any r  the disagreement coefﬁcient θ(r) ≤ O(√d ln(1/r)) [4]; however  for any η > 0 
φ(r η)
r ≤ O(ln(r/η)) (see Lemma 14 in the Appendix)  which is much smaller so long as η/r is not
too small. This leads to the following label complexity bounds.
Corollary 1. Suppose DX is isotropic and log-concave on Rd  and H is the set of homogeneous lin-
ear classiﬁers on Rd. Then Algorithm 1 with inputs example oracle U  labelling oracle O  hypothesis
class H  conﬁdence-rated predictor P of Algorithm 3  target excess error � and target conﬁdence δ
satisﬁes the following properties. With probability 1 − δ:
(1) In the realizable case  there exists some absolute constant c8 > 0 such that the total number of
labels queried is at most c8 ln 1

δ ).
4Here the ˜O(·) notation hides factors logarithmic in 1/δ

� (d + ln ln 1

� + ln 1

7

2

κ−2 ln 1

3

2 ln2 1

�

�

+ ln 1

δ ) + ln 1

�2 + ln 1

(d ln �+ν∗(D)

� ln �+ν∗(D)

�

� (d ln 1

� + ln 1

� (ln d + ln ln 1

� ) ln �+ν∗(D)

(2) In the agnostic case  there exists some absolute constant c9 > 0 such that the total number of la-
bels queried is at most c9( ν∗(D)2
� .
ln ln 1
(3) If (C0  κ)-Tsybakov Noise condition holds for D with respect to H  then there exists some
constant c10 > 0 (that depends on C0  κ) such that the total number of labels queried is at most
c10�

δ ).
In the realizable case  our bound matches [4]. For disagreement-based algorithms  the bound is
� ))  which is worse by a factor of O(√d ln(1/�)). [4] does not address the
˜O(d
fully agnostic case directly; however  if ν∗(D) is known a-priori  then their algorithm can achieve
roughly the same label complexity as ours.
For the Tsybakov Noise Condition with κ > 1  [3  4] provides a label complexity bound for
˜O(�
� )) with an algorithm that has a-priori knowledge of C0 and κ. We get
a slightly better bound. On the other hand  a disagreement based algorithm [20] gives a label
� )). Again our bound is better by factor of Ω(√d)
complexity of ˜O(d
over disagreement-based algorithms. For κ = 1  we can tighten our label complexity to get a
˜O(ln 1
δ )) bound  which again matches [4]  and is better than the ones provided by
disagreement-based algorithm – ˜O(d

κ−2(ln d + ln ln 1

� (d + ln ln 1

� + ln 1

� (d + ln ln 1

2

κ−2 ln2 1

3

2 ln2 1
� �

2

3

2 ln2 1

� (ln d + ln ln 1

� )) [20].

4 Related Work
Active learning has seen a lot of progress over the past two decades  motivated by vast amounts of
unlabelled data and the high cost of annotation [28  10  20]. According to [10]  the two main threads
of research are exploitation of cluster structure [31  11]  and efﬁcient search in hypothesis space 
which is the setting of our work. We are given a hypothesis class H  and the goal is to ﬁnd an h ∈ H
that achieves a target excess generalization error  while minimizing the number of label queries.
Three main approaches have been studied in this setting. The ﬁrst and most natural one is generalized
binary search [17  8  9  27]  which was analyzed in the realizable case by [9] and in various limited
noise settings by [23  27  26]. While this approach has the advantage of low label complexity  it is
generally inconsistent in the fully agnostic setting [11]. The second approach  disagreement-based
active learning  is consistent in the agnostic PAC model. [7] provides the ﬁrst disagreement-based
algorithm for the realizable case. [2] provides an agnostic disagreement-based algorithm  which
is analyzed in [18] using the notion of disagreement coefﬁcient. [12] reduces disagreement-based
active learning to passive learning; [5] and [6] further extend this work to provide practical and efﬁ-
cient implementations. [19  24] give algorithms that are adaptive to the Tsybakov Noise condition.
The third line of work [3  4  1]  achieves a better label complexity than disagreement-based active
learning for linear classiﬁers on the uniform distribution over unit sphere and logconcave distribu-
tions. However  a limitation is that their algorithm applies only to these speciﬁc settings  and it is
not apparent how to apply it generally.
Research on conﬁdence-rated prediction has been mostly focused on empirical work  with relatively
less theoretical development. Theoretical work on this topic includes KWIK learning [25]  confor-
mal prediction [29] and the weighted majority algorithm of [16]. The closest to our work is the recent
learning-theoretic treatment by [13  14]. [13] addresses conﬁdence-rated prediction with guaranteed
error in the realizable case  and provides a predictor that abstains in the disagreement region of the
version space. This predictor achieves zero error  and coverage equal to the measure of the agree-
ment region. [14] shows how to extend this algorithm to the non-realizable case and obtain zero
error with respect to the best hypothesis in H. Note that the predictors in [13  14] generally achieve
less coverage than ours for the same error guarantee; in fact  if we plug them into our Algorithm 1 
then we recover the label complexity bounds of disagreement-based algorithms [12  19  24].
A formal connection between disagreement-based active learning in realizable case and perfect
conﬁdence-rated prediction (with a zero error guarantee) was established by [15]. Our work can
be seen as a step towards bridging these two areas  by demonstrating that active learning can be
further reduced to imperfect conﬁdence-rated prediction  with potentially higher label savings.

Acknowledgements. We thank NSF under IIS-1162581 for research support. We thank Sanjoy
Dasgupta and Yoav Freund for helpful discussions. CZ would like to thank Liwei Wang for intro-
ducing the problem of selective classiﬁcation to him.

8

References
[1] P. Awasthi  M-F. Balcan  and P. M. Long. The power of localization for efﬁciently learning

linear separators with noise. In STOC  2014.

[2] M.-F. Balcan  A. Beygelzimer  and J. Langford. Agnostic active learning. J. Comput. Syst.

Sci.  75(1):78–89  2009.

[3] M.-F. Balcan  A. Z. Broder  and T. Zhang. Margin based active learning. In COLT  2007.
[4] M.-F. Balcan and P. M. Long. Active and passive learning of linear separators under log-

concave distributions. In COLT  2013.

[5] A. Beygelzimer  S. Dasgupta  and J. Langford. Importance weighted active learning. In ICML 

2009.

[6] A. Beygelzimer  D. Hsu  J. Langford  and T. Zhang. Agnostic active learning without con-

straints. In NIPS  2010.

[7] D. A. Cohn  L. E. Atlas  and R. E. Ladner.

Machine Learning  15(2)  1994.

Improving generalization with active learning.

[8] S. Dasgupta. Analysis of a greedy active learning strategy. In NIPS  2004.
[9] S. Dasgupta. Coarse sample complexity bounds for active learning. In NIPS  2005.
[10] S. Dasgupta. Two faces of active learning. Theor. Comput. Sci.  412(19)  2011.
[11] S. Dasgupta and D. Hsu. Hierarchical sampling for active learning. In ICML  2008.
[12] S. Dasgupta  D. Hsu  and C. Monteleoni. A general agnostic active learning algorithm. In

NIPS  2007.

[13] R. El-Yaniv and Y. Wiener. On the foundations of noise-free selective classiﬁcation. JMLR 

2010.

[14] R. El-Yaniv and Y. Wiener. Agnostic selective classiﬁcation. In NIPS  2011.
[15] R. El-Yaniv and Y. Wiener. Active learning via perfect selective classiﬁcation. JMLR  2012.
[16] Y. Freund  Y. Mansour  and R. E. Schapire. Generalization bounds for averaged classiﬁers.

The Ann. of Stat.  32  2004.

[17] Y. Freund  H. S. Seung  E. Shamir  and N. Tishby. Selective sampling using the query by

committee algorithm. Machine Learning  28(2-3):133–168  1997.

[18] S. Hanneke. A bound on the label complexity of agnostic active learning. In ICML  2007.
[19] S. Hanneke. Adaptive rates of convergence in active learning. In COLT  2009.
[20] S. Hanneke. A statistical theory of active learning. Manuscript  2013.
[21] S. Hanneke and L. Yang. Surrogate losses in passive and active learning. CoRR  abs/1207.3772 

2012.

[22] D. Hsu. Algorithms for Active Learning. PhD thesis  UC San Diego  2010.
[23] M. K¨a¨ari¨ainen. Active learning in the non-realizable case. In ALT  2006.
[24] V. Koltchinskii. Rademacher complexities and bounding the excess risk in active learning.

JMLR  2010.

[25] L. Li  M. L. Littman  and T. J. Walsh. Knows what it knows: a framework for self-aware

learning. In ICML  2008.

[26] M. Naghshvar  T. Javidi  and K. Chaudhuri. Noisy bayesian active learning. In Allerton  2013.
[27] R. D. Nowak. The geometry of generalized binary search. IEEE Transactions on Information

Theory  57(12):7893–7906  2011.

[28] B. Settles. Active learning literature survey. Technical report  University of Wisconsin-

Madison  2010.

[29] G. Shafer and V. Vovk. A tutorial on conformal prediction. JMLR  2008.
[30] A. B. Tsybakov. Optimal aggregation of classiﬁers in statistical learning. Annals of Statistics 

32:135–166  2004.

[31] R. Urner  S. Wulff  and S. Ben-David. Plal: Cluster-based active learning. In COLT  2013.

9

,Chicheng Zhang
Kamalika Chaudhuri