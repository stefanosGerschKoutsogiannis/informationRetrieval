2010,More data means less inference: A pseudo-max approach to structured learning,The problem of learning to predict structured labels is of key importance in many applications. However  for general graph structure both learning and inference in this setting are intractable. Here we show that it is possible to circumvent this difficulty when the input distribution is rich enough via a method similar in spirit to pseudo-likelihood. We show how our new method achieves consistency  and illustrate empirically that it indeed performs as well as exact methods when sufficiently large training sets are used.,More data means less inference: A pseudo-max

approach to structured learning

David Sontag

Microsoft Research

Ofer Meshi

Hebrew University

Tommi Jaakkola

CSAIL  MIT

Amir Globerson
Hebrew University

Abstract

The problem of learning to predict structured labels is of key importance in many
applications. However  for general graph structure both learning and inference are
intractable. Here we show that it is possible to circumvent this difﬁculty when
the distribution of training examples is rich enough  via a method similar in spirit
to pseudo-likelihood. We show that our new method achieves consistency  and
illustrate empirically that it indeed approaches the performance of exact methods
when sufﬁciently large training sets are used.

Many prediction problems in machine learning applications are structured prediction tasks. For
example  in protein folding we are given a protein sequence and the goal is to predict the protein’s
native structure [14]. In parsing for natural language processing  we are given a sentence and the goal
is to predict the most likely parse tree [2]. In these and many other applications  we can formalize the
structured prediction problem as taking an input x (e.g.  primary sequence  sentence) and predicting
y (e.g.  structure  parse) according to y = arg maxˆy∈Y θ · φ(x  ˆy)  where φ(x  y) is a function that
maps any input and a candidate assignment to a feature vector  Y denotes the space of all possible
assignments to the vector y  and θ is a weight vector to be learned.
This paper addresses the problem of learning structured prediction models from data. In particular 
given a set of labeled examples {(xm  ym)}M
m=1  our goal is to ﬁnd a vector θ such that for each
example m  ym = arg maxy∈Y θ · φ(xm  y)  i.e. one which separates the training data. For many
structured prediction models  maximization over Y is computationally intractable. This makes it
difﬁcult to apply previous algorithms for learning structured prediction models  such as structured
perceptron [2]  stochastic subgradient [10]  and cutting-plane algorithms [5]  which require making
a prediction at every iteration (equivalent to repeatedly solving an integer linear program).
Given training data  we can consider the space of parameters Θ that separate the data. This space can
be deﬁned by the intersection of a large number of linear inequalities. A recent approach to getting
around the hardness of prediction is to use linear programming (LP) relaxations to approximate the
maximization over Y [4  6  9]. However  separation with respect to a relaxation places stronger
constraints on the parameters. The target solution  an integral vertex in the LP  must now distinguish
itself also from possible fractional vertexes that arise due to the relaxation. The relaxations can
therefore be understood as optimizing over an inner bound of Θ. This set may be empty even if
the training data is separable with exact inference [6]. Another obstacle to using LP relaxations for
learning is that solving the LPs can be very slow.
In this paper we ask whether it is possible to learn while avoiding inference altogether. We propose
a new learning algorithm  inspired by pseudo-likelihood [1]  that optimizes over an outer bound of
Θ. Learning involves optimizing over only a small number of constraints per data point  and thus
can be performed quickly  even for complex structured prediction models. We show that  if the data
it will ﬁnd some θ ∈ Θ. This
available for learning is “nice”  this algorithm is consistent  i.e.
is an example of how having the right data can circumvent the hardness of learning for structured
prediction.

1

We also investigate the limitations of the proposed method. We show that the problem of even
deciding whether a given data set is separable is NP-hard  and thus learning in a strict sense is no
easier than prediction. Thus  we should not expect for our algorithm  or any other polynomial time
algorithm  to always succeed at learning from an arbitrary ﬁnite data set. To our knowledge  this is
the ﬁrst result characterizing the hardness of exact learning for structured prediction.
Finally  we show empirically that our algorithm allows us to successfully learn the parameters for
both multi-label prediction and protein side-chain placement. The performance of the algorithm is
improved as more data becomes available  as our theoretical results anticipate.

1 Pseudo-Max method
We consider the general structured prediction problem. The input space is denoted by X and the set
of all possible assignments by Y. Each y ∈ Y corresponds to n variables y1  . . .   yn  each with k
possible states. The classiﬁer uses a (given) function φ(x  y) : X  Y → Rd and (learned) weights
θ ∈ Rd  and is deﬁned as y(x; θ) = arg maxˆy∈Y f(ˆy; x  θ) where f is the discriminant function
f(y; x  θ) = θ · φ(x  y). Our analysis will focus on functions φ whose scope is limited to small
sets of the yi variables  but for now we keep the discussion general.
set of separating weight vectors  Θ =(cid:8)θ | ∀m  y ∈ Y  f(ym; xm  θ) ≥ f(y; xm  θ)+e(y  ym)(cid:9).
Given a set of labeled examples {(xm  ym)}M
m=1  the goal of the typical learning problem is to ﬁnd
weights θ that correctly classify the training examples. Consider ﬁrst the separable case. Deﬁne the

e is a loss function (e.g.  zero-one or Hamming) such that e(ym  ym) = 0 and e(y  ym) > 0
for y (cid:54)= ym  which serves to rule out the trivial solution θ = 0.1 The space Θ is deﬁned by
exponentially many constraints per example  one for each competing assignment.
In this work we consider a much simpler set of constraints where  for each example  we only consider
the competing assignments obtained by modifying a single label yi  while ﬁxing the other labels to
their value at ym. The pseudo-max set  which is an outer bound on Θ  is given by
−i  yi; xm  θ) + e(yi  ym

Θps =(cid:8)θ | ∀m  i  yi  f(ym; xm  θ) ≥ f(ym

i )(cid:9).

(1)

−i denotes the label ym without the assignment to yi.

Here ym
When the data is not separable  Θ will be the empty set. Instead  we may choose to minimize the

(cid:2)f(y; xm  θ) − f(ym; xm  θ) + e(y  ym)(cid:3)  which can be shown to

hinge loss  (cid:96)(θ) =(cid:80)

be an upper bound on the training error [13]. When the data is separable  minθ (cid:96)(θ) = 0. Note that
regularization may be added to this objective.
The corresponding pseudo-max objective replaces the maximization over all of y with maximization
over a single variable yi while ﬁxing the other labels to their value at ym:2 3

m maxy

M(cid:88)

n(cid:88)

m=1

i=1

(cid:2)f(ym
i )(cid:3) .
−i  yi; xm  θ) − f(ym; xm  θ) + e(yi  ym

max
yi

(cid:96)ps(θ) =

(2)

Analogous to before  we have minθ (cid:96)ps(θ) = 0 if and only if θ ∈ Θps.
The objective in Eq. 2 is similar in spirit to pseudo-likelihood objectives used for maximum likeli-
hood estimation of parameters of Markov random ﬁelds (MRFs) [1]. The pseudo-likelihood estimate
is provably consistent when the data generating distribution is a MRF of the same structure as used
in the pseudo-likelihood objective. However  our setting is different since we only get to view the
maximizing assignment of the MRF rather than samples from it. Thus  a particular x will always be
paired with the same y rather than samples y drawn from the conditional distribution p(y|x; θ).
The pseudo-max constraints in Eq. 1 are also related to cutting plane approaches to inference [4  5].
In the latter  the learning problem is solved by repeatedly looking for assignments that violate the
separability constraint (or its hinge version). Our constraints can be viewed as using a very small

1An alternative formulation  which we use in the next section  is to break the symmetry by having part of

the input not be multiplied by any weight. This will also rule out the trivial solution θ = 0.

2It is possible to use maxi instead ofP

i  and some of our consistency results will still hold.

3The pseudo-max approach is markedly different from a learning method which predicts each label yi

independently  since the objective considers all i simultaneously (both at learning and test time).

2

Figure 1: Illustrations for a model with two variables. Left: Partitioning of X induced by conﬁgurations y(x)
for some J∗ > 0. Blue lines carve out the exact regions. Red lines denote the pseudo-max constraints that
hold with equality. Pseudo-max does not obtain the diagonal constraint coming from comparing conﬁgurations
y = (1  1) and (0  0)  since these differ by more than one coordinate. Right: One strictly-convex component
of the (cid:96)ps(J ) function (see Eq. 9). The function is shown for different values of c1  the mean of the x1 variable.

subset of assignments for the set of candidate constraint violators. We also note that when exact
maximization over the discriminant function f(y; x  θ) is hard  the standard cutting plane algorithm
cannot be employed since it is infeasible to ﬁnd a violated constraint. For the pseudo-max objective 
ﬁnding a constraint violation is simple and linear in the number of variables.4
It is easy to see (as will be elaborated on next) that the pseudo-max method does not in general yield
a consistent estimate of θ  even in the separable case. However  as we show  consistency can be
shown to be achieved under particular assumptions on the data generating distribution p(x).

2 Consistency of the Pseudo-Max method

In this section we show that if the feature generating distribution p(x) satisﬁes particular assump-
tions  then the pseudo-max approach yields a consistent estimate. In other words  if the training
data is of the form {(xm  y(xm; θ∗))}M
m=1 for some true parameter vector θ∗  then as M → ∞ the
minimum of the pseudo-max objective will converge to θ∗ (up to equivalence transformations).
The section is organized as follows. First  we provide intuition for the consistency results by con-
sidering a model with only two variables. Then  in Sec. 2.1  we show that any parameter θ∗ can
be identiﬁed to within arbitrary accuracy by choosing a particular training set (i.e.  choice of xm).
This in itself proves consistency  as long as there is a non-zero probability of sampling this set. In
Sec. 2.2 we give a more direct proof of consistency by using strict convexity arguments.
For ease of presentation  we shall work with a simpliﬁed instance of the structured learning setting.
We focus on binary variables  yi ∈ {0  1}  and consider discriminant functions corresponding to
Ising models  a special case of pairwise MRFs (J denotes the vector of “interaction” parameters):

f(y; x  J) =(cid:80)

ij∈E Jijyiyj +(cid:80)

i yixi

(3)

The singleton potential for variable yi is yixi and is not dependent on the model parameters. We
could have instead used Jiyixi  which would be more standard. However  this would make the
parameter vector J invariant to scaling  complicating the identiﬁability analysis. In the consistency
analysis we will assume that the data is generated using a true parameter vector J∗. We will show
that as the data size goes to inﬁnity  minimization of (cid:96)ps(J) yields J∗.
We begin with an illustrative analysis of the pseudo-max constraints for a model with only two vari-
ables  i.e. f(y; x  J) = Jy1y2 + y1x1 + y2x2. The purpose of the analysis is to demonstrate general
principles for when pseudo-max constraints may succeed or fail. Assume that training samples are
generated via y(x) = argmaxy f(y; x  J∗). We can partition the input space X into four regions 
{x ∈ X : y(x) = ˆy} for each of the four conﬁgurations ˆy  shown in Fig. 1 (left). The blue lines
outline the exact decision boundaries of f(y; x  J∗)  with the lines being given by the constraints

4The methods differ substantially in the non-separable setting where we minimize (cid:96)ps(θ)  using a slack

variable for every node and example  rather than just one slack variable per example as in (cid:96)(θ).

3

x2x1J∗+x1+x2=0J∗+x2=0J∗+x1=0x1=0x2=0y=(0 0)y=(1 0)y=(0 1)y=(1 1)(cid:239)1(cid:239)0.500.5100.050.10.150.2Jg(J12)  c1=0c1=1c1=(cid:239)1in Θ that hold with equality. The red lines denote the pseudo-max constraints in Θps that hold with
equality. For x such that y(x) = (1  0) or (0  1)  the pseudo-max and exact constraints are identical.
We can identify J∗ by obtaining samples x = (x1  x2) that explore both sides of one of the decision
boundaries that depends on J∗. The pseudo-max constraints will fail to identify J∗ if the samples
do not sufﬁciently explore the transitions between y = (0  1) and y = (1  1) or between y = (1  0)
and y = (1  1). This can happen  for example  when the input samples are dependent  giving only
rise to the conﬁgurations y = (0  0) and y = (1  1). For points labeled (1  1) around the decision
line J∗ + x1 + x2 = 0  pseudo-max can only tell that they respect J∗ + x1 ≥ 0 and J∗ + x2 ≥ 0
(dashed red lines)  or x1 ≤ 0 and x2 ≤ 0 for points labeled (0  0).
Only constraints that depend on the parameter are effective for learning. For pseudo-max to be able
to identify J∗  the input samples must be continuous  densely populating the two parameter depen-
dent decision lines that pseudo-max can use. The two point sets in the ﬁgure illustrate good and bad
input distributions for pseudo-max. The diagonal set would work well with the exact constraints but
badly with pseudo-max  and the difference can be arbitrarily large. However  the input distribution
on the right  populating the J∗ + x2 = 0 decision line  would permit pseudo-max to identify J∗.

2.1

Identiﬁability of True Parameters

f(y; x  θ) =(cid:80)

ij∈E θij(yi  yj) +(cid:80)

i θi(yi) +(cid:80)

In this section  we show that it is possible to approximately identify the true model parameters  up to
model equivalence  using the pseudo-max constraints and a carefully chosen linear number of data
points. Consider the learning problem for structured prediction deﬁned on a ﬁxed graph G = (V  E)
where the parameters to be learned are pairwise potential functions θij(yi  yj) for ij ∈ E and single
node ﬁelds θi(yi) for i ∈ V . We consider discriminant functions of the form

i xi(yi) 

(4)
where the input space X = R|V |k speciﬁes the single node potentials. Without loss of generality  we
remove the additional degrees of freedom in θ by restricting it to be in a canonical form: θ ∈ Θcan
if for all edges θij(yi  yj) = 0 whenever yi = 0 or yj = 0  and if for all nodes  θi(yi) = 0 when
yi = 0. As a result  assuming the training set comes from a model in this class  and the input ﬁelds
xi(yi) exercise the discriminant function appropriately  we can hope to identify θ∗ ∈ Θcan. Indeed 
we show that  for some data sets  the pseudo-max constraints are sufﬁcient to identify θ∗.
Let Θps({ym  xm}) be the set of parameters that satisfy the pseudo-max classiﬁcation constraints
i   f(ym; xm  θ) ≥ f(ym
(5)
For simplicity we omit the margin losses e(ym
i   yi)  since the input ﬁelds xi(yi) already sufﬁce to
rule out the trivial solution θ = 0.
Proposition 2.1. For any θ∗ ∈ Θcan  there is a set of 2|V |(k − 1) + 2|E|(k − 1)2 examples 
{xm  y(xm; θ∗)}  such that any pseudo-max consistent θ ∈ Θps({ym  xm}) ∩ Θcan is arbitrarily
close to θ∗.

Θps({ym  xm}) =(cid:8)θ | ∀m  i  yi (cid:54)= ym

−i  yi; xm  θ)(cid:9).

The proof is given in the supplementary material. To illustrate the key ideas  we consider the simpler
binary discriminant function discussed in Eq. 3. Note that the binary model is already in the canon-
ical form since Jijyiyj = 0 whenever yi = 0 or yj = 0. For any ij ∈ E  we show how to choose
two input examples x1 and x2 such that any J consistent with the pseudo-max constraints for these
two examples will have Jij ∈ [J∗ij −   J∗ij + ]. Repeating this for all of the edge parameters then
gives the complete set of examples. The input examples we need for this will depend on J∗.
For the ﬁrst example  we set the input ﬁelds for all neighbors of i (except j) in such a way that
k < −|N(k)| maxl |J∗kl| for
we force the corresponding labels to be zero. More formally  we set x1
k ∈ N(i)\j  resulting in y1
j to a large value  e.g.
i = −J∗ij +  so as to obtain a
j > |N(j)| maxl |J∗jl|  so that y1
x1
i = 1. All other input ﬁelds can be set arbitrarily. As a result  the pseudo-max
slight preference for y1
constraints pertaining to node i are f(y1; x1  J) ≥ f(y1
−i  yi; x1  J) for yi = 0  1. By taking into
i and its neighbors  and by removing terms that are the same on
account the label assignments for y1
both sides of the equation  we get Jij + x1
j  which  for yi = 0  implies
i ≥ 0 or Jij − J∗ij +  ≥ 0. The second example x2 differs only in terms of the input
that Jij + x1
i = 0. This gives Jij ≤ J∗ij +   as desired.
ﬁeld for i. In particular  we set x2

k = 0  where y1 = y(x1). In contrast  we set x1

j = 1. Finally  for node i  we set x1

i = −J∗ij −  so that y2

i + x1

i + x1

j ≥ Jijyi + yix1

4

2.2 Consistency via Strict Convexity

In this section we prove the consistency of the pseudo-max approach by showing that it corresponds
to minimizing a strictly convex function. Our proof only requires that p(x) be non-zero for all x ∈
Rn (a simple example being a multi-variate Gaussian) and that J∗ is ﬁnite. We use a discriminant
function as in Eq. 3. Now  assume the input points xm are distributed according to p(x) and that
ym are obtained via ym = arg maxy f(y; xm  J∗). We can write the (cid:96)ps(J) objective for ﬁnite
data  and its limit when M → ∞  compactly as:

(cid:96)ps(J) =

1
M

→ (cid:88)

i

(cid:88)

i

(cid:88)
(cid:90)

m

max
yi

p(x) max

yi

i + (cid:88)
(cid:2)(yi − ym
i )(cid:0)xm
(cid:2)(yi − yi(x))(cid:0)xi + (cid:88)

k∈N (i)

Jkiym
k

(cid:1)(cid:3)
Jkiyk(x)(cid:1)(cid:3)dx

k∈N (i)

(6)

(cid:90) ∞

−∞

(cid:90) ∞

−∞

gik(Jik)(cid:3) 

where gik(Jik) =(cid:82)

(cid:2) ˆgi({Jik}k∈N (i)) + (cid:88)

where yi(x) is the label of i for input x when using parameters J∗. Starting from the above 
consider the terms separately for each i. We partition the integral over x ∈ Rn into exclusive
regions according to the predicted labels of the neighbors of i (given x). Deﬁne Sij = {x : yj(x) =
1 and yk(x) = 0 for k ∈ N(i)\j}. Eq. 6 can then be written as

(cid:96)ps(J) =(cid:88)
(7)
p(x) maxyi[(yi−yi(x))(xi +Jik)]dx and ˆgi({Jik}k∈N (i)) contains all of
the remaining terms  i.e. where either zero or more than one neighbor is set to one. The function ˆgi
is convex in J since it is a sum of integrals over convex functions. We proceed to show that gik(Jik)
is strictly convex for all choices of i and k ∈ N(i). This will show that (cid:96)ps(J) is strictly convex
since it is a sum over functions strictly convex in each one of the variables in J.
For all values xi ∈ (−∞ ∞) there is some x in Sij. This is because for any ﬁnite xi and ﬁnite J∗ 
the other xj’s can be chosen so as to give the y conﬁguration corresponding to Sij. Now  since p(x)
has full support  we have P (Sij) > 0 and p(x) > 0 for any x in Sij. As a result  this also holds for
the marginal pi(xi|Sij) over xi within Sij. After some algebra  we obtain:

k∈N (i)

x∈Sik

i

gij(Jij) = P (Sij)

pi(xi|Sij) max [0  xi + Jij] dxi −

p(x)yi(x)(xi + Jij)dx

The integral over the yi(x)(xi + Jij) expression just adds a linear term to gij(Jij). The relevant
remaining term is (for brevity we drop P (Sij)  a strictly positive constant  and the ij index):

h(J) =

pi(xi|Sij) max [0  xi + J] dxi =

pi(xi|Sij)ˆh(xi  J)dxi

(8)

where we deﬁne ˆh(xi  J) = max [0  xi + J]. Note that h(J) is convex since ˆh(xi  J) is convex in J
for all xi. We want to show that h(J) is strictly convex. Consider J(cid:48) < J and α ∈ (0  1) and deﬁne
the interval I = [−J −αJ − (1 − α)J(cid:48)]. For xi ∈ I it holds that: αˆh(xi  J) + (1 − α)ˆh(xi  J(cid:48)) >
ˆh(xi  αJ + (1 − α)J(cid:48)) (since the ﬁrst term is strictly positive and the rest are zero). For all other x 
this inequality holds but is not necessarily strict (since ˆh is always convex in J). We thus have after
integrating over x that αh(J) + (1 − α)h(J(cid:48)) > h(αJ + (1 − α)J(cid:48))  implying h is strictly convex 
as required. Note that we used the fact that p(x) has full support when integrating over I.
The function (cid:96)ps(J) is thus a sum of strictly convex functions in all its variables (namely g(Jik))
plus other convex functions of J  hence strictly convex. We can now proceed to show consistency.
By strict convexity  the pseudo-max objective is minimized at a unique point J. Since we know
that (cid:96)ps(J∗) = 0 and zero is a lower bound on the value of (cid:96)ps(J)  it follows that J∗ is the unique
minimizer. Thus we have that as M → ∞  the minimizer of the pseudo-max objective is the true
parameter vector  and thus we have consistency.
As an example  consider the case of two variables y1  y2  with x1 and x2 distributed according to
N (c1  1) N (0  1) respectively. Furthermore assume J∗12 = 0. Then simple direct calculation yields:
(9)

(cid:90) −c1

e−(J12+c1)2/2

1/2 +

e−c2

g(J12) = c1 + J12√
2π

e−x2/2dx − 1√
2π

−J12−c1

which is indeed a strictly convex function that is minimized at J = 0 (see Fig. 1 for an illustration).

1√
2π

(cid:90)

x∈Sij

(cid:90) ∞

−∞

5

3 Hardness of Structured Learning

Most structured prediction learning algorithms use some form of inference as a subroutine. However 
the corresponding prediction task is generally NP-hard. For example  maximizing the discriminant
function deﬁned in Eq. 3 is equivalent to solving Max-Cut  which is known to be NP-hard. This
raises the question of whether it is possible to bypass prediction during learning. Although prediction
may be intractable for arbitrary MRFs  what does this say about the difﬁculty of learning with a
polynomial number of data points? In this section  we show that the problem of deciding whether
there exists a parameter vector that separates the training data is NP-hard.
Put in the context of the positive results in this paper  these hardness results show that  although in
some cases the pseudo-max constraints yield a consistent estimate  we cannot hope for a certiﬁcate
of optimality. Put differently  although the pseudo-max constraints in the separable case always give
an outer bound on Θ (and may even be a single point)  Θ could be the empty set – and we would
never know the difference.
Theorem 3.1. Given labeled examples {(xm  ym)}M
m=1 for a ﬁxed but arbitrary graph G  it is
NP-hard to decide whether there exists parameters θ such that ∀m  ym = arg maxy f(y; xm  θ).
Proof. Any parameters θ have an equivalent parameterization in canonical form (see section
Sec. 2.1  also supplementary). Thus  the examples will be separable if and only if they are sepa-
rable by some θ ∈ Θcan. We reduce from unweighted Max-Cut. The Max-Cut problem is to decide 
given an undirected graph G  whether there exists a cut of at least K edges. Let G be the same graph
as G  with k = 3 states per variable. We construct a small set of examples where a parameter vector
will exist that separates the data if and only if there is no cut of K or more edges in G.
ij(yi  yj) = 1 if (yi  yj) ∈ {(1  2)  (2  1)}  0 if
Let θ be parameters in canonical form equivalent to θ
yi = yj  and −n2 if (yi  yj) ∈ {(1  3)  (2  3)  (3  1)  (3  2)}. We ﬁrst construct 4n + 8|E| examples 
using the technique described in Sec. 2.1 (also supplementary material)  which when restricted to
the space Θcan  constrain the parameters to equal θ. We then use one more example (xm  ym) where
ym = 3 (every node is in state 3) and  for all i  xm
i (2) = 0. The ﬁrst
i (3) = K−1
n
two states encode the original Max-Cut instance  while the third state is used to construct a labeling
ym that has value equal to K − 1  and is otherwise not used.
Let K∗ be the value of the maximum cut in G. If in any assignment to the last example there is a
variable taking the state 3 and another variable taking the state 1 or 2  then the assignment’s value
will be at most K∗− n2  which is less than zero. By construction  the 3 assignment has value K −1.
Thus  the optimal assignment must either be 3 with value K − 1  or some combination of states 1
and 2  which has value at most K∗. If K∗ > K − 1 then 3 is not optimal and the examples are not
separable. If K∗ ≤ K − 1  the examples are separable.
This result illustrates the potential difﬁculty of learning in worst-case graphs. Nonetheless  many
problems have a more restricted dependence on the input. For example  in computer vision  edge
potentials may depend only on the difference in color between two adjacent pixels. Our results do
not preclude positive results of learnability in such restricted settings. By establishing hardness of
learning  we also close the open problem of relating hardness of inference and learning in structured
prediction. If inference problems can be solved in polynomial time  then so can learning (using  e.g. 
structured perceptron). Thus  when learning is hard  inference must be hard as well.

i (1) = xm

and xm

(cid:48)

4 Experiments

To evaluate our learning algorithm  we test its performance on both synthetic and real-world datasets.
We show that  as the number of training samples grows  the accuracy of the pseudo-max method im-
proves and its speed-up gain over competing algorithms increases. Our learning algorithm cor-
responds to solving the following  where we add L2 regularization and use a scaled 0-1 loss 
e(yi  ym

M(cid:88)
nm(cid:88)
i ) = 1{yi (cid:54)= ym
i }/nm (nm is the number of labels in example m):
C(cid:80)

−i  yi; xm  θ) − f(ym; xm  θ) + e(yi  ym
i )

+ (cid:107)θ(cid:107)2 .

(10)

min
θ

max
yi

f(ym

(cid:105)

(cid:104)

m nm

m=1

i=1

We will compare the pseudo-max method with learning using structural SVMs  both with exact
inference and LP relaxations [see  e.g.  4]. We use exact inference for prediction at test time.

6

(a) Synthetic

(b) Reuters

Figure 2: Test error as a function of train size for various algorithms. Subﬁgure (a) shows results for a synthetic
setting  while (b) shows performance on the Reuters data.

In the synthetic setting we use the discriminant function f(y; x  θ) = (cid:80)
(cid:80)

ij∈E θij(yi  yj) +
i xiθi(yi)  which is similar to Eq. 4. We take a fully connected graph over n = 10 binary labels.
For a weight vector θ∗ (sampled once  uniformly in the range [−1  1]  and used for all train/test
sets) we generate train and test instances by sampling xm uniformly in the range [−5  5] and then
computing the optimal labels ym = arg maxy∈Y f(y; xm  θ∗).
We generate train sets of increasing size (M = {10  50  100  500  1000  5000})  run the learning al-
gorithms  and measure the test error for the learned weights (with 1000 test samples). For each train
size we average the test error over 10 repeats of sampling and training. Fig. 2(a) shows a comparison
of the test error for the three learning algorithms. For small numbers of training examples  the test
error of pseudo-max is larger than that of the other algorithms. However  as the train size grows  the
error converges to that of exact learning  as our consistency results predict.
We also test the performance of our algorithm on a multi-label document classiﬁcation task from the
Reuters dataset [7]. The data consists of M = 23149 training samples  and we use a reduction of
the dataset to the 5 most frequent labels. The 5 label variables form a fully connected pairwise graph
structure (see [4] for a similar setting). We use random subsamples of increasing size from the train
set to learn the parameters  and then measure the test error using 20000 additional samples. For each
sample size and learning algorithm  we optimize the trade-off parameter C using 30% of the training
data as a hold-out set. Fig. 2(b) shows that for the large data regime the performance of pseudo-max
learning gets close to that of the other methods. However  unlike the synthetic setting there is still a
small gap  even after seeing the entire train set. This could be because the full dataset is not yet large
enough to be in the consistent regime (note that exact learning has not ﬂattened either)  or because
the consistency conditions are not fully satisﬁed: the data might be non-separable or the support of
the input distribution p(x) may be partial.
We next apply our method to the problem of learning the energy function for protein side-chain
placement  mirroring the learning setup of [14]  where the authors train a conditional random ﬁeld
(CRF) using tree-reweighted belief propagation to maximize a lower bound on the likelihood.5 The
prediction problem for side-chain placement corresponds to ﬁnding the most likely assignment in
a pairwise MRF  and ﬁts naturally into our learning framework. There are only 8 parameters to
be learned  corresponding to a reweighting of known energy terms. The dataset consists of 275
proteins  where each MRF has several hundred variables (one per residue of the protein) and each
variable has on average 20 states. For prediction we use CPLEX’s ILP solver.
Fig. 3 shows a comparison of the pseudo-max method and a cutting-plane algorithm which uses an
LP relaxation  solved with CPLEX  for ﬁnding violated constraints.6 We generate training sets of
increasing size (M = {10  50  100  274})  and measure the test error for the learned weights on the
remaining examples.7 For M = 10  50  100 we average the test error over 3 random train/test splits 
whereas for M = 274 we do 1-fold cross validation. We use C = 1 for both algorithms.

5The authors’ data and results are available from: http://cyanover.fhcrc.org/recomb-2007/
6We signiﬁcantly optimized the cutting-plane algorithm  e.g. including a large number of initial cutting-

planes and restricting the weight vector to be positive (which we know to hold at optimality).

7Speciﬁcally  for each protein we compute the fraction of correctly predicted χ1 and χ2 angles for all
residues (except when trivial  e.g. just 1 state). Then  we compute the median of this value across all proteins.

7

10110210300.050.10.150.2Train sizeTest error  exactLP−relaxationpseudo−max10110210310400.10.20.30.4Train sizeTest error  exactLP−relaxationpseudo−maxFigure 3: Training time (for one train/test split) and test error as a function of train size for both the pseudo-
max method and a cutting-plane algorithm which uses a LP relaxation for inference  applied to the problem of
learning the energy function for protein side-chain placement. The pseudo-max method obtains better accuracy
than both the LP relaxation and HCRF (given roughly ﬁve times more data) for a fraction of the training time.

The original weights (“Soft rep” [3]) used for this energy function have 26.7% error across all 275
proteins. The best previously reported parameters  learned in [14] using a Hidden CRF  obtain
25.6% error (their training set included 55 of these 275 proteins  so this is an optimistic estimate).
To get a sense of the difﬁculty of this learning task  we also tried a random positive weight vector 
uniformly sampled from the range [0  1]  obtaining an error of 34.9% (results would be much worse
if we allowed the weights to be negative). Training using pseudo-max with 50 examples  we learn
parameters in under a minute that give better accuracy than the HCRF. The speed-up of training with
pseudo-max (using CPLEX’s QP solver) versus cutting-plane is striking. For example  for M = 10 
pseudo-max takes only 3 seconds  a 1000-fold speedup. Unfortunately the cutting-plane algorithm
took a prohibitive amount of time to be able to run on the larger training sets. Since the data used
in learning for protein side-chain placement is both highly non-separable and relatively little  these
positive results illustrate the potential wide-spread applicability of the pseudo-max method.

5 Discussion

The key idea of our method is to ﬁnd parameters that prefer the true assignment ym over assignments
that differ from it in only one variable  in contrast to all other assignments. Perhaps surprisingly  this
weak requirement is sufﬁcient to achieve consistency given a rich enough input distribution. One
extension of our approach is to add constraints for assignments that differ from ym in more than one
variable. This would tighten the outer bound on Θ and possibly result in improved performance  but
would also increase computational complexity. We could also add such competing assignments via
a cutting-plane scheme so that optimization is performed only over a subset of these constraints.
Our work raises a number of important open problems: It would be interesting to derive generaliza-
tion bounds to understand the convergence rate of our method  as well as understanding the effect of
the distribution p(x) on these rates. The distribution p(x) needs to have two key properties. On the
one hand  it needs to explore the space Y in the sense that a sufﬁcient number of labels need to be
obtained as the correct label for the true parameters (this is indeed used in our consistency proofs).
On the other hand  p(x) needs to be sufﬁciently sensitive close to the decision boundaries so that
the true parameters can be inferred. We expect that generalization analysis will depend on these two
properties of p(x). Note that [11] studied active learning schemes for structured data and may be
relevant in the current context.
How should one apply this learning algorithm to non-separable data sets? We suggested one ap-
proach  based on using a hinge loss for each of the pseudo constraints. One question in this context
is  how resilient is this learning algorithm to label noise? Recent work has analyzed the sensitivity
of pseudo-likelihood methods to model mis-speciﬁcation [8]  and it would be interesting to perform
a similar analysis here. Also  is it possible to give any guarantees for the empirical and expected
risks (with respect to exact inference) obtained by outer bound learning versus exact learning?
Finally  our algorithm demonstrates a phenomenon where more data can make computation easier.
Such a scenario was recently analyzed in the context of supervised learning [12]  and it would be
interesting to combine the approaches.
Acknowledgments: We thank Chen Yanover for his assistance with the protein data. This work was sup-
ported by BSF grant 2008303 and a Google Research Grant. D.S. was supported by a Google PhD Fellowship.

8

0501001502002500.250.2550.260.2650.27Train sizeTest error (χ1 and χ2)  pseudo−maxLP−relaxationSoft rep050100150200250050100150200250Train sizeTime to train (minutes)  pseudo−maxLP−relaxationReferences
[1] J. Besag. The analysis of non-lattice data. The Statistician  24:179–195  1975.
[2] M. Collins. Discriminative training methods for hidden Markov models: Theory and experiments with

perceptron algorithms. In EMNLP  2002.

[3] G. Dantas  C. Corrent  S. L. Reichow  J. J. Havranek  Z. M. Eletr  N. G. Isern  B. Kuhlman  G. Varani 
E. A. Merritt  and D. Baker. High-resolution structural and thermodynamic analysis of extreme stabi-
lization of human procarboxypeptidase by computational protein design. Journal of Molecular Biology 
366(4):1209 – 1221  2007.

[4] T. Finley and T. Joachims. Training structural SVMs when exact inference is intractable. In Proceedings

of the 25th International Conference on Machine Learning 25  pages 304–311. ACM  2008.

[5] T. Joachims  T. Finley  and C.-N. Yu. Cutting-plane training of structural SVMs. Machine Learning 

77(1):27–59  2009.

[6] A. Kulesza and F. Pereira. Structured learning with approximate inference. In Advances in Neural Infor-

mation Processing Systems 20  pages 785–792. 2008.

[7] D. Lewis    Y. Yang  T. Rose  and F. Li. RCV1: a new benchmark collection for text categorization

research. JMLR  5:361–397  2004.

[8] P. Liang and M. I. Jordan. An asymptotic analysis of generative  discriminative  and pseudolikelihood
estimators. In Proceedings of the 25th international conference on Machine learning  pages 584–591 
New York  NY  USA  2008. ACM Press.

[9] A. F. T. Martins  N. A. Smith  and E. P. Xing. Polyhedral outer approximations with application to natural

language parsing. In ICML 26  pages 713–720  2009.

[10] N. Ratliff  J. A. D. Bagnell  and M. Zinkevich. (Online) subgradient methods for structured prediction.

In AISTATS  2007.

[11] D. Roth and K. Small. Margin-based active learning for structured output spaces. In Proc. of the European

Conference on Machine Learning (ECML). Springer  September 2006.

[12] S. Shalev-Shwartz and N. Srebro. SVM optimization: inverse dependence on training set size. In Pro-

ceedings of the 25th international conference on Machine learning  pages 928–935. ACM  2008.

[13] B. Taskar  C. Guestrin  and D. Koller. Max margin Markov networks. In Advances in Neural Information

Processing Systems 16  pages 25–32. 2004.

[14] C. Yanover  O. Schueler-Furman  and Y. Weiss. Minimizing and learning energy functions for side-chain

prediction. Journal of Computational Biology  15(7):899–911  2008.

9

,Tetsuro Morimura
Takayuki Osogami
Tsuyoshi Ide
Harikrishna Narasimhan
Rohit Vaish
Shivani Agarwal