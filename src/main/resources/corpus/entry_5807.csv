2018,Uplift Modeling from Separate Labels,Uplift modeling is aimed at estimating the incremental impact of an action on an individual's behavior  which is useful in various application domains such as targeted marketing (advertisement campaigns) and personalized medicine (medical treatments). Conventional methods of uplift modeling require every instance to be jointly equipped with two types of labels: the taken action and its outcome. However  obtaining two labels for each instance at the same time is difficult or expensive in many real-world problems. In this paper  we propose a novel method of uplift modeling that is applicable to a more practical setting where only one type of labels is available for each instance. We show a mean squared error bound for the proposed estimator and demonstrate its effectiveness through experiments.,Uplift Modeling from Separate Labels

Ikko Yamane1 2 Florian Yger3 2

Jamal Atif3 Masashi Sugiyama2 1

1 The University of Tokyo  CHIBA  JAPAN

2 RIKEN Center for Advanced Intelligence Project (AIP)  TOKYO  JAPAN

3 LAMSADE  CNRS  Université Paris-Dauphine  Université PSL  PARIS  FRANCE

{yamane@ms.  sugi@}k.u-tokyo.ac.jp  {florian.yger@  jamal.atif@}dauphine.fr

Abstract

Uplift modeling is aimed at estimating the incremental impact of an action on
an individual’s behavior  which is useful in various application domains such as
targeted marketing (advertisement campaigns) and personalized medicine (medical
treatments). Conventional methods of uplift modeling require every instance to
be jointly equipped with two types of labels: the taken action and its outcome.
However  obtaining two labels for each instance at the same time is difﬁcult or
expensive in many real-world problems. In this paper  we propose a novel method
of uplift modeling that is applicable to a more practical setting where only one type
of labels is available for each instance. We show a mean squared error bound for
the proposed estimator and demonstrate its effectiveness through experiments.

1

Introduction

In many real-world problems  a central objective is to optimally choose a right action to maximize
the proﬁt of interest. For example  in marketing  an advertising campaign is designed to promote
people to purchase a product [29]. A marketer can choose whether to deliver an advertisement to
each individual or not  and the outcome is the number of purchases of the product. Another example
is personalized medicine  where a treatment is chosen depending on each patient to maximize the
medical effect and minimize the risk of adverse events or harmful side effects [1  13]. In this case 
giving or not giving a medical treatment to each individual are the possible actions to choose  and the
outcome is the rate of recovery or survival from the disease. Hereafter  we use the word treatment for
taking an action  following the personalized medicine example.
A/B testing [14] is a standard method for such tasks  where two groups of people  A and B  are
randomly chosen. The outcomes are measured separately from the two groups after treating all the
members of Group A but none of Group B. By comparing the outcomes between the two groups by a
statistical test  one can examine whether the treatment positively or negatively affected the outcome.
However  A/B testing only compares the two extreme options: treating everyone or no one. These
two options can be both far from optimal when the treatment has positive effect on some individuals
but negative effect on others.
To overcome the drawback of A/B testing  uplift modeling has been investigated recently [11  28  32].
Uplift modeling is the problem of estimating the individual uplift  the incremental proﬁt brought by
the treatment conditioned on features of each individual. Uplift modeling enables us to design a
reﬁned decision rule for optimally determining whether to treat each individual or not  depending on
his/her features. Such a treatment rule allows us to only target those who positively respond to the
treatment and avoid treating negative responders.
In the standard uplift modeling setup  there are two types of labels [11  28  32]: One is whether the
treatment has been given to the individual and the other is its outcome. Existing uplift modeling
methods require each individual to be jointly given these two labels for analyzing the association

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

between outcomes and the treatment [11  28  32]. However  joint labels are expensive or hard (or even
impossible) to obtain in many real-world problems. For example  when distributing an advertisement
by email  we can easily record to whom the advertisement has been sent. However  for technical
or privacy reasons  it is difﬁcult to keep track of those people until we observe the outcomes on
whether they buy the product or not. Alternatively  we can easily obtain information about purchasers
of the product at the moment when the purchases are actually made. However  we cannot know
whether those who are buying the product have been exposed to the advertisement or not. Thus  every
individual always has one missing label. We term such samples separately labeled samples.
In this paper  we consider a more practical uplift modeling setup where no jointly labeled samples
are available  but only separately labeled samples are given. Theoretically  we ﬁrst show that the
individual uplift is identiﬁable when we have two sets of separately labeled samples collected under
different treatment policies. We then propose a novel method that directly estimates the individual
uplift only from separately labeled samples. Finally  we demonstrate the effectiveness of the proposed
method through experiments.

2 Problem Setting

This paper focuses on estimation of the individual uplift u(x)  often called individual treatment
effect (ITE) in the causal inference literature [31]  deﬁned as u(x) := E[Y1 | x] − E[Y−1 | x] 
where E[ · | · ] denotes the conditional expectation  and x is a X -valued random variable (X ⊆ Rd)
representing features of an individual  and Y1  Y−1 are Y-valued potential outcome variables [31]
(Y ⊆ R) representing outcomes that would be observed if the individual was treated and not treated 
respectively. Note that only one of either Y1 or Y−1 can be observed for each individual. We denote
the {1 −1}-valued random variable of the treatment assignment by t  where t = 1 means that the
individual has been treated and t = −1 not treated. We refer to the population for which we want to
evaluate u(x) as the test population  and denote the density of the test population by p(Y1  Y−1  x  t).
We assume that t is unconfounded with either of Y1 and Y−1 conditioned on x  i.e. p(Y1 | x  t) =
p(Y1 | x) and p(Y−1 | x  t) = p(Y−1 | x). Unconfoundedness is an assumption commonly made in
observational studies [5  33]. For notational convenience  we denote by y := Yt the outcome of the
treatment assignment t. Furthermore  we refer to any conditional density of t given x as a treatment
policy.
In addition to the test population  we suppose that there are two training populations k = 1  2  whose
joint probability density pk(Y1  Y−1  x  t) satisfy

pk(Yt0 = y0 | x = x0) = p(Yt0 = y0 | x = x0)
p1(t = t0 | x = x0) (cid:54)= p2(t = t0 | x = x0) 

(1)
(2)
for all possible realizations x0 ∈ X   t0 ∈ {−1  1}  and y0 ∈ Y. Intuitively  Eq. (1) means that
potential outcomes depend on x in the same way as those in the test population  and Eq. (2) states
that those two policies give a treatment with different probabilities for every x = x0.
We suppose that the following four training data sets  which we call separately labeled samples  are
given:

(for k = 1  2) 

{(x(k)

i

)}nk

i=1

i.i.d.∼ pk(x  y) 

i

  y(k)

where nk and (cid:101)nk  k = 1  2  are positive integers. Under Assumptions (1)  (2)  and the uncon-
foundedness  we have pk(Yt | x  t = t0) = p(Yt0 | x  t = t0) = p(Yt0 | x) for t0 ∈ {−1  1}
and k ∈ {1  2}. Note that we can safely denote p(y | x  t) := pk(y | x  t). Moreover  we have
E[Yt0 | x] = E[y | x  t = t0] for t0 = 1 −1  and thus our goal boils down to the estimation of

(for k = 1  2) 

  t(k)

i=1

i

u(x) = E[y | x  t = 1] − E[y | x  t = −1]

(3)

from the separately labeled samples  where the conditional expectation is taken over p(y | x  t).
Estimation of the individual uplift is important for the following reasons.
It enables the estimation of the average uplift. The average uplift U (π) of the treatment policy
π(t | x) is the average outcome of π  subtracted by that of the policy π−  which constantly assigns

2

{((cid:101)x(k)

i

)}(cid:101)nk

i.i.d.∼ pk(x  t)

the treatment as t = −1  i.e.  π−(t = τ | x) := 1[τ = −1]  where 1[·] denotes the indicator function:
yp(y | x  t)π−(t | x)p(x)dydx

yp(y | x  t)π(t | x)p(x)dydx −

U (π) :=

(cid:90)(cid:90) (cid:88)

t=−1 1

(cid:90)(cid:90) (cid:88)
(cid:90)

t=−1 1

=

u(x)π(t = 1 | x)p(x)dx.

(4)

This quantity can be estimated from samples of x once we obtain an estimate of u(x).
It provides the optimal treatment policy. The treatment policy given by π(t = 1 | x) = 1[0 ≤
u(x)] is the optimal treatment that maximizes the average uplift U (π) and equivalently the average

t=−1 1 yp(y | x  t)π(t | x)p(x)dydx (see Eq. (4)) [32].

outcome(cid:82)(cid:82)(cid:80)

It is the optimal ranking scoring function. From a practical viewpoint  it may be useful to prioritize
individuals to be treated according to some ranking scores especially when the treatment is costly
and only a limited number of individuals can be treated due to some budget constraint. In fact  u(x)
serves as the optimal ranking scores for this purpose [36]. More speciﬁcally  we deﬁne a family of
treatment policies {πf α}α∈R associated with scoring function f by πf α(t = 1 | x) = 1[α ≤ f (x)].
Then  under some technical condition  f = u maximizes the area under the uplift curve (AUUC)
deﬁned as

(cid:90) 1
(cid:90)
(cid:90) 1

0

AUUC(f ) :=

U (πf α)dCα

u(x)1[α ≤ f (x)]p(x)dxdCα

=
= E[1[f (x) ≤ f (x(cid:48))]u(x(cid:48))] 

0

where Cα := Pr[f (x) < α]  x  x(cid:48) i.i.d.∼ p(x)  and E denotes the expectation with respect to these
variables. AUUC is a standard performance measure for uplift modeling methods [11  25  28  32].
For more details  see Appendix B in the supplementary material.
Remark on the problem setting: Uplift modeling is often referred to as individual treatment effect
estimation or heterogeneous treatment effect estimation and has been extensively studied especially
in the causal inference literature [5  7  9  12  16  24  31  37]. In particular  recent research has
investigated the problem under the setting of observational studies  inference using data obtained
from uncontrolled experiments because of its practical importance [33]. Here  experiments are said
to be uncontrolled when some of treatment variables are not controlled to have designed values.
Given that treatment policies are unknown  our problem setting is also of observational studies but
poses an additional challenge that stems from missing labels. What makes our problem feasible is
that we have two kinds of data sets following different treatment policies.
It is also important to note that our setting generalizes the standard setting for observational studies
since the former is reduced to the latter when one of the treatment policies always assigns individuals
to the treatment group  and the other to the control group.
Our problem is also closely related to individual treatment effect estimation via instrumental vari-
ables [2  6  10  19].1

3 Naive Estimators
A naive approach is ﬁrst estimating the conditional density pk(y | x) and pk(t | x) from training
samples by some conditional density estimator [4  34]  and then solving the following linear system
for p(y | x  t = 1) and p(y | x  t = −1):

(cid:123)(cid:122)

pk(y | x)
Estimated from {(x(k)

(cid:125)

(cid:124)

  y(k)

i

i

=

)}n

i=1

(cid:88)

t=−1 1

p(y | x  t)

(cid:123)(cid:122)
(cid:125)
pk(t | x)
Estimated from {((cid:101)x(k)

(cid:124)

i

(for k = 1  2).

(5)

)}(cid:101)n

i=1

  t(k)

i

1Among the related papers mentioned above  the most relevant one is Lewis and Syrgkanis [19]  which is

concurrent work with ours.

3

linear system implied by Eq. (5) instead: Ek[y | x] = (cid:80)

After that  the conditional expectations of y over p(y | x  t = 1) and p(y | x  t = −1) are calculated
by numerical integration  and ﬁnally their difference is calculated to obtain another estimate of u(x).
However  this may not yield a good estimate due to the difﬁculty of conditional density estimation
and the instability of numerical integration. This issue may be alleviated by working on the following
t=−1 1 E[y | x  t]pk(t | x)  k = 1  2 
where Ek[y | x] and pk(t | x) can be estimated from our samples. Solving this new system for
E[y | x  t = 1] and E[y | x  t = −1] and taking their difference gives an estimate of u(x). A method
called two-stage least-squares for instrumental variable regression takes such an approach [10].
The second approach of estimation Ek[y|x] and pk(t|x) avoids both conditional density estimation
and numerical integration  but it still involves post processing of solving the linear system and
subtraction  being a potential cause of performance deterioration.

4 Proposed Method

In this section  we develop a method that can overcome the aforementioned problems by directly
estimating the individual uplift.

4.1 Direct Least-Square Estimation of the Individual Uplift

First  we will show an important lemma that directly relates the marginal distributions of separately
labeled samples to the individual uplift u(x).
Lemma 1. For every x such that p1(x) (cid:54)= p2(x)  u(x) can be expressed as

u(x) = 2 × Ey∼p1(y|x)[y] − Ey∼p2(y|x)[y]
Et∼p1(t|x)[t] − Et∼p2(t|x)[t]

.

(6)

For a proof  refer to Appendix C in the supplementary material.
Using Eq. (6)  we can re-interpret the naive methods described in Section 3 as estimating the condi-
tional expectations on the right-hand side by separately performing regression on {(x(1)
)}n1
i=1 
{(x(2)
i=1. This approach may result in unreliable
performance when the denominator is close to zero  i.e.  p1(t | x) (cid:39) p2(t | x).
Lemma 1 can be simpliﬁed by introducing auxiliary variables z and w  which are Z-valued and
{−1  1}-valued random variables whose conditional probability density and mass are deﬁned by

i=1  and {((cid:101)x(2)
)}(cid:101)n1

i=1  {((cid:101)x(1)

)}(cid:101)n2

)}n2

  y(1)

  y(2)

  t(2)

  t(1)

i

i

i

i

i

i

i

i

p(z = z0 | x) = 1
p(w = w0 | x) = 1

2 p1(y = z0 | x) + 1
2 p1(t = w0 | x) + 1

2 p2(y = −z0 | x) 
2 p2(t = −w0 | x) 

for any z0 ∈ Z and any w0 ∈ {−1  1}  where Z := {s0y0 | y0 ∈ Y  s0 ∈ {1 −1}}.
Lemma 2. For every x such that p1(x) (cid:54)= p2(x)  u(x) can be expressed as

u(x) = 2 × E[z | x]
E[w | x]

 

where E[z | x] and E[w | x] are the conditional expectations of z given x over p(z | x) and w given
x over p(w | x)  respectively.

i

:= (−1)k−1t(k)

A proof can be found in Appendix D in the supplementary material.
Let w(k)

n1 = n2  and (cid:101)n1 = (cid:101)n2 for simplicity  {((cid:101)xi  wi)}n
)}k=1 2; i=1 ... (cid:101)nk and
x)p(x) and p(x  w) := p(w | x)p(x)  respectively  where n = n1 + n2 and(cid:101)n = (cid:101)n1 +(cid:101)n2. The
)}k=1 2; i=1 ... nk can be seen as samples drawn from p(x  z) := p(z |
more general cases where p1(x) (cid:54)= p2(x)  n1 (cid:54)= n2  or(cid:101)n1 (cid:54)=(cid:101)n2 are discussed in Appendix I in the

i=1 := {((cid:101)x(k)

. Assuming that p1(x) = p2(x) =: p(x) 

:= (−1)k−1y(k)

i=1 := {(x(k)

{(xi  zi)}n

and z(k)

  w(k)

  z(k)

i

i

i

i

i

i

i

supplementary material.

4

Theorem 1. Assume that µw  µz ∈ L2(p) and µw(x) (cid:54)= 0 for every x such that p(x) > 0  where
L2(p) := {f : X → R | Ex∼p(x)[f (x)2] < ∞}. The individual uplift u(x) equals the solution to
the following least-squares problem:

u(x) = argmin
f∈L2(p)

E[(µw(x)f (x) − 2µz(x))2] 

(7)

where E denotes the expectation over p(x)  µw(x) := E[w | x]  and µz(x) := E[z | x].
Theorem 1 follows from Lemma 2. Note that p1(x) (cid:54)= p2(x) in Eq. (2) implies µw(x) (cid:54)= 0.
In what follows  we develop a method that directly estimates u(x) by solving Eq. (7). A challenge
here is that it is not straightforward to evaluate the objective functional since it involves unknown
functions  µw and µz.

4.2 Disentanglement of z and w

Our idea is to transform the objective functional in Eq. (7) into another form in which µw(x) and
µz(x) appear separately and linearly inside the expectation operator so that we can approximate them
using our separately labeled samples.
For any function g ∈ L2(p) and any x ∈ X   expanding the left-hand side of the inequality
E[(µw(x)f (x) − 2µz(x) − g(x))2] ≥ 0  we have

E[(µw(x)f (x) − 2µz(x))2] ≥ 2E[(µw(x)f (x) − 2µz(x))g(x)] − E[g(x)2] =: J(f  g).

(8)
The equality is attained when g(x) = µw(x)f (x) − µz(x) for any ﬁxed f. This means that the
objective functional of Eq. (7) can be calculated by maximizing J(f  g) with respect to g. Hence 

u(x) = argmin
f∈L2(p)

max
g∈L2(p)

J(f  g).

(9)

Furthermore  µw and µz are separately and linearly included in J(f  g)  which makes it possible to
write it in terms of z and w as

(10)
Unlike the original objective functional in Eq. (7)  J(f  g) can be easily estimated using sample
averages by

J(f  g) = 2E[wf (x)g(x)] − 4E[zg(x)] − E[g(x)2].

(cid:98)J(f  g) =

(cid:101)n(cid:88)

i=1

2(cid:101)n

wif ((cid:101)xi)g((cid:101)xi) − 4

n

zig(xi) − 1
2n

n(cid:88)
n(cid:88)
(cid:98)J(f  g) + Ω(f  g) 

i=1

i=1

min
f∈F

max
g∈G

In practice  we solve the following regularized empirical optimization problem:

(cid:101)n(cid:88)

i=1

2(cid:101)n

g((cid:101)xi)2.

g(xi)2 − 1

(11)

(12)

where F   G are models for f  g respectively  and Ω(f  g) is some regularizer.
An advantage of the proposed framework is that it is model-independent  and any models can be
trained by optimizing the above objective.
The function g can be interpreted as a critic of f as follows. Minimizing Eq. (10) with respect
to f is equivalent to minimizing J(f  g) = E[g(x){µw(x)f (x) − 2µz(x)}]. g(x) serves as a
good critic of f (x) when it makes the cost g(x){µw(x)f (x) − 2µz(x)} larger for x at which f
makes a larger error |µw(x)f (x) − 2µz(x)|. In particular  g maximizes the objective above when
g(x) = µw(x)f (x)− 2µz(x) for any f  and the maximum coincides with the least-squares objective
in Eq. (7).
Suppose that F and G are linear-in-parameter models: F = {fα : x (cid:55)→ α(cid:62)φ(x) | α ∈ Rbf} and
G = {gβ : x (cid:55)→ β(cid:62)ψ(x) | β ∈ Rbg}  where φ and ψ are bf-dimensional and bg-dimensional

vectors of basis functions in L2(p). Then  (cid:98)J(fα  gβ) = 2α(cid:62)Aβ − 4b(cid:62)β − β(cid:62)Cβ  where

A :=

C :=

(cid:101)n(cid:88)
wiφ((cid:101)xi)ψ((cid:101)xi)(cid:62) 
n(cid:88)

ψ(xi)ψ(xi)(cid:62) +

i=1

1(cid:101)n

1
2n

i=1

5

1
n

n(cid:88)
ψ((cid:101)xi)ψ((cid:101)xi)(cid:62).

ziψ(xi) 

i=1

b :=

(cid:101)n(cid:88)

i=1

1

2(cid:101)n

Using (cid:96)2-regularizers  Ω(f  g) = λf α(cid:62)α − λgβ(cid:62)β with some positive constants λf and λg  the
solution to the inner maximization problem can be obtained in the following analytical form:

(cid:98)βα := argmax

(cid:98)J(fα  gβ) = (cid:101)C−1(A(cid:62)α − 2b) 

β

(cid:98)J(fα  g(cid:98)βα

where (cid:101)C = C + λgIbg and Ibg is the bg-by-bg identity matrix. Then  we can obtain the solution to
Eq. (12) analytically as(cid:98)α := argmin
Finally  from Eq. (7)  our estimate of u(x) is given as (cid:98)α(cid:62)φ(x).
Instead  we may evaluate the value of J((cid:98)f  (cid:98)g)  where ((cid:98)f  (cid:98)g) ∈ F × G is the optimal solution pair to
minf∈F maxg∈G (cid:98)J(f  g). However  it is still nontrivial to tell if the objective value is small because

Remark on model selection: Model selection for F and G is not straightforward since the test
performance measure cannot be directly evaluated with (held out) training data of our problem.

) = 2(A(cid:101)C−1A(cid:62) + λf Ibg )−1A(cid:101)C−1b.

the solution is good in terms of the outer minimization  or because it is poor in terms of the inner
maximization. We leave this issue for future work.

α

5 Theoretical Analysis

A theoretically appealing property of the proposed method is that its objective consists of simple
sample averages. This enables us to establish a generalization error bound in terms of the Rademacher
complexity [15  22].
Denote εG(f ) := supg∈L2(p) J(f  g) − supg∈G J(f  g). Also  let RN
q (H) denote the Rademacher
complexity of a set of functions H over N random variables following probability density q (refer
to Appendix E for the deﬁnition). Proofs of the following theorems and corollary can be found in
Theorem 2. Assume that n1 = n2  (cid:101)n1 = (cid:101)n2  p1(x) = p2(x)  W := inf x∈X |µw(x)| > 0 
Appendix E  Appendix F  and Appendix G in the supplementary material.
MZ := supz∈Z |z| < ∞  MF := supf∈F x∈X |f (x)| < ∞  and MG := supg∈G x∈X |g(x)| < ∞.
(cid:35)
Then  the following holds with probability at least 1 − δ for every f ∈ F :

(cid:19)(cid:114)
:= 4MY MG + M 2G/2  Mw = 2MF MG + M 2G/2  and Rn (cid:101)n

(cid:18) Mz√
(cid:98)J(f  g) + Rn (cid:101)n
p(x w)(F ) + 2(MF + MG)R(cid:101)n

p(x z)(G) + 2(2MF + MG)R(cid:101)n

Ex∼p(x)[(f (x) − u(x))2] ≤ 1
W 2

where Mz
4MZ)Rn

F G := 2(MF +

p(x w)(G).

+ εG(f )

 

2(cid:101)n

F G +

Mw√

sup
g∈G

(cid:34)

log

2
δ

2n

+

In particular  the following bound holds for the linear-in-parameter models.
Corollary 1. Let F = {x (cid:55)→ α(cid:62)φ(x) | (cid:107)α(cid:107)2 ≤ ΛF}  G = {x (cid:55)→ β(cid:62)ψ(x) | (cid:107)β(cid:107)2 ≤ ΛG}.
Assume that rF := supx∈X (cid:107)φ(x)(cid:107) < ∞ and rG := supx∈X (cid:107)ψ(x)(cid:107) < ∞  where (cid:107)·(cid:107)2 is the
L2-norm. Under the assumptions of Theorem 2  it holds with probability at least 1 − δ that for every
f ∈ F  

Ex∼p(x)[(f (x) − u(x))2] ≤ 1
W 2

sup

g∈G

(cid:113)

(cid:98)J(f  g) +

Cz

(cid:113)

log 2
√

δ + Dz
2n

Cw

+

δ + Dw

log 2
√

2(cid:101)n

+ εG(f )

  

GΛ2

GΛ2

where Cz := r2
4rGΛGMY  and Dw := r2

G + 4rGΛGMY  Cw := 2r2

F Λ2
G/2 + 4rF rGΛF ΛG.

Theorem 2 and Corollary 1 imply that minimizing supg∈G (cid:98)J(f  g)  as the proposed method does 

amounts to minimizing an upper bound of the mean squared error. In fact  for the linear-in-parameter
models  it can be shown that the mean squared error of the proposed estimator is upper bounded by
√
O(1/

√(cid:101)n) plus some model mis-speciﬁcation error with high probability as follows.

F + 2rF rGΛF ΛG + r2

G  Dz := r2

G/2 +

n + 1/

GΛ2

GΛ2

6

Theorem 3 (Informal). Let (cid:98)f ∈ F be any approximate solution to inf f∈F supg∈G (cid:98)J(f  g) with

sufﬁcient precision. Under the assumptions of Corollary 1  it holds with probability at least 1− δ that

log

1
δ

+

2εF

G + εF
W 2

 

(13)

Ex∼p(x)[((cid:98)f (x) − u(x))2] ≤ O

(cid:18)(cid:18) 1√

n
G := supf∈F εG(f ) and εF := inf f∈F J(f ).

where εF

(cid:19)

(cid:19)

+

1√(cid:101)n

A more formal version of Theorem 3 can be found in Appendix G.

6 More General Loss Functions

Our framework can be extended to more general loss functions:

inf

f∈L2(p)

E[(cid:96)(µw(x)f (x)  2µz(x))] 

(14)
where (cid:96) : R × R → R is a loss function that is lower semi-continuous and convex with respect to
both the ﬁrst and the second arguments  where a function ϕ : R → R is lower semi-continuous if
lim inf y→y0 ϕ(y) = ϕ(y0) for every y0 ∈ R [30].2 As with the squared loss  a major difﬁculty in
solving this optimization problem is that the operand of the expectation has nonlinear dependency
on both µw(x) and µz(x) at the same time. Below  we will show a way to transform the objective
functional into a form that can be easily approximated using separately labeled samples.
From the assumptions on (cid:96)  we have (cid:96)(y  y(cid:48)) = supz∈R yz − (cid:96)∗(z  y(cid:48))  where (cid:96)∗(·  y(cid:48)) is the convex
conjugate of the function y (cid:55)→ (cid:96)(y  y(cid:48)) deﬁned for any y(cid:48) ∈ R as z (cid:55)→ (cid:96)∗(z  y(cid:48)) = supy∈R[yz −
(cid:96)(y  y(cid:48))] (see Rockafellar [30]). Hence 

E[(cid:96)(µw(x)f (x)  2µz(x))] = sup

g∈L2(p)

E[µw(x)f (x)g(x) − (cid:96)∗(g(x)  2µz(x))].

Similarly  we obtain E[(cid:96)∗(g(x)  2µz(x))] = suph∈L2(p) 2E[µz(x)h(x)]−E[(cid:96)∗
∗(y ·) is the convex conjugate of the function y(cid:48)
(cid:96)∗
∗(y  z(cid:48)) := supy(cid:48)∈R[y(cid:48)z − (cid:96)∗(y  y(cid:48))]. Thus  Eq. (14) can be rewritten as
(cid:96)∗

∗(g(x)  h(x))]  where
(cid:55)→ (cid:96)∗(y  y(cid:48)) deﬁned for any y  z(cid:48) ∈ R by

inf

f∈L2(p)

sup

g∈L2(p)

inf

h∈L2(p)

K(f  g  h) 

where K(f  g  h) := E[µw(x)f (x)g(x)] − 2E[µz(x)h(x)] + E[(cid:96)∗
∗(g(x)  h(x))]. Since µw and µz
appear separately and linearly  K(f  g  h) can be approximated by sample averages using separately
labeled samples.

7 Experiments

In this section  we test the proposed method and compare it with baselines.

7.1 Data Sets

We use the following data sets for experiments.
Synthetic data: Features x are drawn from the two-dimensional Gaussian distribution with mean
zero and covariance 10I2. We set p(y | x  t) as the following logistic models: p(y | x  t) =
1/(1 − exp(−ya(cid:62)
t x))  where a−1 = (10  10)(cid:62) and a1 = (10 −10)(cid:62). We also use the logistic
models for pk(t | x): p1(t | x) = 1/(1 − exp(−tx2)) and p2(t | x) = 1/(1 − exp(−t{x2 + b}) 
where b is varied over 25 equally spaced points in [0  10]. We investigate how the performance
changes when the difference between p1(t | x) and p2(t | x) varies.
Email data: This data set consists of data collected in an email advertisement campaign for promoting
customers to visit a website of a store [8  27]. Outcomes are whether customers visited the website
or not. We use 4 × 5000 and 2000 randomly sub-sampled data points for training and evaluation 
respectively.

2lim inf y→y0 ϕ(y) := limδ(cid:38)0 inf|y−y0|≤δ ϕ(y).

7

Jobs data: This data set consists of randomized experimental data obtained from a job training
program called the National Supported Work Demonstration [17]  available at http://users.nber.
org/~rdehejia/data/nswdata2.html. There are 9 features  and outcomes are income levels
after the training program. The sample sizes are 297 for the treatment group and 425 for the control
group. We use 4 × 50 randomly sub-sampled data points for training and 100 for evaluation.
Criteo data: This data set consists of banner advertisement log data collected by Criteo [18]
available at http://www.cs.cornell.edu/~adith/Criteo/. The task is to select a product to
be displayed in a given banner so that the click rate will be maximized. We only use records for
banners with only one advertisement slot. Each display banner has 10 features  and each product
has 35 features. We take the 12th feature of a product as a treatment variable merely because
it is a well-balanced binary variable. The outcome is whether the displayed advertisement was
clicked. We treat the data set as the population although it is biased from the actual population since
non-clicked impressions were randomly sub-sampled down to 10% to reduce the data set size. We
made two subsets with different treatment policies by appropriately sub-sampling according to the
predeﬁned treatment policies (see Appendix L in the supplementary material). We set pk(t | x) as
p1(t | x) = 1/(1 + exp(−t1(cid:62)x)) and p2(t | x) = 1/(1 + exp(t1(cid:62)x))  where 1 := (1  . . .   1)(cid:62).

7.2 Experimental Settings

We conduct experiments under the following settings.
Methods compared: We compare the proposed method with baselines that separately estimate
the four conditional expectations in Eq. (6). In the case of binary outcomes  we use the logistic-
regression-based (denoted by FourLogistic) and a neural-network-based method trained with the
soft-max cross-entropy loss (denoted by FourNNC). In the case of real-valued outcomes  the ridge-
regression-based (denoted by FourRidge) and a neural-network-based method trained with the squared
loss (denoted by FourNNR). The neural networks are fully connected ones with two hidden layers
each with 10 hidden units. For the proposed method  we use the linear-in-parameter models with
Gaussian basis functions centered at randomly sub-sampled training data points (see Appendix K for
more details).
Performance evaluation: We evaluate trained uplift models by the area under the uplift curve
(AUUC) estimated on test samples with joint labels as well as uplift curves [26]. The uplift curve of
an estimated individual uplift is the trajectory of the average uplift when individuals are gradually
moved from the control group to the treated group in the descending order according to the ranking
given by the estimated individual uplift. These quantities can be estimated when data are randomized
experiment ones. The Criteo data are not randomized experiment data unlike other data sets  but there
are accurately logged propensity scores available. In this case  uplift curves and the AUUCs can be
estimated using the inverse propensity scoring [3  20]. We conduct 50 trials of each experiment with
different random seeds.

7.3 Results

The results on the synthetic data are summarized in Figure 1. From the plots  we can see that all
methods perform relatively well in terms of AUUCs when the policies are distant from each other
(i.e.  b is larger). However  the performance of the baseline methods immediately declines as the
treatment policies get closer to each other (i.e.  b is smaller).3 In contrast  the proposed method
maintains its performance relatively longer until b reaches the point around 2. Note that the two
policies would be identical when b = 0  which makes it impossible to identify the individual uplift
from their samples by any method since the system in Eq. (5) degenerates. Figure 2 highlights their
performance in terms of the squared error. For FourNNC  test points with small policy difference
|p1(t = 1 | x) − p2(t = 1 | x)| (colored darker) tend to have very large estimation errors. On the
other hand  the proposed method has relatively small errors even for such points. Figure 3 shows
results on real data sets. The proposed method and the baseline method with logistic regressors
both performed better than the baseline method with neural nets on the Email data set (Figure 3a).

3The instability of performance of FourLogistic can be explained as follows. FourLogistic uses linear models 
whose expressive power is limited. The resulting estimator has small variance with potentially large bias. Since
different b induces different u(x)  the bias depends on b. For this reason  the method works well for some b but
poorly for other b.

8

Figure 1: Results on the synthetic data. The plot shows the aver-
age AUUCs obtained by the proposed method and the baseline
methods for different b. p1(t | x) and p2(t | x) are closer to
each other when b is smaller.

(a) Baseline (FourLogistic).

(b) Baseline (FourNNC).

(c) Proposed (MinMaxGau).

Figure 2: The plots show the squared errors of the estimated individual uplifts on the synthetic
data with b = 1. Each point is darker-colored when |p1(t = 1 | x) − p2(t = 1 | x)| is smaller  and
lighter-colored otherwise.

(a) The Email data.
Figure 3: Average uplifts as well as their standard errors on real-world data sets.

(b) The Jobs data.

(c) The Criteo data.

On the Jobs data set  the proposed method again performed better than the baseline methods with
neural networks. For the Criteo data set  the proposed method outperformed the baseline methods
(Figure 3c). Overall  we conﬁrmed the superiority of the proposed both on synthetic and real data
sets.

8 Conclusion

We proposed a theoretically guaranteed and practically useful method for uplift modeling or individual
treatment effect estimation under the presence of systematic missing labels. The proposed method
showed promising results in our experiments on synthetic and real data sets. The proposed framework
is model-independent: any models can be used to approximate the individual uplift including ones
tailored for speciﬁc problems and complex models such as neural networks. On the other hand  model
selection may be a challenging problem due to the min-max structure. Addressing this issue would be
important research directions for further expanding the applicability and improving the performance
of the proposed method.

9

0246810b0.0250.0000.0250.0500.0750.1000.1250.150AUUCThe Synthetic DataProposed (MinMaxGau)Baseline (FourNNC)Baseline (FourLogistic)0.00.20.40.60.81.0Proportion of Treated Individuals0.000.010.020.030.04Average UpliftUplift CurveProposed (MinMaxGau)Baseline (FourNNC)Baseline (FourLogistic)0.20.40.60.81.0Proportion of Treated Individuals0200400600800100012001400Average UpliftUplift CurveProposed (MinMaxGau)Baseline (FourNNR)Baseline (FourRidge)0.00.20.40.60.81.0Proportion of Treated Individuals0.0000.0020.0040.0060.0080.010Average UpliftUplift CurveProposed (MinMaxGau)Baseline (FourNNC)Baseline (FourLogistic)Acknowledgments

We are grateful to Marthinus Christoffel du Plessis and Takeshi Teshima for their inspiring suggestions
and for the meaningful discussions. We would like to thank the anonymous reviewers for their helpful
comments. IY was supported by JSPS KAKENHI 16J07970. JA and FY would like to thank
Adway for its support. MS was supported by the International Research Center for Neurointelligence
(WPI-IRCN) at The University of Tokyo Institutes for Advanced Study.

References
[1] E. Abrahams and M. Silver. The Case for Personalized Medicine. Journal of Diabetes Science and

Technology  3(4):680–684  July 2009.

[2] S. Athey  J. Tibshirani  and S. Wager. Generalized Random Forests. arXiv:1610.01271 [econ  stat] 

October 2016. arXiv: 1610.01271.

[3] P. C. Austin. An introduction to propensity score methods for reducing the effects of confounding in

observational studies. Multivariate behavioral research  46(3):399–424  2011.

[4] C. M. Bishop. Pattern Recognition and Machine Learning (Information Science and Statistics). Springer-

Verlag New York  Inc.  2006.

[5] P. Gutierrez and J. Y. Gérardy. Causal inference and uplift modelling: A review of the literature. In
Proceedings of The 3rd International Conference on Predictive Applications and APIs  volume 67 of
Proceedings of Machine Learning Research  pages 1–13. PMLR  11–12 Oct 2017.

[6] J. Hartford  G. Lewis  K. Leyton-Brown  and M. Taddy. Deep IV: A Flexible Approach for Counterfactual

Prediction. In International Conference on Machine Learning  pages 1414–1423  July 2017.

[7] J. L. Hill. Bayesian Nonparametric Modeling for Causal Inference. Journal of Computational and

Graphical Statistics  20(1):217–240  January 2011.

[8] K. Hillstrom. The minethatdata e-mail analytics and data mining challenge  2008. https://blog.

minethatdata.com/2008/03/minethatdata-e-mail-analytics-and-data.html.

[9] K. Imai and M. Ratkovic. Estimating treatment effect heterogeneity in randomized program evaluation.

The Annals of Applied Statistics  7(1):443–470  March 2013.

[10] G. W. Imbens. Instrumental Variables: An Econometrician’s Perspective. Statistical Science  29(3):

323–358  August 2014.

[11] M. Jaskowski and S. Jaroszewicz. Uplift modeling for clinical trial data. In ICML Workshop on Clinical

Data Analysis  2012.

[12] F. D. Johansson  U. Shalit  and D. Sontag. Learning Representations for Counterfactual Inference. In
Proceedings of the 33rd International Conference on Machine Learning  volume 48 of Proceedings of
Machine Learning Research  pages 3020–3029. JMLR  2016.

[13] S. H. Katsanis  G. Javitt  and K. Hudson. A Case Study of Personalized Medicine. Science  320(5872):

53–54  April 2008.

[14] R. Kohavi  R. Longbotham  D. Sommerﬁeld  and R. M. Henne. Controlled experiments on the web: survey

and practical guide. Data Mining and Knowledge Discovery  18(1):140–181  February 2009.

[15] V. Koltchinskii. Rademacher penalties and structural risk minimization. IEEE Transactions on Information

Theory  47(5):1902–1914  July 2001.

[16] S. R. Künzel  J. S. Sekhon  P. J. Bickel  and B. Yu. Meta-learners for Estimating Heterogeneous Treatment

Effects using Machine Learning. arXiv:1706.03461 [math  stat]  June 2017. arXiv: 1706.03461.

[17] R. J. LaLonde. Evaluating the econometric evaluations of training programs with experimental data. The

American economic review  pages 604–620  1986.

[18] D. Lefortier  A. Swaminathan  X. Gu  T. Joachims  and M. de Rijke. Large-scale validation of counterfactual
In NIPS Workshop on "Inference and Learning of Hypothetical and

learning methods: A test-bed.
Counterfactual Interventions in Complex Systems"  2016.

[19] G. Lewis and V. Syrgkanis. Adversarial Generalized Method of Moments. arXiv:1803.07164 [cs  econ 

math  stat]  March 2018. arXiv: 1803.07164.

10

[20] L. Li  W. Chu  J. Langford  and X. Wang. An unbiased ofﬂine evaluation of contextual bandit algorithms
with generalized linear models. In Proceedings of the Workshop on On-line Trading of Exploration and
Exploitation 2  volume 26 of Proceedings of Machine Learning Research  pages 19–36. PMLR  02 Jul
2012.

[21] S. Liu  A. Takeda  T. Suzuki  and K. Fukumizu. Trimmed density ratio estimation. In I. Guyon  U. V.
Luxburg  S. Bengio  H. Wallach  R. Fergus  S. Vishwanathan  and R. Garnett  editors  Advances in Neural
Information Processing Systems 30  pages 4518–4528. Curran Associates  Inc.  2017.

[22] M. Mohri  A. Rostamizadeh  and A. Talwalkar. Foundations of machine learning. MIT press  2012.

[23] X. Nguyen  M. J. Wainwright  and M. I. Jordan. Estimating divergence functionals and the likelihood ratio
by convex risk minimization. IEEE Transactions on Information Theory  56(11):5847–5861  Nov 2010.

[24] J. Pearl. Causality. Cambridge university press  2009.

[25] N. Radcliffe. Using control groups to target on predicted lift: Building and assessing uplift model. Direct

Marketing Analytics Journal  pages 14–21  2007.

[26] N. Radcliffe and P. Surry. Differential Response Analysis: Modeling True Responses by Isolating the

Effect of a Single Action. Credit Scoring and Credit Control IV  1999.

[27] N. J. Radcliffe. Hillstrom’s minethatdata email analytics challenge: An approach using uplift modelling.

Technical report  Stochastic Solutions Limited  2008.

[28] N. J. Radcliffe and P. D. Surry. Real-world uplift modelling with signiﬁcance-based uplift trees. White

Paper TR-2011-1  Stochastic Solutions  2011.

[29] R. Renault. Chapter 4 - Advertising in Markets. In Simon P. Anderson  Joel Waldfogel  and David
Strömberg  editors  Handbook of Media Economics  volume 1 of Handbook of Media Economics  pages
121–204. North-Holland  January 2015.

[30] R. T. Rockafellar. Convex Analysis. Princeton University Press  1970.

[31] D. B. Rubin. Causal inference using potential outcomes: Design  modeling  decisions. Journal of the

American Statistical Association  100(469):322–331  2005.

[32] P. Rzepakowski and S. Jaroszewicz. Decision trees for uplift modeling with single and multiple treatments.

Knowledge and Information Systems  32(2):303–327  2012.

[33] U. Shalit  F. D. Johansson  and D. Sontag. Estimating individual treatment effect: generalization bounds
and algorithms. In Doina Precup and Yee Whye Teh  editors  Proceedings of the 34th International
Conference on Machine Learning  volume 70 of Proceedings of Machine Learning Research  pages
3076–3085. PMLR  06–11 Aug 2017.

[34] M. Sugiyama  I. Takeuchi  T. Suzuki  T. Kanamori  H. Hachiya  and D. Okanohara. Conditional density
estimation via least-squares density ratio estimation. In International Conference on Artiﬁcial Intelligence
and Statistics  pages 781–788  2010.

[35] M. Sugiyama  T. Suzuki  and T. Kanamori. Density Ratio Estimation in Machine Learning. Cambridge

University Press  2012.

[36] S. Tufféry. Data mining and statistics for decision making  volume 2. Wiley Chichester  2011.

[37] S. Wager and S. Athey. Estimation and Inference of Heterogeneous Treatment Effects using Random

Forests. arXiv:1510.04342 [math  stat]  October 2015.

[38] M. Yamada  T. Suzuki  T. Kanamori  H. Hachiya  and M. Sugiyama. Relative density-ratio estimation for

robust distribution comparison. Neural Computation  25(5):1324–1370  2013.

11

,Ikko Yamane
Florian Yger
Jamal Atif
Masashi Sugiyama