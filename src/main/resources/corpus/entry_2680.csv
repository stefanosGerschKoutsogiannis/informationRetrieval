2019,Integrating Markov processes with structural causal modeling enables counterfactual inference in complex systems,This manuscript contributes a general and practical framework for casting a Markov process model of a system at equilibrium as a structural causal model  and carrying out counterfactual inference. Markov processes mathematically describe the mechanisms in the system  and predict the system’s equilibrium behavior upon intervention  but do not support counterfactual inference. In contrast  structural causal models support counterfactual inference  but do not identify the mechanisms. This manuscript leverages the benefits of both approaches. We define the structural causal models in terms of the parameters and the equilibrium dynamics of the Markov process models  and counterfactual inference flows from these settings. The proposed approach alleviates the identifiability drawback of the structural causal models  in that the counterfactual inference is consistent with the counterfactual trajectories simulated from the Markov process model. We showcase the benefits of this framework in case studies of complex biomolecular systems with nonlinear dynamics. We illustrate that  in presence of Markov process model misspecification  counterfactual inference leverages prior data  and therefore estimates the outcome of an intervention more accurately than a direct simulation.,Integrating Markov processes with structural causal modeling

enables counterfactual inference in complex systems

Robert Ness
Gamalon Inc.

robert.ness@gamalon.com

Kaushal Paneri

Northeastern University
kaushalpaneri@gmail.com

Olga Vitek

Northeastern University
o.vitek@northeastern.edu

Abstract

This manuscript contributes a general and practical framework for casting a Markov
process model of a system at equilibrium as a structural causal model  and carry-
ing out counterfactual inference. Markov processes mathematically describe the
mechanisms in the system  and predict the system’s equilibrium behavior upon
intervention  but do not support counterfactual inference. In contrast  structural
causal models support counterfactual inference  but do not identify the mechanisms.
This manuscript leverages the beneﬁts of both approaches. We deﬁne the structural
causal models in terms of the parameters and the equilibrium dynamics of the
Markov process models  and counterfactual inference ﬂows from these settings.
The proposed approach alleviates the identiﬁability drawback of the structural
causal models  in that the counterfactual inference is consistent with the counter-
factual trajectories simulated from the Markov process model. We showcase the
beneﬁts of this framework in case studies of complex biomolecular systems with
nonlinear dynamics. We illustrate that  in presence of Markov process model mis-
speciﬁcation  counterfactual inference leverages prior data  and therefore estimates
the outcome of an intervention more accurately than a direct simulation.

Introduction

1
Many complex systems contain discrete components that interact in continuous time  and maintain
interactions that are stochastic  dynamic  and governed by natural laws. For example  molecular
systems biology studies molecules (e.g.  gene products  proteins) in a living cell that interact according
to biochemical laws. An important aspect of studying these systems is predicting the equilibrium
behavior of the system upon an intervention  and selecting high-value interventions. For example 
we may want to predict the effect of a drug intervention on a new equilibrium of gene expression
[1  27]. The intervention may have a high value if reduces the expression of a speciﬁc gene  while
minimizing changes to the other genes.
Recent work in the reinforcement learning community has highlighted the utility of counterfactual
policy evaluation for evaluating and comparing interventions. Counterfactual policy evaluation uses
data from past experimental interventions to ask whether a higher value could have been achieved
under an alternative intervention [7  16  8  19]. Counterfactual inference answers this question by
predicting the outcome of the alternative intervention  conditional on the outcome of the intervention
for which the data were observed [7  21].
Predicting the outcome of an intervention requires us to model the system. In particular  discrete-state
continuous-time Markov process models unambiguously describe the changes of system components
across all the system states (i.e.  not only at equilibrium) in term of hazard functions [11  28]. A
Markov process model predicts the equilibrium upon an intervention by applying the intervention to
the initial conditions  performing multiple direct stochastic simulations to reach post-intervention
equilibriums  and averaging over these equilibriums. Markov process modeling is one way of
modeling complexity in biological systems  particularly in systems that are intrinsically stochastic
[1]. The Markov process models are called stochastic kinetic models in this context.

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

Unfortunately  Markov process models do not support counterfactual inference. Moreover  it is often
impossible to correctly specify a Markov process model of a complex system such as a biological
system  where many aspects of the underlying mechanism are unknown. Direct simulations from an
incorrectly speciﬁed model may incorrectly predict the outcomes of interventions.
An alternative class of models are structural causal models (SCMs). These probabilistic generative
causal models are attractive  in that they enable both interventional and counterfactual inference
[20]. Recent work used SCMs to model the transition functions in simple Markov decision process
models and apply counterfactual policy evaluation to the decisions (i.e. interventions) at each time
step [8  19]. Unfortunately  these approaches require outcome data at each time point. This limits
their use in situations where we are only interested in the outcome at equilibrium  and only collect
data once the equilibrium is reached.
Deﬁning SCM models at equilibrium directly is non-trivial  because multiple SCMs may be consis-
tent with the equilibrium distribution of the system components upon an intervention  but provide
contradictory answers to the same counterfactual query [20  23]. Recent work [6  18  5] connected a
broader class of dynamic models and SCMs  and established the conditions under which interventions
in dynamic simulations correspond to SCM’s predictions of equilibrium upon the interventions.
However  researchers lack practical examples that leverage this connection  and combine the beneﬁts
of these two approaches for counterfactual inference.
This manuscript builds on these prior results  and contributes a general and practical framework for
casting the equilibrium distribution Markov process model as an SCM model of equilibrium behavior.
The SCMs are deﬁned in terms of the structure and the hazard rates parameters of the Markov process
model  and counterfactual inference ﬂows from these settings. The proposed approach alleviates
the identiﬁability drawback of the SCMs  in that their counterfactual inference is consistent with
the counterfactual trajectories simulated from the Markov process model. We showcase the beneﬁts
of this approach in two studies of cell signal transduction with nonlinear dynamics. The ﬁrst is a
canonical model of the MAPK signaling pathway [17]. The second is a larger model that connects
the MAPK pathway to stimulus from growth factors [3]. We illustrate that  when the underlying
Markov process model is misspeciﬁed  counterfactual inference anchors intervention predictions to
past observed data  and makes selection of interventions more robust to model misspeciﬁcation.
2 Background
Discrete-state continuous-time Markov process models Discrete-state continuous-time Markov
process models describe the temporal interactions between the system components in terms of
abstract or physical processes  called rate laws  with real-valued parameters rates [11]. The rate laws
determine hazard functions  which provide instantaneous probabilities of state transitions.
A place invariant is a set of system components with an invariant sum. A minimal place invariant can
not be further reduced to smaller place invariants [9]. Deﬁne random variables X(t) = {Xi(t) : i ∈
1...J} representing the states of J minimal place invariant components in a Markov process model.
We use capital letters to refer to random variables  lower case letters to refer to instances of random
variables  normal font for a single variable  and boldface for a tuple of variables. Denote P
(t) the
probability distribution of X(t)  and P
(t) the marginal probability of Xi(t). A Markov process
model M is deﬁned by master equations  i. e. a coupled set of ordinary differential equations that
describe the rate of change of the probabilities of the states X(t) over time [29]:

M
Xi

M

(t)

= hi (t  vi  PAM i(t))   Xi(0) = (x0)i ∀i ∈ J

(1)

dP

M
Xi
dt

The function hi is the hazard function that determines the probability of a state change between
Xi(t) and Xi(s)  s > t. Here vi is a set of parameters of the rate laws  and x0 is an initial
condition. PAM i(t) ⊆ X(t) \ Xi(t) is the set of parents of variable Xi(t)  i.e. variables that
regulate Xi(t). Here we consider only Markov process models that converge to unique equilibrium
stationary distributions. If equilibrium exists  then limt→∞ dP
i the random
variable to which Xi(t) converges in distribution X∗
M the equilibrium
distribution of X∗  and P
Equilibrium distribution of a Markov process model as a generative model In the equilibrium
distribution the place invariants in a Markov process model factorizes into a set of conditional

the marginal probability of X∗
i .

dt = 0. We denote X∗

d
:= limt→∞ Xi. We denote P

M
Xi

M
X∗

i

(t)

i

2

probability distributions  with a causal ordering based on the solutions to the master equations (see
Supplementary materials for details). Based on this  the equilibrium distribution can be cast as a
causal generative model G that consists of [20  23]:

1. Random variables X = {Xi; i ∈ 1...J}: the states of the system

2. A directed acyclic graph D with nodes {i ∈ J} that impose an ordering on X.

Xi ∼ pi(PAD i  Ni) ∀i ∈ J where PAD i ⊆ X \ Xi are the parents of Xi in D.

3. A set of probabilistic generative functions for each variable Xi  p = {pi  i ∈ J} such that
G. This means that a procedure
G is a generative model that entails an observational distribution P
G. This is viewed
that ﬁrst samples from each pi along the ordering in D generates samples from P
as the generating process for the observed X. A primary contribution of this work is a method for
transforming G into and structural causal model.
Structural causal models (SCMs) A structural causal model C of the same system has the same
causal directed graph D  ordering the same random variables X. The model consists of [20  23]:

N on independent noise random variables N = {Ni; i ∈ J}
C
1. A distribution P
2. A set of functions f = {fi  i ∈ J} called structural assignments  such that

Xi = fi(PAC i  Ni) ∀i ∈ J where PAC i ⊆ X \ Xi are the parents of Xi in D.

M of X∗.

C. This is viewed as the generating process for the observed X.

G  the same observational distribution as G. For consistency  we
C when discussed in the context of C. This means that a procedure that
C
N  and then sets the values of X deterministically with f  generates

C is a generative model that entails P
refer to this distribution as P
ﬁrst samples noise values from P
samples from P
Interventions in Markov process models and in SCMs An SCM C uses ideal interventions  which
replace a random variable with a ﬁxed point value. These are represented with Pearl’s “do” notation
do(Xi = x) [10  22]  denoted. The intervention that sets Xi to x replaces the structural assignment
C;do(Xi=x) is entailed by C under
Xi = fi(PAC i  Ni) with Xi = x. The intervention distribution P
the intervention and is generally different from the equilibrium distribution P
In the context of a Markov process model  a typical intervention deﬁnition is that an intervention
increases a reaction rate (catalyzation) or decreases a reaction rate (inhibition). We deﬁne a type
of soft intervention [10] for Markov process models that make this rate manipulation comparable
to the SCM’s ideal intervention. We deﬁne a ﬁxed post-equilibrium expected value for a variable
that we want to achieve  then ﬁnd a change to the variables rate parameter values that achieve that
outcome. For example  an intervention that sets the equilibrium value of Xi to x does so by ﬁnding
manipulating Xi’s rate parameters to achieve this result. Borrowing the “do” notation  denote this
as do(X∗
i =x). We compare
C;do(Xi=x). For both Markov process models and SCMs 
intervention queries on P
the intervention queries are answered by sampling from these distributions. See Supplementary
materials for contrasts to related intervention modeling approaches.
Counterfactual inference in SCMs Counterfactual inference is the process of observing a random
outcome  making inference about the unseen causes of the outcome  and then inferring the outcome
that would have been observed under an intervention [23  26]. For example  an SCM C helps
answer the query “Having observed Xi = x  what would have happened under the intervention
do(Xi = ¬x)?". SCMs support the following algorithm for counterfactual inference [2]: (1) having
observed X = x  infer the noise distribution conditional on the observation P
  (2) replace
in C  (3) apply the intervention do(X = ¬x)  and (4) sample from the resulting
C
N with P
P
mutated model. The intuition is that in (2) we infer the latent initial conditions (values of N) that
could have lead to the outcome X = x  this information is encoded in P
  the posterior of N
given X = x. We then pass that encoded information to the counterfactual world where X is set to
¬x and play out scenarios in that world by sampling from P
and deriving downstream variables
given those noise values. Thus the algorithm mutates C into an SCM entailing the counterfactual
distribution P

M;do(X∗

i =x) to P

i = x). Let the equilibrium distribution under intervention be P

M;do(X∗

C;X=x
N

C;X=x
N

C;X=x
N

C;X=x do(X=¬x).

C;X=x
N

3

3 Methods

3.1 Motivating example

This manuscript contributes a practical framework for casting Markov process models of a system
observed at equilibrium as an SCM  for the purposes of conducting counterfactual inference. As a
motivating example  we consider a system of three biomolecules (i.e.  components) X1  X2 and Y.
Each component takes two states: active (“on") and inactive (“off"). Component X1 in the “on" state
activates Y; component X2 in the “on" state deactivates Y  as shown in the causal diagram [1] below:

Xon
1 + Yoff

v1→ Xon

1 + Yon and Xon

2 + Yon

v2→ Xon

2 + Yoff

(2)

Let X1(t)  X2(t)  and Y (t) be the total number of active-state particles of X1  X2  and Y at time t.
Assume that each component has T = 100 particles in total  such that T − Y (t) is the number of
inactive particles of Y at time t  and that each component is initialized with 100 off-state particles.
To ensure that the equilibrium distribution of the Markov process model M has a closed-form
solution  we limit this work to M with zero or ﬁrst-order hazard functions (i.e. hazard functions
for which outputs are either constant or directly proportional to a product of the inputs) [15  29].
In this example  the hazard functions assume mass action kinetics [13]  a common assumption in
biochemical modeling. Let h1(Y (t)) and h2(Y (t)) denote stochastic rate laws for the activation and
deactivation of Y  expressing the probabilities that the reactions occur in the instant (t  t + dt]. Then 
according to a ﬁrst-order stochastic kinetic assumption of chemical reactions [28]  h1 and h2 are

h1(Y (t)) = v1X1(t)(T − Y (t)) and h2(Y (t)) = v2X2(t)Y (t)

(3)
The hazard functions are parameterized by v = {v1  v2} regulating X1 and X2  and by the initial
states.
The Kolmogorov forward equations determine the change in P

dP

M
Y (t)
dt =

h1(Y (t) − 1)P

Y (t)−1 − h1(Y (t))P
M

M
Y (t)

+

(cid:17)

(cid:16)

M
Y (t) as the system evolves in time:
Y (t)+1 − h2(Y (t))P
M
M
Y (t)

h2(Y (t) + 1)P

(cid:17)

(4)

(cid:16)

We pose a counterfactual query “Having observed X1 = 34  X2 = 45  Y = 56  what would Y have
been if X1 was set to 50"?

3.2 Converting a Markov process model into an SCM

Algorithm 1 summarizes the proposed steps of converting the Markov process model into an SCM.
The steps are a series of mathematical derivations (as opposed to a pseudocode for a computational
implementation). Below we illustrate these steps for the component Y in the motivating example.
Additional mathematical details are available in Supplementary materials.

M

dt

dP

(t)

(t) :=(cid:82)

Algorithm 1 Convert Markov process into SCM
Inputs: Markov process model M
Structural causal model C
Output:
1: procedure GETSCM(M)
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:

(cid:73) Solve master equation
M
P
)dt
(cid:73) Find the equilibrium distribution
M
= limt→∞ P
P
(cid:73) Use P
G := {x ∼ P
M}
(cid:73) Convert the generative model to an SCM
(cid:73) that entails P
M
C :=
return C

M to deﬁne generative model G

(cid:26) N ∼ P

X = f (X  N)

C ≈ P

M

(t)

C
N

: P

t

Algorithm 2 Counterfactual inference on SCM
Inputs: Prior distribution on exogenous noise NPrior

Structural causal model C
Observed endogenous variables X = x
Counterfactual interventions X = ¬x
Desired sample size ssize

C;X=x do(X:=¬x)

Output: ssize samples from P
1: procedure CFQUERY(C  NPrior  x  ¬x  ssize)
2:
3:
4:
5:
6:
7:

(cid:73) Create “observation" and “intervention" models
obsModel ← Condition(C  X = x)
intModel ← Do(C  X = ¬x)
(cid:73) Infer noise distribution with observation model
NPosterior ← Infer(obsModel  NPrior)
(cid:73) Simulate from intervention model w/ updated

samples = array(ssize)
for i in (0:ssize) do

samples[i] ← intModel(NPosterior)

M

noise

8:
9:
10:
11:

return samples

4

Solve the master equation (Algo. 1 line 3). We can arrive at the solution for P
indirectly by solving the ordinary differential equation on the expectation of Y (t) over P

M
Y (t) in Eq. (4)

M
Y (t):

(5)

(6)

E(Y (t)) = v1X1(t)T − (v1X1(t) + v2X2(t)) E(Y (t))

d
dt

This has an analytical solution  where:

E(Y (t))

= e−t(v1X1(t)+v2X2(t)) +

T

v1X1(t)

v1X1(t) + v2X2(t)

Finally  Y (t) is a count of binary state variables with the same probability of being activated at a
M
Y (t) must be Binomial distribution with T trials  and trial probability E(Y (t))
given instant. Then P
.
Find the equilibrium distribution (Algo. 1 line 5). Taking the limit in time of Eq. (6):

T

E(Y )

T

= lim
t→∞

E(Y (t))

T

=

v1X1(t)

v1X1(t) + v2X2(t)

(7)

v1X1(t)

T

M
X1

and P

Thus at equilibrium Y follows the Binomial probability distribution with parameter

G := {X1 ∼ Binom(T  θX1); X2 ∼ Binom(T  θX2); Y ∼ Binom(T  θY (X1  X2))}

v1X1(t)+v2X2(t).
M to deﬁne generative model G (Algo. 1 line 7). Let θX1 and θX1 be the probability
Use P
M
. Let θY (X1  X2) = E(Y )
be the
parameters for the equilibrium Binomial distributions P
X2
M
Y . Deﬁne a generative model G:
probability parameter for the equilibrium Binomial distribution P
(8)
M (Algo. 1 line 10). We rely on a method
Convert the generative model to an SCM that entails P
of monotonic conversion  which restricts the class of possible SCMs to those with a common set
of identiﬁable counterfactual quantities (such as the probability of necessity  i.e. the probability
that Y would not have been activated without X1) [20]. For each structural assignment Xi =
|
fi(PAC i  Ni) ∀i ∈ J the method enforces the property E[Xi
| do(PAC i = y)] ≥ E[Xi
do(PAC i = y(cid:48))] ⇒ fi(y  ni) ≥ fi(y(cid:48)  ni)∀ni.
For this example we selected a monotonic conversion by means of the inverse CDF transform. Denote
F −1(u  n  p) the inverse CDF of the Binomial distribution  where 0 < u < 1  and n (number of
trials) and p (success probability) are the parameters of the Binomial distribution. Then the SCM C
that entails P
(9)

C :=(cid:8)X1 = F −1(NX1  T  θX1 ); X2 = F −1(NX2  T  θX2); Y = F −1(NY   T  θY (X1  X2))(cid:9)

ind∼ Uniform(0  1);

M is deﬁned as

NX1   NX2  NY

For larger models such as in Case studies 1 and 2 thereafter  it may be desirable to work with alternative
transforms that are more amenable to gradient-based inference such as stochastic variational inference.

3.3 Counterfactual inference and evaluation
Algorithm 2 details the counterfactual inference on C. Algorithms 3 and 4 in Supplementary materials
detail the evaluation. The evaluation stems from the insight that noise at the equilibrium captures
the stochasticity in the Markov process trajectories. Therefore  we repeatedly simulate pairs of the
trajectories with and without the counterfactual intervention  with a same random seed in a pair  such
that each pair has an identical stochastic component. We then compare the differences in the values
of these pairs at equilibrium to the differences between the original and the intervened-upon values
projected by the SCM. These differences estimate the respective causal effects. The algorithms differ
in choosing a deterministic or a stochastic approach for the estimation of causal effects. To ensure
scalability to large models and the ability to do inference over a broad set of structural assignments 
we implemented the algorithms in PyTorch and the probabilistic programming language Pyro [4].
The code and the runtime data are in Supplementary materials.

4 Case studies

4.1 Case Study 1: The MAPK signaling pathway

The system The mitogen-activated protein kinase (MAPK) pathway is important in many biological
processes  such as determination of cell fate. It is a cascade of three proteins  a MAPK  a MAPK

5

activation hazard
deactivation hazard

MAP3K
K3E1(TK3 − K3(t))
vact
K3 K3(t)
vinh

MAP2K
K2K3(TK2 − K2(t))
vact
K2 K2(t)
vinh

MAPK
K K2(TK − K(t))
vact
K K(t)
vinh

Table 1: The hazard functions in Case study 1 (MAPK)  speciﬁed according to mass action enzyme kinetics.

E1 → MAP3K → MAP2K → MAPK

kinase (MAP2K)  and a MAPK kinase kinase (MAP3K)  represented with a causal diagram [14  24]
(10)
Here E1 is an input signal to the pathway. The cascade relays the signal from one protein to the next
by changing the count of proteins in an active state.
The biochemical reactions A protein molecule is in an active state if it has one or more attached
phosphoryl groups. Each arrow in Eq. (10) combines the reactions of phosphorylation (i.e.  activation)
and dephosphorylation (i.e.  desactivation). For example  E1 → MAP3K combines two reactions

K3  vact

K2  vact

K3   vinh

K2   vinh

E1 + MAP3K vact

K3→ E1 + P-MAP3K and P-MAP3K vinh

K3→ MAP3K

K and deactivation rate parameters vinh

(11)
In the ﬁrst reaction in Eq. (11)  a particle of the input signal E1 binds (i.e.  activates) a molecule
of MAP3K to produce MAP3K with an attached phosphoryl. The rate parameter associated with
this reaction is vact. In the second reaction  phosphorylated MAP3K loses its phosphoryl (i.e. 
deactivates)  with the rate vinh. The remaining arrows in Eq. (10) aggregate similar reactions and
rate pairs.
The mechanistic model Let K3(t)  K2(t) and K(t) denote the counts of phosphorylated MAP3K 
MAP2K  and MAPK at time t. Let TK3  TK2  and TK represent the total amount of each of the three
proteins  and E1 the total amount of input  which we assume are constant in time. We model the
system as a continuous-time discrete-state Markov process M with hazard rates functions in Table 1.
The data We simulated the counts of protein particles using the Markov process model with rate
parameters vact
K . We conducted three
simulation experiments with three sets of rates  all consistent with a low concentration in a cell-sized
volume (see Supplementary materials). The initial conditions assumed 1 particle of E1  100 particles
of the unphosphorylated form of each protein  and 0 particles of the phosphorylated form.
The counterfactual of interest Let K3  K2 and K denote the observed counts of phosphorylated
MAP3K  MAP2K  and MAPK at 100 seconds  the time corresponding to an equilibrium for all the
rates. Let K3(cid:48) be the count of phosphorylated MAP3K generated by a 3 times smaller vact
K3. Thus
v(cid:48) = [vact
K ]. We pose the counterfactual question: “Having observed
the equilibrium particle counts K3  K2 and K  what would have been the count of K if we had K3(cid:48)?”.
The evaluation We derive the SCM C of the Markov process model and evaluate the counterfactual
where x(cid:48) is the expected equilibrium value associated with
distribution P
v(cid:48). We evaluate this counterfactual statement as described in Algorithms 3 and 4 (with 500 seeds). If
the counterfactuals from the converted SCMs are consistent with the Markov process models  their
histograms from Algorithms 3 and 4 should overlap.
The evaluation under model misspeciﬁcation We consider the Markov process model M with the
ﬁrst set of rates (see Supplementary materials). Let [x  y  z] be sampled from M. Next  instead of the
correct model we consider a misspeciﬁed model M(cid:48)  where vact
K2 is perturbed with noise sampled from
Uniform(0.1  0.5). We denote as C(cid:48) the SCM corresponding to M(cid:48)  and evaluate the counterfactual
distribution P
. We expect that  since the counterfactual distribution from
C(cid:48) incorporates the data from the correct model  it should be closer to the true causal effect simulated
from M than the direct simulation from the misspeciﬁed M(cid:48). We repeat this experiment 50 times.

C(cid:48);K3=x K2=y K=z do(K3=x(cid:48))
K3

C;K3=x K2=y K=z do(K3=x(cid:48))
K3

K3/3  vinh

K3   vact

K2  vinh

K2   vact

K   vinh

4.2 Case Study 2: The IGF signaling system

The system The growth factor signaling system is involved in growth and development of tissues.
When external stimuli activate the epidermal growth factor (EGF) or the insulin-like growth factor
(IGF)  this triggers a cascade [3] in Fig. (1)(a). The Raf-Mek-Erk pathway is equivalent to Eq. (10) 
renamed to follow the convention adopted by the biological literature in this context.
The biochemical reactions All the edges in Fig. (1)(a) represent enzyme reactions E + S v→ E +
P  where the change of substrate S to product P is catalyzed by enzyme E. As in Case study 1  the

6

Ras-SOS = vact

pointed edges combine activation and deactivation. The ﬂat-headed edges only represent deactivation.
The mechanistic model is built similarly to Case study 1.
The data We simulated the counts of protein particles using the Markov process model with rates
in Supplemental Tables 2 and 3. The other settings are as in Case study 1. The initial condition
assumed 37 particles of EGFR  5 particles of IGFR  100 particles of the unphosphorylated form of
other proteins  and 0 particles of the phosphorylated form.
The counterfactual of interest Let R(cid:48) be the number of phosphorylated particles of Ras at equilib-
rium  achieved with v(cid:48)act
Ras-SOS/6. We pose the counterfactual: Having observed the number
of phosphorylated particles of each protein before the intervention  what would be the number of
particles of Erk if the intervention had ﬁxed Ras = R(cid:48)? Unlike the MAPK pathway  where the
intervention on MAP3K affects the counterfactual target MAPK through a direct path  this system
has two paths from Ras to Erk. One path goes directly through Raf  and the other through a mediating
path PI3K → AKT. This challenges the algorithm to address multiple paths of inﬂuence.
The evaluation We consider the rates vact
and the Algorithms 3 and 4 (with 300 seeds).
The evaluation under model misspeciﬁcation We consider Markov process model M with the same
rates and initial conditions as above. Let xi be sampled from M. We then introduce a misspeciﬁed
model M(cid:48)  where vact
AKT-PI3K is perturbed with noise sampled from Uniform(0.01  0.1). We denote as
C(cid:48);Xi=xi do(Ras=R(cid:48))
C(cid:48) the SCM corresponding to M(cid:48)  and evaluate the counterfactual distribution P
.
Erk
The resulting counterfactual distribution from C(cid:48) should be closer to the true causal effect simulated
from M than the direct simulation from the misspeciﬁed M(cid:48). We repeat this experiment 50 times.

Ras-SOS/6  the counterfactual distribution P

C;Xi=xi do(Ras=R(cid:48))
Erk

 

(a)

(b)

(c)

Figure 1: Case study 2 (IGF). (a) IGF signaling. The top nodes are receptors for the epidermal growth factor
(EGF) and the insulin growth factor (IGF). Downstream of the receptors are several canonical signaling pathways
(including Raf-Mek-Erk  a renamed equivalent of Eq. (10)). Each reaction has a single rate parameter. The
auto-deactivation reactions are not pictured. (b) Deterministic and stochastic trajectories of the active-state
proteins in the system. Horizontal lines are the expected values at equilibrium. (c) Histogram of causal effects 
deﬁned as differences between the “observed" and the “counterfactual" trajectories of ERK at equilibrium.

5 Results
5.1 Case Study 1: The MAPK signaling pathway

M

Solve stochastic process’s master equation (Algorithm 1 line 3). As in the motivating example  we
indirectly solve dP
by way of the solving the forward equations for the expectation. For K3(t)
this is dE(K3(t))
K3 E(K3(t))) (Added Expectation in RHS  please
review). We derive similar forward equations for K2(t) and K(t). We solve the ODE above:

K3 E1(TK3 − E(K3(t)) − vinh

= vact

(t)

dt

dt

E(K3(t))

TK3

= e−t(vact

K3 E1+vinh

K3 ) +

and obtain the equilibrium by taking the limit t → ∞. The ﬁrst term in Eq. (12) goes to 0:

K3 E1
vact

K3 E1 + vinh
vact
K3

E(K3)

TK3

=

K3 TK3E1
vact
K3 E1 + vinh
vact
K3

7

(12)

(13)

EGFIGFnucleusRafPPRafAktPP2AMekErkRasSOSPI3Kp90RasGapcell wallFind the equilibrium distribution (Algorithm 1 line 5) As in Sec. 3.2)  the each active-state MAPK
protein has a Binomial marginal distribution. Let θK3(E1) denote the probability that a MAP3K
particle is active at equilibrium given E1. After solving the master equation 

K3 E1 + vinh
vact
K3
Extending this solution to MAP2K and MAPK leads to probabilities

TK3

θK3(E1) =

E(K3)

=

K3 E1
vact

(14)

(15)

K K2
vact

K K2 + vinh
vact

K

θK3(E1) =

K3 E1
vact

K3 E1 + vinh
vact
K3

; θK2(K3) =

K2 K3
vact

K2 K3 + vinh
vact
K2

; θK(K2) =

M
K3:

K2 ≡ Binomial(TK2  θK2(K3)); P
M

K ≡ Binomial(TK  θK(K2)) (16)
M
M to deﬁne generative model G (Algorithm 1 line 7). From here it is straightforward to create

and the following equilibrium distributions:
K3 ≡ Binomial(TK3  θK3(E1)); P
M
P
Use P
a generative model that entails P
G := {K3 ∼ Binom(TK3  θK3(E1)); K2 ∼ Binom(TK2  θK2(K3)); K ∼ Binom(TK  θK(K2))} (17)
M (Algorithm 1 line 10). Here the
Convert the generative model to an SCM that entails P
challenge is in expressing the stochasticity in G  while deﬁning K3  K2  K as deterministic functions
of the noise variables NK  NK2  NK3. Instead of using the inverse binomial CDF  we demonstrate the
use of a differentiable monotonic conversion  so that we can validate approximate counterfactual
inference with stochastic gradient descent. We achieve this by ﬁrst applying a Gaussian approximation
to the Binomial distribution  and then applying the “reparameterization trick" used in variational
autoencoders [25] (combined in helper function q in Eq. (18)).

(18)
C := {K3 = q(θK3(E1)  TK3  NK3); K2 = q(θK2(K3)  TK2  NK2); K = q(θK(K2)  TK  NK)} (19)

ind∼ N (0  1); q(θ  T  N ) = N · (T θ(1 − θ))1/2 + θT

NK  NK2  NK3

The Gaussian approximation facilitates the gradient-based inference in line 6 of Algorithm 2. Despite
the approximation  the resulting SCM is still deﬁned in terms of θ. In this manner the SCM retains
the biological mechanisms and the interpretation of the Markov process model.
Create “observation" and “intervention" models (Algorithm 2 lines 3-4) In a probabilistic pro-
gramming language  the deterministic functions in Eq. (19) are speciﬁed with a Dirac Delta dis-
tribution. However  at the time of writing  gradient-based inference in Pyro produced errors when
conditioning on a Dirac sample. We relaxed the Dirac Delta to allow a small amount of density.

(a)

(b)

Figure 2: Case study 1 (MAPK). (a) Deterministic and stochastic trajectories of the active-state MAPK
proteins. Horizontal lines are the expected values at equilibrium. (b) Histograms of causal effects  deﬁned as
differences between the “observed" and the “counterfactual" trajectories of MAP3K at equilibrium.

Infer noise distribution with observation model (Algorithm 2 line 6) We use stochastic variational
inference ([12]) to infer and update NK3  NK2 and NK from the observation model  and independent
Normal distributions as approximating distributions.
Simulate from intervention model with updated noise (Algorithm 2 line 10) After updating the
noise distributions  we generate the target distribution of the intervention model.
Deterministic and stochastic counterfactual simulation and evaluation (Algorithms 3 and 4 in
Supplementary materials). Fig. (2)(a) illustrates that the simulated trajectories converge in steady state.

8

Since we rely on the Gaussian approximation to the Binomial in constructing C  we would expect
worse results if we were to set the rates on or near the boundaries 0 and 100  where the approximation
is weak. Fig. (2)(b) shows that for each experiment with different sets of rates  the causal effects from
the SCM’s counterfactual distribution are centered around the ground truth simulated deterministically
using Eq. (12) and similar equations for K2 and K. The SCM’s distribution has less variance  likely
due to the fact that ideal interventions in the SCM allow less variation than rate-manipulation-based
interventions in the Markov process model.
Evaluation under model misspeciﬁcation Fig. (3)(a) shows histograms from one of the 50 repeti-
tions of the experiment conducted to evaluate the robustness of the SCM under model misspeciﬁcation 
and illustrates that the causal effects from the misspeciﬁed SCM is closer to true causal effect than
the causal effect derived from a direct but misspeciﬁed simulation. Over the 50 repetitions  the
absolute difference between the median of the true causal effect and the causal effect derived from
the misspeciﬁed SCM is on average 0.343. The absolute difference between the median of the true
causal effect and misspeciﬁed direct simulation is on average 1.03.
5.2 Case Study 2: The IGF signaling system
The derivations for the growth factor signaling system align closely with that of the motivating
example and of the MAPK model. For variable Xi with parents PAM i  we partition each parent set
into activators and inhibitors PAM i = {PAactM i  PAinhM i}. The rate parameters are also partitioned
into v = {vact  vinh}. For each Xi the probability for particle activation at equilibrium is:

vactPAactM i

vactPAactM i + vinhPAinhM i

θXi(PAM i) =

(20)

Next  we derive an SCM using the same Normal approximation to the Binomial distribution as in the
MAPK pathway. Fig. (1)(b) plots deterministic and stochastic time courses for active states counts of
the proteins in the pathway. Fig. (1)(c) illustrates that the counterfactual inference was successful
despite the increased model complexity and size.
The evaluation under model misspeciﬁcation Similarly to Case study 1  Fig. (3)(b) illustrates that
the causal effects from the misspeciﬁed SCM are closer to the true causal effect than the causal effect
derived from a direct but misspeciﬁed simulation. Over the 50 repetitions  the absolute difference
between the median of the true causal effect and the causal effect derived from the misspeciﬁed
SCM is on average 7.563. The absolute difference between the median of the true causal effect and
misspeciﬁed direct simulation is on average 92.55.

Figure 3: Histograms of causal effects  i.e. differences between the “observed" and the “counterfactual"
trajectories at equilibrium  for one repetition of the evaluation. The causal effect from the misspeciﬁed SCM
(blue histogram) is closer to true causal effect (orange histogram) than the causal effect derived from a direct but
misspeciﬁed simulation (green histogram). (a) MAPK  (b) IGF.
6 Discussion
This work proposed a practical approach for casting a Markov process model of a system at equi-
librium as an SCM. Equilibrium counterfactual inferences using this SCM are anchored to the rate
laws of the Markov process. We derived the speciﬁc steps of conducting counterfactual inference
in real-life case studies of biochemical networks. The case studies illustrate that the counterfactual
inference is consistent with the differences in the initial and the intervened upon trajectories of the
Markov process  and makes the selection of interventions more robust to model misspeciﬁcation.
This approach opens many opportunities for future methodological research  such as extending this
approach to models with cycles  a common feature of complex systems. Overall  this work is a step
towards broader adoption of counterfactual inference in systems biology and other applications.

9

References
[1] U. Alon. An Introduction to Systems Biology. CRC press  2006.

[2] A. Balke and J. Pearl. Counterfactual probabilities: Computational methods  bounds and
applications. In Proceedings of the Conference on Uncertainty in Artiﬁcial Intelligence  1994.

[3] F. Bianconi  E. Baldelli  V. Ludovini  L. Crinò  A. Flacco  and P. Valigi. Computational model
of EGFR and IGF1R pathways in lung cancer: A systems biology approach for translational
oncology. Biotechnology Advances  30:142  2012.

[4] E. Bingham  J. P. Chen  M. Jankowiak  F. Obermeyer  N. Pradhan  T. Karaletsos  R. Singh 
P. Szerlip  P. Horsfall  and N. D. Goodman. Pyro: Deep universal probabilistic programming.
arXiv:1810.09538  2018.

[5] T. Blom  S. Bongers  and J. M. Mooij. Beyond structural causal models: Causal constraints

models. Proceedings of the Conference on Uncertainty in Artiﬁcial Intelligence  2019.

[6] S. Bongers and J. M. Mooij. From random differential equations to structural causal models:

The stochastic case. arXiv:1803.08784  2018.

[7] L. Bottou  J. Peters  J. Quiñonero-Candela  D. X. Charles  D. M. Chickering  E. Portugaly 
D. Ray  P. Simard  and E. Snelson. Counterfactual reasoning and learning systems: The example
of computational advertising. The Journal of Machine Learning Research  14:3207  2013.

[8] L. Buesing  T. Weber  Y. Zwols  S. Racaniere  A. Guez  J.-B. Lespiau  and N. Heess. Woulda 

coulda  shoulda: Counterfactually-guided policy search. arXiv 1811.06272  2018.

[9] L. E. Dubins and D. A. Freedman. Invariant probabilities for certain Markov processes. The

Annals of Mathematical Statistics  37:837  1966.

[10] F. Eberhardt and R. Scheines. Interventions and Causal Inference. Philosophy of Science 

74:981  2007.

[11] R. Hilborn and M. Mangel. The Ecological Detective: Confronting Models with Data (MPB-28).

Princeton University Press  1997.

[12] M. Hoffman  D. M. Blei  C. Wang  and J. Paisley.

arXiv:1206.7051  2012.

Stochastic variational inference.

[13] F. Horn and R. Jackson. General mass action kinetics. Archive for rational mechanics and

analysis  47:81  1972.

[14] C.-Y. F. Huang and J. E. Ferrell. Ultrasensitivity in the mitogen-activated protein kinase cascade.

Proceedings of the National Academy of Sciences  93:10078  1996.

[15] Tobias Jahnke and Wilhelm Huisinga. Solving the chemical master equation for monomolecular

reaction systems analytically. Journal of mathematical biology  54(1):1–26  2007.

[16] T. Joachims and A. Swaminathan. Counterfactual evaluation and learning for search  recom-
mendation and ad placement. In Proceedings of the 39th International ACM SIGIR conference
on Research and Development in Information Retrieval  page 1199. ACM  2016.

[17] E. K. Kim and E. Choi. Pathological roles of MAPK signaling pathways in human diseases.

Biochimica et Biophysica Acta (BBA) - Molecular Basis of Disease  1802:396  2010.

[18] J. M. Mooij  D. Janzing  and B. Schölkopf. From ordinary differential equations to structural

causal models: The deterministic case. arXiv:1304.7920  2013.

[19] M. Oberst and D. Sontag. Counterfactual off-policy evaluation with Gumbel-Max structural

causal models. arXiv preprint arXiv:1905.05824  2019.

[20] J. Pearl. Causality: Models  Reasoning and Inference. Cambridge University Press  2009.

[21] J. Pearl. The algorithmization of counterfactuals. Annals of Mathematics and Artiﬁcial

Intelligence  61:29  2011.

10

[22] J. Pearl. On the interpretation of do(x). Journal of Causal Inference  2019.

[23] J. Peters  D. Janzing  and B. Schölkopf. Elements of Causal Inference: Foundations and

Learning Algorithms. MIT press  2017.

[24] L. Qiao  R. B. Nachbar  I. G. Kevrekidis  and S. Y. Shvartsman. Bistability and oscillations in

the Huang-Ferrell model of MAPK signaling. PLoS computational biology  3:e184  2007.

[25] D. J. Rezende  S. Mohamed  and D. Wierstra. Stochastic backpropagation and approximate

inference in deep generative models. arXiv:1401.4082  2014.

[26] N. J. Roese. Counterfactual thinking. Psychological bulletin  121:133  1997.

[27] J. J Tyson  K. C. Chen  and B. Novak. Sniffers  buzzers  toggles and blinkers: Dynamics of
regulatory and signaling pathways in the cell. Current Opinion in Cell Biology  15:221  2003.

[28] D. J. Wilkinson. Stochastic Modelling for Systems Biology. Chapman and Hall/CRC  2006.

[29] D. J. Wilkinson. Stochastic modeling for quantitative description of heterogeneous biological

systems. Nature Reviews Genetics  10:122  2009.

11

,Robert Ness
Kaushal Paneri
Olga Vitek