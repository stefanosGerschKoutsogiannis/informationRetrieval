2012,Mixing Properties of Conditional Markov Chains with Unbounded Feature Functions,Conditional Markov Chains (also known as Linear-Chain Conditional Random Fields  in the literature) are a versatile class of discriminative models for the distribution of a sequence of hidden states conditional on a sequence of observable variables. Large-sample properties of Conditional Markov Chains have been first studied by Sinn and Poupart [1]. The paper extends this work in two directions: first  mixing properties of models with unbounded feature functions are being established; second  necessary conditions for model identifiability and the uniqueness of maximum likelihood estimates are being given.,Mixing Properties of Conditional Markov Chains

with Unbounded Feature Functions

Mathieu Sinn

IBM Research - Ireland
Mulhuddart  Dublin 15

mathsinn@ie.ibm.com

Bei Chen

McMaster University

Hamilton  Ontario  Canada

bei.chen@math.mcmaster.ca

Abstract

Conditional Markov Chains (also known as Linear-Chain Conditional Random
Fields in the literature) are a versatile class of discriminative models for the dis-
tribution of a sequence of hidden states conditional on a sequence of observable
variables. Large-sample properties of Conditional Markov Chains have been ﬁrst
studied in [1]. The paper extends this work in two directions: ﬁrst  mixing prop-
erties of models with unbounded feature functions are being established; second 
necessary conditions for model identiﬁability and the uniqueness of maximum
likelihood estimates are being given.

1

Introduction

Conditional Random Fields (CRF) are a widely popular class of discriminative models for the dis-
tribution of a set of hidden states conditional on a set of observable variables. The fundamental
assumption is that the hidden states  conditional on the observations  form a Markov random ﬁeld
[2 3]. Of special importance  particularly for the modeling of sequential data  is the case where the
underlying undirected graphical model forms a simple linear chain. In the literature  this subclass
of models is often referred to as Linear-Chain Conditional Random Fields. This paper adopts the
terminology of [4] and refers to such models as Conditional Markov Chains (CMC).
Large-sample properties of CRFs and CMCs have been ﬁrst studied in [1] and [5]. [1] deﬁnes CMCs
of inﬁnite length and studies ergodic properties of the joint sequences of observations and hidden
states. The analysis relies on fundamental results from the theory of weak ergodicity [6]. The
exposition is restricted to CMCs with bounded feature functions which precludes the application 
e.g.  to models with linear features and Gaussian observations.
[5] considers weak consistency
and central limit theorems for models with a more general structure. Ergodicity and mixing of the
models is assumed  but no explicit conditions on the feature functions or on the distribution of the
observations are given. An analysis of model identiﬁability in the case of ﬁnite sequences can be
found in [7].
The present paper studies mixing properties of Conditional Markov Chains with unbounded feature
functions. The results are fundamental for analyzing the consistency of Maximum Likelihood es-
timates and establishing Central Limit Theorems (which are very useful for constructing statistical
hypothesis tests  e.g.  for model misspeciﬁciations and the signﬁcance of features). The paper is or-
ganized as follows: Sec. 2 reviews the deﬁnition of inﬁnite CMCs and some of their basic properties.
In Sec. 3 the ergodicity results from [1] are extended to models with unbounded feature functions.
Sec. 4 establishes various mixing properties. A key result is that  in order to allow for unbounded
feature functions  the observations need to follow a distribution such that Hoeffding-type concentra-
tion inequalities can be established. Furthermore  the mixing rates depend on the tail behaviour of
the distribution. In Sec. 5 the mixture properties are used to analyze model identiﬁability and con-
sistency of the Maximum Likelihood estimates. Sec. 6 concludes with an outlook on open problems
for future research.

2 Conditional Markov Chains

Preliminaries. We use N  Z and R to denote the sets of natural numbers  integers and real numbers 
respectively. Let X be a metric space with the Borel sigma-ﬁeld A  and Y be a ﬁnite set. Further-
more  consider a probability space (Ω F  P) and let X = (Xt)t∈Z  Y = (Yt)t∈Z be sequences of
measurable mappings from Ω into X and Y  respectively. Here 

• X is an inﬁnite sequence of observations ranging in the domain X  
• Y is an aligned sequence of hidden states taking values in the ﬁnite set Y.

For now  the distribution of X is arbitrary. Next we deﬁne Conditional Markov Chains  which
parameterize the conditional distribution of Y given X.

Deﬁnition. Consider a vector f of real-valued functions f : X × Y × Y → R  called the feature
functions. Throughout this paper  we assume that the following condition is satisﬁed:
|f (x  i  j)| < ∞ for all x ∈ X and i  j ∈ Y.

(A1) All feature functions are ﬁnite:

Associated with the feature functions is a vector λ of real-valued model-weights. The key in the
deﬁnition of Conditional Markov Chains is the matrix M (x) with the (i  j)-th component

m(x  i  j) = exp(λT f (x  i  j)).

In terms of statistical physics  m(x  i  j) measures the potential of the transition between the hidden
states i and j from time t−1 to t  given the observation x at time t. Next  for a sequence x = (xt)t∈Z
in X and time points s  t ∈ Z with s ≤ t  introduce the vectors

αt
βt

s(x) = M (xt)T . . . M (xs)T (1  1  . . .   1)T  
s(x) = M (xs+1) . . . M (xt) (1  1  . . .   1)T  
s(x  j) to denote the ith respectively jth components. Intuitively  αt

s(x  i) and βt

and write αt
s(x  i)
measures the potential of the hidden state i at time t given the observations xs  . . .   xt and assuming
that at time s − 1 all hidden states have potential equal to 1. Similarly  βt
s(x  j) is the potential of
j at time s assuming equal potential of all hidden states at time t. Now let t ∈ Z and k ∈ N  and
deﬁne the distribution of the labels Yt  . . .   Yt+k conditional on X 

k(cid:89)

P(Yt = yt  . . .   Yt+k = yt+k | X)

:=

m(Xt+i  yt+i−1  yt+i)

i=1

× lim
n→∞

t−n(X  yt) βt+k+n
αt

t+k

(X  yt+k)

αt

t−n(X)T βt+k+n

t

(X)

.

Note that  under assumption (A1)  the limit on the right hand side is well-deﬁned (see Theorem 2 in
[1]). Furthermore  the family of all marginal distributions obtained this way satisﬁes the consistency
conditions of Kolmogorov’s Extension Theorem. Hence we obtain a unique distribution for Y
conditional on X parameterized by the feature functions f and the model weights λ. Intuitively  the
distribution is obtained by conditioning the marginal distributions of Y on the ﬁnite observational
context (Xt−n  . . .   Xt+k+n)  and then letting the size of the context going to inﬁnity.

Basic properties. We introduce the following notation: For any matrix P = (pij) with strictly
positive entries let φ(P ) denote the mixing coefﬁcient

φ(P ) = min
i j k l

pikpjl
pjkpil

.

Note that 0 ≤ φ(P ) ≤ 1. This coefﬁcient will play a key role in the analysis of mixing properties.
The following proposition summarizes fundamental properties of the distribution of Y conditional
on X  which directly follow from the above deﬁnition (also see Corollary 1 in [1]).

Proposition 1. Suppose that condition (A1) holds true. Then Y conditional on X forms a time-
inhomogeneous Markov chain. Moreover  if X is strictly stationary  then the joint distribution
of the aligned sequences (X  Y ) is strictly stationary. The conditional transition probabilities
Pt(x  i  j) := P(Yt = j | Yt−1 = i  X = x) of Y given X = x have the following form:

Pt(x  i  j) = m(xt  i  j) lim
n→∞

βn
t (x  j)
βn
t−1(x  i)

.

In particular  a lower bound for Pt(x  i  j) is given by

Pt(x  i  j) ≥

m(xt  i  j) (mink∈Y m(xt+1  i  k))

|Y| (maxk∈Y m(xt  j  k)) (maxk l∈Y m(xt+1  k  l))

 

and the matrix of transition probabilities P t(x)  with the (i  j)-th component given by Pt(x  i  j) 
satisﬁes φ(P t(x)) = φ(M (xt)).

3 Ergodicity

In this section we establish conditions under which the aligned sequences (X  Y ) are jointly er-
godic. Let us ﬁrst recall the deﬁnition of ergodicity of X (see [8]): By X we denote the space of
sequences x = (xt)t∈Z in X   and by A the corresponding product σ-ﬁeld. Consider the probability
measure PX on (X  A) deﬁned by PX (A) := P(X ∈ A) for A ∈ A. Finally  let τ denote the
operator on X which shifts sequences one position to the left: τ x = (xt+1)t∈Z. Then ergodicity of
X is formally deﬁned as follows:

(A2) X is ergodic  that is  PX (A) = PX (τ−1A) for every A ∈ A  and PX (A) ∈ {0  1} for

every set A ∈ A satisfying A = τ−1A.

As a particular consequence of the invariance PX (A) = PX (τ−1A)  we obtain that X is strictly
stationary. Now we are able to formulate the key result of this section  which will be of central
importance in the later analysis. For simplicity  we state it for functions depending on the values
of X and Y only at time t. The generalization of the statement is straight-forward. In our later
analysis  we will use the theorem to show that the time average of feature functions f (Xt  Yt−1  Yt)
converges to the expected value E[f (Xt  Yt−1  Yt)].
Theorem 1. Suppose that conditions (A1) and (A2) hold  and g : X × Y → R is a function which
satisﬁes E[|g(Xt  Yt)|] < ∞. Then

g(Xt  Yt) = E[g(Xt  Yt)]

P-almost surely.

n(cid:88)

t=1

lim
n→∞

1
n

Proof. Consider the sequence Z = (Zt)t∈N given by Zt := (τ t−1X  Yt)  where we write τ t−1 to
denote the (t − 1)th iterate of τ. Note that Zt represents the hidden state at time t together with the
entire aligned sequence of observations τ t−1X. In the literature  such models are known as Markov
sequences in random environments (see [9]). The key step in the proof is to show that Z is ergodic.
Then  for any function h : X × Y → R with E[|h(Zt)|] < ∞  the time average 1
t=1 h(Zt)
converges to the expected value E[h(Zt)] P-almost surely. Applying this result to the composition
of the function g and the projection of (τ t−1X  Yt) onto (Xt  Yt) completes the proof. The details
of the proof that Z is ergodic can be found in an extended version of this paper  which is included
in the supplementary material.

(cid:80)n

n

4 Mixing properties

In this section we are going to study mixing properties of the aligned sequences (X  Y ). To establish
the results  we will assume that the distribution of the observations X satisﬁes conditions under
which certain concentration inequalities hold true:

(A3) Let A ⊂ A be a measurable set  with p := P(Xt ∈ A) and Sn(x) := 1

for x ∈ X . Then there exists a constant γ such that  for all n ∈ N and  > 0 

n

P(|Sn(X) − p| ≥ ) ≤ exp(−γ 2n).

(cid:80)n
t=1 1(xt ∈ A)

If X is a sequence of independent random variables  then (A3) follows by Hoeffding’s inequality. In
the dependent case  concentration inequalities of this type can be obtained by imposing Martingale
or mixing conditions on X (see [12 13]). Furthermore  we will make the following assumption 
which relates the feature functions to the tail behaviour of the distribution of X:

(A4) Let h : [0 ∞) → [0 ∞) be a differentiable decreasing function with h(z) = O(z−(1+κ))

for some κ > 0. Furthermore  let

F (x)

:=

|λT f (x  j  k)|

(cid:88)

j k∈Y

for x ∈ X . Then E[h(F (Xt))−1] and E[h(cid:48)(F (Xt))−1] both exist and are ﬁnite.

The following theorem establishes conditions under which the expected conditional covariances of
square-integrable functions are summable. The result is obtained by studying ergodic properties of
the transition probability matrices.
Theorem 2. Suppose that conditions (A1) - (A3) hold true  and g : X × Y → R is a function with
ﬁnite second moment  E[|g(Xt  Yt)|2] < ∞. Let γt k(X) = Cov(g(Xt  Yt)  g(Xt+k  Yt+k)| X)
denote the covariance of g(Xt  Yt) and g(Xt+k  Yt+k) conditional on X. Then  for every t ∈ Z:

n(cid:88)

k=1

lim
n→∞

E[|γt k(X)|] < ∞.

Proof. Without loss of generality we may assume that g can be written as g(x  y) = g(x)1(y = i).
Hence  using H¨older’s inequality  we obtain

E[|γt k(X)|] ≤ E[|g(Xt)|] E[|g(Xt+k)|] E[|Cov(1(Yt = i)  1(Yt+k = i)| X)|].

According to the assumptions  we have E[|g(Xt)|] = E[|g(Xt+k)|] < ∞  so we only need to bound
the expectation of the conditional covariance. Note that
Cov(1(Yt = i)  1(Yt+k = i)| X) = P(Yt = i  Yt+k = i| X) − P(Yt = i| X) P(Yt+k = i| X).
Recall the deﬁnition of φ(P ) before Corollary 1. Using probabilistic arguments  it is not difﬁcult to
show that the ratio of P(Yt = i  Yt+k = i| X) to P(Yt = i| X) P(Yt+k = i| X) is greater than or
equal to φ(P t+1(X) . . . P t+k(X))  where P t+1(X)  . . .   P t+k(X) denote the transition matrices
introduced in Proposition 1. Hence 
|Cov(1(Yt = i)  1(Yt+k = i)| X)| ≤ P(Yt = i  Yt+k = i| X)[1 − φ(P t+1(X) . . . P t+k(X))].
Now  using results from the theory of weak ergodicity (see Chapter 3 in [6])  we can establish

1 −(cid:112)φ(P t+j(x))
≤ k(cid:89)
1 +(cid:112)φ(P t+j(x))
Proposition 1  we obtain φ(P t+1(x) . . . P t+k(x)) ≥ 1−4(cid:81)k
for all x ∈ X . Using Bernoulli’s inequality and the fact φ(P t+j(x)) = M (xt+j) established in
j=1[1−φ(M (xt+j))]. Consequently 
k(cid:89)
[1 − φ(M (Xt+j))].

1 −(cid:112)φ(P t+1(x) . . . P t+k(x))
1 +(cid:112)φ(P t+1(x) . . . P t+k(x))

|Cov(1(Yt = i)  1(Yt+k = i)| X)| ≤ 4

j=1

With the notation introduced in assumption (A3)  let δ > 0 and A ⊂ X with p > 0 be such that
x ∈ A implies φ(M (x)) ≥ δ. Furthermore  let  be a constant with 0 <  < p. In order to
bound |Cov(1(Yt = i)  1(Yt+k = i)| X)| for a given k ∈ N  we distinguish two different cases: If
|Sk(X) − p| <   then we obtain

j=1

(cid:0)1 − φ(M (Xt+j))(cid:1) ≤ 4 (1 − δ)k(p−).

k(cid:89)

j=1

4

If |Sk(X) − p| ≥   then we use the trivial upper bound 1. According to assumption (A3)  the
probability of the latter event is bounded by an exponential  and hence

E[|Cov(1(Yt = i)  1(Yt+k = i)| X)|] ≤ 4 (1 − δ)k(p−) + exp(−γ 2k).

Obviously  the sum of all these expectations is ﬁnite  which completes the proof.

The next theorem bounds the difference between the distribution of Y conditional on X and ﬁnite
approximations of it. Introduce the following notation: For t  k ≥ 0 with t + k ≤ n let

P(0:n)(Yt = yt  . . .   Yt+k = yt+k | X = x)

k(cid:89)

i=1

:=

m(xt+i  yt+i−1  yt+i) lim
n→∞

αt
0(x  yt) βn

t+k(x  yt+k)

αt

0(x)T βn

t (x)

.

Accordingly  write E(0:n) for expectations taken with respect to P(0:n). As emphasized by the su-
perscrips  these quantities can be regarded as marginal distributions of Y conditional on the ob-
servations at times t = 0  1  . . .   n. To simplify notation  the following theorem is stated for
1-dimensional conditional marginal distributions  however  the extension to the general case is
straight-forward.
Theorem 3. Suppose that conditions (A1) - (A4) hold true. Then the limit
P(0:n)(Yt = i| X)

P(0:∞)(Yt = i| X)

:= lim
n→∞

is well-deﬁned P-almost surely. Moreover  there exists a measurable function C(x) of x ∈ X with
ﬁnite expectation  E[|C(X)|] < ∞  and a function h(z) satisfying the conditions in (A4)   such that

(cid:12)(cid:12)P(0:∞)(Yt = i| X) − P(0:n)(Yt = i| X)(cid:12)(cid:12) ≤ C(τ tX) h(n − t).

Proof. Deﬁne Gn(x) := M (xt+1) . . . M (xn) and write gn(x  i  j) for the (i  j)-th component
of Gn(x). Note that βn
t (x) = Gn(x)(1  1  . . .   1)T . According to Lemma 3.4 in [6]  there exist
numbers rij(x) such that

lim
n→∞

= rij(x)

gn(x  i  k)
gn(xj  k)
t (x  i) to βn
t (x  i)
t (x)
0(x)/αt

=

for all k ∈ Y. Consequently  the ratio of βn
0(x  i) βn
αt
0(x)T βn
αt

lim
n→∞

t (x  j) converges to rij(x)  and hence

1

qi(x)T ri(x)

where we use the notation qi(x) = αt
0(x  i) and ri(x) denotes the vector with the kth
component rki(x). This proves the ﬁrst part of the theorem. In order to prove the second part  note
that |x − y| ≤ |x−1 − y−1| for any x  y ∈ (0  1]  and hence

(cid:12)(cid:12)P(0:∞)(Yt = i| X) − P(0:n)(Yt = i| X)(cid:12)(cid:12) ≤ (cid:12)(cid:12)(cid:12)qi(X)T ri(X) − αt
(cid:18) gn(x  k  l)

(cid:18) gn(x  k  l)

To bound the latter expression  introduce the vectors rn

i (x) with the kth components

i (x) and rn

0(X)T βn
0(X  i) βn
αt

t (X)
t (X  i)

(cid:12)(cid:12)(cid:12).

(cid:19)

(cid:19)

rn
ki(x) = min
l∈Y

It is easy to see that qi(x)T rn

Hence 

qi(x)T rn

(cid:12)(cid:12)(cid:12)qi(X)T ri(X) − αt

and

rn
ki(x) = max
l∈Y

gn(x  i  l)
i (x) ≤ qi(x)T ri(x) ≤ qi(x)T rn
0(x)T βn
i (x) ≤ αt
0(x  i) βn
αt

t (x)
t (x  i)

≤ qi(x)T rn

i (x)  and

i (x).

gn(x  i  l)

.

(cid:12)(cid:12)(cid:12) ≤ (cid:12)(cid:12)qi(X)T (rn

i (X))(cid:12)(cid:12).

i (X) − rn

0(X)T βn
0(X  i) βn
αt

t (X)
t (X  i)

Due to space limitations  we only give a sketch of the proof how the latter quantity can be bounded.
For details  see the extended version of this paper in the supplementary material. The ﬁrst step is
ki(X)| ≤
to show the existence of a function C1(x) with E[|C1(X)|] < ∞ such that |rn
C1(τ tX) (1 − ζ)n−t for some ζ > 0. With the function F (x) introduced in assumption (A4)  we
deﬁne C2(x) := exp(F (x)) for x ∈ X and arrive at

(cid:12)(cid:12)P(0:∞)(Yt = i| X) − P(0:n)(Yt = i| X)(cid:12)(cid:12) ≤ |Y|2 C1(τ tX) C2(Xt) (1 − ζ)n−t.

ki(X) − rn

The next step is to construct a function C3(x) satisfying the following two conditions: (i) If
C2(x)(1 − ζ)k ≥ 1  then C3(x)h(k) ≥ 1.
(ii) If C2(x)(1 − ζ)k < 1  then C3(x)h(k) ≥
C2(x) (1 − ζ)k. Since the difference between two probabilities cannot exceed 1  we obtain

(cid:12)(cid:12)P(0:∞)(Yt = i| X) − P(0:n)(Yt = i| X)(cid:12)(cid:12) ≤ |Y|2 C1(τ tX) C3(Xt) h(n − t).

The last step is to show that E[|C3(Xt)|] < ∞.

The following result will play a key role in the later analysis of empirical likelihood functions.
Theorem 4. Suppose that conditions (A1) - (A4) hold  and the function g : X × Y → R satisﬁes
E[|g(Xt  Yt)|] < ∞. Then

E(0:n)[g(Xt  Yt)| X] = E[g(Xt  Yt)]

P-almost surely.

n(cid:88)

t=1

lim
n→∞

1
n

Proof. Without loss of generality we may assume that g can be written as g(x  y) = g(x)1(y = i).
Using the result from Theorem 3  we obtain

E(0:∞)[g(Xt  Yt)| X]

|g(Xt)||C(τ tX)| h(n − t) 

(cid:12)(cid:12)(cid:12) n(cid:88)

t=1

E(0:n)[g(Xt  Yt)| X] − n(cid:88)

t=1

(cid:12)(cid:12)(cid:12) ≤ n(cid:88)

t=1

where h(z) is a function satisfying the conditions in assumption (A4). See the extended version of
this paper in the supplementary material for more details. Using the facts that X is ergodic and the
expectations of |g(Xt)| and |C(τ tX)| are ﬁnite  we obtain

(cid:12)(cid:12)(cid:12) n(cid:88)
E(0:n)[g(Xt  Yt)| X] − n(cid:88)
(cid:12)(cid:12)(cid:12) n(cid:88)
E(0:∞)[g(Xt  Yt)| X] − n(cid:88)

t=1

t=1

1
n

t=1

t=1

lim
n→∞

1
n

lim
n→∞

E(0:∞)[g(Xt  Yt)| X]

E[g(Xt  Yt)| X]

(cid:12)(cid:12)(cid:12) = 0.
(cid:12)(cid:12)(cid:12) = 0.

By similar arguments to the proof of the ﬁrst part of Theorem 3 one can show that the difference
|E(0:∞)[g(Xt  Yt)| X] − E[g(Xt  Yt)| X]| tends to 0 as t → ∞. Thus 

Now  noting that E[g(Xt  Yt)| X] = E[g(X0  Y0)| τ tX] for every t  the theorem follows by the
ergodicity of X.

5 Maximum Likelihood learning and model identiﬁability

In this section we apply the previous results to analyze asymptotic properties of the empirical
likelihood function. The setting is the following: Suppose that we observe ﬁnite subsequences
X n = (X0  . . .   Xn) and Y n = (Y0  . . .   Yn) of X and Y   where the distribution of Y condi-
tional on X follows a conditional Markov chain with ﬁxed feature functions f and unknown model
weights λ∗. We assume that λ∗ lies in some parameter space Θ  the structure of which will be-
come important later. To emphasize the role of the model weights  we will use subscripts  e.g. 
Pλ and Eλ  to denote the conditional distributions. Our goal is to identify the unknown model
weights from the ﬁnite samples  X n and Y n. In order to do so  introduce the shorthand notation
t=1 f (xt  yt−1  yt) for xn = (x0  . . .   xn) and yn = (y0  . . .   yn). Consider the

f (xn  yn) = (cid:80)n

normalized conditional likelihood 

(cid:16)

(cid:88)

exp(cid:0)λT f (X n  yn)(cid:1)(cid:17)

.

yn∈Y n+1

Ln(λ) =

1
n

λT f (X n  Y n) − log

Note that  in the context of ﬁnite Conditional Markov Chains  Ln(λ) is the exact likelihood of Y n
conditional on X n. The Maximum Likelihood estimate of λ∗ is given by

ˆλn

:= arg max

λ∈Θ

Ln(λ).

If Ln(λ) is strictly concave  then the arg max is unique and can be found using gradient-based
search (see [14]). It is easy to see that Ln(λ) is strictly concave if and only if |Y| > 1  and there
exists a sequence yn such that at least one component of f (X n  yn) is non-zero. In the following 
we study strong consistency of the Maximum Likelihood estimates  a property which is of central
importance in large sample theory (see [15]). As we will see  a key problem is the identiﬁability and
uniqueness of the model weights.

5.1 Asymptotic properties of the likelihood function

In addition to the conditions (A1)-(A4) stated earlier  we will make the following assumptions:

(A5) The feature functions have ﬁnite second moments: Eλ∗ [|f (Xt  Yt−1  Yt)|2] < ∞.
(A6) The parameter space Θ is compact.

The next theorem establishes asymptotic properties of the likelihood function Ln(λ).
Theorem 5. Suppose that conditions (A1)-(A6) are satisﬁed. Then the following holds true:

(i) There exists a function L(λ) such that limn→∞ Ln(λ) = L(λ) Pλ∗-almost surely for
every λ ∈ Θ. Moreover  the convergence of Ln(λ) to L(λ) is uniform on Θ  that is 
limn→∞ supλ∈Θ |Ln(λ) − L(λ)| = 0 Pλ∗-almost surely.

(ii) The gradients satisfy limn→∞ ∇Ln(λ) = Eλ∗ [f (Xt  Yt−1  Yt)] − Eλ[f (Xt  Yt−1  Yt)]

Pλ∗-almost surely for every λ ∈ Θ.

(iii) If the limit of the Hessian ∇2Ln(λ) is ﬁnite and non-singular  then the function L(λ) is
strictly concave on Θ. As a consequence  the Maximum Likelihood estimates are strongly
consistent:

lim
n→∞

ˆλn = λ∗

Pλ∗-almost surely.

Proof. The statements are obtained analogously to Lemma 4-6 and Theorem 4 in [1]  using the
auxiliary results for Conditional Markov Chains with unbounded feature functions established in
Theorem 1  Theorem 2  and Theorem 4.

λT f (X n  Y n) = (cid:80)n

Next  we study the asymptotic behaviour of the Hessian ∇2Ln(λ). In order to compute the dervia-
tives  introduce the vectors λ1  . . .   λn with λt = λ for t = 1  . . .   n. This allows us to write
t f (Xt  Yt−1  Yt). Now  regard the argument λ of the likelihood func-

tion as a stacked vector (λ1  . . .   λn). Same as in [1]  this gives us the expressions

t=1 λT

(cid:2)f (Xt  Yt−1  Yt)  f (Xt+k  Yt+k−1  Yt+k)T | X(cid:3)

∂2

∂λt∂λT

t+k

Ln(λ) =

1
n

Cov(0:n)

λ

where Cov(0:n)
Using these expressions  the Hessian of Ln(λ) can be written as

is the covariance with respect to the measure P(0:n)

λ

λ

introduced before Theorem 3.

∇2Ln(λ) = −(cid:16) n(cid:88)

n−1(cid:88)

n−k(cid:88)

(cid:17)

∂2

∂λt∂λT
t

Ln(λ) + 2

t=1

∂2

Ln(λ)

.

k=1

t=1

∂λt∂λT

t+k

The following theorem establishes an expression for the limit of ∇2Ln(λ).
expression given in Lemma 7 of [1]  which is incorrect.
Theorem 6. Suppose that conditions (A1) - (A5) hold. Then

It differs from the

n→∞∇2Ln(λ) = −(cid:16)

lim

(cid:17)

∞(cid:88)

k=1

γλ(0) + 2

γλ(k)

Pλ∗-almost surely

where γλ(k) = E[Covλ(f (Xt  Yt−1  Yt)  f (Xt+k  Yt+k−1  Yt+k)| X)] is the expectation of the
conditional covariance (with respect to Pλ) between f (Xt  Yt−1  Yt) and f (Xt+k  Yt+k−1  Yt+k)
given X. In particular  the limit of ∇2Ln(λ) is ﬁnite.

Proof. The key step is to show the existence of a positive measurable function Uλ(k  x) such that

n−1(cid:88)

n−k(cid:88)

k=1

t=1

(cid:12)(cid:12)(cid:12)

lim
n→∞

(cid:12)(cid:12)(cid:12) ≤ lim

n→∞

n−1(cid:88)

k=1

∂2

∂λt∂λT

t+k

Ln(λ)

E[Uλ(k  X)]

with the limit on the right hand side being ﬁnite. Then the rest of the proof is straight-forward:
Theorem 4 shows that  for ﬁxed k ≥ 0 

n−k(cid:88)

t=1

lim
n→∞

∂2

∂λt∂λT

Ln(λ) = γλ(k)

Pλ∗-almost surely.

Hence  in order to establish the theorem  it sufﬁces to show that

(cid:12)(cid:12)(cid:12) ≤ 
for all  > 0. Now let  > 0 be ﬁxed. According to Theorem 2 we have(cid:80)∞

n−1(cid:88)

t+k

(cid:12)(cid:12)(cid:12)γλ(k) − n−k(cid:88)

Ln(λ)

∂λt∂λT

t+k

lim
n→∞

∂2

t=1

we can ﬁnd a ﬁnite N such that

On the other hand  Theorem 4 shows that

k=1 |γλ(k)| < ∞. Hence

k=1

n−1(cid:88)
N−1(cid:88)

k=N

k=1

lim
n→∞

lim
n→∞

n−1(cid:88)

k=N

|γλ(k)| + lim
n→∞

(cid:12)(cid:12)(cid:12)γλ(k) − n−k(cid:88)

t=1

∂2

∂λt∂λT

t+k

E[Uλ(k  X)] ≤ .

(cid:12)(cid:12)(cid:12) = 0.

Ln(λ)

For details on how to construct Uλ(k  x)  see the extended version of this paper.

5.2 Model identiﬁability

Let us conclude the analysis by investigating conditions under which the limit of the Hessian
∇2Ln(λ) is non-singular. Note that ∇2Ln(λ) is negative deﬁnite for every n  so also the limit
is negative deﬁnite  but not necessarily strictly negative deﬁnite. Using the result in Theorem 6  we
can establish the following statement:
Corollary 1. Suppose that assumptions (A1)-(A5) hold true. Then the following conditions are
necessary for the limit of ∇2Ln(λ) to be non-singular:

(i) For each feature function f (x  i  j)  there exists a set A ⊂ X with P(Xt ∈ A) > 0 such

that  for every x ∈ A  we can ﬁnd i  j  k  l ∈ Y with f (x  i  j) (cid:54)= f (x  k  l).

(ii) There does not exist a non-zero vector λ and a subset A ⊂ X with P(Xt ∈ A) = 1 such

that λT f (x  i  j) is constant for all x ∈ X and i  j ∈ Y.

Condition (i) essentially says: features f (x  i  j) must not be constant in i and j. Condition (ii)
says that features must not be expressible as linear combinations of each other. Clearly  features
violating condition (i) can be assigned arbitrary model weights without any effect on the conditional
distributions. If condition (ii) is violated  then there are inﬁnitely many ways for parameterizing the
same model. In practice  some authors have found positive effects of including redundant features
(see  e.g.  [16])  however  usually in the context of a learning objective with an additional penalizer.

6 Conclusions

We have established ergodicity and various mixing properties of Conditional Markov Chains with
unbounded feature functions. The main insight is that similar results to the setting with bounded
feature functions can be obtained  however  under additional assumptions on the distribution of the
observations. In particular  the proof of Theorem 2 has shown that the sequence of observations
needs to satisfy conditions under which Hoeffding-type concentration inequalities can be obtained.
The proof of Theorem 3 has reveiled an interesting interplay between mixing rates  feature func-
tions  and the tail behaviour of the distribution of observations. By applying the mixing proper-
ties to the empirical likelihood functions we have obtained necessary conditions for the Maximum
Likelihood estimates to be strongly consistent. We see a couple of interesting problems for future
research: establishing Central Limit Theorems for Conditional Markov Chains; deriving bounds for
the asymptotic variance of Maximum Likelihood estimates; constructing tests for the signiﬁcance
of features; generalizing the estimation theory to an inﬁnite number of features; ﬁnally  ﬁnding
sufﬁcient conditions for the model identiﬁability.

References

[1] Sinn  M. & Poupart  P. (2011) Asymptotic theory for linear-chain conditional random ﬁelds. In Proc. of the
14th International Conference on Artiﬁcial Intelligence and Statistics (AISTATS).
[2] Lafferty  J.  McCallum  A. & Pereira  F. (2001) Conditional random ﬁelds: Probabilistic models for seg-
menting and labeling sequence data. In Proc. of the 18th IEEE International Conference on Machine Learning
(ICML).
[3] Sutton  C. & McCallum  A. (2006) An introduction to conditional random ﬁelds for relational learning. In:
Getoor  L. & Taskar  B. (editors)  Introduction to Statistical Relational Learning. Cambridge  MA: MIT Press.
[4] Hofmann  T.  Sch¨olkopf  B. & Smola  A.J. (2008) Kernel methods in machine learning. The Annals of
Statstics  Vol. 36  No. 3  1171-1220.
[5] Xiang  R. & Neville  J. (2011) Relational learning with one network: an asymptotic analysis. In Proc. of
the 14th International Conference on Artiﬁcial Intelligence and Statistics (AISTATS).
[6] Seneta  E. (2006) Non-Negative Matrices and Markov Chains. Revised Edition. New York  NY: Springer.
[7] Wainwright  M.J. & Jordan  M.I. (2008) Graphical models: exponential families  and variational inference.
Foundations and Trends R(cid:13) in Machine Learning  Vol. 1  Nos. 1-2  1-305.
[8] Cornfeld  I.P.  Fomin  S.V. & Sinai  Y.G. (1982) Ergodic Theory. Berlin  Germany: Springer.
[9] Orey  S. (1991) Markov chains with stochastically stationary transition probabilities. The Annals of Proba-
bility  Vol. 19  No. 3  907-928.
[10] Hern´andez-Lerma  O. & Lasserre  J.B. (2003) Markov Chains and Invariant Probabilities. Basel  Switzer-
land: Birkh¨auser.
[11] Foguel  S.R. (1969) The Ergodic Theory of Markov Processes. Princeton  NJ: Van Nostrand.
[12] Samson  P.-M. (2000) Concentration of measure inequalities for Markov chains and Φ-mixing processes.
The Annals of Probability  Vol. 28  No. 1  416-461.
[13] Kontorovich  L. & Ramanan  K. (2008) Concentration inequalities for dependent random variables via the
martingale method. The Annals of Probability  Vol. 36  No. 6  2126-2158.
[14] Sha  F. & Pereira  F. (2003) Shallow parsing with conditional random ﬁelds. In Proc. of the Human Lan-
guage Technology Conference of the North American Chapter of the Association for Computational Linguistics
(HLT-NAACL).
[15] Lehmann  E.L. (1999) Elements of Large-Sample Theory. New York  NY: Springer.
[16] Hoefel  G. & Elkan  C. (2008) Learning a two-stage SVM/CRF sequence classiﬁer. In Proc. of the 17th
ACM International Conference on Information and Knowledge Management (CIKM).

,Adhiraj Somani
Nan Ye
David Hsu
Wee Sun Lee