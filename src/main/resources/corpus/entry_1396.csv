2019,Deep Structured Prediction for Facial Landmark Detection,Existing deep learning based facial landmark detection methods have achieved excellent performance. These methods  however  do not explicitly embed the structural dependencies among landmark points. They hence cannot preserve the geometric relationships between landmark points or generalize well to challenging conditions or unseen data. This paper proposes a method for deep structured facial landmark detection based on combining a deep Convolutional Network with a Conditional Random Field. We demonstrate its superior performance to existing state-of-the-art techniques in facial landmark detection  especially a better generalization ability on challenging datasets that include large pose and occlusion.,Deep Structured Prediction for Facial Landmark

Detection

Lisha Chen1  Hui Su1 2  Qiang Ji1

1Rensselaer Polytechnic Institute  2IBM Research

chenl21@rpi.edu  huisuibmres@us.ibm.com  jiq@rpi.edu

Abstract

Existing deep learning based facial landmark detection methods have achieved
excellent performance. These methods  however  do not explicitly embed the
structural dependencies among landmark points. They hence cannot preserve the
geometric relationships between landmark points or generalize well to challenging
conditions or unseen data. This paper proposes a method for deep structured
facial landmark detection based on combining a deep Convolutional Network
with a Conditional Random Field. We demonstrate its superior performance to
existing state-of-the-art techniques in facial landmark detection  especially a better
generalization ability on challenging datasets that include large pose and occlusion.

1

Introduction

Facial landmark detection is to automatically localize the ﬁducial facial landmark points around facial
components and facial contour. It is essential for various facial analysis tasks such as facial expression
analysis  headpose estimation and face recognition. With the development of deep learning techniques 
traditional facial landmark detection approaches that rely on hand-crafted low-level features have
been outperformed by deep feature based approaches. The purely deep learning based methods 
however  cannot effectively capture the structural dependencies among landmark points. They hence
cannot perform well under challenging conditions  such as large head pose  occlusion  and large
expression variation. Probabilistic graphical models such as Conditional Random Fields (CRFs)  have
been widely applied to various computer vision tasks. They can systematically capture the structural
relationships among random variables and perform structured prediction. Recently  there have been
works that combine deep models with CRF to simultaneously leverage convolutional neural networks’
(CNNs) representation power and CRF’s structure modeling power [10  9  51]. Their combination has
yielded signiﬁcant performance improvement over methods that use either CNN or CRF alone. These
works so far are mainly applied to classiﬁcation tasks such as semantic image segmentation. Besides
classiﬁcation  some works apply the CNN and CRF model to human pose [41  12  11] and facial
landmark detection [2  44] . To simplify computational complexity  the CRF models are typically
of special structure (e.g. tree structure)  moreover  they employ approximate learning and inference
criteria. In this work  we propose to combine CNN with a fully-connected CRF to jointly perform
facial landmark detection in regression framework.
Compared to the existing works  the contributions of our work are summarized as follows:
1) We introduce the fully-connected CNN-CRF that produces structured probabilistic prediction of
facial landmark locations.
2) Our model explicitly captures the structure relationship variations caused by pose and deformation 
unlike some previous works that combine CNN with CRF using a ﬁxed pairwise relationship.
3) We use an alternating method and derive closed-form solutions in the alternating steps for learning
and inference  unlike previous works that use approximate methods such as energy minimization
which ignores the partition function for learning and mean-ﬁeld for inference. And instead of using
discriminative criterion or other approximate loss functions  we employ negative log likelihood (NLL)

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

loss function  without any assumption.
4) Experiments on benchmark face alignment datasets demonstrate the advantages of the proposed
method in achieving better prediction accuracy and generalization to challenging or unseen data than
current state-of-the-art (SoA) models.

2 Related Work

2.1 Facial Landmark Detection

Classic facial landmark detection methods including Active Shape Model (ASM) [14  28]  Active
Appearance Model (AAM) [13  24  27  36]  Constrained Local Model (CLM) [25  37]  and Cascade
Regression [8  6  53  7  46] rely on hand-crafted shallow image features and are usually sensitive to
initializations. They are outperformed by modern deep learning based methods.
Using deep learning for face alignment was ﬁrst proposed in [39] and achieved better performance
than classic methods. This purely deep appearance based approach uses a deep cascade convolutional
network and coordinate regression in each cascade level. Later on  more work using purely deep
appearance based framework for coordinate regression has been explored. Tasks-constrained deep
convolutional network (TCDCN) [50] was proposed to jointly optimize facial landmark detection
with correlated tasks such as head pose estimation and facial attribute inference. Mnemonic Descent
Method (MDM) [42]  an end-to-end trainable deep convolutional Recurrent Neural Network (RNN) 
was proposed where the cascade regression was implemented by RNN. Recently  heatmap learning
based methods established new state-of-the-art for face alignment and body pose estimation [41 
30  43]. And most of these face alignment methods [5  44] follow the architecture of Stacked
Hourglass [30]. The stacked modules reﬁne the network predictions after each stack. Different from
direct coordinate regression  it predicts a heatmap with the same size as the input image. Hybrid
deep methods combine deep models with face shape models. One strategy is to directly predict 3D
deformable parameters instead of landmark locations in a cascaded deep regression framework  e.g.
3D Dense Face Alignment (3DDFA) [54] and Pose-Invariant Face Alignment (PIFA) [23]. Another
strategy is to use the deformable model as a constraint to limit the face shape search space thus to
reﬁne the predictions from the appearance features  e.g. Convolutional Experts Constrained Local
Model (CE-CLM) [48].

2.2 Structured Deep Models

To produce structured predictions  some works combine deep models with graphical models. Early
works like [31] jointly train a CNN and a graphical model for image segmentation. Do et al.[16]
introduced NeuralCRF for sequence labeling. And various works are explored for other tasks. For
instance  Jain et al. [22] and Eigen et al. [18]’s work for image restoration  Yao et al. and Morin et
al.’s work [47  29] for language understanding  Yoshua et al.  Peng et al. and Jaderberg et al.’s work
[3  32  21] for handwriting or text recognition. Recently  for human body pose estimation  Chen et
al.[10] use CNN to output image dependent part presence as the unary term and spatial relationship
as the pairwise potential in a tree-structured CRF and uses Dynamic Programming for inference.
Tompson et al. [41  40] jointly trained a CNN and a fully-connected MRF by using the convolution
kernel to capture pairwise relationships among different body joints and an iterative convolution
process to implement the belief propagation. The idea of using convolution to implement message
passing has also been explored in [12]  where structure relationships at the body joint feature level
rather than the output level are captured in a bi-directional tree structured model. And the work
of Chu et al.[12] is applied to face alignment [44] to pass messages between facial part boundary
feature maps. As an extension to [12]  [11] models structures in both output and hidden feature
layers in CNN. Similarly  for image segmentation  DeepLab [9] uses fully connected CRF with
binary cliques and mean-ﬁeld inference  and [26] uses efﬁcient piecewise training to avoid repeated
inference during training. In [51]  the CRF mean-ﬁeld inference is implemented by RNN and the
network is end-to-end trainable by directly optimizing the performance of the mean-ﬁeld inference.
Using RNN to implement message passing has also been applied to facial action unit recognition
[15]. In [20]  the MRF deformable part model is implemented as a layer in a CNN.
Comparison. Compared to previous models serving similar purposes such as [12  11  44] that
assume a tree structured model with belief propagation as inference method  we use a fully-connected

2

model. With a fully connected model  we don’t need to specify a certain tree structured model  letting
the model learn the strong or weak relationships from data  thus this method is more generalizable to
different tasks. And the works [41  12  11  44  51] use convolution to implement the pairwise term
and the message passing process. The pairwise term  once trained  is independent of the input image 
thus cannot capture the pairwise constraint variations across different conditions like target object
rotation and object shape. However  we explicitly capture the object pose  deformation variations.
Moreover  they employ approximate methods such as energy minimization ignoring the partition
function for learning and mean-ﬁeld for inference. In this paper we do exact learning and inference 
capturing the full covariance of the joint distribution of facial landmarks given deformable parameters.
Lastly  compared to the traditional CRF models [33  34]  the weights for each unary terms in our
model are also outputs of the neural network whose inverse quantiﬁes heteroscedastic aleatoric
uncertainty of the unary prediction.

3 Method

This section presents the proposed structured deep probabilistic facial landmark detection model. In
this model  the joint probability distribution of facial landmark locations and deformable parameters
are captured by a conditional random ﬁeld model.

3.1 Model deﬁnition

Denote the face image as x  the 2D facial landmark lo-
cations as y  each landmark is yi  i = 1  . . .   N. The
deformable model parameters that capture pose  identity
and expression variation are denoted as ζ. The model
parameter we want to learn is denoted as Θ. Assuming
ζ is marginally dependent on x but conditionally inde-
pendent of x given y  the graphical model is shown in
Fig. 1.
Based on this deﬁnition and assumption  the joint dis-
tribution of landmarks y and deformable parameters ζ
conditioned on the face image x can be formulated in a
CRF framework and written as

pΘ(y  ζ | x) =

1

ZΘ(x)

− N(cid:88)

exp{− N(cid:88)
N(cid:88)

i=1

φθ1(yi | x)

ψCij (yi  yj  ζ)}

Figure 1: The graphical model. Dashed 
dotted  solid lines represent dependencies
between pairs of landmarks  landmark and
deformable parameters  landmarks and
face image  respectively.

(1)

i=1

j=i+1

where Θ = [θ1  Cij]  θ1 is neural network parameter  Cij is a 2× 2 symmetric positive deﬁnite matrix
that captures the spatial relationships between a pair of landmark points  yi and yj. ZΘ(x) is the
partition function. φθ1 (yi | x) is the unary energy function with parameter θ1 and ψCij (yi  yj  ζ) is
the triple-wise energy function with parameter Cij.

3.2 Energy functions

We deﬁne the unary and triple-wise energy in Eq.(2) and Eq.(3) respectively.

1
2

[yi − µi(x  θ1)]T Σ−1

φθ1(yi | x) =
ψCij (yi  yj  ζ) = [yi − yj − µij(ζ)]T Cij[yi − yj − µij(ζ)]

(x  θ1)[yi − µi(x  θ1)]

i

(3)
where µi(x  θ1) and Σi(x  θ1) are the outputs of the CNN that represent mean and covariance
matrix of each landmark given the image x. µij(ζ) represents the expected difference between
two landmark locations. It is fully determined by the 3D deformable face shape parameters ζ 
which contains rigid parameters: rotation R and scale S  and non-rigid parameters q.

(cid:20)µij(ζ)

(cid:21)

=

(2)

1

3

Output: deformableparametersOutput: faciallandmark locationsy3Input: face imagey2y5y4y1i + Φiq − ¯y3d

j − Φjq)  where ¯y3d is the 3D mean face shape  Φ is the bases of deformable
1
λ SR(¯y3d
model  they are learned from data. The deformable parameters ζ = [S  R  q] are jointly estimated
with 2D landmark locations during inference. In this work  we assume weak perspective projection
model. S is a 3 × 3 diagonal matrix that contains 2 independent parameters sx  sy as scaling factor
(encode the camera intrinsic parameters) for column and row respectively. While R is a 3 × 3
orthonormal matrix with 3 independent parameters γ1  γ2  γ3 as the pitch  yaw  roll rotation angle.
Note that the translation vector is canceled by taking the difference of two landmark points.

3.3 Learning and Inference

We propose to implement the conditional probability distribution in Eq. (1) with a CNN-CRF model.
As shown in Fig. 2  the CNN with parameter θ1 outputs mean µi(x  θ1) and covariance matrix
Σi(x  θ1) for each facial landmark yi  which together forms the unary energy function φθ1 (yi | x).
A fully-connected (FC) graph with parameter Cij (cid:31) 0 gives the triple-wise energy ψCij (yi  yj  ζ)  if
given ζ as well as the output from the unary  the FC can output E(x  ζ  Θ) and Λp(x  ζ  Θ)  the mean
and precision matrix for the conditional distribution pΘ(y | ζ  x). The FC can be implemented as
another layer following the CNN. Combining the unary and the triple-wise energy  we obtain the joint
distribution pΘ(y  ζ | x). However  direct inference of y∗  ζ∗ from pΘ(y  ζ | x) is difﬁcult  therefore
we iteratively infer from conditional distributions pΘ(y | ζ  x) and pΘ(ζ | y).

Figure 2: Overall ﬂowchart of the proposed CNN-CRF model.

Mean and Precision matrix
During learning and inference  we need to compute conditional probability pΘ(y | ζ  x). By using
the quadratic unary and triple-wise energy function  the distribution pΘ(y | ζ  x) is a multivariate
Gaussian distribution that can be written as

exp{− N(cid:88)

φθ1(yi | x) − N(cid:88)

N(cid:88)

i=1

i=1

j=i+1

ψCij (yi  yj  ζ)}

(4)

pΘ(y | ζ  x) =

1
Z(cid:48)
Θ(x)
= exp{ 1
2

ln|Λp(x  Θ  ζ)| − 1
2

[y − E(x  Θ  ζ)]T Λp(x  Θ  ζ)[y − E(x  Θ  ζ)]}

where Z(cid:48)
Θ(x) is the partition function. E(x  Θ  ζ) and Λp(x  Θ  ζ) is the mean and precision matrix
of the multivariate Gaussian distribution. They are computed exactly during learning and inference.
The mean E can be computed by solving the linear system of equations ΛpE = b where Λp  the
precision matrix  is a symmetric positive deﬁnite matrix that can be directly computed from the
coefﬁcient in the unary and pairwise term as shown in Eq. (5)  and b can be computed from Eq. (5).

 Λp11

...

ΛpN 1

Λp =

. . . Λp1N
...
. . . ΛpN N

...

(cid:40)

  

i +(cid:80)

−1
Λpii = Σ
Λpij = −Cij

j(cid:54)=i Cij

b =

   bi = Σ

 b1

b2

...

bN

(cid:88)

j(cid:54)=i

Cijµij

(5)

−1
i µi +

From Eq.(5) we can see that the ﬁnal inference result Ei is a combination of µi and µj + µij  j ∈
{1  . . .   N}  j (cid:54)= i. To solve this linear system of equations  we use direct method for exact solution
with a fast implementation by Cholesky factorization that requires O(N 3) FLOPs. For a practical
implementation of the determinant to avoid numerical issues  we again use the Cholesky factorization
diag(·) takes the diagonal element of a matrix.

of Λp to get LLT = Λp  then we compute the log determinant by ln|Λp| = 2(cid:80) ln diag(L) where

4

CNN       unary energytriple-wise energyFC         Input image xJoint distributionexpnormalizeConditional distributionConditional distributionJointly infer-+Learning
During learning  our goal is to optimize Θ given training data D = {xm  ym  m = 1  . . .   M}.
We directly optimize the inference performance. Note that we don’t have ground truth label for ζ 
where ζ = {ζ1  . . .   ζm}. We use an alternating method  based on the current Θt  ˆyt = E(x  Θt  ζ t) 
optimize ζ by

− ln pΘt(ˆyt
Then based on current ζt  optimize Θ by

ζ t+1
m = arg min

ζm

m  ζm | xm) = arg min

ζm

Θt+1 = arg min

Θ

Loss = arg min

Θ

m=1

ln pΘ(ym  ζ t

m | xm) = arg min

Θ

− M(cid:88)

ψCt

ij

(ˆyt

mi  ˆyt

mj  ζm)

(6)

− M(cid:88)

m=1

ln pΘ(ym | ζ t

m  xm)

Θ

m=1

− 1
2

= arg min

ln|Λp(xm  Θ  ζ t

m)[ym − E(xm  Θ  ζ t
(7)
The algorithm for this problem is designed to ﬁrst set Cij = 0 and optimize θ1  the CNN parameter.
Then set Cij = 0.01I and optimize ζ  then ﬁx a subset of parameters from Θ and optimize the others
alternately  whose pseudo code is shown in Algorithm 1.

[ym − E(xm  Θ  ζ t

m)]T Λp(xm  Θ  ζ t

m)| +

1
2

m)]

M(cid:88)

Algorithm 1: Learning CNN-CRF
Input: training data {xm  ym  m = 1  . . .   M};
Initialization: parameters Θ0 = {θ0
while not converge do

1 = randn  C 0

θt+1
1 = θt

1 − ηt

1

∂Loss

∂θ1

; t = t + 1;

end
m = E(xm  Θt  ζ t)  C t
ˆyt
while not converge do

ij = 0.01I;

ij = 0}  t = 0 ;

Stage 1: Fix parameters Θ = Θt  optimize ζ by Eq. (6);
while not converge do

(cid:46) Optimize deformable parameters

(ˆyt

mi  ˆyt

mj  ζm)  ˆyt+1 = E(x  Θ  ζ t+1)  t = t + 1;

ζ t+1
m = arg minζm ψCt

ij

end
Θt = Θ
Stage 2: Fix ζ = ζt  Cij = C t
while not converge do

θt+1
1 = θt

1 − ηt

1

∂Loss

∂θ1

; t = t + 1;

ij] = [ζ  Cij]

end
[ζt  C t
Stage 3: Fix ζ = ζt  θ1 = θt
while not converge do
ij − ηt

ij = C t

C t+1

∂Loss
∂Cij

2

end
[ζt  θt

end

1] = [ζ  θ1]

ij  update θ1 using Eq. (7);

1  update Cij using Eq. (7);

; t = t + 1;

(cid:46) Update CNN parameters

(cid:46) Update CRF parameters

Inference
The inference problem is a joint inference of ζ  y for each input face image x  deﬁned in Eq. (8)

y∗  ζ∗ = arg max

ln pΘ(y  ζ | x)

y ζ

We use an alternating method. Based on current yt  optimize ζ t by (see supplementary):

ζ t = arg max

ζ

ln pΘ(yt  ζ | x) = arg min

ζ

ψCij (yt

i  yt

j  ζ)

Then based on current ζ t  optimize yt+1 by:

yt+1 = arg max

y

ln pΘ(y  ζ t | x) = arg max

ln pΘ(y | ζ t  x) = E(x  Θ  ζ t)

y

5

N(cid:88)

N(cid:88)

i=1

j=i+1

(8)

(9)

(10)

The inference algorithm is shown in Algorithm 2.

Algorithm 2: Inference for CNN-CRF
Input: face image x
Initialization: y0
while not converge do

i = µi  i = 1  . . .   N   t = 0;

Update ζ by Eq. (9). ζ t = arg minζ
i=1
Update y by Eq. (10). yt+1 = E(x  Θ  ζ t);
t = t + 1 ;

end

(cid:80)N

(cid:80)N

j=i+1 ψCij (yt

i  yt

j  ζ);

4 Experiments

Datasets. We evaluate our methods on popular benchmark facial landmark detection datasets 
including 300W [35]  Menpo [49]  COFW [6]  300VW [1].
300W has 68 landmark annotation. It contains 3837 faces for training and 300 indoor and 300 outdoor
faces for testing.
Menpo contains images from AFLW and FDDB with landmark re-annotation following the 68
landmark annotation scheme. It has two subsets  Menpo-frontal which has 68 landmark annotations
for near frontal faces (6679 samples) and Menpo-proﬁle which has 39 landmark annotations for
proﬁle faces (2300 samples). We use it as a test set for cross dataset evaluation.
COFW has 1345 training samples and 507 testing samples  whose facial images are all partially
occluded. The original dataset is annotated with 29 landmarks. We use the COFW-68 test set [19]
which has 68 landmarks re-annotation for cross dataset evaluation.
300VW is a facial video dataset with 68 landmarks annotation. It contains 3 scenarios: 1) constrained
laboratory and naturalistic well-lit conditions; 2) unconstrained real-world conditions with different
illuminations  dark rooms  overexposed shots  etc.; 3) completely unconstrained arbitrary conditions
including various illumination  occlusions  make-up  expression  head pose  etc. We use the test set
for cross dataset evaluation.
Evaluation metrics. We evaluate our algorithm using the standard normalized mean error (NME)
and the Cumulative Errors Distribution (CED) curve. Besides  the area-under-the-curve (AUC)
and the failure rate (FR) for a maximum error of 0.07 are reported. Same as in [5]  the NME is
deﬁned as the average point-to-point Euclidean distance between the ground truth (ygt) and predicted
wbbox ∗ hbbox 
(ypred) landmark locations normalized by the ground truth bounding box size d =
. Based on the NME in the test dataset  we can draw a CED Curve
NME = 1
N
with NME as the horizontal axis and percentage of test images as the vertical axis. Then the AUC is
computed as the area under that curve for each test dataset.
Implementation details. To make a fair comparison with the SoA purely deep learning based
methods [5]  we use the same training and testing procedure for 2D landmark detection. The 3D
deformable model was trained on the 300W-train dataset or 300W-LP dataset by structure from
motion [4]. For CNN  we use 4 stacks of Hourglass with the same structure as [5]  each stack followed
by a softmax layer to output a probability map for each facial landmark. From the probability map 
we compute mean µi and covariance Σi. And we use additional softmax cross entropy loss and L1
loss on the mean [38] to assist training which shows better performance empirically.
Training procedure: The initial learning rate η1 is 10−4 for 15 epochs using a minibatch of 10  then
dropped to 10−5 and 10−6 after every 15 epochs and keep training until convergence. The learning
rate η2 is set to 10−3. We applied random augmentations such as random cropping  rotation  etc. We
ﬁrst train the method on 300W-LP [54] dataset which is augmented from the original 300W dataset
for large yaw pose. And then we ﬁne-tune on the original 300W train dataset.
Testing procedure: We follow the same testing procedure as [5]. The face is cropped using the
ground truth bounding box deﬁned in 300W. The cropped face is rescaled to 256 × 256 before
passed to the network. For the Menpo-proﬁle dataset  the annotation scheme is different  we use the
overlapping 26 points for evaluation  i.e.  removing points other than the 2 endpoints on the face
contour and the eyebrow respectively and removing the 5th point on the nose contour.

(cid:80)N

pred−y(i)

gt ||2

||y(i)

√

i=1

d

4.1 Comparison with existing approaches

6

In Table 1  we compare with some most recent best results
reported  in the 300W protocol that trains on LFPW-train 
HELEN-train  AFW and tests on LFPW-test  HELEN-test 
ibug and use NME normalized with inter-ocular/pupil dis-
tance as the metric.
In Table 2  we compare with other baseline facial landmark
detection algorithms  including purely deep learning based
methods such as TCDCN [50] and FAN [5] as well as hybrid
methods such as CLNF [2] and CE-CLM [48]. The results
for these methods are evaluated using the code provided
by the authors in the same experiment protocol  i.e.  same
bounding box and same evaluation metrics. The CED curves
on the 300W testset are shown in Fig. 3a.

Table 1: Comparison with SoA meth-
ods on 300W dataset using 300W pro-
tocol (NME normalized with inter-
ocular/pupil distance %)
Com.

Subset

Chal.

Full

Method

Inter-ocular distance

-

5.03
3.34
2.98
2.93

4.83
4.20
4.06

-

8.95
6.60
5.19
4.84

10.14
7.41
6.98

4.05
5.80
3.98
3.49
3.30

5.88
4.92
4.63

MDM [42]
RDR [45]
SAN [17]
LAB (4-stack) [44]
Our method (4-stack)

MDM [42]
LAB (4-stack) [44]
Our method (4-stack)

Inter-pupil distance

(a) 300W testset

(b) Menpo-frontal dataset (c) Menpo-proﬁle dataset

(d) COFW-68 testset

Figure 3: CED curves on different datasets (better viewed in color and magniﬁed)

(a) 300VW category1

(b) 300VW category2

(c) 300VW category3

Figure 4: CED curves on 300VW testset (better viewed in color and magniﬁed)

Cross-dataset Evaluation
Besides 300W testset  we evaluate the proposed method on Menpo dataset  COFW-68 testset  300VW
testset for cross dataset evaluation. The results are shown in Table 2 for Menpo and COFW-68 dataset
and Table 3 for 300VW dataset. And the CED curves are shown in Fig. 3b  3c  3d respectively. The
method is trained on 300W-LP and ﬁne-tuned on 300W Challenge train set for 68 landmarks. We can
see that compared to the results on 300W testset and Menpo-frontal dataset  where the SoA methods
attaining saturating performance as mentioned in [5]  for cross-dataset evaluation in more challenging
conditions such as COFW with heavy occlusion and Menpo-proﬁle with large pose  the proposed
method shows better generalization ability with a signiﬁcant performance improvement. On the other
hand  the proposed method shows smallest failure rate (FR) on all evaluated datasets.

Table 2: Within and cross dataset prediction results (%)

300W-test

Menpo-frontal

Menpo-proﬁle

COFW-68 test

NME
4.15
3.09
6.90
4.22
3.05

-

2.86
2.21

AUC
42.1
56.7
20.6
47.6
56.9
66.9
59.7
68.1

FR
4.83
1.83
30.00
6.67
2.33

-

1.00
0.17

NME
4.04
3.91
6.57
3.74
2.78

-

2.95
2.01

AUC
46.2
57.4
28.7
55.4
63.3
67.5
61.9
71.0

FR
5.84
9.75
24.57
5.82
1.66

-

3.11
0.16

NME
13.96
15.04
8.37
8.32
4.63

-

8.80
3.03

AUC
5.9
15.2
20.5
27.8
45.2

-

29.0
60.0

FR
75.61
58.87
41.43
27.65
7.17

-

28.65
1.96

NME
4.71
3.79
8.13
4.75
3.36

-

3.50
2.55

AUC
35.8
49.0
18.2
42.9
52.4

-

51.9
63.2

FR
8.68
4.34
43.79
10.65
2.37

-

3.94
0.00

Dataset

Metric

Method
TCDCN [50]
CFSS [52]
3DDFA [54]
CLNF [2]
CE-CLM [48]
FAN (reported in [5])
SAN [17]
our method
4.2 Analysis

In this section  we report the results of sensitivity analysis and ablation study. If not speciﬁed  analysis
is performed on test datasets with models trained on 300W-LP and ﬁne-tuned on 300W train set.

7

01234567NME (%)0102030405060708090100Proportion of images (%)TCDCNCFSS3DDFACLNFCECLMFANSANproposed01234567NME (%)0102030405060708090100Proportion of images (%)TCDCNCFSS3DDFACLNFCECLMFANSANproposed01234567NME (%)0102030405060708090100Proportion of images (%)TCDCNCFSS3DDFACLNFCECLMFANSANproposed01234567NME (%)0102030405060708090100Proportion of images (%)TCDCNCFSS3DDFACLNFCECLMFANSANproposed01234567NME (%)0102030405060708090100Proportion of images (%)TCDCNCFSS3DDFACLNFCECLMFANSANproposed01234567NME (%)0102030405060708090100Proportion of images (%)TCDCNCFSS3DDFACLNFCECLMFANSANproposed01234567NME (%)0102030405060708090100Proportion of images (%)TCDCNCFSS3DDFACLNFCECLMFANSANproposedTable 3: 300VW testset prediction results for cross-dataset evaluation (%)
300VW-category3
Dataset

300VW-category2

300VW-category1

Metric

Method
TCDCN [50]
CFSS [52]
3DDFA [54]
CLNF [2]
CE-CLM [48]
FAN (reported in [5])
SAN [17]
our method

NME
3.49
2.44
5.80
3.34
2.54

-

2.58
1.91

AUC
51.2
67.0
32.4
60.4
65.7
72.1
64.5
73.3

FR
1.74
1.66
24.50
4.31
1.58

-

1.10
0.36

NME
3.80
2.49
4.44
2.98
2.39

-

2.57
1.97

AUC
45.8
64.3
39.2
60.0
66.0
71.2
63.2
71.6

FR
1.76
0.77
8.82
3.02
0.61

-

0.42
0.04

NME
4.45
3.26
5.48
4.73
3.61

-

4.06
2.50

AUC
43.8
60.5
31.6
47.1
56.4
64.1
52.9
67.4

FR
8.85
5.18
18.26
7.74
5.69

-

7.19
1.68

Sensitivity to challenging conditions. We evaluate different methods on challenging conditions
caused by either high noise  low resolution  or different initializations in Fig. 5. Generally  the
proposed CNN-CRF model is more robust under challenging conditions compared to a pure CNN
model with the same structure  i.e. the CNN-CRF model with Cij = 0.

(a) Noise

(b) Lower resolution

(c) Larger bounding box

Figure 5: Prediction error sensitivity to challenging conditions

Ablation Study. The improvement of the proposed method lies in two aspects. On the one hand  the
proposed softmax + L1 mean loss + Gaussian negative log likelihood (NLL) loss gives better results
empirically. On the other hand  the joint training of the CNN-CRF model with the assistance of the
deformable model captures structured relationships with pose and deformation awareness. To analyze
the effect of the proposed method  in Table 4  we evaluate the performance of a plain CNN prediction 
the 3D deformable model ﬁtting to the ground truth  and the joint CNN-CRF prediction accuracy.

Table 4: Ablation study on 300W testset (%)

Method
Plain CNN with softmax cross entropy loss
Plain CNN with softmax + L1 mean loss + Gaussian NLL loss (proposed loss)
Separately trained CNN and CRF with proposed loss
Deformable model ﬁtting
Jointly trained CNN-CRF with proposed loss (proposed method)

NME
2.38
2.30
2.23
1.39
2.21

AUC
65.9
67.4
67.8
79.8
68.1

FR
0.50
0.50
0.50
0.00
0.17

5 Conclusion

In this paper  we propose a method combining CNN with a fully-connected CRF model for facial
landmark detection. Compared to the state-of-the-art purely deep learning based methods  our method
explicitly captures the structured relationships between different facial landmark locations. Compared
to previous methods that combine CNN with CRF for human body pose estimation that learn a
ﬁxed pairwise relationship representation for different test samples implemented by convolution  our
methods capture the structure relationship variations caused by pose and deformation. Moreover 
we use a fully-connected model instead of a tree-structured model  obtaining a better representation
ability. Lastly  compared to previous methods that do approximate learning such as omitting the
partition function and inference such as mean-ﬁeld method  we perform exact learning and inference 
thus able to provide a better structured uncertainty. Experiments on benchmark datasets demonstrate
that the proposed method outperforms the existing state-of-the-art methods  in particular under
challenging conditions  for both within dataset and cross dataset.

8

Acknowledgment The work described in this paper is supported in part by NSF award IIS #1539012
and by RPI-IBM Cognitive Immersive Systems Laboratory (CISL)  a center in IBM’s AI Horizon
Network.

References
[1] 300VW dataset. http://ibug.doc.ic.ac.uk/resources/300-VW/  2015.

[2] Tadas Baltrušaitis  Peter Robinson  and Louis-Philippe Morency. Continuous conditional neural ﬁelds
for structured regression. In David Fleet  Tomas Pajdla  Bernt Schiele  and Tinne Tuytelaars  editors 
Computer Vision – ECCV 2014  pages 593–608  Cham  2014. Springer International Publishing.

[3] Yoshua Bengio  Yann LeCun  and Donnie Henderson. Globally trained handwritten word recognizer
using spatial representation  convolutional neural networks  and hidden markov models. In J. D. Cowan 
G. Tesauro  and J. Alspector  editors  Advances in Neural Information Processing Systems 6  pages 937–944.
Morgan-Kaufmann  1994.

[4] C. Bregler  L. Torresani  and A. Hertzmann. Nonrigid structure-from-motion: Estimating shape and motion
with hierarchical priors. IEEE Transactions on Pattern Analysis and Machine Intelligence  30(05):878–892 
may 2008.

[5] Adrian Bulat and Georgios Tzimiropoulos. How far are we from solving the 2d & 3d face alignment
problem? (and a dataset of 230 000 3d facial landmarks). In International Conference on Computer Vision 
2017.

[6] Xavier P. Burgos-Artizzu  Pietro Perona  and Piotr Dollár. Robust face landmark estimation under
occlusion. In Proceedings of the 2013 IEEE International Conference on Computer Vision  ICCV ’13 
pages 1513–1520  Washington  DC  USA  2013. IEEE Computer Society.

[7] Xudong Cao  Yichen Wei  Fang Wen  and Jian Sun. Face alignment by explicit shape regression. Interna-

tional Journal of Computer Vision  107(2):177–190  Apr 2014.

[8] Dong Chen  Shaoqing Ren  Yichen Wei  Xudong Cao  and Jian Sun. Joint cascade face detection and
alignment. In David Fleet  Tomas Pajdla  Bernt Schiele  and Tinne Tuytelaars  editors  Computer Vision –
ECCV 2014  pages 109–122  Cham  2014. Springer International Publishing.

[9] L. Chen  G. Papandreou  I. Kokkinos  K. Murphy  and A. L. Yuille. Deeplab: Semantic image segmentation
with deep convolutional nets  atrous convolution  and fully connected crfs. IEEE Transactions on Pattern
Analysis and Machine Intelligence  40(4):834–848  April 2018.

[10] Xianjie Chen and Alan Yuille. Articulated pose estimation by a graphical model with image dependent
pairwise relations. In Proceedings of the 27th International Conference on Neural Information Processing
Systems - Volume 1  NIPS’14  pages 1736–1744  Cambridge  MA  USA  2014. MIT Press.

[11] Xiao Chu  Wanli Ouyang  hongsheng Li  and Xiaogang Wang. Crf-cnn: Modeling structured information
in human pose estimation. In D. D. Lee  M. Sugiyama  U. V. Luxburg  I. Guyon  and R. Garnett  editors 
Advances in Neural Information Processing Systems 29  pages 316–324. Curran Associates  Inc.  2016.

[12] Xiao Chu  Wanli Ouyang  Hongsheng Li  and Xiaogang Wang. Structured feature learning for pose

estimation. In CVPR  2016.

[13] T. F. Cootes  G. J. Edwards  and C. J. Taylor. Active appearance models. In Hans Burkhardt and Bernd
Neumann  editors  Computer Vision — ECCV’98  pages 484–498  Berlin  Heidelberg  1998. Springer
Berlin Heidelberg.

[14] T.F. Cootes  C.J. Taylor  D.H. Cooper  and J. Graham. Active shape models-their training and application.

Computer Vision and Image Understanding  61(1):38 – 59  1995.

[15] Ciprian A. Corneanu  Meysam Madadi  and Sergio Escalera. Deep structure inference network for facial

action unit recognition. In ECCV  2018.

[16] Trinh–Minh–Tri Do and Thierry Artieres. Neural conditional random ﬁelds. In Yee Whye Teh and Mike
Titterington  editors  Proceedings of the Thirteenth International Conference on Artiﬁcial Intelligence and
Statistics  volume 9 of Proceedings of Machine Learning Research  pages 177–184  Chia Laguna Resort 
Sardinia  Italy  13–15 May 2010. PMLR.

9

[17] Xuanyi Dong  Yan Yan  Wanli Ouyang  and Yi Yang. Style aggregated network for facial landmark
detection. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 
pages 379–388  2018.

[18] David Eigen  Dilip Krishnan  and Rob Fergus. Restoring an image taken through a window covered with
dirt or rain. In Proceedings - 2013 IEEE International Conference on Computer Vision  ICCV 2013  pages
633–640. Institute of Electrical and Electronics Engineers Inc.  2013.

[19] Golnaz Ghiasi and Charless C. Fowlkes. Occlusion coherence: Detecting and localizing occluded faces.

CoRR  abs/1506.08347  2015.

[20] R. Girshick  F. Iandola  T. Darrell  and J. Malik. Deformable part models are convolutional neural networks.
In 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)  pages 437–446  June
2015.

[21] Max Jaderberg  Karen Simonyan  Andrea Vedaldi  and Andrew Zisserman. Deep Structured Output

Learning for Unconstrained Text Recognition. dec 2014.

[22] V. Jain  J. F. Murray  F. Roth  S. Turaga  V. Zhigulin  K. L. Briggman  M. N. Helmstaedter  W. Denk  and
H. S. Seung. Supervised learning of image restoration with convolutional networks. In 2007 IEEE 11th
International Conference on Computer Vision  pages 1–8  Oct 2007.

[23] Amin Jourabloo and Xiaoming Liu. Pose-invariant face alignment via cnn-based dense 3d model ﬁtting.

Int. J. Comput. Vision  124(2):187–203  September 2017.

[24] F. Kahraman  G. Muhitin  S. Darkner  and R. Larsen. An active illumination and appearance model for
face alignment. Turkish Journal of Electrical Engineering and Computer Science  18(4):677–692  2010.

[25] Neeraj Kumar  Peter N. Belhumeur  and Shree K. Nayar. Facetracer: A search engine for large collections

of images with faces. In The 10th European Conference on Computer Vision (ECCV)  October 2008.

[26] G. Lin  C. Shen  A. Hengel  and I. Reid. Efﬁcient piecewise training of deep structured models for semantic
segmentation. In 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)  pages
3194–3203  Los Alamitos  CA  USA  jun 2016. IEEE Computer Society.

[27] Iain Matthews and Simon Baker. Active appearance models revisited. International Journal of Computer

Vision  60(2):135–164  Nov 2004.

[28] Stephen Milborrow and Fred Nicolls. Locating facial features with an extended active shape model. In
Proceedings of the 10th European Conference on Computer Vision: Part IV  ECCV ’08  pages 504–513 
Berlin  Heidelberg  2008. Springer-Verlag.

[29] Frederic Morin and Yoshua Bengio. Hierarchical probabilistic neural network language model. In Robert G.
Cowell and Zoubin Ghahramani  editors  Proceedings of the Tenth International Workshop on Artiﬁcial
Intelligence and Statistics  pages 246–252. Society for Artiﬁcial Intelligence and Statistics  2005.

[30] Alejandro Newell  Kaiyu Yang  and Jia Deng. Stacked hourglass networks for human pose estimation. In
Computer Vision - ECCV 2016 - 14th European Conference  Amsterdam  The Netherlands  October 11-14 
2016  Proceedings  Part VIII  pages 483–499  2016.

[31] Feng Ning  D. Delhomme  Y. LeCun  F. Piano  L. Bottou  and P. E. Barbano. Toward automatic phenotyping

of developing embryos from videos. Trans. Img. Proc.  14(9):1360–1371  September 2005.

[32] Jian Peng  Liefeng Bo  and Jinbo Xu. Conditional neural ﬁelds. In Y. Bengio  D. Schuurmans  J. D.
Lafferty  C. K. I. Williams  and A. Culotta  editors  Advances in Neural Information Processing Systems
22  pages 1419–1427. Curran Associates  Inc.  2009.

[33] Vladan Radosavljevic  Slobodan Vucetic  and Zoran Obradovic. Continuous conditional random ﬁelds
for regression in remote sensing. In Proceedings of the 2010 Conference on ECAI 2010: 19th European
Conference on Artiﬁcial Intelligence  pages 809–814  Amsterdam  The Netherlands  The Netherlands 
2010. IOS Press.

[34] Kosta Ristovski  Vladan Radosavljevic  Slobodan Vucetic  and Zoran Obradovic. Continuous conditional

random ﬁelds for efﬁcient regression in large fully connected graphs. In AAAI  2013.

[35] Christos Sagonas  Epameinondas Antonakos  Georgios Tzimiropoulos  Stefanos Zafeiriou  and Maja

Pantic. 300 faces in-the-wild challenge. Image Vision Comput.  47(C):3–18  March 2016.

10

[36] J. Saragih and R. Goecke. A nonlinear discriminative approach to aam ﬁtting.

In 2007 IEEE 11th
International Conference on Computer Vision  pages 1–8  2007. Exported from https://app.dimensions.ai
on 2018/11/15.

[37] Jason M. Saragih  Simon Lucey  and Jeffrey F. Cohn. Deformable model ﬁtting by regularized landmark

mean-shift. International Journal of Computer Vision  91(2):200–215  Jan 2011.

[38] Xiao Sun  Bin Xiao  Shuang Liang  and Yichen Wei. Integral human pose regression. arXiv preprint

arXiv:1711.08229  2017.

[39] Yi Sun  Xiaogang Wang  and Xiaoou Tang. Deep convolutional network cascade for facial point de-
In Computer Vision - CVPR IEEE Computer Society Conference on Computer Vision and
tection.
Pattern Recognition. IEEE Computer Society Conference on Computer Vision and Pattern Recognition. .
10.1109/CVPR.2013.446.  Proceedings  pages 3476–3483  2013.

[40] Jonathan Tompson  Ross Goroshin  Arjun Jain  Yann LeCun  and Christoph Bregler. Efﬁcient object

localization using convolutional networks. In CVPR  2015.

[41] Jonathan Tompson  Arjun Jain  Yann LeCun  and Christoph Bregler. Joint training of a convolutional
network and a graphical model for human pose estimation. In Proceedings of the 27th International
Conference on Neural Information Processing Systems - Volume 1  NIPS’14  pages 1799–1807  Cambridge 
MA  USA  2014. MIT Press.

[42] George Trigeorgis  Patrick Snape  Mihalis A. Nicolaou  Epameinondas Antonakos  and Stefanos Zafeiriou.
Mnemonic descent method: A recurrent process applied for end-to-end face alignment. In CVPR  pages
4177–4187. IEEE Computer Society  2016.

[43] Shih-En Wei  Varun Ramakrishna  Takeo Kanade  and Yaser Sheikh. Convolutional pose machines. In
2016 IEEE Conference on Computer Vision and Pattern Recognition  CVPR 2016  Las Vegas  NV  USA 
June 27-30  2016  pages 4724–4732  2016.

[44] Wayne Wu  Chen Qian  Shuo Yang  Quan Wang  Yici Cai  and Qiang Zhou. Look at boundary: A

boundary-aware face alignment algorithm. In CVPR  2018.

[45] Shengtao Xiao  Jiashi Feng  Luoqi Liu  Xuecheng Nie  Wei Wang  Shuicheng Yan  and Ashraf Kassim.
In The IEEE International

Recurrent 3d-2d dual learning for large-pose facial landmark detection.
Conference on Computer Vision (ICCV)  Oct 2017.

[46] Xuehan Xiong and Fernando De la Torre. Global supervised descent method. In CVPR  pages 2664–2673.

IEEE Computer Society  2015.

[47] K. Yao  B. Peng  G. Zweig  D. Yu  X. Li  and F. Gao. Recurrent conditional random ﬁeld for language
understanding. In 2014 IEEE International Conference on Acoustics  Speech and Signal Processing
(ICASSP)  pages 4077–4081  May 2014.

[48] Amir Zadeh  Yao Chong Lim  Tadas Baltrusaitis  and Louis-Philippe Morency. Convolutional experts
constrained local model for 3d facial landmark detection. In The IEEE International Conference on
Computer Vision (ICCV) Workshops  Oct 2017.

[49] S. Zafeiriou  G. Trigeorgis  G. Chrysos  J. Deng  and J. Shen. The menpo facial landmark localisation
In 2017 IEEE Conference on Computer Vision and Pattern

challenge: A step towards the solution.
Recognition Workshops (CVPRW)  pages 2116–2125  July 2017.

[50] Zhanpeng Zhang  Ping Luo  Chen Change Loy  and Xiaoou Tang. Facial landmark detection by deep
multi-task learning. In David Fleet  Tomas Pajdla  Bernt Schiele  and Tinne Tuytelaars  editors  Computer
Vision – ECCV 2014  pages 94–108  Cham  2014. Springer International Publishing.

[51] Shuai Zheng  Sadeep Jayasumana  Bernardino Romera-Paredes  Vibhav Vineet  Zhizhong Su  Dalong
Du  Chang Huang  and Philip H. S. Torr. Conditional random ﬁelds as recurrent neural networks. In
Proceedings of the 2015 IEEE International Conference on Computer Vision (ICCV)  ICCV ’15  pages
1529–1537  Washington  DC  USA  2015. IEEE Computer Society.

[52] Shizhan Zhu  Cheng Li  Chen Change Loy  and Xiaoou Tang. Face alignment by coarse-to-ﬁne shape
searching. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition  pages
4998–5006  2015.

[53] Shizhan Zhu  Cheng Li  Chen Change Loy  and Xiaoou Tang. Unconstrained face alignment via cascaded
compositional learning. 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 
pages 3409–3417  2016.

[54] Xiangyu Zhu  Zhen Lei  Stan Z Li  et al. Face alignment in full pose range: A 3d total solution. IEEE

Transactions on Pattern Analysis and Machine Intelligence  2017.

11

,Lisha Chen
Hui Su
Qiang Ji