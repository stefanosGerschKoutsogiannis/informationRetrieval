2019,Tight Certificates of Adversarial Robustness for Randomly Smoothed Classifiers,Strong theoretical guarantees of robustness can be given for ensembles of classifiers generated by input randomization. Specifically  an $\ell_2$ bounded adversary cannot alter the ensemble prediction generated by an additive isotropic Gaussian noise  where the radius for the adversary depends on both the variance of the distribution as well as the ensemble margin at the point of interest. We build on and considerably expand this work across broad classes of distributions. In particular  we offer adversarial robustness guarantees and associated algorithms for the discrete case where the adversary is $\ell_0$ bounded. Moreover  we exemplify how the guarantees can be tightened with specific assumptions about the function class of the classifier such as a decision tree. We empirically illustrate these results with and without functional restrictions across image and molecule datasets.,Tight Certiﬁcates of Adversarial Robustness

for Randomly Smoothed Classiﬁers

Guang-He Lee1  Yang Yuan1 2  Shiyu Chang3  Tommi S. Jaakkola1

1MIT Computer Science and Artiﬁcial Intelligence Lab

2Institute for Interdisciplinary Information Sciences  Tsinghua University

{guanghe  yangyuan  tommi}@csail.mit.edu  shiyu.chang@ibm.com

3MIT-IBM Watson AI Lab

Abstract

Strong theoretical guarantees of robustness can be given for ensembles of classiﬁers
generated by input randomization. Speciﬁcally  an (cid:96)2 bounded adversary cannot
alter the ensemble prediction generated by an additive isotropic Gaussian noise 
where the radius for the adversary depends on both the variance of the distribution as
well as the ensemble margin at the point of interest. We build on and considerably
expand this work across broad classes of distributions. In particular  we offer
adversarial robustness guarantees and associated algorithms for the discrete case
where the adversary is (cid:96)0 bounded. Moreover  we exemplify how the guarantees
can be tightened with speciﬁc assumptions about the function class of the classiﬁer
such as a decision tree. We empirically illustrate these results with and without
functional restrictions across image and molecule datasets.1

1

Introduction

Many powerful classiﬁers lack robustness in the sense that a slight  potentially unnoticeable manipu-
lation of the input features  e.g.  by an adversary  can cause the classiﬁer to change its prediction [15].
The effect is clearly undesirable in decision critical applications. Indeed  a lot of recent work has
gone into analyzing such failures together with providing certiﬁcates of robustness.
Robustness can be deﬁned with respect to a variety of metrics that bound the magnitude or the
type of adversarial manipulation. The most common approach to searching for violations is by
ﬁnding an adversarial example within a small neighborhood of the example in question  e.g.  using
gradient-based algorithms [13  15  26]. The downside of such approaches is that failure to discover
an adversarial example does not mean that another technique could not ﬁnd one. For this reason  a
recent line of work has instead focused on certiﬁcates of robustness  i.e.  guarantees that ensure  for
speciﬁc classes of methods  that no adversarial examples exist within a certiﬁed region. Unfortunately 
obtaining exact guarantees can be computationally intractable [20  25  36]  and guarantees that scale
to realistic architectures have remained somewhat conservative [7  27  38  39  42].
Ensemble classiﬁers have recently been shown to yield strong guarantees of robustness [6]. The
ensembles  in this case  are simply induced from randomly perturbing the input to a base classiﬁer.
The guarantees state that  given an additive isotropic Gaussian noise on the input example  an
adversary cannot alter the prediction of the corresponding ensemble within an (cid:96)2 radius  where the
radius depends on the noise variance as well as the ensemble margin at the given point [6].
In this work  we substantially extend robustness certiﬁcates for such noise-induced ensembles. We
provide guarantees for alternative metrics and noise distributions (e.g.  uniform)  develop a stratiﬁed

1Project page: http://people.csail.mit.edu/guanghe/randomized_smoothing.

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

likelihood ratio analysis that allows us to provide certiﬁcates of robustness over discrete spaces
with respect to (cid:96)0 distance  which are tight and applicable to any measurable classiﬁers. We also
introduce scalable algorithms for computing the certiﬁcates. The guarantees can be further tightened
by introducing additional assumptions about the family of classiﬁers. We illustrate this in the context
of ensembles derived from decision trees. Empirically  our ensemble classiﬁers yield the state-of-the-
art certiﬁed guarantees with respect to (cid:96)0 bounded adversaries across image and molecule datasets in
comparison to the previous methods adapted from continuous spaces.

2 Related Work

In a classiﬁcation setting  the role of robustness certiﬁcates is to guarantee a constant classiﬁcation
within a local region; a certiﬁcate is always sufﬁcient to claim robustness. When a certiﬁcate is
both sufﬁcient and necessary  it is called an exact certiﬁcate. For example  the exact (cid:96)2 certiﬁcate
of a linear classiﬁer is the (cid:96)2 distance between the classiﬁer and a given point. Below we focus the
discussions on the recent development of robustness guarantees for deep networks.
Most of the exact methods are derived on piecewise linear networks  deﬁned as any network archi-
tectures with piecewise linear activation functions. Such class of networks has a mix integer-linear
representation [22]  which allows the usage of mix integer-linear programming [4  9  14  25  36] or
satisﬁability modulo theories [3  12  20  33] to ﬁnd the exact adversary under an (cid:96)q radius. However 
the exact method is in general NP-complete  and thus does not scale to large problems [36].
A certiﬁcate that only holds a sufﬁcient condition is conservative but can be more scalable than exact
methods. Such guarantees may be derived as a linear program [39  40]  a semideﬁnite program [30 
31]  or a dual optimization problem [10  11] through relaxation. Alternative approaches conduct layer-
wise relaxations of feasible neuron values to derive the certiﬁcates [16  27  34  38  42]. Unfortunately 
there is no empirical evidence of an effective certiﬁcate from the above methods in large scale
problems. This does not entail that the certiﬁcates are not tight enough in practice; it might also be
attributed to the fact that it is challenging to obtain a robust network in a large scale setting.
Recent works propose a new modeling scheme that ensembles a classiﬁer by input randomization [2 
24]  mostly done via an additive isotropic Gaussian noise. Lecuyer et al. [21] ﬁrst propose a certiﬁcate
based on differential privacy  which is improved by Li et al. [23] using R´enyi divergence. Cohen et
al. [6] proceed with the analysis by proving the tight certiﬁcate with respect to all the measurable
classiﬁers based on the Neyman-Pearson Lemma [28]  which yields the state-of-the-art provably
robust classiﬁer. However  the tight certiﬁcate is tailored to an isotropic Gaussian distribution and (cid:96)2
metric  while we generalize the result across broad classes of distributions and metrics. In addition 
we show that such tight guarantee can be tightened with assumptions about the classiﬁer.
Our method of certiﬁcation also yields the ﬁrst tight and actionable (cid:96)0 robustness certiﬁcates in
discrete domains (cf. continuous domains where an adversary is easy to ﬁnd [15]). Robustness
guarantees in discrete domains are combinatorial in nature and thus challenging to obtain. Indeed 
even for simple binary vectors  verifying robustness requires checking an exponential number of
predictions for any black-box model.2

3 Certiﬁcation Methodology
Given an input x ∈ X   a randomization scheme φ assigns a probability mass/density Pr(φ(x) = z)
for each randomized outcome z ∈ X . We can deﬁne a probabilistic classiﬁer either by specifying
the associated conditional distribution P(y|x) for a class y ∈ Y or by viewing it as a random
function f (x) where the randomness in the output is independent for each x. We compose the
randomization scheme φ with a classiﬁer f to get a randomly smoothed classiﬁer Eφ[P(y|φ(x))] 
where the probability for outputting a class y ∈ Y is denoted as Pr(f (φ(x)) = y) and abbreviated
as p  whenever f  φ  x and y are clear from the context. Under this setting  we ﬁrst develop our
framework for tight robustness certiﬁcates in §3.1  exemplify the framework in §3.2-3.4  and illustrate
how the guarantees can be reﬁned with further assumption in §3.5-3.6. We defer all the proofs to
Appendix A.

2We are aware of two concurrent works also yielding certiﬁcates in discrete domain [18  19].

2

3.1 A Framework for Tight Certiﬁcates of Robustness

In this section  we develop our framework for deriving tight certiﬁcates of robustness for randomly
smoothed classiﬁers  which will be instantiated in the following sections.

Point-wise Certiﬁcate. Given p  we ﬁrst identify a tight lower bound on the probability score
Pr(f (φ( ¯x)) = y) for another (neighboring) point ¯x ∈ X . Here we denote the set of measurable
classiﬁers with respect to φ as F. Without any additional assumptions on f  a lower bound can be
found by the minimization problem:

ρx  ¯x(p) (cid:44)

min

¯f∈F :Pr( ¯f (φ(x))=y)=p

Pr( ¯f (φ( ¯x)) = y) ≤ Pr(f (φ( ¯x)) = y).

(1)

Note that bound is tight since f satisﬁes the constraint.

Regional Certiﬁcate. We can extend the point-wise certiﬁcate ρx  ¯x(p) to a regional certiﬁcate by
examining the worst case ¯x over the neighboring region around x. Formally  given an (cid:96)q metric
(cid:107) · (cid:107)q  the neighborhood around x with radius r is deﬁned as Br q(x) (cid:44) { ¯x ∈ X : (cid:107)x − ¯x(cid:107)q ≤ r}.
Assuming p = Pr(f (φ(x)) = y) > 0.5 for a y ∈ Y  a robustness certiﬁcate on the (cid:96)q radius can be
found by

R(x  p  q) (cid:44) sup r  s.t. min

¯x∈Br q(x)

ρx  ¯x(p) > 0.5.

(2)

Essentially  the certiﬁcate R(x  p  q) entails the following robustness guarantee:

∀ ¯x ∈ X : (cid:107)x − ¯x(cid:107)q < R(x  p  q)  we have Pr(f (φ( ¯x)) = y) > 0.5.

(3)
When the maximum can be attained in Eq. (2) (which will be the case in (cid:96)0 norm)  the above <
can be replaced with ≤. Note that here we assume Pr(f (φ(x)) = y) > 0.5 and ignore the case
that 0.5 ≥ Pr(f (φ( ¯x)) = y) > maxy(cid:48)(cid:54)=y Pr(f (φ( ¯x)) = y(cid:48)). By deﬁnition  the certiﬁed radius
R(x  p  q) is tight for binary classiﬁcation  and provides a reasonable sufﬁcient condition to guarantee
robustness for |Y| > 2. The tight guarantee for |Y| > 2 will involve the maximum prediction
probability over all the remaining classes (see Theorem 1 of [6]). However  when the prediction
probability p = Pr(f (φ(x)) = y) is intractable to compute and relies on statistical estimation for
each class y (e.g.  when f is a deep network)  the tight guarantee is statistically challenging to obtain.
The actual algorithm used by Cohen et al. [6] is also a special case of Eq. (2).

3.2 A Warm-up Example: the Uniform Distribution
To illustrate the framework  we show a simple (but new) scenario when X =
Rd and φ is an additive uniform noise with a parameter γ ∈ R>0:

φ(x)i = xi + i  i

i.i.d.∼ Uniform([−γ  γ]) ∀i ∈ {1  . . .   d}.

(4)
Given two points x and ¯x  as illustrated in Fig. 1  we can partition the space Rd
into 4 disjoint regions: L1 = Bγ ∞(x)\Bγ ∞( ¯x)  L2 = Bγ ∞(x) ∩ Bγ ∞( ¯x) 
L3 = Bγ ∞( ¯x)\Bγ ∞(x) and L4 = Rd\(Bγ ∞( ¯x)∪Bγ ∞(x)). Accordingly 
∀ ¯f ∈ F  we can rewrite Pr( ¯f (φ(x)) = y) and Pr( ¯f (φ( ¯x)) = y) as follows:

Pr( ¯f (φ(x)) = y) =

Pr( ¯f (φ( ¯x)) = y) =

Pr(φ(x) = z) Pr( ¯f (z) = y))dz =

Pr(φ( ¯x) = z) Pr( ¯f (z) = y))dz =

L4

L1

¯x

L3

L2
x

Figure 1: Uniform
distributions.

Pr( ¯f (z) = y))dz 

Pr( ¯f (z) = y))dz 

4(cid:88)
4(cid:88)

i=1

i=1

πi

¯πi

(cid:90)
(cid:90)

Li

Li

(cid:90)
(cid:90)

4(cid:88)
4(cid:88)

i=1

i=1

Li

Li

where π1:4 = ((2γ)−d  (2γ)−d  0  0)  and ¯π1:4 = (0  (2γ)−d  (2γ)−d  0). With this representation  it
is clear that  in order to solve Eq. (1)  we only have to consider the integral behavior of ¯f within each
region L1  . . .  L4. Concretely  we have:

ρx  ¯x(p) =

¯f∈F :(cid:80)4

i=1 πi

(cid:82)

min
Li

Pr( ¯f (z)=y))dz=p

Pr( ¯f (z) = y))dz

=

min

g:{1 2 3 4}→[0 1] 

π1|L1|g(1)+π2|L2|g(2)=p

¯π2|L2|g(2) + ¯π3|L3|g(3) =

min

g:{1 2 3 4}→[0 1] 

π1|L1|g(1)+π2|L2|g(2)=p

¯π2|L2|g(2) 

(cid:90)

¯πi

Li

4(cid:88)

i=1

3

where the second equality ﬁlters the components with πi = 0 or ¯πi = 0  and the last equality is due
to the fact that g(3) is unconstrained and minimizes the objective when g(3) = 0. Since π2 = ¯π2 

(cid:26)ρx  ¯x(p) = 0 

ρx  ¯x(p) = p − π1|L1| 

if 0 ≤ p ≤ π1|L1| = Pr(φ(x) ∈ L1) 
if 1 ≥ p > π1|L1| = Pr(φ(x) ∈ L1).

To obtain the regional certiﬁcate  the minimizers of min ¯x∈Br q(x) ρx  ¯x(p) are simply the points that
maximize the volume of L1 = B1\B2. Accordingly 
Proposition 1. If φ(·) is deﬁned as Eq. (4)  we have R(x  p  q = 1) = 2pγ−γ and R(x  p  q =
∞) = 2γ−2γ(1.5 − p)1/d.

Discussion. Our goal here was to illustrate how certiﬁcates can be computed with the uniform
distribution using our technique. However  the certiﬁcate radius itself is inadequate in this case. For
example  R(x  p  q = 1) ≤ γ  which arises from the bounded support in the uniform distribution. The
derivation nevertheless provides some insights about how one can compute the point-wise certiﬁcate
ρx  ¯x(p). The key step is to partition the space into regions L1  . . .  L4  where the likelihoods
Pr(φ(x) = z) and Pr(φ( ¯x) = z) are both constant within each region Li. The property allows
us to substantially reduce the optimization problem in Eq. (1) to ﬁnding a single probability value
g(i) ∈ [0  1] for each region Li.

3.3 A General Lemma for Point-wise Certiﬁcate

In this section  we generalize the idea in §3.2 to ﬁnd the point-wise certiﬁcate ρx  ¯x(p). For each point
z ∈ X   we deﬁne the likelihood ratio ηx  ¯x(z) (cid:44) Pr(φ(x) = z)/ Pr(φ( ¯x) = z).3 If we can partition
X into n regions L1  . . .  Ln : ∪n
i=1Li = X for some n ∈ Z>0  such that the likelihood ratio within
each region Li is a constant ηi ∈ [0 ∞]: ηx  ¯x(z) = ηi ∀z ∈ Li  then we can sort the regions such
that η1 ≥ η2 ≥ ··· ≥ ηn. Note that X can still be uncountable (see the example in §3.2).
Informally  we can always “normalize” ¯f so that it predicts a constant probability value g(i) ∈
[0  1] within each likelihood ratio region Li. This preserves the integral over Li and thus over X  
generalizing the scenario in §3.2. Moreover  to minimize Pr( ¯f (φ( ¯x)) = y) under a ﬁxed budget
Pr( ¯f (φ(x)) = y)  as in Eq. (1)  it is advantageous to set ¯f (z) to y in regions with high likelihood
ratio. These arguments suggest a greedy algorithm for solving Eq. (1) by iteratively assigning
f (z) = y ∀z ∈ Li for i ∈ (1  2  . . . ) until the budget constraint is met. Formally 
Lemma 2. ∀x  ¯x ∈ X   p ∈ [0  1]  let H∗ (cid:44) minH∈{1 ... n}:(cid:80)H
any f∗ satisfying Eq. (5) is a minimizer of Eq. (1) 
p−(cid:80)H∗−1

i=1 Pr(φ(x)∈Li)≥p H  then ηH∗ > 0 

∀i ∈ {1  2  . . .   n} ∀z ∈ Li  Pr(f∗(z) = y) =

1 
i=1 Pr(φ( ¯x) ∈ Li) + (p −(cid:80)H∗−1

0 

and ρx  ¯x(p) =(cid:80)H∗−1

if i < H∗ 
if i = H∗ 
if i > H∗.

(5)

i=1 Pr(φ(x)∈Li)
Pr(φ(x)∈LH∗ )

 

i=1 Pr(φ(x) ∈ Li))/ηH∗

We remark that Eq. (1) and Lemma 2 can be interpreted as a likelihood ratio testing [28]  by casting
Pr(φ(x) = z) and Pr(φ( ¯x) = z) as likelihoods for two hypothesis with the signiﬁcance level p. We
refer the readers to [37] to see a similar Lemma derived under the language of hypothesis testing.
Remark 3. ρx  ¯x(p) is an increasing continuous function of p; if η1 < ∞  ρx  ¯x(p) is a strictly
increasing continuous function of p; if η1 < ∞ and ηn > 0  ρx  ¯x : [0  1] → [0  1] is a bijection.
Remark 3 will be used in §3.4 to derive an efﬁcient algorithm to compute robustness certiﬁcates.
Discussion. Given Li  Pr(φ(x) ∈ Li)  and Pr(φ( ¯x) ∈ Li) ∀i ∈ [n]  Lemma 2 provides an O(n)
method to compute ρx  ¯x(p). For any actual randomization φ  the key is to ﬁnd a partition L1  . . .  Ln
such that Pr(φ(x) ∈ Li) and Pr(φ( ¯x) ∈ Li) are easy to compute. Having constant likelihoods in
each Li : Pr(φ(x) = z) = Pr(φ(x) = z(cid:48)) ∀z  z(cid:48) ∈ Li (cf. only having constant likelihood ratio
ηi) is a way to simplify Pr(φ(x) ∈ Li) = |Li| Pr(φ(x) = z)  and similarly for Pr(φ( ¯x) ∈ Li).

3If Pr(φ( ¯x) = z) = Pr(φ(x) = z) = 0  ηx  ¯x(z) can be deﬁned arbitrarily in [0 ∞] without affecting the

solution in Lemma 2.

4

3.4 A Discrete Distribution for (cid:96)0 Robustness

We consider (cid:96)0 robustness guarantees in a discrete space X =(cid:8)0  1
(cid:26)Pr(φ(x)i = xi) = α 
if z ∈(cid:8)0  1

Pr(φ(x)i = z) = (1 − α)/K (cid:44) β ∈ (0  1/K) 

K   2

K   . . .   1(cid:9)d for some K ∈
K   . . .   1(cid:9) and z (cid:54)= xi.

(6)

Z>0;4 we deﬁne the following discrete distribution with a parameter α ∈ (0  1)  independent and
identically distributed for each dimension i ∈ {1  2  . . .   d}:

K   2

Here φ(·) can be regarded as a composition of a Bernoulli random variable and a uniform random
variable. Due to the symmetry of the randomization with respect to all the conﬁgurations of x  ¯x ∈ X
such that (cid:107)x − ¯x(cid:107)0 = r (for some r ∈ Z≥0)  we have the following Lemma for the equivalence of
ρx  ¯x:
Lemma 4. If φ(·) is deﬁned as Eq. (6)  given r ∈ Z≥0  deﬁne the canonical vectors xC (cid:44)
(0  0 ···   0) and ¯xC (cid:44) (1  1 ···   1  0  0 ···   0)  where (cid:107) ¯xC(cid:107)0 = r. Let ρr (cid:44) ρxC   ¯xC . Then
for all x  ¯x such that (cid:107)x − ¯x(cid:107)0 = r  we have ρx  ¯x = ρr.
d − r = 3
Based on Lemma 4  ﬁnding R(x  p  q) for a given p  it sufﬁces to
ﬁnd the maximum r such that ρr(p) > 0.5. Since the likelihood
ratio ηx  ¯x(z) is always positive and ﬁnite  the inverse ρ−1
exists
(due to Remark 3)  which allows us to pre-compute ρ−1
r (0.5) and
r (0.5) for each r ∈ Z≥0  instead of computing
check p > ρ−1
ρr(p) for each given p and r. Then R(x  p  q) is simply the
maximum r such that p > ρ−1
r (0.5). Below we discuss how to
compute ρ−1
r (0.5) in a scalable way. Our ﬁrst step is to identify
a set of likelihood ratio regions L1  . . .  Ln such that Pr(φ(x) ∈
Li) and Pr(φ( ¯x) ∈ Li) as used in Lemma 2 can be computed
efﬁciently. Note that  due to Lemma 4  it sufﬁces to consider
xC  ¯xC such that (cid:107) ¯xC(cid:107)0 = r throughout the derivation.
For an (cid:96)0 radius r ∈ Z≥0  ∀(u  v) ∈ {0  1  . . .   d}2  we construct the region

Figure 2: Illustration for Eq. (7)

u = 4

v = 5

d = 7

r = 4

¯xC

xC

1
K

3
K

1

1

0

0

0

0

z

0

0

0

1

1

0

1

0

0

0

0

0

1

r

L(u  v; r) (cid:44) {z ∈ X : Pr(φ(xC) = z) = αd−uβu  Pr(φ( ¯xC) = z) = αd−vβv} 

(7)
which contains points that can be obtained by “ﬂipping” u coordinates from xC or v coordinates from
¯xC. See Figure 2 for an illustration  where different colors represent different types of coordinates:
orange means both xC  ¯xC are ﬂipped on this coordinate and they were initially the same; red means
both are ﬂipped and were initially different; green means only xC is ﬂipped and blue means only ¯xC
is ﬂipped. By denoting the numbers of these coordinates as i  j∗  u − i − j∗  v − i − j∗  respectively 
we have the following formula for computing the cardinality of each region |L(u  v; r)|.
Lemma 5. For any u  v ∈ {0  1  . . .   d}  u ≤ v  r ∈ Z≥0 we have |L(u  v; r)| = |L(v  u; r)|  and

min(u d−r (cid:98) u+v−r

(cid:99))(cid:88)

2

i=max{0 v−r}

where j∗ (cid:44) u + v − 2i − r.

|L(u  v; r)| =

(K − 1)j∗

r!

(u − i − j∗)!(v − i − j∗)!j∗!

K i(d − r)!
(d − r − i)!i!

 

Therefore  for a ﬁxed r  the complexity of computing all the cardinalities |L(u  v; r)| is Θ(d3).
Since each region L(u  v; r) has a constant likelihood ratio αv−uβu−v and we have ∪d
L(u  v; r) = X   we can apply the regions to ﬁnd the function ρx  ¯x = ρr via Lemma 2. Under
this representation  the number of nonempty likelihood ratio regions n is bounded by (d + 1)2  the
perturbation probability Pr(φ(x) ∈ L(u  v; r)) used in Lemma 2 is simply αd−uβu|L(u  v; r)|  and
similarly for the Pr(φ( ¯x) ∈ L(u  v; r)). Based on Lemma 2 and Lemma 5  we may use a for-loop
to compute the bijection ρr(·) for the input p until ρr(p) = 0.5  and return the corresponding p as
ρ−1
r (0.5). The procedure is illustrated in Algorithm 1.

u=0 ∪d

v=0

4More generally  the method applies to the (cid:96)0 / Hamming distance in a Hamming space (i.e.  ﬁxed length

sequences of tokens from a discrete set  e.g.  (♠10 ♠J ♠Q ♠K ♠A) ∈ {♠A ♠K  ... ♣2}5).

5

ratio

Algorithm 1 Computing ρ−1
1: sort {(ui  vi)}n

r (0.5)
i=1 by likelihood

2: p  ρr = 0  0
3: for i = 1  . . .   n do
p(cid:48) = αd−uiβui
4:
ρ(cid:48)
r = αd−vi βvi
5:
r × |L(ui  vi; r)|
6: ∆ρr = ρ(cid:48)
if ρr + ∆ρr < 0.5 then
7:
8:
9:
10:
11:
12:
end if
13:
14: end for

Scalable implementation.
In practice  Algorithm 1 can
be challenging to implement; the probability values (e.g. 
αd−uβu) can be extremely small  which is infeasible to be
computationally represented using ﬂoating points. If we set
α to be a rational number  both α and β can be represented
in fractions  and thus all the corresponding probability values
can be represented by two (large) integers; we also observe
that computing the (large) cardinality |L(u  v; r)| is feasible
in modern large integer computation frameworks in practice
(e.g.  python)  which motivates us to adapt the computation
in Algorithm 1 to large integers.
For simplicity  we assume α = α(cid:48)/100 with some α(cid:48) ∈
Z : 100 ≥ α(cid:48) ≥ 0. If we deﬁne ˜α (cid:44) 100Kα ∈ Z  ˜β (cid:44)
100Kβ ∈ Z  we may implement Algorithm 1 in terms of the
non-normalized  integer version ˜α  ˜β. Speciﬁcally  we replace
α  β and the constant 0.5 with ˜α  ˜β and 50K × (100K)d−1 
respectively. Then all the computations in Algorithm 1 can be
r. Since the division is bounded by |L(ui  vi; r)|
trivially adapted except the division (0.5 − ρr)/ρ(cid:48)
(see the comparison between line 9 and line 11)  we can implement the division by a binary search
over {1  2 . . .  |L{mi  ni}|}  which will result in an upper bound with an error bounded by ρ(cid:48)
r in
the original space  which is in turn bounded by αd assuming α > β. Finally  to map the computed 
unnormalized ρ−1
r (0.5)  back to the original space  we ﬁnd an upper bound of
r (0.5) up to the precision of 10−c for some c ∈ Z>0 (we set c = 20 in the experiments): we ﬁnd
ρ−1
r (0.5) ≤ ˆρ × (10K)c(100K)d−c over ˆρ ∈ {1  2  . . .   10c} via binary
the smallest upper bound of ˜ρ−1
r (0.5) as ˆρ × 10−c with an error bounded by 10−c + αd in
search  and report an upper bound of ρ−1
total. Note that an upper bound of ρ−1
As a side note  simply computing the probabilities in the log-domain will lead to uncontrollable
approximate results due to ﬂoating point arithmetic; using large integers to ensure a veriﬁable
approximation error in Algorithm 1 is necessary to ensure a computationally accurate certiﬁcate.

ρr = ρr + ∆ρr
p = p + p(cid:48) ×|L(ui  vi; r)|
p = p + p(cid:48) × (0.5 − ρr)/ρ(cid:48)
return p

r (0.5) is still a valid certiﬁcate.

r (0.5)  denoted as ˜ρ−1

else

r

3.5 Connection Between the Discrete Distribution and an Isotropic Gaussian Distribution
When the inputs are binary vectors X = {0  1}d  one may still apply the prior work [6] using an
additive isotropic Gaussian noise φ to obtain an (cid:96)0 certiﬁcates since there is a bijection between
(cid:96)0 and (cid:96)2 distance in {0  1}d. If one uses a denoising function ζ(·) that projects each randomized
coordinate φ(x)i ∈ R back to the space {0  1} using the (likelihood ratio testing) rule

ζ(φ(x))i = I{φ(x)i > 0.5} ∀i ∈ [d] 

then the composition ζ ◦ φ is equivalent to our discrete randomization scheme with α = Φ(0.5; µ =
0  σ2)  where Φ is the CDF function of the Gaussian distribution with mean µ and variance σ2.
If one applies a classiﬁer upon the composition (or  equivalently  the discrete randomization scheme) 
then the certiﬁcates obtained via the discrete distribution is always tighter than the one via Gaussian
distribution. Concretely  we denote Fζ ⊂ F as the set of measurable functions with respect to the
Gaussian distribution that can be written as the composition ¯f(cid:48) ◦ ζ for some ¯f(cid:48)  and we have
Pr( ¯f (φ( ¯x)) = y) 

Pr( ¯f (φ( ¯x)) = y) ≥

min

min

¯f∈Fζ :Pr( ¯f (φ(x))=y)=p

¯f∈F :Pr( ¯f (φ(x))=y)=p

where the LHS corresponds to the certiﬁcate derived from the discrete distribution (i.e.  applying ζ to
an isotropic Gaussian)  and the RHS corresponds to the certiﬁcate from the Gaussian distribution.

3.6 A Certiﬁcate with Additional Assumptions

In the previous analyses  we assume nothing but the measurability of the classiﬁer. If we further make
assumptions about the functional class of the classiﬁer  we can obtain a tighter certiﬁcate than the
ones outlined in §3.1. Assuming an extra denoising step in the classiﬁer over an additive Gaussian
noise as illustrated in §3.5 is one example.

6

Here we illustrate the idea with another example. We assume that the inputs are binary vectors
X = {0  1}d  the outputs are binary Y = {0  1}  and that the classiﬁer is a decision tree that each
input coordinate can be used at most once in the entire tree. Under the discrete randomization scheme 
the prediction probability can be computed via tree recursion  since a decision tree over the discrete
randomization scheme can be interpreted as assigning a probability of visiting the left child and the
right child for each decision node. To elaborate  we denote idx[i]  left[i]  and right[i] as the split
feature index  the left child and the right child of the ith node. Without loss of generality  we assume
that each decision node i routes its input to the right branch if xidx[i] = 1. Then Pr(f (φ(x)) = 1)
can be found by the recursion

I{xidx[i]=1}β

I{xidx[i]=0}pred[right[i]] + α

I{xidx[i]=0}β

I{xidx[i]=1}pred[left[i]] 

pred[i] = α

(8)
where the boundary condition is the output of the leaf nodes. Effectively  we are recursively
aggregating the partial solutions found in the left subtree and the right subtree rooted at each node i 
and pred[root] is the ﬁnal prediction probability. Note that changing one input coordinate in xk is
equivalent to changing the recursion in the corresponding unique node i(cid:48) (if exists) that uses feature k
as the splitting index  which gives
I{xidx[i(cid:48) ]=0}pred[left[i(cid:48)]].
pred[i(cid:48)] = α
In addition  changes in the left subtree do not affect the partial solution found in the right subtree 
and vice versa. Hence  we may use dynamic programming to ﬁnd the exact adversary under each (cid:96)0
radius r by aggregating the worst case changes found in the left subtree and the right subtree rooted
at each node i. See Appendix B.1 for details.

I{xidx[i(cid:48) ]=1}pred[right[i(cid:48)]] + α

I{xidx[i(cid:48) ]=1}β

I{xidx[i(cid:48) ]=0}β

4 Learning and Prediction in Practice

Since we focus on the development of certiﬁcates  here we only brieﬂy discuss how we train the
classiﬁers and compute the prediction probability Pr(f (φ(x)) = y) in practice.

Deep networks: We follow the approach proposed by the prior work [21]: training is conducted on
samples drawn from the randomization scheme via a cross entropy loss. The prediction probability
Pr(f (φ(x)) = y) is estimated by the lower bound of the Clopper-Pearson Bernoulli conﬁdence
interval [5] with 100K samples drawn from the distribution and the 99.9% conﬁdence level. Since
ρx  ¯x(p) is an increasing function of p (Remark 3)  a lower bound of p entails a valid certiﬁcate.
Decision trees: we train the decision tree greedily in a breadth-ﬁrst ordering with a depth limit; for
each split  we only search coordinates that are not used before to enforce the functional constraint in
§3.6  and optimize a weighted gini index  which weights each training example x by the probability
that it is routed to the node by the discrete randomization. The details of the training algorithm is in
Appendix B.2. The prediction probability is computed by Eq. (8).

5 Experiment
In this section  we validate the robustness certiﬁcates of the proposed discrete distribution (D) in
(cid:96)0 norm. We compare to the state-of-the-art additive isotropic Gaussian noise (N ) [6]  since an (cid:96)0
certiﬁcate with radius r in X = {0  1
K   . . .   1}d can be obtained from an (cid:96)2 certiﬁcate with radius
√
r. Note that the derived (cid:96)0 certiﬁcate from Gaussian distribution is still tight with respect to all the
measurable classiﬁers (see Theorem 1 in [6]). We consider the following evaluation measures:
• µ(R): the average certiﬁed (cid:96)0 radius R(x  p  q) (with respect to the labels) across the testing set.
• ACC@r: the certiﬁed accuracy within a radius r (the average I{R(x  p  q) ≥ r} in the testing set).

5.1 Binarized MNIST

We use a 55  000/5  000/10  000 split of the MNIST dataset for training/validation/testing. For each
data point x in the dataset  we binarize each coordinate by setting the threshold as 0.5. Experiments are
conducted on randomly smoothed CNN models and the implementation details are in Appendix C.1.
The results are shown in Table 1. For the same randomly smoothed CNN model (the 1st and 2nd
rows in Table 1)  our certiﬁcates are consistently better than the ones derived from the Gaussian

7

Table 1: Randomly smoothed CNN models on the MNIST dataset. The ﬁrst two rows refer to the
same model with certiﬁcates computed via different methods (see details in §3.5).

φ

D
D
N

Certiﬁcate

µ(R)

D
N [6]
N [6]

3.456
1.799
2.378

ACC@r

r = 1
0.921
0.830
0.884

r = 2
0.774
0.557
0.701

r = 3
0.539
0.272
0.464

r = 4
0.524
0.119
0.252

r = 5
0.357
0.021
0.078

r = 6
0.202
0.000
0.000

r = 7
0.097
0.000
0.000

Table 2: The guaranteed accuracy of randomly smoothed ResNet50 models on ImageNet.

φ and certiﬁcate

ACC@r

D
N [6]

r = 1
0.538
0.372

r = 2
0.394
0.292

r = 3
0.338
0.226

r = 4
0.274
0.194

r = 5
0.234
0.170

r = 6
0.190
0.154

r = 7
0.176
0.138

distribution (see §3.5). The gap between the average certiﬁed radius is about 1.7 in (cid:96)0 distance  and
the gap between the certiﬁed accuracy can be as large as 0.4. Compared to the models trained with
Gaussian noise (the 3rd row in Table 1)  our model is also consistently better in terms of the measures.
Since the above comparison between our certiﬁcates and the Gaussian-based certiﬁcates is relative 
we conduct an exhaustive search over all the possible adversary within (cid:96)0 radii 1 and 2 to study the
tightness against the exact certiﬁcate. The resulting certiﬁed accuracies at radii 1 and 2 are 0.954
and 0.926  respectively  which suggest that our certiﬁcate is reasonably tight when r = 1 (0.954 vs.
0.921)  but still too pessimistic when r = 2 (0.926 vs. 0.774). The phenomenon is expected since the
certiﬁcate is based on all the measurable functions for the discrete distribution. A tighter certiﬁcate
requires additional assumptions on the classiﬁer such as the example in §3.6.

5.2

ImageNet

We conduct experiments on ImageNet [8]  a large scale image dataset with 1  000 labels. Following
common practice  we consider the input space X = {0  1/255  . . .   1}224×224×3 by scaling the
images. We consider the same ResNet50 classiﬁer [17] and learning procedure as Cohen et al. [6]
with the only modiﬁcation on the noise distribution. The details and visualizations can be found in
Appendix C.2. For comparison  we report the best guaranteed accuracy of each method for each (cid:96)0
radius r in Table 2. Our model outperforms the competitor by a large margin at r = 1 (0.538 vs.
0.372)  and consistently outperforms the baseline across different radii.

Analysis. We analyze our method in ImageNet in terms of 1) the number n of nonempty likelihood
ratio region L(u  v; r) in Algorithm 1  2) the pre-computed ρ−1
r (0.5)  and 3) the certiﬁed accuracy
at each α. The results are in Figure 3. For reproducability  the detailed accuracy numbers of 3)
is available in Table 3 in Appendix C.2  and the pre-computed ρ−1
r (0.5) is available at our code
repository. 1) The number n of nonempty likelihood ratio regions is much smaller than the bound
(d + 1)2 = (3 × 224 × 224)2 for small radii. 2) The value ρ−1
r (0.5) approaches 1 more rapidly for a
higher α value than a lower one. Note that ρ−1
r (0.5) only reaches 1 when r = d due to Remark 3.
Computing ρ−1
r (0.5) in large integer is time-consuming  which takes about 4 days for each α and r 
but this can be trivially parallelized across different α and r.5 For each radius r and randomization
parameter α  note that the 4-day computation only has to be done once  and the pre-computed
ρ−1
r (0.5) can be applied to any ImageNet scale images and models. 3) The certiﬁed accuracy behaves
nonlinearly across different radii; relatively  a high α value exhibits a high certiﬁed accuracy at small
radii and low certiﬁed accuracy at large radii  and vice versa.

5As a side note  computing ρ−1

r (0.5) in MNIST takes less than 1 second for each α and r.

8

(a) # of nonempty L(u  v; r)

(b) ρ−1

r (0.5) for an α

(c) The certiﬁed accuracy for an α

Figure 3: Analysis of the proposed method in the ImageNet dataset.

(a) r = 1

(b) r = 2

(c) r = 3

Figure 4: The guaranteed AUC in the Bace dataset across different (cid:96)0 radius r and the ratio of testing
data that the adversary can manipulate.

5.3 Chemical Property Prediction

The experiment is conducted on the Bace dataset [35]  a binary classiﬁcation dataset for biophysical
property prediction on molecules. We use the Morgan ﬁngerprints [32] to represent molecules  which
are commonly used binary features [41] indicating the presence of various chemical substructures.
The dimension of the features (ﬁngerprints) is 1  024. Here we focus on an ablation study comparing
the proposed randomly smoothed decision tree with a vanilla decision tree  where the adversary is
found by dynamic programming in §3.6 (thus the exact worse case) and a greedy search  respectively.
More details can be found in Appendix C.3.
Since the chemical property prediction is typically evaluated via AUC [41]  we deﬁne a robust version
of AUC that takes account of the radius of the adversary as well as the ratio of testing data that can be
manipulated. Note that to maximally decrease the score of AUC via a positive (negative) example 
the adversary only has to maximally decrease (increase) its prediction probability  regardless of the
scores of the other examples. Hence  given an (cid:96)0 radius r and a ratio of testing data  we ﬁrst compute
the adversary for each testing data  and then ﬁnd the combination of adversaries and the clean data
under the ratio constraint that leads to the worst AUC score. See details in Appendix C.4.
The results are in Figure 4. Empirically  the adversary of the decision tree at r = 1 always changes
the prediction probability of a positive (negative) example to 0 (1). Hence  the plots of the decision
tree model are constant across different (cid:96)0 radii. The randomly smoothed decision tree is consistently
more robust than the vanilla decision tree model. We also compare the exact certiﬁcate of the
prediction probability with the one derived from Lemma 2; the average difference across the training
data is 0.358 and 0.402 when r equals to 1 and 2  respectively. The phenomenon encourages the
development of a classiﬁer-aware guarantee that is tighter than the classiﬁer-agnostic guarantee.

6 Conclusion

We present a stratiﬁed approach to certifying the robustness of randomly smoothed classiﬁers  where
the robustness guarantees can be obtained in various resolutions and perspectives  ranging from a
point-wise certiﬁcate to a regional certiﬁcate and from general results to speciﬁc examples. The
hierarchical investigation opens up many avenues for future extensions at different levels.

Acknowledgments

GH and TJ were in part supported by a grant from Siemens Corporation.

9

1234567radius r500000100000015000002000000nNumber of regions (ImageNet)ImageNet012345670 radius r0.50.60.70.80.91.01r(0.5)=0.1=0.2=0.3=0.4=0.5012345670 radius r0.00.10.20.30.40.50.60.7Certified accuracy=0.1=0.2=0.3=0.4=0.50.00.20.40.60.81.0Ratio of manipulated data0.00.20.40.60.81.0Guaranteed AUCdecision treerandomly smoothed decision tree0.00.20.40.60.81.0Ratio of manipulated data0.00.20.40.60.81.0Guaranteed AUCdecision treerandomly smoothed decision tree0.00.20.40.60.81.0Ratio of manipulated data0.00.20.40.60.81.0Guaranteed AUCdecision treerandomly smoothed decision treeReferences
[1] G. W. Bemis and M. A. Murcko. The properties of known drugs. 1. molecular frameworks.

Journal of medicinal chemistry  39(15):2887–2893  1996.

[2] X. Cao and N. Z. Gong. Mitigating evasion attacks to deep neural networks via region-based
classiﬁcation. In Proceedings of the 33rd Annual Computer Security Applications Conference 
pages 278–287. ACM  2017.

[3] N. Carlini  G. Katz  C. Barrett  and D. L. Dill. Provably minimally-distorted adversarial

examples. arXiv preprint arXiv:1709.10207  2017.

[4] C.-H. Cheng  G. Nührenberg  and H. Ruess. Maximum resilience of artiﬁcial neural networks.
In International Symposium on Automated Technology for Veriﬁcation and Analysis  pages
251–268. Springer  2017.

[5] C. J. Clopper and E. S. Pearson. The use of conﬁdence or ﬁducial limits illustrated in the case

of the binomial. Biometrika  26(4):404–413  1934.

[6] J. M. Cohen  E. Rosenfeld  and J. Z. Kolter. Certiﬁed adversarial robustness via randomized

smoothing. In the 36th International Conference on Machine Learning  2019.

[7] F. Croce  M. Andriushchenko  and M. Hein. Provable robustness of relu networks via maxi-
mization of linear regions. In the 22nd International Conference on Artiﬁcial Intelligence and
Statistics  2018.

[8] J. Deng  W. Dong  R. Socher  L.-J. Li  K. Li  and L. Fei-Fei. Imagenet: A large-scale hierarchical
image database. In Proceedings of the IEEE international conference on computer vision  pages
248–255. Ieee  2009.

[9] S. Dutta  S. Jha  S. Sankaranarayanan  and A. Tiwari. Output range analysis for deep feedforward

neural networks. In NASA Formal Methods Symposium  pages 121–138. Springer  2018.

[10] K. Dvijotham  S. Gowal  R. Stanforth  R. Arandjelovic  B. O’Donoghue  J. Uesato  and P. Kohli.

Training veriﬁed learners with learned veriﬁers. arXiv preprint arXiv:1805.10265  2018.

[11] K. Dvijotham  R. Stanforth  S. Gowal  T. Mann  and P. Kohli. A dual approach to scalable
veriﬁcation of deep networks. In the 34th Annual Conference on Uncertainty in Artiﬁcial
Intelligence  2018.

[12] R. Ehlers. Formal veriﬁcation of piece-wise linear feed-forward neural networks. In Inter-
national Symposium on Automated Technology for Veriﬁcation and Analysis  pages 269–286.
Springer  2017.

[13] C. Finlay  A.-A. Pooladian  and A. M. Oberman. The logbarrier adversarial attack: making

effective use of decision boundary information. arXiv preprint arXiv:1903.10396  2019.

[14] M. Fischetti and J. Jo. Deep neural networks and mixed integer linear optimization. Constraints 

23:296–309  2018.

[15] I. Goodfellow  J. Shlens  and C. Szegedy. Explaining and harnessing adversarial examples. In

International Conference on Learning Representations  2015.

[16] S. Gowal  K. Dvijotham  R. Stanforth  R. Bunel  C. Qin  J. Uesato  T. Mann  and P. Kohli. On
the effectiveness of interval bound propagation for training veriﬁably robust models. arXiv
preprint arXiv:1810.12715  2018.

[17] K. He  X. Zhang  S. Ren  and J. Sun. Deep residual learning for image recognition.

In
Proceedings of the IEEE conference on computer vision and pattern recognition  pages 770–
778  2016.

[18] P.-S. Huang  R. Stanforth  J. Welbl  C. Dyer  D. Yogatama  S. Gowal  K. Dvijotham  and
P. Kohli. Achieving veriﬁed robustness to symbol substitutions via interval bound propagation.
arXiv preprint arXiv:1909.01492  2019.

10

[19] R. Jia  A. Raghunathan  K. Göksel  and P. Liang. Certiﬁed robustness to adversarial word

substitutions. arXiv preprint arXiv:1909.00986  2019.

[20] G. Katz  C. Barrett  D. L. Dill  K. Julian  and M. J. Kochenderfer. Reluplex: An efﬁcient smt
solver for verifying deep neural networks. In International Conference on Computer Aided
Veriﬁcation  pages 97–117. Springer  2017.

[21] M. Lecuyer  V. Atlidakis  R. Geambasu  D. Hsu  and S. Jana. Certiﬁed robustness to adversarial

examples with differential privacy. IEEE Symposium on Security and Privacy (SP)  2019.

[22] G.-H. Lee  D. Alvarez-Melis  and T. S. Jaakkola. Towards robust  locally linear deep networks.

In International Conference on Learning Representations  2019.

[23] B. Li  C. Chen  W. Wang  and L. Carin. Second-order adversarial attack and certiﬁable

robustness. arXiv preprint arXiv:1809.03113  2018.

[24] X. Liu  M. Cheng  H. Zhang  and C.-J. Hsieh. Towards robust neural networks via random
self-ensemble. In Proceedings of the European Conference on Computer Vision (ECCV)  pages
369–385  2018.

[25] A. Lomuscio and L. Maganti. An approach to reachability analysis for feed-forward relu neural

networks. arXiv preprint arXiv:1706.07351  2017.

[26] A. Madry  A. Makelov  L. Schmidt  D. Tsipras  and A. Vladu. Towards deep learning models
resistant to adversarial attacks. In International Conference on Learning Representations  2018.

[27] M. Mirman  T. Gehr  and M. Vechev. Differentiable abstract interpretation for provably robust

neural networks. In the 35th International Conference on Machine Learning  2018.

[28] J. Neyman and E. S. Pearson.

Ix. on the problem of the most efﬁcient tests of statistical
hypotheses. Philosophical Transactions of the Royal Society of London. Series A  Containing
Papers of a Mathematical or Physical Character  231(694-706):289–337  1933.

[29] A. Paszke  S. Gross  S. Chintala  G. Chanan  E. Yang  Z. DeVito  Z. Lin  A. Desmaison 

L. Antiga  and A. Lerer. Automatic differentiation in pytorch. 2017.

[30] A. Raghunathan  J. Steinhardt  and P. Liang. Certiﬁed defenses against adversarial examples. In

International Conference on Learning Representations  2018.

[31] A. Raghunathan  J. Steinhardt  and P. S. Liang. Semideﬁnite relaxations for certifying robustness
to adversarial examples. In Advances in Neural Information Processing Systems  pages 10877–
10887  2018.

[32] D. Rogers and M. Hahn. Extended-connectivity ﬁngerprints. Journal of chemical information

and modeling  50(5):742–754  2010.

[33] K. Scheibler  L. Winterer  R. Wimmer  and B. Becker. Towards veriﬁcation of artiﬁcial neural

networks. In MBMV  pages 30–40  2015.

[34] G. Singh  T. Gehr  M. Mirman  M. Püschel  and M. Vechev. Fast and effective robustness
certiﬁcation. In Advances in Neural Information Processing Systems  pages 10802–10813 
2018.

[35] G. Subramanian  B. Ramsundar  V. Pande  and R. A. Denny. Computational modeling of β-
secretase 1 (bace-1) inhibitors using ligand based approaches. Journal of chemical information
and modeling  56(10):1936–1949  2016.

[36] V. Tjeng  K. Xiao  and R. Tedrake. Evaluating robustness of neural networks with mixed integer

programming. In International Conference on Learning Representations  2017.

[37] K. Tocher. Extension of the neyman-pearson theory of tests to discontinuous variates.

Biometrika  37(1/2):130–144  1950.

11

[38] T.-W. Weng  H. Zhang  H. Chen  Z. Song  C.-J. Hsieh  D. Boning  I. S. Dhillon  and L. Daniel.
Towards fast computation of certiﬁed robustness for relu networks. In the 35th International
Conference on Machine Learning  2018.

[39] E. Wong and J. Z. Kolter. Provable defenses against adversarial examples via the convex outer

adversarial polytope. In the 35th International Conference on Machine Learning  2018.

[40] E. Wong  F. Schmidt  J. H. Metzen  and J. Z. Kolter. Scaling provable adversarial defenses. In

Advances in Neural Information Processing Systems  pages 8400–8409  2018.

[41] Z. Wu  B. Ramsundar  E. N. Feinberg  J. Gomes  C. Geniesse  A. S. Pappu  K. Leswing  and
V. Pande. Moleculenet: a benchmark for molecular machine learning. Chemical science 
9(2):513–530  2018.

[42] H. Zhang  T.-W. Weng  P.-Y. Chen  C.-J. Hsieh  and L. Daniel. Efﬁcient neural network
robustness certiﬁcation with general activation functions. In Advances in Neural Information
Processing Systems  pages 4939–4948  2018.

12

,Guang-He Lee
Yang Yuan
Shiyu Chang
Tommi Jaakkola