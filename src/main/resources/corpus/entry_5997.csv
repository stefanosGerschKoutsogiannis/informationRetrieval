2013,k-Prototype Learning for 3D Rigid Structures,In this paper  we study the following new variant of prototype learning  called {\em $k$-prototype learning problem for 3D rigid structures}: Given a set of 3D rigid structures  find a set of $k$ rigid structures so that each of them is a prototype for a cluster of the given rigid structures and the total cost (or dissimilarity) is minimized. Prototype learning is a core problem in machine learning and has a wide range of applications in many areas. Existing results on this problem have mainly focused on the graph domain. In this paper  we present the first algorithm for learning multiple prototypes from 3D rigid structures. Our result is based on a number of new insights to rigid structures alignment  clustering  and prototype reconstruction  and is practically efficient with quality guarantee. We validate our approach using two type of data sets  random data and biological data of chromosome territories. Experiments suggest that our approach can effectively learn prototypes in both types of data.,k-Prototype Learning for 3D Rigid Structures (cid:63)

Hu Ding

Ronald Berezney

Department of Computer Science and Engineering

State University of New York at Buffalo

Department of Biological Sciences

State University of New York at Buffalo

Buffalo  NY14260

huding@buffalo.edu

Buffalo  NY14260

berezney@buffalo.edu

Jinhui Xu

Department of Computer Science and Engineering

State University of New York at Buffalo

Buffalo  NY14260

jinhui@buffalo.edu

Abstract

In this paper  we study the following new variant of prototype learning  called
k-prototype learning problem for 3D rigid structures: Given a set of 3D rigid
structures  ﬁnd a set of k rigid structures so that each of them is a prototype for
a cluster of the given rigid structures and the total cost (or dissimilarity) is mini-
mized. Prototype learning is a core problem in machine learning and has a wide
range of applications in many areas. Existing results on this problem have mainly
focused on the graph domain. In this paper  we present the ﬁrst algorithm for learn-
ing multiple prototypes from 3D rigid structures. Our result is based on a number
of new insights to rigid structures alignment  clustering  and prototype reconstruc-
tion  and is practically efﬁcient with quality guarantee. We validate our approach
using two type of data sets  random data and biological data of chromosome terri-
tories. Experiments suggest that our approach can effectively learn prototypes in
both types of data.

1

Introduction

Learning prototype from a set of given or observed objects is a core problem in machine learning 
and has numerous applications in computer vision  pattern recognition  data mining  bioinformatics 
etc. A commonly used approach for this problem is to formulate it as an optimization problem and
determine an object (called pattern or prototype) so as to maximize the total similarity (or minimize
the total difference) with the input objects. Such computed prototypes are often used to classify or
index large-size structural data so that queries can be efﬁciently answered by only considering those
prototypes. Other important applications of prototype include reconstructing object from partially
observed snapshots and identifying common (or hidden) pattern from a set of data items.
In this paper  we study a new prototype learning problem called k-prototype learning for 3D rigid
structures  where a 3D rigid structure is a set of points in R3 whose pairwise distances remain
invariant under rigid transformation. Since our problem needs to determine k prototypes  it thus can
be viewed as two tightly coupled problems  clustering rigid structures and prototype reconstruction
for each cluster.
Our problem is motivated by an important application in biology for determining the spatial organi-
zation pattern of chromosome territories from a population of cells. Recent research in biology [3]

(cid:63)This research was supported in part by NSF under grant IIS-1115220.

has suggested that conﬁguration of chromosome territories could signiﬁcantly inﬂuence the cell
molecular processes  and are closely related to cancer-promoting chromosome translocations. Thus 
ﬁnding the spatial organization pattern of chromosome territories is a key step to understanding the
cell molecular processes [6 7 10 25]. Since the set of observed chromosome territories in each cell
can be represented as a 3D rigid structure  the problem can thus be formulated as a k-prototype
learning problem for a set of 3D rigid structures.
Related work: Prototype learning has a long and rich history. Most of the research has focused on
ﬁnding prototype in the graph domain. Jiang et al. [18] introduced the median graph concept  which
can be viewed as the prototype of a set of input graphs  and presented a genetic approach to solve
it. Later  Ferrer et al. [14] proposed another efﬁcient method for median graph. Their idea is to ﬁrst
embed the graphs into some metric space  and obtain the median using a recursive procedure. In the
geometric domain  quite a number of results have concentrated on ﬁnding prototypes from a set of
2D shapes [11 20 21 22]. A commonly used strategy in these methods is to ﬁrst represent each shape
as a graph abstraction and then compute the median of the graph abstractions.
Our prototype learning problem is clearly related to the challenging 3D rigid structure clustering
and alignment problem [1 2 4 5 13 17]. Due to its complex nature  most of the existing approaches
are heuristic algorithms and thus cannot guarantee the quality of solution. There are also some
theoretical results [13] on this problem  but none of them is practical due to their high complexities.
Our contributions and main ideas: 1 Our main objective on this problem is to obtain a practical
solution which has guarantee on the quality of its solution. For this purpose  we ﬁrst give a formal
deﬁnition of the problem and then consider two cases of the problem  1-prototype learning and
k-prototype learning.
For 1-prototype learning  we ﬁrst present a practical algorithm for the alignment problem. Our result
is based on a multi-level net technique which ﬁnds the proper Euler angles for the rigid transforma-
tion. With this alignment algorithm  we can then reduce the prototype learning problem to a new
problem called chromatic clustering (see Figure 1(b) and 1(c ))  and present two approximate solu-
tions for it. Finally  a local improvement algorithm is introduced to iteratively improve the quality
of the obtained prototype.
For k-prototype learning  a key challenge is how to avoid the high complexity associated with clus-
tering 3D rigid structures. Our idea is to map each rigid structure to a point in some metric space
and build a correlation graph to capture their pairwise similarity. We show that the correlation graph
is metric; this means that we can reduce the rigid structure clustering problem to a metric k-median
clustering problem on the correlation graph. Once obtaining the clustering  we can then use the
1-prototype learning algorithm on each cluster to generate the desired prototype. We also provide
techniques to deal with several practical issues  such as the unequal sizes of rigid structures and the
weaker metric property caused by imperfect alignment computation for the correlation graph.
We validate our algorithms by using two types of datasets. The ﬁrst is randomly generated datasets
and the second is a real biological dataset of chromosome territories. Experiments suggest that our
approach can effectively reduce the cost in prototype learning.
2 Preliminaries
In this section  we introduce several deﬁnitions which will be used throughout this paper.
Deﬁnition 1 (m-Rigid Structure). Let P = {p1 ···   pm} be a set of m points in 3D space. P is
an m-rigid structure if the distance between any pair of vertices pi and pj in P remains the same
under any rigid transformation  including translation  rotation  reﬂection and their combinations 
on P . For any rigid transformation T   the image of P under T is denoted as T (P ).
Deﬁnition 2 (Bipartite Matching). Let S1 and S2 be two point-sets in 3D space with |S1| = |S2| 
and G = (U  V  E) be their induced complete bipartite graph  where each vertex in U (or V )
corresponds to a unique point in S1 (or S2)  and each edge in E is associated with a weight equal to
the Euclidean distance of the corresponding two points. The bipartite matching of S1 and S2  is the
one-to-one match from S1 to S2 with the minimum total matching weight (denoted as Cost(S1  S2))
in G (see Figure 1(a)).
1 Due to space limit  we put some details and proofs in our full version paper.

Note that the bipartite matching can be computed using some existing algorithms  such as the Hun-
garian algorithm [24].

(a)

(b)

(c)

Fig. 1: (a) An example of bipartite matching (red edges); (b) 4 point-sets with each in a different
color; (c ) chromatic clustering of point-sets in (b). The three clusters form a chromatic partition.

Deﬁnition 3 (Alignment). Let P and Q be two m-rigid structures in 3D space with points
{p1 ···   pm} and {q1 ···   qm} respectively. Their alignment is to ﬁnd a rigid transformation T
for P so as to minimize the cost of the bipartite matching between T (P ) and Q. The minimum
(alignment) cost  minT Cost(T (P )  Q)  is denoted by A(P  Q).
Deﬁnition 4 (k-Prototype Learning). Let P1 ··· Pn be n different m-rigid structures in 3D  and
k be a positive integer. k-prototype learning is to determine k m-rigid structures  Q1 ···   Qk  so
as to minimize the following objective function

n(cid:88)

i=1

A(Pi  Qj).

min
1≤j≤k

(1)

1-Prototype learning

From Deﬁnition 4  we know that the k-prototype learning problem can be viewed as ﬁrst clustering
the rigid structures into k clusters and then build a prototype for each cluster so as to minimize the
total alignment cost.
3
In this section  we consider the 1-prototype learning problem. We ﬁrst overview the main steps of
our algorithm and then present the details in each subsection. Our algorithm is an iterative procedure.
In each iteration  it constructs a new prototype using the one from previous iteration  and reduces
the objective value. A ﬁnal prototype is obtained once the objective value becomes stable.
Algorithm: 1-prototype learning

1. Randomly select a rigid structure from the input {P1 ···   Pn} as the initial prototype Q.
2. Repeatedly perform the following steps until the objective value becomes stable.

(a) For each Pi  ﬁnd the rigid transformation (approximately) realizing A(Pi  Q).
(b) Based on the new conﬁguration (i.e.  after the corresponding rigid transformation) of

each Pi  construct an updated prototype Q which minimizes the objective value.

Since both of 2(a) and 2(b) reduce the cost  the objective value would always decrease. In the next
two subsections  we discuss our ideas for Step 2(a) (alignment) and Step 2(b) (prototype reconstruc-
tion)  respectively. Note that the above algorithm is different with generalized procrustes analysis
(GPA) [15]  since the points from each Pi are not required to be pre-labeled in our algorithm  while
for GPA every input point should have an individual index. This is also the main difﬁculty for this
prototype learning problem.

3.1 Alignment

To determine the alignment of two rigid structures  one way is to use our recent theoretical algorithm
for point-set matching [13]. For any pair of point-sets P and Q in Rd space with m points each 
d2 m2d+2 log2d(m)) time  a rigid transformation T for P so that the
our algorithm outputs  in O( 1
bipartite matching cost between T (P ) and Q is a (1 + )-approximation of the optimal alignment
cost between P and Q  where  > 0 is a small constant. Applying this algorithm to our 3D rigid
9 m8 log6(m)). The algorithm is based on following key
structures  the running time becomes O( 1

UVq1q2q3idea. First  we show that there exist 3 “critical” points  called base  in each of P and Q  which
control the matching cost. Although the base cannot be explicitly identiﬁed  it is possible to obtain
it implicitly by considering all 3-tuples of the points in P and Q. The algorithm then builds an -net
around each base point to determine an approximate rigid transformation. Clearly  this theoretical
algorithm is efﬁcient only when m is small. For large m  we use the following relaxation.
First  we change the edge weight in Deﬁnition 2 from Euclidean distance to squared Euclidean
distance. The following lemma shows some nice property of such a change.
Lemma 1. Let P = {p1 ···   pm} and Q = {q1 ···   qm} be two m-rigid structures in 3D space 
and T be the rigid transformation realizing the minimum bipartite matching cost (where the edge
weight is replaced by the squared Euclidean distance of the corresponding points in Deﬁnition 2).
Then  the mean points of T (P ) and Q coincide with each other.

Lemma 1 tells us that to align two rigid structures  we can ﬁrst translate them to share one common
mean point  and then consider only the rotation in 3D space. (Note that we can ignore reﬂection in
the rigid transformation  as it can be captured by computing the alignment twice  one for the original
rigid structure  and the other for its mirror image.) Using Euler angles and 3D rotation matrix  we
can easily have the following fact.
Fact 1 Give any rotation matrix A in 3D  there are 3 angles φ  θ  ψ ∈ (−π  π]  and three matrices 
A1  A2 and A3 such that A = A1 ∗ A2 ∗ A3  where

   A2 =

 cos θ 0 sin θ

0
− sin θ 0 cos θ

0

1

 and A3 =

cos ψ − sin ψ 0

sin ψ cos ψ 0
1

0

0

 .

1

A1 =

0

0

0 cos φ − sin φ
0 sin φ cos φ

From the above Fact 1  we know that the main issue for aligning two rigid structures P and Q is
to ﬁnd three proper angles φ  θ  ψ to minimize the cost. Clearly  this is a non-convex optimization
problem. Thus  we cannot use existing convex optimization methods to obtain an efﬁcient solution.
One way to solve this problem is to build a dense enough -net (or grid) in the domain [−π  π]3 of
φ  θ  ψ  and evaluate each grid point to ﬁnd the best possible solution. Clearly  this will be rather
inefﬁcient when the number of grid points is huge. To obtain a practically efﬁcient solution  our
strategy is to generalize the idea of building a dense net to recursively building a sparse net  which is
called multi-level net. At each level  we partition the current searching domain into a set of smaller
regions  which can be viewed as a sparse net  and evaluate some representative point in each of the
smaller region to determine its likelihood of containing the optimal point. The recursion will only
continue at the most likely N smaller regions (for some well selected parameter N ≥ 1 in practice).
In this way  we can save a great deal of time for searching the optimal point in those unlikely regions.
Below is the main steps of our approach.

1. Let S be the current searching space  which is initialized as [−π  π]3  and t  N be two input
parameters. Recursively perform the following steps until the best objective value in two
consecutive recursive steps roughly remains the same.
(a) Uniformly partition S into t disjoint sub-regions S = S1 ∪ ··· ∪ St.
(b) Randomly select a representative point si ∈ Si  and compute the alignment cost under
(c) Choose the top N points with the minimum objective values from {s1 ···   st}. Let

the rotational matrix corresponding to si via Hungarian algorithm.
{st1 ···   stN} be the chosen points.

(d) Update S =(cid:83)N

i=1 Sti.

2. Output the rotation which yields the minimum objective value.

Why not use other alignment algorithms? There are several existing alignment algorithms for 3D
rigid structures  and each suffers from its own limitations. For example  the Iterative Closest Point
algorithm [4] is one of the most popular algorithms for alignment. However  it does not generate the
one-to-one match between the rigid structures. Instead  every point in one rigid structure is matched
to its nearest neighbor in the other rigid structure. This means that some point could match multiple
points in the other rigid structure. Obviously  this type of matching cannot meet our requirement 
especially in the biological application where chromosome territory is expected to match only one

chromosome. Similar problem also occurs in some other alignment algorithms [1 5 17]. Arun et
al. [2] presented an algebraic approach to ﬁnd the best alignment between two 3D point-sets. Al-
though their solution is a one-to-one match  it requires that the correspondence between the two
point-sets is known in advance  which is certainly not the case in our model. Branch-and-bound
(BB) approach [16] needs to grow a searching tree in the parameter space  and for each node it re-
quires estimating the upper and lower bounds of the objective value in the corresponding sub-region.
But for our alignment problem  it is challenging to obtain such accurate estimations.
3.2 Prototype reconstruction
In this section  we discuss how to build a prototype from a set of 3D rigid structures. We ﬁrst ﬁx
the position of each Pi  and then construct a new prototype Q to minimize the objective function in
Deﬁnition 4. Our main idea is to introduce a new type of clustering problem called Chromatic Clus-
tering which was ﬁrstly introduced by Ding and Xu [12]  and reduce our prototype reconstruction
problem to it. We start with two deﬁnitions.
Deﬁnition 5 (Chromatic Partition). Let G = {G1 ···   Gn} be a set of n point-sets with each Gi
consisting of m points in the space. A chromatic partition of G is a partition of the n× m points into
m sets  U1 ···   Um  such that each Uj contains exactly one point from each Gi.
Deﬁnition 6 (Chromatic Clustering). Let G = {G1  ···   Gn} be a set of n point-sets with each
Gi consisting of m points in the space. The chromatic clustering of G is to ﬁnd m median points
||p−
qj|| is minimized  where || · || denotes the Euclidean distance.

{q1 ···   qm} in the space and a chromatic partition U1 ···   Um of G such that(cid:80)m

(cid:80)

p∈Uj

j=1

From Deﬁnition 6  we know that chromatic clustering is quite similar to k-median clustering in
Euclidean space; the only difference is that it has the chromatic requirement  i.e.  the obtained k
clusters should be a chromatic partition (see Figure 1(b) and 1(c )).
Reduction to chromatic clustering. Since the position of each Pi is ﬁxed (note that with a slight
abuse of notation  we still use Pi to denote its image T (Pi) under the rigid transformation T obtained
in Section 3.1)  we can view each Pi as a point-set Gi  and the new prototype Q as the k median
points {q1 ···   qm} in Deﬁnition 6. Further  if a point p ∈ Pi is matched to qj  then it is part of Uj.
Since we compute the one-to-one match  Uj contains exactly one point from each Pi  which implies
that {U1 ···   Um} is a chromatic partition on G. Let pi
j be the one in Pi ∩ Uj. Then the objective
function in Deﬁnition 4 becomes

n(cid:88)

m(cid:88)

m(cid:88)

n(cid:88)

||pi

j − qj|| =

||pi

j − qj|| =

||p − qj|| 

(2)

i=1

j=1

j=1

i=1

m(cid:88)

(cid:88)

j=1

p∈Uj

which is exactly the objective function in Deﬁnition 6. Thus  we have the following theorem.

Theorem 1. Step 2(b) in the algorithm of 1-prototype learning is equivalent to solving a chromatic
clustering problem.
Next  we give two constant approximation algorithms for the chromatic clustering problem; one is
randomized  and the other is deterministic.
Theorem 2. Let G = {G1 ···   Gn} be an instance of chromatic clustering with each Gi consisting
of m points in the space.
1. If Gl is randomly selected from G as the m median points  then with probability at least

1/2  Gl yields a 3-approximation for chromatic clustering on G.

2. If enumerating all point-sets in G as the m median points  there exists one Gi0  which yields

a 2-approximation for chromatic clustering on G.

Proof. We consider the randomized algorithm ﬁrst. Let {q1 ···   qm} be the m median points in
the optimal solution  and U1 ···   Um be the corresponding chromatic partition. Let pi
j = Gi ∩ Uj.
Since the objective value is the sum of the total cost from all point-sets {G1 ···   Gn}  by Markov
inequality  the contribution from Gl should be no more than 2 times the average cost with probability
at least 1/2  i.e. 

m(cid:88)

j=1

n(cid:88)

m(cid:88)

i=1

j=1

||pl

j − qj|| ≤ 2

1
n

||pi

j − qj||.

(3)

From (3) and triangle inequality  if replacing each qj by pl
j − qj|| + ||qj − pl

j − pl

(||pi

||pi

j  the objective value becomes
j||)

n(cid:88)

m(cid:88)

j|| ≤ n(cid:88)
n(cid:88)

i=1

m(cid:88)
m(cid:88)

j=1

=

j − qj|| + n × m(cid:88)

||pi

n(cid:88)

m(cid:88)

||qj − pl

j|| ≤ 3

||pi

j − qj|| 

(4)

(5)

i=1

j=1

i=1

j=1

j=1

i=1

j=1

where (4) follows from triangle inequality  and (5) follows from (3). Thus  the ﬁrst part of the
theorem is true. The analysis for the deterministic algorithm is similar. The only difference is that
there must exist one point-set Gi0 whose contribution to the total cost is no more than the average
cost. Thus the constant in the right-hand side of (3) becomes 1 rather than 2  and consequently the
ﬁnal approximation ratio in (5) turns to 2. Note that the desired Gi0 can be found by enumerating
(cid:117)(cid:116)
all point-sets  and selecting the one having the smallest objective value.
Remark 1. Comparing the two approximation algorithms  we can see a tradeoff between the approx-
imation ratio and the running time. The randomized algorithm has a larger approximation ratio  but a
linear dependence on n in its running time. The deterministic algorithm has a smaller approximation
ratio  but a quadratic dependence on n.
Local improvement. After ﬁnding a constant approximation  it is necessary to conduct some local
improvement. An easy-to-implement method is the follows. Let ˜Q = {˜q1 ···   ˜qm} be the initial
constant approximation solution. Compute the bipartite matching between ˜Q and each Gi. This
yields a chromatic partition { ˜U1 ···   ˜Um} on G  where each ˜Uj consists of all the points matched
to ˜qj. By Deﬁnition 6  we know that qj should be the geometric median point of Uj in order to make
the objective value as low as possible. Thus  we can use the well known Weiszfelds algorithm [23] to
compute the geometric median point for each ˜Uj  and update ˜qj to be the corresponding geometric
median point. We can iteratively perform the following two steps  (1) computing the chromatic
partition and (2) generating the geometric median points  until the objective value becomes stable.
4 k-Prototype learning
In this section  we generalize the ideas for 1-prototype learning to k-prototype learning for some
k > 1. As mentioned in Section 1  our idea is to build a correlation graph. We ﬁrst introduce the
following lemma.

Lemma 2. The alignment cost in Deﬁnition 3 satisﬁes the triangle inequality.
Correlation graph. We denote the correlation graph on the given m-rigid structures {P1 ···   Pn}
as Γ   which contains n vertices {v1 ···   vn}. Each vi represents the rigid structure Pi  and the edge
connecting vi and vj has the weight equal to A(Pi  Pj). From Lemma 2  we know that Γ is a metric
graph. Thus  we have the following key theorem.

Theorem 3. Any λ-approximation solution for metric k-median clustering on Γ yields a 2λ-
approximation solution for the k-prototype learning problem on {P1 ···   Pn}  where λ ≥ 1.
Proof. Let {Q1 ···   Qk} be the k rigid structures yielded in an optimal solution of the k-prototype
learning  and {C1 ···  Ck} be the corresponding k optimal clusters. For each 1 ≤ j ≤ k  the cost of

A(Pi  Qj). There exists one rigid structure Pij ∈ Cj such that

Cj is(cid:80)

Pi∈Cj

A(Pij   Qj) ≤ 1
|Cj|
If we replace Qj by Pij   the cost of Cj becomes

(cid:88)

Pi∈Cj

A(Pi  Qj).

(A(Pi  Qj) + A(Qj  Pij )) ≤ 2

(cid:88)

Pi∈Cj

A(Pi  Qj) 

(6)

(7)

(cid:88)

Pi∈Cj

A(Pi  Pij ) ≤ (cid:88)
(cid:88)

k(cid:88)

Pi∈Cj

j=1

Pi∈Cj

where the ﬁrst inequality follows from the triangle inequality (by Lemma 2)  and the second in-
equality follows from (6). Then  (7) directly implies that

A(Pi  Pij ) ≤ 2

A(Pi  Qj) 

(8)

k(cid:88)

(cid:88)

j=1

Pi∈Cj

(8) is similar to the deterministic solution in Theorem 2; the only difference is that the point-sets
here need to be aligned through rigid transformation  while in Theorem 2  the point-sets are ﬁxed.
Now  consider the correlation graph Γ . If we select {vi1 ···   vik} as the k medians  the objective
value of the k-median clustering is the same as the left-hand side of (8). Let {vi(cid:48)
} be the k
median vertices of the λ-approximation solution on Γ . Then  we have

 ···   vi(cid:48)

k

1

n(cid:88)

i=1

n(cid:88)

i=1

A(Pi  Pi(cid:48)

j

) ≤ λ

min
1≤j≤k

A(Pi  Pij ) ≤ 2λ

min
1≤j≤k

A(Pi  Qj) 

k(cid:88)

(cid:88)

j=1

Pi∈Cj

(9)

(cid:117)(cid:116)

where the second inequality follows from (8). Thus the theorem is true.
Based on Theorem 3  we have the following algorithm for k-prototype learning.
Algorithm: k-prototype learning

1. Build the correlation graph Γ   and run the algorithm proposed in [9] to obtain a
3-approximation for the metric k-median clustering on Γ   and consequently a 13 1
3-
6 2
approximation for k-prototype learning.

2. For each obtained cluster  run the 1-prototype learning algorithm presented in Section 3.

Remark 2. Note that there are several algorithms for metric k-median clustering with better approx-
imation ratio (than 6 2
3)  such as the ones in [19]. But they are all theoretical algorithms and have
difﬁcult to be applied in practice. We choose the linear programming rounding based algorithm by
Charikar et al. [9] partially due to its simplicity to be implemented for practical purpose.
The exact correlation graph is not available. From the methods presented in Section 3.1  we
know that only approximate alignments can be obtained. This means that the exact correlation graph
Γ is not available. As a consequence  the approximate correlation graph may not be metric (due
to possible violation of the triangle inequality). This seems to cause the above algorithm to yield
solution with no quality guarantee. Fortunately  as pointed in [9]  the LP-rounding method still
yields a provably good approximation solution  as long as a weaker version of the triangle inequality
is satisﬁed (i.e.  for any three vertices va  vb and vc in Γ   their edge weights satisfy the inequality
w(vavb) ≤ δ(w(vavc) + w(vbvc)) for some constant δ > 1  where w(vavb) is the weight of the
edge connecting va and vb).
Theorem 4. For a given set of rigid structures  if a (1 + )-approximation of the alignment between
any pair of rigid structures can be computed  then the algorithm for metric k-median clustering
in [9] yields a 2( 23
What if the rigid structures have unequal sizes? In some scenario  the rigid structures may not
have the same number of points  and consequently the one-to-one match between rigid structures in
Deﬁnition 2 is not available. To resolve this issue  we can use the weight normalization strategy and
adopt Earth Mover’s Distance (EMD) [8]. Generally speaking  for any rigid structure Pi containing
m(cid:48) points for some m(cid:48)
m(cid:48)   and compute the
alignment cost based on EMD  rather than the bipartite matching cost. With this modiﬁcation  both
the 1- and k-prototype learning algorithms still work.

3 (1 + ) − 1)(1 + )-approximation for the k-prototype learning problem.

(cid:54)= m  we assign each point with a weight equal to m

5 Exepriments
To evaluate the performance of our proposed approach  we implement our algorithms on a Linux
workstation (with 2.4GHz CPU and 4GB memory). We consider two types of data  the sets of
randomly generated 3D rigid structures and a real biological data set which is used to determine the
organization pattern (among a population of cells) of chromosome territories inside the cell nucleus.
Random data. For random data  we test a number of data sets with different size. For each data
set  we ﬁrst randomly generate k different rigid structures  {Q1 ···   Qk}. Then around each point
of Qj  j = 1 ···   k  we generate a set of points following Gaussian distribution  with variance
δ. We randomly select one point from each of the m Gaussian distributions (around the m points
of Qj) to form an m-rigid structure  and transform it by a random rigid transformation. Thus  we
build a cluster (denoted by Cj) of m-rigid structures around each Qj  and Qj can be viewed as its
j=1 Cj forms an instance of the k-prototype learning problem.

prototype (i.e.  the ground truth).(cid:83)k

1 ···   Q(cid:48)

1 ···   Q(cid:48)

1 ···   Q(cid:48)

k}  and for each pair Qi and Q(cid:48)

the sum t2 =(cid:80)k

We run the algorithm of k-prototype learning in Section 4  and denote the resulting k rigid structures
by {Q(cid:48)
k}. To evaluate the performance  we compute the following two values. Firstly  we
compute the bipartite matching cost  t1  between {Q1 ···   Qk} and {Q(cid:48)
k}  i.e.  build the
bipartite graph between {Q1 ···   Qk} and {Q(cid:48)
j  connect
an edge with a weight equal to the alignment cost A(Qi  Q(cid:48)
j). Secondly  we compute the average
alignment cost (denoted by cj) between the rigid structures in Cj and Qj for 1 ≤ j ≤ k  and compute
j=1 cj. Finally  we use the ratio t1/t2 to show the performance. The ratio indicates
how much cost (i.e.  t1) has been reduced by our prototype learning algorithm  comparing to the
cost (i.e.  t2) of the input rigid structures. We choose k = 1  2  3  4  5; for each k  vary m from 10
(cid:80)m
to 20  and the size of each Cj from 100 to 300. Also  for each Cj  we vary the Gaussian variance
from 10% to 30% of the average spread norm of Qj  where if we assume Qj contains m points
{q1 ···   qm}  and o = 1
l=1 ||ql − o||.
For each k  we generate 10 datasets  and plot the average experimental results in Figure 2(a). The
experiment suggests that our generated prototypes are much closer (at least 40% for each k) to the
ground truth than the input rigid structures.

l=1 ql  then the average spread norm is deﬁned as 1

(cid:80)m

m

m

(a)

(b)

(c)

Fig. 2: (a) Experimental results for random data; (b)A 2D slice of the 3D microscopic image of 8
pairs of chromosome territories; (c ) Average alignment cost for biological data set.
Biological data. For real data  we use a biological data set consisting of 91 microscopic nucleus
images of WI-38 lung ﬁbroblasts cells. Each image includes 8 pairs of chromosome territories (see
Fig. 2(b)). The objective of this experiment is to determine whether there exists any spatial pattern
among the population of cells governing the organization of the chromosomes inside the 3D cell
nucleus so as to provide new evidence to resolve a longstanding conjecture in cell biology which says
that each chromosome territory has a preferable position inside the cell nucleus. For this purpose 
we calculate the gravity center of each chromosome territory and use it as the representative of
the chromosome. In this way  each cell is converted into a rigid structure of 16 points. Since there
is no ground truth for the biological data  we directly use the average alignment cost between our
generated solutions and the input rigid structures to evaluate the performance. We run our algorithms
for k = 1  2  3  4  and plot the cost in Fig. 2(c ). Our preliminary experiments indicate that there is a
signiﬁcant reduction on the average cost from k = 1 to k = 2  and the cost does not change too much
for k = 2  3  4. We also analyze how chromosomes change their clusters when increase k from 2 to
4}.
2}  and the clusters for k = 4 as {C 4
4. We denote the clusters for k = 2 as {C 2
1   C 2
3   C 4
1   C 4
|C4
j ∩C2
2|
For each 1 ≤ j ≤ 4  we use
to represent the preservation of C 4
1 and
j from C 2
2|
|C2
1 and C 2
2 . It
2 respectively. The following table 1 shows the preservation (denoted by Pre) with C 2
C 2
3} preserved C 2
1 well. This
shows that C 4
1   C 4
seems to suggest that all the cells are aggregated around two clusters.

2 well  meanwhile  the union of {C 4

4 preserved C 2

j ∩C2
1|
|C2
1|

2   C 4

2   C 4

and

|C4

Table 1: The preservations

C 4
2

C 4
3

C 4
4

Pre C 4
1
C 2
C 2
2

1 26.53% 18.37% 46.94% 8.16%
0% 5.56% 94.44%

0%

6 Conclusion
In this paper  we study a new prototype learning problem  called k-prototype learning  for 3D rigid
structures  and present a practical optimization model for it. As the base case  we consider the 1-
prototype learning problem  and reduce it to the chromatic clustering problem. Then we extend
1-prototype learning algorithm to k-prototype learning to achieve a quality guaranteed approximate
solution. Finally  we implement our algorithms on both random and biological data sets. Experi-
ments suggest that our algorithms can effectively learn prototypes from both types of data.

012345600.20.40.60.81kt1/t20123450.060.0650.070.0750.080.0850.09kAverage alignment costReferences

[1] H. Alt and L. Guibas  Discrete geometric shapes: matching  interpolation  and approximation  in: J.-R. Sack 
J. Urrutia (Eds.)  Handbook of Computational Geometry  Elsevier  Amsterdam  1999  pp. 121-153.
[2] K. S. Arun  T. S. Huang and S. D. Blostein: Least-Squares Fitting of Two 3-D Point Sets. IEEE Trans.
Pattern Anal. Mach. Intell. (PAMI) 9(5):698-700  1987.
[3] R. Berezney. Regulating the mammalian genome: the role of nuclear architecture. Advances in Enzyme
Regulation  42:39-52  2002.
[4] P.J. Besl and N.D. McKay  A method for registration of 3-d shapes  IEEE Trans. Pattern Anal. Mach. Intell.
14 (2) 239-256  1992.
[5] S. Belongie  J. Malik and J. Puzicha. Shape Matching and Object Recognition Using Shape Contexts. IEEE
Trans. Pattern Anal. Mach. Intell. 24(4): 509-522 (2002)
[6] J. Croft  J. Bridger  S. Boyle  P. Perry  P. Teague and W. Bickmore. Differences in the localization and
morphology of chromosomes in the human nucleus. J. Cell. Biol.  145(6):1119-1131  1999.
[7] T. Cremer  M. Cremer  S. Dietzel  S. Mller  I. Solovei  and S. Fakan. Chromosome territoriesa functional
nuclear landscape. Curr. Opin. Cell. Biol.  18(3):307-316  2006.
[8] S. D. Cohen and L. J. Guibas. The Earth Mover’s Distance under Transformation Sets. In ICCV  1076-1083 
1999.
[9] M. Charikar  S. Guha  E. Tardos and D. B. Shmoys. A constant-factor approximation algorithm for the
k-median problem (extended abstract). In Proceedings of the thirtieth annual ACM symposium on Theory of
computing  STOC ’99  pages 1-10  New York  NY  USA  1999.
[10] H. Ding  B. Stojkovic  R. Berezney and J. Xu. Gauging Association Patterns of Chromosome Territories
via Chromatic Median. In CVPR 2013: 1296-1303
[11] M. F. Demirci  A. Shokoufandeh and S. J. Dickinson. Skeletal Shape Abstraction from Examples. IEEE
Trans. Pattern Anal. Mach. Intell. 31(5): 944-952  2009.
[12] H. Ding and J. Xu. Solving the Chromatic Cone Clustering Problem via Minimum Spanning Sphere. In
ICALP (1) 2011: 773-784
[13] H. Ding and J. Xu. FPTAS for Minimizing Earth Mover’s Distance under Rigid Transformations. In ESA
2013: 397-408
[14] M. Ferrer  D. Karatzas  E. Valveny  I. Bardaj and H. Bunke. A generic framework for median graph
computation based on a recursive embedding approach. Computer Vision and Image Understanding 115(7):
919-928  2011.
[15] J. C. Gower. Generalized procrustes analysis. Psychometrika 40: 3331  1975.
[16] R. I. Hartley and F. Kahl. Global Optimization through Rotation Space Search. International Journal of
Computer Vision 82(1): 64-79 (2009)
[17] T. Jiang  F. Jurie and C. Schmid. Learning shape prior models for object matching. In CVPR 2009: 848-855
[18] X. Jiang  A. Munger and H. Bunke. On Median Graphs: Properties  Algorithms  and Applications  IEEE
TPAMI  vol. 23  no. 10  pp. 1144-1151  Oct. 2001.
[19] S. Li and O. Svensson: Approximating k-median via pseudo-approximation. In STOC 2013: 901-910.
[20] D. Macrini  K. Siddiqi and S. J. Dickinson. From skeletons to bone graphs: Medial abstraction for object
recognition. In CVPR  2008.
[21] T. B. Sebastian  P. N. Klein and B. B. Kimia. Recognition of Shapes by Editing Shock Graphs. In ICCV 
755-762  2001.
[22] N. H. Trinh and B. B. Kimia. Learning Prototypical Shapes for Object Categories. In SMiCV  2010.
[23] E. Weiszfeld. On the point for which the sum of the distances to n given points is minimum. Tohoku. Math.
Journal.  43:355-386  1937.
[24] D. B. West  Introduction to Graph Theory   Prentice Hall  Chapter 3  ISBN 0-13-014400-2  1999.
[25] M.J. Zeitz  L. Mukherjee  J. Xu  S. Bhattacharya and R. Berezney. A Probabilistic Model for the Arrange-
ment of a Subset of Chromosome Territories in WI38 Human Fibroblasts. Journal of Cellular Physiology  221 
120-129  2009.

,Hu Ding
Ronald Berezney
Jinhui Xu
Pritish Mohapatra
C.V. Jawahar
M. Pawan Kumar
Yunchen Pu
Zhe Gan
Ricardo Henao
Xin Yuan
Chunyuan Li
Andrew Stevens
Lawrence Carin
Ruoqi Shen
Yin Tat Lee