2018,Optimal Algorithms for Continuous Non-monotone Submodular and DR-Submodular Maximization,In this paper we study the fundamental problems of maximizing a continuous non monotone submodular function over a hypercube  with and without coordinate-wise concavity. This family of optimization problems has several applications in machine learning  economics  and communication systems. Our main result is the first 1/2 approximation algorithm for continuous submodular function maximization; this approximation factor of is the best possible for algorithms that use only polynomially many queries.  For the special case of DR-submodular maximization  we provide a faster 1/2-approximation algorithm that runs in (almost) linear time. Both of these results improve upon prior work [Bian et al.  2017  Soma and Yoshida  2017  Buchbinder et al.  2012].

Our first algorithm is a single-pass algorithm that uses novel ideas such as reducing the guaranteed approximation problem to analyzing a zero-sum game for each coordinate  and incorporates the geometry of this zero-sum game to fix the value at this coordinate. Our second algorithm is a faster single-pass algorithm that
exploits coordinate-wise concavity to identify a monotone equilibrium condition sufficient for getting the required approximation guarantee  and hunts for the equilibrium point using binary search. We further run experiments to verify the performance of our proposed algorithms in related machine learning applications.,Optimal Algorithms for Continuous Non-monotone
Submodular and DR-Submodular Maximization

Rad Niazadeh⇤

Tim Roughgarden†

Department of Computer Science

Stanford University  Stanford  CA 95130

Department of Computer Science

Stanford University  Stanford  CA 95130

rad@cs.stanford.edu

tim@cs.stanford.edu

Joshua R. Wang

Google  Mountain View  CA 94043

joshuawang@google.com

Abstract

In this paper we study the fundamental problems of maximizing abcontinuous
non-monotone submodular function over a hypercube  with and without coordinate-
wise concavity. This family of optimization problems has several applications in
machine learning  economics  and communication systems. Our main result is the
2-approximation algorithm for continuous submodular function maximization;
ﬁrst 1
the approximation factor of 1
2 is the best possible for algorithms that use only
polynomially many queries. For the special case of DR-submodular maximization 
i.e.  when the submodular functions is also coordinate-wise concave along all
coordinates  we provide a faster 1
2-approximation algorithm that runs in almost
linear time. Both of these results improve upon prior work [Bian et al.  2017a b 
Soma and Yoshida  2017  Buchbinder et al.  2012  2015].
Our ﬁrst algorithm is a single-pass algorithm that uses novel ideas such as reducing
the guaranteed approximation problem to analyzing a zero-sum game for each
coordinate  and incorporates the geometry of this zero-sum game to ﬁx the value at
this coordinate. Our second algorithm is a faster single-pass algorithm that exploits
coordinate-wise concavity to identify a monotone equilibrium condition sufﬁcient
for getting the required approximation guarantee  and hunts for the equilibrium
point using binary search. We further run experiments to verify the performance of
our proposed algorithms in related machine learning applications.

1

Introduction

Submodular optimization is a sweet spot between tractability and expressiveness  with numerous
applications in machine learning (e.g.  Krause and Golovin [2014]  and see below) and with many
algorithms that are both practical and enjoy good rigorous guarantees (e.g.  Buchbinder et al. [2012 
2015]). In general  a real-valued function F deﬁned on a lattice L is submodular if and only if

F(x _ y) + F(x ^ y) F (x) + F(y)

for all x  y 2L   where x_ y and x^ y denote the join and meet  respectively  of x and y in the lattice
L. Such functions are generally neither convex nor concave. In one of the most commonly studied
examples  L is the lattice of subsets of a ﬁxed ground set (or a sublattice thereof)  with union and
intersection playing the roles of join and meet  respectively.

⇤Rad Niazadeh was supported by Stanford Computer Science Motwani Fellowship.
†Tim Roughgarden was supported in part by Google Faculty Grant  Guggenheim Fellowship  and NSF

Grants CCF-1524062 and CCF-1813188.

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

This paper concerns a different well-studied setting  where L is a hypercube (i.e.  [0  1]n)  with
componentwise maximum and minimum serving as the join and meet  respectively.3 We consider
the fundamental problem of (approximately) maximizing a continuous and nonnegative submodular
function over the hypercube.4 The function F is given as a “black box” and can only be accessed by
querying its value at a point. We are interested in algorithms that use at most a polynomial (in n)
number of queries. We do not assume that F is monotone (otherwise the problem is trivial).
We next brieﬂy mention four applications of maximizing a non-monotone submodular function over
a hypercube that are germane to machine learning and other related application domains.5
Non-concave quadratic programming. In this problem  the goal is to maximize F(x) = 1
2xT Hx +
hT x + c  where the off-diagonal entries of H are non-positive. One application of this problem is to
large-scale price optimization on the basis of demand forecasting models [Ito and Fujimaki  2016].
Map inference for Determinantal Point Processes (DPP). DPPs are elegant probabilistic models that
arise in statistical physics and random matrix theory. DPPs can be used as generative models in
applications such as text summarization  human pose estimation  and news threading tasks [Kulesza
et al.  2012]. The approach in Gillenwater et al. [2012] to the problem boils down to maximize a
suitable submodular function over the hypercube  accompanied with an appropriate rounding (see
also [Bian et al.  2017a]). One can also think of regularizing this objective function with `2-norm
regularizer  to avoid overﬁtting  and the function will still remain submodular.
Log-submodularity and mean-ﬁeld inference. Another probabilistic model that generalizes DPPs
and all other strong Rayleigh measures [Li et al.  2016  Zhang et al.  2015] is the class of log-
submodular distributions over sets  i.e.  p(S) ⇠ exp(F(S)) where F(·) is a set submodular function.
MAP inference over this distribution has applications in machine learning [Djolonga and Krause 
2014]. One variational approach towards this MAP inference task is to use mean-ﬁeld inference to
approximate the distribution p with a product distribution x 2 [0  1]n  which again boils down to
submodular function maximization over the hypercube (see [Bian et al.  2017a]).
Revenue maximization over social networks. Here  there is a seller who wants to sell a product over
a social network of buyers. To do so  it freely assigns trial products and fractions thereof to the
buyers in the network [Bian et al.  2017b  Hartline et al.  2008]. For this problem  one can reduce it
to maximizing an objective function that takes into account two parts: the revenue gain from those
who did not get a free product  where the revenue function for any such buyer is a non-negative
non-decreasing and submodular function Ri(x); and the revenue loss from those who received the
free product  where the revenue function for any such buyer is a non-positive non-increasing and
submodular function ¯Ri(x). The combination for all buyers is a non-monotone submodular function.
It also is non-negative at ~0 and ~1  by extending the model and accounting for extra revenue gains
from buyers with free trials.

Our Results. Maximizing a submodular function over the hypercube is at least as difﬁcult as over
the subsets of a ground set.6 For the latter problem  the best approximation ratio achievable by an
algorithm making a polynomial number of queries is 1
2; the (information-theoretic) lower bound is
due to [Feige et al.  2007  2011]  the optimal algorithm to [Buchbinder et al.  2012  2015]. Thus  the
best-case scenario for maximizing a submodular function over the hypercube (using polynomially
many queries) is a 1
2-approximation. The main result of this paper achieves this best-case scenario:

There is an algorithm for maximizing a continuous submodular function over
the hypercube that guarantees a 1
2-approximation while using only a polynomial
number of queries to the function under mild continuity assumptions.

Our algorithm is inspired by the bi-greedy algorithm of Buchbinder et al. [2015]  which maximizes
a submodular set function; it maintains two solutions initialized at ~0 and ~1  goes over coordinates

3Our results also extend easily to arbitrary axis-aligned boxes (i.e.  “box constraints”).
4More generally  the function only has to be nonnegative at the points ~0 and ~1.
5See the supplement for more details on these applications.
6An instance of the latter problem can be converted to one of the former by extending the given set function f
(with domain viewed as {0  1}n) to its multilinear extension F deﬁned on the hypercube (where F(x) =
PS✓[n]Qi2S xiQi /2S(1  xi)f (S)). Sampling based on an ↵-approximate solution for the multilinear
extension yields an equally good approximate solution to the original problem.

2

sequentially  and makes the two solutions agree on each coordinate. The algorithmic question here is
how to choose the new coordinate value for the two solutions  so that the algorithm gains enough
value relative to the optimum in each iteration. Prior to our work  the best-known result was a
3-approximation [Bian et al.  2017b]  which generalized the simple non-optimal 1
3-approximation
1
deterministic bi-greedy algorithm of [Buchbinder et al.  2012  2015] for set functions to continuous
domains. However  to get the optimal approximation factor and systematically passing the barrier of
pure continuous submodularity  our algorithm requires a number of new ideas  including a reduction
to the analysis of a zero-sum game for each coordinate  and the use of the special geometry of this
game to bound the value of the game at its equilibrium. See Section 2 for more details.
The second and third applications above induce objective functions that  in addition to being sub-
modular  are concave in each coordinate. 7 This class of functions is called DR-submodular in the
literature (e.g.  in [Soma and Yoshida  2015] and based on diminishing returns deﬁned in [Kapralov
et al.  2013]). Here  an optimal 1
2-approximation algorithm was recently already known on integer
lattices [Soma and Yoshida  2017]  that can easily be generalized to our continuous setting as well;
our contribution is a signiﬁcantly faster such bi-greedy algorithm. The main idea here is to identify a
monotone equilibrium condition sufﬁcient for getting the required approximation guarantee  which
enables a binary search-type solution. See Section 3 for more details.
We also run experiments to verify the performance of our proposed algorithms in practical machine
learning applications. We observe that our algorithms match the performance of the prior work  while
providing either a better guaranteed approximation or a better running time.

Further Related Work. Buchbinder and Feldman [2016] derandomize the bi-greedy algorithm.
Staib and Jegelka [2017] apply continuous submodular optimization to budget allocation  and develop
a new submodular optimization algorithm to this end. Hassani et al. [2017] give a 1
2-approximation
for monotone continuous DR-submodular functions under convex constraints  which is later improved
e )-approximation in Mokhtari et al. [2018] (even for stochastic functions). Gotovos et al.
to (1  1
[2015] consider (adaptive) submodular maximization when feedback is given after an element is
chosen. Chen et al. [2018]  Roughgarden and Wang [2018] consider submodular maximization in the
context of online no-regret learning. Mirzasoleiman et al. [2013] show how to perform submodular
maximization with distributed computation. Submodular minimization is studied in Schrijver [2000] 
Iwata et al. [2001]. See Bach et al. [2013] for a survey on more applications in machine learning.

Variations of Continuous Submodularity. We consider non-monotone non-negative continuous
submodular functions  i.e.  F : [0  1] ! [0  1]n s.t. 8x  y 2 [0  1]n  F(x) +F(y) F (x_y) +F(x^
y)  where _ and ^ are coordinate-wise max and min operations. Two related properties are weak
Diminishing Returns Submodularity (weak DR-SM) and strong Diminishing Returns Submodularity
(strong DR-SM) [Bian et al.  2017b]  formally deﬁned below. Indeed  weak DR-SM is equivalent to
submodularity (see Proposition 3 in the supplement)  and hence we use these terms interchangeably.
Deﬁnition 1 (Weak/Strong DR-SM). Consider a continuous function F : [0  1]n ! [0  1]:
• Weak DR-SM (continuous submodular): 8i 2 [n]  8xi  yi 2 [0  1]n  and 8  0 8z

F(z +   xi) F (z  xi) F (z +   yi) F (z  yi)

• Strong DR-SM (DR-submodular ): 8i 2 [n]  8x  y 2 [0  1]n  and 8  0:
F(xi +   xi) F (x) F (yi +   yi) F (y)

As simple corollaries  a twice-differentiable F is strong DR-SM if and only if all the entries of its
Hessian are non-positive  and weak DR-SM if and only if all of the off-diagonal entries of its Hessian
are non-positive. Also  weak DR-SM together with concavity along each coordinate is equivalent to
strong DR-SM (see Proposition 3 in the supplementary materials for more details).

Coordinate-wise Lipschitz Continuity. Consider univariate functions generated by ﬁxing all but
one of the coordinates of the original function F(·). In future sections  we sometimes require mild
technical assumptions on the Lipschitz continuity of these single dimensional functions.

7However  after regularization the function still remains submodular  but can lose coordinate-wise concavity.

3

Figure 1: Continuous curve r(z) in R2 (dark blue)  positive-orthant concave envelope (red).

Deﬁnition 2 (Coordinate-wise Lipschitz). A function F : [0  1]n ! [0  1] is coordinate-wise
Lipschitz continuous if there exists a constant C > 0 such that 8i 2 [n]  8xi 2 [0  1]n  the single
variate function F(·  xi) is C-Lipschitz continuous  i.e. 

8z1  z2 2 [0  1] :

|F(z1  xi) F (z2  xi)| C|z1  z2|

2 Weak DR-SM Maximization: Continuous Randomized Bi-Greedy

2-approximation algorithm (up to additive error ) for maximizing a contin-
Our ﬁrst main result is a 1
uous submodular function F  a.k.a. weak DR-SM  which is information-theoretically optimal [Feige
et al.  2007  2011]. This result assumes that F is coordinate-wise Lipschitz continuous.8 Before
describing our algorithm  we introduce the notion of the positive-orthant concave envelope of a
two-dimensional curve  which is useful for understanding our algorithm.
Deﬁnition 3. Consider a curve r(z) = (g(z)  h(z)) 2 R2 over the interval z 2 [Zl  Zu] such that:

1. g : [Zl  Zu] ! [1 ↵ ] and h : [Zl  Zu] ! [1  ] are both continuous 
2. g(Zl) = h(Zu) = 0  and h(Zl) =  2 [0  1]  g(Zu) = ↵ 2 [0  1].

Then the positive-orthant concave envelope of r(·)  denoted by conc-env(r)  is the smallest concave
curve in the positive-orthant upper-bounding all the points {r(z) : z 2 [Zl  Zu]} (see Figure 1)  i.e. 
conc-env(r)   upper-face✓conv ({r(z) : z 2 [Zl  Zu]}) \⇢(g0  h0) 2 [0  1]2 :
↵  1◆
We start by describing a vanilla version of our algorithm for maximizing F over the unit hypercube 
termed as continuous randomized bi-greedy (Algorithm 1). This version assumes blackbox oracle
access to algorithms for a few computations involving univariate functions of the form F(.  xi) (e.g. 
maximization over [0  1]  computing conc-env(.)  etc.). We ﬁrst prove that the vanilla algorithm
ﬁnds a solution with an objective value of at least 1
2 of the optimum. In Section 2.2  we show how to
approximately implement these oracles in polynomial time when F is coordinate-wise Lipschitz.
Theorem 1. If F(·) is non-negative and continuous submodular (or equivalently is weak DR-SM) 
then Algorithm 1 is a randomized 1

h0


g0

+

2E [F(ˆz)] F (x⇤) 

2-approximation algorithm  i.e.  returns ˆz 2 [0  1]n s.t.
x2[0 1]n F(x) is the optimal solution.

where x⇤ 2 argmax

8Such an assumption is necessary  since otherwise the single-dimensional problem amounts to optimizing
an arbitrary function and is hence intractable. Prior works  e.g . Bian et al. [2017b] and Bian et al. [2017a] 
implicitly require such an assumption to perform single-dimensional optimization.

4

Figure 2: Pentagon (M0 M1 Q1 Q2 M2)= ADV player’s positive region against a mixed strategy
over two points P1 and P2.

2.1 Analysis of the Continuous Randomized Bi-Greedy (Proof of Theorem 1)

We start by deﬁning these vectors  used in our analysis in the same spirit as Buchbinder et al. [2015]:

i 2 [n] : X(i)   (ˆz1  . . .   ˆzi  0  0  . . .   0)  X(0)   (0  . . .   0)
i 2 [n] : Y(i)   (ˆz1  . . .   ˆzi  1  1  . . .   1)  Y(0)   (1  . . .   1)
i 2 [n] : O(i)   (ˆz1  . . .   ˆzi  x⇤i+1  . . .   x⇤n)  O(0)   (x⇤1  . . .   x⇤n)

Note that X(i) and Y(i) (or X(i1) and Y(i1)) are the values of X and Y at the end of (or at the
beginning of) the ith iteration of Algorithm 1. In the remainder of this section  we give the high-level
proof ideas and present some proof sketches. See the supplementary materials for the formal proofs.

Reduction to Coordinate-wise Zero-sum Games. For each coordinate i 2 [n]  we consider a sub-
problem. In particular  deﬁne a two-player zero-sum game played between the algorithm player
(denoted by ALG) and the adversary player (denoted by ADV). ALG selects a (randomized) strategy
ˆzi 2 [0  1]  and ADV selects a (randomized) strategy x⇤i 2 [0  1]. Recall the descriptions of g(z) and
h(z) at iteration i of Algorithm 1 :

g(z) = F(z  X(i1)
i

) F (Zl  X(i1)
i

)   h(z) = F(z  Y(i1)

i

) F (Zu  Y(i1)

i

).

We now deﬁne the utility of ALG (negative of the utility of ADV) in our zero-sum game as follows:

V (i)(ˆzi  x⇤i )   1

2

g(ˆzi) +

1
2

h(ˆzi)  max (g(x⇤i )  g(ˆzi)  h(x⇤i )  h(ˆzi)) .

(1)

Suppose the expected utility of ALG is non-negative at the equilibrium of this game. In particular 
suppose ALG’s randomized strategy ˆzi (in Algorithm 1) guarantees that for every strategy x⇤i of ADV
the expected utility of ALG is non-negative. If this statement holds for all of the zero-sum games
corresponding to different iterations i 2 [n]  then Algorithm 1 is a 1
2-approximation of the optimum.
Lemma 1. If 8i 2 [n] : E⇥V (i)(ˆzi  x⇤i )⇤  /n for constant > 0  then 2E [F(ˆz)] F (x⇤)  .

5

Algorithm 1: (Vanilla) Continuous Randomized Bi-Greedy
input: function F : [0  1]n ! [0  1] ;
output: vector ˆz = (ˆz1  . . .   ˆzn) 2 [0  1]n ;
Initialize X (0  . . .   0) and Y (1  . . .   1) ;
for i = 1 to n do
Zl 2 argmax
Zu 2 argmax

;

z2[0 1] F(z  Yi)
z2[0 1] F(z  Xi)

Find Zu  Zl 2 [0  1] such that8><>:
if Zu  Zl then
ˆzi Zl ;
else
8z 2 [Zl  Zu]  let(g(z)   F(z  Xi) F (Zl  Xi) 
h(z)   F(z  Yi) F (Zu  Yi) 
Let ↵   g(Zu) and    h(Zl) ;
Let r(z)   (g(z)  h(z)) be a continuous two-dimensional curve in [1 ↵ ] ⇥ [1  ] ;
Compute conc-env(r) (i.e. positive-orthant concave envelope of r(t) as in Deﬁnition 3) ;
Find point P   intersection of conc-env(r) and the line h0   = g0  ↵ on g-h plane ;
Suppose P = P1 + (1  )P2  where  2 [0  1] and Pj = r(z(j))  z(j) 2 [Zl  Zu] for
// see Figure 2
Randomly pick ˆzi such that(ˆzi z(1) with probablity 
Let Xi ˆzi and Yi ˆzi ;

j = 1  2  and both points are also on the conc-env(r) ;

// note that ↵    0

;

;

ˆzi z(2) o.w.

// after this  X and Y will agree at coordinate i

Proof sketch. Our bi-greedy approach  á la Buchbinder et al. [2012  2015]  revolves around analyzing
the evolving values of three points: X(i)  Y(i)  and O(i). These three points begin at all-zeroes 
all-ones  and the optimum solution  respectively  and converge to the algorithm’s ﬁnal point. In each
iteration  we aim to relate the total increase in value of the ﬁrst two points with the decrease in value
of the third point. If we can show that the former quantity is at least twice the latter quantity  then a
telescoping sum proves that the algorithm’s ﬁnal choice of point scores at least half that of optimum.
The utility of our game is speciﬁcally engineered to compare the total increase in value of the ﬁrst
two points with the decrease in value of the third point. The positive term of the utility is half of this
increase in value  and the negative term is a bound on how large in magnitude the decrease in value
may be. As a result  an overall nonnegative utility implies that the increase beats the decrease by a
factor of two  exactly the requirement for our bi-greedy approach to work. Finally  an additive slack
of /n in the utility of each game sums over n iterations for a total additive slack of .

Analyzing the Zero-sum Games. Fix an iteration i 2 [n] of Algorithm 1. We then have the
following.
Proposition 1. If ALG plays the (randomized) strategy ˆzi as described in Algorithm 1  then we have
E⇥V (i)(ˆzi  x⇤i )⇤  0 against any strategy x⇤i of ADV.
Proof of Proposition 1. We do the proof by case analysis over two cases:
⇤ Case Zl  Zu (easy): See the supplementary materials for this case.
⇤ Case Zl < Zu (hard): In this case  ALG plays a mixed strategy over two points. To determine
the two-point support  it considers the curve r = {(g(z)  h(z))}z2[Zl Zu] and ﬁnds a point P on
conc-env(r) (i.e.  Deﬁnition 3) that lies on the line h0   = g0  ↵  where recall that ↵ =
g(Zu)  0 and  = g(Zl)  0 (as Zu and Zl are the maximizers of F(z  X(i1)
) and F(z  Y(i1)
)
i
respectively). Because this point is on the concave envelope it should be a convex combination of two
points on the curve r(z). Lets say P = P1 + (1 )P2  where P1 = r(z(1)) and P2 = r(z(2))  and
 2 [0  1]. The ﬁnal strategy of ALG is a mixed strategy over {z(1)  z(2)} with probabilities (  1 ).
Fixing any mixed strategy of ALG over two points P1 = (g1  h1) and P2 = (g2  h2) with probabilities

i

6

(  1  ) (denoted by FP)  deﬁne the ADV’s positive region  i.e.

(g0  h0) 2 [1  1] ⇥ [1  1] : E(g h)⇠FP 1

2

g +

1
2

h  max(g0  g  h0  h)  0.

2 h2 + 1

2 h1 + 1

2 g1 + 1

2 h1) + (1  )( 3

2 g2 + 1

Now  suppose ALG plays a mixed strategy with the property that its corresponding ADV’s positive
region covers the entire curve {g(z)  h(z)}z2[0 1]. Then  for any strategy x⇤i of ADV the expected
utility of ALG is non-negative. In the rest of the proof  we geometrically characterize the ADV’s positive
region against a mixed strategy of ALG over any 2-point support  and then we show for the particular
choice of P1  P2 and  in Algorithm 1 the positive region covers the entire curve {g(z)  h(z)}z2[0 1].
Lemma 2. Suppose ALG plays a 2-point mixed strategy over P1 = r(z(1)) = (g1  h1) and P2 =
r(z(1)) = (g2  h2) with probabilities (  1  )  and w.l.o.g. h1  g1  h2  g2. Then ADV’s positive
region is the pentagon (M0 M1 Q1 Q2 M2)  where M0 = (1 1) and (see Figure 2):

2 g1) + (1  )( 3

2 g2) 
2 h2) 1 

1. M1 =1  ( 3
2. M2 =( 3
3. Q1 is the intersection of the lines leaving P1 with slope 1 and leaving M1 along the g-axis 
4. Q2 is the intersection of the lines leaving P2 with slope 1 and leaving M2 along the h-axis.
By applying Lemma 2  we have the following main technical lemma. The proof is geometric and is
pictorially visible in Figure 2. This lemma ﬁnishes the proof of Proposition 1.
Lemma 3 (main lemma). If ALG plays the two point mixed strategy described in Algorithm 1  then
for every x⇤i 2 [0  1] the point (g0  h0) = (g(x⇤i )  h(x⇤i )) is in the ADV’s positive region.
Proof sketch. For simplicity assume Zl = 0 and Zu = 1. To understand the ADV’s positive region
that results from playing a two-point mixed strategy by ALG  we consider the positive region that
results from playing a one point pure strategy. When ALG chooses a point (g  h)  the positive term of
the utility is one-half of its one-norm. The negative term of the utility is the worse between how much
the ADV’s point is above ALG’s point  and how much it is to the right of ALG’s point. The resulting
positive region is deﬁned by an upper boundary g0  3
2 h.
Next  let’s consider what happens when we pick point (g1  h1) with probability  and point (g2  h2)
with probability (1  ). We can compute the expected point: let (g3  h3) = (g1  h1) + (1 
)(g2  h2). As suggested by Lemma 2  the positive region for our mixed strategy has three boundary
conditions: an upper boundary  a right boundary  and a corner-cutting boundary. The ﬁrst two
boundary conditions correspond to a pure strategy which picks (g3  h3). By design  (g3  h3) is
located so that these boundaries cover the entire [1 ↵ ] ⇥ [1  ] rectangle. This leaves us with
analyzing the corner-cutting boundary  which is the focus of Figure 2. As it turns out  the intersections
of this boundary with the two other boundaries lie on lines of slope 1 extending from (gj  hj)j=1 2.
If we consider the region between these two lines  the portion under the envelope (where the curve r
may lie) is distinct from the portion outside the corner-cutting boundary. However  if r were to ever
violate the corner-cutting boundary condition without violating the other two boundary conditions  it
must do so in this region. Hence the resulting positive region covers the entire curve r  as desired.

2 h and a right boundary h0  1

2 g + 1

2 g + 3

2.2 Polynomial-time Implementation under Lipschitz Continuity: Overview
At each iteration  Algorithm 1 interfaces with F in two ways: (i) when performing optimization
to compute Zl  Zu and (ii) when computing the upper-concave envelope. In both cases  we are
concerned with univariate projections of F  namely F(z  Xi) and F(z  Yi. Assuming F is
coordinate-wise Lipschitz continuous with constant C > 0  we choose a small ✏> 0 and take
periodic samples at ✏-spaced intervals from each one of these functions  for a total of O( 1
✏ ) samples.
To perform task (i)  we simply return the the sample which resulted in the maximum function value.
Since the actual maximum is ✏-close to one of the samples  our maximum is at most an additive ✏C
lower in value. To perform task (ii)  we use these samples to form an approximate r(z) curve  denoted
by ˆr(z). Note that we then proceed exactly as described in Algorithm 1 to pick a (randomized) strategy

7

ˆzi using ˆr(z). Note that ADV can actually choose a point on the exact curve r(z). However the point
she chooses is close to one of our samples and hence is at most an additive ✏C better in value with
respect to functions g(.) and h(.). Furthermore  we can compute the upper-concave envelope ˆr(z) in
time linear in the number of samples using Graham’s algorithm [Graham  1972]. Roughly speaking 
this is because we can go through the samples in order of z-coordinate  avoiding the sorting cost of
running Graham’s on completely unstructured data. Formally  we have the following proposition.
See the supplementary materials for detailed implementations (Algorithm 3 and Algorithm 4).
Proposition 2. If F is coordinate-wise Lipschitz continuous with constant C > 0  then Algorithm 1
can be implemented with O(n2/✏) calls to F and returning a (randomized) point ˆz s.t.

2E [F(ˆz)] F (x⇤)  2C✏ 

where x⇤ 2 argmax

x2[0 1]n F(x) is the optimal solution.

3 Strong DR-SM Maximization: Binary-Search Bi-Greedy

Our second result is a fast binary search algorithm  achieving the tight 1
2-approximation factor (up to
additive error ) in quasi-linear time in n  but only for the special case of strong DR-SM functions
(a.k.a. DR-submodular); see Deﬁnition 1. This algorithm leverages the coordinate-wise concavity
to identify a coordinate-wise monotone equilibrium condition. In each iteration  it hunts for an
equilibrium point by using binary search. Satisfying the equilibrium at each iteration then guarantees
the desired approximation factor. Formally we propose Algorithm 2. As a technical assumption  we

Algorithm 2: Binary-Search Continuous Bi-greedy
input: function F : [0  1]n ! [0  1]  error ✏> 0 ;
output: vector ˆz = (ˆz1  . . .   ˆzn) 2 [0  1]n ;
Initialize X (0  . . .   0) and Y (1  . . .   1) ;
for i = 1 to n do

if @F@xi

(1  Yi)  0 then

(0  Xi)  0 then
ˆzi 0
else if @F@xi
ˆzi 1
// we do binary search.
while Yi  Xi >✏/n do

else

Let ˆzi Xi+Yi
if @F@xi

2

;

else

(ˆzi  Xi) · (1  ˆzi) + @F@xi
// we need to increase wi.
Set Xi ˆzi ;
// we need to decrease wi.
Set Yi ˆzi ;
Let Xi ˆzi and Yi ˆzi ;

(ˆzi  Yi) · ˆzi > 0 then

// after this  X and Y will agree at coordinate i

assume F is Lipschitz continuous with some constant C > 0  so that we can relate the precision of
our binary search with additive error. We arrive at the theorem  whose proof is in the supplement.
Theorem 2. If F(.) is non-negative and DR-submodular (a.k.a Strong DR-SM) and is coordinate-
wise Lipschitz continuous with constant C > 0  then Algorithm 2 runs in time On log n
✏ and is a
deterministic 1
2-approximation algorithm up to O(✏) additive error  i.e. returns ˆz 2 [0  1]n s.t.
x2[0 1]n F(x) is the optimal solution.

2F(ˆz) F (x⇤)  2C✏  

where x⇤ 2 argmax

Running Time.
(z  Yi)z is monotone non-
increasing in z  then clearly the binary search terminates in O (log(n/✏)) steps (note that the algorithm
only does binary search in the case when f (0) > 0 and f (1) < 0). To see the monotonicity 

If we show that f (z)   @F@xi

(z  Xi)(1  z) + @F@xi
2 (z  Yi) +✓ @F

@xi

(z  Yi) 

8

@F
@xi

(z  Xi)◆  0

f0(z) = (1  z)

@2F
@xi

2 (z  Xi) + z

@2F
@xi

(a) Strong DR-SM NQP

(b) Weak DR-SM NQP

(c) Strong DR-SM Softmax

Figure 3: Box and whisker plots of our experimental results.

where the inequality holds due to strong DR-SM and the fact that all of the Hessian entries (including
diagonal) are non-positive. Hence the total running time is O (n log(n/✏)).

4 Experimental Results

We empirically measure the solution quality of three algorithms: Algorithm 1 (GAME)  Algorithm 2
(BINARY) and the Bi-Greedy algorithm of Bian et al. [2017b] (BMBK). These are all based on a double-
greedy framework  which we implemented to iterate over coordinates in a random order. These
algorithms also do not solely rely on oracle access to the function; they invoke one-dimensional
optimizers  concave envelopes  and derivatives. We implement the ﬁrst and the second (Algorithm 3
and Algorithm 4 in the supplement)  and numerically compute derivatives by discretization. We
consider two application domains  namely Non-concave Quadratic Programming (NQP) [Bian
et al.  2017b  Kim and Kojima  2003  Luo et al.  2010]  under both strong-DR and weak-DR  and
maximization of softmax extension for MAP inference of determinantal point process[Kulesza
et al.  2012  Gillenwater et al.  2012]. Each experiment consists of twenty repeated trials. For each
experiment  we use n = 100 dimensional functions. Our experiments were implemented in python.
See the supplementary materials for the detailed speciﬁcs of each experiment. The results of our
experiments are in Table 1  and the corresponding box and whisker plots are in Figure 3. The data
suggest that for all three experiments the three algorithms obtain very similar objective values. For
example  in the weak-DR NQP experiment  all three algorithms have standard deviations around 6
while their means differ by less than 1.

GAME
BINARY
BMBK

1225.416454 ± 8.201871
1225.392136 ± 8.203827
1225.339063 ± 8.141104

NQP  8i  j : Hi j  0  (strong-DR) NQP  8i 6= j : Hi j  0  (weak-DR)

Softmax Ext. (strong-DR)
24.056934 ± 3.794209
23.945428 ± 3.770932
24.055435 ± 3.796350
Table 1: Experimental results listing mean and standard deviation over T = 20 repeated trials with
dimension n = 100.

1200.860403 ± 6.009484
1200.248876 ± 6.088293
1200.798114 ± 5.975035

5 Conclusion

We proposed a tight approximation algorithm for continuous submodular maximization  and a qausi-
linear time tight approximation algorithm for the special case of DR-submodular maxmization. Our
experiments also verify the applicability of these algorithms in practical domains in machine learning.
One interesting avenue for future research is to generalize our techniques to the maximization over
any arbitrary separable convex set  which will result in a broader application domain.

9

References
Anestis Antoniadis  Irène Gijbels  and Mila Nikolova. Penalized likelihood regression for generalized
linear models with non-quadratic penalties. Annals of the Institute of Statistical Mathematics  63
(3):585–615  2011.

Francis Bach et al. Learning with submodular functions: A convex optimization perspective. Founda-

tions and Trends R in Machine Learning  6(2-3):145–373  2013.

An Bian  Kﬁr Levy  Andreas Krause  and Joachim M Buhmann. Continuous DR-submodular
maximization: Structure and algorithms. In Advances in Neural Information Processing Systems 
pages 486–496  2017a.

Andrew An Bian  Baharan Mirzasoleiman  Joachim Buhmann  and Andreas Krause. Guaranteed non-
convex optimization: Submodular maximization over continuous domains. In Artiﬁcial Intelligence
and Statistics  pages 111–120  2017b.

Niv Buchbinder and Moran Feldman. Deterministic algorithms for submodular maximization
In Proceedings of the twenty-seventh annual ACM-SIAM symposium on Discrete

problems.
algorithms  pages 392–403. SIAM  2016.

Niv Buchbinder  Moran Feldman  Joseph Sefﬁ Naor  and Roy Schwartz. A tight linear time (1/2)-
approximation for unconstrained submodular maximization. In Proceedings of the 2012 IEEE
53rd Annual Symposium on Foundations of Computer Science  pages 649–658. IEEE Computer
Society  2012.

Niv Buchbinder  Moran Feldman  Joseph Sefﬁ  and Roy Schwartz. A tight linear time (1/2)-
approximation for unconstrained submodular maximization. SIAM Journal on Computing  44(5):
1384–1402  2015.

Lin Chen  Hamed Hassani  and Amin Karbasi. Online continuous submodular maximization. In

International Conference on Artiﬁcial Intelligence and Statistics  pages 1896–1905  2018.

Josip Djolonga and Andreas Krause. From map to marginals: Variational inference in bayesian
submodular models. In Advances in Neural Information Processing Systems  pages 244–252  2014.

Uriel Feige  Vahab S Mirrokni  and Jan Vondrak. Maximizing non-monotone submodular functions.
In Foundations of Computer Science  2007. FOCS’07. 48th Annual IEEE Symposium on  pages
461–471. IEEE  2007.

Uriel Feige  Vahab S Mirrokni  and Jan Vondrak. Maximizing non-monotone submodular functions.

SIAM Journal on Computing  40(4):1133–1153  2011.

Jennifer Gillenwater  Alex Kulesza  and Ben Taskar. Near-optimal map inference for determinantal
point processes. In Advances in Neural Information Processing Systems  pages 2735–2743  2012.

Alkis Gotovos  Amin Karbasi  and Andreas Krause. Non-monotone adaptive submodular maximiza-

tion. In Twenty-Fourth International Joint Conference on Artiﬁcial Intelligence  2015.

Ronald L Graham. An efﬁcient algorith for determining the convex hull of a ﬁnite planar set.

Information processing letters  1(4):132–133  1972.

Jason Hartline  Vahab Mirrokni  and Mukund Sundararajan. Optimal marketing strategies over social
networks. In Proceedings of the 17th international conference on World Wide Web  pages 189–198.
ACM  2008.

Hamed Hassani  Mahdi Soltanolkotabi  and Amin Karbasi. Gradient methods for submodular
maximization. In Advances in Neural Information Processing Systems  pages 5843–5853  2017.

Shinji Ito and Ryohei Fujimaki. Large-scale price optimization via network ﬂow. In Advances in

Neural Information Processing Systems  pages 3855–3863  2016.

Satoru Iwata  Lisa Fleischer  and Satoru Fujishige. A combinatorial strongly polynomial algorithm

for minimizing submodular functions. Journal of the ACM (JACM)  48(4):761–777  2001.

10

Michael Kapralov  Ian Post  and Jan Vondrák. Online submodular welfare maximization: Greedy is
optimal. In Proceedings of the twenty-fourth annual ACM-SIAM symposium on Discrete algorithms 
pages 1216–1225. SIAM  2013.

Sunyoung Kim and Masakazu Kojima. Exact solutions of some nonconvex quadratic optimization
problems via sdp and socp relaxations. Computational Optimization and Applications  26(2):
143–154  2003.

Andreas Krause and Daniel Golovin. Submodular function maximization. In Tractability: Practical

Approaches to Hard Problems  pages 71–104. Cambridge University Press  2014.

Alex Kulesza  Ben Taskar  et al. Determinantal point processes for machine learning. Foundations

and Trends R in Machine Learning  5(2–3):123–286  2012.

Chengtao Li  Suvrit Sra  and Stefanie Jegelka. Fast mixing markov chains for strongly rayleigh
measures  dpps  and constrained sampling. In Advances in Neural Information Processing Systems 
pages 4188–4196  2016.

Zhi-Quan Luo  Wing-Kin Ma  Anthony Man-Cho So  Yinyu Ye  and Shuzhong Zhang. Semideﬁnite
relaxation of quadratic optimization problems. IEEE Signal Processing Magazine  27(3):20–34 
2010.

Baharan Mirzasoleiman  Amin Karbasi  Rik Sarkar  and Andreas Krause. Distributed submodular
In Advances in Neural

maximization: Identifying representative elements in massive data.
Information Processing Systems  pages 2049–2057  2013.

Aryan Mokhtari  Hamed Hassani  and Amin Karbasi. Conditional gradient method for stochastic
submodular maximization: Closing the gap. In International Conference on Artiﬁcial Intelligence
and Statistics  pages 1886–1895  2018.

Tim Roughgarden and Joshua R Wang. An optimal learning algorithm for online unconstrained
submodular maximization. In To Appear in Proceedings of the 31st Conference on Learning
Theory (COLT)  2018.

Alexander Schrijver. A combinatorial algorithm minimizing submodular functions in strongly

polynomial time. Journal of Combinatorial Theory  Series B  80(2):346–355  2000.

Tasuku Soma and Yuichi Yoshida. A generalization of submodular cover via the diminishing return
property on the integer lattice. In Advances in Neural Information Processing Systems  pages
847–855  2015.

Tasuku Soma and Yuichi Yoshida. Non-monotone dr-submodular function maximization. In AAAI 

volume 17  pages 898–904  2017.

Matthew Staib and Stefanie Jegelka. Robust budget allocation via continuous submodular functions.

arXiv preprint arXiv:1702.08791  2017.

Jian Zhang  Josip Djolonga  and Andreas Krause. Higher-order inference for multi-class log-
supermodular models. In Proceedings of the IEEE International Conference on Computer Vision 
pages 1859–1867  2015.

11

,Rad Niazadeh
Tim Roughgarden
Joshua Wang