2019,Reflection Separation using a Pair of Unpolarized and Polarized Images,When we take photos through glass windows or doors  the transmitted background scene is often blended with undesirable reflection. Separating two layers apart to enhance the image quality is of vital importance for both human and machine perception. In this paper  we propose to exploit physical constraints from a pair of unpolarized and polarized images to separate reflection and transmission layers. Due to the simplified capturing setup  the system becomes more underdetermined compared with existing polarization based solutions that take three or more images as input. We propose to solve semireflector orientation estimation first to make the physical image formation well-posed and then learn to reliably separate two layers using a refinement network with gradient loss. Quantitative and qualitative experimental results show our approach performs favorably over existing polarization and single image based solutions.,Reﬂection Separation using a Pair of
Unpolarized and Polarized Images

Youwei Lyu1(cid:93)† Zhaopeng Cui2(cid:93) Si Li1∗ Marc Pollefeys2 Boxin Shi3 4∗

1Beijing University of Posts and Telecommunications

2Department of Computer Science  ETH Zürich

3National Engineering Laboratory for Video Technology  Peking University

4Peng Cheng Laboratory

{youweilv  zhpcui}@gmail.com  lisi@bupt.edu.cn 
marc.pollefeys@inf.ethz.ch  shiboxin@pku.edu.cn

Abstract

When we take photos through glass windows or doors  the transmitted background
scene is often blended with undesirable reﬂection. Separating two layers apart
to enhance the image quality is of vital importance for both human and machine
perception. In this paper  we propose to exploit physical constraints from a pair of
unpolarized and polarized images to separate reﬂection and transmission layers.
Due to the simpliﬁed capturing setup  the system becomes more underdetermined
compared with existing polarization based solutions that take three or more images
as input. We propose to solve semireﬂector orientation estimation ﬁrst to make the
physical image formation well-posed and then learn to reliably separate two layers
using a reﬁnement network with gradient loss. Quantitative and qualitative experi-
mental results show our approach performs favorably over existing polarization
and single image based solutions.

1

Introduction

Taking photos of a scene behind semireﬂectors (e.g.  glass windows and doors) without reﬂection
contamination is not an easy task for photographers  because the captured image often contains two
layers of the scene: the layer transmitting through the surface and the other layer reﬂected by the
surface. To separate the reﬂection and transmission layers is not an easy task for computer vision
researchers either  because recovering two images from a single mixture image is highly ill-posed
and the number of unknowns is twice as many as that of given measurements. Strong priors crafted
from natural image statistics (e.g.  gradient sparsity [14]) or learned from deep neural networks
(e.g.  [6]) can solve the problem if the assumed priors are well observed in the input. The problem
naturally becomes less ill-posed if multiple images are captured from different viewpoints (e.g.  ﬁve
images in [15]) or different polarization angles (e.g.  at least three images in [12]). The motions
between the layers present in multiple images provide a strong and effective constraint  but aligning
multiple-view images contaminated by reﬂections is not a trivial task [15]. Rotating a polarizer to
capture multiple images doesn’t suffer from the alignment issue [12]  but it requires skillful operations
and the polarized images always ﬁlter part of the incoming light.
In this paper  we propose to separate reﬂection and transmission layers using a pair of unpolarized
and polarized images. Such a setup takes fewer images than existing polarization based solutions

(cid:93)Authors contributed equally to this work.
†Part of this work was ﬁnished as a visiting student at Peking University.
∗Corresponding authors.

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

[18  12  22] and keeps an unpolarized image to maintain high light energy throughput. Directly
solving the two layers is still an ill-posed problem  but we ﬁnd that the problem has a closed-
form solution when the semireﬂector surface normal is known. By assuming the semireﬂector is
mostly planar  we can use only two parameters to determine the complete physical image formation
model that encodes the solution to layer separation. Based on these physical and mathematical
deductions  we propose an end-to-end deep neural network for reﬂection separation using two
(un)polarized images. More speciﬁcally  we design a cascaded architecture consisting of three
modules: semireﬂector orientation estimation to determine key variables for a well-posed physical
image formation model  polarization-guided separation based on the physical model  and separated
layers reﬁnement with gradient loss to enhance the sharpness. The code and test data are available at
https://github.com/YouweiLyu/reflection_separation_with_un-polarized_images.
The main contributions of this paper can be summarized as follows:

• We propose to solve reﬂection separation using a pair of unpolarized and polarized images
for the ﬁrst time  which integrates polarization cues with a simpler and light-efﬁcient setup.
• We derive a new formulation based on semireﬂector orientation estimation  which induces a

well-posed physical image formation model to be reliably learned for layer separation.

• We design an end-to-end deep neural network with gradient loss to solve the separation
problem and show superior performance over existing polarization and single image based
solutions.

2 Related Work

In terms of input  reﬂection separation can take a single image or multiple images. The single image
problem has the most relaxed requirement  since it only needs an image captured by an ordinary
camera in the wild. But such a problem is also highly ill-posed  priors formulated using hand
crafted priors [13  14  16  19  21  1] or features learned from large-scale training data [6  20  25  24]
are explored to facilitate the separation. By taking multiple images from different viewpoints  the
difference of projected motion from reﬂection and transmission layers due to the visual parallax
provides useful cues to the separation [2  8  23]. By taking multiple images under different polarization
angles  the differently polarized images provide "independent" representations of reﬂection and
transmission layers based on physical image formation model to leverage the separation using
independent component analysis [7  10  3]  closed form expressions [18  12]  or deep learning [22].
Multiple images usually bring more promising separation quality than relying on only a single image 
but request more complicated and careful image capturing operations.
In terms of solutions  reﬂection separation can be solved by non-learning based methods or learning
methods. Adopted priors of reﬂection and transmission layers by non-learning based methods include
the sparse gradient prior [14  13]  blur level differences between two layers [16]  the ghosting effect
due to thick glass [19  5]  and the Laplacian data ﬁdelity term [1]. Such handcrafted priors may get
violated in various real scenarios when expected properties are weakly observed. Learning based
methods are beneﬁted by the comprehensive modeling ability of deep neural networks. It can be
solved by learning the gradient inference and image restoration sequentially [4  6] or concurrently
[20]  by incorporating perceptual losses [25]  and by considering bidirectional constraints [24]. With
differently polarized images available  a simple encoder-decoder architecture is shown to be effective
for separating two layers using physics based image formation model [22].
Our work belongs to the learning based approach using multiple images and physical constraints.
Different from previous works exploring polarization cues [18  12  22] that require at least three
images with different polarization angles  we take a pair of unpolarized and polarized images and
learn to solve a more underdetermined system.

3 Physical Image Formation Model

Given a pair of unpolarized and polarized images captured at the same view  we aim to separate
the reﬂection layer and the transmission layer. In this section  we will ﬁrst review the reﬂection
and transmission model  and then describe the relationship between polarization properties and

2

Figure 1: Illustration of physical image formation model.

semireﬂector surface geometry. By assuming the medium is planar  we prove that the separation
tightly relies on only two parameters of the plane.

3.1 Reﬂection and Transmission Image Formation

Suppose It  the intensity of light from the transmission scene  and Ir  the intensity of light from
the reﬂection scene  are both unpolarized. After being reﬂected or transmitted  the intensity of light
observed at pixel x changes depending on θ(x)  the angle of incidence (AoI) at the reﬂected point
corresponding to pixel x  as the following [12]:

Iunpol(x) =

R⊥(θ(x)) + R(cid:107)(θ(x))

2

· Ir(x) +

T⊥(θ(x)) + T(cid:107)(θ(x))

2

· It(x) 

(1)

where R represents the relative strength of light reﬂected off a glass surface  T represents the relative
strength of light transmitted through glass  and subscripts ⊥ and (cid:107) correspond to the polarized
components perpendicular and parallel to the plane of incidence (PoI)  respectively.
When we place a linear polarizer with a polarization angle φ in front of the camera  according to
Malus’ law [9]  the intensity at pixel x is

Ipol(x) =

R⊥(θ(x)) cos2 (φ − φ⊥(x)) + R(cid:107)(θ(x)) sin2 (φ − φ⊥(x))
T⊥(θ(x)) cos2 (φ − φ⊥(x)) + T(cid:107)(θ(x)) sin2 (φ − φ⊥(x))

2

· Ir(x)+
· It(x) 

(2)

2

where φ⊥(x) is the orientation of the polarizer for the best transmission of the component perpendic-
ular to the PoI. For easy representation  we denote

ξ(x) = R⊥(θ(x)) + R(cid:107)(θ(x)) 

(3)

ζ(x) = R⊥(θ(x)) cos2 (φ − φ⊥(x)) + R(cid:107)(θ(x)) sin2 (φ − φ⊥(x)).

(4)
The glass can be considered as a double-surfaced semireﬂector  and we have R⊥(θ(x))+T⊥(θ(x)) =
1 and R(cid:107)(θ(x)) + T(cid:107)(θ(x)) = 1 for each pixel x approximately [12]. Then Equation (1) and
Equation (2) can be rewritten as

Iunpol(x) =

ξ(x)

2

· Ir(x) +

2 − ξ(x)

2

· It(x) 

Ipol(x) =

ζ(x)

2

· Ir(x) +

1 − ζ(x)

2

· It(x) 

3

(5)

(6)

Normal ofglass GlassPoINormal of PoI⊥∥Transmission layerReflection layerCaptured image⊥∥CameraI𝐼𝑟𝐼𝑡𝜃where ξ(x) ∈ (0  2) and ζ(x) ∈ (0  1). Given the value of ξ(x) and ζ(x)  the reﬂection layer and the
transmission layer can be computed by

Ir(x) = 2 · (2 − ξ(x)) · Ipol(x) − (1 − ζ(x)) · Iunpol(x)

2ζ(x) − ξ(x)

 

(7)

It(x) = 2 · ζ(x) · Iunpol(x) − ξ(x) · Ipol(x)

2ζ(x) − ξ(x)

(8)
except for 2ζ(x) = ξ(x) where φ − φ⊥(x) = ±45◦ or ±135◦. The angle of a polarizer φ can be
measured by calibration. Associated with surface geometry of semireﬂector  φ⊥(x) is not constant
but spatially varying over the whole image plane. There may exist trivial φ − φ⊥(x) corresponding
to a few pixels  which have negligible effect on the separation.
In short  the reﬂection layer Ir(x) and the transmission layer It(x) are determined by ξ(x) and ζ(x)
when a pair of unpolarized and polarized images are given.

 

3.2 Semireﬂector Surface Geometry

In order to recover the reﬂection layer Ir and the transmission layer It  we ﬁrst have to solve ξ(x)
and ζ(x) according to Equations (5) and (6)  which can be further computed by θ(x) and φ − φ⊥(x)
according to Equations (3) and (4). In this section  we will describe how we compute θ(x) and
φ − φ⊥(x) for each pixel given the surface normal of the semireﬂector and camera parameters.
We assume the semireﬂector has a planar surface  and the camera coordinate is the same as the world
coordinate. Then the semireﬂector plane can be expressed as

sin α · x − cos α sin β · y + cos α cos β(z − z0) = 0 

(9)
where α represents the rotation angle around y-axis and β represents the angle around x-axis. The
plane normal is thus given by

(cid:35)(cid:34) cos α

(cid:35)(cid:34) 0

(cid:35)

(cid:34)

nglass =

0

0

0 cos β − sin β
cos β
0

sin β

0
1
− sin α 0

0

sin α

0

cos α

=

0
1

sin α

− cos α sin β
cos α cos β

(cid:35)

.

(10)

(cid:34) 1

Let f be the focal length of the camera  and (px  py) be the coordinate of the principal point. For the
pixel x located at (u  v) on the image plane  we can easily compute its corresponding 3D point X on
the medium plane as

(cid:35)

(cid:34) u − px

v − py

f

X =

f cos α cos β + (u − px) sin α − (v − py) cos α sin β

z0 cos α cos β

.

(11)

Let X = X/(cid:107)X(cid:107)  then the AoI corresponding to pixel x can be calculated as

θ(x) = arccos(cid:12)(cid:12)nglass · X(cid:12)(cid:12).

(12)
We calculate the absolute value for the above term since θ(x) ∈ [0  90◦]. The normal of PoI
nP oI = (xP oI   yP oI   zP oI )

(cid:62) is then calculated as

nP oI = nglass × X 
and the projection of nP oI on imaging plane is (xP oI   yP oI )
φ⊥(x) ∈ [0  360◦)  we have

(13)
(cid:62) denoting orientation of φ⊥(x). For

φ⊥(x) = arctan

.

(14)

yP oI
xP oI

We combine the reﬂection and transmission image formation and semireﬂector surface geometry
to compute φ⊥(x) and θ(x) for each pixel. Note they are not affected by z0  because physically
the transparent plane can be projected to parallel plane with arbitrary intercept about z-axis and
mathematically before computing arctan and arccos  z0 has been eliminated according to Equations
(12) and (14).
In short  it is the normal of glass that matters  and we only need to estimate coefﬁcients α and β to
determine the semireﬂector plane.

4

Figure 2: Our method takes a cascaded architecture with three modules: semireﬂector orientation
estimation  polarization-guided separation  and separated layers reﬁnement.

4 Reﬂection Separation Network

In this section  we introduce the proposed reﬂection separation network which makes use of physical
model discussed in Section 3  and details about loss function and network training.

4.1 Network Architecture

As shown in Figure 2  our network takes a cascaded architecture which consists of three modules:
semireﬂector orientation estimation  polarization-guided separation  and separated layers reﬁnement.
Taking a pair of unpolarized and polarized images  the semireﬂector orientation module aims to
predict coefﬁcients of the glass plane  i.e.  α and β. As we only need to estimate two parameters  the
pose estimation module is pretty light  and consists of seven convolutional layers followed by two fully
connected layers. The polarization-guided separation module takes α and β as inputs  and computes
the reﬂection layer ˆIr and transmission layer ˆIt. This module only relies on the physical image
formation model in Section 3 using analytic equations  so we do not have any parameters to learn
here. The separated layers using equations may not be satisfactory due to the gap between physical
model and real data. The numerical problem also occurs when the denominators in Equation (7) and
Equation (8) approach zero  and the computed results are degenerated. Fortunately  this happens only
for a few pixels and the remaining non-degenerated calculations can guide a reﬁnement network to
produce compelling separation results. We therefore further feed ˆIr and ˆIt with original input images
and ξ  ζ into the separated layers reﬁnement module to improve the initial estimation. The reﬁnement
module has a widely adopted encoder-decoder architecture. In detail  the encoder consists of eight
convolutional layers and the decoder consists of ﬁve deconvolutional layers.
We hope the network to reconstruct details in the original image as many as possible  so we deﬁne
the loss on both the estimated image and its gradient as:

L = λ1Lr(Ir) + λ2Lt(It) + λ3Lr(gr) + λ4Lt(gt) 

(15)
where Lr(Ir) and Lt(It) deﬁne the loss on the estimated reﬂection and transmission layers  Lr(gr)
and Lt(gt) deﬁne the loss on the gradients of the estimated reﬂection and transmission layers  and
λ1 2 3 4 are the weighting parameters. The mean square error (MSE) is used for all the loss. We
implement our model using PyTorch deep learning framework [17]. Adam [11] is used as the
optimizer with a starting learning rate of 0.0004  β1 = 0.9 and β2 = 0.999. The learning rate is
descended to 0.0002 and 0.00008 after 12th and 18th epochs respectively. λ1 2 3 4 are set to be 1.2 
1.5  1.0  and 1.5 respectively for our training.

4.2 Training Data Generation

The deep-learning method tends to be data-hungry  but it is difﬁcult to obtain pairwise reﬂection and
transmission images with both polarized and unpolarized observations at a large scale. It is possible
to directly use Equation (1) and Equation (2) to generate the synthetic data  but it is expected that the

5

Encoder InputUnpolarized imagePolarized image𝜉𝜃OutputReflection layerTransmission layerEncoderDecoder𝜷𝜶Fully connected layer𝜙⊥𝜁መ𝐼𝑟መ𝐼𝑡Semireflectororientation estimationPolarization-guided separationSeparated layers refinementTable 1: Quantitative evaluation results on synthetic data.

Ours

SSIM 0.9708
28.23
PSNR
SSIM 0.8953
20.92
PSNR

Ours-
Initial
0.8324
21.61

0.6253
13.90

ReﬂectNet-
Finetuned

0.9627
27.52

0.8303
18.50

Ours-

2% noise
0.9691
28.08

0.8785
20.53

Ours-

8% noise
0.9668
27.31

0.8418
19.18

Ours-

16% noise

0.9619
27.17

0.8022
18.26

Transmission

Reﬂection

network trained with such data may not generalize well on real scenarios. Therefore  we propose an
effective data generation pipeline to better match images of real-world scenes.
At the ﬁrst step  we randomly pick two images from PLACE2 dataset [26] as original reﬂection and
transmission layers. Based on a commonly adopted assumption that people take photos focusing on
the background scene (transmission layer) so the reﬂection layer is likely to be blurry [6]  a Gaussian
smoothing kernel with a random kernel size in the range of 3 to 7 pixels is applied to a portion of
reﬂection images. We also need to simulate coefﬁcients α and β of the semireﬂector plane. We
assume people rarely take photos in front of the glass that inclines by a weird angle  e.g.  glass nearly
orthogonal to the image plane  so we set α ∈ (−65◦  65◦) and β ∈ (−35◦  35◦). For the virtual
camera  we set the focal length as 1.4 times as long as the image width  and the image resolution as
256 × 256. By ﬁxing these factors  the normal of glass is speciﬁed  θ(x) and φ⊥(x) can be derived
from Equation (12) and Equation (14)  respectively. φ can be an arbitrary value in the range of [0  2π) 
as long as the polarization images are captured under the same polarizer angle. In our experiment  we
set φ to be 0. Additionally  real-world scenes are generally high-dynamic-range (HDR)  so we apply
dynamic range manipulation as conducted in [22] to simulate appearance of reﬂections in a more
realistic manner. Finally  the synthetic unpolarized image Iunpol and the polarized image Ipol can be
obtained by Equation (5) and Equation (6).

5 Experimental Results

We evaluate our method on both synthetic and real data with extensive experiments including the
comparison with related work and ablation study. For all quantitative evaluations  both the peak-
signal-to-noise ratio (PSNR) and the structural similarity index measure (SSIM) are used to evaluate
the quality of separated images.

5.1 Evaluation on Synthetic Data

We use 5000 pairs of images from our synthetic validation dataset with ground truth reﬂection
and transmission layers to quantitatively compare our method with state-of-the-art approaches.
ReﬂectNet [22] is a learning based method using three polarized images; Zhang et al. [25]  CRRN
[20]  CEILNet [6] are deep learning based solutions using a single image; and LB14 [16] is a non-
learning method using a single image. To test the performance of ReﬂectNet [22]  we generated two
additional polarization images for each pair of (un)polarized images in our dataset  and ﬁnetuned
ReﬂectNet using Adam solver with a learning rate of 0.005 for 5 epochs. The experimental results
are shown in Figure 3 and Table 1. We can see that  compared to all single-image based methods 
our method has much better performance  which shows the advantage with the additional polarized
image. We can also see that all single-image based methods have bad performance for reﬂection
layers1 due to their weak signal in the input images. Our method also outperforms ReﬂectNet [22]
which requires three polarized images as input  especially in terms of the quality of the reﬂection
layer  although our method only needs one polarized image in addition to an unpolarized image.
Moreover  our method performs the best in suppressing undesired reﬂection in transmission layer
and recovers high-quality reﬂection layer as well  as indicated by corresponding SSIM and PSNR
values under images in Figure 3. We also evaluate our initial polarization-guided separation ˆIr and ˆIt
("Ours-Initial") in Table 1  and we can see that the initial separation is effective  and our reﬁnement
network helps eliminate the artifact and noise caused by rough estimation of ξ and ζ. At last  we test

1Brightness is upgraded for visualization purpose.

6

Figure 3: Quantitative and qualitive evaluation on synthetic data  compared with ReﬂectNet [22] 
Zhang et al. [25]  CRRN [20]  CEILNet [6]  and LB14 [16].

7

OursGTInput imagesSSIM:0.8049PSNR:17.99SSIM:0.04383PSNR:4.680SSIM:0.4811PSNR:13.07SSIM:0.1249PSNR:4.511SSIM:0.8990PSNR:18.44SSIM:0.1758PSNR:7.826Zhang et al.SSIM:0.7352PSNR:15.64SSIM:0.8049PSNR:17.99SSIM:0.6100PSNR:13.67SSIM:0.00047PSNR:3.153SSIM:0.7464PSNR:16.64SSIM:0.00324PSNR:6.686LB14SSIM:0.7438PSNR:4.321SSIM:0.00152PSNR:4.321SSIM:0.5368PSNR:13.33SSIM:0.0117PSNR:3.337SSIM:0.7876PSNR:16.72SSIM:0.06656PSNR:7.223CRRNSSIM:0.7664PSNR:18.17SSIM:0.00015PSNR:3.565SSIM:0.5682PSNR:12.39SSIM:0.00035PSNR:2.590SSIM:0.8454PSNR:18.55SSIM:0.00049PSNR:5.887CEILNetReflectNetSSIM:0.9655PSNR:25.86SSIM:0.9721PSNR:22.10SSIM:0.8466PSNR:19.26SSIM:0.9655PSNR:20.24SSIM:0.9708PSNR:27.58SSIM:0.9695PSNR:24.01SSIM:0.4797PSNR:13.89SSIM:0.8130PSNR:14.64SSIM:0.5289PSNR:14.86SSIM:0.6890PSNR:10.69SSIM:0.7744PSNR:18.52SSIM:0.7209PSNR:16.29ReflectionReflectionReflectionTransmission TransmissionTransmissionUnpolarized imgPolarized imgUnpolarized imgPolarized imgUnpolarized imgPolarized imgSSIM:0.8858PSNR:21.31SSIM:0.7956PSNR:14.44SSIM:0.7106PSNR:16.97SSIM:0.9416PSNR:18.15SSIM:0.9016PSNR:20.56SSIM:0.9271PSNR:15.57InitialFigure 4: Qualitative evaluation on real data  compared with ReﬂectNet [22]  Zhang et al. [25]  CRRN
[20]  CEILNet [6]  and LB14 [16].

our method against Gaussian noise added to images with different standard deviations. The results are
shown in Table 1. We can see that our method performs consistently well and is robust to Gaussian
noise.

5.2 Evaluation on Real Data

We use the Lucid Vision Phoenix polarization camera1 to capture the real dataset. The polarization
camera can take four images with different polarizer angles at a single shot. We use three of them
as input images to ReﬂectNet [22] and one of them as polarized input image to our method. The
unpolarized input image is calculated by summing two polarized images captured with orthogonal
polarizer angles [9]. Note the polarization camera has no color ﬁlter  so we can only provide results in
gray scale  as displayed in Figure 42. These scenes contain strong reﬂections with complex textures 
and all single-image based methods fail to recover the transmissions while removing the reﬂections.
Thanks to the polarimetric cues  both ReﬂectNet [22] and our method show obvious advantage over

1https://thinklucid.com/product/phoenix-5-0-mp-polarized-model/
2For better visualization  the minimum and maximum intensity values of different algorithms are stretched in

a consistent range.

8

OursInput imagesZhang et al.LB14CRRNCEILNetReflectNetReflection Reflection Reflection Transmission Transmission Transmission Polarized imgUnpolarized imgPolarized imgUnpolarized imgPolarized imgUnpolarized imgTable 2: Quantitative evaluation results in ablation study.

Ours

SSIM 0.9708
28.23
PSNR
SSIM 0.8953
PSNR
20.92

W/o
ξ & ζ
0.9632
27.38

0.8721
20.02

ReﬂectNet-
reﬁnement

0.9594
27.20

0.8084
18.30

W/o

ori. est.
0.9647
27.47

0.8015
18.84

W/o

grad. loss
0.9674
27.82
0.9131
21.94

Ours-

Parabola
0.8846
24.40

0.4833
13.69

Transmission

Reﬂection

single-image based methods. Compared to ReﬂectNet [22]  our method shows stronger capability in
suppressing the ghost in transmission and clear extraction of the reﬂection layer.

5.3 Ablation Study

We ﬁrst verify the contribution of semireﬂector orientation estimation by directly estimating ξ(x)
and ζ(x) from the network (without inferring α and β ﬁrst). In other words  we also use an encoder-
decoder architecture to estimate ξ(x) and ζ(x) directly from a given pair of (un)polarized images.
SSIM and PSNR averaged over 5000 validation images are shown in "W/o ori. est." column of Table 2.
From Table 2  we can see that  with more prior knowledge encoded in the network  the orientation
estimation with only two parameters is easier to learn and also better than directly estimating ξ(x)
and ζ(x) for each pixel.
We further evaluate different loss functions  and train our network without the gradient loss. The
results are listed in "W/o grad. loss" column of Table 2. We ﬁnd the gradient loss is particularly useful
in improving the quality of transmission layer estimation (background scene with more interests) 
though it may hurt the accuracy of reﬂection layer (usually treated as noise to be removed [16]).
In order to compare our method with ReﬂectNet [22] thoroughly  we remove ξ and ζ from the input
of our reﬁnement network  and feed the results of ReﬂectNet and our polarization-guided separation
into this reﬁnement network. Under this setup  the quantitative results of reﬂection and transmission
are listed in "ReﬂectNet-reﬁnement" and "W/o ξ & ζ" columns of Table 2. We can see that even with
this reﬁnement ReﬂectNet still performs worse than our full pipeline. It also shows the importance of
feeding ξ and ζ into the reﬁnement network.
Our model assumes the semireﬂector approximately has a planar shape. When it becomes a curved
shape such as the windshield in a car  our semireﬂector orientation estimation module will fail  and
thus the performance of our method will deteriorate. We generate the test data using the parabola
surface simulation as ReﬂectNet  and directly test using our current model. The result is listed
in Table 2. We can see that the performance becomes much worse especially for the reﬂection.
The performance might be improved if we modify the semireﬂector orientation estimation module
accordingly  and we will consider this as our future work.

6 Conclusion

We solved the problem of integrating polarimetric constraints from a pair of unpolarized and polarized
images to separate reﬂection and transmission layers. To deal with the ill-posedness introduced
by using fewer polarized images  we derived a semireﬂector orientation constraint to make the
physical image formation for layer separation valid given our setup  and trained a neural network
to successfully separate two layers  showing state-of-the-art performance. Our simple yet unique
capturing setup not only explored polarimetric constraints for separating reﬂection and transmission
layers as reliably as existing approaches using three or more polarized images  but also could be
potentially integrated into smart phones without affecting the original photography quality by not
making all images polarized.

Acknowledgments

This work was supported by the National Natural Science Foundation of China under Grant 61872012
and 61702047.

9

References
[1] N. Arvanitopoulos  R. Achanta  and S. Süsstrunk. Single image reﬂection suppression. In Proc. CVPR 

2017.

[2] E. Be’Ery and A. Yeredor. Blind separation of superimposed shifted images using parameterized joint

diagonalization. IEEE TIP  17(3):340–353  2008.

[3] A. M. Bronstein  M. M. Bronstein  M. Zibulevsky  and Y. Y. Zeevi. Sparse ICA for blind separation of
transmitted and reﬂected images. International Journal of Imaging Systems and Technology  15(1):84–91 
2005.

[4] P. Chandramouli  M. Noroozi  and P. Favaro. Convnet-based depth estimation  reﬂection separation and

deblurring of plenoptic images. In Proc. ACCV  2016.

[5] Y. Diamant and Y. Y. Schechner. Overcoming visual reverberations. In Proc. CVPR  2008.

[6] Q. Fan  J. Yang  G. Hua  B. Chen  and D. Wipf. A generic deep architecture for single image reﬂection

removal and image smoothing. In Proc. ICCV  2017.

[7] H. Farid and E. H. Adelson. Separating reﬂections and lighting using independent components analysis. In

Proc. CVPR  1999.

[8] K. Gai  Z. Shi  and C. Zhang. Blind separation of superimposed moving images using image statistics.

IEEE TPAMI  34(1):19–32  2012.

[9] E. Hecht. Optics. Pearson education. Addison-Wesley  2002.

[10] Hermanto  A. K. D. B. Filho  T. Yamamura  and N. Ohnishi. Separating virtual and real objects using
independent component analysis. IEICE Transactions on Information and Systems  84(9):1241–1248 
2001.

[11] D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 

2014.

[12] N. Kong  Y. Tai  and J. S. Shin. A physically-based approach to reﬂection separation: from physical

modeling to constrained optimization. IEEE TPAMI  36(2):209–221  2014.

[13] A. Levin and Y. Weiss. User assisted separation of reﬂections from a single image using a sparsity prior.

In Proc. ECCV  2004.

[14] A. Levin and Y. Weiss. User assisted separation of reﬂections from a single image using a sparsity prior.

IEEE TPAMI  29(9):1647–1654  2007.

[15] Y. Li and M. S. Brown. Exploiting reﬂection change for automatic reﬂection removal. In Proc. ICCV 

2013.

[16] Y. Li and M. S. Brown. Single image layer separation using relative smoothness. In Proc. CVPR  2014.

[17] A. Paszke  S. Gross  S. Chintala  G. Chanan  E. Yang  Z. DeVito  Z. Lin  A. Desmaison  L. Antiga  and

A. Lerer. Automatic differentiation in PyTorch. In Proc. NIPS Autodiff Workshop  2017.

[18] Y. Y. Schechner  J. Shamir  and N. Kiryati. Polarization and statistical analysis of scenes containing a

semireﬂector. Journal of the Optical Society of America  17(2):276–284  2000.

[19] Y. Shih  D. Krishnan  F. Durand  and W. T. Freeman. Reﬂection removal using ghosting cues. In Proc.

CVPR  2015.

[20] R. Wan  B. Shi  L.-Y. Duan  A.-H. Tan  and A. C. Kot. Crrn: Multi-scale guided concurrent reﬂection

removal network. In Proc. CVPR  2018.

[21] R. Wan  B. Shi  A. H. Tan  and A. C. Kot. Depth of ﬁeld guided reﬂection removal. In Proc. ICIP  2016.

[22] P. Wieschollek  O. Gallo  J. Gu  and J. Kautz. Separating reﬂection and transmission images in the wild. In

Proc. ECCV  2018.

[23] T. Xue  M. Rubinstein  C. Liu  and W. T. Freeman. A computational approach for obstruction-free

photography. ACM TOG  34(4):79:1–79:11  2015.

[24] J. Yang  D. Gong  L. Liu  and Q. Shi. Seeing deeply and bidirectionally: A deep learning approach for

single image reﬂection removal. In Proc. ECCV  2018.

10

[25] X. Zhang  R. Ng  and Q. Chen. Single image reﬂection separation with perceptual losses. In Proc. CVPR 

2018.

[26] B. Zhou  A. Lapedriza  A. Khosla  A. Oliva  and A. Torralba. Places: A 10 million image database for

scene recognition. IEEE TPAMI  40(6):1452–1464  2017.

11

,Youwei Lyu
Zhaopeng Cui
Si Li
Marc Pollefeys
Boxin Shi