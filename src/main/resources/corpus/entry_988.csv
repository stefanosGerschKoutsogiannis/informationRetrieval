2010,Collaborative Filtering in a Non-Uniform World: Learning with the Weighted Trace Norm,We show that matrix completion with trace-norm regularization can be significantly hurt when entries of the matrix are sampled non-uniformly  but that a properly weighted version of the trace-norm regularizer works well with non-uniform sampling. We show that the weighted trace-norm regularization indeed yields significant gains on the highly non-uniformly sampled Netflix dataset.,Collaborative Filtering in a Non-Uniform World:

Learning with the Weighted Trace Norm

Brain and Cognitive Sciences and CSAIL  MIT

Toyota Technological Institute at Chicago

Nathan Srebro

Ruslan Salakhutdinov

Cambridge  MA 02139
rsalakhu@mit.edu

Chicago  Illinois 60637

nati@ttic.edu

Abstract

We show that matrix completion with trace-norm regularization can be signiﬁ-
cantly hurt when entries of the matrix are sampled non-uniformly  but that a prop-
erly weighted version of the trace-norm regularizer works well with non-uniform
sampling. We show that the weighted trace-norm regularization indeed yields sig-
niﬁcant gains on the highly non-uniformly sampled Netﬂix dataset.

1 Introduction

Trace-norm regularization is a popular approach for matrix completion and collaborative ﬁltering 
motivated both as a convex surrogate to the rank [7  6] and in terms of a regularized inﬁnite factor
model with connections to large-margin norm-regularized learning [17  1  15].

Current theoretical guarantees on using the trace-norm for matrix completion assume a uniform
sampling distribution over entries of the matrix [18  6  5  13]. In a collaborative ﬁltering setting 
where rows of the matrix represent e.g. users and columns represent e.g. movies  this corresponds
to assuming all users are equally likely to rate movies and all movies are equally likely to be rated.
This of course cannot be further from the truth  as invariably some users are more active than others
and some movies are rated by many people while others are rarely rated.

In this paper we show  both analytically and through simulations  that this is not a deﬁciency of
the proof techniques used to establish the above guarantees. Indeed  a non-uniform sampling dis-
tribution can lead to a signiﬁcant deterioration in prediction quality and an increase in the sample
complexity. Under non-uniform sampling  as many as Ω(n4/3) samples might be needed for learn-
ing even a simple (e.g. orthogonal low rank) n × n matrix. This is in sharp contrast to the uniform
sampling case  in which ˜O(n) samples are enough. It is important to note that if the rank could
be minimized directly  which is in general not computationally tractable  ˜O(n) samples would be
enough to learn a low-rank model even under an arbitrary non-uniform distribution.

Our analysis further suggests a weighted correction to the trace-norm regularizer  that takes into
account the sampling distribution. Although appearing at ﬁrst as counter-intuitive  and indeed be-
ing the opposite of a previously suggested weighting [21]  this weighting is well-motivated by our
analytic analysis and we discuss how it corrects the problems that the unweighted trace-norm has
with non-uniform sampling. We show how the weighted trace-norm indeed yields a signiﬁcant
improvement on the highly non-uniformly sampled Netﬂix dataset.

The only other work we are aware of that studies matrix completion under non-uniform sampling
is work on exact completion (i.e. when the matrix is assumed to be exactly low rank) under power-
law sampling [12]. Other then being limited to one speciﬁc distribution  the requirement of the
matrix being exactly low rank is central to this work  and the results cannot be directly applied
in the presence of even small noise. Empirically  the approach leads to deterioration in predictive
performance on the Netﬂix data [12].

1

2 Complexity Control in terms of Matrix Factorizations
Consider the problem of predicting the entries of some unknown target matrix Y ∈ Rn×m based
on a random subset S of observed entries YS. For example  n and m may represent the number of
users and the number of movies  and Y may represent a matrix of partially observed rating values.
Predicting elements of Y can be done by ﬁnding a matrix X minimizing the training error  here
measured as a squared error  and some measure c(X) of complexity. That is  minimizing either:

or:

F + λc(X)

X kXS − YSk2
min
c(X)≤C kXS − YSk2
F  
min

(1)

(2)

where YS  and similarly XS  denotes the matrix “masked” by S  where (YS)i j = Yi j if (i  j) ∈ S
and 0 otherwise. For now we ignore possible repeated entries in S and we also assume that n ≤ m
without loss of generality. The two formulations (1) and (2) are equivalent up to some (unknown)
correspondence between λ and C  and we will be referring to them interchangeably.
A basic measure of complexity is the rank of X  corresponding to the minimal dimensionality k such
that X = U ⊤V for some U ∈ Rk×n and V ∈ Rk×m. Directly constraining the rank of X forms
one of the most popular approaches to collaborative ﬁltering. However  the rank is non-convex and
hard to minimize. It is also not clear if a strict dimensionality constraint is most appropriate for
measuring the complexity.

Trace-norm Regularization
Lately  methods regularizing the norm of the factorization U ⊤V   rather than its dimensionality  have
been advocated and were shown to enjoy considerable empirical success [14  15]. This corresponds
to measuring complexity in terms of the trace-norm of X  which can be deﬁned equivalently either
as the sum of the singular values of X  or as [7]:

kXktr = min

X=U ′V

1
2

(kUk2

F + kV k2
F) 

(3)

where the dimensionality of U and V is not constrained. Beyond the modeling appeal of norm-
based  rather than dimension-based  regularization  the trace-norm is a convex function of X and so
can be minimized by either local search or more sophisticated convex optimization techniques.

Scaling
The rank  as a measure of complexity  does not scale with the size of the matrix. That is  even very
large matrices can have low rank. Viewing the rank as a complexity measure corresponding to the
number of underlying factors  if data is explained by e.g. two factors  then no matter how many rows
(“users”) and columns (“movies”) we consider  the data will still have rank two. The trace-norm 
however  does scale with the size of the matrix. To see this  note that the trace-norm is the ℓ1 norm
of the spectrum  while the Frobenius norm is the ℓ2 norm of the spectrum  yielding:

kXkF ≤ kXktr ≤ kXkFprank(X) ≤ √nkXkF .

(4)

The Frobenius norm certainly increases with the size of the matrix  since the magnitude of each ele-
ment does not decrease when we have more elements  and so the trace-norm will also increase. The
above suggests measuring the trace-norm relative to the Frobenius norm. Without loss of generality 
consider each target entry to be of roughly unit magnitude  and so in order to ﬁt Y each entry of
X must also be of roughly unit magnitude. This suggests scaling the trace-norm by √nm. More
speciﬁcally  we study the trace-norm through the complexity measure:

tc(X) = kXk2
tr
nm

 

(5)

which puts the trace-norm on a comparable scale to the rank. In particular  when each entry of X is 
on-average  of unit magnitude (i.e. has unit variance) we have 1 ≤ tc(X) ≤ rank(X).
The relationship between tc(X) and the rank is tight for “orthogonal” low-rank matrices  i.e. low-
rank matrices X = U ⊤V where the rows of U and also the rows of V are orthogonal and of equal
magnitudes. In order for the entries in Y to have unit magnitude  i.e. kY k2
F = nm  we have that rows

2

in U have normqn/√k and rows in V have normqm/√k  yielding precisely tc(X) = rank(X).
Such an orthogonal low-rank matrix can be obtained  e.g.  when entries of U and V are zero-mean
i.i.d. Gaussian with variance 1/√k  corresponding to unit-variance entries in X.
Generalization Guarantees
Another place where we can see that tc(X) plays a similar role to rank(X) is in the generalization
and sample complexity guarantees that can be obtained for low-rank and low-trace-norm learning.
If there is a low-rank matrix X ∗ achieving low average error relative to Y (e.g. if Y = X ∗ + noise) 
then by minimizing the training error subject to a rank constraint (a computationally intractable
task)  |S| = ˜O(rank(X ∗)(n + m)) samples are enough in order to guarantee learning a matrix X
whose overall average error is close to that of X ∗ [16]. Similarly  if there is a low-trace-norm matrix
X ∗ achieving low average error  then minimizing the training error and the trace-norm (a convex
optimization problem)  |S| = ˜O(tc(X ∗)(n + m)) samples are enough in order to guarantee learning
a matrix X whose overall average error is close to that of X ∗ [18]. In these bounds tc(X) plays
precisely the same role as the rank  up to logarithmic factors.

In order to get some intuitive understanding of low-rank learning guarantees  it is enough to consider
the number of parameters in the rank-k factorization X = U ⊤V . It is easy to see that the number of
parameters in the factorization is roughly k(m + n) (perhaps a bit less due to rotational invariants).
We therefore would expect to be able to learn X when we have roughly this many samples  as is
indeed conﬁrmed by the rigorous sample complexity bounds.
For low-trace-norm learning  consider a sample S of size |S| ≤ Cn  for some constant C. Taking
entries of Y to be of unit magnitude  we have kYSkF = p|S| ≤ √Cn (recall that YS is deﬁned to
be zero outside S). From (4) we therefore have: kYSktr ≤ √Cn · √n = √Cn and so tc(YS) ≤ C.
That is  we can “shatter” any sample of size |S| ≤ Cn with tc(X) = C: no matter what the
underlying matrix Y is  we can always perfectly ﬁt the training data with a low trace-norm matrix
X s.t. tc(X) ≤ C  without generalizing at all outside S. On the other hand  we must allow matrices
with tc(X) = tc(X ∗)  otherwise we can not hope to ﬁnd X ∗  and so we can only constrain tc(X) ≤
C = tc(X ∗). We therefore cannot expect to learn with less than ntc(X ∗) samples. It turns out that
this is essentially the largest random sample that can be shattered with tc(X) ≤ C = tc(X ∗). If we
have more than this many samples we can start learning.

3 Trace-Norm Under a Non-Uniform Distribution

In this section  we analyze trace-norm regularized learning when the sampling distribution is not
uniform. That is  when there is some  known or unknown  non-uniform distribution D over entries
of the matrix Y (i.e. over index pairs (i  j)) and our sample S is sampled i.i.d. from D. Our objective
is to get low average error with respect to the distribution D. That is  we measure generalization
performance in terms of the weighted sum-squared-error:
(6)

D(i  j)(Xij − Yij)2.

kX − Y k2

D = E(i j)∼D(cid:2)(Xij − Yij )2(cid:3) = Xij

We ﬁrst point out that when using the rank for complexity control  i.e. when minimizing the training
error subject to a low-rank constraint  non-uniformity does not pose a problem. The same generaliza-
tion and learning guarantees that can be obtained in the uniform case  also hold under an arbitrary
distribution D. In particular  if there is some low-rank X ∗ such that kX ∗ − Y k2
D is small  then
˜O(rank(X ∗)(n + m)) samples are enough in order to learn (by minimizing training error subject to
a rank constraint) a matrix X with kX − Y k2
D [16].
However  the same does not hold when learning using the trace-norm. To see this  consider an
orthogonal rank-k square n×n matrix  and a sampling distribution which is uniform over an nA×nA
sub-matrix A  with nA = na. That is  the row (e.g. “user”) is selected uniformly among the ﬁrst nA
rows  and the column (e.g. “movie”) is selected uniformly among the ﬁrst nA columns. We will use
A to denote the subset of entries in the submatrix  i.e. A = {(i  j)|1 ≤ i  j ≤ nA}. For any sample
S  we have:

D almost as small as kX ∗ − Y k2

tc(YS) = kYSk2

n2 ≤ kYSk2

tr

F rank(YS)
n2

≤ |S|na

n2 = |S|
n2−a  

(7)

3

where we again take the entries in Y to be of unit magnitude. In the second inequality above we
use the fact that YS is zero outside of A  and so we can bound the rank of YS by the dimensionality
nA = na of A.
Setting a < 1  we see that we can shatter any sample of size1 kn2−a = ˜ω(n) with a matrix X for
which tc(X)<k. When a ≤ 1/2  the total number of entries in A is less than n. In this case ˜O(n)
observations are enough in order to memorize2 YA. But when 1/2 < a < 1  with ˜O(n) observations 
restricting to even tc(X) < 1  we can neither learn Y   since we can shatter YS  nor memorize it. For
example  when a = 2/3 and so nA = n2/3  we need roughly n4/3 to start learning by constraining
tc(X) to a constant — the same as we would need in order to memorize YA. This is a factor of n1/3
greater than the sample size needed to learn a matrix with constant tc(X) in the uniform case.
The above arguments establish that restricting the complexity to tc(X) < k might not lead to gen-
eralization with ˜O(kn) samples in the non-uniform case. But does this mean that we cannot learn a
rank-k matrix by minimizing the trace-norm using ˜O(kn) samples when the sampling distribution
is concentrated on a small submatrix? Of course this is not the case. Since the samples are uniform
on a small submatrix  we can just think of the submatrix A as our entire space. The target matrix
still has low rank  even when restricted to A  and we are back in the uniform sampling scenario.

observation scenario. When samples are concentrated in nA  we actually need to restrict to a much

The only issue here is that tc(X) ≤ k  i.e. kXktr ≤ n√k  is the right constraint in the uniform
smaller trace norm  kXktr ≤ na√k  which will allow learning with ˜O(kna) samples.

We can  however  modify the example and construct a sampling distribution under which Ω(n4/3)
samples are required in order to learn even an “orthogonal” low-rank matrix  no matter what con-
straint is placed on the trace-norm. This is a signiﬁcantly large sample complexity than ˜O(kn) 
which is what we would expect  and what is required for learning by constraining the rank directly.
To do so  consider another submatrix B of size nB × nB with nB = n/2  such
that the rows and columns of A and B do not overlap (see ﬁgure). Now  consider
a sampling distribution D which is uniform over A with probability half  and uni-
form over B with probability half. Consider ﬁtting a noisy matrix Y = X ∗ + noise
where X ∗ is “orthogonal” rank-k. In order to ﬁt on B  we need to allow a trace-
√k  i.e. allow tc(X) = k/4. But as discussed above 
norm of at least kX ∗
with such a generous constraint on the trace-norm  we will be able to shatter S ⊂ A whenever
|S ∩ A| = |S|/2 ≤ kn2−a/4. Since there is no overlap in rows and columns  and so values in the
sub-matrices A and B are independent  shattering S∩A means we cannot hope to learn in A. Setting
a=2/3 as before  with o(n4/3) samples  we cannot learn in A and B jointly: either we constrain to
a trace-norm which is too low to ﬁt X ∗
B (we under-ﬁt on B)  or we allow a trace-norm which is high
enough to overﬁt YS∩A. In any case  we will make errors on at least half the mass of D.3
Empirical Example

Bktr = n

B

A

2

Let us consider a simple simulation experiment that will help us illustrates this phenomenon. Con-
sider a simple synthetic example  where we used nA = 300 and nB = 4700  with an orthogonal
rank-2 matrix X ∗ and Y = X ∗ + N (0  1) (in case of repeated entries  the noise is independent for
each appearance in the sample). The training sample size was also set to |S|=140 000.
D−kY − X ∗k2
The three curves of Fig. 1 measure the excess (test) error kX − X ∗k2
D
of the learned model  as well as the error contribution from A and from B  as a function of the
constraint on tc(X)  for the sampling distribution discussed above and a speciﬁc sample size. As
can be seen  although it is possible to constrain tc(X) so as to achieve squared-error of less than 0.8
on B  this constraint is too lax for A and allows for over-ﬁtting. Constraining tc(X) so as to avoid
overﬁtting A (achieving almost zero excess test error)  leads to a suboptimal ﬁt on B.

D = kX − Y k2

1Recall that f (n) = ˜ω(g(n)) iff for all p  g(n) logp g(n)
2The algorithm saw all (or most) entries of the matrix and does not need to predict any unobserved entries.
3More accurately  if we do allow high enough trace-norm to ﬁt B  and |S| = o(n4/3)  then the “cost” of
B. For large enough n  we would be tempted to

overﬁtting YS∩A is negligible compared to the cost of ﬁtting X ∗
very slightly deteriorate the ﬁt of X ∗

B in order to “free up” enough trace-norm and completely overﬁt YS∩A.

→ 0.

f (n)

4

1.2

1

0.8

0.6

0.4

0.2

B

A+B

A

1.2

1

0.8

0.6

0.4

0.2

B

A+B

A

 

r
o
r
r
E
d
e
r
a
u
q
S
n
a
e
M

 

 

r
o
r
r
E
d
e
r
a
u
q
S
n
a
e
M

 

1.2

1

0.8

0.6

0.4

0.2

shift A+B

shift A

B

A+B

A

 

r
o
r
r
E
d
e
r
a
u
q
S
n
a
e
M

 

0
10−3

10−2

10−1
tc(X)

100

101

0
10

15

20

tcpq(X)

25

30

0
10−2

10−1

100

Regularization parameter λ

101

Figure 1: Left: Mean squared error (MSE) of the learned model as a function of the constraint on tc(X)
(left)  tcpq(X) (middle). Right: The solid curves show the optimum of the mean squared error objective
(9) (unweighted trace-norm)  as a function of the regularization parameter λ. The dashed curves display a
weighted trace-norm. The black (middle) curve is the overall MSE error  the red (bottom) curve measures only
the contribution from A  and the blue (top) curve measures only the contribution from B.

Penalty Formulation
Until now we discussed learning by constraining the trace-norm  i.e. using the formulation (2). It is
also insightful to consider the penalty view (1)  i.e. learning by minimizing

(9)

X kYS − XSk2
min

F + λkXktr .

F + λkXBktr)
F + λnBptcB(XB)(cid:17)  

(8)
First observe that the characterization (3) allows us to decompose kXktr = kXAktr + kXBktr 
where w.l.o.g. we take all columns of U and V outside A and B to be zero. Since we also have
kYS − XSk2
F  we can decompose the training objective
(8) as:
kYS − XSk2

F = kYA∩S − XA∩Sk2
F + λkXktr = (kYA∩S − XA∩Sk2

F + λkXAktr) + (kYB∩S − XB∩Sk2

F + kYB∩S − XB∩Sk2

F + λnAptcA(XA)(cid:17) +(cid:16)kYB∩S − XB∩Sk2
= (cid:16)kYA∩S − XA∩Sk2
where tcA(XA) = kXAk2
A (and similarly tcB(XB)) refers to the complexity measure tc(·)
tr /n2
measured relative to the size of A (similarly B). We see that the training objective decomposes
to objectives over A and B. Each one of these corresponds to a trace-norm regularized learning
problem  under a uniform sampling distribution (in the corresponding submatrix) of a noisy low-rank
“orthogonal” matrix  and can therefor be learned with ˜O(knA) and ˜O(knB) samples respectively.
In other words  ˜O(kn) samples should be enough to learn both inside A and inside B.
However  the regularization tradeoff parameter λ compounds the two problems. When the objective
is expressed in terms of tc(·)  as in (9)  the regularization tradeoff is scaled differently in each part
of the training objective. With ˜O(kn) samples  it is possible to learn in A with some setting of λ 
and it is possible to learn in B with some other setting of λ  but from the discussion above we learn
that no single value of λ will allow learning in both A and B. Either λ is too high yielding too strict
regularization in B  so learning on B is not possible  perhaps since it is scaled by nB ≫ nA. Or λ
is too small and does not provide enough regularization in A.
Returning to our simulation experiment  the solid curves of Fig. 1  right panel  show the excess
test error for the minimizer of the training objective (9)  as a function of the regularization tradeoff
parameter λ. Note that these are essentially the same curves as displayed in Fig. 1  except the
path of regularized solutions is now parameterized by λ rather than by the bound on tc(X). Not
surprisingly  we see the same phenomena: different values of λ are required for optimal learning on
A and on B. Forcing the same λ on both parts of the training objective (9) yields a deterioration in
the generalization performance.

4 Weighted Trace Norm
The decomposition (9) and the discussion in the previous section suggests weighting the trace-norm
by the frequency of rows and columns. For a sampling distribution D  denote by p(i) the row
marginal  i.e. the probability of observing row i  and similarly denote by q(j) the column marginal.
We propose using the following weighted version of the trace-norm as a regularizer:

kXktr(p q) = kdiag(√p)Xdiag(√q)ktr = min

X=U ′V

1

2(cid:0)Xi

p(i)kUik2 +Xj

q(j) kVjk2(cid:1)

(10)

5

where diag(√p) is a diagonal matrix with pp(i) on its diagonal (similarly diag(√q)). The corre-
sponding normalized complexity measure is given by tcpq(X) = kXk2
tr(p q). Note that for a uniform
distribution we have that tcpq(X) = tc(X). Furthermore  it is easy to verify that for an “orthogonal”
rank-k matrix X we have tcpq(X) = k for any sampling distribution.
Equipped with the weighted trace-norm as a regularizer  let us revisit the problematic sampling
distribution studied in the previous Section. In order to ﬁt the “orthogonal” rank-k X ∗  we need a

weighted trace-norm of kX ∗ktr(p q) = ptcpq(X) = √k. How large a sample S ∩ A can we now
shatter using such a weighted trace-norm? We can shatter a sample if kYS∩Aktr ≤ √k. We can

calculate:

kYS∩Aktr(p q) = kYS∩Aktr /(2nA) ≤ p|S ∩ A|nA/(2nA) = p|S|/(8nA).

(11)
That is  we can shatter a sample of size up to |S| = 8knA < 8kn. The calculation for B is identical.
It seems that now  with a ﬁxed constraint on the weighted trace-norm  we have enough capacity to
both ﬁt X ∗  and with ˜O(kn) samples  avoid overﬁtting on A.
Returning to the penalization view (2) we can again decompose the training objective as:

F + λkXktr(p q) =

kYS − XSk2
= (cid:16)kYA∩S − XA∩Sk2

avoiding the scaling by the block sizes which we encountered in (9).

F + λ/2ptcA(XA)(cid:17) +(cid:16)kYB∩S − XB∩Sk2

F + λ/2ptcB(XB)(cid:17)

(12)

Returning to the synthetic experiments of Fig. 1 (right panel)  and comparing (9) with (12)  we see
that introducing the weighting corresponds to a relative change of nA/nB in the correspondence of
the regularization tradeoff parameters used for A and for B. This corresponds to a shift of log nA
nB
in the log-domain used in the ﬁgure. Shifting the solid red (bottom) curve by this amount yields
the dashed red (bottom) curve. The solid blue (top) curve and the dashed red (bottom) curve thus
represent the excess error on B and on A when the weighted trace norm is used  i.e. the training
objective (12) is minimized. The dashed black (middle) curve is the overall excess error when using
this training objective. As can be seen  the weighting aligns the excess errors on A and on B much
better  and yields a lower overall error. The weighted trace-norm achieves the lowest MSE of 0.4301
with corresponding λ = 0.11. This is compared to the lowest MSE of 0.4981 with λ = 0.80 
achieved by the unweighted trace-norm.

It is also interesting to observe that the weighted trace-norm outperforms its unweighted counterpart
for a wide range of regularization parameters λ ∈ [0.01; 0.6]. This may also suggest that in prac-
tice  particularly when working with large and imbalanced datasets  it may be easier to search for
regularization parameters using weighted trace-norm.

Finally  Fig. 1  right panel  also suggests that the optimal shift might actually be smaller than
nA/nB. We can consider a smaller shift by using the partially-weighted trace-norm:

= min

X=U ⊤V

1
2

(Xi

q(j)α kVjk2).

tr(pα/n1−α qα/m1−α).

p(i)α kUik2 +Xj

diag(pα/2)Xdiag(qα/2)(cid:13)(cid:13)(cid:13)tr

kXktr(p q α) = (cid:13)(cid:13)(cid:13)
and the corresponding normalized complexity measure tcα(X) = kXk2
Other Weightings and Bayesian Perspective
The weighted trace-norm motivated by the analysis here (with α = 1) implies that the frequent users
(equivalently movies) get regularized much stronger than the rare users (equivalently movies). This
might at ﬁrst seem quite counter-intuitive as the natural weighting might seem to be the opposite.
Indeed  Weimer et al. [21] speculated that with a uniform weighting (α = 0) frequent users are
regularized too heavily compared to infrequent users  and so suggested regularizing frequent users
(and movies) with a lower weight  corresponding to α = −1. Although this might seem natural  we
saw here that the reverse is actually true – the Weimer et al. weighting (α = −1) would only make
things worse. Indeed  given the analysis here  Weimer et al. actually observed a deterioration in
prediction quality when using their weighting. This is also demonstrated in the experiments on the
Netﬂix data in Section 6.

6

The weighted regularization motivated here (with α = 1) is also quite unusual from Bayesian per-
spective. The trace-norm can be viewed as a negative-log-prior for the Probabilistic Matrix Factor-
ization model [15]  where entries of U  V are taken to be i.i.d. Gaussian. The two terms of (8) can
then be interpreted as a log-likelihood and log-prior  and minimizing (8) corresponds to ﬁnding the
MAP parameters. Introducing weighting (with α = 1) effectively states that the effect of the prior
becomes stronger as we observe more data. Yet  our analysis strongly suggest that in non-uniform
setting  such “unorthodox” regularization is crucial for achieving good generalization performance.

5 Practical Implementation
When dealing with large datasets  such as the Netﬂix data  the most practical way to ﬁt trace-norm

regularized models is through stochastic gradient descent [15  8]. Let ni = Pj Sij and mj =
Pi Sij denote the number of observed ratings for user i and movie j respectively. The training

objective using a partially-weighted trace-norm 10 can be written as:
q(j)α

λ

X{i j}∈S

(cid:18)(cid:0)Yij − U ⊤

i Vj(cid:1)2

+

2(cid:18) p(i)α

ni kUik2 +

mj kVjk2(cid:19)(cid:19) 

where U ∈ Rk×n and V ∈ Rk×m. We can optimize this objective using stochastic gradient descent
by picking one training pair (i  j) at random at each iteration  and taking a step in the direction
opposite the gradient of the term corresponding to the chosen (i  j).
Note that even though the objective (13) as a function of U and V is non-convex  there are no non-
global local minima if we set k to be large enough  i.e. k > min(n  m) [2]. However  in practice
using very large values of k becomes computationally expensive. Instead  we consider truncated
trace-norm minimization by restricting k to smaller values.
In the next section we demonstrate
that even when using truncated trace-norm  its weighted version signiﬁcantly improves model’s
prediction performance.

In our experiments  we also replace unknown row p(i) and column q(j) marginals in (13) by their
empirical estimates ˆp(i) = ni/|S| and ˆq(j) = mj/|S|. This results in the following objective:

X{i j}∈S

(cid:18)(cid:0)Yij − U ⊤

i Vj(cid:1)2

+

λ

2|S|(cid:18)nα−1

i

kUik2 + mα−1

j

kVjk2(cid:19)(cid:19).

(13)

Setting α = 1  corresponding to the weighted trace-norm (10)  results in stochastic gradient updates
that do not involve the row and column counts at all and are in some sense the simplest. Strangely 
and likely originating as a “bug” in calculating the stochastic gradients by one of the participants 
these steps match the stochastic training used by many practitioners on the Netﬂix dataset  without
explicitly considering the weighted trace-norm [8  19  15].

6 Experimental results
We tested the weighted trace-norm on the Netﬂix dataset  which is the largest publicly available col-
laborative ﬁltering dataset. The training set contains 100 480 507 ratings from 480 189 anonymous
users on 17 770 movie titles. Netﬂix also provides qualiﬁcation set  containing 1 408 395 ratings 
out of which we set aside 100 000 ratings for validation. The “qualiﬁcation set” pairs were selected
by Netﬂix from the most recent ratings for a subset of the users. Due to the special selection scheme 
ratings from users with few ratings are overrepresented in the qualiﬁcation set  relative to the train-
ing set. To be able to report results where the train and test sampling distributions are the same  we
also created a “test set” by randomly selecting and removing 100 000 ratings from the training set.
All ratings were normalized to be zero-mean by subtracting 3.6. The dataset is very imbalanced: it
includes users with over 10 000 ratings as well as users who rated fewer than 5 movies.

For various values of α  we learned a factorization U ⊤V with k = 30 and with k = 100 dimensions
(factors) using stochastic gradient descent as in (13). For each value of α and k we selected the
regularization tradeoff λ by minimizing the error on the 100 000 qualiﬁcation set examples set aside
for validation. Results on both the Netﬂix qualiﬁcation set and on the test set we created are reported
in Table 1. Recall that the sampling distribution of the “test set” matches that of the training data 
while the qualiﬁcation set is sampled differently  explaining the large difference in generalization
between the two.

7

Table 1: Root Mean Squared Error (RMSE) on the Netﬂix qualiﬁcation set and on a test set that was held out
from the training data  for training by minimizing (13). We report λ/|S| minimizing the error on the validation
set (held out from the qualiﬁcation set)  qualiﬁcation and test errors using this tradeoff  and tcα(X) at the
optimum. Last row: training by regularizing the max-norm.

α
1
0.9
0.75
0.5
0
-1

kXkmax

tcα(X)

λ/|S|
0.05
0.07
0.2
0.5
2.5
450

k
4.34
30
4.27
30
5.04
30
7.32
30
10.36
30
30
11.41
30 mc(X) = 5.06

Test
0.7607
0.7573
0.7723
0.7823
0.7889
0.7913
0.7692

Qual
0.9105
0.9091
0.9128
0.9159
0.9235
0.9256
0.9131

tcα(X)

λ/|S|
0.08
0.1
0.3
0.8
3.0
700

k
5.47
100
5.23
100
6.24
100
9.65
100
21.23
100
100
23.31
100 mc(X) = 5.77

Test
0.7412
0.7389
0.7491
0.7613
0.7667
0.7713
0.7432

Qual
0.9071
0.9062
0.9098
0.9127
0.9203
0.9221
0.9092

For both k = 30 and k = 100  the weighted trace-norm (α = 1) signiﬁcantly outperformed the
unweighted trace-norm (α = 0). Interestingly  the optimal weighting (setting of α) was a bit lower
then  but very close to α = 1. For completeness  we also evaluated the weighting suggested by
Weimer et al. [21]  corresponding to α = −1. Unsurprising  given our analysis  this seemingly
intuitive weighting hurts predictive performance.

For both k = 30 and k = 100  we also observed that for the weighted trace-norm (α = 1) good
generalization is possible with a wide range of λ settings  while for the unweighted trace-norm
(α = 0)  the results were much more sensitive to the setting of λ. This conﬁrms our previous results
on the synthetic experiment and strongly suggests that it may be far easier to search for regularization
parameters using the weighted trace-norm.

Comparison with the Max-Norm
We also compared the predictive performance on Netﬂix to predictions based on max-norm regular-
ization. The max-norm is deﬁned as:

kXkmax = min

X=U ′V

1
2

(max

i kUik2 + max

j kVjk2).

(14)

Similarly to the rank  but unlike the trace-norm  generalization and learning guarantees based on the
max-norm hold also under an arbitrary  non-uniform  sampling distribution. Speciﬁcally  deﬁning
mc(X) = kXk2
max (no normalization is necessary here)  ˜O(mc(X)(n + m)) samples are enough for
generalization w.r.t. any sampling distribution (just like the rank) [18]. This suggests that perhaps the
max-norm can be used as an alternative factorization-regularization in the presence of non-uniform
sampling. Indeed  as evident in Table 1  max-norm based regularization does perform much better
then the unweighted trace-norm. The differences between the max-norm and the weighted trace-
norm are small  but it seems that using the weighted trace-norm is slightly but consistently better.

7 Summary
In this paper we showed both analytically and empirically that under non-uniform sampling  trace-
norm regularization can lead to signiﬁcant performance deterioration and an increase in sample
complexity. Our analytic analysis suggests a non-intuitive weighting for the trace-norm in order to
correct the problem. Our results on both synthetic and on the highly imbalanced Netﬂix datasets fur-
ther demonstrate that the weighted trace-norm yields signiﬁcant improvements in prediction quality.

In terms of optimization  we focused on stochastic gradient descent both since it is a simple and
practical method for very large-scale trace-norm optimization [15  8]  and since the weighting was
originally stumbled upon through this optimization approach. However  most recently proposed
methods for trace-norm optimization (e.g. [3  10  9  11  20]) can also be easily modiﬁed for the
weighted trace-norm.

We hope that the weighted trace-norm  and the discussions in Sections 3 and 4  will be helpful
in deriving theoretical learning guarantees for arbitrary non-uniform sampling distributions  both in
the form of generalization error bounds as in [18]  and generalizing the compressed-sensing inspired
work on recovery of noisy low-rank matrices as in [4  13].

Acknowledgments RS is supported by NSERC  Shell  and NTT Communication Sciences Laboratory.

8

References
[1] J. Abernethy  F. Bach  T. Evgeniou  and J.P. Vert. A new approach to collaborative ﬁlter-
ing: Operator estimation with spectral regularization. Journal of Machine Learning Research 
10:803–826  2009.

[2] S. Burer and R.D.C. Monteiro. Local minima and convergence in low-rank semideﬁnite pro-

gramming. Mathematical Programming  103(3):427–444  2005.

[3] J.F. Cai  E.J. Cand`es  and Z. Shen. A Singular Value Thresholding Algorithm for Matrix

Completion. SIAM Journal on Optimization  20:1956  2010.

[4] E.J. Candes and Y. Plan. Matrix completion with noise. Proceedings of the IEEE (to appear) 

2009.

[5] E.J. Candes and B. Recht. Exact matrix completion via convex optimization. Foundations of

Computational Mathematics  9  2009.

[6] E.J. Candes and T. Tao. The power of convex relaxation: Near-optimal matrix completion.

IEEE Trans. Inform. Theory (to appear)  2009.

[7] M. Fazel  H. Hindi  and S.P. Boyd. A rank minimization heuristic with application to minimum
order system approximation. In Proceedings American Control Conference  volume 6  2001.
[8] Yehuda Koren. Factorization meets the neighborhood: a multifaceted collaborative ﬁltering

model. In ACM SIGKDD  pages 426–434  2008.

[9] Z. Liu and L. Vandenberghe.

Interior-point method for nuclear norm approximation with
application to system identiﬁcation. SIAM Journal on Matrix Analysis and Applications 
31(3):1235–1256  2009.

[10] S. Ma  D. Goldfarb  and L. Chen. Fixed point and Bregman iterative methods for matrix rank

minimization. Mathematical Programming  pages 1–33  2009.

[11] R. Mazumder  T. Hastie  and R. Tibshirani. Spectral Regularization Algorithms for Learning

Large Incomplete Matrices. Journal of Machine Learning Research  11:2287–2322  2010.

[12] R. Meka  P. Jain  and I. S. Dhillon. Matrix completion from power-law distributed samples. In

Advances in Neural Information Processing Systems  volume 21  2009.

[13] B. Recht. A simpler approach to matrix completion. preprint  available from author’s webpage 

2009.

[14] J.D.M. Rennie and N. Srebro. Fast maximum margin matrix factorization for collaborative

prediction. In ICML  page 719  2005.

[15] Ruslan Salakhutdinov and Andriy Mnih. Probabilistic matrix factorization. In Advances in

Neural Information Processing Systems  volume 20  2008.

[16] N. Srebro  N. Alon  and T. Jaakkola. Generalization error bounds for collaborative prediction

with low-rank matrices. In Advances In Neural Information Processing Systems 17  2005.

[17] N. Srebro  J. Rennie  and T. Jaakkola. Maximum margin matrix factorization. In Advances In

Neural Information Processing Systems 17  2005.

[18] N. Srebro and A. Shraibman. Rank  trace-norm and max-norm. In COLT  2005.
[19] G´abor Tak´acs  Istv´an Pil´aszy  Botty´an N´emeth  and Domonkos Tikk. Scalable collaborative
ﬁltering approaches for large recommender systems. Journal of Machine Learning Research 
10:623–656  2009.

[20] R. Tomioka  T. Suzuki  M. Sugiyama  and H. Kashima. A fast augmented lagrangian algorithm

for learning low-rank matrices. In ICML  pages 1087–1094  2010.

[21] M. Weimer  A. Karatzoglou  and A. Smola. Improving maximum margin matrix factorization.

Machine Learning  72(3):263–276  2008.

9

,Haichao Zhang
David Wipf
Sainandan Ramakrishnan
Aishwarya Agrawal
Stefan Lee