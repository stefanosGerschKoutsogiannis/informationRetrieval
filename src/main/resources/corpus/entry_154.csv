2019,A Normative Theory for Causal Inference and Bayes Factor Computation in Neural Circuits,This study provides a normative theory for how Bayesian causal inference can be implemented in neural circuits. In both cognitive processes such as causal reasoning and perceptual inference such as cue integration  the nervous systems need to choose different models representing the underlying causal structures when making inferences on external stimuli. In multisensory processing  for example  the nervous system has to choose whether to integrate or segregate inputs from different sensory modalities to infer the sensory stimuli  based on whether the inputs are from the same or different sources. Making this choice is a model selection problem requiring the computation of Bayes factor  the ratio of likelihoods between the integration and the segregation models. In this paper  we consider the causal inference in multisensory processing and propose a novel generative model based on neural population code that takes into account both stimulus feature and stimulus reliability in the inference. In the case of circular variables such as heading direction  our normative theory yields an analytical solution for computing the Bayes factor  with a clear geometric interpretation  which can be implemented by simple additive mechanisms with neural population code. Numerical simulation shows that the tunings of the neurons computing Bayes factor are consistent with the "opposite neurons" discovered in dorsal medial superior temporal (MSTd) and the ventral intraparietal (VIP) areas for visual-vestibular processing. This study illuminates a potential neural mechanism for causal inference in the brain.,A Normative Theory for Causal Inference and Bayes

Factor Computation in Neural Circuits

wenhao.zhang@pitt.edu; siwu@pku.edu.cn; bdoiron@pitt.edu; tai@cnbc.cmu.edu

Wen-Hao Zhang1 2  Si Wu3  Brent Doiron2  Tai Sing Lee1

1Center for the Neural Basis of Cognition  Carnegie Mellon University.

2Department of Mathematics  University of Pittsburgh.

3School of Electronics Engineering & Computer Science  IDG/McGovern

Institute for Brain Research  Peking-Tsinghua Center for Life Sciences  Peking University.

Abstract

This study provides a normative theory for how Bayesian causal inference can
be implemented in neural circuits. In both cognitive processes such as causal
reasoning and perceptual inference such as cue integration  the nervous systems
need to choose different models representing the underlying causal structures
when making inferences on external stimuli.
In multisensory processing  for
example  the nervous system has to choose whether to integrate or segregate inputs
from different sensory modalities to infer the sensory stimuli  based on whether
the inputs are from the same or different sources. Making this choice is a model
selection problem requiring the computation of Bayes factor  the ratio of likelihoods
between the integration and the segregation models. In this paper  we consider
the causal inference in multisensory processing and propose a novel generative
model based on neural population code that takes into account both stimulus feature
and stimulus reliability in the inference. In the case of circular variables such as
heading direction  our normative theory yields an analytical solution for computing
the Bayes factor  with a clear geometric interpretation  which can be implemented
by simple additive mechanisms with neural population code. Numerical simulation
shows that the tunings of the neurons computing Bayes factor are consistent with
the "opposite neurons" discovered in dorsal medial superior temporal (MSTd) and
the ventral intraparietal (VIP) areas for visual-vestibular processing. This study
illuminates a potential neural mechanism for causal inference in the brain.

1

Introduction

Numerous psychological studies have demonstrated that perception can be formulated as Bayesian
inference of the underlying causes in the world that give rise to our sensations [1–6]. These causes
could be the sensory variables such as heading direction and orientation of edge  but often are causal
structures from which the observations are generated. In multisensory integration  as an example 
when we move around the world  the optical ﬂows we see and the vestibular signals we experience are
concordant. In this case  an integration model will be selected so that multiple cues can be weighed
and combined together to form a uniﬁed estimate of head direction of self-motion [7  8]. However 
when we wear a goggle to navigate in a virtual reality world while sitting on a spinning chair  the
visual and the vestibular signals would be quite discordant and it would be wrong to integrate them
during inference [9]. In this case  a segregation model should be selected so that each cue will remain
separated and their sources can be inferred independently. The selection of these models or latent
causal structures during inference is called causal inference [10  11].

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

Figure 1: The generative model of causal inference. (A) The generative model. The two sensory
cues are generated by the same stimulus in the integration model  while they are independently
generated by two different stimuli in the segregation model. Dashed circle: latent variables; solid
circle: cues (observations). (B) The likelihood function derived from neural population code. Each set
of stimulus parameters include the stimulus feature s (e.g.  motion direction) and the stimulus strength
R (e.g.  motion coherence). Each cue consists of observed direction x and observed spike count Λ
representing the input reliability. (C) A neural encoding model where the stimulus parameters w and
cues d are represented by the population ﬁring rate λ and observed spiking activities u respectively.

A number of psychological studies have suggested that our brains indeed perform causal inference as
an ideal observer (e.g.  [10  12–14]). However  it has been challenging to come up with a simple and
biologically plausible neural implementation for causal inference. This is because the computation
of Bayes factor  which is the ratio of likelihoods between models  requires nonlinear operations
including multiplication and division  while how these nonlinear operations could be implemented
by neural circuits remain a mystery [13–15]. Thus  while cue integration assuming the integration
model can be accomplished by an additive mechanism through linearly summing feedforward spiking
inputs in the framework of probabilistic population codes [16]  a neural model with similar additive
mechanisms for model selection has not been attained [15].
Here  we show that by incorporating stimulus strength or reliability R (e.g. motion coherence of the
visual cue  Fig. 1B) as a latent stimulus parameter to be inferred simultaneously with the stimulus
feature (e.g. heading direction) in a generative model  the Bayes factor can be computed by using
additive mechanism in a biologically plausible implementation. In this implementation  the neural
population activities representing the Bayes factor can be computed by simply summing the inputs
of one direction from one sensory modality with the inputs of the opposite direction from another
modality. We found the tunings of these neurons representing Bayes factor in the form of neural
population code are similar to the “opposite” neurons observed in MSTd and VIP whose preferred
heading directions from the visual and vestibular modalities are indeed opposite  shifted by 180
degrees (Fig. 3B-C  [8  17–19]). This work provides the ﬁrst theoretical justiﬁcation that the opposite
cells are computing and encoding Bayes factor  which is an essential step in causal inference. We
provide numerical simulation in support of this claim.

2 A Generative Model for Multisensory Processing

2.1 A probabilistic generative model

We study causal inference in the case of multisensory processing  an example of which is inferring
heading direction using visual and vestibular cues [8  19  20]. The two cues are denoted by D =
{dl}2
l=1  with l = 1  2 representing the visual and vestibular modality respectively. Each cue can
be regarded as the responses of uni-sensory neurons in visual or vestibular areas  which provide the
feedforward inputs to multisensory neurons in MSTd and VIP  respectively [8  19]. In practice  the
two cues can be generated by two different models M = {mint  mseg}  with each of them specifying
an underlying causal structure (Fig. 1A  [10  13  14]). Each model mh (h ∈ {int  seg}) has its
parameters Wh = {wlh}2
l=1  with wlh denoting the parameters of stimulus of sensory modality l.
Given a model (causal structure)  the two sensory cues are generated independently (since they are
generated and conveyed via different sensory pathways in the brain  Fig. 1A)  i.e. 

(1)

p(D|Wh  mh) =(cid:81)2

l=1 p(dl|wlh).

2

BCAu¸FiringrateFeedfwd. inputFeedfwd input u (Spike count)0246x (observed direction)¤ (amount of spikes)Poisson spike generatorFiring rate ¸(s R)Neuron index θ-1801800s (heading direction)R (motion coherence)xsR¤w1 segw2 segd1d2Segregration modelmsegStimulusparametersUnisensoryCuesIntegration modelmintMd = {x ¤}w = {s R}d1d2wint Model(causal structure)NeuralencodingIn the integration model mint  there is only one source in the world  so the features of stimuli in two
modalities are the same (Fig. 1A  [10  13  14  21])  and we denote as wint (cid:44) w1 int = w2 int. The
prior of parameter wint is assumed as a uniform distribution for simplicity 

p(wint|mint) = U(wint).

(2)
In the segregation model mseg  there are two independent sources (Fig. 1A). Thus  the stimulus
parameters in two modalities are independent with each other  and also satisfy the uniform distribution 
(3)
Notably  the two causal models are mutually exclusive to each other  in term of that only one of them
holds at a single moment. The prior of the two models are assumed to be the same 

p(w1 seg  w2 seg|mseg) = p(w1 seg|mseg)p(w2 seg|mseg) = U(w1 seg) U(w2 seg).

p(mint = 1) = p(mseg = 1) = 1/2.

Combing the likelihood and prior above  the whole generative process is summarized as 

p(D Wh  mh) = p(D|Wh  mh)p(Wh|mh)p(mh) 

(cid:26) p(d1|wint)p(d2|wint) 

mh = mint 
p(d1|w1 seg)p(d2|w2 seg)  mh = mseg.

∝

2.2 Neural population code

(4)

(5)

In the framework of neural population code [16  22]  the above generative model (Eq. 5) can be
described more speciﬁcally  which is a key step in linking abstract causal inference with neural circuit.
Consider that wl = {sl  Rl} are the stimulus parameters of modality l  which is the heading direction
(sl) and its reliability (Rl). The stimulus information is conveyed by the responses of N uni-sensory
neurons in modality l  denoted as ul = {ulj}N
j=1  which satisfy the Poisson statistics (Fig. 1C  [16]) 

p (ul|λlj(sl  Rl)) =(cid:81)N

j=1 Poisson(ulj|λlj) =(cid:81)N

j=1

λ

ulj
lj

ulj ! e−λlj  

(6)

where λlj is the ﬁring rate of neuron ulj and is a function of stimulus parameters sl and Rl 

λlj(sl  Rl) = Rl exp [a cos(sl − θj) − a]  

(7)
where θj is the preferred direction of neuron ulj  and a is the width of the tuning function. Here  we
assume that the stimulus reliability is encoded by the peak ﬁring rate of neurons [16  22].
Although the neuronal responses ul are high-dimensional  the likelihood function of the stimulus
parameters wl given ul can be fully speciﬁed by two one-dimensional variables (sufﬁcient statistics) 
which correspond to the readout (via population vector) of the direction (xl) from ul [23] and the
total spike count (Λl) 

(cid:16)(cid:80)

(cid:17)

= tan−1(cid:16)(cid:80)
(cid:80)

(cid:17)

  Λl =(cid:80)

j ulj sin θj
j ulj cos θj

xl = arg

j uljeiθj

(8)
The sufﬁcient statistics dl = {xl  Λl} correspond to the sensory cues in Eq. (1). The likelihood
function of stimulus parameter wl derived from neural population code is calculated to be (see details
in Supplementary Information (SI) 4) 

j ulj.

p (dl = {xl  Λl}|sl  Rl) = M (xl|sl  aρΛl) Poisson(Λl|βRl) 
∝ M (sl|xl  aρΛl) Γ(Rl|Λl + 1  β) 

(9)
where M(x)  Poisson(x) and Γ(x) denote a von Mises  a Poisson  and a Gamma distributions 
respectively. ρ and β represent the width of ul and the sum of normalized ﬁring rates  respectively
(see SI. 4). The priors of slh and Rlh are assumed to be independent with each other (Eq. 2)  i.e. 

U(wlh) = U(slh) U(Rlh) = (LsLR)−1 

(10)
where Ls and LR are the lengths of the spaces of s and R  respectively. For heading direction
s  Ls = 2π. Combining Eqs. (5  9 and 10) together  the generative model in the form of neural
population code is expressed as 

(cid:26) (cid:81)2
(cid:81)2
l=1 M (xl|sint  aρΛl) Poisson(Λl|βRint) 
mh = mint 
l=1 M (xl|sl seg  aρΛl) Poisson(Λl|βRl seg)  mh = mseg.

p(D Wh  mh) ∝

(11)

3

Figure 2: The geometric representation of Bayes factors. (A) The geometric representation of a von
Mises distribution where its mean and concentration can be represented by the angle and length of a
vector in a 2d plane respectively. (B) The geometric representation of the posterior of direction under
two models (Eq. 20) and the best-ﬁt likelihood ratios (Eq. 25) in Bayes factor. Bottom: the likelihood
ratios depends on the disparity of direction as well as strength. Dashed line: the radius of half blue
vector. (C) Evidence of integration and segregation models and Bayes factor with cue directions. (D)
The decision boundary with input spike count  where the spike count of two cues are always the same 
i.e.  Λ1 = Λ2. Parameters: Ls = 2π  LR = 100 Hz  a = 3 and N = 180. (C) Λ1 = Λ2 = 30.

Notably  the generative model considered in the present study (Eq. 9) includes explicitly the stimulus
strength R  which was treated as a “nuisance” parameter in previous studies (e.g.  [13–15]). We claim
that it is important for the neural system to exploit the disparity of the strength R of two stimuli to
perform causal inference. For example  when you are watching a shaky video (low motion coherence)
in virtual reality while you are walking straight ahead in real world (high reliability)  even if the
moving direction and the speed of optic ﬂow in virtual reality is the same as your actual walking  you
probably feel the optic ﬂow is not generated by your walking and even feel motion-sickness because
of the difference of motion coherence between visual and vestibular stimuli.

3 Bayesian Causal Inference

In order to interpret the world  the neural circuit needs to infer the underlying causal structure mh
based on sensory cues D (Fig. 1)  which can be achieved through estimating the posterior of each
model mh. Although the spike count Λl is observed  the neural circuit is assumed to be only interested
in the heading direction x = {x1  x2}  and evaluates each model’s feasibility by its performance in
explaining x. According to the Bayes’ theorem  the posterior of the integration model mint is 

(cid:20)

(cid:21)−1

p(mint|x) =

(cid:80)
p(x|mint)p(mint)
h p(x|mh)p(mh)

=

1 +

p(x|mseg)
p(x|mint)

 

(12)

Since there are only two models  it always has(cid:80)

where the condition that two models have the same prior is used (Eq. 4)  i.e.  p(mseg)/p(mint) = 1.
h p(mh|x) = 1  and knowing the posterior of one
model fully determines the posterior of another. From Eq. (12)  we see the key of causal inference is
to calculate the likelihood ratio between two models  which is called the Bayes factor [24  25] 

(13)
If the Bayes factor is less than 1  p(mint|x) > p(mseg|x) and the integration model is favoured;
otherwise the segregation model is chosen. The core of computing the Bayes factor is to evaluate

.

B(x) =

p(x|mseg)
p(x|mint)

4

CD-90090Log. of Model Evidence and Bayes Factor Direction disparity x1¡x2int.seg.seg.Int. model evidenceSeg. model evidenceBayes factor-40-20020int.seg.50100150Input spike count ¤ 0901800501001502002500Direction disparity jx1¡x2jLog. of Bayes factorB0.0050.010.01590° 270°180°0°M(60°;∙=3)M(0°;∙=6)Geometric representation of von Mises distributionsGeometric representation of stimulus estimate and Bayes factorL24660° 0AParameter space: p(sint|D mint): Likelihood ratio LR(xl): p(sl seg|D mseg)∙intejsintˆˆ∙lejx∙lpejxlpl0L∙1ejx1∙intejsint∙2ejx2∙2pejx2p∙1pejx1pˆˆ∙1pejx1pStrength Disparity |¤1¡¤2|Direction Disparity |x1¡x2|Likelihood ratio decomposition:direction and strength disparitythe evidence of each model p(x|mh)  which needs to marginalize the parameters Wh and the spike
counts Λ = {Λ1  Λ2} 

p(x|mh) =

p(x  Λ|Wh)p(Wh|mh)dWhdΛ 

(cid:39) p(x| ˆWh)

× p( ˆWh|mh) det(Hh/2π)− 1

2

 

(14)

(cid:123)(cid:122)

(cid:125)

(cid:124)

(cid:123)(cid:122)

(cid:125)

Best-ﬁt likelihood

Occam factor  OF(mh)

(cid:90) (cid:90)
(cid:124)

(15)

where the Laplace’s method is used to approximate the double integral (see SI. 2  [25  26])  which
works well when the spike counts Λ are sufﬁciently large (Fig. S1  see details in SI. 5). Computing
the evidence of each model needs to ﬁt the model to explain the sensory cues. Denote ˆWh =
{ˆslh  ˆRlh}2

l=1 the best-ﬁt parameters (the maximal posterior estimate) of model mh  i.e. 

p(x| ˆWh) =(cid:81)2

ˆWh = arg maxWh
l=1 p(xl| ˆwlh) (cid:39)(cid:81)2

p(Wh|D  mh).

The best-ﬁt likelihood of the observed direction x is given by (see details in SI. 5.3) 

l=1 M(xl|ˆslh  aρβ ˆRlh).
(16)
In Eq. (14)  Hh = −∇∇ ln p( ˆWh|D  mh) is the negative Hessian matrix of the logarithm of the
posterior p(Wh|D  mh)  reﬂecting the uncertainty of the inferred parameter Wh.
Note that causal inference (model selection) is not simply choosing a causal structure (model) which
best explains the observed direction x  since a complex model can always ﬁt the data well. An
over-parameterized model or a model requiring too much ﬁne-tuning will be rejected  and this is
captured by the Occam factor OF(mh) in Eq. (14). The Occam factor for a complex model is small 
since the probability of choosing a particular parameter value p( ˆWh|mh) is low due to the large
parameter space; and a ﬁne-tuned model has a large Hh  which also reduces the Occam factor [26].
In summary  Bayesian causal inference undergoes two levels of inference: the ﬁrst level is inferring
the best-ﬁt parameters ˆs and ˆR given each model (Eq. 15); and the second level is inferring the
models M by using the best-ﬁt parameters to evaluate each model’s performance  with the model
complexity penalized by the Occam factor (Eq. 14). In the section below  we presented how the two
levels of inference are performed.

3.1 Maximum posterior estimate of stimulus parameters

In the segregation model mseg  each cue dl is exclusively used to ﬁt the parameters wlh (Eq. 11) 

p(Wseg|D  mseg) ∝(cid:81)2

l=1 M(cid:0)sl seg|xl  κl (cid:44) aρΛl

(cid:1)Γ(Rl seg|Λl + 1  β) 

and the maximum-posterior estimates of the parameters are (see details in SI. 5.1) 

(17)

(18)
On the other hand  the integration model mint only has one set of parameters wint = {sint  Rint}
(Eq. 2)  whose estimate involves combining two cues together (Eq. 9) 

ˆRl seg = Λl/β.

ˆsl seg = xl 

p(wint|D  mint) ∝(cid:81)2

l=1 M(sint|xl  κl)Γ(Rint|Λl + 1  β) 

∝ M(sint|ˆsint  ˆκint)Γ(Rint|Λ1 + Λ2 + 1  2β).

(19)

(20)

The parameters ˆsint and ˆκint of the posterior of direction satisfy [27] (see details in SI. 5.2) 

ˆκintej ˆsint = κ1ejx1 + κ2ejx2 .

ˆsint = tan−1(cid:16) κ1 sin x1+κ2 sin x2

(cid:17)

Combining the above results (Eqs. 19-20)  the parameter estimates in the integration model are 

.

 

2β

ˆRint = Λ1+Λ2

κ1 cos x1+κ2 cos x2

(21)
It is worthy to note that there is a clear geometric interpretation of the parameters in the posterior of
direction s (Eqs. 17 and 19). The parameters of a von Mises distribution M(s|x  κ) can be represented
by the vector κejx in a two-dimensional parameter plane with its mean x and concentration κ
represented by the angle and length of the vector  respectively (Fig. 2A). Thus  the posterior of
direction in the segregation model (M(sl seg|xl  κl) in Eq. 17) can be represented by two green
vectors κlejxl in Fig. 2B. In comparison  since the integration model combines the two cues together 
the posterior of direction in the integration model can be represented by the blue vector in Fig. 2B 
which is the sum of the two green vectors (Eq. 20). The geometry in the parameter space shows that
the integration model accumulates the common information of two cues to estimate stimulus  and the
estimate of the integration model is always the consensus (reliability based average) of cues.

5

3.2 Occam factors of two models

OF(mseg) = 4 × OF(mint)2  OF(mint) = π[LsLR

The Occam factors of two models are (substituting Eqs. (18  21) into Eq. (14)  see SI. 5 for details) 
(22)
The OF(mseg) is smaller than OF(mint) by a order  because the number of parameters in the
segregation model is double that in the integration model. Moreover  the Occam factors of the two
models are invariant constants with input spikes Λl and direction xl  because the dependence of the
uncertainties of slh and Rlh on Λl cancel  which greatly simplify the neural implementation.

aρβ]−1.

√

3.3 The Bayes factor

Once the best-ﬁt stimulus parameters (Eqs. 18 and 21) and the Occam factors (Eq. 22) are obtained 
the Bayes factor determining two models can be calculated as a function of heading direction (Eq. 13) 

B(x) (cid:39) 2(cid:89)

l=1

M(xl|ˆsl seg  κl)
M(xl|ˆsint  ˆκint/2)

OF(mseg)
OF(mint)

=

LR(xl) × OFR 

(23)

2(cid:89)

l=1

where LR(xl) is the ratio of the best-ﬁt likelihoods of two models  and OFR = OF(mseg)/OF(mint)
is the Occam factor ratio which is a constant invariant to input (Eq. 22). In Eq. (23)  κl = aρβ ˆRl seg
(Eq. 17) and ˆκint/2 ≈ (κ1 + κ2)/2 = aρβ ˆRint due to |x1 − x2| (cid:28) min(κ1  κ2) (Eq. 20). Note that
the concentration of the best-ﬁt likelihood of the integration model  i.e.  ˆκint/2 in the denominator of
Eq. (23)  is half of the concentration of the posterior  i.e.  ˆκint in Eqs. (19-20). Intuitively  this is due
to that the integration model uses the two cues’ consensus (average) to explain each cue. When the
cues are from the same source  their consensus is similar with themselves statistically.
Since the Occam factor ratio OFR is a constant invariant with inputs  computing the dependency
of Bayes factor on inputs lies in the computation of likelihood ratio LR(xl). Notably  the ratio
between two circular distributions is still a circular distribution. Dividing by a circular distribution is
proportional to rotating the distribution to opposite direction and multiplying it (comparing the below
equation with Eq. 23)  i.e. 

LR(xl) ∝ M(xl|ˆsl seg  κl)M(xl|ˆsint + π  ˆκint/2) = A × M(xl|xlp  κlp) 

(24)
where A is the product of normalizing constants1. Using Eq. (20)  the parameters xlp and κlp of
LR(xl) are calculated as 

l(cid:48) = 3 − l.

κlpejxlp = (κlejxl − κl(cid:48)ejxl(cid:48) )/2 = [κlejxl + κl(cid:48)ej(xl(cid:48) +π)]/2 

(25)
Geometrically  the likelihood ratio parameters (xlp and κlp in Eqs. 24-25) correspond to the difference
between green vectors (the best-ﬁt likelihood of the segregation model) and half of the blue vector (the
best-ﬁt likelihood of the integration model)  and they are represented by two red vectors in Fig. 2B.
This geometrical relationship suggests that the likelihood ratio takes into account the disparities of
both direction |x1− x2| and strength |Λ1− Λ2| (Fig. 2B bottom)  and reﬂects how well the integration
model can explain the two cues  as the lengths of the red vectors increase with the cue disparity.
From the property of parallelogram  the two red vectors are always of the same length but point to
the opposite direction with each other  implying the parameters of the two likelihood ratios have the
same concentration  i.e.  κ1p = κ2p  but opposite means  i.e.  x2p = x1p + π.
Fig. 2 presents the results of model evidence and Bayes factor. The evidence of the segregation model 
p(x|mseg)  is a constant irrelevant of |x1 − x2| (Fig. 2C  blue line)  since each cue is independently ﬁt
by a parameter and hence the cues can always be perfectly ﬁt regardless of their disparity. However 
the segregation model is penalized by the Occam factor much more compared with the integration
model since it has more parameters (Eq. 22). In contrast  the integration model parsimoniously uses
the two cues’ consensus to explain cues  and hence its explanatory power  p(x|mint)  decreases
with the cue disparity (Fig. 2C  red line). In summary  the integration model will be favoured when
two cues are similar (Fig. 2C)  consistent with the intuition that cues from the same object will be
statistically more similar than cues from different objects (Fig. 1A) [12  13].
The spike counts Λ affects the integration probability indirectly through the estimate of R (Eqs. 18
and 21). When the spike counts of both cues are low  i.e.  noisy cues due to low motion coherence 

1A = 2πI0(ˆκint/2)I0(κlp)/I0(κl). I0(x) is the modiﬁed Bessel function of the ﬁrst kind and zero order.

6

Figure 3: Congruent and opposite neurons implement the integration and the Bayes factor respectively.
(A) The schematic of the network structure. Congruent (opposite) neurons receive the feedforward
inputs from two cues in a congruent (opposite) manner. Each circle represents a neuron where the two
arrows inside denotes its preferred directions under two sensory modalities  with the color specifying
the modality. (B) The tunings of an example congruent and opposite neuron in the network given
two sensory cues. For illustration  the strength of two cues is set to be different. (C) Tuning curves
of a congruent and an opposite neuron in both MSTd and VIP (adapted from [8]). (D) The number
of congruent and opposite neurons in MSTd and VIP (adapted from [17]). (E) The comparison
between the mean ˆsint and concentration ˆκint decoded from congruent neurons with the theoretical
predictions (Eq. 19). (F) The Bayes factors decoded from opposite neurons are compared with
theoretical prediction (Eq. 23). Parameters: (E-F) s1 = 0◦  s2 ∈ [0◦  20◦]  Rl ∈ [5  50]Hz.

the system tends to integrate two cues together to increase the conﬁdence of the stimulus estimate  so
the range of integration is large (Fig. 2D). In contrast  in the case of large spike counts  the estimate
of each cue is reliable enough even without integration  and the system can discriminate the disparity
between two cues clearly and the range of integration shrinks.

4 Neural Implementation of Causal Inference

We further explore how causal inference can be implemented in neural circuits. As described above 
causal inference involves two operations  estimating the best-ﬁt stimulus parameters of each model
(Eq. 15) and calculating the Bayes factor (Eq. 23). The neural system needs at least two populations
of neurons to implement each of them.

4.1 Congruent neurons responsible for cue integration

Since the estimate of the stimulus parameters in the segregation model is the same as the likeli-
hood (Eq. 18)  the feedforward inputs ul represents the estimate of the segregation model already.
The integration model combines two cues together. Following the idea of [16]  cue integration can
be achieved by a population of neurons which sum the feedforward inputs of two cues together (see
derivations in SI. 6.1). Denote the responses of these neurons by rc  we have 

rc(j) = u1(θj) + u2(θj) 

(26)
where ul(θj) denotes the input from modality l with preferred direction θj given cue l (Eq. 6). The
preferred direction of rc(j) under two cues are the same (Fig. 3B)  consistent with the tuning of
congruent neurons found in MSTd and VIP (Fig. 3C  [8  19])  which are known to be responsible for
cue integration [8  16  28].

4.2 Opposite neurons representing the Bayes factor

The core of computing Bayes factor is the likelihood ratio (Eq. 23)  because the Occam factor of two
models are both constants invariant with inputs (Eq. 22). Thus we consider another population of
neurons computing the likelihood ratio LR(xl) in Bayes factor. Since two likelihood ratios LR(xl)

7

40302010Firing rate (spikes s–1)00VestibularVisualHeading direction (°)602080400Number of Neurons9012018001020304050|∆ Preferred direction (°)|Visual vs. vestibularCongruent neuronOpposite neuronCongruentOppositeAB180°0°θθCue 1 (visual)Cue 2 (vestibular)Congruent neurons(integration)Opposite neurons(likelihood ratio)Opposite neuronCue direction (°)Firing rate (Hz)01020180-1800Cue 1Cue 2Congruent neuron0102030Firing rate (Hz)Cue direction (°)180-1800∙int from int. modelˆ∙int from cong. neuronsˆsint from cong. neuronssint from int. modelˆˆCDBayes factor B(x) (theory)Bayes factor B(x)(oppo. neurons)xlppop. vectorOpposite neuronsOccam factorratio (constant with input)∙lp-1801800Heading direction (°)-180180060EFTuning curvesExperimental evidenceIntegration by congruent neuronsNetwork structureDecode Bayes factor from opposite neuronsFeedfwd. input ulSignal flow1002003000100200300-2020406080-20020406080-50-5000505010010000are always opposite to each other  they can be parsimoniously represented by the same population of
neurons. Eqs. (24-25) reveal that the likelihood ratio is proportional to the product of two best-ﬁt
likelihoods but in the opposite manner. Analogous to the neural implementation of cue integration
(Eq. 19)  the ratio LR(x1) can be represented by another population of neurons averaging the two
feedforward inputs in an opposite manner (see details in SI. 6.2)  whose responses ro are given by 
(27)
The preferred direction of ro(j) under modality 1 is θj  but becomes θj + π under modality 2
(Fig. 3B). Experiments also found such kind of “opposite” neurons in MSTd and VIP whose preferred
directions are opposite in response to visual and vestibular cues (Fig. 3C  [8  19]). Note that the two
populations of neurons explicitly represent the distributions of stimulus direction  while the estimate
of stimulus strength ˆRint implicitly affects the total responses of opposite neurons as the average of
the two inputs (Eq. 27)  in contrast to congruent neurons which sum up two inputs (Eq. 26).

ro(j) = [u1(θj) + u2(θj + π)]/2.

4.3 Simulation results

We simulate a population of congruent neurons and a population of opposite neurons with equal
number  as found in the experiments (Fig. 3D  [17  18]). The congruent neurons’ responses rc sum
up the two feedforward inputs (two cues) together (Eq. 26)  while the opposite neurons’ responses
ro average the two feedforward inputs in an opposite manner (Eq. 27  Fig. 3A  see details in SI. 7).
We decode the mean and concentration of the heading direction from the congruent neurons rc via
population vector (Eq. 8  [23]) and compare the results with the posterior of direction derived from
theory (Eq. 20  see details in SI. 7). Meanwhile  we decode the mean and concentration from the
opposite neurons ro as the neurons’ estimate for x1p and κ1p  which are the parameters of LR(x1).
The parameters of LR(x2) can be obtained by using the relations x2p = −x1p and κ2p = κ1p 
because the two likelihood ratios have the same length but opposite direction (Fig. 2B). The Bayes
factor will be obtained by multiplying the decoded likelihood ratios from opposite neurons with the
constant Occam factor ratios (Eqs. 23-24). We then compare the decoded posteriors represented
by the congruent neurons  and the Bayes factor decoded from opposite neurons with theoretical
predictions (Fig. 3E-F). The results conﬁrm that the congruent neurons achieve cue integration  and
the opposite neurons compute and represent the likelihood ratio in the Bayes factor.

5 Conclusions and Discussions

This study develops a normative theory to address how causal inference can be implemented by
simple additive mechanisms in neural circuits  and demonstrate that the opposite neurons found in
MSTd and VIP could compute and represent the likelihood ratios in Bayes factor in a generative
model framework based on probabilistic population code. Our theory also provides a geometric
interpretation of causal inference which illuminates clearly how the Bayes factor and cue integration
depend on the input direction and strength. Compared to existing proposed complex neural circuits
for causal inference  our model is rather simple  relying only on an additive operation  and is hence
biologically more plausible. Notably  opposite neurons have been known for more than a decade  yet
their precise computational and functional roles remain unclear [17  19]. Here  our study suggests
that opposite neurons are responsible for implementing causal inference in neural systems.
Previous works exploring the implementation of causal inference in neural systems (e.g.  [15]) have
not associated their models with the neuronal properties found in the cortex. An important insight
from our study is that in computing Bayes factor  opposite neurons need to take into account not only
the difference in the heading directions  but also the difference in the stimulus strength or reliability
of signals  from the two sensory modalities (Fig. 2B)  which is an issue missed in the previous works
(e.g. [13  15]). Previous theoretical works also suggested that opposite neurons compute the ratio
between distributions [27  29]  but they consider the difference of the inferred common stimulus
direction sint from two cues  i.e.  the posterior ratio of the stimulus direction [29]. Here  we consider
the opposite neurons compute the difference of the reconstructions of the input x from two models 
i.e.  the ratio of best-ﬁt likelihoods (Eq. 14).
Nevertheless  we would like to point out that our theory on neural computation and representation of
Bayes factor in the current form only holds for circular variables  such as direction or orientation. How
the Bayes factor of a non-periodic variable  e.g.  depth or spatial location  are computed by neurons
remains unclear. Further experimental evidence for cue integration with non-periodic variables are

8

needed to address this issue. Furthermore  the present study mainly focuses on the computation of
Bayes factor  and how the neural system carries out the followed computations based on the inferred
causal structure has yet been explored  which forms our future research.

Acknowledgments

This work is supported by National Science Foundation (1816568)  Intelligence Advanced Research
Projects Activity (D16PC00007)  the National Institutes of Health (Grants 1U19NS107613-01
and R01EB026953)  the Vannevar Bush Faculty (Fellowship N00014-18-1-2002)  and the Simons
Foundation Collaboration on the Global Brain. We also thank Rob Kass and Xaq Pitkow for their
useful suggestions.

References
[1] Marc O Ernst and Heinrich H Bülthoff. Merging the senses into a robust percept. Trends in

Cognitive Sciences  8(4):162–169  2004.

[2] James J Clark and Alan L Yuille. Data Fusion for Sensory Information Processing Systems 

volume 105. Springer Science & Business Media  2013.

[3] Marc O Ernst and Martin S Banks. Humans integrate visual and haptic information in a

statistically optimal fashion. Nature  415(6870):429–433  2002.

[4] Konrad P Körding and Daniel M Wolpert. Bayesian integration in sensorimotor learning. Nature 

427(6971):244  2004.

[5] Robert A Jacobs. Optimal integration of texture and motion cues to depth. Vision Research 

39(21):3621–3629  1999.

[6] David Alais and David Burr. The ventriloquist effect results from near-optimal bimodal

integration. Current Biology  14(3):257–262  2004.

[7] RJV Bertin and A Berthoz. Visuo-vestibular interaction in the reconstruction of travelled

trajectories. Experimental Brain Research  154(1):11–21  2004.

[8] Yong Gu  Dora E Angelaki  and Gregory C DeAngelis. Neural correlates of multisensory cue

integration in macaque mstd. Nature Neuroscience  11(10):1201–1210  2008.

[9] Kalpana Dokka  Hyeshin Park  Michael Jansen  Gregory C DeAngelis  and Dora E Angelaki.
Causal inference accounts for heading perception in the presence of object motion. Proceedings
of the National Academy of Sciences  116(18):9060–9065  2019.

[10] Ladan Shams and Ulrik R Beierholm. Causal inference in perception. Trends in Cognitive

Sciences  14(9):425–432  2010.

[11] Judea Pearl et al. Causal inference in statistics: An overview. Statistics Surveys  3:96–146 

2009.

[12] Mark T Wallace  GE Roberson  W David Hairston  Barry E Stein  J William Vaughan  and
Jim A Schirillo. Unifying multisensory signals across time and space. Experimental Brain
Research  158(2):252–258  2004.

[13] Konrad P Körding  Ulrik Beierholm  Wei Ji Ma  Steven Quartz  Joshua B Tenenbaum  and

Ladan Shams. Causal inference in multisensory perception. PLoS One  2(9):e943  2007.

[14] Yoshiyuki Sato  Taro Toyoizumi  and Kazuyuki Aihara. Bayesian inference explains perception
of unity and ventriloquism aftereffect: identiﬁcation of common sources of audiovisual stimuli.
Neural Computation  19(12):3335–3355  2007.

[15] Wei Ji Ma and Masih Rahmati. Towards a neural implementation of causal inference in cue

combination. Multisensory Research  26(1-2):159–176  2013.

[16] Wei Ji Ma  Jeffrey M Beck  Peter E Latham  and Alexandre Pouget. Bayesian inference with

probabilistic population codes. Nature Neuroscience  9(11):1432–1438  2006.

9

[17] Yong Gu  Paul V Watkins  Dora E Angelaki  and Gregory C DeAngelis. Visual and nonvisual
contributions to three-dimensional heading selectivity in the medial superior temporal area. The
Journal of Neuroscience  26(1):73–85  2006.

[18] Aihua Chen  Gregory C DeAngelis  and Dora E Angelaki. Representation of vestibular
and visual cues to self-motion in ventral intraparietal cortex. The Journal of Neuroscience 
31(33):12036–12052  2011.

[19] Aihua Chen  Gregory C DeAngelis  and Dora E Angelaki. Functional specializations of the
ventral intraparietal area for multisensory heading discrimination. The Journal of Neuroscience 
33(8):3567–3581  2013.

[20] Christopher R Fetsch  Gregory C DeAngelis  and Dora E Angelaki. Bridging the gap between
theories of sensory cue integration and the physiology of multisensory neurons. Nature Reviews
Neuroscience  14(6):429–442  2013.

[21] David R Wozny  Ulrik R Beierholm  and Ladan Shams. Probability matching as a computational

strategy used in perception. PLoS computational biology  6(8):e1000871  2010.

[22] Peter Dayan and Laurence F Abbott. Theoretical Neuroscience  volume 806. Cambridge  MA:

MIT Press  2001.

[23] Apostolos P Georgopoulos  Andrew B Schwartz  and Ronald E Kettner. Neuronal population

coding of movement direction. Science  233(4771):1416–1419  1986.

[24] Robert E Kass and Adrian E Raftery. Bayes factors. Journal of the American Statistical

Association  90(430):773–795  1995.

[25] Christopher M Bishop. Pattern Recognition and Machine Learning. Springer  2006.

[26] David JC MacKay.

Information theory  Inference and Learning Algorithms. Cambridge

university press  2003.

[27] Wen-Hao Zhang  He Wang  KY Michael Wong  and Si Wu. “congruent” and “opposite”
neurons: Sisters for multisensory integration and segregation. In Advances in Neural Information
Processing Systems  pages 3180–3188  2016.

[28] Wen-Hao Zhang  Aihua Chen  Malte J Rasch  and Si Wu. Decentralized multisensory informa-

tion integration in neural systems. The Journal of Neuroscience  36(2):532–547  2016.

[29] Wen-Hao Zhang  He Wang  Aihua Chen  Yong Gu  Tai Sing Lee  KY Michael Wong  and Si Wu.
Complementary congruent and opposite neurons achieve concurrent multisensory integration
and segregation. eLife  8:e43753  2019.

10

,Wenhao Zhang
Si Wu
Brent Doiron
Tai Sing Lee