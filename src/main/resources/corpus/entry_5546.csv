2018,Thermostat-assisted continuously-tempered Hamiltonian Monte Carlo for Bayesian learning,In this paper  we propose a novel sampling method  the thermostat-assisted continuously-tempered Hamiltonian Monte Carlo  for the purpose of multimodal Bayesian learning. It simulates a noisy dynamical system by incorporating both a continuously-varying tempering variable and the Nos\'e-Hoover thermostats. A significant benefit is that it is not only able to efficiently generate i.i.d. samples when the underlying posterior distributions are multimodal  but also capable of adaptively neutralising the noise arising from the use of mini-batches. While the properties of the approach have been studied using synthetic datasets  our experiments on three real datasets have also shown its performance gains over several strong baselines for Bayesian learning with various types of neural networks plunged in.,Thermostat-assisted continuously-tempered

Hamiltonian Monte Carlo for Bayesian learning

Rui Luo1  Jianhong Wang∗1  Yaodong Yang∗1  Zhanxing Zhu2  and Jun Wang†1

1University College London  2Peking University

Abstract

We propose a new sampling method  the thermostat-assisted continuously-tempered
Hamiltonian Monte Carlo  for Bayesian learning on large datasets and multimodal
distributions. It simulates the Nosé-Hoover dynamics of a continuously-tempered
Hamiltonian system built on the distribution of interest. A signiﬁcant advantage of
this method is that it is not only able to efﬁciently draw representative i.i.d. samples
when the distribution contains multiple isolated modes  but capable of adaptively
neutralising the noise arising from mini-batches and maintaining accurate sampling.
While the properties of this method have been studied using synthetic distributions 
experiments on three real datasets also demonstrated the gain of performance over
several strong baselines with various types of neural networks plunged in.

Introduction

1
Bayesian learning via Markov chain Monte Carlo (MCMC) methods is appealing for its inborn nature
of characterising the uncertainty within the learnable parameters. However  when the distributions of
interest contain multiple modes  rapid exploration on the corresponding multimodal landscapes w.r.t.
the parameters becomes difﬁcult using classic methods [7  16]. In particular  given a large number of
modes  some “distant” ones might be beyond the reach from others; this would potentially lead to the
so-called pseudo-convergence [1]  where the guarantee of ergodicity for MCMC methods breaks.
To make things worse  Bayesian learning on large datasets is typically conducted in an online setting:
at each of the iterations  only a subset  i.e. a mini-batch  of the dataset is utilised to update the model
parameters [24]. Although the computational complexity is substantially reduced  those mini-batches
inevitably introduce noise into the system and therefore increase the uncertainty within the parameters 
making it harder to properly sample multimodal distributions.
In this paper  we propose a new sampling method  referred to as the thermostat-assisted continuously-
tempered Hamiltonian Monte Carlo  to address the aforementioned problems and to facilitate Bayesian
learning on large datasets and multimodal posterior distributions. We extend the classic Hamiltonian
Monte Carlo (HMC) with the scheme of continuous tempering stemming from the recent advances in
physics [8] and chemistry [15]. The extended dynamics governs the variation on effective temperature
for the distribution of interest in a continuous and systematic fashion such that the sampling trajectory
can readily overcome high energy barriers and rapidly explore the entire parameter space. In addition
to tempering  we also introduce a set of Nosé-Hoover thermostats [18  11] to handle the noise arising
from the use of mini-batches. The thermostats are integrated into the tempered dynamics so that the
mini-batch noise can be effectively recognised and automatically neutralised. In short  the proposed
method leverages continuous tempering to enhance the sampling efﬁciency  especially for multimodal
distributions; it makes use of Nosé-Hoover thermostats to adaptively dissipate the instabilities caused
by mini-batches so that the desired distributions can be recovered. Various experiments are conducted
to demonstrate the effectiveness of the new method: it consistently outperforms several samplers and
optimisers on the accuracy of image classiﬁcation with different types of neural network.

∗Equal
†Correspondence to: j.wang@cs.ucl.ac.uk

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

2 Preliminaries

We review HMC [6] and continuous tempering [8  15]  the two bases of our model  where the former
serves as a de facto standard for Bayesian sampling and the latter is a state-of-the-art solution to the
acceleration of molecular dynamics simulations on complex physical systems.

2.1 Hamiltonian Monte Carlo for posterior sampling
Bayesian posterior sampling aims at efﬁciently generating i.i.d. samples from the posterior ρ(θ| (cid:68)) of
the variable of interest θ given some dataset (cid:68). Provided the prior ρ(θ) and the likelihood (cid:76)(θ; (cid:68))
along with the dataset (cid:68) = {xi} with | (cid:68)| independent data points xi  the target posterior to generate
samples from can be formulated as

ρ(θ| (cid:68)) ∝ ρ(θ)(cid:76)(θ; (cid:68)) = ρ(θ)

(cid:96)(θ; xi)  with the likelihood per data point (cid:96)(θ; xi).

(1)

| (cid:68)|

i

In a typical HMC setting [16]  a physical system is constructed and connected with the target posterior
in Eq. (1) via the system’s potential  which is deﬁned as

| (cid:68)|

i=1

U(θ) = − log ρ(θ| (cid:68)) = − log ρ(θ) −

log (cid:96)(θ; xi) − const .

(2)

In this system  the variable of interest θ ∈ R D  referred to as the system conﬁguration  is interpreted
as the joint position of all physical objects within that system. An auxiliary variable pθ ∈ R D is then
introduced as the conjugate momentum w.r.t. θ to describe its rate of change. The tuple Γ = (θ pθ)
represents the state of the physical system that uniquely determines the characteristics of that system.
A predeﬁned constant matrix Mθ = diag[mθi] speciﬁes the masses of the objects associated with θ
and can be leveraged for preconditioning.
The energy function H(Γ) of the physical system  referred to as the Hamiltonian  is essentially the sum
of the potential in Eq. (2) and the conventional quadratic kinetic energy: H(Γ) = U(θ) + p(cid:62)
θ pθ/2.
The Hamiltonian dynamics  i.e. the Hamilton’s equations of motion  can be derived by applying the
Hamiltonian formalism [(cid:219)θ = ∂pθ H  (cid:219)pθ
= −∂θH] to H(Γ)  where (cid:219)θ and (cid:219)pθ denote the time derivatives.
The Hamiltonian dynamics  on one hand  describes the time evolution of system from a microscopic
perspective. The principle of statistical physics  on the other hand  states in a macroscopic sense that
given a physical system in thermal equilibrium with a heat bath at a ﬁxed temperature T  the states Γ
of that system are distributed as a particular distribution related to the system’s Hamiltonian H(Γ):

ZΓ(T) e−H(Γ)/T  with the normalising constant ZΓ(T) =

(3)
Such distribution is referred to as the canonical distribution. Note that by setting T = 1 and U(θ) as
in Eq. (2)  the canonical distribution in Eq. (3) can be marginalised as the posterior in Eq. (1).

e−H(Γ)/T .

π(Γ) =

θ M−1

1

Γ

2.2 Continuous tempering

In physical chemistry  continuous tempering [8  15] is currently a state-of-the-art method to accelerate
molecular dynamics simulations by means of continuously and systematically varying the temperature
of a physical system. It extends the original system by coupling with additional degrees of freedom 
namely the tempering variable ξ ∈ R with mass mξ as well as its conjugate momentum pξ ∈ R  which
control the effective temperature of the original system in a continuous fashion via the Hamiltonian
dynamics of the extended system. With a suitable choice of coupling function λ(ξ) and a compatible
conﬁning potential W(ξ)  the Hamiltonian of the extended system can be designed as

H(Γ) = λ(ξ)U(θ) + W(ξ) + p(cid:62)

θ M−1

θ pθ/2 + p2

ξ/2mξ 

(4)
where Γ = (θ  ξ pθ  pξ) represents the state of the extended system with the position of the tempering
variable ξ and its momentum pξ appended to the state of the original system (θ pθ). λ(ξ) ∈ R+ maps
the tempering variable to a multiplier of temperature so that the effective temperature of the original
system T/λ(ξ) can vary; its domain domλ(ξ) ⊂ R is a ﬁnite interval regulated by W(ξ).

2

3 Thermostat-assisted continuously-tempered Hamiltonian Monte Carlo

We propose a sampling method  called the thermostat-assisted continuously-tempered Hamiltonian
Monte Carlo (TACT-HMC)  for multimodal posterior sampling in the presence of unknown noise.
TACT-HMC leverages the extended Hamiltonian in Eq. (4) to raise and vary the effective temperature
continuously; it efﬁciently lowers the energy barriers between modes and hence accelerates sampling.
Our method also incorporates the Nosé-Hoover thermostats to effectively recognise and automatically
neutralise the noise arising from the use of mini-batches.

3.1 System dynamics with the Nosé-Hoover augmentation

|(cid:83)|

log (cid:96)(θ; xik)

In solving for the system dynamics  we apply the Hamiltonian formalism to the extended Hamiltonian
in Eq. (4)  which requires the potential U(θ) and gradient ∇θU(θ). We deﬁne hereafter the negative
gradient of the potential U(θ) as the induced force f(θ) = −∇θU(θ). Because the calculation of either
U(θ) or f(θ) involves the full dataset (cid:68) = {xi}  it is computationally expensive or even unaffordable
to calculate the actual values for large | (cid:68)|. Instead  we consider the mini-batch approximations:
˜U(θ) = − log ρ(θ) − | (cid:68)|
∇θ log (cid:96)(θ; xik) 
|(cid:83)|
where xik denotes the data point sampled from mini-batches (cid:83) = {xik} ⊂ (cid:68) with the size |(cid:83)| (cid:28) | (cid:68)|.
It is clear that ˜U(θ) and ˜f(θ) are unbiased estimators of U(θ) and f(θ).
As we assume xik to be mutually independent  ˜U(θ) and ˜f(θ) are sums of |(cid:83)| i.i.d. random variables 
where the Central Limit Theorem (CLT) applies; the mini-batch approximations converge to Gaussian
variables  i.e. ˜U(θ) → (cid:78)(U(θ)  vU(θ)) and ˜f(θ) → (cid:78)(f(θ) V f (θ)) with variances vU(θ) and V f (θ).
As random variables  ˜U(θ) and ˜f(θ) inevitably inject noise into the system dynamics. We incorporate a
set of independent Nosé-Hoover thermostats [18  11] – apparatuses originally devised for temperature
stabilisation in molecular dynamics simulations – to adaptively cancel the effect of noise. The system
dynamics with the augmentation of thermostats – we call Nosé-Hoover dynamics – is formulated as

˜f(θ) = ∇θ log ρ(θ) +

|(cid:83)|

| (cid:68)|
|(cid:83)|

and

k=1

k=1

ds

(cid:104)i  j(cid:105)
θ
dt

dpθ
dt

dθ
dt

dξ
dt

 

 

=

=

=

κξ

(5)

(cid:3)

ξ
mξ

− T

pξ
mξ

(cid:104)i  j(cid:105)
θ

θ pθ 

dsξ
dt

= −λ

dpξ
dt

− T δi j

= M−1

= λ(ξ)˜f(θ) − λ2(ξ)Sθpθ 

(cid:21)
where Sθ and sξ denote the Nosé-Hoover thermostats coupled with θ and ξ. Speciﬁcally  Sθ =(cid:2)s

(cid:48)(ξ) ˜U(θ) − W(cid:48)(ξ) −(cid:2)λ

(cid:48)(ξ)(cid:3)2sξ pξ 

and κξ are constants that denote the “thermal inertia” corresponding to s

(cid:104)i  j(cid:105)
θ
is a D × D matrix with the (i  j)-th elements s
dependent upon the multiplicative term pθi pθ j/mθi .
(cid:104)i  j(cid:105)
and sξ  respectively.
κ
θ
Intuitively  the thermostats Sθ and sξ act as negative feedback controllers on the momenta pθ and pξ.
ξ/mξ exceeds the reference T  the thermostat sξ will
Consider the dynamics of sξ in Eq. (5)  when p2
increase  leading to a greater friction −sξ pξ in updating pξ; the friction in turn reduces the magnitude
ξ/mξ. The negative feedback loop is thus established.
of pξ  resulting in a decrease in the value of p2
With the help of thermostats  the noise injected into the system can be adaptively neutralised.

We deﬁne the diffusion coefﬁcients bU(θ) (cid:66) vU(θ) dt/2 and B f (θ) =(cid:2)b

(θ)(cid:3) (cid:66) V f (θ) dt/2 such

that the variances vU(θ) and V f (θ) of the mini-batch approximations evaluated at each of the discrete
iterations can be embedded in the Fokker-Planck equation (FPE) [20] established in continuous time.
FPE translates the microscopic motion of particles  formulated by SDEs  into the macroscopic time
evolution of the state distribution in the form of PDEs. With FPE leveraged  we establish the theorem
as follows to characterise the invariant distribution:
Theorem 1. The system governed by the dynamics in Eq. (5) has the invariant distribution:

(cid:104)i  j(cid:105)
θ

(cid:104)i  j(cid:105)
f

(cid:20) pθi pθ j
(cid:2)λ(cid:48)(ξ)(cid:3)2
(cid:20) p2

λ2(ξ)
(cid:104)i  j(cid:105)
κ
θ

mθi

(cid:21)

 

(cid:20)

(cid:16)

(cid:17)2

κξ/2 + 

(cid:32)

(cid:104)i   j(cid:105)
θ

s

− b

(cid:104)i   j(cid:105)
f
mθ j

(θ)
T

i   j

(cid:104)i   j(cid:105)
θ

κ

(cid:33)2

(cid:21)(cid:46)

(cid:14)2

π(Γ Sθ  sξ) ∝ e

−

H(Γ) +

sξ− bU (θ)

mξ T

T

 

(6)

where Γ = (θ  ξ pθ  pξ) denotes the extended state as presented in Eq. (4).

3


(cid:21)
·(cid:104)

π

(cid:21)

(cid:35)

i  j

ds

(cid:105) −
(cid:34)(cid:2)λ(cid:48)(ξ)(cid:3)2
(cid:21)

κξ

Proof. Recall FPE in its vector form [20]:

·(cid:104)

µx(x  t)π(x  t)(cid:105)

(cid:20) ∂

∂(cid:62)
∂x

(cid:21)

·(cid:104)Bx(x  t)π(x  t)(cid:105)

∂

∂t π(x  t) = − ∂
∂x

 

+

∂x

(7)
where x = vec(Γ Sθ  sξ) denotes the vectorisation of the collection of all variables deﬁned in Eq. (6) 
µx and Bx represent the drift and diffusion terms associated with the dynamics in Eq. (5)  respectively 
and the dot operator · deﬁnes the composition of summation after element-wise multiplication.
We substitute the corresponding elements within Eq. (5) into the drift and diffusion of FPE in Eq. (7).
As we presume that the introduced thermostats are mutually independent with each other  the invariant
distribution can hence be factorised into marginals as π(x) = πΓ πsξ
. It is straightforward
to verify that those deterministic parts with the dependency only on Γ cancel exactly with each other.
The remnants are the stochastic parts as well as the deterministic ones that depend on the thermostats
Sθ and sξ  which can be formulated as

i  j πs

(cid:104)i   j(cid:105)
θ

(cid:104)(cid:2)λ

(cid:48)(ξ)(cid:3)2sξ pξ π
(cid:105) − ∂

λ2(ξ)Sθpθ π

∂

∂t π(x  t) =

∂
∂pξ

·(cid:104)

∂
∂pθ

(cid:34)

λ2(ξ)
(cid:104)i  j(cid:105)
κ
θ

(cid:21)

− T

π

∂
(cid:104)i  j(cid:105)
θ

(cid:20) p2

ξ
mξ

(cid:20) pθi pθ j
(cid:35)
(cid:20) ∂

mθi

+

− T δi j

∂(cid:62)
∂pθ

+

∂2
∂pξ

(cid:104)(cid:2)λ

(cid:105)

(cid:48)(ξ)(cid:3)2bU(θ)π
(cid:105)

λ2(ξ)B f (θ)π

.

+

∂sξ

(cid:20)

∂pθ

(8)
We solve for the invariant distribution π(x) by equating Eq. (8) to zero. The resulted formulae for the
marginals πsξ and πs

are obtained under the assumption of factorisation in the form of
(cid:104)i  j(cid:105)
(θ)
f
mθ jT

∂πs
1
(cid:104)i   j(cid:105)
πs
∂s
θ
The solutions to Eq. (9) are clear: both πsξ and πs
are Gaussian distributions determined uniquely
(cid:104)i   j(cid:105)
  along with the canonical distribution πΓ w.r.t. H(Γ) 
θ
by the coefﬁcients. The marginals πsξ and πs
(cid:3)
constitute the invariant distribution deﬁned in Eq. (6).

sξ − bU(θ)

(cid:104)i   j(cid:105)
θ
= − κξ
T

(cid:104)i   j(cid:105)
θ
(cid:104)i  j(cid:105)
θ

(cid:104)i  j(cid:105)
θ
T

∂πsξ
∂sξ

= − κ

1
πsξ

(cid:104)i  j(cid:105)
θ

− b

mξT

(cid:104)i   j(cid:105)
θ

and

(cid:20)

(cid:21)

(9)

s

.

Theorem 1 states that  when the system reaches equilibrium  the system state is distributed as Eq. (6) 
and the mini-batch noise is absorbed into the thermostats from the system dynamics in Eq. (5). Thus 
we can marginalise out both Sθ and sξ to drop the noise  and then obtain the canonical distribution in
Eq. (3). As we are seeking for the recovery of the target posterior from the canonical distribution  we
can assign speciﬁc values to the tempering variable ξ = ξ∗ such that the effective temperature of the
original system is held ﬁxed at unity T/λ(ξ∗) = 1. Hence  the posterior ρ(θ| (cid:68)) equals to the marginal
distribution w.r.t. θ given ξ∗ satisfying λ(ξ∗) = T  which is obtained by the marginalisation of pθ and
pξ over the canonical distribution as follows:

∗) = 

pθ  pξ

π(θ|ξ

π(Γ|ξ

∗) =

pθ  pξ e−H(Γ| ξ∗)/T
Γ\ξ e−H(Γ| ξ∗)/T



=

1
Zθ(T) e−U(θ) = ρ(θ| (cid:68)) 

e−U(θ)
θ e−U(θ) =
ξ/2mξ represents the extended Hamiltonian

where H(Γ|ξ∗) = λ(ξ∗)U(θ) + W(ξ∗) + p(cid:62)
conditioning on the tempering variable ξ = ξ∗  when λ(ξ∗) = T holds.

θ pθ/2 + p2

θ M−1

3.2 Tempering enhancement via adaptive biasing force

A necessary condition for the tempering scheme to be well-functioning is that the tempering variable
ξ can properly explore the majority of the domain of the coupling function domλ(ξ); this ensures the
expected variation on the effective temperature during sampling. For complex systems  however  it is
often the case that the tempering variable is subject to a strong instantaneous force that prevents ξ
from proper exploration of domλ(ξ) and therefore hinders the efﬁciency of tempering. The adaptive
biasing force (ABF) algorithm [3] has emerged as a promising solution to such problem ever since its
inception [4]  where it was introduced to address the problem on fast calculation of the free energy of
complex chemical or biochemical systems. Intuitively  ABF maintains and updates an estimate of the
average force  i.e. the average of the instantaneous force exerted on the target variable. It then applies
the estimate to the target variable in the opposite direction to counteract the instantaneous force and
reduce it into small zero-mean ﬂuctuations so that the variable undergoes random walks.

4

thermal inertia γθ  γξ; # of steps for unit interval K

ξ

− ηξ

(cid:3)(cid:14)γξ

(zθ  zξ) ← (cθ  cξ)

θ rθ j/dim(rθ) − ηθ

level of injected noise cθ  cξ;

δA ← abf[ ABFINDEXING( ξ ) ]

δλ ← LAMBDADERIVATIVE( ξ )

(cid:83)← NEXTBATCH( (cid:68)  k );
˜U ← MODELFORWARD( θ  (cid:83));

zξ ← zξ + δλ2(cid:2)r2
(cid:3)(cid:14)γθ
zθ ← zθ + λ2(cid:2)r(cid:62)
rξ ← rξ − δλ(cid:2)ηξ ˜U + (cid:78)(0 2cξ ηξ)(cid:3) − δλ2zξrξ + ηξ δA
rθ ← rθ + λ(cid:2)ηθ ˜f + (cid:78)(0 2cθ ηθI)(cid:3) − λ2zθrθ

Algorithm 1 Thermostat-assisted continuously-tempering Hamiltonian Monte Carlo
Input: stepsize ηθ  ηξ;
1: rθ ∼ (cid:78)(0  ηθI) and rξ ∼ (cid:78)(0  ηξ);
2: INITIALISE( θ  ξ  abf  samples )
3: for k = 1 2 3  . . . do
λ ← LAMBDA( ξ );
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
APPEND( samples  θ )
17:
rθ ∼ (cid:78)(0  ηθI) and rξ ∼ (cid:78)(0  ηξ)
18:
19: function ABFUPDATE( abf  ξ  δλ  ˜U  k )
20:
21:

ABFUPDATE( abf  ξ  δλ  ˜U  k )
ξ ← ξ + rξ
if ISINSIDEWELL( ξ ) = false then
θ ← θ + rθ
if k = 0 mod K and λ = 0 then

j ← ABFINDEXING( ξ )
abf[ j ] ← [1 − 1/k]abf[ j ] + [1/k]δλ · ˜U

˜f ← MODELBACKWARD( θ  (cid:83))

ξ ← ξ + rξ

rξ ← −rξ;

(cid:46) ξ is restricted by the well of inﬁnite height.
(cid:46) ξ bounces back when hitting the wall.

(cid:46) θ is collected as a new sample in samples.
(cid:46) rθ rξ is optionally resampled.

(cid:46) ξ is mapped to the index j of the associated bin.

Γ\ξ

(10)

∂ξ

(cid:66)

.

∂ξ

dpξ

dπ
dξ

=

Implementation

A(cid:48)(ξ) = − T
π(ξ)

(cid:14) dt = −λ

Formally  the function of free energy w.r.t. ξ is deﬁned by convention in the form of

A(ξ) = −T log π(ξ) + const  where π(ξ) =
(cid:48)(ξ)(cid:3)2sξ pξ 
(cid:48)(ξ) ˜U(θ) − W(cid:48)(ξ) + A(cid:48)(ξ) −(cid:2)λ
π(Γ) with the extended state Γ = (θ  ξ pθ  pξ).
(cid:2) ∂H
(cid:3)e−H(Γ)/T
Γ\ξ
(cid:12)(cid:12)(cid:12)(cid:12)ξ
(cid:28) ∂H
(cid:29)
Γ\ξ e−H(Γ)/T

The equation of pξ in Eq. (5) is then augmented with the derivative of A(ξ) such that
where A(cid:48)(ξ) is referred to as the adaptive biasing force induced by the free energy as

(11)
The brackets (cid:104)·|ξ(cid:105) denote the conditional average  i.e. the average on the canonical distribution π(Γ)
with ξ held ﬁxed. A(cid:48)(ξ) is the average of the reversed instantaneous force on ξ. It is proved [14] that
ABF converges to the equilibrium at which ξ’s free energy landscape is ﬂattened  even though the
augmentation in Eq. (10) alters the equations of motion originally deﬁned in Eq. (5).
3.3
As proved in Theorem 1  the dynamics in Eq. (5) is capable of preserving the correct distribution in
the presence of noise. In principle  it requires the thermostat Sθ to be of size D2 for the D-dimensional
parameter θ; however  the storage is unaffordable for complex models in high dimensions. A plausible
option to mitigate this issue is to assume homogeneous θ and isotropic Gaussian noise such that the
mass Mθ = mθI and the variance V f (θ) = v f (θ)I; this simpliﬁes the high-dimensional Sθ to scalar sθ.
The conﬁning potential W(ξ) that determines the range of the tempering variable ξ is implemented as
a well of inﬁnite height. When colliding with the boundary of W(ξ)  ξ bounces back elastically with
the velocity reversed. The Euler’s method is then applied such that dt → ∆t.
In Eq. (11)  the calculation of A(cid:48)(ξ) involves the ensemble average (cid:104)∂H/∂ξ|ξ(cid:105)  hence being intractable.
∂H/∂ξ|ξk   which is equivalent to the ensemble average
in the long-time limit under the assumption of ergodicity; it can be readily calculated in a recurrent
form during sampling. To maintain the runtime estimates of A(cid:48)(ξ)  the range of ξ is divided uniformly
into J bins of equal length with memory initialised in each of those bins. At each time step k  ABF
determines the index j of the bin in which the tempering variable ξ = ξk is currently located  and then
updates the time average using the record in memory and the current force ∂H/∂ξ|ξk evaluated at ξk.
With all components assembled  we establish the TACT-HMC algorithm as Algorithm. 1 with
κθ
mθ D   γξ =

Here we instead calculate the time average

  zθ = sθ ∆t  zξ = sξ ∆t  ηθ =

pθ ∆t
mθ

pξ ∆t
mξ

∆t2
mθ

∆t2
mξ

  rξ =

  ηξ =

  γθ =

applied as the change of variables for the convenience of implementation. Furthermore  we introduce
additional Gaussian noises (cid:78)(0 2cξ ηξ) and (cid:78)(0 2cθ ηθI) in momenta updates to improve ergodicity.

κξ
mξ

rθ =

k

5

(a) Histograms of samples generated by TACT-HMC and the ablated alternatives  with the target shown in blue.

(b) I: Sampling trajectory of TACT-HMC  demonstrating robust mixing property; II: Cumulative averages of
thermostats  indicating fast convergence to the theoretical reference values drawn by red lines; III: Histograms of
sampled thermostats  showing a good ﬁt to the theoretical distributions by blue curves; IV: Autocorrelation plot
of samples  the decreasing of autocorrelation is comparably fast; V: (A snapshot of) variation on the effective
system temperature during simulation  with the standard reference of unity temperature marked by red line.

Figure 1: Experiment on sampling a 1d synthetic distribution.

4 Related work
Since the inception of the stochastic gradient Langevin dynamics (SGLD) [24]  algorithms originated
from stochastic approximation [21] have received increasing attention on tasks of Bayesian learning.
By adding the right amount of noise to the updates of the stochastic gradient descent (SGD)  SGLD
manages to properly sample the posterior in a random-walk fashion akin to the full-batch Metropolis-
adjusted Langevin algorithm (MALA) [22]. To enable the Hamiltonian dynamics for efﬁcient state
space exploration  Chen et al. [2] extended the mechanism designed for SGLD to HMC  and proposed
the stochastic gradient Hamiltonian Monte Carlo (SGHMC). As is shown that the stochastic gradient
drives the Hamiltonian dynamics to deviate  SGHMC estimates the unknown noise from the stochastic
gradient with the Fisher information matrix  and then compensates the estimated noise by augmenting
the Hamiltonian dynamics with an additive friction derived from the estimated Fisher matrix. It turns
out that the friction can be linked to the momentum term within a class of accelerated gradient-based
methods [19  17  23] in optimisation. Shortly after SGHMC  Ding et al. [5] came up with the idea of
incorporating the Nosé-Hoover thermostat [18  11] into the Hamiltonian dynamics in replacement of
the constant friction in SGHMC  and hence developed the stochastic gradient Nosé-Hoover thermostat
(SGNHT). The thermostat in SGNHT serves as an adaptive friction which adaptively neutralises the
mini-batch noise from the stochastic gradient into the system [12].
Parallel to those aforementioned studies  recent advances in the development of continuous tempering
[8  15] as well as its applications in machine learning [25  9] are of particular interest. Ye et al. [25]
proposed the continuously tempered Langevin dynamics (CTLD)  which leverages the mechanism of
continuous tempering and embeds the tempering variable in an extended stochastic gradient second-
order Langevin dynamics. CTLD facilitates exploration on rugged landscapes of objective functions 
locating the “good” wide valleys on the landscape and preventing early trapping in the “bad” narrow
local minima. Nevertheless  CTLD is designed to be an initialiser for training deep neural networks; it
serves as an enhancement of the subsequent gradient-based optimisers instead of a Bayesian solution.
From the Bayesian perspective  Graham et al. [9] developed the continuously-tempered Hamiltonian
Monte Carlo (CTHMC) operating in a full-batch setting. CTHMC augments the Hamiltonian system
with an extra continuously-varying control variate borrowed from the scheme of continuous tempering 
which enables the extended Hamiltonian dynamics to bridge between sampling a complex multimodal
target posterior and a simpler unimodal base distribution. Albeit beneﬁcial for mixing  its dynamics
lacks the ability to handle the mini-batch noise  and thus fails to function properly with mini-batches.

5 Experiment

Two sets of experiments are carried out. We ﬁrst conduct an ablation study with synthetic distributions 
where we visualise the system dynamics and validate the efﬁcacy of TACT-HMC. We then evaluate
the performance of our method against several strong baselines on three real datasets.

6

-20-15-10-5051015200.000.050.100.150.20Pr()I. Samples via the proposed method-20-15-10-5051015200.000.050.100.150.20Pr()II. Samples via well-tempered HMC w/o thermostats-20-15-10-5051015200.000.050.100.150.20Pr()III. Samples via thermostat-assisted HMC w/o tempering0.000-200-400-60020Iteration151050-5-10-800-10000.05-1200-15-1400-200.10Pr()I. Sampling trajectory0.150.20012345678910Iteration1040.70.80.91.01.11.21.3CUMAVG(s)II. Cumulative averages of thermostats012345678910Iteration1040.70.80.91.01.11.21.3CUMAVG(s)-3-2-1012345s0.00.10.20.30.40.5Pr(s)III. Histograms of sampled thermostats-3-2-1012345s0.00.10.20.30.40.5Pr(s)051015202530Lag k0.000.250.500.751.00(k)IV. Autocorrelation plot050100150200250300Time 051015kBT()V. Variation of temperatureFigure 2: Experiments on sampling two 2d synthetic distributions. Left: The distributions to sample;
Mid-left: Histograms sampled by TACT-HMC; Mid-right: Histograms by the well-tempered sampler
without thermostatting; Right: Histograms by the thermostat-assisted sampler without tempering.

5.1 Multimodal sampling of synthetic distributions
We run TACT-HMC on three 1d/2d synthetic distributions. In the meantime  two ablated alternatives
are initiated in parallel with the same setting: one is equipped with thermostats but without tempering
for sampling acceleration  the other is well-tempered but without thermostatting against noise. The
distributions are synthesised to contain multiple distant modes; the calculation of gradient is perturbed
by Gaussian noise that is unknown to all samplers.
Figure 1 summarises the result of sampling a mixture of three 1d Gaussians. As the ﬁgure indicates 
only TACT-HMC is capable of correctly sampling from the target. The sampler without thermostatting
is heavily inﬂuenced by the noise in gradient  resulting in a spread histogram; while the one without
tempering gets trapped by those energy barriers and hence fails to explore the entire space of system
conﬁgurations. The sampling trajectory and properties of TACT-HMC are illustrated in details in Fig.
1b  which justiﬁes the correctness of TACT-HMC. The autocorrelation of samples ρ(k) is calculated
and shown in Fig. 1b(IV)  which decreases monotonically from ρ(0) = 1 down to ρ(∞) → 0+. The
effective sample size (ESS) can thus be readily evaluated through the formula

ESS =

k=1 ρ(k)  with ρ(k) as the autocorrelation at lag k.

1 + 2∞

n

The ESS for TACT-HMC in this 1d Gaussian mixture case is 2.1096 × 104 out of n = 105 samples 
which is roughly 60.2% of the value for SGHMC and 50.9% of that for SGNHT. We believe that
the non-linear interaction between the parameter of interest θ and the tempering variable ξ via the
multiplicative term λ(ξ)U(θ) results in a longer autocorrelation time and hence a lower ESS value.
We also investigate the variation of the effective system temperature during sampling. A snapshot of
the trajectory regarding the effective system temperature is demonstrated in Fig. 1b(V): it constantly
oscillates between higher and lower temperatures  and returns to the unity temperature occasionally.
We further conduct two 2d sampling experiments as shown in Fig. 2. Comparing between columns 
we ﬁnd that TACT-HMC recovers those multiple modes for both distributions while neutralising the
inﬂuence of the noise in gradient; however  the samplings by the ablated alternatives are impaired
either by the noise in gradient or by the energy barriers as discovered in the 1d scenario.

5.2 Bayesian learning on real datasets
Stepping out of the study on the synthetic cases  we then move on to the tasks of image classiﬁcation
on three real datasets: EMNIST3  Fashion-MNIST4 and CIFAR-10. The performance is evaluated
and compared in terms of the accuracy of classiﬁcation on three types of neural networks: multilayer
perceptrons (MLPs)  recurrent neural networks (RNNs)  and convolutional neural networks (CNNs).
Two recent samplers are chosen as part of the baselines  namely SGNHT [5] and SGHMC [2]; besides 
two widely-used gradient-based optimisers  Adam [13] and momentum SGD [23]  are compared.
Each method will keep running for 1000 epochs in either sampling or training before the evaluation
and comparison. We further apply random permutation to a certain percentage (0%  20%  and 30%)
of the training labels at the beginning of each epoch for demonstrating the robustness of our method.

3https://www.nist.gov/itl/iad/image-group/emnist-dataset
4https://github.com/zalandoresearch/fashion-mnist

7

Table 1: Result of Bayesian learning experiments on real datasets

MLP on EMNIST
0%

20%

% permuted labels
Adam [13]
momentum SGD [23]
SGHMC [2]
SGNHT [5]
TACT-HMC (Alg. 1)

30%

30%
83.39% 80.27% 80.63% 88.84% 88.35% 88.25% 69.53% 72.39% 71.05%
83.95% 82.64% 81.70% 88.66% 88.91% 88.34% 64.25% 65.09% 67.70%
84.53% 82.62% 81.56% 90.25% 88.98% 88.49% 76.44% 73.87% 71.79%
84.48% 82.63% 81.60% 90.18% 89.10% 88.58% 76.60% 73.86% 71.37%
84.85% 82.95% 81.77% 90.84% 89.61% 89.01% 78.93% 74.88% 73.22%

30%

RNN on Fashion-MNIST

0%

20%

CNN on CIFAR-10
0%

20%

All four baselines are tuned to their best on each task; the setting of TACT-HMC will be speciﬁed for
each task in the corresponding subsection. For the baseline samplers  the accuracy of classiﬁcation
is calculated from Monte Carlo integration on all sampled models; for the baseline optimisers  the
performance is evaluated directly on test sets after training. The result is summarised in Table. 1.
EMNIST classiﬁcation with MLP. The MLP herein deﬁnes a three-layered fully-connected neural
network with the hidden layer consisting of 100 neurons. EMNIST Balanced is selected as the dataset 
where 47 categories of images are split into a training set of size 112 800 and a complementary test set
of size 18 800. The batch size is ﬁxed at 128 for all methods in both sampling and training tests. For
readability  we introduce a 7-tuple [ηθ  ηξ  cθ  cξ  γθ  γξ  K] as the speciﬁcation to set up TACT-HMC
(see Alg. 1). In this speciﬁcation  [ηθ  cθ  γθ] denote the step size  the level of the injected Gaussian
noise and the thermal inertia  all w.r.t. the parameter of interest θ; similarly  [ηξ  cξ  γξ] represent the
quantities corresponding to the tempering variable ξ; K deﬁnes the number of steps in simulating a
unit interval. In this experiment  TACT-HMC is conﬁgured as [0.0015 0.0015 0.05 0.05 1.0 1.0 50].
Fashion-MNIST classiﬁcation with RNN. The RNN contains a LSTM layer [10] as the ﬁrst layer 
with the input/output dimensions being 28/128. It takes as the input via scanning a 28 × 28 image
vertically each line of a time. After 28 steps of scanning  the LSTM outputs a representative vector of
length 128 into ReLU activation  which is followed by a dense layer of size 64 with ReLU activation.
The prediction regarding 10 categories is generated through softmax activation in the output layer.
The batch size is ﬁxed at 64 for all methods in comparison. The speciﬁcation of TACT-HMC in this
experiment is determined as [0.0012 0.0012 0.15 0.15 1.0 1.0 50].
CIFAR-10 classiﬁcation with CNN. The CNN comprises of four learnable layers: from the bottom
to the top  a 2d convolutional layer using the kernel of size 3×3×3×16  and another 2d convolutional
layer with the kernel of size 3×3×16×16  then two dense layers of size 100 and 10. ReLU activations
are inserted between each of those learnable layers. For each convolutional layer  the stride is set to
1 × 1  and a pooling layer with 2 × 2 stride is appended after the ReLU activation. Softmax function
is applied for generating the ﬁnal prediction over 10 categories. The batch size is ﬁxed at 64 for all
methods. Here  TACT-HMC’s speciﬁcation is set as [0.0010 0.0010 0.10 0.10 1.0 1.0 50].
Discussion. As summarised in Table. 1  TACT-HMC outperforms all four baselines on the accuracy
of classiﬁcation. Speciﬁcally  TACT-HMC demonstrates advantages on complicated tasks  e.g. the
CIFAR-10 classiﬁcation with CNN where the model has relatively higher complexity and the dataset
contains multiple channels. For the RNN task  our method outperforms others with roughly 0.5% on
accuracy. The performance gain on the MLP task is rather limited; we believe the reason for this is that
the complexities of both model and dataset are essentially moderate. When the random permutation
is applied to a larger portion of training labels  TACT-HMC still maintains robust performance on the
accuracy of classiﬁcation  even though the landscape of the objective function becomes rougher and
the system dynamics gathers more noise.

6 Conclusion
We developed a new sampling method  which is called the thermostat-assisted continuously-tempered
Hamiltonian Monte Carlo  to facilitate Bayesian learning with large datasets and multimodal posterior
distributions. The method builds a well-tempered Hamiltonian system by incorporating the scheme of
continuous tempering in the system for classic HMC  and then simulates the dynamics augmented by
Nosé-Hoover thermostats. This sampler is designed for two substantial demands: ﬁrst  to efﬁciently
generate representative i.i.d. samples from complex multimodal distributions; second  to adaptively
neutralise the noise arising from mini-batches. Extensive experiments have been carried out on both
synthetic distributions and real-world applications. The result validated the efﬁcacy of tempering and
thermostatting  demonstrating great potentials of our sampler in accelerating deep Bayesian learning.

8

References
[1] Steve Brooks  Andrew Gelman  Galin Jones  and Xiao-Li Meng. Handbook of markov chain

monte carlo. CRC press  2011.

[2] Tianqi Chen  Emily B Fox  and Carlos Guestrin. Stochastic gradient hamiltonian monte carlo.

In ICML  pages 1683–1691  2014.

[3] Jeffrey Comer  James C Gumbart  Jérôme Hénin  Tony Lelièvre  Andrew Pohorille  and
Christophe Chipot. The adaptive biasing force method: Everything you always wanted to
know but were afraid to ask. The Journal of Physical Chemistry B  119(3):1129–1151  2014.
[4] Eric Darve and Andrew Pohorille. Calculating free energies using average force. The Journal

of Chemical Physics  115(20):9169–9183  2001.

[5] Nan Ding  Youhan Fang  Ryan Babbush  Changyou Chen  Robert D Skeel  and Hartmut Neven.
Bayesian sampling using stochastic gradient thermostats. In Advances in neural information
processing systems  pages 3203–3211  2014.

[6] Simon Duane  Anthony D Kennedy  Brian J Pendleton  and Duncan Roweth. Hybrid monte

carlo. Physics letters B  195(2):216–222  1987.

[7] Farhan Feroz and MP Hobson. Multimodal nested sampling: an efﬁcient and robust alternative
to markov chain monte carlo methods for astronomical data analyses. Monthly Notices of the
Royal Astronomical Society  384(2):449–463  2008.

[8] Gianpaolo Gobbo and Benedict J Leimkuhler. Extended hamiltonian approach to continuous

tempering. Physical Review E  91(6):061301  2015.

[9] Matthew M. Graham and Amos J. Storkey. Continuously tempered hamiltonian monte carlo. In
Gal Elidan  Kristian Kersting  and Alexander T. Ihler  editors  Proceedings of the Thirty-Third
Conference on Uncertainty in Artiﬁcial Intelligence  UAI 2017  Sydney  Australia  August 11-15 
2017. AUAI Press  2017.

[10] Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural computation 

9(8):1735–1780  1997.

[11] William G Hoover. Canonical dynamics: equilibrium phase-space distributions. Physical review

A  31(3):1695  1985.

[12] Andrew Jones and Ben Leimkuhler. Adaptive stochastic methods for sampling driven molecular

systems. The Journal of chemical physics  135(8):084125  2011.

[13] Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. CoRR 

abs/1412.6980  2014.

[14] Tony Lelièvre  Mathias Rousset  and Gabriel Stoltz. Long-time convergence of an adaptive

biasing force method. Nonlinearity  21(6):1155  2008.

[15] Nicolas Lenner and Gerald Mathias. Continuous tempering molecular dynamics: A deterministic
approach to simulated tempering. Journal of chemical theory and computation  12(2):486–498 
2016.

[16] Radford M Neal et al. Mcmc using hamiltonian dynamics. Handbook of Markov Chain Monte

Carlo  2:113–162  2011.

[17] Yurii Nesterov. A method of solving a convex programming problem with convergence rate

o(1/k2). Soviet Mathematics Doklady  27(2):372–376  1983.

[18] Shuichi Nosé. A uniﬁed formulation of the constant temperature molecular dynamics methods.

The Journal of chemical physics  81(1):511–519  1984.

[19] Boris T Polyak. Some methods of speeding up the convergence of iteration methods. USSR

Computational Mathematics and Mathematical Physics  4(5):1–17  1964.

[20] H. Risken and H. Haken. The Fokker-Planck Equation: Methods of Solution and Applications

Second Edition. Springer  1989.

[21] Herbert Robbins and Sutton Monro. A stochastic approximation method. The annals of

mathematical statistics  pages 400–407  1951.

[22] Gareth O Roberts  Richard L Tweedie  et al. Exponential convergence of langevin distributions

and their discrete approximations. Bernoulli  2(4):341–363  1996.

9

[23] Ilya Sutskever  James Martens  George Dahl  and Geoffrey Hinton. On the importance of
initialization and momentum in deep learning. In International conference on machine learning 
pages 1139–1147  2013.

[24] Max Welling and Yee W Teh. Bayesian learning via stochastic gradient langevin dynamics.
In Proceedings of the 28th International Conference on Machine Learning (ICML-11)  pages
681–688  2011.

[25] Nanyang Ye  Zhanxing Zhu  and Rafal Mantiuk. Langevin dynamics with continuous tempering
for training deep neural networks. In Advances in Neural Information Processing Systems 
pages 618–626  2017.

10

,Rui Luo
Jianhong Wang
Yaodong Yang
Jun WANG
Zhanxing Zhu