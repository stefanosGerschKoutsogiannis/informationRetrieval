2009,Beyond Convexity: Online Submodular Minimization,We consider an online decision problem over a discrete space in which the loss function is submodular. We give algorithms which are computationally efficient and are Hannan-consistent in both the full information and bandit settings.,Online Submodular Minimization

Elad Hazan

IBM Almaden Research Center

650 Harry Rd  San Jose  CA 95120

Satyen Kale

Yahoo! Research

4301 Great America Parkway  Santa Clara  CA 95054

hazan@us.ibm.com

skale@yahoo-inc.com

Abstract

We consider an online decision problem over a discrete space in which the loss
function is submodular. We give algorithms which are computationally efﬁcient
and are Hannan-consistent in both the full information and bandit settings.

1 Introduction

Online decision-making is a learning problem in which one needs to choose a decision repeatedly
from a given set of decisions  in an effort to minimize costs over the long run  even in the face of
complete uncertainty about future outcomes. The performance of an online learning algorithm is
measured in terms of its regret  which is the difference between the total cost of the decisions it
chooses  and the cost of the optimal decision chosen in hindsight. A Hannan-consistent algorithm is
one that achieves sublinear regret (as a function of the number of decision-making rounds). Hannan-
consistency implies that the average per round cost of the algorithm converges to that of the optimal
decision in hindsight.
In the past few decades  a variety of Hannan-consistent algorithms have been devised for a wide
range of decision spaces and cost functions  including well-known settings such as prediction from
expert advice [10]  online convex optimization [15]  etc. Most of these algorithms are based on
an online version of convex optimization algorithms. Despite this success  many online decision-
making problems still remain open  especially when the decision space is discrete and large (say 
exponential size in the problem parameters) and the cost functions are non-linear.
In this paper  we consider just such a scenario. Our decision space is now the set of all subsets of
a ground set of n elements  and the cost functions are assumed to be submodular. This property
is widely seen as the discrete analogue of convexity  and has proven to be a ubiquitous property in
various machine learning tasks (see [4] for references). A crucial component in these latter results
are the celebrated polynomial time algorithms for submodular function minimization [7].
To motivate the online decision-making problem with submodular cost functions  here is an example
from [11]. Consider a factory capable of producing any subset from a given set of n products E.
Let f : 2E (cid:55)→ R be the cost function for producing any such subset (here  2E stands for the set of
all subsets of E). Economics tells us that this cost function should satisfy the law of diminishing
returns:
i.e.  the additional cost of producing an additional item is lower the more we produce.
Mathematically stated  for all sets S  T ⊆ E such that T ⊆ S  and for all elements i ∈ E  we have

f(T ∪ {i}) − f(T ) ≥ f(S ∪ {i}) − f(S).

Such cost functions are called submodular  and frequently arise in real-world economic and other
(cid:80)
scenarios. Now  for every item i  let pi be the market price of the item  which is only determined in
the future based on supply and demand. Thus  the proﬁt from producing a subset S of the items is
i∈S pi − f(S). Maximizing proﬁt is equivalent to minimizing the function −P   which
P (S) =
is easily seen to be submodular as well.
The online decision problem which arises is now to decide which set of products to produce  to max-
imize proﬁts in the long run  without knowing in advance the cost function or the market prices. A

1

more difﬁcult version of this problem  perhaps more realistic  is when the only information obtained
is the actual proﬁt of the chosen subset of items  and no information on the proﬁt possible for other
subsets.
In general  the Online Submodular Minimization problem is the following. In each iteration  we
choose a subset of a ground set of n elements  and then observe a submodular cost function which
gives the cost of the subset we chose. The goal is to minimize the regret  which is the difference
between the total cost of the subsets we chose  and the cost of the best subset in hindsight. Depending
on the feedback obtained  we distinguish between two settings  full-information and bandit. In the
full-information setting  we can query each cost function at as many points as we like. In the bandit
setting  we only get to observe the cost of the subset we chose  and no other information is revealed.
Obviously  if we ignore the special structure of these problems  standard algorithms for learning
with expert advice and/or with bandit feedback can be applied to this setting. However  the com-
putational complexity of these algorithms would be proportional to the number of subsets  which is
2n. In addition  for the submodular bandits problem  even the regret bounds have an exponential
dependence on n. It is hence of interest to design efﬁcient algorithms for these problems. For the
bandit version an even more basic question arises: does there exist an algorithm with regret which
depends only polynomially on n?
In this paper  we answer these questions in the afﬁrmative. We give efﬁcient algorithms for both
problems  with regret which is bounded by a polynomial in n – the underlying dimension – and
√
sublinearly in the number of iterations. For the full information setting  we give two different ran-
T ). One of these algorithms is based on the follow-
domized algorithms with expected regret O(n
the-perturbed-leader approach [5  9]. We give a new way of analyzing such an algorithm. This
analysis technique should have applications for other problems with large decision spaces as well.
This algorithm is combinatorial  strongly polynomial  and can be easily generalized to arbitrary dis-
tributive lattices  rather than just all subsets of a given set. The second algorithm is based on convex
analysis. We make crucial use of a continuous extension of a submodular function known as the
Lov´asz extension. We obtain our regret bounds by running a (sub)gradient descent algorithm in the
style of Zinkevich [15].
For the bandit setting  we give a randomized algorithm with expected regret O(nT 2/3). This algo-
rithm also makes use of the Lov´asz extension and gradient descent. The algorithm folds exploration
and exploitation steps into a single sample and obtains the stated regret bound. We also show that
these regret bounds hold with high probability. Note that the technique of Flaxman  Kalai and
McMahan [1]  when applied to the Lov´asz extension  gives a worse regret bound of O(nT 3/4).

2 Preliminaries and Problem Statement

Submodular functions. The decision space is the set of all subsets of a universe of n elements 
[n] = {1  2  . . .   n}. The set of all subsets of [n] is denoted 2[n]. For a set S ⊆ [n]  denote by χS its
characteristic vector in {0  1}n  i.e. χS(i) = 1 if i ∈ S  and 0 otherwise.
A function f : 2[n] → R is called submodular if for all sets S  T ⊆ [n] such that T ⊆ S  and for all
elements i ∈ E  we have

f(T + i) − f(T ) ≥ f(S + i) − f(S).

Here  we use the shorthand notation S + i to indicate S ∪ {i}. An explicit description of f would
take exponential space. We assume therefore that the only way to access f is via a value oracle  i.e.
an oracle that returns the value of f at any given set S ⊆ [n].
Given access to a value oracle for a submodular function  it is possible to minimize it in polynomial
time [3]  and indeed  even in strongly polynomial time [3  7  13  6  12  8]. The current fastest strongly
polynomial algorithm are those of Orlin[12] and Iwata-Orlin [8]  which takes time O(n5EO + n6) 
where EO is the time taken to run the value oracle. The fastest weakly polynomial algorithm is that
of Iwata [6] and Iwata-Orlin [8] which runs in time ˜O(n4EO + n5).

Online Submodular Minimization.
In the Online Submodular Minimization problem  over a
sequence of iterations t = 1  2  . . .  an online decision maker has to repeatedly chose a subset

2

St ⊆ [n]. In each iteration  after choosing the set St  the cost of the decision is speciﬁed by a
submodular function ft : 2[n] → [−1  1]. The decision maker incurs cost ft(St). The regret of the
decision maker is deﬁned to be

T(cid:88)

t=1

T(cid:88)

t=1

RegretT :=

ft(St) − min
S⊆[n]

ft(S).

If the sets St are chosen by a randomized algorithm  then we consider the expected regret over the
randomness in the algorithm.
An online algorithm to choose the sets St will be said to be Hannan-consistent if it ensures that
RegretT = o(T ). The algorithm will be called efﬁcient if it computes each decision St in poly(n  t)
time. Depending on the kind of feedback the decision maker receives  we distinguish between two
settings of the problem:

• Full information setting. In this case  in each round t  the decision maker has unlimited

access to the value oracles of the previously seen cost function f1  f2  . . . ft−1.

• Bandit setting. In this case  in each round t  the decision maker only observes the cost of

her decision St  viz. ft(St)  and receives no other information.

Main Results.
In the setup of the Online Submodular Minimization  we have the following results:
Theorem 1. In the full information setting of Online Submodular Minimization  there is an efﬁcient
randomized algorithm that attains the following regret bound:

(cid:112)

√
E[RegretT ] ≤ O(n
T ).
√
T ) with probability at least 1 − ε.
log(1/ε))

Furthermore  RegretT ≤ O((n +
Theorem 2. In the bandit setting of Online Submodular Minimization  there is an efﬁcient random-
ized algorithm that attains the following regret bound:

(cid:112)
E[RegretT ] ≤ O(nT 2/3).
log(1/ε)) with probability at least 1 − ε.

Furthermore  RegretT ≤ O(nT 2/3
Both of the theorems above hold against both oblivious as well as adaptive adversaries.

The Lov´asz Extension. A major technical construction we need for the algorithms is the Lov´asz
extension ˆf of the submodular function f. This is deﬁned on the Boolean hypercube K = [0  1]n and
takes real values. Before deﬁning the Lov´asz extension  we need the concept of a chain of subsets
of [n]:
Deﬁnition 1. A chain of subsets of [n] is a collection of sets A0  A1  . . .   Ap such that

A0 ⊂ A1 ⊂ A2 ⊂ ··· ⊂ Ap.

(cid:80)p

A maximal chain is one where p = n. For a maximal chain  we have A0 = ∅  An = [n]  and there is
a unique associated permutation π : [n] → [n] such that for all i ∈ [n]  we have Aπ(i) = Aπ(i)−1+i.
Now let x ∈ K. There is a unique chain A0 ⊂ A2 ⊂ ··· Ap such that x can be expressed as a
convex combination x =
i=0 µi = 1. A nice way to construct this
combination is the following random process: choose a threshold τ ∈ [0  1] uniformly at random 
and consider the level set Sτ = {i : xi > τ}. The sets in the required chain are exactly the level
sets which are obtained with positive probability  and for any such set Ai  µi = Pr[Sτ = Ai]. In
other words  we have x = Eτ [χSτ ]. This follows immediately by noting that for any i  we have
Prτ [i ∈ Sτ ] = xi. Of course  the chain and the weights µi can also be constructed deterministically
simply by sorting the coordinates of x.
Now  we are ready to deﬁne1 the Lov´asz extension ˆf:

i=0 µiχAi where µi > 0 and

(cid:80)p

1Note that this is not the standard deﬁnition of the Lov´asz extension  but an equivalent characterization.

3

Deﬁnition 2. Let x ∈ K. Let A0 ⊂ A2 ⊂ ··· Ap such that x can be expressed as a convex
i=0 µi = 1. Then the value of the Lov´asz
combination x =
extension ˆf at x is deﬁned to be

i=0 µiχAi where µi > 0 and

(cid:80)p

(cid:80)p

p(cid:88)

ˆf(x) :=

µif(Ai).

The preceding discussion gives an equivalent way of deﬁning the Lov´asz extension: choose a thresh-
old τ ∈ [0  1] uniformly at random  and consider the level set Sτ = {i : xi > τ}. Then we have

i=0

ˆf(x) = Eτ [f(Sτ )].

Note that the deﬁnition immediately implies that for all sets S ⊆ [n]  we have ˆf(χS) = f(S).
We will also need the notion of a maximal chain associated to a point x ∈ K in order to deﬁne
subgradients of the Lov´asz extension:
Deﬁnition 3. Let x ∈ K  and let A0 ⊂ A2 ⊂ ··· Ap be the unique chain such that x =
i=0 µiχAi
i=0 µi = 1. A maximal chain associated with x is any maximal completion of
where µi > 0 and
the Ai chain  i.e. a maximal chain ∅ = B0 ⊂ B1 ⊂ B2 ⊂ ··· Bn = [n] such that all sets Ai appear
in the Bj chain.

(cid:80)p

(cid:80)p

We have the following key properties of the Lov´asz extension. For proofs  refer to Fujishige [2] 
chapter IV.
Proposition 3. The following properties of the Lov´asz extension ˆf : K → R hold:

1. ˆf is convex.
2. Let x ∈ K. Let ∅ = B0 ⊂ B1 ⊂ B2 ⊂ ··· Bn = [n] be an arbitrary maximal chain
associated with x  and let π : [n] → [n] be the corresponding permutation. Then  a
subgradient g of ˆf at x is given as follows:

gi = f(Bπ(i)) − f(Bπ(i)−1).

3 The Full Information Setting

√
In this section we give two algorithms for regret minimization in the full information setting  both of
T ). The ﬁrst is a randomized combinatorial algorithm 
which attain the same regret bound of O(n
based on the “follow the leader” approach of Hannan [5] and Kalai-Vempala [9]  and the second is
an analytical algorithm based on (sub)gradient descent on the Lov´asz extension.
Both algorithms have pros and cons: while the second algorithm is much simpler and more efﬁcient 
we do not know how to extend it to distributive lattices  for which the ﬁrst algorithm readily applies.

3.1 A Combinatorial Algorithm

In this section we analyze a combinatorial  strongly polynomial  algorithm for minimizing regret in
the full information Online Submodular Minimization setting:

Algorithm 1 Submodular Follow-The-Perturbed-Leader
1: Input: parameter η > 0.
2: Initialization: For every i ∈ [n]  choose a random number ri ∈ [−1/η  1/η] uniformly at

(cid:80)

random. Deﬁne R : 2[n] → R as R(S) =

i∈S ri.

3: for t = 1 to T do
4:
5: end for

Use the set St = arg minS⊆[n]

τ =1 fτ (S) + R(S)  and obtain cost ft(St).

Deﬁne Φt : 2[n] → R as Φt(S) =
τ =1 fτ (S) + R(S). Note that R is a submodular function  and
Φt  being the sum of submodular functions  is itself submodular. Furthermore  it is easy to construct

(cid:80)t−1
(cid:80)t−1

4

a value oracle for Φt simply by using the value oracles for the fτ . Thus  the optimization in step 3
is poly-time solvable given oracle access to Φt.
While the algorithm itself is a simple extension of Hannan’s [5] follow-the-perturbed-leader algo-
rithm  previous analysis (such as Kalai and Vempala [9])  which rely on linearity of the cost func-
tions  cannot be made to work here. Instead  we introduce a new analysis technique: we divide the
decision space using n different cuts so that any two decisions are separated by at least one cut  and
then we give an upper bound on the probability that the chosen decision switches sides over each
such cut. This new technique may have applications to other problems as well. We now prove the
regret bound of Theorem 1:
Theorem 4. Algorithm 1 run with parameter η = 1/

√
T achieves the following regret bound:
√
T .

E[RegretT ] ≤ 6n

Proof. We note that the algorithm is essentially running a “follow-the-leader” algorithm on the
cost functions f0  f1  . . .   ft−1  where f0 = R is a ﬁctitious “period 0” cost function used for
regularization. The ﬁrst step to analyzing this algorithm is to use a stability lemma  essentially
proved in Theorem 1.1 of [9]  which bounds the regret as follows:

RegretT ≤ T(cid:88)
(cid:80)T

t=1

ft(St) − ft(St+1) + R(S∗) − R(S1).

(cid:88)

i∈[n]

t=1 ft(S).

Here  S∗ = arg minS⊆[n]
To bound the expected regret  by linearity of expectation  it sufﬁces to bound E[f(St) − f(St+1)] 
where for the purpose of analysis  we assume that we re-randomize in every round (i.e. choose a
fresh random function R : 2[n] → R). Naturally  the expectation E[f(St) − f(St+1)] is the same
regardless of when R is chosen.
To bound this  we need the following lemma:
Lemma 5.

Pr[St (cid:54)= St+1] ≤ 2nη.

Proof. First  we note the following simple union bound:

Pr[St (cid:54)= St+1] ≤

Pr[i ∈ St and i /∈ St+1] + Pr[i /∈ St and i ∈ St+1].

(1)

(cid:80)

(cid:80)t−1
Now  ﬁx any i  and we aim to bound Pr[i ∈ St and i /∈ St+1]. For this  we condition on the
randomness in choosing rj for all j (cid:54)= i. Deﬁne R(cid:48) : 2[n] → R as R(cid:48)(S) =
j∈S j(cid:54)=i rj  and
τ =1 fτ (S) + R(cid:48)(S). Note that if i /∈ S  then R(cid:48)(S) = R(S) and
t : 2[n] → R as Φ(cid:48)
Φ(cid:48)
Φ(cid:48)
t(S) = Φt(S). Let

t(S) =

A = arg min

S⊆[n]:i∈S

Φ(cid:48)(S)

and B = arg min
S⊆[n]:i /∈S
t(A) + ri < Φ(cid:48)

Φ(cid:48)(S).

Now  we note that the event i ∈ St happens only if Φ(cid:48)
Φ(cid:48)
t(A) + ri < Φ(cid:48)

t(B) − 2  then we must have i ∈ St+1  since for any C such that i /∈ C 
t(C) + ft(C) = Φt(C).
The inequalities above use the fact that ft(S) ∈ [−1  1] for all S ⊆ [n]. Thus  if v := Φ(cid:48)
Φ(cid:48)
t(A)  we have

t(A) + ri + ft(A) < Φ(cid:48)

t(B) − 1 < Φ(cid:48)

Φt+1(A) = Φ(cid:48)

t(B)  and St = A. But if

t(B) −

Pr[i ∈ St and i /∈ St+1 | rj  j (cid:54)= i] ≤ Pr[ri ∈ [v − 2  v] | rj  j (cid:54)= i] ≤ η 

since ri is chosen uniformly from [−1/η  1/η]. We can now remove the conditioning on rj for
j (cid:54)= i  and conclude that
Similarly  we can bound Pr[i /∈ St and i ∈ St+1] ≤ η. Finally  the union bound (1) over all choices
of i yields the required bound on Pr[St (cid:54)= St+1].

Pr[i ∈ St and i /∈ St+1] ≤ η.

5

Continuing the proof  we have

E[f(St) − f(St+1)] = E[f(St) − f(St+1) | St (cid:54)= St+1] · Pr[St (cid:54)= St+1]

≤ 0 + 2 · Pr[St (cid:54)= St+1]
≤ 4nη.

The last inequality follows from Lemma 5. Now  we have R(S∗) − R(S1) ≤ 2n/η  and so

E[RegretT ] ≤ T(cid:88)

E[f(St) − f(St+1)] + E[R(S∗) − R(S1)]

t=1

≤ 4nηT + 2n/η
≤ 6n

√
T  

since η = 1/

√
T .

3.2 An Analytical Algorithm

In this section  we give a different algorithm based on the Online Gradient Descent method of
Zinkevich [15]. We apply this technique to the Lov´asz extension of the cost function coupled with a
simple randomized construction of the subgradient  as given in deﬁnition 2. This algorithm requires
the concept of a Euclidean projection of a point in Rn on to the set K  which is a function ΠK :
Rn → K deﬁned by

ΠK(y) := arg min

x∈K (cid:107)x − y(cid:107).

Since K = [0  1]n  it is easy to implement this projection: indeed  for a point y ∈ Rn  the projection
x = ΠK(y) is deﬁned by

yi

0
1

xi =

if yi ∈ [0  1]
if yi < 0
if yi > 1

Algorithm 2 Submodular Subgradient Descent
1: Input: parameter η > 0. Let x1 ∈ K be an arbitrary initial point.
2: for t = 1 to T do
3:

Choose a threshold τ ∈ [0  1] uniformly at random  and use the set St = {i : xt(i) > τ} and
obtain cost ft(St).
Find a maximal chain associated with xt  ∅ = B0 ⊂ B1 ⊂ B2 ⊂ ··· Bn = [n]  and use
ft(B0)  ft(B1)  . . .   ft(Bn) to compute a subgradient gt of ˆft at xt as in part 2 of Proposi-
tion 3.
Update: set xt+1 = ΠK(xt − ηgt).

4:

5:
6: end for

In the analysis of the algorithm  we need the following regret bound. It is a simple extension of
Zinkevich’s analysis of Online Gradient Descent to vector-valued random variables whose expec-
tation is the subgradient of the cost function (the generality to random variables is not required for
this section  but it will be useful in the next section):
Lemma 6. Let ˆf1  ˆf2  . . .   ˆfT : K → [−1  1] be a sequence of convex cost functions over the cube
K. Let x1  x2  . . .   xT ∈ K be deﬁned by x1 = 0 and xt+1 = ΠK(xt − ηˆgt)  where ˆg1  ˆg2  . . .   ˆgT
are vector-valued random variables such that E[ˆgt|xt] = gt  where gt is a subgradient of ˆft at xt.
Then the expected regret of playing x1  x2  . . .   xT is bounded by

T(cid:88)

t=1

T(cid:88)

t=1

E[ ˆft(xt)] − min
x∈K

ˆfT (x) ≤ n
2η

+ 2ηn

E[(cid:107)ˆgt(cid:107)2].

(cid:88)

t

Since this Lemma follows rather easily from [15]  we omit the proof in this extended abstract.
We can now prove the following regret bound:

6

Theorem 7. Algorithm 2  run with parameter η = 1/

√
T   achieves the following regret bound:
√
E[RegretT ] ≤ 3n
T .
Furthermore  with probability at least 1 − ε  RegretT ≤ (3n +
Proof. Note that be Deﬁnition 2  we have that E[ft(St)] = ˆft(xt). Since the algorithm runs Online
Gradient Descent (from Lemma 6) with ˆgt = gt (i.e. no randomness)  we get the following bound
on the regret. Here  we use the bound (cid:107)ˆgt(cid:107)2 = (cid:107)gt(cid:107)2 ≤ 4n.

2 log(1/ε))

√
T .

(cid:112)

E[RegretT ] =
√
T   we get the required regret bound. Furthermore  by a simple Hoeffding bound  we

+ 2ηnT.

t=1

t=1

t=1

t=1

E[ft(St)] − min
S⊆[n]

ˆfT (x) ≤ n
2η

ˆft(xt) − min
x∈K

Since η = 1/
also get that with probability at least 1 − ε 

T(cid:88)

ft(St) ≤ T(cid:88)

(cid:112)

E[ft(St)] +

2T log(1/ε) 

T(cid:88)

T(cid:88)

f(S) ≤ T(cid:88)

T(cid:88)

which implies the high probability regret bound.

t=1

t=1

4 The Bandit Setting

We now present an algorithm for the Bandit Online Submodular Minimization problem. The algo-
rithm is based on the Online Gradient Descent algorithm of Zinkevich [15]. The main idea is use
just one sample for both exploration (to construct an unbiased estimator for the subgradient) and
exploitation (to construct an unbiased estimator for the point chosen by the Online Gradient Descent
algorithm).

Algorithm 3 Bandit Submodular Subgradient Descent
1: Input: parameters η  δ > 0. Let x1 ∈ K be arbitrary.
2: for t = 1 to T do
3:

(cid:80)n

Find a maximal chain associated with xt  ∅ = B0 ⊂ B1 ⊂ B2 ⊂ ··· Bn = [n]  and let
π be the associated permutation as in part 2 of Proposition 3. Then xt can be written as
i=0 µiχBi  where µi = 0 for the extra sets Bi that were added to complete the
xt =
maximal chain for xt.
Choose the set St as follows:

St = Bi with probability ρi = (1 − δ)µi + δ

n + 1 .

4:

5:

Use the set St and obtain cost ft(St).
If St = B0  then set ˆgt = − 1
ft(St)eπ(n).
Otherwise  St = Bi for some i ∈ [2  n − 1]. Choose εt ∈ {+1 −1} uniformly at random 
and set:

ft(St)eπ(1)  and if St = Bn then set ˆgt = 1
ρn

ρ0

 2

ρi

ft(St)eπ(i)

ft(St)eπ(i+1)

if εt = 1
if εt = −1

ˆgt =

− 2
Update: set xt+1 = ΠK(xt − η ˆgt).

ρi

6:
7: end for

Before launching into the analysis  we deﬁne some convenient notation ﬁrst. For a random variable
Xt deﬁned in round t of the algorithm  deﬁne Et[Xt] (resp. VARt[Xt]) to be the expectation (resp.
variance) of Xt conditioned on all the randomness chosen by the algorithm until round t.
A ﬁrst observation is that on the expectation  the regret of the algorithm above is almost the same
as if it had played xt all along and the loss functions were replaced by the Lov´asz extensions of the
actual loss functions.

7

Lemma 8. For all t  we have E[f(St)] ≤ E[ ˆft(xt)] + 2δ.

(cid:80)

i ρif(Bi)  and hence:

n(cid:88)

(cid:80)

(cid:183)

n(cid:88)

(cid:184)

Proof. From Deﬁnition 2 we have that ˆf(xt) =

i µif(Bi). On the other hand  Et[f(St)] =

Et[f(St)] − ˆft(xt) =

(ρi − µi)f(Bi) ≤ δ

i=0

i=0

1

n + 1

+ µi

|f(Bi)| ≤ 2δ.

The lemma now follows by taking the expectation of both sides of this inequality with respect to the
randomness chosen in the ﬁrst t − 1 rounds.

Next  by Proposition 3  the subgradient of the Lov´asz extension of ft at point xt corresponding to
the maximal chain B0 ⊂ B1 ⊂ ··· ⊂ Bn is given by gt(i) = f(Bπ(i)) − f(Bπ(i)−1). Using this
fact  it is easy to check that the random vector ˆgt is constructed in such a way that E[ˆgt|xt] = gt.
Furthermore  we can bound the norm of this estimator as follows:
ft(Bi)2 · ρi ≤ 4(n + 1)2

Et[(cid:107)ˆgt(cid:107)2] ≤ n(cid:88)

(2)

.

≤ 16n2
δ

δ

4
ρ2
i

i=0

We can now remove the conditioning  and conclude that E[(cid:107)ˆgt(cid:107)2] ≤ 16n2
Theorem 9. Algorithm 3  run with parameters δ = n
bound:

T 1/3   η = 1

δ

.

E[RegretT ] ≤ 12nT 2/3.

T 2/3   achieves the following regret

Proof. We bound the expected regret as follows:

T(cid:88)

T(cid:88)

E[ft(St)] − min
S⊆[n]

ft(S) ≤ 2δT +

E[ ˆft(xt)] − min
x∈K

t=1

t=1

T(cid:88)

t=1

T(cid:88)

t=1

T(cid:88)

E[(cid:107)ˆgt(cid:107)2]

ˆft(x)

(By Lemma 8)

(By Lemma 6)

.

(By (2))

≤ 2δT + n
2η
≤ 2δT + n
2η
T 1/3   η = 1
T 2/3 .

+

+ η
2
t=1
8n2ηT

δ

The bound is now obtained for δ = n

4.1 High probability bounds on the regret

The theorem of the previous section gave a bound on the expected regret. However  a much stronger
claim can be made that essentially the same regret bound holds with very high probability (expo-
nential tail). In addition  the previous theorem (which only bounds expected regret) holds against an
oblivious adversary  but not necessarily against a more powerful adaptive adversary. The following
gives high probability bounds against an adaptive adversary.
Theorem 10. With probability 1 − 4ε  Algorithm 3  run with parameters δ = n
achieves the following regret bound:

T 1/3   η = 1

T 2/3  

(cid:112)

RegretT ≤ O(nT 2/3

log(1/ε)).

The proof of this theorem is deferred to the full version of this paper.

5 Conclusions and Open Questions

We have described efﬁcient regret minimization algorithms for submodular cost functions  in both
the bandit and full information settings. This parallels the work of Streeter and Golovin [14] who
study two speciﬁc instances of online submodular maximization (for which the ofﬂine problem is
√
NP-hard)  and give (approximate) regret minimizing algorithms. An open question is whether it is
T ) regret bounds for online submodular minimization in the bandit setting.
possible to attain O(

8

References
[1] A. D. Flaxman  A. T. Kalai  and H. B. McMahan  Online convex optimization in the bandit

setting: gradient descent without a gradient  SODA  2005  pp. 385–394.
[2] Satoru Fujishige  Submodular functions and optimization  Elsevier  2005.
[3] M. Gr¨otschel  L. Lov´asz  and A. Schrijver  Geometric Algorithms and Combinatorial Opti-

mization  Springer Verlag  1988.

[4] Carlos Guestrin and Andreas Krause  Beyond convexity - submodularity in machine learning. 

Tutorial given in the 25rd International Conference on Machine Learning (ICML)  2008.

[5] J. Hannan  Approximation to bayes risk in repeated play  In M. Dresher  A. W. Tucker  and P.

Wolfe  editors  Contributions to the Theory of Games  volume III (1957)  97–139.

[6] Satoru Iwata  A faster scaling algorithm for minimizing submodular functions  SIAM J. Com-

put. 32 (2003)  no. 4  833–840.

[7] Satoru Iwata  Lisa Fleischer  and Satoru Fujishige  A combinatorial strongly polynomial algo-

rithm for minimizing submodular functions  J. ACM 48 (2001)  761–777.

[8] Satoru Iwata and James B. Orlin  A simple combinatorial algorithm for submodular function
minimization  SODA ’09: Proceedings of the Nineteenth Annual ACM -SIAM Symposium on
Discrete Algorithms (Philadelphia  PA  USA)  Society for Industrial and Applied Mathematics 
2009  pp. 1230–1237.

[9] Adam Kalai and Santosh Vempala  Efﬁcient algorithms for online decision problems  Journal

of Computer and System Sciences 71(3) (2005)  291–307.

[10] N. Littlestone and M. K. Warmuth  The weighted majority algorithm  Proceedings of the 30th

Annual Symposium on the Foundations of Computer Science  1989  pp. 256–261.

[11] S. T. McCormick  Submodular function minimization.  Chapter 7 in the Handbook on Discrete
Optimization (G. Nemhauser K. Aardal and R. Weismantel  eds.)  Elsevier  2006  pp. 321–391.
[12] James B. Orlin  A faster strongly polynomial time algorithm for submodular function mini-

mization  Math. Program. 118 (2009)  no. 2  237–251.

[13] Alexander Schrijver  A combinatorial algorithm minimizing submodular functions in strongly

polynomial time  1999.

[14] Matthew J. Streeter and Daniel Golovin  An online algorithm for maximizing submodular func-

tions  NIPS  2008  pp. 1577–1584.

[15] Martin Zinkevich  Online convex programming and generalized inﬁnitesimal gradient ascent. 

Proceedings of the Twentieth International Conference (ICML)  2003  pp. 928–936.

9

,Naoto Ohsaka
Yuichi Yoshida