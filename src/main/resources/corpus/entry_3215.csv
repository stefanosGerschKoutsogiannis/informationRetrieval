2017,Limitations on Variance-Reduction and Acceleration Schemes for Finite Sums Optimization,We study the conditions under which one is able to efficiently apply variance-reduction and acceleration schemes on finite sums  problems. First  we show that perhaps surprisingly  the finite sum structure  by itself  is not sufficient for obtaining a complexity bound of $\tilde{\cO}((n+L/\mu)\ln(1/\epsilon))$ for $L$-smooth and $\mu$-strongly convex finite sums - one must also know exactly which individual function is being referred to by the oracle at each iteration. Next  we show that for a broad class of first-order and coordinate-descent finite sums algorithms (including  e.g.  SDCA  SVRG  SAG)  it is not possible to get an `accelerated' complexity bound of $\tilde{\cO}((n+\sqrt{n L/\mu})\ln(1/\epsilon))$  unless the strong convexity parameter is given explicitly. Lastly  we show that when this class of algorithms is used for minimizing $L$-smooth and non-strongly convex finite sums  the optimal complexity bound is $\tilde{\cO}(n+L/\epsilon)$  assuming that (on average) the same update rule is used for any iteration  and $\tilde{\cO}(n+\sqrt{nL/\epsilon})$  otherwise.,Limitations on Variance-Reduction and Acceleration

Schemes for Finite Sum Optimization

Department of Computer Science and Applied Mathematics

Yossi Arjevani

Weizmann Institute of Science

Rehovot 7610001  Israel

yossi.arjevani@weizmann.ac.il

Abstract

We study the conditions under which one is able to efﬁciently apply variance-
reduction and acceleration schemes on ﬁnite sum optimization problems. First  we
show that  perhaps surprisingly  the ﬁnite sum structure by itself  is not sufﬁcient
for obtaining a complexity bound of ˜O((n + L/µ) ln(1/)) for L-smooth and
µ-strongly convex individual functions - one must also know which individual
function is being referred to by the oracle at each iteration. Next  we show that for
a broad class of ﬁrst-order and coordinate-descent ﬁnite sum algorithms (including 
e.g.  SDCA  SVRG  SAG)  it is not possible to get an ‘accelerated’ complexity

bound of ˜O((n+(cid:112)nL/µ) ln(1/))  unless the strong convexity parameter is given
iteration  and Ω(n +(cid:112)nL/) otherwise.

explicitly. Lastly  we show that when this class of algorithms is used for minimizing
L-smooth and convex ﬁnite sums  the iteration complexity is bounded from below
by Ω(n + L/)  assuming that (on average) the same update rule is used in any

1

Introduction

An optimization problem principal to machine learning and statistics is that of ﬁnite sums:

min
w∈Rd

F (w) :=

1
n

n(cid:88)

i=1

fi(w) 

(1)

where the individual functions fi are assumed to possess some favorable analytical properties  such as
Lipschitz-continuity  smoothness or strong convexity (see [16] for details). We measure the iteration
complexity of a given optimization algorithm by determining how many evaluations of individual
functions (via some external oracle procedure  along with their gradient  Hessian  etc.) are needed in
order to obtain an -solution  i.e.  a point w ∈ Rd which satisﬁes E[F (w) − minw∈Rd F (w)] < 
(where the expectation is taken w.r.t. the algorithm and the oracle randomness).
Arguably  the simplest way of minimizing ﬁnite sum problems is by using optimization algorithms
for general optimization problems. For concreteness of the following discussion  let us assume for the
moment that the individual functions are L-smooth and µ-strongly convex. In this case  by applying
vanilla Gradient Descent (GD) or Accelerated Gradient Descent (AGD  [16])  one obtains iteration
complexity of

˜O(nκ ln(1/)) or ˜O(cid:0)n

κ ln(1/)(cid:1) 

√

(2)
respectively  where κ := L/µ denotes the condition number of the problem and ˜O hides logarithmic
factors in the problem parameters. However  whereas such bounds enjoy logarithmic dependence on

31st Conference on Neural Information Processing Systems (NIPS 2017)  Long Beach  CA  USA.

the accuracy level  the multiplicative dependence on n renders this approach unsuitable for modern
applications where n is very large.
A different approach to tackle a ﬁnite sum problem is by reformulating it as a stochastic optimization
problem  i.e.  minw∈Rd Ei∼U ([n])[fi(w)]  and then applying a general stochastic method  such

as SGD  which allows iteration complexity of O(1/) or O(cid:0)1/2(cid:1) (depending on the problem

parameters). These methods offer rates which do not depend on n  and are therefore attractive for
situations where one seeks for a solution of relatively low accuracy. An evident drawback of these
methods is their broad applicability for stochastic optimization problems  which may conﬂict with
the goal of efﬁciently exploiting the unique noise structure of ﬁnite sums (indeed  in the general
stochastic setting  these rates cannot be improved  e.g.  [1  18]).
In recent years  a major breakthrough was made when stochastic methods specialized in ﬁnite sums
(ﬁrst SAG [19] and SDCA [21]  and then SAGA [10]  SVRG [11]  SDCA without duality [20]  and
others) were shown to obtain iteration complexity of

˜O((n + κ) ln(1/)).

(3)
The ability of these algorithms to enjoy both logarithmic dependence on the accuracy parameter and
an additive dependence on n is widely attributed to the fact that the noise of ﬁnite sum problems
distributes over a ﬁnite set of size n. Perhaps surprisingly  in this paper we show that another key
ingredient is crucial  namely  a mean of knowing which individual function is being referred to by the
oracle at each iteration. In particular  this shows that variance-reduction mechanisms (see  e.g.  [10 
Section 3]) cannot be applied without explicitly knowing the ‘identity’ of the individual functions.
On the more practical side  this result shows that when data augmentation (e.g.  [14]) is done without
an explicit enumeration of the added samples  it is impossible to obtain iteration complexity as stated
in (3  see [7] for relevant upper bounds).
Although variance-reduction mechanisms are essential for obtaining an additive dependence on n (as
shown in (3))  they do not necessarily yield ‘accelerated’ rates which depend on the square root of
the condition number (as shown in (2) for AGD). Recently  generic acceleration schemes were used
by [13] and accelerated SDCA [22] to obtain iteration complexity of

(cid:17)

˜O(cid:16)

√

(n +

nk) ln(1/)

.

(4)

The question of whether this rate is optimal was answered afﬁrmatively by [23  12  5  3]. The ﬁrst
category of lower bounds exploits the degree of freedom offered by a d- (or an inﬁnite-) dimensional
space to show that any ﬁrst-order and a certain class of second-order methods cannot obtain better
rates than (4) in the regime where the number of iterations is less than O(d/n). The second category
of lower bounds is based on maintaining the complexity of the functional form of the iterates  thereby
establishing bounds for ﬁrst-order and coordinate-descent algorithms whose step sizes are oblivious
to the problem parameters (e.g.  SAG  SAGA  SVRG  SDCA  SDCA without duality) for any number
of iterations  regardless of d and n.
In this work  we further extend the theory of oblivious ﬁnite sum algorithms  by showing that if
a ﬁrst-order and a coordinate-descent oracle are used  then acceleration is not possible without
an explicit knowledge of the strong convexity parameter. This implies that in cases where only
poor estimation of the strong convexity is available  faster rates may be obtained through ‘adaptive’
algorithms (see relevant discussions in [19  4]).
Next  we show that in the smooth and convex case  oblivious ﬁnite sum algorithms which  on average 
apply the same update rule at each iteration (e.g.  SAG  SDCA  SVRG  SVRG++ [2]  and typically 
other algorithms with a variance-reduction mechanism as described in [10  Section 3])  are bound
to iteration complexity of Ω(n + L/)  where L denotes the smoothness parameter (rather than

Ω(n +(cid:112)nL/)). To show this  we employ a restarting scheme (see [4]) which explicitly introduces

the strong convexity parameter into algorithms that are designed for smooth and convex functions.
Finally  we use this scheme to establish a tight dimension-free lower bound for smooth and convex
ﬁnite sums which holds for oblivious algorithms with a ﬁrst-order and a coordinate-descent oracle.
To summarize  our contributions (in order of appearance) are the following:

• In Section 2  we prove that in the setting of stochastic optimization  having ﬁnitely supported
noise (as in ﬁnite sum problems) is not sufﬁcient for obtaining linear convergence rates with

2

a linear dependence on n - one must also know exactly which individual function is being
referred to by the oracle at each iteration. Deriving similar results for various settings  we
show that SDCA  accelerated SDCA  SAG  SAGA  SVRG  SVRG++ and other ﬁnite sum
algorithms must have a proper enumeration of the individual functions in order to obtain
their stated convergence rate.
• In Section 3.1  we lay the foundations of the framework of general CLI algorithms (see
[3])  which enables us to formally address oblivious algorithms (e.g.  when step sizes are
scheduled regardless of the function at hand). In section 3.2  we improve upon [4]  by
showing that (in this generalized framework) the optimal iteration complexity of oblivious 
deterministic or stochastic  ﬁnite sum algorithms with both ﬁrst-order and coordinate-descent
oracles cannot perform better than Ω(n + κ ln(1/))  unless the strong convexity parameter
is provided explicitly. In particular  the richer expressiveness power of this framework
allows addressing incremental gradient methods  such as Incremental Gradient Descent [6]
and Incremental Aggregated Gradient [8  IAG].
• In Section 3.3  we show that  in the L-smooth and convex case  the optimal complexity
bound (in terms of the accuracy parameter) of oblivious algorithms whose update rules are

(on average) ﬁxed for any iteration is Ω(n + L/) (rather then ˜O(n +(cid:112)nL/)  as obtained 

e.g.  by accelerated SDCA). To show this  we ﬁrst invoke a restarting scheme (used by [4])
to explicitly introduce strong convexity into algorithms for ﬁnite sums with smooth and
convex individuals  and then apply the result derived in Section 3.2.
• In Section 3.4  we use the reduction introduced in Section 3.3  to show that the optimal itera-
tion complexity of minimizing L-smooth and convex ﬁnite sums using oblivious algorithms
equipped with a ﬁrst-order and a coordinate-descent oracle is Ω

(cid:17)
n +(cid:112)nL/

(cid:16)

.

2 The Importance of Individual Identity

In the following  we address the stochastic setting of ﬁnite sum problems (1) where one is equipped
with a stochastic oracle which  upon receiving a call  returns some individual function chosen
uniformly at random and hides its index. We show that not knowing the identity of the function
returned by the oracle (as opposed to an incremental oracle which addresses the speciﬁc individual
functions chosen by the user)  signiﬁcantly harms the optimal attainable performance. To this end 
we reduce the statistical problem of estimating the bias of a noisy coin into that of optimizing ﬁnite
sums. This reduction (presented below) makes an extensive use of elementary deﬁnitions and tools
from information theory  all of which can be found in [9].
First  given n ∈ N  we deﬁne the following ﬁnite sum problem
n + σ

(5)
where n is w.l.o.g. assumed to be odd  σ ∈ {−1  1} and f +  f− are some functions (to be deﬁned
later). We then deﬁne the following discrepancy measure between F1 and F−1 for different values
of n (see also [1]) 

(cid:18) n − σ

f−(cid:19)

Fσ :=

f + +

1
n

2

2

 

δ(n) = min
w∈Rd

{F1(w) + F−1(w) − F ∗

1 − F ∗

−1} 

(6)

where F ∗
σ := inf w Fσ(w). It is easy to verify that no solution can be δ(n)/4-optimal for both
F1 and F−1  at the same time. Thus  by running a given optimization algorithm long enough to
obtain δ(n)/4-solution w.h.p.  we can deduce the value of σ. Also  note that  one can simplify the
computation of δ(n) by choosing convex f +  f− such that f +(w) = f−(−w). Indeed  in this case 
we have F1(w) = F−1(−w) (in particular  F ∗
−1 is
convex  it must attain its minimum at w = 0  which yields
δ(n) = 2(F1(0) − F ∗
1 ).

(7)
Next  we let σ ∈ {−1  1} be drawn uniformly at random  and then use the given optimization
algorithm to estimate the bias of a random variable X which  conditioned on σ  takes +1 w.p.
1/2 + σ/2n  and −1 w.p. 1/2 − σ/2n. To implement the stochastic oracle described above 

−1)  and since F1(w) + F−1(w) − F ∗

1 = F ∗

1 − F ∗

3

conditioned on σ  we draw k i.i.d. copies of X  denoted by X1  . . .   Xk  and return f−  if Xi = σ 
and f +  otherwise. Now  if k is such that

for both σ = −1 and σ = 1  then by Markov inequality  we have that

E[Fσ(w(k)) − F ∗

σ | σ] ≤ δ(n)
40

 

P(cid:16)

Fσ(w(k)) − F ∗

σ ≥ δ(n)/4

(cid:17) ≤ 1/10

(cid:12)(cid:12)(cid:12) σ

(8)

(note that Fσ(w(k)) − F ∗
σ using the following estimator

σ is a non-negative random variable). We may now try to guess the value of

ˆσ(w(k)) = argmin
σ(cid:48)∈{−1 1}

{Fσ(cid:48)(w(k)) − F ∗

σ(cid:48)} 

whose probability of error  as follows by Inequality (8)  is
P (ˆσ (cid:54)= σ) ≤ 1/10.

(9)

Lastly  we show that the existence of an estimator for σ with high probability of success implies
that k = Ω(n2). To this end  note that the corresponding conditional dependence structure of this
probabilistic setting can be modeled as follows: σ → X1  . . .   Xk → ˆσ. Thus  we have

H(σ | X1  . . .   Xk)

(a)≤ H(σ | ˆσ)

(10)
where H(·) and Hb(·) denote the Shannon entropy function and the binary entropy function  respec-
tively  (a) follows by the data processing inequality (in terms of entropy)  (b) follows by Fano’s
inequality and (c) follows from Equation (9). Applying standard entropy identities  we get

 

(b)≤ Hb(P (ˆσ (cid:54)= σ))

(c)≤ 1
2

H(σ | X1  . . .   Xk)

(e)

(d)

= H(X1  . . .   Xk | σ) + H(σ) − H(X1  . . .   Xk)
= kH(X1 | σ) + 1 − H(X1  . . .   Xk)
(f )≥ kH(X1 | σ) + 1 − kH(X1) 

(11)
where (d) follows from Bayes rule  (e) follows by the fact that Xi  conditioned on σ  are i.i.d. and
(f ) follows from the chain rule and the fact that conditioning reduces entropy. Combining this with
Inequality (10) and rearranging  we have

k ≥

1

2(H(X1) − H(X1 | σ))

≥

1

2 (1/n)2 =

n2
2

 

where the last inequality follows from the fact that H(X1) = 1 and the following estimation for the
binary entropy function: Hb(p) ≥ 1 − 4 (p − 1/2)2 (see Lemma 2  Appendix A). Thus  we arrive at
the following statement.
Lemma 1. The minimal number of stochastic oracle calls required to obtain δ(n)/40-optimal
solution for problem (5) is ≥ n2/2.
Instantiating this schemes for f +  f− of various analytical properties yields the following.
Theorem 1. When solving a ﬁnite sum problem (deﬁned in 1) with a stochastic oracle  one needs at
least n2/2 oracle calls in order to obtain an accuracy level of:

1. κ+1

2.

L

40n2 for smooth and strongly convex individuals with condition κ.
40n2 for L-smooth and convex individuals.
40λn2 if M
convex individuals.

λn ≤ 1  and M

20n − λ

3. M 2

40   otherwise  for (M + λ)-Lipschitz continuous and λ-strongly

4

Proof

1. Deﬁne 

f±(w) =

(w ± q)

(cid:62)

A (w ± q)  

1
2

where A is a d × d diagonal matrix whose diagonal entries are κ  1 . . .   1  and q =
(1  1  0  . . .   0)(cid:62) is a d-dimensional vector. One can easily verify that f± are smooth
and strongly convex functions with condition number κ  and that

(cid:16)

(cid:17)(cid:62)

(cid:16)

(cid:17)

(cid:18)

(cid:19)

Fσ(w) =

1
2

w − σ
n

q

A

w − σ
n

q

+

1
2

1 − 1
n2

q(cid:62)Aq.

Therefore  the minimizer of Fσ is (σ/n)q  and using Equation (7)  we see that δ(n) = κ+1
n2 .

2. We deﬁne

f±(w) =

L
2

(cid:107)w ± e1(cid:107)2 .

One can easily verify that f± are L-smooth and convex functions  and that the minimizer of
Fσ is (σ/n)e1. By Equation (7)  we get δ(n) = L
n2 .

3. We deﬁne

f±(w) = M(cid:107)w ± e1(cid:107) +

(cid:107)w(cid:107)2  

λ
2

over the unit ball. Clearly  f± are (M + λ)-Lipschitz continuous and λ-strongly convex
functions. It can be veriﬁed that the minimizer of Fσ is (σ min{ M
λn   1})e1. Therefore  by
Equation (7)  we see that in this case we have

(cid:40) M 2
n − λ o.w.

λn2
2M

M

λn ≤ 1

.

δ(n) =

A few conclusions can be readily made from Theorem 1. First  if a given optimization algorithm
obtains an iteration complexity of an order of c(n  κ) ln(1/)  up to logarithmic factors (including
the norm of the minimizer which  in our construction  is of an order of 1/n and coupled with the
accuracy parameter)  for solving smooth and strongly convex ﬁnite sum problems with a stochastic
oracle  then

(cid:18)

(cid:19)

.

c(n  κ) = ˜Ω

n2

ln(n2/(κ + 1))

Thus  the following holds for optimization of ﬁnite sums with smooth and strongly convex individuals.
Corollary 1. In order to obtain linear convergence rate with linear dependence on n  one must know
the index of the individual function addressed by the oracle.

This implies that variance-reduction methods such as  SAG  SAGA  SDCA and SVRG (possibly
combining with acceleration schemes)  which exhibit linear dependence on n  cannot be applied
when data augmentation is used. In general  this conclusion also holds for cases when one applies
general ﬁrst-order optimization algorithms  such as AGD  on ﬁnite sums  as this typically results in a
linear dependence on n. Secondly  if a given optimization algorithm obtains an iteration complexity
of an order of n + Lβ(cid:107)w(0) − w∗(cid:107)2/α for solving smooth and convex ﬁnite sum problems with
a stochastic oracle  then n + Lβ−αn2(α−1) = Ω(n2). Therefore  β = α and α ≥ 2  indicating that
an iteration complexity of an order of n + L(cid:107)w(0) − w∗(cid:107)2/  as obtained by  e.g.  SVRG++  is not
attainable with a stochastic oracle. Similar reasoning based on the Lipschitz and strongly convex
case in Theorem 1 shows that the iteration complexity guaranteed by accelerated SDCA is also not
attainable in this setting.

5

3 Oblivious Optimization Algorithms

In the previous section  we discussed different situations under which variance-reduction schemes are
not applicable. Now  we turn to study under what conditions can one apply acceleration schemes.
First  we deﬁne the framework of oblivious CLI algorithms. Next  we show that  for this family of
algorithms  knowing the strong convexity parameter is crucial for obtaining accelerated rates. We then
describe a restarting scheme through which we establish that stationary algorithms (whose update
rule are  on average  the same for every iteration) for smooth and convex functions are sub-optimal.
Finally  we use this reduction to derive a tight lower bound for smooth and convex ﬁnite sums on the
iteration complexity of any oblivious algorithm (not just stationary).

3.1 Framework

In the sequel  following [3]  we present the analytic framework through which we derive iteration
complexity bounds. This  perhaps pedantic  formulation will allows us to study somewhat subtle
distinctions between optimization algorithms. First  we give a rigorous deﬁnition for a class of
optimization problems which emphasizes the role of prior knowledge in optimization.
Deﬁnition 1 (Class of Optimization Problems). A class of optimization problems is an ordered triple
(F I  Of )  where F is a family of functions deﬁned over some domain designated by dom(F)  I is
the side-information given prior to the optimization process and Of is a suitable oracle procedure
which upon receiving w ∈ domF and θ in some parameter set Θ  returns Of (w  θ) ⊆ dom(F) for a
given f ∈ F (we shall omit the subscript in Of when f is clear from the context).
In ﬁnite sum problems  F comprises of functions as deﬁned in (1); the side-information may contain
the smoothness parameter L  the strong convexity parameter µ and the number of individual functions
n; and the oracle may allow one to query about a speciﬁc individual function (as in the case of
incremental oracle  and as opposed to the stochastic oracle discussed in Section 2). We now turn to
deﬁne CLI optimization algorithms (see [3] for a more comprehensive discussion).
Deﬁnition 2 (CLI). An optimization algorithm is called a Canonical Linear Iterative (CLI) opti-
mization algorithm over a class of optimization problems (F I  Of )  if given an instance f ∈ F
and initialization points {w(0)
i }i∈J ⊆ dom(F)  where J is some index set  it operates by iteratively
generating points such that for any i ∈ J  
Of

∈(cid:88)

k = 0  1  . . .

w(k+1)

(cid:16)

w(k)

j

; θ(k)
ij

 

(cid:17)

(12)

i

j∈J

ij ∈ Θ are parameters chosen  stochastically or deterministically  by the algorithm 
holds  where θ(k)
possibly based on the side-information. If the parameters do not depend on previously acquired
oracle answers  we say that the given algorithm is oblivious. For notational convenience  we assume
that the solution returned by the algorithm is stored in w(k)
1 .

Throughout the rest of the paper  we shall be interested in oblivious CLI algorithms (for brevity  we
usually omit the ‘CLI’ qualiﬁer) equipped with the following two incremental oracles:
Generalized ﬁrst-order oracle: O(w; A  B  c  i) := A∇fi(w) + Bw + c 
Steepest coordinate-descent oracle: O(w; j  i) := w + t∗ej 

(13)
where A  B ∈ Rd×d  c ∈ Rd  i ∈ [n]  j ∈ [d]  ej denotes the j’th d-dimensional unit vector and
t∗ ∈ argmint∈R fj(w1  . . .   wj−1  wj + t  wj+1  . . .   wd). We restrict the oracle parameters such
that only one individual function is allowed to be accessed at each iteration. We remark that the family
of oblivious algorithms with a ﬁrst-order and a coordinate-descent oracle is wide and subsumes
SAG  SAGA  SDCA  SDCA without duality  SVRG  SVRG++ to name a few. Also  note that
coordinate-descent steps w.r.t. partial gradients can be implemented using the generalized ﬁrst-order
oracle by setting A to be some principal minor of the unit matrix (see  e.g.  RDCM in [15]). Further 
similarly to [3]  we allow both ﬁrst-order and coordinate-descent oracles to be used during the same
optimization process.

3.2 No Strong Convexity Parameter  No Acceleration for Finite Sum Problems

Having described our analytic approach  we now turn to present some concrete applications. Below 
we show that in the absence of a good estimation for the strong convexity parameter  the optimal

6

iteration complexity of oblivious algorithms is Ω(n + k ln(1/)). Our proof is based on the technique
used in [3  4] (see [3  Section 2.3] for a brief introduction of the technique).
Given 0 <  < L  we deﬁne the following set of optimization problems (over Rd with d > 1)

(cid:18) 1

n(cid:88)

2

i=1

L+µ
µ−L

2

2

Fµ(w) :=

Qµ :=

1
n



(cid:19)

µ

w(cid:62)Qµw − q(cid:62)w
µ−L

2

L+µ

2

µ

...

(14)

  where

   q :=

  



1
1
0

...

0

R√
2

√

2  R/µ

parametrized by µ ∈ (  L) (note that the individual functions are identical. We elaborate more
√
on this below). It can be easily veriﬁed that the condition number of Fµ  which we denote by
κ(Fµ)  is L/µ  and that the corresponding minimizers are w∗(µ) = (R/µ
2  0  . . .   0)(cid:62)
with norm ≤ R.
If we are allowed to use different optimization algorithm for different µ in this setting  then we know

that the optimal iteration complexity is of an order of (n +(cid:112)nκ(Fµ)) ln(1/). However  if we

allowed to use only one single algorithm  then we show that the optimal iteration complexity is of an
order of n + κ(Fµ) ln(1/). The proof goes as follows. First  note that in this setting  the oracles
deﬁned in (13) take the following form 
Generalized ﬁrst-order oracle: O(w; A  B  c  i) = A(Qµw − q) + Bw + c 
(15)
Steepest coordinate-descent oracle: O(w; j  i) = (I − (1/(Qµ)jj)ei(Qµ)j ∗) w − qj/(Qµ)jjej.
Now  since the oracle answers are linear in µ and the k’th iterate is a k-fold composition of sums of
the oracle answers  it follows that w(k)
forms a d-dimensional vector of univariate polynomials in µ
of degree ≤ k with (possibly random) coefﬁcients (formally  see Lemma 3  Appendix A). Denoting
the polynomial of the ﬁrst coordinate of Ew(k)

1

1 (µ) by s(µ)  we see that for any µ ∈ (  L) 
2s(µ)µ
R

2L

2µ

− 1

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)√

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)  

E(cid:107)w(k)

1 (µ) − w∗(µ)(cid:107) ≥ (cid:107)Ew(k)

1 (µ) − w∗(µ)(cid:107) ≥

where the ﬁrst inequality follows by Jensen inequality and the second inequality by focusing on the
ﬁrst coordinate of Ew(k)(η) and w∗(η). Lastly  since the coefﬁcients of s(µ) do not depend on µ 
we have by Lemma 4 in Appendix A  that there exists δ > 0  such that for any µ ∈ (L − δ  L) it
holds that

(cid:12)(cid:12)(cid:12)(cid:12)s(µ) − R√
(cid:18)

1 − 1

κ(Fµ)

(cid:12)(cid:12)(cid:12)(cid:12) ≥ R√
(cid:19)k+1

 

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)√

R√
2L

2s(µ)µ
R

− 1

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) ≥ R√

2L

by which we derive the following.
Theorem 2. The iteration complexity of oblivious ﬁnite sum optimization algorithms equipped with
a ﬁrst-order and a coordinate-descent oracle whose side-information does not contain the strong
convexity parameter is ˜Ω(n + κ ln(1/)).

The n part of the lower bound holds for any type of ﬁnite sum algorithm and is proved in [3  Theorem
5]. The lower bound stated in Theorem 2 is tight up to logarithmic factors and is attained by  e.g. 
SAG [19]. Although relying on a ﬁnite sum with identical individual functions may seem somewhat
disappointing  it suggests that some variance-reduction schemes can only give optimal dependence
in terms of n  and that obtaining optimal dependence in terms of the condition number need to be
done through other (acceleration) mechanisms (e.g.  [13]). Lastly  note that  this bound holds for any
number of iterations (regardless of the problem parameters).

3.3 Stationary Algorithms for Smooth and Convex Finite Sums are Sub-optimal

In the previous section  we showed that not knowing the strong convexity parameter reduces the
optimal attainable iteration complexity. In this section  we use this result to show that whereas general

7

˜O(n +(cid:112)nL/)  the optimal iteration complexity of stationary algorithms (whose expected update

optimization algorithms for smooth and convex ﬁnite sum problems obtain iteration complexity of

rules are ﬁxed) is Ω(n + L/).
The proof (presented below) is based on a general restarting scheme (see Scheme 1) used in [4]. The
scheme allows one to apply algorithms which are designed for L-smooth and convex problems on
smooth and strongly convex ﬁnite sums by explicitly incorporating the strong convexity parameter.
The key feature of this reduction is its ability to ‘preserve’ the exponent of the iteration complexity
from an order of C(f )(L/)α in the non-strongly convex case to an order of (C(f )κ)α ln(1/) in
the strongly convex case  where C(f ) denotes some quantity which may depend on f but not on k 
and α is some positive constant.

SCHEME 1
GIVEN

ITERATE

END

RESTARTING SCHEME
AN OPTIMIZATION ALGORITHM A
FOR SMOOTH CONVEX FUNCTIONS WITH

(cid:13)(cid:13)(cid:13) ¯w(0)−w∗(cid:13)(cid:13)(cid:13)2

f (w(k)) − f∗ ≤ C(f )
FOR ANY INITIALIZATION POINT ¯w0

kα

FOR t = 1  2  . . .

RESTART THE STEP SIZE SCHEDULE OF A
INITIALIZE A AT ¯w(0)

RUN A FOR α(cid:112)4C(f )/µ ITERATIONS

SET ¯w(0) TO BE THE POINT RETURNED BY A

The proof goes as follows. Suppose A is a stationary CLI optimization algorithm for L-smooth and
convex ﬁnite sum problems equipped with oracles (13). Also  assume that its convergence rate for
k ≥ N  N ∈ N is of an order of nγ Lβ(cid:107)w(0)−w∗(cid:107)2
  for some α  β  γ > 0. First  observe that in
this case we must have β = 1. For otherwise  we get f (w(k)) − f∗ = ((νf )(w(k)) − (νf )∗)/ν ≤
nγ(νL)β/νkα = νβ−1nγLβ/kα  implying that  simply by scaling f  one can optimize to any level
of accuracy using at most N iterations  which contradicts [3  Theorem 5]. Now  by [4  Lemma 1] 
Scheme 1 produces a new algorithm whose iteration complexity for smooth and strongly convex
ﬁnite sums with condition number κ is

kα

O(N + nγ (L/)α) −→ ˜O(n + nγκα ln(1/)).

(16)
Finally  stationary algorithms are invariant under this restarting scheme. Therefore  the new algorithm
cannot depend on µ. Thus  by Theorem 2  it must hold that that α ≥ 1 and that max{N  nγ} = Ω(n) 
proving the following.
Theorem 3. If the iteration complexity of a stationary optimization algorithm for smooth and convex
ﬁnite sum problems equipped with a ﬁrst-order and a coordinate-descent oracle is of the form of the
l.h.s. of (16)  then it must be at least Ω(n + L/).

We note that  this lower bound is tight and is attained by  e.g.  SDCA.

3.4 A Tight Lower Bound for Smooth and Convex Finite Sums

We now turn to derive a lower bound for ﬁnite sum problems with smooth and convex individual
functions using the restarting scheme shown in the previous section. Note that  here we allow
any oblivious optimization algorithm  not just stationary. The technique shown in Section 3.2 of
reducing an optimization problem into a polynomial approximation problem was used in [3] to derive
lower bounds for various settings. The smooth and convex case was proved only for n = 1  and
a generalization for n > 1 seems to reduce to a non-trivial approximation problem. Here  using
Scheme 1  we are able to avoid this difﬁculty by reducing the non-strongly case to the strongly convex
case  for which a lower bound for a general n is known.
The proof follows the same lines of the proof of Theorem 3. Given an oblivious optimization
algorithm for ﬁnite sums with smooth and convex individuals equipped with oracles (13)  we apply
again Scheme 1 to get an algorithm for the smooth and strongly convex case  whose iteration
complexity is as in (16). Now  crucially  oblivious algorithm are invariant under Scheme 1 (that

8

is  when applied on a given oblivious algorithm  Scheme 1 produces another oblivious algorithm).
Therefore  using [3  Theorem 2]  we obtain the following.
Theorem 4. If the iteration complexity of an oblivious optimization algorithm for smooth and convex
ﬁnite sum problems equipped with a ﬁrst-order and a coordinate-descent oracle is of the form of the
l.h.s. of (16)  then it must be at least

Ω

n +

nL


.

(cid:32)

(cid:114)

(cid:33)

This bound is tight and is obtained by  e.g.  accelerated SDCA [22]. Optimality in terms of L and 
can be obtained simply by applying Accelerate Gradient Descent [16]  or alternatively  by using
an accelerated version of SVRG as presented in [17]. More generally  one can apply acceleration
schemes  e.g.  [13]  to get an optimal dependence on .

Acknowledgments

We thank Raanan Tvizer and Maayan Maliach for several helpful and insightful discussions.

References
[1] Alekh Agarwal  Martin J Wainwright  Peter L Bartlett  and Pradeep K Ravikumar. Information-
theoretic lower bounds on the oracle complexity of convex optimization. In Advances in Neural
Information Processing Systems  pages 1–9  2009.

[2] Zeyuan Allen-Zhu and Yang Yuan. Improved svrg for non-strongly-convex or sum-of-non-

convex objectives. Technical report  Technical report  arXiv preprint  2016.

[3] Yossi Arjevani and Ohad Shamir. Dimension-free iteration complexity of ﬁnite sum optimization

problems. In Advances in Neural Information Processing Systems  pages 3540–3548  2016.

[4] Yossi Arjevani and Ohad Shamir. On the iteration complexity of oblivious ﬁrst-order optimiza-
tion algorithms. In Proceedings of the 33nd International Conference on Machine Learning 
pages 908–916  2016.

[5] Yossi Arjevani and Ohad Shamir. Oracle complexity of second-order methods for ﬁnite-sum

problems. arXiv preprint arXiv:1611.04982  2016.

[6] Dimitri P Bertsekas. A new class of incremental gradient methods for least squares problems.

SIAM Journal on Optimization  7(4):913–926  1997.

[7] Alberto Bietti and Julien Mairal. Stochastic optimization with variance reduction for inﬁnite

datasets with ﬁnite-sum structure. arXiv preprint arXiv:1610.00970  2016.

[8] Doron Blatt  Alfred O Hero  and Hillel Gauchman. A convergent incremental gradient method

with a constant step size. SIAM Journal on Optimization  18(1):29–51  2007.

[9] Thomas M Cover and Joy A Thomas. Elements of information theory. John Wiley & Sons 

2012.

[10] Aaron Defazio  Francis Bach  and Simon Lacoste-Julien. Saga: A fast incremental gradient
method with support for non-strongly convex composite objectives. In Advances in Neural
Information Processing Systems  pages 1646–1654  2014.

[11] Rie Johnson and Tong Zhang. Accelerating stochastic gradient descent using predictive variance

reduction. In Advances in Neural Information Processing Systems  pages 315–323  2013.

[12] Guanghui Lan. An optimal randomized incremental gradient method.

arXiv:1507.02000  2015.

arXiv preprint

[13] Hongzhou Lin  Julien Mairal  and Zaid Harchaoui. A universal catalyst for ﬁrst-order optimiza-

tion. In Advances in Neural Information Processing Systems  pages 3366–3374  2015.

9

[14] Gaëlle Loosli  Stéphane Canu  and Léon Bottou. Training invariant support vector machines

using selective sampling. Large scale kernel machines  pages 301–320  2007.

[15] Yu Nesterov. Efﬁciency of coordinate descent methods on huge-scale optimization problems.

SIAM Journal on Optimization  22(2):341–362  2012.

[16] Yurii Nesterov. Introductory lectures on convex optimization  volume 87. Springer Science &

Business Media  2004.

[17] Atsushi Nitanda. Accelerated stochastic gradient descent for minimizing ﬁnite sums.

Artiﬁcial Intelligence and Statistics  pages 195–203  2016.

In

[18] Maxim Raginsky and Alexander Rakhlin. Information-based complexity  feedback and dynam-
ics in convex programming. Information Theory  IEEE Transactions on  57(10):7036–7056 
2011.

[19] Mark Schmidt  Nicolas Le Roux  and Francis Bach. Minimizing ﬁnite sums with the stochastic

average gradient. Mathematical Programming  pages 1–30  2013.

[20] Shai Shalev-Shwartz. Sdca without duality. arXiv preprint arXiv:1502.06177  2015.

[21] Shai Shalev-Shwartz and Tong Zhang. Stochastic dual coordinate ascent methods for regularized

loss. The Journal of Machine Learning Research  14(1):567–599  2013.

[22] Shai Shalev-Shwartz and Tong Zhang. Accelerated proximal stochastic dual coordinate ascent

for regularized loss minimization. Mathematical Programming  155(1-2):105–145  2016.

[23] Blake E Woodworth and Nati Srebro. Tight complexity bounds for optimizing composite

objectives. In Advances in Neural Information Processing Systems  pages 3639–3647  2016.

10

,Thibaut Lienart
Yee Whye Teh
Arnaud Doucet
William Montgomery
Sergey Levine
Yossi Arjevani
Amir Khoshaman
Mohammad Amin