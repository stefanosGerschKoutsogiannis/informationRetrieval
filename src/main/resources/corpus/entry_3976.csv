2015,On the Global Linear Convergence of Frank-Wolfe Optimization Variants,The Frank-Wolfe (FW) optimization algorithm has lately re-gained popularity thanks in particular to its ability to nicely handle the structured constraints appearing in machine learning applications. However  its convergence rate is known to be slow (sublinear) when the solution lies at the boundary. A simple less-known fix is to add the possibility to take `away steps' during optimization  an operation that importantly does not require a feasibility oracle. In this paper  we highlight and clarify several variants of the Frank-Wolfe optimization algorithm that has been successfully applied in practice: FW with away steps  pairwise FW  fully-corrective FW and Wolfe's minimum norm point algorithm  and prove for the first time that they all enjoy global linear convergence under a weaker condition than strong convexity. The constant in the convergence rate has an elegant interpretation as the product of the (classical) condition number of the function with a novel geometric quantity that plays the role of the `condition number' of the constraint set. We provide pointers to where these algorithms have made a difference in practice  in particular with the flow polytope  the marginal polytope and the base polytope for submodular optimization.,On the Global Linear Convergence

of Frank-Wolfe Optimization Variants

Simon Lacoste-Julien

INRIA - SIERRA project-team

´Ecole Normale Sup´erieure  Paris  France

Martin Jaggi

Dept. of Computer Science
ETH Z¨urich  Switzerland

Abstract

The Frank-Wolfe (FW) optimization algorithm has lately re-gained popularity
thanks in particular to its ability to nicely handle the structured constraints ap-
pearing in machine learning applications. However  its convergence rate is known
to be slow (sublinear) when the solution lies at the boundary. A simple less-
known ﬁx is to add the possibility to take ‘away steps’ during optimization  an
operation that importantly does not require a feasibility oracle. In this paper  we
highlight and clarify several variants of the Frank-Wolfe optimization algorithm
that have been successfully applied in practice: away-steps FW  pairwise FW 
fully-corrective FW and Wolfe’s minimum norm point algorithm  and prove for
the ﬁrst time that they all enjoy global linear convergence  under a weaker condi-
tion than strong convexity of the objective. The constant in the convergence rate
has an elegant interpretation as the product of the (classical) condition number of
the function with a novel geometric quantity that plays the role of a ‘condition
number’ of the constraint set. We provide pointers to where these algorithms have
made a difference in practice  in particular with the ﬂow polytope  the marginal
polytope and the base polytope for submodular optimization.

The Frank-Wolfe algorithm [9] (also known as conditional gradient) is one of the earliest existing
methods for constrained convex optimization  and has seen an impressive revival recently due to
its nice properties compared to projected or proximal gradient methods  in particular for sparse
optimization and machine learning applications.
On the other hand  the classical projected gradient and proximal methods have been known to exhibit
a very nice adaptive acceleration property  namely that the the convergence rate becomes linear for
strongly convex objective  i.e. that the optimization error of the same algorithm after t iterations will
decrease geometrically with O((1 − ρ)t) instead of the usual O(1/t) for general convex objective
functions.
It has become an active research topic recently whether such an acceleration is also
possible for Frank-Wolfe type methods.
Contributions. We clarify several variants of the Frank-Wolfe algorithm and show that they all
converge linearly for any strongly convex function optimized over a polytope domain  with a con-
stant bounded away from zero that only depends on the geometry of the polytope. Our analysis does
not depend on the location of the true optimum with respect to the domain  which was a disadvan-
tage of earlier existing results such as [34  12  5]  and the newer work of [28]  as well as the line of
work of [1  19  26] which rely on Robinson’s condition [30]. Our analysis yields a weaker sufﬁcient
condition than Robinson’s condition; in particular we can have linear convergence even in some
cases when the function has more than one global minima  and is not globally strongly convex. The
constant also naturally separates as the product of the condition number of the function with a novel
notion of condition number of a polytope  which might have applications in complexity theory.
Related Work. For the classical Frank-Wolfe algorithm  [5] showed a linear rate for the special
case of quadratic objectives when the optimum is in the strict interior of the domain  a result already
subsumed by the more general [12]. The early work of [23] showed linear convergence for strongly

1

convex constraint sets  under the strong requirement that the gradient norm is not too small (see [11]
for a discussion). The away-steps variant of the Frank-Wolfe algorithm  that can also remove weight
from ‘bad’ atoms in the current active set  was proposed in [34]  and later also analyzed in [12].
The precise method is stated below in Algorithm 1. [12] showed a (local) linear convergence rate
on polytopes  but the constant unfortunately depends on the distance between the solution and its
relative boundary  a quantity that can be arbitrarily small. More recently  [1  19  26] have obtained
linear convergence results in the case that the optimum solution satisﬁes Robinson’s condition [30].
In a different recent line of work  [10  22] have studied a variation of FW that repeatedly moves mass
from the worst vertices to the standard FW vertex until a speciﬁc condition is satisﬁed  yielding a
linear rate on strongly convex functions. Their algorithm requires the knowledge of several constants
though  and moreover is not adaptive to the best-case scenario  unlike the Frank-Wolfe algorithm
with away steps and line-search. None of these previous works was shown to be afﬁne invariant 
and most require additional knowledge about problem speciﬁc parameters.
Setup. We consider general constrained convex optimization problems of the form:
with only access to: LMOA(r) ∈ arg min
x∈A

f (x)   M = conv(A) 

(cid:104)r  x(cid:105) 

min
x∈M

(1)
where A ⊆ Rd is a ﬁnite set of vectors that we call atoms.1 We assume that the function f is µ-
strongly convex with L-Lipschitz continuous gradient over M. We also consider weaker conditions
than strong convexity for f in Section 4. As A is ﬁnite  M is a (convex and bounded) polytope. The
methods that we consider in this paper only require access to a linear minimization oracle LMOA(.)
associated with the domain M through a generating set of atoms A. This oracle is deﬁned as to
return a minimizer of a linear subproblem over M = conv(A)  for any given direction r ∈ Rd.2
Examples. Optimization problems of the form (1) appear widely in machine learning and signal
processing applications. The set of atoms A can represent combinatorial objects of arbitrary type.
Efﬁcient linear minimization oracles often exist in the form of dynamic programs or other combina-
torial optimization approaches. As an example from tracking in computer vision  A could be the set
of integer ﬂows on a graph [16  7]  where LMOA can be efﬁciently implemented by a minimum cost
network ﬂow algorithm. In this case  M can also be described with a polynomial number of linear
inequalities. But in other examples  M might not have a polynomial description in terms of linear
inequalities  and testing membership in M might be much more expensive than running the linear
oracle. This is the case when optimizing over the base polytope  an object appearing in submodular
function optimization [3]. There  the LMOA oracle is a simple greedy algorithm. Another example
is when A represents the possible consistent value assignments on cliques of a Markov random ﬁeld
(MRF); M is the marginal polytope [32]  where testing membership is NP-hard in general  though
efﬁcient linear oracles exist for some special cases [17]. Optimization over the marginal polytope
appears for example in structured SVM learning [21] and variational inference [18].
The Original Frank-Wolfe Algorithm. The Frank-Wolfe (FW) optimization algorithm [9]  also
known as conditional gradient [23]  is particularly suited for the setup (1) where M is only accessed
through the linear minimization oracle. It works as follows: At a current iterate x(t)  the algorithm
ﬁnds a feasible search atom st to move towards by minimizing the linearization of the objective
function f over M (line 3 in Algorithm 1) – this is where the linear minimization oracle LMOA
is used. The next iterate x(t+1) is then obtained by doing a line-search on f between x(t) and st
(line 11 in Algorithm 1). One reason for the recent increased popularity of Frank-Wolfe-type algo-
as x(t) = (cid:80)
rithms is the sparsity of their iterates: in iteration t of the algorithm  the iterate can be represented
as a sparse convex combination of at most t + 1 atoms S (t) ⊆ A of the domain M  which we write
v v. We write S (t) for the active set  containing the previously discovered
search atoms sr for r < t that have non-zero weight α(t)
sr > 0 in the expansion (potentially also
including the starting point x(0)). While tracking the active set S (t) is not necessary for the original
FW algorithm  the improved variants of FW that we discuss will require that S (t) is maintained.
Zig-Zagging Phenomenon. When the optimal solution lies at the boundary of M  the conver-

gence rate of the iterates is slow  i.e. sublinear: f (x(t))− f (x∗) ≤ O(cid:0)1/t(cid:1)  for x∗ being an optimal

v∈S (t) α(t)

solution [9  6  8  15]. This is because the iterates of the classical FW algorithm start to zig-zag

1The atoms do not have to be extreme points (vertices) of M.
2All our convergence results can be carefully extended to approximate linear minimization oracles with

multiplicative approximation guarantees; we state them for exact oracles in this paper for simplicity.

2

Figure 1: (left) The FW algorithm zig-zags when the solution x∗ lies on the boundary. (middle) Adding the
possibility of an away step attenuates this problem. (right) As an alternative  a pairwise FW step.
between the vertices deﬁning the face containing the solution x∗ (see left of Figure 1). In fact  the
1/t rate is tight for a large class of functions: Canon and Cullum [6]  Wolfe [34] showed (roughly)

that f (x(t))− f (x∗) ≥ Ω(cid:0)1/t1+δ(cid:1) for any δ > 0 when x∗ lies on a face of M with some additional
regularity assumptions. Note that this lower bound is different than the Ω(cid:0)1/t(cid:1) one presented in [15 

Lemma 3] which holds for all one-atom-per-step algorithms but assumes high dimensionality d ≥ t.
Improved Variants of the Frank-Wolfe Algorithm
1
Algorithm 1 Away-steps Frank-Wolfe algorithm: AFW(x(0) A  )
1: Let x(0) ∈ A  and S (0) := {x(0)}
2: for t = 0 . . . T do
Let st := LMOA
3:
Let vt ∈ arg max
4:
v∈S (t)
if g FW

:=(cid:10)−∇f (x(t))  dFW

(the FW direction)
(the away direction)

v = 1 for v = x(0) and 0 otherwise)

(FW gap is small enough  so return)

t

if(cid:10)−∇f (x(t))  dFW

t

(so that α(0)
:= st − x(t)
t := x(t) − vt

(cid:0)∇f (x(t))(cid:1) and dFW
(cid:10)∇f (x(t))  v(cid:11) and dA
(cid:11) ≥(cid:10)−∇f (x(t))  dA
f(cid:0)x(t) + γdt

(cid:11) ≤  then return x(t)
(cid:11) then
(cid:1)

t

t

t

(choose away direction; maximum feasible step-size)

(and accordingly for the weights α(t+1)  see text)

5:
6:
7:
8:
9:
10:
11:

dt := dFW

t

  and γmax := 1

(choose the FW direction)

else

dt := dA

t   and γmax := αvt/(1 − αvt)

end if
Line-search: γt ∈ arg min
γ∈[0 γmax]
Update x(t+1) := x(t) + γtdt
Update S (t+1) := {v ∈ A s.t. α(t+1)

12:
13:
14: end for
Algorithm 2 Pairwise Frank-Wolfe algorithm: PFW(x(0) A  )
1: . . . as in Algorithm 1  except replacing lines 6 to 10 by: dt = dPFW

> 0}

v

t

:= st−vt  and γmax := αvt.

:= (cid:10)−∇f (x(t))  x(t) − vt

(cid:11). Note that this search is over the (typically small) active set S (t) 

Away-Steps Frank-Wolfe. To address the zig-zagging problem of FW  Wolfe [34] proposed to
add the possibility to move away from an active atom in S (t) (see middle of Figure 1); this simple
modiﬁcation is sufﬁcient to make the algorithm linearly convergent for strongly convex functions.
We describe the away-steps variant of Frank-Wolfe in Algorithm 1.3 The away direction dA
is
deﬁned in line 4 by ﬁnding the atom vt in S (t) that maximizes the potential of descent given by
t
g A
t
and is fundamentally easier than the linear oracle LMOA. The maximum step-size γmax as deﬁned
t stays in M. In fact  this guarantees that the convex
on line 9 ensures that the new iterate x(t) + γdA
representation is maintained  and we stay inside conv(S (t)) ⊆ M. When M is a simplex  then the
t truly lies on the boundary of M. On the other
barycentric coordinates are unique and x(t) + γmaxdA
hand  if |A| > dim(M) + 1 (e.g. for the cube)  then it could hypothetically be possible to have a
step-size bigger than γmax which is still feasible. Computing the true maximum feasible step-size
would require the ability to know when we cross the boundary of M along a speciﬁc line  which
is not possible for general M. Using the conservative maximum step-size of line 9 ensures that we
3The original algorithm presented in [34] was not convergent; this was corrected by Gu´elat and Marcotte
[12]  assuming a tractable representation of M with linear inequalities and called it the modiﬁed Frank-Wolfe
(MFW) algorithm. Our description in Algorithm 1 extends it to the more general setup of (1).

3

x⇤x(t)x(0)x(t+1)stx⇤x(t)x(0)vtstx(t+1)x⇤x(t)x(0)vtst//x(t+1)//do not need this more powerful oracle. This is why Algorithm 1 requires to maintain S (t) (unlike
standard FW). Finally  as in classical FW  the FW gap g FW
is an upper bound on the unknown
suboptimality  and can be used as a stopping criterion:

(cid:69) ≥(cid:68)−∇f (x(t))  x∗ − x(t)(cid:69) ≥ f (x(t)) − f (x∗)

(cid:68)−∇f (x(t))  dFW

(by convexity).

t

g FW
t

:=

t

st

v

st

= α(t)

vt

:= (1 + γt)α(t)

vt = α(t)

:= (1 + γt)α(t)

st +γt and α(t+1)

v

:= (1−γt)α(t)

vt − γ and α(t+1)

v for v ∈ S (t) \ {vt}.

:= (1−γt)α(t)
vt − γt and α(t+1)

vt . In contrast  classical FW shrinks all active weights at every iteration.

If γt = γmax  then we call this step a drop step  as it fully removes the atom vt from the currently
active set of atoms S (t) (by settings its weight to zero). The weight updates for lines 12 and 13
are of the following form: For a FW step  we have S (t+1) = {st} if γt = 1; otherwise S (t+1) =
S (t)∪{st}. Also  we have α(t+1)
v for v ∈ S (t)\{st}.
For an away step  we have S (t+1) = S (t)\{vt} if γt = γmax (a drop step); otherwise S (t+1) = S (t).
Also  we have α(t+1)
Pairwise Frank-Wolfe. The next variant that we present is inspired by an early algorithm
by Mitchell et al. [25]  called the MDM algorithm  originally invented for the polytope distance
problem. Here the idea is to only move weight mass between two atoms in each step. More pre-
cisely  the generalized method as presented in Algorithm 2 moves weight from the away atom vt to
the FW atom st  and keeps all other α weights un-changed. We call such a swap of mass between
the two atoms a pairwise FW step  i.e. α(t+1)
st + γ for some step-size
γ ≤ γmax := α(t)
The pairwise FW direction will also be central to our proof technique to provide the ﬁrst global
linear convergence rate for away-steps FW  as well as the fully-corrective variant and Wolfe’s min-
norm-point algorithm.
As we will see in Section 2.2  the rate guarantee for the pairwise FW variant is more loose than for
the other variants  because we cannot provide a satisfactory bound on the number of the problematic
swap steps (deﬁned just before Theorem 1). Nevertheless  the algorithm seems to perform quite well
in practice  often outperforming away-steps FW  especially in the important case of sparse solutions 
that is if the optimal solution x∗ lies on a low-dimensional face of M (and thus one wants to keep the
active set S (t) small). The pairwise FW step is arguably more efﬁcient at pruning the coordinates in
S (t). In contrast to the away step which moves the mass back uniformly onto all other active elements
S (t) (and might require more corrections later)  the pairwise FW step only moves the mass onto the
(good) FW atom st. A slightly different version than Algorithm 2 was also proposed by ˜Nanculef
et al. [26]  though their convergence proofs were incomplete (see Appendix A.3). The algorithm
is related to classical working set algorithms  such as the SMO algorithm used to train SVMs [29].
We refer to [26] for an empirical comparison for SVMs  as well as their Section 5 for more related
work. See also Appendix A.3 for a link between pairwise FW and [10].
Fully-Corrective Frank-Wolfe  and Wolfe’s Min-Norm Point Algorithm. When the linear or-
acle is expensive  it might be worthwhile to do more work to optimize over the active set S (t) in
between each call to the linear oracle  rather than just performing an away or pairwise step. We
give in Algorithm 3 the fully-corrective Frank-Wolfe (FCFW) variant  that maintains a correction
polytope deﬁned by a set of atoms A(t) (potentially larger than the active set S (t)). Rather than
obtaining the next iterate by line-search  x(t+1) is obtained by re-optimizing f over conv(A(t)).
Depending on how the correction is implemented  and how the correction atoms A(t) are main-
tained  several variants can be obtained. These variants are known under many names  such as the
extended FW method by Holloway [14] or the simplicial decomposition method [31  13]. Wolfe’s
min-norm point (MNP) algorithm [35] for polytope distance problems is often confused with FCFW
for quadratic objectives. The major difference is that standard FCFW optimizes f over conv(A(t)) 
whereas MNP implements the correction as a sequence of afﬁne projections that potentially yield
a different update  but can be computed more efﬁciently in several practical applications [35]. We
describe precisely in Appendix A.1 a generalization of the MNP algorithm as a speciﬁc case of the
correction subroutine from step 7 of the generic Algorithm 3.
The original convergence analysis of the FCFW algorithm [14] (and also MNP algorithm [35]) only
showed that they were ﬁnitely convergent  with a bound on the number of iterations in terms of the
cardinality of A (unfortunately an exponential number in general). Holloway [14] also argued that
FCFW had an asymptotic linear convergence based on the ﬂawed argument of Wolfe [34]. As far
as we know  our work is the ﬁrst to provide global linear convergence rates for FCFW and MNP for

4

(cid:88)

v v  stopping criterion .
α(0)

v∈S (0)

(optionally  a bigger A(0) could be passed as argument for a warm start)

:= st − x(t) and g FW

(cid:0)∇f (x(t))(cid:1)

Algorithm 3 Fully-corrective Frank-Wolfe with approximate correction: FCFW(x(0) A  )
1: Input: Set of atoms A  active set S (0)  starting point x(0) =
2: Let A(0) := S (0)
3: for t = 0 . . . T do
Let st := LMOA
4:
Let dFW
5:
t
if g FW
6:
(x(t+1) A(t+1)) := Correction(x(t) A(t)  st  )
7:
8: end for
Algorithm 4 Approximate correction: Correction(x(t) A(t)  st  )
1: Return (x(t+1) A(t+1)) with the following properties:
2:
3:

t =(cid:10)−∇f (x(t))  dFW

S (t+1) is the active set for x(t+1) and A(t+1) ⊇ S (t+1).
f (x(t+1)) ≤ min
γ∈[0 1]
g A
t+1 := max

f(cid:0)x(t) + γ(st − x(t))(cid:1)
(cid:10)−∇f (x(t+1))  x(t+1) − v(cid:11) ≤ 

t ≤  then return x(t)

(the FW atom)
(FW gap)

(the away gap is small enough)

(approximate correction step)

(make at least as much progress as a FW step)

(cid:11)

4:

t

v∈S (t+1)

general strongly convex functions. Moreover  the proof of convergence for FCFW does not require
an exact solution to the correction step; instead  we show that the weaker properties stated for the
approximate correction procedure in Algorithm 4 are sufﬁcient for a global linear convergence rate
(this correction could be implemented using away-steps FW  as done for example in [18]).
2 Global Linear Convergence Analysis
2.1
We ﬁrst give the general intuition for the linear convergence proof of the different FW variants 
starting from the work of Gu´elat and Marcotte [12]. We assume that the objective function f is
smooth over a compact set M  i.e. its gradient is Lipschitz continuous with constant L. Also let
M := diam(M). Let dt be the direction in which the line-search is executed by the algorithm
(Line 11 in Algorithm 1). By the standard descent lemma [see e.g. (1.2.5) in 27]  we have:

Intuition for the Convergence Proofs

f (x(t+1)) ≤ f (x(t) + γdt) ≤ f (x(t)) + γ

(2)
We let rt := −∇f (x(t)) and let ht := f (x(t)) − f (x∗) be the suboptimality error. Supposing for
now that γmax ≥ γ∗t := (cid:104)rt  dt(cid:105) /(L(cid:107)dt(cid:107)2). We can set γ = γ∗t to minimize the RHS of (2)  subtract
f (x∗) on both sides  and re-organize to get a lower bound on the progress:

L(cid:107)dt(cid:107)2 ∀γ ∈ [0  γmax].

γ2
2

+

(cid:68)∇f (x(t))  dt

(cid:69)

=

ht − ht+1 ≥ (cid:104)rt  dt(cid:105)2
2L(cid:107)dt(cid:107)2
(cid:68)∇f (x(t))  et

1
2L

(cid:69)

(3)
where we use the ‘hat’ notation to denote normalized vectors: ˆdt := dt/(cid:107)dt(cid:107). Let et := x∗ − x(t)
be the error vector. By µ-strong convexity of f  we have:

γ2
2

µ(cid:107)et(cid:107)2 ∀γ ∈ [0  1].

f (x(t) + γet) ≥ f (x(t)) + γ

 

+

(4)
The RHS is lower bounded by its minimum as a function of γ (unconstrained)  achieved using
γ := (cid:104)rt  et(cid:105)/(µ(cid:107)et(cid:107)2). We are then free to use any value of γ on the LHS and maintain a valid
bound. In particular  we use γ = 1 to obtain f (x∗). Again re-arranging  we get:
ht − ht+1 ≥ µ
L

and combining with (3)  we obtain:

ht ≤ (cid:104)rt  ˆet(cid:105)2

(cid:104)rt  ˆdt(cid:105)2
(cid:104)rt  ˆet(cid:105)2 ht.

(5)

2µ

The inequality (5) is fairly general and valid for any line-search method in direction dt. To get a
linear convergence rate  we need to lower bound (by a positive constant) the term in front of ht on the
RHS  which depends on the angle between the update direction dt and the negative gradient rt. If
we assume that the solution x∗ lies in the relative interior of M with a distance of at least δ > 0 from
the boundary  then (cid:104)rt  dt(cid:105) ≥ δ(cid:107)rt(cid:107) for the FW direction dFW
  and by combining with (cid:107)dt(cid:107) ≤ M 
we get a linear rate with constant 1 − µ
M )2 (this was the result from [12]). On the other hand 
if x∗ lies on the boundary  then (cid:104)ˆrt  ˆdt(cid:105) gets arbitrary close to zero for standard FW (the zig-zagging
phenomenon) and the convergence is sublinear.

L ( δ

t

(cid:104)rt  ˆdt(cid:105)2  

5

t

t

t

t

t

t

(cid:105).

t + dA

t (cid:105) = (cid:104)rt  dFW

t (cid:105) = (cid:104)rt  dPFW

Proof Sketch for AFW. The key insight to prove the global linear convergence for AFW is to
relate (cid:104)rt  dt(cid:105) with the pairwise FW direction dPFW
:= st − vt. By the way the direction dt is
chosen on lines 6 to 10 of Algorithm 1  we have:
(cid:105) + (cid:104)rt  dA
2(cid:104)rt  dt(cid:105) ≥ (cid:104)rt  dFW
(6)
(cid:105)/2. Now the crucial property of the pairwise FW direction
We thus have (cid:104)rt  dt(cid:105) ≥ (cid:104)rt  dPFW
is that for any potential negative gradient direction rt  the worst case inner product (cid:104)ˆrt  dPFW
(cid:105)
can be lower bounded away from zero by a quantity depending only on
the geometry of M (unless we are at the optimum). We call this quantity
the pyramidal width of A. The ﬁgure on the right shows the six possible
pairwise FW directions dPFW
for a triangle domain  depending on which
colored area the rt direction falls into. We will see that the pyramidal
width is related to the smallest width of pyramids that we can construct
from A in a speciﬁc way related to the choice of the away and towards
atoms vt and st. See (9) and our main Theorem 3 in Section 3.
This gives the main argument for the linear convergence of AFW for steps where γ∗t ≤ γmax.
When γmax is too small  AFW will perform a drop step  as the line-search will truncate the step-size
to γt = γmax. We cannot guarantee sufﬁcient progress in this case  but the drop step decreases the
active set size by one  and thus they cannot happen too often (not more than half the time). These are
the main elements for the global linear convergence proof for AFW. The rest is to carefully consider
various boundary cases. We can re-use the same techniques to prove the convergence for pairwise
FW  though unfortunately the latter also has the possibility of problematic swap steps. While their
number can be bounded  so far we only found the extremely loose bound quoted in Theorem 1.
Proof Sketch for FCFW. For FCFW  by line 4 of the correction Algorithm 4  the away gap satis-
t ≤  at the beginning of a new iteration. Supposing that the algorithm does not exit at line 6
ﬁes g A
(cid:105) using a similar argument
of Algorithm 3  we have g FW
as in (6). Finally  by line 3 of Algorithm 4  the correction is guaranteed to make at least as much
progress as a line-search in direction dFW
2.2 Convergence Results
We now give the global linear convergence rates for the four variants of the FW algorithm: away-
steps FW (AFW Alg. 1); pairwise FW (PFW Alg. 2); fully-corrective FW (FCFW Alg. 3 with
approximate correction Alg. 4); and Wolfe’s min-norm point algorithm (Alg. 3 with MNP-correction
as Alg. 5 in Appendix A.1). For the AFW  MNP and PFW algorithms  we call a drop step when the
active set shrinks |S(t+1)| < |S(t)|. For the PFW algorithm  we also have the possibility of a swap
step where γt = γmax but |S(t+1)| = |S(t)| (i.e. the mass was fully swapped from the away atom to
the FW atom). A nice property of FCFW is that it does not have any drop step (it executes both FW
steps and away steps simultaneously while guaranteeing enough progress at every iteration).
Theorem 1. Suppose that f has L-Lipschitz gradient4 and is µ-strongly convex over M =
conv(A). Let M = diam(M) and δ = P Width(A) as deﬁned by (9). Then the suboptimal-
ity ht of the iterates of all the four variants of the FW algorithm decreases geometrically at each
step that is not a drop step nor a swap step (i.e. when γt < γmax  called a ‘good step’)  that is

  and so the progress bound (5) applies also to FCFW.

t >  and therefore 2(cid:104)rt  dFW

(cid:105) ≥ (cid:104)rt  dPFW

t

t

t

(cid:18) δ

(cid:19)2

M

.

µ
4L

ht+1 ≤ (1 − ρ) ht  

where ρ :=

Let k(t) be the number of ‘good steps’ up to iteration t. We have k(t) = t for FCFW; k(t) ≥ t/2 for
MNP and AFW; and k(t) ≥ t/(3|A|! + 1) for PFW (because of the swap steps). This yields a global
linear convergence rate of ht ≤ h0 exp(−ρ k(t)) for all variants. If µ = 0 (general convex)  then
ht = O(1/k(t)) instead. See Theorem 8 in Appendix D for an afﬁne invariant version and proof.
Note that to our knowledge  none of the existing linear convergence results showed that the duality
gap was also linearly convergent. The result for the gap follows directly from the simple manipula-
tion of (2); putting the FW gap to the LHS and optimizing the RHS for γ ∈ [0  1].
Theorem 2. Suppose that f has L-Lipschitz gradient over M with M := diam(M). Then the FW
gap g FW

for any algorithm is upper bounded by the primal error ht as follows:
t ≤ ht + LM 2/2 when ht > LM 2/2 
g FW

2htL otherwise .

t ≤ M
g FW

(cid:112)

(7)

t

4For AFW and PFW  we actually require that ∇f is L-Lipschitz over the larger domain M + M − M.

6

dFWtdAtdpFWtxvtstrtt

t

(cid:10) r

s∈M v∈S (t)

(cid:105) =(cid:104)rt  st−vt(cid:105) = max

(cid:105)/(cid:104)rt  ˆet(cid:105). First note that (cid:104)rt  dPFW

3 Pyramidal Width
We now describe the claimed lower bound on the angle between the negative gradient and the pair-
wise FW direction  which depends only on the geometric properties of M. According to our ar-
gument about the progress bound (5) and the PFW gap (6)  our goal is to ﬁnd a lower bound on
(cid:104)rt  dPFW
(cid:104)rt  s− v(cid:105) where S (t) is a pos-
sible active set for x(t). This looks like the directional width of a pyramid with base S (t) and summit
st. To be conservative  we consider the worst case possible active set for x(t); this is what we will
call the pyramid directional width P dirW (A  rt  x(t)). We start with the following deﬁnitions.
Directional Width. The directional width of a set A with respect to a direction r is deﬁned as
dirW (A  r) := maxs v∈A
possible directions in its afﬁne hull.
Pyramidal Directional Width. We deﬁne the pyramidal directional width of a set A with respect
to a direction r and a base point x ∈ M to be

  s − v(cid:11). The width of A is the minimum directional width over all

P dirW (A  r  x) := min
S∈Sx

dirW (S ∪ {s(A  r)}  r) = min
S∈Sx

(8)
where Sx := {S |S ⊆ A such that x is a proper5 convex combination of all the elements in S}  and
s(A  r) := arg maxv∈A
Pyramidal Width. To deﬁne the pyramidal width of a set  we take the minimum over the cone of
possible feasible directions r (in order to avoid the problem of zero width).
A direction r is feasible for A from x if it points inwards conv(A)  (i.e. r ∈ cone(A − x)).
We deﬁne the pyramidal width of a set A to be the smallest pyramidal width of all its faces  i.e.

(cid:104)r  v(cid:105) is the FW atom used as a summit.

  s − v(cid:11) 

(cid:10) r

s∈A v∈S

max

(cid:107)r(cid:107)

(cid:107)r(cid:107)

P Width(A) :=

P dirW (K ∩ A  r  x).

(9)

min

K∈faces(conv(A))
r∈cone(K−x)\{0}

x∈K

(10)

Theorem 3. Let x ∈ M = conv(A) be a suboptimal point and S be an active set for x. Let x∗ be
an optimal point and corresponding error direction ˆe = (x∗−x)/(cid:107)x∗ − x(cid:107)  and negative gradient
r := −∇f (x) (and so (cid:104)r  ˆe(cid:105) > 0). Let d = s−v be the pairwise FW direction obtained over A
and S with negative gradient r. Then (cid:104)r  d(cid:105)

(cid:104)r  ˆe(cid:105) ≥ P Width(A).
3.1 Properties of Pyramidal Width and Consequences
Examples of Values. The pyramidal width of a set A is lower bounded by the minimal width over
all subsets of atoms  and thus is strictly greater than zero if the number of atoms is ﬁnite. On the
other hand  this lower bound is often too loose to be useful  as in particular  vertex subsets of the
unit cube in dimension d can have exponentially small width O(d− d
2 ) [see Corollary 27 in 36]. On
the other hand  as we show here  the pyramidal width of the unit cube is actually 1/
d  justifying
why we kept the tighter but more involved deﬁnition (9). See Appendix B.1 for the proof.
√
Lemma 4. The pyramidal width of the unit cube in Rd is 1/
√
For the probability simplex with d vertices  the pyramidal width is actually the same as its width 
d−1/d when d is odd [2] (see Appendix B.1). In contrast 
which is 2/
the pyramidal width of an inﬁnite set can be zero. For example  for a curved domain  the set of active
atoms S can contain vertices forming a very narrow pyramid  yielding a zero width in the limit.
Condition Number of a Set. The inverse of the rate constant ρ appearing in Theorem 1 is the
product of two terms: L/µ is the standard condition number of the objective function appearing in
the rates of gradient methods in convex optimization. The second quantity (M/δ)2 (diameter over
pyramidal width) can be interpreted as a condition number of the domain M  or its eccentricity.
The more eccentric the constraint set (large diameter compared to its pyramidal width)  the slower
the convergence. The best condition number of a function is when its level sets are spherical; the
analog in term of the constraint sets is actually the regular simplex  which has the maximum width-
to-diameter ratio amongst all simplices [see Corollary 1 in 2]. Its eccentricity is (at most) d/2. In
contrast  the eccentricity of the unit cube is d2  which is much worse.

d when d is even  and 2/

(cid:112)

√

d.

5By proper convex combination  we mean that all coefﬁcients are non-zero in the convex combination.

7

√
d to 1/

µ log( 1

Illustrative Experiments

We conjecture that the pyramidal width of a set of vertices (i.e. extrema of their convex hull) is
non-increasing when another vertex is added (assuming that all previous points remain vertices).
√
For example  the unit cube can be obtained by iteratively adding vertices to the regular probability
√
simplex  and the pyramidal width thereby decreases from 2/
d. This property could
provide lower bounds for the pyramidal width of more complicated polytopes  such as 1/
d for the
d-dimensional marginal polytope  as it can be obtained by removing vertices from the unit cube.
Complexity Lower Bounds. Combining the convergence Theorem 1 and the condition number
of the unit simplex  we get a complexity of O(d L
 )) to reach -accuracy when optimizing a
strongly convex function over the unit simplex. Here the linear dependence on d should not come as
a surprise  in view of the known lower bound of 1/t for t ≤ d for Frank-Wolfe type methods [15].
Applications to Submodular Minimization. See Appendix A.2 for a consequence of our linear
rate for the popular MNP algorithm for submodular function optimization (over the base polytope).
4 Non-Strongly Convex Generalization
Building on the work of Beck and Shtern [4] and Wang and Lin [33]  we can generalize our global
linear convergence results for all Frank-Wolfe variants for the more general case where f (x) :=
g(Ax) + (cid:104)b  x(cid:105)  for A ∈ Rp×d  b ∈ Rd and where g is µg-strongly convex and continuously
differentiable over AM. We note that for a general matrix A  f is convex but not necessarily
strongly convex. In this case  the linear convergence still holds but with the constant µ appearing in
the rate of Theorem 1 replaced with the generalized constant ˜µ appearing in Lemma 9 in Appendix F.
5
We illustrate the performance of the presented algorithm vari-
ants in two numerical experiments  shown in Figure 2. The
ﬁrst example is a constrained Lasso problem ((cid:96)1-regularized
least squares regression)  that is minx∈M f (x) = (cid:107)Ax − b(cid:107)2 
with M = 20 · L1 a scaled L1-ball. We used a random Gaus-
sian matrix A ∈ R200×500  and a noisy measurement b = Ax∗
with x∗ being a sparse vector with 50 entries ±1  and 10% of
additive noise. For the L1-ball  the linear minimization oracle
LMOA just selects the column of A of best inner product with
the residual vector. The second application comes from video
co-localization. The approach used by [16] is formulated as a
quadratic program (QP) over a ﬂow polytope  the convex hull of
paths in a network. In this application  the linear minimization
oracle is equivalent to ﬁnding a shortest path in the network 
which can be done easily by dynamic programming. For the
LMOA  we re-use the code provided by [16] and their included
aeroplane dataset resulting in a QP over 660 variables. In both
Figure 2: Duality gap g FW
vs itera-
experiments  we see that the modiﬁed FW variants (away-steps
tions on the Lasso problem (top)  and
and pairwise) outperform the original FW algorithm  and ex-
video co-localization (bottom). Code
hibit a linear convergence. In addition  the constant in the con-
is available from the authors’ website.
vergence rate of Theorem 1 can also be empirically shown to be
fairly tight for AFW and PFW by running them on an increasingly obtuse triangle (see Appendix E).
Discussion. Building on a preliminary version of our work [20]  Beck and Shtern [4] also proved
a linear rate for away-steps FW  but with a simpler lower bound for the LHS of (10) using linear
duality arguments. However  their lower bound [see e.g. Lemma 3.1 in 4] is looser: they get a d2
constant for the eccentricity of the regular simplex instead of the tighter d that we proved. Finally 
the recently proposed generic scheme for accelerating ﬁrst-order optimization methods in the sense
of Nesterov from [24] applies directly to the FW variants given their global linear convergence rate
that we proved. This gives for the ﬁrst time ﬁrst-order methods that only use linear oracles and
L/µ)
constant in the linear rate for strongly convex functions. Given that the constants also depend on the
dimensionality  it remains an open question whether this acceleration is practically useful.
Acknowledgements. We thank J.B. Alayrac  E. Hazan  A. Hubard  A. Osokin and P. Marcotte for helpful
discussions. This work was partially supported by the MSR-Inria Joint Center and a Google Research Award.

obtain the “near-optimal” ˜O(1/k2) rate for smooth convex functions  or the accelerated ˜O((cid:112)

t

8

iteration02004006008001000gap10-810-610-410-2100102104106FWawayFWpairFWFWawayFWpairFWiteration0500100015002000gap10-810-610-410-2100FWawayFWpairFWFWawayFWpairFWReferences
[1] S. D. Ahipaao˘glu  P. Sun  and M. Todd. Linear convergence of a modiﬁed Frank-Wolfe algorithm for com-

puting minimum-volume enclosing ellipsoids. Optimization Methods and Software  23(1):5–19  2008.

[2] R. Alexander. The width and diameter of a simplex. Geometriae Dedicata  6(1):87–94  1977.
[3] F. Bach. Learning with submodular functions: A convex optimization perspective. Foundations and

Trends in Machine Learning  6(2-3):145–373  2013.

[4] A. Beck and S. Shtern. Linearly convergent away-step conditional gradient for non-strongly convex

functions. arXiv:1504.05002v1  2015.

[5] A. Beck and M. Teboulle. A conditional gradient method with linear rate of convergence for solving

convex linear systems. Mathematical Methods of Operations Research (ZOR)  59(2):235–247  2004.

[6] M. D. Canon and C. D. Cullum. A tight upper bound on the rate of convergence of Frank-Wolfe algorithm.

SIAM Journal on Control  6(4):509–516  1968.

[7] V. Chari et al. On pairwise costs for network ﬂow multi-object tracking. In CVPR  2015.
[8] J. C. Dunn. Rates of convergence for conditional gradient algorithms near singular and nonsingular

extremals. SIAM Journal on Control and Optimization  17(2):187–211  1979.

[9] M. Frank and P. Wolfe. An algorithm for quadratic programming. Naval Research Logistics Quarterly 

3:95–110  1956.

2015.

[10] D. Garber and E. Hazan. A linearly convergent conditional gradient algorithm with applications to online

and stochastic optimization. arXiv:1301.4666v5  2013.

[11] D. Garber and E. Hazan. Faster rates for the Frank-Wolfe method over strongly-convex sets. In ICML 

[12] J. Gu´elat and P. Marcotte. Some comments on Wolfe’s ‘away step’. Mathematical Programming  1986.
[13] D. Hearn  S. Lawphongpanich  and J. Ventura. Restricted simplicial decomposition: Computation and

extensions. In Computation Mathematical Programming  volume 31  pages 99–118. Springer  1987.

[14] C. A. Holloway. An extension of the Frank and Wolfe method of feasible directions. Mathematical

Programming  6(1):14–27  1974.

[15] M. Jaggi. Revisiting Frank-Wolfe: Projection-free sparse convex optimization. In ICML  2013.
[16] A. Joulin  K. Tang  and L. Fei-Fei. Efﬁcient image and video co-localization with Frank-Wolfe algorithm.

[17] V. Kolmogorov and R. Zabin. What energy functions can be minimized via graph cuts? IEEE Transac-

tions on Pattern Analysis and Machine Intelligence  26(2):147–159  2004.

[18] R. G. Krishnan  S. Lacoste-Julien  and D. Sontag. Barrier Frank-Wolfe for marginal inference. In NIPS 

In ECCV  2014.

2015.

[19] P. Kumar and E. A. Yildirim. A linearly convergent linear-time ﬁrst-order algorithm for support vector

classiﬁcation with a core set result. INFORMS Journal on Computing  2010.

[20] S. Lacoste-Julien and M. Jaggi. An afﬁne invariant linear convergence analysis for Frank-Wolfe algo-

[21] S. Lacoste-Julien  M. Jaggi  M. Schmidt  and P. Pletscher. Block-coordinate Frank-Wolfe optimization

rithms. arXiv:1312.7864v2  2013.

for structural SVMs. In ICML  2013.

arXiv:1309.5550v2  2013.

[22] G. Lan.

The complexity of large-scale convex programming under a linear optimization oracle.

[23] E. S. Levitin and B. T. Polyak. Constrained minimization methods. USSR Computational Mathematics

and Mathematical Physics  6(5):787–823  Jan. 1966.

[24] H. Lin  J. Mairal  and Z. Harchaoui. A universal catalyst for ﬁrst-order optimization. In NIPS  2015.
[25] B. Mitchell  V. F. Demyanov  and V. Malozemov. Finding the point of a polyhedron closest to the origin.

SIAM Journal on Control  12(1)  1974.

[26] R. ˜Nanculef  E. Frandi  C. Sartori  and H. Allende. A novel Frank-Wolfe algorithm. Analysis and appli-

cations to large-scale SVM training. Information Sciences  2014.

[27] Y. Nesterov. Introductory Lectures on Convex Optimization. Kluwer Academic Publishers  2004.
[28] J. Pena  D. Rodriguez  and N. Soheili. On the von Neumann and Frank-Wolfe algorithms with away

steps. arXiv:1507.04073v2  2015.

[29] J. C. Platt. Fast training of support vector machines using sequential minimal optimization. In Advances

in kernel methods: support vector learning  pages 185–208. 1999.

[30] S. M. Robinson. Generalized Equations and their Solutions  Part II: Applications to Nonlinear Program-

[31] B. Von Hohenbalken. Simplicial decomposition in nonlinear programming algorithms. Mathematical

ming. Springer  1982.

Programming  13(1):49–68  1977.

[32] M. J. Wainwright and M. I. Jordan. Graphical models  exponential families  and variational inference.

Foundations and Trends in Machine Learning  1(12):1–305  2008.

[33] P.-W. Wang and C.-J. Lin.

Iteration complexity of feasible descent methods for convex optimization.

Journal of Machine Learning Research  15:1523–1548  2014.

[34] P. Wolfe. Convergence theory in nonlinear programming. In Integer and Nonlinear Programming. 1970.
[35] P. Wolfe. Finding the nearest point in a polytope. Mathematical Programming  11(1):128–149  1976.
[36] G. M. Ziegler. Lectures on 0/1-polytopes. arXiv:math/9909177v1  1999.

9

,Ashesh Jain
Brian Wojcik
Thorsten Joachims
Ashutosh Saxena
Simon Lacoste-Julien
Martin Jaggi