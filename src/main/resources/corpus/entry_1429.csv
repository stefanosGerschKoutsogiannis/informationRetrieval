2018,Dendritic cortical microcircuits approximate the backpropagation algorithm,Deep learning has seen remarkable developments over the last years  many of them inspired by neuroscience. However  the main learning mechanism behind these advances – error backpropagation – appears to be at odds with neurobiology. Here  we introduce a multilayer neuronal network model with simplified dendritic compartments in which error-driven synaptic plasticity adapts the network towards a global desired output. In contrast to previous work our model does not require separate phases and synaptic learning is driven by local dendritic prediction errors continuously in time. Such errors originate at apical dendrites and occur due to a mismatch between predictive input from lateral interneurons and activity from actual top-down feedback. Through the use of simple dendritic compartments and different cell-types our model can represent both error and normal activity within a pyramidal neuron. We demonstrate the learning capabilities of the model in regression and classification tasks  and show analytically that it approximates the error backpropagation algorithm. Moreover  our framework is consistent with recent observations of learning between brain areas and the architecture of cortical microcircuits. Overall  we introduce a novel view of learning on dendritic cortical circuits and on how the brain may solve the long-standing synaptic credit assignment problem.,Dendritic cortical microcircuits

approximate the backpropagation algorithm

João Sacramento⇤

Department of Physiology

University of Bern  Switzerland
sacramento@pyl.unibe.ch

Yoshua Bengio‡

Mila and Université de Montréal  Canada

yoshua.bengio@mila.quebec

Rui Ponte Costa†

Department of Physiology

University of Bern  Switzerland

costa@pyl.unibe.ch

Walter Senn

Department of Physiology

University of Bern  Switzerland

senn@pyl.unibe.ch

Abstract

Deep learning has seen remarkable developments over the last years  many of
them inspired by neuroscience. However  the main learning mechanism behind
these advances – error backpropagation – appears to be at odds with neurobiology.
Here  we introduce a multilayer neuronal network model with simpliﬁed dendritic
compartments in which error-driven synaptic plasticity adapts the network towards
a global desired output. In contrast to previous work our model does not require
separate phases and synaptic learning is driven by local dendritic prediction errors
continuously in time. Such errors originate at apical dendrites and occur due to
a mismatch between predictive input from lateral interneurons and activity from
actual top-down feedback. Through the use of simple dendritic compartments
and different cell-types our model can represent both error and normal activity
within a pyramidal neuron. We demonstrate the learning capabilities of the model
in regression and classiﬁcation tasks  and show analytically that it approximates
the error backpropagation algorithm. Moreover  our framework is consistent
with recent observations of learning between brain areas and the architecture of
cortical microcircuits. Overall  we introduce a novel view of learning on dendritic
cortical circuits and on how the brain may solve the long-standing synaptic credit
assignment problem.

1

Introduction

Machine learning is going through remarkable developments powered by deep neural networks (Le-
Cun et al.  2015). Interestingly  the workhorse of deep learning is still the classical backpropagation
of errors algorithm (backprop; Rumelhart et al.  1986)  which has been long dismissed in neuro-
science on the grounds of biologically implausibility (Grossberg  1987; Crick  1989). Irrespective
of such concerns  growing evidence demonstrates that deep neural networks outperform alternative
frameworks in accurately reproducing activity patterns observed in the cortex (Lillicrap and Scott 
2013; Yamins et al.  2014; Khaligh-Razavi and Kriegeskorte  2014; Yamins and DiCarlo  2016; Kell
et al.  2018). Although recent developments have started to bridge the gap between neuroscience
⇤Present address: Institute of Neuroinformatics  University of Zürich and ETH Zürich  Zürich  Switzerland
†Present address: Computational Neuroscience Unit  Department of Computer Science  SCEEM  Faculty of

Engineering  University of Bristol  United Kingdom

‡CIFAR Senior Fellow

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

and artiﬁcial intelligence (Marblestone et al.  2016; Lillicrap et al.  2016; Scellier and Bengio  2017;
Costa et al.  2017; Guerguiev et al.  2017)  how the brain could implement a backprop-like algorithm
remains an open question.
In neuroscience  understanding how the brain learns to associate different areas (e.g.  visual and
motor cortices) to successfully drive behaviour is of fundamental importance (Petreanu et al.  2012;
Manita et al.  2015; Makino and Komiyama  2015; Poort et al.  2015; Fu et al.  2015; Pakan et al. 
2016; Zmarz and Keller  2016; Attinger et al.  2017). However  how to correctly modify synapses to
achieve this has puzzled neuroscientists for decades. This is often referred to as the synaptic credit
assignment problem (Rumelhart et al.  1986; Sutton and Barto  1998; Roelfsema and van Ooyen 
2005; Friedrich et al.  2011; Bengio  2014; Lee et al.  2015; Roelfsema and Holtmaat  2018)  for
which the backprop algorithm provides an elegant solution.
Here we propose that the prediction errors that drive learning in backprop are encoded at distal
dendrites of pyramidal neurons  which receive top-down input from downstream brain areas (we
interpret a brain area as being equivalent to a layer in machine learning) (Petreanu et al.  2009;
Larkum  2013). In our model  these errors arise from the inability to exactly match via lateral input
from local interneurons (e.g. somatostatin-expressing; SST) the top-down feedback from downstream
cortical areas. Learning of bottom-up connections (i.e.  feedforward weights) is driven by such error
signals through local synaptic plasticity. Therefore  in contrast to previous approaches (Marblestone
et al.  2016)  in our framework a given neuron is used simultaneously for activity propagation (at the
somatic level)  error encoding (at distal dendrites) and error propagation to the soma without the need
for separate phases.
We ﬁrst illustrate the different components of the model. Then  we show analytically that under
certain conditions learning in our network approximates backpropagation. Finally  we empirically
evaluate the performance of the model on nonlinear regression and recognition tasks.
2 Error-encoding dendritic cortical microcircuits

2.1 Neuron and network model
Building upon previous work (Urbanczik and Senn  2014)  we adopt a simpliﬁed multicompart-
ment neuron and describe pyramidal neurons as three-compartment units (schematically depicted
in Fig. 1A). These compartments represent the somatic  basal and apical integration zones that
characteristically deﬁne neocortical pyramidal cells (Spruston  2008; Larkum  2013). The dendritic
structure of the model is exploited by having bottom-up and top-down synapses converging onto
separate dendritic compartments (basal and distal dendrites  respectively)  a ﬁrst approximation in line
with experimental observations (Spruston  2008) and reﬂecting the preferred connectivity patterns of
cortico-cortical projections (Larkum  2013).
Consistent with the connectivity of SST interneurons (Urban-Ciecko and Barth  2016)  we also
introduce a second population of cells within each hidden layer with both lateral and cross-layer
connectivity  whose role is to cancel the top-down input so as to leave only the backpropagated
errors as apical dendrite activity. Modelled as two-compartment units (depicted in red  Fig. 1A)  such
interneurons are predominantly driven by pyramidal cells within the same layer through weights
k k  and they project back to the apical dendrites of the same-layer pyramidal cells through weights
WIP
k k (Fig. 1A). Additionally  cross-layer feedback onto SST cells originating at the next upper layer
WPI
k + 1 provide a weak nudging signal for these interneurons  modelled after Urbanczik and Senn
(2014) as a conductance-based somatic input current. We modelled this weak top-down nudging on a
one-to-one basis: each interneuron is nudged towards the potential of a corresponding upper-layer
pyramidal cell. Although the one-to-one connectivity imposes a restriction in the model architecture 
this is to a certain degree in accordance with recent monosynaptic input mapping experiments show
that SST cells in fact receive top-down projections (Leinweber et al.  2017)  that according to our
proposal may encode the weak interneuron ‘teaching’ signals from higher to lower brain areas.
The somatic membrane potentials of pyramidal neurons and interneurons evolve in time according to

d
dt
d
dt

k (t) = glk uP
uP
uI
k(t) = glk uI

k (t) + gBvP
k(t) + gDvI

B k(t)  uP
k(t)  uI

k (t) + gAvP
k(t) + iI

k(t) +  ⇠(t) 

A k(t)  uP

k (t) +  ⇠(t)

(1)

(2)

2

with one such pair of dynamical equations for every hidden layer 0 < k < N; input layer neurons
are indexed by k = 0  g’s are ﬁxed conductances   controls the amount of injected noise. Basal
and apical dendritic compartments of pyramidal cells are coupled to the soma with effective transfer
conductances gB and gA  respectively. Subscript lk is for leak  A is for apical  B for basal  D for
dendritic  superscript I for inhibitory and P for pyramidal neuron. Eqs. 1 and 2 describe standard
conductance-based voltage integration dynamics  having set membrane capacitance to unity and
resting potential to zero for clarity. Background activity is modelled as a Gaussian white noise input 
⇠ in the equations above. To keep the exposition brief we use matrix notation  and denote by uP
k
and uI
k the vectors of pyramidal and interneuron somatic voltages  respectively. Both matrices and
vectors  assumed column vectors by default  are typed in boldface here and throughout. Dendritic
compartmental potentials are denoted by v and are given in instantaneous form by

vP
B k(t) = WPP
vP
A k(t) = WPP

k k1 (uP
k k+1 (uP

k1(t))
k+1(t)) + WPI

k k (uI

k(t)) 

(3)
(4)

where (u) is the neuronal transfer function  which acts componentwise on u.

2

Figure 1: Learning in error-encoding dendritic microcircuit network. (A) Schematic of network
with pyramidal cells and lateral inhibitory interneurons. Starting from a self-predicting state – see
main text and supplementary material (SM) – when a novel teaching (or associative) signal is
presented at the output layer (utrgt
)  a prediction error in the apical compartments of pyramidal
neurons in the upstream layer (layer 1  ‘error’) is generated. This error appears as an apical voltage
deﬂection that propagates down to the soma (purple arrow) where it modulates the somatic ﬁring rate 
which in turn leads to plasticity at bottom-up synapses (bottom  green). (B) Activity traces in the
microcircuit before and after a new teaching signal is learned. (i) Before learning: a new teaching
signal is presented (utrgt
)  which triggers a mismatch between the top-down feedback (grey blue)
and the cancellation given by the lateral interneurons (red). (ii) After learning (with plasticity at the
bottom-up synapses (WPP
1 0))  the network successfully predicts the new teaching signal  reﬂected on
no distal ’error’ (top-down and lateral interneuron input cancel each other). (C) Interneurons learn to
predict the backpropagated activity (i)  while simultaneously silencing the apical compartment (ii) 
even though the pyramidal neurons remain active (not shown).

2

For simplicity  we reduce pyramidal output neurons to two-compartment cells: the apical compartment
is absent (gA = 0 in Eq. 1) and basal voltages are as deﬁned in Eq. 3. Although the design can be
extended to more complex morphologies  in the framework of dendritic predictive plasticity two
compartments sufﬁce to compare desired target with actual prediction. Synapses proximal to the
soma of output neurons provide direct external teaching input  incorporated as an additional source of
current iP
N )  with some ﬁxed somatic nudging
conductance gsom. This can be modelled closer to biology by explicitly setting the somatic excitatory
and inhibitory conductance-based inputs (Urbanczik and Senn  2014). For a given output neuron 
iP
N (t) = gP
and inhibitory synaptic reversal potentials  respectively  where the inputs are balanced according to

N (t)  where Eexc and Einh are excitatory

exc N (t)Eexc  uP

N. In practice  one can simply set iP

N (t) + gP

inh N (t)Einh  uP

N = gsom(utrgt

N  uP

3

ABC(i)layer 2(output)layer 1(hidden)sensory inputlayer 0output(ii)u: somatic potentialv: dendritic potential}B: basalA: apicalP: pyramidal cellI: interneuronI1uI1uP2vlayer 2layer 1PB kvwPI1 1-IP1 1w2 1wPPtarget}errorsensory input(layer 0)utrgt2PP1 0wPP1 0w+uP1PA 1v015000101500010||Apical pot.||Time (ms)Time (ms)beforelearningafterplasticityApicalpotentialTime (ms)0100200error0Sensoryinputtarget0100200Time (ms)(ii)(i)1Apical topdownApical cancelationutrgt2OutputuP2errorrP0PA 1VPP1 0w||pyrk+1 - intk||2targettargetutrgt
N Einh
EexcEinh

  gP

gP
exc N = gsom
deﬁnes the target teaching voltage utrgt
Interneurons are similarly modelled as two-compartment cells  cf. Eq. 2. Lateral dendritic projections
from neighboring pyramidal neurons provide the main source of input as

N towards which the neuron is nudged4.

. The point at which no current ﬂows  iP

inh N = gsom

N = 0 

utrgt
N Eexc
EexcEinh

vI
k(t) = WIP

k k (uP

k (t)) 

(5)

whereas cross-layer  top-down synapses deﬁne the teaching current iI
k. This means that an interneuron
at layer k permanently (i.e.  when learning or performing a task) receives balanced somatic teaching
excitatory and inhibitory input from a pyramidal neuron at layer k+1 on a one-to-one basis (as above 
but with uP
k+1 as target). With this setting  the interneuron is nudged to follow the corresponding
next layer pyramidal neuron. See SM for detailed parameters.

2.2 Synaptic learning rules

The synaptic learning rules we use belong to the class of dendritic predictive plasticity rules (Ur-
banczik and Senn  2014; Spicher et al.  2018) that can be expressed in its general form as

d
dt

w = ⌘ ((u)  (v)) r 

(6)

where w is an individual synaptic weight  ⌘ is a learning rate  u and v denote distinct compartmental
potentials   is a rate function  and r is the presynaptic input. Eq. 6 was originally derived in the light
of reducing the prediction error of somatic spiking  when u represents the somatic potential and v is
a function of the postsynaptic dendritic potential.
In our model the plasticity rules for the various connection types are:

d
dt

WPP

k k1 = ⌘PP
WIP
k k = ⌘IP

WPI

k k = ⌘PI

d
dt
d
dt

B k)rP
k1T
k k1(uP
k )  (ˆvP
k)rP
kT
k k(uI
k)  (ˆvI
A krI
kT
k kvrest  vP

 

 

 

(7)

(8)

(9)

gB

B k and ˆvI
vP

where (·)T denotes vector transpose and rk ⌘ (uk) the layer k ﬁring rates. The synaptic weights
evolve according to the product of dendritic prediction error and presynaptic rate  and can undergo
both potentiation or depression depending on the sign of the ﬁrst factor (i.e.  the prediction error).
For basal synapses  such prediction error factor amounts to a difference between postsynaptic rate
and a local dendritic estimate which depends on the branch potential. In Eqs. 7 and 8  ˆvP
B k =
k take into account dendritic attenuation factors of the different
vI
glk+gB+gA
compartments. On the other hand  the plasticity rule (9) of lateral interneuron-to-pyramidal synapses
aims to silence (i.e.  set to resting potential vrest = 0  here and throughout zero for simplicity)
the apical compartment; this introduces an attractive state for learning where the contribution from
interneurons balances (or cancels out) top-down dendritic input. This learning rule of apical-targeting
interneuron synapses can be thought of as a dendritic variant of the homeostatic inhibitory plasticity
proposed by Vogels et al. (2011); Luz and Shamir (2012).
In experiments where the top-down connections are plastic  the weights evolve according to

k = gD

glk+gD

d
dt
TD k = Wk k+1 rP

WPP

k k+1 = ⌘PP

k k+1(uP

k )  (ˆvP

TD k)rP
k+1T

with ˆvP
compartment into a distal part receiving the top-down input (with voltage ˆvP
compartment receiving the lateral input from the interneurons (with voltage vP

k+1. An implementation of this rule requires a subdivision of the apical
TD k) and another distal

A k).

 

(10)

4Note that in biology a target may be represented by an associative signal from the motor cortex to a sensory

cortex (Attinger et al.  2017).

4

2.3 Comparison to previous work

It has been suggested that error backpropagation could be approximated by an algorithm that requires
alternating between two learning phases  known as contrastive Hebbian learning (Ackley et al.  1985).
This link between the two algorithms was ﬁrst established for an unsupervised learning task (Hinton
and McClelland  1988) and later analyzed (Xie and Seung  2003) and generalized to broader classes
of models (O’Reilly  1996; Scellier and Bengio  2017).
The concept of apical dendrites as distinct integration zones  and the suggestion that this could
simplify the implementation of backprop has been previously made (Körding and König  2000  2001).
Our microcircuit design builds upon this view  offering a concrete mechanism that enables apical error
encoding. In a similar spirit  two-phase learning recently reappeared in a study that exploits dendrites
for deep learning with biological neurons (Guerguiev et al.  2017). In this more recent work  the
temporal difference between the activity of the apical dendrite in the presence and in the absence of
the teaching input represents the error that induces plasticity at the forward synapses. This difference
is used directly for learning the bottom-up synapses without inﬂuencing the somatic activity of the
pyramidal cell. In contrast  we postulate that the apical dendrite has an explicit error representation by
simultaneously integrating top-down excitation and lateral inhibition. As a consequence  we do not
need to postulate separate temporal phases  and our network operates continuously while plasticity at
all synapses is always turned on.
Error minimization is an integral part of brain function according to predictive coding theories
(Rao and Ballard  1999; Friston  2005). Interestingly  recent work has shown that backprop can
be mapped onto a predictive coding network architecture (Whittington and Bogacz  2017)  related
to the general framework introduced by LeCun (1988). A possible network implementation is
suggested by Whittington and Bogacz (2017) that requires intricate circuitry with appropriately tuned
error-representing neurons. According to this work  the only plastic synapses are those that connect
prediction and error neurons. By contrast  in our model  lateral  bottom-up and top-down connections
are all plastic  and errors are directly encoded in dendritic compartments.

3 Results

3.1 Learning in dendritic error networks approximates backprop

In our model  neurons implicitly carry and transmit errors across the network. In the supplementary
material  we formally show such propagation of errors for networks in a particular regime  which we
term self-predicting. Self-predicting nets are such that when no external target is provided to output
layer neurons  the lateral input from interneurons cancels the internally generated top-down feedback
and renders apical dendrites silent. In this case  the output becomes a feedforward function of the
input  which can in theory be optimized by conventional backprop. We demonstrate that synaptic
plasticity in self-predicting nets approximates the weight changes prescribed by backprop.
We summarize below the main points of the full analysis (see SM). First  we show that somatic
membrane potentials at hidden layer k integrate feedforward predictions (encoded in basal dendritic
potentials) with backpropagated errors (encoded in apical dendritic potentials):

k = uk + Nk+1 WPP
uP

k k+1 N1Yl=k+1

Dl WPP

l l+1! DNutrgt

N  uN + O(Nk+2).

Parameter  ⌧ 1 sets the strength of feedback and teaching versus bottom-up inputs and is assumed
to be small to simplify the analysis. The ﬁrst term is the basal contribution and corresponds to uk  
the activation computed by a purely feedforward network that is obtained by removing lateral and
top-down weights from the model (here and below  we use superscript ‘-’ to refer to the feedforward
model). The second term (of order Nk+1) is an error that is backpropagated from the output layer
down to k-th layer hidden neurons; matrix Dk is a diagonal matrix with i-th entry containing the
derivative of the neuronal transfer function evaluated at uk i.
Second  we compare model synaptic weight updates for the bottom-up connections to those prescribed
by backprop. Output layer updates are exactly equal by construction. For hidden neuron synapses 

5

we obtain

l l+1! DNutrgt

k k1Nk+1 N1Yl=k

WPP

Dl WPP

k k1 = ⌘PP

N  uNrk1T + O(Nk+2).
Up to a factor which can be absorbed in the learning rate  this plasticity rule becomes equal to the
backprop weight change in the weak feedback limit  ! 0  provided that the top-down weights are
set to the transpose of the corresponding feedforward weights.
In our simulations  top-down weights are either set at random and kept ﬁxed  in which case the
equation above shows that the plasticity model optimizes the predictions according to an approxima-
tion of backprop known as feedback alignment (Lillicrap et al.  2016); or learned so as to minimize
an inverse reconstruction loss  in which case the network implements a form of target propagation
(Bengio  2014; Lee et al.  2015).

3.2 Deviations from self-predictions encode backpropagated errors

To illustrate learning in the model and to conﬁrm our analytical insights we ﬁrst study a very simple
task: memorizing a single input-output pattern association with only one hidden layer; the task
naturally generalizes to multiple memories.
Given a self-predicting network (established by microcircuit plasticity  Fig. S1  see SM for more
details)  we focus on how prediction errors get propagated backwards when a novel teaching signal is
provided to the output layer  modeled via the activation of additional somatic conductances in output
pyramidal neurons. Here we consider a network model with an input  a hidden and an output layer
(layers 0  1 and 2  respectively; Fig. 1A).
When the pyramidal cell activity in the output layer is nudged towards some desired target (Fig. 1B
(i))  the bottom-up synapses WPP
2 1 from the lower layer neurons to the basal dendrites are adapted 
again according to the plasticity rule that implements the dendritic prediction of somatic spiking (see
Eq. 7). What these synapses cannot explain away encodes a dendritic error in the pyramidal neurons
of the lower layer 1. In fact  the self-predicting microcircuit can only cancel the feedback that is
produced by the lower layer activity.
1 0 (Eq. 7).
The somatic integration of apical activity induces plasticity at the bottom-up synapses WPP
As the apical error changes the somatic activity  plasticity of the WPP
1 0 weights tries to further reduce
the error in the output layer. Importantly  the plasticity rule depends only on local information
available at the synaptic level: postsynaptic ﬁring and dendritic branch voltage  as well as the
presynaptic activity  in par with phenomenological models of synaptic plasticity (Sjöström et al.  2001;
Clopath et al.  2010; Bono and Clopath  2017). This learning occur concurrently with modiﬁcations
of lateral interneuron weights which track changes in the output layer. Through the course of learning
the network comes to a point where the novel top-down input is successfully predicted (Fig. 1B C).

0 assigned to corresponding target rtrgt

3.3 Network learns to solve a nonlinear regression task
We now test the learning capabilities of the model on a nonlinear regression task  where the goal is to
associate sensory input with the output of a separate multilayer network that transforms the same
sensory input (Fig. 2A). More precisely  a pyramidal neuron network of dimensions 30-50-10 (and 10
hidden layer interneurons) learns to approximate a random nonlinear function implemented by a held-
aside feedforward network of dimensions 30-20-10. One teaching example consists of a randomly
drawn input pattern rP
0 )) 
1 0 rP
with scale factors k2 1 = 10 and k1 0 = 2. Teacher network weights and input pattern entries are
sampled from a uniform distribution U (1  1). We used a soft rectifying nonlinearity as the neuronal
transfer function  (u) =  log(1 + exp((u  ✓))  with  = 0.1   = 1 and ✓ = 3. This parameter
setting led to neuronal activity in the nonlinear  sparse ﬁring regime.
The network is initialized to a random initial synaptic weight conﬁguration  with both pyramidal-
pyramidal WPP
1 1 independently drawn
1 2 is kept ﬁxed throughout  in the spirit
from a uniform distribution. Top-down weight matrix WPP
of feedback alignment (Lillicrap et al.  2016). Output layer teaching currents iP
2 are set so as to
. Learning rates were manually chosen to yield best
nudge uP

1 2 and pyramidal-interneuron weights WIP

2 towards the teacher-generated utrgt

2 = (k2 1Wtrgt

2 1 (k1 0 Wtrgt

2 1  WPP

1 0  WPP

1 1  WPI

2

6

Figure 2: Dendritic error microcircuit learns to solve a nonlinear regression task online and
without phases.
(A-C) Starting from a random initial weight conﬁguration  a 30-50-10 fully-
connected network learns to approximate a nonlinear function (‘separate network’) from input-output
pattern pairs. (B) Example ﬁring rates for a randomly chosen output neuron (rP
2   blue noisy trace)
and its desired target imposed by the associative input (rtrgt
  blue dashed line)  together with the
voltage in the apical compartment of a hidden neuron (vP
A 1  grey noisy trace) and the input rate from
0   green). Traces are shown before (i) and after learning (ii). (C) Error curves
the sensory neuron (rP
for the full model and a shallow model for comparison.

2

2  rtrgt

performance. Some learning rate tuning was required to ensure the microcircuit could track the
changes in the bottom-up pyramidal-pyramidal weights  but we did not observe high sensitivity once
the correct parameter regime was identiﬁed. Error curves are exponential moving averages of the sum
of squared errors loss krP
2 k2 computed after every example on unseen input patterns. Test
error performance is measured in a noise-free setting ( = 0). Plasticity induction terms given by
Eqs. 7-9 are low-pass ﬁltered with time constant ⌧w before being deﬁnitely consolidated  to dampen
ﬂuctuations; synaptic plasticity is kept on throughout. Plasticity and neuron model parameters are as
deﬁned above.
We let learning occur in continuous time without pauses or alternations in plasticity as input patterns
are sequentially presented. This is in contrast to previous learning models that rely on computing
activity differences over distinct phases  requiring temporally nonlocal computation  or globally
coordinated plasticity rule switches (Hinton and McClelland  1988; O’Reilly  1996; Xie and Seung 
2003; Scellier and Bengio  2017; Guerguiev et al.  2017). Furthermore  we relaxed the bottom-up
vs. top-down weight symmetry imposed by backprop and kept the top-down weights WPP
1 2 ﬁxed.
Forward WPP
in line with the recently discovered feedback alignment phenomenon (Lillicrap et al.  2016). This
simpliﬁes the architecture  because top-down and interneuron-to-pyramidal synapses need not be
changed. We set the scale of the top-down weights  apical and somatic conductances such that
feedback and teaching inputs were strong  to test the model outside the weak feedback regime
( ! 0) for which our SM theory was developed. Finally  to test robustness  we injected a weak
noise current to every neuron.
Our network was able to learn this harder task (Fig. 2B)  performing considerably better than a
shallow learner where only hidden-to-output weights were adjusted (Fig. 2C). Useful changes were
thus made to hidden layer bottom-up weights. The self-predicting network state emerged throughout
learning from a random initial conﬁguration (see SM; Fig. S1).

1 2 weights quickly aligned to ⇠ 45o of the feedback weightsWPP

2 1T (see Fig. S1) 

3.4 Microcircuit network learns to classify handwritten digits

Next  we turn to the problem of classifying MNIST handwritten digits. We wondered how our
model would fare in this benchmark  in particular whether the prediction errors computed by the
interneuron microcircuit would allow learning the weights of a hierarchical nonlinear network with
multiple hidden layers. To that end  we trained a deeper  larger 4-layer network (with 784-500-500-10
pyramidal neurons  Fig. 3A) by pairing digit images with teaching inputs that nudged the 10 output
neurons towards the correct class pattern. We initialized the network to a random but self-predicting

7

AWPP2 1WPP1 0WPP1 2WIP1 1WPI1 1PA 1rP2shallow learningpyramidal neuron learningSquared errorTraining trial (x107)00.5100.1C0100200rP00100200PA 1Time [ms]Time [ms](ii)(i)beforeafterBlearningr2trgt250rP20v0separate networkteaching/associative inputvr2trgtlayer 2(output)layer 1(hidden)sensoryinputlayer 0ApicalpotentialSensoryinputOutput (Hz)00.503||Apical pot. ||200.503|| pyrk+1 - intk||2Trial (x107)(i)(ii)Figure 3: Dendritic error networks
learn to classify handwritten digits.
(A) A network with two hidden lay-
ers learns to classify handwritten digits
from the MNIST data set. (B) Classi-
ﬁcation error achieved on the MNIST
testing set (blue; cf. shallow learner
(black) and standard backprop6(red)).

k + I uP

k = (1 I) vI

conﬁguration where interneurons cancelled top-down inputs  rendering the apical compartments
silent before training started. Top-down and interneuron-to-pyramidal weights were kept ﬁxed.
Here for computational efﬁciency we used a simpliﬁed network dynamics where the compartmental
potentials are updated only in two steps before applying synaptic changes. In particular  for each
presented MNIST image  both pyramidal and interneurons are ﬁrst initialized to their bottom-
up prediction state (3)  uk = vB k  starting from layer 1 up to the top layer N. Output layer
neurons are then nudged towards their desired target utrgt
N   yielding updated somatic potentials
N = (1  N ) vB N + N utrgt
N . To obtain the remaining ﬁnal compartmental potentials  the
uP
network is visited in reverse order  proceeding from layer k = N  1 down to k = 1. For each k 
interneurons are ﬁrst updated to include top-down teaching signals  uI
k+1; this
yields apical compartment potentials according to (4)  after which we update hidden layer somatic
potentials as a convex combination with mixing factor k. The convex combination factors introduced
above are directly related to neuron model parameters as conductance ratios. Synaptic weights are
then updated according to Eqs. 7-10. Such simpliﬁed dynamics approximates the full recurrent
network relaxation in the deterministic setting  ! 0  with the approximation improving as the
top-down dendritic coupling is decreased  gA ! 0.
We train the models on the standard MNIST handwritten image database  further splitting the training
set into 55000 training and 5000 validation examples. The reported test error curves are computed
on the 10000 held-aside test images. The four-layer network shown in Fig. 3 is initialized in a
self-predicting state with appropriately scaled initial weight matrices. For our MNIST networks 
we used relatively weak feedback weights  apical and somatic conductances (see SM) to justify
our simpliﬁed approximate dynamics described above  although we found that performance did not
appreciably degrade with larger values. To speed-up training we use a mini-batch strategy on every
learning rule  whereby weight changes are averaged across 10 images before being applied. We
take the neuronal transfer function  to be a logistic function  (u) = 1/(1 + exp(u)) and include
a learnable threshold on each neuron  modelled as an additional input ﬁxed at unity with a plastic
weight. Desired target class vectors are 1-hot coded  with rtrgt
N 2{ 0.1  0.8}. During testing  the
output is determined by picking the class label corresponding to the neuron with highest ﬁring rate.
We found the model to be relatively robust to learning rate tuning on the MNIST task  except for the
rescaling by the inverse mixing factor to compensate for teaching signal dilution (see SM for the
exact parameters).
The network was able to achieve a test error of 1.96%  Fig. 3B  a ﬁgure not overly far from the
reference mark of non-convolutional artiﬁcial neural networks optimized with backprop (1.53%) and
comparable to recently published results that lie within the range 1.6-2.4% (Lee et al.  2015; Lillicrap
et al.  2016; Nøkland  2016). The performance of our model also compares favorably to the 3.2%
test error reported by Guerguiev et al. (2017) for a two-hidden-layer network. This was possible
despite the asymmetry of forward and top-down weights and at odds with exact backprop  thanks
to a feedback alignment dynamics. Apical compartment voltages remained approximately silent
when output nudging was turned off (data not shown)  reﬂecting the maintenance of a self-predicting
state throughout learning  which enabled the propagation of errors through the network. To further
demonstrate that the microcircuit was able to propagate errors to deeper hidden layers  and that the
task was not being solved by making useful changes only to the weights onto the topmost hidden
layer  we re-ran the experiment while keeping ﬁxed the pyramidal-pyramidal weights connecting the
two hidden layers. The network still learned the dataset and achieved a test error of 2.11%.

8

BMNIST handwritten digit images50028x2810500inputhidden 1hidden 2output89A1.96%1.53%8.4%02000510TrialsTest error (%)single-layerdendritic microcircuitbackpropAs top-down weights are likely plastic in cortex  we also trained a one-hidden-layer (784-1000-10)
network where top-down weights were learned on a slow time-scale according to learning rule (10).
This inverse learning scheme is closely related to target propagation (Bengio  2014; Lee et al.  2015).
Such learning could play a role in perceptual denoising  pattern completion and disambiguation 
and boost alignment beyond that achieved by pure feedback alignment (Bengio  2014). Starting
from random initial conditions and keeping all weights plastic (bottom-up  lateral and top-down)
throughout  our network achieved a test classiﬁcation performance of 2.48% on MNIST. Once more 
useful changes were made to hidden synapses  even though the microcircuit had to track changes in
both the bottom-up and the top-down pathways.

4 Conclusions

Our work makes several predictions across different levels of investigation. Here we brieﬂy highlight
some of these predictions and related experimental observations. The most fundamental feature of
the model is that distal dendrites encode error signals that instruct learning of lateral and bottom-
up connections. While monitoring such dendritic signals during learning is challenging  recent
experimental evidence suggests that prediction errors in mouse visual cortex arise from a failure
to locally inhibit motor feedback (Zmarz and Keller  2016; Attinger et al.  2017)  consistent with
our model. Interestingly  the plasticity rule for apical dendritic inhibition  which is central to error
encoding in the model  received support from another recent experimental study (Chiu et al.  2018).
A further implication of our model is that prediction errors occurring at a higher-order cortical area
would imply also prediction errors co-occurring at earlier areas. Recent experimental observations in
the macaque face-processing hierarchy support this (Schwiedrzik and Freiwald  2017).
Here we have focused on the role of a speciﬁc interneuron type (SST) as a feedback-speciﬁc
interneuron. There are many more interneuron types that we do not consider in our framework. One
such type are the PV (parvalbumin-positive) cells  which have been postulated to mediate a somatic
excitation-inhibition balance (Vogels et al.  2011; Froemke  2015) and competition (Masquelier
and Thorpe  2007; Nessler et al.  2013). These functions could in principle be combined with our
framework in that PV interneurons may be involved in representing another type of prediction error
(e.g.  generative errors).
Humans have the ability to perform fast (e.g.  one-shot) learning  whereas neural networks trained by
backpropagation of error (or approximations thereof  like ours) require iterating over many training
examples to learn. This is an important open problem that stands in the way of understanding the
neuronal basis of intelligence. One possibility where our model naturally ﬁts is to consider multiple
subsystems (for example  the neocortex and the hippocampus) that transfer knowledge to each other
and learn at different rates (McClelland et al.  1995; Kumaran et al.  2016).
Overall  our work provides a new view on how the brain may solve the credit assignment problem
for time-continuous input streams by approximating the backpropagation algorithm  and bringing
together many puzzling features of cortical microcircuits.

Acknowledgements
The authors would like to thank Timothy P. Lillicrap  Blake Richards  Benjamin Scellier and Mihai
A. Petrovici for helpful discussions. WS thanks Matthew Larkum for many inspiring discussions on
dendritic processing. JS thanks Elena Kreutzer  Pascal Leimer and Martin T. Wiechert for valuable
feedback and critical reading of the manuscript.
This work has been supported by the Swiss National Science Foundation (grant 310030L-156863 of
WS)  the European Union’s Horizon 2020 Framework Programme for Research and Innovation under
the Speciﬁc Grant Agreement No. 785907 (Human Brain Project)  NSERC  CIFAR  and Canada
Research Chairs.

9

References
Ackley  D. H.  Hinton  G. E.  and Sejnowski  T. J. (1985). A learning algorithm for Boltzmann machines.

Cognitive Science  9(1):147–169.

Attinger  A.  Wang  B.  and Keller  G. B. (2017). Visuomotor coupling shapes the functional development of

mouse visual cortex. Cell  169(7):1291–1302.e14.

Bengio  Y. (2014). How auto-encoders could provide credit assignment in deep networks via target propagation.

arXiv:1407.7906

Bono  J. and Clopath  C. (2017). Modeling somatic and dendritic spike mediated plasticity at the single neuron

and network level. Nature Communications  8(1):706.

Bottou  L. (1998). Online algorithms and stochastic approximations. In Saad  D.  editor  Online Learning and

Neural Networks. Cambridge University Press  Cambridge  UK.

Chiu  C. Q.  Martenson  J. S.  Yamazaki  M.  Natsume  R.  Sakimura  K.  Tomita  S.  Tavalin  S. J.  and
Higley  M. J. (2018). Input-speciﬁc nmdar-dependent potentiation of dendritic gabaergic inhibition. Neuron 
97(2):368–377.

Clopath  C.  Büsing  L.  Vasilaki  E.  and Gerstner  W. (2010). Connectivity reﬂects coding: a model of

voltage-based stdp with homeostasis. Nature Neuroscience  13(3):344–352.

Costa  R. P.  Assael  Y. M.  Shillingford  B.  de Freitas  N.  and Vogels  T. P. (2017). Cortical microcircuits as

gated-recurrent neural networks. In Advances in Neural Information Processing Systems  pages 271–282.

Crick  F. (1989). The recent excitement about neural networks. Nature  337:129–132.

Dorrn  A. L.  Yuan  K.  Barker  A. J.  Schreiner  C. E.  and Froemke  R. C. (2010). Developmental sensory

experience balances cortical excitation and inhibition. Nature  465(7300):932–936.

Friedrich  J.  Urbanczik  R.  and Senn  W. (2011). Spatio-temporal credit assignment in neuronal population

learning. PLOS Computational Biology  7(6):e1002092.

Friston  K. (2005). A theory of cortical responses. Philosophical Transactions of the Royal Society of London B:

Biological Sciences  360(1456):815–836.

Froemke  R. C. (2015). Plasticity of cortical excitatory-inhibitory balance. Annual Review of Neuroscience 

38(1):195–219.

Fu  Y.  Kaneko  M.  Tang  Y.  Alvarez-Buylla  A.  and Stryker  M. P. (2015). A cortical disinhibitory circuit for

enhancing adult plasticity. eLife  4:e05558.

Grossberg  S. (1987). Competitive learning: From interactive activation to adaptive resonance. Cognitive

Science  11(1):23–63.

Guerguiev  J.  Lillicrap  T. P.  and Richards  B. A. (2017). Towards deep learning with segregated dendrites.

eLife  6:e22901.

Hinton  G. E. and McClelland  J. L. (1988). Learning representations by recirculation. In Anderson  D. Z. 

editor  Neural Information Processing Systems  pages 358–366. American Institute of Physics.

Kell  A. J.  Yamins  D. L.  Shook  E. N.  Norman-Haignere  S. V.  and McDermott  J. H. (2018). A task-optimized
neural network replicates human auditory behavior  predicts brain responses  and reveals a cortical processing
hierarchy. Neuron.

Khaligh-Razavi  S.-M. and Kriegeskorte  N. (2014). Deep supervised  but not unsupervised  models may explain

it cortical representation. PLOS Computational Biology  10(11):1–29.

Körding  K. P. and König  P. (2000). Learning with two sites of synaptic integration. Network: Comput. Neural

Syst.  11:1–15.

Körding  K. P. and König  P. (2001). Supervised and unsupervised learning with two sites of synaptic integration.

Journal of Computational Neuroscience  11:207–215.

Kumaran  D.  Hassabis  D.  and McClelland  J. L. (2016). What learning systems do intelligent agents need?

complementary learning systems theory updated. Trends in Cognitive Sciences  20(7):512 – 534.

10

Larkum  M. (2013). A cellular mechanism for cortical associations: an organizing principle for the cerebral

cortex. Trends in Neurosciences  36(3):141–151.

LeCun  Y. (1988). A theoretical framework for back-propagation. In Touretzky  D.  Hinton  G.  and Sejnowski 
T.  editors  Proceedings of the 1988 Connectionist Models Summer School  pages 21–28. Morgan Kaufmann 
Pittsburg  PA.

LeCun  Y.  Bengio  Y.  and Hinton  G. (2015). Deep learning. Nature  521(7553):436–444.

Lee  D.-H.  Zhang  S.  Fischer  A.  and Bengio  Y. (2015). Difference target propagation. In Machine Learning

and Knowledge Discovery in Databases  pages 498–515. Springer.

Leinweber  M.  Ward  D. R.  Sobczak  J. M.  Attinger  A.  and Keller  G. B. (2017). A Sensorimotor Circuit in

Mouse Cortex for Visual Flow Predictions. Neuron  95(6):1420–1432.e5.

Lillicrap  T. P.  Cownden  D.  Tweed  D. B.  and Akerman  C. J. (2016). Random synaptic feedback weights

support error backpropagation for deep learning. Nature Communications  7:13276.

Lillicrap  T. P. and Scott  S. H. (2013). Preference distributions of primary motor cortex neurons reﬂect control

solutions optimized for limb biomechanics. Neuron  77(1):168–179.

Luz  Y. and Shamir  M. (2012). Balancing feed-forward excitation and inhibition via Hebbian inhibitory synaptic

plasticity. PLOS Computational Biology  8(1):e1002334.

Makino  H. and Komiyama  T. (2015). Learning enhances the relative impact of top-down processing in the

visual cortex. Nature Neuroscience  18(8):1116–1122.

Manita  S.  Suzuki  T.  Homma  C.  Matsumoto  T.  Odagawa  M.  Yamada  K.  Ota  K.  Matsubara  C. 
Inutsuka  A.  Sato  M.  et al. (2015). A top-down cortical circuit for accurate sensory perception. Neuron 
86(5):1304–1316.

Marblestone  A. H.  Wayne  G.  and Kording  K. P. (2016). Toward an integration of deep learning and

neuroscience. Frontiers in Computational Neuroscience  10:94.

Masquelier  T. and Thorpe  S. (2007). Unsupervised learning of visual features through spike timing dependent

plasticity. PLOS Computational Biology  3.

McClelland  J. L.  McNaughton  B. L.  and O’reilly  R. C. (1995). Why there are complementary learning
systems in the hippocampus and neocortex: insights from the successes and failures of connectionist models
of learning and memory. Psychological review  102(3):419.

Nessler  B.  Pfeiffer  M.  Buesing  L.  and Maass  W. (2013). Bayesian computation emerges in generic cortical

microcircuits through spike-timing-dependent plasticity. PLOS Computational Biology  9(4):e1003037.

Nøkland  A. (2016). Direct feedback alignment provides learning in deep neural networks. In Advances in

Neural Information Processing Systems  pages 1037–1045.

O’Reilly  R. C. (1996). Biologically plausible error-driven learning using local activation differences: The

generalized recirculation algorithm. Neural Computation  8(5):895–938.

Pakan  J. M.  Lowe  S. C.  Dylda  E.  Keemink  S. W.  Currie  S. P.  Coutts  C. A.  Rochefort  N. L.  and
Mrsic-Flogel  T. D. (2016). Behavioral-state modulation of inhibition is context-dependent and cell type
speciﬁc in mouse visual cortex. eLife  5:e14985.

Petreanu  L.  Gutnisky  D. A.  Huber  D.  Xu  N.-l.  O’Connor  D. H.  Tian  L.  Looger  L.  and Svoboda 
K. (2012). Activity in motor-sensory projections reveals distributed coding in somatosensation. Nature 
489(7415):299–303.

Petreanu  L.  Mao  T.  Sternson  S. M.  and Svoboda  K. (2009). The subcellular organization of neocortical

excitatory connections. Nature  457(7233):1142–1145.

Poort  J.  Khan  A. G.  Pachitariu  M.  Nemri  A.  Orsolic  I.  Krupic  J.  Bauza  M.  Sahani  M.  Keller 
G. B.  Mrsic-Flogel  T. D.  and Hofer  S. B. (2015). Learning enhances sensory and multiple non-sensory
representations in primary visual cortex. Neuron  86(6):1478–1490.

Rao  R. P. and Ballard  D. H. (1999). Predictive coding in the visual cortex: a functional interpretation of some

extra-classical receptive-ﬁeld effects. Nature Neuroscience  2(1):79–87.

Roelfsema  P. R. and Holtmaat  A. (2018). Control of synaptic plasticity in deep cortical networks. Nature

Reviews Neuroscience  19(3):166.

11

Roelfsema  P. R. and van Ooyen  A. (2005). Attention-gated reinforcement learning of internal representations

for classiﬁcation. Neural Computation  17(10):2176–2214.

Rumelhart  D. E.  Hinton  G. E.  and Williams  R. J. (1986). Learning representations by back-propagating

errors. Nature  323:533–536.

Scellier  B. and Bengio  Y. (2017). Equilibrium propagation: Bridging the gap between energy-based models

and backpropagation. Frontiers in Computational Neuroscience  11:24.

Schwiedrzik  C. M. and Freiwald  W. A. (2017). High-level prediction signals in a low-level area of the macaque

face-processing hierarchy. Neuron  96(1):89–97.e4.

Sjöström  P. J.  Turrigiano  G. G.  and Nelson  S. B. (2001). Rate  Timing  and Cooperativity Jointly Determine

Cortical Synaptic Plasticity. Neuron  32(6):1149–1164.

Spicher  D.  Clopath  C.  and Senn  W. (2018). Predictive plasticity in dendrites: from a computational principle

to experimental data (in preparation).

Spruston  N. (2008). Pyramidal neurons: dendritic structure and synaptic integration. Nature Reviews Neuro-

science  9(3):206–221.

Sutton  R. S. and Barto  A. G. (1998). Reinforcement learning: An introduction  volume 1. MIT Press 

Cambridge  Mass.

Urban-Ciecko  J. and Barth  A. L. (2016). Somatostatin-expressing neurons in cortical networks. Nature Reviews

Neuroscience  17(7):401–409.

Urbanczik  R. and Senn  W. (2014). Learning by the dendritic prediction of somatic spiking. Neuron  81(3):521–

528.

Vogels  T. P.  Sprekeler  H.  Zenke  F.  Clopath  C.  and Gerstner  W. (2011). Inhibitory plasticity balances

excitation and inhibition in sensory pathways and memory networks. Science  334(6062):1569–1573.

Whittington  J. C. R. and Bogacz  R. (2017). An approximation of the error backpropagation algorithm in a

predictive coding network with local Hebbian synaptic plasticity. Neural Computation  29(5):1229–1262.

Xie  X. and Seung  H. S. (2003). Equivalence of backpropagation and contrastive Hebbian learning in a layered

network. Neural Computation  15(2):441–454.

Yamins  D. L. and DiCarlo  J. J. (2016). Using goal-driven deep learning models to understand sensory cortex.

Nature Neuroscience  19(3):356–365.

Yamins  D. L.  Hong  H.  Cadieu  C. F.  Solomon  E. A.  Seibert  D.  and DiCarlo  J. J. (2014). Performance-
optimized hierarchical models predict neural responses in higher visual cortex. Proceedings of the National
Academy of Sciences  111(23):8619–8624.

Zmarz  P. and Keller  G. B. (2016). Mismatch receptive ﬁelds in mouse visual cortex. Neuron  92(4):766–772.

12

,João Sacramento
Rui Ponte Costa
Yoshua Bengio
Walter Senn