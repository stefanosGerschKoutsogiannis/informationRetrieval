2009,A Neural Implementation of the Kalman Filter,There is a growing body of experimental evidence to suggest that the brain is capable of approximating optimal Bayesian inference in the face of noisy input stimuli.  Despite this progress  the neural underpinnings of this computation are still poorly  understood.  In this paper we focus on the problem of Bayesian filtering of stochastic time series.  In particular we introduce a novel neural network  derived from a line attractor architecture  whose dynamics map directly onto those of the Kalman Filter in the limit where the prediction error is small.  When the prediction error is large we show that the network responds robustly to change-points in a way that is qualitatively compatible with the optimal Bayesian model.  The model suggests ways in which probability distributions are encoded in the brain and makes a number of testable experimental predictions.,A Neural Implementation of the Kalman Filter

Robert C. Wilson

Department of Psychology

Princeton University
Princeton  NJ 08540

rcw2@princeton.edu

Leif H. Finkel

Department of Bioengineering

University of Pennsylvania

Philadelphia  PA 19103

Abstract

Recent experimental evidence suggests that the brain is capable of approximating
Bayesian inference in the face of noisy input stimuli. Despite this progress  the
neural underpinnings of this computation are still poorly understood. In this pa-
per we focus on the Bayesian ﬁltering of stochastic time series and introduce a
novel neural network  derived from a line attractor architecture  whose dynamics
map directly onto those of the Kalman ﬁlter in the limit of small prediction error.
When the prediction error is large we show that the network responds robustly to
changepoints in a way that is qualitatively compatible with the optimal Bayesian
model. The model suggests ways in which probability distributions are encoded
in the brain and makes a number of testable experimental predictions.

1

Introduction

There is a growing body of experimental evidence consistent with the idea that animals are some-
how able to represent  manipulate and  ultimately  make decisions based on  probability distribu-
tions. While still unproven  this idea has obvious appeal to theorists as a principled way in which to
understand neural computation. A key question is how such Bayesian computations could be per-
formed by neural networks. Several authors have proposed models addressing aspects of this issue
[15  10  9  19  2  3  16  4  11  18  17  7  6  8]  but as yet  there is no conclusive experimental evidence
in favour of any one and the question remains open.
Here we focus on the problem of tracking a randomly moving  one-dimensional stimulus in a noisy
environment. We develop a neural network whose dynamics can be shown to approximate those of a
one-dimensional Kalman ﬁlter  the Bayesian model when all the distributions are Gaussian. Where
the approximation breaks down  for large prediction errors  the network performs something akin to
outlier or change detection and this ‘failure’ suggests ways in which the network can be extended to
deal with more complex  non-Gaussian distributions over multiple dimensions.
Our approach rests on the modiﬁcation of the line attractor network of Zhang [26]. In particular  we
make three changes to Zhang’s network  modifying the activation rule  the weights and the inputs
in such a way that the network’s dynamics map exactly onto those of the Kalman ﬁlter when the
prediction error is small. Crucially  these modiﬁcations result in a network that is no longer a line
attractor and thus no longer suffers from many of the limitations of these networks.

2 Review of the one-dimensional Kalman ﬁlter

For clarity of exposition and to deﬁne notation  we brieﬂy review the equations behind the one-
dimensional Kalman ﬁlter. In particular  we focus on tracking the true location of an object  x(t) 
over time  t  based on noisy observations of its position z(t) = x(t) + nz(t)  where nz(t) is zero
mean Gaussian random noise with standard deviation σz(t)  and a model of its dynamics  x(t+1) =

1

x(t) + v(t) + nv(t)  where v(t) is the velocity signal and nv(t) is a Gaussian noise term with zero
mean and standard deviation σv(t). Assuming that σz(t)  σv(t) and v(t) are all known  then the
Kalman ﬁlter’s estimate of the position  ˆx(t)  can be computed via the following three equations

1

ˆσx(t + 1)2 =

¯x(t + 1) = ˆx(t) + v(t)
ˆσx(t)2 + σv(t)2 +

1

1

σz(t + 1)2

ˆx(t + 1) = ¯x(t + 1) +

ˆσx(t + 1)2
σz(t + 1)2 [z(t + 1) − ¯x(t + 1)]

(1)

(2)

(3)

In equation 1 the model computes a prediction  ¯x(t+1)  for the position at time t+1; equation 2 up-
dates the model’s uncertainty  ˆσx(t+1)  in its estimate; and equation 3 updates the model’s estimate
of position  ˆx(t + 1)  based on this uncertainty and the prediction error [z(t + 1) − ¯x(t + 1)].

3 The neural network

The network is a modiﬁcation of Zhang’s line attractor model of head direction cells [26]. We use
rate neurons and describe the state of the network at time t with the membrane potential vector  u(t) 
where each component of u(t) denotes the membrane potential of a single neuron. In discrete time 
the update equation is then
(4)
where w scales the strength of the weights  J is the connectivity matrix  f[·] is the activation rule that
maps membrane potential onto ﬁring rate  and I(t + 1) is the input at time t + 1. As in [26]  we set
J = Jsym + γ(t)Jasym such that the the connections are made up of a mixture of symmetric  Jsym 
and asymmetric components  Jasym (deﬁned as spatial derivative of Jsym)  with mixing strength
γ(t) that can vary over time. Although the results presented here do not depend strongly on the exact
forms of Jsym and Jasym  for concreteness we use the following expressions

u(t + 1) = wJf [u(t)] + I(t + 1)

cos

(cid:16) 2π(i−j)

(cid:17) − 1

 − c

J sym
ij = Kw exp

N
σ2
w

;

J asym
ij

= − 2π
N σ2
w

sin

(cid:18)2π(i − j)

(cid:19)

N

J sym
ij

(5)

where N is the number of neurons in the network and σw  Kw and c are constants that determine
the width and excitatory and inhibitory connection strengths respectively.
To approximate the Kalman ﬁlter  the activation function must implement divisive inhibition [14  13]

S + µ(cid:80)

[u]+

i[ui]+

f[u] =

(6)

where [u]+ denotes recitiﬁcation of u; µ determines the strength of the divisive feedback and S
determines the gain when there is no previous activity in the network.
When w = 1  γ(t) = 0 and I(t) = 0  the network is a line attractor over a wide range of Kw 
σw  c  S and µ  having a continuum of ﬁxed points (as N → ∞). Each ﬁxed point has the same
shape  taking the form of a smooth membrane potential proﬁle  U(x) = Jsymf [U(x)]  centered at
location  x  in the network.
When γ(t) (cid:54)= 0  the bump of activity can be made to move over time (without losing its shape) [26]
and hence  so long as γ(t) = v(t)  implement the prediction step of the Kalman ﬁlter (equation
1). That is  if the bump at time t is centered at ˆx(t)  i.e. u(t) = U(ˆx(t))  then at time t + 1 it is
centered at ¯x(t + 1) = ˆx(t) + γ(t)  i.e. u(t + 1) = U(ˆx(t) + γ(t)) = U(¯x(t + 1)). Thus  in
this conﬁguration  the network can already implement the ﬁrst step of the Kalman ﬁlter through its
recurrent connectivity. The next two steps  equations 2 and 3  however  remain inaccessible as the
network has no way of encoding uncertainty and it is unclear how it will deal with external inputs.

4 Relation to Kalman ﬁlter - small prediction error case

In this section we outline how the neural network dynamics can be mapped onto those of a Kalman
ﬁlter. In the interests of space we focus only on the main points of the derivation  leaving the full
working to the supplementary material.

2

Our approach is to analyze the network in terms of U  which  for clarity  we deﬁne here to be the
ﬁxed point membrane potential proﬁle of the network when w = 1  γ(t) = 0  I(t) = 0  S = S0 and
µ = µ0. Thus  the results described here are independent of the exact form of U so long as it is a
smooth  non-uniform proﬁle over the network.
We begin by making the assumption that both the input  I(t)  and the network membrane potential 
u(t)  take the form of scaled versions U  with the former encoding the noisy observations  z(t)  and
the latter encoding the network’s estimate of position  ˆx(t)  i.e. 

I(t) = A(t)U(z(t))

and u(t) = α(t)U(ˆx(t))

Substituting this ansatz for membrane potential into the left hand side of equation 4 gives

LHS = α(t + 1)U (ˆx(t + 1))

and into the right hand side of equation 4 gives

RHS = wJf [α(t)U (ˆx(t))]

+ A(t + 1)U (z(t + 1))

(cid:125)

(cid:124)

(cid:123)(cid:122)

(cid:125)

recurrent input

external input

For the ansatz to be self-consistent we require that RHS can be written in the same form as LHS.
We now show that this is the case.
As in the previous section  the recurrent input  implements the prediction step of the Kalman ﬁlter 
which  after a little algebra (see supplementary material)  allows us to write

RHS ≈ CU (¯x(t + 1))

+ A(t + 1)U (z(t + 1))

(cid:125)

(cid:124)

(cid:123)(cid:122)

(cid:125)

prediction

external input

(cid:124)

(cid:124)

(cid:123)(cid:122)

(cid:123)(cid:122)

(cid:18)

(7)

(8)

(9)

(10)

(11)

(12)

(13)

(14)

(15)

(16)

With the variable C deﬁned as

where I =(cid:80)

i [Ui(ˆx(t))]+.

C =

1

S

w(S0+µ0I)

1

α(t) +

µI

w(S0+µ0I)

If we now suppose that the prediction error [z(t + 1) − ¯x(t + 1)] is small  then we can linearize
around the prediction  ¯x(t + 1)  to get (see supplementary material)

RHS ≈ [C + A(t + 1)] U

¯x(t + 1) + A(t + 1)
A(t + 1) + C

[z(t + 1) − ¯x(t + 1)]

which is of the same form as equation 8 and thus the ansatz holds. More speciﬁcally  equating terms
in equations 8 and 12  we can write down expressions for α(t + 1) and ˆx(t + 1)

(cid:19)

α(t + 1) ≈ C + A(t + 1) =

S

w(S0+µ0I)
ˆx(t + 1) ≈ ¯x(t) + A(t + 1)
α(t + 1)

1

1

α(t) +

µI

w(S0+µ0I)

+ A(t + 1)

[z(t + 1) − x(t + 1)]

which  if we deﬁne w such that

S

w(S0 + µ0I)

= 1

i.e.

w =

S

S0 + µ0I

are identical to equations 2 and 3 so long as

(a) α(t) ∝ 1

ˆσx(t)2

(b) A(t) ∝ 1

σz(t)2

(c)

µI
S

∝ σv(t)2

Thus the network dynamics  when the prediction error is small  map directly onto the Kalman ﬁlter
equations. This is our main result.

3

Figure 1: Comparison of noiseless network dynamics with dynamics of the Kalman Filter for small
prediction errors.

4.1

Implications

Reciprocal code for uncertainty in input and estimate Equation 16a provides a link between the
strength of activity in the network and the overall uncertainty in the estimate of the Kalman ﬁlter 
ˆσx(t)  with uncertainty decreasing as the activity increases. A similar relation is also implied for the
uncertainty in the observations  σz(t)  where equation 16b suggests that this should be reﬂected in
the magnitude of the input  A(t). Interestingly  such a scaling  without a corresponding narrowing
of tuning curves  is seen in the brain [20  5  2].

Code for velocity signal As with Zhang’s line attractor network [26]  the mean of the velocity
signal  v(t) is encoded into the recurrent connections of the network  with the degree of asymmetry
in the weights  γ(t)  proportional to the speed. Such hard coding of the velocity signal represents
a limitation of the model  as we would like to be able to deal with arbitrary  time varying speeds.
However  this kind of change could be implemented by pre-synaptic inhibition [24] or by using a
‘double-ring’ network similar to [25].
Equation 16c implies that the variance of the velocity signal  σv(t)  is encoded in the strength of the
divisive feedback  µ (assuming constant S). This is very different from Zhang’s model  that has no
concept of uncertainty and is also very different from the traditional view of divisive inhibition that
sees it as a mechanism for gain control [14  13].

The network is no longer a line attractor This can be seen by considering the ﬁxed point values
of the scale factor  α(t)  when the input current  I(t) = 0. Requiring α(t + 1) = α(t) = α∗ in
equation 13 gives values for these ﬁxed points as

α∗ = 0

and

α∗ =

(cid:18) S0 + µ0I

(cid:19)

µI

w − S
µI

(17)

This second solution is exactly zero when w satisﬁes equation 15  hence the network only has one
ﬁxed point corresponding to the all zero state and is not a line attractor. This is a key result as it
removes all of the constraints required for line attractor dynamics such as inﬁnite precision in the
weights and lack of noise in the network and thus the network is much more biologically plausible.

4.2 An example

In ﬁgure 1 we demonstrate the ability of the network to approximate the dynamics of a one-
dimensional Kalman ﬁlter. The input  shown in ﬁgure 1A  is a noiseless bump of current centered

4

neuron #time step02040608010020406080100neuron #time step020406080100204060801000204060801002030405060positiontime step0204060801000246time stepσx(t)ABCDFigure 2: Response of the network when presented with a noisy moving bump input.

at the position of the observation  z(t). The observation noise has standard deviation σz(t) = 5  the
speed v(t) = 0.5 for 1 ≤ t < 50 and v(t) = −0.5 for 50 ≤ t < 100 and the standard deviation of
the random walk dynamics  σv(t) = 0.2. In accordance with equation 16b  the height of each bump
is scaled by 1/σz(t)2.
In ﬁgure 1B we plot the output activity of the network over time. Darker shades correspond to higher
ﬁring rates. We assume that the network gets the correct velocity signal  i.e. γ(t) = v(t) and µ is
set such that equation 16c holds. The other parameters are set to Kw = 1  σw = 0.2  c = 0.05 
S = S0 = 1 and µ0 = 1 which gives I = 5.47. As can be seen from the plot  the amount of
activity in the network steadily grows from zero over time to an asymptotic value  corresponding
to the network’s increasing certainty in its predictions. The position of the bump of activity in the
network is also much less jittery than the input bump  reﬂecting a certain amount of smoothing.
In ﬁgure 1C we compare the positions of the input bumps (gray dots) with the position of the network
bump (black line) and the output of the equivalent Kalman ﬁlter (red line). The network clearly
tracks the Kalman ﬁlter estimate extremely well. The same is true for the network’s estimate of

the uncertainty  computed as 1/(cid:112)α(t) and shown as the black line in ﬁgure 1D  which tracks the

Kalman ﬁlter uncertainty (red line) almost exactly.

5 Effect of input noise

We now consider the effect of noise on the ability of the network to implement a Kalman ﬁlter. In
particular we consider noise in the input signal  which for this simple one layer network is equivalent
to having noise in the update equation. For brevity  we only present the main results along with the
results of simulations  leaving more detailed analysis to the supplementary material.
Speciﬁcally  we consider input signals where the only source of noise is in the input current i.e. there
is no additional jitter in the position of the bump as there was in the noiseless case  thus we write

I(t) = A(t)U (x(t)) + (t)

(18)

where (t) is some noise vector. The main effect of the noise is that it perturbs the effective position
of the input bump. This can be modeled by extracting the maximum likelihood estimate of the input
position given the noisy input and then using this position as the input to the equivalent Kalman
ﬁlter. Because of the noise  this extracted position is not  in general  the same as the noiseless input
position and for zero mean Gaussian noise with covariance Σ  the variance of the perturbation  σz(t) 

5

neuron #time step02040608010020406080100neuron #time step020406080100204060801000204060801002030405060positiontime step02040608010000.511.52time stepσx(t)ABCDFigure 3: Effect of noise magnitude on performance of network.

is approximately given by

(cid:114)

2

U(cid:48)T Σ−1U(cid:48)

σz(t) ≈ 1
A(t)

(19)

Now  for the network to approximate a Kalman ﬁlter  equation 16b must hold which means that we
require the magnitude of the covariance matrix to scale in proportion to the strength of the input
signal  A(t)  i.e. Σ ∝ A(t). Interestingly this relation is true for Poisson noise  the type of noise
that is found all over the brain.
In ﬁgure 2 we demonstrate the ability of the network to approximate a Kalman ﬁlter. In panel A
we show the input current which is a moving bump of activity corrupted by independent Gaussian
noise of standard deviation σnoise = 0.23  or about two thirds of the maximum height of the ﬁxed
point bump  U. This is a high noise setting and it is hard to see the bump location by eye. The
network dramatically cleans up this input signal (ﬁgure 2B) and the output activity  although still
noisy  reﬂects the position of the underlying stimulus much more faithfully than the input. (Note
that the colour scales in A and B are different).
In panel C we compare the position of the output bump in the network (black line) with that of the
equivalent Kalman ﬁlter. To do this we ﬁrst ﬁt the noisy input bump at each time to obtain input
positions z(t) shown as gray dots. Then using σz = 2.23 computed using equation 19 we can
compute the estimates of the equivalent Kalman ﬁlter (thick red line). which closely match those
of the network (black line). Similarly  there is good agreement between the two estimates of the
uncertainty  ˆσx(t)  panel D (black line - network  red line - Kalman ﬁlter).

5.1 Performance of the network as a function of noise magnitude

The noise not only affects the position of the input bump but also  in a slightly more subtle manner 
causes a gradual decline in the ability of the network to emulate a Kalman ﬁlter. The reason for
this (outlined in more detail in the supplementary material) is that the output bump scale factor 
α  decreases as a function of the noise variance  σnoise. This effect is illustrated in ﬁgure 3A
where we plot the steady state value of α (for constant input strength  A(t)) as a function of σnoise.
The average results of simulations on 100 neurons are shown as the red dots  while the black line
represents the results of the theory in the supplementary material.
The reason for the decline in α as σnoise goes up is that  because of the rectifying non-linearity in
the activation rule  increasing σnoise increases the amount of noisy activity in the network. Because
of inhibition (both divisive and subtractive) in the network  this ‘noisy activity’ competes with the
bump activity and decreases it - thus reducing α.
This decrease in α results in a change in the Kalman gain of the network  by equation 14  making
it different from that of the equivalent Kalman ﬁlter  thus degrading the network’s performance. We
quantify this difference in ﬁgure 3B where we plot the root mean squared error (in units of neural
position) between the network and the equivalent Kalman ﬁlter as a function of σnoise. As before  the
results of simulations are shown as red dots and the theory (outlined in the supplementary material)
is the black line. To give some sense for the scale on this plot  the horizontal blue line corresponds
to the maximum height of the (noise free) input bump. Thus we may conclude that the performance
of the network and the theory are robust up to fairly large values of σnoise.

6

00.511.522.530246ασnoise00.511.522.530246810σnoiseERMS vs KFABFigure 4: Response of the network to changepoints.

6 Response to changepoints (and outliers) - large prediction error case

We now consider the dynamics of the network when the prediction error is large. By large we mean
that the prediction error is greater than the width of the bump of activity in the network. Such a big
discrepancy could be caused by an outlier or a changepoint  i.e. a sustained large and abrupt change
in the input position at a random time. In the interests of space we focus only on the latter case and
such an input  with a changepoint at t = 50  is shown in ﬁgure 4A.
In ﬁgure 4B we show the network’s response to this stimulus. As before  prior to the change  there
is a single bump of activity whose position approximates that of a Kalman ﬁlter. However  after the
changepoint  the network maintains two bumps of activity for several time steps. One at the original
position  that shrinks over time and essentially predicts where the input would be if the change had
not occurred  and a second  that grows over time  at the location of the input after the changepoint.
Thus in the period immediately after the changepoint  the network can be thought of as encoding
two separate and competing hypotheses about the position of the stimulus  one corresponding to the
case where no change has occurred  and the other  the case where a change occurred at t = 50.
In ﬁgure 4C we compare the position of the bump(s) in the network (black dots whose size reﬂects
the size of each bump) to the output from the Kalman ﬁlter (red line). Before the changepoint  the
two agree well  but after the change  the Kalman ﬁlter becomes suboptimal  taking a long time to
move to the new position. The network  however  by maintaining two hypotheses reacts much better.
Finally  in ﬁgure 4D we plot the scale factor  αi(t)  of each bump as computed from the simulations
(black dots) and from the approximate analytic solution described in the supplementary material
(red line for bump at 30  blue line for bump at 80). As can be seen  there is good agreement between
theory and simulation  with the largest discrepancy occurring for small values of the scale factor.
Thus  when confronted with a changepoint  the network no longer approximates a Kalman ﬁlter
and instead maintains two competing hypotheses in a way that is qualitatively similar to that of the
run-length distribution in [1]. This is an extremely interesting result and hints at ways in which more
complex distributions may be encoded in these type of networks.

7 Discussion

7.1 Relation to previous work

Of the papers mentioned in the introduction  two are of particular relevance to the current work.
In the ﬁrst  [8]  the authors considered a neural implementation of the Kalman ﬁlter using line

7

time stepneuron #02040608010020406080100time stepneuron #02040608010020406080100020406080100020406080100time stepposition0204060801000123time stepαi(t)ABCDattractors. Although this work  at ﬁrst glance  seems similar to what is presented here  there are
several major differences  the main one being that our network is not a line attractor at all  while the
results in [8] rely on this property. Also  in [8]  the Kalman gain is changed manually  where as in
our case it adjusts automatically (equations 13 and 14)  and the form of non-linearity is different.
Probabilistic population coding [16  4] is more closely related to model presented here. Combined
with divisive normalization  these networks can implement a Kalman ﬁlter exactly  while the model
presented here can ‘only’ approximate one. While this may seem like a limitation of our network 
we see it as an advantage as the breakdown of the approximation leads to a more robust response to
outliers and changepoints than a pure Kalman ﬁlter.

7.2 Extension beyond one-dimensional Gaussians

A major limitation of the current model is that it only applies to one-dimensional Gaussian tracking
- clearly an unreasonable restriction for the brain. One possible way around this limitation is hinted
at by the response of the network in the changepoint case where we saw two  largely independent
bumps of activity in the network. This ability to encode multiple ‘particles’ in the network may
allow networks of this kind to implement something like the dynamics of a particle ﬁlter [12] that
can approximate the inference process for non-linear and non-Gaussian systems. Such a possibility
is an intriguing idea for future work.

7.3 Experimental predictions

The model makes at least two easily testable predictions about the response of head direction cells
[21  22  23] in rats. The ﬁrst comes by considering the response of the neurons in the ‘dark’.
Assuming that all bearing cues can indeed be eliminated  by setting A(t) = 0 in equation 13  we
expect the activity of the neurons to fall off as 1/t and that the shape of the tuning curves will
remain approximately constant. Note that this prediction is vastly different from the behaviour of a
line attractor  where we would not expect the level of activity to fall off at all in the dark.
Another  slightly more ambitious experiment would involve perturbing the reliability of one of the
landmark cues. In particular  one could imagine a training phase  where the position of one landmark
is jittered over time  such that each time the rat encounters it it is at a slightly different heading. In
the test case  all other  reliable  landmark cues would be removed and the response of head direction
cells measured in response to presentation of the unreliable cue alone. The prediction of the model
is that this would reduce the strength of the input  A  which in turn reduces the level of activity in
the head direction cells  α. In particular  if σz is the jitter of the unreliable landmark  then we expect
α to scale as 1/σ2
z. This prediction is very different from that of a line attractor which would predict
a constant level of activity regardless of the reliability of the landmark cues.

8 Conclusions

In this paper we have introduced a novel neural network model whose dynamics map directly onto
those of a one-dimensional Kalman ﬁlter when the prediction error is small. This property is robust
to noise and when the prediction error is large  such as for changepoints  the output of the network
diverges from that of the Kalman ﬁlter  but in a way that is both interesting and useful. Finally  the
model makes two easily testable experimental predictions about head direction cells.

Acknowledgements

We would like to thank the anonymous reviewers for their very helpful comments on this work.

References
[1] R.P. Adams and D.J.C. MacKay. Bayesian online changepoint detection. Technical report  University of

Cambridge  Cambridge  UK  2007.

[2] J. S. Anderson  I. Lampl  D. C. Gillespie  and D. Ferster. The contribution of noise to contrast invariance

of orientation tuning in cat visual cortex. Science  290:1968–1972  2000.

8

[3] M. J. Barber  J. W. Clark  and C. H. Anderson. Neural representation of probabilistic information. Neural

Computation  15:1843–1864  2003.

[4] J. Beck  W. J. Ma  P. E. Latham  and A. Pouget. Probabilistic population codes and the exponential family

of distributions. Progress in Brain Research  165:509–519  2007.

[5] K. H. Britten  M. N. Shadlen  W. T. Newsome  and J. A. Movshon. Response of neurons in macaque mt

to stochastic motion signals. Visual Neuroscience  10(1157-1169)  1993.

[6] S. Deneve. Bayesian spiking neurons i: Inference. Neural Computation  20:91–117  2008.
[7] S. Deneve. Bayesian spiking neurons ii: Learning. Neural Computation  20:118–145  2008.
[8] S. Deneve  J.-R. Duhammel  and A. Pouget. Optimal sensorimotor integration in recurrent cortical net-

works: a neural implementation of kalman ﬁlters. Journal of Neuroscience  27(21):5744–5756  2007.

[9] S. Deneve  P. E. Latham  and A. Pouget. Reading population codes: a neural implementation of ideal

observers. Nature Neuroscience  2(8):740–745  1999.

[10] S. Deneve  P. E. Latham  and A. Pouget. Efﬁcient computation and cue integration with noisy population

codes. Nature Neuroscience  4(8):826–831  2001.

[11] J. I. Gold and M. N. Shadlen. Representation of a perceptual decision in developing oculomotor com-

mands. Nature  404(390-394)  2000.

[12] N. J. Gordon  D. J. Salmond  and A. F. M. Smith. Novel approach to nonlinear/non-gaussian bayesian

state estimation. IEE-Proceedings-F  140:107–113  1993.

[13] D. J. Heeger. Modeling simple cell direction selectivity with normalized half-squared  linear operators.

Journal of Neurophysiology  70:1885–1897  1993.

[14] D. J. Heeger. Normalization of cell responses in cat striate cortex. Visual Neuroscience  9:181–198  1993.
[15] P. E. Latham  S. Deneve  and A. Pouget. Optimal computation with attractor networks. Journal of

Physiology Paris  97(683-694)  2003.

[16] W. J. Ma  J. M. Beck  P. E. Latham  and A. Pouget. Bayesian inference with probabilistic population

codes. Nature Neuroscience  9(11):1432–1438  2006.

[17] R. P. N. Rao. Bayesian computation in recurrent neural circuits. Neural Computation  16:1–38  2004.
[18] R. P. N. Rao. Hierarchical bayesian inference in networks of spiking neurons. In Advances in Neural

Information Processing Systems  volume 17  2005.

[19] M. Sahani and P. Dayan. Doubly distributional population codes: simultaneous representation of uncer-

tainty and multiplicity. Neural Computation  15:2255–2279  2003.

[20] G. Sclar and R. D. Freeman. Orientation selectivity in the cat’s striate cortex is invariant with stimulus

contrast. Experimental Brain Research  46:457–461  1982.

[21] J. S. Taube  R. U. Muller  and J. B. Ranck. Head-direction cells recorded from postsubiculum in freely

moving rats. i. description and quantitative analysis. Journal of Neuroscience  10(2):420–435  1990.

[22] J. S. Taube  R. U. Muller  and J. B. Ranck. Head-direction cells recorded from postsubiculum in freely
moving rats. ii. effects of environmental manipulations. Journal of Neuroscience  10(2):436–447  1990.
[23] S. I. Wiener and J. S. Taube. Head direction cells and the neural mechanisms of spatial orientation. MIT

Press  2005.

[24] L.-G. Wu and P. Saggau. Presynaptic inhibition of elicited neurotransmitter release. Trends in Neuro-

science  20:204–212  1997.

[25] X. Xie  R. H. Hahnloser  and H. S. Seung. Double-ring network model of the head-direction system.

Physical Review E  66:0419021–0419029  2002.

[26] K. Zhang. Representation of spatial orientation by the intrinsic dynamics of the head-direction cell en-

semble: a theory. Journal of Neuroscience  16(6):2112–2126  1996.

9

,Raman Arora
Andy Cotter
Nati Srebro
Dipan Pal
Ashwin Kannan
Gautam Arakalgud
Marios Savvides
Marylou Gabrié
Andre Manoel
Clément Luneau
jean barbier
Nicolas Macris
Florent Krzakala
Lenka Zdeborová
Boyi Li
Felix Wu
Kilian Weinberger
Serge Belongie