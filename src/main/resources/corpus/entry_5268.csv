2017,Stochastic and Adversarial Online Learning without Hyperparameters,Most online optimization algorithms focus on one of two things: performing well in adversarial settings by adapting to unknown data parameters (such as Lipschitz constants)  typically achieving $O(\sqrt{T})$ regret  or performing well in stochastic settings where they can leverage some structure in the losses (such as strong convexity)  typically achieving $O(\log(T))$ regret. Algorithms that focus on the former problem hitherto achieved $O(\sqrt{T})$ in the stochastic setting rather than $O(\log(T))$. Here we introduce an online optimization algorithm that achieves $O(\log^4(T))$ regret in a wide class of stochastic settings while gracefully degrading to the optimal $O(\sqrt{T})$ regret in adversarial settings (up to logarithmic factors). Our algorithm does not require any prior knowledge about the data or tuning of parameters to achieve superior performance.,Stochastic and Adversarial Online Learning without

Hyperparameters

Ashok Cutkosky

Department of Computer Science

Stanford University

ashokc@cs.stanford.edu

Kwabena Boahen

Department of Bioengineering

Stanford University

boahen@stanford.edu

Abstract

Most online optimization algorithms focus on one of two things: performing well
√
in adversarial settings by adapting to unknown data parameters (such as Lipschitz
T ) regret  or performing well in stochastic
constants)  typically achieving O(
settings where they can leverage some structure in the losses (such as strong
√
convexity)  typically achieving O(log(T )) regret. Algorithms that focus on the
former problem hitherto achieved O(
T ) in the stochastic setting rather than
O(log(T )). Here we introduce an online optimization algorithm that achieves
√
O(log4(T )) regret in a wide class of stochastic settings while gracefully degrading
to the optimal O(
T ) regret in adversarial settings (up to logarithmic factors).
Our algorithm does not require any prior knowledge about the data or tuning of
parameters to achieve superior performance.

1 Extending Adversarial Algorithms to Stochastic Settings

The online convex optimization (OCO) paradigm [1  2] can be used to model a large number of
scenarios of interest  such as streaming problems  adversarial environments  or stochastic optimization.
In brief  an OCO algorithm plays T rounds of a game in which on each round the algorithm outputs
a vector wt in some convex space W   and then receives a loss function (cid:96)t : W → R that is convex.
The algorithm’s objective is to minimize regret  which is the total loss of all rounds relative to w(cid:63) 

the minimizer of(cid:80)T

t=1 (cid:96)t in W :

T(cid:88)

RT (w(cid:63)) =

(cid:96)t(wt) − (cid:96)t(w(cid:63))

t=1

√

OCO algorithms typically either make as few as possible assumptions about the (cid:96)t while attempting
to perform well (adversarial settings)  or assume that the (cid:96)t have some particular structure that can
be leveraged to perform much better (stochastic settings). For the adversarial setting  the minimax
optimal regret is O(BLmax
T )  where B is the diameter of W and Lmax is the maximum Lipschitz
constant of the losses [3]. A wide variety of algorithms achieve this bound without prior knowledge of
one or both of B and Lmax [4  5  6  7]  resulting in hyperparameter-free algorithms. In the stochastic
setting  it was recently shown that for a class of problems (those satisfying the so-called Bernstein
condition)  one can achieve regret O(dBLmax log(T )) where W ⊂ Rd using the METAGRAD
algorithm [8  9]. This approach requires knowledge of the parameter Lmax.
In this paper  we extend an algorithm for the parameter-free adversarial setting [7] to the stochastic
setting  achieving both optimal regret in adversarial settings as well as logarithmic regret in a wide
class of stochastic settings  without needing to tune parameters. Our class of stochastic settings is
those for which E[∇(cid:96)t(wt)] is aligned with wt − w(cid:63)  quantiﬁed by a value α that increases with

31st Conference on Neural Information Processing Systems (NIPS 2017)  Long Beach  CA  USA.

increasing alignment. We call losses in this class α-acutely convex  and show that a single quadratic
lower bound on the average loss is sufﬁcient to ensure high α.
This paper is organized as follows. In Section 2  we provide an overview of our approach. In Section
3  we give explicit pseudo-code and prove our regret bounds for the adversarial setting. In Section
4  we formally deﬁne α-acute convexity and prove regret bounds for the acutely convex stochastic
setting. Finally  in Section 5  we give some motivating examples of acutely convex stochastic losses.
Section 6 concludes the paper.

2 Overview of Approach

√

Before giving the overview  we ﬁx some notation. We assume our domain W is a closed convex
subset of a Hilbert space with 0 ∈ W . We write gt to be an arbitrary subgradient of (cid:96)t at wt for all
t  which we denote by gt ∈ ∂(cid:96)t(wt). Lmax is the maximum Lipschitz constant of all the (cid:96)t  and B
w · w. We observe
is the diameter of the space W . The norm (cid:107) · (cid:107) we use is the 2-norm: (cid:107)w(cid:107) =
t=1 gt(wt − w(cid:63)). We will make heavy use of this
t=1 gt(wt − w(cid:63)). Finally 
t(cid:48)=1 gt(cid:48)  and we use ˜O to suppress logarithmic terms in

that since each (cid:96)t is convex  we have RT (w(cid:63)) ≤(cid:80)T
inequality; every regret bound we state will in fact be an upper bound on(cid:80)T
we use a compressed sum notation g1:t =(cid:80)t
(cid:19)
(cid:118)(cid:117)(cid:117)(cid:116)Lmax


big-Oh notation. All proofs omitted from the main text appear in the appendix.
Our algorithm works by trading off some performance in order to avoid knowledge of problem
parameters. Prior analysis of the METAGRAD algorithm [9] showed that any algorithm guaranteeing
RT (w(cid:63)) = ˜O
will obtain logarithmic regret for stochastic settings
satisfying the Bernstein condition. We will instead guarantee the weaker regret bound:

t=1(gt · (wt − w(cid:63)))2

(cid:18)(cid:113)(cid:80)T

(cid:107)gt(cid:107)(cid:107)wt − w(cid:63)(cid:107)2

RT (w(cid:63)) ≤ ˜O



(1)

T(cid:88)

t=1

√

which we will show in turn implies
T regret in adversarial settings and logarithmic regret for
acutely convex stochastic settings. Although (1) is weaker than the METAGRAD regret bound  we
can obtain it without prior knoweldge.
In order to come up with an algorithm that achieves the bound (1)  we interpret it as the square root
of E[(cid:107)w − w(cid:63)(cid:107)2]  where w takes on value wt with probability proportional to (cid:107)gt(cid:107). This allows us to
use the bias-variance decomposition to write (1) as:

(cid:107)w(cid:63) − w(cid:107)(cid:112)Lmax(cid:107)g(cid:107)1:T +

(cid:118)(cid:117)(cid:117)(cid:116) T(cid:88)



t=1

(2)

Lmax(cid:107)gt(cid:107)(cid:107)wt − w(cid:107)2

RT (w(cid:63)) ≤ ˜O
(cid:80)T
(cid:112)(cid:107)g(cid:107)1:T ) simultaneously for all u ∈ W [10  6  11  7]. Thus if we knew w ahead
t=1 (cid:107)gt(cid:107)wt
(cid:107)g(cid:107)1:T
(cid:112)(cid:107)g(cid:107)1:T )  the bias term of (2). We do not know w  but we can estimate it

where w =
. Certain algorithms for unconstrained OCO can achieve RT (u) =
˜O((cid:107)u(cid:107)Lmax
of time  we could translate the predictions of one such algorithm by w to abtain RT (w(cid:63)) ≤
˜O((cid:107)w(cid:63) − w(cid:107)Lmax
over time. Errors in the estimation procedure will cause us to incur the variance term of (2). We
implement this strategy by modifying FREEREX [7]  an unconstrained OCO algorithm that does not
require prior knowledge of any parameters.
Our modiﬁcation to FREEREX is very simple: we set wt = ˆwt + wt−1 where ˆwt is the tth output of
FREEREX  and wt−1 is (approximately) a weighted average of the previous vectors w1  . . .   wt−1
with the weight of wt equal to (cid:107)gt(cid:107). This wt offset can be viewed as a kind of momentum term that
accelerates us towards optimal points when the losses are stochastic (which tends to cause correlated
wt and therefore large offsets)  but has very little effect when the losses are adversarial (which tends
to cause uncorrelated wt and therefore small offsets).

2

3 FREEREXMOMENTUM

√

In this section  we explicitly describe and analyze our algorithm  FREEREXMOMENTUM  a modiﬁca-
tion of FREEREX. FREEREX is a Follow-the-Regularized-Leader (FTRL) algorithm  which means
that for all t  there is some regularizer function ψt such that wt+1 = argminW ψt(w) + g1:t · w.
φ(atw)  where φ(w) = ((cid:107)w(cid:107) + 1) log((cid:107)w(cid:107) + 1) − (cid:107)w(cid:107)
Speciﬁcally  FREEREX uses ψt =
and ηt and at are speciﬁc numbers that grow over time as speciﬁed in Algorithm 1. FREEREXMO-
MENTUM’s predictions are given by offsetting FREEREX’s predictions wt+1 by a momentum term
. We accomplish this by shifting the regularizers ψt by wt  so that FREEREXMO-
wt =
MENTUM is FTRL with regularizers ψt(w − wt).
Algorithm 1 FREEREXMOMENTUM

t(cid:48)=1
1+(cid:107)g(cid:107)1:t

(cid:80)t−1

(cid:107)gt(cid:48)(cid:107)wt

5
atηt

← 0  a0 ← 0  w1 ← 0  L0 ← 0  ψ(w) = ((cid:107)w(cid:107) + 1) log((cid:107)w(cid:107) + 1) − (cid:107)w(cid:107)

Initialize: 1
η2
0
for t = 1 to T do

Play wt
Receive subgradient gt ∈ ∂(cid:96)t(wt)
Lt ← max(Lt−1 (cid:107)gt(cid:107)). // Lt = maxt(cid:48)≤t (cid:107)gt(cid:107)

(cid:16) 1
← max
(cid:80)t−1

+ 2(cid:107)gt(cid:107)2  Lt(cid:107)g1:t(cid:107)(cid:17)
(cid:104)√

5φ(at(w−wt)

.

1
η2
t

η2
t−1

at ← max(at−1  1/(Ltηt)2)
(cid:107)gt(cid:48)(cid:107)wt
wt ←
t(cid:48)=1
1+(cid:107)g(cid:107)1:t
wt+1 ← argminW

atηt

+ g1:t · w

(cid:105)

end for

3.1 Regret Analysis

We leverage the description of FREEREXMOMENTUM in terms of shifted regularizers to prove a
regret bound of the same form as (1) in four steps:

ψt−1(w+

t (w+

t+1) + gt · (wt − w+

t+1)

t+1) − ψ+
T−1(cid:88)

t=1

1. From [7] Theorem 13  we bound the regret by

RT (w(cid:63)) ≤ T(cid:88)

gt · (wt − w(cid:63))

t=1

≤ ψT (w(cid:63)) +

T(cid:88)

t=1

+ ψ+

T (w(cid:63)) − ψT (w(cid:63)) +

ψ+
t (w+

t+2) − ψt(w+

t+2)

t (w) ≈

√

5φ(at(w−wt−1)

atηt

t+1 = argminW ψ+

is a version of ψt shifted by wt−1 instead of wt  and
t (w) + g1:tw. This breaks the regret out into two sums  one in which
t+1) for which the two different functions are shifted
t+2)  for which the functions

where ψ+
w+
we have the term ψt−1(w+
by the same amount  and one with the term ψ+
are shifted differently  but the arguments are the same.
t are shifted by the same amount  the regret analysis for FREEREX
in [7] applies to the second line of the regret bound  yielding a quantity similar to (cid:107)w(cid:63) −

t+2) − ψt(w+

t+1) − ψ+

t (w+

t (w+

2. Because ψt−1 and ψ+

wT(cid:107)(cid:112)Lmax(cid:107)g(cid:107)1:T .

3. Next  we analyze the third line. We show that wt − wt−1 cannot be too big  and use this
t=1 Lmax(cid:107)gt(cid:107)(wt − wT )2.

observation to bound the third line with a quantity similar to
At this point we have enough results to prove a bound of the form (2) (see Theorem 1).

4. Finally  we perform some algebraic manipulation on the bound from the ﬁrst three steps to

obtain a bound of the form (1) (see Corollary 2).

3

(cid:113)(cid:80)T

The details of Steps 1-3 procedure are in the appendix  resulting in Theorem 1  stated below. Step 4
is carried out in Corollary 2  which follows.
Theorem 1. Let ψ(w) = ((cid:107)w(cid:107)+1) log((cid:107)w(cid:107)+1)−(cid:107)w(cid:107). Set Lt = maxt(cid:48)≤t (cid:107)gt(cid:48)(cid:107)  and QT = 2
Deﬁne 1
ηt
FREEREXMOMENTUM is bounded by:

(cid:107)g(cid:107)1:T
.
Lmax
and at as in the pseudo-code for FREEREXMOMENTUM (Algorithm 1). Then the regret of

ψ(QT (w(cid:63)−wT ))+405Lmax+2LmaxB+3

√
Lmax

2Lmax

B log(BaT +1)

T(cid:88)

gt·(wt−w(cid:63)) ≤

(cid:118)(cid:117)(cid:117)(cid:116)2Lmax

(cid:32)

t=1

+

√

5
QT ηT

(cid:107)wT(cid:107)2 +

(cid:33)(cid:18)

T(cid:88)

t=1

(cid:107)gt(cid:107)(cid:107)wt − wT(cid:107)2

√

1 + L1

(cid:19)(cid:19)

(cid:18) 1 + (cid:107)g(cid:107)1:T

1 + (cid:107)g1(cid:107)

2 + log

log(BaT + 1)

Corollary 2. Under the assumptions and notation of Theorem 1  the regret of FREEREXMOMENTUM
is bounded by:

T(cid:88)

√
gt · (wt − w(cid:63)) ≤ 2

5

(cid:118)(cid:117)(cid:117)(cid:116)Lmax

(cid:32)

T(cid:88)

(cid:107)w(cid:63)(cid:107)2 +

(cid:107)gt(cid:107)(cid:107)w(cid:63) − wt(cid:107)2

log(2BT + 1)(2 + log(T ))

(cid:33)

t=1

t=1

+ 405Lmax + 2LmaxB + 3

√
Lmax

√

2Lmax

1 + L1

B log(2BT + 1)

Observe that since wt and w(cid:63) are both in W   (cid:107)w(cid:63)(cid:107) and (cid:107)wt − w(cid:63)(cid:107) both are at most B  so that
Corollary 2 implies that FREEREXMOMENTUM achieves ˜O(BLmax
T ) regret in the worst-case 
which is optimal up to logarithmic factors.

√

3.2 Efﬁcient Implementation for L∞ Balls

(cid:104)√

(cid:105)

A careful reader may notice that the procedure for FREEREXMOMENTUM involves computing
argminW
  which may not be easy if the solution wt+1 is on the boundary
of W . When the wt+1 is not on the boundary of W   then we have a closed-form update:

+ g1:t · w

5ψ(at(w−wt)

atηt

(cid:20)

(cid:18) ηt(cid:107)g1:t(cid:107)√

(cid:19)

(cid:21)

− 1

wt+1 = wt − g1:t

at(cid:107)g1:t(cid:107)

exp

this section we offer a simple strategy for the case that W is an L∞ ball  W =(cid:81)d

However  when wt+1 lies on the boundary of W   it is not clear how to compute it for general W . In

i=1[−b  b].

5

In this setting  we can use the standard trick (e.g. see [12]) of running a separate copy of FREEREX-
MOMENTUM for each coordinate. That is  we observe that

(3)

RT (w(cid:63)) ≤ T(cid:88)

d(cid:88)

T(cid:88)

gt · (wt − u) =

gt i(wt i − ui)

(4)

t=1

i=1

t=1

so that if we run an independent online learning algorithm on each coordinate  using the coordinates
of the gradients gt i as losses  then the total regret is at most the sum of the individual regrets. More
detailed pseudocode is given in Algorithm 2.
Coordinate-wise FREEREXMOMENTUM is easily implementable in time O(d) per update because
the FREEREXMOMENTUM update is easy to perform in one dimension: if the update (3) is outside
the domain [−b  b]  simply set wt+1 to b or −b  whichever is closer to the unconstrained update.
Therefore  coordinate-wise FREEREXMOMENTUM can be computed in O(d) time per update.
We bound the regret of coordinate-wise FREEREXMOMENTUM using Corollary 2 and Equation (4) 
resulting the following Corollary.

4

Algorithm 2 Coordinate-Wise FREEREXMOMENTUM

Initialize: w1 = 0  d copies of FREEREXMOMENTUM  F1 . . .  Fd  where each Fi uses domain
W = [−b  b].
for t = 1 to T do

Play wt  receive subgradient gt.
for i = 1 to d do
Give gt i to Fi.
Get wt+1 i ∈ [−b  b] from Fi.

end for

end for

Corollary 3. The regret of coordinate-wise FREEREXMOMENTUM is bounded by:

T(cid:88)

√
gt · (wt − w(cid:63)) ≤ 2

5

(cid:118)(cid:117)(cid:117)(cid:116)dLmax

(cid:32)

T(cid:88)

d(cid:107)w(cid:63)(cid:107)2 +

(cid:107)gt(cid:107)(cid:107)w(cid:63) − wt(cid:107)2

log(2T b + 1)(2 + log(T ))

(cid:33)

t=1

t=1

+ 405dLmax + 2Lmaxdb + 3d

√
Lmax

√

2Lmax

1 + L1

b log(2bT + 1)

4 Logarithmic Regret in Stochastic Problems

In this section we formally deﬁne α-acute convexity and show that FREEREXMOMENTUM achieves
logarithmic regret for α-acutely convex losses. As a warm-up  we ﬁrst consider the simplest case in
which the loss functions (cid:96)t are ﬁxed  (cid:96)t = (cid:96) for all t. After showing logarithmic regret for this case 
we will then generalize to more complicated stochastic settings.
Intuitively  an acutely convex loss function (cid:96) is one for which the gradient gt is aligned with the
vector wt − w(cid:63) where w(cid:63) = argmin (cid:96)  as deﬁned below.
Deﬁnition 4. A convex function (cid:96) is α-acutely convex on a set W if (cid:96) has a global minimum at some
w(cid:63) ∈ W and for all w ∈ W   for all subgradients g ∈ ∂(cid:96)(w)  we have

g · (w − w(cid:63)) ≥ α(cid:107)g(cid:107)(cid:107)w − w(cid:63)(cid:107)2

With this deﬁnition in hand  we can show logarithmic regret in the case where (cid:96)t = (cid:96) for all t for
some α-acutely convex function (cid:96). From Corollary 2  with w(cid:63) = argmin (cid:96)  we have

(cid:107)w(cid:63)(cid:107) +

gt · (w(cid:63) − wt)

(5)

Where the ˜O notation suppresses terms whose dependence on T is at most O(log2(T )). Now we
need a small Proposition:
Proposition 5. If a  b  c and d are non-negative constants such that

√
x ≤ a

bx + c + d

Then

Applying Proposition 5 to Equation (5) with x =(cid:80)T

√
x ≤ 4a2b + 2a

c + 2d

t=1 gt · (wt − w(cid:63)) yields

(cid:18) Lmax(cid:107)w(cid:63)(cid:107)

(cid:19)

RT (u) ≤ ˜O

α

5

T(cid:88)

t=1

gt · (wt − w(cid:63)) ≤ ˜O

≤ ˜O




(cid:118)(cid:117)(cid:117)(cid:116)Lmax
(cid:118)(cid:117)(cid:117)(cid:116)Lmax

(cid:32)
(cid:32)

T(cid:88)
T(cid:88)

t=1

t=1

1
α

(cid:107)w(cid:63)(cid:107)2 +

(cid:107)gt(cid:107)(cid:107)w(cid:63) − wt(cid:107)2

(cid:33)
(cid:33)

where the ˜O again suppresses logarithmic terms  now with dependence on T at most O(log4(T )).
Having shown that FREEREXMOMENTUM achieves logarithmic regret on ﬁxed α-acutely convex
losses  we now generalize to stochastic losses. In order to do this we will necessarily have to
make some assumptions about the process generating the stochastic losses. We encapsulate these
assumptions in a stochastic version of α-acute convexity  given below.
Deﬁnition 6. Suppose for all t  gt is such that E[gt|g1  . . . gt−1] ∈ ∂(cid:96)(wt) for some convex function
(cid:96) with minimum at w(cid:63). Then we say gt is α-acutely convex in expectation if:

E[gt] · (wt − w(cid:63)) ≥ α E[(cid:107)gt(cid:107)(cid:107)wt − w(cid:63)(cid:107)2]

where all expectations are conditioned on g1  . . .   gt−1.
Using this deﬁnition  a fairly straightforward calculation gives us the following result.
Theorem 7. Suppose gt is α-acutely convex in expectation and gt is bounded (cid:107)gt(cid:107) ≤ Lmax with
probability 1. Then FREEREXMOMENTUM achieves expected regret:

(cid:18) Lmax(cid:107)w(cid:63)(cid:107)

(cid:19)

α

E[RT (w(cid:63))] ≤ ˜O

Proof. Throughout this proof  all expectations are conditioned on prior subgradients. By Corollary 2
and Jensen’s inequality we have
≤ E

405Lmax + 2LmaxB + 3

gt · (wt − w(cid:63))

B log(2BT + 1)

√
Lmax

2Lmax

√

E

(cid:34) T(cid:88)

t=1

(cid:107)w(cid:63)(cid:107)2 +

log(2T B + 1)(2 + log(T ))

≤ 405Lmax + 2LmaxB + 3

B log(2BT + 1)



T(cid:88)

t=1

T(cid:88)

t=1

1 + L1

(cid:33)

(cid:107)gt(cid:107)(cid:107)w(cid:63) − wt(cid:107)2
√
√
2Lmax
δ

Lmax

(cid:33)

(cid:33)

√
√
2Lmax
δ

(cid:107)w(cid:63)(cid:107)2 +

E[(cid:107)gt(cid:107)(cid:107)w(cid:63) − wt(cid:107)2]

log(2T B + 1)(2 + log(T ))

≤ 405Lmax + 2LmaxB + 3

Lmax

B log(2BT + 1)

(cid:107)w(cid:63)(cid:107)2 +

1
α

E[gt · (wt − w(cid:63))]

log(2T B + 1)(2 + log(T ))

. Then we have shown

(cid:107)w(cid:63)(cid:107)2 +

R
α

log(2T B + 1)(2 + log(T ))

Lmax

√
√
2Lmax
δ

+ 405Lmax + 2LmaxB + 3

B log(BT + 1)

T(cid:88)

t=1

(cid:19)

(cid:19)(cid:35)

5

√

(cid:32)

√
+2

(cid:35)
(cid:20)
(cid:118)(cid:117)(cid:117)(cid:116)Lmax
(cid:32)
(cid:118)(cid:117)(cid:117)(cid:116)Lmax
(cid:118)(cid:117)(cid:117)(cid:116)Lmax
(cid:32)
(cid:105)
(cid:115)
t=1 gt(wt − w(cid:63))
R ≤ 2

+ 2

+ 2

√

√

5

5

5

Lmax

(cid:18)

(cid:18)

(cid:34)(cid:115)

T(cid:88)

t=1

Set R = E(cid:104)(cid:80)T

= ˜O

Lmax

(cid:107)w(cid:63)(cid:107)2 +

R
α

And now we use Proposition 5 to conclude:

E[gt · (wt − w(cid:63))] = ˜O

(cid:18) Lmax(cid:107)w(cid:63)(cid:107)

(cid:19)

α

as desired  where again ˜O hides at most a O(log4(T )) dependence on T .

Exactly the same argument with an extra factor of d applies to the regret of FREEREXMOMENTUM
with coordinate-wise updates.

6

5 Examples of α-acute convexity in expectation

In this section  we show that α-acute convexity in expectation is a condition that arises in practice 
justifying the relevance of our logarithmic regret bounds. To do this  we show that a quadratic lower
bound on the expected loss implies α-acute convexity  demonstrating acutely convexity is a weaker
condition than strong convexity.
Proposition 8. Suppose E[gt|g1  . . .   gt−1] ∈ ∂(cid:96)(wt) for some convex (cid:96) such that for some µ > 0
and w(cid:63) = argmin (cid:96)  (cid:96)(w) − (cid:96)(w(cid:63)) ≥ µ
2(cid:107)w − w(cid:63)(cid:107)2 for all w ∈ W . Suppose (cid:107)g(cid:107) ≤ Lmax with
probability 1. Then gt is

-acutely convex in expectation.

µ

2Lmax

Proof. By convexity and the hypothesis of the proposition: E[gt] · (wt − w(cid:63)) ≥ (cid:96)(wt) − (cid:96)(w(cid:63)) ≥
2(cid:107)wt − w(cid:63)(cid:107)2 ≥ µ

E[(cid:107)gt(cid:107)(cid:107)wt − w(cid:63)(cid:107)2

µ

2Lmax

With Proposition 8  we see that FREEREXMOMENTUM obtains logarithmic regret for any loss that is
larger than a quadratic  without requiring knowledge of the parameter µ or the Lipschitz bound Lmax.
Further  this result requires only the expected loss (cid:96) = E[(cid:96)t] to have a quadratic lower bound - the
individual losses (cid:96)t themselves need not do so.
The boundedness of W makes it surprisingly easy to have a quadratic lower bound. Although a
quadratic lower bound for a function (cid:96) is easily implied by strong convexity  the quadratic lower
bound is a signiﬁcantly weaker condition. For example  since W has diameter B  (cid:107)w(cid:107) ≥ 1
B(cid:107)w(cid:107)2
and so the absolute value is 1
B -acutely convex  but not strongly convex. The following Proposition
shows that existence of a quadratic lower bound is actually a local condition; so long as the expected
loss (cid:96) has a quadratic lower bound in a neighborhood of w(cid:63)  it must do so over the entire space W :
Proposition 9. Supppose (cid:96) : W → R is a convex function such that (cid:96)(w) − (cid:96)(w(cid:63)) ≥ µ
2(cid:107)w − w(cid:63)(cid:107)

for all w with (cid:107)w − w(cid:63)(cid:107) ≤ r. Then (cid:96)(w) − (cid:96)(w(cid:63)) ≥ min(cid:0) µr

2B   µ

2

(cid:1)(cid:107)w − w(cid:63)(cid:107)2 for all w ∈ W .
(cid:105) ≥ µr
(cid:16) rw(cid:107)w(cid:107)
(cid:104)

(cid:17) − (cid:96)(w(cid:63))

(cid:96)

Proof. We translate by w(cid:63) to assume without loss of generality that w(cid:63) = 0. Then the statement
is clear for (cid:107)w(cid:107) ≤ r. By convexity  (cid:96)(w) − (cid:96)(w(cid:63)) ≥ (cid:107)w(cid:107)
2 (cid:107)w(cid:107) ≥
2B(cid:107)w(cid:107)2.

µr

r

Finally  we provide a simple motivating example of an interesting problem we can solve with an
α-acutely convex loss that is not strongly convex: computing the median.
Proposition 10. Let W = [a  b]  and (cid:96)t(w) = |w − xt| where each xt is drawn i.i.d. from some ﬁxed
distribution with a continuous cumulative distribution function D  and assume D(x(cid:63)) = 1
2 . Further 
suppose |2D(w) − 1| ≥ F|w − x(cid:63)| for all |w − x(cid:63)| ≤ G. Suppose gt = (cid:96)(cid:48)
t(wt) for wt (cid:54)= xt and
gt = ±1 with equal probability if wt = xt. Then gt is min
-acutely convex in expectation.

(cid:16) F G

(cid:17)

b−a   F

Proof. By a little calculation  E[gt] = (cid:96)(cid:48)(wt) = 2D(wt) − 1  and E[|gt|] = 1. Since (cid:96)(cid:48)(x(cid:63)) = 0 
w(cid:63) = x(cid:63) (the median). For |wt − x(cid:63)| ≥ G  we have |2D(w) − 1| ≥ F G  which gives E[gt] · (wt −
w(cid:63)) ≥ F G
E[|gt|](wt− w(cid:63))2. For |wt− x(cid:63)| ≤ G  we have E[gt]· (wt− w(cid:63)) ≥ F E[|gt|](wt− w(cid:63))2 
b−a
so that gt is min

-acutely convex in expectation.

(cid:16) F G

(cid:17)

b−a   F

Proposition 10 shows that we can obtain low regret for an interesting stochastic problem without
curvature. The condition on the cumulative distribution function D is asking only that there be
positive density in a neighborhood of the median; it would be satisﬁed if D(cid:48)(w) ≥ F for |w| ≤ G.
If the expected loss (cid:96) is µ-strongly convex  we can apply Proposition 8 to see that (cid:96) is µ/2-aligned 
and then use Theorem 7 to obtain a regret of ˜O(Lmax(cid:107)w(cid:63)(cid:107)/µ). This is different from the usual regret
bound of ˜O(L2
max/µ) obtained by Online Newton Step [13]  which is due to an inefﬁciency in using
the wearker α-alignment condition. Instead  arguing from the regret bound of Corollary 2 directly 
we can recover the optimal regret bound:

7

Corollary 11. Suppose each (cid:96)t is an independent random variable with E[(cid:96)t] = (cid:96) for some µ-strongly
convex (cid:96) with minimum at w(cid:63). Then the expected regret of FREEREXMOMENTUM satisﬁes

(cid:34) T(cid:88)

E

(cid:35)

(cid:96)(wt) − (cid:96)(w∗)

≤ ˜O(L2

max/µ)

Where the ˜O hides terms that are logarithmic in T B.

t=1

Proof. From strong-convexity  we have

(cid:107)wt − w(cid:63)(cid:107)2 ≤ 2
µ

((cid:96)(wt) − (cid:96)(w(cid:63)))

Therefore applying Corollary 2 we have

E[RT (w(cid:63))] = E

(cid:96)(wt) − (cid:96)(w∗)

(cid:34) T(cid:88)

t=1

(cid:35)

(cid:118)(cid:117)(cid:117)(cid:116)L2

≤ ˜O((cid:112)L2

≤ ˜O



(cid:107)wt − w(cid:63)(cid:107)2]

T(cid:88)

t=1

max E[

max E[RT (w(cid:63))])

So that applying Proposition 5 we obtain the desired result.

As a result of Corollary 11  we see that FREEREXMOMENTUM obtains logarithmic regret for α-
aligned problems and also obtains the optimal (up to log factors) regret bound for µ-strongly-convex
problems  all without requiring any knowledge of the parameters α or µ. This stands in contrast to
prior algorithms that adapt to user-supplied curvature information such as Adaptive Gradient Descent
[14] or (A B)-prod [15].

6 Conclusions and Open Problems

α

adversarial settings and ˜O(cid:0) LmaxB

(cid:1) regret in α-acutely convex stochastic settings without requiring

T ) regret in

√

We have presented an algorithm  FREEREXMOMENTUM  that achieves both ˜O(BLmax

any prior information about any parameters. We further showed that a quadratic lower bound on
the expected loss implies acute convexity  so that while strong-convexity is sufﬁcient for acute
convexity  other important loss families such as the absolute loss may also be acutely convex. Since
FREEREXMOMENTUM does not require prior information about any problem parameters  it does not
require any hyperparameter tuning to be assured of good convergence. Therefore  the user need not
actually know whether a particular problem is adversarial or acutely convex and stochastic  or really
much of anything at all about the problem  in order to use FREEREXMOMENTUM.
There are still many interesting open questions in this area. First  we would like to ﬁnd an efﬁcient
way to implement the FREEREXMOMENTUM algorithm or some variant directly  without appealing
to coordinate-wise updates. This would enable us to remove the factor of d we incur by using
coordinate-wise updates. Second  our modiﬁcation to FREEREX is extremely simple and intuitive 
but our analysis makes use of some of the internal logic of FREEREX. It is possible  however  that
any algorithm with sufﬁciently low regret can be modiﬁed in a similar way to achieve our results.
Finally  we observe that while log4(T ) is much better than
T asymptotically  it turns out that
log4(T ) >
T for T < 1011  which casts the practical relevance of our logarithmic bounds in doubt.
Therefore we hope that this work serves as a starting point for either new analysis or algorithm design
that further simpliﬁes and improves regret bounds.

√

√

References
[1] Martin Zinkevich. Online convex programming and generalized inﬁnitesimal gradient ascent. In Proceed-

ings of the 20th International Conference on Machine Learning (ICML-03)  pages 928–936  2003.

[2] Shai Shalev-Shwartz. Online learning and online convex optimization. Foundations and Trends in Machine

Learning  4(2):107–194  2011.

8

[3] Jacob Abernethy  Peter L Bartlett  Alexander Rakhlin  and Ambuj Tewari. Optimal strategies and min-
imax lower bounds for online convex games. In Proceedings of the nineteenth annual conference on
computational learning theory  2008.

[4] J. Duchi  E. Hazan  and Y. Singer. Adaptive subgradient methods for online learning and stochastic

optimization. In Conference on Learning Theory (COLT)  2010.

[5] H. Brendan McMahan and Matthew Streeter. Adaptive bound optimization for online convex optimization.

In Proceedings of the 23rd Annual Conference on Learning Theory (COLT)  2010.

[6] Francesco Orabona and Dávid Pál. Coin betting and parameter-free online learning.

In D. D. Lee 
M. Sugiyama  U. V. Luxburg  I. Guyon  and R. Garnett  editors  Advances in Neural Information Processing
Systems 29  pages 577–585. Curran Associates  Inc.  2016.

[7] Ashok Cutkosky and Kwabena Boahen. Online learning without prior information. arXiv preprint

arXiv:1703.02629  2017.

[8] Tim van Erven and Wouter M Koolen. Metagrad: Multiple learning rates in online learning. In D. D.
Lee  M. Sugiyama  U. V. Luxburg  I. Guyon  and R. Garnett  editors  Advances in Neural Information
Processing Systems 29  pages 3666–3674. Curran Associates  Inc.  2016.

[9] Wouter M Koolen  Peter Grünwald  and Tim van Erven. Combining adversarial guarantees and stochastic
fast rates in online learning. In Advances in Neural Information Processing Systems  pages 4457–4465 
2016.

[10] Francesco Orabona. Dimension-free exponentiated gradient. In Advances in Neural Information Processing

Systems  pages 1806–1814  2013.

[11] Ashok Cutkosky and Kwabena A Boahen. Online convex optimization with unconstrained domains and
losses. In D. D. Lee  M. Sugiyama  U. V. Luxburg  I. Guyon  and R. Garnett  editors  Advances in Neural
Information Processing Systems 29  pages 748–756. Curran Associates  Inc.  2016.

[12] Brendan Mcmahan and Matthew Streeter. No-regret algorithms for unconstrained online convex optimiza-

tion. In Advances in neural information processing systems  pages 2402–2410  2012.

[13] Elad Hazan  Amit Agarwal  and Satyen Kale. Logarithmic regret algorithms for online convex optimization.

Machine Learning  69(2):169–192  2007.

[14] Peter L Bartlett  Elad Hazan  and Alexander Rakhlin. Adaptive online gradient descent. In NIPS  volume 20 

pages 65–72  2007.

[15] Amir Sani  Gergely Neu  and Alessandro Lazaric. Exploiting easy data in online optimization. In Advances

in Neural Information Processing Systems  pages 810–818  2014.

9

,Ashok Cutkosky
Kwabena Boahen
Alberto Maria Metelli
Matteo Papini
Francesco Faccio
Marcello Restelli
Tao Tu
John Paisley
Stefan Haufe
Paul Sajda