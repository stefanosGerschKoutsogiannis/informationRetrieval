2017,Experimental Design for Learning Causal Graphs with Latent Variables,We consider the problem of learning causal structures with latent variables using interventions. Our objective is not only to learn the causal graph between the observed variables  but to locate unobserved variables that could confound the relationship between observables. Our approach is stage-wise: We first learn the observable graph  i.e.  the induced graph between observable variables. Next we learn the existence and location of the latent variables given the observable graph. We propose an efficient randomized algorithm that can learn the observable graph using O(d\log^2 n) interventions where d is the degree of the graph. We further propose an efficient deterministic variant which uses O(log n + l) interventions  where l is the longest directed path in the graph. Next  we propose an algorithm that uses only O(d^2 log n) interventions that can learn the latents between both non-adjacent and adjacent variables. While a naive baseline approach would require O(n^2) interventions  our combined algorithm can learn the causal graph with latents using O(d log^2 n + d^2 log (n)) interventions.,Experimental Design for Learning Causal Graphs

with Latent Variables

Murat Kocaoglu⇤

Department of Electrical and Computer Engineering

The University of Texas at Austin  USA

mkocaoglu@utexas.edu

Karthikeyan Shanmugam⇤
IBM Research NY  USA

karthikeyan.shanmugam2@ibm.com

Elias Bareinboim

Department of Computer Science and Statistics

Purdue University  USA

eb@purdue.edu

Abstract

We consider the problem of learning causal structures with latent variables using
interventions. Our objective is not only to learn the causal graph between the
observed variables  but to locate unobserved variables that could confound the
relationship between observables. Our approach is stage-wise: We ﬁrst learn the
observable graph  i.e.  the induced graph between observable variables. Next we
learn the existence and location of the latent variables given the observable graph.
We propose an efﬁcient randomized algorithm that can learn the observable graph
using O(d log2 n) interventions where d is the degree of the graph. We further
propose an efﬁcient deterministic variant which uses O(log n + l) interventions 
where l is the longest directed path in the graph. Next  we propose an algorithm that
uses only O(d2 log n) interventions that can learn the latents between both non-
adjacent and adjacent variables. While a naive baseline approach would require
O(n2) interventions  our combined algorithm can learn the causal graph with
latents using O(d log2 n + d2 log (n)) interventions.

1

Introduction

Causality shapes how we view  understand  and react to the world around us. It is arguably a key
ingredient in building intelligent systems that are autonomous and can act efﬁciently in complex
environments. Not surprisingly  the task of automating the learning of cause-and-effect relationships
have attracted great interest in the artiﬁcial intelligence and machine learning communities. This effort
has led to a general theoretical and algorithmic understanding of the assumptions under which cause-
and-effect relationships can be inferred from data. These results have started to percolate through the
applied ﬁelds ranging from genetics to medicine  from psychology to economics [5  26  33  25].
The endeavour of algorithmically learning causal relations may have started from the independent
discovery of the IC [35] and PC algorithms [33]  which almost identically  and contrary to previously
held beliefs  showed the feasibility of recovering these relations from purely observational  non-
experimental data. A plethora of methods followed this breakthrough  and now we understand  at
least in principle  the limits of what can be inferred from purely observational data  including (not
exhaustively) [31  14  21  27  19  13]. There are a number of assumptions that have been considered
about the data-generating model when attempting to unveil the causal structure. One of the most

⇤Equal contribution.

31st Conference on Neural Information Processing Systems (NIPS 2017)  Long Beach  CA  USA.

popular assumptions is that the data-generating model is causally sufﬁcient  which means that no
latent (unmeasured) variable affects more than one observed variable. In practice  this is a very
stringent condition since the existence of latents affecting more than one observed variable  and
generating what is called confounding bias  is one of the main concerns of empirical scientists.
The problem of causation is deemed challenging in most of the empirical ﬁelds because scientists
recognize that not all the variables inﬂuencing the observed phenomenon can be measured. The
general question that arises is then how much of the observed behavior of the system is truly causal 
or whether it is due to some external  unobserved forces [26  5].
To account for the latent variables in the context of structural learning  the IC* [35] and FCI [33]
algorithms were introduced  which showed the possibility of recovering causal structures even when
latent variables may be confounding the observed behavior 2. One of the main challenges faced
by these algorithms is that although some ancestral relations as well as certain causal edges can be
learned [36  7]  many observationally equivalent architectures cannot be distinguished. Despite the
practical challenges when collecting the data (e.g.  ﬁnite samples  selection bias  missing data)  we
now have a complete characterization of what structures are recoverable from observational data
based on conditional independence constraints [33  2  37]. Inferences will be constrained within
an equivalence class. Initial works leveraged ideas of experimental design and the availability of
interventional data to move from the equivalence class to a speciﬁc graph  but almost exclusively
considering causally sufﬁcient systems [9  15  11  12  30  18].
For causally insufﬁcient systems  there is a growing interest in identifying experimental quantities
and structures based on partially observed interventional data [4  32  29  28  24  16  8  34  22]  but
without the goal of designing the optimal set of interventions. Perhaps the most relevant paper to
our setup is [23]. Authors identify the experiments needed to learn the causal graph under latents 
given the output of FCI algorithm. However  they are not interested in minimizing the number of
experiments.
In this paper  we propose the ﬁrst efﬁcient non-parametric algorithm for learning a causal graph with
latent variables. It is known that log(n) interventions are necessary (across all graphs) and sufﬁcient
to learn a causal graph without latent variables [12]  and we show  perhaps surprisingly  that there
exists an algorithm that can learn any causal graph with latent variables which requires poly(log n)
interventions when the observable graph is sparse. More speciﬁcally  our contributions are as follow:
• We introduce a deterministic 3 algorithm that can learn any causal graph and the existence and
location of the latent variables using O(d log(n) + l) interventions  where d is the largest node
degree and l is the longest directed path of the causal graph.
• We design a randomized algorithm that can learn the observable graph and all the latent variables
using O(d log2(n) + d2 log(n)) interventions with high probability  where d is the largest node
degree.

The ﬁrst algorithm is useful in practical settings where the longest directed path is not very deep  e.g. 
O(log(n)). This includes bipartite  time-series  and relational type of domains where the underlying
causal topology is somewhat sparse. As an example application  consider the problem of inferring
the causal effect of a set of genes on a set of phenotypes  that could be cast as learning a bipartite
causal system. For the more general setting  we introduce a randomized algorithm that with high
probability is capable of unveiling the true causal structure.
Background
We assume for simplicity that all the random variables are discrete. We use the language of Structural
Causal Models (SCM) [26  pp. 204-207]. Formally  an SCM M is a 4-tuple hU V F  P (u)i  where
U is a set of exogenous (unobserved  latent) variables  V is a set of endogenous (measured) variables.
We partition the set of exogenous variables into two disjoint sets: Exogenous variables with one
observable child  denoted by E  exogenous variables with two observable children  denoted by L.
F = {fi} is a collection of functions such that each endogenous variable Vi 2V is determined by
a function fi 2 F : Each fi is a mapping from the respective domain of the exogenous variables
associated with Vi and a set of observable variables associated with Vi  called P Ai  into Vi. The

2Hereafter  latent variable refers to any unmeasured variable that affects more than one observed variable.
3We assume access to an oracle that outputs a size-O(d2 log (n)) independent set cover for the non-edges of
a given graph. This oracle can be implemented using another randomized algorithm as we explain in Section 5.

2

set of exogenous variables associated with Vi can be divided into two classes  the one with a single
observable child  denoted by Ei 2E   and those with two observable children  denoted by Li ✓L .
Hence fi maps from the domain of Ei [ P Ai [L i to Vi. The entire set F forms a mapping from U to
V. The uncertainty is encoded through a product probability distribution over the exogenous variables
P (E L). For simplicity we refer to L as the set of latents  and E as the set of exogenous variables.
Within the structural semantics  performing an action S = s is represented through the do-operator 
do(S = s)  which encodes the operation of replacing the original equation of S by the constant s
and induces a submodel MS (also for when S is not a singleton). We denote the post-interventional
distribution by PS(·). For a detailed discussion on the properties of structural models  we refer
readers to [5  23  24  Ch. 7]. Deﬁne D` = (V[L   E`) to be the causal graph with latents. We deﬁne
the observable graph to be the induced subgraph on V which is D = (V  E).
In practice  we use an independent random variable Wi taking values uniformly at random in the state
space of Vi  to implement an intervention do(Vi). A conditional independence statement  e.g.  X is
independent from Y given Z ⇢V with respect to causal model MS  in shown by (X ?? Y |Z)MS 
or (X ?? Y |Z)S when the causal model is clear from the context. These conditional independencies
are with respect to the post-interventional joint probability distribution PS(·). In this paper  we
assume that an oracle to conditional independence (CI) tests is available.
The mutilated or post-interventional causal graph  denoted D`[S] = (V[L   E`[S])  is identical to
D` except that all the incoming edges incident on any vertex in the interventional set S is absent  i.e. 
E`[S] = E` { (Y  V ) : V 2 S  (Y  V ) 2 E`}. We deﬁne the transitive closure  denoted Dtc  of an
observable causal DAG D as follows: If there is a directed path from Vi to Vj in D  there is a directed
edge from Vi to Vj in Dtc. Essentially  a directed edge in Dtc represents an ancestral relation in D.
For any DAG D = (V  E)  a set of nodes S ⇢ V d-separates two nodes a and b if and only if S
blocks all paths between a and b. ‘Blocking’ is a graphical criterion associated with d-separation 4. A
probability distribution is said to be faithful (or stable) to a graph  if and only if every conditional
independence statement can be read off from the graph using d-separation  see [26  Ch. 2] for a
review. We assume that faithfulness holds in the observational and post-interventional distributions
following [12].
Results and outline of the paper
The skeleton of the proposed learning algorithms can be split into 3 steps  namely:

(a)

;

! Transitive Closure (b)

! Observable graph (c)

! Observable graph with Latent variables

Each step requires different tools and graph theoretic concepts:
(a) We use a pairwise independence test under interventions that reveals the ancestral relations. This
is combined in an efﬁcient manner with separating systems to discover the transitive closure of D
in O(log n) interventions.
(b) We rely on the transitive reduction of directed acyclic graphs that can be efﬁciently computed only
from their transitive closure. A key property we observe is that the transitive reduction reveals a
subset of the true edges. For our randomized algorithm  we use a sequence of transitive reductions
computed from transitive closures (obtained using step (a)) of different post-interventional graphs.
(c) Given the observable graph  it is possible to discover latents between non-adjacent nodes using
CI tests under suitable interventions. We use an edge-clique cover on the complement graph to
optimize the number of experiments. For latents between adjacent nodes  we use a relatively
unknown test called the do-see test  i.e.  leveraging the equivalence between observing and
intervening on the node. We implement it using induced matching cover of the observable graph.
The modularity of our approach allows us to solve subproblems: given the ancestral graph  we can
use (b) to discover the observable graph D. If D is known  we can learn the latents with (c). Some
pictorial illustrations of the main results in the technical sections are found in the full version [20].

Identifying the Observable Graph: A simple baseline

2
We discuss a natural and a simple deterministic baseline algorithm that ﬁnds the observable graph
with experiments when confounders are present. To our knowledge  a provably complete algorithm
4For convenience  detailed deﬁnitions of blocking and non-blocking paths are provided in the full version

[20].

3

that recovers the observable graph under this setting and is superior than this simple baseline in the
worst case is not known. We start from the following observation. Suppose X ! Y where X  Y
are observable variables and let L be a latent variable such that L ! X  L ! Y . Consider the
post interventional graph D`[{X}] where we intervene on X. It is easy to see that  X and Y are
dependent in the post interventional graph too because of the direct causal relationship. However  if
X is not a parent of Y   then in the post interventional graph D`[{X}] even with or without the latent
L between X and Y   X is independent of Y since X is intervened on.
It is possible to recreate this condition between any target variable Y and any one of its direct parents
X when many other observable variables are involved. Simply  we consider the post-interventional
graph where we intervene on all observable variables but Y . In D`[V { Y }]  Y and X are dependent
if and only if X ! Y is a directed edge in the observable graph D  because every variable except X
becomes independent of all other variables in the post interventional graph. Therefore  one needs n
interventions  each of size n 1 to ﬁnd out the parent set of every node. We basically show in the next
two sections that when the graph D has constant degree  it is enough to do O(log2(n)) interventions
representing the ﬁrst provably exponential improvement.

3 Learning Ancestral Relations

In this section  we show that separating systems can be used to construct sequences of pairwise CI
tests to discover the transitive closure of the observable causal graph  i.e.  the graph that captures all
ancestral relations. The following lemma relates post-interventional statistical dependencies with the
ancestral relations in the graph with latents.
Lemma 1. [Pairwise Conditional Independence Test] Consider a causal graph with latents D`. Con-
sider an intervention on the set S ⇢V of observable variables. Then  under the post-interventional
faithfulness assumption  for any pair Xi 2 S  Xj 2V\ S  (Xi 6?? Xj)D`[S] if and only if Xi is an
ancestor of Xj in the post-interventional observable graph D[S].

Lemma 1 constitutes  for any ordered pair of variables (Xi  Xj) in the observable graph D  a test for
whether Xi is an ancestor of Xj or not. Note that a single test is not sufﬁcient to discover the ancestral
relation between a pair (Xi  Xj)  e.g.  if Xi ! Xk ! Xj and Xi  Xk 2 S  Xj /2 S  the ancestral
relation will not be discovered. This issue can be resolved by using a sequence of interventions
guided by a separating system  and later ﬁnding the transitive closure of the learned graph.
Separating systems were ﬁrst deﬁned by [17]  and has been subsequently used in the context of
experimental design [10]. A separating system on a ground set S is a collection of subsets of S 
S = {S1  S2 . . .} such that for every pair (i  j)  there is a set that contains only one  i.e.  9k such
that i 2 Sk  j /2 Sk or j 2 Sk  i /2 Sk. We require a stronger notion which is captured by a strongly
separating system.
Deﬁnition 1. An (m  n) strongly separating system is a family of subsets {S1  S2 . . . Sm} of the
ground set [n] such that for any two pairs of nodes i and j  there is a set S in the family such that
i 2 S  j /2 S and also another set S0 such that i /2 S0  j 2 S0.
Similar to separating systems  one can construct strongly separating systems using O(log(n)) subsets:
Lemma 2. An (m  n) strong separating system exists on a ground set [n] where m  2dlog ne.
We propose Algorithm 1 to discover the ancestral relations between the observable variables. It uses
the subsets of a strongly separating system on the ground set of all observable variables as intervention
sets  to assure that the ancestral relation between every ordered pair of observable variables is tested.
The following theorem shows the number of experiments and the soundness of Algorithm 1.
Theorem 1. Algorithm 1 requires only 2dlog ne interventions and conditional independence tests on
samples obtained from each post-interventional distribution and outputs the transitive closure Dtc.

4 Learning the Observable Graph
We introduce a deterministic and a randomized algorithm for learning the observable causal graph D
from ancestral relations. D encodes every direct causal connection between the observable nodes.

4

E = ;.
Consider a strongly sep. system of size  2 log n on the ground set V - {S1  S2..S2dlog ne}.
for i in [1 : 2dlog ne] do

Algorithm 1 LearnAncestralRelations- Given access to a conditional independence testing oracle
(CI oracle)  query access to samples from any post-interventional causal model derived out of M
(with causal graph D`)  outputs all ancestral relationships between observable variables  i.e.  Dtc
1: function LEARNANCESTRALRELATIONS(M)
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14: end function

Use samples from MSi and use the CI-oracle to test the following.
if (X 6?? Y )D`[S] then
E E [ (X  Y ).
end if

end for
return The transitive closure of the graph (V  E)

Intervene on the set Si of nodes.
for X 2 Si  Y /2 Si  Y 2V do

end for

4.1 A Deterministic Algorithm
Based on Section 3  assume that we are given the transitive closure of the observable graph. We show
in Lemma 3 that  when the intervention set contains all parents of Xi  the only variables dependent
with Xi in the post-interventional observable graph are the parents of Xi in the observable graph.
Lemma 3. For variable Xi  consider an intervention on S where P ai ⇢ S. Then {Xj 2 S : (Xi 6??
Xj)D[S]} = P ai.
Let the longest directed path of Dtc be r. Consider the partial order <Dtc implied by Dtc on
the vertex set V. Deﬁne {Ti : i 2 [r + 1]} as the unique partitioning of vertices of Dtc where
Ti <Dtc Tj 8i < j and each node in Ti is a set of mutually incomparable elements. In other words 
Ti are the set of nodes at layer i of the transitive closure graph Dtc. Deﬁne Ti = [i1
k=1Tk. We have
the following observation: P ai ⇢T i. This paves the way for Algorithm 2 that leverages Lemma 3.
Algorithm 2 LearnObservableGraph/Deterministic - Given the ancestral graph  access to a conditional
independence testing oracle (CI oracle) and outputs the graph induced on observable nodes.
1: function LEARNOBSERVABLEGRAPH/DETERIMINISTIC(M)
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13: end function

E = ;.
for i in {r + 1  r  r  1  . . .   2} do
Intervene on the set Ti of nodes.
Use samples from MTi and use the CI-oracle to test the following.
for X in Ti do

if (X 6?? Y )D`[Ti] then
E E [ (X  Y ).
end if

end for
return Observable graph

end for

The correctness of Algorithm 2 follows from Lemma 3  which is stated explicitly in the sequel.
Theorem 2. Let r be the length of the longest directed path in the causal graph D`. Algorithm 2
requires only r interventions and conditional independence tests on samples obtained from each one
of the post-interventional distributions and outputs the observable graph D.

4.2 A Randomized Algorithm
We propose a randomized algorithm that repeatedly uses the ancestor graph learning algorithm from
Section 3 to learn the observable graph 5. A key structure that we use is the transitive reduction:

5Note that this algorithm does not require learning the ancestral graph ﬁrst.

5

V1

V2

V3

V4

V1

V2

V3

V4

Observable	Graph	D

(a)

Transitive	reduction	of	D
(b)

V1

V2

V3

V4

Post-interventional	graph	D[{V2}]

After	intervention	on	V2

(c)

V1

V2

V3

V4

Transitive	reduction	of	D[{V2}]

(d)

Illustration of Lemma 5 - (a) An example of an observable graph D without latents
Figure 1:
(b): Transitive reduction of D. The highlighted red edge (V1  V3) has not been revealed under the
operation of transitive reduction. c) Intervention on node V2 and its post interventional graph D[{V2}]
d) Since all parents of V3 above V1 in the partial order have been intervened on  by Lemma 5  the
edge (V1  V3) is revealed in the transitive reduction of D[{V2}].

Deﬁnition 2 (Transitive Reduction). Given a directed acyclic graph D = (V  E)  let its transitive
closure be Dtc. Then Tr(D) = (V  Er) is a directed acyclic graph with minimum number of edges
such that its transitive closure is identical to Dtc.
Lemma 4. [1] Tr(D) is known to be unique if D is acyclic. Further  the set of directed edges of
Tr(D) is a subset of the directed edges of D  i.e.  Er ⇢ E. Computing Tr(D) from D takes the same
time as transitive closure of a DAG D  which takes time poly(n).

We note that Tr(D) = Tr(Dtc). Now  we provide an algorithm that outputs an observable graph
based on samples from the post-interventional distribution after a sequence of interventions. Let us
assume an ordering ⇡ on the observable vertices V that satisﬁes the partial order relationships in the
observable causal graph D. The key insight behind the algorithm is given by the following Lemma.
Lemma 5. Consider an intervention on a set S ⇢V of nodes in the observable causal graph D.
Consider the post-interventional observable causal graph D[S]. Suppose for a speciﬁc observable
node Vi  Vi 2 Sc. Let Y be a direct parent of Vi in D such that all the direct parents of Vi above Y
in the partial order6 ⇡(·) is in S  i.e.  {X : ⇡(X) >⇡ (Y )  (X  V ) 2 D}✓ S. Then  Tr(D[S]) will
contain the directed edge (Y  Vi) and it can be computed from Tr((D[S])tc)

We illustrated Lemma 5 through an example in Figure 1. The red edge in Figure 1(a) is not revealed
in the transitive reduction. The edge is revealed when computing the transitive reduction of the
post-interventional graph D[{V2}]. This is possible because all parents of V3 above V1 in the partial
order (in this case node V2) have been intervened on.
Lemma 5 motivates Algorithm 3. The basic idea is to intervene in randomly  then compute the
transitive closure of the post-interventional graph using the algorithm in the previous section  compute
the transitive reduction  and then accumulate all the edges found in the transitive reduction at every
stage. We will show in Theorem 3 that with high probability  the observable graph can be recovered.
Theorem 3. Let dmax be greater than the maximum in-degree in the observable graph D. Al-
gorithm 3 requires at most 8cdmax(log n)2 interventions and CI tests on samples obtained from
post-interventional distributions  and outputs the observable graph with probability at least 1 1
nc2 .
Remark. The above algorithm takes as input a parameter dmax that needs to be estimated. One
practical option is to gradually increase dmax and run Algorithm 3.

6The nodes above with respect to the partial order of a graph are those that are closer to the source nodes.

6

Algorithm 3 LearnObservable- Given access to a conditional independence testing oracle (CI oracle) 
a parameter dmax outputs induced subgraph between observable variables  i.e. D
1: function LEARNOBSERVABLE/RANDOMIZED(M  dmax)
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13: end function

S = ;.
for V 2V do
S S [ V randomly with probability 1  1/dmax.
end for
ˆDS = LearnAncestralRelations(M). Let ˆD = (V  ˆE).
Compute the transitive reduction of ˆD(Tr( ˆDS)) according to the algorithm in [1].
Add the edges of the transitive reduction to the set E if not already there  i.e. E E [ ˆE.

E = ;.
for i in [1 : c ⇤ 4 ⇤ dmax log n] do

end for
return The directed graph (V  E).

5 Learning Latents from the Observable Graph
The ﬁnal stage of our framework is learning the existence and location of latent variables given the
observable graph. We divide this problem into two steps – ﬁrst  we devise an algorithm that can learn
the latent variables between any two variables that are non-adjacent in the observable graph; later  we
design an algorithm that learns the latent variables between every pair of adjacent variables.

5.1 Baseline Algorithm for Detecting Latents between Non-edges
Consider two variables X and Y such that X L ! Y and where L is a latent variable. Clearly  to
distinguish it from the case where X and Y are disconnected and have no latents  one needs check if
X 6?? Y or not. This is a conditional independence test. For any non edge (X  Y ) in the observable
graph D  when the observable graph D is known  to check for latents between them  when other
variables and possible confounders are around  one has to simply intervene on the rest of the n  2
variables and do a independence test between X and Y in the post interventional graph. This requires
a distinct intervention for every pair of variables. If the observable graph has maximum degree
d = o(n)  this requires ⇥(n2) interventions. We will reduce this to O(d2 log n) interventions which
is an exponential improvement for constant degree graphs.

5.2 Latents between Non-adjacent Nodes

We start by noting the following fact about causal systems with latent variables:
Theorem 4. Consider two non-adjacent nodes Xi  Xj. Let S be the union of the parents of Xi  Xj 
S = P ai [ P aj. Consider an intervention on S. Then we have (Xi 6?? Xj)MS if and only if there
exists a latent variable Li j such that Xj Li j ! Xi. The statement holds under an intervention
S such that P ai [ P aj ⇢ S  Xi  Xj /2 S.
The above theorem motivates the following approach: For a set of nodes which forms an independent
set  an intervention on the union of parents of the nodes of the independent set allows us to learn
the latents between any two nodes in the independent set. We leverage this observation using the
following lemma on the number of such independent sets needed to cover all non-edges.
Lemma 6. Consider a directed acyclic graph D = (V  E) with degree (out-degree+in-degree)
d. Then there exists a randomized algorithm that returns a family of m = O(4e2(d + 1)2 log(n))
independent sets I = {I1  I2  . . .   Im} that cover all non-edges of D: 8i  j such that (Xi  Xj) /2 E
and (Xj  Xi) /2 E  9k 2 [m] such that Xi 2 Ik and Xj 2 Ik  with probability at least 1  1
n2 .
Note that this is a randomized construction and we are not aware of any deterministic construction.
Our deterministic causal learning algorithm requires oracle access to such a famiy of independent
sets  whereas our randomized algorithm can directly use this randomized construction. Now  we use
this observation to construct a procedure to identify latents between non-edges (see Algorithm 4).
The following theorem about its performance follows from Lemma 6 and Theorem 4.

7

Algorithm 4 LearnLatentNonEdge- Given access to a CI oracle  observable graph D with max degree
d (in-degree+out-degree)  outputs all latents between non-edges
1: function LEARNLATENTNONEDGE(M  dmax)
2:
3:

L = ;.
Apply the randomized algorithm in Lemma 6 to ﬁnd a family of independent sets I =
for j 2 [1 : m] do

{I1  I2  . . .   Im} that cover all non-edges in D such that m  4e2(d + 1)2 log(n).

Intervene on the parent set of the nodes in Ij.
for every pair of nodes X  Y in Ij do

4:
5:
6:
7:
8:
9:
10:
11:
12:
13: end function

end for

if (X 6?? Y )D`[Ij ] then
L L [{ X  Y }.
end if

end for
return The set of non-edges L.

U

Z

L

M

X

Y

G1: do(PaX) is needed 

T

L

Y

X
M
G2: do(PaY) is needed 

Z

Figure 2: Left: A graph where intervention on the parents of X is needed for do-see test to succeed.
Right: A graph where intervention on the parents of Y is needed for do-see test to succeed.

Theorem 5. Algorithm 4 outputs a list of non-edges L that have latent variables between them  given
the observable graph D  with probability at least 1  1
n2 . The algorithm requires 4e2(d + 1)2 log(n)
interventions where d is the max-degree (in-degree+out-degree) of the observable graph.

5.3 Latents between Adjacent Nodes

We construct an algorithm that can learn latent variables between the variables adjacent in the
observable graph. Note that the approach of CIT testing in the post-interventional graph is not helpful.
Consider the variables X ! Y . To see the effect of the latent path  one needs to cut the direct edge
from X to Y . This requires intervening on Y . However  such an intervention disconnects Y from its
latent parent. Thus we resort to a different approach compared to the previous stages and exploit a
different characterization of causal Bayesian networks called a ‘do-see’ test.
A do-see test can be described as follows: Consider again a graph where X ! Y . If there are no
latents  we have P(Y |X) = P(Y |do(X)). Assume that there is a latent variable Z which causes both
X and Y   then excepting the pathological cases7  P(Y |X) 6= P(Y |do(X)).
Figure 2 illustrates the challenges associated with a do-see test in bigger graphs with latents. Graphs
G1 and G2 are examples where parents of both nodes involved in the test need to be included in the
intervention set for the Do-see test to work. In G1  suppose we condition on X  as required by the
‘see’ test. This opens up a non-blocking path X  U  T  M  Y . Since X ! Y is not the only
d-connecting path  it is not necessarily true that P(Y |X) = P(Y |do(X)). Now suppose we perform
the do-see test under the intervention do(Z). Then the aforementioned path is closed since X is not a
descendant of T in the post interventional graph. Hence we have P(Y |X  do(Z)) = P(Y |do(X  Z)).
Similarly G2 shows that intervening on the parent set of Y is also necessary.
We have the following theorem  which shows that we can perform the do-see test between X  Y
under do(P aX  P aY ):

7These cases are fully identiﬁed in the full version [20].

8

Theorem 6. [Interventional Do-see test] Consider a causal graph D on the set of observable
variables V = {Vi}i2[n] and latent variables L = {Li}i2[m] with edge set E. If (Vi  Vj) 2 E  then

Pr(Vj|Vi = vi  do(P ai = pai  P aj = paj)) = Pr(Vj|do(Vi = vi  P ai = pai  P aj = paj)) 

iff @k such that (Lk  Vi) 2 E and (Lk  Vj) 2 E  where P ai is the set of parents of Vi in V . Quantities
on both sides are invariant irrespective of additional interventions elsewhere.

Next we need a subgraph structure to perform multiple do-see tests at once in order to efﬁciently
discover the latents between the adjacent nodes. Performing the test for every edge would take O(n)
even in graphs with constant degree. We use strong edge coloring of sparse graphs.
Deﬁnition 3. A strong edge coloring of an undirected graph with k colors is a map  : E ! [k]
such that every color class is an induced matching. Equivalently  it is an edge coloring such that any
two nodes adjacent to distinct edges with the same color are non-adjacent.

Graphs of maximum degree d can be strongly edge-colored with at most 2d2 colors.
Lemma 7. [6] A graph of maximum degree d can be strongly edge-colored with at most 2d2 colors.
A simple greedy algorithm that colors edges in sequence achieves this.

Now observe that a color class of the edges forms an induced matching. We show that due to this 
the ‘do’ part (RHS of Theorem 6) of all the do-see tests in a color class can be performed with a
single intervention while the ‘see’ part (RHS of Theorem 6) can be again performed with another
intervention. We argue that we need exactly two different interventions per color class. The following
theorem uses this property to prove correctness of Algorithm 5.

Algorithm 5 LearnLatentEdge- Observable graph D with max degree d (in-degree+out-degree) 
outputs all latents between edges
1: function LEARNLATENTEDGE(M  d)
2:
3:
4:
5:

L = ;.
Apply the greedy algorithm in Lemma 7 to color the edges of D with k  2d2 colors.
for j 2 [1 : k] do

Let Aj be the nodes involved with the edges that form color class j. Let Pj be the union

of parents of all nodes in Aj except the nodes in Aj.

6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20: end function

end for

Let the set of tail nodes of all edges be Tj.
Following loop requires the intervention on the set Tj [ Pj  i.e. do({Tj  Pj}).
for Every directed edge (Vt  Vh) in color class j do
Calculate S(Vt  Vh) = P (Vh|do(Tj  Pj)) using post interventional samples.

end for
Following loop requires the intervention on the set Pj.
for Every directed edge (Vt  Vh) in color class j do

Calculate S0(Vt  Vh) = P (Vh|Vt  do(Pj)) using post interventional samples.
if S0(Vt  Vh) 6= S(Vt  Vh) then
end if

L L [ (Vt  Vh)

end for
return The set of edges L that have latents between them.

Theorem 7. Algorithm 5 requires at most 4d2 interventions and outputs all latents between the edges
in the observable graph.

6 Conclusions

Learning cause-and-effect relations is one of the fundamental challenges in science. We studied the
problem of learning causal models with latent variables using experimental data. Speciﬁcally  we
introduced two efﬁcient algorithms capable of learning direct causal relations (instead of ancestral
relations) and ﬁnding the existence and location of potential latent variables.

9

References
[1] Alfred V. Aho  Michael R Garey  and Jeffrey D. Ullman. The transitive reduction of a directed

graph. SIAM Journal on Computing  1(2):131–137  1972.

[2] Ayesha R. Ali  Thomas S. Richardson  Peter L. Spirtes  and Jiji Zhang. Towards characterizing
markov equivalence classes for directed acyclic graphs with latent variables. In Proc. of the
Uncertainty in Artiﬁcial Intelligence  2005.

[3] Noga Alon. Covering graphs by the minimum number of equivalence relations. Combinatorica 

6(3):201–206  1986.

[4] E. Bareinboim and J. Pearl. Causal inference by surrogate experiments: z-identiﬁability. In
Nando de Freitas and Kevin Murphy  editors  Proceedings of the Twenty-Eighth Conference on
Uncertainty in Artiﬁcial Intelligence  pages 113–120  Corvallis  OR  2012. AUAI Press.

[5] E. Bareinboim and J. Pearl. Causal inference and the data-fusion problem. Proceedings of the

National Academy of Sciences  113:7345–7352  2016.

[6] Julien Bensmail  Marthe Bonamy  and Hervé Hocquard. Strong edge coloring sparse graphs.

Electronic Notes in Discrete Mathematics  49:773–778  2015.

[7] Soﬁa Borboudakis  Giorgos andTriantaﬁllou and Ioannis Tsamardinos. Tools and algorithms for
causally interpreting directed edges in maximal ancestral graphs. In Sixth European Workshop
on Probabilistic Graphical Models  2012.

[8] Tom Claassen and Tom Heskes. Causal discovery in multiple models from different experiments.

In Advances in Neural Information Processing Systems  pages 415–423  2010.

[9] Frederick Eberhardt. Phd thesis. Causation and Intervention (Ph.D. Thesis)  2007.

[10] Frederick Eberhardt and Richard Scheines. Interventions and causal inference. Philosophy of

Science  74(5):981–995  2007.

[11] Alain Hauser and Peter Bühlmann. Characterization and greedy learning of interventional
markov equivalence classes of directed acyclic graphs. Journal of Machine Learning Research 
13(1):2409–2464  2012.

[12] Alain Hauser and Peter Bühlmann. Two optimal strategies for active learning of causal networks
from interventional data. In Proceedings of Sixth European Workshop on Probabilistic Graphical
Models  2012.

[13] Christina Heinze-Deml  Marloes H. Maathuis  and Nicolai Meinshausen. Causal structure

learning. Annual Review of Statistics and Its Applications  2017  To appear.

[14] Patrik O Hoyer  Dominik Janzing  Joris Mooij  Jonas Peters  and Bernhard Schölkopf. Nonlinear

causal discovery with additive noise models. In Proceedings of NIPS 2008  2008.

[15] Antti Hyttinen  Frederick Eberhardt  and Patrik Hoyer. Experiment selection for causal discovery.

Journal of Machine Learning Research  14:3041–3071  2013.

[16] Antti Hyttinen  Patrik O Hoyer  Frederick Eberhardt  and Matti Jarvisalo. Discovering
cyclic causal models with latent variables: A general sat-based procedure. arXiv preprint
arXiv:1309.6836  2013.

[17] Gyula Katona. On separating systems of a ﬁnite set. Journal of Combinatorial Theory 

1(2):174–194  1966.

[18] Murat Kocaoglu  Alexandros G. Dimakis  and Sriram Vishwanath. Cost-optimal learning of

causal graphs. In ICML’17  2017.

[19] Murat Kocaoglu  Alexandros G. Dimakis  Sriram Vishwanath  and Babak Hassibi. Entropic

causal inference. In AAAI’17  2017.

10

[20] Murat Kocaoglu*  Karthikeyan Shanmugam*  and Elias Bareinboim. Experimental design for
learning causal graphs with latent variables. Technical Report R-28  AI Lab  Purdue University 
https://www.cs.purdue.edu/homes/eb/r28.pdf  2017.

[21] Po-Ling Loh and Peter Bühlmann. High-dimensional learning of linear causal networks via

inverse covariance estimation. Journal of Machine Learning Research  5:3065–3105  2014.

[22] Sara Magliacane  Tom Claassen  and Joris M Mooij. Joint causal inference on observational

and experimental datasets. arXiv preprint arXiv:1611.10351  2016.

[23] Stijn Meganck  Sam Maes  Philippe Leray  and Bernard Manderick. Learning semi-markovian
causal models using experiments. In Proceedings of The third European Workshop on Proba-
bilistic Graphical Models   PGM 06  2006.

[24] Pekka Parviainen and Mikko Koivisto. Ancestor relations in the presence of unobserved
variables. In Joint European Conference on Machine Learning and Knowledge Discovery in
Databases  2011.

[25] J. Pearl  M. Glymour  and N.P. Jewell. Causal Inference in Statistics: A Primer. Wiley  2016.
[26] Judea Pearl. Causality: Models  Reasoning and Inference. Cambridge University Press  2009.
[27] Jonas Peters and Peter Bühlman. Identiﬁability of gaussian structural equation models with

equal error variances. Biometrika  101:219–228  2014.

[28] Jonas Peters  Peter Bühlmann  and Nicolai Meinshausen. Causal inference using invariant
prediction: identiﬁcation and conﬁdence intervals. Statistical Methodology  Series B  78:947 –
1012  2016.

[29] Bernhard Schölkopf  David W. Hogg  Dun Wang  Daniel Foreman-Mackey  Dominik Janzing 
Carl-Johann Simon-Gabriel  and Jonas Peters. Removing systematic errors for exoplanet search
via latent causes. In Proceedings of the 32 nd International Conference on Machine Learning 
2015.

[30] Karthikeyan Shanmugam  Murat Kocaoglu  Alex Dimakis  and Sriram Vishwanath. Learning

causal graphs with small interventions. In NIPS 2015  2015.

[31] S Shimizu  P. O Hoyer  A Hyvarinen  and A. J Kerminen. A linear non-gaussian acyclic model

for causal discovery. Journal of Machine Learning Research  7:2003––2030  2006.

[32] Ricardo Silva  Richard Scheines  Clark Glymour  and Peter Spirtes. Learning the structure of

linear latent variable models. Journal of Machine Learning Research  7:191–246  2006.

[33] Peter Spirtes  Clark Glymour  and Richard Scheines. Causation  Prediction  and Search. A

Bradford Book  2001.

[34] Soﬁa Triantaﬁllou and Ioannis Tsamardinos. Constraint-based causal discovery from multiple
interventions over overlapping variable sets. Journal of Machine Learning Research  16:2147–
2205  2015.

[35] Thomas Verma and Judea Pearl. An algorithm for deciding if a set of observed independencies
has a causal explanation. In Proceedings of the Eighth international conference on uncertainty
in artiﬁcial intelligence  1992.

[36] Jiji Zhang. Causal reasoning with ancestral graphs. J. Mach. Learn. Res.  9:1437–1474  June

2008.

[37] Jiji Zhang. On the completeness of orientation rules for causal discovery in the presence of

latent confounders and selection bias. Artiﬁcial Intelligence  172(16):1873–1896  2008.

11

,Murat Kocaoglu
Karthikeyan Shanmugam
Elias Bareinboim