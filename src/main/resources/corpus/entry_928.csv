2012,Causal discovery with scale-mixture model for spatiotemporal variance dependencies,In conventional causal discovery  structural equation models (SEM) are directly applied to the observed variables  meaning that the causal effect can be represented as a function of the direct causes themselves. However  in many real world problems  there are significant dependencies in the variances or energies  which indicates that causality may possibly take place at the level of variances or energies. In this paper  we propose a probabilistic causal scale-mixture model with spatiotemporal variance dependencies to represent a specific type of generating mechanism of the observations. In particular  the causal mechanism including contemporaneous and temporal causal relations in variances or energies is represented by a Structural Vector AutoRegressive model (SVAR). We prove the identifiability of this model under the non-Gaussian assumption on the innovation processes. We also propose algorithms to estimate the involved parameters and discover the contemporaneous causal structure. Experiments on synthesis and real world data are conducted to show the applicability of the proposed model and algorithms.,Causal discovery with scale-mixture model for

spatiotemporal variance dependencies

Zhitang Chen*  Kun Zhang†  and Laiwan Chan*

*Department of Computer Science and Engineering  Chinese University of Hong Kong  Hong Kong

{ztchen lwchan}@cse.cuhk.edu.hk

†Max Planck Institute for Intelligent Systems  T¨ubingen  Germany

kzhang@tuebingen.mpg.de

Abstract

In conventional causal discovery  structural equation models (SEM) are directly
applied to the observed variables  meaning that the causal effect can be represented
as a function of the direct causes themselves. However  in many real world prob-
lems  there are signiﬁcant dependencies in the variances or energies  which indi-
cates that causality may possibly take place at the level of variances or energies. In
this paper  we propose a probabilistic causal scale-mixture model with spatiotem-
poral variance dependencies to represent a speciﬁc type of generating mechanism
of the observations. In particular  the causal mechanism including contempora-
neous and temporal causal relations in variances or energies is represented by a
Structural Vector AutoRegressive model (SVAR). We prove the identiﬁability of
this model under the non-Gaussian assumption on the innovation processes. We
also propose algorithms to estimate the involved parameters and discover the con-
temporaneous causal structure. Experiments on synthetic and real world data are
conducted to show the applicability of the proposed model and algorithms.

1 Introduction

Causal discovery aims to discover the underlying generating mechanism of the observed data  and
consequently  the causal relations allow us to predict the effects of interventions on the system
[15  19]. For example  if we know the causal structure of a stock market  we are able to predict the
reactions of other stocks against the sudden collapse of one share price in the market. A traditional
way to infer the causal structure is by controlled experiments. However  controlled experiments
are in general expensive  time consuming  technically infeasible and/or ethically prohibited. Thus 
causal discovery from non-experimental data is of great importance and has drawn considerable
attention in the past decades [15  19  16  17  12  22  2]. Probabilistic models such as Bayesian
Networks (BNs) and Linear Non-Gaussian Acyclic Models (LiNGAM) have been proposed and
applied to many real world problems [18  13  14  21].
Conventional models such as LiNGAM assume that the causal relations are of a linear form  i.e.  if
the observed variable x is the cause of another observed variable y  we model the causal relation as
y = αx + e  where α is a constant coefﬁcient and e is the additive noise independent of x. However 
in many types of natural signals or time series such as MEG/EEG data [23] and ﬁnancial data [20] 
a common form of nonlinear dependency  as seen from the correlation in variances or energies  is
found [5]. This observation indicates that causality may take place at the level of variances or en-
ergies instead of the observed variables themselves. Generally speaking  traditional methods cannot
detect this type of causal relations. Another restriction of conventional causal models is that these
models assume constant variances of the observations; this assumption is unrealistic for those data
with strong heteroscedasticity [1].

1

In this paper  we propose a new probabilistic model called Causal Scale-Mixture model with Spa-
tioTemporal Variance Dependencies (CSM-STVD) incorporating the spatial and temporal variance
or energy dependencies among the observed data. The main feature of the new model is that we
model the spatiotemporal variance dependencies based on the Structural Vector AutoRegressive
(SVAR) model  in particular the Non-Gaussian SVAR [11]. The contributions of this study are
two-fold. First  we provide an alternative way to model the causal relations among the observa-
tions  i.e.  causality in variances or energies. In this model  causality takes place at the level of
variances or energies  i.e.  the variance or energy of one observed series at time instant t0 is inﬂu-
enced by the variances or energies of other variables at time instants t ≤ t0 and its past values at
time instants t < t0. Thus  both contemporaneous and temporal causal relations in variances are
considered. Secondly  we prove the identiﬁability of this model and more speciﬁcally  we show
that Non-Gaussianity makes the model fully identiﬁable. Furthermore  we propose a method which
directly estimates such causal structures without explicitly estimating the variances.

2 Related work

To model the variance or energy dependencies of the observations  a classic method is to use a scale-
mixture model [5  23  9  8]. Mathematically  we can represent a signal as si = uiσi  where ui is a
signal with zero mean and constant variance  and σi is a positive factor which is independent of ui
and modulates the variance or energy of si [5]. For multivariate case  we have

s = u ⊙ σ 

(1)
where ⊙ means element-wise multiplication. In basic scale-mixture model  u and σ are statistically
 ∀tτ1  tτ2.
independent and the components ui are spatiatemporally independent  i.e. ui t(cid:28)1
However  σi  the standard deviations of the observations  are dependent across i. The observation
x  in many situations  is assumed to be a linear mixture of the source s  i.e.  x = As  where A is a
mixing matrix.
In [5]  Hirayama and Hyv¨arinen proposed a two-stage model. The ﬁrst stage is a classic ICA model
[3  10]  where the observation x is a linear mixture of the hidden source s  i.e.  x = As. On the
second stage  the variance dependencies are modeled by applying a linear Non-Gaussian (LiN) SEM
to the log-energies of the sources.

⊥⊥ uj t(cid:28)2

∑

yi =

j

hijyj + hi0 + ri  i = 1  2 ···   d 

where yi = log ϕ(σi) are the log-energies of sources si and the nonlinear function ϕ is any appropri-
ate measure of energy; ri are non-Gaussian distributed and independent of yj. To make the problem
tractable  they assumed that ui are binary  i.e.  ui ∈ {−1  1} and uniformly distributed. The param-
eters of this two-stage model including A and hij are estimated by maximum likelihood without
approximation due to the uniform binary distribution assumption of u. However  this assumption is
restrictive and thus may not ﬁt real world observations well. Furthermore  they assumed that σi are
spatially dependent but temporally white. However  many time series show strong heterosecadastic-
ity and temporal variance dependencies such as ﬁnancial time series and brain signals. Taking into
account of temporal variance dependencies would improve the quality of the estimated underlying
structure of the observed data.
Another two-stage model for magnetoencephalography (MEG) or electroencephalography (EEG)
data was propsoed earlier in [23]. The ﬁrst stage also performs linear separation; they proposed
a blind source separation algorithm by exploiting the autocorrelations and time-varying variances
of the sources.
In the second stage  si(t) are modeled by autoregressive processes with L lags
(AR(L)) driven by innovations ei(t). The innovation processes ei(t) are mutually uncorrelated and
temporally white. However  ei(t) are not necessarily independent. They modeled ei(t) as follows:
(2)

ei(t) = σitzi(t)  where zi(t) ∼ N (0  1).

Two different methods are used to model the dependencies among the variances of the innovations.
The ﬁrst method is causal-in-variance GARCH (CausalVar-GARCH). Speciﬁcally σ2
it are modeled
by a multivariate GARCH model. The advantage of this model is that we are able to estimate
the temporal causal structure in variances. However  this model provides no information about the

2

contemporaneous causal relations among the sources if there indeed exist such causal relations. The
second method to model the variance dependencies is applying a factor model to the log-energies
(log σ2
it) of the sources. The disadvantage of this method is that we cannot model the causal relations
among the sources which are more interesting to us.
In many real world observations  there are causal inﬂuences in variances among the observed vari-
ables. For instance  there are signiﬁcant mutual inﬂuences among the volatilities of the observed
stock prices. We are more interested in investigating the underlying causal structure among the
variances of the observed data. Consequently  in this paper  we consider the situation where the
correlation in the variances of the observed data is interesting. That is  the ﬁrst stage of [5  23] is
not needed  and we focus on the second stage  i.e.  modeling the spatiotemporal variance depen-
dencies and causal mechanism among the observations. In the following sections  we propose our
probabilistic model based on SVAR to describe the spatiotemporal variance dependencies among
the observations. Our model is  as shown in later sections  closely related to the models introduced
in [5  23]  but has signiﬁcant advantages: (1) both contemporaneous and temporal causal relations
can be modeled; (2) this model is fully identiﬁable under certain assumptions.

3 Causal scale-mixture model with spatiotemporal variances dependencies

We propose the causal scale-mixture model with spatiotemporal variance dependencies as follows.
Let z(t) be the m × 1 observed vector with components zi(t)  which are assumed to be generated
according to the scale-mixture model:

(3)
Here we assume that ui(t) are temporally independent processes  i.e.  ui(tτ1 ) ⊥⊥ uj(tτ2) ∀tτ1
̸= tτ2
but unlike basic scale-mixture model  here ui(t) may be contemporarily dependent  i.e.  ui(t) ̸⊥⊥
uj(t) ∀i ̸= j. σ(t) is spatially and temporally independent of u(t). Using vector notation 

zi(t) = ui(t)σi(t).

(4)
Here σit > 0 are related to the variances or energies of the observations zt and are assumed to be
spatiotemporally dependent. As in [5  23]  let yt = log σt. In this paper  we model the spatiotem-
poral variance dependencies by a Structural Vector AutoRegressive model (SVAR)  i.e. 

zt = ut ⊙ σt.

L∑

L∑

xt = yt + ηt 

yt = A0yt +

yt = A0yt +

τ =1

Bτ yt−τ + ϵt 

(5)

where A0 contains the contemporaneous causal strengths among the variances of the observations 
i.e.  if [A0]ij ̸= 0  we say that yit is contemporaneously affected by yjt; Bτ contains the temporal
(time-lag) causal relations  i.e.  if [Bτ ]ij ̸= 0  we say that yi t is affected by yj t−τ . Here  ϵt are
i.i.d. mutually independent innovations. Let xt = log |zt| (In this model  we assume that ui(t) do
not take value zero) and ηt = log |ut|.Take log of the absolute values of both sides of equation (4) 
then we have the following model:

Bτ yt−τ + ϵt.

(6)

τ =1
We make the following assumptions on the model:

A1 Both ηt and ϵt are temporally white with zero means. The components of ηt are not neces-
sarily independent  and we assume that the covariance matrix of ηt is (cid:6)η. The components
of ϵt are independent and (cid:6)ϵ = I1.
A2 The contemporaneous causal structure is acyclic  i.e.  by simultaneous row and column
permutations  A0 can be permuted to a strictly lower triangular matrix. BL is of full rank.
1Note that (cid:6)ϵ = I is assumed just for convenience. A0 and B(cid:28) can also be correctly estimated if (cid:6)ϵ is a
general diagonal covariance matrix. The explanation why the scaling indeterminacy can be eliminated is the
same as LiNGAM given in [16].

3

A3 The innovations ϵt are non-Gaussian  and ηt are either Gaussian or non-Gaussian.

Inspired by the identiﬁability results of the Non-Gaussian state-space model in [24]  we show that
our model is identiﬁable. Note that our new model and the state-space model proposed in [24] are
two different models  while interestingly by simple re-parameterization we can prove the following
Lemma 3.1 and Theorem 3.1 following [24].
Lemma 3.1 Given the log-transformed observation xt = log |zt| generated by Equations (6)  if the
assumptions A1 ∼ A2 hold  by solving simple linear equations involving the autocovariances of xt 
the covariance (cid:6)η and ABτ can be uniquely determined  where A = (I − A0)
−1; furthermore  A
and Bτ can be identiﬁed up to some rotation transformations. That is  suppose that two models with
parameters (A {Bτ}L
τ =1  ~(cid:6) ~η) generate the same observation xt  then we
have (cid:6)η = ~(cid:6) ~η  ~A = AU  ~Bτ = UT Bτ   where U is an orthogonal matrix.

τ =1  (cid:6)η) and ( ~A { ~Bτ}L

Non-Gaussianity of the innovations ϵt makes the model fully identiﬁable  as seen in the following
theorem.
Theorem 3.1 Given the log-transformed observation xt = log |zt| generated by Equations (6) and
given L  if assumptions A1 ∼ A3 hold  then the model is identiﬁable. In other words  suppose
that two models with parameters (A {Bτ}L
τ =1  ~(cid:6) ~η) generate the same
observation xt; then these two models are identical  i.e.  we have ~(cid:6) ~η = (cid:6)η  ~A = A  ~Bτ = Bτ  
and ~yt = yt.

τ =1  (cid:6)η) and ( ~A { ~Bτ}L

4 Parameter learning and causal discovery

In this section  we propose an effective algorithm to estimate the contemporaneous causal structure
matrix A0 and temporal causal structure matrices Bτ   τ = 1 ···   L (see (6)).

4.1 Estimation of ABτ
We have shown that ABτ can be uniquely determined  where A = (I − A0)
−1. The proof of
Lemma 3.1 also suggests a way to estimate ABτ   as given below. Readers can refer to the appendix
for the detailed mathematical derivation. Although we are aware that this method might not be sta-
tistically efﬁcient  we adopt this estimation method due to its great computational efﬁciency. Given
the log-transformed observations xt = log |zt|  denoted by Rx(k) the autocovariance function of
t+k). Based on the model assumptions A1 and A2  we have
xt at lag k  we have Rx(k) = E(xtxT
the following linear equations of the autocovarainces of xt.
Rx(L (cid:0) 1)
Rx(L)

Rx(L + 1)

Rx(L + 1)

Rx(L + 2)

Rx(L)

(7)

(cid:1)(cid:1)(cid:1) Rx(1)
(cid:1)(cid:1)(cid:1) Rx(2)
...

...

37777775 ;

26666664

3777775

}

CT
1
CT
2
...
CT
L

2666664

3777775 =

2666664

|

...

Rx(2L)

...

Rx(2L (cid:0) 1) Rx(2L (cid:0) 2) (cid:1)(cid:1)(cid:1) Rx(L)

...
{z

where Cτ = ABτ (τ = 1 ···   L). As shown in the proof of Lemma 3.1  H is invertible. We can
easily estimate ABτ by solving the linear Equations (7).

 H

4.2 Estimation of A0
The estimations of ABτ (τ = 1 ···   L) still contain the mixing information of the causal structures
A0 and Bτ . In order to further obtain the contemporaneous and temporal causal relations  we need
to estimate both A0 and Bτ (τ = 1 ···   L). Here  we show that the estimation of A0 can be reduced
to solving a Linear Non-Gaussian Acyclic Models with latent confounders.
Substituting yt = xt − ηt into Equations (6)  we have

xt − ηt =

ABτ (xt−τ − ηt−τ ) + Aϵt.

(8)

L∑

τ =1

4

Since ABτ can be uniquely determined according to Lemma 3.1 or more speciﬁcally Equations (7) 

we can easily obtain ξt = xt −∑

τ =1 ABτ xt−τ   then we have:

L

ξt = Aϵt + ηt − L∑

ABτ ηt−τ .

(9)

This is exactly a Linear Non-Gaussian Acyclic Model with latent confounders and the estimation of
A is a very challenging problem [6  2]. To make to problem tractable  we further have the following
two assumptions on the model:

τ =1

• A4 If the components of ηt are not independent  we assume that ηt follows a factor model:
ηt = Dft  where the components of ft are spatially and temporally independent Gaussian
factors and D is the factor loading matrix (not necessarily square).
• A5 The components of ϵt are simultaneously super-Gaussian or sub-Gaussian.

By replacing ηt with Dft   we have:

ξt = Aϵt + Dft − L∑
{z

|

τ =1

}

ABτ Dft−τ

.

(10)

confounding effects

To identify the matrix A which contains the contemporaneous causal information of the observed
variables  we treat ft and ft−τ as latent confounders and the interpretation of assumption A4 is that
we can treat the independent factors ft as some external factors outside the system. The Gaussian
assumption of ft can be interpreted hierarchically as the result of central limit theorem because these
factors themselves represent the ensemble effects of numerous factors from the whole environment.
On the contrary  the disturbances ϵit are local factors that describe the intrinsic behaviors of the
observed variables [4]. Since they are local and thus not regarded as the ensembles of large amount
of factors. In this case  the disturbances ϵit are assumed to be non-Gaussian.
The LiNGAM-GC model [2] takes into the consideration of latent confounders. In that model  the
confounders are assumed to follow Gaussian distribution  which was interpreted as the result of
central limit theorem. It mainly focuses on the following cause-effect pair:

x = e1 + αc 
y = ρx + e2 + βc 

(11)

where e1 and e2 are non-Gaussian and mutually independent  and c is the latent Gaussian confounder
independent of the disturbances e1 and e2. To tackle the causal discovery problem of LiNGAM-
GC  it was ﬁrstly shown that if x and y are standardized to unit absolute kurtosis then |ρ| < 1
based on the assumption that e1 and e2 are simultaneously super-Gaussian or sub-Gaussian. Note
that assumption A5 is a natural extension of this assumption. It holds in many practical problems 
especially for ﬁnancial data. After the standardization  the following cumulant-based measure ~Rxy
was proposed [2]:

~Rxy = (Cxy + Cyx)(Cxy − Cyx)  where
Cxy = ^E{x3y} − 3^E{xy}^E{x2} 
Cyx = ^E{xy3} − 3^E{xy}^E{y2} 

(12)

and ^E means sample average. It was shown that the causal direction can be identiﬁed simply by
examining the sign of ~Rxy  i.e.  if ~Rxy > 0  x → y is concluded; otherwise if ~Rxy < 0  y →
x is concluded. Once the causal direction has been identiﬁed  the estimation of causal strength
is straightforward. The work can be extended to multivariate causal network discovery following
DirectLiNGAM framework [17].
Here we adopt LiNGAM-GC-UK  the algorithm proposed in [2]  to ﬁnd the contemporaneous casual
structure matrix A0. Once A0 has been estimated  Bτ can be easily obtained by ^Bτ = (I− ^A0) ^Cτ  
where ^A0 and ^Cτ are the estimations of A0 and ABτ   respectively. The algorithm for learning the
model is summarized in the following algorithm.

5

Algorithm 1 Causal discovery with scale-mixture model for spatiotemporal variance dependencies
1: Given the observations zt  compute xt = log |zt|.
2: Subtract the mean (cid:22)xt from xt  i.e.  xt = xt − (cid:22)xt
3: Choose an appropriate lag L for the SVAR and then estimate ABτ where A = (I− A0)

−1 and

4: Obtain the residues by ξt = xt −∑

τ = 1 ···   L  using Equations(7).

5: Apply LiNGAM-GC algorithms to ξt and obtain the estimation of A0 and Bτ (τ = 1 ···   L)

and the corresponding comtemporaneous and temporal causal orderings.

L

τ =1 ABτ xt−τ .

5 Experiment

We conduct experiments using synthetic data and real world data to investigate the effectiveness of
our proposed model and algorithms.

5.1 Synthetic data

We generate the observations according to the following model:

zt = r ⊙ ut ⊙ σt 

r is a m×1 scale vector of which the elements are randomly selected from interval [1.0  6.0]; ut > 0
and ηt = log ut follows a factor model:

where D is m × m and the elements of D are randomly selected from [0.2  0.4] . fit are i.i.d. and
fit ∼ N (0  0.5). Denoted by yt = log σt  we model the spatiotemporal variance dependencies of
the observations xt by an SVAR(1):

ηt = Dft 

yt = A0yt + B1yt−1 + ϵt 

where A0 is a m × m strictly lower triangular matrix of which the elements are randomly selected
from [0.1  0.2] or [−0.2 −0.1]; B1 is a m × m matrix of which the diagonal elements [B1]ii are
randomly selected from [0.7  0.8]  80% of the off-diagonal elements [B1]i̸=j are zero and the re-
maining 20% are randomly selected from [−0.1  0.1]; ϵit are i.i.d. super-Gaussian generated by
ϵit = sign(nit)|nit|2(nit ∼ N (0  1)) and normalized to unit variance. The generated observations
are permuted to a random order. The task of this experiment is to investigate the performance of our
algorithms in estimating the coefﬁcient matrix (I − A0)
−1B1 and also the contemporaneous causal
ordering induced by A0. We estimate the matrix (I − A0)
−1B1 using Lemma 3.1 or speciﬁcally
Equations (7). We use different algorithms: LiNGAM-GC-UK proposed in [2]  C-M proposed in
[7] and LiNGAM [16] to estimate the contemporaneous causal structure. We investigate the perfor-
mances of different algorithms in the scenarios of m = 4 with sample size from 500 to 4000 and
m = 8 with sample size from 1000 to 10000. For each scenario  we randomly conduct 100 inde-
pendent trials and discard those trials where the SVAR processes are not stable. We calculate the
accuracies of LiNGAM-GC-UK  C-M and LiNGAM in ﬁnding (1) whole causal ordering (2) exoge-
∑
nous variable (root) of the causal network. We also calculate the sum square error Err of estimated
∑
causal strength matrix of different algorithms with respect to the true one. The average SNR deﬁned
i V ar(ϵi)
as SN R = 10 log
i V ar(fi) is about 13.85 dB. The experimental results are shown in Figure 1 and
Table 1. Figure 1 shows the plots of the estimated entries of (I−A0)
−1B1 versus the true ones when
the dimension of the observations m = 8. From Figure 1  we can see that the matrix (I− A0)
−1B1
is estimated well enough when the sample size is only 1000. This conﬁrms the correctness of our
theoretical analysis of the proposed model. From Table 1  we can see that when the dimension of
the observations is small (m = 4)  all algorithms have acceptable performances. The performance
of LiNGAM is the best when the sample size is small. This is because C-M and LiNGAM-GC-UK
are cumulant-based methods which need sufﬁciently large sample size. When the dimension of the
observations m increases to 8  we can see that the performances of C-M and LiNGAM degrade
dramatically. While LiNGAM-GC-UK still successfully ﬁnds the exogenous variable (root) or even
the whole contemporaneous causal ordering among the variances of the observations if the sample
size is sufﬁciently large enough. This is mainly due to the fact that when the dimension increases 

6

Figure 1: Estimated entries causal strength matrix (I −
A0)

−1B1 vs the true ones (m = 8)

Figure 2: Contemporaneous causal net-
work of the selected stock indices

Table 1: Accuracy of ﬁnding the causal ordering

sample size

whole causal ordering

C-M LiNGAM LiNGAM-GC-UK

m = 4

500
1000
2000
3000
4000
m = 8
1000
2000
4000
6000
8000
10000

37%
47%
74%
67%
63%

70%
75%
86%
78%
83%

23.08%
0%
1.14% 26.14%
31.87%
0%
25.29%
0%
2.20% 30.77%
23.53%

0%

28%
25%
81%
90%
90%

8.79%
25%
58.24%
83.91%
80.22%
91.76%

C-M

61%
25%
82%
79%
81%

85%
92%
90%
88%
92%

20.88% 75.82%
25%
70.45%
19.78% 82.41%
25.29% 75.86%
17.58% 79.12%
12.94% 68.24%

ﬁrst variable found
LiNGAM LiNGAM-GC-UK

C-M

0.1101
0.0865
0.0679
0.0716
0.0669

0.8516
0.7866
0.7537
0.7638
0.7735
0.7794

Err

LiNGAM LiNGAM-GC-UK

0.0326
0.024
0.02
0.0201
0.0193

0.2318
0.2082
0.1916
0.1843
0.1824
0.194

0.0938
0.0444
0.0199
0.0126
0.0109

0.3017
0.1396
0.0634
0.0341
0.029
0.0199

60%
72%
92%
96%
94%

65.93%
75%
86.81%
96.55%
91.21%
97.64%

the confounding effects of Dft − (I − A)
−1B1Dft−1 become more problematic such that the per-
formances of C-M and LiNGAM are strongly affected by confounding effect. Table 1 also shows
the estimation accuracies of the compared methods. Among them  LiNGAM-GC-UK signiﬁcantly
outperforms other methods given sufﬁciently large sample size.
In order to investigate the robustness of our methods against the Gaussian assumption on the ex-
ternal factors ft  we conduct the following experiment. The experimental setting is the same as
that in the above experiment but here the external factors ft are non-Gaussian  and more speciﬁ-
cally fit = sign(nit)|nit|p  where nit ∼ N (0  0.5). When p > 1  the factor is super-Gaussian
and when p < 1 the factor is sub-Gaussian. We investigate the performances of LiNGAM-
GC-UK  LiNGAM and C-M in ﬁnding the whole causal ordering in difference scenarios where
p = {0.4  0.6  0.8  1.0  1.2  1.4  1.6} with sample size of 6000. The results in Figure 3 show that
LiNGAM-GC-UK achieved satisfying results compared to LiNGAM and C-M. This suggests that al-
though LiNGAM-GC is developed based on the assumption that the latent confounders are Gaussian
distributed  it is still robust in the scenarios where the latent confounders are mildly non-Gaussian
with mild causal strengths.

Figure 3: Robustness against Gaussianity of ft

7

−101−1−0.500.51sample size: 2000true parameters−101−1−0.500.51estimated parameterssample size: 1000−101−1−0.500.51sample size: 4000−101−1−0.500.51estimated parameterssample size: 6000−101−1−0.500.51true parameterssample size: 8000−101−1−0.500.51sample size: 10000FTSEFCHIGDAXIDJINDX1.0050.84270.7404-0.6240.98330.47980.20.40.60.811.21.41.61.8020406080100paccuracy(%)whole causal ordering  LiNGAM−GC−UKC−MLiNGAM0.511.5−0.4−0.200.20.4pkurtosiskurtosis of ft5.2 Real world data

In this section  we use our new model to discover the causal relations among ﬁve major world stocks
indices: (1) Dow Jones Industrial Average (DJI) (2) FTSE 100 (FTSE) (3) Nasdaq-100 (NDX) (4)
CAC 40 (FCHI) (5) DAX (GDAXI)  where DJI and NDX are stock indices in US  and FTSE  FCHI
and GDAXI are indices in Europe. Note that because of the time difference  we believe that the
causal relations among these stock indices are mainly acyclic  as we assumed in this paper. We
collect the adjusted close prices of these selected indices from May 2nd  2006 to April 12th  2012 
and use linear interpolation to estimate the prices on those dates when the data are not available.
We apply our proposed model with SVAR(1) to model the spatiotemporal variance dependencies
of the data. For the contemporaneous causal structure discovery  we use LiNGAM-GC-UK  C-M 
LiNGAM2 and Direct-LiNGAM3 to estimate the causal ordering. The discovered causal orderings
of different algorithms are shown in Table 2. From Table 2  we see that in the causal ordering

Table 2: Contemporaneous causal ordering of the selected stock indices

LiNGAM-GC-UK f2g ! f4g ! f5g ! f1g ! f3g

causal ordering

algorithm

C-M

LiNGAM

f1g ! f2g ! f4g ! f5g
f2g ! f5g ! f3g ! f1g

f1g ! f3g
f2g ! f4g

Direct-LiNGAM f3g ! f1g ! f5g ! f4g ! f2g

discovered by LiNGAM-GC-UK and LiNGAM  the stock indices in US  i.e.  DJI and NDX are con-
temporaneously affected by the indices in Europe. Note that each stock index is given in local time.
Because of the time difference between Europe and America and the efﬁcient market hypothesis
(the market is quick to absorb new information and adjust stock prices relative to that)  the contem-
poraneous causal relations should be from Europe to America  if they exist. This is consistent with
the results our method and LiNGAM produced. Another interesting ﬁnding is that in the graphs
obtained by LiNGAM-GC-UK and LiNGAM  we can see that FTSE is the root  which is consistent
with the fact that London is the ﬁnancial centre of Europe and FTSE is regarded as Europe’s most
important index. However  in results by C-M and DirectLiNGAM  we have the opposite direction 
i.e.  the stock indices in US is contemporaneously the cause of the indices in Europe  which is dif-
ﬁcult to interpret. The contemporaneous causal network of the stock indices are shown in Figure 2.
Further interpretation on the discovered causal strengths needs expertise knowledge.

6 Conclusion

In this paper  we investigate the causal discovery problem where causality takes place at the level
of variances or energies instead of the observed variables themselves. We propose a causal scale-
mixture model with spatiotemporal variance dependencies to describe this type of causal mech-
anism. We show that the model is fully identiﬁable under the non-Gaussian assumption of the
innovations. In addition  we propose algorithms to estimate the parameters  especially the contem-
poraneous causal structure of this model. Experimental results on synthetic data verify the practical
usefulness of our model and the effectiveness of our algorithms. Results using real world data fur-
ther suggest that our new model can possibly explain the underlying interaction mechanism of major
world stock markets.

Acknowledgments

The work described in this paper was partially supported by a grant from the Research Grants Coun-
cil of the Hong Kong Special Administration Region  China.

The code is available at:http://www.cs.helsinki.ﬁ/group/neuroinf/lingam/

2LiNGAM converges to several local optima. We only show one of the discovered causal ordering here.
3http://www.ar.sanken.osaka-u.ac.jp/(cid:24)inazumi/dlingam.html

8

References
[1] T. Bollerslev. Generalized autoregressive conditional heteroskedasticity.

31(3):307–327  1986.

Journal of econometrics 

[2] Z. Chen and L. Chan. Causal discovery for linear non-gaussian acyclic models in the presence of latent
gaussian confounders. In Proceedings of the 10th international conference on Latent Variable Analysis
and Signal Separation  pages 17–24. Springer-Verlag  2012.

[3] P. Comon. Independent component analysis  a new concept? Signal processing  36(3):287–314  1994.
[4] R. Henao and O. Winther. Sparse linear identiﬁable multivariate modeling. Journal of Machine Learning

Research  12:863–905  2011.

[5] J. Hirayama and A. Hyv¨arinen. Structural equations and divisive normalization for energy-dependent

component analysis. Advances in Neural Information Processing Systems (NIPS2011)  24  2012.

[6] P.O. Hoyer  S. Shimizu  A.J. Kerminen  and M. Palviainen. Estimation of causal effects using linear
International Journal of Approximate Reasoning 

non-gaussian causal models with hidden variables.
49(2):362–378  2008.

[7] A. Hyv¨arinen. Pairwise measures of causal direction in linear non-gaussian acyclic models. In JMLR
Workshop and Conference Proceedings (Proc. 2nd Asian Conference on Machine Learning)  ACML2010 
volume 13  pages 1–16  2010.

[8] A. Hyv¨arinen  P. O. Hoyer  and M. Inki. Topographic independent component analysis. Neural Compu-

tation  13(7):1527–1558  2001.

[9] A. Hyv¨arinen and J. Hurri. Blind separation of sources that have spatiotemporal variance dependencies.

Signal Processing  84(2):247–254  2004.

[10] A. Hyv¨arinen and E. Oja. Independent component analysis: algorithms and applications. Neural net-

works  13(4-5):411–430  2000.

[11] A. Hyv¨arinen  K. Zhang  S. Shimizu  and P. O. Hoyer. Estimation of a structural vector autoregression

model using non-gaussianity. Journal of Machine Learning Research  11:1709–1731  2010.

[12] D. Janzing  J. Mooij  K. Zhang  J. Lemeire  J. Zscheischler  P. Daniuˇsis  B. Steudel  and B. Sch¨olkopf.

Information-geometric approach to inferring causal directions. Artiﬁcial Intelligence  2012.

[13] Y. Kawahara  S. Shimizu  and T. Washio. Analyzing relationships among arma processes based on non-

gaussianity of external inﬂuences. Neurocomputing  2011.

[14] A. Moneta  D. Entner  PO Hoyer  and A. Coad. Causal inference by independent component analysis
with applications to micro-and macroeconomic data. Jena Economic Research Papers  2010:031  2010.

[15] J. Pearl. Causality: models  reasoning  and inference. Cambridge Univ Pr  2000.
[16] S. Shimizu  P.O. Hoyer  A. Hyv¨arinen  and A. Kerminen. A linear non-gaussian acyclic model for causal

discovery. Journal of Machine Learning Research  7:2003–2030  2006.

[17] S. Shimizu  T. Inazumi  Y. Sogawa  A. Hyv¨arinen  Y. Kawahara  T. Washio  P.O. Hoyer  and K. Bollen.
Directlingam: A direct method for learning a linear non-gaussian structural equation model. Journal of
Machine Learning Research  12:1225–1248  2011.

[18] Y. Sogawa  S. Shimizu  T. Shimamura  A. Hyv¨arinen  T. Washio  and S. Imoto. Estimating exogenous

variables in data with more variables than observations. Neural Networks  2011.

[19] P. Spirtes  C.N. Glymour  and R. Scheines. Causation  prediction  and search. The MIT Press  2000.
[20] K. Zhang and L. Chan. Efﬁcient factor garch models and factor-dcc models. Quantitative Finance 

9(1):71–91  2009.

[21] K. Zhang and L.W. Chan. Extensions of ica for causality discovery in the hong kong stock market.
In Proc. of the 13th international conference on Neural information processing-Volume Part III  pages
400–409. Springer-Verlag  2006.

[22] K. Zhang and A. Hyv¨arinen. On the identiﬁability of the post-nonlinear causal model. In Proceedings of

the Twenty-Fifth Conference on Uncertainty in Artiﬁcial Intelligence  pages 647–655  2009.

[23] K. Zhang and A. Hyv¨arinen. Source separation and higher-order causal analysis of meg and eeg.

In
Proceedings of the Twenty-Sixth Conference on Uncertainty in Artiﬁcial Intelligence  pages 709–716 
2010.

[24] K. Zhang and A. Hyv¨arinen. A general linear non-gaussian state-space model: Identiﬁability  identiﬁca-
tion  and applications. In Proceedings of Asian Conference on Machine Learning  JMLR W&CP  pages
113–128  2011.

9

,Magauiya Zhussip
Shakarim Soltanayev
Se Young Chun