2014,Hamming Ball Auxiliary Sampling for Factorial Hidden Markov Models,We introduce a novel sampling algorithm for Markov chain Monte Carlo-based Bayesian inference for factorial hidden Markov models. This algorithm is based on an auxiliary variable construction that restricts the model space allowing iterative exploration in polynomial time. The sampling approach overcomes limitations with common conditional Gibbs samplers that use asymmetric updates and become easily trapped in local modes. Instead  our method uses symmetric moves that allows joint updating of the latent sequences and improves mixing. We illustrate the application of the approach with simulated and a real data example.,Hamming Ball Auxiliary Sampling for Factorial

Hidden Markov Models

Michalis K. Titsias

Department of Informatics

Athens University of Economics and Business

mtitsias@aueb.gr

Christopher Yau

Wellcome Trust Centre for Human Genetics

University of Oxford

cyau@well.ox.ac.uk

Abstract

We introduce a novel sampling algorithm for Markov chain Monte Carlo-based
Bayesian inference for factorial hidden Markov models. This algorithm is based
on an auxiliary variable construction that restricts the model space allowing it-
erative exploration in polynomial time. The sampling approach overcomes lim-
itations with common conditional Gibbs samplers that use asymmetric updates
and become easily trapped in local modes. Instead  our method uses symmetric
moves that allows joint updating of the latent sequences and improves mixing. We
illustrate the application of the approach with simulated and a real data example.

1

Introduction

The hidden Markov model (HMM) [1] is one of the most widely and successfully applied statistical
models for the description of discrete time series data. Much of its success lies in the availability of
efﬁcient computational algorithms that allows the calculation of key quantities necessary for statis-
tical inference [1  2]. Importantly  the complexity of these algorithms is linear in the length of the
sequence and quadratic in the number of states which allows HMMs to be used in applications that
involve long data sequences and reasonably large state spaces with modern computational hardware.
In particular  the HMM has seen considerable use in areas such as bioinformatics and computational
biology where non-trivially sized datasets are commonplace [3  4  5].
The factorial hidden Markov model (FHMM) [6] is an extension of the HMM where multiple in-
dependent hidden chains run in parallel and cooperatively generate the observed data. In a typical
setting  we have an observed sequence Y = (y1  . . .   yN ) of length N which is generated through
K binary hidden sequences represented by a K × N binary matrix X = (x1  . . .   xN ). The inter-
pretation of the latter binary matrix is that each row encodes for the presence or absence of a single
feature across the observed sequence while each column xi represents the different features that are
active when generating the observation yi. Different rows of X correspond to independent Markov
chains following

p(xk i|xk i−1) =

xk i = xk i−1 
xk i (cid:54)= xk i−1 

(1)

(cid:26)1 − ρk 

ρk 

and where the initial state xk 1 is drawn from a Bernoulli distribution with parameter νk. All hidden
chains are parametrized by 2K parameters denoted by the vectors ρ = {ρk}K
k=1.
Furthermore  each data point yi is generated conditional on xi through a likelihood model p(yi|xi)
parametrized by φ. The whole set of model parameters consists of the vector θ = (φ  ρ  v) which
determines the joint probability density over (Y  X)  although for notational simplicity we omit
reference to it in our expressions. The joint probability density over (Y  X) is written in the form

k=1 and v = {vk}K

p(Y  X) = p(Y |X)p(X) =

p(yi|xi)

p(xk 1)

p(xk i|xk i−1)

 

(2)

(cid:32) N(cid:89)

(cid:33)(cid:32) K(cid:89)

N(cid:89)

i=1

k=1

i=2

1

(cid:33)

x1 i−1

x2 i−1

x3 i−1

yi−1

x1 i

x2 i

x3 i

yi

x1 i+1

x2 i+1

x3 i+1

yi+1

Figure 1: Graphical model for a factorial HMM with three hidden chains and three consecutive data points.

and it is depicted as a directed graphical model in Figure 1.
While the HMM has enjoyed widespread application  the utility of the FHMM has been relatively
less abundant. One considerable challenge in the adoption of FHMMs concerns the computation of
the posterior distribution p(X|Y ) (conditional on observed data and model parameters) which com-
prises a fully dependent distribution in the space of the 2KN possible conﬁgurations of the binary
matrix X. Exact Monte Carlo inference can be achieved by applying the standard forward-ﬁltering-
backward-sampling (FF-BS) algorithm to simulate a sample from p(X|Y ) in O(22KN ) time (the
independence of the Markov chains can be exploited to reduce this complexity to O(2K+1KN ) [6]).
Joint updating of X is highly desirable in time series analysis since alternative strategies involving
conditional single-site  single-row or block updates can be notoriously slow due to strong coupling
between successive time steps. However  although the use of FF-BS is quite feasible for even very
large HMMs  it is only practical for small values of K and N in FHMMs. As a consequence  infer-
ence in FHMMs has become somewhat synonymous with approximate methods such as variational
inference [6  7].
The main burden of the FF-BS algorithm is the requirement to sum over all possible conﬁgurations of
the binary matrix X during the forward ﬁltering phase. The central idea in this work is to avoid this
computationally expensive step by applying a restricted sampling procedure with polynomial time
complexity that  when applied iteratively  gives exact samples from the true posterior distribution.
Whilst regular conditional sampling procedures use locally asymmetric moves that only allow one
part of X to be altered at a time  our sampling method employs locally symmetric moves that allow
localized joint updating of all the constituent chains making it less prone to becoming trapped in
local modes. The sampling strategy adopts the use of an auxiliary variable construction  similar
to slice sampling [8] and the Swendsen-Wang algorithm [9]  that allows the automatic selection of
the sequence of restricted conﬁguration spaces. The size of these restricted conﬁguration spaces
is user-deﬁned allowing control over balance between the sampling efﬁciency and computational
complexity. Our sampler generalizes the standard FF-BS algorithm which is a special case.

2 Standard Monte Carlo inference for the FHMM

Before discussing the details of our new sampler  we ﬁrst describe the limitations of standard con-
ditional sampling procedures for the FHMM. The most sophisticated conditional sampling schemes
are based on alternating between sampling one chain (or a small block of chains) at a time using the
FF-BS recursion. However  as discussed in the following and illustrated experimentally in Section
4  these algorithms can easily become trapped in local modes leading to inefﬁcient exploration of
the posterior distribution.
One standard Gibbs sampling algorithm for the FHMM is based on simulating from the posterior
conditional distribution over a single row of X given the remaining rows. Each such step can be
carried out in O(4N ) time using the FF-BS recursion  while a full sweep over all K rows requires
O(4KN ) time. A straightforward generalization of the above is to apply a block Gibbs sampling
where at each step a small subset of chains is jointly sampled. For instance  when we consider pairs
of chains the time complexity for sampling a pair is O(16N ) while a full sweep over all possible
pairs requires time O(16 K(K−1)

2 N ).

2

(cid:32)..

..
..

0
1
0
0
1
0
X (t)

(cid:33)

..
..
..

(cid:32)..

..
..

(cid:59)

(a)

0 1
0 1
0 0
X (t+1)

..
..
..

(cid:33) (cid:32)..

..
..

(cid:33)

..
..
..

(cid:32)..

..
..

⇒

0
1
0
0
1
0
X (t)

(cid:33)

..
..
..

⇒

0
1
0

1
0
0
U
(b)

(cid:32).. 0

..
..

1
1
0

0
0
X (t+1)

(cid:33)

..
..
..

Figure 2: Panel (a) shows an example where from a current state X (t) it is impossible to jump to a new state
X (t+1) in a single step using block Gibbs sampling on pairs of rows. In contrast  Hamming ball sampling ap-
plied with the smallest valid radius  i.e. m = 1  can accomplish such move through the intermediate simulation
of U as illustrated in (b). Speciﬁcally  simulating U from the uniform p(U|X) results in a state having one bit
ﬂipped per column compared to X (t). Then sampling X (t+1) given U ﬂips further two bits so in total X (t+1)
differs by X (t) in four bits that exist in three different rows and two columns.

While these schemes can propose large changes to X and be efﬁciently implemented using forward-
backward recursions  they can still easily get trapped to local modes of the posterior distribution. For
instance  suppose we sample pairs of rows and we encounter a situation where  in order to escape
from a local mode  four bits in two different columns (two bits from each column) must be jointly
ﬂipped. Given that these four bits belong to more than two rows  the above Gibbs sampler will fail to
move out from the local mode no matter which row-pair  from the K(K−1)
possible ones  is jointly
simulated. An illustrative example of this phenomenon is given in Figure 2(a).
We could describe the conditional sampling updates of block Gibbs samplers as being locally asym-
metric  in the sense that  in each step  one part of X is restricted to remain unchanged while the
other part is free to change. As the above example indicates  these locally asymmetric updates can
cause the chain to become trapped in local modes which can result in slow mixing. This can be
particularly problematic in FHMMs where the observations are jointly dependent on the underlying
hidden states which induces a coupling between rows of X. Of course  locality in any possible
MCMC scheme for FHMMs seems unavoidable  certainly however  such a locality does not need
to be asymmetric. In the next section  we develop a symmetrically local sampling approach so that
each step gives a chance to any element of X to be ﬂipped in any single update.

2

3 Hamming ball auxiliary sampling

Here we develop the theory of the Hamming ball sampler. Section 3.1 presents the main idea while
Section 3.2 discusses several extensions.

3.1 The basic Hamming ball algorithm

Recall the K-dimensional binary vector xi (the i-th column of X) that deﬁnes the hidden state at
i-th location. We consider the set of all K-dimensional binary vectors ui that lie within a certain
Hamming distance from xi so that each ui is such that

where m ≤ K. Here  h(ui  xi) = (cid:80)K

h(ui  xi) ≤ m.
(3)
k=1 I(uk i (cid:54)= xk i) is the Hamming distance between two
binary vectors and I(·) denotes the indicator function. Notice that the Hamming distance is simply
the number of elements the two binary vectors disagree. We refer to the set of all uis satisfying (3)
as the i-th location Hamming ball of radius m. For instance  when m = 1  the above set includes
all ui vectors restricted to be the same as xi but with at most one bit ﬂipped  when m = 2 these
vectors can have at most two bits ﬂipped and so on. For a given m  the cardinality of the i-th location
Hamming ball is

M =

.

(4)

(cid:18)K

(cid:19)

m(cid:88)

j

j=0

For m = 1 this number is equal to K + 1  for m = 2 is equal to K(K−1)
+ K + 1 and so on.
Clearly  when m = K there is no restriction on the values of ui and the above number takes its
maximum value  i.e. M = 2K. Subsequently  given a certain X we deﬁne the full path Hamming

2

3

N(cid:89)

ball or simply Hamming ball as the set

Bm(X) = {U ; h(ui  xi) ≤ m  i = 1  . . .   N} 

(5)
where U is a K × N binary matrix such that U = (u1  . . .   uN ). This Hamming ball  centered at X 
is simply the intersection of all i-th location Hamming balls of radius m. Clearly  the Hamming ball
set is such that U ∈ Bm(X) iff X ∈ Bm(U )  or more concisely we can write I(U ∈ Bm(X)) =
I(X ∈ Bm(U )). Furthermore  the indicator function I(U ∈ Bm(X)) factorizes as follows 

I(U ∈ Bm(X)) =

I(h(ui  xi) ≤ m).

(6)
We wish now to consider U as an auxiliary variable generated given X uniformly inside Bm(X) 
i.e. we deﬁne the conditional distribution

i=1

p(U|X) =

1

Z I(U ∈ Bm(X)) 

(7)
where crucially the normalizing constant Z simply reﬂects the volume of the ball and is independent
from X. We can augment the initial joint model density from Eq. (2) with the auxiliary variables U
and express the augmented model

p(Y  X  U ) = p(Y |X)p(X)p(U|X).

(8)
Based on this  we can apply Gibbs sampling in the augmented space and iteratively sample U from
the posterior conditional  which is just p(U|X)  and then sample X given the remaining variables.
Sampling p(U|X) is trivial as it requires to independently draw each ui  with i = 1  . . .   N  from the
uniform distribution proportional to I(h(ui  xi) ≤ m)  i.e. randomly select a ui within Hamming
distance at most m from xi. Then  sampling X is carried out by simulating from the following
posterior conditional distribution

(cid:33)

(cid:32) N(cid:89)

p(X|Y  U ) ∝ p(Y |X)p(X)p(U|X) ∝

p(yi|xi)I(h(xi  ui) ≤ m)

p(X) 

(9)

i=1

where we used Eq. (6). Exact sampling from this distribution can be done using the FF-BS algorithm
in O(M 2N ) time where M is the size of each location-speciﬁc Hamming ball given in (4).
The intuition behind the above algorithm is the following. Sampling p(U|X) given the current state
X can be thought of as an exploration step where X is randomly perturbed to produce an auxiliary
matrix U. We can imagine this as moving the Hamming ball that initially is centered at X to a new
location centered at U. Subsequently  we take a slice of the model by considering only the binary
matrices that exist inside this new Hamming ball  centered at U  and draw an new state for X by
performing exact sampling in this sliced part of the model. Exact sampling is possible using the
FF-BS recursion and it has an user-controllable time complexity that depends on the volume of the
Hamming ball. An illustrative example of how the algorithm operates is given in Figure 2(b).
To be ergodic the above sampling scheme (under standard conditions) the auxiliary variable U must
be allowed to move away from the current X (t) (the value of X at the t-th iteration) which implies
that the radius m must be strictly larger than zero. Furthermore  the maximum distance a new X (t+1)
can travel away from the current X (t) in a single iteration is 2mN bits (assuming m ≤ K/2). This
is because resampling a U given the current X (t) can select a U that differs at most mN bits from
X (t)  while subsequently sampling X (t+1) given U further adds at most other mN bits.

3.2 Extensions

So far we have deﬁned Hamming ball sampling assuming binary factor chains in the FHMM. It is
possible to generalize the whole approach to deal with factor chains that can take values in general
ﬁnite discrete state spaces. Suppose that each hidden variable takes P values so that the matrix
X ∈ {1  . . .   P}K×N . Exactly as in the binary case  the Hamming distance between the auxiliary
vector ui ∈ {1  . . .   P}K and the corresponding i-th column xi of X is the number of elements
these two vectors disagree. Based on this we can deﬁne the i-th location Hamming ball of radius m
as the set of all uis satisfying Eq. (3) which has cardinality

M =

(P − 1)j

.

(10)

(cid:18)K

(cid:19)

j

m(cid:88)

j=0

4

2

This  for m = 1 is equal (P − 1)K + 1  for m = 2 it is equal to (P − 1)2 K(K−1)
+ (P − 1)K + 1
and so forth. Notice that for the binary case  where P = 2  all these expressions reduce to the ones
from Section 3.1. Then  the sampling scheme from the previous section can be applied unchanged
where in one step we sample U given the current X and in the second step we sample X given U
using the FF-BS recursion.
Another direction of extending the method is to vary the structure of the uniform distribution p(U|X)
which essentially determines the exploration area around the current value of X. We can even add
randomness in the structure of this distribution by further expanding the joint density in Eq. (8) with
random variables that determine this structure. For instance  we can consider a distribution p(m)
over the radius m that covers a range of possible values and then sample iteratively (U  m) from
p(U|X  m)p(m) and X from p(X|Y  U  m) ∝ p(Y |X)p(X)p(U|X  m). This scheme remains
valid since essentially it is Gibbs sampling in an augmented probability model where we added
the auxiliary variables (U  m). In practical implementation  such a scheme would place high prior
probability on small values of m where sampling iterations would be fast to compute and enable
efﬁcient exploration of local structure but  with non-zero probabilities on larger values on m  the
sampler could still periodically consider larger portions of the model space that would allow more
signiﬁcant changes to the conﬁguration of X.
More generally  we can determine the structure of p(U|X) through a set of radius constraints m =
(m1  . . .   mQ) and base our sampling on the augmented density

p(Y  X  U  m) = p(Y |X)p(X)p(U|X  m)p(m).

(11)

For instance  we can choose m = (m1  . . .   mN ) and consider mi as determining the radius of the
i-location Hamming ball (for the column xi) so that the corresponding uniform distribution over
ui becomes p(ui|xi  mi) ∝ I(h(ui  xi) ≤ mi). This could allow for asymmetric local moves
where in some part of the hidden sequence (where mis are large) we allow for greater exploration
compared to others where the exploration can be more constrained. This could lead to more efﬁcient
variations of the Hamming Ball sampler where the vector m could be automatically tuned during
sampling to focus computational effort in regions of the sequence where there is most uncertainty in
the underlying latent structure of X.
In a different direction  we could introduce the constraints m = (m1  . . .   mK) associated with the
rows of X instead of the columns. This can lead to obtain regular Gibbs sampling as a special case.
In particular  if p(m) is chosen so that in a random draw we pick a single k such that mk = N
and the rest mk(cid:48) = 0  then we essentially freeze all rows of X apart from the k-th row1 and thus
allowing the subsequent step of sampling X to reduce to exact sampling the k-th row of X using
the FF-BS recursion. Under this perspective  block Gibbs sampling for FHMMs can be seen as a
special case of Hamming ball sampling.
Finally  there maybe utility in developing other proposals for sampling U based on distributions
other than the uniform approach used here. For example  a local exponentially weighted proposal
i=1 exp(−λh(ui  xi))I(h(ui  xi) ≤ m)  would keep the centre of the
proposed Hamming ball closer to its current location enabling more efﬁcient exploration of local
conﬁgurations. However  in developing alternative proposals  it is crucial that the normalizing con-
stant of p(U|X) is computed efﬁciently so that the overall time complexity remains O(M 2N ).

of the form p(U|X) ∝ (cid:81)N

4 Experiments

To demonstrate Hamming ball (HB) sampling we consider an additive FHMM as the one used in
[6] and popularized recently for energy disaggregation applications [7  10  11]. In this model  each
k-th factor chain interacts with the data through an associated mean vector wk ∈ RD so that each
observed output yi is taken to be a noisy version of the sum of all factor vectors activated at time i:

K(cid:88)

yi = w0 +

wkxk i + ηi 

(12)

1In particular  for the rows k(cid:48) (cid:54)= k the corresponding uniform distribution over uk(cid:48) is collapses to a point

delta mass centred at the previous states xk(cid:48) is.

k=1

5

where w0 is an extra bias term while ηi is white noise that typically follows a Gaussian: ηi ∼
N (0  σ2I). Using this model we demonstrate the proposed method using an artiﬁcial dataset in
Section 4.1 and a real dataset [11] in energy disaggregation in Section 4.2. In all examples  we
compare HB with block Gibbs (BG) sampling.

4.1 Simulated dataset
Here  we wish to investigate the ability of HB and BG sampling schemes to efﬁcient escape from
local modes of the posterior distribution. We consider an artiﬁcial data sequence of length N = 200
generated as follows. We simulated K = 5 factor chains (with vk = 0.5   ρk = 0.05  k = 1  . . .   5)
which subsequently generated observations in the 25-dimensional space according to the additive
FHMM from Eq. (12) assuming Gaussian noise with variance σ2 = 0.05. The associated factor
vector where selected to be wk = wk ∗ Maskk where wk = 0.8 + 0.05 ∗ (k − 1)  k = 1  . . .   5 and
Maskk denotes a 25-dimensional binary vector or a mask. All binary masks are displayed as 5 × 5
binary images in Figure 1(a) in the supplementary ﬁle together with few examples of generated data
points. Finally  the bias term w0 was set to zero.
We assume that the ground-truth model parameters θ = ({vk  ρk  wk }K
k=1  w0  σ2) that gen-
erated the data are known and our objective is to do posterior inference over the latent factors
X ∈ {0  1}5×200  i.e. to draw samples from the conditional posterior distribution p(X|Y  θ). Since
the data have been produced with small noise variance  this exact posterior is highly picked with
most all the probability mass concentrated on the single conﬁguration Xtrue that generated the data.
So the question is whether BG and HB schemes will able to discover the “unknown” Xtrue from
a random initialization. We tested three block Gibbs sampling schemes: BG1  BG2 and BG3 that
jointly sample blocks of rows of size one  two or three respectively. For each algorithm a full it-
eration is chosen to be a complete pass over all possible combinations of rows so that the time
complexity per iteration for BG1 is O(20N )  for BG2 is O(160N ) and for BG3 is O(640N ). Re-
garding HB sampling we considered three schemes: HB1  HB2 and HB3 with radius m = 1  2
and 3 respectively. The time complexities for these HB algorithms were O(36N )  O(256N ) and
O(676N ). Notice that an exact sample from the posterior distribution can be drawn in O(1024N )
time.
We run all algorithms assuming the same random initialization X (0) so that each bit was chosen
from the uniform distribution. Figure 3(a) shows the evolution of the error of misclassiﬁed bits in
X  i.e. the number of bits the state X (t) disagrees with the ground-truth Xtrue. Clearly  HB2 and
HB3 discover quickly the optimal solution with HB3 being slightly faster. HB1 is unable to discover
the ground-truth but it outperforms BG1 and BG2. All the block Gibbs sampling schemes  including
the most expensive BG3 one  failed to reach Xtrue.

(a)

(b)

(c)

Figure 3: The panel in (a) shows the sampling evolution of the Hamming distance between Xtrue and X (t) for
the three block Gibbs samplers (dashed lines) and the HB schemes (solid lines). The panel in (b) shows the
evolution of the MSE during the MCMC training phase for the REDD dataset. The two Gibbs samplers are
shown with dashed lines while the two HB algorithms with solid lines. Similarly to (b)  the plot in (c) displays
the evolution of MSEs for the prediction phase in the REDD example where we only simulate the factors X.

4.2 Energy disaggregation

Here  we consider a real-world example from the ﬁeld of energy disaggregation where the objective
is to determine the component devices from an aggregated electricity signal. This technology is use-

6

050100150200050100150200250300350Number of errors in XSampling iterations BG1BG2BG3HB1HB2HB3020040060080010000500100015002000250030003500Train MSESampling iterations BG1BG2HB1HB20501001502001000120014001600Test MSESampling iterations BG1BG2HB1HB2ful because having a decomposition  into components for each device  of the total electricity usage
in a household or building can be very informative to consumers and increase awareness of energy
consumption which subsequently can lead to possibly energy savings. For full details regarding the
energy disaggregation application see [7  10  11]. Next we consider a publicly available data set2 
called the Reference Energy Disaggregation Data Set (REDD) [11]  to test the HB and BG sampling
algorithms. The REDD data set contains several types of home electricity data for many different
houses recorded during several weeks. Next  we will consider the main signal power of house_1
for seven days which is a temporal signal of length 604  800 since power was recorded every second.
We further downsampled this signal to every 9 seconds to obtain a sequence of 67  200 size in which
we applied the FHMM described below.
Energy disaggregation can be naturally tackled by an additive FHMM framework  as realized in
[10  11]  where an observed total electricity power yi at time instant i is the sum of individual
powers for all devices that are “on” at that time. Therefore  the observation model from Eq. (12)
can be used to model this situation with the constraint that each device contribution wk (which is
a scalar) is restricted to be non-negative. We assume an FHMM with K = 10 factors and we
follow a Bayesian framework where each wk is parametrized by the exponential transformation  i.e.

wk = e(cid:101)wk  and a vague zero-mean Gaussian prior is assigned on (cid:101)wk. To learn these factors we apply
i) sampling X  ii) sampling each (cid:101)wk individually using its own Gaussian proposal distribution and

unsupervised learning using as training data the ﬁrst day of recorded data. This involves applying an
Metropolis-within-Gibbs type of MCMC algorithm that iterates between the following three steps:

accepting or rejecting based on the M-H step and iii) sampling the noise variance σ2 based on its
conjugate Gamma posterior distribution. Notice that the step ii) involves adapting the variance of
the Gaussian proposal to achieve an acceptance ratio between 20 and 40 percent following standard
ideas from adaptive MCMC. For the ﬁrst step we consider one of the following four algorithms:
BG1  BG2  HB1 and HB2 deﬁned in the previous section. Once the FHMM has been trained then
we would like to do predictions and infer the posterior distribution over the hidden factors for a test
sequence  that will consist of the remaining six days  according to

(cid:90)

T(cid:88)

t=1

p(X∗|Y∗  Y ) =

p(X∗|Y∗  W  σ2)p(W  σ2|Y )dW dσ2 ≈ 1
T

p(X∗|Y∗  W (t)  (σ2)(t)) 

(13)

where Y∗ denotes the test observations and X∗ the corresponding hidden sequence we wish to in-
fer3. This computation requires to be able to simulate from p(X∗|Y∗  W  σ2) for a given ﬁxed setting
for the parameters (W  σ2). Such prediction step will tell us which factors are “on” at each time.
Such factors could directly correspond to devices in the household  such as Electronics  Lighting 
Refrigerator etc  however since our learning approach is purely unsupervised we will not attempt to
establish correspondences between the inferred factors and the household appliances and  instead 
we will focus on comparing the ability of the sampling algorithms to escape from local modes of
the posterior distribution. To quantify such ability we will consider the mean squared error (MSE)
between the model mean predictions and the actual data. Clearly  MSE for the test data can measure
how well the model predicts the unseen electricity powers  while MSE at the training phase can indi-
cate how well the chain mixes and reaches areas with high probability mass (where training data are
reconstructed with small error). Figure 3(b) shows the evolution of MSE through the sampling iter-
ations for the four MCMC algorithms used for training. Figure 3(c) shows the corresponding curves
for the prediction phase  i.e. when sampling from p(X∗|Y∗  W  σ2) given a representative sample
from the posterior p(W  σ2|Y ). All four MSE curves in Figure 3(c) are produced by assuming the
same setting for (W  σ2) so that any difference observed between the algorithms depends solely on
the ability to sample from p(X∗|Y∗  W  σ2). Finally  Figure 4 shows illustrative plots on how we ﬁt
the data for all seven days (ﬁrst row) and how we predict the test data on the second day (second
row) together with corresponding inferred factors for the six most dominant hidden states (having
the largest inferred wk values). The plots in Figure 4 were produced based on the HB2 output.
Some conclusions we can draw are the following. Firstly  Figure 3(c) clearly indicate that both HB
algorithms for the prediction phase  where the factor weights wk are ﬁxed and given  are much better
than block Gibbs samplers in escaping from local modes and discovering hidden state conﬁgurations

2Available from http://redd.csail.mit.edu/.
3Notice that we have also assumed that the training and test sequences are conditionally independent given

the model parameters (W  σ2).

7

that explain more efﬁciently the data. Moreover  HB2 is clearly better than HB1  as expected  since
it considers larger global moves. When we are jointly sampling weights wk and their interacting
latent binary states (as done in the training MCMC phase)  then  as Figure 3(b) shows  block Gibbs
samplers can move faster towards ﬁtting the data and exploring local modes while HB schemes are
slower in terms of that. Nevertheless  the HB2 algorithm eventually reaches an area with smaller
MSE error than the block Gibbs samplers.

Figure 4: First row shows the data for all seven days together with the model predictions (the blue solid line
corresponds to the training part and the red line to the test part). Second row zooms in the predictions for the
second day  while the third row shows the corresponding activations of the six most dominant factors (displayed
with different colors). All these results are based on the HB2 output.

5 Discussion

factored as p(X  Y ) ∝ p(X)(cid:81)N

Exact sampling using FF-BS over the entire model space for the FHMM is intractable. Alternative
solutions based on conditional updating approaches that use locally asymmetric moves will lead to
poor mixing due to the sampler becoming trapped in local modes. We have shown that the Hamming
ball sampler gives a relative improvement over conditional approaches through the use of locally
symmetric moves that permits joint updating of hidden chains and improves mixing.
Whilst we have presented the Hamming ball sampler applied to the factorial hidden Markov model 
it is applicable to any statistical model where the observed data vector yi depends only on the i-th
column of a binary latent variable matrix X and observed data Y and hence the joint density can be
i=1 p(yi|xi). Examples include the spike and slab variable selection
models in Bayesian linear regression [12] and multiple membership models including Bayesian
nonparametric models that utilize the Indian buffet process [13  14]. While  in standard versions of
these models  the columns of X are independent and posterior inference is trivially parallelizable 
the utility of the Hamming ball sampler arises where K is large and sampling individual columns of
X is itself computationally very demanding. Other suitable models that might be applicable include
more complex dependence structures that involve coupling between Markov chains and undirected
dependencies.

Acknowledgments

We thank the reviewers for insightful comments. MKT greatly acknowledges support from “Re-
search Funding at AUEB for Excellence and Extroversion  Action 1: 2012-2014”. CY acknowl-
edges the support of a UK Medical Research Council New Investigator Research Grant (Ref No.
MR/L001411/1). CY is also afﬁliated with the Department of Statistics  University of Oxford.

8

Day 1Day 2Day 3Day 4Day 5Day 6Day 70200040000500100015002000Day 20500100015002000References
[1] Lawrence Rabiner. A tutorial on hidden Markov models and selected applications in speech

recognition. Proceedings of the IEEE  77(2):257–286  1989.

[2] Steven L Scott. Bayesian methods for hidden Markov models. Journal of the American Statis-

tical Association  97(457)  2002.

[3] Na Li and Matthew Stephens. Modeling linkage disequilibrium and identifying recombination

hotspots using single-nucleotide polymorphism data. Genetics  165(4):2213–2233  2003.

[4] Jonathan Marchini and Bryan Howie. Genotype imputation for genome-wide association stud-

ies. Nature Reviews Genetics  11(7):499–511  2010.

[5] Christopher Yau. OncoSNP-SEQ: a statistical approach for the identiﬁcation of somatic copy
number alterations from next-generation sequencing of cancer genomes. Bioinformatics  29
(19):2482–2484  2013.

[6] Zoubin Ghahramani and Michael I. Jordan. Factorial hidden Markov models. Mach. Learn. 

29(2-3):245–273  November 1997.

[7] J Zico Kolter and Tommi Jaakkola. Approximate inference in additive factorial HMMs with
In International Conference on Artiﬁcial Intelligence

application to energy disaggregation.
and Statistics  pages 1472–1482  2012.

[8] Radford M Neal. Slice sampling. Annals of Statistics  pages 705–741  2003.
[9] Robert H Swendsen and Jian-Sheng Wang. Nonuniversal critical dynamics in Monte Carlo

simulations. Physical review letters  58(2):86–88  1987.

[10] Hyungsul Kim  Manish Marwah  Martin F. Arlitt  Geoff Lyon  and Jiawei Han. Unsuper-
vised disaggregation of low frequency power measurements. In SDM  pages 747–758. SIAM /
Omnipress  2011.

[11] J. Zico Kolter and Matthew J. Johnson. REDD: a public data set for energy disaggregation

research. In SustKDD Workshop on Data Mining Applications in Sustainability  2011.

[12] Toby J Mitchell and John J Beauchamp. Bayesian variable selection in linear regression. Jour-

nal of the American Statistical Association  83(404):1023–1032  1988.

[13] Thomas L Grifﬁths and Zoubin Ghahramani.

Inﬁnite latent feature models and the Indian

buffet process. In NIPS  volume 18  pages 475–482  2005.

[14] J. Van Gael  Y. W. Teh  and Z. Ghahramani. The inﬁnite factorial hidden Markov model. In

Advances in Neural Information Processing Systems  volume 21  2009.

9

,Michalis Titsias RC AUEB
Christopher Yau