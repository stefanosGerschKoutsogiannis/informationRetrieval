2010,Large Margin Learning of Upstream Scene Understanding Models,Upstream supervised topic models have been widely used for complicated scene understanding. However  existing maximum likelihood estimation (MLE) schemes can make the prediction model learning independent of latent topic discovery and result in an imbalanced prediction rule for scene classification. This paper presents a joint max-margin and max-likelihood learning method for upstream scene understanding models  in which latent topic discovery and prediction model estimation are closely coupled and well-balanced. The optimization problem is efficiently solved with a variational EM procedure  which iteratively solves an online loss-augmented SVM. We demonstrate the advantages of the large-margin approach on both an 8-category sports dataset and the 67-class MIT indoor scene dataset for scene categorization.,LargeMarginLearningofUpstreamSceneUnderstandingModelsJunZhu†Li-JiaLi‡Fei-FeiLi‡EricP.Xing††{junzhu epxing}@cs.cmu.edu‡{lijiali feifeili}@cs.stanford.edu†SchoolofComputerScience CarnegieMellonUniversity Pittsburgh PA15213‡DepartmentofComputerScience StanfordUniversity Stanford CA94305AbstractUpstreamsupervisedtopicmodelshavebeenwidelyusedforcomplicatedsceneunderstanding.However existingmaximumlikelihoodestimation(MLE)schemescanmakethepredictionmodellearningindependentoflatenttopicdis-coveryandresultinanimbalancedpredictionruleforsceneclassiﬁcation.Thispaperpresentsajointmax-marginandmax-likelihoodlearningmethodforup-streamsceneunderstandingmodels inwhichlatenttopicdiscoveryandpredic-tionmodelestimationarecloselycoupledandwell-balanced.TheoptimizationproblemisefﬁcientlysolvedwithavariationalEMprocedure whichiterativelysolvesanonlineloss-augmentedSVM.Wedemonstratetheadvantagesofthelarge-marginapproachonbothan8-categorysportsdatasetandthe67-classMITindoorscenedatasetforscenecategorization.1IntroductionProbabilistictopicmodelslikethelatentDirichletallocation(LDA)[5]haverecentlybeenappliedtoanumberofcomputervisiontaskssuchasobjectionannotationandsceneclassiﬁcationduetotheirabilitytocapturelatentsemanticcompositionsofnaturalimages[22 23 9 13].Oneoftheadvocatedadvantagesofsuchmodelsisthattheydonotrequire“supervision”duringtraining whichisarguablypreferredoversupervisedlearningthatwouldnecessitateextracost.Butwiththeincreasingavailabilityoffreeon-lineinformationsuchasimagetags userratings etc. variousformsof“side-information”thatcanpotentiallyoffer“free”supervisionhaveledtoaneedfornewmodelsandtrainingschemesthatcanmakeeffectiveuseofsuchinformationtoachievebetterresults suchasmorediscriminativetopicrepresentationsofimagecontents andmoreaccurateimageclassiﬁers.ThestandardunsupervisedLDAignoresthecommonlyavailablesupervisioninformation andthuscandiscoverasub-optimaltopicrepresentationforpredictiontasks.Extensionstosupervisedtopicmodelswhichcanexploresideinformationfordiscoveringpredictivetopicrepresentationshavebeenproposed suchasthesLDA[4 25]andMedLDA[27].Acommoncharacteristicofthesemodelsisthattheyaredownstream thatis thesupervisedresponsevariablesaregeneratedfromtopicassignmentvariables.Anothertypeofsupervisedtopicmodelsaretheso-calledupstreammodels ofwhichtheresponsevariablesdirectlyorindirectlygeneratelatenttopicvariables.Incontrasttodownstreamsupervisedtopicmodels(dSTM) whicharemainlydesignedbymachinelearningresearchers upstreamsupervisedtopicmodels(uSTM)arewell-motivatedfromhumanvisionandpsychologyresearch[18 10]andhavebeenwidelyusedforsceneunderstandingtasks.Forexample intherecentlydevelopedsceneunderstandingmodels[23 13 14 8] complexsceneimagesaremodeledasahierarchyofsemanticconceptswherethemosttoplevelcorrespondstoascene whichcanberepresentedasasetoflatentobjectslikelytobefoundinagivenscene.Tolearnanupstreamscenemodel maximumlikelihoodestimation(MLE)isthemostcommonchoice.However MLEcanmakethepredictionmodelestimationindependentoflatenttopicdiscoveryandresultinanimbalancedpredictionruleforsceneclassiﬁcation asweexplaininSection3.1Inthispaper ourgoalistoaddresstheweaknessofMLEforlearningupstreamsupervisedtopicmodels.Ourapproachisbasedonthemax-marginprincipleforsupervisedlearningwhichhasshowngreatpromiseinmanymachinelearningtasks suchasclassiﬁcation[21]andstructuredout-putprediction[24].ForthedSTM max-margintraininghasbeendevelopedinMedLDA[27] whichhasachievedbetterpredictionperformancethanMLE.Insuchdownstreammodels latenttopicas-signmentsaresufﬁcientstatisticsforthepredictionmodelanditiseasytodeﬁnethemax-marginconstraintsbasedonexistingmax-marginmethods(e.g. SVM).However forupstreamsupervisedtopicmodels thediscriminantfunctionforpredictioninvolvesanintractablecomputationofposte-riordistributions whichmakesthemax-margintrainingmoredelicate.Speciﬁcally wepresentajointmax-marginandmax-likelihoodestimationmethodforlearningup-streamsceneunderstandingmodels.Byusingavariationalapproximationtotheposteriordistri-butionofsupervisedvariables(e.g. scenecategories) ourmax-marginlearningapproachiteratesbetweenposteriorprobabilisticinferenceandmax-marginparameterlearning.Theparameterlearn-ingsolvesanonlineloss-augmentedSVM whichcloselycouplesthepredictionmodelestimationandlatenttopicdiscovery andthiscloseinterplayresultsinawell-balancedpredictionruleforscenecategorization.Finally wedemonstratetheadvantagesofourmax-marginapproachonboththe8-categorysports[13]andthe67-classMITindoorscene[20]datasets.Empiricalresultsshowthatmax-marginlearningcansigniﬁcantlyimprovethesceneclassiﬁcationaccuracy.Thepaperisstructuredasfollows.Sec.2presentsagenericsceneunderstandingmodelwewillworkon.Sec.3discussestheweaknessofMLEinlearningupstreammodels.Sec.4presentsthemax-marginlearningapproach.Sec.5presentsempiricalresultsandSec.6concludes.2JointSceneandObjectModel:aGenericRunningExampleInthissection wepresentagenericjointscenecategorizationandobjectannotationmodel whichwillbeusedtodemonstratethelargemarginlearningofupstreamsceneunderstandingmodels.2.1ImageRepresentationHowshouldwerepresentasceneimage?Friedman[10]pointedoutthatobjectrecognitioniscriticalintherecognitionofascene.Whileindividualobjectscontributetotherecognitionofvisualscenes humanvisionresearchersNavon[18]andBiederman[2]alsoshowedthatpeopleperformrapidglobalsceneanalysisbeforeconductingmoredetailedlocalobjectanalysiswhenrecognizingsceneimages.Toobtainagenericmodel werepresentascenebyusingitsglobalscenefeaturesandobjectswithinit.WeﬁrstsegmentanimageIintoasetoflocalregions{r1 ··· rN}.EachregionisrepresentedbythreeregionfeaturesR(i.e. color locationandtexture)andasetofimagepatchesX.Theseregionfeaturesarerepresentedasvisualcodewords.Todescribedetailedlocalinformationofobjects wepartitioneachregionintopatches.Foreachpatch weextracttheSIFT[16]features whichareinsensitivetoview-pointandilluminationchanges.Tomodeltheglobalscenerepresentation weextractasetofglobalfeaturesG[19].Inourdataset werepresentanimageasatuple(r x g) whererdenotesaninstanceofR andlikewiseforxandg.2.2TheJointSceneandObjectModelThemodelisshowninFig.1(a).Sisthescenerandomvariable takingvaluesfromaﬁnitesetS={s1 ··· sMs}.Foranimage thedistributionoverscenecategoriesdependsonitsglobalrepresentationfeaturesG.EachsceneisrepresentedasamixtureoverlatentobjectsOandthemixingweightsaredeﬁnedwithageneralizedlinearmodel(GLM)parameterizedbyψ.Byusinganormalprioronψ thescenemodelcancapturethemutualcorrelationsbetweendifferentobjects similartothecorrelatedtopicmodels(CTMs)[3].Here weassumethatfordifferentscenes theobjectshavedifferentdistributionsandcorrelations.Letfdenotethevectorofreal-valuedfeaturefunctionsofSandG thegeneratingprocedureofanimageisasfollows:1.Sampleascenecategoryfromaconditionalscenemodel:p(s|g θ)=exp(θ⊤f(g s)∑s′exp(θ⊤f(g s′)).2.Sampletheparametersψ|s µ Σ∼N(µs Σs).3.Foreachregionn(a)sampleanobjectfrom:p(on=k|ψ)=exp(ψk)∑jexp(ψj).(b)sampleMr(i.e. 3:color locationandtexture)regionfeatures:rnm|on β∼Multi(βmon).(c)sampleMximagepatchesxnm|on η∼Multi(ηon).2DRNXGMrMxOSMs(a)1234567802468x 10−3Log−likelihood RatioMLE1234567802468x 10−3Max−Margin(b)120.30.350.40.450.50.550.60.650.70.750.8Scene Classification AccuracyMax−MarginMLE(c)Figure1:(a)ajointscenecategorizationandobjectannotationmodelwithglobalfeaturesG;(b)averagelog-likelihoodratiologp(s|g θ)/L−θunderMLEandmax-marginestimations wheretheﬁrstbarisfortruecategoriesandtherestareforcategoriessortedbasedontheirdifferencefromtheﬁrstone;(c)sceneclassiﬁca-tionaccuracybyusing(Blue)L−θ (Green)logp(s|g θ) and(Red)L−θ+logp(s|g θ)forprediction.Group1isforMLEandgroup2isformax-margintraining.Thegenerativemodeldeﬁnesajointdistributionp(s ψ o r x|g Θ)=p(s|θ g)p(ψ|µs Σs)N∏n=1(p(on|ψ)Mr∏m=1p(rnm|on β)Mx∏m=1p(xnm|on η)) wherewehaveusedΘtodenotealltheunknownparameters(θ µ Σ β η).Fromthejointdistribu-tion wecanmaketwotypesofpredictions namelysceneclassiﬁcationandobjectannotation.Forsceneclassiﬁcation weinferthemaximumaposterioripredictionˆs argmaxsp(s|g r x)=argmaxslogp(s r x|g).(1)Forobjectannotation wecanusetheinferredlatentrepresentationofregionsbasedonp(o|g r x)andbuildaclassiﬁertocategorizeregionsintoobjectclasses whensometrainingexampleswithmanuallyannotatedobjectsareprovided.Sincecollectingfullylabeledimageswithannotatedob-jectsisdifﬁcult upstreamscenemodelsareusuallylearnedwithpartiallylabeledimagesforscenecategorization whereonlyscenecategoriesareprovidedandobjectsaretreatedaslatenttopicsorthemes[9].Inthispaper wefocusonsceneclassiﬁcation.Someempiricalresultsonobjectannotationwillbereportedwhenlabeledobjectsareavailable.Weusethisjointmodelasarunningexampletodemonstratethebasicprincipeofperformingmax-marginlearningforthewidelyappliedupstreamsceneunderstandingmodelsbecauseitiswell-motivated verygenericandcoversmanyotherexistingsceneunderstandingmodels.Forexample ifwedonotincorporatetheglobalscenerepresentationG thejointmodelwillbereducedtoamodelsimilaras[14 6 23].Moreover thegenericjointmodelprovidesagoodframeworkforstudyingtherelativecontributionsoflocalobjectmodelingandglobalscenerepresentation whichhasbeenshowntobeusefulforsceneclassiﬁcation[20]andobjectdetection[17]tasks.3WeakCouplingofMLEinLearningUpstreamSceneModelsTolearnanupstreamscenemodel themostcommonlyusedmethodisthemaximumlikelihoodestimation(MLE) suchasin[23 6 14].Inthissection wediscusstheweaknessofMLEforlearningupstreamscenemodelsandmotivatethemax-marginapproach.LetD={(Id sd)}Dd=1denoteasetofpartiallylabeledtrainingimages.ThestandardMLEobtainstheoptimummodelparametersbymaximizingthelog-likelihood1∑Dd=1logp(sd rd xd|gd Θ).Byusingthefactorizationofp(s ψ o r x|g Θ) MLEsolvesthefollowingequivalentproblemmaxθ Θ−θ∑d(logp(sd|gd θ)+Lsd −θ) (2)whereLsd −θ log∫ψ∑op(ψ o rd xd|sd Θ)=logp(rd xd|sd Θ)isthelog-likelihoodofim-agefeaturesgiventhesceneclass andΘ−θdenotesalltheparametersexceptθ.SinceLs −θdoesnotdependonθ theMLEestimationoftheconditionalscenemodelistosolvemaxθ∑dlogp(sd|gd θ) (3)whichdoesnotdependonthelatentobjectmodel.Thisisinconsistentwiththepredictionrule(1)whichdoesdependonboththeconditionalscenemodel(i.e. p(s|g θ))andthelocalobjectmodel.1Theconditionallikelihoodestimationcanavoidthisproblemtosomeextend butithasnotbeenstudied tothebestofourknowledge.3Thisdecouplingwillresultinanimbalancedcombinationbetweentheconditionalsceneandobjectmodelsforprediction asweexplainbelow.WeﬁrstpresentsomedetailsoftheMLEmethod.Forθ theproblem(3)isanMLEestimationofaGLM anditcanbeefﬁcientlysolvedwithgradientdescentmethods suchasquasi-Newtonmethods[15].ForΘ−θ sincethelikelihoodLs −θisintractabletocompute weapplyvariationalmethodstoobtainanapproximation.Byintroducingavariationaldistributionqs(ψ o)toapproximatetheposteriorp(ψ o|s r x Θ)andusingtheJensen’sinequality wecanderivealowerboundLs −θ≥Eqs[logp(ψ o r x|s Θ)]+H(qs) L−θ(qs Θ) (4)whereH(q)=−Eq[q]istheentropy.Then theintractablepredictionrule(1)canbeapproximatedwiththevariationalpredictionruleˆs argmaxs qs(logp(s|g θ)+L−θ(qs Θ)).(5)Maximizing∑dL−θ(qsd Θ)willleadtoaclosedformsolutionofΘ−θ.SeeAppendixfortheinferenceofqsasinvolvedinthepredictionrule(5)andtheestimationofΘ−θ.Now weexaminetheeffectsoftheconditionalscenemodelp(s|g θ)inmakingapredictionviathepredictionrule(5).Fig.1(b-left)showstherelativeimportanceoflogp(s|g θ)inthejointdecisionrule(5)onthesportsdataset[13].WecanseethatinMLEtheconditionalscenemodelplaysaveryweakroleinmakingapredictionwhenitiscombinedwiththeobjectmodel i.e. L−θ.Therefore asshowninFig.1(c) althoughasimplelogisticregressionwithglobalfeatures(i.e. thegreenbar)canachieveagoodaccuracy theaccuracyofthepredictionrule(5)thatusesthejointlikelihoodbound(i.e theredbar)isdecreasedduetothestrongeffectofthepotentiallybadpredictionrulebasedonL−θ(i.e. thebluebar) whichonlyconsiderslocalimagefeatures.Incontrast asshowninFig.1(b-right) inthemax-marginapproachtobepresented theconditionalscenemodelplaysamuchmoreinﬂuentialroleinmakingapredictionviatherule(5).Thisresultsinabetterbalancedcombinationbetweenthesceneandtheobjectmodels.Thestrongcouplingisduetosolvinganonlineloss-augmentedSVM asweexplainbelow.NotethatwearenotclaiminganyweaknessofMLEingeneral.Allourdiscussionsareconcentratedonlearningupstreamsupervisedtopicmodels asgenericallyrepresentedbythemodelinFig.1.4Max-MarginTrainingNow wepresentthemax-marginmethodforlearningupstreamsceneunderstandingmodels.4.1ProblemDeﬁnitionForthepredictiverule(1) weuseF(s g r x;Θ) logp(s|g r x Θ)todenotethediscriminantfunction whichismorecomplicatedthanthecommonlychosenlinearform inthesensewewillexplainshortly.Inthesamespiritofmax-marginclassiﬁers(e.g. SVMs) wedeﬁnethehingelossofthepredictionrule(1)onDasRhinge(Θ)=1D∑dmaxs[∆ℓd(s)−∆Fd(s;Θ)] where∆ℓd(s)isalossfunction(e.g. 0/1loss) and∆Fd(s;Θ)=F(sd gd rd xd;Θ)−F(s gd rd xd;Θ)isthemarginfavoredbythetruecategorysdoveranyothercategorys.Theproblemwiththeabovedeﬁnitionisthatexactlycomputingtheposteriordistributionp(s|g r x Θ)isintractable.AsinMLE weuseavariationaldistributionqstoapproximateit.ByusingtheBayes’sruleandthevariationalboundinEq.(4) wecanlowerboundthelog-likelihoodlogp(s|g r x Θ)=logp(s r x|g Θ)−logp(r x|g Θ)≥logp(s|g θ)+L−θ(qs Θ)−c (6)wherec=logp(r x|g Θ).Withoutcausingambiguity wewilluseL−θ(qs)withoutΘ.Sinceweneedtomakesomeassumptionsaboutqs theequalityin(6)usuallydoesnothold.Therefore thetightestlowerboundisanapproximationoftheintractablediscriminantfunctionF(s g r x;Θ)≈logp(s|g θ)+maxqsL−θ(qs)−c.(7)Then themarginis∆Fd(s;Θ)=θ⊤∆fd(s)+maxqsdL−θ(qsd)−maxqsL−θ(qs) ofwhichthelineartermisthesameasthatinalinearSVM[7]andthedifferencebetweentwovariationalboundscausesthetopicdiscoverytobiasthelearningofthesceneclassiﬁcationmodel asweshallsee.4UsingthevariationaldiscriminantfunctioninEq.(7)andapplyingtheprincipleofregularizedempiricalriskminimization wedeﬁnethemax-marginlearningofthejointsceneandobjectmodelassolvingminΘΩ(Θ)+λ∑d(−maxqsdL−θ(qsd))+CRhinge(Θ) (8)whereΩ(Θ)isaregularizeroftheparameters.Here wedeﬁneΩ(Θ) 12∥θ∥22.ForthenormalmeanµsorcovariancematrixΣs asimilarℓ2-normorFrobeniusnormcanbeusedwithoutchangingouralgorithm.ThefreeparametersλandCarepositiveandtradeofftheclassiﬁcationlossandthedatalikelihood.Whenλ→∞ theproblem(8)reducestothestandardMLEofthejointscenemodelwithaﬁxeduniformprioronsceneclasses.Moreover wecanseethedifferencefromthestandardMLE(2).Here weminimizeahingeloss whichisdeﬁnedonthejointpredictionrule whileMLEminimizesthelog-likelihoodlosslogp(sd|gd θ) whichdoesnotdependonthelatentobjectmodel.Therefore ourapproachcanbeexpectedtoachieveacloserdependencebetweentheconditionalscenemodelandthelatentobjectmodel.Moreinsightswillbeprovidedinthenextsection.4.2SolvingtheOptimizationProblemTheproblem(8)isgenerallyhardtosolvebecausethemodelparametersandvariationaldistribu-tionsarestronglycoupled.Therefore wedevelopanaturaliterativeprocedurethatestimatestheparametersΘandperformsposteriorinferencealternatively.Theintuitionisthatbyﬁxingonepart(e.g. qs)theotherpart(e.g. Θ)canbeefﬁcientlydone.Speciﬁcally usingthedeﬁnitions werewritetheproblem(8)asamin-maxoptimizationproblemminΘ {qsd}max{s qs}(12∥Θ∥22−(λ+C)∑dL−θ(qsd)+C∑d[−θ⊤∆fd(s)+∆ℓd(s)+L−θ(qs)]) (9)wherethefactor1/DinRhingeisabsorbedintheconstantC.Thismin-maxproblemcanbeapproximatelysolvedwithaniterativeprocedure.First weinfertheoptimalvariationalposterior2q⋆s=argmaxqsL−θ(qs)foreachsandeachtrainingimage.Then wesolveminΘ {qsd}(12∥Θ∥22−(λ+C)∑dL−θ(qsd)+C∑dmaxs[−θ⊤∆fd(s)+∆ℓd(s)+L−θ(q⋆s)]) Forthissub-step again weapplyanalterativeproceduretosolvetheminimizationproblemoverΘandqsd.Weﬁrstinfertheoptimalvariationalposteriorq⋆sd=argmaxqsdL−θ(qsd) andthenweestimatetheparametersbysolvingthefollowingproblemminΘ(12∥Θ∥22−(λ+C)∑dL−θ(q⋆sd)+C∑dmaxs[−θ⊤∆fd(s)+∆ℓd(s)+L−θ(q⋆s)]) (10)Sinceinferringq⋆sdisincludedinthestepofinferringq⋆s(∀s) thealgorithmcanbesummarizedasatwo-stepEM-procedurethatiterativelyperformsposteriorinferenceofqsandmax-marginparameterestimation.Anotherwaytounderstandthisiterativeprocedureisfromthedeﬁnitions.Theﬁrststepofinferringq⋆sistocomputethediscriminantfunctionFunderthecurrentmodel.Then weupdatethemodelparametersΘbysolvingalarge-marginlearningproblem.Forbrevity wepresenttheparameterestimationonly.TheposteriorinferenceisdetailedinAppendixA.1.ParameterEstimation:Thisstepcanbedonewithanalternatingminimizationprocedure.FortheGaussianparameters(µ Σ)andmultinomialparameters(η β) theestimationcanbewritteninaclosed-formasinastandardMLEofCTMs[3]byusingaloss-augmentedpredictionofs.Forbrevity wedeferthedetailstotheAppendixA.2.Now wepresentthestepofestimatingθ whichillustratestheessentialdifferencebetweenthelarge-marginapproachandthestandardMLE.Speciﬁcally theoptimumsolutionofθisobtainedbysolvingthesub-problem3minθ12∥θ∥22+C∑d(maxs[θ⊤f(gd s)+∆ℓd(s)+L−θ(q⋆s)]−[θ⊤f(gd sd)+L−θ(q⋆sd)]) whichisequivalenttoaconstrainedproblembyintroducingasetofnon-negativeslackvariablesξminθ ξ12∥θ∥22+CD∑d=1ξds.t.:θ⊤∆fd(s)+[L−θ(q⋆sd)−L−θ(q⋆s)]≥∆ℓd(s)−ξd ∀d s.(11)2Toretainanaccuratelarge-margincriterionforestimatingmodelparameters(especiallyθ) wedonotperformthemaximizationoversatthisstep.3Theconstant(w.r.t.θ)term−C∑dL−θ(q⋆sd)iskeptforeasyexplanation.Itwon’tchangetheestimation.5TheconstrainedoptimizationproblemissimilartothatofalinearSVM[7].However thedifferenceisthatwehavetheadditionalterm∆L⋆d(s) L−θ(q⋆sd)−L−θ(q⋆s).Thistermindicatesthattheestimationofthesceneclassiﬁcationmodelisinﬂuencedbythetopicdiscoveryprocedure whichﬁndsanoptimumposteriordistributionq⋆.If∆L⋆d(s)<0 s̸=sd whichmeansitisverylikelythatawrongscenesexplainstheimagecontentbetterthanthetruescenesd thentheterm∆L⋆d(s)actsinaroleofaugmentingthelineardecisionboundaryθtomakeacorrectpredictiononthisimagebyusingthepredictionrule(5).If∆L⋆d(s)>0 whichmeansthetruescenecanexplaintheimagecontentbetterthans thenthelineardecisionboundarycanbeslightlyrelaxed.Ifwemovetheadditionaltermtotherighthandside theproblem(11)istolearnalinearSVM butwithanonlineupdatedlossfunction∆ℓd(s)−∆L⋆d(s).WecallthisSVManonlineloss-augmentedSVM.Solvingtheloss-augmentedSVMwillresultinanampliﬁedinﬂuenceofthesceneclassiﬁcationmodelinthejointpredictiverule(5)asshowninFig.1(b).5ExperimentsNow wepresentempiricalevaluationofourapproachonthesports[13]andMITindoorscene[20]datasets.Ourgoalistodemonstratetheadvantagesofthemax-marginmethodovertheMLEforlearningupstreamscenemodelswithorwithoutglobalfeatures.AlthoughthemodelinFig.1canalsobeusedforobjectannotation wereporttheperformanceonscenecategorizationonly whichisourmainfocusinthispaper.Forobjectannotation whichrequiresadditionalhumanannotatedexamplesofobjects somepreliminaryresultsarereportedintheAppendixduetospacelimitation.5.1DatasetsandFeaturesThesportsdatacontain1574diversesceneimagesfrom8categories aslistedinFig.2withexampleimages.Theindoorscenedataset[20]contains15620sceneimagesfrom67categoriesaslistedinTable2.Weusethemethod[1]tosegmenttheseimagesintosmallregionsbasedoncolor bright-nessandtexturehomogeneity.Foreachregion weextractcolor textureandlocationfeatures andquantizetheminto30 50and120codewords respectively.Similarly theSIFTfeaturesextractedfromthesmallpatcheswithineachregionarequantizedinto300SIFTcodewords.Weusethegistfeatures[19]asoneexampleofglobalfeatures.Extensiontoincludeotherglobalfeatures suchasSIFTsparsecodes[26] canbedirectlydonewithoutchangingthemodelorthealgorithm.5.2ModelsFortheupstreamscenemodelasinFig.1 wecomparethemax-marginlearningwiththeMLEmethod andwedenotethescenemodelstrainedwithmax-margintrainingandMLEbyMM-SceneandMLE-Scene respectively.Forbothmethods weevaluatetheeffectivenessofglobalfeatures andwedenotethescenemodelswithoutglobalfeaturesbyMM-Scene-NGandMLE-Scene-NG respectively.Sinceourmaingoalinthispaperistodemonstratetheadvantagesofmax-marginlearninginupstreamsupervisedtopicmodels ratherthandominanceofsuchmodelsoverallothers wejustcomparewithoneexampleofdownstreammodels–themulti-classsLDA(Multi-sLDA)[25].Systematicalcomparisonwithothermethods includingDiscLDA[12]andMedLDA[27] isdeferredtoafullversion.ForthedownstreamMulti-sLDA theimage-wisescenecategoryvariableSisgeneratedfromlatentobjectvariablesOviaasoftmaxfunction.Forthisdownstreammodel theparameterestimationcanbedonewithMLEasdetailedin[25].Finally toshowtheusefulnessoftheobjectmodelinscenecategorization wealsocomparewiththemargin-basedmulti-classSVM[7]andlikelihood-basedlogisticregressionforsceneclassiﬁcationbasedontheglobalfeatures.FortheSVM weusethesoftwareSVMmulticlass4 whichimplementsafastcutting-planealgorithm[11]todoparameterlearning.Weusethesamesoftwarewithslightchangestolearntheloss-augmentedSVMinourmax-marginmethod.5.3SceneCategorizationonthe8-ClassSportsDatasetWepartitionthedatasetequallyintotrainingandtestingdata.ForallthemodelsexceptSVMandlogisticregression werun5timeswithrandominitializationofthetopicparameters(e.g. βandη).4http://svmlight.joachims.org/svmmulticlass.html6badmintonboccecroquetpolobadmintoncroquetboccerockclimbingcroquetpolopolobadmintonrockclimbingrowingsailingsnowboardingrockclimbingsnowboardingrowingsailingsailingrowingsnowboardingbocceFigure2:Exampleimagesfromeachcategoryinthesportsdatasetwithpredictedsceneclasses wherethepredictionsinbluearecorrectwhileredonesarewrongpredictions.1020304050607080901000.250.30.350.40.450.50.550.60.650.70.75# TopicsScene Classification AccuracyMM−SceneMM−Scene−NGMLE−SceneMLE−Scene−NGMulti−sLDAMulti−SVMFigure3:Classiﬁcationaccuracyofdifferentmodelswithrespecttothenumberoftopics.Theaverageoverallaccuracyofscenecategorizationon8categoriesanditsstandarddeviationareshowninFig.3.TheresultoflogisticregressionisshownintheleftgreenbarinFig.1(c).Wealsoshowtheconfusionmatrixofthemax-marginscenemodelwith100latenttopicsinTable1 andexampleimagesfromeachcat-egoryareshowninFig.2withpredictedlabels.Over-all themax-marginscenemodelwithglobalfeaturesachievessigniﬁcantimprovementsascomparedtoallotherapproacheswehavetested.Interestingly al-thoughweprovideonlyscenecategoriesassupervisedinformationduringtraining ourbestperformancewithglobalfeaturesisclosetothatreportedin[13] whereadditionalsupervisionofobjectsisused.Theoutstandingperformanceofthemax-marginmethodforsceneclassiﬁcationcanbeunderstoodfromthefollowingaspects.Max-margintraining:fromthecomparisonofthemax-marginapproachwiththestandardMLEinbothcasesofusingglobalfeaturesandnotusingglobalfeatures wecanseethatthemax-marginlearningcanimprovetheperformancedramatically especiallywhenthescenemodelusesglobalfeatures(about3percent).Thisisduetothewell-balancedpredictionruleachievedbythemax-marginmethod aswehaveexplainedinSection3.Globalfeatures:fromthecomparisonbetweenthescenemodelswithandwithoutglobalfeatures wecanseethatusingthegistfeaturescansigniﬁcantly(about8percent)improvethescenecatego-rizationaccuracyinbothMLEandmax-margintraining.WealsodidsomepreliminaryexperimentsontheSIFTsparsecodesfeature[26] whichareabitmoreexpensivetoextract.Byusingbothgistandsparsecodesfeatures wecanachievedramaticimprovementsinbothmax-marginandMLEmethods.Speciﬁcally themax-marginscenemodelachievesanaccuracyofabout0.83insceneclassiﬁcation andthelikelihood-basedmodelobtainsanaccuracyofabout0.80.Objectmodeling:thesuperiorperformanceofthemax-marginlearnedMM-scenemodelcomparingtotheSVMandlogisticregression(SeetheleftgreenbarofFig.1(c)) whichuseglobalfeaturesonly indicatesthatmodelingobjectscanfacilitatescenecategorization.Thisisbecausethesceneclassiﬁcationmodelisinﬂuencedbythelatentobjectmodelingthroughtheterm∆L⋆d(s) whichcanimprovethedecisionboundaryofastandardlinearSVMforthoseimagesthathavenegativescoresof∆L⋆d(s) aswehavediscussedintheonlineloss-augmentedSVM.However objectmodelingdoesnotimprovetheclassiﬁcationaccuracyandsometimesitcanevenbeharmfulwhenthescenemodelislearnedwiththestandardMLE.Thisisbecausetheobjectmodel(usingthestate-of-the-artrepresentation)(e.g. MM-MLE-NG)aloneperformsmuchworsethanglobalfeaturemodels(e.g. logisticregression) asshowninFig.1andFig.3 andthestandardMLElearnsanimbalancedpredictionrule aswehaveanalyzedinSection3.Giventhatthestate-of-the-artobjectmodelisnotgood itisveryencouragingtoseethatwecanstillobtainpositiveimprovementsbyusingthecloselycoupledandwell-balancedmax-marginlearning.Theseresultsindicatethatfurtherimprovementscanbeexpectedbyimprovingthelocalobjectmodel e.g. byincorporatingrichfeatures.Wealsocomparewiththethememodel[9] whichisforscenecategorizationonly.Thethememodelusesadifferentimagerepresentation whereeachimageisavectorofimagepatchcodewords.Thethememodelachievesabout0.65inclassiﬁcationaccuracy lowerthanthatofMM-Scene.7Table1:Confusionmatrixfor100-topicMM-Sceneonthesportsdataset.0.717badmin-boccecroquetpolorock-rowingsailingsnow-tonclimbingboardingbadminton0.7680.0510.0510.0810.0200.0200.0000.010bocce0.0430.3330.2750.1450.0870.0580.0140.043croquet0.0250.1440.6690.0930.0250.0250.0080.008polo0.2200.0550.0990.5160.0220.0220.0110.055rockclimbing0.0000.0100.0210.0000.8450.0310.0100.082rowing0.0080.0080.0080.0080.0240.9120.0160.016sailing0.0110.0210.0000.0210.0110.0530.8840.000snowboarding0.0110.0210.0320.0950.0840.0530.0630.642Table2:The67indoorcategoriessortedbyclassiﬁcationaccuracyby70-topicMM-Scene.buffet0.85lobby0.40stairscase0.25hospitalroom0.10greenhouse0.84prisoncell0.39studiomusic0.24kindergarden0.10cloister0.71casino0.36childrenroom0.21laundromat0.10insidebus0.61diningroom0.35garage0.20ofﬁce0.10movietheater0.60kitchen0.35gym0.20restaurantkitchen0.09poolinside0.59winecellar0.34hairsalon0.20shoeshop0.09churchinside0.56library0.31livingroom0.20videostore0.08classroom0.55tvstudio0.30operatingroom0.20airportinside0.07concerthall0.55warehouse0.29pantry0.20bar0.06corridor0.55batchroom0.26subway0.20deli0.06ﬂorist0.55bookstore0.25toystore0.19jewelleryshop0.06trainstation0.54computerroom0.25artstudio0.14laboratorywet0.05closet0.51dentalofﬁce0.25fastfoodrestaurant0.13lockerroom0.05elevator0.49grocerystore0.25auditorium0.12museum0.05nursery0.44insidesubway0.25bakery0.11restaurant0.05bowling0.41mall0.25bedroom0.11waitingroom0.04gameroom0.40meetingroom0.25clothingstore0.100.50.550.60.650.70.750.8Scene Classification Accuracy0/10/50/100/200/300/400/50Figure4:ClassiﬁcationaccuracyofMM-Scenewithdifferentlossfunctions∆ℓd(s).Finally weexaminetheinﬂuenceofthelossfunction∆ℓd(s)ontheperformanceofthemax-marginscenemodel.Aswecanseeinproblem(11) thelossfunction∆ℓd(s)isanotherimportantfactorthatinﬂuencestheestimationofθanditsrelativeimportanceinthepredic-tionrule(5).Here weusethe0/ℓ-lossfunction thatis ∆ℓd(s)=ℓifs̸=sd;otherwise0.Fig.4showstheperformanceofthe100-topicMM-Scenemodelwhenusingdifferentlossfunctions.Whenℓissetbetween10and20 theMM-Scenemethodstablyachievesthebestperformance.TheaboveresultsinFig.3andTable1areachievedwithℓselectedfrom5to40withcross-validationduringtraining.5.4SceneCategorizationonthe67-ClassMITIndoorSceneDataset0.140.160.180.20.220.240.260.280.30.320.34  MLE−Scene−NGMM−Scene−NGSVMLRROI+Gist(segmentation)ROI+Gist(annotation)MLE−SceneMM−SceneScene Classification AccuracyFigure5:Classiﬁcationaccuracyonthe67-classMITindoordataset.TheMITindoordataset[20]containscomplexsceneimagesfrom67categories.Weusethesametrainingandtestingdatasetasin[20] inwhicheachcategoryhasabout80imagesfortrainingandabout20imagesfortesting.WecomparethejointscenemodelwithSVM logisticregression(LR) andtheprototype-basedmethods[20].BoththeSVMandLRarebasedontheglobalgistfeaturesonly.Forthejointscenemodel wesetthenumberoflatenttopicsat70.TheoverallperformanceofdifferentmethodsareshowninFig.5andtheclassiﬁcationaccuracyofeachclassisshowninTable2.Fortheprototype-basedmethods wecitetheresultsfrom[20].Wecanseethatthejointscenemodel(bothMLE-SceneandMM-Scene)signiﬁcantlyoutperformsSVMandLRthatuseglobalfeaturesonly.Thelikelihood-basedMLE-SceneslightlyoutperformstheROI-Gist(segmentation) whichusesboththeglobalgistfeaturesandlocalregion-of-interest(ROI)featuresextractedfromautomaticallysegmentedregions[20].Byusingmax-margintraining thejointscenemodel(i.e. MM-Scene)achievessigniﬁcantimprovementscomparedtoMLE-Scene.Moreover themargin-basedMM-Scene whichusesautomaticallysegmentedregionstoextractfeatures outperformstheROI-Gist(annotation)methodthatuseshumanannotatedinterestedregions.6ConclusionsInthispaper weaddresstheweakcouplingproblemofthecommonlyusedmaximumlikelihoodestimationinlearningupstreamsceneunderstandingmodelsbypresentingajointmaximummar-ginandmaximumlikelihoodlearningmethod.Theproposedapproachachievesacloseinterplaybetweenthepredictionmodelestimationandlatenttopicdiscovery andtherebyawell-balancedpredictionrule.TheoptimizationproblemisefﬁcientlysolvedwithavariationalEMprocedure whichiterativelylearnsanonlineloss-augmentedSVM.Finally wedemonstratetheadvantagesofmax-margintrainingandtheeffectivenessofusingglobalfeaturesinsceneunderstandingonbothan8-categorysportsdatasetandthe67-classMITindoorscenedata.8AcknowledgementsJ.ZandE.P.XaresupportedbyONRN000140910758 NSFIIS-0713379 NSFCareerDBI-0546594 andanAlfredP.SloanResearchFellowshiptoE.P.X.L.F-FispartiallysupportedbyanNSFCAREERgrant(IIS-0845230) aGoogleresearchaward andaMicrosoftResearchFellow-ship.WealsowouldliketothankOlgaRussakovskyforhelpfulcomments.References[1]P.Arbel´aezandL.Cohen.Constrainedimagesegmentationfromhierarchicalboundaries.InCVPR 2008.[2]I.Biederman.Onthesemanticsofaglanceatascene.PerceptualOrganization 213–253 1981.[3]D.BleiandJ.Lafferty.Correlatedtopicmodels.InNIPS 2006.[4]D.BleiandJ.D.McAuliffe.Supervisedtopicmodels.InNIPS 2007.[5]D.Blei A.Ng andM.Jordan.LatentDirichletallocation.JMLR (3):993–1022 2003.[6]L.-L.CaoandL.Fei-Fei.Spatiallycoherentlatenttopicmodelforconcurrentsegmentationandclassiﬁ-cationofobjectsandscenes.InICCV 2007.[7]K.CrammerandY.Singer.Onthealgorithmicimplementationofmulticlasskernel-basedvectorma-chines.JMLR (2):265–292 2001.[8]L.Du L.Ren D.Dunson andL.Carin.Abayesianmodelforsimultaneousimagecluster annotationandobjectsegmentation.InNIPS 2009.[9]L.Fei-FeiandP.Perona.Abayesianhierarchicalmodelforlearningnaturalscenecategories.InCVPR 2005.[10]A.Friedman.Framingpictures:Theroleofknowledgeinautomatizedencodingandmemoryforgist.JournalofExperimentalPsychology:General 108(3):316–355 1979.[11]T.Joachims T.Finley andC.-N.Yu.Cutting-planetrainingofstructuralSVMs.MachineLearning 77(1):27–59 2009.[12]S.Lacoste-Jullien F.Sha andM.Jordan.DiscLDA:Discriminativelearningfordimensionalityreductionandclassiﬁcation.InNIPS 2008.[13]L.-J.LiandL.Fei-Fei.What whereandwho?classifyingeventsbysceneandobjectrecognition.InCVPR 2007.[14]L.-J.Li R.Socher andL.Fei-Fei.Towardstotalsceneunderstanding:Classiﬁcation annotationandsegmentationinanautomaticframework.InCVPR 2009.[15]D.C.LiuandJ.Nocedal.OnthelimitedmemoryBFGSmethodforlargescaleoptimization.Mathemat-icalProgramming (45):503–528 1989.[16]D.G.Lowe.Objectrecognitionfromlocalscale-invariantfeatures.InICCV 1999.[17]K.Murphy A.Torralba andW.Freeman.Usingtheforesttoseethetrees:Agraphicalmodelrelatingfeatures objects andscenes.InNIPS 2003.[18]D.Navon.Forestbeforetrees:Theprecedenceofglobalfeaturesinvisualperception.PerceptionandPsychophysics 5:197–200 1969.[19]A.OlivaandA.Torralba.Modelingtheshapeofthescene:aholisticrepresentationofthespatialenve-lope.IJCV 42(3):145–175 2001.[20]A.QuattoniandA.Torralba.Recognizingindoorscenes.InCVPR 2009.[21]B.Sch¨olkopfandA.Smola.LearningwithKernels:SupportVectorMachines Regularization Optimiza-tion andBeyond.MITPress 2001.[22]J.Sivic B.C.Russell A.Efros A.Zisserman andW.T.Freeman.Discoveringobjectsandtheirlocatioinsinimages.InICCV 2005.[23]E.Sudderth A.Torralba W.Freeman andA.Willsky.Learninghierarchicalmodelsofscenes objects andparts.InCVPR 2005.[24]B.Taskar C.Guestrin andD.Koller.Max-marginMarkovnetworks.InNIPS 2003.[25]C.Wang D.Blei andL.Fei-Fei.Simultaneousimageclassiﬁcationandannotation.InCVPR 2009.[26]J.Yang K.Yu Y.Gong andT.Huang.Linearspatialpyramidmatchingusingsparsecodingforimageclassiﬁcation.InCVPR 2009.[27]J.Zhu A.Ahmed andE.P.Xing.MedLDA:Maximummarginsupervisedtopicmodelsforregressionandclassiﬁcation.InICML 2009.9,Sebastien Bubeck
Che-Yu Liu
Zhaoran Wang
Han Liu
Kirill Struminsky
Simon Lacoste-Julien
Anton Osokin