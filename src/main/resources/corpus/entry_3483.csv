2015,Mixing Time Estimation in Reversible Markov Chains from a Single Sample Path,This article provides the first procedure for computing a fully data-dependent interval that traps the mixing time $t_{mix}$ of a finite reversible ergodic Markov chain at a prescribed confidence level.  The interval is computed from a single finite-length sample path from the Markov chain  and does not require the knowledge of any parameters of the chain.  This stands in contrast to previous approaches  which either only provide point estimates  or require a reset mechanism  or additional prior knowledge.  The interval is constructed around the relaxation time $t_{relax}$  which is strongly related to the mixing time  and the width of the interval converges to zero roughly at a $\sqrt{n}$ rate  where $n$ is the length of the sample path.  Upper and lower bounds are given on the number of samples required to achieve constant-factor multiplicative accuracy.  The lower bounds indicate that  unless further restrictions are placed on the chain  no procedure can achieve this accuracy level before seeing each state at least $\Omega(t_{relax})$ times on the average.  Finally  future directions of research are identified.,Mixing Time Estimation in Reversible Markov

Chains from a Single Sample Path

Daniel Hsu

Columbia University
djhsu@cs.columbia.edu

Aryeh Kontorovich

Ben-Gurion University

Csaba Szepesv´ari

University of Alberta

karyeh@cs.bgu.ac.il

szepesva@cs.ualberta.ca

Abstract

This article provides the ﬁrst procedure for computing a fully data-dependent in-
terval that traps the mixing time tmix of a ﬁnite reversible ergodic Markov chain at
a prescribed conﬁdence level. The interval is computed from a single ﬁnite-length
sample path from the Markov chain  and does not require the knowledge of any
parameters of the chain. This stands in contrast to previous approaches  which ei-
ther only provide point estimates  or require a reset mechanism  or additional prior
knowledge. The interval is constructed around the relaxation time trelax  which is
strongly related to the mixing time  and the width of the interval converges to zero
roughly at a √n rate  where n is the length of the sample path. Upper and lower
bounds are given on the number of samples required to achieve constant-factor
multiplicative accuracy. The lower bounds indicate that  unless further restric-
tions are placed on the chain  no procedure can achieve this accuracy level before
seeing each state at least Ω(trelax) times on the average. Finally  future directions
of research are identiﬁed.

1

Introduction

This work tackles the challenge of constructing fully empirical bounds on the mixing time of
Markov chains based on a single sample path. Let (Xt)t=1 2 ... be an irreducible  aperiodic time-
homogeneous Markov chain on a ﬁnite state space [d] := {1  2  . . .   d} with transition matrix P .
Under this assumption  the chain converges to its unique stationary distribution π = (πi)d
i=1 regard-
less of the initial state distribution q:

lim
t→∞

Prq (Xt = i) = lim
t→∞

(qP t)i = πi

for each i ∈ [d].

The mixing time tmix of the Markov chain is the number of time steps required for the chain to be
within a ﬁxed threshold of its stationary distribution:

Here  π(A) = Pi∈A πi is the probability assigned to set A by π  and the supremum is over all

possible initial distributions q. The problem studied in this work is the construction of a non-trivial
conﬁdence interval Cn = Cn(X1  X2  . . .   Xn  δ) ⊂ [0 ∞]  based only on the observed sample
path (X1  X2  . . .   Xn) and δ ∈ (0  1)  that succeeds with probability 1 − δ in trapping the value of
the mixing time tmix.

This problem is motivated by the numerous scientiﬁc applications and machine learning tasks in

which the quantity of interest is the mean π(f ) = Pi πif (i) for some function f of the states

of a Markov chain. This is the setting of the celebrated Markov Chain Monte Carlo (MCMC)
paradigm [1]  but the problem also arises in performance prediction involving time-correlated data 
as is common in reinforcement learning [2]. Observable bounds on mixing times are useful in the

1

tmix := min(cid:26)t ∈ N : sup

q

A⊂[d]|Prq (Xt ∈ A) − π(A)| ≤ 1/4(cid:27) .

max

(1)

design and diagnostics of these methods; they yield effective approaches to assessing the estimation
quality  even when a priori knowledge of the mixing time or correlation structure is unavailable.

Main results. We develop the ﬁrst procedure for constructing non-trivial and fully empirical con-
ﬁdence intervals for Markov mixing time. Consider a reversible ergodic Markov chain on d states
with absolute spectral gap γ⋆ and stationary distribution minorized by π⋆. As is well-known [3 
Theorems 12.3 and 12.4] 

(trelax − 1) ln 2 ≤ tmix ≤ trelax ln

4

π⋆

(2)

where trelax := 1/γ⋆ is the relaxation time. Hence  it sufﬁces to estimate γ⋆ and π⋆. Our main
results are summarized as follows.

1. In Section 3.1  we show that in some problems n = Ω((d log d)/γ⋆ + 1/π⋆) observations
are necessary for any procedure to guarantee constant multiplicative accuracy in estimating
γ⋆ (Theorems 1 and 2). Essentially  in some problems every state may need to be visited
about log(d)/γ⋆ times  on average  before an accurate estimate of the mixing time can be
provided  regardless of the actual estimation procedure used.

2. In Section 3.2  we give a point-estimator for γ⋆  and prove in Theorem 3 that it achieves
multiplicative accuracy from a single sample path of length ˜O(1/(π⋆γ3
⋆)).1 We also pro-
vide a point-estimator for π⋆ that requires a sample path of length ˜O(1/(π⋆γ⋆)). This
establishes the feasibility of estimating the mixing time in this setting. However  the valid
conﬁdence intervals suggested by Theorem 3 depend on the unknown quantities π⋆ and
γ⋆. We also discuss the importance of reversibility  and some possible extensions to non-
reversible chains.

3. In Section 4  the construction of valid fully empirical conﬁdence intervals for π⋆ and γ⋆
are considered. First  the difﬁculty of the task is explained  i.e.  why the standard approach
of turning the ﬁnite time conﬁdence intervals of Theorem 3 into a fully empirical one fails.
Combining several results from perturbation theory in a novel fashion we propose a new
procedure and prove that it avoids slow convergence (Theorem 4). We also explain how
to combine the empirical conﬁdence intervals from Algorithm 1 with the non-empirical
bounds from Theorem 3 to produce valid empirical conﬁdence intervals. We prove in
Theorem 5 that the width of these new intervals converge to zero asymptotically at least as
fast as those from either Theorem 3 and Theorem 4.

Related work. There is a vast statistical literature on estimation in Markov chains. For instance  it
is known that under the assumptions on (Xt)t from above  the law of large numbers guarantees that
the sample mean πn(f ) := 1
t=1 f (Xt) converges almost surely to π(f ) [4]  while the central
limit theorem tells us that as n → ∞  the distribution of the deviation √n(πn(f ) − π(f )) will be

normal with mean zero and asymptotic variance limn→∞ n Var (πn(f )) [5].

nPn

Although these asymptotic results help us understand the limiting behavior of the sample mean
over a Markov chain  they say little about the ﬁnite-time non-asymptotic behavior  which is often
needed for the prudent evaluation of a method or even its algorithmic design [6–13]. To address
this need  numerous works have developed Chernoff-type bounds on Pr(|πn(f ) − π(f )| > ǫ)  thus
providing valuable tools for non-asymptotic probabilistic analysis [6  14–16]. These probability
bounds are larger than corresponding bounds for independent and identically distributed (iid) data
due to the temporal dependence; intuitively  for the Markov chain to yield a fresh draw Xt′ that
behaves as if it was independent of Xt  one must wait Θ(tmix) time steps. Note that the bounds
generally depend on distribution-speciﬁc properties of the Markov chain (e.g.  P   tmix  γ⋆)  which
are often unknown a priori in practice. Consequently  much effort has been put towards estimating
these unknown quantities  especially in the context of MCMC diagnostics  in order to provide data-
dependent assessments of estimation accuracy [e.g.  11  12  17–19]. However  these approaches
generally only provide asymptotic guarantees  and hence fall short of our goal of empirical bounds
that are valid with any ﬁnite-length sample path.

Learning with dependent data is another main motivation to our work. Many results from statisti-
cal learning and empirical process theory have been extended to sufﬁciently fast mixing  dependent

1The ˜O(·) notation suppresses logarithmic factors.

2

data [e.g.  20–26]  providing learnability assurances (e.g.  generalization error bounds). These re-
sults are often given in terms of mixing coefﬁcients  which can be consistently estimated in some
cases [27]. However  the convergence rates of the estimates from [27]  which are needed to derive
conﬁdence bounds  are given in terms of unknown mixing coefﬁcients. When the data comes from a
Markov chain  these mixing coefﬁcients can often be bounded in terms of mixing times  and hence
our main results provide a way to make them fully empirical  at least in the limited setting we study.

It is possible to eliminate many of the difﬁculties presented above when allowed more ﬂexible access
to the Markov chain. For example  given a sampling oracle that generates independent transitions
from any given state (akin to a “reset” device)  the mixing time becomes an efﬁciently testable
property in the sense studied in [28  29]. On the other hand  when one only has a circuit-based
description of the transition probabilities of a Markov chain over an exponentially-large state space 
there are complexity-theoretic barriers for many MCMC diagnostic problems [30].

2 Preliminaries

2.1 Notations

We denote the set of positive integers by N  and the set of the ﬁrst d positive integers {1  2  . . .   d}
by [d]. The non-negative part of a real number x is [x]+ := max{0  x}  and ⌈x⌉+ := max{0 ⌈x⌉}.
We use ln(·) for natural logarithm  and log(·) for logarithm with an arbitrary constant base. Bold-
face symbols are used for vectors and matrices (e.g.  v  M )  and their entries are referenced by
subindexing (e.g.  vi  Mi j ). For a vector v  kvk denotes its Euclidean norm; for a matrix M   kMk
denotes its spectral norm. We use Diag(v) to denote the diagonal matrix whose (i  i)-th entry is vi.
i=1 pi = 1}  and we regard vectors

The probability simplex is denoted by ∆d−1 = {p ∈ [0  1]d :Pd

in ∆d−1 as row vectors.

2.2 Setting

Let P ∈ (∆d−1)d ⊂ [0  1]d×d be a d × d row-stochastic matrix for an ergodic (i.e.  irreducible
and aperiodic) Markov chain. This implies there is a unique stationary distribution π ∈ ∆d−1 with
πi > 0 for all i ∈ [d] [3  Corollary 1.17]. We also assume that P is reversible (with respect to π):
(3)

πiPi j = πjPj i 

i  j ∈ [d].

The minimum stationary probability is denoted by π⋆ := mini∈[d] πi.

Deﬁne the matrices

M := Diag(π)P and L := Diag(π)−1/2M Diag(π)−1/2 .

The (i  j)th entry of the matrix Mi j contains the doublet probabilities associated with P : Mi j =
πiPi j is the probability of seeing state i followed by state j when the chain is started from its
stationary distribution. The matrix M is symmetric on account of the reversibility of P   and hence
it follows that L is also symmetric. (We will strongly exploit the symmetry in our results.) Further 
L = Diag(π)1/2P Diag(π)−1/2  hence L and P are similar and thus their eigenvalue systems are
identical. Ergodicity and reversibility imply that the eigenvalues of L are contained in the interval
(−1  1]  and that 1 is an eigenvalue of L with multiplicity 1 [3  Lemmas 12.1 and 12.2]. Denote and
order the eigenvalues of L as

1 = λ1 > λ2 ≥ ··· ≥ λd > −1.

Let λ⋆ := max{λ2  |λd|}  and deﬁne the (absolute) spectral gap to be γ⋆ := 1−λ⋆  which is strictly
positive on account of ergodicity.
Let (Xt)t∈N be a Markov chain whose transition probabilities are governed by P . For each t ∈ N 
let π(t) ∈ ∆d−1 denote the marginal distribution of Xt  so

π(t+1) = π(t)P  

t ∈ N.

Note that the initial distribution π(1) is arbitrary  and need not be the stationary distribution π.

The goal is to estimate π⋆ and γ⋆ from the length n sample path (Xt)t∈[n]  and also to construct fully
empirical conﬁdence intervals that π⋆ and γ⋆ with high probability; in particular  the construction

3

of the intervals should not depend on any unobservable quantities  including π⋆ and γ⋆ themselves.
As mentioned in the introduction  it is well-known that the mixing time of the Markov chain tmix
(deﬁned in Eq. 1) is bounded in terms of π⋆ and γ⋆  as shown in Eq. (2). Moreover  convergence
rates for empirical processes on Markov chain sequences are also often given in terms of mixing
coefﬁcients that can ultimately be bounded in terms of π⋆ and γ⋆ (as we will show in the proof of
our ﬁrst result). Therefore  valid conﬁdence intervals for π⋆ and γ⋆ can be used to make these rates
fully observable.

3 Point estimation

In this section  we present lower and upper bounds on achievable rates for estimating the spectral
gap as a function of the length of the sample path n.

3.1 Lower bounds

The purpose of this section is to show lower bounds on the number of observations necessary to
achieve a ﬁxed multiplicative (or even just additive) accuracy in estimating the spectral gap γ⋆. By
Eq. (2)  the multiplicative accuracy lower bound for γ⋆ gives the same lower bound for estimating
the mixing time. Our ﬁrst result holds even for two state Markov chains and shows that a sequence
length of Ω(1/π⋆) is necessary to achieve even a constant additive accuracy in estimating γ⋆.
Theorem 1. Pick any ¯π ∈ (0  1/4). Consider any estimator ˆγ⋆ that takes as input a random
sample path of length n ≤ 1/(4¯π) from a Markov chain starting from any desired initial state
distribution. There exists a two-state ergodic and reversible Markov chain distribution with spectral
gap γ⋆ ≥ 1/2 and minimum stationary probability π⋆ ≥ ¯π such that

Pr [|ˆγ⋆ − γ⋆| ≥ 1/8] ≥ 3/8.

Next  considering d state chains  we show that a sequence of length Ω(d log(d)/γ⋆) is required to
estimate γ⋆ up to a constant multiplicative accuracy. Essentially  the sequence may have to visit all
d states at least log(d)/γ⋆ times each  on average. This holds even if π⋆ is within a factor of two of
the largest possible value of 1/d that it can take  i.e.  when π is nearly uniform.
Theorem 2. There is an absolute constant c > 0 such that the following holds. Pick any positive
integer d ≥ 3 and any ¯γ ∈ (0  1/2). Consider any estimator ˆγ⋆ that takes as input a random sample
path of length n < cd log(d)/¯γ from a d-state reversible Markov chain starting from any desired
initial state distribution. There is an ergodic and reversible Markov chain distribution with spectral
gap γ⋆ ∈ [¯γ  2¯γ] and minimum stationary probability π⋆ ≥ 1/(2d) such that

Pr [|ˆγ⋆ − γ⋆| ≥ ¯γ/2] ≥ 1/4.

The proofs of Theorems 1 and 2 are given in Appendix A.2

3.2 A plug-in based point estimator and its accuracy

Let us now consider the problem of estimating γ⋆. For this  we construct a natural plug-in estimator.
Along the way  we also provide an estimator for the minimum stationary probability  allowing one
to use the bounds from Eq. (2) to trap the mixing time.

Deﬁne the random matrix cM ∈ [0  1]d×d and random vector ˆπ ∈ ∆d−1 by

 

cMi j := |{t ∈ [n − 1] : (Xt  Xt+1) = (i  j)}|

n − 1
ˆπi := |{t ∈ [n] : Xt = i}|
 

i  j ∈ [d]  

n

i ∈ [d] .

Furthermore  deﬁne

2A full version of this paper  with appendices  is available on arXiv [31].

Sym(bL) :=

1
2

⊤

)

(bL +bL

4

to be the symmetrized version of the (possibly non-symmetric) matrix

bL := Diag( ˆπ)−1/2cM Diag( ˆπ)−1/2.

Let ˆλ1 ≥ ˆλ2 ≥ ··· ≥ ˆλd be the eigenvalues of Sym(bL). Our estimator of the minimum sta-
tionary probability π⋆ is ˆπ⋆ := mini∈[d] ˆπi  and our estimator of the spectral gap γ⋆ is ˆγ⋆ :=
1 − max{ˆλ2 |ˆλd|}.

These estimators have the following accuracy guarantees:

and

log d
π⋆δ

π⋆δ

+

γ⋆n

δ · log n
π⋆γ⋆n

π⋆δ

+

log 1
γ⋆

Theorem 3. There exists an absolute constant C > 0 such that the following holds. Assume the
estimators ˆπ⋆ and ˆγ⋆ described above are formed from a sample path of length n from an ergodic and
reversible Markov chain. Let γ⋆ > 0 denote the spectral gap and π⋆ > 0 the minimum stationary
probability. For any δ ∈ (0  1)  with probability at least 1 − δ 

Theorem 3 implies that the sequence lengths required to estimate π⋆ and γ⋆ to within constant

|ˆπ⋆ − π⋆| ≤ C s π⋆ log d
γ⋆n 
|ˆγ⋆ − γ⋆| ≤ C s log d
γ⋆n  .
⋆(cid:17) . By Eq. (2)  the second of these is
multiplicative factors are  respectively  ˜O(cid:16) 1
The proof of Theorem 3 is based on analyzing the convergence of the sample averages cM and ˆπ
Chernoff-type bounds for Markov chains to each entry of cM would result in a signiﬁcantly worse

to their expectation  and then using perturbation bounds for eigenvalues to derive a bound on the
error of ˆγ⋆. However  since these averages are formed using a single sample path from a (possibly)
non-stationary Markov chain  we cannot use standard large deviation bounds; moreover applying

sequence length requirement  roughly a factor of d larger. Instead  we adapt probability tail bounds
for sums of independent random matrices [32] to our non-iid setting by directly applying a blocking
technique of [33] as described in the article of [20]. Due to ergodicity  the convergence rate can be
bounded without any dependence on the initial state distribution π(1). The proof of Theorem 3 is
given in Appendix B.

π⋆γ 3
also a bound on the required sequence length to estimate tmix.

π⋆γ⋆(cid:17) and ˜O(cid:16) 1

(4)

(5)

Note that because the eigenvalues of L are the same as that of the transition probability matrix P  
we could have instead opted to estimate P   say  using simple frequency estimates obtained from

the sample path  and then computing the second largest eigenvalue of this empirical estimate bP .

In fact  this approach is a way to extend to non-reversible chains  as we would no longer rely on
the symmetry of M or L. The difﬁculty with this approach is that P lacks the structure required
by certain strong eigenvalue perturbation results. One could instead invoke the Ostrowski-Elsner
theorem [cf. Theorem 1.4 on Page 170 of 34]  which bounds the matching distance between the

eigenvalues of a matrix A and its perturbation A + E by O(kEk1/d). Since kbP − Pk is expected

to be of size O(n−1/2)  this approach will give a conﬁdence interval for γ⋆ whose width shrinks
at a rate of O(n−1/(2d))—an exponential slow-down compared to the rate from Theorem 3. As
demonstrated through an example from [34]  the dependence on the d-th root of the norm of the
perturbation cannot be avoided in general. Our approach based on estimating a symmetric matrix
affords us the use of perturbation results that exploit more structure.

Returning to the question of obtaining a fully empirical conﬁdence interval for γ⋆ and π⋆  we notice
that  unfortunately  Theorem 3 falls short of being directly suitable for this  at least without further
assumptions. This is because the deviation terms themselves depend inversely both on γ⋆ and π⋆ 
and hence can never rule out 0 (or an arbitrarily small positive value) as a possibility for γ⋆ or π⋆.3
In effect  the fact that the Markov chain could be slow mixing and the long-term frequency of some

3Using Theorem 3  it is possible to trap γ⋆ in the union of two empirical conﬁdence intervals—one around

ˆγ⋆ and the other around zero  both of which shrink in width as the sequence length increases.

5

Algorithm 1 Empirical conﬁdence intervals
Input: Sample path (X1  X2  . . .   Xn)  conﬁdence parameter δ ∈ (0  1).
1: Compute state visit counts and smoothed transition probability estimates:

Ni j + 1/d

Ni := |{t ∈ [n − 1] : Xt = i}|  
Ni j := |{t ∈ [n − 1] : (Xt  Xt+1) = (i  j)}|  

i ∈ [d];

 

Ni + 1

5: Spectral gap estimate:

(i  j) ∈ [d]2.

bPi j :=
2: Let bA# be the group inverse of bA := I − bP .
3: Let ˆπ ∈ ∆d−1 be the unique stationary distribution for bP .
4: Compute eigenvalues ˆλ1≥ˆλ2≥···≥ˆλd of Sym(bL)  wherebL := Diag( ˆπ)1/2bP Diag( ˆπ)−1/2.
ˆγ⋆ := 1 − max{ˆλ2  |ˆλd|}.
6: Empirical bounds for |bPi j−Pi j| for (i  j) ∈ [d]2: c := 1.01  τn δ := inf{t ≥ 0 : 2d2(1 +

(5/3)τn δ + |bPi j − 1/d|

bBi j :=r cτn δ

t ⌉+)e−t ≤ δ} 

⌈logc

and

Ni

+

2n

2

.

7: Relative sensitivity of π:

Ni

+s 2cbPi j(1 − bPi j)τn δ
j j − minnbA#

2Ni

2Ni

+vuut cτn δ
maxnbA#
ˆb := ˆκ maxnbBi j : (i  j) ∈ [d]2o  

ˆκ :=

1
2

8: Empirical bounds for maxi∈[d] |ˆπi − πi| and maxSi∈[d]{|pπi/ˆπi − 1|  |pˆπi/πi − 1|}:
[ˆπi − ˆb]+) .

ˆρ :=

1
2

ˆπi

ˆb

 

i j : i ∈ [d]o : j ∈ [d]o .
max [i∈[d]( ˆb
i j!1/2

ˆπi
ˆπj

ˆB2

.

9: Empirical bounds for |ˆγ⋆ − γ⋆|:

ˆw := 2ˆρ + ˆρ2 + (1 + 2ˆρ + ˆρ2) X(i j)∈[d]2

states could be small makes it difﬁcult to be conﬁdent in the estimates provided by ˆγ⋆ and ˆπ⋆. This
suggests that in order to obtain fully empirical conﬁdence intervals  we need an estimator that is not
subject to such effects—we pursue this in Section 4. Theorem 3 thus primarily serves as a point
of comparison for what is achievable in terms of estimation accuracy when one does not need to
provide empirical conﬁdence bounds.

4 Fully empirical conﬁdence intervals

In this section  we address the shortcoming of Theorem 3 and give fully empirical conﬁdence in-
tervals for the stationary probabilities and the spectral gap γ⋆. The main idea is to use the Markov
property to eliminate the dependence of the conﬁdence intervals on the unknown quantities (includ-
ing π⋆ and γ⋆). Speciﬁcally  we estimate the transition probabilities from the sample path using
simple frequency estimates: as a consequence of the Markov property  for each state  the frequency
estimates converge at a rate that depends only on the number of visits to the state  and in particular
the rate (given the visit count of the state) is independent of the mixing time of the chain.

6

As discussed in Section 3  it is possible to form a conﬁdence interval for γ⋆ based on the eigen-
values of an estimated transition probability matrix by appealing to the Ostrowski-Elsner theorem.
However  as explained earlier  this would lead to a slow O(n−1/(2d)) rate. We avoid this slow rate
by using an estimate of the symmetric matrix L  so that we can use a stronger perturbation result
(namely Weyl’s inequality  as in the proof of Theorem 3) available for symmetric matrices.

To form an estimate of L based on an estimate of the transition probabilities  one possibility is
to estimate π using a frequency-based estimate for π as was done in Section 3  and appeal to
the relation L = Diag(π)1/2P Diag(π)−1/2 to form a plug-in estimate. However  as noted in
Section 3.2  conﬁdence intervals for the entries of π formed this way may depend on the mixing
time. Indeed  such an estimate of π does not exploit the Markov property.

We adopt a different strategy for estimating π  which leads to our construction of empirical conﬁ-

estimate ˆγ⋆ of the spectral gap (Steps 4 and 5). In the remaining steps  we use perturbation analyses

be computed at the cost of inverting an (d−1)×(d−1) matrix [35  Theorem 5.2].4 Further  once

dence intervals  detailed in Algorithm 1. We form the matrix bP using smoothed frequency estimates
of P (Step 1)  then compute the so-called group inverse bA# of bA = I − bP (Step 2)  followed by
ﬁnding the unique stationary distribution ˆπ of bP (Step 3)  this way decoupling the bound on the
accuracy of ˆπ from the mixing time. The group inverse bA# of bA is uniquely deﬁned; and if bP
deﬁnes an ergodic chain (which is the case here due to the use of the smoothed estimates)  bA# can
given bA#  the unique stationary distribution ˆπ of bP can be read out from the last row of bA# [35 
Theorem 5.3]. The group inverse is also be used to compute the sensitivity of π. Based on ˆπ and bP  
we construct the plug-in estimatebL of L  and use the eigenvalues of its symmetrization to form the
to relate ˆπ and π  viewing P as the perturbation of bP ; and also to relate ˆγ⋆ and γ⋆  viewing L as a
perturbation of Sym(bL). Both analyses give error bounds entirely in terms of observable quantities
bA#  which  as noted reduces to matrix inversion. Thus  with a standard implementation of matrix
Step 7  with bA# replaced by the group inverse A# of A := I − P . The result is as follows.

Theorem 4. Suppose Algorithm 1 is given as input a sample path of length n from an ergodic and
reversible Markov chain and conﬁdence parameter δ ∈ (0  1). Let γ⋆ > 0 denote the spectral gap 
π the unique stationary distribution  and π⋆ > 0 the minimum stationary probability. Then  on an
event of probability at least 1 − δ 
πi ∈ [ˆπi − ˆb  ˆπi + ˆb]

inversion  the algorithm’s time complexity is O(n + d3)  while its space complexity is O(d2).

To state our main theorem concerning Algorithm 1  we ﬁrst deﬁne κ to be analogous to ˆκ from

(e.g.  ˆκ)  tracing back to empirical error bounds for the smoothed frequency estimates of P .

The most computationally expensive step in Algorithm 1 is the computation of the group inverse

γ⋆ ∈ [ˆγ⋆ − ˆw  ˆγ⋆ + ˆw].

for all i ∈ [d] 

and

Moreover  ˆb and ˆw almost surely satisfy (as n → ∞)

ˆb = O max

(i j)∈[d]2

κr Pi j log log n

πin

!  

ˆw = O κ

π⋆r log log n

π⋆n

π⋆n ! .5
+r d log log n

The proof of Theorem 4 is given in Appendix C. As mentioned above  the obstacle encountered in
Theorem 3 is avoided by exploiting the Markov property. We establish fully observable upper and

lower bounds on the entries of P that converge at apn/ log log n rate using standard martingale tail

inequalities; this justiﬁes the validity of the bounds from Step 6. Properties of the group inverse [35 
36] and eigenvalue perturbation theory [34] are used to validate the empirical bounds on πi and γ⋆
developed in the remaining steps of the algorithm.

The ﬁrst part of Theorem 4 provides valid empirical conﬁdence intervals for each πi and for γ⋆ 
which are simultaneously valid at conﬁdence level δ. The second part of Theorem 4 shows that the

4 The group inverse of a square matrix A  a special case of the Drazin inverse  is the unique matrix A#

satisfying AA#A = A  A#AA# = A# and A#A = AA#.

5In Theorems 4 and 5  our use of big-O notation is as follows. For a random sequence (Yn)n and a (non-
random) positive sequence (εθ n)n parameterized by θ  we say “Yn = O(εθ n) holds almost surely as n → ∞”
if there is some universal constant C > 0 such that for all θ  lim supn→∞ Yn/εθ n ≤ C holds almost surely.

7

width of the intervals decrease as the sequence length increases. We show in Appendix C.5 that

κ ≤ d/γ⋆  and hence ˆb = O(cid:18)max(i j)∈[d]2

d

γ⋆q Pi j log log n

πin

(cid:19)  ˆw = O(cid:16) d

π⋆γ⋆q log log n
π⋆n (cid:17).

It is easy to combine Theorems 3 and 4 to yield intervals whose widths shrink at least as fast
as both the non-empirical intervals from Theorem 3 and the empirical intervals from Theorem 4.

Speciﬁcally  determine lower bounds on π⋆ and γ⋆ using Algorithm 1  π⋆ ≥ mini∈[d][ˆπi − ˆb]+  
γ⋆ ≥ [ˆγ⋆ − ˆw]+; then plug-in these lower bounds for π⋆ and γ⋆ in the deviation bounds in Eq. (5)
from Theorem 3. This yields a new interval centered around the estimate of γ⋆ from Theorem 3 
and it no longer depends on unknown quantities. The interval is a valid 1 − 2δ probability conﬁ-
dence interval for γ⋆  and for sufﬁciently large n  the width shrinks at the rate given in Eq. (5). We
can similarly construct an empirical conﬁdence interval for π⋆ using Eq. (4)  which is valid on the
same 1 − 2δ probability event.6 Finally  we can take the intersection of these new intervals with the
corresponding intervals from Algorithm 1. This is summarized in the following theorem  which we
prove in Appendix D.
Theorem 5. The following holds under the same conditions as Theorem 4. For any δ ∈ (0  1) 

the conﬁdence intervals bU and bV described above for π⋆ and γ⋆  respectively  satisfy π⋆ ∈ bU and
γ⋆ ∈ bV with probability at least 1 − 2δ. Furthermore  the widths of these intervals almost surely
satisfy (as n → ∞) |bU| = O r π⋆ log d
  ˆw(cid:27)(cid:19)  where ˆw is

γ⋆n !  |bV | = O(cid:18)min(cid:26)q log d

the width from Algorithm 1.

δ
π⋆γ⋆n

·log(n)

π⋆ δ

5 Discussion

The construction used in Theorem 5 applies more generally: Given a conﬁdence interval of the
form In = In(γ⋆  π⋆  δ) for some conﬁdence level δ and a fully empirical conﬁdence set En(δ)
for (γ⋆  π⋆) for the same level  I ′
n = En(δ) ∩ ∪(γ π)∈En(δ)In(γ  π  δ) is a valid fully empirical 2δ-
level conﬁdence interval whose asymptotic width matches that of In up to lower order terms under
reasonable assumptions on En and In. In particular  this suggests that future work should focus on
closing the gap between the lower and upper bounds on the accuracy of point-estimation. Another
interesting direction is to reduce the computation cost: The current cubic cost in the number of states
can be too high even when the number of states is only moderately large.

Perhaps more important  however  is to extend our results to large state space Markov chains: In
most practical applications the state space is continuous or is exponentially large in some natural pa-
rameters. As follows from our lower bounds  without further assumptions  the problem of fully data
dependent estimation of the mixing time is intractable for information theoretical reasons. Interest-
ing directions for future work thus must consider Markov chains with speciﬁc structure. Parametric
classes of Markov chains  including but not limited to Markov chains with factored transition kernels
with a few factors  are a promising candidate for such future investigations. The results presented
here are a ﬁrst step in the ambitious research agenda outlined above  and we hope that they will
serve as a point of departure for further insights in the area of fully empirical estimation of Markov
chain parameters based on a single sample path.

References

[1] J. S. Liu. Monte Carlo Strategies in Scientiﬁc Computing. Springer Series in Statistics. Springer-Verlag 

2001.

[2] R. S. Sutton and A. G. Barto. Reinforcement Learning: An Introduction (Adaptive Computation and

Machine Learning). A Bradford Book  1998.

[3] D. Levin  Y. Peres  and E. Wilmer. Markov Chains and Mixing Times. AMS  2008.

[4] S. P. Meyn and R. L. Tweedie. Markov Chains and Stochastic Stability. Springer  1993.

[5] C. Kipnis and S. R. S. Varadhan. Central limit theorem for additive functionals of reversible markov

processes and applications to simple exclusions. Comm. Math. Phys.  104(1):1–19  1986.

6For the π⋆ interval  we only plug-in lower bounds on π⋆ and γ⋆ only where these quantities appear as 1/π⋆

and 1/γ⋆ in Eq. (4). It is then possible to “solve” for observable bounds on π⋆. See Appendix D for details.

8

[6] I. Kontoyiannis  L. A. Lastras-Monta˜no  and S. P. Meyn. Exponential bounds and stopping rules for

MCMC and general Markov chains. In VALUETOOLS  page 45  2006.

[7] M.-F. Balcan  A. Beygelzimer  and J. Langford. Agnostic active learning. In ICML  pages 65–72  2006.

[8] V. Mnih  Cs. Szepesv´ari  and J.-Y. Audibert. Empirical Bernstein stopping. In ICML  pages 672–679 

2008.

[9] A. Maurer and M. Pontil. Empirical Bernstein bounds and sample-variance penalization. In COLT  2009.

[10] L. Li  M. L. Littman  T. J. Walsh  and A. L. Strehl. Knows what it knows: a framework for self-aware

learning. Machine Learning  82(3):399–443  2011.

[11] J. M. Flegal and G. L. Jones. Implementing MCMC: estimating with conﬁdence. In Handbook of Markov

chain Monte Carlo  pages 175–197. Chapman & Hall/CRC  2011.

[12] B. M. Gyori and D. Paulin. Non-asymptotic conﬁdence intervals for MCMC in practice. arXiv:1212.2016 

2014.

[13] A. Swaminathan and T. Joachims. Counterfactual risk minimization: Learning from logged bandit feed-

back. In ICML  2015.

[14] D. Gillman. A Chernoff bound for random walks on expander graphs. SIAM Journal on Computing 

27(4):1203–1220  1998.

[15] C. A. Le´on and F. Perron. Optimal Hoeffding bounds for discrete reversible Markov chains. Annals of

Applied Probability  pages 958–970  2004.

[16] D. Paulin. Concentration inequalities for Markov chains by Marton couplings and spectral methods.

Electronic Journal of Probability  20:1–32  2015.

[17] S. T. Garren and R. L. Smith. Estimating the second largest eigenvalue of a Markov transition matrix.

Bernoulli  6:215–242  2000.

[18] G. L. Jones and J. P. Hobert. Honest exploration of intractable probability distributions via markov chain

monte carlo. Statist. Sci.  16(4):312–334  11 2001.

[19] Y. Atchad´e. Markov Chain Monte Carlo conﬁdence intervals. Bernoulli  2015. (to appear).

[20] B. Yu. Rates of convergence for empirical processes of stationary mixing sequences. The Annals of

Probability  22(1):94–116  January 1994.

[21] R. L. Karandikar and M. Vidyasagar. Rates of uniform convergence of empirical means with mixing

processes. Statistics and Probability Letters  58(3):297–307  2002.

[22] D. Gamarnik. Extension of the PAC framework to ﬁnite and countable Markov chains. IEEE Transactions

on Information Theory  49(1):338–345  2003.

[23] M. Mohri and A. Rostamizadeh. Stability bounds for non-iid processes. In NIPS  2008.

[24] M. Mohri and A. Rostamizadeh. Rademacher complexity bounds for non-i.i.d. processes. In NIPS  2009.

[25] I. Steinwart and A. Christmann. Fast learning from non-i.i.d. observations. In NIPS  2009.

[26] I. Steinwart  D. Hush  and C. Scovel. Learning from dependent observations. Journal of Multivariate

Analysis  100(1):175–194  2009.

[27] D. McDonald  C. Shalizi  and M. Schervish. Estimating beta-mixing coefﬁcients. In AISTATS  pages

516–524  2011.

[28] T. Batu  L. Fortnow  R. Rubinfeld  W. D. Smith  and P. White. Testing that distributions are close. In

FOCS  pages 259–269. IEEE  2000.

[29] T. Batu  L. Fortnow  R. Rubinfeld  W. D. Smith  and P. White. Testing closeness of discrete distributions.

Journal of the ACM (JACM)  60(1):4:2–4:25  2013.

[30] N. Bhatnagar  A. Bogdanov  and E. Mossel. The computational complexity of estimating MCMC conver-

gence time. In RANDOM  pages 424–435. Springer  2011.

[31] D. Hsu  A. Kontorovich  and C. Szepesv´ari. Mixing time estimation in reversible Markov chains from a

single sample path. CoRR  abs/1506.02903  2015.

[32] J. Tropp. An introduction to matrix concentration inequalities. Foundations and Trends in Machine

Learning  2015.

[33] S. Bernstein. Sur l’extension du theoreme limite du calcul des probabilites aux sommes de quantites

dependantes. Mathematische Annalen  97:1–59  1927.

[34] G. W. Stewart and J. Sun. Matrix perturbation theory. Academic Press  Boston  1990.

[35] C. D. Meyer Jr. The role of the group generalized inverse in the theory of ﬁnite Markov chains. SIAM

Review  17(3):443–464  1975.

[36] G. Cho and C. Meyer. Comparison of perturbation bounds for the stationary distribution of a Markov

chain. Linear Algebra and its Applications  335:137–150  2001.

9

,Daniel Hsu
Aryeh Kontorovich
Csaba Szepesvari
Alhussein Fawzi
Seyed-Mohsen Moosavi-Dezfooli
Pascal Frossard