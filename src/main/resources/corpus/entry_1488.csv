2018,Differentially Private Testing of Identity and Closeness of Discrete Distributions,We study the fundamental problems of identity testing (goodness of fit)  and closeness testing (two sample test) of distributions over $k$ elements  under differential privacy. While the problems have a long history in statistics   finite sample bounds for these problems have only been established recently. 

In this work  we derive upper and lower bounds on the sample complexity of both the problems under $(\varepsilon  \delta)$-differential privacy. We provide optimal sample complexity algorithms for identity testing problem for all parameter ranges  and the first results for closeness testing. Our closeness testing bounds are optimal in the sparse regime where the number of samples is at most $k$. 

Our upper bounds are obtained by privatizing non-private estimators for these problems. The non-private estimators are chosen to have small sensitivity. We propose a general framework to establish lower bounds on the sample complexity of statistical tasks under differential privacy. We show a bound on differentially private algorithms in terms of a coupling between the two hypothesis classes we aim to test. By constructing carefully chosen priors over the hypothesis classes  and using Le Cam's two point theorem we provide a general mechanism for proving lower bounds.  We believe that the framework can be used to obtain strong lower bounds for other statistical tasks under privacy.,Dierentially Private Testing of Identity and

Closeness of Discrete Distributions

Jayadev Acharya ú
Cornell University

acharya@cornell.edu

Ziteng Sun ú

Cornell University
zs335@cornell.edu

Huanyu Zhang ú
Cornell University
hz388@cornell.edu

Abstract

We study the fundamental problems of identity testing (goodness of ﬁt)  and
closeness testing (two sample test) of distributions over k elements  under
dierential privacy. While the problems have a long history in statistics 
ﬁnite sample bounds for these problems have only been established recently.
In this work  we derive upper and lower bounds on the sample complexity
of both the problems under (Á  ”)-dierential privacy. We provide sample
optimal algorithms for identity testing problem for all parameter ranges 
and the ﬁrst results for closeness testing. Our closeness testing bounds are
optimal in the sparse regime where the number of samples is at most k.
Our upper bounds are obtained by privatizing non-private estimators for
these problems. The non-private estimators are chosen to have small sensi-
tivity. We propose a general framework to establish lower bounds on the
sample complexity of statistical tasks under dierential privacy. We show a
bound on dierentially private algorithms in terms of a coupling between
the two hypothesis classes we aim to test. By carefully constructing chosen
priors over the hypothesis classes  and using Le Cam’s two point theorem we
provide a general mechanism for proving lower bounds. We believe that the
framework can be used to obtain strong lower bounds for other statistical
tasks under privacy.

1 Introduction
Testing whether observed data conforms to an underlying model is a fundamental scientiﬁc
problem. In a statistical framework  given samples from an unknown probabilistic model 
the goal is to determine whether the underlying model has a property of interest.
This question has received great attention in statistics as hypothesis testing [1  2]  where it
was mostly studied in the asymptotic regime when the number of samples m æ Œ. In the
past two decades there has been a lot of work from the computer science  information theory 
and statistics community on various distribution testing problems in the non-asymptotic
(small-sample) regime  where the domain size k could be potentially larger than m (See [3 
4  5  6  7  8  9  10  11  12  13  14  15]  references therein  and [16] for a recent survey). Here
the goal is to characterize the minimum number of samples necessary (sample complexity)
as a function of the domain size k  and the other parameters.
At the same time  preserving the privacy of individuals who contribute to the data samples
has emerged as one of the key challenges in designing statistical mechanisms over the last few
years. For example  the privacy of individuals participating in surveys on sensitive subjects
úThe authors are listed in alphabetical order. This research was supported by NSF-CCF-CRII

1657471  and a grant from Cornell University.

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

is of utmost importance. Without a properly designed mechanism  statistical processing
might divulge the sensitive information about the data. There have been many publicized
instances of individual data being de-anonymized  including the deanonymization of Netﬂix
database [17]  and individual information from census-related data [18]. Protecting privacy
for the purposes of data release  or even computation on data has been studied extensively
across several ﬁelds  including statistics  machine learning  database theory  algorithm design 
and cryptography (See e.g.  [19  20  21  22  23  24  25]). While the motivation is clear  even
a formal notion of privacy is not straight forward. We use dierential privacy [26]  a notion
which rose from database and cryptography literature  and has emerged as one of the most
popular privacy measures (See [26  27  22  28  29  30  31  32]  references therein  and the
recent book [33]). Roughly speaking  it requires that the output of the algorithm should be
statistically close on two neighboring datasets. For a formal deﬁnition of dierential privacy 
see Section 2.
A natural question when designing a dierentially private algorithm is to understand how
the data requirement grows to ensure privacy  along with the same accuracy. In this paper 
we study the sample size requirements for dierentially private discrete distribution testing.

1.1 Results and Techniques
We consider two fundamental statistical tasks for testing distributions over [k]: (i) identity
testing  where given sample access to an unknown distribution p  and a known distribution
q  the goal is to decide whether p = q  or dT V (p  q) Ø –  and (ii) closeness testing  where
given sample access to unknown distributions p  and q  the goal is to decide whether p = q 
or dT V (p  q) Ø –. (See Section 2 for precise statements of these problems). Given dierential
privacy constraints (Á  ”)  we provide (Á  ”)-dierentially private algorithms for both these
tasks. For identity testing  our bounds are optimal up to constant factors for all ranges of
k  –  Á  ”   and for closeness testing the results are tight in the small sample regime where
m = O(k). Our upper bounds are based on various methods to privatize the previously
known tests. A critical component is to design and analyze test statistic that have low
sensitivity (see Deﬁnition 4)  in order to preserve privacy.
We ﬁrst state that any (Á + ”  0)-DP algorithm is also an (Á  ”) algorithm. [34] showed that
for testing problems  any (Á  ”) algorithm will also imply a (Á + c”  0)-DP algorithm. Please
refer to Lemma 2 and Lemma 3 for more detail. Therefore  for all the problems  we simply
consider (Á  0)-DP algorithms (Á-DP)  and we can replace Á with (Á + ”) in both the upper
and lower bounds without loss of generality.
One of the main contributions of our work is to propose a general framework for establishing
lower bounds for the sample complexity of statistical problems such as property estimation
and hypothesis testing under privacy constraints. We describe this  and the other results
below. A summary of the results is presented in Table 1  which we now describe in detail.
1. DP Lower Bounds via Coupling. We establish a general method to prove lower
bounds for distribution testing problems. Suppose X m1   and Y m1 are generated by two
statistical sources. Further suppose there is a coupling between the two sources such
that the expected hamming distance between the coupled samples is at most D  then if
Á + ” = o(1/D)  there is no (Á  ”)-dierentially private algorithm to distinguish between
the two sources. This result is stated precisely in Theorem 1. By carefully using designed
coupling schemes  we provide lower bounds for identity testing  and closeness testing.
2. Reduction from identity to uniformity. We reduce the problem of Á-DP identity
testing of distributions over [k] to Á-DP uniformity testing over distributions over [6k].
Such a reduction  without privacy constraints was shown in [35]  and we use their result
to obtain a reduction that also preserves privacy  with at most a constant factor blow-up
in the sample complexity. This result is given in Theorem 3.

3. Identity Testing. It was recently shown that O(Ôk

–2 ) [7  36  11  37] samples are necessary
and sucient for identity testing without privacy constraints. The statistic used in these
papers are variants of chi-squared tests  which could have a high global sensitivity.
Given the reduction from identity to uniformity  it suces to consider uniformity testing.
We consider the test statistic studied by [38] which is simply the distance of the empirical
distribution to the uniform distribution. This statistic also has a low sensitivity  and

2

futhermore has the optimal sample complexity in all parameter ranges  without privacy
constraints. In Theorem 2  we state the optimal sample complexity of identity testing.
The upper bounds are derived by privatizing the statistic in [38]. For lower bound  we use
our technique in Theorem 1. We design a coupling between the uniform distribution u[k] 
and a mixture of distributions  which are all at distance – from u[k] in total variation
distance. In particular  we consider the mixture distribution used in [7]. Much of the
technical details go into proving the existence of couplings with small expected Hamming
distance. [34] studied identity testing under pure dierential privacy  and obtained an

bounds signiﬁcantly.
Ôk

4. Closeness Testing. Closeness testing problem was proposed by [3]  and optimal bound

algorithm with complexity O3Ôk
of 1max{ k2/3
of 1 k2/3
–4/3 + Ôk

–5/3Á2/3 4. Our results improve their
–2 }2 was shown in [10]. They proposed a chi-square based statistic 
–2Á2. These
–ÔÁ2  and in the dense regime  we obtain a bound of O1Ôk

which we show has a small sensitivity. We privatize their algorithm to obtain the
sample complexity bounds. In the sparse regime we prove a sample complexity bound

results are stated in Theorem 4. Since closeness testing is a harder problem than identity
testing  all the lower bounds from identity testing port over to closeness testing. The
closeness testing lower bounds are given in Theorem 4.

–2 + Ôk log k

–3/2Á + (k log k)1/3

–2 + 1

–4/3  

Problem

Identity Testing

Closeness Testing

Sample Complexity Bounds

–22 [7]
Non-private : 1Ôk
–3/2Á 4 [34]
Á-DP algorithms: O3Ôk
–2 + Ôk log k
–2 + maxÓ k1/2
S(IT  k – Á ) =1Ôk
k1/3
–4/3Á2/3   1
–Á1/2  
–2 2 [10]
Non-private: 1 k2/3
–4/3 + k1/2
IF –2 =1 1Ôk2 and –2Á =! 1
k"
–ÔÁ2
S(CT  k – Á ) =1 k2/3
–4/3 + Ôk
–Á2 Æ S(CT  k – Á ) Æ O1Ôk
1Ôk
–2 + Ôk

Á-DP algorithms:

–ÔÁ + 1

–2 + 1

ELSE

–ÁÔ2[Theorem 2]

–2Á2 [Theorem 4]

Table 1: Summary of the sample complexity bounds for Á-DP identity  and closeness testing.
For (Á  ”)-DP algorithms  we can simply replace Á in the sample complexity by (Á + ”).

1.2 Related Work
A number of papers have recently studied hypothesis testing problems under dierential
privacy guarantees [39  40  41]. Some works analyze the distribution of the test statistic in
the asymptotic regime. The work most closely related to ours is [34]  which studied identity
testing in the ﬁnite sample regime. We mentioned their guarantees along with our results on
identity testing in the previous section.
There has been a line of research for statistical testing and estimation problems under the
notion of local dierential privacy [24  23  42  43  44  45  46  47  48  49]. These papers study
some basic statistical problems and provide minimax lower bounds using Fano’s inequality. [50]
studies structured distribution estimation under dierential privacy. Information theoretic
approaches to data privacy have been studied recently using quantities like mutual information 
and guessing probability to quantify privacy [51  52  53  54  55].
[56  57] provide methods to prove lower bounds on DP algorithms via packing. Recently  [58]
use coupling to prove lower bounds on the sample complexity for dierentially private
conﬁdence intervals. Our results are more general  in that  we can handle mixtures of
distributions  which can provide optimal lower bounds on identity testing. [59  60] characterize

3

dierential privacy through a coupling argument. [61] also uses the idea of coupling implicitly
when designing dierentially private partition algorithms. [62] uses our coupling argument
to prove lower bounds for dierentially private property estimation problems.
In a contemporaneous and independent work  [63]  the authors study the same problems that
we consider  and obtain the same upper bounds for the sparse case  when m Æ k. They also
provide experimental results to show the performance of the privatized algorithms. However 
their results are sub-optimal for m =( k) for identity testing  and they do not provide any
lower bounds for the problems. Both [34]  and [63] consider only pure-dierential privacy 
which are a special case of our results.
Organization of the paper. In Section 2  we discuss the deﬁnitions and notations. A
general technique for proving lower bounds for dierentially private algorithms is described
in Section 3. Section 4 gives upper and lower bounds for identity testing  and closeness
testing is studied in Section 5.

2Îp ≠ qÎ1.

2 Preliminaries
Let k be the class of all discrete distributions over a domain of size k  which wlog is assumed
to be [k] := {1  . . .  k}. We denote length-m samples X1  . . .  Xm by X m1 . For x œ [k]  let
px be the probability of x under p. Let Mx(X m1 ) be the number of times x appears in
X m1 . For A ™ [k]  let p(A) = qxœA px. Let X ≥ p denote that the random variable X
has distribution p. Let u[k] be the uniform distribution over [k]  and B(b) be the Bernoulli
distribution with bias b. The total variation distance between distributions p  and q over [k]
is dT V (p  q) := supAµ[k]{p(A) ≠ q(A)} = 1
Deﬁnition 1. Let p  and q be distributions over X  and Y respectively. A coupling between
p and q is a distribution over X◊Y whose marginals are p and q respectively.
Deﬁnition 2. The Hamming distance between two sequences X m1 and Y m1
is dH(X m1   Y m1 ) :=
qm
i=1 I{Xi ”= Yi}  the number of positions where X m1   and Y m1 dier.
Deﬁnition 3. A randomized algorithm A on a set X m æS is said to be (Á  ”)-dierentially
private if for any S µ range(A)  and all pairs of X m1   and Y m1 with dH(X m1   Y m1 ) Æ 1 such
that Pr (A(X m1 ) œ S) Æ eÁ · Pr (A(Y m1 ) œ S) + ”.
The case when ” = 0 is called pure dierential privacy. For simplicity  we denote pure
dierential privacy as Á-dierential privacy (Á-DP).
Next we state the group property of dierential privacy. We give a proof in Appendix A.1.
Lemma 1. Let A be a (Á  ”)-DP algorithm 
then for sequences xm1   and ym1 with
dH(xm1   ym1 ) Æ t  and ’S µ range(A)  Pr (A(xm1 ) œ S) Æ etÁ · Pr (A(ym1 ) œ S) + ”teÁ(t≠1).
The next two lemmas state a relationship between (Á  ”) and Á-dierential privacy. We give
a proof of Lemma 2 in Appendix A.2. And Lemma 3 follows from [34].
Lemma 2. Any (Á + ”  0)- dierentially private algorithm is also (Á  ”)-dierentially private.
Lemma 3. An (Á  ”)-DP algorithm for a testing problem can be converted to an (Á + c”  0)
algorithm for some constant c > 0.
Combining these two results  it suces to prove bounds for (Á  0)-DP  and plug in Á with
(Á + ”) to obtain bounds that are tight up to constant factors for (Á  ”)-DP.
The notion of sensitivity is useful in establishing bounds under dierential privacy.
Deﬁnition 4. The sensitivity of f : [k]m æ R is

(f) := maxdH(Xm

1  Y m

1 )Æ1 |f(X m1 ) ≠ f(Y m1 )| .

For x œ R  ‡(x) :=
follow from the deﬁnition of ‡.

1+exp(≠x) = exp(x)

1

1+exp(x) is the sigmoid function. The following properties

4

Lemma 4.

2. Let 0 <÷< 1

1. For all x  “ œ R  exp(≠| “|) Æ ‡(x+“)

‡(x) Æ exp(|“|).

2. Suppose x Ø log 1

÷. Then ‡(x) > 1 ≠ ÷.

Identity Testing (IT). Given description of q œ k over [k]  parameters –  and m
independent samples X m1 from unknown p œ k. A is an (k  –)-identity testing algorithm for
q  if when p = q  A outputs “p = q” with probability at least 0.9  and when dT V (p  q) Ø – 
A outputs “p ”= q” with probability at least 0.9.
Deﬁnition 5. The sample complexity of DP-identity testing  denoted S(IT  k – Á )  is the
smallest m for which there exists an Á-DP algorithm A that uses m samples to achieve
(k  –)-identity testing. Without privacy concerns  S(IT  k – ) denotes the sample complexity.
When q = u[k]  the problem reduces to uniformity testing  and the sample complexity is
denoted as S(UT  k – Á ).
Closeness Testing (CT). Given m independent samples X m1   and Y m1
from unknown
distributions p  and q. An algorithm A is an (k  –)-closeness testing algorithm if when p = q 
A outputs p = q with probability at least 0.9  and when dT V (p  q) Ø –  A outputs p ”= q
with probability at least 0.9.
Deﬁnition 6. The sample complexity of DP-closeness testing  denoted S(CT  k – Á )  is the
smallest m for which there exists an Á-DP algorithm A that uses m samples to achieve
(k  –)-closeness testing. When privacy is not a concern  we denote the sample complexity of
closeness testing as S(CT  k – ).
Hypothesis Testing (HT). Suppose we have distributions p and q over X m  and X m1 ≥
p  Y m1 ≥ q  we say an algorithm A : X m æ{ p  q} can distinguish between p and q if
Pr (A(X m1 ) = q) < 0.1 and Pr (A(Y m1 ) = p) < 0.1.
3 Privacy Bounds Via Coupling
Recall that coupling between distributions p and q over X  and Y  is a distribution over
X◊Y whose marginal distributions are p and q (Deﬁnition 1). For simplicity  we treat
coupling as a randomized function f : XæY such that if X ≥ p  then Y = f(X) ≥ q. Note
that X  and Y are not necessarily independent.
Example 1. Let B(b1)  and B(b2) be Bernoulli distributions with bias b1  and b2 such that
b1 < b2. Let p  and q be distributions over {0  1}m obtained by m i.i.d. samples from B(b1) 
and B(b2) respectively. Let X m1 be distributed according to p. Generate a sequence Y m1 as
follows: If Xi = 1  then Yi = 1. If Xi = 0  we ﬂip another coin with bias (b2≠b1)/(1≠b1)  and
let Yi be the output of this coin. Repeat the process independently for each i  such that the
Yi’s are all independent of each other. Then Pr (Yi = 1) = b1 +(1≠ b1)(b2 ≠ b1)/(1≠ b1) = b2 
and Y m1
We would like to use coupling to prove lower bounds on dierentially private algorithms for
testing problems. Let p and q be distributions over X m. If there is a coupling between p
and q with a small expected Hamming distance  we might expect that the algorithm cannot
have strong privacy guarantees. The following theorem formalizes this intuition:
Theorem 1. Suppose there is a coupling between p and q over X m  such that
E [dH(X m1   Y m1 )] Æ D where X m1 ≥ p  Y m1 ≥ q. Then  any (Á  ”)-dierentially private
hypothesis testing algorithm A : X m æ{ p  q} on p and q must satisfy Á + ” =! 1
D"
Proof. Let (X m1   Y m1 ) be distributed according to a coupling of p  and q with
E [dH(X m1   Y m1 )] Æ D.
inequality  Pr (dH(X m1   Y m1 ) > 10D) <
Pr (dH(X m1   Y m1 ) > 10 · E [dH(X m1   Y m1 )]) < 0.1. Let xm1 and ym1 be the realization of X m1
and Y m1 . Let W = {(xm1   ym1 )|dH(xm1   ym1 ) Æ 10D}. Then we have
1 = ym

1 ) · Pr (A(xm
By Lemma 1  and Pr (dH(X m1   Y m1 ) > 10D) < 0.1  and Pr (A(ym1 ) = q) Æ 1 

1 ) = q) Ø ÿ(xm

is distributed according to q.

0.1 Ø Pr (A(X m

Pr (X m

1 = xm

1   Y m

By Markov’s

1 ) = q).

1  ym

1 )œW

5

1 ) = q) + ÿ(xm

1 ) · Pr (A(ym
1 ) · (eÁ·10D Pr (A(xm

1  ym

1 ) /œW

1 ) = q) + 10D” · eÁ·10(D≠1)) + 0.1

Pr (xm

1   ym

1 ) · 1

Pr (A(Y m

1  ym

1  ym

1 )œW

1   ym

1   ym

Pr (xm

Pr (xm

1 ) = q) Æ ÿ(xm
Æ ÿ(xm
Æ 0.1eÁ·10D + 10D” · eÁ·10D + 0.1.
Á+”2  proving the theorem.

1 )œW

Á   1

Since we know Pr (A(Y m1 ) = q) > 0.9  then 0.9 < Pr (A(Y m1 ) = q) < 0.1eÁ·10D + 10D” ·
eÁ·10D + 0.1. Hence  either eÁ·10D = (1) or 10D” = (1)  which implies that D =
!min) 1

”*" =1 1

Set ” = 0  we obtain the bound for pure dierential privacy. In the next few sections  we use
this theorem to get sample complexity bounds for dierentially private testing problems.

4 Identity Testing
In this section  we prove the bounds for identity testing. Our main result is the following.
Theorem 2.

Or we can write it according to the parameter range 

–Á1/2  

k1/3
–4/3Á2/3   1

–2 + maxÓ k1/2

–ÁÔ2.
S(IT  k – Á ) =1 k1/2
–Á1/22 
–4" and k =! 1
when k =! 1
–2Á" 
–4/3Á2/32  when k =! –
Á" and k = O! 1
–Á2 
when k = O! –
Á".

–2 + k1/2
–2 + k1/3
–2 + 1

1Ôk
1Ôk
1Ôk

–4 + 1

–2Á" 

S(IT  k – Á ) =Y___]___[

Our bounds are tight up to constant factors in all parameters. To get the sample complexity
for (Á  ”)-dierential privacy  we can simply replace Á by (Á + ”).
In Theorem 3 we will show a reduction from identity to uniformity testing under pure
dierential privacy. Using this  it will be enough to design algorithms for uniformity testing 
which is done in Section 4.2.
Moreover since uniformity testing is a special case of identity testing  any lower bound for
uniformity will port over to identity  and we give such bounds in Section 4.3.

4.1 Uniformity Testing implies Identity Testing
The sample complexity of testing identity of any distribution is O(Ôk
–2 )  a bound that is
tight for the uniform distribution. Recently [35] proposed a scheme to reduce the problem
of testing identity of distributions over [k] for total variation distance – to the problem of
testing uniformity over [6k] with total variation parameter –/3. In other words  they show
that S(IT  k – ) Æ S(UT  6k  –/3). Building on [35]  we prove that a similar bound also holds
for dierentially private algorithms. The proof is in Appendix B.
Theorem 3. S(IT  k – Á ) Æ S(UT  6k  –/3 Á ).
Identity Testing – Upper Bounds
4.2
In this section  we will show that by privatizing the statistic proposed in [38] we can achieve
the sample complexity in Theorem 2 for all parameter ranges. The procedure is described in
Algorithm 1.

6

Recall that Mx(X m1 ) is the number of appearances of x in X m1 . Let

S(X m

1 ) := 1
2 ·

Mx(X m1 )

m

≠

nÿx=1----

1

k----  

be the TV distance from the empirical distribution to the uniform distribution. Let µ(p) =
E [S(X m1 )] when the samples are drawn from distribution p. They show the following
separation result on the expected value of S(X m1 ).
Lemma 5 ([38]). Let p be a distribution over [k] and dT V (p  u[k]) Ø –  then there is a
constant c such that

(1)

(2)

µ(p) ≠ µ(u[k]) Ø c–2 minÓ m2

k   1

k2   m

–Ô.

[38] used this result to show that thresholding S(X m1 ) at 0 is an optimal algorithm for
identity testing. We ﬁrst normalize the statistic to simplify the presentation of our DP
algorithm. Let

Z(X m

1 ) :=Y_]_[

k1S(X m1 ) ≠ µ(u[k]) ≠ 1
m!S(X m1 ) ≠ µ(u[k]) ≠ 1
m!S(X m1 ) ≠ µ(u[k]) ≠ 1

k2 2 
2 c–2 · m2
when m Æ k 
k "  when k < m Æ k
2 c–2 · m
2 c–" 
when m Ø k
–2 .

–2  

where c is the constant in Lemma 5  and µ(u[k]) is the expected value of S(X m1 ) when X m1
are drawn from uniform distribution.
Algorithm 1 Uniformity testing

Input: Á  –  i.i.d. samples X m1 from p

1: Let Z(X m1 ) be evaluated from (1)  and (2).
2: Generate Y ≥ B(‡(Á · Z))  ‡ is the sigmoid function.
3:

if Y = 0  return p = u[k]  else  return p ”= u[k].

m

≠ 1

k---. Changing any one symbol changes
k2 = 0(Xm

We now prove that this algorithm is Á-DP. We need the following sensitivity result.
Lemma 6. (Z) Æ 1 for all values of m  and k.
x=1--- Mx(Xm
2 ·qn
1 )
Proof. Recall that S(X m1 ) = 1
at most two of the Mx(X m1 )’s. Therefore at most two of the terms change by at most
m. Therefore  (S(X m1 )) Æ 1
1
m  for any m. When m Æ k  this can be strengthened
with observation that Mx(X m1 )/m Ø 1
k  for all Mx(X m1 ) Ø 1. Therefore  S(X m1 ) = 1
2 ·
k2 +qx:Mx(Xm
1qx:Mx(Xm
≠ 1
  where 0(X m1 ) is the number
of symbols not appearing in X m1 . This changes by at most one when one symbol is changed 
proving the result.
Using this lemma  Á · Z(X m1 ) changes by at most Á when X m1
is changed at one location.
Invoking Lemma 4  the probability of any output changes by a multiplicative exp(Á)  and
the algorithm is Á-dierentially private.
To prove the sample complexity bound  we ﬁrst show that the mean of the test statistic is
well separated using Lemma 5. Then we use the concentration bound of the test statistic
from [38] to get the ﬁnal complexity. Due to lack of space  the detailed proof of sample
complexity bound is given in Appendix C.

1 )Ø11 Mx(Xm

1 )=0

1 )

1 )

m

1

k

4.3 Sample Complexity Lower bounds for Uniformity Testing
In this section  we will show the lower bound part of Theorem 2. The ﬁrst term is the lower
bound without privacy constraints  proved in [7]. In this section  we will prove the terms
associated with privacy.

7

–Á).

The simplest argument is for m Ø k
–2   which hopefully will give you a sense of how coupling
argument works. We consider the case of binary identity testing where the goal is to test
whether the bias of a coin is 1/2 or –-far from 1/2. This is a special case of identity testing
for distributions over [k] (when k ≠ 2 symbols have probability zero). This is strictly harder
than the problem of distinguishing between B(1/2) and B(1/2 + –). The coupling given in
Example 1 has expected hamming distance of –m. Hence combing with Theorem 1  we get
a lower bound of ( 1
We now consider the cases m Æ k and k < m Æ k
–2 .
To this end  we invoke LeCam’s two point theorem  and design a hypothesis testing problem
that will imply a lower bound on uniformity testing. The testing problem will be to distinguish
between the following two cases.
Case 1: We are given m independent samples from the uniform distribution u[k].
Case 2: Generate a distribution p with dT V (p  u[k]) Ø – according to some prior over all
such distributions. We are then given m independent samples from this distribution p.
Le Cam’s two point theorem [64] states that any lower bound for distinguishing between
these two cases is a lower bound on identity testing problem.
We now describe the prior construction for Case 2  which is the same as considered by [7]
for lower bounds on identity testing without privacy considerations. For each z œ {±1}k/2 
deﬁne a distribution pz over [k] such that
pz(2i ≠ 1) = 1 + zi · 2–

  and pz(2i) = 1 ≠ zi · 2–

k

.

k

Then for any z  dT V (Pz  u[k]) = –. For Case 2  choose p uniformly from these 2k/2
distributions. Let Q2 denote the distribution on [k]m by this process. In other words  Q2 is
a mixture of product distributions over [k].
In Case 1  let Q1 be the distribution of m i.i.d. samples from u[k].
To obtain a sample complexity lower bound for distinguishing the two cases  we will design
a coupling between Q1  and Q2  and bound its expected Hamming distance. While it can be
shown that the Hamming distance of the coupling between the uniform distribution with
any one of the 2k/2 distributions grows as –m  it can be signiﬁcantly smaller  when we
consider the mixtures. In particular  the following lemma shows that there exist couplings
with bounded Hamming distance.
Lemma 7. There is a coupling between X m1 generated by Q1  and Y m1

by Q2 such that

E [dH(X m1   Y m1 )] Æ C · –2 min{ m2

k   m3/2
k1/2 }.

The lemma is proved in Appendix D. Now applying Theorem 1  we get the bound in
Theorem 2.

5 Closeness Testing
Recall the closeness testing problem from Section 2  and the tight non-private bounds from
Table 1. Our main result in this section is the following theorem characterizing the sample
complexity of dierentially private algorithms for closeness testing.
Theorem 4. If –> 1/k1/4  and Á–2 > 1/k 

otherwise 

S(CT  k – Á ) =3 k2/3
–ÔÁ4 
–4/3 + k1/2
–Á4 Æ S(CT  k – Á ) Æ O3 k1/2
+ 1

–2Á4.
–2 + 1

3 k1/2

–2 + k1/2
–ÔÁ

8

This theorem shows that in the sparse regime  when m = O(k)  our bounds are tight up to
constant factors in all parameters. To prove the upper bounds  we only consider the case
when ” = 0  which would suce by lemma 2. We privatize the closeness testing algorithm
of [10]. To reduce the strain on the readers  we drop the sequence notations explicitly and let

The statistic used by [10] is

µi := Mi(X m

1 )  and ‹i := Mi(Y m
1 ).

Z(X m

1   Y m

1 ) := ÿiœ[k]

(µi ≠ ‹i)2 ≠ µi ≠ ‹i

µi + ‹i

 

where we assume that ((µi ≠ ‹i)2 ≠ µi ≠ ‹i)/(µi + ‹i) = 0  when µi + ‹i = 0. It turns out
that this statistic has a constant sensitivity  as shown in Lemma 8.
Lemma 8. (Z(X m1   Y m1 )) Æ 14.
Proof. Since Z(X m1   Y m1 ) is symmetric  without loss of generality assume that one of the
symbols is changed in Y m1 . This would cause at most two of the ‹i’s to change. Suppose
‹i Ø 1  and it changed to ‹i ≠ 1. Suppose  µi + ‹i > 1  the absolute change in the ith term
of the statistic is

(µi ≠ ‹i)2
µi + ‹i ≠

----

(µi ≠ ‹i + 1)2

µi + ‹i ≠ 1 ---- =----
Æ----

Æ

(µi + ‹i)(2µi ≠ 2‹i + 1) + (µi ≠ ‹i)2
µi + ‹i ≠ 1 ---- +----
2µi ≠ 2‹i + 1
3|µi ≠ ‹i| + 1
µi + ‹i ≠ 1 Æ 3 +

(µi + ‹i)(µi + ‹i ≠ 1)
µi + ‹i ≠ 1----
µi ≠ ‹i
4
µi + ‹i ≠ 1 Æ 7.

----

When µi + ‹i = 1  the change can again be bounded by 7. Since at most two of the ‹i’s
change  we obtain the desired bound.

We use the same approach with the test statistic as with uniformity testing to obtain a
dierentially private closeness testing method  described in Algorithm 2. Since the sensitivity
of the statistic is at most 14  the input to the sigmoid changes by at most Á when any
input sample is changed. Invoking Lemma 4  the probability of any output changes by a
multiplicative exp(Á)  and the algorithm is Á-dierentially private.

Algorithm 2

Input: Á  –  sample access to distribution p and q

m2–2
4k+2m)/14

1: ZÕ Ω (Z(X m1   Y m1 ) ≠ 1
2
2: Generate Y ≥ B(‡(exp(Á · ZÕ))
if Y = 0  return p = q
3:
4: else  return p ”= q

The remaining part is to show that Algorithm 2 satisﬁes sample complexity upper bounds
described in theorem 4. We will give the details in Appendix E  where the analysis of the
lower bound is also given.

Acknowledgement
The authors thank Gautam Kamath for some very helpful suggestions about this work.

9

References
[1] Jerzy Neyman and Egon Sharpe Pearson. On the problem of the most ecient tests of
statistical hypotheses. Philosophical Transactions of the Royal Society of London. Series
A  Containing Papers of a Mathematical or Physical Character  231:289–337  1933.

[2] Erich Leo Lehmann and George Casella. Theory of Point Estimation  volume 31.

Springer  2006.

[3] Tukan Batu  Lance Fortnow  Ronitt Rubinfeld  Warren D. Smith  and Patrick White.
Testing that distributions are close. In Proceedings of the 41st Annual IEEE Symposium
on Foundations of Computer Science  FOCS ’00  pages 259–269  Washington  DC  USA 
2000. IEEE Computer Society.

[4] Tukan Batu  Eldar Fischer  Lance Fortnow  Ravi Kumar  Ronitt Rubinfeld  and Patrick
White. Testing random variables for independence and identity. In Proceedings of the
42nd Annual IEEE Symposium on Foundations of Computer Science  FOCS ’01  pages
442–451  Washington  DC  USA  2001. IEEE Computer Society.

[5] Oded Goldreich and Dana Ron. On testing expansion in bounded-degree graphs.
In Studies in Complexity and Cryptography. Miscellanea on the Interplay between
Randomness and Computation  pages 68–75. Springer  2011.

[6] Tugkan Batu. Testing properties of distributions. PhD thesis  Cornell University  2001.
[7] Liam Paninski. A coincidence-based test for uniformity given very sparsely sampled

discrete data. IEEE Transactions on Information Theory  54(10):4750–4755  2008.

[8] Jayadev Acharya  Ashkan Jafarpour  Alon Orlitsky  and Ananda Theertha Suresh. A
competitive test for uniformity of monotone distributions. In Proceedings of the 16th
International Conference on Artiﬁcial Intelligence and Statistics  2013.

[9] Jayadev Acharya  Ashkan Jafarpour  Alon Orlitksy  and Ananda Theertha Suresh. Sub-
linear algorithms for outlier detection and generalized closeness testing. In Proceedings
of the 2014 IEEE International Symposium on Information Theory  2014.

[10] Siu-On Chan  Ilias Diakonikolas  Gregory Valiant  and Paul Valiant. Optimal algorithms
for testing closeness of discrete distributions. In Proceedings of the 25th Annual ACM-
SIAM Symposium on Discrete Algorithms  SODA ’14  pages 1193–1203  Philadelphia 
PA  USA  2014. SIAM.

[11] Ilias Diakonikolas  Daniel M. Kane  and Vladimir Nikishkin. Testing identity of struc-
tured distributions. In Proceedings of the 26th Annual ACM-SIAM Symposium on
Discrete Algorithms  SODA ’15  pages 1841–1854  Philadelphia  PA  USA  2015. SIAM.
[12] Bhaswar Bhattacharya and Gregory Valiant. Testing closeness with unequal sized
In Advances in Neural Information Processing Systems  NIPS ’15  pages

samples.
2611–2619. Curran Associates  Inc.  2015.

[13] Clément L. Canonne  Ilias Diakonikolas  Themis Gouleakis  and Ronitt Rubinfeld.
Testing shape restrictions of discrete distributions. In Proceedings of the 33rd Symposium
on Theoretical Aspects of Computer Science  STACS ’16  pages 25:1–25:14  Dagstuhl 
Germany  2016. Schloss Dagstuhl–Leibniz-Zentrum fuer Informatik.

[14] Ilias Diakonikolas and Daniel M. Kane. A new approach for testing properties of discrete
distributions. In Proceedings of the 57th Annual IEEE Symposium on Foundations
of Computer Science  FOCS ’16  pages 685–694  Washington  DC  USA  2016. IEEE
Computer Society.

[15] Tukan Batu and Clément L. Canonne. Generalized uniformity testing. In Proceedings
of the 58th Annual IEEE Symposium on Foundations of Computer Science  FOCS ’17 
pages 880–889  Washington  DC  USA  2017. IEEE Computer Society.

10

[16] Clément L. Canonne. A survey on distribution testing: Your data is big. but is it blue?

Electronic Colloquium on Computational Complexity (ECCC)  22(63):63  2015.

[17] Arvind Narayanan and Vitaly Shmatikov. Robust de-anonymization of large sparse
datasets. In Proceesings of the 29th IEEE Symposium on Security and Privacy  pages
111–125  2008.

[18] Latanya Sweeney. k-anonymity: A model for protecting privacy. International Journal

of Uncertainty  Fuzziness and Knowledge-Based Systems  10(05):557–570  2002.

[19] Stanley L Warner. Randomized response: A survey technique for eliminating evasive

answer bias. Journal of the American Statistical Association  60(309):63–69  1965.

[20] Tore Dalenius. Towards a methodology for statistical disclosure control. Statistisk

Tidskrift  15:429–444  1977.

[21] Irit Dinur and Kobbi Nissim. Revealing information while preserving privacy.

In
Proceedings of the 22nd ACM SIGMOD-SIGACT-SIGART Symposium on Principles of
Database Systems  PODS ’03  pages 202–210  New York  NY  USA  2003. ACM.

[22] Larry Wasserman and Shuheng Zhou. A statistical framework for dierential privacy.

Journal of the American Statistical Association  105(489):375–389  2010.

[23] John C Duchi  Michael I Jordan  and Martin J Wainwright. Local privacy and statistical
minimax rates. In Proceedings of the 54st Annual IEEE Symposium on Foundations of
Computer Science  FOCS ’13  pages 429–438. IEEE  2013.

[24] Martin J Wainwright  Michael I Jordan  and John C Duchi. Privacy aware learning. In

Advances in Neural Information Processing Systems  pages 1430–1438  2012.

[25] Kamalika Chaudhuri  Claire Monteleoni  and Anand D Sarwate. Dierentially private
empirical risk minimization. Journal of Machine Learning Research  12:1069–1109  2011.
[26] Cynthia Dwork  Frank McSherry  Kobbi Nissim  and Adam Smith. Calibrating noise to
sensitivity in private data analysis. In Proceedings of the 3rd Conference on Theory of
Cryptography  TCC ’06  pages 265–284  Berlin  Heidelberg  2006. Springer.

[27] Cynthia Dwork. Dierential privacy: A survey of results. In Proceedings of the 5th
International Conference on Theory and Applications of Models of Computation  TAMC
’08  pages 1–19  Berlin  Heidelberg  2008. Springer.

[28] Cynthia Dwork  Guy N. Rothblum  and Salil Vadhan. Boosting and dierential privacy.
In Proceedings of the 51st Annual IEEE Symposium on Foundations of Computer Science 
FOCS ’10  pages 51–60  Washington  DC  USA  2010. IEEE Computer Society.

[29] Avrim Blum  Katrina Ligett  and Aaron Roth. A learning theory approach to noninter-

active database privacy. Journal of the ACM (JACM)  60(2):12  2013.

[30] Frank McSherry and Kunal Talwar. Mechanism design via dierential privacy. In 48th
Annual IEEE Symposium on Foundations of Computer Science  pages 94–103. IEEE 
2007.

[31] Chao Li  Gerome Miklau  Michael Hay  Andrew McGregor  and Vibhor Rastogi. The
matrix mechanism: Optimizing linear counting queries under dierential privacy. The
VLDB Journal  24(6):757–781  2015.

[32] Peter Kairouz  Sewoong Oh  and Pramod Viswanath. The composition theorem for
dierential privacy. IEEE Transactions on Information Theory  63(6):4037–4049  2017.
[33] Cynthia Dwork and Aaron Roth. The algorithmic foundations of dierential privacy.

Foundations and Trends R• in Theoretical Computer Science  9(3–4):211–407  2014.
[34] Bryan Cai  Constantinos Daskalakis  and Gautam Kamath. Priv’it: Private and sample
ecient identity testing. In Proceedings of the 34th International Conference on Machine
Learning  ICML ’17  pages 635–644. JMLR  Inc.  2017.

11

[35] Oded Goldreich. The uniform distribution is complete with respect to testing identity
to a ﬁxed distribution. In Electronic Colloquium on Computational Complexity (ECCC) 
volume 23  2016.

[36] Gregory Valiant and Paul Valiant. An automatic inequality prover and instance optimal
identity testing. In Proceedings of the 55th Annual IEEE Symposium on Foundations of
Computer Science  pages 51–60. IEEE  2014.

[37] Jayadev Acharya  Constantinos Daskalakis  and Gautam C Kamath. Optimal testing
for properties of distributions. In Advances in Neural Information Processing Systems 
NIPS ’15  pages 3577–3598. Curran Associates  Inc.  2015.

[38] Ilias Diakonikolas  Themis Gouleakis  John Peebles  and Eric Price. Sample-optimal
identity testing with high probability. In Proceedings of the 45th International Colloquium
on Automata  Languages  and Programming  ICALP ’18  pages 41:1–41:14  2018.

[39] Yue Wang  Jaewoo Lee  and Daniel Kifer. Revisiting dierentially private hypothesis

tests for categorical data. arXiv preprint arXiv:1511.03376  2015.

[40] Marco Gaboardi  Hyun-Woo Lim  Ryan M. Rogers  and Salil P. Vadhan. Dierentially
private chi-squared hypothesis testing: Goodness of ﬁt and independence testing. In
Proceedings of the 33rd International Conference on Machine Learning  ICML ’16  pages
1395–1403. JMLR  Inc.  2016.

[41] Ryan Rogers and Daniel Kifer. A New Class of Private Chi-Square Hypothesis Tests.
In Aarti Singh and Jerry Zhu  editors  Proceedings of the 20th International Conference
on Artiﬁcial Intelligence and Statistics  volume 54 of Proceedings of Machine Learning
Research  pages 991–1000  Fort Lauderdale  FL  USA  20–22 Apr 2017. PMLR.

[42] Úlfar Erlingsson  Vasyl Pihur  and Aleksandra Korolova. RAPPOR: Randomized
aggregatable privacy-preserving ordinal response. In Proceedings of the 2014 ACM
Conference on Computer and Communications Security  CCS ’14  pages 1054–1067 
New York  NY  USA  2014. ACM.

[43] Adriano Pastore and Michael Gastpar. Locally dierentially-private distribution estima-
tion. In Proceedings of the 2016 IEEE International Symposium on Information Theory 
pages 2694–2698  2016.

[44] Peter Kairouz  Keith Bonawitz  and Daniel Ramage. Discrete distribution estimation
under local privacy. In Proceedings of the 33rd International Conference on International
Conference on Machine Learning - Volume 48  ICML’16  pages 2436–2444  2016.

[45] Shaowei Wang  Liusheng Huang  Pengzhan Wang  Yiwen Nie  Hongli Xu  Wei Yang 
Xiang-Yang Li  and Chunming Qiao. Mutual information optimally local private discrete
distribution estimation. arXiv preprint arXiv:1607.08025  2016.

[46] Min Ye and Alexander Barg. Optimal schemes for discrete distribution estimation under
locally dierential privacy. IEEE Transactions on Information Theory  64:5662–5676 
2018.

[47] Jayadev Acharya  Ziteng Sun  and Huanyu Zhang. Hadamard response: Estimat-
ing distributions privately  eciently  and with little communication. arXiv preprint
arXiv:1802.04705  2018.

[48] Or Sheet. Locally private hypothesis testing. In Proceedings of the 35th International
Conference on Machine Learning  volume 80  pages 4612–4621. PMLR  10–15 Jul 2018.
[49] Jayadev Acharya  Clément L Canonne  Cody Freitag  and Himanshu Tyagi. Test without
trust: Optimal locally private distribution testing. arXiv preprint arXiv:1808.02174 
2018.

[50] Ilias Diakonikolas  Moritz Hardt  and Ludwig Schmidt. Dierentially private learning of
structured discrete distributions. In Advances in Neural Information Processing Systems
28  NIPS ’15  pages 2566–2574. Curran Associates  Inc.  2015.

12

[51] Darakhshan J Mir. Information-theoretic foundations of dierential privacy. In Interna-

tional Symposium on Foundations and Practice of Security  pages 374–381  2012.

[52] Lalitha Sankar  S Raj Rajagopalan  and H Vincent Poor. Utility-privacy tradeos in
databases: An information-theoretic approach. IEEE Transactions on Information
Forensics and Security  8(6):838–852  2013.

[53] Paul Cu and Lanqing Yu. Dierential privacy as a mutual information constraint. In
ACM SIGSAC Conference on Computer and Communications Security  pages 43–54.
ACM  2016.

[54] Weina Wang  Lei Ying  and Junshan Zhang. On the relation between identiﬁability 
dierential privacy  and mutual-information privacy. IEEE Transactions on Information
Theory  62(9):5018–5029  2016.

[55] Ibrahim Issa and Aaron B. Wagner. Operational deﬁnitions for some common infor-
mation leakage metrics. In Proceedings of the 2017 IEEE International Symposium on
Information Theory  ISIT ’17  2017.

[56] Moritz Hardt and Kunal Talwar. On the geometry of dierential privacy. In Proceedings
of the Forty-Second ACM Symposium on Theory of Computing  pages 705–714. ACM 
2010.

[57] Salil Vadhan. The complexity of dierential privacy. In Yehuda Lindell  editor  Tutorials
on the Foundations of Cryptography: Dedicated to Oded Goldreich  chapter 7  pages
347–450. Springer International Publishing AG  Cham  Switzerland  2017.

[58] Vishesh Karwa and Salil Vadhan. Finite sample dierentially private conﬁdence intervals.
In Proceedings of the 9th Conference on Innovations in Theoretical Computer Science 
ITCS ’18  pages 44:1–44:9. Schloss Dagstuhl–Leibniz-Zentrum fuer Informatik  2018.

[59] Gilles Barthe  Marco Gaboardi  Benjamin Grégoire  Justin Hsu  and Pierre-Yves Strub.
Proving dierential privacy via probabilistic couplings. In Proceedings of the 31st Annual
ACM/IEEE Symposium on Logic in Computer Science  pages 749–758. ACM  2016.

[60] Gilles Barthe  Noémie Fong  Marco Gaboardi  Benjamin Grégoire  Justin Hsu  and Pierre-
Yves Strub. Advanced probabilistic couplings for dierential privacy. In Proceedings of
the 2016 ACM SIGSAC Conference on Computer and Communications Security  pages
55–67. ACM  2016.

[61] Cynthia Dwork  Moni Naor  Omer Reingold  and Guy N Rothblum. Pure dierential
privacy for rectangle queries via private partitions. In International Conference on
the Theory and Application of Cryptology and Information Security  pages 735–751.
Springer  2015.

[62] Jayadev Acharya  Gautam Kamath  Ziteng Sun  and Huanyu Zhang. INSPECTRE:
Privately estimating the unseen. In Jennifer Dy and Andreas Krause  editors  Proceedings
of the 35th International Conference on Machine Learning  volume 80 of Proceedings of
Machine Learning Research  pages 30–39  Stockholmsmässan  Stockholm Sweden  10–15
Jul 2018. PMLR.

[63] Maryam Aliakbarpour  Ilias Diakonikolas  and Ronitt Rubinfeld. Dierentially private
identity and equivalence testing of discrete distributions. In Proceedings of the 35th
International Conference on Machine Learning  pages 169–178  2018.

[64] Bin Yu. Assouad  Fano  and Le Cam. In Festschrift for Lucien Le Cam  pages 423–435.

Springer New York  1997.

[65] Jayadev Acharya  Alon Orlitsky  Ananda Theertha Suresh  and Himanshu Tyagi. Es-
timating Rényi entropy of discrete distributions. IEEE Transactions on Information
Theory  63(1):38–56  Jan 2017.

[66] Andreas Knoblauch. Closed-form expressions for the moments of the binomial probability

distribution. SIAM Journal on Applied Mathematics  69(1):197–204  2008.

13

[67] Frank den Hollander. Probability theory: The coupling method. Lecture notes available
online (http://websites. math. leidenuniv. nl/probability/lecturenotes/CouplingLectures.
pdf)  2012.

14

,Jayadev Acharya
Ziteng Sun
Huanyu Zhang