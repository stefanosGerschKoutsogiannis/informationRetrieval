2018,Zeroth-order (Non)-Convex Stochastic Optimization via Conditional Gradient and Gradient Updates,In this paper  we propose and analyze zeroth-order stochastic approximation algorithms for nonconvex and convex optimization. Specifically  we propose generalizations of the conditional gradient algorithm achieving rates similar to the standard stochastic gradient algorithm using only zeroth-order information. Furthermore  under a structural sparsity assumption  we first illustrate an implicit regularization phenomenon where the standard stochastic gradient algorithm with zeroth-order information adapts to the sparsity of the problem at hand by just varying the step-size. Next  we propose a truncated stochastic gradient algorithm with zeroth-order information  whose rate of convergence depends only poly-logarithmically on the dimensionality.,Zeroth-order (Non)-Convex Stochastic Optimization

via Conditional Gradient and Gradient Updates

Krishnakumar Balasubramanian

Department of Statistics

University of California  Davis

kbala@ucdavis.edu

Department of Operations Research and Financial Engineering

Saeed Ghadimi ⇤

Princeton University

sghadimi@princeton.edu

Abstract

In this paper  we propose and analyze zeroth-order stochastic approximation algo-
rithms for nonconvex and convex optimization. Speciﬁcally  we propose general-
izations of the conditional gradient algorithm achieving rates similar to the standard
stochastic gradient algorithm using only zeroth-order information. Furthermore 
under a structural sparsity assumption  we ﬁrst illustrate an implicit regularization
phenomenon where the standard stochastic gradient algorithm with zeroth-order
information adapts to the sparsity of the problem at hand by just varying the step-
size. Next  we propose a truncated stochastic gradient algorithm with zeroth-order
information  whose rate depends only poly-logarithmically on the dimensionality.

Introduction

1
In this work  we propose and analyze algorithms for solving the following stochastic optimization
problem

x2X⇢f (x) = E⇠[F (x  ⇠)] =Z F (x  ⇠) dP (⇠)  

min

(1.1)

where X is a closed convex subset of Rd. The case of nonconvex objective function f is ubiquitous
in modern deep learning problems and developing provable algorithms for such problems has been a
topic of intense research in the recent years [16  11]  along with the more standard convex case [1].
Several methods are available for solving such stochastic optimization problems under access to
different oracle information  for example  function queries (zeroth-order oracle)  gradient queries
(ﬁrst-order oracle)  and higher-order oracles. In this work  we assume that we only have access to
noisy evaluation of f through a stochastic zeroth-order oracle described in detail in Assumption 1.
This oracle setting is motivated by several applications where only noisy function queries of problem
(1.1) is available and obtaining higher-order information might not be possible. Such a situation
occurs frequently for example  in simulation based modeling [29]  selecting the tuning parameters
of deep neural networks [32] and design of black-box attacks to deep networks [3]. It is worth
noting that recently such zeroth-order optimization techniques have also been applied in the ﬁeld of
reinforcement learning [30  4  20]. Furthermore  methods using similar oracles have been studied in
the literature under the name of derivative-free optimization [33  5]  bayesian optimization [21] and
optimization with bandit feedback [2].

⇤Both authors contributed equally and are listed in alphabetical order.

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

Algorithm

ZSCG (Alg 1)

Modiﬁed ZSCG (Alg 3)

ZSGD (Alg 4)

Truncated ZSGD (Alg 5)

ZSGD

Structure
Nonconvex

Convex
Convex

O(d/✏4)
O(d/✏3)
O(d/✏2)

Nonconvex  s-sparse O(s log d)2/✏4
Os(log d/✏)2

Convex  s-sparse

Convex

Nonconvex

O(d/✏2)
O(d/✏4)

Theorem 2.1
Theorem 2.2
Theorem 3.1
Theorem 3.2

[18  7  9]

[9]

Function Queries

References

Table 1: A list of complexity bounds for stochastic zeroth-order methods to ﬁnd an ✏-stationary or
✏-optimal (see Deﬁnition 1.1) point of problem (1.1).
Algorithms available for solving problem (1.1) also depend crucially on the constraint set X . First 
consider the case of X = Rd. When ﬁrst-order information is available  the rate of convergence of
the standard Gradient Descent (GD) algorithm is dimension-independent [26]. Whereas when only
the zeroth-order information is available  any algorithm (with estimated gradients) has (at least) linear
dependence on d [9  18  7]. This illustrates the main difference between the availability of different
oracle information. Next  note that depending on the geometry of the constraint set X   the cost of
computing the projection to the set might be prohibitive. This lead to the re-emergence of Conditional
Gradient (CG) algorithms recently [12  15]. But the performance of the CG algorithm under the
zeroth-order oracle is unexplored in the literature to the best of our knowledge  both under convex and
nonconvex settings. Hence it is natural to ask if CG algorithms  with access to zeroth-order oracle has
similar (or better) convergence rates compared to GD algorithms with zeroth-order information. We
propose and analyze in Section 2 a classical version of CG algorithm with zeroth-order information
and present convergence results. We then propose a modiﬁcation in Section 2.2 that has improved
rates  when f is convex.
Notably  with zeroth-order information  the complexity of CG algorithms also depend linearly on
the dimensionality  similar to the GD algorithms. We refer to this situation as the low-dimensional
setting in the rest of the paper. This motivates us to examine assumptions under which one can
achieve weaker dependence on the dimensionality while optimizing with zeroth-order information.
In a recent work [34]  the authors used a functional sparsity assumption  under which the function
f : Rd ! R to be optimized depends only on s of the d components  and proposed a LASSO
based algorithm that has poly-logarithmic dependence on the dimensionality when f is convex. We
refer to this situation as the high-dimensional setting. In this work  we perform a reﬁned analysis
under a similar sparsity assumption for both convex and nonconvex objective functions. When the
performance is measured by the size of the gradient  we show in Section 3 that zeroth-order GD
algorithm (without using thresholding or LASSO approach of [34])  has poly-logarithmic dependence
on the dimensionality thereby demonstrating an implicit regularization phenomenon in this setting.
Note that this is applicable for both convex and nonconvex objectives. When the performance is
measured by function values (as in the case of convex objective)  we show that a simple thresholded
zeroth-order GD algorithm achieves a poly-logarithmic dependence on dimensionality. This algorithm
is notably less expensive than the algorithm proposed by [34].
Our contributions: To summarize the above discussion  in this paper we make the following contri-
butions to the literature on zeroth-order stochastic optimization: (i) We ﬁrst analyze a classical version
of CG algorithm in the nonconvex (and convex) setting  under access to zeroth-order information
and provide results on the convergence rates in the low-dimensional setting; (ii) We then propose
and analyze a modiﬁed CG algorithm in the convex setting with zeroth-order information and show
that it attains improved rates in the low-dimensional setting; (iii) Finally  we consider a zeroth-order
stochastic gradient algorithm in the high-dimensional nonconvex (and convex) setting and illustrate an
implicit regularization phenomenon. We also show that this algorithm achieves rates that depend only
poly-logarithmically on dimensionality. Our contributions extend the applicability of zeroth-order
stochastic optimization to the constrained and high-dimensional setting and also provide theoretical
insights in the form of rates of convergence. A summary of the results is provided in Table 1.

1.1 Preliminaries
We now list the main assumptions we make in this work. Additional assumptions will be introduced
in the appropriate sections as needed. We start with the assumption on the zeroth-order oracle.

2

⇤]  2  where k·k ⇤ denotes the dual norm.

Assumption 1 Let k·k be a norm on Rd. For any x 2 Rd  the zeroth-order oracle outputs an
estimator F (x  ⇠) of f (x) such that E[F (x  ⇠)] = f (x)  E[rF (x  ⇠)] = rf (x)  E[krF (x  ⇠) 
rf (x)k2
It should be noted that in the above assumption  we do not observe rF (x  ⇠) and we just assume that
it is an unbiased estimator of gradient of f and its variance is bounded. Furthermore  we make the
following smoothing assumption about the noisy estimation of f.

Assumption 2 Function F has Lipschitz continuous gradient with constant L  almost surely for any
⇠  i.e.  krF (y  ⇠)  rF (x  ⇠)k⇤  Lky  xk  which consequently implies that
|F (y  ⇠)  F (x  ⇠)  hrF (x  ⇠)  y  xi|  L
It is easy to see that the above two assumptions imply that f also has Lipschitz continuous gradient
with constant L since

2 ky  xk2.

krf (y)  rf (x)k⇤  E [krF (y  ⇠)  rF (x  ⇠)k⇤]  Lky  xk

(1.2)
due the Jensen’s inequality for the dual norm. We now collect some facts about a gradient estimator
based on the above zeroth-order information. Let u ⇠ N (0  Id) be a standard Gaussian random vector.
For some ⌫ 2 (0 1) consider the smoothed function f⌫(x) = Eu [f (x + ⌫u)]. Nesterov [27] has
shown that rf⌫(x) =
Eu f (x + ⌫u)

2 du.
(1.3)
This relation implies that we can estimate gradient of f⌫ by only using evaluations of f. In particular 
one can deﬁne stochastic gradient of f⌫(x) as

u = Eu f (x + ⌫u)  f (x)

1

(2⇡)d/2Z f (x + ⌫u)  f (x)

u =

u e kuk2

2

⌫

⌫

⌫

F (x + ⌫u ⇠ )  F (x  ⇠)
which is an unbiased estimator of rf⌫(x) under Assumption 1 since

G⌫(x  ⇠  u) =

⌫

u 

(1.4)

Eu ⇠[G⌫(x  ⇠  u)] = Eu[ f (x+⌫u)f (x)

⌫

u] = rf⌫(x).

We leverage some properties of f⌫ due to Nesterov [27] in our proofs later  that we replicate in the
supplementary material (Section A) for convenience. Finally  we deﬁne the following criterion which
are used to analyze the complexity of our proposed algorithms.
Deﬁnition 1.1 Assume that a solution ¯x 2X as output of an algorithm and a target accuracy ✏> 0
are given. Then: (i) If f is nonconvex  ¯x is called an ✏-stationary point of the unconstrained variant
of problem (1.1) if E[krf (¯x)k⇤]  ✏. For the constrained case  ¯x should satisﬁes E[hrf (¯x)  ¯x 
ui]  ✏ for all u 2X ; (ii) If f is convex  ¯x is called an ✏-optimal point of problem (1.1) if
E[f (¯x)]  f (x⇤)  ✏  where x⇤ denotes an optimal solution of the problem.
It should be pointed out that while the above performance measures are presented in expectation
form  one can also use their high probability counterparts. Since  convergence results in this case
can be obtained by making sub-Gaussian tail assumptions on the output of the zeroth-order oracle
and using the standard two-stage process presented in [9  19]  we do not elaborate more on this
approach. Furthermore  note that the aforementioned measures for evaluating the algorithms are from
the derivative-free optimization point of view. In the literature on optimization with bandit feedback 
the preferred performance measure is the so-called regret of the algorithm [2  31] which may have a
different behavior than our performance measures.
2 Zeroth-order Stochastic Conditional Gradient Type Method
In this section  we study zeroth-order stochastic conditional gradient (ZSCG) algorithms in the
low-dimensional setting for solving constrained stochastic optimization problems. In particular  we
incorporate a variant of the gradient estimate deﬁned in (1.4) into the framework of the classical CG
method and provide its convergence analysis in Subsection 2.1. We also present improved rates for a
variant of this method in Subsection 2.2 when f is convex. Throughout this section  we assume that
Rd is equipped with the self-dual Euclidean norm i.e.  k·k = k·k 2. We also make the following
natural boundedness assumption.

3

Algorithm 1 Zeroth-order Stochastic Conditional Gradient Method

Input: z0 2X   smoothing parameter ⌫> 0  non-negative sequence ↵k  positive integer sequence
mk  iteration limit N  1 and probability distribution PR(·) over {1  . . .   N}.
for k = 1  . . .   N do

1. Generate uk = [uk 1  . . .   uk mk ]  where uk j ⇠ N (0  Id)  call the stochastic oracle to

according to (1.4) and take their average:

compute mk stochastic gradient Gk j
⌫

¯Gk
⌫ ⌘ ¯G⌫(zk1 ⇠ k  uk) =

2. Compute

1
mk

mkXj=1

F (zk1 + ⌫uk j ⇠ k j)  F (zk1 ⇠ k j)

⌫

uk j.

(2.1)

xk = argmin

u2X h ¯Gk

⌫  ui 

zk = (1  ↵k)zk1 + ↵kxk.

end for
Output: Generate R according to PR(·) and output zR.

(2.2)

(2.3)

Assumption 3 The feasible set X is bounded such that maxx y2X ky xk  DX for some DX > 0.
Moreover  for all x 2X   there exists a constant B > 0 such that krf (x)k  B.
We should point out that under Assumptions 1 and 2  the second statement in Assumption 3 follows
immediately by the ﬁrst one and choosing B := LDX + krf (x⇤)k. However  we just use B in our
analysis for simplicity.

2.1 Zeroth-order Stochastic Conditional Gradient Method
The vanilla ZSCG method is formally presented in Algorithm 1 and a few remarks about it follows.
First  note that this algorithm differs from the classical CG method in estimating the gradient using
zeroth-order information and in outputting a random solution from the generated trajectory. This
randomization scheme is the current practice in the literature to provide convergence results for
nonconvex stochastic optimization (see e.g.  [9  28]). Second  ¯Gk
⌫ is the averaged variant of the
gradient estimator presented in Subsection 1.1 and is still an unbiased estimator of rf⌫(zk1).
Moreover  it can be easily seen that it has a reduced variance with respect to the individual estimators
i.e. 

E[k ¯Gk

⌫  rf⌫(zk1)k2] 

E[kGk j

⌫  rf⌫(zk1)k2].

1
mk

(2.4)

We emphasize that the use of the above variance reduction technique in stochastic CG methods is
standard and has been previously proposed and leveraged in several works (see e.g.  [19  13  28 
22  23  10]). Indeed  when exact gradient is not available  an error term appears in the convergence
analysis which should converge to 0 at a certain rate as the algorithm moves forward. Hence  the
choice of mk plays a key role in the convergence analysis of Algorithm 1. ¯Gk
⌫ can be also viewed
as a biased estimator for rf (zk1). Finally  since f is possibly nonconvex  we need a different
criteria than the optimality gap to provide convergence analysis of Algorithm 1. The well-known
Frank-Wolfe Gap given by

gk
X ⌘ g

X

(zk1) := hrf (zk1)  zk1  ˆxki  where ˆxk = argmin

u2X hrf (zk1)  ui 

(2.5)

has been widely use in the literature to show rate of convergence of the CG methods when f is convex
(see e.g.  [8  6  14]). In this case  it is easy to see that
f (zk1)  f⇤  g

(2.6)
(zk1)  8u 2X  
When f is nonconvex  this criteria is still useful since hrf (zk1)  zk1  ui  g
which implies that one can obtain an approximate stationary point of problem (1.1) by minimizing
  in the view of Deﬁnition 1.1. Note that in our setting  this quantity is not exactly computable and
gk
X
it is only used to provide convergence analysis of Algorithm 1 as shown in the next result.
Theorem 2.1 Let {zk}k0 be generated by Algorithm 1 and Assumptions 1  2  and 3 hold.

(zk1).

X

X

4

1. Let f be nonconvex  bounded from below by f⇤  and let the parameters of the algorithm be

set as

⌫ =s 2BL

N (d + 3)3  ↵ k =

1
pN

  mk = 2BL(d + 5)N  8k  1

(2.7)

we have

for some constant BL  max{pB2 + 2/L  1} and a given iteration bound N  1. Then

X + 2pB2 + 2
f (z0)  f⇤ + LD2
pN

E[gR
X

(2.8)
where R is uniformly distributed over {1  . . .   N} and gk is deﬁned in (2.5). Hence  the
total number of calls to the zeroth-order stochastic oracle and linear subproblems required
to be solved to ﬁnd an ✏-stationary point of problem (1.1) are  respectively  bounded by

] 

 

✏4◆   O✓ 1
O✓ d
✏2◆ .

2. Let f be convex and let the parameters be set to

⌫ =s 2BL

N 2(d + 3)3  ↵ k =

6

k + 5

  mk = 2BL(d + 5)N 2  8k  1.

(2.10)

Then we have

E[f (zN )]  f⇤ + E[gR

X

] 

120[f (z0)  f (x⇤)]

(N + 3)3

+

36LD2
X
N + 5

+

pB2 + 2

N

(2.11)

where R is random variable from {1  . . .   N} whose probability distribution is given by

PR(R = k) =

↵kN

2N (1  N )

 

k =

kYi=1⇣1 

↵i

2⌘   0 = 1.

Hence  the total number of calls to the zeroth-order stochastic oracle and linear subproblems
required to be solved to ﬁnd and ✏-optimal solution of problem (1.1) are  respectively 
bounded by

✏3◆   O✓ 1
O✓ d
✏◆ .

(2.9)

(2.12)

(2.13)

Remark 1 Observe that the complexity bounds in (2.9)  in terms of ✏  match the ones obtained in
[10  28  23] for stochastic CG method with ﬁrst-order oracle applied to nonconvex problems. For
convex problems  similar observation can be made for terms in (2.13) which match the ones in
[13  10]. Note that the linear dependence of our complexity bounds on d is unimprovable due to the
lower bounds for zeorth-order algorithms applied to convex optimization problems [7]. We conjecture
that this is also the case for nonconvex problems.

Improved Rates for Convex Problems

2.2
Our goal in this subsection is to improve the complexity bounds of the ZCSG method when f is
convex. Recall that the ZSCG method presented in Section 2.1 involves two main steps: the gradient
evaluation step and the linear optimization step. Motivated by [19]  we now propose a modiﬁed
algorithm that allows one to skip the gradient evaluation from time to time. Notice that  as our
gradients are estimated by calling the zeroth-order oracle  this directly reduces the number of calls to
the zeroth-order oracle. We ﬁrst state a subroutine in Algorithm 2 used in our modiﬁed algorithm.
Note that Algorithm 2 is indeed the zeroth-order conditional gradient method for inexactly solving
the following quadratic program

PX (x  g  ) = argmin

u2X nhg  ui +



2ku  xk2o  

(2.15)

which is the standard subproblem of stochastic ﬁrst-order methods applied to a minimization problem
when g is an unbiased stochastic gradient of the objective function at x. We now present Algorithm 3
which applies the CG method to inexactly solve subproblems of the stochastic accelerated gradient

5

Algorithm 2 Inexact Conditional Gradient (ICG) method

Input: (x  g    µ).
Set ¯y0 = x  t = 1  and  = 0..
while  = 0 do

yt = argmin

u2X {h(u) := hg + (¯yt1  x)  u  ¯yt1i}
t+1 yt and t = t + 1.

If h(yt)  µ  set  = 1.
Else ¯yt = t1

t+1 ¯yt1 + 2

(2.14)

end while
Output ¯yt.

method. This way of using CG methods can signiﬁcantly improve the total number of calls to the
stochastic oracle. Our next result provides convergence analysis of this algorithm.

Algorithm 3 Zeroth-order Stochastic Accelerated Gradient Method with Inexact Updates

Input:z0 = x0 2X   smoothing parameter ⌫> 0  sequences ↵k  mk  k  µk  and iteration limit
N  1.
for k = 1  . . .   N do
1. Set

(2.16)
2. Generate uk = [uk 1  . . .   uk mk ]  where uk j ⇠ N (0  Id)  call the stochastic oracle mk

times to compute ¯Gk

wk = (1  ↵k)zk1 + ↵kxk1
⌫ ⌘ ¯G⌫(wk ⇠ k  uk) as given by (2.1)  and set
⌫  k  µk) 
where ICG(·) is the output of Algorithm 2 with input (xk1  ¯Gk
zk = (1  ↵k)zk1 + ↵kxk

xk = ICG(xk1  ¯Gk

3. Set

(2.17)

(2.18)

⌫  k).

end for
Output: zN

Theorem 2.2 Let {zk}k1 be generated by Algorithm 3  the function f be convex  and
 s D0
d(N + 1))

max( 1

LD0
X
kN

1
p2N

  µk =

  k =

↵k =

4L
k

 ⌫ =

2

k + 1

d + 3

X

mk =

k(k + 1)

D0
X

and for some constants D0
Assumptions 1  2  and 3  we have

max{(d + 5)BLN  d + 3}   8k  1 
X  kx0  x⇤k2 and BL  max{pB2 + 2/L  1}. Then under

(2.19)

E[f (zN )  f (x⇤)] 

12LD0
X
N (N + 1)

.

(2.20)

Hence  the total number of calls to the stochastic oracle and linear subproblems solved to ﬁnd and
✏-stationary point of problem (1.1) are  respectively  bounded by

✏2◆   O✓ 1
O✓ d
✏◆ .

(2.21)

Remark 2 Observe that while the number of linear subproblems required to ﬁnd an ✏-optimal
solution of problem (1.1) is the same for both Algorithms 1 and 3  the number of calls to the stochastic
zeroth-order oracle in Algorithm 3 is signiﬁcantly smaller than that of Algorithm 1. It is also natural
to ask if such an improvement is achievable when f is nonconvex. This situation is more subtle and
the answer depends on the performance measure used to measure the rate of convergence. Indeed  we
can obtain improved complexity bounds for a different performance measure than the Frank-Wolfe

6

Algorithm 4 Zeroth-Order Stochastic Gradient Method

Input: x0 2 Rd  smoothing parameter ⌫> 0  iteration limit N  1  a probability distribution PR
supported on {0  . . .   N  1}.
for k =1  . . .   N do
in (1.4) and set xk = xk1  kG⌫(xk1 ⇠ k; uk).
end for
Output: Generate R according to PR(·) and output xR.

Generate uk ⇠ N (0  Id)  call the stochastic oracle  and compute G⌫(xk1 ⇠ k  uk) as deﬁned

gap with a modiﬁed algorithm. However  the complexity bounds are of the same order as (2.9) in
terms of the Frank-Wolfe gap for the modiﬁed algorithm. For the sake of completeness  we add this
algorithm and its convergence analysis in the supplementary material in Section D.

3 Zeroth-order Stochastic Gradient Methods
In this section  we study unconstrained variant of problem 1.1 i.e  X = Rd  under certain sparsity
assumptions on the objective function f to facilitate zeroth-order optimization in high-dimensions.
Recently  [34] considered the convex case and proposed algorithms for high-dimensional zeroth-order
stochastic optimization. Motivated by [34]  we make the following assumption.
Assumption 4 For any x 2 Rd  we have krf (x)k0  s  i.e.  the gradient is s-sparse  where s ⌧ d.
Note that the above assumption implies krf (x)k2  pskrf (x)k1 and krf (x)k1  skrf (x)k1 
for all x 2 Rd. Furthermore  this assumption also implies that krf⌫(x)k0  s for all x 2 Rd since
rf⌫(x) = Eu [rf (x + ⌫u)]. To exploit the above sparsity assumption  we assume that the primal
space Rd is equipped with the l1 norm throughout this section. More speciﬁcally  we assume that
Assumptions 1 and 2 hold with the choice of k·k = k·k 1 and its dual norm k·k ⇤ = k·k 1. We now
present zeroth-order stochastic gradient methods for solving problem (1.1) when f is nonconvex and
convex  in Subsections 3.1 and 3.2 respectively.

3.1 Zeroth-order Stochastic Gradient Method for Nonconvex Problems
In this subsection  we consider the zeroth-order stochastic gradient method presented in [9] (provided
in Algorithm 4 for convenience) and provide a reﬁned convergence analysis for it under the sparsity
assumption 1  when f is nonconvex. Our main convergence result for Algorithm 4 under the gradient
sparsity assumption is stated below.
Theorem 3.1 Let {xk}k0 be generated by Algorithm 4 and stepsizes are chosen such that 8k  1 
N ) (3.1)
 r D0
for some ˆs  s  ˆC  C (the universal constant deﬁned in Lemma C.1)  and D0  f (x0)  f⇤.
Assume that f is nonconvex. Then under Assumptions 1  2  and 4  we have

2N 29=;
 s D0L ˆC

min(r 22

 ⌫ 

2L ˆC log d

k =

L

1

1

150L ˆCD0ˆss(log d)2

(3.2)
where ⇣ = {⇠  u  R} and R is uniformly distributed over {0  . . .   N  1}. Hence  the total number of
calls to the stochastic oracle (number of iterations) required to ﬁnd an ✏-stationary point of problem
(1.1)  in the view of Deﬁnition 1.1  is bounded by

N

 

1

12ˆs log d

min8<:
E⇣⇥krf (xR)k2
1⇤ 

qL ˆC log d
54p2L ˆCD0 s log d

pN

+

O✓ (ˆs log d)2

✏4

◆ .

(3.3)

Remark 3 Note that the above theorem establishes rate of convergence of Algorithm 4 which only
poly-logarithmically depends on the problem dimension d  by just selecting the step-size appropriately 
under additional assumption that the gradient is sparse. This signiﬁcantly improves the linear
dimensionality dependence of the rate of convergence of this algorithm as presented in [9] for general
nonconvex smooth problems.

7

Algorithm 5 Truncated Zeroth-Order Stochastic Gradient Method

Given a positive integer ˆs  replace updating step of Algorithm 4 with
xk = Pˆs (xk1  kG⌫(xk1 ⇠ k; uk))  

where Pˆs(x) keeps the top ˆs largest absolute value of components of x and make the others 0.

(3.4)

Remark 4 Remarkably  Algorithm 4 does not require any special operation to adapt to the sparsity
assumption. This demonstrates an implicit regularization phenomenon exhibited by the zeroth-order
stochastic gradient method in the high-dimensional setting when the performance is measured by the
size of the gradient in the dual norm. We emphasize that the choice of the performance measure is
motivated by the fact that we allow f to be nonconvex. Trivially  the result also applies to the case
when f is convex  for the same performance measure.

3.2 Zeroth-order Stochastic Gradient Method for Convex Problems
We now consider the case when the function f is convex. In this setting  a more natural performance
measure is the convergence of optimality gap in terms of the function values. For this situation  we
propose and analyze a truncate variant of Algorithm 4 that demonstrates similar poly-logarithmic
dependence on the dimensionality. To proceed  in addition to Assumption 4  we also make the
following sparsity assumption on the optimal solution of problem (1.1).
Assumption 5 Problem (1.1) has a sparse optimal solution x⇤ such that kx⇤k0  s⇤  where s⇤ ⇡ s.
Our algorithm for the convex setting is presented in Algorithm 5. Note that this algorithm could be
considered as a truncated variant of Algorithm 4 and a zeroth-order stochastic variant of the truncated
gradient descent algorithm [17]. In the next result  we present convergence analysis of this algorithm.
Theorem 3.2 Let {xk}k1 be generated by Algorithm 4  f is convex  Assumptions 1  2  4  and 5
hold. Also assume the stepsizes are chosen such that  8k  1 
N ) (3.5)

3N 29=;
 s D0
for some ˆC  C  ˆs  max{s  s⇤}  and D0
X  kx0  x⇤k2.

min8<:

 r ˆs2D0

4 ˆC ˆs log d

12Lˆs log d

k =

ˆC ˆs

X

1

1

X

log d

 ⌫ plog d min( 
69q3 ˆCD0
pN

+

X ˆs log d

E [f (¯xN )  f⇤] 

52L ˆCD0

X ˆs2(log d)2
N

 

(3.6)

where ¯xN = PN1

N

k=0 xk

required to ﬁnd an ✏-optimal point of problem (1.1) is bounded by

. Hence  the total number of calls to the stochastic oracle (number of iterations)

O ˆs✓ log d

✏ ◆2! .

(3.7)

Remark 5 While for convex case  similar to the nonconvex case  the complexity of Algorithm 5
depends poly-logarithmically on d  it only linearly depends on the choice of ˆs  facilitating zeroth-order
stochastic optimization in high-dimensions under sparsity assumptions.

Remark 6 As discussed in detail in [34]  both Assumption 4 and 5 are implied when we assume the
function f depends on only s of the d coordinates. But  both Assumption 4 and 5 are comparatively
weaker than that assumption. Furthermore  unlike [34]  we do not make any assumption on the
sparsity or smoothness of the second-order derivative of the objective function f for our results.

Remark 7 As mentioned before  [34] considers only the convex case. Furthermore  their gradient
estimator with zeroth-order oracle requires poly(s  s⇤  log d) function queries in each iteration
whereas our estimator is based on only one function query per iteration. Moreover  [34] requires
computationally expensive debiased Lasso estimators whereas our method requires only simple
thresholding operations (for convex case) to handle sparsity.

8

4 Future Work
Two concrete extensions are possible for future work. First  for our results  we focus on performance
measures common in the optimization setting. It is interesting to extend our results to the bandit
setting  where the performance is measured via regret of the algorithm. Next  the performance
of conditional gradient algorithm in the high-dimensional constrained optimization setting is not
well-explored; the interaction between the geometry of the constraint set  sparsity structure and
zeroth-order information is extremely interesting to explore. Finally  lower bounds can be explored
for the cases considered in this paper when f is nonconvex.

in Machine Learning  8(3-4):231–357  2015.

References
[1] Sébastien Bubeck. Convex optimization: Algorithms and complexity. Foundations and Trends R
[2] Sébastien Bubeck and Nicolo Cesa-Bianchi. Regret analysis of stochastic and nonstochastic
multi-armed bandit problems. Foundations and Trends R in Machine Learning  5(1):1–122 
2012.
[3] Pin-Yu Chen  Huan Zhang  Yash Sharma  Jinfeng Yi  and Cho-Jui Hsieh. Zoo: Zeroth order
optimization based black-box attacks to deep neural networks without training substitute models.
In Proceedings of the 10th ACM Workshop on Artiﬁcial Intelligence and Security  pages 15–26.
ACM  2017.

[4] Krzysztof Choromanski  Mark Rowland  Vikas Sindhwani  Richard Turner  and Adrian Weller.
Structured evolution with compact architectures for scalable policy optimization. In Proceedings
of the 35th International Conference on Machine Learning. PMLR  2018.

[5] Andrew Conn  Katya Scheinberg  and Luis Vicente. Introduction to derivative-free optimization 

volume 8. Siam  2009.

[6] V. Demyanov and A. Rubinov. Approximate methods in optimization problems. American

Elsevier Publishing Co  1970.

[7] John Duchi  Michael Jordan  Martin Wainwright  and Andre Wibisono. Optimal rates for
zero-order convex optimization: The power of two function evaluations. IEEE Transactions on
Information Theory  61(5):2788–2806  2015.

[8] Marguerite Frank and Philip Wolfe. An algorithm for quadratic programming. Naval Research

Logistics Quarterly  3:95–110  1956.

[9] S. Ghadimi and G. Lan. Stochastic ﬁrst- and zeroth-order methods for nonconvex stochastic

programming. SIAM Journal on Optimization  23(4):2341–2368  2013.

[10] Saeed Ghadimi. Conditional gradient type methods for composite nonlinear and stochastic

optimization. Mathematical Programming  2018.

[11] Ian Goodfellow  Yoshua Bengio  Aaron Courville  and Yoshua Bengio. Deep learning  volume 1.

MIT press Cambridge  2016.

[12] Elad Hazan and Satyen Kale. Projection-free online learning. In Proceedings of the 29th
International Coference on International Conference on Machine Learning  pages 1843–1850.
Omnipress  2012.

[13] Elad Hazan and Haipeng Luo. Variance-reduced and projection-free stochastic optimization. In

International Conference on Machine Learning  pages 1263–1271  2016.

[14] Donald Hearn. The gap function of a convex program. Operations Research Letters  2  1982.
[15] Martin Jaggi. Revisiting frank-wolfe: Projection-free sparse convex optimization. In ICML (1) 

pages 427–435  2013.

[16] Prateek Jain and Purushottam Kar. Non-convex optimization for machine learning. Foundations

and Trends R in Machine Learning  10(3-4):142–336  2017.
[17] Prateek Jain  Ambuj Tewari  and Purushottam Kar. On iterative hard thresholding methods for
high-dimensional m-estimation. In Advances in Neural Information Processing Systems  pages
685–693  2014.

[18] Kevin Jamieson  Robert Nowak  and Ben Recht. Query complexity of derivative-free optimiza-

tion. In Advances in Neural Information Processing Systems  pages 2672–2680  2012.

9

[19] Guanghui Lan and Yi Zhou. Conditional gradient sliding for convex optimization. SIAM

Journal on Optimization  26(2):1379–1409  2016.

[20] Horia Mania  Aurelia Guy  and Benjamin Recht. Simple random search provides a competitive
approach to reinforcement learning. In Advances in Neural Information Processing Systems 
2018.

[21] Jonas Mockus. Bayesian approach to global optimization: theory and applications  volume 37.

Springer Science & Business Media  2012.

[22] Aryan Mokhtari  Hamed Hassani  and Amin Karbasi. Conditional gradient method for stochas-
In International Conference on Artiﬁcial

tic submodular maximization: Closing the gap.
Intelligence and Statistics  pages 1886–1895  2018.

[23] Aryan Mokhtari  Hamed Hassani  and Amin Karbasi. Stochastic conditional gradient methods:
From convex minimization to submodular maximization. arXiv preprint arXiv:1804.09554 
2018.

[24] A. S. Nemirovski and D. Yudin. Problem complexity and method efﬁciency in optimization.

Wiley-Interscience Series in Discrete Mathematics. John Wiley  XV  1983.

[25] Y. E. Nesterov.

Introductory Lectures on Convex Optimization: a basic course. Kluwer

Academic Publishers  Massachusetts  2004.

[26] Yurii Nesterov. Introductory lectures on convex optimization: A basic course  volume 87.

Springer Science & Business Media  2013.

[27] Yurii Nesterov and Vladimir Spokoiny. Random gradient-free minimization of convex functions.

Foundations of Computational Mathematics  17(2):527–566  2017.

[28] Sashank Reddi  Suvrit Sra  Barnabás Póczos  and Alexander Smola. Stochastic Frank-Wolfe
Methods for Nonconvex Optimization. 2016 54th Annual Allerton Conference on Communica-
tion  Control  and Computing (Allerton)  pages 1244–1251  2016.

[29] Reuven Rubinstein and Dirk Kroese. Simulation and the Monte Carlo method  volume 10. John

Wiley & Sons  2016.

[30] Tim Salimans  Jonathan Ho  Xi Chen  Szymon Sidor  and Ilya Sutskever. Evolution strategies

as a scalable alternative to reinforcement learning. arXiv preprint arXiv:1703.03864  2017.

[31] Ohad Shamir. On the complexity of bandit and derivative-free stochastic convex optimization.

In Conference on Learning Theory  pages 3–24  2013.

[32] Jasper Snoek  Hugo Larochelle  and Ryan Adams. Practical bayesian optimization of machine
learning algorithms. In Advances in neural information processing systems  pages 2951–2959 
2012.

[33] James Spall. Introduction to stochastic search and optimization: estimation  simulation  and

control  volume 65. John Wiley & Sons  2005.

[34] Yining Wang  Simon Du  Sivaraman Balakrishnan  and Aarti Singh. Stochastic zeroth-order
optimization in high dimensions. Proceedings of the Twenty-First International Conference on
Artiﬁcial Intelligence and Statistics  2018.

10

,Krishnakumar Balasubramanian
Saeed Ghadimi
Min-hwan Oh
Garud Iyengar