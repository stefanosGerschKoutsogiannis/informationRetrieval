2018,Optimistic optimization of a Brownian,We address the problem of optimizing a Brownian motion. We consider a (random) realization $W$ of a Brownian motion  with input space in $[0 1]$. Given $W$  our goal is to return an $\epsilon$-approximation of its maximum using the smallest possible number of function evaluations  the sample complexity of the algorithm. We provide an algorithm with sample complexity of order $\log^2(1/\epsilon)$. This improves over previous results of Al-Mharmah and Calvin (1996) and Calvin et al. (2017) which provided only polynomial rates. Our algorithm is adaptive---each query depends on previous values---and is an instance of the  optimism-in-the-face-of-uncertainty principle.,Optimistic Optimization of a Brownian

Jean-Bastien Grill

Michal Valko

R´emi Munos

SequeL team  INRIA Lille - Nord Europe  France and DeepMind Paris  France

jbgrill@google.com

michal.valko@inria.fr

munos@google.com

Abstract

We address the problem of optimizing a Brownian motion. We consider a (random)
realization W of a Brownian motion with input space in [0  1]. Given W   our goal
is to return an ε-approximation of its maximum using the smallest possible number
of function evaluations  the sample complexity of the algorithm. We provide an
algorithm with sample complexity of order log2(1/ε). This improves over previous
results of Al-Mharmah and Calvin (1996) and Calvin et al. (2017) which provided
only polynomial rates. Our algorithm is adaptive—each query depends on previous
values—and is an instance of the optimism-in-the-face-of-uncertainty principle.

1

Introduction to sample-efﬁcient Brownian optimization

We are interested in optimizing a sample of a standard Brownian motion on [0  1]  denoted by W.
More precisely  we want to sequentially select query points tn ∈ [0  1]  observe W (tn)  and decide

when to stop to return a point(cid:98)t and its value(cid:99)M = W(cid:0)(cid:98)t(cid:1) in order to well approximate its maximum
as early as possible while still being able to return(cid:98)t such that with probability at least 1 − ε 
M − W(cid:0)(cid:98)t(cid:1) ≤ ε. The number of function evaluations required by the algorithm to achieve this

M (cid:44) supt∈[0 1] W (t). The evaluations tn can be chosen adaptively as a function of previously
observed values W (t1)  ...  W (tn−1). Given an ε > 0  our goal is to stop evaluating the function

ε-approximation of the maximum deﬁnes the sample-complexity.
Motivation There are two types of situations where this problem is useful. The ﬁrst type is when the
random sample function W (drawn from the random process) already exists prior to the optimization.
Either it has been generated before the optimization starts and the queries correspond to reading
values of the function already stored somewhere. For example  ﬁnancial stocks are stored at a high
temporal resolution and we want to retrieve the maximum of a stock using a small number of memory
queries. Alternatively  the process physically exists and the queries correspond to measuring it.
Another situation is when the function does not exist prior to the optimization but is built simultane-
ously as it is optimized. In other words  observing the function actually creates it. An application of
this is when we want to return a sample of the maximum (and the location of the maximum) of a
Brownian motion conditioned on a set of already observed values. For example  in Bayesian optimiza-
tion for Gaussian processes  a technique called Thomson sampling (Thompson  1933; Chapelle and
Li  2011; Russo et al.  2018; Basu and Ghosh  2018) requires returning the maximum of a sampled
function drawn from the posterior distribution. The problem considered in the present paper can
be seen as a way to approximately perform this step in a computationally efﬁcient way when this
Gaussian process is a Brownian motion.
Moreover  even though our algorithm comes from the ideas of learning theory  it has applications
beyond it. For instance  in order to computationally sample a solution of a stochastic differential
equation  Hefter and Herzwurm (2017) express its solution as a function of the Brownian motion W
and its running minimum. They then need  as a subroutine  an algorithm for the optimization of
Brownian motion to compute its running minimum. We are giving them that and it is light-speed fast.

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montr´eal  Canada.

Prior work Al-Mharmah and Calvin (1996) provide a non-adaptive method to optimize a Brownian
motion. They prove that their method is optimal among all non-adaptive methods and their sample
ε. More recently  Calvin et al. (2017) provided an adaptive
complexity is polynomial of order 1/
algorithm with a sample complexity lower than any polynomial rate showing that adaptability to
previous samples yields a signiﬁcant algorithmic improvement. Yet their result does not guarantee a
better rate than a polynomial one.

√

Our contribution We introduce the algorithm OOB = optimistic optimization of the Brownian
motion. It uses the optimism-in-face-of-uncertainty apparatus: Given n − 1 points already eval-
uated  we deﬁne a set of functions Un in which W lies with high probability. We then select
the next query point tn where the maximum of the most optimistic function of Un is reached:
tn (cid:44) arg maxt∈[0 1] maxf∈Un f (t). This begets a simple algorithm that requires an expected number
of queries of the order of log2(1/ε) to return an ε-approximation of the maximum  with probability
at least 1 − ε w.r.t. the random sample of the Brownian motion. Therefore  our sample complexity is
better than any polynomial rate.

Solving an open problem Munos (2011) provided sample complexity results for optimizing any
function f characterized by two coefﬁcients (d  C) where d is the near-optimality dimension and C
the corresponding constant (see his Deﬁnition 3.1). It is deﬁned as the smallest d ≥ 0 such that
there exists a semi-metric (cid:96) and a constant C > 0  such that  for all ε > 0  the maximal number of
disjoint (cid:96)-balls of radius O(ε) with center in {x  f (x) ≥ supx f (x)− ε} is less than Cε−d. Under the
assumption that f is locally (around one global maximum) one-sided Lipschitz with respect to (cid:96) (see
his Assumption 2)  he proved that for a function f characterized by (d = 0  C)  his DOO algorithm
has a sample complexity of O(C log(1/ε))  whereas for a function characterized by (d > 0  C) 

the sample complexity of DOO is O(cid:0)C/εd(cid:1). Our result answers a question he raised: What is the

near-optimality dimension of a Brownian-motion? The Brownian motion being a stochastic process 
this quantity is a random variable so we consider the number of disjoint balls in expectation. We show
that for any ε  there exists some particular metric (cid:96)ε such that the Brownian motion W is (cid:96)ε-Lipschitz
with probability 1 − ε  and there exists a constant C(ε) = O(log(1/ε)) such that (d = 0  C(ε))
characterizes the Brownian motion. However  there exists no constant C < ∞ independent of ε such
that (d = 0  C) characterizes the Brownian motion. Therefore  we solved this open problem. Our
answer is compatible with our result that our algorithm has a sample complexity of O(log2(1/ε)).

2 New algorithm for Brownian optimization

Our algorithm OOB is a version of DOO (Munos  2011) with a modiﬁed upper bound on the function 
in order to be able to optimize stochastic processes. Consider the points t1 < t1 < ... < tn evaluated
so far and t0 = 0. OOB deﬁnes an upper conﬁdence bound B[ti ti+1] for each interval [ti  ti+1] with
i ∈ {0  ...  n − 1} and samples W in the middle of the interval with the highest upper-conﬁdence
bound. Algorithm 1 reveals its pseudo-code.

Algorithm 1 OOB algorithm
1: Input: ε
2: Init: I ← {[0  1]}  t1 = W (1)
3: for i = 2  3  4  . . . do
4:
5:
6:
7:
8:
9:
10: end for

[a  b] ∈ arg maxI∈I BI {break ties arbitrarily}
if ηε(b − a) ≤ ε then
end if
I ← {I ∪ [a  a+b

ti ← W(cid:0) a+b

break

(cid:1)

2

11: Output: location(cid:98)tε ← arg maxti W (ti) and its value W(cid:0)(cid:98)tε
(cid:1)

2   b]}\{[a  b]}

2 ] ∪ [ a+b

2

B[a b] (cid:44) max(W (a)  W (b)) + ηε(b − a)  where ∀δ > 0 s.t. εδ ≤ 1
2

More formally  let ε be the required precision  the only given argument of the algorithm. For any
(cid:115)
0 ≤ a < b ≤ 1  the interval [a  b] is associated with an upper bound B[a b] deﬁned by

(cid:19)
OOB keeps track of a set I of intervals [a  b] with W already being sampled at a and b. The algorithm
ﬁrst samples W (1)  W (1) ∼ N (0  1)  in order to initialize the set I to the singleton {[0  1]}. Then 
OOB keeps splitting the interval I ∈ I associated with the highest upper bound BI quam necessarium.

(cid:18) 2

ηε(δ) (cid:44)

5δ
2

εδ

ln

·

 

P(cid:2)M − W(cid:0)(cid:98)tε

(cid:1) > ε(cid:3) ≤ ε

3 Guarantees: OOB is correct and sample-efﬁcient

Let M (cid:44) supt∈[0 1] W (t) be the maximum of the Brownian motion (cid:98)tε the output of OOB called with

parameter ε > 0  and Nε the number of Brownian evaluations performed until OOB terminates. All
are random variables that depend on the Brownian motion W . We now voice our main result.
Theorem 1. There exists a constant c > 0 such that for all ε < 1/2 

and E[Nε] ≤ c log2(1/ε).

which is at most ε-away from the true maximum. Such guarantee is called probably approximately
correct (PAC). The second inequality quantiﬁes performance. We claim that the expectation (over W )

of the Brownian motion  our OOB is deterministic. The only source of randomness comes from the
realization of the Brownian. Therefore  being correct means that among all possible realizations of

The ﬁrst inequality quantiﬁes the correctness of our estimator (cid:99)Mε = W(cid:0)(cid:98)tε
(cid:1). Given a realization
the Brownian motion  there is a subset of measure at least 1− ε on which OOB outputs an estimate(cid:99)Mε
of the number of samples that OOB needs to optimize this realization with precision ε is O(cid:0)log2(1/ε)(cid:1).
min(δ  ε) and apply Theorem 1 for ε(cid:48) from which we get P(cid:2)M − W(cid:0)(cid:98)tε
(cid:1) > ε(cid:48)(cid:3) ≤ ε(cid:48) which is stronger
(cid:1) > ε(cid:3) ≤ δ. Similarly  E[Nε(cid:48)] ≤ c log2(1/ε(cid:48)) ≤ 4c(log(1/ε) + log(1/δ))2.
than P(cid:2)M − W(cid:0)(cid:98)tε
(cid:1) > ε(cid:12)(cid:12)W (t1)  ...  W (tNε )(cid:3) ≤ ε 
unfavorable cases  i.e.  the Brownian realizations for which(cid:12)(cid:12)M −(cid:99)Mε

Remark 1. Our PAC guarantee is actually stronger than stated in Theorem 1. Indeed  the PAC
guarantee analysis can be done conditioned on the collected function evaluations and get

Corollary 1. We get the classic (δ  ε)-PAC guarantee easily. For any δ > 0 and ε > 0  choose ε(cid:48) =

(cid:12)(cid:12) > ε  are not concentrated on

from which taking the expectation on both sides gives the ﬁrst part of Theorem 1. This means that the

P(cid:2)M − W(cid:0)(cid:98)tε

some subsets of Brownian realizations matching some evaluations in t1  ...  tNε. In other words  the
PAC guarantee also holds when restricted to the Brownian realizations matching the evaluations in
t1  ...  tNε only. This is possible because Nε is not ﬁxed but depends on the evaluations done by OOB.
One difference from the result of Calvin et al. (2017) is that theirs is with respect to the Lp norm. For

their algorithm  they prove that with n samples it returns(cid:98)tn ∈ [0  1] such that
∃cr p  E(cid:104)(cid:12)(cid:12)M − W ((cid:98)tn)(cid:12)(cid:12)p(cid:105)1/p ≤ cr p/nr.

∀r > 1  p > 1 

To express their result in the same formalism as ours  we ﬁrst choose to achieve accuracy ε2 and
compute the number of samples nε2 needed to achieve it. Then  for p = 1  we apply Markov
inequality and get that for all r > 1 there exists cr 1 such that

P(cid:2)M − W ((cid:98)tnε2 ) > ε(cid:3) ≤ ε

and Nε ≤ cr 1/ε1/r.

On the other hand  in our Theorem 1 we give a poly-logarithmic bound for the sample complexity
and we are in the business because this is better than any polynomial rate.

4 Analysis and the proof of the main theorem
We provide a proof of the main result. Let Iﬁn be the set I of intervals tracked by OOB when it ﬁnishes.
We deﬁne an event C such that for any interval I of the form I = [k/2h  (k + 1)/2h] with k and h
being two integers where 0 ≤ k < 2h  the process W is lower than BI on the interval I.

3

(cid:40)
Deﬁnition 1. Event C is deﬁned as
2h−1(cid:92)

∞(cid:92)

C (cid:44)

W (t) ≤ B[k/2h (k+1)/2h]

(cid:41)

·

sup

t∈[k/2h (k+1)/2h]

k=0

h=0

Event C is a proxy for the Lipschitz condition on W for the pseudo-distance d(x  y) =

(cid:112)|y − x| ln(1/|y − x|) because ηε(δ) scales with δ as (cid:112)δ ln (1/δ). We show that it holds

with high probability. To show it  we make use of the Brownian bridge which is the process
Br(t) (cid:44) (W (t)|W (1) = 0). Lemma 1 follows from the Markov property of the Brownian combined
with a bound on the law of the maximum of Br(t) to bound the probability P[supt∈I W (t) ≥ BI ] for
any I of the form [k/2h  (k + 1)/2h] and a union bound over all these intervals.
Lemma 1. For any ε  event C from Deﬁnition 1 holds with high probability. In particular 

P[Cc] ≤ ε5.

Proof. For any interval I 

BI = max(W (a)  W (b)) + ηε(b − a)

=

W (a) + W (b)

2

≥ W (a) + W (b)

2

+

+

|W (a) − W (b)|

(cid:115)(cid:18) W (a) − W (b)

2

(cid:19)2

+ ηε(b − a)

+ (ηε(b − a))2

2

(by deﬁnition of BI )
(max(x  y) = (x+y+|x−y|)/2)

(cid:0)∀x  y > 0  (x+y)2 ≥ x2 +y2(cid:1).

We now deﬁne

and

th k (cid:44) k
2h

 

Ah k (cid:44)

∆h k (cid:44) W (th k) − W (th k+1)
(cid:40)

2

 

ηh (cid:44) ηε(b − a) 

·

(cid:41)
(cid:18)
(cid:19)
− 2(x−Wa)(x−Wb)

·

sup

t∈[k/2h (k+1)/2h]

W (t) > B[k/2h (k+1)/2h]

(cid:34)

(cid:35)

= exp

b − a

W (t) > x

sup
t∈[a b]

P(cid:2)Ah k

First  for any a < b  the law of the maximum of a Brownian bridge gives us

∀x≥ max(W (a)  W (b)) : P
Combining it with the deﬁnition of Ah k and the ﬁrst inequality of the proof we get
(cid:113)

(cid:12)(cid:12)(cid:12)(cid:12)W (a) = Wa  W (b) = Wb
(cid:12)(cid:12)W (th  k)  W (th  k + 1)(cid:3)
(cid:16) W (th k+1)−W (th k)
(cid:113)
− 2
(cid:16)−2h+1(cid:16)(cid:113)
(cid:17)(cid:16)(cid:113)
(cid:18)
(cid:18) 2h
(cid:17)
(cid:16)−2h+1η2
(cid:83)2h−1
h k =(cid:83)∞
(cid:84)2h−1
By deﬁnition  C (cid:44)(cid:84)∞
k=0 Ah k. By union bound on all Ah k we get
k=0 Ac
P[Cc] ≤(cid:88)
P[Ah k] ≤(cid:88)
2h−1(cid:88)
2h−1(cid:88)

(cid:17)(cid:17)
(cid:17)5·
(cid:17)5 ≤(cid:88)

(cid:17)(cid:16) W (th k)−W (th k+1)

h − ∆h k
−2h+1
5

th k+1 − th k

2 · 2h ln

(cid:16) ε

(cid:16) ε

(cid:19)(cid:19)

h k + η2

h + ∆h k

∆2

h k + η2
h

∆2

h k + η2

∆2

h k + η2
h



≤ exp

= exp

h

=

2h

= exp

= exp

(cid:17)

2

+

2

+

∆2

ε

h=0

h=0

ε5

24h ≤ ε5.

h≥1

k=0

h≥1

k=0

2h

h≥1

Lemma 1 is useful for two reasons. As we bound the sample complexity on event C and the
complementary event in two different ways  we can use Lemma 1 to combine the two bounds to
prove Proposition 2 in the end. We also use a weak version of it  bounding ε5 by ε to prove our PAC
guarantee. For this purpose  we combine the deﬁnition of C with the termination condition of OOB to
Since C holds with high probability  we have the following PAC guarantee which is the ﬁrst part of
the main theorem.

get that under event C  the best point(cid:99)Mε so far  is close to the maximum M of the Brownian up to ε.

4

Proposition 1. The estimator(cid:99)Mε = W(cid:0)(cid:98)tε
(cid:1) is probably approximately correct with
P(cid:104)
M −(cid:99)Mε > ε

(cid:105) ≤ ε.

Proof. Let Inext = [a  b] be the interval that the algorithm would split next  if it was not
terminated. Since the algorithm only splits the interval with the highest upper bound then
Bnext = supI∈Iﬁn BI. Also let Imax ∈ Iﬁn be one of the intervals where a maximum is reached 
tmax ∈ arg maxt∈[0 1] W (t) (cid:44) M and tmax ∈ Imax. Then  on event C 

M ≤ BImax ≤ BInext = max(W (a)  W (b)) + ηε(b − a).
Since the algorithm terminated  we have that ηε(b − a) ≤ ε and therefore 

which combined with Lemma 1 ﬁnishes the proof as ε5 ≤ ε.

max(W (a)  W (b)) ≥ M − ε 

Nh(η) (cid:44)

(cid:18) k

(cid:19)

In fact  Proposition 1 is the easy-to-obtain part of the main theorem. We are now left to prove that
the number of samples needed to achieve this PAC guarantee is low. As the next step  we deﬁne the
near-optimality property. A point t is said to be η-near-optimal when its value W (t) is close to the
maximum M of the Brownian motion up to η. Check out the precise deﬁnition below.

(cid:1) ≥ M−η  we say that the point t = (k/2h) is η-near-
Deﬁnition 2. When an (h  k  η) veriﬁes W(cid:0) k
optimal. We deﬁne Nh(η) as the number of η-near-optimal points among(cid:8)0/2h  1/2h  ...  2h/2h(cid:9) 

2h

k ∈ 0  ...  2h  such that W

(cid:12)(cid:12)(cid:12)(cid:12)(cid:26)
(cid:0)1/2h(cid:1)-near-optimal. Since we use the principle of optimism in face

Notice that Nh(η) is a random variable that depends on a particular realization of the Brownian
motion. The reason why we are interested in the number of near-optimal points is that the points the
algorithm will sample are ηε
of uncertainty  we consider the upper bound of the Brownian motion and sample where this upper
bound is the largest. If our bounds on W hold  i.e.  under event C  then any interval I with optimistic
bound BI < M is never split by the algorithm. This is true when C holds because if the maximum
of W is reached in Imax  then BImax ≥ M > BI which shows that Imax is always chosen over I.
Therefore  a necessary condition for an interval [a  b] to be split is that max(W (a)  W (b)) ≥ M − η
which means that either a or b or both are η-near-optimal which is the key point of Lemma 2.
Lemma 2. Under event C  the number of evaluated points Nε by the algorithm veriﬁes

(cid:27)(cid:12)(cid:12)(cid:12)(cid:12)·

≥ M − η

2h

(cid:16)

(cid:16)

1/2h(cid:17)(cid:17)

hmax(cid:88)

h=0

Nε ≤ 2

Nh

ηε

  with hmax being the smallest h such that ηε

(cid:16)
1/2h(cid:17) ≤ ε.

Lemma 2 explicitly links the near-optimality from Deﬁnition 2 with the number of samples Nε
performed by OOB before it terminates. Here  we use the optimism-in-face-of-uncertainty principle
which can be applied to any function. In particular  we deﬁne a high-probability event C under which
the number of samples is bounded by the number of near-optimal points Nh(ηh) for all h ≤ hmax.
Proof. Let I = [a  b] be an interval of It such that max(W (a)  W (b)) + ηε(b − a) < M. Let Inext ∈
It be the interval that the algorithm would split after t function evaluations.. Since the algorithm
only splits the interval with the highest upper bound  then BInext = supI∈It BI. Moreover  if we let
Imax ∈ It be one of the intervals where a maximum is reached  tmax ∈ arg maxt∈[0 1] W (t) (cid:44) M
and tmax ∈ Imax  then on event C 

max(W (a)  W (b)) + ηε(b − a) (cid:44) BI < M ≤ BImax ≤ BInext .

Therefore  under C  a necessary condition for an interval I = [a  b] to be split during the execution
of OOB is that max(W (a)  W (b)) ≥ M − ηε(b − a)  which means that either a or b or both are
ηε(b − a)-near-optimal. From the termination condition of the algorithm  we know that any interval
that is satisfying I = [k/2h  (k + 1)/2h] with h ≥ hmax will not be split during the execution.1
Therefore  another necessary condition for an interval I = [a  b] to be split during the execution is
that b − a > 1/2hmax. Writing ηh (cid:44) ηε

(cid:0)1/2h(cid:1)  we deduce from these two necessary conditions that

1This holds despite ηε(·) is not always decreasing.

5

h=0

2h−1(cid:88)
N ≤ hmax(cid:88)
2h−1(cid:88)
≤ hmax(cid:88)
2h(cid:88)
hmax(cid:88)

h=0

k=0

k=0

≤ 2

1

1

h=0

k=0

2h

(cid:26) k
2h or k + 1
(cid:26) k
(cid:26) k

is ηh-near-optimal

(cid:27)
(cid:26) k + 1
hmax(cid:88)

2h

h=0

(cid:27)
(cid:27)

2h is ηh-near-optimal

+ 1

1

2h is ηh-near-optimal

= 2

Nh(ηh).

(cid:27)

is ηh-near-optimal

We now prove a property speciﬁc to W by bounding the number of near-optimal points of the
Brownian motion in expectation. We do it by rewriting it as two Brownian meanders (Durrett et al. 
1977)  both starting at the maximum of the Brownian  one going backward and the other one forward
with the Brownian meander W + deﬁned as

∀t ∈ [0  1] W +(t) (cid:44) |W (τ + t(1 − τ ))|

√

1 − τ

  where τ (cid:44) sup{t ∈ [0  1] : W (t) = 0}.

We use that the Brownian meander W + can be seen as a Brownian motion conditioned to be positive
(Денисов  1983). This is the main ingredient of Lemma 3.
Lemma 3. For any h and η  the expected number of near-optimal points is bounded as

E[Nh(η)] ≤ 6η22h.

This lemma answers a question raised by Munos (2011): What is the near-optimality dimension
of the Brownian motion? We set ηh (cid:44) ηε
(cid:96)(x  y) = ηε(|y − x|)  the near-optimality dimension measures the rate of increase of Nh(ηh) 
the number of ηh-near-optimal points in [0  1] of the form k/2h. In Lemma 3  we prove that in

(cid:0)1/2h(cid:1). In dimension one with the pseudo-distance
h2h(cid:1) = O(log(1/ε))  which is constant with respect to h.

expectation  this number increases as O(cid:0)η2

This means that for a given ε  there is a metric under which the Brownian is Lipschitz with probability
at least 1 − ε and has a near-optimality dimension d = 0 with C = O(log(1/ε)).
The ﬁnal sample complexity bound is essentially constituted by one O(log(1/ε)) term coming from
the standard DOO error for deterministic function optimization and another O(log(1/ε)) term because
we need to adapt our pseudo-distance (cid:96) to ε such that the Brownian is (cid:96)-Lipschitz with probability

1 − ε. The product of the two gives the ﬁnal sample complexity bound of O(cid:0)log2(1/ε)(cid:1).

Proof of Lemma 3. We denote by W  the Brownian motion whose maximum M is ﬁrst hit at the
point deﬁned as tM = inf{t ∈ [0  1]; W (t) = M} and B+ a Brownian meander (Durrett et al.  1977).
We also deﬁne

0 (t) (cid:44) M − W (tM − t · tM ))

B+

and B+

1 (t) (cid:44) M − W (tM + t(1 − tM ))

√

·

√
tM

1 − tM

L
= denotes the equality in distribution  then Theorem 1 of Денисов (1983) asserts that

If

We upper-bound the expected number of η-near-optimal points for any integer h ≥ 0 and any η > 0 

B+ L

= B+
0

L
= B+

1 and tM is independent from both B+

0 and B+
1 .

W

1

 2h(cid:88)
(cid:26)
(cid:19)
(cid:18) k
(cid:26)(cid:26)
(cid:18)
(cid:26)

2h

k=0

W

(cid:18) k

(cid:19)

2h

(cid:19)

E[Nh(η)] = E

1

(cid:20)
(cid:20)

E

E

2h(cid:88)
2h(cid:88)

k=0

k=0

=

=

> M − η

> M − η ∩ k

2h ≤ tM

1

B+
0

1− k
tM 2h

<

η√
tM

2h ≤ tM
∩ k

(cid:27) =
(cid:27)

(cid:19)

k=0

2h(cid:88)
(cid:26)
(cid:27)(cid:21)

∪

E

W

W

2h

(cid:18) k
(cid:19)
(cid:20)

(cid:26)

1

(cid:20)
(cid:26)
(cid:18) k
2h(cid:88)

2h

E

+

k=0

1

B+
1

(cid:27)(cid:21)

> M − η

(cid:27)(cid:27)(cid:21)

> M − η ∩ k

2h > tM

(cid:18) k/2h−tM

(cid:19)

1 − tM

(cid:27)(cid:21)

.

<

η√
1−tM

∩ k

2h > tM

If X and Y are independent then for any function f 

E[f (X  Y )] = E[E[f (X  Y )|Y ]]

≤ supy E[f (X  y)|Y = y]
= supy E[f (X  y)].

(law of total expectation)
(for any Z  E[Z] ≤ supw Z(w))
(because X and Y are independent)

6

Since tM is independent from B+

0 and B+

1   then using the above with X = (B+

0   B+

1 )  Y = tM   and

(cid:18)

(cid:26)

(cid:18)

1

x0

(cid:19)

1− k
tM 2h

<

η√
y

∩ k
2h ≤ y

(cid:27)

(cid:26)

+1

x1

(cid:18) k/2h−tM

(cid:19)

1−y

<

η√
1−y

∩ k

2h > y

(cid:27)(cid:19)

 

we can claim that
E[Nh(η)] = E[f (X  Y )] ≤ sup
u∈[0 1]

∩ k

2h > u

η√
1 − u

∩ k
2h ≤ u

(cid:27)(cid:21)
(cid:27)(cid:21)
(cid:21) + sup
 2h(cid:88)
(cid:20)
(cid:21) = 2 sup
2 (cid:99)(cid:88)

k=(cid:100)u2h(cid:101)

u∈[0 1]

u∈[0 1]

(cid:98) u2h

P

P

  α2 =

(cid:21)

E[f (X  u)]

1

(cid:26)
(cid:20)
(cid:20)

1

(cid:18)

1 − k
u2h

(cid:19)
(cid:18) k/2h − u
(cid:19)
(cid:19)

1 − u

<

1 − k
u2h

1 − k
u2h

B+
0

B+
1

(cid:26)
(cid:18)
(cid:18)

B+
0

B+
0

(cid:20)

P

<

(cid:19)

η√
u

<

η√
u

<

η√
u

(cid:19)

(cid:18)
(cid:20)

(cid:18)

B+
0

1 − k
u2h

η√
u

<

(cid:19)

P

B+
0

1 − k
u2h

<

η√
u

(cid:21)

k=(cid:100)2hη2(cid:101)

  and α4 =

(cid:19)

(cid:18) k/2h − u

1 − u

B+
1

<

η√
1 − u

(cid:21)

{α1 + α2 + α3 + α4} 

(cid:20)
(cid:18)
(cid:98)u2h(cid:99)(cid:88)

B+
0

1 − k
u2h

(cid:19)

(cid:21)

η√
u

1 − k
u2h

(cid:19)

(cid:21)

·

<

η√
u

<

(cid:18)

(cid:20)

P

B+
0

k=(cid:98)u2h(cid:99)−(cid:98)2hη2(cid:99)

E

k=0

k=0

+ sup
u∈[0 1]

≤ sup
u∈[0 1]

f : (x0  x1)  y → 2h(cid:88)
 2h(cid:88)
(cid:20)
 2h(cid:88)
(cid:98)u2h(cid:99)(cid:88)
(cid:98)u2h(cid:99)(cid:88)
(cid:20)
(cid:98)2hη2(cid:99)(cid:88)
(cid:98)u2h(cid:99)−(cid:100)2hη2(cid:101)(cid:88)

= 2 sup
u∈[0 1]

= sup
u∈[0 1]

with α1 =

k=0

k=0

k=0

k=0

E

P

P

α3 =

2 (cid:101)
k=(cid:100) u2h

where the ﬁrst two inequalities are obtained by upperbounding the terms exp(·) by one. Now  we use
the above bound to bound α2 + α3 

Since a probability is always upper-bounded by 1  we bound α1 and α4 both by η22h  to get that
α1 + α4 ≤ 2η22h. We now bound the remaining probabilities appearing in the above expression by
integrating over the distribution function of Brownian meander (Durrett et al.  1977  Equation 1.1) 

P(cid:2)B+
0 (t) < x(cid:3) = 2

dw dy

√
2
2π

3

(cid:32)

(cid:33)3

 

(cid:21)

x(cid:112)t(1 − t)
(cid:19)

1 − k
u2h

<

η√
u

(cid:18)

exp(cid:0)−w2/(2(1 − t))(cid:1)
(cid:19)

(cid:112)2π(1 − t)

≤

≤

(cid:20)

P

B+
0

0

0

0

t

2

=

dy

≤

2x3

2x3

y2 exp

− y2
2t

√
2π

(cid:90) y

√
2πt

y exp(cid:0)−y2/(2t)(cid:1)
(cid:90) x
(cid:18)
(cid:90) x
t(cid:112)2πt(1 − t)
3t(cid:112)2πt(1 − t)
(cid:19)
(cid:18)

(cid:113)
 η√
u(cid:113) k
 η√
u(cid:113) k

3t(1 − t)(cid:112)2πt(1 − t)
(cid:21)
(cid:20)
(cid:98)u2h(cid:99)−(cid:100)2hη2(cid:101)(cid:88)
3
(cid:98)u2h(cid:99)−(cid:100)2hη2(cid:101)(cid:88)
(cid:113) k

(cid:98)u2h(cid:99)−(cid:100)2hη2(cid:101)(cid:88)
u(cid:113)

2 (cid:101)(cid:88)
(cid:113) (cid:98)u2h(cid:99)

k=(cid:100) u2h
2 (cid:101)
(cid:98)u2h(cid:99)−(cid:100) u2h

3
3

η√
u
1 − k

1 − k
u2h

k=(cid:100) u2h
2 (cid:101)

k=(cid:100) u2h
2 (cid:101)

η√
u

√
1
6

√
1

u2h

u2h

u2h

P

+

<

+

+

+

π

3

6

π

B+
0

k=(cid:100)2hη2(cid:101)

u2h

√
2
2π

3

6

6

√
1
π

√
1
π

√
2
2π

η√
1 − k

u2h

η√
u


(cid:113)
3

u2h + k
u2h

3

·

3

η√
u
1 − k

u2h

(cid:113) k

u2h

7

(cid:98) u2h

k=(cid:100)2hη2(cid:101)

(cid:98) u2h

k=(cid:100)2hη2(cid:101)

(cid:98) u2h

2 (cid:99)(cid:88)
2 (cid:99)(cid:88)
2 (cid:99)(cid:88)
2 (cid:99)(cid:88)

k=(cid:100)2hη2(cid:101)

(cid:98) u2h

k=(cid:100)2hη2(cid:101)

α2 + α3 =

≤

≤

≤

Changing the indexation as k = −k(cid:48) + (cid:98)u2h(cid:99)  we get

α2 + α3 ≤

1
k3/2 +

≤

k3/2 ≤
where in the last line we used that for any k0 ≥ 1 

√
π

1

3

∞(cid:88)

k=k0

(cid:0)2hη2(cid:1)3/2
(cid:0)2hη2(cid:1)3/2

√
π

6

∞(cid:88)

k=(cid:100)2hη2(cid:101)

 (cid:98) u2h
2 (cid:99)(cid:88)
∞(cid:88)
(cid:90) k

k=(cid:100)2hη2(cid:101)

1

k3/2

k=(cid:100)2hη2(cid:101)

(cid:98)u2h(cid:99)−(cid:100) u2h


2 (cid:101)(cid:88)
(cid:0)2hη2(cid:1)3/2
3(cid:112)(cid:100)2hη2(cid:101) ≤ 1√
(cid:90) ∞

√
π

3

η22h ≤ η22h 

π

1

k3/2 ≤ 1
k3/2
0

+

k=k0+1

k−1

1
u3/2 du =

1
k3/2
0

+

k0

1
u3/2 du =

1
k3/2
0

+

2√
k0

≤ 3√
k0

·

We ﬁnally have

and therefore

∀u  α1 + α2 + α3 + α4 ≤ 3η22h

E[Nh(η)] ≤ 6η22h.

To conclude the analysis  we put Lemma 2 and Lemma 3 together in order to bound the sample
complexity conditioned on event C.
Lemma 4. There exists c > 0 such that for all ε ≤ 1/2  E[Nε | C ] ≤ c log2(1/ε).

Proof. By deﬁnition of hmax 

ε2 ≤

5

2 × 2hmax

ln

(cid:18) 2hmax

(cid:19)

ε

≤ 5
2

(cid:112)2hmax /ε

2hmax

 

from which we deduce that
√
εε2 ≤

5

2 × 2hmax/2

and therefore 2hmax ≤ 25
4ε5

 

which gives us an upper bound on hmax 

Furthermore  using Lemma 1  we get that for any ε ≤ 1/2 

hmax ≤ ln(25/4)

+

5 ln(1/ε)

= O(log(1/ε)).

ln 2

ln 2

E[Nh(ηh)] = E[Nh(ηh)| C ]P[C] + E[Nh(ηh)| Cc]P[Cc] ≥ E[Nh(ηh)| C ](1 − ε) ≥ E[Nh(ηh)|C ]

2

·

E[Nε| C ] ≤ 2

We now use Lemma 2 and Lemma 3 to get

(cid:34)
hmax(cid:88)
hmax+1(cid:88)

h=0

E

h=1

Nh

2h

5
2

(cid:17)

(cid:16)

≤ 60

ln(2h+1/ε)

hmax(cid:88)

(cid:33)(cid:12)(cid:12)(cid:12)(cid:12) C
(cid:32)(cid:114)
(cid:35)
(ln(1/ε) + h ln 2) = O(cid:0)h2
max + hmax log(1/ε)(cid:1) = O(cid:0)log2(1/ε)(cid:1).
(cid:0)1/2h(cid:1) ≤ ε. Then  we combine it with Lemma 1 

2h+1/ε

h=0

ln

We also bound the sample complexity on Cc  the event complementary to C  by the total number
of possible intervals [k/2h  (k + 1)/2h] with ηε
Lemma 2  and Lemma 3 to get Proposition 2 which is the second part of the main theorem.
Proposition 2. There exists c > 0 such that for all ε < 1/2 
E[Nε] ≤ c log2(1/ε).

= 60

Proof. From the law of total expectation 

E[Nε] = E[Nε| C ]P[C] + E[Nε|Cc]P[Cc] ≤ E[Nε| C ] + ε5E[Nε|Cc].

8

points are evaluated. Then 

By Lemma 4  we have that E[Nε| C ] = O(cid:0)log2(1/ε)(cid:1). Now let hmax be the maximum h at which
As in the proof of Lemma 4  we get 2hmax+1 = O(cid:0)ε−5(cid:1). We ﬁnally obtain that

Nε ≤ hmax(cid:88)
E[Nε] ≤ O(cid:0)log2(1/ε)(cid:1) + O(1) = O(cid:0)log2(1/ε)(cid:1).

2h = 2hmax+1 − 1 ≤ 2hmax+1.

h=0

Proposition 2 together with Proposition 1 establish the proof of Theorem 1  the holy grail.

5 Numerical evaluation of OOB

For an illustration  we ran a simple experiment and for different values of ε  we computed the average
empirical sample complexity Nε on 250 independent runs that you can see on the left plot. We also
plot one point for each run of OOB instead of averaging the sample complexity  to be seen on the right.
The experiment indicates a linear dependence between the sample complexity and log2(1/ε).

6 Conclusion and ideas for extensions and generalizations

We presented OOB  an algorithm inspired by DOO (Munos  2011) that efﬁciently optimizes a Brownian

motion. We proved that the sample complexity of OOB is of order O(cid:0)log2(1/ε)(cid:1) which improves
the Brownian motion optimization  we do not know whether O(cid:0)log2(1/ε)(cid:1) is the minimax rate of

over the previously best known bound (Calvin et al.  2017). As we are not aware of a lower bound for

the sample complexity or if there exists an algorithm that can do even better.
What would be needed to do if we wanted to use our approach for Gaussian processes with a different
kernel? The optimistic approach we took is quite general and only Lemma 3 would need additional
work as this is the ingredient most speciﬁc to Brownian motion. Notice  that Lemma 3 bounds the
number of near-optimal nodes of a Brownian motion in expectation. To bound the expected number
of near-optimal nodes  we use the result of Денисов (1983) which is based on 2 components:

1 A Brownian motion can be rewritten as an afﬁne transformation of a Brownian motion
conditioned to be positive  translated by an (independent) time at which the Brownian
motion attains its maximum.

2 A Brownian motion conditioned to be positive is a Brownian meander. It requires some
additional work to prove that a Brownian motion conditioned to be positive is actually
properly deﬁned.

A similar result for another Gaussian process or its generalization of our result to a larger class of
Gaussian processes would need to adapt or generalize these two items in Lemma 3. On the other hand 
the adaptation or generalization of the other parts of the proof would be straightforward. Moreover 
for the second item  the full law of the process conditioned to be positive is actually not needed  only
the local time of the Gaussian process conditioned to be positive at points near zero.

9

Acknowledgements This research was supported by European CHIST-ERA project DELTA 
French Ministry of Higher Education and Research  Nord-Pas-de-Calais Regional Council  Inria and
Otto-von-Guericke-Universit¨at Magdeburg associated-team north-European project Allocate  French
National Research Agency projects ExTra-Learn (n.ANR-14-CE24-0010-01) and BoB (n.ANR-16-
CE23-0003)  FMJH Program PGMO with the support to this program from Criteo  a doctoral grant
of ´Ecole Normale Sup´erieure  and Maryse & Michel Grill.

References
Hisham Al-Mharmah and James M. Calvin. Optimal random non-adaptive algorithm for global

optimization of Brownian motion. Journal of Global Optimization  8(1):81–90  1996.

Kinjal Basu and Souvik Ghosh. Analysis of Thompson sampling for Gaussian process optimization

in the bandit setting. arXiv preprint arXiv:1705.06808  2018.

James M. Calvin  Mario Hefter  and Andr´e Herzwurm. Adaptive approximation of the minimum of

Brownian motion. Journal of Complexity  39(C):17–37  2017.

Olivier Chapelle and Lihong Li. An empirical evaluation of Thompson sampling.

Information Processing Systems. 2011.

In Neural

И. В. Денисов. Случайное блуждание и винеровский процесс  рассматриваемые из точки

максимума. Теория вероятностей и ее применения  28(4):785–788  1983.

Richard T. Durrett  Donald L. Iglehart  and Douglas R. Miller. Weak convergence to Brownian

meander and Brownian excursion. The Annals of Probability  5(1):117–129  1977.

Mario Hefter and Andr´e Herzwurm. Optimal strong approximation of the one-dimensional squared

Bessel process. Communications in Mathematical Sciences  15(8):2121–2141  2017.

R´emi Munos. Optimistic optimization of deterministic functions without the knowledge of its

smoothness. In Neural Information Processing Systems  2011.

Daniel Russo  Benjamin Van Roy  Abbas Kazerouni  Ian Osband  and Zheng Wen. A tutorial on

Thompson sampling. Foundations and Trends in Machine Learning  2018.

William R. Thompson. On the likelihood that one unknown probability exceeds another in view of

the evidence of two samples. Biometrika  25:285–294  1933.

10

,Jean-Bastien Grill
Michal Valko
Remi Munos