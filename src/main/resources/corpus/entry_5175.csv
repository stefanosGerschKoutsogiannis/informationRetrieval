2019,Spherical Text Embedding,Unsupervised text embedding has shown great power in a wide range of NLP tasks. While text embeddings are typically learned in the Euclidean space  directional similarity is often more effective in tasks such as word similarity and document clustering  which creates a gap between the training stage and usage stage of text embedding. To close this gap  we propose a spherical generative model based on which unsupervised word and paragraph embeddings are jointly learned. To learn text embeddings in the spherical space  we develop an efficient optimization algorithm with convergence guarantee based on Riemannian optimization. Our model enjoys high efficiency and achieves state-of-the-art performances on various text embedding tasks including word similarity and document clustering.,Spherical Text Embedding

Yu Meng1  Jiaxin Huang1  Guangyuan Wang1  Chao Zhang2 

Honglei Zhuang1⇤  Lance Kaplan3  Jiawei Han1

1 Department of Computer Science  University of Illinois at Urbana-Champaign

2 College of Computing  Georgia Institute of Technology

3 U.S. Army Research Laboratory

1 {yumeng5 jiaxinh3 gwang10 hzhuang3 hanj}@illinois.edu

2 chaozhang@gatech.edu 3 lance.m.kaplan.civ@mail.mil

Abstract

Unsupervised text embedding has shown great power in a wide range of NLP tasks.
While text embeddings are typically learned in the Euclidean space  directional
similarity is often more effective in tasks such as word similarity and document
clustering  which creates a gap between the training stage and usage stage of text
embedding. To close this gap  we propose a spherical generative model based
on which unsupervised word and paragraph embeddings are jointly learned. To
learn text embeddings in the spherical space  we develop an efﬁcient optimization
algorithm with convergence guarantee based on Riemannian optimization. Our
model enjoys high efﬁciency and achieves state-of-the-art performances on various
text embedding tasks including word similarity and document clustering.

1

Introduction

Recent years have witnessed enormous success of unsupervised text embedding techniques [29 
30  33] in various natural language processing and text mining tasks. Such techniques capture
the semantics of textual units (e.g.  words  paragraphs) via learning low-dimensional distributed
representations in an unsupervised way  which can be either directly used as feature representations
or further ﬁne-tuned with training data from downstream supervised tasks. Notably  the popular
Word2Vec method [29  30] learns word embeddings in the Euclidean space  by modeling local word
co-occurrences in the corpus. This strategy has later been extended to obtain embeddings of other
textual units such as sentences [2  19] and paragraphs [22].
Despite the success of unsupervised text embedding techniques  an intriguing gap exists between the
training procedure and the practical usages of the learned embeddings. While the embeddings are
learned in the Euclidean space  it is often the directional similarity between word vectors that captures
word semantics more effectively. Across a wide range of word similarity and document clustering
tasks [3  16  23]  it is common practice to either use cosine similarity as the similarity metric or ﬁrst
normalize word and document vectors before computing textual similarities. Current procedures of
training text embeddings in the Euclidean space and using their similarities in the spherical space
is clearly suboptimal. After projecting the embedding from Euclidean space to spherical space  the
optimal solution to the loss function in the original space may not remain optimal in the new space.
In this work  we propose a method that learns spherical text embeddings in an unsupervised way. In
contrast to existing techniques that learn text embeddings in the Euclidean space and use normalization
as a post-processing step  we directly learn text embeddings in a spherical space by imposing unit-
norm constraints on embeddings. Speciﬁcally  we deﬁne a two-step generative model on the surface
of a unit sphere: A word is ﬁrst generated according to the semantics of the paragraph  and then

⇤Currently at Google Research.

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

the surrounding words are generated in consistency with the center word’s semantics. We cast the
learning of the generative model as an optimization problem and propose an efﬁcient Riemannian
optimization procedure to learn spherical text embeddings.
Another major advantage of our spherical text embedding model is that it can jointly learn word
embeddings and paragraph embeddings. This property naturally stems from our two-step generative
process  where the generation of a word is dependent on its belonging paragraph with a von Mishes-
Fisher distribution in the spherical space. Explicitly modeling the generative relationships between
words and their belonging paragraphs allows paragraph embeddings to be directly obtained during
the training stage. Furthermore  it allows the model to learn better word embeddings by jointly
exploiting word-word and word-paragraph co-occurrence statistics; this is distinct from existing word
embedding techniques that learn word embeddings only based on word co-occurrences [5  29  30  33]
in the corpus.

Contributions.
(1) We propose to learn text embeddings in the spherical space which addresses the
mismatch issue between training and using embeddings of previous Euclidean embedding models;
(2) We propose a two-step generative model that jointly learns unsupervised word and paragraph
embeddings by exploiting word-word and word-paragraph co-occurrence statistics; (3) We develop
an efﬁcient optimization algorithm in the spherical space with convergence guarantee; (4) Our model
achieves state-of-the-art performances on various text embedding applications.

2 Related Work
2.1 Text Embedding
Most unsupervised text embedding models such as [5  19  22  29  30  33  37  42] are trained in the
Euclidean space. The embeddings are trained to capture semantic similarity of textual units based on
co-occurrence statistics  and demonstrate effectiveness on various text semantics tasks such as named
entity recognition [21]  text classiﬁcation [18  27  28  38] and machine translation [8]. Recently 
non-Euclidean embedding space has been explored for learning speciﬁc structural representations.
Poincaré [11  31  39]  Lorentz [32] and hyperbolic cone [15] models have proven successful on
learning hierarchical representations in a hyperbolic space for tasks such as lexical entailment and
link prediction. Our model also learns unsupervised text embeddings in a non-Euclidean space  but
still for general text embedding applications including word similarity and document clustering.

2.2 Spherical Space Models
Previous works have shown that the spherical space is a superior choice for tasks focusing on
directional similarity. For example  normalizing document tf-idf vectors is common practice when
used as features for document clustering and classiﬁcation  which helps regularize the vector against
the document length and leads to better document clustering performance [3  16]. Spherical generative
modeling [4  43  44] models the distribution of words on the unit sphere  motivated by the effectiveness
of directional metrics over word embeddings. Recently  spherical models also show great effectiveness
in deep learning. Spherical normalization [24] on the input leads to easier optimization  faster
convergence and better accuracy of neural networks. Also  a spherical loss function can be used to
replace the conventional softmax layer in language generation tasks  which results in faster and better
generation quality [20]. Motivated by the success of these models  we propose to learn unsupervised
text embeddings in the spherical space so that the embedding space discrepancy between training and
usage can be eliminated  and directional similarity is more effectively captured.

3 Spherical Text Embedding

In this section  we introduce the spherical generative model for jointly learning word and paragraph
embeddings and the corresponding loss function.

3.1 The Generative Model
The design of our generative model is inspired by the way humans write articles: Each word should be
semantically consistent with not only its surrounding words  but also the entire paragraph/document.

2

Speciﬁcally  we assume text generation is a two-step process: A center word is ﬁrst generated
according to the semantics of the paragraph  and then the surrounding words are generated based
on the center word’s semantics2. Further  we assume the direction in the spherical embedding space
captures textual semantics  and higher directional similarity implies higher co-occurrence probability.
Hence  we model the text generation process as follows: Given a paragraph d  a center word u is ﬁrst
generated by

and then a context word is generated by

p(u | d) / exp(cos(u  d)) 

(1)

p(v | u) / exp(cos(v  u)) 

(2)
where kuk = kvk = kdk = 1  and cos(· ·) denotes the cosine of the angle between two vectors on
the unit sphere.
Next we derive the analytic forms of Equations (1) and (2).
Theorem 1. When the corpus has inﬁnite vocabulary  i.e.  |V |! 1   the analytic forms of Equa-
tions (1) and (2) are given by the von Mises-Fisher (vMF) distribution with the prior embedding as
the mean direction and constant 1 as the concentration parameter  i.e. 

lim

|V |!1

p(v | u) = vMFp(v; u  1) 

lim

|V |!1

p(u | d) = vMFp(u; d  1).

The proof of Theorem 1 can be found in Appendix A.
The vMF distribution deﬁnes a probability density over a hypersphere and is parameterized by a
mean vector µ and a concentration parameter . The probability density closer to µ is greater and
the spread is controlled by . Formally  A unit random vector x 2 Sp1 has the p-variate vMF
distribution vMFp(x; µ  ) if its probability dense function is

where kµk = 1 is the mean direction    0 is the concentration parameter  and the normalization
constant cp() is given by

f (x; µ  ) = cp() exp ( · cos(x  µ))  

cp() =

p/21

(2⇡)p/2Ip/21()

 

where Ir(·) represents the modiﬁed Bessel function of the ﬁrst kind at order r  given by Deﬁnition 1
in the appendix.
Finally  the probability density function of a context word v appearing in a center word u’s local
context window in a paragraph/document d is given by

p(v  u | d) / p(v | u) · p(u | d) / vMFp(v; u  1) · vMFp(u; d  1).

3.2 Objective
Given a positive training tuple (u  v  d) where v appears in the local context window of u in paragraph
d  we aim to maximize the probability p(v  u | d)  while minimize the probability p(v  u0 | d) where
u0 is a randomly sampled word from the vocabulary serving as a negative sample. This is similar to
the negative sampling technique used in Word2Vec [30] and GloVe [33]. To achieve this  we employ
a max-margin loss function  similar to [15  40  41]  and push the log likelihood of the positive tuple
over the negative one by a margin:

L(u  v  d) = max✓0  m  logcp(1) exp(cos(v  u)) · cp(1) exp(cos(u  d))
+ logcp(1) exp(cos(v  u0)) · cp(1) exp(cos(u0  d))◆

= max (0  m  cos(v  u)  cos(u  d) + cos(v  u0) + cos(u0  d))  

(3)

where m > 0 is the margin.

2Like previous works  we assume each word has independent center word representation and context
word representation  and thus the generation processes of a word as a center word and as a context word are
independent.

3

4 Optimization

In this section  we describe the approach to optimize the objective introduced in the previous section
on the unit sphere.

4.1 The Constrained Optimization Problem
The unit hypersphere Sp1 := {x 2 Rp |k xk = 1} is the common choice for spherical space
optimization problems. The text embedding training is thus a constrained optimization problem:

⇥ L(⇥)
min

s.t. 8✓ 2 ⇥ : k✓k = 1 
i=1 is the set of target word embeddings  context word

where ⇥ = {ui}|V |

i=1 [{ vi}|V |

i=1 [{ di}|D|

embeddings and paragraph embeddings to be learned.
Since the optimization problem is constrained on the unit sphere  the Euclidean space optimization
methods such as SGD cannot be used to optimize our objective  because the Euclidean gradient
provides the update direction in a non-curvature space  while the parameters in our model must be
updated on a surface with constant positive curvature. Therefore  we need to base our embedding
training problem on Riemannian optimization.

4.2 Preliminaries
A Riemannian manifold (M  g) is a real  smooth manifold whose tangent spaces are endowed with a
smoothly varying inner product g  also called the Riemannian metric. Let TxM denote the tangent
space at x 2M   then g deﬁnes the inner product h· ·ix : TxM⇥ TxM! R. A unit sphere Sp1
can be considered as a Riemmannian submanifold of Rp  and its Riemannian metric can be inherited
from Rp  i.e.  h↵  ix := ↵>.
The intrinsic distance on the unit sphere between two arbitrary points x  y 2 Sp1 is deﬁned by
d(x  y) := arccos(x>y). A geodesic segment  : [a  b] ! Sp1 is the generalization of a straight
line to the sphere  and it is said to be minimal if it equals to the intrinsic distance between its end
points  i.e.  `() = arccos((a)>(b)).
Let TxSp1 denote the tangent hyperplane at x 2 Sp1  i.e.  TxSp1 := {y 2 Rp | x>y = 0}.
The projection onto TxSp1 is given by the linear mapping I  xx> : Rp ! TxSp1 where I is
the identity matrix. The exponential mapping expx : TxSp1 ! Sp1 projects a tangent vector
z 2 TxSp1 onto the sphere such that expx(z) = y  (0) = x  (1) = y and @
4.3 Riemannian Optimization

@t (0) = z.

Since the unit sphere is a Riemannian manifold  we can optimize our objectives with Riemannian
SGD [6  34]. Speciﬁcally  the parameters are updated by

xt+1 = expxt (⌘tgrad f (xt))  

where ⌘t denotes the learning rate and grad f (xt) 2 TxtSp1 is the Riemannian gradient of a
differentiable function f : Sp1 ! R.
On the unit sphere  the exponential mapping expx : TxSp1 ! Sp1 is given by
  z 2 TxSp1\{0} 

expx(z) :=(cos(kzk)x + sin(kzk) z

z = 0.

kzk

(4)

x 

To derive the Riemannian gradient grad f (x) at x  we view Sp1 as a Riemannian submanifold of
Rp endowed with the canonical Riemannian metric h↵  ix := ↵>. Then the Riemannian gradient
is obtained by using the linear mapping I  xx> : Rp ! TxSp1 to project the Euclidean gradient
rf (x) from the ambient Euclidean space onto the tangent hyperplane [1  12]  i.e. 

grad f (x) :=I  xx>rf (x).

4

(5)

<latexit sha1_base64="gQMk3f5amyCNSQbXPnd5BMpwKTQ=">AAACFHicdVDPSxwxFM5otbr+2tajl9BFUNQl2S7ueigsePFooavCzjhkshkNZpIheVO6DPtHePFf6cWDIl49eOt/04xuoYp+EPLxfe/x3vuSXEkHhPwJpqY/zMx+nJuvLSwuLa/UP30+cqawXPS5UcaeJMwJJbXogwQlTnIrWJYocZxc7Ff+8U9hnTT6B4xyEWXsTMtUcgZeiutbO6FmiWI4jSneCBOjhm6U+a/8NY5h89uAbtPotAzB5OO43iDNve5uq72LSZOQDm3RirQ67a9tTL1SoYEmOIzrj+HQ8CITGrhizg0oySEqmQXJlRjXwsKJnPELdiYGnmqWCReVT0eN8bpXhjg11j8N+En9v6NkmatW9ZUZg3P32qvEt7xBAWk3KqXOCxCaPw9KC4XB4CohPJRWcFAjTxi30u+K+TmzjIPPseZD+Hcpfp8ctZqUNOn3dqNHJnHMoTX0BW0gijqohw7QIeojji7Rb3SDboOr4Dq4C+6fS6eCSc8qeoHg4S+1OZ31</latexit>
<latexit sha1_base64="gQMk3f5amyCNSQbXPnd5BMpwKTQ=">AAACFHicdVDPSxwxFM5otbr+2tajl9BFUNQl2S7ueigsePFooavCzjhkshkNZpIheVO6DPtHePFf6cWDIl49eOt/04xuoYp+EPLxfe/x3vuSXEkHhPwJpqY/zMx+nJuvLSwuLa/UP30+cqawXPS5UcaeJMwJJbXogwQlTnIrWJYocZxc7Ff+8U9hnTT6B4xyEWXsTMtUcgZeiutbO6FmiWI4jSneCBOjhm6U+a/8NY5h89uAbtPotAzB5OO43iDNve5uq72LSZOQDm3RirQ67a9tTL1SoYEmOIzrj+HQ8CITGrhizg0oySEqmQXJlRjXwsKJnPELdiYGnmqWCReVT0eN8bpXhjg11j8N+En9v6NkmatW9ZUZg3P32qvEt7xBAWk3KqXOCxCaPw9KC4XB4CohPJRWcFAjTxi30u+K+TmzjIPPseZD+Hcpfp8ctZqUNOn3dqNHJnHMoTX0BW0gijqohw7QIeojji7Rb3SDboOr4Dq4C+6fS6eCSc8qeoHg4S+1OZ31</latexit>
<latexit sha1_base64="gQMk3f5amyCNSQbXPnd5BMpwKTQ=">AAACFHicdVDPSxwxFM5otbr+2tajl9BFUNQl2S7ueigsePFooavCzjhkshkNZpIheVO6DPtHePFf6cWDIl49eOt/04xuoYp+EPLxfe/x3vuSXEkHhPwJpqY/zMx+nJuvLSwuLa/UP30+cqawXPS5UcaeJMwJJbXogwQlTnIrWJYocZxc7Ff+8U9hnTT6B4xyEWXsTMtUcgZeiutbO6FmiWI4jSneCBOjhm6U+a/8NY5h89uAbtPotAzB5OO43iDNve5uq72LSZOQDm3RirQ67a9tTL1SoYEmOIzrj+HQ8CITGrhizg0oySEqmQXJlRjXwsKJnPELdiYGnmqWCReVT0eN8bpXhjg11j8N+En9v6NkmatW9ZUZg3P32qvEt7xBAWk3KqXOCxCaPw9KC4XB4CohPJRWcFAjTxi30u+K+TmzjIPPseZD+Hcpfp8ctZqUNOn3dqNHJnHMoTX0BW0gijqohw7QIeojji7Rb3SDboOr4Dq4C+6fS6eCSc8qeoHg4S+1OZ31</latexit>
<latexit sha1_base64="gQMk3f5amyCNSQbXPnd5BMpwKTQ=">AAACFHicdVDPSxwxFM5otbr+2tajl9BFUNQl2S7ueigsePFooavCzjhkshkNZpIheVO6DPtHePFf6cWDIl49eOt/04xuoYp+EPLxfe/x3vuSXEkHhPwJpqY/zMx+nJuvLSwuLa/UP30+cqawXPS5UcaeJMwJJbXogwQlTnIrWJYocZxc7Ff+8U9hnTT6B4xyEWXsTMtUcgZeiutbO6FmiWI4jSneCBOjhm6U+a/8NY5h89uAbtPotAzB5OO43iDNve5uq72LSZOQDm3RirQ67a9tTL1SoYEmOIzrj+HQ8CITGrhizg0oySEqmQXJlRjXwsKJnPELdiYGnmqWCReVT0eN8bpXhjg11j8N+En9v6NkmatW9ZUZg3P32qvEt7xBAWk3KqXOCxCaPw9KC4XB4CohPJRWcFAjTxi30u+K+TmzjIPPseZD+Hcpfp8ctZqUNOn3dqNHJnHMoTX0BW0gijqohw7QIeojji7Rb3SDboOr4Dq4C+6fS6eCSc8qeoHg4S+1OZ31</latexit>

rf1(xt) = [1  1]>
z<latexit sha1_base64="Wet73zNqxVFTEbAnDllx3Pv6AYk=">AAAB9XicdVBLSwMxGMzWV62vqkcvwSJ4WpLS1R4LXjxWsA9oa8lms21odrMkWaUu/R9ePCji1f/izX9jtq2gogMhw8z3kcn4ieDaIPThFFZW19Y3ipulre2d3b3y/kFby1RR1qJSSNX1iWaCx6xluBGsmyhGIl+wjj+5yP3OLVOay/jaTBM2iMgo5iGnxFjppu9LEehpZK/sfjYsV5CLzrwarkPkegjXsWdJ1cMIVSF20RwVsERzWH7vB5KmEYsNFUTrHkaJGWREGU4Fm5X6qWYJoRMyYj1LYxIxPcjmqWfwxCoBDKWyJzZwrn7fyEik82h2MiJmrH97ufiX10tNWB9kPE5Sw2K6eChMBTQS5hXAgCtGjZhaQqjiNiukY6IINbaoki3h66fwf9Kuuhi5+KpWaaBlHUVwBI7BKcDgHDTAJWiCFqBAgQfwBJ6dO+fReXFeF6MFZ7lzCH7AefsEn4iTLw==</latexit>

<latexit sha1_base64="Wet73zNqxVFTEbAnDllx3Pv6AYk=">AAAB9XicdVBLSwMxGMzWV62vqkcvwSJ4WpLS1R4LXjxWsA9oa8lms21odrMkWaUu/R9ePCji1f/izX9jtq2gogMhw8z3kcn4ieDaIPThFFZW19Y3ipulre2d3b3y/kFby1RR1qJSSNX1iWaCx6xluBGsmyhGIl+wjj+5yP3OLVOay/jaTBM2iMgo5iGnxFjppu9LEehpZK/sfjYsV5CLzrwarkPkegjXsWdJ1cMIVSF20RwVsERzWH7vB5KmEYsNFUTrHkaJGWREGU4Fm5X6qWYJoRMyYj1LYxIxPcjmqWfwxCoBDKWyJzZwrn7fyEik82h2MiJmrH97ufiX10tNWB9kPE5Sw2K6eChMBTQS5hXAgCtGjZhaQqjiNiukY6IINbaoki3h66fwf9Kuuhi5+KpWaaBlHUVwBI7BKcDgHDTAJWiCFqBAgQfwBJ6dO+fReXFeF6MFZ7lzCH7AefsEn4iTLw==</latexit>
<latexit sha1_base64="Wet73zNqxVFTEbAnDllx3Pv6AYk=">AAAB9XicdVBLSwMxGMzWV62vqkcvwSJ4WpLS1R4LXjxWsA9oa8lms21odrMkWaUu/R9ePCji1f/izX9jtq2gogMhw8z3kcn4ieDaIPThFFZW19Y3ipulre2d3b3y/kFby1RR1qJSSNX1iWaCx6xluBGsmyhGIl+wjj+5yP3OLVOay/jaTBM2iMgo5iGnxFjppu9LEehpZK/sfjYsV5CLzrwarkPkegjXsWdJ1cMIVSF20RwVsERzWH7vB5KmEYsNFUTrHkaJGWREGU4Fm5X6qWYJoRMyYj1LYxIxPcjmqWfwxCoBDKWyJzZwrn7fyEik82h2MiJmrH97ufiX10tNWB9kPE5Sw2K6eChMBTQS5hXAgCtGjZhaQqjiNiukY6IINbaoki3h66fwf9Kuuhi5+KpWaaBlHUVwBI7BKcDgHDTAJWiCFqBAgQfwBJ6dO+fReXFeF6MFZ7lzCH7AefsEn4iTLw==</latexit>
<latexit sha1_base64="Wet73zNqxVFTEbAnDllx3Pv6AYk=">AAAB9XicdVBLSwMxGMzWV62vqkcvwSJ4WpLS1R4LXjxWsA9oa8lms21odrMkWaUu/R9ePCji1f/izX9jtq2gogMhw8z3kcn4ieDaIPThFFZW19Y3ipulre2d3b3y/kFby1RR1qJSSNX1iWaCx6xluBGsmyhGIl+wjj+5yP3OLVOay/jaTBM2iMgo5iGnxFjppu9LEehpZK/sfjYsV5CLzrwarkPkegjXsWdJ1cMIVSF20RwVsERzWH7vB5KmEYsNFUTrHkaJGWREGU4Fm5X6qWYJoRMyYj1LYxIxPcjmqWfwxCoBDKWyJzZwrn7fyEik82h2MiJmrH97ufiX10tNWB9kPE5Sw2K6eChMBTQS5hXAgCtGjZhaQqjiNiukY6IINbaoki3h66fwf9Kuuhi5+KpWaaBlHUVwBI7BKcDgHDTAJWiCFqBAgQfwBJ6dO+fReXFeF6MFZ7lzCH7AefsEn4iTLw==</latexit>

dcos · z

<latexit sha1_base64="ci/PQFU/w10c/I1+qmSKfpNGhPQ=">AAACBHicdVDLSgMxFM34rPU16rKbYBFcDZnawXZXcOOygn1Ap5RMJm1DM5MhyQh16MKNv+LGhSJu/Qh3/o2ZtoKKHgg5nHMv994TJJwpjdCHtbK6tr6xWdgqbu/s7u3bB4dtJVJJaIsILmQ3wIpyFtOWZprTbiIpjgJOO8HkIvc7N1QqJuJrPU1oP8KjmA0ZwdpIA7sUDjKfCDXzSSi0Hwgeqmlkvux2NrDLyEFe3XMRRI6H3PpZTur1WtXzoOugOcpgiebAfvdDQdKIxppwrFTPRYnuZ1hqRjidFf1U0QSTCR7RnqExjqjqZ/MjZvDEKCEcCmlerOFc/d6R4Ujlq5nKCOux+u3l4l9eL9XDWj9jcZJqGpPFoGHKoRYwTwSGTFKi+dQQTCQzu0IyxhITbXIrmhC+LoX/k3bFcZHjXlXLjcoyjgIogWNwClxwDhrgEjRBCxBwBx7AE3i27q1H68V6XZSuWMueI/AD1tsnsOqZXg==</latexit>
<latexit sha1_base64="ci/PQFU/w10c/I1+qmSKfpNGhPQ=">AAACBHicdVDLSgMxFM34rPU16rKbYBFcDZnawXZXcOOygn1Ap5RMJm1DM5MhyQh16MKNv+LGhSJu/Qh3/o2ZtoKKHgg5nHMv994TJJwpjdCHtbK6tr6xWdgqbu/s7u3bB4dtJVJJaIsILmQ3wIpyFtOWZprTbiIpjgJOO8HkIvc7N1QqJuJrPU1oP8KjmA0ZwdpIA7sUDjKfCDXzSSi0Hwgeqmlkvux2NrDLyEFe3XMRRI6H3PpZTur1WtXzoOugOcpgiebAfvdDQdKIxppwrFTPRYnuZ1hqRjidFf1U0QSTCR7RnqExjqjqZ/MjZvDEKCEcCmlerOFc/d6R4Ujlq5nKCOux+u3l4l9eL9XDWj9jcZJqGpPFoGHKoRYwTwSGTFKi+dQQTCQzu0IyxhITbXIrmhC+LoX/k3bFcZHjXlXLjcoyjgIogWNwClxwDhrgEjRBCxBwBx7AE3i27q1H68V6XZSuWMueI/AD1tsnsOqZXg==</latexit>
<latexit sha1_base64="ci/PQFU/w10c/I1+qmSKfpNGhPQ=">AAACBHicdVDLSgMxFM34rPU16rKbYBFcDZnawXZXcOOygn1Ap5RMJm1DM5MhyQh16MKNv+LGhSJu/Qh3/o2ZtoKKHgg5nHMv994TJJwpjdCHtbK6tr6xWdgqbu/s7u3bB4dtJVJJaIsILmQ3wIpyFtOWZprTbiIpjgJOO8HkIvc7N1QqJuJrPU1oP8KjmA0ZwdpIA7sUDjKfCDXzSSi0Hwgeqmlkvux2NrDLyEFe3XMRRI6H3PpZTur1WtXzoOugOcpgiebAfvdDQdKIxppwrFTPRYnuZ1hqRjidFf1U0QSTCR7RnqExjqjqZ/MjZvDEKCEcCmlerOFc/d6R4Ujlq5nKCOux+u3l4l9eL9XDWj9jcZJqGpPFoGHKoRYwTwSGTFKi+dQQTCQzu0IyxhITbXIrmhC+LoX/k3bFcZHjXlXLjcoyjgIogWNwClxwDhrgEjRBCxBwBx7AE3i27q1H68V6XZSuWMueI/AD1tsnsOqZXg==</latexit>
<latexit sha1_base64="ci/PQFU/w10c/I1+qmSKfpNGhPQ=">AAACBHicdVDLSgMxFM34rPU16rKbYBFcDZnawXZXcOOygn1Ap5RMJm1DM5MhyQh16MKNv+LGhSJu/Qh3/o2ZtoKKHgg5nHMv994TJJwpjdCHtbK6tr6xWdgqbu/s7u3bB4dtJVJJaIsILmQ3wIpyFtOWZprTbiIpjgJOO8HkIvc7N1QqJuJrPU1oP8KjmA0ZwdpIA7sUDjKfCDXzSSi0Hwgeqmlkvux2NrDLyEFe3XMRRI6H3PpZTur1WtXzoOugOcpgiebAfvdDQdKIxppwrFTPRYnuZ1hqRjidFf1U0QSTCR7RnqExjqjqZ/MjZvDEKCEcCmlerOFc/d6R4Ujlq5nKCOux+u3l4l9eL9XDWj9jcZJqGpPFoGHKoRYwTwSGTFKi+dQQTCQzu0IyxhITbXIrmhC+LoX/k3bFcZHjXlXLjcoyjgIogWNwClxwDhrgEjRBCxBwBx7AE3i27q1H68V6XZSuWMueI/AD1tsnsOqZXg==</latexit>

xt+1

<latexit sha1_base64="sCJTyiS9us4IUY6D/qcTTy5Fd5M=">AAAB/XicdVBLSwMxGMz6rPW1Pm5egkUQhCXRLra3ghePFewD2lKy2Wwbmn2QZMW6FP+KFw+KePV/ePPfmG0rqOhAyDDzfWQyXiK40gh9WAuLS8srq4W14vrG5ta2vbPbVHEqKWvQWMSy7RHFBI9YQ3MtWDuRjISeYC1vdJH7rRsmFY+jaz1OWC8kg4gHnBJtpL693/Vi4atxaK7sdtLP9Ame9O0ScpBbdTGCyHERrp7lpFqtlF0XYgdNUQJz1Pv2e9ePaRqySFNBlOpglOheRqTmVLBJsZsqlhA6IgPWMTQiIVO9bJp+Ao+M4sMgluZEGk7V7xsZCVUe0EyGRA/Vby8X//I6qQ4qvYxHSapZRGcPBamAOoZ5FdDnklEtxoYQKrnJCumQSEK1KaxoSvj6KfyfNE8djBx8VS7V0LyOAjgAh+AYYHAOauAS1EEDUHAHHsATeLburUfrxXqdjS5Y85098APW2yeBtJXZ</latexit>
<latexit sha1_base64="sCJTyiS9us4IUY6D/qcTTy5Fd5M=">AAAB/XicdVBLSwMxGMz6rPW1Pm5egkUQhCXRLra3ghePFewD2lKy2Wwbmn2QZMW6FP+KFw+KePV/ePPfmG0rqOhAyDDzfWQyXiK40gh9WAuLS8srq4W14vrG5ta2vbPbVHEqKWvQWMSy7RHFBI9YQ3MtWDuRjISeYC1vdJH7rRsmFY+jaz1OWC8kg4gHnBJtpL693/Vi4atxaK7sdtLP9Ame9O0ScpBbdTGCyHERrp7lpFqtlF0XYgdNUQJz1Pv2e9ePaRqySFNBlOpglOheRqTmVLBJsZsqlhA6IgPWMTQiIVO9bJp+Ao+M4sMgluZEGk7V7xsZCVUe0EyGRA/Vby8X//I6qQ4qvYxHSapZRGcPBamAOoZ5FdDnklEtxoYQKrnJCumQSEK1KaxoSvj6KfyfNE8djBx8VS7V0LyOAjgAh+AYYHAOauAS1EEDUHAHHsATeLburUfrxXqdjS5Y85098APW2yeBtJXZ</latexit>
<latexit sha1_base64="sCJTyiS9us4IUY6D/qcTTy5Fd5M=">AAAB/XicdVBLSwMxGMz6rPW1Pm5egkUQhCXRLra3ghePFewD2lKy2Wwbmn2QZMW6FP+KFw+KePV/ePPfmG0rqOhAyDDzfWQyXiK40gh9WAuLS8srq4W14vrG5ta2vbPbVHEqKWvQWMSy7RHFBI9YQ3MtWDuRjISeYC1vdJH7rRsmFY+jaz1OWC8kg4gHnBJtpL693/Vi4atxaK7sdtLP9Ame9O0ScpBbdTGCyHERrp7lpFqtlF0XYgdNUQJz1Pv2e9ePaRqySFNBlOpglOheRqTmVLBJsZsqlhA6IgPWMTQiIVO9bJp+Ao+M4sMgluZEGk7V7xsZCVUe0EyGRA/Vby8X//I6qQ4qvYxHSapZRGcPBamAOoZ5FdDnklEtxoYQKrnJCumQSEK1KaxoSvj6KfyfNE8djBx8VS7V0LyOAjgAh+AYYHAOauAS1EEDUHAHHsATeLburUfrxXqdjS5Y85098APW2yeBtJXZ</latexit>
<latexit sha1_base64="sCJTyiS9us4IUY6D/qcTTy5Fd5M=">AAAB/XicdVBLSwMxGMz6rPW1Pm5egkUQhCXRLra3ghePFewD2lKy2Wwbmn2QZMW6FP+KFw+KePV/ePPfmG0rqOhAyDDzfWQyXiK40gh9WAuLS8srq4W14vrG5ta2vbPbVHEqKWvQWMSy7RHFBI9YQ3MtWDuRjISeYC1vdJH7rRsmFY+jaz1OWC8kg4gHnBJtpL693/Vi4atxaK7sdtLP9Ame9O0ScpBbdTGCyHERrp7lpFqtlF0XYgdNUQJz1Pv2e9ePaRqySFNBlOpglOheRqTmVLBJsZsqlhA6IgPWMTQiIVO9bJp+Ao+M4sMgluZEGk7V7xsZCVUe0EyGRA/Vby8X//I6qQ4qvYxHSapZRGcPBamAOoZ5FdDnklEtxoYQKrnJCumQSEK1KaxoSvj6KfyfNE8djBx8VS7V0LyOAjgAh+AYYHAOauAS1EEDUHAHHsATeLburUfrxXqdjS5Y85098APW2yeBtJXZ</latexit>

TxtS1

<latexit sha1_base64="g7ywfvtlq/AGxWinhbm8wYj3dPg=">AAACC3icbVC7TsMwFHXKq5RXgJElaoXEVCUICcYKFsYi+pKaEDmO01p14sh2EJWVnYVfYWEAIVZ+gI2/wWkzQMuVLB+dc6/uuSdIKRHStr+Nysrq2vpGdbO2tb2zu2fuH/QEyzjCXcQo44MACkxJgruSSIoHKccwDijuB5OrQu/fYy4ISzpymmIvhqOERARBqSnfrHd85QaMhmIa6089+DLP3RjKcRCo2/xOOblvNuymPStrGTglaICy2r755YYMZTFOJKJQiKFjp9JTkEuCKM5rbiZwCtEEjvBQwwTGWHhqdktuHWsmtCLG9UukNWN/TygYi8Kr7ixcikWtIP/ThpmMLjxFkjSTOEHzRVFGLcmsIhgrJBwjSacaQMSJ9mqhMeQQSR1fTYfgLJ68DHqnTcduOjdnjdZlGUcVHIE6OAEOOActcA3aoAsQeATP4BW8GU/Gi/FufMxbK0Y5cwj+lPH5A77InBw=</latexit>
<latexit sha1_base64="g7ywfvtlq/AGxWinhbm8wYj3dPg=">AAACC3icbVC7TsMwFHXKq5RXgJElaoXEVCUICcYKFsYi+pKaEDmO01p14sh2EJWVnYVfYWEAIVZ+gI2/wWkzQMuVLB+dc6/uuSdIKRHStr+Nysrq2vpGdbO2tb2zu2fuH/QEyzjCXcQo44MACkxJgruSSIoHKccwDijuB5OrQu/fYy4ISzpymmIvhqOERARBqSnfrHd85QaMhmIa6089+DLP3RjKcRCo2/xOOblvNuymPStrGTglaICy2r755YYMZTFOJKJQiKFjp9JTkEuCKM5rbiZwCtEEjvBQwwTGWHhqdktuHWsmtCLG9UukNWN/TygYi8Kr7ixcikWtIP/ThpmMLjxFkjSTOEHzRVFGLcmsIhgrJBwjSacaQMSJ9mqhMeQQSR1fTYfgLJ68DHqnTcduOjdnjdZlGUcVHIE6OAEOOActcA3aoAsQeATP4BW8GU/Gi/FufMxbK0Y5cwj+lPH5A77InBw=</latexit>
<latexit sha1_base64="g7ywfvtlq/AGxWinhbm8wYj3dPg=">AAACC3icbVC7TsMwFHXKq5RXgJElaoXEVCUICcYKFsYi+pKaEDmO01p14sh2EJWVnYVfYWEAIVZ+gI2/wWkzQMuVLB+dc6/uuSdIKRHStr+Nysrq2vpGdbO2tb2zu2fuH/QEyzjCXcQo44MACkxJgruSSIoHKccwDijuB5OrQu/fYy4ISzpymmIvhqOERARBqSnfrHd85QaMhmIa6089+DLP3RjKcRCo2/xOOblvNuymPStrGTglaICy2r755YYMZTFOJKJQiKFjp9JTkEuCKM5rbiZwCtEEjvBQwwTGWHhqdktuHWsmtCLG9UukNWN/TygYi8Kr7ixcikWtIP/ThpmMLjxFkjSTOEHzRVFGLcmsIhgrJBwjSacaQMSJ9mqhMeQQSR1fTYfgLJ68DHqnTcduOjdnjdZlGUcVHIE6OAEOOActcA3aoAsQeATP4BW8GU/Gi/FufMxbK0Y5cwj+lPH5A77InBw=</latexit>
<latexit sha1_base64="g7ywfvtlq/AGxWinhbm8wYj3dPg=">AAACC3icbVC7TsMwFHXKq5RXgJElaoXEVCUICcYKFsYi+pKaEDmO01p14sh2EJWVnYVfYWEAIVZ+gI2/wWkzQMuVLB+dc6/uuSdIKRHStr+Nysrq2vpGdbO2tb2zu2fuH/QEyzjCXcQo44MACkxJgruSSIoHKccwDijuB5OrQu/fYy4ISzpymmIvhqOERARBqSnfrHd85QaMhmIa6089+DLP3RjKcRCo2/xOOblvNuymPStrGTglaICy2r755YYMZTFOJKJQiKFjp9JTkEuCKM5rbiZwCtEEjvBQwwTGWHhqdktuHWsmtCLG9UukNWN/TygYi8Kr7ixcikWtIP/ThpmMLjxFkjSTOEHzRVFGLcmsIhgrJBwjSacaQMSJ9mqhMeQQSR1fTYfgLJ68DHqnTcduOjdnjdZlGUcVHIE6OAEOOActcA3aoAsQeATP4BW8GU/Gi/FufMxbK0Y5cwj+lPH5A77InBw=</latexit>

S1

<latexit sha1_base64="zVF/cDu1tConQsSZq4vcr0qZJ6s=">AAAB9XicbVDLSgMxFL3js9ZX1aWbYBFclYkIuiy6cVnRPqCdlkyaaUMzmSHJKGWY/3DjQhG3/os7/8ZMOwttPRA4nHMv9+T4seDauO63s7K6tr6xWdoqb+/s7u1XDg5bOkoUZU0aiUh1fKKZ4JI1DTeCdWLFSOgL1vYnN7nffmRK80g+mGnMvJCMJA84JcZK/V5IzNj30/usn+JsUKm6NXcGtExwQapQoDGofPWGEU1CJg0VROsudmPjpUQZTgXLyr1Es5jQCRmxrqWShEx76Sx1hk6tMkRBpOyTBs3U3xspCbWehr6dzFPqRS8X//O6iQmuvJTLODFM0vmhIBHIRCivAA25YtSIqSWEKm6zIjomilBjiyrbEvDil5dJ67yG3Rq+u6jWr4s6SnAMJ3AGGC6hDrfQgCZQUPAMr/DmPDkvzrvzMR9dcYqdI/gD5/MHtiaSog==</latexit>
<latexit sha1_base64="zVF/cDu1tConQsSZq4vcr0qZJ6s=">AAAB9XicbVDLSgMxFL3js9ZX1aWbYBFclYkIuiy6cVnRPqCdlkyaaUMzmSHJKGWY/3DjQhG3/os7/8ZMOwttPRA4nHMv9+T4seDauO63s7K6tr6xWdoqb+/s7u1XDg5bOkoUZU0aiUh1fKKZ4JI1DTeCdWLFSOgL1vYnN7nffmRK80g+mGnMvJCMJA84JcZK/V5IzNj30/usn+JsUKm6NXcGtExwQapQoDGofPWGEU1CJg0VROsudmPjpUQZTgXLyr1Es5jQCRmxrqWShEx76Sx1hk6tMkRBpOyTBs3U3xspCbWehr6dzFPqRS8X//O6iQmuvJTLODFM0vmhIBHIRCivAA25YtSIqSWEKm6zIjomilBjiyrbEvDil5dJ67yG3Rq+u6jWr4s6SnAMJ3AGGC6hDrfQgCZQUPAMr/DmPDkvzrvzMR9dcYqdI/gD5/MHtiaSog==</latexit>
<latexit sha1_base64="zVF/cDu1tConQsSZq4vcr0qZJ6s=">AAAB9XicbVDLSgMxFL3js9ZX1aWbYBFclYkIuiy6cVnRPqCdlkyaaUMzmSHJKGWY/3DjQhG3/os7/8ZMOwttPRA4nHMv9+T4seDauO63s7K6tr6xWdoqb+/s7u1XDg5bOkoUZU0aiUh1fKKZ4JI1DTeCdWLFSOgL1vYnN7nffmRK80g+mGnMvJCMJA84JcZK/V5IzNj30/usn+JsUKm6NXcGtExwQapQoDGofPWGEU1CJg0VROsudmPjpUQZTgXLyr1Es5jQCRmxrqWShEx76Sx1hk6tMkRBpOyTBs3U3xspCbWehr6dzFPqRS8X//O6iQmuvJTLODFM0vmhIBHIRCivAA25YtSIqSWEKm6zIjomilBjiyrbEvDil5dJ67yG3Rq+u6jWr4s6SnAMJ3AGGC6hDrfQgCZQUPAMr/DmPDkvzrvzMR9dcYqdI/gD5/MHtiaSog==</latexit>
<latexit sha1_base64="zVF/cDu1tConQsSZq4vcr0qZJ6s=">AAAB9XicbVDLSgMxFL3js9ZX1aWbYBFclYkIuiy6cVnRPqCdlkyaaUMzmSHJKGWY/3DjQhG3/os7/8ZMOwttPRA4nHMv9+T4seDauO63s7K6tr6xWdoqb+/s7u1XDg5bOkoUZU0aiUh1fKKZ4JI1DTeCdWLFSOgL1vYnN7nffmRK80g+mGnMvJCMJA84JcZK/V5IzNj30/usn+JsUKm6NXcGtExwQapQoDGofPWGEU1CJg0VROsudmPjpUQZTgXLyr1Es5jQCRmxrqWShEx76Sx1hk6tMkRBpOyTBs3U3xspCbWehr6dzFPqRS8X//O6iQmuvJTLODFM0vmhIBHIRCivAA25YtSIqSWEKm6zIjomilBjiyrbEvDil5dJ67yG3Rq+u6jWr4s6SnAMJ3AGGC6hDrfQgCZQUPAMr/DmPDkvzrvzMR9dcYqdI/gD5/MHtiaSog==</latexit>

xt

<latexit sha1_base64="9enq+mmFpcUJ39EbQMVcj+roths=">AAAB+XicdVDNS8MwHE3n15xfVY9egkPwVNJatnkbePE4wc3BVkqapltY+kGSDkfZf+LFgyJe/U+8+d+YbhNU9EHI473fj7y8IONMKoQ+jMra+sbmVnW7trO7t39gHh71ZJoLQrsk5anoB1hSzhLaVUxx2s8ExXHA6V0wuSr9uykVkqXJrZpl1IvxKGERI1hpyTfNYZDyUM5ifRX3c1/5Zh1Zl62G4zYgshBq2o5dEqfpXrjQ1kqJOlih45vvwzAleUwTRTiWcmCjTHkFFooRTue1YS5phskEj+hA0wTHVHrFIvkcnmklhFEq9EkUXKjfNwocyzKcnoyxGsvfXin+5Q1yFbW8giVZrmhClg9FOYcqhWUNMGSCEsVnmmAimM4KyRgLTJQuq6ZL+Pop/J/0HMtGln3j1ttoVUcVnIBTcA5s0ARtcA06oAsImIIH8ASejcJ4NF6M1+VoxVjtHIMfMN4+AbwSlFE=</latexit>
<latexit sha1_base64="9enq+mmFpcUJ39EbQMVcj+roths=">AAAB+XicdVDNS8MwHE3n15xfVY9egkPwVNJatnkbePE4wc3BVkqapltY+kGSDkfZf+LFgyJe/U+8+d+YbhNU9EHI473fj7y8IONMKoQ+jMra+sbmVnW7trO7t39gHh71ZJoLQrsk5anoB1hSzhLaVUxx2s8ExXHA6V0wuSr9uykVkqXJrZpl1IvxKGERI1hpyTfNYZDyUM5ifRX3c1/5Zh1Zl62G4zYgshBq2o5dEqfpXrjQ1kqJOlih45vvwzAleUwTRTiWcmCjTHkFFooRTue1YS5phskEj+hA0wTHVHrFIvkcnmklhFEq9EkUXKjfNwocyzKcnoyxGsvfXin+5Q1yFbW8giVZrmhClg9FOYcqhWUNMGSCEsVnmmAimM4KyRgLTJQuq6ZL+Pop/J/0HMtGln3j1ttoVUcVnIBTcA5s0ARtcA06oAsImIIH8ASejcJ4NF6M1+VoxVjtHIMfMN4+AbwSlFE=</latexit>
<latexit sha1_base64="9enq+mmFpcUJ39EbQMVcj+roths=">AAAB+XicdVDNS8MwHE3n15xfVY9egkPwVNJatnkbePE4wc3BVkqapltY+kGSDkfZf+LFgyJe/U+8+d+YbhNU9EHI473fj7y8IONMKoQ+jMra+sbmVnW7trO7t39gHh71ZJoLQrsk5anoB1hSzhLaVUxx2s8ExXHA6V0wuSr9uykVkqXJrZpl1IvxKGERI1hpyTfNYZDyUM5ifRX3c1/5Zh1Zl62G4zYgshBq2o5dEqfpXrjQ1kqJOlih45vvwzAleUwTRTiWcmCjTHkFFooRTue1YS5phskEj+hA0wTHVHrFIvkcnmklhFEq9EkUXKjfNwocyzKcnoyxGsvfXin+5Q1yFbW8giVZrmhClg9FOYcqhWUNMGSCEsVnmmAimM4KyRgLTJQuq6ZL+Pop/J/0HMtGln3j1ttoVUcVnIBTcA5s0ARtcA06oAsImIIH8ASejcJ4NF6M1+VoxVjtHIMfMN4+AbwSlFE=</latexit>
<latexit sha1_base64="9enq+mmFpcUJ39EbQMVcj+roths=">AAAB+XicdVDNS8MwHE3n15xfVY9egkPwVNJatnkbePE4wc3BVkqapltY+kGSDkfZf+LFgyJe/U+8+d+YbhNU9EHI473fj7y8IONMKoQ+jMra+sbmVnW7trO7t39gHh71ZJoLQrsk5anoB1hSzhLaVUxx2s8ExXHA6V0wuSr9uykVkqXJrZpl1IvxKGERI1hpyTfNYZDyUM5ifRX3c1/5Zh1Zl62G4zYgshBq2o5dEqfpXrjQ1kqJOlih45vvwzAleUwTRTiWcmCjTHkFFooRTue1YS5phskEj+hA0wTHVHrFIvkcnmklhFEq9EkUXKjfNwocyzKcnoyxGsvfXin+5Q1yFbW8giVZrmhClg9FOYcqhWUNMGSCEsVnmmAimM4KyRgLTJQuq6ZL+Pop/J/0HMtGln3j1ttoVUcVnIBTcA5s0ARtcA06oAsImIIH8ASejcJ4NF6M1+VoxVjtHIMfMN4+AbwSlFE=</latexit>

O<latexit sha1_base64="UaeGPGlSTEcc6/SnXGnxtlHbwMU=">AAAB6HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lE0GPRizdbsB/QhrLZTtq1m03Y3Qgl9Bd48aCIV3+SN/+N2zYHbX0w8Hhvhpl5QSK4Nq777RTW1jc2t4rbpZ3dvf2D8uFRS8epYthksYhVJ6AaBZfYNNwI7CQKaRQIbAfj25nffkKleSwfzCRBP6JDyUPOqLFS475frrhVdw6ySrycVCBHvV/+6g1ilkYoDRNU667nJsbPqDKcCZyWeqnGhLIxHWLXUkkj1H42P3RKzqwyIGGsbElD5urviYxGWk+iwHZG1Iz0sjcT//O6qQmv/YzLJDUo2WJRmApiYjL7mgy4QmbExBLKFLe3EjaiijJjsynZELzll1dJ66LquVWvcVmp3eRxFOEETuEcPLiCGtxBHZrAAOEZXuHNeXRenHfnY9FacPKZY/gD5/MHqBWM0w==</latexit>

<latexit sha1_base64="UaeGPGlSTEcc6/SnXGnxtlHbwMU=">AAAB6HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lE0GPRizdbsB/QhrLZTtq1m03Y3Qgl9Bd48aCIV3+SN/+N2zYHbX0w8Hhvhpl5QSK4Nq777RTW1jc2t4rbpZ3dvf2D8uFRS8epYthksYhVJ6AaBZfYNNwI7CQKaRQIbAfj25nffkKleSwfzCRBP6JDyUPOqLFS475frrhVdw6ySrycVCBHvV/+6g1ilkYoDRNU667nJsbPqDKcCZyWeqnGhLIxHWLXUkkj1H42P3RKzqwyIGGsbElD5urviYxGWk+iwHZG1Iz0sjcT//O6qQmv/YzLJDUo2WJRmApiYjL7mgy4QmbExBLKFLe3EjaiijJjsynZELzll1dJ66LquVWvcVmp3eRxFOEETuEcPLiCGtxBHZrAAOEZXuHNeXRenHfnY9FacPKZY/gD5/MHqBWM0w==</latexit>
<latexit sha1_base64="UaeGPGlSTEcc6/SnXGnxtlHbwMU=">AAAB6HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lE0GPRizdbsB/QhrLZTtq1m03Y3Qgl9Bd48aCIV3+SN/+N2zYHbX0w8Hhvhpl5QSK4Nq777RTW1jc2t4rbpZ3dvf2D8uFRS8epYthksYhVJ6AaBZfYNNwI7CQKaRQIbAfj25nffkKleSwfzCRBP6JDyUPOqLFS475frrhVdw6ySrycVCBHvV/+6g1ilkYoDRNU667nJsbPqDKcCZyWeqnGhLIxHWLXUkkj1H42P3RKzqwyIGGsbElD5urviYxGWk+iwHZG1Iz0sjcT//O6qQmv/YzLJDUo2WJRmApiYjL7mgy4QmbExBLKFLe3EjaiijJjsynZELzll1dJ66LquVWvcVmp3eRxFOEETuEcPLiCGtxBHZrAAOEZXuHNeXRenHfnY9FacPKZY/gD5/MHqBWM0w==</latexit>
<latexit sha1_base64="hP+6LrUf2d3tZaldqaQQvEKMXyw=">AAAB2XicbZDNSgMxFIXv1L86Vq1rN8EiuCozbnQpuHFZwbZCO5RM5k4bmskMyR2hDH0BF25EfC93vo3pz0JbDwQ+zknIvSculLQUBN9ebWd3b/+gfugfNfzjk9Nmo2fz0gjsilzl5jnmFpXU2CVJCp8LgzyLFfbj6f0i77+gsTLXTzQrMMr4WMtUCk7O6oyaraAdLMW2IVxDC9YaNb+GSS7KDDUJxa0dhEFBUcUNSaFw7g9LiwUXUz7GgUPNM7RRtRxzzi6dk7A0N+5oYkv394uKZ9bOstjdzDhN7Ga2MP/LBiWlt1EldVESarH6KC0Vo5wtdmaJNChIzRxwYaSblYkJN1yQa8Z3HYSbG29D77odBu3wMYA6nMMFXEEIN3AHD9CBLghI4BXevYn35n2suqp569LO4I+8zx84xIo4</latexit>
<latexit sha1_base64="Z07julpOBXN90Cdgu4O9g46E6ws=">AAAB3XicbZBLSwMxFIXv1FetVatbN8EiuCozbnQpuHFnC/YB7VAy6Z02NpMZkjtCKf0Fblwo4t9y578xfSy09UDg45yE3HuiTElLvv/tFba2d3b3ivulg/Lh0XHlpNyyaW4ENkWqUtOJuEUlNTZJksJOZpAnkcJ2NL6b5+1nNFam+pEmGYYJH2oZS8HJWY2HfqXq1/yF2CYEK6jCSvV+5as3SEWeoCahuLXdwM8onHJDUiiclXq5xYyLMR9i16HmCdpwuhh0xi6cM2BxatzRxBbu7xdTnlg7SSJ3M+E0suvZ3Pwv6+YU34RTqbOcUIvlR3GuGKVsvjUbSIOC1MQBF0a6WZkYccMFuW5KroRgfeVNaF3VAr8WNHwowhmcwyUEcA23cA91aIIAhBd4g3fvyXv1PpZ1FbxVb6fwR97nD5Uyi4A=</latexit>
<latexit sha1_base64="Z07julpOBXN90Cdgu4O9g46E6ws=">AAAB3XicbZBLSwMxFIXv1FetVatbN8EiuCozbnQpuHFnC/YB7VAy6Z02NpMZkjtCKf0Fblwo4t9y578xfSy09UDg45yE3HuiTElLvv/tFba2d3b3ivulg/Lh0XHlpNyyaW4ENkWqUtOJuEUlNTZJksJOZpAnkcJ2NL6b5+1nNFam+pEmGYYJH2oZS8HJWY2HfqXq1/yF2CYEK6jCSvV+5as3SEWeoCahuLXdwM8onHJDUiiclXq5xYyLMR9i16HmCdpwuhh0xi6cM2BxatzRxBbu7xdTnlg7SSJ3M+E0suvZ3Pwv6+YU34RTqbOcUIvlR3GuGKVsvjUbSIOC1MQBF0a6WZkYccMFuW5KroRgfeVNaF3VAr8WNHwowhmcwyUEcA23cA91aIIAhBd4g3fvyXv1PpZ1FbxVb6fwR97nD5Uyi4A=</latexit>
<latexit sha1_base64="+4LGwp8UvmKKaDKjz+np2NzJZkU=">AAAB6HicbVA9SwNBEJ2LXzF+RS1tFoNgFe5sTBm0sTMB8wHJEfY2c8mavb1jd08IR36BjYUitv4kO/+Nm+QKTXww8Hhvhpl5QSK4Nq777RQ2Nre2d4q7pb39g8Oj8vFJW8epYthisYhVN6AaBZfYMtwI7CYKaRQI7AST27nfeUKleSwfzDRBP6IjyUPOqLFS835QrrhVdwGyTrycVCBHY1D+6g9jlkYoDRNU657nJsbPqDKcCZyV+qnGhLIJHWHPUkkj1H62OHRGLqwyJGGsbElDFurviYxGWk+jwHZG1Iz1qjcX//N6qQlrfsZlkhqUbLkoTAUxMZl/TYZcITNiagllittbCRtTRZmx2ZRsCN7qy+ukfVX13KrXdCv1mzyOIpzBOVyCB9dQhztoQAsYIDzDK7w5j86L8+58LFsLTj5zCn/gfP4AptWMzw==</latexit>
<latexit sha1_base64="UaeGPGlSTEcc6/SnXGnxtlHbwMU=">AAAB6HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lE0GPRizdbsB/QhrLZTtq1m03Y3Qgl9Bd48aCIV3+SN/+N2zYHbX0w8Hhvhpl5QSK4Nq777RTW1jc2t4rbpZ3dvf2D8uFRS8epYthksYhVJ6AaBZfYNNwI7CQKaRQIbAfj25nffkKleSwfzCRBP6JDyUPOqLFS475frrhVdw6ySrycVCBHvV/+6g1ilkYoDRNU667nJsbPqDKcCZyWeqnGhLIxHWLXUkkj1H42P3RKzqwyIGGsbElD5urviYxGWk+iwHZG1Iz0sjcT//O6qQmv/YzLJDUo2WJRmApiYjL7mgy4QmbExBLKFLe3EjaiijJjsynZELzll1dJ66LquVWvcVmp3eRxFOEETuEcPLiCGtxBHZrAAOEZXuHNeXRenHfnY9FacPKZY/gD5/MHqBWM0w==</latexit>
<latexit sha1_base64="UaeGPGlSTEcc6/SnXGnxtlHbwMU=">AAAB6HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lE0GPRizdbsB/QhrLZTtq1m03Y3Qgl9Bd48aCIV3+SN/+N2zYHbX0w8Hhvhpl5QSK4Nq777RTW1jc2t4rbpZ3dvf2D8uFRS8epYthksYhVJ6AaBZfYNNwI7CQKaRQIbAfj25nffkKleSwfzCRBP6JDyUPOqLFS475frrhVdw6ySrycVCBHvV/+6g1ilkYoDRNU667nJsbPqDKcCZyWeqnGhLIxHWLXUkkj1H42P3RKzqwyIGGsbElD5urviYxGWk+iwHZG1Iz0sjcT//O6qQmv/YzLJDUo2WJRmApiYjL7mgy4QmbExBLKFLe3EjaiijJjsynZELzll1dJ66LquVWvcVmp3eRxFOEETuEcPLiCGtxBHZrAAOEZXuHNeXRenHfnY9FacPKZY/gD5/MHqBWM0w==</latexit>
<latexit sha1_base64="UaeGPGlSTEcc6/SnXGnxtlHbwMU=">AAAB6HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lE0GPRizdbsB/QhrLZTtq1m03Y3Qgl9Bd48aCIV3+SN/+N2zYHbX0w8Hhvhpl5QSK4Nq777RTW1jc2t4rbpZ3dvf2D8uFRS8epYthksYhVJ6AaBZfYNNwI7CQKaRQIbAfj25nffkKleSwfzCRBP6JDyUPOqLFS475frrhVdw6ySrycVCBHvV/+6g1ilkYoDRNU667nJsbPqDKcCZyWeqnGhLIxHWLXUkkj1H42P3RKzqwyIGGsbElD5urviYxGWk+iwHZG1Iz0sjcT//O6qQmv/YzLJDUo2WJRmApiYjL7mgy4QmbExBLKFLe3EjaiijJjsynZELzll1dJ66LquVWvcVmp3eRxFOEETuEcPLiCGtxBHZrAAOEZXuHNeXRenHfnY9FacPKZY/gD5/MHqBWM0w==</latexit>
<latexit sha1_base64="UaeGPGlSTEcc6/SnXGnxtlHbwMU=">AAAB6HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lE0GPRizdbsB/QhrLZTtq1m03Y3Qgl9Bd48aCIV3+SN/+N2zYHbX0w8Hhvhpl5QSK4Nq777RTW1jc2t4rbpZ3dvf2D8uFRS8epYthksYhVJ6AaBZfYNNwI7CQKaRQIbAfj25nffkKleSwfzCRBP6JDyUPOqLFS475frrhVdw6ySrycVCBHvV/+6g1ilkYoDRNU667nJsbPqDKcCZyWeqnGhLIxHWLXUkkj1H42P3RKzqwyIGGsbElD5urviYxGWk+iwHZG1Iz0sjcT//O6qQmv/YzLJDUo2WJRmApiYjL7mgy4QmbExBLKFLe3EjaiijJjsynZELzll1dJ66LquVWvcVmp3eRxFOEETuEcPLiCGtxBHZrAAOEZXuHNeXRenHfnY9FacPKZY/gD5/MHqBWM0w==</latexit>
<latexit sha1_base64="UaeGPGlSTEcc6/SnXGnxtlHbwMU=">AAAB6HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lE0GPRizdbsB/QhrLZTtq1m03Y3Qgl9Bd48aCIV3+SN/+N2zYHbX0w8Hhvhpl5QSK4Nq777RTW1jc2t4rbpZ3dvf2D8uFRS8epYthksYhVJ6AaBZfYNNwI7CQKaRQIbAfj25nffkKleSwfzCRBP6JDyUPOqLFS475frrhVdw6ySrycVCBHvV/+6g1ilkYoDRNU667nJsbPqDKcCZyWeqnGhLIxHWLXUkkj1H42P3RKzqwyIGGsbElD5urviYxGWk+iwHZG1Iz0sjcT//O6qQmv/YzLJDUo2WJRmApiYjL7mgy4QmbExBLKFLe3EjaiijJjsynZELzll1dJ66LquVWvcVmp3eRxFOEETuEcPLiCGtxBHZrAAOEZXuHNeXRenHfnY9FacPKZY/gD5/MHqBWM0w==</latexit>
<latexit sha1_base64="UaeGPGlSTEcc6/SnXGnxtlHbwMU=">AAAB6HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lE0GPRizdbsB/QhrLZTtq1m03Y3Qgl9Bd48aCIV3+SN/+N2zYHbX0w8Hhvhpl5QSK4Nq777RTW1jc2t4rbpZ3dvf2D8uFRS8epYthksYhVJ6AaBZfYNNwI7CQKaRQIbAfj25nffkKleSwfzCRBP6JDyUPOqLFS475frrhVdw6ySrycVCBHvV/+6g1ilkYoDRNU667nJsbPqDKcCZyWeqnGhLIxHWLXUkkj1H42P3RKzqwyIGGsbElD5urviYxGWk+iwHZG1Iz0sjcT//O6qQmv/YzLJDUo2WJRmApiYjL7mgy4QmbExBLKFLe3EjaiijJjsynZELzll1dJ66LquVWvcVmp3eRxFOEETuEcPLiCGtxBHZrAAOEZXuHNeXRenHfnY9FacPKZY/gD5/MHqBWM0w==</latexit>

TxtS1

<latexit sha1_base64="g7ywfvtlq/AGxWinhbm8wYj3dPg=">AAACC3icbVC7TsMwFHXKq5RXgJElaoXEVCUICcYKFsYi+pKaEDmO01p14sh2EJWVnYVfYWEAIVZ+gI2/wWkzQMuVLB+dc6/uuSdIKRHStr+Nysrq2vpGdbO2tb2zu2fuH/QEyzjCXcQo44MACkxJgruSSIoHKccwDijuB5OrQu/fYy4ISzpymmIvhqOERARBqSnfrHd85QaMhmIa6089+DLP3RjKcRCo2/xOOblvNuymPStrGTglaICy2r755YYMZTFOJKJQiKFjp9JTkEuCKM5rbiZwCtEEjvBQwwTGWHhqdktuHWsmtCLG9UukNWN/TygYi8Kr7ixcikWtIP/ThpmMLjxFkjSTOEHzRVFGLcmsIhgrJBwjSacaQMSJ9mqhMeQQSR1fTYfgLJ68DHqnTcduOjdnjdZlGUcVHIE6OAEOOActcA3aoAsQeATP4BW8GU/Gi/FufMxbK0Y5cwj+lPH5A77InBw=</latexit>
<latexit sha1_base64="g7ywfvtlq/AGxWinhbm8wYj3dPg=">AAACC3icbVC7TsMwFHXKq5RXgJElaoXEVCUICcYKFsYi+pKaEDmO01p14sh2EJWVnYVfYWEAIVZ+gI2/wWkzQMuVLB+dc6/uuSdIKRHStr+Nysrq2vpGdbO2tb2zu2fuH/QEyzjCXcQo44MACkxJgruSSIoHKccwDijuB5OrQu/fYy4ISzpymmIvhqOERARBqSnfrHd85QaMhmIa6089+DLP3RjKcRCo2/xOOblvNuymPStrGTglaICy2r755YYMZTFOJKJQiKFjp9JTkEuCKM5rbiZwCtEEjvBQwwTGWHhqdktuHWsmtCLG9UukNWN/TygYi8Kr7ixcikWtIP/ThpmMLjxFkjSTOEHzRVFGLcmsIhgrJBwjSacaQMSJ9mqhMeQQSR1fTYfgLJ68DHqnTcduOjdnjdZlGUcVHIE6OAEOOActcA3aoAsQeATP4BW8GU/Gi/FufMxbK0Y5cwj+lPH5A77InBw=</latexit>
<latexit sha1_base64="g7ywfvtlq/AGxWinhbm8wYj3dPg=">AAACC3icbVC7TsMwFHXKq5RXgJElaoXEVCUICcYKFsYi+pKaEDmO01p14sh2EJWVnYVfYWEAIVZ+gI2/wWkzQMuVLB+dc6/uuSdIKRHStr+Nysrq2vpGdbO2tb2zu2fuH/QEyzjCXcQo44MACkxJgruSSIoHKccwDijuB5OrQu/fYy4ISzpymmIvhqOERARBqSnfrHd85QaMhmIa6089+DLP3RjKcRCo2/xOOblvNuymPStrGTglaICy2r755YYMZTFOJKJQiKFjp9JTkEuCKM5rbiZwCtEEjvBQwwTGWHhqdktuHWsmtCLG9UukNWN/TygYi8Kr7ixcikWtIP/ThpmMLjxFkjSTOEHzRVFGLcmsIhgrJBwjSacaQMSJ9mqhMeQQSR1fTYfgLJ68DHqnTcduOjdnjdZlGUcVHIE6OAEOOActcA3aoAsQeATP4BW8GU/Gi/FufMxbK0Y5cwj+lPH5A77InBw=</latexit>
<latexit sha1_base64="g7ywfvtlq/AGxWinhbm8wYj3dPg=">AAACC3icbVC7TsMwFHXKq5RXgJElaoXEVCUICcYKFsYi+pKaEDmO01p14sh2EJWVnYVfYWEAIVZ+gI2/wWkzQMuVLB+dc6/uuSdIKRHStr+Nysrq2vpGdbO2tb2zu2fuH/QEyzjCXcQo44MACkxJgruSSIoHKccwDijuB5OrQu/fYy4ISzpymmIvhqOERARBqSnfrHd85QaMhmIa6089+DLP3RjKcRCo2/xOOblvNuymPStrGTglaICy2r755YYMZTFOJKJQiKFjp9JTkEuCKM5rbiZwCtEEjvBQwwTGWHhqdktuHWsmtCLG9UukNWN/TygYi8Kr7ixcikWtIP/ThpmMLjxFkjSTOEHzRVFGLcmsIhgrJBwjSacaQMSJ9mqhMeQQSR1fTYfgLJ68DHqnTcduOjdnjdZlGUcVHIE6OAEOOActcA3aoAsQeATP4BW8GU/Gi/FufMxbK0Y5cwj+lPH5A77InBw=</latexit>

S1

<latexit sha1_base64="zVF/cDu1tConQsSZq4vcr0qZJ6s=">AAAB9XicbVDLSgMxFL3js9ZX1aWbYBFclYkIuiy6cVnRPqCdlkyaaUMzmSHJKGWY/3DjQhG3/os7/8ZMOwttPRA4nHMv9+T4seDauO63s7K6tr6xWdoqb+/s7u1XDg5bOkoUZU0aiUh1fKKZ4JI1DTeCdWLFSOgL1vYnN7nffmRK80g+mGnMvJCMJA84JcZK/V5IzNj30/usn+JsUKm6NXcGtExwQapQoDGofPWGEU1CJg0VROsudmPjpUQZTgXLyr1Es5jQCRmxrqWShEx76Sx1hk6tMkRBpOyTBs3U3xspCbWehr6dzFPqRS8X//O6iQmuvJTLODFM0vmhIBHIRCivAA25YtSIqSWEKm6zIjomilBjiyrbEvDil5dJ67yG3Rq+u6jWr4s6SnAMJ3AGGC6hDrfQgCZQUPAMr/DmPDkvzrvzMR9dcYqdI/gD5/MHtiaSog==</latexit>
<latexit sha1_base64="zVF/cDu1tConQsSZq4vcr0qZJ6s=">AAAB9XicbVDLSgMxFL3js9ZX1aWbYBFclYkIuiy6cVnRPqCdlkyaaUMzmSHJKGWY/3DjQhG3/os7/8ZMOwttPRA4nHMv9+T4seDauO63s7K6tr6xWdoqb+/s7u1XDg5bOkoUZU0aiUh1fKKZ4JI1DTeCdWLFSOgL1vYnN7nffmRK80g+mGnMvJCMJA84JcZK/V5IzNj30/usn+JsUKm6NXcGtExwQapQoDGofPWGEU1CJg0VROsudmPjpUQZTgXLyr1Es5jQCRmxrqWShEx76Sx1hk6tMkRBpOyTBs3U3xspCbWehr6dzFPqRS8X//O6iQmuvJTLODFM0vmhIBHIRCivAA25YtSIqSWEKm6zIjomilBjiyrbEvDil5dJ67yG3Rq+u6jWr4s6SnAMJ3AGGC6hDrfQgCZQUPAMr/DmPDkvzrvzMR9dcYqdI/gD5/MHtiaSog==</latexit>
<latexit sha1_base64="zVF/cDu1tConQsSZq4vcr0qZJ6s=">AAAB9XicbVDLSgMxFL3js9ZX1aWbYBFclYkIuiy6cVnRPqCdlkyaaUMzmSHJKGWY/3DjQhG3/os7/8ZMOwttPRA4nHMv9+T4seDauO63s7K6tr6xWdoqb+/s7u1XDg5bOkoUZU0aiUh1fKKZ4JI1DTeCdWLFSOgL1vYnN7nffmRK80g+mGnMvJCMJA84JcZK/V5IzNj30/usn+JsUKm6NXcGtExwQapQoDGofPWGEU1CJg0VROsudmPjpUQZTgXLyr1Es5jQCRmxrqWShEx76Sx1hk6tMkRBpOyTBs3U3xspCbWehr6dzFPqRS8X//O6iQmuvJTLODFM0vmhIBHIRCivAA25YtSIqSWEKm6zIjomilBjiyrbEvDil5dJ67yG3Rq+u6jWr4s6SnAMJ3AGGC6hDrfQgCZQUPAMr/DmPDkvzrvzMR9dcYqdI/gD5/MHtiaSog==</latexit>
<latexit sha1_base64="zVF/cDu1tConQsSZq4vcr0qZJ6s=">AAAB9XicbVDLSgMxFL3js9ZX1aWbYBFclYkIuiy6cVnRPqCdlkyaaUMzmSHJKGWY/3DjQhG3/os7/8ZMOwttPRA4nHMv9+T4seDauO63s7K6tr6xWdoqb+/s7u1XDg5bOkoUZU0aiUh1fKKZ4JI1DTeCdWLFSOgL1vYnN7nffmRK80g+mGnMvJCMJA84JcZK/V5IzNj30/usn+JsUKm6NXcGtExwQapQoDGofPWGEU1CJg0VROsudmPjpUQZTgXLyr1Es5jQCRmxrqWShEx76Sx1hk6tMkRBpOyTBs3U3xspCbWehr6dzFPqRS8X//O6iQmuvJTLODFM0vmhIBHIRCivAA25YtSIqSWEKm6zIjomilBjiyrbEvDil5dJ67yG3Rq+u6jWr4s6SnAMJ3AGGC6hDrfQgCZQUPAMr/DmPDkvzrvzMR9dcYqdI/gD5/MHtiaSog==</latexit>

xt

<latexit sha1_base64="9enq+mmFpcUJ39EbQMVcj+roths=">AAAB+XicdVDNS8MwHE3n15xfVY9egkPwVNJatnkbePE4wc3BVkqapltY+kGSDkfZf+LFgyJe/U+8+d+YbhNU9EHI473fj7y8IONMKoQ+jMra+sbmVnW7trO7t39gHh71ZJoLQrsk5anoB1hSzhLaVUxx2s8ExXHA6V0wuSr9uykVkqXJrZpl1IvxKGERI1hpyTfNYZDyUM5ifRX3c1/5Zh1Zl62G4zYgshBq2o5dEqfpXrjQ1kqJOlih45vvwzAleUwTRTiWcmCjTHkFFooRTue1YS5phskEj+hA0wTHVHrFIvkcnmklhFEq9EkUXKjfNwocyzKcnoyxGsvfXin+5Q1yFbW8giVZrmhClg9FOYcqhWUNMGSCEsVnmmAimM4KyRgLTJQuq6ZL+Pop/J/0HMtGln3j1ttoVUcVnIBTcA5s0ARtcA06oAsImIIH8ASejcJ4NF6M1+VoxVjtHIMfMN4+AbwSlFE=</latexit>
<latexit sha1_base64="9enq+mmFpcUJ39EbQMVcj+roths=">AAAB+XicdVDNS8MwHE3n15xfVY9egkPwVNJatnkbePE4wc3BVkqapltY+kGSDkfZf+LFgyJe/U+8+d+YbhNU9EHI473fj7y8IONMKoQ+jMra+sbmVnW7trO7t39gHh71ZJoLQrsk5anoB1hSzhLaVUxx2s8ExXHA6V0wuSr9uykVkqXJrZpl1IvxKGERI1hpyTfNYZDyUM5ifRX3c1/5Zh1Zl62G4zYgshBq2o5dEqfpXrjQ1kqJOlih45vvwzAleUwTRTiWcmCjTHkFFooRTue1YS5phskEj+hA0wTHVHrFIvkcnmklhFEq9EkUXKjfNwocyzKcnoyxGsvfXin+5Q1yFbW8giVZrmhClg9FOYcqhWUNMGSCEsVnmmAimM4KyRgLTJQuq6ZL+Pop/J/0HMtGln3j1ttoVUcVnIBTcA5s0ARtcA06oAsImIIH8ASejcJ4NF6M1+VoxVjtHIMfMN4+AbwSlFE=</latexit>
<latexit sha1_base64="9enq+mmFpcUJ39EbQMVcj+roths=">AAAB+XicdVDNS8MwHE3n15xfVY9egkPwVNJatnkbePE4wc3BVkqapltY+kGSDkfZf+LFgyJe/U+8+d+YbhNU9EHI473fj7y8IONMKoQ+jMra+sbmVnW7trO7t39gHh71ZJoLQrsk5anoB1hSzhLaVUxx2s8ExXHA6V0wuSr9uykVkqXJrZpl1IvxKGERI1hpyTfNYZDyUM5ifRX3c1/5Zh1Zl62G4zYgshBq2o5dEqfpXrjQ1kqJOlih45vvwzAleUwTRTiWcmCjTHkFFooRTue1YS5phskEj+hA0wTHVHrFIvkcnmklhFEq9EkUXKjfNwocyzKcnoyxGsvfXin+5Q1yFbW8giVZrmhClg9FOYcqhWUNMGSCEsVnmmAimM4KyRgLTJQuq6ZL+Pop/J/0HMtGln3j1ttoVUcVnIBTcA5s0ARtcA06oAsImIIH8ASejcJ4NF6M1+VoxVjtHIMfMN4+AbwSlFE=</latexit>
<latexit sha1_base64="9enq+mmFpcUJ39EbQMVcj+roths=">AAAB+XicdVDNS8MwHE3n15xfVY9egkPwVNJatnkbePE4wc3BVkqapltY+kGSDkfZf+LFgyJe/U+8+d+YbhNU9EHI473fj7y8IONMKoQ+jMra+sbmVnW7trO7t39gHh71ZJoLQrsk5anoB1hSzhLaVUxx2s8ExXHA6V0wuSr9uykVkqXJrZpl1IvxKGERI1hpyTfNYZDyUM5ifRX3c1/5Zh1Zl62G4zYgshBq2o5dEqfpXrjQ1kqJOlih45vvwzAleUwTRTiWcmCjTHkFFooRTue1YS5phskEj+hA0wTHVHrFIvkcnmklhFEq9EkUXKjfNwocyzKcnoyxGsvfXin+5Q1yFbW8giVZrmhClg9FOYcqhWUNMGSCEsVnmmAimM4KyRgLTJQuq6ZL+Pop/J/0HMtGln3j1ttoVUcVnIBTcA5s0ARtcA06oAsImIIH8ASejcJ4NF6M1+VoxVjtHIMfMN4+AbwSlFE=</latexit>

O<latexit sha1_base64="UaeGPGlSTEcc6/SnXGnxtlHbwMU=">AAAB6HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lE0GPRizdbsB/QhrLZTtq1m03Y3Qgl9Bd48aCIV3+SN/+N2zYHbX0w8Hhvhpl5QSK4Nq777RTW1jc2t4rbpZ3dvf2D8uFRS8epYthksYhVJ6AaBZfYNNwI7CQKaRQIbAfj25nffkKleSwfzCRBP6JDyUPOqLFS475frrhVdw6ySrycVCBHvV/+6g1ilkYoDRNU667nJsbPqDKcCZyWeqnGhLIxHWLXUkkj1H42P3RKzqwyIGGsbElD5urviYxGWk+iwHZG1Iz0sjcT//O6qQmv/YzLJDUo2WJRmApiYjL7mgy4QmbExBLKFLe3EjaiijJjsynZELzll1dJ66LquVWvcVmp3eRxFOEETuEcPLiCGtxBHZrAAOEZXuHNeXRenHfnY9FacPKZY/gD5/MHqBWM0w==</latexit>

<latexit sha1_base64="UaeGPGlSTEcc6/SnXGnxtlHbwMU=">AAAB6HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lE0GPRizdbsB/QhrLZTtq1m03Y3Qgl9Bd48aCIV3+SN/+N2zYHbX0w8Hhvhpl5QSK4Nq777RTW1jc2t4rbpZ3dvf2D8uFRS8epYthksYhVJ6AaBZfYNNwI7CQKaRQIbAfj25nffkKleSwfzCRBP6JDyUPOqLFS475frrhVdw6ySrycVCBHvV/+6g1ilkYoDRNU667nJsbPqDKcCZyWeqnGhLIxHWLXUkkj1H42P3RKzqwyIGGsbElD5urviYxGWk+iwHZG1Iz0sjcT//O6qQmv/YzLJDUo2WJRmApiYjL7mgy4QmbExBLKFLe3EjaiijJjsynZELzll1dJ66LquVWvcVmp3eRxFOEETuEcPLiCGtxBHZrAAOEZXuHNeXRenHfnY9FacPKZY/gD5/MHqBWM0w==</latexit>
<latexit sha1_base64="UaeGPGlSTEcc6/SnXGnxtlHbwMU=">AAAB6HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lE0GPRizdbsB/QhrLZTtq1m03Y3Qgl9Bd48aCIV3+SN/+N2zYHbX0w8Hhvhpl5QSK4Nq777RTW1jc2t4rbpZ3dvf2D8uFRS8epYthksYhVJ6AaBZfYNNwI7CQKaRQIbAfj25nffkKleSwfzCRBP6JDyUPOqLFS475frrhVdw6ySrycVCBHvV/+6g1ilkYoDRNU667nJsbPqDKcCZyWeqnGhLIxHWLXUkkj1H42P3RKzqwyIGGsbElD5urviYxGWk+iwHZG1Iz0sjcT//O6qQmv/YzLJDUo2WJRmApiYjL7mgy4QmbExBLKFLe3EjaiijJjsynZELzll1dJ66LquVWvcVmp3eRxFOEETuEcPLiCGtxBHZrAAOEZXuHNeXRenHfnY9FacPKZY/gD5/MHqBWM0w==</latexit>
<latexit sha1_base64="hP+6LrUf2d3tZaldqaQQvEKMXyw=">AAAB2XicbZDNSgMxFIXv1L86Vq1rN8EiuCozbnQpuHFZwbZCO5RM5k4bmskMyR2hDH0BF25EfC93vo3pz0JbDwQ+zknIvSculLQUBN9ebWd3b/+gfugfNfzjk9Nmo2fz0gjsilzl5jnmFpXU2CVJCp8LgzyLFfbj6f0i77+gsTLXTzQrMMr4WMtUCk7O6oyaraAdLMW2IVxDC9YaNb+GSS7KDDUJxa0dhEFBUcUNSaFw7g9LiwUXUz7GgUPNM7RRtRxzzi6dk7A0N+5oYkv394uKZ9bOstjdzDhN7Ga2MP/LBiWlt1EldVESarH6KC0Vo5wtdmaJNChIzRxwYaSblYkJN1yQa8Z3HYSbG29D77odBu3wMYA6nMMFXEEIN3AHD9CBLghI4BXevYn35n2suqp569LO4I+8zx84xIo4</latexit>
<latexit sha1_base64="Z07julpOBXN90Cdgu4O9g46E6ws=">AAAB3XicbZBLSwMxFIXv1FetVatbN8EiuCozbnQpuHFnC/YB7VAy6Z02NpMZkjtCKf0Fblwo4t9y578xfSy09UDg45yE3HuiTElLvv/tFba2d3b3ivulg/Lh0XHlpNyyaW4ENkWqUtOJuEUlNTZJksJOZpAnkcJ2NL6b5+1nNFam+pEmGYYJH2oZS8HJWY2HfqXq1/yF2CYEK6jCSvV+5as3SEWeoCahuLXdwM8onHJDUiiclXq5xYyLMR9i16HmCdpwuhh0xi6cM2BxatzRxBbu7xdTnlg7SSJ3M+E0suvZ3Pwv6+YU34RTqbOcUIvlR3GuGKVsvjUbSIOC1MQBF0a6WZkYccMFuW5KroRgfeVNaF3VAr8WNHwowhmcwyUEcA23cA91aIIAhBd4g3fvyXv1PpZ1FbxVb6fwR97nD5Uyi4A=</latexit>
<latexit sha1_base64="Z07julpOBXN90Cdgu4O9g46E6ws=">AAAB3XicbZBLSwMxFIXv1FetVatbN8EiuCozbnQpuHFnC/YB7VAy6Z02NpMZkjtCKf0Fblwo4t9y578xfSy09UDg45yE3HuiTElLvv/tFba2d3b3ivulg/Lh0XHlpNyyaW4ENkWqUtOJuEUlNTZJksJOZpAnkcJ2NL6b5+1nNFam+pEmGYYJH2oZS8HJWY2HfqXq1/yF2CYEK6jCSvV+5as3SEWeoCahuLXdwM8onHJDUiiclXq5xYyLMR9i16HmCdpwuhh0xi6cM2BxatzRxBbu7xdTnlg7SSJ3M+E0suvZ3Pwv6+YU34RTqbOcUIvlR3GuGKVsvjUbSIOC1MQBF0a6WZkYccMFuW5KroRgfeVNaF3VAr8WNHwowhmcwyUEcA23cA91aIIAhBd4g3fvyXv1PpZ1FbxVb6fwR97nD5Uyi4A=</latexit>
<latexit sha1_base64="+4LGwp8UvmKKaDKjz+np2NzJZkU=">AAAB6HicbVA9SwNBEJ2LXzF+RS1tFoNgFe5sTBm0sTMB8wHJEfY2c8mavb1jd08IR36BjYUitv4kO/+Nm+QKTXww8Hhvhpl5QSK4Nq777RQ2Nre2d4q7pb39g8Oj8vFJW8epYthisYhVN6AaBZfYMtwI7CYKaRQI7AST27nfeUKleSwfzDRBP6IjyUPOqLFS835QrrhVdwGyTrycVCBHY1D+6g9jlkYoDRNU657nJsbPqDKcCZyV+qnGhLIJHWHPUkkj1H62OHRGLqwyJGGsbElDFurviYxGWk+jwHZG1Iz1qjcX//N6qQlrfsZlkhqUbLkoTAUxMZl/TYZcITNiagllittbCRtTRZmx2ZRsCN7qy+ukfVX13KrXdCv1mzyOIpzBOVyCB9dQhztoQAsYIDzDK7w5j86L8+58LFsLTj5zCn/gfP4AptWMzw==</latexit>
<latexit sha1_base64="UaeGPGlSTEcc6/SnXGnxtlHbwMU=">AAAB6HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lE0GPRizdbsB/QhrLZTtq1m03Y3Qgl9Bd48aCIV3+SN/+N2zYHbX0w8Hhvhpl5QSK4Nq777RTW1jc2t4rbpZ3dvf2D8uFRS8epYthksYhVJ6AaBZfYNNwI7CQKaRQIbAfj25nffkKleSwfzCRBP6JDyUPOqLFS475frrhVdw6ySrycVCBHvV/+6g1ilkYoDRNU667nJsbPqDKcCZyWeqnGhLIxHWLXUkkj1H42P3RKzqwyIGGsbElD5urviYxGWk+iwHZG1Iz0sjcT//O6qQmv/YzLJDUo2WJRmApiYjL7mgy4QmbExBLKFLe3EjaiijJjsynZELzll1dJ66LquVWvcVmp3eRxFOEETuEcPLiCGtxBHZrAAOEZXuHNeXRenHfnY9FacPKZY/gD5/MHqBWM0w==</latexit>
<latexit sha1_base64="UaeGPGlSTEcc6/SnXGnxtlHbwMU=">AAAB6HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lE0GPRizdbsB/QhrLZTtq1m03Y3Qgl9Bd48aCIV3+SN/+N2zYHbX0w8Hhvhpl5QSK4Nq777RTW1jc2t4rbpZ3dvf2D8uFRS8epYthksYhVJ6AaBZfYNNwI7CQKaRQIbAfj25nffkKleSwfzCRBP6JDyUPOqLFS475frrhVdw6ySrycVCBHvV/+6g1ilkYoDRNU667nJsbPqDKcCZyWeqnGhLIxHWLXUkkj1H42P3RKzqwyIGGsbElD5urviYxGWk+iwHZG1Iz0sjcT//O6qQmv/YzLJDUo2WJRmApiYjL7mgy4QmbExBLKFLe3EjaiijJjsynZELzll1dJ66LquVWvcVmp3eRxFOEETuEcPLiCGtxBHZrAAOEZXuHNeXRenHfnY9FacPKZY/gD5/MHqBWM0w==</latexit>
<latexit sha1_base64="UaeGPGlSTEcc6/SnXGnxtlHbwMU=">AAAB6HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lE0GPRizdbsB/QhrLZTtq1m03Y3Qgl9Bd48aCIV3+SN/+N2zYHbX0w8Hhvhpl5QSK4Nq777RTW1jc2t4rbpZ3dvf2D8uFRS8epYthksYhVJ6AaBZfYNNwI7CQKaRQIbAfj25nffkKleSwfzCRBP6JDyUPOqLFS475frrhVdw6ySrycVCBHvV/+6g1ilkYoDRNU667nJsbPqDKcCZyWeqnGhLIxHWLXUkkj1H42P3RKzqwyIGGsbElD5urviYxGWk+iwHZG1Iz0sjcT//O6qQmv/YzLJDUo2WJRmApiYjL7mgy4QmbExBLKFLe3EjaiijJjsynZELzll1dJ66LquVWvcVmp3eRxFOEETuEcPLiCGtxBHZrAAOEZXuHNeXRenHfnY9FacPKZY/gD5/MHqBWM0w==</latexit>
<latexit sha1_base64="UaeGPGlSTEcc6/SnXGnxtlHbwMU=">AAAB6HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lE0GPRizdbsB/QhrLZTtq1m03Y3Qgl9Bd48aCIV3+SN/+N2zYHbX0w8Hhvhpl5QSK4Nq777RTW1jc2t4rbpZ3dvf2D8uFRS8epYthksYhVJ6AaBZfYNNwI7CQKaRQIbAfj25nffkKleSwfzCRBP6JDyUPOqLFS475frrhVdw6ySrycVCBHvV/+6g1ilkYoDRNU667nJsbPqDKcCZyWeqnGhLIxHWLXUkkj1H42P3RKzqwyIGGsbElD5urviYxGWk+iwHZG1Iz0sjcT//O6qQmv/YzLJDUo2WJRmApiYjL7mgy4QmbExBLKFLe3EjaiijJjsynZELzll1dJ66LquVWvcVmp3eRxFOEETuEcPLiCGtxBHZrAAOEZXuHNeXRenHfnY9FacPKZY/gD5/MHqBWM0w==</latexit>
<latexit sha1_base64="UaeGPGlSTEcc6/SnXGnxtlHbwMU=">AAAB6HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lE0GPRizdbsB/QhrLZTtq1m03Y3Qgl9Bd48aCIV3+SN/+N2zYHbX0w8Hhvhpl5QSK4Nq777RTW1jc2t4rbpZ3dvf2D8uFRS8epYthksYhVJ6AaBZfYNNwI7CQKaRQIbAfj25nffkKleSwfzCRBP6JDyUPOqLFS475frrhVdw6ySrycVCBHvV/+6g1ilkYoDRNU667nJsbPqDKcCZyWeqnGhLIxHWLXUkkj1H42P3RKzqwyIGGsbElD5urviYxGWk+iwHZG1Iz0sjcT//O6qQmv/YzLJDUo2WJRmApiYjL7mgy4QmbExBLKFLe3EjaiijJjsynZELzll1dJ66LquVWvcVmp3eRxFOEETuEcPLiCGtxBHZrAAOEZXuHNeXRenHfnY9FacPKZY/gD5/MHqBWM0w==</latexit>
<latexit sha1_base64="UaeGPGlSTEcc6/SnXGnxtlHbwMU=">AAAB6HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lE0GPRizdbsB/QhrLZTtq1m03Y3Qgl9Bd48aCIV3+SN/+N2zYHbX0w8Hhvhpl5QSK4Nq777RTW1jc2t4rbpZ3dvf2D8uFRS8epYthksYhVJ6AaBZfYNNwI7CQKaRQIbAfj25nffkKleSwfzCRBP6JDyUPOqLFS475frrhVdw6ySrycVCBHvV/+6g1ilkYoDRNU667nJsbPqDKcCZyWeqnGhLIxHWLXUkkj1H42P3RKzqwyIGGsbElD5urviYxGWk+iwHZG1Iz0sjcT//O6qQmv/YzLJDUo2WJRmApiYjL7mgy4QmbExBLKFLe3EjaiijJjsynZELzll1dJ66LquVWvcVmp3eRxFOEETuEcPLiCGtxBHZrAAOEZXuHNeXRenHfnY9FacPKZY/gD5/MHqBWM0w==</latexit>

xt+1

<latexit sha1_base64="sCJTyiS9us4IUY6D/qcTTy5Fd5M=">AAAB/XicdVBLSwMxGMz6rPW1Pm5egkUQhCXRLra3ghePFewD2lKy2Wwbmn2QZMW6FP+KFw+KePV/ePPfmG0rqOhAyDDzfWQyXiK40gh9WAuLS8srq4W14vrG5ta2vbPbVHEqKWvQWMSy7RHFBI9YQ3MtWDuRjISeYC1vdJH7rRsmFY+jaz1OWC8kg4gHnBJtpL693/Vi4atxaK7sdtLP9Ame9O0ScpBbdTGCyHERrp7lpFqtlF0XYgdNUQJz1Pv2e9ePaRqySFNBlOpglOheRqTmVLBJsZsqlhA6IgPWMTQiIVO9bJp+Ao+M4sMgluZEGk7V7xsZCVUe0EyGRA/Vby8X//I6qQ4qvYxHSapZRGcPBamAOoZ5FdDnklEtxoYQKrnJCumQSEK1KaxoSvj6KfyfNE8djBx8VS7V0LyOAjgAh+AYYHAOauAS1EEDUHAHHsATeLburUfrxXqdjS5Y85098APW2yeBtJXZ</latexit>
<latexit sha1_base64="sCJTyiS9us4IUY6D/qcTTy5Fd5M=">AAAB/XicdVBLSwMxGMz6rPW1Pm5egkUQhCXRLra3ghePFewD2lKy2Wwbmn2QZMW6FP+KFw+KePV/ePPfmG0rqOhAyDDzfWQyXiK40gh9WAuLS8srq4W14vrG5ta2vbPbVHEqKWvQWMSy7RHFBI9YQ3MtWDuRjISeYC1vdJH7rRsmFY+jaz1OWC8kg4gHnBJtpL693/Vi4atxaK7sdtLP9Ame9O0ScpBbdTGCyHERrp7lpFqtlF0XYgdNUQJz1Pv2e9ePaRqySFNBlOpglOheRqTmVLBJsZsqlhA6IgPWMTQiIVO9bJp+Ao+M4sMgluZEGk7V7xsZCVUe0EyGRA/Vby8X//I6qQ4qvYxHSapZRGcPBamAOoZ5FdDnklEtxoYQKrnJCumQSEK1KaxoSvj6KfyfNE8djBx8VS7V0LyOAjgAh+AYYHAOauAS1EEDUHAHHsATeLburUfrxXqdjS5Y85098APW2yeBtJXZ</latexit>
<latexit sha1_base64="sCJTyiS9us4IUY6D/qcTTy5Fd5M=">AAAB/XicdVBLSwMxGMz6rPW1Pm5egkUQhCXRLra3ghePFewD2lKy2Wwbmn2QZMW6FP+KFw+KePV/ePPfmG0rqOhAyDDzfWQyXiK40gh9WAuLS8srq4W14vrG5ta2vbPbVHEqKWvQWMSy7RHFBI9YQ3MtWDuRjISeYC1vdJH7rRsmFY+jaz1OWC8kg4gHnBJtpL693/Vi4atxaK7sdtLP9Ame9O0ScpBbdTGCyHERrp7lpFqtlF0XYgdNUQJz1Pv2e9ePaRqySFNBlOpglOheRqTmVLBJsZsqlhA6IgPWMTQiIVO9bJp+Ao+M4sMgluZEGk7V7xsZCVUe0EyGRA/Vby8X//I6qQ4qvYxHSapZRGcPBamAOoZ5FdDnklEtxoYQKrnJCumQSEK1KaxoSvj6KfyfNE8djBx8VS7V0LyOAjgAh+AYYHAOauAS1EEDUHAHHsATeLburUfrxXqdjS5Y85098APW2yeBtJXZ</latexit>
<latexit sha1_base64="sCJTyiS9us4IUY6D/qcTTy5Fd5M=">AAAB/XicdVBLSwMxGMz6rPW1Pm5egkUQhCXRLra3ghePFewD2lKy2Wwbmn2QZMW6FP+KFw+KePV/ePPfmG0rqOhAyDDzfWQyXiK40gh9WAuLS8srq4W14vrG5ta2vbPbVHEqKWvQWMSy7RHFBI9YQ3MtWDuRjISeYC1vdJH7rRsmFY+jaz1OWC8kg4gHnBJtpL693/Vi4atxaK7sdtLP9Ame9O0ScpBbdTGCyHERrp7lpFqtlF0XYgdNUQJz1Pv2e9ePaRqySFNBlOpglOheRqTmVLBJsZsqlhA6IgPWMTQiIVO9bJp+Ao+M4sMgluZEGk7V7xsZCVUe0EyGRA/Vby8X//I6qQ4qvYxHSapZRGcPBamAOoZ5FdDnklEtxoYQKrnJCumQSEK1KaxoSvj6KfyfNE8djBx8VS7V0LyOAjgAh+AYYHAOauAS1EEDUHAHHsATeLburUfrxXqdjS5Y85098APW2yeBtJXZ</latexit>

z<latexit sha1_base64="Wet73zNqxVFTEbAnDllx3Pv6AYk=">AAAB9XicdVBLSwMxGMzWV62vqkcvwSJ4WpLS1R4LXjxWsA9oa8lms21odrMkWaUu/R9ePCji1f/izX9jtq2gogMhw8z3kcn4ieDaIPThFFZW19Y3ipulre2d3b3y/kFby1RR1qJSSNX1iWaCx6xluBGsmyhGIl+wjj+5yP3OLVOay/jaTBM2iMgo5iGnxFjppu9LEehpZK/sfjYsV5CLzrwarkPkegjXsWdJ1cMIVSF20RwVsERzWH7vB5KmEYsNFUTrHkaJGWREGU4Fm5X6qWYJoRMyYj1LYxIxPcjmqWfwxCoBDKWyJzZwrn7fyEik82h2MiJmrH97ufiX10tNWB9kPE5Sw2K6eChMBTQS5hXAgCtGjZhaQqjiNiukY6IINbaoki3h66fwf9Kuuhi5+KpWaaBlHUVwBI7BKcDgHDTAJWiCFqBAgQfwBJ6dO+fReXFeF6MFZ7lzCH7AefsEn4iTLw==</latexit>

<latexit sha1_base64="Wet73zNqxVFTEbAnDllx3Pv6AYk=">AAAB9XicdVBLSwMxGMzWV62vqkcvwSJ4WpLS1R4LXjxWsA9oa8lms21odrMkWaUu/R9ePCji1f/izX9jtq2gogMhw8z3kcn4ieDaIPThFFZW19Y3ipulre2d3b3y/kFby1RR1qJSSNX1iWaCx6xluBGsmyhGIl+wjj+5yP3OLVOay/jaTBM2iMgo5iGnxFjppu9LEehpZK/sfjYsV5CLzrwarkPkegjXsWdJ1cMIVSF20RwVsERzWH7vB5KmEYsNFUTrHkaJGWREGU4Fm5X6qWYJoRMyYj1LYxIxPcjmqWfwxCoBDKWyJzZwrn7fyEik82h2MiJmrH97ufiX10tNWB9kPE5Sw2K6eChMBTQS5hXAgCtGjZhaQqjiNiukY6IINbaoki3h66fwf9Kuuhi5+KpWaaBlHUVwBI7BKcDgHDTAJWiCFqBAgQfwBJ6dO+fReXFeF6MFZ7lzCH7AefsEn4iTLw==</latexit>
<latexit sha1_base64="Wet73zNqxVFTEbAnDllx3Pv6AYk=">AAAB9XicdVBLSwMxGMzWV62vqkcvwSJ4WpLS1R4LXjxWsA9oa8lms21odrMkWaUu/R9ePCji1f/izX9jtq2gogMhw8z3kcn4ieDaIPThFFZW19Y3ipulre2d3b3y/kFby1RR1qJSSNX1iWaCx6xluBGsmyhGIl+wjj+5yP3OLVOay/jaTBM2iMgo5iGnxFjppu9LEehpZK/sfjYsV5CLzrwarkPkegjXsWdJ1cMIVSF20RwVsERzWH7vB5KmEYsNFUTrHkaJGWREGU4Fm5X6qWYJoRMyYj1LYxIxPcjmqWfwxCoBDKWyJzZwrn7fyEik82h2MiJmrH97ufiX10tNWB9kPE5Sw2K6eChMBTQS5hXAgCtGjZhaQqjiNiukY6IINbaoki3h66fwf9Kuuhi5+KpWaaBlHUVwBI7BKcDgHDTAJWiCFqBAgQfwBJ6dO+fReXFeF6MFZ7lzCH7AefsEn4iTLw==</latexit>
<latexit sha1_base64="Wet73zNqxVFTEbAnDllx3Pv6AYk=">AAAB9XicdVBLSwMxGMzWV62vqkcvwSJ4WpLS1R4LXjxWsA9oa8lms21odrMkWaUu/R9ePCji1f/izX9jtq2gogMhw8z3kcn4ieDaIPThFFZW19Y3ipulre2d3b3y/kFby1RR1qJSSNX1iWaCx6xluBGsmyhGIl+wjj+5yP3OLVOay/jaTBM2iMgo5iGnxFjppu9LEehpZK/sfjYsV5CLzrwarkPkegjXsWdJ1cMIVSF20RwVsERzWH7vB5KmEYsNFUTrHkaJGWREGU4Fm5X6qWYJoRMyYj1LYxIxPcjmqWfwxCoBDKWyJzZwrn7fyEik82h2MiJmrH97ufiX10tNWB9kPE5Sw2K6eChMBTQS5hXAgCtGjZhaQqjiNiukY6IINbaoki3h66fwf9Kuuhi5+KpWaaBlHUVwBI7BKcDgHDTAJWiCFqBAgQfwBJ6dO+fReXFeF6MFZ7lzCH7AefsEn4iTLw==</latexit>

dcos · z

<latexit sha1_base64="ci/PQFU/w10c/I1+qmSKfpNGhPQ=">AAACBHicdVDLSgMxFM34rPU16rKbYBFcDZnawXZXcOOygn1Ap5RMJm1DM5MhyQh16MKNv+LGhSJu/Qh3/o2ZtoKKHgg5nHMv994TJJwpjdCHtbK6tr6xWdgqbu/s7u3bB4dtJVJJaIsILmQ3wIpyFtOWZprTbiIpjgJOO8HkIvc7N1QqJuJrPU1oP8KjmA0ZwdpIA7sUDjKfCDXzSSi0Hwgeqmlkvux2NrDLyEFe3XMRRI6H3PpZTur1WtXzoOugOcpgiebAfvdDQdKIxppwrFTPRYnuZ1hqRjidFf1U0QSTCR7RnqExjqjqZ/MjZvDEKCEcCmlerOFc/d6R4Ujlq5nKCOux+u3l4l9eL9XDWj9jcZJqGpPFoGHKoRYwTwSGTFKi+dQQTCQzu0IyxhITbXIrmhC+LoX/k3bFcZHjXlXLjcoyjgIogWNwClxwDhrgEjRBCxBwBx7AE3i27q1H68V6XZSuWMueI/AD1tsnsOqZXg==</latexit>
<latexit sha1_base64="ci/PQFU/w10c/I1+qmSKfpNGhPQ=">AAACBHicdVDLSgMxFM34rPU16rKbYBFcDZnawXZXcOOygn1Ap5RMJm1DM5MhyQh16MKNv+LGhSJu/Qh3/o2ZtoKKHgg5nHMv994TJJwpjdCHtbK6tr6xWdgqbu/s7u3bB4dtJVJJaIsILmQ3wIpyFtOWZprTbiIpjgJOO8HkIvc7N1QqJuJrPU1oP8KjmA0ZwdpIA7sUDjKfCDXzSSi0Hwgeqmlkvux2NrDLyEFe3XMRRI6H3PpZTur1WtXzoOugOcpgiebAfvdDQdKIxppwrFTPRYnuZ1hqRjidFf1U0QSTCR7RnqExjqjqZ/MjZvDEKCEcCmlerOFc/d6R4Ujlq5nKCOux+u3l4l9eL9XDWj9jcZJqGpPFoGHKoRYwTwSGTFKi+dQQTCQzu0IyxhITbXIrmhC+LoX/k3bFcZHjXlXLjcoyjgIogWNwClxwDhrgEjRBCxBwBx7AE3i27q1H68V6XZSuWMueI/AD1tsnsOqZXg==</latexit>
<latexit sha1_base64="ci/PQFU/w10c/I1+qmSKfpNGhPQ=">AAACBHicdVDLSgMxFM34rPU16rKbYBFcDZnawXZXcOOygn1Ap5RMJm1DM5MhyQh16MKNv+LGhSJu/Qh3/o2ZtoKKHgg5nHMv994TJJwpjdCHtbK6tr6xWdgqbu/s7u3bB4dtJVJJaIsILmQ3wIpyFtOWZprTbiIpjgJOO8HkIvc7N1QqJuJrPU1oP8KjmA0ZwdpIA7sUDjKfCDXzSSi0Hwgeqmlkvux2NrDLyEFe3XMRRI6H3PpZTur1WtXzoOugOcpgiebAfvdDQdKIxppwrFTPRYnuZ1hqRjidFf1U0QSTCR7RnqExjqjqZ/MjZvDEKCEcCmlerOFc/d6R4Ujlq5nKCOux+u3l4l9eL9XDWj9jcZJqGpPFoGHKoRYwTwSGTFKi+dQQTCQzu0IyxhITbXIrmhC+LoX/k3bFcZHjXlXLjcoyjgIogWNwClxwDhrgEjRBCxBwBx7AE3i27q1H68V6XZSuWMueI/AD1tsnsOqZXg==</latexit>
<latexit sha1_base64="ci/PQFU/w10c/I1+qmSKfpNGhPQ=">AAACBHicdVDLSgMxFM34rPU16rKbYBFcDZnawXZXcOOygn1Ap5RMJm1DM5MhyQh16MKNv+LGhSJu/Qh3/o2ZtoKKHgg5nHMv994TJJwpjdCHtbK6tr6xWdgqbu/s7u3bB4dtJVJJaIsILmQ3wIpyFtOWZprTbiIpjgJOO8HkIvc7N1QqJuJrPU1oP8KjmA0ZwdpIA7sUDjKfCDXzSSi0Hwgeqmlkvux2NrDLyEFe3XMRRI6H3PpZTur1WtXzoOugOcpgiebAfvdDQdKIxppwrFTPRYnuZ1hqRjidFf1U0QSTCR7RnqExjqjqZ/MjZvDEKCEcCmlerOFc/d6R4Ujlq5nKCOux+u3l4l9eL9XDWj9jcZJqGpPFoGHKoRYwTwSGTFKi+dQQTCQzu0IyxhITbXIrmhC+LoX/k3bFcZHjXlXLjcoyjgIogWNwClxwDhrgEjRBCxBwBx7AE3i27q1H68V6XZSuWMueI/AD1tsnsOqZXg==</latexit>

rf2(xt) = [1 1]>

<latexit sha1_base64="IIm86azxHJuamdqfxUiGtXKIOec=">AAACFXicdVBBSxwxFM5oq+va6qpHL6GLYEGHybi4ehCWeulxC10VdsYhk81oMJMMyRtxGeZPeOlf6cVDS/Fa6K3/ppl1C22pH4R8fN97vPe+tJDCQhD89BYWX7xcWm6ttFdfvV5b72xsnlldGsZHTEttLlJquRSKj0CA5BeF4TRPJT9Pb04b//yWGyu0+gjTgsc5vVIiE4yCk5LO3n6kaCopzpIQ70aplhM7zd1X3dUJvD0Zk719El9WEeiiTjrdwD8+Ogx7hzjwg6BPQtKQsN876GHilAZdNMcw6fyIJpqVOVfAJLV2TIIC4ooaEEzyuh2VlheU3dArPnZU0ZzbuJpdVeMdp0xwpo17CvBM/bOjorltdnWVOYVr+6/XiP/zxiVkR3ElVFECV+xpUFZKDBo3EeGJMJyBnDpCmRFuV8yuqaEMXJBtF8LvS/Hz5Cz0SeCTD73u4N08jhbaRm/QLiKojwboPRqiEWLoHn1GX9BX75P34H3zHp9KF7x5zxb6C973XzNQnj8=</latexit>
<latexit sha1_base64="IIm86azxHJuamdqfxUiGtXKIOec=">AAACFXicdVBBSxwxFM5oq+va6qpHL6GLYEGHybi4ehCWeulxC10VdsYhk81oMJMMyRtxGeZPeOlf6cVDS/Fa6K3/ppl1C22pH4R8fN97vPe+tJDCQhD89BYWX7xcWm6ttFdfvV5b72xsnlldGsZHTEttLlJquRSKj0CA5BeF4TRPJT9Pb04b//yWGyu0+gjTgsc5vVIiE4yCk5LO3n6kaCopzpIQ70aplhM7zd1X3dUJvD0Zk719El9WEeiiTjrdwD8+Ogx7hzjwg6BPQtKQsN876GHilAZdNMcw6fyIJpqVOVfAJLV2TIIC4ooaEEzyuh2VlheU3dArPnZU0ZzbuJpdVeMdp0xwpo17CvBM/bOjorltdnWVOYVr+6/XiP/zxiVkR3ElVFECV+xpUFZKDBo3EeGJMJyBnDpCmRFuV8yuqaEMXJBtF8LvS/Hz5Cz0SeCTD73u4N08jhbaRm/QLiKojwboPRqiEWLoHn1GX9BX75P34H3zHp9KF7x5zxb6C973XzNQnj8=</latexit>
<latexit sha1_base64="IIm86azxHJuamdqfxUiGtXKIOec=">AAACFXicdVBBSxwxFM5oq+va6qpHL6GLYEGHybi4ehCWeulxC10VdsYhk81oMJMMyRtxGeZPeOlf6cVDS/Fa6K3/ppl1C22pH4R8fN97vPe+tJDCQhD89BYWX7xcWm6ttFdfvV5b72xsnlldGsZHTEttLlJquRSKj0CA5BeF4TRPJT9Pb04b//yWGyu0+gjTgsc5vVIiE4yCk5LO3n6kaCopzpIQ70aplhM7zd1X3dUJvD0Zk719El9WEeiiTjrdwD8+Ogx7hzjwg6BPQtKQsN876GHilAZdNMcw6fyIJpqVOVfAJLV2TIIC4ooaEEzyuh2VlheU3dArPnZU0ZzbuJpdVeMdp0xwpo17CvBM/bOjorltdnWVOYVr+6/XiP/zxiVkR3ElVFECV+xpUFZKDBo3EeGJMJyBnDpCmRFuV8yuqaEMXJBtF8LvS/Hz5Cz0SeCTD73u4N08jhbaRm/QLiKojwboPRqiEWLoHn1GX9BX75P34H3zHp9KF7x5zxb6C973XzNQnj8=</latexit>
<latexit sha1_base64="IIm86azxHJuamdqfxUiGtXKIOec=">AAACFXicdVBBSxwxFM5oq+va6qpHL6GLYEGHybi4ehCWeulxC10VdsYhk81oMJMMyRtxGeZPeOlf6cVDS/Fa6K3/ppl1C22pH4R8fN97vPe+tJDCQhD89BYWX7xcWm6ttFdfvV5b72xsnlldGsZHTEttLlJquRSKj0CA5BeF4TRPJT9Pb04b//yWGyu0+gjTgsc5vVIiE4yCk5LO3n6kaCopzpIQ70aplhM7zd1X3dUJvD0Zk719El9WEeiiTjrdwD8+Ogx7hzjwg6BPQtKQsN876GHilAZdNMcw6fyIJpqVOVfAJLV2TIIC4ooaEEzyuh2VlheU3dArPnZU0ZzbuJpdVeMdp0xwpo17CvBM/bOjorltdnWVOYVr+6/XiP/zxiVkR3ElVFECV+xpUFZKDBo3EeGJMJyBnDpCmRFuV8yuqaEMXJBtF8LvS/Hz5Cz0SeCTD73u4N08jhbaRm/QLiKojwboPRqiEWLoHn1GX9BX75P34H3zHp9KF7x5zxb6C973XzNQnj8=</latexit>

z = gradf (xt)

<latexit sha1_base64="/ONnItqDDM/jN1sFB6eKhc0zy+M=">AAACGHicbVC7SgNBFJ2NrxhfUUubwaDEJu6KoI0QtLGMYB6QDWF2djYZMvtg5q4kLvsZNv6KjYUitun8G2eTFDHxwDCHc+7l3nucSHAFpvlj5FZW19Y38puFre2d3b3i/kFDhbGkrE5DEcqWQxQTPGB14CBYK5KM+I5gTWdwl/nNJyYVD4NHGEWs45NewD1OCWipWzy3nVC4auTrL3lOT29sYENIepK4KfbK8+4w7cJZt1gyK+YEeJlYM1JCM9S6xbHthjT2WQBUEKXalhlBJyESOBUsLdixYhGhA9JjbU0D4jPVSSaHpfhEKy72QqlfAHiiznckxFfZdrrSJ9BXi14m/ue1Y/CuOwkPohhYQKeDvFhgCHGWEna5ZBTESBNCJde7YtonklDQWRZ0CNbiycukcVGxzIr1cFmq3s7iyKMjdIzKyEJXqIruUQ3VEUUv6A19oE/j1Xg3vozvaWnOmPUcoj8wxr+HU6FN</latexit>
<latexit sha1_base64="/ONnItqDDM/jN1sFB6eKhc0zy+M=">AAACGHicbVC7SgNBFJ2NrxhfUUubwaDEJu6KoI0QtLGMYB6QDWF2djYZMvtg5q4kLvsZNv6KjYUitun8G2eTFDHxwDCHc+7l3nucSHAFpvlj5FZW19Y38puFre2d3b3i/kFDhbGkrE5DEcqWQxQTPGB14CBYK5KM+I5gTWdwl/nNJyYVD4NHGEWs45NewD1OCWipWzy3nVC4auTrL3lOT29sYENIepK4KfbK8+4w7cJZt1gyK+YEeJlYM1JCM9S6xbHthjT2WQBUEKXalhlBJyESOBUsLdixYhGhA9JjbU0D4jPVSSaHpfhEKy72QqlfAHiiznckxFfZdrrSJ9BXi14m/ue1Y/CuOwkPohhYQKeDvFhgCHGWEna5ZBTESBNCJde7YtonklDQWRZ0CNbiycukcVGxzIr1cFmq3s7iyKMjdIzKyEJXqIruUQ3VEUUv6A19oE/j1Xg3vozvaWnOmPUcoj8wxr+HU6FN</latexit>
<latexit sha1_base64="/ONnItqDDM/jN1sFB6eKhc0zy+M=">AAACGHicbVC7SgNBFJ2NrxhfUUubwaDEJu6KoI0QtLGMYB6QDWF2djYZMvtg5q4kLvsZNv6KjYUitun8G2eTFDHxwDCHc+7l3nucSHAFpvlj5FZW19Y38puFre2d3b3i/kFDhbGkrE5DEcqWQxQTPGB14CBYK5KM+I5gTWdwl/nNJyYVD4NHGEWs45NewD1OCWipWzy3nVC4auTrL3lOT29sYENIepK4KfbK8+4w7cJZt1gyK+YEeJlYM1JCM9S6xbHthjT2WQBUEKXalhlBJyESOBUsLdixYhGhA9JjbU0D4jPVSSaHpfhEKy72QqlfAHiiznckxFfZdrrSJ9BXi14m/ue1Y/CuOwkPohhYQKeDvFhgCHGWEna5ZBTESBNCJde7YtonklDQWRZ0CNbiycukcVGxzIr1cFmq3s7iyKMjdIzKyEJXqIruUQ3VEUUv6A19oE/j1Xg3vozvaWnOmPUcoj8wxr+HU6FN</latexit>
<latexit sha1_base64="/ONnItqDDM/jN1sFB6eKhc0zy+M=">AAACGHicbVC7SgNBFJ2NrxhfUUubwaDEJu6KoI0QtLGMYB6QDWF2djYZMvtg5q4kLvsZNv6KjYUitun8G2eTFDHxwDCHc+7l3nucSHAFpvlj5FZW19Y38puFre2d3b3i/kFDhbGkrE5DEcqWQxQTPGB14CBYK5KM+I5gTWdwl/nNJyYVD4NHGEWs45NewD1OCWipWzy3nVC4auTrL3lOT29sYENIepK4KfbK8+4w7cJZt1gyK+YEeJlYM1JCM9S6xbHthjT2WQBUEKXalhlBJyESOBUsLdixYhGhA9JjbU0D4jPVSSaHpfhEKy72QqlfAHiiznckxFfZdrrSJ9BXi14m/ue1Y/CuOwkPohhYQKeDvFhgCHGWEna5ZBTESBNCJde7YtonklDQWRZ0CNbiycukcVGxzIr1cFmq3s7iyKMjdIzKyEJXqIruUQ3VEUUv6A19oE/j1Xg3vozvaWnOmPUcoj8wxr+HU6FN</latexit>

dcos = 1  cos (xt rf (xt)) = 1 +

<latexit sha1_base64="CEL2Rnh7Kfz/8QYB4nznkp+q2yY=">AAACkHicfVHBTuMwEHUC7EIXli575GJRrQRaqBJYaTlQLYgL4gQSBaS6GzmO01o4dmRPEFXI9/A/3PgbnFIkaBEjWX56b2Y8fhPnUlgIgifPn5tf+PJ1canxbXnl+2rzx9ql1YVhvMu01OY6ppZLoXgXBEh+nRtOs1jyq/jmuNavbrmxQqsLGOW8n9GBEqlgFBwVNR+SqCRM2wp3wp0aEMlT2CSxlokdZe4q76oItneIorGkOJ2RtogRgyFsNTrhb5IaysrpjP8EdI5fG+DZDlVJ7j+RyX3ViJqtoB2MA8+CcAJaaBJnUfORJJoVGVfAJLW2FwY59EtqQDDJqwYpLM8pu6ED3nNQ0Yzbfjk2tMK/HJPgVBt3FOAx+7aipJmtJ3SZGYWhndZq8iOtV0C63y+Fygvgir08lBYSg8b1dnAiDGcgRw5QZoSbFbMhdaaC22FtQjj95VlwudsOg3Z4/qd1GEzsWETraANtohD9RYfoBJ2hLmLeirfnHXgdf83f9//5Ry+pvjep+YnehX/6DEUXyX4=</latexit>
<latexit sha1_base64="CEL2Rnh7Kfz/8QYB4nznkp+q2yY=">AAACkHicfVHBTuMwEHUC7EIXli575GJRrQRaqBJYaTlQLYgL4gQSBaS6GzmO01o4dmRPEFXI9/A/3PgbnFIkaBEjWX56b2Y8fhPnUlgIgifPn5tf+PJ1canxbXnl+2rzx9ql1YVhvMu01OY6ppZLoXgXBEh+nRtOs1jyq/jmuNavbrmxQqsLGOW8n9GBEqlgFBwVNR+SqCRM2wp3wp0aEMlT2CSxlokdZe4q76oItneIorGkOJ2RtogRgyFsNTrhb5IaysrpjP8EdI5fG+DZDlVJ7j+RyX3ViJqtoB2MA8+CcAJaaBJnUfORJJoVGVfAJLW2FwY59EtqQDDJqwYpLM8pu6ED3nNQ0Yzbfjk2tMK/HJPgVBt3FOAx+7aipJmtJ3SZGYWhndZq8iOtV0C63y+Fygvgir08lBYSg8b1dnAiDGcgRw5QZoSbFbMhdaaC22FtQjj95VlwudsOg3Z4/qd1GEzsWETraANtohD9RYfoBJ2hLmLeirfnHXgdf83f9//5Ry+pvjep+YnehX/6DEUXyX4=</latexit>
<latexit sha1_base64="CEL2Rnh7Kfz/8QYB4nznkp+q2yY=">AAACkHicfVHBTuMwEHUC7EIXli575GJRrQRaqBJYaTlQLYgL4gQSBaS6GzmO01o4dmRPEFXI9/A/3PgbnFIkaBEjWX56b2Y8fhPnUlgIgifPn5tf+PJ1canxbXnl+2rzx9ql1YVhvMu01OY6ppZLoXgXBEh+nRtOs1jyq/jmuNavbrmxQqsLGOW8n9GBEqlgFBwVNR+SqCRM2wp3wp0aEMlT2CSxlokdZe4q76oItneIorGkOJ2RtogRgyFsNTrhb5IaysrpjP8EdI5fG+DZDlVJ7j+RyX3ViJqtoB2MA8+CcAJaaBJnUfORJJoVGVfAJLW2FwY59EtqQDDJqwYpLM8pu6ED3nNQ0Yzbfjk2tMK/HJPgVBt3FOAx+7aipJmtJ3SZGYWhndZq8iOtV0C63y+Fygvgir08lBYSg8b1dnAiDGcgRw5QZoSbFbMhdaaC22FtQjj95VlwudsOg3Z4/qd1GEzsWETraANtohD9RYfoBJ2hLmLeirfnHXgdf83f9//5Ry+pvjep+YnehX/6DEUXyX4=</latexit>
<latexit sha1_base64="CEL2Rnh7Kfz/8QYB4nznkp+q2yY=">AAACkHicfVHBTuMwEHUC7EIXli575GJRrQRaqBJYaTlQLYgL4gQSBaS6GzmO01o4dmRPEFXI9/A/3PgbnFIkaBEjWX56b2Y8fhPnUlgIgifPn5tf+PJ1canxbXnl+2rzx9ql1YVhvMu01OY6ppZLoXgXBEh+nRtOs1jyq/jmuNavbrmxQqsLGOW8n9GBEqlgFBwVNR+SqCRM2wp3wp0aEMlT2CSxlokdZe4q76oItneIorGkOJ2RtogRgyFsNTrhb5IaysrpjP8EdI5fG+DZDlVJ7j+RyX3ViJqtoB2MA8+CcAJaaBJnUfORJJoVGVfAJLW2FwY59EtqQDDJqwYpLM8pu6ED3nNQ0Yzbfjk2tMK/HJPgVBt3FOAx+7aipJmtJ3SZGYWhndZq8iOtV0C63y+Fygvgir08lBYSg8b1dnAiDGcgRw5QZoSbFbMhdaaC22FtQjj95VlwudsOg3Z4/qd1GEzsWETraANtohD9RYfoBJ2hLmLeirfnHXgdf83f9//5Ry+pvjep+YnehX/6DEUXyX4=</latexit>

x>t rf (xt)
krf (xt)k

Figure 1: Example of modiﬁed Riemannian gradient descent on S1. Without modiﬁcation  two
Euclidean descent directions rf1(xt) and rf2(xt) give the same Riemannian gradient z. We
propose to multiply z with the cosine distance between xt and rf (xt) as the modiﬁed Riemannian
gradient so that angular distances are taken into account during the parameter update.

4.4 Training Details
We describe two sets of design that lead to more efﬁcient and effective training of the above optimiza-
tion procedure.
First  the exponential mapping requires computation of non-linear functions  speciﬁcally  sin(·)
and cos(·) in Equation (4)  which is inefﬁcient especially when the corpus is large. To tackle this
issue  we can use a ﬁrst-order approximation of the exponential mapping  called a retraction  i.e. 
Rx (z) : TxSp1 ! Sp1 such that d(Rx (z)   expx(z)) = O(kzk2). For the unit sphere  we can
simply deﬁne the retraction Rx (z) to be an addition in the ambient Euclidean space followed by a
projection onto the sphere [1  6]  i.e. 

Rx (z) :=

.

(6)

x + z
kx + zk

Second  the Riemannian gradient given by Equation (5) provides the correct direction to update the
parameters on the sphere  but its norm is not optimal when our goal is to train embeddings that capture
directional similarity. This issue can be illustrated by the following toy example shown in Figure
1: Consider a point xt with Euclidean coordinate (0  1) on a 2-d unit sphere S1 and two Euclidean
gradient descent directions rf1(xt) = [1  1]> and rf2(xt) = [1 1]>. Also  for simplicity 
assume ⌘t = 1. In this case  the Riemannian gradient projected from rf2(xt) is the same with
that of rf1(xt) and is equal to [1  0]>  i.e.  grad f1(xt) = grad f2(xt) = [1  0]>. However  when
our goal is to capture directional information and distance is measured by the angles between vectors 
rf2(xt) suggests a bigger step to take than rf1(xt) at point xt. To explicitly incorporate
angular distance into the optimization procedure  we use the cosine distance between the current
krf (xt)k⌘  as
point xt 2 Sp1 and the Euclidean gradient descent direction rf (xt)  i.e. ⇣1 + x>t rf (xt)

a multiplier to the computed Riemannian gradient according to Equation (5). The rationale of this
design is to encourage parameters with greater cosine distance from its target direction to take a larger
update step. We ﬁnd that when updating negative samples  it is empirically better to use negative
cosine similarity instead of cosine distance as the multiplier to the Riemannian gradient. This is
probably because negative samples are randomly sampled from the vocabulary and most of them are
semantically irrelevant with the center word. Therefore  their ideal embeddings should be orthogonal
to the center word’s embedding. However  using cosine distance will encourage them to point to the
opposite direction of the center word’s embedding.
In summary  with the above designs  we optimize the parameters by the following update rule:

xt+1 = Rxt✓⌘t✓1 +

x>t rf (xt)

krf (xt)k◆I  xtx>trf (xt)◆ .

(7)

5

Finally  we provide the convergence guarantee of the above update rule when applied to optimize our
objectives.
Theorem 2. When the update rule given by Equation (7) is applied to L(x)  and the learning rate
satisﬁes the usual condition in stochastic approximation  i.e. Pt ⌘2
t < 1 andPt ⌘t = 1  x
converges almost surely to a critical point x⇤ and gradL(x) converges almost surely to 0  i.e. 

gradL(xt) = 0⌘ = 1.

Pr⇣ lim
t!1L(xt) = L(x⇤)⌘ = 1  Pr⇣ lim

t!1

The proof of Theorem 2 can be found in Appendix B.

5 Evaluation

In this section  we empirically evaluate the quality of spherical text embeddings for three common text
embedding application tasks  i.e.  word similarity  document clustering and document classiﬁcation.
Our model is named JoSE  for Joint Spherical Embedding. For all three tasks  our spherical
embeddings and all baselines are trained according to the following setting: The models are trained
for 10 iterations on the corpus; the local context window size is 10; the embedding dimension is 100.
In our JoSE model  we set the margin in Equation (3) to be 0.15  the number of negative samples to
be 2  the initial learning rate to be 0.04 with linear decay. Other hyperparameters are set to be the
default value of the corresponding algorithm.
Also  since text embeddings serve as the building block for many downstream tasks  it is essential
that the embedding training is efﬁcient and can scale to very large datasets. At the end of this section 
we will provide the training time of different word embedding models when trained on the latest
Wikipedia dump.

5.1 Word Similarity

We conduct word similarity evaluation on the following benchmark datasets: WordSim353 [13] 
MEN [7] and SimLex999 [17]. The training corpus for word similarity is the latest Wikipedia dump3
containing 2.4 billion tokens. Words appearing less than 100 times are discarded  leaving 239  672
unique tokens. The Spearman’s rank correlation is reported in Table 1  which reﬂects the consistency
between word similarity rankings given by cosine similarity of word embeddings and human raters.
We compare our model with the following baselines: Word2Vec [30]  GloVe [33]  fastText [5]
and BERT [10] which are trained in Euclidean space  and Poincaré GloVe [39] which is trained in
Poincaré space. The results demonstrate that training embeddings in the spherical space is essential
for the superior performance on word similarity. We attempt to explain why the recent popular
language model  BERT [10]  falls behind other baselines on this task: (1) BERT learns contextualized
representations  but word similarity evaluation is conducted in a context-free manner; averaging
contextualized representations to derive context-free representations may not be the intended usage
of BERT. (2) BERT is optimized on speciﬁc downstream tasks like predicting masked words and
sentence relationships  which have no direct relation to word similarity.

Table 1: Spearman rank correlation on word similarity evaluation.

Embedding Space

Euclidean

Poincaré
Spherical

Model

Word2Vec

GloVe
fastText
BERT

Poincaré GloVe

JoSE

WordSim353 MEN SimLex999

0.711
0.598
0.697
0.477
0.623
0.739

0.726
0.710
0.722
0.594
0.652
0.748

0.311
0.321
0.303
0.287
0.321
0.339

3https://dumps.wikimedia.org/enwiki/latest/enwiki-latest-pages-articles.xml.bz2

6

5.2 Document Clustering

We perform document clustering to evaluate the quality of the spherical paragraph embeddings trained
by our model. The training corpus is the 20 Newsgroups dataset4  and we treat each document as a
paragraph in all compared models. The dataset contains around 18  000 newsgroup documents (both
training and testing documents are used) partitioned into 20 classes. For clustering methods  we use
both K-Means and spherical K-Means (SK-Means) [3] which performs clustering in the spherical
space. We compare with the following paragraph embedding baselines: Averaged word embedding
using Word2Vec [30]  SIF [2]  BERT [10] and Doc2Vec [22]. We use four widely used external
measures [3  25  36] as metrics: Mutual Information (MI)  Normalized Mutual Information (NMI) 
Adjusted Rand Index (ARI)  and Purity. The results are reported in Table 2  with mean and standard
deviation computed over 10 runs. It is shown that feature quality is generally more important that
clustering algorithms for document clustering tasks: Using spherical K-Means only gives marginal
performance boost over K-Means  while JoSE remains optimal regardless of clustering algorithms.
This demonstrates that directional similarity on document/paragraph-level features is beneﬁcial also
for clustering tasks  which can be captured intrinsically in the spherical space.

Table 2: Document clustering evaluation on the 20 Newsgroup dataset.

Avg. W2V

Embedding Clus. Alg.
K-Means
SK-Means
K-Means
SK-Means
K-Means
SK-Means
K-Means
SK-Means
K-Means
SK-Means

Doc2Vec

SIF

BERT

JoSE

MI

NMI

ARI

1.299 ± 0.031
1.328 ± 0.024
0.893 ± 0.028
0.958 ± 0.012
0.719 ± 0.013
0.854 ± 0.022
1.856 ± 0.020
1.876 ± 0.020
1.975 ± 0.026
1.982 ± 0.034

0.445 ± 0.009
0.453 ± 0.009
0.308 ± 0.009
0.322 ± 0.004
0.248 ± 0.004
0.289 ± 0.008
0.626 ± 0.006
0.630 ± 0.007
0.663 ± 0.008
0.664 ± 0.010

0.247 ± 0.008
0.250 ± 0.008
0.137 ± 0.006
0.164 ± 0.004
0.100 ± 0.003
0.127 ± 0.003
0.469 ± 0.015
0.494 ± 0.012
0.556 ± 0.018
0.568 ± 0.020

Purity

0.408 ± 0.014
0.419 ± 0.012
0.285 ± 0.011
0.331 ± 0.005
0.233 ± 0.005
0.281 ± 0.010
0.640 ± 0.016
0.648 ± 0.017
0.711 ± 0.020
0.721 ± 0.029

5.3 Document Classiﬁcation

Apart from document clustering  we also evaluate the quality of spherical paragraph embeddings on
document classiﬁcation tasks. Besides the 20 Newsgroup dataset used in Section 5.2 which is a topic
classiﬁcation dataset  we evaluate different document/paragraph embedding methods also on a binary
sentiment classiﬁcation dataset consisting of 1  000 positive and 1  000 negative movie reviews5. We
again treat each document in both datasets as a paragraph in all models. For the 20 Newsgroup
dataset  we follow the original train/test sets split; for the movie review dataset  we randomly select
80% of the data as training and 20% as testing. We use k-NN [9] as the classiﬁcation algorithm with
Euclidean distance as the distance metric. Since k-NN is a non-parametric method  the performances
of k-NN directly reﬂect how well the topology of the embedding space captures document-level
semantics (i.e.  whether documents from the same semantic class are embedded closer). We set k = 3
in the experiment (we observe similar comparison results when ranging k in [1  10]) and report the
performances of all methods measured by Macro-F1 and Micro-F1 scores in Table 3. JoSE achieves
the best performances on both datasets with k-NN classiﬁcation  demonstrating the effectiveness of
JoSE in capturing both topical and sentiment semantics into learned paragraph embeddings.

5.4 Training Efﬁciency

We report the training time on the latest Wikipedia dump per iteration of all baselines used in
Section 5.1 to compare the training efﬁciency. All the models except BERT are run on a machine
with 20 cores of Intel(R) Xeon(R) CPU E5-2680 v2 @ 2.80 GHz; BERT is trained on 8 NVIDIA

4http://qwone.com/~jason/20Newsgroups/
5http://www.cs.cornell.edu/people/pabo/movie-review-data/

7

Table 3: Document classiﬁcation evaluation using k-NN (k = 3).

Embedding

Avg. W2V

SIF
BERT
Doc2Vec

JoSE

20 Newsgroup

Movie Review

Macro-F1 Micro-F1 Macro-F1 Micro-F1

0.630
0.552
0.380
0.648
0.703

0.631
0.549
0.371
0.645
0.707

0.712
0.650
0.664
0.674
0.764

0.713
0.656
0.665
0.678
0.765

GeForce GTX 1080 GPUs. The training time is reported in Table 4. All text embedding frameworks
are able to scale to large datasets (except BERT which is not speciﬁcally designed for learning text
embeddings)  but JoSE enjoys the highest efﬁciency. The overall efﬁciency of our model results
from both our objective function design and the optimization procedure: (1) The objective of our
model (Equation (3)) only contains simple operations (note that cosine similarity on the unit sphere
is simply vector dot product)  while other models contains non-linear operations (Word2Vec’s and
fastText’s objectives involve exponential functions; GloVe’s objective involves logarithm functions);
(2) After replacing the original exponential mapping (Equation (4)) with retraction (Equation (6)) 
the update rule (Equation (7)) only computes vector additions  multiplications and normalization in
addition to the Euclidean gradient  which are all inexpensive operations.

Table 4: Training time (per iteration) on the latest Wikipedia dump.

Word2Vec
0.81 hrs

GloVe
0.85 hrs

fastText
2.11 hrs

BERT
> 5 days

Poincaré GloVe

1.25 hrs

JoSE
0.73 hrs

6 Conclusions and Future Work

In this paper  we propose to address the discrepancy between the training procedure and the practical
usage of Euclidean text embeddings by learning spherical text embeddings that intrinsically captures
directional similarity. Speciﬁcally  we introduce a spherical generative model consisting of a two-step
generative process to jointly learn word and paragraph embeddings. Furthermore  we develop an
efﬁcient Riemannian optimization method to train text embeddings on the unit hypersphere. State-
of-the-art results on common text embedding applications including word similarity and document
clustering demonstrate the efﬁcacy of our model. With a simple training objective and an efﬁcient
optimization procedure  our proposed model enjoys better efﬁciency compared to previous embedding
learning systems.
In future work  it will be interesting to exploit spherical embedding space for other tasks like lexical
entailment  by also learning the concentration parameter in the vMF distribution of each word in
the generative model or designing other generative models. It may also be possible to incorporate
other signals such as subword information [5] into spherical text embeddings learning for even better
embedding quality. Our unsupervised embedding model may also beneﬁt other supervised tasks:
Since word embeddings are commonly used as the ﬁrst layer in deep neural networks  it might be
beneﬁcial to either add norm constraints or apply Riemannian optimization when ﬁne-tuning the
word embedding layer.

Acknowledgments
Research was sponsored in part by U.S. Army Research Lab. under Cooperative Agreement No.
W911NF-09-2-0053 (NSCTA)  DARPA under Agreements No. W911NF-17-C-0099 and FA8750-
19-2-1004  National Science Foundation IIS 16-18481  IIS 17-04532  and IIS 17-41317  DTRA
HDTRA11810026  and grant 1U54GM114838 awarded by NIGMS through funds provided by the
trans-NIH Big Data to Knowledge (BD2K) initiative (www.bd2k.nih.gov). Any opinions  ﬁndings 
and conclusions or recommendations expressed in this document are those of the author(s) and should
not be interpreted as the views of any U.S. Government. The U.S. Government is authorized to

8

reproduce and distribute reprints for Government purposes notwithstanding any copyright notation
hereon. We thank anonymous reviewers for valuable and insightful feedback.

References
[1] P.-A. Absil  R. E. Mahony  and R. Sepulchre. Optimization algorithms on matrix manifolds.

2007.

[2] S. Arora  Y. Liang  and T. Ma. A simple but tough-to-beat baseline for sentence embeddings. In

ICLR  2017.

[3] A. Banerjee  I. S. Dhillon  J. Ghosh  and S. Sra. Clustering on the unit hypersphere using von

mises-ﬁsher distributions. Journal of Machine Learning Research  6:1345–1382  2005.

[4] K. Batmanghelich  A. Saeedi  K. Narasimhan  and S. J. Gershman. Nonparametric spherical

topic modeling with word embeddings. In ACL  2016.

[5] P. Bojanowski  E. Grave  A. Joulin  and T. Mikolov. Enriching word vectors with subword

information. TACL  2017.

[6] S. Bonnabel. Stochastic gradient descent on riemannian manifolds. IEEE Transactions on

Automatic Control  58:2217–2229  2013.

[7] E. Bruni  N.-K. Tran  and M. Baroni. Multimodal distributional semantics. J. Artif. Intell. Res. 

49:1–47  2014.

[8] K. Cho  B. van Merrienboer  Çaglar Gülçehre  D. Bahdanau  F. Bougares  H. Schwenk  and
Y. Bengio. Learning phrase representations using rnn encoder-decoder for statistical machine
translation. In EMNLP  2014.

[9] T. M. Cover and P. E. Hart. Nearest neighbor pattern classiﬁcation. IEEE Trans. Information

Theory  13:21–27  1967.

[10] J. Devlin  M.-W. Chang  K. Lee  and K. Toutanova. Bert: Pre-training of deep bidirectional

transformers for language understanding. CoRR  abs/1810.04805  2018.

[11] B. Dhingra  C. J. Shallue  M. Norouzi  A. M. Dai  and G. E. Dahl. Embedding text in hyperbolic

spaces. In TextGraphs@NAACL-HLT  2018.

[12] O. P. Ferreira  A. N. Iusem  and S. Z. Németh. Concepts and techniques of optimization on the

sphere. 2014.

[13] L. Finkelstein  E. Gabrilovich  Y. Matias  E. Rivlin  Z. Solan  G. Wolfman  and E. Ruppin.

Placing search in context: the concept revisited. In WWW  2001.

[14] D. L. Fisk. Quasi-martingales. Transactions of the American Mathematical Society  1965.
[15] O.-E. Ganea  G. Bécigneul  and T. Hofmann. Hyperbolic entailment cones for learning hierar-

chical embeddings. In ICML  2018.

[16] S. Gopal and Y. Yang. Von mises-ﬁsher clustering models. In ICML  2014.
[17] F. Hill  R. Reichart  and A. Korhonen. Simlex-999: Evaluating semantic models with (genuine)

similarity estimation. Computational Linguistics  41:665–695  2015.

[18] Y. Kim. Convolutional neural networks for sentence classiﬁcation. In EMNLP  2014.
[19] R. Kiros  Y. Zhu  R. R. Salakhutdinov  R. S. Zemel  A. Torralba  R. Urtasun  and S. Fidler.

Skip-thought vectors. In NIPS  2015.

[20] S. Kumar and Y. Tsvetkov. Von mises-ﬁsher loss for training sequence to sequence models with

continuous outputs. In ICLR  2019.

[21] G. Lample  M. Ballesteros  S. Subramanian  K. Kawakami  and C. Dyer. Neural architectures

for named entity recognition. In HLT-NAACL  2016.

9

[22] Q. V. Le and T. Mikolov. Distributed representations of sentences and documents. In ICML 

2014.

[23] O. Levy and Y. Goldberg. Linguistic regularities in sparse and explicit word representations. In

CoNLL  2014.

[24] W. Liu  Y.-M. Zhang  X. Li  Z. Yu  B. Dai  T. Zhao  and L. Song. Deep hyperspherical learning.

In NIPS  2017.

[25] C. D. Manning  P. Raghavan  and H. Schütze. Introduction to information retrieval. 2008.
[26] K. V. Mardia and P. E. Jupp. Directional statistics  volume 494. John Wiley & Sons  2009.
[27] Y. Meng  J. Shen  C. Zhang  and J. Han. Weakly-supervised neural text classiﬁcation. In CIKM 

2018.

[28] Y. Meng  J. Shen  C. Zhang  and J. Han. Weakly-supervised hierarchical text classiﬁcation. In

AAAI  2019.

[29] T. Mikolov  K. Chen  G. S. Corrado  and J. Dean. Efﬁcient estimation of word representations

in vector space. CoRR  abs/1301.3781  2013.

[30] T. Mikolov  I. Sutskever  K. Chen  G. S. Corrado  and J. Dean. Distributed representations of

words and phrases and their compositionality. In NIPS  2013.

[31] M. Nickel and D. Kiela. Poincaré embeddings for learning hierarchical representations. In

NIPS  2017.

[32] M. Nickel and D. Kiela. Learning continuous hierarchies in the lorentz model of hyperbolic

geometry. In ICML  2018.

[33] J. Pennington  R. Socher  and C. D. Manning. Glove: Global vectors for word representation.

In EMNLP  2014.

[34] S. T. Smith. Optimization techniques on riemannian manifolds. CoRR  abs/1407.5965  2014.
[35] S. Sra. Matrix nearness problems in data mining. PhD thesis  2007.
[36] D. Steinley. Properties of the hubert-arabie adjusted rand index. Psychological methods  9

3:386–96  2004.

[37] J. Tang  M. Qu  and Q. Mei. Pte: Predictive text embedding through large-scale heterogeneous

text networks. In KDD  2015.

[38] F. Tao  C. Zhang  X. Chen  M. Jiang  T. Hanratty  L. M. Kaplan  and J. Han. Doc2cube:

Allocating documents to text cube without labeled data. In ICDM  2018.

[39] A. Tifrea  G. Bécigneul  and O.-E. Ganea. Poincaré glove: Hyperbolic word embeddings. In

ICLR  2019.

[40] I. Vendrov  R. Kiros  S. Fidler  and R. Urtasun. Order-embeddings of images and language. In

ICLR  2016.

[41] L. Vilnis and A. McCallum. Word representations via gaussian embedding. In ICLR  2015.
[42] J. Wieting  M. Bansal  K. Gimpel  and K. Livescu. Towards universal paraphrastic sentence

embeddings. In ICLR  2016.

[43] C. Zhang  L. Liu  D. Lei  Q. Yuan  H. Zhuang  T. Hanratty  and J. Han. Triovecevent: Embedding-

based online local event detection in geo-tagged tweet streams. In KDD  2017.

[44] H. Zhuang  C. Wang  F. Tao  L. M. Kaplan  and J. Han. Identifying semantically deviating

outlier documents. In EMNLP  2017.

10

,Yu Meng
Jiaxin Huang
Guangyuan Wang
Chao Zhang
Honglei Zhuang
Lance Kaplan
Jiawei Han