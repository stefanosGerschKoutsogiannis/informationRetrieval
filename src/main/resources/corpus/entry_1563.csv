2013,Distributed $k$-means and $k$-median Clustering on General Topologies,This paper provides new algorithms for distributed clustering for two popular center-based objectives  $k$-median and $k$-means. These algorithms have provable guarantees and improve communication complexity over existing approaches. Following a classic approach in clustering by \cite{har2004coresets}  we reduce the problem of finding a clustering with low cost to the problem of finding a `coreset' of small size. We provide a distributed method for constructing a global coreset which improves over the previous methods by reducing the communication complexity  and which works over general communication topologies. We provide experimental evidence for this approach on both synthetic and real data sets.,Distributed k-Means and k-Median Clustering on

General Topologies

Maria Florina Balcan  Steven Ehrlich  Yingyu Liang

School of Computer Science

Georgia Institute of Technology

{ninamf sehrlich}@cc.gatech.edu yliang39@gatech.edu

Atlanta  GA 30332

Abstract

This paper provides new algorithms for distributed clustering for two popular
center-based objectives  k-median and k-means. These algorithms have provable
guarantees and improve communication complexity over existing approaches.
Following a classic approach in clustering by [13]  we reduce the problem of
ﬁnding a clustering with low cost to the problem of ﬁnding a coreset of small
size. We provide a distributed method for constructing a global coreset which
improves over the previous methods by reducing the communication complexity 
and which works over general communication topologies. Experimental results
on large scale data sets show that this approach outperforms other coreset-based
distributed clustering algorithms.

Introduction

1
Most classic clustering algorithms are designed for the centralized setting  but in recent years data
has become distributed over different locations  such as distributed databases [21  5]  images and
videos over networks [20]  surveillance [11] and sensor networks [4  12]. In many of these appli-
cations the data is inherently distributed because  as in sensor networks  it is collected at different
sites. As a consequence it has become crucial to develop clustering algorithms which are effective
in the distributed setting.
Several algorithms for distributed clustering have been proposed and empirically tested. Some of
these algorithms [10  22  7] are direct adaptations of centralized algorithms which rely on statistics
that are easy to compute in a distributed manner. Other algorithms [14  17] generate summaries of
local data and transmit them to a central coordinator which then performs the clustering algorithm.
No theoretical guarantees are provided for the clustering quality in these algorithms  and they do
not try to minimize the communication cost. Additionally  most of these algorithms assume that
the distributed nodes can communicate with all other sites or that there is a central coordinator that
communicates with all other sites.
In this paper  we study the problem of distributed clustering where the data is distributed across
nodes whose communication is restricted to the edges of an arbitrary graph. We provide algorithms
with small communication cost and provable guarantees on the clustering quality. Our technique
for reducing communication in general graphs is based on the construction of a small set of points
which act as a proxy for the entire data set.
An -coreset is a weighted set of points whose cost on any set of centers is approximately the cost
of the original data on those same centers up to accuracy . Thus an approximate solution for the
coreset is also an approximate solution for the original data. Coresets have previously been studied
in the centralized setting ([13  8]) but have also recently been used for distributed clustering as in
[23] and as implied by [9]. In this work  we propose a distributed algorithm for k-means and k-

1

(a) Zhang et al.[23]

(b) Our Construction

(a) Each node computes a coreset on the weighted pointset for its own data and its
Figure 1:
subtrees’ coresets. (b) Local constant approximation solutions are computed  and the costs of these
solutions are used to coordinate the construction of a local portion on each node.

median  by which each node constructs a local portion of a global coreset. Communicating the
approximate cost of a global solution to each node is enough for the local construction  leading to
low communication cost overall. The nodes then share the local portions of the coreset  which can
be done efﬁciently in general graphs using a message passing approach.
More precisely  in Section 3  we propose a distributed coreset construction algorithm based on local
approximate solutions. Each node computes an approximate solution for its local data  and then
constructs the local portion of a coreset using only its local data and the total cost of each node’s ap-
proximation. For  constant  this builds a coreset of size ˜O(kd+nk) for k-median and k-means when
the data lies in d dimensions and is distributed over n sites. If there is a central coordinator among
the n sites  then clustering can be performed on the coordinator by collecting the local portions of
the coreset with a communication cost equal to the coreset size ˜O(kd + nk). For distributed clus-
tering over general connected topologies  we propose an algorithm based on the distributed coreset
construction and a message-passing approach  whose communication cost improves over previous
coreset-based algorithms. We provide a detailed comparison below.
Experimental results on large scale data sets show that our algorithm performs well in practice. For
a ﬁxed amount of communication  our algorithm outperforms other coreset construction algorithms.
Comparison to Other Coreset Algorithms: Since coresets summarize local information they are
a natural tool to use when trying to reduce communication complexity. If each node constructs an -
coreset on its local data  then the union of these coresets is clearly an -coreset for the entire data set.
Unfortunately the size of the coreset in this approach increases greatly with the number of nodes.
Another approach is the one presented in [23]. Its main idea is to approximate the union of local
coresets with another coreset. They assume nodes communicate over a rooted tree  with each node
passing its coreset to its parent. Because the approximation factor of the constructed coreset depends
on the quality of its component coresets  the accuracy a coreset needs (and thus the overall commu-
nication complexity) scales with the height of this tree. Although it is possible to ﬁnd a spanning
tree in any communication network  when the graph has large diameter every tree has large height.
In particular many natural networks such as grid networks have a large diameter (Ω(√n) for grids)
which greatly increases the size of the local coresets. We show that it is possible to construct a global
coreset with low communication overhead. This is done by distributing the coreset construction pro-
cedure rather than combining local coresets. The communication needed to construct this coreset is
negligible – just a single value from each data set representing the approximate cost of their local
optimal clustering. Since the sampled global -coreset is the same size as any local -coreset  this
leads to an improvement of the communication cost over the other approaches. See Figure 1 for an
illustration. The constructed coreset is smaller by a factor of n in general graphs  and is independent
of the communication topology. This method excels in sparse networks with large diameters  where
the previous approach in [23] requires coresets that are quadratic in the size of the diameter for
k-median and quartic for k-means; see Section 4 for details. [9] also merge coresets using coreset
construction  but they do so in a model of parallel computation and ignore communication costs.
Balcan et al. [3] and Daume et al. [6] consider communication complexity questions arising when
doing classiﬁcation in distributed settings. In concurrent and independent work  Kannan and Vem-

2

563124C2C4C5C6C3565631245 2 3 4 6 1 pala [15] study several optimization problems in distributed settings  including k-means clustering
under an interesting separability assumption.

p∈P w(p)d(p  x)2. Similarly  the k-median cost is deﬁned as(cid:80)

set P ⊆ Rd. Here the k-means cost is deﬁned as cost(P  x) = (cid:80)
is deﬁned as(cid:80)

2 Preliminaries
Let d(p  q) denote the Euclidean distance between any two points p  q ∈ Rd. The goal of k-means
clustering is to ﬁnd a set of k centers x = {x1  x2  . . .   xk} which minimize the k-means cost of data
p∈P d(p  x)2 where d(p  x) =
minx∈x d(p  x). If P is a weighted data set with a weighting function w  then the k-means cost
p∈P d(p  x). Both
k-means and k-median cost functions are known to be NP-hard to minimize (see for example [2]).
For both objectives  there exist several readily available polynomial-time algorithms that achieve
constant approximation solutions (see for example [16  18]).
In distributed clustering  we consider a set of n nodes V = {vi  1 ≤ i ≤ n} which communicate
on an undirected connected graph G = (V  E) with m = |E| edges. More precisely  an edge
(vi  vj) ∈ E indicates that vi and vj can communicate with each other. Here we measure the
communication cost in number of points transmitted  and assume for simplicity that there is no
latency in the communication. On each node vi  there is a local data set Pi  and the global data set
i=1 Pi. The goal is to ﬁnd a set of k centers x which optimize cost(P  x) while keeping
the computation efﬁcient and the communication cost as low as possible. Our focus is to reduce the
communication cost while preserving theoretical guarantees for approximating clustering cost.
Coresets: For the distributed clustering task  a natural approach to avoid broadcasting raw data is
to generate a local summary of the relevant information. If each site computes a summary for their
own data set and then communicates this to a central coordinator  a solution can be computed from
a much smaller amount of data  drastically reducing the communication.
In the centralized setting  the idea of summarization with respect to the clustering task is captured
by the concept of coresets [13  8]. A coreset is a set of weighted points whose cost approximates the
cost of the original data for any set of k centers. The formal deﬁnition of coresets is:
Deﬁnition 1 (coreset). An -coreset for a set of points P with respect to a center-based cost function
is a set of points S and a set of weights w : S → R such that for any set of centers x  we have
(1 − )cost(P  x) ≤
In the centralized setting  many coreset construction algorithms have been proposed for k-median 
k-means and some other cost functions. For example  for points in Rd  algorithms in [8] construct
coresets of size ˜O(kd/4) for k-means and coresets of size ˜O(kd/2) for k-median. In the dis-
tributed setting  it is natural to ask whether there exists an algorithm that constructs a small coreset
for the entire point set but still has low communication cost. Note that the union of coresets for mul-
tiple data sets is a coreset for the union of the data sets. The immediate construction of combining
the local coresets from each node would produce a global coreset whose size was larger by a factor
of n  greatly increasing the communication complexity. We present a distributed algorithm which
constructs a global coreset the same size as the centralized construction and only needs a single
value1 communicated to each node. This serves as the basis for our distributed clustering algorithm.

is P =(cid:83)n

(cid:80)

p∈S w(p)cost(p  x) ≤ (1 + )cost(P  x).

3 Distributed Coreset Construction
Here we design a distributed coreset construction algorithm for k-means and k-median. The under-
lying technique can be extended to other additive clustering objectives such as k-line median.
To gain some intuition on the distributed coreset construction algorithm  we brieﬂy review the con-
struction algorithm in [8] in the centralized setting. The coreset is constructed by computing a
constant approximation solution for the entire data set  and then sampling points proportional to
their contributions to the cost of this solution. Intuitively  the points close to the nearest centers can
be approximately represented by the centers while points far away cannot be well represented. Thus 
points should be sampled with probability proportional to their contributions to the cost. Directly
adapting the algorithm to the distributed setting would require computing a constant approximation

1The value that is communicated is the sum of the costs of approximations to the local optimal clustering.

This is guaranteed to be no more than a constant factor times larger than the optimal cost.

3

Algorithm 1 Communication aware distributed coreset construction
Input: Local datasets {Pi  1 ≤ i ≤ n}  parameter t (number of points to be sampled).

Round 1: on each node vi ∈ V
• Compute a constant approximation Bi for Pi.
Communicate cost(Pi  Bi) to all other nodes.
(cid:80)n
Round 2: on each node vi ∈ V
• Set ti = t cost(Pi Bi)
j=1 cost(Pj  Bj ) and mp = cost(p  Bi) ∀p ∈ Pi.
• Pick a non-uniform random sample Si of ti points from Pi 
(cid:80)
(cid:80)
Let wq =
• For ∀b ∈ Bi  let Pb = {p ∈ Pi : d(p  b) = d(p  Bi)}  wb = |Pb| −

where for every q ∈ Si and p ∈ Pi  we have q = p with probability mp/(cid:80)
(cid:80)

for each q ∈ Si.

q∈Pb∩S wq.
Output: Distributed coreset: points Si ∪ Bi with weights {wq : q ∈ Si ∪ Bi}  1 ≤ i ≤ n.

z∈Pi
tmq

z∈Pi

mz

i

mz.

solution for the entire data set. We show that a global coreset can be constructed in a distributed
fashion by estimating the weight of the entire data set with the sum of local approximations. With
this approach  it sufﬁces for nodes to communicate the total costs of their local solutions.
Theorem 1. For distributed k-means and k-median clustering on a graph  there exists an algorithm
such that with probability at least 1 − δ  the union of its output on all nodes is an -coreset for
2 (kd+
log 1

δ )+nk log nk
δ ) + nk) for k-median. The total communication cost is O(mn).

i=1 Pi. The size of the coreset is O( 1

δ ) for k-means  and O( 1

P =(cid:83)n

4 (kd+log 1

2 (kd + log 1

4 (kd + log 1

δ ) + nk log nk

δ ) for k-means and O( 1

. Set the weights of the points as wp =

mp(cid:80)
(cid:105)
=(cid:80)
q∈S E[wqf (q)] =(cid:80)

As described below  the distributed coreset construction can be achieved by using Algorithm 1 with
appropriate t  namely O( 1
δ )) for k-
median. Due to space limitation  we describe a proof sketch highlighting the intuition and provide
the details in the supplementary material.
Proof Sketch of Theorem 1: The analysis relies on the deﬁnition of the pseudo-dimension of a
function space and a sampling lemma.
Deﬁnition 2 ([19  8]). Let F be a ﬁnite set of functions from a set P to R≥0. For f ∈ F   let
B(f  r) = {p : f (p) ≤ r}. The dimension of the function space dim(F  P ) is the smallest integer d

such that for any G ⊆ P  (cid:12)(cid:12){G ∩ B(f  r) : f ∈ F  r ≥ 0}
(cid:12)(cid:12) ≤ |G|d.
(cid:104)(cid:80)
(cid:80)
p∈P Pr[q = p]wpf (p) =(cid:80)

Suppose we draw a sample S according to {mp : p ∈ P}  namely for each q ∈ S and p ∈ P   q = p
with probability
for p ∈ P . Then for
any f ∈ F   the expectation of the weighted cost of S equals the cost of the original data P   since
E
If the sample size is large enough  then we also have concentration for any f ∈ F . The lemma is
implicit in [8] and we include the proof in the supplementary material.
mp(cid:80)
Lemma 1. Fix a set F of functions f : P → R≥0. Let S be a sample drawn i.i.d. from P according
(cid:0)dim(F  P ) + log 1
(cid:1)  then with probabil-
(cid:80)
. Let wp =
to {mp ∈ R≥0 : p ∈ P}: for each q ∈ S and p ∈ P   q = p with probability
(cid:12)(cid:12)(cid:12) ≤ 
(cid:16)(cid:80)
(cid:17)(cid:16)
z∈P mz
mp|S|
p∈P f (p) and(cid:80)
To get a small bound on the difference between(cid:80)
ity at least 1 − δ ∀f ∈ F :
mp such that(cid:80)
maxf∈F f (p)  then the difference is bounded by (cid:80)

q∈S wqf (q)  we need to choose
is bounded. More precisely  if we choose mp =
p∈P mp.

for p ∈ P . For a sufﬁciently large c  if |S| ≥ c
2
q∈S wqf (q)

p∈P mp is small and maxp∈P

p∈P f (p) −

(cid:12)(cid:12)(cid:12)(cid:80)

q∈S wqf (q)

p∈P f (p).

p∈P mp

maxp∈P

f (p)
mp

.

(cid:80)

z∈P mz
mp|S|

(cid:80)

z∈P mz

δ

(cid:17)

z∈P mz

q∈S

f (p)
mp

We ﬁrst consider the centralized setting and review how [8] applied the lemma to construct a core-
set for k-median as in Deﬁnition 1. A natural approach is to apply this lemma directly to the
cost fx(p) := cost(p  x). The problem is that a suitable upper bound mp is not available for
cost(p  x). However  we can still apply the lemma to a different set of functions deﬁned as fol-
lows. Let bp denote the closest center to p in the approximation solution. Aiming to approximate

4

δ

2

(cid:80)

p∈P fx(p) −

p∈P fx(p) −

p∈P cost(p  x) −

p[cost(p  x) − cost(bp  x)] rather than to approximate(cid:80)

the error(cid:80)
(cid:80)
(cid:80)
q∈S wqfx(q)| by 2(cid:80)
Note that(cid:80)
(cid:80)
q∈S wqfx(q) does not equal(cid:80)
However  it equals the difference between(cid:80)

p cost(p  x) directly  we deﬁne
fx(p) := cost(p  x)− cost(bp  x) + cost(p  bp)  where cost(p  bp) is added so that fx(p) ≥ 0. Since
0 ≤ fx(p) ≤ 2cost(p  bp)  we can apply the lemma with mp = 2cost(p  bp). It bounds the differ-
ence |
p∈P cost(p  bp)  so we have an O()-approximation.
q∈S wqcost(q  x).
p∈P cost(p  x) and a weighted cost of the sampled
points and the centers in the approximation solution. To get a coreset as in Deﬁnition 1  we need to
add the centers of the approximation solution with speciﬁc weights to the coreset. Then when the
sample is sufﬁciently large  the union of the sampled points and the centers is an -coreset.
Our key contribution in this paper is to show that in the distributed setting  it sufﬁces to choose
bp from the local approximation solution for the local dataset containing p  rather than from an
approximation solution for the global dataset. Furthermore  the sampling and the weighting of the
coreset points can be done in a local manner. In the following  we provide a formal veriﬁcation
of our discussion above. We have the following lemma for k-median with F = {fx : fx(p) =
d(p  x) − d(bp  x) + d(p  bp)  x ∈ (Rd)k}.
Lemma 2. For k-median  the output of Algorithm 1 is an -coreset with probability at least 1 − δ 
if t ≥ c
Proof Sketch of Lemma 2: We want to show that for any set of centers x the true cost for using
these centers is well approximated by the cost on the weighted coreset. Note that our coreset has two
types of points: sampled points q ∈ S = ∪n
and local solution
centers b ∈ B = ∪n
wq. We use bp to represent the nearest
center to p in the local approximation solution. We use Pb to represent the set of points which have
b as their closest center in the local approximation solution.
As mentioned above  we construct fx(p) to be the difference between the cost of p and
the cost of bp so that Lemma 1 can be applied. Note that the centers are weighted such
p∈P d(bp  x) −
q∈S wqmq  we can show

(cid:1) for a sufﬁciently large constant c.

(cid:0)dim(F  P ) + log 1

i=1Si with weight wq :=

b∈B |Pb|d(b  x) −

z∈P mz
mq|S|

(cid:80)

q∈S∩Pb

q∈S∩Pb

(cid:80)

b∈B

In [8] it

q∈S wqfx(q)

2 (kd + log 1

q∈S∪B wqd(q  x)

q∈S∪B wqd(q  x)

p∈P fx(p) −

p∈P d(p  x) −

p∈P d(p  x) −

p∈P d(p  x)  as desired.

wqd(b  x) = (cid:80)
(cid:80)

i=1Bi with weight wb := |Pb|−
that (cid:80)
b∈B wbd(b  x) = (cid:80)
(cid:80)
(cid:80)
(cid:80)
q∈S wqd(bq  x). Taken together with the fact that (cid:80)
p∈P mp = (cid:80)
(cid:12)(cid:12)(cid:12)(cid:80)
(cid:12)(cid:12)(cid:12) =
(cid:12)(cid:12)(cid:12)(cid:80)
(cid:80)
(cid:12)(cid:12)(cid:12)(cid:80)
(cid:12)(cid:12)(cid:12) ≤ O()(cid:80)
O(cid:0) 1

(cid:12)(cid:12)(cid:12). Note that 0 ≤
(cid:80)
δ )(cid:1)  the weighted cost of S ∪ B approximates the k-median cost of P for any set

that
fx(p) ≤ 2d(p  bp) by triangle inequality  and S is sufﬁciently large and chosen according to
weights mp = d(p  bp)  so the conditions of Lemma 1 are met. Thus we can conclude that

is shown that dim(F  P ) = O(kd). Therefore  by Lemma 2  when |S| ≥
of centers  then (S ∪ B  w) becomes an -coreset for P . The total communication cost is bounded
by O(mn)  since even in the most general case that every node only knows its neighbors  we can
broadcast the local costs with O(mn) communication (see Algorithm 3).
Proof Sketch for k-means: Similar methods prove that for k-means when t = O( 1
δ ) +
δ ))  the algorithm constructs an -coreset with probability at least 1− δ. The key difference
nk log nk
is that triangle inequality does not apply directly to the k-means cost  and so the error |cost(p  x) −
cost(bp  x)| and thus fx(p) are not bounded. The main change to the analysis is that we divide the
points into two categories: good points whose costs approximately satisfy the triangle inequality
(up to a factor of 1/) and bad points. The good points for a ﬁxed set of centers x are deﬁned as
G(x) = {p ∈ P : |cost(p  x) − cost(bp  x)| ≤ ∆p} where the upper bound is ∆p = cost(p bp)
  and
the analysis follows as in Lemma 2. For bad points we can show that the difference in cost must still
be small  namely O( min{cost(p  x)  cost(bp  x)}).
More formally  let fx(p) = cost(p  x) − cost(bp  x) + ∆p  and let gx(p) be fx(p) if p ∈ G(x) and
(cid:88)

q∈S∪B wqcost(q  x) is decomposed into three terms:

4 (kd + log 1

(cid:88)



0 otherwise. Then(cid:80)
(cid:88)
(cid:124)

p∈P

p∈P cost(p  x) −
gx(p) −

wqgx(q)

(cid:88)
(cid:123)(cid:122)

q∈S

(A)

(cid:80)
(cid:125)

+

(cid:124)

p∈P\G(x)

q∈S\G(x)

fx(p)

−

(cid:125)

(cid:124)

(cid:123)(cid:122)

(C)

wqfx(q)

(cid:125)

(cid:123)(cid:122)

(B)

5

Algorithm 2 Distributed clustering on a graph
Input: {Pi  1 ≤ i ≤ n}: local datasets; {Ni  1 ≤ i ≤ n}: the neighbors of vi; Aα: an α-
approximation algorithm for weighted clustering instances.

Round 1: on each node vi

Round 2: on each node vi

• Construct its local portion Di of an /2-coreset by Algorithm 1 
using Message-Passing for communicating the local costs.

• Call Message-Passing(Di  Ni). Compute x = Aα((cid:83)

j Dj).

Output: x

Algorithm 3 Message-Passing(Ii  Ni)

Input: Ii is the message  Ni are the neighbors.

• Let Ri denote the information received. Initialize Ri = {Ii}  and send Ii to Ni.
• While Ri (cid:54)= {Ij  1 ≤ j ≤ n}:

If receive message Ij (cid:54)∈ Ri  then let Ri = Ri ∪ {Ij} and send Ij to Ni.

Lemma 1 bounds (A) by O()cost(P  x)  but we need an accuracy of 2 to compensate for the 1/
factor in the upper bound of fx(p). This leads to an O(1/4) factor in the sample complexity.
For (B) and (C)  |cost(p  x) − cost(bp  x)| > ∆p since p (cid:54)∈ G(x). This can be used to show that
p and bp are close to each other and far away from x  and thus |cost(p  x) − cost(bp  x)| is O()
smaller than cost(p  x) and cost(bp  x). This fact bounds ((B)) by O()cost(P  x). It also bounds
δ ).
q∈Pb∩S wq ≤ 2|Pb| when t ≥ O(nk log nk

q∈Pb∩S wq] = |Pb|  and thus(cid:80)

(C)  noting that E[(cid:80)

The proof is completed by bounding the function space dimension by O(kd) as in [8].
4 Effect of Network Topology on Communication Cost
If there is a central coordinator in the communication graph  then we can run distributed coreset con-
struction algorithm and send the local portions of the coreset to the coordinator  which can perform
the clustering task. The total communication cost is just the size of the coreset.
In this section  we consider distributed clustering over arbitrary connected topologies. We propose
to use a message passing approach for collecting information for coreset construction and sharing
the local portions of the coreset. The details are presented in Algorithm 2 and 3. Since each piece
of the coreset is shared at most twice across any particular edge in message passing  we have
Theorem 2. Given an α-approximation algorithm for weighted k-means (k-median respectively)
as a subroutine  there exists an algorithm that with probability at least 1 − δ outputs a (1 + )α-
approximation solution for distributed k-means (k-median respectively). The communication cost is
δ ) + nk)) for k-median.
O(m( 1
In contrast  an approach where each node constructs an -coreset for k-means and sends it to the
other nodes incurs communication cost of ˜O( mnkd
Our algorithm can also be applied on a rooted tree: we can send the coreset portions to the root
which then applies an approximation algorithm. Since each portion are transmitted at most h times 
Theorem 3. Given an α-approximation algorithm for weighted k-means (k-median respectively)
as a subroutine  there exists an algorithm that with probability at least 1 − δ outputs a (1 + )α-
approximation solution for distributed k-means (k-median respectively) clustering on a rooted tree
of height h. The total communication cost is O(h( 1
δ )) for k-means  and
O(h( 1

). Our algorithm signiﬁcantly reduces this.

δ )) for k-means  and O(m( 1

δ ) + nk log nk

δ ) + nk log nk

4 (kd + log 1

2 (kd + log 1

2 (kd + log 1

δ ) + nk)) for k-median.

4 (kd + log 1

4

Our approach improves the cost of ˜O( nh4kd
) for k-median
in [23] 2. The algorithm in [23] builds on each node a coreset for the union of coresets from its
2 Their algorithm used coreset construction as a subroutine. The construction algorithm they used builds
d log |P|). Throughout this paper  when we compare to [23] we assume they use the

coreset of size ˜O( nkh
coreset construction technique of [8] to reduce their coreset size and communication cost.

) for k-means and the cost of ˜O( nh2kd

2

4

6

children  and thus needs O(/h) accuracy to prevent the accumulation of errors. Since the coreset
construction subroutine has quadratic dependence on 1/ for k-median (quartic for k-means)  the
algorithm then has quadratic dependence on h (quartic for k-means). Our algorithm does not build
coreset on top of coresets  resulting in a better dependence on the height of the tree h.
In a general graph  any rooted tree will have its height h at least as large as half the diameter. For
sensors in a grid network  this implies h = Ω(√n). In this case  our algorithm gains a signiﬁcant
improvement over existing algorithms.

5 Experiments

Here we evaluate the effectiveness of our algorithm and compare it to other distributed coreset algo-
rithms. We present the k-means cost of the solution by our algorithm with varying communication
cost  and compare to those of other algorithms when they use the same amount of communication.
Data sets: We present results on YearPredictionMSD (515345 points in R90  k = 50). Similar
results are observed on ﬁve other datasets  which are presented in the supplementary material.
Experimental Methodology: We ﬁrst generate a communication graph connecting local sites  and
then partition the data into local data sets. The algorithms were evaluated on Erd¨os-Renyi random
graphs with p = 0.3  grid graphs  and graphs generated by the preferential attachment mecha-
nism [1]. We used 100 sites for YearPredictionMSD.
The data is then distributed over the local sites. There are four partition methods: uniform 
similarity-based  weighted  and degree-based. In all methods  each example is distributed to the
local sites with probability proportional to the site’s weight. In uniform partition  the sites have
equal weights; in similarity-based partition  each site has an associated data point randomly selected
from the global data and the weight is the similarity to the associated point; in weighted partition 
the weights are chosen from |N (0  1)|; in degree-based  the weights are the sites’ degrees.
To measure the quality of the coreset generated  we run Lloyd’s algorithm on the coreset and the
global data respectively to get two solutions  and compute the ratio between the costs of the two
solutions over the global data. The average ratio over 30 runs is then reported. We compare our
algorithm with COMBINE  the method of combining coresets from local data sets  and with the
algorithm of [23] (Zhang et al.). When running the algorithm of Zhang et al.  we restrict the network
to a spanning tree by picking a root uniformly at random and performing a breadth ﬁrst search.
Results: Figure 2 shows the results over different network topologies and partition methods. We
observe that the algorithms perform well with much smaller coreset sizes than predicted by the
theoretical bounds. For example  to get 1.1 cost ratio  the coreset size and thus the communication
needed is only 0.1% − 1% of the theoretical bound.
In the uniform partition  our algorithm performs nearly the same as COMBINE. This is not surpris-
ing since our algorithm reduces to the COMBINE algorithm when each local site has the same cost
and the two algorithms use the same amount of communication. In this case  since in our algorithm
the sizes of the local samples are proportional to the costs of the local solutions  it samples the same
number of points from each local data set. This is equivalent to the COMBINE algorithm with the
same amount of communication. In the similarity-based partition  similar results are observed as it
also leads to balanced local costs. However  when the local sites have signiﬁcantly different costs (as
in the weighted and degree-based partitions)  our algorithm outperforms COMBINE. As observed
in Figure 2  the costs of our solutions consistently improve over those of COMBINE by 2% − 5%.
Our algorithm then saves 10% − 20% communication cost to achieve the same approximation ratio.
Figure 3 shows the results over the spanning trees of the graphs. Our algorithm performs much better
than the algorithm of Zhang et al.  achieving about 20% improvement in cost. This is due to the fact
that their algorithm needs larger coresets to prevent the accumulation of errors when constructing
coresets from component coresets  and thus needs higher communication cost to achieve the same
approximation ratio.

Acknowledgements This work was supported by ONR grant N00014-09-1-0751  AFOSR grant
FA9550-09-1-0538  and by a Google Research Award. We thank Le Song for generously allowing
us to use his computer cluster.

7

(a) random graph  uniform

(b) random graph  similarity-based

(c) random graph  weighted

(d) grid graph  similarity-based

(e) grid graph  weighted

(f) preferential graph  degree-based

Figure 2: k-means cost (normalized by baseline) v.s. communication cost over graphs. The titles
indicate the network topology and partition method.

(a) random graph  uniform

(b) random graph  similarity-based

(c) random graph  weighted

(d) grid graph  similarity-based

(e) grid graph  weighted

(f) preferential graph  degree-based

Figure 3: k-means cost (normalized by baseline) v.s. communication cost over the spanning trees of
the graphs. The titles indicate the network topology and partition method.

References
[1] R. Albert and A.-L. Barab´asi. Statistical mechanics of complex networks. Reviews of Modern

Physics  2002.

8

  COMBINEOurAlgok-meanscostratio×1071.61.822.21.051.11.15×1071.71.81.922.12.22.31.041.061.081.11.121.141.161.181.2×1071.61.71.81.922.12.21.041.061.081.11.121.141.161.181.2k-meanscostratiocommunicationcost×10622.22.42.62.81.051.11.15communicationcost×10622.22.42.62.81.051.11.15communicationcost×1062.22.42.62.81.051.11.15  Zhangetal.OurAlgok-meanscostratio×1071.61.822.211.11.21.31.41.5×1071.71.81.922.12.22.311.051.11.151.21.251.31.351.4×1071.61.71.81.922.12.211.051.11.151.21.251.31.351.4k-meanscostratiocommunicationcost×10622.22.42.62.811.11.21.31.4communicationcost×10622.22.42.62.811.11.21.31.4communicationcost×1062.22.42.62.811.11.21.31.4[2] P. Awasthi and M. Balcan. Center based clustering: A foundational perspective. Survey Chap-

ter in Handbook of Cluster Analysis (Manuscript)  2013.

[3] M.-F. Balcan  A. Blum  S. Fine  and Y. Mansour. Distributed learning  communication com-

plexity and privacy. In Proceedings of the Conference on Learning Thoery  2012.

[4] J. Considine  F. Li  G. Kollios  and J. Byers. Approximate aggregation techniques for sensor

databases. In Proceedings of the International Conference on Data Engineering  2004.

[5] J. C. Corbett  J. Dean  M. Epstein  A. Fikes  C. Frost  J. Furman  S. Ghemawat  A. Gubarev 
C. Heiser  P. Hochschild  et al. Spanner: Googles globally-distributed database. In Proceedings
of the USENIX Symposium on Operating Systems Design and Implementation  2012.

[6] H. Daum´e III  J. M. Phillips  A. Saha  and S. Venkatasubramanian. Efﬁcient protocols for
distributed classiﬁcation and optimization. In Algorithmic Learning Theory  pages 154–168.
Springer  2012.

[7] S. Dutta  C. Gianella  and H. Kargupta. K-means clustering over peer-to-peer networks. In Pro-
ceedings of the International Workshop on High Performance and Distributed Mining  2005.
[8] D. Feldman and M. Langberg. A uniﬁed framework for approximating and clustering data. In

Proceedings of the Annual ACM Symposium on Theory of Computing  2011.

[9] D. Feldman  A. Sugaya  and D. Rus. An effective coreset compression algorithm for large scale
sensor networks. In Proceedings of the International Conference on Information Processing
in Sensor Networks  2012.

[10] G. Forman and B. Zhang. Distributed data clustering can be efﬁcient and exact. ACM SIGKDD

Explorations Newsletter  2000.

[11] S. Greenhill and S. Venkatesh. Distributed query processing for mobile surveillance. In Pro-

ceedings of the International Conference on Multimedia  2007.

[12] M. Greenwald and S. Khanna. Power-conserving computation of order-statistics over sensor
networks. In Proceedings of the ACM SIGMOD-SIGACT-SIGART Symposium on Principles
of Database Systems  2004.

[13] S. Har-Peled and S. Mazumdar. On coresets for k-means and k-median clustering. In Proceed-

ings of the Annual ACM Symposium on Theory of Computing  2004.

[14] E. Januzaj  H. Kriegel  and M. Pfeiﬂe. Towards effective and efﬁcient distributed clustering.
In Workshop on Clustering Large Data Sets in the IEEE International Conference on Data
Mining  2003.

[15] R. Kannan and S. Vempala. Nimble algorithms for cloud computing.

arXiv:1304.3162  2013.

arXiv preprint

[16] T. Kanungo  D. M. Mount  N. S. Netanyahu  C. D. Piatko  R. Silverman  and A. Y. Wu. A
local search approximation algorithm for k-means clustering. In Proceedings of the Annual
Symposium on Computational Geometry  2002.

[17] H. Kargupta  W. Huang  K. Sivakumar  and E. Johnson. Distributed clustering using collective

principal component analysis. Knowledge and Information Systems  2001.

[18] S. Li and O. Svensson. Approximating k-median via pseudo-approximation. In Proceedings

of the Annual ACM Symposium on Theory of Computing  2013.

[19] Y. Li  P. M. Long  and A. Srinivasan. Improved bounds on the sample complexity of learning.
In Proceedings of the eleventh annual ACM-SIAM Symposium on Discrete Algorithms  2000.
[20] S. Mitra  M. Agrawal  A. Yadav  N. Carlsson  D. Eager  and A. Mahanti. Characterizing web-

based video sharing workloads. ACM Transactions on the Web  2011.

[21] C. Olston  J. Jiang  and J. Widom. Adaptive ﬁlters for continuous queries over distributed data
streams. In Proceedings of the ACM SIGMOD International Conference on Management of
Data  2003.

[22] D. Tasoulis and M. Vrahatis. Unsupervised distributed clustering. In Proceedings of the Inter-

national Conference on Parallel and Distributed Computing and Networks  2004.

[23] Q. Zhang  J. Liu  and W. Wang. Approximate clustering on distributed data streams.

Proceedings of the IEEE International Conference on Data Engineering  2008.

In

9

,Maria-Florina Balcan
Steven Ehrlich
Yingyu Liang