2010,Probabilistic latent variable models for distinguishing between cause and effect,We propose a novel method for inferring whether X causes Y or vice versa from joint observations of X and Y. The basic idea is to model the observed data using probabilistic latent variable models  which incorporate the effects of unobserved noise. To this end  we consider the hypothetical effect variable to be a function of the hypothetical cause variable and an independent noise term (not necessarily additive). An important novel aspect of our work is that we do not restrict the model class  but instead put general non-parametric priors on this function and on the distribution of the cause. The causal direction can then be inferred by using standard Bayesian model selection. We evaluate our approach on synthetic data and real-world data and report encouraging results.,Probabilistic latent variable models for distinguishing

between cause and effect

Joris M. Mooij

MPI for Biological Cybernetics

T¨ubingen  Germany

Oliver Stegle

MPI for Biological Cybernetics

T¨ubingen  Germany

joris.mooij@tuebingen.mpg.de

oliver.stegle@tuebingen.mpg.de

Dominik Janzing

MPI for Biological Cybernetics

T¨ubingen  Germany

Kun Zhang

MPI for Biological Cybernetics

T¨ubingen  Germany

dominik.janzing@tuebingen.mpg.de

kun.zhang@tuebingen.mpg.de

Bernhard Sch¨olkopf

MPI for Biological Cybernetics

T¨ubingen  Germany

bernhard.schoelkopf@tuebingen.mpg.de

Abstract

We propose a novel method for inferring whether X causes Y or vice versa from joint
observations of X and Y . The basic idea is to model the observed data using probabilistic
latent variable models  which incorporate the effects of unobserved noise. To this end  we
consider the hypothetical effect variable to be a function of the hypothetical cause variable
and an independent noise term (not necessarily additive). An important novel aspect of
our work is that we do not restrict the model class  but instead put general non-parametric
priors on this function and on the distribution of the cause. The causal direction can then
be inferred by using standard Bayesian model selection. We evaluate our approach on
synthetic data and real-world data and report encouraging results.

Introduction

1
The challenge of inferring whether X causes Y (“X → Y ”) or vice versa (“Y → X”) from
joint observations of the pair (X  Y ) has recently attracted increasing interest [1  2  3  4  5  6  7 
8]. While the traditional causal discovery methods [9  10] based on (conditional) independences
between variables require at least three observed variables  some recent approaches can deal with
pairs of variables by exploiting the complexity of the (conditional) probability distributions. On
an intuitive level  the idea is that the factorization of the joint distribution P (cause  eﬀect) into
P (cause)P (eﬀect| cause) typically yields models of lower total complexity than the factorization
into P (eﬀect)P (cause| eﬀect). Although the notion of “complexity” is intuitively appealing  it is
not obvious how it should be precisely deﬁned.
If complexity is measured in terms of Kolmogorov complexity  this kind of reasoning would be
in the spirit of the principle of “algorithmically independent conditionals” [11]  which can also
be embedded into a general theory of algorithmic-information-based causal discovery [12]. The
following theorem is implicitly stated in the latter reference (see remarks before (26) therein):

1

Theorem 1 Let P (X  Y ) be a joint distribution with ﬁnite Kolmogorov complexity such that P (X)
and P (Y | X) are algorithmically independent  i.e. 

I(cid:0)P (X) : P (Y | X)(cid:1) += 0  

where += denotes equality up to additive constants. Then:

K(cid:0)P (X)(cid:1) + K(cid:0)P (Y | X)(cid:1) +≤ K(cid:0)P (Y )(cid:1) + K(cid:0)P (X | Y )(cid:1) .

(1)

(2)

The proof is given by observing that (1) implies that the shortest description of P (X  Y ) is given
by separate descriptions of P (X) and P (Y | X). It is important to note at this point that the total
complexity of the causal model consists of both the complexity of the conditional distribution and
of the marginal of the putative cause. However  since Kolmogorov complexity is uncomputable 
this does not solve the causal discovery problem in practice. Therefore  other notions of complexity
need to be considered.
The work of [4] measures complexity in terms of norms in a reproducing kernel Hilbert space  but
due to the high computational costs it applies only to cases where one of the variables is binary. The
methods [1  2  3  5  6] deﬁne classes of conditionals C and marginal distributions M  and prefer
X → Y whenever P (X) ∈ M and P (Y | X) ∈ C but P (Y ) (cid:54)∈ M or P (X | Y ) (cid:54)∈ C. This can
be interpreted as a (crude) notion of model complexity: all probability distributions inside the class
are simple  and those outside the class are complex. However  this a priori restriction to a particular
class of models poses serious practical limitations (even when in practice some of these methods
“soften” the criteria by  for example  using the p-values of suitable hypothesis tests).
In the present work we propose to use a fully non-parametric  Bayesian approach instead. The
key idea is to deﬁne appropriate priors on marginal distributions (of the cause) and on conditional
distributions (of the effect given the cause) that both favor distributions of low complexity. To decide
upon the most likely causal direction  we can compare the marginal likelihood (also called evidence)
of the models corresponding to each of the hypotheses X → Y and Y → X. An important novel
aspect of our work is that we explicitly treat the “noise” as a latent variable that summarizes the
inﬂuence of all other unobserved causes of the effect. The additional key assumption here is the
independence of the “causal mechanism” (the function mapping from the cause and noise to the
effect) and the distribution of the cause  an idea that was exploited in a different way recently for the
deterministic (noise-free) case [13]. The three main contributions of this work are:

restricting the class of possible causal mechanisms;

• to show that causal discovery for the two-variable cause-effect problem can be done without
• to point out the importance of accounting for the complexity of the distribution of the cause  in
• to show that a Bayesian approach can be used for causal discovery even in the case of two

addition to the complexity of the causal mechanism (like in equation (2));

continuous variables  without the need for explicit independence tests.

The last aspect allows for a straightforward extension of the method to the multi-variable case  the
details of which are beyond the scope of this article.1 Apart from discussing the proposed method on
a theoretical level  we also evaluate our approach on both simulated and real-world data and report
good empirical results.

2 Theory

We start with a theoretical treatment of how to solve the basic causal discovery task (see Figure 1a).

1For the special case of additive Gaussian noise  the method proposed in [1] would also seem to be a valid
Bayesian approach to causal discovery with continuous variables. However  that approach is ﬂawed  as it
either completely ignores the distribution for the cause  or uses a simple Gaussian marginal distribution for the
cause  which may not be realistic (from the paper it is not clear exactly what is proposed). But  as suggested
by Theorem 1  and as illustrated by our empirical results  the complexity of the input distribution plays an
important role here that cannot be neglected  especially in the two-variable case.

2

(a)

X

E

Y

or

X

Y

˜E

(b)

θX

xi

ei

θf

f

yi = f (xi  ei)

“X causes Y ”

“Y causes X”

i = 1  . . .   N

Figure 1: Observed variables are colored gray  and unobserved variables are white. (a) The basic
causal discovery task: which of the two causal models gives the best explanation of the observed
data D = {(xi  yi)}N

i=1? (b) More detailed version of the graphical model for “X causes Y ”.

2.1 Probabilistic latent variable models for causal discovery

First  we give a more precise deﬁnition of the class of models that we use for representing that X
causes Y (“X → Y ”). We assume that the relationship between X and Y is not deterministic  but
disturbed by unobserved noise E (effectively  the summary of all other unobserved causes of Y ).
The situation is depicted in the left-hand part of Figure 1a: X and E both cause Y   but although X
and Y are observed  E is not. We make the following additional assumptions:
(A) There are no other causes of Y   or in other words  we assume determinism: a function f exists

such that

This function will henceforth be called the causal mechanism.

(B) X and E have no common causes  i.e.  X and E are independent:

Y = f (X  E).

X⊥⊥E.

(C) The distribution of the cause is “independent” from the causal mechanism.2
(D) The noise has a standard-normal distribution: E ∼ N (0  1).3
Several recent approaches to causal discovery are based on the assumptions (A) and (B) only  but
pose one of the following additional restrictions on f:

• f is linear [2];
• additive noise [5]  where f (X  E) = F (X) + E for some function F ;
• the post-nonlinear model [6]  where f (X  E) = G(F (X) + E) for some functions F  G.

For these special cases  it has been shown that a model of the same (restricted) form in the reverse
direction Y → X that induces the same joint distribution on (X  Y ) does not exist in general. This
asymmetry can be used for inferring the causal direction.
In practice  a limited model class may lead to wrong conclusions about the causal direction. For
example  when assuming additive noise  it may happen that neither of the two directions provides
a sufﬁciently good ﬁt to the data and hence no decision can be made. Therefore  we would like to
drop this kind of assumptions that limit the model class. However  assumptions (A) and (B) are not
enough on their own: in general  one can always construct a random variable ˜E ∼ N (0  1) and a
function ˜f : R2 → R such that

X = ˜f (Y  ˜E) 

Y ⊥⊥ ˜E

(3)

(for a proof of this statement  see e.g.  [14  Theorem 1]).
In combination with the other two assumptions (C) and (D)  however  one does obtain an asymmetry
that can be used to infer the causal direction. Note that assumption (C) still requires a suitable math-
ematical interpretation. One possibility would be to interpret this independence as an algorithmic

2This assumption may be violated in biological systems  for example  where the causal mechanisms may

have been tuned to their input distributions through evolution.

with ¯E ∼ N (0  1) and ¯f = f(cid:0)·  g(·)(cid:1).

3This is not a restriction of the model class  since in general we can write E = g( ¯E) for some function g 

3

independence similar to Theorem 1  but then we could not use it in practice. Another interpretation
has been used in [13] for the noise-free case (i.e.  the deterministic model Y = f (X)). Here  our
aim is to deal with the noisy case. For this setting we propose a Bayesian approach  which will be
explained in the next subsection.
2.2 The Bayesian generative model for X → Y
The basic idea is to deﬁne non-parametric priors on the causal mechanisms and input distributions
that favor functions and distributions of low complexity. Inferring the causal direction then boils
down to standard Bayesian model selection  where preference is given to the model with the largest
marginal likelihood.
We introduce random variables xi (the cause)  yi (the effect) and ei (the noise)  for i = 1  . . .   N
i=1 to denote the whole N-
where N is the number of data points. We use vector notation x = (xi)N
tuple of X-values xi  and similarly for y and e. To make a Bayesian model comparison between the
two models X → Y and Y → X  we need to calculate the marginal likelihoods p(x  y | X → Y )
and p(x  y | Y → X). Below  we will only consider the model X → Y and omit this from the
notation for brevity. The other model Y → X is completely analogous  and can be obtained by
simply interchanging the roles of X and Y .
The marginal likelihood for the observed data x  y under the model X → Y is given by (see also
Figure 1b):
p(x  y) = p(x)p(y | x) =

(cid:35)(cid:34)(cid:90) (cid:32) N(cid:89)

δ(cid:0)yi − f (xi  ei)(cid:1)pE(ei)

(cid:33)

i=1

i=1

p(θX )dθX

p(xi | θX )

de p(f | θf )df p(θf )dθf
(4)
Here  θX and θf parameterize prior distributions of the cause X and the causal mechanism f 
respectively. Note how the four assumptions discussed in the previous subsection are incorporated
1  . . .   N. Assumption (B) is realized by the a priori independence p(x  e| θX ) = p(x| θX )pE(e).
Assumption (C) is realized as the a priori independence p(f  θX ) = p(f )p(θX ). Assumption (D)
is obvious by taking pE(e) := N (e| 0  1).

into the model: assumption (A) results in Dirac delta distributions δ(cid:0)yi − f (xi  ei)(cid:1) for each i =

(cid:34)(cid:90) (cid:32) N(cid:89)

(cid:33)

(cid:35)

2.3 Choosing the priors
In order to completely specify the model X → Y   we need to choose particular priors. In this work 
we assume that all variables are real numbers (i.e.  x  y and e are random variables taking values in
RN )  and use the following choices (although other choices are also possible):
• For the prior distribution of the cause X  we use a Gaussian mixture model

p(xi | θX ) =

αjN (xi | µj  σ2
j )

k(cid:88)

j=1

with hyperparameters θX = (k  α1  . . .   αk  µ1  . . .   µk  σ1  . . .   σk). We put an improper
Dirichlet prior (with parameters (−1 −1  . . .  −1)) on the component weights α and ﬂat priors
on the component parameters µ  σ.
• For the prior distribution p(f | θf ) of the causal mechanism f  we take a Gaussian process with

zero mean function and squared-exponential covariance function:

(cid:0)(x  e)  (x(cid:48)  e(cid:48))(cid:1) = λ2

kθf

Y exp

(cid:18)
− (x − x(cid:48))2

(cid:19)

2λ2
X

(cid:18)

exp

− (e − e(cid:48))2

2λ2
E

(cid:19)

(5)

where θf = (λX   λY   λE) are length-scale parameters. The parameter λY determines the
amplitude of typical functions f (x  e)  and the length scales λX and λE determine how quickly
typical functions change depending on x and e  respectively. In the additive noise case  for
example  the length scale λE is large compared to the length scale λX  as this leads to an almost
linear dependence of f on e. We put broad Gamma priors on all length-scale parameters.

4

2.4 Approximating the evidence
Now that we have fully speciﬁed the model X → Y   the remaining task is to calculate the integral (4)
for given observations x  y. As the exact calculation seems intractable  we here use a particular
approximation of this integral.

The marginal distribution

For the model of the distribution of the cause p(x)  we use an asymptotic expansion based on the
Minimum Message Length principle that yields the following approximation (for details  see [15]):

− log p(x) ≈ min

θX

+

k
2

log

N
12

+

3k
2

− log p(x| θX )

(6)

 k(cid:88)

j=1

(cid:18) N αj

(cid:19)

12

log

 .

The conditional distribution
For the conditional distribution p(y | x) according to the model X → Y   we start by replacing the
integral over the length-scales θf by a MAP estimate:

Integrating over the latent variables e and using the Dirac delta function calculus (where we assume
invertability of the functions fx : e (cid:55)→ f (e  x) for all x)  we obtain:4

(cid:90)

(cid:90)

p(y | x) ≈ max

θf

p(θf )

δ(cid:0)y − f (x  e)(cid:1) pE(e)de p(f | θf )df.
(cid:0)(f )(cid:1) p(f | θf )
(cid:0)xi  i(f )(cid:1)(cid:12)(cid:12)(cid:12)(cid:12)

(cid:90)
(cid:12)(cid:12)(cid:12)(cid:12) ∂f

J(f )

pE

∂e

i=1

δ(cid:0)y − f (x  e)(cid:1) pE(e)de p(f | θf )df =
N(cid:89)
J(f ) = det(cid:12)(cid:12)∇ef(cid:0)x  (f )(cid:1)(cid:12)(cid:12) =

where (f ) is the (unique) vector satisfying y = f (x  )  and

df

(7)

is the absolute value of the determinant of the Jacobian which results when integrating over the
Dirac delta function. The next step would be to integrate over all possible causal mechanisms f
(which would be an inﬁnite-dimensional integral). However  this integral again seems intractable 
and hence we revert to the following approximation. Because of space constraints  we only give a
brief sketch of the procedure here.
Let us suppress the hyperparameters θf for the moment to simplify notation. The idea is to ap-
proximate the inﬁnite-dimensional GP function f by a linear combination over basis functions φj
parameterized by a weight vector α ∈ RN with a Gaussian prior distribution:

fα(x  e) =

αjφj(x  e) 

α ∼ N (0  1).

N(cid:88)

j=1

Now  deﬁning the matrix Φij(x  ) := φj(xi  i)  the relationship y = Φ(x  )α gives a corre-
spondence between  and α (for ﬁxed x and y)  which we assume to be one-to-one. In particular 
α = Φ(x  )−1y. We can then approximate equation (7) by replacing the integral by a maximum:

(cid:0)(α)(cid:1) N (α| 0  1)

J(α)

(cid:0)(cid:1) N (y | 0  ΦΦT )

J()

  (8)

= max



pE

dα ≈ max

α

pE

(cid:90)

(cid:0)(α)(cid:1) N (α| 0  1)

J(α)

pE

where in the last step we used the one-to-one correspondence between  and α.

4Alternatively  one could ﬁrst integrate over the causal mechanisms f  and then optimize over the noise
values e  similar to what is usually done in GPLVMs [16]. However  we believe that for the purpose of causal
discovery  that approach does not work well. The reason is that when optimizing over e  the result is often quite
dependent on x  which violates our basic assumption that X⊥⊥E. The approach we follow here is more related
to nonlinear ICA  whereas GPLVMs are related to nonlinear PCA.

5

(cid:123)(cid:122)

i=1

(9)

(cid:124)

(cid:123)(cid:122)

θf  

(cid:123)(cid:122)

(cid:125)

(cid:124)

(cid:125)

(cid:124)

Hyperpriors

Noise prior

GP marginal

(cid:125)

+

− log N (| 0  I)

− log N (y | 0  K)

− log p(y | x) ≈ min

− log p(θf )

After working out the details and taking the negative logarithm  the ﬁnal optimization problem
becomes:

 .
N(cid:88)
log(cid:12)(cid:12)Mi·K−1y(cid:12)(cid:12)
(cid:123)(cid:122)
(cid:125)
(cid:124)
Here  the kernel (Gram) matrix K is deﬁned by Kij := k(cid:0)(xi  i)  (xj  j)(cid:1)  where k : R4 → R
(cid:0)(xi  i)  (xj  j)(cid:1). Note that the matrices K and M both depend upon .

is the covariance function (5).
contains the expected mean derivatives of the GP with respect to e and is deﬁned by Mij
∂k
∂e
The Information term in the objective function (involving the partial derivatives ∂k
∂e ) may be sur-
prising at ﬁrst sight. It is necessary  however  to penalize dependences between x and : ignoring
it would yield an optimal  that is heavily dependent on x  violating assumption (B). Interestingly 
this term is not present in the additive noise case that is usually considered  as the derivative of the
causal mechanism with respect to the noise equals one  and its logarithm therefore vanishes. In the
next subsection  we discuss some implementation issues that arise when one attempts to solve (6)
and (9) in practice.

It corresponds to ΦΦT in our approximation. The matrix M
:=

Information term

Implementation issues

First of all  we preprocess the observed data x and y by standardizing them to zero mean and unit
variance for numerical reasons: if the length scales become too large  the kernel matrix K becomes
difﬁcult to handle numerically.
We solve the optimization problem (6) concerning the marginal distribution numerically by means
of the algorithm written by Figueiredo and Jain [15]. We use a small but nonzero value (10−4) of
the regularization parameter.
The optimization problem (9) concerning the conditional distribution poses more serious practical
problems. Basically  since we approximate a Bayesian integral by an optimization problem  the
objective function (9) still needs to be regularized: if one of the partial derivatives ∂f
∂e becomes zero 
the objective function diverges. In addition  the kernel matrix corresponding to (5) is extremely
ill-posed. To deal with these matters  we propose the following ad-hoc solutions:

√

it as log |x| ≈ log

• We regularize the numerically ill-behaving logarithm in the last term in (9) by approximating
• We add a small amount of N (0  σ2)-uncertainty to each observed yi-value  with σ (cid:28) 1. This
is equivalent to replacing K by K + σ2I  which regularizes the ill-conditioned matrix K. We
used σ = 10−5.

x2 +  with  (cid:28) 1.

Further  note that in the ﬁnal optimization problem (9)  the unobserved noise values  can in fact
also be regarded as additional hyperparameters  similar to the GPLVM model [16]. In our setting 
this optimization is particularly challenging  as the number of parameters exceeds the number of
observations. In particular  for small length scales λX and λE the objective function may exhibit
a large number of local minima. In our implementation we applied the following measures to deal
with this issue:

• We initialize  with an additive noise model  by taking the residuals from a standard GP re-
gression as initial values for . The reason for doing this is that in an additive noise model  all
partial derivatives ∂f
∂e are positive and constant. This initialization effectively leads to a solution
that satisﬁes the invertability assumption that we made in approximating the evidence.5

• We implemented a log barrier that heavily penalized negative values of ∂f

∂e . This was done
to avoid sign ﬂips of these terms that would violate the invertability assumption. Basically 
together with our earlier regularization of the logarithm  we replaced the logarithms log |x| in

5This is related in spirit to the standard initialization of GPLVM models by PCA.

6

the last term in (9) by:

log(cid:112)(x − )2 +  + A(cid:0) log(cid:112)(x − )2 +  − log

(cid:1)1x≤

√

with  (cid:28) 1. We used  = 10−3 and A = 102.

The resulting optimization problem can be solved using standard numerical optimization methods
(we used LBFGS). The source code of our implementation is available as supplementary material
and can also be downloaded from http://webdav.tuebingen.mpg.de/causality/.

3 Experiments

To evaluate the ability of our method to identify causal directions  we have tested our approach
on simulated and real-world data. To identify the most probable causal direction  we evaluate the
marginal likelihoods corresponding to both possible causal directions (which are given by combin-
ing the results of equations (6) and (9))  choosing the model that assigns higher probability to the
observed data. We henceforth refer to this approach as GPI-MML. For comparison  we also con-
sidered the marginal likelihood using a GP covariance function that is constant with respect to e 
i.e.  assuming additive noise. For this special case  the noise values e can be integrated out ana-
lytically  resulting in standard GP regression. We call this approach AN-MML. We also compare
with the method proposed in [1]  which also uses an additive noise GP regression for the conditional
model  but uses a simple Gaussian model for the input distribution p(x). We refer to this approach
as AN-GAUSS.
We complemented the marginal likelihood as selection criterion with another possible criterion for
causal model selection: the independence of the cause and the estimated noise [5]. Using HSIC [17]
as test criterion for independence  this approach can be applied to both the additive noise GP and
the more general latent variable approach. As the marginal likelihood does not provide a signif-
icance level for the inferred causal direction  we used the ratio of the p-values of HSIC for both
causal directions as prediction criterion  preferring the direction with a higher p-value (i.e.  with
less dependence between the estimated noise and the cause). HSIC as selection criterion applied
to the additive or general Gaussian process model will be referred to as AN-HSIC and GPI-HSIC
respectively.
We compared these methods with other related methods: IGCI [13]  a method that is also based
on assumption (C)  although designed for the noise-free case; LINGAM [2]  which assumes a linear
causal mechanism; and PNL  the Post-NonLinear model [6]. We evaluated all methods in the “forced
decision” scenario  i.e.  the only two possible decisions that a method could take were X → Y and
Y → X (so decisions like “both models ﬁt the data” or ”neither model ﬁts the data” were not
possible).

Simulated data Inspired by the experimental setup in [5]  we generated simulated datasets from
the model Y = (X+bX 3)eαE +(1−α)E. Here  the random variables X and E where sampled from
a Gaussian distribution with their absolute values raised to the power q  while keeping the original
sign. The parameter α controls the type of the observation noise  interpolating between purely
additive noise (α = 0) and purely multiplicative noise (α = 1). The coefﬁcient b determines the non-
linearity of the true causal model  with b = 0 corresponding to the linear case. Finally  the parameter
q controls the non-Gaussianity of the input and noise distributions: q = 1 gives a Gaussian  while
q > 1 and q < 1 produces super-Gaussian and sub-Gaussian distributions respectively.
For alternative parameter settings α  b and q  we generated D = 40 independent datasets. Each
dataset consisted of N = 500 samples from the corresponding generative model. Figure 2 shows
the accuracy of the considered methods evaluated on these simulated datasets. Encouragingly  GPI
appears to be robust with respect to the type of noise  outperforming additive noise models in the
full range between additive and multiplicative noise (Figure 2a). Note that the additive noise models
actually yield the wrong decision for high values of α  whereas the GPI methods stay well above
chance level. Figure 2b shows accuracies for a linear model and a non-Gaussian noise and input
distribution. Figure 2c shows accuracies for a non-linear model with Gaussian additive noise. We
observe that GPI-MML performs well in each scenario. Further  we observe that AN-GAUSS  the
method proposed in [1]  only performs well for Gaussian input distributions and additive noise.

7

(a) From additive to multiplicative noise

(b) Linear function  non-Gaussian additive
noise

(c) Non-linear function  Gaussian additive
noise

(d) Legend

Figure 2: Accuracy of recovering the true causal direction in simulated datasets. (a) From additive
(α = 0) to multiplicative noise (α = 1)  for q = 1 and b = 1; (b) from sub-Gaussian noise (q < 1) 
Gaussian noise (q = 1) to super-Gaussian noise (q > 1)  for a linear function (b = 0) with additive
noise (α = 0); (c) from non-linear (b < 0) to linear (b = 0) to non-linear (b > 1)  with additive
Gaussian noise (q = 1 α = 0).

Table 1: Accuracy (in percent) of recovering the true causal direction in 68 real world datasets.

AN-MML AN-HSIC AN-GAUSS GPI-MML GPI-HSIC
62 ± 4
68 ± 1

45 ± 3

68 ± 3

72 ± 2

IGCI
76 ± 1

LINGAM
62 ± 3

PNL
67 ± 4

Results on cause-effect pairs Next  we applied the same methods and selection criteria to real-
world cause-effect pairs where the true causal direction is known. The data was obtained from
http://webdav.tuebingen.mpg.de/cause-effect/. We considered a total of 68
pairs in this dataset collected from a variety of domains. To reduce computation time  we subsam-
pled the data  using a total of at most N = 500 samples for each cause-effect pair. Table 1 shows
the prediction accuracy for the same approaches as in the simulation study  reporting averages and
standard deviations estimated from 3 repetitions of the experiments with different subsamples.

4 Conclusions and discussion

We proposed the ﬁrst method (to the best of our knowledge) for addressing the challenging task of
distinguishing between cause and effect without an a priori restriction to a certain class of mod-
els. The method compares marginal likelihoods that penalize complex input distributions and causal
mechanisms. Moreover  our framework generalizes a number of existing approaches that assume a
limited class of possible causal mechanisms functions. A more extensive evaluation of the perfor-
mance of our method has to be performed in future. Nevertheless  the encouraging results that we
have obtained thus far conﬁrm the hypothesis that asymmetries of the joint distribution of cause and
effect provide useful hints on the causal direction.

Acknowledgments

We thank Stefan Harmeling and Hannes Nickisch for fruitful discussions. We also like to thank the
authors of the GPML toolbox [18]  which was very useful during the development of our software.
OS was supported by a fellowship from the Volkswagen Foundation.

8

00.10.20.30.40.50.60.70.80.9100.10.20.30.40.50.60.70.80.91Accuracyα0.20.40.60.811.21.41.61.800.10.20.30.40.50.60.70.80.91Accuracyq−1−0.8−0.6−0.4−0.200.20.40.60.8100.10.20.30.40.50.60.70.80.91Accuracyb AN−MMLAN−HSICAN−GAUSSGPI−MMLGPI−HSICIGCIReferences

[1] N. Friedman and I. Nachman. Gaussian process networks. In Proc. of the 16th Annual Conference on

Uncertainty in Artiﬁcial Intelligence  pages 211–219  2000.

[2] S. Shimizu  P. O. Hoyer  A. Hyv¨arinen  and A. J. Kerminen. A linear non-Gaussian acyclic model for

causal discovery. Journal of Machine Learning Research  7:2003–2030  2006.

[3] X. Sun  D. Janzing  and B. Sch¨olkopf. Causal inference by choosing graphs with most plausible Markov

kernels. In Proceeding of the 9th Int. Symp. Art. Int. and Math.  Fort Lauderdale  Florida  2006.

[4] X. Sun  D. Janzing  and B. Sch¨olkopf. Distinguishing between cause and effect via kernel-based com-

plexity measures for conditional probability densities. Neurocomputing  pages 1248–1256  2008.

[5] P. O. Hoyer  D. Janzing  J. M. Mooij  J. Peters  and B. Sch¨olkopf. Nonlinear causal discovery with
In D. Koller  D. Schuurmans  Y. Bengio  and L. Bottou  editors  Advances in

additive noise models.
Neural Information Processing Systems 21 (NIPS*2008)  pages 689–696  2009.

[6] K. Zhang and A. Hyv¨arinen. On the identiﬁability of the post-nonlinear causal model. In Proceedings of

the 25th Conference on Uncertainty in Artiﬁcial Intelligence  Montreal  Canada  2009.

[7] D. Janzing  P. Hoyer  and B. Sch¨olkopf. Telling cause from effect based on high-dimensional observations.
In Proceedings of the International Conference on Machine Learning (ICML 2010)  pages 479–486  2010.
[8] J. M. Mooij and D. Janzing. Distinguishing between cause and effect. In Journal of Machine Learning

Research Workshop and Conference Proceedings  volume 6  pages 147–156  2010.

[9] P. Spirtes  C. Glymour  and R. Scheines. Causation  Prediction  and Search. Springer-Verlag  1993. (2nd

ed. MIT Press 2000).

[10] J. Pearl. Causality: Models  Reasoning  and Inference. Cambridge University Press  2000.
[11] J. Lemeire and E. Dirkx.

Causal models as minimal descriptions of multivariate systems.

http://parallel.vub.ac.be/∼jan/  2006.

[12] D. Janzing and B. Sch¨olkopf. Causal inference using the algorithmic Markov condition. IEEE Transac-

tions on Information Theory  56(10):5168–5194  2010.

[13] P. Daniuˇsis  D. Janzing  J. M. Mooij  J. Zscheischler  B. Steudel  K. Zhang  and B. Sch¨olkopf. Inferring
deterministic causal relations. In Proceedings of the 26th Annual Conference on Uncertainty in Artiﬁcial
Intelligence (UAI-10)  2010.

[14] A. Hyv¨arinen and P. Pajunen. Nonlinear independent component analysis: Existence and uniqueness

results. Neural Networks  12(3):429–439  1999.

[15] M. A. T. Figueiredo and A. K. Jain. Unsupervised learning of ﬁnite mixture models. IEEE Transactions

on Pattern Analysis and Machine Intelligence  24(3):381–396  March 2002.

[16] N. D. Lawrence. Gaussian process latent variable models for visualisation of high dimensional data. In
Advances in Neural Information Processing Systems 16: Proceedings of the 2003 Conference  page 329.
The MIT Press  2004.

[17] A. Gretton  R. Herbrich  A. Smola  O. Bousquet  and B. Sch¨olkopf. Kernel methods for measuring

independence. Journal of Machine Learning Research  6:2075–2129  2005.

[18] C. E. Rasmussen and H. Nickisch. Gaussian Processes for Machine Learning (GPML) Toolbox. Journal

of Machine Learning Research  accepted  2010.

9

,Abhradeep Guha Thakurta
Adam Smith
Noga Alon
Daniel Reichman
Igor Shinkar
Tal Wagner
Jonathan Cohen
Tom Griffiths
Biswadip dey
Kayhan Ozcimder