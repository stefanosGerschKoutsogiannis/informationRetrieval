2012,A Better Way to Pretrain Deep Boltzmann Machines,We describe how the pre-training algorithm for Deep Boltzmann Machines (DBMs) is related to the pre-training algorithm for Deep Belief Networks and we show that under certain conditions  the pre-training procedure improves the variational lower bound of a two-hidden-layer DBM. Based on this analysis  we develop a different method of pre-training DBMs that distributes the modelling work more evenly over the hidden layers. Our results on the MNIST and NORB datasets demonstrate that the new pre-training algorithm allows us to learn better generative models.,A Better Way to Pretrain Deep Boltzmann Machines

Ruslan Salakhutdinov

Geoffrey Hinton

Department of Statistics and Computer Science

Department of Computer Science

University of Toronto

rsalakhu@cs.toronto.edu

University of Toronto

hinton@cs.toronto.edu

Abstract

We describe how the pretraining algorithm for Deep Boltzmann Machines
(DBMs) is related to the pretraining algorithm for Deep Belief Networks and
we show that under certain conditions  the pretraining procedure improves the
variational lower bound of a two-hidden-layer DBM. Based on this analysis  we
develop a different method of pretraining DBMs that distributes the modelling
work more evenly over the hidden layers. Our results on the MNIST and NORB
datasets demonstrate that the new pretraining algorithm allows us to learn better
generative models.

1

Introduction

A Deep Boltzmann Machine (DBM) is a type of binary pairwise Markov Random Field with mul-
tiple layers of hidden random variables. Maximum likelihood learning in DBMs  and other related
models  is very difﬁcult because of the hard inference problem induced by the partition function
[3  1  12  6]. Multiple layers of hidden units make learning in DBM’s far more difﬁcult [13]. Learn-
ing meaningful DBM models  particularly when modelling high-dimensional data  relies on the
heuristic greedy pretraining procedure introduced by [7]  which is based on learning a stack of mod-
iﬁed Restricted Boltzmann Machines (RBMs). Unfortunately  unlike the pretraining algorithm for
Deep Belief Networks (DBNs)  the existing procedure lacks a proof that adding additional layers
improves the variational bound on the log-probability that the model assigns to the training data.
In this paper  we ﬁrst show that under certain conditions  the pretraining algorithm improves a
variational lower bound of a two-layer DBM. This result gives a much deeper understanding of
the relationship between the pretraining algorithms for Deep Boltzmann Machines and Deep Belief
Networks. Using this understanding  we introduce a new pretraining procedure for DBMs and show
that it allows us to learn better generative models of handwritten digits and 3D objects.

2 Deep Boltzmann Machines (DBMs)

A Deep Boltzmann Machine is a network of symmetrically coupled stochastic binary units. It con-
tains a set of visible units v ∈ {0  1}D  and a series of layers of hidden units h(1) ∈ {0  1}F1 
h(2) ∈ {0  1}F2 ...  h(L) ∈ {0  1}FL. There are connections only between units in adjacent layers.
Consider a DBM with three hidden layers  as shown in Fig. 1  left panel. The probability that the
DBM assigns to a visible vector v is:

(cid:88)

(cid:18)(cid:88)

P (v; θ) =

1
Z(θ)

(cid:88)

(cid:88)

(cid:19)

 

exp

W (1)

ij vih(1)

j +

W (2)

jl h(1)

j h(2)

l +

W (3)

lm h(2)

l h(3)

m

(1)

h

ij

jl

1

lm

Deep Belief Network

Deep Boltzmann Machine

Pretraining

’

Figure 1: Left: Deep Belief Network (DBN) and Deep Boltzmann Machine (DBM). The top two layers of a
DBN form an undirected graph and the remaining layers form a belief net with directed  top-down connections.
For a DBM  all the connections are undirected. Right Pretraining a DBM with three hidden layers consists of
learning a stack of RBMs that are then composed to create a DBM. The ﬁrst and last RBMs in the stack need
to be modiﬁed by using asymmetric weights.

where h = {h(1)  h(2)  h(3)} are the set of hidden units  and θ = {W(1)  W(2)  W(3)} are
the model parameters  representing visible-to-hidden and hidden-to-hidden symmetric interaction
terms1. Setting W(2)=0 and W(3)=0 recovers the Restricted Boltzmann Machine (RBM) model.
Approximate Learning: Exact maximum likelihood learning in this model is intractable  but efﬁ-
cient approximate learning of DBMs can be carried out by using a mean-ﬁeld inference to estimate
data-dependent expectations  and an MCMC based stochastic approximation procedure to approx-
imate the model’s expected sufﬁcient statistics [7]. In particular  consider approximating the true
posterior P (h|v; θ) with a fully factorized approximating distribution over the three sets of hidden
k |v)  where µ = {µ(1)  µ(2)  µ(3)}
|v)q(h(3)
are the mean-ﬁeld parameters with q(h(l)
for l = 1  2  3. In this case  we can write
down the variational lower bound on the log-probability of the data  which takes a particularly sim-
ple form:

units: Q(h|v; µ) =(cid:81)F1

|v)q(h(2)
i = 1) = µ(l)

(cid:81)F3

(cid:81)F2

k=1 q(h(1)

j

log P (v; θ) ≥ v(cid:62)W(1)µ(1) + µ(1)(cid:62)

W(3)µ(3) − log Z(θ) + H(Q)  (2)
where H(·) is the entropy functional. Learning proceeds by ﬁnding the value of µ that maximizes
this lower bound for the current value of model parameters θ  which results in a set of the mean-ﬁeld
ﬁxed-point equations. Given the variational parameters µ  the model parameters θ are then updated
to maximize the variational bound using stochastic approximation (for details see [7  11  14  15]).

W(2)µ(2) + µ(2)(cid:62)

j=1

l=1

l

i

3 Pretraining Deep Boltzmann Machines

The above learning procedure works quite poorly when applied to DBMs that start with randomly
initialized weights. Hidden units in higher layers are very under-constrained so there is no consistent
learning signal for their weights. To alleviate this problem  [7] introduced a layer-wise pretraining
algorithm based on learning a stack of “modiﬁed” Restricted Boltzmann Machines (RBMs).
The idea behind the pretraining algorithm is straightforward. When learning parameters of the ﬁrst
layer “RBM”  the bottom-up weights are constrained to be twice the top-down weights (see Fig. 1 
right panel). Intuitively  using twice the weights when inferring the states of the hidden units h(1)
compensates for the initial lack of top-down feedback. Conversely  when pretraining the last “RBM”
in the stack  the top-down weights are constrained to be twice the bottom-up weights. For all the
intermediate RBMs the weights are halved in both directions when composing them to form a DBM 
as shown in Fig. 1  right panel.
This heuristic pretraining algorithm works surprisingly well in practice. However  it is solely mo-
tivated by the need to end up with a model that has symmetric weights  and does not provide any

1We omit the bias terms for clarity of presentation.

2

h(3)h(2)h(1)vW(3)W(2)W(1)h(3)h(2)h(1)vW(3)W(2)W(1)“RBM”RBM“RBM”v2W(1)W(1)h(1)2W(2)2W(2)W(3)2W(3)h(1)h(2)h(2)h(3)W(1)W(2)W(3)useful insights into what is happening during the pretraining stage. Furthermore  unlike the pretrain-
ing algorithm for Deep Belief Networks (DBNs)  it lacks a proof that each time a layer is added to
the DBM  the variational bound improves.

3.1 Pretraining Algorithm for Deep Belief Networks

We ﬁrst brieﬂy review the pretraining algorithm for Deep Belief Networks [2]  which will form the
basis for developing a new pretraining algorithm for Deep Boltzmann Machines.
Consider pretraining a two-layer DBN using a stack of RBMs. After learning the ﬁrst RBM in the
h(1) p(v|h(1); W(1))p(h(1); W(1)).
The second RBM in the stack attempts to replace the prior p(h(1); W(1)) by a better model

stack  we can write the generative model as: p(v; W(1)) =(cid:80)
p(h(1); W(2)) =(cid:80)
log P (vn) ≥(cid:88)
N(cid:88)

More formally  for any approximating distribution Q(h(1)|v)  the DBN’s log-likelihood has the
following variational lower bound on the log probability of the training data {v1  ...  vN}:

h(2) p(h(1)  h(2); W(2))  thus improving the ﬁt to the training data.

Q(h(1)|vn)||P (h(1); W(1))

log P (vn|h(1); W(1))

(cid:105) −(cid:88)

(cid:16)

(cid:104)

KL

EQ(h(1)|vn)

(cid:17)

n=1

n

n

We set Q(h(1)|vn; W(1)) = P (h(1)|vn; W(1))  which is the true factorial posterior of the ﬁrst layer
RBM. Initially  when W(2) = W(1)(cid:62)  Q(h(1)|vn) deﬁnes the DBN’s true posterior over h(1)  and
the bound is tight. Maximizing the bound with respect to W(2) only affects the last KL term in the
above equation  and amounts to maximizing:

Q(h(1)|vn; W(1))P (h(1); W(2)).

(3)

N(cid:88)

(cid:88)

n=1

h(1)

1
N

.

.

(5)

(cid:17)

cases: 1/N(cid:80)

This is equivalent to training the second layer RBM with vectors drawn from Q(h(1)|v; W(1)) as
data. Hence  the second RBM in the stack learns a better model of the mixture over all N training
n Q(h(1)|vn; W(1))  called the “aggregated posterior”. This scheme can be extended

to training higher-layer RBMs.
Observe that during the pretraining stage the whole prior of the lower-layer RBM is replaced by the
next RBM in the stack. This leads to the hybrid Deep Belief Network model  with the top two layers
forming a Restricted Boltzmann Machine  and the lower layers forming a directed sigmoid belief
network (see Fig. 1  left panel).

3.2 A Variational Bound for Pretraining a Two-layer Deep Boltzmann Machine
Consider a simple two-layer DBM with tied weights W(2) = W(1)(cid:62)  as shown in Fig. 2a:

P (v; W(1)) =

1

Z(W(1))

exp

v(cid:62)W(1)h(1) + h(1)(cid:62)W(1)(cid:62)h(2)

.

(4)

Similar to DBNs  for any approximate posterior Q(h(1)|v)  we can write a variational lower bound
on the log probability that this DBM assigns to the training data:

(cid:18)

(cid:88)

h(1) h(2)

N(cid:88)

log P (vn) ≥(cid:88)

(cid:104)

(cid:105) −(cid:88)

(cid:16)

EQ(h(1)|vn)

log P (vn|h(1); W(1))

KL

Q(h(1)|vn)||P (h(1); W(1))

n=1

n

n

(cid:19)

The key insight is to note that the model’s marginal distribution over h(1) is the product of two
identical distributions  one deﬁned by an RBM composed of h(1) and v  and the other deﬁned by an
identical RBM composed of h(1) and h(2) [8]:

(cid:18)(cid:88)
(cid:124)

v

ev(cid:62)W(1)h(1)(cid:19)
(cid:123)(cid:122)
(cid:125)

RBM with h(1) and v

(cid:18)(cid:88)
(cid:124)

h(2)

eh(2)(cid:62)W(1)h(1)(cid:19)
(cid:123)(cid:122)
(cid:125)

RBM with h(1) and h(2)

.

(6)

P (h(1); W(1)) =

1

Z(W(1))

3

a)

b)

c)

Figure 2: Left: Pretraining a Deep Boltzmann Machine with two hidden layers. a) The DBM with tied
weights. b) The second RBM with two sets of replicated hidden units  which will replace half of the 1stRBM’s
prior. c) The resulting DBM with modiﬁed second hidden layer. Right: The DBM with tied weights is trained
to model the data using one-step contrastive divergence.

The idea is to keep one of these two RBMs and replace the other by the square root of a better
(cid:80)
prior P (h(1); W(2)). In particular  another RBM with two sets of replicated hidden units and tied
h(2a) h(2b) P (h(1)  h(2a)  h(2b); W(2)) is trained to be a better model
n Q(h(1)|vn; W(1)) of the ﬁrst model (see Fig. 2b).
of the aggregated variational posterior 1
N
By initializing W(2) = W(1)(cid:62)  the second-layer RBM has exactly the same prior over h(1) as the
original DBM. If the RBM is trained by maximizing the log likelihood objective:

weights P (h(1); W(2)) = (cid:80)
(cid:88)

(cid:88)

Q(h(1)|vn) log P (h(1); W(2)) 

then we obtain:(cid:88)

KL(Q(h(1)|vn)||P (h(1); W(2))) ≤(cid:88)

h(1)

n

n

n

KL(Q(h(1)|vn)||P (h(1); W(1))).

Similar to Eq. 6  the distribution over h(1) deﬁned by the second-layer RBM is also the product of
two identical distributions. Once the two RBMs are composed to form a two-layer DBM model (see
Fig. 2c)  the marginal distribution over h(1) is the geometric mean of the two probability distribu-
tions: P (h(1); W(1))  P (h(1); W(2)) deﬁned by the ﬁrst and second-layer RBMs:

(7)

(8)

(9)

P (h(1); W(1)  W(2)) =

1

Z(W(1)  W(2))

(cid:18)(cid:88)

ev(cid:62)W(1)h(1)(cid:19)(cid:18)(cid:88)
(cid:17) ≤(cid:88)

(cid:16)

KL

h(2)

v

eh(1)(cid:62)W(2)h(2)(cid:19)
(cid:17)

.

(cid:88)

(cid:16)

Based on Eqs. 8  9  it is easy to show that the variational lower bound of Eq. 5 improves because
replacing half of the prior by a better model reduces the KL divergence from the variational posterior:

KL

Q(h(1)|vn)||P (h(1); W(1)  W(2))

Q(h(1)|vn)||P (h(1); W(1))

.

(10)

n

n

Due to the convexity of asymmetric divergence  this is guaranteed to improve the variational bound
of the training data by at least half as much as fully replacing the original prior.
This result highlights a major difference between DBNs and DBMs. The procedure for adding an
extra layer to a DBN replaces the full prior over the previous top layer  whereas the procedure for
adding an extra layer to a DBM only replaces half of the prior. So in a DBM  the weights of the
bottom level RBM perform much more of the work than in a DBN  where the weights are only used
to deﬁne the last stage of the generative process P (v|h(1); W(1)).
This result also suggests that adding layers to a DBM will give diminishing improvements in the
variational bound  compared to adding layers to a DBN. This may explain why DBMs with three
hidden layers typically perform worse than the DBMs with two hidden layers [7  8]. On the other
hand  the disadvantage of the pretraining procedure for Deep Belief Networks is that the top-layer
RBM is forced to do most of the modelling work. This may also explain the need to use a large
number of hidden units in the top-layer RBM [2].
There is  however  a way to design a new pretraining algorithm that would spread the modelling work
more equally across all layers  hence bypassing shortcomings of the existing pretraining algorithms
for DBNs and DBMs.

4

vh(2)h(1)W(1)W(1)W(2)W(2)h(1)h(2a)h(2b)vh(1)h(2)W(1)W(2)vh(2)=vh(1)W(1)W(1)Replacing 2/3 of the Prior

Practical Implementation

a)

b)

c)

Figure 3: Left: Pretraining a Deep Boltzmann Machine with two hidden layers. a) The DBM with tied
weights. b) The second layer RBM is trained to model 2/3 of the 1st RBM’s prior. c) The resulting DBM with
modiﬁed second hidden layer. Right: The corresponding practical implementation of the pretraining algorithm
that uses asymmetric weights.

3.3 Controlling the Amount of Modelling Work done by Each Layer
Consider a slightly modiﬁed two-layer DBM with two groups of replicated 2nd-layer units  h(2a)
and h(2b)  and tied weights (see Fig. 3a). The model’s marginal distribution over h(1) is the product
of three identical RBM distributions  deﬁned by h(1) and v  h(1) and h(2a)  and h(1) and h(2b):

ev(cid:62)W(1)h(1)(cid:19)(cid:18)(cid:88)

eh(2a)(cid:62)W(1)h(1)(cid:19)(cid:18)(cid:88)

eh(2b)(cid:62)W(1)h(1)(cid:19)

.

(cid:18)(cid:88)

P (h(1); W(1)) =

1

Z(W(1))

v

h(2a)

h(2b)

During the pretraining stage  we keep one of these RBMs and replace the other two by a better prior
P (h(1); W(2)). To do so  similar to Sec. 3.2  we train another RBM  but with three sets of hidden
units and tied weights (see Fig. 3b). When we combine the two RBMs into a DBM  the marginal
distribution over h(1) is the geometric mean of three probability distributions: one deﬁned by the
ﬁrst-layer RBM  and the remaining two deﬁned by the second-layer RBMs:

P (h(1); W(1)  W(2)) =

=

1

Z(W(1)  W(2))

Z(W(1)  W(2))

1

(cid:18)(cid:88)

P (h(1); W(1))P (h(1); W(2))P (h(1); W(2))

ev(cid:62)W(1)h(1)(cid:19)(cid:18)(cid:88)

eh(2a)(cid:62)W(2)h(1)(cid:19)(cid:18)(cid:88)

eh(2b)(cid:62)W(2)h(1)(cid:19)

.

v

h(2a)

h(2b)

In this DBM  2/3 of the ﬁrst RBM’s prior over the ﬁrst hidden layer has been replaced by the prior de-
ﬁned by the second-layer RBM. The variational bound on the training data is guaranteed to improve
by at least 2/3 as much as fully replacing the original prior. Hence in this slightly modiﬁed DBM
model  the second layer performs 2/3 of the modelling work compared to the ﬁrst layer. Clearly  con-
trolling the number of replicated hidden groups allows us to easily control the amount of modelling
work left to the higher layers in the stack.

3.4 Practical Implementation

So far  we have made the assumption that we start with a two-layer DBM with tied weights. We now
specify how one would train this initial set of tied weights W(1).
Let us consider the original two-layer DBM in Fig. 2a with tied weights. If we knew the initial
state vector h(2)  we could train this DBM using one-step contrastive divergence (CD) with mean
ﬁeld reconstructions of both the visible states v and the top-layer states h(2)  as shown in Fig. 2 
right panel. Instead  we simply set the initial state vector h(2) to be equal to the data  v. Using
mean-ﬁeld reconstructions for v and h(2)  one-step CD is exactly equivalent to training a modiﬁed
“RBM” with only one hidden layer but with bottom-up weights that are twice the top-down weights 
as deﬁned in the original pretraining algorithm (see Fig. 1  right panel). This way of training the
simple DBM with tied weights is unlikely to maximize the likelihood objective  but in practice it
produces surprisingly good models that reconstruct the training data well.
When learning the second RBM in the stack  instead of maintaining a set of replicated hidden groups 
it will often be convenient to approximate CD learning by training a modiﬁed RBM with one hidden
layer but with asymmetric bottom-up and top-down weights.

5

vh(2)ah(2)bh(1)W(1)W(1)W(1)W(2)W(2)W(2)h(1)h(2)ah(2)bh(2)cvh(2)ah(2)bh(1)W(2)W(2)W(1)vh(1)3W(1)W(1)h(1)h(2)2W(2)3W(2)vh(2)h(1)2W(2)W(1)1

1 + exp(−(cid:80)
1 + exp(−(cid:80)

For example  consider pretraining a two-layer DBM  in which we would like to split the modelling
work between the 1st and 2nd-layer RBMs as 1/3 and 2/3. In this case  we train the ﬁrst layer RBM
using one-step CD  but with the bottom-up weights constrained to be three times the top-down
weights (see Fig. 3  right panel). The conditional distributions needed for CD learning take form:

P (vi = 1|h(1)) =

 

i 3W (1)

ij vi)

1 + exp(−(cid:80)

1

.

j W (1)

ij h(1)
j )

P (h(1)

j = 1|v) =

P (h(2)

  P (h(1)

1
j 2W (2)

l = 1|h(1)) =

Conversely  for the second modiﬁed RBM in the stack  the top-down weights are constrained to be
3/2 times the bottom-up weights. The conditional distributions take form:
j = 1|h(2)) =

jl h(2)
)
Note that this second-layer modiﬁed RBM simply approximates the proper RBM with three sets of
replicated h(2) groups. In practice  this simple approximation works well compared to training a
proper RBM  and is much easier to implement. When combining the RBMs into a two-layer DBM 
we end up with W(1) and 2W(2) in the ﬁrst and second layers  each performing 1/3 and 2/3 of the
modelling work respectively:
1
Z(θ)

v(cid:62)W(1)h(1) + h(1)(cid:62)2W(2)h(2)

1 + exp(−(cid:80)

1
l 3W (2)

(cid:88)

jl h(1)
j )

(cid:19)

.

P (v; θ) =

(cid:18)

(11)

.

l

exp

h(1) h(2)

Parameters of the entire model can be generatively ﬁne-tuned using the combination of the mean-
ﬁeld algorithm and the stochastic approximation algorithm described in Sec. 2

4 Pretraining a Three Layer Deep Boltzmann Machine

In the previous section  we showed that provided we start with a two-layer DBM with tied weights 
we can train the second-layer RBM in a way that is guaranteed to improve the variational bound.
For the DBM with more than two layers  we have not been able to develop a pretraining algorithm
that is guaranteed to improve a variational bound. However  results of Sec. 3 suggest that using
simple modiﬁcations when pretraining a stack of RBMs would allow us to approximately control
the amount of modelling work done by each layer.

Pretraining a 3-layer DBM

Consider learning a 3-layer DBM  in which
each layer is forced to perform approxi-
mately 1/3 of the modelling work. This
can easily be accomplished by learning a
stack of three modiﬁed RBMs. Similar
to the two-layer model  we train the ﬁrst
layer RBM using one-step CD  but with the
bottom-up weights constrained to be three
times the top-down weights (see Fig. 4).
Two-thirds of this RBM’s prior will be
modelled by the 2ndand 3rd-layer RBMs.
For the second modiﬁed RBM in the stack 
we use 4W(2) bottom-up and 3W(2) top-
down. Note that we are using 4W(2)
bottom-up  as we are expecting to replace
half of the second RBM prior by a third RBM  hence splitting the remaining 2/3 of the work equally
between the top two layers. If we were to pretrain only a two-layer DBM  we would use 2W(2)
bottom-up and 3W(2) top-down  as discussed in Sec. 3.2.
For the last RBM in the stack  we use 2W(3) bottom-up and 4W(2) top-down. When combining the
three RBMs into a three-layer DBM  we end up with symmetric weights W(1)  2W(2)  and 2W(3)
in the ﬁrst  second  and third layers  with each layer performing 1/3 of the modelling work:

Figure 4: Layer-wise pretraining of a 3-layer
Deep Boltzmann Machine.

P (v; θ) =

1
Z(θ)

exp

v(cid:62)W(1)h(1) + h(1)(cid:62)2W(2)h(2) + h(2)(cid:62)2W(3)h(3)

.

(12)

(cid:88)

(cid:18)

(cid:19)

h

6

vh(1)3W(1)W(1)h(1)h(2)4W(2)3W(2)h(2)h(3)2W(3)4W(3)2W(3)h(3)vh(2)h(1)2W(2)W(1)Algorithm 1 Greedy Pretraining Algorithm for a 3-layer Deep Boltzmann Machine
1: Train the 1st layer “RBM” using one-step CD learning with mean ﬁeld reconstructions of the visible vec-
2: Freeze 3W(1) that deﬁnes the 1st layer of features  and use samples h(1) from P (h(1)|v; 3W(1)) as the

tors. Constrain the bottom-up weights  3W(1)  to be three times the top-down weights  W(1).

data for training the second RBM.

3: Train the 2nd layer “RBM” using one-step CD learning with mean ﬁeld reconstructions of the visible
4: Freeze 4W(2) that deﬁnes the 2nd layer of features and use the samples h(3) from P (h(2)|h(1); 4W(2))

vectors. Set the bottom-up weights to 4W(1)  and the top-down weights to 3W(1).

as the data for training the next RBM.

5: Train the 3rd-layer “RBM” using one-step CD learning with mean ﬁeld reconstructions of its visible vec-
6: Use the weights {W(1)  2W(2)  2W(3)} to compose a three-layer Deep Boltzmann Machine.

tors. During the learning  set the bottom-up weights to 2W(3)  and the top-down weights to 4W(3).

The new pretraining procedure for a 3-layer DBM is shown in Alg. 1. Note that compared to the
original algorithm  it requires almost no extra work and can be easily integrated into existing code.
Extensions to training DBMs with more layers is trivial. As we show in our experimental results 
this pretraining can improve the generative performance of Deep Boltzmann Machines.

5 Experimental Results

In our experiments we used the MNIST and NORB datasets. During greedy pretraining  each layer
was trained for 100 epochs using one-step contrastive divergence. Generative ﬁne-tuning of the
full DBM model  using mean-ﬁeld together with stochastic approximation  required 300 epochs.
In order to estimate the variational lower-bounds achieved by different pretraining algorithms  we
need to estimate the global normalization constant. Recently  [10] demonstrated that Annealed
Importance Sampling (AIS) can be used to efﬁciently estimate the partition function of an RBM.
We adopt AIS in our experiments as well. Together with variational inference this will allow us to
obtain good estimates of the lower bound on the log-probability of the training and test data.

5.1 MNIST
The MNIST digit dataset contains 60 000 training and 10 000 test images of ten handwritten digits
(0 to 9)  with 28×28 pixels. In our ﬁrst experiment  we considered a standard two-layer DBM with
500 and 1000 hidden units2  and used two different algorithms for pretraining it. The ﬁrst pretraining
algorithm  which we call DBM-1/2-1/2  is the original algorithm for pretraining DBMs  as introduced
by [7] (see Fig. 1). Here  the modelling work between the 1stand 2nd-layer RBMs is split equally.
The second algorithm  DBM-1/3-2/3  uses a modiﬁed pretraining procedure of Sec. 3.4  so that the
second RBM in the stack ends up doing 2/3 of the modelling work compared to the 1st-layer RBM.
Results are shown in Table 1. Prior to the global generative ﬁne-tuning  the estimate of the lower
bound on the average test log-probability for DBM-1/3-2/3 was −108.65 per test case  compared to
−114.32 achieved by the standard pretraining algorithm DBM-1/2-1/2. The large difference of about
7 nats shows that leaving more of the modelling work to the second layer  which has a larger number
of hidden units  substantially improves the variational bound.
After the global generative ﬁne-tuning  DBM-1/3-2/3 achieves a lower bound of −83.43  which is
better compared to −84.62  achieved by DBM-1/2-1/2. This is also lower compared to the lower
bound of −85.97  achieved by a carefully trained two-hidden-layer Deep Belief Network [10].
In our second experiment  we pretrained a 3-layer Deep Boltzmann Machine with 500  500  and
1000 hidden units. The existing pretraining algorithm  DBM-1/2-1/4-1/4  approximately splits the
modelling between three RBMs in the stack as 1/2  1/4  1/4  so the weights in the 1st-layer RBM
perform half of the work compared to the higher-level RBMs. On the other hand  the new pretraining
procedure (see Alg. 1)  which we call DBM-1/3-1/3-1/3  splits the modelling work equally across all
three layers.

2These architectures have been considered before in [7  9]  which allows us to provide a direct comparison.

7

Table 1: MNIST: Estimating the lower bound on the average training and test log-probabilities for two DBMs:
one with two layers (500 and 1000 hidden units)  and the other one with three layers (500  500  and 1000 hidden
units). Results are shown for various pretraining algorithms  followed by generative ﬁne-tuning.

Pretraining

Test

Generative Fine-Tuning
Train
Train
−113.32 −114.32 −83.61
2 layers DBM-1/2-1/2
−107.89 −108.65 −82.83
DBM-1/3-2/3
3 layers DBM-1/2-1/4-1/4 −116.74 −117.38 −84.49
DBM-1/3-1/3-1/3 −107.12 −107.65 −82.34

Test
−84.62
−83.43
−85.10
−83.02

Table 2: NORB: Estimating the lower bound on the average training and test log-probabilities for two DBMs:
one with two layers (1000 and 2000 hidden units)  and the other one with three layers (1000  1000  and 2000
hidden units). Results are shown for various pretraining algorithms  followed by generative ﬁne-tuning.

Pretraining

Generative Fine-Tuning

Train
Train
−640.94 −643.87 −598.13
2 layers DBM-1/2-1/2
−633.21 −636.65 −593.76
DBM-1/3-2/3
3 layers DBM-1/2-1/4-1/4 −641.87 −645.06 −598.98
DBM-1/3-1/3-1/3 −632.75 −635.14 −592.87

Test

Test

−601.76
−597.23
−602.84
−596.11

Table 1 shows that DBM-1/3-1/3-1/3 achieves a lower bound on the average test log-probability of
−107.65  improving upon DBM-1/2-1/4-1/4’s bound of −117.38. The difference of about 10 nats
further demonstrates that during the pretraining stage  it is rather crucial to push more of the mod-
elling work to the higher layers. After generative ﬁne-tuning  the bound on the test log-probabilities
for DBM-1/3-1/3-1/3 was −83.02  so with a new pretraining procedure  the three-hidden-layer DBM
performs slightly better than the two-hidden-layer DBM. With the original pretraining procedure 
the 3-layer DBM achieves a bound of −85.10  which is worse than the bound of 84.62  achieved by
the 2-layer DBM  as reported by [7  9].

5.2 NORB
The NORB dataset [4] contains images of 50 different 3D toy objects with 10 objects in each of
ﬁve generic classes: cars  trucks  planes  animals  and humans. Each object is photographed from
different viewpoints and under various lighting conditions. The training set contains 24 300 stereo
image pairs of 25 objects  5 per class  while the test set contains 24 300 stereo pairs of the remaining 
different 25 objects. From the training data  4 300 were set aside for validation. To deal with raw
pixel data  we followed the approach of [5] by ﬁrst learning a Gaussian-binary RBM with 4000
hidden units  and then treating the the activities of its hidden layer as preprocessed binary data.
Similar to the MNIST experiments  we trained two Deep Boltzmann Machines: one with two layers
(1000 and 2000 hidden units)  and the other one with three layers (1000  1000  and 2000 hidden
units). Table 2 reveals that for both DBMs  the new pretraining achieves much better variational
bounds on the average test log-probability. Even after the global generative ﬁne-tuning  Deep Boltz-
mann Machines  pretrained using a new algorithm  improve upon standard DBMs by at least 5 nats.

6 Conclusion
In this paper we provided a better understanding of how the pretraining algorithms for Deep Belief
Networks and Deep Boltzmann Machines are related  and used this understanding to develop a
different method of pretraining. Unlike many of the existing pretraining algorithms for DBNs and
DBMs  the new procedure can distribute the modelling work more evenly over the hidden layers.
Our results on the MNIST and NORB datasets demonstrate that the new pretraining algorithm allows
us to learn much better generative models.

Acknowledgments
This research was funded by NSERC  Early Researcher Award  and gifts from Microsoft and
Google. G.H. and R.S. are fellows of the Canadian Institute for Advanced Research.

8

References
[1] Y. Bengio. Learning deep architectures for AI. Foundations and Trends in Machine Learning 

2009.

[2] G. E. Hinton  S. Osindero  and Y. W. Teh. A fast learning algorithm for deep belief nets. Neural

Computation  18(7):1527–1554  2006.

[3] H. Larochelle  Y. Bengio  J. Louradour  and P. Lamblin. Exploring strategies for training deep

neural networks. Journal of Machine Learning Research  10:1–40  2009.

[4] Y. LeCun  F. J. Huang  and L. Bottou. Learning methods for generic object recognition with

invariance to pose and lighting. In CVPR (2)  pages 97–104  2004.

[5] V. Nair and G. E. Hinton. Implicit mixtures of restricted Boltzmann machines. In Advances in

Neural Information Processing Systems  volume 21  2009.

[6] M. A. Ranzato. Unsupervised learning of feature hierarchies. In Ph.D. New York University 

2009.

[7] R. R. Salakhutdinov and G. E. Hinton. Deep Boltzmann machines.

In Proceedings of the

International Conference on Artiﬁcial Intelligence and Statistics  volume 12  2009.

[8] R. R. Salakhutdinov and G. E. Hinton. An efﬁcient learning procedure for Deep Boltzmann

Machines. Neural Computation  24:1967 – 2006  2012.

[9] R. R. Salakhutdinov and H. Larochelle. Efﬁcient learning of deep Boltzmann machines. In Pro-
ceedings of the International Conference on Artiﬁcial Intelligence and Statistics  volume 13 
2010.

[10] R. R. Salakhutdinov and I. Murray. On the quantitative analysis of deep belief networks. In
Proceedings of the International Conference on Machine Learning  volume 25  pages 872 –
879  2008.

[11] T. Tieleman. Training restricted Boltzmann machines using approximations to the likelihood

gradient. In ICML. ACM  2008.

[12] M. Welling and G. E. Hinton. A new learning algorithm for mean ﬁeld Boltzmann machines.

Lecture Notes in Computer Science  2415  2002.

[13] M. Welling and C. Sutton. Learning in markov random ﬁelds with contrastive free energies. In

International Workshop on AI and Statistics (AISTATS’2005)  2005.

[14] L. Younes. On the convergence of Markovian stochastic algorithms with rapidly decreasing

ergodicity rates  March 17 2000.

[15] A. L. Yuille. The convergence of contrastive divergences. In Advances in Neural Information

Processing Systems  2004.

9

,Aswin Raghavan
Roni Khardon
Alan Fern
Prasad Tadepalli