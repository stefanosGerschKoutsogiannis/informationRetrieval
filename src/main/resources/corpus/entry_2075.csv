2018,Faster Online Learning of Optimal Threshold for Consistent F-measure Optimization,In this paper  we consider online F-measure optimization (OFO). Unlike traditional performance metrics (e.g.  classification error rate)  F-measure is non-decomposable over training examples and is a non-convex function of model parameters  making it much more difficult to be optimized in an online fashion. Most existing results of OFO usually suffer from high memory/computational costs and/or lack  statistical consistency  guarantee for optimizing F-measure at the population level. To advance OFO  we propose an efficient online algorithm based on simultaneously learning a posterior probability of class and learning an optimal threshold by minimizing  a stochastic strongly convex function with unknown strong convexity parameter. A key component of the proposed method is  a novel stochastic algorithm with low memory and computational costs  which can enjoy a  convergence rate of $\widetilde O(1/\sqrt{n})$ for learning the optimal threshold under a mild condition on the convergence of the posterior probability   where $n$ is the number of processed examples. It is provably  faster than its predecessor based on a heuristic for updating the threshold.   The experiments verify  the efficiency of the proposed algorithm in comparison with state-of-the-art OFO algorithms.,Faster Online Learning of Optimal Threshold for

Consistent F-measure Optimization

Mingrui Liu∗†  Xiaoxuan Zhang∗†  Xun Zhou‡  Tianbao Yang†

†Department of Computer Science  The University of Iowa  Iowa City  IA 52242  USA
‡Department of Management Sciences  The University of Iowa  Iowa City  IA 52242  USA

mingrui-liu  tianbao-yang@uiowa.edu

Abstract

In this paper  we consider online F-measure optimization (OFO). Unlike tra-
ditional performance metrics (e.g.  classiﬁcation error rate)  F-measure is non-
decomposable over training examples and is a non-convex function of model
parameters  making it much more difﬁcult to be optimized in an online fashion.
Most existing results of OFO usually suffer from high memory/computational
costs and/or lack statistical consistency guarantee for optimizing F-measure at
the population level. To advance OFO  we propose an efﬁcient online algorithm
based on simultaneously learning a posterior probability of class and learning
an optimal threshold by minimizing a stochastic strongly convex function with
unknown strong convexity parameter. A key component of the proposed method
is a novel stochastic algorithm with low memory and computational costs  which
n) for learning the optimal threshold under
a mild condition on the convergence of the posterior probability  where n is the
number of processed examples. It is provably faster than its predecessor based on a
heuristic for updating the threshold. The experiments verify the efﬁciency of the
proposed algorithm in comparison with state-of-the-art OFO algorithms.

can enjoy a convergence rate of (cid:101)O(1/

√

Introduction

1
A learning algorithm is to optimize a certain performance metric deﬁned over a set or population of
examples. Online learning [18  28  4  10] is a paradigm in which an algorithm alternatively makes
prediction on a received data and then updates the model given the feedback of prediction to optimize
a target performance metric. It has attracted tremendous attention due to its efﬁciency in handling
large-scale and/or streaming data  and has been actively investigated for decades. While many studies
are devoted to learning with traditional performance metrics (e.g.  classiﬁcation error rate)  there
has also been an increasing interest in designing efﬁcient online learning algorithms to maximize F-
measure for tackling large-scale streaming data or by one pass of large-scale batch data [3  9  14  23].
This is because F-measure is more suited for imbalanced classiﬁcation data because it enforces a
better balance between performance on the rare class and the dominating class. Imbalanced data can
be found in many applications  e.g.  medical diagnostics [13]  spam email detection [20]  malicious
URL detection [27]  etc.
Online F-measure optimization is much more challenging than traditional online learning with point-
wise loss functions since F-measure is non-decomposable over training examples and is a non-convex
function of model parameters. Nevertheless  several previous works have made efforts to tackle
this difﬁcult problem [3  9  14  23]  which fall into three categories. The ﬁrst category is based
on minimizing a surrogate loss function or maximizing a surrogate reward function in an online
fashion. This type of approaches usually has large memory costs and/or lacks statistical consistency
for F-measure due to that the consistency/calibration of surrogate loss of F-measure is not clear.

∗equal contribution

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

Table 1: Comparison with Existing Work of Online F-measure Optimization. The comparison is
based on ﬁxing the total number of processed examples to be n  where d is the dimensionality of data 
m > 0 is a parameter of the referred algorithm  and α > 0. Comp. costs is short for computational
costs.

[9]
[14]
[23]
[3]

Target of Convergence Analysis

Empirical Structural Surrogate Loss

Surrogate F-measure

Cost-sensitive loss/F-measure
Optimal Threshold/F-measure
Optimal Threshold/F-measure

Convergence Result

√
O(1/n1/4)
n)
O(1/

√
O(1/

√
n)/O(1/m + 1/
asymptotic/asymptotic
√
n)/asymptotic

(cid:101)O(1/

n) Yes (iff m = nα)

No
No

Yes
Yes

Consistency

Memory Costs Comp. Costs

√

O(

nd)

O(d)
O(md)
O(d)
O(d)

O(nd)
O(nd)
O(mnd)
O(nd)
O(nd)

This work
The second category of approaches leverages the characterization that F-measure optimization is
equivalent to a cost-sensitive loss minimization and uses online learning algorithms for minimizing
a cost-sensitive loss. However  the optimal costs in this characterization depend on the optimal
F-measure  which makes this type of approaches suffer from a large computational cost for tuning or
searching the optimal costs. The third family of methods is based on a result that the optimal classiﬁer
for maximizing the F-measure can be achieved by thresholding the posterior class probability. Then 
the problem reduces to learning the optimal threshold and the posterior probability incrementally.
Online learning of the posterior probability can implemented by minimizing calibrated surrogate loss
functions (e.g.  logistic loss). However  the challenge of this type of approach lies at how to learn the
optimal threshold on-the-ﬂy.
In this paper  we address this challenge (online learning of the optimal threshold) in an elegant
way. In particular  we cast the problem of learning the optimal threshold as stochastic strongly convex

optimization. Nevertheless  the existing online gradient descent method with (cid:101)O(1/n) convergence

for minimizing strongly convex functions is not directly applicable. The reason is that the strong
convexity parameter is unknown and unbiased stochastic gradient is not available. The signiﬁ-
cance of this work is to address these challenges by a new design of online algorithm and novel high
probability analysis of the proposed algorithm. Our main contributions are summarized below:
• We propose a Fast Online F-measure Optimization (FOFO) with a novel component for learning
the optimal threshold for a probabilistic binary classiﬁer. The proposed algorithm has low memory
and computational costs.

n) 2 convergence rate for learning the optimal threshold and the consistency
of F-measure optimization at the population level under a point-wise convergence condition of
learning the posterior probability. It is provably faster than its predecessor [3] that updates the
threshold based on a heuristic.
• We conduct extensive experiments comparing the proposed algorithm with existing algorithms
in the three categories. Experimental results show that FOFO has much better online and testing
performance than other algorithms especially on highly imbalanced datasets.

• We prove an (cid:101)O(1/

√

2 Related Work
This work is motivated by addressing the deﬁciencies of previous algorithms of OFO and is also built
on existing results for F-measure optimization. In this section  we will highlight them. As mentioned
before previous OFO algorithms can be organized into three categories. In review of related work 
we focus on the F-measure optimization part  though some of them also include contributions for
optimizing other non-decomposable metrics (e.g.  AUC  Precision) [9  14  23].
Two representative algorithms in the ﬁrst category are proposed in [9  14]. In particular  Kar et al. [9]
developed an online gradient descent method for minimizing structural surrogate loss  which was
motivated by a batch-learning method for optimizing the structural surrogate loss [7]. The authors
of [9] established a convergence rate for minimizing the empirical structural surrogate loss in the order
√
of O(1/n1/4)  where n is the total number of processed examples. One deﬁciency of their algorithm
is the large-memory costs due to that it needs to maintain O(
n) examples for computing the gradient
of the structural surrogate loss for each update of the model parameters. Narasimhan et al. [14]
addressed the issue of high-memory cost by optimizing a surrogate F-measure that is deﬁned based
on surrogate reward functions for approximating true-positive and true-negative rate. They leveraged

2The (cid:101)O(·) notation hides logarithmic factors. This convergence rate is implied by a convergence rate of
(cid:101)O(1/n) for minimizing the involved strongly convex function.

2

the pseudo-linear property of the (surrogate) F-measure and developed an alternate-maximization
√
algorithms for optimizing the surrogate F-measure  which has a stochastic version called STAMP
with a convergence rate of O(1/
n). However  their stochastic algorithm is not designed for online
learning where online performance is important. In particular  their algorithm alternates between
two stages with one stage updating the models using received examples and another stage updating
the so-called challenge level using received examples. In contrast  our algorithm simultaneously
updating the probabilistic classiﬁer and its threshold for making predications  making it more suitable
for online learning. Another deﬁciency of both works [9  14] is the lack of statistical consistency of
F-measure optimization at the population level.
A related algorithm in the second category of OFO is proposed in [23]  which is based on minimizing
cost-sensitive loss. It is motivated by that F-measure maximization is equivalent to a cost-sensitive
error minimization that consists of a weighted sum of false positive and false negative [16]. Neverthe-
less  the optimal weight is dependent on the optimal F-measure and thus is not available. To tackle
the unknown optimal weight  Yan et al. [23] proposed to learn multiple cost-sensitive classiﬁers
corresponding to multiple settings of the weight. For online prediction  they also maintain and update
selection probabilities of the multiple classiﬁers. At each iteration  the algorithm selects one classiﬁer
for making prediction and updates all classiﬁers upon receiving the label information of received
data. As a result  their algorithm suffers from high memory and computational costs. They proved a
convergence result for F-measure optimization by utilizing the fact that cost-sensitive surrogate loss
is calibrated [19]. Nevertheless  the consistency of F-measure optimization requires the number of
maintained classiﬁers (denoted by m in Table 1) to be very large.
Recently  Busa-Fekete et al. [3] proposed a remarkably simple OFO algorithm  which belongs to
the third category. It is based on a fact that optimal F-measure can be achieved by thresholding the
true posterior probability of positive class [24  15]. Hence  an online algorithm for updating the
model of the posterior probability and updating the threshold is developed in [3]. Their update for the
threshold is based on a heuristic by setting the threshold as half of the F-measure computed on the
historical examples. This is motivated by fact established in [26] that the optimal threshold for the
true posterior probability is half of the optimal F-measure. However  it is generally not true that for
any probabilistic classiﬁer the optimal threshold is half of its F-measure. As a result  they can only
prove asymptotic convergence (with n → ∞) for learning the optimal threshold even using the true
posterior probability at each iteration. In contrast  we overcome this shortcoming by learning the
optimal threshold through solving a strongly convex optimization problem. With careful design and
n) for learning

analysis of the proposed algorithm  we are able to prove a convergence rate of (cid:101)O(1/

the optimal threshold under a mild condition for learning the posterior class probability.
We note that the consistency of F-measure optimization is an important concern for the design and
analysis of OFO algorithm [15]. It requires that given inﬁnite amount of data  the learned classiﬁer
should achieve the best F-measure at the population level. As a summary  we present a quick
comparison between this work and related studies in Table 1 from various perspectives  including
theoretical convergence results  consistency of F-measure optimization  memory and computational
costs  where linear models are assumed for different algorithms in order to compare the memory and
computational costs. Finally  we emphasize that although there are some batch-learning based F-
measure optimization algorithms [15  24]  the comparison in this paper focuses on online algorithms.

√

positive class by η(x) = Pr(y = 1|x)  and thus we have π =(cid:82)

3 Preliminaries and Notations
Let z = (x  y) denote a random data  where x ∈ X represents the feature vector and y ∈ {1  0}
represents the binary class label. Let Z = X × {1  0} denote the domain of the data. We assume z
follows an unknown distribution P  and denote the marginal distribution of the feature x by µ(x). We
denote the probability of positive class by π = Pr(y = 1)  and the true posterior probability of the
x∈X η(x)dµ(x). Since we assume
the received examples follow a distribution  in the sequel we use online gradient descent (OGD) and
stochastic gradient descent (SGD) interchangeably.
Let F = {f : X → {1  0}} be the set of all binary classiﬁers on X . The F-measure (in particular F1
measure) of f at the population level is deﬁned as

F (f ) =

.

(1)

2(cid:82)
X η(x)dµ(x) +(cid:82)

(cid:82)

X η(x)f (x)dµ(x)

X f (x)dµ(x)

3

Denote by F∗ = arg maxf∈F F (f ). Let G = {g : X → [0  1]} denote a set of probabilistic classiﬁer
that assigns to any example x a probability that it belongs to the positive class. It induces a family of
thresholded binary classiﬁers H = {gθ(x) := I[g(x)≥θ]} ⊆ F  where I is an indicator function  and
θ ∈ [0  1] is a threshold.
It was shown that the optimal binary classiﬁer that maximizes the F-measure at the population level
can be achieved by thresholding the true posterior probability η(x)  i.e.  ηθ(x) = I[η(x)≥θ] [24  15].
As a result  we have maxf∈F F (f ) = maxθ∈[0 0.5] F (ηθ). This reduces the problem of F-measure
optimization into two sub-problems: learning the posterior probability η(x) and learning the optimal
threshold. The best threshold θ∗ that maximizes F (ηθ) has a relationship with the optimal F-measure 
i.e.  θ∗ = F∗/2 [26]. It also implies that the best optimal threshold θ∗ ∈ [0  0.5].
Deﬁnition 1. An algorithm is said to be F-measure consistent if the learned classiﬁer f satisﬁes
F∗ − F (f )
Let W = [0  0.5] and B(θ0  r) = {θ : |θ − θ0| ≤ r}. Denote by ΠW [θ] by a projection of θ into the

domain W. Denote by Xθ = {x ∈ X : η(x) ≥ θ} for any θ ∈ [0  0.5] and by ρθ =(cid:82)

p−→ 0  as n → ∞  where p−→ denotes convergence in probability.

dµ(x).

x∈Xθ

4 Fast Online F-measure Optimization Algorithm
From the discussion above  we can cast OFO into two sub-problems  i.e.  online learning of the
posterior probability and online learning of the optimal threshold. Let us ﬁrst discuss the ﬁrst sub-
problem and then focus on the second sub-problem. For the ﬁrst sub-problem  we assume that there
exists an online algorithm A that can incrementally learn the posterior probability. To better illustrate
this  let us consider a scenario that the true posterior probability is speciﬁed by a generalized linear
model  i.e.  with an appropriate feature mapping φ(x) ∈ Rd there exists w∗ ∈ Rd such that

η(x) = Pr(y = 1|x) =

1

1 + exp(−w(cid:62)∗ φ(x))

.

(2)

It is not difﬁcult to show that the model parameter w∗ can be learned by minimizing the expected
logistic loss (see supplement)  i.e. 

w∗ ∈ arg min
w∈Rd

L(w) (cid:44) Ex y log(1 + exp(−(2y − 1)w(cid:62)φ(x))).

(3)

Therefore  one can use existing online learning algorithms (e.g.  SGD [28  17]) to learn w∗. To this
end  we denote by

wt = A(wt−1  xt  yt) 

(4)
the update of an online algorithm that updates the model parameter wt−1 iteratively  where t =
1  . . .   n. In the next section  we discuss some choices of the online algorithm A and its implication

for the convergence result. At the t-th iteration (before receiving the t-th example)  let(cid:98)ηt(x) denote
(cid:98)ηt(x) can be computed by

an estimate of the posterior probability. For example of generalized linear model considered above 

(5)
where ¯wt−1 is a solution computed based on w0  . . .   wt−1 that has a convergence guarantee (please
see Assumption 1 and its discussion in next section). It is notable that online learning of the posterior
probability is also used in [3].
Next  we focus on online learning of the optimal threshold θ∗. According to [26]  θ∗ is achieved at
the unique root of

t−1φ(x))) 

(cid:98)ηt(x) = 1/(1 + exp(− ¯w(cid:62)

q(θ) = πθ − Ex [(η(x) − θ)+]  

where q(θ) is continuous and strictly increasing  and the function (·)+ is deﬁned as (x)+ = max(x  0).
Instead  we will cast the problem of learning the optimal threshold θ∗ as the following strongly convex
optimization problem.
Lemma 1. θ∗ is the unique optimizer of the following strongly convex function

(cid:2)(η(x) − θ)2

(cid:3) +

+

min

θ∈[0 0.5]

Q(θ) (cid:44) 1
2

Ex

1
2

πθ2.

(6)

Indeed  Q(θ) is a σ-strongly convex function with σ = π + minθ∈[0 0.5] ρθ.

4

Algorithm 1 FOFO(n)

1: Set w0 = 0 (cid:98)θ(0) = 0  m = (cid:98) 1

2: for k = 1  . . .   m do
3:

(cid:104)
w(k) (cid:98)θ(k) (cid:98)π(k)(cid:105)

Set γk = Rk−1√
10n0

4:
5: end for

2n

2 log2

log2 n(cid:99) − 1  n0 = (cid:98)n/m(cid:99) (cid:98)π0 = 0  R0 = 0.5.
= SFO(w(k−1) (cid:98)θ(k−1) (cid:98)π(k−1)  n0  γk  Rk−1  (k − 1)n0)

  Rk = Rk−1/2

Algorithm 2 SFO(w  θ (cid:98)π  T  γ  R  T0)
1: Initialize ¯θ1 = θ1 = θ (cid:98)πT0 =(cid:98)π  wT0 = w

Let t = τ + T0 be the global iteration index.
Receive an example xt

Compute(cid:98)ηt(xt) according to (5)
if(cid:98)ηt(xt) ≥ ¯θτ then

Make a prediction ˆyt = 1

else

2: for τ = 1  . . .   T do
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15: wt = A(wt−1  xt  yt)
16: end for

end if
Observe the label yt

17: return wt  ¯θT +1 (cid:98)πt

¯θτ +1 = 1

τ +1 (τ ¯θτ + θτ +1)

Make a prediction ˆyt = 0

t ((t − 1)(cid:98)πt−1 + I[yt=1])

(cid:98)πt = 1
θτ +1 = ΠW∩B(θ1 R)(θτ − γ∂(cid:98)Qt(θτ ))

The above lemma can be easily shown by noting that ∇Q(θ) = q(θ). The strong convexity of Q(θ)
is also not difﬁcult to prove (see supplement for details). The next lemma shows that if θ is closer to
θ∗ then F (ηθ) is closer to F∗  which further justiﬁes our approach of learning the optimal threshold
by optimizing the strongly convex function Q(θ).
Lemma 2. ∀θ ∈ [0  0.5]  there exists c > 0 such that F∗ − F (ηθ) ≤ c|θ − θ∗|.
The proof of this lemma can be found in the supplement. However  there are several challenges for
minimizing Q(θ) to have a faster convergence. First  even an unbiased stochastic gradient of Q(θ)
through the historical model parameters. Second  the strongly convex parameter σ ≥ π of Q(θ) is

is not available due to that η(x) is not given aprior. Only a noisy estimation of(cid:98)ηt(x) is available
unknown. Standard SGD method for minimizing a σ-strongly convex function with an (cid:101)O(1/(σn))

convergence rate on the objective value requires knowing the strong convexity parameter for setting
the step size. One may use historical examples y1  . . .   yt−1 to obtain a new estimate of π at each
iteration t and use it to set the step size. However  analysis of such an approach is difﬁcult. Another
simple approach is to use a dedicated set of examples to obtain a lower bound of π and then use it to
set the step size. Nevertheless  such an approach could yield a large convergence error because the
lower bound of π could be very small especially when the data is highly imbalanced.
We address these issues by proposing a novel stochastic algorithm that does not require using the

strong convexity parameter to set the step size  and also can tolerate moderate noise in(cid:98)ηt(x) to enjoy
a fast convergence rate of (cid:101)O(1/(σn)) for minimizing Q(θ). We present the Fast Online F-measure
Optimization (FOFO) in Algorithm 1 and Algorithm 2  where(cid:98)πt in Step 12 is the estimate of π
up to the t-th iteration  i.e. (cid:98)πt =(cid:80)t
2(cid:98)πtθ2. It is worth

τ =1 yτ /t and (cid:98)Qt(θ) = 1

2 ((cid:98)ηt(xt) − θ)2

mentioning that the Step 5 and 15 in Algorithm 2 can be replaced by other online learners of the
posterior probability which are not necessarily restricted to the generalized linear model (2). The main
algorithm FOFO is presented in a way that facilitates the analysis. The updates of FOFO are divided
into m stages  where at each stage a stochastic F-measure optimization method (Algorithm 2) is called
for running n0 iterations. For each received example xt  the prediction ˆyt is computed by thresholding

current estimate of posterior probability(cid:98)ηt(xt) by the current value of θ. At each iteration of a

+ + 1

5

stage k  we use the gradient of (cid:98)Qt(θ) to update θ with a constant step size γk and project it into

W ∩ B(θ1  Rk−1)  where θ1 is the initial solution of this stage and Rk−1 is a radius parameter. The
step-size γk and radius parameter Rk−1 are changed according to Step 3 in Algorithm 1. We remark
that the same multi-stage scheme (especially the setting of m and n0) Algorithm 1 is due to [8]  which
was also used in several stochastic optimization algorithms for solving different problems [11  12].

However  the difference from these studies is that ∂(cid:98)Qt(θ) is not an unbiased stochastic gradient of

Q(θ).

√

√

5 Convergence and Consistency Results of FOFO
In this section  we further justify the proposed FOFO by presenting a convergence result of FOFO
for learning the optimal threshold θ∗ and a consistency result of FOFO for F-measure optimization.
Omitted proofs can be found in the supplement.
For simplicity of analysis  we let φ(x) = x and w.l.o.g assume that feature vectors are bounded by

a positive number κ  i.e.  supx∈X (cid:107)x(cid:107)2 ≤ κ. As mentioned in the last section that ∂(cid:98)Qt(θ) is not
an unbiased stochastic gradient of Q(θ). Nevertheless  we expect that ∂(cid:98)Qt(θ) is getting close to an
unbiased stochastic gradient of Q(θ) as(cid:98)ηt(x) converges to η(x). To formalize this notion  we will
t  i.e.  by learning with t examples the error of learned posterior probability(cid:98)ηt(·) is
maxx∈X |(cid:98)ηt(x) − η(x)| ≤ O(1/

introduce the following assumption about convergence of the model for the posterior probability.
Assumption 1. Assume there exists an online algorithm A that learns the posterior probability at
a rate of 1/

t) with high probability.
√
Remark: Please note that this is a high-level assumption without imposing any form of the poste-
√
t) rate for learning the posterior probability is the minimal
rior probability. The assumed O(1/
assumption for achieving an O(1/
n) rate of the learning the threshold. It is worth mentioning that
estimating the posterior probability can be considered as a special problem of statistical density esti-
mation  which has been studied in the literature with a convergence rate as fast as O(1/t) [25  6  21].
We provide a justiﬁcation here for the considered generalized linear model (2)  which is Lipchitz
continuous with respect to w. To this end  it sufﬁces to assume that there exists an algorithm A as
in (4) that produces solutions ¯wt converging to w∗ at a rate of O(1/
t) with high probability  i.e. 
we have (cid:107) ¯wt − w∗(cid:107)2 ≤ C(cid:48)√
with high probability  where ¯wt is a solution computed from w1  . . .   wt
and C(cid:48) is a problem-dependent value. This can be justiﬁed as following. Note that the objective
function L(w) in (3) is strongly convex for w in a compact domain if the data covariance matrix is
nonsingular [1]. Thus SGD method for strongly convex function using a sufﬁx-averaging solution
¯wt = (w(1−α)t+1 + . . . + wt)/(αt) with α ∈ (0  1) can have an O(log(1/δ)/t) convergence rate for
minimizing L(w)  i.e.  L( ¯wt) − L(w∗) ≤ O(log(1/δ)/t) [17]  which implies (cid:107) ¯wt − w∗(cid:107)2 ≤ C(cid:48)√

with a high probability 1 − δ for δ ∈ (0  1) and C(cid:48) = O((cid:112)log(1/δ)). When the convariance matrix

is not singular  by Corollary 7 of [22]  a quadratic growth condition is satisﬁed and we can still get the
O(1/t) convergence for minimizing L(w) via accelerated stochastic subgradient method proposed
in [22]. Even though the strong convexity parameter of L(w) is not exploited  the stochastic approxi-
mation algorithm proposed in [2] with a constant step size also has an O(1/t) convergence rate of an
√
averged solution ¯wt for minimizing L(w) with a large probability (e.g.  0.99). These results would
t) convergence for (cid:107) ¯wt − w∗(cid:107) for an optimal solution w∗ ∈ arg minw∈W L(w).
limply an O(1/
a high probability 1 − δ. The results can be extended to the case that it holds with a large constant
probability.
We ﬁrst state the convergence result of one stage of FOFO  i.e.  SFO.
√
Theorem 2 (Convergence Result of SFO). Suppose Assumption 1 holds with high probability
t. If |θ1 − θ∗| ≤ R  running

In the following results  we will assume that maxx∈X |(cid:98)ηt(x)− η(x)| ≤ O((cid:112)log(1/δ)/t) holds with
1 − δ in the sense that maxx∈X |(cid:98)ηt(x) − η(x)| ≤ Cκ(cid:112)log(1/δ)/

√

t

t

Algorithm 2 for T -iterations with γ = R√
10T
√

Q(¯θT ) − Q(θ∗) ≤ 2

  we have with probability at least 1 − δ 

10R + R(20 + 4Cκ)(cid:112)ln(12T /δ)

.

√

T

6

Q((cid:98)θm) − Q(θ∗) ≤ (cid:101)O

(cid:18) log( 1

δ )

(cid:19)

.

√
Remark: The above result indicates the FOFO has at least an O(1/

Q(θ). The next theorem establishes a faster convergence (cid:101)O(1/n) by utilizing the above result and

n) convergence for optimizing

the multi-stage scheme of FOFO.
Theorem 3 (Convergence Result of FOFO). Given δ ∈ (0  1)  under the same condition in Theo-
rem 2 and n is sufﬁciently large such that n > 100. Then with probability at least 1 − δ 

σn

√

n)).

optimization by using Proposition 13 in [15].
Theorem 4 (Consistency of F-measure Optimization). Suppose Assumption 1 holds  then FOFO

Remark: Since Q(θ) is σ-strongly convex  the above result implies that |(cid:98)θm − θ∗| ≤ (cid:101)O(1/(σ
Finally  by the convergence of(cid:98)θm and(cid:98)ηn(x)  we can establish the consistency of FOFO for F-measure
is F-measure consistent  i.e.  the ﬁnal binary classiﬁer [(cid:98)ηn(x) ≥(cid:98)θm] is F-measure consistent.
weaker assumption about the convergence of(cid:98)ηt can be used. As long as maxx∈X |(cid:98)ηt(x) − η(x)| ≤
O(1/tα) for some α > 0  a convergence result can be established for (cid:98)θm  which implies the

We would like to mention that for establishing the consistency of FOFO for F-measure optimization a

consistency of FOFO for F-measure optimization by the Proposition 13 in [15].
Extension to Other Metrics. Before ending this section  we would like to mention that the proposed
method can be extended to other non-decomposable metrics such as Jaccard similarity coefﬁcient
(JAC) and Fβ measure. We present more details in the supplement for interested readers.
6 Experiments
We present some experimental results in this section. We will compare with four baselines including
online learning with logistic loss using 0.5 for thresholding the posterior probability (referred as LR) 
STAMP [14]  OMCSL [23]  and OFO [3]. The last three are representative algorithms from the three
categories. For LR  OFO and FOFO  we use the same SGD for learning the posterior probability by
minimizing the logistic loss. To be fair  we implement the STAMP algorithm with a logistic loss
based reward function  and also use logistic loss for OMCSL.
We evaluate the performance on 25 binary classiﬁcation tasks from seven benchmark datasets
(covtype  webspam  a9a  ijcnn1  w8a  sensorless  protein). All the datasets involved are downloaded
from the LIBSVM repository [5]. It is notable that covtype  sensorless and protein are multi-class
datasets. We construct binary tasks following the scheme one vs others denoted by “X vs o" below.
Each dataset is divided into three parts (1:1:1) for online training  online validation and ofﬂine testing.
The validation data is used to select the best parameters by running the considered algorithms and
selecting the best parameters according to the ﬁnal F-measure. In particular  for FOFO  OFO  and
LR  we tune the initial step parameter for learning the posterior probability in the range 2[−4:1:4].
For STAMP and OMCSL  the stepsize parameter is also tuned in 2[−8:1:4]. For OMCSL  we use 10
settings for the weights and learn 10 classiﬁers online. For each data  we repeat the experiments 10
times by running on 10 random shufﬂed data and report the average and variance. We will report
online performance (evaluation of predictions on historical examples) on online training data  and
ofﬂine performance by evaluating the ﬁnal models on the testing data.
Due to limitation of space  we only report part of the results (complete results are included in the
supplement). The online performance (F-score vs iterations) is plotted in Figure 1 and 2 for covtype
datasets and other datasets. The F-measure vs running time s plotted in Figure 3 and 4 and the ofﬂine
testing performance are reported in the supplement. We can ﬁrst consider the results on covtype.
From (a) to (f) in Figure 1 where p = x% denotes the percentage of positive examples  we organize
the data in the order of increasing imbalance. We can see that as data becomes more imbalanced  the
improvement of our algorithm FOFO over baselines becomes larger. On the datasets that are more
balanced (covtype 2 vs o  1 vs o)  the difference between FOFO and OFO is small  and they both
outperforms other baselines. When the datasets become highly imbalanced (covtype 6 vs o  5 vs
o)  the baseline LR becomes extremely worse  and the margin of FOFO over OFO becomes larger.
The comparison between FOFO and OFO veriﬁes that the proposed method for learning the optimal
threshold converges faster as they share the same component for learning the posterior probability.
The comparison between FOFO and other baselines verify that the proposed method is better than

7

(a) cov (2 vs o) (p=48.76%)

(b) cov (1 vs o) (p=36.46%)

(c) cov (3 vs o) (p=6.15%)

(d) cov (7 vs o) (p=3.53%)

(e) cov (6 vs o) (p=2.99%)

(f) cov (5 vs o) (p=1.63%)

Figure 1: Online Performance of F-measure for covtype dataset

(a) webspam (p=60.72%)

(b) protein (0 vs o) (p=46.14%)

(c) a9a (p=24.08%)

(d) ijcnn1 (p=9.49%)

(e) Sensorless (1 vs o) (p=9.09%)

(f) w8a (p=2.97%)

Figure 2: Online Performance of F-measure for other datasets

other categories of algorithms. The results on other datasets in Figure 2 also demonstrate that FOFO
is faster than OFO and other baselines especially for highly imbalanced data. The running time
results in Figure 3 and 4 also verify that the proposed FOFO algorithm is the most efﬁcient.

7 Conclusions
In this paper  we proposed a fast online F-measure optimization algorithm with low memory and
computational costs by learning the optimal threshold for a probabilistic classiﬁer. A novel stochastic
algorithm was proposed for learning the optimal threshold. We prove that the proposed algorithm
n)  and the proposed algorithm
enjoys F-measure consistency at the population level. Extensive experimental results comparing

for learning of the optimal threshold has a convergence rate (cid:101)O(1/

√

8

0.511.5iteration1050.70.710.720.730.740.750.760.770.78F-scoreFOFOOFOLRSTAMPOMCSL0.511.5iteration1050.580.60.620.640.660.680.70.72F-scoreFOFOOFOLRSTAMPOMCSL0.511.5iteration1050.50.550.60.650.70.750.8F-scoreFOFOOFOLRSTAMPOMCSL0.511.5iteration1050.20.30.40.50.60.70.8F-scoreFOFOOFOLRSTAMPOMCSL0.511.5iteration105-0.100.10.20.30.40.5F-scoreFOFOOFOLRSTAMPOMCSL0.511.5iteration105-0.0500.050.10.150.20.250.30.35F-scoreFOFOOFOLRSTAMPOMCSL246810iteration1040.840.860.880.90.920.94F-scoreFOFOOFOLRSTAMPOMCSL2000400060008000iteration0.450.50.550.60.650.70.750.8F-scoreFOFOOFOLRSTAMPOMCSL50001000015000iteration0.50.550.60.650.70.75F-scoreFOFOOFOLRSTAMPOMCSL1234iteration10400.10.20.30.40.50.60.7F-scoreFOFOOFOLRSTAMPOMCSL0.511.5iteration104-0.200.20.40.60.8F-scoreFOFOOFOLRSTAMPOMCSL0.511.522.5iteration10400.10.20.30.40.50.60.70.8F-scoreFOFOOFOLRSTAMPOMCSL(a) cov (2 vs o)

(b) cov (1 vs o)

(c) cov (3 vs o)

(d) cov (7 vs o)

(e) cov (6 vs o)

(f) cov (5 vs o)

Figure 3: Online F-measure vs Running Time for covtype dataset

(a) webspam

(b) protein (0 vs o)

(c) a9a

(d) ijcnn1

(e) Sensorless (1 vs o)

(f) w8a

Figure 4: Online F-measure vs Running Time for other datasets

with state-of-the-art online F-measure optimization algorithms also demonstrate the efﬁciency of the
proposed algorithm  especially on highly imbalanced datasets.

Acknowledgement

The authors thank the anonymous reviewers for their helpful comments. M. Liu  X. Zhang and T.
Yang are partially supported by National Science Foundation (IIS-1545995).

9

02468time (second)0.70.710.720.730.740.750.760.770.78F-scoreFOFOOFOLRSTAMPOMCSL02468time (second)0.580.60.620.640.660.680.70.72F-scoreFOFOOFOLRSTAMPOMCSL02468time (second)0.50.550.60.650.70.750.8F-scoreFOFOOFOLRSTAMPOMCSL02468time (second)0.20.30.40.50.60.70.8F-scoreFOFOOFOLRSTAMPOMCSL02468time (second)-0.100.10.20.30.40.5F-scoreFOFOOFOLRSTAMPOMCSL02468time (second)-0.0500.050.10.150.20.250.30.35F-scoreFOFOOFOLRSTAMPOMCSL012345time (second)0.840.860.880.90.920.94F-scoreFOFOOFOLRSTAMPOMCSL00.10.20.30.4time (second)0.450.50.550.60.650.70.750.8F-scoreFOFOOFOLRSTAMPOMCSL00.10.20.30.40.50.6time (second)0.50.550.60.650.70.75F-scoreFOFOOFOLRSTAMPOMCSL00.511.52time (second)00.10.20.30.40.50.60.7F-scoreFOFOOFOLRSTAMPOMCSL00.20.40.60.8time (second)-0.100.10.20.30.40.50.60.7F-scoreFOFOOFOLRSTAMPOMCSL00.20.40.60.811.2time (second)00.10.20.30.40.50.60.70.8F-scoreFOFOOFOLRSTAMPOMCSLReferences
[1] Alekh Agarwal  Sahand Negahban  and Martin J. Wainwright. Stochastic optimization and
sparse statistical recovery: Optimal algorithms for high dimensions. In Advances in Neural
Information Processing Systems 25 (NIPS)  pages 1547–1555  2012.

[2] Francis R. Bach and Eric Moulines. Non-strongly-convex smooth stochastic approximation
with convergence rate o(1/n). In Advances in Neural Information Processing Systems (NIPS) 
pages 773–781  2013.

[3] Róbert Busa-Fekete  Balázs Szörényi  Krzysztof Dembczynski  and Eyke Hüllermeier. Online
f-measure optimization. In Advances in Neural Information Processing Systems  pages 595–603 
2015.

[4] Nicolo Cesa-Bianchi  Philip M Long  and Manfred K Warmuth. Worst-case quadratic loss
bounds for prediction using linear functions and gradient descent. IEEE Transactions on Neural
Networks  7(3):604–619  1996.

[5] Chih-Chung Chang and Chih-Jen Lin. Libsvm: a library for support vector machines. ACM

transactions on intelligent systems and technology (TIST)  2(3):27  2011.

[6] Peter D. Grünwald. The Minimum Description Length Principle (Adaptive Computation and

Machine Learning). The MIT Press  2007.

[7] Thorsten Joachims. A support vector method for multivariate performance measures.

In
Proceedings of the 22Nd International Conference on Machine Learning (ICML)  pages 377–
384  2005.

[8] Anatoli Juditsky  Yuri Nesterov  et al. Deterministic and stochastic primal-dual subgradient

algorithms for uniformly convex minimization. Stochastic Systems  4(1):44–80  2014.

[9] Purushottam Kar  Harikrishna Narasimhan  and Prateek Jain. Online and stochastic gradient
methods for non-decomposable loss functions. In Advances in Neural Information Processing
Systems 27 (NIPS)  pages 694–702  2014.

[10] Jyrki Kivinen and Manfred K Warmuth. Exponentiated gradient versus gradient descent for

linear predictors. Information and Computation  132(1):1–63  1997.

[11] Mingrui Liu  Xiaoxuan Zhang  Zaiyi Chen  Xiaoyu Wang  and Tianbao Yang. Fast stochastic
AUC maximization with o(1/n)-convergence rate. In Proceedings of the 35th International
Conference on Machine Learning (ICML)  pages 3195–3203  2018.

[12] Mingrui Liu  Xiaoxuan Zhang  Lijun Zhang  Rong Jin  and Tianbao Yang. Fast rates of erm
and stochastic approximation: Adaptive to error bound conditions. In Advances in Neural
Information Processing Systems (NIPS)  pages –  2018.

[13] Maciej A Mazurowski  Piotr A Habas  Jacek M Zurada  Joseph Y Lo  Jay A Baker  and
Georgia D Tourassi. Training neural network classiﬁers for medical decision making: The
effects of imbalanced datasets on classiﬁcation performance. Neural networks  21(2-3):427–436 
2008.

[14] Harikrishna Narasimhan  Purushottam Kar  and Prateek Jain. Optimizing non-decomposable
performance measures: A tale of two classes. In International Conference on Machine Learning 
pages 199–208  2015.

[15] Nagarajan Natarajan  Oluwasanmi Koyejo  Pradeep Ravikumar  and Inderjit S. Dhillon. Con-
In Neural Information

sistent binary classiﬁcation with generalized performance metrics.
Processing Systems (NIPS)  2014.

[16] Shameem Puthiya Parambath  Nicolas Usunier  and Yves Grandvalet. Optimizing f-measures
by cost-sensitive classiﬁcation. In Advances in Neural Information Processing Systems 27 
pages 2123–2131  2014.

10

[17] Alexander Rakhlin  Ohad Shamir  and Karthik Sridharan. Making gradient descent optimal
for strongly convex stochastic optimization. In Proceedings of International Conference on
Machine Learning (ICML)  2012.

[18] Frank Rosenblatt. The perceptron: A probabilistic model for information storage and organiza-

tion in the brain. Psychological review  65(6):386  1958.

[19] Clayton Scott. Calibrated asymmetric surrogate losses. Electron. J. Statist.  6:958–992  2012.

[20] Yuchun Tang  Sven Krasser  Paul Judge  and Yan-Qing Zhang. Fast and effective spam sender
detection with granular svm on highly imbalanced mail server behavior data. In Collabora-
tive Computing: Networking  Applications and Worksharing  2006. CollaborateCom 2006.
International Conference on  pages 1–6. IEEE  2006.

[21] Tim van Erven  Peter D. Grünwald  Nishant A. Mehta  Mark D. Reid  and Robert C. Williamson.

Fast rates in statistical and online learning. Journal of Machine Learning Research  2015.

[22] Yi Xu  Qihang Lin  and Tianbao Yang. Stochastic convex optimization: Faster local growth
implies faster global convergence. In Proceedings of the 34th International Conference on
Machine Learning (ICML)  pages 3821–3830  2017.

[23] Yan Yan  Tianbao Yang  Yi Yang  and Jianhui Chen. A framework of online learning with
imbalanced streaming data. In Proceedings of the Thirty-First AAAI Conference on Artiﬁcial
Intelligence (AAAI)  pages 2817–2823  2017.

[24] Nan Ye  Kian Ming Adam Chai  Wee Sun Lee  and Hai Leong Chieu. Optimizing f-measure:
A tale of two approaches. In Proceedings of the 29th International Conference on Machine
Learning (ICML)  2012.

[25] Tong Zhang. From -entropy to kl-entropy: Analysis of minimum information complexity

density estimation. Ann. Statist.  34(5):2180–2210  10 2006.

[26] Ming-Jie Zhao  Narayanan Edakunni  Adam Pocock  and Gavin Brown. Beyond fano’s inequal-
ity: bounds on the optimal f-score  ber  and cost-sensitive risk and their implications. Journal of
Machine Learning Research  14(Apr):1033–1090  2013.

[27] Peilin Zhao and Steven CH Hoi. Cost-sensitive online active learning with application to
malicious url detection. In Proceedings of the 19th ACM SIGKDD international conference on
Knowledge discovery and data mining  pages 919–927. ACM  2013.

[28] Martin Zinkevich. Online convex programming and generalized inﬁnitesimal gradient ascent.
In Proceedings of the International Conference on Machine Learning (ICML)  pages 928–936 
2003.

11

,Miguel Bautista
Artsiom Sanakoyeu
Ekaterina Tikhoncheva
Bjorn Ommer
Xiaoxuan Zhang
Mingrui Liu
Xun Zhou
Tianbao Yang
Shuang Li
Gongguo Tang
Michael Wakin