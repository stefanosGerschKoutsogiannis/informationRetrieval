2018,Optimization for Approximate Submodularity,We consider the problem of maximizing a submodular function when given access to its approximate version. Submodular functions are heavily studied in a wide variety of disciplines  since they are used to model many real world phenomena  and are amenable to optimization. However  there are many cases in which the phenomena we observe is only approximately submodular and the approximation guarantees cease to hold. We describe a technique which we call the sampled
mean approximation that yields strong guarantees for maximization of submodular functions from approximate surrogates under cardinality and intersection of matroid constraints. In particular  we show tight guarantees for maximization under a cardinality constraint and 1/(1+P) approximation
under intersection of P matroids.,Optimization for Approximate Submodularity

Avinatan Hassidim

Bar Ilan University and Google
avinatan@cs.biu.ac.il

Yaron Singer

Harvard University

yaron@seas.harvard.edu

Abstract

We consider the problem of maximizing a submodular function when given access
to its approximate version. Submodular functions are heavily studied in a wide
variety of disciplines since they are used to model many real world phenomena
and are amenable to optimization. There are many cases however in which the
phenomena we observe is only approximately submodular and the optimization
guarantees cease to hold. In this paper we describe a technique that yields strong
guarantees for maximization of monotone submodular functions from approximate
surrogates under cardinality and intersection of matroid constraints. In particular 
we show tight guarantees for maximization under a cardinality constraint and
1/(1 + P ) approximation under intersection of P matroids.

1

Introduction

In this paper we study maximization of approximately submodular functions. For nearly half a
century submodular functions have been extensively studied since they are amenable to optimization
and are recognized as an effective modeling instrument. In machine learning  submodular functions
capture a variety of objectives that include entropy  diversity  image segmentation  and clustering.
Although submodular functions are used to model real world phenomena  in many cases the functions
we encounter are only approximately submodular. This is either due to the fact that the objectives are
not exactly submodular  or alternatively they are  but we only observe their approximate version.
In the literature  approximate utility functions are modeled as surrogates of the original function that
have been corrupted by random variables drawn i.i.d from some distribution. Some examples include:

• Revealed preference theory. Luce’s famous model assumes that an agent’s revealed utility
˜f : 2N ! R can be approximated by a well-behaved utility function f : 2N ! R s.t.
˜f (S) = f (S) + ⇠S for every S ✓ N where ⇠S is drawn i.i.d from a distribution [CE16]. ˜f
is a utility function that approximates f  and multiple queries to ˜f return the same response;
• Statistics and learning theory. The assumption in learning is that the data we observe is
generated by ˜f (x) = f (x) + ⇠x where f is in some well-behaved hypothesis class and ⇠x
is drawn i.i.d from some distribution. The use of ˜f is not to model corruption by noise but
rather the fact that data is not exactly manufactured by a function in the hypothesis class;
• Active learning. There is a long line of work on noise-robust learning where one has access
to a noisy membership oracle ˜f (x) = f (x) + ⇠x and for every x we have that ⇠x is drawn
i.i.d from a distribution [Ang88  GKS90  Jac94  SS95  BF02  Fel09]. In this model as well 
the oracle is consistent and multiple queries return the same response. For set functions 
one can consider active learning in experimental design applications where the objective
function is often submodular and the goal would be to optimize f : 2N ! R given ˜f.

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

Similar to the above examples  we say that a function ˜f : 2N ! R+ is approximately submodular
if there is a submodular function f : 2N ! R+ and a distribution D s.t. for each set S ✓ N we
have that ˜f (S) = ⇠Sf (S) where ⇠S is drawn i.i.d from D.1 The modeling assumption that ⇠S is not
adversarially chosen but drawn i.i.d is crucial. Without this assumption for ˜f (S) = ⇠Sf (S) where
⇠S 2 [1  ✏  1 + ✏] even for subconstant ✏> 0 no algorithm can obtain an approximation strictly
better than n1/2 to maximizing either ˜f or f under a cardinality constraint when n = |N| [HS17].
This hardness stems from the fact that approximate submodularity implies that the function is close
to submodular  but its marginals (or gradients) are not well approximated by those of the submodular
function. When given an ↵ approximation to the marginals  the greedy algorithm produces a 1 1/e↵
approximation. Furthermore  even for continuous submodular functions  a recent line of work
shows that gradient methods produce strong guarantees with approximate gradient information of the
function [HSK17  CHHK18  MHK18].
In contrast to the vast literature on submodular optimization  optimization of approximate sub-
modularity is nascent. For distributions bounded in [1  ✏/k  1 + ✏/k] the function is sufﬁ-
ciently close to submodular for the approximation guarantees of the greedy algorithm to go
through [HS  LCSZ17  QSY+17]. Without this assumptions  the greedy algorithm performs ar-
bitrarily poorly. In [HS17] the authors give an algorithm that obtains an approximation arbitrarily
close to 1  1/e under a cardinality constraint that is sufﬁciently large. For arbitrary cardinality and
general matroid constraints there are no known approximation guarantees.

1.1 Our Contribution
In this paper we consider the problem maxS2F f (S) when f : 2N ! R is non-negative monotone
submodular deﬁned of a ground set N of size n and the algorithm is only given access to an
approximate surrogate ˜f and F is a uniform matroid (cardinality) or intersection of matroids constraint.
We introduce a powerful technique which we call the sampled mean approximation and show:

• Optimal guarantees for maximization under a cardinality constraint. In [HS17] the re-
sult gives an approximation arbitrarily close to 1 1/e for k 2 ⌦(log log n). This is a funda-
mental limitation in their technique that initializes the solution with a set of size ⌦(log log n)
used for “smoothing” the approximately submodular function (see Appendix G.1 for more
details). The technique in this paper is novel and yields an approximation of 1  1/e for any
k  2  and 1/2 for k = 1  which is information theoretically tight  as we later show;
• 1/(1 + P ) approximation for intersection of P matroids. We utilize the sampled mean
approximation method to produce the ﬁrst results for the more challenging case of maxi-
mization under general matroid constraints. Our approximation guarantees are comparable
with those achievable with a greedy algorithm for monotone submodular functions;
• Information theoretic lower bounds. We show that no randomized algorithm can obtain an
approximation strictly better than 1/2+O(n1/2) for maxa2N f (a) given an approximately
submodular oracle ˜f  and that no randomized algorithm can obtain an approximation strictly
better than (2k  1)/2k + O(n1/2) for maximization under cardinality constraint k;
• Bounds in Extreme Value Theory. As we later discuss  some of our results may be of
independent interest to Extreme Value Theory (EVT) which studies the bounds on the
maximum sample (or the top samples) from some distribution. To achieve our main result
we prove subtle properties about extreme values of random variables where not all samples
are created equal and the distributions generalize those typically studied in EVT.

The results above are for the problem maxS2F f (S) when the algorithm is given access to ˜f. In
some applications  however  ˜f is the function that we actually wish to optimize  i.e. our goal is
˜f (S). If ˜f (S) approximates f (S) well on all sets S  we can use the solution
to solve maxS2F
˜f (S). In general  however  a solution that is good for
for maxS2F f (S) as a solution for maxS2F
˜f (S). In Appendix E we give a black-box reduction
maxS2F f (S) can be arbitrarily bad for maxS2F
showing that these problems are essentially equivalent. Speciﬁcally  we show that given a solution

1Describing ˜f as a multiplicative approximation of f is more convenient for analyzing multiplicative

approximation guarantees. This is w.l.o.g as all our results apply to additive approximations as well.

2

˜f (S)
to maxS2F f (S) one can produce a solution that is of arbitrarily close quality to maxS2F
when F is any uniform matroid  an intersection of matroids of rank ⌦(log n)  and an intersection of
matroids of any rank when the distribution D has bounded support.
1.2 Technical Overview

The approximately submodular functions we consider approximate a submodular function f using
samples from a distribution D of the class of generalized exponential tail distributions deﬁned as:
Deﬁnition. A noise distribution D has a generalized exponential tail if there exists some x0 such
that for x > x0 the probability density function ⇢(x) = eg(x)  where g(x) =Pi aix↵i for some
(not necessarily integers) ↵0  ↵1  . . .  s.t. ↵0  1. If D has bounded support we only require that
either it has an atom at its supremum  or that ⇢ is continuous and non-zero at the supremum.

This class of distributions is carefully deﬁned. On the one hand it is general enough to contain
Gaussian and Exponential distributions  as well as any distribution with bounded support. On the
other hand it has enough structure one can leverage. Note that optimization in this setting always
requires that the support is independent of n and that n is sufﬁciently large 2. Throughout the paper
we assume that D has a generalized exponential tail and that n is sufﬁciently large.
Theorem. For any non-negative monotone submodular function there is a deterministic polynomial-
time algorithm which optimizes the function under a cardinality constraint k  3 and obtains an
approximation ratio that is arbitrarily close to 1  1/e with probability 1  o(1) using access to
an approximate oracle. For k  2 there is a randomized algorithm whose approximation ratio is
arbitrarily close to 1  1/e  in expectation over the randomization of the algorithm. For k = 1 the
algorithm achieves a 1/2 approximation in expectation  and no randomized algorithm can achieve
an approximation better than 1/2 + o(1)  in expectation.

The main part of the proof involves analysis of the following greedy algorithm. The algorithm
iteratively chooses bundles of elements of size O(1/✏). In each iteration the algorithm ﬁrst identiﬁes
a bundle x whose addition to the current solution approximately maximizes the approximate mean
value ˜F . Informally  ˜F (x) is the average value of ˜f evaluated on all bundles at Hamming distance
one from x. Then  the algorithm does not choose x but rather the bundle at Hamming distance one
from x whose addition to the current solution maximizes the approximate submodular value ˜f.
The major technical challenge is in analyzing the regime in which k 2 ⌦(1/✏2) \O (plog n). At

a high level  in this regime the analysis relies on showing that the marginal contribution of the
bundle of elements selected in every iteration is approximately largest. Doing so requires proving
subtle properties about extreme values of random variables drawn from the generalized exponential
tail distribution  and the analysis fully leverages the properties of the distribution and the fact that

k 2O (plog n). This is of independent interest to Extreme Value Theory (EVT) which tries to bound
the maximum sample (or the top samples) from some distribution. If we would consider the constant
function f (S) = 1 for S 6= ;  and try to maximize an approximate version of f with respect to some
distribution  this would be a classical EVT setting. One can view the bounds we develop as bounds
on a generalization of EVT  where not all samples are created equal.
For general matroid constraints we apply the sampled-mean technique and obtain an approximation
comparable to that of applying the greedy algorithm on a monotone submodular function.
Theorem. For any non-negative monotone submodular function there is a deterministic polynomial-
time algorithm which optimizes the function under an intersection of P matroids constraint and
obtains an approximation ratio arbitrarily close to 1/(1 + P ) given an approximate oracle.

Paper organization. The main contribution of the paper is the deﬁnition of sampled mean ap-
proximation in Section 2 and the subsequent analysis of the algorithm for cardinality constraint in
Section 3 and matroid constraints in Section 4. The techniques are novel  and the major technical
crux of the paper is in analyzing the algorithm in Section 3. Optimization for small rank and lower
bounds are in Appendix B.1. In Appendix G we further discuss related work  and in Appendix F we
discuss extensions of the algorithms to related models.

2For example  if for every S the noise is s.t. ⇠S = 2100 w.p. 1/2100 and 0 otherwise  but n = 50  it is likely

that the oracle will always return 0  in which case we cannot do better than selecting an element at random.

3

2 The Sampled Mean Approximation

We begin by deﬁning the sampled mean approximation of a function. This approach considers
bundles x of size c 2O (1/✏). We can then run a variant of a greedy algorithm which adds a bundle
of size c in every iteration. For a given bundle x and set S  we deﬁne a ball to be all bundles obtained
by swapping a single element from x with another not in S [ x. We denote xij = (x \ {xi}) [{ xj}.
Deﬁnition. For S ⇢ N and bundle x ⇢ N  the ball around x is BS(x) := {xij : i 2 x  j /2 S [ x}.
We illustrate a ball in Figure 1. Notice that as long as |S| (1  )|N| for some ﬁxed > 0  we
have that |BS(x)|2 ⌦(n). This will allow us to derive weak (but sufﬁcient) concentration bounds.
Deﬁnition. Let f : 2N ! R. For a set S ✓ N and bundle x ✓ N  the mean value  noisy mean
value  and mean marginal contribution of x given S are  respectively:

(1)

(2)

(3)

F (S [ x)
˜F (S [ x)
FS(x)

:= Ez⇠BS (x)⇥
:= Ez⇠BS (x)⇥
:= Ez⇠BS (x)⇥

f (S [ z)
˜f (S [ z)
fS(z)

⇤
⇤
⇤

The following lemma implies that under the right conditions  the bundle that maximizes the noisy
mean value is a good approximation of the bundle whose (non-noisy) mean value is largest.
Lemma 2.1. Let x 2 argmaxz:|z|=c

˜F (S [ z) where c = 2/✏. Then  w.p.  1  exp⌦n1/4:

FS(x)  (1  ✏) max
z:|z|=c

FS(z).

The above lemma gives us a weak concentration bound in the following sense. While it is generally
not true that ˜F (S [ z) ⇡ F (S [ z)  we can upper bound ˜F (S [ z) in a meaningful way and show that
˜F (S [ x?) ⇡ F (S [ x?) for x? 2 argmaxz fS(z) by using submodularity. This allows us to show
that the mean marginal contribution of x that maximizes the noisy mean value is an ✏-approximation
to the maximal (non-noisy) mean marginal contribution. Details and proofs are in Appendix A.
In addition to approximating the mean marginal contribution given a noisy oracle  an important
property of the sampled-mean approach is that it well-approximates its true marginal contribution.
Lemma 2.2. For any ✏> 0 and any set S ⇢ N  let x be a bundle of size 1/✏  then:

FS(x)  (1  ✏)fS(x) 

The proof is in Appendix A and exploits a natural property of submodular functions: the removal of a
random element from a sufﬁciently large set does not signiﬁcantly affect its value  in expectation.
Let x? 2 argmaxb:|b|=c fS(b). Lemma 2.1 and Lemma 2.2 together imply the following corollary:
˜F (S [ b). Then  w.p. at least
Corollary 2.3. For a ﬁxed ✏> 0 let c = 3/✏  and x 2 argmaxb:|b|=c
1  exp(⌦(n1/4)) we have that: FS(x)  (1  ✏)fS(x?).
At a ﬁrst glance  it may seem as if running the greedy algorithm with F instead of f sufﬁces. The
problem  however  is that the mean marginal contribution FS may be an unbounded overestimate
of the true marginal contribution fS. Consider for example an instance where S = ; and there is
a bundle x of size c s.t. for every ; 6= z ✓ x we have f (z) =  for some arbitrarily small   while
every other subset T ✓ N \ x is complementary to x and has some arbitrarily large value M. In this
case  x = argmaxz:|z|=c F (z) and F (x) = M +  while f (x) = .
3 The Sampled Mean Greedy for Cardinality Constraints

The SM-GREEDY begins with the empty set S and at every iteration considers all bundles (sets) of
size c 2O (1/✏) to add to S. At every iteration  the algorithm ﬁrst identiﬁes the bundle x which
maximizes the noisy mean value. After identifying x  it then considers all possible bundles z 2B S(x)
and takes the one whose noisy value is largest. We include a formal description below.

4

x 1 3 = {x2  x3}

x 2 3 = {x1  x3}

x = {x1  x2}

Figure 1: Illustration of a ball around x = {x1  x2} where N = {x1  x2  x3}  and S = ;. We think of x as a
point in [0  1]3 and BS(x) = {x12  x23} = {{x2  x3} {x1  x3}} = {(0  1  1)  (1  0  1)}.
Algorithm 1 SM-GREEDY
Input: budget k  precision ✏> 0  c 56
1: S ;
2: while |S| < c ·⌅ k
3:
4:
5:
6: end while
7: return S

x argmaxb:|b|=c
ˆx argmaxz2B(x)
S S [ ˆx

˜F (S [ b)
˜f (S [ z)

c⇧ do

✏

A key step in analyzing greedy algorithms like the one above is showing that in every iteration the
marginal contribution of the element selected by the algorithm is arbitrarily close to maximal. This
can then be used in a standard inductive argument to show that the algorithm obtains an approximation
arbitrarily close to 1  1/e. The main crux of the analysis is showing that this property indeed holds
in SM-GREEDY w.h.p. when k 2 ⌦(1/✏2) \O (plog n). For k > plog n the analysis become
substantially simpler since it sufﬁces to argue that the algorithm chooses an element whose marginal
contribution is approximately optimal in expectation (details are in the proof of Theorem 3.5).

3.1 Analysis for k 2 ⌦(1/✏2) \O (plog n)
Throughout the rest of this section we will analyze a single iteration of SM-GREEDY in which a set
S ⇢ N was selected in previous iterations and the algorithm adds a bundle ˆx of size c. Speciﬁcally 
ˆx 2 argmaxz2BS (x)
As discussed above  for x? 2 argmaxb:|b|=c fS(b) we want to show that when c 2O (1/✏):

˜f (S [ z) where x 2 argmaxb:|b|=c

˜F (S [ b).

fS(ˆx)  (1  ✏)fS(x?).

To do so  we will deﬁne two kinds of bundles in BS(x)  called good and bad. A good bundle is a
bundle z for which fS(z)  (1  2
3 ✏)fS(x?) and a bad bundle z is one s.t. fS(z)  (1  ✏)fS(x?).
Our goal is to prove that the bundle ˆx added by the algorithm is w.h.p. not bad. Since according to the
deﬁnition of good and bad the true marginal contribution of good bundles has a ﬁxed advantage over
the true marginal contribution of bad bundles  and ˆx is the bundle with largest noisy value  essentially
what we need to show is that the largest noise multiplier of a good bundle is sufﬁciently close to the
largest noise multiplier of a bad bundle  with sufﬁciently high probability.
As a ﬁrst step we quantify the fraction of good bundles in a ball  which will then allow us to bound
the values of the noise multipliers of good and bad bundles. The following claim implies at least half
of the bundles in BS(x) are good and at most half are bad (the proof is in Appendix B).
Claim 3.1. Suppose FS(x) 1  ✏

3 fS(x?). Then at least half of the bundles in BS(x) are good.

We next deﬁne two thresholds ⇠inf and ⇠sup. The threshold ⇠inf is used as a lower bound on the
largest value obtained when sampling at least |BS (x)|
random variables from the noise distribution.
Since at least half of the bundles in the ball are good  ⇠inf is a lower bound on the largest noise
multiplier of a good bundle. The threshold ⇠sup is used as an upper bound on the largest value
obtained when sampling at most |BS (x)|
random variables from the noise distribution. Since at most
half of the bundles in the ball are bad  ⇠sup upper bounds the value of a noise multiplier of a bad
bundle. Throughout the rest of this section D will denote a generalized exponential tail distribution.

2

2

5

Deﬁnition. Let m = |BS (x)|

2

. For probability density function ⇢(x) of D we deﬁne:

• ⇠sup is the value for which:R 1
• ⇠inf is the value for which:R 1

⇠inf

⇠sup

Claim 3.2. Let m = |BS (x)|

2

⇢(x)dx = 2

m log n;

⇢(x)dx = 2 log n
m .

  ⇠1  . . .  ⇠ m be i.i.d samples of D and ⇠? = max{⇠1  . . .  ⇠ m}. Then:
Prh ⇠inf  ⇠?  ⇠sup i  1 

log n

3

The proof is in Appendix B. Since at least half of the bundles in the ball are good and at most half are
bad  the above claim implies that with probability 1 3/ log n the maximal value of noise multipliers
of good and bad bundles fall within the range [⇠inf ⇠ sup]. Since this holds in every iteration  when
k 2 O(plog n) by a union bound we get that this holds in all iterations w.p. 1  o(1).

At this point  our lower bound on the largest noisy value of a good bundle is:

and the upper bound on the noisy value of any bad bundle is:

max
z2good

˜f (S [ z)  ⇠inf ⇥✓f (S) +✓1 
✏◆ fS(x?)◆
˜f (S [ z)  ⇠sup ⇥ (f (S) + (1  ✏) fS(x?)) .

2
3

max
z2bad
˜f (S [ z). We show that given the right bound on ⇠inf against ⇠sup  then ˆx
Let ˆx = argmaxz2BS (x)
is not a bad bundle (it does not have to be a good bundle). Lemma 3.3 below gives us such a bound.
Lemma 3.3. For any generalized exponential tail distribution  ﬁxed > 0 and sufﬁciently large n:

⇠inf ✓1 



plog n◆ ⇠sup

The proof is quite technical and the fully leverages the fact that k 2O (plog n) and the properties of

generalized exponential tail distributions. The main challenge is that the tail of the distribution is not
necessarily monotone (see Appendix B for further discussion). We defer the proof to Appendix B.

Proving the Main Lemma. We can now prove our main lemma which shows that for any k 2
!(1/✏) \O (plog n) taking a bundle according to the sample mean approach is guaranteed to be
close to the optimal bundle. We state it for a cardinality constraint  but this fact holds more generally
for any matroid of rank k. We include a short proof sketch and defer the full proof to Appendix B.
Lemma 3.4. Let ✏> 0  and assume that k 2 !(1/✏) \O (plog n) and that fS(x?) 2 ⌦⇣ f (S)
k ⌘.
Then  in every iteration of SM-GREEDY we have that with probability at least 1  4

log n:

fS(ˆx)  (1  ✏)fS(x?).

Proof Sketch. From Corollary 2.3 we know that in every iteration with overwhelming high probabil-
ity FS(x)  (1  )f (x?) for  = ✏/3. Since Lemma 3.3 applies for any ﬁxed > 0 we know that
for sufﬁciently large n we can lower bound the value of the maximal good bundle in the ball:

Let b be the bad bundle with the maximal noisy value for fS. To bound this:

˜f (S [ z) ✓1 

max
z2good

2

3plog n◆ ⇠sup ⇥[f (S) + (1  2)fS(x?)]
⇠S[zf (S [ z)  ⇠sup ⇥[f (S) + (1  3)fS(x?)]

˜f (S [ b) = max
z2bad

The difference between the two bounds is positive  implying that a bad bundle is not selected.
Theorem 3.5. For any ﬁxed ✏> 0 and k  4/✏2 SM-GREEDY returns a set S s.t. w.p. 1  o(1):

f (S)  (1  1/e  ✏)OPT.

6

c  c and by submodularity f (O)  (1  )OPT when k  1

Proof. Let  = b k
cc and use O to denote the set of  bundles of size c whose total value is
largest. To simplify notation we will treat sets of bundles as sets of elements. We will show that
f (S)  (1  1/e  )f (O) where  = ✏/2. Notice that this implies f (S)  (1  1/e  ✏) since
> k
We introduce some notation: we use ˆxi to denote the bundle selected at iteration i 2 []  Si = [jiˆxj 
i 2 argmaxz fSi-1(z)  and O is the set of  bundles with maximal
xi 2 argmaxz
value. Deﬁne i = f (O)  f (Si-1)  and S0 = ;. From submodularity and monotonicity:

˜F (Si-1 [ z)  x?

✏2 .
2 = 4

fSi-1(x?

i ) 

1


i

⇣j

(1)

i

⇣i+1

 

j=1 ⇣j f (O)

We therefore have that:

f (Si)  f (Si-1) = fSi-1( ˆxi)  ⇣ifSi-1(x?

Consider now a set of bundles {z1  . . .   z} where for every i 2 [] we have that zi is drawn u.a.r.
from BSi-1(xi). For each such bundle we can assign a random variable ⇣i for which fSi-1(zi) =
i ). Since in every iteration i 2 [] we choose the set whose value is maximal in BSi-1(xi) 
⇣ifSi-1(x?
by stochastic dominance we know that fSi-1( ˆxi)  f (zi) and therefore:
⇣i
i ) 

j=1⇣1  ⇣j
⌘ f (O). This is
We will now show by induction that for all i 2 [] we have that i Qi
clearly the case for i = 1 when S0 = ; and in general applying the inductive hypothesis we get:
i+1Yj=1✓1 
 ◆ 
i+1 = f (O)  f (Si) = i  (f (Si)  f (Si1))  i✓1 
◆ f (O)
Yj=1✓1 
◆ f (O)  e 1
P
f (S) ⇣1  e 1
j=1 ⇣j⌘ f (O)
P
fSi-1( ˆxi)  (1  )fSi-1(x?
i )
Ez⇠B(xi)[fSi-1(z)] = FSi-1(xi) ✓1 

Observe that the solution of the algorithm S respects f (S) = f (S) = f (O)    thus:
From Lemma 3.4  when k  plog n for every i 2 [  1] we have that w.p. 1  4/ log(n): 3
Therefore by a union bound  with probability 1  o(1)  we have that ⇣i  (1  ) for all i 2 []. In
particular  1

2◆ fSi-1(x?
i )
Thus  E[⇣i+1]  (1  /2)  and by Chernoff when > plog n we get 1
P
i=1 ⇣i  (1  ) w.p. at
least 1  exp(2/8). Therefore  in both cases  when k  plog n and when k  plog n we have
P
j=1 ⇣j  (1  ) w.p. 1  o(1). With 1 this implies f (S)  (1  1/e  )f (O).
Constant k and information theoretic lower bounds. For any constant  a single iteration of a
minor modiﬁcation of SM-GREEDY sufﬁces. In Appendix B.1 we show an approximation arbitrarily
close to 1 1/k w.h.p. and 1 1/(k + 1) in expectation. For k = 1 this is arbitrarily close to 1/2. In
Appendix D we show nearly matching lower bounds  and in particular that no randomized algorithm
can obtain an approximation ratio better than 1/2 + o(1) when k = 1  and that it is impossible to
obtain an approximation better than (2k  1)/2k + O(1/pn) for the optimal set of size k.
Theorem 3.6. For any non-negative monotone submodular function there is a deterministic
polynomial-time algorithm which optimizes the function under a cardinality constraint k  3
and obtains an approximation ratio that is arbitrarily close to 1 1/e with probability 1 o(1) using
access to an approximate oracle. For k  2 there is a randomized algorithm whose approximation
ratio is arbitrarily close to 1  1/e  in expectation over the randomization of the algorithm. For
k = 1 the algorithm achieves a 1/2 approximation in expectation  and no randomized algorithm can
achieve an approximation better than 1/2 + o(1)  in expectation.

j=1 ⇣j  (1  ). Otherwise  when k > plog n from Lemma 2.1:
P

that 1

⇣j



3W.l.o.g we assume that in every iteration fSi-1 (x?

) to apply Lemma 3.4. Since  2 ⌦(1/✏) 
k 2 ⌦(1/✏2)  and f (S)  OPT  ignoring iterations where this does not hold costs ✏OPT for a small ﬁxed .

i ) 2 ⌦( f (Si-1)

k

7

4 Approximation Algorithm for Matroids

For intersection of matroids F the algorithm from the Section 3 is generalized as described below.
Algorithm 2 SM-MATROID-GREEDY
Input: intersection of matroids F  precision ✏> 0  c 56
1: S ;  X N
2: while X 6= S do
3: X X \ {x : S [ x /2F}
˜F (S [ b)
4:
˜f (S [ z)
5:
6:
7: end while
8: return S

x argmaxb:|b|=c
ˆx argmaxz2B(x)
S S [ ˆx

✏

The analysis of the algorithm uses the lemma below  which is a generalization of the classic result
of [NWF78a]. The proof can be found in the Appendix.
Lemma 4.1. Let O be the optimal solution  k = |O|  and for every iteration i of SM-MATROID-
GREEDY let Si be the set of elements selected and x?

k

i 2 argmax|z|=c fSi-1(z). Then:
cXi=1

fSi(x?
i )

f (O)  (P + 1)

Theorem 4.2. Let F denote the intersection of P  1 matroids on the ground set N  and f : 2N ! R
be a non-negative monotone submodular function. Then with probability 1 o(1) the SM-MATROID-
GREEDY algorithm returns a set S 2F s.t.:

f (S) 

1  ✏
P + 1

OPT

Proof Sketch. If the rank of the matroid is O(1/✏2) we can simply apply the case of small k as in the
previous section. Otherwise  assume the rank is at least ⌦(1/✏2) Let  = k
c   Si = {ˆx1  . . .   ˆxi} be
current solutions of bundles of size c at iteration i 2 [] of the algorithm  and let x?
i be the optimal
i = argmaxb:|b|c fSi1(b) . In every iteration i 2 []  similar to the
bundle at iteration i  i.e. x?
proof of Theorem 3.5  since we choose the set whose value is maximal in BSi-1(xi) we have:

where ⇣i is a random variable with mean (1  

f (S) =

⇣ifSi-1(x?
i )

fSi-1( ˆxi)  ⇣ifSi-1(x?
i )
2 ). Therefore:
Xi=1
Xi=1
fSi-1( ˆxi)  (1  )fSi-1(x?
i )

fi-1( ˆxi) 

From Lemma 3.4  when k  plog n for every i 2 [  1] we have that w.p. 1  4/ log(n):

Therefore by a union bound  with probability 1  o(1)  we have that ⇣i  (1  ) for all i 2 [].
Otherwise  when k > plog n we apply a Chernoff bound. We get that with probability 1  o(1):

f (S) 

⇣ifSi-1(x?

i )  (1  )

Xi=1

fSi-1(x?
i )

Xi=1

From Lemma 4.1 this implies the result.

Acknowledgements. A.H. is supported by 1394/16 and by a BSF grant. Y.S. is supported by NSF
grant CAREER CCF 1452961  NSF CCF 1301976  BSF grant 2014389  NSF USICCS proposal
1540428  a Google Research award  and a Facebook research award.

8

References

[Ang88] Dana Angluin. Queries and concept learning. Machine Learning  2(4):319–342  1988.

[AS04] Alexander A. Ageev and Maxim Sviridenko. Pipage rounding: A new method of
constructing algorithms with proven performance guarantee. J. Comb. Optim.  8(3) 
2004.

[BDF+10] D. Buchfuhrer  S. Dughmi  H. Fu  R. Kleinberg  E. Mossel  C. H. Papadimitriou 
M. Schapira  Y. Singer  and C. Umans. Inapproximability for VCG-based combinatorial
auctions. In SIAM-ACM Symposium on Discrete Algorithms (SODA)  pages 518–536 
2010.

[BF02] Nader H. Bshouty and Vitaly Feldman. On using extended statistical queries to avoid

membership queries. Journal of Machine Learning Research  2:359–395  2002.

[BFNS12] Niv Buchbinder  Moran Feldman  Joseph Naor  and Roy Schwartz. A tight linear time
(1/2)-approximation for unconstrained submodular maximization. In 53rd Annual IEEE
Symposium on Foundations of Computer Science  FOCS 2012  New Brunswick  NJ 
USA  October 20-23  2012  pages 649–658  2012.

[BFNS14] Niv Buchbinder  Moran Feldman  Joseph Naor  and Roy Schwartz. Submodular max-
imization with cardinality constraints.
In Proceedings of the Twenty-Fifth Annual
ACM-SIAM Symposium on Discrete Algorithms  SODA 2014  Portland  Oregon  USA 
January 5-7  2014  pages 1433–1452  2014.

[BH11] Maria-Florina Balcan and Nicholas J. A. Harvey. Learning submodular functions. In
Proceedings of the 43rd ACM Symposium on Theory of Computing  STOC 2011  San
Jose  CA  USA  6-8 June 2011  pages 793–802  2011.

[BMKK14] Ashwinkumar Badanidiyuru  Baharan Mirzasoleiman  Amin Karbasi  and Andreas
Krause. Streaming submodular maximization: massive data summarization on the ﬂy.
In The 20th ACM SIGKDD International Conference on Knowledge Discovery and
Data Mining  KDD ’14  New York  NY  USA - August 24 - 27  2014  pages 671–680 
2014.

[BSS10] D. Buchfuhrer  M. Schapira  and Y. Singer. Computation and incentives in combinatorial

public projects. In EC  pages 33–42  2010.

[CCPV07] Gruia Calinescu  Chandra Chekuri  Martin Pál  and Jan Vondrák. Maximizing a sub-
modular set function subject to a matroid constraint. In Integer programming and
combinatorial optimization  pages 182–196. Springer  2007.

[CE11] Chandra Chekuri and Alina Ene. Approximation algorithms for submodular multiway
partition. In IEEE 52nd Annual Symposium on Foundations of Computer Science  FOCS
2011  Palm Springs  CA  USA  October 22-25  2011  pages 807–816  2011.

[CE16] C.P. Chambers and F. Echenique. Revealed Preference Theory. Econometric Society

Monographs. Cambridge University Press  2016.

[CHHK18] Lin Chen  Christopher Harshaw  Hamed Hassani  and Amin Karbasi. Projection-free
online optimization with stochastic gradient: From convexity to submodularity. In
Proceedings of the 35th International Conference on Machine Learning  ICML 2018 
Stockholmsmässan  Stockholm  Sweden  July 10-15  2018  pages 813–822  2018.

[CJV15] Chandra Chekuri  T. S. Jayram  and Jan Vondrák. On multiplicative weight updates for
concave and submodular function maximization. In Proceedings of the 2015 Conference
on Innovations in Theoretical Computer Science  ITCS 2015  Rehovot  Israel  January
11-13  2015  pages 201–210  2015.

[DFK11] Shahar Dobzinski  Hu Fu  and Robert D. Kleinberg. Optimal auctions with correlated

bidders are easy. In STOC  pages 129–138  2011.

9

[DK14] J. Djolonga and A. Krause. From MAP to marginals: Variational inference in bayesian
submodular models. In Advances in Neural Information Processing Systems (NIPS) 
2014.

[DLN08] Shahar Dobzinski  Ron Lavi  and Noam Nisan. Multi-unit auctions with budget limits.

In FOCS  2008.

[DNS05] Shahar Dobzinski  Noam Nisan  and Michael Schapira. Approximation algorithms for
combinatorial auctions with complement-free bidders. In STOC  pages 610–618  2005.

[DRY11] Shaddin Dughmi  Tim Roughgarden  and Qiqi Yan. From convex optimization to
randomized mechanisms: toward optimal combinatorial auctions. In STOC  pages
149–158  2011.

[DS06] Shahar Dobzinski and Michael Schapira. An improved approximation algorithm for
combinatorial auctions with submodular bidders. In Proceedings of the seventeenth
annual ACM-SIAM symposium on Discrete algorithm  pages 1064–1073. Society for
Industrial and Applied Mathematics  2006.

[DV12] Shahar Dobzinski and Jan Vondrák. The computational complexity of truthfulness in

combinatorial auctions. In EC  pages 405–422  2012.

[Fei98] Uriel Feige. A threshold of ln n for approximating set cover. Journal of the ACM

(JACM)  45(4):634–652  1998.

[Fel09] Vitaly Feldman. On the power of membership queries in agnostic learning. Journal of

Machine Learning Research  10:163–182  2009.

[FFI+15] Uriel Feige  Michal Feldman  Nicole Immorlica  Rani Izsak  Brendan Lucier  and Vasilis
Syrgkanis. A unifying hierarchy of valuations with complements and substitutes. In
AAAI  pages 872–878  2015.

[FMV11] Uriel Feige  Vahab S Mirrokni  and Jan Vondrak. Maximizing non-monotone submodu-

lar functions. SIAM Journal on Computing  40(4):1133–1153  2011.

[FNW78] Marshall L Fisher  George L Nemhauser  and Laurence A Wolsey. An analysis of

approximations for maximizing submodular set functions—II. Springer  1978.

[FV06] Uriel Feige and Jan Vondrak. Approximation algorithms for allocation problems:
Improving the factor of 1-1/e. In Foundations of Computer Science  2006. FOCS’06.
47th Annual IEEE Symposium on  pages 667–676. IEEE  2006.

[GFK10] D. Golovin  M. Faulkner  and A. Krause. Online distributed sensor selection. In IPSN 

2010.

[GK10] R. Gomes and A. Krause. Budgeted nonparametric learning from data streams. In Int.

Conference on Machine Learning (ICML)  2010.

[GK11] D. Golovin and A. Krause. Adaptive submodularity: Theory and applications in active

learning and stochastic optimization. JAIR  42:427–486  2011.

[GKS90] Sally A. Goldman  Michael J. Kearns  and Robert E. Schapire. Exact identiﬁcation of
circuits using ﬁxed points of ampliﬁcation functions (abstract). In Proceedings of the
Third Annual Workshop on Computational Learning Theory  COLT 1990  University of
Rochester  Rochester  NY  USA  August 6-8  1990.  page 388  1990.

[HS] Thibaut Horel and Yaron Singer. Maximizing approximately submodular functions. In
Advances in Neural Information Processing Systems 29: Annual Conference on Neural
Information Processing Systems 2016.

[HS17] Avinatan Hassidim and Yaron Singer. Submodular optimization under noise. 2017.

COLT.

10

[HSK17] S. Hamed Hassani  Mahdi Soltanolkotabi  and Amin Karbasi. Gradient methods for
submodular maximization. In Advances in Neural Information Processing Systems 30:
Annual Conference on Neural Information Processing Systems 2017  4-9 December
2017  Long Beach  CA  USA  pages 5843–5853  2017.

[Jac94] Jeffrey C. Jackson. An efﬁcient membership-query algorithm for learning DNF with
respect to the uniform distribution.
In 35th Annual Symposium on Foundations of
Computer Science  Santa Fe  New Mexico  USA  20-22 November 1994  pages 42–53 
1994.

[JB11a] S. Jegelka and J. Bilmes. Approximation bounds for inference using cooperative cuts.

In Int. Conference on Machine Learning (ICML)  2011.

[JB11b] S. Jegelka and J. Bilmes. Submodularity beyond submodular energies: Coupling edges
in graph cuts. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 
pages 1897–1904  2011.

[KG07] A. Krause and C. Guestrin. Nonmyopic active learning of gaussian processes. an
exploration–exploitation approach. In Int. Conference on Machine Learning (ICML) 
2007.

[KKT03] D. Kempe  J. Kleinberg  and E. Tardos. Maximizing the spread of inﬂuence through
a social network. In ACM SIGKDD Conference on Knowledge Discovery and Data
Mining (KDD)  2003.

[KLMM05] Subhash Khot  Richard J Lipton  Evangelos Markakis  and Aranyak Mehta.

Inap-
proximability results for combinatorial auctions with submodular utility functions. In
Internet and Network Economics  pages 92–101. Springer  2005.

[KMVV13] Ravi Kumar  Benjamin Moseley  Sergei Vassilvitskii  and Andrea Vattani. Fast greedy

algorithms in mapreduce and streaming. In SPAA  2013.

[KOJ13] P. Kohli  A. Osokin  and S. Jegelka. A principled deep random ﬁeld for image seg-
mentation. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 
2013.

[LB11a] H. Lin and J. Bilmes. A class of submodular functions for document summarization. In

ACL/HLT  2011.

[LB11b] H. Lin and J. Bilmes. Optimal selection of limited vocabulary speech corpora. In Proc.

Interspeech  2011.

[LCSZ17] Qiang Li  Wei Chen  Xiaoming Sun  and Jialin Zhang. Inﬂuence maximization with
✏-almost submodular threshold functions. In Advances in Neural Information Processing
Systems 30: Annual Conference on Neural Information Processing Systems 2017  4-9
December 2017  Long Beach  CA  USA  pages 3804–3814  2017.

[LKG+07] J. Leskovec  A. Krause  C. Guestrin  C. Faloutsos  J. VanBriesen  and N. Glance. Cost-
effective outbreak detection in networks. In ACM SIGKDD Conference on Knowledge
Discovery and Data Mining (KDD)  2007.

[LMNS09] Jon Lee  Vahab S. Mirrokni  Viswanath Nagarajan  and Maxim Sviridenko. Non-
monotone submodular maximization under matroid and knapsack constraints. In Pro-
ceedings of the 41st Annual ACM Symposium on Theory of Computing  STOC 2009 
Bethesda  MD  USA  May 31 - June 2  2009  pages 323–332  2009.

[LSST13] Brendan Lucier  Yaron Singer  Vasilis Syrgkanis  and Éva Tardos. Equilibrium in

combinatorial public projects. In WINE  pages 347–360  2013.

[MHK18] Aryan Mokhtari  Hamed Hassani  and Amin Karbasi. Conditional gradient method for
stochastic submodular maximization: Closing the gap. In International Conference
on Artiﬁcial Intelligence and Statistics  AISTATS 2018  9-11 April 2018  Playa Blanca 
Lanzarote  Canary Islands  Spain  pages 1886–1895  2018.

11

[MSV08] Vahab S. Mirrokni  Michael Schapira  and Jan Vondrák. Tight information-theoretic
lower bounds for welfare maximization in combinatorial auctions. In Proceedings 9th
ACM Conference on Electronic Commerce (EC-2008)  Chicago  IL  USA  June 8-12 
2008  pages 70–77  2008.

[NW78] George L Nemhauser and Leonard A Wolsey. Best algorithms for approximating the
maximum of a submodular set function. Mathematics of operations research  3(3):177–
188  1978.

[NWF78a] G. L. Nemhauser  L. A. Wolsey  and M. L. Fisher. An analysis of approximations for

maximizing submodular set functions ii. Math. Programming Study 8  1978.

[NWF78b] George L Nemhauser  Laurence A Wolsey  and Marshall L Fisher. An analysis of ap-
proximations for maximizing submodular set functions—I. Mathematical Programming 
14(1):265–294  1978.

[PP11] Christos H. Papadimitriou and George Pierrakos. On optimal single-item auctions. In

STOC  pages 119–128  2011.

[PSS08] Christos H. Papadimitriou  Michael Schapira  and Yaron Singer. On the hardness of
being truthful. In 49th Annual IEEE Symposium on Foundations of Computer Science 
FOCS 2008  October 25-28  2008  Philadelphia  PA  USA  pages 250–259  2008.

[QSY+17] Chao Qian  Jing-Cheng Shi  Yang Yu  Ke Tang  and Zhi-Hua Zhou. Subset selection
under noise.
In Advances in Neural Information Processing Systems 30: Annual
Conference on Neural Information Processing Systems 2017  4-9 December 2017  Long
Beach  CA  USA  pages 3563–3573  2017.

[RLK11] M. Gomez Rodriguez  J. Leskovec  and A. Krause. Inferring networks of diffusion and

inﬂuence. ACM TKDD  5(4)  2011.

[SGK09] M. Streeter  D. Golovin  and A. Krause. Online learning of assignments. In Advances

in Neural Information Processing Systems (NIPS)  2009.

[SS95] Eli Shamir and Clara Schwartzman. Learning by extended statistical queries and its
relation to PAC learning. In Computational Learning Theory: Eurocolt ’95  pages
357–366. Springer-Verlag  1995.

[SS08] Michael Schapira and Yaron Singer. Inapproximability of combinatorial public projects.

In WINE  pages 351–361  2008.

[VCZ11] Jan Vondrák  Chandra Chekuri  and Rico Zenklusen. Submodular function maximization
via the multilinear relaxation and contention resolution schemes. In Proceedings of
the Forty-third Annual ACM Symposium on Theory of Computing  STOC ’11  pages
783–792  New York  NY  USA  2011. ACM.

[Von08] Jan Vondrák. Optimal approximation for the submodular welfare problem in the value

oracle model. In STOC  pages 67–74  2008.

12

,Yaron Singer
Avinatan Hassidim