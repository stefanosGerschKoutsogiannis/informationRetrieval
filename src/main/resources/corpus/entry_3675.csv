2009,Nash Equilibria of Static Prediction Games,The standard assumption of identically distributed training and test data can be violated when an adversary can exercise some control over the generation of the test data. In a prediction game  a learner produces a predictive model while an adversary may alter the distribution of input data. We study single-shot prediction games in which the cost functions of learner and adversary are not necessarily antagonistic. We identify conditions under which the prediction game has a unique Nash equilibrium  and derive algorithms that will find the equilibrial prediction models. In a case study  we explore properties of Nash-equilibrial prediction models for email spam filtering empirically.,Nash Equilibria of Static Prediction Games

Michael Br¨uckner

Department of Computer Science
University of Potsdam  Germany

Tobias Scheffer

Department of Computer Science
University of Potsdam  Germany

mibrueck@cs.uni-potsdam.de

scheffer@cs.uni-potsdam.de

Abstract

The standard assumption of identically distributed training and test data is violated
when an adversary can exercise some control over the generation of the test data.
In a prediction game  a learner produces a predictive model while an adversary
may alter the distribution of input data. We study single-shot prediction games in
which the cost functions of learner and adversary are not necessarily antagonistic.
We identify conditions under which the prediction game has a unique Nash equi-
librium  and derive algorithms that will ﬁnd the equilibrial prediction models. In a
case study  we explore properties of Nash-equilibrial prediction models for email
spam ﬁltering empirically.

1 Introduction

The assumption that training and test data are governed by identical distributions underlies many
popular learning mechanisms. In a variety of applications  however  data at application time are
generated by an adversary whose interests are in conﬂict with those of the learner. In computer
and network security  fraud detection  and drug design  the distribution of data is changed – by a
malevolent individual or under selective pressure – in response to the predictive model.
An adversarial interaction between learner and data generator can be modeled as a single-shot game
in which one player controls the predictive model whereas the other player exercises some control
over the distribution of the input data. The optimal action for either player generally depends on
both players’ moves.
The minimax strategy minimizes the costs under the worst possible move of the opponent. This
strategy is motivated for an opponent whose goal is to inﬂict the highest possible costs on the learner;
it can also be applied when no information about the interests of the adversary is available. Lanckriet
et al. [1] study the so called Minimax Probability Machine. This classiﬁer minimizes the maximal
probability of misclassifying new instances for a given mean and covariance matrix of each class.
El Ghaoui et al. [2] study a minimax model for input data that are known to lie within some hyper-
rectangle. Their solution minimizes the worst-case loss over all possible choices of the data in these
intervals. Similarly  minimax solutions to classiﬁcation games in which the adversary deletes input
features or performs a feature transformation have been studied [3  4  5]. These studies show that
the minimax solution outperforms a learner that naively minimizes the costs on the training data
without taking the adversary into account.
When rational opponents aim at minimizing their personal costs  then the minimax solution is overly
pessimistic. A Nash equilibrium is a pair of actions chosen such that no player gains a beneﬁt by
unilaterally selecting a different action. If a game has a unique Nash equilibrium  it is the strongest
available concept of an optimal strategy in a game against a rational opponent. If  however  multiple
equilibria exist and the players choose their action according to distinct ones  then the resulting
combination may be arbitrarily disadvantageous for either player. It is therefore interesting to study
whether adversarial prediction games have a unique Nash equilibrium.

1

We study games in which both players – learner and adversary – have cost functions that consist of
data-dependent loss and regularizer. Contrasting prior results  we do not assume that the players’
cost functions are antagonistic. As an example  consider that a spam ﬁlter may minimize the error
rate whereas a spam sender may aim at maximizing revenue solicited by spam emails. These criteria
are conﬂicting  but not the exact negatives of each other. We study under which conditions unique
Nash equilibria exist and derive algorithms for identifying them.
The rest of this paper is organized as follows. Section 2 introduces the problem setting and deﬁnes
action spaces and cost functions. We study the existence of a unique Nash equilibrium and derive an
algorithm that ﬁnds it under deﬁned conditions in Section 3. Section 4 discusses antagonistic loss
functions. For this case  we derive an algorithm that ﬁnds a unique Nash equilibrium whenever it
exists. Section 5 reports on experiments on email spam ﬁltering; Section 6 concludes.

(cid:81)n

2 Modeling the Game
We study prediction games between a learner (v = +1) and an adversary (v = −1). We consider
static inﬁnite games. Static or single-shot game means that players make decisions simultaneously;
neither player has information about the opponent’s decisions.
Inﬁnite refers to continuous cost
functions that leave players with inﬁnitely many strategies to choose from. We constrain the players
to select pure (i.e.  deterministic) strategies. Mixed strategies and extensive-form games such as
(cid:81)n
Stackelberg  Cournot  Bertrand  and repeated games are not within the scope of this work.
Both players can access an input matrix of training instances X with outputs y  drawn according
i=1 q(xi  yi). The learner’s action a+1 ∈ A+1 now is
to a probability distribution q(X  y) =
to choose parameters of a linear model ha+1(x) = a+1
Tx. Simultaneously  the adversary chooses
a transformation function φa−1 that maps any input matrix X to an altered matrix φa−1(X). This
transformation induces a transition from input distribution q to test distribution qtest with q(X  y) =
i=1 qtest(φa−1(X)i  yi). Our main result uses a model that implements
qtest(φa−1(X)  y) =
transformations as matrices a−1 ∈ A−1 ⊆ Rm×n. Transformation φa−1(X) = X + a−1 adds
perturbation matrix a−1 to input matrix X  i.e.  input pattern xi is subjected to a perturbation vector
a−1 i. If  for instance  inputs are word vectors  the perturbation matrix adds and deletes words.
The possible moves a = [a+1  a−1] constitute the joint action space A = A+1 × A−1 which is
assumed to be nonempty  compact  and convex. Action spaces Av are parameters of the game. For
instance  in spam ﬁltering it is appropriate to constrain A−1 such that perturbation matrices contain
zero vectors for non-spam messages; this reﬂects that spammers can only alter spam messages.
Each pair of actions a incurs costs of θ+1(a) and θ−1(a)  respectively  for the players. Each player
has an individual loss function (cid:96)v(y(cid:48)  y) where y(cid:48) is the value of decision function ha+1 and y
is the true label. Section 4 will discuss antagonistic loss functions (cid:96)+1 = −(cid:96)−1. However  our
main contribution in Section 3 regards non-antagonistic loss functions. For instance  a learner may
minimize the zero-one loss whereas the adversary may focus on the lost revenue.
Both players aim at minimizing their loss over the test distribution qtest. But  since q and con-
sequently qtest are unknown  the cost functions are regularized empirical loss functions over the
sample φa−1(X) which reﬂects test distribution qtest. Equation 1 deﬁnes either player’s cost func-
tion as player-speciﬁc loss plus regularizer. The learner’s regularizer Ωa+1 will typically regularize
the capacity of ha+1. Regularizer Ωa−1 controls the amount of distortion that the adversary may
inﬂict on the data and thereby the extent to which an information payload has to be preserved.

n(cid:88)

θv(av  a−v) =

(cid:96)v(ha+1(φa−1(X)i)  yi) + Ωav

(1)

i=1

Each player’s cost function depends on the opponent’s parameter. In general  there is no value av
that maximizes θv(av  a−v) independently of the opponent’s choice of a−v. The minimax solution
arg minav maxa−v θv(av  a−v) minimizes the costs under the worst possible move of the opponent.
This solution is optimal for a malicious opponent whose goal is to inﬂict maximally high costs on
the learner. In absence of any information on the opponent’s goals  the minimax solution still gives
the lowest upper bound on the learner’s costs over all possible strategies of the opponent.
If both players – learner and adversary – behave rationally in the sense of minimizing their personal
costs  then the Nash equilibrium is the strongest available concept of an optimal choice of av. A

2

Nash equilibrium is deﬁned as a pair of actions a∗ = [a∗
from changing the strategy unilaterally. That is  for both players v ∈ {−1  +1} 

+1  a∗

−1] such that no player can beneﬁt

θv(a∗

v  a∗

−v) = min
av∈Av

θv(av  a∗

−v).

(2)

The Nash equilibrium has several catches. Firstly  if the adversary behaves irrationally in the sense
of inﬂicting high costs on the other player at the expense of incurring higher personal costs  then
choosing an action according to the Nash equilibrium may result in higher costs than the minimax
solution. Secondly  a game may not have an equilibrium point. If an equilibrium point exists  the
game may thirdly possess multiple equilibria. If a∗ = [a∗
−1] are distinct
equilibria  and each player decides to act according to one of them  then a combination [a∗
−v]
may be a poor joint strategy and may give rise to higher costs than a worst-case solution. However 
if a unique Nash equilibrium exists and both players seek to minimize their individual costs  then
the Nash equilibrium is guaranteed to be the optimal move.

−1] and a(cid:48) = [a(cid:48)

+1  a∗

+1  a(cid:48)

v  a(cid:48)

3 Solution for Convex Loss Functions

In this section  we study the existence of a unique Nash equilibrium of prediction games with
cost functions as in Equation 1. We derive an algorithm that identiﬁes the unique equilibrium if
sufﬁcient conditions are met. We consider regularized player-speciﬁc loss functions (cid:96)v(y(cid:48)  y) which
are not assumed to satisfy the antagonicity criterion (cid:96)+1 = −(cid:96)−1. Both loss functions are  however 
required to be convex and twice differentiable  and we assume strictly convex regularizers Ωav
such as the l2-norm regularizer. Player- and instance-speciﬁc costs may be attached to the loss
functions; however  we omit such cost factors for greater notational harmony. This section’s main
result is that if both loss functions are monotonic in y(cid:48) with different monotonicities – that is  one is
monotonically increasing  and one is decreasing for any ﬁxed y – then the game has a unique Nash
equilibrium that can be found efﬁciently.

Theorem 1. Let the cost functions be deﬁned as in Equation 1 with strictly convex regularizers Ωav 
let action spaces Av be nonempty  compact  and convex subsets of ﬁnite-dimensional Euclidean
If for any ﬁxed y  both loss functions (cid:96)v(y(cid:48)  y) are monotonic in y(cid:48) ∈ R with distinct
spaces.
monotonicity  convex in y(cid:48)  and twice differentiable in y(cid:48)  then a unique Nash equilibrium exists.

The players’

regularizers Ωav

functions
Proof.
(cid:96)v(ha+1(φa−1(X)i)  yi) are convex and twice differentiable in av ∈ Av for any ﬁxed a−v ∈ A−v.
Hence  both cost functions θv are continuously differentiable and strictly convex  and according to
Theorem 4.3 in [6]  at least one Nash equilibrium exists. As each player has an own nonempty 
compact  and convex action space Av  Theorem 2 of [7] applies as well; that is  if function

are strictly convex 

and both loss

σr(a) = rθ+1(a+1  a−1) + (1 − r)θ−1(a+1  a−1)

(3)

is diagonally strictly convex in a for some ﬁxed 0 < r < 1  then a unique Nash equilibrium exists.
A sufﬁcient condition for σr(a) to be diagonally strictly convex is that matrix Jr(a) in Equation 4
is positive deﬁnite for any a ∈ A (see Theorem 6 in [7]). This matrix

(cid:183)

(cid:184)

Jr(a) =

r∇2

(1 − r)∇2

a+1a+1 θ+1(a)

a−1a+1θ−1(a)

r∇2

(1 − r)∇2

a+1a−1θ+1(a)

a−1a−1θ−1(a)

(4)

(5)

is the Jacobian of the pseudo-gradient of σr(a)  that is 

(cid:183)

gr(a) =

r∇a+1 θ+1(a)

(1 − r)∇a−1θ−1(a)

(cid:184)

.

We want to show that Jr(a) is positive deﬁnite for some ﬁxed r if both loss functions (cid:96)v(y(cid:48)  y)
v(y(cid:48)  y) be the
have distinct monotonicity and are convex in y(cid:48). Let (cid:96)(cid:48)
second derivative of (cid:96)v(y(cid:48)  y) with respect to y(cid:48). Let Ai denote the matrix where the i-th col-
umn is a+1 and all other elements are zero  let Γv be the diagonal matrix with diagonal elements
γv i = (cid:96)(cid:48)(cid:48)
v(ha+1(φa−1(X)i)  yi). Using these deﬁni-

v(ha+1(φa−1(X)i)  yi)  and we deﬁne µv i = (cid:96)(cid:48)

v(y(cid:48)  y) be the ﬁrst and (cid:96)(cid:48)(cid:48)

3

tions  the Jacobian of Equation 4 can be rewritten 

Jr(a) =

rΓ+1

(1 − r)Γ−1

rΓ+1

(1 − r)Γ−1

(cid:183)



0
A1

0

 φa−1 (X)


+

...

...
...
0
An
r∇2Ωa+1
(1 − r)µ−1 1I

(1 − r)µ−1 nI

rµ+1 1I

(1 − r)∇2Ωa−1

...

0

. . .
. . .
...
. . .

0

(cid:184) φa−1 (X)
 .

0

0

...

...

rµ+1 nI



T

0
A1

...

An

(6)

(1 − r)∇2Ωa−1





The eigenvalues of the inner matrix of the ﬁrst summand in Equation 6 are rγ+1 i +(1− r)γ−1 i and
zero. Loss functions (cid:96)v are convex in y(cid:48)  that is  both second derivatives (cid:96)(cid:48)(cid:48)
v(y(cid:48)  y) are non-negative
for any y(cid:48) and consequently rγ+1 i + (1 − r)γ−1 i ≥ 0. Hence  the ﬁrst summand of Jacobian
Jr(a) is positive semi-deﬁnite for any choice of 0 < r < 1. Additionally  we can decompose the
regularizers’ Hessians as follows:

(7)
where λv is the smallest eigenvalue of ∇2Ωav. As the regularizers are strictly convex  λv > 0 and
the second summand in Equation 7 is positive semi-deﬁnite. Hence  it sufﬁces to show that matrix

∇2Ωav = λvI + (∇2Ωav − λvI) 

rλ+1I

(1 − r)µ−1 1I

(1 − r)µ−1 nI

...

rµ+1 1I

(1 − r)λ−1I

...

0

. . .
. . .
...
. . .

rµ+1 nI

0

...

(1 − r)λ−1I

(8)

(cid:182)

(cid:181)

1
2

(cid:113)

is positive deﬁnite. We derive the eigenvalues of this matrix which assume only three different
values; these are (1 − r)λ−1 and

rλ+1 + (1 − r)λ−1 ±

(rλ+1 − (1 − r)λ−1)2 + 4r(1 − r)µT

(9)
Eigenvalue (1− r)λ−1 is positive by deﬁnition. The others are positive if the value under the square
root is non-negative and less than (rλ+1 + (1 − r)λ−1)2. The scalar product b = µT
+1µ−1 is non-
positive as both loss functions (cid:96)v(y(cid:48)  y) are monotonic in y(cid:48) with distinct monotonicity  i.e.  both
derivatives have a different sign for any y(cid:48) ∈ R and consequently b ≤ 0. This implies that the
value under the square root is less or equal to (rλ+1 − (1 − r)λ−1)2 < (rλ+1 + (1 − r)λ−1)2. In
addition  b is bounded from below as action spaces Av  and therefore the value of ha+1(φa−1(X)i) 
+1µ−1 be such a lower bound with −∞ < b ≤ 0. We solve for r such
is bounded. Let b = inf a∈A µT
that the value under the square root in Equation 9 attains a non-negative value  that is 

+1µ−1

.

(cid:113)

(cid:113)

(cid:113)

0 < r ≤ (λ+1 + λ−1)λ−1 − 2b − 2

(λ+1 + λ−1)2 − 4b

b2 − λ+1λ−1b

(10)

or alternatively

(λ+1 + λ−1)λ−1 − 2b + 2

b2 − λ+1λ−1b

(11)
For any λ+1  λ−1 > 0 there are values r that satisfy Inequality 10 or 11 because  for any ﬁxed b ≤ 0 

(λ+1 + λ−1)2 − 4b

≤ r < 1.

0 < (λ+1 + λ−1)λ−1 − 2b ± 2

b2 − λ+1λ−1b < (λ+1 + λ−1)2 − 4b.

(12)

For such r all eigenvalues in Equation 9 are strictly positive which completes the proof.
According to Theorem 1  a unique Nash equilibrium exists for suitable loss functions such as the
squared hinge loss  logistic loss  etc. To ﬁnd this equilibrium  we make use of the weighted Nikaido-
Isoda function (Equation 13). Intuitively  Ψrv(a  b) quantiﬁes the weighted sum of the relative cost
savings that the players can enjoy by changing from strategy av to strategy bv while their opponent
continues to play a−v. Equation 14 deﬁnes the value function Vrv(a) as the weighted sum of greatest

4

possible cost savings attainable by changing from a to any strategy unilaterally. By these deﬁnitions 
a∗ is a Nash equilibrium if  and only if  Vrv(a∗) is a global minimum of the value function with
Vrv(a∗) = 0 for any ﬁxed weights r+1 = r and r−1 = 1 − r  where 0 < r < 1.
rv(θv(av  a−v) − θv(bv  a−v))

Ψrv(a  b) =

(cid:88)

(13)

v∈{+1 −1}

Vrv(a) = max
b∈A

Ψrv(a  b)

(14)

To ﬁnd this global minimum of Vrv(a) we make use of Corollary 3.4 of [8]. The weights rv are
ﬁxed scaling factors of the players’ objectives which do not affect the Nash equilibrium in Equa-
tion 2; however  these weights ensure the main condition of Corollary 3.4  that is  the positive

deﬁniteness of the Jacobian Jr(a) in Equation 4. According to this corollary  vector d = (cid:98)b − a is
a descent direction for the value function at any position a  where(cid:98)b is the maximizing argument
(cid:98)b = arg maxb∈A Ψrv(a  b). In addition  the convexity of A ensures that any point a + td with
t ∈ [0  1] (i.e.  a point between a and(cid:98)b) is a valid pair of actions.

Algorithm 1 Nash Equilibrium of Games with Convex Loss Functions
Require: Cost functions θv as deﬁned in Equation 1 and action spaces Av.
1: Select initial a0 ∈ A+1 × A−1  set k := 0  and choose r that satisﬁes Inequality 10 or 11.
2: repeat
3:
4:
5:
6:
7: until (cid:107)ak − ak−1(cid:107) ≤ .

Set bk := arg maxb∈A+1×A−1 Ψrv(ak  b) where Ψrv is deﬁned in Equation 13.
Set dk := bk − ak.
Find maximal step size tk ∈ {2−l : l ∈ N} with Vrv(ak + tkdk) ≤ Vrv(ak) − (cid:107)tkdk(cid:107)2.
Set ak+1 := ak + tkdk and k := k + 1.

Algorithm 1 exploits these properties and ﬁnds the global minimum of Vrv and thereby the unique
Nash equilibrium  under the preconditions of Theorem 1. Convergence follows from the fact that if
in the k-th iteration dk = 0  then ak is a Nash equilibrium which is unique according to Theorem 1.
If dk (cid:54)= 0  then dk is a descent direction of Vrv at position ak. Together with term (cid:107)tkdk(cid:107)2 
this ensures Vrv(ak+1) < Vrv(ak)  and as value function Vrv is bounded from below  Algorithm 1
converges to the global minimum of Vrv. Note that r only controls the convergence rate  but has no
inﬂuence on the solution. Any value of r that satisﬁes Inequality 10 or 11 ensures convergence.

4 Solution for Antagonistic Loss Functions

Algorithm 1 is guaranteed to identify the unique equilibrium if the loss functions are convex  twice
differentiable  and of distinct monotonicities. We will now study the case in which the learner’s cost
function is continuous and convex  and the adversary’s loss function is antagonistic to the learner’s
loss  that is  (cid:96)+1 = −(cid:96)−1. We abstain from making assumptions about the adversary’s regularizers.
Because of the regularizers  the game is still not a zero-sum game. In this setting  a unique Nash
equilibrium cannot be guaranteed to exist because the adversary’s cost function is not necessarily
strictly convex. However  an individual game may still possess a unique Nash equilibrium  and we
can derive an algorithm that identiﬁes it whenever it exists.
The symmetry of the loss functions simpliﬁes the players’ cost functions in Equation 1 to

n(cid:88)
θ−1(a−1  a+1) = − n(cid:88)

θ+1(a+1  a−1) =

i=1

(cid:96)+1(ha+1(φa−1(X)i)  yi) + Ωa+1  

(cid:96)+1(ha+1(φa−1(X)i)  yi) + Ωa−1 .

(15)

(16)

i=1

Even though the loss functions are antagonistic  the cost functions in Equations 15 and 16 are not 
unless the player’s regularizers are antagonistic as well. Hence  the game is not a zero-sum game.
However  according to Theorem 2  if the game has a unique Nash equilibrium  then this equilibrium
is a minimax solution of the zero-sum game deﬁned by the joint cost function of Equation 17.

5

If

Theorem 2.
and 16 has a unique Nash equilibrium a∗ 
arg mina+1 maxa−1 θ0(a+1  a−1) where

the game with cost

functions θ+1 and θ−1 deﬁned in Equations 15
then this equilibrium also satisﬁes a∗ =

(cid:88)n

i=1

θ0(a+1  a−1) =

(cid:96)+1(ha+1(φa−1(X)i)  yi) + Ωa+1 − Ωa−1.

(17)

The proof can be found in the appendix. As a consequence of Theorem 2  we can identify the unique
Nash equilibrium of the game with cost functions θ+1 and θ−1  if it exists  by ﬁnding the minimax
solution of the game with joint cost function θ0. The minimax solution is given by

a∗
+1 = arg min

(18)

max

a+1∈A+1

a−1∈A−1

θ0(a+1  a−1).

To solve this optimization problem  we deﬁne(cid:98)θ0(a+1) = θ0(a+1 (cid:98)a−1) to be the function of a+1
where(cid:98)a−1 is set to the value(cid:98)a−1 = arg maxa−1 θ0(a+1  a−1). Since cost function θ0 is continuous
in its arguments  convex in a+1  and A−1 is a compact set  Danskin’s Theorem [9] implies that(cid:98)θ0
The signiﬁcance of Danskin’s Theorem is that when calculating the gradient ∇a+1θ0(a+1 (cid:98)a−1) at
position a+1  argument(cid:98)a−1 acts as a constant in the derivative instead of as a function of a+1.
The convexity of (cid:98)θ0(a+1) suggests the gradient descent method implemented in Algorithm 2. It

∇(cid:98)θ0(a+1) = ∇a+1θ0(a+1 (cid:98)a−1).

is convex in a+1 with gradient

identiﬁes the unique Nash equilibrium of a game with antagonistic loss functions  if it exists  by
ﬁnding the minimax solution of the game with joint cost function θ0.

(19)

Algorithm 2 Nash Equilibrium of Games with Antagonistic Loss Functions
Require: Joint cost function θ0 as deﬁned in Equation 17 and action spaces Av.
1: Select initial a0
2: repeat
3:

+1 ∈ A+1 and set k := 0.

Set ak−1 := arg maxa−1∈A−1 θ0(ak
Set dk := −∇ak
Find maximal step size tk ∈ {2−l : l ∈ N} with

+1  ak−1).

+1  a−1).

θ0(ak

+1

4:

5:

θ0(ak

+1 + tkdk  ak−1) ≤ θ0(ak

+1  ak−1) − (cid:107)tkdk(cid:107)2.

+1 := ak

+1 + tkdk and k := k + 1.

+1 to the admissible set A+1  if necessary.

Set ak+1
Project ak

6:
7:
8: until (cid:107)ak

+1 − ak−1

+1 (cid:107) ≤ 

A minimax solution arg mina+1 maxa−1 θ+1(a+1  a−1) of the learner’s cost function minimizes
the learner’s costs when playing against the most malicious opponent; for instance  Invar-SVM [4]
ﬁnds such a solution. By contrast  the minimax solution arg mina+1 maxa−1 θ0(a+1  a−1) of the
joint cost function as deﬁned in Equation 17 constitutes a Nash equilibrium of the game with cost
functions θ+1 and θ−1  deﬁned in Equations 15 and 16. It minimizes the costs for each of two players
that seek their personal advantage. Algorithmically  Invar-SVM and Algorithm 2 are very similar;
the main difference lies in the optimization criteria and the resulting properties of the solution.

5 Experiments

We study the problem of email spam ﬁltering where the learner tries to identify spam emails while
the adversary conceals spam messages in order to penetrate the ﬁlter. Our goal is to explore the
relative strengths and weaknesses of the proposed Nash models for antagonistic and non-antagonistic
loss functions and existing baseline methods. We compare a regular SVM  logistic regression  SVM
with Invariances (Invar-SVM  [4])  the Nash equilibrium for antagonistic loss functions found by
identifying the minimax solution of the joint cost function (Minimax  Algorithm 2)  and the Nash
equilibrium for convex loss functions (Nash  Algorithm 1).

6

Figure 1: Adversary’s regularization parameter and AUC on test data (private emails).

2 (cid:107)av(cid:107)2

2 xi ≤ a−1 i ≤ 1

We use the logistic loss as the learner’s loss function (cid:96)+1(h(x)  y) = log(1 + e−yh(x)) for the
Minimax and the Nash model. Consequently  the adversary’s loss for the Minimax solution is the
negative loss of the learner. In the Nash model  we choose (cid:96)−1(h(x)  y) = log(1 + eyh(x)) which is
a convex approximation of the adversary’s zero-one loss  that is  correct predictions by the learner
incur high costs for the adversary. We use the additive transformation model φa−1(X)i = xi +a−1 i
as deﬁned in Section 2. For spam emails xi  we impose box constraints − 1
2 xi on
the adversary’s parameters; for non-spam we set a−1 i = 0. That is  the spam sender can only
transform spam emails. This model is equivalent to the component-wise scaling model [4] with
scaling factors between 0.5 and 1.5  and ensures that the adversary’s action space is nonempty 
compact  and convex. We use l2-norm regularizers for both players  that is  Ωav = λv
2 where
λv is the regularization parameter of player v. For the Nash model we set r to the mean of the
interval deﬁned by Inequality 11  where b = − n
4 is a lower bound for the chosen logistic loss and
regularization parameters λv are identical to the smallest eigenvalues of ∇2Ωav.
We use two email corpora: the ﬁrst contains 65 000 publicly available emails received between 2000
and 2002 from the Enron corpus  the SpamAssassin corpus  Bruce Guenter’s spam trap  and several
mailing lists. The second contains 40 000 private emails received between 2000 and 2007. All
emails are binary word vectors of dimensionality 329 518 and 160 981  respectively. The emails are
sorted chronologically and tagged with label  date  and size. The preprocessed corpora are available
from the authors. We cannot use a standard TREC corpus because there the delivery dates of the
spam messages have been fabricated  and our experiments require the correct chronological order.
Our evaluation protocol is as follows. We use the 6 000 oldest instances as training portion and
set the remaining emails aside as test instances. We use the area under the ROC curve as a fair
evaluation metric that is adequate for the application; error bars indicate the standard error. We train
all methods 20 times for the ﬁrst experiment and 50 times for the following experiments on a subset
of 200 messages drawn at random from the training portion and average the AUC values on the test
set. In order to tune both players’ regularization parameters  we conduct a grid search maximizing
the AUC for 5-fold cross validation on the training portion.
In the ﬁrst experiment  we explore the impact of the regularization parameter of the transformation
model  i.e.  λ−1 for our models and K – the maximal number of alterable attributes – for Invar-SVM.
Figure 1 shows the averaged AUC value on the private corpus’ test portion. The crosses indicate the
parameter values found by the grid search with cross validation on the training data.
In the next experiment  we evaluate all methods into the future by processing the test set in chrono-
logical order. Figure 2 shows that Invar-SVM  Minimax  and the Nash solution outperform the reg-
ular SVM and logistic regression signiﬁcantly. For the public data set  Minimax performs slightly
better than Nash; for the private corpus  there is no signiﬁcant difference between the solutions of
Minimax and Nash. For both data sets  the l2-regularization gives Minimax and Nash an advantage
over Invar-SVM. Recall that Minimax refers to the Nash equilibrium for antagonistic loss functions
found by solving the minimax problem for the joint cost function (Algorithm 2). In this setting  loss
functions – but not cost functions – are antagonistic; hence  Nash cannot gain an advantage over
Minimax. Figure 2 (right hand side) shows the execution time of all methods. Regular SVM and
logistic regression are faster than the game models; the game models behave comparably.
Finally  we explore a setting with non-antagonistic loss. We weight the loss functions with player-
v(ha+1(φa−1(X)i)  yi) = cv i(cid:96)v(ha+1(φa−1(X)i)  yi).
and instance speciﬁc factors cv i  that is  (cid:96)c

7

 0.988 0.992 0.996 11510204080120160AUCKAmount of Transformation vs. AccuracySVMLogRegInvar-SVM 0.988 0.992 0.996 10.50.10.050.020.010.0050.0020.001AUCλ−1Amount of Transformation vs. AccuracySVMLogRegMinimax 0.988 0.992 0.996 1510.50.10.050.010.005AUCλ−1Amount of Transformation vs. AccuracySVMLogRegNashFigure 2: Left  center: AUC evaluated into the future after training on past. Right: execution time.

Figure 3: Average storage costs versus non-spam recall.

Our model reﬂects that an email service provider may delete detected spam emails after a latency pe-
riod whereas other emails incur storage costs c+1 i proportional to their ﬁle size. The spam sender’s
costs are c−1 i = 1 for all spam instances and c−1 i = 0 for all non-spam instances. The classiﬁer
threshold balances a trade-off between non-spam recall (fraction of legitimate emails delivered) and
storage costs. For a threshold of −∞  storage costs and non-spam recall are zero for all decision
functions. Likewise  a threshold of ∞ gives a recall of 1  but all emails have to be stored. Fig-
ure 3 shows this trade-off for all methods. The Nash prediction model behaves most favorably: it
outperforms all reference methods for almost all threshold values  often by several standard errors.
Invar-SVM and Minimax cannot reﬂect differing costs for learner and adversary in their optimiza-
tion criteria and therefore perform worse. Logistic regression and the SVM with costs perform better
than their counterparts without costs  but worse than the Nash model.

6 Conclusion

We studied games in which each player’s cost function consists of a data-dependent loss and a
regularizer. A learner produces a linear model while an adversary chooses a transformation matrix
to be added to the data matrix. Our main result regards regularized non-antagonistic loss functions
that are convex  twice differentiable  and have distinct monotonicity. In this case  a unique Nash
equilibrium exists. It minimizes the costs of each of two players that aim for their highest personal
beneﬁt. We derive an algorithm that identiﬁes the equilibrium under these conditions. For the case
of antagonistic loss functions with arbitrary regularizers a unique Nash equilibrium may or may
not exist. We derive an algorithm that ﬁnds the unique Nash equilibrium  if it exists  by solving a
minimax problem on a newly derived joint cost function.
We evaluate spam ﬁlters derived from the different optimization problems on chronologically or-
dered future emails. We observe that game models outperform the reference methods. In a setting
with player- and instance-speciﬁc costs  the Nash model for non-antagonistic loss functions excels
because this setting is poorly modeled with antagonistic loss functions.

Acknowledgments

We gratefully acknowledge support from STRATO AG.

8

 0.98 0.99 1present   20 00040 000 futureAUCt emails received after trainingAccuracy over Time (65 000 Public Emails) 0.985 0.99 0.995 1present   10 00020 000 futureAUCt emails received after trainingAccuracy over Time (40 000 Private Emails)SVMLogRegInvar-SVMMinimaxNash 0.1 1 10 100 1000 100001004001 6006 200time in secnumber of training emailsExecution Time 70 75 80 85 90 95 0.84 0.88 0.92 0.96required storage in MBnon-spam recallStorage Costs vs. Accuracy (65 000 Public Emails)SVMSVM with costsLogRegLogReg with costsInvar-SVMMinimaxNashNash with costs 38 39 40 41 42 43 44 45 0.92 0.94 0.96 0.98required storage in MBnon-spam recallStorage Costs vs. Accuracy (40 000 Private Emails)References
[1] Gert R. G. Lanckriet  Laurent El Ghaoui  Chiranjib Bhattacharyya  and Michael I. Jordan. A
robust minimax approach to classiﬁcation. Journal of Machine Learning Research  3:555–582 
2002.

[2] Laurent El Ghaoui  Gert R. G. Lanckriet  and Georges Natsoulis. Robust classiﬁcation with in-
terval data. Technical Report UCB/CSD-03-1279  EECS Department  University of California 
Berkeley  2003.

[3] Amir Globerson and Sam T. Roweis. Nightmare at test time: robust learning by feature deletion.

In Proceedings of the International Conference on Machine Learning  2006.

[4] Choon Hui Teo  Amir Globerson  Sam T. Roweis  and Alex J. Smola. Convex learning with

invariances. In Advances in Neural Information Processing Systems  2008.

[5] Amir Globerson  Choon Hui Teo  Alex J. Smola  and Sam T. Roweis. Dataset Shift in Machine
Learning  chapter An adversarial view of covariate shift and a minimax approach  pages 179–
198. MIT Press  2009.

[6] Tamer Basar and Geert J. Olsder. Dynamic Noncooperative Game Theory. Society for Industrial

and Applied Mathematics  1999.

[7] J. B. Rosen. Existence and uniqueness of equilibrium points for concave n-person games.

Econometrica  33(3):520–534  1965.

[8] Anna von Heusinger and Christian Kanzow. Relaxation methods for generalized Nash equi-
librium problems with inexact line search. Journal of Optimization Theory and Applications 
143(1):159–183  2009.

[9] John M. Danskin. The theory of max-min  with applications. SIAM Journal on Applied Mathe-

matics  14(4):641–664  1966.

9

,Elad Hazan
Kfir Levy