2014,A State-Space Model for Decoding Auditory Attentional Modulation from MEG in a Competing-Speaker Environment,Humans are able to segregate auditory objects in a complex acoustic scene  through an interplay of bottom-up feature extraction and top-down selective attention in the brain. The detailed mechanism underlying this process is largely unknown and the ability to mimic this procedure is an important problem in artificial intelligence and computational neuroscience. We consider the problem of decoding the attentional state of a listener in a competing-speaker environment from magnetoencephalographic (MEG) recordings from the human brain. We develop a behaviorally inspired state-space model to account for the modulation of the MEG with respect to attentional state of the listener. We construct a decoder based on the maximum a posteriori (MAP) estimate of the state parameters via the Expectation-Maximization (EM) algorithm. The resulting decoder is able to track the attentional modulation of the listener with multi-second resolution using only the envelopes of the two speech streams as covariates. We present simulation studies as well as application to real MEG data from two human subjects. Our results reveal that the proposed decoder provides substantial gains in terms of temporal resolution  complexity  and decoding accuracy.,A State-Space Model for Decoding Auditory

Attentional Modulation from MEG in a

Competing-Speaker Environment

Sahar Akram1 2  Jonathan Z. Simon1 2 3  Shihab Shamma1 2  and Behtash Babadi1 2

1 Department of Electrical and Computer Engineering 

2 Institute for Systems Research  3 Department of Biology

University of Maryland

College Park  MD 20742  USA

{sakram jzsimon sas behtash}@umd.edu

Abstract

Humans are able to segregate auditory objects in a complex acoustic scene 
through an interplay of bottom-up feature extraction and top-down selective at-
tention in the brain. The detailed mechanism underlying this process is largely
unknown and the ability to mimic this procedure is an important problem in ar-
tiﬁcial intelligence and computational neuroscience. We consider the problem of
decoding the attentional state of a listener in a competing-speaker environment
from magnetoencephalographic (MEG) recordings from the human brain. We de-
velop a behaviorally inspired state-space model to account for the modulation of
the MEG with respect to attentional state of the listener. We construct a decoder
based on the maximum a posteriori (MAP) estimate of the state parameters via
the Expectation-Maximization (EM) algorithm. The resulting decoder is able to
track the attentional modulation of the listener with multi-second resolution using
only the envelopes of the two speech streams as covariates. We present simula-
tion studies as well as application to real MEG data from two human subjects.
Our results reveal that the proposed decoder provides substantial gains in terms of
temporal resolution  complexity  and decoding accuracy.

Introduction

1
Segregating a speaker of interest in a multi-speaker environment is an effortless task we routinely
perform. It has been hypothesized that after entering the auditory system  the complex auditory sig-
nal resulted from concurrent sound sources in a crowded environment is decomposed into acoustic
features. An appropriate binding of the relevant features  and discounting of others  leads to forming
the percept of an auditory object [1  2  3]. The complexity of this process becomes tangible when
one tries to synthesize the underlying mechanism known as the cocktail party problem [4  5  6  7].
In a number of recent studies it has been shown that concurrent auditory objects even with highly
overlapping spectrotemporal features  are neurally encoded as a distinct object in auditory cortex
and emerge as fundamental representational units for high-level cognitive processing [8  9  10]. In
the case of listening to speech  it has recently been demonstrated by Ding and Simon [8]  that the
auditory response manifested in MEG is strongly modulated by the spectrotemporal features of the
speech. In the presence of two speakers  this modulation appears to be strongly correlated with the
temporal features of the attended speaker as opposed to the unattended speaker (See Figure 1–A).
Previous studies employ time-averaging across multiple trials in order to decode the attentional state
of the listener from MEG observations. This method is only valid when the subject is attending to a
single speaker during the entire trial. In a real-world scenario  the attention of the listener can switch
dynamically from one speaker to another. Decoding the attentional target in this scenario requires a

1

Figure 1: A) Schematic depiction of auditory object encoding in the auditory cortex. B) The MEG
magnetic ﬁeld distribution of the ﬁrst DSS component shows a stereotypical pattern of neural activity
originating separately in the left and right auditory cortices. Purple and green contours represent the
magnetic ﬁeld strength. Red arrows schematically represent the locations of the dipole currents 
generating the measured magnetic ﬁeld. C) An example of the TRF  estimated from real MEG data.
Signiﬁcant TRF components analogous to the well-known M50 and M100 auditory responses are
marked in the plot.

dynamic estimation framework with high temporal resolution. Moreover  the current techniques use
the full spectrotemporal features of the speech for decoding. It is not clear whether the decoding can
be carried out with a more parsimonious set of spectrotemporal features.
In this paper  we develop a behaviorally inspired state-space model to account for the modulation
of MEG with respect to the attentional state of the listener in a double-speaker environment. MAP
estimation of the state-space parameters given MEG observations is carried out via the EM algo-
rithm. We present simulation studies as well as application to experimentally acquired MEG data 
which reveal that the proposed decoder is able to accurately track the attentional state of a listener
in a double-speaker environment while selectively listening to one of the two speakers. Our method
has three main advantages over existing techniques. First  the decoder provides estimates with sub-
second temporal resolution. Second  it only uses the envelopes of the two speech streams as the
covariates  which is a substantial reduction in the dimension of the spectrotemporal feature set used
for decoding. Third  the principled statistical framework used in constructing the decoder allows us
to obtain conﬁdence bounds on the estimated attentional state.
The paper is organized as follows. In Section 2  we introduce the state-space model and the proposed
decoding algorithm. We present simulation studies to test the decoder in terms of robustness with
respect to noise as well as tracking performance and apply to real MEG data recorded from two
human subjects in Section 3. Finally  we discuss the future directions and generalizations of our
proposed framework in Section 4.

2 Methods
We ﬁrst consider the forward problem of relating the MEG observations to the spectrotemporal
features of the attended and unattended speech streams. Next  we consider the inverse problem
where we seek to decode the attentional state of the listener given the MEG observations and the
temporal features of the two speech streams.

2.1 The Forward Problem: Estimating the Temporal Response Function
Consider a task where the subject is passively listening to a speech stream. Let the discrete-
time MEG observation at time t  sensor j  and trial r be denoted by xt j r  for t = 1  2 ···   T  
j = 1  2 ···   M and r = 1  2 ···   R. The stimulus-irrelevant neural activity can be removed using
denoising source separation (DSS) [11]. The DSS algorithm is a blind source separation method
that decomposes the data into T temporally uncorrelated components by enhancing consistent com-
ponents over trials and suppressing noise-like components of the data  with no knowledge of the
stimulus or timing of the task. Let the time series y1 r  y2 r ···   yT r denote the ﬁrst signiﬁcant
component of the DSS decomposition  denoted hereafter by MEG data. In an auditory task  this
component has a ﬁeld map which is consistent with the stereotypical auditory response in MEG
(See Figure 1–B). Also  let Et be the speech envelope of the speaker at time t in dB scale. In a linear
model  the MEG data is linearly related to the envelope of speech as:

yt r = τt ∗ Et + vt r 

2

(1)

Spk1 AttendedSpk2 AttendedSinkSource50ft/StepBAC0 125 250375500−6−4−202468x 10−562Time (ms)Temporal Response FunctionSpk1Spk2MEGSpk1 SpeechSpk2 Speechwhere τt is a linear ﬁlter of length L denoted by temporal response function (TRF)  ∗ denotes the
convolution operator  and vt r is a nuisance component accounting for trial-dependent and stimulus-
independent components manifested in the MEG data. It is known that the TRF is a sparse ﬁlter 
with signiﬁcant components analogous to the M50 and M100 auditory responses ([9  8]  See Figure
1–C). A commonly-used technique for estimating the TRF is known as Boosting ([12  9])  where
the components of the TRF are greedily selected to decrease the mean square error (MSE) of the
ﬁt to the MEG data. We employ an alternative estimation framework based on (cid:96)1-regularization.
Let τ := [τL  τL−1 ···   τ1](cid:48) be the time-reversed version of the TRF ﬁlter in vector form  and
let Et := [Et  Et−1 ···   Et−L+1](cid:48). In order to obtain a sparse estimate of the TRF  we seek the
(cid:96)1-regularized estimate:

(cid:107)yt r − τ (cid:48)Et(cid:107)2

2 + γ(cid:107)τ(cid:107)1 

(2)

(cid:98)τ = argmin

τ

R T(cid:88)

r t=1

where γ is the regularization parameter. The above problem can be solved using standard opti-
mization software. We have used a fast solver based on iteratively re-weighted least squares [13].
The parameter γ is chosen by two-fold cross-validation  where the ﬁrst half of the data is used for
estimating τ and the second half is used to evaluate the goodness-of-ﬁt in the MSE sense. An exam-
ple of the estimated TRF is shown in Figure 1–C. In a competing-speaker environment  where the
subject is only attending to one of the two speakers  the linear model takes the form:

t   τ u

t   Ea

yt r = τ a

t   and Eu

(3)
t   denoting the TRF and envelope of the attended and unattended speak-
with τ a
ers  respectively. The above estimation framework can be generalized to the two-speaker case
by replacing the regressor τ (cid:48)Et with τ a(cid:48)Ea
t are deﬁned
in a fashion similar to the single-speaker case. Similarly  the regularization γ(cid:107)τ(cid:107)1 is replaced by
γa(cid:107)τ a(cid:107)1 + γu(cid:107)τ u(cid:107)1.

t   where τ a  Ea

t + τ u(cid:48)Eu

t   τ u  and Eu

t + vt r 

t + τ u

t ∗ Ea

t ∗ Eu

2.2 The Inverse Problem: Decoding Attentional Modulation
2.2.1 Observation Model
Let y1 r  y2 r ···   yT r denote the MEG data time series at trial r  for r = 1  2 ···   R during an
observation period of length T . For a window length W   let

yk r :=(cid:2)y(k−1)W +1 r  y(k−1)W +2 r ···   ykW r

(4)
for k = 1  2 ···   K := (cid:98)T /W(cid:99). Also  let Ei t be the speech envelope of speaker i at time t in dB
scale  i = 1  2. Let τ a
t denote the TRFs of the attended and unattended speakers  respectively.
The MEG predictors in the linear model are given by:

(cid:3)  

e2 t := τ a

t ∗ E2 t
t ∗ E1 t

t and τ u
t ∗ E1 t + τ u
t ∗ E2 t + τ u

(cid:26) e1 t := τ a
ei k :=(cid:2)ei (k−1)W +1  ei (k−1)W +2 ···   ei kW
(cid:3)  
(cid:18)(cid:28) yk r

θi k r := arccos

(cid:29)(cid:19)

(cid:107)yk r(cid:107)2

 

ei k
(cid:107)ei k(cid:107)2

Let

(6)
Recent work by Ding and Simon [8] suggests that the MEG data yk is more correlated with the
predictor ei k when the subject is attending to the ith speaker at window k. Let

for i = 1  2 and k = 1  2 ···   K.

attending to speaker 1
attending to speaker 2  

t = 1  2 ···   T.

(5)

(7)

denote the empirical correlation between the observed MEG data and the model prediction when
attending to speaker i at window k and trial r. When θi k r is close to 0 (π)  the MEG data and its
predicted value are highly (poorly) correlated. Inspired by the ﬁndings of Ding and Simon [8]  we
model the statistics of θi k r by the von Mises distribution [14]:

1

θi k r ∈ [0  π] 

πI0(κi)

p (θi k r) =

exp (κi cos (θi k r))  

(8)
where I0(·) is the zeroth order modiﬁed Bessel function of the ﬁrst kind  and κi denotes the spread
parameter of the von Mises distribution for i = 1  2. The von Mises distribution gives more (less)
weight to higher (lower) values of correlation between the MEG data and its predictor and is pretty
robust to gain ﬂuctuations of the neural data.The spread parameter κi accounts for the concentration
of θi k r around 0. We assume a conjugate prior of the form p(κi) ∝ exp(c0dκi)
over κi  for some
hyper-parameters c0 and d.

i = 1  2

I0(κi)d

3

2.2.2 State Model
Suppose that at each window of observation  the subject is attending to either of the two speakers.
Let nk r be a binary variable denoting the attention state of the subject at window k and trial r:

nk r =

attending to speaker 1
attending to speaker 2

(9)

(cid:26) 1

0

The subjective experience of attending to a speciﬁc speech stream among a number of competing
speeches reveals that the attention often switches to the competing speakers  although not intended
by the listener. Therefore  we model the statistics of nk r by a Bernoulli process with a success
probability of qk:
(10)
A value of qk close to 1 (0) implies attention to speaker 1 (2). The process {qk}K
k=1 is assumed to be
common among different trials. In order to model the dynamics of qk  we deﬁne a variable zk such
that

p(nk r|qk) = qnk r

(1 − qk)1−nk r .

k

qk = logit−1(zk) :=

exp(zk)

(11)
When zk tends to +∞ (−∞)  qk tends to 1 (0). We assume that zk obeys AR(1) dynamics of the
form:

1 + exp(zk)

(12)
where wk is a zero-mean i.i.d. Gaussian random variable with a variance of ηk. We further assume
that ηk are distributed according to the conjugate prior given by the inverse-Gamma distribution with
hyper-parameters α (shape) and β (scale).

zk = zk−1 + wk 

.

(cid:110)

(cid:111)

(13)
be the set of parameters. The log-posterior of the parameter set Ω given the observed data

Ω :=

k=1

κ1  κ2 {zk}K

k=1 {ηk}K

2.2.3 Parameter Estimation
Let

(cid:8)θi k r
(cid:16)

log p

(cid:9)2 T R
(cid:12)(cid:12)(cid:12){θi k r}2 K R

Ω

i k r=1

i k r=1 is given by:

(cid:17)

=

qk

log

(cid:20)
(cid:26) 1

R K(cid:88)
+(cid:2)(κ1 + κ2)c0d − d(cid:0) log I0(κ1) + log I0(κ2)(cid:1)(cid:3)
− R K(cid:88)

exp (κ1cos (θ1 k r))+

(zk−zk−1)2 +

πI0(κ1)

r k=1

1 − qk
πI0(κ2)

1
2

2ηk

r k=1

log ηk + (α + 1) log ηk +

exp (κ2cos (θ2 k r))

(cid:27)

β
ηk

+ cst.

(cid:21)

where cst. denotes terms that are not functions of Ω. The MAP estimate of the parameters is
difﬁcult to obtain given the involved functional form of the log-posterior. However  the complete
data log-posterior  where the unobservable sequence {nk r}K R

k=1 r=1 is given  takes the form:

(cid:16)

(cid:12)(cid:12)(cid:12){θi k r  nk r}2 K R

i k r=1

(cid:17)

log p

Ω

=

r k=1

nk r [κ1 cos (θ1 k r)−log I0(κ1) + log qk]

R K(cid:88)
R K(cid:88)
+(cid:2)(κ1 + κ2)c0d − d(cid:0) log I0(κ1) + log I0(κ2)(cid:1)(cid:3)
− R K(cid:88)

(zk−zk−1)2 +

(cid:26) 1

r k=1

+

1
2

2ηk

r k=1

(1−nk r) [κ2 cos (θ2 k r)−log I0(κ2) + log(1 − qk)]

log ηk +(α + 1) log ηk +

(cid:27)

β
ηk

+cst.

The log-posterior of the parameters given the complete data has a tractable functional form for
optimization purposes. Therefore  by taking {nk r}K R
k=1 r=1 as the unobserved data  we can estimate

4

Ω via the EM algorithm [15]. Using Bayes’ rule  the expectation of nk r  given(cid:8)θi k r
(cid:9)2 K R
current estimates of the parameters Ω((cid:96)) :=(cid:8)κ((cid:96))
(cid:9) is given by:
(cid:17)
E(cid:110)
(cid:16)
(cid:16)
(cid:17) exp

(cid:9)K
k=1 (cid:8)η((cid:96))
2  (cid:8)z((cid:96))
(cid:16)
1   κ((cid:96))
(cid:16)
(cid:17) exp
(cid:17)
q((cid:96))
κ((cid:96))
1 cos (θ1 k r)
k
κ((cid:96))
(cid:16)
+ 1−q((cid:96))

κ((cid:96))
2 cos (θ2 k r)
Denoting the expectation above by the shorthand E((cid:96)){nk r}  the M-step of the EM algorithm for
κ((cid:96)+1)
1

κ((cid:96))
1 cos (θ1 k r)

i k r=1 and

(cid:17) exp

and κ((cid:96)+1)

(cid:9)K

q((cid:96))
k
κ((cid:96))

k
κ((cid:96))

nk r

(cid:16)

k=1

πI0

πI0

πI0

=

k

k

1

2

1

(cid:17) .

(cid:12)(cid:12)(cid:12){θi k r}2 K R
i k r=1  Ω((cid:96))(cid:111)


= A−1

gives:

c0d +

R K(cid:88)

d +

2

r k=1

κ((cid:96)+1)
i

(cid:26) E((cid:96)){nk r}

1 − E((cid:96)){nk r}

ε((cid:96))
i k r =

i = 1
i = 2

 

(14)

  

ε((cid:96))
i k r cos (θi k r)

R K(cid:88)

r k=1

ε((cid:96))
i k r

k=1 and {zk}K
R K(cid:88)

(cid:20)

where A(x) := I1(x)/I0(x)  with I1(·) denoting the ﬁrst order modiﬁed Bessel function of the ﬁrst
kind. Inversion of A(·) can be carried out numerically in order to ﬁnd κ((cid:96)+1)
. The M-step
for {ηk}K

and κ((cid:96)+1)

1

2

k=1 corresponds to the following maximization problem:
(zk − zk−1)2 +2β

E((cid:96)){nk r}zk−log(1 + exp(zk))− 1
2ηk

k=1

r k=1

argmax
{zk ηk}K
An efﬁcient approximate solution to this maximization problem is given by another EM algorithm 
where the E-step is the point process smoothing algorithm [16  17] and the M-step updates the
state variance sequence [18]. At iteration m  given an estimate of η((cid:96)+1)
  the
forward pass of the E-step for k = 1  2 ···   K is given by:

  denoted by η((cid:96)+1 m)

log ηk

k

k

2

.

(cid:105)− 1+2(α+1)

(cid:21)

(cid:104)



k|k−1 = ¯z((cid:96)+1 m)
¯z((cid:96)+1 m)
k−1|k−1
σ((cid:96)+1 m)
k|k−1 = σ((cid:96)+1 m)

k−1|k−1 +

η((cid:96)+1 m)
k

R

¯z((cid:96)+1 m)
k|k

= ¯z((cid:96)+1 m)

k|k−1 + σ((cid:96)+1 m)

k|k−1



(cid:16)

1

σ((cid:96)+1 m)
k|k−1

+ R

σ((cid:96)+1 m)
k|k

=

 R(cid:88)
(cid:16)

r=1

exp

E((cid:96)){nk r} − R

(cid:17)

−1

(cid:17)(cid:17)2

¯z((cid:96)+1 m)
k|k

(cid:16)

1 + exp

¯z((cid:96)+1 m)
k|k

(cid:16)

(cid:16)

¯z((cid:96)+1 m)
k|k
¯z((cid:96)+1 m)
k|k

exp

1 + exp

(cid:17)



(cid:17)

(15)



(cid:16)

and for k = K − 1  K − 2 ···   1  the backward pass of the E-step is given by:

(cid:17)
(cid:17)
k+1|K − ¯z((cid:96)+1 m)
¯z((cid:96)+1 m)
k+1|k
k+1|K − σ((cid:96)+1 m)
σ((cid:96)+1 m)
k+1|k
Note that the third equation in the forward ﬁlter is non-linear in ¯z((cid:96)+1 m)
standard techniques (e.g.  Newton’s method). The M-step gives the updated value of η((cid:96)+1 m+1)

/σ((cid:96)+1 m)
+ s((cid:96)+1 m)
+ s((cid:96)+1 m)

= σ((cid:96)+1 m)
= ¯z((cid:96)+1 m)
= σ((cid:96)+1 m)

s((cid:96)+1 m)
k
¯z((cid:96)+1 m)
k|K
σ((cid:96)+1 m)
k|K

  and can be solved using
as:

k|k
k|k
k|k

s((cid:96)+1 m)
k

(cid:16)
(cid:16)

k+1|k

(16)

k|k

k

k

k

η((cid:96)+1 m+1)
k

=

¯z((cid:96)+1 m)
k|K

− ¯z((cid:96)+1 m)
k−1|K

+ σ((cid:96)+1 m)

k|K

+ σ((cid:96)+1 m)

k−1|K − 2σ((cid:96)+1 m)

k|K

1 + 2(α + 1)

s((cid:96)+1 m)
k−1

+ 2β

. (17)

For each (cid:96) in the outer EM iteration  the inner iteration over m is repeated until convergence  to
}K
obtain the updated values of {z((cid:96)+1)
k=1 to be passed to the outer EM iteration.

}K
k=1 and {η((cid:96)+1)

k

k

5

(cid:17)2

−1(cid:0)z((cid:96)+1)

k

= logit

(cid:1). Starting with an initial guess of the parameters  the outer EM algorithm

The updated estimate of the Bernoulli success probability at window k and iteration (cid:96) + 1 is given by
q((cid:96)+1)
k
alternates between ﬁnding the expectation of {nk r}K R
k=1 r=1 and estimating the parameters κ1  κ2 
{zk}K
k can be obtained by mapping
the Gaussian conﬁdence intervals for the Gaussian variable z((cid:96))
k via the inverse logit mapping. In
summary  the decoder inputs the MEG observations and the envelopes of the two speech streams 
and outputs the Bernoulli success probability sequence corresponding to attention to speaker 1.

k=1 until convergence. Conﬁdence intervals for q((cid:96))

k=1 and {ηk}K

3 Results
3.1 Simulated Experiments
We ﬁrst evaluated the proposed state-space model and estimation procedure on simulated MEG
data. For a sampling rate of Fs = 200Hz  a window length of W = 50 samples (250ms)  and a
total observation time of T = 12000 samples (60s)  the binary sequence {nk r}240 3
k=1 r=1 is generated
as realizations of a Bernoulli process with success probability qk = 0.95 or 0.05  corresponding to
attention to speaker one or two  respectively. Using a TRF template of length 0.5s estimated from
real data  we generated 3 trials with an SNR of 10dB. Each trial includes three attentional switches
occurring every 15 seconds. The hyper-parameters α and β for the inverse-Gamma prior on the state
variance are chosen as α = 2.01 and β = 2. This choice of α close to 2 results in a non-informative
prior  as the variance of the prior is given by β2/[(α − 1)2(α − 2)] ≈ 400  while the mean is given
by β/(α − 1) ≈ 2. The mean of the prior is chosen large enough so that the state transition from
qk = 0.99 to qk+1 = 0.01 lies in the 98% conﬁdence interval around the state innovation variable
2 KR and
wk (See Eq. (12)). The hyper-parameters for the von Mises distribution are chosen as d = 7
c0 = 0.15  as the average observed correlation between the MEG data and the model prediction is ≈
in the range of 0.1–0.2. The choice of d = 7
2 KR gives more weight to the prior than the empirical
estimate of κi.
Figure 2–A and 2–B show the simulated MEG signal (black traces) and predictors of attending to
speaker one and two (red traces)  respectively  at an SNR of 10 dB. Regions highlighted in yellow
in panels A and B indicate the attention of the listener to either of the two speakers. Estimated
values of {qk}240
k=1 (green trace) and the corresponding conﬁdence intervals (green hull) are shown
in Figure 2–C. The estimated qk values reliably track the attentional modulation  and the transitions
are captured with high accuracy. MEG data recorded from the brain is usually contaminated with
environmental noise as well as nuisance sources of neural activity  which can considerably decrease
the SNR of the measured signal.
In order to test the robustness of the decoder with respect to
observation noise  we repeated the above simulation with SNR values of 0 dB  −10 dB and −20
dB. As Figure 2–D shows  the dynamic denoising feature of the proposed state-space model results
in a desirable decoding performance for SNR values as low as −20 dB. The conﬁdence intervals
and the estimated transition width widen gracefully as the SNR decreases. Finally  we test the
tracking performance of the decoder with respect to the frequency of the attentional switches. From
subjective experience  attentional switches occur over a time scale of few seconds. We repeated the
above simulation for SNR = 10 dB with 14 attentional switches equally spaced during the 60s trial.
Figure 2–E shows the corresponding estimate values of {qk}  which reliably tracks the 14 attentional
switches during the observation period.

3.2 Application to Real MEG Data
We evaluated our proposed state-space model and decoder on real MEG data recorded from two
human subjects listening to a speech mixture from a male and a female speaker under different at-
tentional conditions. The experimental methods were approved by the Institutional Review Board
(IRB) at the authors’ home institution. Two normal-hearing right-handed young adults participated
in this experiment. Listeners selectively listened to one of the two competing speakers of opposite
gender  mixed into a single acoustic channel with equal density. The stimuli consisted of 4 segments
from the book A Child History of England by Charles Dickens  narrated by two different readers
(one male and one female). Three different mixtures  each 60s long  were generated and used in dif-
ferent experimental conditions to prevent reduction in attentional focus of the listeners  as opposed
to listening to a single mixture repeatedly over the entire experiment. All stimuli were delivered

6

Figure 2: Simulated MEG data (black traces) and model prediction (red traces) of A) speaker one and
B) speaker two at SNR = 10 dB. Regions highlighted in yellow indicate the attention of the listener
to each of the speakers. C) Estimated values of {qk} with 95% conﬁdence intervals. D) Estimated
values of {qk} from simulated MEG data vs. SNR = 0  −10 and −20dB. E) Estimated values of
{qk} from simulated MEG data with SNR = 10dB and 14 equally spaced attention switches during
the entire trial. Error hulls indicate 95% conﬁdence intervals. The MEG units are in pT /m.

identically to both ears using tube phones plugged into the ears and at a comfortable loudness level
of around 65 dB. The neuromagnetic signal was recorded using a 157–channel  whole-head MEG
system (KIT) in a magnetically shielded room  with a sampling rate of 1kHz. Three reference chan-
nels were used to measure and cancel the environmental magnetic ﬁeld [19].
The stimulus-irrelevant neural activity was removed using the DSS algorithm [11]. The recorded
neural response during each 60s was high-pass ﬁltered at 1 Hz and downsampled to 200 Hz before
submission to the DSS analysis. Only the ﬁrst component of the DSS decomposition was used in the
analysis [9]. The TRF corresponding to the attended speaker was estimated from a pilot condition
where only a single speech stream was presented to the subject  using 3 repeated trials (See Section
2.1). The TRF corresponding to the unattended speaker was approximated by truncating the attended
TRF beyond a lag of 90ms  on the grounds of the recent ﬁndings of Ding and Simon [8] which show
that the components of the unattended TRF are signiﬁcantly suppressed beyond the M50 evoked
ﬁeld. In the following analysis  trials with poor correlation values between the MEG data and the
model prediction were removed by testing for the hypothesis of uncorrelatedness using the Fisher
transformation at a conﬁdence level of 95% [20]  resulting in rejection of about 26% of the trials.
All the hyper-parameters are equal to those used for the simulation studies (See Section 3.1).
In the ﬁrst and second conditions  subjects were asked to attend to the male and female speakers 
respectively  during the entire trial. Figure 3–A and 3–B show the MEG data and the predicted qk
values for averaged as well as single trials for both subjects. Conﬁdence intervals are shown by the
shaded hulls for the averaged trial estimate in each condition. The decoding results indicate that the
decoder reliably recovers the attention modulation in both conditions  by estimating {qk} close to 1
and 0 for the ﬁrst and second conditions  respectively. For the third and fourth conditions  subjects
were instructed to switch their attention in the middle of each trial  from the male to the female
speaker (third condition) and from the female to the male speaker (fourth condition). Switching
times were cued by inserting a 2s pause starting at 28s in each trial. Figures 3–C and 3–D show the
MEG data and the predicted qk values for averaged and single trials corresponding to the third and
fourth conditions  respectively. Dashed vertical lines show the start of the 2s pause before attentional
switch. Using multiple trials  the decoder is able to capture the attentional switch occurring roughly
halfway through the trial. The decoding of individual trials suggest that the exact switching time is
not consistent across different trials  as the attentional switch may occur slightly earlier or later than
the presented cue due to inter-trial variability. Moreover  the decoding results for a correlation-based
classiﬁer is shown in the third panel of each ﬁgure for one of the subjects. At each time window  the

7

Figure 3: Decoding of auditory attentional modulation from real MEG data. In each subplot  the
MEG data (black traces) and the model prediction (red traces) for attending to speaker 1 (male) and
speaker 2 (female) are shown in the ﬁrst and second panels  respectively  for subject 1. The third
panel shows the estimated values of {qk} and the corresponding conﬁdence intervals using multiple
trials for both subjects. The gray traces show the results for a correlation-based classiﬁer for subject
1. The fourth panel shows the estimated {qk} values for single trials. A) Condition one: attending
to speaker 1 through the entire trial. B) Condition two: attending to speaker 2 through the entire
trial. C) Condition three: attending to speaker 1 until t = 28s and switching attention to speaker 2
starting at t = 30s. D) Condition four: attending to speaker 2 until t = 28s and switching attention
to speaker 1 starting at t = 30s. Dashed lines in subplots C and D indicate the start of the 2s silence
cue for attentional switch. Error hulls indicate 95% conﬁdence intervals. The MEG units are in
pT /m.

classiﬁer picks the speaker with the maximum correlation (averaged across trials) between the MEG
data and its predicted value based on the envelopes. Our proposed method signiﬁcantly outperforms
the correlation-based classiﬁer which is unable to consistently track the attentional modulation of
the listener over time.

4 Discussion
In this paper  we presented a behaviorally inspired state-space model and an estimation framework
for decoding the attentional state of a listener in a competing-speaker environment. The estimation
framework takes advantage of the temporal continuity in the attentional state  resulting in a decoding
performance with high accuracy and high temporal resolution. Parameter estimation is carried out
using the EM algorithm  which at its heart ties to the efﬁcient computation of the Bernoulli process
smoothing  resulting in a very low overall computational complexity. We illustrate the performance
of our technique on simulated and real MEG data from human subjects. The proposed approach
beneﬁts from the inherent model-based dynamic denosing of the underlying state-space model  and
is able to reliably decode the attentional state under very low SNR conditions. Future work includes
generalization of the proposed model to more realistic and complex auditory environments with
more diverse sources such as mixtures of speech  music and structured background noise. Adapting
the proposed model and estimation framework to EEG is also under study.

8

References
[1] Bregman  A. S. (1994). Auditory Scene Analysis: The Perceptual Organization of Sound  Cam-

bridge  MA: MIT Press.

[2] Grifﬁths  T. D.  & Warren  J. D. (2004). What is an auditory object?. Nature Reviews Neuro-

science  5(11)  887–892.

[3] Shamma  S. A.  Elhilali  M.  & Micheyl  C. (2011). Temporal coherence and attention in audi-

tory scene analysis. Trends in neurosciences  34(3)  114–123.

[4] Bregman  A. S. (1998). Psychological data and computational ASA. In Computational Auditory

Scene Analysis (pp. 1-12). Hillsdale  NJ: L. Erlbaum Associates Inc.

[5] Cherry  E. C. (1953). Some experiments on the recognition of speech  with one and with two

ears. Journal of the Acoustical Society of America  25(5)  975–979.

[6] Elhilali  M.  Xiang  J.  Shamma  S. A.  & Simon  J. Z. (2009). Interaction between attention and
bottom-up saliency mediates the representation of foreground and background in an auditory
scene. PLoS Biology  7(6)  e1000129.

[7] Shinn-Cunningham  B. G. (2008). Object-based auditory and visual attention. Trends in Cogni-

tive Sciences  12(5)  182–186.

[8] Ding  N. & Simon  J.Z. (2012). Emergence of neural encoding of auditory objects while listen-

ing to competing speakers. PNAS  109(29):11854–11859.

[9] Ding  N. & Simon  J.Z. (2012). Neural coding of continuous speech in auditory cortex during

monaural and dichotic listening. Journal of Neurophisiology  107(1):78–89.

[10] Mesgarani  N.  & Chang  E. F. (2012). Selective cortical representation of attended speaker in

multi-talker speech perception. Nature  485(7397)  233–236.

[11] de Cheveign´e  A.  & Simon  J. Z. (2008). Denoising based on spatial ﬁltering. Journal of

Neuroscience Methods  171(2)  331–339.

[12] David  S. V.  Mesgarani  N.  & Shamma. (2007). Estimating sparse spectro-temporal receptive

ﬁelds with natural stimuli. Network: Computation in Neural Systems  18(3)  191–212.

[13] Ba  D.  Babadi  B.  Purdon  P. L.  & Brown  E. N. (2014). Convergence and stability of itera-
tively re-weighted least squares algorithms  IEEE Trans. on Signal Processing  62(1)  183–195.
[14] Fisher  N. I. (1995). Statistical Analysis of Circular Data  Cambridge  UK: Cambridge Uni-

versity Press.

[15] Dempster  A. P.  Laird  N. M.  & Rubin  D. B. (1977). Maximum likelihood from incomplete

data via the EM algorithm. Journal of the Royal Statistical Society  39(1)  1–38.

[16] Smith  A. C. & Brown  E. N. (2003). Estimating a state-space model from point process obser-

vations. Neural Computation. 15(5)  965–991.

[17] Smith  A. C.  Frank  L. M.  Wirth  S.  Yanike  M.  Hu  D.  Kubota  Y.  Graybiel  A. M.  Suzuki 
W. A.  & Brown  E. N. (2004). Dynamic analysis of learning in behavioral experiments. The
Journal of Neuroscience  24(2)  447–461.

[18] Shumway  R. H.  & Stoffer  D. S. (1982). An approach to time series smoothing and forecasting

using the EM algorithm. Journal of Time Series Analysis  3(4)  253–264.

[19] de Cheveign´e  A.  & Simon  J. Z. (2007). Denoising based on time-shift PCA. Journal of

Neuroscience Methods  165(2)  297–305.

[20] Fisher  R. A. (1915). Frequency distribution of the values of the correlation coefﬁcient in sam-

ples of an indeﬁnitely large population. Biometrika  10(4): 507–521.

9

,Sahar Akram
Jonathan Simon
Shihab Shamma
Behtash Babadi
Guiguan Lin
xinyang gong
Kang-Jun Liu
Shan-Hung (Brandon) Wu
Abhishek Kar
Christian Häne