2018,Algorithmic Assurance: An Active Approach to Algorithmic Testing using Bayesian Optimisation,We introduce algorithmic assurance  the problem of testing whether
machine learning algorithms are conforming to their intended design
goal. We address this problem by proposing an efficient framework
for algorithmic testing. To provide assurance  we need to efficiently
discover scenarios where an algorithm decision deviates maximally
from its intended gold standard. We mathematically formulate this
task as an optimisation problem of an expensive  black-box function.
We use an active learning approach based on Bayesian optimisation
to solve this optimisation problem. We extend this framework to algorithms
with vector-valued outputs by making appropriate modification in Bayesian
optimisation via the EXP3 algorithm. We theoretically analyse our
methods for convergence. Using two real-world applications  we demonstrate
the efficiency of our methods. The significance of our problem formulation
and initial solutions is that it will serve as the foundation in assuring
humans about machines making complex decisions.,Algorithmic Assurance: An Active Approach to
Algorithmic Testing using Bayesian Optimisation

Shivapratap Gopakumar  Sunil Gupta∗  Santu Rana  Vu Nguyen  Svetha Venkatesh

Centre for Pattern Recognition and Data Analytics

Deakin University  Geelong  Australia

Abstract

We introduce algorithmic assurance  the problem of testing whether machine
learning algorithms are conforming to their intended design goal. We address this
problem by proposing an efﬁcient framework for algorithmic testing. To provide
assurance  we need to efﬁciently discover scenarios where an algorithm decision
deviates maximally from its intended gold standard. We mathematically formulate
this task as an optimisation problem of an expensive  black-box function. We use an
active learning approach based on Bayesian optimisation to solve this optimisation
problem. We extend this framework to algorithms with vector-valued outputs by
making appropriate modiﬁcation in Bayesian optimisation via the EXP3 algorithm.
We theoretically analyse our methods for convergence. Using two real-world
applications  we demonstrate the efﬁciency of our methods. The signiﬁcance of
our problem formulation and initial solutions is that it will serve as the foundation
in assuring humans about machines making complex decisions.

1

Introduction

Supervised learning algorithms today serve as proxies for decision processes traditionally performed
by humans. As decision making processes get increasingly automated  it is reasonable to ask if
our algorithms are behaving as intended. How far is the algorithm from the gold standard (human
decision maker) it is serving as a proxy for? For example  consider a metallurgist who routinely
makes decisions about elemental compositions to design a target alloy. If an algorithm is built to
serve as a proxy for this decision process  can we provide assurance that the difference in the decision
made by the algorithm and the metallurgist is within a stipulated bound? Similarly if an algorithm
has been trained to recognize digits  can we ensure that the recognition error of the algorithm is
acceptable across all allowable visual variations within which a human can recognise digits correctly?
To provide such assurance we need to compare an algorithm against its gold standard and ﬁnd the
maximum deviation. An exhaustive comparison may solve this problem but would be prohibitively
expensive as we need gold standard decisions for a large number of test instances. In absence of such
a large set  how do we ﬁnd such deviations efﬁciently?
Traditionally machine learning algorithms are tested by separating a small fraction of the available
data as a validation set. Considering the validation set as a collection of random samples from the
data space  we may need a large validation set to have high conﬁdence on the algorithmic assurance 
i.e. the maximal deviation of the algorithm from its gold standard is within an acceptable limit. Let
us assume a hypervolume vε wherein a function takes values within 1− ε of its maximum. Then
a random search will sample this hypervolume with the probability vε
V where V is the total search
space volume. Assuming V = Rd and vε ≈ rd  where d is the input dimension  the random search
number of samples [3]. This can be expensive - e.g.

scheme would need  on an average O(cid:16)(cid:0) r

(cid:1)−d(cid:17)

R

∗Corresponding author email:sunil.gupta@deakin.edu.au

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

T

(cid:19)

(cid:18)(cid:113) dln T

R = 0.01  nearly a million samples are required in just a three dimensional space. Therefore  a

if r
sample efﬁcient alternative is needed for the algorithmic assurance.
We propose to use an active strategy for ﬁnding the maximum deviation that samples the data
space such that each sample is only queried if it is aligned with the goal to ﬁnd the maximum.
Bayesian optimisation is one such efﬁcient active learning method with a convergence guarantee
on the average regret as O
(using a Gaussian process model with squared-exponential
kernel [4  19]) where T is the number of iterations/samples. Thus to reach the same regret level ε 
Bayesian optimisation requires much smaller sample numbers. This approach actively recommends
new instances during validation for which decisions are required from both algorithm and the human
expert. Although costly  it remains practical because of the sample-efﬁciency guarantee of Bayesian
optimisation. Our experience shows that it common to reach the maximum within tens of samples
per dimension.
We develop a Bayesian Optimisation (BO) framework to efﬁciently discover the scenario wherein an
algorithm maximally deviates from its gold standard. Given a difference function y = f (x)  where
x representing input instances and y representing the difference of the algorithm’s decision  our
proposed algorithmic assurance framework aims to efﬁciently discover the instance for which the
algorithmic decision differs most from the gold standard. We assume that functions underlying
the decision making of both the gold standard process and the algorithm are smooth and therefore
their difference function f (x) is also smooth. We model f (x) using a Gaussian process [15]  and
its predictive distribution is used to predict the deviation of the algorithm from the gold standard
along with any epistemic uncertainty. This prediction is then used to construct a cheap surrogate
function (acquisition function) that takes higher values at points where either the algorithm deviation
or the epistemic uncertainty is high. The acquisition function is ﬁnally maximised to recommend a
new instance for the algorithm testing. Both the gold standard and the algorithm decisions are then
acquired to evaluate f (x) at the new instance and this information is used to update the Gaussian
process model of f (x). This process iterates until convergence. We call this framework single-task
algorithmic assurance.
We next move to multi-task algorithmic assurance where we extend our framework to provide
assurance for algorithms that have vector-valued outputs. Our goal now is to ﬁnd the scenario where
an algorithm maximally deviates from its gold standard across any output. For example  in alloy
design  elements are combined and heated  leading to phase formations. The strength of the resultant
alloy is related to these phase fractions. An algorithm can be used to model the relation between the
elemental composition and phases. Some phases are more common  thus statistics for each phase is
not equally strong. This makes the rarer phase prediction more error prone. We therefore need to
efﬁciently ﬁnd the elemental composition where our algorithm’s phase prediction maximally deviates
from the true phase values across any phase  since predicting each phase is equally important. This
boils down to a BO problem with C black-box expensive functions and our task is ﬁnd the largest
global maximum across all the functions. To address this efﬁciently  we formulate each function as
an arm of a multi-arm bandit and deﬁne the reward for pulling an arm as the best value found by
BO for the corresponding function (up to any iteration). This method can efﬁciently switch across C
optimisation problems to quickly discover the optimum point. We theoretically analyse this algorithm
and show that its simple regret has the order O

(cid:18)(cid:113) dln T

(cid:113)ClnC

T

(cid:19)

.

T +

It may appear superﬁcially that the multi-task BO [20] is related  however  this method optimizes
multiple related functions concurrently through mutual learning. We note that our problem is different
in two ways: (1) we do not aim to maximise each function  rather quickly identify the function with
the largest maximum and then ﬁnd its maximum point; and  (2) multiple functions in our setting need
not be related  which is a crucial assumption in the multi-task BO.
We demonstrate our framework on two problems: Prediction of strength-determining phases in
an alloy design process  and recognition of handwritten digits under visual distortions. Our main
contributions are:
• Introduction of a new notion of algorithmic assurance to assess the deviation behaviour of
• Construction of an efﬁcient framework for algorithmic assurance in both single and multi-

an algorithm from its intended use;

task settings;

2

• Demonstration of the efﬁciency of our methods using two real world applications.

The signiﬁcance of our problem formulation and solutions is that it will be the ﬁrst step towards
providing assurance to users of an algorithm.

2 An Active Approach to Algorithmic Testing

i  otr

i ) i = 1  . . .  n}. Given the dataset Dtrain

In this section we present our proposed framework for efﬁcient algorithmic testing. Let us assume
we have an unknown function a(x) to be modelled using a set of observations of the form Dtrain
n =
{(xtr
  a typical approach is to use a machine learning
algorithm (e.g. a neural network) to learn an approximation A (x) of a(x). Deﬁne a function
f (x) = L (a(x)  A (x)) that measures the deviation of A (x) from a(x) at any point x. Various form of
deviation can be used  for example  L (a(x)  A (x)) = (a(x)− A (x))2 when dealing with a regression
problem. In our proposed algorithmic testing framework  our goal is to efﬁciently identify a scenario
x∗ wherein the algorithm output A (x∗) maximally deviates from the function a(x∗). We express this
goal through the following optimisation problem

n

x∗ = argmax
x∈X

f (x) = argmax

x∈X

(a(x)− A (x))2

(1)

Since function f (x) is not known analytically  the objective function in the above optimisation
problem is treated as a black-box function. In addition  evaluating f (x) is expensive. The problem is
thus ﬁnding the optimum of an expensive  black-box function.

ε ))  collectively denoted as Dt = {xi yi}t

Bayesian Optimisation: A method that has recently become popular for efﬁcient global optimisa-
tion of expensive  black-box functions is Bayesian optimisation (BO) [17  6  7  13]. It represents the
black-box function through a probabilistic model  which is then used to reason about where in the
space the optimum is located (for exploitation of available knowledge) and where we have the least
knowledge about the function (for exploration for further knowledge). Based on this reasoning  the
function is evaluated at a new location balancing the exploration and exploitation requirements and
the new observation is used to update the function model. This sequential procedure repeats until
the global optimum is reached or the optimisation budget is exceeded. The BO algorithms [19  4]
come with an efﬁciency guarantee on their convergence and usually have sub-linear growth rate for
cumulative regret.
Gaussian processes are most popular for modelling the unknown function when doing Bayesian
optimisation though other models have also been used [9  18  14]. Using Gaussian process prior  a
function is modelled as f (x) ∼ GP (m (x)  k (x x(cid:48)))  where m is a mean function and k (x x(cid:48)) contains
the covariance of any two points on the function. With availability of noisy observations of the form
yi = f (xi) + εi (where εi ∼ N (0 σ 2
i=1  we can derive the
predictive distribution for the function value at a new observation x(cid:48) to be a Gaussian distribution [15] -
its mean and variance are given as µt (x(cid:48)) = kT (K +σ 2
ε I)−1k
where assuming k as a covariance function [15]  K is a matrix of size t ×t whose (i  j)-th element is
deﬁned as k(xi x j) and k is a vector (overloaded notation) with its i-th element deﬁned as k(x xi).
A nice property of BO when using Gaussian processes is that it usually avoids convergence to any
“spurious peaks” and mostly converges to a stable peak. This property is useful for our algorithmic
testing framework when we are interested in ﬁnding not just the location of the largest deviation of
the algorithm but a region where the deviations are generally high. This may help in understanding
the reasons of algorithm deviation and any potential remedies.
An illustrative example: To understand how BO avoids convergence to any “spurious peaks”  let us
consider an illustrative example function f (x) with two peaks (see Figure 1) at locations x0 and x(cid:48)
0 such
that f (x0) > f (x(cid:48)
0). Now consider two cases such that in the ﬁrst case  the peak at x is sharper (red)
than the second case (grey). When using a Gaussian process model  we can show that if the two cases
have previous observations at the same locations {x1  . . .  xt}  the predictive mean of the Gaussian pro-
ε I)−1y
cess model µt (x) for case-1 will be lower than that of case-2. This is because µt (x) = kT (K +σ 2
and since yi’s of the case-1 are only equal or lower than the corresponding yi’s of case-2. With the
assumption of previous observations for the two cases being at the same locations  the predictive
variance of the Gaussian process model σt (x) for both cases would be equal. Thus an acquisition func-
tion αt (x) (based on typical acquisition function such as GP-UCB [19] or EI [10]) will take a lower
value for case-1 than case-2. Since the two cases mainly differ around location x0 (see Figure)  the

t (x(cid:48)) = k(x(cid:48) x(cid:48))−kT (K +σ 2

ε I)−1y and σ 2

3

acquisition function αt (x) around x0 will be
lower for case-1 than case-2. Therefore the prob-
ability of a point x around x0 being the maxima
of αt (x) is lower for case-1 than case-2. Further 
the narrower the peak of case-1  the lower is this
probability. Therefore  Bayesian optimisation
algorithm converges to the narrower peak with
lower probability. This result would generally
hold as long as the observations used in BO have
a small measurement noise. If convergence to
narrow peaks is becoming unavoidable or com-
mon  one may resort to BO methods that are
customised to avoid spurious peaks [12  5].

3 Multi-Task Algorithmic Testing

Figure 1 – An example function illustrating spuri-
ous (red) and wider (grey) peaks.

There are several applications where we need to model vector-valued outputs. In other words  this
involves modelling multiple outputs or tasks. For example  in alloy design  for each composition
of constituent elements  we have multiple phases. Let us assume that we have trained one machine
learning model for each of these tasks. These models can be either independently or jointly trained
depending on whether the tasks are independent or related. Since each task is different  the scenario
where the algorithm output maximally deviates from the true output differs from task to task. Our
above-mentioned single-task algorithmic testing method can be applied to this multi-task problem by
aggregating the deviations for all tasks and thus can only discover the scenario where the algorithm
deviates from the true output in an average sense. However  when it is important to get the assurance
for each task or output  this approach may be insufﬁcient.
In our proposed multi-task algorithmic testing  we aim to efﬁciently discover the scenario wherein the
algorithm maximally differs from the true function for any of the outputs or tasks. Let us assume that
there are C tasks  indexed as c = 1  . . .  C and for c-th task  the true and the trained algorithm functions
are ac(x) and Ac(x) respectively. We denote the discrepancy functions between the algorithm and the
true functions by f1(x)  ...  fC(x). Each function has an optimum f ∗
c = max∀x∈X fc(x). We aim to ﬁnd
f ∗
c and the optimizer location x∗ = argmaxx∈X fc∗(x).
both the optimal index c∗ such that c∗ = argmax

c∈C

A simple approach to solve our problem is to perform Bayesian optimisation for each function fc(x)
to obtain f ∗
c and then ﬁnally ﬁnd c∗ and x∗. However this approach is inefﬁcient as it unnecessarily
evaluates the suboptimal functions for their complete Bayesian optimisation sequence. Our intuition
is that it is possible to identify the tasks for which the algorithm has high errors within few function
evaluations from all tasks and then mostly perform function evaluations for tasks with high deviations
from the gold standard.
In multi-arm bandit (MAB) research  this problem can be thought of
identifying an arm with the best reward (or simply the “best arm”). There are several algorithms to
identify the best arm  e.g. UCB1  ε-greedy  Hedge  EXP3 etc [1  2]. Of these  Hedge and EXP3
are the algorithms that can be used under most general conditions with few assumptions on reward
distributions unlike UCB1 and ε-greedy that require i.i.d. assumption. In our case  at any iteration of
Bayesian optimisation  we deﬁne the reward of choosing a task at any iteration as the best function
value reached up to that iteration from that task. Since the “best so far” statistics is not independent
across iterations  the reward distribution is not i.i.d.The use of Hedge algorithm with BO has been
considered earlier by [8] in a different context to ours. The Hedge algorithm in [8] is used to select
acquisition functions for Bayesian optimisation. A requirement of the Hedge algorithm is that it
needs the observation of rewards from each arm at all iterations. Unfortunately this requirement is not
met in our scheme as if we only receive the reward for the selected arm – a partial reward feedback
scenario. Therefore  for our multi-task algorithmic testing framework we use EXP3 algorithm [2  16]
which is capable of working in a partial reward feedback scenario.
Using the EXP3 algorithm we proceed as follows. At each iteration t  we ﬁrst select a function
indexed as ht = c and then advance its (one step) Bayesian optimisation to select the next point for
αt (x | Dt (ht )) where Dt (ht ) are
evaluation by maximising the acquisition function as xt = argmax
observations up to iteration t for the task indexed as ht. The reward for the selected function is denoted

x∈X

4

xf(x)Case1Case2x0x'0t as pc

(cid:113) C lnC

t = (1−η) ωc
∑C
c=1 ωc

by gt (c) and is deﬁned as the best function value so far  i.e. gt (c) = max∀xi∈Dt (c) fc(xi). Using rewards
C   where ωc = ωc × exp(η ˆgt (c)/C) and
+ η
gt (c)  we compute a probability pc
η =
(e−1)T is a EXP3 parameter pre-deﬁned given the maximum budget T (as per Corollary 3.2
of [2]). The probability vector pt = [p1
t ] indicates the promise of different tasks for obtaining
high values and is used to select a function for performing Bayesian optimisation. This process
continues iteratively either until convergence or the function evaluation budget is exhausted. We refer
to this algorithm as EXP3BO (see Algorithm 1).

t   ...  pC

(cid:113) C lnC

Algorithm 1 EXP3BO Algorithm for Multi-task Algorithmic Testing
Input η =
1: Init ωc = 1 ∀c = 1...C.
2:
3:

(e−1)T   C #categorical choice  T #max iteration

for t = 1 to T

+ η

t = (1− η) ωc
∑C
c=1 ωc

Compute the probability pc
Choose a categorical variable at random ht ∈ [1  ... C] ∼ pt = [p1
Optimize the acquisition function xt = argmaxαt (x|Dt (ht )) given ht.
Evaluate the blackbox function yt = f ([xt  ht = c]) and augment Dt (ht ) = Dt−1(ht )∪ (xt  yt ).
Update the reward gt (ht ) = max∀xi∈Dt (ht ) fht (xi) and normalise as ˆgt (ht ) = gt (ht )/pt
c.
Update the weight ωht = ωht × exp(η ˆgt (ht )/C).

t   ...  pC
t ].

C  ∀c = 1...C.

4:
5:
6:
7:
8:
9: end for
Output: DT

Convergence Analysis

We now present the convergence analysis. All the bounds are probabilistic bounds that hold with
high probability. Let γT be the maximum information gain over any T iterations  it can be bounded
for common kernels (e.g. for SE kernel γT ∼ O
Lemma 1. (Due to [19]) Let T be the number of iterations  d be the input space dimension  then we
can bound the simple regret ST after T iterations of GP-UCB by a sublinear term as

) [19].

(cid:16)
(lnT )d+1(cid:17)
c − fc(xt )) ≤ O(cid:16)(cid:112)γT lnT /T

( f ∗

ST = f ∗

c − max
∀xt  t≤T

fc(xt ) ≤ 1
T

(cid:17)

.

T

∑

t=1

Since we do not know which function among f1  . . .   fC has the overall maxima f ∗  as discussed
earlier a naïve algorithm can divide any available function evaluation budget T equally among C
options. We refer to this algorithm as Round-robin BO. This algorithm only allocates T
C evaluations
for the optimal function indexed by c∗. We next provide the convergence rate for this Round-robin
algorithm and later show that our proposed EXP3BO algorithm will have a tighter bound than the
Round-robin BO. Another similar naïve approach (Random Categorical BO) is to randomly select a
function and optimise. On average  this approach will also allocate T
C evaluations for each function.
Lemma 2. Given C choices  the Round-robin BO and the Random Categorical BO methods will

have the simple regret bounded as ST ≤ O((cid:112)CγT lnT /T ).

Proof. Since these methods allocate only T
Lemma 1 we can write the simple regret bound as ST = S T
√
C
the regret increases as O(
C).

C evaluations to optimize the optimal function fc∗(x)  using
C ). We can see that

(c∗) ≤ O(

T ln T

(cid:113)CγT

Lemma 3. (Due to [2]) For T > 0  setting η =
is bounded as

(e−1)T   the expected regret of the EXP3 algorithm

max
h∈[C]

T

∑

t=1

gt (h)− E

≤ O(cid:16)√

(cid:17)

TC lnC

 

(cid:34) T

∑

t=1

(cid:113) C lnC
(cid:35)

gt (ht )

5

Figure 2 – Left: Element compositions (parallel coordinates) for max error during training and test.
Bounds for each element composition in shaded regions. Right: Convergence of test error (RMSE).

where we denote gt (c) = max∀xi∈Dt (c) fc(xi). The expectation is under randomness in the algorithm
to select ht.
Theorem 4. The EXP3BO algorithm has its simple regret bounded by

E(cid:104)

SExp3BO
T

(cid:34)

(cid:105) ≤ O(cid:16)(cid:112)γT lnT /T +(cid:112)C lnC/T
(cid:40)
(cid:35)

(cid:41)

.

(cid:17)
(cid:32)(cid:114)C lnC

T

(cid:33)
(cid:3) = f ∗ − E [gT (hT )] ≤ f ∗ − E(cid:2) 1

gt (h)

< O

∑

T

.

(2)

t=1 gt (ht )(cid:3).

Proof. Let f ∗ = max∀c∈C ∀x∈X fc(x) be the optimum value that we seek. From Lemma 3  we can
write

T ∑T

Since 1
Denote the oracle simple regret as SOracle
best arm can be identiﬁed by oracle with high probability  using Lemma 1  we have SOracle

t=1 gt (h). Further assuming that the
≤

T ∑T
1

T ∑T

T

T

T

∑

1
T

−

f ∗ − E

f ∗ − max
h∈[C]

1
T

t=1

t=1

gt (ht )

t=1 gt (ht ) ≤ gT (hT )  we have E(cid:2)SEXP3BO
(cid:17)
(cid:3) < O(cid:16)(cid:112)C lnC/T

E(cid:2)SEXP3BO

= f ∗ − maxh∈[C]
(cid:17)

and thus

T

T

O(cid:16)(cid:112)γT lnT /T

+ O(cid:16)(cid:112)γT lnT /T

(cid:17)

.

We can see that the regret bound remains sublinear in T and is tighter than the regret bound of the
Random Categorical or the Round-robin algorithm.

4 Experiments

We evaluate single and multi-task assurance using the two real world applications: (1) Alloy design 
and (2) hand written digit recognition. In our algorithm  a squared exponential kernel is used for BO.
All our results are reported by aggregating results from 10 runs with each run initialized randomly.

4.1 A neural network model predicting alloy-strengthening phases

Alloys are mixtures of elements that are able to achieve properties that are not possible by a single
element. Laboriously collected experimental data elaborate how a mixture of elements form “phases”.
A phase is a homogeneous part of the alloy that has uniform physical and chemical characteristics 
and determines the alloy strength. Experimental data for alloys are contained in proprietary simulators
(eg. Thermocalc) and experimenters query such simulators for computed phase characteristics. These
complex computations are expensive.
We construct a proxy algorithm for Thermocalc using a neural network to predict phases. We then
apply our model to discover the test data point where the network prediction differs most from the
Thermocalc output. Our proxy network is trained on 1000 samples generated from Thermocalc for

6

7:%33$42548943%7 3#$$30% 8 #$0100200300400Iterations0.10.30.6RMSEAluminium 7000 series alloys that mainly consists of Aluminium and seven other elements (Cr  Cu 
Mg  Ti  Zn  Mn  Si) whose % compositions are in a deﬁned range as shown by the shaded region in
Fig. 2 (Left). Input to the network is a 7 dimensional vector of element compositions. The output is
a vector of alloy phases. After consulting with domain experts  we model 16 relevant phases. Our
neural network consists of 2 hidden layers with 14 and 36 nodes respectively. A 30% dropout was
introduced between the second layer and the output layer. The network was trained to minimize the
error averaged over 16 phases. The neural network was trained for 100 epochs using a batch size of 5.
The alloy composition corresponding to the maximal training RMSE of 0.27 was: Cr = 0.85 %  Cu=
2.06 %  Mg=0.18 %  Ti= 0.88 %  Zn= 8.25 %  Mn=0.37 %  and Si= 0.56 % (Fig. 2 (Left)). We use
this neural network model for single and multi-task assurance. Single task measures the average error
made across all phases  whilst multi-task measures error in each phase individually. In our notation  x
denotes an elemental composition and y denotes the error in phase prediction.

4.1.1 Single task assurance

We run BO for our single task assurance to discover the composition with the maximal deviation from
Thermocalc. The optimisation result is shown in Fig. 2 (Right). The element composition discovered
by our method corresponding to the maximal error is Cr = 0.38 %  Cu = 6.04 %  Mg = 4.89 %  Ti =
0.48 %  Zn = 6.95 %  Mn = 0.86 % and Si = 2.51 %. As seen from Fig. 2  our algorithm discovers a
signiﬁcantly different composition with a much larger error (0.59) in just about 200 iterations.

4.1.2 Multi-task assurance

We use EXP3BO for multi-task assurance to discover the
composition with the maximal deviation from Thermo-
calc for any alloy phase. Instead of measuring the error
averaged across all phases  we consider the error of each
phase separately. This gives rise 16 error functions where
the highest error needs to be found efﬁciently without
exhaustively optimising all. To evaluate the optimisation
efﬁciency of our proposed EXP3BO algorithm we com-
pare it against the baselines - Round-robin BO  Random
Categorical BO and SMAC [9]. To ﬁnd the phase that
has the highest error (Oracle)  we run BO for each phase
separately and identify the phase with the highest error
(c∗). Fig. 4 (Left) shows that the EXP3BO outperforms
other baselines and reaches close to the Oracle. Also
it accurately identiﬁes the “AL12MN” phase that has
the highest error - see histogram in Fig. 4 (Right). We
found the maximal error for “AL12MN” phase for RMSE=1.05  at a substantially different element
composition compared to the one found during the algorithm training stage (see Fig. 3).

Figure 3 – Element compositions (parallel
coordinates) for maximal error found dur-
ing training and test stages by EXP3BO.

Figure 4 – Alloy phase prediction using EXP3BO. Left: Performance comparison - RMSE vs
iterations. Right: Histogram of phases selected. It converges and exploits “AL12MN” phase more.

4.2 A convolutional neural network for handwritten digit recognition

We construct a proxy algorithm for recognising digits and the task is to identify the level of distortion
causing the largest error in a transformed MNIST[11] dataset. In our notation  x denotes a visual

7

7:%33$42548943%7 3#$! #$02004006008001000Iteration0.60.70.80.91.01.1RMSEThermocalcD=7C=16EXP3BORoundrobinBORandomCategoricalBOOracleSMAC#$$&*%*'*'$ **!*$*"*&$$%*%*!$'*!$%*!$4:39distortion (shear and rotation) while y denotes recognition error. The training data consists of MNIST
images distorted with shear (shx  shy) and rotation (θ ). Our training dataset is created as follows:
Each MNIST digit is ﬁrst randomly sheared between shx  shy ∈ [−0.2  0.2]  followed by a random
rotation θ ∈ [0 360]. We removed digit 9 from our data to avoid confusions with digit 6 when
subjected to rotation transform. 54 051 such sheared and rotated MNIST digits are used for training a
CNN. We use the LENET-5 architecture (as in [11]) with learning rate = 10−3 and number of epochs
set to 20. The mean training error was found to be 4.1%. Maximal error from grid search was found
to be 5.7% at shear (shx = −0.2 shy = −0.2) and rotation θ = 3◦.
4.2.1 Single assurance task

We run BO for our single task assurance to discover the
distortion for maximal recognition error. The optimisa-
tion result is shown in Fig. 5. BO discovered a highest
error of 7.1% at distortion parameters (shx = 0.088 shy =
−0.2) and rotation θ = 175.7◦.
4.2.2 Multi-task assurance

We use EXP3BO for multi-task assurance to discover
the maximal recognition error for any digits. Instead
of measuring the error averaged across all digits  we
consider error of each digit separately. This is important
because the error in recognising each digit may differ
depending on its visual complexity and distortion. Once
again we compare EXP3BO with the baselines described
in Section 4.1.2. The performance of EXP3BO is superior
to SMAC (Fig. 6 (Left)). EXP3BO selects digit ‘2’ as that with the highest error (Fig. 6 (Right)). The
confusion between digits 2  7 and 4 from shearing and rotation causes comparable performance of
other methods.
Our
AlgorithmicAssurance_NIPS2018.

Figure 5 – Single task assurance for digit
recognition- optimisation results showing
recognition error vs iteration.

https://github.com/shivapratap/

available

at URL

implementation

is

Figure 6 – Multitask assurance using EXP3BO on digit recognition. Left: Performance comparison
of recognition error vs iterations; Right: Histogram of digits selected.

5 Conclusion

We have introduced a novel problem of algorithmic assurance to assess the deviation of an algorithm
from its intended use. We have developed an efﬁcient framework for algorithmic testing for single-
task and multi-task settings. The usefulness of our framework is demonstrated on two problems:
prediction of strength-determining phases in alloy design and recognition of handwritten digits under
shear and rotation distortions. In the modern era of artiﬁcial intelligence  algorithms are increasingly
taking decisions pertinent to our life  it is very timely to build the conﬁdence that algorithms can be
trusted and our proposed algorithmic assurance framework is an early attempt towards this goal.

8

0100200300400Iterations56Error %0100200300400500Iteration051015Error%CNNMNISTD=3C=9EXP3BORoundrobinBORandomCategoricalBOOracleSMAC4:39Acknowledgements

This research was partially funded by the Australian Government through the Australian Re-
search Council (ARC). Prof Venkatesh is the recipient of an ARC Australian Laureate Fellowship
(FL170100006).

References
[1] P. Auer  N. Cesa-Bianchi  and P. Fischer. Finite-time analysis of the multiarmed bandit problem.

Machine learning  47(2-3):235–256  2002.

[2] P. Auer  N. Cesa-Bianchi  Y. Freund  and R. E. Schapire. The nonstochastic multiarmed bandit

problem. SIAM journal on computing  32(1):48–77  2002.

[3] J. Bergstra and Y. Bengio. Random search for hyper-parameter optimization. Journal of

Machine Learning Research  13(Feb):281–305  2012.

[4] A. D. Bull. Convergence rates of efﬁcient global optimization algorithms. The Journal of

Machine Learning Research  12:2879–2904  2011.

[5] T. Dai Nguyen  S. Gupta  S. Rana  and S. Venkatesh. Stable bayesian optimization.

In
Paciﬁc-Asia Conference on Knowledge Discovery and Data Mining  pages 578–591. Springer 
2017.

[6] P. Hennig and C. J. Schuler. Entropy search for information-efﬁcient global optimization.

Journal of Machine Learning Research  13:1809–1837  2012.

[7] J. M. Hernández-Lobato  M. W. Hoffman  and Z. Ghahramani. Predictive entropy search
for efﬁcient global optimization of black-box functions. In Advances in Neural Information
Processing Systems  pages 918–926  2014.

[8] M. Hoffman  E. Brochu  and N. de Freitas. Portfolio allocation for bayesian optimization. In
Proceedings of the Twenty-Seventh Conference on Uncertainty in Artiﬁcial Intelligence  pages
327–336. AUAI Press  2011.

[9] F. Hutter  H. H. Hoos  and K. Leyton-Brown. Sequential model-based optimization for general
algorithm conﬁguration. In Learning and Intelligent Optimization  pages 507–523. Springer 
2011.

[10] D. R. Jones  M. Schonlau  and W. J. Welch. Efﬁcient global optimization of expensive black-box

functions. Journal of Global optimization  13(4):455–492  1998.

[11] Y. LeCun  L. Bottou  Y. Bengio  and P. Haffner. Gradient-based learning applied to document

recognition. Proceedings of the IEEE  86(11):2278–2324  1998.

[12] J. Nogueira  R. Martinez-Cantin  A. Bernardino  and L. Jamone. Unscented bayesian opti-
mization for safe robot grasping. In Intelligent Robots and Systems (IROS)  2016 IEEE/RSJ
International Conference on  pages 1967–1972. IEEE  2016.

[13] S. Rana  C. Li  S. Gupta  V. Nguyen  and S. Venkatesh. High dimensional Bayesian optimization
with elastic gaussian process. In Proceedings of the 34th International Conference on Machine
Learning (ICML)  pages 2883–2891  2017.

[14] C. E. Rasmussen. The inﬁnite gaussian mixture model. In NIPS  volume 12  pages 554–560 

1999.

[15] C. E. Rasmussen. Gaussian processes for machine learning. Citeseer  2006.
[16] Y. Seldin  C. Szepesvári  P. Auer  and Y. Abbasi-Yadkori. Evaluation and analysis of the
performance of the exp3 algorithm in stochastic environments. In EWRL  pages 103–116  2012.
[17] J. Snoek  H. Larochelle  and R. P. Adams. Practical Bayesian optimization of machine learning

algorithms. In Advances in neural information processing systems  pages 2951–2959  2012.

[18] J. Snoek  O. Rippel  K. Swersky  R. Kiros  N. Satish  N. Sundaram  M. Patwary  M. Prabhat 
and R. Adams. Scalable bayesian optimization using deep neural networks. In Proceedings of
the 32nd International Conference on Machine Learning  pages 2171–2180  2015.

[19] N. Srinivas  A. Krause  S. Kakade  and M. Seeger. Gaussian process optimization in the bandit
setting: No regret and experimental design. In Proceedings of the 27th International Conference
on Machine Learning  pages 1015–1022  2010.

[20] K. Swersky  J. Snoek  and R. P. Adams. Multi-task Bayesian optimization. In Advances in

neural information processing systems  pages 2004–2012  2013.

9

,Shivapratap Gopakumar
Sunil Gupta
Santu Rana
Vu Nguyen
Svetha Venkatesh
Fan Yang
Liu Leqi
Yifan Wu
Zachary Lipton
Pradeep Ravikumar
Tom Mitchell
William Cohen