2016,Learning Parametric Sparse Models for Image Super-Resolution,Learning accurate prior knowledge of natural images is of great importance for single image super-resolution (SR). Existing SR methods either learn the prior from the low/high-resolution patch pairs or estimate the prior models from the input low-resolution (LR) image. Specifically  high-frequency details are learned in the former methods. Though effective  they are heuristic and have limitations in dealing with blurred LR images; while the latter suffers from the limitations of frequency aliasing. In this paper  we propose to combine those two lines of ideas for image super-resolution. More specifically  the parametric sparse prior of the desirable high-resolution (HR) image patches are learned from both the input low-resolution (LR) image and a training image dataset. With the learned sparse priors  the sparse codes and thus the HR image patches can be accurately recovered by solving a sparse coding problem. Experimental results show that the proposed SR method outperforms existing state-of-the-art methods in terms of both subjective and objective image qualities.,Learning Parametric Sparse Models for Image

Super-Resolution

Yongbo Li  Weisheng Dong∗  Xuemei Xie  Guangming Shi1  Xin Li2  Donglai Xu3
State Key Lab. of ISN  School of Electronic Engineering  Xidian University  China

1Key Lab. of IPIU (Chinese Ministry of Education)  Xidian University  China

2Lane Dep. of CSEE  West Virginia University  USA

3Sch. of Sci. and Eng.  Teesside University  UK

yongboli@stu.xidian.edu.cn  {wsdong  xmxie}@mail.xidian.edu.cn

gmshi@xidian.edu.cn  Xin.Li@mail.wvu.edu

Abstract

Learning accurate prior knowledge of natural images is of great importance for
single image super-resolution (SR). Existing SR methods either learn the prior
from the low/high-resolution patch pairs or estimate the prior models from the
input low-resolution (LR) image. Speciﬁcally  high-frequency details are learned
in the former methods. Though effective  they are heuristic and have limitations
in dealing with blurred LR images; while the latter suffers from the limitations
of frequency aliasing. In this paper  we propose to combine those two lines of
ideas for image super-resolution. More speciﬁcally  the parametric sparse prior
of the desirable high-resolution (HR) image patches are learned from both the
input low-resolution (LR) image and a training image dataset. With the learned
sparse priors  the sparse codes and thus the HR image patches can be accurately
recovered by solving a sparse coding problem. Experimental results show that the
proposed SR method outperforms existing state-of-the-art methods in terms of both
subjective and objective image qualities.

1

Introduction

Image super-resolution (SR) aiming to recover a high-resolution (HR) image from a single low-
resolution (LR) image  has important applications in image processing and computer vision  ranging
from high-deﬁnition (HD) televisions and surveillance to medical imaging. Due to the information
loss in the LR image formation  image SR is a classic ill-posed inverse problem  for which strong
prior knowledge of the underlying HR image is required. Generally  image SR methods can be
categorized into two types  i.e.  model-based and learning-based methods.
In model-based image SR  the selection of image prior is of great importance. The image priors 
ranging from smoothness assumptions to sparsity and structured sparsity priors  have been exploited
for image SR [1][3][4][13][14][15][19]. The smoothness prior models  e.g.  Tikhonov and total
variation (TV) regularizers[1]  are effective in suppressing the noise but tend to over smooth image
details. The sparsity-based SR methods  assuming that the HR patches have sparse representation with
respect to a learned dictionary  have led to promising performances. Due to the ill-posed nature of the
SR problem  designing an appropriate sparse regularizer is critical for the success of these methods.
Generally  parametric sparse distributions  e.g.  Laplacian and Generalized Gaussian models  which
correspond to the (cid:96)1 and (cid:96)p (0 ≤ p ≤ 1) regularizers  are widely used. It has been shown that the
SR performance can be much boosted by exploiting the structural self-similarity of natural images

∗Corresponding author.

30th Conference on Neural Information Processing Systems (NIPS 2016)  Barcelona  Spain.

[3][4][15]. Though promising SR performance can be achieved by the sparsity-based methods  it
is rather challenging to recover high-quality HR images for a large scaling factors  as there is no
sufﬁcient information for accurate estimation of the sparse models from the input LR image.
Instead of adopting a speciﬁcal prior model  learning-based SR methods learn the priors directly
from a large set of LR and HR image patch pairs [2][5][6][8][18]. Speciﬁcally  mapping functions
between the LR and the high-frequency details of the HR patches are learned. Popular learning-based
SR methods include the sparse coding approaches[2] and the more efﬁcient anchored neighborhood
regression methods (i.e.  ANR and A+)[5][6]. More recently  inspired by the great success of the
deep neural network (DNN)[16] for image recognition  the DNN based SR methods have also been
proposed[8]  where the DNN models is used to learn the mapping functions between the LR and
the high-frequency details of the HR patches. Despite the state-of-the-art performances achieved 
these patch-based methods [6][8] have limitations in dealing with the blurred LR images (as shown
in Sec. 5). Instead of learning high-frequency details  in [12] Li et al. proposed to learn parametric
sparse distributions (i.e.  non-zero mean Laplacian distributions) of the sparse codes from retrieved
HR images that are similar to the LR image. State-of-the-art SR results have been achieved for the
landmark LR images  for which similar HR images can be retrieved from a large image set. However 
it has limitations for general LR images (i.e.  it reduces to be the conventional sparsity-based SR
method)  for which correlated HR images cannot be found in the image database.
In this paper  we propose a novel image SR approach combining the ideas of sparsity-based and
learning-based approaches for SR. The sparse prior  i.e.  the parametric sparse distributions (e.g. 
Laplace distribution) are learned from general HR image patches. Speciﬁcally  a set of mapping
functions between the LR image patches and the sparse codes of the HR patches are learned. In
addition to the learned sparse prior  the learned sparse distributions are also combined with those
estimated from the input LR image. Experimental results show that the proposed method performs
much better than the current state-of-the-art SR approaches.

2 Related works

(cid:88)

(x  α) = argmin

||y − Hx||2

In model-based SR  it is often assumed that the desirable HR image/patches have sparse expansions
with respect to a certain dictionary. For a given LR image y = Hx + n  where H ∈ RM×N speciﬁes
the degradation model  x ∈ RN and n ∈ RM denote the original image and additive Gaussian noise 
respectively. Sparsity-based SR image reconstruction can be formulated as [3][4]
2 + λψ(α)} 
{||Rix − Dαi||2
√
n × √

where Ri ∈ Rn×N denotes the matrix extracting image patch of size
n at position i from x 
D ∈ Rn×K denotes the dictionary that is an off-the-shelf basis or learned from an training dataset 
and ψ(·) denotes the sparsity regularizer. As recovering x from y is an ill-posed inverse problem 
the selection of ψ(·) is critical for the SR performance. Common selection of ψ(·) is the (cid:96)p-norm
(0 ≤ p ≤ 1) regularizer  where zero-mean sparse distributions of the sparse coefﬁcients are assumed.
In [12]  nonzero-mean Laplacian distributions are used  leading to the following sparsity-based SR
method 

2 + η

(1)

x α

i

(x  α) = argmin

x α

||y − Hx||2

2 + η

{||Rix − Dαi||2

2 + ||Λi(αi − βi)||1} 

(2)

√

2σ2
n

θi j

where Λ = diag( 2
)  θi and βi denote the standard derivation and expectation of αi  respectively.
It has been shown in [3] that by estimating {βi  θi} from the nonlocal similar image patches of
the input image  promising SR performance can be achieved. However  for large scaling factors 
it is rather challenging to accurately estimate {βi  θi} from the input LR image  due to the lack
of sufﬁcient information. To overcome this limitations  Li et al.  propose to learn the parametric
distributions from retrieved similar HR images [12] via block matching  and obtain state-of-the-art
SR performance for landmark images. However  for general LR images  for which similar HR images
cannot be found  the sparse prior (βi  θi) cannot be learned.
Learning-based SR methods resolve the SR problem by learning mapping functions between LR and
HR image patches [2][6][8]. Popular methods include the sparse coding methods [2]  where LR/HR
dictionary pair is jointly learned from a training set. The sparse codes of the LR patches with respect

(cid:88)

i

2

to the LR dictionary are inferred via sparse coding and then used to reconstruct the HR patches with
the HR dictionary. To reduce the computational complexity  anchored neighborhood points (ANR)
and its advanced version (i.e.  A+) methods [6] have been proposed. These methods ﬁrst divided the
patch spaces into many clusters  then LR/HR dictionary pairs are learned for each cluster. Mapping
functions between the LR/HR patches are learned for each cluster via ridge regression. Recently 
deep neural network (DNN) model has also been developed to learn the mapping functions between
the LR and HR patches [8]. The advantages of the DNN model is that the entire SR pipeline is
jointly optimized via end-to-end learning  leading to state-of-the-art SR performance. Despite the
excellent performances  these learning-based methods focusing on learning the mapping functions
between LR and HR patches have limitations in recovering a HR image from a blurry LR image
generated by ﬁrst applying a low-pass ﬁltering followed by downsampling (as shown in Sec. 4). In
this paper  we propose a novel image SR method by taking advantages of both the sparse-based and
the example-based SR approaches. Speciﬁcally  mapping functions between the LR patches and
the sparse codes of the desirable HR patches are learned. Hence  sparse prior can be learned from
both the training patches and the input LR image. With the learned sparse prior  state-of-the-art SR
performance can be achieved.

3 Learning Parametric Sparse Models

In this section  we ﬁrst propose a novel method to learn the sparse codes of the desirable HR patches
and then present the method to estimate the parametric distributions from both the predicted sparse
codes and those of the LR images.

3.1 Learning the sparse codes from LR/HR patch pairs
For a given LR image patch yi ∈ Rm  we aim to learn the expectation of the sparse code αi of the
desirable HR patch xi with respect to dictionary D. Without the loss of generality  we deﬁne the
learning function as
(3)
where zi denotes the feature vector extracted from the LR patch yi  W ∈ RK×m is the weighting
matrix and b ∈ RK is the bias  and g(·) denotes an activation function. Now  the remaining task
is to learn the parameters of the learning function of Eq. (3). To learn the parameters  we ﬁrst
construct a large set of LR feature vectors and HR image patch pairs {(zi  xi)}  i = 1  2 ···   N.
For a given dictionary  the sparse codes αi of xi can be obtained by a sparse coding algorithm. Then 
the parameters W = {W  b} can be learned by minimizing the following objective function

˜αi = f (zi; W  b) = g(W ∗ zi + b) 

(W  b) = argmin

W b

||αi − f (zi; W  b)||2
2.

(4)

N(cid:88)

i=1

(cid:88)

i∈Sk

The above optimization problem can be iteratively solved by using a stochastic gradient descent
approach.
Considering the highly complexity of the mapping function between the LR feature vectors and the
desirable sparse codes  we propose to learn a set of mapping functions for each possible local image
structures. Speciﬁcally  the K-means clustering algorithm is used to cluster the LR/HR patches into
K clusters. Then  a mapping function is learned for each cluster. After clustering  the LR/HR patches
in each cluster generally contain similar image structures  and linear mapping function would be
sufﬁcient to characterize the correlations between the LR feature vectors and the sparse codes of
the desirable HR patches. Therefore  for each cluster Sk  the mapping function can be learned via
minimizing

(Wk  bk) = argmin
Wk bk

||αi − (Wkzi + bk)||2
2.

(5)

For simplicity  the bias term bk in the above equation can be absorbed into Wk by rewriting Wk and
zi as Wk = [Wk  bk] and zi = [z(cid:62)
i ; 1](cid:62)  respectively. Then  the parameters Wk can be easily solved
via a least-square method.
As the HR patches in each cluster generally have similar image structures  a compact dictionary
should be sufﬁcient to represent the various HR patches. Hence  instead of learning an overcomplete
dictionary for all HR patches  an orthogonal basis is learned for each cluster Sk. Speciﬁcally  a PCA

3

Algorithm 1 Sparse codes learning algorithm
Initialization:

conventional SR method;

(a) Construct a set of LR and HR image pairs {y  x} and recover the HR images { ˆx} with a
(b) Extract feature patches zi  the LR and HR patches yi and xi from { ˆx  y  x}  respectively;
(c) Clustering {zi  yi  xi} into K clusters using K-means algorithm.

Outer loop: Iteration on k = 1  2 ···   K

(a) Calculate the PCA basis Dk for each cluster using the HR patches belong to the k-th cluster;
(b) Computer the sparse codes as αi = Sλ(D(cid:62)
xi) for each xi  i ∈ Sk;
(c) Learn the parameters W of the mapping function via solving Eq. (5).

ki

End for

Output: {Dk Wk}.

basis  denoted as Dk ∈ Rn×n is learned for each Sk  k = 1  2 ···   K. Then  the sparse codes αi can
be easily obtained αi = Sλ(D(cid:62)
xi)  where Dki denotes the PCA basis of the ki-th cluster. Regarding
the feature vectors zi  we extract feature vectors from an initially recovered HR image  which can be
obtained with a conventional sparsity-based method. Similar to [5][6]  the ﬁrst- and second-order
gradients are extracted from the initially recovered HR image as the features. However  other more
effective features can also be used. The sparse distribution learning algorithm is summarized in
Algorithm 1.

ki

3.2 Parametric sparse models estimation

After learning linearized mapping functions  denoted as ˜αi  the estimates of αi can be estimated from
LR patch via Eq. (3). Based on the observation that natural images contain abundant self-repeating
structures  a collection of similar patches can often be found for an exemplar patch. Then  the mean
of αi can be estimated as a weighted average of the sparse codes of the similar patches. As the
original image is unknown  an initial estimate of the desirable HR image  denoted as ˆx is obtained
using a conventional SR method  e.g.  solving Eq. (2). Then  the search of similar patches can be
conducted based on ˆx. Let ˆxi denote the patch extracted from ˆx at position i and ˆxi l denote the
patches similar to ˆxi that are within the ﬁrst L-th closest matches  l = 1  2 ···   L. Denoted by zi l
the corresponding features vectors extracted from ˆx. Therefore  the mean of βi can be estimated by

L(cid:88)

l=1

L(cid:88)

˜βi =

wi l ˜αi l 

(6)

c exp(−|| ˆxi l − ˆxi||/h)  c is the normalization constant  and h is the predeﬁned

where wi l = 1
parameter.
Additionally  we can also estimate the mean of space codes αi directly from the intermediate estimate
of target HR image. For each initially recovered HR patch ˆxi  the sparse codes can be obtained
via a sparse coding algorithm. As the patch space has been clustered into K sub-spaces and a
compact PCA basis is computed for each cluster  the sparse code of ˆxi can be easily computed as
ˆαi j = Sλ(D(cid:62)
ˆxi j)  where Sλ(·) is the soft-thresholding function with threshold λ  ki denote the
cluster that ˆxi falls into. The sparse codes of the set of similar patches ˆxi l can also be computed.
Then  the expectation of βi can be estimated as

ki

ˆβi =

wi j ˆαi l.

Then  an improved estimation of βi can be obtained by combining the above two estimates  i.e. 

l=1

βi = ∆ ˜βi + (1 − ∆) ˆβi.

4

(7)

(8)

where ∆ = ωdiag(δj) ∈ RK×K. Similar to [12]  δj is set according to the energy ratio of ˜βi(j) and
ˆβi(j) as

  rj = ˜βi(j)/ ˆβi(j).

(9)

And ω is a predeﬁned constant. After estimating βi  the variance of the sparse codes are estimated as

r2
j

δj =

j + 1/r2
r2
j

L(cid:88)

j=1

θ2
i =

1
L

( ˆαi j − βi)2.

The learned parametric Laplacian distributions with {βi  θi} for image patches xi are then used with
the MAP estimator for image SR in the next section.

Image Super-Resolution with learned Parametric Sparsity Models

4
With the learned parametric sparse distributions {(βi  θi)}  image SR problem can be formulated as

(cid:88)

L(cid:88)

( ˆx  ˆAi) = argmin
xi Ai

||y − xH||2

2 + η

{|| ˜Rix − DkiAi||2

F + λ

||Λi(αi l − βi)||1} 

(11)

i

l=1

where ˜Rix = [Ri 1x  Ri 2x ···   Ri Lx] ∈ Rn×L denotes the matrix formed by the similar patches 
Ai = [αi 1 ···   αi L]  Dki denotes the selected PCA basis of the ki-th cluster  and Λi = diag( 1
).
In Eq.
(11)  the group of similar patches is assumed to follow the same estimated parametric
distribution {βi  θi}. Eq. (11) can be approximately solved via alternative optimization. For ﬁxed
xi  the sets of sparse codes Ai can be solved by minimizing

θi j

ˆAi = argmin

Ai

|| ˜Rix − DkiAi||2

F + λ

||Λi(αi l − βi)||1

(12)

As the orthogonal PCA basis is used  the above equation can be solved in closed-form solution  i.e. 

(10)

(13)

(14)

(15)

L(cid:88)

l=1

(cid:88)

i

ˆαi l = Sτi(D(cid:62)

kiRi lx − βi) + βi 

where τi = λ/θi. With estimated ˆAi  the whole image can be estimated by solving

ˆx = argmin

x

||y − xH||2

2 + η

|| ˜Rix − DkiAi||2
F  

which is a quadratic optimization problem and admits a closed-form solution  as

ˆx = (H(cid:62)H + η

˜Ri)−1(H(cid:62)y + η

(cid:62)
i Dki

˜R

ˆAi) 

(cid:62)
i

(cid:88)
ˆAi =(cid:80)L

˜R

i

(cid:62)
i Dki

(cid:88)

i

˜Ri =(cid:80)L

(cid:62)
i

l=1 R(cid:62)

l Rl and ˜R

where ˜R
l Dki ˆαi l. As the matrix to be inverted in Eq.
(15) is very large  the conjugate gradient algorithm is used to compute Eq. (15). The proposed image
SR algorithm is summarized in Algorithm 2. In Algorithm 2  we iteratively extract the feature
patches from ˆx(t) and learn ˜βi from the training set  leading to further improvements in predicting
the sparse codes with the learned mapping functions.

l=1 R(cid:62)

5 Experimental results

In this section  we verify the performance of the proposed SR method. For fair comparisons  we
use the relative small training set of images used in [2][6]. The training images are used to simulate
the LR images  which are recovered by a sparsity-based method (e.g.  the NCSR method [3]). Total
100  000 features and HR patches pairs are extracted from the reconstructed HR images and the
original HR images. Patches of size 7 × 7 are extracted from the feature images and HR images.
Similar to [5][6]  the PCA technique is used to reduce the dimensions of the feature vectors. The
training patches are clustered into 1000 clusters. The other major parameters of the proposed SR

5

Algorithm 2 Image SR with Learned Sparse Representation
Initialization:

(a) Initialize ˆx(0) with a conventional SR method;
(b) Set parameters η and λ;

Outer loop: Iteration over t = 0  1 ···   T

(a) Extract feature vectors zi from ˆx(t) and cluster the patches into clusters;
(b) Learn ˜βi for each local patch using Eq. (6);
(c) Update the estimate of βi using Eq. (8) and estimate θi with Eq. (10);
(d) Inner loop (solve Eq.(11)): iteration over j = 1  2 ···   J;

i

by solving Eq.(13);

(I) Compute A(j+1)
(II) Update the whole image ˆx(j+1) via Eq. (15);
(III) Set x(t+1) = x(j+1) if j = J.
End for
Output: x(t+1).

method are set as: L = 12  T = 8  and J = 10. The proposed SR method is compared with several
current state-of-the-art image SR methods  i.e.  the sparse coding based SR method (denoted as
SCSR)[2]  the SR method based on sparse regression and natural image prior (denoted as KK) [7] 
the A+ method [6]  the recent SRCNN method [8]  and the NCSR method [3]. Note that the NCSR is
the current sparsity-based SR method. Three images sets  i.e.  Set5[9]  Set14[10] and BSD100[11] 
which consists of 5  14 and 100 images respectively  are used as the test images.
In this paper  we consider two types of degradation when generating the LR images  i.e.  the bicubic
image resizing function implemented with imresize in matlab and Gaussian blurring followed by
downsampling with a scaling factor  both of which are commonly used in the literature of image SR.

5.1

Image SR for LR images generated with bicubic interpolation function

In [2][6][7][8]  the LR images are generated with the bicubic interpolation function (i.e.  imresize
function in Matlab)  i.e.  y = B(x) + n  where B(·) denotes the bicubic downsampling function. To
deal with this type of degradation  we implement the degradation matrix H as an operator that resizes
s and implement H(cid:62) as an operator that
a HR image using bicubic function with scaling factors of 1
upscales a LR image using bicubic function with scaling factor s  where s = 2  3  4. The average
PSNR and SSIM results of the reconstructed HR images are reported in Table 1. It can be seen that
the SRCNN method performs better than the A+ and the SCSR methods. It is surprising to see that
the NCSR method  which only exploits the internal similar samples performs comparable with the
SRCNN method. By exploiting both the external image patches and the internal similar patches  the
proposed method outperforms the NCSR. The average PSNR gain over SRCNN can be up to 0.64
dB. Parts of some reconstructed HR images by the test methods are shown in Fig. 1  from which
we can see that the proposed method reproduces the most visually pleasant HR images than other
competing methods. Please refer to the supplementary ﬁle for more visual comparison results.

5.2

Image SR for LR images generated with Gaussian blur followed by downsampling

Another commonly used degradation process is to ﬁrst apply a Gaussian kernel followed by down-
sampling. In this experimental setting  the 7 × 7 Gaussian kernel of standard deviation of 1.6 is used 
followed by downsampling with scaling factor s = 2  3  4. For these SCSR  KK  A+ and SRCNN
methods  which cannot deal with the Gaussian blur kernel  the iterative back-projection [17] method
is applied to the reconstructed HR images by those methods as a post processing to remove the
blur. The average PSNR and SSIM results on the three test image sets are reported in Table 2. It
can be seen that the performance of the example-based methods  i.e.  SCSR[2]  KK[7]  A+[6] and
SRCNN[8] methods are much worse than the NCSR [3] method. Compared with the NCSR method 
the average PSNR gain of the proposed method can be up to 0.46 dB  showing the effectiveness of
the proposed sparse codes learning method. Parts of the reconstructed HR images are shown in Fig. 2

6

Table 1: Average PSNR and SSIM results of the test methods (LR images generated with bicubic
resizing function)

Images
Upscaling
SCSR[2]

KK[7]

A+[6]

SRCNN[8]

NCSR[3]

Proposed

×2
-

36.22
0.9514
36.55
0.9544
36.66
0.9542
36.68
0.9550
36.99
0.9551

Se5
×3
31.42
0.8821
32.29
0.9037
32.59
0.9088
32.75
0.9090
33.05
0.9149
33.39
0.9173

×4
-

30.03
0.8544
30.29
0.8603
30.49
0.8628
30.77
0.8720
31.04
0.8779

×2
-

32.12
0.9029
32.28
0.9056
32.45
0.9067
32.26
0.9058
32.61
0.9072

Set14
×3
28.31
0.7954
28.39
0.8135
29.13
0.8188
29.30
0.8215
29.30
0.8239
29.59
0.8264

×4
-

27.15
0.7422
27.33
0.7491
27.50
0.7513
27.52
0.7563
27.77
0.7620

×2
-

31.08
0.8834
31.21
0.8863
31.36
0.8879
31.14
0.8863
31.42
0.8879

BSD100

×3
26.54
0.7729
28.15
0.7780
28.29
0.7835
28.41
0.7863
28.37
0.7872
28.56
0.7899

×4
-

26.69
0.7017
26.82
0.7087
26.90
0.7103
26.91
0.7143
27.08
0.7187

(a) Original

(b) Bicubic

(c) SCSR / 26.01dB

(d) KK / 26.49dB

(e) A+ / 26.55dB

(f) SRCNN / 26.71dB

(g) NCSR / 27.11dB

(h) Proposed / 27.35dB

Figure 1: SR results on image ’86000’ of BSD100 of scaling factor 3 (LR image generated with
bicubic interpolation function).

and Fig. 3. Obviously  the proposed method can recover sharper edges and ﬁner details than other
competing methods.

6 Conclusion

In this paper  we propose a novel approach for learning parametric sparse models for image super-
resolution. Speciﬁcally  mapping functions between the LR patch and the sparse codes of the desirable
HR patches are learned from a training set. Then  parametric sparse distributions are estimated from
the learned sparse codes and those estimated from the input LR image. With the learned sparse
models  the sparse codes and thus the HR image patches can be accurately recovered by solving a
sparse coding problem. Experimental results show that the proposed SR method outperforms existing
state-of-the-art methods in terms of both subjective and objective image qualities.

Acknowledgments

This work was supported in part by the Natural Science Foundation (NSF) of China under Grants(No.
No. 61622210  61471281  61632019  61472301  and 61390512)  in part by the Specialized Research
Fund for the Doctoral Program of Higher Education (No. 20130203130001).

7

Table 2: Average PSNR and SSIM results of the test methods of scaling factor 3 (LR images generated
with Gaussian kernel followed by downsampling)
A+[6]
29.39
0.8502
26.96
0.7627
26.59
0.7331

SCSR[2] KK[7]
30.28
0.8536
27.46
0.7640
27.10
0.7342

33.49
0.9165
29.63
0.8255
28.60
0.7887

30.22
0.8484
27.51
0.7619
27.10
0.7338

33.03
0.9106
29.28
0.8203
28.35
0.7841

Set5

Set14

BSD100

SRCNN[8] NCSR[3]

Proposed

30.20
08514
27.48
0.7638
27.11
0.7338

(a) Original

(b) Bicubic

(c) SCSR / 29.85dB

(d) KK / 29.94dB

(e) A+ / 29.48dB

(f) SRCNN / 29.88dB (g) NCSR / 32.97dB (h) Proposed / 33.84dB

Figure 2: SR results on ’Monarch’ from Set14 of scaling factor 3 (LR images generated with Gaussian
blur followed downsampling).

(a) Original

(b) Bicubic

(c) SCSR / 32.22dB

(d) KK / 32.12dB

(e) A+ / 30.81dB

(f) SRCNN / 32.16dB (g) NCSR / 34.59dB (h) Proposed / 35.15dB

Figure 3: SR results on ’Pepper’ from Set14 of scaling factor 3 (LR images generated with Gaussian
blur followed downsampling).

8

References

[1] A. Marquina and S. J. Osher. Image super-resolution by TV-regularization and bregman iteration. Journal of
Scientiﬁc Computing  37(3):367–382  2008.
[2] J. Yang  J. Wright  T. S. Huang  and Y. Ma. Image super-resolution via sparse representation. IEEE
transactions on image processing  19(11):2861–2873  2010.
[3] W. Dong  L. Zhang  G. Shi  and X. Li. Nonlocally centralized sparse representation for image restoration.
IEEE Transactions on Image Processing  22(4):1620–1630  2013.
[4] W. Dong  G. Shi  Y. Ma  and X. Li. Image restoration via simultaneous sparse coding: Where structured
sparsity meets gaussian scale mixture. International Journal of Computer Vision  114(2-3):217–232  2015.
[5] R. Timofte  V. De Smet  and L. Van Gool. Anchored neighborhood regression for fast example-based
super-resolution. In Proceedings of the IEEE International Conference on Computer Vision  pages 1920–1927 
2013.
[6] R. Timofte  V. De Smet  and L. Van Gool. A+: Adjusted anchored neighborhood regression for fast
super-resolution. In Asian Conference on Computer Vision  pages 111–126. Springer  2014.
[7] K. I. Kim and Y. Kwon. Single-image super-resolution using sparse regression and natural image prior. IEEE
Transactions on Pattern Analysis and Machine Intelligence  32(6):1127–1133  2010.
[8] C. Dong  C. C. Loy  K. He  and X. Tang. Image super-resolution using deep convolutional networks. IEEE
transactions on pattern analysis and machine intelligence  38(2):295–307  2016.
[9] M. Bevilacqua  A. Roumy  C. Guillemot  and M. L. AlberiMorel. Low-complexity single-image super-
resolution based on nonnegative neighbor embedding. 2012.
[10] R. Zeyde  M. Elad  and M. Protter. On single image scale-up using sparse-representations. In International
conference on curves and surfaces  pages 711–730. Springer  2010.
[11] D. Martin  C. Fowlkes  D. Tal  and J. Malik. A database of human segmented natural images and its
application to evaluating segmentation algorithms and measuring ecological statistics. In Computer Vision  2001.
ICCV 2001. Proceedings. Eighth IEEE International Conference on  volume 2  pages 416–423. IEEE  2001.
[12] Y. Li  W. Dong  G. Shi  and X. Xie. Learning parametric distributions for image super-resolution: Where
patch matching meets sparse coding. In Proceedings of the IEEE International Conference on Computer Vision 
pages 450–458  2015.
[13] W. Dong  L. Zhang  G. Shi  and X. Wu. Image deblurring and super-resolution by adaptive sparse domain
selection and adaptive regularization. IEEE Transactions on Image Processing  20(7):1838–1857  2011.
[14] W. Dong  L. Zhang  and G. Shi. Centralized sparse representation for image restoration. In 2011 Interna-
tional Conference on Computer Vision  pages 1259–1266. IEEE  2011.
[15] G. Yu  G. Sapiro  and S. Mallat. Solving inverse problems with piecewise linear estimators: From gaussian
mixture models to structured sparsity. IEEE Transactions on Image Processing  21(5):2481–2499  2012.
[16] A. Krizhevsky  I. Sutskever  and G. E. Hinton. Imagenet classiﬁcation with deep convolutional neural
networks. In Advances in neural information processing systems  pages 1097–1105  2012.
[17] M. Irani and S. Peleg. Motion analysis for image enhancement: Resolution  occlusion  and transparency.
Journal of Visual Communication and Image Representation  4(4):324–335  1993.
[18] D. Dai  R. Timofte  and L. Van Gool. Jointly optimized regressors for image super-resolution. In Computer
Graphics Forum  volume 34  pages 95–104. Wiley Online Library  2015.
[19] K. Egiazarian and V. Katkovnik. Single image super-resolution via BM3D sparse coding. In Signal
Processing Conference (EUSIPCO)  2015 23rd European  pages 2849–2853. IEEE  2015.

9

,Yongbo Li
Weisheng Dong
Xuemei Xie
GUANGMING Shi
Xin Li
Donglai Xu
Dominique Joncas
Marina Meila
James McQueen