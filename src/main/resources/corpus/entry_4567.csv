2012,Rational inference of relative preferences,Statistical decision theory axiomatically assumes that the relative desirability of different options that humans perceive is well described by assigning them option-specific scalar utility functions. However  this assumption is refuted by observed human behavior  including studies wherein preferences have been shown to change systematically simply through variation in the set of choice options presented. In this paper  we show that interpreting desirability as a relative comparison between available options at any particular decision instance results in a rational theory of value-inference that explains heretofore intractable violations of rational choice behavior in human subjects. Complementarily  we also characterize the conditions under which a rational agent selecting optimal options indicated by dynamic value inference in our framework will behave identically to one whose preferences are encoded using a static ordinal utility function.,Rational inference of relative preferences

Nisheeth Srivastava

Dept of Computer Science
University of Minnesota

Paul R Schrater
Dept of Psychology

University of Minnesota

Abstract

Statistical decision theory axiomatically assumes that the relative desirability of
different options that humans perceive is well described by assigning them option-
speciﬁc scalar utility functions. However  this assumption is refuted by ob-
served human behavior  including studies wherein preferences have been shown
to change systematically simply through variation in the set of choice options
presented. In this paper  we show that interpreting desirability as a relative com-
parison between available options at any particular decision instance results in a
rational theory of value-inference that explains heretofore intractable violations of
rational choice behavior in human subjects. Complementarily  we also character-
ize the conditions under which a rational agent selecting optimal options indicated
by dynamic value inference in our framework will behave identically to one whose
preferences are encoded using a static ordinal utility function.

1

Introduction

Normative theories of human choice behavior have long been based on how economic theory has
postulated they should be made. The standard version of the theory states that consumers seek to
maximize innate  stable preferences over the options they consume. Preferences are represented by
numerical encoding of value in terms of utilities  and subjects are presumed to select the option with
the maximum expected utility. The most difﬁcult part of this theory is that preferences must exist
before decisions can be made. The standard response  in both economics and decision theory  to the
basic question “Where do preferences come from?” is “We’ll leave that one to the philosophers 
utilities are simply abstractions we assume for the work we do.”  which  while true  is not an answer.
While this question has been studied before in the form of learning utility values from behavior [5 
14  10]  human preferences exhibit patterns of behavior that are impossible to reconcile with the idea
that stable numerical representations of value can be ascribed to each item they choose between.
Behavioral experiments in the last half century have conclusively demonstrated (see [18] for a
comprehensive review) that human choice strongly violates the key axioms that the existence of
stable utility values depends on. A particular subset of these violations  called context effects  wound
the utility maximization program the most deeply  since such violations cannot be explained away
as systematic distortions of underlying utility and/or probability representations [22]. Consider for
instance  the “frog legs” thought problem  pictured in Figure 1  introduced by Luce and Raiffa in
their seminal work [15]. No possible algebraic reformulation of option-speciﬁc utility functions
can possibly explain preference reversals of the type exhibited in the frog legs example. Preference
reversals elicited through choice set variation have been observed in multiple empirical studies 
using a variety of experimental tasks  and comprise one of the most powerful criticisms of the use
of expected utility as a normative standard in various economic programs  e.g.
in public goods
theory. However  for all its problems  the mathematical simplicity of the utility framework and lack
of principled alternatives has allowed it to retain its central role in microeconomics [12]  machine
learning [1]  computational cognitive science [7] and neuroscience [11].

1

(a) When asked to select between just
salmon and steak  the diner picks salmon  in-
dicating salmon (cid:31) steak by his choice

(b) When presented with an additional third
menu item  the diner picks steak  indicating
steak (cid:31) salmon

Figure 1: Illustration of Luce’s ‘frog legs’ thought experiment. No possible absolute utility assigna-
tion to individual items can account for the choice behavior exhibited by the diner in this experiment.
The frog legs example is illustrative of reversals in preference occuring solely through variation in
the set of options a subject has to choose from.

Our contribution in this paper is the development of a rational model that infers preferences from
limited information about the relative value of options. We postulate that there is a value inference
process that predicts the relative goodness of items in enabling the agent to achieve its homeostatic
and other longer-range needs (e.g. survival and reproductive needs). While this process should be
fully explicated  we simply don’t know enough to make detailed mathematical models. However 
we show that we only have to postulate that feedback from decisions provides limited information
about the relative worth of options within the choice set for a decision to retrieve an inductive rep-
resentation of value that is equivalent to traditional preference relations. Thus  instead of assuming
utilities as being present in the environment  we learn an equivalent sense of option desirability from
information in a limited format that depends on the set of options in the decision set. This induc-
tive methodology naturally makes choice sets informative about the value of options  and hence
affords simple explanations for context effects. We show how to formalize the idea of relative value
inference  and that it provides a new rational foundation for understanding the origins of human
preferences.

2 Human Preferences via Value Inference

We begin by reviewing and formalizing probabilistic decision-making under uncertainty. An agent
selects between possibilities x in the world represented by the set X . The decision-making problem
can be formulated as one wherein the agent forms a belief b(x)  x ∈ X about the relative desirability
of different possibilities in X and uses this belief to choose an element or subset X ∗ ⊂ X . When
these beliefs satisfy the axioms of utility  the belief function simply the expected utility associated
with individual possibilities u(x)  u : X → R.
We assume these desirabilities must be learned from experience  suggesting a reinforcement learn-
ing approach. The agent’s belief about the relative desirability of the world is constantly updated by
information that it receives about the desirability of options in terms of value signals r(x). Belief
updating produces transition dynamics on bt(x). Given a sequence of choices  the normative expec-
tation is for agents to select possibilities in a way that maximizes their inﬁnite-horizon cumulative
discounted desirability 

∞(cid:88)

t

arg max
x(t)

γtbt(x).

(1)

The sequence of choices selected describes the agent’s expected desirability maximizing behavior
in a belief MDP-world.

2

From a Bayesian standpoint  it is critical to describe the belief updating about the desirability of dif-
ferent states. Let p(x|r(1:t)) represent the belief a value x is the best option given a sequence of value
signals. Since the agent learns this distribution from observing r(x) signals from the environment 
an update of the form 

p(x|r(t)) = p(r(t)|x) × p(x|{r(1)  r(2) ···   r(t−1)}) 

(2)
reﬂects the basic process of belief formation via value signals. When value signals are available for
every option  independent of other options  the likelihood term p(r|x) in Equation (2) is a probabilis-
tic representation of observed utility  which remains unaffected in the update by the agent’s history
of sampling past possibilities and hence is invariant to transition probabilities. Such separation be-
tween utilities and probabilities in statistical decision theory is called probabilistic sophistication 
an axiom that underlies almost all existing computational decision theory models [11].
The crux of our new approach is that we assume that value signals p(r|x) are not available for
every option . Instead  we assume we get partial information about the value of one or more options
within the set of options c available in the decision instance t. In this case value signals are hidden
for most options x. However  the set of options c ∈ C ⊆ P(X )1 observed can now potentially be
used as auxiliary information to impute values for options whose value has not been observed. In
such a scenario  the agent requires a more sophisticated inference process 

p(x|r(1:t)) =

=

1

p(r(1:t))

1

p(r(1:t))

c

c

p(x  c  r(1:t)) 

[p(rt|x  c)p(c|x)] × p(x|{r(1)  r(2) ···   r(t−1)}).

(cid:90)
(cid:90)

Importantly  we concentrate on understanding the meaning of utility in this framework. As in the
case of value observability for all options  a probabilistic representation of utility under indirect
observability must be equivalent to 

(cid:82)
(cid:82)
c p(r  x  c)
c p(x|c)p(c)

(cid:82)

=

(cid:82)
c p(r|x  c)p(x|c)p(c)
c p(x|c)p(c)

.

(3)

p(r|x) =

p(r  x)
p(x)

=

The resulting prediction of value of an option couples value signals received across decision in-
stances with different option sets  or contexts. The intuition behind this approach is contained in the
frog leg’s example - the set of options become informative about the hidden state of the world  like
whether the restaurant has a good chef.
Naively  one could assume that altering existing theory to include this additional source of informa-
tion would be an incremental exercise. However  a formidable epistemological difﬁculty arises as
soon as we attempt to incorporate context into utility-based accounts of decision-making. To see
this  let us assume that we have deﬁned a measure of utility u(x  c) that is sensitive to the context c
of observing possibility x. Now  for such a utility measure  if it is true that for any two possibilities
{xi  xj} and any two contexts {ck  cl} 

u(xi  ck) > u(xj  ck) ⇒ u(xi  cl) > u(xj  cl) 

then the choice behavior of an agent maximizing u(x  c) would be equivalent to one maximiz-
ing u(x). Thus  for the inclusion of context to have any effect  there must exist at least some
{xi  xj  ck  cl} for which the propositions u(xi  ck) > u(xj  ck) and u(xi  cl) < u(xj  cl) can hold
simultaneously.
Note however  that the context in this operationalization is simply a collection of other possibilities 
i.e. c ⊆ X which ultimately implies u(x  c) = u(X ∗) = u(X ) X ∗ = {x  c} ⊆ X . Such a
measure could assign absolute numbers to each of the possibilities  but any such static assignment
would make it impossible for the propositions u(x1 X ) > u(x2 X ) and u(x1 X ) < u(x2 X )
to hold simultaneously  as is desired of a context-sensitive utility measure. Thus  we see that it is
impossible to design a utility function u such that u : X × C → R. If we wish to incorporate the
effects of context variation on the desirability of a particular world possibility  we must abandon a
foundational premise of existing statistical decision theory - the representational validity of absolute
utility.

1P(·) references the power set operation throughout this paper.

3

3 Rational decisions without utilities

In place of the traditional utility framework  we deﬁne an alternative conceptual partitioning of the
world X as a discrete choice problem. In this new formulation  at any decision instant t  agents
observe the feasibility of a subset o(t) ⊆ X of all the possibilities in the world. In the following
exposition  we use yt to denote an indicator function on X encoding the possibilities observed as
o(t) 

yt(x) =

δ(x − i) 

(cid:88)

i∈o(t)

(cid:88)

i∈c(t)

. An intelligent agent will encode its understanding of partial observability as a belief over which
possibilities of the world likely co-occur. We call an agent’s belief about the co-occurrence of
possibilities in the world its understanding of the context of its observation. We instantiate contexts
c as subsets of X that the agent believes will co-occur based on its history of partial observations of
the world and index them with an indicator function z on X   so that for context c(t) 

zt(x) =

δ(x − i).

Instead of computing absolute utilities on all x ∈ X   a context-aware agent evaluates the comparable
desirability of only those possibilities considered feasible in a particular context c. Hence  instead
of using scalar values to indicate which possibility is more preferable  we introduce preference
information into our system via a desirability function d that simply ‘points’ to the best option in a
given context  i.e. d(c) = B  where B is a binary relation (c  c  m) and mi = 1 iff ci (cid:31) ci(cid:48)∀ci(cid:48) ∈
c \ {ci} and zero otherwise. The desirability indicated by d(c) can be remapped on to the larger
set of options by deﬁning a relative desirability across all possibilities r(x) = m  x ∈ c and zero
otherwise.
Recall now that we have already deﬁned what we mean by utility in our system in Equation 3.
Instantiated in the discrete choice setting  this can be restated as a probabilistic deﬁnition of relative
desirability at decision instant t as 

R(t)(x) = p(r(t)|x) =

(4)
where it is understood that p(c) = p(c|{o1  o2 ···   ot−1}) is a distribution on the set of all possible
contexts inferred from the agent’s observation history. From the deﬁnition of desirability  we can
also obtain a simple deﬁnition of p(r|x  c) as p(ri|xi  c) = 1 iff rixi = 1 and zero otherwise.
To instantiate Eqn (4) concretely  it is ﬁnally necessary to deﬁne a speciﬁc form for the likelihood
term p(x|c). While multiple mathematical forms can be proposed for this expression  depending on
quantitative assumptions about the amount of uncertainty intrinsic to the observation  the underlying
intuition must remain one that obtains the highest possible value for c = o and penalizes mismatches
in set membership. Such deﬁnitions can be introduced in the mathematical deﬁnition of the element-
wise mismatch probability  p(¬yt
i )  we can use these element-
wise probabilities to compute the likelihood of any particular observation o(t) as 

i ). Since p(xi|c(t)) = 1 − p(¬yt

i|zt

i|zt

(cid:80)C
(cid:80)C
c p(r(t)|x  c)p(x|c)p(c)
c p(x|c)p(c)

 

|o(t)|(cid:91)

|c(t)|(cid:91)

   = 1 − β

|X|(cid:88)

P (o(t)|c(t)) = 1 − p

{¬yt
i}|

{zt
i}

p(¬yt

i|zt
i ) 

i

i

i

where β is a parameter controlling the magnitude of the penalty imposed for each mismatch ob-
served.
This likelihood function can then be used to update the agent’s posterior belief about the contexts it
considers viable at decision instance t  given its observation history as 

p(c(t)|{o(1)  o(2) ···   o(t)}) =

(cid:80)C
p(o(t)|c)p(c|{o(1)  o(2) ···   o(t−1)})
c p(o(t)|c)p(c|{o(1)  o(2) ···   o(t−1)})

 

(5)

To outline a decision theory within this framework  observe that  at decision instant t  a Bayesian
agent could represent its prior preference for different world possibilities in the form of a probability

4

distribution over the possible outcomes in X   conditioned on desirability information obtained in
earlier decisions  p(x|c(t) {r(1)  r(2) ··· r(t−1)}). New evidence for the desirability of outcomes
observed in context c(t) is incorporated using p(r(t)|x  c(t))  a distribution encoding the relative
desirability information obtained from the environment at the current time step  conditioned on the
context in which the information is obtained. This formulation immediately yields the belief update 

p(x|c(t)  r(t)) ∝ p(r(t)|c(t)  x) × p(x|c(t) {r(1)  r(2) ··· r(t−1)}) 

(6)
to obtain a posterior probability encoding the desirability of different possibilities x  while also
accounting tractably for the context in which desirability information is obtained at every decision
instance. Deﬁning a choice function to select the mode of the posterior belief completes a rational
context-sensitive decision theory.

4 Demonstrations

To demonstrate the value of the relative desirability-based encoding of preferences  in Section 4.1 
we describe situations in which the inﬂuence of context shifting signiﬁcantly affects human pref-
erence behavior in ways that utility-based decision theories have historically been hard-pressed to
explain. Complementarily  in Section 4.2 we characterize conditions under which the relative desir-
ability framework yields predictions of choice behavior equivalent to that predicted by ordinal utility
theories  and hence  is an equivalent representation for encoding preferences.

4.1 Where context matters ...

In this section  we show how our inductive theory of context-sensitive value inference leads  not
surprisingly  to a simple explanation for the major varieties of context effects seen in behavioral
experiments. These are generally enumerated as attraction  similarity  comparison and reference
point effects [2]. Interestingly  we ﬁnd that each of these effects can be described as a special case
of the frog legs example  with the specialization arising out of additional assumptions made about
the relationship of the new option added to the choice set. Table 1  with some abuse of notation 
describes this relationship between the effects in set-theoretic terms. Space constraints necessitate

Effect name

Frog legs
Similarity
Attraction
Compromise
Reference point

Description

c1 ← {X  Y } ⇒ X (cid:31) Y   c2 ← {X  Y  Z} ⇒ Y (cid:31) X
c1 ← {X  Y } ⇒ X (cid:31) Y   c2 ← {X  Y  Z} ⇒ Y (cid:31) X
c1 ← {X  Y } ⇒ X ∼ Y   c2 ← {X  Y  Z} ⇒ X (cid:31) Y
c1 ← {X  Y } ⇒ X (cid:31) Y   c2 ← {X  Y  Z} ⇒ Y (cid:31) X
c1 ← {X  Y } ⇒ X ∼ Y   c2 ← {X  Y  Z} ⇒ X (cid:31)(−) Y

Assumptions

-

Z ≈ X
X (cid:31) Z
Z (cid:31) X

Y (cid:31)(c) X  Z

Table 1: A uniﬁed description of context effects. (cid:31) indicates stochastic preference for one item
over another. (cid:31)(c) indicates that the preference in question holds only in some observation contexts.
(cid:31)(−) indicates that the preference in question is stochastically weaker than before.

an abbreviate description of our results. Detailed descriptions of these effects  supplemented with
an explanation of how they may be elicited in our framework  is provided in SI. We use available
space to completely describe how the most general version of preference reversal  as seen in the frog
legs example  emerges from our framework and provide a brief overview of the other results. To
instantiate our likelihood deﬁnition in (5)  we deﬁne a speciﬁc mismatch probability 

(cid:0)(1 − zt

(cid:1)  

p(¬yt

i|zt

i ) =

1
|X|

i + (1 − yt

i )zt
i

i )yt

(7)

with β = 1 for all our demonstrations.
In the frog legs example  the reversal in preferences is anecdotally explained by the diner originally
forming a low opinion of the restaurant’s chef  given the paucity of choices on the menu  deciding to
pick the safe salmon over a possibly a burnt steak. However  the waiter’s presenting frog legs as the
daily special suddenly raises the diner’s opinion of the chef’s abilities  causing him to favor steak.
This intuition maps very easily into our framework of choice selection  wherein the diner’s partial

5

menu observations o1 = {steak  salmon} and o2 = {steak  salmon  frog legs} are associated with two
separate contexts c1 and c2 of observing the menu X . Bad experiences related to ordering steak in
menus typically observed under context c1 (interpretable as ‘cheap restaurants’) may be encoded by
deﬁning the vector m = {1  0  0  0} for c1 and good experiences ordering steak off menues observed
in context c2 (interpretable as ‘upscale restaurants’) as m = {0  1  0  0} for c2. Then  by deﬁnition 
p(r|salmon  c1) > p(r|steak  c1)  while p(r|salmon  c2) < p(r|steak  c2). For the purposes of this
demonstration  let us assume these probability pairs  obtained through the diner’s past experiences in
restaurants to be {0.7  0.3} and {0.3  0.7} respectively. Now  when the waiter ﬁrst offers the diner a
choice between steak or salmon  the diner computes relative desirabilities using (4)  where the only
context for the observation is {salmon  steak}. Hence  the relative desirabilities of steak and salmon
are computed over a single context  and are simply R(salmon) = 0.7  R(steak) = 0.3. When the
diner is next presented with the possibility of ordering frog legs  he now has two possible contexts to
evaluate the desirability of his menu options: {salmon  steak} and {salmon  steak  frog legs}. Based
on the sequence of his history of experience with both contexts  the diner will have some posterior
belief p(c) = {p  1 − p} on the two contexts. Then  the relative desirability of salmon  after having
observed frog legs on the menu can be calculated using (4) as 

R(salmon) =

=

p(r|salmon  c1)p(salmon|c1)p(c1) + p(r|salmon  c2)p(salmon|c2)p(c2)

 

0.7 × 1 × p + 0.3 × 1 × (1 − p)

p(salmon|c1)p(c1) + p(salmon|c2)p(c2)
= 0.7p + 0.3(1 − p).

1 × p + 1 × (1 − p)

Similarly  we obtain R(steak) = 0.3p + 0.7(1 − p). Clearly  for 1 − p > p  R(steak) > R(salmon) 
and the diner would be rational in switching his preference. Thus  through our inferential machinery 
we retrieve the anecdotal explanation for the diner’s behavior: if he believes that he is more likely
to be in a good restaurant (with probability (1 − p)) than not  he will prefer steak.
Along identical lines  making reasonable assumptions about the contexts of past observations  our
decision framework accomodates parsimonious explanations for each of the other effects detailed in
Table 1. Attraction effects are traditionally studied in market research settings where a consumer is
unsure about which of two items to prefer. The introduction of a third item that is clearly inferior to
one of the two earlier options leads the consumer towards preferring that particular earlier option.
Our framework elicits this behavior through the introduction of additional evidence of the desir-
ability of one of the options from a new context  causing the relative desirability of this particular
option to rise. Similarity effects arise when  given that a consumer prefers one item to another  giv-
ing him further options that resemble his preferred item causes him to subsequently prefer the item
he earlier considered inferior. This effect is elicited simply as a property of division of probability
among multiple similar options  resulting in reduced desirabiliy of the previously superior option.
Compromise effects arise when the introduction of a third option to a choice set where the consumer
already prefers one item to another causes the consumer to consider the previously inferior option
as a compromise between the formerly superior option and the new option  and hence prefer it. We
ﬁnd that the compromise effect arises through a combination of reduction in the desirability of the
superior option through negative comparions with the new item and increase in the desirability of
the formerly inferior item through positive comparisons with the new item  and that this inference
occurs automatically in our framework assuming equal history of comparisons between the exist-
ing choice set items and the new item. Reference point effects have typically not been associated
with explicit studies of context variation  and may in fact be used to reference a number of behavior
patterns that do not satisfy the deﬁnition we provide in Table 1. Our deﬁnition of the reference
point effect is particularized to explain data on pain perception collected by [23]  demonstrating
relativity in evaluation of objectively identical pain conditions depending on the magnitude of al-
ternatively experienced pain conditions. In concord with empirical observation  we show that the
relative (un)desirability of an intermediate pain option reduces upon the experience of greater pain 
a simple demonstration of prospect relativity that utility-based accounts of value cannot match.
Competing hypotheses that seek to explain these behaviors are either normative and static  (e.g. ex-
tended discrete choice models ( [13] provides a recent review)  componential context theory [21] 
quantum cognition [8]) or descriptive and dynamic  (speciﬁcally  decision ﬁeld theory [3]). In con-
trast  our approach not only takes a dynamic inductive view of value elicitation  it retains a norma-
tivity criterion (Bayes rationality) for falsifying observed predictions  a standard that is expected of
any rational model of decision-making [6].

6

4.2

... and where it doesn’t

It could be conjectured that the relative desirability indicator d will be an inadequate representation
of preference information compared with scalar utility signals assigned to each world possibility 
which would leave open the possibility that we may have retrieved a context-sensitive decision
theory at the expense of theoretical assurance of rational choice selection  as has been the case in
many previous attempts cited above. Were this conjecture to be true  it would severely limit the
scope and applicability of our proposal. To anticipate this objection  we theoretically prove that
our framework reduces to the standard utility-based representation of preferences under equivalent
epistemic conditions  showing that our theory retains equivalent rational representational ability
as utility theory in simple  and simply extends this representational ability to explain preference
behaviors that utility theory can’t.
What does it mean for a measure to represent preference information? To show that a utility function
u completely represents a preference relation on X it is sufﬁcient [12] to show that  ∀x1  x2 ∈
X   x1 (cid:31) x2 ⇔ u(x1) > u(x2). Hence  equivalently  to show that our measure of relative desirability
R also completely represents preference information  it should be sufﬁcient to show that  for any two
possibilities xi  xj ∈ X   and for any observation context c

xi (cid:31) xj ⇔ R(xi) > R(xj).

(8)

In SI  we prove that (8) holds at decision instant t under three conditions 

j\i|.2.

i\j| = |C(t)

(I) Context consistency: ∃c ∈ C  s.t. xi (cid:31) xj ⇒ xi (cid:31) xj∀c ∈ Cij {xi  xj} ∈ Cij ⊆ C.
(II) Transitivity between contexts: if xi (cid:31) xj in c1 and xj (cid:31) xk in c2 ∀c ∈ C  xi (cid:31) xk.
(III) Symmetry in context observability: ∀xi  xj ∈ X   limt→∞ |C(t)
Of the three assumptions we need to prove this equivalence result  (I) and (II) simply deﬁne a sta-
ble preference relation across observation contexts and ﬁnd exact counterparts in the completeness
and transitivity assumptions necessary for representing preferences using ordinal utility functions.
(III)  the only additional assumption we require  ensures that the agent’s history of partial obser-
vations of the environment does not contain any useful information. The restriction of inﬁnite data
observability  while stringent and putatively implausible  actually uncovers an underlying epistemo-
logical assumption of utility theory  viz.
that utility/desirability values can somehow be obtained
directly from the environment. Any inference based preference elicitation procedure will therefore
necessarily need inﬁnite data to attain formal equivalence with the utility representation. Finally 
we point out that our equivalence result does not require us to assume continuity or the equiva-
lent Archimedean property to encode preferences  as required in ordinal utility deﬁnitions. This is
because the continuity assumption is required as a technical condition in mapping a discrete math-
ematical object (a preference relation) to a continuous utility function. Since relative desirability is
deﬁned constructively on Q ⊆ Q |Q| < ∞  a continuity assumption is not needed.

5 Discussion

Throughout this exegesis  we have encountered three different representations of choice preferences:
relative (ordinal) utilities  absolute (cardinal) utilities and our own proposal  viz. relative desirability.
Each representation leads to a slightly different deﬁnition of rationality  so that  assuming a rational
set selection function σ in each case we have 

preference modeling in neoclassical economics [12]]  e.g. discrete choice modeling [9].

• Economic rationality: x ∈ σ(X ) ⇒ (cid:64)y ∈ X   s.t. y (cid:31) x  predominantly used in human
• VNM-rationality: x ∈ σ(X ) ⇒ (cid:64)y ∈ X   s.t. u(y) > u(x)  predominantly used in
studying decision-making under risk [19]  e.g. reinforcement learning [1].
• Bayes rationality: x ∈ σ(X ) ⇒ (cid:64)y ∈ X   s.t. R(y {H}) > R(x {H})  which we have
proposed. The term {H} here is shorthand for {o1  o2 ···   ot−1} {r1  r2 ··· rt−1}  the
entire history of choice set and relative desirability observations made by an agent leading
up to the current decision instance.

2The notation Ci\j references the subset of all observed contexts that contain xi but not xj.

7

Bayes rationality simply claims that value inference with the same history of partial observations
will lead to a consistent preference for a particular option in discrete choice settings. In Section
4.2  we have shown conditions on choice set observations under which Bayes-rationality will be
equivalent to economic rationality. VNM-rationality is a further specialization of economic ratio-
nality  valid for preference relations that  in addition to being complete  transitive and continuous (as
required for economic preferences representable via ordinal utilities) also satisfy an independence
of irrelevant attributes (IIA) assumption [16]. Bayes-rationality specializes to economic rationality
once we instantiate the underlying intuitions behing the completeness and transitivity assumptions
in a context-sensitive preference inference theory. Therefore  rational value inference in the form
we propose can formally replace static assumptions about preference orderings in microeconomic
models that currently exclusively use ordinal utilities [12]. As such  context-sensitive preference
elicitation is immediately useful for the nascent agent-based economic modeling paradigm as well
as in dynamic stochastic general equilibrium models of economic behavior. Further work is nec-
essary to develop a context-sensitive equivalent of the IIA assumption  which is necessary for our
system to be directly useful in modeling decision-making behaviors under uncertainty. However 
even in its current form  our inference model can be used in conjunction with existing ‘inverse plan-
ning’ models of utility elicitation from choice data [17] that infer absolute utilities from choice data
using extraneous constraints on the form of the utility function from the environment. In such a
synthesis  our model could generate a preference relation sensitive to action set observability  which
inverse planning models could use along with additional information from the environment to gen-
erate absolute utilities that account for observational biases in the agent’s history.
A philosophically astute reader will point out a subtle ﬂaw in our inferential deﬁnition of rationality.
Namely  while we assume an intuitive notion of partial observability of the world  in practice  our
agents compile desirability statistics on the set of all possibilities  irrespective of whether they have
ever been observed  a problem that is rooted in an inherent limitation of Bayesian epistemology
of being restricted to computing probabilities over a ﬁxed set of hypotheses. How can a desirabil-
ity representation that assumes that observers maintain probabilistic preferences over all possible
states of the world be more epistemologically realistic than one that assumes that observers main-
tain scalar utility values over the same state space3? As a partial response to this criticism  we point
out that we do not require an ontic commitment to the computation of joint probability distributions
on all x ∈ X . In practice  it is likely that Bayesian computations are implemented in the brain via
sampling schemes that  in hierarchical formulations  allow approximating information of the joint
distribution as a set of the most likely marginals (in our case  relative desirability in typical observa-
tion contexts). Neural implementations of such sampling schemes have been proposed in the recent
cognitive science literature [20]. Devising a sampling scheme that matches the intuition of context
retrieval from memory to supplement our value-inference scheme presents a promising direction for
future research.
Another straightforward extension of our framework would imbue observable world possibilities
with attributes  resulting in the possibility of deriving a more general deﬁnition of contexts as clus-
ters in the space of attributes. Such an extension would result in the possibility of transferring pref-
erences to entirely new possibilities  allowing the set X to be modiﬁed dynamically  which would
further address the epistemological criticism above. Even further  such an extension maps directly
to the intuition of value inference resulting from organisms’ monitoring of internal need states  here
modeled as attributes. Canini’s recent modeling of transfer learning using hierarchical Dirichlet
processes [4] provides most of the mathematical apparatus required to perform such an extension 
making this a promising direction for future work in our project.
In conclusion  it has long been recognized that state-speciﬁc utility representations of the desirability
of options are insufﬁcient to capture the rich variety of systematic behavior patterns that humans ex-
hibit. In this paper  we show that reformulating the atomic unit of desirability as a context-sensitive
‘pointer’ to the best option in the observed set recovers a rational way of representing desirability in
a manner sufﬁciently powerful to describe a broad range of context effects in decisions. Since it is
likely that preferences for options do not exist a priori and are induced via experience  our present
proposal is expected to approximate the true mechanisms for the emergence of context-sensitive
preference variation better than alternative static theories  while retaining normativity criteria miss-
ing in alternative dynamic accounts.

3One could argue that we are essentially observing the state space (to be able to index using its membership) 

but pretending to not observe it.

8

References
[1] A.G. Barto and R.S. Sutton. Reinforcement Learning: an introduction. Univesity of Cambridge

Press  1998.

[2] J. R. Busemeyer  R. Barkan  S. Mehta  and A. Chaturvedi. Context effects and models of
preferential choice: implications for consumer behavior. Marketing Theory  7(1):39–58  2007.
[3] J.R. Busemeyer and J.T. Townsend. Decision ﬁeld theory: A dynamic cognition approach to

decision making. Psychological Review  100:432–459  1993.

[4] K. Canini  M. Shashkov  and T. Grifﬁths. Modeling transfer learning in human categorization

with the hierarchical dirichlet process. In ICML  pages 151–158  2010.

[5] U. Chajewska  D. Koller  and D. Ormoneit. Learning an agent’s utility function by observing

behavior. In ICML  pages 35–42  2001.

[6] N. Chater. Rational and mechanistic perspectives on reinforcement learning. Cognition 

113(3):350 – 364  2009. Reinforcement learning and higher cognition.

[7] N. Daw and M. Frank. Reinforcement learning and higher level cognition: Introduction to spe-
cial issue. Cognition  113(3):259 – 261  2009. Reinforcement learning and higher cognition.
[8] L. Gabora and D. Aerts. Contextualizing concepts using a mathematical generalization of the
quantum formalism. Joural of Experimental and Theoretical Artiﬁcial Intelligence  14(4):327–
358  2002.

[9] D. Hensher  J. Rose  and W. Greene. Applied Choice Analysis: A Primer. Cambridge Univer-

sity Press  2005.

[10] A. Jern  C. Lucas  and C. Kemp. Evaluating the inverse decision-making approach to prefer-

ence learning. In NIPS  pages 2276–2284  2011.

[11] D. Kahneman. Perception  action and utility: the tangled skein. In M. Rabinovich  K. Friston 
and P. Varona  editors  Principles of Brain Dynamics: Global State Interactions. MIT Pres 
2012.

[12] D. Kreps. A Course in Microeconomic Theory  pages 17–69. Princeton University Press  1990.
[13] W. Leong and D. Hensher. Embedding decision heuristics in discrete choice models: A review.

Transport Reviews  32(3):313–331  2012.

[14] C.G. Lucas  T. Grifﬁths  F. Xu  and C. Fawcett. A rational model of preference learning and

choice prediction by children. In NIPS  pages 985–992  2008.

[15] R. D. Luce and H. Raiffa. Games and Decisions: Introduction and Critical Survey. Wiley 

New York  1957.

[16] J.v. Neumann and O. Morgenstern. Theory of Games and Economic Behavior. Princeton

University Press  1953.

[17] A. Y. Ng and S. J. Russell. Algorithms for inverse reinforcement learning. In Proceedings of
the Seventeenth International Conference on Machine Learning  ICML ’00  pages 663–670 
2000.

[18] M. Rabin. Psychology and economics. Journal of Economic Literature  36(1):pp. 11–46  1998.
[19] S.J. Russell and P. Norvig. Artiﬁcial Intelligence: A Modern Approach. MIT Press  1998.
[20] L. Shi and T. Grifﬁths. Neural Implementation of Hierarchical Bayesian Inference by Impor-
tance Sampling. In Y. Bengio  D. Schuurmans  J. Lafferty  C. K. I. Williams  and A. Culotta 
editors  Advances in Neural Information Processing Systems 22  pages 1669–1677. 2009.

[21] A. Tversky and I. Simonson. Context-dependent preferences. Management Science  39(10):pp.

1179–1189  1993.

[22] I. Vlaev  N. Chater  N. Stewart  and G. Brown. Does the brain calculate value? Trends in

Cognitive Sciences  15(11):546 – 554  2011.

[23] I. Vlaev  B. Seymour  R.J. Dolan  and N. Chater. The price of pain and the value of suffering.

Psychological Science  20(3):309–317  2009.

9

,Ozan Irsoy
Claire Cardie
Sampath Kannan
Jamie Morgenstern
Aaron Roth
Bo Waggoner
Zhiwei  Steven Wu