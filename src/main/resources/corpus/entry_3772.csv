2015,No-Regret Learning in Bayesian Games,Recent price-of-anarchy analyses of games of complete information suggest that coarse correlated equilibria  which characterize outcomes resulting from no-regret learning dynamics  have near-optimal welfare. This work provides two main technical results that lift this conclusion to games of incomplete information  a.k.a.  Bayesian games. First  near-optimal welfare in Bayesian games follows directly from the smoothness-based proof of near-optimal welfare in the same game when the private information is public.  Second  no-regret learning dynamics converge to Bayesian coarse correlated equilibrium in these incomplete information games. These results are enabled by interpretation of a Bayesian game as a stochastic game of complete information.,No-Regret Learning in Bayesian Games

Jason Hartline

Northwestern University

Evanston  IL

hartline@northwestern.edu

Vasilis Syrgkanis
Microsoft Research

New York  NY

vasy@microsoft.com

´Eva Tardos

Cornell University

Ithaca  NY

eva@cs.cornell.edu

Abstract

Recent price-of-anarchy analyses of games of complete information suggest that
coarse correlated equilibria  which characterize outcomes resulting from no-regret
learning dynamics  have near-optimal welfare. This work provides two main tech-
nical results that lift this conclusion to games of incomplete information  a.k.a. 
Bayesian games. First  near-optimal welfare in Bayesian games follows directly
from the smoothness-based proof of near-optimal welfare in the same game when
the private information is public. Second  no-regret learning dynamics converge
to Bayesian coarse correlated equilibrium in these incomplete information games.
These results are enabled by interpretation of a Bayesian game as a stochastic
game of complete information.

1

Introduction

A recent conﬂuence of results from game theory and learning theory gives a simple explanation for
why good outcomes in large families of strategically-complex games can be expected. The advance
comes from (a) a relaxation the classical notion of equilibrium in games to one that corresponds to
the outcome attained when players’ behavior ensures asymptotic no-regret  e.g.  via standard online
learning algorithms such as weighted majority  and (b) an extension theorem that shows that the
standard approach for bounding the quality of classical equilibria automatically implies the same
bounds on the quality of no-regret equilibria. This paper generalizes these results from static games
to Bayesian games  for example  auctions.
Our motivation for considering learning outcomes in Bayesian games is the following. Many impor-
tant games model repeated interactions between an uncertain set of participants. Sponsored search 
and more generally  online ad-auction market places  are important examples of such games. Plat-
forms are running millions of auctions  with each individual auction slightly different and of only
very small value  but such market places have high enough volume to be the ﬁnancial basis of large
industries. This online auction environment is best modeled by a repeated Bayesian game: the auc-
tion game is repeated over time  with the set of participants slightly different each time  depending
on many factors from budgets of the players to subtle differences in the opportunities.
A canonical example to which our methods apply is a single-item ﬁrst-price auction with players’
values for the item drawn from a product distribution. In such an auction  players simultaneously
submit sealed bids and the player with the highest bid wins and pays her bid. The utility of the
winner is her value minus her bid; the utilities of the losers are zero. When the values are drawn from
non-identical continuous distributions the Bayes-Nash equilibrium is given by a differential equation

1

that is not generally analytically tractable  cf. [8] (and generalizations of this model  computationally
hard  see [3]). Again  though their Bayes-Nash equilibria are complex  we show that good outcomes
can be expected in these kinds of auctions.
Our approach to proving that good equilibria can be expected in repeated Bayesian games is to
extend an analogous result for static games 1 i.e.  the setting where the same game with the same
payoffs and the same players is repeated. Nash equilibrium is the classical model of equilibrium for
each stage of the static game. In such an equilibrium the strategies of players may be randomized;
however  the randomizations of the players are independent. To measure the quality of outcomes in
games Koutsoupias and Papadimitriou [9] introduced the price of anarchy  the ratio of the quality
of the worst Nash equilibrium over a socially optimal solution. Price of anarchy results have been
shown for large families of games  with a focus on those relevant for computer networks. Roughgar-
den [11] identiﬁed the canonical approach for bounding the price of anarchy of a game as showing
that it satisﬁes a natural smoothness condition.
There are two fundamental ﬂaws with Nash equilibrium as a description of strategic behavior. First 
computing a Nash equilibrium can be PPAD hard and  thus  neither should efﬁcient algorithms for
computing a Nash equilibrium be expected nor should any dynamics (of players with bounded com-
putational capabilities) converge to a Nash equilibrium. Second  natural behavior tends to introduce
correlations in strategies and therefore does not converge to Nash equilibrium even in the limit.
Both of these issues can be resolved for large families of games. First  there are relaxations of Nash
equilibrium which allow for correlation in the players’ strategies. Of these  this paper will focus
on coarse correlated equilibrium which requires the expected payoff of a player for the correlated
strategy be no worse than the expected payoff of any action at the player’s disposal. Second  it was
proven by Blum et al. [2] that the (asymptotic) no-regret property of many online learning algorithms
implies convergence to the set of coarse correlated equilibria.2
Blum et al. [2] extended the deﬁnition of the price of anarchy to outcomes obtained when each
player follows a no-regret learning algorithm.3 As coarse correlated equilibrium generalize Nash
equilibrium it could be that the worst case equilibrium under the former is worse than the latter.
Roughgarden [11]  however  observed that there is often no degradation; speciﬁcally  the very same
smoothness property that he identiﬁed as implying good welfare in Nash equilibrium also proves
good welfare of coarse correlated equilibrium (equivalently: for outcomes from no-regret learners).
Thus  for a large family of static games  we can expect strategic behavior to lead to good outcomes.
This paper extends this theory to Bayesian games. Our contribution is two-fold: (i) We show an
analog of the convergence of no-regret learning to coarse correlated equilibria in Bayesian games 
which is of interest independently of our price of anarchy analysis; and (ii) we show that the coarse
correlated equilibria of the Bayesian version of any smooth static game have good welfare. Com-
bining these results  we conclude that no-regret learning in smooth Bayesian games achieves good
welfare.
These results are obtained as follows. It is possible to view a Bayesian game as a stochastic game 
i.e.  where the payoff structure is ﬁxed but there is a random action on the part of Nature. This
viewpoint applied to the above auction example considers a population of bidders associated for
each player and  in each stage  Nature uniformly at random selects one bidder from each population
to participate in the auction. We re-interpret and strengthen a result of Syrgkanis and Tardos [12]
by showing that the smoothness property of the static game (for any ﬁxed proﬁle of bidder values)
implies smoothness of this stochastic game. From the perspective of coarse correlated equilibrium 
there is no difference between a stochastic game and the non-stochastic game with each random
variable replaced with its expected value. Thus  the smoothness framework of Roughgarden [11]
extends this result to imply that the coarse correlated equilibria of the stochastic game are good.
To show that we can expect good outcomes in Bayesian games  it sufﬁces to show that no-regret
learning converges to the coarse correlated equilibrium of this stochastic game. Importantly  when
we consider learning algorithms there is a distinction between the stochastic game where players’
payoffs are random variables and the non-stochastic game where players’ payoffs are the expectation

1In the standard terms of the game theory literature  we extend results for learning in games of complete

information to games of incomplete information.

2This result is a generalization of one of Foster and Vohra [7].
3They referred to this price of anarchy for no-regret learners as the price of total anarchy.

2

of these variables. Our analysis addressed this distinction and  in particular  shows that  in the
stochastic game on populations  no-regret learning converges almost surely to the set of coarse
correlated equilibrium. This result implies that the average welfare of no-regret dynamics will be
good  almost surely  and not only in expectation over the random draws of Nature.

2 Preliminaries

This section describes a general game theoretic environment which includes auctions and resource
allocation mechanisms. For this general environment we review the results from the literature for
analyzing the social welfare that arises from no-regret learning dynamics in repeated game play.
The subsequent sections of the paper will generalize this model and these results to Bayesian games 
a.k.a.  games of incomplete information.
General Game Form. A general game M is speciﬁed by a mapping from a proﬁle a ∈ A ≡
A1 × ··· × An of allowable actions of players to an outcome. Behavior in a game may result in
(possibly correlated) randomized actions a ∈ ∆(A).4 Player i’s utility in this game is determined
by a proﬁle of individual values v ∈ V ≡ V1 × ··· × Vn and the (implicit) outcome of the game; it
is denoted Ui(a; vi) = Ea∼a [Ui(a; vi)]. In games with a social planner or principal who does not
take an action in the game  the utility of the principal is R(a) = Ea∼a [R(a)]. In many games of
interest  such as auctions or allocation mechanisms  the utility of the principal is the revenue from
payments from the players. We will use the term mechanism and game interchangeably.
In a static game the payoffs of the players (given by v) are ﬁxed. Subsequent sections will consider
Bayesian games in the independent private value model  i.e.  where player i’s value vi is drawn
independently from the other players’ values and is known only privately to player i. Classical
game theory assumes complete information for static games  i.e.  that v is known  and incomplete
information in Bayesian games  i.e.  that the distribution over V is known. For our study of learning
in games no assumptions of knowledge are made; however  to connect to the classical literature
we will use its terminology of complete and incomplete information to refer to static and Bayesian
games  respectively.

will denote by SW (a; v) =(cid:80)

Social Welfare. We will be interested in analyzing the quality of the outcome of the game as
deﬁned by the social welfare  which is the sum of the utilities of the players and the principal. We
i∈[n] Ui(a; vi) + R(a) the expected social welfare of mechanism M
under a randomized action proﬁle a. For any valuation proﬁle v ∈ V we will denote the optimal
social welfare  i.e  the maximum over outcomes of the game of the sum of utilities  by OPT(v).

No-regret Learning and Coarse Correlated Equilibria. For complete information games  i.e. 
ﬁxed valuation proﬁle v  Blum et al. [2] analyzed repeated play of players using no-regret learning
algorithms  and showed that this play converges to a relaxation of Nash equilibrium  namely  coarse
correlated equilibrium.
Deﬁnition 1 (no regret). A player achieves no regret in a sequence of play a1  . . .   aT if his regret
against any ﬁxed strategy a(cid:48)

limT→∞ 1
T

(1)
Deﬁnition 2 (coarse correlated equilibrium  CCE). A randomized action proﬁle a ∈ ∆(A) is a
coarse correlated equilibrium of a complete information game with valuation proﬁle v if for every
player i and a(cid:48)

i  at−i; vi) − Ui(at; vi)) = 0.

i ∈ Ai:

(cid:80)T
i vanishes to zero:
t=1(Ui(a(cid:48)

(2)
Theorem 3 (Blum et al. [2]). The empirical distribution of actions of any no-regret sequence in a
repeated game converges to the set of CCE of the static game.

i  a−i; vi)]

Ea [Ui(a; vi)] ≥ Ea [Ui(a(cid:48)

Price of Anarchy of CCE. Roughgarden [11] gave a unifying framework for comparing the social
welfare  under various equilibrium notions including coarse correlated equilibrium  to the optimal
social welfare by deﬁning the notion of a smooth game. This framework was extended to games like
auctions and allocation mechanisms by Syrgkanis and Tardos [12].

4Bold-face symbols denote random variables.

3

Simultaneous First Price Auction with Submodular Bidders

Game/Mechanism

First Price Multi-Unit Auction
First Price Position Auction

All-Pay Auction

Greedy Combinatorial Auction with d-complements

Proportional Bandwitdth Allocation Mechanism

Submodular Welfare Games

Congestion Games with Linear Delays

(λ  µ)

(1 − 1/e  1)
(1 − 1/e  1)
(1/2  1)
(1/2  1)
(1 − 1/e  d)
(1/4  1)
(1  1)

(5/3  1/3)

POA Reference
e
e−1
e
e−1
2
2
de
e−1
4
2
5/2

[12]
[5]
[12]
[12]
[10]
[12]

[13  11]

[11]

Figure 1: Examples of smooth games and mechanisms

Deﬁnition 4 (smooth mechanism). A mechanism M is (λ  µ)-smooth for some λ  µ ≥ 0 there exists
an independent randomized action proﬁle a∗(v) ∈ ∆(A1)×···× ∆(An) for each valuation proﬁle
v  such that for any action proﬁle a ∈ A and valuation proﬁle v ∈ V:

i (v)  a−i; vi) ≥ λ · OPT(v) − µ · R(a).

(3)

(cid:80)
i∈[n] Ui(a∗

Many important games and mechanisms satisfy this smoothness deﬁnition for various parameters
of λ and µ (see Figure 1); the following theorem shows that the welfare of any coarse correlated
equilibrium in any of these games is nearly optimal.
Theorem 5 (efﬁciency of CCE; [12]). If a mechanism is (λ  µ)-smooth then the social welfare of
any course correlated equilibrium at least
max{1 µ} of the optimal welfare  i.e.  the price of anarchy
satisﬁes POA ≤ max{1 µ}

λ

.

λ

Price of Anarchy of No-regret Learning. Following Blum et al. [2]  Theorem 3 and Theorem 5
imply that no-regret learning dynamics have near-optimal social welfare.
Corollary 6 (efﬁciency of no-regret dyhamics; [12]). If a mechanism is (λ  µ)-smooth then the
average welfare of any no-regret dynamics of the repeated game with a ﬁxed player set and valuation
proﬁle  achieves average social welfare at least
max{1 µ} of the optimal welfare  i.e.  the price of
anarchy satisﬁes POA ≤ max{1 µ}
Importantly  Corollary 6 holds the valuation proﬁle v ∈ V ﬁxed throughout the repeated game play.
The main contribution of this paper is in extending this theory to games of incomplete information 
e.g.  where the values of the players are drawn at random in each round of game play.

λ

λ

.

3 Population Interpretation of Bayesian Games

i

In the standard independent private value model of a Bayesian game there are n players. Player i
has type vi drawn uniformly from the set of type Vi (and this distribution is denoted Fi).5 We will
restrict attention to the case when the type space Vi is ﬁnite. A player’s strategy in this Bayesian
game is a mapping si : Vi → Ai from a valuation vi ∈ Vi to an action ai ∈ Ai. We will denote
with Σi = AVi
the strategy space of each player and with Σ = Σ1 × . . . × Σn. In the game  each
player i realizes his type vi from the distribution and then makes action si(vi) in the game.
In the population interpretation of the Bayesian game  also called the agent normal form representa-
tion [6]  there are n ﬁnite populations of players. Each player in population i has a type vi which we
assume to be distinct for each player in each population and across populations.6 The set of players
in the population is denoted Vi. and the player in population i with type vi is called player vi. In the
population game  each player vi chooses an action si(vi). Nature uniformly draws one player from

5The restriction to the uniform distribution is without loss of generality for any ﬁnite type space and for any

distribution over the type space that involves only rational probabilities.

6The restriction to distinct types is without of loss of generality as we can always augment a type space with

an index that does not affect player utilities.

4

each population  and the game is played with those players’ actions. In other words  the utility of
player vi from population i is:

U AG
i vi

(s) = Ev [Ui(s(v); vi) · 1{vi = vi}]

(4)
Notice that the population interpretation of the Bayesian game is in fact a stochastic game of com-
plete information.
There are multiple generalizations of coarse correlated equilibria from games of complete informa-
tion to games of incomplete information (c.f. [6]  [1]  [4]). One of the canonical deﬁnitions is simply
the coarse correlated equilibrium of the stochastic game of complete information that is deﬁned by
the population interpretation above.7
Deﬁnition 7 (Bayesian coarse correlated equilibrium - BAYES-CCE). A randomized strategy proﬁle
s ∈ ∆(Σ) is a Bayesian coarse correlated equilibrium if for every a(cid:48)
i ∈ Ai and for every vi ∈ Vi:
(5)

EsEv [Ui(s(v); vi) | vi = vi] ≥ EsEv [Ui(a(cid:48)

i  s−i(v−i); vi) | vi = vi]

In a game of incomplete information the welfare in equilibrium will be compared to the expected
ex-post optimal social welfare Ev[OPT(v)]. We will refer to the worst-case ratio of the expected
optimal social welfare over the expected social welfare of any BAYES-CCE as BAYES-CCE-POA.

4 Learning in Repeated Bayesian Game

Consider a repeated version of the population interpretation of a Bayesian game. At each iteration
one player vi from each population is sampled uniformly and independently from other populations.
The set of chosen players then participate in an instance of a mechanism M. We assume that each
player vi ∈ Vi  uses some no-regret learning rule to play in this repeated game.8 In Deﬁnition 8  we
describe the structure of the game and our notation more elaborately.
Deﬁnition 8. The repeated Bayesian game of M proceeds as follows. In stage t:

1. Each player vi ∈ Vi in each population i picks an action st
the function that maps a player vi ∈ Vi to his action.

i ∈ A|Vi|
st

i

i(vi) ∈ Ai. We denote with

2. From each population i one player vt

n) be the chosen proﬁle of players and st(vt) = (st

i ∈ Vi is selected uniformly at random. Let vt =
n)) be the

1)  . . .   st

n(vt

1(vt

1  . . .   vt

(vt
proﬁle of chosen actions.

3. Each player vt

action st
experience zero utility.

i(vt

i participates in an instance of game M  in the role of player i ∈ [n]  with
i ). All players not selected in Step 2

i ) and experiences a utility of Ui(st(vt); vt

Remark. We point out that for each player in a population to achieve no-regret he does not need
to know the distribution of values in other populations. There exist algorithms that can achieve the
no-regret property and simply require an oracle that returns the utility of a player at each iteration.
Thus all we need to assume is that each player receives as feedback his utility at each iteration.

Remark. We also note that our results would extend to the case where at each period multiple
matchings are sampled independently and players potentially participate in more than one instance
of the mechanism M and potentially with different players from the remaining population. The only
thing that the players need to observe in such a setting is their average utility that resulted from their
i(vi) ∈ Ai from all the instances that they participated at the given period. Such a scenario
action st
seems an appealing model in online ad auction marketplaces where players receive only average
utility feedback from their bids.

7This notion is the coarse analog of the agent normal form Bayes correlated equilibrium deﬁned in Section

4.2 of Forges [6].

8An equivalent and standard way to view a Bayesian game is that each player draws his value independently
from his distribution each time the game is played. In this interpretation the player plays by choosing a strategy
that maps his value to an action (or distribution over actions). In this interpretation our no-regret condition
requires that the player not regret his actions for each possible value.

5

Bayesian Price of Anarchy for No-regret Learners.
In this repeated game setting we want to
compare the average social welfare of any sequence of play where each player uses a vanishing
regret algorithm versus the average optimal welfare. Moreover  we want to quantify the worst-case
such average welfare over all possible valuation distributions within each population:

(6)

(cid:80)T

(cid:80)T

t=1 OPT(vt)

t=1 SW M(st(vt);vt)

sup

F1 ... Fn

lim sup
T→∞

λ

We will refer to this quantity as the Bayesian price of anarchy for no-regret learners. The numerator
of this term is simply the average optimal welfare when players from each population are drawn
independently in each stage; it converges almost surely to the expected ex-post optimal welfare
Ev[OPT(v)] of the stage game. Our main theorem is that if the mechanism is smooth and players
follow no-regret strategies then the expected welfare is guaranteed to be close to the optimal welfare.
Theorem 9 (Main Theorem). If a mechanism is (λ  µ)-smooth then the average (over time) welfare
of any no-regret dynamics of the repeated Bayesian game achieves average social welfare at least
max{1 µ} of the average optimal welfare  i.e. POA ≤ max{1 µ}
Roadmap of the proof.
In Section 5  we show that any vanishing regret sequence of play of the
repeated Bayesian game  will converge almost surely to the Bayesian version of a coarse correlated
equilibrium of the incomplete information stage game. Therefore the Bayesian price of total anarchy
will be upper bounded by the efﬁciency of guarantee of any Bayesian coarse correlated equilibrium.
Finally  in Section 6 we show that the price of anarchy bound of smooth mechanisms directly extends
to Bayesian coarse correlated equilibria  thereby providing an upper bound on the Bayesian price of
total anarchy of the repeated game.

  almost surely.

λ

Remark. We point out that our deﬁnition of BAYES-CCE is inherently different and more restricted
than the one deﬁned in Caragiannis et al. [4]. There  a BAYES-CCE is deﬁned as a joint distribution
D over V × A  such that if (v  a) ∼ D then for any vi ∈ Vi and a(cid:48)

i(vi) ∈ Ai:

E(v a) [Ui(a; vi)] ≥ E(v a) [Ui(a(cid:48)

i(vi)  a−i; vi)]

(7)
The main difference is that the product distribution deﬁned by a distribution in ∆(Σ) and the dis-
tribution of values  cannot produce any possible joint distribution over (V A)  but the type of joint
distributions are restricted to satisfy a conditional independence property described by [6]. Namely
that player i’s action is conditionally independent of some other player j’s value  given player i’s
type. Such a conditional independence property is essential for the guarantees that we will present
in this work to extend to a BAYES-CCE and hence do not seem to extend to the notion given in [4].
However  as we will show in Section 5  the no-regret dynamics that we analyze  which are math-
ematically equivalent to the dynamics in [4]  do converge to this smaller set of BAYES-CCE that
we deﬁne and for which our efﬁciency guarantees will extend. This extra convergence property is
not needed when the mechanism satisﬁes the stronger semi-smoothness property deﬁned in [4] and
thereby was not needed to show efﬁciency bounds in their setting.

5 Convergence of Bayesian No-Regret to BAYES-CCE

In this section we show that no-regret learning in the repeated Bayesian game converges almost
surely to the set of Bayesian coarse correlated equilibria. Any given sequence of play of the repeated
Bayesian game  which we deﬁned in Deﬁnition 8  gives rise to a sequence of strategy-value pairs
  captures the actions that each player vi in population
(st  vt) where st = (st
i would have chosen  had they been picked. Then observe that all that matters to compute the average
social welfare of the game for any given time step T   is the empirical distribution of pairs (s  v)  up
till time step T   denoted as DT   i.e. if (sT   vT ) is a random sample from DT :

i ∈ AVi

n) and st

1  . . .   st

i

1
T

t=1 SW (st(vt); vt) = E(sT  vT )

(8)
Lemma 10 (Almost sure convergence to BAYES-CCE). Consider a sequence of play of the random
matching game  where each player uses a vanishing regret algorithm and let DT be the empirical
distribution of (strategy  valuation) proﬁle pairs up till time step T . Consider any subsequence of
{DT}T that converges in distribution to some distribution D. Then  almost surely  D is a product
distribution  i.e. D = Ds × Dv  with Ds ∈ ∆(Σ) and Dv × ∆(V) such that Dv = F and
Ds ∈ BAYES-CCE of the static incomplete information game with distributional beliefs F.

(cid:2)SW (sT (vT ); vT )(cid:3)

(cid:80)T

6

(cid:80)

Es

(cid:104) 1|Ts|
(cid:104)(cid:80)

w∈V

(cid:105) ≤ o(T )
(cid:105) ≤ o(T )

T

T

(10)

(11)

Proof. We will denote with

ri(a∗

i   a; vi) = Ui(a∗

i   a−i; vi) − Ui(a; vi) 

i ∈ Σi:

the regret of player vi from population i  for action a∗
1{vt
that for any s∗

i(vi) =
i = vi}. Since the sequence has vanishing regret for each player vi in population Pi  it must be

i at action proﬁle a. For a vi ∈ Vi let xt

i(vi) · ri (s∗

i (vi)  st(vt); vi) ≤ o(T )

t=1 xt

(9)
s ∈ ∆(Σ) denote the empirical distribution of st and let s be a random sample
s . For each s ∈ Σ  let Ts ⊂ [T ] denote the time steps such that st = s for each t ∈ Ts. Then

For any ﬁxed T   let DT
from DT
we can re-write Equation (9) as:

(cid:80)T

i(vi) · ri (s∗
xt

t∈Ts

i (vi)  st(vt); vi)

For any s ∈ Σ and w ∈ V  let Ts w = {t ∈ Ts : vt = w}. Then we can re-write Equation (10) as:

Es

|Ts w|
|Ts| 1{wi = vi} · ri (s∗

i (vi)  s(w); vi)

Now we observe that |Ts w|
is the empirical frequency of the valuation vector w ∈ V  when ﬁltered
|Ts|
at time steps where the strategy vector was s. Since at each time step t the valuation vector vt is
picked independently from the distribution of valuation proﬁles F  this is the empirical frequency
of Ts independent samples from F.
By standard arguments from empirical processes theory  if Ts → ∞ then this empirical distribution
converges almost surely to the distribution F. On the other hand if Ts doesn’t go to ∞  then the
empirical frequency of strategy s vanishes to 0 as T → ∞ and therefore has measure zero in the
above expectation as T → ∞. Thus for any convergent subsequence of {DT}  if D is the limit
distribution  then if s is in the support of D  then almost surely the distribution of w conditional on
strategy s is F. Thus we can write D as a product distribution Ds × F.
Moreover  if we denote with w the random variable that follows distribution F  then the limit of
Equation (11) for any convergent sub-sequence  will give that:

a.s.: Es∼Ds

Ew∼F [1{wi = vi} · ri (s∗

i (vi)  s(w); vi)] ≤ 0

Equivalently  we get that Ds will satisfy that for all vi ∈ Vi and for all s∗
i :

a.s.: Es∼Ds

Ew∼F [ri (s∗

i (wi)  s(w); wi) | wi = vi] ≤ 0

The latter is exactly the BAYES-CCE condition from Deﬁnition 7. Thus Ds is in the set of
BAYES-CCE of the static incomplete incomplete information game among n players  where the
type proﬁle is drawn from F.

Given the latter convergence theorem we can easily conclude the following the following theorem 
whose proof is given in the supplementary material.
Theorem 11. The price of anarchy for Bayesian no-regret dynamics is upper bounded by the price
of anarchy of Bayesian coarse correlated equilibria  almost surely.

6 Efﬁciency of Smooth Mechanisms at Bayes Coarse Correlated Equilibria
In this section we show that smoothness of a mechanism M implies that any BAYES-CCE of the
incomplete information setting achieves at least
max{1 µ} of the expected optimal welfare. To show
this we will adopt the interpretation of BAYES-CCE that we used in the previous section  as coarse
correlated equilibria of a more complex normal form game; the stochastic agent normal form rep-
resentation of the Bayesian game. We can interpret this complex normal form game as the game
i |Vi| players  which randomly
samples one player from each of the n population and where the utility of a player in the complete
information mechanism MAG is given by Equation (4). The set of possible outcomes in this agent

that arises from a complete information mechanism MAG among(cid:80)

λ

7

λ

λ

game corresponds to the set of mappings from a proﬁle of chosen players to an outcome in the un-
derlying mechanism M. The optimal welfare of this game  is then the expected ex-post optimal
welfare OPTAG = Ev [OPT(v)].
The main theorem that we will show is that whenever mechanism M is (λ  µ)-smooth  then also
mechanism MAG is (λ  µ)-smooth. Then we will invoke a theorem of [12  11]  which shows that
any coarse correlated equilibrium of a complete information mechanism achieves at least
max{1 µ}
of the optimal welfare. By the equivalence between BAYES-CCE and CCE of this complete infor-
mation game  we get that every BAYES-CCE of the Bayesian game achieves at least
max{1 µ} of the
expected optimal welfare.
Theorem 12 (From complete information to Bayesian smoothness). If a mechanism M is (λ  µ)-
smooth  then for any vector of independent valuation distributions F = (F1  . . .  Fn)  the complete
information mechanism MAG is also (λ  µ)-smooth.
Proof. Consider the following randomized deviation for each player vi ∈ Vi in population i: He
random samples a valuation proﬁle w ∼ F. Then he plays according to the randomized action
s∗
i (vi  w−i)  i.e.  the player deviates using the randomized action guaranteed by the smoothness
property of mechanism M for his type vi and the random sample of the types of the others w−i.
In this
Consider an arbitrary action proﬁle s = (s1  . . .   sn) for all players in all populations.
context it is better to think of each si as a |Vi| dimensional vector in A|Vi|
i |Vi|
dimensional vector. Then with s−vi we will denote all the components of this large vector except
the ones corresponding to player vi ∈ Vi. Moreover  we will be denoting with v a sample from F
drawn by mechanism MAG. We now argue about the expected utility of player vi from this deviation 
which is:
Ew

and to view s as a(cid:80)

i (vi  w−i)  s−i(v−i); vi) · 1{vi = vi}]

i (vi  w−i)  s−vi)(cid:3) = EwEv [Ui(s∗
(cid:2)(cid:80)
i (vi  w−i)  s−vi)(cid:3) = Ew v

Summing the latter over all players vi ∈ Vi in population i:
Ui(s∗

(cid:2)U AG
(cid:2)U AG

i (vi  w−i)  s−i(v−i); vi) · 1{vi = vi}(cid:3)

(cid:88)

Ew

(s∗

(s∗

i vi

i

i vi

vi∈Vi

vi∈Vi

= Ev w [Ui(s∗
= Ev w [Ui(s∗
= Ev w [Ui(s∗

i (vi  w−i)  s−i(v−i); vi)]
i (wi  w−i)  s−i(v−i); wi)]
i (w)  s−i(v−i); wi)]  

where the second to last equation is an exchange of variable names and regrouping using indepen-
dence. Summing over populations and using smoothness of M  we get smoothness of MAG:
i (w)  s−i(v−i); wi)

i (vi  w−i)  s−vi)(cid:3) = Ev w

(cid:2)U AG

i∈[n] Ui(s∗

Ew

(s∗

i vi

(cid:88)

(cid:88)

(cid:104)(cid:80)

(cid:105)

i∈[n]

vi∈Vi
≥ Ev w [λOPT(w) − µR(s(v))] = λEw [OPT(w)] − µRAG(s)

Corollary 13. Every BAYES-CCE of the incomplete information setting of a smooth mechanism
M  achieves expected welfare at least

max{1 µ} of the expected optimal welfare.

λ

7 Finite Time Analysis and Convergence Rates

In the previous section we argued about the limit average efﬁciency of the game as time goes to
inﬁnity. In this section we analyze the convergence rate to BAYES-CCE and we show approximate
efﬁciency results even for ﬁnite time  when players are allowed to have some -regret.
Theorem 14. Consider the repeated matching game with a (λ  µ)-smooth mechanism. Suppose that
for any T ≥ T 0  each player in each of the n populations has regret at most 
n . Then for every δ
and ρ  there exists a T ∗(δ  ρ)  such that for any T ≥ min{T 0  T ∗}  with probability 1 − ρ:

(cid:80)T
(cid:17)
t=1 SW (st(vt); vt) ≥
max{1 µ}Ev [OPT(v)] − δ − µ · 
.

(cid:16) 2

log

λ

1
T

(12)

Moreover  T ∗(δ  ρ) ≤ 54·n3·|Σ|·|V|2·H 3

δ3

ρ

8

References
[1] Dirk Bergemann and Stephen Morris. Correlated Equilibrium in Games with Incomplete In-
formation. Cowles Foundation Discussion Papers 1822  Cowles Foundation for Research in
Economics  Yale University  October 2011.

[2] Avrim Blum  MohammadTaghi Hajiaghayi  Katrina Ligett  and Aaron Roth. Regret minimiza-
tion and the price of total anarchy. In Proceedings of the Fortieth Annual ACM Symposium on
Theory of Computing  STOC ’08  pages 373–382  New York  NY  USA  2008. ACM.

[3] Yang Cai and Christos Papadimitriou. Simultaneous bayesian auctions and computational
complexity. In Proceedings of the ﬁfteenth ACM conference on Economics and Computation 
EC ’14  pages 895–910  New York  NY  USA  2014. ACM.

[4] Ioannis Caragiannis  Christos Kaklamanis  Panagiotis Kanellopoulos  Maria Kyropoulou 
Brendan Lucier  Renato Paes Leme  and ´Eva Tardos. Bounding the inefﬁciency of outcomes
in generalized second price auctions. Journal of Economic Theory  (0):–  2014.

[5] Bart de Keijzer  Evangelos Markakis  Guido Schfer  and Orestis Telelis. Inefﬁciency of stan-
dard multi-unit auctions. In HansL. Bodlaender and GiuseppeF. Italiano  editors  Algorithms
ESA 2013  volume 8125 of Lecture Notes in Computer Science  pages 385–396. Springer
Berlin Heidelberg  2013.

[6] Franoise Forges. Five legitimate deﬁnitions of correlated equilibrium in games with incomplete

information. Theory and Decision  35(3):277–310  1993.

[7] Dean P Foster and Rakesh V Vohra. Asymptotic calibration. Biometrika  85(2):379–390  1998.
[8] ToddR. Kaplan and Shmuel Zamir. Asymmetric ﬁrst-price auctions with uniform distributions:

analytic solutions to the general case. Economic Theory  50(2):269–302  2012.

[9] Elias Koutsoupias and Christos Papadimitriou. Worst-case equilibria. In Proceedings of the
16th annual conference on Theoretical aspects of computer science  STACS’99  pages 404–
413  Berlin  Heidelberg  1999. Springer-Verlag.

[10] B. Lucier and A. Borodin. Price of anarchy for greedy auctions. In Proceedings of the Twenty-
First Annual ACM-SIAM Symposium on Discrete Algorithms  SODA ’10  pages 537–553 
Philadelphia  PA  USA  2010. Society for Industrial and Applied Mathematics.

[11] T. Roughgarden. Intrinsic robustness of the price of anarchy. In Proceedings of the 41st annual
ACM symposium on Theory of computing  STOC ’09  pages 513–522  New York  NY  USA 
2009. ACM.

[12] Vasilis Syrgkanis and ´Eva Tardos. Composable and efﬁcient mechanisms. In Proceedings of
the Forty-ﬁfth Annual ACM Symposium on Theory of Computing  STOC ’13  pages 211–220 
New York  NY  USA  2013. ACM.

[13] A. Vetta. Nash equilibria in competitive societies  with applications to facility location  traf-
ﬁc routing and auctions. In Foundations of Computer Science  2002. Proceedings. The 43rd
Annual IEEE Symposium on  pages 416–425  2002.

9

,Jason Hartline
Vasilis Syrgkanis
Eva Tardos
Christoph Feichtenhofer
Axel Pinz
Richard Wildes