2012,Globally Convergent Dual MAP LP Relaxation Solvers using Fenchel-Young Margins,While finding the exact solution for the MAP inference problem is intractable for many real-world tasks  MAP LP relaxations have been shown to be very effective in practice.  However  the most efficient methods that perform block coordinate descent can get stuck in sub-optimal points as  they are not globally convergent. In this work we propose to augment these algorithms with an $\epsilon$-descent approach and present a method to efficiently optimize for a descent direction in the subdifferential using a margin-based extension of the Fenchel-Young duality theorem. Furthermore  the presented approach provides a methodology to construct a primal optimal solution from its dual optimal counterpart. We demonstrate the efficiency of the presented approach on spin glass models and protein interactions problems and show that our approach outperforms state-of-the-art solvers.,Globally Convergent Dual MAP LP Relaxation

Solvers using Fenchel-Young Margins

Alexander G. Schwing

ETH Zurich

aschwing@inf.ethz.ch

Marc Pollefeys

ETH Zurich

pomarc@inf.ethz.ch

Tamir Hazan
TTI Chicago

tamir@ttic.edu

Raquel Urtasun

TTI Chicago

rurtasun@ttic.edu

Abstract

While ﬁnding the exact solution for the MAP inference problem is intractable for
many real-world tasks  MAP LP relaxations have been shown to be very effective
in practice. However  the most efﬁcient methods that perform block coordinate
descent can get stuck in sub-optimal points as they are not globally convergent.
In this work we propose to augment these algorithms with an -descent approach
and present a method to efﬁciently optimize for a descent direction in the sub-
differential using a margin-based formulation of the Fenchel-Young duality the-
orem. Furthermore  the presented approach provides a methodology to construct
a primal optimal solution from its dual optimal counterpart. We demonstrate the
efﬁciency of the presented approach on spin glass models and protein interaction
problems and show that our approach outperforms state-of-the-art solvers.

Introduction

1
Graphical models are a common method to describe the dependencies of a joint probability distribu-
tion over a set of discrete random variables. Finding the most likely conﬁguration of a distribution
deﬁned by such a model  i.e.  the maximum a-posteriori (MAP) assignment  is one of the most
important inference tasks. Unfortunately  it is a computationally hard problem for many interest-
ing applications. However  it has been shown that linear programming (LP) relaxations recover the
MAP assignment in many cases of interest (e.g.  [13  23]).
Due to the large amount of variables and constraints  solving inference problems in practice still re-
mains a challenge for standard LP solvers. Development of speciﬁcally tailored algorithms has since
become a growing area of research. Many of these designed solvers consider the dual program  thus
they are based on local updates that follow the graphical model structure  which ensures suitability
for very large problems. Unfortunately  the dual program is non-smooth  hence introducing difﬁcul-
ties to existing solvers. For example  block coordinate descent algorithms  typically referred to as
convex max-product  monotonically decrease the dual objective and converge very fast  but are not
guaranteed to reach the global optimum of the dual program [3  6  11  14  17  20  22  24  25]. Dif-
ferent approaches to overcome the sub-optimality of the convex max-product introduced different
perturbed programs for which convergence to the dual optimum is guaranteed  e.g.  smoothing  prox-
imal methods and augmented Lagrangian methods [6  7  8  16  18  19  27]. However  since these
algorithms consider a perturbed program they are typically slower than the convex max-product
variants [8  18].
In this work we propose to augment the convex max-product algorithm with a steepest -descent
approach to monotonically decrease the dual objective until reaching the global optimum of the dual
program. To perform the -descent we explore the -subgradients of the dual program  and provide
a method to search for a descent direction in the -subdifferential using a margin-based formula-
tion of the Fenchel-Young duality theorem. This characterization also provides a new algorithm to

1

construct a primal optimal solution for the LP relaxation from a dual optimal solution. We demon-
strate the effectiveness of our approach on spin glass models and protein-protein interactions taken
from the probabilistic inference challenge (PIC 2011)1. We illustrate that the method exhibits nice
convergence properties while possessing optimality certiﬁcates.
We begin by introducing the notation  MAP LP relaxations and their dual programs. We subse-
quently describe the subgradients of the dual and provide an efﬁcient procedure to recover a primal
optimal solution. We explore the -subgradients of the dual objective  and introduce an efﬁcient
globally convergent dual solver based on the -margin of the Fenchel-Young duality theorem. Fi-
nally  we extend our approach to graphical models over general region graphs.
2 Background
Graphical models encode joint distributions over discrete product spaces X = X1 × ··· × Xn. The
joint probability is deﬁned by combining energy functions over subsets of variables. Throughout
this work we consider two types of functions: single variable functions  θi(xi)  which correspond
to the n vertices in the graph  i ∈ {1  ...  n}  and functions over subsets of variables θα(xα)  for
α ⊂ {1  ..  n}  that correspond to the graph hyperedges. The joint distribution is then given by
α∈E θα(xα)). In this paper we focus on estimating the MAP  i.e. 
ﬁnding the assignment that maximizes the probability  or equivalently minimizes the energy which
is the negative log probability. Estimating the MAP can be written as a program of the form [10]:

i∈V θi(xi) +(cid:80)

p(x) ∝ exp((cid:80)

θi(xi) +

θα(xα).

(1)

(cid:88)

i∈V

argmax
x1 ... xn

(cid:88)

α∈E

Due to its combinatorial nature  this problem is NP-hard for general graphical models. It is tractable
only in some special cases such as tree structured graphs  where specialized dynamic programming
algorithms (e.g.  max-product belief propagation) are guaranteed to recover the optimum.
The MAP program in Eq. (1) has a linear form  thus it is naturally represented as an integer linear
program. Its tractable relaxation is obtained by replacing the integral constraints with non-negativity
constraints as follows:

bα(xα)θα(xα) +

bi(xi)θi(xi)

s.t. bi(xi)  bα(xα) ≥ 0 

bα(xα) = 1 

xα

xi

(cid:88)

(cid:88)

xα\xi

bi(xi) = 1 

bα(xα) = bi(xi).

(2)

(cid:88)

α xα

max
bi bα

(cid:88)
(cid:88)

i xi

Whenever the maximizing argument to above linear program happens to be integral  i.e.  the optimal
beliefs satisfy bi(xi)  bα(xα) ∈ {0  1}  the program value equals the MAP value. Moreover  the
maximum arguments of the optimal beliefs point toward the MAP assignment [26].
We denote by N (i) the edges that contain vertex i and by N (α) the vertices in the edge α. Following
[22  27] we consider the re-parametrized dual

(cid:88)

i

θi(xi) +

(cid:88)

α∈N (i)

 +

(cid:88)

α

θα(xα) − (cid:88)

i∈N (α)

q(λ) =

max

xi

λi→α(xi)

max
xα

λi→α(xi)

(3)

 .

The dual program value upper bounds the primal program described in Eq. (2). Therefore to compute
the primal optimal value one can minimize the dual upper bound. Using block coordinate descent
on the dual objective amounts to optimizing blocks of dual variables while holding the remaining
ones ﬁxed. This results in the convex max-product message-passing update rules [6  17]:

(cid:110)

(cid:16)

(cid:88)
(cid:88)

j∈N (α)\i

β∈N (i)

λj→α(xj)

(cid:111)
(cid:17) − µα→i(xi)

θi(xi) +

µβ→i(xi)

Repeat until convergence  for every i = 1  ...  n:
∀xi  α ∈ N (i) µα→i(xi) = max
xα\xi

θα(xα) +

∀xi  α ∈ N (i) λi→α(xi) =

1

1 + |N (i)|

1http://www.cs.huji.ac.il/project/PASCAL/index.php

2

∀ˆλ

q(ˆλ) − d(cid:62)ˆλ ≥ q(λ) − d(cid:62)λ.

The convex max-product algorithm is guaranteed to converge since it minimizes the dual function 
which is lower bounded by the primal program. Interestingly  the convex max-product shares the
same complexity as the max-product belief propagation  which is attained by replacing the coef-
ﬁcient 1/(1 + |N (i)|) by 1. It has  however  two fundamental problems. First  it can get stuck
in non-optimal stationary points. This happens since the dual objective is non-smooth  thus the
algorithm can reach a corner  for which the dual objective stays ﬁxed when changing only a few
variables. For example  consider the case of a minimization problem where we try to descend from
a pyramid while taking only horizontal and vertical paths. We eventually stay at the same height.
The second drawback of convex max-product is that it does not always produce a primal optimal
solution  bi(xi)  bα(xα)  even when it reaches a dual optimal solution.
In the next section  we consider the dual subgradients  and provide an efﬁcient algorithm for detect-
ing corners  as well as for decoding a primal optimal solution from a dual optimal solution. This is
an intermediate step which facilitates the margin analysis of the Fenchel-Young duality theorem in
Sec. 4. It provides an efﬁcient way to get out of corners  and to reach the optimal dual value.
3 The Subgradients of the Dual Objective and Steepest Descent
Subgradients are generalizations of gradients for non-smooth convex functions. Consider the func-
tion q(λ) in Eq. (3). A vector d is called a subgradient of q(λ) if it supports the epigraph of q(λ) at
λ  i.e. 

α = argmaxxα{θα(xα) +(cid:80)

(4)
The supporting hyperplane at (λ  q(λ)) with slope d takes the form d(cid:62)λ − q∗(d)  when deﬁning
the conjugate dual as q∗(d) = maxλ{d(cid:62)λ − q(λ)}. From the deﬁnition of q∗(d) one can derive
the Fenchel-Young duality theorem: q(λ) + q∗(d) ≥ d(cid:62)λ  where equality holds if and only if d
is a supporting hyperplane at (λ  q(λ)). The set of all subgradients is called the subdifferential 
denoted by ∂q(λ)  which can be characterized using the Fenchel-Young theorem as ∂q(λ) = {d :
q(λ) + q∗(d) = λ(cid:62)d}. The subdifferential provides a way to reason about the optimal solutions of
q(λ). Using Eq. (4) we can verify that λ is dual optimal if and only if 0 ∈ ∂q(λ). In the following
claim we characterize the subdifferential of the dual function q(λ) using the Fenchel-Young duality
theorem:
i = argmaxxi{θi(xi) −
Claim 1. Consider the dual function q(λ) given in Eq. (3). Let X∗
i∈N (α) λi→α(xi)}. Then d ∈ ∂q(λ)  if
bα(xα) − bi(xi) for probability distributions bi(xi)  bα(xα) whose
α respectively.

(cid:80)
and only if di→α(xi) =(cid:80)
α∈N (i) λi→α(xi)} and X∗
nonzero entries belong to X∗
Proof: Using the Fenchel-Young characterization of Eq. (4) for the max-function we obtain the set
α. Summing over all regions r ∈ {i  α} while noticing the change
of maximizing elements X∗
of sign  we obtain the marginalization disagreements di→α(xi).
The convex max-product algorithm performs block coordinate descent updates. Thus it iterates
over vertices i and computes optimal solutions λi→α(xi) for every xi  α ∈ N (i) analytically  while
holding the rest of the variables ﬁxed. The claim above implies that the convex max-product iterates
over i and generates beliefs bi(xi)  bα(xα) for every xi  α ∈ N (i) that agree on their marginal
probabilities. This interpretation provides an insight into the non-optimal stationary points of the
convex max-product  i.e.  points for which it is not able to generate consistent beliefs bα(xα) when
it iterates over i = 1  . . .   n. The representation of the subdifferential as the amount of disagreement
between the marginalization constraints provides a simple procedure to verify dual optimality  as
well as to construct primal optimal solutions. This is summarized in the corollary below.
Corollary 1. Given a point λ  and sets X∗
X∗
i   X∗

α be elements in

xα\xi
i   X∗

i   X∗

α as deﬁned in Claim 1  let x∗

i   x∗

i   X∗

α respectively. Consider the quadratic program
bα(x∗

(cid:88)

(cid:16) (cid:88)

(cid:17)2

min
bi bα

i x∗
s.t. bi(x∗

i  α∈N (i)
α\x∗
x∗
α) ≥ 0 
i )  bα(x∗

i

α) − bi(x∗
(cid:88)
i )

bα(x∗

α) = 1 

x∗

α

(cid:88)

x∗

i

bi(x∗

i ) = 1.

λ is a dual optimal solution if and only if the value of the above program equals zero. Moreover  if
λ is a dual optimal solution  then the optimal beliefs b∗
i (xi) are also the optimal solution

α(xα)  b∗

3

(cid:80)

b∗
α(x∗

α) − b∗

i (x∗

α\x∗
x∗

i

of the primal program in Eq. (2). However  if λ is not dual optimal  then the vector d∗

i→α(xi) =

i ) points towards the steepest descent direction of the dual function  i.e. 

d∗ = argmin
(cid:107)d(cid:107)≤1

lim
α↓0

q(λ + αd) − q(λ)

α

.

Proof: The steepest descent direction d of q is given by minimizing the directional derivative q(cid:48)
d 

min(cid:107)d(cid:107)≤1

q(cid:48)
d(λ) = min(cid:107)d(cid:107)≤1

d(cid:62)y = max
y∈∂q

max
y∈∂q

min(cid:107)d(cid:107)≤1

d(cid:62)y = max
y∈∂q

−(cid:107)y(cid:107)2 

which yields the above program (cf . [2]  Chapter 4). If the zero vector is part of the subdifferential 
we are dual optimal. Primal optimality follows from Claim 1.
One can monotonically decrease the dual objective by minimizing it along the steepest descent
direction. Unfortunately  following the steepest descent direction does not guarantee convergence to
the global minimum of the dual function [28]. Performing steepest descent might keep minimizing
the dual objective with smaller and smaller increments  thus converging to a suboptimal solution.
The main drawback of steepest descent as well as block coordinate descent when applied to the dual
objective in Eq. (3) is that both procedures only consider the support of X∗
α deﬁned in Claim 1.
In the following we show that by considering the -margin of these supports we can guarantee that
at every iteration we decrease the dual value by at least . This procedure results in an efﬁcient
algorithm that reaches both dual and primal optimal solutions.

i   X∗

4 The -Subgradients of the Dual Objective and Steepest -Descent
To monotonically decrease the dual value while converging to the optimum  we suggest to explore
the -neighborhood of the dual objective in Eq. (3) around the current iterate λ. For this purpose  we
explore its family of -subgradients. Given our convex dual function q(λ) and a positive scalar   we
say that a vector d is an -subgradient at λ if it supports the epigraph of q(λ) with an -margin:

∀ˆλ

q(ˆλ) − d(cid:62)ˆλ ≥ q(λ) − d(cid:62)λ − .

(5)

The subgradients of a convex function are also -subgradients. The family of -subgradients is called
the -subdifferential and is denoted by ∂q(λ). Using the conjugate dual q∗(d)  we can characterize
the -subdifferential by employing the -margin Fenchel-Young duality theorem.

(-margin Fenchel-Young duality)

∂q(λ) =

d : 0 ≤ q(λ) + q∗(d) − d(cid:62)λ ≤ 

(6)

(cid:110)

(cid:111)

The -subdifferential augments the subdifferential of q(λ) with additional directions d which control
the -neighborhood of the function. Whenever one ﬁnds a steepest descent direction within ∂q(λ) 
it is guaranteed to improve the dual objective by at least . Moreover  if one cannot ﬁnd such a
direction within the -subdifferential  then q(λ) is guaranteed to be -close to the dual optimum.
This is summarized in the following claim.
Claim 2. Let q(λ) be a convex function and let  be a positive scalar. The -subdifferential ∂q(λ) is
a convex and compact set. If 0 (cid:54)∈ ∂q(λ) then the direction d∗ = argmin(cid:107)d(cid:107) subject to d ∈ ∂q(λ)
is a descent direction and inf α>0 q(λ − αd) < q(λ) − . On the other hand  if 0 ∈ ∂q(λ) then
q(λ) ≤ inf λ q(λ) + .
Proof: [2] Proposition 4.3.1.
Although ∂q(λ) is a convex and compact set  ﬁnding its direction of descent is computationally
challenging. Fortunately  it can be approximated whenever the convex function is a sum of simple
r ∂qr(λ) satisﬁes
∂q(λ) ⊂ ˜∂q(λ) ⊂ ∂mq(λ)  (see  e.g.  [2]). On the one hand  if 0 (cid:54)∈ ˜∂q(λ) then the direction of
steepest descent taken from ˜∂q(λ) reduces the dual objective by at least . If 0 ∈ ˜∂q(λ) then q(λ)
is m-close to the dual optimum. In the following claim we use the -margin Fenchel-Young duality
in Eq. (6) to characterize the approximated -subdifferential of the dual function.

r=1 qr(λ). The approximation ˜∂q(λ) = (cid:80)

convex functions  i.e.  q(λ) = (cid:80)m

4

xα\xi

only if di→α(xi) =(cid:80)
θi(xi) − (cid:88)
θα(xα) +
(cid:88)

max
xα

∀α

max

∀i

α∈N (i)

xi

i∈N (α)

λi→α(xi)

bi(xi)

λi→α(xi)

 −  ≤(cid:88)
 −  ≤(cid:88)

xi

xα

θi(xi) − (cid:88)
θα(xα) +
(cid:88)

α∈N (i)

i∈N (α)
r (b) − b(cid:62) ˆθ ≤  with q∗



 .

λi→α(xi)

bα(xα)

λi→α(xi)

Claim 3. Consider the dual function q(λ) in Eq. (3). Then the approximated -subdifferential con-
sists of vectors d whose entries correspond to marginalization disagreements  i.e.  d ∈ ˜∂q(λ) if and
bα(xα)− bi(xi) for probability distributions bi(xi)  bα(xα) that satisfy

Proof: Eq. (6) implies b ∈ ∂qr(ˆθ) if and only if qr(ˆθ) + q∗
r (b) denoting the
conjugate dual of qr(ˆθ). Plugging in qr  q∗
r we obtain not only the maximizing beliefs but all beliefs
with an -margin. Summing over r ∈ {i  α} while noticing that λi→α(xi) change signs between qα

and qi we obtain the marginalization disagreements di→α(xi) =(cid:80)

bα(xα) − bi(xi).

xα\xi

˜∂q(λ) is described using beliefs bi(xi)  bα(xα) that satisfy linear constraints  therefore ﬁnding a
direction of -descent can be done efﬁciently. Claim 2 ensures that minimizing the dual objec-
tive along a direction of descent decreases its value by at least . Moreover  we are guaranteed to be
(|V |+|E|)-close to a dual optimal solution if no direction of descent is found in ˜∂q(λ). Therefore 
we are able to get out of corners and efﬁciently reach an approximated dual optimal solution. The
interpretation of the Fenchel-Young margin as the amount of disagreement between the marginaliza-
tion constraints also provides a simple way to reconstruct an approximately optimal primal solution.
This is summarized in the following corollary.

α∈N (i) λi→α(xi) and ˆθα(xα) = θα(xα) +

(cid:88)

i∈N (α) λi→α(xi). Consider the quadratic program

Corollary 2. Given a point λ  set ˆθi(xi) = θi(xi) −(cid:80)
(cid:80)
(cid:17)2
(cid:88)
(cid:88)

xα\xi
s.t. bi(xi)  bα(xα) ≥ 0 

bα(xα) − bi(xi)

(cid:16) (cid:88)

bα(xα) = 1 

(cid:88)

(cid:88)

i xi α∈N (i)

min
bi bα

xα

xi

bi(xi)ˆθi(xi) ≥ max

{ˆθi(xi)} −  

xi

xα

bi(xi) = 1

bα(xα)ˆθα(xα) ≥ max

xα

{ˆθα(xα)} − .

xi

q(λ) is (|V | + |E|)-close to the dual optimal value if and only if the value of the above program
i (xi) primal value is (|V | + |E|)-close to the
equals zero. Moreover  the optimal beliefs b∗
optimal primal value in Eq. (2). However  if q(λ) is not (|V | +|E|)-close to the dual optimal value
then the vector d∗
i (xi) points towards the steepest -descent direction
of the function  namely
q(λ + αd) − q(λ) + 

i→α(xi) =(cid:80)

α(xα)−b∗
b∗

α(xα)  b∗

xα\xi

d∗ = argmin
(cid:107)d(cid:107)≤1

lim
α↓0

α

.

(cid:88)

Proof: The steepest -descent direction is given by the minimum norm element of the -
subdifferential  described in Claim 3. (|V | + |E|)-closeness to the dual optimum is given by ([2] 
Proposition 4.3.1) once we ﬁnd the value of the quadratic program to be zero. Note that the superset
˜∂ is composed of |V | + |E| subdifferentials. If the value of the above program equals zero  the
beliefs fulﬁll marginalization constraints and they denote a probability distribution. Summing both
-margin inequalities w.r.t. i  α  we obtain

(cid:88)

bα(xα)ˆθα(xα) ≥(cid:88)

bi(xi)ˆθi(xi) +

ˆθi(xi) +

max

xi

max
xα

ˆθα(xα) − (|V | + |E|).

i xi

α xα

i

where the primal on the left hand side of the resulting inequality is larger then the dual subtracted
by (|V | + |E|). With the dual itself upper bounding the primal  the corollary follows.
Thus  we can construct an algorithm that performs  improvements over the dual function in each
iteration. We can either perform block-coordinate dual descent (i.e.  convex max-product updates)
or steepest -descent steps. Since both methods monotonically improve the same dual function  our
approach is guaranteed to reach the optimal dual solution and to recover the primal optimal solution.

5

(cid:88)

α

(a)

(b)

Figure 1: (a) Difference between the minimal dual value attained by convex max-product q(λCMP)
and our approach q(λ). Convex max-product gets stuck in about 20% of all cases. (b) Dual value
achieved after a certain amount of time for cases where convex max-product gets stuck.
5 High-Order Region Graphs
Graphical models naturally describe probability distributions with different types of regions r ⊂
{1  ...  n}. However  the linear program relaxation described in Eq. (2) considers interactions be-
tween regions which correspond to variables i and regions that correspond to cliques α.
In the
following we extend the -descent framework when considering linear programming relaxations
without constraining the region interactions. Since we allow any regions to interact  we denote these
interactions through a region graph [29]. A region graph is a directed graph whose nodes represent
the regions and its direct edges correspond to the inclusion relation  i.e.  a directed edge from node
r to s is possible only if s ⊂ r. We adopt the terminology where P (r) and C(r) stand for all nodes
that are parents and children of the node r  respectively. Thus we consider the linear programming
relaxation of a general high-order graphical model as follows

(cid:88)

r xr

(cid:88)

xr

(cid:110)

(cid:88)

r

q(λ) =

max

xr

θr(xr) +

(cid:88)

λc→r(xc) − (cid:88)

c∈C(r)

p∈P (r)

max

b

br(xr)θr(xr)

s.t. br(xr) ≥ 0 

br(xr) = 1 

∀r  s ∈ P (r)

Following [5  22  27] we consider the re-parametrized dual program

(cid:88)

xs\xr

(7)

bs(xs) = br(xr)

(cid:111)

λr→p(xr)

which is a sum of max-functions. Its approximated -subdifferential is described with respect to
their Fenchel-Young margins. Using the same reasoning as in Sec. 4 we present a simple way to
recover an -steepest descent direction  as well as to reconstruct an approximated optimal primal
solution.

c∈C(r) λc→r(xr) −(cid:80)

p∈P (r) λr→p(xr).

Consider the quadratic program

Corollary 3. Given a point λ  set ˆθr(xr) = θr(xr) +(cid:80)
(cid:17)2
(cid:88)

(cid:16) (cid:88)
(cid:88)

bp(xp) − br(xr)

(cid:88)

xp\xr

minb

r xr p∈P (r)
br(xr) ≥ 0 

br(xr) = 1 

s.t.

xr

xr

br(xr)ˆθr(xr) ≥ max

{ˆθr(xr)} − 

xr

Let |R| be the total number of regions in the graph  then λ is |R|-close to the dual optimal solution
if and only if the value of the above program equals zero. Moreover  the optimal beliefs b∗
r(xr) are
also |R|-close to the optimal solution of the primal program in Eq. (7). However  if q(λ) is not
|R| close to the dual optimal solution then the vector d∗
r(xr) points
towards the steepest -descent direction of the dual function.

r→p(xr) =(cid:80)

p(xp) − b∗
b∗

xp\xr

Proof: It is a straightforward generalization of Corollary 2.
When dealing with high-order region graphs  one can choose a region graph  e.g.  the Hasse diagram 
that has signiﬁcantly less edges than a region graph that connects variables i to cliques α. Therefore 
when considering many high-order regions  the formulation in the above corollary is more efﬁcient
than the one in Corollary 2.

6

]
s
[

e
m

i
t

]
s
[

e
m

i
t


(a)


(b)

Figure 2: Average time required for different solvers to achieve a speciﬁed accuracy on 30 spin glass
models  (a) when solvers are applied to “hard” problems only  i.e.  those where CMP gets stuck far
from the optimum. Average results over 30 models are shown in (b)  (c) decrease of the dual value
over time for ADLP and our -descent approach.

(c)

6 Experimental Evaluation

To beneﬁt from the efﬁciency of convex max-product  our implementation starts by employing
block-coordinate descent iterations before switching to the globally convergent -descent approach
once the dual value decreases by less than  = 0.01. As we always optimize the same cost func-
tion  switching the gradient computation is possible. We employ a backtracking line search in our
-descent approach. In the following we demonstrate the effectiveness of our approach on synthetic
10x10 spin glass models as well as protein interactions from the probabilistic inference challenge
(PIC 2011). We consider spin glass models that consist of local factors  each having 3 states with
values randomly chosen according to N (0  1). We use three states as convex max-product is optimal
for pairwise spin glass models with only two states per random variable. The pairwise factors of the
regular grid are weighted potentials with +1 on the diagonal and off-diagonal entries being −1. The
weights are again independently drawn from N (0  1). In the ﬁrst experiment we are interested in
estimating how often convex max-product gets stuck in corners. We generate a set of 1000 spin glass
models and estimate the distribution of the dual value difference comparing the -descent approach
with the convex max-product result after 10  000 iterations. We observe in Fig. 1(a) that about 20%
of the spin glass models have a dual value difference larger than zero.
Having observed that convex max-product does not achieve optimality for 20% of the models  we
now turn our attention to evaluating the run-time of different algorithms. We compare our imple-
mentation of the -steepest descent algorithm with the alternating direction method for dual MAP-
LP relaxations (ADLP) [18].
In addition  we illustrate the performance of convex max-product
(CMP) [6] and compare against the dual-decomposition work of [12] provided in a generic (DDG)
and a re-weighted (DDR) version in the STAIR library [4]. Note that ADLP is also implemented in
this library. All algorithms are restricted to at most 20  000 iterations. We draw the readers attention
to Fig. 1(b)  where we evaluate a single spin glass model and illustrate the dual value obtained after
a certain amount of time. As given by the derivations  CMP is a monotonically decreasing algorithm
that can get stuck in corners. It is important to note that our -descent approach is monotonically
decreasing as well  which contrasts all the other investigated algorithms (ADLP  DDG  DDR).
We evaluate the time it requires the different algorithms to achieve a given accuracy. We ﬁrst focus
on “hard” problems  where we deﬁned “hard” as those spin glass models whose difference between
convex max-product and the -descent method is larger than 0.2. To obtain statistically meaningful
results we average over 30 hard problems and report the time to achieve a given accuracy in Fig. 2(a).
We used the minimum across all dual values found by all algorithms as the optimum. If an algorithm
does not achieve -close accuracy within 20 000 iterations we set its time to the arbitrarily chosen
value of 105. We note that CMP is very fast for low accuracies (high ) but gets stuck in corners 
not achieving high accuracies (low ). This is also the case for DDG and DDR. ADLP achieves
signiﬁcantly lower -closeness but the 20  000 iteration limit stops it from reaching 10−3. The
previous experiment focus on hard problems. In order to evaluate the average case  we randomly
generate 30 spin glass models. The results are provided in Fig. 2(b). As expected the -descent
approach performs similarly well  ADLP achieves lower accuracies on more samples. The step
apparent for CMP  DDG and DDR is not as sharp  but still very signiﬁcant.
Protein interactions: We rely on the data provided by the PIC 2011 and compare the -descent
approach to ADLP as it is the most competitive method in the previous experiments. The dual
energy obtained after a given amount of time is illustrated in Fig. 2(c).

7

7 Related Work
We explore methods to solve LP relaxations by monotonically decreasing the value of its dual ob-
jective and reconstructing a primal optimal solution. For this purpose we investigate approximated
subgradients of the dual program using the Fenchel-Young margins  and provide a method to reduce
the dual objective in every step by a constant value until convergence to the optimum. Efﬁcient dual
solvers were extensively studied in the context of LP relaxations for the MAP problem [14  20  25].
The dual program is non-smooth  thus subgradient descent algorithms are guaranteed to reach the
dual optimum [12]  as well as recover the primal optimum [12]. Despite their theoretical guarantees 
subgradient methods are typically slow. Dual block coordinate descent methods  typically referred
to as convex max-product algorithms  are monotonically decreasing  and were shown to be faster
than subgradient methods [3  6  11  17  22  24  27]. Since the dual program is non-smooth  these
algorithms can get stuck in non-optimal stationary points and cannot in general recover a primal
optimal solution [26]. Our work speciﬁcally addresses these drawbacks.
Recently  several methods were devised to overcome the sub-optimality of convex max-product
algorithms. Unlike our approach  all these algorithms optimize a perturbed program. Some methods
use the soft-max with low temperature to smooth the dual objective in order to avoid corners as well
as to recover primal optimal solutions [6  7  8]. However  these methods are typically slower  as
computation of the low-temperature soft-max is more expensive than max-computation. [19] applied
the proximal method  employing a primal strictly concave perturbation  which results in a smooth
dual approximation that is temperature independent. This approach converges to the dual optimum
and recovers the primal optimal solution. However  it uses a double loop scheme where every
update involves executing a convex sum-product algorithm. Alternative methods applied augmented
Lagrangian techniques to the primal [16] and the dual programs [18]. The augmented Lagrangian
method guarantees to reach the global optimum and recover the dual and primal solutions. Unlike
our approach  this method is not monotonically decreasing and works on a perturbed objective  thus
cannot be efﬁciently integrated with convex max-product updates that perform block coordinate
descent on the dual of the LP relaxation.
Our approach is based on the -descent algorithm for convex functions [2]. We use the -margin
of the Fenchel-Young duality theorem to adjust the -subdifferential to the dual objective of the
LP relaxation  thus augmenting the convex max-product with the ability to get out of corners. We
also construct an efﬁcient method to recover a primal optimal solution. Our approach is related
to the Bundle method [15  9]  which performs an -subgradient descent in cases where efﬁcient
search in the -subdifferential is impossible. The graphical model structure in our setting makes
searching in the -subdifferential easy  thus our approach is signiﬁcantly faster. Our algorithm satis-
ﬁes -complementary slackness while performing -descent step  similarly to the auction algorithm.
However  our algorithm is monotonically decreasing and can be used for general graphical models 
while the auction algorithm might increase its dual and its convergence properties hold only for
network ﬂow problems.
8 Conclusions and Discussion
Evaluating the MAP assignment and solving its LP relaxations are key problems in approximate
inference. Some of the existing solvers  such as convex max-product  have limitations. Mainly  these
solvers can get stuck in a non-optimal stationary point  thus they cannot recover the primal optimal
solution. We explore the properties of subgradients of the dual objective and construct a simple
algorithm that determines if the dual stationary point is optimal and recovers the primal optimal
solution in this case (Corollary 1). Moreover  we investigate the family of -subgradients using
Fenchel-Young margins and construct a monotonically decreasing algorithm that is guaranteed to
achieve optimal dual and primal solutions (Corollary 2)  including general region graphs (Corollary
3). We show that our algorithm compares favorably with pervious methods on spin glass models
and protein interactions. The approximated steepest descent direction is recovered by solving a
quadratic program subject to linear constraints. We used the Gurobi solver2  which ignores the
graphical structure of the linear constraints. We believe that constructing a message-passing solver
for this sub-problem will signiﬁcantly speed-up our approach. Further extensions  e.g.  enforcing
constraints over messages such as those arising from cloud computing are also applicable to our
setting [1  21].

2http://www.gurobi.com

8

References
[1] A. Auslender and M. Teboulle. Interior gradient and epsilon-subgradient descent methods for constrained

convex minimization. Mathematics of Operations Research  2004.

[2] D. P. Bertsekas  A. Nedi´c  and A. E. Ozdaglar. Convex Analysis and Optimization. Athena Scientiﬁc 

2003.

[3] A. Globerson and T. S. Jaakkola. Fixing max-product: convergent message passing algorithms for MAP

relaxations. In Proc. NIPS  2007.

[4] S. Gould  O. Russakovsky  I. Goodfellow  P. Baumstarck  A. Y. Ng  and D. Koller. The STAIR Vision

Library (v2.4)  2011. http://ai.stanford.edu/ sgould/svl.

[5] T. Hazan  J. Peng  and A. Shashua. Tightening fractional covering upper bounds on the partition function

for high-order region graphs. In Proc. UAI  2012.

[6] T. Hazan and A. Shashua. Norm-product belief propagation: Primal-dual message-passing for approxi-

mate inference. Trans. on Information Theory  2010.

[7] J. K. Johnson. Convex relaxation methods for graphical models: Lagrangian and maximum entropy

approaches. PhD thesis  Massachusetts Institute of Technology  2008.

[8] V. Jojic  S. Gould  and D. Koller. Accelerated dual decomposition for MAP inference. In Proc. ICML 

2010.

[9] J. H. Kappes  B. Savchynskyy  and C. Schn¨orr. A Bundle Approach To Efﬁcient MAP-Inference by

Lagrangian Relaxation. In Proc. CVPR  2012.

[10] D. Koller and N. Friedman. Probabilistic graphical models. MIT Press  2009.
[11] V. Kolmogorov. Convergent tree-reweighted message passing for energy minimization. PAMI  2006.
[12] N. Komodakis  N. Paragios  and G. Tziritas. MRF Energy Minimization & Beyond via Dual Decomposi-

tion. PAMI  2010.

[13] T. Koo  A.M. Rush  M. Collins  T. Jaakkola  and D. Sontag. Dual decomposition for parsing with non-

projective head automata. In Proc. EMNLP  2010.

[14] A.M.C.A. Koster  S.P.M. van Hoesel  and A.W.J. Kolen. The partial constraint satisfaction problem:

Facets and lifting theorems. Operations Research Letters  1998.

[15] C. Lemar´echal. An algorithm for minimizing convex functions. Information processing  1974.
[16] A.F.T. Martins  M.A.T. Figueiredo  P.M.Q. Aguiar  N.A. Smith  and E.P. Xing. An Augmented La-

grangian Approach to Constrained MAP Inference. In Proc. ICML  2011.

[17] T. Meltzer  A. Globerson  and Y. Weiss. Convergent Message Passing Algorithms – A Unifying View. In

Proc. UAI  2009.

[18] O. Meshi and A. Globerson. An Alternating Direction Method for Dual MAP LP Relaxation. In Proc.

ECML PKDD  2011.

[19] P. Ravikumar  A. Agarwal  and M. J. Wainwright. Message-passing for graph-structured linear programs:

Proximal methods and rounding schemes. JMLR  2010.

[20] M. Schlesinger. Syntactic analysis of two-dimensional visual signals in noisy conditions. Kibernetika 76.
[21] A. G. Schwing  T. Hazan  M. Pollefeys  and R. Urtasun. Distributed message passing for large scale

graphical models. In Proc. CVPR  2011.

[22] D. Sontag and T. S. Jaakkola. Tree block coordinate descent for MAP in graphical models.

AISTATS  2009.

In Proc.

[23] D. Sontag  T. Meltzer  A. Globerson  T. Jaakkola  and Y. Weiss. Tightening LP relaxations for MAP using

message passing. In Proc. UAI  2008.

[24] D. Tarlow  D. Batra  P. Kohli  and V. Kolmogorov. Dynamic tree block coordinate ascent. In Proc. ICML 

2011.

[25] M. J. Wainwright  T. S. Jaakkola  and A. S. Willsky. MAP estimation via agreement on trees: message-

passing and linear programming. Trans. on Information Theory  2005.

[26] Y. Weiss  C. Yanover  and T. Meltzer. MAP Estimation  Linear Programming and Belief Propagation with

Convex Free Energies. In Proc. UAI  2007.

[27] T. Werner. Revisiting the linear programming relaxation approach to gibbs energy minimization and

weighted constraint satisfaction. PAMI  2010.

[28] P. Wolfe. A method of conjugate subgradients for minimizing nondifferentiable functions. Nondifferen-

tiable Optimization  1975.

[29] J. S. Yedidia  W. T. Freeman  and Y. Weiss. Constructing free-energy approximations and generalized

belief propagation algorithms. Trans. on Information Theory  2005.

9

,Ravi Sastry Ganti
Laura Balzano
Rebecca Willett
Geoffrey Irving
Christian Szegedy
Alexander Alemi
Niklas Een
Francois Chollet
Josef Urban