2018,A General Method for Amortizing Variational Filtering,We introduce the variational filtering EM algorithm  a simple  general-purpose method for performing variational inference in dynamical latent variable models using information from only past and present variables  i.e. filtering. The algorithm is derived from the variational objective in the filtering setting and consists of an optimization procedure at each time step. By performing each inference optimization procedure with an iterative amortized inference model  we obtain a computationally efficient implementation of the algorithm  which we call amortized variational filtering. We present experiments demonstrating that this general-purpose method improves inference performance across several recent deep dynamical latent variable models.,A General Method for

Amortizing Variational Filtering

Joseph Marino  Milan Cvitkovic  Yisong Yue

California Institute of Technology

{jmarino  mcvitkovic  yyue}@caltech.edu

Abstract

We introduce the variational ﬁltering EM algorithm  a simple  general-purpose
method for performing variational inference in dynamical latent variable models
using information from only past and present variables  i.e. ﬁltering. The algorithm
is derived from the variational objective in the ﬁltering setting and consists of an op-
timization procedure at each time step. By performing each inference optimization
procedure with an iterative amortized inference model  we obtain a computationally
efﬁcient implementation of the algorithm  which we call amortized variational
ﬁltering. We present experiments demonstrating that this general-purpose method
improves performance across several deep dynamical latent variable models.

1

Introduction

Complex tasks with time-series data  like audio comprehension or robotic manipulation  must often
be performed online  where the model can only consider past and present information. Models for
such tasks  e.g. Hidden Markov Models  frequently operate by inferring the hidden state of the world
at each time-step. This type of online inference procedure is known as ﬁltering. Learning ﬁltering
models purely through supervised labels or rewards can be impractical  requiring massive collections
of labeled data or signiﬁcant efforts at reward shaping. In contrast  generative models can learn
and infer hidden structure and states directly from data. Deep latent variable models [18  27  37] 
in particular  offer a promising direction; they infer latent representations using expressive deep
networks  commonly using variational methods to perform inference [24]. Recent works have
extended deep latent variable models to the time-series setting  e.g. [7  12]. However  inference
procedures for these dynamical models have been proposed on the basis of intuition rather than from
a rigorous inference optimization perspective  potentially limiting performance.
We introduce variational ﬁltering EM  an algorithm for performing ﬁltering variational inference and
learning that is rigorously derived from the variational objective. As detailed below  the variational
objective in the ﬁltering setting results in a sequence of inference optimization objectives  with
one at each time-step. By initializing each of these inference optimization procedures from the
corresponding prior distribution  a classic Bayesian prediction-update loop naturally emerges. This
contrasts with existing ﬁltering approaches for deep dynamical models  which use inference models
that do not explicitly account for prior predictions during inference. However  using iterative inference
models [32]  which overcome this limitation  we develop a computationally efﬁcient implementation
of the variational ﬁltering EM algorithm  which we refer to as amortized variational ﬁltering (AVF).
The main contributions of this paper are the variational ﬁltering EM algorithm and its amortized
implementation  AVF. This general-purpose ﬁltering algorithm is widely applicable to dynamical
latent variable models  as we demonstrate in our experiments. Moreover  the variational ﬁltering EM
algorithm is derived from the ﬁltering variational objective  providing a solid theoretical framework
for ﬁltering inference. By precisely specifying the inference optimization procedure  this method
takes a simple form compared to previous hand–designed methods. Using several deep dynamical

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

T(cid:89)

t=1

T(cid:89)

t=1

latent variable models  we demonstrate that this ﬁltering approach compares favorably against current
methods across a variety of benchmark sequence data sets.

2 Background

Section 2.1 provides the general form of a dynamical latent variable model. Section 2.2 covers
variational inference. Deep latent variable models are often trained efﬁciently by amortizing inference
optimization (Section 2.3). Applying this technique to dynamical models is non-trivial  leading many
prior works to use hand–designed amortized inference methods (Section 2.4).

2.1 Dynamical latent variable models

A sequence of T observations  x≤T   can be modeled using a dynamical latent variable model 
pθ(x≤T   z≤T )  which models the joint distribution between x≤T and a sequence of latent variables 
z≤T   with parameters θ. It is typically assumed that pθ(x≤T   z≤T ) can be factorized into conditional
joint distributions at each step  pθ(xt  zt|x<t  z<t)  which are conditioned on preceding variables.
This results in the following auto-regressive formulation:

pθ(x≤T   z≤T ) =

pθ(xt  zt|x<t  z<t) =

pθ(xt|x<t  z≤t)pθ(zt|x<t  z<t).

(1)

pθ(xt|x<t  z≤t) is the observation model  and pθ(zt|x<t  z<t) is the dynamics model  both of which
can be arbitrary functions of their conditioning variables. However  while Eq. 1 provides the general
form of a dynamical latent variable model  further assumptions about the dependency structure  e.g.
Markov  or functional forms  e.g. linear  are often necessary for tractability.

2.2 Variational inference

DKL(q(z≤T|x≤T )||p(z≤T|x≤T )) = log pθ(x≤T ) + F 

Given a model and a set of observations  we typically want to infer the posterior for each sequence 
p(z≤T|x≤T )  and learn the model parameters  θ. Inference can be performed online or ofﬂine through
Bayesian ﬁltering or smoothing respectively [38]  and learning can be performed through maximum
likelihood estimation. Unfortunately  inference and learning are intractable for all but the simplest
model classes. For non-linear functions  which are present in deep latent variable models  we must
resort to approximate inference. Variational inference [24] reformulates inference as optimization by
introducing an approximate posterior  q(z≤T|x≤T )  then minimizing the KL-divergence to the true
posterior  p(z≤T|x≤T ). To avoid evaluating p(z≤T|x≤T )  one can express the KL-divergence as
(2)
where F is the variational free energy  also referred to as the (negative) evidence lower bound or
ELBO  deﬁned as
(3)
In Eq. 2  log pθ(x≤T ) is independent of q(z≤T|x≤T )  so one can minimize the KL-divergence to
the true posterior  thereby performing approximate inference  by minimizing F w.r.t. q(z≤T|x≤T ).
Further  as KL-divergence is non-negative  Eq. 2 implies that free energy upper bounds the negative
log likelihood. Therefore  upon minimizing F w.r.t. q(z≤T|x≤T )  one can use the gradient ∇θF to
learn the model parameters. These two optimization procedures are respectively the expectation and
maximization steps of the variational EM algorithm [34]  which alternate until convergence. To scale
this algorithm  stochastic gradients can be used for both inference [35] and learning [21].

pθ(x≤T   z≤T )
q(z≤T|x≤T )

F ≡ −Eq(z≤T |x≤T )

(cid:20)

(cid:21)

.

log

2.3 Amortized variational inference

Performing inference optimization using conventional stochastic gradient descent techniques can be
computationally demanding  potentially requiring many inference iterations. To increase efﬁciency  a
separate inference model can learn to map data examples to approximate posterior estimates [8  18 
27  37]  thereby amortizing inference across examples [16]. Denoting the distribution parameters of
q as λq (e.g. Gaussian mean and variance)  standard inference models take the form

λq ← fφ(x) 

2

(4)

where the inference model is denoted as f with parameters φ. These models  though efﬁcient  have
limitations. Notably  because these models only receive the data as input  they are unable to account
for empirical priors  which occur from one latent variable to another. Such priors arise in the dynamics
of dynamical models  forming priors across time steps  as well as in hierarchical models  forming
priors across levels. Previous works have neglected to include empirical priors during inference 
attempting to overcome this limitation through heuristics  like “top-down” inference in hierarchical
models [40] and recurrent inference models in dynamical models  e.g. [7].
Iterative inference models [32] directly account for these priors  instead performing inference opti-
mization by iteratively encoding approximate posterior estimates and gradients:

λq ← fφ(λq ∇λqF).

(5)

The gradients  ∇λqF  can be estimated through black box methods [35] or the reparameterization
trick [27  37] when applicable. Analogously to learning to learn [1]  iterative inference models learn
to perform inference optimization  thereby learning to infer. Eq. 5 provides a viable encoding form
for an iterative inference model  but other forms  such as additionally encoding the data  x  can
potentially lead to faster inference convergence. Empirically  iterative inference models have also
been shown to yield improved modeling performance over comparable standard models [32].

2.4 Related work

Many deterministic deep dynamical latent variable models have been proposed for sequential data
[6  41  30  10]. While these models often capture many aspects of the data  they cannot account for the
uncertainty inherent in many domains  typically arising from partial observability of the environment.
By averaging over multi-modal distributions  these models often produce samples in regions of low
probability  e.g. blurry video frames. This inadequacy necessitates moving to probabilistic models 
which can explicitly model uncertainty to accurately capture the distribution of possible sequences.
Amortized variational inference [27  37] has enabled many recently proposed probabilistic deep
dynamical latent variable models  with applications to video [42  26  43  23  15  11  3  9  29  19] 
speech [7  12  17  22  29]  handwriting [7]  music [12]  etc. While these models differ in their
functional mappings  most fall within the general form of Eq. 1. Crucially  simply encoding the
observation at each step is insufﬁcient to accurately perform approximate inference  as the prior
can vary across steps. Thus  with each model  a hand-crafted amortized inference procedure has
been proposed. For instance  many ﬁltering inference methods re-use various components of the
generative model [7  12  15  9]  while some methods introduce separate recurrent neural networks
into the ﬁltering procedure [4  9] or encode the previous latent sample [26]. Specifying a ﬁltering
method has been an engineering effort  as we have lacked a theoretical framework.
The variational ﬁltering EM algorithm precisely speciﬁes the inference optimization procedure
implied by the ﬁltering variational objective. The main insight from this analysis is that  having drawn
approximate posterior samples at previous steps  inference becomes a local optimization  depending
only on the current prior and observation. This suggests one uniﬁed approach that explicitly performs
inference optimization at each step  replacing the current collection of custom ﬁltering methods.
When the approximate posterior at each step is initialized at the corresponding prior  this approach
entails a Bayesian prediction-update loop  with the update composed of a gradient (error) signal.
Perhaps the closest technique in the probabilistic modeling literature is the “residual" inference
method from Fraccaro et al. [12]  which updates the approximate posterior mean from the prior.
Similar ideas have been proposed on an empirical basis for deterministic models [30  20]. PredNet
[30] is a deterministic model that encodes prediction errors to perform inference. This approach is
inspired by predictive coding [36  13]  a theory from neuroscience that postulates that feedforward
pathways in sensory processing areas of the brain use prediction errors to update state estimates from
prior predictions. In turn  this theory is motivated by classical Bayesian ﬁltering [38]  which updates
the posterior from the prior using the likelihood of the prediction. For linear Gaussian models  this
manifests as the Kalman ﬁlter [25]  which uses prediction errors to perform exact inference.
Finally  several recent works have used particle ﬁltering in conjunction with amortized inference to
provide a tighter lower bound on the log likelihood for sequential data [31  33  28]. The techniques
developed here can also be applied to this tighter bound.

3

Figure 1: Variational ﬁltering EM. The diagram shows ﬁltering inference within a dynamical latent
variable model  as outlined in Algorithm 1. The central gray region depicts inference optimization
of the approximate posterior  q(zt|x≤t  z<t)  at step t  which can be initialized at or near the corre-
sponding prior  pθ(zt|x<t  z<t). Sampling from the approximate posterior generates the conditional
likelihood  pθ(xt|x<t  z≤t)  which is evaluated at the observation  xt  to calculate the reconstruction
error. This term is combined with the KL divergence between the approximate posterior and prior 
yielding the step free energy  Ft (Eq. 9). Inference optimization (E-step) involves ﬁnding the approx-
imate posterior that minimizes the step free energy terms. Learning (M-step)  which is not shown 
corresponds to updating the model parameters  θ  to minimize the total free energy  F.

3 Variational ﬁltering

Section 3.1 describes variational ﬁltering EM (Algorithm 1)  a general algorithm for performing
ﬁltering variational inference in dynamical latent variable models. In Section 3.2  we introduce a
method for amortizing inference optimization using iterative inference models.

3.1 Variational ﬁltering expectation maximization (EM)

In the ﬁltering setting  the approximate posterior at each step is conditioned only on information
from past and present variables  enabling online approximate inference. This implies a structured
approximate posterior  in which q(z≤T|x≤T ) factorizes across steps as

q(z≤T|x≤T ) =

q(zt|x≤t  z<t).

(6)

Note that the conditioning variables in each term of q denote an indirect dependence that arises
through free energy minimization and does not necessarily constitute a direct functional mapping.
Under a ﬁltering approximate posterior  the free energy (Eq. 3) can be expressed as

(see Appendix A for the derivation) where Ft is the step free energy  deﬁned as

(7)

(8)

T(cid:89)

t=1

(cid:20)

T(cid:88)

t=1

E(cid:81)t−1

F =

τ =1 q(zτ|x≤τ  z<τ ) [Ft] =

T(cid:88)

t=1

˜Ft 

(cid:21)

 

Ft ≡ −Eq(zt|x≤t z<t)

log

pθ(xt  zt|x<t  z<t)
q(zt|x≤t  z<t)

4

ModelStepstt+1InferenceOptimization(E-step)t1PriorObservationKLDivergenceInferenceReconstructionErrorGenerativeModelConditionalLikelihoodApproximatePosteriorAlgorithm 1 Variational Filtering Expectation Maximization
1: Input: observation sequence x1:T   model pθ(x1:T   z1:T )
2: ∇θF = 0
3: for t = 1 to T do
4:
5:
6:
7:
8: end for
9: θ = θ − α∇θF

initialize q(zt|x≤t  z<t)
˜Ft := Eq(z<t|x<t z<t−1) [Ft]
˜Ft
q(zt|x≤t  z<t) = arg minq
∇θF = ∇θF + ∇θ ˜Ft

(cid:46) parameter gradient
(cid:46) at/near pθ(zt|x<t  z<t)
(cid:46) inference (E-Step)

(cid:46) learning (M-Step)

and we have also deﬁned ˜Ft as the tth term in the summation. Note that with a single step  the ﬁltering
free energy reduces to the ﬁrst step free energy  thereby recovering the static case. As in this setting 
the step free energy can be re-expressed as a reconstruction term and a KL-divergence term:
Ft = −Eq(zt|x≤t z<t) [log pθ(xt|x<t  z≤t)] + DKL(q(zt|x≤t  z<t)||pθ(zt|x<t  z<t)).

(9)
The ﬁltering free energy in Eq. 7 is the sum of these step free energy terms  each of which is evaluated
according to expectations over past latent sequences. To perform ﬁltering variational inference  we
must ﬁnd the set of T terms in q(z≤T|x≤T ) that minimize the ﬁltering free energy summation.
We now describe the variational ﬁltering EM algorithm  given in Algorithm 1 and depicted in Figure
1  which optimizes Eq. 7. This algorithm sequentially optimizes each of the approximate posterior
terms to perform ﬁltering inference. Consider the approximate posterior at step t  q(zt|x≤t  z<t).
This term appears in F  either directly or in expectations  in terms t through T of the summation:

(10)

(11)

F = (cid:124)

(cid:123)(cid:122)

˜F1 + ˜F2 + ··· + ˜Ft−1 +
steps on which q(zt|x≤t  z<t) depends

(cid:122)
(cid:123)
terms in which q(zt|x≤t  z<t) appears
(cid:125)
˜Ft + ˜Ft+1 + ··· + ˜FT−1 + ˜FT .

(cid:125)(cid:124)

However  the ﬁltering setting dictates that the optimization of the approximate posterior at each step
can only condition on past and present variables  i.e. steps 1 through t. Therefore  of the T terms in
F  the only term through which we can optimize q(zt|x≤t  z<t) is the tth term:

∗

q

(zt|x≤t  z<t) = arg min
q(zt|x≤t z<t)

˜Ft.

Optimizing ˜Ft requires evaluating expectations over previous approximate posteriors. Again  because
approximate posterior estimates cannot be inﬂuenced by future variables  these past expectations
remain ﬁxed through the future. Thus  variational ﬁltering (the variational E-step) can be performed
by sequentially minimizing each Ft w.r.t. q(zt|x≤t  z<t)  holding the expectations over past variables
ﬁxed. Conveniently  once the past expectations have been evaluated  inference optimization is entirely
deﬁned by the free energy at that step.
For simple models  such as linear Gaussian models  these expectations may be computed exactly.
However  in general  the expectations must be estimated through Monte Carlo samples from q 
with inference optimization carried out using stochastic gradients [35]. As in the static setting 
we can initialize q(zt|x≤t  z<t) at (or near) the prior  pθ(zt|x<t  z<t). This yields a simple inter-
pretation: starting with q at the prior  we generate a prediction of the data through the likelihood 
pθ(xt|x<t  z≤t)  to evaluate the current step free energy. Using the approximate posterior gradient 
we then perform an inference update to the estimate of q. This resembles classical Bayesian ﬁltering 
where the posterior is updated from the prior prediction according to the likelihood of observations.
Unlike the classical setting  reconstruction and update steps are repeated until inference convergence.
After inferring an optimal approximate posterior  learning (the variational M-step) can be performed
by minimizing the total ﬁltering free energy w.r.t. the model parameters  θ. As Eq. 7 is a summation
and differentiation is a linear operation  ∇θF is the sum of contributions from each of these terms:
(12)

(cid:104)E(cid:81)t−1

(cid:105)

.

∇θF =

τ =1 q(zτ|x≤τ  z<τ ) [Ft]

T(cid:88)
t=1 ∇θ

5

Parameter gradients can be estimated online by accumulating the result from each term in the ﬁltering
free energy. The parameters are then updated at the end of the sequence. For large data sets  stochastic
estimates of parameter gradients can be obtained from a mini-batch of data examples [21].

3.2 Amortized variational ﬁltering

Performing approximate inference optimization (Algorithm 1  Line 6) with traditional techniques can
be computationally costly  requiring many iterations of gradient updates and hand-tuning of optimizer
hyper-parameters. In online settings  with large models and data sets  this may be impractical. An
alternative approach is to employ an amortized inference model  which can learn to minimize Ft w.r.t.
q(zt|x≤t  z<t) more efﬁciently at each step. Note that Ft (Eq. 8) contains pθ(xt  zt|x<t  z<t) =
pθ(xt|x<t  z≤t)pθ(zt|x<t  z<t). The prior  pθ(zt|x<t  z<t)  varies across steps  constituting the
latent dynamics. Standard inference models  which only encode xt  do not have access to the prior
and therefore cannot properly optimize q(zt|x≤t  z<t). Many inference models in the sequential
setting attempt to account for this information by including hidden states  e.g. [7  12  9]. However 
given the complexities of many generative models  it can be difﬁcult to determine how to properly
route the necessary prior information into the inference model. As a result  each dynamical latent
latent variable model has been proposed with an accompanying custom inference model set-up.
We propose a simple and general alternative method for amortizing ﬁltering inference that is agnostic
to the particular form of the generative model. Iterative inference models [32] naturally account for
the changing prior through the approximate posterior gradients. These models are thus a natural
candidate for performing inference at each step. Similar to Eq. 5  when q(zt|x≤t  z<t) is a parametric
distribution with parameters λq

t   the inference update takes the form:

λq
t ← fφ(λq

(13)
We refer to this set-up as amortized variational ﬁltering (AVF). As in Eq. 5  we note that Eq. 13
offers just one particular encoding form for an iterative inference model. For instance  xt could be
additionally encoded at each step. Marino et al. also note that in latent Gaussian models  precision-
weighted errors provide an alternative inference optimization signal [32]. There are two main beneﬁts
to using iterative inference models in the ﬁltering setting:

˜Ft).

t  ∇λq

t

inference corrections rather than re-estimating the approximate posterior at each step.

• The approximate posterior is updated from the prior  so model capacity is utilized for
• These inference models contain all of the terms necessary to perform inference optimization 
providing a simple model form that does not require any additional hidden states or inputs.

In practice  these advantages permit the use of relatively simple iterative inference models that can
perform ﬁltering inference efﬁciently and accurately. We demonstrate this in the following section.

4 Experiments

We empirically evaluate amortized variational ﬁltering using multiple deep dynamical latent Gaussian
model architectures on a variety of sequence data sets. Speciﬁcally  we use AVF to train VRNN
[7]  SRNN [12]  and SVG [9] on speech [14]  music [5]  and video [39] data. In each setting  we
compare AVF against the originally proposed ﬁltering method for the model. Diagrams of the ﬁltering
methods are shown in Figure 2. Implementations of the models are based on code provided by
the respective authors of VRNN1  SRNN2  and SVG3. Accompanying code can be found online at
github.com/joelouismarino/amortized-variational-filtering.

4.1 Experiment set-up

Iterative inference models are implemented as speciﬁed in Eq. 13  encoding the approximate posterior
parameters and their gradients at each inference iteration at each step. Following [32]  we normalize
the inputs to the inference model using layer normalization [2]. The generative models that we

1https://github.com/jych/nips2015_vrnn
2https://github.com/marcofraccaro/srnn
3https://github.com/edenton/svg

6

(a) VRNN

(b) SRNN

(c) SVG

(d) AVF

Figure 2: Filtering inference models for VRNN  SRNN  SVG  and AVF. Each diagram shows the
computational graph for inferring the approximate posterior parameters  λq  at step t. Previously
proposed methods rely on hand-crafted architectures of observations  hidden states  and latent
variables. AVF is a simple  general ﬁltering procedure that only requires the local inference gradient.

evaluate contain non-spatial latent variables  thus  we use fully-connected layers to parameterize the
inference models. Importantly  minimal effort went into engineering the inference model architectures:
across all models and data sets  we utilize the same inference model architecture for AVF. Further
details are found in Appendix B.

4.1.1 Speech modeling

Models For speech modeling  we
use VRNN and SRNN  attempting to
keep the model architectures consis-
tent with the original implementations.
The most notable difference in our im-
plementation occurs in SRNN  where
we use an LSTM rather than a GRU
as the recurrent module. As in [12] 
we anneal the KL divergence initially
during training. In both models  we
use a Gaussian output density. Un-
like [7  12  17]  which evaluate log
densities  we evaluate and report log
probabilities by integrating the out-
put density over the data discretization
window  as in modeling image pixels.
This permits comparison across differ-
ent output distributions.

Figure 3: Test data (top)  output predictions (middle)  and
reconstructions (bottom) for TIMIT using SRNN with AVF.
Sequences run from left to right. The predictions made by
the model already contain the general structure of the data.
AVF explicitly updates the approximate posterior from the
prior prediction  focusing on inference corrections rather
than re-estimation.

Data We train and evaluate on TIMIT [14]  which consists of audio recordings of 6 300 sentences
spoken by 630 individuals. As performed in [7]  we sample the audio waveforms at 16 kHz  split
the training and validation sets into half second clips  and group each sequence into bins of 200
consecutive samples. Thus  each training and validation sequence consists of 40 model steps.
Evaluation is performed on the full duration of each test sequence  averaging roughly 3 seconds.

4.1.2 Music modeling

Model We model polyphonic music using SRNN. The generative model architecture is the same as
in the speech modeling experiments  with changes in the number of layers and units to match [12].
To model the binary music notes  we use a Bernoulli output distribution. Again  we anneal the KL
divergence initially during training.

Data We use four data sets of polyphonic (MIDI) music [5]: Piano-midi.de  MuseData  JSB
Chorales  and Nottingham. Each data set contains between 100 and 1 000 songs  with each song

7

ObservationModelOutputIteration0Iteration1ModelOutput(a)

(b)

Figure 4: Improvement with inference iterations. Results are shown on the TIMIT validation set
using VRNN with AVF. (a) Average free energy per step with varying numbers of inference iterations
during training. Additional iterations tend to result in improved performance. (b) Average relative
improvement in free energy from the initial (prior) estimate at each inference iteration for a single
model. Empirically  each successive iteration provides further  smaller improvements.

between 100 to 4 000 steps. For training and validation  we break the sequences into clips of length
25  and we test on the entire test sequences.

4.1.3 Video modeling
Model Our implementation of SVG differs from the original model in that we evaluate conditional
log-likelihood under a Gaussian output density rather than mean squared output error. All other
architecture details are identical to the original model. However  [9] down-weight the KL-divergence
by a factor of 1e-6 at all steps. We instead remove this factor to use the free energy during training
and evaluation. As to be expected  this results in the model using the latent variables to a lesser extent.
We train and evaluate SVG using ﬁltering inference at all steps  rather than predicting multiple steps
into the future  as in [9].

Data We train and evaluate SVG on KTH Actions [39]  which contains 760 train / 768 val / 863
test videos of people performing various actions  each of which is between roughly 50 - 150 frames.
Frames are re-sized to 64 × 64. For training and validation  we split the data into clips of 20 frames.
4.2 Results

4.2.1 Additional Inference Iterations

The variational ﬁltering EM algorithm involves inference optimization at each step (Algorithm 1 
Line 6). AVF optimizes each approximate posterior through a model that learns to perform iterative
updates (Eq. 13). Additional inference iterations may lead to further improvement in performance
[32]. We explore this aspect on TIMIT using VRNN. In Figure 4a  we plot the average free energy
per step on validation sequences for models trained with varying numbers of inference iterations.
Figure 4b shows average relative improvement over the prior estimate for a single model trained with
8 inference iterations. We observe that training with additional inference iterations empirically leads
to improved performance (Figure 4a)  with each iteration providing diminishing improvement during
inference (Figure 4b). This aspect is distinct from many baseline ﬁltering methods  which directly
output the approximate posterior at each step.
We can also directly visualize inference improvement through the model output. Figure 3 illustrates
example reconstructions over inference iterations  using SRNN on TIMIT. At the initial inference
iteration  the approximate posterior is initialized from the prior  resulting in an output prediction.
The iterative inference model then uses the approximate posterior gradients to update the estimate 
improving the output reconstruction.

8

1248TrainingInferenceIterations1130113511401145115011551160FreeEnergyperStep(nats)0123456789InferenceIteration0510152025ImprovementinFreeEnergy(%)Table 1: Average free energy per step (in nats)
on the TIMIT speech data set for SRNN and
VRNN with the respective originally proposed
ﬁltering procedures (baselines) and with AVF.

Table 2: Average free energy per step (in nats)
on the KTH Actions video data set for SVG
with the originally proposed ﬁltering procedure
(baseline) and with AVF.

VRNN

SRNN

baseline
AVF

baseline
AVF

TIMIT

1 082
1 105

1 026
1 024

KTH Actions

SVG

baseline
AVF

15 097
11  714

Table 3: Average free energy per step (in nats) on polyphonic music data sets for SRNN with and
without AVF. Results from Fraccaro et al. [12] are provided for comparison  however  our model
implementation differs in several aspects (see Appendix B).

Piano-midi.de MuseData

JSB Chorales Nottingham

SRNN

baseline [12]
baseline
AVF

8.20
8.19
8.12

6.28
6.27
5.99

4.74
6.92
6.97

2.94
3.19
3.13

4.2.2 Quantitative Comparison

Tables 1  2  and 3 present quantitative comparisons of average ﬁltering free energy per step between
AVF (with 1 inference iteration per step) and baseline ﬁltering methods for TIMIT  KTH Actions 
and the polyphonic music data sets respectively. On TIMIT  training with AVF performs comparably
to the baseline methods for both VRNN and SRNN. We note that VRNN with AVF using 2 inference
iterations resulted in a ﬁnal test performance of 1 071 nats per step  outperforming the baseline
method. Similar results are also observed on each of the polyphonic music data sets. Again  increasing
the number of inference iterations to 5 for AVF on JSB Chorales resulted in a ﬁnal test performance
of 6.77 nats per step. AVF signiﬁcantly improves the performance of SVG on KTH Actions. We
attribute this  likely  to the absence of the KL down-weighting factor in our training objective as
compared with [9]. The baseline ﬁltering procedure seems to struggle to a greater degree than AVF.
From comparing the results above  we see that AVF is a general ﬁltering procedure that performs
well across multiple models and data sets  despite using a relatively simple inference model structure.

5 Conclusion

We introduced the variational ﬁltering EM algorithm for ﬁltering in dynamical latent variable models.
Variational ﬁltering inference can be expressed as a sequence of optimization objectives  linked
across steps through previous latent samples. Using iterative inference models to perform inference
optimization  we arrived at an efﬁcient implementation of the algorithm: amortized variational
ﬁltering. This general ﬁltering algorithm scales to large models and data sets. Numerous methods
have been proposed for ﬁltering in deep dynamical latent variable models  with each method hand–
designed for each model. The variational ﬁltering EM algorithm provides a single framework for
analyzing and constructing these methods. Amortized variational ﬁltering is a simple  theoretically-
motivated  and general ﬁltering method that we have shown performs on-par with or better than
multiple existing state-of-the-art methods.

Acknowledgments

We would like to thank Matteo Ruggero Ronchi for helpful discussions. This work was supported by
the following grants: JPL PDF 1584398  NSF 1564330  and NSF 1637598.

9

References
[1] Marcin Andrychowicz  Misha Denil  Sergio Gomez  Matthew W Hoffman  David Pfau  Tom
Schaul  and Nando de Freitas. Learning to learn by gradient descent by gradient descent. In
Advances in Neural Information Processing Systems  2016.

[2] Jimmy Lei Ba  Jamie Ryan Kiros  and Geoffrey E Hinton. Layer normalization. In NIPS Deep

Learning Symposium  2016.

[3] Mohammad Babaeizadeh  Chelsea Finn  Dumitru Erhan  Roy H Campbell  and Sergey Levine.
Stochastic variational video prediction. In International Conference on Learning Representa-
tions  2018.

[4] Justin Bayer and Christian Osendorfer. Learning stochastic recurrent networks. In NIPS 2014

Workshop on Advances in Variational Inference  2014.

[5] Nicolas Boulanger-Lewandowski  Yoshua Bengio  and Pascal Vincent. Modeling temporal
dependencies in high-dimensional sequences: Application to polyphonic music generation and
transcription. In International Conference on Machine Learning  2012.

[6] Junyoung Chung  Caglar Gulcehre  KyungHyun Cho  and Yoshua Bengio. Empirical evaluation
of gated recurrent neural networks on sequence modeling. arXiv preprint arXiv:1412.3555 
2014.

[7] Junyoung Chung  Kyle Kastner  Laurent Dinh  Kratarth Goel  Aaron C Courville  and Yoshua
Bengio. A recurrent latent variable model for sequential data. In Advances in Neural Information
Processing Systems  2015.

[8] Peter Dayan  Geoffrey E Hinton  Radford M Neal  and Richard S Zemel. The helmholtz

machine. Neural computation  7(5):889–904  1995.

[9] Emily Denton and Rob Fergus. Stochastic video generation with a learned prior. In International

Conference on Machine Learning  2018.

[10] Chelsea Finn  Ian Goodfellow  and Sergey Levine. Unsupervised learning for physical in-
teraction through video prediction. In Advances in Neural Information Processing Systems 
2016.

[11] Marco Fraccaro  Simon Kamronn  Ulrich Paquet  and Ole Winther. A disentangled recognition
and nonlinear dynamics model for unsupervised learning. In Advances in Neural Information
Processing Systems  2017.

[12] Marco Fraccaro  Søren Kaae Sønderby  Ulrich Paquet  and Ole Winther. Sequential neural
models with stochastic layers. In Advances in Neural Information Processing Systems  2016.

[13] Karl Friston. A theory of cortical responses. Philosophical Transactions of the Royal Society of

London B: Biological Sciences  360(1456):815–836  2005.

[14] J. S. Garofolo  L. F. Lamel  W. M. Fisher  J. G. Fiscus  D. S. Pallett  and N. L. Dahlgren. Darpa

timit acoustic phonetic continuous speech corpus  1993.

[15] Mevlana Gemici  Chia-Chun Hung  Adam Santoro  Greg Wayne  Shakir Mohamed  Danilo J
Rezende  David Amos  and Timothy Lillicrap. Generative temporal models with memory. arXiv
preprint arXiv:1702.04649  2017.

[16] Samuel Gershman and Noah Goodman. Amortized inference in probabilistic reasoning. In

Cognitive Science Society  volume 36  2014.

[17] Anirudh Goyal  Alessandro Sordoni  Marc-Alexandre Côté  Nan Ke  and Yoshua Bengio. Z-
forcing: Training stochastic recurrent networks. In Advances in Neural Information Processing
Systems  2017.

[18] Karol Gregor  Ivo Danihelka  Andriy Mnih  Charles Blundell  and Daan Wierstra. Deep

autoregressive networks. In International Conference on Machine Learning  2014.

10

[19] Jiawei He  Andreas Lehrmann  Joseph Marino  Greg Mori  and Leonid Sigal. Probabilistic
video generation using holistic attribute control. In European Conference on Computer Vision 
2018.

[20] Mikael Henaff  Junbo Zhao  and Yann LeCun. Prediction under uncertainty with error-encoding

networks. arXiv preprint arXiv:1711.04994  2017.

[21] Matthew D Hoffman  David M Blei  Chong Wang  and John Paisley. Stochastic variational

inference. The Journal of Machine Learning Research  14(1):1303–1347  2013.

[22] Wei-Ning Hsu  Yu Zhang  and James Glass. Unsupervised learning of disentangled and inter-
pretable representations from sequential data. In Advances in Neural Information Processing
Systems  2017.

[23] Matthew Johnson  David K Duvenaud  Alex Wiltschko  Ryan P Adams  and Sandeep R Datta.
Composing graphical models with neural networks for structured representations and fast
inference. In Advances in Neural Information Processing Systems  2016.

[24] Michael I Jordan  Zoubin Ghahramani  Tommi S Jaakkola  and Lawrence K Saul. An introduc-
tion to variational methods for graphical models. NATO ASI SERIES D BEHAVIOURAL AND
SOCIAL SCIENCES  89:105–162  1998.

[25] Rudolph Emil Kalman et al. A new approach to linear ﬁltering and prediction problems. Journal

of basic Engineering  82(1):35–45  1960.

[26] Maximilian Karl  Maximilian Soelch  Justin Bayer  and Patrick van der Smagt. Deep variational
bayes ﬁlters: Unsupervised learning of state space models from raw data. In International
Conference on Learning Representations  2017.

[27] Diederik P Kingma and Max Welling. Stochastic gradient vb and the variational auto-encoder.

In International Conference on Learning Representations  2014.

[28] Tuan Anh Le  Maximilian Igl  Tom Jin  Tom Rainforth  and Frank Wood. Auto-encoding

sequential monte carlo. In International Conference on Learning Representations  2018.

[29] Yingzhen Li and Stephan Mandt. A deep generative model for disentangled representations of

sequential data. In International Conference on Machine Learning  2018.

[30] William Lotter  Gabriel Kreiman  and David Cox. Deep predictive coding networks for video
prediction and unsupervised learning. In International Conference on Learning Representations 
2017.

[31] Chris J Maddison  John Lawson  George Tucker  Nicolas Heess  Mohammad Norouzi  Andriy
Mnih  Arnaud Doucet  and Yee Teh. Filtering variational objectives. In Advances in Neural
Information Processing Systems  2017.

[32] Joseph Marino  Yisong Yue  and Stephan Mandt. Iterative amortized inference. In International

Conference on Machine Learning  2018.

[33] Christian Naesseth  Scott Linderman  Rajesh Ranganath  and David Blei. Variational sequential

monte carlo. In International Conference on Artiﬁcial Intelligence and Statistics  2018.

[34] Radford M Neal and Geoffrey E Hinton. A view of the em algorithm that justiﬁes incremental 

sparse  and other variants. In Learning in graphical models  pages 355–368. Springer  1998.

[35] Rajesh Ranganath  Sean Gerrish  and David Blei. Black box variational inference. In Artiﬁcial

Intelligence and Statistics  2014.

[36] Rajesh PN Rao and Dana H Ballard. Predictive coding in the visual cortex: a functional
interpretation of some extra-classical receptive-ﬁeld effects. Nature neuroscience  2(1)  1999.

[37] Danilo Jimenez Rezende  Shakir Mohamed  and Daan Wierstra. Stochastic backpropagation
and approximate inference in deep generative models. In International Conference on Machine
Learning  2014.

11

[38] Simo Särkkä. Bayesian ﬁltering and smoothing  volume 3. Cambridge University Press  2013.

[39] Christian Schuldt  Ivan Laptev  and Barbara Caputo. Recognizing human actions: a local svm

approach. In International Conference on Pattern Recognition  2004.

[40] Casper Kaae Sønderby  Tapani Raiko  Lars Maaløe  Søren Kaae Sønderby  and Ole Winther.
Ladder variational autoencoders. In Advances in Neural Information Processing Systems  2016.

[41] Nitish Srivastava  Elman Mansimov  and Ruslan Salakhudinov. Unsupervised learning of video

representations using lstms. In International Conference on Machine Learning  2015.

[42] Jacob Walker  Carl Doersch  Abhinav Gupta  and Martial Hebert. An uncertain future: Forecast-
ing from static images using variational autoencoders. In European Conference on Computer
Vision  2016.

[43] Tianfan Xue  Jiajun Wu  Katherine Bouman  and Bill Freeman. Visual dynamics: Probabilistic
future frame synthesis via cross convolutional networks. In Advances in Neural Information
Processing Systems  2016.

12

,Joseph Marino
Milan Cvitkovic
Yisong Yue