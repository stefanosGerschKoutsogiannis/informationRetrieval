2018,Non-Ergodic Alternating Proximal  Augmented Lagrangian Algorithms with Optimal Rates,We develop two new non-ergodic alternating proximal augmented Lagrangian algorithms (NEAPAL) to solve a class of nonsmooth constrained convex optimization problems. Our approach relies on a novel combination of the augmented Lagrangian framework   alternating/linearization scheme  Nesterov's acceleration techniques  and adaptive strategy for parameters. Our algorithms have several new features compared to existing methods. Firstly  they have a Nesterov's acceleration step on the primal variables compared to the dual one in  several methods in the literature.
Secondly  they achieve non-ergodic optimal convergence rates under standard assumptions  i.e. an $\mathcal{O}\left(\frac{1}{k}\right)$ rate without any smoothness or strong convexity-type assumption  or an $\mathcal{O}\left(\frac{1}{k^2}\right)$ rate under only semi-strong convexity  where $k$ is the iteration counter. 
Thirdly  they preserve or have better per-iteration complexity compared to existing algorithms. Fourthly  they can be implemented in a parallel fashion.
Finally  all the parameters are adaptively updated without heuristic tuning.
We verify our algorithms on different numerical examples and compare them with some state-of-the-art methods.,Non-Ergodic Alternating Proximal Augmented
Lagrangian Algorithms with Optimal Rates

Department of Statistics and Operations Research  University of North Carolina at Chapel Hill

Address: Hanes Hall 333  UNC-Chapel Hill  NC27599  USA.

Email: quoctd@email.unc.edu

Quoc Tran-Dinh⇤

Abstract

We develop two new non-ergodic alternating proximal augmented Lagrangian algorithms
(NEAPAL) to solve a class of nonsmooth constrained convex optimization problems. Our
approach relies on a novel combination of the augmented Lagrangian framework  alter-
nating/linearization scheme  Nesterov’s acceleration techniques  and adaptive strategy for
parameters. Our algorithms have several new features compared to existing methods. Firstly 
they have a Nesterov’s acceleration step on the primal variables compared to the dual one in
several methods in the literature. Secondly  they achieve non-ergodic optimal convergence

rates under standard assumptions  i.e. an O 1
convexity-type assumption  or an O 1

k rate without any smoothness or strong
k2 rate under only semi-strong convexity  where k is

the iteration counter. Thirdly  they preserve or have better per-iteration complexity compared
to existing algorithms. Fourthly  they can be implemented in a parallel fashion. Finally  all
the parameters are adaptively updated without heuristic tuning. We verify our algorithms on
different numerical examples and compare them with some state-of-the-art methods.

Introduction

1
Problem statement: We consider the following nonsmooth constrained convex problem:

(1)

F ? :=

min

z:=(x y)2RpnF (z) := f (x) +

mXi=1

gi(yi) s.t. Ax +

mXi=1

Biyi = co 
i=1 gi(yi)  and By := Pm

where f : R¯p ! R [{ +1} and gi : Rpi ! R [{ +1} are proper  closed  and convex functions;
p := ¯p + ˆp with ˆp := Pm
i=1 pi; A 2 Rn⇥¯p  Bi 2 Rn⇥pi  and c 2 Rn are given. Here  we also
deﬁne y := [y1 ···   ym] as a column vector  g(y) := Pm
i=1 Biyi. We
often assume that we do not explicitly form matrices A and Bi  but we can only compute Ax  Biyi
and their adjoints A> and B>i  for any given x  yi  and  for i = 1 ···   m.
Problem (1) is sufﬁciently general to cope with many applications in different ﬁelds including
machine learning  statistics  image/signal processing  and model predictive control. In particular  (1)
covers convex empirical risk minimization  support vector machine  LASSO-type  matrix completion 
compressive sensing problems as representative examples.
Our approach: Our approach relies on a novel combination of the augmented Lagrangian (AL)
function and other classical and new techniques. First  we use AL as a merit function. Next  we
incorporate an acceleration step (either Nesterov’s momentum [17] or Tseng’s accelerated variant
[25]) into the primal steps. Then  we alternate the augmented Lagrangian primal subproblem into x
and y. We also linearize the yi-subproblems and parallelize them to reduce per-iteration complexity.
Finally  we incorporate with an adaptive strategy proposed in [23] to derive explicit update rules for
algorithmic parameters. Our approach shares some similarities with the alternating direction method
of multipliers (ADMM) and alternating minimization algorithm (AMA) but is essentially different
from several aspects as will be discussed below.
Our contribution: Our contribution can be summarized as follows:

(a) We propose a novel algorithm called NEAPAL  Algorithm 1  to solve (1) under only
convexity and strong duality assumptions. This algorithm can be viewed as a Nesterov’s
accelerated  alternating  linearizing  and parallel proximal AL method which alternates
between x and yi  and linearizes and parallelizes the yi-subproblems.

⇤This work is partly supported by the NSF-grant  DMS-1619884  USA.

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

k-rate of this algorithm in terms of |F (zk)  F ?| and kAxk +
(b) We prove an optimal O 1
Byk  ck. Our rate achieves at the last iterate (i.e. in a non-ergodic sense)  while our
per-iteration complexity is the same or even better than existing methods.
(c) When the problem (1) is semi-strongly convex  i.e. f is non-strongly convex and g is
strongly convex  we develop a new NEAPAL variant  Algorithm 2  that achieves an optimal

O 1
k2-rate. This rate is either in a semi-ergodic (i.e. non-ergodic in x and ergodic in y)

sense or a non-ergodic sense. The non-ergodic rate just requires one more proximal operator
of g. This variant also possesses the same parallel computation feature as in Algorithm 1.
From a practical point of view  Algorithm 1 has better per-iteration complexity than ADMM and AMA
since the yi-subproblems are linearized and parallelized. This per-iteration complexity is essentially
the same as in primal-dual methods [3] when applying to solve composite convex problems with
linear operators. When f = 0  we obtain fully parallel variants of Algorithms 1 and 2 which only
require the proximal operators of gi and solve all the yi-subproblems in parallel.

ADMM method in [11]. To our best knowledge  optimal rates at the last iterate have not been

the dual step does not require averaging. Algorithm 2 only requires F to be semi-strongly convex

In terms of theory  Algorithm 1 achieves an optimal O 1
to achieve an optimal O 1
known yet in primal-dual methods such as in [3].2 The O 1

k-rate in a non-ergodic sense. Moreover 
k2-rate on the last iterate  which is weaker than that of the accelerated
k2-rate is also achieved in [29] for

accelerated ADMM  but Algorithm 2 remains essentially different from [29]. First  it combines
different acceleration schemes for x and y. Second  the convergence rate can achieve in either a
non-ergodic or semi-ergodic sense. Third  the parameters are updated explicitly.
Related work: Our algorithms developed in this paper can be cast into the framework of augmented
Lagrangian-type methods. In this context  we brieﬂy review some notable and recent works which
are most related to our methods. The augmented Lagrangian method was dated back from the work
of Powell and Hessenberg in nonlinear programming in early 1970s. It soon became a powerful
method to solve nonlinear optimization and constrained convex optimization problems. Alternatively 
alternating methods were dated back from Von Neumann’s work. Among these algorithms  AMA
and ADMM are the most popular ones. ADMM can be viewed either as the dual variant of Douglas-
Rachford’s method [8  15] or as an alternating variant of AL methods [1]. ADMM is widely used in
practice  especially in signal and image processing. [2] provides a comprehensive survey of ADMM
using in statistical learning. While the asymptotic convergence of ADMM has been long known  see 

is achieved through a gap function in the framework of variational inequality and in an ergodic sense.

k-convergence rate seems to be ﬁrst proved in [13  16]. However  such a rate in [13]
e.g.  [8]  its O 1
k-non-ergodic rate was then proved in [12]  but still on the sequence of differences
The same O 1
kwk+1  wkk2 combining both the primal and dual variables in w. Many other works also focus
on theoretical aspects of ADMM by showing its O 1
k-convergence rate in the objective residual
|F (zk)F ?| and feasibility gap kAxk+Bykck. Notable works include [6  11  20  22]. Extensions
to stochastic settings as well as multi-blocks formulations have also been intensively studied in the
literature such as [4  7]. Other researchers have attempted to optimize the rate of convergence in
certain cases such as quadratic problems or using the theory of feedback control [10  19].
In terms of algorithms  the main steps of ADMM remain the same in most of the existing research
papers. Some modiﬁcations have been made for ADMM such as relaxation [6  20  22]  or dual
acceleration [11  20]. Other extensions to Bregman distances and proximal settings remain essentially
the same as the original version  see  e.g.  [26]. Note that our algorithms can be cast into a primal-dual
method such as [3  23] rather than ADMM when solving composite problems with linear operators.

gap function or in both objective residual and constraint violation [5  6  11  13  20  22  27]. This rate
has been shown to be optimal for ADMM-type methods under only convexity and strong duality in

In terms of theory  most of existing results have shown an ergodic convergence rate of O 1
recent work [14  28]. When one function f or g is strongly convex  one can achieve O 1
ADMM variant using Nesterov’s acceleration step and showed O 1

k in either
k2 rate as
k-non-ergodic rate. This scheme

shown in [29] but it is still on an averaging sequence. A recent work in [14] proposed a linearized

is very similar to a special case of Algorithm 1. However  our scheme has a better per-iteration

2In [14]  a non-ergodic rate is obtained  but the algorithm is essentially different. However  a non-ergodic

optimal rate of ﬁrst-order methods for solving (1) was perhaps ﬁrst proved in [24].

2

u f (u) + 1

complexity than [14] since it updates yi in parallel instead of alternating as in [14]. Besides  our
analysis is much simpler than [14] which is extremely long and involves various parameters.
Paper organization: The rest of this paper is organized as follows. Section 2 recalls the dual
problem of (1) and optimality condition. It also provides a key lemma for convergence analysis.
Section 3 presents two new NEAPAL algorithms and analyzes their convergence rate. It also
considers an extension. Section 4 provides some representative numerical examples.
Notations: We work on ﬁnite dimensional spaces Rp and Rn  equipped with a standard inner
product h· ·i and norm k·k . Given a proper  closed  and convex function f  dom(f ) denotes its
domain  @f (·) is its subdifferential  f⇤(y) := supx {hy  xi  f (x)} is its Fenchel conjugate  and
proxfx := argmin
2ku  xk2 is its proximal operator  where > 0. We say that
proxf is tractably proximal if it can be computed efﬁciently in a closed form or by a polynomial
algorithm. Several tractable proximity functions can be found from the literature. We say that f
has Lf -Lipschitz gradient if it is differentiable  and its gradient rf is Lipschitz continuous with
the Lipschitz constant Lf 2 [0  +1)  f is µf -strongly convex if f (·)  µf
2 k·k 2 is convex  where
µf > 0 is its strong convexity parameter. For a given convex set X   ri (X ) denotes its relative interior.
For a given matrix A  we denote kAk its operator (or spectral) norm.
2 Duality theory  fundamental assumption  and optimality conditions
The Lagrange function associated with (1) is L(x  y  ) := f (x) + g(y)  hAx + By  c  i  where
 is the vector of Lagrange multipliers. The dual function is deﬁned as
(x y)2dom(F )nhAx + By  c  i  f (x)  g(y)o = f⇤(A>) + g⇤(B>)  hc  i 
d()
where dom(F ) := dom(f ) ⇥ dom(g)  and f⇤ and g⇤ are the Fenchel conjugates of f and g 
respectively. The dual problem of (1) is

L(x?  y?  ) L (x?  y?  ?) L (x  y  ?).

2Rnnd() ⌘ f⇤(A>) + g⇤(B>)  hc  io.

(2)
We say that a point (x?  y?  ?) 2 dom(F ) ⇥ Rn is a saddle point of the Lagrange function L if for
all (x  y) 2 dom(F )  and  2 Rn  one has
(3)
We denote by S ? := {(x?  y?  ?)} the set of saddle points of L  by Z ? := {(x?  y?)} the set of
primal components of saddle points  and by ⇤? := {?} the set of corresponding multipliers.
In this paper  we rely on the following general assumption used in any primal-dual-type method.
Assumption 2.1. Both functions f and g are proper  closed  and convex. The set of saddle points
S ? of the Lagrange function L is nonempty  and the optimal value F ? is ﬁnite and is attainable at
some (x?  y?) 2Z ?.
We assume that Assumption 2.1 holds throughout this paper without recalling it in the sequel.
The optimality condition (or the KKT condition) of (1) can be written as

d? := min

:=

max

0 2 @f (x?)  A>?  0 2 @g(y?)  B>?  and Ax? + By? = c.

Let us assume that the following Slater condition holds:

(4)

ri (dom(F )) \{ (x  y) | Ax + By = c}6 = ;.

Then  the optimality condition (4) is necessary and sufﬁcient for the strong duality of (1) and (2) to
hold  i.e.  F ? + D? = 0  and the dual solution is attainable and ⇤? is bounded  see  e.g.  [1].
In practice  we can only ﬁnd an approximation ˜z? := (˜x?  ˜y?) to z? of (1) in the following sense:
Deﬁnition 2.1. Given a tolerance " := ("p " d) > 0  we say that ˜z? := (˜x?  ˜y?) 2 dom(F ) is an
"-solution of (1) if |F (˜z?)  F ?| "p and kA˜x? + B ˜y?  ck  "d.
Let us deﬁne an augmented Lagrangian function L⇢ associated with the constrained problem (1) as
(5)
where z := (x  y)   is the corresponding multiplier  and ⇢> 0 is a penalty parameter. The following
lemma characterizes approximate solutions of (1) whose proof is in Supplementary Document A.

L⇢(z  ) := f (x) + g(y)  h  Ax + By  ci + ⇢

2 kAx + By  ck2  

3

⇢  

(6)

2⇢   1

|F (z)  F ?| maxnS⇢(z  ) + kk2

Lemma 2.1. Let S⇢(z  ) := L⇢(z  )  F ? for L⇢ deﬁned by (5). Then  for any z = (x  y) 2
dom(F ) and ? 2 ⇤?  we have
⇢k?kRdo and kAx + By  ck  Rd
where Rd := k  ?k +pk  ?k2 + 2⇢S⇢(z  ) and k  ?k2 + 2⇢S⇢(z  )  0.
Using Lemma 2.1  our goal is to generate a sequence(zk ⇢ k) such that S⇢k (zk  ˆ0) converges to

zero. In this case  we obtain zk as an approximate solution of (1) in the sense of Deﬁnition 2.1.
3 Non-Ergodic Alternating Proximal Augmented Lagrangian Algorithms
We ﬁrst propose a new primal-dual algorithm to solve nonsmooth and nonstrongly convex problems
in (1). Then  we present another variant for the semi-strongly convex case. Finally  we extend our
methods to the sum of smooth and nonsmooth objectives.
3.1 NEAPAL for nonstrongly convex case
The classical augmented Lagrangian method minimizes the augmented Lagrangian function L⇢ in
(5) over x and y altogether  which is often difﬁcult. Our methods alternate between x and y to break
the non-separability of the augmented term ⇢
2kAx + By  ck2. Therefore  at each iteration k  given
ˆzk := (ˆxk  ˆyk) 2 dom(F )  ˆk 2 Rn  ⇢k > 0  and k  0  we deﬁne the x-subproblem as
2 kx ˆxkk2o.

x2dom(f )nf (x)hˆk  Axi+ ⇢k

Sk (ˆzk  ˆk; ⇢k) := arg min

If k > 0  then (7) is well-deﬁned and has unique solution. If k = 0  then we need to assume that (7)
has optimal solution but not necessarily unique. For the y-subproblem  we linearize the augmented
term to make use of proximal operators of g. We also incorporate Nesterov’s accelerated steps [18]
into these primal subproblems. In summary  our algorithm is presented in Algorithm 1  which we call
a Non-Ergodic Alternating Proximal Augmented Lagrangian (NEAPAL) method.
Algorithm 1 (Non-Ergodic Alternating Proximal Augmented Lagrangian Algorithm (NEAPAL))
1: Initialization: Choose z0 := (x0  y0) 2 dom(F )  ˆ0 2 Rn  ⇢0 > 0  and 0  0. Set ˜z0 := z0.
2: For k := 0 to kmax perform
3:
4:
5:
6:

(Parameter update) ⌧k := 1
(Acceleration step) ˆzk := (1  ⌧k)zk + ⌧k ˜zk with z = (x  y).
(x-update) xk+1 := Sk (ˆzk  ˆk; ⇢k) by solving (7) and rk := Axk+1 + B ˆyk  c.
kˆyk
(Parallel y-update) For i = 1 to m update yk+1
(zk+1  ˆzk).
(Momentum step) ˜zk+1 := ˜zk + 1
⌧k
(Dual step) ˆk+1 := ˆk  ⌘k(A˜xk+1 + B ˜yk+1  c).
k+1k if necessary.
(-update) Choose 0  k+1  k+2

k+1  ⇢k := ⇢0(k + 1)  k := 2⇢0LB(k + 1)  and ⌘k := ⇢0
2 .

B>i (⇢krk  ˆk).

8:
9:
10: End for

2 kAx+B ˆykck2 + k

i  1

:= prox gi

(7)

7:

i

k

The parameter LB in Algorithm 1 can be chosen as LB

m maxkBik2 | 1  i  m . Moreover  we have a ﬂexibility to choose ⇢0 and 0. For exam-

ple  we can ﬁx 0 > 0 to make sure (7) is well-deﬁned. But if A = I  the identity operator  or A is
orthogonal  then we should choose 0 = 0.
Combining Step 4 and Step 7  we can show that the per-iteration complexity of Algorithm 1 is domi-
nated by the subproblem (7) at Step 5  one proximal operator of g  one matrix vector-multiplication
(Ax  By)  and one adjoint B>. Hence  the per-iteration complexity of Algorithm 1 is better than
that of standard ADMM [2]. We also observe the following additional features of Algorithm 1.

:= kBk2  or LB

:=

• Firstly  the subproblem (7) not only admits a unique solution  but it is also strongly convex.
Hence  if we use ﬁrst-order methods to solve it  then we obtain a linear convergence rate. In
particular  if A = I or A is orthonormal  then we can choose 0 = 0  and (7) reduces to the
proximal operator of f  i.e.

S0(ˆzk  ˆk; ⇢k) := proxf /⇢ kA>(c  B ˆyk  ⇢1

k

ˆk).

4

ˆk+1

:= ˆk  ⌘k

• Secondly  we directly incorporate Nesterov’s accelerated steps into the primal variables
instead of the dual one as in [11  20]. We can eliminate ˜zk  and update ˆzk+1 := zk+1 +
k+2 (zk+1  zk). In this case  the dual variable ˆk can be updated as
k

⌧kAxk+1 + Byk+1  c  (1  ⌧k)(Axk + Byk  c) .

• Fourthly  we can use different parameters i

This dual update collapses to the one in classical AL methods such as AMA and ADMM 
and their variants when ⌧k = 1 is ﬁxed in all iterations.
• Thirdly  the parameters ⇢k and k are increasingly updated with the same rate of O (k)  and
k can be increasing  decreasing  or ﬁxed. Moreover  while the penalty parameter ⇢k is
updated at each iteration  the step-size ⌘k in the dual step remains ﬁxed.
k for each yi-subproblem for i = 1 ···   m. In
• Finally  if f = 0  then we can remove the x-subproblem in Algorithm 1 to obtain a parallel
variant of this algorithm. In this case  if we use different i
k  then they can be updated as
k := 2LBi(k + 1). The convergence analysis of this variant requires some slight changes.
i
The convergence of Algorithm 1 is stated in the following theorem whose proof can be found in
Supplementary Document B.

k based on LBi := mkBik2 for each component i.

this case  we can update i

maxn⇢0R2

k-rate  i.e.  |F (zk)  F ?|O  1

0 + kˆ0k2  2Rdk?ko and kAxk + Byk  ck 

Theorem 3.1. Letzk be the sequence generated by Algorithm 1. Then  for any k  1  we have
|F (zk)  F ?|
0 := 0kx0  x?k2 + 2⇢0LBky0  y?k2 and Rd := kˆ0  ?k +qkˆ0  ?k2 + ⇢0R2
where R2
Consequently  the sequence of the last iterateszk globally converges to a solution z? of (1) at a
k and kAxk + Byk  ck O  1
k.
non-ergodic optimal O 1
3.2 NEAPAL for semi-strongly convex case
Now  we propose a new variant of Algorithm 1 that can exploit the semi-strong convexity of F .
Without loss of generality  we assume that gi is strongly convex with the convexity parameter µgi > 0
for all i = 1 ···   m. In this case g(y) =Pm
i=1 gi(yi) is also strongly convex with the parameter
µg := min{µgi | 1  i  m} > 0.
To exploit the strong convexity of g  we apply Tseng’s accelerated scheme in [25] to the y-subproblem 
while using Nesterov’s momentum idea [17] for the x-subproblem to keep the non-ergodic conver-
gence onxk . The complete algorithm is described in Algorithm 2.
1: Initialization: Choose z0 := (x0  y0) 2 dom(F )  ˆ0 2 Rn  ⇢0 2⇣0  µg

Algorithm 2 (scvx-NEAPAL for solving (1) with strongly convex objective term g)

4LBi  and 0  0.

Rd
⇢0k

2⇢0k

(8)

0.

1

 

Set ⌧0 := 1 and ˜z0 := z0.
2:
3: For k := 0 to kmax perform
4:

  k := 0  k := 2LB⇢k  and ⌘k := ⇢k⌧k
2 .

(Parameter update) Set ⇢k := ⇢0
⌧ 2
k
(Accelerated step) ˆzk := (1  ⌧k)zk + ⌧k ˜zk with z = (x  y).
(x-update) xk+1 := Sk (ˆzk  ˆk; ⇢k) by solving (7) and rk := Axk+1 + B ˆyk  c.
(x-momentum step) ˜xk+1 := ˜xk + 1
⌧k
(Parallel ˜y-update) For i = 1 to m  update ˜yk+1
(Dual step) ˆk+1 := ˆk  ⌘k(A˜xk+1 + B ˜yk+1  c).
(Parallel y-update) For i = 1 to m  update yk+1

⌧k k˜yk

(xk+1  ˆxk).

i  1

:= prox gi

⌧kk

i

using one of the following two options:

i

B>i (⇢krk  ˆk).

5:
6:
7:

8:

9:
10:

24

yk+1
i
yk+1
i

:= (1  ⌧k)yk
:= prox gi

i

i + ⌧k ˜yk+1
i  1
k + 4  ⌧k.

⇢k LBˆyk
2 ⌧kp⌧ 2

⇢kLB

B>i ⇢krk  ˆ0

(⌧-update) ⌧k+1 := 1

11:
12: End for

(Option 1: Averaging step)
(Option 2: Proximal step).

5

The parameter LB is chosen as in Algorithm 1  and µg := min{µgi | 1  i  m} in Algorithm
4LBi | 1  i  mo  where
2. We can replace the choice of ⇢ in Algorithm 2 by 0 <⇢ 0  minn µgi
LBi := kBik2. Before analyzing the convergence of Algorithm 2  we make the following remarks:
(a) Firstly  Algorithm 2 linearizes the y-subproblem to reduce the per-iteration complexity. This
step relies on Tseng’s accelerated variant in [25] instead of Nesterov’s optimal scheme [17]
as in Algorithm 1. Hence  it uses two different options at Step 10 to form yk+1.

(b) Secondly  if yk+1 is updated using Option 1  then one can take a weighted averaging step
on yk without incurring extra cost. The Option 2 at Step 10 requires one additional proxg
but can avoid averaging on yk as in Option 1.

(c) Thirdly  we can eliminate all parameters k  k  and ⌘k in Algorithm 2 so that it has only

two parameters ⌧k and ⇢0 that need to be updated and initialized  respectively.

The following theorem proves convergence of Algorithm 2 (cf. Supplementary Document D).
Theorem 3.2. Assume that gi is µgi-strongly convex with µgi > 0 for all i = 1 ···   m  but f is not
necessarily strongly convex. Letzk be generated by Algorithm 2. Then  the following bounds hold:
0 + kˆ0k2  2Rdk?ko and kAxk + Byk  ck  4Rd
|F (zk)  F ?|
0 := 0kx0x?k2 + 2⇢0LBky0y?k2 and Rd := kˆ0?k +qkˆ0?k2 + 2⇢0R2
where R2
k2-rate either in a semi-ergodic sense (i.e.

non-ergodic in xk and ergodic in yk) if Option 1 is chosen  or a non-ergodic sense if Option 2 is

⇢0(k+1)2n⇢0R2

⇢0(k+1)2   (9)

0.

2

3.3 Extension to the sum of smooth and nonsmooth objective functions

k2 and kAxk + Byk  ck O  1
k2.

Consequently zk globally converges to z? at O 1
chosen  i.e.  |F (zk)  F ?|O  1
We can consider (1) with F (z) := f (x) + ˆf (x) +Pm
x nf (x)+hr ˆf (ˆxk)A>ˆk  x ˆxki+ ⇢k
8><>:
yi ngi(yi)+hrˆgi(ˆyk

xk+1 := argmin

:= argmin

yk+1
i

i )+B>i ⇢krk  ˆk  yi ˆyk

smooth with L ˆf - and Lˆgi-Lipschitz gradients  respectively. In this case  the x- and yi-subproblems in
Algorithm 1 can be replaced respectively by

i=1⇥gi(yi) + ˆgi(yi)⇤  where ˆf and ˆgi are
2 kx ˆxkk2o 
2 kAx+B ˆykck2+ ˆk
i k2o 
2 kyi ˆyk

i i+

ˆi
k

F ? := min

k := kLBi + Lˆgi for i = 1 ···   m. We can also modify Algorithm

where ˆk := kLA + L ˆf and ˆi
2 and its convergence guarantee to handle this case  but we omit the details here.
4 Numerical experiments
We provide some numerical examples to illustrate our algorithms. More examples can be found in
Supplementary Document E. All the experiments are implemented in Matlab R2014b  running on a
MacBook Pro. Retina  2.7GHz Intel Core i5 with 16Gb RAM.
4.1 Square-root LASSO and Square-root Elastic-net
We consider the following square-root elastic-net problem as a modiﬁcation of the model in [30]:

2 + 2kyk1o 

y2Rp2nF (y) := kBy  ck2 + 1

(10)
where B 2 Rn⇥ˆp  c 2 Rn  and 1  0 and 2 > 0 are two regularization parameters. If 1 = 0 
then (10) reduces to the well-known square-root LASSO model which is fully nonsmooth.
Square-root LASSO Problem: We ﬁrst compare our algorithms with state-of-the-art methods on
the square-root LASSO problem. Since this problem is fully nonsmooth and non-strongly convex 
we implement three candidates to compare: ASGARD [23] and its restarting variant  and Chambolle-
Pock’s method [3]. For ASGARD  we use the same setting as in [23]  and for Chambolle-Pock’s (CP)
method  we use step-sizes  = ⌧ = kBk1 and ✓ = 1. In Algorithm 1  we choose ⇢0 :=
kBkky0y?k
as suggested by Theorem 3.1 to trade-off the objective residual and feasibility gap  where (x?  ?) is
computed by MOSEK up to the best accuracy. In Algorithm 2  we set ⇢0 := µg
4kBk2 as suggested by
our theory  where µg := 0.1 ⇥ min(B) as a guess for the restricted strong convexity parameter.

2 kyk2

k?k

6

We generate B randomly using standard Gaussian distribution without or with 50% correlated
columns. Then  we normalize B to get unit norm columns. We generate c as c := By\ + N (0  ) 
where y\ is a s-sparse vector  and  = 0 (i.e. without noise) and  = 103 (i.e. with noise). In
square-root LASSO  we set 1 = 0 and 2 = 0.055 which gives us reasonable results close to y\.
We run these algorithms on two problem instances  where (n  p  s) = (700  2000  100)  and the results
are plotted in Figure 1. Here  NEAPAL is Algorithm 1  scvx-NEAPAL is Algorithm 2  NEAPAL-par is
the parallel variant of Algorithm 1 by setting f = 0 and g1(y1) = kBy  ck2 and g2(y2) := 2kyk1 
and ASGARD-rs is the restarting-ASGARD [23]  and avg-CP is the averaging sequence of CP.

102

100

CP-Avg

10-2

NEAPAL-par

e
l
a
c
s
-
g
o
l

n

i
-

?
F
!

)
k
y
(
F

j
?
F

j

10-4

10-6

0

CP-Avg-1

ASGARD

NEAPAL
scvx-NEAPAL

ASGARD-rs

C

h

a

m

b

o

l
l

e
-

P

k
c
o
P
-
e
l
l
o
b
m
a
h
C

o

c

k
-
1

100

200

300

400

500

Iterations

102

100

10-2

e
l
a
c
s
-
g
o
l

n

i
-

10-4

j
?
F

j

?
F
!

)
k
y
(
F

10-6

10-8

0

CP-Avg

CP-Avg-1

Chambolle-Pock-1
scvx-NEAPAL
NEAPAL-par

100

200

Iterations

Chambolle-Pock

ASGARD-rs

NEAPAL

400

500

A
S
G
A
R
D

300

Figure 1: Convergence behavior on the relative objective residuals of 6 algorithms for the square-root LASSO
problem (10) after 500 iterations. Left: Without noise; Right: With noise and 50% correlated columns.
We can observe from Figure 1 that Algorithm 1 and its parallel variant has similar performance and
are comparable with ASGARD. Algorithm 2 also performs well compared to other methods. It works
better than Chambolle-Pock’s method (CP) in early iterations  but becomes slower in late iterations.
ASGARD-rs does not perform well due to the lack of strong convexity. While the last iterate of CP
shows a great progress  its averaging sequence  where we have convergence rate guarantee is very
slow in both cases: standard case and the case where the stepsize ⌧ = 1.
Square-root Elastic-net Problems: Now  we consider the case 1 = 0.01 > 0 in (10)  which is
called the square-root elastic-net problem. Our data is generated as in square-root LASSO. In this
case  Algorithm 2 and Chambolle-Pock’s method with strong convexity are used. The results of these
algorithms and non-strongly convex variants are plotted in Figure 2.

102

100

10-2

10-4

e
l
a
c
s
g
o
l

n

i
-

?
F
!

)
k
y
(
F

j
?
F

j

10-6

10-8

10-10

CP-Avg

Chambolle-Pock

102

100

10-2

10-4

e
l
a
c
s
g
o
l

n

i
-

D
R
A
G
S
A

N

E

A

P

A

L

-

p

a

r

s
r
-
D
R
A
G
S
A

scvx-NEAPAL

?
F
!

)
k
y
(
F

j
?
F

j

10-6

N

E

A

P

A

L

0

100

200

300

400

500

Iterations

CP-Avg

NEAPAL-par

scvx-NEAPAL

Chambolle-Pock

N

E

A

P

A

L

D
R
A
G
S
A

A

S

G

A

R

D

-r

s

10-8

10-10

0

100

200

300
Iterations

400

500

Figure 2: Convergence behavior on the relative objective residuals of 6 algorithms for the square-root elastic-net
problem (10) after 500 iterations. Left: Without noise; Right: With noise and 50% correlated columns.
NEAPAL  NEAPAL-par  and scvx-NEAPAL all work well in this example. They are all comparable
with ASGARD. CP makes a slow progress in early iterations  but reaches better accuracy at the end.
ASGARD-rs is the best due to the strong convexity of the problem. However  it does not have a
theoretical guarantee. Again  the averaging sequence of CP is the slowest one.
4.2 Low-rank matrix recovery with square-root loss
We consider a low-rank matrix recovery problem with square-root loss  which can be considered as a
penalized formulation of the model in [21]:

Y 2Rm⇥qnF (Y ) := kB(Y )  ck2 + kY k⇤o 

(11)
where k·k ⇤ is a nuclear norm  B : Rm⇥q ! Rn is a linear operator  c 2 Rn is a given observed
vector  and > 0 is a penalty parameter. By letting z := (x  Y )  F (z) := kxk2 + kY k⇤ and
x + B(Y ) = c  we can reformulate (11) into (1).

F ? := min

7

To avoid complex subproblems of ADMM  we reformulate (11) into the following one:

min

x Y Znkxk2 + kZk⇤ | x + B(Y ) = c  Y  Z = 0o 

by introducing two auxiliary variables x := B(Y )  c and Z := Y . The main computation at each
iteration of ADMM includes proxk·k⇤
  B(Y )  B⇤(x)  and the solution of (I + B⇤B)(Y ) = ek  where
ek is a residual term computed at each iteration. Since B and B⇤ are given in operators  we apply a
preconditioned conjugate gradient (PCG) method to solve it. We warm-start PCG and terminate it
with a tolerance of 105 or a maximum of 30 iterations. We tune the penalty parameter ⇢ in ADMM
for our test and ﬁnd that ⇢ = 0.25 works best. We call this variant “Tuned-ADMM”.
We test 3 algorithms: Algorithm 1  ASGARD [23]  and Tuned-ADMM on 5 logo images: IBM  EPFL 
MIT  TUM  and UNC. These images are pre-processed to get low-rank forms of 45  59  6  7 and 56 
respectively. The measurement c is generated as c := B(Y \) + N (0  103 max|Y \
ij|) with Gaussian
noise  where Y \ is the original image  and B is a linear operator formed by a subsampled-FFT with
25% of sampling rate. We run 3 algorithms with 200 iterations  and the results are given in Table 1.

Table 1: The results and performance of 3 algorithms on 5 Logo images of size 256 ⇥ 256.

ASGARD [23]

Algorithm 1 (NEAPAL)

Tuned-ADMM

Name Time

Error F (Y k) PSNR rank Res Time

Error F (Y k) PSNR rank Res Time

Error F (Y k) PSNR rank Res

IBM 8.0 0.0615
EPFL 8.2 0.0830
MIT
7.9 0.0501
TUM 7.5 0.0382
UNC
8.3 0.0611

0.293 72.4
0.414 69.8
0.348 74.2
0.266 76.5
0.283 72.5

34 0.107
56 0.108
6 0.102
49 0.087
42 0.112

8.5 0.0604
8.1 0.0803
7.5 0.0485
7.6 0.0390
7.7 0.0596

0.297 72.4
0.426 69.8
0.349 74.2
0.277 76.5
0.287 72.5

34 0.107 12.7 0.0615
56 0.108 17.2 0.0830
6 0.102 15.9 0.0502
49 0.087 20.1 0.0384
42 0.112 14.7 0.0611

0.293 72.4
0.414 69.8
0.348 74.2
0.267 76.5
0.283 72.5

34 0.107
56 0.108
6 0.102
49 0.087
42 0.112

The results in Table 1 show that ASGARD and NEAPAL work well and are comparable with
Tuned-ADMM. However  NEAPAL and ASGARD are faster than ADMM due to the PCG loop
for solving the linear system. The recovered results of two images: TUM and MIT are shown in
Figure 3. Except for TUM  three algorithms produce low-rank solutions as expected  and their PSNR

Original (rank=7)

ASGARD (rank=49)

NEAPAL (rank=49)

Tuned-ADMM (rank=49)

Original (rank=6)

ASGARD (rank=6)

NEAPAL (rank=6)

Tuned-ADMM (rank=6)

Figure 3: The low-rank recovery from three algorithms on two loge images: TUM and MIT.

kY \kF

showing the relative error

(peak-signal-to-noise-ratio) is consistent. Moreover  Error:= kY kY \kF
between Y k and the original image Y \ is small in all cases.
5 Conclusion
We have proposed two novel primal-dual algorithms to solve a broad class of nonsmooth constrained
convex optimization problems that have the following features. They offer the same or better per-
iteration complexity as existing methods such as AMA or ADMM. They achieve optimal convergence
rates in non-ergodic sense (i.e.  in the last iterates) on the objective residual and feasibility violation 
which are important in sparse and low-rank optimization as well as in image processing. They can be
implemented in both sequential and parallel manner. The dual update step in Algorithms 1 and 2 can
be viewed as the dual step in relaxed augmented Lagrangian-based methods  where the step-size is
different from the penalty parameter. Our future research is to develop new variants of Algorithms
1 and 2 such as coordinate descent  stochastic primal-dual  and asychronous parallel algorithms.
We also plan to investigate connection of our methods to primal-dual ﬁrst-order methods such as
primal-dual hybrid gradient and projective and other splitting methods.

8

6. D. Davis and W. Yin. Faster convergence rates of relaxed Peaceman-Rachford and ADMM under regularity

7. W. Deng  M.-J. Lai  Z. Peng  and W. Yin. Parallel multi-block ADMM with o(1/k) convergence. J.

25(3):1760–1786  2015.

assumptions. Math. Oper. Res.  2014.

Scientiﬁc Computing  71(2): 712–736  2017.

References
1. Dimitri P. Bertsekas. Constrained Optimization and Lagrange Multiplier Methods. Athena Scientiﬁc  1996.
2. S. Boyd  N. Parikh  E. Chu  B. Peleato  and J. Eckstein. Distributed optimization and statistical learning via
the alternating direction method of multipliers. Found. and Trends in Machine Learning  3(1):1–122  2011.
3. A. Chambolle and T. Pock. A ﬁrst-order primal-dual algorithm for convex problems with applications to

imaging. J. Math. Imaging Vis.  40(1):120–145  2011.

4. C. Chen  B. He  Y. Ye  and X. Yuan. The direct extension of ADMM for multi-block convex minimization

problems is not necessarily convergent. Math. Program.  155(1-2):57–79  2016.

5. D. Davis. Convergence rate analysis of the forward-Douglas-Rachford splitting scheme. SIAM J. Optim. 

8. J. Eckstein and D. Bertsekas. On the Douglas - Rachford splitting method and the proximal point algorithm

for maximal monotone operators. Math. Program.  55:293–318  1992.

9. J. E. Esser. Primal-dual algorithm for convex models and applications to image restoration  registration

and nonlocal inpainting. PhD Thesis  University of California  Los Angeles  Los Angeles  USA  2010.

10. E. Ghadimi  A. Teixeira  I. Shames  and M. Johansson. Optimal parameter selection for the alternating
direction method of multipliers: quadratic problems. IEEE Trans. Automat. Contr.  60(3):644–658  2015.
11. T. Goldstein  B. O’Donoghue  and S. Setzer. Fast Alternating Direction Optimization Methods. SIAM J.

Imaging Sci.  7(3):1588–1623  2012.

12. B. He and X. Yuan. On non-ergodic convergence rate of Douglas–Rachford alternating direction method of

multipliers. Numerische Mathematik  130(3):567–577  2012.

13. B.S. He  M. Tao  M.H. Xu  and X.M. Yuan. Alternating directions based contraction method for generally

separable linearly constrained convex programming problems. Optimization  (to appear)  2011.

14. H. Li and Z. Lin. Accelerated Alternating Direction Method of Multipliers: an Optimal O(1/k) Nonergodic
15. P. L. Lions and B. Mercier. Splitting algorithms for the sum of two nonlinear operators. SIAM J. Num. Anal. 

Analysis. arXiv preprint arXiv:1608.06366  2016.

16:964–979  1979.

16. R.D.C. Monteiro and B.F. Svaiter. Iteration-complexity of block-decomposition algorithms and the alternat-

ing minimization augmented Lagrangian method. SIAM J. Optim.  23(1):475–507  2013.

17. Y. Nesterov. A method for unconstrained convex minimization problem with the rate of convergence

18. Y. Nesterov. Introductory lectures on convex optimization: A basic course  volume 87 of Applied Optimiza-

O(1/k2). Doklady AN SSSR  269:543–547  1983. Translated as Soviet Math. Dokl.
tion. Kluwer Academic Publishers  2004.

19. R. Nishihara  L. Lessard  B. Recht  A. Packard  and M. Jordan. A general analysis of the convergence of

ADMM. In ICML  Lille  France  pages 343–352  2015.

20. Y. Ouyang  Y. Chen  G. Lan  and E. JR. Pasiliao. An accelerated linearized alternating direction method of

multiplier. SIAM J. Imaging Sci.  8(1):644–681  2015.

21. B. Recht  M. Fazel  and P.A. Parrilo. Guaranteed minimum-rank solutions of linear matrix equations via

nuclear norm minimization. SIAM Review  52(3):471–501  2010.

22. R. Sheﬁ and M. Teboulle. On the rate of convergence of the proximal alternating linearized minimization

algorithm for convex problems. EURO J. Comput. Optim.  4(1):27–46  2016.

23. Q. Tran-Dinh  O. Fercoq  and V. Cevher. A smooth primal-dual optimization framework for nonsmooth

composite convex minimization. SIAM J. Optim.  pages 1–35  2018.

24. Q. Tran-Dinh  C. Savorgnan  and M. Diehl. Combining Lagrangian decomposition and excessive gap
smoothing technique for solving large-scale separable convex optimization problems. Compt. Optim. Appl. 
55(1):75–111  2013.

25. P. Tseng. On accelerated proximal gradient methods for convex-concave optimization. Submitted to SIAM J.

Optim  2008.

26. H. Wang and A. Banerjee. Bregman Alternating Direction Method of Multipliers. Advances in Neural

Information Processing Systems (NIPS)  pages 1–18  2013.

27. E. Wei  A. Ozdaglar  and A.Jadbabaie. A Distributed Newton Method for Network Utility Maximization.

IEEE Trans. Automat. Contr.  58(9):2162 – 2175  2011.

28. B. E. Woodworth and N. Srebro. Tight complexity bounds for optimizing composite objectives. In Advances

in neural information processing systems (NIPS)  pages 3639–3647  2016.

29. Y. Xu. Accelerated ﬁrst-order primal-dual proximal methods for linearly constrained composite convex

programming. SIAM J. Optim.  27(3):1459–1484  2017.

30. H. Zou and T. Hastie. Regularization and variable selection via the elastic net. Journal of the Royal

Statistical Society: Series B  67(2):301–320  2005.

9

,Cong Fang
Feng Cheng
Zhouchen Lin
Quoc Tran Dinh