2019,Efficient Regret Minimization Algorithm for Extensive-Form Correlated Equilibrium,Self-play methods based on regret minimization have become the state of the art for computing Nash equilibria in large two-players zero-sum extensive-form games. These methods fundamentally rely on the hierarchical structure of the players' sequential strategy spaces to construct a regret minimizer that recursively minimizes regret at each decision point in the game tree. In this paper  we introduce the first efficient regret minimization algorithm for computing extensive-form correlated equilibria in large two-player general-sum games with no chance moves. Designing such an algorithm is significantly more challenging than designing one for the Nash equilibrium counterpart  as the constraints that define the space of correlation plans lack the hierarchical structure and might even form cycles. We show that some of the constraints are redundant and can be excluded from consideration  and present an efficient algorithm that generates the space of extensive-form correlation plans incrementally from the remaining constraints. This structural decomposition is achieved via a special convexity-preserving operation that we coin scaled extension. We show that a regret minimizer can be designed for a scaled extension of any two convex sets  and that from the decomposition we then obtain a global regret minimizer. Our algorithm produces feasible iterates. Experiments show that it significantly outperforms prior approaches and for larger problems it is the only viable option.,Efﬁcient Regret Minimization Algorithm for
Extensive-Form Correlated Equilibrium∗

Gabriele Farina

Computer Science Department
Carnegie Mellon University

gfarina@cs.cmu.edu

Chun Kai Ling

Computer Science Department
Carnegie Mellon University
chunkail@cs.cmu.edu

Fei Fang

Institute for Software Research

Carnegie Mellon University

feif@cs.cmu.edu

Tuomas Sandholm

Computer Science Department  CMU

Strategic Machine  Inc.

Strategy Robot  Inc.

Optimized Markets  Inc.
sandholm@cs.cmu.edu

Abstract

Self-play methods based on regret minimization have become the state of the art
for computing Nash equilibria in large two-players zero-sum extensive-form games.
These methods fundamentally rely on the hierarchical structure of the players’
sequential strategy spaces to construct a regret minimizer that recursively minimizes
regret at each decision point in the game tree. In this paper  we introduce the ﬁrst
efﬁcient regret minimization algorithm for computing extensive-form correlated
equilibria in large two-player general-sum games with no chance moves. Designing
such an algorithm is signiﬁcantly more challenging than designing one for the Nash
equilibrium counterpart  as the constraints that deﬁne the space of correlation plans
lack the hierarchical structure and might even form cycles. We show that some of
the constraints are redundant and can be excluded from consideration  and present
an efﬁcient algorithm that generates the space of extensive-form correlation plans
incrementally from the remaining constraints. This structural decomposition is
achieved via a special convexity-preserving operation that we coin scaled extension.
We show that a regret minimizer can be designed for a scaled extension of any
two convex sets  and that from the decomposition we then obtain a global regret
minimizer. Our algorithm produces feasible iterates. Experiments show that it
signiﬁcantly outperforms prior approaches and for larger problems it is the only
viable option.

1

Introduction

In recent years  self-play methods based on regret minimization  such as counterfactual regret
minimization (CFR) [Zinkevich et al.  2007] and its faster variants [Tammelin et al.  2015; Brown
et al.  2017; Brown and Sandholm  2019a] have emerged as powerful tools for computing Nash
equilibria in large extensive-form games  and have been instrumental in several recent milestones
in poker [Bowling et al.  2015; Brown and Sandholm  2017a b; Moravˇcík et al.  2017; Brown and
Sandholm  2019b]. These methods exploit the hierarchical structure of the sequential strategy spaces
of the players to construct a regret minimizer that recursively minimizes regret locally at each decision

∗The full version of this paper is available on arXiv.

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

point in the game tree. This has inspired regret-based algorithms for other solution concepts in game
theory  such as extensive-form perfect equilibria [Farina et al.  2017]  Nash equilibrium with strategy
constraints [Farina et al.  2017  2019a b; Davis et al.  2019]  and quantal-response equilibrium [Farina
et al.  2019a].
In this paper  we give the ﬁrst efﬁcient regret-based algorithm for ﬁnding an extensive-form correlated
equilibrium (EFCE) [von Stengel and Forges  2008] in two-player general-sum games with no chance
moves. EFCE is a natural extension of the correlated equilibrium (CE) solution concept to the setting
of extensive-form games. Here  the strategic interaction of rational players is complemented by a
mediator that privately recommends behavior  but does not enforce it: it is up to the mediator to
make recommendations that the players are incentivized to follow. Designing a regret minimization
algorithm that can efﬁciently search over the space of extensive-form correlated strategies (known as
correlation plans) is signiﬁcantly more difﬁcult than designing one for Nash equilibrium. This is
because the constraints that deﬁne the space of correlation plans lack the hierarchical structure of
sequential strategy spaces and might even form cycles. Existing general-purpose regret minimization
algorithms  such as follow-the-regularized-leader [Shalev-Shwartz and Singer  2007] and mirror
descent  as well as those proposed by Gordon et al. [2008] in the context of convex games  are not
practical: they require the evaluation of proximal operators (generalized projections problems) or the
minimization of linear functions on the space of extensive-form correlation plans. In the former case 
no distance-generating function is known that can be minimized efﬁciently over this space  while in
the latter case current linear programming technology does not scale to large games  as we show in
the experimental section of this paper. The regret minimization algorithm we present in this paper
computes the next iterate in linear time in the dimension of the space of correlation plans.
We show that some of the constraints that deﬁne the polytope of correlation plans are redundant and
can be eliminated  and present an efﬁcient algorithm that generates the space of correlation plans
incrementally from the remaining constraints. This structural decomposition is achieved via a special
convexity-preserving operation that we coin scaled extension. We show that a regret minimizer can
be designed for a scaled extension of any two convex sets  and that from the decomposition we then
obtain a global regret minimizer. Experiments show that our algorithm signiﬁcantly outperforms prior
approaches—the LP-based approach [von Stengel and Forges  2008] and a very recent subgradient
descent algorithm [Farina et al.  2019c]—and for larger problems it is the only viable option.

2 Preliminaries
Extensive-form games (EFGs) are played on a game tree. Each node in the game tree belongs to
a player  who acts at that node; for the purpose of this paper  we focus on two-player games only.
Edges leaving a node correspond to actions that can be taken at that node. In order to capture private
information  the game tree is supplemented with information sets. Each node belongs to exactly one
information set  and each information set is a nonempty set of tree nodes for the same Player i  which
are the set of nodes that Player i cannot distinguish among  given what they have observed so far. We
will focus on perfect-recall EFGs  that is  EFGs where no player forgets what the player knew earlier.
We denote by I1 and I2 the sets of all information sets that belong to Player 1 and 2  respectively. All
nodes that belong to an information set I ∈ I1 ∪ I2 share the same set of available actions (otherwise
the player acting at those nodes would be able to distinguish among them); we denote by AI the set
of actions available at information set I. We deﬁne the set of sequences of Player i as the set Σi :=
{(I  a) : I ∈ Ii  a ∈ AI} ∪ {∅}  where the special element ∅ is called empty sequence. Given an in-
formation set I ∈ Ii  we denote by σ(I) the parent sequence of I  deﬁned as the last pair (I(cid:48)  a(cid:48)) ∈ Σi
encountered on the path from the root to any node v ∈ I; if no such pair
exists (that is  Player i never acts before any node v ∈ I)  we let σ(I) = ∅.
We (recursively) deﬁne a sequence τ ∈ Σi to be a descendent of sequence
τ(cid:48) ∈ Σi  denoted by τ (cid:23) τ(cid:48)  if τ = τ(cid:48) or if τ = (I  a) and σ(I) (cid:23) τ(cid:48). We
use the notation τ (cid:31) τ(cid:48) to mean τ (cid:23) τ(cid:48) ∧ τ (cid:54)= τ(cid:48). Figure 1 shows a small
example EFG; black round nodes belong to Player 1  white round nodes
belong to Player 2  action names are not shown  gray round sets deﬁne
information sets  and the numbers along the edges deﬁne concise names
for sequences (for example  ‘7’ denotes sequence (D  a) where a is the
leftmost action at D).
In the sequence-form representation [Romanovskii  1962; Koller et
Sequence-Form Strategies
al.  1996; von Stengel  1996]  a strategy for Player i is compactly represented via a vector x indexed

Figure 1: Small example.

A
1

3 4

5 6

789

789

2

B

C

D

2

x must satisfy the ‘probability mass conservation’ constraint: for all I ∈ Ii (cid:80)

by sequences σ ∈ Σi. When σ = (I  a)  the entry x[σ] ≥ 0 deﬁnes the product of the probabilities
according to which Player i takes their actions on the path from the root to information set I  up to
and including action a; furthermore  x[∅] = 1. Hence  in order to be a valid sequence-form strategy 
a∈AI x[(I  a)] =
x[σ(I)]. That is  every information sets partitions the probability mass received from the parent
sequence onto its actions. In this sense  the constraints that deﬁne the space of sequence-form
strategies naturally exhibit a hierarchical structure.

2.1 Extensive-Form Correlated Equilibria
Extensive-form correlated equilibrium (EFCE) [von Stengel and Forges  2008] is a natural extension
of the solution concept of correlated equilibrium (CE) [Aumann  1974] to extensive-form games. In
EFCE  a mediator privately reveals recommendations to the players as the game progresses. These
recommendations are incremental  in the sense that recommendations for the move to play at each
decision point of the game are revealed only if and when the decision point is reached. This is in
contrast with CE  where recommendations for the whole game are privately revealed upfront when the
game starts. Players are free to not follow the recommended moves  but once a player does not follow
a recommendation  he will not receive further recommendations. In an EFCE  the recommendations
are incentive-compatible—that is  the players are motivated to follow all recommendations. EFCE
and CE are good candidates to model strategic interactions in which intermediate forms of centralized
control can be achieved [Ashlagi et al.  2008].
In a recent preprint  Farina et al. [2019c] show that in two-player perfect-recall extensive-form games 
an EFCE that guarantees a social welfare (that is  sum of player’s utilities) at least τ is the solution to
a bilinear saddle-point problem  that is an optimization problem of the form minx∈X maxy∈Y x(cid:62)Ay 
where X and Y are convex and compact sets and A is a matrix of real numbers. In the case of
EFCE  X = Ξ is known as the polytope of correlation plans (see Section 2.2) and Y is the convex
hull of certain sequence-form strategy spaces. In general  Ξ cannot be captured by a polynomially
small set of constraints  since computing an optimal EFCE in a two-player perfect-recall game is
computationally hard [von Stengel and Forges  2008].2 However  in the special case of games with
no chance moves  this is not the case  and Ξ is the intersection of a polynomial (in the game tree
size) number of constraints  as discussed in the next subsection. In fact  most of the current paper
is devoted to studying the structure of Ξ. We will largely ignore Y  for which an efﬁcient regret
minimizer can already be built  for instance by using the theory of regret circuits [Farina et al.  2019b]
(see also Appendix A in the full paper). Similarly  we will not use any property of matrix A (except
that it can be computed and stored efﬁciently).

2.2 Polytope of Extensive-Form Correlation Plans in Games with no Chance Moves
In their seminal paper  von Stengel and Forges [2008] characterize the constraints that deﬁne the
space of extensive-form correlation plans Ξ in the case of two-player perfect-recall games with no
chance moves. The characterization makes use of the following two concepts:
Deﬁnition 1 (Connected information sets  I1 (cid:10) I2). Let I1  I2 be information sets for Player 1
and 2  respectively. We say that I1 and I2 are connected  denoted I1 (cid:10) I2  if there exist two nodes
u ∈ I1  v ∈ I2 such that u is on the path from the root to v  or v is on the path from the root to u.
Deﬁnition 2 (Relevant sequence pair  σ1 (cid:46)(cid:47) σ2). Let σ1 ∈ Σ1  σ2 ∈ Σ2. We say that (σ1  σ2) is
a relevant sequence pair  and write σ1 (cid:46)(cid:47) σ2  if either σ1 or σ2 or both is the empty sequence  or
if σ1 = (I1  a1) and σ2 = (I2  a2) and I1 (cid:10) I2. Similarly  given σ1 ∈ Σ1 and I2 ∈ I2  we say
that (σ1  I2) forms a relevant sequence-information set pair  and write σ1 (cid:46)(cid:47) I2  if σ1 = ∅ or if
σ1 = (I1  a1) and I1 (cid:10) I2 (a symmetric statement holds for I1 (cid:46)(cid:47) σ2).
Deﬁnition 3 (von Stengel and Forges [2008]). In a two-player perfect-recall extensive-form game
with no chance moves  the space Ξ of correlation plans is a convex polytope containing nonnegative
vectors indexed over relevant sequences pairs  and is deﬁned as

ξ ≥ 0 :

Ξ :=

• ξ[∅  ∅] = 1

• (cid:80)
• (cid:80)

a∈AI
a∈AJ

ξ[(I1  a)  σ2] = ξ[σ(I1)  σ2] ∀I1 ∈ I1  σ2 ∈ Σ2 s.t. I1 (cid:46)(cid:47) σ2
∀I2 ∈ I2  σ1 ∈ Σ1 s.t. σ1 (cid:46)(cid:47) I2
ξ[σ1  (I2  a)] = ξ[σ1  σ(I2)]

2A feasible EFCE can be found in theoretical polynomial time [Huang and von Stengel  2008; Huang  2011]
using the ellipsoid-against-hope algorithm [Papadimitriou and Roughgarden  2008; Jiang and Leyton-Brown 
2015]. Unfortunately  that algorithm is known to not scale beyond small games.

3

.

In particular  Ξ is the intersection of at most 1 + |I1| · |Σ2| + |Σ1| · |I2| constraints  a polynomial
number in the input game size.

2.3 Regret Minimization and Relationship with Bilinear Saddle-Point Problems

A regret minimizer is a device that supports two operations: (i) RECOMMEND  which provides
the next decision xt+1 ∈ X   where X is a nonempty  convex  and compact subset of a Euclidean
space Rn; and (ii) OBSERVELOSS  which receives/observes a convex loss function (cid:96)t that is used
to evaluate decision xt [Zinkevich  2003]. In this paper  we will consider linear loss functions 
which we represent in the form of a vector (cid:96)t ∈ Rn. A regret minimizer is an online decision
maker in the sense that each decision is made by taking into account only past decisions and their
corresponding losses. The quality metric for the regret minimizer is its cumulative regret RT   deﬁned
RT :=(cid:80)T
(cid:80)T
as the difference between the loss cumulated by the sequence of decisions x1  . . .   xT and the loss
that would have been cumulated by the best-in-hindsight time-independent decision ˆx. Formally 
t=1(cid:104)(cid:96)t  ˆx(cid:105). A ‘good’ regret minimizer has RT sublinear in T ;
this property is known as Hannan consistency. Hannan consistent regret minimizers can be used
to converge to a solution of a bilinear saddle-point problem (Section 2.1). To do so  two regret
minimizers  one for X and one for Y  are set up so that at each time t they observe loss vectors
(cid:80)T
x := −Ayt and (cid:96)t
y := A(cid:62)xt  respectively  where xt ∈ X and yt ∈ Y are the decisions output
(cid:96)t
by the two regret minimizers. A well-known folk theorem asserts that in doing so  at time T the
t=1 yt) have saddle-point gap (a standard measure
average decisions ( ¯xT   ¯yT ) := ( 1
T
of how close a point is to being a saddle-point) γ( ¯xT   ¯yT ) := max ˆx∈X ˆx(cid:62)A ¯yT − min ˆy∈Y ( ¯xT )(cid:62)A ˆy
are the cumulative regrets of the
bounded above by γ( ¯xT   ¯yT ) ≤ (RT
regret minimizers. Since the regrets grow sublinearly  γ( ¯xT   ¯yT ) → 0 as T → +∞. As discussed in
the introduction  this approach has been extremely successful in computational game theory.

t=1(cid:104)(cid:96)t  xt(cid:105) − min ˆx∈X

(cid:80)T

t=1 xt  1
T

X + RT

Y )/T where RT
X

and RT
Y

3 Scaled Extension: A Convexity-Preserving Operation for Incrementally

Constructing Strategy Spaces

In this section  we introduce a new convexity-preserving operation between two sets. We show that
it provides an alternative way of constructing the strategy space of a player in an extensive-form
game that is different from the construction based on convex hulls and Cartesian products described
by Farina et al. [2019b]. Our new construction enables one to incrementally extend the strategy
space in a top-down fashion  whereas the construction by Farina et al. [2019b] was bottom-up.
Most importantly  as we will show in Section 3.1  this new operation enables one to incrementally 
recursively construct the extensive-form correlated strategy space (again in a top-down fashion).
Deﬁnition 4. Let X and Y be nonempty  compact and convex sets  and let h : X → R+ be a
nonnegative afﬁne real function. The scaled extension of X with Y via h is deﬁned as the set

h

X

(cid:47) Y := {(x  y) : x ∈ X   y ∈ h(x)Y}.

Since we will be composing multiple scaled extensions together  it is important to verify that the
operation above not only preserves convexity  but also preserves the non-emptiness and compactness
of the sets (a proof of the following Lemma is available in Appendix B in the full paper):
Lemma 1. Let X  Y and h be as in Deﬁnition 4. Then X
3.1 Construction of the Set of Sequence-Form Strategies

(cid:47) Y is nonempty  compact and convex.

h

The scaled extension operation can be used to construct the polytope of a perfect-recall player’s
strategy in sequence-form in an extensive-form game. We illustrate the approach in the small example
of Figure 1; the generalization to any extensive-form strategy space is immediate. As noted in
Section 2  any valid sequence-form strategy must satisfy probability mass constraints  and can be
constructed incrementally in a top-down fashion  as follows (in the following we refer to the same
naming scheme as in Figure 1 for the sequences of Player 1):

i. First  the empty sequence is set to value x[∅] = 1.
ii. (Info set A) Next  the value x[∅] is partitioned into the two non-negative values x[1]+x[2] = x[∅].

4

iii. (Info set B) Next  the value x[1] is partitioned into two non-negative values x[3] + x[4] = x[1].
iv. (Info set C) Next  the value x[1] is partitioned into two non-negative values x[5] + x[6] = x[1].
v. (Info set D) Next  the value x[2] is partitioned into 3 non-negative values x[7]+x[8]+x[9] = x[2].
The incremental choices in the above recipe can be directly translated—in the same order—into set
operations by using scaled extensions  as follows:
i. First  the set of all feasible values of sequence x[∅] is the singleton X0 := {1}.
ii. Then  the set of all feasible values of (x[∅]  x[1]  x[2]) is the set X1 := X0 × ∆2 = X0 (cid:47) h1 ∆2 
where h1 is the linear function h1 : X0 (cid:51) x[∅] (cid:55)→ x[∅] (the identity function).
iii. In order to characterize the set of all feasible values of (x[∅]  . . .   x[4]) we start from X1  and
extend any element (x[∅]  x[1]  x[2]) ∈ X1 with the two sequences x[3] and x[4]  drawn from
the set {(x[3]  x[4]) ∈ R+
2 : x[3] + x[4] = x[1]} = x[1]∆2. We can express this extension using
scaled extension: X2 := X1 (cid:47) h2 ∆2  where h2 : X1 (cid:51) (x[∅]  x[1]  x[2]) (cid:55)→ x[1].
iv. Similarly  we can extend every element in X2 to include (x[5]  x[6]) ∈ x[1]∆2: in this case 
X3 := X2 (cid:47) h3 ∆2  where h3 : X2 (cid:51) (x[∅]  x[1]  x[2]  x[3]  x[4]) (cid:55)→ x[1].
v. The set of all feasible(x[∅]  ..  x[9]) is X4 :=X3 (cid:47) h4 ∆3  where h4 :X3(cid:51) (x[∅]  . . .  x[6])(cid:55)→ x[2].
Hence  the polytope of sequence-form strategies for Player 1 in Figure 1 can be expressed as
h1(cid:47) ∆2 h2(cid:47) ∆2 h3(cid:47) ∆2 h4(cid:47) ∆3  where the scaled extension operation is intended as left associative.
{1}
3.2 Regret Minimizer for Scaled Extension

h

It is always possible to construct a regret minimizer for Z = X
(cid:47) Y  where h(x) = (cid:104)a  x(cid:105) + b 
starting from a regret minimizer for X ⊆ Rm and Y ⊆ Rn. The fundamental technical insight of the
construction is that  given any vector (cid:96) = ((cid:96)x  (cid:96)y) ∈ Rm × Rn  the minimization of a linear function
(cid:9) = min
(cid:8)
(cid:9)
z (cid:55)→ (cid:104)(cid:96)  z(cid:105) over Z can be split into two separate linear minimization problems over X and Y:
y∈Y(cid:104)(cid:96)y  y(cid:105)  x(cid:11)(cid:9) + b · min
y∈Y(cid:104)(cid:96)y  y(cid:105)
x∈X
y∈Y(cid:104)(cid:96)y  y(cid:105).

(cid:8)
(cid:8)(cid:10)(cid:96)x + a · min

z∈Z (cid:104)(cid:96)  z(cid:105) = min
x∈X  y∈Y
= min
x∈X

(cid:104)(cid:96)x  x(cid:105) + h(x)(cid:104)(cid:96)y  y(cid:105)

(cid:104)(cid:96)x  x(cid:105) + h(x) min

min

Thus  it is possible to break the problem of minimizing regret over Z into two regret minimization
subproblems over X and Y (more details in Appendix C in the full paper). In particular:
be two regret minimizer over X and Y respectively  and let
Proposition 1. Let RM
denote their cumulative regret at time T . Then  Algorithm 1 provides a regret minimizer over
X   RT
RT
Y
  where h∗ := maxx∈X h(x).
Z whose cumulative regret RT
Z
Algorithm 1 Regret minimizer over the scaled extension X (cid:47) h Y.

is bounded above as RT

X + h∗RT
Y

Z ≤ RT

and RM

X

Y

Algorithm 1 can be composed recursively to construct a regret minimizer for any set that is expressed
via a chain of scaled extensions  such as the polytope of sequence-form strategies (Section 3.1) or
that of extensive-form correlation plans (Section 4). When used on the polytope of sequence-form
strategies  Algorithm 1 coincides with the CFR algorithm if all regret minimizers for the individual
simplexes in the chain of scaled extensions are implemented using the regret matching algorithm [Hart
and Mas-Colell  2000].

4 Unrolling the Structure of the Correlated Strategy Polytope

In this section  we study the combinatorial structure of the polytope of correlated strategies (Sec-
tion 2.2) of a two-player perfect-recall extensive-form game with no chance moves. The central
result of this section  Theorem 1  asserts that the correlated strategy polytope Ξ can be expressed via
a chain of scaled extensions. This matches the similar result regarding the sequence-form strategy
polytope that we discussed in Section 3.1. However  unlike the sequence-form strategy polytope  the

5

1:functionRECOMMEND()2:xt←RMX.RECOMMEND()3:yt←RMY.RECOMMEND()4:return(xt h(xt)yt)1:functionOBSERVELOSS(‘t=(‘tx ‘ty))2:yt←RMY.RECOMMEND()3:˜‘tx←‘tx+h‘ty yti·a4:RMX.OBSERVELOSS(˜‘tx)5:RMY.OBSERVELOSS(‘ty)constraints that deﬁne the correlated strategy polytope do not exhibit a natural hierarchical structure:
the constraints that deﬁne Ξ (Deﬁnition 3) are such that the same entry of the correlation plan ξ
can appear in multiple constraints  and furthermore the constraints will in general form cycles. This
makes the problem of unrolling the structure of Ξ signiﬁcantly more challenging.
The key insight is that some of the constraints that deﬁne Ξ are redundant (that is  implied by the
remaining constraints) and can therefore be safely eliminated. Our algorithm identiﬁes one such
set of redundant constraints  and removes them. The set is chosen in such a way that the remaining
constraints can be laid down in a hierarchical way that can be captured via a chain of scaled extensions.

4.1 Example

Before we delve into the technical details of the construction  we illustrate the key idea of the
algorithm in a small example. In particular  consider the small game tree of Figure 2 (left)  where we
used the same conventions as in Section 2 and Figure 1. All sequence pairs are relevant; the set of
constraints that deﬁne Ξ is shown in Figure 2 (middle).

A
1

2

B

C

1 2

3 4

 ξ[∅  ∅] = 1 

In this game  Ξ is deﬁned by the following constraints:

∀σ1 ∈ {∅  1  2} 
ξ[σ1  1] + ξ[σ1  2] = ξ[σ1  ∅]
∀σ1 ∈ {∅  1  2} 
ξ[σ1  3] + ξ[σ1  4] = ξ[σ1  ∅]
ξ[1  σ2] + ξ[2  σ2] = ξ[∅  σ2] ∀σ2 ∈ {∅  1  2  3  4}.

∅ 1
1

2

4

3

∅

1

2

2

3

4

4

3

Figure 2: (Left) Example game (Section 4.1). (Middle) Constraints that deﬁne Ξ in the example game. (Right)
Fill-in order of ξ. The cell at the intersection of row σ1 and column σ2 represents the entry ξ[σ1  σ2] of ξ.
In order to generate all possible correlation plans ξ ∈ Ξ  we proceed as follows. First  we assign
ξ[∅  ∅] = 1. Then  we partition ξ[∅  ∅] into two non-negative values (ξ[1  ∅]  ξ[2  ∅]) ∈ ξ[∅  ∅]∆2
in accordance with the constraint ξ[1  ∅] + ξ[2  ∅] = ξ[∅  ∅]. Next  using the constraints
ξ[σ1  1] + ξ[σ1  2] = ξ[σ1  ∅] and ξ[σ1  3] + ξ[σ1  4] = ξ[σ1  ∅]  we pick values (ξ[σ1  1]  ξ[σ1  2]) ∈
ξ[σ1  ∅]∆2 and (ξ[σ1  3]  ξ[σ1  4]) ∈ ξ[σ1  ∅]∆2 for σ1 ∈ {1  2}. So far  our strategy for ﬁlling the
correlation plan has been to split entries according to the information structure of the players. As
shown in Section 3.1  these steps can be expressed via scaled extension operations.
Next  we ﬁll in the four remaining entries in ξ  that is ξ[∅  σ2] for σ2 ∈ {1  2  3  4}  in accordance
with constraint ξ[1  σ2] + ξ[2  σ2] = ξ[∅  σ2]. In this step  we are not splitting any value; rather  we
ﬁll in ξ[∅  σ2] in the only possible way (that is  ξ[∅  σ2] = ξ[1  σ2] + ξ[2  σ2])  by means of a linear
combination of already-ﬁlled-in entries. This operation can be also expressed via scaled extensions 
with the singleton set {1}: {(ξ[1  σ2]  ξ[2  σ2]  ξ[∅  σ2])} = {(ξ[1  σ2]  ξ[2  σ2])} (cid:47) h{1}  where
h : (ξ[1  σ2]  ξ[2  σ2]) (cid:55)→ ξ[1  σ2] + ξ[2  σ2] (note that h respects the requirements of Deﬁnition 4).
This way  we have ﬁlled in all entries in ξ. However  only 9 out of the 11 constraints have been
taken into account in the construction  and we still need to verify that the two leftover constraints
ξ[∅  1] + ξ[∅  2] = ξ[∅  ∅] and ξ[∅  3] + ξ[∅  4] = ξ[∅  ∅] are automatically satisﬁed by our way
of ﬁlling in the entries of ξ. Luckily  this is always the case: by construction  ξ[∅  1]+ξ[∅  2] =
(ξ[1  1]+ξ[1  2])+(ξ[2  1]+ξ[2  2]) = ξ[1  ∅]+ξ[2  ∅] = ξ[∅  ∅] (the proof for ξ[∅  3] + ξ[∅  4] is
analogous). We summarize the construction steps pictorially in Figure 2 (right).
Remark 1. Similar construction that starts from assigning values for ξ[∅  σ2] (σ2 ∈ {1  2  3  4}
using constraints ξ[∅  1] + ξ[∅  2] = ξ[∅  ∅]  ξ[∅  3] + ξ[∅  4] = ξ[∅  ∅] and ﬁlls out ξ[σ1  σ2] for
(σ1  σ2) ∈ {1  2}×{1  2  3  4} would have not been successful: if (ξ[1  1]  ξ[1  2]) and (ξ[1  3]  ξ[1  4])
are ﬁlled in independently  there is no way of guaranteeing that ξ[1  1] + ξ[1  2] = ξ[1  3] + ξ[1  4]
(= ξ[1  ∅]) as required by the constraints.

4.2 An Unfavorable Case that Cannot Happen in Games with No Chance Moves

We now show that there exist game instances in which the general approach used in the previous
subsection fails. In particular  consider a relevant sequence pair (σ1  σ2) such that both σ1 and σ2 are
parent sequences of two information sets of Player 1 and Player 2 respectively  and assume that all
sequence pairs in the game are relevant. Then  no matter what the order of operations is  the situation
described in Remark 1 cannot be avoided. Luckily  in two-player perfect-recall games with no chance
moves  one can prove that this occurrence never happens (see Appendix D in the full paper for a
proof):

6

(cid:10) I(cid:48)2.

Proposition 2. Consider a two-player perfect-recall game with no chance moves  and let (σ1  σ2)
be a relevant sequence pair  let I1  I(cid:48)1 be two distinct information sets of Player 1 such that σ(I1) =
σ(I(cid:48)1) = σ1  and let I2  I(cid:48)2 be two distinct information sets of Player 2 such that σ(I2) = σ(I(cid:48)2) = σ2.
It is not possible that both I1 (cid:10) I2 and I(cid:48)1
In other words  if I1 (cid:10) I2  then any pair of sequences (σ(cid:48)1  σ(cid:48)2) where σ(cid:48)1 belongs to I(cid:48)1 and σ(cid:48)2 belongs
to I(cid:48)2 is irrelevant. As we show in the next subsection  this is enough to yield a polynomial-time
algorithm to ‘unroll’ the process of ﬁlling in the entries of ξ ∈ Ξ in any two-player perfect-recall
extensive-form game with no chance moves. The following deﬁnition is crucial for that algorithm:
Deﬁnition 5. Let (σ1  σ2) be a relevant sequence pair  and let I1 ∈ I1 be an information set for
Player 1 such that σ(I1) = σ1. Information set I1 is called critical for σ2 if there exists at least one
I2 ∈ I2 with σ(I2) = σ2 such that I1 (cid:10) I2. (A symmetric deﬁnition holds for an I2 ∈ I2.)
It is a simple corollary of Proposition 2 that for any relevant sequence pair  at least one player has at
most one critical information set for the opponent’s sequence. We call such a player critical for that
relevant sequence pair.

4.3 A Polynomial-Time Algorithm that Decomposes Ξ using Scaled Extensions

In this section  we present the central result of the paper: an efﬁcient algorithm that expresses Ξ as a
chain of scaled extensions of simpler sets. In particular  as we have already seen in Section 4.1  each
set in the decomposition is either a simplex (when splitting an already-ﬁlled-in entry) or the singleton
set {1} (when summing already ﬁlled-in entries and assigning the result to a new entry of ξ).
The algorithm consists of a recursive function  DECOMPOSE  which takes three arguments: a relevant
sequence pair (σ1  σ2)  a subset S of the set of all relevant sequence pairs  and a set D of vectors with
entries indexed by the elements in S. S represents the set of indices of ξ that have already been ﬁlled
in  while D is the set of all partially-ﬁlled-in correlation plans (see Section 4.1). The decomposition for
the whole polytope Ξ is obtained by evaluating DECOMPOSE((∅  ∅) S = {(∅  ∅)} D = {(1)}) 
which corresponds to the starting situation in which only the entry ξ[∅  ∅] has been ﬁlled in (with
the value 1 as per Deﬁnition 3). Each call to DECOMPOSE returns a pair (S(cid:48) D(cid:48)) of updated
indices and partial vectors  to reﬂect the new entries that were ﬁlled in during the call. Each call to
DECOMPOSE((σ1  σ2) S D) works as follows:
• First  the algorithm ﬁnds one critical player for the relevant sequence pair (σ1  σ2) (see end of
Section 4.2). Assume without loss of generality that Player 1 is critical (the other case is symmetric) 
and let I∗ ⊆ I1 be the set of critical information sets for σ2 that belong to Player 1. By deﬁnition
of critical player  I∗ is either a singleton or it is an empty set.

• For each I ∈ I1 such that σ(I) = σ1 and I (cid:46)(cid:47) σ2  we:

– Fill in all entries {ξ[(I∗  a)  σ2] : a ∈ AI} by splitting ξ[σ1  σ2]. This is reﬂected by updating
the set of ﬁlled-in-indices S ← S ∪ {((I  a)  σ2)} and extending D via a scaled extension:
D ← D (cid:47) h ∆|AI| where h extracts ξ[σ1  σ2] from any partially-ﬁlled-in vector.
– Then  for each a ∈ AI we assign (S D) ← DECOMPOSE(((I  a)  σ2) S D).

After this step  all the indices in {(σ(cid:48)1  σ(cid:48)2) : σ(cid:48)1 (cid:31) σ1  σ(cid:48)2 (cid:23) σ2} ∪ {(σ1  σ2)} have been ﬁlled in 
and none of the indices in {(σ1  σ(cid:48)2) : σ(cid:48)2 (cid:31) σ2} have been ﬁlled in yet.
• Finally  we ﬁll out all indices in {(σ1  σ(cid:48)2) : σ(cid:48)2 (cid:31) σ2}. We do so by iterating over all information
sets J ∈ I2 such that σ(J) (cid:23) σ2 and σ1 (cid:46)(cid:47) J. For each such J  we split into two cases  according
signing its value in accordance with the constraint ξ[σ1  (J  a)] =(cid:80)
to whether I∗ = {I∗} (for some I∗ ∈ I1  as opposed to I∗ being empty) and J (cid:10) I∗  or not:
– If I∗ = {I∗} and J (cid:10) I∗  then for all a ∈ AJ we ﬁll in the sequence pair ξ[σ1  (J  a)] by as-
vector to the value of(cid:80)
a∗∈AI∗ ξ[(I∗  a∗)  (J  a)]
via the scaled extension D ← D (cid:47) h{1} where the linear function h maps a partially-ﬁlled-in
– Otherwise  we ﬁll in the entries {ξ[σ1  (J  a)] : a ∈ AJ}  by splitting the value ξ[σ1  σ(J)].
In other words  we let D ← D (cid:47) h ∆|AJ| where h extracts the entry ξ[σ1  σ(J)] from a
partially-ﬁlled-in vector in D.
• At this point  all the entries corresponding to indices ˜S = {(σ(cid:48)1  σ(cid:48)2) : σ(cid:48)1 (cid:23) σ1  σ(cid:48)2 (cid:23) σ2} have

a∗∈AI∗ ξ[(I∗  a∗)  (J  a)].

been ﬁlled in  and we return (S ∪ ˜S D).

Every call to DECOMPOSE increases the cardinality of S by at least one unit. Since S is a subset of
the set of relevant sequence pairs  and since the total number of relevant sequence pair is polynomial

7

in the input game tree size  the algorithm runs in polynomial time. See Appendix E in the full paper
for pseudocode  as well as a proof of correctness of the algorithm. Since every change to D is done
via scaled extensions (with either a simplex or the singleton set {1})  we conclude that:
Theorem 1. In a two-player perfect-recall EFG with no chance moves  the space of correlation
plans Ξ can be expressed via a sequence of scaled extensions with simplexes and singleton sets:
hn(cid:47) Xn  where  for i = 1  . . .   n  either Xi = ∆si or Xi = {1} 

h3(cid:47) ···
(1)
and hi(·) = (cid:104)ai ·(cid:105) is a linear function. Furthermore  an exact algorithm exists to compute such
expression in polynomial time.

Ξ = {1}

h1(cid:47) X1

h2(cid:47) X2

We can recursively use Algorithm 1 on the expression (1) to obtain a regret minimizer for Ξ. The
resulting algorithm  shown in Algorithm 3 of Appendix F in the full paper  is contingent on a choice of
“local” regret minimizers RMi for each of the simplex domains ∆si in (1). By virtue of Algorithm 1 
if each local regret minimizer RMi for ∆si runs in linear time (i.e.  computes recommendations and
observes losses by running an algorithm whose complexity is linear in si)3  then the overall regret
minimization algorithm for Ξ runs in linear time in the number of relevant sequence pairs of the
game. Furthermore  Proposition 1 immediately implies that if each RMi is Hannan consistent  then
so is our overall algorithm for Ξ. Putting these observations together  we conclude:
Theorem 2. For any two-player extensive-form game with no chance moves  there exists a Hannan
consistent regret minimizer for Ξ that runs in linear time in the number of relevant sequence pairs.

5 Experimental Evaluation

Board Num Ship
size
length

We experimentally evaluate the scalability of our regret-minimization algorithm for computing an
extensive-form correlated equilibrium. In particular  we implement a regret minimizer for the space
of correlation plans by computing the structural decomposition of Ξ into a chain of scaled extensions
(Section 4.3) and repeatedly applying the construction of Section 3.2. This regret minimizer is then
used on the saddle-point formulation of an EFCE (Section 2.1) as explained in Section 2.3  with
two modiﬁcations that are standard in the literature on regret minimization algorithms for game
theory [Tammelin et al.  2015; Burch et al.  2019]: (i) alternating updates and (ii) linear averaging of
the iterates4. We use regret-matching-plus [Tammelin et al.  2015] to minimize the regret over the
simplex domains in the structural decomposition. These variants are known to be beneﬁcial in the case
of Nash equilibrium  and we observed the same for EFCE. We compare our algorithm to two known
algorithms in the literature. The ﬁrst is based on linear programming [von Stengel and Forges  2008].
The second is a very recent subgradient descent algorithm
for this problem [Farina et al.  2019c]  which leverages a
recent subgradient descent technique [Wang and Bertsekas 
2013]. All algorithms were run on a machine with 16 GB
of RAM and an Intel i7 processor with 8 cores. We used
the Gurobi commercial solver (while allowing it to use
any number of threads) to solve the LP when evaluating
the scalability of the LP-based method proposed by von
Stengel and Forges [2008].
Game instances. We test the scalability of our algorithm in a benchmark game for EFCE that was
recently proposed by Farina et al. [2019b]: a parametric variant of the classical war game Battleship.
Table 1 shows some statistics about the three game instances that we use  including the number of
relevant sequence pairs in the game (Deﬁnition 2). ‘Board size’ refers to the size of the Battleship
playﬁeld; each player has a ﬁeld of that size in which to place his ship. ‘Num turns’ refers to the
maximum number of shots that each player can take (in turns). ‘Ship length’ is the length of the
one ship that each player has. Despite the seemingly small board sizes and the presence of only one
ship per player  the game trees for these instances are quite large  with each player having tens of
thousands to millions of sequences.
Scalability of the Linear Programming Approach [von Stengel and Forges  2008]. Only the
small instance could be solved by Gurobi  Figure 3 (left). (Out of the LP algorithms provided by
3Linear-time regret minimizers for simplexes include regret-matching [Hart and Mas-Colell  2000]  regret-
matching-plus [Tammelin et al.  2015]  mirror-descent and follow-the-regularized-leader (e.g  Hazan [2016]).

Table 1: Game metrics for the different
instances of the Battleship game we test on.

|Σ1|
3.89M
15k
145k
26.4M
970k 2.27M 111M

4The linear average of n vectors ξ1  . . .   ξn is ((cid:80)n

t=1 t · ξt)/((cid:80)n

t=1 t) = 2((cid:80)n

t=1 t · ξt)/(n(n + 1)).

|Σ2|
47k
306k

Num. rel.
seq. pairs

turns

(3  2)
(3  2)
(3  2)

3
4
4

1
1
2

8

Figure 3: Experimental results. The y-axis shows the maximum utility increase upon deviation.

Gurobi  the barrier method was faster than the primal- and dual-simplex methods.) On the medium
and large instance  Gurobi was killed by the system for trying to allocate too much memory. Farina
et al. [2019c] report that the large instance needs more than 500GB of memory in order for Gurobi
to run. The Gurobi run time shown in Figure 3 does not include the time needed to construct and
destruct the Gurobi LP objects  which is negligible.
Scalability of the Very Recent Subgradient Technique [Farina et al.  2019c]. The very recent
subgradient descent algorithm for this problem was able to solve the small and medium instances if
the algorithm’s step size was tuned well. An advantage of our technique is that it has no parameters
to tune. Another issue is that the iterates Ξ of the subgradient algorithm are not feasible while ours
are. Furthermore  on the large instance  the subgradient technique was already essentially unusable
because each iteration took over an hour (mainly due to computing the projection).
Figure 3 shows the experimental performance of the subgradient descent algorithm. We used a step
size of 10−3 in the small instance and of 10−6 in the medium instance. Since the iterates produced by
the subgradient technique are not feasible  extra care has to be taken when comparing the performance
of the subgradient method to that of our approach or Gurobi. Figure 5 in Appendix G in the full paper
reports the infeasibility of the iterates produced by the subgradient technique over time.
Scalability of Our Approach. We implemented the structural decomposition algorithm of Sec-
tion 4.3. Our parallel implementation using 8 threads has a runtime of 2 seconds on the small instance 
6 seconds on the medium instance  and 40 seconds on the large instance (each result was averaged
over 10 runs). Finally  we evaluated the performance of the regret minimizer constructed according
to Section 3.2; the results are in Figure 3 (left) for the small instance and Figure 3 (right) for the
medium and large instance. The plots do not include the time needed to construct and destruct the
regret minimizers in memory  which again is negligible. As expected  on the small instance  the rate
of convergence of our regret minimizer (a ﬁrst-order method) is slower than that of the barrier method
(a second-order method). However  the barrier method incurs a large overhead at the beginning  since
Gurobi spends time factorizing the constraint matrix and computing a good ordering of variables for
the elimination tree. The LP-based approach could not solve the medium or large instance  while ours
could. Even on the largest instance  no more than 2GB of memory was reserved by our algorithm.

6 Conclusions

We introduced the ﬁrst efﬁcient regret minimization algorithm for ﬁnding an extensive-form correlated
equilibrium in large two-player general-sum games with no chance moves. This is more challenging
than designing an algorithm for Nash equilibrium because the constraints that deﬁne the space of
correlation plans lack the hierarchical structure of sequential strategy spaces and might even form
cycles. We showed that some of the constraints are redundant and can be excluded from consideration 
and presented an efﬁcient algorithm that generates the space of extensive-form correlation plans
incrementally from the remaining constraints. We achieved this decomposition via a special convexity-
preserving operation that we coined scaled extension. We showed that a regret minimizer can be
designed for a scaled extension of any two convex sets  and that from the decomposition we then
obtain a global regret minimizer. Our algorithm produces feasible iterates. Experiments showed that
it signiﬁcantly outperforms prior approaches—the LP-based approach and a very recent subgradient
descent algorithm—and for larger problems it is the only viable option.

9

010020030040050060010−1010−810−610−410−2100102GurobiOursSubgradientRuntime[s]MaxdeviationSmallBattleshipinstance05001 0001 50010−410−310−210−1100Ours MediumSubgradient MediumOurs LargeRuntime[s]MaxdeviationMediumandlargeBattleshipinstanceAcknowledgments

This material is based on work supported by the National Science Foundation under grants IIS-
1718457  IIS-1617590  and CCF-1733556  and the ARO under award W911NF-17-1-0082. Gabriele
Farina is supported by a Facebook fellowship. Co-authors Ling and Fang are supported in part by a
research grant from Lockheed Martin.

References
Itai Ashlagi  Dov Monderer  and Moshe Tennenholtz. On the value of correlation. Journal of Artiﬁcial

Intelligence Research  33:575–613  2008.

Robert Aumann. Subjectivity and correlation in randomized strategies. Journal of Mathematical

Economics  1:67–96  1974.

Michael Bowling  Neil Burch  Michael Johanson  and Oskari Tammelin. Heads-up limit hold’em

poker is solved. Science  347(6218)  January 2015.

Noam Brown and Tuomas Sandholm. Safe and nested subgame solving for imperfect-information
games. In Proceedings of the Annual Conference on Neural Information Processing Systems
(NIPS)  pages 689–699  2017.

Noam Brown and Tuomas Sandholm. Superhuman AI for heads-up no-limit poker: Libratus beats

top professionals. Science  page eaao1733  Dec. 2017.

Noam Brown and Tuomas Sandholm. Solving imperfect-information games via discounted regret

minimization. In AAAI Conference on Artiﬁcial Intelligence (AAAI)  2019.

Noam Brown and Tuomas Sandholm. Superhuman AI for multiplayer poker. Science  365(6456):885–

890  2019.

Noam Brown  Christian Kroer  and Tuomas Sandholm. Dynamic thresholding and pruning for regret

minimization. In AAAI Conference on Artiﬁcial Intelligence (AAAI)  2017.

Neil Burch  Matej Moravcik  and Martin Schmid. Revisiting CFR+ and alternating updates. Journal

of Artiﬁcial Intelligence Research  64:429–443  2019.

Trevor Davis  Kevin Waugh  and Michael Bowling. Solving large extensive-form games with strategy

constraints. In AAAI Conference on Artiﬁcial Intelligence (AAAI)  2019.

Gabriele Farina  Christian Kroer  and Tuomas Sandholm. Regret minimization in behaviorally-

constrained zero-sum games. In International Conference on Machine Learning (ICML)  2017.

Gabriele Farina  Christian Kroer  and Tuomas Sandholm. Online convex optimization for sequential
decision processes and extensive-form games. In AAAI Conference on Artiﬁcial Intelligence
(AAAI)  2019.

Gabriele Farina  Christian Kroer  and Tuomas Sandholm. Regret circuits: Composabilty of regret

minimizers. In International Conference on Machine Learning (ICML)  2019.

Gabriele Farina  Chun Kai Ling  Fei Fang  and Tuomas Sandholm. Correlation in extensive-form
games: Saddle-point formulation and benchmarks. In Proceedings of the Annual Conference on
Neural Information Processing Systems (NeurIPS)  2019.

Geoffrey J Gordon  Amy Greenwald  and Casey Marks. No-regret learning in convex games. In
Proceedings of the 25th international conference on Machine learning  pages 360–367. ACM 
2008.

Sergiu Hart and Andreu Mas-Colell. A simple adaptive procedure leading to correlated equilibrium.

Econometrica  68:1127–1150  2000.

Elad Hazan. Introduction to online convex optimization. Foundations and Trends in Optimization 

2(3-4):157–325  2016.

10

Wan Huang and Bernhard von Stengel. Computing an extensive-form correlated equilibrium in
polynomial time. In International Workshop On Internet And Network Economics (WINE)  pages
506–513. Springer  2008.

Wan Huang. Equilibrium computation for extensive games. PhD thesis  London School of Economics

and Political Science  January 2011.

Albert Xin Jiang and Kevin Leyton-Brown. Polynomial-time computation of exact correlated

equilibrium in compact games. Games and Economic Behavior  91:347–359  2015.

Daphne Koller  Nimrod Megiddo  and Bernhard von Stengel. Efﬁcient computation of equilibria for

extensive two-person games. Games and Economic Behavior  14(2)  1996.

Matej Moravˇcík  Martin Schmid  Neil Burch  Viliam Lisý  Dustin Morrill  Nolan Bard  Trevor
Davis  Kevin Waugh  Michael Johanson  and Michael Bowling. Deepstack: Expert-level artiﬁcial
intelligence in heads-up no-limit poker. Science  356(6337)  May 2017.

Christos H Papadimitriou and Tim Roughgarden. Computing correlated equilibria in multi-player

games. Journal of the ACM  55(3):14  2008.

I. Romanovskii. Reduction of a game with complete memory to a matrix game. Soviet Mathematics 

3  1962.

Shai Shalev-Shwartz and Yoram Singer. A primal-dual perspective of online learning algorithms.

Machine Learning  69(2-3):115–142  2007.

Oskari Tammelin  Neil Burch  Michael Johanson  and Michael Bowling. Solving heads-up limit
Texas hold’em. In Proceedings of the 24th International Joint Conference on Artiﬁcial Intelligence
(IJCAI)  2015.

Bernhard von Stengel and Françoise Forges. Extensive-form correlated equilibrium: Deﬁnition and

computational complexity. Mathematics of Operations Research  33(4):1002–1022  2008.

Bernhard von Stengel. Efﬁcient computation of behavior strategies. Games and Economic Behavior 

14(2):220–246  1996.

Mengdi Wang and Dimitri P Bertsekas. Incremental constraint projection-proximal methods for

nonsmooth convex optimization. SIAM J. Optim.(to appear)  2013.

Martin Zinkevich  Michael Bowling  Michael Johanson  and Carmelo Piccione. Regret minimization
In Proceedings of the Annual Conference on Neural

in games with incomplete information.
Information Processing Systems (NIPS)  2007.

Martin Zinkevich. Online convex programming and generalized inﬁnitesimal gradient ascent. In
International Conference on Machine Learning (ICML)  pages 928–936  Washington  DC  USA 
2003.

11

,Bo Han
Jiangchao Yao
Gang Niu
Mingyuan Zhou
Ivor Tsang
Ya Zhang
Masashi Sugiyama
Gabriele Farina
Chun Kai Ling
Fei Fang
Tuomas Sandholm