2014,Constrained convex minimization via model-based excessive gap,We introduce a model-based excessive gap technique to analyze first-order primal- dual methods for constrained convex minimization. As a result  we construct first- order primal-dual methods with optimal convergence rates on the primal objec- tive residual and the primal feasibility gap of their iterates separately. Through a dual smoothing and prox-center selection strategy  our framework subsumes the augmented Lagrangian  alternating direction  and dual fast-gradient methods as special cases  where our rates apply.,Constrained convex minimization

via model-based excessive gap

Quoc Tran-Dinh and Volkan Cevher

´Ecole Polytechnique F´ed´erale de Lausanne (EPFL)  CH1015-Lausanne  Switzerland

Laboratory for Information and Inference Systems (LIONS)
{quoc.trandinh  volkan.cevher}@epfl.ch

Abstract

We introduce a model-based excessive gap technique to analyze ﬁrst-order primal-
dual methods for constrained convex minimization. As a result  we construct new
primal-dual methods with optimal convergence rates on the objective residual and
the primal feasibility gap of their iterates separately. Through a dual smoothing
and prox-function selection strategy  our framework subsumes the augmented La-
grangian  and alternating methods as special cases  where our rates apply.

f (cid:63) := min

Introduction

1
In [1]  Nesterov introduced a primal-dual technique  called the excessive gap  for constructing and
analyzing ﬁrst-order methods for nonsmooth and unconstrained convex optimization problems. This
paper builds upon the same idea for constructing and analyzing algorithms for the following a class
of constrained convex problems  which captures a surprisingly broad set of applications [2  3  4  5]:
(1)
where f : Rn → R∪{+∞} is a proper  closed and convex function; X ⊆ Rn is a nonempty  closed
and convex set; and A ∈ Rm×n and b ∈ Rm are given.
In the sequel  we show how Nesterov’s excessive gap relates to the smoothed gap function for a
variational inequality that characterizes the optimality condition of (1). In the light of this connec-
tion  we enforce a simple linear model on the excessive gap  and use it to develop efﬁcient ﬁrst-order
methods to numerically approximate an optimal solution x(cid:63) of (1). Then  we rigorously characterize
how the following structural assumptions on (1) affect their computational efﬁciency:
Structure 1: Decomposability. We say that problem (1) is p-decomposable if its objective function
f and its feasible set X can be represented as follows:

{f (x) : Ax = b  x ∈ X}  

x

i=1

i=1

1  . . .   p  and(cid:80)p

f (x) :=
where xi ∈ Rni  Xi ⊆ Rni  fi

(2)
: Rni → R ∪ {+∞} is proper  closed and convex for i =
i=1 ni = n. Decomposability naturally arises in machine learning applications such
as group sparsity linear recovery  consensus optimization  and the dual formulation of empirical risk
minimization problems [5]. As an important example  the composite convex minimization problem
minx1{f1(x1) + f2(Kx1)} can be cast into (1) with a 2-decomposable structure using intermediate
variables x2 = Kx1 to represent Ax = b. Decomposable structure immediately supports parallel
and distributed implementations in synchronous hardware architectures.
Structure 2: Proximal tractability. By proximal tractability  we mean that the computation of the
following operation with a given proper  closed and convex function g is “efﬁcient” (e.g.  by a closed
form solution or by polynomial time algorithms) [6]:

proxg(z) := argmin
w

(3)
When the constraint z ∈ Z is available  we consider the proximal operator of g(·) + δZ (·) instead
of g  where δZ is the indicator function of Z. Many smooth and non-smooth convex functions have
tractable proximal operators such as norms  and the projection onto a simple set [3  7  4  5].

{g(w) + (1/2)(cid:107)w − z(cid:107)2}.

(cid:88)p

(cid:89)p

fi(xi)  and X :=

Xi 

1

Scalable algorithms for (1) and their limitations. We can obtain scalable numerical solutions of
(1) when we augment the objective f with simple penalty functions on the constraints. Despite the
fundamental difﬁculties in choosing the penalty parameter  this approach enhances our computa-
tional capabilities as well as numerical robustness since we can apply modern proximal gradient 
alternating direction  and primal-dual methods. Unfortunately  existing approaches invariably fea-
ture one or both of the following two limitations:
Limitation 1: Non-ideal convergence characterizations. Ideally  the convergence rate characteriza-
tion of a ﬁrst-order algorithm for solving (1) must simultaneously establish for its iterates xk ∈ X
both on the objective residual f (xk) − f (cid:63) and on the primal feasibility gap (cid:107)Axk − b(cid:107) of its linear
constraints. The constraint feasibility is critical so that the primal convergence rate has any signif-
icance. Rates on a joint of the objective residual and feasibility gap is not necessarily meaningful
since (1) is a constrained problem and f (xk) − f (cid:63) can easily be negative at all times as compared
to the unconstrained setting  where we trivially have f (xk) − f (cid:63) ≥ 0.
Hitherto  the convergence results of state-of-the-art methods are far from ideal; see Table 1 in [28].
Most algorithms have guarantees in the ergodic sense [8  9  10  11  12  13  14] with non-optimal
rates  which diminishes the practical performance; they rely on special function properties to im-
prove convergence rates on the function and feasibility [12  15]  which reduces the scope of their
applicability; they provide rates on dual functions [16]  or a weighted primal residual and feasibility
score [13]  which does not necessarily imply convergence on the primal residual or the feasibility;
or they obtain convergence rate on the gap function value sequence composed both the primal and
dual variables via variational inequality and gap function characterizations [8  10  11]  where the
rate is scaled by a diameter parameter of the dual feasible set which is not necessary bounded.
Limitation 2: Computational inﬂexibility. Recent theoretical developments customize algorithms to
special function classes for scalability  such as convex functions with global Lipschitz gradient and
strong convexity. Unfortunately  these algorithms often require knowledge of function class param-
eters (e.g.  the Lipschitz constant and the strong convexity parameter); they do not address the full
scope of (1) (e.g.  with self-concordant [barrier] functions or fully non-smooth decompositions); and
they often have complicated algorithmic implementations with backtracking steps  which can cre-
ate computational bottlenecks. These issues are compounded by their penalty parameter selection 
which can signiﬁcantly decrease numerical efﬁciency [17]. Moreover  they lack a natural ability to
handle p-decomposability in a parallel fashion at optimal rates.
Our speciﬁc contributions. To this end  this paper addresses the question: “Is it possible to efﬁ-
ciently solve (1) using only the proximal tractability assumption with rigorous global convergence
rates on the objective residual and the primal feasibility gap?” The answer is indeed positive pro-
vided that there exists a solution in a bounded feasible set X . Surprisingly  we can still leverage
favorable function classes for fast convergence  such as strongly convex functions  and exploit p-
decomposability at optimal rates.
Our characterization is radically different from existing results  such as in [18  8  19  9  10  11  12 
13]. Speciﬁcally  we unify primal-dual methods [20  21]  smoothing (both for Bregman distances
and for augmented Lagrangian functions) [22  21]  and the excessive gap function technique [1] in
one. As a result  we develop an efﬁcient algorithmic framework for solving (1)  which covers aug-
mented Lagrangian method [23  24]  [preconditioned] alternating direction method-of-multipliers
([P]ADMM) [8] and fast dual descent methods [18] as special cases.
Based on the new technique  we establish rigorous convergence rates for a few well-known primal-
dual methods  which is optimal (in the sense of ﬁrst order black-box models [25]) given our partic-
ular assumptions. We also discuss adaptive strategies for trading-off between the objective residual
|f (xk)−f (cid:63)| and the feasibility gap (cid:107)Axk−b(cid:107)  which enhance practical performance. Finally  we
describe how strong convexity of f can be exploited  and numerically illustrate theoretical results.

2 Preliminaries
2.1. A semi-Bregman distance. Given a nonempty  closed and convex set Z ⊆ Rnz  a nonnegative 
continuous and µb-strongly convex function b is called a µb-proximity function (or prox-function)
of Z if Z ⊆ dom (b). Then zc := argminz∈Z b(z) exists and is unique  called the center point of
b. Given a smooth µb-prox-function b of Z (with µb = 1)  we deﬁne db(z  ˆz) := b(ˆz)− b(z)−
∇b(z)T (ˆz−z)  ∀z  ˆz ∈ dom (b)  as the Bregman distance between z and ˆz given b. As an example 
with b(z) := (1/2)(cid:107)z(cid:107)2

2  we have db(z  ˆz) = (1/2)(cid:107)z − ˆz(cid:107)2

2  which is the Euclidean distance.

2

In order to unify both the Bregman distance and augmented Lagrangian smoothing methods  we
introduce a new semi-Bregman distance db(Sx  Sxc) between x and xc  given matrix S. Since S is
not necessary square  we use the preﬁx “semi” for this measure. We also denote by:

DSX := sup{db(Sx  Sxc) : x  xc ∈ X} 

(4)

the semi-diameter of X . If X is bounded  then 0 ≤ DSX < +∞.
2.2. The dual problem of (1). Let L(x  y) := f (x) + yT (Ax − b) be the Lagrange function of
(1)  where y ∈ Rm is the Lagrange multipliers. The dual problem of (1) is deﬁned as:

g(cid:63) := max
y∈Rm

g(y) 

(5)

where g is the dual function  which is deﬁned as:

x∈X{f (x) + yT (Ax − b)}.

g(y) := min

(6)
For y ∈ Rm  let us denote by x(cid:63)(y) the solution of (6). Corresponding to x(cid:63)(y)  we also deﬁne the
domain of g as dom (g) := {y ∈ Rm : x(cid:63)(y) exists}. If f is continuous on X and if X is bounded 
then x(cid:63)(y) exists for all y ∈ Rm. Unfortunately  g is nonsmooth  and numerical solutions of (5)
are difﬁcult [25]. In general  we have g(y) ≤ f (x) which is the weak-duality condition in convex
optimization. To guarantee strong duality  i.e.  f (cid:63) = g(cid:63) for (1) and (5)  we need an assumption:
Assumption A. 1. The solution set X (cid:63) of (1) is nonempty. The function f is proper  closed and
convex. In addition  either X is a polytope or the Slater condition holds  i.e.: {x ∈ Rn : Ax = b}∩
relint(X ) (cid:54)= ∅  where relint(X ) is the relative interior of X .
Under Assumption A.1  the solution set Y (cid:63) of (5) is also nonempty and bounded. Moreover  the
strong duality holds  i.e.  f (cid:63) = g(cid:63). Any point (x(cid:63)  y(cid:63)) ∈ X (cid:63) × Y (cid:63) is a primal-dual solution to (1)
and (5)  and is also a saddle point of L  i.e.  L(x(cid:63)  y) ≤ L(x(cid:63)  y(cid:63)) ≤ L(x  y(cid:63)) ∀(x  y) ∈ X × Rm.
2.3. Mixed-variational inequality formulation and the smoothed gap function. We use w :=
[x  y] ∈ Rn × Rm to denote the primal-dual variable  F (w) :=
to denote a partial
Karush-Kuhn-Tucker (KKT) mapping  and W := X × Rm. Then  we can write the optimality
condition of (1) as:

(cid:20) AT y

b − Ax

(cid:21)

(7)

(8)

which is known as the mixed-variational inequality (MVIP) [26]. If we deﬁne:

f (x) − f (x(cid:63)) + F (w(cid:63))T (w − w(cid:63)) ≥ 0  ∀w ∈ W 

(cid:8)f (x(cid:63)) − f (x) + F (w(cid:63))T (w(cid:63) − w)(cid:9)  

G(w(cid:63)) := max
w∈W

then G is known as the Auslender gap function of (7) [27]. By the deﬁnition of F   we can see that:

(cid:8)f (x(cid:63)) − f (x) − (Ax − b)T y(cid:63)(cid:9) = f (x(cid:63)) − g(y(cid:63)) ≥ 0.

G(w(cid:63)) := max
[x y]∈W

It is clear that G(w(cid:63)) = 0 if and only if w(cid:63) := [x(cid:63)  y(cid:63)] ∈ W (cid:63) := X (cid:63) ×Y (cid:63)—i.e.  the strong duality.
Since G is generally nonsmooth  we strictly smooth it by adding an augmented term:

dγβ(w) ≡ dγβ(x  y) := γdb(Sx  Sxc) + (β/2)(cid:107)y(cid:107)2 

(9)
where db is a Bregman distance  S is a given matrix  and γ  β > 0 are two smoothness parameters.
The smoothed gap function for G is deﬁned as:

(cid:8)f (¯x) − f (x) + F ( ¯w)T ( ¯w − w) − dγβ(w)(cid:9)  

Gγβ( ¯w) := max
w∈W

where F is deﬁned in (7). By the deﬁnition of G and Gγβ  we can easily show that:

Gγβ( ¯w) ≤ G( ¯w) ≤ Gγβ( ¯w) + max{dγβ(w) : w ∈ W} 

which is key to develop the algorithm in the next section.
Problem (10) is convex  and its solution w(cid:63)

(cid:40)x(cid:63)

γβ( ¯w) can be computed as:

(cid:8)f (x)+yT (Ax−b)+γdb(Sx  Sxc)(cid:9)

γ(¯y) := argmin
x∈X
β(¯x) := β−1(A¯x − b).
y(cid:63)

w(cid:63)

γβ( ¯w) := [x(cid:63)

γ(¯y)  y(cid:63)

β(¯x)] ⇔

3

(10)

(11)

(12)

In this case  the following concave function:

(cid:8)f (x) + yT (Ax − b) + γdb(Sx  Sxc)(cid:9)  

gγ(y) := min
x∈X

(13)

can be considered as a smooth approximation of the dual function g deﬁned by (6).
2.4. Bregman distance smoother vs. augmented Lagrangian smoother. Depending on the choice
of S and xc  we deal with two smoothers as follows:

1. If we choose S = I  the identity matrix  and xc is then center point of b  then we obtain a
2. If we choose S = A  and xc ∈ X such that Axc = b  then we have the augmented

Bregman distance smoother.

Lagrangian smoother.

Clearly  with both smoothing techniques  the function gγ is smooth and concave. Its gradient is
Lipschitz continuous with the Lipschitz constant Lg

γ := γ−1(cid:107)A(cid:107)2 and Lg

γ := γ−1  respectively.

3 Construction and analysis of a class of ﬁrst-order primal-dual algorithms
3.1. Model-based excessive gap technique for (1). Since G(w(cid:63)) = 0 iff w(cid:63) = [x(cid:63)  y(cid:63)] is a primal-
dual optimal solution of (1)-(5). The goal is to construct a sequence { ¯wk} such that G( ¯wk) → 0 
which implies that { ¯wk} converges to w(cid:63). As suggested by (11)  if we can construct two sequences
{ ¯wk} and {(γk  βk)} such that Gγkβk ( ¯wk) → 0+ as γkβk ↓ 0+  then G( ¯wk) → 0.
Inspired by Nesterov’s excessive gap idea in [1]  we construct the following model-based excessive
gap condition for (1) in order to achieve our goal.
Deﬁnition 1 (Model-based Excessive Gap). Given ¯wk ∈ W and (γk  βk) > 0  a new point ¯wk+1 ∈
W and (γk+1  βk+1) > 0 with γk+1βk+1 < γkβk is said to reduce the primal-dual gap if:

Gk+1( ¯wk+1) ≤ (1 − τk)Gk( ¯wk) − ψk 

(14)

where Gk := Gγkβk  τk ∈ [0  1) and ψk ≥ 0.

From Deﬁnition 1  if(cid:8) ¯wk(cid:9) and {(γk  βk)} satisfy (14)  then we have Gk( ¯wk) ≤ ωkG0( ¯w0) − Ψk
by induction  where ωk :=(cid:81)k−1
Lemma 1 ([28]). Let Gγβ be deﬁned by (10). Let(cid:8) ¯wk(cid:9) ⊂ W and {(γk  βk)} ⊂ R2

(cid:81)k
i=j(1−τi)ψj−1. If G0( ¯w0) ≤ 0 
then we can bound the objective residual |f (¯xk) − f (cid:63)| and the primal feasibility (cid:107)A¯xk − b(cid:107) of (1):
++ be the

j=0 (1−τj) and Ψk := ψk +(cid:80)k

j=1

sequences that satisfy (14). Then  it holds that:

− D(cid:63)Y(cid:107)A¯xk − b(cid:107) ≤ f (¯xk) − f (cid:63) ≤ γkDSX and (cid:107)A¯xk − b(cid:107) ≤ 2βkD(cid:63)Y +

2γkβkDSX  
where D(cid:63)Y := min{(cid:107)y(cid:63)(cid:107) : y(cid:63) ∈ Y (cid:63)}  which is the norm of a minimum norm dual solutions.
Hence  we can derive algorithms based (γk  βk) with a predictable convergence rate via (15). In the
sequel  we manipulate τk and ψk to do just that in order to preserve (14) ´a la Nesterov [1]. Finally 
we say that ¯xk ∈ X is an ε-solution of (1) if |f (¯xk) − f (cid:63)| ≤ ε and (cid:107)A¯xk − b(cid:107) ≤ ε.
3.2. Initial points. We ﬁrst show how to compute an initial point w0 such that G0( ¯w0) ≤ 0.
Lemma 2 ([28]). Given xc ∈ X   ¯w0 := [¯x0  ¯y0] ∈ W is computed by:

(15)

(cid:113)

(cid:40)¯x0 = x(cid:63)

γ0
¯y0 = y(cid:63)
β0

x∈X {f (x) + (γ0/2)db(Sx  Sxc)}  

(0m) := arg min
(¯x0) := β−1

0 (A¯x0 − b).

(16)

satisﬁes Gγ0β0( ¯w0) ≤ 0 provided that β0γ0 ≥ ¯Lg  where ¯Lg is the Lipschitz constant of ∇gγ with
gγ given by (13).
3.3. An algorithmic template. Algorithm 1 combines the above ingredients for solving (1). We
observe that the key computational step of Algorithm 1 is Step 3  where we update [¯xk+1  ¯yk+1]. In
the algorithm  we provide two update schemes (1P2D) and (2P1D) based on the updates of the
primal or dual variables. The primal step x(cid:63)
(¯yk) is calculated via (12). At line 3 of (2P1D)  the
γk
operator proxS

(cid:8)f (x) + ˆyT A(x − ˆx) + β−1db(Sx  Sˆx)(cid:9)  

βf is computed as:
proxS

βf (ˆx  ˆy) := argmin
x∈X

(17)

4

0   and β0 := γ−1

0

¯Lg (c.f. the text).

2: Compute [¯x0  ¯y0] by (16) as in Lemma 2.
For k = 0 to kmax  perform the following steps:
3: If stopping criterion holds  then terminate. Otherwise  use one of the following schemes:

Algorithm 1: (A primal-dual algorithmic template using model-based excessive gap)
Inputs: Fix γ0 > 0. Choose c0∈ (−1  1].
Initialization:

1: Compute a0 := 0.5(1+c0+(cid:112)4(1−c0)+(1+c0)2  τ0 := a−1


:= (1 − τk)¯xk + τkx(cid:63)
ˆxk
k+1(Aˆxk − b)
:= β−1
ˆyk
¯xk+1 := proxS
βk+1f (ˆxk  ˆyk)
¯yk+1 := (1 − τk)¯yk + τk ˆyk.



(2P1D) :

(1P2D) :

(¯yk)

γk

k (A¯xk − b) 
:= β−1
¯y(cid:63)
:= (1 − τk)¯yk + τk ¯y(cid:63)
k
ˆyk
k 
¯xk+1 := (1−τk)¯xk +τkx(cid:63)
(ˆyk) 
¯yk+1 := ˆyk +γk

(ˆyk)−b(cid:1).

(cid:0)Ax(cid:63)

γk

γk

4: Update βk+1 := (1 − τk)βk and γk+1 := (1 − ckτk)γk. Update ck+1 from ck (optional).

5: Update ak+1 := 0.5(cid:0)1 + ck+1 +(cid:112)4a2

k + (1 − ck+1)2(cid:1) and set τk+1 := a−1

k+1.

End For

√

where we overload the notation of the proximal operator prox deﬁned by (3). At Step 2 of Algorithm
1  if we choose S := I  i.e.  db(Sx  Sxc) := db(x  xc) for xc being the center point of b  then we set
¯Lg := (cid:107)A(cid:107)2. If S := A  i.e.  db(Sx  Sxc) := (1/2)(cid:107)Ax − b(cid:107)2  then we set ¯Lg := 1.
Theorem 1 characterizes three variants of Algorithm 1  whose proof can be found in [28].

Theorem 1. Let(cid:8)(¯xk  ¯yk)(cid:9) be the sequence generated by Algorithm 1 after k iterations. Then:

¯Lg = 1  and ck := 0  then

a) If S = A  i.e.  using the augmented Lagrangian smoother  γ0 :=
the (1P2D) update satisﬁes:
(cid:107)A¯xk−b(cid:107)2−D(cid:63)Y(cid:107)A¯xk−b(cid:107) ≤ f (¯xk) − f (cid:63) ≤ 0 and (cid:107)A¯xk−b(cid:107) ≤ 8D(cid:63)Y
(1P2D) : − 1
(k + 1)2 .
2
Consequently  the worst-case complexity of Algorithm 1 to achieve an ε-solution ¯xk is O(ε−1/2).
¯Lg = (cid:107)A(cid:107)  and ck := 1  then  for
b) If S = I  i.e.  using the Bregman distance smoother  γ0 :=
the (2P1D) scheme  we have:
(2P1D) : − D(cid:63)Y(cid:107)A¯xk− b(cid:107)≤ f (¯xk) − f (cid:63) ≤ (cid:107)A(cid:107)
√
2(cid:107)A(cid:107)
c) Similarly  if γ0 := 2
K+1 and ck := 0 for all k = 0  1  . . .   K  then  for the (1P2D) scheme  we
have:

(cid:113)
Hence  the worst-case complexity to achieve an ε-solution ¯xk of (1) in either b) or c) is O(cid:0)ε−1(cid:1).

√
(1P2D) : −D(cid:63)Y(cid:107)A¯xK−b(cid:107)≤ f (¯xK)−f (cid:63) ≤ 2

X and (cid:107)A¯xK−b(cid:107)≤ 2

X and (cid:107)A¯xk− b(cid:107) ≤
I
D

(cid:107)A(cid:107)(2D(cid:63)Y +
k + 1

2(cid:107)A(cid:107)(D(cid:63)Y +
(K +1)

2(cid:107)A(cid:107)
(K +1)

(cid:113)

I
X )

k+1

√

√

2D

D

I

.

I
X )

D

.

The (1P2D) scheme has close relationship to some well-known primal dual methods we describe
below. Unfortunately  (1P2D) has the drawback of ﬁxing the total number of iterations a priori 
which (2P1D) can avoid at the expense of one more proximal operator calculation at each iteration.
3.4. Impact of strong convexity. We can improve the above schemes when f ∈ Fµ  i.e.  f is
strongly convex with parameter µf > 0. The dual function g given in (6) is smooth and Lipschitz
f (cid:107)A(cid:107)2. Let us illustrate this when S = I and using the (1P2D) scheme as:
gradient with Lg

f := µ−1

 ˆyk

(1P2Dµ) :

:= (1−τk)¯yk +τkβ−1

¯xk+1 := (1−τk)¯xk +τkx(cid:63)(ˆyk) 
¯yk+1 := ˆyk + 1
Lg
f

(cid:0)Ax(cid:63)(ˆyk)−b(cid:1).

k (A¯xk − b) 

Here  x(cid:63)(ˆyk) is the solution of (6) at ˆyk. We can still choose the starting point as in (16) with β0 :=
f . The parameters βk and τk at Steps 4 and 5 of Algorithm 1 are updated as βk+1 := (1 − τk)βk 
Lg

5

2 ((cid:112)τ 2

√

k + 4 − τk)  where β0 := Lg

and τk+1 := τk
illustrates the convergence of Algorithm 1 using (1P2Dµ); see [28] for the detail proof.

Corollary 1. Let f ∈ Fµ and(cid:8)(¯xk  ¯yk)(cid:9)

f and τ0 := (

k≥0 be generated by Algorithm 1 using (1P2Dµ). Then:

5 − 1)/2. The following corollary

−D(cid:63)Y(cid:107)A¯xk − b(cid:107) ≤ f (¯xk) − f (cid:63) ≤ 0 and (cid:107)A¯xk − b(cid:107) ≤ 4(cid:107)A(cid:107)2D(cid:63)Y
µf (k + 2)2 .

Moreover  we also have (cid:107)¯xk − x(cid:63)(cid:107) ≤ 4(cid:107)A(cid:107)
It is important to note that  when f ∈ Fµ  we only have one smoothness parameter β and  hence 
we do not need to ﬁx the number of iterations a priori (compared with [18]).

D(cid:63)Y.

(k+2)µf

γ

x(cid:63)

γk−1

(18)

(cid:9)

1)(cid:107)2

2

c := x(cid:63)

2 for ﬁxed xc

(cid:107)A1(x1−xc

k−1) with the Bregman distance db.

γ 1(ˆyk) + A2x2−b(cid:107)2(cid:9).

(cid:8)f1(x1)+(ˆyk)TA1x1 +
(cid:8)f2(x2)+ (ˆyk)T A2x2 +

γ 2(ˆyk)] in (1P2D) by the following alternating step:
2−b(cid:107)2 +
γ
2

4 Algorithmic enhancements through existing methods
Our framework can be applied to develop other variants of popular primal-dual methods for (1)
including alternating minimization algorithms and alternating direction methods of multipliers. We
illustrate in this section three variants of Algorithm 1. We also borrow adaptation heuristics from
other algorithms to enhance our practical performance.
(ˆyk−1). This makes
4.1. Proximal-based decomposition method. We can choose xk
the (1P2D) scheme of Algorithm 1 similar to the proximal-based decomposition algorithm in [30] 
which employs the proximal term db(·  ˆx(cid:63)
4.2. ADMM. Let f and X be 2-decomposable  i.e.  f (x) := f1(x1) + f2(x2) and X := X1 × X2.
We can apply the (1P2D) scheme of Algorithm 1 to this case with f1 being fγ 1(·) := f1(·) +
1)(cid:107)2
1 ∈ X1. For this variant  we substitute the primal step of computing
2(cid:107)A1(· − xc
γ(ˆyk) = [x(cid:63)
γ 1(ˆyk)  x(cid:63)
x(cid:63)
γ 1(ˆyk) := arg min
x1∈X1
γ 2(ˆyk) := arg min
x(cid:63)
x2∈X2

(cid:107)A1x1 +A2 ˆxk
ρk
2
(cid:107)A1x(cid:63)
ηk
2
Here  ρk and ηk are two penalty parameters  and ˆxk
2 is the previous iteration of x(cid:63)
of parameters  as well as the complete algorithm and its convergence can be found in [29].
4.3. Primal-dual hybrid gradient (PDHG). When A1 and A2 are not orthogonal  one can linearize
the quadratic terms in both steps of (18) to obtain a new preconditioned ADMM (PADMM) algo-
rithm that employes the proximal operator of f1 and f2 instead of two general convex subproblems.
In this case  the (1P2D) scheme with (18) leads to a new variant of PADMM in [8] or PDHG in [9].
Details of the complete algorithm can be found in [29].
4.4. Enhancements of our schemes. For the PADMM and ADMM methods  a great deal of
adaptation techniques has been proposed to enhance their convergence. We can view some of these
techniques in the light of model-based excessive gap condition. For instance  Algorithm 1 decreases
the smoothed gap function Gγkβk as illustrated in Deﬁnition 1. The actual decrease is then given by
f (¯xk) − f (cid:63) ≤ γk(DSX − Ψk/γk). In practice  Dk := DSX − Ψk/γk can be dramatically smaller
than DSX in the early iterations. This implies that increasing γk can improve practical performance.
Such a strategy indeed forms the basis of many adaptation techniques in PADMM and in ADMM.
Speciﬁcally  if γk increases  then τk also increases and βk decreases. Since βk measures the primal
feasibility gap Fk := (cid:107)A¯xk − b(cid:107) due to Lemma 1  we should only increase γk if the feasibility
gap Fk is relatively high. Indeed  when xc = xc
k is updated adaptively  we can compute the dual
2)k)(cid:107). Then  if Fk ≥ sHk for some s > 0  we
2)k+1 − (ˆx(cid:63)
feasibility gap as Hk := γk(cid:107)AT
increase γk+1 := cγk for some c > 1 (we use ck = c := 1.05 in practice). We can also decrease the
(ˆyk)  Sxc)/DSX ∈ [0  1]
parameter γk in (1P2D) by γk+1 := (1 − ckτk)γk  where ck := db(Sx(cid:63)
after or during the update of (¯xk+1  ¯yk+1) as in (2P1D) if we know the estimate DSX .
5 Numerical illustrations
5.1. Theoretical vs. practical bounds. We demonstrate the empirical performance of Algorithm 1
w.r.t. its theoretical bounds via a basic non-overlapping sparse-group basis pursuit problem:

γ 2(ˆyk). The update

1 A2((ˆx(cid:63)

(cid:8)(cid:88)ng

i=1

min
x∈Rn

wi(cid:107)xgi(cid:107)2 : Ax = b  (cid:107)x(cid:107)∞ ≤ ρ(cid:9) 

(19)

γk

6

where ρ > 0 is the signal magnitude  and gi and wi’s are the group indices and weights  respectively.

√

[top row] – the decomposable Bregman distance

Figure 1: Actual performance vs. theoretical bounds:
smoother (S = I)  and [bottom row] – the augmented Lagrangian smoother (S = A).
In this test  we ﬁx xc = 0n and db(x  xc) := (1/2)(cid:107)x(cid:107)2. Since ρ is given  we can evaluate DX
numerically. By solving (19) with the SDPT3 interior-point solver [31] up to the accuracy 10−8  we
2(cid:107)A(cid:107)(K + 1)−1 with K := 104 and generate the theoretical

can numerically estimate D(cid:63)Y and f (cid:63). In the (2P1D) scheme  we set γ0 = β0 = (cid:112) ¯Lg  while  in

the (1P2D) scheme  we set γ0 := 2
bounds deﬁned in Theorem 1.
We test the performance of the four variants using a synthetic data: n = 1024  m = (cid:98)n/3(cid:99) = 341 
ng = (cid:98)n/8(cid:99) = 128  and x(cid:92) is a (cid:98)ng/8(cid:99)-sparse vector. Matrix A is generated randomly using the iid
standard Gaussian and b := Ax(cid:92). The group indices gi is also generated randomly (i = 1 ···   ng).
The empirical performance of two variants: (2P1D) and (1P2D) of Algorithm 1 is shown in Fig-
ure 1. The basic algorithm refers to the case when xc
k := xc = 0n and the parameters are not tuned.
Hence  at each iteration of the basic (1P2D)  it requires only 1 proximal calculation and applies A
and AT once each  and at each iteration of the basic (2P1D)  we use 2 proximal calculations and
apply A twice and AT once. In contrast  (2P1D) and (1P2D) variants whose iterations require one
more application of AT for adaptive parameter updates.
As can be seen from Figure 1 (row 1) that the empirical performance of the basic variants roughly
follows the O(1/k) convergence rate in terms of |f (¯xk)− f (cid:63)| and (cid:107)A¯xk − b(cid:107). The deviations from
the bound are due to the increasing sparsity of the iterates  which improves empirical convergence.
With a kick-factor of ck = −0.02/τk and adaptive xc
k  both turned variants (2P1D) and (1P2D)
signiﬁcantly outperform theoretical predictions. Indeed  they approach x(cid:63) up to 10−13 accuracy 
i.e.  (cid:107)¯xk − x(cid:63)(cid:107) ≤ 10−13 after a few hundreds of iterations.
Similarly  Figure 1 (row 2) illustrates the actual performance vs. the theoretical bounds O(1/k2) by
using the augmented Lagrangian smoother. Here  we solve the subproblems (13) and (17) by using
FISTA [32] up to 10−8 accuracy as suggested in [28]. In this case  the theoretical bounds and the
actual performance of the basis variants are very close to each other both in terms of |f (¯xk) − f (cid:63)|
and (cid:107)A¯xk − b(cid:107). When the parameter γk is updated  the algorithms exhibit a better performance.
5.2. Binary linear support vector machine. This example is concerned with the following binary
linear support vector machine problem:

min
x∈Rn

(cid:96)j(yj  wT

(20)
where (cid:96)j(· ·) is the Hinge loss function given by (cid:96)j(s  τ ) := max{0  1 − sτ} = [1 − sτ ]+  wj is
the column of a given matrix W ∈ Rm×n  b ∈ Rn is the intercept vector  y ∈ {−1  +1}m is a
classiﬁer vector g is a given regularization function  e.g.  g(x) := (λ/2)(cid:107)x(cid:107)2 for the (cid:96)2-regularizer
or g(x) := λ(cid:107)x(cid:107)1 for the (cid:96)1-regularizer  where λ > 0 is a regularization parameter.
By introducing a slack variable r = Wx − b  we can write (20) in terms of (1) as:

j=1

(cid:8)F (x) :=

(cid:88)m

j x − bj) + g(x)(cid:9) 

(cid:110)(cid:88)m

min

x∈Rn r∈Rm

j=1

7

(cid:96)j(yj  rj) + g(x) : Wx − r = b

(21)

(cid:111)

.

020004000600080001000010−5100105#iterations|f(xk)−f∗|inlog-scale 020004000600080001000010−1010−5100105#iterationskAxk−bkinlog-scale 020004000600080001000010−5100105#iterations|f(xk)−f∗|inlog-scale 020004000600080001000010−1010−5100105#iterationskAxk−bkinlog-scale Theoretical boundBasic 2P1D algorithm2P1D algorithmTheoretical boundBasic 1P2D algorithm1P2D algorithm020004000600080001000010−1010−5100105#iterations|f(xk)−f∗|inlog-scale 020004000600080001000010−1510−1010−5100105#iterationskAxk−bkinlog-scale 020004000600080001000010−1010−5100105#iterations|f(xk)−f∗|inlog-scale 020004000600080001000010−1510−1010−5100105#iterationskAxk−bkinlog-scale Theoretical boundBasic 1P2D algorithm1P2D algorithmTheoretical boundBasic 2P1D algorithm2P1D algorithmNow  we apply the (1P2D) variant to solve (21). We test this algorithm on (21) and compare it
with LibSVM [33] using two problems from the LibSVM data set available at http://www.csie.
ntu.edu.tw/˜cjlin/libsvmtools/datasets/. The ﬁrst problem is a1a  which has p = 119
features and N = 1605 data points  while the second problem is news20  which has p = 1(cid:48)355(cid:48)191
features and N = 19(cid:48)996 data points.
We compare Algorithm 1 and the LibSVM solver in terms of the ﬁnal value F (xk) of the orig-
inal objective function F   the computational time  and the classiﬁcation accuracy caλ := 1 −

(cid:2)sign(Wxk − r) (cid:54)= y)(cid:3) of both training and test data set. We randomly select 30%

data in a1a and news20 to form a test set  and the remaining 70% data is used for training. We
perform 10 runs and compute the average results. These average results are plotted in Fig. 2 for two
separate problems  respectively. The upper and lower bounds show the maximum and minimum
values of these 10 runs.

N−1(cid:80)N

j=1

Figure 2: The average performance results of the two algorithms on the a1a (ﬁrst row) and news20
(second row) problems.
As can be seen from these results that both solvers give relatively the same objective values  the
accuracy for these two problems  while the computational of (1P2D) is much lower than LibSVM.
We note that LibSVM becomes slower when the parameter λ becomes smaller due to its active-set
strategy. The (1P2D) algorithm is almost independent of the regularization parameter λ  which is
different from active-set methods. In addition  the performance of (1P2D) can be improved by tak-
ing account its parallelization ability  which has not fully been exploited yet in our implementation.

6 Conclusions
We propose a model-based excessive gap (MEG) technique for constructing and analyzing ﬁrst-order
primal-dual methods that numerically approximate an optimal solution of the constrained convex
optimization problem (1). Thanks to a combination of smoothing strategies and MEG  we propose 
to the best of our knowledge  the ﬁrst primal-dual algorithmic schemes for (1) that theoretically
obtain optimal convergence rates directly without averaging the iterates and that seamlessly handle
the p-decomposability structure. In addition  our analysis techniques can be simply adapt to handle
inexact oracle produced by solving approximately the primal subproblems (c.f.
[28])  which is
important for the augmented Lagrangian versions with lower-iteration counts. We expect a deeper
understanding of MEG and different smoothing strategies to help us in tailoring adaptive update
strategies for our schemes (as well as several other connected and well-known schemes) in order to
further improve the empirical performance.
Acknowledgments. This work is supported in part by the European Commission under the grants MIRG-
268398 and ERC Future Proof  and by the Swiss Science Foundation under the grants SNF 200021-132548 
SNF 200021-146750 and SNF CRSII2-147633.

8

0200400600800100000.511.522.533.5x 108The objective valuesParameterhorizon(λ−1)TheobjectivevaluesF(xk) 1P2DLibSVM020040060080010000.740.760.780.80.820.840.860.880.9The classification accuracy (training data)Parameterhorizon(λ−1)The classification accuracy (training set) 1P2DLibSVM020040060080010000.740.760.780.80.820.840.86The classification accuracy (test data)Parameterhorizon(λ−1)The classification accuracy (test set) 02004006008001000−20246810121416The CPU time [second]Parameterhorizon(λ−1)The CPU time [second] 1P2DLibSVM1P2DLibSVM0200400600800100000.511.522.533.54x 107The objective valuesParameterhorizon(λ−1)TheobjectivevalueF(xk) 1P2DLibSVM020040060080010000.50.60.70.80.91The classification accuracy (training data)Parameterhorizon(λ−1)The classification accuracy (training set) 1P2DLibSVM020040060080010000.50.60.70.80.91The classification accuracy (test data)Parameterhorizon(λ−1)The classification accuracy (test set) 1P2DLibSVM02004006008001000400450500550600650700750800850The CPU time [second]Parameterhorizon(λ−1)CPU time [second] 1P2DLibSVMReferences
[1] Y. Nesterov  “Excessive gap technique in nonsmooth convex minimization ” SIAM J. Optim.  vol. 16  no. 1  pp. 235–249  2005.
[2] D. Bertsekas and J. N. Tsitsiklis  Parallel and distributed computation: Numerical methods. Prentice Hall  1989.
[3] V. Chandrasekaran  B. Recht  P. Parrilo  and A. Willsky  “The convex geometry of linear inverse problems ” Laboratory for Informa-
tion and Decision Systems  Department of Electrical Engineering and Computer Science  Massachusetts Institute of Technology  Tech.
Report.  2012.

[4] M. B. McCoy  V. Cevher  Q. Tran-Dinh  A. Asaei  and L. Baldassarre  “Convexity in source separation: Models  geometry  and algo-

rithms ” IEEE Signal Processing Magazine  vol. 31  no. 3  pp. 87–95  2014.

[5] M. J. Wainwright  “Structured regularizers for high-dimensional problems: Statistical and computational issues ” Annual Review of

Statistics and its Applications  vol. 1  pp. 233–253  2014.

[6] N. Parikh and S. Boyd  “Proximal algorithms ” Foundations and Trends in Optimization  vol. 1  no. 3  pp. 123–231  2013.
[7] P. L. Combettes and V. R. Wajs  “Signal recovery by proximal forward-backward splitting ” Multiscale Model. Simul.  vol. 4  pp. 1168–

1200  2005.

[8] A. Chambolle and T. Pock  “A ﬁrst-order primal-dual algorithm for convex problems with applications to imaging ” Journal of Mathe-

matical Imaging and Vision  vol. 40  no. 1  pp. 120–145  2011.

[9] T. Goldstein  E. Esser  and R. Baraniuk  “Adaptive primal-dual hybrid gradient methods for saddle point problems ” Tech. Report.  vol.

http://arxiv.org/pdf/1305.0546v1.pdf  pp. 1–26  2013.

[10] B. He and X. Yuan  “On non-ergodic convergence rate of Douglas-Rachford alternating direction method of multipliers ” Numer. Math. 

[11] ——  “On the O(1/n) convergence rate of the Douglas-Rachford alternating direction method ” SIAM J. Numer. Anal.  vol. 50  pp.

DOI 10.1007/s00211-014-0673-6  2014.

700–709  2012.

[12] Y. Ouyang  Y. Chen  G. L. Lan.  and E. J. Pasiliao  “An accelerated linearized alternating direction method of multiplier ” Tech  2014.
[13] R. Sheﬁ and M. Teboulle  “Rate of convergence analysis of decomposition methods based on the proximal method of multipliers for

convex minimization ” SIAM J. Optim.  vol. 24  no. 1  pp. 269–297  2014.

[14] H. Wang and A. Banerjee  “Bregman alternating direction method of multipliers ” Tech. Report  pp. 1–18  2013. Online at:

http://arxiv.org/pdf/1306.3203v1.pdf.

[15] H. Ouyang  N. He  L. Q. Tran  and A. Gray  “Stochastic alternating direction method of multipliers ” JMLR W&CP  vol. 28  pp. 80–88 

2013.

[16] T. Goldstein  B. O. Donoghue  and S. Setzer  “Fast alternating direction optimization methods ” SIAM J. Imaging Sci.  vol. 7  no. 3 

pp. 1588–1623  2014.

[17] S. Boyd  N. Parikh  E. Chu  B. Peleato  and J. Eckstein  “Distributed optimization and statistical learning via the alternating direction

method of multipliers ” Foundations and Trends in Machine Learning  vol. 3  no. 1  pp. 1–122  2011.

[18] A. Beck and M. Teboulle  “A fast dual proximal gradient algorithm for convex minimization and applications ” Oper. Res. Letter  vol. 42 

no. 1  pp. 1–6  2014.

[19] W. Deng and W. Yin  “On the global and linear convergence of the generalized alternating direction method of multipliers ” Rice Uni-

versity CAAM  Tech. Rep.  2012  tR12-14.

[20] D. P. Bertsekas  Constrained optimization and Lagrange multiplier methods. Athena Scientiﬁc  1996.
[21] R. T. Rockafellar  “Augmented lagrangians and applications of the proximal point algorithm in convex programming ” Mathematics of

Operations Research  vol. 1  pp. 97–116  1976.

[22] Y. Nesterov  “Smooth minimization of non-smooth functions ” Math. Program.  vol. 103  no. 1  pp. 127–152  2005.
[23] G. Lan and R. Monteiro  “Iteration-complexity of ﬁrst-order augmented Lagrangian methods for convex programming ” Math. Program. 

DOI 10.1007/s10107-015-0861-x  2015.

[24] V. Nedelcu  I. Necoara  and Q. Tran-Dinh  “Computational complexity of inexact gradient augmented Lagrangian methods: Application

to constrained MPC ” SIAM J. Optim. Control  vol. 52  no. 5  pp. 3109–3134  2014.

[25] Y. Nesterov  Introductory lectures on convex optimization: a basic course  Kluwer Academic Publishers  2004  vol. 87.
[26] F. Facchinei and J.-S. Pang  Finite-dimensional variational inequalities and complementarity problems  N. York  Ed. Springer-Verlag 

2003  vol. 1-2.

[27] A. Auslender  Optimisation: M´ethodes Num´eriques. Paris: Masson  1976.
[28] Q. Tran-Dinh and V. Cevher  “A primal-dual algorithmic framework for constrained convex minimization ” Tech. Report.  LIONS  pp.

1–54  2014.

[29] Q. Tran-Dinh and V. Cevher  “Optimal-rate and tuning-free alternating algorithms for constrained convex optimization ” Tech. Report. 

LIONS  2015.

[30] G. Chen and M. Teboulle  “A proximal-based decomposition method for convex minimization problems ” Math. Program.  vol. 64  pp.

81–101  1994.

[31] K.-C. Toh  M. Todd  and R. T¨ut¨unc¨u  “On the implementation and usage of SDPT3 – a Matlab software package for semideﬁnite-

quadratic-linear programming  version 4.0 ” NUS Singapore  Tech. Report  2010.

[32] A. Beck and M. Teboulle  “A fast iterative shrinkage-thresholding algorithm for linear inverse problems ” SIAM J. Imaging Sciences 

vol. 2  no. 1  pp. 183–202  2009.

[33] C.-C. Chang and C.-J. Lin  “LIBSVM: a library for support vector machines ” ACM Transactions on Intelligent Systems and Technology 

vol. 2  no. 27  pp. 1–27  2011.

9

,Quoc Tran-Dinh
Volkan Cevher