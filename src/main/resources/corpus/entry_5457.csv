2016,The Generalized Reparameterization Gradient,The reparameterization gradient has become a widely used method to obtain Monte Carlo gradients to optimize the variational objective. However  this technique does not easily apply to commonly used distributions such as beta or gamma without further approximations  and most practical applications of the reparameterization gradient fit Gaussian distributions. In this paper  we introduce the generalized reparameterization gradient  a method that extends the reparameterization gradient to a wider class of variational distributions. Generalized reparameterizations use invertible transformations of the latent variables which lead to transformed distributions that weakly depend on the variational parameters. This results in new Monte Carlo gradients that combine reparameterization gradients and score function gradients. We demonstrate our approach on variational inference for two complex probabilistic models. The generalized reparameterization is effective: even a single sample from the variational distribution is enough to obtain a low-variance gradient.,The Generalized Reparameterization Gradient

Francisco J. R. Ruiz
University of Cambridge
Columbia University

Michalis K. Titsias
Athens University of

Economics and Business

David M. Blei

Columbia University

Abstract

The reparameterization gradient has become a widely used method to obtain Monte
Carlo gradients to optimize the variational objective. However  this technique does
not easily apply to commonly used distributions such as beta or gamma without
further approximations  and most practical applications of the reparameterization
gradient ﬁt Gaussian distributions. In this paper  we introduce the generalized repa-
rameterization gradient  a method that extends the reparameterization gradient to a
wider class of variational distributions. Generalized reparameterizations use invert-
ible transformations of the latent variables which lead to transformed distributions
that weakly depend on the variational parameters. This results in new Monte Carlo
gradients that combine reparameterization gradients and score function gradients.
We demonstrate our approach on variational inference for two complex probabilistic
models. The generalized reparameterization is eﬀective: even a single sample from
the variational distribution is enough to obtain a low-variance gradient.

Introduction

1
Variational inference (vi) is a technique for approximating the posterior distribution in probabilistic
models (Jordan et al.  1999; Wainwright and Jordan  2008). Given a probabilistic model p.x; z/ of
observed variables x and hidden variables z  the goal of vi is to approximate the posterior p.zj x/ 
which is intractable to compute exactly for many models. The idea of vi is to posit a family of
distributions over the latent variables q.zI v/ with free variational parameters v. vi then ﬁts those
parameters to ﬁnd the member of the family that is closest in Kullback-Leibler (kl) divergence to
the exact posterior  v(cid:3) D arg minv KL.q.zI v/jjp.zj x//. This turns inference into optimization  and
diﬀerent ways of doing vi amount to diﬀerent optimization algorithms for solving this problem.
For a certain class of probabilistic models  those where each conditional distribution is in an exponential
family  we can easily use coordinate ascent optimization to minimize the kl divergence (Ghahramani
and Beal  2001). However  many important models do not fall into this class (e.g.  probabilistic neural
networks or Bayesian generalized linear models). This is the scenario that we focus on in this paper.
Much recent research in vi has focused on these diﬃcult settings  seeking eﬀective optimization
algorithms that can be used with any model. This has enabled the application of vi on nonconjugate
probabilistic models (Carbonetto et al.  2009; Paisley et al.  2012; Ranganath et al.  2014; Titsias and
Lázaro-Gredilla  2014)  deep neural networks (Neal  1992; Hinton et al.  1995; Mnih and Gregor  2014;
Kingma and Welling  2014)  and probabilistic programming (Wingate and Weber  2013; Kucukelbir
et al.  2015; van de Meent et al.  2016).
One strategy for vi in nonconjugate models is to obtain Monte Carlo estimates of the gradient of the
variational objective and to use stochastic optimization to ﬁt the variational parameters. Within this
strategy  there have been two main lines of research: black-box variational inference (bbvi) (Ranganath
et al.  2014) and reparameterization gradients (Salimans and Knowles  2013; Kingma and Welling 
2014). Each enjoys diﬀerent advantages and limitations.
bbvi expresses the gradient of the variational objective as an expectation with respect to the variational
distribution using the log-derivative trick  also called reinforce or score function method (Glynn 
1990; Williams  1992). It then takes samples from the variational distribution to calculate noisy
gradients. bbvi is generic—it can be used with any type of latent variables and any model. However 
30th Conference on Neural Information Processing Systems (NIPS 2016)  Barcelona  Spain.

the gradient estimates typically suﬀer from high variance  which can lead to slow convergence.
Ranganath et al. (2014) reduce the variance of these estimates using Rao-Blackwellization (Casella
and Robert  1996) and control variates (Ross  2002; Paisley et al.  2012; Gu et al.  2016). Other
researchers have proposed further reductions  e.g.  through local expectations (Titsias and Lázaro-
Gredilla  2015) and importance sampling (Ruiz et al.  2016).
The second approach to Monte Carlo gradients of the variational objective is through reparameteriza-
tion (Price  1958; Bonnet  1964; Salimans and Knowles  2013; Kingma and Welling  2014; Rezende
et al.  2014). This approach reparameterizes the latent variable z in terms of a set of auxiliary random
variables whose distributions do not depend on the variational parameters (typically  a standard
normal). This facilitates taking gradients of the variational objective because the gradient operator can
be pushed inside the expectation  and because the resulting procedure only requires drawing samples
from simple distributions  such as standard normals. We describe this in detail in Section 2.
Reparameterization gradients exhibit lower variance than bbvi gradients. They typically need only
one Monte Carlo sample to estimate a noisy gradient  which leads to fast algorithms. Further  for some
models  their variance can be bounded (Fan et al.  2015). However  reparameterization is not as generic
as bbvi. It is typically used with Gaussian variational distributions and does not easily generalize to
other common distributions  such as the gamma or beta  without using further approximations. (See
Knowles (2015) for an alternative approach to deal with the gamma distribution.)
We develop the generalized reparameterization (g-rep) gradient  a new method to extend reparameter-
ization to other variational distributions. The main idea is to deﬁne an invertible transformation of the
latent variables such that the distribution of the transformed variables is only weakly governed by the
variational parameters. (We make this precise in Section 3.) Our technique naturally combines both
bbvi and reparameterization; it applies to a wide class of nonconjugate models; it maintains the black-
box criteria of reusing variational families; and it avoids approximations. We empirically show in two
probabilistic models—a nonconjugate factorization model and a deep exponential family (Ranganath
et al.  2015)—that a single Monte Carlo sample is enough to build an eﬀective low-variance estimate
of the gradient. In terms of speed  g-rep outperforms bbvi. In terms of accuracy  it outperforms
automatic diﬀerentiation variational inference (advi) (Kucukelbir et al.  2016)  which considers
Gaussian variational distributions on a transformed space.
2 Background
Consider a probabilistic model p.x; z/  where z denotes the latent variables and x the observations.
We assume that the posterior distribution p.zj x/ is analytically intractable and we wish to apply vi.
We introduce a tractable distribution q.zI v/ to approximate p.zj x/ and minimize the kl divergence
DKL .q.zI v/ k p.zj x// with respect to the variational parameters v. This minimization is equivalently
expressed as the maximization of the so-called evidence lower bound (elbo) (Jordan et al.  1999) 

L.v/ D Eq.zIv/ Œlog p.x; z/ (cid:0) log q.zI v/ D Eq.zIv/ Œf .z/ C H Œq.zI v/ :

(1)

f .z/   log p.x; z/

We denote
(2)
to be the model log-joint density and H Œq.zI v/ to be the entropy of the variational distribution. When
the expectation Eq.zIv/ Œf .z/ is analytically tractable  the maximization of the elbo can be carried out
using standard optimization methods. Otherwise  when it is intractable  other techniques are needed.
Recent approaches rely on stochastic optimization to construct Monte Carlo estimates of the gradient
with respect to the variational parameters. Below  we review the two main methods for building such
Monte Carlo estimates: the score function method and the reparameterization trick.
Score function method. A general way to obtain unbiased stochastic gradients is to use the score
function method  also called log-derivative trick or reinforce (Williams  1992; Glynn  1990)  which
has been recently applied to vi (Paisley et al.  2012; Ranganath et al.  2014; Mnih and Gregor  2014).
It is based on writing the gradient of the elbo with respect to v as

rvL D Eq.zIv/ Œf .z/rv log q.zI v/ C rvH Œq.zI v/ ;

(3)
and then building Monte Carlo estimates by approximating the expectation with samples from q.zI v/.
The resulting estimator suﬀers from high variance  making it necessary to apply variance reduction
methods such as control variates (Ross  2002) or Rao-Blackwellization (Casella and Robert  1996).
Such variance reduction techniques have been used in bbvi (Ranganath et al.  2014).

2

hrzf .z/

ˇˇzDT .(cid:15)Iv/

i C rvH Œq.zI v/ :

Reparameterization. The reparameterization trick (Salimans and Knowles  2013; Kingma and
Welling  2014) expresses the latent variables z as an invertible function of another set of variables (cid:15) 
i.e.  z D T .(cid:15)I v/  such that the distribution of the new random variables q(cid:15).(cid:15)/ does not depend on
the variational parameters v. Under these assumptions  expectations with respect to q.zI v/ can be
expressed as Eq.zIv/ Œf .z/ D Eq(cid:15) .(cid:15)/ Œf .T .(cid:15)I v//  and the gradient with respect to v can be pushed
into the expectation  yielding

rvT .(cid:15)I v/

rvL D Eq(cid:15) .(cid:15)/

(cid:15) D T

(4)
The assumption here is that the log-joint f .z/ is diﬀerentiable. The gradient rzf .z/ depends on the
model  but it can be computed using automatic diﬀerentiation tools (Baydin et al.  2015). Monte Carlo
estimates of the reparameterization gradient typically present much lower variance than those based
on Eq. 3. In practice  a single sample from q(cid:15).(cid:15)/ is enough to obtain a low-variance estimate.1
The reparameterization trick is thus a powerful technique to reduce the variance of the estimator 
but it requires a transformation (cid:15) D T
(cid:0)1.zI v/ such that q(cid:15).(cid:15)/ does not depend on the variational
parameters v. For instance  if the variational distribution is Gaussian with mean (cid:22) and covariance † 
a straightforward transformation consists of standardizing the random variable z  i.e. 

(cid:0)1.zI (cid:22); †/ D †

2 .z (cid:0) (cid:22)/:
(cid:0) 1

(5)
This transformation ensures that the (Gaussian) distribution q(cid:15).(cid:15)/ does not depend on (cid:22) or †.
For a general variational distribution q.zI v/  Kingma and Welling (2014) discuss three families
of transformations: inverse cumulative density function (cdf)  location-scale  and composition.
However  these transformations may not apply in certain cases.2 Notably  none of them apply to the
gamma3 and the beta distributions  although these distributions are often used in vi.
Next  we show how to relax the constraint that the transformed density q(cid:15).(cid:15)/ must not depend on the
variational parameters v. We follow a standardization procedure similar to the Gaussian case in Eq. 5 
but we allow the distribution of the standardized variable (cid:15) to depend (at least weakly) on v.
3 The Generalized Reparameterization Gradient
We now generalize the reparameterization idea to distributions that  like the gamma or the beta  do
not admit the standard reparameterization trick. We assume that we can eﬃciently sample from the
variational distribution q.zI v/  and that q.zI v/ is diﬀerentiable with respect to z and v. We introduce
a random variable (cid:15) deﬁned by an invertible transformation

z D T .(cid:15)I v/;

(cid:15) D T

(cid:0)1.zI v/;

and

(6)
(cid:0)1.zI v/ as a standardization procedure that attempts to make the
where we can think of (cid:15) D T
distribution of (cid:15) weakly dependent on the variational parameters v. “Weakly” means that at least
its ﬁrst moment does not depend on v. For instance  if (cid:15) is deﬁned to have zero mean  then its ﬁrst
moment has become independent of v. However  we do not assume that the resulting distribution of (cid:15)
is completely independent of the variational parameters v  and therefore we write it as q(cid:15).(cid:15)I v/. We use
the distribution q(cid:15).(cid:15)I v/ in the derivation of g-rep  but we write the ﬁnal gradient as an expectation
with respect to the original variational distribution q.zI v/  from which we can sample.
More in detail  by the standard change-of-variable technique  the transformed density is
q(cid:15).(cid:15)I v/ D q .T .(cid:15)I v/I v/ J.(cid:15); v/; where J.(cid:15); v/   jdet r(cid:15)T .(cid:15)I v/j ;

(7)
is a short-hand for the absolute value of the determinant of the Jacobian. We ﬁrst use the transformation
to rewrite the gradient of Eq.zIv/ Œf .z/ in (1) as

rvEq.zIv/ Œf .z/ D rvEq(cid:15) .(cid:15)Iv/ Œf .T .(cid:15)I v// D rv

q(cid:15).(cid:15)I v/f .T .(cid:15)I v// d (cid:15):

(8)

Z

1In the literature  there is no formal proof that reparameterization has lower variance than the score function
estimator  except for some simple models (Fan et al.  2015). Titsias and Lázaro-Gredilla (2014) provide some
intuitions  and Rezende et al. (2014) show some beneﬁts of reparameterization in the Gaussian case.
(cid:0)1.zI v/ to the cdf. This leads to a uniform distribution over (cid:15) on the unit
interval  but it is not practical because the inverse cdf  T .(cid:15)I v/  does not have analytical solution in general. We
develop an approach that does not require computation of (inverse) cdf’s or their derivatives.
3Composition is only available when it is possible to express the gamma as a sum of exponentials  i.e.  its

2The inverse cdf approach sets T

shape parameter is an integer  which is not generally the case in vi.

3

We now express the gradient as the sum of two terms  which we name grep and gcorr for reasons that
we will explain below. We apply the log-derivative trick and the product rule for derivatives  yielding

rvEq.zIv/ Œf .z/ DZ
„

…
q(cid:15).(cid:15)I v/rvf .T .(cid:15)I v// d (cid:15)

ƒ‚

grep

…
q(cid:15).(cid:15)I v/f .T .(cid:15)I v//rv log q(cid:15).(cid:15)I v/d (cid:15)

ƒ‚

;

gcorr

(9)

CZ
„

We rewrite Eq. 9 as an expression that involves expectations with respect to the original variational
distribution q.zI v/ only. For that  we deﬁne the following two auxiliary functions that depend on the
transformation T .(cid:15)I v/:

h.(cid:15)I v/   rvT .(cid:15)I v/;

and

u.(cid:15)I v/   rv log J.(cid:15); v/:

(cid:2)rzf .z/h(cid:0)T
(cid:0)1.zI v/I v(cid:1)(cid:3) ;
(cid:2)f .z/(cid:0)rz log q.zI v/h(cid:0)T

After some algebra (see the Supplement for details)  we obtain
grep D Eq.zIv/
gcorr D Eq.zIv/
Thus  we can ﬁnally write the full gradient of the elbo as

(cid:0)1.zI v/I v(cid:1) C rv log q.zI v/ C u(cid:0)T

(cid:0)1.zI v/I v(cid:1)(cid:1)(cid:3) :

(10)

(11)

rvL D grep C gcorr C rvH Œq.zI v/ ;

(12)
Interpretation of the generalized reparameterization gradient. The term grep is easily recognizable
as the standard reparameterization gradient  and hence the label “rep.” Indeed  if the distribution
q(cid:15).(cid:15)I v/ does not depend on the variational parameters v  then the term rv log q(cid:15).(cid:15)I v/ in Eq. 9
vanishes  making gcorr D 0. Thus  we may interpret gcorr as a “correction” term that appears when the
transformed density depends on the variational parameters.
Furthermore  we can recover the score function gradient in Eq. 3 by choosing the identity transfor-
mation  z D T .(cid:15)I v/ D (cid:15). In such case  the auxiliary functions in Eq. 10 become zero because the
transformation does not depend on v  i.e.  h.(cid:15)I v/ D 0 and u.(cid:15)I v/ D 0. This implies that grep D 0
and gcorr D Eq.zIv/ Œf .z/rv log q.zI v/.
Alternatively  we can interpret the g-rep gradient as a control variate of the score function gradient.
For that  we rearrange Eqs. 9 and 11 to express the gradient as
rvEq.zIv/ Œf .z/ D Eq.zIv/ Œf .z/rv log q.zI v/

(cid:0)1.zI v/I v(cid:1) C u(cid:0)T

(cid:0)1.zI v/I v(cid:1)(cid:1)(cid:3) ;

(cid:2)f .z/(cid:0)rz log q.zI v/h(cid:0)T

C grep C Eq.zIv/

where the second line is the control variate  which involves the reparameterization gradient.
Transformations. Eqs. 9 and 11 are valid for any transformation T .(cid:15)I v/. However  we may expect
some transformations to perform better than others  in terms of the variance of the resulting estimator.
It seems sensible to search for transformations that make gcorr small  as the reparameterization gradient
grep is known to present low variance in practice under standard smoothness conditions of the log-joint
(Fan et al.  2015).4 Transformations that make gcorr small are such that (cid:15) D T
(cid:0)1.zI v/ becomes
weakly dependent on the variational parameters v. In the standard reparameterization of Gaussian
random variables  the transformation takes the form in (5)  and thus (cid:15) is a standardized version of
z. We mimic this standardization idea for other distributions as well. In particular  for exponential
family distributions  we use transformations of the form (suﬃcient statistic (cid:0) expected suﬃcient
statistic)=(scale factor). We present several examples in the next section.
3.1 Examples
For concreteness  we show here some examples of the equations above for well-known probability
distributions. In particular  we choose the gamma  log-normal  and beta distributions.
Gamma distribution. Let q.zI ˛; ˇ/ be a gamma distribution with shape ˛ and rate ˇ. We use a
transformation based on standardization of the suﬃcient statistic log.z/  i.e. 

(cid:15) D T

(cid:0)1.zI ˛; ˇ/ D log.z/ (cid:0) .˛/ C log.ˇ/

;

p

 1.˛/

4Techniques such as Rao-Blackwellization could additionally be applied to reduce the variance of gcorr. We

do not apply any such technique in this paper.

4

where .(cid:1)/ denotes the digamma function  and k.(cid:1)/ is its k-th derivative. This ensures that (cid:15) has zero
mean and unit variance  and thus its two ﬁrst moments do not depend on the variational parameters ˛
and ˇ. We now compute the auxiliary functions in Eq. 10 for the components of the gradient with
respect to ˛ and ˇ  which take the form

 

(cid:15) 2.˛/

p
!
C 1.˛/

 1.˛/

2

!
C 1.˛/

C 2.˛/
2 1.˛/

;

;

h˛.(cid:15)I ˛; ˇ/ D T .(cid:15)I ˛; ˇ/
p

u˛.(cid:15)I ˛; ˇ/ D

 

(cid:15) 2.˛/

2

 1.˛/

hˇ .(cid:15)I ˛; ˇ/ D (cid:0) T .(cid:15)I ˛; ˇ/
uˇ .(cid:15)I ˛; ˇ/ D (cid:0) 1

ˇ

:

;

ˇ

The terms grep and gcorr are obtained after substituting these results in Eq. 11. We provide the ﬁnal
expressions in the Supplement. We remark here that the component of gcorr corresponding to the
D 0  meaning that the distribution of (cid:15) does
derivative with respect to the rate equals zero  i.e.  gcorr
not depend on the parameter ˇ. Indeed  we can compute this distribution following Eq. 7 as

exp(cid:16)

ˇ

 1.˛/ (cid:0) exp(cid:16)
p


p
 1.˛/ C .˛/

q(cid:15).(cid:15)I ˛; ˇ/ D e˛ .˛/p

(cid:15)˛
where we can verify that it does not depend on ˇ.
Log-normal distribution. For a log-normal distribution with location (cid:22) and scale (cid:27)  we can
standardize the suﬃcient statistic log.z/ as

.˛/

(cid:15)

;

 1.˛/

(cid:15) D T

(cid:0)1.zI (cid:22); (cid:27) / D log.z/ (cid:0) (cid:22)

:

(cid:27)

This leads to a standard normal distribution on (cid:15)  which does not depend on the variational parameters 
and thus gcorr D 0. The auxiliary function h.(cid:15)I (cid:22); (cid:27) /  which is needed for grep  takes the form

Thus  the reparameterization gradient is given in this case by

h(cid:22).(cid:15)I (cid:22); (cid:27) / D T .(cid:15)I (cid:22); (cid:27) /;
D Eq.zI(cid:22);(cid:27) / Œzrzf .z/ ;

grep

(cid:22)

h(cid:27) .(cid:15)I (cid:22); (cid:27) / D (cid:15)T .(cid:15)I (cid:22); (cid:27) /:

(cid:2)zT

(cid:0)1.zI (cid:22); (cid:27) /rzf .z/(cid:3) :

grep

(cid:27)

D Eq.zI(cid:22);(cid:27) /

This corresponds to advi (Kucukelbir et al.  2016) with a logarithmic transformation over a positive
random variable  since the variational distribution over the transformed variable is Gaussian. For a
general variational distribution  we recover advi if the transformation makes (cid:15) Gaussian.
Beta distribution. For a random variable z (cid:24) Beta.˛; ˇ/  we could rewrite z D z
0
0
0
2/ for
(cid:24) Gamma.˛; 1/ and z
1=.z
0
0
1
and
0
. Instead  in the spirit of applying standardization directly over z  we deﬁne a transformation to
standardize the logit function  logit .z/   log.z=.1 (cid:0) z// (sum of suﬃcient statistics of the beta) 

C z
(cid:24) Gamma.ˇ; 1/  and apply the gamma reparameterization for z

z
z

0

2

2

1

1

(cid:15) D T

(cid:0)1.zI ˛; ˇ/ D logit .z/ (cid:0) .˛/ C .ˇ/

:

(cid:27) .˛; ˇ/

This ensures that (cid:15) has zero mean. We can set the denominator to the standard deviation of logit .z/.
However  for larger-scaled models we found better performance with a denominator (cid:27) .˛; ˇ/ that
makes gcorr D 0 for the currently drawn sample z (see the Supplement for details)  even though the
variance of the transformed variable (cid:15) is not one in such case.5 The reason is that gcorr suﬀers from
high variance in the same way as the score function estimator does.
3.2 Algorithm
We now present our full algorithm for g-rep. It requires the speciﬁcation of the variational family
and the transformation T .(cid:15)I v/. Given these  the full procedure is summarized in Algorithm 1. We
use the adaptive step-size sequence proposed by Kucukelbir et al. (2016)  which combines rmsprop
(Tieleman and Hinton  2012) and Adagrad (Duchi et al.  2011). Let g.i /
be the k-th component of the
gradient at the i-th iteration  and (cid:26).i /

the step-size for that component. We set

k

(cid:26).i /
k

D  (cid:2) i

k /2 C .1 (cid:0) (cid:13) /s.i(cid:0)1/
where we set  D 10
variational parameters as v.iC1/ D v.i / C (cid:26).i / ı rvL  where ‘ı’ is the element-wise product.

(13)
(cid:0)16  (cid:28) D 1  (cid:13) D 0:1  and we explore several values of . Thus  we update the

D (cid:13).g.i /

with

s.i /
k

s.i /
k

5Note that this introduces some bias since we are ignoring the dependence of (cid:27) .˛; ˇ/ on z.

k

;

;

(cid:0)0:5C (cid:2)

(cid:28) Cq

k

(cid:0)1

5

:data x  probabilistic model p.x; z/  variational family q.zI v/  transformation z D T .(cid:15)I v/

Algorithm 1: Generalized reparameterization gradient algorithm
input
output :variational parameters v
Initialize v
repeat

Compute the auxiliary functions h(cid:0)T

Draw a single sample z (cid:24) q.zI v/
Estimate grep and gcorr (Eq. 11  estimate the expectation with one sample)
Compute (analytic) or estimate (Monte Carlo) the gradient of the entropy  rvH Œq.zI v/
Compute the noisy gradient rvL (Eq. 12)
Set the step-size (cid:26).i / (Eq. 13) and take a gradient step for v

(cid:0)1.zI v/I v(cid:1) and u(cid:0)T

(cid:0)1.zI v/I v(cid:1) (Eq. 10)

until convergence

3.3 Related work
A closely related vi method is advi  which also relies on reparameterization and has been incorporated
into Stan (Kucukelbir et al.  2015  2016). advi applies a transformation to the random variables such
that their support is on the reals and then uses a Gaussian variational posterior on the transformed
space. For instance  random variables that are constrained to be positive are ﬁrst transformed through
a logarithmic function and then a Gaussian variational approximating distribution is placed on the
unconstrained space. Thus  advi struggles to approximate probability densities with singularities 
which are useful in models where sparsity is appropriate. In contrast  the g-rep method allows
to estimate the gradient for a wider class of variational distributions  including gamma and beta
distributions  which are more appropriate to encode sparsity constraints.
Schulman et al. (2015) also write the gradient in the form given in Eq. 12 to automatically estimate
the gradient through a backpropagation algorithm in the context of stochastic computation graphs.
However  they do not provide additional insight into this equation  do not apply it to general vi  do
not discuss transformations for any distributions  and do not report experiments. Thus  our paper
complements Schulman et al. (2015) and provides an oﬀ-the-shelf tool for general vi.
4 Experiments
We apply g-rep to perform mean-ﬁeld vi on two nonconjugate probabilistic models: the sparse
gamma deep exponential family (def) and a beta-gamma matrix factorization (mf) model. The sparse
gamma def (Ranganath et al.  2015) is a probabilistic model with several layers of latent locations
and latent weights  mimicking the architecture of a deep neural network. The weights of the model
0 run over latent components  and ` indexes the layer. The latent
are denoted by w.`/
locations are z.`/
  where n denotes the observation. We consider Poisson-distributed observations
xnd for each dimension d. Thus  the model is speciﬁed as

0  where k and k

nk

kk

xnd (cid:24) Poisson

;

z.`/
nk

˛z;

0 z.`C1/
0 w.`/
0
k
k
0 with rate 0:3 and shape 0:1  and a gamma prior with
We place gamma priors over the weights w`
. We set the hyperparameter ˛z D 0:1 
rate 0:1 and shape 0:1 over the top-layer latent variables z.L/
and we use L D 3 layers with 100  40  and 15 latent factors.
The second model is a beta-gamma mf model with weights wkd and latent locations znk. We use this
model to describe binary observations xnd   which are modeled as

nk

nk

kk

z.1/
nk

0 w.0/
0
d
k

:

!

 

(cid:24) Gamma

P

k

˛z

!

 X

0

k

!!

 

 X

xnd (cid:24) Bernoulli

sigmoid

logit .znk/ wkd

;

where logit .z/ D log.z=.1 (cid:0) z// and sigmoid .(cid:1)/ is the inverse logit function. We place a gamma
prior with shape 0:1 and rate 0:3 over the weights wkd   a uniform prior over the variables znk  and
we use K D 100 latent components.
Datasets. We apply the sparse gamma def on two diﬀerent databases: (i) the Olivetti database at
AT&T 6 which consists of 400 (320 for training and 80 for test) 64 (cid:2) 64 images of human faces in a 8

k

6http://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html

6

Dataset
Olivetti
nips
mnist
Omniglot

g-rep

bbvi

5
0:5
5
5

1
5
5
(cid:0)

advi
0:1
1
0:1
0:1

Dataset
Olivetti
nips
mnist
Omniglot

g-rep
0:46
0:83
1:09
5:50

bbvi
12:90
20:95
25:99
(cid:0)

advi
0:17
0:25
0:34
4:10

Table 1: (Left) Step-size constant   reported for completeness. (Right) Average time per iteration in
seconds. g-rep is 1-4 times slower than advi but above one order of magnitude faster than bbvi.
bit scale (0 (cid:0) 255); and (ii) the collection of papers at the Neural Information Processing Systems
(nips) 2011 conference  which consists of 305 documents and a vocabulary of 5715 eﬀective words
in a bag-of-words format (25% of words from all documents are set aside to form the test set).
We apply the beta-gamma mf on: (i) the binarized mnist data 7 which consists of 28 (cid:2) 28 images of
hand-written digits (we use 5000 training and 2000 test images); and (ii) the Omniglot dataset (Lake
et al.  2015)  which consists of 105 (cid:2) 105 images of hand-written characters from diﬀerent alphabets
(we select 10 alphabets  with 4425 training images  1475 test images  and 295 characters).
Evaluation. We apply mean-ﬁeld vi and we compare g-rep with bbvi (Ranganath et al.  2014) and
advi (Kucukelbir et al.  2016). We do not apply bbvi on the Omniglot dataset due to its computational
complexity. At each iteration  we evaluate the elbo using one sample from the variational distribution 
except for advi  for which we use 20 samples (for the Omniglot dataset  we only use one sample). We
run each algorithm with a ﬁxed computational budget of CPU time. After that time  we also evaluate
the predictive log-likelihood on the test set  averaging over 100 posterior samples. For the nips data 
we also compute the test perplexity (with one posterior sample) every 10 iterations  given by

 (cid:0)PdocsP

exp

w2doc.d /

log p.w j #held out in doc.d //

#held out words

!

:

Experimental setup. To estimate the gradient  we use 30 Monte Carlo samples for bbvi  and only 1
for advi and g-rep. For bbvi  we use Rao-Blackwellization and control variates (we use a separate
set of 30 samples to estimate the control variates). For bbvi and g-rep  we use beta and gamma
variational distributions  whereas advi uses Gaussian distributions on the transformed space  which
correspond to log-normal or logit-normal distributions on the original space. Thus  only g-rep and
bbvi optimize the same variational family. We parameterize the gamma distribution in terms of
its shape and mean  and the beta in terms of its shape parameters ˛ and ˇ. To avoid constrained
0 D log.exp.v/ (cid:0) 1/ to the variational parameters that are
optimization  we apply the transformation v
0. We use the analytic
constrained to be positive and take stochastic gradient steps with respect to v
gradient of the entropy terms. We implement advi as described by Kucukelbir et al. (2016).
We use the step-size schedule in Eq. 13  and we explore the parameter  2 f0:1; 0:5; 1; 5g. For each
algorithm and each dataset  we report the results based on the value of  for which the best elbo was
achieved. We report the values of  in Table 1 (left).
Results. We show in Figure 1 the evolution of the elbo as a function of the running time for
three of the considered datasets. bbvi converges slower than the rest of the methods  since each
iteration involves drawing multiple samples and evaluating the log-joint for each of them. advi and
g-rep achieve similar bounds  except for the mnist dataset  for which g-rep provides a variational
approximation that is closer to the posterior  since the elbo is higher. This is because a variational
family with sparse gamma and beta distributions provides a better ﬁt to the data than the variational
family to which advi is limited (log-normal and logit-normal). advi seems to converge slower;
however  we do not claim that advi converges slower than g-rep in general. Instead  the diﬀerence
may be due to the diﬀerent step-sizes schedules that we found to be optimal (see Table 1). We also
report in Table 1 (right) the average time per iteration8 for each method: bbvi is the slowest method 
and advi is the fastest because it involves simulation of Gaussian random variables only.
However  g-rep provides higher likelihood values than advi. We show in Figure 2a the evolution of
the perplexity (lower is better) for the nips dataset  and in Figure 2b the resulting test log-likelihood
(larger is better) for the rest of the considered datasets. In Figure 2b  we report the mean and standard
deviation over 100 posterior samples. advi cannot ﬁt the data as well as g-rep or bbvi because it is
constrained to log-normal and logit-normal variational distributions. These cannot capture sparsity 

7http://yann.lecun.com/exdb/mnist
8On the full mnist with 50; 000 training images  g-rep (advi) took 8:08 (2:04) seconds per iteration.

7

(a) elbo (Olivetti dataset).

(b) elbo (mnist dataset).

(c) elbo (Omniglot dataset).

Figure 1: Comparison between g-rep  bbvi  and advi in terms of the variational objective function.

g-rep

Dataset
(cid:0)4:63 ˙ 0:01
(cid:0)4:48 ˙ 0:01
Olivetti
mnist (cid:0)0:0932 ˙ 0:0004 (cid:0)0:0888 ˙ 0:0004 (cid:0)0:189 ˙ 0:009
Omniglot (cid:0)0:0472 ˙ 0:0001
(cid:0)0:0823 ˙ 0:0009

(cid:0)9:74 ˙ 0:08

(cid:0)

bbvi

advi

(b) Average test log-likelihood per entry xnd

.

(a) Perplexity (nips dataset).

Figure 2: Comparison between g-rep  bbvi  and advi in terms of performance on the test set. g-rep
outperforms bbvi because the latter has not converged in the allowed time  and it also outperforms
advi because of the variational family it uses.
which is an important feature for the considered models. We can also conclude this by a simple visual
inspection of the ﬁtted models. In the Supplement  we compare images sampled from the g-rep and
the advi posteriors  where we can observe that the latter are more blurry or lack some details.
5 Conclusion
We have introduced the generalized reparameterization gradient (g-rep)  a technique to extend the
standard reparameterization gradient to a wider class of variational distributions. As the standard
reparameterization method  our method is applicable to any probabilistic model that is diﬀerentiable
with respect to the latent variables. We have demonstrated the generalized reparameterization gradient
on two nonconjugate probabilistic models to ﬁt a variational approximation involving gamma and
beta distributions. We have also empirically shown that a single Monte Carlo sample is enough to
obtain a noisy estimate of the gradient  therefore leading to a fast inference procedure.
Acknowledgments
This project has received funding from the EU H2020 programme (Marie Skłodowska-Curie grant
agreement 706760)  NFS IIS-1247664  ONR N00014-11-1-0651  DARPA FA8750-14-2-0009 
DARPA N66001-15-C-4032  Adobe  the John Templeton Foundation  and the Sloan Foundation. The
authors would also like to thank Kriste Krstovski  Alp Kuckukelbir  and Christian A. Naesseth for
helpful comments and discussions.
References
Baydin  A. G.  Pearlmutter  B. A.  and Radul  A. A. (2015). Automatic diﬀerentiation in machine learning: a

survey. arXiv:1502.05767.

Bonnet  G. (1964). Transformations des signaux aléatoires a travers les systemes non linéaires sans mémoire.

Annals of Telecommunications  19(9):203–220.

Carbonetto  P.  King  M.  and Hamze  F. (2009). A stochastic approximation method for inference in probabilistic

graphical models. In Advances in Neural Information Processing Systems.

Casella  G. and Robert  C. P. (1996). Rao-Blackwellisation of sampling schemes. Biometrika  83(1):81–94.
Duchi  J.  Hazan  E.  and Singer  Y. (2011). Adaptive subgradient methods for online learning and stochastic

optimization. Journal of Machine Learning Research  12:2121–2159.

Fan  K.  Wang  Z.  Beck  J.  Kwok  J.  and Heller  K. A. (2015). Fast second order stochastic backpropagation for

variational inference. In Advances in Neural Information Processing Systems.

Ghahramani  Z. and Beal  M. J. (2001). Propagation algorithms for variational Bayesian learning. In Advances

in Neural Information Processing Systems.

Glynn  P. W. (1990). Likelihood ratio gradient estimation for stochastic systems. Communications of the ACM 

33(10):75–84.

8

00.511.522.533.5−2.5−2−1.5−1−0.5x 107Time (h)ELBOOlivetti G−REPBBVIADVI02468−3−2.5−2−1.5−1−0.5x 106Time (h)ELBOMNIST G−REPBBVIADVI051015−5−4−3−2−1x 107Time (h)ELBOOmniglot G−REPADVI01234561000150020002500Time (h)Test perplexityNIPS G−REPBBVIADVIGu  S.  Levine  S.  Sutskever  I.  and Mnih  A. (2016). MuProp: Unbiased backpropagation for stochastic neural

networks. In International Conference on Learning Representations.

Hinton  G.  Dayan  P.  Frey  B. J.  and Neal  R. M. (1995). The wake-sleep algorithm for unsupervised neural

networks. Science  268(5214):1158–1161.

Jordan  M. I.  Ghahramani  Z.  Jaakkola  T. S.  and Saul  L. K. (1999). An introduction to variational methods

for graphical models. Machine Learning  37(2):183–233.

Kingma  D. P. and Welling  M. (2014). Auto-encoding variational Bayes. In International Conference on

Learning Representations.

Knowles  D. A. (2015).
arXiv:1509.01631v1.

Stochastic gradient variational Bayes for gamma approximating distributions.

Kucukelbir  A.  Ranganath  R.  Gelman  A.  and Blei  D. M. (2015). Automatic variational inference in Stan. In

Advances in Neural Information Processing Systems.

Kucukelbir  A.  Tran  D.  Ranganath  R.  Gelman  A.  and Blei  D. M. (2016). Automatic diﬀerentiation variational

inference. arXiv:1603.00788.

Lake  B. M.  Salakhutdinov  R.  and Tenenbaum  J. B. (2015). Human-level concept learning through probabilistic

program induction. Science  350(6266):1332–1338.

Mnih  A. and Gregor  K. (2014). Neural variational inference and learning in belief networks. In International

Conference on Machine Learning.

Neal  R. (1992). Connectionist learning of belief networks. Artiﬁcial Intelligence  56(1):71–113.
Paisley  J. W.  Blei  D. M.  and Jordan  M. I. (2012). Variational Bayesian inference with stochastic search. In

International Conference on Machine Learning.

Price  R. (1958). A useful theorem for nonlinear devices having Gaussian inputs. IRE Transactions on Information

Theory  4(2):69–72.

Ranganath  R.  Gerrish  S.  and Blei  D. M. (2014). Black box variational inference. In Artiﬁcial Intelligence and

Statistics.

Ranganath  R.  Tang  L.  Charlin  L.  and Blei  D. M. (2015). Deep exponential families. In Artiﬁcial Intelligence

and Statistics.

Rezende  D. J.  Mohamed  S.  and Wierstra  D. (2014). Stochastic backpropagation and approximate inference in

deep generative models. In International Conference on Machine Learning.

Ross  S. M. (2002). Simulation. Elsevier.
Ruiz  F. J. R.  Titsias  M. K.  and Blei  D. M. (2016). Overdispersed black-box variational inference.

Uncertainty in Artiﬁcial Intelligence.

In

Salimans  T. and Knowles  D. A. (2013). Fixed-form variational posterior approximation through stochastic

linear regression. Bayesian Analysis  8(4):837–882.

Schulman  J.  Heess  N.  Weber  T.  and Abbeel  P. (2015). Gradient estimation using stochastic computation

graphs. In Advances in Neural Information Processing Systems.

Tieleman  T. and Hinton  G. (2012). Lecture 6.5-RMSPROP: Divide the gradient by a running average of its

recent magnitude. Coursera: Neural Networks for Machine Learning  4.

Titsias  M. K. and Lázaro-Gredilla  M. (2014). Doubly stochastic variational Bayes for non-conjugate inference.

In International Conference on Machine Learning.

Titsias  M. K. and Lázaro-Gredilla  M. (2015). Local expectation gradients for black box variational inference.

In Advances in Neural Information Processing Systems.

van de Meent  J.-W.  Tolpin  D.  Paige  B.  and Wood  F. (2016). Black-box policy search with probabilistic

programs. In Artiﬁcial Intelligence and Statistics.

Wainwright  M. J. and Jordan  M. I. (2008). Graphical models  exponential families  and variational inference.

Foundations and Trends in Machine Learning  1(1–2):1–305.

Williams  R. J. (1992). Simple statistical gradient-following algorithms for connectionist reinforcement learning.

Automated variational inference in probabilistic programming.

9

Machine Learning  8(3–4):229–256.
Wingate  D. and Weber  T. (2013).

arXiv:1301.1299.

,Yuanyuan Mi
Luozheng Li
Dahui Wang
Si Wu
Francisco Ruiz
Michalis Titsias RC AUEB
David Blei