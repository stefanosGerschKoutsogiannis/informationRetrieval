2014,Learning Time-Varying Coverage Functions,Coverage functions are an important class of discrete functions that capture laws of diminishing returns. In this paper  we propose a new problem of learning time-varying coverage functions which arise naturally from applications in social network analysis  machine learning  and algorithmic game theory. We develop a novel parametrization of the time-varying coverage function by illustrating the connections with counting processes. We present an efficient algorithm to learn the parameters by maximum likelihood estimation  and provide a rigorous theoretic analysis of its sample complexity. Empirical experiments from information diffusion in social network analysis demonstrate that with few assumptions about the underlying diffusion process  our method performs significantly better than existing approaches on both synthetic and real world data.,Learning Time-Varying Coverage Functions

Nan Du†  Yingyu Liang‡  Maria-Florina Balcan(cid:5)  Le Song†

†College of Computing  Georgia Institute of Technology
‡Department of Computer Science  Princeton University
(cid:5)School of Computer Science  Carnegie Mellon University
dunan@gatech.edu yingyul@cs.princeton.edu

ninamf@cs.cmu.edu lsong@cc.gatech.edu

Abstract

Coverage functions are an important class of discrete functions that capture the
law of diminishing returns arising naturally from applications in social network
analysis  machine learning  and algorithmic game theory. In this paper  we pro-
pose a new problem of learning time-varying coverage functions  and develop a
novel parametrization of these functions using random features. Based on the con-
nection between time-varying coverage functions and counting processes  we also
propose an efﬁcient parameter learning algorithm based on likelihood maximiza-
tion  and provide a sample complexity analysis. We applied our algorithm to the
inﬂuence function estimation problem in information diffusion in social networks 
and show that with few assumptions about the diffusion processes  our algorithm
is able to estimate inﬂuence signiﬁcantly more accurately than existing approaches
on both synthetic and real world data.

Introduction

1
Coverage functions are a special class of the more general submodular functions which play impor-
tant role in combinatorial optimization with many interesting applications in social network anal-
ysis [1]  machine learning [2]  economics and algorithmic game theory [3]  etc. A particularly
important example of coverage functions in practice is the inﬂuence function of users in information
diffusion modeling [1] — news spreads across social networks by word-of-mouth and a set of inﬂu-
ential sources can collectively trigger a large number of follow-ups. Another example of coverage
functions is the valuation functions of customers in economics and game theory [3] — customers are
thought to have certain requirements and the items being bundled and offered fulﬁll certain subsets
of these demands.
Theoretically  it is usually assumed that users’ inﬂuence or customers’ valuation are known in ad-
vance as an oracle. In practice  however  these functions must be learned. For example  given past
traces of information spreading in social networks  a social platform host would like to estimate
how many follow-ups a set of users can trigger. Or  given past data of customer reactions to differ-
ent bundles  a retailer would like to estimate how likely customer would respond to new packages of
goods. Learning such combinatorial functions has attracted many recent research efforts from both
theoretical and practical sides (e.g.  [4  5  6  7  8])  many of which show that coverage functions can
be learned from just polynomial number of samples.
However  the prior work has widely ignored an important dynamic aspect of the coverage functions.
For instance  information spreading is a dynamic process in social networks  and the number of
follow-ups of a ﬁxed set of sources can increase as observation time increases. A bundle of items
or features offered to customers may trigger a sequence of customer actions over time. These real
world problems inspire and motivate us to consider a novel time-varying coverage function  f (S  t) 
which is a coverage function of the set S when we ﬁx a time t  and a continuous monotonic function
of time t when we ﬁx a set S. While learning time-varying combinatorial structures has been ex-

1

plored in graphical model setting (e.g.  [9  10])  as far as we are aware of  learning of time-varying
coverage function has not been addressed in the literature. Furthermore  we are interested in esti-
mating the entire function of t  rather than just treating the time t as a discrete index and learning
the function value at a small number of discrete points. From this perspective  our formulation is the
generalization of the most recent work [8] with even less assumptions about the data used to learn
the model.
Generally  we assume that the historical data are provided in pairs of a set and a collection of times-
tamps when caused events by the set occur. Hence  such a collection of temporal events associated
with a particular set Si can be modeled principally by a counting process Ni(t)  t (cid:62) 0 which is a
stochastic process with values that are positive  integer  and increasing along time [11]. For instance 
in the information diffusion setting of online social networks  given a set of earlier adopters of some
new product  Ni(t) models the time sequence of all triggered events of the followers  where each
jump in the process records the timing tij of an action. In the economics and game theory setting  the
counting process Ni(t) records the number of actions a customer has taken over time given a partic-
ular bundled offer. This essentially raises an interesting question of how to estimate the time-varying
coverage function from the angle of counting processes. We thus propose a novel formulation which
builds a connection between the two by modeling the cumulative intensity function of a counting
process as a time-varying coverage function. The key idea is to parametrize the intensity function
as a weighted combination of random kernel functions. We then develop an efﬁcient learning algo-
rithm TCOVERAGELEARNER to estimate the parameters of the function using maximum likelihood
approach. We show that our algorithm can provably learn the time-varying coverage function using
only polynomial number of samples. Finally  we validate TCOVERAGELEARNER on both inﬂuence
estimation and maximization problems by using cascade data from information diffusion. We show
that our method performs signiﬁcantly better than alternatives with little prior knowledge about the
dynamics of the actual underlying diffusion processes.

2 Time-Varying Coverage Function
We will ﬁrst give a formal deﬁnition of the time-varying coverage function  and then explain its
additional properties in details.
Deﬁnition. Let U be a (potentially uncountable) domain. We endow U with some σ-algebra A and
denote a probability distribution on U by P. A coverage function is a combinatorial function over a
ﬁnite set V of items  deﬁned as

(1)
where Us ⊂ U is the subset of domain U covered by item s ∈ V  and Z is the additional nor-
malization constant. For time-varying coverage functions  we let the size of the subset Us to grow
monotonically over time  that is

 

s∈S Us

for all S ∈ 2V  

f (S) := Z · P(cid:16)(cid:91)

(cid:17)

for all t (cid:54) τ and s ∈ V 

(2)

which results in a combinatorial temporal function

Us(t) ⊆ Us(τ ) 

f (S  t) = Z · P(cid:16)(cid:91)

(cid:17)

 

for all S ∈ 2V .

s∈S Us(t)
(3)
In this paper  we assume that f (S  t) is smooth and continuous  and its ﬁrst order derivative with
respect to time  f(cid:48)(S  t)  is also smooth and continuous.
Representation. We now show that a time-varying coverage function  f (S  t)  can be represented
as an expectation over random functions based on multidimensional step basis functions. Since
Us(t) is varying over time  we can associate each u ∈ U with a |V|-dimensional vector τu of change
points. In particular  the s-th coordinate of τu records the time that source node s covers u. Let τ
to be a random variable obtained by sampling u according to P and setting τ = τu. Note that given
all τu we can compute f (S  t); now we claim that the distribution of τ is sufﬁcient.
We ﬁrst introduce some notations. Based on τu we deﬁne a |V|-dimensional step function ru(t) :
R+ (cid:55)→ {0  1}|V|
  where the s-th dimension of ru(t) is 1 if u is covered by the set Us(t) at time t  and
0 otherwise. To emphasize the dependence of the function ru(t) on τu  we will also write ru(t) as
ru(t|τu). We denote the indicator vector of a set S by χS ∈ {0  1}|V| where the s-th dimension of
S ru(t) (cid:62) 1.

χS is 1 if s ∈ S  and 0 otherwise. Then u ∈ U is covered by(cid:83)

s∈S Us(t) at time t if χ(cid:62)

2

Lemma 1. There exists a distribution Q(τ ) over the vector of change points τ   such that the time-
varying coverage function can be represented as

f (S  t) = Z · Eτ∼Q(τ )

(cid:2)φ(χ(cid:62)
S r(t|τ ))(cid:3)

(4)

where φ(x) := min{x  1}  and r(t|τ ) is a multidimensional step function parameterized by τ .
s∈S Us(t). By deﬁnition (3)  we have the following integral representation
I{u ∈ US} dP(u) = Z ·

f (S  t) = Z ·
We can deﬁne the set of u having the same τ as Uτ := {u ∈ U | τu = τ} and deﬁne a distribution

(cid:2)φ(χ(cid:62)
S ru(t))(cid:3) .

Proof. Let US :=(cid:83)
(cid:90)
over τ as dQ(τ ) :=(cid:82)

dP(u). Then the integral representation of f (S  t) can be rewritten as

φ(χ(cid:62)

S ru(t)) dP(u) = Z · Eu∼P(u)

(cid:2)φ(χ(cid:62)
S ru(t))(cid:3) = Z · Eτ∼Q(τ )

(cid:2)φ(χ(cid:62)
S r(t|τ ))(cid:3)  

Uτ
Z · Eu∼P(u)

(cid:90)

U

U

which proves the lemma.

3 Model for Observations
In general  we assume that the input data are provided in the form of pairs  (Si  Ni(t))  where Si is
a set  and Ni(t) is a counting process in which each jump of Ni(t) records the timing of an event.
We ﬁrst give a brief overview of a counting process [11] and then motivate our model in details.
Counting Process. Formally  a counting process {N (t)  t (cid:62) 0} is any nonnegative  integer-valued
stochastic process such that N (t(cid:48)) (cid:54) N (t) whenever t(cid:48) (cid:54) t and N (0) = 0. The most common
use of a counting process is to count the number of occurrences of temporal events happening along
time  so the index set is usually taken to be the nonnegative real numbers R+. A counting process
is a submartingale: E[N (t)|Ht(cid:48)] (cid:62) N (t(cid:48)) for all t > t(cid:48) where Ht(cid:48) denotes the history up to time t(cid:48).
By Doob-Meyer theorem [11]  N (t) has the unique decomposition:

(5)
where Λ(t) is a nondecreasing predictable process called the compensator (or cumulative intensity) 
and M (t) is a mean zero martingale. Since E[dM (t)|Ht− ] = 0  where dM (t) is the increment of
M (t) over a small time interval [t  t + dt)  and Ht− is the history until just before time t 

N (t) = Λ(t) + M (t)

E[dN (t)|Ht− ] = dΛ(t) := a(t) dt

(6)

where a(t) is called the intensity of a counting process.
Model formulation. We assume that the cumulative intensity of the counting process is modeled
by a time-varying coverage function  i.e.  the observation pair (Si  Ni(t)) is generated by

Ni(t) = f (Si  t) + Mi(t)

(7)
in the time window [0  T ] for some T > 0  and df (S  t) = a(S  t)dt. In other words  the time-
varying coverage function controls the propensity of occurring events over time. Speciﬁcally  for a
ﬁxed set Si  as time t increases  the cumulative number of events observed grows accordingly for
that f (Si  t) is a continuous monotonic function over time; for a given time t  as the set Si changes
to another set Sj  the amount of coverage over domain U may change and hence can result in a
different cumulative intensity. This abstract model can be mapped to real world applications. In
the information diffusion context  for a ﬁxed set of sources Si  as time t increases  the number of
inﬂuenced nodes in the social network tends to increase; for a given time t  if we change the sources
to Sj  the number of inﬂuenced nodes may be different depending on how inﬂuential the sources
are. In the economics and game theory context  for a ﬁxed bundle of offers Si  as time t increases  it
is more likely that the merchant will observe the customers’ actions in response to the offers; even
at the same time t  different bundles of offers  Si and Sj  may have very different ability to drive the
customers’ actions.
Compared to a regression model yi = g(Si) + i with i.i.d. input data (Si  yi)  our model outputs
a special random function over time  that is  a counting process Ni(t) with the noise being a zero
mean martingale Mi(t). In contrast to functional regression models  our model exploits much more
interesting structures of the problem. For instance  the random function representation in the last
section can be used to parametrize the model. Such special structure of the counting process allows
us to estimate the parameter of our model using maximum likelihood approach efﬁciently  and the
martingale noise enables us to use exponential concentration inequality in analyzing our algorithm.

3

4 Parametrization
Based on the following two mild assumptions  we will show how to parametrize the intensity func-
tion as a weighted combination of random kernel functions  learn the parameters by maximum
likelihood estimation  and eventually derive a sample complexity.

is absolutely continuous with(cid:82) ¨a(t)dt < ∞.

(A1) a(S  t) is smooth and bounded on [0  T ]: 0 < amin (cid:54) a (cid:54) amax < ∞  and ¨a := d2a/dt2
(A2) There is a known distribution Q(cid:48)(τ ) and a constant C with Q(cid:48)(τ )/C (cid:54) Q(τ ) (cid:54) CQ(cid:48)(τ ).
Kernel Smoothing To facilitate our ﬁnite dimensional parameterization  we ﬁrst convolve the
√
intensity function with K(t) = k(t/σ)/σ where σ is the bandwidth parameter and k is a kernel
function (such as the Gaussian RBF kernel k(t) = e−t2/2/

2π) with

0 (cid:54) k(t) (cid:54) κmax 

k(t) dt = 1 

(8)
The convolution results in a smoothed intensity aK(S  t) = K(t) (cid:63) (df (S  t)/dt) = d(K(t) (cid:63)
Λ(S  t))/dt. By the property of convolution and exchanging derivative with integral  we have that
aK(S  t) = d(Z · Eτ∼Q(τ )[K(t) (cid:63) φ(χ(cid:62)

t k(t) dt = 0 

and σ2

k :=

t2k(t) dt < ∞.

(cid:2)d(K(t) (cid:63) φ(χ(cid:62)

S r(t|τ )])/dt

S r(t|τ ))/dt(cid:3)

= Z · Eτ∼Q(τ )
= Z · Eτ∼Q(τ ) [K(t) (cid:63) δ(t − t(S  r)]
= Z · Eτ∼Q(τ ) [K(t − t(S  τ ))]

by deﬁnition of f (·)
exchange derivative and integral
by property of convolution and function φ(·)
by deﬁnition of δ(·)

(cid:90)

(cid:90)

S r(t|τ )) jumps from 0 to 1. If we choose small enough
where t(S  τ ) is the time when function φ(χ(cid:62)
kernel bandwidth  aK only incurs a small bias from a. But the smoothed intensity still results in
inﬁnite number of parameters  due to the unknown distribution Q(τ ). To address this problem  we
design the following random approximation with ﬁnite number of parameters.

(cid:90)

i=1

Z
C

(cid:41)

A =

ESEt

(cid:54) ZC

(cid:82) T

W(cid:88)

(cid:54) (cid:107)w(cid:107)1

w (S  t) =
aK

Random Function Approximation The key idea is to sample a collection of W random change
points τ from a known distribution Q(cid:48)(τ ) which can be different from Q(τ ). If Q(cid:48)(τ ) is not very
far way from Q(τ )  the random approximation will be close to aK  and thus close to a. More
speciﬁcally  we will denote the space of weighted combination of W random kernel function by
 {τi} i.i.d.∼ Q(cid:48)(τ ).

Lemma 2. If W = ˜O(Z 2/(σ)2)  then with probability (cid:62) 1 − δ  there exists an(cid:101)a ∈ A such that

(cid:40)
(cid:2)(a(S  t) −(cid:101)a(S  t))2(cid:3) := ES∼P(S)

(cid:2)(a(S  t) −(cid:101)a(S  t))2(cid:3) dt/T = O(2 + σ4).

wi K(t − t(S  τi)) : w (cid:62) 0 

) to get O(2) approximation error.

√
The lemma then suggests to set the kernel bandwidth σ = O(
5 Learning Algorithm
We develop a learning algorithm  referred to as TCOVERAGELEARNER  to estimate the parameters
w (S  t) by maximizing the joint likelihood of all observed events based on convex optimization
of aK
techniques as follows.
Maximum Likelihood Estimation Instead of directly estimating the time-varying coverage func-
tion  which is the cumulative intensity function of the counting process  we turn to estimate
the intensity function a(S  t) = ∂Λ(S  t)/∂t. Given m i.i.d. counting processes  Dm :=
{(S1  N1(t))  . . .   (Sm  Nm(t))} up to observation time T   the log-likelihood of the dataset is [11]

(9)

0

(cid:96)(Dm|a) =

{log a(Si  t)} dNi(t) −

a(Si  t) dt

(10)
Maximizing the log-likelihood with respect to the intensity function a(S  t) then gives us the esti-

mation(cid:98)a(S  t). The W -term random kernel function approximation reduces a function optimization

problem to a ﬁnite dimensional optimization problem  while incurring only small bias in the esti-
mated function.

i=1

0

0

.

(cid:90) T

(cid:41)

(cid:40)(cid:90) T

m(cid:88)

4

Algorithm 1 TCOVERAGELEARNER

INPUT : {(Si  Ni(t))}   i = 1  . . .   m;
Sample W random features τ1  . . .   τW from Q(cid:48)(τ );
Compute {t(Si  τw)}  {gi}  {k(tij)}   i ∈ {1  . . .   m}   w = 1  . . .   W  tij < T ;
Initialize w0 ∈ Ω = {w (cid:62) 0 (cid:107)w(cid:107)1 (cid:54) 1};
Apply projected quasi-newton algorithm [12] to solve 11;
OUTPUT : aK

i=1 wi K(t − t(S  τi))

Convex Optimization. By plugging the parametrization aK
we formulate the optimization problem as :

w (S  t) (9) into the log-likelihood (10) 

log(cid:0)w(cid:62)k(tij)(cid:1) subject to w (cid:62) 0  (cid:107)w(cid:107)1 (cid:54) 1 

min
w

where we deﬁne

w (S  t) =(cid:80)W
w(cid:62)gi − (cid:88)
(cid:90) T

m(cid:88)

i=1

tij <T

gik =

0

(11)

(12)

 .

K (t − t(Si  τk)) dt

and kl(tij) = K(tij − t(Si  τl)) 

tij when the j-th event occurs in the i-th counting process. By treating the normalization constant
Z as a free variable which will be tuned by cross validation later  we simply require that (cid:107)w(cid:107)1 (cid:54) 1.
By applying the Gaussian RBF kernel  we can derive a closed form of gik and the gradient (cid:79)(cid:96) as

(cid:18) T − t(Si  τk)

(cid:19)(cid:27)

√

2h

  (cid:79)(cid:96) =

gi − (cid:88)

tij <T

m(cid:88)

i=1

k(tij)
w(cid:62)k(tij)

(cid:26)

(cid:18)

(cid:19)

gik =

1
2

erfc

− t(Si  τk)√

2h

− erfc

i=1 on each random feature {τw}W

(13)
A pleasing feature of this formulation is that it is convex in the argument w  allowing us to apply
various convex optimization techniques to solve the problem efﬁciently. Speciﬁcally  we ﬁrst draw
W random features τ1  . . .   τW from Q(cid:48)(τ ). Then  we precompute the jumping time t(Si  τw)
for every source set {Si}m
w=1. Because in general |Si| << n 
this computation costs O(mW ). Based on the achieved m-by-W jumping-time matrix  we prepro-
i=1 and k(tij)  i ∈ {1  . . .   m}   tij < T   which costs O(mW ) and
cess the feature vectors {gi}m
O(mLW ) where L is the maximum number of events caused by a particular source set before time
T . Finally  we apply the projected quasi-newton algorithm [12] to ﬁnd the weight w that minimizes
the negative log-likelihood of observing the given event data. Because the evaluation of the objective
function and the gradient  which costs O(mLW )  is much more expensive than the projection onto
the convex constraint set  and L << n  the worst case computation complexity is thus O(mnW ).
Algorithm 1 summarizes the above steps in the end.
Sample Strategy. One important constitution of our parametrization is to sample W random change
points τ from a known distribution Q(cid:48)(τ ). Because given a set Si  we can only observe the jumping
time of the events in each counting process without knowing the identity of the covered items (which
is a key difference from [8])  the best thing we can do is to sample from these historical data.
Speciﬁcally  let the number of counting processes that a single item s ∈ V is involved to induce
be Ns  and the collection of all the jumping timestamps before time T be Js. Then  for the s-th
entry of τ   with probability |Js|/nNs  we uniformly draw a sample from Js; and with probability
1 − |Js|/nNs  we assign a time much greater than T to indicate that the item will never be covered
until inﬁnity. Given the very limited information  although this Q(cid:48)(τ ) might be quite different from
Q(τ )  by drawing sufﬁciently large number of samples and adjusting the weights  we expect it still
can lead to good results  as illustrated in our experiments later.

6 Sample Complexity

Suppose we use W random features and m training examples to compute an (cid:96)-MLE solution(cid:98)a  i.e. 
The goal is to analyze how well the function (cid:98)f induced by(cid:98)a approximates the true function f. This

(cid:96)(Dm|(cid:98)a) (cid:62) max

a(cid:48)∈A (cid:96)(Dm|a(cid:48)) − (cid:96).

sections describes the intuition and the complete proof is provided in the appendix.

5

A natural choice for connecting the error between f and (cid:98)f with the log-likelihood cost used in MLE
h(a (cid:98)a) between(cid:98)a and the true intensity a  for which we need to show a high probability bound on
the (total) empirical Hellinger distance (cid:98)H 2(a  a(cid:48)) between the two. Here  h and (cid:98)H are deﬁned as

is the Hellinger distance [13]. So it sufﬁces to prove an upper bound on the Hellinger distance

(cid:104)(cid:112)a(S  t) −(cid:112)a(cid:48)(S  t)
(cid:105)2
(cid:90) T
(cid:104)(cid:112)a(Si  t) −(cid:112)a(cid:48)(Si  t)
(cid:105)2

 

dt.

h2(a  a(cid:48)) :=

(cid:98)H 2(a  a(cid:48)) :=

1
2
1
2

ESEt

m(cid:88)

i=1

0

The key for the analysis is to show that the empirical Hellinger distance can be bounded by a mar-
tingale plus some other additive error terms  which we then bound respectively. This martingale is
deﬁned based on our hypotheses and the martingales Mi associated with the counting process Ni:

M (t|g) :=

(cid:32)(cid:88)
(cid:90) t
(cid:110)
2a : a(cid:48) ∈ A(cid:111)
Lemma 3. Suppose(cid:98)a is an (cid:96)-MLE. Then
(cid:98)H 2 ((cid:98)a  a) (cid:54) 16M (T ; g(cid:98)a) + 4

where g ∈ G =

2 log a+a(cid:48)

ga(cid:48) = 1

g(t)d

0

i

(cid:20)

(cid:33)

(cid:90) t

m(cid:88)

i=1

0

Mi(t)

=

g(t)dMi(t)

. More precisely  we have the following lemma.

(cid:21)
a(cid:48)∈A (cid:96)(Dm|a(cid:48))

(cid:96)(Dm|a) − max

+ 4(cid:96).

The right hand side has three terms: the martingale (estimation error)  the likelihood gap between
the truth and the best one in our hypothesis class (approximation error)  and the optimization error.
We then focus on bounding the martingale and the likelihood gap.
To bound the martingale  we ﬁrst introduce a notion called (d  d(cid:48))-covering dimension measuring
the complexity of the hypothesis class  generalizing that in [14]. Based on this notion  we prove
a uniform convergence inequality  combining the ideas in classic works on MLE [14] and count-
ing process [15]. Compared to the classic uniform inequality  our result is more general  and the
complexity notion has more clear geometric interpretation and are thus easier to verify. For the like-
lihood gap  recall that by Lemma 2  there exists an good approximation ˜a ∈ A. The likelihood gap
is then bounded by that between a and ˜a  which is small since a and ˜a are close.
Combining the two leads to a bound on the Hellinger distance based on bounded dimension of the
hypothesis class. We then show that the dimension of our speciﬁc hypothesis class is at most the

number of random features W   and convert (cid:98)H 2((cid:98)a  a) to the desired (cid:96)2 error bound on f and (cid:98)f.
[W + (cid:96)](cid:1). Then

and m = ˜O(cid:0) ZT

(cid:18)

Z 2

+

Theorem 4. Suppose W = ˜O
with probability (cid:62) 1 − δ over the random sample of {τi}W

amin



i=1  we have that for any 0 (cid:54) t (cid:54) T  

(cid:20)(cid:0) ZT
(cid:16) ZT
(cid:1)5/2
(cid:104)(cid:98)f (S  t) − f (S  t)

(cid:17)5/4(cid:21)(cid:19)
(cid:105)2 (cid:54) .

ES



The theorem shows that the number of random functions needed to achieve  error is roughly
O(−5/2)  and the sample size is O(−7/2). They also depend on amin  which means with more
random functions and data  we can deal with intensities with more extreme values. Finally  they
increase with the time T   i.e.  it is more difﬁcult to learn the function values at later time points.
7 Experiments
We evaluate TCOVERAGELEARNER on both synthetic and real world information diffusion data.
We show that our method can be more robust to model misspeciﬁcation than other state-of-the-art
alternatives by learning a temporal coverage function all at once.
7.1 Competitors
Because our input data only include pairs of a source set and the temporal information of its trig-
gered events {(Si  Ni(t))}m
i=1 with unknown identity  we ﬁrst choose the general kernel ridge re-
gression model as the major baseline  which directly estimates the inﬂuence value of a source set

6

(a) Weibull (CIC)

(b) Exponential (CIC)

(c) DIC

(d) LT

Figure 1: MAE of the estimated inﬂuence on test data along time with the true diffusion model being
continuous-time independent cascade with pairwise Weibull (a) and Exponential (b) transmission
functions  (c) discrete-time independent cascade model and (d) linear-threshold cascade model.
χS by f (χS ) = k(χS )(K + λI)−1y where k(χS ) = K(χSi  χS )  and K is the kernel ma-
trix. We discretize the time into several steps and ﬁt a separate model to each of them. Between
two consecutive time steps  the predictions are simply interpolated. In addition  to further demon-
strate the robustness of TCOVERAGELEARNER  we compare it to the two-stage methods which
must know the identity of the nodes involved in an information diffusion process to ﬁrst learn
a speciﬁc diffusion model based on which they can then estimate the inﬂuence. We give them
such an advantage and study three well-known diffusion models : (I) Continuous-time Independent
Cascade model(CIC)[16  17]; (II) Discrete-time Independent Cascade model(DIC)[1]; and (III)
Linear-Threshold cascade model(LT)[1].

√

Inﬂuence Estimation on Synthetic Data

7.2
We generate Kronecker synthetic networks ([0.9 0.5;0.5 0.3]) which mimic real world information
diffusion patterns [18]. For CIC  we use both Weibull distribution (Wbl) and Exponential distribu-
tion (Exp) for the pairwise transmission function associated with each edge  and randomly set their
parameters to capture the heterogeneous temporal dynamics. Then  we use NETRATE [16] to learn
the model by assuming an exponential pairwise transmission function. For DIC  we choose the pair-
wise infection probability uniformly from 0 to 1 and ﬁt the model by [19]. For LT  we assign the edge
weight wuv between u and v as 1/dv  where dv is the degree of node v following [1]. Finally  1 024
source sets are sampled with power-law distributed cardinality (with exponent 2.5)  each of which
induces eight independent cascades(or counting processes)  and the test data contains another 128
independently sampled source sets with the ground truth inﬂuence estimated from 10 000 simulated
cascades up to time T = 10. Figure 1 shows the MAE(Mean Absolute Error) between the estimated
inﬂuence value and the true value up to the observation window T = 10. The average inﬂuence
is 16.02  36.93  9.7 and 8.3. We use 8 192 random features and two-fold cross validation on the
train data to tune the normalization Z  which has the best value 1130  1160  1020  and 1090  respec-
tively. We choose the RBF kernel bandwidth h = 1/
2π so that the magnitude of the smoothed
approximate function still equals to 1 (or it can be tuned by cross-validation as well)  which matches
the original indicator function. For the kernel ridge regression  the RBF kernel bandwidth and the
regularization λ are all chosen by the same two-fold cross validation. For CIC and DIC  we learn
the respective model up to time T for once.
Figure 1 veriﬁes that even though the underlying diffusion models can be dramatically different 
the prediction performance of TCOVERAGELEARNER is robust to the model changes and con-
sistently outperforms the nontrivial baseline signiﬁcantly.
In addition  even if CIC and DIC are
provided with extra information  in Figure 1(a)  because the ground-truth is continuous-time dif-
fusion model with Weibull functions  they do not have good performance. CIC assumes the right
model but the wrong family of transmission functions. In Figure 1(b)  we expect CIC should have
the best performance for that it assumes the correct diffusion model and transmission functions.
Yet  TCOVERAGELEARNER still has comparable performance with even less information. In Fig-
ure 1(c)  although DIC has assumed the correct model  it is hard to determine the correct step size to
discretize the time line  and since we only learn the model once up to time T (instead of at each time
point)  it is harder to ﬁt the whole process. In Figure1(d)  both CIC and DIC have the wrong model 
so we have similar trend as Figure synthetic(a). Moreover  for kernel ridge regression  we have to
ﬁrst partition the timeline with arbitrary step size  ﬁt the model to each of time  and interpolate the
value between neighboring time legs. Not only will the errors from each stage be accumulated to
the error of the ﬁnal prediction  but also we cannot rely on this method to predict the inﬂuence of a
source set beyond the observation window T .

7

12345678910051015TimeMAE TCoverageLearnerKernel Ridge RegressionCICDIC123456789100102030TimeMAE TCoverageLearnerKernel Ridge RegressionCICDIC12345678910051015TimeMAE TCoverageLearnerKernel Ridge RegressionCICDIC12345678910012345TimeMAE TCoverageLearnerKernel Ridge RegressionCICDIC(a) Average MAE

(b) Features’ Effect

(c) Runtime

(d) Inﬂuence maximization

(a) Average MAE from time 1 to 10 on seven groups of real cascade data; (b) Improved
Figure 2:
estimation with increasing number of random features; (c) Runtime in log-log scale; (d) Maximized
inﬂuence of selected sources on the held-out testing data along time.

Overall  compared to the kernel ridge regression  TCOVERAGELEARNER only needs to be trained
once given all the event data up to time T in a compact and principle way  and then can be used to in-
fer the inﬂuence of any given source set at any particular time much more efﬁciently and accurately.
In contrast to the two-stage methods  TCOVERAGELEARNER is able to address the more general
setting with much less assumption and information but still can produce consistently competitive
performance.

Inﬂuence Estimation on Real Data

7.3
MemeTracker is a real-world dataset [20] to study information diffusion. The temporal ﬂow of in-
formation was traced using quotes which are short textual phrases spreading through the websites.
We have selected seven typical groups of cascades with the representative keywords like ‘apple and
jobs’  ‘tsunami earthquake’  etc.  among the top active 1 000 sites. Each set of cascades is split into
60%-train and 40%-test. Because we often can observe cascades only from single seed node  we
rarely have cascades produced from multiple sources simultaneously. However  because our model
can capture the correlation among multiple sources  we challenge TCOVERAGELEARNER with sets
of randomly chosen multiple source nodes on the independent hold-out data. Although the genera-
tion of sets of multiple source nodes is simulated  the respective inﬂuence is calculated from the real
test data as follows : Given a source set S  for each node u ∈ S  let C(u) denote the set of cascades
generated from u on the testing data. We uniformly sample cascades from C(u). The average length
of all sampled cascades is treated as the true inﬂuence of S. We draw 128 source sets and report
the average MAE along time in Figure 2(a). Again  we can observe that TCOVERAGELEARNER
has consistent and robust estimation performance across all testing groups. Figure 2(b) veriﬁes that
the prediction can be improved as more random features are exploited  because the representational
power of TCOVERAGELEARNER increases to better approximate the unknown true coverage func-
tion. Figure 2(c) indicates that the runtime of TCOVERAGELEARNER is able to scale linearly with
large number of random features. Finally  Figure 2(d) shows the application of the learned coverage
function to the inﬂuence maximization problem along time  which seeks to ﬁnd a set of source nodes
that maximize the expected number of infected nodes by time T . The classic greedy algorithm[21]
is applied to solve the problem  and the inﬂuence is calculated and averaged over the seven held-out
test data. It shows that TCOVERAGELEARNER is very competitive to the two-stage methods with
much less assumption. Because the greedy algorithm mainly depends on the relative rank of the
selected sources  although the estimated inﬂuence value can be different  the selected set of sources
could be similar  so the performance gap is not large.

8 Conclusions

We propose a new problem of learning temporal coverage functions with a novel parametrization
connected with counting processes and develop an efﬁcient algorithm which is guaranteed to learn
such a combinatorial function from only polynomial number of training samples. Empirical study
also veriﬁes our method outperforms existing methods consistently and signiﬁcantly.

Acknowledgments This work was supported in part by NSF grants CCF-0953192  CCF-1451177 
CCF-1101283  and CCF-1422910  ONR grant N00014-09-1-0751  AFOSR grant FA9550-09-1-
0538  Raytheon Faculty Fellowship  NSF IIS1116886  NSF/NIH BIGDATA 1R01GM108341  NSF
CAREER IIS1350983 and Facebook Graduate Fellowship 2014-2015.

8

12345670510152025Groups of MemesAverage MAE TCoverageLearnerKernel Ridge RegressionCICDIC12825651210242048409681920246810# Random featuresAverage MAE1282565121024204840968192100101102103time(s)# random features1234567891020406080100Timeinfluence TCoverageLearnerKernel Ridge RegressionCICDICReferences
[1] D. Kempe  J. Kleinberg  and ´E. Tardos. Maximizing the spread of inﬂuence through a social network. In

SIGKDD  pages 137–146. ACM  2003.

[2] C. Guestrin  A. Krause  and A. Singh. Near-optimal sensor placements in gaussian processes. In Interna-

tional Conference on Machine Learning ICML’05  2005.

[3] B. Lehmann  D. Lehmann  and N. Nisan. Combinatorial auctions with decreasing marginal utilities. In

Proceedings of the 3rd ACM conference on Electronic Commerce  pages 18–28. ACM  2001.

[4] M.F. Balcan and N. Harvey. Learning submodular functions. In Proceedings of the 43rd annual ACM

symposium on Theory of computing  pages 793–802. ACM  2011.

[5] A. Badanidiyuru  S. Dobzinski  H. Fu  R. D. Kleinberg  N. Nisan  and T. Roughgarden. Sketching valua-

tion functions. In Proceedings of the Annual ACM-SIAM Symposium on Discrete Algorithms  2012.

[6] V. Feldman and P. Kothari. Learning coverage functions. arXiv preprint arXiv:1304.2079  2013.
[7] V. Feldman and J. Vondrak. Optimal bounds on approximation of submodular and xos functions by juntas.

In FOCS  2013.

[8] N. Du  Y. Liang  N. Balcan  and L. Song. Inﬂuence function learning in information diffusion networks.

In International Conference on Machine Learning (ICML)  2014.

[9] L. Song  M. Kolar  and E. P. Xing. Time-varying dynamic bayesian networks. In Neural Information

Processing Systems  pages 1732–1740  2009.

[10] M. Kolar  L. Song  A. Ahmed  and E. P. Xing. Estimating time-varying networks. Ann. Appl. Statist. 

4(1):94–123  2010.

[11] O. Aalen  O. Borgan  and H. Gjessing. Survival and event history analysis: a process point of view.

Springer  2008.

[12] M. Schmidt  E. van den Berg  M. P. Friedlander  and K. Murphy. Optimizing costly functions with simple
constraints: A limited-memory projected quasi-newton algorithm. In D. van Dyk and M. Welling  editors 
Proceedings of The Twelfth International Conference on Artiﬁcial Intelligence and Statistics (AISTATS)
2009  volume 5  pages 456–463  Clearwater Beach  Florida  April 2009.

[13] Sara van de Geer. Hellinger-consistency of certain nonparametric maximum likelihood estimators. The

Annals of Statistics  pages 14–44  1993.

[14] L. Birg´e and P. Massart. Minimum Contrast Estimators on Sieves: Exponential Bounds and Rates of

Convergence. Bernoulli  4(3)  1998.

[15] Sara van de Geer. Exponential inequalities for martingales  with application to maximum likelihood

estimation for counting processes. The Annals of Statistics  pages 1779–1801  1995.

[16] M. Gomez-Rodriguez  D. Balduzzi  and S. Bernhard. Uncovering the temporal dynamics of diffusion

networks. In Proceedings of the International Conference on Machine Learning  2011.

[17] N. Du  L. Song  M. Gomez-Rodriguez  and H.Y. Zha. Scalable inﬂuence estimation in continuous time

diffusion networks. In Advances in Neural Information Processing Systems 26  2013.

[18] J. Leskovec  D. Chakrabarti  J. Kleinberg  C. Faloutsos  and Z. Ghahramani. Kronecker graphs: An

approach to modeling networks. Journal of Machine Learning Research  11(Feb):985–1042  2010.

[19] P. Netrapalli and S. Sanghavi.

Learning the graph of epidemic cascades.

RICS/PERFORMANCE  pages 211–222. ACM  2012.

In SIGMET-

[20] J. Leskovec  L. Backstrom  and J. Kleinberg. Meme-tracking and the dynamics of the news cycle. In Pro-
ceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining 
pages 497–506. ACM  2009.

[21] G. Nemhauser  L. Wolsey  and M. Fisher. An analysis of the approximations for maximizing submodular

set functions. Mathematical Programming  14:265–294  1978.
[22] L. Wasserman. All of Nonparametric Statistics. Springer  2006.
[23] A. Rahimi and B. Recht. Weighted sums of random kitchen sinks: Replacing minimization with random-

ization in learning. In Neural Information Processing Systems  2009.

[24] G.R. Shorack and J.A. Wellner. Empirical Processes with Applications to Statistics. Wiley  New York 

1986.

[25] Wing Hung Wong and Xiaotong Shen. Probability inequalities for likelihood ratios and convergence rates

of sieve mles. The Annals of Statistics  pages 339–362  1995.

[26] Kenneth S Alexander. Rates of growth and sample moduli for weighted empirical processes indexed by

sets. Probability Theory and Related Fields  75(3):379–423  1987.

9

,Nan Du
Yingyu Liang
Maria-Florina Balcan
Le Song
AmirEmad Ghassami
Saber Salehkaleybar
Negar Kiyavash
Kun Zhang