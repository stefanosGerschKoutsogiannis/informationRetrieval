2018,Causal Discovery from Discrete Data using Hidden Compact Representation,Causal discovery from a set of observations is one of the fundamental problems across several disciplines. For continuous variables  recently a number of causal discovery methods have demonstrated their effectiveness in distinguishing the cause from effect by exploring certain properties of the conditional distribution  but causal discovery on categorical data still remains to be a challenging problem  because it is generally not easy to find a compact description of the causal mechanism for the true causal direction. In this paper we make an attempt to find a way to solve this problem by assuming a two-stage causal process: the first stage maps the cause to a hidden variable of a lower cardinality  and the second stage generates the effect from the hidden representation. In this way  the causal mechanism admits a simple yet compact representation. We show that under this model  the causal direction is identifiable under some weak conditions on the true causal mechanism. We also provide an effective solution to recover the above hidden compact representation within the likelihood framework. Empirical studies verify the effectiveness of the proposed approach on both synthetic and real-world data.,Causal Discovery from Discrete Data using Hidden

Compact Representation

Ruichu Cai 1  Jie Qiao1  Kun Zhang2  Zhenjie Zhang3  Zhifeng Hao1  4
1 School of Computer Science  Guangdong University of Technology  China

2 Department of philosophy  Carnegie Mellon University

3 Singapore R&D  Yitu Technology Ltd.

4 School of Mathematics and Big Data  Foshan University  China

cairuichu@gdut.edu.cn  qiaojie.chn@gmail.com  kunz1@andrew.cmu.edu 

zhenjie.zhang@yitu-inc.com  zfhao@gdut.edu.cn

Abstract

Causal discovery from a set of observations is one of the fundamental problems
across several disciplines. For continuous variables  recently a number of causal
discovery methods have demonstrated their effectiveness in distinguishing the cause
from effect by exploring certain properties of the conditional distribution  but causal
discovery on categorical data still remains to be a challenging problem  because it
is generally not easy to ﬁnd a compact description of the causal mechanism for the
true causal direction. In this paper we make an attempt to ﬁnd a way to solve this
problem by assuming a two-stage causal process: the ﬁrst stage maps the cause to
a hidden variable of a lower cardinality  and the second stage generates the effect
from the hidden representation. In this way  the causal mechanism admits a simple
yet compact representation. We show that under this model  the causal direction is
identiﬁable under some weak conditions on the true causal mechanism. We also
provide an effective solution to recover the above hidden compact representation
within the likelihood framework. Empirical studies verify the effectiveness of the
proposed approach on both synthetic and real-world data.

1

Introduction

Because randomized controlled experiments are usually infeasible and generally too expensive 
observational data-based causal discovery  has been a focus of recent research in this area [Spirtes et
al.  2000; Pearl  2009]. Various observational-based causal discovery methods have been proposed by
exploring certain properties of the conditional distribution. For example  constraint-based methods
exploit conditional independence relations between the variables in order to estimate the Markov
equivalence class of the underlying causal graph [Spirtes et al.  2000; Pearl and Verma  1995]. On
linear non-Gaussian acyclic data  the Linear  Non-Gaussian  Acyclic Model (LiNGAM) [Shimizu et
al.  2006  2011] has been used to reconstruct the causal network by maximizing the independence
among the noises. On nonlinear data  additive noise model [Hoyer et al.  2009] and post-nonlinear
model [Zhang and Chan  2006; Zhang and Hyvärinen  2009] can be used to distinguish the cause from
effect by considering the independence between the noise and the cause. Recently  the likelihood
embedded with various constraints and models among the variables are conducted for score-based
methods [Cai et al.  2018].

Though the additive noise model (Y = g(X) + E  X  E) has been extended to handle discrete data

[Peters et al.  2010]  causal discovery on categorical data still remains to be a challenging problem.
Note that it is usually hard to justify the additive noise assumptions for discrete data  especially for

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

Figure 1: Food Poisoning: A Hidden Compact Representation Example in Real World.

categorical data. In fact  the additive noise model assumes that all categories of the variables are
placed in the “right” order; furthermore  if X → Y holds according to the additive noise model 

then for any observation(x  y)  there exists a function g(X) such that the noise E = y − g(x) is
conditional distribution P(YࢯX = x) always has the same shape for different values of x  after being
properly shifted according to g(x). But the values of a categorical variable are mutually exclusive

independent of X  i.e.  it has the same distribution for different values of x. In other words  the

′) provides a compact representation of the

categories or groups  without a meaningful order of magnitude. Thus  the additive noise model may
not be a proper representation of the causal mechanism for categorical variables.
Therefore  a proper description of the causal mechanism for discrete data that helps in causal discovery
remains under explored. In this work  we make an attempt to ﬁnd a way to solve this problem by
introducing a new assumption  called Hidden Compact Representation (HCR in short) as shown in
the food poisoning example given in Figure 1: the ﬁrst stage maps cause to a hidden variable of a
lower cardinality  and the second stage generates the effect from the hidden representation. As shown
in the example  in the ﬁrst stage  the food (X) with four different categories is mapped to the binary
′) with the key information whether it is poisonous; in the second
compact hidden representation (Y
stage  the hidden representation (poisonous or not) determines whether the patient is diagnosed as

having food poisoning (Y ). The hidden representation(Y
X  YࢯY

causes and captures key information of the causal mechanism  leaving out irrelevant information in
the cause. This way  the causal mechanism admits a simple  compact representation.
Let us have a closer look at the hidden compact representation model and see whether it is possible
to estimate it from data. First  these two stages are separated by the hidden representation  i.e. 
′ holds. As a result  we can use two conditional probabilities to express the whole causal
mechanism from X to Y   as shown in the tables in Figure 1. Second  as a compact representation
of the cause  the ﬁrst stage is deterministic  all stage transfer is done with probability 1. Third  as a
causal mechanism  the second stage can be represented by a probabilistic mapping from the hidden
′ to the effect Y . Based on the above observations  we provide a practical method to
variable Y
estimate the above HCR model under the likelihood framework. We also theoretically show that the
model is identiﬁable under weak conditions on the causal mechanism.
Our main contributions include 1) proposing a two-stage compact representation of the causal
mechanism in the discrete case  2) developing a likelihood-based framework for estimating the HCR
model  and 3) conducting a theoretical analysis of the identiﬁability of the underlying causal direction.

2 Hidden Compact Representation Model

Without loss of generality  let X be the cause of Y in a discrete cause-effect pair  i.e.  X → Y . Here 
′ → Y   to model the causal mechanism
we use the hidden compact representation  M ࢼ X → Y
behind the discrete data  with Y

′ as a hidden compact representation of the cause X.

′  cause X is mapped to a low-cardinality hidden variable Y

′ = f(X)  where f ࢼ Z → Z is a noise-free arbitrary function. It

In the ﬁrst stage X → Y
It can be expressed by using Y

′ deterministically.

2

(cid:28651)(cid:28652)(cid:28704)(cid:28652)(cid:28599)(cid:28629)(cid:28649)(cid:28647)(cid:28633)(cid:28601)(cid:28634)(cid:28634)(cid:28633)(cid:28631)(cid:28648)(cid:28604)(cid:28637)(cid:28632)(cid:28632)(cid:28633)(cid:28642)(cid:28564)(cid:28599)(cid:28643)(cid:28641)(cid:28644)(cid:28629)(cid:28631)(cid:28648)(cid:28564)(cid:28614)(cid:28633)(cid:28644)(cid:28646)(cid:28633)(cid:28647)(cid:28633)(cid:28642)(cid:28648)(cid:28629)(cid:28648)(cid:28637)(cid:28643)(cid:28642)(cid:28643)(cid:28674)(cid:28668)(cid:28678)(cid:28674)(cid:28673)(cid:28674)(cid:28680)(cid:28678)(cid:28595)(cid:28640)(cid:28680)(cid:28678)(cid:28667)(cid:28677)(cid:28674)(cid:28674)(cid:28672)(cid:28640)(cid:28680)(cid:28678)(cid:28667)(cid:28677)(cid:28674)(cid:28674)(cid:28672)(cid:28645)(cid:28668)(cid:28662)(cid:28664)(cid:28643)(cid:28674)(cid:28668)(cid:28678)(cid:28674)(cid:28673)(cid:28674)(cid:28680)(cid:28678)(cid:28641)(cid:28674)(cid:28679)(cid:28595)(cid:28643)(cid:28674)(cid:28668)(cid:28678)(cid:28674)(cid:28673)(cid:28674)(cid:28680)(cid:28678)(cid:28643)(cid:28674)(cid:28668)(cid:28678)(cid:28674)(cid:28673)(cid:28674)(cid:28680)(cid:28678)(cid:28595)(cid:28633)(cid:28668)(cid:28678)(cid:28667)(cid:28612)(cid:28612)(cid:28611)(cid:28611)(cid:28611)(cid:28611)(cid:28612)(cid:28612)(cid:28643)(cid:28674)(cid:28668)(cid:28678)(cid:28674)(cid:28673)(cid:28674)(cid:28680)(cid:28678)(cid:28633)(cid:28674)(cid:28674)(cid:28663)(cid:28595)(cid:28643)(cid:28674)(cid:28668)(cid:28678)(cid:28674)(cid:28673)(cid:28668)(cid:28673)(cid:28666)(cid:28641)(cid:28674)(cid:28677)(cid:28672)(cid:28660)(cid:28671)(cid:28611)(cid:28609)(cid:28619)(cid:28616)(cid:28611)(cid:28609)(cid:28611)(cid:28616)(cid:28641)(cid:28674)(cid:28679)(cid:28595)(cid:28643)(cid:28674)(cid:28668)(cid:28678)(cid:28674)(cid:28673)(cid:28674)(cid:28680)(cid:28678)(cid:28646)(cid:28679)(cid:28674)(cid:28672)(cid:28660)(cid:28662)(cid:28667)(cid:28595)(cid:28633)(cid:28671)(cid:28680)(cid:28611)(cid:28609)(cid:28612)(cid:28611)(cid:28611)(cid:28609)(cid:28620)(cid:28611)(cid:28611)(cid:28609)(cid:28611)(cid:28614)(cid:28611)(cid:28609)(cid:28611)(cid:28618)(cid:28615)(cid:28648)(cid:28629)(cid:28635)(cid:28633)(cid:28564)(cid:28581)(cid:28590)(cid:28564)(cid:28632)(cid:28633)(cid:28648)(cid:28633)(cid:28646)(cid:28641)(cid:28637)(cid:28642)(cid:28637)(cid:28647)(cid:28648)(cid:28637)(cid:28631)(cid:28564)(cid:28641)(cid:28629)(cid:28644)(cid:28644)(cid:28637)(cid:28642)(cid:28635)(cid:28665)(cid:28677)(cid:28674)(cid:28672)(cid:28595)(cid:28662)(cid:28660)(cid:28680)(cid:28678)(cid:28664)(cid:28595)(cid:28603)(cid:28651)(cid:28604)(cid:28595)(cid:28679)(cid:28674)(cid:28595)(cid:28667)(cid:28668)(cid:28663)(cid:28663)(cid:28664)(cid:28673)(cid:28595)(cid:28677)(cid:28664)(cid:28675)(cid:28677)(cid:28664)(cid:28678)(cid:28664)(cid:28673)(cid:28679)(cid:28660)(cid:28679)(cid:28668)(cid:28674)(cid:28673)(cid:28595)(cid:28603)(cid:28652)(cid:28704)(cid:28604)(cid:28615)(cid:28648)(cid:28629)(cid:28635)(cid:28633)(cid:28564)(cid:28582)(cid:28590)(cid:28564)(cid:28644)(cid:28646)(cid:28643)(cid:28630)(cid:28629)(cid:28630)(cid:28637)(cid:28640)(cid:28637)(cid:28647)(cid:28648)(cid:28637)(cid:28631)(cid:28564)(cid:28641)(cid:28629)(cid:28644)(cid:28644)(cid:28637)(cid:28642)(cid:28635)(cid:28564)(cid:28665)(cid:28677)(cid:28674)(cid:28672)(cid:28595)(cid:28667)(cid:28668)(cid:28663)(cid:28663)(cid:28664)(cid:28673)(cid:28595)(cid:28677)(cid:28664)(cid:28675)(cid:28677)(cid:28664)(cid:28678)(cid:28664)(cid:28673)(cid:28679)(cid:28660)(cid:28679)(cid:28668)(cid:28674)(cid:28673)(cid:28595)(cid:28603)(cid:28652)(cid:28704)(cid:28604)(cid:28595)(cid:28679)(cid:28674)(cid:28595)(cid:28664)(cid:28665)(cid:28665)(cid:28664)(cid:28662)(cid:28679)(cid:28595)(cid:28603)(cid:28652)(cid:28604)(cid:28651)(cid:28652)(cid:28704)(cid:28652)(cid:28704)(cid:28652)′. This stage extracts the
implies that the cause X can be reduced to a hidden low-cardinality space Y
real  necessary causal factor behind the various cause states. As shown in Figure 1  there are four
′ extracts the key information in this causal
different values of X  and the hidden representation Y
mechanism  i.e.  whether the food is poisonous or not.

In the second stage  the effect Y is generated from the hidden representation Y

′ = f(x)). For instance  as shown in

′ by the probabilistic

Figure 1  the food poisoning may misdiagnose as stomach ﬂu with probability 0.1  which is captured
by the conditional distribution.
In this hidden compact representation model  the deterministic mapping stage and probabilistic
′. Given a
mapping stage are naturally separable by the hidden representation Y
′ → Y is

′  i.e.  X  YࢯY

i=1  the log-likelihood of the model M ࢼ X → Y

′

3

estimated as follows.

mapping with conditional probability distribution P(Y = yࢯY
group of observations D ={(xi  yi)}m
P(X = xi  Y
P(X = xi)P(Y
P(X = xi)P(Y = yiࢯY

L(M ;D)

= log

= log

= log

m(cid:53)

m(cid:53)

m(cid:53)

′ = y

(cid:61)

(cid:61)

i=1

i=1

′
i

′
i

y

y

′

′

′

′ = y

′ = y

i)

i  Y = yiࢯM)
iࢯX = xi)P(Y = yiࢯY
′ = f(xi))
iࢯX = xi)  denotes how the compact representation
iࢯX = xi) = 1 if
i ≠ f(xi)  where function f denotes the true mapping.

′. The

′ = y

(1)

′

′

′

′

i=1

′ = y

′ = y

log(m)

Equation (1) decomposes the joint probability into three components according to X  YࢯY
middle term of the second equation  P(Y
′ is generated from X. Since this process is deterministic  we have P(Y
iࢯX = xi) = 0 if y
i = f(xi) and P(Y

Y
′
y
Different from the previous likelihood framework  the likelihood given in equation (1) contains a
hidden representation with an unknown cardinality. Thus  the Bayesian Information Criterion (BIC)
[Schwarz and others  1978] is introduced to control the complexity of the model  which provides a
trade-off between the goodness of ﬁt and model complexity. The BIC is given in equation (2)  which
is an approximation of the marginal likelihood of the hidden compact representation model M based
on the data D:

L∗(M ;D) = L(M ;D) − d
′ࢯ(ࢯYࢯ − 1) measures the effective number of parameters in the model. In
where d =(ࢯXࢯ − 1) +ࢯY
′ࢯ(ࢯYࢯ − 1) are the numbers of parameters for P(X)  and the probabilistic
detail (ࢯXࢯ − 1) andࢯY
mapping PYࢯY ′  respectively.
in M are decomposed into two parts  θ and f  where θ includes the parameters of P(X) and
P(YࢯY
′). Maximization of above objective function  i.e.  maxL∗ = supf maxθ L∗  involves two
To recover the causal model  we regard the model with the highest L∗ as the best one. The parameters
iterative steps. First  calculate the maximum likelihood estimator (MLE) ˆθ = argmaxθ L(θ;D) while
best f to achieve supf L∗(f ;D). Such an alternate maximization procedure eventually converges 
maxθ L(θ;D) and the MLE ˆθ of the likelihood L can be calculated directly as described in the
Let ˆθ ={ˆa  ˆb} where ˆax = ˆP(X = x)  ˆby y′ = ˆP(Y = yࢯY
′) denote the MLE of the distribution
PX PYࢯY ′ respectively. The MLE of those parameters can be written as ˆax = nx∑
  yi = y) are the frequencies of value
i=1 I(xi = x)  and ny′ y = ∑m
i=1 I(y
where nx = ∑m
′ = y
X = x and Y

as shown in [Bezdek and Hathaway  2003].
In the ﬁrst step  more speciﬁcally  while ﬁxing the f  the maximization is equivalent to maxθ L∗ =

  Y = y in samples respectively. Such solutions can be derived by maximizing L

ﬁxing the function f. Second  ﬁx the parameter values of θ and ﬁnd a better model by choosing the

  ˆby′ y = ny
 y∑
y ny

following.

i = y

′ = y

(2)

x nx

2

 y

 

′

′

′

′

′. Following likelihood of the model

y by′ y = 1  ∀y

in equation (1)  the solution of maxθ L(θ;D) is given in equation (3).
with the constraints conditions ∑
′ = f(xi))
ny′ ylog( ny′ y∑

x ax = 1  and ∑
L(θ;D)
P(X = xi)P(Y = yiࢯY
x (cid:53)
nx log( nx∑
ˆanx

m(cid:53)
= log
= log(cid:53)
=(cid:61)

) + (cid:61)

′
ny
ˆb
 y
y′ y

(cid:53)

(cid:61)

max

i=1

y′

x

y

θ

x

x nx

y′

y

y ny′ y

(3)

)

In the second and third equalities  we collect each category and perform a MLE to estimate each
parameter in the distribution. Consequently  the optimum solution ˆθ is given in the closed form 
which will be used in the second step of the optimization procedure.
In the second step  we propose a greedy search algorithm to search the best f with supf L∗. Firstly 

f(x) is initialized with the y0  where y0 is the mode of{yࢯ < x  y >∈ D}. Secondly  we perform
greedy search on the f(x) by enumerating all possible values for each x.

In summary  the optimization of maxL∗ = supf maxθ L∗ is given in the following algorithm.
Algorithm 1 Optimization of maxL∗ = supf maxθ L∗
Input: Data D
Output: L∗

′ > do

if ˆL∗ < L∗ then

log(m)

t = t + 1
for each pair < x  y

1: f(0)(x) ← argmaxy
ˆP(X = x  Y = y)
2: while L∗ no longer increases do
L∗ ← maxθ L(f
x→y′   θ;D) − d
(t−1)
3:
4:
ˆx  ˆy
 L∗
  ˆL∗ ←x  y
5:
6:
Set f(ˆx) to be ˆy
7:
8:
9:
10:
11: end while
12: return L∗
x→y′ denotes that the change of the value f(t−1)(x) to value y
(t−1)
(t−1)
f(ˆx) to ˆy
′ in order to achieve the highest score increase. Finally  set f(ˆx) ← ˆy

′ and let L∗ = ˆL∗

end for

end if

2

′

′

′ > by traversing the value of y

where f
the best gain pair < ˆx  ˆy
until L∗ no longer increases.
Based on the above proposed hidden compact representation and its BIC score  we can simply get the
following practical method for causal inference.

′. In each iteration  we search
x→y′ . In other words  change the value
′ and update the score

′ in f

1. Estimate the model M ࢼ X → Y

L∗( ˜M ;D) respectively;
2. If L∗(M ;D) > L∗( ˜M ;D)  infer “X → Y ” 
If L∗(M ;D) < L∗( ˜M ;D)  infer “Y → X” 
If L∗(M ;D) = L∗( ˜M ;D)  infer “non-identiﬁable”.

′ → Y   ˜M ࢼ Y → X

′ → X by maximizing L∗(M ;D)  

The asymptotic correctness of this practical methods is implied by the identiﬁability of the model 
which is theoretically analyzed in the following section.

4

3

Identiﬁability

functions of X.)

random in the sense that

Then asymptotically  in the reverse direction there does not exist X

We shall show that under the hidden compact representation model  the causal direction is asymptoti-
cally identiﬁable in the general case (under some technical conditions).
We ﬁrst show the following property for the reverse direction under certain conditions on the

conditional distribution P(YࢯX).
Theorem 1. Assume that for the correct causal direction  the conditional distribution P(YࢯX) is
A1. there does not exist values y1 ≠ y2 such that P(Y = y1ࢯ X) equals P(Y = y2ࢯ X) times a
constant for all possible X values. (Note that both P(Y = y1ࢯ X) and P(Y = y2ࢯ X) are
′ࢯ <ࢯYࢯ such
′ = ˆf(Y) withࢯX
that P(XࢯY) = P(XࢯX
′) for all possible X and Y values  i.e.  the reverse direction does not admit
a low-cardinality hidden representation ˆf(Y).
Proof. We have P(X  Y) = P(X)P(YࢯX) for the correct direction. Assume that there exists such
′ = ˆf(Y) to satisfy P(XࢯY) = P(XࢯX
′). Hence 
′). We then have P(X  Y) = P(Y)P(XࢯX
′) = P(X)P(YࢯX)
P(XࢯX
P(Y)
′ࢯ <ࢯYࢯ  there must exist two values y1 ≠ y2 such that ˆf(y1) = ˆf(y2)  which implies
BecauseࢯX
P(Xࢯ ˆf(y1)) = P(Xࢯ ˆf(y2)). According to Equation (4)  we have
= P(X)P(Y = y2ࢯX)
P(X)P(Y = y1ࢯX)
P(Y = y2)
P(Y = y1)
P(Y = y1ࢯX) = P(Y = y2ࢯX) ⋅ P(Y = y1)
P(Y = y2)  

a X

or

.

(4)

 

which contradicts Assumption A1. Therefore  the reverse direction does not admit a low-cardinality
hidden representation.

Note that assumption A1 may be violated  but the chance for it to be violated should be low. Roughly
speaking  this assumption states that X and Y are not “locally” independent. Suppose assumption

A1 does not hold; then there must exist y1 y2 satisfying P(Y = y1ࢯX) = cP(Y = y2ࢯX) for all
possible values of X. One can derive that P(XࢯY = y1) = P(XࢯY = y2). This means if we ignore

all the other possible values of Y other than y1 and y2  X and Y become independent. Generally
speaking  this will not hold when X and Y are dependent  especially when the cardinality of X is
not small. The experimental results also illustrate the plausibility of this assumption.
As an immediate result of Theorem 1  we have the identiﬁability of the causal direction under the
hidden compact representation model  as given in Theorem 2.
Theorem 2. Assume that in the causal direction there exists the transformation Y

′ = f(X) such
′ࢯ <ࢯXࢯ  and and assumption A1 holds. Then to produce the
that P(YࢯX) = P(YࢯY
same distribution P(X  Y)  the reverse direction must involve more effective number of parameters

′)  whereࢯY

in the model than the causal direction.

Going one step further  Theorem 3 shows the BIC of the causal direction is asymptotically higher
than that of the reverse one. The proof of this theorem is provided in the supplementary material.
Theorem 3. If the reverse direction involves more parameters than the causal direction to produce

the same distribution P(X  Y)  the BIC of the causal direction is asymptotically higher than that of

the reverse one.

5

4 Experiments

To investigate the effectiveness of the proposed method based on the hidden compact representation
model  we compare it with baseline algorithms on both synthetic data and the real world data. On
synthetic data  we simulate the data according to the hidden compact representation model. In all the
experiments  we generate 1000 different causal pairs and 2000 samples for each pair. On real-world
data  we run the algorithm on Pittsburgh Bridges dataset and Abalone dataset. The implementation of
HCR can be found on CRAN 1.
The following ﬁve algorithms are taken as the baseline: ANM [Peters et al.  2010]  SA [Liu and
Chan  2016a]  DC [Liu and Chan  2016b]  IGCI [Janzing et al.  2012] and CISC [Budhathoki and
Vreeken  2017]. The parameter settings of all the algorithms are based on their origin work.
To make a fair comparison  the decision rate is used as the metric to evaluate the models’ performance 
same as that in IGCI [Janzing et al.  2012] and CISC [Budhathoki and Vreeken  2017].

4.1 Synthetic Data with Hidden Compact Representation Model

In this set of experiments  the samples are generated according to the following two-stage proce-
dure. Firstly  generate X from a multinomial distribution and its cardinality is randomly chosen

from{3  4  ...  15}. Secondly  map each X to a value that uniformly samples from the interval
{1  2  ... ࢯXࢯ}. Finally  randomly generate a conditional probability distribution P(YࢯY
′) and
′ࢯ  ...  15}.

sample Y according to Y

′ and P(YࢯY

′)  andࢯYࢯ is generated from the interval{ࢯY

(a) Sensitivity to Decision Rate.

(b) Sensitivity to Sample Size.

Figure 2: Results on the Hidden Compact Representation Model.

Figure 2(a) shows the accuracy with difference decision rate. As shown in the ﬁgure 2(a)  HCR
outperforms the baseline methods across all the decision rates. HCR achieves acceptable results
even when the decision rate is 1  which shows HCR can reliably infer the causal direction for all the
cause-effect pairs. In this set of experiment  ANM fails to work because its additive noise assumption
may not hold for the current causal mechanism.
Figure 2(b) shows the performance of the algorithms with the sample size varying from 250 to 3000.
The decision rate is 1 in this set of experiments. As shown in the ﬁgure  the performance of HCR
grows much faster than the baseline methods and converge to 1 when the sample size reaches 3000.
This shows that the hidden compact representation explores the information behind the data more
efﬁciently  compared with the other algorithms.

4.2 Real-World Data

To further assess the performance of our method for the discrete casual inference  we test the
algorithms on two real-world datasets  Pittsburgh Bridges dataset and Abalone dataset. Both of them
are wildly used in previous research and can be downloaded from UCI Machine Learning Repository
[Lichman  2013].

1

https://cran.r-project.org/package=HCR

6

0.000.250.500.751.000.000.250.500.751.00Decision RateAccuracyHCRANMSADCIGCICISC0.000.250.500.751.00100020003000Sample sizeAccuracyHCRANMSADCIGCICISCPittsburgh Bridges dataset: There are 108 bridges in this dataset. The following 4 cause-effect
pairs are known as ground truth in this experiment. They are 1) Erected (Crafts  Emerging  Mature 
Modern) → Span (Long  Medium  Short)  2) Material (Steel  Iron  Wood) → Span (Long  Medium 
Short); 3) Material (Steel  Iron  Wood) → Lanes (1  2  4  6); 4) Purpose (Walk  Aqueduct  RR 
Highway) → type (Wood  Suspen  Simple-T  Arch  Cantilev  CONT-T).

Table 1: Hidden Compact Representation on Pittsburgh Bridges Data Set.

Ground truth

Erected→Span

Material→Span

Material→Lanes

Purpose→Type

′

f(X) → Y
f({Craf ts}) → 1
f({Emerging  M ature  M odern}) → 2
f({Steel}) → 1
f({Iron  W ood}) → 2
f({Steel}) → 1
f({Iron  W ood}) → 2
f({Aqueduct  Highway  W alk}) → 1
f({RR}) → 2

P(YࢯY

′)

Medium: 0.5  Short:0.5
Long: 0.37  Medium:0.59  Short:0.04
Long: 0.42  Medium:0.58
Medium:0.55  Short:0.45
2 Lane:0.6  4 Lane:0.33  6 Lane:0.06
1 Lane:0.15  2 Lane:0.8  4 Lane:0.04
Arch:0.18  Cantilev:0.12  CONT-T:0.12 
Simple-T:0.24  Suspen: 0.15  Wood:0.19
Cantilev:0.06  CONT-T:0.03 
Simple-T:0.81  NIL:0.3 wood:0.06

′ = 2  while Crafts is mapped to Y

Generally speaking  HCR can identify all 4 cause-effect pairs correctly. To gain an insight into the
hidden compact representation  we give the reconstructed model in Table 1. In detail  the result on
“Erected → Span” shows that {Emerging  Mature  and Modern} of erected are mapped into a hidden
′ = 1. This hidden representation reﬂects
compact representation Y
that Crafts is the main cause of the medium and short bridge  which is compatible with common
sense. Similarly  from the results on “Material → Span” and “Material → Lanes”  we can see that
the steel belongs to modern material with high strength  while iron and wood are classic materials
with lower strength. This hidden property of the material causes the different span and lanes. Similar
results can be found in “purpose → type”. All of those results on the four cause-effect pairs reﬂect
that HCR is a proper representation of the causal mechanism for discrete data.
Figure 3(a) shows the results of the algorithms on Pittsburgh Bridges dataset with different sample
sizes. Because of the space limitation  only the average result of the four pairs are reported. As shown
in the ﬁgure  HCR outperforms the baseline methods and shows competitive performance even when
the sample size is smaller than 100  while the other four baselines are all failed to ﬁnd the right causal
direction with such a small sample size. This reﬂects HCR might be a suitable representation of the
causal mechanism in this real-world scenario.

(a) Results on Pittsburgh Bridges Data Set.

(b) Result on Abalone Data Set.

Figure 3: Sensitivity to Sample Size.

Abalone Data Set: This dataset contains 4177 samples and each sample has 4 different properties.
The ground truth contains three cause-effect pairs  Sex → {Length  Diameter  Height}. The property
sex has three values  male  female and infant. The length  diameter  and height are measured in mm
and treated as discrete values  similar to [Peters et al.  2010].

7

0.000.250.500.751.00255075100Sample SizeAccuracyHCRANMSADCIGCICISC0.000.250.500.751.0001000200030004000Sample SizeAccuracyHCRANMSADCIGCICISCTable 2: Hidden Compact Representation on Abalone Data Set.
Ground truth

′

P(YࢯY

′)

f(X) → Y
f({Inf ant}) → 1
f({F emale  M ale}) → 2
f({Inf ant}) → 1
f({F emale  M ale}) → 2
f({Inf ant}) → 1
f({F emale  M ale}) → 2

0.43 ± 0.1
0.57 ± 0.96
0.33 ± 0.088
0.45 ± 0.079
0.11 ± 0.032
0.15 ± 0.037

Sex→Length

Sex→Diameter

Sex→Height

′ = 2. Here Y

In this dataset  HCR successfully determines the causal direction for all the three pairs  and the details
of the model are given in Table 2. Because the properties have many discrete states  column Y shows
its mean and standard variance. Although this dataset closely relates to the additive noise model 
Table 2 demonstrates that HCR still successfully identiﬁes the causal direction and provides a fruitful
′ = 1  and maps {Female 
insight of the causal mechanism. In detail  the model maps Infant to Y
′ indicates that categorizing the sex of abalones into male and female is
Male} to Y
redundant relative to the considered effect  which is Length  Diameter  or Height. In the second stage 
the mapping shows the maturity causes the sizes.
We also compare our results with the baseline methods with different sample sizes. As shown in
Figure 3(b)  although this dataset follows the assumptions of the discrete additive noise model  HCR
still outperforms ANM. Note that  ICGI and CISC achieve the same performance as HCR and their
curves are covered by that of HCR. Moreover  SA and DC fail to give the correct direction on this
data set  perhaps because they are designed for the discrete data with a small number of cardinalities
while the cardinality of the variables is very large in this dataset. These results also indicate that HCR
may provide a suitable representation of the causal mechanism in various scenarios.
As a summary  HCR stably outperforms all the baseline methods on these two real-world discrete
datasets and  furthermore  shows a meaningful hidden compact representation of the causal mecha-
nism.

5 Conclusion

Finding causal direction between discrete variables is an important but challenging problem. In this
paper  we make an attempt to solve this problem by developing a low-cardinality hidden representation
model for the causal mechanism  which decomposes the mechanism into two stages. With this model
estimated by the Bayesian Information Criterion (BIC)  we develop an effective causal discovery
method for discrete variables. Theoretical analysis also shows that the model is generally identiﬁable—
it is not identiﬁable when some weak technical conditions on the causal mechanism are violated.
Experimental results on both synthetic and real data verify our theoretical results and support the
validity of the proposed model  at least in a number of real situations. In future work  we plan to
extend the proposed method to discrete data with confounding factors.

Acknowledgments

of China

(61876043 

This research was supported in part by NSFC-Guangdong Joint Found (U1501254)  Nat-
ural Science Foundation
61472089)  NSF of Guangdong
(2014A030306004  2014A030308008)  Science and Technology Planning Project of Guang-
dong (2015B010108006  2015B010131015)  Guangdong High-level Personnel of Special Sup-
port Program (2015TQ01X140)   Pearl River S&T Nova Program of Guangzhou (201610010101).
This material is partially based upon work supported by United States Air Force under Contract No.
FA8650-17-C-7715  by National Science Foundation under EAGER Grant No. IIS-1829681  and
National Institutes of Health under Contract No. NIH-1R01EB022858-01  FAINR01EB022858 
NIH-1R01LM012087  NIH-5U54HG008540-02  and FAIN-U54HG008540  and work funded and
supported by the Department of Defense under Contract No. FA8702-15-D-0002 with Carnegie

8

Mellon University for the operation of the Software Engineering Institute  a federally funded research
and development center. Any opinions  ﬁndings  and conclusions or recommendations expressed in
this material are those of the authors and do not necessarily reﬂect the views of the United States Air
Force or the National Institutes of Health or the National Science Foundation. We appreciate the
comments from anonymous reviewers  which greatly helped to improve the paper.

References
James C Bezdek and Richard J Hathaway. Convergence of alternating optimization. Neural  Parallel

& Scientiﬁc Computations  11(4):351–368  2003.

Kailash Budhathoki and Jilles Vreeken. MDL for causal inference on discrete data. In ICDM  pages

751–756  2017.

Ruichu Cai  Jie Qiao  Zhenjie Zhang  and Zhifeng Hao. Self: Structural equational embedded

likelihood framework for causal discovery. In AAAI  2018.

Patrik O Hoyer  Dominik Janzing  Joris M Mooij  Jonas Peters  and Bernhard Schölkopf. Nonlinear

causal discovery with additive noise models. In NIPS  pages 689–696  2009.

Dominik Janzing  Joris Mooij  Kun Zhang  Jan Lemeire  Jakob Zscheischler  Povilas Daniušis 
Bastian Steudel  and Bernhard Schölkopf. Information-geometric approach to inferring causal
directions. Artiﬁcial Intelligence  182:1–31  2012.

M. Lichman. UCI machine learning repository  2013.

Furui Liu and Laiwan Chan. Causal discovery on discrete data with extensions to mixture model.

ACM Transactions on Intelligent Systems and Technology (TIST)  7(2):21  2016.

Furui Liu and Laiwan Chan. Causal inference on discrete data via estimating distance correlations.

Neural computation  2016.

Judea Pearl and Thomas S Verma. A theory of inferred causation. Studies in Logic and the

Foundations of Mathematics  134:789–811  1995.

Judea Pearl. Causality: models  reasoning and inference. Cambridge university press  2009.

Jonas Peters  Dominik Janzing  and Bernhard Schölkopf. Identifying cause and effect on discrete

data using additive noise models. In AISTATS  pages 597–604  2010.

Gideon Schwarz et al. Estimating the dimension of a model. The annals of statistics  6(2):461–464 

1978.

Shohei Shimizu  Patrik O Hoyer  Aapo Hyvärinen  and Antti Kerminen. A linear non-gaussian
acyclic model for causal discovery. Journal of Machine Learning Research  7(Oct):2003–2030 
2006.

Shohei Shimizu  Takanori Inazumi  Yasuhiro Sogawa  Aapo Hyvärinen  Yoshinobu Kawahara 
Takashi Washio  Patrik O Hoyer  and Kenneth Bollen. Directlingam: A direct method for learn-
ing a linear non-gaussian structural equation model. Journal of Machine Learning Research 
12(Apr):1225–1248  2011.

Peter Spirtes  Clark N Glymour  and Richard Scheines. Causation  prediction  and search. MIT

press  2000.

Kun Zhang and Laiwan Chan. Extensions of ICA for causality discovery in the hong kong stock
market. In Proc. 13th International Conference on Neural Information Processing (ICONIP 2006) 
2006.

Kun Zhang and Aapo Hyvärinen. On the identiﬁability of the post-nonlinear causal model. In UAI 

pages 647–655  2009.

9

,Ruichu Cai
Jie Qiao
Kun Zhang
Zhenjie Zhang
Zhifeng Hao
Kristof Meding
Dominik Janzing
Bernhard Schölkopf
Felix A. Wichmann