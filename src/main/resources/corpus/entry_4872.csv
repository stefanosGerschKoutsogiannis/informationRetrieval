2013,Scalable Influence Estimation in Continuous-Time Diffusion Networks,If a piece of information is released from a media site  can it spread  in 1 month  to a million web pages? This influence estimation problem is very challenging since both the time-sensitive nature of the problem and the issue of scalability need to be addressed simultaneously. In this paper  we propose a randomized algorithm for influence estimation in continuous-time diffusion networks. Our algorithm can estimate the influence of every node in a network with $|\Vcal|$ nodes and $|\Ecal|$ edges to an accuracy of $\epsilon$ using  $n=O(1/\epsilon^2)$ randomizations and up to logarithmic factors $O(n|\Ecal|+n|\Vcal|)$ computations. When used as a subroutine in a greedy influence maximization algorithm  our proposed method is guaranteed to find a set of nodes with an influence of at least $(1 - 1/e)\operatorname{OPT} - 2\epsilon$  where $\operatorname{OPT}$ is the optimal value. Experiments on both synthetic and real-world data show that the proposed method can easily scale up to networks of millions of nodes while significantly improves over previous state-of-the-arts in terms of the accuracy of the estimated influence and the quality of the selected nodes in maximizing the influence.,Scalable Inﬂuence Estimation in

Continuous-Time Diffusion Networks

Nan Du∗

Le Song∗

Manuel Gomez-Rodriguez†

Hongyuan Zha∗

Georgia Institute of Technology∗

MPI for Intelligent Systems†

dunan@gatech.edu

lsong@cc.gatech.edu

manuelgr@tue.mpg.de

zha@cc.gatech.edu

Abstract

If a piece of information is released from a media site  can we predict whether
it may spread to one million web pages  in a month ? This inﬂuence estimation
problem is very challenging since both the time-sensitive nature of the task and
the requirement of scalability need to be addressed simultaneously. In this paper 
we propose a randomized algorithm for inﬂuence estimation in continuous-time
diffusion networks. Our algorithm can estimate the inﬂuence of every node in
a network with |V| nodes and |E| edges to an accuracy of  using n = O(1/2)
randomizations and up to logarithmic factors O(n|E|+n|V|) computations. When
used as a subroutine in a greedy inﬂuence maximization approach  our proposed
algorithm is guaranteed to ﬁnd a set of C nodes with the inﬂuence of at least
(1 − 1/e) OPT−2C  where OPT is the optimal value. Experiments on both
synthetic and real-world data show that the proposed algorithm can easily scale
up to networks of millions of nodes while signiﬁcantly improves over previous
state-of-the-arts in terms of the accuracy of the estimated inﬂuence and the quality
of the selected nodes in maximizing the inﬂuence.

Introduction

1
Motivated by applications in viral marketing [1]  researchers have been studying the inﬂuence max-
imization problem: ﬁnd a set of nodes whose initial adoptions of certain idea or product can trigger 
in a time window  the largest expected number of follow-ups. For this purpose  it is essential to ac-
curately and efﬁciently estimate the number of follow-ups of an arbitrary set of source nodes within
the given time window. This is a challenging problem for that we need ﬁrst accurately model the
timing information in cascade data and then design a scalable algorithm to deal with large real-world
networks. Most previous work in the literature tackled the inﬂuence estimation and maximization
problems for inﬁnite time window [1  2  3  4  5  6]. However  in most cases  inﬂuence must be
estimated or maximized up to a given time  i.e.  a ﬁnite time window must be considered [7]. For
example  a marketer would like to have her advertisement viewed by a million people in one month 
rather than in one hundred years. Such time-sensitive requirement renders those algorithms which
only consider static information  such as network topologies  inappropriate in this context.
A sequence of recent work has argued that modeling cascade data and information diffusion using
continuous-time diffusion networks can provide signiﬁcantly more accurate models than discrete-
time models [8  9  10  11  12  13  14  15]. There is a twofold rationale behind this modeling choice.
First  since follow-ups occur asynchronously  continuous variables seem more appropriate to repre-
sent them. Artiﬁcially discretizing the time axis into bins introduces additional tuning parameters 
like the bin size  which are not easy to choose optimally. Second  discrete time models can only
describe transmission times which obey an exponential density  and hence can be too restricted
to capture the rich temporal dynamics in the data. Extensive experimental comparisons on both
synthetic and real world data showed that continuous-time models yield signiﬁcant improvement
in settings such as recovering hidden diffusion network structures from cascade data [8  10] and
predicting the timings of future events [9  14].

1

However  estimating and maximizing inﬂuence based on continuous-time diffusion models also en-
tail many challenges. First  the inﬂuence estimation problem in this setting is a difﬁcult graphical
model inference problem  i.e.  computing the marginal density of continuous variables in loopy
graphical models. The exact answer can be computed only for very special cases. For example 
Gomez-Rodriguez et al. [7] have shown that the problem can be solved exactly when the trans-
mission functions are exponential densities  by using continuous time Markov processes theory.
However  the computational complexity of such approach  in general  scales exponentially with the
size and density of the network. Moreover  extending the approach to deal with arbitrary transmis-
sion functions would require additional nontrivial approximations which would increase even more
the computational complexity. Second  it is unclear how to scale up inﬂuence estimation and maxi-
mization algorithms based on continuous-time diffusion models to millions of nodes. Especially in
the maximization case  even a naive sampling algorithm for approximate inference is not scalable:
n sampling rounds need to be carried out for each node to estimate the inﬂuence  which results in an
overall O(n|V||E|) algorithm. Thus  our goal is to design a scalable algorithm which can perform
inﬂuence estimation and maximization in this regime of networks with millions of nodes.
In particular  we propose CONTINEST (Continous-Time Inﬂuence Estimation)  a scalable rando-
mized algorithm for inﬂuence estimation in a continuous-time diffusion network with heterogeneous
edge transmission functions. The key idea of the algorithm is to view the problem from the perspec-
tive of graphical model inference  and reduces the problem to a neighborhood estimation problem
in graphs. Our algorithm can estimate the inﬂuence of every node in a network with |V| nodes and
|E| edges to an accuracy of  using n = O(1/2) randomizations and up to logarithmic factors
O(n|E| + n|V|) computations. When used as a subroutine in a greedy inﬂuence maximization al-
gorithm  our proposed algorithm is guaranteed to ﬁnd a set of nodes with an inﬂuence of at least
(1 − 1/e) OPT−2C  where OPT is the optimal value. Finally  we validate CONTINEST on both
inﬂuence estimation and maximization problems over large synthetic and real world datasets. In
terms of inﬂuence estimation  CONTINEST is much closer to the true inﬂuence and much faster
than other state-of-the-art methods. With respect to the inﬂuence maximization  CONTINEST al-
lows us to ﬁnd a set of sources with greater inﬂuence than other state-of-the-art methods.

2 Continuous-Time Diffusion Networks
First  we revisit the continuous-time generative model for cascade data in social networks introduced
in [10]. The model associates each edge j → i with a transmission function  fji(τji)  a density over
time  in contrast to previous discrete-time models which associate each edge with a ﬁxed infection
probability [1]. Moreover  it also differs from discrete-time models in the sense that events in a
cascade are not generated iteratively in rounds  but event timings are sampled directly from the
transmission function in the continuous-time model.
Continuous-Time Independent Cascade Model. Given a directed contact network  G = (V E) 
we use a continuous-time independent cascade model for modeling a diffusion process [10]. The
process begins with a set of infected source nodes  A  initially adopting certain contagion (idea 
meme or product) at time zero. The contagion is transmitted from the sources along their out-going
edges to their direct neighbors. Each transmission through an edge entails a random spreading time 
τ  drawn from a density over time  fji(τ ). We assume transmission times are independent and
possibly distributed differently across edges. Then  the infected neighbors transmit the contagion
to their respective neighbors  and the process continues. We assume that an infected node remains
infected for the entire diffusion process. Thus  if a node i is infected by multiple neighbors  only the
neighbor that ﬁrst infects node i will be the true parent. As a result  although the contact network
can be an arbitrary directed network  each cascade (a vector of event timing information from the
spread of a contagion) induces a Directed Acyclic Graph (DAG).
Heterogeneous Transmission Functions. Formally  the transmission function fji(ti|tj) for di-
rected edge j → i is the conditional density of node i getting infected at time ti given that node j
was infected at time tj. We assume it is shift invariant: fji(ti|tj) = fji(τji)  where τji := ti − tj 
and nonnegative: fji(τji) = 0 if τji < 0. Both parametric transmission functions  such as the ex-
ponential and Rayleigh function [10  16]  and nonparametric function [8] can be used and estimated
from cascade data (see Appendix A for more details).
Shortest-Path property. The independent cascade model has a useful property we will use later:
given a sample of transmission times of all edges  the time ti taken to infect a node i is the length

2

of the shortest path in G from the sources to node i  where the edge weights correspond to the
associated transmission times.
3 Graphical Model Perspectives for Continuous-Time Diffusion Networks
The continuous-time independent cascade model is essentially a directed graphical model for a set of
dependent random variables  the infection times ti of the nodes  where the conditional independence
structure is supported on the contact network G (see Appendix B for more details). More formally 
the joint density of {ti}i∈V can be expressed as

p ({ti}i∈V ) =

(1)
where πi denotes the set of parents of node i in a cascade-induced DAG  and p(ti|{tj}j∈πi) is the
conditional density of infection ti at node i given the infection times of its parents.
Instead of directly modeling the infection times ti  we can focus on the set of mutually independent
random transmission times τji = ti − tj. Interestingly  by switching from a node-centric view to an
edge-centric view  we obtain a fully factorized joint density of the set of transmission times

(cid:89)
i∈V p (ti|{tj}j∈πi )  

p(cid:0){τji}(j i)∈E(cid:1) =

(cid:89)

(j i)∈E fji(τji) 

(2)

Based on the Shortest-Path property of the independent cascade model  each variable ti can be
viewed as a transformation from the collection of variables {τji}(j i)∈E.
More speciﬁcally  let Qi be the collection of directed paths in G from the source nodes to node i 
where each path q ∈ Qi contains a sequence of directed edges (j  l). Assuming all source nodes are
infected at zero time  then we obtain variable ti via

(cid:0){τji}(j i)∈E(cid:1) := min

(cid:88)

(3)
where the transformation gi(·) is the value of the shortest-path minimization. As a special case  we
can now compute the probability of node i infected before T using a set of independent variables:

ti = gi

(j l)∈q

q∈Qi

τjl 

Pr{ti ≤ T} = Pr(cid:8)gi

(cid:0){τji}(j i)∈E(cid:1) ≤ T(cid:9) .

Inﬂuence Estimation Problem in Continuous-Time Diffusion Networks

(4)
The signiﬁcance of the relation is that it allows us to transform a problem involving a sequence of
dependent variables {ti}i∈V to one with independent variables {τji}(j i)∈E. Furthermore  the two
perspectives are connected via the shortest path algorithm in weighted directed graph  a standard
well-studied operation in graph analysis.
4
Intuitively  given a time window  the wider the spread of infection  the more inﬂuential the set of
sources. We adopt the deﬁnition of inﬂuence as the average number of infected nodes given a set of
source nodes and a time window  as in previous work [7]. More formally  consider a set of C source
nodes A ⊆ V which gets infected at time zero  then  given a time window T   a node i is infected in
the time window if ti ≤ T . The expected number of infected nodes (or the inﬂuence) given the set
of transmission functions {fji}(j i)∈E can be computed as

=

i∈V

(5)
where I{·} is the indicator function and the expectation is taken over the the set of dependent
variables {ti}i∈V.
Essentially  the inﬂuence estimation problem in Eq. (5) is an inference problem for graphical models 
where the probability of event ti ≤ T given sources in A can be obtained by summing out the
possible conﬁguration of other variables {tj}j(cid:54)=i. That is

i∈V

i∈V Pr{ti ≤ T}  

E [I{ti ≤ T}] =

(cid:88)

σ(A  T ) = E(cid:104)(cid:88)

I{ti ≤ T}(cid:105)

(cid:88)

(cid:90) ∞

(cid:16)(cid:89)
j∈V p(cid:0)tj|{tl}l∈πj

(cid:1)(cid:17)(cid:16)(cid:89)

(cid:17)

j∈V dtj

 

(6)

Pr{ti ≤ T} =

···

···

0

ti=0

0

(cid:90) ∞

(cid:90) T

which is  in general  a very challenging problem. First  the corresponding directed graphical models
can contain nodes with high in-degree and high out-degree. For example  in Twitter  a user can
follow dozens of other users  and another user can have hundreds of “followees”. The tree-width
corresponding to this directed graphical model can be very high  and we need to perform integration
for functions involving many continuous variables. Second  the integral in general can not be eval-

3

uated analytically for heterogeneous transmission functions  which means that we need to resort to
numerical integration by discretizing the domain [0 ∞). If we use N level of discretization for each
variable  we would need to enumerate O(N|πi|) entries  exponential in the number of parents.
Only in very special cases  can one derive the closed-form equation for computing Pr{ti ≤ T} [7].
However  without further heuristic approximation  the computational complexity of the algorithm
is exponential in the size and density of the network. The intrinsic complexity of the problem
entails the utilization of approximation algorithms  such as mean ﬁeld algorithms or message passing
algorithms.We will design an efﬁcient randomized (or sampling) algorithm in the next section.
5 Efﬁcient Inﬂuence Estimation in Continuous-Time Diffusion Networks
Our ﬁrst key observation is that we can transform the inﬂuence estimation problem in Eq. (5) into a
problem with independent variables. Using relation in Eq. (4)  we have

(cid:88)

i∈V Pr(cid:8)gi

(cid:0){τji}(j i)∈E(cid:1) ≤ T(cid:9) = E(cid:104)(cid:88)

I(cid:8)gi

(cid:0){τji}(j i)∈E(cid:1) ≤ T(cid:9)(cid:105)

σ(A  T ) =

 

i∈V

borhood size of the source nodes  i.e.  the summation (cid:80)

(7)
where the expectation is with respect to the set of independent variables {τji}(j i)∈E. This equivalent
formulation suggests a naive sampling (NS) algorithm for approximating σ(A  T ): draw n samples
of {τji}(j i)∈E  run a shortest path algorithm for each sample  and ﬁnally average the results (see
Appendix C for more details). However  this naive sampling approach has a computational com-
plexity of O(nC|V||E| + nC|V|2 log |V|) due to the repeated calling of the shortest path algorithm.
This is quadratic to the network size  and hence not scalable to millions of nodes.
Our second key observation is that for each sample {τji}(j i)∈E  we are only interested in the neigh-
i∈V I{·} in Eq. (7)  rather than in the
individual shortest paths. Fortunately  the neighborhood size estimation problem has been studied
in the theoretical computer science literature. Here  we adapt a very efﬁcient randomized algorithm
by Cohen [17] to our inﬂuence estimation problem. This randomized algorithm has a computational
complexity of O(|E| log |V| + |V| log2 |V|) and it estimates the neighborhood sizes for all possible
single source node locations. Since it needs to run once for each sample of {τji}(j i)∈E  we obtain
an overall inﬂuence estimation algorithm with O(n|E| log |V| + n|V| log2 |V|) computation  nearly
linear in network size. Next we will revisit Cohen’s algorithm for neighborhood estimation.
5.1 Randomized Algorithm for Single-Source Neighborhood Size Estimation
Given a ﬁxed set of edge transmission times {τji}(j i)∈E and a source node s  infected at time 0  the
neighborhood N (s  T ) of a source node s given a time window T is the set of nodes within distance
T from s  i.e. 

N (s  T ) =(cid:8)i(cid:12)(cid:12) gi

(cid:0){τji}(j i)∈E(cid:1) ≤ T  i ∈ V(cid:9) .

(8)
Instead of estimating N (s  T ) directly  the algorithm will assign an exponentially distributed ran-
dom label ri to each network node i. Then  it makes use of the fact that the minimum of a set of
exponential random variables {ri}i∈N (s T ) will also be a exponential random variable  but with its
parameter equals to the number of variables. That is if each ri ∼ exp(−ri)  then the smallest label
within distance T from source s  r∗ := mini∈N (s T ) ri  will distribute as r∗ ∼ exp{−|N (s  T )|r∗}.
Suppose we randomize over the labeling m times  and obtain m such least labels  {ru∗}m
u=1. Then
the neighborhood size can be estimated as

.

u=1 ru∗

(9)
which is shown to be an unbiased estimator of |N (s  T )| [17]. This is an interesting relation since
it allows us to transform the counting problem in (8) to a problem of ﬁnding the minimum random
label r∗. The key question is whether we can compute the least label r∗ efﬁciently  given random
labels {ri}i∈V and any source node s.
Cohen [17] designed a modiﬁed Dijkstra’s algorithm (Algorithm 1) to construct a data structure
r∗(s)  called least label list  for each node s to support such query. Essentially  the algorithm starts
with the node i with the smallest label ri  and then it traverses in breadth-ﬁrst search fashion along
the reverse direction of the graph edges to ﬁnd all reachable nodes. For each reachable node s  the
distance d∗ between i and s  and ri are added to the end of r∗(s). Then the algorithm moves to the
node i(cid:48) with the second smallest label ri(cid:48)  and similarly ﬁnd all reachable nodes. For each reachable

|N (s  T )| ≈ m − 1(cid:80)m

4

node s  the algorithm will compare the current distance d∗ between i(cid:48) and s with the last recorded
distance in r∗(s). If the current distance is smaller  then the current d∗ and ri(cid:48) are added to the end
of r∗(s). Then the algorithm move to the node with the third smallest label and so on. The algorithm
is summarized in Algorithm 1 in Appendix D.
Algorithm 1 returns a list r∗(s) per node s ∈ V  which contains information about distance to the
smallest reachable labels from s. In particular  each list contains pairs of distance and random labels 
(d  r)  and these pairs are ordered as

∞ > d(1) > d(2) > . . . > d(|r∗(s)|) = 0

(10)
(11)
where {·}(l) denotes the l-th element in the list. (see Appendix D for an example). If we want to
query the smallest reachable random label r∗ for a given source s and a time T   we only need to
perform a binary search on the list for node s:

r(1) < r(2) < . . . < r(|r∗(s)|) 

r∗ = r(l)  where d(l−1) > T ≥ d(l).

(12)
Finally  to estimate |N (s  T )|  we generate m i.i.d. collections of random labels  run Algorithm 1
u=1  which we use on Eq. (9) to estimate |N (i  T )|.
on each collection  and obtain m values {ru∗}m
The computational complexity of Algorithm 1 is O(|E| log |V| + |V| log2 |V|)  with expected size
of each r∗(s) being O(log |V|). Then the expected time for querying r∗ is O(log log |V|) using
binary search. Since we need to generate m set of random labels and run Algorithm 1 m times  the
overall computational complexity for estimating the single-source neighborhood size for all s ∈ V
is O(m|E| log |V| + m|V| log2 |V| + m|V| log log |V|). For large scale network  and when m (cid:28)
min{|V| |E|}  this randomized algorithm can be much more efﬁcient than approaches based on
directly calculating the shortest paths.

5.2 Constructing Estimation for Multiple-Source Neighborhood Size
When we have a set of sources  A  its neighborhood is the union of the neighborhoods of its consti-
tuent sources

(cid:91)
i∈A N (i  T ).

N (A  T ) =

(13)

This is true because each source independently infects its downstream nodes. Furthermore  to cal-
culate the least label list r∗ corresponding to N (A  T )  we can simply reuse the least label list r∗(i)
of each individual source i ∈ A. More formally 

r∗ = mini∈A minj∈N (i T ) rj 

(14)
where the inner minimization can be carried out by querying r∗(i). Similarly  after we obtain m
samples of r∗  we can estimate |N (A  T )| using Eq. (9). Importantly  very little additional work is
needed when we want to calculate r∗ for a set of sources A  and we can reuse work done for a single
source. This is very different from a naive sampling approach where the sampling process needs to
be done completely anew if we increase the source set. In contrast  using the randomized algorithm 
only an additional constant-time minimization over |A| numbers is needed.

5.3 Overall Algorithm
So far  we have achieved efﬁcient neighborhood size estimation of |N (A  T )| with respect to a
given set of transmission times {τji}(j i)∈E. Next  we will estimate the inﬂuence by averaging over
multiple sets of samples for {τji}(j i)∈E. More speciﬁcally  the relation from (7)

σ(A  T ) = E{τji}(j i)∈E [|N (A  T )|] = E{τji}E{r1 ... rm}|{τji}

 

(15)

(cid:21)

(cid:20) m − 1(cid:80)m

u=1 ru∗

suggests the following overall algorithm

Continuous-Time Inﬂuence Estimation (CONTINEST):
1. Sample n sets of random transmission times {τ l
2. Given a set of {τ l
3. Estimate σ(A  T ) by sample averages σ(A  T ) ≈ 1

ij}(j i)∈E  sample m sets of random labels {ru

ij}(j i)∈E ∼ (cid:81)
(cid:80)n

i }i∈V ∼ (cid:81)
(cid:0)(m − 1)/(cid:80)m

(j i)∈E fji(τji)

n

l=1

i∈V exp(−ri)

ul=1 rul∗ (cid:1)

5

(cid:18) 2|V|

(cid:19)

n (cid:62) CΛ

Importantly  the number of random labels  m  does not need to be very large. Since the estimator
for |N (A  T )| is unbiased [17]  essentially the outer-loop of averaging over n samples of random
transmission times further reduces the variance of the estimator in a rate of O(1/n). In practice 
we can use a very small m (e.g.  5 or 10) and still achieve good results  which is also conﬁrmed
by our later experiments. Compared to [2]  the novel application of Cohen’s algorithm arises for
estimating inﬂuence for multiple sources  which drastically reduces the computation by cleverly
using the least-label list from single source. Moreover  we have the following theoretical guarantee
(see Appendix E for proof)
Theorem 1 Draw the following number of samples for the set of random transmission times

(16)
where Λ := maxA:|A|≤C 2σ(A  T )2/(m − 2) + 2V ar(|N (A  T )|)(m − 1)/(m − 2) + 2a/3 and
|N (A  T )| ≤ a  and for each set of random transmission times  draw m set of random labels. Then

|(cid:98)σ(A  T ) − σ(A  T )| (cid:54)  uniformly for all A with |A| (cid:54) C  with probability at least 1 − δ.

2 log

δ

The theorem indicates that the minimum number of samples  n  needed to achieve certain accuracy
is related to the actual size of the inﬂuence σ(A  T )  and the variance of the neighborhood size
|N (A  T )| over the random draw of samples. The number of random labels  m  drawn in the inner
loop of the algorithm will monotonically decrease the dependency of n on σ(A  T ). It sufﬁces to
draw a small number of random labels  as long as the value of σ(A  T )2/(m − 2) matches that
of V ar(|N (A  T )|). Another implication is that inﬂuence at larger time window T is harder to
estimate  since σ(A  T ) will generally be larger and hence require more random labels.

Inﬂuence Maximization

6
Once we know how to estimate the inﬂuence σ(A  T ) for any A ⊆ V and time window T efﬁciently 
we can use them in ﬁnding the optimal set of C source nodes A∗ ⊆ V such that the expected number
of infected nodes in G is maximized at T . That is  we seek to solve 

A∗ = argmax|A|(cid:54)C σ(A  T ) 

(17)
where set A is the variable. The above optimization problem is NP-hard in general. By construction 
σ(A  T ) is a non-negative  monotonic nondecreasing function in the set of source nodes  and it can
be shown that σ(A  T ) satisﬁes a diminishing returns property called submodularity [7].
A well-known approximation algorithm to maximize monotonic submodular functions is the greedy
algorithm. It adds nodes to the source node set A sequentially. In step k  it adds the node i which
maximizes the marginal gain σ(Ak−1 ∪{i}; T )− σ(Ak−1; T ). The greedy algorithm ﬁnds a source
node set which achieves at least a constant fraction (1 − 1/e) of the optimal [18]. Moreover  lazy
evaluation [5] can be employed to reduce the required number of marginal gains per iteration. By
using our inﬂuence estimation algorithm in each iteration of the greedy algorithm  we gain the
following additional beneﬁts:
First  at each iteration k  we do not need to rerun the full inﬂuence estimation algorithm (section 5.2).
We just need to store the least label list r∗(i) for each node i ∈ V computed for a single source 
which requires expected storage size of O(|V| log |V|) overall.
Second  our inﬂuence estimation algorithm can be easily parallelized. Its two nested sampling loops
can be parallelized in a straightforward way since the variables are independent of each other. How-
ever  in practice  we use a small number of random labels  and m (cid:28) n. Thus we only need to
parallelize the sampling for the set of random transmission times {τji}. The storage of the least
element lists can also be distributed.
However  by using our randomized algorithm for inﬂuence estimation  we also introduce a sampling
error to the greedy algorithm due to the approximation of the inﬂuence σ(A  T ). Fortunately  the
greedy algorithm is tolerant to such sampling noise  and a well-known result provides a guarantee
for this case (following an argument in [19  Th. 7.9]):
Theorem 2 Suppose the inﬂuence σ(A  T ) for all A with |A| ≤ C are estimated uniformly with
(1 − 1/e)OP T − 2C with probability at least 1 − δ.

error  and conﬁdence 1 − δ  the greedy algorithm returns a set of sources (cid:98)A such that σ((cid:98)A  T ) ≥

6

(a) Inﬂuence vs. time

(b) Error vs. #samples

(c) Error vs. #labels

Figure 1: For core-periphery networks with 1 024 nodes and 2 048 edges  (a) estimated inﬂuence for increas-
ing time window T   and (b) ﬁxing T = 10  relative error for increasing number of samples with 5 random
labels  and (c) for increasing number of random labels with 10 000 random samples.
7 Experiments

(cid:0) t

α

e−(t/α)β

(cid:1)β−1

We evaluate the accuracy of the estimated inﬂuence given by CONTINEST and investigate the per-
formance of inﬂuence maximization on synthetic and real networks. We show that our approach
signiﬁcantly outperforms the state-of-the-art methods in terms of both speed and solution quality.
Synthetic network generation. We generate three types of Kronecker networks [20]: (i) core-
periphery networks (parameter matrix:
[0.9 0.5; 0.5 0.3])  which mimic the information dif-
fusion traces in real world networks [21]  (ii) random networks ([0.5 0.5; 0.5 0.5])  typically
used in physics and graph theory [22] and (iii) hierarchical networks ([0.9 0.1; 0.1 0.9]) [10].
Next  we assign a pairwise transmission function for every directed edge in each type of net-
work and set its parameters at random. In our experiments  we use the Weibull distribution [16] 
  t (cid:62) 0  where α > 0 is a scale parameter and β > 0 is a shape
f (t; α  β) = β
α
parameter. The Weibull distribution (Wbl) has often been used to model lifetime events in survival
analysis  providing more ﬂexibility than an exponential distribution [16]. We choose α and β from 0
to 10 uniformly at random for each edge in order to have heterogeneous temporal dynamics. Finally 
for each type of Kronecker network  we generate 10 sample networks  each of which has different
α and β chosen for every edge.
Accuracy of the estimated inﬂuence. To the best of our knowledge  there is no analytical solu-
tion to the inﬂuence estimation given Weibull transmission function. Therefore  we compare CON-
TINEST with Naive Sampling (NS) approach (see Appendix C) by considering the highest degree
node in a network as the source  and draw 1 000 000 samples for NS to obtain near ground truth.
Figures 1(a) compares CONTINEST with the ground truth provided by NS at different time window
T   from 0.1 to 10 in corre-periphery networks. For CONTINEST  we generate up to 10 000 ran-
dom samples (or set of random waiting times)  and 5 random labels in the inner loop. In all three
networks  estimation provided by CONTINEST ﬁts accurately the ground truth  and the relative er-
ror decreases quickly as we increase the number of samples and labels (Figures 1(b) and 1(c)). For
10 000 random samples with 5 random labels  the relative error is smaller than 0.01. (see Appendix F
for additional results on the random and hierarchal networks)
Scalability. We compare CONTINEST to the state-of-the-art method INFLUMAX [7] and the Naive
Sampling (NS) method in terms of runtime for the continuous-time inﬂuence estimation and maxi-
mization. For CONTINEST  we draw 10 000 samples in the outer loop  each having 5 random labels
in the inner loop. For NS  we also draw 10 000 samples. The ﬁrst two experiments are carried out
in a single 2.4GHz processor. First  we compare the performance of increasingly selecting sources
(from 1 to 10) on small core-periphery networks (Figure 2(a)). When the number of selected sources
is 1  different algorithms essentially spend time estimating the inﬂuence for each node. CONTINEST
outperforms other methods by order of magnitude and for the number of sources larger than 1  it can
efﬁciently reuse computations for estimating inﬂuence for individual nodes. Dashed lines mean that
a method did not ﬁnish in 24 hours  and the estimated run time is plotted. Next  we compare the run
time for selecting 10 sources on core-periphery networks of 128 nodes with increasing densities (or
the number of edges) (Figure 2(a)). Again  INFLUMAX and NS are order of magnitude slower due to
their respective exponential and quadratic computational complexity in network density. In contrast 
the run time of CONTINEST only increases slightly with the increasing density since its compu-
tational complexity is linear in the number of edges (see Appendix F for additional results on the
random and hierarchal networks). Finally  we evaluate the speed on large core-periphery networks 
ranging from 100 to 1 000 000 nodes with density 1.5 in Figure 2(c). We report the parallel run time

7

246810050100150200Tinfluence  NSConTinEst10210310400.020.040.060.08#samplesrelative error5102030405002468x 10−3#labelsrelative error(a) Run time vs. # sources (b) Run time vs. network density (c) Run time vs. #nodes

Figure 2: For core-periphery networks with T = 10  runtime for (a) selecting increasing number of sources
in networks of 128 nodes and 320 edges; for (b)selecting 10 sources in networks of 128 nodes with increasing
density; and for (c) selecting 10 sources with increasing network size from 100 to 1 000 000 ﬁxing 1.5 density.

(a) Inﬂuence estimation error (b) Inﬂuence vs. #sources

(c) Inﬂuence vs. time

Figure 3:
In MemeTracker dataset  (a) comparison of the accuracy of the estimated inﬂuence in terms of
mean absolute error  (b) comparison of the inﬂuence of the selected nodes by ﬁxing the observation window
T = 5 and varying the number sources  and (c) comparison of the inﬂuence of the selected nodes by by ﬁxing
the number of sources to 50 and varying the time window.
only for CONTINEST and NS (both are implemented by MPI running on 192 cores of 2.4Ghz) since
INFLUMAX is not scalable. In contrast to NS  the performance of CONTINEST increases linearly
with the network size and can easily scale up to one million nodes.
Real-world data. We ﬁrst quantify how well each method can estimate the true inﬂuence in a
real-world dataset. Then  we evaluate the solution quality of the selected sources for inﬂuence max-
imization. We use the MemeTracker dataset [23] which has 10 967 hyperlink cascades among 600
media sites. We repeatedly split all cascades into a 80% training set and a 20% test set at random
for ﬁve times. On each training set  we learn the continuous-time model using NETRATE [10] with
exponential transmission functions. For discrete-time model  we learn the infection probabilities
using [24] for IC  SP1M and PMIA. Similarly  for LT  we follow the methodology by [1]. Let C(u)
be the set of all cascades where u was the source node. Based on C(u)  the total number of distinct
nodes infected before T quantiﬁes the real inﬂuence of node u up to time T . In Figure 3(a)  we
report the Mean Absolute Error (MAE) between the real and the estimated inﬂuence. Clearly  CON-
TINEST performs the best statistically. Because the length of real cascades empirically conforms
to a power-law distribution where most cascades are very short (2-4 nodes)  the gap of the estima-
tion error is relatively not large. However  we emphasize that such accuracy improvement is critical
for maximizing long-term inﬂuence. The estimation error for individuals will accumulate along the
spreading paths. Hence  any consistent improvement in inﬂuence estimation can lead to signiﬁcant
improvement to the overall inﬂuence estimation and maximization task  which is further conﬁrmed
by Figures 3(b) and 3(c) where we evaluate the inﬂuence of the selected nodes in the same spirit as
inﬂuence estimation: the true inﬂuence is calculated as the total number of distinct nodes infected
before T based on C(u) of the selected nodes. The selected sources given by CONTINEST achieve
the best performance as we vary the number of selected sources and the observation time window.
8 Conclusions
We propose a randomized inﬂuence estimation algorithm in continuous-time diffusion networks 
which can scale up to networks of millions of nodes while signiﬁcantly improves over previous state-
of-the-arts in terms of the accuracy of the estimated inﬂuence and the quality of the selected nodes
in maximizing the inﬂuence. In future work  it will be interesting to apply the current algorithm
to other tasks like inﬂuence minimization and manipulation  and design scalable algorithms for
continuous-time models other than the independent cascade model.
Acknowledgement: Our work is supported by NSF/NIH BIGDATA 1R01GM108341-01  NSF
IIS1116886  NSF IIS1218749  NSFC 61129001  a DARPA Xdata grant and Raytheon Faculty Fel-
lowship of Gatech.

8

12345678910100101102103104105#sourcestime(s)  ConTinEstNSInflumax> 24 hours1.522.533.544.55100101102103104105densitytime(s)  ConTinEstNSInflumax> 24 hours102103104105106102103104105106#nodestime(s)  ConTinEstNS> 48 hours10203040500.511.522.533.5TMAE  ConTinEstICLTSP1MPMIA010203040500102030405060#sourcesinfluence  ConTinEstGreedy(IC)Greedy(LT)SP1MPMIA05101520020406080Tinfluence  ConTinEst(Wbl)Greedy(IC)Greedy(LT)SP1MPMIAReferences
[1] David Kempe  Jon Kleinberg  and ´Eva Tardos. Maximizing the spread of inﬂuence through a

social network. In KDD  pages 137–146  2003.

[2] Wei Chen  Yajun Wang  and Siyu Yang. Efﬁcient inﬂuence maximization in social networks.

In KDD  pages 199–208  2009.

[3] Wei Chen  Yifei Yuan  and Li Zhang. Scalable inﬂuence maximization in social networks

under the linear threshold model. In ICDM  pages 88–97  2010.

[4] Amit Goyal  Francesco Bonchi  and Laks V. S. Lakshmanan. A data-based approach to social

inﬂuence maximization. Proc. VLDB Endow.  5  2011.

[5] Jure Leskovec  Andreas Krause  Carlos Guestrin  Christos Faloutsos  Jeanne M. VanBriesen 
and Natalie S. Glance. Cost-effective outbreak detection in networks. In KDD  pages 420–429 
2007.

[6] Matthew Richardson and Pedro Domingos. Mining knowledge-sharing sites for viral market-

ing. In KDD  pages 61–70  2002.

[7] Manuel Gomez-Rodriguez and Bernhard Sch¨olkopf.

time diffusion networks. In ICML ’12  2012.

Inﬂuence maximization in continuous

[8] Nan Du  Le Song  Alexander J. Smola  and Ming Yuan. Learning networks of heterogeneous

inﬂuence. In NIPS  2012.

[9] Nan Du  Le Song  Hyenkyun Woo  and Hongyuan Zha. Uncover topic-sensitive information

diffusion networks. In AISTATS  2013.

[10] Manuel Gomez-Rodriguez  David Balduzzi  and Bernhard Sch¨olkopf. Uncovering the tempo-

ral dynamics of diffusion networks. In ICML  pages 561–568  2011.

[11] Manuel Gomez-Rodriguez  Jure Leskovec  and Bernhard Sch¨olkopf. Structure and Dynamics

of Information Pathways in On-line Media. In WSDM  2013.

[12] Ke Zhou  Le Song  and Hongyuan Zha. Learning social infectivity in sparse low-rank networks
using multi-dimensional hawkes processes. In Artiﬁcial Intelligence and Statistics (AISTATS) 
2013.

[13] Ke Zhou  Hongyuan Zha  and Le Song. Learning triggering kernels for multi-dimensional

hawkes processes. In International Conference on Machine Learning(ICML)  2013.

[14] Manuel Gomez-Rodriguez  Jure Leskovec  and Bernhard Sch¨olkopf. Modeling information

propagation with survival theory. In ICML  2013.

[15] Shuanghong Yang and Hongyuan Zha. Mixture of mutually exciting processes for viral diffu-

sion. In International Conference on Machine Learning(ICML)  2013.

[16] Jerald F. Lawless. Statistical Models and Methods for Lifetime Data. Wiley-Interscience  2002.
[17] Edith Cohen. Size-estimation framework with applications to transitive closure and reachabil-

ity. Journal of Computer and System Sciences  55(3):441–453  1997.

[18] GL Nemhauser  LA Wolsey  and ML Fisher. An analysis of approximations for maximizing

submodular set functions. Mathematical Programming  14(1)  1978.

[19] Andreas Krause. Ph.D. Thesis. CMU  2008.
[20] Jure Leskovec  Deepayan Chakrabarti  Jon M. Kleinberg  Christos Faloutsos  and Zoubin

Ghahramani. Kronecker graphs: An approach to modeling networks. JMLR  11  2010.

[21] Manuel Gomez-Rodriguez  Jure Leskovec  and Andreas Krause. Inferring networks of diffu-

sion and inﬂuence. In KDD  2010.

[22] David Easley and Jon Kleinberg. Networks  Crowds  and Markets: Reasoning About a Highly

Connected World. Cambridge University Press  2010.

[23] Jure Leskovec  Lars Backstrom  and Jon M. Kleinberg. Meme-tracking and the dynamics of

the news cycle. In KDD  2009.

[24] Praneeth Netrapalli and Sujay Sanghavi. Learning the graph of epidemic cascades. In SIG-

METRICS/PERFORMANCE  pages 211–222. ACM  2012.

[25] Wei Chen  Chi Wang  and Yajun Wang. Scalable inﬂuence maximization for prevalent viral

marketing in large-scale social networks. In KDD ’10  pages 1029–1038  2010.

9

,Nan Du
Le Song
Manuel Gomez Rodriguez
Hongyuan Zha
Sainbayar Sukhbaatar
arthur szlam
Jason Weston
Rob Fergus
Kevin Scaman
Francis Bach
Sebastien Bubeck
Laurent Massoulié
Yin Tat Lee
Ryan Tibshirani
Rina Foygel Barber
Emmanuel Candes
Aaditya Ramdas