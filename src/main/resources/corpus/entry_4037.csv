2016,Online ICA: Understanding Global Dynamics of Nonconvex Optimization via Diffusion Processes,Solving statistical learning problems often involves nonconvex optimization. Despite the empirical success of nonconvex statistical optimization methods  their global dynamics  especially convergence to the desirable local minima  remain less well understood in theory. In this paper  we propose a new analytic paradigm based on diffusion processes to characterize the global dynamics of nonconvex statistical optimization. As a concrete example  we study stochastic gradient descent (SGD) for the tensor decomposition formulation of independent component analysis. In particular  we cast different phases of SGD into diffusion processes  i.e.  solutions to stochastic differential equations. Initialized from an unstable equilibrium  the global dynamics of SGD transit over three consecutive phases: (i) an unstable Ornstein-Uhlenbeck process slowly departing from the initialization  (ii) the solution to an ordinary differential equation  which quickly evolves towards the desirable local minimum  and (iii) a stable Ornstein-Uhlenbeck process oscillating around the desirable local minimum. Our proof techniques are based upon Stroock and Varadhan’s weak convergence of Markov chains to diffusion processes  which are of independent interest.,Online ICA: Understanding Global Dynamics of
Nonconvex Optimization via Diffusion Processes

Chris Junchi Li

Zhaoran Wang

Han Liu

Department of Operations Research and Financial Engineering  Princeton University

{junchil  zhaoran  hanliu}@princeton.edu

Abstract

Solving statistical learning problems often involves nonconvex optimization. De-
spite the empirical success of nonconvex statistical optimization methods  their
global dynamics  especially convergence to the desirable local minima  remain
less well understood in theory. In this paper  we propose a new analytic paradigm
based on diffusion processes to characterize the global dynamics of nonconvex
statistical optimization. As a concrete example  we study stochastic gradient de-
scent (SGD) for the tensor decomposition formulation of independent component
analysis. In particular  we cast different phases of SGD into diffusion processes 
i.e.  solutions to stochastic differential equations. Initialized from an unstable equi-
librium  the global dynamics of SGD transit over three consecutive phases: (i) an
unstable Ornstein-Uhlenbeck process slowly departing from the initialization  (ii)
the solution to an ordinary differential equation  which quickly evolves towards the
desirable local minimum  and (iii) a stable Ornstein-Uhlenbeck process oscillating
around the desirable local minimum. Our proof techniques are based upon Stroock
and Varadhan’s weak convergence of Markov chains to diffusion processes  which
are of independent interest.

Introduction

1
For solving a broad range of large-scale statistical learning problems  e.g.  deep learning  nonconvex
optimization methods often exhibit favorable computational and statistical efﬁciency empirically.
However  there is still a lack of theoretical understanding of the global dynamics of these nonconvex
optimization methods. In speciﬁc  it remains largely unexplored why simple optimization algorithms 
e.g.  stochastic gradient descent (SGD)  often exhibit fast convergence towards local minima with de-
sirable statistical accuracy. In this paper  we aim to develop a new analytic framework to theoretically
understand this phenomenon.
The dynamics of nonconvex statistical optimization are of central interest to a recent line of work.
Speciﬁcally  by exploring the local convexity within the basins of attraction  [1  5–8  10–13  20–
22  24–26  31  35  36  39  46–58] establish local fast rates of convergence towards the desirable local
minima for a variety statistical problems. Most of these characterizations of local dynamics are based
on two decoupled ingredients from statistics and optimization: (i) the local (approximately) convex
geometry of the objective functions  which is induced by the underlying statistical models  and (ii)
adaptation of classical optimization analysis [19  34] by incorporating the perturbations induced by
nonconvex geometry as well as random noise. To achieve global convergence guarantees  they rely
on various problem-speciﬁc approaches to obtain initializations that provably fall into the basins of
attraction. Meanwhile  for some learning problems  such as phase retrieval and tensor decomposition
for latent variable models  it is empirically observed that good initializations within the basins of
attraction are not essential to the desirable convergence. However  it remains highly challenging to
characterize the global dynamics  especially within the highly nonconvex regions outside the local
basins of attraction.
In this paper  we address this problem with a new analytic framework based on diffusion processes.
In particular  we focus on the concrete example of SGD applied on the tensor decomposition formula-
30th Conference on Neural Information Processing Systems (NIPS 2016)  Barcelona  Spain.

tion of independent component analysis (ICA). Instead of adapting classical optimization analysis
accordingly to local nonconvex geometry  we cast SGD in different phases as diffusion processes 
i.e.  solutions to stochastic differential equations (SDE)  by analyzing the weak convergence from
discrete Markov chains to their continuous-time limits [17  40]. The SDE automatically incorporates
the geometry and randomness induced by the statistical model  which allows us to establish the
exact dynamics of SGD. In contrast  classical optimization analysis only yields upper bounds on
the optimization error  which are unlikely to be tight in the presence of highly nonconvex geometry 
especially around the stationary points that have negative curvatures along certain directions. In
particular  we identify three consecutive phases of the global dynamics of SGD  which is illustrated
in Figure 1.

(i) We consider the most challenging initialization at a stationary point with negative curvatures 
which can be cast as an unstable equilibrium of the SDE. Within the ﬁrst phase  the dynamics
of SGD are characterized by an unstable Ornstein-Uhlenbeck process [2  37]  which departs
from the initialization at a relatively slow rate and enters the second phase.

(ii) Within the second phase  the dynamics of SGD are characterized by the exact solution to an
ordinary differential equation. This solution evolves towards the desirable local minimum at
a relatively fast rate until it approaches a small basin around the local minimum.

(iii) Within the third phase  the dynamics of SGD are captured by a stable Ornstein-Uhlenbeck

process [2  37]  which oscillates within a small basin around the local minimum.

Local
Minima

Other
Stationary
Points

Objective
Value

(i)

(ii)

(iii)

Time

Figure 1: Left: an illustration of the objective function for the tensor decomposition formulation of
ICA. Note that here we use the spherical coordinate system and add a global offset of 2 to the objective
function for better illustration. Right: An illustration of the three phases of diffusion processes.

More related work. Our results are connected with a very recent line of work [3  18  27  29  38  42–
45] on the global dynamics of nonconvex statistical optimization. In detail  they characterize the
global geometry of nonconvex objective functions  especially around their saddle points or local
maxima. Based on the geometry  they prove that speciﬁc optimization algorithms  e.g.  SGD with
artiﬁcial noise injection  gradient descent with random initialization  and second-order methods  avoid
the saddle points or local maxima  and globally converge to the desirable local minima. Among
these results  our results are most related to [18]  which considers SGD with noise injection on
ICA. Compared with this line of work  our analysis takes a completely different approach based on
diffusion processes  which is also related to another line of work [14  15  30  32  33  41].
Without characterizing the global geometry  we establish the global exact dynamics of SGD  which
illustrate that  even starting from the most challenging stationary point  it may be unnecessary to use
additional techniques such as noise injection  random initialization  and second-order information to
ensure the desirable convergence. In other words  the unstable Ornstein-Uhlenbeck process within
the ﬁrst phase itself is powerful enough to escape from stationary points with negative curvatures.
This phenomenon is not captured by the previous upper bound-based analysis  since previous upper
bounds are relatively coarse-grained compared with the exact dynamics  which naturally give a sharp
characterization simultaneously from upper and lower bounds. Furthermore  in Section 5 we will
show that our sharp diffusion process-based characterization provides understanding on different
phases of dynamics of our online/SGD algorithm for ICA.
A recent work [29] analyzes an online principal component analysis algorithm based on the intuition
gained from diffusion approximation. In this paper  we consider a different statistical problem with a
rigorous characterization of the diffusion approximations in three separate phases.
Our contribution. In summary  we propose a new analytic paradigm based on diffusion processes
for characterizing the global dynamics of nonconvex statistical optimization. For SGD on ICA  we
identify the aforementioned three phases for the ﬁrst time. Our analysis is based on Stroock and
Varadhan’s weak convergence of Markov chains to diffusion processes  which are of independent
interest.

2

2 Background
In this section we formally introduce a special model of independent component analysis (ICA) and
the associated SGD algorithm. Let {X (i)}n
i=1 be the data sample identically distributed as X 2 Rd.
We make assumptions for the distribution of X as follows. Let k·k be the `2-norm of a vector.
Assumption 1. There is an orthonormal matrix A 2 Rd⇥d such that X = AY   where Y 2 Rd is a
random vector that has independent entries satisfying the following conditions:

(i) The distribution of each Yi is symmetric about 0;
(ii) There is a constant B such that kY k2  B;
(iii) The Y1  . . .   Yd are independent with identical m moments for m  8  denoted by m ⌘ EY m
1 ;
(iv) The 1 = EYi = 0  2 = EY 2
Assumption 1(iii) above is a generalization of i.i.d. tensor components. Let A = (a1  . . .   ad) whose
columns form an orthonormal basis. Our goal is to estimate the orthonormal basis ai from online
data X1  . . .   Xn. We ﬁrst establish a preliminary lemma.
Lemma 1. Let T = E(X⌦4) be the 4th-order tensor whose (i  j  k  l)-entry is E (XiXjXkXl).
Under Assumption 1  we have

i = 1  ⌘ 4 6= 3.

T(u  u  u  u) ⌘ Eu>X4

dXi=1

= 3 + (  3)

(a>i u)4.

(2.1)

Lemma 1 implies that ﬁnding ai’s can be cast into the solution to the following population optimiza-
tion problem

argmin  sign(  3) · Eu>X4

dXi=1

= argmin

(a>i u)4

subject to kuk = 1.

(2.2)

(2.3)

It is straightforward to conclude that all stable equilibria of (2.2) are ±ai whose number linearly
grows with d. Meanwhile  by analyzing the Hessian matrices the set of unstable equilibria of (2.2)
includes (but not limited to) all v⇤ = d1/2(±1 ···  ±1)  whose number grows exponentially as d
increases [18  44].
Now we introduce the SGD algorithm for solving (2.2) with ﬁnite samples. Let S d1 = {u : kuk =
1} be the unit sphere in Rd  and denote ⇧u = u/kuk for u 6= 0 the projection operator onto S d1.
With appropriate initialization  the SGD for tensor method iteratively updates the estimator via the
following Eq. (2.3):

u(n) =⇧ ⇢u(n1) + sign(  3) · ⇣u(n1) >X (n)⌘3

X (n) .

The SGD algorithms that performs stochastic approximation using single online data sample in
each update has the advantage of less temporal and spatial complexity  especially when d is high
[18  29]. An essential issue of this nonconvex optimization problem is how the algorithm escape from
unstable equilibria. [18] provides a method of adding artiﬁcial noises to the samples  where the noise
variables are uniformly sampled from S d1. In our work  we demonstrate that under some reasonable
distributional assumptions  the online data provide sufﬁcient noise for the algorithm to escape from
the unstable equilibria.
By symmetry  our algorithm in Eq. (2.3) converges to a uniformly random tensor component from d
components. In order to solve the problem completely  one can repeatedly run the algorithm using
different set of online samples until all tensor components are found. In the case where d is high  the
well-known coupon collector problem [16] implies that it takes ⇡ d log d runs of SGD algorithm to
obtain all d tensor components.
Remark. From Eq. (2.2) we see the tensor structure in Eq. (2.1) is unidentiﬁable in the case of
 = 3  see more discussion in [4  18]. Therefore in Assumption 1 we rule out the value = 3
and call the value |  3| the tensor gap. The reader will see later that  analogous to eigengap in
SGD algorithm for principal component analysis (PCA) [29]  tensor gap plays a vital role in the time
complexity in the algorithm analysis.
3 Markov Processes and Differential Equation Approximation
To work on the approximation we ﬁrst conclude the following proposition.

3

Proposition 1. The iteration u(n)  n = 0  1  . . . generated by Eq. (2.3) forms a discrete-time  time-
homogeneous Markov process that takes values on S d1. Furthermore  u(n) holds strong Markov
property.
For convenience of analysis we use the transformed iteration v(n) ⌘ A>u(n) in the rest of this paper.
The update equation in Eq. (2.3) is equivalently written as

v(n) = A>u(n) =⇧ ⇢A>u(n1) ± ⇣u(n1) >AA>X (n)⌘3
Y (n) .

=⇧ ⇢v(n1) ± ⇣v(n1) >Y (n)⌘3

A>X (n)

(3.1)

Here ± has the same sign with  3. It is obvious from Proposition 1 that the (strong) Markov prop-
erty applies to v(n)  and one can analyze the iterates v(n) generated by Eq. (3.1) from a perspective
of Markov processes.
Our next step is to conclude that as the stepsize  ! 0+  the iterates generated by Eq. (2.3)  under
the time scaling that speeds up the algorithm by a factor 1  can be globally approximated by the
solution to the following ODE system. To characterize such approximation we use theory of weak
convergence to diffusions [17  40] via computing the inﬁnitesimal mean and variance for SGD for the
tensor method. We remind the readers of the deﬁnition of weak convergence Z ) Z in stochastic
processes: for any 0  t1 < t2 < ··· < tn the following convergence in distribution occurs as
 ! 0+

Z(t1)  Z(t2)  . . .   Z(tn) d! (Z(t1)  Z(t2)  . . .   Z(tn)) .

To highlight the dependence on  we add it in the superscipts of iterates v (n) = v(n). Recall that
bt1c is the integer part of the real number t1.
Theorem 1. If for each k = 1  . . .   d  as  ! 0+ v (0)
k then the Markov process v (bt1c)
V o
i !  
dXi=1

= |  3| Vk V 2

converges weakly to the solution of the ODE system

converges weakly to some constant scalar

with initial values Vk(0) = V o
k .
To understand the complex ODE system in Eq. (3.2) we ﬁrst investigate into the case of d = 2.
Consider a change of variable V 2
1 the
following derivation:
dV1
dt

1 (t) we have by chain rule in calculus and V 2

2 = 1  V 2

k = 1  . . .   d 

dV 2
1
dt

dVk
dt

k 

(3.2)

V 4

k

k

2
1  V 4

1  V 4
1 )2 = 2|  3| V 2

= 2V1 · |  3| V1V 2
= 2V1 ·
1 V 2
1  (1  V 2
1  V 4
= 2|  3| V 2
1 (t) = 0.5 ± 0.5(1 + C exp (|  3|t))0.5 
V 2
1 )2 < (V o

1 ✓V 2

Eq. (3.3) is an autonomous  ﬁrst-order ODE for V 2
solution is available:

1 )2  . . .   (V o

2 (t) = 1  V 2

1 (t)  where the choices of ± and C depend on the initial value. The above
and V 2
2 )2) 
solution allows us to conclude that if the initial vector (V o
2 )2 (resp. (V o
then it approaches to 1 (resp. 0) as t ! 1. This intuition can be generalized to the case of higher
d that the ODE system in Eq. (3.2) converges to the coordinate direction ±ek if (V o
k )2 is strictly
maximal among (V o
d )2 in the initial vector. To estimate the time of traverse we establish
the following Proposition 2.
Proposition 2. Fix  2 (0  1/2) and the initial value Vk(0) = V o
k )2 for
all 1  k  d  k 6= k0  then there is a constant (called traverse time) T that depends only on d  
such that V 2
k0(T )  1  . Furthermore T has the following upper bound: let y(t) solution to the
following auxillary ODE
(3.4)

k that satisﬁes (V o

k0)2  2(V o

1 )2 > (V o

dy
dt

= y2 (1  y)  

1

2◆ (V 2

1  1).

1 

(3.3)

1 . Although this equation is complex  a closed-form

with y(0) = 2/(d + 1). Let T0 be the time that y(T0) = 1  . Then

T |  3|1T0 |  3|1d  3 + 4 log(2)1 .

4

(3.5)

Proposition 2 concludes that  by admitting a gap of 2 between the largest (V o
k0)2 and second largest
k )2  k 6= k0 the estimate on traverse time can be given  which is tight enough for our purposes in
(V o
Section 5.
Remark. In an earlier paper [29] which focuses on the SGD algorithm for PCA  when the stepsize is
small  the algorithm iteration is approximated by the solution to ODE system after appropriate time
rescaling. The approximate ODE system for SGD for PCA is

dVk
dt

= 2Vk

dXi=1

(k  i)V 2
i  

k = 1  . . .   d.

(3.6)

The analysis there also involves computation of inﬁnitesimal mean and variance for each coordinate
as the stepsize  ! 0+ and theory of convergence to diffusions [17  40]. A closed-form solution to
Eq. (3.6) is obtained in [29]  called the generalized logistic curves. In contrast  to our best knowledge
a closed-form solution to Eq. (3.2) is generally not available.
4 Local Approximation via Stochastic Differential Equation
The ODE approximation in Section 3 is very informative: it characterizes globally the trajectory of
our algorithm for ICA or tensor method in Eq. (2.3) with O(1) approximation errors. However it
fails to characterize the behavior near equilibria where the gradients in our ODE system are close to
zero. For instance  if the SGD algorithm starts from v⇤  on a microscopic magnitude of O(1/2) the
noises generated by online samples help escaping from a neighborhood of v⇤.
Our main goal in this section is to demonstrate that under appropriate spatial and temporal scalings 
the algorithm iteration converges locally to the solution to certain stochastic differential equations
(SDE). We provide the SDE approximations in two scenarios  separately near an arbitrary tensor
component (Subsection 4.1) which indicates that our SGD for tensor method converges to a local
minimum at a desirable rate  and a special local maximum (Subsection 4.2) which implies that the
stochastic nature of our SGD algorithm for tensor method helps escaping from unstable equilibria.
Note that in the algorithm iterates  the escaping from stationary points occurs ﬁrst  followed by the
ODE and then by the phase of convergence to local minimum. We discuss this further in Section 5.
4.1 Neighborhood of Local Minimizers
To analyze the behavior of SGD for tensor method we ﬁrst consider the case where the iterates enter
a neighborhood of one local minimizer  i.e. the tensor component. Since the tensor decomposition
in Eq. (2.2) is full-rank and symmetric  we consider without loss of generality the neighborhood
near e1 the ﬁrst tensor component. The following Theorem 2 indicates that under appropriate spatial
and temporal scalings  the process admits an approximation by Ornstein-Uhlenbeck process. Such
approximation is characterized rigorously using weak convergence theory of Markov processes
[17  40]. The readers are referred to [37] for fundamental topics on SDE.
Theorem 2. If for each k = 2  . . .   d  1/2v (0)
then the stochastic process 1/2v (bt1c)
differential equation

k 2 (0 1) as  ! 0+
k
converges weakly to the solution of the stochastic

converges weakly to U o

k

with initial values Uk(0) = U o
We identify the solution to Eq. (4.1) as an Ornstein-Uhlenbeck process which can be expressed in
terms of a Itô integral  with

dUk(t) = |  3| Uk(t)dt + 1/2
k . Here Bk(t) is a standard one-dimensional Brownian motion.

6 dBk(t) 

(4.1)

Itô isometry along with mean-zero property of Itô integral gives

Uk(t) = U o

E(Uk(t))2 = (U o

6 Z t
k exp (|  3|t) + 1/2
k )2 exp (2|  3|t) + 6Z t

0

0

=

 6

2|  3|

+✓(U o
k )2 

 6

2|  3|◆ exp (2|  3|t)  

exp (2|  3|(t  s)) ds

exp (|  3|(t  s)) dBk(s).

(4.2)

which  by taking the limit t ! 1  approaches 6/(2|  3|). From the above analysis we con-
clude that the Ornstein-Uhlenbeck process has the mean-reverting property that its mean decays
exponentially towards 0 with persistent ﬂuctuations at equilibrium.

5

4.2 Escape from Unstable Equilibria
In this subsection we consider SGD for tensor method that starts from a sufﬁciently small neighbor-
hood of a special unstable equilibrium. We show that after appropriate rescalings of both time and
space  the SGD for tensor iteration can be approximated by the solution to a second SDE. Analyzing
the approximate SDE suggests that our SGD algorithm iterations can get rid of the unstable equilibria
(including local maxima and stationary points with negative curvatures) whereas the traditional
gradient descent (GD) method gets stuck. In other words  under weak distributional assumptions the
stochastic gradient plays a vital role that helps the escape. As a illustrative example  we consider the
special stationary points v⇤ = d1/2(±1  . . .  ±1). Consider a submanifold SF ✓S d1 where
i .

SF =v 2S d1 : there exists 1  k < k0  d such that v2
In words  SF consists of all v 2S d1 where the maximum of v2
k is not unique. In the case of d = 3 
it is illustrated by Figure 1 that SF is the frame of a 3-dimenisional box  and hence we call SF the
frame. Let
kk0(t) = 1/2 logv (bt1c)
(4.3)
The reason we study W 
kk0(t) is that these d(d  1) functions of v 2S d1 form a local coordinate
map around v⇤ and further characterize the distance between v and SF on a spatial scale of 1/2. We
deﬁne the positive constant ⇤d  as
d  = 8d2 8 + (16d  28) 6 + 15d 2

2  1/2 logv (bt1c)

5(72d2  228d + 175) 4 + 15(2d  7)(d  2)(d  3) .

We have our second SDE approximation result as follows.
Theorem 3. Let W 
k  k0 = 1  . . .   d  W 
process W 

kk0(t) be deﬁned as in Eq. (4.3)  and let ⇤d  be as in Eq. (4.4). If for each distinct
kk0(0) converges weakly to W o
kk0 2 (0 1) as  ! 0+ then the stochastic

kk0(t) converges weakly to the solution of the stochastic differential equation

k0 = max1id v2

2 

k = v2

(4.4)

W 

⇤2

k0

k

4

dWkk0(t) =

2|  3|

with initial values Wkk0(0) = W o
We can solve Eq. (4.5) and obtain an unstable Ornstein-Uhlenbeck process as

(4.5)
kk0. Here Bkk0(t) is a standard one-dimensional Brownian motion.

Wkk0(t)dt +⇤ d  dBkk0(t)

d

2|  3|

d

s◆ dBkk0(s)◆ exp✓ 2|  3|

d

Wkk0(t) =✓W o

Let Ckk0 be deﬁned as

0

kk0 +⇤ d  Z t
Ckk0 ⌘ W o

exp✓
kk0 +⇤ d  Z 1

0

We conclude that the following holds.

(i) Ckk0 is a normal variable with mean W o
(ii) When t is large Wkk0(t) has the following approximation

t◆ .

(4.6)

(4.7)

(4.8)

d

4|  3|

exp✓

kk0 and variance d⇤2

s◆ dBkk0(s).
d  / (4|  3|);
t◆ .
s◆ dBkk0(s)◆ = 0 
exp✓
s◆ ds =

Wkk0(t) ⇡ Ckk0 exp✓ 2|  3|
exp✓
s◆ dBkk0(s)◆2
exp✓
d  Z 1
⇡ ⇤2

d  Z t

4|  3|

=⇤ 2

d

d

d

0

0

s◆ ds

4|  3|

d
d⇤2
4|  3|

d  

.

To verify (i) above we have the Itô integral in Eq. (4.6)
2|  3|

0

E✓⇤d  Z 1
exp✓

d

2|  3|

and by using Itô isometry

E✓⇤d  Z 1

0

The analysis above on the unstable Ornstein-Uhlenbeck process indicates that the process has the
momentum nature that when t is large  it can be regarded as at a normally distributed location
centered at 0 and grows exponentially. In Section 5 we will see how the result in Theorem 3 provides
explanation on the escape from unstable equilibria.

6

d  

d⇤2

k
v(n)

= 1/2W 

kk0 = 0 for all

log v(n)
k0 !2

1 )
Eq. (5.1) we know k1k2 is positive. By setting

5 Phase Analysis
In this section  we utilize the weak convergence results in Sections 3 and 4 to understand the dynamics
of online ICA in different phases. For purposes of illustration and brevity  we restrict ourselves to the
case of starting point v⇤  a local maxima that has negative curvatures in every direction. In below we
denote by Z ⇣ W  as  ! 0+ when the limit of ratio Z/W  ! 1.
Phase I (Escape from unstable equilibria). Assume we start from v⇤  then W o
k 6= k0. We have from Eqs. (4.6) and (4.7) that
kk0(n) ⇡ 
4|  3|!1/2
kk0 exp✓ 2|  3|
Suppose k1 is the index that maximizes⇣v(N 
⌘2
and k2 maximizes⇣v(N 
⌘2
k2 ⌘2
log⇣v(N 
k1 ⌘2
 log⇣v(N 
log 21A ⇣
2 |  3|1 d1 log0@ 
4|  3|!1/2
= 2⇣v(0)
k2⌘2

we have from the construction in the proof of Theorem 3 that as  ! 0+
1
N 
1 =

Phase II (Deterministic traverse). By (strong) Markov property we can restart the counter of
iteration  we have the max and second max

4 |  3|1 d1 log1 .

· n◆ .
  k 6= k1. Then by

Proposition 2 implies that it takes time

⇣v(0)
k1⌘2

= log 2 

1
k1k2

(5.1)

d⇤2

d  

d

1 )

k

1 )

1 )

1

k

 

k for k > 1. Converting to the timescale of the

for the ODE to traverse from V 2
SGD  the second phase has the following relations as  ! 0+

T |  3|1d  3 + 4 log(2)1  

1 = 2/(d + 1) = 2V 2

Phase III (Convergence to stable equilibria). Again restart our counter. We have from the ap-
proximation in Theorem 3 and Eq. (4.2) that

N 

2 ⇣ T 1 |  3|1d  3 + 4 log(2)1 1.
k )2 exp (2|  3|n) +  6Z n

0

exp (2|  3|(t  s)) ds

E(v(n)

k )2 = (v(0)

=

 6

 6
2|  3|

+✓(v(0)
k )2 

2|  3|◆ exp (2|  3|n) .
In terms of the iterations v(n)  note the relationship E sin2 \(v  e1) =Pd
+✓ 

of ODE phase implies that E sin2 \(v(0)  e1) =   and hence

E sin2 \(v(n)  e1) =

(d  1) 6
2|  3|

2|  3| ◆ exp (2|  3|n) .

(d  1) 6

k = 1  v2

k=2 v2

By setting

1. The end

E sin2 \(v(N 

3 )  e1) = (C0 + 1) ·

(d  1) 6
2|  3|

 

we conclude that as  ! 0+

N 

3 =

1

2|  3|

log✓1 ·

2|  3|  (d  1) 6

C0(d  1) 6

◆ ⇣

1

2|  3|11 log1 .

6 Summary and discussions
In this paper  we take online ICA as a ﬁrst step towards understanding the global dynamics of stochastic
gradient descent. For general nonconvex optimization problems such as training deep networks  phase-
retrieval  dictionary learning and PCA  we expect similar multiple-phase phenomenon. It is believed

7

that the ﬂavor of asymptotic analysis above can help identify a class of stochastic algorithms for
nonconvex optimization with statistical structure.
Our continuous-time analysis also reﬂects the dynamics of the algorithm in discrete time. This is
substantiated by Theorems 1  2 and 3 which rigorously characterize the convergence of iterates to
ODE or SDE by shifting to different temporal and spatial scales. In detail  our results imply when
 ! 0+:

Phase I takes iteration number N 
Phase II takes iteration number N 
Phase III takes iteration number N 

1 ⇣ (1/4)|  3|1d · 1 log(1);
2 ⇣|  3|1d · 1;
3 ⇣ (1/2)|  3|1 · 1 log(1).

After the three phases  the iteration reaches a point that is C · 6|  3|1 · d1/2 distant on
average to one local minimizer. As  ! 0+ we have N 
1 ! 0. This implies that the algorithm
demonstrates the cutoff phenomenon which frequently occur in discrete-time Markov processes [28 
Chap. 18]. In words  the Phase II where the objective value in Eq. (2.2) drops from 1  " to " is a
short-time phase compared to Phases I and III  so the convergence curve illustrated in the right ﬁgure
in Figure 1 instead of an exponentially decaying curve. As  ! 0+ we have N 
3 ⇣ d/2  which
suggests that Phase I of escaping from unstable equlibria dominates Phase III by a factor of d/2.
References
[1] Agarwal  A.  Anandkumar  A.  Jain  P. and Netrapalli  P. (2013). Learning sparsely used overcomplete

2 /N 

1 /N 

dictionaries via alternating minimization. arXiv preprint arXiv:1310.7991.

[2] Aldous  D. (1989). Probability approximations via the Poisson clumping heuristic. Applied Mathematical

Sciences  77.

[3] Anandkumar  A. and Ge  R. (2016). Efﬁcient approaches for escaping higher order saddle points in

non-convex optimization. arXiv preprint arXiv:1602.05908.

[4] Anandkumar  A.  Ge  R.  Hsu  D.  Kakade  S. M. and Telgarsky  M. (2014). Tensor decompositions for

learning latent variable models. Journal of Machine Learning Research  15 2773–2832.

[5] Anandkumar  A.  Ge  R. and Janzamin  M. (2014). Analyzing tensor power method dynamics in overcom-

[6] Arora  S.  Ge  R.  Ma  T. and Moitra  A. (2015). Simple  efﬁcient  and neural algorithms for sparse coding.

plete regime. arXiv preprint arXiv:1411.1488.

arXiv preprint arXiv:1503.00778.

[7] Balakrishnan  S.  Wainwright  M. J. and Yu  B. (2014). Statistical guarantees for the EM algorithm: From

population to sample-based analysis. arXiv preprint arXiv:1408.2156.

[8] Bhojanapalli  S.  Kyrillidis  A. and Sanghavi  S. (2015). Dropping convexity for faster semi-deﬁnite opti-

mization. arXiv preprint arXiv:1509.03917.

[9] Bronshtein  I. N. and Semendyayev  K. A. (1998). Handbook of mathematics. Springer.
[10] Cai  T. T.  Li  X. and Ma  Z. (2015). Optimal rates of convergence for noisy sparse phase retrieval via

thresholded Wirtinger ﬂow. arXiv preprint arXiv:1506.03382.

[11] Candès  E.  Li  X. and Soltanolkotabi  M. (2014). Phase retrieval via Wirtinger ﬂow: Theory and algorithms.

arXiv preprint arXiv:1407.1065.

[12] Chen  Y. and Candès  E. (2015). Solving random quadratic systems of equations is nearly as easy as

solving linear systems. In Advances in Neural Information Processing Systems.

[13] Chen  Y. and Wainwright  M. J. (2015). Fast low-rank estimation by projected gradient descent: General

statistical and algorithmic guarantees. arXiv preprint arXiv:1509.03025.

[14] Darken  C. and Moody  J. (1991). Towards faster stochastic gradient search.

In Advances in Neural

Information Processing Systems.

[15] De Sa  C.  Olukotun  K. and Ré  C. (2014). Global convergence of stochastic gradient descent for some

non-convex matrix problems. arXiv preprint arXiv:1411.1134.

[16] Durrett  R. (2010). Probability: Theory and examples. Cambridge University Press.
[17] Ethier  S. N. and Kurtz  T. G. (1985). Markov processes: Characterization and convergence  vol. 282.

[18] Ge  R.  Huang  F.  Jin  C. and Yuan  Y. (2015). Escaping from saddle points — online stochastic gradient

for tensor decomposition. arXiv preprint arXiv:1503.02101.

[19] Golub  G. H. and Van Loan  C. F. (2012). Matrix computations. JHU Press.
[20] Gu  Q.  Wang  Z. and Liu  H. (2014). Sparse PCA with oracle property. In Advances in neural information

[21] Gu  Q.  Wang  Z. and Liu  H. (2016). Low-rank and sparse structure pursuit via alternating minimization.

In International Conference on Artiﬁcial Intelligence and Statistics.

[22] Hardt  M. (2014). Understanding alternating minimization for matrix completion. In Foundations of

[23] Hirsch  M. W.  Smale  S. and Devaney  R. L. (2012). Differential equations  dynamical systems  and an

introduction to chaos. Academic Press.

John Wiley & Sons.

processing systems.

Computer Science.

8

[24] Jain  P.  Jin  C.  Kakade  S. M. and Netrapalli  P. (2015). Computing matrix squareroot via non convex

local search. arXiv preprint arXiv:1507.05854.

[25] Jain  P. and Netrapalli  P. (2014). Fast exact matrix completion with ﬁnite samples. arXiv preprint

[26] Jain  P.  Netrapalli  P. and Sanghavi  S. (2013). Low-rank matrix completion using alternating minimization.

[27] Lee  J. D.  Simchowitz  M.  Jordan  M. I. and Recht  B. (2016). Gradient descent converges to minimizers.

arXiv:1411.1087.

In Symposium on Theory of Computing.

arXiv preprint arXiv:1602.04915.

Society.

[28] Levin  D. A.  Peres  Y. and Wilmer  E. L. (2009). Markov chains and mixing times. American Mathematical

[29] Li  C. J.  Wang  M.  Liu  H. and Zhang  T. (2016). Near-optimal stochastic approximation for online

principal component estimation. arXiv preprint arXiv:1603.05305.

[30] Li  Q.  Tai  C. et al. (2015). Dynamics of stochastic gradient algorithms. arXiv preprint arXiv:1511.06251.
[31] Loh  P.-L. and Wainwright  M. J. (2015). Regularized M-estimators with nonconvexity: Statistical and

algorithmic theory for local optima. Journal of Machine Learning Research  16 559–616.

[32] Mandt  S.  Hoffman  M. D. and Blei  D. M. (2016). A variational analysis of stochastic gradient algorithms.

arXiv preprint arXiv:1602.02666.

[33] Mobahi  H. (2016). Training recurrent neural networks by diffusion. arXiv preprint arXiv:1601.04114.
[34] Nesterov  Y. (2004). Introductory lectures on convex optimization: A basic course  vol. 87. Springer.
[35] Netrapalli  P.  Jain  P. and Sanghavi  S. (2013). Phase retrieval using alternating minimization. In Advances

in Neural Information Processing Systems.

[36] Netrapalli  P.  Niranjan  U.  Sanghavi  S.  Anandkumar  A. and Jain  P. (2014). Non-convex robust pca. In

Advances in Neural Information Processing Systems.

[37] Oksendal  B. (2003). Stochastic differential equations. Springer.
[38] Panageas  I. and Piliouras  G. (2016). Gradient descent converges to minimizers: The case of non-isolated

critical points. arXiv preprint arXiv:1605.00405.

[39] Qu  Q.  Sun  J. and Wright  J. (2014). Finding a sparse vector in a subspace: Linear sparsity using alternat-

ing directions. In Advances in Neural Information Processing Systems.

[40] Stroock  D. W. and Varadhan  S. S. (1979). Multidimensional diffusion processes  vol. 233. Springer.
[41] Su  W.  Boyd  S. and Candès  E. (2014). A differential equation for modeling Nesterov’s accelerated

gradient method: Theory and insights. In Advances in Neural Information Processing Systems.

[42] Sun  J.  Qu  Q. and Wright  J. (2015). Complete dictionary recovery over the sphere i: Overview and the

geometric picture. arXiv preprint arXiv:1511.03607.

[43] Sun  J.  Qu  Q. and Wright  J. (2015). Complete dictionary recovery over the sphere ii: Recovery by

Riemannian trust-region method. arXiv preprint arXiv:1511.04777.

[44] Sun  J.  Qu  Q. and Wright  J. (2015). When are nonconvex problems not scary?

arXiv preprint

arXiv preprint

arXiv:1510.06096.

arXiv:1602.06664.

of Computer Science.

arXiv:1502.01425.

[45] Sun  J.  Qu  Q. and Wright  J. (2016). A geometric analysis of phase retrieval.

[46] Sun  R. and Luo  Z.-Q. (2015). Guaranteed matrix completion via nonconvex factorization. In Foundations

[47] Sun  W.  Lu  J.  Liu  H. and Cheng  G. (2015). Provable sparse tensor decomposition. arXiv preprint

[48] Sun  W.  Wang  Z.  Liu  H. and Cheng  G. (2015). Non-convex statistical optimization for sparse tensor

graphical model. In Advances in Neural Information Processing Systems 28.

[49] Tan  K. M.  Wang  Z.  Liu  H. and Zhang  T. (2016). Sparse generalized eigenvalue problem: Optimal

statistical rates via truncated rayleigh ﬂow. arXiv preprint arXiv:1604.08697.

[50] Tu  S.  Boczar  R.  Soltanolkotabi  M. and Recht  B. (2015). Low-rank solutions of linear matrix equations

via procrustes ﬂow. arXiv preprint arXiv:1507.03566.

[51] Wang  Z.  Gu  Q.  Ning  Y. and Liu  H. (2015). High dimensional EM algorithm: Statistical optimization

and asymptotic normality. In Advances in Neural Information Processing Systems.

[52] Wang  Z.  Liu  H. and Zhang  T. (2014). Optimal computational and statistical rates of convergence for

sparse nonconvex learning problems. Annals of statistics  42 2164.

[53] Wang  Z.  Lu  H. and Liu  H. (2014). Nonconvex statistical optimization: Minimax-optimal sparse PCA in

[54] White  C. D.  Sanghavi  S. and Ward  R. (2015). The local convexity of solving systems of quadratic

polynomial time. arXiv preprint arXiv:1408.5352.

equations. arXiv preprint arXiv:1506.07868.

[55] Yang  Z.  Wang  Z.  Liu  H.  Eldar  Y. C. and Zhang  T. (2015). Sparse nonlinear regression: Parameter

estimation and asymptotic inference under nonconvexity. arXiv preprint arXiv:1511.04514.

[56] Zhang  Y.  Chen  X.  Zhou  D. and Jordan  M. I. (2014). Spectral methods meet em: A provably optimal

algorithm for crowdsourcing. In Advances in neural information processing systems.

[57] Zhao  T.  Wang  Z. and Liu  H. (2015). A nonconvex optimization framework for low rank matrix estima-

tion. In Advances in Neural Information Processing Systems.

[58] Zheng  Q. and Lafferty  J. (2015). A convergent gradient descent algorithm for rank minimization and

semideﬁnite programming from random linear measurements. arXiv preprint arXiv:1506.06081.

9

,Chris Junchi Li
Zhaoran Wang
Han Liu
Yuanyuan Liu
Fanhua Shang
James Cheng
Hong Cheng
Licheng Jiao