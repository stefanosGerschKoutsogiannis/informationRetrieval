2014,Object Localization based on Structural SVM using Privileged Information,We propose a structured prediction algorithm for object localization based on Support Vector Machines (SVMs) using privileged information. Privileged information provides useful high-level knowledge for image understanding and facilitates learning a reliable model even with a small number of training examples. In our setting  we assume that such information is available only at training time since it may be difficult to obtain from visual data accurately without human supervision. Our goal is to improve performance by incorporating privileged information into ordinary learning framework and adjusting model parameters for better generalization. We tackle object localization problem based on a novel structural SVM using privileged information  where an alternating loss-augmented inference procedure is employed to handle the term in the objective function corresponding to privileged information. We apply the proposed algorithm to the Caltech-UCSD Birds 200-2011 dataset  and obtain encouraging results suggesting further investigation into the benefit of privileged information in structured prediction.,Object Localization based on Structural SVM

using Privileged Information

Jan Feyereisl  Suha Kwak‚àó  Jeany Son  Bohyung Han

Dept. of Computer Science and Engineering  POSTECH  Pohang  Korea

thefillm@gmail.com  {mercury3 jeany bhhan}@postech.ac.kr

Abstract

We propose a structured prediction algorithm for object localization based on Sup-
port Vector Machines (SVMs) using privileged information. Privileged informa-
tion provides useful high-level knowledge for image understanding and facilitates
learning a reliable model even with a small number of training examples. In our
setting  we assume that such information is available only at training time since it
may be difÔ¨Åcult to obtain from visual data accurately without human supervision.
Our goal is to improve performance by incorporating privileged information into
ordinary learning framework and adjusting model parameters for better general-
ization. We tackle object localization problem based on a novel structural SVM
using privileged information  where an alternating loss-augmented inference pro-
cedure is employed to handle the term in the objective function corresponding to
privileged information. We apply the proposed algorithm to the Caltech-UCSD
Birds 200-2011 dataset  and obtain encouraging results suggesting further inves-
tigation into the beneÔ¨Åt of privileged information in structured prediction.

1

Introduction

Object localization is often formulated as a binary classiÔ¨Åcation problem  where a learned classiÔ¨Åer
determines the existence or absence of a target object within a candidate window of every location 
size  and aspect ratio. Recently  a structured prediction technique using Support Vector Machine
(SVM) has been applied to this problem [1]  where the optimal bounding box containing target ob-
ject is obtained by a trained classiÔ¨Åer. This approach provides a uniÔ¨Åed framework for detection and
post-processing (non-maximum suppression)  and handles issues related to the object with variable
aspect ratios naturally. However  object localization is an inherently difÔ¨Åcult task due to the large
amount of variations in objects and scenes  e.g.  shape deformations  color variations  pose changes 
occlusion  view point changes  background clutter  etc. This issue is aggravated when the size of
training dataset is small.
More reliable model can be learned even with fewer training examples if additional high-level
knowledge about an object of interest is available during training. Such high-level knowledge is
called privileged information  which typically describes useful semantic properties of an object such
as parts  attributes  and segmentations. This idea corresponds to the Learning Using Privileged In-
formation (LUPI) paradigm [3]  which exploits the additional information to improve predictive
models in training but does not require the information for prediction. The LUPI framework has
been incorporated into SVM in the form of the SVM+ algorithm [4]. However  the applications of
SVM+ are often limited to binary classiÔ¨Åcation problems [3  4].
We propose a novel Structural SVM using privileged information (SSVM+) framework  shown in
Figure 1  and apply the algorithm to the problem of object localization. In this formulation  priv-
ileged information  e.g.  parts  attributes and segmentations  are incorporated to learn a structured

‚àóCurrent afÔ¨Åliation: INRIA‚ÄìWILLOW Project  Paris  France; e-mail: suha.kwak@inria.fr

1

Figure 1: Overview of our object localization framework using privileged information. Unlike
visual observations  privileged information is available only during training. We use attributes and
segmentation masks of an object as privileged information to improve generalization of trained
model. To incorporate privileged information during training  we propose an extension of SSVM 
called SSVM+  whose loss-augmented inference is performed by alternating EfÔ¨Åcient Subwindow
Search (ESS) [2].

prediction function for object localization. Note that high-level information is available only for
training but not testing in this framework. Our algorithm employs an efÔ¨Åcient branch-and-bound
loss-augmented subwindow search procedure to perform the inference by a joint optimization in
original and privileged spaces during training. Since the additional information is not used in test-
ing  the inference in testing phase is the same as the standard Structural SVM (SSVM) case. We
evaluate our method by learning to localize birds in the Caltech-UCSD Birds 200-2011 (CUB-2011)
dataset [5] and exploiting attributes and segmentation masks as privileged information in addition to
standard visual features. The main contributions of our work are as follows:

‚Ä¢ We introduce a novel framework for object localization exploiting privileged information

that is not required or needed to be inferred at test time.

‚Ä¢ We formulate an SSVM+ framework  where an alternating loss-augmented inference pro-
cedure for efÔ¨Åcient subwindow search is incorporated to handle the privileged information
together with the conventional visual features.

‚Ä¢ Performance gains in localization and classiÔ¨Åcation are achieved  especially with small

training datasets.

Methods that exploit additional information have been discussed to improve models for image clas-
siÔ¨Åcation or search in the context of transfer learning [6  7]  learning with side information [8  9  10]
and domain adaptation [11]  where underlying techniques rely on pair-wise constraints [8]  multiple
kernels [9] or metric learning [9]. Zero-shot learning is an extreme framework  where the models
for unseen classes are constructed even without training data [12  13]. Recent works often rely on
natural language processing techniques to handle pure textual description [14  15].
Standard learning algorithms require many data to construct a robust model while zero-shot learning
does not need any training examples. LUPI framework is in the middle of traditional data-driven
learning and zero-shot learning since it aims to learn a good model with a small number of training
data by taking advantage of privileged information available at training time. Privileged information
has been considered in face recognition [16]  facial feature detection [17]  and event recognition
[18]  but such works are still uncommon. Our work applies the LUPI framework to an object local-
ization problem based on SSVM. The use of SSVMs for object localization is originally investigated
by [1]. More recently  [19  20] employ SSVM as part of their localization procedure  however none
of them incorporate privileged information or similar idea. Recently  [21] presented the potential
beneÔ¨Åt of SVM+ in object recognition task.
The rest of this paper is organized as follows. We Ô¨Årst review the LUPI framework and SSVM
in Section 2  and our SSVM+ formulation for object localization is presented in Section 3. The
performance of our object localization algorithm is evaluated in Section 4.

2

Groundtruth (yi) xi* : Segmentation/Part/Attributes xi : Image SSVM+ Learning Model Prediction Output (y) x : Image Training example Testing example argmaxùë¶‚àó ‚àÜ (ùë¶ùëñ ùë¶ùëê ùë¶‚àó)+ùë§‚àó Œ®‚àóùë¶‚àó argmaxùë¶ ‚àÜ (ùë¶ùëñ ùë¶ ùë¶ùëê‚àó)+ùë§ Œ®ùë¶ Privileged space Visual space y* ùë¶ùëê‚àó ùë¶ùëê Loss-Augmented Inference by ESS Localization Alternating optimization ‚Ä¶ ‚Ä¶ ‚Ä¶ ‚Ä¶ ‚Ä¶ ‚Ä¶ ‚Ä¶ Keypoints Visual descriptors (SURF) Vocabulary ‚Ä¶ Histogram Bag-of-Words Features y 2 Background

2.1 Learning Using Privileged Information

1  y1)  . . .   (xn  x‚àó

The LUPI paradigm [3  4  22  23] is a framework for incorporating additional information during
training that is not available at test time. The inclusion of such information is exploited to Ô¨Ånd
a better model  which yields lower generalization error. Contrary to classical supervised learn-
ing  where pairs of data are provided (x1  y1)  . . .   (xn  yn)  xi ‚àà X   yi ‚àà {‚àí1  1}  in the LUPI
paradigm additional information x‚àó ‚àà X ‚àó is provided with each training example as well  i.e. 
i ‚àà X ‚àó  yi ‚àà {‚àí1  1}. This information is  however  not
(x1  x‚àó
required during testing. In both learning paradigms  the task is then to Ô¨Ånd among a collection of
functions the one that best approximates the underlying decision function from the given data.
SpeciÔ¨Åcally  we formulate object localization within a LUPI framework as learning a pair of func-
tions h : X (cid:55)‚Üí Y and œÜ : X ‚àó (cid:55)‚Üí Y jointly  where only h is used for prediction. These functions  for
example  map the space of images and attributes to the space of bounding box coordinates Y. The
decision function h and the correcting function œÜ depend on each other by the following relation 

n  yn)  xi ‚àà X   x‚àó

‚àÄ 1 ‚â§ i ‚â§ n 

(cid:96)X (h(xi)  yi) ‚â§ (cid:96)X ‚àó (œÜ(x‚àó

i )  yi) 

(1)
where (cid:96)X and (cid:96)X ‚àó denote the empirical loss functions on the visual (X ) and the privileged space
(X ‚àó)  respectively. This inequality is inspired by the LUPI paradigm [3  4  22  23]  where for all
training examples the model h is always corrected to have a smaller loss on data than the model œÜ on
privileged information. The constraint in Eq. (1) is meaningful when we assume that  for the same
number of training examples  the combination of visual and privileged information provides a space
to learn a better model than visual information alone.
To translate this general learning idea into practice  the SVM+ algorithm for binary classiÔ¨Åcation
has been developed [3  4  22]. The SVM+ algorithm replaces the slack variable Œæ in the standard
SVM formulation by a correcting function Œæ = ((cid:104)w‚àó  x‚àó(cid:105) + b‚àó)  which estimates its values from the
privileged information. This results in the following formulation 

1
2

min

(cid:107)w(cid:107)2

(cid:107)w‚àó(cid:107)2

w w‚àó b b‚àó

Œ≥
2
(cid:123)(cid:122)
(cid:125)
i (cid:105) + b‚àó)
yi((cid:104)w  xi(cid:105) + b) ‚â•1 ‚àí ((cid:104)w‚àó  x‚àó
 

2 +

(cid:124)

2 +

Œæi

s.t.

n(cid:88)

C
n
((cid:104)w‚àó  x‚àó

i=1

(cid:124)

((cid:104)w‚àó  x‚àó

(cid:123)(cid:122)
(cid:125)
i (cid:105) + b‚àó)
(cid:123)(cid:122)
(cid:125)
i (cid:105) + b‚àó)

‚â• 0 

Œæi

(cid:124)

 

Œæi

(2)

‚àÄ 1 ‚â§ i ‚â§ n 

where the terms w‚àó  x‚àó and b‚àó play the same role as w  x and b in the classical SVM  however
within the new correcting space X ‚àó. Furthermore  Œ≥ denotes a regularization parameter for w‚àó. It is
important to observe that the weight vector w depends not only on x but also on x‚àó. For this reason
the function that replaces the slack Œæ is called the correcting function. As privileged information
is only used to estimate the values of the slacks  it is required only during training but not during
testing. Theoretical analysis [4] shows that the bound on the convergence rate of the above SVM+
algorithm could substantially improve upon standard SVM if suitable privileged information is used.

2.2 Structural SVM (SSVM)
SSVMs discriminatively learn a weight vector w for a scoring function f : X √óY (cid:55)‚Üí R over the set
of training input/output pairs. Once learned  the prediction function h is obtained by maximizing f
over all possible y ‚àà Y as follows:

ÀÜy = h(x) = arg max

(3)
where Œ® : X √ó Y ‚Üí Rd is the joint feature map that models the relationship between input x and
structured output y. To learn the weight vector w  the following optimization problem (margin-
rescaling) then needs to be solved:

f (x  y) = arg max

y‚ààY

y‚ààY

(cid:104)w  Œ®(x  y)(cid:105) 

n(cid:88)
(cid:104)w  Œ¥Œ®i(y)(cid:105) ‚â• ‚àÜ(yi  y) ‚àí Œæi

(cid:107)w(cid:107)2 +

min
w Œæ

C
n

1
2

i=1

s.t.

3

Œæi 
1 ‚â§ i ‚â§ n  ‚àÄy ‚àà Y 

(4)

where Œ¥Œ®i(y) ‚â° Œ®(xi  yi)‚àíŒ®(xi  y)  and ‚àÜ(yi  y) is a task-speciÔ¨Åc loss that measures the quality
of the prediction y with respect to the ground-truth yi. To obtain a prediction  we need to maximize
Eq. (3) over the response variable y for a given input x. SSVMs are a general method for solving a
variety of prediction tasks. For each application  the joint feature map Œ®  the loss function ‚àÜ and an
efÔ¨Åcient loss-augmented inference technique need to be customized.

3 Object Localization with Privileged Information

We deal with object localization with privileged information: given a set of training images of
objects  their locations and their attribute and segmentation information  we want to learn a function
to localize objects of interest in yet unseen images. Unlike existing methods  our learned function
does not need explicit or even inferred attribute and segmentation information during prediction.

3.1 Structural SVM with Privileged Information (SSVM+)

1  y1)  . . .   (xn  x‚àó

We extend the above structured prediction problem to exploit privileged information. Recollecting
Eq. (1)  to learn the pair of interdependent functions h and œÜ  we learn to predict a structure y based
i ‚àà X ‚àó  yi ‚àà Y  where X
on a training set of triplets  (x1  x‚àó
corresponds to various visual features  X ‚àó to attributes or segmentations  and Y is the space of all
possible bounding boxes. Once learned  only the function h is used for prediction. It is obtained by
maximizing the learned function over all possible joint features based on input x ‚àà X and output
y ‚àà Y as in Eq. (3)  identically to standard SSVMs.
On the other hand  to jointly learn h and œÜ  subject to the constraint in Eq. (1)  we need to extend the
SSVM framework substantially. The functions h and œÜ are characterized by the parameter vectors
w and w‚àó  respectively as

n  yn)  xi ‚àà X   x‚àó

h(x) = arg max

y‚ààY

(cid:104)w  Œ®(x  y)(cid:105) and œÜ(x‚àó) = arg max
y‚àó‚ààY

(cid:104)w‚àó  Œ®(x‚àó  y‚àó)(cid:105).

(5)

To learn the weight vectors w and w‚àó simultaneously  we propose a novel max-margin structured
prediction framework called SSVM+ that incorporates the constraint in Eq. (1) and hence learns two
models jointly as follows:

n(cid:88)

i=1

Œæi 

(cid:107)w(cid:107)2 +
1
2
(cid:104)w  Œ¥Œ®i(y)(cid:105)+(cid:104)w‚àó  Œ¥Œ®‚àó
i (y‚àó)(cid:105) ‚â• ¬Ø‚àÜ(yi  y  y‚àó) ‚àí Œæi ‚àÄ 1 ‚â§ i ‚â§ n  ‚àÄy  y‚àó ‚àà Y.

(cid:107)w‚àó(cid:107)2 +

min
w w‚àó Œæ

C
n

s.t.
where Œ¥Œ®‚àó
gate task-speciÔ¨Åc loss ¬Ø‚àÜ derived from [23]. This surrogate loss is deÔ¨Åned as

i (y‚àó) ‚â° Œ®‚àó(x‚àó

i   yi) ‚àí Œ®‚àó(x‚àó

i   y‚àó) and the inequality in Eq. (1) is introduced via a surro-

(6)

Œ≥
2

¬Ø‚àÜ(yi  y  y‚àó) =

1
œÅ

‚àÜ‚àó(yi  y‚àó) + [‚àÜ(yi  y) ‚àí ‚àÜ‚àó(yi  y‚àó)]+ 

(7)

where [t]+ = max(t  0) and œÅ > 0 is a penalization parameter corresponding to the constraint in
Eq. (1)  and task-speciÔ¨Åc loss functions ‚àÜ and ‚àÜ‚àó are deÔ¨Åned in Section 3.3. Through this surrogate
loss  we can apply the inequality in Eq. (1) within the ordinary max-margin optimization framework.
Our framework enforces that the model learned on attributes and segmentations (w‚àó) always corrects
the model trained on visual features (w). This results in a model with better generalization on visual
features alone. Similar to SSVMs  we can tractably deal with the exponential number of possible
constraints present in our problem via loss-augmented inference and optimization methods such
as the cutting plane algorithm [24] or the more recent block-coordinate Frank Wolfe method [25].
Pseudocode for solving Eq. (6) using the the cutting plane method is presented in Algorithm 1.
Our formulation has a general form that follows the SSVM framework. This means that Eq. (6) is
independent of the deÔ¨Ånitions of joint feature map  task-speciÔ¨Åc loss and loss-augmented inference.
We can therefore apply our method to a variety of other problems in addition to object localization.
All that is required is the deÔ¨Ånition of the three problem speciÔ¨Åc components  which are also required
in the standard SSVMs. As will be shown later  only the loss-augmented inference step becomes
harder compared to SSVMs due to the inclusion of privileged information.

4

1  y1)  . . .   (xn  x‚àó

œÅ ‚àÜ‚àó(yi  y‚àó) + [‚àÜ(yi  y) ‚àí ‚àÜ‚àó(yi  y‚àó)]+
i (y‚àó)(cid:105)

for i = 1  . . .   n do
SET-UP SURROGATE TASK-SPECIFIC LOSS (EQ. (7))
¬Ø‚àÜ(yi  y  y‚àó) = 1
SET-UP COST FUNCTION (EQ. (12))
H(y  y‚àó) = ¬Ø‚àÜ(yi  y  y‚àó) ‚àí (cid:104)w  Œ¥Œ®i(y)(cid:105) ‚àí (cid:104)w‚àó  Œ¥Œ®‚àó
FIND CUTTING PLANE
) = arg maxy y‚àó‚ààY H(y  y‚àó)
(ÀÜy  ÀÜy
FIND VALUE OF CURRENT SLACK
Œæi = max{0  maxy y‚àó‚ààSi H(y  y‚àó)}
if H(ÀÜy  ÀÜy

Algorithm 1 Cutting plane method for solving Eq. (6)
1: Input: (x1  x‚àó
n  yn)  C  œÅ  Œ≥  
2: Si ‚Üê ‚àÖ for all i = 1  . . .   n
3: repeat
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19: until no Si has changed during iteration

ADD CONSTRAINT TO WORKING SET
Si ‚Üê Si ‚à™ {(ÀÜy  ÀÜy
(w  w‚àó) ‚Üê optimize Eq. (6) over ‚à™iSi.

) > Œæi +  then

end if
end for

‚àó

)}

‚àó

‚àó

3.2

Joint Feature Map

Our extended structured output regressor  SSVM+  estimates bounding box coordinates within target
images by considering all possible bounding boxes. The structured output space is deÔ¨Åned as Y ‚â°
{(Œ∏  t  l  b  r) | Œ∏ ‚àà {+1 ‚àí1}  (t  l  b  r) ‚àà R4}  where Œ∏ denotes the presence/absence of an object
and (t  l  b  r) correspond to coordinates of the top  left  bottom  and right corners of a bounding box 
respectively. To model the relationship between input and output variables  we deÔ¨Åne a joint feature
map  encoding features in x to their bounding boxes deÔ¨Åned by y. This is modeled as

Œ®(xi  y) = xi|y 

(8)
where x|y denotes the region of an image inside a bounding box with coordinates y. Identically 
for the privileged space  we deÔ¨Åne another joint feature map  which instead of on visual features  it
operates on the space of attributes aided by segmentation information as

(9)
The deÔ¨Ånition of the joint feature map is problem speciÔ¨Åc  and we follow the method in [1] pro-
posed for object localization. Implementation details about both joint feature maps are described in
Section 4.2

Œ®‚àó(x‚àó

i   y‚àó) = x‚àó

i |y‚àó .

3.3 Task-SpeciÔ¨Åc Loss

To measure the level of discrepancy between the predicted output y and the true structured label
yi  we need to deÔ¨Åne a loss function that accurately measures such a level of disagreement. In our
object localization problem  the following task-speciÔ¨Åc loss  based on the Pascal VOC overlap ratio
[1]  is employed in both spaces 

(cid:40)

1 ‚àí area(yi‚à©y)
area(yi‚à™y)
1 ‚àí ( 1
2 (yiŒ∏yŒ∏ + 1))

if yiŒ∏ = yŒ∏ = 1
otherwise 

‚àÜ(yi  y) =

(10)
where yiŒ∏ ‚àà {+1 ‚àí1} denotes the presence (+1) or absence (‚àí1) of an object in the i-th image. In
the case yiŒ∏ = ‚àí1  Œ®(x|y) = 0  where 0 is an all zero vector. The loss is 0 when bounding boxes
deÔ¨Åned by yi and y are identical  and equal to 1 when they are disjoint or yiŒ∏ (cid:54)= yŒ∏.

3.4 Loss-Augmented Inference

Due to the exponential number of constraints that arise during learning of Eq. (6) and the possibly
very large search space Y dealt with during prediction  we require an efÔ¨Åcient inference technique 
which may differ in training and testing in the SSVM+ framework.

5

3.4.1 Prediction

The goal is to Ô¨Ånd the best bounding box given the learned weight vector w and the visual feature x.
Privileged information is not available at testing time  and inference is performed on visual features
only. Therefore  the same maximization problem as in standard SSVMs needs to be solved during
prediction  which is given by

h(x) = arg max

y‚ààY

(cid:104)w  Œ®(x  y)(cid:105).

(11)

This maximization problem is over the space of bounding box coordinates. However  this problem
involves a very large search space and therefore cannot be solved exhaustively. In the object localiza-
tion task  the EfÔ¨Åcient Subwindow Search (ESS) algorithm [2] is employed to solve the optimization
problem efÔ¨Åciently.

3.4.2 Learning

Compared to the inference problem required during the prediction step shown in Eq. (11)  the op-
timization of our main objective during training involves a more complex inference procedure. We
need to perform the following maximization with the surrogate loss and an additional term corre-
sponding to the privileged space during an iterative procedure:

‚àó

(ÀÜy  ÀÜy

) = arg max
y y‚àó‚ààY
= arg max
y y‚àó‚ààY

i (y‚àó)(cid:105)
¬Ø‚àÜ(yi  y  y‚àó) ‚àí (cid:104)w  Œ¥Œ®i(y)(cid:105) ‚àí (cid:104)w‚àó  Œ¥Œ®‚àó
¬Ø‚àÜ(yi  y  y‚àó) + (cid:104)w  Œ®(xi  y)(cid:105) + (cid:104)w‚àó  Œ®‚àó(x‚àó

i   y‚àó)(cid:105).

(12)
i   yi)(cid:105) are constants in Eq. (12) and do not affect the opti-
Note that (cid:104)w  Œ®(xi  yi)(cid:105) and (cid:104)w‚àó  Œ®‚àó(x‚àó
mization. The problem in Eq. (12)  called loss-augmented inference  is required during each iteration
of the cutting plane method  which is used for learning the functions h and œÜ and hence the weight
vectors w and w‚àó.
We adopt an alternating approach for the inference  where we Ô¨Årst solve for y‚àó in the privileged
space given the Ô¨Åxed solution in the original space yc

¬Ø‚àÜ(yi  yc  y‚àó) + (cid:104)w‚àó  Œ®‚àó(x‚àó

i   y‚àó)(cid:105)

arg max

y‚àó‚ààY

and subsequently perform optimization in the original space while Ô¨Åxing y‚àó

c

¬Ø‚àÜ(yi  y  y‚àó

c ) + (cid:104)w  Œ®(xi  y)(cid:105).

arg max

y‚ààY

(13)

(14)

These two sub-procedures in Eq. (13) and (14) are repeated until convergence  and we obtain the
Ô¨Ånal solutions w and w‚àó. In the object localization task  both problems are solved by ESS [2]  a
branch-and-bound optimization technique  for which it is essential to derive upper bounds of the
above objective functions over a set of rectangles from Y. Here we derive the upper bounds of only
the surrogate loss terms in Eq. (7); the derivation for the other terms can be found in [2].
When the solution in the privileged space is Ô¨Åxed  we need to consider the upper bound of only
[‚àÜ ‚àí ‚àÜ‚àó]+ to obtain the upper bound of the surrogate loss. Since [‚àÜ ‚àí ‚àÜ‚àó]+ is a monotonically
increasing function of ‚àÜ  its upper bound is derived directly from the upper bound of ‚àÜ. SpeciÔ¨Åcally 
the upper bound of ‚àÜ is given by

and the upper bound of the surrogate loss with a Ô¨Åxed ‚àÜ‚àó is given by

‚àÜ = 1 ‚àí area(yi ‚à© y)
area(yi ‚à™ y)

‚â§ 1 ‚àí miny‚ààY area(yi ‚à© y)
maxy‚ààY area(yi ‚à™ y)
‚àí ‚àÜ‚àó(cid:21)

(cid:20)
1 ‚àí miny‚ààY area(yi ‚à© y)
maxy‚ààY area(yi ‚à™ y)

+

 

.

[‚àÜ ‚àí ‚àÜ‚àó]+ ‚â§

(15)

(16)

When the original space is Ô¨Åxed  the problem is not straightforward since the surrogate loss becomes
a V-shaped function with œÅ > 1. In this case  we need to check outputs of the function at both upper

6

and lower bounds of ‚àÜ‚àó. The upper bound of ‚àÜ‚àó is derived identically to that of ‚àÜ  and the lower
bound of ‚àÜ‚àó is given by

(17)
l be the upper and lower bounds of ‚àÜ‚àó  respectively. Then the upper bound of the

.

‚â• 1 ‚àí maxy‚àó‚ààY area(yi ‚à© y‚àó)
miny‚àó‚ààY area(yi ‚à™ y‚àó)

‚àÜ‚àó = 1 ‚àí area(yi ‚à© y‚àó)
area(yi ‚à™ y‚àó)
(cid:18) 1

Let ‚àÜ‚àó
surrogate loss with a Ô¨Åxed ‚àÜ is given by
‚àÜ‚àó + [‚àÜ ‚àí ‚àÜ‚àó]+ ‚â§ max

u and ‚àÜ‚àó

1
œÅ

u + [‚àÜ ‚àí ‚àÜ‚àó
‚àÜ‚àó

u]+  

œÅ

l + [‚àÜ ‚àí ‚àÜ‚àó
‚àÜ‚àó
l ]+

1
œÅ

(cid:19)

.

(18)

By identifying the bounds of the surrogate loss as in Eq. (17) and (18)  we can optimize the objective
function in Eq. (12) through the alternating procedure based on the standard ESS algorithm.

4 Experiments

4.1 Dataset

Empirical evaluation of our method is performed on the Caltech-UCSD Birds 2011 (CUB-2011)
[5] Ô¨Åne-grained categorization dataset. It contains 200 categories of different species of birds. The
location of each bird is speciÔ¨Åed using a bounding box. In addition  a large collection of privileged
information is provided in the form of 15 different part annotations  312 attributes and segmentation
masks  manually labeled in each image by human annotators. Each category contains 30 training
images and around 30 testing images.

4.2 Visual and Privileged Feature Extraction

Our feature descriptor in visual space adopts the bag-of-visual-words model based on Speeded Up
Robust Features (SURF) [26]  which is almost identical to [2]. The dimensionality of visual feature
descriptors is 3 000. We additionally employ attributes and segmentation masks as privileged infor-
mation. The information about attributes is described by a 312 dimensional vector  whose element
corresponds to each attribute and which has a binary value depending on its visibility and relevance.
We use segmentation information to inpaint segmentation masks into each image  which results in
an image containing the original background pixels with uniform foreground pixels. Subsequently 
we extract the 3 000-dimensional feature descriptor based on the same bag-of-visual-words model as
in the visual space. The intuition behind this approach is to generate a set of features that provide a
guaranteed strong response in the foreground region. This response is to be stronger than in the orig-
inal space  hence allowing for easier localization in the privileged space. For each sub-window  we
create a histogram based on the presence of attributes and the frequency of the privileged codewords
corresponding to the augmented visual space.

4.3 Evaluation

To evaluate our SSVM+ algorithm  we compare it against the original SSVM localization method
by Blaschko and Lampert [1] in several training scenarios. In all experiments we tune the hyper-
parameters C  Œª and œÅ on a 4√ó 4√ó 4 space spanning values [2‚àí8  ...  25]. For SSVM  one dimension
of the search space corresponding to the parameter C is searched.
We Ô¨Årst investigate the inÔ¨Çuence of small training sample sizes on localization performance. For
this setting  we loosely adopt the experimental setup of [27]. For training  we focus on 14 bird
categories corresponding to 2 major bird groups. We train four different models  each trained on
a distinctive number of training images  namely nc = {1  5  10  20} images per class  resulting
in n = {14  70  140  280} training images  respectively. Additionally  we train a model on n =
1000 images  corresponding to 100 bird classes  each with 10 training images. As a validation
set  500 training images chosen at random from categories other than the ones used for training
are used. For testing  we use all testing images of the entire CUB-2011 dataset. Table 1 presents
results of this experiment. In all cases  our method outperforms the SSVM method in both average
overlap as well as average detection (PASCAL VOC overlap ratio > 50%). This implies that for

7

Table 1: Comparison between our SSVM+ and the standard SSVM [1] by varying the number of
classes and training images.

(A) OVERLAP

# training images
SSVM [1]
SSVM+
DIFF.

14
38.2
41.3
+3.1

70
43.8
45.7
+1.9

140
42.3
45.8
+3.5

280
44.9
46.9
+2.0

1000
48.1
49.0
+0.9

(B) DETECTION
280
70
39.8
37.3
43.3
42.4
+5.1
+3.5

140
34.3
41.5
+7.2

14
25.9
32.6
+6.7

1000
46.2
48.1
+1.9

Figure 2: Comparison results of average overlap (A) and detection results (B) between our structured
learning with privileged information (SSVM+) and the standard structured learning (SSVM) on 100
classes of the CUB-2011 dataset. The bird classes aligned in x-axis are sorted by the differences of
two methods shown in black area in a non-increasing order.

the same number of training examples  our method consistently converges to a model with better
generalization performance than SSVM. A previously observed trend [4  23] of decreasing beneÔ¨Åt
of privileged information with increasing training set sizes is also apparent here.
To evaluate the beneÔ¨Åt of SSVM+ in more depth  we illustrate average overlap and detection per-
formance on all the 100 classes in Figure 2  where 10 images per class are used for training with
14 classes (n = 140). In most of bird classes  SSVM+ shows relatively better performance in both
overlap ratio and detection rate. Note that each class typically has 30 testing images but some classes
have as little as 18 images. Average overlap ratio is 45.8% and average detection is 12.1 (41.5%).

5 Discussion

We presented a structured prediction algorithm for object localization based on SSVM with privi-
leged information. Our algorithm is the Ô¨Årst method for incorporating privileged information within
a structured prediction framework. Our method allows the use of various types of additional in-
formation during training to improve generalization performance at testing time. We applied our
proposed method to an object localization problem  which is solved by a novel structural SVM
formulation using privileged information. We employed an alternating loss-augmented inference
procedure to handle the term in the objective function corresponding to privileged information. We
applied the proposed algorithm to the Caltech-UCSD Birds 200-2011 dataset and obtained encour-
aging results  suggesting the potential beneÔ¨Åt of exploiting additional information that is available
during training only. Unfortunately  the beneÔ¨Åt of privileged information tends to reduce as the
number of training examples increases; our SSVM+ framework would be particularly useful when
there exist only a few training data or annotation cost is very high.

Acknowledgement

This work was supported partly by ICT R&D program of MSIP/IITP [14-824-09-006; 14-824-09-
014] and IT R&D Program of MKE/KEIT (10040246).

8

(cid:16)(cid:20)(cid:19)(cid:19)(cid:20)(cid:19)(cid:21)(cid:19)(cid:22)(cid:19)(cid:23)(cid:19)(cid:24)(cid:19)(cid:25)(cid:19)(cid:50)(cid:89)(cid:72)(cid:85)(cid:79)(cid:68)(cid:83)(cid:3)(cid:85)(cid:68)(cid:87)(cid:76)(cid:82)(cid:3)(cid:11)(cid:8)(cid:12)(cid:10)(cid:35)(cid:11)(cid:3)(cid:49)(cid:88)(cid:71)(cid:84)(cid:78)(cid:67)(cid:82)(cid:3)(cid:84)(cid:67)(cid:86)(cid:75)(cid:81)(cid:54)(cid:54)(cid:57)(cid:48)(cid:14)(cid:54)(cid:54)(cid:57)(cid:48)(cid:71)(cid:76)(cid:73)(cid:73)(cid:16)(cid:24)(cid:19)(cid:24)(cid:20)(cid:19)(cid:20)(cid:24)(cid:21)(cid:19)(cid:55)(cid:75)(cid:72)(cid:3)(cid:81)(cid:88)(cid:80)(cid:69)(cid:72)(cid:85)(cid:3)(cid:82)(cid:73)(cid:3)(cid:71)(cid:72)(cid:87)(cid:72)(cid:70)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:3)(cid:11)(cid:81)(cid:12)(cid:10)(cid:36)(cid:11)(cid:3)(cid:38)(cid:71)(cid:86)(cid:71)(cid:69)(cid:86)(cid:75)(cid:81)(cid:80)(cid:54)(cid:54)(cid:57)(cid:48)(cid:14)(cid:54)(cid:54)(cid:57)(cid:48)(cid:71)(cid:76)(cid:73)(cid:73)References
[1] Matthew B. Blaschko and Christoph H. Lampert. Learning to localize objects with structured output

regression. In ECCV  pages 2‚Äì15  2008.

[2] Christoph H. Lampert  Matthew B. Blaschko  and Thomas Hofmann. EfÔ¨Åcient subwindow search: A

branch and bound framework for object localization. TPAMI  31(12):2129‚Äì2142  2009.

[3] Vladimir Vapnik  Akshay Vashist  and Natalya Pavlovitch. Learning using hidden information: Master-

class learning. In NATO Workshop on Mining Massive Data Sets for Security  pages 3‚Äì14  2008.

[4] Vladimir Vapnik and Akshay Vashist. A new learning paradigm: Learning using privileged information.

Neural Networks  22(5-6):544‚Äì557  2009.

[5] Catherine Wah  Steve Branson  Peter Welinder  Pietro Perona  and Serge Belongie. The Caltech-UCSD

Birds-200-2011 Dataset. Technical report  California Institute of Technology  2011.

[6] Lixin Duan  Dong Xu  Ivor W. Tsang  and Jiebo Luo. Visual event recognition in videos by learning from

web data. TPAMI  34(9):1667‚Äì1680  2012.

[7] Lixin Duan  Ivor W. Tsang  and Dong Xu. Domain transfer multiple kernel learning. TPAMI  34(3):465‚Äì

479  2012.

[8] Qiang Chen  Zheng Song  Yang Hua  Zhongyang Huang  and Shuicheng Yan. Hierarchical matching with

side information for image classiÔ¨Åcation. In CVPR  pages 3426‚Äì3433  2012.

[9] Hao Xia  Steven C.H. Hoi  Rong Jin  and Peilin Zhao. Online multiple kernel similarity learning for

visual search. TPAMI  36(3):536‚Äì549  2013.

[10] Gang Wang  David Forsyth  and Derek Hoiem. Improved object categorization and detection using com-

parative object similarity. TPAMI  35(10):2442‚Äì2453  2013.

[11] Wen Li  Lixin Duan  Dong Xu  and Ivor W. Tsang. Learning with augmented features for supervised and

semi-supervised heterogeneous domain adaptation. TPAMI  36(6):1134‚Äì11148  2013.

[12] Christoph H. Lampert  Hannes Nickisch  and Stefan Harmeling. Learning to detect unseen object classes

by between-class attribute transfer. In CVPR  2009.

[13] Ali Farhadi  Ian Endres  Derek Hoiem  and David Forsyth. Describing objects by their attributes.

CVPR  2009.

In

[14] Mohamed Elhoseiny  Babak Saleh  and Ahmed Elgammal. Write a classiÔ¨Åer: Zero-shot learning using

purely textual descriptions. In ICCV  2013.

[15] Richard Socher  Milind Ganjoo  Christopher D. Manning  and Andrew Y. Ng. Zero-shot learning through

cross-modal transfer. In NIPS  pages 935‚Äì943  2013.

[16] Lior Wolf and Noga Levy. The svm-minus similarity score for video face recognition. In CVPR  2013.
[17] Heng Yang and Ioannis Patras. Privileged information-based conditional regression forest for facial fea-

ture detection. In IEEE FG  pages 1‚Äì6  2013.

[18] Xiaoyang Wang and Qiang Ji. A novel probabilistic approach utilizing clip attribute as hidden knowledge

for event recognition. In ICPR  pages 3382‚Äì3385  2012.

[19] Cezar Ionescu  Liefeng Bo  and Cristian Sminchisescu. Structural svm for visual localization and contin-

uous state estimation. In ICCV  pages 1157‚Äì1164  2009.

[20] Qieyun Dai and Derek Hoiem. Learning to localize detected objects. In CVPR  pages 3322‚Äì3329  2012.
[21] Viktoriia Sharmanska  Novi Quadrianto  and Christoph H. Lampert. Learning to rank using privileged

information. In ICCV  pages 825‚Äì832  2013.

[22] Vladimir Vapnik. Estimation of Dependences Based on Empirical Data. Springer  2006.
[23] Dmitry Pechyony and Vladimir Vapnik. On the theory of learning with privileged information. NIPS 

pages 1894‚Äì1902  2010.

[24] Ioannis Tsochantaridis  Thorsten Joachims  Thomas Hofmann  and Yasemin Altun. Large margin meth-

ods for structured and interdependent output variables. JMLR  6:1453‚Äì1484  2005.

[25] Simon Lacoste-Julien  Martin Jaggi  Mark Schmidt  and Patrick Pletscher. Block-coordinate frank-wolfe

optimization for structural svms. In ICML  2013.

[26] Herbert Bay  Andreas Ess  Tinne Tuytelaars  and Luc Van Gool. Speeded-up robust features (SURF).

CVIU  110(3):346‚Äì359  2008.

[27] Ryan Farrell  Om Oza  Ning Zhang  Vlad I. Morariu  Trevor Darrell  and Larry S. Davis. Birdlets:
Subordinate categorization using volumetric primitives and pose-normalized appearance. In ICCV  pages
161‚Äì168  2011.

9

,Jan Feyereisl
Suha Kwak
Jeany Son
Bohyung Han