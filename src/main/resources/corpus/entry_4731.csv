2017,Revisiting Perceptron: Efficient and Label-Optimal Learning of Halfspaces,It has been a long-standing problem to efficiently learn a halfspace using as few labels as possible in the presence of noise. In this work  we propose an efficient Perceptron-based algorithm for actively learning homogeneous halfspaces under the uniform distribution over the unit sphere. Under the bounded noise condition~\cite{MN06}  where each label is flipped with probability at most $\eta < \frac 1 2$  our algorithm achieves a near-optimal label complexity of $\tilde{O}\left(\frac{d}{(1-2\eta)^2}\ln\frac{1}{\epsilon}\right)$ in time $\tilde{O}\left(\frac{d^2}{\epsilon(1-2\eta)^3}\right)$. Under the adversarial noise condition~\cite{ABL14  KLS09  KKMS08}  where at most a $\tilde \Omega(\epsilon)$ fraction of labels can be flipped  our algorithm achieves a near-optimal label complexity of $\tilde{O}\left(d\ln\frac{1}{\epsilon}\right)$ in time $\tilde{O}\left(\frac{d^2}{\epsilon}\right)$. Furthermore  we show that our active learning algorithm can be converted to an efficient passive learning algorithm that has near-optimal sample complexities with respect to $\epsilon$ and $d$.,Revisiting Perceptron:

Efﬁcient and Label-Optimal Learning of Halfspaces

Songbai Yan
UC San Diego
La Jolla  CA

Chicheng Zhang∗
Microsoft Research

New York  NY

yansongbai@ucsd.edu

chicheng.zhang@microsoft.com

Abstract

It has been a long-standing problem to efﬁciently learn a halfspace using as few
labels as possible in the presence of noise. In this work  we propose an efﬁcient
Perceptron-based algorithm for actively learning homogeneous halfspaces under the
uniform distribution over the unit sphere. Under the bounded noise condition [49] 
where each label is ﬂipped with probability at most η < 1
2  our algorithm achieves a

the adversarial noise condition [6  45  42]  where at most a ˜Ω(�) fraction of labels

near-optimal label complexity of ˜O�
�(1−2η)3�. Under
can be ﬂipped  our algorithm achieves a near-optimal label complexity of ˜O�d ln 1
��
in time ˜O� d2
��. Furthermore  we show that our active learning algorithm can be

converted to an efﬁcient passive learning algorithm that has near-optimal sample
complexities with respect to � and d.

d

(1−2η)2 ln 1

��2 in time ˜O�

d2

1

Introduction

We study the problem of designing efﬁcient noise-tolerant algorithms for actively learning homoge-
neous halfspaces in the streaming setting. We are given access to a data distribution from which we
can draw unlabeled examples  and a noisy labeling oracle O that we can query for labels. The goal is
to ﬁnd a computationally efﬁcient algorithm to learn a halfspace that best classiﬁes the data while
making as few queries to the labeling oracle as possible.
Active learning arises naturally in many machine learning applications where unlabeled examples are
abundant and cheap  but labeling requires human effort and is expensive. For those applications  one
natural question is whether we can learn an accurate classiﬁer using as few labels as possible. Active
learning addresses this question by allowing the learning algorithm to sequentially select examples
to query for labels  and avoid requesting labels which are less informative  or can be inferred from
previously-observed examples.
There has been a large body of work on the theory of active learning  showing sharp distribution-
dependent label complexity bounds [21  11  34  27  35  46  60  41]. However  most of these general
active learning algorithms rely on solving empirical risk minimization problems  which are computa-
tionally hard in the presence of noise [5].
On the other hand  existing computationally efﬁcient algorithms for learning halfspaces [17  29  42 
45  6  23  7  8] are not optimal in terms of label requirements. These algorithms have different degrees
of noise tolerance (e.g. adversarial noise [6]  malicious noise [43]  random classiﬁcation noise [3] 

∗Work done while at UC San Diego.
2We use ˜O(f (·)) := O(f (·) ln f (·))  and ˜Ω(f (·)) := Ω(f (·)/ ln f (·)). We say f (·) = ˜Θ(g(·)) if f (·) =
˜O(g(·)) and f (·) = ˜Ω�g(·)�

31st Conference on Neural Information Processing Systems (NIPS 2017)  Long Beach  CA  USA.

bounded noise [49]  etc)  and run in time polynomial in 1
� and d. Some of them naturally exploit the
utility of active learning [6  7  8]  but they do not achieve the sharpest label complexity bounds in
contrast to those computationally-inefﬁcient active learning algorithms [10  9  60].
Therefore  a natural question is: is there any active learning halfspace algorithm that is computationally
efﬁcient  and has a minimum label requirement? This has been posed as an open problem in [50].
In the realizable setting  [26  10  9  56] give efﬁcient algorithms that have optimal label complexity
of ˜O(d ln 1
� ) under some distributional assumptions. However  the challenge still remains open in
the nonrealizable setting. It has been shown that learning halfspaces with agnostic noise even under
Gaussian unlabeled distribution is hard [44]. Nonetheless  we give an afﬁrmative answer to this
question under two moderate noise settings: bounded noise and adversarial noise.

1.1 Our Results

d

d

d

d2

d

O(

1

O(

1

We propose a Perceptron-based algorithm  ACTIVE-PERCEPTRON  for actively learning homoge-
neous halfspaces under the uniform distribution over the unit sphere. It works under two noise
settings: bounded noise and adversarial noise. Our work answers an open question by [26] on
whether Perceptron-based active learning algorithms can be modiﬁed to tolerate label noise.
In the η-bounded noise setting (also known as the Massart noise model [49])  the label of an example
x ∈ Rd is generated by sign(u · x) for some underlying halfspace u  and ﬂipped with probabil-
(1−2η)3��  and requires ˜O�
��
ity η(x) ≤ η < 1
(1−2η)2 · ln 1
labels. We show that this label complexity is nearly optimal by providing an almost matching
��. Our time and label complexities substan-
information-theoretic lower bound of Ω�

2. Our algorithm runs in time ˜O�
(1−2η)2 · ln 1

tially improve over the state of the art result of [8]  which runs in time ˜O(d
˜O(d
Our main theorem on learning under bounded noise is as follows:
Theorem 2 (Informal). Suppose the labeling oracle O satisﬁes the η-bounded noise condition with
respect to u  then for ACTIVE-PERCEPTRON  with probability at least 1−δ: (1) The output halfspace
v is such that P[sign(v · X) �= sign(u · X)] ≤ �; (2) The number of label queries to oracle O is at
most ˜O�
(1−2η)3��; (4)
The algorithm runs in time ˜O�

��; (3) The number of unlabeled examples drawn is at most ˜O�

(1−2η)3��.

(1−2η)2 · ln 1

� ) and requires

� ) labels.

(1−2η)4 ) 1

(1−2η)4 )

ln 1

�

ln d

δ +ln ln 1

��. It runs in time ˜O� d2

In addition  we show that our algorithm also works in a more challenging setting  the ν-adversarial
noise setting [6  42  45].3 In this setting  the examples still come iid from a distribution  but the
assumption on the labels is just that P[sign(u · X) �= Y ] ≤ ν for some halfspace u. Under this
assumption  the Bayes classiﬁer may not be a halfspace. We show that our algorithm achieves an
error of � while tolerating a noise level of ν = Ω�
��  and requires
only ˜O�d · ln 1
�� labels which is near-optimal. ACTIVE-PERCEPTRON has a label complexity bound
that matches the state of the art result of [39]4  while having a lower running time.
Our main theorem on learning under adversarial noise is as follows:
Theorem 3 (Informal). Suppose the labeling oracle O satisﬁes the ν-adversarial noise condition
with respect to u  where ν < Θ(
). Then for ACTIVE-PERCEPTRON  with probability at
least 1− δ: (1) The output halfspace v is such that P[sign(v· X) �= sign(u· X)] ≤ �; (2) The number
of label queries to oracle O is at most ˜O�d · ln 1
��; (3) The number of unlabeled examples drawn is
at most ˜O� d
��.
��; (4) The algorithm runs in time ˜O� d2

δ +ln ln 1

ln d

�

�

d2

3Note that the adversarial noise model is not the same as that in online learning [18]  where each example

4The label complexity bound is implicit in [39] by a reﬁned analysis of the algorithm of [6] (See their Lemma

can be chosen adversarially.

8 for details).

2

Table 1: A comparison of algorithms for active learning of halfspaces under the uniform distribution 
in the η-bounded noise model.

Algorithm Label Complexity
[10  9  60]
[8]
Our Work

(1−2η)2 ln 1
� )

˜O(
˜O(d
˜O(

(1−2η)4 ) · ln 1
� )

O(

d

1

d

(1−2η)2 ln 1
� )

Time Complexity
� ) 5
superpoly(d  1
(1−2η)4 ) · 1
˜O(d
� )
��

˜O� d2

(1−2η)3

O(

1

1

Table 2: A comparison of algorithms for active learning of halfspaces under the uniform distribution 
in the ν-adversarial noise model.

Algorithm Noise Tolerance
[60]
[39]
Our Work

ν = Ω(�)
ν = Ω(�)
ν = Ω(

�

ln d+ln ln 1
�

Label Complexity Time Complexity
˜O(d ln 1
� )
˜O(d ln 1
� )
˜O(d ln 1
� )

superpoly(d  1
� )
poly(d  1
� )

˜O�d2 · 1
��

)

Throughout the paper  ACTIVE-PERCEPTRON is shown to work if the unlabeled examples are drawn
uniformly from the unit sphere. The algorithm and analysis can be easily generalized to any spherical
symmetrical distributions  for example  isotropic Gaussian distributions. They can also be generalized
to distributions whose densities with respect to uniform distribution are bounded away from 0.
In addition  we show in Section 6 that ACTIVE-PERCEPTRON can be converted to a passive learning
algorithm  PASSIVE-PERCEPTRON  that has near optimal sample complexities with respect to � and
d under the two noise settings. We defer the discussion to the end of the paper.

2 Related Work

Active Learning. The recent decades have seen much success in both theory and practice of active
learning; see the excellent surveys by [54  37  25]. On the theory side  many label-efﬁcient active
learning algorithms have been proposed and analyzed. An incomplete list includes [21  11  34  27 
35  46  60  41]. Most algorithms relies on solving empirical risk minimization problems  which are
computationally hard in the presence of noise [5].

Computational Hardness of Learning Halfspaces. Efﬁcient learning of halfspaces is one of
the central problems in machine learning [22]. In the realizable case  it is well known that linear
programming will ﬁnd a consistent hypothesis over data efﬁciently. In the nonrealizable setting 
however  the problem is much more challenging.
A series of papers have shown the hardness of learning halfspaces with agnostic noise [5  30  33  44 
23]. The state of the art result [23] shows that under standard complexity-theoretic assumptions  there
exists a data distribution  such that the best linear classiﬁer has error o(1)  but no polynomial time
algorithms can achieve an error at most 1
dc for every c > 0  even with improper learning. [44]
2 − 1
shows that under standard assumptions  even if the unlabeled distribution is Gaussian  any agnostic
halfspace learning algorithm must run in time ( 1
� )Ω(ln d) to achieve an excess error of �. These results
indicate that  to have nontrivial guarantees on learning halfspaces with noise in polynomial time  one
has to make additional assumptions on the data distribution over instances and labels.

Efﬁcient Active Learning of Halfspaces. Despite considerable efforts  there are only a few halfs-
pace learning algorithms that are both computationally-efﬁcient and label-efﬁcient even under the
uniform distribution. In the realizable setting  [26  10  9] propose computationally efﬁcient active
learning algorithms which have an optimal label complexity of ˜O(d ln 1
Since it is believed to be hard for learning halfspaces in the general agnostic setting  it is natural
to consider algorithms that work under more moderate noise conditions. Under the bounded noise

� ).

5The algorithm needs to minimize 0-1 loss  the best known method for which requires superpolynomial time.

3

1

d

O(

ln 1

(1−2η)4 )

(1−2η)2 ln 1

setting [49]  the only known algorithms that are both label-efﬁcient and computationally-efﬁcient are
[7  8]. [7] uses a margin-based framework which queries the labels of examples near the decision
boundary. To achieve computational efﬁciency  it adaptively chooses a sequence of hinge loss
minimization problems to optimize as opposed to directly optimizing the 0-1 loss. It works only
when the label ﬂipping probability upper bound η is small (η ≤ 1.8 × 10−6). [8] improves over [7]
by adapting a polynomial regression procedure into the margin-based framework. It works for any
η < 1/2  but its label complexity is O(d
� )  which is far worse than the information-
theoretic lower bound Ω(
� ). Recently [20] gives an efﬁcient algorithm with a near-optimal
label complexity under the membership query model where the learner can query on synthesized
points. In contrast  in our stream-based model  the learner can only query on points drawn from the
data distribution. We note that learning in the stream-based model is harder than in the membership
query model  and it is unclear how to transform the DC algorithm in [20] into a computationally
efﬁcient stream-based active learning algorithm.
Under the more challenging ν-adversarial noise setting  [6] proposes a margin-based algorithm that
reduces the problem to a sequence of hinge loss minimization problems. Their algorithm achieves an
error of � in polynomial time when ν = Ω(�)  but requires ˜O(d2 ln 1
� ) labels. Later  [39] performs a
reﬁned analysis to achieve a near-optimal label complexity of ˜O(d ln 1
� )  but the time complexity of
the algorithm is still an unspeciﬁed high order polynomial.
Tables 1 and 2 present comparisons between our results and results most closely related to ours
in the literature. Due to space limitations  discussions of additional related work are deferred to
Appendix A.

3 Deﬁnitions and Settings

We consider learning homogeneous halfspaces under uniform distribution. The instance space X
is the unit sphere in Rd  which we denote by Sd−1 := �x ∈ Rd : �x� = 1�. We assume d ≥ 3
throughout this paper. The label space Y = {+1 −1}. We assume all data points (x  y) are drawn
i.i.d. from an underlying distribution D over X × Y. We denote by DX the marginal of D over X
(which is uniform over Sd−1)  and DY |X the conditional distribution of Y given X. Our algorithm is
allowed to draw unlabeled examples x ∈ X from DX   and to make queries to a labeling oracle O for
labels. Upon query x  O returns a label y drawn from DY |X=x. The hypothesis class of interest is
the set of homogeneous halfspaces H :=�hw(x) = sign(w · x) | w ∈ Sd−1�. For any hypothesis
h ∈ H  we deﬁne its error rate err(h) := PD[h(X) �= Y ]. We will drop the subscript D in PD when
it is clear from the context. Given a dataset S =�(X1  Y1)  . . .   (Xm  Ym)�  we deﬁne the empirical
error rate of h over S as errS(h) := 1
Deﬁnition 1 (Bounded Noise [49]). We say that the labeling oracle O satisﬁes the η-bounded noise
condition for some η ∈ [0  1/2) with respect to u  if for any x  P[Y �= sign(u · x) | X = x] ≤ η.
It can be seen that under η-bounded noise condition  hu is the Bayes classiﬁer.
Deﬁnition 2 (Adversarial Noise [6]). We say that the labeling oracle O satisﬁes the ν-adversarial
noise condition for some ν ∈ [0  1] with respect to u  if P[Y �= sign(u · X)] ≤ ν.
For two unit vectors v1  v2  denote by θ(v1  v2) = arccos(v1 · v2) the angle between them. The
following lemma gives relationships between errors and angles (see also Lemma 1 in [8]).

1�h(xi) �= yi�.

m�m

i=1

Additionally  if the labeling oracle satisﬁes the η-bounded noise condition with respect to u  then for

Lemma 1. For any v1  v2 ∈ Sd−1 ��err(hv1 ) − err(hv2 )�� ≤ P�hv1 (X) �= hv2 (X)� = θ(v1 v2)
any vector v ��err(hv) − err(hu)�� ≥ (1 − 2η)P�hv(X) �= hu(X)� = 1−2η

Given access to unlabeled examples drawn from DX and a labeling oracle O  our goal is to ﬁnd a
polynomial time algorithm A such that with probability at least 1 − δ  A outputs a halfspace hv ∈ H
with P[sign(v · X) �= sign(u · X)] ≤ � for some target accuracy � and conﬁdence δ. (By Lemma 1 
this guarantees that the excess error of hv is at most �  namely  err(hv) − err(hu) ≤ �.) The desired
algorithm should make as few queries to the labeling oracle O as possible.

π θ(v  u).

π

.

4

We say an algorithm A achieves a label complexity of Λ(�  δ)  if for any target halfspace hu ∈ H 
with probability at least 1 − δ  A outputs a halfspace hv ∈ H such that err(hv) ≤ err(hu) + �  and
requests at most Λ(�  δ) labels from oracle O.
4 Main Algorithm

Our main algorithm  ACTIVE-PERCEPTRON (Algorithm 1)  works in epochs. It works under the
bounded and the adversarial noise models  if its sample schedule {mk} and band width {bk} are set
appropriately with respect to each noise model. At the beginning of each epoch k  it assumes an upper
2k on θ(vk−1  u)  the angle between current iterate vk−1 and the underlying halfspace u.
bound of π
As we will see  this can be shown to hold with high probability inductively. Then  it calls procedure
MODIFIED-PERCEPTRON (Algorithm 2) to ﬁnd an new iterate vk  which can be shown to have an
angle with u at most
1
��
epochs have passed.
For simplicity  we assume for the rest of the paper that the angle between the initial halfspace v0 and
2 ; Appendix F shows that this assumption
the underlying halfspace u is acute  that is  θ(v0  u) ≤ π
can be removed with a constant overhead in terms of label and time complexities.

2k+1 with high probability. The algorithm ends when a total of k0 = �log2

π

Algorithm 1 ACTIVE-PERCEPTRON
Input: Labeling oracle O  initial halfspace v0  target error �  conﬁdence δ  sample schedule {mk} 
band width {bk}.
Output: learned halfspace v.
1: Let k0 = �log2
��.
2: for k = 1  2  . . .   k0 do
3:
4: end for
5: return vk0.

vk ← MODIFIED-PERCEPTRON(O  vk−1  π
2k  

1

δ

k(k+1)   mk  bk).

Procedure MODIFIED-PERCEPTRON (Algorithm 2) is the core component of ACTIVE-PERCEPTRON.
It sequentially performs a modiﬁed Perceptron update rule on the selected new examples (xt  yt) [51 
17  26]:

wt+1 ← wt − 21{ytwt · xt < 0} (wt · xt) · xt

(1)

Deﬁne θt := θ(wt  u). Update rule (1) implies the following relationship between θt+1 and θt (See
Lemma 8 in Appendix E for its proof):

cos θt+1 − cos θt = −21{ytwt · xt < 0} (wt · xt) · (u · xt)

(2)
This motivates us to take cos θt as our measure of progress; we would like to drive cos θt up to 1(so
that θt goes down to 0) as fast as possible.
To this end  MODIFIED-PERCEPTRON samples new points xt under time-varying distributions DX|Rt
and query for their labels  where Rt =�x ∈ Sd−1 : b
2 ≤ wt · x ≤ b� is a band inside the unit sphere.

The rationale behind the choice of Rt is twofold:

1. We set Rt to have a probability mass of ˜Ω(�)  so that the time complexity of rejection
� ) per example. Moreover  in the adversarial noise setting  we set Rt

sampling is at most ˜O( 1
large enough to dominate the noise of magnitude ν = ˜Ω(�).

2. Unlike the active Perceptron algorithm in [26] or other margin-based approaches (for
example [55  10]) where examples with small margin are queried  we query the label of the
examples with a range of margin [ b
2   b]. From a technical perspective  this ensures that θt
decreases by a decent amount in expectation (see Lemmas 9 and 10 for details).

Following the insight of [32]  we remark that the modiﬁed Perceptron update (1) on distribution
DX|Rt can be alternatively viewed as performing stochastic gradient descent on a special non-convex
loss function �(w  (x  y)) = min(1  max(0 −1− 2
b yw·x)). It is an interesting open question whether
optimizing this new loss function can lead to improved empirical results for learning halfspaces.

5

iterations m  band width b.

Algorithm 2 MODIFIED-PERCEPTRON
Input: Labeling oracle O  initial halfspace w0  angle upper bound θ  conﬁdence δ  number of
Output: Improved halfspace wm.
1: for t = 0  1  2  . . .   m − 1 do
2:
3:

2 ≤ wt · x ≤ b�.
Deﬁne region Rt =�x ∈ Sd−1 : b
Rejection sample xt ∼ DX|Rt. In other words  draw xt from DX until xt is in Rt. Query O
for its label yt.
wt+1 ← wt − 21{ytwt · xt < 0} · (wt · xt) · xt.

4:
5: end for
6: return wm.

5 Performance Guarantees

We show that ACTIVE-PERCEPTRON works in the bounded and the adversarial noise models  achiev-
ing computational efﬁciency and near-optimal label complexities. To this end  we ﬁrst give a lower
bound on the label complexity under bounded noise  and then give computational and label complexity
upper bounds under the two noise conditions respectively. We defer all proofs to the Appendix.

5.1 A Lower Bound under Bounded Noise

We ﬁrst present an information-theoretic lower bound on the label complexity in the bounded noise
setting under uniform distribution. This extends the distribution-free lower bounds of [53  37]  and
generalizes the realizable-case lower bound of [47] to the bounded noise setting. Our lower bound
can also be viewed as an extension of [59]’s Theorem 3; speciﬁcally it addresses the hardness under
the α-Tsybakov noise condition where α = 0 (while [59]’s Theorem 3 provides lower boundes when
α ∈ (0  1)).
Theorem 1. For any d > 4  0 ≤ η < 1
4   for any active learning algorithm
A  there is a u ∈ Sd−1  and a labeling oracle O that satisﬁes η-bounded noise condition with respect
to u  such that if with probability at least 1− δ  A makes at most n queries of labels to O and outputs
v ∈ Sd−1 such that P[sign(v · X) �= sign(u · X)] ≤ �  then n ≥ Ω� d log 1

(1−2η)2�.
(1−2η)2 + η log 1

4π   0 < δ ≤ 1

2   0 < � ≤ 1

δ

�

5.2 Bounded Noise

d

1

(1−2η)4 )

ln 1

O(

(1−2η)2 ln 1

� ) is shown using a different algorithm.

We establish Theorem 2 in the bounded noise setting. The theorem implies that  with appropriate
settings of input parameters  ACTIVE-PERCEPTRON efﬁciently learns a halfspace of excess error
at most � with probability at least 1 − δ  under the assumption that DX is uniform over the unit
sphere and O has bounded noise. In addition  it queries at most ˜O(
� ) labels. This matches
the lower bound of Theorem 1  and improves over the state of the art result of [8]  where a label
complexity of ˜O(d
The proof and the precise setting of parameters (mk and bk) are given in Appendix C.
Theorem 2 (ACTIVE-PERCEPTRON under Bounded Noise). Suppose Algorithm 1 has inputs la-
beling oracle O that satisﬁes η-bounded noise condition with respect to halfspace u  initial half-
space v0 such that θ(v0  u) ∈ [0  π
2 ]  target error �  conﬁdence δ  sample schedule {mk} where
√d ln(kmk/δ)�. Then with
mk = Θ�
(1−2η)2 + ln k
probability at least 1 − δ:
1. The output halfspace v is such that P[sign(v · X) �= sign(u · X)] ≤ �.
2. The number of label queries is O� d
(1−2η)2 + ln 1

δ )�  band width {bk} where bk = Θ� 2−k(1−2η)

(1−2η)2 · ln 1

(1−2η)2 (ln

δ + ln ln 1

d

d

� ·�ln

d

6

���.

d

d

3. The number of unlabeled examples drawn is

· 1
� ln 1

· 1
� ln 1

��.

��2

δ + ln ln 1

δ + ln ln 1

��2
(1−2η)3 ·�ln

��.
(1−2η)2 + ln 1

O� d
(1−2η)3 ·�ln
(1−2η)2 + ln 1
4. The algorithm runs in time O� d2
The theorem follows from Lemma 2 below. The key ingredient of the lemma is a delicate analysis
of the dynamics of the angles {θt}m
t=0  where θt = θ(wt  u) is the angle between the iterate wt
and the halfspace u. Since xt is randomly sampled and yt is noisy  we are only able to show that
θt decreases by a decent amount in expectation. To remedy the stochastic ﬂuctuations  we apply
martingale concentration inequalities to carefully control the upper envelope of sequence {θt}m
t=0.
Lemma 2 (MODIFIED-PERCEPTRON under Bounded Noise). Suppose Algorithm 2 has inputs
labeling oracle O that satisﬁes η-bounded noise condition with respect to halfspace u  initial
halfspace w0 and angle upper bound θ ∈ (0  π
2 ] such that θ(w0  u) ≤ θ  conﬁdence δ  number
δ ))  band width b = Θ� θ(1−2η)
√d ln(m/δ)�. Then with
of iterations m = Θ(
(1−2η)2 + ln 1
probability at least 1 − δ:
1. The output halfspace wm is such that θ(wm  u) ≤ θ
2 .
2. The number of label queries is O� d
3. The number of unlabeled examples drawn is O� d
4. The algorithm runs in time O� d2

δ��.
(1−2η)2 + ln 1
(1−2η)3 ·�ln
δ�2
(1−2η)2 + ln 1

δ�2
(1−2η)2 + ln 1
θ�.
· 1

(1−2η)3 ·�ln

(1−2η)2�ln

θ�.
· 1

(1−2η)2 (ln

d

d

d

d

d

5.3 Adversarial Noise

�

ln d+ln ln 1
�

We establish Theorem 3 in the adversarial noise setting. The theorem implies that  with appropriate
settings of input parameters  ACTIVE-PERCEPTRON efﬁciently learns a halfspace of excess error at
most � with probability at least 1 − δ  under the assumption that DX is uniform over the unit sphere
). In addition  it queries at most
and O has an adversarial noise of magnitude ν = Ω(
˜O(d ln 1
� ) labels. Our label complexity bound is information-theoretically optimal [47]  and matches
the state of the art result of [39]. The beneﬁt of our approach is computational: it has a running time
of ˜O( d2
� )  while [39] needs to solve a convex optimization problem whose running time is some
polynomial over d and 1
The proof and the precise setting of parameters (mk and bk) are given in Appendix C.
Theorem 3 (ACTIVE-PERCEPTRON under Adversarial Noise). Suppose Algorithm 1 has inputs
labeling oracle O that satisﬁes ν-adversarial noise condition with respect to halfspace u  initial
halfspace v0 such that θ(v0  u) ≤ π
2   target error �  conﬁdence δ  sample schedule {mk} where
√d ln(kmk/δ)�. Additionally ν ≤
mk = Θ(d(ln d + ln k

δ ))  band width {bk} where bk = Θ�

� with an unspeciﬁed degree.

2−k

Ω(

ln d

�

�

). Then with probability at least 1 − δ:
δ +ln ln 1
1. The output halfspace v is such that P[sign(v · X) �= sign(u · X)] ≤ �.
2. The number of label queries is O�d · ln 1
3. The number of unlabeled examples drawn is O�d ·�ln d + ln 1
4. The algorithm runs in time O�d2 ·�ln d + ln 1
��2

� ·�ln d + ln 1

���.
��.

δ + ln ln 1

δ + ln ln 1

· 1
� ln 1

7

δ + ln ln 1

· 1
� ln 1

��.

��2

The theorem follows from Lemma 3 below  whose proof is similar to Lemma 2.
Lemma 3 (MODIFIED-PERCEPTRON under Adversarial Noise). Suppose Algorithm 2 has inputs
labeling oracle O that satisﬁes ν-adversarial noise condition with respect to halfspace u  initial
halfspace w0 and angle upper bound θ ∈ (0  π
2 ] such that θ(w0  u) ≤ θ  conﬁdence δ  number of
iterations m = Θ(d(ln d + ln 1
ln(m/δ)) ).
Then with probability at least 1 − δ:

δ ))  band width b = Θ�
1. The output halfspace wm is such that θ(wm  u) ≤ θ
2 .

θ√d ln(m/δ)�. Additionally ν ≤ Ω(

θ

2. The number of label queries is O�d ·�ln d + ln 1
δ��.
3. The number of unlabeled examples drawn is O�d ·�ln d + ln 1
δ�2
θ�.
4. The algorithm runs in time O�d2 ·�ln d + ln 1
δ�2
· 1

θ�
· 1

6

Implications to Passive Learning

1

�

d

ACTIVE-PERCEPTRON can be converted to a passive learning algorithm  PASSIVE-PERCEPTRON 
for learning homogeneous halfspaces under the uniform distribution over the unit sphere.
PASSIVE-PERCEPTRON has PAC sample complexities close to the lower bounds under the two
noise models. We give a formal description of PASSIVE-PERCEPTRON in Appendix B. We give its
formal guarantees in the corollaries below  which are immediate consequences of Theorems 2 and 3.
In the η-bounded noise model  the sample complexity of PASSIVE-PERCEPTRON improves over the
(1−2η)4 )
state of the art result of [8]  where a sample complexity of ˜O( d
) is obtained. The bound
has the same dependency on � and d as the minimax upper bound of ˜Θ(
�(1−2η) ) by [49]  which is
achieved by a computationally inefﬁcient ERM algorithm.
Corollary 1 (PASSIVE-PERCEPTRON under Bounded Noise). Suppose PASSIVE-PERCEPTRON has
inputs distribution D that satisﬁes η-bounded noise condition with respect to u  initial halfspace v0 

δ )� 
target error �  conﬁdence δ  sample schedule {mk} where mk = Θ�
(1−2η)2 + ln k
band width {bk} where bk = Θ� 2−k(1−2η)
√d ln(kmk/δ)�. Then with probability at least 1 − δ: (1) The
output halfspace v is such that err(hv) ≤ err(hu) + �; (2) The number of labeled examples drawn is
˜O�
(1−2η)3��. (3) The algorithm runs in time ˜O�

(1−2η)3��.

(1−2η)2 (ln

d2

O(

In the ν-adversarial noise model  the sample complexity of PASSIVE-PERCEPTRON matches the
minimax optimal sample complexity upper bound of ˜Θ( d
� ) obtained in [39]. Same as in active
learning  our algorithm has a faster running time than [39].
Corollary 2 (PASSIVE-PERCEPTRON under Adversarial Noise). Suppose PASSIVE-PERCEPTRON
has inputs distribution D that satisﬁes ν-adversarial noise condition with respect to u  initial

halfspace v0  target error �  conﬁdence δ  sample schedule {mk} where mk = Θ�d(ln d + ln k
δ )� 
band width {bk} where bk = Θ�
). Then with
probability at least 1 − δ: (1) The output halfspace v is such that err(hv) ≤ err(hu) + �; (2) The
number of labeled examples drawn is ˜O� d

��. (3) The algorithm runs in time ˜O� d2
��.

√d ln(kmk/δ)�. Furthermore ν = Ω(

Tables 3 and 4 present comparisons between our results and results most closely related to ours.

�
ln ln 1
� +ln d

2−k

d

d

d

δ

Acknowledgments. The authors thank Kamalika Chaudhuri for help and support  Hongyang Zhang
for thought-provoking initial conversations  Jiapeng Zhang for helpful discussions  and the anonymous
reviewers for their insightful feedback. Much of this work is supported by NSF IIS-1167157 and
1162581.

8

Table 3: A comparison of algorithms for PAC learning halfspaces under the uniform distribution  in
the η-bounded noise model.

Algorithm Sample Complexity Time Complexity

[8]
ERM [49]
Our Work

O(

˜O( d
˜O(
˜O(

1

(1−2η)4 )
d

�

(1−2η)� )
(1−2η)3� )

d

)

1

�

O(

(1−2η)4 )
˜O( d
)
superpoly(d  1
� )
˜O(
(1−2η)3 · 1
� )

d2

Table 4: A comparison of algorithms for PAC learning halfspaces under the uniform distribution  in
the ν-adversarial noise model where ν = Ω(

�
ln ln 1

� +ln d ).

Algorithm Sample Complexity Time Complexity
[39]
ERM [57]
Our Work

poly(d  1
� )
superpoly(d  1
� )
˜O( d2
� )

˜O( d
� )
˜O( d
� )
˜O( d
� )

References
[1] Alekh Agarwal. Selective sampling algorithms for cost-sensitive multiclass prediction. ICML (3)  28:

1220–1228  2013.

[2] Nir Ailon  Ron Begleiter  and Esther Ezra. Active learning using smooth relative regret approximations

with applications. Journal of Machine Learning Research  15(1):885–920  2014.

[3] Dana Angluin and Philip Laird. Learning from noisy examples. Machine Learning  2(4):343–370  Apr
1988. ISSN 1573-0565. doi: 10.1023/A:1022873112823. URL https://doi.org/10.1023/A:
1022873112823.

[4] Martin Anthony and Peter L Bartlett. Neural network learning: Theoretical foundations. Cambridge

University Press  2009.

[5] Sanjeev Arora  László Babai  Jacques Stern  and Z Sweedyk. The hardness of approximate optima in
lattices  codes  and systems of linear equations. In Foundations of Computer Science  1993. Proceedings. 
34th Annual Symposium on  pages 724–733. IEEE  1993.

[6] Pranjal Awasthi  Maria Florina Balcan  and Philip M Long. The power of localization for efﬁciently
learning linear separators with noise. In Proceedings of the 46th Annual ACM Symposium on Theory of
Computing  pages 449–458. ACM  2014.

[7] Pranjal Awasthi  Maria-Florina Balcan  Nika Haghtalab  and Ruth Urner. Efﬁcient learning of linear

separators under bounded noise. In COLT  pages 167–190  2015.

[8] Pranjal Awasthi  Maria-Florina Balcan  Nika Haghtalab  and Hongyang Zhang. Learning and 1-bit
compressed sensing under asymmetric noise. In Proceedings of The 28th Conference on Learning Theory 
COLT 2016  2016.

[9] M.-F. Balcan and P. M. Long. Active and passive learning of linear separators under log-concave distribu-

tions. In COLT  2013.

[10] M.-F. Balcan  A. Z. Broder  and T. Zhang. Margin based active learning. In COLT  2007.

[11] M.-F. Balcan  A. Beygelzimer  and J. Langford. Agnostic active learning. J. Comput. Syst. Sci.  75(1):

78–89  2009.

[12] Maria-Florina Balcan and Vitaly Feldman. Statistical active learning algorithms. In NIPS  pages 1295–1303 

2013.

[13] Maria-Florina Balcan and Hongyang Zhang. S-concave distributions: Towards broader distributions for

noise-tolerant and sample-efﬁcient learning algorithms. arXiv preprint arXiv:1703.07758  2017.

[14] Maria-Florina Balcan  Steve Hanneke  and Jennifer Wortman Vaughan. The true sample complexity of

active learning. Machine learning  80(2-3):111–139  2010.

9

[15] A. Beygelzimer  D. Hsu  J. Langford  and T. Zhang. Agnostic active learning without constraints. In NIPS 

2010.

[16] Alina Beygelzimer  Sanjoy Dasgupta  and John Langford.

Importance weighted active learning.

Twenty-Sixth International Conference on Machine Learning  2009.

In

[17] Avrim Blum  Alan M. Frieze  Ravi Kannan  and Santosh Vempala. A polynomial-time algorithm for

learning noisy linear threshold functions. Algorithmica  22(1/2):35–52  1998.

[18] Nicolo Cesa-Bianchi and Gábor Lugosi. Prediction  learning  and games. Cambridge university press 

2006.

[19] Nicolò Cesa-Bianchi  Claudio Gentile  and erancesco Orabona. Robust bounds for classiﬁcation via
selective sampling. In Proceedings of the 26th Annual International Conference on Machine Learning 
ICML 2009  Montreal  Quebec  Canada  June 14-18  2009  pages 121–128  2009.

[20] Lin Chen  Hamed Hassani  and Amin Karbasi. Near-optimal active learning of halfspaces via query

synthesis in the noisy setting. In Thirty-First AAAI Conference on Artiﬁcial Intelligence  2017.

[21] David A. Cohn  Les E. Atlas  and Richard E. Ladner. Improving generalization with active learning.

Machine Learning  15(2):201–221  1994.

[22] Nello Cristianini and John Shawe-Taylor. An introduction to support vector machines and other kernel-

based learning methods. 2000.

[23] Amit Daniely. Complexity theoretic limitations on learning halfspaces. arXiv preprint arXiv:1505.05800 

2015.

[24] S. Dasgupta. Coarse sample complexity bounds for active learning. In NIPS  2005.

[25] Sanjoy Dasgupta. Two faces of active learning. Theoretical computer science  412(19):1767–1781  2011.

[26] Sanjoy Dasgupta  Adam Tauman Kalai  and Claire Monteleoni. Analysis of perceptron-based active
learning. In Learning Theory  18th Annual Conference on Learning Theory  COLT 2005  Bertinoro  Italy 
June 27-30  2005  Proceedings  pages 249–263  2005.

[27] Sanjoy Dasgupta  Daniel Hsu  and Claire Monteleoni. A general agnostic active learning algorithm. In

Advances in Neural Information Processing Systems 20  2007.

[28] Ofer Dekel  Claudio Gentile  and Karthik Sridharan. Selective sampling and active learning from single

and multiple teachers. Journal of Machine Learning Research  13(Sep):2655–2697  2012.

[29] John Dunagan and Santosh Vempala. A simple polynomial-time rescaling algorithm for solving linear
programs. In Proceedings of the thirty-sixth annual ACM symposium on Theory of computing  pages
315–320. ACM  2004.

[30] Vitaly Feldman  Parikshit Gopalan  Subhash Khot  and Ashok Kumar Ponnuswami. New results for
learning noisy parities and halfspaces. In Foundations of Computer Science  2006. FOCS’06. 47th Annual
IEEE Symposium on  pages 563–574. IEEE  2006.

[31] Y. Freund  H. S. Seung  E. Shamir  and N. Tishby. Selective sampling using the query by committee

algorithm. Machine Learning  28(2-3):133–168  1997.

[32] Andrew Guillory  Erick Chastain  and Jeff Bilmes. Active learning as non-convex optimization.

International Conference on Artiﬁcial Intelligence and Statistics  pages 201–208  2009.

In

[33] Venkatesan Guruswami and Prasad Raghavendra. Hardness of learning halfspaces with noise. SIAM

Journal on Computing  39(2):742–765  2009.

[34] S. Hanneke. A bound on the label complexity of agnostic active learning. In ICML  2007.

[35] S. Hanneke. Theoretical Foundations of Active Learning. PhD thesis  Carnegie Mellon University  2009.

[36] Steve Hanneke. Rates of convergence in active learning. The Annals of Statistics  39(1):333–361  2011.
[37] Steve Hanneke. Theory of disagreement-based active learning. Foundations and Trends R� in Machine

Learning  7(2-3):131–309  2014.

[38] Steve Hanneke and Liu Yang. Surrogate losses in passive and active learning.

arXiv:1207.3772  2012.

arXiv preprint

10

[39] Steve Hanneke  Varun Kanade  and Liu Yang. Learning with a drifting target concept. In International

Conference on Algorithmic Learning Theory  pages 149–164. Springer  2015.

[40] D. Hsu. Algorithms for Active Learning. PhD thesis  UC San Diego  2010.

[41] Tzu-Kuo Huang  Alekh Agarwal  Daniel Hsu  John Langford  and Robert E. Schapire. Efﬁcient and

parsimonious agnostic active learning. CoRR  abs/1506.08669  2015.

[42] Adam Tauman Kalai  Adam R Klivans  Yishay Mansour  and Rocco A Servedio. Agnostically learning

halfspaces. SIAM Journal on Computing  37(6):1777–1805  2008.

[43] Michael Kearns and Ming Li. Learning in the presence of malicious errors. SIAM Journal on Computing 

22(4):807–837  1993.

[44] Adam Klivans and Pravesh Kothari. Embedding Hard Learning Problems Into Gaussian Space.

APPROX/RANDOM 2014  pages 793–809  2014.

In

[45] Adam R Klivans  Philip M Long  and Rocco A Servedio. Learning halfspaces with malicious noise.

Journal of Machine Learning Research  10(Dec):2715–2740  2009.

[46] V. Koltchinskii. Rademacher complexities and bounding the excess risk in active learning. JMLR  2010.

[47] Sanjeev R Kulkarni  Sanjoy K Mitter  and John N Tsitsiklis. Active learning using arbitrary binary valued

queries. Machine Learning  11(1):23–35  1993.

[48] Philip M Long. On the sample complexity of pac learning half-spaces against the uniform distribution.

IEEE Transactions on Neural Networks  6(6):1556–1559  1995.

[49] Pascal Massart and Élodie Nédélec. Risk bounds for statistical learning. The Annals of Statistics  pages

2326–2366  2006.

[50] Claire Monteleoni. Efﬁcient algorithms for general active learning.

Computational Learning Theory  pages 650–652. Springer  2006.

In International Conference on

[51] TS Motzkin and IJ Schoenberg. The relaxation method for linear inequalities. Canadian Journal of

Mathematics  6(3):393–404  1954.

[52] Francesco Orabona and Nicolo Cesa-Bianchi. Better algorithms for selective sampling. In Proceedings of

the 28th international conference on Machine learning (ICML-11)  pages 433–440  2011.

[53] Maxim Raginsky and Alexander Rakhlin. Lower bounds for passive and active learning. In Advances in

Neural Information Processing Systems  pages 1026–1034  2011.

[54] Burr Settles. Active learning literature survey. University of Wisconsin  Madison  52(55-66):11  2010.

[55] Simon Tong and Daphne Koller. Support vector machine active learning with applications to text classiﬁ-

cation. Journal of machine learning research  2(Nov):45–66  2001.

[56] Christopher Tosh and Sanjoy Dasgupta. Diameter-based active learning. In ICML  pages 3444–3452  2017.

[57] Vladimir N. Vapnik and Alexey Ya. Chervonenkis. On the uniform convergence of relative frequencies of

events to their probabilities. Theory of Probability and Its Applications  16(2):264–280  1971.

[58] Liwei Wang. Smoothness  disagreement coefﬁcient  and the label complexity of agnostic active learning.

Journal of Machine Learning Research  12(Jul):2269–2292  2011.

[59] Yining Wang and Aarti Singh. Noise-adaptive margin-based active learning and lower bounds under

tsybakov noise condition. In AAAI  2016.

[60] Chicheng Zhang and Kamalika Chaudhuri. Beyond disagreement-based agnostic active learning. In
Advances in Neural Information Processing Systems 27: Annual Conference on Neural Information
Processing Systems 2014  December 8-13 2014  Montreal  Quebec  Canada  pages 442–450  2014.

[61] Yuchen Zhang  Percy Liang  and Moses Charikar. A hitting time analysis of stochastic gradient langevin

dynamics. In COLT  pages 1980–2022  2017.

11

,Maximilian Nickel
Xueyan Jiang
Volker Tresp
Chen Huang
Chen Change Loy
Xiaoou Tang
Songbai Yan
Chicheng Zhang