2010,Probabilistic Multi-Task Feature Selection,Recently  some variants of the $l_1$ norm  particularly matrix norms such as the $l_{1 2}$ and $l_{1 \infty}$ norms  have been widely used in multi-task learning  compressed sensing and other related areas to enforce sparsity via joint regularization. In this paper  we unify the $l_{1 2}$ and $l_{1 \infty}$ norms by considering a family of $l_{1 q}$ norms for $1 < q\le\infty$ and study the problem of determining the most appropriate sparsity enforcing norm to use in the context of multi-task feature selection. Using the generalized normal distribution  we provide a probabilistic interpretation of the general multi-task feature selection problem using the $l_{1 q}$ norm. Based on this probabilistic interpretation  we develop a probabilistic model using the noninformative Jeffreys prior. We also extend the model to learn and exploit more general types of pairwise relationships between tasks. For both versions of the model  we devise expectation-maximization~(EM) algorithms to learn all model parameters  including $q$  automatically. Experiments have been conducted on two cancer classification applications using microarray gene expression data.,Probabilistic Multi-Task Feature Selection

Department of Computer Science and Engineering  Bioengineering Program

Yu Zhang  Dit-Yan Yeung  Qian Xu 

Hong Kong University of Science and Technology

zhangyu dyyeung@cse.ust.hk  fleurxq@ust.hk

Abstract

Recently  some variants of the  norm  particularly matrix norms such as the  
and Ý norms  have been widely used in multi-task learning  compressed sens-
ing and other related areas to enforce sparsity via joint regularization.
In this
paper  we unify the  and Ý norms by considering a family of  norms for
   ࣘ Ý and study the problem of determining the most appropriate sparsity
enforcing norm to use in the context of multi-task feature selection. Using the
generalized normal distribution  we provide a probabilistic interpretation of the
general multi-task feature selection problem using the  norm. Based on this
probabilistic interpretation  we develop a probabilistic model using the noninfor-
mative Jeffreys prior. We also extend the model to learn and exploit more general
types of pairwise relationships between tasks. For both versions of the model 
we devise expectation-maximization (EM) algorithms to learn all model parame-
ters  including   automatically. Experiments have been conducted on two cancer
classiﬁcation applications using microarray gene expression data.

1

Introduction

Learning algorithms based on  regularization have a long history in machine learning and statistics.
A well-known property of  regularization is its ability to enforce sparsity in the solutions. Recently 
some variants of the  norm  particularly matrix norms such as the  and Ý norms  were
proposed to enforce sparsity via joint regularization [24  17  28  1  2  15  20  16  18]. The  norm
is the sum of the  norms of the rows and the Ý norm is the sum of the Ý norms of the rows.
Regularizers based on these two matrix norms encourage row sparsity  i.e.  they encourage entire
rows of the matrix to have zero elements. Moreover  these norms have also been used for enforcing
group sparsity among features in conventional classiﬁcation and regression problems  e.g.  group
LASSO [29]. Recently  they have been widely used in multi-task learning  compressed sensing and
other related areas. However  when given a speciﬁc application  we often have no idea which norm
is the most appropriate choice to use.
In this paper  we study the problem of determining the most appropriate sparsity enforcing norm
to use in the context of multi-task feature selection [17  15].
Instead of choosing between spe-
ciﬁc choices such as the  and Ý norms  we consider a family of  norms. We restrict 
to the range    ࣘ Ý to ensure that all norms in this family are convex  making it easier to
solve the optimization problem formulated based on it. Within this family  the  and Ý norms
are just two special cases. Using the  norm  we formulate the general multi-task feature se-
lection problem and give it a probabilistic interpretation. It is noted that the automatic relevance
determination (ARD) prior [9  3  26] comes as a special case under this interpretation. Based on
this probabilistic interpretation  we develop a probabilistic formulation using a noninformative prior
called the Jeffreys prior [10]. We devise an expectation-maximization (EM) algorithm [8] to learn
all model parameters  including   automatically. Moreover  an underlying assumption of existing
multi-task feature selection methods is that all tasks are similar to each other and they share the
same features. This assumption may not be correct in practice because there may exist outlier tasks

1

or tasks with negative correlation. As another contribution of this paper  we propose to use a matrix
variate generalized normal prior [13] for the model parameters to learn the relationships between
tasks. The task relationships learned here can be seen as an extension of the task covariance used
in [4  32  31]. Experiments will be reported on two cancer classiﬁcation applications using microar-
ray gene expression data.

2 Multi-Task Feature Selection
. For the th task   the training set  consists
Suppose we are given  learning tasks 
 ࢠ Ó and
of  labeled data points in the form of ordered pairs N
 ࢠ ࢤ  if it is a binary
its corresponding output 
 N  . For applications
classiﬁcation problem. The linear function for  is deﬁned as N  M
that need feature selection  e.g.  document classiﬁcation  the feature dimensionality is usually very
high and it has been found that linear methods usually perform better.
The objective functions of most existing multi-task feature selection methods [24  17  28  1  2  15 
20  16  18] can be expressed in the following form:

 ࢠ Ó if it is a regression problem and 

           with N

 

ࢣ

ࢣ



 M

 N

    9

(1)





where 9  M     M   denotes the loss function (e.g.  squared loss for regression and
hinge loss for classiﬁcation)   is the regularization function that enforces feature sparsity un-
der the multi-task setting  and  is the regularization parameter controlling the relative contribution
of the empirical loss and the regularizer. Multi-task feature selection seeks to minimize the ob-
jective function above to obtain the optimal parameters M . Two regularization functions are
widely used in existing multi-task feature selection methods. One of them is based on the  norm
 ࢱMࢱ where ࢱࢱ denotes the -norm (or  norm) of a
vector and M denotes the th row of 9. Another one is based on the Ý norm of 9 [24  15  20]:

of 9 [17  28  1  2  16  18]: 9 ࢣ
9 ࢣ

 ࢱMࢱÝ.

In this paper  we unify these two cases by using the  norm of 9 to deﬁne a more general
regularization function:

ࢣ

9 

ࢱMࢱ

   ࣘ Ý



Note that when     9 is non-convex with respect to 9. Although 9 is convex when
    each element of 9 is independent of each other and so the regularization function cannot
enforce feature sparsity. Thus we restrict the range to    ࣘ Ý.
Even though restricting the range to    ࣘ Ý can enforce feature sparsity between different tasks 
different values of  imply different ‘group discounts’ for sharing the same feature. Speciﬁcally 
when  approaches 1  the cost grows almost linearly with the number of tasks that use a feature  and
when   Ý  only the most demanding task matters. So selecting a proper  can potentially have a
signiﬁcant effect on the performance of the learning algorithms.
In the following  we ﬁrst give a probabilistic interpretation for multi-task feature selection methods.
Based on this probabilistic interpretation  we then develop a probabilistic model which  among other
things  can solve the model selection problem automatically by estimating  from data.

3 Probabilistic Interpretation

In this section  we will show that existing multi-task feature selection methods are related to the
maximum a posteriori (MAP) solution of a probabilistic model. This probabilistic interpretation
sets the stage for introducing our probabilistic model in the next section.
We ﬁrst introduce the generalized normal distribution [11] which is useful for the model to be intro-
duced.

2

Deﬁnition 1  is a univariate generalized normal random variable iff its probability density func-
tion (p.d.f.) is given as follows:

 



 Ɖ  
 

ANF

 ࢤ ࢯ ࢤ ࢯ







where Ɖ denotes the Gamma function and ࢯ  ࢯ denotes the absolute value of a scalar.
For simplicity  if  is a univariate generalized normal random variable  we write  ß    .
The (ordinary) normal distribution can be viewed as a special case of the generalized normal distribu-
tion when   and the Laplace distribution is a special case when   . When  approaches Ý 
the generalized normal distribution approaches the uniform distribution in the range  ࢤ    .
The generalized normal distribution has proven useful in Bayesian analysis and robustness studies.
Deﬁnition 2 A standardized    multivariate generalized normal random variable  
      consists of  independent and identically distributed (i.i.d.) univariate generalized
normal random variables.
If  is a standardized    multivariate generalized normal random variable  we write  ß
ࡕ    with the following p.d.f.:


ࢣ
 ࢯ ࢤ ࢯ



 

 Ɖ  

  ANF

 ࢤ





With these deﬁnitions  we now begin to present our probabilistic interpretation for multi-task feature
selection by proposing a probabilistic model. For notational simplicity  we assume that all tasks
perform regression. Extension to include classiﬁcation tasks will go through similar derivation.
For a regression problem  we use the normal distribution to deﬁne the likelihood for N
:

where     denotes the (univariate) normal distribution with mean  and variance  .
We impose the generalized normal prior on each element of 9:

 ß  M


 N

    

(2)

(3)
where  is the  th element of 9 (or  equivalently  the th element of M or the th element
of M). Then we can express the prior on M as

 ß    

M ß ࡕ   

When     this becomes the ARD prior [9  3  26] commonly used in Bayesian methods for
enforcing sparsity. From this view  the generalized normal prior can be viewed as a generalization
of the ARD prior.
With the above likelihood and prior  we can obtain the MAP solution of 9 by solving the following
problem:

ࢣ

ࢣ





E
9>

 


 

ࢣ

ࢱMࢱ












 M

 N

   

   



(4)

where >        and         .
We set the derivative of  with respect to  to zero and get

 ࢱMࢱ

 



 

ࢣ

ࢣ

ࢣ

Plugging this into problem (4)  the optimization problem can be reformulated as

E
9>

 


 



 M

 N

    

ࢱMࢱ

(5)







Note that problem (5) is non-convex since the second term is non-convex with respect to 9. Be-
cause   ࣘ  ࢤ  for any     problem (5) can be relaxed to problem (1) by setting    .

3

So the solutions of multi-task feature selection methods can be viewed as the solution of the relaxed
optimization problem above. In many previous works such as [5  27]   can be used as an ap-
proximation of  ࢧ  where  is an indicator function. Using this view  we can regard the
second term in problem (5) as an approximation of the number of rows with nonzero -norms.
Note that we can directly solve problem (5) using a majorization-minimization (MM) algorithm [14].
For numerical stability  we can slightly modify the objective function in problem (5) by replacing
 ࢱMࢱ  where  can be regarded as a regularization parameter.
. In the   th iteration  due to the

the second term with ࢣ

We denote the solution obtained in the th iteration as M

concavity property of   we can bound the second term in problem (5) as follows



ࢣ



ࢱMࢱ   ࣘ ࢣ
ࢣ

ࢣ



E
9>


 

ࢱM

ࢱ   

ࢱMࢱ ࢤ ࢱM
ࢱ
ࢱ  

ࢱM





 M

 N

    







ࢣ

ࢱMࢱ
ࢱ  

ࢱM



Thus  in the   th iteration  we need to solve a weighted version of problem (1):

According to [14]  the MM algorithm is guaranteed to converge to a local optimum.

4 A Probabilistic Framework for Multi-Task Feature Selection
In the probabilistic interpretation above  we use a type II method to estimate  in the generalized
normal prior which can be viewed as a generalization of the ARD prior. In the ARD prior  according
to [19]  this approach is likely to lead to overﬁtting because the hyperparameters in the ARD prior
are treated as points. Similar to the ARD prior  the model in the above section may overﬁt since 
are estimated via point estimation. In the following  we will present our probabilistic framework for
multi-task feature selection by imposing priors on the hyperparameters.

4.1 The Model

As in the above section  the likelihood for N

 is also deﬁned based on the normal distribution:

 ß  M


(6)
Here we use different noise variances  for different tasks to make our model more ﬂexible. The
prior on 9 is also deﬁned similarly:

    

 N

 

(7)
The main difference here is that we treat  as a random variable with the noninformative Jeffreys
prior:

 ß    

 ÝÝ 

Ý



 ࢚  Mࢯ

  Ý 

(8)
where  denotes the Fisher information for  and  denotes the expectation with respect
to . One advantage of using the Jeffreys prior is that the distribution has no hyperparameters.

Mࢯ

࢚





4.2 Parameter Learning and Inference

Here we use the EM algorithm [8] to learn the model parameters. In our model  we denote Ǝ 
9 >  as the model parameters and         as the hidden variables.
In the E-step  we construct the so-called -function as the surrogate for the log-likelihood:

Þ

ƎࢯƎ 

 ƎࢯO ࢯO Ǝ

where Ǝ denotes the estimate of Ǝ in the th iteration and O  
show that

     


 . It is easy to

 ƎࢯO  Ý  Oࢯ9   9ࢯ
 ࢤ  

Ý ࢤ ࢣ

 ࢤ M
 N

  






 ࢣ



ࢤ ࢣ

ࢣ









ࢯࢯ ࢤ   Ɖ 








   


 

4

M


and ࢯO Ǝ ÝÜ
(cid:12)(cid:12)O Ǝ
 
 ࢣ
ƎࢯƎ  ࢤ ࢣ

So we can get







Þ Ý
ࢯ
Þ Ý





 ࢤ M
 N

  


 ࢤ  

   








. We then compute  


M
 M








ࢱM
ࢱ





ࢯO Ǝ as

ࢯ
ࢯ


ࢤ ࢣ

 

ࢣ







ࢯࢯ ࢤ   Ɖ 






.

ࢱ


ࢱM

where  
In the M-step  we maximize ƎࢯƎ to update the estimates of 9  >   and .
For the estimation of 9  we need to solve  convex optimization problems



  ࢱO ࢤ :

 Mࢱ 

 

E
M

ࢯࢯ

       

(9)

 ࢤ 

ࢤ 



     


 . When    
where O  
this becomes the conventional ridge regression problem. Here  is related to the sparsity of the
th row in 9: the more sparse the th row in 9  the larger the . When  is large  
will be enforced to approach 0. We use a gradient method such as conjugate gradient to optimize
problem (9). The subgradient with respect to M is

   :  N

  and  

     N


 







::

࢚
࢚M

 

 M ࢤ :O

  

where   ࢯࢯࢤsign     ࢯࢯࢤsign and sign denotes the sign func-
tion.
We set the derivatives of ƎࢯƎ with respect to  and  to 0 and get
 

 ࢤ M





 N


















 ࢤ M




 N

 ࢤ 





ࢣ




ࢣ
(cid:118)(cid:117)(cid:117) 

ࢣ
ࢣ
(cid:12)(cid:12)







For the estimation of   we also use a gradient method. The gradient can be calculated as

 ࢤ ࢣ



࢚
࢚

(cid:12)(cid:12) (cid:12)(cid:12)



(cid:12)(cid:12) 







 






where  ࣕ ࢚  Ɖ

࢚








ࢧ

is the digamma function.

4.3 Extension to Deal with Outlier Tasks and Tasks with Negative Correlation

An underlying assumption of multi-task feature selection using the  norm is that all tasks are
similar to each other and they share the same features. This assumption may not be correct in
practice because there may exist outlier tasks (i.e.  tasks that are not related to all other tasks) or
tasks with negative correlation (i.e.  tasks that are negatively correlated with some other tasks). In
this section  we will discuss how to extend our probabilistic model to deal with these tasks.
We ﬁrst introduce the matrix variate generalized normal distribution [13] which is a generalization
of the generalized normal distribution to random matrices.
Deﬁnition 3 A matrix  ࢠ Ó is a matrix variate generalized normal random variable iff its p.d.f.
is given as follows:
ࢯ    
ࢤ
where  ࢠ Ó and  ࢠ Ó are nonsingular  det denotes the determinant of a square matrix 
 is the  th element of matrix ) and ࢤ is the  th element of the matrix inverse )ࢤ.

 detdet

 Ɖ  

ࢤ ࢤ 

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) ࢣ

ࢤ ࢣ

ࢣ

ࢣ



ANF













(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)



5

We write  ß ࡕ     for a matrix variate generalized normal random variable .
When     the matrix variate generalized normal distribution becomes the (ordinary) matrix
variate normal distribution [12] with row covariance matrix  and column covariance matrix
   which has been used before in multi-task learning [4  32  31]. From this view   is used
to model the relationships between the rows of  and  is to model the relationships between the
columns.
We note that the prior on 9 in Eq. (7) can be written as

9 ß ࡕ  diag      1 

where  denotes a zero vector or matrix of proper size  1 denotes the    identity matrix and
diag converts a vector into a diagonal matrix. In this formulation  it can be seen that the columns
of 9 (and hence the tasks) are independent of each other. However  the tasks are in general not
independent. So we propose to use a new prior on 9:

9 ß ࡕ  diag       

(10)

where  models the pairwise relationships between tasks.
The likelihood is still based on the normal distribution. Since in practice the relationships between
tasks are not known in advance  we also need to estimate  from data.
For parameter learning  we again use the EM algorithm to learn the model parameters. Here the
model parameters are denoted as Ǝ  9 >  . It is easy to show that

 ƎࢯO  Ý ࢤ ࢣ

 ࢣ





 ࢤ M
 N

  


 ࢤ  



   


 

 ࢤ ࢣ

ࢣ

(cid:12)(cid:12)(cid:12) ࢣ











(cid:12)(cid:12)(cid:12)



ࢤ

 ࢤ   det

Then we compute  



ࢤ   Ɖ 


Þ Ý
ࢯO Ǝ as
(cid:12)(cid:12)O Ǝ
 
Þ Ý
 ࢣ
ƎࢯƎ  ࢤ ࢣ

M
 M












In the E-step  the -function can be formulated as
 ࢤ  

ࢯ
ࢯ

 ࢤ M
 N

  






ࢣ





   




 



  



(cid:12)(cid:12)ࢣ
 ࢤ ࢣ







ࢤ
(cid:12)(cid:12)(cid:12) ࢣ
ࢣ











(cid:12)(cid:12) ࣕ 
(cid:12)(cid:12)(cid:12)

ࢤ



ࢤ   Ɖ 

 ࢤ   det




In the M-step  for 9 and   the optimization problem becomes

E
9

ࢣ





 



ࢣ

ࢣ

 ࢤ M


ࢣ


 . We deﬁne a new variable 9  9ࢤ to rewrite the above problem as
ࢣ

(cid:12)(cid:12)(cid:12) ࢣ
ࢣ

   det

ࢣ

ࢣ

ࢤ

(cid:12)(cid:12)(cid:12)



 N

 













 ࢤ A


  9 N

 

ࢯ ࢯ    det








 

E
9

where 

 









where A denotes the th column of the    identity matrix. We use an alternating method to
solve this problem. For a ﬁxed   the problem with respect to 9 is a convex problem and we use
conjugate gradient to solve it with the following subgradient

N
N

 9AA

  ࢤ 

N

A

 

 


ࢣ

ࢣ



࢚
࢚ 9

 








ࢣ

ࢣ

 9 N

࢚
࢚

 








where  is a    matrix with the  th element 
also use conjugate gradient with the following gradient



ࢯ ࢯࢤsign . For a ﬁxed 9  we

N

 9AA

 ࢤ 



9 N

A


  

ࢤ

After obtaining the optimal 9ਭ and ਭ  we can compute the optimal 9ਭ as 9ਭ  9ਭਭ. The
update rules for    and  are similar to those in the above section.

6

5 Related Work

Some probabilistic multi-task feature selection methods have been proposed before [28  2]. How-
ever  they only focus on the  norm. Moreover  they use point estimation in the ARD prior and
hence  as discussed in Section 3  are susceptible to overﬁtting [19].
Zhang et al. [30] proposed a latent variable model for multi-task learning by using the Laplace prior
to enforce sparsity. This is equivalent to using the  norm in our framework which  as discussed
above  cannot enforce group sparsity among different features over all tasks.

6 Experiments

In this section  we study our methods empirically on two cancer classiﬁcation applications using
microarray gene expression data. We compare our methods with three related methods: multi-task
feature learning (MTFL) [1]1  multi-task feature selection using  regularization [16]2  and multi-
task feature selection using Ý regularization [20]3.

6.1 Breast Cancer Classiﬁcation

We ﬁrst conduct empirical study on a breast cancer classiﬁcation application. This application con-
sists of three learning tasks with data collected under different platforms [21]. The dataset for the
ﬁrst task  collected at the Koo Foundation Sun Yat-Sen Cancer Centre in Taipei  contains 89 sam-
ples with 8948 genes per sample. The dataset for the second task  obtained from the Netherlands
Cancer Institute  contains 97 samples with 16360 genes per sample. Most of the patients in this
dataset had stage I or II breast cancer. The dataset for the third task  obtained using 22K Agilent
oligonucleotide arrays  contains 114 samples with 12065 genes per sample. Even though these three
datasets were collected under different platforms  they share 6092 common genes which are used in
our experiments.
Here we abbreviate the method in Section 4.2 as PMTFS1 and that in Section 4.3 as PMTFS2. For
each task  we choose 70% of the data for training and the rest for testing. We perform 10 random
splits of the data and report the mean and standard derivation of the classiﬁcation error over the
10 trials. The results are summarized in Table 1. It is clear that PMTFS1 outperforms the three
previous methods  showing the effectiveness of our more general formulation with  determined
automatically. Moreover  we also note that PMTFS2 is better than PMTFS1. This veriﬁes the
usefulness of exploiting the relationships between tasks in multi-task feature selection. Since our
methods can estimate  automatically  we compute the mean of the estimated  values over 10 trials.
The means for PMTFS1 and PMTFS2 are 2.5003 and 2.6718  respectively  which seem to imply that
smaller values of  are preferred for this application. This probably explains why the performance
of MTFSÝ is not good when compared with other methods.
Table 1: Comparison of different methods on the breast cancer classiﬁcation application in terms of
classiﬁcation error rate (in meanstd-dev). Each column in the table represents one task.

1st Task

Method
0.34780.1108
MTFL
0.33700.0228
MTFS 
MTFSÝ 0.38960.0583
0.30720.0234
PMTFS1
0.28700.0228
PMTFS2

2nd Task

0.03640.0345
0.03430.0134
0.11360.0579
0.02980.0121
0.02730.0102

3rd Task

0.30910.0498
0.28550.0337
0.29090.0761
0.17860.0245
0.14550.0263

6.2 Prostate Cancer Classiﬁcation

We next study a prostate cancer classiﬁcation application consisting of two tasks. The Singh
dataset [22] for the ﬁrst task is made up of laser intensity images from each microarray. The RMA
preprocessing method was used to produce gene expression values from these images. On the other

1http://ttic.uchicago.edu/ßargyriou/code/index.html
2http://www.public.asu.edu/ßjye02/Software/SLEP/index.htm
3http://www.lsi.upc.edu/ßaquattoni/

7

hand  the Welsh dataset [25] for the second task is already in the form of gene expression values.
Even though the collection techniques for the two datasets are different  they have 12600 genes in
common and are used in our experiments.
The experimental setup for this application is similar to that in the previous subsection  that is  70%
of the data of each task are used for training and the rest for testing  and 10 random splits of the data
are performed. We report the mean and standard derivation of the classiﬁcation error over the 10
trials in Table 2. As in the ﬁrst set of experiments  PMTFS1 and PMTFS2 are better than the other
three methods compared and PMTFS2 slightly outperforms PMTFS1. The means of the estimated
 values for PMTFS1 and PMTFS2 are 2.5865 and 2.6319  respectively. So it seems that smaller
values are also preferred for this application.
Table 2: Comparison of different methods on the prostate cancer classiﬁcation application in terms
of classiﬁcation error rate (in meanstd-dev). Each column in the table represents one task.

1st Task

Method
0.12260.0620
MTFL
0.12320.0270
MTFS 
MTFSÝ 0.22160.1667
0.11230.0170
PMTFS1
0.10320.0136
PMTFS2

2nd Task

0.35000.0085
0.34200.0067
0.42000.1304
0.32140.0053
0.30000.0059

7 Concluding Remarks

In this paper  we have proposed a probabilistic framework for general multi-task feature selection
using the  norm (   ࣘ Ý). Our model allows the optimal value of  to be determined
from data automatically. Besides considering the case in which all tasks are similar  we have also
considered the more general and challenging case in which there also exist outlier tasks or tasks with
negative correlation.
Compressed sensing aims at recovering the sparse signal M from a measurement vector >  )M for
a given matrix ). Compressed sensing can be extended to the multiple measurement vector (MMV)
model in which the signals are represented as a set of jointly sparse vectors sharing a common set
of nonzero elements [7  6  23]. Speciﬁcally  joint compressed sensing considers the reconstruction
of the signal represented by a matrix 9  which is given by a dictionary (or measurement matrix) )
and multiple measurement vector * such that *  )9. Similar to multi-task feature selection 
we can use ࢱ9ࢱ to enforce the joint sparsity in 9. Since there usually exists noise in the data 
the optimization problem of MMV can be formulated as: E9 ࢱ9ࢱ  ࢱ)9 ࢤ *ࢱ 
 . This
problem is almost identical to problem (1) except that the loss deﬁnes the reconstruction error rather
than the prediction error. So we can use the probabilistic model presented in Section 4 to develop
a probabilistic model for joint compressed sensing. Besides  we are also interested in developing a
full Bayesian version of our model to further exploit the advantages of Bayesian modeling.

Acknowledgment

This research has been supported by General Research Fund 622209 from the Research Grants
Council of Hong Kong.

References
[1] A. Argyriou  T. Evgeniou  and M. Pontil. Convex multi-task feature learning. Machine Learning 

73(3):243–272  2008.

[2] J. Bi  T. Xiong  S. Yu  M. Dundar  and R. B. Rao. An improved multi-task learning approach with

applications in medical diagnosis. In ECMLPKDD  2008.

[3] C. M. Bishop. Pattern Recognition and Machine Learning. Springer  New York  2006.
[4] E. Bonilla  K. M. A. Chai  and C. Williams. Multi-task Gaussian process prediction. In NIPS 20  2008.
[5] E. J. Cand`es  M. B. Wakin  and S. P. Boyd. Enhancing sparsity by reweighted  minimization. Journal

of Fourier Analysis and Applications  14(5):877–905  2008.

8

[6] J. Chen and X. Huo. Theoretical results on sparse representations of multiple-measurement vectors. IEEE

Transactions on Signal Processing  54(12):4634–4643  2006.

[7] S. F. Cotter  B. D. Rao  K. Engan  and K. Kreutz-Delgado. Sparse solutions to linear inverse problems

with multiple measurement vectors. IEEE Transactions on Signal Processing  53(7):2477–2488  2005.

[8] A. P. Dempster  N. M. Laird  and D. B. Rubin. Maximum likelihood from incomplete data via the EM

algorithm. Journal of the Royal Statistic Society  B  39(1):1–38  1977.

[9] M. A. T. Figueiredo. Adaptive sparseness for supervised learning. IEEE Transactions on Pattern Analysis

and Machine Intelligence  25(9):1150–1159  2003.

[10] A. Gelman  J. B. Carlin  H. S. Stern  and D. B. Rubin. Bayesian Data Analysis. Chapman & Hall  2nd

edition  2003.

[11] I. R. Goodman and S. Kotz. Multivariate -generalized normal distributions. Journal of Multivariate

Analysis  3(2):204–219  1973.

[12] A. K. Gupta and D. K. Nagar. Matrix Variate Distributions. Chapman & Hall  2000.
[13] A. K. Gupta and T. Varga. Matrix variate -generalized normal distribution. Transactions of The American

Mathematical Society  347(4):1429–1437  1995.

[14] K. Lange  D. R. Hunter  and I. Yang. Optimization transfer using surrogate objective functions. Journal

of Computational and Graphical Statistics  9(1):1–59  2000.

[15] H. Liu  M. Palatucci  and J. Zhang. Blockwise coordinate descent procedures for the multi-task lasso 

with applications to neural semantic basis discovery. In ICML  2009.

[16] J. Liu  S. Ji  and J. Ye. Multi-task feature learning via efﬁcient  -norm minimization. In UAI  2009.
[17] G. Obozinski  B. Taskar  and M. Jordan. Multi-task feature selection. Technical report  Department of

Statistics  University of California  Berkeley  June 2006.

[18] G. Obozinski1  B. Taskar  and M. I. Jordan. Joint covariate selection and joint subspace selection for

multiple classiﬁcation problems. Statistics and Computing  20(2):231–252  2010.

[19] Y. Qi  T. P. Minka  R. W. Picard  and Z. Ghahramani. Predictive automatic relevance determination by

expectation propagation. In ICML  2004.

[20] A. Quattoni  X. Carreras  M. Collins  and T. Darrell. An efﬁcient projection for Ý regularization. In

ICML  2009.

[21] A. A. Shabalin  H. Tjelmeland  C. Fan  C. M. Perou  and A. B. Nobel. Merging two gene-expression

studies via cross-platform normalization. Bioinformatics  24(9):1154–1160  2008.

[22] D. Singh  P. G. Febbo  K. Ross  D. G. Jackson  J. Manola  C. Ladd  P. Tamayo  A. A. Renshaw  A. V.
DAmico  J. P. Richie  E. S. Lander  M. Loda  P. W. Kantoff  T. R. Golub  and W. R.Sellers. Gene
expression correlates of clinical prostate cancer behavior. Cancer Cell  1(2):203–209  2002.

[23] L. Sun  J. Liu  J. Chen  and J. Ye. Efﬁcient recovery of jointly sparse vectors. In NIPS 22. 2009.
[24] B. A. Turlach  W. N. Wenables  and S. J. Wright. Simultaneous variable selection. Technometrics 

47(3):349–363  2005.

[25] J. B. Welsh  L. M. Sapinoso  A. I. Su  S. G. Kern  J. Wang-Rodriguez  C. A. Moskaluk  F. H. Frierson 
Jr.  and G. M. Hampton. Analysis of gene expression identiﬁes candidate markers and pharmacological
targets in prostate cancer. Cancer Research  61(16):5974–5978  2001.

[26] D. Wipf and S. Nagarajan. A new view of automatic relevance determination. In NIPS 20  2007.
[27] D.P. Wipf and S. Nagarajan. Iterative reweighted  and  methods for ﬁnding sparse solutions. Journal

of Selected Topics in Signal Processing  2010.

[28] T. Xiong  J. Bi  B. Rao  and V. Cherkassky. Probabilistic joint feature selection for multi-task learning.

In SDM  2007.

[29] M. Yuan and Y. Lin. Model selection and estimation in regression with grouped variables. Journal of the

Royal Statistical Society  Series B  2006.

[30] J. Zhang  Z. Ghahramani  and Y. Yang. Flexible latent variable models for multi-task learning. Machine

Learning  73(3):221–242  2008.

[31] Y. Zhang and D.-Y. Yeung. A convex formulation for learning task relationships in multi-task learning.

In UAI  2010.

[32] Y. Zhang and D.-Y. Yeung. Multi-task learning using generalized  process. In AISTATS  2010.

9

,Brian McWilliams
David Balduzzi
Joachim Buhmann
Arthur Guez
Nicolas Heess
David Silver
Peter Dayan
Luca Bertinetto
João Henriques
Jack Valmadre
Philip Torr
Andrea Vedaldi