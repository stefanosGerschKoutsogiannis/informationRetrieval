2019,Facility Location Problem in Differential Privacy Model Revisited,In this paper we study the facility location problem in the model of differential privacy (DP) with uniform facility cost. Specifically  we first show that under the hierarchically well-separated tree (HST) metrics and the super-set output setting that was introduced in Gupta et. al.  there is an $\epsilon$-DP algorithm that achieves an $O(\frac{1}{\epsilon})$(expected multiplicative) approximation ratio; this implies an $O(\frac{\log n}{\epsilon})$ approximation ratio for the general metric case  where $n$ is the size of the input metric. These bounds improve the best-known results given by Gupta et. al.  In particular  our approximation ratio for HST-metrics is independent of $n$  and the ratio for general metrics is independent of the aspect ratio of the input metric. On the negative side  we show that the approximation ratio of any $\epsilon$-DP algorithm is lower bounded by $\Omega(\frac{1}{\sqrt{\epsilon}})$  even for instances on HST metrics with uniform facility cost  under the super-set output setting. The lower bound shows that the dependence of the approximation ratio for HST metrics on $\epsilon$ can not be removed or greatly improved. Our novel methods and techniques for both the upper and lower bound may find additional applications.,Facility Location Problem in Differential Privacy

Model Revisited

Yunus Esencayi ∗
SUNY at Buffalo

yunusese@buffalo.edu

Marco Gaboardi
Boston University

gaboardi@bu.edu

Shi Li

SUNY at Buffalo

shil@buffalo.edu

Di Wang

SUNY at Buffalo

dwang45@buffalo.edu

Abstract

In this paper we study the uncapacitated facility location problem in the model
of differential privacy (DP) with uniform facility cost. Speciﬁcally  we ﬁrst show
that  under the hierarchically well-separated tree (HST) metrics and the super-set
output setting that was introduced in [8]  there is an -DP algorithm that achieves
 ) (expected multiplicative) approximation ratio; this implies an O( log n
an O( 1
)
approximation ratio for the general metric case  where n is the size of the input
metric. These bounds improve the best-known results given by [8]. In particular 
our approximation ratio for HST-metrics is independent of n  and the ratio for
general metrics is independent of the aspect ratio of the input metric.
On the negative side  we show that the approximation ratio of any -DP algorithm
is lower bounded by Ω( 1√
 )  even for instances on HST metrics with uniform
facility cost  under the super-set output setting. The lower bound shows that the
dependence of the approximation ratio for HST metrics on  can not be removed or
greatly improved. Our novel methods and techniques for both the upper and lower
bound may ﬁnd additional applications.



Introduction

1
The facility location problem is one of the most fundamental problems in combinatorial optimization
and has a wide range of applications such as plant or warehouse location problems and network design
problems  also it is closely related to clustering problems such as k-median  where one typically
seeks to partition a set of data points  which themselves ﬁnd applications in data mining  machine
learning  and bioinformatics [1  13  4]. Due to its versatility  the problem has been studied by both
operations research and computer science communities [20  19  16  15  1  13  4]. Formally  it can be
deﬁned as following.
Deﬁnition 1 (Uniform Facility Location Problem (Uniform-FL)). The input to the Uniform Facility
Location (Uniform-FL) problem is a tuple (V  d  f  (cid:126)N )  where (V  d) is a n-point discrete metric 
f ∈ R≥0 is the facility cost  and (cid:126)N = (Nv)v∈V ∈ ZV≥0 gives the number of clients in each location
v ∈ V . The goal of the problem is to ﬁnd a set of facility locations S ⊆ V which minimize the
following  where d(v  S) = mins∈S d(v  s) 

(cid:88)

v∈V

costd(S; (cid:126)N ) := |S| · f +

min
S⊆V

Nvd(v  S).

(1)

The ﬁrst term of (1) is called the facility cost and the second term is called the connection cost.

∗Authors are alphabetically ordered.

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

√

Throughout the paper  we shall simply use UFL to refer to Uniform-FL. Although the problem has
been studied quite well in recent years  there is some privacy issue on the locations of the clients.
Consider the following scenario: One client may get worried that the other clients may be able
to obtain some information on her location by colluding and exchanging their information. As a
commonly-accepted approach for preserving privacy  Differential Privacy (DP) [5] provides provable
protection against identiﬁcation and is resilient to arbitrary auxiliary information that might be
available to attackers.
However  under the -DP model  Gupta et al. [8] recently showed that it is impossible to achieve a
useful multiplicative approximation ratio of the facility location problem. Speciﬁcally  they showed
that any 1-DP algorithm for UFL under general metric that outputs the set of open facilities must
have a (multiplicative) approximation ratio of Ω(
n) which negatively shows that UFL in DP model
is useless. Thus one needs to consider some relaxed settings in order to address the issue.
In the same paper [8] the authors showed that  under the following setting  an O( log2 n log2 ∆
)
approximation ratio under the -DP model is possible  where ∆ = maxu v∈V d(u  v) is the diameter
of the input metric. In the setting  the output is a set R ⊆ V   which is a super-set of the set of open
facilities. Then every client sees the output R and chooses to connect to its nearest facility in R. The
the actual set S of open facilities  is the facilities in R with at least one connecting client. Thus  in
this model  a client will only know its own service facility  instead of the set of open facilities.
We call this setting the super-set output setting. Roughly speaking  under the -DP model  one can
not well distinguish between if there is 0 or 1 client at some location v. If v is far away from all the
other locations  then having one client at v will force the algorithm to open v and thus will reveal
information about the existence of the client at v. This is how the lower bound in [8] was established.
By using the super-set output setting  the algorithm can always output v and thus does not reveal
much information about the client. If there is no client at v then v will not be open.
In this paper we further study the UFL problem in the -DP model with the super-set output setting
by [8] we address the following questions.



For the UFL problem under the -DP model and the super-set output setting  can
we do better than the results in [8] in terms of the approximation ratio? Also  what
is the lower bound of the approximation ratio in the same setting?

We make progresses on both problems. Our contributions can be summarized as the followings.
• We show that under the so called Hierarchical-Well-Separated-Tree (HST) metrics  there is an
 ) approximation ratio. By using the classic FRT tree embedding
algorithm that achieves O( 1
technique of [6]  we can achieve O( log n
) approximation ratio for any metrics  under the -DP
model and the super-set output setting. These factors respectively improve upon a factor of
O(log n log2 ∆) in [8] for HST and general metrics. Thus  for HST-metrics  our approximation
only depends on . For general metrics  our result removed the poly-logarithmic dependence on ∆
in [8].
• On the negative side  we show that the approximation ratio under -DP model is lower bounded
 ) even if the metric is a star (which is a special case of a HST). This shows that the

by Ω( 1√
dependence on  is unavoidable and can not been improved greatly.



Related Work The work which is the most related to this paper is [8]  where the author ﬁrst studied
the problem. Nissim et al. [18] study an abstract mechanism design model where DP is used to design
approximately optimal mechanism  and they use facility location as one of their key examples. The
UFL problem has close connection to k-median clustering and submodular optimization  whose DP
versions have been studied before such as [17  3  7  8  2]. However  their methods cannot be used in
our problem. There are many papers study other combinatorial optimization problems in DP model
such as [9  10  11  12  8]. Finally  we remark that the setting we considered in the paper is closely
related to the Joint Differential Privacy Model that was introduced in [14]. We leave the details to the
full version of the paper.
2 Preliminaries
Given a data universe V and a dataset D = {v1 ···   vN} ∈ V N where each record vi belongs to
an individual i whom we refer as a client in this paper. Let A : V N (cid:55)→ S be an algorithm on D and
produce an output in S. Let D−i denote the dataset D without entry of the i-th client. Also (v(cid:48)
i  D−i)
denote the dataset by adding v(cid:48)

i to D−i.

2

i  D−i) ∈ T ].

Deﬁnition 2 (Differential Privacy [5]). A randomized algorithm A is -differentially private (DP) if
for any client i ∈ [N ]  any two possible data entries vi  v(cid:48)
i ∈ V   any dataset D−i ∈ V N−1 and for all
events T ⊆ S in the output space of A  we have Pr[A(vi  D−i) ∈ T ] ≤ e Pr[A(v(cid:48)
For the UFL problem  instead of using a set D of clients as input  it is more convenient for us to use a
vector (cid:126)N = (Nv)v∈V ∈ ZV≥0  where Nv indicates the number of clients at location v. Then the -DP
requires that for any input vectors (cid:126)N and (cid:126)N(cid:48) with | (cid:126)N − (cid:126)N(cid:48)|1 = 1 and any event T ⊆ S  we have
Pr[A( (cid:126)N ) ∈ T ] ≤ e Pr[A( (cid:126)N(cid:48)) ∈ T ].
In the super-set output setting for the UFL problem  the output of an algorithm is a set R ⊆ V of
potential open facilities. Then  every client  or equivalently  every location v with Nv ≥ 1  will be
connected to the nearest location in R under some given metric (in our algorithm  we use the HST tree
metric). Then the actual set S of open facilities is the set of locations in R with at least 1 connected
client. Notice that the connection cost of S will be the same as that of R; but the facility cost might
be much smaller than that of R. This is why the super-set output setting may help in getting good
approximation ratios.
Throughout the paper  approximation ratio of an algorithm A is the expected multiplicative
approximation ratio  which is the expected cost of the solution given by the algorithm  divided
by the cost of the optimum solution  i.e. 
  where the expectation is over the
randomness of A.
Organization In Section 3  we show how to reduce UFL on general metrics to that on HST
metrics  while losing a factor of O(log n) in the approximation ratio. In Section 4  we give our -DP
√
O(1/)-approximation for UFL under the super-set output setting. Finally in Section 5  we prove our
)-lower bound on the approximation ratio for the same setting. All missing proofs will be
Ω(1/
deferred to the full version of the paper.
3 Reducing General Metrics to Hierarchically Well-Separated Tree Metrics
The classic result of Fakcharoenphol  Rao and Talwar (FRT) [6] shows that any metric on n points
can be embedded into a distribution of metrics induced by hierarchically well-separated trees with
distortion O(log n). As in [8]  this tree-embedding result is our starting point for our DP algorithm
for uniform UFL. To apply the technique  we ﬁrst deﬁne what is a hierarchically well-separated tree.
Deﬁnition 3. For any real number λ > 1  an integer L ≥ 1  a λ-Hierarchically Well-Separated tree
(λ-HST) of depth L is an edge-weighted rooted tree T satisfying the following properties:

Ecostd(A( (cid:126)N ); (cid:126)N )
minS⊆V costd(S; (cid:126)N )

(3a) Every root-to-leaf path in T has exactly L edges.

(3b) If we deﬁne the level of a vertex v in T to be L minus the number of edges in the unique
root-to-v path in T   then an edge between two vertices of level (cid:96) and (cid:96) + 1 has weight λ(cid:96).
Given a λ-HST T   we shall always use VT to denote its vertex set. For a vertex v ∈ VT   we let (cid:96)T (v)
denote the level of v using the deﬁnition in (3b). Thus  the root r of T has level (cid:96)T (r) = L and every
leaf v ∈ T has level (cid:96)T (v) = 0. For every u  v ∈ VT   deﬁne dT (u  v) be the total weight of edges in
the unique path from u to v in T . So (VT   dT ) is a metric. With the deﬁnitions  we have:
Fact 4. Let u ∈ VT be a non-leaf of T and v (cid:54)= u be a descendant of u  then

λ(cid:96)T (u)−1 ≤ dT (u  v) ≤ λ(cid:96)T (u)−1

λ−1 ≤ λ(cid:96)T (u)
λ−1 .

We say a metric (V  d) is a λ-HST metric for some λ > 1 if there exists a λ-HST T with leaves being
V such that (V  d) ≡ (V  dT|V )  where dT|V is the function dT restricted to pairs in V . Throughout
the paper  we guarantee that if a metric is a λ-HST metric  the correspondent λ-HST T is given. We
give the formal description of the FRT result as well how to apply it to reduce UFL on general metrics
to that on O(1)-HST metrics in the full version of the paper.
Speciﬁcally  we shall prove the following theorem:
Theorem 5. Let λ > 1 be any absolute constant. If there exists an efﬁcient -DP αtree(n  )-
approximation algorithm A for UFL on λ-HST’s under the super-set output setting  then there exists
an efﬁcient -DP O(log n) · αtree(n  )-approximation algorithm for UFL on general metrics under
the same setting.

3

In Section 4  we shall show that it is possible to make αtree(n  ) = O(1/):
Theorem 6. For every small enough absolute constant λ > 1  there is an efﬁcient -DP O(1/)-
approximation algorithm for UFL on λ-HST metrics under the super-set output setting.

Combining Theorems 5 and 6 will give our main theorem.
Theorem 7 (Main Theorem). Given any UFL tuple (V  d  f  (cid:126)N ) where |V | = n and  > 0  there
is an efﬁcient -DP algorithm A in the super-set output setting achieving an approximation ratio of
O( log n

).



design an -DP(cid:0)αtree = O(1/)(cid:1)-approximation algorithm for UFL instances on the metric (V  dT ).

4
-DP Algorithm with O(1/) Approximation Ratio for HST Metrics
In this section  we prove Theorem 6. Let λ ∈ (1  2) be any absolute constant and let η =
λ. We
prove the theorem for this ﬁxed λ. So we are given a λ-HST T with leaves being V . Our goal is to
Our input vector is (cid:126)N = (Nv)v∈V   where Nv ∈ Z≥0 is the number of clients at the location v ∈ V .

√

4.1 Useful Deﬁnitions and Tools

Before describing our algorithm  we introduce some useful deﬁnitions and tools. Recall that VT is the
set of vertices in T and V ⊆ VT is the set of leaves. Since we are dealing with a ﬁxed T in this section 
we shall use (cid:96)(v) for (cid:96)T (v). Given any u ∈ VT   we use Tu to denote the sub-tree of T rooted at u.
Let L ≥ 1 be the depth of T ; we assume L ≥ logλ(f ).2 We use L(cid:48) = max{0 (cid:100)logλ(f )(cid:101)} ≤ L to
denote the smallest non-negative integer (cid:96) such that λ(cid:96) ≥ f.

We extend the deﬁnition of Nu’s to non-leaves u of T : For every u ∈ VT \V   let Nu =(cid:80)

v∈Tu∩V Nv
to be the total number of clients in the tree Tu.
We can assume that facilities can be built at any location v ∈ VT (instead of only at leaves V ): On
one hand  this assumption enriches the set of valid solutions and thus only decreases the optimum
cost. On the other hand  for any u ∈ VT with an open facility  we can move the facility to any leaf v
in Tu. Then for any leaf v(cid:48) ∈ V   it is the case that d(v(cid:48)  v) ≤ 2d(v(cid:48)  u). Thus moving facilities from
VT \ V to V only incurs a factor of 2 in the connection cost.
An important function that will be used throughout this section is the following set of minimal
vertices:
Deﬁnition 8. For a set M ⊆ T of vertices in T   let

min-set(M ) := {u ∈ M : ∀v ∈ Tu \ {u}  v /∈ M}.

For every v  let we deﬁne Bv := min{f  Nvλ(cid:96)(v)}. This can be viewed as a lower bound on the cost
incurred inside the tree Tv  as can be seen from the following claim:
Claim 9. Let V (cid:48) ⊆ VT be a subset of vertices that does not contain an ancestor-descendant pair3.

Then we have opt ≥(cid:80)

v∈V (cid:48) Bv.

4.2 Base Algorithm for UFL without Privacy Guarantee

Before describing the -DP algorithm  we ﬁrst give a base algorithm (Algorithm 1) without any privacy
guarantee as the starting point of our algorithmic design. The algorithm gives an approximation ratio
of O(1/); however  it is fairly simple to see that by making a small parameter change  we can achieve
O(1)-approximation ratio. We choose to present the algorithm with O(1/)-ratio only to make it
closer to our ﬁnal algorithm (Algorithm 2)  which is simply the noise-version of the base algorithm.
The noise makes the algorithm -DP  while only incurring a small loss in the approximation ratio.
Recall that we are considering the super-set output setting where we return a set R of facilities  but
only open a set S ⊆ R of facilities using the following closest-facility rule: We connect every client
to its nearest facility in R  then the set S ⊆ R of open facilities is the set of facilities in R with at
least 1 connected client.

root for T and let the old root be its child.

2If this is not the case  we can repeat the following process many steps until the condition holds: create a new
3This means for every two distinct vertices u  v ∈ V (cid:48)  u is not an ancestor of v

4

Algorithm 1 UFL-tree-base()
1: L(cid:48) ← max{0 (cid:100)logλ(f )(cid:101)}

2: Let M ←(cid:110)

v ∈ VT : (cid:96)(v) ≥ L(cid:48) or Nv · λ(cid:96)(v) ≥ f

be the set of marked vertices

3: R ← min-set(M )
4: return R but only open S ⊆ R using the closest-facility rule.

In the base algorithm  M is the set of marked vertices in T and we call vertices not in M unmarked.
All vertices at levels [L(cid:48)  L] are marked. Notice that there is a monotonicity property among vertices
in VT : for two vertices u  v ∈ VT with u being an ancestor of v  v is marked implies that u is marked.
Due to this property  we call an unmarked vertex v ∈ VT maximal-unmarked if its parent is marked.
Similarly  we call a marked vertex v ∈ VT minimal-marked if all its children are unmarked (this is
the case if v is a leaf). So R is the set of minimal-marked vertices. Notice one difference between our
algorithm and that of [8]: we only return minimal-marked vertices  while [8] returns all marked ones.
This is one place where we can save a logarithmic factor  which requires more careful analysis.
We bound the facility and connection cost of the solution S given by Algorithm 1 respectively. Indeed 
for the facility cost  we prove some stronger statement. Deﬁne V ◦ = {u ∈ Vt : Nu ≥ 1} be the set
of vertices u with at least 1 client in Tu. We prove
Claim 10. S ⊆ min-set(V ◦ ∩ M ).
The stronger statement we prove about the facility cost of the solution S is the following:
Lemma 11. |min-set(V ◦ ∩ M )| · f ≤ (1 + 1/)opt.
Notice that Claim 10 and Lemma 11 imply that |S| · f ≤ O(1 + 1/)opt.
Now we switch gear to consider the connection cost of the solution S and prove:
Lemma 12. The connection cost of S given by the base algorithm is at most O(1)opt.

4.3 Guaranteeing -DP by Adding Noises

In this section  we describe the ﬁnal algorithm (Algorithm 2) that achieves -DP without sacriﬁcing
the order of the approximation ratio. Recall that η =

λ.

√

(cid:111)

(cid:111)

Algorithm 2 DP-UFL-tree()
1: L(cid:48) ← max{0 (cid:100)logλ(f )(cid:101)}
2: for every v ∈ VT with (cid:96)(v) < L(cid:48)  deﬁne ˜Nv := Nv + Lap

(cid:18)

f

cηL(cid:48)+(cid:96)(v)

(cid:19)

  where c = η−1
η2 .

v ∈ VT : (cid:96)(v) ≥ L(cid:48) or ˜Nv · λ(cid:96)(v) ≥ f

be the set of marked vertices

3: Let M ←(cid:110)

4: R ← min-set(M )
5: return R but only open S ⊆ R using the closest-facility rule.

We give some intuitions on how we choose the noises in Step 1 of the Algorithm. Let us travel
through the tree from level L(cid:48) down to level 0. Then the Laplacian parameter  which corresponds to
the magnitude of the Laplacian noise  goes up by factors of η. This scaling factor is carefully chosen
to guarantee two properties. First the noise should go up exponentially so that the DP parameter
only depends on the noise on the highest level  i.e  level L(cid:48). Second  η is smaller than the distance
scaling factor λ = η2. Though the noises are getting bigger as we travel down the tree  their effects
are getting smaller since they do not grow fast enough. Then essentially  the effect of the noises is
only on levels near L(cid:48).
Lemma 13. Algorithm 2 satisﬁes -DP property.

4.4

Increase of cost due to the noises

We shall analyze how the noise affects the facility and connection costs. Let M 0  R0 and S0 (resp.
M 1  R1 and S1) be the M  R and S generated by Algorithm 1 (resp. Algorithm 2). In the proof 

5

we shall also consider running Algorithm 1 with input vector being 2 (cid:126)N instead of (cid:126)N. Let M(cid:48)0  R(cid:48)0
and S(cid:48)0 be the M  R and S generated by Algorithm 1 when the input vector is 2 (cid:126)N. Notice that the
optimum solution for input vector 2 (cid:126)N is at most 2opt. Thus  Lemma 11 implies |S(cid:48)0|·f = O(1/)opt.
Notice that M 0  R0  S0  M(cid:48)0  R(cid:48)0 and S(cid:48)0 are deterministic while M 1  R1 and S1 are randomized.
The lemmas we shall prove are the following:

Lemma 14. E(cid:2)|S1| · f(cid:3) ≤ O(1/) · opt.

Lemma 15. The expected connection cost of the solution S1 is O(1) times that of S0.

Thus  combining the two lemmas  we have that the expected cost of the solution S1 is at most
O(1/)opt  ﬁnishing the proof of Theorem 6. Indeed  we only lose an O(1)-factor for the connection
cost as both factors in Lemma 11 and 15 are O(1). We then prove the two lemmas separately.

4.4.1 Increase of facility costs due to the noise

In this section  we prove Lemma 14. A technical lemma we can prove is the following:
Claim 16. Let M ⊆ VT and M(cid:48) = M ∪ {v} for some v ∈ VT \ M  then exactly one of following
three cases happens.

(16a) min-set(M(cid:48)) = min-set(M ).
(16b) min-set(M(cid:48)) = min-set(M ) (cid:93) {v}.
(16c) min-set(M(cid:48)) = min-set(M ) \ {u} ∪ {v}  where u ∈ min-set(M )  v /∈ min-set(M ) and

v is a descendant of u.

Proof of Lemma 14. Recall that V ◦ is the set of vertices u with Nu ≥ 1. We ﬁrst focus on open
facilities in V ◦ in S1. Claim 16 implies that adding one new element to M will increase |min-set(M )|
by at most 1. Thus  we have

|min-set(M 1 ∩ V ◦)| − |min-set(M(cid:48)0 ∩ V ◦)| ≤ |(M 1 ∩ V ◦) \ (M(cid:48)0 ∩ V ◦)|

=

u ∈ V ◦ : (cid:96)(u) < L(cid:48)  2Nu <

f

λ(cid:96)(u)

≤ ˜Nu

(cid:20)

We now bound the expectation of the above quantity. Let U∗ be the set of vertices u ∈ V ◦ with
(cid:96)(u) < L(cid:48) and Nu < f

(cid:19)
2λ(cid:96)(u) . Then for every u ∈ U∗  we have
(cid:32)
≥ f
Pr[u ∈ M 1] = Pr
λ(cid:96)(u)
− cηL(cid:48)−(cid:96)(u)
have Bu = min(cid:8)f  Nuλ(cid:96)(u)(cid:9) ≥ λ(cid:96)(u) for every u we are interested. Then 

(2)
We bound f times the sum of (2)  over all u ∈ U∗. Notice that every u ∈ V ◦ has Nu ≥ 1. So we

f /(cid:0)cηL(cid:48)+(cid:96)(u)(cid:1)(cid:33)

− f /(2λ(cid:96)(u))

(cid:21)
(cid:33)

cηL(cid:48)+(cid:96)(u)

Nv + Lap

≤ 1
2

(cid:32)

(cid:18)

exp

exp

2

=

1
2

f

.

f ≤ 1


· f · Bu
λ(cid:96)(u)
The last inequality comes from f ≤ λL(cid:48)
. The equality used that λ = η2.
We group the u’s according to (cid:96)(u). For each level (cid:96) ∈ [0  L(cid:48) − 1]  we have

· λL(cid:48) · Bu
λ(cid:96)(u)

≤ 1


Bu


· η2(L(cid:48)−(cid:96)(u)).

=

(cid:88)

(cid:32)
− cηL(cid:48)−(cid:96)(u)

(cid:33)

f
2

exp

u∈U∗:(cid:96)(u)=(cid:96)

≤ 1
2
(cid:96) exp(− cx(cid:96)
where we deﬁned x(cid:96) = ηL(cid:48)−(cid:96)(u) and c(cid:96) = x2
holds since all u’s in the summation are at the same level.
Taking the sum over all (cid:96) from 0 to L(cid:48)  we obtain

η2(L(cid:48)−(cid:96)) exp

2

(3)

Bu ≤ c(cid:96)
2

opt 

(cid:32)
− cηL(cid:48)−(cid:96)

2

(cid:33) (cid:88)

u as before

2 ). The last inequality used Claim 9  which

(cid:27)(cid:12)(cid:12)(cid:12)(cid:12) .

(cid:12)(cid:12)(cid:12)(cid:12)(cid:26)

(cid:88)

f

u∈U∗

Pr[u ∈ M 1] ≤ opt
2

c(cid:96) =

opt
2

· L(cid:48)−1(cid:88)

(cid:96)=0

(cid:96) exp(− cx(cid:96)
x2
2

).

· L(cid:48)−1(cid:88)

(cid:96)=0

6

Notice that {x(cid:96) : (cid:96) ∈ [0  L(cid:48) − 1]} is exactly {η  η2 ···   ηL(cid:48)}. It is easy to see summation is bounded
by a constant for any constant c. Thus  the above quantity is at most O(1/)opt. Therefore  we
proved

f · E(cid:2)|min-set(M 1 ∩ V ◦)| − |min-set(M(cid:48)0 ∩ V ◦)|(cid:3) ≤ O(1/) · opt.

Notice that Lemma 11 says that f · |min-set(M(cid:48)0 ∩ V ◦)| ≤ O(1/)opt. Thus f · E[|min-set(M 1 ∩
V ◦)|] ≤ O(1/)opt.
Then we take vertices outside V ◦ into consideration. Let U = min-set(M 1 ∩ V ◦). Then S1 ⊆
R1 = min-set(U ∪ (VT \ V ◦)). To bound the facility cost of S1  we start with the set U(cid:48) = U
and add vertices in VT \ V ◦ (these are vertices u with Nu = 0) to U(cid:48) one by one and see how
this changes min-set(U(cid:48)). By Claim 16  adding a vertex Nv = 0 to U(cid:48) will either not change
min-set(U(cid:48))  or add v to min-set(U(cid:48))  or replace an ancestor of v with v. In all the cases  the set
min-set(U(cid:48)) ∩ V ◦ can only shrink. Thus  we have R1 ∩ V ◦ ⊆ min-set(U ) = min-set(M 1 ∩ V ◦).
We have E[|R1 ∩ V | · f ] ≤ O(1/) · opt.
Thus  it sufﬁces to bound the expectation of |S \ V ◦|· f. Focus on some u ∈ VT with Nu = 0. Notice
that u /∈ S if (cid:96)(u) ≥ L(cid:48). So  we assume (cid:96)(u) < L(cid:48). In this case there is some leaf v ∈ V with Nv > 0
such that u is the closest point in R to v. So v is not a descendant of u. Let u(cid:48) be the ancestor of v that
is at the same level at u and deﬁne π(u) = u(cid:48). Then (cid:96)(π(u)) = (cid:96)(u). Moreover  u is also the closest
point in R to u(cid:48)  implying that π is an injection. For every u  we can bound f as in (3)  but with Bu
u:Nu=0 (cid:96)(u)=(cid:96) Bπ(u) ≤ opt
for every (cid:96) ∈ [0  L(cid:48) − 1] by Claim 9.

replaced by Bπ(u). Then the above analysis still works since we have(cid:80)

4.4.2 Increase of connection cost due to the noise

Now we switch gear to consider the change of connection cost due to the noise.
Proof of Lemma 15. Focus on a vertex v at level (cid:96) and suppose v ∈ S0 and some clients are connected
to v in the solution produced by Algorithm 2. So  we have Nv ≥ f
λ(cid:96) . Let the ancestor of v (including
v itself) be v0 = v  v1  v2 ··· from the bottom to the top. Then the probability that v0 /∈ M 0 is
at most 1/2 and in that case the connection cost increases by a factor of λ. The probability that
v0  v1 /∈ M 0 is at most 1/4  and in that case the cost increases by a factor of λ2 and so on. As a
result  the expected scaling factor for the connection cost due to the noise is at most

(cid:18) λ

(cid:19)i

∞(cid:88)

1

2i · λi =

2

i=1

= O(1).

Thus  the connection cost of the solution S1 is at most a constant times that of S0. This is the place
where we require λ < 2.

5 Lower Bound of UFL for HST Metric

λ−1 for some integer L.

In this section  we prove an Ω(1/
) lower bound on the approximation ratio of any algorithm for
UFL in the super-set setting under the -DP model. The metric we are using is the uniform star-metric:
the shortest-path metric of a star where all edges have the same length. We call the number of edges
in the star its size and the length of these edges its radius. By splitting edges  we can easily see that
the metric is a λ-HST metric for a λ > 1  if the radius is λL
The main theorem we are going to prove is the following:
Theorem 17. There is a constant c > 0 such that the following holds. For any small enough
 < 1  f > 0 and sufﬁciently large integer n that depends on   there exists a set of UFL instances
{(V  d  f  (cid:126)N )} (cid:126)N   where (V  d) is the uniform-star metric of size n and radius
f  and every instance
in the set has n ≤ | (cid:126)N|1 ≤ n/  such that the following holds: no -DP algorithm under the super-set
setting can achieve c 1√
Proof. Throughout the proof  we let m = 1/ and we assume m is an integer. We prove Theorem 17
in two steps  ﬁrst we show the lower bound on an instance with a 2-point metric  but non-uniform
facility costs. Then we make the facility costs uniform by combining multiple copies of the 2-point
metric into a star metric.

-approximation for all the instances in the set.

√

∞(cid:88)

i=0

√

7

Consider the instance shown in Figure 1a where V = {a  b} and d(a  b) =
f. The facility costs
for a and b are respectively f and 0. Thus  we can assume the facility b is always open. All the clients
are at a  and the number N of clients is promised to be an integer between 1 and m. We show that
√
for this instance  no -DP algorithm in the super-set output setting can distinguish between the case
where N = 1 and that N = m with constant probability; this will establish the Ω(
m) lower bound.

√

(a)

(b)

(c)

Figure 1: Instance for the lower bound.

Obviously  there are only 2 solutions for any instance in the setting: either we open a  or we do not.
Since we are promised there is at least 1 client  the central curator has to reveal whether we open a or
not  even in the super-set output setting: If we do not open a  then we should not include a in the
returned set R since otherwise the client will think it is connected to a; if we open a  then we need to
include it in the returned set R since all the clients need to be connected to a.
Let Di be the scenario where we have N = i clients at a  where i ∈ [m]. Then the cost of the two
solutions for the two scenarios D1 and Dm are listed in the following table:

not open a

√
√
f /

m
mf

open a

f
f

D1
Dm

√
√
Thus  if the data set is D1  we should not open a; if we opened  we’ll lose a factor of
m. If the data
set is Dm  then we should open a; if we did not open  then we also lose a factor of
m.
√
Now consider any -DP algorithm A. Assume towards the contradiction that A achieves 0.2
m
approximation ratio. Then  under the data set D1  A should choose not to open a with probability at
least 0.8. By the -DP property  under the data set Dm  A shall choose not to open a with probability
at least 0.8e−(m−1) > 0.8/e ≥ 0.2. Then under the data set Dm  the approximation ratio of A is
√
more than 0.2
Indeed  later we need an average version of the lower bound as follows:

m  leading to a contradiction.

√
m√
m + 1

E cost(A(1); 1) +

(4)
where c is an absolute constant  A(N ) is the solution output by the algorithm A when there are
N clients at a  and cost(A(N ); N ) is the cost of the solution under the input N. Our argument
√
above showed that either E cost(A(1); 1) ≥ Ω(0.2
m = 0.2f  or E cost(A(N ); N ) ≥
√
0.2

√
mf. In either case  the left side of (4) is at least 0.2

√
m · f = 0.2

√
m) · f /

√
m+1 ≥ cf if c is small.

mf

E cost(A(m); m) ≥ cf 

1√
m + 1

The above proof almost proved Theorem 17 except that we need to place a free open facility at
location b. To make the facility costs uniform  we can make multiple copies of the locations a  while
only keeping one location b; this is exactly a star metric (see Figure 1b). The costs for all facilities
are f. However  since there are so many copies of a  the cost of f for opening a facility at b is so
small and thus can be ignored. Then  the instance essentially becomes many separate copies of the
2-point instances we described (see Figure 1c).
However  proving that the “parallel repetition” instance in Figure 1c has the same lower bound
as the original two-point instance is not so straightforward. Intuitively  we can imagine that the
central curator should treat all copies independently: the input data for one copy should not affect
the decisions we make for the other copies. However  it is tricky to prove this. Instead  we prove
Theorem 17 directly by deﬁning a distribution over all possible instances and argue that an -DP
algorithm must be bad on average.

8

baf/√mcost=0cost=fa1a2······an−1anbcost=ff/√mcost=fcost=fcost=fcost=f············b1b2b3bna1a2a3an∞∞cost=0f/√mcost=0cost=0cost=0cost=fcost=fcost=fcost=fDue to the page limit  the detailed analysis is left to the full vesion of the paper.

Acknowledgements

Yunus Esencayi is supported in part by NSF grants CCF-1566356. Part of the work was done when
Di Wang and Marco Gaboardi were visiting the Simons Institute of the Theory for Computing. Marco
Gaboardi is supported in part by NSF through grant CCF-1718220. Di Wang is supported in part
by NSF through grant CCF-1716400. Shi Li is supported in part by NSF grants CCF-1566356 
CCF-1717138 and CCF-1844890.

References
[1] Vijay Arya  Naveen Garg  Rohit Khandekar  Adam Meyerson  Kamesh Munagala  and Vinayaka
Pandit. Local search heuristics for k-median and facility location problems. SIAM Journal on
computing  33(3):544–562  2004.

[2] Maria-Florina Balcan  Travis Dick  Yingyu Liang  Wenlong Mou  and Hongyang Zhang.
Differentially private clustering in high-dimensional euclidean spaces. In Proceedings of the
34th International Conference on Machine Learning-Volume 70  pages 322–331. JMLR. org 
2017.

[3] Adrian Rivera Cardoso and Rachel Cummings. Differentially private online submodular
minimization. In The 22nd International Conference on Artiﬁcial Intelligence and Statistics 
pages 1650–1658  2019.

[4] Moses Charikar and Sudipto Guha. Improved combinatorial algorithms for the facility location
and k-median problems. In 40th Annual Symposium on Foundations of Computer Science 
pages 378–388. IEEE  1999.

[5] Cynthia Dwork  Frank McSherry  Kobbi Nissim  and Adam Smith. Calibrating noise to

sensitivity in private data analysis. In TCC  pages 265–284. Springer  2006.

[6] Jittat Fakcharoenphol  Satish Rao  and Kunal Talwar. A tight bound on approximating arbitrary

metrics by tree metrics. Journal of Computer and System Sciences  69(3):485–497  2004.

[7] Dan Feldman  Amos Fiat  Haim Kaplan  and Kobbi Nissim. Private coresets. In Proceedings of
the forty-ﬁrst annual ACM symposium on Theory of computing  pages 361–370. ACM  2009.

[8] Anupam Gupta  Katrina Ligett  Frank McSherry  Aaron Roth  and Kunal Talwar. Differentially
In Proceedings of the twenty-ﬁrst annual ACM-SIAM
private combinatorial optimization.
symposium on Discrete Algorithms  pages 1106–1125. Society for Industrial and Applied
Mathematics  2010.

[9] Justin Hsu  Zhiyi Huang  Aaron Roth  Tim Roughgarden  and Zhiwei Steven Wu. Private

matchings and allocations. SIAM Journal on Computing  45(6):1953–1984  2016.

[10] Justin Hsu  Zhiyi Huang  Aaron Roth  and Zhiwei Steven Wu. Jointly private convex pro-
gramming. In Proceedings of the twenty-seventh annual ACM-SIAM symposium on Discrete
algorithms  pages 580–599. Society for Industrial and Applied Mathematics  2016.

[11] Zhiyi Huang and Xue Zhu. Near optimal jointly private packing algorithms via dual multiplica-
tive weight update. In Proceedings of the Twenty-Ninth Annual ACM-SIAM Symposium on
Discrete Algorithms  pages 343–357. Society for Industrial and Applied Mathematics  2018.

[12] Zhiyi Huang and Xue Zhu. Scalable and jointly differentially private packing. arXiv preprint

arXiv:1905.00767  2019.

[13] Kamal Jain and Vijay V Vazirani. Approximation algorithms for metric facility location and
k-median problems using the primal-dual schema and lagrangian relaxation. Journal of the
ACM (JACM)  48(2):274–296  2001.

9

[14] Michael Kearns  Mallesh Pai  Aaron Roth  and Jonathan Ullman. Mechanism design in large
games: Incentives and privacy. In Proceedings of the 5th conference on Innovations in theoretical
computer science  pages 403–410. ACM  2014.

[15] Shi Li. A 1.488 approximation algorithm for the uncapacitated facility location problem. In
International Colloquium on Automata  Languages  and Programming  pages 77–88. Springer 
2011.

[16] Shi Li. On facility location with general lower bounds. In Proceedings of the Thirtieth Annual
ACM-SIAM Symposium on Discrete Algorithms  pages 2279–2290. Society for Industrial and
Applied Mathematics  2019.

[17] Marko Mitrovic  Mark Bun  Andreas Krause  and Amin Karbasi. Differentially private submod-
ular maximization: data summarization in disguise. In Proceedings of the 34th International
Conference on Machine Learning-Volume 70  pages 2478–2487. JMLR. org  2017.

[18] Kobbi Nissim  Rann Smorodinsky  and Moshe Tennenholtz. Approximately optimal mechanism
design via differential privacy. In Innovations in Theoretical Computer Science 2012  Cambridge 
MA  USA  January 8-10  2012  pages 203–213  2012.

[19] David B Shmoys and KI Aardal. Approximation algorithms for facility location problems 

volume 1997. Utrecht University: Information and Computing Sciences  1997.

[20] Jean-Michel Thizy. A facility location problem with aggregate capacity. INFOR: Information

Systems and Operational Research  32(1):1–18  1994.

10

,Yunus Esencayi
Marco Gaboardi
Shi Li
Di Wang