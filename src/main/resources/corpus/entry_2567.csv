2019,Implicitly learning to reason in first-order logic,We consider the problem of answering queries about formulas of first-order logic based on background knowledge partially represented explicitly as other formulas  and partially represented as examples independently drawn from a fixed probability distribution. PAC semantics  introduced by Valiant  is one rigorous  general proposal for learning to reason in formal languages: although weaker than classical entailment  it allows for a powerful model theoretic framework for answering queries while requiring minimal assumptions about the form of the distribution in question. To date  however  the most significant limitation of that approach  and more generally most machine learning approaches with robustness guarantees  is that the logical language is ultimately essentially propositional  with finitely many atoms. Indeed  the theoretical findings on the learning of relational theories in such generality have been resoundingly negative. This is despite the fact that first-order logic is widely argued to be most appropriate for representing human knowledge. 
In this work  we present a new theoretical approach to robustly learning to reason in first-order logic  and consider universally quantified clauses over a countably infinite domain. Our results exploit symmetries exhibited by constants in the language  and generalize the notion of implicit learnability to show how queries can be computed against (implicitly) learned first-order background knowledge.,Implicitly Learning to Reason in First-Order Logic

University of Edinburgh & Alan Turing Institute

Washington University in St. Louis

Brendan Juba

bjuba@wustl.edu

Vaishak Belle

vaishak@ed.ac.uk

Abstract

We consider the problem of answering queries about formulas of ﬁrst-order logic
based on background knowledge partially represented explicitly as other formulas 
and partially represented as examples independently drawn from a ﬁxed probabil-
ity distribution. PAC semantics  introduced by Valiant  is one rigorous  general
proposal for learning to reason in formal languages: although weaker than classical
entailment  it allows for a powerful model theoretic framework for answering
queries while requiring minimal assumptions about the form of the distribution
in question. To date  however  the most signiﬁcant limitation of that approach 
and more generally most machine learning approaches with robustness guarantees 
is that the logical language is ultimately essentially propositional  with ﬁnitely
many atoms. Indeed  the theoretical ﬁndings on the learning of relational theories
in such generality have been resoundingly negative. This is despite the fact that
ﬁrst-order logic is widely argued to be most appropriate for representing human
knowledge. In this work  we present a new theoretical approach to robustly learning
to reason in ﬁrst-order logic  and consider universally quantiﬁed clauses over a
countably inﬁnite domain. Our results exploit symmetries exhibited by constants in
the language  and generalize the notion of implicit learnability to show how queries
can be computed against (implicitly) learned ﬁrst-order background knowledge.

1

Introduction

The tension between deduction and induction is perhaps the most fundamental issue in areas such as
philosophy  cognition and artiﬁcial intelligence. The deduction camp concerns itself with questions
about the expressiveness of formal languages for capturing knowledge about the world  together with
proof systems for reasoning from such knowledge bases. The learning camp attempts to generalize
from examples about partial descriptions about the world. In an inﬂuential paper  Valiant [31]
recognized that the challenge of learning should be integrated with deduction. In particular  he
proposed a semantics to capture the quality possessed by the output of (probably approximately
correct) PAC-learning algorithms when formulated in a logic. Although weaker than classical
entailment  it allows for a powerful model theoretic framework for answering queries.
From the standpoint of learning an expressive logical knowledge base and reasoning with it  most
PAC results are somewhat discouraging. For example  in agnostic learning [12] where one does not
require examples (drawn from an arbitrary distribution) to be fully consistent with learned sentences 
efﬁcient algorithms for learning conjunctions would yield an efﬁcient algorithm for PAC-learning
DNF (also over arbitrary distributions)  which current evidence suggests to be intractable [6]. Thus 
it is not surprising that when it comes to ﬁrst-order logic (FOL)  very little work tackles the problem
in a general manner. This is despite the fact that FOL is widely argued to be most appropriate for
representing human knowledge (e.g.  [23  26  18]). For example  [4] consider the problem of the
learnability of description logics with equality constraints. While description logics are already
restricted fragments of FOL in only allowing unary and some binary predicates  it is shown that
such a fragment cannot be tractably learned  leading to the identiﬁcation of syntactic restrictions for

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

learning from positive examples alone. Analogously  when it comes to the learning of logic programs
[5]  which in principle may admit inﬁnitely many terms  syntactic restrictions are also typical [7].
In this work  we present new results on learning to reason in FOL knowledge bases. In particular  we
consider the problem of answering queries about FOL formulas based on background knowledge
partially represented explicitly as other formulas  and partially represented as examples independently
drawn from a ﬁxed probability distribution. Our results are based on a surprising observation made in
[11] about the advantages of eschewing the explicit construction of a hypothesis  leading to a paradigm
of implicit learnability. Not only does it enable a form of agnostic learning while circumventing
known barriers  it also avoids the design of an often restrictive and artiﬁcial choice for representing
hypotheses. (See  for example  [14]  which is similar in spirit in allowing declarative background
knowledge but only permits constant-width clauses.) In particular  implicit learning allows such
learning from partially observed examples  which is commonplace when knowledge bases and/or
queries address entities and relations not observed in the data used for learning.
That work was limited to the propositional setting  however. Here  we develop a ﬁrst-order logical
generalization. This requires us to generalize the notions of validity and entailment  and propose
new methods for recognizing true formulas under partial information  that capture what is implicitly
learned. Since reasoning in full FOL is undecidable we need to consider a fragment  but the fragment
we identify and are able to learn and reason with is expressive and powerful. Consider that standard
databases correspond to a maximally consistent and ﬁnite set of literals: every relevant atom is
known to be true and stored in the database  or known to be false  inferred by (say) negation as
failure. Our fragment corresponds to a consistent but inﬁnite set of ground clauses  not necessarily
maximal. To achieve the generalization  we revisit the PAC semantics and exploit symmetries
exhibited by constants in the language. Moreover  the underlying language is general in the sense
that no restrictions are posed on clause length  predicate arity  and other similar technical devices
seen in PAC results. We hope the simplicity of the framework is appealing to the readers and hope
our results will renew interest in learnability for expressive languages with quantiﬁcational power.
We remark that our sole focus is in PAC-semantics approaches  but there are also other families of
methods for unifying statistical and logical representations  that fall under the banner of statistical
relational learning (SRL) (e.g.  [13]). SRL includes widely used formalisms such as Markov Logic
Networks [28] and frameworks such as Inductive Logic Programming [27]. Learning strategies for
SRL is an active area of research with numerous recent advances—for example  a family of recent
works have adapted the techniques for training neural networks into the Inductive Logic Programming
paradigm [3  29  8  22]. Generally speaking  there are signiﬁcant differences to PAC-semantics
approaches  such as in terms of the learning regime  the notion of correctness  and the underlying
algorithmic machinery. For example  Markov Logic Networks use approximate maximum-likelihood
learning strategies to capture the distribution of the data  whereas in PAC formulations  one considers
an arbitrary unknown distribution over the data and studies the question of what formulas are learnable
whilst costing for the number of examples needed to be sampled from that distribution. PAC-semantics
is distinguished in being able to provide guarantees of generalization performance and polynomial
time complexity with the minimal assumption of i.i.d. training examples. Of course  there is much
to be gained by attempting to integrate these communities; see  for example  [5]. These differences
notwithstanding  the learning of logical theories is usually restricted to ﬁnite-domain ﬁrst-order logic 
and so it is essentially propositional  and in that regard  our setting is signiﬁcantly more challenging.

2 Logical Framework
Language: We let L be a ﬁrst-order
language with equality and relational symbols
{P (x)  . . .   Q(x1  . . .   xk)  . . .}  variables {x  y  z  . . .}  and a countably inﬁnite set of rigid designa-
tors or names  say  the set of natural numbers N  serving as the domain of discourse for quantiﬁcation.
Well-deﬁned formulas are constructed using logical connectives {¬ ∨ ∀ ∧ ∃ ⊃}  as usual. (⊃
denotes implication.) Together with equality  names essentially realize an inﬁnitary version of the
unique-name assumption.1

1Our language L is essentially equivalent to standard FOL together with a unique-name assumption for

inﬁnitely many constants [17  Deﬁnition 3].

see [9  30]  for example.

In general  the unique-name assumption does not rule out capturing uncertainty about the identity of objects;

2

The set of (ground) atoms is obtained as:2 ATOMS = {P (a1  . . .   ak) | P is a predicate  ai ∈ N} .
We sometimes refer to elements of ATOMS as propositions  and ground formulas as propositional
formulas. We will use p  q  e to denote atoms  and α  β  φ  ψ to denote ground formulas.
Semantics: A L-model M is a {0  1} assignment to the elements of ATOMS. Using |= to denote
satisfaction  the semantics for φ ∈ L is deﬁned as usual inductively  but with equality as identity:
M |= (a = b) iff a and b are the same names  and quantiﬁcation understood substitutionally over all
names in N: M |= ∀xφ(x) iff M |= φ(a) for all a ∈ N. We say that φ is valid iff for every L-model
M  M |= φ. Let the set of all models be M.
Representation: Like in standard FOL  reasoning over the full fragment of L is undecidable.
Interestingly  owing to a ﬁxed  albeit countably inﬁnite  domain of discourse  the compactness
property that holds for classical ﬁrst-order logic does not hold in general [17]. For example 
{∃xP (x) ¬P (1) ¬P (2)  . . .} is an unsatisﬁable theory for which every ﬁnite subset is indeed
satisﬁable. However  as identiﬁed in [1]  and earlier in [15]  the case of disjunctive knowledge is
more manageable. In particular  we will be interested in learning and reasoning with incomplete
knowledge bases with disjunctive information [1]:
Deﬁnition 1: An acceptable equality is of the form x = a  where x is any variable and a any name.
Let e range over formulas built from acceptable equalities and connectives {¬ ∨ ∧}. Let c range
over quantiﬁer-free disjunctions of (possibly non-ground) atoms. Let ∀φ mean the universal closure
of φ  i.e.  with a universal quantiﬁer on each free variable of φ. A formula of the form ∀(e ⊃ c) is
called a ∀-clause. A knowledge base (KB) ∆ is proper+ if it is a ﬁnite non-empty set of ∀-clauses.
The rank of ∆ is the maximum number of variables mentioned in any ∀-clause in ∆.
This fragment is very expressive. Consider that standard databases correspond to a maximally
consistent and ﬁnite set of literals  in the sense that every relevant atom is known to be true and stored
in the database  or known to be false  inferred by (say) negation as failure. In contrast  proper+ KBs
correspond to a consistent but inﬁnite set of ground clauses  not necessarily maximal in this way. We
also note that [19] shows how to represent a certain family of “local” action models for planning
within the fragment of proper+ we consider  for which polynomial-time reasoning is possible.
Grounding: A ground theory is obtained from ∆ by substituting variables with names. Suppose θ
denotes a substitution. We denote the result of applying θ to a formula φ by φθ. For any set of names
C ⊆ N  we write θ ∈ C to mean substitutions are only allowed wrt the names in C. Formally  we
deﬁne:

mentioned in ∆ plus z (arbitrary) new ones;

• GND(∆) = {cθ | ∀(e ⊃ c) ∈ ∆  θ ∈ N and |= eθ};
• For z ≥ 0  GND(∆  z) = {cθ | ∀(e ⊃ c) ∈ ∆ |= eθ  θ ∈ Z}  where Z is the set of names
• For C ⊆ N  GND(∆  C) = {cθ | ∀(e ⊃ c) ∈ ∆ |= eθ  θ ∈ Z} where Z is the set of
• GND−(∆) = GND(∆  z) where z is the rank of ∆.

names mentioned in ∆ plus the names in C;

Reasoning: Unfortunately  arbitrary reasoning with such KBs is also undecidable [15  Theorem
7]. Various proposals have appeared to consider that problem: in [15]  for example  a sound but
incomplete evaluation-based semantics is studied. In [1]  it is instead shown that when the query is
limited to ground formulas  we can reduce ﬁrst-order entailment to propositional satisﬁability:
Theorem 2: [1] Suppose ∆ is a proper+ KB  and α is a ground formula. Then  ∆ |= α iff
GND−(∆ ∧ ¬α) is unsatisﬁable.
Here  the RHS of the iff is a propositional formula  obtained by a ﬁnite grounding  as deﬁned above.
Example 3: Suppose ∆ = {∀x(Grad(x) ∨ Prof(x)) ∀x(x (cid:54)= charles ⊃ Grad(x))} and the query
is Grad(logan). The query can be seen to be entailed. Given that the KB’s rank is 1  consider the
grounding of the KB and the negated query wrt {charles  logan  jean} (here jean is chosen arbitrarily).
It is indeed unsatisﬁable.
It is worth noting that the proof here (and in other proposals with L-like languages [18  15  21]) is
established by setting up a bijection between names to show that all names other than those that

2Because equality is treated separately  atoms and clauses do not include equalities.

3

appear in the ﬁnite grounding in the RHS behave “identically ” and so for entailment purposes  it
sufﬁces to consider a ﬁnite set consisting of the constants already mentioned and a few extra ones.
That idea can be traced back to [17] (reformulated here for our purposes):
Theorem 4: [17] Suppose α = ∀xφ(x) is a ∀-clause. (Its rank is 1.) Let C be the names mentioned
in GND(α  1). Then for every a ∈ N  there is a b ∈ C such that |= φ(a) iff |= φ(b).
The essence of Theorem 2 is to exploit this idea to show (reformulated here for our purposes):
Lemma 5: [1] Suppose α is as above. If GND(α  1) is satisﬁable  then so is GND(α  z) for z ≥ 1.
Thus  because Theorem 4 establishes that GND(α  1) is satisﬁable if and only if α is in the countably
inﬁnite domain  and Lemma 5 establishes that the introduction of extra names in GND(α  z) preserves
satisﬁability  we obtain satisﬁability under the larger  common subset of names used in GND−. These
observations will now lead to an appealing account for implicit learnability with proper+ KBs.

3 Generalizing PAC-Semantics

We now recall the semantics we use  PAC semantics as introduced by Valiant [31]. PAC semantics
was formulated to capture the quality possessed by the output of PAC-learning algorithms  when
viewed as formulas in a logic. Because inductive generalization cannot be captured by deduction 
it inherently requires we admit the possibility of an incorrect generalization. Thus  as compared to
classical (Tarskian) semantics  the PAC semantics is necessarily weaker. In the classical propositional
formulation  we suppose a propositional language with (say) n propositions  yielding a model theoretic
space {0  1}n. We suppose that we observe examples independently drawn from a distribution D over
{0  1}n. Then  suppose further that these examples enable a learning algorithm to ﬁnd a formula φ.
We cannot expect this formula to be valid in the traditional sense  as PAC-learning does not guarantee
that the rule holds for every possible binding  only that φ so produced agrees with probability 1 − 
wrt future examples drawn from the same distribution. This motivates a weaker notion of validity:
Deﬁnition 6: Given a distribution D over {0  1}n  we say that a Boolean function F is (1 − )-valid
if Prx∈D[F (x) = 1] ≥ 1 − . If  = 0  we say F is perfectly valid.
Thus far  the PAC semantics and its application to the formalization of robust logic-based learning has
been limited to the propositional setting [31  24  11]  that is  where the learning vocabulary is ﬁnitely
many atoms  and the background knowledge is essentially restricted to a propositional formula.3
Generalizing that to the FOL case has to address  among other things  what (1 − )-validity means 
how FOL formulas could be learned by algorithms  and ﬁnally  how entailments can be computed.
That is precisely our goal for this paper.
We start by proposing an extension of the PAC semantics for the inﬁnitary structures (generalizing
assignments) constructed for L  namely M. For this  we will need to consider distributions on M 
which are deﬁned as usual [2]: we take M to be the sample space (of elementary events)  deﬁne a
σ-algebra M to be a set of subsets of M  which represent a collection of (not necessarily elementary)
events  and a function Pr : M → [0  1]  which is the probability measure.
We are now ready to deﬁne (1 − )-validity as needed in the PAC semantics.
Deﬁnition 7: Given a distribution Pr over M  we say a formula φ ∈ L is (1 − )-valid iff
φ ∈ L denotes the set {M ∈ M | M |= φ} .
In practice  the most important use of the notion of validity is to check the entailment of a formula
from a knowledge base  and by extension  the reader may wonder how that carries over from classical
validity. As also observed in [11] (for the propositional case)  the union bound allows classical
reasoning to have a natural analogue in the PAC semantics  shown below. Note that  as already
mentioned  our assumption henceforth is that knowledge bases are proper+  and queries are ground
formulas  both in the context of reasoning as well as learning.

Pr((cid:74)φ(cid:75)) ≥ 1 − . If  = 0  then we say that φ is perfectly valid. Here (cid:74)φ(cid:75) for any closed formula

3Valiant [31] uses a fragment of FOL for which propositionalization is guaranteed to yield a small proposi-

tional formula  and only considers such a reduction to the propositional case.

4

Proposition 8: Let ψ1  . . .   ψk be ∀-clauses such that each ψi is (1 − i)-valid under a common
distribution D for some i ∈ [0  1]. Suppose {ψ1  . . .   ψk} |= ϕ  for some ground formula ϕ. Then ϕ

is (1 − (cid:48))-valid under D for (cid:48) =(cid:80)

i i.

4 Partial Observability

The learning problem of interest here is to obtain knowledge about the distribution D  which  of
course  is not revealed directly  but in the form of a set of examples. The examples in question
are models independently drawn from D  and we are then interested in knowing whether a query
α is (1 − )-valid. Intuitively  background knowledge ∆ may be provided additionally and so the
examples correspond to additional knowledge that the agent learns. This additional knowledge is
never materialized in the form of L-formulas  but is left implicit  as postulated ﬁrst in [11].
When it comes to the examples themselves  however  we certainly cannot expect the examples to
reveal the full nature of the world  and indeed  partial descriptions are commonplace in almost all
applications [25]. In the case of L  moreover  providing a full description may even be impossible in
ﬁnite time. All of this motivates the following:
Deﬁnition 9: A partial model N maps ATOMS to {1  0 ∗} . We say N is consistent with a L-model
M iff for all p ∈ ATOMS  if N [p] (cid:54)= ∗ then N [p] = M [p]. Let N be the set of all partial models.

Essentially  our knowledge of D will be obtained from a set of partial models that are the examples.
Deﬁnition 10: A mask is a function θ that maps L-models to partial models  with the property that
for any M ∈ M  θ(M ) is consistent with M  and only a ﬁnite number of atoms are mapped to {0  1}.
A masking process Θ is a mask-valued random variable (i.e.  a random function). We denote the
distribution over partial models obtained by applying a masking process Θ to a distribution D over
L-models by Θ(D).4

The deﬁnition of masking processes allows the hiding of entries to depend on the underlying example
from D. Moreover  as discussed in [11] (for the propositional case)  reasoning in PAC-Semantics
from complete examples is trivial  whereas the hiding of all entries by a masking process means
that the problem reduces to classical entailment. So  we expect examples to be of a sort that is in
between these extremes. In particular  for the sake of tractable learning  we must consider formulas
that can be evaluated efﬁciently from the partial models with high probability. This leads to a notion
of witnessing.
Deﬁnition 11: We deﬁne a propositional formula φ ∈ L to be witnessed to evaluate to true or false
in a partial assignment N by induction as follows:

• an atom Q((cid:126)c) is witnessed to be true/false iff it is true/false respectively in N;
• ¬φ is witnessed true/false iff φ is witnessed false/true respectively;
• φ ∨ ψ is witnessed true iff either φ or ψ is  and it is witnessed false iff both φ and ψ are
• φ∧ ψ is witnessed true iff both φ and ψ are witnessed true  and it is witnessed false iff either
• φ ⊃ ψ is witnessed true iff either φ is witnessed false or ψ is witnessed true  and it is

φ or ψ is witnessed false;

witnessed false;

witnessed false iff both φ is witnessed true and ψ is witnessed false.

We deﬁne a ∀-clause ∀(cid:126)xφ((cid:126)x) to be witnessed true in a partial model N for the set of names C if for
every binding of (cid:126)x to names (cid:126)c ∈ C  the resulting ground clause φ((cid:126)c) is witnessed true in N.
It is the witnessing of ∀-clauses that  in essence  enables the implicit learning of quantiﬁed generaliza-
tions. Let us see how that works. Intuitively  from examples φ((cid:126)c1)  . . .   one would like to generalize
to ∀(cid:126)xφ((cid:126)x)  the latter being a statement about inﬁnitely many objects. But what criteria would justify
this generalization  outside of (say) witnessing inﬁnitely many instances? Our result shows that 
surprisingly  it sufﬁces to get ﬁnitely many examples  so as to witness φ((cid:126)c1)  . . .   φ((cid:126)ck) and yield

4Note that since we assume that the resulting partial models are ﬁnite and thus countable  as long as the
masking processes are measurable functions w.r.t. the joint probability measure  every event deﬁned in terms of
the partial models is a countable union of measurable events  and thus measurable.

5

universally quantiﬁed sentences with high probability. This is possible because  via Theorem 2  all
the names not mentioned in the KB and the query behave identically. Thus  provided we witness the
grounding of φ for a sufﬁcient but ﬁnite set of constants  we can treat the implicit KB as including
∀-clauses  as it yields the same judgments on our queries.
Putting it all together  formally  in any given learning epoch  let S be the class of queries we are
interested in asking: that is  S is any ﬁnite set of ground formulas. Let C then be all the names
mentioned in S  the KB  and z extra new ones chosen arbitrarily  where z is at least the rank of the
KB. If z = KB’s rank  then the rank of the implicit KB matches that of the explicit KB; otherwise  it
would be higher. So the deﬁnition says that the witnessing of ∀(cid:126)xφ((cid:126)x) happens when φ((cid:126)c) is witnessed
for all (cid:126)c ∈ C. We think this notion is particularly powerful  as it neither makes references to bindings
from the full set of names N (which is inﬁnite)  nor to not observing negative instances. Note also
that witnessing does not require observing all atoms: a clause is witnessed to evaluate to true if some
literal appearing in it is true in the partial model. Thus  the ∀-clause witnessed may involve predicates
not explicitly appearing in the partial model.

Example 12: Let ∆ be the KB

{∀x (cid:54)= logan ⊃ Mutant(x) ∀x (cid:54)= y ⊃ [Mutant(x) ∧ Teammate(x  y) ⊃ Mutant(y)]}.

Then the ∀-clause ∀x (cid:54)= logan ⊃ [Mutant(x) ⊃ Teammate(x  logan)] is witnessed for a suitable set
of names w.r.t. ∆ (with rank two) in any example that mentions at least two other names (in addition
to logan) for which the substitution into Mutant(x) ⊃ Teammate(x  logan) is satisﬁed in the partial
model. For instance  we may have the partial model {Teammate(scott logan) Teammate(jean logan)} 
or the partial model {Teammate(ororo logan) Teammate(kurt logan)}.

Witnessed formulas correspond to the implicit KB. In order to capture the inferences that the implicit
KB permits  we will use partial models to simplify complex formulas in the KB or query. To that end 
we deﬁne:

Deﬁnition 13: Given a partial model N and a propositional formula φ  the restriction of φ under
N  denoted φ|N   is recursively deﬁned: if φ is an atom witnessed in N  then φ|N is the value that φ
is witnessed to evaluate to under N; if φ is an atom not set by N  then φ|N = φ; if φ = ¬ψ  then
φ|N = ¬(ψ|N ); and if φ = α ∧ β  then φ|N = (α|N ) ∧ (β|N ). (And analogously for Boolean
connectives ∨ and ⊃ .) For a partial model N and set of propositional formulas F   we let F|N denote
the set {φ|N : φ ∈ F}.
Notice that here we do not deﬁne restrictions for quantiﬁed formulas  such as those appearning in the
KB: while that is possible it is not needed  as we will be leveraging Theorem 2 for reasoning.
Example 14 : Consider GND−(∆) for the KB ∆ of Example 12 using the set of names
{scott jean logan}. Then the restriction of the grounding of our second rule under the partial model
{Teammate(scott logan) Teammate(jean logan) Teammate(scott jean)} is

Mutant(scott) ⊃ Mutant(logan)  [Mutant(logan) ∧ Teammate(logan scott) ⊃ Mutant(scott)] 
Mutant(jean) ⊃ Mutant(logan)  [Mutant(logan) ∧ Teammate(logan jean) ⊃ Mutant(jean)] 
Mutant(scott) ⊃ Mutant(jean)  [Mutant(jean) ∧ Teammate(jean scott) ⊃ Mutant(scott)].

Had the partial model also included Teammate(logan scott)  Teammate(logan jean)  and
Teammate(scott jean) we would have had the further simpler collection

Mutant(scott) ⊃ Mutant(logan)  Mutant(logan) ⊃ Mutant(scott) 
Mutant(jean) ⊃ Mutant(logan)  Mutant(logan) ⊃ Mutant(jean) 
Mutant(scott) ⊃ Mutant(jean)  Mutant(jean) ⊃ Mutant(scott).

5

Implicit Learnability

The central motivation here is learning to reason in FOL  and as argued earlier  implicit learning
circumvents the need for an explicit hypothesis  especially since hypothesis ﬁtting is intractable 
unless one severly restricts the hypothesis space. So  learning is integrated tightly into the application

6

using the knowledge extracted from data. Our deﬁnitions in the previous sections establish the
grounds for which a ﬁrst-order implict KB can be learned from ﬁnitely many ﬁnite-size examples 
but also the grounds for deciding propositional entailments of ∀-clauses speciﬁed explicitly – i.e.  the
background knowledge. (Of course  reasoning is not yet tractable  but simply decidable; we return
to this point later). Overall  the learning regime is presented in Algorithm 1  and its correctness is
justiﬁed in Theorem 15.

Algorithm 1 Reasoning with implicit learning

Input: Partial models N (1)  N (2)  . . .   N (m)  explicit KB ∆  query α (a ground formula)  number
of names k at least equal to ∆’s rank
Output: ˆp ∈ [0  1] estimating α is ˆp-valid (See Theorem 15)
Initialize v ← 0
for i = 1  . . .   m do

for all k-tuples of names (c1  . . .   ck) from N (i) not appearing in ∆ ∧ ¬α do

if GND(∆ ∧ ¬α {c1  . . .   ck})|N (i) is unsatisﬁable then
end if
end for

Increment v and skip to the next i.

end for
Return v/m

Theorem 15: Let δ  γ ∈ (0  1) and k ∈ N be given. Suppose we have m partial models drawn i.i.d.
from a common distribution D masked by a masking process Θ  where m ≥ 1
δ . (Here  ln
denotes the natural logarithm.) With probability at least 1 − δ  Algorithm 1 returns a value ˆp s.t.

2γ2 ln 2

I if ∆ ⊃ α is at most p-valid  ˆp ≤ p + γ
II if there is a KB I such that

1. ∆ ∧ I |= α 
2. the rank of ∆ ∧ I is at most k  and
3. with probability at least p over partial models N ∈ Θ(D)  there exists names c1  . . .   ck
not appearing in ∆ or α  such that every formula in I is witnessed true in N for
c1  . . .   ck together with the names appearing in ∆ and α

then ˆp ≥ p − γ.
Part I: ˆp ≤ p + γ if ∆ ⊃ α is at most p-valid. We ﬁrst note that when GND(∆ ∧
Proof:
¬α  C)|N (i) |= ⊥ for any set of names C  since N (i) is consistent with the actual model M (i) that
produced it  GND(∆ ∧ ¬α  C)|M (i) |= ⊥ as well. Thus  in this case  GND(∆ ∧ ¬α  C) is falsiﬁed
by M (i). Since |C| is at least the rank of ∆  it is easy to see that GND(∆ ∧ ¬α)  which is logically
equivalent to ∆ ∧ ¬α  is falsiﬁable at M (i). So  it must be that the negation of that theory (i.e. 
∆ ⊃ α) is satisﬁed at M (i).
Now  ∆ ⊃ α is by deﬁnition p-valid with respect to this distribution on M (i) if the probability that
∆ ⊃ α is satisﬁed by each M (i) is p. Moreover  it follows immediately from Hoeffding’s inequality
that for m ≥ 1
δ   the probability that the fraction of times ∆ ⊃ α is satisﬁed by M (i) (out of
m) exceeds p by more than γ is at most δ/2. Thus  ˆp  which is at most the fraction of times ∆ ⊃ α is
actually satisﬁed by M (i)  likewise is at most p + γ with probability at least 1 − δ/2.
Part II: rate of witnessing an implicit KB lower bounds ˆp. Note that by the grounding trick
(Theorem 2)  ∆ ∧ I |= α implies that for any set of names c1  . . .   ck not appearing in ∆ or α 
GND(∆∧I∧α {c1  . . .   ck}) |= ⊥. Suppose that I is witnessed true for c1  . . .   ck together with the
names in ∆ and α in N (i). We note that in the restricted formula GND(∆∧I∧¬α {c1  . . .   ck})|N (i) 
the groundings of formulas in I all simplify to 1 (true)  and so GND(∆∧I∧¬α {c1  . . .   ck})|N (i) =
GND(∆∧¬α {c1  . . .   ck})|N (i). Thus  GND(∆∧¬α {c1  . . .   ck})|N (i) |= ⊥  so v is incremented
on this iteration. Thus  indeed  ˆp = v/m is at least the fraction of times out of m that I is witnessed
true for some set of k names. It again follows from Hoeffding’s inequality that for m ≥ 1
δ   this
is at least p − γ with probability 1 − δ/2.

2γ2 ln 2

2γ2 ln 2

7

By a union bound  the two parts hold simultaneously with probability at least 1 − δ  as needed.

In essence  the no-overestimation condition is a soundness guarantee and the no-underestimation
condition is a limited completeness guarantee: in other words  if the query logically follows from the
explicit KB and examples then the algorithm returns success with an appropriate ˆp  and vice versa.
Note that the number of examples m needed (to answer a single query) depends only on the desired
accuracy γ and conﬁdence δ. It is independent of the size of the KB  the number of predicates  etc.
Example 16: Continuing Examples 12 and 14  we noted that the ∀-clause
∀x (cid:54)= logan ⊃ [Mutant(x) ⊃ Teammate(x logan)]

was witnessed w.r.t. ∆ for partial models such as {Teammate(scott logan)  Teammate(jean logan)}
or {Teammate(ororo logan)  Teammate(kurt logan)}. This formula could serve as an implicit
KB if Θ(D) produces such examples; it completes a proof of Mutant(logan) by ﬁrst inferring
Mutant(x) for some x (cid:54)= logan from the ﬁrst rule of ∆  using this implicit KB formula to infer
Teammate(x logan)  and ﬁnally using the second rule of ∆ to infer Mutant(logan). In these partial
models  respectively  the restricted grounding of ∆ correspondingly produces Mutant(scott) and
Mutant(scott) ⊃ Mutant(logan)  or Mutant(ororo) and Mutant(ororo) ⊃ Mutant(logan)  which in
each case allows us to prove the query Mutant(logan)  via a different individual depending on the
names mentioned in the partial example. Observe that ∆ does not allow us to infer that the Teammate
relation holds for any individuals  whereas the data alone  which only gives positive examples of
the Teammate relation  is not adequate to infer the Mutant relation. We need both to establish
Mutant(logan).

6 Tractable Reasoning

Algorithm 1 reduces reasoning with implicit learning to deciding entailment. In order to obtain a
tractable algorithm  we generally need to restrict the reasoning task somehow. One approach  taken in
the previous work on propositional implicit learning [11]  is to “promise” that the query is provable in
some low-complexity fragment; for example  it is provable by a small treelike resolution proof (where
“small” refers to the number of lines of the proof). Equivalently  we give up on completeness  and
only seek completeness with respect to conclusions provable in low complexity in a given fragment.
In general  then  one obtains a running time guarantee that is parameterized by the size of the proof
of the query. We can take a similar approach here  by using an algorithm for deciding entailment that
is efﬁcient when parameterized in such terms. In general  what is needed is a fragment for which
we can decide the existence of proofs efﬁciently  and that is “restriction-closed ” meaning that for
any partial model N  if we consider the restriction of each line of the proof  we obtain a proof in the
same fragment. Most fragments we might consider  including speciﬁcally treelike or bounded-width
resolution  are restriction-closed. (See [10] for details.)
We will motivate an entirely new strategy here  which offers a semantic perspective to the proof-
theoretic view in [11]. One classically sound model-theoretic approach to constraining propositional
reasoning is to limit the power of the reasoner  as represented  for example  by the work on tautological
entailment [16]. More recently  [20] suggest a simple evaluation scheme for proper+ KBs that
gradually increases the power of the reasoner: level 0 is standard database lookup together with unit
propagation  level 1 allows for one case split in a clause  level 2 allows two case splits  and so on. The
formal intuition is as follows: suppose s is a set of ground clauses and φ is a ground query  and let us
say its a clause for simplicity. Let U(s) denote the the closure of s under unit propagation  deﬁned as
the least set s(cid:48) satisfying: (a) s ⊆ s(cid:48) and (b) if literal l ∈ s(cid:48) and (¬l ∨ c) ∈ s(cid:48) then c ∈ s(cid:48). Then let
V(s) deﬁne all possible weakenings: {c | c is a ground clause and there is a c(cid:48) ∈ U(s) s.t. c(cid:48) ⊆ c} .
Then we deﬁne s |=z φ (read: “entails at levels z") iff one of the following holds:

• subsume: z = 0  and φ ∈ V(s);
• split: z > 0 and there is some clause c ∈ s such that for all literals l ∈ c  s ∪ {l} |=(z−1) φ.

For small values of z  entailment at level z is tractable to decide as well as sound:
Theorem 17: [20] Suppose ∆  φ are propositional formulas and z ∈ N. Then  determining if
∆ |=z φ can be done in time O((|φ||∆|)z+1). Moreover  if ∆ |=z φ then ∆ |= φ.

8

We will now see how to leverage these results. First  however  we need the equivalent to restriction-
closed  as discussed above.
Proposition 18: Suppose φ  ∆  z are as above. Then if ∆ |=z φ  and N is any partial model then
(∆|N ) |=z (φ|N ).
Basically  if φ is entailed at level z from ∆  then any restriction of φ under N must also be entailed by
∆ restricted to N  at least at level z if not lower. Notice that restricting a ground formula is equivalent
(w.r.t. satisﬁability) to simply conjoining the literals true at N with that formula  from which the
proof follows. Now  recall from Theorem 2  given a proper+ KB ∆ and ground query φ  we have
∆ |= φ iff GND−(∆ ∧ ¬α) is unsatisﬁable. Here  since α is already ground  we really only need
to make sure that ∆ is ground wrt all the names in ∆ ∧ ¬α and k new ones  k being the rank of ∆.
So let GNDα(∆) denote precisely such a grounding of ∆. It then follows that GNDα(∆) |= α iff
∆ |= α. It is easy to show that the same holds for |=z as well [20]. So let Algorithm 1(cid:48) be exactly
like Algorithm 1 except that it takes an additional parameter z (for limited reasoning) and replaces
the following check:

GND(∆ ∧ ¬α {c1  . . .   ck})|N (i) is unsatisﬁable
GND(∆ {c1  . . .   ck  d1  . . .   dm})|N (i)
names appearing in α but not in ∆.

with

|=z (α|N (i))  where {d1  . . .   dm} is the set of

2γ2 ln 2

Theorem 19: Let δ  γ ∈ (0  1)  k ∈ N  m ≥ 1
δ   and let z ∈ N. Then with a probability at
least 1 − δ  Algorithm 1(cid:48) returns a value ˆp such that: (I) and (II) is as in Theorem 15 except for (II.1)
which states that ∆ ∧ I |=z α. The algorithm runs in time O((|α||GNDα(∆)|)z+1m).
Discussion.
Interestingly  in [21]  it is shown that reasoning is also tractable in the ﬁrst-order case if
the knowledge base and the query both use a bounded number of variables. This would then mean
that we would no longer be limited to ground queries and can handle queries with quantiﬁers. This
direction is left for future research. Nonetheless  we note that deciding quantiﬁed (as opposed to
ground) queries appears to demand more from learning. In general  in an inﬁnite domain  we cannot
hope to observe in a ﬁnite partial model that universally quantiﬁed formulas are ever true. Thus 
we anticipate that extensions that handle queries with quantiﬁers will need a substantially different
framework  presumably with stronger assumptions. One possible framework takes a more credulous
approach to the learning problem (in contrast to our skeptical approach based on witnessing truth):
we suppose that when a formula is frequently false on the distribution of examples  we also frequently
obtain a partial model that witnesses the formula false—e.g.  a partial model in which a binding of a
candidate ∀-clause falsiﬁes it. This is undoubtedly an assumption about the benevolent nature of the
environment  captured as the notion of concealment in [25]  but it does make learning conceptually
simpler. In this framework  one permits all conclusions that are not explicitly falsiﬁed. Whether such
an idea can be used for inductive generalization of FOL formulas over arbitrary distributions remains
to be seen.

7 Conclusions

In this work  we presented new results on the problem of answering queries about formulas of ﬁrst-
order logic (FOL) based on background knowledge partially represented explicitly as other formulas 
and partially represented as examples independently drawn from a ﬁxed probability distribution.
By appealing to the paradigm of implicit learnability  we sidestepped many major negative results 
leading to a learning regime that works with a general and expressive FOL fragment. No restrictions
were posed on clause length  predicate arity  and other similar technical devices seen in PAC results.
Overall  we hope the simplicity of the framework is appealing to the readers and hope our results will
renew interest in learnability for expressive languages with quantiﬁcational power.

Acknowledgements

V. Belle was supported by a Royal Society University Research Fellowship. B. Juba was supported
by NSF Award CCF-1718380. This work was partially performed while B. Juba was visiting the
Simons Institute for the Theory of Computing. We thank our reviewers for their helpful suggestions.

9

References
[1] V. Belle. Open-universe weighted model counting. In AAAI  pages 3701–3708  2017.

[2] P. Billingsley. Probability and Measure. Wiley-Interscience  New York  NY  USA  3rd edition 

1995.

[3] W. W. Cohen. Tensorlog: A differentiable deductive database. Preprint  arXiv:1605.06523 

2016.

[4] W. W. Cohen and H. Hirsh. The learnability of description logics with equality constraints.

Machine Learning  17(2-3):169–199  1994.

[5] W. W. Cohen and C. D. Page. Polynomial learnability and inductive logic programming:

Methods and results. New Generation Computing  13(3-4):369–409  1995.

[6] A. Daniely and S. Shalev-Shwartz. Complexity theoretic limitations on learning DNF’s. In

COLT  pages 815–830  2016.

[7] L. De Raedt and S. Džeroski. First-order jk-clausal theories are PAC-learnable. Artiﬁcial

Intelligence  70(1):375–392  1994.

[8] R. Evans and E. Grefenstette. Learning explanatory rules from noisy data. Journal of Artiﬁcial

Intelligence Research  61:1–64  2018.

[9] G. D. Giacomo  Y. Lespérance  and H. J. Levesque. Efﬁcient reasoning in proper knowledge

bases with unknown individuals. In IJCAI  pages 827–832  2011.

[10] B. Juba. Learning implicitly in reasoning in PAC-semantics. Preprint  arXiv:1209.0056  2012.

[11] B. Juba. Implicit learning of common sense for reasoning. In IJCAI  pages 939–946  2013.

[12] M. J. Kearns  R. E. Schapire  and L. M. Sellie. Toward efﬁcient agnostic learning. Machine

Learning  17(2-3):115–141  1994.

[13] K. Kersting  S. Natarajan  and D. Poole. Statistical relational AI: Logic  probability and
computation. In International Conference on Logic Programming and Nonmonotonic Reasoning 
pages 1–9  2011.

[14] R. Khardon and D. Roth. Learning to reason with a restricted view. Machine Learning 

35(2):95–116  1999.

[15] G. Lakemeyer and H. J. Levesque. Evaluation-based reasoning with disjunctive information in

ﬁrst-order knowledge bases. In KR  pages 73–81  2002.

[16] H. Levesque. A logic of implicit and explicit belief. In AAAI  pages 198–202  1984.

[17] H. J. Levesque. A completeness result for reasoning with incomplete ﬁrst-order knowledge

bases. In KR  pages 14–23  1998.

[18] H. J. Levesque and G. Lakemeyer. The logic of knowledge bases. The MIT Press  Cambridge 

MA  USA  2001.

[19] Y. Liu and G. Lakemeyer. On ﬁrst-order deﬁnability and computability of progression for

local-effect actions and beyond. In IJCAI  pages 860–866  2009.

[20] Y. Liu  G. Lakemeyer  and H. J. Levesque. A logic of limited belief for reasoning with

disjunctive information. In KR  pages 587–597  2004.

[21] Y. Liu and H. J. Levesque. Tractable reasoning in ﬁrst-order knowledge bases with disjunctive

information. In AAAI  pages 639–644  2005.

[22] R. Manhaeve  S. Dumancic  A. Kimmig  T. Demeester  and L. De Raedt. Deepproblog: Neural
probabilistic logic programming. In Advances in Neural Information Processing Systems 31 
pages 3749–3759  2018.

10

[23] J. McCarthy and P. J. Hayes. Some philosophical problems from the standpoint of artiﬁcial

intelligence. In Machine Intelligence  pages 463–502  1969.

[24] L. Michael. Reading between the lines. In IJCAI  pages 1525–1530  2009.

[25] L. Michael. Partial observability and learnability. Artiﬁcial Intelligence  174(11):639–669 

2010.

[26] R. C. Moore. The role of logic in knowledge representation and commonsense reasoning. In

AAAI  pages 428–433  1982.

[27] S. Muggleton and L. De Raedt. Inductive logic programming: Theory and methods. The Journal

of Logic Programming  19:629–679  1994.

[28] M. Richardson and P. Domingos. Markov logic networks. Machine learning  62(1):107–136 

2006.

[29] T. Rocktäschel and S. Riedel. End-to-end differentiable proving.

Information Processing Systems 30  pages 3788–3800  2017.

In Advances in Neural

[30] S. Srivastava  S. J. Russell  P. Ruan  and X. Cheng. First-order open-universe POMDPs. In UAI 

pages 742–751  2014.

[31] L. G. Valiant. Robust logics. Artiﬁcial Intelligence  117(2):231–253  2000.

11

,Judy Hoffman
Sergio Guadarrama
Eric Tzeng
Ronghang Hu
Jeff Donahue
Ross Girshick
Trevor Darrell
Kate Saenko
Yi Xu
Qihang Lin
Tianbao Yang
Vaishak Belle
Brendan Juba