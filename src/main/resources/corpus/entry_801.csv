2017,Beyond Worst-case: A Probabilistic Analysis of Affine Policies in Dynamic Optimization,Affine policies (or control) are widely used as a solution approach in dynamic optimization where computing an optimal adjustable solution is usually intractable. While the worst case performance of affine policies can be significantly bad  the empirical performance is observed to be near-optimal for a large class of problem instances. For instance  in the two-stage dynamic robust optimization problem with linear covering constraints and uncertain right hand side  the worst-case approximation bound for affine policies is $O(\sqrt m)$ that is also tight (see Bertsimas and Goyal (2012))  whereas observed empirical performance is near-optimal. In this paper  we aim to address this stark-contrast between the worst-case and the empirical performance of affine policies. In particular  we  show that affine policies give a good approximation for the two-stage adjustable robust optimization problem with high probability on random instances where the constraint coefficients are generated i.i.d. from a large class of distributions; thereby  providing a theoretical justification of the observed empirical performance. On the other hand  we also present a distribution such that the performance bound for affine policies on instances generated according to that distribution is $\Omega(\sqrt m)$ with high probability; however  the constraint coefficients are not i.i.d.. This demonstrates that the empirical performance of affine policies can depend on the generative model for instances.,Beyond Worst-case: A Probabilistic Analysis of Afﬁne

Policies in Dynamic Optimization

Omar El Housni
IEOR Department
Columbia University

oe2148@columbia.edu

Vineet Goyal

IEOR Department
Columbia University

vg2277@columbia.edu

Abstract

Afﬁne policies (or control) are widely used as a solution approach in dynamic
optimization where computing an optimal adjustable solution is usually intractable.
While the worst case performance of afﬁne policies can be signiﬁcantly bad  the
empirical performance is observed to be near-optimal for a large class of problem
instances. For instance  in the two-stage dynamic robust optimization problem with
linear covering constraints and uncertain right hand side  the worst-case approx-
imation bound for afﬁne policies is O(pm) that is also tight (see Bertsimas and
Goyal [8])  whereas observed empirical performance is near-optimal. In this paper 
we aim to address this stark-contrast between the worst-case and the empirical
performance of afﬁne policies. In particular  we show that afﬁne policies give
a good approximation for the two-stage adjustable robust optimization problem
with high probability on random instances where the constraint coefﬁcients are
generated i.i.d. from a large class of distributions; thereby  providing a theoret-
ical justiﬁcation of the observed empirical performance. On the other hand  we
also present a distribution such that the performance bound for afﬁne policies on
instances generated according to that distribution is ⌦(pm) with high probabil-
ity; however  the constraint coefﬁcients are not i.i.d.. This demonstrates that the
empirical performance of afﬁne policies can depend on the generative model for
instances.

1

Introduction

In most real word problems  parameters are uncertain at the optimization phase and decisions need
to be made in the face of uncertainty. Stochastic and robust optimization are two widely used
paradigms to handle uncertainty. In the stochastic optimization approach  uncertainty is modeled as a
probability distribution and the goal is to optimize an expected objective [13]. We refer the reader
to Kall and Wallace [19]  Prekopa [20]  Shapiro [21]  Shapiro et al. [22] for a detailed discussion
on stochastic optimization. On the other hand  in the robust optimization approach  we consider
an adversarial model of uncertainty using an uncertainty set and the goal is to optimize over the
worst-case realization from the uncertainty set. This approach was ﬁrst introduced by Soyster [23] and
has been extensively studied in recent past. We refer the reader to Ben-Tal and Nemirovski [3  4  5] 
El Ghaoui and Lebret [14]  Bertsimas and Sim [10  11]  Goldfarb and Iyengar [17]  Bertsimas et
al. [6] and Ben-Tal et al. [1] for a detailed discussion of robust optimization. However  in both these
paradigms  computing an optimal dynamic solution is intractable in general due to the “curse of
dimensionality”.
This intractability of computing the optimal adjustable solution necessitates considering approximate
solution policies such as static and afﬁne policies where the decision in any period t is restricted
to a particular function of the sample path until period t. Both static and afﬁne policies have been

31st Conference on Neural Information Processing Systems (NIPS 2017)  Long Beach  CA  USA.

studied extensively in the literature and can be computed efﬁciently for a large class of problems.
While the worst-case performance of such approximate policies can be signiﬁcantly bad as compared
to the optimal dynamic solution  the empirical performance  especially of afﬁne policies  has been
observed to be near-optimal in a broad range of computational experiments. Our goal in this paper is
to address this stark contrast between the worst-case performance bounds and near-optimal empirical
performance of afﬁne policies.
In particular  we consider the following two-stage adjustable robust linear optimization problems
with uncertain demand requirements:

zAR (c  d  A  B U) = min

x

cT x + max
h2U

dT y(h)

min
y(h)

Ax + By(h)  h 8h 2U
x 2 Rn
+ 8h 2U

+  y(h) 2 Rn

+

+

  c 2 Rn

+  d 2 Rn

+  B 2 Rm⇥n

where A 2 Rm⇥n
. The right-hand-side h belongs to a compact
convex uncertainty set U✓ Rm
+ . The goal in this problem is to select the ﬁrst-stage decision x  and
the second-stage recourse decision  y(h)  as a function of the uncertain right hand side realization  h
such that the worst-case cost over all realizations of h 2U is minimized. We assume without loss of
generality that c = e and d = ¯d · e (by appropriately scaling A and B). Here  ¯d can interpreted as
the inﬂation factor for costs in the second-stage.
This model captures many important applications including set cover  facility location  network
design  inventory management  resource planning and capacity planning under uncertain demand.
Here the right hand side  h models the uncertain demand and the covering constraints capture the
requirement of satisfying the uncertain demand. However  the adjustable robust optimization problem
(1) is intractable in general. In fact  Feige et al. [16] show that ⇧AR(U) (1) is hard to approximate
within any factor that is better than ⌦(log n).
Both static and afﬁne policy approximations have been studied in the literature for (1). In a static
solution  we compute a single optimal solution (x  y) that is feasible for all realizations of the
uncertain right hand side. Bertsimas et al. [9] relate the performance of static solution to the
symmetry of the uncertainty set and show that it provides a good approximation to the adjustable
problem if the uncertainty is close to being centrally symmetric. However  the performance of static
solutions can be arbitrarily large for a general convex uncertainty set with the worst case performance
being ⌦(m). El Housni and Goyal [15] consider piecewise static policies for two-stage adjustable
robust problem with uncertain constraint coefﬁcients. These are a generalization of static policies
where we divide the uncertainty set into several pieces and specify a static solution for each piece.
However  they show that  in general  there is no piecewise static policy with a polynomial number of
pieces that has a signiﬁcantly better performance than an optimal static policy.
An afﬁne policy restricts the second-stage decisions  y(h) to being an afﬁne function of the uncertain
right-hand-side h  i.e.  y(h) = P h + q for some P 2 Rn⇥m and q 2 Rm are decision variables.
Afﬁne policies in this context were introduced in Ben-Tal et al. [2] and can be formulated as:

(1)

(2)

zA↵ (c  d  A  B U) = min

x P  q

cT x + max
h2U

dT (P h + q)

Ax + B (P h + q)  h 8h 2U
P h + q  0 8h 2U
x 2 Rn

+

An optimal afﬁne policy can be computed efﬁciently for a large class of problems. Bertsimas and
Goyal [8] show that afﬁne policies give a O(pm)-approximation to the optimal dynamic solution
for (1). Furthermore  they show that the approximation bound O(pm) is tight. However  the observed
empirical performance for afﬁne policies is near-optimal for a large set of synthetic instances of (1).

1.1 Our Contributions
Our goal in this paper is to address this stark contrast by providing a theoretical analysis of the
performance of afﬁne policies on synthetic instances of the problem generated from a probabilistic
model. In particular  we consider random instances of the two-stage adjustable problem (1) where the
entries of the constraint matrix B are random from a given distribution and analyze the performance
of afﬁne policies for a large class of distributions. Our main contributions are summarized below.

2

zA↵(c  d  A  B U) 

b

Independent and Identically distributed Constraint Coefﬁcients. We consider random instances
of the two-stage adjustable problem where the entries of B are generated i.i.d. according to a
given distribution and show that an afﬁne policy gives a good approximation for a large class of
distributions including distributions with bounded support and unbounded distributions with Gaussian
and sub-gaussian tails.
In particular  for distributions with bounded support in [0  b] and expectation µ  we show that for
sufﬁciently large values of m and n  afﬁne policy gives a b/µ-approximation to the adjustable
problem (1). More speciﬁcally  with probability at least (1  1/m)  we have that
where ✏ = b/µplog m/n (Theorem 2.1). Therefore  if the distribution is symmetric  afﬁne policy

gives a 2-approximation for the adjustable problem (1). For instance  for the case of uniform or
Bernoulli distribution with parameter p = 1/2  afﬁne gives a nearly 2-approximation for (1).
While the above bound leads to a good approximation for many distributions  the ratio b
µ can be
signiﬁcantly large in general; for instance  for distributions where extreme values of the support are
extremely rare and signiﬁcantly far from the mean. In such instances  the bound b/µ can be quite
loose. We can tighten the analysis by using the concentration properties of distributions and can
extend the analysis even for the case of unbounded support. More speciﬁcally  we show that if Bij
are i.i.d. according to an unbounded distribution with a sub-gaussian tail  then for sufﬁciently large
values of m and n  with probability at least (1  1/m) 

µ(1  ✏) · zAR(c  d  A  B U) 

zA↵(c  d  A  B U)  O(plog mn) · zAR(c  d  A  B U).

We prove the case of folded normal distribution in Theorem 2.6. Here we assume that the parameters
of the distributions are constants independent of the problem dimension and we would like to emphasis
that the i.i.d. assumption on the entries of B is for the scaled problem where c = e and d = ¯de.
We would like to note that the above performance bounds are in stark contrast with the worst case
performance bound O(pm) for afﬁne policies which is tight. For the random instances where Bij are
i.i.d. according to above distributions  the performance is signiﬁcantly better. Therefore  our results
provide a theoretical justiﬁcation of the good empirical performance of afﬁne policies and close
the gap between worst case bound of O(pm) and observed empirical performance. Furthermore 
surprisingly these performance bounds are independent of the structure of the uncertainty set  U
unlike in previous work where the performance bounds depend on the geometric properties of U.
Our analysis is based on a dual-reformulation of (1) introduced in [7] where (1) is reformulated as
an alternate two-stage adjustable optimization and the uncertainty set in the alternate formulation
depends on the constraint matrix B. Using the probabilistic structure of B  we show that the alternate
dual uncertainty set is close to a simplex for which afﬁne policies are optimal.
We would also like to note that our performance bounds are not necessarily tight and the actual
performance on particular instances can be even better. We test the empirical performance of afﬁne
policies for random instances generated according to uniform and folded normal distributions and
observe that afﬁne policies are nearly optimal with a worst optimality gap of 4% (i.e. approximation
ratio of 1.04) on our test instances as compared to the optimal adjustable solution that is computed
using a Mixed Integer Program (MIP).

Worst-case distribution for Afﬁne policies. While for a large class of commonly used distributions 
afﬁne policies give a good approximation with high probability for random i.i.d. instances according
to the given distribution  we present a distribution where the performance of afﬁne policies is ⌦(pm)
with high probability for instances generated from this distribution. Note that this matches the
worst-case deterministic bound for afﬁne policies. We would like to remark that in the worst-case
distribution  the coefﬁcients Bij are not identically distributed. Our analysis suggests that to obtain
bad instances for afﬁne policies  we need to generate instances using a structured distribution where
the structure of the distribution might depend on the problem structure.

2 Random instances with i.i.d. coefﬁcients

In this section  we theoretically characterize the performance of afﬁne policies for random instances
of (1) for a large class of generative distributions including both bounded and unbounded support

3

distributions. In particular  we consider the two-stage problem where constraint coefﬁcients A and
B are i.i.d. according to a given distribution. We consider a polyhedral uncertainty set U given as
(3)

U = {h 2 Rm

+ | Rh  r}

+

and r 2 RL

+. This is a fairly general class of uncertainty sets that includes many

where R 2 RL⇥m
commonly used sets such as hypercube and budget uncertainty sets.
Our analysis of the performance of afﬁne policies does not depend on the structure of ﬁrst stage
constraint matrix A or cost c. The second-stage cost  as already mentioned  is wlog of the form
d = ¯de. Therefore  we restrict our attention only to the distribution of coefﬁcients of the second
stage matrix B. We will use the notation ˜B to emphasis that B is random. For simplicity  we refer
to zAR (c  d  A  B U) as zAR (B) and to zA↵ (c  d  A  B U) as zA↵ (B).
2.1 Distributions with bounded support

We ﬁrst consider the case when ˜Bij are i.i.d. according to a bounded distribution with support in
[0  b] for some constant b independent of the dimension of the problem. We show a performance
bound of afﬁne policies as compared to the optimal dynamic solution. The bound depends only on the
distribution of ˜B and holds for any polyhedral uncertainty set U. In particular  we have the following
theorem.
Theorem 2.1. Consider the two-stage adjustable problem (1) where ˜Bij are i.i.d. according to
a bounded distribution with support in [0  b] and E[ ˜Bij] = µ 8i 2 [m] 8j 2 [n]. For n and m
sufﬁciently large  we have with probability at least 1  1
m 

zA↵( ˜B) 

b

µ(1  ✏) · zAR( ˜B)

where ✏ = b

µq log m

n .

The above theorem shows that for sufﬁciently large values of m and n  the performance of afﬁne
policies is at most b/µ times the performance of an optimal adjustable solution. Moreover  we know
that zAR( ˜B)  zA↵( ˜B) for any B since the adjustable problem is a relaxation of the afﬁne problem.
This shows that afﬁne policies give a good approximation (and signiﬁcantly better than the worst-case
bound of O(pm)) for many important distributions. We present some examples below.
Example 1. [Uniform distribution] Suppose for all i 2 [m] and j 2 [n] ˜Bij are i.i.d. uniform in
[0  1]. Then µ = 1/2 and from Theorem 2.1 we have with probability at least 1  1/m 

zA↵( ˜B) 

2

1  ✏ · zAR( ˜B)

where ✏ = 2plog m/n. Therefore  for sufﬁciently large values of n and m afﬁne policy gives a

2-approximation to the adjustable problem in this case. Note that the approximation bound of 2 is a
conservative bound and the empirical performance is signiﬁcantly better. We demonstrate this in our
numerical experiments.
Example 2. [Bernoulli distribution] Suppose for all i 2 [m] and j 2 [n]  ˜Bij are i.i.d. according
to a Bernoulli distribution of parameter p. Then µ = p  b = 1 and from Theorem 2.1 we have with
probability at least 1  1
m 

zA↵( ˜B) 

1

p(1  ✏) · zAR( ˜B)

pq log m

n . Therefore for constant p  afﬁne policy gives a constant approximation to the

where ✏ = 1
adjustable problem (for example 2-approximation for p = 1/2).
Note that these performance bounds are in stark contrast with the worst case performance bound
O(pm) for afﬁne policies which is tight. For these random instances  the performance is signiﬁcantly
better. We would like to note that the above distributions are very commonly used to generate
instances for testing the performance of afﬁne policies and exhibit good empirical performance.

4

Here  we give a theoretical justiﬁcation of the good empirical performance of afﬁne policies on such
instances  thereby closing the gap between worst case bound of O(pm) and observed empirical
performance. We discuss the intuition and the proof of Theorem 2.1 in the following subsections.

2.1.1 Preliminaries
In order to prove Theorem 2.1  we need to introduce certain preliminary results. We ﬁrst introduce
the following formulation for the adjustable problem (1) based on ideas in Bertsimas and de Ruiter
[7].

zdAR(B) = min

x

cT x + max
w2W

(w)(Ax)T w + rT (w)
min

where the set W is deﬁned as

RT (w)  w 8w 2W
x 2 Rn

+  (w) 2 RL

+  8w 2W

W = {w 2 Rm

+ | BT w  d}.

(4)

(5)

We show that the above problem is an equivalent formulation of (1).
Lemma 2.2. Let zAR(B) be as deﬁned in (1) and zdAR(B) as deﬁned in (4). Then  zAR(B) =
zdAR(B).
The proof follows from [7]. For completeness  we present it in Appendix A. Reformulation (4) can
be interpreted as a new two-stage adjustable problem over dualized uncertainty set W and decision
(w). Following [7]  we refer to (4) as the dualized formulation and to (1) as the primal formulation.
Bertsimas and de Ruiter [7] show that even the afﬁne approximations of (1) and (4) (where recourse
decisions are restricted to be afﬁne functions of respective uncertainties) are equivalent. In particular 
we have the following Lemma which is a restatement of Theorem 2 in [7].
Lemma 2.3. (Theorem 2 in Bertsimas and de Ruiter [7]) Let zdA↵(B) be the objective value
when (w) is restricted to be afﬁne function of w and zA↵(B) as deﬁned in (2). Then zdA↵(B) =
zA↵(B).

Bertsimas and Goyal [8] show that afﬁne policy is optimal for the adjustable problem (1) when the
uncertainty set U is a simplex. In fact  optimality of afﬁne policies for simplex uncertainty sets holds
for more general formulation than considered in [8]. In particular  we have the following lemma
Lemma 2.4. Suppose the set W is a simplex  i.e. a convex combination of m + 1 afﬁnely independent
points  then afﬁne policy is optimal for the adjustable problem (4)  i.e. zdA↵(B) = zdAR(B).
The proof proceeds along similar lines as in [8]. For completeness  we provide it in Appendix A.
In fact  if the uncertainty set is not simplex but can be approximated by a simplex within a small
scaling factor  afﬁne policies can still be shown to be a good approximation  in particular we have the
following lemma.
Lemma 2.5. Denote W the dualized uncertainty set as deﬁned in (5) and suppose there exists a
simplex S and   1 such that S✓W✓ ·S. Therefore  zdAR(B)  zdA↵(B)  · zdAR(B).
Furthermore  zAR(B)  zA↵(B)   · zAR(B).
The proof of Lemma 2.5 is presented in Appendix A.

2.1.2 Proof of Theorem 2.1
We consider instances of problem (1) where ˜Bij are i.i.d. according to a bounded distribution
with support in [0  b] and E[ ˜Bij] = µ for all i 2 [m]  j 2 [n]. Denote the dualized uncertainty set
w  ¯d · e}. Our performance bound is based on showing that ˜W can be
˜W = {w 2 Rm
sandwiched between two simplicies with a small scaling factor. In particular  consider the following
simplex 

+ | ˜B

T

+ 
b) .
S =(w 2 Rm
µ(1✏) · S with probability at least 1  1

mXi=1

wi 

¯d

b

5

(6)

m where ✏ = b

µq log m

n .

we will show that S✓ ˜W✓

First  we show that S✓ ˜W. Consider any w 2S . For any any i = 1  . . .   n

˜Bjiwj  b

mXj=1
The ﬁrst inequality holds because all components of ˜B are upper bounded by b and the second one
follows from w 2S . Hence  we have ˜B
Now  we show that the other inclusion holds with high probability. Consider any w 2 ˜W. We have
˜B

w  ¯de and consequently S✓ ˜W.

w  ¯d · e. Summing up all the inequalities and dividing by n  we get

wj  ¯d

mXj=1

T

T

˜Bji

mXj=1 Pn
Using Hoeffding’s inequality [18] (see Appendix B) with ⌧ = bq log m
 µ  ⌧!  1  exp✓2n⌧ 2

! · wj  ¯d.

P Pn

i=1
n

i=1
n

˜Bji

b2 ◆ = 1 

n   we have

1
m2

(7)

and a union bound over j = 1  . . .   m gives us

P Pn

i=1
n

˜Bji

1

m2◆m

 1 

1
m

.

 µ  ⌧ 8j = 1  . . .   m! ✓1 
µ  ⌧ Pn

! · wj 

i=1
n

¯d

1

b

b

b

=

¯d
b

˜Bji

wj 

where the last inequality follows from Bernoulli’s inequality. Therefore  with probability at least
1  1

m  we have

mXj=1

(µ  ⌧ )

mXj=1
µ(1✏) · S for any w 2 ˜W and consequently S✓ ˜W✓

µ(1  ✏) ·
where the second inequality follows from (7). Note that for m sufﬁciently large   we have µ  ⌧> 0.
µ(1✏) · S with probability at
Then  w 2
⇤
least 1  1/m. Finally  we apply the result of Lemma 2.5 to conclude.
2.2 Unbounded distributions
While the approximation bound in Theorem 2.1 leads to a good approximation for many distributions 
the ratio b/µ can be signiﬁcantly large in general. We can tighten the analysis by using the concen-
tration properties of distributions and can extend the analysis even for the case of distributions with
unbounded support and sub-gaussian tails. In this section  we consider the special case where ˜Bij are
i.i.d. according to absolute value of a standard Gaussian  also called the folded normal distribution 
and show a logarithmic approximation bound for afﬁne policies. In particular  we have the following
theorem.
Theorem 2.6. Consider the two-stage adjustable problem (1) where 8i 2 [n]  j 2 [m]  ˜Bij = | ˜Gij|
and ˜Gij are i.i.d. according to a standard Gaussian distribution. For n and m sufﬁciently large  we
have with probability at least 1  1
m 
where  = Oplog m + log n.
bound for the class of distributions with sub-gaussian tails. The bound of Oplog m + log n

depends on the dimension of the problem unlike the case of uniform bounded distribution. But  it is
signiﬁcantly better than the worst-case of O(pm) [8] for general instances. Furthermore  this bound
holds for all uncertainty sets with high probability. We would like to note though that the bounds are
not necessarily tight. In fact  in our numerical experiments where the uncertainty set is a budget of
uncertainty  we observe that afﬁne policies are near optimal.

The proof of Theorem 2.6 is presented in Appendix C. We can extend the analysis and show a similar

zA↵( ˜B)   · zAR( ˜B)

6

3 Family of worst-case distribution: perturbation of i.i.d. coefﬁcients

For any m sufﬁciently large  the authors in [8] present an instance where afﬁne policy is ⌦(m 1
2)
away from the optimal adjustable solution. The parameters of the instance in [8] were carefully
chosen to achieve the gap ⌦(m 1
2). In this section  we show that the family of worst-case instances
is not measure zero set. In fact  we exhibit a distribution and an uncertainty set such that a random
instance from that distribution achieves a worst-case bound of ⌦(pm) with high probability. The
coefﬁcients ˜Bij in our bad family of instances are independent but not identically distributed. The
instance can be given as follows.

n = m  A = 0  c = 0  d = e
U = conv (0  e1  . . .   em  ⌫1  . . .   ⌫m) where ⌫i =
˜Bij =⇢ 1

(e  ei) 8i 2 [m].
if i = j
if i 6= j where for all i 6= j  ˜uij are i.i.d. uniform[0  1].
Theorem 3.1. For the instance deﬁned in (8)  we have with probability at least 1  1/m 
zA↵( ˜B) =⌦( pm) · zAR( ˜B).

1pm · ˜uij

1
pm

(8)

We present the proof of Theorem 3.1 in Appendix D. As a byproduct  we also tighten the lower bound
on the performance of afﬁne policy to ⌦(pm) improving from the lower bound of ⌦(m 1
2) in [8].
We would like to note that both uncertainty set and distribution of coefﬁcients in our instance (8) are
carefully chosen to achieve the worst-case gap. Our analysis suggests that to obtain bad instances for
afﬁne policies  we need to generate instances using a structured distribution as above and it may not
be easy to obtain bad instances in a completely random setting.

4 Performance of afﬁne policy: Empirical study

In this section  we present a computational study to test the empirical performance of afﬁne policy
for the two-stage adjustable problem (1) on random instances.
Experimental setup. We consider two classes of distributions for generating random instances:
i) Coefﬁcients of ˜B are i.i.d. uniform [0  1]  and ii) Coefﬁcients of ˜B are absolute value of i.i.d.
standard Gaussian. We consider the following budget of uncertainty set.

Note that the set (9) is widely used in both theory and practice and arises naturally as a consequence of
concentration of sum of independent uncertain demand requirements. We would like to also note that
the adjustable problem over this budget of uncertainty  U is hard to approximate within a factor better
than O(log n) [16]. We consider n = m  d = e. Also  we consider c = 0  A = 0. We restrict to
this case in order to compute the optimal adjustable solution in a reasonable time by solving a single
Mixed Integer Program (MIP). For the general problem  computing the optimal adjustable solution
requires solving a sequence of MIPs each one of which is signiﬁcantly challenging to solve. We
would like to note though that our analysis does not depend on the ﬁrst stage cost c and matrix A and
afﬁne policy can be computed efﬁciently even without this assumption. We consider values of m from
10 to 50 and consider 20 instances for each value of m. We report the ratio r = zA↵( ˜B)/zAR( ˜B) in
Table 1. In particular  for each value of m  we report the average ratio ravg  the maximum ratio rmax 
the running time of adjustable policy TAR(s) and the running time of afﬁne policy TA↵(s). We ﬁrst
give a compact LP formulation for the afﬁne problem (2) and a compact MIP formulation for the
separation of the adjustable problem(1).
LP formulations for the afﬁne policies. The afﬁne problem (2) can be reformulated as follows

zA↵(B) = min 8><>:

cT x + z 

z  dT (P h + q) 8h 2U
Ax + B (P h + q)  h 8h 2U
P h + q  0 8h 2U
x 2 Rn

+

7

.

9>=>;

U =(h 2 [0  1]m

mXi=1

hi  pm) .

(9)

Note that this formulation has inﬁnitely many constraints but we can write a compact LP formulation
using standard techniques from duality. For example  the ﬁrst constraint is equivalent to z  dT q 
max {dT P h | Rh  r  h  0}. By taking the dual of the maximization problem  the constraint
becomes z  dT q  min {rT v | RT v  P T d  v  0}. We can then drop the min and introduce v
as a variable  hence we obtain the following linear constraints z  dT q  rT v   RT v  P T d and
v  0. We can apply the same techniques for the other constraints. The complete LP formulation
and its proof of correctness is presented in Appendix E.
Mixed Integer Program Formulation for the adjustable problem (1). For the adjustable prob-
lem (1)  we show that the separation problem (10) can be formulated as a mixed integer program.
The separation problem can be formulated as follows: Given ˆx and ˆz decide whether

max {(h  Aˆx)T w | w 2W   h 2U} > ˆz

(10)

The correctness of formulation (10) follows from equation (11) in the proof of Lemma 2.2 in
Appendix A. The constraints in (10) are linear but the objective function contains a bilinear term 
hT w. We linearize this using a standard digitized reformulation. In particular  we consider ﬁnite bit
representations of continuous variables  hi nd wi to desired accuracy and introduce additional binary
variables  ↵ik  ik where ↵ik and ik represents the kth bits of hi and wi respectively. Now  for any
i 2 [m]  hi · wi can be expressed as a bilinear expression with products of binary variables  ↵ik · ij
which can be linearized using additional variable ijk and standard linear inequalities: ijk  ij 
ijk  ↵ik  ijk + 1  ↵ik + ij. The complete MIP formulation and the proof of correctness is
presented in Appendix E.
For general A 6= 0  we need to solve a sequence of MIPs to ﬁnd the optimal adjustable solution. In
order to compute the optimal adjustable solution in a reasonable time  we assume A = 0  c = 0 in
our experimental setting so that we only need to solve one MIP.

Results. In our experiments  we observe that the empirical performance of afﬁne policy is near-
optimal.
In particular  the performance is signiﬁcantly better than the theoretical performance
bounds implied in Theorem 2.1 and Theorem 2.6. For instance  Theorem 2.1 implies that afﬁne
policy is a 2-approximation with high probability for random instances from a uniform distribution.
However  in our experiments  we observe that the optimality gap for afﬁne policies is at most 4%
(i.e. approximation ratio of at most 1.04). The same observation holds for Gaussian distributions

as well Theorem 2.6 gives an approximation bound of O(plog(mn)). We would like to remark
that we are not able to report the ratio r for large values of m because the adjustable problem is
computationally very challenging and for m  40  MIP does not solve within a time limit of 3 hours
for most instances . On the other hand  afﬁne policy scales very well and the average running time is
few seconds even for large values of m. This demonstrates the power of afﬁne policies that can be
computed efﬁciently and give good approximations for a large class of instances.

m ravg
1.01
10
1.02
20
1.01
30
50
**

TAR(s)
10.55
110.57
761.21

rmax
1.03
1.04
1.02
**
**
(a) Uniform

TA↵(s)
0.01
0.23
1.29
14.92

m ravg
1.00
10
1.01
20
1.01
30
50
**

rmax
1.03
1.03
1.03
**

TAR(s)
12.95
217.08
594.15

**

TA↵(s)
0.01
0.39
1.15
13.87

(b) Folded Normal

Table 1: Comparison on the performance and computation time of afﬁne policy and optimal adjustable
policy for uniform and folded normal distributions. For 20 instances  we compute zA↵( ˜B)/zAR( ˜B)
and present the average and max ratios. Here  TAR(s) denotes the running time for the adjustable
policy and TA↵(s) denotes the running time for afﬁne policy in seconds. ** Denotes the cases when
we set a time limit of 3 hours. These results are obtained using Gurobi 7.0.2 on a 16-core server with
2.93GHz processor and 56GB RAM.

8

References
[1] A. Ben-Tal  L. El Ghaoui  and A. Nemirovski. Robust optimization. Princeton University press  2009.

[2] A. Ben-Tal  A. Goryashko  E. Guslitzer  and A. Nemirovski. Adjustable robust solutions of uncertain linear

programs. Mathematical Programming  99(2):351–376  2004.

[3] A. Ben-Tal and A. Nemirovski. Robust convex optimization. Mathematics of Operations Research 

23(4):769–805  1998.

[4] A. Ben-Tal and A. Nemirovski. Robust solutions of uncertain linear programs. Operations Research

Letters  25(1):1–14  1999.

[5] A. Ben-Tal and A. Nemirovski. Robust optimization–methodology and applications. Mathematical

Programming  92(3):453–480  2002.

[6] D. Bertsimas  D. Brown  and C. Caramanis. Theory and applications of robust optimization. SIAM review 

53(3):464–501  2011.

[7] D. Bertsimas and F. J. de Ruiter. Duality in two-stage adaptive linear optimization: Faster computation and

stronger bounds. INFORMS Journal on Computing  28(3):500–511  2016.

[8] D. Bertsimas and V. Goyal. On the Power and Limitations of Afﬁne Policies in Two-Stage Adaptive

Optimization. Mathematical Programming  134(2):491–531  2012.

[9] D. Bertsimas  V. Goyal  and X. Sun. A geometric characterization of the power of ﬁnite adaptability in
multistage stochastic and adaptive optimization. Mathematics of Operations Research  36(1):24–54  2011.

[10] D. Bertsimas and M. Sim. Robust Discrete Optimization and Network Flows. Mathematical Programming

Series B  98:49–71  2003.

[11] D. Bertsimas and M. Sim. The Price of Robustness. Operations Research  52(2):35–53  2004.

[12] F. Chung and L. Lu. Concentration inequalities and martingale inequalities: a survey. Internet Mathematics 

3(1):79–127  2006.

[13] G. Dantzig. Linear programming under uncertainty. Management Science  1:197–206  1955.

[14] L. El Ghaoui and H. Lebret. Robust solutions to least-squares problems with uncertain data. SIAM Journal

on Matrix Analysis and Applications  18:1035–1064  1997.

[15] O. El Housni and V. Goyal. Piecewise static policies for two-stage adjustable robust linear optimization.

Mathematical Programming  pages 1–17  2017.

[16] U. Feige  K. Jain  M. Mahdian  and V. Mirrokni. Robust combinatorial optimization with exponential

scenarios. Lecture Notes in Computer Science  4513:439–453  2007.

[17] D. Goldfarb and G. Iyengar. Robust portfolio selection problems. Mathematics of Operations Research 

28(1):1–38  2003.

[18] W. Hoeffding. Probability inequalities for sums of bounded random variables. Journal of the American

statistical association  58(301):13–30  1963.

[19] P. Kall and S. Wallace. Stochastic programming. Wiley New York  1994.

[20] A. Prékopa. Stochastic programming. Kluwer Academic Publishers  Dordrecht  Boston  1995.

[21] A. Shapiro. Stochastic programming approach to optimization under uncertainty. Mathematical Program-

ming  Series B  112(1):183–220  2008.

[22] A. Shapiro  D. Dentcheva  and A. Ruszczy´nski. Lectures on stochastic programming: modeling and theory.

Society for Industrial and Applied Mathematics  2009.

[23] A. Soyster. Convex programming with set-inclusive constraints and applications to inexact linear program-

ming. Operations research  21(5):1154–1157  1973.

9

,Omar El Housni
Vineet Goyal
Alexandre Marques
Remi Lam
Karen Willcox