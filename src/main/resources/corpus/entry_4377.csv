2011,Predicting response time and error rates in visual search,A model of human visual search is proposed. It predicts both response time (RT) and error rates (RT) as a function of image parameters such as target contrast and clutter. The model is an ideal observer  in that it optimizes the Bayes ratio of tar- get present vs target absent. The ratio is computed on the firing pattern of V1/V2 neurons  modeled by Poisson distributions. The optimal mechanism for integrat- ing information over time is shown to be a ‘soft max’ of diffusions  computed over the visual field by ‘hypercolumns’ of neurons that share the same receptive field and have different response properties to image features. An approximation of the optimal Bayesian observer  based on integrating local decisions  rather than diffusions  is also derived; it is shown experimentally to produce very similar pre- dictions. A psychophyisics experiment is proposed that may discriminate between which mechanism is used in the human brain.,Predicting response time and error rates in visual

search

Bo Chen
Caltech

bchen3@caltech.edu

Vidhya Navalpakkam

Yahoo! Research

nvidhya@yahoo-inc.com

Pietro Perona

Caltech

perona@caltech.edu

Abstract

A model of human visual search is proposed. It predicts both response time (RT)
and error rates (RT) as a function of image parameters such as target contrast and
clutter. The model is an ideal observer  in that it optimizes the Bayes ratio of target
present vs target absent. The ratio is computed on the ﬁring pattern of V1/V2 neu-
rons  modeled by Poisson distributions. The optimal mechanism for integrating
information over time is shown to be a ‘soft max’ of diffusions  computed over
the visual ﬁeld by ‘hypercolumns’ of neurons that share the same receptive ﬁeld
and have different response properties to image features. An approximation of the
optimal Bayesian observer  based on integrating local decisions  rather than diffu-
sions  is also derived; it is shown experimentally to produce very similar predic-
tions to the optimal observer in common psychophysics conditions. A psychophy-
isics experiment is proposed that may discriminate between which mechanism is
used in the human brain.

A

Figure 1: Visual search. (A) Clutter and camouﬂage make visual search difﬁcult. (B C) Psychologists and
neuroscientists build synthetic displays to study visual search. In (B) the target ‘pops out’ (∆θ = 450)  while
in (C) the target requires more time to be detected (∆θ = 100) [1].

B

C

1

Introduction

Animals and humans often use vision to ﬁnd things: mushrooms in the woods  keys on a desk  a
predator hiding in tall grass. Visual search is challenging because the location of the object that
one is looking for is not known in advance  and surrounding clutter may generate false alarms. The
three ecologically relevant performance parameters of visual search are the two error rates (ER):
false alarms (FA) and false rejects (FR)  and response time (RT). The design of a visual system is
crucial in obtaining low ER and RT. These parameters may be traded off by manipulating suitable
thresholds [2  3  4].
Psychologists and physiologists have long been interested in understanding the performance and the
mechanisms of visual search. In order to approach this difﬁcult problem they present human sub-
jects with synthetic stimuli composed of a variable number of ‘items’ which may include a ‘target’

1

and multiple ‘distractors’ (see Fig. 1). By varying the number of items one may vary the amount of
clutter; by designing different target-distractor pairs one may probe different visual cues (contrast 
orientation  color  motion) and by varying the visual distinctiveness of the target vis-a-vis the dis-
tractors one may study the effect of the signal-to-noise ratio (SNR). Several studies since 1980s have
investigated how RT and ER are affected by the complexity of the stimulus (number of distractors) 
and by target-distractor discriminability with different visual cues. One early observation is that
when the target and distractor features are widely separated in feature space (e.g.  red target among
green distractors)  the target ‘pops out’. In these situations the ER is nearly zero  and the slope of
RT vs. setsize is ﬂat  i.e.  RT to ﬁnd the target is independent of number of items in the display [1].
Decreasing the discriminability between the target and distractor increases error rates  and increases
the slope of RT vs. setsize [5]. Moreover  it was found that the RT for displays with no target is
longer than where the target is present (see review in [6]). Recent studies investigated the shape of
RT distributions in visual search [7  8].
Neurophysiologically plausible models have been recently proposed to predict RTs in visual discrim-
ination tasks [9] and various other 2AFC tasks [10] at a single spatial location in the visual ﬁeld.
They are based on sequential tests of statistical hypotheses (target present vs target absent) [11] com-
puted on the response of stimulus-tuned neurons [2  3]. We do not yet have satisfactory models for
explaining RTs in visual search  which is harder as it involves integrating information across several
locations across the visual ﬁeld  as well as time. Existing models predicting RT in visual search are
either qualitative (e.g. [12]) or descriptive (e.g.  the drift-diffusion model [13  14  15])  and do not
attempt to predict experimental results with new set sizes  target and distractor settings.
We propose a Bayesian model of visual search that predicts both ER and RT. Our study makes a
number of contributions. First  while visual search has been modeled using signal-detection theory
to predict ER [16]  our model is based on neuron-like mechanisms and predicts both ER and RT.
Second  our model is an optimal observer  given a physiologically plausible front-end of the visual
system. Third  our model shows that in visual search the optimal computation is not a diffusion  as
one might believe by analogy with single-location discrimination models [17  18]  rather  it is a ‘soft-
max’ nonlinear combination of locally-computed diffusions. Fourth  we study a physiologically
parsimonious approximation to the optimal observer  we show that it is almost optimal when the
characteristics of the task are known in advance and held constant  and we explore whether there are
psychophysical experiments that could discriminate between the two models.
Our model is based on a number of simplifying assumptions. First  we assume that stimulus items
are centered on cortical hypercolumns [19] and at locations where there is no item neuronal ﬁring is
negligible. Second  retinal and cortical magniﬁcation [19] are ignored  since psychophysicists have
developed displays that sidestep this issue (by placing items on a constant-eccentricity ring as shown
in Fig 1). Third  we do not account for overt and covert attentional shifts. Overt attentional shifts
are manifested by saccades (eye motions)  which happen every 200ms or so. Since the post-decision
motor response to a stimulus by pressing a button takes about 250-300ms  one does not need to
worry about eye motions when response times are shorter than 500ms. For longer RTs  one may
enforce eye ﬁxation at the center of the display so as to prevent overt attentional shifts. Furthermore 
our model explains serial search without the need to invoke covert attentional shifts [20] which are
difﬁcult to prove neurophysiologically.

2 Target discrimination at a single location with Poisson neurons

We ﬁrst consider probabilistic reasoning at one location  where two possible stimuli may appear.
The stimuli differ in one respect  e.g. they have different orientations θ(1) and θ(2). We will call
them distractor (D) and target (T)  also labeled C = 1 and C = 2 (call c ∈ {1  2} the generic value
of C). Based on the response of N neurons (a hypercolumn) we will decide whether the stimulus
was a target or a distractor. Crucially  a decision should be reached as soon as possible  i.e. as soon
as there is sufﬁcient evidence for T or D [11].
Given the evidence T (deﬁned further below in terms of the neurons’ activity) we wish to decide
whether the stimulus was of type 1 or 2. We may do so when the probability P (C = 1|T ) of the
stimulus being of type 1 given the observations in T exceeds a given threshold T1 (T1 = 0.99).
We may instead decide in favor of C = 2 e.g. when P (C = 1|T ) < T2 (e.g. T2 = 0.01). If

2

Figure 2: (Left three panels) Model of a hypercolumn in V1/V2 cortex composed of four orientation-tuned
neurons (our simulations use 32). The left panel shows the neurons’ tuning curve λ(θ) representing the expected
Poisson ﬁring rate when the stimulus has orientation θ. The middle plot shows the expected ﬁring rate of the
population of neurons for two stimuli whose orientation is indicated with a red (distractor) and green (target)
vertical line. The third plot shows the step-change in the value of the diffusion when an action potential is
registered from a given neuron. (Right panel) Diagram of the decision models. (A) One-location Bayesian
observer. The action potentials of a hypercolumn of neurons (top) are integrated in time to produce a diffusion.
When the diffusion reaches either an upper bound T1 or a lower bound T0 the decision is taken that either
the target is present (1) or the target is absent (0). (B–D) Multi-location ideal Bayesian observer. (B) While
not a diffusion  it may be seen as a ‘soft maximum’ combination of local diffusions: the local diffusions are
ﬁrst exponentiated  then averaged; the log of the result is compared to two thresholds to reach a decision. (C)
The ‘Max approximation’ is a simpliﬁed approximation of the ideal observer  where the maximum of local
diffusions replaces a soft-maximum. (D) Equivalently  in the Max approximation decisions are reached locally
and combined by logical operators. The white AND in a dark ﬁeld indicates inverted AND of multiple inverted
inputs.

P (C = 1|T ) ∈ (T2  T1) we will wait for more evidence. Thus  we need to compute P (C = 1|T ) :

Pr(C = 1|T ) =

where R(T ) =

1

1 + P (C=2|T )
P (C=1|T )
P (T |C = 2)
P (T |C = 1)

1

=
1 + R(T ) P (C=2)
P (C = 2|T )
P (C = 1|T )

P (C=1)

P (C = 1)
P (C = 2)

=

(1)
where P (C = 1) = 1 − P (C = 2) is the prior probability of C = 1. Thus  it is equivalent to take
decisions by thresholding log R(T )1; we will elaborate on this in Sec. 3.
We will model the ﬁring rate of the neurons with a Poisson pdf: the number n of action potentials
that will be observed during one second is distributed as P (n|λ) = λne−λ/n!. The constant λ is
the expectation of the number of action potentials per second. Each neuron i ∈ {1  . . .   N} is tuned
to a different orientation θi; for the sake of simplicity we will assume that the width of the tuning
curve is the same for all neurons; i.e. each neuron i will respond to stimulus c with expectation
c = f (|θ(c)−θi|) (in spikes per second) which are determined by the distance between the neuron’s
λi
preferred orientation θi and by the stimulus orientation θ(c).
Let Ti = {ti

k} be the set of action potentials from neuron i produced starting at t = 0 and until
the end of the observation period t = T . Indicate with T = {tk} = (cid:83)i Ti the complete set of
action potentials from all neurons (where the tk are sorted). We will indicate with i(k) the index of
the neuron who ﬁred the action potential at time tk. Call Ik = (tk tk+1) the intervals of time in
between action potentials  where I0 = (0 t1). These intervals are open i.e. they do not contain the
boundaries  hence they do not contain the action potentials.
The signal coming from the neurons is thus a concatenation of ‘spikes’ and ‘intervals’  and the
interval (0  T ) may be viewed as the union of instants tk and open intervals (tk  tk+1). i.e. (0  T ) =

I0(cid:83) t1(cid:83) I1(cid:83) t2(cid:83)···

Since the spike trains Ti and T are Poisson processes  once we condition on the class of the stimulus
the spike times are independent. This implies that: P (T |C = c) = ΠkP (Ik|C = c)P (tk|C = c).
This may be proven by dividing up (0  T ) into smaller and smaller intervals and taking the limit for

1We use base 10 for all our logarithms and exponentials  i.e. log(x) ≡ log10(x) and exp(x) ≡ 10x.

3

05010015001234567891011Stimulus orientation (cid:101) (degrees)Expected firing rate (cid:104) (spikes per second)Neurons’ tuning curves050100150024681012Mean spiking rate per secondNeuron’s preferred orientation (cid:101) (degrees)Poisson (cid:104) (spikes/s)  (cid:101)D(cid:101)T(cid:104) (D (cid:101)i) per s(cid:104) (T (cid:101)i) per s050100150(cid:239)0.25(cid:239)0.2(cid:239)0.15(cid:239)0.1(cid:239)0.0500.050.10.150.20.25Diffusion jump caused by action potentialNeuron’s preferred orientation (cid:101) (degrees)diffusion jump per spike  (cid:101)D=90o(cid:101)T=105ojump on spikeinterspike drift per s=0.01<T0>T101explog￿Bexp...<T0>T101<T0>T101<T0>T101<T0>T101￿dt￿dtmaxAC￿dt...￿dt￿dt...￿dt￿dt...<T00ANDOR01...Dthe size of the intervals going to zero. The intervals containing action potentials converge to the ti
and the intervals not containing action potentials may be merged into the intervals Ii.
Let’s analyze separately the log likelihood ratio for the intervals and for the spikes.

Diffusion drift during the intervals. During the intervals no neuron spiked. The ratio therefore
is computed as a function of the Poissons P (n = 0|λ) when the spike count n is zero. The Poisson
expectation has to be multiplied by the time-length of the interval; call ∆tk = tk+1 − tk the length
of the interval Ik. Assuming that the neurons i = 1  . . .   N are independent we obtain:

1 − λi
2)

(λi

N(cid:88)i=1

log R(Ik) = log

P (n = 0|C = 2  t ∈ Ik)
P (n = 0|C = 1  t ∈ Ik)

= log

i=1P (n = 0|λi
ΠN
i=1P (n = 0|λi
ΠN

2∆tk)
1∆tk)

= ∆tk

(2)
Thus  during the time-intervals where no action potential is observed  the diffusion drifts linearly
with a slope equal to the sum over all neurons of the difference between the expected ﬁring rate with
stimulus 1 and the expected ﬁring rate with stimulus 2.
Notice that if there are neurons that ﬁre equally well to targets and distractors  and if the population
of neurons is large and made of neurons whose tuning curve’s shape is identical and whose preferred
2  thus the diffusion has drift with slope close

to zero and the drift term may be ignored. In this case intervals carry no information.

orientation θi is regularly spaced  then(cid:80)i λi

1 ≈(cid:80)i λi

Diffusion jump at the action potentials.
If the neurons are uncorrelated  then the probability of
two or more action potentials happening at the same time is zero. Thus  at any time tk there is only
one action potential from one neuron. We can compute the likelihood ratio by taking a limit for the
length δt of the interval t ∈ (tk − δt/2  tk + δt/2) going to zero. As seen in the previous section 
the contribution from the neurons who did not register a spike is δt(λi
2) and goes to zero as
δt → 0. Thus we are only left with the contribution of the neuron i(k) whose spike happened at
time tk.

1 − λi

log R(tk) = lim
δt→0

log

P (n = 1|λi(k)
P (n = 1|λi(k)

2

1

δt)

δtk)

= lim
δt→0

log

2

(λi(k)
(λi(k)

1

δt)1e−λi(k)
δt)1e−λi(k)

2

1

δt

δt

= log

λi(k)
2
λi(k)
1

(3)

As a result  at each action potential tk the diffusion jumps by an amount that is the log of the ratio
of the expected ﬁring rate of the neuron i(k)’s response to target vs distractor. Thus:

1. Neurons that are equally tuned to target and distractor  whether they respond much or not 
will not contribute to the diffusion  while neurons whose response is very different for
target and distractor will contribute substantially to the diffusion.

2. A larger number of neurons will produce more action potentials and thus a faster action-

potential-driven drift in the diffusion.

Diffusion overall. Given the analysis presented above:

log R(T ) =(cid:88)k

∆tk(cid:88)i

1 − λi

(λi

2) +(cid:88)k

log

λi(k)
2
λi(k)
1

= |T |(cid:88)i

1 − λi

(λi

2) +(cid:88)k

log

λi(k)
2
λi(k)
1

(4)

Ignoring diffusion during the intervals  the diffusion at a single location where the stimulus is of
type c can be described as:

log R(T ) ∼ N(cid:88)i=1

c|T |)
c|T |
E[log R(T )] = ac|T |  V[log R(T )] = b2

)P oiss(λi

λi
2
λi
1

(log

where P oiss(λ) denotes a Poisson distributed variable with mean λ  ac ≡ (cid:80)N
c ≡(cid:80)N

i=1(log λi
2
λi
1
c. The mean and variance of the diffusion grows linearly with time.

i=1(log λi

)2λi

2
λi
1

b2

4

(5)

(6)

)λi

c and

A

B

C

D

Figure 3: (A) Diffusions realized at 10 spatial locations when the target is absent (black). The ideal
observer Bayes ratio is shown in green  the max-model approximation is shown in red. Thresholds
Θ1 = −2  Θ2 = 2 are shown  which produce 1% error rates in the ideal observer. (B) Target present
case. Notice that the decision takes longer when the target is absent (see also Fig. 4). (C) Error rates
vs. number of items and (D) vs target contrast when decision thresholds are held constant. Decision
thresholds were chosen to obtain 5% error rates in the condition M = 10 ∆θ = π/6. As we change
target contrast and the number of targets the optimal observer has constant error rates  while the
Max approximation produces variable error rates. Testing human subjects with a mix of stimuli
with different values of M and ∆θ may prevent them from adjusting decision thresholds between
stimuli; thus  one would expect constant error rates if the visual system uses the ideal observer and
variable error rates if it uses the Max approximation.

3 Visual search: detection across M locations with Poisson neurons

We now consider the case with M locations with N Poisson neurons each. At each location we
may either have a target T or a distractor D. In the whole display we have two hypotheses: no target
(C = 1) or one target at a location l (C = 2). The second hypothesis may be broken up into the
target being at any of M locations l. Because of this  the numerator of the likelihood ratio is the sum
of M terms. The Bayesian observer must integrate the action potentials from each unit to a central
unit that computes the posterior beliefs. The multi-location Bayesian observer may be computed by
observing that the target-present event is the union of the target-present events in each one of the
locations  while the target absent event implies that each location has no target. Thus  the likelihood
can be computed as the weighted sum of local likelihoods at each location in the display.
We assume that

1. The likelihood at each location is independent from the rest when the stimulus type at that

location is known; i.e. P (T |C l ∀l) =(cid:81)l P (T l|C l) .

∀l  P (C l = 2  C l = 1|C = 2) = 1/M.

2. The target 

if present 

is equally likely to occur at any location in the display;

i.e.

Calling l a location and l the complement of that location (i.e. all locations but l) we have:

P (T l|C l = 1)

P (T |C l = 2  C l = 1)P (C l = 2  C l = 1|C = 2)

Rl(T l)

Rl(T l) = log

M(cid:88)l=1

1
M

M(cid:88)l=1

exp(log Rl(T l))

(7)

M(cid:88)l=1

1
M

5

P (T |C = 1) =

P (T |C = 2) =

M(cid:89)l=1
M(cid:88)l=1

=

1
M

log Rtot(T ) = log

(

M(cid:89)l=1

P (T l|C l = 1))

P (T |C = 2)
P (T |C = 1)

= log

Eqn. 7 tells us two things:

050010001500200025003000(cid:239)6(cid:239)5(cid:239)4(cid:239)3(cid:239)2(cid:239)10123Time (ms)log R  Full bayesMAX05001000150020002500(cid:239)5(cid:239)4(cid:239)3(cid:239)2(cid:239)10123Time (ms)log R  Full bayesMAX10010110210(cid:239)310(cid:239)210(cid:239)1100MError Rate (%)ER=1.0%  FPR Full BayesFNR Full BayesFPR MaxFNR Max10010110210(cid:239)310(cid:239)210(cid:239)1100ER=10.0%M00.511.5210(cid:239)310(cid:239)210(cid:239)1100(cid:54)(cid:101)Error Rate (%)ER=1.0%  FPR Full BayesFNR Full BayesFPR MaxFNR Max00.511.5210(cid:239)310(cid:239)210(cid:239)1100ER=10.0%(cid:54)(cid:101)1. The process log Rtot is not a diffusion  in that log Rtot at time t + 1 can not be computed
2. The process log Rtot may be computed easily from the local diffusions log Rl(T l) (in

by incrementing its value at time t by a term that depends only on the interval (t  t + 1).

Sec. 4 we ﬁnd an approximation that has a natural neural implementation).

Now that we know how to compute log R(T ) for single and multi-location Bayesian observer  we
may take our decision by thresholding log R(T ) (Eqn. 1). Speciﬁcally  we choose separate thresh-
olds for making the target absent and the target present decision  and adjusted the thresholds based
on tolerance levels for the false positive rate (FPR) and the false negative rate (FNR). We keep
accumulating evidence until either decision can be made.
The relationship between FPR  FNR and the two thresholds can be derived using analysis similar
to [11]. When log Rtot(T ) reaches the target present threshold (Θ2)  with probability P (C = 2|T ) 
the target is present and with probability P (C = 1|T ) the target is absent  i.e. F P R = P (C = 1|T )
and 1 − F N R = P (C = 2|T ). We have:

Θ2 = log Rtot(T ) = log

P (C = 2|T )
P (C = 1|T )

= log

1 − F N R

F P R
Similarly  when log R(T ) reaches the target absent threshold (Θ1)  we have:
F P R

Θ1 = log Rtot(T ) = log

P (C = 2|T )
P (C = 1|T )

= log

1 − F N R

(8)

(9)

Therefore  given desired FPR and FNR  we can analytically compute the upper and lower thresholds
for the Full Bayesian model using Eqn. 8 and 9.

4 Max approximation

An alternative  more economic  approach to full Bayesian decision is to approximate the global
belief using the largest local diffusion and suppress the rest. This is because  in the limit where
|T | is large  the diffusion at the location where the target is present will dominate over the other
diffusions and thus it is a good approximation of the sum in Eq. 7. We will call this approach “max
approximation” and also “Max model”. In this scheme  at each location a diffusion based on the
local Bayesian observer is computed. If any location ‘detects’ a target  then a target is declared.
If all locations detect a distractor  then the ‘no target’ condition is declared. This may not be the
optimal method  but it has the advantage of requiring only two low-frequency communication lines
between each location and the central decision unit. Equivalently  the max approximation can be
implemented by computing the maximum of the local diffusions and comparing it to an adjusted
high and a low threshold for target present/absent decision (see Fig. 2).
More speciﬁcally  let l∗ denote the location of maximum diffusion in the display  and log Rl∗
denote
l=1 log Rl(T l)). From eqn 7 we know that the global
the maximum diffusion (i.e.  log Rl∗
likelihood ratio is the average of the local likelihood ratios  and equivalently  the log likelihood ratio
is the soft-max of the local diffusions:

= maxM

log Rtot(T ) = log(cid:32) 1

M

exp(cid:0)log Rl(T l)(cid:1)(cid:33)
M(cid:88)l=1
+ log 1
(1 +(cid:88)l(cid:54)=l∗

M

))

= log Rl∗

exp(log Rl − log Rl∗

(10)

Target present – When the target is present in the display  if the target is different from the distrac-
tor  the diffusion at the target’s location will frequently become much higher than at other locations 
and the terms corresponding to Rl
Rl∗ may be safely ignored. Thus  the total log likelihood ratio may
be approximated by the maximum local diffusions minus a constant:

log Rtot ≈ log Rl∗ − log M

if Rl << Rl∗

(11)

6

A

B

C

Figure 4: (A) Histogram of response-times (RT) when the target is present (green) and when the target is
absent (red) for M = 10 for different values of target contrast (∆θ). Response times are longer when the
contrast is smaller (see Fig. 1). Also  they are longer when the target is absent (see Fig. 3). Notice that the
response times have a Gaussian-like distribution when time is plotted on a log scale  and the width of the
distribution does not change signiﬁcantly as the difﬁculty of the task changes; thus  the mean and median
response time are equivalently informative statistics of RT. (B) Mean RT as a function of the number M of
items for different values of target contrast; the curves appear linear as a function of log M [21]. Notice that RT
slope is almost zero (‘parallel search’) when the target has high contrast  while when target contrast is low RT
increases signiﬁcantly with M (‘serial search’) [1]. The response times observed using the Max approximation
are almost identical to those obtained with the ideal observer.
(C) Error vs. RT tradeoff curves obtained
by changing systematically the value of the decision threshold. The mean RT ±σ is shown. Ideal bayesian
observer (blue) and Max approximation (cyan) are almost identical indicating that the Max approximation’s
performance is almost as good as that of the optimal observer.

From Eqn. 5 and 6 we know that the difference in diffusion value between the target location and
the distractor location grows linearly in time. Thus  the longer the process lasts  the better the
approximation. Conversely  when t = |T | is small  the approximation is unreliable  and a different
approximation term must be introduced (see supplementary material2 for derivation):

log Rtot ≈ log Rl∗ −(cid:18)a2t + log(

1
M

+

(M − 1)

M

exp((a1 − a2 +

b2
1 + b2
2

2

)t))(cid:19) if Rl ≈ Rl∗

(12)

Target absent
– When the target is absent in the display  the value of all the local diffusions at
time t will be distributed according to the same density. According to Eqn. 6  the standard deviation
t  hence the expected value of log Rl∗ − log Rl is monotonically increasing. When this
grows as
expected difference is large enough  we can make the same approximation as Eqn. 11:

√

log Rtot ≈ log Rl∗ − log M

(13)
On the other hand  when |T | is small  we resort to another approximation (see supplementary mate-
rial for derivation):

if Rl << Rl∗

where µM ≡ M(cid:82) ∞

log Rtot ≈ log Rl∗ − µM b1

t +

(14)
−∞ zΦM−1(z)N (z)dz  and N (z) and Φ(z) denote the pdf and cdf of normal

log(

M

)

if Rl ≈ Rl∗

distribution.
Since the max diffusion does not represent the global log likelihood ratio  its thresholds can not be
computed directly from the error rates. Nonetheless we can ﬁrst compute analytically the thresholds
for the Bayesian observer (Eqn. 8 and 9)  and adjust them based on the approximations stated above
(Eqn. 11  12  13 and 14). Finally  we threshold the maximum local diffusion log Rl∗
with respect to
the adjusted upper and lower threshold to make our decision.

√

b2
1t
2

− 1
2

exp(b2t) + M − 1

5 Experiments

Experiment 1. - Overall model predictions.
In this experiment we explore the model’s prediction
of response time over a series of interesting conditions. The default parameters are the number of

2http://vision.caltech.edu/˜bchen3/nips2011/supplementary.pdf

7

10010210400.050.10.150.20.25Response time (ms)Normalized counts(cid:54)(cid:101)=pi/18  5.0% TA5.0% TP10010210400.050.10.150.20.25(cid:54)(cid:101)=pi/610010210400.050.10.150.20.25(cid:54)(cid:101)=pi/2100101102020040060080010001200MMean response time (ms)(cid:54)(cid:101)=pi/18 Full Bayes  TATP100101102020040060080010001200(cid:54)(cid:101)=pi/6 Full Bayes100101102020040060080010001200(cid:54)(cid:101)=pi/2 Full Bayes10010150100150200250Error Rate (%)Response time (ms)M=3.00  TA Full BayesTP Full BayesTA MaxTP Max10010150100150200250M=10.0010010150100150200250M=30.00neurons per location N = 32  the tuning width of each neuron = π/8  the maximum expected
ﬁring rate (λ = 10 action potentials per second) and minimum expected ﬁring rate (λ = 1 a.p./s)
of a neuron  which reﬂects the signal-to-noise ratio of the neuron’s tuning curves  the number of
items (locations) in the display M = 10 and the stimulus contrast ∆θ = π/6. Both M and ∆θ
refers to the display  while the other parameters refer to the brain. We will focus on how predictions
change when the display parameters are changed over a set of discrete settings: M ∈ {3  10  30}
and ∆θ ∈ {π/18  π/6  π/2}. For each setting of the parameters  we simulate the bayesian and the
max model for 1000 runs. The length of simulation is set to a large value (4 seconds) to make sure
that all decisions are made before the simulation terminates.
We are also interested in the trade-off between RT and ER η for η = {1%  5%  10%}. For each
η we search for the best pair of upper and lower thresholds that achieve F N R ≈ FPR ≈ η. We
search over the interval [0 3.5] for the optimal upper threshold and over [−3.5 0] for the optimal
lower threshold (an upper threshold of 3.5 corresponds to a FPR of 0.03%). The search is conducted
exhaustively over an [80 × 80] discretization of the joint space of the thresholds. We record the
response time distributions for all parameter settings and for all values of η (Fig. 4).

Experiment 2. - Conditions where Bayesian and Max models differ maximally
In this exper-
iment we test the robustness of Bayesian and Max models with respect to a ﬁxed threshold. For a
Bayesian observer  the thresholds yielding a given error rate can be computed exactly independent
of the display (Eqn. 9 and 8). On the contrary  in order for the max model to achieve the equivalent
performance  its threshold must be adjusted differently depending on the number of items M and
the target contrasts ∆θ (Eqn. 11-14). As a result  if a constant threshold is used for all conditions 
we would expect the Bayesian observer ER to be roughly constant  whereas the Max model would
have considerable ER variability. The error rates are shown in Fig. 3 as we vary M and ∆θ. The
threshold is set as the optimal threshold that produces 5% error for the Bayesian observer at a single
location M = 1 and with ∆θ = π/18.

6 Discussion and conclusions

We presented a Bayesian ideal observer model of visual search. To the best of our knowledge  this
is the ﬁrst model that can predict the statistics of both response times (RT) and error rates (ER)
purely from physiologically relevant constants (number  tuning width  signal-to-noise ratio of cor-
tical mechanisms) and from image parameters (target contrast and number of distractors). Neurons
are modeled as Poisson units and the model has only four free parameters: the number of neurons per
hypercolumn  the tuning width of their response curve  the maximum and the minimum ﬁring rate
of each neuron. The model predicts qualitatively the main phenomena that are observed in visual
search: serial vs. parallel search [1]  the Gaussian-like shape of the response time histograms in log
time [7] and the faster response times when the target is present [3]. The model is easily adaptable
to predictions involving multiple targets  different image features and conjunction of features.
Unlike the case of binary detection/decision  the ideal observer may not be implemented by a diffu-
sion. However  it may be implemented using a precisely deﬁned ‘soft-max’ combination of diffu-
sions  each one of which is computed at a different location across the visual ﬁeld. We discuss an
approximation of the ideal observer  the Max model  which has two natural and simple implemen-
tations in neural hardware. The Max model is found experimentally to have a performance that is
very close to that of the ideal observer when the task parameters do not change.
We explored whether any combinations of target contrast and number of distractors would produce
signiﬁcantly different predictions of the ideal observer vs the Max model approximation and found
none in the case where the visual system can estimate decision thresholds in advance. However  our
simulations predict different error rates when interleaving images containing diverse contrast levels
and distractor numbers.

Acknowledgements: We thank the three anonymous referees for many insightful comments and
suggestions; thanks to M. Shadlen for a tutorial discussion on the history of discrimination models.
This research was supported by the California Institute of Technology.

8

References
[1] A.M. Treisman and G. Gelade. A feature-integration theory of attention. Cognitive psychology  12(1):97–

136  1980.

[2] W.T. Newsome  K.H. Britten  and J.A. Movshon. Neuronal correlates of a perceptual decision. Nature 

341(6237):52–54  1989.

[3] P. Verghese. Visual search and attention:: A signal detection theory approach. Neuron  31(4):523–535 

2001.

[4] Vidhya Navalpakkam and Laurent Itti. Search goal tunes visual features optimally. Neuron  53(4):605–17 

Feb 2007.

[5] J. Duncan and G.W. Humphreys. Visual search and stimulus similarity. Psychological review  96(3):433 

1989.

[6] J.M. Wolfe. Attention (Ed. H. Pashler)  chapter Visual Search  pages 13–73. University College London

Press  London  U.K.  1998.

[7] J.M. Wolfe  E.M. Palmer  and T.S. Horowitz. Reaction time distributions constrain models of visual

search. Vision research  50(14):1304–1311  2010.

[8] E.M. Palmer  T.S. Horowitz  A. Torralba  and J.M. Wolfe. What are the shapes of response time dis-
tributions in visual search? Journal of Experimental Psychology: Human Perception and Performance 
37(1):58  2011.

[9] Jeffrey M Beck  Wei Ji Ma  Roozbeh Kiani  Tim Hanks  Anne K Churchland  Jamie Roitman  Michael N
Shadlen  Peter E Latham  and Alexandre Pouget. Probabilistic population codes for bayesian decision
making. Neuron  60(6):1142–52  Dec 2008.

[10] R. Bogacz  E. Brown  J. Moehlis  P. Holmes  and J.D. Cohen. The physics of optimal decision making: A
formal analysis of models of performance in two-alternative forced-choice tasks. Psychological Review 
113(4):700  2006.

[11] A. Wald. Sequential tests of statistical hypotheses. The Annals of Mathematical Statistics  16(2):117–186 

1945.

[12] M.M. Chun and J.M. Wolfe. Just say no: How are visual searches terminated when there is no target

present? Cognitive Psychology  30(1):39–78  1996.

[13] R. Ratcliff. A theory of memory retrieval. Psychological Review  85(2):59–108  1978.
[14] Philip L Smith and Roger Ratcliff. Psychology and neurobiology of simple decisions. Trends Neurosci 

27(3):161–8  Mar 2004.

[15] Roger Ratcliff and Gail McKoon. The diffusion decision model: theory and data for two-choice decision

tasks. Neural Comput  20(4):873–922  Apr 2008.

[16] D.G. Pelli. Uncertainty explains many aspects of visual contrast detection and discrimination. JOSA A 

2(9):1508–1531  1985.

[17] R. Ratcliff. A theory of order relations in perceptual matching. Psychological Review  88(6):552  1981.
[18] Joshua I Gold and Michael N Shadlen. The neural basis of decision making. Annu Rev Neurosci  30:535–

74  2007.

[19] R.L. De Valois and K.K. De Valois. Spatial vision. Oxford University Press  USA  1990.
[20] MI Posner  Y. Cohen  and RD Rafal. Neural systems control of spatial orienting. Philosophical Transac-

tions of the Royal Society of London. B  Biological Sciences  298(1089):187  1982.

[21] W.E. Hick. On the rate of gain of information. Quarterly Journal of Experimental Psychology  4(1):11–

46  1952.

9

,Chaitanya Ryali
Gautam Reddy
Angela Yu