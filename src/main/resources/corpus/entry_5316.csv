2008,Structured ranking learning using cumulative distribution networks,Ranking is at the heart of many information retrieval applications. Unlike standard regression or classification  in which we predict outputs independently  in ranking  we are interested in predicting structured outputs so that misranking one object can significantly affect whether we correctly rank the other objects. In practice  the problem of ranking involves a large number of objects to be ranked and either approximate structured prediction methods are required  or assumptions of independence between object scores must be made in order to make the problem tractable. We present a probabilistic method for learning to rank using the graphical modelling framework of cumulative distribution networks (CDNs)  where we can take into account the structure inherent to the problem of ranking by modelling the joint cumulative distribution functions (CDFs) over multiple pairwise preferences. We apply our framework to the problem of document retrieval in the case of the OHSUMED benchmark dataset. We will show that the RankNet  ListNet and ListMLE probabilistic models can be viewed as particular instances of CDNs and that our proposed framework allows for the exploration of a broad class of flexible structured loss functionals for ranking learning.,Structured Ranking Learning using
Cumulative Distribution Networks

Jim C. Huang

Brendan J. Frey

Probabilistic and Statistical Inference Group

Probabilistic and Statistical Inference Group

University of Toronto

Toronto  ON  Canada M5S 3G4

jim@psi.toronto.edu

University of Toronto

Toronto  ON  Canada M5S 3G4
frey@psi.toronto.edu

Abstract

Ranking is at the heart of many information retrieval applications. Unlike standard
regression or classiﬁcation in which we predict outputs independently  in ranking
we are interested in predicting structured outputs so that misranking one object
can signiﬁcantly affect whether we correctly rank the other objects. In practice 
the problem of ranking involves a large number of objects to be ranked and ei-
ther approximate structured prediction methods are required  or assumptions of
independence between object scores must be made in order to make the problem
tractable. We present a probabilistic method for learning to rank using the graph-
ical modelling framework of cumulative distribution networks (CDNs)  where we
can take into account the structure inherent to the problem of ranking by mod-
elling the joint cumulative distribution functions (CDFs) over multiple pairwise
preferences. We apply our framework to the problem of document retrieval in
the case of the OHSUMED benchmark dataset. We will show that the RankNet 
ListNet and ListMLE probabilistic models can be viewed as particular instances
of CDNs and that our proposed framework allows for the exploration of a broad
class of ﬂexible structured loss functionals for learning to rank.

1

Introduction

Ranking is the central problem for many information retrieval applications such as web search 
collaborative ﬁltering and document retrieval [8]. In these problems  we are given a set of objects
to be ranked and a series of observations where each observation consists of some subset of the
objects  a feature vector and some ordering of the objects with highly ranked objects corresponding
to a higher relevance or degree of importance. The goal is to then learn a model which allows
us to assign a score to new test objects:
this often takes the form of a ranking function [2  4]
which assigns a higher score to objects with higher rankings. Unlike the canonical problems of
regression or classiﬁcation in which we predict outputs independently of one another  in ranking
we are interested in predicting structured outputs  as the rank of one item can only be determined
given the scores of all other items  and so complex inter-dependencies exist between outputs. This
requires measures of loss which are multivariate and structured. However  such ranking measures
are typically difﬁcult to optimize directly [3]  making the problem of learning difﬁcult. A previous
approach has been to treat the problem as one of structured prediction [7]  where the aim is to directly
optimize ranking measures. Another approach has been to approximate these ranking measures with
smooth differentiable loss functionals by formulating probabilistic models on pairwise preferences
between objects (RankNet; [2])  or on ordered lists of objects (ListNet and ListMLE; [4  13]). In
practice  these methods either require approximating a learning problem with an intractable number
of constraints  or they require observations containing complete orderings over the objects to be
ranked or one must make independence assumptions on pairwise preferences.

In practice however  we can take advantage of the fact that each observation in the training set
only provides preference information about a small subset of the objects to be ranked  so that a
sensible probabilistic representation would be the probability of observing a partial ordering over

nodes for a given observation. We will show that 1) a probability over orderings is equivalent to a
probability over pairwise inequalities between objects to be ranked and 2) this amounts to specifying
a joint cumulative distribution function (CDF) over pairwise object preferences. We will present a
framework for ranking using the recently-developed probabilistic graphical modelling framework
of CDNs which compactly represents this joint CDF as a product of local functions [5]. While the
problem of inference in CDNs was addressed in [5]  here we address the problem of learning in
CDNs in the context of ranking learning where we estimate model parameters under a structured
loss functional that accounts for dependencies between pairwise object preferences. We will then
test the proposed framework on the OHSUMED dataset [8]  a benchmark dataset used in information
retrieval research. Finally we will show that the frameworks proposed by [2  4  13] can be viewed
as particular types of CDNs so that novel classes of ﬂexible structured loss functionals for ranking
learning can be speciﬁed under our framework.

2 Cumulative distribution networks
The CDN [5] is an undirected graphical model in which the joint CDF F (z) over a set of random
variables is represented as a product over functions deﬁned over subsets of these variables. More
formally 

(cid:1)

c∈C

F (z) =

φc(zc) 

(1)

where φc(zc) is a function deﬁned over some subset of variables. An example of a CDN is shown
in Figure 1(a)  along with an example bivariate density which can be obtained by differentiating a
product of 2 Gaussian CDF functions (Figure 1(b)).

In contrast to undirected models for probability density functions  the global normalization con-
straint on the CDF does not require computing a partition function and can be enforced locally for
each φc(zc). Thus  in order for the CDN to represent a valid CDF  it is sufﬁcient that each of the local
functions φc satisfy all of the properties of a multivariate CDF. These properties include the require-
ments that each CDN function φc be bounded between 0 and 1  and that each φc is monotonically
non-decreasing with respect to all of its argument variables zc  so that the joint CDF F (z) is also
bounded between 0 and 1 and is monotonically non-decreasing with respect to any and all subsets
of variables. In a CDN  disjoint sets of variables A  B are marginally independent if they share no
functions in common  and disjoint sets of variables A  B are conditionally independent given vari-
able set C if no path linking any variable in A to any variable in B passes through C. In addition 
marginalization of variables in a CDN can be done in constant-time via a trivial maximization of the
joint CDF with respect to the variables being marginalized. The problem of inference in a CDN can
be solved efﬁciently using a message-passing algorithm called derivative-sum-product. For detailed
derivations of the properties of CDNs  including marginal and conditional independence properties 
we refer the reader to [5]. The CDN framework provides us with a means to compactly represent
multivariate joint CDFs over many variables: in the next section we will formulate a loss functional
for learning to rank which takes on such a form.

y

8

6

4

2

0
0

(a)

6

8

2

4

x
(b)

a) Cumulative distribution network representing the joint CDF F (z1  z2  z3  z4  z5) =
Figure 1:
φa(z2)φb(z1  z2  z3)φc(z3)φd(z4)φe(z3  z4  z5)φf (z5); b) Example of a bivariate density P (x  y) corre-
sponding to differentiating a CDF F (x  y) obtained from taking the product of 2 Gaussian bivariate CDFs.

3 Structured loss functionals for ranking learning
We now proceed to formulate the problem of learning to rank in a structured setting. Suppose
we wish to rank N nodes in the set V = {V1 ···   VN} and we are given a set of observations
D1 ···   DT . Each observation Dt consists of an ordering over the nodes in a subset Vt ⊆ V  where
each node is provided with a corresponding feature vector x ∈ RL which may be speciﬁc to the
given observation. The orderings could be provided in the form of ordinal node labels1  or in the
form of pairwise node preferences. The orderings can be represented as a directed graph over the
nodes in which a directed edge e = (Vi → Vj) is drawn between 2 nodes Vi  Vj iff Vi is preferred
to node Vj  which we denote as Vi (cid:4) Vj. In general  we assume that for any given observation 
we observe a partial ordering over nodes  with complete orderings being a special case. We denote
the above graph consisting of edges e = (Vi → Vj) ∈ Et and the node set Vt as the order graph
Gt = (Vt Et) for observation Dt so that Dt = {Gt {xt
}. A toy example of an observation
over 4 nodes is shown in Figure 2(a). Note that under this framework  the absence of an edge
between two nodes Vi  Vj in the order graph indicates we cannot assert any preference between the
two nodes for the given observation.

n}Vn∈Vt

(a)

(b)

Figure 2: a) An example of an order graph over 4 nodes V1  V2  V3  V4 corresponding to the objects to be
ranked. The graph represents the set of preference relationships V1 (cid:1) V2  V1 (cid:1) V3  V1 (cid:1) V4  V2 (cid:1) V4  V3 (cid:1)
V4; b) Learning the ranking function from training data. The training data consists of a set of order graphs over
subsets of the objects to be ranked. For order graph  the ranking function ρ maps each node to the real line .
The goal is to learn ρ such that we minimize our probability of misranking on test observations.
We now deﬁne ρ : V → R as a ranking function which assigns scores to nodes via their feature
vectors so that for node Vi 

Si = ρ(Vi) +π i

(2)
where Si is a scalar and πi is a random variable speciﬁc to node Vi. We wish to learn such a function
given multiple observations D1 ···   DT so that we minimize the probability of misranking on test
observations (Figure 2(b)). The above model allows us to account for the fact that the amount of
uncertainty about a node’s rank may depend on unobserved features for that node (e.g.: documents
associated with certain keywords might have less variability in their rankings than other documents).
Under this model  the preference relation Vi (cid:4) Vj is completely equivalent to

ρ(Vi) + πi ≥ ρ(Vj) + πj ⇔ πij = πj − πi ≤ ρ(Vi) − ρ(Vj).

(3)

where we have deﬁned πij as a preference variable between nodes Vi  Vj.
For each edge e = (Vi → Vj) ∈ Et in the order graph  we can deﬁne r(ρ; e  Dt) ≡ ρ(Vi) − ρ(Vj)
and collect these into the vector r(ρ; Gt) ∈ R|Et|
. Similarly  let πe ≡ πij. Having deﬁned the
preferences  we must select an appropriate loss measure. A sensible metric here [13] is the joint

1It is crucial to note that node labels may in general not be directly comparable with one another from one
observation to the next (e.g.: documents with the same rating might not truly have the same degree of relevance
for different queries)  or the scale of the labels may be arbitrary.

probability of observing the order graph Gt = (Vt Et) corresponding to the partial ordering of
nodes in Vt. From Equation (3)  this will take the form of a probability measure over events of the
(cid:2) (cid:3)
type πe ≤ r(ρ; e  Dt) so that we obtain
P r{Et|Vt  ρ} = P r

(cid:4)
[πe ≤ r(ρ; e  Dt)]

r(ρ; Gt)

= Fπ

(cid:6)

(cid:5)

(4)

 

e∈Et

where Fπ is the joint CDF over the preference variables πe. Given an observation Dt  the goal is to
learn the ranking function ρ by maximizing Equation (4). Note that under this framework  the set
of edges Et corresponding to the set of pairwise preferences are treated as random variables which
may have a high degree of dependence between one another  so that Fπ
is a joint CDF
over multiple pairwise preferences. The problem of learning the ranking function then consists of
scoring multiple nodes simultaneously whilst accounting for dependencies between node scores.
Now  if we are given multiple independent (but not necessarily identically distributed) observations
D = {D1 ···   DT}  we can deﬁne a structured loss functional
(cid:5)

r(ρ; Gt)

(cid:5)

(cid:6)

(cid:6)

L(ρ  Fπ D) =− T(cid:7)

log Fπ

r(ρ; Gt)

(5)

t=1

where each term in the loss functional depends on multiple preference relationships speciﬁed by the
order graph for observation t. The problem of learning then consists of solving the optimization
problem

L(ρ  Fπ D).

inf
ρ Fπ

(6)

In general  the above structured loss functional may be difﬁcult to specify  as it takes on the form of
a joint CDF over many random variables with a high degree of inter-dependency which may require
a large number of parameters to specify. We can  however  compactly represent this using the CDN
framework  as we will now show.

3.1 Tranforming order graphs into CDNs

Figure 3: Transforming the order graph Gt into a CDN. For each edge e = (Vi → Vj) in the order graph
(left)  a preference variable πij is created. All such random variables are then connected to one another in a
CDN (right)  allowing for complex dependencies between preferences.

The representation of the structured loss functional in Equation (5) as a CDN consists of transform-
ing the order graph Gt for a each observation into a set of variable nodes in a CDN. More precisely 
for each edge e = (Vi → Vj) in the order graph  the preference variable πij is created. All such
variables are then connected to one another in a CDN (Figure 3)  where the pattern of connectivity
used will determine the set of dependencies between these preferences πij as given by the marginal
and conditional independence properties of CDNs [5]. Thus for any given CDN topology  each
preference node πe is a member of some neighborhood of preference nodes πe(cid:1) so that neighboring
preferences nodes are marginally dependent of one another.

One possible concern here is that we may require a fully connected CDN topology over all possible
pairwise preferences between all nodes in order to capture all of these dependencies  leading to a

model which is cumbersome to learn. In practice  because any observation only conveys information
about a small subset of the nodes in V and because in practice we observe partial orderings between
these  the order graph is sparse and so the number of preference nodes in the CDN for the given
observation will be much smaller than the worst-case number of all possible pairwise preferences
between nodes. Furthermore  we do not have to store a large CDN in memory during training  as
we only need to store a single CDN over a relatively small number of preference variables for the
current observation. We can thus perform ranking learning in an online fashion by constructing a
single CDN for each observation Dt and optimizing the loss − log Fπ
deﬁned by that
CDN for the given observation.

r(ρ; Gt)

(cid:5)

(cid:6)

4 StructRank: a probabilistic model for structured ranking learning with

node labels

Suppose now that each node in the training set is provided with an ordinal node label y along with a
feature vector x. For any given order graph over some subset of the nodes  the node labels y allow
us to establish edges in the order graph  so that an edge Vi → Vj exists between two nodes Vi  Vj iff
yi > yj. We can then parametrically model the ranking function ρ(V ) ≡ ρ(x; a) (where a is a set
of parameters) using a Nadaraya-Watson [10  12] local estimator with a Gaussian kernel so that

(cid:8)
(cid:8)

ρ(x; a) =

i K(xi  x; a)yi
i K(xi  x; a)

 

K(˜x  x; a) = exp

(cid:9)

(cid:5)

− 1
2

x − ˜x

(cid:5)

(cid:6)T A

x − ˜x

(cid:6)(cid:10)

 

(7)

where the summations are taken over all feature vector-label pairs in the training set  with A =
L). Consider now an edge e = (Vi → Vj) in the order graph and deﬁne re ≡
1 ···   a2
diag(a2
i; a) − ρ(xt
j; a). For a given order graph  the structured loss functional L(θ; Dt) is
re(a; Dt) =ρ( xt
given by
(cid:12)

L(θ; Dt) =− log Fπ
(cid:11)

log φ(re(a; Dt)  re(cid:1)(a; Dt)) 

(cid:7)

r(ρ; Gt)

= −

(cid:5)

(cid:6)

(8)

e e(cid:1)

is the parameter vector and the function φ(r1  r2) set to a multivariate

where θ =
sigmoidal function so that

a w1 w2

φ(r1  r2) =

1 + exp(−w1r1) + exp(−w2r2)

1

  w1  w2 ≥ 0 

(9)

where w1  w2 are weights parameterizing the CDN function φ(r1  r2). It can be readily shown that
this choice of CDN function φ(r1  r2)  when combined with the constraints w1  w2 > 0  satisﬁes
all of the necessary and sufﬁcient conditions required for the CDN to represent a valid CDF  as
0 ≤ φ(r1  r2) ≤ 1 and is monotonically non-decreasing with respect to all of its arguments. For the
given CDN and ranking functions  the learning problem for the current observation Dt then becomes

(cid:5) − w1re(a; Dt)

(cid:6)

+ exp

(cid:5) − w2re(cid:1)(a; Dt)

(cid:6)(cid:10)

(cid:9)

(cid:7)

(cid:7)

t

e e(cid:1)

inf
θ

log

1 + exp

(10)
where we have introduced a regularizer in the form of an L1-norm constraint. Notice that our model
has one parameter per data feature and 2 parameters deﬁning the CDN for any given observation.
The gradient ∇aL(θ; Dt) and the derivatives with respect to the CDN function weights w1  w2 for
a given observation Dt are provided in the Supplementary Information.

s.t. θ ≥ 0

(cid:9)θ(cid:9)1 ≤ t 

5 Results
To compare the performance of our proposed framework to other methods  we will use the following
three metrics commonly in use in information retrieval research: Precision  Mean Average Precision
(MAP) and Normalized Discounted Cumulative Gain (NDCG) [6]. The NDCG accounts for the fact
that less relevant documents are less likely to be examine by a user by putting more weight on highly
relevant documents than marginally relevant ones.

We downloaded the OHSUMED dataset provided as part of the LETOR 2.0 benchmark [8]. The
dataset consists of a set of 106 query-document pairs  with a feature vector and relevance judgment

(a)

(b)

(c)

Figure 4: a) Average NDCG as a function of truncation level n for the OHSUMED dataset. NDCG values are
averaged over 5 cross-validation splits; b) Mean average precision (MAP) as a function of truncation level n;
c) Mean average precision value for several methods.

provided for each pair  where queries correspond to medical searches associated with patient and
topic information. There are a total of 16 140 query-document pairs with relevance judgments pro-
vided by humans on three ordinal levels: deﬁnitely relevant  partially relevant or not relevant. For

any given query  we used the ordinal labels y for each document in the query in order to establish
preferences between documents for that query. Each node in the order graph is provided with 25
query-speciﬁc features including term frequency  document length  BM25 and LMIR features as
well as combinations thereof [1  11  14]. In accordance with the nomenclature above  we use the
terms query and observation interchangeably.

The OHSUMED dataset is provided in the form of 5 training/validation/test splits of sizes 63/21/22
observations each. To ensure that features are comparable across all observations  we normalized
each feature vector within each observation as described in [8]. We performed learning of our model
using a constrained stochastic gradients algorithm where for each observation  we prevent updates
from violating the inequality constraints in the optimization problem deﬁned by Equation (10) by
reducing the learning rate α until the update becomes feasible. We set the default learning rate
to α = 0.5 and we randomly initialized the model parameters a  w1  w2 in the range [0  1]. This
optimization was run for 10 epochs (passes through the training set) and α was scaled by 1√
2 at
the end of each epoch. We set the regularization parameter using the validation set for a given data
split. Due to the nonconvex nature of the optimization problem  for each cross-validation split  we
performed learning using 3 random initializations  and we then selected the model which achieved
the best MAP score on the validation set.

We tested a fully connected CDN which models full interdependence between preferences  and a
completely disconnected CDN which models preferences independently of one another. The above
3 performance metrics are shown in Figures 4(a) 4(b) 4(c) in addition to the performances of seven
state-of-the-art methods which are part of the LETOR 2.0 benchmarks. At the time of submission 
numerical performance scores for ListMLE [13] were not available and so were not included in
these plots. With the exception of ListNet and ListMLE  none of the above methods explicitly
model dependencies between pairwise preferences. As can be seen  accounting for dependencies
between pairwise preferences provides a signiﬁcant gain in performance compared to modellling
preferences as being independent. Additional results on the TREC2004 dataset from LETOR 2.0
are provided in Supplemental Information.

6 Discussion

We have proposed here a novel framework for ranking learning using structured loss functionals.
We have shown that the problem of learning to rank can be reduced to maximizing a joint CDF
over multiple pairwise preferences. We have shown how to compactly represent this using the CDN
framework and have applied it to the OHSUMED benchmark dataset. We have demonstrated that
representing the dependencies between pairwise preferences leads to improved performance over
modelling preferences as being independent of one another.

6.1 Relation to RankNet and ListNet/ListMLE

The probability models for ranking proposed by [2  4  13] can all be expressed as special cases of
models deﬁned by different CDNs. In the case of RankNet [2]  the corresponding probability over a
given pairwise preference Vi (cid:4) Vj is modelled by a logistic function of ρ(xi)− ρ(xj) and the model
was optimized using cross-entropy loss. The joint probability of preferences can thus be represented
as a completely disconnected CDN with logistic functions in which all pairwise object preferences
are treated as being independent. In the case of ListNet [4] and ListMLE [13]  the probability of
observing a complete ordering V1 (cid:4) ··· (cid:4) VN over N objects are deﬁned as products of functions
of the type
(cid:6)(cid:14) =
P (V1 (cid:4) ··· (cid:4) VN|D) =

N(cid:1)

N(cid:1)

(cid:13)

=

(cid:8)N

(cid:8)N

exp(ρ(xi))
k=i exp(ρ(xk))

i=1

i=1

1 +

k=i+1 exp

ρ(xi) − ρ(xk)

1

−(cid:5)

which we see is equivalent to a CDN with N multivariate sigmoids. As noted by the authors of [13] 
the above model is also an example of the Plackett-Luce class of probability models over object
scores [9]. In addition  the ListNet/ListMLE frameworks both require a complete ordering over
objects by deﬁnition: under the CDN framework  we can model partial orderings  with complete
orderings as a special case. The connections between RankNet  ListNet and ListMLE and the CDN
framework are illustrated in Supplementary Figure 2. Our proposed framework uniﬁes the above

N(cid:1)

i=1

φi(ri) 

views of ranking as different instantiations of a joint CDF over pairwise preferences and hence as
particular types of CDNs. This allows us to consider ﬂexible joint CDFs deﬁned over different
subsets of object preferences and over different families of CDN functions so as to capture various
data speciﬁc properties.

6.2 Future directions

Our work here suggests several future directions for research. In [13]  it was shown that the log-
likelihood corresponding to the probability of an ordering is a good surrogate to the 0-1 loss be-
tween the predicted ordering and the true ordering  as the former is differentiable and penalizes
mis-orderings in a sensible way. One could investigate connections between the structured loss
functionals proposed in this paper and other ranking measures such as NDCG. Another possible di-
rection is to generalize StructRank to products over Gaussian multivariate CDFs or other classes of
functions which satisfy the requirements of CDN functions   as in this paper we have elected to use
a product of bivariate sigmoids φ(re  re(cid:1)) to represent our loss functional. Also  it may be fruitful
to investigate different CDN topologies: for example  we found that averaging randomly connected
CDNs are very fast to learn and perform comparably to the fully-connected CDN we used in this
paper (data not shown). In addition  we have only investigated representing the loss functional using
a single CDN function: this could easily be generalized to K functions. Lastly  alternatives to the
Nadaraya-Watson local estimator  such as the neural networks used in [2  4  13]  can be investigated.

References

[1] R. Baeza-Yates and B. Ribeiro-Neto. Modern information retrieval. Addison Wesley  1999.
[2] C.J.C. Burges  T. Shaked  E. Renshaw  A. Lazier  M. Deeds  N. Hamilton and G. Hullender.
Learning to rank using gradient descent. In Proceedings of the Twenty-Second International Con-
ference on Machine Learning (ICML)  2005.

[3] C.J.C. Burges  R. Ragno and Q.V. Le. Learning to rank with nonsmooth cost functions. In Pro-
ceedings of the Nineteenth Annual Conference on Neural Information Processing Systems (NIPS) 
2007.

[4] Z. Cao  T. Qin  T.Y. Liu  M.F. Tsai and H. Li. Learning to rank: from pairwise approach to
listwise approach. In Proceedings of the Twenty-Fourth International Conference on Machine
Learning (ICML)  2007.

[5] J.C. Huang and B.J. Frey. Cumulative distribution networks and the derivative-sum-product al-
gorithm. In Proceedings of the Twenty-Fourth Conference on Uncertainty in Artiﬁcial Intelligence
(UAI)  2008.

[6] K. Jarvelin and J. Kekalainen. Cumulated evaluation of IR techniques  ACM Information Sys-

tems  2002.

[7] T. Joachims. A support vector method for multivariate performance measures. In Proceedings

of the Twenty-Second International Conference on Machine Learning (ICML)  2005.

[8] T.Y. Liu  J. Xu  T. Qin  W. Xiong and H. Li. LETOR: Benchmark dataset for research on learning

to rank for information retrieval. LR4IR 2007  in conjunction with SIGIR 2007  2007.

[9] J. I. Marden. Analyzing and modeling rank data. CRC Press  1995.
[10] E.A. Nadaraya. On estimating regression. Theory of Probability and its Applications 9(1)  pp.

141-142  1964.

[11] S.E. Robertson. Overview of the OKAPI projects. Journal of Documentation 53 (1)  pp. 3-7 

1997.

[12] G.S. Watson. Smooth regression analysis. The Indian Journal of Statistics. Series A 26  pp.

359-372  1964.

[13] F. Xia  T.Y. Liu  J. Wang  W. Zhang and H. Li. Listwise approach to learning to rank - theory
and algorithm. In Proceedings of the Twenty-Fifth International Conference on Machine Learning
(ICML)  2008.

[14] C. Zhai and J. Lafferty. A study of smoothing methods for language models applied to ad hoc

information retrieval. In Proceedings of SIGIR 2001  2001.

,Simon Du
Yining Wang
Xiyu Zhai
Sivaraman Balakrishnan
Russ Salakhutdinov
Aarti Singh