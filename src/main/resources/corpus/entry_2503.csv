2009,Human Rademacher Complexity,We propose to use Rademacher complexity  originally developed in computational learning theory  as a measure of human learning capacity.  Rademacher complexity measures a learners ability to fit random data  and can be used to bound the learners true error based on the observed training sample error.  We first review the definition of Rademacher complexity and its generalization bound.  We then describe a learning the noise" procedure to experimentally measure human Rademacher complexities.  The results from empirical studies showed that: (i) human Rademacher complexity can be successfully measured  (ii) the complexity depends on the domain and training sample size in intuitive ways  (iii) human learning respects the generalization bounds  (iv) the bounds can be useful in predicting the danger of overfitting in human learning.  Finally  we discuss the potential applications of human Rademacher complexity in cognitive science.",Human Rademacher Complexity

Xiaojin Zhu1  Timothy T. Rogers2  Bryan R. Gibson1
Department of {1Computer Sciences  2Psychology}
University of Wisconsin-Madison. Madison  WI 15213

jerryzhu@cs.wisc.edu  ttrogers@wisc.edu  bgibson@cs.wisc.edu

Abstract

We propose to use Rademacher complexity  originally developed in computational
learning theory  as a measure of human learning capacity. Rademacher complex-
ity measures a learner’s ability to ﬁt random labels  and can be used to bound
the learner’s true error based on the observed training sample error. We ﬁrst re-
view the deﬁnition of Rademacher complexity and its generalization bound. We
then describe a “learning the noise” procedure to experimentally measure human
Rademacher complexities. The results from empirical studies showed that: (i)
human Rademacher complexity can be successfully measured  (ii) the complex-
ity depends on the domain and training sample size in intuitive ways  (iii) hu-
man learning respects the generalization bounds  (iv) the bounds can be useful in
predicting the danger of overﬁtting in human learning. Finally  we discuss the
potential applications of human Rademacher complexity in cognitive science.

1 Introduction

Many problems in cognitive psychology arise from questions of capacity. How much information
can human beings hold in mind and deploy in simple memory tasks [19  15  6]? What kinds of
functions can humans easily acquire when learning to classify items [29  7]  and do they have bi-
ases for learning some functions over others[10]? Is there a single domain-general answer to these
questions  or is the answer domain-speciﬁc [28]? How do human beings avoid over-ﬁtting learning
examples when acquiring knowledge that allows them to generalize [20]? Such questions are central
to a variety of research in cognitive psychology  but only recently have they begun to be placed on a
formal mathematical footing [7  9  5].

Machine learning offers a variety of formal approaches to measuring the capacity of a learning sys-
tem  with concepts such as Vapnik-Chervonenkis (VC) dimension [27  25  12] and Rademacher
complexity [1  13  24]. Based on these notions of capacity  one can quantify the generalization
performance of a classiﬁer  and the danger of over-ﬁtting  by bounding its future test error using
its observed training sample error.
In this paper  we show how one such concept–Rademacher
complexity–can be measured in humans  based on their performance in a “learning the noise” pro-
cedure. We chose Rademacher complexity (rather than the better-known VC dimension) because
it is particularly amenable to experimental studies  as discussed in Section 5. We assess whether
human capacity varies depending on the nature of the materials to be categorized  and empirically
test whether human generalization behavior respects the error bounds in a variety of categorization
tasks. The results validate Rademacher complexity as a meaningful measure of human learning
capacity  and provide a new perspective on the human tendency to overﬁt training data in category
learning tasks. We note that our aim is not to develop a new formal approach to complexity  but
rather to show how a well-studied formal measure can be computed for human beings.

1

2 Rademacher Complexity

Background and deﬁnitions. Let X be a domain of interest  which in psychology corresponds to a
stimulus space. For example  X could be an inﬁnite set of images parametrized by some continuous
parameters  a ﬁnite set of words  etc.. We will use x ∈ X to denote an instance (e.g.  an image
or a word) from the domain; precisely how x is represented is immaterial. We assume there is an
underlying marginal distribution PX on X   such that x is sampled with probability PX(x) during
training and testing. For example  PX can be uniform on the set of words.
Let f : X 7→ R be a real-valued function. This corresponds to a hypothesis that predicts the label
of any instance in the domain. The label can be a continuous value for regression  or {−1  1} for
binary classiﬁcation. Let F be the set of such functions  or the hypothesis space  that we consider.
For example  in machine learning F may be the set of linear classiﬁers. In the present work  we will
take F to be the (possibly inﬁnite) set of hypotheses from X to binary classes {−1  1} that humans
can come up with.
Rademacher complexity (see for example [1]) measures the capacity of the hypothesis space F by
how easy it is for F to ﬁt random noise. Consider a sample of n instances: x1  . . .   xn drawn
i.i.d. from PX. Now generate n random numbers σ1  . . .   σn  each taking value -1 or 1 with equal
i=1 σif(xi)|.
This is easier to understand when f produces -1  1 binary labels. In this case  the σ’s can be thought
of as random labels  and {(xi  σi)}n
i=1 as a training sample. The ﬁt measures how f’s predictions
match the random labels on the training sample: if f perfectly predicts the σ’s  or completely the
opposite by ﬂipping the classes  then the ﬁt is maximized at n; if f’s predictions are orthogonal to
the σ’s  the ﬁt is minimized at 0.

probability. For a given function f ∈ F  its ﬁt to the random numbers is deﬁned as |Pn

The ﬁt of a set of functions F is deﬁned as supf∈F |Pn

i=1 σif(xi)|. That is  we are ﬁtting the
particular training sample by ﬁnding the hypothesis in F with the best ﬁt. If F is rich  it will be
easier to ﬁnd a hypothesis f ∈ F that matches the random labels  and its ﬁt will be large. On the
other hand  if F is simple (e.g.  in the extreme containing only one function f)  it is unlikely that
f(xi) will match σi  and its ﬁt will be close to zero.
Finally  recall that {(xi  σi)}n
i=1 is a particular random training sample. If  for every random training
sample of size n  there always exists some f ∈ F (which may be different each time) that matches
it  then F is very good at ﬁtting random noise. This also means that F is prone to overﬁtting  whose
very deﬁnition is to learn noise. This is captured by taking the expectation over training samples:
Deﬁnition 1 (Rademacher Complexity). For a set of real-valued functions F with domain X   a
distribution PX on X   and a size n  the Rademacher complexity R(F X   PX   n) is

R(F X   PX   n) = Exσ

σif(xi)

 

(1)

"

sup
f∈F

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) 2

n

nX

i=1

#

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

2   1

iid∼ PX  and σ = σ1  . . .   σn

iid∼ Bernoulli( 1

2) with

where the expectation is over x = x1  . . .   xn
values ±1.
Rademacher complexity depends on the hypothesis space F  the domain X   the distribution on the
domain PX  as well as the training sample size n. The size n is relevant because for a ﬁxed F 
it will be increasingly difﬁcult to ﬁt random noise as n gets larger. On the other hand  it is worth
noting that Rademacher complexity is independent of any future classiﬁcation tasks. For example 
in Section 4 we will discuss two different tasks on the same X (set of words): classifying a word by
its emotional valence  or by its length. These two tasks will share the same Rademacher complexity.
In general  the value of Rademacher complexity will depend on the range of F. In the special case
when F is a set of functions mapping x to {−1  1}  R(F X   PX   n) is between 0 and 2.
A particularly important property of Rademacher complexity is that it can be estimated from random
samples. Let {(x(1)
i=1 be m random samples of size n each. In
Section 3  these will correspond to m different subjects. The following theorem is an extension of
Theorem 11 in [1]. The proof follows from McDiarmid’s inequality [16].

)}n
i=1  . . .  {(x(m)

  σ(m)

  σ(1)

)}n

i

i

i

i

2

Theorem 1. Let F be a set of functions mapping to [−1  1]. For any integers n  m 


(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)R(F X   PX   n) − 1

m

mX

j=1

P

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) 2

n

nX

i=1

sup
f∈F

i f(x(j)
σ(j)
i )

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) ≥ 
 ≤ 2 exp

(cid:18)

(cid:19)

(2)

− 2nm

8

Theorem 1 allows us to estimate the expectation in (1) with random samples  which is of practical
importance. It remains to compute the supremum in (1). In Section 3  we will discuss our procedure
to approximate the supremum in the case of human learning.
Generalization Error Bound. We state a generalization error bound by Bartlett and Mendelson
(Theorem 5 in [1]) as an important application of Rademacher complexity. Consider any binary
classiﬁcation task of predicting a label in Y = {−1  1} for x ∈ X . For example  the label y could be
the emotional valence (positive=1 vs. negative=-1) of a word x. In general  a binary classiﬁcation
task is characterized by a joint distribution PXY on X × {−1  1}. Training data and future test
data consist of instance-label pairs (x  y) iid∼ PXY . Let F be a set of binary classiﬁers that map
Pn
X to {−1  1}. For f ∈ F  let (y 6= f(x)) be an indicator function which is 1 if y 6= f(x)  and 0
otherwise. On a training sample {(xi  yi)}n
i=1 of size n  the observed training sample error of f is
i=1(yi 6= f(xi)). The more interesting quantity is the true error of f  i.e.  how well
ˆe(f) = 1
[(y 6= f(x))]. Rademacher complexity
f can generalize to future test data: e(f) = E
n
allows us to bound the true error using training sample error as follows.
Theorem 2. (Bartlett and Mendelson) Let F be a set of functions mapping X to {−1  1}. Let
PXY be a probability distribution on X × {−1  1} with marginal distribution PX on X . Let
{(xi  yi)}n
iid∼ PXY be a training sample of size n. For any δ > 0  with probability at least
1 − δ  every function f ∈ F satisﬁes

(x y)iid∼ PXY

i=1

e(f) − ˆe(f) ≤ R(F X   PX   n)

2

+

.

(3)

rln(1/δ)

2n

The probability 1 − δ is over random draws of the training sample. That is  if one draws a large
number of training samples of size n each  then (3) is expected to hold on 1 − δ fraction of those
samples. The bound has two factors  one from the Rademacher complexity and the other from
the conﬁdence parameter δ and training sample size n. When the bound is tight  training sample
error is a good indicator of true error  and we can be conﬁdent that overﬁtting is unlikely. A tight
bound requires the Rademacher complexity to be close to zero. On the other hand  if the Rademacher
complexity is large  or n is too small  or the requested conﬁdence 1− δ is overly stringent  the bound
can be loose. In that case  there is a danger of overﬁtting. We will demonstrate this generalization
error bound on four different human classiﬁcation tasks in Section 4.

3 Measuring Human Rademacher Complexity by Learning the Noise

Our aim is to measure the Rademacher complexity of the human learning system for a given stimulus
space X   distribution of instances PX  and sample-size n. By “human learning system ” we mean
the set of binary classiﬁcation functions that an average human subject can come up with on the
domain X   under the experiment conditions described below. We will denote this set of functions F
with Ha  that is  “average human.”
We make two assumptions. The ﬁrst is the assumption of universality [2]: every individual has the
same Ha. It allows us to pool subjects together. This assumption can be loosened in the future.
For instance  F could be deﬁned as the set of functions that a particular individual or group can
employ in the learning task  such as a given age-group  education level  or other special population.
A second assumption is required to compute the supremum on Ha. Obviously  we cannot measure
and compare the performance of every single function contained in Ha. Instead  we assume that 
when making their classiﬁcation judgments  participants use the best function at their disposal–so
that the errors they make when tested on the training instances reﬂect the error generated by the
best-performing function in Ha  thus providing a direct measure of the supremum. In essence  the
assumption is that participants are doing their best to perform the task.

3

i

i

i

i

i

i

i

n

(cid:12)(cid:12) 2

With the two assumptions above  we can compute human Rademacher complexity for a given
stimulus domain X   distribution PX  and sample size n  by assessing how well human partici-
pants are able to learn randomly-assigned labels. Each participant is presented with a training
i=1 where the σ’s are random ±1 labels  and asked to learn the instance-label
sample {(xi  σi)}n
Pn
mapping. The subject is not told that the labels are random. We assume that the subject will
search within Ha for the best hypothesis (“rule”)  which is the one that minimizes training error:
i=1 σif(xi) = argminf∈Ha ˆe(f). We do not directly observe f∗. Later  we
f∗ = argmaxf∈Ha
ask the subject to classify the same training instances {xi}n
i=1 using what she has learned. Her clas-
siﬁcation labels will be f∗(x1)  . . .   f∗(xn)  which we do observe. We then approximate the supre-
mum as follows: supf∈Ha
complexity to reﬂect actual learning capacity on the set Ha  it is important to prevent participants
from simply doing rote learning. With these considerations  we propose the following procedure to
estimate human Rademacher complexity.
Procedure. Given domain X   distribution PX  training sample size n  and number of subjects m 
we generate m random samples of size n each: {(x(1)
i=1  where
2) with value ±1  for j = 1 . . . m. The procedure is paper-
x(j)
i
and-pencil based  and consists of three steps:

i=1 σif∗(xi)(cid:12)(cid:12). For the measured Rademacher
Pn

i=1 σif(xi)(cid:12)(cid:12) ≈(cid:12)(cid:12) 2
Pn

Step 1. Participant j is shown a printed sheet with the training sample {(x(j)

i=1  where
each instance x(j)
(shown as “A” and “B” instead of -1 1 for
convenience). the participant is informed that there are only two categories; the order does not mat-
ter; they have three minutes to study the sheet; and later they will be asked to use what they have
learned to categorize more instances into “A” or “B”.

is paired with its random label σ(j)

)}n
i=1  . . .  {(x(m)

iid∼ PX and σ(j)

iid∼ Bernoulli( 1

  σ(m)

  σ(1)

  σ(j)

)}n

)}n

2   1

n

i

i

n

m

j=1

i }n

(cid:12)(cid:12)(cid:12) 2

i=1 σ(j)

Pn

We estimate

Pm

i f (j)(x(j)
i )

1 )  . . .   f (j)(x(j)

(encoded as ±1).

Step 2. After three minutes the sheet is taken away. To prevent active maintenance of training
items in working memory the participant performs a ﬁller task consisting of ten two-digit addi-
tion/subtraction questions.

n ) be subject j’s answers

Step 3. The participant is given another sheet with the same training instances {x(j)

i=1 but no
labels. The order of the n instances is randomized and different from step 1. The participant is not
told that they are the same training instances  and is asked to categorize each instance as “A” or “B”
and is encouraged to guess if necessary. There is no time limit.

(cid:12)(cid:12)(cid:12). We also conduct a post-experiment inter-

Let f (j)(x(j)
R(Ha X   PX   n) by 1
view where the subject reports any insights or hypotheses they may have on the categories.
Materials To instantiate the general procedure  one needs to specify the domain X and an associated
marginal distribution PX. For simplicity  in all our experiments PX is the uniform distribution over
the corresponding domain. We conducted experiments on example domains. They are not of spe-
ciﬁc interest in themselves but nicely illustrate many interesting properties of human Rademacher
complexity: (1) The “Shape” Domain. X consists of 321 computer-generated 3D shapes [3]. The
shapes are parametrized by a real number x ∈ [0  1]  such that small x produces spiky shapes  while
large x produces smooth ones. A few instances and their parameters are shown in Figure 1(a). It
is important to note that this internal structure is unnecessary to the deﬁnition or measurement of
Rademacher complexity per se. However  in Section 4 we will deﬁne some classiﬁcation tasks that
utilize this internal structure. Participants have little existing knowledge about this domain. (2) The
“Word” Domain. X consists of 321 English words. We start with the Wisconsin Perceptual At-
tribute Ratings Database [18]  which contains words rated by 350 undergraduates for their emotional
valence. We sort the words by their emotion valence  and take the 161 most positive and the 160
most negative ones for use in the study. A few instances and their emotion ratings are shown in
Figure 1(b). Participants have rich knowledge about this domain. The size of the domain for shapes
and words was matched to facilitate comparison.
Participants were 80 undergraduate students  participating for partial course credit. They were
divided evenly into eight groups. Each group of m = 10 subjects worked on a unique combination
of the Shape or the Word domain  and training sample size n in 5  10  20  or 40  using the procedure
deﬁned previously.

4

1/4

3/4

0
1
(a) examples from the Shape domain

1/2

rape
-5.60

killer
-5.55

funeral
-5.47

···
···

fun
4.91

laughter

4.95

joy
5.19

(b) examples from the Word domain

(c) R(Ha  Shape  uniform  n)

(d) R(Ha  Word  uniform  n)

Figure 1: Human Rademacher complexity on the “Shape” and “Word” domains.

Results. Figures 1(c d) show the measured human Rademacher complexities on the domains
X =Shape and Word respectively  with distribution PX=uniform  and with different training sam-
ple sizes n. The error bars are 95% conﬁdence intervals. Several interesting observations can be
made from the data:

Observation 1: human Rademacher complexities in both domains decrease as n increases. This is
anticipated  as it should be harder to learn a larger number of random labels. Indeed  when n = 5 
our interviews show that  in both domains  9 out of 10 participants offered some spurious rules
of the random labels. For example  one subject thought the shape categories were determined by
whether the shape “faces” downward; another thought the word categories indicated whether the
word contains the letter T. Such beliefs  though helpful in learning the particular training samples 
amount to over-ﬁtting the noise. In contrast  when n = 40  about half the participants indicated that
they believed the labels to be random  as spurious “rules” are more difﬁcult to ﬁnd.

Observation 2: human Rademacher complexities are signiﬁcantly higher in the Word domain than
in the Shape domain  for n = 10  20  40 respectively (t-tests  p < 0.05). The higher complexity
indicates that  for the same sample sizes  participants are better able to ﬁnd spurious explanations of
the training data for the Words than for the Shapes. Two distinct strategies were apparent in the Word
domain interviews: (i) Some participants created mnemonics. For example  one subject received the
training sample (grenade  B)  (skull  A)  (conﬂict  A)  (meadow  B)  (queen  B)  and came up with
the following story: “a queen was sitting in a meadow and then a grenade was thrown (B = before) 
then this started a conﬂict ending in bodies & skulls (A = after).” (ii) Other participants came up
with idiosyncratic  but often imperfect  rules. For instance  whether the item “tastes good ” “relates
to motel service ” or “physical vs. abstract.” We speculate that human Rademacher complexities on
other domains can be drastically different too  reﬂecting the richness of the participant’s pre-existing
knowledge about the domain.

Observation 3: many of these human Rademacher complexities are relatively large. This means that
under those X   PX   n  humans have a large capacity to learn arbitrary labels  and so will be more
prone to overﬁt on real (i.e.  non-random) tasks. We will present human generalization experiments
in Section 4. It is also interesting to note that both Rademacher complexities at n = 5 are less than 2:
under our procedure  participants are not perfect at remembering the labels of merely ﬁve instances.

4 Bounding Human Generalization Errors

We reiterate the interpretation of human Rademacher complexity for psychology. It does not predict
ˆe (how well humans perform when training for a given task). Instead  Theorem 2 bounds e − ˆe 
the “amount of overﬁtting” (sometimes also called “instability”) when the subject switches from
training to testing. A tight (close to 0) bound guarantees no severe overﬁtting: humans’ future

5

01020304000.511.52nRademacher complexity01020304000.511.52nRademacher complexityTable 1: Human learning performance abides by the generalization error bounds.

condition
Shape-+
n=5

Shape-+
n=40

Shape-+-
n=5

Shape-+-
n=40

ID
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100

ˆe
0.00
0.00
0.00
0.00
0.00
0.05
0.03
0.03
0.00
0.00
0.00
0.00
0.00
0.00
0.20
0.12
0.32
0.15
0.15
0.03

bound e
1.35
1.35
1.35
1.35
1.35
0.39
0.36
0.36
0.34
0.34
1.35
1.35
1.35
1.35
1.55
0.46
0.66
0.49
0.49
0.36

e
0.05
0.22
0.10
0.09
0.07
0.04
0.14
0.03
0.04
0.01
0.23
0.27
0.21
0.40
0.18
0.16
0.50
0.08
0.11
0.10

condition
WordEmotion
n=5

WordEmotion
n=40

WordLength
n=5

WordLength
n=40

ID
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120

ˆe
0.00
0.00
0.00
0.00
0.00
0.70
0.00
0.00
0.62
0.00
0.00
0.00
0.00
0.00
0.00
0.12
0.45
0.00
0.15
0.15

bound e
1.43
1.43
1.43
1.43
1.43
1.23
0.53
0.53
1.15
0.53
1.43
1.43
1.43
1.43
1.43
0.65
0.98
0.53
0.68
0.68

e
0.58
0.46
0.04
0.03
0.31
0.65
0.04
0.00
0.53
0.05
0.46
0.69
0.55
0.26
0.57
0.51
0.55
0.00
0.29
0.37

test performance e will be close to their training performance ˆe. This does not mean they will do
well: ˆe could be large and thus e is similarly large. A loose bound  in contrast  is a warning sign for
overﬁtting: good training performance (small ˆe) may not reﬂect learning of the correct categorization
rule  and so does not entail good performance on future samples (i.e.  e can be much larger than ˆe).
We now present four non-random category-learning tasks to illustrate these points.
Materials. We consider four very different binary classiﬁcation tasks to assess whether Theorem 2
holds for all of them. The tasks are: (1) Shape-+: Recall the Shape domain is parametrized by
x ∈ [0  1]. The task has a linear decision boundary at x = 0.5  i.e.  P (y = 1|x) = 0 if x < 0.5 
and 1 if x ≥ 0.5. It is well-known that people can easily learn such boundaries  so this is a fairly
easy task on the domain. (2) Shape-+-: This task is also on the Shape domain  but with a nonlinear
decision boundary. The negative class is on both ends while the positive class is in the middle:
P (y = 1|x) = 0 if x ∈ [0  0.25) ∪ (0.75  1]  and 1 if x ∈ [0.25  0.75]. Prior research suggests that
people have difﬁculty learning nonlinearly separable categories [28  7]  so this is a harder task. Note 
however  that the two shape tasks share the same Rademacher complexity  and therefore have the
same bound for the same n. (3) WordEmotion: This task is on the Word domain. P (y = 1|x) = 0
if word x has a negative emotion rating in the Wisconsin Perceptual Attribute Ratings Database  and
P (y = 1|x) = 1 otherwise. (4) WordLength: P (y = 1|x) = 0 if word x has 5 or less letters 
and P (y = 1|x) = 1 otherwise. The two word tasks are drastically different in that one focuses on
semantics and the other on orthography  but they share the same Rademacher complexity and thus
the same bound (for the same n)  because the underlying domain is the same.
Procedure. The procedure is identical to that in Section 3 except for two things:
(i) Instead
of random labels σ  we sample labels y iid∼ P (y|x) appropriate for each task.
(ii) In step 3 
in addition to the training instances {x(j)
i=1  the jth subject is also given 100 test instances
{x(j)
i=n+1  sampled from PX. The order of the training and test instances is randomized.
The true test labels y are sampled from P (y|x). We compute the participant’s training sam-
  and estimate her generalization error as

i }n+100

(cid:17)

ple error as ˆe(f (j)) = 1/nPn
e(f (j)) = 1/100Pn+100

(cid:16)

i }n
(cid:17)

(cid:16)

yi 6= f (j)(x(j)
i )
yi 6= f (j)(x(j)
i )

i=1

.

i=n+1

Participants were 40 additional students  randomly divided into 8 groups of ﬁve each. Each group
worked on one of the four tasks  with training sample size n=5 or 40.
Results. We present the performance of individual participants in Table 1: ˆe is the observed train-
ing error for that subject  “bound e” is the 95% conﬁdence (i.e.  δ = 0.05) bound on test error:

6

Figure 2: Human Rademacher complexity predicts the trend of overﬁtting.

ˆe(f) + R(F X   PX   n)/2 +pln(1/δ)/2n  and e is the observed test error. We also present the

aggregated results across subjects and tasks in Figure 2  comparing the bound on e− ˆe (the “amount
of overﬁtting ” RHS of (3)) vs. the observed e− ˆe  as the underlying Rademacher complexity varies.
We make two more observations:

Observation 4: Theorem 2 holds for every participant. Table 1 provides empirical support that our
application of computational learning theory to human learning is viable. In fact  for our choice of
δ = 0.05  Theorem 2 allows the bound to fail on about two (5% of 40) participants – which did
not happen. Of course  some of the “bound e” are vacuous (greater than 1) as it is well-known that
bounds in computational learning theory are not always tight [14]  but others are reasonably tight
(e.g.  on Shape-+ with n = 40).
Observation 5: the larger the Rademacher complexity  the worse the actual amount of overﬁtting
e − ˆe. Figure 2 shows that as R increases  e − ˆe increases (solid line; error bar ±standard error;
averaged over the two different tasks with the same domain and n  as noted in the graph). The bound
on e − ˆe (dotted line; RHS of (3)) has the same trend  although  being loose  it is higher up. This
seems to be true regardless of the classiﬁcation task. For example  the Word domain and n = 5 has
a large Rademacher complexity 1.76  and both task WordLength and task WordEmotion severely
overﬁt: In task WordLength with n = 5  all subjects had zero training error but had large test error 
suggesting that their good performance on the training items reﬂects overﬁtting. Accordingly  the
explanations offered during the post-test interviews for this group spuriously ﬁt the training items
but did not reﬂect the true categorization rule. Subject 111 thought that the class decision indicated
“things you can go inside ” while subject 114 thought the class indicated an odd or even number of
syllables. Similarly  on task WordEmotion with n = 5  three out of ﬁve subjects overﬁt the training
items. Subject 102 received the training items (daylight  1)  (hospital  -1)  (termite  -1)  (envy  -1) 
(scream  -1)  and concluded that class 1 is “anything related to omitting[sic] light ” and proceeded
to classify the test items as such.

5 Discussions and Future Work

Is our study on memory or learning? This distinction is not necessarily relevant here  as we adopt
an abstract perspective which analyzes the human system as a black box that produces labels  and
both learning and memory contribute to the process being executed in that black box. We do have
evidence from post-interviews that Figure 1 does not merely reﬂect list-length effects from memory
studies: (i) participants treated the study as a category-learning and not a memory task – they were
not told that the training and test items are the same when we estimate R; (ii) the memory load was
identical in the shape and the word domains  yet the curves differ markedly; (iii) participants were
able to articulate the “rules” they were using to categorize the items.

Much recent research has explored the relationship between the statistical complexity of some cate-
gorization task and the ease with which humans learn the task [7  5  9  11]. Rademacher complexity
is different: it indexes not the complexity of the X 7→ Y categorization task  but the sophistication
of the learner in domain X (note Y does not appear in Rademacher complexity). Greater complex-
ity indicates  not a more difﬁcult categorization task  but a greater tendency to overﬁt sparse data.

7

00.511.5200.511.5Rademacher complexitye − e^ Shape 40Word 40Shape 5Word 5boundobservedOn the other hand  our deﬁnition of Rademacher complexity depends only on the domain  distribu-
tion  and sample size. In human learning  other factors also contribute to learnability  such as the
instructions  motivation  time to study  and should probably be incorporated into the complexity.

Human Rademacher complexity has interesting connections to other concepts.
The VC-
dimension [27  25  12] is another capacity measure. Let {x1  . . .   xm} ⊆ X be a subset of
the domain. Let (f(x1)  . . .   f(xm)) be a ±1-valued vector which is the classiﬁcations made
by some f ∈ F.
If F is rich enough such that its members can produce all 2m vectors:
{(f(x1)  . . .   f(xm)) : f ∈ F} = {−1  1}m  then we say that the subset is shattered by F. The
VC-dimension of F is the size of the largest subset that can be shattered by F  or ∞ if F can shatter
arbitrarily large subsets. Unfortunately  human VC-dimension seems difﬁcult to measure experi-
mentally: First  shattering requires validating an exponential (2m) number of classiﬁcations on a
given subset. Second  to determine that the VC-dimension is m  one needs to show that no subset
of size m + 1 can be shattered. However  the number of such subsets can be inﬁnite. A variant 
“effective VC-dimension”  may be empirically estimated from a training sample [26]. This is left
for future research. Normalized Maximum Likelihood (NML) uses a similar complexity measure
for a model class [21]  the connection merits further study ([23]  p.50).

Human Rademacher complexity might help to advance theories of human cognition in many ways.
First  human Rademacher complexity can provide a means of testing computational models of hu-
man concept learning. Traditionally  such models are assessed by comparing their performance to
human performance in terms of classiﬁcation error. A new approach would be to derive or empiri-
cally estimate the Rademacher complexity of the computational models  and compare that to human
Rademacher complexity. A good computational model should match humans in this regard.

Second  our procedure could be used to measure human Rademacher complexity in individuals or
special populations  including typically and atypically-developing children and adults. Relating in-
dividual Rademacher complexity to standard measures of learning ability or IQ may shed light on
the relationship between complexity  learning  and intelligence. Many IQ tests measure the partici-
pant’s ability to generalize the pattern in words or images. Individuals with very high Rademacher
complexity may actually perform worse by being “distracted” by other potential hypotheses.

Third  human Rademacher complexity may help explain the human tendency to discern patterns in
random stimuli  such as the well-known Rorschach inkblot test  “illusory correlations” [4]  or “false-
memory” effect [22]. These effects may be viewed as spurious rule-ﬁtting to (or generalization of)
the observed data  and Human Rademacher complexity may quantify the possibility of observing
such an effect.

Fourth  cognitive psychologists have long entertained an interest in characterizing the capacity of
different mental processes such as  for instance  the capacity limitations of short-term memory [19 
6]. In this vein  our work suggests a different kind of metric for assessing the capacity of the human
learning system.

Finally  human Rademacher complexity can help experimental psychologists to determine the
propensity of overﬁtting in their stimulus materials. We have seen that human Rademacher complex-
ity can be much higher in some domains (e.g. Word) than others (e.g. Shape). Our procedure could
be used to measure the human Rademacher complexity of many standard concept-learning materials
in cognitive science  such as the Greebles used by Tarr and colleagues [8] and the circle-and-line
stimuli of McKinley & Nosofsky [17].
Acknowledgment: We thank the reviewers for their helpful comments. XZ thanks Michael Coen for discus-
sions that lead to the realization of the difﬁculties in measuring human VC dimension. This work is supported
in part by AFOSR grant FA9550-09-1-0313 and the Wisconsin Alumni Research Foundation.

References

[1] P. L. Bartlett and S. Mendelson. Rademacher and Gaussian complexities: risk bounds and structural

results. Journal of Machine Learning Research  3:463–482  2002.

[2] A. Caramazza and M. McCloskey. The case for single-patient studies. Cognitive Neuropsychology 

5(5):517–527  1988.

[3] R. Castro  C. Kalish  R. Nowak  R. Qian  T. Rogers  and X. Zhu. Human active learning. In Advances in

Neural Information Processing Systems (NIPS) 22. 2008.

8

[4] L. J. Chapman.

Illusory correlation in observational report. Journal of Verbal Learning and Verbal

Behavior  6:151–155  1967.

[5] N. Chater and P. Vitanyi. Simplicity: A unifying principle in cognitive science? Trends in Cognitive

Science  7(1):19–22  2003.

[6] N. Cowan. The magical number 4 in short-term memory: A reconsideration of mental storage capacity.

Behavioral and Brain Sciences  24:87–185  2000.

[7] J. Feldman. Minimization of boolean complexity in human concept learning. Nature  407:630–633  2000.
[8] I. Gauthier and M. Tarr. Becoming a ”greeble” expert: Exploring mechanisms for face recognition. Vision

Research  37(12):1673–1682  1998.

[9] N. Goodman  J. B. Tenenbaum  J. Feldman  and T. L. Grifﬁths. A rational analysis of rule-based concept

learning. Cognitive Science  32(1):108–133  2008.

[10] T. L. Grifﬁths  B. R. Christian  and M. L. Kalish. Using category structures to test iterated learning as a

method for identifying inductive biases. Cognitive Science  32:68–107  2008.

[11] T. L. Grifﬁths and J. B. Tenenbaum. From mere coincidences to meaningful discoveries. Cognition 

103(2):180–226  2007.

[12] M. J. Kearns and U. V. Vazirani. An Introduction to Computational Learning Theory. MIT Press  1994.
[13] V. I. Koltchinskii and D. Panchenko. Rademacher processes and bounding the risk of function learning.
In E. Gine  D. Mason  and J. Wellner  editors  High Dimensional Probability II  pages 443–459. MIT
Press  2000.

[14] J. Langford. Tutorial on practical prediction theory for classiﬁcation. Journal of Machine Learning

Research  6:273–306  2005.

[15] R. L. Lewis. Interference in short-term memory: The magical number two (or three) in sentence process-

ing. Journal of Psycholinguistic Research  25(1):93–115  1996.

[16] C. McDiarmid. On the method of bounded differences. In Surveys in Combinatorics 1989  pages 148–

188. Cambridge University Press  1989.

[17] S. C. McKinley and R. M. Nosofsky. Selective attention and the formation of linear decision boundaries.

Journal of Experimental Psychology: Human Perception & Performance  22(2):294–317  1996.

[18] D. Medler  A. Arnoldussen  J. Binder  and M. Seidenberg. The Wisconsin perceptual attribute ratings

database  2005. http://www.neuro.mcw.edu/ratings/.

[19] G. Miller. The magical number seven plus or minus two: Some limits on our capacity for processing

information. Psychological Review  63(2):81–97  1956.

[20] R. C. O’Reilly and J. L. McClelland. Hippocampal conjunctive encoding  storage  and recall: Avoiding a

tradeoff. Hippocampus  4:661–682  1994.

[21] J. Rissanen. Strong optimality of the normalized ML models as universal codes and information in data.

IEEE Transaction on Information Theory  47(5):17121717  2001.

[22] H. L. Roediger and K. B. McDermott. Creating false memories: Remembering words not presented in

lists. Journal of Experimental Psychology: Learning  Memory and Cognition  21(4):803–814  1995.

[23] T. Roos. Statistical and Information-Theoretic Methods for Data Analysis. PhD thesis  Department of

Computer Science  University of Helsinki  2007.

[24] J. Shawe-Taylor and N. Cristianini. Kernel Methods for Pattern Analysis. Cambridge University Press 

New York  NY  USA  2004.

[25] V. Vapnik. Statistical Learning Theory. Wiley-Interscience  1998.
[26] V. Vapnik  E. Levin  and Y. Le Cun. Measuring the VC-dimension of a learning machine. Neural Com-

putation  6:851–876  1994.

[27] V. N. Vapnik and A. Y. Chervonenkis. On the uniform convergence of relative frequencies of events to

their probabilities. Theory of Probability and its Applications  16(2):264–280  1971.

[28] W. D. Wattenmaker. Knowledge structures and linear separability: Integrating information in object and

social categorization. Cognitive Psychology  28(3):274–328  1995.

[29] W. D. Wattenmaker  G. I. Dewey  T. D. Murphy  and D. L. Medin. Linear separability and concept
learning: Context  relational properties  and concept naturalness. Cognitive Psychology  18(2):158–194 
1986.

9

,Minh Ha Quang
Marco San Biagio
Vittorio Murino
Huan Li
Zhouchen Lin