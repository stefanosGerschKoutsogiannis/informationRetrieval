2017,Learning Neural Representations of Human Cognition across Many fMRI Studies,Cognitive neuroscience is enjoying rapid increase in extensive public brain-imaging datasets. It opens the door to large-scale statistical models. Finding a unified perspective for all available data calls for scalable and automated solutions to an old challenge: how to aggregate heterogeneous information on brain function into a universal cognitive system that relates mental operations/cognitive processes/psychological tasks to brain networks? We cast this challenge in a machine-learning approach to predict conditions from statistical brain maps across different studies. For this  we leverage multi-task learning and multi-scale dimension reduction to learn low-dimensional representations of brain images that carry cognitive information and can be robustly associated with psychological stimuli. Our multi-dataset classification model achieves the best prediction performance on several large reference datasets  compared to models without cognitive-aware low-dimension representations; it brings a substantial performance boost to the analysis of small datasets  and can be introspected to identify universal template cognitive concepts.,Learning Neural Representations of

Human Cognition across Many fMRI Studies

Arthur Mensch∗

Inria

arthur.mensch@m4x.org

Julien Mairal†

Inria

julien.mairal@inria.fr

Bertrand Thirion∗

Inria

Danilo Bzdok

Department of Psychiatry  RWTH
danilo.bzdok@rwth-aachen.de

Gaël Varoquaux∗

Inria

bertrand.thirion@inria.fr

gael.varoquaux@inria.fr

Abstract

Cognitive neuroscience is enjoying rapid increase in extensive public brain-imaging
datasets. It opens the door to large-scale statistical models. Finding a uniﬁed
perspective for all available data calls for scalable and automated solutions to
an old challenge: how to aggregate heterogeneous information on brain func-
tion into a universal cognitive system that relates mental operations/cognitive
processes/psychological tasks to brain networks? We cast this challenge in a
machine-learning approach to predict conditions from statistical brain maps across
different studies. For this  we leverage multi-task learning and multi-scale dimen-
sion reduction to learn low-dimensional representations of brain images that carry
cognitive information and can be robustly associated with psychological stimuli.
Our multi-dataset classiﬁcation model achieves the best prediction performance
on several large reference datasets  compared to models without cognitive-aware
low-dimension representations; it brings a substantial performance boost to the
analysis of small datasets  and can be introspected to identify universal template
cognitive concepts.

Due to the advent of functional brain-imaging technologies  cognitive neuroscience is accumulating
quantitative maps of neural activity responses to speciﬁc tasks or stimuli. A rapidly increasing
number of neuroimaging studies are publicly shared (e.g.  the human connectome project  HCP [1]) 
opening the door to applying large-scale statistical approaches [2]. Yet  it remains a major challenge
to formally extract structured knowledge from heterogeneous neuroscience repositories. As stressed
in [3]  aggregating knowledge across cognitive neuroscience experiments is intrinsically difﬁcult due
to the diverse nature of the hypotheses and conclusions of the investigators. Cognitive neuroscience
experiments aim at isolating brain effects underlying speciﬁc psychological processes: they yield
statistical maps of brain activity that measure the neural responses to carefully designed stimulus.
Unfortunately  neither regional brain responses nor experimental stimuli can be considered to be
atomic: a given experimental stimulus recruits a spatially distributed set of brain regions [4]  while
each brain region is observed to react to diverse stimuli. Taking advantage of the resulting data
richness to build formal models describing psychological processes requires to describe each cognitive

∗Inria  CEA  Université Paris-Saclay  91191 Gif sur Yvette  France
†Univ. Grenoble Alpes  Inria  CNRS  Grenoble INP  LJK  38000 Grenoble  France

31st Conference on Neural Information Processing Systems (NIPS 2017)  Long Beach  CA  USA.

conclusion on a common basis for brain response and experimental study design. Uncovering atomic
basis functions that capture the neural building blocks underlying cognitive processes is therefore a
primary goal of neuroscience [5]  for which we propose a new data-driven approach.
Several statistical approaches have been proposed to tackle the problem of knowledge aggregation in
functional imaging. A ﬁrst set of approaches relies on coordinate-based meta-analysis to deﬁne robust
neural correlates of cognitive processes: those are extracted from the descriptions of experiments —
based on categories deﬁned by text mining [6] or expert [7]— and correlated with brain coordinates
related to these experiments. Although quantitative meta-analysis techniques provide useful sum-
maries of the existing literature  they are hindered by label noise in the experiment descriptions  and
weak information on brain activation as the maps are reduced to a few coordinates [8]. A second 
more recent set of approaches models directly brain maps across studies  either focusing on studies
on similar cognitive processes [9]  or tackling the entire scope of cognition [10  11]. Decoding  i.e.
predicting the cognitive process from brain activity  across many different studies touching different
cognitive questions is a key goal for cognitive neuroimaging as it provides a principled answer to
reverse inference [12]. However  a major roadblock to scaling this approach is the necessity to label
cognitive tasks across studies in a rich but consistent way  e.g.  building an ontology [13].
We follow a more automated approach and cast dataset accumulation into a multi-task learning
problem: our model is trained to decode simultaneously different datasets  using a shared architecture.
Machine-learning techniques can indeed learn universal representations of inputs that give good
performance in multiple supervised problems [14  15]. They have been successful  especially with
the development of deep neural network [see  e.g.  16]  in sharing representations and transferring
knowledge from one dataset prediction model to another (e.g.  in computer-vision [17] and audio-
processing [18]). A popular approach is to simultaneously learn to represent the inputs of the
different datasets in a low-dimensional space and to predict the outputs from the low-dimensional
representatives. Using very deep model architectures in functional MRI is currently thwarted by the
signal-to-noise ratio of the available recordings and the relative little size of datasets [19] compared
to computer vision and text corpora. Yet  we show that multi-dataset representation learning is a
fertile ground for identifying cognitive systems with predictive power for mental operations.

Contribution. We introduce a new model architecture dedicated to multi-dataset classiﬁcation  that
performs two successive linear dimension reductions of the input statistical brain images and predicts
psychological conditions from a learned low-dimensional representation of these images  linked to
cognitive processes. In contrast to previous ontology-based approaches  imposing a structure across
different cognitive experiments is not needed in our model: the representation of brain images is
learned using the raw set of experimental conditions for each dataset. To our knowledge  this work is
the ﬁrst to propose knowledge aggregation and transfer learning in between functional MRI studies
with such modest level of supervision. We demonstrate the performance of our model on several
openly accessible and rich reference datasets in the brain-imaging domain. The different aspects of
its architecture bring a substantial increase in out-of-sample accuracy compared to models that forgo
learning a cognitive-aware low-dimensional representation of brain maps. Our model remains simple
enough to be interpretable: it can be collapsed into a collection of classiﬁcation maps  while the space
of low-dimensional representatives can be explored to uncover a set of meaningful latent components.

1 Model: multi-dataset classiﬁcation of brain statistical images

Our general goal is to extract and integrate biological knowledge across many brain-imaging studies
within the same statistical learning framework. We ﬁrst outline how analyzing large repositories of
fMRI experiments can be cast as a classiﬁcation problem. Here  success in capturing brain-behavior
relationships is measured by out-of-sample prediction accuracy. The proposed model (Figure 1)
solves a range of these classiﬁcation problems in an identical statistical estimation and imposes
a shared latent structure across the single-dataset classiﬁcation parameters. These shared model
parameters may be viewed as a chain of two dimension reductions. The ﬁrst reduction layer leverages
knowledge about brain spatial regularities; it is learned from resting-state data and designed to capture
neural activity patterns at different coarseness levels. The second reduction layer projects data on
directions generally relevant for cognitive-state prediction. The combination of both reductions
yields low-dimensional representatives that are less affected by noise and subject variance than

2

Figure 1: Model architecture: Three-layer multi-dataset classiﬁcation. The ﬁrst layer (orange) is
learned from data acquired outside of cognitive experiments and captures a spatially coherent signal
at multiple scales  the second layer (blue) embeds these representations in a space common to all
datasets  from which the conditions are predicted (pink) from multinomial models.

the high-dimensional samples: classiﬁcation is expected to have better out-of-sample prediction
performance.

1.1 Problem setting: predicting conditions from brain activity in multiple studies

We ﬁrst introduce our notations and terminology  and formalize a general prediction problem applica-
ble to any task fMRI dataset. In a single fMRI study  each subject performs different experiments
in the scanner. During such an experiment  the subjects are presented a set of sensory stimuli (i.e. 
conditions) that aim at recruiting a target set of cognitive processes. We ﬁt a ﬁrst-level general linear
model for every record to obtain z-score maps that quantify the importance of each condition in
explaining each voxel. Formally  the n statistical maps (xi)i∈[n] of a given study form a sequence
in Rp  where p is the number of voxels in the brain. Each such observation is labelled by a condition ci
in [1  k] whose effect captures xi. A single study typically features one or a few (if experiments are
repeated) statistical map per condition and per subject  and may present up to k = 30 conditions.
Across the studies  the observed brain maps can be modeled as generated from an unknown joint
distribution of brain activity and associated cognitive conditions ((xi  ci))i∈[n] where variability
across trials and subjects acts as confounding noise. In this context  we wish to learn a decoding
model that predicts condition c from brain activity x measured from new subjects or new studies.
Inspired by recent work [10  20  21]  we frame the condition prediction problem into the estimation
of a multinomial classiﬁcation model. Our models estimate a probability vector of x being labeled by
each condition in C. This vector is modeled as a function of (W  b) in Rp×k × Rk that takes the
softmax form. For all j in [1  k]  its j-th coordinate is deﬁned as

p(x  W  b)j (cid:44) P[c = j|x  W  b] =

.

x+b

(1)

(cid:80)

x+b

eW(j)(cid:62)
l∈C eW(l)(cid:62)

Fitting the model weights is done by minimizing the cross-entropy between (p(xi))i and the true
labels ([ci = j]j∈[k])i  with respect to (W  b)  with or without imposing parameter regularization.
In this model  an input image is classiﬁed in between all conditions presented in the whole study.
It is possible to restrict this classiﬁcation to the set of conditions used in a given experiment — the
empirical results of this study can be reproduced in this setting.

The challenge of model parameter estimation. A major inconvenience of the vanilla multinomial
model lies in the ratio between the limited number of samples provided by a typical fMRI dataset
and the overwhelming number of model weights to be estimated. Fitting the model amounts to
estimating k discriminative brain map  i.e. millions of parameters (4M for the 23 conditions of HCP) 
whereas most brain-imaging studies yield less than a hundred observations and therefore only a few
thousands samples. This makes it hard to reasonably approximate the population parameters for
successful generalization  especially because the variance between subjects is high compared to the

3

variance between conditions. The obstacle is usually tackled in one of two major ways in brain-
imaging: 1) we can impose sparsity or a-priori structure over the model weights. Alternatively  2) we
can reduce the dimension of input data by performing spatial clustering or univariate feature selection
by ANOVA. However  we note that  on the one hand  regularization strategies frequently incur costly
computational budgets if one wants to obtain interpretable weights [22] and they introduce artiﬁcial
bias. On the other hand  existing techniques developed in fMRI analysis for dimension reduction can
lead to distorted signal and accuracy losses [23]. Most importantly  previous statistical approaches
are not tuned to identifying conditions from task fMRI data. We therefore propose to use a dimension
reduction that is estimated from data and tuned to capture the common hidden aspects shared by
statistical maps across studies — we aggregate several classiﬁcation models that share parameters.

1.2 Learning shared representation across studies for decoding

We write D the set of all studies  Cd the set of all kd conditions from study d  k (cid:44)(cid:80)

We now consider several fMRI studies. (xi)i∈[n] is the union of all statistical maps from all datasets.
d kd the total
number of conditions and Sd the subset of [n] that index samples of study d. For each study d 
we estimate the parameters (Wd  bd) for the classiﬁcation problem deﬁned above. Adapting the
multi-task learning framework of [14]  we constrain the weights (Wd)d to share a common latent
structure: namely  we ﬁx a latent dimension l ≤ p  and enforce that for all datasets d 

Wd = WeW(cid:48)
d 

(2)
where the matrix We in Rp×l is shared across datasets  and (W(cid:48)
d)d are dataset-speciﬁc classiﬁcation
matrices from a l dimensional input space. Intuitively  We should be a “consensus” projection matrix 
that project every sample xi from every dataset onto a lower dimensional representation W(cid:62)
e xi in Rl
that is easy to label correctly.
The latent dimension l may be chosen larger than k. In this case  regularization is necessary to
ensure that the factorization (2) is indeed useful  i.e.  that the multi-dataset classiﬁcation problem
does not reduce to separate multinomial regressions on each dataset. To regularize our model  we
apply Dropout [24] to the projected data representation. Namely  during successive training iterations 
we set a random fraction r of the reduced data features to 0. This prevents the co-adaptation of
matrices We and (W(cid:48)
d)d and ensures that every direction of We is useful for classifying every
dataset. Formally  Dropout amounts to sample binary diagonal matrices M in Rl×l during training 
with Bernouilli distributed coefﬁcients; for all datasets d  W(cid:48)
d is estimated through the task of
classifying Dropout-corrupted reduced data (MW(cid:62)
In practice  matrices We and (W(cid:48)
d)d are learned by jointly minimizing the following expected risk 
where the objective is the sum of each of single-study cross-entropies  averaged over Dropout noise:

e xi)i∈Sd M∼M.

(cid:2) − δj=ci log pd[xi  WeMW(cid:48)

d  bd]j](cid:3)

EM

(cid:88)

d∈D

1
|Sd|

(cid:88)

(cid:88)

i∈Sd

j∈Cd

min
We
(W(cid:48)

d)d

(3)

Imposing a common structure to the classiﬁcation matrices (Wd)d is natural as the classes to be
distinguished do share some common neural organization — brain maps have a correlated spatial
structure  while the psychological conditions of the diffent datasets may trigger shared cognitive
primitives underlying human cognition [21  20]. With our design  we aim at learning a matrix We
that captures these common aspects and thus beneﬁts the generalization performance of all the
classiﬁers. As We is estimated from data  brain maps from one study are enriched by the maps from
all the other studies  even if the conditions to be classiﬁed are not shared among studies. In so doing 
our modeling approach allows transfer learning among all the classiﬁcation tasks.
Unfortunately  estimators provided by solving (3) may have limited generalization performance as n
remain relatively small (∼ 20  000) compared to the number of parameters. We address this issue by
performing an initial dimension reduction that captures the spatial structure of brain maps.

1.3

Initial dimension reduction using localized rest-fMRI activity patterns

The projection expressed by We ignores the signal structure of statistical brain maps. Acknowledging
this structure in commonly acquired brain measurements should allow to reduce the dimensionality
of data with little signal loss  and possibly the additional beneﬁt of a denoising effect. Several recent

4

studies [25] in the brain-imaging domain suggest to use fMRI data acquired in experiment-free studies
for such dimension reduction. For this reason  we introduce a ﬁrst reduction of dimension that is not
estimated from statistical maps  but from resting-state data. Formally  we enforce We = WgW(cid:48)
e 
e ∈ Rg×k. Intuitively  the multiplication by matrix Wg
where g > l (g ∼ 300)  Wg ∈ Rp×g and W(cid:48)
should summarize the spatial distribution of brain maps  while multiplying by W(cid:48)
e  that is estimated
solving (3)  should ﬁnd low-dimensional representations able to capture cognitive features. W(cid:48)
is now of reasonable size (g × l ∼ 15000): solving (3) should estimate parameters with better
e
generalization performance. Deﬁning an appropriate matrix Wg is the purpose of the next paragaphs.

Resting-state decomposition. The initial dimension reduction determines the relative contribution
of statistical brain maps over what is commonly interpreted by neuroscience investigators as functional
networks. We discover such macroscopical brain networks by performing a sparse matrix factorization
over the massive resting-state dataset provided in the HCP900 release [1]: such a decomposition
technique  described e.g.  in [26  27] efﬁciently provides (i.e.  in the order of few hours) a given
number of sparse spatial maps that decompose the resting state signal with good reconstruction
performance. That is  it ﬁnds a sparse and positive matrix D in Rp×g and loadings A in Rg×m such
that the m resting-state brain images Xrs in Rp×m are well approximated by DA. D is this a set
of slightly overlapping networks — each voxel belongs to at most two networks. To maximally
preserve Euclidian distance when performing the reduction  we perform an orthogonal projection 
which amounts to setting Wg (cid:44) D(D(cid:62)D)−1. Replacing in (3)  we obtain the reduced expected risk
minimization problem  where the input dimension is now the number g of dictionary components:

g xi  W(cid:48)

eMW(cid:48)

d  bd]
j

(4)

(cid:3).

(cid:88)

d∈D

(cid:88)

(cid:88)

i∈Sd

j∈Cd

1
|Sd|

(cid:2) − δj=cilog pd[W(cid:62)

EM

min
e∈Rg×l
W(cid:48)
(W(cid:48)
d)d

Multiscale projection. Selecting the “best” number of brain networks q is an ill-posed prob-
lem [28]: the size of functional networks that will prove relevant for condition classiﬁcation is
unknown to the investigator. To address this issue  we propose to reduce high-resolution data (xi)i
in a multi-scale fashion: we initially extract 3 sparse spatial dictionaries (Dj)j∈[3] with 16  64
and 512 components respectively. Then  we project statistical maps onto each of the dictionaries 
and concatenate the loadings  in a process analogous to projecting on an overcomplete dictionary in
computer vision [e.g.  29]. This amounts to deﬁne the matrix Wg as the concatenation
3 D3)−1] ∈ Rp×(16+64+512).

1 D1)−1 D2(D(cid:62)
(5)
With this deﬁnition  the reduced data (W(cid:62)
i carry information about the network activations
at different scales. As such  it makes the classiﬁcation maps learned by the model more regular
than when using a single-scale dictionary  and indeed yields more interpretable classiﬁcation maps.
However  it only brings only a small improvement in term of predictive accuracy  compared to using
a simple dictionary of size k = 512. We further discuss multi-scale decomposition in Appendix A.2.

2 D2)−1 D3(D(cid:62)
g xi)

Wg (cid:44) [D1(D(cid:62)

1.4 Training with stochastic gradient descent

As illustrated in Figure 1  our model may be interpreted as a three-layer neural network with linear
activations and several read-out heads  each corresponding to a speciﬁc dataset. The model can be
trained using stochastic gradient descent  following a previously employed alternated training scheme
[18]: we cycle through datasets d ∈ D and select  at each iteration  a mini-batch of samples (xi)i∈B 
where B ⊂ Sd has the same size for all datasets. We perform a gradient step — the weights W(cid:48)
d  bd
and W(cid:48)
e are updated  while the others are left unchanged. The optimizer thus sees the same number
of samples for each dataset  and the expected stochastic gradient is the gradient of (4)  so that the
empirical risk decreases in expectation and we ﬁnd a critical point of (4) asymptotically. We use the
Adam solver [30] as a ﬂavor of stochastic gradient descent  as it allows faster convergence.
Computational cost. Training the model on projected data (W(cid:62)
i takes 10 minutes on a conven-
tional single CPU machine with an Intel Xeon 3.21Ghz. The initial step of computing the dictionaries
(D1  D2  D3) from all HCP900 resting-state (4TB of data) records takes 5 hours using [27]  while
transforming data from all the studies with Wg projection takes around 1 hour. Adding a new dataset
with 30 subjects to our model and performing the joint training takes no more than 20 minutes. This
is much less than the cost of ﬁtting a ﬁrst-level GLM on this dataset (∼ 1h per subject).

g xi)

5

2 Experiments

We characterize the behavior and performance of our model on several large  publicly available
brain-imaging datasets. First  to validate the relevance of all the elements of our model  we perform an
ablation study. It proves that the multi-scale spatial dimension reduction and the use of multi-dataset
classiﬁcation improves substancially classiﬁcation performance  and suggests that the proposed
model captures a new interesting latent structure of brain images. We further illustrate the effect
of transfer learning  by systematically varying the number of subjects in a single dataset: we show
how multi-dataset learning helps mitigating the decrease in accuracy due to smaller train size — a
result of much use for analysing cognitive experiments on small cohorts. Finally  we illustrate the
interpretability of our model and show how the latent “cognitive-space” can be explored to uncover
some template brain maps associated with related conditions in different datasets.

2.1 Datasets and tools

Datasets. Our experimental study features 5 publicly-available task fMRI study. We use all resting-
state records from the HCP900 release [1] to compute the sparse dictionaries that are used in the ﬁrst
dimension reduction materialized by Wg. We succinctly describe the conditions of each dataset —
we refer the reader to the original publications for further details.

• HCP: gambling  working memory  motor  language  social and relational tasks. 800 subjects.
• Archi [31]: localizer protocol  motor  social and relational task. 79 subjects.
• Brainomics [32]: localizer protocol. 98 subjects.
• Camcan [33]: audio-video task  with frequency variation. 606 subjects.
• LA5c consortium [34]: task-switching  balloon analog risk taking  stop-signal and spatial

working memory capacity tasks — high-level tasks. 200 subjects.

The last four datasets are target datasets  on which we measure out-of-sample prediction performance.
The larger HCP dataset serves as a knowledge transfering dataset  which should boost these perfor-
mance when considered in the multi-dataset model. We register the task time-series in the reference
MNI space before ﬁtting a general linear model (GLM) and computing the maps (standardized by
z-scoring) associated with each base condition — no manual design of contrast is involved. More
details on the pipeline used for z-map extraction is provided in Appendix A.1.

Tools. We use pytorch 1 to deﬁne and train the proposed models  nilearn [35] to handle brain datasets 
along with scikit-learn [36] to design the experimental pipelines. Sparse brain decompositions were
computed from the whole HCP900 resting-state data. The code for reproducing experiments is
available at http://github.com/arthurmensch/cogspaces. Our model involves a few non-
critical hyperparameters: we use batches of size 256  set the latent dimension l = 100 and use a
Dropout rate r = 0.75 in the latent cognitive space — this value perform slightly better than r = 0.5.
We use a multi-scale dictionary with 16  64 and 512 components  as it yields the best quantitative
and qualitative results.2. Finally  test accuracy is measured on half of the subjects of each dataset 
that are removed from training sets beforehand. Benchmarks are repeated 20 times with random split
folds to estimate the variance in performance.

2.2 Dimension reduction and transfer improves test accuracy

For the four benchmark studies  the proposed model brings between +1.3% to +13.4% extra test
accuracy compared to a simple multinomial classiﬁcation. To further quantify which aspects of the
model improve performance  we perform an ablation study: we measure the prediction accuracy
of six models  from the simplest to the most complete model described in Section 1. The ﬁrst
three experiments study the effect of initial dimension reduction and regularization3. The last three
experiments measure the performance of the proposed factored model  and the effect of multi-dataset
classiﬁcation.

1http://pytorch.org/
2Note that using only the 512-components dictionary yields comparable predictive accuracy. Quantitatively 
the multi-scale approach is beneﬁcial when using dictionary with less components (e.g.  16  64  128) — see
Appendix A.2 for a quantitative validation of the multi-scale approach.

3For these models  (cid:96)2 and Dropout regularization parameter are estimated by nested cross-validation.

6

Figure 2: Ablation results. Each dimension reduction of the model has a relevant contribution.
Dropout regularization is very effective when applied to the cognitive latent space. Learning this
latent space allows to transfer knowledge between datasets.

Figure 3: Learning curves in the single-dataset and multi-dataset setting. Estimating the latent
cognitive space from multiple datasets is very useful for studying small cohorts.

1. Baseline (cid:96)2-penalized multinomial classiﬁcation  where we predict c from x ∈ Rp directly.
2. Multinomial classiﬁcation after projection on a dictionary  i.e. predicting c from Wgx.
3. Same as experience 2  using Dropout noise on projected data Wgx.
4. Factored model in the single-study case: solving (4) with the target study only.
5. Factored model in a two-study case: using target study alongside HCP.
6. Factored model in the multi-study case: using target study alongside all other studies.

The results are summarized in Figure 2. On average  both dimension reduction introduced by Wg
and W(cid:48)
e are beneﬁcial to generalization performance. Using many datasets for prediction brings a
further increase in performance  providing evidence of transfer learning between datasets.
In detail  the comparison between experiments 1  2 and 3 conﬁrms that projecting brain images onto
functional networks of interest is a good strategy to capture cognitive information [20  25]. Note that
in addition to improving the statistical properties of the estimators  the projection reduces drastically
the computational complexity of training our full model. Experiment 2 and 3 measure the impact of
the regularization method without learning a further latent projection. Using Dropout on the input
space performs consistently better than (cid:96)2 regularization (+1% to +5%); this can be explained in
view of [37]  that interpret input-Dropout as a (cid:96)2 regularization on the natural model parametrization.
Experiment 4 shows that Dropout regularization becomes much more powerful when learning a
second dimension reduction  i.e. when solving problem (4). Even when using a single study for
learning  we observe a signiﬁcant improvement (+3% to +7%) in performance on three out of four
datasets. Learning a latent space projection together with Dropout-based data augmentation in this
space is thus a much better regularization strategy than a simple (cid:96)2 or input-Dropout regularization.
Finally  the comparison between experiments 4  5 and 6 exhibits the expected transfer effect. On
three out of four target studies  learning the projection matrix W(cid:48)
e using several datasets leads to an
accuracy gain from +1.1% to +1.6%  consistent across folds. The more datasets are used  the higher
the accuracy gain — already note that this gain increases with smaller train size. Jointly classifying
images on several datasets thus brings extra information to the cognitive model  which allows to ﬁnd
better representative brain maps for the target study. In particular  we conjecture that the large number
of subjects in HCP helps modeling inter-subject noises. On the other hand  we observe a negative
transfer effect on LA5c  as the tasks of this dataset share little cognitive aspects with the tasks of the
other datasets. This encourages us to use richer dataset repositories for further improvement.

7

77.584.685.490.791.091.9Brainomics50%55%60%65%60.659.961.061.362.062.9CamCan55.855.661.162.661.859.8LA5C75%80%85%90%95%Testaccuracy76.579.181.886.787.487.8ArchiFullinput+L2Dim.reduction+L2Dim.red.+dropoutFactoredmodel+dropoutTransferfromHCPTransferfromalldatasets510203039Trainsize65%70%80%90%TestaccuracyArchiTrainsubjectsNotransferTransferfromHCPTransferfromalldatasets5102030404960%70%80%90%Brainomics206010020030250%60%68%CamcanFigure 4: Classiﬁcation maps from our model are more speciﬁc of higher level functions: they focus
more on the FFA for faces  and on the left intraparietal suci for calculations.

Figure 5: The latent space of our model can be explored to unveil some template brain statistical
maps  that corresponds to bags of conditions related across color-coded datasets.

2.3 Transfer learning is very effective on small datasets

To further demonstrate the beneﬁts of the multi-dataset model  we vary the size of target datasets
(Archi  Brainomics and CamCan) and compare the performance of the single-study model with the
model that aggregates Archi  Brainomics  CamCan and HCP studies. Figure 3 shows that the effect
of transfer learning increases as we reduce the training size of the target dataset. This suggests that
the learned data embedding WgW(cid:48)
e does capture some universal cognitive information  and can be
learned from different data sources. As a consequence  aggregating a larger study to mitigate the
small number of training samples in the target dataset. With only 5 subjects  the gain in accuracy due
to transfer is +13% on Archi  +8% on Brainomics  and +6% on CamCan. Multi-study learning
should thus proves very useful to classify conditions in studies with ten or so subjects  which are still
very common in neuroimaging.

2.4

Introspecting classiﬁcation maps

eW(cid:48)

At prediction time  our multi-dataset model can be collapsed into one multinomial model per dataset.
Each dataset d is then classiﬁed using matrix WgW(cid:48)
d. Similar to the linear models classically
used for decoding  the model weights for each condition can be represented as a brain map. Figure 4
shows the maps associated with digit computation and face viewing  for the Archi dataset. The
models 2  4 and 5 from the ablation study are compared. Although it is hard to assess the intrinsic
quality of the maps  we can see that the introduction of the second projection layer and the multi-
study problem formulation (here  appending the HCP dataset) yields maps with more weight on the
high-level functional regions known to be speciﬁc of the task: for face viewing  the FFA stands out
more compared to primary visual cortices; for calculations  the weights of the intraparietal sulci
becomes left lateralized  as it has been reported for symbolic number processing [38].

2.5 Exploring the latent space

Within our model  classiﬁcation is performed on the same l-dimensional space E for all datasets 
that is learned during training. To further show that this space captures some cognitive information 
we extract from E template brain images associated to general cognitive concepts. Fitting our
model on the Archi  Brainomics  CamCan and HCP studies  we extract representative vectors of E
with a k-means clustering over the projected data and consider the centroids (yj)j of 50 clusters.
Each centroid yj can be associated to a brain image tj ∈ Rp that lies in the span of D1  D2

8

Multi-scalespatialprojectionLRFacez=-10mmLatentcognitivespace(single)Latentcognitive(multi-study)Multi-scalespatialprojectionLRAudiocalculationz=46mmLatentcognitivespace(single)Latentcognitive(multi-study)(cid:62)

W(cid:48)(cid:62)

d yj = W(cid:48)

and D3. In doing so  we go backward through the model and obtain a representative of yj with
well delineated spatial regions. Going forward  we compute the classiﬁcation probability vectors
W(cid:62)
g tj for each study d. Together  these probability vectors give an indication
on the cognitive functions that tj captures. Figure 5 represents six template images  associated
to their probability vectors  shown as word clouds. We clearly obtain interpretable pairs of brain
image/cognitive concepts. These pairs capture across datasets clusters of experiment conditions with
similar brain representations.

e W(cid:62)

d

3 Discussion

We compare our model to a previously proposed formulation for brain image classiﬁcation. We show
how our model differs from convex multi-task learning  and stress the importance of Dropout.

Task fMRI classiﬁcation. Our model is related to a previous semi-supervised classiﬁcation
model [20] that also performs multinomial classiﬁcation of conditions in a low-dimensional space:
the dimension reduction they propose is the equivalent of our projection Wg. Our approach differs
in two aspects. First  we replace the initial semi-supervised dimension reduction with unsupervised
analysis of resting-state  using a much more tractable approach that we have shown to be conservative
of cognitive signals. Second  we introduce the additional cognitive-aware projection W(cid:48)
e  learned
on multiple studies. It substancially improves out-of-sample prediction performance  especially on
small datasets  and above all allow to uncover a cognitive-aware latent space  as we have shown in
our experiments.

e[W(cid:48)

Convex multi-task learning. Due to the Dropout regularization and the fact that l is allowed to be
larger than k  our formulation differs from the classical approach [39] to the multi-task problem  that
d]d ∈ Rg×k by solving a convex empirical risk minimization
would estimate Θ = W(cid:48)
problem with a trace-norm penalization  that encourages Θ to be low-rank. We tested this formulation 
which does not perform better than the explicit factorization formulation with Dropout regularization.
Trace-norm regularized regression has the further drawback of being slower to train  as it typically
operates with full gradients  e.g. using FISTA [40]. In contrast  the non-convex explicit factorization
model is easily amenable to large-scale stochastic optimization — hence our focus.

1  . . .   W(cid:48)

Importance of Dropout. The use of Dropout regularization is crucial in our model. Without
Dropout  in the single-study case with l > k  solving the factored problem (4) yields a solution worse
in term of empirical risk than solving the simple multinomial problem on (W(cid:62)
i  which ﬁnds a
global minimizer of (4). Yet  Figure 2 shows that the model enriched with a latent space (red) has
better performance in test accuracy than the simple model (orange)  thanks to the Dropout noise
applied to the latent-space representation of the input data. Dropout is thus a promising novel way of
regularizing fMRI models.

g xi)

4 Conclusion

We proposed and characterized a novel cognitive neuroimaging modeling scheme that blends latent
factor discovery and transfer learning. It can be applied to many different cognitive studies jointly
without requiring explicit correspondences between the cognitive tasks. The model helps identifying
the fundamental building blocks underlying the diversity of cognitive processes that the human
mind can realize. It produces a basis of cognitive processes whose generalization power is validated
quantitatively  and extracts representations of brain activity that grounds the transfer of knowledge
from existing fMRI repositories to newly acquired task data. The captured cognitive representations
will improve as we provide the model with a growing number of studies and cognitive conditions.

5 Acknowledgments

This project has received funding from the European Union’s Horizon 2020 Framework Programme
for Research and Innovation under grant agreement No 720270 (Human Brain Project SGA1). Julien
Mairal was supported by the ERC grant SOLARIS (No 714381) and a grant from ANR (MACARON
project ANR-14-CE23-0003-01). We thank Olivier Grisel for his most helpful insights.

9

References
[1] David Van Essen  Kamil Ugurbil  and others. The Human Connectome Project: A data acquisition

perspective. NeuroImage  62(4):2222–2231  2012.

[2] Russell A. Poldrack  Chris I. Baker  Joke Durnez  Krzysztof J. Gorgolewski  Paul M. Matthews  Marcus R.
Munafò  Thomas E. Nichols  Jean-Baptiste Poline  Edward Vul  and Tal Yarkoni. Scanning the horizon:
Towards transparent and reproducible neuroimaging research. Nature Reviews Neuroscience  18(2):
115–126  2017.

[3] Allen Newell. You can’t play 20 questions with nature and win: Projective comments on the papers of this

symposium. 1973.

[4] John D. Medaglia  Mary-Ellen Lynall  and Danielle S. Bassett. Cognitive Network Neuroscience. Journal

of Cognitive Neuroscience  27(8):1471–1491  2015.

[5] Lisa Feldman Barrett. The future of psychology: Connecting mind to brain. Perspectives on psychological

science  4(4):326–339  2009.

[6] Tal Yarkoni  Russell A. Poldrack  Thomas E. Nichols  David C. Van Essen  and Tor D. Wager. Large-scale

automated synthesis of human functional neuroimaging data. Nature methods  8(8):665–670  2011.

[7] Angela R. Laird  Jack J. Lancaster  and Peter T. Fox. Brainmap. Neuroinformatics  3(1):65–77  2005.

[8] Gholamreza Salimi-Khorshidi  Stephen M. Smith  John R. Keltner  Tor D. Wager  and Thomas E. Nichols.
Meta-analysis of neuroimaging data: A comparison of image-based and coordinate-based pooling of
studies. NeuroImage  45(3):810–823  2009.

[9] Tor D. Wager  Lauren Y. Atlas  Martin A. Lindquist  Mathieu Roy  Choong-Wan Woo  and Ethan Kross.
An fMRI-Based Neurologic Signature of Physical Pain. New England Journal of Medicine  368(15):
1388–1397  2013.

[10] Yannick Schwartz  Bertrand Thirion  and Gael Varoquaux. Mapping paradigm ontologies to and from the

brain. In Advances in Neural Information Processing Systems  pages 1673–1681. 2013.

[11] Oluwasanmi Koyejo and Russell A. Poldrack. Decoding cognitive processes from functional MRI. In

NIPS Workshop on Machine Learning for Interpretable Neuroimaging  pages 5–10  2013.

[12] Russell A. Poldrack  Yaroslav O. Halchenko  and Stephen José Hanson. Decoding the large-scale structure
of brain function by classifying mental states across individuals. Psychological Science  20(11):1364–1372 
2009.

[13] Jessica A. Turner and Angela R. Laird. The cognitive paradigm ontology: Design and application.

Neuroinformatics  10(1):57–66  2012.

[14] Rie Kubota Ando and Tong Zhang. A framework for learning predictive structures from multiple tasks and

unlabeled data. Journal of Machine Learning Research  6(Nov):1817–1853  2005.

[15] Ya Xue  Xuejun Liao  Lawrence Carin  and Balaji Krishnapuram. Multi-task learning for classiﬁcation

with dirichlet process priors. Journal of Machine Learning Research  8(Jan):35–63  2007.

[16] Yann LeCun  Yoshua Bengio  and Geoffrey Hinton. Deep learning. Nature  521(7553):436–444  2015.

[17] Jeff Donahue  Yangqing Jia  Oriol Vinyals  Judy Hoffman  Ning Zhang  Eric Tzeng  and Trevor Darrell.
DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition. In International
Conference on Machine Learning  volume 32  pages 647–655  2014.

[18] Ronan Collobert and Jason Weston. A uniﬁed architecture for natural language processing: Deep neural
networks with multitask learning. In International Conference on Machine Learning  pages 160–167 
2008.

[19] Danilo Bzdok and B. T. Thomas Yeo. Inference in the age of big data: Future perspectives on neuroscience.

NeuroImage  155(Supplement C):549 – 564  2017.

[20] Danilo Bzdok  Michael Eickenberg  Olivier Grisel  Bertrand Thirion  and Gaël Varoquaux. Semi-supervised
factored logistic regression for high-dimensional neuroimaging data. In Advances in Neural Information
Processing Systems  pages 3348–3356  2015.

10

[21] Timothy Rubin  Oluwasanmi O Koyejo  Michael N Jones  and Tal Yarkoni. Generalized Correspondence-
LDA Models (GC-LDA) for Identifying Functional Regions in the Brain. In Advances in Neural Information
Processing Systems  pages 1118–1126  2016.

[22] Alexandre Gramfort  Bertrand Thirion  and Gaël Varoquaux. Identifying Predictive Regions from fMRI
with TV-L1 Prior. In International Workshop on Pattern Recognition in Neuroimaging  pages 17–20  2013.

[23] Bertrand Thirion  Gaël Varoquaux  Elvis Dohmatob  and Jean-Baptiste Poline. Which fMRI clustering

gives good brain parcellations? Frontiers in neuroscience  8:167  2014.

[24] Nitish Srivastava  Geoffrey E. Hinton  Alex Krizhevsky  Ilya Sutskever  and Ruslan Salakhutdinov. Dropout:
A simple way to prevent neural networks from overﬁtting. Journal of Machine Learning Research  15(1):
1929–1958  2014.

[25] Thomas Blumensath  Saad Jbabdi  Matthew F. Glasser  David C. Van Essen  Kamil Ugurbil  Timothy E.J.
Behrens  and Stephen M. Smith. Spatially constrained hierarchical parcellation of the brain with resting-
state fMRI. NeuroImage  76:313–324  2013.

[26] Arthur Mensch  Julien Mairal  Bertrand Thirion  and Gaël Varoquaux. Dictionary learning for massive

matrix factorization. In International Conference on Machine Learning  pages 1737–1746  2016.

[27] Arthur Mensch  Julien Mairal  Bertrand Thirion  and Gaël Varoquaux. Stochastic Subsampling for

Factorizing Huge Matrices. IEEE Transactions on Signal Processing  99(to appear)  2017.

[28] Simon B. Eickhoff  Bertrand Thirion  Gaël Varoquaux  and Danilo Bzdok. Connectivity-based parcellation:

Critique and implications. Human brain mapping  36(12):4771–4792  2015.

[29] Stéphane G. Mallat and Zhifeng Zhang. Matching pursuits with time-frequency dictionaries.

Transactions on Signal Processing  41(12):3397–3415  1993.

IEEE

[30] Diederik P. Kingma and Jimmy Ba. Adam: A Method for Stochastic Optimization. In International

Conference for Learning Representations  2015.

[31] Philippe Pinel  Bertrand Thirion  Sébastien Meriaux  Antoinette Jobert  Julien Serres  Denis Le Bihan 
Jean-Baptiste Poline  and Stanislas Dehaene. Fast reproducible identiﬁcation and large-scale databasing of
individual functional cognitive networks. BMC Neuroscience  8(1):91  2007.

[32] Dimitri Papadopoulos Orfanos  Vincent Michel  Yannick Schwartz  Philippe Pinel  Antonio Moreno  Denis

Le Bihan  and Vincent Frouin. The Brainomics/Localizer database. NeuroImage  144:309–314  2017.

[33] Meredith A. Shafto  Lorraine K. Tyler  Marie Dixon  Jason R Taylor  James B. Rowe  Rhodri Cusack 
William D. Calder  Andrew J. an d Marslen-Wilson  John Duncan  Tim Dalgleish  Richard N. Henson 
Carol Brayne  and Fiona E. Matthews. The Cambridge Centre for Ageing and Neuroscience (Cam-CAN)
study protocol: A cross-sectional  lifespan  multidisciplinary examination of healthy cognitive ageing.
BMC Neurology  14:204  2014.

[34] RA Poldrack  Eliza Congdon  William Triplett  KJ Gorgolewski  KH Karlsgodt  JA Mumford  FW Sabb 
NB Freimer  ED London  TD Cannon  et al. A phenome-wide examination of neural and cognitive function.
Scientiﬁc Data  3:160110  2016.

[35] Alexandre Abraham  Fabian Pedregosa  Michael Eickenberg  Philippe Gervais  Andreas Mueller  Jean
Kossaiﬁ  Alexandre Gramfort  Bertrand Thirion  and Gael Varoquaux. Machine learning for neuroimaging
with scikit-learn. Frontiers in Neuroinformatics  8:14  2014.

[36] Fabian Pedregosa  Gaël Varoquaux  Alexandre Gramfort  Vincent Michel  Bertrand Thirion  Olivier Grisel 
Mathieu Blondel  Peter Prettenhofer  Ron Weiss  Vincent Dubourg  Jake Vanderplas  Alexandre Passos 
David Cournapeau  Matthieu Brucher  Matthieu Perrot  and Édouard Duchesnay. Scikit-learn: Machine
learning in Python. Journal of Machine Learning Research  12:2825–2830  2011.

[37] Stefan Wager  Sida Wang  and Percy S Liang. Dropout Training as Adaptive Regularization. In Advances

in Neural Information Processing Systems  pages 351–359. 2013.

[38] Stephanie Bugden  Gavin R. Price  D. Adam McLean  and Daniel Ansari. The role of the left intraparietal
sulcus in the relationship between symbolic number processing and children’s arithmetic competence.
Developmental Cognitive Neuroscience  2(4):448–457  2012.

[39] Nathan Srebro  Jason Rennie  and Tommi S. Jaakkola. Maximum-margin matrix factorization. In Advances

in Neural Information Processing Systems  pages 1329–1336  2004.

[40] Amir Beck and Marc Teboulle. A fast iterative shrinkage-thresholding algorithm for linear inverse problems.

SIAM Journal on Imaging Sciences  2(1):183–202  2009.

11

,Arthur Mensch
Julien Mairal
Danilo Bzdok
Bertrand Thirion
Gael Varoquaux
Boyuan Pan
Yazheng Yang
Hao Li
Zhou Zhao
Yueting Zhuang
Deng Cai
Xiaofei He
Andrea Zanette
Alessandro Lazaric
Mykel Kochenderfer
Emma Brunskill