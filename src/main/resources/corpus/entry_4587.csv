2016,Reconstructing Parameters of Spreading Models from Partial Observations,Spreading processes are often modelled as a stochastic dynamics occurring on top of a given network with edge weights corresponding to the transmission probabilities. Knowledge of veracious transmission probabilities is essential for prediction  optimization  and control of diffusion dynamics. Unfortunately  in most cases the transmission rates are unknown and need to be reconstructed from the spreading data. Moreover  in realistic settings it is impossible to monitor the state of each node at every time  and thus the data is highly incomplete. We introduce an efficient dynamic message-passing algorithm  which is able to reconstruct parameters of the spreading model given only partial information on the activation times of nodes in the network. The method is generalizable to a large class of dynamic models  as well to the case of temporal graphs.,Reconstructing Parameters of Spreading Models

from Partial Observations

Center for Nonlinear Studies and Theoretical Division T-4

Los Alamos National Laboratory  Los Alamos  NM 87545  USA

Andrey Y. Lokhov

lokhov@lanl.gov

Abstract

Spreading processes are often modelled as a stochastic dynamics occurring on top
of a given network with edge weights corresponding to the transmission probabili-
ties. Knowledge of veracious transmission probabilities is essential for prediction 
optimization  and control of diffusion dynamics. Unfortunately  in most cases the
transmission rates are unknown and need to be reconstructed from the spreading
data. Moreover  in realistic settings it is impossible to monitor the state of each
node at every time  and thus the data is highly incomplete. We introduce an efﬁcient
dynamic message-passing algorithm  which is able to reconstruct parameters of the
spreading model given only partial information on the activation times of nodes in
the network. The method is generalizable to a large class of dynamic models  as
well to the case of temporal graphs.

1

Introduction

Knowledge of the underlying parameters of the spreading model is crucial for understanding the
global properties of the dynamics and for development of effective control strategies for an opti-
mal dissemination or mitigation of diffusion [1  2]. However  in many realistic settings effective
transmission probabilities are not known a priori and need to be recovered from a limited number of
realizations of the process. Examples of such situations include spreading of a disease [3]  propagation
of information and opinions in a social network [4]  correlated infrastructure failures [5]  or activation
cascades in biological and neural networks [6]: precise model and parameters  as well as propagation
paths are often unknown  and one is left at most with several observed diffusion traces. It can be
argued that for many interesting systems  even the functional form of the dynamic model is uncertain.
Nevertheless  the reconstruction problem still makes sense in this case: the common approach is to
assume some simple and reasonable form of the dynamics  and recover the parameters of the model
which explain the data in the most accurate and minimalistic way; this is crucial for understanding
the basic mechanisms of the spreading process  as well as for making further predictions without
overﬁtting. For example  if only a small number of samples is available  a few-parameter model
should be used.
In practice  it is very costly or even impossible to record the state of each node at every time step of
the dynamics: we might only have access to a subset of nodes  or monitor the state of the system
at particular times. For instance  surveys may give some information on the health or awareness of
certain individuals  but there is no way to get a detailed account for the whole population; neural
avalanches are usually recorded in cortical slices  representing only a small part of the brain; it is
costly to deploy measurement devices on each unit of a complex infrastructure system; ﬁnally  hidden
nodes play an important role in the artiﬁcial learning architectures. This is precisely the setting
that we address in this article: reconstruction of parameters of a propagation model in the presence
of nodes with hidden information  and/or partial information in time. It is not surprising that this

30th Conference on Neural Information Processing Systems (NIPS 2016)  Barcelona  Spain.

challenging problem turns out to be notably harder then its detailed counterpart and requires new
algorithms which would be robust with respect to missing observations.
Related work. The inverse problem of network and couplings reconstruction in the dynamic setting
has attracted a considerable attention in the past several years. However  most of the existing works
are focused on learning the propagation networks under the assumption of availability of full diffusion
information. The papers [7  8  9  10] developed inference methods based on the maximization of
the likelihood of the observed cascades  leading to distributed and convex optimization algorithms
in the case of continuous and discrete dynamics  principally for the variants of the independent
cascade (IC) model [11]. These algorithms have been further improved under the sparse recovery
framework [12  13]  particularly efﬁcient for structure learning of treelike networks. A careful
rigorous analysis of these likelihood-based and alternative [14  15] reconstruction algorithms give
an estimation of the number of observed cascades required for an exact network recovery with high
probability. Precise conditions for the parameters recovery at a given accuracy are still lacking. The
fact that the aforementioned algorithms rely on the fully observed spreading history represents an
important limitation in the case of incomplete information. The case of missing time information has
been addressed in two recent papers: focusing primarily on tree graphs  [16] studied the structure
learning problem in which only initial and ﬁnal spreading states are observed; [17] addressed the
network reconstruction problem in the case of partial time snapshots of the network  using relaxation
optimization techniques and assuming that full probabilistic trace for each node in the network is
available. A standard technique for dealing with incomplete data involves maximizing the likelihood
marginalized over the hidden information; for example  this approach has been used in [18] for
identifying the diffusion source. In what follows  we use this method for benchmarking our results.
Overview of results. In this article  we propose a different algorithm  based on recently introduced
dynamic message-passing (DMP) equations for cascading processes [19  20]  which will be referred
to as DMPREC (DMP-reconstruction) throughout the text. Making use of all available information 
it yields signiﬁcantly more accurate reconstruction results  outperforming the likelihood method
and having a substantially lower algorithmic complexity  independent on the number of nodes with
unobserved information. More generally  the DMPREC framework can be easily adapted to allow
reconstruction of heterogeneous transmission probabilities in a large class of cascading processes 
including the IC and threshold models  SIR and other epidemiological models  rumor spreading
dynamics  etc.  as well as for the processes occurring on dynamically-changing networks.

2 Problem formulation

Model. For the sake of simplicity and deﬁniteness  we assume that cascades follow the dynamics of
stochastic susceptible-infected (SI) model in discrete time  deﬁned on a network G = (V  E) with set
of nodes denoted by V and set of directed edges E [3]. Each node i ∈ V at times t = 1  2  . . .   T
can be in either of two states: susceptible (S) or infected (I). At each time step  node i in the I state
1 . The dynamics is non-recurrent:
can activate one of its susceptible neighbors j with probability αij
once the node is activated (infected)  it can never change its state back to susceptible. In what follows 
the network G is supposed to be known.
Incomplete observations and inference problem. We assume that the input is formed from M
independent cascades  where a cascade Σc is deﬁned as a collection of activation times of nodes in
the network {τ c
i }i∈V . Each cascade is observed up to the ﬁnal observation time T . Notice that T is
an important parameter: intuitively  the larger is T   the more information is contained in cascades 
and the less samples are needed. We assume that T is given and ﬁxed  being related to the availability
of the ﬁnite-time observation window. If node i in cascade c does not get activated at a certain time
prior to the horizon T   we put by deﬁnition τ c
i = T means that node i changes its
state at time T or later. The full information on the cascades Σ = ∪cΣc is divided into the observed
part  ΣO  and the hidden part ΣH. Thus  in general ΣO contains only a subset of activation times
in T ∈ [0  T ] for a part of observed nodes in the network O ∈ V . The task is to reconstruct the

i = T ; hence  τ c

1We chose this two-state model since it has slightly more general dynamic rules compared to the popular IC
model [11] with an additional restriction: a node infected at time t has a single chance to activate its susceptible
neighbors at time step t+1  while further infection attempts in subsequent rounds are not allowed. The DMPREC
method presented below can be easily applied to the case of IC model by noticing that it corresponds to the SIR
model with a recovery probability equal to one  for which the DMP equations are known [20].

2

ij}(ij)∈E ≡ Gα∗  where Gα∗ with a star denotes the original transmission probabilities

couplings {α∗
that have been used to generate the data.
Maximization of the likelihood. Similarly to the formulations considered in [7  8  10]  it is possible
to explicitly write the expression for the likelihood of the discrete-time SI model in the case of fully
available information ΣO = Σ under the assumption that the data has been generated using the
couplings Gα:

with
Pi(τ c

i | Σc  Gα) =

τ c
i −2(cid:89)

(cid:89)

t(cid:48)=0

k∈∂i

P (Σ | Gα) =

Pi(τ c

i | Σc  Gα) 

i∈V

1≤c≤M

(cid:89)

(cid:89)
(cid:34)

(cid:32)(cid:89)

k∈∂i

(1 − αki1τ c

k≤t(cid:48))

1 −

(1 − αki1τ c

k≤τ c

i −1)

(cid:33)

(1)

(cid:35)

1τ c

i <T

  (2)

where ∂i denotes the set of neighbors of node i in the graph G  and 1 is the indicator function. The
expression (2) has the following meaning: the probability that node i has been activated at time τi
given the activation times of its neighbors is equal to the probability that the activation signal has
not been transmitted by any infected neighbor of i until the time τi − 2 (ﬁrst term in the product) 
and that at least one of the active neighbors actually transmitted the infection at time τi − 1 (second
term). A straightforward adaptation of the NETRATE algorithm  suggested in [8]  to the present

setting implies that the estimation of the transmission probabilities (cid:98)Gα∗ is obtained as a solution of
the convex optimization problem(cid:98)Gα∗ = arg min (− ln P (Σ | Gα))  

(3)
which can be solved locally for each node i and its neighborhood due to the factorization of the
likelihood (1) under assumption of asymmetry of the couplings. In the case of partial observations 
the optimization problem (3) is not well deﬁned since it requires the full knowledge of activation
times for each node. A simple and natural extension of this scheme  which we will refer to as the
maximum likelihood estimator (MLE)  is to consider the likelihood function marginalized over
unknown activation times:

P (ΣO | Gα) =

P (Σ | Gα).

(4)

(cid:88)

{τ c

h} h∈H

An exact evaluation of (4) is a computationally hard high-dimensional integration problem with
complexity proportional to T H in the presence of H nodes with hidden information. In order to
correct for this fact  we propose a heuristic scheme which we denote as the heuristic two-stage
h}h∈H of the cascades
(HTS) algorithm. The idea of HTS consists of completing the missing part {τ c
estimation of the couplings (cid:98)Gα (cid:98)ΣH = arg max P (Σ | (cid:98)Gα)  and solving the optimization problem
at each step of the optimization process with the most probable values according to the current
(3) using the full information on the cascades Σ = ΣO ∪(cid:98)ΣH; these two alternating steps are iterated
until the global convergence of the algorithm. An exact (brute-force) estimation of(cid:98)ΣH requires an

exponential number of operations T H  as the original MLE formulation. However  we found that
in practice the computational time can be signiﬁcantly reduced with the use of the Monte Carlo
sampling. The corresponding approximation is based on the observation that the likelihood (1) is
i }i∈V forming possible (realizable) cascades. Hence  for each c  we sample
non-zero only for {τ c
LH T auxiliary cascades  and choose the set of {τ c
h}h∈H maximizing (1). LH T is typically a large
sampling parameter  growing with T and H to ensure a proper convergence. This procedure leads
to an algorithm with a complexity O(N M|E|2LH T ) at each step of the optimization  where |E|
denotes the number of edges; see the journal version of the paper [21] for a more in-depth discussion.
Hence  both MLE and HTS algorithms are practically intractable; the remaining part of the paper
is devoted to the development of an accurate algorithm with a polynomial-time computational
complexity for this hard problem. The next section introduces dynamic message-passing equations
which serve as a basis for such algorithm.

3 Dynamic message-passing equations.

The dynamic message-passing equations for the SI model in continuous [19] and discrete [20] settings
allow to compute marginal probabilities that node i is in the state S at time t:

(5)

(cid:89)

k∈∂i

θk→i(t)

P i
S(t) = P i

S(0)

3

S(0). The variables θk→i(t) represent the probability that
for t > 0 and a given initial condition P i
node k did not pass the activation signal to the node i until time t. The intuition behind the key
Equation (5) is that the probability of node i to be susceptible at time t is equal to the probability of
being in the S state at initial time times the probability that neither of its neighbors infected it until
time t. The quantities θk→i(t) can be computed iteratively using the following expressions:

θk→i(t) = θk→i(t − 1) − αkiφk→i(t − 1) 

φk→i(t) = (1 − αki)φk→i(t − 1) + P k

S (0)

 (cid:89)

l∈∂k\i

θl→k(t − 1) − (cid:89)

θl→k(t)

l∈∂k\i

  

(6)

(7)

where ∂k\i denotes the set of neighbors of k excluding i. The Equation (6) translates the fact that
θk→i(t) can only decrease if the infection is actually transmitted along the directed link (ki) ∈ E;
this happens with probability αki times φk→i(t − 1) which denotes the probability that node k is in
the state I at time t  but has not transmitted the infection to node i until time t − 1. The Equation
(7)  which allows to close the system of dynamic equations  describes the evolution of probability
φk→i(t): at time t− 1  it decreases if the infection is transmitted (ﬁrst term in the sum)  and increases
if node k goes from the state S to the state I (difference of terms 2 and 3). Note that node i is
excluded from the corresponding products over θ-variables because this equation is conditioned on
the fact that i is in the state S  and therefore can not infect k. The Equations (6) and (7) are iterated
in time starting from initial conditions θi→j(0) = 1 and φi→j(0) = 1 − P i
S(0) which are consistent
with the deﬁnitions above. The name “DMP equations” comes from the fact the whole scheme can
be interpreted as the procedure of passing “messages” along the edges of the network.
Theorem 1. DMP equations for the SI model  deﬁned by Equations (5)-(7)  yield exact marginal
probabilities on tree networks. On general networks  the quantities P i
S(t) give lower bound on values
of marginal probabilities.

Proof Sketch. The exactness of solution on tree graphs immediately follows from the fact that the
DMP equations can be derived from belief propagation equations on time trajectories [20]  which
provide exact marginals on trees. The fact that P i
S(t) computed according to (5) represent a lower
bound on marginal probabilities in general networks can be derived from a counting argument 
considering multiple infection paths on a loopy graph which contribute to the computation of P i
S(t) 
effectively lowering its value through the Equation (5); the proof technique is borrowed from [19] 
(cid:3)
where similar dynamic equations in the continuous-time case have been considered.
Using the deﬁnition (5) of P i
S(t)  it is convenient to deﬁne the marginal probability mi(t) of activation
of node i at time t:

(cid:35)

mi(t) = P i

S(0)

θk→i(t)

.

(8)

(cid:34)(cid:89)

k∈∂i

θk→i(t − 1) − (cid:89)

k∈∂i

As it often happens with message-passing algorithms  although being exact only on tree networks 
DMP equations provide accurate results even on loopy networks. An example is provided in the
Figure 1  where the DMP-predicted marginals are compared with the values obtained from extensive
simulations of the dynamics on a network of retweets with N = 96 nodes [22]. This observation will
allow us to use DMP equations as a suitable approximation tool on general networks. In the next
section we describe an efﬁcient reconstruction algorithm  DMPREC  which is based on the resolution
of the dynamics given by DMP equations and makes use of all available information.

4 Proposed algorithm: DMPREC

Probability of cascades and free energy. The marginalization over hidden nodes in (4) creates a
complex relation between couplings in the whole graph  resulting in a non-explicit expression. The
main idea behind the DMPREC algorithm is to approximate the likelihood of observed cascades (4)
through the marginal probability distributions (5) and (8):
i | Gα)1τ c

P (ΣO | Gα) ≈ M(cid:89)

(cid:2)mi(τ c

i | Gα)1τ c

(cid:89)

i ≤T + P i

S(τ c

(cid:3) .

(9)

i =T

c=1

i∈O

The expression (9) is at the core of the suggested algorithm. As there is no tractable way to compute
exactly the joint probability of partial observations  we approximate it using a mean-ﬁeld-type

4

Figure 1: Illustration of the accuracy of DMP equations on a network of retweets with N = 96 nodes [22].
(a) Comparison of DMP-predicted P i
S(t) estimated from 106 runs of Monte Carlo simulations with
t = 10 and one infected node at initial time. The couplings {αij} have been generated uniformly at random in
the range [0  1]. (b) Visualization of the network topology created with the Gephi software.

S(t) with P i

approach as a product of marginal probabilities provided by the dynamic message-passing equations.
The reasoning behind this approach is that each marginal is expressed through an average of all
possible realizations of dynamics with a given initial condition; this is in contrast with the likelihood
function which considers only particular instance realized in the given cascade. Therefore  equation
(9) summarizes the effect of different propagation paths  and the maximization of this probability
function will yield the most likely consensus between the ensemble of couplings in the network.
Precisely this key property makes the reconstruction possible in the case involving nodes with
hidden information via maximization of the objective (9) which can be interpreted as a cost function
representing the product of individual probabilities of activation taken precisely at the value of the
observed infection times. Starting from this expression  one can deﬁne the associated “free energy”:

fDMP = − ln P (ΣO | Gα) =

DMP = −(cid:80)

c ln(cid:2)mi(τ c

(cid:88)
(cid:3). In the last expression for f i

f i
DMP 

i∈O

(10)

S(T − 1)1τ c

i ≤T−1 + P i

i )1τ c
S(T ) = P i

DMP we
where f i
S(T − 1). Our goal is to minimize the free energy (10)
used the fact that mi(T ) + P i
with respect to {αij}(ij)∈E. A similar approach has been previously outlined by [23] as a way to
learn homogeneous couplings in the spreading source inference algorithm. In order to carry out this
optimization task  we need to develop an efﬁcient way of gradient evaluation.
Computation of the gradient. The gradient of the free energy reads (note that the indicator functions
point to disjoint events):

i =T

i | Gα)/∂αrs

mi(τ c

i | Gα)

1τ c

i ≤T−1 +

∂P i

S(T − 1 | Gα)/∂αrs
S(T − 1 | Gα)
P i

1τ c

i =T

(11)

(cid:104) ∂mi(τ c

= −(cid:88)

c

∂f i
DMP
∂αrs

(cid:105)

 

rs

where the derivatives of the marginal probabilities can be computed explicitly by taking the derivative
of the DMP equations (5)-(8). Let us denote ∂θk→i(t)/∂αrs ≡ pk→i
(t) and ∂φk→i(t)/∂αrs ≡
(t). Since the dynamic messages at initial time {θi→j(0)} and {φi→j(0)} are independent
qk→i
on the couplings  we have pk→i
(0) = 0 for all k  i  r  s  and these quantities can be
computed iteratively using the analogues of the Equations (6) and (7):
(t − 1) − φk→i(t − 1)1k=r i=s 

(t − 1) − αkiqk→i

(0) = qk→i

(12)

rs

rs

rs

rs

rs

pk→i
qk→i
rs
+ P k

(t) = pk→i
(t) = (1 − αki)qk→i
S (0)

(cid:88)

rs

rs

(cid:89)

(t − 1) − φk→i(t − 1)1k=r i=s
θn→k(t − 1) − P k
S (0)

l∈∂k\i

n∈∂k\{i l}

(cid:88)

l∈k\i

pl→k
rs (t)

θn→k(t).

(13)

n∈∂k\{i l}

(cid:89)

Using these quantities  the derivatives of the marginals entering in Equation (11) can be written as

rs (t − 1)
pl→k
(cid:88)

pk→i

rs

k∈∂i

(cid:89)

(t)

l∈∂i\k

∂P i
S(t)
∂αrs

= P i

S(0)

θl→i(t) 

∂mi(t)
∂αrs

=

∂P i

S(t − 1)
∂αrs

− ∂P i
S(t)
∂αrs

.

(14)

5

00.20.40.60.8100.20.40.60.81MC-predictedPiS(t)DMP-predictedPiS(t)(a)(b)The following observation shows that at least on tree networks  corresponding to the regime in
which DMP equations have been derived  the values of the original transmission probabilities Gα∗
correspond to the point in which the gradient of the free energy takes zero value.
Claim 1. On a tree network  in the limit of large number of samples M → ∞  the derivative of the
free energy is equal to zero at the values of couplings Gα∗ used for generating cascades.

Proof. Let us ﬁrst look at samples originating from the same initial condition. According to Theorem
1  the DMP equations are exact on tree graphs  and hence it is easy to see that
S(T − 1 | Gα∗ ) ln P i
M→∞f i
lim

DMP = − (cid:88)

mi(t | Gα∗ ) ln mi(t | Gα) − P i

(15)

t≤T−1

S(T − 1 | Gα).
(cid:35)

Therefore 

lim
M→∞

∂f i
DMP
∂αrs

|Gα∗ = − ∂
∂αrs

(cid:34) (cid:88)

t≤T−1

mi(t | Gα∗ ) + P i

S(T − 1 | Gα∗ )

= 0 

since the expression inside the brackets sums exactly to one. This result trivially holds by summing up
samples with different initial conditions. Combination of this result with the deﬁnition (10) completes
the proof.

The DMPREC algorithm consists of running the message-passing equations for the derivatives of the
dynamic variables (12)  (13) in parallel with DMP equations (5)-(7)  allowing for the computation
of the gradient of the free energy (11) through (14)  which is used afterwards in the optimization
procedure. Let us analyse the computational complexity of each step of parameters update. The
number of runs is equal to the number of distinct initial conditions in the ensemble of observed
cascades  so if all M cascades start with distinct initial conditions  the complexity of the DMPREC
algorithm is equal to O(|E|2T M ) for each step of the update of {αrs}(rs)∈E. Hence  in a typical
situation where each cascade is initiated at one particular node  the number of runs will be limited by
N  and the overall update-step complexity of DMPREC will be O(|E|2T N ).
Missing information in time. On top of inaccessible nodes  the state of the network can be monitored
at a lower frequency compared to the natural time scale of the dynamics. It is easy to adapt the
algorithm to the case of observations at K time steps T ≡ {tk}k∈[1 K]. Since the activation time
i +1] ≡ δkc
i of node i in cascade c is now known only up to the interval [tkc
  where
τ c
S(t | Gα)
i ≤ tkc
i ) − P i
tkc
P i
i < τ c
i ) in this case. This leads to obvious modiﬁcations to the expressions (10) and (11) 
instead of mi(τ c
(cid:35)
using the differences of derivatives at corresponding times instead of one-step differences as in (14).
For instance  if the ﬁnal time is not included in the observations  we have

i +1  one should maximize(cid:80)
DMP = −(cid:88)

S(t | Gα)(cid:3)  

= −(cid:88)

ln(cid:2)∆kc

i + 1  tkc
S(tkc

i +1) ≡ ∆kc

mi(t) = P i

S(tkc

t∈δkc

i

∂∆kc

i

i

(cid:34)

f i

S(t | Gα)/∂αrs
P i
S(t | Gα)
P i
∆kc

i

i

.

P i

i

∂f i
DMP
∂αrs

c

c

5 Numerical results

We evaluate the performance of the DMPREC algorithm on synthetic and real-world networks under
assumption of partial observations. In numerical experiments  we focus primarily on the presence of
inaccessible nodes  which is a more computationally difﬁcult case compared to the setting of missing
information in time. An example involving partial time observations is shown in section 5.1.

5.1 Tests with synthetic data
Experimental setup. In the tests described in this section  the couplings {αij} are sampled uniformly
in the range [0  1]  the ﬁnal observation time is set to T = 10. Each cascade is generated using a
discrete-time SI model deﬁned in section 2 from randomly selected sources. In the case of inaccessible
nodes  the activation times data is hidden in all the samples for H randomly selected nodes. We use the
likelihood methods for benchmarking the accuracy of our approach. The MLE algorithm introduced
above is not tractable even on small graphs  therefore we compare the results of DMPREC with

6

the HTS algorithm outlined in the section 2. Still  HTS has a very high computational complexity 
and therefore we are bound to run comparative tests on small graphs: a connected component of an
artiﬁcially-generated network with N = 20  sampled using a power-law degree distribution  and a
real directed network of relationships in a New England monastery with N = 18 nodes [24]. Both
algorithms are initialized with αij = 0.5 for all (ij) ∈ E. The accuracy of reconstruction is assessed
using the (cid:96)1 norm of the difference between reconstructed and original couplings  normalized over
the number of directed edges in the graph2 . Intuitively  this measure gives an average expected error
for each parameter αij.

Figure 2: Tests for DMPREC and HTS on a small power-law network: (a) for ﬁxed number of nodes with
unobserved information H = 5  (b) for ﬁxed number of samples M = 6400. (c) Scatter plot of {αij} obtained
with DMPREC versus original parameters {α∗
ij} in the case of missing information in time with M = 6400 
T = 10; the state of the network is observed every other time step.

Figure 3: Numerical results for the real-world Monastery network of [24]: (a) for ﬁxed number of nodes with
unobserved information H = 4  (b) for ﬁxed number of samples M = 6400. (c) The topology of the network
(thickness of edges proportional to {α∗

ij} used for generating cascades).

Results. In the Figure 2 we present results for a small power-law network with short loops  which
is not a favorable situation for DMP equations derived in the treelike approximation of the graph.
Figures 2 (a) and 2 (b) show the dependence of an average reconstruction error as a function of M
(for ﬁxed H/N = 0.25) and H (for ﬁxed M = 6400)  respectively. DMPREC clearly outperforms
the HTS algorithm  yielding surprisingly accurate reconstruction of transmission probabilities even
in the case where a half of network nodes do not report any information. Most importantly  DMPREC
achieves reconstruction with a signiﬁcantly lower computational time: for example  while it took
more than 24 hours to compute the point corresponding to H = 4 and M = 6400 with HTS (MLE
at this test point took several weeks to converge)  the computation involving DMPREC converged to
the presented level of accuracy in less than 10 minutes on a standard laptop. These times illustrate
the hardness of the learning problem involving incomplete information.
We have also used this case study network to test the estimation of transmission probabilities with the
DMPREC algorithm when the state of the network is recorded only at a subset of times T ∈ [0  T ].
Results for the case where every other time stamp is missing are given in the Figure 2 (c): couplings
estimated with DMPREC are compared to the original values {α∗
ij}; despite the fact that only 50% of
time stamps are available  the inferred couplings show an excellent agreement with the ground truth.
Equivalent results for the real-world relationship network extracted from the study [24] and containing
both directed and undirected links  are shown in the Figure 3; an ability of DMPREC to capture the
mutual dependencies of different couplings through dynamic correlations is even more pronounced in
this case  with almost perfect reconstruction of couplings for large M and a rather weak dependence

2Note that this measure excludes those few parameters which are impossible to reconstruct: e.g. no algorithm

can learn the coupling associated with the ingoing edge of the hidden node located at the leaf of a network.

7

 0.2 0.4 0.6 0.8 1 0.2 0.4 0.6 0.8 1α*ijαij(c) 0 0.05 0.1025710H(c)(b) 0 0.05 0.1 0.15102103104105106〈αij - α*ij〉 M(×0.64)(c)(b)(a)HTSDMPrec(c) 0 0.05 0.1 0 2 4 6 8H(c)(b) 0 0.05 0.1 0.15102103104105106〈αij - α*ij〉 M(×0.64)(c)(b)(a)HTSDMPrecon the number of nodes with removed observations. We have run tests on larger synthetic networks
which show similar reconstruction results for DMPREC  but where comparisons with the likelihood
method could not be carried out. In the next section we focus on an application involving real-world
data which represents a more interesting and important case for the validation of the algorithm.

5.2 Test with a real-world data

As a proxy for the real statistics  we used the data provided by the Bureau of Transportation Statistics
[25]  from which we reconstructed a part of the U.S. air transportation network  where airports are
the nodes  and directed links correspond to trafﬁc between them. The reason behind this choice is
based on the fact that the majority of large-scale inﬂuenza pandemics over the past several decades
represented the air-trafﬁc mediated epidemics. For illustration purposes  we selected top N = 30
airports ranked according to the total number of passenger enplanements and commonly classiﬁed as
large hubs  and extracted a sub-network of ﬂights between them. The weight of each edge is deﬁned
by the annual number of transported passengers  aggregated over multiple routes; we have pruned
links with a relatively low trafﬁc – below 10% of the trafﬁc level on the busiest routes  so that the
total number of remaining directed links is |E| = 210. The ﬁnal weights are based on the assumption
that the probability of infection transmission is proportional to the ﬂux; the weights have been
renormalized accordingly so that the busiest route received the coupling αij = 0.5. The resulting
network is depicted in the Figure 4 . We have generated M = 10  000 independent cascades in this
network  and have hidden the information at H = 15 nodes (50% of airports) selected at random.
We observe that even with a signiﬁcantly large portion of missing information  the reconstructed
parameters show a good agreement with the original ones.

Figure 4: Left: Sub-network of ﬂights between major U.S. hubs  where the thickness of edges is proportional to
the aggregated trafﬁc between them; nodes which do not report information are indicated in red. Right: Scatter
plots of reconstructed {αij} versus original {α∗

ij} couplings for H = 0 and H = 15 and M = 10  000.

6 Conclusions and path forward

From the algorithmic point of view  inference of spreading parameters in the presence of nodes with
incomplete information considerably complicates the problem because the reconstruction can no
longer be performed independently for each neighborhood. In this paper  it is shown how the dynamic
interdependence of parameters can be exploited in order to be able to recover the couplings in the
setting involving hidden information. Let us discuss several directions for future work. DMPREC
can be straightforwardly generalized to more complicated spreading models using a generic form
of DMP equations [20] and the key approximation ingredient (9)  as well as adapted to the case
of temporal graphs by encoding network dynamics via time-dependent coefﬁcients αij(t)  which
might be more appropriate in certain real situations. It would also be useful to extend the present
framework to the case of continuous dynamics using the continuous-time version of DMP equations
of [19]. An important direction would be to generalize the learning problem beyond the assumption
of a known network  and formulate precise conditions for detection of hidden nodes and for a perfect
network recovery in this case. Finally  in the spirit of active learning  we anticipate that DMPREC
could be helpful for the problems involving an optimal placement of observes in the situations where
collection of full measurements is costly.
Acknowledgements. The author is grateful to M. Chertkov and T. Misiakiewicz for discussions and comments 
and acknowledges support from the LDRD Program at Los Alamos National Laboratory by the National Nuclear
Security Administration of the U.S. Department of Energy under Contract No. DE-AC52-06NA25396.

8

llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll 0.1 0.2 0.3 0.4 0.5 0.1 0.2 0.3 0.4 0.5α*ijαijH=0〈αij - α*ij〉=0.0400 0.1 0.2 0.3 0.4 0.5 0.1 0.2 0.3 0.4 0.5α*ijαijH=15〈αij - α*ij〉=0.0473References
[1] C. Nowzari  V. Preciado  and G. Pappas. Analysis and control of epidemics: A survey of spreading

processes on complex networks. Control Systems  IEEE  36(1):26–46  2016.

[2] A. Y. Lokhov and D. Saad. Optimal deployment of resources for maximizing impact in spreading processes.

arXiv preprint arXiv:1608.08278  2016.

[3] R. Pastor-Satorras  C. Castellano  P. Van Mieghem  and A. Vespignani. Epidemic processes in complex

networks. Rev. Mod. Phys.  87:925–979  2015.

[4] S. Boccaletti  V. Latora  Y. Moreno  M. Chavez  and D.-U. Hwang. Complex networks: Structure and

dynamics. Physics reports  424(4):175–308  2006.

[5] I. Dobson  B. A. Carreras  V. E. Lynch  and D. E. Newman. Complex systems analysis of series of

blackouts: Cascading failure  critical points  and self-organization. Chaos  17(2):026103  2007.

[6] R. O’Dea  J. J. Crofts  and M. Kaiser. Spreading dynamics on spatially constrained complex brain networks.

J. R. Soc. Interface  10(81):20130016  2013.

[7] S. Myers and J. Leskovec. On the convexity of latent social network inference. In Advances in Neural

Information Processing Systems  pages 1741–1749  2010.

[8] M. Gomez-Rodriguez  D. Balduzzi  and B. Schölkopf. Uncovering the temporal dynamics of diffusion
networks. In Proceedings of the 28th International Conference on Machine Learning (ICML-11)  ICML
’11  pages 561–568  New York  NY  USA  June 2011. ACM.

[9] N. Du  L. Song  M. Yuan  and A. J. Smola. Learning networks of heterogeneous inﬂuence. In Advances in

Neural Information Processing Systems  pages 2780–2788  2012.

[10] P. Netrapalli and S. Sanghavi. Learning the graph of epidemic cascades. In ACM SIGMETRICS Performance

Evaluation Review  volume 40  pages 211–222. ACM  2012.

[11] D. Kempe  J. Kleinberg  and É. Tardos. Maximizing the spread of inﬂuence through a social network.
In Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data
mining  pages 137–146. ACM  2003.

[12] H. Daneshmand  M. Gomez-Rodriguez  L. Song  and B. Schölkopf. Estimating diffusion network structures:
In Proceedings of the 31st

Recovery conditions  sample complexity & soft-thresholding algorithm.
International Conference on Machine Learning (ICML-14)  volume 2014  page 793  2014.

[13] J. Pouget-Abadie and T. Horel.

Inferring graphs from cascades: A sparse recovery framework.

Proceedings of The 32nd International Conference on Machine Learning  pages 977–986  2015.

In

[14] B. Abrahao  F. Chierichetti  R. Kleinberg  and A. Panconesi. Trace complexity of network inference. In
Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining 
pages 491–499. ACM  2013.

[15] V. Gripon and M. Rabbat. Reconstructing a graph from path traces. In Information Theory Proceedings

(ISIT)  2013 IEEE International Symposium on  pages 2488–2492. IEEE  2013.

[16] K. Amin  H. Heidari  and M. Kearns. Learning from contagion (without timestamps). In Proceedings of

the 31st International Conference on Machine Learning  pages 1845–1853  2014.

[17] E. Sefer and C. Kingsford. Convex risk minimization to infer networks from probabilistic diffusion data at

multiple scales. In Data Engineering (ICDE)  2015 IEEE 31th International Conference on  2015.

[18] M. Farajtabar  M. Gomez-Rodriguez  N. Du  M. Zamani  H. Zha  and L. Song. Back to the past: Source
identiﬁcation in diffusion networks from partially observed cascades. In Proceedings of the Eighteenth
International Conference on Artiﬁcial Intelligence and Statistics (AISTATS)  pages 232–240  2015.

[19] B. Karrer and M. E. Newman. Message passing approach for general epidemic models. Physical Review E 

82(1):016101  2010.

[20] A. Y. Lokhov  M. Mézard  and L. Zdeborová. Dynamic message-passing equations for models with

unidirectional dynamics. Physical Review E  91(1):012811  2015.

[21] A. Y. Lokhov and T. Misiakiewicz. Efﬁcient reconstruction of transmission probabilities in a spreading

process from partial observations. arXiv preprint arXiv:1509.06893  2016.

[22] R. Rossi and N. Ahmed. Network repository  2013. http://networkrepository.com.
[23] F. Altarelli  A. Braunstein  L. Dall’Asta  A. Lage-Castellanos  and R. Zecchina. Bayesian inference of

epidemics on networks via belief propagation. Physical review letters  112(11):118701  2014.

[24] S. F. Sampson. Crisis in a cloister. PhD thesis  Cornell University  Ithaca  1969.
[25] Bureau of transportation statistics. http://www.rita.dot.gov/bts/.

9

,Murat Erdogdu
Andrea Montanari
Andrey Lokhov