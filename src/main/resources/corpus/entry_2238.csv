2018,Generalisation in humans and deep neural networks,We compare the robustness of humans and current convolutional deep neural networks (DNNs) on object recognition under twelve different types of image degradations. First  using three well known DNNs (ResNet-152  VGG-19  GoogLeNet) we find the human visual system to be more robust to nearly all of the tested image manipulations  and we observe progressively diverging classification error-patterns between humans and DNNs when the signal gets weaker. Secondly  we show that DNNs trained directly on distorted images consistently surpass human performance on the exact distortion types they were trained on  yet they display extremely poor generalisation abilities when tested on other distortion types. For example  training on salt-and-pepper noise does not imply robustness on uniform white noise and vice versa. Thus  changes in the noise distribution between training and testing constitutes a crucial challenge to deep learning vision systems that can be systematically addressed in a lifelong machine learning approach. Our new dataset consisting of 83K carefully measured human psychophysical trials provide a useful reference for lifelong robustness against image degradations set by the human visual system.,Generalisation in humans and deep neural networks

Robert Geirhos1-3∗§

Carlos R. Medina Temme1∗

Jonas Rauber2 3∗

Heiko H. Schütt1 4 5

Matthias Bethge2 6 7∗

Felix A. Wichmann1 2 6 8∗

1Neural Information Processing Group  University of Tübingen
2Centre for Integrative Neuroscience  University of Tübingen

3International Max Planck Research School for Intelligent Systems

4Graduate School of Neural and Behavioural Sciences  University of Tübingen

5Department of Psychology  University of Potsdam

6Bernstein Center for Computational Neuroscience Tübingen

7Max Planck Institute for Biological Cybernetics

8Max Planck Institute for Intelligent Systems

∗Joint ﬁrst / joint senior authors

§To whom correspondence should be addressed: robert.geirhos@bethgelab.org

Abstract

We compare the robustness of humans and current convolutional deep neural net-
works (DNNs) on object recognition under twelve different types of image degra-
dations. First  using three well known DNNs (ResNet-152  VGG-19  GoogLeNet)
we ﬁnd the human visual system to be more robust to nearly all of the tested image
manipulations  and we observe progressively diverging classiﬁcation error-patterns
between humans and DNNs when the signal gets weaker. Secondly  we show that
DNNs trained directly on distorted images consistently surpass human performance
on the exact distortion types they were trained on  yet they display extremely poor
generalisation abilities when tested on other distortion types. For example  training
on salt-and-pepper noise does not imply robustness on uniform white noise and
vice versa. Thus  changes in the noise distribution between training and testing
constitutes a crucial challenge to deep learning vision systems that can be sys-
tematically addressed in a lifelong machine learning approach. Our new dataset
consisting of 83K carefully measured human psychophysical trials provide a useful
reference for lifelong robustness against image degradations set by the human
visual system.

1

Introduction

1.1 Deep neural networks as models of human object recognition

The visual recognition of objects by humans in everyday life is rapid and seemingly effortless  as
well as largely independent of viewpoint and object orientation [1]. The rapid and primarily foveal
recognition during a single ﬁxation has been termed core object recognition (see [2] for a review).
We know  for example  that it is possible to reliably identify objects in the central visual ﬁeld within a
single ﬁxation in less than 200 ms when viewing “standard” images [2–4]. Based on the rapidness of
object recognition  core object recognition is often thought to be achieved with mainly feedforward
processing although feedback connections are ubiquitous in the primate brain. Object recognition

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

Train

Test

Train

Test

Train

Test

(a) Super-human performance

(b) Super-human performance

(c) Chance level performance

Figure 1: Classiﬁcation performance of ResNet-50 trained from scratch on (potentially distorted)
ImageNet images. (a) Classiﬁcation performance when trained on standard colour images and tested
on colour images is close to perfect (better than human observers). (b) Likewise  when trained and
tested on images with additive uniform noise  performance is super-human. (c) Striking generalisation
failure: When trained on images with salt-and-pepper noise and tested on images with uniform noise 
performance is at chance level—even though both noise types do not seem much different to human
observers.

in the primate brain is believed to be realised by the ventral visual pathway  a hierarchical structure
consisting of areas V1-V2-V4-IT  with information from the retina reaching the cortex in V1 (e.g.
[5]).
Until a few years ago  animate visual systems were the only ones known to be capable of broad-
ranging visual object recognition. This has changed  however  with the advent of brain-inspired deep
neural networks (DNNs) which  after having been trained on millions of labeled images  achieve
human-level performance when classifying objects in images of natural scenes [6]. DNNs are now
employed on a variety of tasks and set the new state-of-the-art  sometimes even surpassing human
performance on tasks which only a few years ago were thought to be beyond an algorithmic solution
for decades to come [7  8]. Since DNNs and humans achieve similar accuracy  a number of studies
have started investigating similarities and differences between DNNs and human vision [9–24]. On
the one hand  the network units are an enormous simpliﬁcation given the sophisticated nature and
diversity of neurons in the brain [25]. On the other hand  often the strength of a model lies not
in replicating the original system but rather in its ability to capture the important aspects while
abstracting from details of the implementation (e.g. [26  27]).
One of the most remarkable properties of the human visual system is its ability to generalise
robustly. Humans generalise across a wide variety of changes in the input distribution  such as across
different illumination conditions and weather types. For instance  human object recognition is largely
unimpaired even if there are rain drops or snow ﬂakes in front of an object. While humans are
certainly exposed to a large number of such changes during their preceding lifetime (i.e.  at “training
time”  as we would say for DNNs)  there seems to be something very generic about the way the
human visual system is able to generalise that is not limited to the same distribution one was exposed
to previously. Otherwise we would not be able to make sense of a scene if there was some sort of
“new”  previously unseen noise. Even if one never had a shower of confetti before  one is still able to
effortlessly recognise objects at a carnival parade. Naturally  such generic  robust mechanisms are
not only desirable for animate visual systems but also for solving virtually any visual task that goes
beyond a well-conﬁned setting where one knows the exact test distribution already at training time.
Deep learning for autonomous driving may be one prominent example: one would like to achieve
robust classiﬁcation performance in the presence of confetti  despite not having had any confetti
exposure during training time. Thus  from a machine learning perspective  general noise robustness
can be used as a highly relevant example of lifelong machine learning [28] requiring generalisation
that does not rely on the standard assumption of independent  identically distributed (i.i.d.) samples
at test time.

1.2 Comparing generalisation abilities

Generalisation in DNNs usually works surprisingly well: First of all  DNNs are able to learn
sufﬁciently general features on the training distribution to achieve a high accuracy on the i.i.d. test
distribution despite having sufﬁcient capacity to completely memorise the training data [29]  and

2

considerable effort has been devoted to understand this phenomenon (e.g. [30–32]).1 Secondly 
features learned on one task often transfer to only loosely related tasks  such as from classiﬁcation to
saliency prediction [33]  emotion recognition [34]  medical imaging [35] and a large number of other
transfer learning tasks [36]. However  transfer learning still requires a substantial amount of training
before it works on the new task. Here  we focus on a third setting that adopts the lifelong machine
learning point of view of generalisation [37]: How well can a visual learning system cope with a
new image degradation after it has learned to cope with a certain set of image distortions before. As
a measure of object recognition robustness we can test the ability of a classiﬁer or visual system
to tolerate changes in the input distribution up to a certain degree  i.e.  to achieve high recognition
performance despite being evaluated on a test distribution that differs to some degree from the training
distribution (testing under realistic  non-i.i.d. conditions). Using this approach we measure how well
DNNs and human observers cope with parametric image manipulations that gradually distort the
original image.
First  we assess how top-performing DNNs that are trained on ImageNet  GoogLeNet [38]  VGG-
19 [39] and ResNet-152 [40]  compare against human observers when tested on twelve different
distortions such as additive noise or phase noise (see Figure 2 for an overview)—in other words 
how well do they generalise towards previously unseen distortions.2 In a second set of experiments 
we train networks directly on distorted images to see how well they can in general cope with noisy
input  and how much training on distortions as a form of data augmentation helps in dealing with
other distortions. Psychophysical investigations of human behaviour on object recognition tasks 
measuring accuracies depending on image colour (greyscale vs. colour)  image contrast and the
amount of additive visual noise have been powerful means of exploring the human visual system 
revealing much about the internal computations and mechanisms at work [42–48]. As a consequence 
similar experiments might yield equally interesting insights into the functioning of DNNs  especially
as a comparison to high-quality measurements of human behaviour. In particular  human data
for our experiments were obtained using a controlled lab environment (instead of e.g. Amazon
Mechanical Turk without sufﬁcient control about presentation times  display calibration  viewing
angles  and sustained attention of participants). Our carefully measured behavioural datasets—twelve
experiments encompassing a total number of 82 880 psychophysical trials—as well as materials and
code are available online at https://github.com/rgeirhos/generalisation-humans-DNNs.

2 Methods

We here report the core elements of employed paradigm  procedure  image manipulations  observers
and DNNs; this is aimed at giving the reader just enough information to understand experiments
and results. For in-depth explanations we kindly refer to the comprehensive supplementary material 
which seeks to provide exhaustive and reproducible experimental details.

2.1 Paradigm  procedure & 16-class-ImageNet

For this study  we developed an experimental paradigm aimed at comparing human observers
and DNNs as fair as possible by using a forced-choice image categorisation task.3 Achieving
a fair psychophysical comparison comes with a number of challenges: First of all  many high-
performing DNNs are trained on the ILSRVR 2012 database [50] with 1 000 ﬁne-grained cate-
gories (e.g.  over a hundred different dog breeds). If humans are asked to name objects  however 
they most naturally categorise them into so-called entry-level categories (e.g. dog rather than
German shepherd). We thus developed a mapping from 16 entry-level categories such as dog 
car or chair to their corresponding ImageNet categories using the WordNet hierarchy [51]. We
term this dataset “16-class-ImageNet” since it groups a subset of ImageNet classes into 16 entry-
level categories (airplane  bicycle  boat  car  chair  dog  keyboard  oven  bear 
bird  bottle  cat  clock  elephant  knife  truck). In every experiment  then  an im-
age was presented on a computer screen and observers had to choose the correct category by clicking
on one of these 16 categories. For pre-trained DNNs  the sum of all softmax values mapping to

1Still  DNNs usually need orders of magnitude more training data in comparison to humans  as explored by

the literature on one-shot or few-shot learning (see e.g. [23] for an overview).

2We have reported a subset of these experiments on arXiv in an earlier version of this paper [41].
3This is the same paradigm as reported in [49].

3

Figure 2: Example stimulus image of class bird across all distortion types. From left to right  image
manipulations are: colour (undistorted)  greyscale  low contrast  high-pass  low-pass (blurring)  phase
noise  power equalisation. Bottom row: opponent colour  rotation  Eidolon I  II and III  additive
uniform noise  salt-and-pepper noise. Example stimulus images across all used distortion levels are
available in the supplementary material.

a certain entry-level category was computed. The entry-level category with the highest sum was
then taken as the network’s decision. A second challenge is the fact that standard DNNs only use
feedforward computations at inference time  while recurrent connections are ubiquitous in the human
brain [52  53].4 In order to prevent this discrepancy from playing a major confounding role in our
experimental comparison  presentation time for human observers was limited to 200 ms. An image
was immediately followed by a 200 ms presentation of a noise mask with 1/f spectrum  known to
minimise  as much as psychophysically possible  feedback inﬂuence in the brain.

2.2 Observers & pre-trained deep neural networks

Data from human observers were compared against classiﬁcation performance of three pre-trained
DNNs: VGG-19 [39]  GoogLeNet [38] and ResNet-152 [40]. For each of the twelve experiments that
were conducted  either ﬁve or six observers participated (with the exception of the colour experiment 
for which only three observers participated since similar experiments had already been performed by
a number of studies [48  55  56]). Observers reported normal or corrected-to-normal vision.

2.3

Image manipulations

A total of twelve experiments were performed in a well-controlled psychophysical lab setting. In
every experiment  a (possibly parametric) distortion was applied to a large number of images  such
that the signal strength ranged from ‘no distortion / full signal’ to ‘distorted / weak(er) signal’.
We then measured how classiﬁcation accuracy changed as a function of signal strength. Three of
the employed image manipulations were dichotomous (colour vs. greyscale  true vs. opponent
colour  original vs. equalised power spectrum); one manipulation had four different levels (0  90 
180 and 270 degrees of rotation); one had seven levels (0  30  ...  180 degrees of phase noise)
and the other distortions had eight different levels. Those manipulations were: uniform noise 
controlled by the ‘width’ parameter indicating the bounds of pixel-wise additive uniform noise;
low-pass ﬁltering and high-pass ﬁltering (with different standard deviations of a Gaussian ﬁlter);
contrast reduction (contrast levels from 100% to 1%) as well as three different manipulations from
the eidolon toolbox [57]). The three eidolon experiments correspond to different versions of a
parametric image manipulation  with the ‘reach’ parameter controlling the strength of the distortion.
Additionally  for experiments with training on distortions  we also evaluated performance on stimuli
with salt-and-pepper noise (controlled by parameter p indicating probability of setting a pixel to
either black or white; p ∈ [0  10  20  35  50  65  80  95]%). More information about the different
image manipulations is provided in the supplementary material (Section Image preprocessing and
distortions)  where we also show example images across all manipulations and distortion levels
(Figures 10  11  12  13  14). For a brief overview  Figure 2 depicts one exemplary manipulation
per distortion. Overall  the manipulations we used were chosen to reﬂect a large variety of possible
distortions.

4But see e.g. [54] for a critical assessment of this argument.

4

Accuracy

Entropy

Accuracy

Entropy

(a) Colour vs. greyscale

(b) True vs. false colour

(c) Uniform noise

(d) Low-pass

(e) Contrast

(f) High-pass

(g) Eidolon I

(h) Phase noise

(i) Eidolon II

(j) Power equalisation

(k) Eidolon III

(l) Rotation

Figure 3: Classiﬁcation accuracy and response distribution entropy for GoogLeNet  VGG-19 and
ResNet-152 as well as for human observers. ‘Entropy’ indicates the Shannon entropy of the re-
sponse/decision distribution (16 classes). It here is a measure of bias towards certain categories: using
a test dataset that is balanced with respect to the number of images per category  responding equally
frequently with all 16 categories elicits the maximum possible entropy of four bits. If a network
or observer responds prefers some categories over others  entropy decreases (down to zero bits in
the extreme case of responding with one particular category all the time  irrespective of the ground
truth category). Human ‘error bars’ indicate the full range of results across participants. Image
manipulations are explained in Section 2.3 and visualised in Figures 10  11  12  13 and 14.

5

ColourClassification accuracycolourgreyscale0.00.20.40.60.81.0lparticipants (avg.)GoogLeNetVGG−19ResNet−152llColourResponse distr. entropy [bits]colourgreyscale0.01.02.03.04.0llColourClassification accuracytrueopponent0.00.20.40.60.81.0llColourResponse distr. entropy [bits]trueopponent0.01.02.03.04.0llUniform noise widthClassification accuracy00.20.40.60.810.00.20.40.60.81.0llllllllUniform noise widthResponse distr. entropy [bits]00.20.40.60.810.01.02.03.04.0llllllllFilter standard deviationClassification accuracy013510400.00.20.40.60.81.0llllllllFilter standard deviationResponse distr. entropy [bits]013510400.01.02.03.04.0llllllllLog10 of contrast in percentClassification accuracy21.510.500.00.20.40.60.81.0llllllllLog10 of contrast in percentResponse distr. entropy [bits]21.510.500.01.02.03.04.0llllllllFilter standard deviationClassification accuracyInf31.510.70.450.00.20.40.60.81.0llllllllFilter standard deviationResponse distr. entropy [bits]Inf31.510.70.450.01.02.03.04.0llllllllLog2 of 'reach' parameterClassification accuracy012345670.00.20.40.60.81.0llllllllLog2 of 'reach' parameterResponse distr. entropy [bits]012345670.01.02.03.04.0llllllllPhase noise width [°]Classification accuracy03060901201501800.00.20.40.60.81.0lllllllPhase noise width [°]Response distr. entropy [bits]03060901201501800.01.02.03.04.0lllllllLog2 of 'reach' parameterClassification accuracy012345670.00.20.40.60.81.0llllllllLog2 of 'reach' parameterResponse distr. entropy [bits]012345670.01.02.03.04.0llllllllPower spectrumClassification accuracyoriginalequalised0.00.20.40.60.81.0llPower spectrumResponse distr. entropy [bits]originalequalised0.01.02.03.04.0llLog2 of 'reach' parameterClassification accuracy012345670.00.20.40.60.81.0llllllllLog2 of 'reach' parameterResponse distr. entropy [bits]012345670.01.02.03.04.0llllllllRotation angle [°]Classification accuracy0901802700.00.20.40.60.81.0llllRotation angle [°]Response distr. entropy [bits]0901802700.01.02.03.04.0llll2.4 Training on distortions

Beyond evaluating standard pre-trained DNNs on distortions (results reported in Figure 3)  we
also trained networks directly on distortions (Figure 4). These networks were trained on 16-class-
ImageNet  a subset of the standard ImageNet dataset as described in Section 2.1. This reduced the size
of the unperturbed training set to approximately one ﬁfth. To correct for the highly imbalanced number
of samples per class  we weighted each sample in the loss function with a weight proportional to one
over the number of samples of the corresponding class. All networks trained in these experiments
had a ResNet-like architecture that differed from a standard ResNet-50 only in the number of output
neurons that we reduced from 1000 to 16 to match the 16 entry-level classes of the dataset. Weights
were initialised with a truncated normal distribution with zero mean and a standard deviation of
1√
n where n is the number of output neurons in a layer. While training from scratch  we performed
on-the-ﬂy data augmentation using different combinations of the image manipulations. When training
a network on multiple types of image manipulations (models B1 to B9 as well as C1 and C2 of
Figure 4)  the type of manipulation (including unperturbed  i.e. standard colour images if applicable)
was drawn uniformly and we only applied one manipulation at a time (i.e.  the network never saw a
single image perturbed with multiple image manipulations simultaneously  except that some image
manipulations did include other manipulations per construction: uniform noise  for example  was
always added after conversion to greyscale and contrast reduction to 30%). For a given image
manipulation  the amount of perturbation was drawn uniformly from the levels used during test
time (cf. Figure 3). The remaining aspects of the training followed standard training procedures for
training a ResNet on ImageNet: we used SGD with a momentum of 0.997  a batch size of 64  and
an initial learning rate of 0.025. The learning rate was multiplied with 0.1 after 30  60  80 and 90
epochs (when training for 100 epochs) or 60  120  160 and 180 epochs (when training for 200 epochs).
Training was done using TensorFlow 1.6.0 [58]. In the training experiments  all manipulations with
more than two levels were included except for the eidolon stimuli  since the generation of those
stimuli is computationally too slow for ImageNet training. For comparison purposes  we additionally
included colour vs. greyscale as well as salt-and-pepper noise (for which there is no human data  but
informal comparisons between uniform noise and salt-and-pepper noise strongly suggest that human
performance will be similar  see Figure 1c).

3 Generalisation of humans and pre-trained DNNs towards distortions

In order to assess generalisation performance when the signal gets weaker  we tested twelve different
ways of degrading images. These images at various levels of signal strength were then shown to
both human observers in a lab and to pre-trained DNNs (ResNet-152  GoogLeNet and VGG-19)
for classiﬁcation. The results of this comparison are visualised in Figure 3. While human and
DNN performance was similar for comparatively minor colour-related distortions such as conversion
to greyscale or opponent colours  we ﬁnd human observers to be more robust for all of the other
distortions: by a small margin for low contrast  power equalisation and phase noise images and by
a larger margin for uniform noise  low-pass  high-pass  rotation and all three eidolon experiments.
Furthermore  there are strong differences in the error patterns as measured by the response distribution
entropy (indicating biases towards certain categories). Human participants’ responses were distributed
more or less equally amongst the 16 classes  whereas all three DNNs show increasing biases towards
certain categories when the signal gets weaker. These biases are not completely explained by the
prior class probabilities  and deviate from distortion to distortion. For instance  ResNet-152 almost
solely predicts class bottle for images with strong uniform noise (irrespective of the ground truth
category) 5 and classes dog or bird for images distorted by phase noise. One might think of
simple tricks to reduce the discrepancy between the response distribution entropy of DNNs and
humans. One possible way would be increasing the softmax temperature parameter and assuming that
model decisions are sampled from the softmax distribution rather than taking the argmax. However 
increasing the response DNN distribution entropy in this way dramatically decreases classiﬁcation
accuracy and thus comes with a trade-off (cf. Figure 8 in the supplementary material).
These results are in line with previous ﬁndings reporting human-like processing of chromatic infor-
mation in DNNs [19] but strong decreases in DNN recognition accuracy for image degradations like

5A category-level analysis of decision biases for the uniform noise experiment is provided in the supplemen-

tary material  Figure 9.

6

Figure 4: Classiﬁcation accuracy (in percent) for networks with potentially distorted training data.
Rows show different test conditions at an intermediate difﬁculty (exact condition indicated in brackets 
units as in Figure 3). Columns correspond to differently trained networks (leftmost column: human
observers for comparison; no human data available for salt-and-pepper noise). All of the networks
were trained from scratch on (a potentially manipulated version of) 16-class-ImageNet. Manipulations
included in the training data are indicated by a red rectangle; additionally ‘greyscale’ is underlined
if it was part of the training data because a certain distortion encompasses greyscale images at full
contrast. Models A1 to A9: ResNet-50 trained on a single distortion (100 epochs). Models B1 to B9:
ResNet-50 trained on uniform noise plus one other distortion (200 epochs). Models C1 & C2:
ResNet-50 trained on all but one distortion (200 epochs). Chance performance is at 1
16 = 6.25%
accuracy.

noise and blur [13  14  59–61]. Overall  DNNs seem to have much more problems generalising to
weaker signals than humans  across a wide variety of image distortions. While the human visual
system has been exposed to a number of distortions during evolution and lifetime  we clearly had no
exposure whatsoever to many of the exact image manipulations that we tested here. Thus  our human
data show that a high level of generalisation is  in principle  possible. There may be many different
reasons for the discrepancy between human and DNN generalisation performance that we ﬁnd: Are
there limitations in terms of the currently used network architectures (as hypothesised by [60])  which
may be inferior to the human brain’s intricate computations? Is it a problem of the training data (as
suggested by e.g. [61])  or are today’s training methods / optimisers not sufﬁcient to solve robust and
general object recognition? In order to shed light on the dissimilarities we found  we performed a
second batch of experiments by training networks directly on distorted images.

4 Training DNNs directly on distorted images

We trained one network per distortion directly and from scratch on (potentially manipulated) 16-class-
ImageNet images. The results of this training are visualised in Figure 4 (models A1 to A9). We ﬁnd
that these specialised networks consistently outperformed human observers  by a large margin  on
the image manipulation they were trained on (as indicated by strong network performance on the
diagonal). This is a strong indication that currently employed architectures (such as ResNet-50) and
training methods (standard optimiser and training procedure) are sufﬁcient to ‘solve’ distortions under
i.i.d. train/test conditions. We were able to not only close the human-DNN performance gap that was
observed by [13] (who ﬁne-tuned networks on distortions  reporting improved but not human-level
DNN performance) but to surpass human performance in this respect. While the human visual system
certainly has a much more complicated structure [24]  this does not seem to be necessary to deal with
even strong image manipulations of the type employed here.
However  as noted earlier  robust generalisation is primarily not about solving a speciﬁc problem
known exactly in advance. We therefore tested how networks trained on a certain distortion type
perform when tested on other distortions. These results are visualised in Figure 4 by the off-diagonal

7

88.596.78.150.083.190.886.184.295.995.510.410.290.611.297.995.472.393.091.192.494.986.687.89.894.186.290.593.287.895.194.810.311.495.612.894.096.896.293.395.794.390.947.613.129.089.419.610.239.817.188.290.928.634.614.237.946.351.795.150.579.159.445.249.821.120.629.911.78.392.627.790.791.410.418.924.719.825.122.829.225.094.327.528.348.518.96.616.478.49.811.916.074.974.76.97.116.19.316.018.614.487.220.513.813.545.66.280.36.99.06.07.36.271.511.010.285.47.389.884.683.385.084.683.782.583.857.423.38.931.227.024.446.681.482.682.97.47.828.37.630.831.430.631.443.487.424.178.536.58.039.931.889.040.437.780.580.18.58.343.38.838.541.940.335.240.140.589.0NA6.16.25.87.96.46.26.213.678.679.489.66.46.26.26.16.35.45.85.76.2= manipulation included in training datauniform noise (0.35)salt−and−pepper noise (0.2)rotation (90°)phase noise (90°)high−pass (std=0.7)low−pass (std=7)contrast (5%)greyscalecolourhuman observersA1A2A3A4A5A6A7A8A9B1B2B3B4B5B6B7B8B9C1C2ModelEvaluation conditioncells of models A1 to A9. Overall  we ﬁnd that training on a certain distortion slightly improves
performance on other distortions in a few instances  but is detrimental in other cases (when compared
to a vanilla ResNet-50 trained on colour images  model A1 in the ﬁgure).6 Performance on salt-and-
pepper noise as well as uniform noise was close to chance level for all networks  even for a network
trained directly on the respectively other noise model. This may be surprising given that these two
types of noise do not seem very different to a human eye (as indicated in Figure 1c). Hence  training
a network on one distortion does not generally lead to improvements on other distortions.
Since training on a single distortion alone does not seem to be sufﬁcient to evoke robust generalisation
performance in DNNs  we also trained the same architecture (ResNet-50) on two additional settings.
Models B1 to B9 in Figure 4 show performance for training on one particular distortion in combination
with uniform noise (training consisted of 50% images from each manipulation). Uniform noise was
chosen since it seemed to be one of the hardest distortions for all networks  and hence they might
beneﬁt from including this particular distortion in the training data. Furthermore  we trained models
C1 and C2 on all but one distortion (either uniform or salt-and-pepper noise was left out).
We ﬁnd that object recognition performance of models B1 to B9 is improved compared to models A1
to A9  both on the distortions they were actually trained on (diagonal entries with red rectangles in
Figure 4) as well as on a few of the distortions that were not part of the training data. However  this
improvement may be largely due to the fact that models B1 to B9 were trained on 200 epochs instead
of 100 epochs as for models A1 to A9  since the accuracy of model B9 (trained & tested on uniform
noise  200 epochs) also shows an improvement towards model A9 (trained & tested on uniform
noise  100 epochs). Hence  in the presence of heavy distortions  training longer may go a long way
but incorporating other distortions in the training does not seem to be generally beneﬁcial to model
performance. Furthermore  we ﬁnd that it is possible even for a single model to reach high accuracies
on all of the eight distortions it was trained on (models C1 & C2)  however for both left-out uniform
and salt-and-pepper noise  object recognition accuracy stayed around 11 to 14%  which is by far
closer to chance level (approx. 6%) than to the accuracy reached by a specialised network trained on
this exact distortion (above 70%  serving as a lower bound on the achievable performance).
Taken together  these ﬁndings indicate that data augmentation with distortions alone may be insufﬁ-
cient to overcome the generalisation problem that we ﬁnd. It may be necessary to move from asking
“why are DNNs generalising so well (under i.i.d. settings)?” [29] to “why are DNNs generalising
so poorly (under non-i.i.d. settings)?”. It is up to future investigations to determine how DNNs that
are currently being handled as computational models of human object recognition can solve this
challenge. At the exciting interface between cognitive science / visual perception and deep learning 
inspiration and ideas may come from both ﬁelds: While the computer vision sub-area of domain
adaptation (see [63] for a review) is working on robust machine inference in spite of shifts in the
input distribution  the human vision community is accumulating strong evidence for the beneﬁts of
local gain control mechanisms. These normalisation processes seem to be crucial for many aspects
of robust animal and human vision [46]  are predictive for human vision data [21  64] and have
proven useful in the context of computer vision [65  66]. It could be an interesting avenue for future
research to determine whether there is a connection between neural normalisation processes and
DNN generalisation performance. Furthermore  incorporating a shape bias in DNNs seems to be a
very promising avenue towards general noise robustness  strongly improving performance on many
distortions [67].

5 Conclusion

We conducted a behavioural comparison of human and DNN object recognition robustness against
twelve different image distortions. In comparison to human observers  we ﬁnd the classiﬁcation
performance of three well-known DNNs trained on ImageNet—ResNet-152  GoogLeNet and VGG-
19—to decline rapidly with decreasing signal-to-noise ratio under image distortions. Additionally  we
ﬁnd progressively diverging patterns of classiﬁcation errors between humans and DNNs with weaker
signals.Our results  based on 82 880 psychophysical trials under well-controlled lab conditions 
demonstrate that there are still marked differences in the way humans and current DNNs process
6The no free lunch theorem [62] states that better performance on some input is necessarily accompanied
by worse performance on other input; however we here are only interested in a narrow subset of the possible
input space (natural images corrupted by distortions). The high accuracies of human observers across distortions
indicate that it is  in principle  possible to achieve good performance on many distortions simultaneously.

8

object information. These differences  in our setting  cannot be overcome by training on distorted
images (i.e.  data augmentation): While DNNs cope perfectly well with the exact distortion they
were trained on  they still show a strong generalisation failure towards previously unseen distortions.
Since the space of possible distortions is literally unlimited (both theoretically and in real-world
applications)  it is not feasible to train on all of them. DNNs have a generalisation problem when it
comes to settings that go beyond the usual (yet often unrealistic) i.i.d. assumption. We believe that
solving this generalisation problem will be crucial both for robust machine inference and towards
better models of human object recognition  and we envision that our ﬁndings as well as our carefully
measured and freely available behavioural data7 may provide a new useful benchmark for improving
DNN robustness and a motivation for neuroscientists to identify mechanisms in the brain that may be
responsible for this remarkable robustness.

Author contributions

The initial project idea of comparing humans against DNNs was developed by F.A.W. and R.G. All
authors jointly contributed towards designing the study and interpreting the data. R.G. and C.R.M.T.
developed the image manipulations and acquired the behavioural data with input from H.H.S. and
F.A.W.; J.R. trained networks on distortions; experimental data and networks were evaluated by
C.R.M.T.  R.G. and J.R. with input from H.H.S  M.B. and F.A.W.; R.G. and C.R.M.T. worked on
making our work reproducible (data  code and materials openly accessible; writing supplementary
material); R.G. wrote the paper with signiﬁcant input from all other authors.

Acknowledgments

This work has been funded  in part  by the German Federal Ministry of Education and Research
(BMBF) through the Bernstein Computational Neuroscience Program Tübingen (FKZ: 01GQ1002)
as well as the German Research Foundation (DFG; Sachbeihilfe Wi 2103/4-1 and SFB 1233 on
“Robust Vision”). The authors thank the International Max Planck Research School for Intelli-
gent Systems (IMPRS-IS) for supporting R.G. and J.R.; J.R. acknowledges support by the Bosch
Forschungsstiftung (Stifterverband  T113/30057/17); M.B. acknowledges support by the Centre for
Integrative Neuroscience Tübingen (EXC 307) and by the Intelligence Advanced Research Projects
Activity (IARPA) via Department of Interior/Interior Business Center (DoI/IBC) contract number
D16PC00003.
We would like to thank David Janssen for his invaluable contributions in shaping the early stage of
this project. Furthermore  we are very grateful to Tom Wallis for providing the MATLAB source code
of one of his experiments  and for allowing us to use and modify it; Silke Gramer for administrative
and Uli Wannek for technical support  as well as Britta Lewke for the method of creating response
icons and Patricia Rubisch for help with testing human observers. Moreover  we would like to thank
Nikolaus Kriegeskorte  Jakob Macke and Tom Wallis for helpful feedback  and three anonymous
reviewers for constructive suggestions.

References
[1] Irving Biederman. Recognition-by-components: a theory of human image understanding. Psychological

Review  94(2):115–147  1987.

[2] James J DiCarlo  Davide Zoccolan  and Nicole C Rust. How does the brain solve visual object recognition?

Neuron  73(3):415–434  2012.

[3] Mary C Potter. Short-term conceptual memory for pictures. Journal of Experimental Psychology: human

learning and memory  2(5):509  1976.

[4] Simon Thorpe  Denis Fize  and Catherine Marlot. Speed of processing in the human visual system. Nature 

381(6582):520–522  1996.

[5] Melvyn A. Goodale and A. David Milner. Separate visual pathways for perception and action. Trends in

Neurosciences  15(1):20–25  1992.

[6] A. Krizhevsky  I. Sutskever  and G. E. Hinton. ImageNet classiﬁcation with deep convolutional neural

networks. In Advances in Neural Information Processing Systems  pages 1097–1105  2012.

7https://github.com/rgeirhos/generalisation-humans-DNNs

9

[7] Kaiming He  Xiangyu Zhang  Shaoqing Ren  and Jian Sun. Delving deep into rectiﬁers: Surpassing
human-level performance on ImageNet classiﬁcation. In Proceedings of the IEEE International Conference
on Computer Vision  pages 1026–1034  2015.

[8] David Silver  Aja Huang  Chris J. Maddison  Arthur Guez  Laurent Sifre  George van den Driessche 
Julian Schrittwieser  Ioannis Antonoglou  Veda Panneershelvam  Marc Lanctot  Sander Dieleman  Dominik
Grewe  John Nham  Nal Kalchbrenner  Ilya Sutskever  Timothy Lillicrap  Madeleine Leach  Koray
Kavukcuoglu  Thore Graepel  and Demis Hassabis. Mastering the game of Go with deep neural networks
and tree search. Nature  529(7587):484–489  2016. ISSN 0028-0836.

[9] Charles F. Cadieu  H. Hong  D. L. K. Yamins  N. Pinto  D. Ardila  E. A. Solomon  N. J. Majaj  and
J. J. DiCarlo. Deep neural networks rival the representation of primate IT cortex for core visual object
recognition. PLoS Computational Biology  10(12)  2014.

[10] Daniel LK Yamins  Ha Hong  Charles F Cadieu  Ethan A Solomon  Darren Seibert  and James J DiCarlo.
Performance-optimized hierarchical models predict neural responses in higher visual cortex. Proceedings
of the National Academy of Sciences  111(23):8619–8624  2014.

[11] Radoslaw Martin Cichy  Aditya Khosla  Dimitrios Pantazis  and Aude Oliva. Dynamics of scene represen-
tations in the human brain revealed by magnetoencephalography and deep neural networks. NeuroImage 
2016.

[12] Saeed Reza Kheradpisheh  Masoud Ghodrati  Mohammad Ganjtabesh  and Timothée Masquelier.
Deep networks resemble human feed-forward vision in invariant object recognition. arXiv preprint
arXiv:1508.03929  2016.

[13] Samuel Dodge and Lina Karam. A study and comparison of human and deep learning recognition

performance under visual distortions. arXiv preprint arXiv:1705.02498  2017.

[14] Samuel Dodge and Lina Karam. Can the early human visual system compete with deep neural networks?

arXiv preprint arXiv:1710.04744  2017.

[15] Ron Dekel. Human perception in computer vision. arXiv preprint arXiv:1701.04674  2017.

[16] RT Pramod and SP Arun. Do computational models differ systematically from human object perception?
In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition  pages 1601–1609 
2016.

[17] Hamid Karimi-Rouzbahani  Nasour Bagheri  and Reza Ebrahimpour. Invariant object recognition is a
personalized selection of invariant features in humans  not simply explained by hierarchical feed-forward
vision models. Scientiﬁc reports  7(1):14402  2017.

[18] Amir Rosenfeld  Markus D Solbach  and John K Tsotsos. Totally looks like-how humans compare 

compared to machines. arXiv preprint arXiv:1803.01485  2018.

[19] Alban Flachot and Karl R Gegenfurtner. Processing of chromatic information in a deep convolutional

neural network. JOSA A  35(4):B334–B346  2018.

[20] Thomas SA Wallis  Christina M Funke  Alexander S Ecker  Leon A Gatys  Felix A Wichmann  and
Matthias Bethge. A parametric texture model based on deep convolutional features closely matches texture
appearance for humans. Journal of vision  17(12):5–5  2017.

[21] Alexander Berardino  Valero Laparra  Johannes Ballé  and Eero Simoncelli. Eigen-distortions of hi-
erarchical representations. In Advances in Neural Information Processing Systems  pages 3533–3542 
2017.

[22] Kamila M Jozwik  Nikolaus Kriegeskorte  Katherine R Storrs  and Marieke Mur. Deep convolutional neural
networks outperform feature-based but not categorical models in explaining object similarity judgments.
Frontiers in psychology  8:1726  2017.

[23] Brenden M Lake  Tomer D Ullman  Joshua B Tenenbaum  and Samuel J Gershman. Building machines

that learn and think like people. Behavioral and Brain Sciences  40  2017.

[24] Tim C Kietzmann  Patrick McClure  and Nikolaus Kriegeskorte. Deep neural networks in computational

neuroscience. bioRxiv  2017.

[25] Rodney J Douglas and Kevan A C Martin. Opening the grey box. Trends in Neurosciences  14(7):286–293 

1991.

10

[26] George E P Box. Science and statistics. Journal of the American Statistical Association  71(356):791–799 

1976.

[27] Nikolaus Kriegeskorte. Deep neural networks: A new framework for modeling biological vision and brain

information processing. Annual Review of Vision Science  1(15):417–446  2015.

[28] Zhiyuan Chen and Bing Liu. Lifelong Machine Learning. Morgan & Claypool Publishers  2016. ISBN

1627055010  9781627055017.

[29] Chiyuan Zhang  Samy Bengio  Moritz Hardt  Benjamin Recht  and Oriol Vinyals. Understanding deep

learning requires rethinking generalization. arXiv preprint arXiv:1611.03530  2016.

[30] Kenji Kawaguchi  Leslie Pack Kaelbling  and Yoshua Bengio. Generalization in deep learning. arXiv

preprint arXiv:1710.05468  2017.

[31] Behnam Neyshabur  Srinadh Bhojanapalli  David McAllester  and Nati Srebro. Exploring generalization in

deep learning. In Advances in Neural Information Processing Systems  pages 5949–5958  2017.

[32] Ravid Shwartz-Ziv and Naftali Tishby. Opening the black box of deep neural networks via information.

arXiv preprint arXiv:1703.00810  2017.

[33] Matthias Kümmerer  Thomas SA Wallis  and Matthias Bethge. Deepgaze II: Reading ﬁxations from deep

features trained on object recognition. arXiv preprint arXiv:1610.01563  2016.

[34] Hong-Wei Ng  Viet Dung Nguyen  Vassilios Vonikakis  and Stefan Winkler. Deep learning for emotion
recognition on small datasets using transfer learning. In Proceedings of the 2015 ACM on international
conference on multimodal interaction  pages 443–449. ACM  2015.

[35] Hayit Greenspan  Bram van Ginneken  and Ronald M Summers. Guest editorial deep learning in medical
imaging: Overview and future promise of an exciting new technique. IEEE Transactions on Medical
Imaging  35(5):1153–1159  2016.

[36] Jeff Donahue  Yangqing Jia  Oriol Vinyals  Judy Hoffman  Ning Zhang  Eric Tzeng  and Trevor Darrell.
Decaf: A deep convolutional activation feature for generic visual recognition. In International conference
on machine learning  pages 647–655  2014.

[37] Sebastian Thrun. Is learning the n-th thing any easier than learning the ﬁrst? In Advances in Neural

Information Processing Systems  pages 640–646. The MIT Press  1996.

[38] Christian Szegedy  Wei Liu  Yangqing Jia  Pierre Sermanet  Scott Reed  Dragomir Anguelov  Dumitru
Erhan  Vincent Vanhoucke  and Andrew Rabinovich. Going deeper with convolutions. In Proceedings of
the IEEE Conference on Computer Vision and Pattern Recognition  pages 1–9  2015.

[39] Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recogni-

tion. arXiv preprint arXiv:1409.1556  2015.

[40] K. He  X. Zhang  S. Ren  and J. Sun. Deep residual learning for image recognition. In Proceedings of the

IEEE Conference on Computer Vision and Pattern Recognition  pages 770–778  2016.

[41] Robert Geirhos  David HJ Janssen  Heiko H Schütt  Jonas Rauber  Matthias Bethge  and Felix A Wichmann.
Comparing deep neural networks against humans: object recognition when the signal gets weaker. arXiv
preprint arXiv:1706.06969  2017.

[42] Jacob Nachmias and R V Sansbury. Grating contrast: Discrimination may be better than detection. Vision

Research  14(10):1039–1042  1974.

[43] Denis G Pelli and Bart Farell. Why use noise? Journal of the Optical Society of America A  16(3):647–653 

1999.

[44] Felix A Wichmann. Some Aspects of Modelling Human Spatial Vision: Contrast Discrimination. PhD

thesis  The University of Oxford  1999.

[45] G Bruce Henning  C M Bird  and Felix A Wichmann. Contrast discrimination with pulse trains in pink

noise. Journal of the Optical Society of America A  19(7):1259–1266  2002.

[46] Matteo Carandini and David J Heeger. Normalization as a canonical neural computation. Nature Reviews

Neuroscience  13(1):51–62  2012.

[47] Matteo Carandini  David J Heeger  and J Anthony Movshon. Linearity and normalization in simple cells

of the macaque primary visual cortex. The Journal of Neuroscience  17(21):8621–8644  1997.

11

[48] Arnaud Delorme  Guillaume Richard  and Michele Fabre-Thorpe. Ultra-rapid categorisation of natural
scenes does not rely on colour cues: a study in monkeys and humans. Vision Research  40(16):2187–2200 
2000.

[49] Felix A Wichmann  David HJ Janssen  Robert Geirhos  Guillermo Aguilar  Heiko H Schütt  Marianne
Maertens  and Matthias Bethge. Methods and measurements to compare men against machines. Electronic
Imaging  Human Vision and Electronic Imaging  2017(14):36–45  2017.

[50] Olga Russakovsky  Jia Deng  Hao Su  Jonathan Krause  Sanjeev Satheesh  Sean Ma  Zhiheng Huang 
Andrej Karpathy  Aditya Khosla  Michael Bernstein  Alexander C Berg  and Li Fei-Fei. ImageNet Large
Scale Visual Recognition Challenge. International Journal of Computer Vision  115(3):211–252  2015.

[51] George A Miller. Wordnet: a lexical database for English. Communications of the ACM  38(11):39–41 

1995.

[52] Victor AF Lamme  Hans Super  and Henk Spekreijse. Feedforward  horizontal  and feedback processing in

the visual cortex. Current opinion in neurobiology  8(4):529–535  1998.

[53] Olaf Sporns and Jonathan D Zwi. The small world of the cerebral cortex. Neuroinformatics  2(2):145–162 

2004.

[54] Wulfram Gerstner. How can the brain be so fast? In J. Leo van Hemmen and Terrence J Sejnowski  editors 

23 Problems in Systems Neuroscience  pages 135–142. Oxford University Press  2005.

[55] Jonas Kubilius  Stefania Bracci  and Hans P Op de Beeck. Deep neural networks as a computational model

for human shape sensitivity. PLoS Computational Biology  12(4):e1004896  2016.

[56] Felix A Wichmann  Doris I Braun  and Karl R Gegenfurtner. Phase noise and the classiﬁcation of natural

images. Vision Research  46(8):1520–1529  2006.

[57] Jan Koenderink  Matteo Valsecchi  Andrea van Doorn  Johan Wagemans  and Karl Gegenfurtner. Eidolons:

Novel stimuli for vision research. Journal of Vision  17(2):7–7  2017.

[58] M. Abadi  A. Agarwal  P. Barham  E. Brevdo  Z. Chen  C. Citro  G. S. Corrado  A. Davis  J. Dean 
M. Devin  S. Ghemawat  I. Goodfellow  A. Harp  G. Irving  M. Isard  Y. Jia  R. Jozefowicz  L. Kaiser 
M. Kudlur  J. Levenberg  D. Mane  R. Monga  S. Moore  D. Murray  C. Olah  M. Schuster  J. Shlens 
B. Steiner  I. Sutskever  K. Talwar  P. Tucker  V. Vanhoucke  V. Vasudevan  F. Viegas  O. Vinyals 
P. Warden  M. Wattenberg  M. Wicke  Y. Yu  and X. Zheng. TensorFlow: Large-Scale Machine Learning
on Heterogeneous Distributed Systems. arXiv preprint arXiv:1603.04467  2016.

[59] I. Vasiljevic  A. Chakrabarti  and G. Shakhnarovich. Examining the Impact of Blur on Recognition by

Convolutional Networks. arXiv preprint arXiv:1611.05760  2016.

[60] Samuel Dodge and Lina Karam. Understanding how image quality affects deep neural networks. In Quality
of Multimedia Experience (QoMEX)  2016 Eighth International Conference on  pages 1–6. IEEE  2016.

[61] Yiren Zhou  Sibo Song  and Ngai-Man Cheung. On classiﬁcation of distorted images with deep convolu-
tional neural networks. In Acoustics  Speech and Signal Processing (ICASSP)  2017 IEEE International
Conference on  pages 1213–1217. IEEE  2017.

[62] David H Wolpert and William G Macready. No free lunch theorems for optimization. IEEE transactions

on evolutionary computation  1(1):67–82  1997.

[63] Vishal M Patel  Raghuraman Gopalan  Ruonan Li  and Rama Chellappa. Visual domain adaptation: A

survey of recent advances. IEEE signal processing magazine  32(3):53–69  2015.

[64] Heiko H Schütt and Felix A Wichmann. An image-computable psychophysical spatial vision model.

Journal of vision  17(12):12–12  2017.

[65] Kevin Jarrett  Koray Kavukcuoglu  Yann LeCun  et al. What is the best multi-stage architecture for object
recognition? In Computer Vision  2009 IEEE 12th International Conference on  pages 2146–2153. IEEE 
2009.

[66] Mengye Ren  Renjie Liao  Raquel Urtasun  Fabian H Sinz  and Richard S Zemel. Normalizing the
normalizers: Comparing and extending network normalization schemes. arXiv preprint arXiv:1611.04520 
2016.

[67] Robert Geirhos  Patricia Rubisch  Claudio Michaelis  Matthias Bethge  Felix A Wichmann  and Wieland
Brendel. ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and
robustness. arXiv preprint arXiv:1811.12231  2018.

12

[68] R Core Team. R: A Language and Environment for Statistical Computing. R Foundation for Statistical

Computing  Vienna  Austria  2016. URL https://www.R-project.org/.

[69] David H Brainard. The psychophysics toolbox. Spatial Vision  10:433–436  1997.

[70] Mario Kleiner  David Brainard  Denis Pelli  Allen Ingling  Richard Murray  and Christopher Broussard.

What’s new in Psychtoolbox-3. Perception  36(14):1  2007.

[71] Eleanor Rosch. Principles of categorization. Concepts: core readings  189  1999.

[72] Tsung-Yi Lin  Michael Maire  Serge Belongie  James Hays  Pietro Perona  Deva Ramanan  Piotr Dollár 
and C Lawrence Zitnick. Microsoft COCO: Common objects in context. In European Conference on
Computer Vision  pages 740–755. Springer  2015.

[73] Stefan Van der Walt  Johannes L Schönberger  Juan Nunez-Iglesias  François Boulogne  Joshua D Warner 
Neil Yager  Emmanuelle Gouillart  and Tony Yu. scikit-image: image processing in Python. PeerJ  2:e453 
2014.

[74] A. M. Derrington  J. Krauskopf  and P. Lennie. Chromatic mechanisms in lateral geniculate nucleus of

macaque. The Journal of Physiology  357:241–265  1984.

[75] Andrew Stockman and Lindsay T Sharpe. The spectral sensitivities of the middle-and long-wavelength-
sensitive cones derived from measurements in observers of known genotype. Vision research  40(13):
1711–1737  2000.

[76] David H Brainard. Human color vision  chapter Cone Contrast and Opponent Modulation Color Spaces.

Optical Society of America  Washington  DC  2 edition  1996.

[77] A. van der Schaaf and J.H. van Hateren. Modelling the power spectra of natural images: Statistics and
information. Vision Research  36(17):2759 – 2770  1996. ISSN 0042-6989. doi: http://dx.doi.org/10.1016/
0042-6989(96)00002-8.

[78] Felix A Wichmann  Jan Drewes  Pedro Rosas  and Karl R Gegenfurtner. Animal detection in natural

scenes: Critical features revisited. Journal of Vision  10(4:6):1–27  2010.

[79] Yarin Gal and Zoubin Ghahramani. Dropout as a Bayesian approximation: Representing model uncertainty

in deep learning. In international conference on machine learning  pages 1050–1059  2016.

13

,Robert Geirhos
Carlos R. M. Temme
Jonas Rauber
Heiko H. Schütt
Matthias Bethge
Felix A. Wichmann
DongDong Ge
Haoyue Wang
Zikai Xiong
Yinyu Ye