2010,An Approximate Inference Approach to Temporal Optimization in Optimal Control,Algorithms based on iterative local approximations present a practical approach to optimal control in robotic systems. However  they generally require the temporal parameters (for e.g. the movement duration or the time point of reaching an intermediate goal) to be specified \textit{a priori}. Here  we present a methodology that is capable of jointly optimising the temporal parameters in addition to the control command profiles. The presented approach is based on a Bayesian canonical time formulation of the optimal control problem  with the temporal mapping from canonical to real time parametrised by an additional control variable. An approximate EM algorithm is derived that efficiently optimises both the movement duration and control commands offering  for the first time  a practical approach to tackling generic via point problems in a systematic way under the optimal control framework. The proposed approach is evaluated on simulations of a redundant robotic plant.,An Approximate Inference Approach to Temporal

Optimization in Optimal Control

Konrad C. Rawlik
School of Informatics
University of Edinburgh

Edinburgh  UK

Marc Toussaint

TU Berlin

Berlin  Germany

Sethu Vijayakumar
School of Informatics
University of Edinburgh

Edinburgh  UK

Abstract

Algorithms based on iterative local approximations present a practical approach
to optimal control in robotic systems. However  they generally require the tem-
poral parameters (for e.g. the movement duration or the time point of reaching
an intermediate goal) to be speciﬁed a priori. Here  we present a methodology
that is capable of jointly optimizing the temporal parameters in addition to the
control command proﬁles. The presented approach is based on a Bayesian canon-
ical time formulation of the optimal control problem  with the temporal mapping
from canonical to real time parametrised by an additional control variable. An ap-
proximate EM algorithm is derived that efﬁciently optimizes both the movement
duration and control commands offering  for the ﬁrst time  a practical approach to
tackling generic via point problems in a systematic way under the optimal control
framework. The proposed approach  which is applicable to plants with non-linear
dynamics as well as arbitrary state dependent and quadratic control costs  is eval-
uated on realistic simulations of a redundant robotic plant.

1 Introduction

Control of sensorimotor systems  artiﬁcial or biological  is inherently both a spatial and temporal
process. Not only do we have to specify where the plant has to move to but also when it reaches
that position. In some control schemes  the temporal component is implicit; for example  with a
PID controller  movement duration results from the application of the feedback loop  while in other
cases it is explicit  like for example in ﬁnite or receding horizon optimal control approaches where
the time horizon is set explicitly as a parameter of the problem [8  13].

Although control based on an optimality criterion is certainly attractive  practical approaches for
stochastic systems are currently limited to the ﬁnite horizon [9  16] or ﬁrst exit time formulation [14 
17]. The former does not optimize temporal aspects of the movement  i.e.  duration or the time when
costs for speciﬁc sub goals of the problem are incurred  assuming them as given a priori. However 
how should one choose these temporal parameters? This question is non trivial and important even
while considering a simple reaching problem. The solution generally employed in practice is to use
a apriori ﬁxed duration  chosen experimentally. This can result in not reaching the goal  having to
use unrealistic range of control commands or excessive (wasteful) durations for short distance tasks.
The alternative ﬁrst exit time formulation  on the other hand  either assumes speciﬁc exit states in the
cost function and computes the shortest duration trajectory which fulﬁls the task or assumes a time
stationary task cost function and computes the control which minimizes the joint cost of movement
duration and task cost [17  1  14]. This formalism is thus only directly applicable to tasks which do
not require sequential achievement of multiple goals. Although this limitation could be overcome
by chaining together individual time optimal single goal controllers  such a sequential approach has
several drawbacks. First  if we are interested in placing a cost on overall movement duration  we are
restricted to linear costs if we wish to remain time optimal. A second more important ﬂaw is that

1

future goals should inﬂuence our control even before we have achieved the previous goal  a problem
which we highlight during our comparative simulation studies.

A wide variety of successful approaches to address stochastic optimal control problems have been
described in the literature [6  2  7]. The approach we present here builds on a class of approximate
stochastic optimal control methods which have been successfully used in the domain of robotic ma-
nipulators and in particular  the iLQG [9] algorithm used by [10]  and the Approximate Inference
Control (AICO) algorithm [16]. These approaches  as alluded to earlier  are ﬁnite horizon formu-
lations and consequently require the temporal structure of the problem to be ﬁxed a priori. This
requirement is a direct consequence of a ﬁxed length discretization of the continuous problem and
the structure of the temporally non-stationary cost function used  which binds incurrence of goal
related costs to speciﬁc (discretised) time points. The fundamental idea proposed here is to refor-
mulate the problem in canonical time and alternately optimize the temporal and spatial trajectories.
We implement this general approach in the context of the approximate inference formulation of
AICO  leading to an Expectation Maximisation (EM) algorithm where the E-Step reduces to the
standard inference control problem. It is worth noting that due to the similarities between AICO 
iLQG and other algorithms  e.g.  DDP [6]  the same principle and approach should be applicable
more generally. The proposed approach provides an extension to the time scaling approach [12  3]
by considering the scaling for a complete controlled system  rather then a single trajectory. Addi-
tionally  it also extends previous applications of Expectation Maximisation algorithms for system
identiﬁcation of dynamical systems  e.g. [4  5]  which did not consider the temporal aspects.

2 Preliminaries

Let us consider a process with state x ∈ RDx and controls u ∈ RDu which is of the form

dx = (F(x) + Bu)dt + dξ

(cid:10)dξdξ⊤(cid:11) = Q

(1)

(2)

with non-linear state dependent dynamics F  control matrix B and Brownian motion ξ  and deﬁne
a cost of the form

L(x(·)  u(·)) =Z T

0

(cid:2)C(x(t)  t) + u(t)⊤Hu(t)(cid:3) dt  

with arbitrary state dependent cost C and quadratic control cost. Note in particular that T   the
trajectory length  is assumed to be known. The closed loop stochastic optimal control problem is to
ﬁnd the policy π : x(t) → u(t) given by

π∗ = argmin

π

E

x u|π x(0) {L(x(·)  u(·))} .

(3)

In practice  the continuous time problem is discretized into a ﬁxed number of K steps of length ∆t 
leading to the discreet problem with dynamics

P(xk+1|xk  uk) = N (xk+1|xk + (F(x) + Bu)∆t  Q∆t)  

(4)

where we use N (·|a  A) to denote a Gaussian distribution with mean a and covariance A  and cost

L(x1:K   u1:K) = CK(xK ) +

K−1Xk=0 (cid:2)∆tCk(xk) + u⊤

k(H∆t)uk(cid:3) .

(5)

Note that here we used the Euler Forward Method as the discretization scheme  which will prove
advantageous if a linear cost on the movement duration is chosen  leading to closed form solution
for certain optimization problems. However  in other cases  alternative discretisation methods could
be used and indeed  be preferable.

2.1 Approximate Inference Control

Recently  it has been suggested to consider a Bayesian inference approach [16] to (discreet) optimal
control problems formalised in Section 2. With the probabilistic trajectory model in (4) as a prior 
an auxiliary (binary) dynamic random task variable rk  with the associated likelihood

P(rk = 1|xk  uk) = exp(cid:8)−(∆tCk(xk) + u⊤

k(H∆t)uk)(cid:9)  

(6)

2

u0

u1

u2

x0

x1

x2

. . .

xK

r0

r1

r2

rK

θ0

u0

x0

r0

θ1

u1

x1

r1

θ2

u2

x2

. . .

xK

r2

rK

(a)

(b)

Figure 1: The graphical models for (a) standard inference control and (b) the AICO-T model
with canonical time. Circle and square nodes indicate continous and discreet variables respectively.
Shaded nodes are observed.

is introduced  i.e.  we interpret the cost as a negative log likelihood of task fulﬁlment. Inference
control consists of computing the posterior conditioned on the observation r0:K = 1 within the
resulting model (illustrated as a graphical model in Fig. 1 (a))  and from it obtaining the maximum
a posteriori (MAP) controls. For cases  where the process and cost are linear and quadratic in u
respectively  the controls can be marginalised in closed form and one is left with the problem of
computing the posterior

P (x0:K|r0:K = 1) =Yk

N (xk+1|xk + F(xk)∆t  W∆t) exp(−∆tCk(xk))  

(7)

with W := Q + BH−1B⊤.
As this posterior is in general not tractable  the AICO [16] algorithm computes a Gaussian approxi-
mation to the true posterior using an approximate message passing approach similar in nature to EP
(details are given in supplementary material). The algorithm has been shown to have competitive
performance when compared to iLQG [16].

3 Temporal Optimization for Optimal Control

Often the state dependent cost term C(x  t) in (2) can be split into a set of costs which are incurred
only at speciﬁc times: also referred to as goals  and others which are independent of time  that is

C(x  t) = J (x) +

NXn=1

δt=ˆtnVn(x) .

(8)

Classically  ˆtn refer to real time and are ﬁxed. For instance  in a reaching movement  generally a cost
that is a function of the distance to the target is incurred only at the ﬁnal time T while collision costs
are independent of time and incurred throughout the movement. In order to allow the time point at
which the goals are achieved to be inﬂuenced by the optimization  we will re-frame the goal driven
part of the problem in a canonical time and in addition to optimizing the controls  also optimize the
mapping from canonical to real time.

Speciﬁcally  we introduce into the problem deﬁned by (1) & (2) the canonical time variable τ with
the associated mapping

τ = β(t) =Z t

0

1

θ(s)

ds  

θ(·) > 0  

(9)

with θ as an additional control. We also reformulate the cost in terms of the time τ as1

L(x(·)  u(·)  θ(·)) =

NXn=1

Vn(x(β−1(ˆτn))) +Z ˆτN

0

T (θ(s))ds

+Z β−1(ˆτN )

0

(cid:2)J (x(t)) + u(t)⊤Hu(t)(cid:3) dt  

(10)

1Note that as β is strictly monotonic and increasing  the inverse function β−1 exists

3

with T an additional cost term over the controls θ and the ˆτ1:N ∈ R assumed as given. Based on the
last assumption  we are still required to choose the time point at which individual goals are achieved
and how long the movement lasts; however  this is now done in terms of the canonical time and since
by controlling θ  we can change the real time point at which the cost is incurred  the exact choices
for ˆτ1:N are relatively unimportant. The real time behaviour is mainly speciﬁed by the additional
cost term T over the new controls θ which we have introduced. Note that in the special case where
0 T (θs)ds = T (T )  i.e.  T is equivalent to a cost on the total movement
duration. Although here we will stick to the linear case  the proposed approach is also applicable
to non-linear duration costs. We brieﬂy note the similarity of the formulation to the canonical time
formulation of [11] used in an imitation learning setting.

T is linear  we have R ˆτN

We now discretize the augmented system in canonical time with a ﬁxed number of steps K. Making
the arbitrary choice of a step length of 1 in τ induces  by (9)  a sequence of steps in t with length2
∆k = θk. Using this time step sequence and (4) we can now obtain a discreet process in terms of
the canonical time with an explicit dependence on θ0:K−1. Discretization of the cost in (10) gives

L(x1:K   u1:K   θ0:K−1) =

NXn=1

Vn(xˆkn

) +

K−1Xk=0 (cid:2)T (θk) + J (xk)θk + u⊤

kHθkuk(cid:3)  

(11)

for some given ˆk1:N . We now have a new formulation of the optimal control problem that no longer
of the form of equations (4) & (5)  e.g. (11) is no longer quadratic in the controls as θ is a control.

Proceeding as for standard inference control and treating the cost (11) as a neg-log likelihood of
an auxiliary binary dynamic random variable  we obtain the inference problem illustrated by the
Bayesian network in Figure 1(b). With controls u marginalised  our aim is now to ﬁnd the posterior
P(x0:K   θ0:K−1|r0:K = 1). Unfortunately  this problem is intractable even for the simplest case  e.g.
LQG with linear duration cost. However  observing that for given θk’s  the problem reduces to the
standard case of Section 2.1 suggest restricting ourselves to ﬁnding the MAP estimate for θ0:K−1 and
the associated posterior P(x0:K|θMAP
0:K−1  r0:K = 1) using an EM algorithm. The solution is obtained
by iterating the E- & M-Steps (see below) until the θ’s have converged; we call this algorithm AICO-
T to reﬂect the temporal aspect of the optimization.

3.1 E-Step

In general  the aim of the E-Step is to calculate the posterior over the unobserved variables  i.e. the
trajectories  given the current parameter values  i.e. the θi’s.

qi(x0:K) = P(x0:K |r0:K = 1  θi

0:K−1) .

(12)

However  as will be shown below we actually only require the expectations(cid:10)xkx⊤

during the M-Step. As these are in general not tractable  we compute a Gaussian approximation to
the posterior  following an approximate message passing approach with linear and quadratic approx-
imations to the dynamics and cost respectively [16] (for details  refer to supplementary material).

k(cid:11) and(cid:10)xkx⊤
k+1(cid:11)

3.2 M-Step

In the M-Step  we solve

with

θi+1
0:K−1 = argmax
θ0:K−1

Q(θ0:K−1|θi

0:K−1)  

(13)

Q(θ0:K−1|θi

0:K−1) = hlog P(x0:K   r0:K = 1|θ0:K−1)i

=

K−1Xk=0

K−1Xk=1

hlog P(xk+1|xk  θk)i −

[T (θk) + θk hJ (xk)i] + constant  

(14)
where h·i denotes the expectation with respect to the distribution calculated in the E-Step  i.e.  the
posterior qi(x0:K) over trajectories given the previous parameter values. The required expectations 

2under the assumption of constant θ(·) during each step

4

hJ (xk)i and

hlog P(xk+1|xk  θk)i = −

Dx
2

log |fWk| −

1

2D(xk+1 − eF(xk))⊤fW−1

k (xk+1 − eF(xk))E  

(15)

with eF(xk) = xk + F(xk)θk and fWk = θkW  are in general not tractable. Therefore  we take

approximations

F(xk) ≈ ak + Akxk

and J (xk) ≈

x⊤
kJkxk − j⊤

kxk  

(16)

1
2

choosing the mean of qi(xk) as the point of approximation  consistent with the equivalent approxi-
mations made in the E-Step. Under these approximations  it can be shown that  up to additive terms
independent of θ 

Q(θ0:K−1|θi

0:K−1) = −

2

1
2

(cid:20) Dx
K−1Xk=0
log |fWk| + T (θk) +
kfW−1
− Tr(eA′
k ˜ak + θk(cid:20) 1
kfW−1

k hxk+1x′

ki) +

Tr(Jk(cid:10)xkx⊤

k (cid:10)xk+1x′
Tr(fW−1
Tr(eAkfW−1
k eA′
k(cid:11) − jk hxki(cid:21)(cid:21)  

k hxkx′

˜a⊤

1
2

1
2

+

2

k+1(cid:11))

ki) + ˜a⊤

kfW−1

k eAk hxki

with ˜a⊤

=

θ−2

1
2
1

∂Q
∂θk

k = θkak  eAk = I + θkAk and taking partial derivatives leads to
k(cid:11) +(cid:10)xkx⊤

k Tr(cid:0)W−1((cid:10)xk+1x⊤
2(cid:20) Tr(AW−1A⊤(cid:10)xkx⊤
+ Tr(Jk(cid:10)xkx⊤

k+1(cid:11) − 2(cid:10)xk+1x⊤
dθ(cid:12)(cid:12)(cid:12)(cid:12)θk
k(cid:11)) + 2
k(cid:11)) − 2jk hxki(cid:21) .

+ a⊤

dT

−

k(cid:11))(cid:1) −

D2
x
2

θ−1
k

kW−1ak + 2a⊤

kW−1Ak hxki

(17)

In the general case  we can now use gradient ascent to improve the θ’s. However  in the speciﬁc
case where T is a linear function of θ  we note that 0 = ∂Q
and the unique
∂θk
extremum under the constraint θk > 0 can be found analytically.

is a quadratic in θ−1

k

3.3 Practical Remarks

The performance of the algorithm can be greatly enhanced by using the result of the previous E-
Step as initialisation for the next one. As this is likely to be near the optimum with the new temporal
trajectory  AICO converges within only a few iterations. Additionally  in practise it is often sufﬁcient
to restrict the θk’s between goals to be constant  which is easily achieved as Q is a sum over the θ’s.
The proposed algorithms leads to a variation of discretization step length which can be a problem.
For one  the approximation error increases with the step length which may lead to wrong results. On
the other hand  the algorithm may lead to control frequencies which are not achievable in practice.
In general  a ﬁxed control signal frequency may be prescribed by the hardware system. In practice 
θ’s can be kept in a prescribed range by adjusting the number of discretization steps K after an
M-Step.

Finally  although we have chosen to express the time cost in terms of a function of the θ’s  often it

may be desirable to consider a cost directly over the duration T . Noting that T = P θk  all that is

required is to replace dT

in (17).

dθ with ∂T (P θ)

∂θk

4 Experiments

The proposed algorithm was evaluated in simulation. As a basic plant  we used a kinematic simula-
tion of a 2 degrees of freedom (DOF) planar arm  consisting of two links of equal length. The state
of the plant is given by x = (q  ˙q)  with q ∈ R2 the joint angles and ˙q ∈ R2 associated angular

5

0.6

n
o
i
t
a
r
u
D

0.4

t
n
e
m
e
v
o
M

0.2

0

0.2

AICO-T(α = α0)
AICO-T(α = 2α)
AICO-T(α = 0.5α)

0.4

0.8
Task Space Movement Distance

0.6

300

200

100

t
s
o
C
g
n
i
h
c
a
e
R

0

0.2

AICO-T(α = α0)
AICO-T(α = 2α0)
AICO-T(α = 0.5α0)

0.4

0.8
Task Space Movement Distance

0.6

600

t
s
o
C
g
n
i
h
c
a
e
R

400

200

0

0.2

AICO (T = 0.07)
AICO (T = 0.24)
AICO (T = 0.41)
AICO-T(α = α0)

0.4

0.8
Task Space Movement Distance

0.6

(a)

(b)

(c)

Figure 2: Temporal scaling behaviour using AICO-T. (a & b) Effect of changing time-cost weight
α  (effectively the ratio between reaching cost and duration cost) on (a) duration and (b) reaching
cost (control + state cost). (c) Comparison of reaching costs (control + error cost) for AICO-T and
a ﬁxed duration approach  i.e. AICO.
velocities. The controls u ∈ R2 are the joint space accelerations. We also added some iid noise with
small diagonal covariance.

For all experiments  we used a quadratic control cost and the state dependent cost term:

V(xk) =Xi

δk=ˆki

(φi(xk) − y∗

i )⊤Λi(φi(xk) − y∗

i )  

(18)

for some given ˆki and employed a diagonal weight matrix Λi while y∗
i represented the desired state
in task space. For point targets  the task space mapping is φ(x) = (x  y  ˙x  ˙y)⊤  i.e.  the map from
x to the vector of end point positions and velocities in task space coordinates. The time cost was
linear  that is  T (θ) = αθ.

4.1 Variable Distance Reaching Task

In order to evaluate the behaviour of AICO-T we applied it to a reaching task with varying start-
target distance. Speciﬁcally  for a ﬁxed start point we considered a series of targets lying equally
spaced along a line in task space. It should be noted that although the targets are equally spaced
in task space and results are shown with respect to movement distance in task space  the distances
in joint space scale non linearly. The state cost (18) contained a single term incurred at the ﬁnal
discrete step with Λ = 106 · I and the control cost were given by H = 104 · I. Fig. 2(a & b) shows

the movement duration (=P θk) and standard reaching cost3 for different temporal-cost parameters

α (we used α0 = 2·107)  demonstrating that AICO-T successfully trades-off the movement duration
and standard reaching cost for varying movement distances. In Fig. 2(c)  we compare the reaching
costs of AICO-T with those obtained with a ﬁxed duration approach  in this case AICO. Note that
although with a ﬁxed  long duration (e.g.  AICO with duration T=0.41) the control and error costs
are reduced for short movements  these movements necessarily have up to 4× longer durations than
those obtained with AICO-T. For example for a movement distance of 0.2 application of AICO-T
results in a optimised movement duration of 0.07 (cf. Fig. 2(a))  making the ﬁxed time approach
impractical when temporal costs are considered. Choosing a short duration on the other hand (AICO
(T=0.07)) leads to signiﬁcantly worse costs for long movements. We further emphasis that the
ﬁxed durations used in this comparison were chosen post hoc by exploiting the durations suggested
by AICO-T in absence of this  there would have been no practical way of choosing them apart
from experimentation. Furthermore  we would like to highlight that  although the results suggests a
simple scaling of duration with movement distance  in cluttered environments and plants with more
complex forward kinematics  an efﬁcient decision on the movement duration cannot be based only
on task space distance.

4.2 Via Point Reaching Tasks

We also evaluated the proposed algorithm in a more complex via point task. The task requires the
end-effector to reach to a target  having passed at some point through a given second target  the

3n.b. the standard reaching cost is the sum of control costs and cost on the endpoint error  without taking

duration into account  i.e.  (11) without the T (θ) term.

6

−1.5

−2

]
d
a
r
[
2
t
n
i
o
J

e
l
g
n
A

−2.5

n
o
i
t
a
r
u
D

 
t
n
e
m
e
v
o
M

1.5

2

1

0.5

2.5

25

20

15

10

t
s
o
C
 
g
n
h
c
a
e
R

i

5

0

(c)

Near

Far

−0.2

−0.4

−0.6

]
d
a
r
[
1
t
n
i
o
J

e
l
g
n
A

−0.8

0

3.4

3.2

3

2.8

2.6

−0.4−0.2 0

0.2

(a)

1

Time

2

0

(b)

1

Time

2

0

Near

Far

Figure 3: Comparision of AICO-T (solid) to the common modelling approach  using AICO 
(dashed) with ﬁxed times on a via point task. (a) End point task space trajectories for two dif-
ferent via points (circles) obtained for a ﬁxed start point (triangle). (b) The corresponding joint
space trajectories. (c) Movement durations and reaching costs (control + error costs) from 10 ran-
dom start points. The proportion of the movement duration spend before the via point is shown in
light gray (mean in the AICO-T case).

via point. This task is of interest as it can be seen as an abstraction of a diverse range of complex
sequential tasks that requires one to achieve a series of sub-tasks in order to reach a ﬁnal goal. This
task has also seen some interest in the literature on modeling of human movement using the optimal
control framework  e.g.  [15]. Here the common approach is to choose the time point at which
one passes the via point such as to divide the movement duration in the same ratio as the distances
between the start point  via point and end target. This requires on the one hand prior knowledge of
these movement distances and on the other  makes the implicit assumption that the two movements
are in some sense independent.

In a ﬁrst experiment  we demonstrate the ability of our approach to solve such sequential problems 
adjusting movement durations between sub goals in a principled manner  and show that it improves
upon the standard modelling approach. Speciﬁcally  we apply AICO-T to the two via point problems
illustrated in Fig. 3(a) with randomised start states4. For comparison  we follow the standard mod-
eling approach and apply AICO to compute the controller. We again choose the movement duration
for the standard case post hoc to coincide with the mean movement duration obtained with AICO-T
for each of the individual via point tasks. Each task is expressed using a cost function consisting of
two point target cost terms. Speciﬁcally  (18) takes the form

V(xk) = δk= K

2

(φ(xk) − y∗

v)⊤Λv(φ(xk) − y∗

v) + δk=K(φ(xk) − y∗

e )⊤Λe(φ(xk) − y∗

e )  

(19)

v = (·  ·  0  0)⊤  y∗

with K the number of discrete steps and diagonal matrices Λv = diag(λpos  λpos  0  0)  Λe =
diag(λpos  λpos  λvel  λvel)  where λpos = 105 & λvel = 107 and vectors y∗
e =
(·  ·  0  0)⊤ desired states for individual via point and target  respectively. Note that the cost function
does not penalise velocity at the via point but encourages the stopping at the target. While admittedly
2 ) is likely to be a sub-
the choice of incurring the via point cost at the middle of the movement ( K
optimal choice for the standard approach  one has to consider that in more complex task spaces  the
relative ratio of movement distances may not be easily accessible and one may have to resort to the
most intuitive choice for the uninformed case as we have done here. Note that although for AICO-T
this cost is incurred at the same discrete step  we allow θ before and after the via point to differ  but
constrain them to be constant throughout each part of the movement  hence  allowing the cost to be
incurred at an arbitrary point in real time. We sampled the initial position of each joint independently
from a Gaussian distribution with a variance of 3◦. In Fig. 3(a&b)  we show maximum a posteriori
(MAP) trajectories in task space and joint space for controllers computed for the mean initial state.
Interestingly  although the end point trajectory for the near via point produced by AICO-T may
look sub-optimal than that produced by the standard AICO algorithm  closer examination of the
joint space trajectories reveal that our approach results in more efﬁcient actuation trajectories. In
Fig. 3(c)  we illustrate the resulting average movement durations and costs of the mean trajectories.
As can be seen  AICO-T results in the expected passing times for the two via points  i.e. early
vs. late in the movement for the near and far via point  respectively. This directly leads to a lower
incurred cost compared to un-optimised movement durations.

4For the sake of clarity  Fig. 3(a&b) show MAP trajectories of controllers computed for the mean start state.

7

]
d
a
r
[
1
t
n
i
o
J

e
l
g
n
A

−0.2

−0.4

−0.6

−0.8

−1

−1.2

3.4

3.2

3

2.8

2.6

0

0.2

0.4

0.6

(a)

−1.5

]
d
a
r
[
2

−2

t
n
i
o
J

e
l
g
n
A

−2.5

0

1
Time

2

0

1
Time

2

n
o
i
t
a
r
u
D

 
t
n
e
m
e
v
o
M

2.5

2

1.5

1

0.5

0

Joint Seq.

t
s
o
C
 
g
n
h
c
a
e
R

i

60

50

40

30

20

10

0

Joint Seq.

(b)

(c)

Figure 4:
Joint (solid) vs. sequential (dashed) optimisation using AICO-T for a sequential (via
point) task. (a) Task space trajectories for a ﬁxed start point (triangle). Viapoint and target are
indicated by the circle and square  respectively. (b) The corresponding joint space trajectories. (c)
The movement durations and reaching costs (control + error cost) for 10 random start points. The
mean proportion of the movement duration spend before the via point is shown in light gray.

In order to highlight the shortcomings of sequential time optimal control  next we compare plan-
ning a complete movement over sequential goals to planning a sequence of individual movements.
Speciﬁcally  using AICO-T  we compare planning the whole via point movement (joint planner) to
planning a movement from the start to the via point followed by a second movement from the end
point of the ﬁrst movement (n.b. not from the via point) to the end target (sequential planner). The
joint planner used the same cost function as the previous experiment. For the sequential planner 
each of the two sub-trajectories had half the number of discrete time steps of the joint planner and
the cost functions were given by appropriately splitting (19)  i.e. 

V 1(xk) = δk= K

2

(φ(xk)−y∗

v)⊤Λv(φ(xk)−y∗
v)

and V 2(xk) = δk= K

2

(φ(xk)−y∗

e)⊤Λe(φ(xk)−y∗

e)  

v  y∗

with Λv  Λe  y∗
e as for (19). The start states were sampled according to the distribution used in
the last experiment and in Fig. 4(a&b)  we plot the MAP trajectories for the mean start state  in task
as well as joint space. The results illustrate that sequential planning leads to sub-optimal results as
it does not take future goals into consideration. This leads directly to a higher cost (c.f. Fig. 4(c)) 
calculated from trials with randomised start state. One should however note that this effect would
be less pronounced if the cost required stopping at the via point  as it is the velocity away from the
end target which is the main problem for the sequential planner.

5 Conclusion

The contribution of this paper is a novel method for jointly optimizing a movement trajectory and
its time evolution (temporal scale and duration) in the stochastic optimal control framework. As a
special case  this solves the problem of an unknown goal horizon and the problem of trajectory op-
timization through via points when the timing of intermediate constraints is unknown and subject to
optimization. Both cases are of high relevance in practical robotic applications where pre-specifying
a goal horizon by hand is common practice but typically lacks justiﬁcation.

The method was derived in the form of an Expectation-Maximization algorithm where the E-step ad-
dresses the stochastic optimal control problem reformulated as an inference problem and the M-step
re-adapts the time evolution of the trajectory. In principle  the proposed framework can be applied
to extend any algorithm that – directly or indirectly – provides us with an approximate trajectory
posterior in each iteration. AICO [16] does so directly in terms of a Gaussian approximation; simi-
larly  the local LQG solution implicit in iLQG [9] can  with little extra computational cost  be used
to compute a Gaussian posterior over trajectories. For algorithms like DDP [6]  which do not lead to
an LQG approximation  we can employ the Laplace method to obtain Gaussian posteriors or adjust
the M-Step for the non-Gaussian posterior. We demonstrated the algorithm on a standard reaching
task with and without via points. In particular  in the via point case  it becomes obvious that ﬁxed
horizon methods and sequenced ﬁrst exit time methods cannot ﬁnd equally efﬁcient motions as the
proposed method.

8

References

[1] David Barber and Tom Furmston. Solving deterministic policy (PO)MDPs using expectation-
maximisation and antifreeze. In European Conference on Machine Learning (LEMIR work-
shop)  2009.

[2] Marc Peter Deisenroth  Carl Edward Rasmussen  and Jan Peters. Gaussian process dynamic

programming. Neurocomputing  72(7-9):1508 – 1524  2009.

[3] Yu-Yi Fu  Chia-Ju Wu  Kuo-Lan Su  and Chia-Nan Ko. A time-scaling method for near-time-
optimal control of an omni-directional robot along speciﬁed paths. Artiﬁcial Life and Robotics 
13(1):350–354  2008.

[4] Z Ghahramani and G Hinton. Parameter estimation for linear dynamical systems. Technical

Report CRG-TR-96-2  University of Toronto  1996.

[5] Z Ghahramani and S Roweis. Learning nonlinear dynamical systems using an em algorithm.

In Advances in Neural Information Processing Systems  volume 11  Nov 1999.
[6] D Jacobson and D Mayne. Differential Dynamic Programming. Elsevier  1970.
[7] Hilbert J. Kappen. A linear theory for control of non-linear stochastic systems. Physical

Review Letters  95(20):200201  2005.

[8] Donald E. Kirk. Optimal Control Theory - An Introduction. Prentice-Hall  1970.
[9] Weiwei Li and Emanuel Todorov. An iterative optimal control and estimation design for non-
linear stochastic system. In Proc. of the 45th IEEE Conference on Decision and Control  2006.
[10] Djordje Mitrovic  Sho Nagashima  Stefan Klanke  Takamitsu Matsubara  and Sethu Vijayaku-
mar. Optimal feedback control for anthropomorphic manipulators. In Proc. IEEE International
Conference on Robotics and Automation (ICRA 2010)  2010.

[11] Peter Pastor  Heiko Hoffmann  Tamim Asfour  and Stefan Schaal. Learning and generalization
of motor skills by learning from demonstration. In Proc. IEEE International Conference on
Robotics and Automation (ICRA 2010)  Feb 2010.

[12] Gideon Sahar and John M. Hollerbach. Planning of minimum- time trajectories for robot arms.

The International Journal of Robotics Research  5(3):90–100  1986.

[13] Robert F. Stengel. Optimal Control and Estimation. Dover Publications  1986.
[14] Emanuel Todorov. Compositionality of optimal control laws. In Advances in Neural Informa-

tion Processing Systems  volume 22  2009.

[15] Emanuel Todorov and Michael Jordan. Optimal feedback control as a theory of motor coordi-

nation. Nature Neuroscience  5(11):1226–1235  2002.

[16] Marc Toussaint. Robot trajectory optimization using approximate inference. In Proc. of the 26

th International Conference on Machine Learning (ICML 2009)  2009.

[17] Marc Toussaint and Amos Storkey. Probabilistic inference for solving discrete and continuous
state Markov Decision Processes. In Proc. of the 23nd Int. Conf. on Machine Learning (ICML
2006)  pages 945–952  2006.

9

,Yi Xu
Yan Yan
Qihang Lin
Tianbao Yang
Vincent Sitzmann
Michael Zollhoefer
Gordon Wetzstein