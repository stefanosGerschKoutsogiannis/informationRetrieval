2017,Learning spatiotemporal piecewise-geodesic trajectories from longitudinal manifold-valued data,We introduce a hierarchical model which allows to estimate a group-average piecewise-geodesic trajectory in the Riemannian space of measurements and individual variability. This model falls into the well defined mixed-effect models. The subject-specific trajectories are defined through spatial and temporal transformations of the group-average piecewise-geodesic path  component by component. Thus we can apply our model to a wide variety of situations. Due to the non-linearity of the model  we use the Stochastic Approximation Expectation-Maximization algorithm to estimate the model parameters. Experiments on synthetic data validate this choice. The model is then applied to the metastatic renal cancer chemotherapy monitoring: we run estimations on RECIST scores of treated patients and estimate the time they escape from the treatment. Experiments highlight the role of the different parameters on the response to treatment.,Learning spatiotemporal piecewise-geodesic

trajectories from longitudinal manifold-valued data

Juliette Chevallier

CMAP  École polytechnique

juliette.chevallier@polytechnique.edu

Pr Stéphane Oudard
Oncology Department
USPC  AP-HP  HEGP

Stéphanie Allassonnière

CRC  Université Paris Descartes

stephanie.allassonniere@parisdescartes.fr

Abstract

We introduce a hierarchical model which allows to estimate a group-average
piecewise-geodesic trajectory in the Riemannian space of measurements and in-
dividual variability. This model falls into the well deﬁned mixed-effect models.
The subject-speciﬁc trajectories are deﬁned through spatial and temporal trans-
formations of the group-average piecewise-geodesic path  component by compo-
nent. Thus we can apply our model to a wide variety of situations. Due to the
non-linearity of the model  we use the Stochastic Approximation Expectation-
Maximization algorithm to estimate the model parameters. Experiments on syn-
thetic data validate this choice. The model is then applied to the metastatic renal
cancer chemotherapy monitoring: we run estimations on RECIST scores of treated
patients and estimate the time they escape from the treatment. Experiments high-
light the role of the different parameters on the response to treatment.

1

Introduction

During the past few years  the way we treat renal metastatic cancer was profoundly changed: a new
class of anti-angiogenic therapies targeting the tumor vessels instead of the tumor cells has emerged
and drastically improved survival by a factor of three (Escudier et al.  2016). These new drugs 
however  do not cure the cancer  and only succeed in delaying the tumor growth  requiring the use of
successive therapies which must be continued or interrupted at the appropriate moment according to
the patient’s response. The new medicine process has also created a new scientiﬁc challenge: how
to choose the more efﬁcient drug therapy. This means that one has to properly understand how the
patient reacts to the possible treatments. Actually  there are several strategies and taking the right
decision is a contested issue (Rothermundt et al.  2015  2017).
To achieve that goal  physicians took an interest in mathematical modeling. Mathematics has already
demonstrated its efﬁciency and played a role in the change of stop-criteria for a given treatment
(Burotto et al.  2014). However  to the best of our knowledge  there only exists one model which
was designed by medical practitioners. Although  very basic mathematically  it seems to show that
this point of view may produce interesting results. Introduced by Stein et al. in 2008  the model
performs a non-linear regression using the least squares method to ﬁt an increasing or/and decreasing
exponential curve. This model is still used but suffers limitations. First  as the proﬁle are ﬁtted
individual-by-individual independently  the model cannot explain a global dynamic. Then  the choice
of exponential growth avoids the emergence of plateau effects which are often observed in practice.
This opens the way to new models which would explain both a population and each individual with
other constraints on the shape of the response.

31st Conference on Neural Information Processing Systems (NIPS 2017)  Long Beach  CA  USA.

Learning models of disease progression from such databases raises great methodological challenges.
We propose here a very generic model which can be adapted to a large number of situations. For a
given population  our model amounts to estimating an average trajectory in the set of measurements
and individual variability. Then we can deﬁne continuous subject-speciﬁc trajectories in view of the
population progression. Trajectories need to be registered in space and time  to allow anatomical
variability (as different tumor sizes)  different paces of progression and sensitivity to treatments. The
framework of mixed-effects models is well suited to deal with this hierarchical problem. Mixed-
effects models for longitudinal measurements were introduced in the seminal paper of Laird and Ware
(1982) and have been widely developed since then. The recent generic approach of Schiratti et al.
(2015) to align patients is even more suitable. First  anatomical data are naturally modeled as points on
Riemannian manifolds while the usual mixed-effects models are deﬁned for Euclidean data. Secondly 
the model was built with the aim of granting individual temporal and spatial variability through
individual variations of a common time-line grant and parallel shifting of the average trajectory.
However  Schiratti et al. (2015) have made a strong hypothesis to build their model as they consider
that the mean evolution is a geodesic. This would mean in our targeted situation that the cancer
would either go on evolving or is always sensitive to the treatment. Unfortunately  the anti-angiogenic
treatments may be inefﬁcient  efﬁcient or temporarily efﬁcient  leading to a re-progression of the
metastasis. Therefore  we want to relax this assumption on the model.
In this paper  we propose a generic statistical framework for the deﬁnition and estimation of spatiotem-
poral piecewise-geodesic trajectories from longitudinal manifold-valued data. Riemannian geometry
allows us to derive a method that makes few assumptions about the data and applications dealt with.
We ﬁrst introduce our model in its most generic formulation and then make it explicit for RECIST
(Therasse et al.  2000) score monitoring  i.e. for one-dimension manifolds. Experimental results
on those scores are given in section 4.2. The introduction of a more general model is a deliberate
choice as we are expecting to apply our model to the corresponding medical images. Because of
the non-linearity of the model  we have to use a stochastic version of the Expectation-Maximization
algorithm (Dempster et al.  1977)  namely the MCMC-SAEM algorithm  for which theoretical results
regarding the convergence have been proved in Delyon et al. (1999) and Allassonnière et al. (2010)
and numerical efﬁciency has been demonstrated for these types of models (Schiratti et al. (2015) 
MONOLIX – MOdèles NOn LInéaires à effets miXtes).

2 Mixed-effects model for piecewise-geodesically distributed data
We consider a longitudinal dataset obtained by repeating measurements of n ∈ N∗ individuals 

where each individual i ∈(cid:74)1  n(cid:75) is observed ki ∈ N∗ times  at the time points ti = (ti j)1(cid:54)j(cid:54)ki
denote k = (cid:80)n
and where yi = (yi j)1(cid:54)j(cid:54)ki denotes the sequence of observations for this individual. We also
i=1 ki the total numbers of observations. We assume that each observation yi j
is a point on a d-dimensional geodesically complete Riemannian manifold (M  g)  so that y =
(yi j)1(cid:54)i(cid:54)n  1(cid:54)j(cid:54)ki ∈ M k.
We generalize the idea of Schiratti et al. (2015) and build our model in a hierarchical way. We see
our data points as samples along trajectories and suppose that each individual trajectory derives
from a group-average scenario through spatiotemporal transformations. Key to our model is that the
group-average trajectory in no longer assumed to be geodesic but piecewise-geodesic.

2.1 Generic piecewise-geodesic curves model
R < . . . < tm−1

Let m ∈ N∗ and tR =(cid:0)−∞ < t1
up times sequence. Let M0 a d-dimensional geodesically complete manifold and(cid:0)¯γ(cid:96)

R < +∞(cid:1) a subdivision of R  called the breaking-

(cid:1)

1(cid:54)(cid:96)(cid:54)m a
family of geodesics on M0. To completely deﬁne our average trajectory  we introduce m isometries
0 : M0 → M (cid:96)
0 – by
φ(cid:96)
0 ensures that the manifolds
setting down γ(cid:96)
0 remains
M (cid:96)
parametrizable (Gallot et al.  2004). We deﬁne the average trajectory by

0(M0). This deﬁnes m new geodesics – on the corresponding space M (cid:96)
0 ◦ ¯γ0

0 remain Riemannian and that the curves γ(cid:96)

0 remain geodesic. In particular  each γ(cid:96)

(cid:96). The isometric nature of the mapping φ(cid:96)

0 := φ(cid:96)
0 = φ(cid:96)

0

∀t ∈ R 

γ0(t) = γ1

0 (t) 1

]−∞ t1

R](t) +

γ(cid:96)
0(t) 1

]t(cid:96)−1
R  t(cid:96)

R](t) + γm

0 (t) 1

]tm−1

 +∞[(t) .

R

m−1(cid:88)

(cid:96)=2

2

t1 ∈ R. We impose1 that for all (cid:96) ∈(cid:74)1  m − 1(cid:75)  ¯γ1

In this framework  M0 may be understood as a manifold-template of the geodesic components of the
curve γ0.
Because of the piecewise nature of our average-trajectory γ0  constraints have to be formulated on
each interval of the subdivision tR. Following the formulation of the local existence and uniqueness
theorem (Gallot et al.  2004)  constraints on geodesics are generally formulated by forcing a value
and a tangent vector at a given time-point. However  such an approach cannot ensure the curve γ0
to be at least continuous. That is why we re-formulate these constraints in our model as boundary
conditions. Let a sequence ¯A = ( ¯A0  . . .   ¯Am) ∈ (M0)m+1  an initial time t0 ∈ R and a ﬁnal time
R) = ¯A(cid:96) and
0 (t1) = ¯Am. Notably  the 2m constraints are deﬁned step by step. In one dimension (cf section
¯γm
2.2)  the geodesics could be written explicitly and such constraints do not complicate the model so
much. In higher dimension  we have to use shooting or matching methods to enforce this constraint.
In practice  the choice of the isometries φ(cid:96)
0 have to be done with the aim to be
"as regular as possible" (at least continuous as said above) at the rupture points t(cid:96)
R. In one dimension
for instance  we build trajectories that are continuous  not differentiable but with a very similar slope
on each side of the breaking-points.
We want the individual trajectories to represent a wide variety of behaviors and to derive from the
group average path by spatiotemporal transformations. To do that  we deﬁne for each component (cid:96) of
the piecewise-geodesic curve γ0 a couple of transformations (φ(cid:96)
i ). These transformations  namely
the diffeomorphic component deformations and the time component reparametrizations  characterize
respectively the spatial and the temporal variability of propagation among the population. Thus 
individual trajectories may write in the form of

0 and the geodesics ¯γ(cid:96)

R) = ¯A(cid:96)  ¯γ(cid:96)+1

0 (t0) = ¯A0  ¯γ(cid:96)

i   ψ(cid:96)

0(t(cid:96)

(t(cid:96)

0

∀t ∈ R 

γi(t) = γ1

i (t) 1

]−∞ t1

R i](t) +

γ(cid:96)
i (t) 1

]t(cid:96)−1
R i  t(cid:96)

R i](t) + γm

i (t) 1

]tm−1

R i

 +∞[(t)

((cid:63))

m−1(cid:88)

of rupture times tR i =(cid:0)t(cid:96)

(cid:96)=2
0 through the applications of the two transformations
i described below. Note that  in particular  each individual possesses his own sequence
. Moreover  we require the fewest constraints possible in the

where the functions γ(cid:96)
i and ψ(cid:96)
φ(cid:96)

i are obtained from γ(cid:96)

(cid:1)

R i

1(cid:54)(cid:96)<m

R for t1.

i (t(cid:96)

R i) = t(cid:96)

i (t) = α(cid:96)

i ) + t(cid:96)−1

R for t0 and tm

i (t − t(cid:96)−1

R − τ (cid:96)

R i and the time-warps to satisfy ψ(cid:96)

i ∈(cid:74)1  n(cid:75) and for the geodesic component (cid:96) ∈(cid:74)1  m(cid:75) by ψ(cid:96)

construction: at least continuity and control of the slopes at these breaking-up points.
For compactness  we will now abusively denote t0
To allow different paces in the progression and different breaking-up times for each individual 
i   called time-warp  that are deﬁned for the subject
we introduce some temporal transformations ψ(cid:96)
R . The
i correspond to the time-shift between the mean and the individual progression onset and
parameters τ (cid:96)
the α(cid:96)
i are the acceleration factors that describe the pace of individuals  being faster or slower than
the average. To ensure good adjunction at the rupture points  we demand the individual breaking-up
times t(cid:96)
R . Hence the subdivision
tR i is constrained by the time reparametrizations  which are also constrained. Only the acceleration
factors α(cid:96)
R i = t(cid:96)−1
t(cid:96)
Concerning the space variability  we introduce m diffeomorphic deformations φ(cid:96)
i which enable the
different components of the individual trajectories to vary more irrespectively of each other. We just
enforce the adjunction to be at least continuous and therefore the diffeomorphisms φ(cid:96)
i have to satisfy
i ◦ γ(cid:96)
i do not need to be isometric anymore  as
φ(cid:96)
the individual trajectories are no longer required to be geodesic.
Finally  for all i ∈ (cid:74)1  n(cid:75) and (cid:96) ∈ (cid:74)1  m(cid:75)  we set γ(cid:96)
i ◦ γ(cid:96)
i and deﬁne γi as in ((cid:63)). The
observations yi = (yi j) are assumed to be distributed along the curve γi and perturbed by an additive
Gaussian noise εi ∼ N (0  σ2Iki) :
∀(i  j) ∈(cid:74)1  n(cid:75) ×(cid:74)1  ki(cid:75) 

i are free: for all (cid:96) ∈(cid:74)1  m(cid:75)  the constraints rewrite step by step as
i = t(cid:96)−1

i and the ﬁrst time shift τ 1
and τ (cid:96)
R + τ (cid:96)

R). Note that the mappings φ(cid:96)

yi j = γi(ti j) + εi j where

εi j ∼ N (0  σ2) .

R i ) = t(cid:96)−1

R i − t(cid:96)−1
R .

R) = φ(cid:96)+1

R and ψ(cid:96)

i (t(cid:96)−1

0 ◦ ψ(cid:96)

◦ γ(cid:96)+1

i + t(cid:96)

i = φ(cid:96)

R−t(cid:96)−1

R

0(t(cid:96)

(t(cid:96)

α(cid:96)
i

0

i

1By deﬁning A(cid:96) = φ(cid:96)

0( ¯A(cid:96)) for each (cid:96) we can apply the constraints on γ(cid:96)

0 instead of ¯γ(cid:96)
0.

3

i will induce a large panel of piecewise-
The choice of the isometries φ(cid:96)
0 and the diffeomorphisms φ(cid:96)
geodesic models. For example  if m = 1  φ0 = Id and if φ1
i denotes the application that maps the
curve γ0 onto its parallel curve for a given non-zero tangent vector wi  we feature the model proposed
by Schiratti et al. (2015). In the following paragraph we propose another speciﬁc model which can be
used for chemotherapy monitoring for instance (see section 4.2).

2.2 Piecewise-logistic curve model

0

0

0

  γinit

0 − γescap

0 [ and ]γescap

(cid:1) x + γescap

(cid:1) x + γescap

0 : x (cid:55)→(cid:0)γﬁn

0 : x (cid:55)→(cid:0)γinit

We focus in the following on the case of piecewise-logistic model  which presents a real interest
regarding to our target application (cf section 4.2). We assume that m = 2 and d = 1 and we set
M0 = ]0  1[ equipped with the logistic metric. Given three real numbers γinit
0 we set
0 − γescap
0
down φ1
. Thus  we can map
and φ2
0
M0 onto the intervals ]γescap
  γﬁn
0 [ respectively: if ¯γ0 refers to the sigmoid function 
0 ◦ ¯γ0 will be a logistic curve  growing from γescap
φ1
0
In this way  there is essentially a single breaking-up time and we will denote it tR at the population
level and ti
R at the individual one. Moreover  due to our target applications  we force the ﬁrst logistic
to be decreasing and the second one increasing (this condition may be relaxed). Logistics are deﬁned
on open intervals  with asymptotic constraints. We want to formulate our constraints on some non-
inﬁnite time-points  as explained in the previous paragraph  we set a positive threshold ν close to zero
0 to be ν-near from their corresponding asymptotes. More precisely 
and demand the logistics γ1
we impose the average trajectory γ0 to be of the form γ0 = γ1
1]tR +∞[ where
0

1]−∞ tR] + γ2
0

0   γescap

0 and γ2

to γinit
0 .

and γﬁn

0

0

(cid:40)

0 + 2ν (cid:54) γinit
γescap
0 + 2ν (cid:54) γﬁn
γescap

0

0

0 : R → ]γescap
γ1
t (cid:55)→ γinit

  γinit
0 [
0 + γescap

0

0

e(at+b)

1 + e(at+b)
0 − ν  

0 (t0) = γinit
γ1

0 : R → ]γescap
γ2

0

  γﬁn
0 [
0 + γescap

0

t (cid:55)→ γﬁn

e−(ct+d)

1 + e−(ct+d)

and a  b  c and d are some positive numbers given by the following constraints

γ1
0 (tR) = γ2

0 (tR) = γescap

0 + ν

and γ2

0 (t1) = γﬁn

0 − ν .

ψ2
i (t) = α2

(cid:16) 1−α1

i (t− tR − τ 2

Moreover  for each individual i ∈(cid:74)1  n(cid:75)  the time-warps write ψ1
i (t − t0 − τ 1
amplitudes and rupture values: for each subject i ∈(cid:74)1  n(cid:75)  given the two scaling factors r1

In our context  the initial time of the process is known: it is the beginning of the treatment. So 
we assume that the average initial time t0 is equal to zero. Especially t0 is no longer a variable.
i ) + t0 and
(tR − t0). From now on  we note τi for τ 1
i .
i are chosen to allow different
i and r2
i (x − γ0(tR)) + γ0(tR) + δi  (cid:96) ∈ {1  2}. Other choices
i
and the space-shift δi  we deﬁne φ(cid:96)
are conceivable but in the context of our target applications  this one is appropriate. Mathematically 
any regular and injective function deﬁned on ]γescap

In the same way as the time-warp  the diffeomorphisms φ1

i ) + tR where τ 2

0 [ (respectively ]γescap

0 [) is suited.

i (t) = α1

i (x) = r(cid:96)

i and φ2

i = τ 1

  γinit

(cid:17)

  γﬁn

i +

α1
i

i

0

0

)
s
s
e
l
n
o
i
t
n
e
m
i
d
(

e
r
o
c
s
T
S
I
C
E
R

400

200

0

0

1 000

2 000

Times (in days)

(a) Diversity of individual trajectories.

γ0
γ1
γ2
γ3
γ4
γ5
γ6
γ7
t0 t1
tR

γi

γ0

0 −ν
γinit

0 −ν
γﬁn

r1
i

r2
i

γ

escap
0 +ν

δi

t0

ti
R

τi

ti
1

tR

t1

(b) From average to individual trajectory.

Figure 1: Model description. Figure 1a represents a typical average trajectory and several individual
ones  for different vectors Pi. The rupture times are represented by diamonds and the initial/ﬁnal
times by stars. Figure 1b illustrates the non-standard constraints for γ0 and the transition from the
average trajectory to an individual one: the trajectory γi is subject to a temporal and a spacial warp.
In other "words"  γi = φ1

0 ◦ ψ1

0 ◦ ψ2

i ◦ γ1

i ◦ γ2

]−∞ ti

1

1

i

i

R +∞[.
]ti

R] + φ2

4

To sum up  each individual trajectory γi depends on the average curve γ0 through ﬁxed effects

0   γescap

zpop = (cid:0)γinit
non-linear mixed-effects model. More precisely  for all (i  j) ∈(cid:74)1  n(cid:75) ×(cid:74)1  ki(cid:75) 

(cid:1) and random effects zi = (cid:0)α1
(cid:3) 1
(cid:0)γ2
i (ti j) − γ0(tR)(cid:1) + γ0(tR) + δi

(cid:0)γ1
i (ti j) − γ0(tR)(cid:1) + γ0(tR) + δi
+ (cid:2) r2

yi j = (cid:2) r1

(cid:3) 1

0   tR  t1

R](ti j)

i   τi  r1

]−∞ ti

i   α2

i   r2

  γﬁn

0

i

i

i   δi

(cid:1). This leads to a

R +∞[(ti j) + εi j
]ti

i + tR−t0

i ◦ γ1

i ◦ γ2

α1
i

0  γ2

i = φ2

i = φ1

0 and ti

R = t0 + τ 1

where γ1
. Figure 1 provides an illustration of the
model. On each subﬁgure  the bold black curve represents the average trajectory γ0 and the colour
curves several individual trajectories.
The acceleration and the scaling parameters have to be positive and equal to one on average while the
i = eξ(cid:96)
time and space shifts are of any signs and must be zero on average. For these reasons  we set α(cid:96)
and r(cid:96)
where Σ ∈ SpR  p = 6. This assumption is important in view of the applications. Usually  the
random effects are studied independently. Here  we are interested in correlations between the two
phases of patient’s response to treatment (see section 4.2).

i for (cid:96) ∈ {1  2} leading to Pi = t(cid:0) ξ1

(cid:1). We assume that Pi ∼ N (0  Σ)

i = eρ(cid:96)

i τi ρ1

i ξ2

i ρ2

i δi

i

3 Parameters estimation with the MCMC-SAEM algorithm

In this section  we explain how to use a stochastic version of the EM algorithm to produce maximum
a posteriori estimates of the parameters.

3.1 Statistical analysis of the piecewise-logistic curves model

We want to estimate (zpop  Σ  σ). The theoretical convergence of the EM algorithm  and a fortiori
of the SAEM algorithm (Delyon et al.  1999)  is proved only if the model belongs to the curved
exponential family. Moreover  for numerical performances this framework is important. Without
further hypothesis  the piecewise-logistic model does not satisfy this constraint. We proceed as in
Kuhn and Lavielle (2005): we assume that zpop is the realization of independent Gaussian random
variables with ﬁxed small variances and estimate the means of those variables. So  the parameters we
want to estimate are from now on θ =

(cid:16)

(cid:17)

  γﬁn

.

0   tR  t1  Σ  σ

0   γescap
γinit

0

The ﬁxed and random effects z = (zpop  zi)1(cid:54)i(cid:54)n are considered as latent variables. Our model write
in a hierarchical way as

y | z  θ ∼ n(cid:79)

ki(cid:79)

N(cid:0)γi(ti j)  σ2(cid:1)

i=1

j=1



n(cid:79)

0

i=1

  σ2

0   σ2

0   σ2

z | θ ∼ N (γinit

escap) ⊗ N (γﬁn

init) ⊗ N (γescap

ﬁn) ⊗ N (tR  σ2

R) ⊗ N (t1  σ2
1)

N (0  Σ)
where σinit  σescap  σﬁn  σR and σ1 are hyperparameters of the model. The product measures ⊗ mean
that the corresponding entries are considered to be independent in our model. Of course  it is not the
case for the observations which are obtained by repeating measurements for several individuals but
this assumption leads us to a more computationally tractable algorithm.
In this context  the EM algorithm is very efﬁcient to compute the maximum likelihood estimate of θ.
Due to the non-linearity of our model  a stochastic version of the EM algorithm is adopted  namely
the Stochastic Approximation Expectation-Maximization (SAEM) algorithm. As the conditional
distribution q(z|y  θ) is unknown  the Expectation step is replaced using a Monte-Carlo Markov
Chain (MCMC) sampling algorithm  leading to consider the MCMC-SAEM algorithm introduced in
Kuhn and Lavielle (2005) and Allassonnière et al. (2010). It alternates between a simulation step 
a stochastic approximation step and a maximization step until convergence. The simulation step is
achieved using a symmetric random walk Hasting-Metropolis within Gibbs sampler (Robert and
Casella  1999). See the supplementary material for details about algorithmics.
To ensure the existence of the maximum a posteriori (theorem 1)  we use a "partial" Bayesian
formalism  i.e. we assume the following prior

(Σ  σ) ∼ W−1 (V  mΣ) ⊗ W−1 (v  mσ) where V ∈ SpR  v  mΣ  mσ ∈ R

5

and W−1 (V  mΣ) denotes the inverse Wishart distribution with scale matrix V and degrees of
freedom mΣ. In order for the inverse Wishart to be non-degenerate  the degrees mΣ and mσ must
satisfy mΣ > 2p and mσ > 2. In practice  we yet use degenerate priors but with correct posteriors
.To be consistent with the one-dimension inverse Wishart distribution  we deﬁne the density function
of distribution of higher dimension as

(cid:1) (cid:32) (cid:112)|V |
2(cid:112)|Σ| exp

2

p

(cid:18)

(cid:0) mΣ

1

2

tr(cid:0)V Σ−1(cid:1)(cid:19)(cid:33)mΣ

− 1
2

fW−1(V mΣ)(Σ) =

Γp

where Γp is the multivariate gamma function. The maximization step is straightforward given the
sufﬁcient statistics of our exponential model: we update the parameters by taking a barycenter
between the corresponding sufﬁcient statistic and the prior. See the supplementary material for
explicit equations.

3.2 Existence of the Maximum a Posteriori

The next theorem ensures us that the model is well-posed and that the maximum we are looking for
through the MCMC-SAEM algorithm exists. Let Θ the space of admissible parameters :

(cid:17) ∈ R5 × SpR × R+(cid:12)(cid:12)(cid:12) Σ positive-deﬁnite

(cid:111)

.

Θ =

0   γescap
γinit

0

  γﬁn

0   tR  t1  Σ  σ

(cid:110) (cid:16)

Theorem 1 (Existence of the MAP). Given the piecewise-logistic model and the choice of
probability distributions for the parameters and latent variables of the model  for any dataset

(ti j  yi j)i∈(cid:74)1 n(cid:75)  j∈(cid:74)1 ki(cid:75)  there exist(cid:98)θM AP ∈ argmax

q(θ|y).

θ∈Θ

A detailed proof is postponed to the supplementary material.

4 Experimental results

The piecewise-logistic model has been designed for chemotherapy monitoring. More speciﬁcally 
we have met radiologists of the Hôpital Européen Georges-Pompidou (HEGP – Georges Pompidou
European Hospital) to design our model. In practice  patients suffer from the metastatic kidney cancer
and take a drug each day. Regularly  they come to the HEGP to check the tumor evolution. The
response to a given treatment has generally two distinct phases: ﬁrst  tumor’s size reduces; then  the
tumor grows again. A practical question is to quantify the correlation between both phases and to
determine as accurately as possible the individual rupture times ti
R which are related to an escape of
the patient’s response to treatment.

4.1 Synthetic data

In order to validate our model and numerical scheme  we ﬁrst run experiments on synthetic data.
We well understood that the covariance matrix Σ gives a lot of information on the health status of a
patient: pace and amplitude of tumor progression  individual rupture times. . . Therefore  we have to
pay special attention to the estimation of Σ in this paragraph.
An important point was to allow a lot of different individual behaviors. In our synthetic example 
Figure 1a illustrates this variability. From a single average trajectory (γ0 in bold plain line)  we can
generate individuals who are cured at the end (dot-dashed lines: γ3 and γ4)  some whose response to
the treatment is bad (dashed lines: γ5 and γ6)  some who only escape (no positive response to the
treatments – dotted lines: γ7). Likewise  we can generate "patients" with only positive responses or
no response at all. The case of individual 4 is interesting in practice: the tumor still grows but so
slowly that the growth is negligible  at least in the short-run.
Figure 2 illustrates the qualitative performance of the estimation. We are notably able to understand
various behaviors and ﬁt subjects which are far from the average path  such as the orange and the
green curves. We represent only ﬁve individuals but 200 subjects have been used to perform the
estimation.
To measure the inﬂuence of the sample size on our model/algorithm  we generate synthetic datasets
of various size and perform the estimation 50 times for each dataset. Means and standard deviations

6

200

100

)
s
s
e
l
n
o
i
t
n
e
m
i
d
(

e
r
o
c
s
T
S
I
C
E
R

0

0

200

100

)
s
s
e
l
n
o
i
t
n
e
m
i
d
(

e
r
o
c
s
T
S
I
C
E
R

0

0

500

1 000

Times (in days)

1 500

(b) After 600 iterations.

500

1 000

Times (in days)

1 500

(a) Initialisation.

Figure 2: Initialisation and "results". On both ﬁgures  the estimated trajectories are in plain lines and
the target curves in dashed lines. The (noisy) observations are represented by crosses. The average
path is in bold black line  the individuals in color. Figure 2a: Population parameters zpop and latent
variables zpop are initialized at the empirical mean of the observations; individual trajectories are
initialized on the average trajectory (P = 0  Σ = 0.1Ip  σ = 1). Figure 2b: After 600 iterations 
sometime less  the estimated curves ﬁt very well the observations. As the algorithm is stochastic 
estimated curves – and effectively the individuals – still wave around the target curves.

Table 1: Mean (standard deviation) of relative error (expressed as a percentage) for the population
parameters zpop and the residual standard deviation σ for 50 runs according to the sample size n.
Sample
size n
50
100
150

11.58 (1.64)
13.62 (1.31)
9.24 (1.63)

9.45 (5.40)
9.07 (5.19)
11.40 (5.72)

25.24 (12.84)
10.35 (3.96)
2.83 (2.31)

1.63 (1.46)
2.42 (1.50)
2.14 (1.17)

6.23 (2.25)
7.82 (2.43)
5.82 (2.55)

4.41 (0.75)
5.27 (0.60)
3.42 (0.71)

γescap
0

γinit
0

γﬁn
0

tR

t1

σ

0   γescap

0

  γﬁn

of the relative errors for the real parameters  namely γinit
0   tR  t1 and σ  are compiled
in Table 1. To compare things which are comparable  we have generated a dataset of size 200 and
shortened them to the desired size. Moreover  to put the algorithm on a more realistic situation  the
synthetic individual times are non-periodically spaced  individual sizes vary between 12 and 18 and
the observed values are noisy (σ = 3).
We remark that our algorithm is stable and that the bigger the sample size  the better we learn the
residual standard deviation σ. The parameters tR and γescap
are quite difﬁcult to learn as they occur
on the ﬂat section of the trajectory. However  the error we made is not crippling as the most important
for clinicians is the dynamic along both phases. As the algorithm enables to estimate both the mean
trajectory and the individual dynamic  it succeeds in estimating the inter-individual variability. This
ends in a good estimate of the covariance matrix Σ (see ﬁgure 4).

0

4.2 Chemotherapy monitoring: RECIST score of treated patients

We now run our estimation algorithm on real data from HEGP.
The RECIST (Response Evaluation Criteria In Solid Tumors) score (Therasse et al.  2000) measures
the tumoral growth and is a key indicator of the patient survival. We have performed the estimation
over a drove of 176 patients of the HEGP. There is an average of 7 visits per subjects (min: 3  max:
22)  with an average duration of 90 days between consecutive visits.
We have run the algorithm several times  with different proposal laws for the sampler (a Symmetric
Random Walk Hasting-Metropolis within Gibbs one) and different priors. We present here a run with
a low residual standard variation in respect to the amplitude of the trajectories and complexity of the
dataset: σ = 14.50 versus max(γinit
0 = 452.4. Figure 3a illustrates the performance of
the model on the ﬁrst eight patients. Although we cannot explain all the paths of progression  the
algorithm succeeds in ﬁtting various types of curves: from the yellow curve γ3 which is rather ﬂat
and only escape to the red γ7 which is spiky. From Figure 3b  it seems that the rupture times occur
early in the progression in average. Nevertheless   this result is to be considered with some reserve:
the rupture time generally occurs on a stable phase of the disease and the estimation may be difﬁcult.

0 ) − γescap

0   γﬁn

7

400

200

)
s
s
e
l
n
o
i
t
n
e
m
i
d
(

e
r
o
c
s
T
S
I
C
E
R

0

0

γ0
γ1
γ2
γ3
γ4
γ5
γ6
γ7
γ8

40

20

0

0

1 000

2 000

3 000

4 000

5 000

Individual rupture times (in days)

(b) Individual rupture times ti
R.

100

200
300
Times (in days)

400

500

(a) After 600 iterations.

Figure 3: RECIST score. We keep conventions of the previous ﬁgures. Figure 3a is the result of a 600
iterations run. We represent here only the ﬁrst 8 patients among the 176. Figure 3b is the histogram of
the rupture times ti
R for this run. In black bold line  the estimated average rupture time tR is a good
estimate of the average of the individual rupture times although there exists a large range of escape.

10

0

τ

t
f
i
h
s

e
m
T

i

→

t
e
s
n
o
t
s
a
L

t
e
s
n
o
y
l
r
a
E

←

−10
−4

−2
1st acceleration factor ξ1

←Slow response Fast response→

0

2

4

2

0

−5

Slowprogress→
nd accelerationfactorξ
← Fastprogress

5

2

(a) The time warp.

→

500

e
r
o
c
s
h
g
i
H

δ

t
f
i
h
s

e
c
a
p
S

e
r
o
c
s
w
o
L

←

Individual

rupture times ti
R

(in days)

4 000

2 000

0

0

−10
0
1st amplitude factor ρ1
←Low step High step→

(b) The space warp.

2

0

−5

nd amplitudefactorρ
Lowstep→
← Highstep

2

5

Figure 4: Individual random effects. Figure 4a: log-acceleration factors ξ1
shifts τi. Figure 4b: log-amplitude factors ρ1
corresponds to the individual rupture time ti

i against times
i and ρ2
i against space shifts δi. In both ﬁgure  the color
R. These estimations hold for the same run as Figure 3.

i and ξ2

In Figure 4  we plot the individual estimates of the random effects (obtained from the last iteration) in
comparison to the individual rupture times. Even though the parameters which lead the space warp 
i.e. ρ1
i and δi are correlated  the correlation with the rupture time is not clear. In other words  the
volume of the tumors seems to not be relevant to evaluate the escape of a patient. On the contrary 
which is logical  the time warp strongly impacts the rupture time.

i   ρ2

4.3 Discussion and perspective

We propose here a generic spatiotemporal model to analyze longitudinal manifold-valued measure-
ments. Contrary to Schiratti et al. (2015)  the average trajectory is not assumed to be geodesic
anymore. This allows us to apply our model to more complex situations: in chemotherapy monitoring
for example  where the patients are treated and tumors may respond  stabilize or progress during
the treatment  with different conducts for each phase. At the age of personalized medicine  to give
physicians decision support systems is really important. Therefore learning correlations between both
phases is crucial. This has been taken into account here.
For purpose of working with more complicated data  medical images for instance  we have ﬁrst
presented our model in a very generic version. Then we made it explicit for RECIST scores monitoring
and performed experiments on data from the HEGP. However  we have studied that dataset as if all
patients behave similarly  which is not true in practice. We believe that a possible amelioration of our
model is to put it into a mixture model.
Lastly  the SAEM algorithm is really sensitive to initial conditions. This phenomenon is emphasized
by the non-independence between the individual variables: actually  the average trajectory γ0 is not
exactly the trajectory of the average parameters. Fortunately  the more the sample size n increases 
the more γ0 draws closer to the trajectory of the average parameters.

8

Acknowledgments

Ce travail bénéﬁcie d’un ﬁnancement public Investissement d’avenir  reference ANR-11-LABX-
0056-LMH. This work was supported by a public grant as part of the Investissement d’avenir  project
reference ANR-11-LABX-0056-LMH.
Travail réalisé dans le cadre d’un projet ﬁnancé par la Fondation de la Recherche Médicale 
"DBI20131228564". Work performed as a part of a project funded by the Fondation of Medical
Research  grant number "DBI20131228564".

References
Stéphanie Allassonnière  Estelle Kuhn  and Alain Trouvé. Construction of bayesian deformable models via a

stochastic approximation algorithm: A convergence study. Bernoulli  16(3):641–678  08 2010.

Mauricio Burotto  Julia Wilkerson  Wilfred Stein  Motzer Robert  Susan Bates  and Tito Fojo. Continuing a
cancer treatment despite tumor growth may be valuable: Sunitinib in renal cell carcinoma as example. PLoS
ONE  9(5):e96316  2014.

Bernard Delyon  Marc Lavielle  and Eric Moulines. Convergence of a stochastic approximation version of the

em algorithm. The Annals of Statistics  27(1):94–128  1999.

Arthur Dempster  Nan M. Laird  and Donald B. Rubin. Maximum likelihood from incomplete data via the em

algorithm. Journal of the Royal Statistical Society. Series B (Methodological)  39(1):1–38  1977.

Bernard Escudier  Camillo Porta  Mélanie Schmidinger  Nathalie Rioux-Leclercq  Axel Bex  Vincent S. Khoo 
Viktor Gruenvald  and Alan Horwich. Renal cell carcinoma: Esmo clinical practice guidelines for diagnosis 
treatment and follow-up. Annals of Oncology  27(suppl 5):v58–v68  2016.

Sylvestre Gallot  Dominique Hulin  and Jacques Lafontaine. Riemannian Geometry. Universitext. Springer-

Verlag Berlin Heidelberg  3 edition  2004.

Estelle Kuhn and Marc Lavielle. Maximum likelihood estimation in nonlinear mixed effects models. Computa-

tional Statistics & Data Analysis  49(4):1020–1038  2005.

Nan M. Laird and James H. Ware. Random-effects models for longitudinal data. Biometrics  38(4):963–974 

1982.

Christian P. Robert and George Casella. Monte Carlo Statistical Methods. Springer Texts in Statistics. Springer-

Verlag New York  1999.

Christian Rothermundt  Alexandra Bailey  Linda Cerbone  Tim Eisen  Bernard Escudier  Silke Gillessen  Viktor
Grünwald  James Larkin  David McDermott  Jan Oldenburg  Camillo Porta  Brian Rini  Manuela Schmidinger 
Cora N. Sternberg  and Paul M. Putora. Algorithms in the ﬁrst-line treatment of metastatic clear cell renal
cell carcinoma – analysis using diagnostic nodes. The Oncologist  20(9):1028–1035  2015.

Christian Rothermundt  Joscha Von Rappard  Tim Eisen  Bernard Escudier  Viktor Grünwald  James Larkin 
David McDermott  Jan Oldenburg  Camillo Porta  Brian Rini  Manuela Schmidinger  Cora N. Sternberg 
and Paul M. Putora. Second-line treatment for metastatic clear cell renal cell cancer: experts’ consensus
algorithms. World Journal of Urology  35(4):641–648  2017.

Jean-Baptiste Schiratti  Stéphanie Allassonniere  Olivier Colliot  and Stanley Durrleman. Learning spatiotempo-
ral trajectories from manifold-valued longitudinal data. In Neural Information Processing Systems  number 28
in Advances in Neural Information Processing Systems. 2015.

Wilfred D. Stein  William Doug Figg  William Dahut  Aryeh D. Stein  Moshe B. Hoshen  Doug Price  Susan E.
Bates  and Tito Fojo. Tumor growth rates derived from data for patients in a clinical trial correlate strongly
with patient survival: A novel strategy for evaluation of clinical trial data. The Oncologist  13(10):1046–1054 
2008.

Patrick Therasse  Susan G. Arbuck  Elizabeth A. Eisenhauer  Jantien Wanders  Richard S. Kaplan  Larry
Rubinstein  Jaap Verweij  Martine Van Glabbeke  Allan T. van Oosterom  Michaele C. Christian  and Steve G.
Gwyther. New guidelines to evaluate the response to treatment in solid tumors. Journal of the National
Cancer Institute  92(3):205–216  2000.

9

,Stéphanie ALLASSONNIERE
Juliette Chevallier
Stephane Oudard