2019,Kalman Filter  Sensor Fusion  and Constrained Regression: Equivalences and Insights,The Kalman filter (KF) is one of the most widely used tools for data assimilation and sequential estimation. In this work  we show that the state estimates from the KF in a standard linear dynamical system setting are equivalent to those given by the KF in a transformed system  with infinite process noise (i.e.  a ``flat prior'') and an augmented measurement space. This reformulation---which we refer to as augmented measurement sensor fusion (SF)---is conceptually interesting  because the transformed system here is seemingly static (as there is effectively no process model)  but we can still capture the state dynamics inherent to the KF by folding the process model into the measurement space. Further  this reformulation of the KF turns out to be useful in settings in which past states are observed eventually (at some lag). Here  when the measurement noise covariance is estimated by the empirical covariance  we show that the state predictions from SF are equivalent to those from a regression of past states on past measurements  subject to particular linear constraints (reflecting the relationships encoded in the measurement map). This allows us to port standard ideas (say  regularization methods) in regression over to dynamical systems. For example  we can posit multiple candidate process models  fold all of them into the measurement model  transform to the regression perspective  and apply $\ell_1$ penalization to perform process model selection. We give various empirical demonstrations  and focus on an application to nowcasting the weekly incidence of influenza in the US.,Kalman Filter  Sensor Fusion  and Constrained

Regression: Equivalences and Insights

Maria Jahja

Department of Statistics

Carnegie Mellon University

Pittsburgh  PA 15213
maria@stat.cmu.edu

Roni Rosenfeld

Machine Learning Department
Carnegie Mellon University

Pittsburgh  PA 15213
roni@cs.cmu.edu

David Farrow

Computational Biology Department

Carnegie Mellon University

Pittsburgh  PA 15213
dfarrow0@gmail.com

Ryan J. Tibshirani

Department of Statistics

Machine Learning Department
Carnegie Mellon University

Pittsburgh  PA 15213

ryantibs@stat.cmu.edu

Abstract

The Kalman ﬁlter (KF) is one of the most widely used tools for data assimilation
and sequential estimation. In this work  we show that the state estimates from the
KF in a standard linear dynamical system setting are equivalent to those given by
the KF in a transformed system  with inﬁnite process noise (i.e.  a “ﬂat prior”)
and an augmented measurement space. This reformulation—which we refer to as
augmented measurement sensor fusion (SF)—is conceptually interesting  because
the transformed system here is seemingly static (as there is effectively no process
model)  but we can still capture the state dynamics inherent to the KF by folding
the process model into the measurement space. Further  this reformulation of the
KF turns out to be useful in settings in which past states are observed eventually
(at some lag). Here  when the measurement noise covariance is estimated by the
empirical covariance  we show that the state predictions from SF are equivalent to
those from a regression of past states on past measurements  subject to particular
linear constraints (reﬂecting the relationships encoded in the measurement map).
This allows us to port standard ideas (say  regularization methods) in regression
over to dynamical systems. For example  we can posit multiple candidate process
models  fold all of them into the measurement model  transform to the regression
perspective  and apply (cid:96)1 penalization to perform process model selection. We give
various empirical demonstrations  and focus on an application to nowcasting the
weekly incidence of inﬂuenza in the US.

Introduction

1
Let xt ∈ Rk  t = 1  2  3  . . . denote states and zt ∈ Rd  t = 1  2  3  . . . denote measurements evolving
according to the time-invariant linear dynamical system:

(1)
(2)
for t = 1  2  3  . . .. We assume the noise terms δt  t have mean zero and covariances Q ∈ Rk×k and
R ∈ Rd×d  respectively  for all t = 1  2  3  . . .. Also  we assume that the initial state x0 and all noise
terms are mutually independent. We call (1) the process model and (2) the measurement model.

xt = F xt−1 + δt 
zt = Hxt + t 

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

Kalman ﬁlter. The Kalman ﬁlter (KF) [Kalman  1960] is a method for sequential estimation in the
model (1)  (2). Given past estimates ˆx1  . . .   ˆxt and measurements z1  . . .   zt+1  we form an estimate
ˆxt+1 of the state xt+1 via

¯xt+1 = F ˆxt 
ˆxt+1 = ¯xt+1 + Kt+1(zt+1 − H ¯xt+1) 

¯Pt+1 = F PtF T + Q 
Kt+1 = ¯Pt+1H T (H ¯Pt+1H T + R)−1 
Pt+1 = (I − Kt+1H) ¯Pt+1.

(3)
(4)
where Kt+1 ∈ Rk×d is called the Kalman gain (at time t + 1). It is itself updated sequentially  via
(5)
(6)
(7)
where Pt+1 ∈ Rk×k denotes the state error covariance (at time t + 1). The step (3) is often called
the predict step: we form an intermediate estimate ¯xt+1 of the state based on the process model and
our estimate at the previous time point. The step (4) is often called the update step: we update our
estimate ˆxt+1 based on the measurement model and the measurement zt+1.
Under the data model (1)  (2) and the conditions on the noise stated above  the Kalman ﬁlter attains
the optimal mean squared error E(cid:107)ˆxt − xt(cid:107)2
2 among all linear unbiased ﬁlters  at each t = 1  2  3  . . ..
When the initial state x0 and all noise terms are Gaussian  the Kalman ﬁlter estimates exactly reduce
to the Bayes estimates ˆxt = E(xt|z1  . . .   zt)  t = 1  2  3  . . .. Numerous important extensions have
been proposed  e.g.  the ensemble Kalman ﬁlter (EnKF) [Evensen  1994  Houtekamer and Mitchell 
1998]  which approximates the noise process covariance Q by a sample covariance in an ensemble
of state predictions  as well as the extended Kalman ﬁlter (EKF) [Smith et al.  1962] and unscented
Kalman ﬁlter (UKF) [Julier and Uhlmann  1997]  which both allow for nonlinearities in the process
model. Particle ﬁltering (PF) [Gordon et al.  1993] has more recently become a popular approach for
modeling complex dynamics. PF adaptively approximates the posterior distribution  and in doing so 
avoids the linear and Gaussian assumptions inherent to the KF. This ﬂexibility comes at the cost of a
greater computational burden.
In this paper  we revisit the standard KF (3)  (4) and show that its estimates ˆxt+1  t = 0  1  2  . . . are
equivalent to those from the KF applied to a transformed system  with inﬁnite process noise and an
augmented measurement space. At ﬁrst glance  this is perhaps surprising  because the transformed
system effectively lacks a process model and is therefore seemingly static; however  it is able to take
the state dynamics into account as part of its measurement model. Importantly  this reformulation of
the KF leads us to derive a second  key reformulation for problems in which past states are observed
(at some lag). This second reformulation is the methodological crux of our paper: it is a constrained
regression approach for predicting states from measurements  motivated by (derived from) SF and the
KF. We illustrate its effectiveness in an application to nowcasting weekly inﬂuenza levels in the US.
If we let the noise covariance in the process model diverge to inﬁnity  Q → ∞1 

Sensor fusion.
then the Kalman ﬁlter estimate in (3)  (4) simpliﬁes to

ˆxt+1 = (H T R−1H)−1H T R−1zt+1.
(8)
This can be veriﬁed by rewriting the Kalman gain as Kt+1 = ( ¯P −1
t+1 + H T R−1H)−1H T R−1  and
t+1 → 0 as Q → ∞. Alternatively  we can verify this by specializing to the case of
observing that ¯P −1
Gaussian noise: as tr(Q) → ∞  we approach a ﬂat prior  and the Kalman ﬁlter (Bayes estimator)
just maximizes the likelihood of zt+1|xt+1. From the measurement model (2) (assuming Gaussian
noise)  this is a weighted regression of zt+1 on the measurement map H  precisely as in (8).
We will call (8) the sensor fusion (SF) estimate (at time t + 1).2 In this setting  we will also refer to
the measurements as sensors. As deﬁned  sensor fusion is a special case of the Kalman ﬁlter when
there is inﬁnite process noise; said differently  it is a special case of the Kalman ﬁlter when there is no
process model at all. Thus  looking at (8)  the state dynamics have apparently been completely lost.
Perhaps surprisingly  as we will show shortly  these dynamics can be exactly recovered by augmenting
the measurement vector zt+1 with the KF intermediate prediction ¯xt+1 = F ˆxt in (3) (and adjusting
the map H and covariance R appropriately). We summarize this and our other contributions next.

1To make this unambiguous  we may take  say  Q = aI and let a → ∞.
2 “Sensor fusion” is typically used as a generic term  similar to “data assimilation”; we use it to speciﬁcally
describe the estimate in (8) to distinguish it from the KF. This is useful when we describe equivalences  shortly.

2

Summary of contributions. An outline of our contributions in this paper is as follows.

1. We show in Section 2 that  if we take the KF intermediate prediction ¯xt+1 in (3)  append it
to the measurement vector zt+1  and perform SF (8) (with an appropriately adjusted H  R) 
then the result is exactly the KF estimate (4).

2. We show in Section 3 that  if we are in a problem setting in which past states are observed
(at some lag  which is the case in the ﬂu nowcasting application)  and we replace the noise
covariance R from the measurement model by the empirical covariance on past data  then
the sensor fusion estimate (8) can be written as ˆBT zt+1  where ˆB ∈ Rd×k is a matrix of
coefﬁcients that solves a regression problem of the states on the measurements (using past
data)  subject to the equality constraint H T ˆB = I.

3. We demonstrate the effectiveness of our new regression formulation of SF in Section 4 by
describing an application of this methodology to nowcasting the incidence of weekly ﬂu in
the US. This achieves state-of-the art performance in this problem.

4. We present in Section 5 some extensions of the regression formulation of SF; they do not
have direct equivalences to SF (or the KF)  but are intuitive and extend dynamical systems
modeling in new directions (e.g.  using (cid:96)1 penalization to perform a kind of process model
selection).

We make several remarks. The equivalences described in points 1–3 above are deterministic (they do
not require the modeling assumptions (1)  (2)  or any modeling assumptions whatsoever). Further 
even though their proofs are elementary (they are purely linear algebraic) and the setting is a classical
one (linear dynamical systems)  these equivalences are—as far as we can tell—new results. They
deserve to be widely known and may have implications beyond what is explored in this paper.
For example  the regression formulation of SF may still be a useful perspective for problems in which
past states are fully unobserved (this being the case in most KF applications). In such problems 
we may consider using smoothed estimates of past states  obtained by running a backward version
of the KF forward recursions (3)–(7) (see  e.g.  Chapter 7 of Anderson and Moore [1979])  for the
purposes of the regression formulation. As another example  the SF view of the KF may be a useful
formulation for the purposes of estimating the covariances R  Q  or the maps F  H  or all of them;
in this paper  we assume that F  H  R  Q are known (except for in the regression formulation of SF 
in which R is unknown but past states are available); in general  there are well-developed methods
for estimating F  H  R  Q such as subspace identiﬁcation algorithms (see  e.g.  Overshee and Moor
[1996])  and it may be interesting to see if the SF perspective offers any advantages here.

Related work. The Kalman ﬁlter and its extensions  as previously referenced (EnKF  EKF  UKF) 
are the de facto standard in state estimation and tracking problems; the literature surrounding them
is enormous and we cannot give a thorough treatment. Various authors have pointed out the simple
fact that maximum likelihood estimate in (8)  which we call sensor fusion  is the limit of the KF as
the noise covariance in the process model approaches inﬁnity (see  e.g.  Chapter 5.9 of Brown and
Hwang [2012]). We have not  however  seen any authors note that this static model can recover the
KF by augmenting the measurement vector with the KF intermediate prediction (Theorem 1).
Along the lines of our second equivalence (Theorem 2)  there is older work in the statistical calibration
literature that studies the relationships between the regressions of y on x and x on y (for multivariate
x  y  see Brown [1982]). This is somewhat related to our result  since we show that a backwards or
indirect approach  which models zt+1|xt+1  is actually equivalent to a forwards or direct approach 
which predicts xt+1 from zt+1 via regression. However  the details are quite different.
Finally  our SF methodology in the ﬂu nowcasting application blends together individual predictors
in a way that resembles linear stacking [Wolpert  1992  Breiman  1996]. In fact  one implication of
our choice of measurement map H in the ﬂu nowcasting problem  as well as the constraints in our
regression formulation of SF  is that all regression weights must sum to 1  which is the standard in
linear stacking as well. However  the equality constraints in our regression formulation are quite a bit
more complex  and reﬂect aspects of the sensor hierarchy that linear stacking would not.

3

2 Equivalence between KF and SF

As already discussed  the sensor fusion estimate (8) is a limiting case of the Kalman ﬁlter (3)  (4)  and
initially  it seems  one rather limited in scope: there is effectively no process model (as we have sent
the process variance to inﬁnity). However  as we show next  the KF is actually itself a special case of
SF  when we augment the measurement vector by the KF intermediate predictions  and appropriately
adjust the measurement map H and noise covariance R. The proof is elementary  a consequence of
the Woodbury matrix and related manipulations. It is given in the supplement.
Theorem 1. At each time t = 0  1  2  . . .  suppose we augment our measurement vector by deﬁning
˜zt+1 = (zt+1  ¯xt+1) ∈ Rd+k  where ¯xt+1 = F ˆxt is the KF intermediate prediction at time t + 1.
Suppose that we also augment our measurement map by deﬁning ˜H ∈ R(d+k)×k to be the rowwise
concatenation of H and the identity matrix I ∈ Rk×k. Furthermore  suppose we deﬁne an augmented
measurement noise covariance

˜Rt+1 =

 

(9)

(cid:20)R

0

(cid:21)

0

¯Pt+1

where ¯Pt+1 is the KF intermediate error covariance at time t + 1 (as in (5)). Then applying SF to
the augmented system produces an estimate at t + 1 that equals the KF estimate 
t+1 ˜zt+1 = ¯xt+1 + Kt+1(zt+1 − H ¯xt+1) 

˜H)−1 ˜H T ˜R−1

( ˜H T ˜R−1

(10)

t+1

where Kt+1 is the Kalman gain at t + 1 (as in (6)).
Remark 1. We can think of the last state estimate ˆxt in the theorem (which is propagated forward
via ¯xt+1 = F ˆxt) as the previous output from SF itself  when applied to the appropriate augmented
system. More precisely  by induction  Theorem 1 says that iteratively applying SF to ˜zt+1  ˜H  ˜Rt+1
across times t = 0  1  2  . . .  where each ¯xt+1 = F ˆxt is the intermediate prediction using the last SF
estimate ˆxt  produces a sequence ˆxt+1  t = 0  1  2  . . . that matches the state estimates from the KF.
Remark 2. The result in Theorem 1 can be seen from a Bayesian perspective  as was pointed out by
an anonymous reviewer. When the initial state x0 and all noise terms in (1)  (2) are Gaussian  recall
the KF reduces to the Bayes estimator. Here the posterior is the product of a Gaussian likelihood and
Gaussian prior  and is thus itself Gaussian. (The proof of this standard fact uses similar arguments
to the proof of Theorem 1.) Meanwhile  in augmented SF  we can view the Gaussian likelihood
being maximized as the product of the Gaussian density of zt+1 and that of ¯xt+1. This matches the
posterior used by the KF  where the density of ¯xt+1 plays the role of the prior in the KF. Therefore in
each case  we are deﬁning our estimate to be the mean of the same Gaussian distribution.
Remark 3. The equivalence between SF and KF can be extended beyond the case of linear process
and linear measurement models. Given a nonlinear process map f and a nonlinear process model h 
suppose we deﬁne ¯xt+1 = f (ˆxt)  Ft+1 = Df (ˆxt) (the Jacobian of f at ˆxt)  and Ht+1 = Dh(¯xt+1)
(the Jacobian of h at ¯xt+1). Suppose we deﬁne the augmented measurement vector as

˜zt+1 =(cid:0)zt+1 + Ht+1 ¯xt+1 − h(¯xt+1)  ¯xt+1

(11)
where we have offset the measurement zt+1 by the residual Ht+1 ¯xt+1 − h(¯xt+1) from linearization.
Suppose  as in the theorem  we deﬁne the augmented measurement map ˜Ht+1 ∈ R(d+k)×k to be the
rowwise concatenation of Ht+1 and I ∈ Rk×k  and deﬁne ˜Rt+1 ∈ R(d+k)×(d+k) as in (9)  for ¯Pt+1
as in (5)  but with Ft+1  Ht+1 in place of F  H. In the supplement  we prove that

(cid:1) 

(cid:0)zt+1 − h(¯xt+1)(cid:1) 

(12)

( ˜H T

t+1

˜R−1

t+1

˜Ht+1)−1 ˜H T

t+1

˜R−1
t+1 ˜zt+1 = ¯xt+1 + Kt+1

where Kt+1 is as in (6)  but with Ft+1  Ht+1 in place of F  H. The right-hand side above is precisely
the extended KF (EKF). The left-hand side is what we might call extended SF (ESF).

3 Equivalence between SF and regression

Suppose that in our linear dynamical system  at each time t  we observe the measurement zt  make a
prediction ˆxt for xt  then later observe the state xt itself. (This setup indeed describes the inﬂuenza
nowcasting problem  a central motivating example that we will describe shortly.) In such problems 
we can estimate R using the empirical covariance on past data. When we plug this into (8)  it turns
out SF reduces to a prediction from a constrained regression of past states on past measurements.

4

3.1 Equivalent regression problem

In making a prediction at time t + 1  we assume in this section that we observe past states. We may
assume without a loss of generality that we observe the full past xi  i = 1  . . .   t (if this is not the
case  and we observe only some subset of the past  then the only changes to make in what follows are
notational). Assuming the measurement noise covariance R is unknown  we may use

t(cid:88)

i=1

ˆRt+1 =

1
t

(zi − Hxi)(zi − Hxi)T  

(13)

(14)

the empirical (uncentered) covariance based on past data  as an estimate. Under this choice  it turns
out that sensor fusion (8) is exactly equivalent to a regression of states on measurements  subject to
certain equality constraints. The proof is elementary  but requires detailed arguments. It is deferred
until the supplement.
Theorem 2. Let ˆRt+1 be as in (13) (assumed to be invertible). Consider the SF prediction at time
t + 1  with ˆRt+1 in place of R. Denote this by ˆxt+1 = ˆBT zt+1  where

(and H T ˆR−1

t+1H is assumed invertible). Each column of ˆB  denoted ˆbj ∈ Rd  j = 1  . . .   k  solves

ˆBT = (H T ˆR−1

t+1

t+1H)−1H T ˆR−1
t(cid:88)

(xij − bT

j zi)2

minimize

bj∈Rd

i=1

subject to H T bj = ej 

where ej ∈ Rd is the jth standard basis vector (all 0s except for a 1 in the jth component).
Remark 4. As discussed in the introduction  the interpretation of (H T ˆR−1
t+1H)−1H T ˆR−1
t+1zt+1 as
the coefﬁcients from regressing zt+1(the response) onto H (the covariates) is more or less immediate.
Interpreting the same quantity as ˆBT zt+1 = (ˆbT
k zt+1)  the predictions from historically
regressing xi  i = 1  . . .   t (the response) onto zi  i = 1  . . .   t (the covariates)  however  is much less
obvious. The latter is a forwards or direct regression approach to predicting xt+1  whereas SF was
originally deﬁned via the backwards or indirect perspective inherent to the measurement model (2).

1 zt+1  . . .   ˆbT

3.2

Inﬂuenza nowcasting

An example that we will revisit frequently  for the rest of the paper  is the following inﬂuenza (or ﬂu)
nowcasting problem. The state variable of interest is the weekly percentage of weighted inﬂuenza-like
illness (wILI)  a measure of ﬂu incidence provided by the Centers for Disease Control and Prevention
(CDC)  in each of the k = 51 US states (including DC). Because it takes time for the CDC to collect
and compile this data  they release wILI values with a 1 week delay. Meanwhile  various proxies for
the ﬂu (i.e.  data sources that are potentially correlated with ﬂu incidence) are available in real time 
e.g.  web search volume for ﬂu-related terms  site trafﬁc metrics for ﬂu-related pages  pharmaceutical
sales for ﬂu-related products  etc. We can hence train (using historical data) sensors to predict wILI 
one from each data source  and plug them into sensor fusion (8) in order to “nowcast” the current ﬂu
incidence (that would otherwise remain unknown for another week).
Such a sensor fusion system for ﬂu nowcasting  using d = 308 sensors (ﬂu proxies)  is described in
Chapter 4 of Farrow [2016]3. In addition to the surveillance sensors described above (search volume
for ﬂu terms  site trafﬁc metrics for ﬂu pages  etc.)  the measurement vector in this nowcasting system
also uses a sensor that is trained to make predictions of wILI using a seasonal autoregression with
3 lags (SAR3). From the KF-SF equivalence established in Section 2  we can think of this SAR3
sensor as serving the role of something like a process model  in the underlying dynamical system.
While wILI itself is available at the US state level  the data source used to train each sensor may only
be available at coarser geographic resolution. Thus  importantly  each sensor outputs a prediction at a
different geographic resolution (which reﬂects the resolution of its corresponding data source). As an

3This is more than just a hypothetical system; it is fully operational  and run by the Carnegie Mellon DELPHI
group to provide real-time nowcasts of ﬂu incidence every week  in all US states  plus select regions  cities  and
territories. (See https://delphi.midas.cs.cmu.edu).

5

Figure 1: Simpliﬁed version of the ﬂu nowcasting
problem  with k = 5 states and d = 8 sensors. We
have a 3-level hierarchy  where x1  x2  x3 are part
of the ﬁrst region and x4  x5 are part of the second.
The national level is at the root. As for the sensors 
we have one at each state  one at each region  and
one at the national level. Assuming all states have
equal populations  the sensor map H is



H =

 .

1
0
0
0
0
1/3
0
1/5

0
1
0
0
0
1/3
0
1/5

0
0
1
0
0
1/3
0
1/5

0
0
0
1
0
0
1/2
1/5

0
0
0
0
1
0
1/2
1/5

example  the number of visits to ﬂu-related CDC pages are available for each US state separately; so
for each US state  we train a separate sensor to predict wILI from CDC site trafﬁc. However  counts
for Wikipedia page visits are only available nationally; so we train just one sensor to predict national
wILI from Wikipedia page visits.
Assuming unbiasedness of all the sensors  we construct the map H in (2) so that its rows reﬂect the
geography of the sensors. For example  if a sensor is trained on data that is available at the ith US
state  then its associated row in H is

(0  . . . 1↑

  . . . 0);

i

and if a sensor is trained on data from the aggregate of the ﬁrst 3 US states  then its associated row is

for weights w1  w2  w3 > 0 such that w1 + w2 + w3 = 1  based on relative state populations; and so
on. Figure 1 illustrates the setup in a simple example.

(w1  w2  w3  0  . . . 0) 

3.3

Interpreting the constraints

At a high-level  the constraints in (14) encode information about the measurement model (2). They
also provide some kind of implicit regularization. Interestingly  as we will see later in Section 4  this
can still be useful when used in addition to more typical (explicit) regularization.
How can we interpret these constraints? We give three interpretations  the ﬁrst one speciﬁc to the ﬂu
forecasting setting  and the next two general.

Flu interpretation.
In the ﬂu nowcasting problem  recall  the map H has rows that sum to 1  and
they reﬂect the geographic level at which the corresponding sensors were trained (see Section 3.2).
The constraints H T bj = ej  j = 1  . . .   k can be seen in this case as a mechanism that accounts for
the geographical hierachy underlying the sensors. As a concrete example  consider the simpliﬁed
setup in Figure 1  and j = 3. The constraint H T b3 = e3 reads:
b31 + 1/3 b36 + 1/5 b38 = 0 
b32 + 1/3 b36 + 1/5 b38 = 0 
b33 + 1/3 b36 + 1/5 b38 = 1 
b34 + 1/3 b37 + 1/5 b38 = 0 
b35 + 1/3 b37 + 1/5 b38 = 0.

The third line can be interpreted as follows: an increase of 1 unit in sensor z3  1/3 units in z6  and
1/5 units in z8  holding all other sensors ﬁxed  should lead to an increase in 1 unit of our prediction
for x3. This is a natural consequence of the hierarchy in the sensor model (2)  visualized in Figure 1.
The ﬁrst line can be read as: an increase of 1 unit in sensor z1  1/3 units in z6  and 1/5 in z8  with
all others ﬁxed  should not change our prediction for x3. This is also natural  following from the
hierachy (i.e.  such a change must have been propogated by x1). The other lines are similar.

6

Invariance interpretation. The SF prediction (at time t + 1) is ˆxt+1 = ˆBT zt+1. To denoise (i.e. 
estimate the mean of) the measurement zt+1  based on the model (2)  we could use ˆzt+1 = H ˆxt+1.
Given the denoised ˆzt+1  we could then reﬁt our state prediction via ˜xt+1 = ˆBT ˆzt+1. But due to
the constraint H T ˆB = I (a compact way of expressing H T ˆbj = ej  for j = 1  . . .   k)  it holds that
˜xt+1 = ˆBT H ˆxt+1 = ˆxt+1. This is a kind of invariance property. In other words  we can go from
estimating states  to reﬁtting measurements  to reﬁtting states  etc.  and in this process  our state
estimates will not change.
Generative interpretation. Assume t ≥ k  and ﬁx an arbitrary j = 1  . . .   k as well as bj ∈ Rk.
The constraint H T bj = ej implies  by taking an inner product on both sides with xi  i = 1  . . .   k 

(Hxi)T bj = xij 

i = 1  . . .   k.

If we assume xi  i = 1  . . .   k are linearly independent  then the above linear equalities are not only
implied by H T bj = ej  they are actually equivalent to it. Invoking the model (2)  we may rewrite the
constraint H T bj = ej as

(15)
In the context of problem (14)  this is a statement about a generative model for the data (as zi|xi
describes the distribution of the covariates conditional on the response). The representation in (15)
shows that (14) constrains the regression estimator to have the correct conditional predictions  on
average  on the data we have already seen (xi  zi)  i = 1  . . .   k. (Note here we did not have to use
the ﬁrst k time points; any past k time points would sufﬁce.)

i = 1  . . .   k.

E(bT

j zi|xi) = xij 

3.4 Modiﬁcations and equivalences

In the supplement  we show that two modiﬁcations of the basic SF formulation also have equivalences
in the regression perspective: namely  shrinking the empirical covariance in (13) towards the identity
is equivalent to adding a ridge (squared (cid:96)2) penalty to the criterion in (14); and also  adding a null
sensor at each state (one that always outputs 0) is equivalent to removing the constraints in (14). The
latter equivalence here provides indirect but fairly compelling evidence that the constraints in the
regression formulation (14) play an important role (under the model (2)): it says that removing them
is equivalent to including meaningless null sensors  which intuitively should worsen its predictions.

4 Flu nowcasting application

Experimental setup. We examine the performance of our methods for nowcasting (one-week-
ahead prediction of) wILI across 5 ﬂu seasons  from 2013 to 2018 (total of 140 weeks). Recall the
setup described in Section 3.2  with k = 51 states and d = 308 measurements. At week t + 1  we
derive an estimate ˆxt+1 of the current wILI in the 51 US states  based on sensors zt+1 (each sensor
being the output of an algorithm trained to predict wILI at a different geographic resolution from a
given data source)  and past wILI and sensor data. We consider 7 methods for computing the nowcast
ˆxt+1: (i) SF  or equivalently  constrained regression (14); (ii) SF as in (14)  but with an additional
ridge (squared (cid:96)2) penalty (equivalently  SF with covariance shrinkage); (iii) SF as in (14)  but with
an additional lasso ((cid:96)1) penalty; (iv/v) regression as in (14)  but without constraints  and using a
ridge/lasso penalty; (vi) random forests (RF) [Breiman  2001]  trained on all of the sensors; (vii) RF 
but trained on all of the underlying data sources used to ﬁt the sensors.
At prediction week t + 1  we use the last 3 years (weeks t − 155 through t) as the training set for all
7 methods. We do not implement unpenalized regression (as in (14)  but without constraints)  as it
is not well-deﬁned (156 observations and 308 covariates).4 All ridge and lasso tuning parameters
are chosen by optimizing one-week-ahead prediction error over the latest 10 weeks of data (akin to
cross-validation  but for a time series context like ours). Python code for this nowcasting experiment
is available at http://github.com/mariajahja/kf-sf-flu-nowcasting.

4SF is still well-deﬁned  due of the constraint in (14): a nonunique solution only occurs when the (random)
null space of the covariate matrix has a nontrivial intersection with the null space of H T   which essentially never
happens.

7

Figure 2: Top row  from left to right: data sources  sensors  and nowcasts are compared to the underlying wILI
values for Pennsylvania during ﬂu season 2017-18. For visualization purposes  the sources are scaled to ﬁt the
range of wILI. On the rightmost plot  we display nowcasts using select methods. Bottom row: MAEs (full colors)
and MADs (light colors) of nowcasts over 5 ﬂu seasons from 2013-14 to 2017-18.

Missing data. Unfortunately  sensors are observed at not only varying geographic resolutions  but
also varying temporal resolutions (since their underlying data sources are)  and missing values occur.
In our experiments  we choose to compute predictions using the regression perspective  and apply a
simple mean imputation approach (using only past sensor data)  before ﬁtting all models.

Nowcasting results. The bottom row of Figure 2 displays the mean absolute errors (MAEs) from
one-week-ahead predictions by the 7 methods considered  averaged over the 51 US states  for each
of the 5 seasons. Also displayed are the mean absolute deviations (MADs)  in light colors. We see
that SF with ridge regularization is generally the most accurate over the 5 seasons  SF with lasso
regularization is a close second  and SF without any regularization is the worst. Thus  clearly  explicit
regularization helps. Importantly  we also see that the constraints in the regression problem (14)
(which come from its connection to SF) play a key role: in each season  SF with ridge regularization
outperforms ridge regression  and SF with lasso regularization outperforms the lasso. Therefore  the
constraints provide additional (beneﬁcial) implicit regularization.
RF trained on sensors performs somewhat competitively. RF trained on sources is more variable (in
some seasons  much worse than RF on sensors). This observation indicates that training the sensors
is an important step for nowcasting accuracy  as this can be seen as a form of denoising  and suggests
a view of all the methods we consider here (except RF on sources) as prediction assimilators (rather
than data assimilators). Finally  the top row Figure 2 visualizes the nowcasts for Pennsylvania in the
2017-18 season. We can see that SF  RF (on sensors)  and even ridge regression are noticeably more
volatile than SF with ridge regularization.

5 Discussion and extensions

In this paper  we studied connections between the Kalman ﬁlter  sensor fusion  and regression. We
derived equivalences between the ﬁrst two and latter two  discussed the general implications of our
results  and studied the application of our work to nowcasting the weekly inﬂuenza levels in the US.
We conclude with some ideas for extending the constrained regression formulation (14) of SF.

8

DecJanFebMarAprMay1234567wILIwILISourcesDecJanFebMarAprMay1234567wILISensorsDecJanFebMarAprMay1234567wILISF + L2RidgeSFRF (sensors)2013-142014-152015-162016-172017-18Season0.00.20.40.60.81.01.21.4Mean Absolute ErrorSF + L2SF + L1RidgeLassoSFRF (sensors)RF (sources)StatesSensor selection. The problem of selecting a small number of relevant sensors (on which to perform
sensor fusion) among a possibly large number  which we can call sensor selection  is quite a difﬁcult
problem. Beyond this  measurement selection in the Kalman ﬁlter is a generally difﬁcult problem. As
far as we know  this is an active and relatively open area of research. On the other hand  in regression 
variable selection is extremely well-studied  and (cid:96)1 regularization (among many other tools) is now
very well-developed (see  e.g.  Hastie et al. [2009  2015]). Starting from the regression formulation
for SF in (14)  it would be natural to add to the criterion an (cid:96)1 or lasso penalty [Tibshirani  1996] to
select relevant sensors 

minimize

bj∈Rd

1
t

(xij − bT

j zi)2 + λj(cid:107)bj(cid:107)1

(16)

where (cid:107)bj(cid:107)1 =(cid:80)k

subject to H T bj = ej 

(cid:96)=1 |bj(cid:96)|  j = 1  . . .   k. It is not clear (nor likely) that (16) has an equivalent SF
formulation  but the exact equivalence when λj = 0 suggests that (16) could be a reasonable tool for
sensor selection. (Indeed  without even considering its sensor selection capabilities  this performed
respectably for predictive purposes in the experiments in Section 4.) Further  we can perform a kind
of process model selection with (16) by augmenting our measurement vector with multiple candidate
process models  and penalizing only their coefﬁcients. An example is given in the supplement.

t(cid:88)

i=1

Joint sensor learning.
In the ﬂu nowcasting problem  recall  the sensors are outputs of predictive
models  each trained individually to predict wILI from a particular data source (ﬂu proxy). Denote by
ui ∈ Rd  i = 1  . . .   t the data sources at times 1 through t. Instead of learning the sensors (predictive
transformations of these sources) individually  we could learn them jointly  by extending (14) into:

(cid:0)xij − bT

j fj(ui)(cid:1)2

t(cid:88)

i=1

minimize

fj∈Fj

1
t

+ λjPj(fj)

(17)

subject to H T bj = ej.

for j = 1  . . .   k. Here  each Fj is a space of functions from Rd to Rd (e.g.  diagonal linear maps)
and Pj is a penalty to be speciﬁed by the modeler (e.g.  the Frobenius norm in the linear map case).
The key in (17) is that we are simultaneously learning the sensors and assimilating them.

Gradient boosting. Solving (17) is computationally difﬁcult (even in the simple linear map case  it
is nonconvex). An alternative that is more tractable is to proceed iteratively  in a manner inspired by
gradient boosting [Friedman  2001]. For each j = 1  . . .   d  let Aj be an algorithm (“base learner”)
that we use to ﬁt sensor j from data source j. Write yi = Hxi  i = 1  . . .   t  and let η > 0 be a small
ﬁxed learning rate. To make a prediction at time t + 1  we initialize x(0)
i = 0  i = 1  . . .   t + 1 (or
initialize at the ﬁts from the usual linear SF)  and repeat  for boosting iterations b = 1  . . .   B:

• For j = 1  . . .   d:
– Let y(b−1)
– Run Aj with responses {yij − y(b−1)
}t
i=1 and covariates {uij}t
– Deﬁne intermediate sensors z(b)
ij = ¯f (b)
(uij)  for i = 1  . . .   t + 1.

= (Hx(b−1))ij  for i = 1  . . .   t.

ij

ij

j

• For j = 1  . . .   k:

i=1  to produce ¯f (b)

j

.

– Run SF as in (14) (possibly with regularization) with responses {xij − x(b−1)

ij

}t
i=1 and

covariates {z(b)}t

i=1  to produce ˆbj.

– Deﬁne intermediate state ﬁts ¯x(b)
ij = x(b−1)
– Update total state ﬁts x(b)

ij = ˆbT

j z(b)
+ η¯x(b)

  for i = 1  . . .   t + 1.
ij   for i = 1  . . .   t + 1.

ij

i

We return at the end our ﬁnal prediction ˆxt+1 = x(B)
in detail  and study the extent to which it can improve on the usual linear SF.

t+1. It would be interesting to pursue this approach

Acknowledgments. We thank Logan Brooks for several helpful conversations and brainstorming
sessions. MJ was supported by NSF Graduate Research Fellowship No. DGE-1745016. RR and RJT
were supported by DTRA Contract No. HDTRA1-18-C-0008.

9

References
Brian D. O. Anderson and John B. Moore. Optimal Filtering. Prentice-Hall  1979.

Leo Breiman. Stacked regressions. Machine Learning  24(1):49–64  1996.

Leo Breiman. Random forests. Machine Learning  45(1):5–32  2001.

P. J. Brown. Multivariate calibration. Journal of the Royal Statistical Society: Series B  44(3):

287–321  1982.

Robert Brown and Patrick Hwang. Introduction to Random Signals and Applied Kalman Filtering.

Wiley  2012. Fourth edition.

Geir Evensen. Sequential data assimilation with nonlinear quasi-geostrophic model using Monte
Carlo methods to forecast error statistics. Journal of Geophysical Research  99(C5):143–162 
1994.

David Farrow. Modeling the Past  Present  and Future of Inﬂuenza. PhD thesis  Computational

Biology Department  Carnegie Mellon University  2016.

Jerome Friedman. Greedy function approximation: a gradient boosting machine. Annals of Statistics 

29(5):1190–1232  2001.

Neil J. Gordon  David J. Salmond  and Adrian F. M. Smith. Novel approach to nonlinear/non-
Gaussian Bayesian state estimation. IEE Proceedings F  Radar and Signal Processing  140(2):
107–113  1993.

Trevor Hastie  Robert Tibshirani  and Jerome Friedman. The Elements of Statistical Learning; Data

Mining  Inference and Prediction. Springer  2009. Second edition.

Trevor Hastie  Robert Tibshirani  and Martin Wainwright J. Statistical Learning with Sparsity: The

Lasso and Generalizations. Chapman & Hall  2015.

P. L. Houtekamer and Herschel L. Mitchell. Data assimilation using an ensemble Kalman ﬁlter

technique. Monthly Weather Review  126(3):796–811  1998.

Simon J. Julier and Jeffrey K. Uhlmann. A new extension of the Kalman ﬁlter to nonlinear systems.

Signal Processing  Sensor Fusion  and Target Recognition  1997.

Rudolf E. Kalman. A new approach to linear ﬁltering and prediction problems. Journal of Basic

Engineering  82(1):35–45  1960.

Peter Van Overshee and Bart De Moor. Subspace Identiﬁcation for Linear Systems. Kluwer Academic 

1996.

Gerald L. Smith  Stanley F. Schmidt  and Leonard A. McGee. Application of statistical ﬁlter theory
to the optimal estimation of position and velocity on board a circumlunar vehicle. National
Aeronautics and Space Administration Tech Report  1962.

Robert Tibshirani. Regression shrinkage and selection via the lasso. Journal of the Royal Statistical

Society: Series B  58(1):267–288  1996.

David Wolpert. Stacked generalization. Neural Networks  5(2):241–259  1992.

10

,Maria Jahja
David Farrow
Roni Rosenfeld
Ryan Tibshirani