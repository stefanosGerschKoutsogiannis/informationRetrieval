2018,Modeling Dynamic Missingness of Implicit Feedback for Recommendation,Implicit feedback is widely used in collaborative filtering methods for recommendation. It is well known that implicit feedback contains a large number of values that are \emph{missing not at random} (MNAR); and the missing data is a mixture of negative and unknown feedback  making it difficult to learn user's negative preferences. 
Recent studies modeled \emph{exposure}  a latent missingness variable which indicates whether an item is missing to a user  to give each missing entry a confidence of being negative feedback.
However  these studies use static models and ignore the information in temporal dependencies among items  which seems to be a essential underlying factor to subsequent missingness. To model and exploit the dynamics of missingness  we propose a latent variable named ``\emph{user intent}'' to govern the temporal changes of item missingness  and a hidden Markov model to represent such a process. The resulting framework captures the dynamic item missingness and incorporate it into matrix factorization (MF) for recommendation. We also explore two types of constraints to achieve a more compact and interpretable representation of \emph{user intents}. Experiments on real-world datasets demonstrate the superiority of our method against state-of-the-art recommender systems.,Modeling Dynamic Missingness of Implicit Feedback

for Recommendation

Menghan Wang

College of Computer Science 

Zhejiang University

wangmengh@zju.edu.cn

Xiaolin Zheng∗

College of Computer Science 

Zhejiang University

xlzheng@zju.edu.cn

Mingming Gong

Department of Biomedical Informatics 

University of Pittsburgh

mig73@pitt.edu

Kun Zhang

Department of Philosophy 
Carnegie Mellon University

kunz1@cmu.edu

Abstract

Implicit feedback is widely used in collaborative ﬁltering methods for recommenda-
tion. It is well known that implicit feedback contains a large number of values that
are missing not at random (MNAR); and the missing data is a mixture of negative
and unknown feedback  making it difﬁcult to learn users’ negative preferences.
Recent studies modeled exposure  a latent missingness variable which indicates
whether an item is exposed to a user  to give each missing entry a conﬁdence of
being negative feedback. However  these studies use static models and ignore the
information in temporal dependencies among items  which seems to be an essential
underlying factor to subsequent missingness. To model and exploit the dynamics
of missingness  we propose a latent variable named “user intent” to govern the tem-
poral changes of item missingness  and a hidden Markov model to represent such
a process. The resulting framework captures the dynamic item missingness and
incorporate it into matrix factorization (MF) for recommendation. We also explore
two types of constraints to achieve a more compact and interpretable representation
of user intents. Experiments on real-world datasets demonstrate the superiority of
our method against state-of-the-art recommender systems.

1

Introduction

Collaborative ﬁltering methods based on implicit feedback (e.g.  purchase records and browsing
history) are widely used in recommender systems. Compared to explicit feedback (e.g.  1-5 star
ratings)  implicit feedback is more abundant and accessible in real-world applications. However 
the missing data of implicit feedback also brings two challenges. First  the data is missing not at
random (MNAR). Only positive feedback is collected in implicit feedback and all negative feedback
is missing  leading to a severely biased dataset. Second  the missing data is a mixture of negative and
unknown feedback; a missing entry may indicate the user either dislikes or does not know the item 
which makes it hard to learn user’s negative preferences. Several previous works [Hu et al.  2008 
Marlin and Zemel  2009] provided evidence that both ignoring missing data and treating all missing
data as negative feedback will lead to biased recommendations.
A possible solution is to model the MNAR mechanism and treat the missing data properly. Several
researchers have proposed various methods to address this issue. Popular methods [Hu et al.  2008 

∗Corresponding author

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

Pan et al.  2008] are based on the uniformity assumption that assigns a uniform weight to degrade
the importance of the missing data  assuming that each missing entry is equally likely to be negative
feedback. This is a strong assumption and limits models’ ﬂexibility for real applications. Recently 
researchers [Liang et al.  2016  Wang et al.  2018a] treated missing entries differently with the so-
called “exposure” variables and achieved improved results. An exposure variable indicates whether
or not an item is missing to a user. They make predictions in two steps: They ﬁrst model exposure
variables for each user to get the candidate items that are not missing and then recommend top-ranked
items in the set of candidate items based on user preferences.
However  these modeled exposure-based missingness mechanisms are static and the temporal de-
pendencies among items are not utilized  which can naturally inﬂuence the subsequent missingness
greatly. Consider the following example. If a user has just bought a mobile phone  it is more likely
for him/her to buy a suitable phone case next so missingness probabilities of candidate phone cases
will be lower than if the user had not bought the phone. Moreover  the effect of item dependencies on
the missingness is asymmetric: purchase of a phone case indicates that the user has probably owned a
mobile phone and the missingness probabilities of phones should be high during his/her next purchase.
Thus the key to modeling the dynamic missingness is how to utilize the temporal information of
implicit feedback to capture the asymmetric item dependencies. Instead of ﬁnding explicit item
dependencies  we assume that the missingness of items for a user at one time is generated by a latent
variable called “user intent"  and that the dynamics of missingness are driven by a Markov process of
user intents. In other words  user intents capture item relations implicitly and generate time-sensitive
exposure variables.
Particularly  in this paper  we use a hidden Markov model (HMM) to represent the dynamic missing-
ness of implicit feedback and the estimated missingness of items is incorporated into a probabilistic
matrix factorization (MF) model for recommendation. To the best of our knowledge  the proposed
framework  namly “H4MF”  as a strategy of “leveraging HMM and MF to model the dynamic
Missingness for recommendation ” is the ﬁrst work to address the dynamic missingness of implicit
feedback in recommendation area. The HMM and MF are seamlessly incorporated in H4MF  making
the framework interpretable and extensible. Further  we propose a principled computational algorithm 
showing promising results on real-world datasets.

2 Related Work

Missing data presents a common challenge for empirical sciences. Most prior studies on recommender
systems assumed data is missing at random (MAR); however  Marlin and Zemel [2009] demonstrated
that data in real recommender systems is not MAR and recommendation algorithms based on
MAR assumption may lead to biased results. Several studies have modeled different missingness
mechanisms to address the MNAR problem. For explicit feedback  a widely accepted mechanism
[Marlin and Zemel  2009  Ling et al.  2012  Hernández-Lobato et al.  2014] is that missingness is
related to the potential ratings (e.g  1-5 star ratings). Data for items with high ratings are less likely to
be missing compared to items with low ratings. For implicit feedback  some causal-process-based
methods [Liang et al.  2016  Wang et al.  2018a] ﬁrst computed exposures for each user and then used
them to guide rating prediction  which have shown promising results. Different from these studies 
we address the MNAR problem with a dynamic missingness assumption.
Another related work is sequential recommendation  where researchers utilize temporal data for
next-item recommendation. Existing sequential recommender systems mainly capture the dynamic
user preferences. A popular idea is to utilize Markov chains [He and McAuley  2016] to model
the sequential information. Rendle et al. [2010] proposed a factorized personalized Markov chain
(FPMC) model that combines both a common Markov chain and a matrix factorization model. Sahoo
et al. [2012] chose a hidden Markov model to capture the dynamic of user preferences for personalized
recommendation. However  they did not consider the MNAR problem and the missing data is not
well utilized. Some other researchers also used deep learning techniques (e.g.  LSTM [Wu et al. 
2017] and GRU [Chung et al.  2015] ) for sequential recommendation; however  they are limited
in interpretability. In this paper we assume user preferences are static and focus on modeling the
dynamic missingness for the MNAR problem. Moreover  it is rather straightforward to extend our
framework to capture the dynamic user preferences with existing studies on online learning [Mairal
et al.  2010].

2

Figure 1: Graphical model of the proposed model.

3 H4MF Framework

i

.

i   y2

i   ...  yT

i }  where yt

ij = 1 means item j is exposed to user i at time t  and αt

In this section  we ﬁrst introduce the problem formula and our proposed framework. Then we describe
the parameter inference and the prediction formula in detail.
Problem Formulation. Suppose we have N users and M items. For each user i  a T -length rating
history in chronological order is given as Yi = {y1
i denotes the item that user i
rated at time t (Note that the rating denotes implicit feedback in this paper). The goal of recommender
systems is to predict which item the user will rate next  more speciﬁcally  yT +1
Before describing our model  we ﬁrst introduce the representation of yt
i and the deﬁnition of miss-
ingness variables  which can help to understand the proposed dynamic missingness mechanism. We
i as a M × 1 rating vector. As one user can only rate one of M items at one time  there
represent yt
i and “0” elsewhere. Thus the missing data of implicit feedback refers
is a “1” in one position of yt
to “0” entries  which contain negative and unknown feedback. For each yt
ij in dataset  we use a
ij (same as the exposure variable in [Liang et al.  2016]) to indicate
Bernoulli missingness variable αt
the missingness: αt
ij = 0 means the user
does not see the item. The missingness variables have a reasonable interpretation: users ﬁrst have to
ij can be utilized to extract negative
see the items  then they have the possibility to rate them. Thus αt
feedback from the missing data: if user i has seen item j (αt
ij is 0  this rating
is more likely to be negative feedback rather than unknown feedback  which can be further utilized to
learn user preference. Note that αt
ij may be different for different t and our model aims to capture its
dynamics.
Model Description. We assume that user intent and user preference work together for recommen-
dation: User intent determines the missingness of items and user preference determines recommen-
dations from the non-missing items. In this paper we propose a framework named “H4MF” that
combines HMM and MF to model the dynamic Missingness for recommendation. As shown in
Figure 1  H4MF has two components: the User Intent Component and the User Preference Com-
ponent. In the User Intent Component we use a ﬁrst-order hidden Markov model to capture the
missingness mechanism. αt is a M × 1 missingness vector of items at time t generated by a latent
state variable St (named “user intent”)  and the probability of St depends only on the last state
St−1. The user intent is a single categorical random variable that can take one of D discrete values 
St ∈ {1  ...  D}. We assume that user intents are shared by all users so the generated αt
j represents
ij for all possible users. The state transitions follow a categorical distribution and the conditional
αt
observation distribution is deﬁned as:

ij = 1) but the rating yt

M(cid:89)

(cid:88)

p(yt

i|St  P ) =

p(yt

ij|αt

ij  P )p(αt

ij|St)  αt

ij ∈ {0  1}

(1)

j=1

αt
ij

In the User Preference Component  we adopt a classical but effective matrix factorization model
[Mnih and Salakhutdinov  2008]: the user preference P ∈ RN×M is decomposed as a product of
two submatrices U ∈ RK×N and V ∈ RK×M   which represent user-speciﬁc and item-speciﬁc latent

3

(cid:22)(cid:21)(cid:3)(cid:4)(cid:11)(cid:21)(cid:3)(cid:4)(cid:22)(cid:21)(cid:11)(cid:21)(cid:22)(cid:21)(cid:2)(cid:4)(cid:11)(cid:21)(cid:2)(cid:4)(cid:7)(cid:9)(cid:10)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:8)(cid:21)(cid:3)(cid:4)(cid:8)(cid:21)(cid:8)(cid:21)(cid:2)(cid:4)(cid:1)(cid:1)(cid:1)(cid:1)(cid:9)(cid:20)(cid:13)(cid:19)(cid:1)(cid:6)(cid:16)(cid:21)(cid:13)(cid:16)(cid:21)(cid:1)(cid:5)(cid:17)(cid:15)(cid:18)(cid:17)(cid:16)(cid:13)(cid:16)(cid:21)(cid:1)(cid:9)(cid:20)(cid:13)(cid:19)(cid:1)(cid:7)(cid:19)(cid:13)(cid:14)(cid:13)(cid:19)(cid:13)(cid:16)(cid:12)(cid:13)(cid:1)(cid:5)(cid:17)(cid:15)(cid:18)(cid:17)(cid:16)(cid:13)(cid:16)(cid:21)(cid:1)feature factors respectively. More speciﬁcally  we use Pij = U T
toward item j. The conditional distribution over the observed ratings Y t
term) for user i and the prior distribution are given by:

i Vj to show the preference of user i
i ∈ RN×M (the likelihood

T(cid:89)

M(cid:89)

t=1

i   P ) =

p(Yi|αT

ijN (yt
[αt
ij|St) = Bernoulli(Is(µt
N (Ui|0  λ−1

p(αt
p(U|λu) =

N(cid:89)

j=1

ij|Pij  λ−1

y IK) + (1 − αt

ij)I[yt

ij = 0]] 

j))  µt

j ∼ Beta(at  bt) 
M(cid:89)

u IK)  p(V |λv) =

N (Vj|0  λ−1

v IK) 

(2)

i=1

j=1

ij is deﬁnitely 0; when αt

ij = 0  the rating is missing so yt

ij = 0 is true  and 0 otherwise. Is(µt

where N (x|µ  λ) denotes the Gaussian distribution with mean µ and precision λ  I[yt
ij = 0] is the
j) indicates that µt
indicator function that evaluates to 1 when yt
j
is St-speciﬁc. IK stands for the identity matrix of dimension K. p(Yi|αT
i   P ) can be interpreted as
ij = 1  the rating is not
follows: when αt
missing so yt
ij is either 0 or 1  depending on the user preference Pij. In this paper we present our
method and its inference for the case of one user’s sequential records; but it is straightforward to
apply them to multiple user cases. Note that users have variable-length rating records so that T is not
a ﬁxed number for different users.
Next we explain the underlying design of H4MF. We choose HMM for user intent because HMM can
well utilize the temporal data to mine the asymmetric item dependencies; and the latent states (user
intents) can be shared by all users  which simpliﬁes the structure of the missingness mechanism. We
choose MF for user preference because MF can model a low dimensional representation for both users
and items  which has been proved effective in recommender systems. Meanwhile  H4MF is more
explainable and reasonable with this modular structure. Most existing sequential recommendation
algorithms [Xiang et al.  2010  Shi et al.  2014] only used “dynamic preference” to account for the
temporal user behaviors; they assumed time-varying user preference is the only explanation for the
noisy user behaviors. In this case the learned user preference will ﬂuctuate rapidly and be difﬁcult to
explain.
Although choosing a dynamic preference model will make H4MF more reasonable  we assume user
preference to be static for two main reasons: 1) User preference evolves steadily and is rather stable
compared to user intent. Moore et al. [2013] visualized dynamic user preference via trajectories.
Their results show that user preferences change steadily and slowly in a long time (month level) 
especially for older users. In contrast  user intent changes every user-item interaction in H4MF. So
it is reasonable to choose static preferences in H4MF. 2) Simplicity for inference is a concern. As
our goal to explore the effects of dynamic missingness to recommender systems  MF is also fair for
comparison to baselines.
Parameter Inference. We choose expectation-maximization (EM) to ﬁnd the maximum a posteriori
(MAP) estimations of the parameters of H4MF. In the E-step  we compute the expected log posterior
of the observed data and the user intents  which is:

i   P|ST   Yi) ∝ log p(Yi|αT

i |ST ) + log p(ST ) + log p(P )

log p(αT

(3)
i |ST ) is computed as
The log p(P ) is computed as log p(U|λu) + log p(V |λv) and log p(αT
log Is(µt
j. As the exact expectation
of HMM is computationally intractable  we use Gibbs sampling to infer the posterior probabilities of
St. For a given rating sequence {Y t

j)|at  bt); we add a prior to regularize the µt

i } by user i. St is sampled from

j) + log p(Is(µt

i   P ) + log p(αT

p(St|St−1  St+1  Yi  αt

(4)
where p(St|St−1) and p(St+1|St) can be obtained from the state transition matrix of the HMM  and
the expectation of log likelihood of one rating record yt

i  P ) ∝ p(St|St−1)p(St+1|St)p(yt

i|αt

i  P ) 

log p(yt

i|αt

i  P ) =

log

yt
ijµt
j

N (0|U T

(cid:16)

M(cid:88)

j=1

i is given by:
N (1|U T
i Vj  λ−1
y )
y ) + N (1|U T
i Vj  λ−1

i Vj  λ−1
y )
i Vj  λ−1
y )
y ) + N (1|U T

N (0|U T
i Vj  λ−1

i Vj  λ−1
y )

(cid:17)

)

(5)

+ (1 − yt

ij)(1 − µt

j + µt
j

N (0|U T

4

In the M-step  we maximize the log posterior with respect to µ  U  V   and {St}. We use gradient
ascent to update µ  and compute optimal U and V by setting their derivatives to zero. The details are
included in Appendix 1.1. Note that we update U and V and ﬁx the hyperparameters λu  λv  and
λy. This strategy follows the original PMF [Mnih and Salakhutdinov  2008] for simpliﬁcation. For
user intents {St}  we use the Baum-Welch algorithm [Ghahramani and Jordan  1996] to update the
transition matrix and initial states probability distribution of the HMM; as a strict EM-type algorithm
it is guaranteed to converge to at least a local maximum.
Making Prediction. In the recommendation phase we are interested in the prediction of yT +1
for
user i given his/her previous rating records. We make predictions by integrating out the uncertainty
from the missing variable αT +1

ij

:

  Pij](cid:3)

(cid:2)Ey[yT +1
(cid:88)

ij

∈{0 1}
· U T

i Vj

|αT +1
p(αT +1

j

j

j

Ey[yT +1

ij

|Pij] = Eα

=

αT +1

j

= µT +1

j

) Ey[yT +1

ij

|αT +1

j

  Ui  Vj]

(6)

where µT +1
algorithm of HMM.

j

is determined by the next user intent ST +1  which can be predicted with the forward

4 Further Constraints on Items
Currently all missingness variables {αt
j} share the symmetric Beta priors. One potential drawback is
the learned user intents may be redundant and items under the same user intent tend to have similar
missing probabilities. In this section we deﬁne two kinds of constraints  namely inner constraint
and outer constraint  to specialize the Beta priors of missingness variables of different items under
different user intents. The intuitions are simple but reasonable: Items have relations under the
same user intent and their exposure variables are related. We use the inner constraint to denote
the inﬂuences from other items under the same user intent to one item’s missingness. Meanwhile 
the missingness of one item under different user intents should follow some patterns to reduce the
redundancy. And we use the outer constraint to denote the inﬂuences from the same item under
different user intents to one item’s missingness. We adopt a simple implementation: we update the
Beta priors in every M-step as follows:

#total records under user intent d

j λInner + ωd

j λOuter  bd

new ← ad
ad
ini and bd

new ← bd

ini + λInner + λOuter  d ∈ {1  ...  D}

Where ad
#records of item j under user intent d

ini + σd
ini are initial Beta priors  λInner and λOuter are the scale parameters  σd

j =
indicates the occurrence probability of item j with respect to other
items under user intent d  and ωd
indicates the occurrence probability
of item j that is “triggered” by user intent d. Then the ad and bd are not global constants during
the EM procedure and play a constraint role. The items with similar occurrence probabilities under
the same user intent will have similar Beta priors. Instead of putting constraints directly on µd
j  
this strategy can avoid sophisticated inferences and later experiments prove its effectiveness. In
experiments we denote this constrained version as H4MFc.

j = #records of item j under user intent d

#total records of item j

(7)

5 Experimental Results

In this section we describe the used datasets and experimental settings  evaluate the performance
results  and analyze the user intent and the item constraints.

5.1 Datasets and Settings

We evaluate the performance of our method on three real-world datasets: 1) MovieLens-100K dataset
(∼ 100 thousand ratings from 943 users on 1 682 movies). The dataset was collected during the
seven-month period from September 19th  1997 through April 22nd  1998. 2) MovieLens-1M dataset
(∼ 1 million ratings from 6 040 users on 3 706 movies). The dataset was collected from April 25th 

5

2000 through February 28th  2003. 3) LastFM dataset (∼ 100 thousand ratings from 1 892 users on
17 632 movies). The time period is from August 1st  2005 through May 1st  2011. We transform
the two MovieLens datasets into implicit data by setting ratings that are ≥ 3 to “1” and the others
to “0”. We then choose four prevalent methods for comparison  including: (1) PMF [Mnih and
Salakhutdinov  2008]  a classical matrix factorization approach that is widely applied as a benchmark.
(2) WMF [Hu et al.  2008]  a standard matrix factorization model for implicit data  which uses a
simple heuristic where all unobserved user-item interactions are equally down weighted against the
observed interactions. (3) FPMC [Rendle et al.  2010]  a sequential recommendation algorithm based
on personalized transition graphs over underlying Markov chains. It used a variant of Bayesian
Personalized Ranking (BPR) [Rendle et al.  2009] for optimization. (4) ExpoMF Liang et al. [2016] 
a probabilistic approach that incorporates user exposure to items into collaborative ﬁltering. The
baselines are chosen for the following reasons: PMF and FPMC can been seen as sub-models of
H4MF  while they overlook the missing data problem. WMF treats the missing data as a MAR
problem. ExpoMF takes a static method to the MNAR problem. The main goal of the experiments is
to show that how we treat the missing data makes a difference.
We adopt Hit Ratio (HR) and Normalized Discounted Cumulative Gain (NDCG) to measure the item
ranking accuracy of different algorithms. HR measures whether the ground truth item is present
on the ranked list  while NDCG measures the ranking quality by considering the positions of hits.
We follow the deﬁnitions of HR and NDCG in [He et al.  2015]. In our study we always report
the averaged HR and NDCG across users. We split the dataset for experiments with the following
strategy: we ﬁrst sort the historical ratings of each user by time order. Then the last records of users
are used as test data  the second last records are used as validation data  and the remaining records are
used for training. We search for the optimal parameters to maximize the performance on validation
data and evaluate the model on test data. For the parameters of baseline models  we refer to their
original papers and follow their tuning strategies.

5.2 Analysis of Prediction Performance

We report the performance of our methods and baseline models with optimal parameters. For PMF 
we set K = 10. For WMF  we set K = 10  α = 0.4. For ExpoMF  we set λθ = 0.01  λβ = 0.01 
λy = 0.01  and K = 30. For our models  we set λθ = 0.1  λβ = 0.1  λy = 0.1  K = 30  ad
ini = 1 
ini = 2. For item constraints  λOuter is set as 1  and λInner is set 10  1  and 0.1 for MovieLens-
and bd
100K  MovieLens-1M  and LastFM  respectively. We show the performance of our methods with
other baseline models in Table 1. As shown in the results  H4MFc achieves higher item ranking
accuracy than the other compared algorithms due to the capability of better capturing the missingness
of implicit feedback. Note that PMF  WMF  ExpoMF  and H4MF model user preference similarly:
they all use a basic matrix factorization method and the main difference is the way they model the
missing data. PMF performs poorly because the datasets are sparse and all the missing entries are
treated as negative feedback. So the positive feedback is overwhelmed by negative feedback  leading
to a biased user preference learning. FPMC has the same reason for its poor performance. Besides  it
is originally proposed for next-basket recommendation. Here we set basket size as 1 as we do not
have basket information  which also limits the effectiveness of FPMC. WMF is better than PMF as it
treats the missing data with a globally ﬁxed low conﬁdence. ExpoMF models exposure variable αui
for every user-item pair so it can capture more information from the missing data compared to WMF
and PMF. H4MF is better than ExpoMF because it considers the dynamic missingness of items. Note
that the experimental results of WMF  ExpoMF  and H4MF are very close; WMF even beats WMF
and H4MF on LastFM. This is because modeling missingness for each missing entry adds model
complexity and is prone to overﬁtting. On the other hand  the superiority of H4MFc compared to
H4MF proves the effectiveness of the user intent constraints.

5.3 Analysis of User Intents

This section analyzes user intents in three aspects: recommendation overlaps  sensitivity of user
intent number  and interpretation of user intents.
Recommendation Overlaps. In H4MF  we use user preference and user intent for recommendation.
For a particular user with ﬁxed preference  we sample different user intents and see how different
are the recommendation lists. We use the term “recommendation overlap” to denote the ratio of
common items in Top-N recommendation lists generated by two different user intents. A large

6

Dataset

MovieLens-100K

MovieLens-1M

LastFM

Metrics
HR@10
HR@50
NDCG@10
NDCG@50
HR@10
HR@50
NDCG@10
NDCG@50
HR@10
HR@50
NDCG@10
NDCG@50

Effectiveness of models
PMF
0.0031
0.0296
0.0011
0.0066
0.0021
0.0093
0.0008
0.0022
0.0012
0.0037
0.0004
0.0009

FPMC WMF
0.1251
0.0021
0.3968
0.0212
0.0501
0.0007
0.0046
0.1203
0.0791
0.0034
0.2696
0.0129
0.0372
0.0087
0.0800
0.0549
0.0021
0.0835
0.2144
0.0360
0.0432
0.0008
0.0074
0.0713

ExpoMF H4MF H4MFc
0.1569
0.1230
0.4347
0.3478
0.0779
0.0616
0.1367
0.1101
0.0877
0.0801
0.3049
0.2808
0.0435
0.0331
0.0897
0.0675
0.0945
0.0736
0.2298
0.1824
0.0495
0.0352
0.0789
0.0575

0.1317
0.3990
0.0583
0.1205
0.0805
0.2704
0.0408
0.0811
0.0799
0.1980
0.0423
0.0639

Table 1: Performance of different models on three datasets.

Figure 2: Performances of proposed models with different numbers of user intents (D).

recommendation overlap indicates that the two user intents have similar missingness mechanisms. We
choose N = 10 and show the average of recommendation overlaps across users in Table 2. We can
see the recommendation overlaps of H4MFc are much smaller than those of H4MF  proving that the
item constraints can reduce the redundancy of user intents. Meanwhile  the recommendation overlaps
decrease both in H4MF and in H4MFc when D increases. This result conforms to our expectations
because our methods can capture more aspects of user intents with a large D.

Recommendation Overlaps of Different User Intents

Movielens-100K

Movielens-1M

LastFM

Dataset

User Intent
U1 vs U2
U2 vs U3
U1 vs U3

D=2

D=3

D=2

D=3

D=2

D=3

H4MF H4MFc H4MF H4MFc H4MF H4MFc H4MF H4MFc H4MF H4MFc H4MF H4MFc
14%
80%
2%
0%

84%
78%
78%

74%
72%
72%

92%

14%

52%
32%
28%

30%
18%
16%

52%

-
-

26%

-
-

8%
-
-

6%
2%
2%

-
-

-
-

-
-

Table 2: Recommendation overlaps of different user intents on three datasets. U 1  U 2  and U 3
indicate the indices of user intents. The cases of D = 4 and D = 5 are included in the Appendix 1.2.

Sensitivity of User Intent Number. The number of user intents D is vital to the performance of
H4MF. We varied D to train H4MF and presented the prediction results in Figure 2. We can see that
H4MFc performs consistently better than H4MF on all the three datasets. The optimal D is 2 on
three datasets. When D increase after D = 2  the performance decreases monotonously. Note that in
last paragraph we ﬁnd that the recommendation overlaps decreases when D increase; but this does
not guarantee the recommendation performance because a large D will also add model complexity.
Interpretation of User Intents. User intents could be utilized to interpret user behaviors and provide
explainable recommendations. Table 3 shows a recommendation example of one user in Movielens-
100K under two different user intents. From the results we can see the genres of recommended
movies under user intent 1 are mainly about “Crime” and “Action”  but the genres under user intent
2 are mainly about “Comedy”  “Romance”  and “Drama” (Note that the genre information is not
used in model training). Thus we can infer that the user mainly has two tastes in movies. As H4MF

7

12345D0.100.150.200.250.300.350.400.450.50HR@50Movielens-100KH4MFH4MF_c12345D0.100.150.200.250.300.35HR@50Movielens-1MH4MFH4MF_c12345D0.000.050.100.150.200.250.30HR@50LastFMH4MFH4MF_ccan predict the user’s next user intent  we will know which genres the user want to see next and
provide more precise and interpretable recommendations.

User Intent 1

User Intent 2

Genres
Movie Name
Comedy  Romance
1. Pulp Fiction
Drama
2. Fargo
Documentary
3. Star Wars
Drama
4. The Full Monty
Comedy  Drama
5. Contact
Drama
6. The English Patient
Comedy
7. Four Weddings and a Funeral
8. The Fugitive
Comedy  Drama
Documentary
9. The Princess Bride
Drama  Romance
10. Raiders of the Lost Ark
Table 3: Top 10 recommendations for one user on Movielens-100K under two user intents.

Movie Name
1. Little City
2. The Whole Wide World
3. Maya Lin: A Strong Clear Vision
4. Savage Nights
5. Beat the Devil
6. Ill Gotten Gains
7. Withnail and I
8. The Inkwell
9. Fast  Cheap & Out of Control
10. Carrington

Genres
Crime  Drama
Crime  Drama  Thriller
Action  Adventure  Sci-Fi  War
Comedy
Drama  Sci-Fi
Drama  Romance  War
Comedy  Romance
Action  Thriller
Action  Adventure  Romance
Action  Adventure

5.4 Effectiveness of Item Constraints

To evaluate the effectiveness of item constraints  we tune the λInner and λOuter to observe how
they inﬂuence the HR@50 of H4MFc. We ﬁx other parameters as described in Section 5.2 and
show the results in Figure 3. The optimal parameters are λInner = 10  λOuter = 1 for Movielens-
100K  λInner = 1  λOuter = 1 for Movielens-1M  and λInner = 0.1  λOuter = 1 for LastFM. The
optimal λOuter is around 1 for all the three datasets; When it increases  the HR@50 decreases
dramatically. Meanwhile  the optimal λInner varies across datasets and the performance is less
sensitive to the change of λInner. One main reason is that the total item records under user intents are
huge when we have a small D. So the ratio measure σd
j is very small for all items and there are fewer
differences among different σd
j   which limits the effectiveness of λInner. The black dashed lines are
the performances of H4MF (λInner = 0 and λOuter = 0). We can conclude that H4MFc can achieve
improvements with proper constraints  which supports the effectiveness of the two item constraints.

(a) Movielens-100k

(b) Movielens-1M

(c) LastFM

Figure 3: Effectiveness of λInner and λOuter in H4MFc.

5.5 Discussions

In this section we ﬁrst discuss the extensibility and efﬁciency of H4MF  and then discuss utilization
of item relations in recommendation.
Extensibility. User intent and user preference can be seen as a factorization of user behavior  which
makes H4MF more modular and extensible. We can extend one component without considering the
other component. Moreover  both HMM and MF are well studied techniques and their variants can
bring insights into H4MF. For example  we can use local low-rank MF [Lee et al.  2013] and mixture-
rank matrix approximation [Li et al.  2017] to learn user preference by exploiting the underlying
group information of users and items. We can also use hidden semi-Markov model [Yu  2010] to
model the durations of user intents: it is always the case that users purchase serveral items to meet
one intent.
Efﬁciency. A potential limitation of H4MF is the time complexity. The inference of the HMM is a
bottleneck; its theoretical complexity is O( ˆT D2) for each iteration of the EM method  where ˆT is the

8

λOuter0.00.51.01.52.02.53.03.54.0λInner0246810121416HR@500.320.330.350.360.370.390.400.410.430.440.340.350.360.370.380.390.400.410.42λOuter0.00.51.01.52.02.53.03.54.0λInner0.00.51.01.52.02.53.03.54.0HR@500.210.220.230.240.250.260.270.280.290.300.2320.2400.2480.2560.2640.2720.2800.288λOuter0.00.51.01.52.02.53.03.54.0λInner012345HR@500.120.130.140.150.160.170.180.190.200.210.1380.1440.1500.1560.1620.1680.1740.180length of training data and D is the state number. The experimental runtime results in Appendix 1.3
also reveal that the runtime increases dramatically when D and ˆT increase. In real-world applications
customers’ data are collected accumulatively  so the ˆT will become very large. One of the possible
extensions is to devise an online version of H4MF. Currently there are several studies related to the
online learning of HMM and MF [Mongillo and Deneve  2008  Mairal et al.  2010]  which can be
utilized to make H4MF more scalable.
Item relations in recommendation. Most recommendation algorithms mainly focus on mining
and utilizing the information of item similarity. However  item similarity may lead to meaningless
recommendations (e.g.  the phone and phone case example in introduction). The key to address this
issue is to ﬁnd asymmetric relations of items. Several researchers [McAuley et al.  2015  Wang et al. 
2018b] proposed methods to discriminate substitutes and complements from similar products. But
their methods are supervised and the ground truth of labels are directly extracted from user log ﬁles 
which may contain biases and noise. A more principled approach is to apply techniques of causal
discovery to ﬁnd the directed relations among items. However  current techniques of causal discovery
(e.g  modiﬁed PC [Spirtes et al.  2000] and GES [Chickering and Meek  2002]) may not work well
on the recommendation data as they are extremely sparse and MNAR. Instead in our model  the
asymmetric relations of items are revealed from the temporal data by the dynamical missingness
mechanism. In this regard our H4MF can be seen as a step toward causality-based recommendations
from similarity-based recommendations.
6 Conclusion
In this paper we aim to model and leverage properties of dynamic item missingness to improve
recommendation. We proposed a framework that seamlessly combines HMM and MF to model the
dynamic missing mechanism of implicit feedback for recommendation. To make the user intents less
redundant  we introduced two types of constraints for the missingness variables. Empirical results on
three datasets show that our method not only outperform alternatives but also provide interpretable
recommendations. Further analysis demonstrates the effectiveness of user intent and its constraints.
Future work includes extending H4MF with recent advanced variants of HMM and MF.

Acknowledgments

This work was supported in part by the National Natural Science Foundation of China (No.U1509221) 
the National Key TechnologyR&D Program (2015BAH07F01)  the Zhejiang Province key R&D
program (No.2017C03044). This material is partially based upon work supported by United States Air
Force under Contract No. FA8650-17-C-7715  by National Science Foundation under EAGER Grant
No. IIS-1829681  and National Institutes of Health under Contract No. NIH-1R01EB022858-01 
FAINR01EB022858  NIH-1R01LM012087  NIH-5U54HG008540-02  and FAIN-U54HG008540.
Any opinions  ﬁndings  and conclusions or recommendations expressed in this material are those of
the authors and do not necessarily reﬂect the views of the United States Air Force or the National
Institutes of Health or the National Science Foundation. We appreciate the comments from anonymous
reviewers  which helped to improve the paper.

References
David Maxwell Chickering and Christopher Meek. Finding optimal bayesian networks. In UAI 

pages 94–102  2002.

Junyoung Chung  Caglar Gulcehre  Kyunghyun Cho  and Yoshua Bengio. Gated feedback recurrent

neural networks. In ICML  pages 2067–2075  2015.

Zoubin Ghahramani and Michael I Jordan. Factorial hidden markov models. In NIPS  pages 472–478 

1996.

Ruining He and Julian McAuley. Fusing similarity models with markov chains for sparse sequential

recommendation. In ICDM  pages 191–200. IEEE  2016.

Xiangnan He  Tao Chen  Min-Yen Kan  and Xiao Chen. Trirank: Review-aware explainable

recommendation by modeling aspects. In CIKM  pages 1661–1670  2015.

9

José Miguel Hernández-Lobato  Neil Houlsby  and Zoubin Ghahramani. Probabilistic matrix factor-

ization with non-random missing data. In ICML  pages 1512–1520  2014.

Yifan Hu  Yehuda Koren  and Chris Volinsky. Collaborative ﬁltering for implicit feedback datasets.

In ICDM  pages 263–272. IEEE  2008.

Joonseok Lee  Seungyeon Kim  Guy Lebanon  and Yoram Singer. Local low-rank matrix approxima-

tion. In ICML  pages 82–90  2013.

Dongsheng Li  Chao Chen  Wei Liu  Tun Lu  Ning Gu  and Stephen Chu. Mixture-rank matrix

approximation for collaborative ﬁltering. In NIPS  pages 477–485  2017.

Dawen Liang  Laurent Charlin  James Mcinerney  and David M Blei. Modeling user exposure in

recommendation. In WWW  pages 951–961  2016.

Guang Ling  Haiqin Yang  Michael R Lyu  and Irwin King. Response aware model-based collaborative

ﬁltering. In UAI  pages 501–510  2012.

Julien Mairal  Francis Bach  Jean Ponce  and Guillermo Sapiro. Online learning for matrix factoriza-

tion and sparse coding. JMLR  11(Jan):19–60  2010.

Benjamin M. Marlin and Richard S. Zemel. Collaborative prediction and ranking with non-random

missing data. In RecSys  pages 5–12  2009.

Julian J. McAuley  Rahul Pandey  and Jure Leskovec.

Inferring networks of substitutable and

complementary products. In SIGKDD  pages 785–794  2015.

Andriy Mnih and Ruslan R Salakhutdinov. Probabilistic matrix factorization.

1257–1264  2008.

In NIPS  pages

Gianluigi Mongillo and Sophie Deneve. Online learning with hidden markov models. Neural

computation  20(7):1706–1716  2008.

Joshua L Moore  Shuo Chen  Douglas Turnbull  and Thorsten Joachims. Taste over time: The

temporal dynamics of user preferences. In ISMIR  pages 401–406  2013.

Rong Pan  Yunhong Zhou  Bin Cao  Nathan N Liu  Rajan Lukose  Martin Scholz  and Qiang Yang.

One-class collaborative ﬁltering. In ICDM  pages 502–511. IEEE  2008.

Steffen Rendle  Christoph Freudenthaler  Zeno Gantner  and Lars Schmidt-Thieme. Bpr: Bayesian

personalized ranking from implicit feedback. In UAI  pages 452–461. AUAI Press  2009.

Steffen Rendle  Christoph Freudenthaler  and Lars Schmidt-Thieme. Factorizing personalized markov

chains for next-basket recommendation. In WWW  pages 811–820. ACM  2010.

Nachiketa Sahoo  Tridas Mukhopadhyay  et al. A hidden markov model for collaborative ﬁltering.

Management Information Systems Quarterly  36(4):1329–1356  2012.

Yue Shi  Martha Larson  and Alan Hanjalic. Collaborative ﬁltering beyond the user-item matrix: A

survey of the state of the art and future challenges. CSUR  47(1):3  2014.

Peter Spirtes  Clark N Glymour  and Richard Scheines. Causation  prediction  and search. MIT

press  2000.

Menghan Wang  Xiaolin Zheng  Yang Yang  and Kun Zhang. Collaborative ﬁltering with social

exposure: A modular approach to social recommendation. In AAAI  pages 2516–2523  2018a.

Zihan Wang  Ziheng Jiang  Zhaochun Ren  Jiliang Tang  and Dawei Yin. A path-constrained
In

framework for discriminating substitutable and complementary products in e-commerce.
WSDM  pages 619–627  2018b.

Chao-Yuan Wu  Amr Ahmed  Alex Beutel  Alexander J Smola  and How Jing. Recurrent recom-

mender networks. In WSDM  pages 495–503. ACM  2017.

Liang Xiang  Quan Yuan  Shiwan Zhao  Li Chen  Xiatian Zhang  Qing Yang  and Jimeng Sun.
Temporal recommendation on graphs via long-and short-term preference fusion. In SIGKDD 
pages 723–732. ACM  2010.

Shun-Zheng Yu. Hidden semi-markov models. Artiﬁcial intelligence  174(2):215–243  2010.

10

,Menghan Wang
Mingming Gong
Xiaolin Zheng
Kun Zhang