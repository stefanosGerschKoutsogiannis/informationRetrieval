2008,Clustered Multi-Task Learning: A Convex Formulation,In multi-task learning several related tasks are considered simultaneously  with the hope that by an appropriate sharing of information across tasks  each task may benefit from the others. In the context of learning linear functions for supervised classification or regression  this can be achieved by including a priori information about the weight vectors associated with the tasks  and how they are expected to be related to each other. In this paper  we assume that tasks are clustered into groups  which are unknown beforehand  and that tasks within a group have similar weight vectors. We design a new spectral norm that encodes this a priori assumption  without the prior knowledge of the partition of tasks into groups  resulting in a new convex optimization formulation for multi-task learning. We show in simulations on synthetic examples and on the iedb MHC-I binding dataset  that our approach outperforms well-known convex methods for multi-task learning  as well as related non convex methods dedicated to the same problem.,Clustered Multi-Task Learning:

a Convex Formulation

Laurent Jacob

Mines ParisTech – CBIO

INSERM U900  Institut Curie

Francis Bach

INRIA – Willow Project
Ecole Normale Sup´erieure 

35  rue Saint Honor´e  77300 Fontainebleau  France

laurent.jacob@mines-paristech.fr

45  rue d’Ulm  75230 Paris  France
francis.bach@mines.org

Jean-Philippe Vert

Mines ParisTech – CBIO

INSERM U900  Institut Curie

35  rue Saint Honor´e  77300 Fontainebleau  France

jean-philippe.vert@mines-paristech.fr

Abstract

In multi-task learning several related tasks are considered simultaneously  with
the hope that by an appropriate sharing of information across tasks  each task may
beneﬁt from the others. In the context of learning linear functions for supervised
classiﬁcation or regression  this can be achieved by including a priori informa-
tion about the weight vectors associated with the tasks  and how they are expected
to be related to each other. In this paper  we assume that tasks are clustered into
groups  which are unknown beforehand  and that tasks within a group have similar
weight vectors. We design a new spectral norm that encodes this a priori assump-
tion  without the prior knowledge of the partition of tasks into groups  resulting
in a new convex optimization formulation for multi-task learning. We show in
simulations on synthetic examples and on the IEDB MHC-I binding dataset  that
our approach outperforms well-known convex methods for multi-task learning  as
well as related non-convex methods dedicated to the same problem.

1 Introduction

Regularization has emerged as a dominant theme in machine learning and statistics  providing an
intuitive and principled tool for learning from high-dimensional data. In particular  regularization
by squared Euclidean norms or squared Hilbert norms has been thoroughly studied in various set-
tings  leading to efﬁcient practical algorithms based on linear algebra  and to very good theoretical
understanding (see  e.g.  [1  2]). In recent years  regularization by non Hilbert norms  such as ℓp
norms with p 6= 2  has also generated considerable interest for the inference of linear functions in
supervised classiﬁcation or regression. Indeed  such norms can sometimes both make the problem
statistically and numerically better-behaved  and impose various prior knowledge on the problem.
For example  the ℓ1-norm (the sum of absolute values) imposes some of the components to be equal
to zero and is widely used to estimate sparse functions [3]  while various combinations of ℓp norms
can be deﬁned to impose various sparsity patterns.
While most recent work has focused on studying the properties of simple well-known norms  we
take the opposite approach in this paper. That is  assuming a given prior knowledge  how can we
design a norm that will enforce it?
More precisely  we consider the problem of multi-task learning  which has recently emerged as a
very promising research direction for various applications [4]. In multi-task learning several re-
lated inference tasks are considered simultaneously  with the hope that by an appropriate sharing

1

of information across tasks  each one may beneﬁt from the others. When linear functions are es-
timated  each task is associated with a weight vector  and a common strategy to design multi-task
learning algorithm is to translate some prior hypothesis about how the tasks are related to each other
into constraints on the different weight vectors. For example  such constraints are typically that the
weight vectors of the different tasks belong (a) to a Euclidean ball centered at the origin [5]  which
implies no sharing of information between tasks apart from the size of the different vectors  i.e.  the
amount of regularization  (b) to a ball of unknown center [5]  which enforces a similarity between
the different weight vectors  or (c) to an unknown low-dimensional subspace [6  7].
In this paper  we consider a different prior hypothesis that we believe could be more relevant in some
applications: the hypothesis that the different tasks are in fact clustered into different groups  and that
the weight vectors of tasks within a group are similar to each other. A key difference with [5]  where
a similar hypothesis is studied  is that we don’t assume that the groups are known a priori  and in a
sense our goal is both to identify the clusters and to use them for multi-task learning. An important
situation that motivates this hypothesis is the case where most of the tasks are indeed related to each
other  but a few “outlier” tasks are very different  in which case it may be better to impose similarity
or low-dimensional constraints only to a subset of the tasks (thus forming a cluster) rather than to
all tasks. Another situation of interest is when one can expect a natural organization of the tasks
into clusters  such as when one wants to model the preferences of customers and believes that there
are a few general types of customers with similar preferences within each type  although one does
not know beforehand which customers belong to which types. Besides an improved performance if
the hypothesis turns out to be correct  we also expect this approach to be able to identify the cluster
structure among the tasks as a by-product of the inference step  e.g.  to identify outliers or groups of
customers  which can be of interest for further understanding of the structure of the problem.
In order to translate this hypothesis into a working algorithm  we follow the general strategy men-
tioned above which is to design a norm or a penalty over the set of weights which can be used as
regularization in classical inference algorithms. We construct such a penalty by ﬁrst assuming that
the partition of the tasks into clusters is known  similarly to [5]. We then attempt to optimize the
objective function of the inference algorithm over the set of partitions  a strategy that has proved
useful in other contexts such as multiple kernel learning [8]. This optimization problem over the
set of partitions being computationally challenging  we propose a convex relaxation of the problem
which results in an efﬁcient algorithm.

2 Multi-task learning with clustered tasks

We consider m related inference tasks that attempt to learn linear functions over X = Rd from a
training set of input/output pairs (xi  yi)i=1 ... n  where xi ∈ X and yi ∈ Y. In the case of binary
classiﬁcation we usually take Y = {−1  +1}  while in the case of regression we take Y = R. Each
training example (xi  yi) is associated to a particular task t ∈ [1  m]  and we denote by I(t) ⊂ [1  n]
the set of indices of training examples associated to the task t. Our goal is to infer m linear functions
ft(x) = w⊤t x  for t = 1  . . .   m  associated to the different tasks. We denote by W = (w1 . . . wm)
the d × m matrix whose columns are the successive vectors we want to estimate.
We ﬁx a loss function l : R × Y 7→ R that quantiﬁes by l(f (x)  y) the cost of predicting f (x)
for the input x when the correct output is y. Typical loss functions include the square error in
regression l(u  y) = 1
2 (u − y)2 or the hinge loss in binary classiﬁcation l(u  y) = max(0  1 − uy)
with y ∈ {−1  1}. The empirical risk of a set of linear classiﬁers given in the matrix W is then
deﬁned as the average loss over the training set:

ℓ(W ) = 1

n Pm

t=1Pi∈I(t) l(w⊤t xi  yi) .

(1)

In the sequel  we will often use the m×1 vector 1 composed of ones  the m×m projection matrices
U = 11⊤/m whose entries are all equal to 1/m  as well as the projection matrix Π = I − U.
In order to learn simultaneously the m tasks  we follow the now well-established approach which
looks for a set of weight vectors W that minimizes the empirical risk regularized by a penalty
functional  i.e.  we consider the problem:

where Ω(W ) can be designed from prior knowledge to constrain some sharing of information be-
tween tasks. For example  [5] suggests to penalize both the norms of the wi’s and their variance 

minW∈Rd×m ℓ(W ) + λΩ(W )  

(2)

2

i.e.  to consider a function of the form:

Ωvariance(W ) = k ¯wk2 + β

m Pm

i=1 kwi − ¯wk2  

(3)

where ¯w = (Pn

towards their mean when β increases. Alternatively  [7] propose to penalize the trace norm of W :

i=1 wi) /m is the mean weight vector. This penalty enforces a clustering of the w′is

Ωtrace(W ) = Pmin(d m)

i=1

σi(W )  

(4)

where σ1(W )  . . .   σmin(d m)(W ) are the successive singular values of W . This enforces a low-rank
solution in W   i.e.  constrains the different wi’s to live in a low-dimensional subspace.
Here we would like to deﬁne a penalty function Ω(W ) that encodes as prior knowledge that tasks
are clustered into r < m groups. To do so  let us ﬁrst assume that we know beforehand the clusters 
i.e.  we have a partition of the set of tasks into r groups. In that case we can follow an approach
proposed by [5] which for clarity we rephrase with our notations and slightly generalize now. For a
given cluster c ∈ [1  r]  let us denote J (c) ⊂ [1  m] the set of tasks in c  mc = |J (c)| the number
of tasks in the cluster c  and E the m × r binary matrix which describes the cluster assignment
for the m tasks  i.e.  Eij = 1 if task i is in cluster j  0 otherwise. Let us further denote by ¯wc =
(Pi∈J (c) wi)/mc the average weight vector for the tasks in c  and recall that ¯w = (Pm
i=1 wi) /m
denotes the average weight vector over all tasks. Finally it will be convenient to introduce the matrix
M = E(E⊤E)−1E⊤. M can also be written I − L  where L is the normalized Laplacian of the
graph G whose nodes are the tasks connected by an edge if and only if they are in the same cluster.
Then we can deﬁne three semi-norms of interest on W that quantify different orthogonal aspects:

• A global penalty  which measures on average how large the weight vectors are:

Ωmean(W ) = nk ¯wk2 = trW U W ⊤ .

• A measure of between-cluster variance  which quantiﬁes how close to each other the dif-

ferent clusters are:

Ωbetween(W ) = Pr

c=1 mck ¯wc − ¯wk2 = trW (M − U )W ⊤.

• A measure of within-cluster variance  which quantiﬁes the compactness of the clusters:

Ωwithin(W ) = Pr

c=1nPi∈J (c) kwi − ¯wck2o = trW (I − M )W ⊤ .

We note that both Ωbetween(W ) and Ωwithin(W ) depend on the particular choice of clusters E  or
equivalently of M. We now propose to consider the following general penalty function:

Ω(W ) = εM Ωmean(W ) + εBΩbetween(W ) + εW Ωwithin(W )  

(5)

where εM   εB and εW are non-negative parameters that can balance the importance of the compo-
nents of the penalty. Plugging this quadratic penalty into (2) leads to the general problem:

minW∈Rd×m ℓ(W ) + λtrW Σ(M )−1W ⊤  

(6)

where

(7)
Here we use the notation Σ(M ) to insist on the fact that this quadratic penalty depends on the cluster
structure through the matrix M. Observing that the matrices U  M − U and I − M are orthogonal
projections onto orthogonal supplementary subspaces  we easily get from (7):

Σ(M )−1 = εM U + εB(M − U ) + εW (I − M ) .

Σ(M ) = ε−1

M U + ε−1

B (M − U ) + ε−1

W (I − M ) = ε−1

W I + (ε−1

M − ε−1

B )U + (ε−1

B − ε−1

W )M . (8)

By choosing particular values for εM   εB and εW we can recover several situations  In particular:
• For εW = εB = εM = ε  we simply recover the Frobenius norm of W   which does not put

any constraint on the relationship between the different tasks:

Ω(W ) = εtrW W ⊤ = εPm

i=1 kwik2 .

3

• For εW = εB > εM   we recover the penalty of [5] without clusters:
Ω(W ) = trW (εM U + εB(I − U )) W ⊤ = εM nk ¯wk2 + εBPm

i=1 kwi − ¯wk2 .

In that case  a global similarity between tasks is enforced  in addition to the general con-
straint on their mean. The structure in clusters plays no role since the sum of the between-
and within-cluster variance is independent of the particular choice of clusters.

• For εW > εB = εM we recover the penalty of [5] with clusters:
nmck ¯wck2 + εW

Ω(W ) = trW (εM M + εW (I − M )) W ⊤ = εM

rX

c=1

εM Pi∈J (c) kwi − ¯wck2o .

In order to enforce a cluster hypothesis on the tasks  we therefore see that a natural choice is to
take εW > εB > εM in (5). This would have the effect of penalizing more the within-cluster
variance than the between-cluster variance  hence promoting compact clusters. Of course  a major
limitation at this point is that we assumed the cluster structure known a priori (through the matrix
E  or equivalently M). In many cases of interest  we would like instead to learn the cluster structure
itself from the data. We propose to learn the cluster structure in our framework by optimizing our
objective function (6) both in W and M  i.e.  to consider the problem:

minW∈Rd×m M∈Mr ℓ(W ) + λtrW Σ(M )−1W ⊤  

(9)
where Mr denotes the set of matrices M = E(E⊤E)−1E⊤ deﬁned by a clustering of the m tasks
into r clusters and Σ(M ) is deﬁned in (8). Denoting by Sr = {Σ(M ) : M ∈ Mr} the correspond-
ing set of positive semideﬁnite matrices  we can equivalently rewrite the problem as:
(10)
The objective function in (10) is jointly convex in W ∈ Rd×m and Σ ∈ S m
+   the set of m×m positive
semideﬁnite matrices  however the (ﬁnite) set Sr is not convex  making this problem intractable. We
are now going to propose a convex relaxation of (10) by optimizing over a convex set of positive
semideﬁnite matrices that contains Sr.
3 Convex relaxation

minW∈Rd×m Σ∈Sr ℓ(W ) + λtrW Σ−1W ⊤ .

In order to formulate a convex relaxation of (10)  we observe that in the penalty term (5) the cluster
structure only contributes to the second and third terms Ωbetween(W ) and Ωwithin(W )  and that
these penalties only depend on the centered version of W . In terms of matrices  only the last two
terms of Σ(M )−1 in (7) depend on M  i.e.  on the clustering  and these terms can be re-written as:
(11)
Indeed  it is easy to check that M − U = M Π = ΠM Π  and that I − M = I − U − (M − U ) =
Π − ΠM Π = Π(I − M )Π. Intuitively  multiplying by Π on the right (resp. on the left) centers the
rows (resp. the columns) of a matrix  and both M − U and I − M are row- and column-centered.
To simplify notations  let us introduce fM = ΠM Π. Plugging (11) in (7) and (9)  we get the penalty

εB(M − U ) + εW (I − M ) = Π(εBM + εW (I − M ))Π.

trW Σ(M )−1W ⊤ = εM ¡trW ⊤W U¢ + (W Π)(εBfM + εW (I − fM ))(W Π)⊤ 

(12)
in which  again  only the second part needs to be optimized with respect to the clustering M. Denot-
ing Σ−1

c (M ) = εBfM + εW (I − fM )  one can express Σc(M )  using the fact that fM is a projection:
Σc is characterized by fM = ΠM Π  that is discrete by construction  hence the non-convexity of Sr.
We have the natural constraints M ≥ 0 (i.e.  fM ≥ −U)  0 ¹ M ¹ I (i.e.  0 ¹ fM ¹ Π) and
trM = r (i.e.  trfM = r − 1). A possible convex relaxation of the discrete set of matrices fM is
therefore {fM : 0 ¹ fM ¹ I  trfM = r − 1}. This gives an equivalent convex set Sc for Σc  namely:
(14)
B . Incorporating the ﬁrst part of the
penalty (12) into the empirical risk term by deﬁning ℓc(W ) = λℓ(W ) + εM ¡trW ⊤W U¢  we are

+ : αI ¹ Σc ¹ βI  trΣc = γª  

B and γ = (m − r + 1)ε−1

W ¢ fM + ε−1

Sc = ©Σc ∈ S m

Σc(M ) = ¡ε−1

B − ε−1

with α = ε−1

W   β = ε−1

W + (r − 1)ε−1

W I.

(13)

now ready to state our relaxation of (10):

minW∈Rd×m Σc∈Sc ℓc(W ) + λtrW ΠΣ−1

c (W Π)⊤ .

(15)

4

c = minΣc∈Sc trW Σ−1

3.1 Reinterpretation in terms of norms
We denote kWk2
c W T the cluster norm (CN). For any convex set Sc  we ob-
tain a norm on W (that we apply here to its centered version). By putting some different constraints
on the set Sc  we obtain different norms on W   and in fact all previous multi-task formulations may
be cast in this way  i.e.  by choosing a speciﬁc set of positive matrices Sc (e.g.  trace constraint for
the trace norm  and simply a singleton for the Frobenius norm). Thus  designing norms for multi-
task learning is equivalent to designing a set of positive matrices. In this paper  we have investigated
a speciﬁc set adapted for clustered-tasks  but other sets could be designed in other situations.
Note that we have selected a simple spectral convex set Sc in order to make the optimization sim-
pler in Section 3.3  but we could also add some additional constraints that encode the point-wise
positivity of the matrix M. Finally  when r = 1 (one cluster) and r = m (one cluster per task)  we
get back the formulation of [5].

3.2 Reinterpretation as a convex relaxation of K-means
c that we have designed earlier  can be interpreted
In this section we show that the semi-norm kW Πk2
as a convex relaxation of K-means on the tasks [9]. Indeed  given W ∈ Rd×m  K-means aims
to decompose it in the form W = µE⊤ where µ ∈ Rd×r are cluster centers and E represents
a partition. Given E  µ is found by minimizing minµ kW ⊤ − Eµ⊤k2
F . Thus  a natural strategy
outlined by [9]  is to alternate between optimizing µ  the partition E and the weight vectors W . We
now show that our convex norm is obtained when minimizing in closed form with respect to µ and
relaxing.
F . If we add a
By translation invariance  this is equivalent to minimizing minµ kΠW ⊤ − ΠEµ⊤k2
penalization on µ of the form λtrE⊤Eµµ⊤  then a short calculation shows that the minimum with
respect to µ (i.e.  after optimization of the cluster centers) is equal to

trΠW ⊤W Π(ΠE(E⊤E)−1E⊤Π/λ + I)−1 = trΠW ⊤W Π(ΠM Π/λ + I)−1.

By comparing with Eq. (13)  we see that our formulation is indeed a convex relaxation of K-means.

3.3 Primal optimization

Let us now show in more details how (15) can be solved efﬁciently. Whereas a dual formulation
could be easily derived following [8]  a direct approach is to rewrite (15) as

c (W Π)⊤¢

c = minΣc∈Sc trW ΠΣ−1

minW∈Rd×m ¡ℓc(W ) + minΣc∈Sc trW ΠΣ−1

(16)
which  if ℓc is differentiable  can be directly optimized by gradient-based methods on W since
c (W Π)⊤ is a quadratic semi-norm of W Π. This regularization
kW Πk2
term trW ΠΣ−1
c (W Π)⊤ can be computed efﬁciently using a semi-closed form. Indeed  since Σc as
deﬁned in (14) is a spectral set (i.e.  it does depend only on eigenvalues of covariance matrices)  we
obtain a function of the singular values of W Π (or equivalently the eigenvalues of W ΠW ⊤):
minΣc∈Sc trW ΠΣ−1
c (W Π)⊤ = minλ∈Rm  α≤λi≤β  λ1=γ  V ∈Om trW ΠV diag(λ)−1V ⊤(W Π)⊤ 
where Om is the set of orthogonal matrices in Rm×m. The optimal V is the matrix of the eigenvec-
tors of W ΠW ⊤  and we obtain the value of the objective function at the optimum:

minΣ∈S trW ΠΣ−1(W Π)⊤ = minλ∈Rm  α≤λi≤β  λ1=γ Pm

i=1

σ2
i
λi

 

where σ and λ are the vectors containing the singular values of W Π and Σ respectively. Now  we
simply need to be able to compute this function of the singular values.
The only coupling in this formulation comes from the trace constraint. The Lagrangian correspond-
ing to this constraint is:

i=1

(17)
For ν ≤ 0  this is a decreasing function of λi  so the minimum on λi ∈ [α  β] is reached for λi = β.
The dual function is then a linear non-decreasing function of ν (since α ≤ γ/m ≤ β from the
deﬁnition of α  β  γ in (14))  which reaches it maximum value (on ν ≤ 0) at ν = 0. Let us therefore
now consider the dual for ν ≥ 0. (17) is then a convex function of λi. Canceling its derivative with
respect to λi gives that the minimum in λ ∈ R is reached for λi = σi/√ν. Now this may not be

i=1 λi − γ) .

L(λ  ν) = Pm

σ2
i
λi

+ ν (Pm

5

in the constraint set (α  β)  so if σi < α√ν then the minimum in λi ∈ [α  β] of (17) is reached
for λi = α  and if σi > β√ν it is reached for λi = β. Otherwise  it is reached for λi = σi/√ν.
Reporting this in (17)  the dual problem is therefore
β + νβ´− νγ . (18)
maxν≥0Pi α√ν≤σi≤β√ν 2σi√ν +Pi σi<α√ν ³ σ2
Since a closed form for this expression is known for each ﬁxed value of ν  one can obtain kW Πk2
c
(and the eigenvalues of Σ∗) by Algorithm 1. The cancellation condition in Algorithm 1 is that the

α + να´ +Pi β√ν<σi ³ σ2

i

i

c

Algorithm 1 Computing kAk2
Require: A  α  β  γ.
Ensure: kAk2
c  λ∗.
Compute the singular values σi of A.
Order the σ2
for all interval (a  b) of I do

α2   σ2

i

i

β2 in a vector I (with an additional 0 at the beginning).

if ∂L(λ∗ ν)

∂ν

is canceled on ν ∈ (a  b) then

Replace ν∗ in the dual function L(λ∗  ν) to get kAk2
return kAk2

c  λ∗.

c  compute λ∗ on (a  b).

end if
end for

value canceling the derivative belongs to (a  b)  i.e. 

γ−(αn−+βn+) ´2
ν = ³ Pi α√ν≤σi≤β√ν σi

∈ (a  b)  

where n− and n+ are the number of σi < α√ν and σi > β√ν respectively. Denoting kAk2
c =
F (A  Σ∗(A))  ∇AF = ∂AF + ∂ΣF ∂AΣ cannot be computed because of the non-differentiable
constraints on Σ for F . We followed an alternative direction  using only the ∂AF part.

4 Experiments

4.1 Artiﬁcial data

c )  σ2

We generated synthetic data consisting of two clusters of two tasks. The tasks are vectors of Rd  d =
30. For each cluster  a center ¯wc was generated in Rd−2  so that the two clusters be orthogonal. More
precisely  each ¯wc had (d − 2)/2 random features randomly drawn from N (0  σ2
r = 900  and
(d − 2)/2 zero features. Then  each tasks t was computed as wt + ¯wc(t)  where c(t) was the cluster
of t. wt had the same zero feature as its cluster center  and the other features were drawn from
c = 16. The last two features were non-zero for all the tasks and drawn from N (0  σ2
c ).
N (0  σ2
n = 150 was added.
For each task  2000 points were generated and a normal noise of variance σ2
c with the single-task learning given by the
In a ﬁrst experiment  we compared our cluster norm k.k2
Frobenius norm  and with the trace norm  that corresponds to the assumption that the tasks live in a
low-dimension space. The multi-task kernel approach being a special case of CN  its performance
will always be between the performance of the single task and the performance of CN.
In a second setting  we compare CN to alternative methods that differ in the way they learn Σ:

r )  σ2

• The True metric approach  that simply plugs the actual clustering in E and optimizes W
using this ﬁxed metric. This necessitates to know the true clustering a priori  and can be
thought of like a golden standard.

• The k-means approach  that alternates between optimizing the tasks in W given the metric
Σ and re-learning Σ by clustering the tasks wi [9]. The clustering is done by a k-means run
3 times. This is a non convex approach  and different initialization of k-means may result
in different local minima.

We also tried one run of CN followed by a run of True metric using the learned Σ reprojected
in Sr by rounding  i.e.  by performing k-means on the eigenvectors of the learned Σ (Reprojected
approach)  and a run of k-means starting from the relaxed solution (CNinit approach).

6

Only the ﬁrst method requires to know the true clustering a priori  all the other methods can be run
without any knowledge of the clustering structure of the tasks.
Each method was run with different numbers of training points. The training points were equally
separated between the two clusters and for each cluster  5/6th of the points were used for the ﬁrst
task and 1/6th for the second  in order to simulate a natural setting were some tasks have fewer data.
We used the 2000 points of each task to build 3 training folds  and the remaining points were used
for testing. We used the mean RMSE across the tasks as a criterion  and a quadratic loss for ℓ(W ).
The results of the ﬁrst experiment are shown on Figure 1 (left). As expected  both multi-task ap-
proaches perform better than the approach that learns each task independently. CN penalization on
the other hand always gives better testing error than the trace norm penalization  with a stronger ad-
vantage when very few training points are available. When more training points become available 
all the methods give more and more similar performances. In particular  with large samples  it is not
useful anymore to use a multi-task approach.

35

30

25

20

15

E
S
M
R

 
10
3

3.5

4

4.5

5

5.5

Number of training points (log)

 

Frob
Trace
CN

32

30

28

26

24

22

20

18

16

E
S
M
R

6

6.5

 
14
3

3.5

4

4.5

5

5.5

Number of training points (log)

 

CN
KM
True
Repr

6

6.5

Figure 1: RMSE versus number of training points for the tested methods.

Figure 2: Recovered Σ with CN (upper line) and k-means (lower line) for 28  50 and 100 points.

Figure 1 (right) shows the results of the second experiment. Using the true metric always gives the
best results. For 28 training points  no method recovers the correct clustering structure  as displayed
on Figure 2  although CN performs slightly better than the k-means approach since the metric it
learns is more diffuse. For 50 training points  CN performs much better than the k-means approach 
which completely fails to recover the clustering structure as illustrated by the Σ learned for 28 and
50 training points on Figure 2. In the latter setting  CN partially recovers the clusters. When more
training points become available  the k-means approach perfectly recovers the clustering structure
and outperforms the relaxed approach. The reprojected approach  on the other hand  performs al-
ways as well as the best of the two other methods. The CNinit approach results are not displayed
since the are the same as for the reprojected method.

4.2 MHC-I binding data

We also applied our method to the IEDB MHC-I peptide binding benchmark proposed in [10]. This
database contains binding afﬁnities of various peptides  i.e.  short amino-acid sequences  with dif-
ferent MHC-I molecules. This binding process is central in the immune system  and predicting it is
crucial  for example to design vaccines. The afﬁnities are thresholded to give a prediction problem.
Each MHC-I molecule is considered as a task  and the goal is to predict whether a peptide binds a
molecule. We used an orthogonal coding of the amino acids to represent the peptides and balanced

7

Table 1: Prediction error for the 10 molecules with less than 200 training peptides in IEDB.

Method
Test error

Pooling

26.53% ± 2.0

Frobenius norm Multi-task kernel
11.62% ± 1.4
10.10% ± 1.4

Trace norm Cluster norm
9.20% ± 1.3
8.71% ± 1.5

the data by keeping only one negative example for each positive point  resulting in 15236 points
involving 35 different molecules. We chose a logistic loss for ℓ(W ).
Multi-task learning approaches have already proved useful for this problem  see for example [11 
12]. Besides  it is well known in the vaccine design community that some molecules can be grouped
into empirically deﬁned supertypes known to have similar binding behaviors.
[12] showed in particular that the multi-task approaches were very useful for molecules with few
known binders. Following this observation  we consider the mean error on the 10 molecules with
less than 200 known ligands  and report the results in Table 1. We did not select the parameters by
internal cross validation  but chose them among a small set of values in order to avoid overﬁtting.
More accurate results could arise from such a cross validation  in particular concerning the number
of clusters (here we limited the choice to 2 or 10 clusters).
The pooling approach simply considers one global prediction problem by pooling together the data
available for all molecules. The results illustrate that it is better to consider individual models than
one unique pooled model.On the other hand  all the multitask approaches improve the accuracy  the
cluster norm giving the best performance. The learned Σ  however  did not recover the known super-
types  although it may contain some relevant information on the binding behavior of the molecules.

5 Conclusion

We have presented a convex approach to clustered multi-task learning  based on the design of a
dedicated norm. Promising results were presented on synthetic examples and on the IEDB dataset.
We are currently investigating more reﬁned convex relaxations and the natural extension to non-
linear multi-task learning as well as the inclusion of speciﬁc features on the tasks  which has shown
to improve performance in other settings [6].

References
[1] G. Wahba. Spline Models for Observational Data  volume 59 of CBMS-NSF Regional Conference Series

in Applied Mathematics. SIAM  Philadelphia  1990.

[2] F. Girosi  M. Jones  and T. Poggio. Regularization Theory and Neural Networks Architectures. Neural

Comput.  7(2):219–269  1995.

[3] R. Tibshirani. Regression shrinkage and selection via the lasso. J. Royal. Stat. Soc. B.  58:267–288  1996.
[4] B. Bakker and T. Heskes. Task clustering and gating for bayesian multitask learning. J. Mach. Learn.

Res.  4:83–99  2003.

[5] T. Evgeniou  C. Micchelli  and M. Pontil. Learning multiple tasks with kernel methods. J. Mach. Learn.

Res.  6:615–637  2005.

[6] J. Abernethy  F. Bach  T. Evgeniou  and J.-P. Vert. Low-rank matrix factorization with attributes. Technical

Report cs/0611124  arXiv  2006.

[7] A. Argyriou  T. Evgeniou  and M. Pontil. Multi-task feature learning.

In B. Sch¨olkopf  J. Platt  and

T. Hoffman  editors  Adv. NIPS 19  pages 41–48  Cambridge  MA  2007. MIT Press.

[8] G.R.G. Lanckriet  N. Cristianini  P. Bartlett  L. El Ghaoui  and M.I. Jordan. Learning the Kernel Matrix

with Semideﬁnite Programming. J. Mach. Learn. Res.  5:27–72  2004.

[9] M. Deodhar and J. Ghosh. A framework for simultaneous co-clustering and learning from complex data.

In KDD ’07  pages 250–259  New York  NY  USA  2007. ACM.

[10] B. Peters  H.-H Bui  S. Frankild  M. Nielson  C. Lundegaard  E. Kostem  D. Basch  K. Lamberth 
M. Harndahl  W. Fleri  S. S Wilson  J. Sidney  O. Lund  S. Buus  and A. Sette. A community resource
benchmarking predictions of peptide binding to MHC-I molecules. PLoS Comput Biol  2(6):e65  2006.

[11] D. Heckerman  D. Kadie  and J. Listgarten. Leveraging information across HLA alleles/supertypes im-

proves epitope prediction. J. Comput. Biol.  14(6):736–746  2007.

[12] L. Jacob and J.-P. Vert. Efﬁcient peptide-MHC-I binding prediction for alleles with few known binders.

Bioinformatics  24(3):358–366  Feb 2008.

8

,Siddartha Ramamohan
Arun Rajkumar
Shivani Agarwal
Shivani Agarwal