2011,Exploiting spatial overlap to efficiently compute appearance distances between image windows,We present a computationally efficient technique to compute the distance of high-dimensional appearance descriptor vectors between image windows.  The method exploits the relation between appearance distance and spatial overlap.  We derive an upper bound on appearance distance given the spatial overlap of two windows in an image   and use it to bound the distances of many pairs between two images.  We propose algorithms that build on these basic operations to efficiently solve tasks relevant to many computer vision applications  such as finding all pairs of windows between two images with distance smaller than a threshold   or finding the single pair with the smallest distance. In experiments on the PASCAL VOC 07 dataset  our algorithms accurately solve these problems while greatly reducing the number of appearance distances computed  and achieve larger speedups than approximate nearest neighbour algorithms based on trees [18]and on hashing [21].    For example  our algorithm finds the most similar pair of windows between two images while computing only 1% of all distances on average.,Exploiting spatial overlap to efﬁciently compute
appearance distances between image windows

Bogdan Alexe
ETH Zurich

Viviana Petrescu

ETH Zurich

Vittorio Ferrari

ETH Zurich

Abstract

We present a computationally efﬁcient technique to compute the distance of high-
dimensional appearance descriptor vectors between image windows. The method
exploits the relation between appearance distance and spatial overlap. We derive
an upper bound on appearance distance given the spatial overlap of two windows
in an image  and use it to bound the distances of many pairs between two images.
We propose algorithms that build on these basic operations to efﬁciently solve
tasks relevant to many computer vision applications  such as ﬁnding all pairs of
windows between two images with distance smaller than a threshold  or ﬁnding
the single pair with the smallest distance. In experiments on the PASCAL VOC 07
dataset  our algorithms accurately solve these problems while greatly reducing the
number of appearance distances computed  and achieve larger speedups than ap-
proximate nearest neighbour algorithms based on trees [18] and on hashing [21].
For example  our algorithm ﬁnds the most similar pair of windows between two
images while computing only 1% of all distances on average.

Introduction

1
Computing the appearance distance between two windows is a fundamental operation in a wide
variety of computer vision techniques. Algorithms for weakly supervised learning of object
classes [7  11  16] typically compare large sets of windows between images trying to ﬁnd recurring
patterns of appearance. Sliding-window object detectors based on kernel SVMs [13  24] compute
appearance distances between the support vectors and a large number of windows in the test image.
In human pose estimation  [22] computes the color histogram dissimilarity between many candidate
windows for lower and upper arms. In image retrieval the user can search a large image database for
a query object speciﬁed by an image window [20]. Finally  many tracking algorithms [4  5] compare
a window around the target object in the current frame to all windows in a surrounding region of the
next frame.
In most cases one is not interested in computing the distance between all pairs of windows from two
sets  but in a small subset of low distances  such as all pairs below a given threshold  or the single
best pair. Because of this  computer vision researchers often rely on efﬁcient nearest neighbour
algorithms [2  6  10  17  18  21]. Exact nearest neighbour algorithms organize the appearance
descriptors into trees which can be efﬁciently searched [17]. However  these methods work well only
for descriptors of small dimensionality n (typically n < 20)  and their speedup vanishes for larger
n (e.g. the popular GIST descriptor [19] has n = 960). Locality sensitive hashing (LSH [2  10  21])
techniques hash the descriptors into bins  so that similar descritors are mapped to the same bins with
high probability. LSH is typically used for efﬁciently ﬁnding approximate nearest neighbours in
high dimensions [2  6].
All the above methods consider windows only as points in appearance space. However  windows
exist also as points in the geometric space deﬁned as their 4D coordinates in the image they lie in. In
this geometric space  a natural distance between two windows is their spatial overlap (ﬁg. 1). In this
paper we propose to take advantage of an important relation between the geometric and appearance
spaces: the apparance distance between two windows decreases as their spatial overlap increases.
We derive an upper bound on the appearance distance between two windows in the same image 

1

Fig. 1: Relation between spatial overlap and appearance distance. Windows w1  w2 in an image I are
embedded in geometric space and in appearance space. All windows overlapping more than r with w1 are at
most at distance B(r) in appearance space. The bound B(r) decreases as overlap increases (i.e. r decreases).

given their spatial overlap (sec. 2). We then use this bound in conjuction with the triangle inequality
to bound the appearance distances of many pairs of windows between two images  given the distance
of just one pair. Building on these basic operations  we design algorithms to efﬁciently ﬁnd all pairs
with distance smaller than a threshold (sec. 3) and to ﬁnd the single pair with the smallest distance
(sec. 4).
The techniques we propose reduce computation by minimizing the number of times appearance
distances are computed. They are complementary to methods for reducing the cost of computing
one distance  such as dimensionality reduction [15] or Hamming embeddings [14  23].
We experimentally demonstrate in sec. 5 that the proposed algorithms accurately solve the above
problems while greatly reducing the number of appearance distances computed. We compare to
approximate nearest neighbour algorithms based on trees [18]  as well as on the recent LSH tech-
nique [21]. The results show our techniques outperform them in the setting we consider  where the
datapoints are embedded in a space with additional overlap structure.

2 Relation between spatial overlap and appearance distance
Windows w in an image I are emdebbed in two spaces at the same time (ﬁg. 1).
In geometric
space  w is represented by its 4 spatial coordinates (e.g. x  y center  width  height). The distance
between two windows is deﬁned based on their spatial overlap o(w1  w2) = |w1\w2|
|w1[w2| 2 [0  1] 
where \ denotes the area of the intersection and [ the area of the union. In appearance space  w
is represented by a high dimensional vector describing the pixel pattern inside it  as computed by
a function fapp(w) : I ! Rn (e.g. the GIST descriptor has n = 960 dimensions). In appearance
space  two windows are compared using a distance d(fapp(w1)  fapp(w2)).
Two overlapping windows w1  w2 in an image I share the pixels contained in their intersection
(ﬁg. 1). The spatial overlap of the two windows correlates with the proportion of common pixels
input to fapp when computing the descriptor for each window. In general  fapp varies smoothly with
the geometry of w  so that windows of similar geometry are close in appearance space. Conse-
quently  the spatial overlap o and appearance distance d are related. In this paper we exploit this
relation to derive an upper bound B(o(w1  w2)) on the appearance distance between two overlapping
windows.
We present here the general form of the bound B  its main properties and explain why it is useful. In
subsections 2.1 and 2.2 we derive the actual bound itself. To simplify the notation we use d(w1  w2)
to denote the appearance distance d(fapp(w1)  fapp(w2)). We refer to it simply as distance and we
say overlap for spatial overlap. The upper bound B is a function of the overlap o(w1  w2)  and has
the following property

d(w1  w2) B (o(w1  w2))

8w1  w2

Moreover  B is a monotonic decreasing function

B(o1) B (o2)

8o1  o2

2

(1)

(2)

(a)

(b)

(c)

Fig. 2: Triangle inequality in appearance space.
points fapp(w1)  fapp(w2) and fapp(w3) in appearance space.
|d(w1  w2)  d(w2  w3)| = d(w1  w3); (c) Upper bound case: d(w1  w3) = d(w1  w2) + d(w2  w3).
This property means B continuously decreases as overlap increases. Therefore  all pairs of windows
within an overlap radius r (i.e. o(w1  w2)  r) have distance below B(r) (ﬁg. 1)
8w1  w2  o(w1  w2)  r
(3)

The triangle inequality (4) holds for any three
(a) General case; (b) Lower bound case:

d(w1  w2) B (o(w1  w2)) B (r)

As deﬁned above  B bounds the appearance distance between two windows in the same image.
Now we show how it can be used to derive a bound on the distances between windows in two
different images I 1  I 2. Given two windows w1  w2 in I 1 and a window w3 in I 2  we use the
triangle inequality to derive (ﬁg. 2)

|d(w1  w2)  d(w2  w3)| d(w1  w3)  d(w1  w2) + d(w2  w3)

Using the bound B in eq. (4) we obtain

max(0  d(w2  w3) B (o(w1  w2)))  d(w1  w3) B (o(w1  w2)) + d(w2  w3)

(4)

(5)

Eq. (5) delivers lower and upper bounds for d(w1  w3) without explicitly computing it (given that
d(w2  w3) and o(w1  w2) are known). These bounds will form the basis of our algorithms for reduc-
ing the number of times the appearance distance is computed when solving two classic tasks (sec. 3
and 4).
In the next subsection we estimate B for arbitrary window descriptors (e.g. color histograms  bag of
visual words  GIST [19]  HOG [8]) from a set of images (no human annotation required). In sub-
section 2.2 we derive exact bounds in closed form for histogram descriptors (e.g. color histograms 
bag of visual words [25]).

2.1 Statistical bounds for arbitrary window descriptors
We estimate B↵ from training data so that eq. (1) holds with probability ↵
P ( d(w1  w2) B ↵(o(w1  w2)) ) = ↵ 8w1  w2

(6)

B↵ is estimated from a set of M training images I = {I m}. For each image I m we sample N
j ) and distance
windows {wm
ij ) for every window pair
ij = d(wm
dm
(7)

i }  and then compute for all window pairs their overlap om
j ). The overall training dataset D is composed of (om
i   wm

ij = o(wm
ij   dm
ij ) | k 2{ 1  M}   i  j 2{ 1  N}}

D = { (om

i   wm

ij   dm

We now quantize the overlap values into 100 bins and estimate B↵(o) for each bin o separately. For
ij is in the bin. We choose B↵(o) as
a bin o  we consider the set Do of all distances dm
the ↵-quantile of D(o) (ﬁg. 3a)

ij for which om

B↵(o) = q↵(Do)

(8)

ij for which om

B1(o) is the largest distance dm
ij is in bin o. Fig. 3a shows the binned distance-
overlap pairs and the bound B0.95 for GIST descriptors [19]. The data comes from 100 windows
sampled from more than 1000 images (details in sec. 5). Each column of this matrix is roughly
Gaussian distributed  and its mean continuously decreases with increasing overlap  conﬁrming our
assumptions about the relation between overlap and distance (sec. 2). In particular  note how the
mean distance decrease fastest for 50% to 80% overlap.

3

(a)

(b)

Fig. 3: Estimating B0.95(o) and omin(✏). (a) The estimated B0.95(o) (white line) for the GIST [19] appear-
ance descriptor. (b) Using B0.95(o) we derive omin(✏).
Given a window w1 and a distance ✏ we can use B↵ to ﬁnd windows w2 overlapping with w1
that are at most distance ✏ from w1. This will be used extensively by our algorithms presented in
secs. 3 and 4. From B↵ we can derive what is the smallest overlap omin(✏) so that all pairs of
windows overlapping more than omin(✏) have distance smaller than ✏ (with probability more than
↵). Formally

P ( d(w1  w2)  ✏ )  ↵ 8w1  w2  o(w1  w2)  omin(✏)

and omin(✏) is deﬁned as the smallest overlap o for which the bound is smaller than ✏ (ﬁg. 3b)

omin(✏) = min{o | B↵(o)  ✏}

(9)

(10)

2.2 Exact bounds for histogram descriptors
The statistical bounds of the previous subsection can be estimated from images for any appearance
descriptor. In contrast  in this subsection we derive exact bounds in closed form for histogram de-
scriptors (e.g. color histograms  bag of visual words [25]). Our derivation applies to L1-normalized
histograms and the 2 distance. For simplicity of presentation  we assume every pixel contributes
one feature to the histogram of the window (as in color histograms). The derivation is very similar
for features computed on another regular grid (e.g. dense SURF bag-of-words [11]). We present
here the main idea behind the bound and give the full derivation in the supplementary material [1].
The upper bound B for two windows w1 and w2 corresponds to the limit case where the three
regions w1 \ w2  w1 \ w2 and w2 \ w1 contain three disjoint sets of colors (or visual word in
general). Therefore  the upper bound B is
B(w1  w2) = |w1 \ w2|
|w1|

+ |w1 \ w2| ·⇣ 1

|w2|⌘2
|w1|  1
+ 1
1
|w1|
|w2|

+ |w2 \ w1|

|w2|

(11)

Expressing the terms in (11) based on the windows overlap o = o(w1  w2) = |w1\w2|
|w1[w2|
closed form for the upper bound B that depends only on o

B(w1  w2) = B(o(w1  w2)) = B(o) = 2  4 ·

o

o + 1

  we obtain a

(12)

In practice  this exact bound is typically much looser than its corresponding statistical bound learned
from data (sec. 2.1). Therefore  we use the statistical bound for the experiments in sec. 5.

3 Efﬁciently computing all window pairs with distance smaller than ✏
In this section we present an algorithm to efﬁciently ﬁnd all pairs of windows with distance smaller
than a threshold ✏ between two images I 1  I 2. Formally  given an input set of windows W 1 = {w1
i }
in image I 1 and a set W 2 = {w2
j} in image I 2  the algorithm should return the set of pairs P✏ =
{ (w1
j )  ✏ }.
Algorithm overview. Algorithm 1 summarizes our technique. Block 1 randomly samples a small
set of seed pairs  for which it explicly computes distances. The core of the algorithm (Block 3)
explores pairs overlapping with a seed  looking for all appearance distances smaller than ✏. When

j ) | d(w1

i   w2

i   w2

4

Algorithm 1 Efﬁciently computing all distances smaller than ✏
Input: windows W m = {wm
Output: set P✏ of all pairs p with d(p)  ✏

i }  threshold ✏  lookup table omin  number of initial samples F

1. Compute seed pairs PF

(a) sample F random pairs pij = (w1
(b) compute dij = d(w1

i   w2
j )  8pij 2P F

i   w2

j ) from P = W 1 ⇥W 2  giving PF

2. Determine a sequence S of all pairs from P (gives schedule of block 3 below)

(a) sort the seed pairs in PF in order of decreasing distance
(b) set S(1 : F ) = PF
(c) ﬁll S((F + 1) : end) with random pairs from P \ PF

3. For pc = S(1 : end) (explore the pairs in the S order)

(a) compute d(pc)
(b) if d(pc)  ✏

i. let r = omin(✏  d(pc))
ii. let N = overlap neighborhood(pc  r)
iii. for all pairs p 2N : compute d(p)
iv. update P✏ P ✏ [{ p 2N | d(p)  ✏}
i. let r = omin(d(pc)  ✏)
ii. let N = overlap neighborhood(pc  r)
iii. discard all pairs in N from S: S S \ N

(c) else

j )  overlap radius r

i   w2

i   w2

overlap neighborhood
Input: pair pij = (w1
Output: overlap neighborhood N of pij
N = { (w1
compute
Input: pair pij
Output: If d(w1
d(w1

v) | o(w2

i   w2

j   w2

i   w2

j ) is already in D  then directly return it.

v)  r }[{ (w1

u  w2

j ) | o(w1

i   w1

u)  r }

j ) was never computed before  then compute it and store it in a table D.

If

exploring a seed  the algorithm can decide to discard many pairs overlapping with it  as the bound
predicts that their distance cannot be lower than ✏. This causes the computational saving (step 3.c).
Before starting Block 3  Block 2 establishes the sequence in which to explore the seeds  i.e. in order
of decreasing distance. The remaining pairs are appended in random order afterwards.
Algorithm core. Block 3 takes one of two actions based on the distance of the pair pc currently
being explored. If d(pc)  ✏  then all pairs in the overlap neighborhood N of pc have distance
smaller than ✏. This overlap neighborhood has a radius r = omin(✏  d(pc)) predicted by the
bound lookup table omin (ﬁg. 4a). Therefore  Block 3 computes the distance of all pairs in N
(step 3.b). Instead  if d(pc) >✏   Block 3 determines the radius r = omin(d(pc)  ✏) of the overlap
neighborhood containing pairs with distance greater than ✏  and then discards all pairs in it (step 3.c).
j ) with radius r con-
Overlap neighborhood. The overlap neighborhood of a pair pij = (w1
tains all pairs (w1
u)  r
(ﬁg. 4a).

v)  r  and all pairs (w1

j ) such that o(w1

v) such that o(w2

u  w2

i   w2

j   w2

i   w1

i   w2

4 Efﬁciently computing the single window pair with the smallest distance
We give an algorithm to efﬁciently ﬁnd the single pair of windows with the smallest appearance
distance between two images. Given as input the two sets of windows W 1 W 2  the algorithm
should return the pair p⇤ = (w1
j ).
i   w2

j⇤) with the smallest distance: d(w1

j⇤) = minij d(w1

i⇤  w2

i⇤  w2

5

(a)

(b)

Fig. 4: Overlap neighborhoods. (a) The overlap neighborhood of radius r of a pair (w1
blue pairs. (b) The joint overlap neighborhood of radius s of a pair (w1

j ) contains all
j ) contains all blue and green pairs.

i   w2

i   w2

Algorithm overview. Algorithm 2 is analog to Algorithm 1. Block 1 computes distances for the
seed pairs and it selectes the pair with the smallest distance as initial approximation to p⇤. Block 3
explores pairs overlapping with a seed  looking for a distance smaller than d(p⇤). When exploring a
seed  the algorithm can decide to discard many pairs overlapping with it  as the bound predicts they
cannot be better than p⇤. Block 2 organizes the seeds in order of increasing distance. In this way 
the algorithm can rapidly reﬁne p⇤ towards smaller and smaller values. This is useful because in
step 3.c  the amount of discarded pairs is greater as d(p⇤) gets smaller. Therefore  this seed ordering
maximises the number of discarded pairs (i.e. minimizes the number of distances computed).
Algorithm core. Block 3 takes one of two actions based on d(pc). If d(pc)  d(p⇤) + B↵(s) 
then there might be a better pair than d(p⇤) within radius s in the joint overlap neighborhood of
pc. Therefore  the algorithm computes the distance of all pairs in this neighborhood (step 3.b). The
radius s is an input parameter. Instead  if d(pc) > d(p⇤) + B↵(s)  the algorithm determines the
radius r = omin(d(pc)  d(p⇤)) of the overlap neighborhood that contains only pairs with distance
greater than d(p⇤)  and then discards all pairs in it (step 3.c).
Joint overlap neighborhood. The joint overlap neighborhood of a pair pij = (w1
j ) with
radius s contains all pairs (w1

v) such that o(w1

u  w2

i   w2

i   w1

u)  s and o(w2

j   w2

v)  s.

5 Experiments and conclusions
We present experiments on a test set composed of 1000 image pairs from the PASCAL VOC 07
dataset [12]  randomly sampled under the constraint that two images in a pair contain at least one
object of the same class (out of 6 classes: aeroplane  bicycle  bus  boat  horse  motorbike). This
setting is relevant for various applications  such as object detection [13  24]  and ensures a balanced
distribution of appearance distances in each image pair (some pairs of windows will have a low
distance while others high distances). We experiment with three appearance descriptors: GIST [19]
(960D)  color histograms (CHIST  4000D)  and bag-of-words [11  25] on the dense SURF descrip-
tor [3] (BOW  2000D). As appearance distances we use the Euclidean for GIST  and 2 for CHIST
and SURF BOW. The bound tables B↵ for each descriptor were estimated beforehand from a sepa-
rate set of 1300 images of other classes (sec. 2.1).
Task 1: all pairs of windows with distance smaller than ✏. The task is to ﬁnd all pairs of win-
dows with distance smaller than a user-deﬁned threshold ✏ between two images I 1  I 2 (sec. 3). This
task occurs in weakly supervised learning of object classes [7  11  16]  where algorithms search for
recurring patterns over training images containing thousands of overlapping windows  and in human
pose estimation [22]  which compares many overlapping candidate body part locations.
We random sample 3000 windows in each image (|W 1| = |W 2| = 3000) and set ✏ so that 10%
of all distances are below it. This makes the task meaningful for any image pair  regardless of the
range of distances it contains. For each image pair we quantify performance with two measures: (i)
cost: the number of computed distances divided by the total number of window pairs (9 millions);
(i) accuracy:
rithm  and the denominator sums over all distances truly below ✏. The lowest possible cost while
still achieving 100% accuracy is 10%.
We compare to LSH [2  6  10] using [21] as a hash function. It maps descriptors to binary strings 
such that the Hamming distance between two strings is related to the value of a Gaussian kernel
between the original descriptors [21]. As recommended in [6  10]  we generate T separate (random)
encodings and build T hash tables  each with 2C bins  where C is the number of bits in the encoding.

P{p2W1⇥W2|d(p)✏}(✏d(p))  where P✏ is the set of window pairs returned by the algo-

Pp2P✏

(✏d(p))

6

Algorithm 2 Efﬁciently computing the smallest distance
Input: windows W m = {wm
Output: pair p⇤ with the smallest distance

i }  lookup table omin  search radius s  number of initial samples F

estimate current best pair: p⇤ = arg minpij2PF dij

1. Compute seed pairs PF (as Block 1 of Algorithm 1) and
2. Determine a sequence S of all pairs (as Block 2 of Algorithm 1)
3. For pc = S(1 : end) (explore the pairs in the S order)

(a) compute d(pc)
(b) if d(pc)  d(p⇤) + B↵(s)

(c) else

i. let N = joint overlap neighborhood(pc  s)
ii. for all pairs p 2N : compute d(p)
iii. update p⇤ arg min {{d(p⇤)}[{ d(p) | p 2 N}}
i. let r = omin(d(pc)  d(p⇤))
ii. let N = overlap neighborhood(pc  r)
iii. discard all pairs in N from S: S S \ N

joint overlap neighborhood
j )  overlap radius s
Input pair pij = (w1
Output: joint overlap neighborhood N of pij
N = { (w1
j   w2

u)  s  o(w2

v) | o(w1

i   w2

u  w2

i   w1

v)  s }

j 2 b1
i   w2

i into its bin b1

To perform Task 1  we loop over each table t and do: (H1) hash all w2
j 2W 2 into table t; (H2) for
t i; (H2.2) compute all distances d in the original
each w1
i 2W 1 do: (H2.1) hash w1
i and all windows w2
space between w1
t i (unless already computed when inspecting a previous
table); (H3) return all computed d(w1
j )  ✏.
We also compare to approximate nearest-neighbors based on kd-trees  using the ANN library [18].
To perform Task 1  we do: (A1) for each w1
i 2W 1 do: (A1.1) compute the ✏-NN between w1
i
and all windows w2
j 2W 2 and return them all. The notion of cost above is not deﬁned for ANN
methods based on trees. Instead  we measure wall clock runtime. Instead  we report as cost the ratio
of the runtime of approximate NN over the runtime of exact NN (also computed using the ANN
library [18]). This gives a meaningful indication of speedup  which can be compared to the cost we
report for our method and LSH. As the ANN library supports only the Euclidean distance  we report
results only for GIST.
The results table reports cost and accuracy averaged over the test set. Our method from sec. 3
performs very well for all three descriptors. On average it achieves 98% accuracy at 16% cost. This
is a considerable speedup over exhaustive search  as it means only 7% of the 90% distances greater
than ✏ have been computed. The behavior of LSH depends on T and C. The higher the T   the
higher the accuracy  but also the cost (because there are more collisions; the same holds for lower
C). To compare fairly  we evaluate LSH over T 2{ 1  20} and C 2{ 2  30} and report results for
the T  C that deliver the closest accuracy to our method. As the table shows  on average over the
three descriptors  for same accuracy LSH has cost 92%  substantially worse than our method. The
behavior of ANN depends on the degree of approximation which we set so as to get accuracy closest
to our method. At 92% accuracy  ANN has 72% of the runtime of exact NN. This shows that  if high
accuracy is desired  ANN offers only a modest speedup (compared to our 18% cost for GIST).

Task 2: all windows closer than ✏ to a query. This is a special case of Task 1  where W 1 contains
just one window. Hence  this becomes a ✏-nearest-neighbours task where W 1 acts as a query and
W 2 as the retrieval database. This task occurs in many applications  e.g. object detectors based
on kernel SVMs compare a support vector (query) to a large set of overlapping windows in the test
image [13  24]. As this is expensive  many detectors resort to linear kernels [9]. Our algorithms

7

method

GIST + Euclidean distance
accuracy
97.3%
95.4%
91.9%

cost
18.0%
86.2%
71.8%

our
LSH
ANN

method

our
LSH
ANN

method

our
LSH
ANN

method

our
LSH
ANN

cost
30.2%
73.4%
72.6%

accuracy
87.1%
83.5%
87.7%

method

our
LSH
ANN

ratio
cost
2.3%
1.02
16.4% 1.03
58.6% 1.01

rank method
1.39
2.72
1.48

our
LSH
ANN

CHIST + 2 distance

accuracy
97.7%
97.2%

accuracy
96.2%
95.1%

-

-

Task 1

cost
15.7%
93.7%

-
Task 2
cost
30.3%
96.9%

-
Task 3
ratio
cost
0.4%
1.01
37.5% 1.02

-

-

method

SURF BOW + 2 distance
accuracy
98.5%
98.5%

cost
15.2%
96.8%

our
LSH
ANN

-

method

our
LSH
ANN

cost
28.6%
88.7%

-

accuracy
94.0%
92.1%

-

rank method
1.12
33.5

our
LSH
ANN

-

ratio
cost
0.7%
1.01
46.5% 1.01

-

rank
1.19
9.62

-

-

-

offer the option to use more complex kernels while retaining a practical speed. Other applications
include tracking in video [4  5] and image retrieval [20] (see beginning of sec. 1).
As the table shows  our method is somewhat less efﬁcient than on Task 1. This makes sense  as it
can only exploit overlap structure in one of the two input sets. Yet  for a similar accuracy it offers
greater speedup than LSH and ANN.
Task 3: single pair of windows with smallest distance. The task is to ﬁnd the single pair of
windows with the smallest distance between I 1 and I 2  out of 3000 windows in each image (sec. 4) 
and has similar applications as Task 1.
We quantify performance with three measures: (i) cost: as in all other tasks. (ii) distance ratio: the
ratio between the smallest distance returned by the algorithm and the true smallest distance. The
best possible value is 1  and higher values are worse; (iii) rank: the rank of the returned distance
among all 9 million.
To perform Task 3 with LSH  we simply modify step (H3) of the procedure given for Task 1 to:
return the smallest distance among all those computed. To perform Task 3 with ANN we replace
i in W 2. At the end of loop (A1) return the smallest distance
step (A1.1) with: compute the NN of w1
among all those computed.
As the table shows  on average over the three descriptors  our method from sec. 4 achieves a distance
ratio of 1.01 at 1.1% cost  which is almost a 100⇥ faster than exhaustive search. The average rank of
the returned distance is 1.25 out of 9 millions  which is almost a perfect result. When compared at a
similar distance ratio  our method is considerably more efﬁcient than LSH and ANN. LSH computes
33.3% of all distances  while ANN brings only a speedup of factor 2 over exact NN.
Runtime considerations. While we have measured only the number of computed appearance dis-
tances  our algorithms also compute spatial overlaps. Crucially  spatial overlaps are computed in the
4D geometric space  compared to 1000+ dimensions for the appearance space. Therefore  comput-
ing spatial overlaps has negligible impact on the total runtime of the algorithms. In practice  when
using 5000 windows per image with 4000D dense SURF BOW descriptors  the total runtime of our
algorithms is 71s for Task 1 or 16s for Task 3  compared to 335s for exhaustive search. Impor-
tantly  the cost of computing the descriptors is small compared to the cost of evaluating distances 
as it is roughly linear in the number of windows and can be implemented very rapidly. In practice 
computing dense SURF BOW for 5000 windows in two images takes 5 seconds.
Conclusions. We have proposed efﬁcient algorithms for computing distances of appearance de-
scriptors between two sets of image windows  by taking advantage of the overlap structure in the
sets. Our experiments demonstrate that these algorithms greatly reduce the number of appearance
distances computed when solving several tasks relevant to computer vision and outperform LSH
and ANN for these tasks. Our algorithms could be useful in various applications. For example 
improving the spatial accuracy of weakly supervised learners [7  11] by using thousands of win-
dows per image  using more complex kernels and detecting more classes in kernel SVM object
detectors [13  24]  and enabling image retrieval systems to search at the window level with any de-
scriptor  rather than returning entire images or be constrained to bag-of-words descriptors [20]. To
encourage these applications  we release our source code at http://www.vision.ee.ethz.ch/˜calvin.

8

References
[1] B. Alexe  V. Petrescu  and V. Ferrari. Exploiting spatial overlap to efﬁciently compute ap-
pearance distances between image windows - supplementary material. In NIPS  2011. Also
available at http://www.vision.ee.ethz.ch/ calvin/publications.html.

[2] A. Andoni and P. Indyk. Near-optimal hashing algorithms for approximate nearest neighbor in

high dimensions. In Communications of the ACM  2008.

[3] H. Bay  A. Ess  T. Tuytelaars  and L. van Gool. SURF: Speeded up robust features. CVIU 

110(3):346–359  2008.

[4] C. Bibby and I. Reid. Robust real-time visual tracking using pixel-wise posteriors. In ECCV 

[5] S. Birchﬁeld. Elliptical head tracking using intensity gradients and color histograms. In CVPR 

2008.

1998.

[6] O. Chum  J. Philbin  M. Isard  and A. Zisserman. Scalable near identical image and shot

detection. In CIVR  2007.

[7] O. Chum and A. Zisserman. An exemplar model for learning object classes. In CVPR  2007.
[8] N. Dalal and B. Triggs. Histogram of Oriented Gradients for Human Detection. In CVPR 

volume 2  pages 886–893  2005.

[9] N. Dalal and B. Triggs. Histogram of oriented gradients for human detection. In CVPR  2005.
[10] M. Datar  N. Immorlica  P. Indyk  and V. Mirrokni. Locality-sensitive hashing scheme based

on p-stable distributions. In SCG  2004.

[11] T. Deselaers  B. Alexe  and V. Ferrari. Localizing objects while learning their appearance. In

ECCV  2010.

[12] M. Everingham  L. Van Gool  C. Williams  J. Winn  and A. Zisserman. The PASCAL Visual

Object Classes Challenge 2007 Results  2007.

[13] H. Harzallah  F. Jurie  and C. Schmid. Combining efﬁcient object localization and image

classiﬁcation. In ICCV  2009.

[14] H. Jegou  M. Douze  and C. Schmid. Hamming embedding and weak geometric consistency

for large-scale image search. In ECCV  2008.

[15] Y. Ke and R. Sukthankar. Pca-sift: A more distinctive representation for local image descrip-

[16] G. Kim and A. Torralba. Unsupervised detection of regions of interest using iterative link

tors. In CVPR  2004.

analysis. In NIPS  2009.

[17] N. Kumar  L. Zhang  and S. Nayar. What is a good nearest neighbors algorithm for ﬁnding

similar patches in images? In ECCV  2008.

[18] D. M. Mount and S. Arya. Ann: A library for approximate nearest neighbor searching  August

[19] A. Oliva and A. Torralba. Modeling the shape of the scene: a holistic representation of the

spatial envelope. IJCV  42(3):145–175  2001.

[20] J. Philbin  O. Chum  M. Isard  J. Sivic  and A. Zisserman. Object retrieval with large vocabu-

laries and fast spatial matching. In CVPR  2007.

[21] M. Raginski and S. Lazebnik. Locality sensitive binary codes from shift-invariant kernels. In

[22] B. Sapp  A. Toshev  and B. Taskar. Cascaded models for articulated pose estimation. In ECCV 

[23] A. Torralba  R. Fergus  and Y. Weiss. Small codes and large image databases for recognition.

[24] A. Vedaldi  V. Gulshan  M. Varma  and A. Zisserman. Multiple kernels for object detection.

[25] J. Zhang  M. Marszalek  S. Lazebnik  and C. Schmid. Local features and kernels for classiﬁ-

cation of texture and object categories: a comprehensive study. IJCV  2007.

NIPS  2009.

2010.

In CVPR  2008.

In ICCV  2009.

2006.

9

,Moritz Hardt
Eric Price
Motoya Ohnishi
Masahiro Yukawa
Mikael Johansson
Masashi Sugiyama