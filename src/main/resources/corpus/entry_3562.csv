2017,Multi-Objective Non-parametric Sequential Prediction,Online-learning research has mainly been focusing on minimizing one objective function. In many real-world applications  however  several objective functions have to be considered simultaneously. Recently  an algorithm for dealing with several objective functions in the i.i.d. case has been presented.  In this paper  we extend the multi-objective framework to the case of stationary and ergodic processes  thus  allowing dependencies among observations. We first identify an asymptomatic lower bound for any prediction strategy and then present an algorithm whose predictions achieve the optimal solution while  fulfilling  any continuous and convex constraining criterion.,Multi-Objective Non-parametric Sequential

Prediction

Guy Uziel

Computer Science Department

Technion - Israel Institute of Technology

guziel@cs.technion.ac.il

Ran El-Yaniv

Computer Science Department

Technion - Israel Institute of Technology

rani@cs.technion.ac.il

Abstract

Online-learning research has mainly been focusing on minimizing one objective
function. In many real-world applications  however  several objective functions
have to be considered simultaneously. Recently  an algorithm for dealing with
several objective functions in the i.i.d. case has been presented. In this paper 
we extend the multi-objective framework to the case of stationary and ergodic
processes  thus allowing dependencies among observations. We ﬁrst identify an
asymptomatic lower bound for any prediction strategy and then present an algorithm
whose predictions achieve the optimal solution while fulﬁlling any continuous and
convex constraining criterion.

1

Introduction

In the traditional online learning setting  and in particular in sequential prediction under uncertainty 
the learner is evaluated by a single loss function that is not completely known at each iteration [6].
When dealing with multiple objectives  since it is impossible to simultaneously minimize all of the
objectives  one objective is chosen as the main function to minimize  leaving the others to be bound
by pre-deﬁned thresholds. Methods for dealing with one objective function can be transformed to
deal with several objective functions by giving each objective a pre-deﬁned weight. The difﬁculty 
however  lies in assigning an appropriate weight to each objective in order to keep the objectives
below a given threshold. This approach is very problematic in real world applications  where the
player is required to to satisfy certain constraints. For example  in online portfolio selection [4]  the
player may want to maximize wealth while keeping the risk (i.e.  variance) contained below a certain
threshold. Another example is the Neyman-Pearson (NP) classiﬁcation paradigm (see  e.g.  [19])
(which extends the objective in classical binary classiﬁcation) where the goal is to learn a classiﬁer
achieving low classiﬁcation error whose type I error is kept below a given threshold.
In the adversarial setting it is known that multiple-objective is generally impossible when the
constraints are unknown a-priory [18]. In the stochastic setting  Mahdavi et al. [17] proposed a
framework for dealing with multiple objectives in the i.i.d. case. They proved that if there exists a
solution that minimizes the main objective function while keeping the other objectives below given
thresholds  then their algorithm will converge to the optimal solution.
In this work  we study online prediction with multiple objectives but now consider the challenging
general case where the unknown underlying process is stationary and ergodic  thus allowing observa-
tions to depend on each other arbitrarily. The (single-objective) sequential prediction under stationary
and ergodic sources  has been considered in many papers and in various application domains. For
example  in online portfolio selection  [12  9  10] proposed non-parametric online strategies that
guarantee  under mild conditions  the best possible outcome. Another interesting example in this
regard is the work on time-series prediction by [2  8  3]. A common theme to all these results is that
the asymptotically optimal strategies are constructed by combining the predictions of many simple

31st Conference on Neural Information Processing Systems (NIPS 2017)  Long Beach  CA  USA.

experts. The above strategies use a countably inﬁnite set of experts  and the guarantees provided
for these strategies are always asymptotic. This is no coincidence  as it is well known that ﬁnite
sample guarantees for these methods cannot be achieved without additional strong assumptions on the
source distribution [7  16]. Approximate implementations of non-parametric strategies (which apply
only a ﬁnite set of experts)  however  turn out to work exceptionally well and  despite the inevitable
approximation  are reported [11  10  9] to signiﬁcantly outperform strategies designed to work in an
adversarial  no-regret setting  in various domains.
The algorithm presented in this paper utilizes as a sub-routine the Weak Aggregating Algorithm
(WAA) of [21]  and [13] to handle multiple objectives. While we discuss here the case of only two
objective functions  our theorems can be extended easily to any ﬁxed number of functions.

2 Problem Formulation
We consider the following prediction game. Let X (cid:44) [−D  D]d ⊂ Rd be a compact observation
space where D > 0. At each round  n = 1  2  . . .  the player is required to make a prediction yn ∈ Y 
where Y ⊂ Rm is a compact and convex set  based on past observations  X n−1
(cid:44) (x1  . . .   xn−1)
and  xi ∈ X (X 0
1 is the empty observation). After making the prediction yn  the observation xn is
revealed and the player suffers two losses  u(yn  xn) and c(yn  xn)  where u and c are real-valued
continuous functions and convex w.r.t. their ﬁrst argument. We view the player’s prediction strategy as
a sequence S (cid:44) {Sn}∞
n=1 of forecasting functions Sn : X (n−1) → Y; that is  the player’s prediction
at round n is given by Sn(X n−1
)). Throughout the paper we
assume that x1  x2  . . . are realizations of random variables X1  X2  . . . such that the stochastic
−∞ is jointly stationary and ergodic and P(Xi ∈ X ) = 1. The player’s goal is to play
process (Xn)∞
the game with a strategy that minimizes the average u-loss  1
)  xi)  while keeping
N
the average c-loss 1
)  xi) bounded below a prescribed threshold γ. Formally  we
N
deﬁne the following:
Deﬁnition 1 (γ-bounded strategy). A prediction strategy S will be called γ-bounded if

) (for brevity  we denote S(X n−1

(cid:80)N
i=1 u(S(X i−1
(cid:33)

(cid:80)N
i=1 c(S(X i−1
(cid:32)

1

1

1

1

1

1

i=1

1
N

)  Xi)

lim sup
N→∞

c(S(X i−1

E(cid:2)maxy∈Y() EP∞ [u(y  X0)](cid:3) where P∞ is the regular conditional probability distribution of X0

≤ γ
almost surely. The set of all γ-bounded strategies will be denoted Sγ.
The well known result of [1] states that for the single objective case the best possible outcome is
given F∞ (the σ-algebra generated by the inﬁnite past X−1  X−2  . . .) and the maximization is over
the F∞-measurable functions. This motivates us to deﬁne the following:
Deﬁnition 2 (γ-feasible process). We say that the stationary and ergodic process {Xi}∞
−∞ is γ-
feasible w.r.t. the functions u and c  if for a threshold γ > 0  there exists some y(cid:48) ∈ Y() such that
E [c(y(cid:48)  X0)] < γ.
If γ-feasibility holds  then we will denote by y∗
following minimization problem:

∞ is not necessarily unique) the minimizer of the

∞ (y∗

N(cid:88)

E [u(y  X0)]

minimize
y∈Y()
subject to E [c(y  X0)] ≤ γ 

(1)

(1) and we deﬁne the γ-feasible optimal value as

V∗ = E [EP∞ [u(y∗

∞  X0)]] .

Note that problem (1) is a convex minimization problem over Y(). Therefore  the problem is
equivalent to ﬁnding the saddle point of the Lagrangian function [15]  namely 

min
y∈Y()

max
λ∈R+

L(y  λ) 

where the Lagrangian is

L(y  λ) (cid:44) (E [u(y  X0)] + λ (E [c(y  X0)] − γ)) .

2

We denote the optimal dual by λ∗
function  λ∗
Λ (cid:44) [0  λmax]. We also deﬁne the instantaneous Lagrangian function as

∞(). Moreover  we set a constant λmax such that λmax > λ∗

∞ and assume that L can be maximize by a unique F∞-measurable
∞() P∞-a.s.  and set

l(y  λ  x) (cid:44) u(y  x) + λ (c(y  x) − γ) .

(2)
In Brief  we are seeking a strategy S ∈ Sγ that is as good as any other γ-bounded strategy  in terms
of the average u-loss  when the underlying process is γ-feasible. Such a strategy will be called
γ-universal.
3 Optimality of V∗

In this section  we show that the average u-loss of any γ-bounded prediction strategy cannot be
smaller than V∗  the γ-feasible optimal value. This result is a generalization of the well-known
result of [1] regarding the best possible outcome under a single objective. Before stating and proving
this optimality result  we state three lemmas that will be used repeatedly in this paper. The ﬁrst
lemma is known as Breiman’s generalized ergodic theorem. The second and the third lemmas
concern the continuity of the saddle point w.r.t. the probability distribution  their proofs appear in the
supplementary material.
Lemma 1 (Ergodicity  [5]). Let X = {Xi}∞
−∞ be a stationary and ergodic process. For each positive
integer i  let Ti denote the operator that shifts any sequence by i places to the left. Let f1  f2  . . .
be a sequence of real-valued functions such that limn→∞ fn(X) = f (X) almost surely  for some
function f. Assume that E supn |fn(X)| < ∞. Then 

n(cid:88)

i=1

lim
n→∞

1
n

fi(T iX) = Ef (X)

almost surely.
Lemma 2 (Continuity and Minimax). Let Y  Λ X be compact real spaces. l : Y × Λ × X → R
be a continuous function. Denote by P(X ) the space of all probability measures on X (equipped with
the topology of weak-convergence). Then the following function L∗ : P(X ) → R is continuous

L∗(Q) = inf

y∈Y sup
λ∈Λ

EQ [l(y  λ  x)] .

(3)

Moreover  for any Q ∈ P(X ) 
inf
y∈Y sup
λ∈Λ

EQ [l(y  λ  x)] = sup
λ∈Λ

EQ [l(y  λ  x)] .

inf
y∈Y

(cid:18)

(cid:19)

(cid:18)

(cid:19)

Lemma 3 (Continuity of the optimal selection). Let Y  Λ X be compact real spaces. Then  there
exist two measurable selection functions hX hλ such that

hy(Q) ∈ arg min
y∈Y

max
λ∈Λ

EQ [l(y  λ  x)]

  hλ(Q) ∈ arg max
λ∈Λ

min
y∈Y

EQ [l(y  λ  x)]

for any Q ∈ P(X ). Moreover  let L∗ be as deﬁned in Equation (3). Then  the set
Gr(L∗) (cid:44) {(u∗  v∗  Q) | u∗ ∈ hy(Q)  v∗ ∈ hλ(Q)  Q ∈ P(X )} 

is closed in Y × Λ × P(X ).
The importance of Lemma 3 stems from the fact that it proves the continuity properties of the
multi-valued correspondences Q → hy(Q) and Q → hλ(Q). This leads to the knowledge that if for
the limiting distribution  Q∞  the optimal set is a singleton  then Q → hy(Q) and Q → hλ(Q) are
continuous in Q∞. We are now ready to prove the optimality of V∗.
−∞ be a γ-feasible process. Then  for any strategy S ∈ Sγ 
Theorem 1 (Optimality of V∗). Let {Xi}∞
N(cid:88)
the following holds a.s.

lim inf
N→∞

1
N

u(S(X i−1

1

)  Xi) ≥ V∗.

i=1

3

Proof. For any given strategy S ∈ Sγ  we will look at the following sequence:

N(cid:88)

i=1

1
N

l(S(X i−1

1

)  ˜λ∗

i   Xi).

(4)

where ˜λ∗

i ∈ hλ(P

Xi|X i−1

1

) Observe that

N(cid:88)

(cid:16)

i=1

(4) =

1
N

i   Xi) − E(cid:104)

)  ˜λ∗

l(S(X i−1

)  ˜λ∗

1

1

l(S(X i−1

E(cid:104)
N(cid:88)
i   Xi) − E(cid:104)

1
N

i=1

+

(cid:105)(cid:17)

l(S(X i−1

)  ˜λ∗

1

i   Xi) | X i−1
(cid:105)

1

.

Since Ai = l(S(X i−1
is a martingale difference se-
quence  the last summand converges to 0 a.s.  by the strong law of large numbers (see  e.g.  [20]).
Therefore 

l(S(X i−1

)  ˜λ∗

)  ˜λ∗

1

1

1

lim inf
N→∞

1
N

l(S(X i−1

1

)  ˜λ∗

i   Xi) = lim inf
N→∞

l(S(X i−1

1

)  ˜λ∗

i   Xi) | X i−1

1

(cid:105)

1

i   Xi) | X i−1
(cid:105)

i   Xi) | X i−1
N(cid:88)

E(cid:104)

1
N

i=1

(cid:105)

E(cid:104)

N(cid:88)

i=1

N(cid:88)

i=1

≥ lim inf
N→∞

1
N

min
y∈Y()

l(y  ˜λ∗

i   Xi) | X i−1

1

 

(5)

where the minimum is taken w.r.t. all the σ(X i−1
stationary  we get for ˆλ∗

) 

1

)-measurable functions. Because the process is

i ∈ hλ(P
N(cid:88)

X0|X

−1
1−i

E(cid:104)

min
y∈Y()

i=1

1
N

(cid:105)

= lim inf
N→∞

1
N

N(cid:88)

i=1

(5) = lim inf
N→∞

l(y  ˆλ∗

i   X0) | X−1
1−i

L∗(P

X0|X

−1
1−i

).

(6)

−1
1−i

X0|X

→ P∞ weakly as i approaches ∞ and from Lemma 2 we know

Using Levy’s zero-one law  P
that L∗ is continuous. Therefore  we can apply Lemma 1 and get that a.s.
∞  X0)]] = E [L (y∗

(6) = E [L∗(P∞)] = E [EP∞ [l (y∗

∞  λ∗

(7)
Note also  that due to the complementary slackness condition of the optimal solution  i.e. 
E [λ∗

∞  X0)] − γ)] = 0  we get

∞(EP∞ [c(y∗

∞  X0)] .

∞  λ∗

(7) = E [EP∞ [u (y∗
∞  and using Lemma 3 ˆλ∗

∞  X0)]] = V∗.
i → λ∗

∞ as i approaches ∞. Moreover  since l is
From the uniqueness of λ∗
continuous on a compact set  l is also uniformly continuous. Therefore  for any given  > 0  there
exists δ > 0  such that if |λ(cid:48) − λ| < δ  then

|l(y  λ(cid:48)  x) − l(y  λ  x)| < 

for any y ∈ Y and x ∈ X . Therefore  there exists i0 such that if i > i0 then |l(y  ˆλ∗
l(y  λ∗

∞  x)| <  for any y ∈ Y and x ∈ X . Thus 

i   x) −

i=1

N(cid:88)
N(cid:88)
N(cid:88)

i=1

i=1

lim inf
N→∞

= lim inf
N→∞

1
N

1
N

≥ lim inf
N→∞

1
N

N(cid:88)
N(cid:88)

i=1

i=1

l(S(X i−1

1

)  λ∗

∞  Xi) − lim inf
N→∞

1
N

l(S(X i−1

1

)  ˆλ∗

i   Xi)

l(S(X i−1

1

)  λ∗

∞  Xi) + lim sup
N→∞

1
N

−l(S(X i−1

1

)  ˆλ∗

i   Xi)

l(S(X i−1

1

l(S(X i−1

1

)  λ∗

∞  Xi) ≥ − a.s. 

N(cid:88)

i=1

)  ˆλ∗

i   Xi) − 1
N

4

Algorithm 1 Minimax Histogram Based Aggregation (MHA)

Input: Countable set of experts {Hk h}  y0 ∈ Y  λ0 ∈ Λ  initial probability {αk h} 
For n = 0 to ∞
Play yn  λn.
Nature reveals xn
Suffer loss l(yn  λn  xn).
Update the cumulative loss of the experts

(cid:44) n(cid:88)

i=0

(cid:44) n(cid:88)

lk h
y n

l(yi

k h  λi  xi)

lk h
λ n

l(yi  λi

k h  xi)

Update experts’ weights

wy (k h)

n

(cid:44) αk h exp

− 1√
n

Update experts’ weights wλ (k h)

n+1

wλ (k h)

n+1

(cid:44) αk h exp

Choose yn+1 and λn+1 as follows

(cid:18)
(cid:18) 1√
(cid:88)

k h

(cid:19)

lk h
y n

i=0

py (k h)
n+1

(cid:44)

(cid:80)∞

h=1

wy (k h)

n+1

(cid:80)∞

k=1 wy (k h)

n+1

(cid:19)

lk h
λ n

pλ (k h)
n+1 =

n

yn+1
k h

λn+1 =

(cid:88)

k h

(cid:80)∞

h=1

wλ (k h)

n+1

(cid:80)∞

k=1 wλ (k h)

n+1

pλ (k h)
n+1 λn+1
k h

yn+1 =

py (k h)
n+1

l(S(X i−1

1

)  λ∗

∞  Xi) ≥ lim inf
N→∞

N(cid:88)

i=1

1
N

l(S(X i−1

1

)  ˆλ∗

i   Xi).

End For

and since  is arbitrary 

lim inf
N→∞

1
N

N(cid:88)

i=1

Therefore we can conclude that

lim inf
N→∞

1
N

We ﬁnish the proof by noticing that since S ∈ Sγ  then by deﬁnition

l(S(X i−1

1

)  λ∗

∞  Xi) ≥ V∗ a.s.

lim sup
N→∞

c(S(X i−1

1

)  Xi) ≤ γ a.s.

N(cid:88)
N(cid:88)

i=1

1
N

i=1

∞ is non negative  we will get the desired result.

and since λ∗
The above lemma also provides the motivation to ﬁnd the saddle point of the Lagrangian L. Therefore 
for the reminder of the paper we will use the loss function l as deﬁned in Equation 2.

4 Minimax Histogram Based Aggregation

We are now ready to present our algorithm Minimax Histogram based Aggregation (MHA) and prove
that its predictions are as good as the best strategy.
By Theorem 1 we can restate our goal: ﬁnd a prediction strategy S ∈ Sγ such that for any γ-feasible
process {Xi}∞

−∞ the following holds:

lim
N→∞

1
N

u(S(X i−1

1

)  Xi) = V∗ a.s.

N(cid:88)

i=1

5

k h  λi

(cid:80)N
(cid:80)N

Such a strategy will be called γ-universal. We do so by maintaining a countable set of experts
{Hk h} k  h = 1  2  . . .  which are constructed in a similar manner to the experts used in [10].
Each expert is deﬁned using a histogram which gets ﬁner as h grows  allowing us to construct an
empirical measure on X . An expert Hk h therefore outputs a pair (yi
k h) ∈ Y × Λ at round
i. This pair is the minimax w.r.t. its empirical measure. We show that those emprical measures
converge weakly to P∞  thus  the experts’ prediction will converge to V∗. Our algorithm outputs at
round i a pair (yi  λi) ∈ Y × Λ where the sequence of predictions y1  y2  . . . tries to minimize the
i=1 l(y  λi  xi) and the sequence of predictions λ1  λ2  . . . tries to maximize the
average loss 1
N
average loss 1
i=1 l(yi  λ  xi). Each of yi and λi is the aggregation of predictions yi
k h 
N
k  h = 1  2  . . .   respectively. In order to ensure that the performance of MHA will be as good as
any other expert for both the y and the λ predictions  we apply the Weak Aggregating Algorithm of
[21]  and [13] twice alternately. Theorem 2 states that the selection of points made by the experts
above converges to the optimal solution  the proof of Theorem 2 and the explicit construction of the
experts appears in the supplementary material. Then  in Theorem 3 we prove that MHA applied on
the experts deﬁned in Theorem 2 generates a sequence of predictions that is γ-bounded and as good
as any other strategy w.r.t. any γ-feasible process.
Theorem 2. Assume that {Xi}∞
countable set of experts {Hk h} for which

−∞ is a γ-feasible process. Then  it is possible to construct a

k h and λi

lim
k→∞ lim

h→∞ lim
n→∞

1
N

l(yi

k h  λi

k h  Xi) = V∗ a.s. 

N(cid:88)

i=1

where (yi

k h  λi

k h) are the predictions made by expert Hk h at round i.

N(cid:88)

l(cid:0)yi

(cid:1) ≤ V∗ ≤ sup

N(cid:88)

l(cid:0)yi  λi

(cid:1)  

Before stating the main theorem regarding MHA  we state the following lemma (the proof appears in
the supplementary material)  which is used in the proof of the main result regarding MHA.
Lemma 4. Let {Hk h} be a countable set of experts as deﬁned in the proof of Theorem 2. Then  the
following relation holds a.s.:

i=1

inf
k h

1
N

k h  λi  Xi

lim sup
n→∞

1
N
where (yi  λi) are the predictions of MHA when applied on {Hk h}.
We are now ready to state and prove the optimality of MHA.
Theorem 3 (Optimality of MHA). Let (yi  λi) be the predictions generated by MHA when applied
on {Hk h} as deﬁned in the proof of Theorem 2. Then  for any γ-feasible process {Xi}∞
−∞: MHA is
a γ-bounded and γ-universal strategy.

lim inf
n→∞

k h  Xi

i=1

k h

Proof. We ﬁrst show that

N(cid:88)

i=1

lim
N→∞

1
N

l(yi  λi  Xi) = V∗ a.s.

Applying Lemma 5 in [13]  we know that the x updates guarantee that for every expert Hk h 

(8)

(9)

(10)

l(yi  λi  xi) ≤ 1
N

l(yi  λi  xi) ≥ 1
N

l(yi

k h  λi  xi) +

Ck h√
N
k h  xi) − C(cid:48)
k h√
N

 

l(yi  λi

where Ck h  C(cid:48)

k h > 0 are some constants independent of N. In particular  using Equation (9) 

1
N

l(yi  λi  xi) ≤ inf

k h

l(yi

k h  λi  xi) +

Ck h√
N

(cid:33)

.

N(cid:88)
N(cid:88)

i=1

i=1

1
N

1
N

N(cid:88)

i=1

N(cid:88)
N(cid:88)

i=1

i=1

(cid:32)

N(cid:88)

i=1

1
N

6

Therefore  we get

lim sup
N→∞

(cid:32)

lim sup
N→∞

1
N

1
N

≤ inf

k h

N(cid:88)
N(cid:88)

i=1

i=1

l(yi  λi  xi) ≤ lim sup
N→∞

inf
k h

(cid:33)

l(yi

k h  λi  xi) +

(cid:32)

l(yi

k h  λi  xi) +

Ck h√
N

≤ inf

k h

lim sup
N→∞

1
N

l(yi

k h  λi  xi)

 

(11)

(cid:33)

Ck h√
N

(cid:33)

where in the last inequality we used the fact that lim sup is sub-additive. Using Lemma (4)  we get
that

(11) ≤ V∗ ≤ sup

k h

lim inf
n→∞

(12)

(cid:32)

N(cid:88)

i=1

1
N

N(cid:88)

i=1

(cid:1) .

l(cid:0)yi  λi

k h  Xi

1
N

N(cid:88)
N(cid:88)

i=1

i=1

Using similar arguments and using Equation (10) we can show that

(12) ≤ lim inf
N→∞

1
N

l(yi  λi  xi).

Summarizing  we have

lim sup
N→∞

1
N

N(cid:88)

i=1

l(yi  λi  xi) ≤ V∗ ≤ lim inf
N→∞

1
N

l(yi  λi  xi).

(cid:80)N
i=1 l(yi  λi  Xi) = V∗.

i=1

Therefore  we can conclude that a.s. limN→∞ 1
N
To show that MHA is indeed a γ-bounded strategy  we use two special experts H0 0  H−1 −1 whose
predictions are λn

0 0 = λmax and λn−1 −1 = 0 for every n and to shorten the notation  we denote

g(y  λ  x) (cid:44) λ(c(y  x) − γ).

First  from Equation (10) applied on the expert H0 0  we get that:

lim sup
N→∞

1
N

g(yi  λmax  x) ≤ lim sup
N→∞

1
N

g(yi  λi  x).

(13)

N(cid:88)

N(cid:88)

i=1

N(cid:88)

i=1

Moreover  since l is uniformly continuous  for any given  > 0  there exists δ > 0  such that if
|λ(cid:48) − λ| < δ  then |l(y  λ(cid:48)  x) − l(y  λ  x)| <  for any y ∈ Y and x ∈ X . We also know from the
proof of Theorem 2 that limk→∞ limh→∞ limi→∞ λi
∞. Therefore  there exist k0  h0  i0 such
that |λi

∞| < δ for any i > i0. Therefore 

k h = λ∗

− λ∗

k0 h0

(cid:32)
(cid:32)
(cid:32)

1
N

1
N

i=1

N(cid:88)
N(cid:88)
N(cid:88)

i=1

i=1

1
N

lim sup
N→∞

lim sup
N→∞

lim sup
N→∞

l(yi  λ∗

N(cid:88)
∞  xi) − 1
N(cid:88)
N

i=1

l(yi  λ∗

∞  xi) − 1
N

i=1

l(yi  λi

k0 h0

  xi) − 1
N

N(cid:88)

i=1

(cid:33)

≤

(cid:33)
(cid:33)

+

l(yi  λi  xi)

l(yi  λi

k0 h0

  xi)

l(yi  λi  xi)

(14)

From the uniform continuity we also learn that the ﬁrst summand is bounded above by   and from
Equation (10)  we get that the last summand is bounded above by 0. Thus 

and since  is arbitrary  we get that

(cid:32)

N(cid:88)

i=1

1
N

lim sup
N→∞

(14) ≤  

l(yi  λ∗

∞  xi) − 1
N

7

(cid:33)

l(yi  λi  xi)

≤ 0.

N(cid:88)

i=1

∞  Xi) ≤ V∗  and from Theorem 1 we can conclude that

Thus  lim supN→∞ 1
N
limN→∞ 1
N

(cid:80)N
(cid:80)N
i=1 l(yi  λ∗
∞  Xi) = V∗. Therefore  we can deduce that
i=1 l(yi  λ∗
N(cid:88)
g(yi  λ∗
1
N(cid:88)
N

g(yi  λi  xi) − lim sup
N→∞

lim sup
N→∞

i=1

i=1

g(yi  λi  xi) + lim inf
N→∞

∞  xi) =

−g(yi  λ∗

∞  xi)

lim sup
N→∞

1
N

i=1

≤ lim sup
N→∞

N(cid:88)
N(cid:88)

i=1

1
N

i=1

g(yi  λi  xi) − 1
N

g(yi  λ∗

∞  xi)

1
N

N(cid:88)
N(cid:88)
N(cid:88)
N(cid:88)

1
N

i=1

i=1

i=1

N(cid:88)
N(cid:88)

i=1

i=1

= lim sup
N→∞

l(yi  λi  xi) − 1
N

l(yi  λ∗

∞  xi) = 0 

which results in

lim sup
N→∞

1
N

g(yi  λi  xi) ≤ lim sup
N→∞

1
N

g(yi  λ∗

∞  xi).

Combining the above with Equation (13)  we get that

lim sup
N→∞

1
N

g(yi  λmax  xi) ≤ lim sup
N→∞

1
N

g(yi  λ∗

∞  xi).

Since 0 ≤ λ∗

∞ < λmax  we get that MHA is γ-bounded. This also implies that

1
N

N(cid:88)
N(cid:88)

i=1

i=1

lim sup
N→∞

1
N

λi(c(yi  xi) − γ) ≤ 0.

Now  if we apply Equation (10) on the expert H−1 −1  we get that
λi(c(yi  xi) − γ) ≥ 0.

lim inf
N→∞

1
N

Thus 

lim
N→∞

1
N

λi(c(yi  xi) − γ) = 0 

and using Equation (8)  we get that MHA is also γ-universal.

i=1

N(cid:88)
N(cid:88)
N(cid:88)

i=1

i=1

5 Concluding Remarks

In this paper  we introduced the Minimax Histogram Aggregation (MHA) algorithm for multiple-
objective sequential prediction. We considered the general setting where the unknown underlying
process is stationary and ergodic.  and given that the underlying process is γ-feasible  we extended the
well-known result of [1] regarding the asymptotic lower bound of prediction with a single objective 
to the case of multi-objectives. We proved that MHA is a γ-bounded strategy whose predictions also
converge to the optimal solution in hindsight.
In the proofs of the theorems and lemmas above  we used the fact that the initial weights of the
experts  αk h  are strictly positive thus implying a countably inﬁnite expert set. In practice  however 
one cannot maintain an inﬁnite set of experts. Therefore  it is customary to apply such algorithms
with a ﬁnite number of experts (see [12  9  10]). Despite the fact that in the proof we assumed that the
observation set X is known a priori  the algorithm can also be applied in the case that X is unknown
by applying the doubling trick. For a further discussion on this point  see [8]. In our proofs  we relied
on the compactness of the set X . It will be interesting to see whether the universality of MHA can be
sustained under unbounded processes as well. A very interesting open question would be to identify
conditions allowing for ﬁnite sample bounds when predicting with multiple objectives.

8

Acknowledgments

We would like to thank the anonymous reviewers for providing helpful comments. This research was
supported by The Israel Science Foundation (grant No. 1890/14)

References
[1] P.H. Algoet. The strong law of large numbers for sequential decisions under uncertainty. IEEE

Transactions on Information Theory  40(3):609–633  1994.

[2] G. Biau  K. Bleakley  L. Györﬁ  and G. Ottucsák. Nonparametric sequential prediction of time

series. Journal of Nonparametric Statistics  22(3):297–317  2010.

[3] G. Biau and B. Patra. Sequential quantile prediction of time series. IEEE Transactions on

Information Theory  57(3):1664–1674  2011.

[4] A. Borodin and R. El-Yaniv. Online Computation and Competitive Analysis. Cambridge

University Press  2005.

[5] L. Breiman. The individual ergodic theorem of information theory. The Annals of Mathematical

Statistics  28(3):809–811  1957.

[6] N. Cesa-Bianchi and G. Lugosi. Prediction  Learning  and Games. Cambridge University Press 

2006.

[7] L. Devroye  L. Györﬁ  and G. Lugosi. A probabilistic theory of pattern recognition  volume 31.

Springer Science & Business Media  2013.

[8] L. Györﬁ and G. Lugosi. Strategies for sequential prediction of stationary time series. In

Modeling uncertainty  pages 225–248. Springer  2005.

[9] L. Györﬁ  G. Lugosi  and F. Udina. Nonparametric kernel-based sequential investment strategies.

Mathematical Finance  16(2):337–357  2006.

[10] L. Györﬁ and D. Schäfer. Nonparametric prediction. Advances in Learning Theory: Methods 

Models and Applications  339:354  2003.

[11] L. Györﬁ  F. Udina  and H. Walk. Nonparametric nearest neighbor based empirical portfolio
selection strategies. Statistics & Decisions  International Mathematical Journal for Stochastic
Methods and Models  26(2):145–157  2008.

[12] L. Györﬁ  A. Urbán  and I. Vajda. Kernel-based semi-log-optimal empirical portfolio selection
strategies. International Journal of Theoretical and Applied Finance  10(03):505–516  2007.

[13] Y. Kalnishkan and M. Vyugin. The weak aggregating algorithm and weak mixability. In
International Conference on Computational Learning Theory  pages 188–203. Springer  2005.

[14] D. Luenberger. Optimization by vector space methods. John Wiley & Sons  1997.

[15] U.V. Luxburg and B. Schölkopf. Statistical learning theory: Models  concepts  and results.

arXiv preprint arXiv:0810.4752  2008.

[16] M. Mahdavi  T. Yang  and R. Jin. Stochastic convex optimization with multiple objectives. In

Advances in Neural Information Processing Systems  pages 1115–1123  2013.

[17] S. Mannor  J. Tsitsiklis  and J.Y. Yu. Online learning with sample path constraints. Journal of

Machine Learning Research  10(Mar):569–590  2009.

[18] P. Rigollet and X. Tong. Neyman-pearson classiﬁcation  convexity and stochastic constraints.

Journal of Machine Learning Research  12(Oct):2831–2855  2011.

[19] W. Stout. Almost sure convergence  vol. 24 of probability and mathematical statistics  1974.

[20] V. Vovk. Competing with stationary prediction strategies. In International Conference on

Computational Learning Theory  pages 439–453. Springer  2007.

9

,Rakesh Shivanna
Chiranjib Bhattacharyya
Guy Uziel
Ran El-Yaniv
Dimitris Kalimeris
Gal Kaplun
Preetum Nakkiran
Benjamin Edelman
Tristan Yang
Boaz Barak
Haofeng Zhang