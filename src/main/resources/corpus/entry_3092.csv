2019,Learning search spaces for Bayesian optimization: Another view of hyperparameter transfer learning,Bayesian optimization (BO) is a successful methodology to optimize black-box functions that are expensive to evaluate. While traditional methods optimize each black-box function in isolation  there has been recent interest in speeding up BO by transferring knowledge across multiple related black-box functions. In this work  we introduce a method to automatically design the BO search space by relying on evaluations of previous black-box functions. We depart from the common practice of defining a set of arbitrary search ranges a priori by considering search space geometries that are learnt from historical data. This simple  yet effective strategy can be used to endow many existing BO methods with transfer learning properties. Despite its simplicity  we show that our approach considerably boosts BO by reducing the size of the search space  thus accelerating the optimization of a variety of black-box optimization problems. In particular  the proposed approach combined with random search results in a parameter-free  easy-to-implement  robust hyperparameter optimization strategy. We hope it will constitute a natural baseline for further research attempting to warm-start BO.,Learning search spaces for Bayesian optimization:
Another view of hyperparameter transfer learning

Valerio Perrone  Huibin Shen  Matthias Seeger  Cédric Archambeau  Rodolphe Jenatton∗

{vperrone  huibishe  matthis  cedrica}@amazon.com

Amazon

Berlin  Germany

Abstract

Bayesian optimization (BO) is a successful methodology to optimize black-box
functions that are expensive to evaluate. While traditional methods optimize each
black-box function in isolation  there has been recent interest in speeding up BO by
transferring knowledge across multiple related black-box functions. In this work 
we introduce a method to automatically design the BO search space by relying
on evaluations of previous black-box functions. We depart from the common
practice of deﬁning a set of arbitrary search ranges a priori by considering search
space geometries that are learned from historical data. This simple  yet effective
strategy can be used to endow many existing BO methods with transfer learning
properties. Despite its simplicity  we show that our approach considerably boosts
BO by reducing the size of the search space  thus accelerating the optimization of
a variety of black-box optimization problems. In particular  the proposed approach
combined with random search results in a parameter-free  easy-to-implement 
robust hyperparameter optimization strategy. We hope it will constitute a natural
baseline for further research attempting to warm-start BO.

1

Introduction

Tuning the hyperparameters (HPs) of machine leaning (ML) models and in particular deep neural
networks is critical to achieve good predictive performance. Unfortunately  the mapping of the HPs
to the prediction error is in general a black-box in the sense that neither its analytical form nor its
gradients are available. Moreover  every (noisy) evaluation of this black-box is time-consuming as
it requires retraining the model from scratch. Bayesian optimization (BO) provides a principled
approach to this problem: an acquisition function  which takes as input a cheap probabilistic surrogate
model of the target black-box function  repeatedly scores promising HP conﬁgurations by performing
an explore-exploit trade-off [30  22  37]. The surrogate model is built from the set of black-box
function evaluations observed so far. For example  a popular approach is to impose a Gaussian
process (GP) prior on the unobserved target black-box function f (x). Based on a set of evaluations
{f (xi)}n
i=1  possibly perturbed by Gaussian noise  one can compute the posterior GP  characterized
by a posterior mean and a posterior (co)variance function. The next query points are selected by
optimizing an acquisition function  such as the expected improvement [30]  which is analytically
tractable given these two quantities. While BO takes the human out of the loop in ML by automating
HP optimization (HPO)  it still requires the user to deﬁne a suitable search space a priori. Deﬁning a
default search space for a particular ML problem is difﬁcult and left to human experts.
In this work  we automatically design the BO search space  which is a critical input to any BO
procedure applied to HPO  based on historical data. The proposed approach relies on the observation
that HPO problems occurring in ML are often related (for example  tuning the HPs of an ML model

∗Work done while afﬁliated with Amazon; now at Google Brain  Berlin  rjenatton@google.com

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

trained on different data sets [43  3  51  35  11  32  9  28]). Moreover  our method learns a suitable
search space in a universal fashion: it can endow any BO algorithm with transfer learning capabilities.
For instance  we demonstrate this feature with three widely used HPO algorithms – random search [4] 
SMAC [20] and hyperband [29]. Further  we investigate the use of novel geometrical representations
of the search spaces  departing from the traditional rectangular boxes. In particular  we show that an
ellipsoidal representation is not only simple to compute and manipulate  but leads to faster black-box
optimization  especially as the dimension of the search space increases.

2 Related work and contributions

Previous work has implemented BO transfer learning in many different ways. For instance  the
problem can be framed as a multi-task learning problem  where each run of BO corresponds to a task.
Tasks can be modelled jointly or as being conditionally independent with a multi-output GP [43]  a
Bayesian neural network [41]  a multi-layer perceptron with Bayesian linear regression heads [39  32] 
possibly together with some embedding [28]  or a weighted combination of GPs [35  9]. Alternatively 
several authors attempted to rely on manually deﬁned meta-features in order to measure the similarity
between BO problems [3  51  35]. If these problems further come in a speciﬁc ordering (e.g.  because
of successive releases of an ML model)  the successive surrogate models can be ﬁt to the residuals
relative to predictions of the previous learned surrogate model [15  33]. In particular  if GP surrogates
are used  the new GP is centered around the predictive mean of the previously learned GP surrogate.
Finally  rather than ﬁtting a surrogate model to all past data  some transfer can be achieved by
warm-starting BO with the solutions to the previous BO problems [10  50].
The work most closely related to ours is [49]  where the search space is pruned during BO  removing
unpromising regions based on information from related BO problems. Similarity scores between BO
problems are computed from data set meta-features. While we also aim to restrict the BO search space 
our approach is different in many ways. First  we do not require meta-features  which in practice can
be hard to obtain and need careful manual design. Second  our procedure works completely ofﬂine 
as a preprocessing step  and does not require feedback from the black-box function being optimized.
Third  it is parameter-free and model-free. By contrast  [49] rely on a GP model and have to select a
radius and the fraction of the space to prune. Finally  [49] use a discretization step to prune the search
space  which may not scale well as its dimension increases. The generality of our approach is such
that [49] could be used on top of our proposed method (while the converse is not true).
Another line of research has developed search space expansion strategies for BO. Those approaches
are less dependent on the initial search space provided by the users  incrementally expanding it
during BO [36  31]. None of this research has considered transfer learning. A related idea to learn
hyperparameter importance has been explored in [45]  where a post-hoc functional ANOVA analysis
is used to learn priors over the hyperparameter space. Again  such techniques could be used together
with our approach  which would deﬁne the initial search space in a data driven manner.
Our contributions are: (1) We introduce a simple and generic class of methods that design compact
search spaces from historical data  making it possible to endow any BO method with transfer learning
properties  (2) we explore and demonstrate the value of new geometrical representations of search
spaces beyond the rectangular boxes traditionally employed  and (3) we show over a broad set of
transfer learning experiments that our approach consistently boosts the performance of the optimizers
it is paired with. When combined with random search  the resulting simple and parameter-free
optimization strategy constitutes a strong baseline  which we hope will be adopted in future research.

3 Black-box function optimization on a reduced search space
Consider T + 1 black-box functions {ft(·)}T
t=0  deﬁned on a common search space X ⊆ Rp.
The functions are expensive-to-evaluate  possibly non-convex  and accessible only through their
values  without gradient information. In loose terms  the functions {ft(·)}T
t=0 are assumed related 
corresponding for instance to the evaluations of a given ML model over T + 1 data sets (in which
case X is the set of feasible HPs of this model). Our goal is to minimize f0:

(1)
However  for t ≥ 1  we have access to nt noisy evaluations of the function ft  which we denote by
Dt = {(xi t  yi t)}nt
i=1. In this work  we consider methods that take the previous evaluations {Dt}T

min
x∈X f0(x).

t=1

2

as inputs  and output a search space ˆX ⊆ X   so that we solve the following problem instead of (1):
(2)

f0(x).

min
x∈ ˆX

The local minima of (2) are a subset of the local minima of (1). Since ˆX is more compact (formally
deﬁned later)  BO methods will ﬁnd those minima faster  i.e.  with fewer function evaluations. Hence 
we aim to design ˆX such that it contains a “good” set of local minima  close to the global ones of X .

4 Data-driven search space design via transfer learning

t=1  respectively max{wt}T

t ) as the element in Dt that reaches the smallest
Notations and preliminaries. We deﬁne (x(cid:63)
t   y(cid:63)
t ) = arg min(xt yt)∈Dt yt. For any two vectors
(i.e.  best) evaluation for the black-box t  i.e.  (x(cid:63)
t   y(cid:63)
u and w in Rp  u ≤ w stands for the element-wise inequalities uj ≤ wj for j ∈ {1  . . .   p}. We also
denote by |u| the vector with entries |uj| for j ∈ {1  . . .   p}. For a collection {wt}T
t=1 of T vectors in
Rp  we denote by min{wt}T
t=1  the p-dimensional vector resulting from
the element-wise minimum  respectively maximum  over the T vectors. Finally  for any symmetric
matrix A ∈ Rp×p  A (cid:31) 0 indicates that A is positive deﬁnite.
We assume that the original search space X is deﬁned by axis-aligned ranges that can be thought of
as a bounding box: X = {x ∈ Rp| l0 ≤ x ≤ u0} where l0 and u0 are the initial vectors of lower
and upper bounds. Search spaces represented as boxes are commonly used in popular BO packages
such as Spearmint [38]  GPyOpt [1]  GPflowOpt [27]   Dragonfly [24] and Ax [7].
The methodology we develop applies to numerical parameters (either integer or continuous). If
the problems under consideration exhibit categorical parameters (we have such examples in our
experiments  Section 6)  we let X = Xcat × Xnum. Our methodology then applies to Xnum only 
keeping Xcat unchanged. Hence  in the remainder the dimension p refers to the dimension of Xnum.

Q(cid:0)θ) such that for t ≥ 1  x(cid:63)

4.1 Search space estimation as an optimization problem
The reduced search space ˆX we would like to learn is deﬁned by a parameter vector θ ∈ Rk. To
estimate ˆX   we consider the following constrained optimization problem:
t ∈ ˆX (θ) 

(3)
where Q(θ) is some measure of volume of ˆX (θ); concrete examples are given in Sections 4.2 and 4.3.
t}T
In solving (3)  we ﬁnd a search space ˆX (θ) that contains all solutions {x(cid:63)
t=1 to previously solved
black-box optimization problems  while at the same time minimizing Q(θ). Note that ˆX (θ) can only
get larger (as measured by Q(θ)) as more related black-box optimization problems are considered.
Moreover  formulation (3) does not explicitly use the y(cid:63)
t ’s and never compares them across tasks. As
a result  unlike previous work such as [51  9]  we need not normalize the tasks (e.g.  whitening).

min
θ∈Rk

4.2 Search space as a low-volume bounding box

The ﬁrst instantiation of (3) is a search space deﬁned by a bounding box (or hyperrectangle)  which is
parameterized by the lower and upper bounds l and u. More formally  ˆX (θ) = {x ∈ Rp| l ≤ x ≤ u}
and θ = (l  u)  with k = 2p. A tight bounding box containing all {x(cid:63)
t}T
t=1 can be obtained as the
solution to the following constrained minimization problem:

min

l∈Rp  u∈Rp

1
2

(cid:107)u − l(cid:107)2

2 such that for t ≥ 1  l ≤ x(cid:63)

t ≤ u

(4)

where the compactness of the search space is enforced by a squared (cid:96)2 term that penalizes large
ranges in each dimension. This problem has a simple closed-form solution θ∗

b = (l∗  u∗)  where

l∗ = min{x(cid:63)

t}T

(5)
These solutions are simple and intuitive: while the initial lower and upper bounds l0 and u0 may
deﬁne overly wide ranges  the new ranges of ˆX (θ∗
b ) are the smallest ranges containing all the

t=1

and u∗ = max{x(cid:63)

t}T
t=1.

3

t}T
t=1. The resulting search space ˆX (θ∗

related solutions {x(cid:63)
b ) deﬁnes a new  tight bounding box that
can directly be used with any optimizer operating on the original X . Despite the simplicity of the
deﬁnition of ˆX (θ∗
b )  we show in Section 6 that this approach constitutes a surprisingly strong baseline 
even when combined with random search only. We will generalize the optimization problem (4) in
Section 5 to obtain solutions that account for outliers contained {x(cid:63)
t}T
t=1 and  as a result  produce an
even tighter search space.

4.3 Search space as a low-volume ellipsoid

A∈Rp×p  A(cid:31)0  b∈Rp

log det(A−1) such that for t ≥ 1  (cid:107)Ax(cid:63)

The second instantiation of (3) is a search space deﬁned by a hyperellipsoid (i.e.  afﬁne transformations
of a unit (cid:96)2 ball)  which is parameterized by a symmetric positive deﬁnite matrix A ∈ Rp×p and an
offset vector b ∈ Rp. More formally  ˆX (θ) = {x ∈ Rp| (cid:107)Ax + b(cid:107)2 ≤ 1} and θ = (A  b)  with
k = p(p + 3)/2. Using the classical Löwner-John formulation [21]  the lowest volume ellipsoid
t}T
covering all points {x(cid:63)
t=1 is the solution to the following problem (see Section 8.4 in [5]):
min

increasing function of the volume of the ellipsoid ∝ 1/(cid:112)det(A) [17]. This problem is convex  admits

(6)
t ∈ ˆX (θ)  while the minimized objective is a strictly
e = (A∗  b∗)  and can be solved efﬁciently by interior-points algorithms [42]. In

where the T norm constraints enforce x(cid:63)
a unique solution θ∗
our experiments  we use CVXPY [6].
t}T
Intuitively  an ellipsoid should be more suitable than a hyperrectangle when the points {x(cid:63)
t=1 we
want to cover do not cluster in the corners of the box. In Section 6  a variety of real-world ML
t}T
problems suggest that the distribution of the solutions {x(cid:63)
t=1 supports this hypothesis. We will
also generalize the optimization problem (6) in Section 5 to obtain solutions that account for outliers
contained in {x(cid:63)

t + b(cid:107)2 ≤ 1 

t}T
t=1.

4.4 Optimizing over ellipsoidal search spaces

We cannot directly plug ellipsoidal search spaces into standard HPO procedures. Algorithm 1
details how to adapt random search  and as a consequence also methods like hyperband [29]  to an
ellipsoidal search space. In a nutshell  we use rejection sampling to guarantee uniform sampling in
X ∩ ˆX (θ∗
e ): we ﬁrst sample uniformly in the p-dimensional ball  then apply the inverse mapping
of the ellipsoid [12]  and ﬁnally check whether the sample belongs to X . The last step is important
as not all points in the ellipsoid may be valid points in X . For example  a HP might be restricted
to only take positive values. However  after ﬁtting the ellipsoid  some small amount of its volume
might include negative values. Finally  ellipsoidal search spaces cannot directly be used with more
complex  model-based BO engines  such as GPs. They would require resorting to constrained BO
modelling [16  13  14]  e.g.  to optimize the acquisition function over the ellipsoid  which would add
signiﬁcant complexity to the procedure. Hence  we defer this investigation to future work.

e  X )

(cid:46) θ∗

e and IS_FEASIBLE ← FALSE

A∗  b∗ ← θ∗
while not IS_FEASIBLE do

Algorithm 1 Rejection sampling algorithm to uniformly sample in an ellipsoidal search space
1: procedure ELLIPSOIDRANDOMSAMPLING(θ∗
2:
3:
4:
5:
6:
7:
8:
9:

z ∼ N (0  I)  with z ∈ Rp  and r ∼ U (0  1)
t ← r1/p
(cid:107)z(cid:107)2
x ← (A∗)−1(t − b∗)
if x ∈ X then

(cid:46) x is uniformly distributed in the ellipsoid ˆX (θ∗
(cid:46) We check if x is valid since we may not have ˆX (θ∗

(cid:46) t is uniformly distributed in the unit (cid:96)2 ball [19]
e ) [12]
e ) ⊆ X

e is the solution from Section 4.3

IS_FEASIBLE ← TRUE

z

return x

5 Handling outliers in the historical data

The search space chosen by our method is the smallest hyperrectangle or hyperellipsoid enclosing
a set of solutions {x(cid:63)
t}T
t=1 found by optimizing related black-box optimization problems. In order

4

to exploit as much information as possible  a large number of related problems may be considered.
However  the learned search space volume might increase as a result  which will make black-box
optimization algorithms  such as BO  less effective. For example  if some of these problems depart
signiﬁcantly from the other black-box optimization problems  their contribution to the volume
increase might be disproportionate and discarding them will be beneﬁcial. In this section  we extend
of our methodology to exclude such outliers automatically.
We allow for some x(cid:63)
exclude outliers from the hyperrectangle  problem (4) is modiﬁed as follows:

t to violate feasibility  but penalize such violations by way of slack variables. To

min
−
l∈Rp  u∈Rp  ξ
t ≥0  ξ+
−
t |l0|≤x(cid:63)

t ≥0
t ≤u+ξ+

for t≥1  l−ξ

t |u0|

(cid:107)u − l(cid:107)2

2 +

λb
2

1
2T

(ξ−
t + ξ+

t ) 

(7)

where λb ≥ 0 is a regularization parameter  and {ξ−
t=1 the slack variables associated
respectively to l and u  which we make scale-free by using |l0| and |u0|. Slack variables can also be
used to exclude outliers from an ellipsoidal search region [26  42] by rewriting (6) as follows:

t=1 and {ξ+

t }T

t }T

T(cid:88)

t=1

T(cid:88)

t=1

min
A∈Rp×p  A(cid:31)0  b∈Rp  ξt≥0
for t≥1  (cid:107)Ax(cid:63)
t +b(cid:107)2≤1+ξt

λe log det(A−1) +

1
T

ξt.

(8)

t}T
t=1 are ignored  leading to a tighter search space.

where λe ≥ 0 is a regularization parameter and {ξt}T
t=1 the slack variables . Note that the original
formulations (4) and (6) are recovered when λb or λe tend to zero  as the optimal solution is then
found when all the slack variables are equal to zero. By contrast  when λb or λe get larger  more
solutions in the set {x(cid:63)
To set λb and λe  we proceed in two steps. First  we compute the optimal solution Q(θ∗) of the
original problem  namely (4) and (6) for the bounding box and ellipsoid  respectively. Q(θ∗) captures
the scale of the problem at hand. Then  we look at λ = s/Q(θ∗) for s in a small  scale-free  grid
of values and select the smallest value of λ that leads to no more than (1 − ν) × T solutions from
{x(cid:63)
t}T
t=1 (by checking the number of active  i.e.  strictly positive  slack variables in (7) and (8)). We
therefore turn the selection of the abstract regularization parameter λ to the more interpretable choice
of ν as a fraction of outliers. In our experiments  we purely determined those values on the toy SGD
synthetic setting (Section 6.1)  and then applied it as a default to the real-world problems with no
extra tuning (this led to νb = 0.5 and νe = 0.1).

6 Experiments

Our experiments are guided by three key messages. First  our method can be combined with a
large number of HPO algorithms. Hence  we obtain a modular design for HPO (and BO) which is
convenient when building ML systems. Second  by introducing parametric assumptions (with the
box and the ellipsoid)  we show empirically that our approach is more robust to low-data regimes
compared to model-based approaches. Third  our simple method induces transfer learning by reducing
the search space of BO. The method compares favorably to more complex alternative models for
transfer learning proposed in the literature  thus setting a competitive baseline for future research.
In the experiments  we consider combinations of search space deﬁnitions and HPO algorithms. Box
and Ellipsoid refer to learned hyperrectangular (Section 4.2) and hyperellipsoidal search spaces
(Section 4.3). When none of these preﬁxes are used  we deﬁned the search space using manually
speciﬁed bounding boxes (see Subsections 6.1–6.3 for the speciﬁcs). We further consider a diverse
set of HPO algorithms: random search  Hyperband [29]  GP-based BO  GP-based BO with input
warping [40]  random forest-based BO [20]  and adaptive bayesian linear regression-based BO [32] 
which are denoted respectively by Random  HB  GP  GP warping  SMAC  and ABLR. We assessed the
transfer learning capabilities in a leave-one-task-out fashion  meaning that we leave out one of the
black-box optimization problems and then aggregate the results. Each curve and shaded area in the
plots respectively corresponds to the mean metric and standard error obtained over 10 independent
replications times the number of leave-one-task-out runs. To report the results and ease comparisons
of tasks  we normalize the performance curves of each model by the best value obtained by random
search  inspired by [15  44]. Consequently  each random search performance curve ends up at 1 (or 0
when the metric is log transformed).

5

(a)

(b)

Figure 1: Tuning SGD for ridge regression. (a) Comparison of BO algorithms with Box transfer
learning counterparts. (b) Comparison of resource-aware BO with transfer learning counterparts Box
and Ellipsoid. Note that HB with transfer outperforms all methods shown in (a).

(a)

(b)

Figure 2: Visualization of the learned Ellipsoid search space (a) without and (b) with slack
variables. The blue dots are the observed evaluations and the orange dots are the samples drawn from
the learned Ellipsoid. The slack-extension successfully excludes the outlier learning rate.

6.1 Tuning SGD for ridge regression

We consider the problem of tuning the parameters of stochastic gradient descent (SGD) when opti-
mizing a set of 30 synthetic ridge regression problems with 81 input dimensions and 81 observations.
The setting is inspired by [44] and is described in the Supplement. The HPO problem consists in
tuning 3 HPs: learning rate in the range of (0.001  1.0)  momentum in the range of (0.3  0.999) and
regularization parameter in the range of (0.001  10.0). Figure 1a shows that the convergence to a
good local minimum of conventional BO algorithms  such as Random  GP  and SMAC  is signiﬁcantly
boosted when the search space is learned (Box) from related problems. It is also interesting to note
that all perform similarly once the search space is learned. The results for GP warping combined
with Box are also similar  where the Box improves over GP warping but not as much as in the GP
case due to signiﬁcant performance gain with warping. We show the results in Supplement A.
The transfer learning methodology can be combined with resource-based BO algorithms  such as
Hyperband [29]. We deﬁned a unit of resource as three SGD updates (following [44]). By design  the
more resources  the better the performance. Figure 1b shows that both the Box and Ellipsoid-based
transfer beneﬁt HB. Furthermore  HB with transfer is competitive with all other conventional BO
algorithms  including model-based ones when comparing the RMSE across Figure 1a and Figure 1b.
We then studied the impact of introducing the slack variables to exclude outliers. One example of a
learned Ellipsoid search space found for the 3 HPs of SGD on one of the ridge regression tasks
is illustrated in Figure 2  together with its slack counterpart. The slack extension provides a more
compact search space by discarding the outlier with learning rate value ≈ 0.06. A similar result was
obtained with the Box-based learned search space (see Supplement A).

6.2 Tuning binary classiﬁers over multiple OpenML data sets

We consider HPO for three popular binary classiﬁcation algorithms: random forest (RF; 5 HPs) 
support vector machine (SVM; 4 HPs)  and extreme gradient boosting (XGBoost; 10 HPs). Here  each
problem consists of tuning one of these algorithms on a different data set. We leveraged OpenML [46] 

6

01020304050iteration0.40.20.00.20.40.60.8log10(normalized RMSE)Aggregated Toy SGD resultsRandomEllipsoid + RandomBox + RandomGPBox + GPSMACBox + SMAC2.01.51.00.50.00.51.01.5log10 resources0.40.20.00.20.40.60.8log10(normalized RMSE)Aggregated Toy SGD resultsRandomHBBox + HBEllipsoid + HB(a)

(b)

(c)

Figure 3: OpenML. (a) Performance of BO algorithms and their transfer learning counterparts.
(b) Compares GP warm-start with Box + Random and Ellipsoid + Random. (c) Shows that
Box + GP warm-start outperforms plain GP warm-start.

which provides evaluation data for many ML algorithm and data set pairs. Following [32]  we selected
the 30 most-evaluated data sets for each algorithm. The default search ranges were deﬁned by the
minimum and maximum hyperparameter value used by each algorithm when trained on any of the
data sets. Results are shown in Figure 3a. The Box variants consistently outperform their non-transfer
counterparts in terms of convergence speed  and Box Random performs en par with Box SMAC and
Box GP. In this experiment  we also compared to GP with input warping [40]  which exhibited a
comparable boost when used in conjunction with the Box search space  slightly outperforming all
other methods. Finally  Ellipsoid Random slightly outperforms Box Random. Next  we compare
Ellipsoid Random and Box Random with two different transfer learning extensions of GP-based
HPO  derived from [10]. Each black-box optimization problem is described by meta-features
computed on the data set.2 In GP warm start  the closest problem (among the 29 left out) in terms
of (cid:96)1 distance of meta-features is selected  and its k best evaluations are used to warm start the GP
surrogate. Results are given in Figure 3b. Our simple search space transfer learning techniques
outperform these GP-based extensions for all k. We also considered GP warm start T=29  which
transfers the k best evaluations from all the 29 left out problems  appending the meta-feature vector to
the hyperparameter conﬁguration as input to the GP (see Figure B1a in Supplement B). Results were
qualitatively very similar  but the cubic scaling of GP surrogates renders GP warm start T=29
unattractive for a large T and/or k. In contrast  our transfer learning techniques are model-free.
In the next experiment  we combine our Box search space with these GP-based transfer techniques. In
all methods  we use 256 random samples from each problem t: nt go to Box  the remaining 256 − nt
to GP warm start. The results are given in Figure 3c. It is clear that the Box improves plain
GP warm start regardless of nt. We also ran experiments with GP warm start T=29 (n=*) and
ABLR (n=*) [32]  a transfer HPO method which scales linearly in the total number of evaluations (as
opposed to GP  which scales cubically). In all cases  Box Random is signiﬁcantly outperformed by
some Box GP or Box ABLR variant  demonstrating that additional gains are achievable by using some
of the data from the related problems to tighten the search space (see Figure B1b and Figure B1c
in Supplement B). Next  we studied the effect of the number nt of samples from each problem on
Ellipsoid Random. Results are reported in Figure 4a. We found that with a small number (nt = 8)
of samples per problem  learning the search space already provided sizable gains. We also studied the
effects of the number of related problems.3 Results are given in Figure 4b. We see that our transfer
learning by reducing the search space performs well even if only 3 previous problems are available 
while transfering from 9 problems yields most of the improvements. The results for Box Random are
similar (see Figure B2a- B2b in Supplement B).
Finally  we benchmark our slack variable extensions of Box and Ellipsoid from Section 5. As the
number of related problems grows  the volume of the smallest box or ellipsoid enclosing all minima
may be overly large due to some outlier solutions. For example  we observed that the optimal learning
rate η of XGBoost is typically ≤ 0.3  except η ≈ 1 for one data set. Our slack extensions are able
to neutralize such outliers  reducing the learned search space and improving the performance (see
Figure B3a and Figure B3b in Supplement B for more details).

2 Four features: data set size; number of features; class imbalance; Naive Bayes landmark feature.
3 For each of the 30 target problems  we pick k < 29 of the remaining ones at random  independently in

each random repetition. We transfer nt = 256 samples per problem.

7

01020304050iteration0.10.00.10.20.30.40.5log10(normalized (1-AUC))Aggregated OpenML resultsRandomBox + RandomEllipsoid + RandomGPBox + GPSMACBox + SMAC01020304050iteration0.10.00.10.20.30.40.5log10(normalized (1-AUC))Aggregated OpenML resultsRandomBox + RandomEllipsoid + RandomGPGP warm-start (top 16)GP warm-start (top 32)GP warm-start (top 64)GP warm-start (top 128)01020304050iteration0.10.00.10.20.30.40.5log10(normalized (1-AUC))Aggregated OpenML resultsRandomBox + RandomGP warm-startBox + GP warm-start (n=255)Box + GP warm-start (n=248)Box + GP warm-start (n=192)(a)

(b)

Figure 4: OpenML. (a) Sample size complexity and (b) robustness to the number of related problems
for Ellipsoid Random.

(a)

(b)

Figure 5: Feedforward neural network. (a) Performance of BO algorithms and their transfer learning
counterparts. (b) Comparison with resource-based BO.

6.3 Tuning neural networks across multiple data sets

The last set of experiments we conduct consist of tuning the HPs of a 2-layer feed-forward neu-
ral network on 4 data sets [25]  namely {slice localization  protein structure  naval
propulsion  parkinsons telemonitoring}. The search space for this neural network contains
the initial learning rate  batch size  learning rate schedule  as well as layer-speciﬁc widths  dropout
rates and activation functions  thus in total 9 HPs. All the HPs are discretized and there are in total
62208 HP conﬁgurations which have been trained with ADAM with 100 epochs on the 4 data sets 
optimizing the mean squared error. For each HP conﬁguration  the learning curves (both on training
and validation set) and the ﬁnal test metric are saved and provided publicly by the authors [25]. As a
result  we avoided re-evaluating the HPs  which signiﬁcantly reduced our experiment time.
Each black-box optimization problem consists of tuning the neural network parameters over 1 data set
after using 256 evaluations randomly chosen from the remaining 3 data sets to learn the search space.
The default search space ranges are provided in [25]. We compared plain Random  SMAC  and GP to
their variants based on Box. The results are illustrated in Figure 5a  where signiﬁcant improvements
can be observed. Ellipsoid Random also outperforms classic BO baselines such as GP and SMAC.
Finally  Figure 5b demonstrates that HB can be further sped up by our transfer learning extensions.
These results also indicate that good solutions are typically found in the interior of the search space.
To see how much accuracy could potentially be lost compared to methods that search over the
entire search space  we re-ran the OpenML and neural network experiments using 16 times as many
iterations (see Figure C1a and Figure C1b in Supplement C). Empirical evidence shows that excluding
the best solution is not a concern in practice  and that restricting the search space leads to considerably
faster convergence.

7 Conclusions

We presented a novel  modular approach to induce transfer learning in BO. Rather than designing
a specialized multi-task model  our simple method automatically crafts promising search spaces

8

01020304050iteration0.10.00.10.20.30.40.5log10(normalized (1-AUC))Aggregated OpenML resultsRandomEllipsoid + Random (n=1)Ellipsoid + Random (n=2)Ellipsoid + Random (n=4)Ellipsoid + Random (n=8)Ellipsoid + Random (n=16)Ellipsoid + Random (n=32)Ellipsoid + Random (n=64)Ellipsoid + Random (n=128)Ellipsoid + Random (n=256)01020304050iteration0.10.00.10.20.30.40.5log10(normalized (1-AUC))Aggregated OpenML resultsRandomEllipsoid + Random (T=3)Ellipsoid + Random (T=9)Ellipsoid + Random (T=15)Ellipsoid + Random (T=21)Ellipsoid + Random (T=27)01020304050iteration0.500.250.000.250.500.751.001.251.50log10(normalized MSE)Aggregated Neural Network resultsRandomBox + RandomEllipsoid + RandomGPBox + GPSMACBox + SMAC2.01.51.00.50.00.51.01.5log10 resources0.500.250.000.250.500.751.001.251.50log10(normalized MSE)Aggregated Neural Network resultsRandomHBEllipsoid HBBox HBbased on previously run experiments. Over an extensive set of benchmarks  we showed that our
approach signiﬁcantly speeds up the optimization  and can be seamlessly combined with a wide
range of existing BO techniques. Beyond those we used in our experiments  we can further mention
recent resource-aware optimizers [2  8]  evolutionary-based techniques [18  34] and virtually any core
improvement of BO  be it related to the acquisition function [48] or efﬁcient parallelism [23  47].
The proposed method could be extended in a model-based fashion  allowing us to simultaneously
search for the best HP conﬁgurations xt’s for each data set  together with compact spaces contain-
ing all of these conﬁgurations. When evaluation data from a large number of tasks is available 
heterogeneity in their minima may be better captured by employing a mixture of boxes or ellipsoids.

References
[1] GPyOpt:

A

optimization
https://github.com/SheffieldML/GPyOpt  2016.

Bayesian

framework

in

Python.

[2] B. Baker  O. Gupta  R. Raskar  and N. Naik. Accelerating neural architecture search using

performance prediction. Technical report  preprint Arxiv 1705.10823  2017.

[3] R. Bardenet  M. Brendel  B. Kégl  and M. Sebag. Collaborative hyperparameter tuning. In
Proceedings of the International Conference on Machine Learning (ICML)  pages 199–207 
2013.

[4] J. Bergstra  R. Bardenet  Y. Bengio  B. Kégl  et al. Algorithms for hyper-parameter optimization.

In Advances in Neural Information Processing Systems  volume 24  pages 2546–2554  2011.

[5] S. P. Boyd and L. Vandenberghe. Convex Optimization. Cambridge University Press  2004.

[6] S. Diamond  E. Chu  and S. Boyd. CVXPY: A Python-embedded modeling language for convex

optimization  version 0.2. http://cvxpy.org/  May 2014.

[7] Facebook. Ax  adaptive experimentation platform  2019.

[8] S. Falkner  A. Klein  and F. Hutter. Bohb: Robust and efﬁcient hyperparameter optimization
at scale. In Proceedings of the International Conference on Machine Learning (ICML)  pages
1436–1445  2018.

[9] M. Feurer  B. Letham  and E. Bakshy. Scalable meta-learning for Bayesian optimization using
ranking-weighted Gaussian process ensembles. In ICML 2018 AutoML Workshop  July 2018.

[10] M. Feurer  T. Springenberg  and F. Hutter. Initializing Bayesian hyperparameter optimization via
meta-learning. In Proceedings of the Twenty-Ninth AAAI Conference on Artiﬁcial Intelligence 
2015.

[11] N. Fusi and H. M. Elibol. Probabilistic matrix factorization for automated machine learning.

Technical report  preprint arXiv:1705.05355  2017.

[12] J. D. Gammell and T. D. Barfoot. The probability density function of a transformation-based

hyperellipsoid sampling technique. Technical report  preprint arXiv:1404.1347  2014.

[13] J. Gardner  M. Kusner  Z. Xu  K. Weinberger  and J. Cunningham. Bayesian optimization
with inequality constraints. In Proceedings of the 31st International Conference on Machine
Learning (ICML-14)  pages 937–945  2014.

[14] E. C. Garrido-Merchán and D. Hernández-Lobato. Predictive entropy search for multi-objective

Bayesian optimization with constraints. Technical report  preprint arXiv:1609.01051  2016.

[15] D. Golovin  B. Solnik  S. Moitra  G. Kochanski  J. Karro  and D. Sculley. Google Vizier: A
service for black-box optimization. In Proceedings of the 23rd ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining  pages 1487–1495  2017.

[16] R. B. Gramacy and H. K. Lee. Optimization under unknown constraints. Technical report 

preprint arXiv:1004.4027  2010.

9

[17] M. Grötschel  L. Lovász  and A. Schrijver. Geometric algorithms and combinatorial optimiza-

tion  volume 2. Springer Science & Business Media  2012.

[18] N. Hansen. The cma evolution strategy: A tutorial. Technical report  preprint arXiv:1604.00772 

2016.

[19] R. Harman and V. Lacko. On decompositional algorithms for uniform sampling from n-spheres

and n-balls. Journal of Multivariate Analysis  101(10):2297–2304  2010.

[20] F. Hutter  H. H. Hoos  and K. Leyton-Brown. Sequential model-based optimization for general

algorithm conﬁguration. In Proceedings of LION-5  page 507?523  2011.

[21] F. John. Extremum problems with inequalities as subsidiary conditions. In Studies and Essays

presented to R. Courant on his 60th Birthday  pages 187—204  1948.

[22] D. R. Jones  M. Schonlau  and W. J. Welch. Efﬁcient global optimization of expensive black-box

functions. Journal of Global optimization  13(4):455–492  1998.

[23] K. Kandasamy  A. Krishnamurthy  J. Schneider  and B. Poczos. Asynchronous parallel Bayesian

optimisation via thompson sampling. Technical report  preprint arXiv:1705.09236  2017.

[24] K. Kandasamy  K. R. Vysyaraju  W. Neiswanger  B. Paria  C. R. Collins  J. Schneider  B. Poczos 
and E. P. Xing. Tuning hyperparameters without grad students: Scalable and robust Bayesian
optimisation with Dragonﬂy. arXiv preprint arXiv:1903.06694  2019.

[25] A. Klein and F. Hutter. Tabular benchmarks for joint architecture and hyperparameter optimiza-

tion. arXiv preprint arXiv:1905.04970  2019.

[26] E. M. Knorr  R. T. Ng  and R. H. Zamar. Robust space transformations for distance-based
operations. In Proceedings of the seventh ACM SIGKDD international conference on Knowledge
discovery and data mining  pages 126–135. ACM  2001.

[27] N. Knudde  J. van der Herten  T. Dhaene  and I. Couckuyt. GPﬂowOpt: A Bayesian Optimization

Library using TensorFlow. arXiv preprint – arXiv:1711.03845  2017.

[28] H. C. L. Law  P. Zhao  J. Huang  and D. Sejdinovic. Hyperparameter learning via distributional

transfer. Technical report  preprint arXiv:1810.06305  2018.

[29] L. Li  K. Jamieson  G. DeSalvo  A. Rostamizadeh  and A. Talwalkar. Hyperband: A novel
bandit-based approach to hyperparameter optimization. Journal of Machine Learning Research 
18(185):1–52  2018.

[30] J. Mockus  V. Tiesis  and A. Zilinskas. The application of Bayesian methods for seeking the

extremum. Towards Global Optimization  2(117-129):2  1978.

[31] V. Nguyen  S. Gupta  S. Rana  C. Li  and S. Venkatesh. Filtering Bayesian optimization
approach in weakly speciﬁed search space. Knowledge and Information Systems  pages 1–29 
2018.

[32] V. Perrone  R. Jenatton  M. Seeger  and C. Archambeau. Scalable hyperparameter transfer

learning. In Advances in Neural Information Processing Systems (NIPS)  2018.

[33] M. Poloczek  J. Wang  and P. I. Frazier. Warm starting Bayesian optimization. In Winter

Simulation Conference (WSC)  2016  pages 770–781. IEEE  2016.

[34] E. Real  A. Aggarwal  Y. Huang  and Q. V. Le. Regularized evolution for image classiﬁer

architecture search. Technical report  preprint arXiv:1802.01548  2018.

[35] N. Schilling  M. Wistuba  and L. Schmidt-Thieme. Scalable hyperparameter optimization with
products of Gaussian process experts. In Joint European Conference on Machine Learning and
Knowledge Discovery in Databases  pages 33–48. Springer  2016.

[36] B. Shahriari  A. Bouchard-Cote  and N. Freitas. Unbounded Bayesian optimization via regular-
ization. In Proceedings of the International Conference on Artiﬁcial Intelligence and Statistics
(AISTATS)  pages 1168–1176  2016.

10

[37] B. Shahriari  K. Swersky  Z. Wang  R. P. Adams  and N. de Freitas. Taking the human out of
the loop: A review of Bayesian optimization. Proceedings of the IEEE  104(1):148–175  2016.

[38] J. Snoek  H. Larochelle  and R. P. Adams. Practical Bayesian optimization of machine learning
algorithms. In Advances in Neural Information Processing Systems  pages 2960–2968  2012.

[39] J. Snoek  O. Rippel  K. Swersky  R. Kiros  N. Satish  N. Sundaram  M. Patwary  M. Prabhat 
and R. Adams. Scalable Bayesian optimization using deep neural networks. In Proceedings of
the International Conference on Machine Learning (ICML)  pages 2171–2180  2015.

[40] J. Snoek  K. Swersky  R. Zemel  and R. Adams. Input warping for Bayesian optimization of
non-stationary functions. In Proceedings of the International Conference on Machine Learning
(ICML)  pages 1674–1682  2014.

[41] J. T. Springenberg  A. Klein  S. Falkner  and F. Hutter. Bayesian optimization with robust
Bayesian neural networks. In Advances in Neural Information Processing Systems (NIPS) 
pages 4134–4142  2016.

[42] P. Sun and R. M. Freund. Computation of minimum-volume covering ellipsoids. Operations

Research  52(5):690–706  2004.

[43] K. Swersky  J. Snoek  and R. P. Adams. Multi-task Bayesian optimization. In Advances in

Neural Information Processing Systems (NIPS)  pages 2004–2012  2013.

[44] L. Valkov  R. Jenatton  F. Winkelmolen  and C. Archambeau. A simple transfer-learning

extension of Hyperband. In NIPS Workshop on Meta-Learning  2018.

[45] J. N. van Rijn and F. Hutter. Hyperparameter importance across datasets. In Proceedings of the
24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining  pages
2367–2376. ACM  2018.

[46] J. Vanschoren  J. N. Van Rijn  B. Bischl  and L. Torgo. OpenML: Networked science in machine

learning. ACM SIGKDD Explorations Newsletter  15(2):49–60  2014.

[47] Z. Wang  C. Li  S. Jegelka  and P. Kohli. Batched high-dimensional Bayesian optimization via

structural kernel learning. Technical report  preprint arXiv:1703.01973  2017.

[48] J. Wilson  F. Hutter  and M. Deisenroth. Maximizing acquisition functions for Bayesian
optimization. In Advances in Neural Information Processing Systems (NIPS)  pages 9906–9917 
2018.

[49] M. Wistuba  N. Schilling  and L. Schmidt-Thieme. Hyperparameter search space pruning–a
new component for sequential model-based hyperparameter optimization. In Machine Learning
and Knowledge Discovery in Databases  pages 104–119. Springer  2015.

[50] M. Wistuba  N. Schilling  and L. Schmidt-Thieme. Learning hyperparameter optimization
initializations. In Data Science and Advanced Analytics (DSAA)  2015. 36678 2015. IEEE
International Conference on  pages 1–10. IEEE  2015.

[51] D. Yogatama and G. Mann. Efﬁcient transfer learning method for automatic hyperparameter
tuning. In Proceedings of the International Conference on Artiﬁcial Intelligence and Statistics
(AISTATS)  pages 1077–1085  2014.

11

,Valerio Perrone
Huibin Shen
Matthias Seeger
Cedric Archambeau
Rodolphe Jenatton