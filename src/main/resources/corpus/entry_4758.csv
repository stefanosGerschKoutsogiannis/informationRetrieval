2014,Robust Kernel Density Estimation by Scaling and Projection in Hilbert Space,While robust parameter estimation has been well studied in parametric density estimation  there has been little investigation into robust density estimation in the nonparametric setting. We present a robust version of the popular kernel density estimator (KDE). As with other estimators  a robust version of the KDE is useful since sample contamination is a common issue with datasets. What ``robustness'' means for a nonparametric density estimate is not straightforward and is a topic we explore in this paper. To construct a robust KDE we scale the traditional KDE and project it to its nearest weighted KDE in the $L^2$ norm. Because the squared $L^2$ norm penalizes point-wise errors superlinearly this causes the weighted KDE to allocate more weight to high density regions. We demonstrate the robustness of the SPKDE with numerical experiments and a consistency result which shows that asymptotically the SPKDE recovers the uncontaminated density under sufficient conditions on the contamination.,Robust Kernel Density Estimation by Scaling and

Projection in Hilbert Space

Robert A. Vandermeulen

Department of EECS
University of Michigan
Ann Arbor  MI 48109
rvdm@umich.edu

Clayton D. Scott
Deparment of EECS
Univeristy of Michigan
Ann Arbor  MI 48109

clayscot@umich.edu

Abstract

While robust parameter estimation has been well studied in parametric density es-
timation  there has been little investigation into robust density estimation in the
nonparametric setting. We present a robust version of the popular kernel density
estimator (KDE). As with other estimators  a robust version of the KDE is useful
since sample contamination is a common issue with datasets. What “robustness”
means for a nonparametric density estimate is not straightforward and is a topic
we explore in this paper. To construct a robust KDE we scale the traditional KDE
and project it to its nearest weighted KDE in the L2 norm. This yields a scaled
and projected KDE (SPKDE). Because the squared L2 norm penalizes point-wise
errors superlinearly this causes the weighted KDE to allocate more weight to high
density regions. We demonstrate the robustness of the SPKDE with numerical
experiments and a consistency result which shows that asymptotically the SPKDE
recovers the uncontaminated density under sufﬁcient conditions on the contami-
nation.

1

Introduction

The estimation of a probability density function (pdf) from a random sample is a ubiquitous problem
in statistics. Methods for density estimation can be divided into parametric and nonparametric 
depending on whether parametric models are appropriate. Nonparametric density estimators (NDEs)
offer the advantage of working under more general assumptions  but they also have disadvantages
with respect to their parametric counterparts. One of these disadvantages is the apparent difﬁculty in
making NDEs robust  which is desirable when the data follow not the density of interest  but rather
a contaminated version thereof. In this work we propose a robust version of the KDE  which serves
as the workhorse among NDEs [11  10].
We consider the situation where most observations come from a target density ftar but some ob-
servations are drawn from a contaminating density fcon  so our observed samples come from the
density fobs = (1 − ε) ftar + εfcon. It is not known which component a given observation comes
from. When considering this scenario in the inﬁnite sample setting we would like to construct some
transform that  when applied to fobs  yields ftar. We introduce a new formalism to describe trans-
formations that “decontaminate” fobs under sufﬁcient conditions on ftar and fcon. We focus on a
speciﬁc nonparametric condition on ftar and fcon that reﬂects the intuition that the contamination
manifests in low density regions of ftar. In the ﬁnite sample setting  we seek a NDE that converges
to ftar asymptotically. Thus  we construct a weighted KDE where the kernel weights are lower in
low density regions and higher in high density regions. To do this we multiply the standard KDE
by a real value greater than one (scale) and then ﬁnd the closest pdf to the scaled KDE in the L2
norm (project)  resulting in a scaled and projected kernel density estimator (SPKDE). Because the
squared L2 norm penalizes point-wise differences between functions quadratically  this causes the

1

SPKDE to draw weight from the low density areas of the KDE and move it to high density areas to
get a more uniform difference to the scaled KDE. The asymptotic limit of the SPKDE is a scaled
and shifted version of fobs. Given our proposed sufﬁcient conditions on ftar and fcon  the SPKDE
can asymptotically recover ftar.
A different construction for a robust kernel density estimator  the aptly named “robust kernel density
estimator” (RKDE)  was developed by Kim & Scott [6]. In that paper the RKDE was analytically
and experimentally shown to be robust  but no consistency result was presented. Vandermeulen
& Scott [15] proved that a certain version of the RKDE converges to fobs. To our knowledge the
convergence of the SPKDE to a transformed version of fobs  which is equal to ftar under sufﬁcient
conditions on ftar and fcon  is the ﬁrst result of its type.
In this paper we present a new formalism for nonparametric density estimation  necessary and suf-
ﬁcient conditions for decontamination  the construction of the SPKDE  and a proof of consistency.
We also include experimental results applying the algorithm to benchmark datasets with compar-
isons to the RKDE  traditional KDE  and an alternative robust KDE implementation. Many of our
results and proof techniques are novel in KDE literature. Proofs are contained in the supplemental
material.

2 Nonparametric Contamination Models and Decontamination Procedures

for Density Estimation

What assumptions are necessary and sufﬁcient on a target and contaminating density in order to
theoretically recover the target density is a question that  to the best of our knowledge  is completely
unexplored in a nonparametric setting. We will approach this problem in the inﬁnite sample setting 
where we know fobs = (1 − ε)ftar + εfcon and ε  but do not know ftar or fcon. To this end we
introduce a new formalism. Let D be the set of all pdfs on Rd. We use the term contamination
model to refer to any subset V ⊂ D × D  i.e. a set of pairs (ftar  fcon). Let Rε : D → D be
a set of transformations on D indexed by ε ∈ [0  1). We say that Rε decontaminates V if for all
(ftar  fcon) ∈ V and ε ∈ [0  1) we have Rε((1 − ε)ftar + εfcon) = ftar.
One may wonder whether there exists some set of contaminating densities  Dcon  and a transfor-
mation  Rε  such that Rε decontaminates D × Dcon. In other words  does there exist some set of
contaminating densities for which we can recover any target density? It turns out this is impossible
if Dcon contains at least two elements.
Proposition 1. Let Dcon ⊂ D contain at least two elements. There does not exist any transformation
Rε which decontaminates D × Dcon.
Proof. Let f ∈ D and g  g(cid:48) ∈ Dcon such that g (cid:54)= g(cid:48). Let ε ∈ (0  1
and f(cid:48)

2 ). Clearly ftar (cid:44) f (1−2ε)+gε

are both elements of D. Note that

(cid:44) f (1−2ε)+εg(cid:48)

1−ε

tar

1−ε

(1 − ε)ftar + εg(cid:48) = (1 − ε)f(cid:48)

tar + εg.

In order for Rε to decontaminate D with respect to Dcon  we need Rε ((1 − ε)ftar + εg(cid:48)) = ftar
and Rε ((1 − ε)f(cid:48)

tar  which is impossible since ftar (cid:54)= f(cid:48)

tar + εg) = f(cid:48)

tar.

This proposition imposes signiﬁcant limitations on what contamination models can be decontami-
nated. For example  suppose we know that fcon is Gaussian with known covariance matrix and un-
known mean. Proposition 1 says we cannot design Rε so that it can decontaminate (1−ε)ftar+εfcon
for all ftar ∈ D. In other words  it is impossible to design an algorithm capable of removing Gaus-
sian contamination (for example) from arbitrary target densities. Furthermore  if Rε decontaminates
V and V is fully nonparametric (i.e. for all f ∈ D there exists some f(cid:48) ∈ D such that (f  f(cid:48)) ∈ V)
then for each (ftar  fcon) pair  fcon must satisfy some properties which depend on ftar.

2.1 Proposed Contamination Model
For a function f : Rd → R let supp(f ) denote the support of f. We introduce the following
contamination assumption:

2

(ftar fcon)∈VA

Assumption A. For the pair (ftar  fcon)  there exists u such that fcon(x) = u for almost all (in the
Lebesgue sense) x ∈ supp(ftar) and fcon(x(cid:48)) ≤ u for almost all x(cid:48) /∈ supp(ftar).
See Figure 1 for an example of a density satisfying this assumption. Because fcon must be uniform
over the support of ftar a consequence of Assumption A is that supp(ftar) has ﬁnite Lebesgue mea-
sure. Let VA be the contamination model containing all pairs of densities which satisfy Assumption
ftar is exactly all densities whose support has ﬁnite Lebesgue measure 

A. Note that(cid:83)

which includes all densities with compact support.
The uniformity assumption on fcon is a common “noninformative” assumption on the contamina-
tion. Furthermore  this assumption is supported by connections to one-class classiﬁcation. In that
problem  only one class (corresponding to our ftar) is observed for training  but the testing data is
drawn from fobs and must be classiﬁed. The dominant paradigm for nonparametric one-class clas-
siﬁcation is to estimate a level set of ftar from the one observed training class [14  7  13  16  12  9] 
and classify test data according to that level set. Yet level sets only yield optimal classiﬁers (i.e.
likelihood ratio tests) under the uniformity assumption on fcon  so that these methods are implicitly
adopting this assumption. Furthermore  a uniform contamination prior has been shown to optimize
the worst-case detection rate among all choices for the unknown contamination density [5]. Finally 
our experiments demonstrate that the SPKDE works well in practice  even when Assumption A is
signiﬁcantly violated.

2.2 Decontamination Procedure

Under Assumption A ftar is present in fobs and its shape is left unmodiﬁed (up to a multiplicative
factor) by fcon. To recover ftar it is necessary to ﬁrst scale fobs by β = 1

1−ε yielding

1
1 − ε

((1 − ε)ftar + εfcon) = ftar +

ε
1 − ε

fcon.

ε

1−ε fcon from the bottom of ftar + ε

(1)
1−ε fcon. This transform

After scaling we would like to slice off
is achieved by

(cid:26)

(cid:27)

max

0  ftar +

ε
1 − ε

fcon − α

 

(2)

where α is set such that 2 is a pdf (which in this case is achieved with α = r ε
show that this transform is well deﬁned in a general sense. Let f be a pdf and let

1−ε). We will now

gβ α = max{0  βf (·) − α}

where the max is deﬁned pointwise. The following lemma shows that it is possible to slice off the
bottom of any scaled pdf to get a transformed pdf and that the transformed pdf is unique.
Lemma 1. For ﬁxed β > 1 there exists a unique α(cid:48) > 0 such that (cid:107)gβ α(cid:48)(cid:107)L1 = 1.
Figure 2 demonstrates this transformation applied to a pdf. We deﬁne the following transform
ε (f ) is a pdf.
RA
ε

(cid:110) 1
(cid:111)
1−ε f (·) − α  0

: D → D where RA

where α is such that RA

Proposition 2. RA

ε (f ) = max
ε decontaminates VA.

The proof of this proposition is an intermediate step for
the proof for Theorem 2. For any two subsets of V V(cid:48) ⊂
D × D  Rε decontaminates V and V(cid:48) iff Rε decontam-

inates V(cid:83)V(cid:48). Because of this  every decontaminating

ε   i.e. the set VA is maximal.

transform has a maximal set which it can decontaminate.
Assumption A is both sufﬁcient and necessary for decon-
tamination by RA
Proposition 3. Let {(q  q(cid:48))} ∈ D × D and (q  q(cid:48)) /∈ VA.
ε cannot decontaminate {(q  q(cid:48))}.
RA
The proof of this proposition is in the supplementary ma-
terial.

2.3 Other Possible Contamination Models

3

Figure 1: Density with contamination
satisfying Assumption A

 εfcon(1-ε)ftarNext we would select some threshold λ > 0 and declare a sample  Xi  as being anomalous if

Figure 2: Inﬁnite sample SPKDE transform. Arrows indi-
cate the area under the line.

The model described previously is
just one of many possible mod-
els. An obvious approach to robust
kernel density estimation is to use
an anomaly detection algorithm and
construct the KDE using only non-
anomalous samples. We will inves-
tigate this model under a couple of
anomaly detection schemes and de-
scribe their properties.
One of the most common methods for anomaly detection is the level set method. For a probability
measure µ this method attempts to ﬁnd the set S with smallest Lebesgue measure such that µ(S)
is above some threshold  t  and declares samples outside of that set as being anomalous. For a
{x|f (x)≥λ} f (y)dy = t and declaring samples
were f (X) < λ as being anomalous. Let X1  . . .   Xn be iid samples from fobs. Using the level

density f this is equivalent to ﬁnding λ such that(cid:82)
set method for a robust KDE  we would construct a density (cid:98)fobs which is an estimate of fobs.
(cid:98)fobs(Xi) < λ. Finally we would construct a KDE using the non-anomalous samples. Let χ{·} be
the indicator function. Applying this method in the inﬁnite sample situation  i.e. (cid:98)fobs = fobs  would
(cid:82) χ{f (y)>λ}f (y)dy. See Figure 3. Perfect recovery of ftar using this method requires εfcon(x) ≤

cause our non-anomalous samples to come from the density p(x) =
where τ =
ftar(x) (1 − ε) for all x and that fcon and ftar have disjoint supports. The ﬁrst assumption means
that this density estimator can only recover ftar if it has a drop off on the boundary of its support 
whereas Assumption A only requires that ftar have ﬁnite support. See the last diagram in Figure
3. Although these assumptions may be reasonable in certain situations  we ﬁnd them less palatable
than Assumption A. We also evaluate this approach experimentally later and ﬁnd that it performs
poorly.
Another approach based on anomaly detection
would be to ﬁnd the connected components of
fobs and declare those that are  in some sense 
small as being anomalous. A “small” con-
nected component may be one that integrates
to a small value  or which has a small mode.
Unfortunately this approach also assumes that
ftar and fcon have disjoint supports. There are
also computational issues with this anomaly de-
tection scheme; ﬁnding connected components 
ﬁnding modes  and numerical integration are
computationally difﬁcult.
To some degree  RA
ε actually achieves the ob-
jectives of the previous two robust KDEs. For
the ﬁrst model  the RA
ε does indeed set those regions of the pdf that are below some threshold to
zero. For the second  if the magnitude of the level at which we choose to slice off the bottom of
the contaminated density is larger than the mode of the anomalous component then the anomalous
component will be eliminated.

Figure 3: Inﬁnite sample version of the level set
rejection KDE

fobs(x)χ{fobs (x)>λ}

τ

3 Scaled Projection Kernel Density Estimator

ε in a ﬁnite sample situation. Let f ∈ L2(cid:0)Rd(cid:1) be a pdf and
such that kσ (x  x(cid:48)) = σ−dq ((cid:107)x − x(cid:48)(cid:107)2 /σ)  where q ((cid:107)·(cid:107)2) ∈ L2(cid:0)Rd(cid:1) and is a pdf. The classic

Here we consider approximating RA
X1  . . .   Xn be iid samples from f. Let kσ (x  x(cid:48)) be a radial smoothing kernel with bandwidth σ

kernel density estimator is:

¯f n
σ :=

1
n

kσ (·  Xi) .

n(cid:88)

1

4

 1-1/βOriginal DensityScaled DensityShifted to pdfβ-1λOriginal DensityThreshold at λ Set density under threshold to 0Normalize to integrate to 1In practice ε is usually not known and Assumption A is violated. Because of this we will scale our
density by β > 1 rather than 1

1−ε. For a density f deﬁne
Qβ(f ) (cid:44) max{βf (·) − α  0}  

where α = α(β) is set such that the RHS is a pdf. β can be used to tune robustness with larger
β corresponding to more robustness (setting β to 1 in all the following transforms simply yields
the KDE). Given a KDE we would ideally like to apply Qβ directly and search over α until

σ (·) − α  0(cid:9) integrates to 1. Such an estimate requires multidimensional numerical in-

max(cid:8)β ¯f n

tegration and is not computationally tractable. The SPKDE is an alternative approach that always
yields a density and manifests the transformed density in its asymptotic limit.
We now introduce the construction of
σ be the convex hull of
kσ (·  X1)   . . .   kσ (·  Xn) (the space of weighted kernel density estimators). The SPKDE is de-
ﬁned as

the SPKDE. Let Dn

which is guaranteed to have a unique minimizer since Dn
in a Hilbert space ([1] Theorem 3.14). If we represent f n

σ is closed and convex and we are projecting
σ β in the form

f n
σ β := arg min
g∈Dn

σ

(cid:13)(cid:13)β ¯f n
σ − g(cid:13)(cid:13)L2  
n(cid:88)

aikσ (·  Xi)  

f n
σ β =

1

then the minimization problem is a quadratic program over the vector a = [a1  . . .   an]T   with a
restricted to the probabilistic simplex  ∆n. Let G be the Gram matrix of kσ (·  X1)   . . .   kσ (·  Xn) 
that is

(cid:90)

Gij = (cid:104)kσ (·  Xi)   kσ (·  Xj)(cid:105)L2

=

kσ (x  Xi) kσ (x  Xj) dx.

Let 1 be the ones vector and b = G1 β

n  then the quadratic program is

aT Ga − 2bT a.

min
a∈∆n

Since G is a Gram matrix  and therefore positive-semideﬁnite  this quadratic program is convex.
Furthermore  the integral deﬁning Gij can be computed in closed form for many kernels of interest.
For example for the Gaussian kernel

(cid:32)−(cid:107)x − x(cid:48)(cid:107)2

(cid:33)

2 exp

2σ2

=⇒ Gij = k√

2σ(Xi  Xj) 

kσ (x  x(cid:48)) =(cid:0)2πσ2(cid:1)− d
(cid:1)
Γ(cid:0) 1+d

2

1 +

σ2

2

(cid:32)

(cid:107)x − x(cid:48)(cid:107)2

kσ (x  x(cid:48)) =

π(d+1)/2 · σd

and for the Cauchy kernel [2]

We now present some results on the asymptotic behavior of the SPKDE. Let D be the set of all pdfs

(cid:33)− 1+d
in L2(cid:0)Rd(cid:1). The inﬁnite sample version of the SPKDE is
h∈D (cid:107)βf − h(cid:107)2
L2 .
deﬁned if the convex set we are projecting onto is closed and convex. D is not closed in L2(cid:0)Rd(cid:1) 

It is worth noting that projection operators in Hilbert space  like the one above  are known to be well

=⇒ Gij = k2σ(Xi  Xj).

f(cid:48)
β = arg min

but this turns out not to be an issue because of the form of βf. For details see the proof of Lemma
2 in the supplemental material.
Lemma 2. f(cid:48)

β = max{βf (·) − α  0} where α is set such that max{βf (·) − α  0} is a pdf.

5

Given the same rate on bandwidth necessary for consistency of the traditional KDE  the SPKDE
converges to its inﬁnite sample version in its asymptotic limit.

Theorem 1. Let f ∈ L2(cid:0)Rd(cid:1). If n → ∞ and σ → 0 with nσd → ∞ then
(cid:13)(cid:13)(cid:13)f n

Because f n
L1 convergence.
Corollary 1. Given the conditions in the previous theorem statement 

σ β is a sequence of pdfs and f(cid:48)

β ∈ L2(cid:0)Rd(cid:1)  it is possible to show L2 convergence implies

σ β − f(cid:48)

σ β − f(cid:48)

p→ 0.

p→ 0.

(cid:13)(cid:13)(cid:13)L1

β

(cid:13)(cid:13)(cid:13)f n

(cid:13)(cid:13)(cid:13)L2

β

To summarize  the SPKDE converges to a transformed version of f. In the next section we will
show that under Assumption A and with β = 1

1−ε  the SPKDE converges to ftar.

3.1 SPKDE Decontamination

Let ftar ∈ L2(cid:0)Rd(cid:1) be a pdf having support with ﬁnite Lebesgue measure and let ftar and fcon

satisfy Assumption A. Let X1  X2  . . .   Xn be iid samples from fobs = (1 − ε) ftar + εfcon with
ε ∈ [0  1). Finally let f n
σ β be the SPKDE constructed from X1  . . .   Xn  having bandwidth σ and
robustness parameter β. We have
1−ε . If n → ∞ and σ → 0 with nσd → ∞ then
Theorem 2. Let β = 1

σ β − ftar

p→ 0.

(cid:13)(cid:13)(cid:13)f n

(cid:13)(cid:13)(cid:13)L1

To our knowledge this result is the ﬁrst of its kind  wherein a nonparametric density estimator is able
to asymptotically recover the underlying density in the presence of contaminated data.

4 Experiments

For all of the experiments optimization was performed using projected gradient descent. The pro-
jection onto the probabilistic simplex was done using the algorithm developed in [4] (which was
actually originally discovered a few decades ago [3  8]).

4.1 Synthetic Data

To show that the SPKDE’s theoretical properties are manifested in practice we conducted an ide-
alized experiment where the contamination is uniform and the contamination proportion is known.
Figure 4 exhibits the ability of the SPKDE to compensate for uniform noise. Samples for the den-
sity estimator came from a mixture of the “Target” density with a uniform contamination on [−2  2] 
sampling from the contamination with probability ε = 0.2. This experiment used 500 samples and
4 (the value for perfect asymptotic decontamination).
the robustness parameter β was set to 1
The SPKDE performs well in this situation and yields a scaled and shifted version of the standard
KDE. This scale and shift is especially evident in the preservation of the bump on the right hand side
of Figure 4.

1−ε = 5

4.2 Datasets

In our remaining experiments we investigate two performance metrics for different amounts of con-
tamination. We perform our experiments on 12 classiﬁcation datasets (names given in the supple-
mental material) where the 0 label is used as the target density and the 1 label is the anomalous
contamination. This experimental setup does not satisfy Assumption A. The training datasets are
1−ε n0 samples from label 1  thus making an ε pro-
constructed with n0 samples from label 0 and ε
portion of our samples come from the contaminating density. For our experiments we use the values
ε = 0  0.05  0.1  0.15  0.20  0.25  0.30. Given some dataset we are interested in how well our density

estimators (cid:98)f estimate the density of the 0 class of our dataset  ftar. Each test is performed on 15

permutations of the dataset. The experimental setup here is similar to the setup in Kim & Scott [6] 
the most signiﬁcant difference being that σ is set differently.

4.3 Performance Criteria

6

First we investigate the Kullback-Leibler (KL)
divergence

(cid:16)(cid:98)f||f0

(cid:17)

=

(cid:90) (cid:98)f (x) log

(cid:32) (cid:98)f (x)

(cid:33)

dx.

DKL

f0 (x)

f0 to have mass where it does not. For exam-

This KL divergence is large when (cid:98)f estimates
ple  in our context  (cid:98)f makes mistakes because
ple using a KDE  (cid:101)f0. The bandwidth for (cid:101)f0 is

of outlying contamination. We estimate this KL
divergence as follows. Since we do not have ac-
cess to f0  it is estimated from the testing sam-

(cid:16)
f0||(cid:101)f0
set using the testing data with a LOOCV line
search minimizing DKL
  which is de-
scribed in more detail below. We then approxi-
erating samples from (cid:98)f  {x(cid:48)
mate the integral using a sample mean by gen-
i}n(cid:48)
1 and using the

(cid:17)

estimate

(cid:16)(cid:98)f||f0

(cid:17) ≈ 1

n(cid:48)

n(cid:48)(cid:88)

1

DKL

(cid:33)

(cid:32) (cid:98)f (x(cid:48)
(cid:101)f0 (x(cid:48)

i)
i)

.

(cid:90)

dx = C −

log

(cid:33)

(cid:32)

f0 (x)

(cid:98)f (x)

(cid:16)
(cid:17)
f0||(cid:98)f

(cid:90)

The number of generated samples n(cid:48) is set to double the number of training samples.
Since KL divergence isn’t symmetric we also investigate

(cid:16)(cid:98)f (y)

(cid:17)

Figure 4: KDE and SPKDE in the presence of uni-
form noise

DKL

=

f0 (x) log

where C is a constant not depending on (cid:98)f. This KL divergence is large when f0 has mass where (cid:98)f

f0 (y) log

dy 

does not. The ﬁnal term is easy to estimate using expectation. Let {x(cid:48)(cid:48)
f0 (not used for training). The following is a reasonable approximation

1 be testing samples from

(cid:90)

−

(cid:16)(cid:98)f (y)

(cid:17)

f0 (y) log

dy ≈ − 1
n(cid:48)(cid:48)

i }n(cid:48)(cid:48)
(cid:17)

i )

.

(cid:16)(cid:98)f (x(cid:48)(cid:48)

n(cid:48)(cid:48)(cid:88)

1

log

For a given performance metric and contamination amount  we compare the mean performance of
two density estimators across datasets using the Wilcoxon signed rank test [17]. Given N datasets
we ﬁrst rank the datasets according to the absolute difference between performance criterion  with
hi being the rank of the ith dataset. For example if the jth dataset has the largest absolute difference
we set hj = N and if the kth dataset has the smallest absolute difference we set hk = 1. We let
R1 be the sum of the his where method one’s metric is greater than metric two’s and R2 be the sum
of the his where method two’s metric is larger. The test statistic is min(R1  R2)  which we do not
report. Instead we report R1 and R2 and the p-value that the two methods do not perform the same
on average. Ri < Rj is indicative of method i performing better than method j.

4.4 Methods

The data were preprocessed by scaling to ﬁt in the unit cube. This scaling technique was chosen over
whitening because of issues with singular covariance matrices. The Gaussian kernel was used for
all density estimates. For each permutation of each dataset  the bandwidth parameter is set using the
training data with a LOOCV line search minimizing DKL
the contaminated data and fobs is the observed density. This metric was used in order to maximize
the performance of the traditional KDE in KL divergence metrics. For the SPKDE the parameter β
was chosen to be 2 for all experiments. This choice of β is based on a few preliminary experiments

  where (cid:98)f is the KDE based on

(cid:17)
fobs||(cid:98)f

(cid:16)

7

−2−1.5−1−0.500.511.5200.10.20.30.40.50.60.70.8 KDESPKDETargetTable 1: Wilcoxon signed rank test results

Wilcoxon Test Applied to DKL

(cid:16)(cid:98)f||f0

(cid:17)

ε

SPKDE
KDE
p-value
SPKDE
RKDE
p-value
SPKDE
rejKDE
p-value

0.15

0.05

2
76

0
78

0
5
73

0.1
1
77

0.2
0
78
.0049 5e-4 1e-3 .0015 5e-4
63
15
.064

67
11
.027

58
20
0.15

53
25
0.31

59
19
0.13

0.25

0
78
5e-4
61
17
.092

0.3
0
78
5e-4
63
15
.064

0
78
5e-4

0
1
78
77
5e-4 1e-3

1
77
1e-3

0
0
78
78
5e-4 .0015 5e-4

2
76

(cid:16)

(cid:17)
f0||(cid:98)f

0.25
16
62

0.1
27
51
.38
14
64

0.15
21
57
.18
10
68

0.05
30
48
.52
14
64

Wilcoxon Test Applied to DKL
0.3
0.2
0
17
17
37
61
61
41
.092 .078 .092
.91
12
10
14
64
68
66
.052 .052 .052 .021 .021 .034 .034
15
11
29
63
49
67
.064 .043 .016 .027
.47

21
57
.18

19
59
.13

13
65

9
69

12
66

for which it yielded good results over various sample contamination amounts. The construction of
the RKDE follows exactly the methods outlined in the “Experiments” section of Kim & Scott [6].
It is worth noting that the RKDE depends on the loss function used and that the Hampel loss used
in these experiments very aggressively suppresses the kernel weights on the tails. Because of this
we expect that RKDE performs well on the DKL
metric. We also compare the SPKDE to a
kernel density estimator constructed from samples declared non-anomalous by a level set anomaly
detection as described in Section 2.3. To do this we ﬁrst construct the classic KDE  ¯f n
σ and then
reject those samples in the lower 10th percentile of ¯f n
σ (Xi). Those samples not rejected are used in
a new KDE  the “rejKDE” using the same σ parameter.

(cid:16)(cid:98)f||f0

(cid:17)

4.5 Results

We present the results of the Wilcoxon signed rank tests in Table 1. Experimental results for each
dataset can be found in the supplemental material. From the results it is clear that the SPKDE is
effective at compensating for contamination in the DKL
metric  albeit not quite as well as
the RKDE. The main advantage of the SPKDE over the RKDE is that it signiﬁcantly outperforms
the RKDE in the DKL
metric. The rejKDE performs signiﬁcantly worse than the SPKDE
on almost every experiment. Remarkably the SPKDE outperforms the KDE in the situation with no
contamination (ε = 0) for both performance metrics.

(cid:17)
f0||(cid:98)f

(cid:16)

(cid:16)(cid:98)f||f0

(cid:17)

5 Conclusion

Robustness in the setting of nonparametric density estimation is a topic that has received little at-
tention despite extensive study of robustness in the parametric setting. In this paper we introduced a
robust version of the KDE  the SPKDE  and developed a new formalism for analysis of robust den-
sity estimation. With this new formalism we proposed a contamination model and decontaminating
transform to recover a target density in the presence of noise. The contamination model allows that
the target and contaminating densities have overlapping support and that the basic shape of the target
density is not modiﬁed by the contaminating density. The proposed transform is computationally
prohibitive to apply directly to the ﬁnite sample KDE and the SPKDE is used to approximate the
transform. The SPKDE was shown to asymptotically converge to the desired transform. Experi-
ments have shown that the SPKDE is more effective than the RKDE at minimizing DKL
.
Furthermore the p-values for these experiments were smaller than the p-values for the DKL
experiments where the RKDE outperforms the SPKDE.

(cid:17)
(cid:16)
f0||(cid:98)f
(cid:16)(cid:98)f||f0
(cid:17)

Acknowledgements

This work support in part by NSF Awards 0953135  1047871  1217880  1422157. We would also
like to thank Samuel Brodkey for his assistance with the simulation code.

8

References
[1] H.H. Bauschke and P.L. Combettes. Convex analysis and monotone operator theory in Hilbert
spaces. CMS Books in Mathematics  Ouvrages de math´ematiques de la SMC. Springer New
York  2011.

[2] D.A. Berry  K.M. Chaloner  J.K. Geweke  and A. Zellner. Bayesian Analysis in Statistics and
Econometrics: Essays in Honor of Arnold Zellner. A Wiley Interscience publication. Wiley 
1996.

[3] Peter Brucker. An o(n) algorithm for quadratic knapsack problems. Operations Research

Letters  3(3):163 – 166  1984.

[4] John C. Duchi  Shai Shalev-Shwartz  Yoram Singer  and Tushar Chandra. Efﬁcient projections

onto the l1-ball for learning in high dimensions. In ICML  pages 272–279  2008.

[5] R. El-Yaniv and M. Nisenson. Optimal single-class classiﬁcation strategies. In B. Sch¨olkopf 
J. Platt  and T. Hoffman  editors  Adv. in Neural Inform. Proc. Systems 19. MIT Press  Cam-
bridge  MA  2007.

[6] J. Kim and C. Scott. Robust kernel density estimation. J. Machine Learning Res.  13:2529–

2565  2012.

[7] G. Lanckriet  L. El Ghaoui  and M. I. Jordan. Robust novelty detection with single-class mpm.
In S. Thrun S. Becker and K. Obermayer  editors  Advances in Neural Information Processing
Systems 15  pages 905–912. MIT Press  Cambridge  MA  2003.

[8] P.M. Pardalos and N. Kovoor. An algorithm for a singly constrained class of quadratic pro-
grams subject to upper and lower bounds. Mathematical Programming  46(1-3):321–328 
1990.

[9] B. Sch¨olkopf  J. Platt  J. Shawe-Taylor  A. Smola  and R. Williamson. Estimating the support

of a high-dimensional distribution. Neural Computation  13(7):1443–1472  2001.

[10] D. W. Scott. Multivariate Density Estimation. Wiley  New York  1992.
[11] B. W. Silverman. Density Estimation for Statistics and Data Analysis. Chapman and Hall 

London  1986.

[12] K. Sricharan and A. Hero. Efﬁcient anomaly detection using bipartite k-nn graphs. In J. Shawe-
Taylor  R.S. Zemel  P. Bartlett  F.C.N. Pereira  and K.Q. Weinberger  editors  Advances in
Neural Information Processing Systems 24  pages 478–486. 2011.

[13] I. Steinwart  D. Hush  and C. Scovel. A classiﬁcation framework for anomaly detection. JMLR 

6:211–232  2005.

[14] J. Theiler and D. M. Cai. Resampling approach for anomaly detection in multispectral images.

In Proc. SPIE  volume 5093  pages 230–240  2003.

[15] R. Vandermeulen and C. Scott. Consistency of robust kernel density estimators. COLT  30 

2013.

[16] R. Vert and J.-P. Vert. Consistency and convergence rates of one-class SVM and related algo-

rithms. JMLR  pages 817–854  2006.

[17] F. Wilcoxon. Individual comparisons by ranking methods. Biometrics Bulletin  1(6):80–83 

1945.

9

,Robert Vandermeulen
Clayton Scott