2019,Are Anchor Points Really Indispensable in Label-Noise Learning?,In label-noise learning  the \textit{noise transition matrix}  denoting the probabilities that clean labels flip into noisy labels  plays a central role in building \textit{statistically consistent classifiers}. Existing theories have shown that the transition matrix can be learned by exploiting \textit{anchor points} (i.e.  data points that belong to a specific class almost surely). However  when there are no anchor points  the transition matrix will be poorly learned  and those previously consistent classifiers will significantly degenerate. In this paper  without employing anchor points  we propose a \textit{transition-revision} ($T$-Revision) method to effectively learn transition matrices  leading to better classifiers. Specifically  to learn a transition matrix  we first initialize it by exploiting data points that are similar to anchor points  having high \textit{noisy class posterior probabilities}. Then  we modify the initialized matrix by adding a \textit{slack variable}  which can be learned and validated together with the classifier by using noisy data. Empirical results on benchmark-simulated and real-world label-noise datasets demonstrate that without using exact anchor points  the proposed method is superior to state-of-the-art label-noise learning methods.,Are Anchor Points Really Indispensable

in Label-Noise Learning?

Xiaobo Xia1 2 Tongliang Liu1 Nannan Wang2

Bo Han3 Chen Gong4 Gang Niu3 Masashi Sugiyama3 5

1University of Sydney

2Xidian University 3RIKEN

4Nanjing University of Science and Technology 5University of Tokyo

Abstract

In label-noise learning  the noise transition matrix  denoting the probabilities that
clean labels ﬂip into noisy labels  plays a central role in building statistically
consistent classiﬁers. Existing theories have shown that the transition matrix can be
learned by exploiting anchor points (i.e.  data points that belong to a speciﬁc class
almost surely). However  when there are no anchor points  the transition matrix
will be poorly learned  and those previously consistent classiﬁers will signiﬁcantly
degenerate. In this paper  without employing anchor points  we propose a transition-
revision (T -Revision) method to effectively learn transition matrices  leading to
better classiﬁers. Speciﬁcally  to learn a transition matrix  we ﬁrst initialize it by
exploiting data points that are similar to anchor points  having high noisy class
posterior probabilities. Then  we modify the initialized matrix by adding a slack
variable  which can be learned and validated together with the classiﬁer by using
noisy data. Empirical results on benchmark-simulated and real-world label-noise
datasets demonstrate that without using exact anchor points  the proposed method
is superior to state-of-the-art label-noise learning methods.

1

Introduction

Label-noise learning can be dated back to [1] but becomes a more and more important topic recently.
The reason is that  in this era  datasets are becoming bigger and bigger. Often  large-scale datasets
are infeasible to be annotated accurately due to the expensive cost  which naturally brings us cheap
datasets with noisy labels.
Existing methods for label-noise learning can be generally divided into two categories: algorithms that
result in statistically inconsistent/consistent classiﬁers. Methods in the ﬁrst category usually employ
heuristics to reduce the side-effect of noisy labels. For example  many state-of-the-art approaches
in this category are speciﬁcally designed to  e.g.  select reliable examples [45  14  24]  reweight
examples [33  15]  correct labels [23  17  37  32]  employ side information [39  21]  and (implicitly)
add regularization [13  12  43  39  21]. All those methods were reported to work empirically very
well. However  the differences between the learned classiﬁers and the optimal ones for clean data are
not guaranteed to vanish  i.e.  no statistical consistency has been guaranteed.
The above issue motivates researchers to explore algorithms in the second category: risk-/classiﬁer-
consistent algorithms. In general  risk-consistent methods possess statistically consistent estimators
to the clean risk (i.e.  risk w.r.t. the clean data)  while classiﬁer-consistent methods guarantee the
classiﬁer learned from the noisy data is consistent to the optimal classiﬁer (i.e.  the minimizer of the
clean risk) [42]. Methods in this category utilize the noise transition matrix  denoting the probabilities
that clean labels ﬂip into noisy labels  to build consistent algorithms. Let Y denote the variable
for the clean label  ¯Y the noisy label  and X the instance/feature. The basic idea is that given the

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

noisy class posterior probability P ( ¯Y|X = x) = [P ( ¯Y = 1|X = x)  . . .   P ( ¯Y = C|X = x)]>
(which can be learned using noisy data) and the transition matrix T (X = x) where Tij(X = x) =
P ( ¯Y = j|Y = i  X = x)  the clean class posterior probability P (Y|X = x) can be inferred 
i.e.  P (Y|X = x) = (T (X = x)>)1P ( ¯Y|X = x). For example  loss functions are modiﬁed to
ensure risk consistency  e.g.  [49  17  22  29  35  26]; a noise adaptation layer is added to deep neural
networks to design classiﬁer-consistent deep learning algorithms [9  30  38  47]. Those algorithms
are strongly theoretically grounded but heavily rely on the success of learning transition matrices.
Given risk-consistent estimators  one stream to learn the transition matrix is the cross-validation
method (using only noisy data) for binary classiﬁcation [26]. However  it is prohibited for multi-class
problems as its computational complexity grows exponentially to the number of classes. Besides 
the current risk-consistent estimators involve the inverse of the transition matrix  making tuning the
transition matrix inefﬁcient and also leading to performance degeneration [30]  especially when the
transition matrix is non-invertible. Independent of risk-consistent estimators  another stream to learn
the transition matrix is closely related to mixture proportion estimation [40]. A series of assumptions
[36  22  35  31] were proposed to efﬁciently learn transition matrices (or mixture parameters) by only
exploiting the noisy data. All those assumptions require anchor points  i.e.  instances belonging to a
speciﬁc class with probability exactly one or close to one. Nonetheless  without anchor points  the
transition matrix could be poorly learned  which will degenerate the accuracies of existing consistent
algorithms.
Therefore  in this paper  to handle the applications where the anchor-point assumptions are violated
[46  41]  we propose a transition-revision (T -Revision) method to effectively learn transition matrices 
leading to better classiﬁers. In a high level  we design a deep-learning-based risk-consistent estimator
to tune the transition matrix accurately. Speciﬁcally  we ﬁrst initialize the transition matrix by
exploiting examples that are similar to anchor points  namely  those having high estimated noisy class
posterior probabilities. Then  we modify the initial matrix by adding a slack variable  which will
be learned and validated together with the classiﬁer by using noisy data only. Note that given true
transition matrix  the proposed estimator will converge to the classiﬁcation risk w.r.t. clean data by
increasing the size of noisy training examples. Our heuristic for tuning the transition matrix is that a
favorable transition matrix would make the classiﬁcation risk w.r.t. clean data small. We empirically
show that the proposed T -Revision method will enable tuned transition matrices to be closer to the
ground truths  which explains why T -Revision is much superior to state-of-the-art algorithms in
classiﬁcation.
The rest of the paper is organized as follows. In Section 2 we review label-noise learning with anchor
points. In Section 3  we discuss how to learn the transition matrix and classiﬁer without anchor points.
Experimental results are provided in Section 4. Finally  we conclude the paper in Section 5.

2 Label-Noise Learning with Anchor Points

In this section  we brieﬂy review label-noise learning when there are anchor points.
Preliminaries Let D be the distribution of a pair of random variables (X  Y ) 2X⇥{ 1  2  . . .   C} 
where the feature space X✓ Rd and C is the size of label classes. Our goal is to predict a label
y for any given instance x 2X . However  in many real-world classiﬁcation problems  training
examples drawn independently from distribution D are unavailable. Before being observed  their true
labels are independently ﬂipped and what we can obtain is a noisy training sample {(Xi  ¯Yi)}n
i=1 
where ¯Y denotes the noisy label. Let ¯D be the distribution of the noisy random variables (X  ¯Y ) 2
X⇥{ 1  2  . . .   C}.
Transition matrix The random variables ¯Y and Y are related through a noise transition matrix
T 2 [0  1]C⇥C [8]. Generally  the transition matrix depends on instances  i.e.  Tij(X = x) = P ( ¯Y =
j|Y = i  X = x). Given only noisy examples  the instance-dependent transition matrix is non-
identiﬁable without any additional assumption. For example  P ( ¯Y = j|X = x) =PC
i=1 Tij(X =
x)P (Y = i|X = x) =PC
i=1 T 0ij(X = x)P 0(Y = i|X = x) are both valid  when T 0ij(X = x) =
Tij(X = x)P (Y = i|X = x)/P 0( ¯Y = i|X = x). In this paper  we study the class-dependent
and instance-independent transition matrix  i.e.  P ( ¯Y = j|Y = i  X = x) = P ( ¯Y = j|Y = i) 
which is identiﬁable under mild conditions and on which the vast majority of current methods focus
[14  13  30  29  26].

2

clean data  i.e.  P ( ¯Y = j|X = x) =PC

Consistent algorithms The transition matrix bridges the class posterior probabilities for noisy and
i=1 TijP (Y = i|X = x). Thus  it has been exploited to build
consistent algorithms. Speciﬁcally  it has been used to modify loss functions to build risk-consistent
estimators  e.g.  [26  35  30]  and has been used to correct hypotheses to build classiﬁer-consistent
algorithms  e.g.  [9  30  47]. Note that an estimator is risk-consistent if  by increasing the size of
noisy examples  the empirical risk calculated by noisy examples and the modiﬁed loss function will
converge to the expected risk calculated by clean examples and the original loss function. Similarly 
an algorithm is classiﬁer-consistent if  by increasing the size of noisy examples  the learned classiﬁer
will converge to the optimal classiﬁer learned by clean examples. Deﬁnitions of the expected and
empirical risks can be found in Appendix B  where we further discuss how consistent algorithms
work.
Anchor points The successes of consistent algorithms rely on ﬁrm bridges  i.e.  accurately learned
transition matrices. To learn transition matrices  the concept of anchor point was proposed [22  35].
Anchor points are deﬁned in the clean data domain  i.e.  an instance x is an anchor point for the class
i if P (Y = i|X = x) is equal to one or close to one1. Given an x  if P (Y = i|X = x) = 1  we have
that for k 6= i  P (Y = k|X = x) = 0. Then  we have

P ( ¯Y = j|X = x) =

CXk=1

TkjP (Y = k|X = x) = Tij.

(1)

0.5 0.3 0.2

0.5 .25 .25

Namely  T can be obtained via estimating the noisy class posterior probabilities for anchor points [47].
However  the requirement of given anchor points is a bit strong. Thus  anchor points are assumed to
exist but unknown in datasets  which can be identiﬁed either theoretically [22] or heuristically [30].
Transition matrix learning is also closely related
to mixture proportion estimation [40]  which is in-
dependent of classiﬁcation. By giving only noisy
data  to ensure the learnability and efﬁciency of
learning transition matrices (or mixture parame-
ters)  a series of assumptions were proposed  e.g. 
irreducibility [36]  anchor point [22  35]  and sepa-
rability [31]. All those assumptions require anchor
points or instances belonging to a speciﬁc class
with probability one or approaching one.
When there are no anchor points in datasets/data
distributions  all the above mentioned methods
will lead to inaccurate transition matrices  which
will degenerate the performances of current con-
sistent algorithms. This motivates us to investigate
how to maintain the efﬁcacy of those consistent
algorithms without using exact anchor points.

0.5 0.3 0.2
0.5 0.3
0.5

0.5 0.3 0.2
0.5 0.3
0.5

0.5 0.3 0.2

0.5 0.3 0.2

!

0.2
0.3 0.2

0.2
0.3 0.2

!"

Figure 1: Illustrative experimental results (us-
ing a 5-class classiﬁcation problem as an ex-
ample). The noisy class posterior probability
P ( ¯Y|X = x) can be estimated by exploiting
noisy data. Let an example have P ( ¯Y|X =
x) = [0.141; 0.189; 0.239; 0.281; 0.15].
If
the true transition matrix T is given  we
can infer the clean class posterior probabil-
ity as P (Y|X = x) = (T >)1P ( ¯Y|X =
x) = [0.15; 0.28; 0.25; 0.3; 0.02] and that the
instance belongs to the fourth class. How-
ever  if the transition matrix is not accurately
learned as ˜T (only slightly differing from
T with two entries in the second row)  the
clean class posterior probability can be in-
ferred as P (Y|X = x) = ( ˜T >)1P ( ¯Y|X =
x) = [0.1587; 0.2697; 0.2796; 0.2593; 0.0325]
and the instance could be mistakenly classiﬁed
into the third class.

3 Label-Noise
Learning without Anchor Points

This section presents a deep-learning-based risk-
consistent estimator for the classiﬁcation risk w.r.t.
clean data. We employ this estimator to tune the
transition matrix effectively without using anchor
points  which ﬁnally leads to better classiﬁers.

1In the literature  the assumption inf x P (Y = i|X = x) ! 1 was introduced as irreducibility [5] to ensure
the transition matrix is identiﬁable; an anchor point x for class i is deﬁned by P (Y = i|X = x) = 1 [35  22] to
ensure a fast convergence rate. In this paper  we generalize the deﬁnition for the anchor point family  including
instances whose class posterior probability P (Y = i|X = x) is equal to or close to one.

3

3.1 Motivation
According to Eq. (1)  to learn the transition matrix  P ( ¯Y|X = x) needs to be estimated and anchor
points need to be given. Note that learning P ( ¯Y|X = x) may introduce error. Even worse  when
there are no anchor points  it will be problematic if we use existing methods [36  22  35  31] to learn
transition matrices. For example  let P (Y|X = xi) be the i-th column of a matrix L  i = 1  . . .   C.
If xi is an anchor point for the i-th class  then L is an identity matrix. According to Eq. (1)  if we use
xi as an anchor point for the i-th class while P (Y = i|X = xi) 6= 1 (e.g.  the identiﬁed instances in
[30] are not guaranteed to be anchor points)  the learned transition matrix would be T L  where L is a
non-identity matrix. This means that transition matrices will be inaccurately estimated.
Based on inaccurate transition matrices  the accuracy of current consistent algorithms will signiﬁcantly
degenerate. To demonstrate this  Figure 1 shows that given a noisy class posterior probability
P ( ¯Y|X = x)  even if the transition matrix changes slightly by two entries  e.g.  kT  ˜Tk1/kTk1 =
0.02 where T and ˜T are deﬁned in Figure 1 and kTk1 = Pij |Tij|  the inferred class posterior
probability for the clean data may lead to an incorrect classiﬁcation. Since anchor points require
clean class posterior probabilities to be or approach one  which is quite strong to some real-world
applications [46  41]  we would like to study how to maintain the performances of current consistent
algorithms when there are no anchor points and then transition matrices are inaccurately learned.

3.2 Risk-consistent estimator
Intuitively  the entries of transition matrix can be tuned by minimizing the risk-consistent estimator 
since the estimator is asymptotically identical to the expected risk for the clean data and that a
favorable transition matrix should make the clean expected risk small. However  existing risk-
consistent estimators involve the inverse of transition matrix (more details are provided in Appendix
B)  which degenerates classiﬁcation performances [30] and makes tuning the transition matrix
ineffectively. To address this  we propose a risk-consistent estimator that does not involve the inverse
of the transition matrix.
The inverse of transition matrix is involved in risk-consistent estimators  since the noisy class posterior
probability P ( ¯Y|X = x) and the transition matrix are explicitly or implicitly used to infer the clean
class posterior probability P (Y|X = x)  i.e.  P (Y|X = x) = (T >)1P ( ¯Y|X = x). To avoid
the inverse in building risk-consistent estimators  we directly estimate P (Y|X = x) instead of
inferring it through P ( ¯Y|X = x). Thanks to the equation T >P (Y|X = x) = P ( ¯Y|X = x) 
P (Y|X = x) and P ( ¯Y|X = x) could be estimated at the same time by adding the true transition
matrix to modify the output of the softmax function  e.g.  [47  30]. Speciﬁcally  P ( ¯Y|X = x) can
be learned by exploiting the noisy data  as shown in Figure 2 by minimizing the unweighted loss
¯Rn(f ) = 1/nPn
i=1 `(f (Xi)  ¯Yi)  where `(f (X)  ¯Y ) is a loss function [25]. Let ˆT + T be the
true transition matrix  i.e.  ˆT + T = T . Due to P ( ¯Y|X = x) = T >P (Y|X = x)  the output
of the softmax function g(x) = ˆP (Y|X = x) before the transition matrix is an approximation for
P (Y|X = x). However  the learned g(x) = ˆP (Y|X = x) by minimizing the unweighted loss may
perform poorly if the true transition matrix is inaccurately learned as explained in the motivation.
If having P (Y|X = x) and P ( ¯Y|X = x)  we could employ the importance reweighting technique
[11  22] to rewrite the expected risk w.r.t. clean data without involving the inverse of transition matrix.
Speciﬁcally 

¯`(f (x)  i) =
where D denotes
PD( ¯Y =i|X=x)
P ¯D( ¯Y =i|X=x) `(f (x)  i)  and the second last equation holds because label noise is assumed to be

the distribution for clean data 

¯D for noisy data 

4

R(f ) = E(X Y )⇠D[`(f (X)  Y )] =ZxXi
=ZxXi
=ZxXi

PD(X = x  ¯Y = i)
P ¯D(X = x  ¯Y = i)
PD( ¯Y = i|X = x)
P ¯D( ¯Y = i|X = x)

P ¯D(X = x  ¯Y = i)

P ¯D(X = x  ¯Y = i)

= E(X Y )⇠ ¯D[¯`(f (X)  Y )] 

PD(X = x  Y = i)`(f (x)  i)dx

`(f (x)  i)dx

`(f (x)  i)dx

(2)

Neural Network

Noisy 

Training Sample

𝑔𝑋 =෠𝑃𝒀|𝑋

S
o
f
t

m
a
x

𝑔𝑋 =෠𝑃𝒀|𝑋
෠𝑇+∆𝑇 ⊤

෠𝑇+∆𝑇 ⊤𝑔𝑋 =෠𝑃(ഥ𝒀|𝑋)
Unweighted Loss ത𝑅𝑛𝑓

ത𝑅𝑛 𝑤 ෠𝑇+Δ𝑇 𝑓

Weighted Loss

W
e
i
g
h
t
s

Figure 2: An overview of the proposed method. The proposed method will learn a more accurate
classiﬁer because the transition matrix is renovated.

Algorithm 1 Reweight T -Revision (Reweight-R) Algorithm.
Input: Noisy training sample Dt; Noisy validation set Dv.
Stage 1: Learn ˆT
1: Minimize the unweighted loss to learn ˆP ( ¯Y|X = x) without a noise adaption layer;
2: Initialize ˆT according to Eq. (1) by using instances with the highest ˆP ( ¯Y = i|X = x) as anchor
points for the i-th class;
Stage 2: Learn the classiﬁer f and T
3: Initialize the neural network by minimizing the weighted loss with a noisy adaption layer ˆT >;
4: Minimize the weighted loss to learn f and T with a noisy adaption layer ( ˆT + T )>;
//Stopping criterion for learning ˆP ( ¯Y|X = x)  f and T : when ˆP ( ¯Y|X = x) yields the minimum
classiﬁcation error on the noisy validation set Dv
Output: ˆT   T   and f.

independent of instances. In the rest of the paper  we have omitted the subscript for P when no con-
fusion is caused. Since P ( ¯Y|X = x) = T >P (Y|X = x) and that the diagonal entries of (learned)
transition matrices for label-noise learning are all much larger than zero  PD( ¯Y = i|X = x) 6= 0
implies P ¯D( ¯Y = i|X = x) 6= 0  which also makes the proposed importance reweighting method
stable without truncating the importance ratios.
Eq. (2) shows that the expected risk w.r.t. clean data and the loss `(f (x)  i) is equivalent to an
expected risk w.r.t. noisy data and a reweighted loss  i.e.  PD( ¯Y =i|X=x)
P ¯D( ¯Y =i|X=x) `(f (x)  i). The empirical
counterpart of the risk in the rightmost-hand side of Eq. (2) is therefore a risk-consistent estimator
for label-noise learning. We exploit a deep neural network to build this counterpart. As shown
in Figure 2  we use the output of the softmax function g(x) to approximate P (Y|X = x)  i.e. 
g(x) = ˆP (Y|X = x) ⇡ P (Y|X = x). Then  T >g(x) (or ( ˆT + T )>g(x) in the ﬁgure) is an
approximation for P ( ¯Y|X = x)  i.e.  T >g(x) = ˆP ( ¯Y|X = x) ⇡ P ( ¯Y|X = x). By employing
ˆP (Y = y|X = x)/ ˆP ( ¯Y = y|X = x) as weight  we build the risk-consistent estimator as

¯Rn w(T  f ) =

`(f (Xi)  ¯Yi) 

(3)

1
n

nXi=1

g ¯Yi(Xi)

(T >g) ¯Yi(Xi)

where f (X) = arg maxj2{1 ... C} gj(X)  gj(X) is an estimate for P (Y = j|X)  and the subscript
w denotes that the loss function is weighted. Note that if the true transition matrix T is given 
¯Rn w(T  f ) only has one argument g to learn.

3.3

Implementation and the T -revision method

When the true transition matrix T is unavailable  we propose to use ¯Rn w( ˆT + T  f ) to approximate
R(f )  as shown in Figure 2. To minimize ¯Rn w( ˆT + T  f )  a two-stage training procedure is
proposed. Stage 1: ﬁrst learn P ( ¯Y|X = x) by minimizing the unweighted loss without a noise
adaption layer and initialize ˆT by exploiting examples that have the highest learned ˆP ( ¯Y|X = x);
Stage 2: modify the initialization ˆT by adding a slack variable T and learn the classiﬁer and T
by minimizing the weighted loss. The procedure is called the Weighted T -Revision method and
is summarized in Algorithm 1. It is worthwhile to mention that all anchor points based consistent
estimators for label-noise learning have a similar two-stage training procedure. Speciﬁcally  with one
stage to learn P ( ¯Y|X = x) and the transition matrix and a second stage to learn the classiﬁer for the
clean data.

5

The proposed T -revision method works because we learn T by minimizing the risk-consistent
estimator  which is asymptotically equal to the expected risk w.r.t. clean data. The learned slack
variable can also be validated on the noisy validation set  i.e.  to check if ˆP ( ¯Y|X = x) ﬁts the
validation set. The philosophy of our approach is similar to that of the cross-validation method.
However  the proposed method does not need to try different combinations of parameters (T is
learned) and thus is much more computationally efﬁcient. Note that the proposed method will also
boost the performances of consistent algorithms even there are anchor points as the transition matrices
and classiﬁers are jointly learned. Note also that if a clean validation set is available  it can be used to
better initialize the transition matrix  to better validate the slack variable T   and to ﬁne-tune the
deep network.

3.4 Generalization error
While we have discussed the use of the proposed estimator for evaluating the risk w.r.t clean data 
we theoretically justify how it generalizes for learning classiﬁers. Assume the neural network has
d layers  parameter matrices W1  . . .   Wd  and activation functions 1  . . .   d1for each layer. Let
denote the mapping of the neural network by h : x 7! Wdd1(Wd1d2(. . . 1(W1x))) 2 RC.
Then  the output of the softmax is deﬁned by gi(x) = exp (hi(x))/PC
k=1 exp (hk(x))  i = 1  . . .   C.
Let ˆf = arg maxi2{1 ... C} ˆgi be the classiﬁer learned from the hypothesis space F determined by
the real-valued parameters of the neural network  i.e.  ˆf = arg minf2F ¯Rn w(f ).
To derive a generalization bound  as the common practice [6  25]  we assume that instances are upper
bounded by B  i.e.  kxk  B for all x 2X   and that the loss function is L-Lipschitz continuous w.r.t.
f (x) and upper bounded by M  i.e.  for any f1  f2 2 F and any (x  ¯y)  |`(f1(x)  ¯y)  `(f2(x)  ¯y)|
L|f1(x)  f2(x)|  and for any (x  ¯y)  `(f (x)  ¯y)  M.
Theorem 1 Assume the Frobenius norm of
the weight matrices W1  . . .   Wd are at most
M1  . . .   Md. Let the activation functions be 1-Lipschitz  positive-homogeneous  and applied
element-wise (such as the ReLU). Let the loss function be the cross-entropy loss  i.e.  `(f (x)  ¯y) =
PC
i=1 1{¯y=i} log(gi(x)). Let ˆf and  ˆT be the learned classiﬁer and slack variable. Assume
 ˆT is searched from a space of T constituting valid transition matrices2  i.e.  8T and 8i 6= j 
ˆTij + Tij  0 and ˆTii + Tii > ˆTij + Tij. Then  for any > 0  with probability at least 1   
+ CMr log 1/
E[ ¯Rn w( ˆT + ˆT   ˆf )]  ¯Rn w( ˆT + ˆT   ˆf ) 
.
A detailed proof is provided in Appendix C. The factor (p2d log 2 + 1)⇧d
i=1Mi is induced by the
hypothesis complexity of the deep neural network [10] (see Theorem 1 therein)  which could be
improved [27  48  16]. Although the proposed reweighted loss is more complex than the traditional
unweighted loss function  we have derived a generalization error bound not larger than those derived
for the algorithms employing the traditional loss [25] (can be seen by Lemma 2 in the proof of the
theorem). This shows that the proposed Algorithm 1 does not need a larger training sample to achieve
a small difference between training error ( ¯Rn w( ˆT + ˆT   ˆf )) and test error (E[ ¯Rn w( ˆT + ˆT   ˆf )]).
Also note that deep learning is powerful in yielding a small training error. If the training sample size n
is large  then the upper bound in Theorem 1 is small  which implies a small E[ ¯Rn w( ˆT + ˆT   ˆf )] and
justiﬁes why the proposed method will have small test errors in the experiment section. Meanwhile 
in the experiment section  we show that the proposed method is much superior to the state-of-the-art
methods in classiﬁcation accuracy  implying that the small generalization error is not obtained at the
cost of enlarging the approximation error.

2BCL(p2d log 2 + 1)⇧d

2n

i=1Mi

pn

4 Experiments

Datasets We verify the effectiveness of the proposed method on three synthetic noisy datasets  i.e. 
MNIST [19]  CIFAR-10 [18]  and CIFAR-100 [18]  and one real-world noisy dataset  i.e.  clothing1M
2During the training  T + T can be ensured to be a valid transition matrix by ﬁrst projecting their negative
entries to be zero and then performing row normalization. In the experiments  T is initialized to be a zero
matrix and we haven’t pushed T + T to be a valid matrix when tuning T .

6

Table 1: Means and standard deviations (percentage) of classiﬁcation accuracy. Methods with “-A”
means that they run on the intact datasets without removing possible anchor points; Methods with
“-R” means that the transition matrix used is revised by a revision  ˆT .

MNIST

CIFAR-10

CIFAR-100

Sym-20%
Decoupling-A 95.39±0.29
96.57±0.18
MentorNet-A
Co-teaching-A 97.22±0.18
Forward-A
98.75±0.08
Reweight-A
98.71±0.11
Forward-A-R
98.84±0.09
Reweight-A-R 98.91±0.04

Sym-50%
81.52±0.29
90.13±0.09
91.68±0.21
97.86±0.22
98.13±0.19
98.12±0.22
98.38±0.21

Sym-20%
79.85±0.30
80.49±0.52
82.38±0.11
85.63±0.52
86.77±0.40
88.10±0.21
89.63±0.13

Sym-50%
52.22±0.45
70.71±0.24
72.80±0.45
77.92±0.66
80.16±0.46
81.11±0.74
83.40±0.65

Sym-20%
42.75±0.49
52.11±0.10
54.23±0.08
57.75±0.37
58.35±0.64
62.13±2.09
65.40±1.07

Sym-50%
29.24±0.54
38.45±0.25
41.37±0.08
44.66±1.01
43.97±0.67
50.46±0.52
50.24±1.45

Table 2: Means and standard deviations (percentage) of classiﬁcation accuracy. Methods with “-N/A”
means instances with high estimated P (Y |X) are removed from the dataset; Methods with “-R”
means that the transition matrix used is revised by a revision  ˆT .

MNIST

CIFAR-10

CIFAR-100

Sym-20%
Decoupling-N/A 95.93±0.21
97.11±0.09
MentorNet-N/A
Co-teaching-N/A 97.69±0.23
Forward-N/A
98.64±0.12
Reweight-N/A
98.69±0.08
Forward-N/A-R
98.80±0.06
Reweight-N/A-R 98.85±0.02

Sym-50%
82.55±0.39
91.44±0.25
93.58±0.49
97.74±0.13
98.05±0.22
97.96±0.13
98.37±0.17

Sym-20%
75.37±1.24
78.51±0.31
81.72±0.14
84.75±0.81
85.53±0.26
86.93±0.39
88.90±0.22

Sym-50%
47.19±0.19
67.37±0.30
70.44±1.01
74.32±0.69
77.70±1.00
77.14±0.65
81.55±0.94

Sym-20%
39.59±0.42
48.62±0.43
53.21±0.54
56.23±0.34
56.60±0.71
58.72±0.45
62.00±1.78

Sym-50%
24.04±1.19
33.53±0.31
40.06±0.83
39.28±0.59
39.28±0.71
44.60±0.79
44.75±2.10

[44]. MNIST has 10 classes of images including 60 000 training images and 10 000 test images.
CIFAR-10 has 10 classes of images including 50 000 training images and 10 000 test images. CIFAR-
100 also has 50 000 training images and 10 000 test images  but 100 classes. For all the datasets 
we leave out 10% of the training examples as a validation set. The three datasets contain clean
data. We corrupted the training and validation sets manually according to true transition matrices
T . Speciﬁcally  we employ the symmetry ﬂipping setting deﬁned in Appendix D. Sym-50 generates
heavy label noise and leads almost half of the instances to have noisy labels  while Sym-20 generates
light label noise and leads around 20% of instances to have label noise. Note that the pair ﬂipping
setting [14]  where each row of the transition matrix only has two non-zero entries  has also been
widely studied. However  for simplicity  we do not pose any constraint on the slack variable T to
achieve speciﬁc speculation of the transition matrix  e.g.  sparsity [13]. We leave this for future work.
Besides reporting the classiﬁcation accuracy on test set  we also report the discrepancy between the
learned transition matrix ˆT + ˆT and the true one T . All experiments are repeated ﬁve times on
those three datasets. Clothing1M consists of 1M images with real-world noisy labels  and additional
50k  14k  10k images with clean labels for training  validation  and testing. We use the 50k clean data
to help initialize the transition matrix as did in the baseline [30].
Network structure and optimization For fair comparison  we implement all methods with default
parameters by PyTorch on NVIDIA Tesla V100. We use a LeNet-5 network for MNIST  a ResNet-18
network for CIFAR-10  a ResNet-34 network for CIFAR-100. For learning the transition matrix
ˆT in the ﬁrst stage  we follow the optimization method in [30]. During the second stage  we ﬁrst
use SGD with momentum 0.9  weight decay 104  batch size 128  and an initial learning rate of
102 to initialize the network. The learning rate is divided by 10 after the 40th epoch and 80th
epoch. 200 epochs are set in total. Then  the optimizer and learning rate are changed to Adam and
5 ⇥ 107 to learn the classiﬁer and slack variable. For CIFAR-10 and CIFAR-100  we perform data
augmentation by horizontal random ﬂips and 32⇥32 random crops after padding 4 pixels on each
side. For clothing1M  we use a ResNet-50 pre-trained on ImageNet. Follow [30]  we also exploit
the 1M noisy data and 50k clean data to initialize the transition matrix. In the second stage  for
initialization  we use SGD with momentum 0.9  weight decay 103  batch size 32  and run with
learning rates 103 and 104 for 5 epochs each. For learning the classiﬁer and slack variable  Adam
is used and the learning rate is changed to 5 ⇥ 107.

7

Table 3: Means and standard deviations (percentage) of classiﬁcation accuracy on MNIST with
different label noise levels. Methods with “-A” means that they run on the intact datasets without
removing possible anchor points; Methods with “-R” means that the transition matrix used is revised
by a revision  ˆT ; Methods with “-N/A” means instances with high estimated P (Y |X) are removed
from the dataset.

Sym-60%
Forward-A
97.10±0.08
Forward-A-R
97.65±0.11
Reweight-A
97.39±0.27
97.83±0.18
Reweight-A-R
Forward-N/A
96.82±0.14
Forward-N/A-R
96.99±0.16
Reweight-N/A
97.01±0.20
Reweight-N/A-R 97.81±0.12

Sym-70%
96.06±0.41
96.42±0.35
96.25±0.26
97.13±0.08
94.61±0.28
95.02±0.17
95.94±0.14
96.59±0.15

Sym-80%
91.46±1.03
91.77±0.22
93.79±0.52
94.19±0.45
85.95±1.01
86.04±1.03
91.59±0.70
91.91±0.65

Table 4: Classiﬁcation accuracy (percentage) on Clothing1M.

Decoupling MentorNet Co-teaching

53.98

56.77

58.68

Forward Reweight
71.79

70.95

Forward-R Reweight-R

72.25

74.18

Baselines We compare the proposed method with state-of-the-art approaches. Speciﬁcally  we
compare with the following three inconsistent but well-designed algorithms: Decoupling [24] 
MentorNet [15]  and Co-teaching [14]  which free the learning of transition matrices. To compare
with consistent estimators  we set Forward [30]  a classiﬁer-consistent algorithm  and the importance
reweighting method (Reweight)  a risk-consistent algorithm  as baselines. The risk-consistent
estimator involving the inverse of transition matrix  e.g.  Backward in [30]  has not been included in
the comparison  because it has been reported to perform worse than the Forward method [30].

4.1 Comparison for classiﬁcation accuracy
The importance of anchor points To show the importance of anchor points  we modify the datasets
by moving possible anchor points  i.e.  instances with large estimated class posterior probability
P (Y |X)  before corrupting the training and validation sets. As the MNIST dataset is simple  we
removed 40% of the instances with the largest estimated class posterior probabilities in each class.
For CIFAR-10 and CIFAR-100  we removed 20% of the instances with the largest estimated class
posterior probabilities in each class. To make it easy for distinguishing  we mark a “-A” in the
algorithm’s name if it runs on the original intact datasets  and mark a “-N/A” in the algorithm’s name
if it runs on those modiﬁed datasets.
Comparing Decoupling-A  MentorNet-A  and Co-teaching-A in Table 1 with Decoupling-N/A 
MentorNet-N/A  and Co-teaching-N/A in Table 2  we can ﬁnd that on MNIST  the methods with
“-N/A” work better; while on CIFAR-10 and CIFAR-100  the methods with “-A” work better. This is
because those methods are independent of transition matrices but dependent of dataset properties.
Removing possible anchors points may not always lead to performance degeneration.
Comparing Forward-A and Reweight-A with Forward-N/A and Reweight-N/A  we can ﬁnd that the
methods without anchor points  i.e.  with “-N/A”  degenerate clearly. The degeneration on MNIST
is slight because the dataset can be well separated and many instances have high class posterior
probability even in the modify dataset. Those results show that  without anchor points  the consistent
algorithms will have performance degeneration. Speciﬁcally  on CIFAR-100  the methods with “-N/A”
have much worse performance than the ones with “-A”  with accuracy dropping at least 4%.
To discuss the model performances on MNIST with more label noise  we raise the noise rates to 60% 
70%  80%. Other experiment settings are unchanged. The results are presented in Table 3. We can
see that the proposed model outperforms the baselines more signiﬁcantly as the noise rate grows.
Risk-consistent estimator vs. classiﬁer-consistent estimator Comparing Forward-A with
Reweight-A in Table 1 and comparing Forward-N/A with Reweight-N/A in Table 2  it can be
seen that the proposed Reweight method  a risk-consistent estimator not involving the inverse of
transition matrix  works slightly better than or is comparable to Forward  a classiﬁer-consistent

8

(a) MNIST

(b) CIFAR-10

(c) CIFAR-100

Figure 3: The estimation error of the transition matrix by employing classiﬁer-consistent and risk-
consistent estimators. The ﬁrst row is about sym-20 label noise while the second row is about sym-50
label noise. The error bar for standard deviation in each ﬁgure has been shaded.

algorithm. Note that in [30]  it is reported that Backward  a risk-consistent estimator which involves
the inverse of the transition matrix  works worse than Forward  the classiﬁer-consistent algorithm.
The importance of T -revision Note that for fair comparison  we also set it as a baseline to modify
the transition matrix in Forward. As shown in Tables 1 and 2  methods with “-R” means that they use
the proposed T -revision method  i.e.  modify the learned ˆT by adding  ˆT . Comparing the results in
Tables 1 and 2  we can ﬁnd that the T -revision method signiﬁcantly outperforms the others. Among
them  the proposed Reweight-R works signiﬁcantly better than the baseline Forward-R. We can ﬁnd
that the T -Revision method boosts the classiﬁcation performance even without removing possible
anchor points. The rationale behind this may be that the network  transition matrix  and classiﬁer are
jointly learned and validated and that the identiﬁed anchor points are not reliable.
Comparison on real-world dataset The proposed T -revision method signiﬁcantly outperforms the
baselines as shown in Table 4  where the highest accuracy is bold faced.

4.2 Comparison for estimating transition matrices

To show that the proposed risk-consistent estimator is more effective in modifying the transition
matrix  we plot the estimation error for the transition matrix  i.e.  kT  ˆT   ˆTk1/kTk1. In Figure
4  we can see that for all cases  the proposed risk-consistent-estimator-based revision leads to smaller
estimator errors than the classiﬁer-consistent algorithm based method (Forward-R)  showing that the
risk-consistent estimator is more powerful in modifying the transition matrix. This also explains why
the proposed method works better. We provide more discussions about Figure 4 in Appendix E.

5 Conclusion

This paper presents a risk-consistent estimator for label-noise learning without involving the inverse
of transition matrix and a simple but effective learning paradigm called T -revision  which trains deep
neural networks robustly under noisy supervision. The aim is to maintain effectiveness and efﬁciency
of current consistent algorithms when there are no anchor points and then the transition matrices are
poorly learned. The key idea is to revise the learned transition matrix and validate the revision by
exploiting a noisy validation set. We conduct experiments on both synthetic and real-world label
noise data to demonstrate that the proposed T -revision can signiﬁcantly help boost the performance
of label-noise learning. In the future  we will extend the work in the following aspects. First  how to
incorporate some prior knowledge of the transition matrix  e.g.  sparsity  into the end-to-end learning
system. Second  how to recursively learn the transition matrix and classiﬁer as our experiments show
that transition matrices can be reﬁned.

9

Acknowledgments

TLL was supported by Australian Research Council Project DP180103424 and DE190101473. NNW
was supported by National Natural Science Foundation of China under Grants 61922066  61876142 
and the CCF-Tencent Open Fund. CG was supported by NSF of China under Grants 61602246 
61973162  NSF of Jiangsu Province under Grants BK20171430  the Fundamental Research Funds
for the Central Universities under Grants 30918011319  and the “Young Elite Scientists Sponsorship
Program” by CAST under Grants 2018QNRC001. MS was supported by the International Research
Center for Neurointelligence (WPI-IRCN) at The University of Tokyo Institutes for Advanced Study.
XBX and TLL would give special thanks to Haifeng Liu and Brain-Inspired Technology Co.  Ltd. for
their support of GPUs used for this research.

References
[1] Dana Angluin and Philip Laird. Learning from noisy examples. Machine Learning  2(4):343–

370  1988.

[2] Peter L Bartlett  Dylan J Foster  and Matus J Telgarsky. Spectrally-normalized margin bounds

for neural networks. In NeurIPS  pages 6240–6249  2017.

[3] Peter L Bartlett  Michael I Jordan  and Jon D McAuliffe. Convexity  classiﬁcation  and risk

bounds. Journal of the American Statistical Association  101(473):138–156  2006.

[4] Peter L Bartlett and Shahar Mendelson. Rademacher and gaussian complexities: Risk bounds

and structural results. Journal of Machine Learning Research  3(Nov):463–482  2002.

[5] Gilles Blanchard  Gyemin Lee  and Clayton Scott. Semi-supervised novelty detection. Journal

of Machine Learning Research  11(Nov):2973–3009  2010.

[6] Stéphane Boucheron  Olivier Bousquet  and Gábor Lugosi. Theory of classiﬁcation: A survey

of some recent advances. ESAIM: probability and statistics  9:323–375  2005.

[7] Stéphane Boucheron  Gábor Lugosi  and Pascal Massart. Concentration inequalities: A

nonasymptotic theory of independence. Oxford university press  2013.

[8] Jiacheng Cheng  Tongliang Liu  Kotagiri Ramamohanarao  and Dacheng Tao. Learning with

bounded instance-and label-dependent label noise. arXiv preprint arXiv:1709.03768  2017.

[9] Jacob Goldberger and Ehud Ben-Reuven. Training deep neural-networks using a noise adapta-

tion layer. In ICLR  2017.

[10] Noah Golowich  Alexander Rakhlin  and Ohad Shamir. Size-independent sample complexity of

neural networks. In COLT  pages 297–299  2018.

[11] Arthur Gretton  Alex Smola  Jiayuan Huang  Marcel Schmittfull  Karsten Borgwardt  and
Bernhard Schölkopf. Covariate shift by kernel mean matching. Dataset shift in machine
learning  pages 131–160  2009.

[12] Sheng Guo  Weilin Huang  Haozhi Zhang  Chenfan Zhuang  Dengke Dong  Matthew R Scott 
and Dinglong Huang. Curriculumnet: Weakly supervised learning from large-scale web images.
In ECCV  pages 135–150  2018.

[13] Bo Han  Jiangchao Yao  Gang Niu  Mingyuan Zhou  Ivor Tsang  Ya Zhang  and Masashi
Sugiyama. Masking: A new perspective of noisy supervision. In NeurIPS  pages 5836–5846 
2018.

[14] Bo Han  Quanming Yao  Xingrui Yu  Gang Niu  Miao Xu  Weihua Hu  Ivor Tsang  and Masashi
Sugiyama. Co-teaching: Robust training of deep neural networks with extremely noisy labels.
In NeurIPS  pages 8527–8537  2018.

[15] Lu Jiang  Zhengyuan Zhou  Thomas Leung  Li-Jia Li  and Li Fei-Fei. MentorNet: Learning
data-driven curriculum for very deep neural networks on corrupted labels. In ICML  pages
2309–2318  2018.

10

[16] Kenji Kawaguchi  Leslie Pack Kaelbling  and Yoshua Bengio. Generalization in deep learning.

arXiv preprint arXiv:1710.05468  2017.

[17] Jan Kremer  Fei Sha  and Christian Igel. Robust active label correction. In AISTATS  pages

308–316  2018.

[18] Alex Krizhevsky. Learning multiple layers of features from tiny images. Technical report  2009.

[19] Yann LeCun  Corinna Cortes  and Christopher J.C. Burges. The MNIST database of handwritten

digits. http://yann.lecun.com/exdb/mnist/.

[20] Michel Ledoux and Michel Talagrand. Probability in Banach Spaces: isoperimetry and

processes. Springer Science & Business Media  2013.

[21] Yuncheng Li  Jianchao Yang  Yale Song  Liangliang Cao  Jiebo Luo  and Li-Jia Li. Learning

from noisy labels with distillation. In ICCV  pages 1910–1918  2017.

[22] Tongliang Liu and Dacheng Tao. Classiﬁcation with noisy labels by importance reweighting.

IEEE Transactions on pattern analysis and machine intelligence  38(3):447–461  2016.

[23] Xingjun Ma  Yisen Wang  Michael E Houle  Shuo Zhou  Sarah M Erfani  Shu-Tao Xia  Sudanthi
Wijewickrema  and James Bailey. Dimensionality-driven learning with noisy labels. In ICML 
pages 3361–3370  2018.

[24] Eran Malach and Shai Shalev-Shwartz. Decoupling" when to update" from" how to update". In

NeurIPS  pages 960–970  2017.

[25] Mehryar Mohri  Afshin Rostamizadeh  and Ameet Talwalkar. Foundations of Machine Learning.

MIT Press  2018.

[26] Nagarajan Natarajan  Inderjit S Dhillon  Pradeep K Ravikumar  and Ambuj Tewari. Learning

with noisy labels. In NeurIPS  pages 1196–1204  2013.

[27] Behnam Neyshabur  Srinadh Bhojanapalli  David McAllester  and Nati Srebro. Exploring

generalization in deep learning. In NeurIPS  pages 5947–5956  2017.

[28] Behnam Neyshabur  Srinadh Bhojanapalli  and Nathan Srebro. A PAC-Bayesian approach to

spectrally-normalized margin bounds for neural networks. In ICLR  2018.

[29] Curtis G Northcutt  Tailin Wu  and Isaac L Chuang. Learning with conﬁdent examples: Rank

pruning for robust classiﬁcation with noisy labels. In UAI  2017.

[30] Giorgio Patrini  Alessandro Rozza  Aditya Krishna Menon  Richard Nock  and Lizhen Qu.
Making deep neural networks robust to label noise: A loss correction approach. In CVPR  pages
1944–1952  2017.

[31] Harish Ramaswamy  Clayton Scott  and Ambuj Tewari. Mixture proportion estimation via

kernel embeddings of distributions. In ICML  pages 2052–2060  2016.

[32] Scott E Reed  Honglak Lee  Dragomir Anguelov  Christian Szegedy  Dumitru Erhan  and
Andrew Rabinovich. Training deep neural networks on noisy labels with bootstrapping. In
ICLR  2015.

[33] Mengye Ren  Wenyuan Zeng  Bin Yang  and Raquel Urtasun. Learning to reweight examples

for robust deep learning. In ICML  pages 4331–4340  2018.

[34] Clayton Scott. Calibrated asymmetric surrogate losses. Electronic Journal of Statistics  6:958–

992  2012.

[35] Clayton Scott. A rate of convergence for mixture proportion estimation  with application to

learning from noisy labels. In AISTATS  pages 838–846  2015.

[36] Clayton Scott  Gilles Blanchard  and Gregory Handy. Classiﬁcation with asymmetric label

noise: Consistency and maximal denoising. In COLT  pages 489–511  2013.

11

[37] Daiki Tanaka  Daiki Ikami  Toshihiko Yamasaki  and Kiyoharu Aizawa. Joint optimization

framework for learning with noisy labels. In CVPR  pages 5552–5560  2018.

[38] Kiran K Thekumparampil  Ashish Khetan  Zinan Lin  and Sewoong Oh. Robustness of

conditional gans to noisy labels. In NeurIPS  pages 10271–10282  2018.

[39] Arash Vahdat. Toward robustness against label noise in training deep discriminative neural

networks. In NeurIPS  pages 5596–5605  2017.

[40] Robert A Vandermeulen and Clayton D Scott. An operator theoretic approach to nonparametric

mixture models. arXiv preprint arXiv:1607.00071  2016.

[41] Robert A Vandermeulen and Clayton D Scott. An operator theoretic approach to nonparametric

mixture models. accepted to The Annals of Statistics  2019.

[42] Vladimir Vapnik. The nature of statistical learning theory. Springer science & business media 

2013.

[43] Andreas Veit  Neil Alldrin  Gal Chechik  Ivan Krasin  Abhinav Gupta  and Serge Belongie.
Learning from noisy large-scale datasets with minimal supervision. In CVPR  pages 839–847 
2017.

[44] Tong Xiao  Tian Xia  Yi Yang  Chang Huang  and Xiaogang Wang. Learning from massive

noisy labeled data for image classiﬁcation. In CVPR  pages 2691–2699  2015.

[45] Xingrui Yu  Bo Han  Jiangchao Yao  Gang Niu  Ivor W Tsang  and Masashi Sugiyama. How

does disagreement beneﬁt co-teaching? In ICML  2019.

[46] Xiyu Yu  Tongliang Liu  Mingming Gong  Kayhan Batmanghelich  and Dacheng Tao. An
efﬁcient and provable approach for mixture proportion estimation using linear independence
assumption. In CVPR  pages 4480–4489  2018.

[47] Xiyu Yu  Tongliang Liu  Mingming Gong  and Dacheng Tao. Learning with biased complemen-

tary labels. In ECCV  pages 68–83  2018.

[48] Chiyuan Zhang  Samy Bengio  Moritz Hardt  Benjamin Recht  and Oriol Vinyals. Understanding

deep learning requires rethinking generalization. In ICLR  2017.

[49] Zhilu Zhang and Mert Sabuncu. Generalized cross entropy loss for training deep neural networks

with noisy labels. In NeurIPS  pages 8778–8788  2018.

12

,Xiaobo Xia
Tongliang Liu
Nannan Wang
Bo Han
Chen Gong
Gang Niu
Masashi Sugiyama