2014,Encoding High Dimensional Local Features by Sparse Coding Based Fisher Vectors,Deriving from the gradient vector of a generative model of local features  Fisher vector coding (FVC) has been identified as an effective coding method for image classification. Most  if not all  FVC implementations employ the Gaussian mixture model (GMM) to characterize the generation process of local features. This choice has shown to be sufficient for traditional low dimensional local features  e.g.  SIFT; and typically  good performance can be achieved with only a few hundred Gaussian distributions. However  the same number of Gaussians is insufficient to model the feature space spanned by higher dimensional local features  which have become popular recently. In order to improve the modeling capacity for high dimensional features  it turns out to be inefficient and computationally impractical to simply increase the number of Gaussians. In this paper  we propose a model in which each local feature is drawn from a Gaussian distribution whose mean vector is sampled from a subspace. With certain approximation  this model can be converted to a sparse coding procedure and the learning/inference problems can be readily solved by standard sparse coding methods. By calculating the gradient vector of the proposed model  we derive a new fisher vector encoding strategy  termed Sparse Coding based Fisher Vector Coding (SCFVC). Moreover  we adopt the recently developed Deep Convolutional Neural Network (CNN) descriptor as a high dimensional local feature and implement image classification with the proposed SCFVC. Our experimental evaluations demonstrate that our method not only significantly outperforms the traditional GMM based Fisher vector encoding but also achieves the state-of-the-art performance in generic object recognition  indoor scene  and fine-grained image classification problems.,Encoding High Dimensional Local Features by Sparse

Coding Based Fisher Vectors

Lingqiao Liu1  Chunhua Shen1 2  Lei Wang3  Anton van den Hengel1 2  Chao Wang3

3 School of Computer Science and Software Engineering  University of Wollongong  Australia

1 School of Computer Science  University of Adelaide  Australia

2 ARC Centre of Excellence for Robotic Vision

Abstract

Deriving from the gradient vector of a generative model of local features  Fisher
vector coding (FVC) has been identiﬁed as an effective coding method for im-
age classiﬁcation. Most  if not all  FVC implementations employ the Gaussian
mixture model (GMM) to characterize the generation process of local features.
This choice has shown to be sufﬁcient for traditional low dimensional local fea-
tures  e.g.  SIFT; and typically  good performance can be achieved with only a few
hundred Gaussian distributions. However  the same number of Gaussians is insuf-
ﬁcient to model the feature space spanned by higher dimensional local features 
which have become popular recently. In order to improve the modeling capacity
for high dimensional features  it turns out to be inefﬁcient and computationally
impractical to simply increase the number of Gaussians.
In this paper  we propose a model in which each local feature is drawn from a
Gaussian distribution whose mean vector is sampled from a subspace. With cer-
tain approximation  this model can be converted to a sparse coding procedure and
the learning/inference problems can be readily solved by standard sparse coding
methods. By calculating the gradient vector of the proposed model  we derive
a new ﬁsher vector encoding strategy  termed Sparse Coding based Fisher Vec-
tor Coding (SCFVC). Moreover  we adopt the recently developed Deep Convo-
lutional Neural Network (CNN) descriptor as a high dimensional local feature
and implement image classiﬁcation with the proposed SCFVC. Our experimen-
tal evaluations demonstrate that our method not only signiﬁcantly outperforms
the traditional GMM based Fisher vector encoding but also achieves the state-of-
the-art performance in generic object recognition  indoor scene  and ﬁne-grained
image classiﬁcation problems.

1

Introduction

Fisher vector coding is a coding method derived from the Fisher kernel [1] which was originally pro-
posed to compare two samples induced by a generative model. Since its introduction to computer
vision [2]  many improvements and variants have been proposed. For example  in [3] the normaliza-
tion of Fisher vectors is identiﬁed as an essential step to achieve good performance; in [4] the spatial
information of local features is incorporated; in [5] the model parameters are learned through a end-
to-end supervised training algorithm and in [6] multiple layers of Fisher vector coding modules are
stacked into a deep architecture. With these extensions  Fisher vector coding has been established
as the state-of-the-art image classiﬁcation approach.
Almost all of these methods share one common component:
they all employ Gaussian mixture
model (GMM) as the generative model for local features. This choice has been proved effective in
modeling standard local features such as SIFT  which are often of low dimension. Usually  using a

1

mixture of a few hundred Gaussians has been sufﬁcient to guarantee good performance. Generally
speaking  the distribution of local features can only be well captured by a Gaussian distribution
within a local region due to the variety of local feature appearances and thus the number of Gaussian
mixtures needed is essentially determined by the volume of the feature space of local features.
Recently  the choice of local features has gone beyond the traditional local patch descriptors such as
SIFT or SURF [7] and higher dimensional local features such as the activation of a pre-trained deep
neural-network [8] or pooled coding vectors from a local region [9  10] have demonstrated promis-
ing performance. The higher dimensionality and rich visual content captured by those features make
the volume of their feature space much larger than that of traditional local features. Consequently  a
much larger number of Gaussian mixtures will be needed in order to model the feature space accu-
rately. However  this would lead to the explosion of the resulted image representation dimensionality
and thus is usually computationally impractical.
To alleviate this difﬁculty  here we propose an alternative solution. We model the generation process
of local features as randomly drawing features from a Gaussian distribution whose mean vector is
randomly drawn from a subspace. With certain approximation  we convert this model to a sparse
coding model and leverage an off-the-shelf solver to solve the learning and inference problems.
With further derivation  this model leads to a new Fisher vector coding algorithm called Sparse
Coding based Fisher Vector Coding (SCFVC). Moreover  we adopt the recently developed Deep
Convolutional Neural Network to generate regional local features and apply the proposed SCFVC
to these local features to build an image classiﬁcation system.
To demonstrate its effectiveness in encoding the high dimensional local feature  we conduct a series
of experiments on generic object  indoor scene and ﬁne-grained image classiﬁcation datasets  it is
shown that our method not only signiﬁcantly outperforms the traditional GMM based Fisher vector
coding in encoding high dimensional local features but also achieves state-of-the-art performance in
these image classiﬁcation problems.

2 Fisher vector coding

2.1 General formulation

Given two samples generated from a generative model  their similarity can be evaluated by using a
Fisher kernel [1]. The sample can take any form  including a vector or a vector set  as long as its gen-
eration process can be modeled. For a Fisher vector based image classiﬁcation approach  the sample
is a set of local features extracted from an image which we denote it as X = {x1  x2 ···   xT}.
Assuming each xi is modeled by a p.d.f P (x|λ) and is drawn i.i.d  in Fisher kernel a sample X can
be described by the gradient vector over the model parameter λ

λ = ∇λ log P (X|λ) =
GX

∇λ log P (xi|λ).

(1)

(cid:88)

i

T

F−1GX

T

λ GX
λ

λ   where F is the information matrix
The Fisher kernel is then deﬁned as K(X  Y) = GX
λ
and is deﬁned as F = E[GX
]. In practice  the role of the information matrix is less signiﬁcant
and is often omitted for computational simplicity [3]. As a result  two samples can be directly
compared by the linear kernel of their corresponding gradient vectors which are often called Fisher
vectors. From a bag-of-features model perspective  the evaluation of the Fisher kernel for two
images can be seen as ﬁrst calculating the gradient or Fisher vector of each local feature and then
performing sum-pooling. In this sense  the Fisher vector calculation for each local feature can be
seen as a coding method and we call it Fisher vector coding in this paper.

2.2 GMM based Fisher vector coding and its limitation

To implement the Fisher vector coding framework introduced above  one needs to specify the dis-
tribution P (x|λ). In the literature  most  if not all  works choose GMM to model the generation
process of x  which can be described as follows:

• Draw a Gaussian model N (µk  Σk) from the prior distribution P (k)  k = 1  2 ···   m .
• Draw a local feature x from N (µk  Σk).

2

Generally speaking  the distribution of x resembles a Gaussian distribution only within a local region
of feature space. Thus  for a GMM  each of Gaussian essentially models a small partition of the
feature space and many of them are needed to depict the whole feature space. Consequently  the
number of mixtures needed will be determined by the volume of the feature space. For the commonly
used low dimensional local features  such as SIFT  it has been shown that it is sufﬁcient to set the
number of mixtures to few hundreds. However  for higher dimensional local features this number
may be insufﬁcient. This is because the volume of feature space usually increases quickly with the
feature dimensionality. Consequently  the same number of mixtures will result in a coarser partition
resolution and imprecise modeling.
To increase the partition resolution for higher dimensional feature space  one straightforward so-
lution is to increase the number of Gaussians. However  it turns out that the partition resolution
increases slowly (compared to our method which will be introduced in the next section) with the
number of mixtures. In other words  much larger number of Gaussians will be needed and this will
result in a Fisher vector whose dimensionality is too high to be handled in practice.

3 Our method

3.1

Inﬁnite number of Gaussians mixture

Our solution to this issue is to go beyond a ﬁxed number of Gaussian distributions and use an
inﬁnite number of them. More speciﬁcally  we assume that a local feature is drawn from a Gaussian
distribution with a randomly generated mean vector. The mean vector is a point on a subspace
spanned by a set of bases (which can be complete or over-complete) and is indexed by a latent
coding vector u. The detailed generation process is as follows:

• Draw a coding vector u from a zero mean Laplacian distribution P (u) = 1
• Draw a local feature x from the Gaussian distribution N (Bu  Σ) 

2λ exp(−|u|
λ ).

where the Laplace prior for P (u) ensures the sparsity of resulting Fisher vector which can be helpful
for coding. Essentially  the above process resembles a sparse coding model. To show this relation-
ship  let’s ﬁrst write the marginal distribution of x:
P (x  u|B)du =

P (x|u  B)P (u)du.

P (x) =

(cid:90)

(cid:90)

(2)

u

u

The above formulation involves an integral operator which makes the likelihood evaluation difﬁcult.
To simplify the calculation  we use the point-wise maximum within the integral term to approximate
the likelihood  that is 

P (x) ≈ P (x|u∗  B)P (u∗).

u∗ = argmax

P (x|u  B)P (u)

u

(3)

By assumming that Σ = diag(σ2
logarithm of P (x) is written as

m = σ2 as a constant. The

1 ···   σ2

m) and setting σ2

1 = ··· = σ2

log(P (x|B)) = min

u

1

σ2(cid:107)x − Bu(cid:107)2

2 + λ(cid:107)u(cid:107)1 

(4)
which is exactly the objective value of a sparse coding problem. This relationship suggests that we
can learn the model parameter B and infer the latent variable u by using the off-the-shelf sparse
coding solvers.
One question for the above method is that compared to simply increasing the number of models
in traditional GMM  how much improvement is achieved by increasing the partition resolution. To
answer this question  we designed an experiment to compare these two schemes. In our experiment 
the partition resolution is roughly measured by the average distance (denoted as d ) between a feature
and its closest mean vector in the GMM or the above model. The larger d is  the lower the partition
resolution is. The comparison is shown in Figure 1. In Figure 1 (a)  we increase the dimensionality

3

of local features 1 and for each dimension we calculate d in a GMM model with 100 mixtures. As
seen  d increases quickly with the feature dimensionality. In Figure 1 (b)  we try to reduce d by
introducing more mixture distributions in GMM model. However  as can be seen  d drops slowly
with the increase in the number of Gaussians. In contrast  with the proposed method  we can achieve
much lower d by using only 100 bases. This result illustrates the advantage of our method.

(a)

(b)

Figure 1: Comparison of two ways to increase the partition resolution. (a) For GMM  d (the av-
erage distance between a local feature and its closest mean vector) increases with the local feature
dimensionality. Here the GMM is ﬁxed at 100 Gaussians. (b) d is reduced in two ways (1) simply
increasing the number of Gaussian distributions in the mixture. (2) using the proposed generation
process. As can be seen  the latter achieves much lower d even with a small number of bases.

3.2 Sparse coding based Fisher vector coding

Once the generative model of local features is established  we can readily derive the corresponding
Fisher coding vector by differentiating its log likelihood  that is 
σ2(cid:107)x − Bu∗(cid:107)2
∂ 1

∂ log(P (x|B))

2 + λ(cid:107)u∗(cid:107)1

C(x) =

∂B
u∗ = argmax

P (x|u  B)P (u).

=

∂B

(5)
Note that the differentiation involves u∗ which implicitly interacts with B. To calculate this term 
we notice that the sparse coding problem can be reformulated as a general quadratic programming
problem by deﬁning u+ and u− as the positive and negative parts of u  that is  the sparse coding
problem can be rewritten as

u

u+ u− (cid:107)x − B(u+ − u−)(cid:107)2
min
s.t. u+ ≥ 0 u− ≥ 0

2 + λ1T (u+ + u−)

(6)
By further deﬁning u(cid:48) = (u+  u−)T   log(P (x|B)) can be expressed in the following general form 

log(P (x|B)) = L(B) = max

u(cid:48) u(cid:48)T v(B) − 1

2

u(cid:48)T P(B)u(cid:48) 

(7)

where P(B) and v(B) are a matrix term and a vector term depending on B respectively. The
derivative of L(B) has been studied in [11]. According to the Lemma 2 in [11]  we can differentiate
L(B) with respect to B as if u(cid:48) did not depend on B. In other words  we can ﬁrstly calculate u(cid:48) or
equivalently u∗ by solving the sparse coding problem and then obtain the Fisher vector ∂ log(P (x|B))
as

∂B

σ2(cid:107)x − Bu∗(cid:107)2
∂ 1

2 + λ(cid:107)u∗(cid:107)1

∂B

= (x − Bu∗)u∗T .

(8)

1This is achieved by performing PCA on a 4096-dimensional CNN regional descriptor. For more details

about the feature we used  please refer to Section 3.4

4

10020030040050060070080090010001.822.22.42.62.83Dimensionality of regional local features d GMM with 100 mixtures10020030040050060070080090010002.252.32.352.42.452.52.55Number of Gaussian mixturesd GMMProposed model (with 100 bases)Table 1: Comparison of results on Pascal VOC 2007. The lower part of this table lists some results
reported in the literature. We only report the mean average precision over 20 classes. The average
precision for each class is listed in Table 2.

Methods
SCFVC (proposed)
GMMFVC
CNNaug-SVM [8]
CNN-SVM [8]
NUS [13]
GHM [14]
AGS [15]

mean average precision Comments
76.9%
73.8%
77.2%
73.9%
70.5%
64.7%
71.1%

single scale  no augmented data
single scale  no augmented data
with augmented data  use CNN for whole image
no augmented data.use CNN for whole image
-
-
-

Note that the Fisher vector expressed in Eq. (8) has an interesting form: it is simply the outer product
between the sparse coding vector u∗ and the reconstruction residual term (x − Bu∗). In traditional
sparse coding  only the kth dimension of a coding vector uk is used to indicate the relationship
between a local feature x and the kth basis. Here in the sparse coding based Fisher vector  the
coding value uk multiplied by the reconstruction residual is used to capture their relationship.

3.3 Pooling and normalization

From the i.i.d assumption in Eq. (1)  the Fisher vector of the whole image is 2
(xi − Bu∗

∂ log(P (xi|B))

∂ log(P (I|B))

=

=

i )u∗

i

(cid:62)

.

(9)

(cid:88)

xi∈I

∂B

∂B

(cid:88)

xi∈I

This is equivalent to performing the sum-pooling for the extracted Fisher coding vectors. However 
it has been observed [3  12] that the image signature obtained using sum-pooling tends to over-
emphasize the information from the background [3] or bursting visual words [12]. It is important to
apply normalization when sum-pooling is used. In this paper  we apply intra-normalization [12] to
normalize the pooled Fisher vectors. More speciﬁcally  we apply l2 normalization to the subvectors
i . Besides

i k ∀k  where k indicates the kth dimension of the sparse coding u∗

(cid:80)
xi∈I(xi − Bu∗

i )u∗

intra-normalization  we also utilize the power normalization as suggested in [3].

3.4 Deep CNN based regional local features

Recently  the middle-layer activation of a pre-trained deep CNN has been demonstrated to be a
powerful image descriptor [8  16]. In this paper  we employ this descriptor to generate a number
of local features for an image. More speciﬁcally  an input image is ﬁrst resized to 512×512 pixels
and regions with the size of 227×227 pixels are cropped with the stride 8 pixels. These regions
are subsequently feed into the deep CNN and the activation of the sixth layer is extracted as local
features for these regions. In our implementation  we use the Caffe [17] package which provides a
deep CNN pre-trained on ILSVRC2012 dataset and its 6-th layer is a 4096-dimensional vector. This
strategy has demonstrated better performance than directly using deep CNN features for the whole
image recently [16].
Once regional local features are extracted  we encoded them using the proposed SCFVC method and
generate an image level representation by sum-pooling and normalization. Certainly  our method is
open to the choice of other high-dimensional local features. The reason for choosing deep CNN
features in this paper is that by doing so we can demonstrate state-of-the-art image classiﬁcation
performance.

4 Experimental results

We conduct experimental evaluation of the proposed sparse coding based Fisher vector coding
(SCFVC) on three large datasets: Pascal VOC 2007  MIT indoor scene-67 and Caltech-UCSD Birds-

2the vectorized form of ∂ log(P (I|B))

∂B

is used as the image representation.

5

Table 2: Comparison of results on Pascal VOC 2007 for each of 20 classes. Besides the proposed
SCFVC and the GMMFVC baseline  the performance obtained by directly using CNN as global
feature is also compared.

aero
89.5
SCFVC
GMMFVC
87.1
CNN-SVM 88.5
table
72.0
SCFVC
GMMFVC
66.9
CNN-SVM 66.5

bike
84.1
80.6
81.0
dog
77.1
75.1
77.8

boat
83.7
79.7
82.0

bird
83.7
80.3
83.5
horse mbike
88.7
84.9
81.8

82.1
81.2
78.8

bottle
43.9
42.8
42.0
person
94.4
93.1
90.2

bus
76.7
72.2
72.5
plant
56.8
53.1
54.8

car
87.8
87.4
85.3
sheep
71.4
70.8
71.1

cat
82.5
76.1
81.6
sofa
67.7
66.2
62.6

chair
60.6
58.6
59.9
train
90.9
87.9
87.2

cow
69.6
64.0
58.5
TV
75.0
71.3
71.8

Table 3: Comparison of results on MIT-67. The lower part of this table lists some results reported
in the literature.

Methods
SCFVC (proposed)
GMMFVC
MOP-CNN [16]
VLAD level2 [16]
CNN-SVM [8]
FV+Bag of parts [19]
DPM [20]

Classiﬁcation Accuracy Comments
68.2%
64.3%
68.9%
65.5%
58.4%
63.2%
37.6%

with single scale
with single scale
with three scales
with single best scale
use CNN for whole image
-
-

200-2011. These are commonly used evaluation benchmarks for generic object classiﬁcation  scene
classiﬁcation and ﬁne-grained image classiﬁcation respectively. The focus of these experiments is
to examine that whether the proposed SCFVC outperforms the traditional Fisher vector coding in
encoding high dimensional local features.

4.1 Experiment setup

In our experiments  the activations of the sixth layer of a pre-trained deep CNN are used as regional
local features. PCA is applied to further reduce the regional local features from 4096 dimensions to
2000 dimensions. The number of Gaussian distributions and the codebook size for sparse coding is
set to 100 throughout our experiments unless otherwise mentioned.
For the sparse coding  we use the algorithm in [18] to learn the codebook and perform the coding
vector inference. For all experiments  linear SVM is used as the classiﬁer.

4.2 Main results

Pascal-07 Pascal VOC 2007 contains 9963 images with 20 object categories which form 20 binary
(object vs. non-object) classiﬁcation tasks. The use of deep CNN features has demonstrated the
state-of-the-art performance [8] on this dataset. In contrast to [8]  here we use the deep CNN fea-
tures as local features to model a set of image regions rather than as a global feature to model the
whole image. The results of the proposed SCFVC and traditional Fisher vector coding  denoted as
GMMFVC  are shown in Table 1 and Table 2. As can be seen from Table 1  the proposed SCFVC
leads to superior performance over the traditional GMMFVC and outperforms GMMFVC by 3%.
By cross-referencing Table 2  it is clear that the proposed SCFVC outperforms GMMFVC in all
of 20 categories. Also  we notice that the GMMFVC is merely comparable to the performance of
directly using deep CNN as global features  namely  CNN-SVM in Table 1. Since both the proposed
SCFVC and GMMFVC adopt deep CNN features as local features  this observation suggests that
the advantage of using deep CNN features as local features can only be clearly demonstrated when
the appropriate coding method  i.e. the proposed SCFVC is employed. Note that to further boost the

6

Table 4: Comparison of results on Birds-200 2011. The lower part of this table lists some results
reported in the literature.

Methods
SCFVC (proposed)
GMMFVC
CNNaug-SVM [8]
CNN-SVM [8]
DPD+CNN+LogReg [21]
DPD [22]

Classiﬁcation Accuracy Comments
66.4%
61.7%
61.8%
53.3%
65.0%
51.0%

with single scale
with single scale
with augmented data  use CNN for the whole image
no augmented data  use CNN as global features
use part information
-

Figure 2: The performance comparison of classiﬁcation accuracy vs. local feature dimensionality
for the proposed SCFVC and GMMFVC on MIT-67.

performance  one can adopt some additional approaches like introducing augmented data or com-
bining multiple scales. Some of the methods compared in Table 1 have employed these approaches
and we have commented this fact as so inform readers that whether these methods are directly com-
parable to the proposed SCFVC. We do not pursue these approaches in this paper since the focus of
our experiment is to compare the proposed SCFVC against traditional GMMFVC.
MIT-67 MIT-67 contains 6700 images with 67 indoor scene categories. This dataset is quite chal-
lenging because the differences between some categories are very subtle. The comparison of classi-
ﬁcation results are shown in Table 3. Again  we observe that the proposed SCFVC signiﬁcantly out-
performs traditional GMMFVC. To the best of our knowledge  the best performance on this dataset
is achieved in [16] by concatenating the features extracted from three different scales. The proposed
method achieves the same performance only using a single scale. We also tried to concatenate the
image representation generated from the proposed SCFVC with the global deep CNN feature. The
resulted performance can be as high as 70% which is by far the best performance achieved on this
dataset.
Birds-200-2011 Birds-200-2011 contains 11788 with 200 different birds species  which is a com-
monly used benchmark for ﬁne-grained image classiﬁcation. The experimental results on this
dataset are shown in Table 4. The advantage of SCFVC over GMMFVC is more pronounced on
this dataset: SCFVC outperforms GMMFVC by over 4%. We also notice two interesting obser-
vations: (1) GMMFVC even achieves comparable performance to the method of using the global
deep CNN feature with augmented data  namely  CNNaug-SVM in Table 4. (2) Although we do
not use any parts information (of birds)  our method outperforms the result using parts information
(DPD+CNN+LogReg in Table 4). These two observations suggest that using deep CNN features
as local features is better for ﬁne-grained problems and the proposed method can further boost its
advantage.

7

0200400600800100012001400160018002000616263646566676869Dimensionality of regional local featuresClassification Accuracy % SCFVGMMFVTable 5: Comparison of results on MIT-67 with three different settings: (1) 100-basis codebook with
1000 dimensional local features  denoted as SCFV-100-1000D (2) 400 Gaussian mixtures with 300
dimensional local features  denoted as GMMFV-400-300D (3) 1000 Gaussian mixtures with 100
dimensional local features denoted as GMMFV-1000-100D. They have the same/similar total image
representation dimensionality.

SCFV-100-1000D GMMFV-400-300D GMMFV-1000-100D
68.1%

64.0%

60.8%

4.3 Discussion

In the above experiments  the dimensionality of local features is ﬁxed to 2000. But how about the
performance comparison between the proposed SCFV and traditional GMMFV on lower dimen-
sional features? To investigate this issue  we vary the dimensionality of the deep CNN features from
100 to 2000 and compare the performance of the two Fisher vector coding methods on MIT-67. The
results are shown in Figure 2. As can be seen  for lower dimensionality (like 100)  the two methods
achieve comparable performance and in general both methods beneﬁt from using higher dimensional
features. However  for traditional GMMFVC  the performance gain obtained from increasing fea-
ture dimensionality is lower than that obtained by the proposed SCFVC. For example  from 100 to
1000 dimensions  the traditional GMMFVC only obtains 4% performance improvement while our
SCFVC achieves 7% performance gain. This validates our argument that the proposed SCFVC is
especially suited for encoding high dimensional local features.
Since GMMFVC works well for lower dimensional features  how about reducing the higher dimen-
sional local features to lower dimensions and use more Gaussian mixtures? Will it be able to achieve
comparable performance to our SCFVC which uses higher dimensional local features but a smaller
number of bases? To investigate this issue  we also evaluate the classiﬁcation performance on MIT-
67 using 400 Gaussian mixtures with 300-dimension local features and 1000 Gaussian mixtures with
100-dimension local features. Thus the total dimensionality of these two image representations will
be similar to that of our SCFVC which uses 100 bases and 1000-dimension local features. The com-
parison is shown in Table 5. As can be seen  the performance of these two settings are much inferior
to the proposed one. This suggests that some discriminative information may have already been lost
after the PCA dimensionality reduction and the discriminative power can not be re-boosted by sim-
ply introducing more Gaussian distributions. This veriﬁes the necessity of using high dimensional
local features and justiﬁes the value of the proposed method.
In general  the inference step in sparse coding can be slower than the membership assignment in
GMM model. However  the computational efﬁciency can be greatly improved by using an approx-
imated sparse coding algorithm such as learned FISTA [23] or orthogonal matching pursuit [10].
Also  the proposed method can be easily generalized to several similar coding models  such as local
linear coding [24]. In that case  the computational efﬁciency is almost identical (or even faster if
approximated k-nearest neighbor algorithms are used) to the traditional GMMFVC.

5 Conclusion

In this work  we study the use of Fisher vector coding to encode high-dimensional local features.
Our main discovery is that traditional GMM based Fisher vector coding is not particular well suited
to modeling high-dimensional local features. As an alternative  we proposed to use a generation
process which allows the mean vector of a Gaussian distribution to be chosen from a point in a
subspace. This model leads to a new Fisher vector coding method which is based on sparse coding
model. Combining with the activation of the middle layer of a pre-trained CNN as high-dimensional
local features  we build an image classiﬁcation system and experimentally demonstrate that the
proposed coding method is superior to the traditional GMM in encoding high-dimensional local
features and can achieve state-of-the-art performance in three image classiﬁcation problems.
Acknowledgements This work was in part supported by Australian Research Council grants
FT120100969  LP120200485  and the Data to Decisions Cooperative Research Centre. Correspon-
dence should be addressed to C. Shen (email: chhshen@gmail.com).

8

References
[1] T. Jaakkola and D. Haussler  “Exploiting generative models in discriminative classiﬁers ” in Proc. Adv.

Neural Inf. Process. Syst.  1998  pp. 487–493.

[2] F. Perronnin and C. R. Dance  “Fisher kernels on visual vocabularies for image categorization ” in Proc.

IEEE Conf. Comp. Vis. Patt. Recogn.  2007.

[3] F. Perronnin  J. S´anchez  and T. Mensink  “Improving the Fisher kernel for large-scale image classiﬁca-

tion ” in Proc. Eur. Conf. Comp. Vis.  2010.

[4] J. Krapac  J. J. Verbeek  and F. Jurie  “Modeling spatial layout with ﬁsher vectors for image categoriza-

tion.” in Proc. IEEE Int. Conf. Comp. Vis.  2011  pp. 1487–1494.

[5] K. Simonyan  A. Vedaldi  and A. Zisserman  “Deep ﬁsher networks for large-scale image classiﬁcation ”

in Proc. Adv. Neural Inf. Process. Syst.  2013.

[6] V. Sydorov  M. Sakurada  and C. H. Lampert  “Deep ﬁsher kernels—end to end learning of the Fisher

kernel GMM parameters ” in Proc. IEEE Conf. Comp. Vis. Patt. Recogn.  2014.

[7] H. Bay  A. Ess  T. Tuytelaars  and L. J. V. Gool  “Speeded-up robust features (SURF) ” Computer Vision

& Image Understanding  vol. 110  no. 3  pp. 346–359  2008.

[8] A. S. Razavian  H. Azizpour  J. Sullivan  and S. Carlsson  “CNN features off-the-shelf: an astounding

baseline for recognition ” 2014  http://arxiv.org/abs/1403.6382.

[9] S. Yan  X. Xu  D. Xu  S. Lin  and X. Li  “Beyond spatial pyramids: A new feature extraction framework
with dense spatial sampling for image classiﬁcation ” in Proc. Eur. Conf. Comp. Vis.  2012  pp. 473–487.
[10] L. Bo  X. Ren  and D. Fox  “Hierarchical matching pursuit for image classiﬁcation: Architecture and fast

algorithms ” in Proc. Adv. Neural Inf. Process. Syst.  2011  pp. 2115–2123.

[11] O. Chapelle  V. Vapnik  O. Bousquet  and S. Mukherjee  “Choosing multiple parameters for support vector

machines ” Machine Learning  vol. 46  no. 1–3  pp. 131–159  2002.

[12] R. Arandjelovi´c and A. Zisserman  “All about VLAD ” in Proc. IEEE Int. Conf. Comp. Vis.  2013.
[13] Z. Song  Q. Chen  Z. Huang  Y. Hua  and S. Yan  “Contextualizing object detection and classiﬁcation.” in

Proc. IEEE Conf. Comp. Vis. Patt. Recogn.  2011.

[14] Q. Chen  Z. Song  Y. Hua  Z. Huang  and S. Yan  “Hierarchical matching with side information for image

classiﬁcation.” in Proc. IEEE Conf. Comp. Vis. Patt. Recogn.  2012  pp. 3426–3433.

[15] J. Dong  W. Xia  Q. Chen  J. Feng  Z. Huang  and S. Yan  “Subcategory-aware object classiﬁcation.” in

Proc. IEEE Conf. Comp. Vis. Patt. Recogn.  2013  pp. 827–834.

[16] Y. Gong  L. Wang  R. Guo  and S. Lazebnik  “Multi-scale orderless pooling of deep convolutional activa-

tion features ” in Proc. Eur. Conf. Comp. Vis.  2014.

[17] Y. Jia  “Caffe ” 2014  https://github.com/BVLC/caffe.
[18] H. Lee  A. Battle  R. Raina  and A. Y. Ng  “Efﬁcient sparse coding algorithms ” in Proc. Adv. Neural Inf.

Process. Syst.  2007  pp. 801–808.

[19] C. Doersch  A. Gupta  and A. A. Efros  “Mid-level visual element discovery as discriminative mode

seeking ” in Proc. Adv. Neural Inf. Process. Syst.  2013.

[20] M. Pandey and S. Lazebnik  “Scene recognition and weakly supervised object localization with de-

formable part-based models ” in Proc. IEEE Int. Conf. Comp. Vis.  2011  pp. 1307–1314.

[21] J. Donahue  Y. Jia  O. Vinyals  J. Hoffman  N. Zhang  E. Tzeng  and T. Darrell  “DeCAF: A deep convo-

lutional activation feature for generic visual recognition ” in Proc. Int. Conf. Mach. Learn.  2013.

[22] N. Zhang  R. Farrell  F. Iandola  and T. Darrell  “Deformable part descriptors for ﬁne-grained recognition

and attribute prediction ” in Proc. IEEE Int. Conf. Comp. Vis.  December 2013.

[23] K. Gregor and Y. LeCun  “Learning fast approximations of sparse coding ” in Proc. Int. Conf. Mach.

Learn.  2010  pp. 399–406.

[24] J. Wang  J. Yang  K. Yu  F. Lv  T. Huang  and Y. Gong  “Locality-constrained linear coding for image

classiﬁcation ” in Proc. IEEE Conf. Comp. Vis. Patt. Recogn.  2010.

9

,Boqing Gong
Kristen Grauman
Fei Sha
Lingqiao Liu
Chunhua Shen
Lei Wang
Anton van den Hengel
Chao Wang