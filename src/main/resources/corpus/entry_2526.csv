2019,Icebreaker: Element-wise Efficient Information Acquisition with a Bayesian Deep Latent Gaussian Model,In this paper  we address the ice-start problem  i.e.  the challenge of deploying machine learning models when only a little or no training data is initially available  and acquiring each feature element of data is associated with costs. This setting is representative of the real-world machine learning applications. For instance  in the health care domain  obtaining every single measurement comes with a cost. We propose Icebreaker  a principled framework for elementwise training data acquisition. Icebreaker introduces a full Bayesian Deep Latent Gaussian Model (BELGAM) with a novel inference method  which combines recent advances in amortized inference and stochastic gradient MCMC to enable fast and accurate posterior inference. By utilizing BELGAM’s ability to fully quantify model uncertainty  we also propose two information acquisition functions for imputation and active prediction problems. We demonstrate that BELGAM performs significantly better than previous variational autoencoder (VAE) based models  when the data set size is small  using both machine learning benchmarks and real world recommender systems and health-care applications. Moreover  Icebreaker not only demonstrates improved performance compared to baselines  but it is also capable of achieving better test performance with less training data available.,Icebreaker:

Element-wise Efﬁcient Information Acquisition with

a Bayesian Deep Latent Gaussian Model

Wenbo Gong1∗  Sebastian Tschiatschek2  Richard E. Turner12 

Sebastian Nowozin2†  José Miguel Hernández-Lobato12  Cheng Zhang2

Abstract

In this paper  we address the ice-start problem  i.e.  the challenge of deploying
machine learning models when only a little or no training data is initially available 
and acquiring each feature element of data is associated with costs. This setting
is representative of the real-world machine learning applications. For instance  in
the health-care domain  obtaining every single measurement comes with a cost.
We propose Icebreaker  a principled framework for element-wise training data
acquisition. Icebreaker introduces a full Bayesian Deep Latent Gaussian Model
(BELGAM) with a novel inference method  which combines recent advances in
amortized inference and stochastic gradient MCMC to enable fast and accurate
posterior inference. By utilizing BELGAM’s ability to fully quantify model un-
certainty  we also propose two information acquisition functions for imputation
and active prediction problems. We demonstrate that BELGAM performs signif-
icantly better than previous variational autoencoder (VAE) based models  when
the data set size is small  using both machine learning benchmarks and real-world
recommender systems and health-care applications. Moreover  Icebreaker not only
demonstrates improved performance compared to baselines  but it is also capable
of achieving better test performance with less training data available.

1

Introduction

Acquiring information is costly in many real-world applications. For example  a medical doctor often
needs to carry out a sequence of lab tests to make a correct diagnosis  where each of these tests is
associated with a cost in terms of money  time  and health risks. To this end  an AI system should be
able to suggest the information to be acquired in the form of "one measurement (feature) at a time" for
accurate predictions (diagnosis) of any new user. Recently  test-time active prediction methods  such
as EDDI (Efﬁcient Dynamic Discovery of high-value Inference) [28]  provide a solution for such a
problem when there is a sufﬁcient amount of training data. Unfortunately  in many scenarios  training
data can also be challenging and costly to obtain. For example  new data needs to be collected by
taking measurements of currently hospitalized patients with their consent. Ideally  we would like to
deploy an AI system  such as EDDI  when no or only limited training data is available. We call this
problem the ice-start problem.
The key to address the ice-start problem is to have a scalable model that knows what it does not know 
namely to quantify the epistemic uncertainty. This knowledge can be used to guide the acquisition of

1Department of Engineering  University of Cambridge  Cambridge  UK
∗Contributed during internship in Microsoft Research
2Microsoft Research  Cambridge  UK
†Now at Google AI  Berlin  Germany (contributed while being with Microsoft Research)

Correspondence to: Cheng Zhang <Cheng.Zhang@microsoft.com> and Wenbo Gong <wg242@cam.ac.uk>

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

training data. Intuitively  unfamiliar  but informative features are more useful for model training. We
refer to this as element-wise training-time active acquisition.
Training-time active acquisition is needed in a great range of applications. One example is the
recommender system with no historical user data.
Despite the success of element-wise test-time active prediction [23  28  44  56]  few works have
provided a general and scalable solution for the ice-start problem. Additionally  these works [21  22 
32] are commonly limited to a speciﬁc application scenario. More importantly  we need to design
new acquisition functions that take the model parameters uncertainty into account.
In this work  we propose Icebreaker 1  a principled and efﬁcient framework to solve the ice-start
problem. Icebreaker actively acquires informative feature elements during training and also performs
two general test tasks. To enable Icebreaker  we contribute the following:

1. We propose a Bayesian deep Latent Gaussian Model (BELGAM). Standard training of the
deep generative model produces the point estimates for the parameters  whereas our approach
applies a fully Bayesian treatment to the weights. The resulting epistemic uncertainty can
be later used for training acquisition. (Section 2)

2. We design a novel partial amortized inference method for BELGAM  named PA-BELGAM.
We combine the efﬁcient amortized inference for the local latent variables with stochastic
gradient MCMC for the model parameters to ensure high inference accuracy. (Section 2.2)
3. To complete Icebreaker  we propose two training-time element-wise information acquisition
functions based on PA-BELGAM for imputation (Section 3) and active prediction (Section
4) tasks  respectively.

4. We evaluate PA-BELGAM and the entire Icebreaker approach on common machine learning
benchmarks and a real-world health-care task. Our method demonstrates clear improvements
when compared to multiple baselines  showing that it can be effectively used to solve the
ice-start problem. (Section 5)

2 Bayesian Deep Latent Gaussian Model (BELGAM) with Partial

Amortized Inference

Here  we propose a Bayesian Deep Latent Gaussian Model (BELGAM) with explicit epistemic
uncertainty quantiﬁcation  and a novel hybrid inference scheme for efﬁcient and accurate inference.
2.1 Bayesian Deep Latent Gaussian Model (BELGAM)
A Bayesian latent variable model shown in Figure 1  is a common
modeling choice  but previous work has focused on models that are
typically linear and not ﬂexible enough to model highly complex data.
On the other hand  Deep Latent Gaussian Model [20]  which uses a
ﬂexible neural network  does not quantify the parameter uncertainty.
We unify the above two models and propose a Bayesian Deep Latent
Gaussian Model (BELGAM)  which uses a Bayesian neural network
to generate observations XO from local latent variables Z with
global weights θ shown in Figure 1. The model is thus deﬁned as:

XX

Z

θ

p(XO  θ  Z) = p(θ)

p(xi d|zi  θ)p(zi) 

Figure 1: BELGAM

(1)

|O|(cid:89)

(cid:89)

i=1

d∈Oi

where |O| is the amount of observed data  and Oi is the et of indices of observed feature entries
for the ith data point. The goal is to infer the posterior  p(θ  Z|XO)  for both local latent variables
Z = [z1  . . .   z|o|] and global latent weights θ. However  the posterior is generally intractable  and
approximate inference is needed [25  57]. Variational inference (VI) [3  18  25  52  57] and sampling-
based methods [1] are two types of approaches commonly used for this task. Sampling-based
approaches are known for accurate inference performances and theoretical guarantees[6].

1Code available: https://github.com/microsoft/Icebreaker

2

However  sampling the local latent variable Z is computationally expensive as the cost scales
linearly with the data set size. To best trade off computational cost against inference accuracy  we
propose to amortize the inference for Z and keep an accurate sampling-based approach for the global
latent weights θ. Speciﬁcally  we use preconditioned stochastic gradient Hamiltonian Monte Carlo
(SGHMC) [6] (see appendix for details).
2.2 Partial Amortized BELGAM
Revisiting amortized inference in the presence of missing data. Amortized inference [20  38]
is an efﬁcient extension for variational inference. It was originally proposed for inferring local latent
variables Z of deep latent Gaussian models. Amortized inference uses a deep neural network as a
function estimator to compute the variational distribution q(zi|xi) for the posterior of zi using xi as
input  instead of using individually parameterized approximations q(zi). Thus  the estimation of the
local latent variable does not scale with data set size during model training.
However  in our problem setting  the feature values for
each data instance are partially observed. Thus  the vanilla
amortized inference approach cannot be used as the input
dimensionality of the observed data can vary for each
data instance. As with the Partial VAE proposed in [28] 
we adopt a set encoding structure [37  55] to build an
inference network to infer Z based on partial observations
in an amortized manner.
The structure of the inference net is shown in Figure 2.
For each data instance xi ∈ XO with |Oi| observed features  the input is modiﬁed as Si =
[si 1  . . .   si |Oi|] where si d = [xi d  ed] and ed is a feature embedding. This is fed into a standard
neural network h : RM +1 → RK where M and K are the dimensions of the latent space and ed 
respectively. Finally  a permutation invariant set function g(·) is applied.

Figure 2: The illustration of P-VAE in-
ference network structure.

h(·)
h(·)

h(·)

g(·)

xi |O|

e|O|

xi 1

xi 2

e1

e2

. . .

latent space

Amortized inference + SGHMC As discussed previously  we want to be computationally efﬁcient
when inferring Z and be accurate when inferring the global latent weights θ for BELGAM. Here  we
discuss how to combine an accurate sampling approach for the global parameters with the efﬁcient
amortized inference for the local latent variables.
Assume we have the factorized approximated posterior q(θ  Z|XO) ≈ q(θ|XO)qφ(Z|XO) [20  28] 
then the proposed inference scheme can be summarized into two stages: (i) Sample θ ∼ q(θ|XO)
using SGHMC  (ii) Update the amortized inference network qφ(zi|xi) to approximate p(zi|xi).
First  we present how to sample θ ∼ q(θ|XO) using SGHMC. The optimal form for q(θ|XO) can
be deﬁned as q(θ|XO) = 1
C elog p(XO θ)  where C is the normalization constant p(XO). The key to
sampling from such distribution is to compute the gradient ∇θ log p(XO  θ)  which  unfortunately 
is intractable due to marginalizing the latent variable Z. Instead  we propose to approximate this
quantity by transforming the marginalization into an optimization:

(cid:2)Eqφ(zi|xi)[log p(xi|zi  θ)] − KL[qφ(zi|xi)||p(zi)](cid:3) + log p(θ) 
(cid:88)

where right hand side is the lower bound of the joint distribution. Assuming that F is a sufﬁciently
large function class  we can compute the gradient as:
∇θ log p(XO  θ) = ∇θ max
qφ∈F

(cid:2)Eqφ(zi|xi)[log p(xi|zi  θ)] − KL[qφ(zi|xi)||p(zi)](cid:3) + log p(θ).

log p(XO  θ) ≥ (cid:88)

i∈XO

(2)

i∈XO

After sampling θ  we then update the inference network with these samples by optimizing:
(cid:35)
L(XO; φ) = Eq(θ Z|XO)[log p(XO|Z  θ)] − KL[q(Z  θ|XO)||p(Z  θ)]
Eqφ(zi|xi)[log p(xi|zi  θ)] − KL[qφ(zi|xi)||p(zi)]
= Eq(θ|XO)

(cid:34)(cid:88)

− KL[q(θ|XO)||p(θ)].

(3)

i∈XO

(4)
where the outer expectation can be approximated by SGHMC samples  and the outer KL penalty is
intractable but can be ignored for updating the inference network. The resulting inference algorithm

3

resembles an iterative update procedure  like Monte Carlo Expectation Maximization (MCEM) [53]
where it samples latent Z and optimizes θ instead. We call the proposed model Partial Amortized
BELGAM (PA-BELGAM). Partial VAE [27] is actually a special case of PA-BELGAM  where θ is
estimated by a point instead of with a set of samples.
Note that  in this way  the computational cost with the single-chain SGHMC is exactly the same as
training a normal VAE thanks to the amortization for Z. Thus  PA-BELGAM scales to large data
when needed. For additional memory cost  we adopt a similar idea based on the Moving Window
MCEM algorithm [12]  where samples are stored and updated in a ﬁxed size pool with a ﬁrst in ﬁrst
out procedure. In the next two sections  we present two objective functions for two general machine
learning tasks respectively: imputation tasks and prediction tasks.

Icebreaker for Imputation Tasks

3
We present Icebreaker for imputation tasks  which can be directly applied in the same way as [27].

Problem Deﬁnition Assume that at each training data acquisition step we have already obtained
training data Dtrain  a pool data set Dpool that contains the data we could query next and Dtrain ∪
Dpool = X ∈ RN×D. In the ice-start scenario  Dtrain = ∅. At each step of the training-time
acquisition  we actively select data points xi d ∈ Dpool to acquire  thereby moving them into Dtrain
and updating the model with the newly formed Dtrain. Figure 3 shows the ﬂow diagram of this
procedure at a given step. During the process  there is an observed data set XO (e.g. the training data
set XO = Dtrain) and unobserved set XU with |O| and |U| number of rows respectively. For each
data instance xi ∈ XO  we have the observed index set Oi containing the indices of the observed
features for row i. The training time acquisition procedure is summarised in algorithm 1.

Algorithm 1: Element-wise training time acquisition
input :XO XU  Φ M  Acquisition number K  Ξ
XO = ∅;
while XU (cid:54)= ∅ do

/* Information acquisition */
Compute reward R(xi d  XO) for xi d ∈ XU using
Eq. 5 or 10 ;
// Reward computation
Sample Xnew ; // Sample K feature elements
according to the R value.
XO = XO ∪ Xnew;
/* Model Training */
Re-initialize model M ;
to avoid local optimum
M =Train(M Ξ);
/* Test task */
Test(M);
current model M

// Test performance of the

// Update training set

// Re-initialization

end

Figure 3: Icebreaker Flowchart. The green
and gray blocks represent observed and un-
observed items respectively.

We denote the training set Dtrain = XO and the pool set Dpool = XU . The model M and training
hyper-parameters are grouped as Ξ. We evaluate its quality on the test task using metrics such as
predictive negative log likelihood (NLL).
3.1 Active Information Acquisition for Imputation
Designing the training time acquisition function is nontrivial. Existing information-theoretical
objectives such as the one used in EDDI is not applicable in this setting (see appendix C.1). The key
for such an objective function is to make the model certain about the data set as quickly as possible
simultaneously focus on improving test performance.
Imputing missing values is important in applications such as recommender systems and other down-
stream tasks. In this setting  the goal is to learn about all the feature elements as quickly as possible.
This can be formalized as selecting the elements xi d that maximize the expected reduction in the
posterior uncertainty of θ:

RI (xi d  XO) = H[p(θ|XO)] − Ep(xi d|XO)[H[p(θ|XO  xi d)]] 

(5)

4

………………………………PA-BELGAMObjectiveQuerywhere H[·] denotes the entropy of a distribution. We use the symmetry of the mutual information to
sidestep the posterior update p(θ|XO  xi d) and entropy estimation of θ for efﬁciency. Thus  Eq. 5 is
written as

(6)

RI (xi d  XO) = H[p(xi d|XO)] − Ep(θ|XO)[H[p(xi d|θ  XO)]].
(cid:88)

(cid:88)

(cid:88)

1

1

We can approximate Eq. 6 as
RI (xi d  XO) ≈ − 1
K

(cid:88)
m=1 and {xk
i }M

i d|zm

p(xk

m n

k

log

M N
n=1  {zm

i   θn)+

log

1
M

m

N K

k n

p(xk

i d|zm

i   θn)  (7)

based on the samples {θn}N
k=1 from SGHMC  the amortized inference
network and the data distribution  respectively. The sample xi d ∼ p(xi d|XO) can be generated in
the following way: (i) zi ∼ qφ(zi|xio)  (ii) θ ∼ q(θ|XO) and (iii) xi d ∼ p(xi d|θ  zi)  where xio
represents the observed features in the ith row of XO

i d}K

4

Icebreaker for Prediction Tasks

Next  we introduce a second type of test task called active prediction  where a sequence of active
acquisition steps is carried out before predicting a speciﬁed target variable at test time. Note that the
typical test prediction task is a special case where no acquisition of features is performed. Here  we
demonstrate the case where feature-wise active information acquisition is used in both training and
testing time  which is desired in data costly situations.

Problem Deﬁnition During the training acquisition  the procedure is the same as in the imputation
task  which is shown in Algorithm 1 and Figure 3. The only difference is that we have speciﬁed target
variables. We denote the target as Y . In this case  each xi ∈ XO has a corresponding target yi. In
addition  instead of querying a single feature value xi d during training  as in the imputation task  we
query a feature-target pair (xi d  yi) if yi has not been queried before. Otherwise  we only query xi d.
As an example  we adopt a similar procedure used in EDDI [28] for test time active prediction  and
use the Area under the information curve (AUIC) generated from EDDI to evaluate the performance
of Icebreaker. This reﬂects the overall model performance with test time active acquisition. The
evaluation procedure is summarised in Algorithm 3 in the appendix.
4.1 Model and Active Information Acquisition for Active Prediction
Conditional BELGAM The proposed model and inference algorithm in section 3 can be easily
extended to incorporate the target variables. In general  PA-BELGAM can be directly adapted to any
VAE based framework. One possible choice is to adopt the formulation of the conditional VAE [45]
for the prediction task here (see appendix B for details).

Icebreaker for active target prediction. For the prediction task  solely reducing the model epis-
temic uncertainty is not optimal as the goal is to predict the target variable Y . Instead  we require
the model to (1) capture feature correlations for accurate imputations in both training and test time
(similar to reducing the model epistemic uncertainty)  and (2) ﬁnd informative features to learn to
predict the target variable. Thus  the desired acquisition function needs to balance the unsupervised
learning  which focuses on exploring relations between features  and supervised learning that exploits
informative features to predict speciﬁed targets. We propose the following objective:

RP (xi d  XO) = Ep(xi d|XO)[H[p(yi|xi d  XO)]] − Ep(θ xi d|XO)[H[p(yi|θ  xi d  XO)]].

(8)
The above objective is the conditional mutual information I(yi  θ|xi d; XO). Thus  maximizing
8 is the same as maximizing the information gain between the target yi and the model weights
θ  conditioned on the additional feature xi d  and observed features XO. In our case  the xi d is
unobserved. As the weights θ do not change signiﬁcantly after collecting xi d  for computational
convenience  we assume p(θ|XO) ≈ p(θ|XO  xi d) when estimating the objective.
As before  we approximate this objective using Monte Carlo integration:
RP (xi d  XO) ≈
− 1
JK

(cid:88)

(cid:88)

(cid:88)

(cid:88)

|z(m k)

|z(m k)

p(y(j k)

p(y(j k)

  θn) +

  θn) 

KN J

1
M

i

i

i

i

1

M N

(9)

log

log

1

j k

m n

j n k

m

5

(a) Boston Housing Imputation

(b) Long-tail selection pattern

(c) Boston Housing Active prediction

i

}J
j=1 and {xk

i

i d) for each imputed sample xk

Figure 4: Boston Housing experimental results. (a) The NLL over the number of observed feature
values. (b) The distribution (log scale) of the number of observed features per data instance during
the training time. (c) Performance on the active prediction task vs. training set size. The test time
active prediction curves at the training data size indicated by the black dash line are shown in Figure 5
where we draw {z(m k)
}M
m=1 from qφ(zi|XO  xk
n=1 
{y(j k)
i d}K
k=1) are sampled in a similar way as in the imputation task. This objective
naturally balances the exploration of new unseen features that may be informative as well as the
exploitation of the familiar ones to facilitate learning a better predictor. For example  if feature xi d
has not been observed before or uninformative about the target  the ﬁrst entropy term in Eq. 8 will be
high  which encourages the algorithm to pick this data point. However  using this term alone may
result in selecting uninformative/noisy features. Thus  we need an extra term that eliminates the
possibility of selecting uninformative features  which is exactly the second term. Unless xi d together
with θ can provide extra information about yi  the entropy in the second term for uninformative
features will still be high. Thus  the two terms combined together encourage the model to select the
less explored but informative features. The resulting objective is mainly targeted at (2) mentioned at
the beginning of this subsection. Thus  a natural way to satisfy both (1) and (2) is a combination of
the two objectives:

i d. Others ({θn}N

RC(xi d  XO) = (1 − α)RI (xi d  XO) + αRP (xi d  XO) 

(10)

where α controls which task the model focuses on. This objective also has an information-theoretic
interpretation. In the appendix C.1  we show that when α = 1
2  this combined objective is equivalent
to the mutual information between θ and the feature-target pair (xi d  yi).
5 Experiments

We evaluate Icebreaker ﬁrst on benchmark data sets UCI [8] on both imputation and prediction tasks.
We then consider two real-world applications: (a) movie rating imputation task using the MovieLens
dataset [10]; and (b) risk prediction in intensive care using the MIMIC dataset [17].

Experiments Setup and evaluation. We compare Icebreaker with a random feature acquisition
strategy for training where both P-VAE [28] and PA-BELGAM are used. For the imputation task 
P-VAE already achieves excellent results in various data sets compared to traditional methods [28  34].
Additionally  for the active prediction task  we compare Icebreaker to an instance-wise active learning
method  denoted as Row AT  in which the data are assumed to be fully observed apart from the target.
We evaluate the imputation performance by reporting negative log likelihood (NLL) over the test
target. For the active prediction task  we use EDDI [28] to sequentially select features at test time. We
report the area under the information curve (AUIC) [28] for the test set (See Figure 5 for an example
and the appendix for details). A smaller value of AUIC indicates better overall active prediction
performance. All experiments are averaged over 10 runs  and their setting details are in the appendix.
5.1 UCI Data Set
Imputation Task. At each step of Icebreaker  we select 50 feature elements from the pool. Figure
4a shows the averaged NLL on the test set as the training set increases. Icebreaker outperforms

6

05001000150020002500300035004000Training data set size1.001.251.501.752.002.252.502.75NLLBoston Housing missing value imputation NLLIcebreakerPA-BELGAMPVAE0500100015002000250030003500Training data set size1.52.02.53.03.5Concrete missing value imputation NLL05001000150020002500300035004000Training data set size1.82.02.22.42.62.83.03.2Wine quality missing value imputation NLL2468101214Number of features100101102Accumulated numberBoston Housing selection distribution with training size 250RandomIcebreaker246810Number of features100101102Accumulated numberConcrete selection distribution with training size 25024681012Number of features100101102Accumulated numberWine selection distribution with training size 2500250500750100012501500175020002250Training Set Size35.037.540.042.545.047.550.052.555.0AUIC Value500 training data1250 training data2250 training dataBoston Housing Active testing performanceIcebreaker+EDDIRow AT+EDDIPA-BELGAM+EDDIPVAE+EDDI0250500750100012501500175020002250Training Set Size19202122232425AUIC ValueEnergy Active testing performanceIcebreaker+EDDIRow AT+EDDIPA-BELGAM+EDDIPVAE+EDDIFigure 5: Evaluation of test time performance after exposure to different amounts of training data:
(Left): 550 feature elements. (Middle):1250 feature elements (Right): 2250 feature elements. The x-
axis indicates the number of actively-acquired feature elements used for prediction. Legend indicates
the methods used for training (Icebreaker  Row AT  etc.) and test time acquisition (EDDI  RAND)

random acquisition with both PA-BELGAM and P-VAE by a large margin  especially at the early
stages of training. We also see that PA-BELGAM alone can be beneﬁcial compared to P-VAE with
small data sets. This is because P-VAE tends to over-ﬁt  while PA-BELGAM leverages the model
uncertainties.
We also analyze the selection pattern. We gather all the rows that have been queried with at least one
feature during training acquisition and count how many features are queried for each. We repeat this
for the ﬁrst 5 acquisitions. Figure 4b shows the histogram of the number of features acquired for each
data point. The random selection concentrates around one feature per data instance. However  the
long-tailed distribution of the number of features selected by Icebreaker means it tends to concentrate
more features in certain rows to exploit feature relations for predicting target but simultaneously tries
to spread its selection for more exploration. We include imputation results on other UCI data sets in
the Appendix. We ﬁnd that Icebreaker consistently outperforms the baselines by a large margin.

Prediction Task. Figure 4c shows the AUIC curve as the amount of training data increases. The
Icebreaker clearly achieves better results compared to all baselines (Also conﬁrmed by Figure 5). This
shows that it not only yields a more accurate prediction of the targets but also captures correlations
between features and targets. Interestingly  the baseline Row AT performs a little worse than PA-
BELGAM. We argue that before querying a single target variable  Row AT needs to query the whole
row  which induces the costs equivalent to the number of features. Thus  with ﬁxed query budgets 
Row AT will form a relatively small but complete data set. Again  the uncertainty of PA-BELGAM
brings beneﬁts compared to P-VAE with point estimated parameters.
At the early training stage (500 data points  the left panel in Figure 5)  the performance of Row AT is
worse at test time than others when few features are selected. This is due to the fact that obtaining a
complete observed datum is costly. With the budget of 500 feature elements  it can only select 50
fully observed data instances. In contrast  Icebreaker has obtained  within that budget  260 partially
observed instances with different levels of missingness. As more features are selected during the
test  these issues are mitigated  and the performance starts to improve. Further evidence suggests
that  as the training data grows  we can clearly observe a better prediction performance of Row AT at
the early test stage. We also include in the appendix the evaluation of other UCI data sets for active
prediction.
5.2 Recommender System using MovieLens
One common benchmark data set for recommender systems is MovieLens-1M [10]. P-VAE has
obtained state-of-the-art imputation performance in this dataset after training with a sufﬁcient amount
of data [27]. Figure 6a shows the performance on predicting unseen data points in terms of NLL.
Icebreaker shows that with minimum training data  the model has already learned to predict the unseen
data with high accuracy. Given any small amount of data  Icebreaker obtains the best performance at
the given query budget  followed by PA-BELGAM which outperforms P-VAE. The selection pattern
in Figure 6b is similar to the UCI imputation  shown in Figure 6b. We argue this long-tail selection is
important  especially when each row contains many features. The random selection tends to scatter
the choices and is less likely to discover dependencies until the data set grows larger. However  if

7

024681012Feature number0.751.001.251.501.752.002.252.50NLLActive Test curve with training data set 500 pointsIcebreaker+EDDIIcebreaker+RANDRow AT+EDDIRow AT+RANDPA-BELGAM+EDDIPA-BELGAM+RANDPVAE+EDDIPVAE+RAND024681012Feature number0.500.751.001.251.501.752.002.252.50Active Test curve with training data set 1250 points024681012Feature number0.500.751.001.251.501.752.002.252.50Active Test curve with training data set 2250 points(a) Imputation NLL Curve

(b) Long-tailed selection

Figure 6: Performance on MovieLens. Panel (a) shows the imputation NLL vs. the number of
observed movie ratings. Panel (b) shows the distribution of the number of features selected per user.

there are many features per data instance  this accumulation will take a very long time. On the other
hand  the long-tailed selection exploits the features inside certain rows to discover their dependencies
and simultaneously tries to spread out the queries for exploration.
5.3 Mortality Prediction using MIMIC
We apply Icebreaker in a health-care setting using the Medical Information Mart for Intensive
Care (MIMIC III) data set [17]. This is the largest real-world health-care data set in terms of
patient numbers. The goal is to predict mortality based on 17 medical measurements. The data is
pre-processed following [11] and balanced. Full details are available in appendix E.2.1.
The left panel in Figure 7 shows that the Icebreaker outperforms the other baselines signiﬁcantly
in active prediction with higher robustness (smaller std. error). Robustness is crucial in health-care
settings as the cost of unstable model performance is high. As before  Row AT performs worse until
it accumulates sufﬁcient data. Note that without active training feature selection  PA-BELGAM
performs better than P-VAE due to its ability to model uncertainty  which is very useful in this
extremely noisy data set.
To evaluate whether the proposed method can discover valuable information  we plot the accumulated
feature number in the middle panel of Figure 7. The x-axis indicates the total number of observed
data in the training set  and each point on the curve indicates the number of features selected in the
corresponding training set. We see that not only different features have been collected at different
frequencies  but the curve of Glucose is clearly non-linear as well. This indicates that the importance
of different features varies for different training set size. Icebreaker is establishing a sophisticated
feature element acquisition scheme that no heuristic method can currently achieve. The top 3
features are the Glasgow coma scale (GCS). These features have been identiﬁed previously as being
clinically important (e.g. by the IMPACT model [47]. Glucose is also in the IMPACT set. It was not
collected frequently in the early stage  but in the later training phase  more Glucose feature has been
selected. Compared to GCS  Glucose has a highly non-linear relationship with the patient outcome
[36] (or refer to the appendix E.2.1). Icebreaker chooses more informative features with simpler
relationships in the very early iterations. While the learning progresses  Icebreaker is able to identify
these informative features with complex relationships to the target. Additionally  the missing rate for
each feature in the entire data set differs. Capillary reﬁll rate (Cap.) has more than 90% data missing 
much higher than Height. Icebreaker is still able to pick the useful and rarely observed information 
while only choosing a small percent of the irrelevant information at test time. On the right hand side
of Figure 7  we plot the histogram of the initial choices during test-time acquisition. GCS are mostly
selected in the ﬁrst step  as it is the most informative feature.

6 Related Work

Data-wise Active Learning. The goal of active learning is to obtain optimal model performance
with as fewer queries as possible [29  31  43]  where only querying labels are associated with a
cost. One category is based on decision theory [39]  where the acquisition step is to minimize the

8

050000100000150000200000250000Training data set size90010001100120013001400150016001700NLLMovielens Imputation NLLIcebreakerPA-BELGAMPVAE050100150200250Num of picked features102101100101102FrequencyFeature picking distributionIcebreakerRandom050000100000150000200000250000Training data set size90010001100120013001400150016001700NLLMovielens Imputation NLLIcebreakerPA-BELGAMPVAE050100150200250Num of picked features102101100101102FrequencyFeature picking distributionIcebreakerRandomFigure 7: Performance MIMIC experiments. (Left) This ﬁgure shows the predictive AUIC curve as
training data size increases. (Middle) The accumulated feature statistics as active selection progresses
(Right) This indicates the histogram of initial choice during active prediction using EDDI.

loss deﬁned by test tasks after making the query based on observed data. Indeed this coincides
perfectly with the goal of active learning. However  its evaluation can be expensive in practice
[19  59]. Another category is based on information theory  including many previous active learning
approaches [7  26  50]. Another well-known acquisition function is BALD [14]  which is based on
mutual information. Although our acquisition for imputation is also based on mutual information  we
emphasize that the original BALD objective is only applied to scenarios with complete data set. In
another word  those methods aim to only select next data instance to label while assuming that every
feature of each data point is observed. We call this approach instance-wise selection. Obviously 
these methods are not directly applicable to the ice-start problem as they assume that the only cost
comes from acquiring labels.

Feature-wise Active Learning.
Instead of only querying labels  the above active learning idea
can be extended to query features  named as active feature acquisition (AFA). It makes sequential
feature selections in order to improve model performance[5  15  32  40  41  48  49]  which is similar
to our framework. However  they are commonly designed for a speciﬁc application such as clustering
[51] and classiﬁcation [33]  assuming the data are fully observed in the test time. In addition  many
methods have other limitations. For example  only simple linear models can be used [5  40  48] with
non-information-theoretical objective functions [15  32]. None of the above methods can be easily
combined with test time active prediction methods [16  28  44]. Our method enables both training
time and test-time efﬁcient information acquisition in a principled way with a ﬂexible model  which
is of great need in real-life applications.

Cold-start problem Another relevant problem to ice-start is called cold-start problem [30  42].
The key difference between these two scenarios is that cold-start problem targets at the test time
data scarcity after the model has been trained. Taking the recommender system as an example  the
cold-start problem handles the scenario when there are new users incoming with no historical ratings
given a trained recommender. One common strategy is to utilise the meta data (e.g. user proﬁles 
item category) to initialise the latent factors of users/items [35  46  54].

7 Conclusion

In this work  we introduce the ice-start problem where machine learning models are expected to be
deployed where little or no training data has been collected. The costs of collecting new training
datum apply at the level of feature elements. Icebreaker provides an information-theoretical way to
acquire element-wise data for training actively and uses the minimum amount of data for downstream
test tasks like imputation and active prediction. Within the framework of Icebreaker  we propose
PA-BELGAM  a Bayesian deep latent Gaussian model together with a novel inference scheme
that combines amortized inference and SGHMC. This enables fast and accurate posterior inference.
Furthermore  we propose two training time acquisition functions targeted at the imputation and active
prediction tasks. We evaluate Icebreaker on several benchmark data sets  including two real-world
applications. Icebreaker consistently outperforms the baselines. Possible future directions include
taking the mixed-type variables into account and deploying it in a pure streaming environment.

9

050010001500200025003000Training data set size4050607080AUICMIMIC-III AUIC CurveIcebreaker+EDDIPA-BELGAM+EDDIPVAE+EDDIRow AT+EDDI050010001500200025003000Training data set size050100150200250300NumberAccumulated feature numberGCS:eyeGCS:verbalGCS:motorGCS:totalGlucoseHeightpHCap.Cap.Dia.BPIns.OxyGCS:EGCS:MGCS:TGCS:VGlu.HRHei.MBPOxy.SatRes.RSys.BPTempWei.pH050100150200250Initial choice for active prediction Cap.GCS:EGCS:MGCS:TGCS:VGlu.Hei.pHReferences

[1] C. Andrieu  N. De Freitas  A. Doucet  and M. I. Jordan. An introduction to MCMC for machine

learning. Machine learning  50(1-2):5–43  2003.

[2] Y. Baram  R. E. Yaniv  and K. Luz. Online choice of active learning algorithms. Journal of

Machine Learning Research  5(Mar):255–291  2004.

[3] M. J. Beal et al. Variational algorithms for approximate Bayesian inference. 2003.

[4] J. M. Bernardo. Expected information as expected utility. The Annals of Statistics  pages

686–690  1979.

[5] S. Chakraborty  J. Zhou  V. Balasubramanian  S. Panchanathan  I. Davidson  and J. Ye. Active
matrix completion. In 2013 IEEE 13th International Conference on Data Mining  pages 81–90.
IEEE  2013.

[6] C. Chen  D. Carlson  Z. Gan  C. Li  and L. Carin. Bridging the gap between stochastic gradient
MCMC and stochastic optimization. In Artiﬁcial Intelligence and Statistics  pages 1051–1060 
2016.

[7] T. M. Cover and J. A. Thomas. Elements of information theory. John Wiley & Sons  2012.

[8] D. Dheeru and E. Karra Taniskidou. UCI machine learning repository  2017.

[9] Y. Gal  R. Islam  and Z. Ghahramani. Deep bayesian active learning with image data. In
Proceedings of the 34th International Conference on Machine Learning-Volume 70  pages
1183–1192. JMLR. org  2017.

[10] F. M. Harper and J. A. Konstan. The Movielens datasets: History and context. Acm transactions

on interactive intelligent systems (tiis)  5(4):19  2016.

[11] H. Harutyunyan  H. Khachatrian  D. C. Kale  and A. Galstyan. Multitask learning and bench-

marking with clinical time series data. arXiv preprint arXiv:1703.07771  2017.

[12] M. Havasi  J. M. Hernández-Lobato  and J. J. Murillo-Fuentes. Inference in deep gaussian pro-
cesses using stochastic gradient Hamiltonian Monte Carlo. In Advances in Neural Information
Processing Systems  pages 7506–7516  2018.

[13] N. Houlsby  J. M. Hernández-Lobato  and Z. Ghahramani. Cold-start active learning with robust
ordinal matrix factorization. In International Conference on Machine Learning  pages 766–774 
2014.

[14] N. Houlsby  F. Huszár  Z. Ghahramani  and M. Lengyel. Bayesian active learning for classiﬁca-

tion and preference learning. arXiv preprint arXiv:1112.5745  2011.

[15] S.-J. Huang  M. Xu  M.-K. Xie  M. Sugiyama  G. Niu  and S. Chen. Active feature acquisition

with supervised matrix completion. arXiv preprint arXiv:1802.05380  2018.

[16] J. Janisch  T. Pevn`y  and V. Lis`y. Classiﬁcation with costly features using deep reinforcement

learning. arXiv preprint arXiv:1711.07364  2017.

[17] A. E. Johnson  T. J. Pollard  L. Shen  H. L. Li-wei  M. Feng  M. Ghassemi  B. Moody 
P. Szolovits  L. A. Celi  and R. G. Mark. MIMIC-III  a freely accessible critical care database.
Scientiﬁc Data  3:160035  2016.

[18] M. I. Jordan  Z. Ghahramani  T. S. Jaakkola  and L. K. Saul. An introduction to variational

methods for graphical models. Machine learning  37(2):183–233  1999.

[19] A. Kapoor  E. Horvitz  and S. Basu. Selective supervision: Guiding supervised learning with

decision-theoretic active learning.

[20] D. P. Kingma and M. Welling. Auto-encoding variational Bayes. In International Conference

on Learning Representation  2014.

10

[21] A. Krause and E. Horvitz. A utility-theoretic approach to privacy in online services. Journal of

Artiﬁcial Intelligence Research  39:633–662  2010.

[22] J. Krumm and E. Horvitz. Trafﬁc updates: Saying a lot while revealing a little. 2019.

[23] Y. Lewenberg  Y. Bachrach  U. Paquet  and J. S. Rosenschein. Knowing what to ask: A Bayesian

active learning approach to the surveying problem. In AAAI  pages 1396–1402  2017.

[24] C. Li  C. Chen  D. Carlson  and L. Carin. Preconditioned stochastic gradient Langevin dynamics

for deep neural networks. In Thirtieth AAAI Conference on Artiﬁcial Intelligence  2016.

[25] Y. Li. Approximate Inference: New Visions. PhD thesis  University of Cambridge  2018.

[26] D. V. Lindley. On a measure of the information provided by an experiment. The Annals of

Mathematical Statistics  pages 986–1005  1956.

[27] C. Ma  W. Gong  J. M. Hernández-Lobato  N. Koenigstein  S. Nowozin  and C. Zhang. Partial
VAE for hybrid recommender system. In NIPS Workshop on Bayesian Deep Learning  2018.

[28] C. Ma  S. Tschiatschek  K. Palla  J. M. H. Lobato  S. Nowozin  and C. Zhang. EDDI: Ef-
ﬁcient dynamic discovery of high-value information with partial vae. In Proceedings of the
International Conference on Machine Learning  2019.

[29] D. J. MacKay. Information-based objective functions for active data selection. Neural computa-

tion  4(4):590–604  1992.

[30] D. Maltz and K. Ehrlich. Pointing the way: active collaborative ﬁltering.

[31] A. K. McCallumzy and K. Nigamy. Employing EM and pool-based active learning for text
classiﬁcation. In International Conference on Machine Learning  pages 359–367. Citeseer 
1998.

[32] P. Melville  M. Saar-Tsechansky  F. Provost  and R. Mooney. Active feature-value acquisition
for classiﬁer induction. In International Conference on Data Mining  pages 483–486. IEEE 
2004.

[33] P. Melville  M. Saar-Tsechansky  F. Provost  and R. Mooney. An expected utility approach
to active feature-value acquisition. In Fifth IEEE International Conference on Data Mining
(ICDM’05)  pages 4–pp. IEEE  2005.

[34] A. Nazabal  P. M. Olmos  Z. Ghahramani  and I. Valera. Handling incomplete heterogeneous

data using VAEs. arXiv preprint arXiv:1807.03653  2018.

[35] A. K. Pandey and D. S. Rajpoot. Resolving cold start problem in recommendation system
using demographic approach. In 2016 International Conference on Signal Processing and
Communication (ICSC)  pages 213–218. IEEE  2016.

[36] A.-L. Popkes  H. Overweg  A. Ercole  Y. Li  J. M. Hernández-Lobato  Y. Zaykov  and C. Zhang.
Interpretable outcome prediction with sparse Bayesian neural networks in intensive care. arXiv
preprint arXiv:1905.02599  2019.

[37] C. R. Qi  H. Su  K. Mo  and L. J. Guibas. Pointnet: Deep learning on point sets for 3D
classiﬁcation and segmentation. In Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition  pages 652–660  2017.

[38] D. J. Rezende  S. Mohamed  and D. Wierstra. Stochastic backpropagation and approximate
inference in deep generative models. In Interantional Conference on Machine Learning  2014.

[39] N. Roy and A. McCallum. Toward optimal active learning through monte carlo estimation of

error reduction.

[40] N. Ruchansky  M. Crovella  and E. Terzi. Matrix completion with queries. In Proceedings of
the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining 
pages 1025–1034. ACM  2015.

11

[41] M. Saar-Tsechansky  P. Melville  and F. Provost. Active feature-value acquisition. Management

Science  55(4):664–684  2009.

[42] A. I. Schein  A. Popescul  L. H. Ungar  and D. M. Pennock. Methods and metrics for cold-start
recommendations. In Proceedings of the 25th annual international ACM SIGIR conference on
Research and development in information retrieval  pages 253–260. ACM  2002.

[43] B. Settles. Active learning. Synthesis Lectures on Artiﬁcial Intelligence and Machine Learning 

6(1):1–114  2012.

[44] H. Shim  S. J. Hwang  and E. Yang. Joint active feature acquisition and classiﬁcation with

variable-size set encoding. In Advances in Neural Information Processing Systems  2018.

[45] K. Sohn  H. Lee  and X. Yan. Learning structured output representation using deep conditional
generative models. In Advances in neural information processing systems  pages 3483–3491 
2015.

[46] D. Stern  R. Herbrich  and T. Graepel. Matchbox: Large scale bayesian recommendations. In

International World Wide Web Conference  2009.

[47] E. W. Steyerberg  N. Mushkudiani  P. Perel  I. Butcher  J. Lu  G. S. McHugh  G. D. Murray 
A. Marmarou  I. Roberts  J. D. F. Habbema  et al. Predicting outcome after traumatic brain
injury: development and international validation of prognostic scores based on admission
characteristics. PLoS medicine  5(8):e165  2008.

[48] D. J. Sutherland  B. Póczos  and J. Schneider. Active learning and search on low-rank matrices.
In Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery
and data mining  pages 212–220. ACM  2013.

[49] M. Thahir  T. Sharma  and M. K. Ganapathiraju. An efﬁcient heuristic method for active feature
acquisition and its application to protein-protein interaction prediction. In BMC proceedings 
volume 6  page S2. BioMed Central  2012.

[50] S. Tong and D. Koller. Support vector machine active learning with applications to text

classiﬁcation. Journal of machine learning research  2(Nov):45–66  2001.

[51] D. Vu  P. Melville  M. Bilenko  and M. Saar-Tsechansky. Intelligent information acquisition for

improved clustering.

[52] M. J. Wainwright  M. I. Jordan  et al. Graphical models  exponential families  and variational

inference. Foundations and Trends R(cid:13) in Machine Learning  1(1–2):1–305  2008.

[53] G. C. Wei and M. A. Tanner. A Monte Carlo implementation of the EM algorithm and the
poor man’s data augmentation algorithms. Journal of the American statistical Association 
85(411):699–704  1990.

[54] J. Xu  Y. Yao  H. Tong  X. Tao  and J. Lu. Ice-breaking: mitigating cold-start recommendation
problem by rating comparison. In Twenty-Fourth International Joint Conference on Artiﬁcial
Intelligence  2015.

[55] M. Zaheer  S. Kottur  S. Ravanbakhsh  B. Poczos  R. R. Salakhutdinov  and A. J. Smola. Deep

sets. In Advances in Neural Information Processing Systems  pages 3391–3401  2017.

[56] S. Zannone  J. M. Hernández-Lobato  C. Zhang  and K. Palla. Odin: Optimal discovery of
high-value information using model-based deep reinforcement learning. In ICML Real-world
Sequential Decision Making Workshop  2019.

[57] C. Zhang  J. Butepage  H. Kjellstrom  and S. Mandt. Advances in variational inference. IEEE

transactions on pattern analysis and machine intelligence  2018.

[58] J.-J. Zhu and J. Bento. Generative adversarial active learning. arXiv preprint arXiv:1702.07956 

2017.

[59] X. Zhu  J. Lafferty  and Z. Ghahramani. Combining active learning and semi-supervised learning

using gaussian ﬁelds and harmonic functions.

12

,Wenbo Gong
Sebastian Tschiatschek
Sebastian Nowozin
Richard Turner
José Miguel Hernández-Lobato
Cheng Zhang