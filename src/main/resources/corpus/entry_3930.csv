2019,On The Classification-Distortion-Perception Tradeoff,Signal degradation is ubiquitous  and computational restoration of degraded signal has been investigated for many years. Recently  it is reported that the capability of signal restoration is fundamentally limited by the so-called perception-distortion tradeoff  i.e. the distortion and the perceptual difference between the restored signal and the ideal "original" signal cannot be made both minimal simultaneously. Distortion corresponds to signal fidelity and perceptual difference corresponds to perceptual naturalness  both of which are important metrics in practice. Besides  there is another dimension worthy of consideration--the semantic quality of the restored signal  i.e. the utility of the signal for recognition purpose. In this paper  we extend the previous perception-distortion tradeoff to the case of classification-distortion-perception (CDP) tradeoff  where we introduced the classification error rate of the restored signal in addition to distortion and perceptual difference. In particular  we consider the classification error rate achieved on the restored signal using a predefined classifier as a representative metric for semantic quality. We rigorously prove the existence of the CDP tradeoff  i.e. the distortion  perceptual difference  and classification error rate cannot be made all minimal simultaneously. We also provide both simulation and experimental results to showcase the CDP tradeoff. Our findings can be useful especially for computer vision research where some low-level vision tasks (signal restoration) serve for high-level vision tasks (visual understanding). Our code and models have been published.,On The ClassiÔ¨Åcation-Distortion-Perception Tradeoff

Dong Liu  Haochen Zhang  Zhiwei Xiong

University of Science and Technology of China  Hefei 230027  China

dongeliu@ustc.edu.cn

Abstract

Signal degradation is ubiquitous  and computational restoration of degraded signal
has been investigated for many years. Recently  it is reported that the capability of
signal restoration is fundamentally limited by the so-called perception-distortion
tradeoff  i.e.
the distortion and the perceptual difference between the restored
signal and the ideal ‚Äúoriginal‚Äù signal cannot be made both minimal simultaneously.
Distortion corresponds to signal Ô¨Ådelity and perceptual difference corresponds to
perceptual naturalness  both of which are important metrics in practice. Besides 
there is another dimension worthy of consideration‚Äìthe semantic quality of the
restored signal  i.e. the utility of the signal for recognition purpose. In this paper 
we extend the previous perception-distortion tradeoff to the case of classiÔ¨Åcation-
distortion-perception (CDP) tradeoff  where we introduced the classiÔ¨Åcation error
rate of the restored signal in addition to distortion and perceptual difference. In
particular  we consider the classiÔ¨Åcation error rate achieved on the restored signal
using a predeÔ¨Åned classiÔ¨Åer as a representative metric for semantic quality. We
rigorously prove the existence of the CDP tradeoff  i.e. the distortion  perceptual
difference  and classiÔ¨Åcation error rate cannot be made all minimal simultaneously.
We also provide both simulation and experimental results to showcase the CDP
tradeoff. Our Ô¨Åndings can be useful especially for computer vision research where
some low-level vision tasks (signal restoration) serve for high-level vision tasks
(visual understanding). Our code and models have been published.

1

Introduction

Signal degradation refers to the corruption of the signal due to many different reasons such as
interference and the blend of interested signal and uninterested signal or noise  which is observed
ubiquitously in practical information systems. The cause of signal degradation may be physical
factors  such as the imperfectness of data acquisition devices and the noise in data transmission
medium; or may be artiÔ¨Åcial factors  such as the lossy data compression and the transmission of
multiple sources over the same medium at the same time. In addition  in cases where we want to
enhance signal  we may assume the signal to have been somehow ‚Äúdegraded.‚Äù For example  if we
want to enhance the resolution of an image  we assume the image is a degraded version of an ideal
‚Äúoriginal‚Äù image that has high resolution [6].
To tackle signal degradation or to fulÔ¨Åll signal enhancement  computational restoration of degraded
signal has been investigated for many years. There are various signal restoration tasks corresponding
to different degradation reasons. Taken image as example  image denoising [23]  image deblurring
[17]  single image super-resolution [6]  image contrast enhancement [7]  image compression artifact
removal [5]  image inpainting [22]  . . .   all belong to image restoration tasks.
Different restoration tasks have various objectives. Some tasks may be keen to recover the ‚Äúoriginal‚Äù
signal as faithfully as possible  like image denoising is to recover the noise-free image  compression
artifact removal is to recover the uncompressed image. Some other tasks may concern more about
the perceptual quality of the restored signal  like image super-resolution is to produce image details

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

to make the enhanced image look like having ‚Äúhigh-resolution ‚Äù image inpainting is to generate a
complete image that looks ‚Äúnatural.‚Äù Yet some other tasks may serve for recognition or understanding
purpose: for one example  an image containing a car license plate may have blur  and image deblurring
can achieve a less blurred image so as to recognize the license plate [13]; for another example  an
image taken at night is difÔ¨Åcult to identify  and image contrast enhancement can produce a more
naturally looking image that is better understood [10]. Recent years have witnessed more and more
efforts about the last category [16  19].
Given the different objectives  it is apparent that a signal restoration method designed for one speciÔ¨Åc
task shall be evaluated with the speciÔ¨Åc metric that corresponds to the task‚Äôs objective. Indeed  the
aforementioned objectives correspond to three groups of evaluation metrics:

1. Signal Ô¨Ådelity metrics that evaluate how similar is the restored signal to the ‚Äúoriginal‚Äù signal.
These include all the full-reference quality metrics  such as the well-known mean-squared-
error (MSE) and its counterpart peak signal-to-noise ratio (PSNR)  the structural similarity
(SSIM) [21]  and the difference in features extracted from original signal and restored signal
[8]  to name a few.

2. Perceptual naturalness metrics that evaluate how ‚Äúnatural‚Äù is the restored signal with
respect to human perception. These are usually known as no-reference quality metrics
[14  15]. Recently  the popularity of generative adversarial network (GAN) has motivated a
mathematical formulation of perceptual naturalness [3].

3. Semantic quality metrics that evaluate how ‚Äúuseful‚Äù is the restored signal in the sense that it
better serves for the following semantic-related analyses. For example  whether a restored
sample can be correctly classiÔ¨Åed is a measure of the semantic quality. There are only a few
studies about semantic quality assessment methods [12].

It is worth noting that signal Ô¨Ådelity metrics have dominated in the research of signal restoration.
However  is one method optimized for signal Ô¨Ådelity also optimal for perceptual naturalness or
semantic quality? This question has been overlooked for a long while until recently. Blau and
Michaeli considered signal Ô¨Ådelity and perceptual naturalness  and concluded that optimizing for the
two metrics can be contradictory [3]. Indeed  they provided a rigorous proof of the existence of the
perception-distortion tradeoff: with distortion representing signal Ô¨Ådelity and perceptual difference
representing perceptual naturalness  one signal restoration method cannot achieve both low distortion
and low perceptual difference up to a bound. This conclusion reveals the fundamental limit of
the capability of signal restoration  and quickly inspires the investigation of perceptual naturalness
metrics in different tasks [2  20].
Following the work of the perception-distortion tradeoff  in this paper  we aim to consider the three
groups of metrics jointly  i.e. we want to study the relation between signal Ô¨Ådelity  perceptual
naturalness  and semantic quality  in the context of signal restoration. In particular  we consider
classiÔ¨Åcation error rate as a representative of semantic quality metrics  because classiÔ¨Åcation is
the most fundamental semantic-related analysis. We adopt the classiÔ¨Åcation error rate achieved on
the restored signal using a predeÔ¨Åned classiÔ¨Åer as the third dimension in addition to distortion and
perceptual difference. We provide a rigorous proof of the existence of the classiÔ¨Åcation-distortion-
perception (CDP) tradeoff  i.e. the distortion  perceptual difference  and classiÔ¨Åcation error rate
cannot be made all minimal simultaneously. We also provide both simulation and experimental
results to showcase the CDP tradeoff. Our code and models are published at https://github.com/
AlanZhang1995/CDP-Tradeoff.
To the best of our knowledge  this paper is the Ô¨Årst to reveal the fundamental tradeoff between the
three kinds of quality metrics: signal Ô¨Ådelity  perceptual naturalness  and semantic quality  in the
context of signal restoration. Our results imply that  if a signal restoration method is meant to serve
for recognition or understanding purpose  then the method is better optimized for semantic quality
instead of signal Ô¨Ådelity or perceptual naturalness. This is in contrast to most of the existing practices.
It then calls for more investigation of semantic quality metrics.

2 Problem Formulation
Consider the process: X ‚Üí Y ‚Üí ÀÜX  where X denotes the ideal ‚Äúoriginal‚Äù signal  Y denotes the
degraded signal  and ÀÜX denotes the restored signal. We consider X  Y   and ÀÜX each as a discrete

2

random variable. The cases of continuous random variables can be deduced in a similar manner  and
are omitted hereafter. The probability mass function of X is denoted by pX (x). The degradation
model is denoted by PY |X  which is characterized by a conditional mass function p(y|x). The
restoration method is then denoted by P ÀÜX|Y and characterized by p(ÀÜx|y).

2.1 Distortion  Perceptual Difference  and ClassiÔ¨Åcation Error Rate

There are different categories of quality metrics to evaluate the signal restoration methods. For the
Ô¨Årst category  signal Ô¨Ådelity  we usually adopt distortion that is deÔ¨Åned precisely as the expectation
of a given bivariate function  i.e.

Distortion := E[‚àÜ(X  ÀÜX)]

(1)
where E is to take expectation over the joint distribution pX  ÀÜX  ‚àÜ(¬∑ ¬∑) : X √ó ÀÜX ‚Üí R+ is a given
function to measure the difference between the original and the restored samples. This deÔ¨Ånition is
corresponding to the common practice of using various forms of full-reference loss functions  e.g.
MSE  in the signal restoration tasks. The deÔ¨Ånition measures the dissimilarity  i.e. the lower the
better  while some popular quality metrics such as PSNR and SSIM measure similarity.
For the second category  perceptual naturalness  it has been proved in [3] that the perceptual quality
evaluated by human when performing a real-or-fake test is indeed equivalent to the total-variation
(TV) distance between the distribution of the original signal and that of the restored signal. Following
[3]  we deÔ¨Åne perceptual difference as

Perceptual Difference := d(pX   p ÀÜX )

(2)
where d(¬∑ ¬∑) is a function to measure the difference between two probability mass functions  such as
the TV distance and the Kullback-Leibler (KL) distance. Perception is also the lower the better.
For the third category  semantic quality  we will focus on the classiÔ¨Åcation error rate achieved on the
restored signal using a predeÔ¨Åned classiÔ¨Åer in this paper. We will discuss the case of classifying the
signal into two categories  and note that extension to multiple categories is straightforward.
We assume each sample of the original signal belongs to one of two classes: œâ1 or œâ2. The a priori
probabilities and the conditional mass functions are assumed to be known as P1  P2 = 1 ‚àí P1 and
pX1(x)  pX2(x)  respectively. In other words  X follows a two-component mixture model: pX (x) =
P1pX1(x) + P2pX2(x). Accordingly  Y follows the model: pY (y) = P1pY 1(y) + P2pY 2(y)  and
ÀÜX follows the model: p ÀÜX (ÀÜx) = P1p ÀÜX1(ÀÜx) + P2p ÀÜX2(ÀÜx)  where

(cid:88)
(cid:88)

x‚ààX

y‚ààY

pY i(y) =

p ÀÜXi(ÀÜx) =

p(y|x)pXi(x)  i = 1  2

p(ÀÜx|y)pY i(y) =

p(ÀÜx|y)p(y|x)pXi(x)  i = 1  2

(3)

(4)

(5)

(cid:88)
(cid:88)
(cid:26)œâ1 

x

y

if t ‚àà R
œâ2  otherwise

(cid:88)

ÀÜx‚ààR

A binary classiÔ¨Åer can be denoted by

c(t) = c(t|R) =

If we apply this classiÔ¨Åer on the restored signal ÀÜX  we shall achieve an error rate

ClassiÔ¨Åcation Error Rate := Œµ( ÀÜX|c) = Œµ( ÀÜX|R) = P2

p ÀÜX2(ÀÜx) + P1

p ÀÜX1(ÀÜx)

(6)

(cid:88)

ÀÜx /‚ààR

2.2 The CDP Function

We are now ready to deÔ¨Åne the CDP function  which is the focus of our study.
DeÔ¨Ånition 1. The classiÔ¨Åcation-distortion-perception (CDP) function is

C(D  P ) = min
P ÀÜX|Y

Œµ( ÀÜX|c0)  subject to E[‚àÜ(X  ÀÜX)] ‚â§ D  d(pX   p ÀÜX ) ‚â§ P

(7)

where c0 = c(¬∑|R0) is a predeÔ¨Åned binary classiÔ¨Åer.

3

Figure 1: A toy example to showcase the CDP function. See text for details.

The CDP function characterizes how well a signal restoration method (P ÀÜX|Y ) can perform  if it is
constrained to have a low distortion (less than D) and a low perceptual difference (less than P ). Note
that if D = ‚àû  P = ‚àû  then the restoration method is optimized purely for lowering error rate  and
thus the CDP function reaches its minimum. By deÔ¨Åning the CDP function  we are interested to know
whether a constrained optimization can perform as well as an unconstrained one. This is because
the optimization for distortion has been studied extensively  and if the optimization for distortion or
perception also leads to the optimization for classiÔ¨Åcation  then we are done. However  this is not the
case  as we will prove.
Another issue is about the predeÔ¨Åned classiÔ¨Åer in the deÔ¨Ånition of the CDP function. One may be
curious to know whether it is possible to adjust the classiÔ¨Åer itself to achieve a lower error rate: this is
surely possible. However  there are a practical difÔ¨Åculty to train the optimal classiÔ¨Åer for the restored
signal  since the distribution of the restored signal is dependent on the restoration method that is to be
decided. Next  we may ask whether it is practical to adjust the restoration method and the classiÔ¨Åer
simultaneously. However  this is not necessary  because we can prove that the optimal classiÔ¨Åer for
ÀÜX cannot outperform the optimal classiÔ¨Åer for Y (see the supplementary for the proof ). That says 
we do not need to perform signal restoration if we can train the optimal classiÔ¨Åer for the degraded
signal. But this is another practical difÔ¨Åculty: the distribution of the signal to be restored is often
unknown (called blind restoration)  so it is not easy to train the optimal classiÔ¨Åer for it. In summary 
if dealing with blind restoration  i.e. the distribution of the degraded signal is unknown  then it is
difÔ¨Åcult to achieve the optimal classiÔ¨Åer for either degraded or restored signal  so using a predeÔ¨Åned
classiÔ¨Åer is a more practical choice. If dealing with non-blind restoration  i.e. the distribution of
the degraded signal is known  then we can achieve the optimal classiÔ¨Åer for the degraded signal 
and it is not necessary to perform signal restoration prior to classiÔ¨Åcation as it will not improve the
classiÔ¨Åcation performance. In this paper  we consider the case of blind restoration  and we leave the
case of non-blind restoration as our future work.

2.3 Toy Example

To showcase the characteristic of the CDP function  we conduct simulations with a toy example.
As shown in Figure 1  the original signal follows a two-component Gaussian mixture model: P1 =
0.7  P2 = 0.3  pX1(x) = N (‚àí1  1)  pX2(x) = N (1  1). The signal is corrupted by additive white
Gaussian noise: Y = X + N  where N ‚àº N (0  1). The denoising method is linear: ÀÜX = aY where
a is an adjustable parameter. For example  the restored signal with a = 0.8 is depicted in Figure 1 (b).
We use the binary classiÔ¨Åer that is the optimal for the original signal to evaluate error rate. In addition 
we use MSE to evaluate distortion  and use the KL distance to evaluate perception. Under these
settings  we can derive closed-form functions of MSE and error rate with respect to the parameter a
(see the supplementary for details). For the KL distance  we do not have closed-form expression so
we perform numerical calculation. We then use numerical methods to calculate the CDP function and
depict the function in Figure 2.
First  the CDP function is monotonically non-increasing  i.e.
the minimal attainable error rate
decreases as the maximal allowable distortion and perception increase. It implies that if one wants to
have a restoration method for better classiÔ¨Åcation performance  it must come at the cost of higher
distortion  lower perceptual quality  or both. Second  the CDP function is convex  indicating that

4

(a) original signal ùëã(b) restored signal ‡∑°ùëã(c) MSE/KL Distance/Error Rate functionFigure 2: (a) The CDP function for the toy example where we can Ô¨Ånd the minimal attainable error
rate (C) decreases as the maximal allowable MSE (D) and KL divergence (P) increase. (b) ProÔ¨Åles
of the CDP function at different P values and D values respectively  from which we can Ô¨Ånd the
function is convex.

if D (P ) is smaller  the error rate increases faster. Thus  minimizing D (P ) can be quite harmful
for the classiÔ¨Åcation performance. Third  from Figure 2 (b)  we observe that when D is small  C is
invariant with P   and when D is large  C is invariant with D. In this example  the feasible domain of
P ÀÜX|Y is fully determined by the feasible set of a  which is indeed the intersection of the feasible set
of a deÔ¨Åned by D and that deÔ¨Åned by P . If D is small  the feasible set deÔ¨Åned by D is also small
and determines the intersection. If D is large  the feasible set is also large and has no effect on the
intersection. Similarly  from Figure 2 (b)  we observe that when P is small  C is invariant with D 
and when P is large  C is invariant with P . It can be interpreted similarly. Last but not the least  note
that the areas where D and P are both small are not present in the CDP function  which results from
the perception-distortion tradeoff [3].
In more general situations  it is impossible to solve Eq. (7) analytically. But some properties of the
CDP function are still valid  as shown in the following section.

3 The CDP Tradeoff
Theorem 1. Considering the CDP function (7)  if d(¬∑  q) is convex in q  then C(D  P ) is

1. monotonically non-increasing 

2. convex in D and P .

Proof. For the Ô¨Årst point  simply note that when increasing D or P   the feasible domain of P ÀÜX|Y
is enlarged; as C(D  P ) is the minimal value of Œµ( ÀÜX|c0) over the feasible domain  and the feasible
domain is enlarged  the minimal value will not increase.
For the second point  it is equivalent to prove:

ŒªC(D1  P1) + (1 ‚àí Œª)C(D2  P2) ‚â• C(ŒªD1 + (1 ‚àí Œª)D2  ŒªP1 + (1 ‚àí Œª)P2)

(8)
for any Œª ‚àà [0  1]. First  let ¬µ(ÀÜx|y) (resp. ŒΩ(ÀÜx|y)) denote the optimal restoration method under
constraint (D1  P1) (resp. (D2  P2))  and ÀÜX¬µ (resp. ÀÜXŒΩ) be the restored signal  i.e.

Œµ( ÀÜX¬µ|c0) = min

P ÀÜX|Y

Œµ( ÀÜX|c0)  subject to E[‚àÜ(X  ÀÜX)] ‚â§ D1  d(pX   p ÀÜX ) ‚â§ P1

(9)

5

(a)(b)Œµ( ÀÜXŒΩ|c0) = min

P ÀÜX|Y

Œµ( ÀÜX|c0)  subject to E[‚àÜ(X  ÀÜX)] ‚â§ D2  d(pX   p ÀÜX ) ‚â§ P2

(10)

Then the left hand side of (8) becomes

ŒªŒµ( ÀÜX¬µ|c0) + (1 ‚àí Œª)Œµ( ÀÜXŒΩ|c0) = Œµ( ÀÜXŒª|c0)

(11)
where ÀÜXŒª denotes the restored signal corresponding to pŒª(ÀÜx|y) = Œª¬µ(ÀÜx|y) + (1 ‚àí Œª)ŒΩ(ÀÜx|y) (see the
supplementary for the proof of this equation). Let DŒª = E[‚àÜ(X  ÀÜXŒª)]  PŒª = d(pX   p ÀÜXŒª
)  then by
deÔ¨Ånition

(cid:110)
Œµ( ÀÜX|c0) : E[‚àÜ(X  ÀÜX)] ‚â§ DŒª  d(pX   p ÀÜX ) ‚â§ PŒª

Œµ( ÀÜXŒª|c0) ‚â• min

P ÀÜX|Y

(cid:111)

= C(DŒª  PŒª)

(12)

Next  as d(¬∑ ¬∑) in (7) is convex in its second argument  we have
+ (1 ‚àí Œª)p ÀÜXŒΩ
)
) + (1 ‚àí Œª)d(pX   p ÀÜXŒΩ

PŒª = d(pX   Œªp ÀÜX¬µ
‚â§ Œªd(pX   p ÀÜX¬µ
‚â§ ŒªP1 + (1 ‚àí Œª)P2

)

the last inequality is due to (9) and (10). Similarly  we have

DŒª = E[‚àÜ(X  ÀÜXŒª)] = EY E[‚àÜ(X  ÀÜXŒª)|Y ]

= EY [ŒªE[‚àÜ(X  ÀÜX¬µ)|Y ] + (1 ‚àí Œª)E[‚àÜ(X  ÀÜXŒΩ)|Y ]]
= ŒªE[‚àÜ(X  ÀÜX¬µ)] + (1 ‚àí Œª)E[‚àÜ(X  ÀÜXŒΩ)]
‚â§ ŒªD1 + (1 ‚àí Œª)D2

(13)

(14)

the last inequality is again due to (9) and (10). Finally  note that C(D  P ) is non-increasing with
respect to D and P  

C(DŒª  PŒª) ‚â• C(ŒªD1 + (1 ‚àí Œª)D2  ŒªP1 + (1 ‚àí Œª)P2)

(15)

Combining (11)  (12)  and (15)  we have (8).

Discussion. Note that the property of the CDP function is quite similar to that of the perception-
distortion function [3]  and the proof is similar  too. The theorem has assumed the convexity of the
function d(¬∑ ¬∑)  which is satisÔ¨Åed by a large number of commonly used functions  including any
f-divergence (e.g. KL  TV  Hellinger) and the R√©nyi divergence [4  18]. The theorem does not require
any assumption on the function ‚àÜ(¬∑ ¬∑)  implying that the CDP tradeoff exists for any distortion metric 
including MSE/PSNR  SSIM  and the so-called feature losses which are calculated between deep
features [8]  and so on. The convexity of C(D  P ) implies the tradeoff is stronger at the low distortion
or low perception regimes. In these regimes  any small improvement in distortion/perception achieved
by a restoration algorithm  must be accompanied by a large loss of classiÔ¨Åcation accuracy. Similarly 
any small improvement in classiÔ¨Åcation accuracy achieved by an algorithm whose error rate is already
small  must be accompanied by a large increase of distortion and/or perceptual difference.

4 Experiments

In this section  we want to demonstrate the CDP
tradeoff by real-world datasets and realistic set-
tings. We use the MNIST handwritten digit
recognition dataset [11] and the CIFAR-10 im-
age recognition dataset [9]. The restoration
tasks we considered are denoising and super-
resolution (SR)  and we use trained networks to
perform the tasks. Since our intention is not to
study the restoration method itself  we design
simple denoising and SR networks inspired by
the successful DnCNN [23] and SRCNN [6] 

Table 1: Experimental conÔ¨Ågurations. CNN-2 and
CNN-2‚Äô have the same network structure but differ
in input image size (28√ó28 and 32√ó32).

Task

ClassiÔ¨Åer
Denoising Logistic
Denoising CNN-1
Denoising CNN-2
CNN-1
CNN-2‚Äô

SR
SR

Dataset
Exp-1 MNIST
Exp-2 MNIST
Exp-3 MNIST
Exp-4 MNIST
Exp-5 CIFAR-10

6

Figure 3: ProÔ¨Åles of the CDP functions. From top to bottom: Exp-1  Exp-2  and Exp-4. Better
classiÔ¨Åcation performance always comes at the cost of higher distortion and worse perceptual quality.

respectively. Experimental conÔ¨Ågurations are summarized in Table 1. More details can be found in
the supplementary.
In order to showcase the CDP tradeoff  we train a restoration (denoising or SR) network with
a combination of three loss functions that correspond to distortion  perceptual difference  and
classiÔ¨Åcation error rate. In short  the entire loss function is

(cid:96)restoration = Œ±(cid:96)M SE + Œ≤(cid:96)adv + Œ≥(cid:96)CE

(16)
where Œ±  Œ≤  Œ≥ are weights. The Ô¨Årst term is MSE loss to represent distortion  which is widely used in
image restoration research. The second term is an adversarial loss  minimizing which is to ensure
perceptual quality as suggested in [3]. Here we adopt the Wasserstein GAN [1] and the adversarial
loss (cid:96)adv is proportional to the Wasserstein distance dW (pX   p ÀÜX ). Note that in the Wasserstein
GAN  the discriminator loss is indeed an estimate of the Wasserstein distance  which can be used to
assess the perceptual quality of the restored images quantitatively. The third term is cross entropy 
corresponding to classiÔ¨Åcation error rate. To demonstrate that the CDP tradeoff is generic  we use
multiple classiÔ¨Åers in experiments: the Ô¨Årst is a simple logistic regression  and the others are CNN-
based classiÔ¨Åers. For each classiÔ¨Åer  we pretrain it on the clean (i.e. noise-free and original-resolution)
training data  and use it to evaluate cross entropy when training the denoising or SR network.
For Exp-1  Exp-2  and Exp-3  noisy images are generated by adding Gaussian noise N (0  1) onto
the MNIST images. Then  the noisy training data as well as their clean version are used to train the
denoiser  with different combinations of (Œ±  Œ≤  Œ≥). After training we use the denoiser to process the
noisy MNIST test data  and calculate D (MSE)  P (Wasserstein distance using the discriminator)  and
C (using the pretrained classiÔ¨Åer). For Exp-4  MNIST images are down-sampled by a factor of 6 and
then interpolated to original resolution. Interpolated images and their clean version are used to train
the SR network. For Exp-5  CIFAR-10 images are down-sampled by a factor of 3.

7

(a) (b)(c)Figure 4: Visual results of Exp-2 with different combinations of loss weights. As Œ≥ increases  the
perceptual quality becomes worse but the restored images are easier to recognize  see for example the
numbers ‚Äò5‚Äô and ‚Äò2‚Äô highlighted by red boxes.

Fig. 3 presents the results of Exp-1/2/4  where we plot each pair of (C  D  P) separately. For example
in (a)  we plot the relation of P and D and using color to denote C. We also draw curves to connect
the points with approximately the same C. As can be observed  when C is sufÔ¨Åciently large  there is a
tradeoff between P and D  which has been characterized in [3]. Once C is smaller  the P-D curve
elevates  indicating that better classiÔ¨Åcation performance comes at the cost of higher distortion and/or
worse perceptual quality. Similarly in (b) and (c)  we can observe the relations of C-P and C-D and
all of them are convex as the theorem forecasts. Moreover  comparing Exp-1 and Exp-2 that use
different classiÔ¨Åers  although the error rates differ much in number  the trends of the CDP tradeoff
are similar. Please check the supplementary for more results.
Fig. 4 presents some results of Exp-2 for visual inspection. As observed  the visual quality of
denoised images in general increases along with the weight Œ≤. Given the same Œ≤  when increasing
Œ≥  the visual quality decreases  showing a tradeoff. As expected  increasing Œ≥ will enhance the
semantic quality of the denoised images  which is actually evaluated by the pretrained classiÔ¨Åer.
Please note the numbers ‚Äò5‚Äô and ‚Äò2‚Äô highlighted by red boxes  these numbers may be difÔ¨Åcult to
recognize if Œ≥ is small  but seem recognizable when Œ≥ is large. There seems a positive correlation
between classiÔ¨Åcation error rate (which is evaluated by the classiÔ¨Åer) and human recognition (which
is evaluated by ourselves). Note that the human recognition is different from the visual quality:
human recognition means whether the class can be correctly recognized by human  visual quality
(perceptual naturalness as deÔ¨Åned in this paper) means whether the image looks like a natural image.
More visual examples are provided in the supplementary.

5 Conclusion

We have addressed the classiÔ¨Åcation-distortion-perception tradeoff by both proving a theorem about
the characteristic of the CDP function and showcasing the CDP functions under simulation and
experimental settings. Regardless of the restoration algorithm  the classiÔ¨Åcation error rate on the
restored signal evaluated by a predeÔ¨Åned classiÔ¨Åer cannot be made minimal along with the distortion
and perceptual difference. The CDP function is convex  indicating that when the error rate is already
low  any improvement of classiÔ¨Åcation performance comes at the cost of higher distortion and worse
perceptual quality.
Our Ô¨Åndings can be useful especially for computer vision research where some low-level vision tasks
(signal restoration) serve for high-level vision tasks (visual understanding). It is worth noting that we
have used a predeÔ¨Åned classiÔ¨Åer to evaluate the classiÔ¨Åcation error rate  but in practice  we may have
a different metric that directly measures the semantic quality of restored signal. More studies are
expected at this aspect in the future.

Acknowledgments

This work was supported by the Natural Science Foundation of China under Grant 61772483.

8

ùõΩ=0.02ùõΩ=0.1ùõΩ=0ùõæ=0ùõæ=0.005ùõæ=0.01Original ImageNoisy ImageReferences
[1] Martin Arjovsky  Soumith Chintala  and L√©on Bottou. Wasserstein GAN. arXiv preprint

arXiv:1701.07875  2017.

[2] Yochai Blau  Roey Mechrez  Radu Timofte  Tomer Michaeli  and Lihi Zelnik-Manor. The 2018

PIRM challenge on perceptual image super-resolution. In ECCV  pages 1‚Äì22  2018.

[3] Yochai Blau and Tomer Michaeli. The perception-distortion tradeoff. In CVPR  pages 6228‚Äì

6237  2018.

[4] Imre Csisz√°r and Paul C. Shields. Information theory and statistics: A tutorial. Foundations

and Trends in Communications and Information Theory  1(4):417‚Äì528  2004.

[5] Chao Dong  Yubin Deng  Chen Change Loy  and Xiaoou Tang. Compression artifacts reduction

by a deep convolutional network. In ICCV  pages 576‚Äì584  2015.

[6] Chao Dong  Chen Change Loy  Kaiming He  and Xiaoou Tang. Learning a deep convolutional

network for image super-resolution. In ECCV  pages 184‚Äì199  2014.

[7] Micha√´l Gharbi  Jiawen Chen  Jonathan T. Barron  Samuel W. Hasinoff  and Fr√©do Durand.
Deep bilateral learning for real-time image enhancement. ACM Transactions on Graphics 
36(4):118  2017.

[8] Justin Johnson  Alexandre Alahi  and Li Fei-Fei. Perceptual losses for real-time style transfer

and super-resolution. In ECCV  pages 694‚Äì711  2016.

[9] Alex Krizhevsky. Learning multiple layers of features from tiny images. Technical report 

University of Toronto  2009.

[10] Hulin Kuang  Xianshi Zhang  Yong-Jie Li  Leanne Lai Hang Chan  and Hong Yan. Nighttime
vehicle detection based on bio-inspired image enhancement and weighted score-level feature
fusion. IEEE Transactions on Intelligent Transportation Systems  18(4):927‚Äì936  2017.

[11] Yann LeCun  L√©on Bottou  Yoshua Bengio  and Patrick Haffner. Gradient-based learning

applied to document recognition. Proceedings of the IEEE  86(11):2278‚Äì2324  1998.

[12] Dong Liu  Dandan Wang  and Houqiang Li. Recognizable or not: Towards image semantic

quality assessment for compression. Sensing and Imaging  18(1):1‚Äì20  2017.

[13] Qingbo Lu  Wengang Zhou  Lu Fang  and Houqiang Li. Robust blur kernel estimation for
license plate images from fast moving vehicles. IEEE Transactions on Image Processing 
25(5):2311‚Äì2323  2016.

[14] Anish Mittal  Anush Krishna Moorthy  and Alan Conrad Bovik. No-reference image quality
assessment in the spatial domain. IEEE Transactions on Image Processing  21(12):4695‚Äì4708 
2012.

[15] Michele A. Saad  Alan C. Bovik  and Christophe Charrier. Blind image quality assessment: A
natural scene statistics approach in the DCT domain. IEEE Transactions on Image Processing 
21(8):3339‚Äì3352  2012.

[16] Jacob Shermeyer and Adam Van Etten. The effects of super-resolution on object detection

performance in satellite imagery. In CVPR Workshops  pages 1‚Äì10  2019.

[17] Shuochen Su  Mauricio Delbracio  Jue Wang  Guillermo Sapiro  Wolfgang Heidrich  and Oliver

Wang. Deep video deblurring for hand-held cameras. In CVPR  pages 1279‚Äì1288  2017.

[18] Tim Van Erven and Peter Harremos. R√©nyi divergence and Kullback-Leibler divergence. IEEE

Transactions on Information Theory  60(7):3797‚Äì3820  2014.

[19] Rosaura G. VidalMata  Sreya Banerjee  Brandon RichardWebster  Michael Albright  Pedro
Davalos  Scott McCloskey  Ben Miller  Asong Tambo  Sushobhan Ghosh  and Sudarshan
Nagesh. Bridging the gap between computational photography and visual recognition. arXiv
preprint arXiv:1901.09482  2019.

9

[20] Thang Vu  Cao Van Nguyen  Trung X. Pham  Tung M. Luu  and Chang D. Yoo. Fast and
efÔ¨Åcient image quality enhancement via desubpixel convolutional neural networks. In ECCV 
pages 1‚Äì17  2018.

[21] Zhou Wang  Alan C. Bovik  Hamid R. Sheikh  and Eero P. Simoncelli. Image quality assessment:
From error visibility to structural similarity. IEEE Transactions on Image Processing  13(4):600‚Äì
612  2004.

[22] Jiahui Yu  Zhe Lin  Jimei Yang  Xiaohui Shen  Xin Lu  and Thomas S. Huang. Generative

image inpainting with contextual attention. In CVPR  pages 5505‚Äì5514  2018.

[23] Kai Zhang  Wangmeng Zuo  Yunjin Chen  Deyu Meng  and Lei Zhang. Beyond a Gaussian
denoiser: Residual learning of deep CNN for image denoising. IEEE Transactions on Image
Processing  26(7):3142‚Äì3155  2017.

10

,Mehmet G√∂nen
Adam Margolin
Emmanuel Abbe
Colin Sandon
Dong Liu
Haochen Zhang
Zhiwei Xiong