2019,DeepWave: A Recurrent Neural-Network for Real-Time Acoustic Imaging,We propose a recurrent neural-network for real-time reconstruction of acoustic camera spherical maps. The network  dubbed DeepWave  is both physically and algorithmically motivated: its recurrent architecture mimics iterative solvers from convex optimisation  and its parsimonious parametrisation is based on the natural structure of acoustic imaging problems.
Each network layer applies successive filtering  biasing and activation steps to its input  which can be interpreted as generalised deblurring and sparsification steps. To comply with the irregular geometry of spherical maps  filtering operations are implemented efficiently by means of graph signal processing techniques.
Unlike commonly-used imaging network architectures  DeepWave is moreover capable of directly processing the complex-valued raw microphone correlations  learning how to optimally back-project these into a spherical map. We propose moreover a smart physically-inspired initialisation scheme that attains much faster training and higher performance than random initialisation.
Our real-data experiments show DeepWave has similar computational speed to the state-of-the-art delay-and-sum imager with vastly superior resolution. While developed primarily for acoustic cameras  DeepWave could easily be adapted to neighbouring  signal processing fields  such as radio astronomy  radar and sonar.,DeepWave: A Recurrent Neural-Network

for Real-Time Acoustic Imaging

Matthieu Simeoni ∗

IBM Zurich Research Laboratory

meo@zurich.ibm.com

Paul Hurley

Western Sydney University

paul.hurley@westernsydney.edu.au

Sepand Kashani †

École Polytechnique Fédérale de Lausanne (EPFL)

sepand.kashani@epfl.ch

Martin Vetterli

École Polytechnique Fédérale de Lausanne (EPFL)

martin.vetterli@epfl.ch

Abstract

We propose a recurrent neural-network for real-time reconstruction of acoustic
camera spherical maps. The network  dubbed DeepWave  is both physically and
algorithmically motivated: its recurrent architecture mimics iterative solvers from
convex optimisation  and its parsimonious parametrisation is based on the natural
structure of acoustic imaging problems. Each network layer applies successive
ﬁltering  biasing and activation steps to its input  which can be interpreted as gener-
alised deblurring and sparsiﬁcation steps. To comply with the irregular geometry of
spherical maps  ﬁltering operations are implemented efﬁciently by means of graph
signal processing techniques. Unlike commonly-used imaging network architec-
tures  DeepWave is moreover capable of directly processing the complex-valued
raw microphone correlations  learning how to optimally back-project these into
a spherical map. We propose moreover a smart physically-inspired initialisation
scheme that attains much faster training and higher performance than random ini-
tialisation. Our real-data experiments show DeepWave has similar computational
speed to the state-of-the-art delay-and-sum imager with vastly superior resolution.
While developed primarily for acoustic cameras  DeepWave could easily be adapted
to neighbouring signal processing ﬁelds  such as radio astronomy  radar and sonar.

1

Introduction

Motivation An acoustic camera (AC) [26  8  18  24] is a multi-modal imaging device that allows
one to visualise in real-time sound emissions from every direction in space. This is typically achieved
by overlaying on the live video from an optical camera a heatmap representing the intensity of the
ambient directional sound ﬁeld  recovered from the simultaneous recordings of a microphone array
[3  42]. Most commercial acoustic cameras recover the sound intensity ﬁeld by combining linearly
the correlated microphone recordings with a Delay-And-Sum (DAS) beamformer [42  Chapter 5]. The
beamformer acts as an angular ﬁlter [20  21]  steering sequentially the array sensitivity pattern –or
beamshape– towards various directions where the sound intensity ﬁeld is probed. Acoustic images
obtained this way are cheap to compute  but are blurred by the beamshape of the microphone array 
∗Corresponding author. Matthieu Simeoni is also afﬁliated to the École Polytechnique Fédérale de Lausanne
†Matthieu Simeoni and Sepand Kashani have contributed equally to this work. Sepand Kashani was in part
supported by the Swiss National Science Foundation grant number 200021 181978/1  “SESAM - Sensing and
Sampling: Theory and Algorithms".

(EPFL)  with email address matthieu.simeoni@epfl.ch

Preprint. Under review.

and hence exhibit poor angular resolution [49  7  48]. The severity of this blur can be shown [53] to
be proportional to the ratio λ/D  where D is the diameter of the microphone array and λ the sound
wavelength. Because of the relatively large wavelengths of acoustic waves in the audible range  this
blur can be signiﬁcant in practice: a 30 cm diameter microphone array has an angular resolution at
5 kHz (an E(cid:91)) of approximately 10 degrees  against 7·10−4 degrees for a standard optical camera
at 790 THz (violet). Moreover  acoustic cameras are often deployed in conﬁned environments [34] 
requiring them to be as compact and portable as possible  which limits3 further the achievable angular
resolution.
The advent of compressed sensing techniques [14  44] –and their wide adoption in imaging sciences
[54  4  32]– have inspired algorithmic solutions [48  7  11  12] to the acoustic imaging problem 
promising vastly improved angular resolutions. Unfortunately  these methods proved ill-suited for
real-time purposes. Indeed  they often rely on iterative solvers  such as proximal gradient descent
(PGD) [37] or its accelerated variants [2  31]. While exhibiting a fast convergence rate [2]  such
methods still require on the order of a few dozen iterations to converge in practice  making them
unable to cope with the high refresh-rate4 of acoustic cameras. For this reason  and despite their
clear superiority in terms of resolving power  nonlinear imaging methods have not yet replaced the
suboptimal DAS imager in the software stack of commercial acoustic cameras.
The recent eruption of deep learning [33  56  10] in the ﬁeld of imaging sciences may however seal
the fate of DAS for good. Indeed  this new imaging paradigm leverages neural-networks [28] to
reduce dramatically the image formation time. Unlike compressed-sensing methods which proceed
iteratively  neural networks encode the image reconstruction process in a cascade of linear and
nonlinear transformations trained on a very large number of input/output example pairs. Once
properly trained  a neural-network can be efﬁciently evaluated for some input data to produce
images of high quality  with similar accuracy and resolution as state-of-the-art compressed-sensing
methods [33]. Network architectures used for inverse imaging [22  17  56  10  40] are most often
convolutional neural-networks (CNNs)  directly adapted from generic architectures developed for
image classiﬁcation and segmentation [45]. While suitable for image processing tasks such as
denoising  super-resolution or deblurring [38  6]  such architectures are ill-suited [33] for more
complex image reconstruction problems where the input data may not consist of an image  as is
the case in biomedical imagery [4  32]  interferometry [54] or acoustic imaging. Moreover  and
particularly limiting for our current purposes  standard convolutional architectures cannot handle
images with non-Euclidean domains [13] such as spherical maps [41] produced by omnidirectional
acoustic or optical cameras.
To overcome these limitations  recurrent architectures [16  50  30  33] have been proposed  by
unrolling iterative convex optimisation algorithms. Such networks are not only able to handle non-
image inputs  but also have greater interpretability than generic CNNs. For example  Gregor and
LeCun proposed in their pioneering work [16] a recurrent neural-network (RNN) dubbed LISTA5 
inspired from the popular iterative soft-thresholding algorithm (ISTA)[2].6 Their network can be seen
as generalising ISTA  allowing for the normally ﬁxed gradient and proximal steps occurring at each
iteration of the algorithm to be learnt from the data: update steps of ISTA are replaced by a cascade
of recurrent layers with trainable parameters. The depth of the resulting RNN is typically much
smaller than the number of iterations required for ISTA to converge. Roughly speaking  the network
is learning shortcuts in the reconstruction space  allowing it to achieve a prescribed reconstruction
accuracy faster than gradient-based iterative methods.7
While the effectiveness of LISTA was veriﬁed on small images from the MNIST dataset (784 pixels)
[16]  its application to large-scale imaging problems remains challenging. This is mainly due to the
huge number of weights parametrising the network which  in the fully-connected case  grows as
the number of pixels to the square. Storing8 –let alone learning– all those weights quickly becomes
intractable for increasing resolutions. As a potential ﬁx  Gregor and LeCun recommended sparsifying
the network by pruning layer connections. While they showed that such a pruning could reduce the
number of parameters in the network by 80% without affecting too much the performance of the

3Remember that the blur spread is inversely proportional to the microphone array diameter.
4An acoustic camera typically updates the acoustic image a dozen times per second.
5LISTA stands for learned iterative soft-thresholding algorithm.
6ISTA is an instance of proximal gradient descent for penalised basis pursuit problems [52].
7Of course  such shortcuts will most likely only be valid for the distribution of inputs and outputs implicitly
deﬁned by the training set  which should hence be carefully crafted for the network to generalise well in practice.

8For a 1 megapixel image  the weights parametrising the network would be approximately 8 Gb in size.

2

Figure 1: DeepWave’s recurrent architecture (1) for L = 2 layers and random initialisation. Learnable
parameters of the network are denoted by dashed boxes. Afﬁne operations are denoted by white
boxes and nonlinear activations by grey boxes.

latter  this is still insufﬁcient for large-scale problems  and additional structure must be considered on
network layers. Such structure is however often very dependent on the problem at hand.

Contributions
In this work  we propose the ﬁrst realistic architecture of a LISTA neural-network
adapted to acoustic imaging. Our custom architecture  dubbed DeepWave  is capable of rendering
high-resolution spherical maps of real-life sound intensity ﬁelds in milliseconds. DeepWave is
tailored to the acoustic imaging problem  leveraging fully its underlying structure so as to minimise
the number of network parameters. The latter is easy to train  with a typical training time of less
than an hour on a general-purpose CPU. Unlike most state-of-the-art neural-network architectures  it
moreover readily supports complex-valued input vectors  making it capable of directly processing
the raw correlated microphone recordings. Assuming a microphone array with M microphones 
the instantaneous covariance matrix ˆΣ ∈ CM×M of the microphone recordings is processed by the
network as follows (see also ﬁg. 1):

(cid:16)

Pθ (L) xl−1 +(cid:2)B ◦ B(cid:3)H

xl = σ

(cid:17)

vec( ˆΣ) − τ

 

l = 1  . . .   L 

(1)

where vec : CM×M → CM 2 is the vectorisation operator and ◦ denotes the Khatri-Rao product
(see appendix A9 for deﬁnitions). The neurons {x1  . . .   xL} ⊂ RN
+ at the output of each layer l
of the depth L neural-network correspond to the acoustic image as it is processed by the network 
with N the number of pixels. The neuron x0 ∈ RN
+ deﬁnes the initial state of the network. The
nonlinear activation function10 σ : R → R induces sparsity in the acoustic image  and is inspired by
the proximal operator of an elastic-net penalty [37]. The remaining quantities  namely Pθ(L)  B
and τ are trainable parameters of the network  with various roles:

• Deblurring: the matrix Pθ(L) :=(cid:80)K

k=0 θkLk ∈ RN×N can be interpreted as a deblurring
matrix  cleaning potential artefacts from the array beamshape. Following the approach
of [41]  it is deﬁned as a polynomial of the graph Laplacian L ∈ RN×N based on the
connectivity graph of the spherical tessellation in use  with learnable coefﬁcients θ =
[θ0  . . .   θK] ∈ RK+1. Such parametrisation permits notably the interpretation of Pθ(L) as
a ﬁnite-support ﬁlter deﬁned on the tessellation graph. Moreover  fast graph convolution
algorithms are available for such ﬁlters [13].

• Back-projection: the operation (cid:2)B ◦ B(cid:3)H

(A.8) is a back-
projection  mapping the raw microphone correlations to the image domain. Thanks to
the convenient Khatri-Rao structure  this linear operation depends only on the matrix
B ∈ CM×N .

vec( ˆΣ) = diag

BH ˆΣB

(cid:16)

(cid:17)

9In all that follows  labels preﬁxed with roman letters refer to elements of the supplementary material.
10Typiﬁed by a rectilinear unit.

3

• Bias: the vector τ ∈ RN is a non-uniform bias  boosting or shrinking the neurons of
the network. Since only positive neurons are activated by the nonlinearity σ  this biasing
operation helps sparsify the ﬁnal acoustic image.

The total number of learnable coefﬁcients in DeepWave is linear in the number of pixels. The
rationale behind DeepWave’s architecture is detailed in section 2  with theoretical justiﬁcations
for the structures of the deblurring and back-projection linear operators. In section 3  we discuss
network training  including initialisation and regularisation. We moreover derive the forward- and
backward-propagation recursions11 for our custom architecture  required for forming gradient steps.
Finally  we test the architecture on synthetic as well as real data acquired with the Pyramic array
[5  46]. DeepWave is shown to have similar resolving power as state-of-the-art compressed-sensing
methods  with a computational overhead similar to the DAS imager. To our knowledge  this is the ﬁrst
time a nonlinear imager of the kind achieves real-time performance on a standard computing platform.
While developed primarily for acoustic cameras  DeepWave can easily be applied in neighbouring
array signal processing ﬁelds [27]  including radio astronomy  radar and sonar technologies.

2 Network architecture

In this section  we proceed similarly to [16  50  30] and construct DeepWave by studying the update
equations of an iterative solver  namely proximal gradient descent applied to acoustic imaging.

2.1 Proximal gradient descent for acoustic imaging

In all that follows  we model the sound intensity ﬁeld as a discrete spherical map with resolution
N  speciﬁed by an intensity vector x ∈ RN
+ and a tessellation Θ = {r1  . . .   rN} ⊂ S2. Spherical
tessellations [19  15] can be viewed as pixelation schemes for spherical geometries (see appendix B.1).
As is customary in compressed-sensing  we propose to recover the sound intensity map by solving a
convex optimisation problem (see appendix C):

(cid:13)(cid:13)(cid:13) ˆΣ − A diag(x)AH(cid:13)(cid:13)(cid:13)2

F

+ λ(cid:2)γ(cid:107)x(cid:107)1 + (1 − γ)(cid:107)x(cid:107)2

(cid:3)  

2

ˆx = arg min
x∈RN

+

1
2

(2)

where (cid:107)·(cid:107)F denotes the Frobenius norm  γ ∈]0  1[ and λ > 0 are hyperparameters  and ˆΣ ∈ CM×M is
the empirical covariance matrix of the microphone recordings. In a far-ﬁeld context  the forward map
A ∈ CM×N –linking the intensity vector to the microphone recordings– is commonly modelled by
the so-called steering matrix [27]: [A]mn := exp (−2πj(cid:104)pm  rn(cid:105)/λ0)   where {p1  . . .   pM} ⊂ R3
are the microphone locations and λ0 > 0 the sound wavelength. Using properties (A.5) and (A.6)
of the vectorisation operator and the Frobenius norm [23  53]  problem (2) can be re-written in
vectorised form as:

(cid:13)(cid:13)(cid:13)vec

(cid:16) ˆΣ

(cid:13)(cid:13)(cid:13)2
(cid:17) −(cid:0)A ◦ A(cid:1) x

1
2

+ λ(cid:2)γ(cid:107)x(cid:107)1 + (1 − γ)(cid:107)x(cid:107)2

(cid:3) 

+

ˆx = arg min
x∈RN

(3)
where ◦ denotes the Khatri-Rao product (see deﬁnition A.3). Problem (3) is an elastic-net penalised
least-squares problem [57]  which seeks an optimal12 trade-off between data-ﬁdelity and group-
sparsity. Group-sparsity is in this context better suited than traditional sparsity since acoustic sources
are often diffuse. It is worth noting that  since the elastic-net functional is strictly convex for γ ∈ [0  1[ 
problem (3) admits a unique solution. The latter can moreover be approximated by means of proximal
gradient descent (PGD) [2]  whose update equations are given here by (see appendix D):

2

2

 xk−1 − α(cid:0)A ◦ A(cid:1)H(cid:104)(cid:0)A ◦ A(cid:1) xk−1 − vec

2λα(1 − γ) + 1

(cid:16) ˆΣ
(cid:17)(cid:105) − λαγ

  

k ≥ 1 

(4)

xk = ReLu

where x0 ∈ RN is arbitrary  α ≤ 1/(cid:13)(cid:13)A ◦ A(cid:13)(cid:13)2

2 is the step size and ReLu(x) := max(x  0) is the
rectiﬁed linear unit [29]  applied element-wise to a real vector.13 The sequence of iterates {xk}k∈N

11DeepWave implementation can be found on https://github.com/imagingofthings/DeepWave.
12The notion of optimality is deﬁned here by the penalty parameter λ.
13Note that with x0 ∈ RN   every gradient step produces a real vector.

4

(cid:16) ˆΣ
(cid:17)(cid:105) − λαγ

deﬁned in (4) reduces the objective function in (3) at a rate O(1/k) [2]. Accelerated variants of
proximal gradient descent have been proposed [2]  which modify (4) with an extra momentum term:

 xk−1 − α(cid:0)A ◦ A(cid:1)H(cid:104)(cid:0)A ◦ A(cid:1) xk−1 − vec

yk = ReLu
xk = yk + ωk(cid:0)yk − yk−1(cid:1)
gence rate o(1/k2) [31]. Finally  we leverage the formulae(cid:0)A ◦ A(cid:1) x = vec(A diag(x)AH ) (A.5) 
and(cid:0)A ◦ A(cid:1)H

where the momentum sequence {ωk}k∈N can be designed in various ways [31  9]. In our experiments 
we will use (5) as a baseline for speed comparisons  where ωk is updated according to Chambolle and
Dossal’s strategy [9]: ωk = (k − 1)/(k + d) 
k ≥ 0  with d = 50 [31]. The accelerated proximal
gradient descent (APGD) method thus obtained is the fastest reported in the literature  with conver-

vec(R) = diag(AH RA) (A.8)  to compute gradient steps efﬁciently in (5).

2λα(1 − γ) + 1



k ≥ 1 

(5)

 

2.2 DeepWave : a PGD-inspired RNN for fast acoustic imaging

(cid:17) − τ
(cid:16) ˆΣ

(cid:17)

 

In practice PGD is terminated according to some stopping criterion. The intensity map xL obtained
after L iterations of (4) can then be seen as the output of an RNN with depth L and intermediate
neurons linked by the recursion formula:

(cid:16)Dxl−1 + B vec
I − α(cid:0)A ◦ A(cid:1)H(cid:0)A ◦ A(cid:1)(cid:105)

 

β

1
β

α
β

τ =

λαγ

1N  

(cid:104)

D =

l = 1  . . .   L.

xl = ReLu

(cid:0)A ◦ A(cid:1)H

(6)
We call this RNN the oracle RNN  since its weights D ∈ RN×N   B ∈ CN×M 2 and τ ∈ RN are not
learnt but simply given to us by identifying (6) with (4):
  B =

(7)
where β = 2λα(1 − γ) + 1. An analysis of (7) allows us moreover to interpret physically the afﬁne
operations performed by the oracle RNN. The matrix B ﬁrst is a back-projection operator  mapping
the vectorised correlation matrix into a spherical map by applying the adjoint of the forward operator
used in (3). The resulting spherical map is called a dirty map  and is equivalent to the DAS image
[53  Section 5.2][55]. The matrix D then is a deblurring operator  which subtracts at each iteration a
fraction of the array beamshape from the spherical map  hence cleaning the latter of blur artefacts.
The vector τ ﬁnally is an afﬁne shrinkage operator  which biases uniformly the spherical map. The
latter permits –in conjunction with the rectiﬁed linear unit– the sparsiﬁcation of the spherical map
and hence improve its angular resolution.
Since the oracle RNN is merely a reinterpretation of PGD  it inherits all its properties. In particular  it
is capable of solving (3) with high accuracy for arbitrary input correlation matrices. Unfortunately 
this great generalisability is typically obtained at the price of a very large number14 of layers L 
resulting in impractical reconstruction times. If one is however willing to sacriﬁce some of this
generalisability  it is possible to reduce drastically the network depth by unfreezing the weights D 
B  τ in (6)  and allowing them to be learnt for some speciﬁc input distribution. This idea was ﬁrst
explored in the context of sparse coding by Gregor and LeCun [16]  resulting in the LISTA network.
A fully-connected architecture  corresponding to unconstrained D  B and τ   would however result
in O(N 2) weights to be learnt  which is unfeasible in large-scale acoustic imaging problems. To
overcome this issue  we propose in the next paragraphs a parsimonious parametrisation of D and B.
The resulting RNN architecture  dubbed DeepWave  is given in (1) and depicted in ﬁg. 1.
Parametrisation of D Our parametrisation of D is motivated by the following result  characteris-
ing the oracle deblurring kernel for spherical microphone arrays[42] (see proof in appendix E).
Proposition 1. Consider a spherical microphone array  with diameter D and microphone directions
{˜p1  . . .   ˜pM} ⊂ S2  forming a near-regular tessellation of the sphere. Then  we have

(cid:104)
I − α(cid:0)A ◦ A(cid:1)H(cid:0)A ◦ A(cid:1)(cid:105)

(cid:20)

(cid:39)

ij

(cid:18) D

λ0

(cid:19)(cid:21)

δij − αM 2 sinc2

(cid:107)ri − rj(cid:107)

  ∀i  j ∈ {1  . . .   N} (8)

14Even with momentum acceleration  PGD typically requires more than 50 iterations to converge. The oracle

RNN obtained by unrolling PGD will consequently be very deep.

5

Algorithm 1 DeepWave forward propagation
1: Input: ˆΣt  x0

2: Output: Lt ∈ R+ (cid:8)sl

t   ˆxt  θ  B  τ   σ

l=1 ... L ⊂ RN

(cid:9)

t

3:
4: yt ← diag(BH ˆΣtB) − τ
5: for l in [1  . . .   L] do
t ← Pθ(L)xl−1
sl
6:
t ← σ(sl
xl
7:
t)
8: Lt ← 1

(cid:13)(cid:13)ˆxt − xL

t + yt
2 /(cid:107)ˆxt(cid:107)2

(cid:13)(cid:13)2

2

2

t

t

l=1 ... L

(cid:9)
(cid:1) /(cid:107)ˆxt(cid:107)2

Algorithm 2 DeepWave backward propagation
1: Input: ˆΣt  x0
2: Output: ∂θ ∈ RK+1  ∂B ∈ CM×N   ∂τ ∈ RN

t   ˆxt  θ  B  σ  (cid:8)sl

3: (∂x  ∂θ  ∂τ ) ← ((cid:0)σ(sL
t)(cid:1) ∂x
∂s ← diag(cid:0)σ(cid:48)(sl

4: for l in [L  . . .   1] do
5:
∂x ← Pθ(L)∂s
6:
∂τ ← ∂τ − ∂s
7:
[∂θ]k ← [∂θ]k + ∂sT Tk(L) σ(sl−1
8:
9: ∂B ← −2 ˆΣtB diag (∂τ )

t ) − ˆxt

2   0  0)

)

t

Figure 2: Forward and backward algorithms to compute gradients of Lt with respect to θ  B  τ . For
notational simplicity we use the shorthand ∂α = ∂Lt/∂α  and assume σ(s0

t .
t ) = x0

where λ0 is the wavelength  δij denotes the Kronecker delta and sinc(x) := sin(πx)/πx is the
cardinal sine. Moreover  the approximation (8) is extremely good for M ≥ 3(cid:98) 2πD

(cid:99)2.

λ0

consider the following parametrisation (see appendix B.3 for details): D = Pθ(L) :=(cid:80)K

Proposition 1 tells us that  for spherical arrays with sufﬁcient number of microphones15  the oracle
deblurring operator D in (7) corresponds actually to a sampled zonal kernel [35]: [D]ij = κ((cid:107)ri −
rj(cid:107)) for some κ : R+ → R. Since zonal kernels are used to deﬁne spherical convolutions [35]  D
can hence be seen as a discrete convolution operator over the tessellation in use Θ = {r1  . . .   rN}.
Its bandwidth is moreover essentially ﬁnite  since coefﬁcients [D]ij decay as 1/(cid:107)ri − rj(cid:107)2. As
discussed in [41  13]  discrete spherical convolution operators with ﬁnite scope can be efﬁciently
represented and implemented by means of graph signal processing [47] techniques. This leads us to
k=0 θkLk 
where θ = [θ0  . . .   θK] ∈ RK+1  K controls the scope of the discrete convolution and L ∈ RN×N
is the Laplacian [47] associated to the convex-hull graph of Θ. Note that with this parametrisation 
the number of parameters characterising D drops from N 2 to K + 1  with K (cid:28) N.
Parametrisation of B The oracle back-projection operator (7) admits a factorisation in terms of the
Khatri-Rao product. We decide hence to equip B with a similar structure: B = (B ◦ B)H for some
learnable matrix B ∈ CM×N . With such a parametrisation  the number of parameters characterising
B drops from N M 2 to N M. The Khatri-Rao structure guarantees moreover real-valued –and hence
physically-interpretable– dirty maps.

3 Network training

To facilitate the description of the training procedure  we adopt the following shorthand notations.
• DeepWave(Ω  L) denotes a speciﬁc instance of the DeepWave network (1) with parameters
• APGD(α  λ  γ) denotes an instance of APGD (5)  with tuning parameters (α  λ  γ) ∈ R3
+.

Ω := {θ  B  τ} and depth L.

ˆΩ ∈ arg min
θ∈RK+1
B∈CM×N
τ∈RN

The network parameters are chosen as minimisers of the following optimisation problem:

(cid:13)(cid:13)ˆxt − xL
t (Ω)(cid:13)(cid:13)2
(cid:125)
(cid:123)(cid:122)
(cid:124)

(cid:13)(cid:13)(cid:13)L1/2τ
(cid:13)(cid:13)(cid:13)2
(cid:123)(cid:122)
(cid:125)
(cid:80)T
(9)
t (Ω)}t and {ˆxt}t in (9) correspond respectively to the outputs of DeepWave(Ω  L)
t=1 Lt is a

The quantities {xL
and APGD(α  λ  γ) with identical example input data {( ˆΣt  x0

t )}t. The ﬁrst term 1
15For a spherical array with diameter D = 30 cm operating at 1 kHz  M ≥ 90 is sufﬁcient.

2(cid:107)ˆxt(cid:107)2
:=Lt

2(K + 1)
:=Lθ

T(cid:88)

(cid:107)B(cid:107)2

(cid:107)θ(cid:107)2

(cid:123)(cid:122)

(cid:123)(cid:122)

λτ
2N

:=LB

2M N

:=Lτ

(cid:124)

(cid:124)

(cid:124)

(cid:125)

2

(cid:125)

.

2

2

+

+

F

λB

+

t=1

2

T

1
T

λθ

6

t (Ω) as close as possible from one another.16 The
data-ﬁdelity term  which attempts to bring ˆxt and xL
additional terms Lθ LB Lτ are smoothing regularisers  ﬁghting against overﬁtting  a common issue
in deep learning. Since the shrinkage operator τ is deﬁned over an irregular spherical tessellation 
the smoothing term Lτ is deﬁned via the Laplacian L ∈ RN×N associated to the connectivity graph
of the tessellation  as is customary in graph signal processing (see appendix B.3).
Optimisation of (9) is carried out by stochastic gradient descent (SGD) with momentum acceleration
[51]. Gradients of Lt with respect to θ  B  τ are efﬁciently evaluated using reverse-mode algorithmic
differentiation [1  25] and are given in algorithms 1 and 2 (see appendix F for a derivation). While
random initialisation of neural-networks is a common practice in deep learning [51]  this strategy
failed for our speciﬁc architecture  leading to poor validation loss and considerably increased training
times. Instead  we hence use the oracle parameters (7) to initialise SGD:

θ0 := arg min
θ∈RK+1

(cid:107)Pθ(L) − D(cid:107)2

F   B0 :=

A 

τ 0 :=

λαγ

β

1N .

(10)

β

(cid:114) α

ﬁlter as Pθ(˜L) =(cid:80)K

For greater numerical stability during training  we follow [41] and reparameterise the deblurring
k=0 θkTk(˜L)  where Tk(·) is the Chebychev polynomial of order k and ˜L is the
normalised Laplacian with spectrum in [−1  1] (see appendix B.3 for implementation details). Finally 
we substitute the ReLu activation function by a scaled rectiﬁed tanh to avoid the exploding gradient
problem [39].17

4 Experimental results

In this section  we compare the accuracy  resolution and runtime performance of DeepWave to
DAS and APGD on real-world (RW) and simulated (SIM) datasets. More comprehensive dataset
descriptions and additional results  including an ablation study  are provided in appendices G to I.

Dataset 1 [36] (RW)
reproduces a conference room setup depicted in ﬁgs. 3a and 3b  where 8
people18 are gathered around a table and speak either in turns or simultaneously (with at most 3
concurrent speakers). Recordings of the conversation are collected by the 48-element Pyramic array
[46] (ﬁg. 3f) positioned at the centre of the table. Since human speech is wide-band  the audible range
[1500  4500] Hz in the latter are pre-processed every 100 ms and split into 9 uniform bins to form
t )}t of 2760 data points per frequency band for DeepWave (with
a suitable training set {( ˆΣt  ˆxt  x0
N = 2234). (See appendix G.2.) Frequency channels are processed independently by each algorithm.
DeepWave is trained by splitting the data points into a training and validation set (respectively 80%
and 20% in size). For each frequency band  we chose an architecture with 5 layers.
In ﬁg. 3  ﬁgs. G.4 and H.3 respectively  we compare the accuracy and runtime of DeepWave  DAS
and APGD. A video showing the evolution in time of DeepWave and DAS azimuthal sound ﬁelds (as
in ﬁgs. 3a and 3b) is also available.19 In terms of resolution  DeepWave and APGD perform similarly 
outperforming DAS by approximately 27%. The mean contrast scores for DeepWave and DAS over
the test set of Dataset 1 are 0.99 (±0.0081) and 0.89 (±0.07)  respectively. Note that since the metrics
used for assessing resolution and contrast20 are not perfectly reﬂective of human-eye perception  the
reported image quality improvements appear even more striking through visual inspection of the
sound intensity ﬁelds (see for example ﬁg. 3).

Dataset 2 [43] (RW)
consists of 2700 template recordings from the Pyramic array taken in an
anechoic chambre at an angular resolution of 2 degrees in azimuth and three different elevations (-15 
0  15 degrees). Recordings contain both male and female speech samples to cover a wide audible
range. The audio samples can be combined to simulate complex multi-source sound ﬁelds  hence we
leverage this property to augment the dataset to 5700 distinct recordings with one  two  or three active
speakers simultaneously. The raw time-series are then pre-processed as for Dataset 1 to obtain a

16in a mean relative squared-error sense.
17An alternative is to use a truncated ReLu. Given initialisation strategy 10  network training will still

converge with similar step sizes as those used with tanh non-linearities.

18The 8 people are represented in the experiment by loadspeakers playing male and female speech samples.
19Available online: https://www.youtube.com/watch?v=PwB3CS2rHdI
20As is customary  resolution is measured as the width at half-maximum of the impulse response of the

algorithms. Contrast is measured as the difference between the maximum and mean of the greyscale image.

7

(a) DAS azimuthal sound ﬁeld.

(b) DeepWave azimuthal sound ﬁeld.

(c) DAS spherical sound ﬁeld (resolution: 25.3◦   RMS contrast: 0.78).

(d) Frequency-colour mapping.

(e) DeepWave spherical sound ﬁeld (resolution: 18.5◦   contrast: 0.97).

(f) Pyramic array.

Figure 3: Snapshots at time t = 1.7 s of the sound intensity ﬁelds produced by DeepWave and DAS
for the Pyramic recordings with speakers 2  6 and 16 active. Sound frequencies range from 1.5 to 4.5
kHz and were mapped to true colours (see ﬁg. 3d  colour shades correspond to lower intensities). The
spherical maps of DAS and DeepWave are plotted in ﬁgs. 3c and 3e  respectively. In ﬁgs. 3a and 3b
we plot the azimuthal projections of ﬁgs. 3c and 3e  respectively.

training set of 151980 data points per frequency band (with N = 1568). Network training is identical
to that of Dataset 1  except that 10 azimuth directions are also witheld from the training set to assess
how well the network generalises to emissions from unseen directions.
Figures 4a and 4b show sample DAS and DeepWave reconstructions with real sources from directions
withheld from the training set. Similarly  ﬁg. 4c shows sample reconstructions when the network is
trained on real data but tested on synthetic narrow-band covariance matrices induced by sources from
directions absent from the training set. In both cases we see that DeepWave outperforms DAS in
resolution and contrast (i.e. sharper blobs and darker background).

Dataset 3 (SIM) ﬁnally is a dataset with recordings from a spherical microphone array using a
narrow-band point-source data-model at 2 kHz [53]. The sources are randomly positioned over a
120◦ ﬁeld-of-view  with up to 10 concurrent sources per recording. Experiment results available in
ﬁg. H.1 corroborate the real-data results  hence showing that DeepWave generalises well to a large
number of sources with unconstrained positions. We further investigated in ﬁg. H.2 the inﬂuence of
network depth  and concluded that 5 or 6 layers are generally sufﬁcient for the investigated dataset.

8

(a) DAS/DeepWave sound ﬁelds for Dataset 2.

(b) DAS/DeepWave sound ﬁelds for Dataset 2.

(c) DAS/DeepWave sound ﬁelds for synthetic data trained on Dataset 2.

Figure 4: Snapshots of the sound intensity ﬁelds produced by DeepWave and DAS when trained
on Dataset 2 (with 10 held-out source directions). Each subplot contains a DAS image (top) and a
DeepWave image (bottom). The frequency color mapping is identical to ﬁg. 3d. Figures 4a and 4b
show azimuthal sound ﬁeld slices on [−20◦  150◦] using real-world covariance matrices with sources
from unseen directions during training. Figure 4c shows a full 360◦ sound ﬁeld on a synthetic
covariance matrix from unseen directions during training. Elevations span [−15◦  +15◦].

In terms of runtimes ﬁnally  DeepWave and DAS both reach real-time requirements (6.5 ms and 2.0
ms respectively)  largely outperforming APGD (211 ms). (See ﬁg. H.3 for more details.)

5 Conclusion

We introduced DeepWave  the ﬁrst recurrent neural-network for real-time and high resolution acoustic
imaging. It mimics iterative solvers from convex optimisation  while using the natural structure
of acoustic imaging problems for efﬁcient training and operation. Our real and simulated data
experiments show DeepWave has similar computational speed to the state-of-the-art DAS imager
with vastly superior resolution and contrast.
For future work  one of our goals is to make DeepWave time-aware  by training it on sequences of
consecutive measurements in time. To this end  we plan to connect multiple DeepWave networks
together  one for each time  and train them end-to-end. In such an architecture  the output neurons
from one network would serve as initial neural state x0 for the next network in line. This can be
interpreted as warm-starting the network with the sound ﬁeld estimated at the previous time instant.
Additionally  we would like to propose a frequency-invariant DeepWave architecture  allowing to
train a single network for all frequency bands. Properties of the oracle weights (7) suggest that this
should be possible. This would considerably facilitate the training of the network  since the training
set would be augmented and the number of trainable parameters reduced.

9

Acknowledgments We thank Erwan Zerhouni for useful discussions regarding network training
and implementation details; and Ivan Dokmani´c for insights on related works that inspired our
approach. Finally we express our gratitude towards Robin Scheibler and Hanjie Pan for their
openly-accessible real-world datasets [36  43].

References
[1] Atilim Gunes Baydin  Barak A Pearlmutter  Alexey Andreyevich Radul  and Jeffrey Mark
Siskind. Automatic differentiation in machine learning: a survey. Journal of Marchine Learning
Research  18:1–43  2018.

[2] Amir Beck and Marc Teboulle. A fast iterative shrinkage-thresholding algorithm for linear

inverse problems. SIAM journal on imaging sciences  2(1):183–202  2009.

[3] Jacob Benesty  Jingdong Chen  and Yiteng Huang. Microphone array signal processing 

volume 1. Springer Science & Business Media  2008.

[4] Adrien Besson  Lucien Roquette  Dimitris Perdios  Matthieu Simeoni  Marcel Arditi  Paul
Hurley  Yves Wiaux  and Jean-Philippe Thiran. A physical model of non-stationary blur in
ultrasound imaging. IEEE Transactions on Computational Imaging  2019.

[5] Eric Bezzam  Robin Scheibler  Juan Azcarreta  Hanjie Pan  Matthieu Simeoni  René Beuchat 
Paul Hurley  Basile Bruneau  Corentin Ferry  and Sepand Kashani. Hardware and software for
reproducible research in audio array signal processing. In 2017 IEEE International Conference
on Acoustics  Speech and Signal Processing (ICASSP)  pages 6591–6592. Ieee  2017.

[6] Jan Biemond  Reginald L Lagendijk  and Russell M Mersereau. Iterative methods for image

deblurring. Proceedings of the IEEE  78(5):856–883  1990.

[7] Thomas F Brooks and William M Humphreys. A deconvolution approach for the mapping of
acoustic sources (damas) determined from phased microphone arrays. Journal of Sound and
Vibration  294(4-5):856–879  2006.

[8] Leon Brusniak  James Underbrink  and Robert Stoker. Acoustic imaging of aircraft noise
sources using large aperture phased arrays. In 12th AIAA/CEAS Aeroacoustics Conference (27th
AIAA Aeroacoustics Conference)  page 2715  2006.

[9] Antonin Chambolle and Ch Dossal. On the convergence of the iterates of the “fast itera-
tive shrinkage/thresholding algorithm”. Journal of Optimization theory and Applications 
166(3):968–982  2015.

[10] Yunjin Chen and Thomas Pock. Trainable nonlinear reaction diffusion: A ﬂexible framework
for fast and effective image restoration. IEEE transactions on pattern analysis and machine
intelligence  39(6):1256–1272  2017.

[11] Ning Chu  José Picheral  Ali Mohammad-Djafari  and Nicolas Gac. A robust super-resolution
approach with sparsity constraint in acoustic imaging. Applied Acoustics  76:197–208  2014.

[12] Zhigang Chu and Yang Yang. Comparison of deconvolution methods for the visualization of
acoustic sources based on cross-spectral imaging function beamforming. Mechanical Systems
and Signal Processing  48(1-2):404–422  2014.

[13] Michaël Defferrard  Xavier Bresson  and Pierre Vandergheynst. Convolutional neural networks
on graphs with fast localized spectral ﬁltering. In Advances in neural information processing
systems  pages 3844–3852  2016.

[14] Simon Foucart and Holger Rauhut. A mathematical introduction to compressive sensing. Bull.

Am. Math  54:151–165  2017.

[15] Krzysztof M Gorski  Eric Hivon  Anthony J Banday  Benjamin D Wandelt  Frode K Hansen 
Mstvos Reinecke  and Matthia Bartelmann. Healpix: a framework for high-resolution discretiza-
tion and fast analysis of data distributed on the sphere. The Astrophysical Journal  622(2):759 
2005.

10

[16] Karol Gregor and Yann LeCun. Learning fast approximations of sparse coding. In Proceedings
of the 27th International Conference on International Conference on Machine Learning  pages
399–406. Omnipress  2010.

[17] Harshit Gupta  Kyong Hwan Jin  Ha Q Nguyen  Michael T McCann  and Michael Unser.
Cnn-based projected gradient descent for consistent ct image reconstruction. IEEE transactions
on medical imaging  37(6):1440–1453  2018.

[18] RK Hansen and PA Andersen. A 3d underwater acoustic camera—properties and applications.

In Acoustical Imaging  pages 607–611. Springer  1996.

[19] Doug P Hardin  Timothy Michaels  and Edward B Saff. A comparison of popular point

conﬁgurations on sˆ 2. Dolomites Research Notes on Approximation  9(1)  2016.

[20] Paul Hurley and Matthieu Simeoni. Flexibeam: analytic spatial ﬁltering by beamforming. In
2016 IEEE International Conference on Acoustics  Speech and Signal Processing (ICASSP) 
pages 2877–2880. Ieee  2016.

[21] Paul Hurley and Matthieu Simeoni. Flexarray: Random phased array layouts for analytical
spatial ﬁltering. In 2017 IEEE International Conference on Acoustics  Speech and Signal
Processing (ICASSP)  pages 3380–3384. Ieee  2017.

[22] Kyong Hwan Jin  Michael T McCann  Emmanuel Froustey  and Michael Unser. Deep convolu-
tional neural network for inverse problems in imaging. IEEE Transactions on Image Processing 
26(9):4509–4522  2017.

[23] KG Jinadasa. Applications of the matrix operators vech and vec. Linear Algebra and its

Applications  101:73–79  1988.

[24] Charles H Jones and George A Gilmour. Acoustic camera apparatus  August 5 1975. US Patent

3 898 608.

[25] Sepand Kashani. Optimization notes. page 6  2019.

[26] K Kim  N Neretti  and N Intrator. Mosaicing of acoustic camera images. IEE Proceedings-Radar 

Sonar and Navigation  152(4):263–270  2005.

[27] Hamid Krim and Mats Viberg. Two decades of array signal processing research. IEEE signal

processing magazine  1996.

[28] Yann LeCun  Yoshua Bengio  and Geoffrey Hinton. Deep learning. nature  521(7553):436 

2015.

[29] Yann LeCun  Léon Bottou  Yoshua Bengio  Patrick Haffner  et al. Gradient-based learning

applied to document recognition. Proceedings of the IEEE  86(11):2278–2324  1998.

[30] Huan Li  Yibo Yang  Dongmin Chen  and Zhouchen Lin. Optimization algorithm inspired deep

neural network structure design. arXiv preprint arXiv:1810.01638  2018.

[31] Jingwei Liang and Carola-Bibiane Schönlieb. Faster ﬁsta. arXiv preprint arXiv:1807.04005 

2018.

[32] Michael Lustig  David Donoho  and John M Pauly. Sparse mri: The application of compressed
sensing for rapid mr imaging. Magnetic Resonance in Medicine: An Ofﬁcial Journal of the
International Society for Magnetic Resonance in Medicine  58(6):1182–1195  2007.

[33] Michael T McCann  Kyong Hwan Jin  and Michael Unser. Convolutional neural networks for
inverse problems in imaging: A review. IEEE Signal Processing Magazine  34(6):85–95  2017.

[34] Andy Meyer and Dirk Döbler. Noise source localization within a car interior using 3d-

microphone arrays. Proceedings of the BeBeC  pages 1–7  2006.

[35] Volker Michel. Lectures on constructive approximation. AMC  10:12  2013.

11

[36] Hanjie Pan  Robin Scheibler  Eric Bezzam  Ivan Dokmani´c  and Martin Vetterli. Audio speech
recordings used in the paper FRIDA: FRI-based DOA Estimation for Arbitrary Array Layout 
March 2017. This work was supported by the Swiss National Science Foundation grant 20FP-1
151073  LABEX WIFI under references ANR-10-LABX-24 and ANR-10-IDEX-0001-02 PSL*
and by Agence Nationale de la Recherche under reference ANR-13-JS09-0001-01.

[37] Neal Parikh  Stephen Boyd  et al. Proximal algorithms. Foundations and Trends R(cid:13) in Optimiza-

tion  1(3):127–239  2014.

[38] Sung Cheol Park  Min Kyu Park  and Moon Gi Kang. Super-resolution image reconstruction: a

technical overview. IEEE signal processing magazine  20(3):21–36  2003.

[39] Razvan Pascanu  Tomas Mikolov  and Yoshua Bengio. On the difﬁculty of training recurrent

neural networks. In International conference on machine learning  pages 1310–1318  2013.

[40] Dimitris Perdios  Adrien Besson  Marcel Arditi  and Jean-Philippe Thiran. A deep learning
approach to ultrasound image recovery. In 2017 IEEE International Ultrasonics Symposium
(IUS)  pages 1–4. Ieee  2017.

[41] Nathanaël Perraudin  Michaël Defferrard  Tomasz Kacprzak  and Raphael Sgier. Deepsphere:
Efﬁcient spherical convolutional neural network with healpix sampling for cosmological appli-
cations. Astronomy and Computing  2019.

[42] Boaz Rafaely. Fundamentals of spherical array processing  volume 8. Springer  2015.

[43] Scheibler Robin. Pyramic Dataset : 48-Channel Anechoic Audio Recordings of 3D Sources 
March 2018. The author would like to acknowledge Juan Azcarreta Ortiz  Corentin Ferry  and
René Beuchat for their help in the design and usage of the Pyramic array. Hanjie Pan  Miranda
Krekovi´c  Mihailo Kolundzija  and Dalia El Badawy for lending a hand  or even two  during
experiments. Finally  Juan Azcarreta Ortiz  Eric Bezzam  Hanjie Pan and Ivan Dokmani´c for
feedback on the documentation and dataset organization.

[44] Justin Romberg.

Imaging via compressive sampling.

25(2):14–20  2008.

IEEE Signal Processing Magazine 

[45] Olaf Ronneberger  Philipp Fischer  and Thomas Brox. U-net: Convolutional networks for
biomedical image segmentation. In International Conference on Medical image computing and
computer-assisted intervention  pages 234–241. Springer  2015.

[46] Robin Scheibler  Juan Azcarreta  René Beuchat  and Corentin Ferry. Pyramic: Full stack open
microphone array architecture and dataset. In 2018 16th International Workshop on Acoustic
Signal Enhancement (IWAENC)  pages 226–230. IEEE  2018.

[47] David Shuman  Sunil Narang  Pascal Frossard  Antonio Ortega  and Pierre Vandergheynst. The
emerging ﬁeld of signal processing on graphs: Extending high-dimensional data analysis to
networks and other irregular domains. IEEE Signal Processing Magazine  3(30):83–98  2013.

[48] Pieter Sijtsma. Clean based on spatial source coherence. International journal of aeroacoustics 

6(4):357–374  2007.

[49] Matthieu Martin Jean-Andre Simeoni and Paul Hurley. Graph spectral clustering of convolution

artefacts in radio interferometric images. Technical report  2019.

[50] Jian Sun  Huibin Li  Zongben Xu  et al. Deep admm-net for compressive sensing mri. In

Advances in neural information processing systems  pages 10–18  2016.

[51] Ilya Sutskever  James Martens  George Dahl  and Geoffrey Hinton. On the importance of
initialization and momentum in deep learning. In International conference on machine learning 
pages 1139–1147  2013.

[52] Michael Unser  Julien Fageot  and Harshit Gupta. Representer theorems for sparsity-promoting

l1 regularization. IEEE Transactions on Information Theory  62(9):5167–5180  2016.

[53] Alle-Jan van der Veen and Stefan J Wijnholds. Signal processing tools for radio astronomy. In

Handbook of Signal Processing Systems  pages 421–463. Springer  2013.

12

[54] Yves Wiaux  Laurent Jacques  Gilles Puy  Anna MM Scaife  and Pierre Vandergheynst. Com-
pressed sensing imaging techniques for radio interferometry. Monthly Notices of the Royal
Astronomical Society  395(3):1733–1742  2009.

[55] Stefan J Wijnholds and Alle-Jan van der Veen. Fundamental imaging limits of radio telescope

arrays. IEEE Journal of Selected Topics in Signal Processing  2(5):613–623  2008.

[56] Li Xu  Jimmy SJ Ren  Ce Liu  and Jiaya Jia. Deep convolutional neural network for image
deconvolution. In Advances in Neural Information Processing Systems  pages 1790–1798  2014.

[57] Hui Zou and Trevor Hastie. Regularization and variable selection via the elastic net. Journal of

the Royal Statistical Society: Series B (Statistical Methodology)  67(2):301–320  2005.

13

,Matthieu SIMEONI
Sepand Kashani
Paul Hurley
Martin Vetterli