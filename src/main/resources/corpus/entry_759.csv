2012,Bayesian active learning with localized priors for fast receptive field characterization,Active learning can substantially improve the yield of neurophysiology experiments by adaptively selecting stimuli to probe a neuron's receptive field (RF) in real time. Bayesian active learning methods maintain a posterior distribution over the RF  and select stimuli to maximally reduce posterior entropy on each time step.  However  existing methods tend to rely on simple Gaussian priors  and do not exploit uncertainty at the level of hyperparameters when determining an optimal stimulus.  This uncertainty can play a substantial role in RF characterization  particularly when RFs are smooth  sparse  or local in space and time.  In this paper  we describe a novel framework for active learning under hierarchical  conditionally Gaussian priors.  Our algorithm uses sequential Markov Chain Monte Carlo sampling (''particle filtering'' with MCMC) over hyperparameters to construct a mixture-of-Gaussians representation of the RF posterior  and selects optimal stimuli using an approximate infomax criterion.  The core elements of this algorithm are parallelizable  making it computationally efficient for real-time experiments.  We apply our algorithm to simulated and real neural data  and show that it can provide highly accurate receptive field estimates from very limited data  even with a small number of hyperparameter samples.,Bayesian active learning with localized priors

for fast receptive ﬁeld characterization

Mijung Park

Electrical and Computer Engineering

The University of Texas at Austin
mjpark@mail.utexas.edu

Jonathan W. Pillow

Center For Perceptual Systems
The University of Texas at Austin
pillow@mail.utexas.edu

Abstract

Active learning methods can dramatically improve the yield of neurophysiology
experiments by adaptively selecting stimuli to probe a neuron’s receptive ﬁeld
(RF). Bayesian active learning methods specify a posterior distribution over the
RF given the data collected so far in the experiment  and select a stimulus on
each time step that maximally reduces posterior uncertainty. However  existing
methods tend to employ simple Gaussian priors over the RF and do not exploit
uncertainty at the level of hyperparameters.
Incorporating this uncertainty can
substantially speed up active learning  particularly when RFs are smooth  sparse 
or local in space and time. Here we describe a novel framework for active learning
under hierarchical  conditionally Gaussian priors. Our algorithm uses sequential
Markov Chain Monte Carlo sampling (“particle ﬁltering” with MCMC) to con-
struct a mixture-of-Gaussians representation of the RF posterior  and selects op-
timal stimuli using an approximate infomax criterion. The core elements of this
algorithm are parallelizable  making it computationally efﬁcient for real-time ex-
periments. We apply our algorithm to simulated and real neural data  and show
that it can provide highly accurate receptive ﬁeld estimates from very limited data 
even with a small number of hyperparameter samples.

1

Introduction

Neurophysiology experiments are costly and time-consuming. Data are limited by an animal’s will-
ingness to perform a task (in awake experiments) and the difﬁculty of maintaining stable neural
recordings. This motivates the use of active learning  known in statistics as “optimal experimen-
tal design”  to improve experiments using adaptive stimulus selection in closed-loop experiments.
These methods are especially powerful for models with many parameters  where traditional methods
typically require large amounts of data.
In Bayesian active learning  the basic idea is to deﬁne a statistical model of the neural response 
then carry out experiments to efﬁciently characterize the model parameters [1–6]. (See Fig. 1A).
Typically  this begins with a (weakly- or non-informative) prior distribution  which expresses our
uncertainty about these parameters before the start of the experiment. Then  recorded data (i.e. 
stimulus-response pairs) provide likelihood terms that we combine with the prior to obtain a poste-
rior distribution. This posterior reﬂects our beliefs about the parameters given the data collected so
far in the experiment. We then select a stimulus for the next trial that maximizes some measure of
utility (e.g.  expected reduction in entropy  mean-squared error  classiﬁcation error  etc.)  integrated
with respect to the current posterior.
In this paper  we focus on the problem of receptive ﬁeld (RF) characterization from extracellularly
recorded spike train data. The receptive ﬁeld is a linear ﬁlter that describes how the neuron integrates
its input (e.g.  light) over space and time; it can be equated with the linear term in a generalized linear

1

model (GLM) of the neural response [7]. Typically  RFs are high-dimensional (with 10s to 100s of
parameters  depending on the choice of input domain)  making them an attractive target for active
learning methods. Our paper builds on prior work from Lewi et al [6]  a seminal paper that describes
active learning for RFs under a conditionally Poisson point process model.
Here we show that a sophisticated choice of prior distribution can lead to substantial improvements
in active learning. Speciﬁcally  we develop a method for learning under a class of hierarchical 
conditionally Gaussian priors that have been recently developed for RF estimation [8  9]. These pri-
ors ﬂexibly encode a preference for smooth  sparse  and/or localized structure  which are common
features of real neural RFs. In ﬁxed datasets (“passive learning”)  the associated estimators give sub-
stantial improvements over both maximum likelihood and standard lasso/ridge-regression shrinkage
estimators  but they have not yet been incorporated into frameworks for active learning.
Active learning with a non-Gaussian prior poses several major challenges  however  since the poste-
rior is non-Gaussian  and requisite posterior expectations are much harder to compute. We address
these challenges by exploiting a conditionally Gaussian representation of the prior (and posterior)
using sampling at the level of the hyperparameters. We demonstrate our method using the Automatic
Locality Determination (ALD) prior introduced in [9]  where hyperparameters control the locality
of the RF in space-time and frequency. The resulting algorithm outperforms previous active learning
methods on real and simulated neural data  even under various forms of model mismatch.
The paper is organized as follows. In Sec. 2  we formally deﬁne the Bayesian active learning prob-
lem and review the algorithm of [6]  to which we will compare our results. In Sec. 3  we describe
a hierarchical response model  and in Sec. 4 describe the localized RF prior that we will employ
for active learning. In Sec. 5  we describe a new active learning method for conditionally Gaussian
priors. In Sec. 6  we show results of simulated experiments with simulated and real neural data.

2 Bayesian active learning

Bayesian active learning (or “experimental design”) provides a model-based framework for selecting
optimal stimuli or experiments. A Bayesian active learning method has three basic ingredients:
(1) an observation model (likelihood) p(y|x  k)  specifying the conditional probability of a scalar
response y given vector stimulus x and parameter vector k; (2) a prior p(k) over the parameters
of interest; and (3) a loss or utility function U  which characterizes the desirability of a stimulus-
response pair (x  y) under the current posterior over k. The optimal stimulus x is the one that
maximizes the expected utility Ey|x[U (x  y)]  meaning the utility averaged over the distribution of
(as yet) unobserved y|x.
One popular choice of utility function is the mutual information between (x  y) and the parameters
k. This is commonly known as information-theoretic or infomax learning [10]. It is equivalent to
picking the stimulus on each trial that minimizes the expected posterior entropy.
Let Dt = {xi  yi}t
learning  the optimal stimulus at time step t + 1 is:

i=1 denote the data collected up to time step t in the experiment. Under infomax

Ey|x Dt[I(y  k|x Dt)] = arg min

Ey|x Dt [H(k|x  y Dt)] 

(1)

x

xt+1 = arg max

where H(k|x  y Dt) = −(cid:82) p(k|x  y Dt) log p(k|x  y Dt)dk denotes the posterior entropy of k 
and p(y|x Dt) =(cid:82) p(y|x  k)p(k|Dt)dk is the predictive distribution over response y given stimulus

x and data Dt. The mutual information provided by (y  x) about k  denoted by I(y  k|x Dt)  is
simply the difference between the prior and posterior entropy.

x

2.1 Method of Lewi  Butera & Paninski 2009

Lewi et al [6] developed a Bayesian active learning framework for RF characterization in closed-loop
neurophysiology experiments  which we henceforth refer to as “Lewi-09”. This method employs a
conditionally Poisson generalized linear model (GLM) of the neural spike response:

λt = g(k(cid:62)xt)
yt ∼ Poiss(λt) 

2

(2)

Figure 1: (A) Schematic of Bayesian active learning for neurophysiology experiments. For each
presented stimulus x and recorded response y (upper right)  we update the posterior over receptive
ﬁeld k (bottom)  then select the stimulus that maximizes expected information gain (upper left).
(B) Graphical model for the non-hierarchical RF model used by Lewi-09. It assumes a Gaussian
prior p(k) and Poisson likelihood p(yt|xt  k). (C) Graphical model for the hierarchical RF model
used here  with a hyper-prior pθ(θ) over hyper-parameters and conditionally Gaussian prior p(k|θ)
over the RF. For simplicity and speed  we assume a Gaussian likelihood for p(yt|xt  k)  though all
examples in the manuscript involved real neural data or simulations from a Poisson GLM.

where g is a nonlinear function that ensures non-negative spike rate λt.
The Lewi-09 method assumes a Gaussian prior over k  which leads to a (non-Gaussian) posterior
given by the product of Poisson likelihood and Gaussian prior. (See Fig. 1B). Neither the predictive
distribution p(y|x Dt) nor the posterior entropy H(k|x  y Dt) can be computed in closed form.
However  the log-concavity of the posterior (guaranteed for suitable choice of g [11]) motivates a
tractable and accurate Gaussian approximation to the posterior  which provides a concise analytic
formula for posterior entropy [12  13].
The key contributions of Lewi-09 include fast methods for updating the Gaussian approximation to
the posterior and for selecting the stimulus (subject to a maximum-power constraint) that maximizes
expected information gain. The Lewi-09 algorithm yields substantial improvement in characteriza-
tion performance relative to randomized iid (e.g.  “white noise”) stimulus selection. Below  we will
benchmark the performance of our method against this algorithm.

3 Hierarchical RF models

Here we seek to extend the work of Lewi et al to incorporate non-Gaussian priors in a hierarchical
receptive ﬁeld model. (See Fig. 1C). Intuitively  a good prior can improve active learning by reducing
the prior entropy  i.e.  the effective size of the parameter space to be searched. The drawback of
more sophisticated priors is that they may complicate the problem of computing and optimizing the
posterior expectations needed for active learning.
To focus more straightforwardly on the role of the prior distribution  we employ a simple linear-
Gaussian model of the neural response:

(3)
where t is iid zero-mean Gaussian noise with variance σ2. We then place a hierarchical  condition-
ally Gaussian prior on k:

yt = k(cid:62)xt + t 

t ∼ N (0  σ2) 

(4)
(5)
where Cθ is a prior covariance matrix that depends on hyperparameters θ. These hyperparameters
in turn have a hyper-prior pθ. We will specify the functional form of Cθ in the next section.
In this setup  the effective prior over k is a mixture-of-Gaussians  obtained by marginalizing over θ:

∼ pθ 

k | θ ∼ N (0  Cθ)
θ

N (0  Cθ) pθ(θ)dθ.

(6)

(cid:90)

p(k) =

(cid:90)

p(k|θ)p(θ)dθ =

3

Chyper-parametersparameters(RF)parameters(RF)hierarchical RF modelAselect stimulusupdate posteriorexperimentBRF model (Lewi et al 09)stimulusspikecountGiven data X = (x1  . . .   xt)(cid:62) and Y = (y1  . . .   yt)(cid:62)  the posterior also takes the form of a
mixture-of-Gaussians:

p(k|X  Y ) =

p(k|X  Y  θ)p(θ|X  Y )dθ

(cid:90)

(7)

(8)

where the conditional posterior given θ is the Gaussian

p(k|X  Y  θ) = N (µθ  Λθ) 

µθ = 1

σ2 ΛθX(cid:62)Y  Λθ = ( 1

σ2 X(cid:62)X + C−1

θ )−1 

and the mixing weights are given by the marginal posterior 

p(θ|X  Y ) ∝ p(Y |X  θ)pθ(θ) 

|2πΛθ| 1

2

(cid:0)µ(cid:62)

(9)
which we will only need up to a constant of proportionality. The marginal likelihood or evidence
p(Y |X  θ) is the marginal probability of the data given the hyperparameters  and has a closed form
for the linear Gaussian model:
p(Y |X  θ) =

θ µθ − m(cid:62)L−1m(cid:1)(cid:3)  

exp(cid:2) 1

2|2πCθ| 1
σ2 LX(cid:62)Y .

|2πσ2I| 1
where L = σ2(X(cid:62)X)−1 and m = 1
Several authors have pointed out that active learning confers no beneﬁt over ﬁxed-design experi-
ments in linear-Gaussian models with Gaussian priors  due to the fact that the posterior covariance
is response-independent [1  6]. That is  an optimal design (one that minimizes the ﬁnal posterior
entropy) can be planned out entirely in advance of the experiment. However  this does not hold
for linear-Gaussian models with non-Gaussian priors  such as those considered here. The posterior
distribution in such models is data-dependent via the marginal posterior’s dependence on Y (eq. 9).
Thus  active learning is warranted even for linear-Gaussian responses  as we will demonstrate em-
pirically below.

θ Λ−1

(10)

2

2

4 Automatic Locality Determination (ALD) prior

In this paper  we employ a ﬂexible RF model underlying the so-called automatic locality determina-
tion (ALD) estimator [9].1 The key justiﬁcation for the ALD prior is the observation that most neural
RFs tend to be localized in both space-time and spatio-temporal frequency. Locality in space-time
refers to the fact that (e.g.  visual) neurons integrate input over a limited domain in time and space;
locality in frequency refers to the band-pass (or smooth / low pass) character of most neural RFs.
The ALD prior encodes these tendencies in the parametric form of the covariance matrix Cθ  where
hyperparameters θ control the support of both the RF and its Fourier transform.
The hyperparameters for the ALD prior are θ = (ρ  νs  νf   Ms  Mf )(cid:62)  where ρ is a “ridge” pa-
rameter that determines the overall amplitude of the covariance; νs and νf are length-D vectors that
specify the center of the RF support in space-time and frequency  respectively (where D is the degree
of the RF tensor2); and Ms and Mf are D × D positive deﬁnite matrices that describe an elliptical
(Gaussian) region of support for the RF in space-time and frequency  respectively. In practice  we
will also include the additive noise variance σ2 (eq. 3) as a hyperparameter  since it plays a similar
role to C in determining the posterior and evidence. Thus  for the (D = 2) examples considered
here  there are 12 hyperparameters  including scalars σ2 and ρ  two hyperparameters each for νs and
νf   and three each for symmetric matrices Ms and Mf .
Note that although the conditional ALD prior over k|θ assigns high prior probability to smooth
and sparse RFs for some settings of θ  for other settings (i.e.  where Ms and Mf describe elliptical
regions large enough to cover the entire RF) the conditional prior corresponds to a simple ridge
prior and imposes no such structure. We place a ﬂat prior over θ so that no strong prior beliefs about
spatial locality or bandpass frequency characteristics are imposed a priori. However  as data from a
neuron with a truly localized RF accumulates  the support of the marginal posterior p(θ|Dt) shrinks
down on regions that favor a localized RF  shrinking the posterior entropy over k far more quickly
than is achievable with methods based on Gaussian priors.

1“Automatic” refers to the fact that in [9]  the model was used for empirical Bayes inference  i.e.  MAP
inference after maximizing the evidence for θ. Here  we consider perform fully Bayesian inference under the
associated model.

2e.g.  a space×space×time RF has degree D = 3.

4

5 Bayesian active learning with ALD

To perform active learning under the ALD model  we need two basic ingredients: (1) an efﬁcient
method for representing and updating the posterior p(k|Dt) as data come in during the experiment;
and (2) an efﬁcient algorithm for computing and maximizing the expected information gain given a
stimulus x. We will describe each of these in turn below.

5.1 Posterior updating via sequential Markov Chain Monte Carlo

To represent the ALD posterior over k given data  we will rely on the conditionally Gaussian repre-
sentation of the posterior (eq. 7) using particles {θi}i=1 ... N sampled from the marginal posterior 
θi ∼ P (θ|Dt) (eq. 9). The posterior will then be approximated as:
p(k|Dt  θi) 

(cid:88)

(11)

p(k|Dt) ≈ 1
N

i

where each distribution p(k|Dt  θi) is Gaussian with θi-dependent mean and covariance (eq. 8).
Markov Chain Monte Carlo (MCMC) is a popular method for sampling from distributions known
only up to a normalizing constant. In cases where the target distribution evolves over time by ac-
cumulating more data  however  MCMC samplers are often impractical due to the time required for
convergence (i.e.  “burning in”). To reduce the computational burden  we use a sequential sampling
algorithm to update the samples of the hyperparameters at each time step  based on the samples
drawn at the previous time step. The main idea of our algorithm is adopted from the resample-move
particle ﬁlter  which involves generating initial particles; resampling particles according to incom-
ing data; then performing MCMC moves to avoid degeneracy in particles [14]. The details are as
follows.
Initialization: On the ﬁrst time step  generate initial hyperparameter samples {θi} from the hyper-
prior pθ  which we take to be ﬂat over a broad range in θ.
Resampling: Given a new stimulus/response pair {x  y} at time t  resample the existing particles
according to the importance weights:

p(yt|θ(t)

i

 Dt−1  xt) = N (yt|µi

(cid:62)xt  xt

(cid:62)Λixt + σ2
i ) 

(12)

where (µi  Λi) denote the mean and covariance of the Gaussian component attached to particle θi 
This ensures the posterior evolves according to:
|Dt) ∝ p(yt|θ(t)

 Dt−1  xt)p(θ(t)

|Dt−1).

p(θ(t)

(13)

i

i

i

MCMC Move: Propagate particles via Metropolis Hastings (MH)  with multivariate Gaussian pro-
posals centered on the current particle θi of the Markov chain: θ∗ ∼ N (θi  Γ)  where Γ is a diagonal
matrix with diagonal entries given by the variance of the particles at the end of time step t−1. Accept
the proposal with probability min(1  α)  where α = q(θ∗)
q(θi)   with q(θi) = p(θi|Dt). Repeat MCMC
moves until computational or time budget has expired.
The main bottleneck of this scheme is the updating of conditional posterior mean µi and covariance
Λi for each particle θi  since this requires inversion of a d × d matrix. (Note that  unlike Lewi-
09  these are not rank-one updates due to the fact that Cθi changes after each θi move). This cost
is independent of the amount of data  linear in the number of particles  and scales as O(d3) in
RF dimensionality d. However  particle updates can be performed efﬁciently in parallel on GPUs or
machines with multi-core processors  since the particles do not interact except for stimulus selection 
which we describe below.

5.2 Optimal Stimulus Selection
Given the posterior over k at time t  represented by a mixture of Gaussians attached to particles {θi}
sampled from the marginal posterior  our task is to determine the maximally informative stimulus to
present at time t + 1. Although the entropy of a mixture-of-Gaussians has no analytic form  we can

5

Figure 2: Simulated experiment. (A) Angular error in estimates of a simulated RF (20 × 20 pixels 
shown in inset) vs. number of stimuli  for Lewi-09 method (blue)  the ALD-based active learning
method using 10 (pink) or 100 (red) particles  and the ALD-based passive learning method (black).
True responses were simulated from a Poisson-GLM neuron. Traces show average over 20 inde-
pendent repetitions. (B) RF estimates obtained by each method after 200  400  and 1000 trials. Red
numbers below indicate angular error (deg).

compute the exact posterior covariance via the formula:

N(cid:88)

(cid:0)Λi + µiµi

(cid:62)(cid:1) − ˜µ˜µ(cid:62) 

1
N

˜Λt =

(14)

i=1

(cid:80) µi is the full posterior mean. This leads to an upper bound on posterior en-

where ˜µt = 1
N
tropy  since a Gaussian is the maximum-entropy distribution for ﬁxed covariance. We then take
the next stimulus to be the maximum-variance eigenvector of the posterior covariance  which is the
most informative stimulus under a Gaussian posterior and Gaussian noise model  subject to a power
constraint on stimuli [6].
Although this selection criterion is heuristic  since it is not guaranteed to maximize mutual informa-
tion under the true posterior  it is intuitively reasonable since it selects the stimulus direction along
which the current posterior is maximally uncertain. Conceptually  directions of large posterior vari-
ance can arise in two different ways: (1) directions of large variance for all covariances Λi  meaning
that all particles assign high posterior uncertainty over k|Dt in the direction of x; or (2) directions in
which the means µi are highly dispersed  meaning the particles disagree about the mean of k|Dt in
the direction of x. In either scenario  selecting a stimulus proportional to the dominant eigenvector
is heuristically justiﬁed by the fact that it will reduce collective uncertainty in particle covariances or
cause particle means to converge by narrowing of the marginal posterior. We show that the method
performs well in practice for both real and simulated data (Section 6). We summarize the complete
method in Algorithm 1.

Algorithm 1 Sequential active learning under conditionally Gaussian models

Given particles {θi} from p(θ|Dt)  which deﬁne the posterior as P (k|Dt) =(cid:80)

1. Compute the posterior covariance ˜Λt from {(µi  Λi)} (eq. 14).
2. Select optimal stimulus xt+1 as the maximal eigenvector of ˜Λt
3. Measure response yt+1.
4. Resample particles {θi} with the weights {N (yt+1|µi
5. Perform MH sampling of p(θ|Dt+1)  starting from resampled particles.
repeat

(cid:62)xt+1  xt+1

(cid:62)Λixt+1 + σ2

i )}.

i N (µi  Λi) 

6

true filter10201020200 trials400 trialsLewi-09ALD10 ALD100 11BA 1000 trials020040060080010003040506070angle difference in degree# trialsLewi-09ALD10ALD100                      62.82               51.54           44.9457.29               40.69           36.6543.34               35.90          28.98Passive-ALDFigure 3: Additional simulated exam-
ples comparing Lewi-09 and ALD-
based active learning. Responses were
simulated from a GLM-Poisson model
with three different true 400-pixel RFs
(A) a Gabor ﬁlter
(left column):
(shown previously in [6]); (B): a center-
surround RF  typical in retinal ganglion
(C): a relatively non-localized
cells;
grid-cell RF. Middle and right columns
show RF estimates after 400 trials of ac-
tive learning under each method  with
average angular error (over independent
20 repeats) shown beneath in red.

6 Results

Simulated Data: We tested the performance of our algorithm using data simulated from a Poisson-
GLM neuron with a 20 × 20 pixel Gabor ﬁlter and an exponential nonlinearity (See Fig. 2). This is
the response model assumed by the Lewi-09 method  and therefore substantially mismatched to the
linear-Gaussian model assumed by our method.
For the Lewi-09 method  we used a diagonal prior covariance with amplitude set by maximizing
marginal likelihood for a small dataset. We compared two versions of the ALD-based algorithm
(with 10 and 100 hyperparameter particles  respectively) to examine the relationship between per-
formance and ﬁdelity of the posterior representation. To quantify the performance  we used the
angular difference (in degrees) between the true and estimated RF.
Fig 2A shows the angular difference between the true RF and estimates obtained by Lewi-09 and
the ALD-based method  as a function of the number of trials. The ALD estimate exhibits more
rapid convergence  and performs noticeably better with 100 than with 10 particles (ALD100 vs.
ALD10)  indicating that accurately preserving uncertainty over the hyperparameters is beneﬁcial to
performance. We also show the performance of ALD inference under passive learning (iid random
stimulus selection)  which indicates that the improvement in our method is not simply due to the use
of an improved RF estimator. Fig 2B shows the estimates obtained by each method after 200  400 
and 1000 trials. Note that the estimate with 100 hyperparameter samples is almost indistinguishable
from the true ﬁlter after 200 trials  which is substantially lower than the dimensionality of the ﬁlter
itself (d = 400).
Fig. 3 shows a performance comparison using three additional 2-dimensional receptive ﬁelds  to
show that performance improves across a variety of different RF shapes. The ﬁlters included: (A)
a gabor ﬁlter similar to that used in [6]; (B) a retina-like center-surround receptive ﬁeld; (C) a
grid-cell receptive ﬁeld with multiple modes. As before  noisy responses were simulated from a
Poisson-GLM. For the grid-cell example  these ﬁlter is not strongly localized in space  yet the ALD-
based estimate substantially outperforms Lewi-09 due to its sensitivity to localized components in
frequency. Thus  ALD-based method converges more quickly despite the mismatch between the
model used to simulate data and the model assumed for active learning.
Neural Data: We also tested our method with an off-line analysis of real neural data from a sim-
ple cell recorded in primate V1 (published in [15]). The stimulus consisted of 1D spatiotemporal
white noise (“ﬂickering bars”)  with 16 spatial bars on each frame  aligned with the cell’s preferred
orientation. We took the RF to have 16 time bins  resulting in a 256-dimensional parameter space
for the RF. We performed simulated active learning by extracting the raw stimuli from 46 minutes
of experimental data. On each trial  we then computed the expected information gain from present-
ing each of these stimuli (blind to neuron’s actual response to each stimulus). We used ALD-based
active learning with 10 hyperparameter particles  and examined performance of both algorithms for
960 trials (selecting from ≈ 276 000 possible stimuli on each trial).

7

 Lewi-09true filter(A)(B)(C)angle difference:  60.68             37.8262.82              42.5760.32              50.73ALD10 Figure 4: Comparison of active learning methods in a simulated experiment with real neural data
from a primate V1 simple cell. (Original data recorded in response to white noise “ﬂickering bars”
stimuli  see [15]). (A): Average angular difference between the MLE (inset  computed from an entire
46-minute dataset) and the estimates obtained by active learning  as a function of the amount of data.
We simulated active learning via an ofﬂine analysis of the ﬁxed dataset  where methods had access
to possible stimuli but not responses. (B): RF estimates after 10 and 30 seconds of data. Note that
the ALD-based estimate has smaller error with 10 seconds of data than Lewi-09 with 30 seconds of
data. (C): Average entropy of hyperparameter particles as a function of t  showing rapid narrowing
of marginal posterior.

Fig 4A shows the average angular difference between the maximum likelihood estimate (computed
with the entire dataset) and the estimate obtained by each active learning method  as a function of
the number of stimuli. The ALD-based method reduces the angular difference by 45 degrees with
only 160 stimuli  although the ﬁlter dimensionality of the RF for this example is 256. The Lewi-09
method requires four times more data to achieve the same accuracy. Fig 4B shows estimates after
160 and 480 stimuli. We also examined the average entropy of the hyperparameter particles as a
function of the amount of data used. Fig. 4C shows that the entropy of the marginal posterior over
hyperparameters falls rapidly during the ﬁrst 150 trials of active learning.
The main bottleneck of the algorithm is eigendecomposition of the posterior covariance ˜Λ  which
took 30ms for a 256 × 256 matrix on a 2 × 2.66 GHz Quad-Core Intel Xeon Mac Pro. Updating
importance weights and resampling 10 particles took 4ms  and a single step of MH resampling for
each particle took 5ms. In total  it took <60 ms to compute the optimal stimulus in each trial using a
non-optimized implementation of our algorithm  indicating that our methods should be fast enough
for use in real-time neurophysiology experiments.

7 Discussion

We have developed a Bayesian active learning method for neural RFs under hierarchical response
models with conditionally Gaussian priors. To take account of uncertainty at the level of hyperpa-
rameters  we developed an approximate information-theoretic criterion for selecting optimal stimuli
under a mixture-of-Gaussians posterior. We applied this framework using a prior designed to capture
smooth and localized RF structure. The resulting method showed clear advantages over traditional
designs that do not exploit structured prior knowledge. We have contrasted our method with that
of Lewi et al [6]  which employs a more ﬂexible and accurate model of the neural response  but
a less ﬂexible model of the RF prior. A natural future direction therefore will be to combine the
Poisson-GLM likelihood and ALD prior  which will combine the beneﬁts of a more accurate neural
response model and a ﬂexible (low-entropy) prior for neural receptive ﬁelds  while incurring only a
small increase in computational cost.

8

ml (46 min.)816816Lewi-09ALD 11B A0160 48096040506070# of stimuliALDLewi-09−140−100−60−2020angle: 55.0    42.5C 0  320  640960# of stimuli160 stimuli480 stimuli45.147.2avg angle differenceAcknowledgments

We thank N. C. Rust and J. A. Movshon for V1 data  and several anonymous reviewers for help-
ful advice on the original manuscript. This work was supported by a Sloan Research Fellowship 
McKnight Scholar’s Award  and NSF CAREER Award IIS-1150186 (JP).

References
[1] D. J. C. MacKay. Information-based objective functions for active data selection. Neural Computation 

4(4):590–604  1992.

[2] K. Chaloner and I. Verdinelli. Bayesian experimental design: a review. Statistical Science  10:273–304 

1995.

[3] D. A. Cohn  Z. Ghahramani  and M. I. Jordan. Active learning with statistical models. J. Artif. Intell. Res.

(JAIR)  4:129–145  1996.

[4] A. Watson and D. Pelli. QUEST: a Bayesian adaptive psychophysical method. Perception and Psy-

chophysics  33:113–120  1983.

[5] L. Paninski. Asymptotic theory of information-theoretic experimental design. Neural Computation 

17(7):1480–1507  2005.

[6] J. Lewi  R. Butera  and L. Paninski. Sequential optimal design of neurophysiology experiments. Neural

Computation  21(3):619–687  2009.

[7] W. Truccolo  U. T. Eden  M. R. Fellows  J. P. Donoghue  and E. N. Brown. A point process framework
for relating neural spiking activity to spiking history  neural ensemble and extrinsic covariate effects. J.
Neurophysiol  93(2):1074–1089  2005.

[8] M. Sahani and J. Linden. Evidence optimization techniques for estimating stimulus-response functions.

NIPS  15  2003.

[9] M. Park and J. W. Pillow. Receptive ﬁeld inference with localized priors. PLoS Comput Biol 

7(10):e1002219  2011.

[10] N. Houlsby  F. Huszar  Z. Ghahramani  and M. Lengyel. Bayesian active learning for classiﬁcation and

preference learning. CoRR  abs/1112.5745  2011.

[11] L. Paninski. Maximum likelihood estimation of cascade point-process neural encoding models. Network:

Computation in Neural Systems  15:243–262  2004.

[12] R. Kass and A. Raftery. Bayes factors. Journal of the American Statistical Association  90:773–795 

1995.

[13] J. W. Pillow  Y. Ahmadian  and L. Paninski. Model-based decoding  information estimation  and change-

point detection techniques for multineuron spike trains. Neural Comput  23(1):1–45  Jan 2011.

[14] W. R. Gilks and C. Berzuini. Following a moving target – monte carlo inference for dynamic bayesian
models. Journal of the Royal Statistical Society: Series B (Statistical Methodology)  63(1):127–146 
2001.

[15] N. C. Rust  Schwartz O.  J. A. Movshon  and Simoncelli E.P. Spatiotemporal elements of macaque v1

receptive ﬁelds. Neuron  46(6):945–956  2005.

9

,Hongseok Namkoong
John Duchi
Lars Mescheder
Sebastian Nowozin
Andreas Geiger