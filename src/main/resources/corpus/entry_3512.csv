2019,Modeling Tabular data using Conditional GAN,Modeling the probability distribution of rows in tabular data and generating realistic synthetic data is a non-trivial task. Tabular data usually contains a mix of discrete and continuous columns. Continuous columns may have multiple modes whereas discrete columns are sometimes imbalanced making the modeling difficult. Existing statistical and deep neural network models fail to properly model this type of data. We design CTGAN  which uses a conditional generative adversarial network to address these challenges. To aid in a fair and thorough comparison  we design a benchmark with 7 simulated and 8 real datasets and several Bayesian network baselines. CTGAN outperforms Bayesian methods on most of the real datasets whereas other deep learning methods could not.,Modeling Tabular Data using Conditional GAN

Lei Xu
MIT LIDS

Cambridge  MA
leix@mit.edu

Maria Skoularidou

MRC-BSU  University of Cambridge

Cambridge  UK

ms2407@cam.ac.uk

Alfredo Cuesta-Infante

Universidad Rey Juan Carlos

Móstoles  Spain

alfredo.cuesta@urjc.es

Kalyan Veeramachaneni

MIT LIDS

Cambridge  MA

kalyanv@mit.edu

Abstract

Modeling the probability distribution of rows in tabular data and generating realistic
synthetic data is a non-trivial task. Tabular data usually contains a mix of discrete
and continuous columns. Continuous columns may have multiple modes whereas
discrete columns are sometimes imbalanced making the modeling difﬁcult. Existing
statistical and deep neural network models fail to properly model this type of data.
We design CTGAN  which uses a conditional generator to address these challenges.
To aid in a fair and thorough comparison  we design a benchmark with 7 simulated
and 8 real datasets and several Bayesian network baselines. CTGAN outperforms
Bayesian methods on most of the real datasets whereas other deep learning methods
could not.

1

Introduction

Table 1: The number of wins of a particular method
compared with the corresponding Bayesian network
against an appropriate metric on 8 real datasets.

Recent developments in deep generative mod-
els have led to a wealth of possibilities. Us-
ing images and text  these models can learn
probability distributions and draw high-quality
realistic samples. Over the past two years 
the promise of such models has encouraged
the development of generative adversarial net-
works (GANs) [10] for tabular data genera-
tion. GANs offer greater ﬂexibility in model-
ing distributions than their statistical counter-
parts. This proliferation of new GANs neces-
sitates an evaluation mechanism. To evaluate
these GANs  we used a group of real datasets
to set-up a benchmarking system and imple-
mented three of the most recent techniques. For comparison purposes  we created two baseline
methods using Bayesian networks. After testing these models using both simulated and real datasets 
we found that modeling tabular data poses unique challenges for GANs  causing them to fall short
of the baseline methods on a number of metrics such as likelihood ﬁtness and machine learning
efﬁcacy of the synthetically generated data. These challenges include the need to simultaneously
model discrete and continuous columns  the multi-modal non-Gaussian values within each continuous
column  and the severe imbalance of categorical columns (described in Section 3).

MedGAN  2017 [6]
VeeGAN  2017 [21]
TableGAN  2018 [18]
CTGAN

Method CLBN [7]

PrivBN [28]

outperform

1
0
3
7

1
2
3
8

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

To address these challenges  in this paper  we propose conditional tabular GAN (CTGAN)1  a method
which introduces several new techniques: augmenting the training procedure with mode-speciﬁc
normalization  architectural changes  and addressing data imbalance by employing a conditional
generator and training-by-sampling (described in section 4). When applied to the same datasets
with the benchmarking suite  CTGAN performs signiﬁcantly better than both the Bayesian network
baselines and the other GANs tested  as shown in Table 1.
The contributions of this paper are as follows:
(1) Conditional GANs for synthetic data generation. We propose CTGAN as a synthetic tabular
data generator to address several issues mentioned above. CTGAN outperforms all methods to date
and surpasses Bayesian networks on at least 87.5% of our datasets. To further challenge CTGAN  we
adapt a variational autoencoder (VAE) [15] for mixed-type tabular data generation. We call this TVAE.
VAEs directly use data to build the generator; even with this advantage  we show that our proposed
CTGAN achieves competitive performance across many datasets and outperforms TVAE on 3 datasets.
(2) A benchmarking system for synthetic data generation algorithms.2 We designed a compre-
hensive benchmark framework using several tabular datasets and different evaluation metrics as well
as implementations of several baselines and state-of-the-art methods. Our system is open source
and can be extended with other methods and additional datasets. At the time of this writing  the
benchmark has 5 deep learning methods  2 Bayesian network methods  15 datasets  and 2 evaluation
mechanisms.

2 Related Work

During the past decade  synthetic data has been generated by treating each column in a table as a
random variable  modeling a joint multivariate probability distribution  and then sampling from that
distribution. For example  a set of discrete variables may have been modeled using decision trees
[20] and Bayesian networks [2  28]. Spatial data could be modeled with a spatial decomposition tree
[8  27]. A set of non-linearly correlated continuous variables could be modeled using copulas [19  23].
These models are restricted by the type of distributions and by computational issues  severely limiting
the synthetic data’s ﬁdelity.
The development of generative models using VAEs and  subsequently  GANs and their numerous
extensions [1  11  29  26]  has been very appealing due to the performance and ﬂexibility offered
in representing data. GANs are also used in generating tabular data  especially healthcare records;
for example  [25] uses GANs to generate continuous time-series medical records and [4] proposes
the generation of discrete tabular data using GANs. medGAN [6] combines an auto-encoder and a
GAN to generate heterogeneous non-time-series continuous and/or binary data. ehrGAN [5] generates
augmented medical records. tableGAN [18] tries to solve the problem of generating synthetic data
using a convolutional neural network which optimizes the label column’s quality; thus  generated
data can be used to train classiﬁers. PATE-GAN [14] generates differentially private synthetic data.

3 Challenges with GANs in Tabular Data Generation Task

The task of synthetic data generation task requires training a data synthesizer G learnt from a table
T and then using G to generate a synthetic table Tsyn. A table T contains Nc continuous columns
{C1  . . .   CNc} and Nd discrete columns {D1  . . .   DNd}  where each column is considered to be
a random variable. These random variables follow an unknown joint distribution P(C1:Nc  D1:Nd ).
One row rj = {c1 j  . . .   cNc j  d1 j  . . .   dNd j}  j ∈ {1  . . .   n}  is one observation from the joint
distribution. T is partitioned into training set Ttrain and test set Ttest. After training G on Ttrain 
Tsyn is constructed by independently sampling rows using G. We evaluate the efﬁcacy of a generator
along 2 axes. (1) Likelihood ﬁtness: Do columns in Tsyn follow the same joint distribution as
Ttrain? (2) Machine learning efﬁcacy: When training a classiﬁer or a regressor to predict one column
using other columns as features  can such classiﬁer or regressor learned from Tsyn achieve a similar
performance on Ttest  as a model learned on Ttrain?
Several unique properties of tabular data challenge the design of a GAN model.

1Our CTGAN model is open-sourced at https://github.com/DAI-Lab/CTGAN
2Our benchmark can be found at https://github.com/DAI-Lab/SDGym.

2

Mixed data types. Real-world tabular data consists of mixed types. To simultaneously generate a
mix of discrete and continuous columns  GANs must apply both softmax and tanh on the output.
Non-Gaussian distributions: In images  pixels’ values follow a Gaussian-like distribution  which
can be normalized to [−1  1] using a min-max transformation. A tanh function is usually employed
in the last layer of a network to output a value in this range. Continuous values in tabular data are
usually non-Gaussian where min-max transformation will lead to vanishing gradient problem.
Multimodal distributions. We use kernel density estimation to estimate the number of modes in
a column. We observe that 57/123 continuous columns in our 8 real-world datasets have multiple
modes. Srivastava et al. [21] showed that vanilla GAN couldn’t model all modes on a simple 2D
dataset; thus it would also struggle in modeling the multimodal distribution of continuous columns.
Learning from sparse one-hot-encoded vectors. When generating synthetic samples  a generative
model is trained to generate a probability distribution over all categories using softmax  while the
real data is represented in one-hot vector. This is problematic because a trivial discriminator can
simply distinguish real and fake data by checking the distribution’s sparseness instead of considering
the overall realness of a row.
Highly imbalanced categorical columns. In our datasets we noticed that 636/1048 of the categori-
cal columns are highly imbalanced  in which the major category appears in more than 90% of the
rows. This creates severe mode collapse. Missing a minor category only causes tiny changes to
the data distribution that is hard to be detected by the discriminator. Imbalanced data also leads to
insufﬁcient training opportunities for minor classes.

4 CTGAN Model

CTGAN is a GAN-based method to model tabular data distribution and sample rows from the distri-
bution. In CTGAN  we invent the mode-speciﬁc normalization to overcome the non-Gaussian and
multimodal distribution (Section 4.2). We design a conditional generator and training-by-sampling
to deal with the imbalanced discrete columns (Section 4.3). And we use fully-connected networks
and several recent techniques to train a high-quality model.

4.1 Notations

We deﬁne the following notations.

– x1 ⊕ x2 ⊕ . . .: concatenate vectors x1  x2  . . .
– gumbelτ (x): apply Gumbel softmax[13] with parameter τ on a vector x
– leakyγ(x): apply a leaky ReLU activation on x with leaky ratio γ
– FCu→v(x): apply a linear transformation on a u-dim input to get a v-dim output.

We also use tanh  ReLU  softmax  BN for batch normalization [12]  and drop for dropout [22].

4.2 Mode-speciﬁc Normalization

Properly representing the data is critical in training neural networks. Discrete values can naturally be
represented as one-hot vectors  while representing continuous values with arbitrary distribution is
non-trivial. Previous models [6  18] use min-max normalization to normalize continuous values to
[−1  1]. In CTGAN  we design a mode-speciﬁc normalization to deal with columns with complicated
distributions.
Figure 1 shows our mode-speciﬁc normalization for a continuous column. In our method  each
column is processed independently. Each value is represented as a one-hot vector indicating the
mode  and a scalar indicating the value within the mode. Our method contains three steps.

1. For each continuous column Ci  use variational Gaussian mixture model (VGM) [3] to
estimate the number of modes mi and ﬁt a Gaussian mixture. For instance  in Figure 1  the
VGM ﬁnds three modes (mi = 3)  namely η1  η2 and η3. The learned Gaussian mixture
k=1 µkN (ci j; ηk  φk) where µk and φk are the weight and standard

is PCi(ci j) = (cid:80)3

deviation of a mode respectively.

3

Figure 1: An example of mode-speciﬁc normalization.

2. For each value ci j in Ci  compute the probability of ci j coming from each mode. For
instance  in Figure 1  the probability densities are ρ1  ρ2  ρ3. The probability densities are
computed as ρk = µkN (ci j; ηk  φk).

3. Sample one mode from given the probability density  and use the sampled mode to normalize
the value. For example  in Figure 1  we pick the third mode given ρ1  ρ2 and ρ3. Then
we represent ci j as a one-hot vector βi j = [0  0  1] indicating the third mode  and a scalar
αi j = ci j−η3

to represent the value within the mode.

4φ3

The representation of a row become the concatenation of continuous and discrete columns

rj = α1 j ⊕ β1 j ⊕ . . . ⊕ αNc j ⊕ βNc j ⊕ d1 j ⊕ . . . ⊕ dNd j 

where di j is one-hot representation of a discrete value.

4.3 Conditional Generator and Training-by-Sampling

Traditionally  the generator in a GAN is fed with a vector sampled from a standard multivariate
normal distribution (MVN). By training together with a Discriminator or Critic neural networks  one
eventually obtains a deterministic transformation that maps the standard MVN into the distribution of
the data. This method of training a generator does not account for the imbalance in the categorical
columns. If the training data are randomly sampled during training  the rows that fall into the minor
category will not be sufﬁciently represented  thus the generator may not be trained correctly. If the
training data are resampled  the generator learns the resampled distribution which is different from the
real data distribution. This problem is reminiscent of the “class imbalance” problem in discriminatory
modeling - the challenge however is exacerbated since there is not a single column to balance and the
real data distribution should be kept intact.
Speciﬁcally  the goal is to resample efﬁciently in a way that all the categories from discrete attributes
are sampled evenly (but not necessary uniformly) during the training process  and to recover the
(not-resampled) real data distribution during test. Let k∗ be the value from the i∗th discrete column
Di∗ that has to be matched by the generated samples ˆr  then the generator can be interpreted
as the conditional distribution of rows given that particular value at that particular column  i.e.
ˆr ∼ PG(row|Di∗ = k∗). For this reason  in this paper we name it Conditional generator  and a GAN
built upon it is referred to as Conditional GAN.
Integrating a conditional generator into the architecture of a GAN requires to deal with the following
issues: 1) it is necessary to devise a representation for the condition as well as to prepare an
input for it  2) it is necessary for the generated rows to preserve the condition as it is given  and
3) it is necessary for the conditional generator to learn the real data conditional distribution  i.e.
PG(row|Di∗ = k∗) = P(row|Di∗ = k∗)  so that we can reconstruct the original distribution as

P(row) =

PG(row|Di∗ = k∗)P(Di∗ = k).

(cid:88)

k∈Di∗

We present a solution that consists of three key elements  namely: the conditional vector  the generator
loss  and the training-by-sampling method.

4

Model the distribution of a continuous column with VGM.For each value  compute the probability of each mode.Sample a mode and normalize the value.Figure 2: CTGAN model. The conditional generator can generate synthetic rows conditioned on one of
the discrete columns. With training-by-sampling  the cond and training data are sampled according
to the log-frequency of each category  thus CTGAN can evenly explore all possible discrete values.

Conditional vector. We introduce the vector cond as the way for indicating the condition (Di∗ = k∗).
Recall that all the discrete columns D1  . . .   DNd end up as one-hot vectors d1  . . .   dNd such that
]  for k = 1  . . .  |Di| be
the ith one-hot vector is di = [d(k)
the ith mask vector associated to the ith one-hot vector di. Hence  the condition can be expressed in
terms of these mask vectors as

]  for k = 1  . . .  |Di|. Let mi = [m(k)

i

i

(cid:26) 1

0

m(k)

i =

if i = i∗ and k = k∗ 
otherwise.

Then  deﬁne the vector cond as cond = m1 ⊕ . . . ⊕ mNd. For instance  for two discrete columns 
D1 = {1  2  3} and D2 = {1  2} the condition (D2 = 1) is expressed by the mask vectors m1 =
[0  0  0] and m2 = [1  0]; so cond = [0  0  0  1  0].
Generator loss. During training  the conditional generator is free to produce any set of one-hot
discrete vectors {ˆd1  . . .   ˆdNd}. In particular  given the condition (Di∗ = k∗) in the form of cond
vector  nothing in the feed-forward pass prevents from producing either ˆd(k∗)
i∗ = 1 for
k (cid:54)= k∗. The mechanism proposed to enforce the conditional generator to produce ˆdi∗ = mi∗ is to
penalize its loss by adding the cross-entropy between mi∗ and ˆdi∗  averaged over all the instances of
the batch. Thus  as the training advances  the generator learns to make an exact copy of the given
mi∗ into ˆdi∗.
Training-by-sampling. The output produced by the conditional generator must be assessed by the
critic  which estimates the distance between the learned conditional distribution PG(row|cond) and
the conditional distribution on real data P(row|cond). The sampling of real training data and the
construction of cond vector should comply to help critic estimate the distance. Properly sample
the cond vector and training data can help the model evenly explore all possible values in discrete
columns. For our purposes  we propose the following steps:

i∗ = 0 or ˆd(k)

1. Create Nd zero-ﬁlled mask vectors mi = [m(k)

]k=1...|Di|  for i = 1  . . .   Nd  so the ith
mask vector corresponds to the ith column  and each component is associated to the category
of that column.
2. Randomly select a discrete column Di out of all the Nd discrete columns  with equal
probability. Let i∗ be the index of the column selected. For instance  in Figure 2  the selected
column was D2  so i∗ = 2.

i

probability mass of each value is the logarithm of its frequency in that column.
the range D2 has two values and the ﬁrst one was selected  so k∗ = 1.

3. Construct a PMF across the range of values of the column selected in 2  Di∗  such that the
4. Let k∗ be a randomly selected value according to the PMF above. For instance  in Figure 2 
5. Set the k∗th component of the i∗th mask to one  i.e. m(k∗)
6. Calculate the vector cond = m1 ⊕ ··· mi∗ ⊕ mNd. For instance  in Figure 2  we have the

i∗ = 1.

masks m1 = [0  0  0] and m2∗ = [1  0]  so cond = [0  0  0  1  0].

5

Generator G(.)Critic C(.)Score z ~ N(0  1)Select fromD1 and D2αSay D2 is selectedPick a row from T with D2 = 11  j	β1  j α2  j	β2  jdd1  j2  j α1  j	β1  j α2  j	β2  jdd1  j2  jtrainSelect a categoryfrom D2 D2 D1 00010Say category 1 is selected4.4 Network Structure

Since columns in a row do not have local structure  we use fully-connected networks in generator and
critic to capture all possible correlations between columns. Speciﬁcally  we use two fully-connected
hidden layers in both generator and critic. In generator  we use batch-normalization and Relu
activation function. After two hidden layers  the synthetic row representation is generated using a
mix activation functions. The scalar values αi is generated by tanh  while the mode indicator βi and
discrete values di is generated by gumbel softmax. In critic  we use leaky relu function and dropout
on each hidden layer.
Finally  the conditional generator G(z  cond) can be formally described as

h0 = z ⊕ cond
h1 = h0 ⊕ ReLU(BN(FC|cond|+|z|→256(h0)))
h2 = h1 ⊕ ReLU(BN(FC|cond|+|z|+256→256(h1)))
ˆαi = tanh(FC|cond|+|z|+512→1(h2))
ˆβi = gumbel0.2(FC|cond|+|z|+512→mi(h2))
ˆdi = gumbel0.2(FC|cond|+|z|+512→|Di|(h2))

1 ≤ i ≤ Nc
1 ≤ i ≤ Nc
1 ≤ i ≤ Nd

We use the PacGAN [17] framework with 10 samples in each pac to prevent mode collapse. The archi-
tecture of the critic (with pac size 10) C(r1  . . .   r10  cond1  . . .   cond10) can be formally described
as

h0 = r1 ⊕ . . . ⊕ r10 ⊕ cond1 ⊕ . . . ⊕ cond10
h1 = drop(leaky0.2(FC10|r|+10|cond|→256(h0)))
h2 = drop(leaky0.2(FC256→256(h1)))
C(·) = FC256→1(h2)

We train the model using WGAN loss with gradient penalty [11]. We use Adam optimizer with
learning rate 2 · 10−4.

4.5 TVAE Model

Variational autoencoder is another neural network generative model. We adapt VAE to tabular data
by using the same preprocessing and modifying the loss function. We call this model TVAE. In
TVAE  we use two neural networks to model pθ(rj|zj) and qφ(zj|rj)  and train them using evidence
lower-bound (ELBO) loss [15].
The design of the network pθ(rj|zj) that needs to be done differently so that the probability can
be modeled accurately. In our design  the neural network outputs a joint distribution of 2Nc + Nd
variables  corresponding to 2Nc + Nd variables rj. We assume αi j follows a Gaussian distribution
with different means and variance. All βi j and di j follow a categorical PMF. Here is our design.



h1 = ReLU(FC128→128(zj))
h2 = ReLU(FC128→128(h1))
¯αi j = tanh(FC128→1(h2))
ˆαi j ∼ N (¯αi j  δi)
ˆβi j ∼ softmax(FC128→mi(h2))
ˆdi j ∼ softmax(FC128→|Di|(h2))

pθ(rj|zj) =(cid:81)Nc

P(ˆαi j = αi j)(cid:81)Nc

i=1

i=1

P( ˆβi j = βi j)(cid:81)Nd

i=1

P(ˆαi j = αi j)

1 ≤ i ≤ Nc
1 ≤ i ≤ Nc
1 ≤ i ≤ Nc
1 ≤ i ≤ Nd





Here ˆαi j  ˆβi j  ˆdi j are random variables. And pθ(rj|zj) is the joint distribution of these variables.
In pθ(rj|zj)  weight matrices and δi are parameters in the network. These parameters are trained
using gradient descent.
The modeling for qφ(zj|rj) is similar to conventional VAE.



h1 = ReLU(FC|rj|→128(rj))
h2 = ReLU(FC128→128(h1))
µ = FC128→128(h2)
σ = exp( 1
qφ(zj|rj) ∼ N (µ  σI)

2 FC128→128(h2))

6

TVAE is trained using Adam with learning rate 1e-3.

5 Benchmarking Synthetic Data Generation Algorithms

There are multiple deep learning methods for modeling tabular data. We noticed that all methods
and their corresponding papers neither employed the same datasets nor were evaluated under similar
metrics. This fact made comparison challenging and did not allow for identifying each method’s
weaknesses and strengths vis-a-vis the intrinsic challenges presented when modeling tabular data. To
address this  we developed a comprehensive benchmarking suite.

5.1 Baselines and Datasets

In our benchmarking suite  we have baselines that consist of Bayesian networks (CLBN [7]  PrivBN
[28])  and implementations of current deep learning approaches for synthetic data generation (MedGAN
[6]  VeeGAN [21]  TableGAN [18]). We compare TVAE and CTGAN with these baselines.
Our benchmark contains 7 simulated datasets and 8 real datasets.
Simulated data: We handcrafted a data oracle S to represent a known joint distribution  then sample
Ttrain and Ttest from S. This oracle is either a Gaussian mixture model or a Bayesian network.
We followed procedures found in [21] to generate Grid and Ring Gaussian mixture oracles. We
added random offset to each mode in Grid and called it GridR. We picked 4 well known Bayesian
networks - alarm  child  asia  insurance 3 - and constructed Bayesian network oracles.
Real datasets: We picked 6 commonly used machine learning datasets from UCI machine learning
repository [9]  with features and label columns in a tabular form - adult  census  covertype 
intrusion and news. We picked credit from Kaggle. We also binarized 28 × 28 the MNIST [16]
dataset and converted each sample to 784 dimensional feature vector plus one label column to mimic
high dimensional binary data  called MNIST28. We resized the images to 12 × 12 and used the same
process to generate a dataset we call MNIST12. All in all there are 8 real datasets in our benchmarking
suite.

5.2 Evaluation Metrics and Framework

Given that evaluation of generative models is not a straightforward process  where different metrics
yield substantially diverse results [24]  our benchmarking suite evaluates multiple metrics on multiple
datasets. Simulated data come from a known probability distribution and for them we can evaluate
the generated synthetic data via likelihood ﬁtness metric. For real datasets  there is a machine learning
task and we evaluate synthetic data generation method via machine learning efﬁcacy. Figure 3
illustrates the evaluation framework.
Likelihood ﬁtness metric: On simulated data  we take advantage of simulated data oracle S to
compute the likelihood ﬁtness metric. We compute the likelihood of Tsyn on S as Lsyn. Lsyn prefers
overﬁted models. To overcome this issue  we use another metric  Ltest. We retrain the simulated
data oracle S(cid:48) using Tsyn. S(cid:48) has the same structure but different parameters than S. If S is a
Gaussian mixture model  we use the same number of Gaussian components and retrain the mean and
covariance of each component. If S is a Bayesian network  we keep the same graphical structure and
learn a new conditional distribution on each edge. Then Ltest is the likelihood of Ttest on S(cid:48). This
metric overcomes the issue in Lsyn. It can detect mode collapse. But this metric introduces the prior
knowledge of the structure of S(cid:48) which is not necessarily encoded in Tsyn.
Machine learning efﬁcacy: For a real dataset  we cannot compute the likelihood ﬁtness  instead
we evaluate the performance of using synthetic data as training data for machine learning. We train
prediction models on Tsyn and test prediction models using Ttest. We evaluate the performance
of classiﬁcation tasks using accuracy and F1  and evaluate the regression tasks using R2. For each
dataset  we select classiﬁers or regressors that achieve reasonable performance on each data. (Models
and hyperparameters can be found in supplementary material as well as our benchmark framework.)
Since we are not trying to pick the best classiﬁcation or regression model  we take the the average
performance of multiple prediction models to evaluate our metric for G.

3The structure of Bayesian networks can be found at http://www.bnlearn.com/bnrepository/.

7

Figure 3: Evaluation framework on simulated data (left) and real data (right).

Table 2: Benchmark results over three sets of experiments  namely Gaussian mixture simulated data
(GM Sim.)  Bayesian network simulated data (BN Sim.)  and real data. For GM Sim. and BN Sim. 
we report the average of each metric. For real datasets  we report average F1 for classiﬁcation tasks
and R2 for regression tasks respectively.

GM Sim.

BN Sim.

Method
Identity
CLBN
PrivBN
MedGAN
VEEGAN
TableGAN
TVAE
CTGAN

Lsyn
-2.61
-3.06
-3.38
-7.27
-10.06
-8.24
-2.65
-5.72

Ltest
-2.61
-7.31
-12.42
-60.03
-4.22
-4.12
-5.42
-3.40

Lsyn
-9.33
-10.66
-12.97
-11.14
-15.40
-11.84
-6.76
-11.67

Ltest
-9.36
-9.92
-10.90
-12.15
-13.86
-10.47
-9.59
-10.60

Real

clf
0.743
0.382
0.225
0.137
0.143
0.162
0.519
0.469

reg
0.14
-6.28
-4.49
-8.80
-6.5e6
-3.09
-0.20
-0.43

5.3 Benchmarking Results

We evaluated CLBN  PrivBN  MedGAN  VeeGAN  TableGAN  CTGAN  and TVAE using our benchmark
framework. We trained each model with a batch size of 500. Each model is trained for 300 epochs.
Each epoch contains N/batch_size steps where N is the number of rows in the training set. We
posit that for any dataset  across any metrics except Lsyn  the best performance is achieved by Ttrain.
Thus we present the Identity method which outputs Ttrain.
We summarize the benchmark results in Table 2. Full results table can be found in Supplementary
Material. For simulated data from Gaussian mixture  CLBN and PrivBN suffer because continuous
numeric data has to be discretized before modeling using Bayesian networks. MedGAN  VeeGAN  and
TableGAN all suffer from mode collapse. With mode-speciﬁc normalization  our model performs
well on these 2-dimensional continuous datasets.
On simulated data from Bayesian networks  CLBN and PrivBN have a natural advantage. Our CTGAN
achieves slightly better performance than MedGAN and TableGAN. Surprisingly  TableGAN works
well on these datasets  despite considering discrete columns as continuous values. One possible
reasoning for this is that in our simulated data  most variables have fewer than 4 categories  so
conversion does not cause serious problems.
On real datasets  TVAE and CTGAN outperform CLBN and PrivBN  whereas other GAN models cannot
get as good a result as Bayesian networks. With respect to large scale real datasets  learning a
high-quality Bayesian network is difﬁcult. So models trained on CLBN and PrivBN synthetic data are
36.1% and 51.8% worse than models trained on real data.
TVAE outperforms CTGAN in several cases  but GANs do have several favorable attributes  and this
does not indicate that we should always use VAEs rather than GANs to model tables. The generator
in GANs does not have access to real data during the entire training process; thus  we can make
CTGAN achieve differential privacy [14] easier than TVAE.

8

ParameterizedSimulated DataOracle SsynLikelihood LLikelihood LtestPass the oracleRe-parameterizedOracle S’TrainingDataSynthetic DataGeneratorSyntheticDataTestDataTrainingDataSynthetic DataGeneratorTrain predictionmodelsAccuracyF1R2Test prediction modelsDecision TreeLinear SVMMLPSyntheticDataTestDataLearn oracleparameters fromsynthetic data5.4 Ablation Study

We did an ablation study to understand the usefulness of each of the components in our model.
Table 3 shows the results from the ablation study.
Mode-speciﬁc normalization. In CTGAN  we use variational Gaussian mixture model (VGM) to
normalize continuous columns. We compare it with (1) GMM5: Gaussian mixture model with 5 modes 
(2) GMM10: Gaussian mixture model with 10 modes  and (3) MinMax: min-max normalization to
[−1  1]. Using GMM slightly decreases the performance while min-max normalization gives the
worst performance.
Conditional generator and training-by-sampling: We successively remove these two components.
(1) w/o S.: we ﬁrst disable training-by-sampling in training  but the generator still gets a condition
vector and its loss function still has the cross-entropy term. The condition vector is sampled from
training data frequency instead of log frequency. (2) w/o C.: We further remove the condition
vector in the generator. These ablation results show that both training-by-sampling and conditional
generator are critical for imbalanced datasets. Especially on highly imbalanced dataset such as
credit  removing training-by-sampling results in 0% on F1 metric.
Network architecture: In the paper  we use WGANGP+PacGAN. Here we compare it with three
alternatives  WGANGP only  vanilla GAN loss only  and vanilla GAN + PacGAN. We observe that
WGANGP is more suitable for synthetic data task than vanilla GAN  while PacGAN is helpful for
vanilla GAN loss but not as important for WGANGP.

Table 3: Ablation study results on mode-speciﬁc normalization  conditional generator and training-
by-sampling module  as well as the network architecture. The absolute performance change on real
classiﬁcation datasets (excluding MNIST) is reported.

Model
Performance

Mode-speciﬁc Normalization
GMM5
MinMax
GMM10
-25.7%
-4.1% -8.6%

6 Conclusion

Generater

Network Architechture

w/o S.
WGANGP
-17.8% -36.5% -6.5% +1.75%

w/o C.

GAN

GAN+PacGAN

-5.2%

In this paper we attempt to ﬁnd a ﬂexible and robust model to learn the distribution of columns
with complicated distributions. We observe that none of the existing deep generative models can
outperform Bayesian networks which discretize continuous values and learn greedily. We show
several properties that make this task unique and propose our CTGAN model. Empirically  we show
that our model can learn a better distributions than Bayesian networks. Mode-speciﬁc normalization
can convert continuous values of arbitrary range and distribution into a bounded vector representation
suitable for neural networks. And our conditional generator and training-by-sampling can over come
the imbalance training data issue. Furthermore  we argue that the conditional generator can help
generate data with a speciﬁc discrete value  which can be used for data augmentation. As future
work  we would derive a theoretical justiﬁcation on why GANs can work on a distribution with both
discrete and continuous data.

Acknowledgements

This paper is partially supported by the National Science Foundation Grants ACI-1443068. We
(authors from MIT) also acknowledge generous support provided by Accenture for the synthetic
data generation project. Dr. Cuesta-Infante is funded by the Spanish Government research fundings
RTI2018-098743-B-I00 (MICINN/FEDER) and Y2018/EMT-5062 (Comunidad de Madrid).

References
[1] Martin Arjovsky  Soumith Chintala  and Léon Bottou. Wasserstein generative adversarial

networks. In International Conference on Machine Learning  2017.

9

[2] Laura Aviñó  Matteo Rufﬁni  and Ricard Gavaldà. Generating synthetic but plausible healthcare
record datasets. In KDD workshop on Machine Learning for Medicine and Healthcare  2018.

[3] Christopher M Bishop. Pattern recognition and machine learning. springer  2006.

[4] Ramiro Camino  Christian Hammerschmidt  and Radu State. Generating multi-categorical
samples with generative adversarial networks. In ICML workshop on Theoretical Foundations
and Applications of Deep Generative Models  2018.

[5] Zhengping Che  Yu Cheng  Shuangfei Zhai  Zhaonan Sun  and Yan Liu. Boosting deep
learning risk prediction with generative adversarial networks for electronic health records. In
International Conference on Data Mining. IEEE  2017.

[6] Edward Choi  Siddharth Biswal  Bradley Malin  Jon Duke  Walter F. Stewart  and Jimeng
Sun. Generating multi-label discrete patient records using generative adversarial networks. In
Machine Learning for Healthcare Conference. PMLR  2017.

[7] C Chow and Cong Liu. Approximating discrete probability distributions with dependence trees.

IEEE transactions on Information Theory  14(3):462–467  1968.

[8] Graham Cormode  Cecilia Procopiuc  Divesh Srivastava  Entong Shen  and Ting Yu. Differen-
tially private spatial decompositions. In International Conference on Data Engineering. IEEE 
2012.

[9] Dheeru Dua and Casey Graff. UCI machine learning repository  2017. URL http://archive.

ics.uci.edu/ml.

[10] Ian J. Goodfellow  Jean Pouget-Abadie  Mehdi Mirza  Bing Xu  David Warde-Farley  Sherjil
Ozair  Aaron C. Courville  and Yoshua Bengio. Generative adversarial nets. In Advances in
Neural Information Processing Systems  2014.

[11] Ishaan Gulrajani  Faruk Ahmed  Martin Arjovsky  Vincent Dumoulin  and Aaron C Courville.
Improved training of wasserstein gans. In Advances in Neural Information Processing Systems 
2017.

[12] Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training
by reducing internal covariate shift. In International Conference on International Conference
on Machine Learning  2015.

[13] Eric Jang  Shixiang Gu  and Ben Poole. Categorical reparameterization with gumbel-softmax.

In International Conference on Learning Representations  2016.

[14] James Jordon  Jinsung Yoon  and Mihaela van der Schaar. Pate-gan: Generating synthetic data
with differential privacy guarantees. In International Conference on Learning Representations 
2019.

[15] Diederik P Kingma and Max Welling. Auto-encoding variational bayes. In International

Conference on Learning Representations  2013.

[16] Yann LeCun and Corinna Cortes. MNIST handwritten digit database  2010. URL http:

//yann.lecun.com/exdb/mnist/.

[17] Zinan Lin  Ashish Khetan  Giulia Fanti  and Sewoong Oh. Pacgan: The power of two samples
in generative adversarial networks. In Advances in Neural Information Processing Systems 
2018.

[18] Noseong Park  Mahmoud Mohammadi  Kshitij Gorde  Sushil Jajodia  Hongkyu Park  and
Youngmin Kim. Data synthesis based on generative adversarial networks. In International
Conference on Very Large Data Bases  2018.

[19] Neha Patki  Roy Wedge  and Kalyan Veeramachaneni. The synthetic data vault. In International

Conference on Data Science and Advanced Analytics. IEEE  2016.

[20] Jerome P Reiter. Using cart to generate partially synthetic public use microdata. Journal of

Ofﬁcial Statistics  21(3):441  2005.

10

[21] Akash Srivastava  Lazar Valkov  Chris Russell  Michael U Gutmann  and Charles Sutton.
Veegan: Reducing mode collapse in gans using implicit variational learning. In Advances in
Neural Information Processing Systems  2017.

[22] Nitish Srivastava  Geoffrey Hinton  Alex Krizhevsky  Ilya Sutskever  and Ruslan Salakhutdinov.
Dropout: A simple way to prevent neural networks from overﬁtting. Journal of Machine
Learning Research  15(1):1929–1958  2014.

[23] Yi Sun  Alfredo Cuesta-Infante  and Kalyan Veeramachaneni. Learning vine copula models for

synthetic data generation. In AAAI Conference on Artiﬁcial Intelligence  2018.

[24] Lucas Theis  Aäron van den Oord  and Matthias Bethge. A note on the evaluation of generative

models. In International Conference on Learning Representations  2016.

[25] Alexandre Yahi  Rami Vanguri  Noémie Elhadad  and Nicholas P Tatonetti. Generative adversar-
ial networks for electronic health records: A framework for exploring and evaluating methods
for predicting drug-induced laboratory test trajectories. In NIPS workshop on machine learning
for health care  2017.

[26] Lantao Yu  Weinan Zhang  Jun Wang  and Yong Yu. Seqgan: Sequence generative adversarial

nets with policy gradient. In AAAI Conference on Artiﬁcial Intelligence  2017.

[27] Jun Zhang  Xiaokui Xiao  and Xing Xie. Privtree: A differentially private algorithm for
hierarchical decompositions. In International Conference on Management of Data. ACM  2016.

[28] Jun Zhang  Graham Cormode  Cecilia M Procopiuc  Divesh Srivastava  and Xiaokui Xiao.
Privbayes: Private data release via bayesian networks. ACM Transactions on Database Systems 
42(4):25  2017.

[29] Jun-Yan Zhu  Taesung Park  Phillip Isola  and Alexei A Efros. Unpaired image-to-image
translation using cycle-consistent adversarial networks. In international conference on computer
vision  pages 2223–2232. IEEE  2017.

11

,Lei Xu
Maria Skoularidou
Alfredo Cuesta-Infante
Kalyan Veeramachaneni