2016,Interpretable Distribution Features with Maximum Testing Power,Two semimetrics on probability distributions are proposed  given as the sum of differences of expectations of analytic functions evaluated at spatial or frequency locations (i.e  features). The features are chosen so as to maximize the distinguishability of the distributions  by optimizing a lower bound on test power for a statistical test using these features. The result is a parsimonious and interpretable indication of how and where two distributions differ locally. An empirical estimate of the test power criterion converges with increasing sample size  ensuring the quality of the returned features. In real-world benchmarks on high-dimensional text and image data  linear-time tests using the proposed semimetrics achieve comparable performance to the state-of-the-art quadratic-time maximum mean discrepancy test  while returning human-interpretable features that explain the test results.,Interpretable Distribution Features

with Maximum Testing Power

Wittawat Jitkrittum  Zoltán Szabó  Kacper Chwialkowski  Arthur Gretton

wittawatj@gmail.com

zoltan.szabo.m@gmail.com

kacper.chwialkowski@gmail.com

arthur.gretton@gmail.com

Gatsby Unit  University College London

Abstract

Two semimetrics on probability distributions are proposed  given as the sum of
differences of expectations of analytic functions evaluated at spatial or frequency
locations (i.e  features). The features are chosen so as to maximize the distin-
guishability of the distributions  by optimizing a lower bound on test power for a
statistical test using these features. The result is a parsimonious and interpretable
indication of how and where two distributions differ locally. We show that the
empirical estimate of the test power criterion converges with increasing sample size 
ensuring the quality of the returned features. In real-world benchmarks on high-
dimensional text and image data  linear-time tests using the proposed semimetrics
achieve comparable performance to the state-of-the-art quadratic-time maximum
mean discrepancy test  while returning human-interpretable features that explain
the test results.

Introduction

1
We address the problem of discovering features of distinct probability distributions  with which they
can most easily be distinguished. The distributions may be in high dimensions  can differ in non-trivial
ways (i.e.  not simply in their means)  and are observed only through i.i.d. samples. One application
for such divergence measures is to model criticism  where samples from a trained model are compared
with a validation sample: in the univariate case  through the KL divergence (Cinzia Carota and Polson 
1996)  or in the multivariate case  by use of the maximum mean discrepancy (MMD) (Lloyd and
Ghahramani  2015). An alternative  interpretable analysis of a multivariate difference in distributions
may be obtained by projecting onto a discriminative direction  such that the Wasserstein distance on
this projection is maximized (Mueller and Jaakkola  2015). Note that both recent works require low
dimensionality  either explicitly (in the case of Lloyd and Gharamani  the function becomes difﬁcult
to plot in more than two dimensions)  or implicitly in the case of Mueller and Jaakkola  in that a
large difference in distributions must occur in projection along a particular one-dimensional axis.
Distances between distributions in high dimensions may be more subtle  however  and it is of interest
to ﬁnd interpretable  distinguishing features of these distributions.
In the present paper  we take a hypothesis testing approach to discovering features which best
distinguish two multivariate probability measures P and Q  as observed by samples X := {xi}n
i=1 ⊂ Rd from Q. Non-
i=1
drawn independently and identically (i.i.d.)
parametric two-sample tests based on RKHS distances (Eric et al.  2008; Fromont et al.  2012;
Gretton et al.  2012a) or energy distances (Székely and Rizzo  2004; Baringhaus and Franz  2004)
have as their test statistic an integral probability metric  the Maximum Mean Discrepancy (Gretton
et al.  2012a; Sejdinovic et al.  2013). For this metric  a smooth witness function is computed  such
that the amplitude is largest where the probability mass differs most (e.g. Gretton et al.  2012a 

from P   and Y := {yi}n

30th Conference on Neural Information Processing Systems (NIPS 2016)  Barcelona  Spain.

Figure 1). Lloyd and Ghahramani (2015) used this witness function to compare the model output of
the Automated Statistician (Lloyd et al.  2014) with a reference sample  yielding a visual indication
of where the model fails. In high dimensions  however  the witness function cannot be plotted  and
is less helpful. Furthermore  the witness function does not give an easily interpretable result for
distributions with local differences in their characteristic functions. A more subtle shortcoming is
that it does not provide a direct indication of the distribution features which  when compared  would
maximize test power - rather  it is the witness function norm  and (broadly speaking) its variance
under the null  that determine test power.
Our approach builds on the analytic representations of probability distributions of Chwialkowski
et al. (2015)  where differences in expectations of analytic functions at particular spatial or frequency
locations are used to construct a two-sample test statistic  which can be computed in linear time.
Despite the differences in these analytic functions being evaluated at random locations  the analytic
tests have greater power than linear time tests based on subsampled estimates of the MMD (Gretton
et al.  2012b; Zaremba et al.  2013). Our ﬁrst theoretical contribution  in Sec. 3  is to derive a lower
bound on the test power  which can be maximized over the choice of test locations. We propose two
novel tests  both of which signiﬁcantly outperform the random feature choice of Chwialkowski et al..
The (ME) test evaluates the difference of mean embeddings at locations chosen to maximize the test
power lower bound (i.e.  spatial features); unlike the maxima of the MMD witness function  these
features are directly chosen to maximize the distinguishability of the distributions  and take variance
into account. The Smooth Characteristic Function (SCF) test uses as its statistic the difference of
the two smoothed empirical characteristic functions  evaluated at points in the frequency domain so
as to maximize the same criterion (i.e.  frequency features). Optimization of the mean embedding
kernels/frequency smoothing functions themselves is achieved on a held-out data set with the same
consistent objective.
As our second theoretical contribution in Sec. 3  we prove that the empirical estimate of the test
power criterion asymptotically converges to its population quantity uniformly over the class of
Gaussian kernels. Two important consequences follow: ﬁrst  in testing  we obtain a more powerful
test with fewer features. Second  we obtain a parsimonious and interpretable set of features that best
distinguish the probability distributions. In Sec. 4  we provide experiments demonstrating that the
proposed linear-time tests greatly outperform all previous linear time tests  and achieve performance
that compares to or exceeds the more expensive quadratic-time MMD test (Gretton et al.  2012a).
Moreover  the new tests discover features of text data (NIPS proceedings) and image data (distinct
facial expressions) which have a clear human interpretation  thus validating our feature elicitation
procedure in these challenging high-dimensional testing scenarios.

i=1  Y := {yi}n

2 ME and SCF tests
In this section  we review the ME and SCF tests (Chwialkowski et al.  2015) for two-sample testing.
In Sec. 3  we will extend these approaches to learn features that optimize the power of these tests.
Given two samples X := {xi}n
i=1 ⊂ Rd independently and identically distributed
(i.i.d.) according to P and Q  respectively  the goal of a two-sample test is to decide whether P is
different from Q on the basis of the samples. The task is formulated as a statistical hypothesis test
proposing a null hypothesis H0 : P = Q (samples are drawn from the same distribution) against
an alternative hypothesis H1 : P (cid:54)= Q (the sample generating distributions are different). A test
calculates a test statistic ˆλn from X and Y  and rejects H0 if ˆλn exceeds a predetermined test threshold
(critical value). The threshold is given by the (1 − α)-quantile of the (asymptotic) distribution of ˆλn
under H0 i.e.  the null distribution  and α is the signiﬁcance level of the test.
(cid:80)n
ME test The ME test uses as its test statistic ˆλn  a form of Hotelling’s T-squared statistic  deﬁned
i=1(zi − zn)(zi − zn)(cid:62)  and zi :=
as ˆλn := nz(cid:62)
i=1 zi  Sn := 1
n−1
j=1 ∈ RJ . The statistic depends on a positive deﬁnite kernel k : X × X → R
(k(xi  vj) − k(yi  vj))J
(with X ⊆ Rd)  and a set of J test locations V = {vj}J
j=1 ⊂ Rd. Under H0  asymptotically
ˆλn follows χ2(J)  a chi-squared distribution with J degrees of freedom. The ME test rejects H0
if ˆλn > Tα  where the test threshold Tα is given by the (1 − α)-quantile of the asymptotic null
distribution χ2(J). Although the distribution of ˆλn under H1 was not derived  Chwialkowski et al.
(2015) showed that if k is analytic  integrable and characteristic (in the sense of Sriperumbudur et al.
(2011))  under H1  ˆλn can be arbitrarily large as n → ∞  allowing the test to correctly reject H0.

n zn  where zn := 1
n

n S−1

(cid:80)n

2

(cid:80)n

i=1 δyi where VJ := 1

J

n

(cid:80)J

(cid:80)n

i=1 δxi  and Qn := 1

i vj)  ˆl(xi) cos(x(cid:62)

i vj) − ˆl(yi) sin(y(cid:62)

R2J   where ˆl(x) = (cid:82)
function as φP (v) = (cid:82)

One can intuitively think of the ME test statistic as a squared normalized (by the inverse covariance
n ) L2(X   VJ ) distance of the mean embeddings (Smola et al.  2007) of the empirical measures
S−1
i=1 δvi  and δx is the Dirac measure
Pn := 1
n
concentrated at x. The unnormalized counterpart (i.e.  without S−1
n ) was shown by Chwialkowski
et al. (2015) to be a metric on the space of probability measures for any V. Both variants behave
similarly for two-sample testing  with the normalized version being a semimetric having a more
computationally tractable null distribution  i.e.  χ2(J).
SCF test The SCF uses the test statistic which has the same form as the ME test statistic with
j=1 ∈
a modiﬁed zi := [ˆl(xi) sin(x(cid:62)
Rd exp(−iu(cid:62)x)l(u) du is the Fourier transform of l(x)  and l : Rd → R
is an analytic translation-invariant kernel i.e.  l(x − y) deﬁnes a positive deﬁnite kernel for x
and y. In contrast to the ME test deﬁning the statistic in terms of spatial locations  the locations
V = {vj}J
j=1 ⊂ Rd in the SCF test are in the frequency domain. As a brief description  let
ϕP (w) := Ex∼P exp(iw(cid:62)x) be the characteristic function of P . Deﬁne a smooth characteristic
Rd ϕP (w)l(v − w) dw (Chwialkowski et al.  2015  Deﬁnition 2). Then 
similar to the ME test  the statistic deﬁned by the SCF test can be seen as a normalized (by S−1
n )
version of L2(X   VJ ) distance of empirical φP (v) and φQ(v). The SCF test statistic has asymptotic
distribution χ2(2J) under H0. We will use J(cid:48) to refer to the degrees of freedom of the chi-squared
distribution i.e.  J(cid:48) = J for the ME test  and J(cid:48) = 2J for the SCF test.
In this work  we modify the statistic with a regularization parameter γn > 0  giving ˆλn :=
−1 zn  for stability of the matrix inverse. Using multivariate Slutsky’s theorem 
nz(cid:62)
under H0  ˆλn still asymptotically follows χ2(J(cid:48)) provided that γn → 0 as n → ∞.

i vj) − ˆl(yi) cos(y(cid:62)

n (Sn + γnI)

i vj)]J

3 Lower bound on test power  consistency of empirical power statistic
This section contains our main results. We propose to optimize the test locations V and kernel
parameters (jointly referred to as θ) by maximizing a lower bound on the test power in Proposition 1.
This criterion offers a simple objective function for fast parameter tuning. The bound may be of
independent interest in other Hotelling’s T-squared statistics  since apart from the Gaussian case
(e.g. Bilodeau and Brenner  2008  Ch. 8)  the characterization of such statistics under the alternative
distribution is challenging. The optimization procedure is given in Sec. 4. We use Exy as a shorthand
for Ex∼P Ey∼Q and let (cid:107) · (cid:107)F be the Frobenius norm.
Proposition 1 (Lower bound on ME test power). Let K be a uniformly bounded (i.e.  ∃B < ∞
such that supk∈K sup(x y)∈X 2 |k(x  y)| ≤ B) family of k : X × X → R measurable ker-
nels. Let V be a collection in which each element is a set of J test locations. Assume that
of the ME test satisﬁes

˜c := supV∈V k∈K (cid:107)Σ−1(cid:107)F < ∞. Then  the test power P(cid:16)ˆλn ≥ Tα
P(cid:16)ˆλn ≥ Tα

(cid:17) ≥ L(λn) where

(cid:17)

L(λn) := 1 − 2e−ξ1(λn−Tα)2/n − 2e

− [γn (λn−Tα)(n−1)−ξ2n]2

ξ3n(2n−1)2

− 2e−[(λn−Tα)/3−c3nγn]2γ2

n/ξ4  

and c3  ξ1  . . . ξ4 are positive constants depending on only B  J and ˜c. The parameter λn :=
−1 zn where µ = Exy[z1] and
nµ(cid:62)Σ−1µ is the population counterpart of ˆλn := nz(cid:62)
Σ = Exy[(z1 − µ)(z1 − µ)(cid:62)]. For large n  L(λn) is increasing in λn.
Proof (sketch). The idea is to construct a bound for |ˆλn − λn| which involves bounding (cid:107)zn − µ(cid:107)2
and (cid:107)Sn − Σ(cid:107)F separately using Hoeffding’s inequality. The result follows after a reparameterization

of the bound on P(|ˆλn − λn| ≥ t) to have P(cid:16)ˆλn ≥ Tα

. See Sec. F for details.

n (Sn + γnI)

(cid:17)

Proposition 1 suggests that for large n it is sufﬁcient to maximize λn to maximize a lower bound
on the ME test power. The same conclusion holds for the SCF test (result omitted due to space
constraints). Assume that k is characteristic (Sriperumbudur et al.  2011). It can be shown that
λn = 0 if and only if P = Q i.e.  λn is a semimetric for P and Q. In this sense  one can see λn as
encoding the ease of rejecting H0. The higher λn  the easier for the test to correctly reject H0 when
H1 holds. This observation justiﬁes the use of λn as a maximization objective for parameter tuning.

3

Contributions The statistic ˆλn for both ME and SCF tests depends on a set of test locations V and
a kernel parameter σ. We propose to set θ := {V  σ} = arg maxθ λn = arg maxθ µ(cid:62)Σ−1µ. The
optimization of θ brings two beneﬁts: ﬁrst  it signiﬁcantly increases the probability of rejecting
H0 when H1 holds; second  the learned test locations act as discriminative features allowing an
interpretation of how the two distributions differ. We note that optimizing parameters by maximizing
a test power proxy (Gretton et al.  2012b) is valid under both H0 and H1 as long as the data used
for parameter tuning and for testing are disjoint. If H0 holds  then θ = arg max 0 is arbitrary. Since
the test statistic asymptotically follows χ2(J(cid:48)) for any θ  the optimization does not change the null
distribution. Also  the rejection threshold Tα depends on only J(cid:48) and is independent of θ.
To avoid creating a dependency between θ and the data used for testing (which would affect the null
distribution)  we split the data into two disjoint sets. Let D := (X  Y) and Dtr  Dte ⊂ D such that
Dtr ∩ Dte = ∅ and Dtr ∪ Dte = D. In practice  since µ and Σ are unknown  we use ˆλtr
n/2 in place of
λn  where ˆλtr
n/2 is the test statistic computed on the training set Dtr. For simplicity  we assume that
each of Dtr and Dte has half of the samples in D. We perform an optimization of θ with gradient
ascent algorithm on ˆλtr
n/2(θ)
computed on Dte. The full procedure from tuning the parameters to the actual two-sample test is
summarized in Sec. A.
Since we use an empirical estimate ˆλtr
n/2 in place of λn for parameter optimization  we give a ﬁnite-
sample bound in Theorem 2 guaranteeing the convergence of z(cid:62)
n (Sn + γnI)−1zn to µ(cid:62)Σ−1µ as
n increases  uniformly over all kernels k ∈ K (a family of uniformly bounded kernels) and all test
locations in an appropriate class. Kernel classes satisfying conditions of Theorem 2 include the widely

used isotropic Gaussian kernel class Kg =(cid:8)kσ : (x  y) (cid:55)→ exp(cid:0)−(2σ2)−1(cid:107)x − y(cid:107)2(cid:1) | σ > 0(cid:9)  and
the more general full Gaussian kernel class Kfull = {k : (x  y) (cid:55)→ exp(cid:0)−(x − y)(cid:62)A(x − y)(cid:1) |

n/2(θ). The actual two-sample test is performed using the test statistic ˆλte

A is positive deﬁnite} (see Lemma 5 and Lemma 6).
Theorem 2 (Consistency of ˆλn in the ME test). Let X ⊆ Rd be a measurable set  and V be a
collection in which each element is a set of J test locations. All suprema over V and k are to be
understood as supV∈V and supk∈K respectively. For a class of kernels K on X ⊆ Rd  deﬁne
F1 := {x (cid:55)→ k(x  v) | k ∈ K  v ∈ X}  F2 := {x (cid:55)→ k(x  v)k(x  v(cid:48)) | k ∈ K  v  v(cid:48) ∈ X}  (1)
F3 := {(x  y) (cid:55)→ k(x  v)k(y  v(cid:48)) | k ∈ K  v  v(cid:48) ∈ X}.
(2)
Assume that (1) K is a uniformly bounded (by B) family of k : X × X → R measurable kernels 
(2) ˜c := supV k (cid:107)Σ−1(cid:107)F < ∞  and (3) Fi = {fθi | θi ∈ Θi} is VC-subgraph with VC-index
V C(Fi)  and θ (cid:55)→ fθi(m) is continuous (∀m  i = 1  2  3). Let c1 := 4B2J
J ˜c 
and c3 := 4B2J ˜c2. Let Ci-s (i = 1  2  3) be the universal constants associated to Fi-s according to
Theorem 2.6.7 in van der Vaart and Wellner (2000). Then for any δ ∈ (0  1) with probability at least
1 − δ 

J ˜c  c2 := 4B

√

√

J

+

+ c2

log(cid:2)Cj × V C(Fj)(16e)V C(Fj )(cid:3) +

c1J(TF2 + TF3 ) +

8
γn

c1B2J
n − 1

(cid:112)2π[V C(Fj) − 1]

(cid:33)

2
γn

+ c3γn  where

(cid:114)

2

+ Bζj

2 log(5/δ)

n

 

for j = 1  2  3 and ζ1 = 1  ζ2 = ζ3 = 2.
Proof (sketch). The idea is to lower bound the difference with an expression involving supV k (cid:107)zn −
µ(cid:107)2 and supV k (cid:107)Sn − Σ(cid:107)F . These two quantities can be seen as suprema of empirical processes 
and can be bounded by Rademacher complexities of their respective function classes (i.e.  F1 F2 
and F3). Finally  the Rademacher complexities can be upper bounded using Dudley entropy bound
and VC subgraph properties of the function classes. Proof details are given in Sec. D.

(cid:12)(cid:12)z(cid:62)
n (Sn + γnI)−1zn − µ(cid:62)Σ−1µ(cid:12)(cid:12) = Op(n−1/4) as the rate of convergence. Both

O(n−1/4) 

Theorem 2
supV k

then we

if we

implies

have

that

set

γn

=

4

(cid:12)(cid:12)(cid:12)z

(cid:62)
n (Sn + γnI)

(cid:18) 2

sup
V k
≤ 2TF1
γn
√
2Bζj√
16
n

c1BJ

(cid:32)

(cid:113)

2

TFj =

(cid:12)(cid:12)(cid:12)

−1zn − µ
(cid:62)
2n − 1
n − 1

−1µ
Σ
√

(cid:19)

Proposition 1 and Theorem 2 require ˜c := supV∈V k∈K (cid:107)Σ−1(cid:107)F < ∞ as a precondition.
To guarantee that ˜c < ∞  a concrete construction of K is the isotropic Gaussian ker-
nel class Kg  where σ is constrained to be in a compact set. Also  consider V := {V |
any two locations are at least  distance apart  and all test locations have their norms bounded by ζ}
for some   ζ > 0. Then  for any non-degenerate P  Q  we have ˜c < ∞ since (σ V) (cid:55)→ λn is
continuous  and thus attains its supremum over compact sets K and V.

4 Experiments

P
N (0d  Id) N (0d  Id)

Q

Table 1: Four toy problems. H0 holds only in SG.

Data
SG
GMD N (0d  Id) N ((1  0  . . .   0)(cid:62)  Id)
GVD N (0d  Id) N (0d  diag(2  1  . . .   1))
Blobs Gaussian mixtures in R2 as studied in
Chwialkowski et al. (2015); Gretton
et al. (2012b).

In this section  we demonstrate the effectiveness
of the proposed methods on both toy and real
problems. We consider the isotropic Gaussian
kernel class Kg in all kernel-based tests. We
study seven two-sample test algorithms. For the
SCF test  we set ˆl(x) = k(x  0). Denote by ME-
full and SCF-full the ME and SCF tests whose
test locations and the Gaussian width σ are fully
optimized using gradient ascent on a separate
training sample (Dtr) of the same size as the
test set (Dte). ME-grid and SCF-grid are as in
Chwialkowski et al. (2015) where only the Gaus-
sian width is optimized by a grid search 1and
the test locations are randomly drawn from a
multivariate normal distribution. MMD-quad
(quadratic-time) and MMD-lin (linear-time) re-
fer to the nonparametric tests based on maximum mean discrepancy of Gretton et al. (2012a)  where
to ensure a fair comparison  the Gaussian kernel width is also chosen so as to maximize a criterion
for the test power on training data  following the same principle as (Gretton et al.  2012b). For MMD-
quad  since its null distribution is given by an inﬁnite sum of weighted chi-squared variables (no
closed-form quantiles)  in each trial we randomly permute the two samples 400 times to approximate
the null distribution. Finally  T 2 is the standard two-sample Hotelling’s T-squared test  which serves
as a baseline with Gaussian assumptions on P and Q.
In all the following experiments  each problem is repeated for 500 trials. For toy problems  new
samples are generated from the speciﬁed P  Q distributions in each trial. For real problems  samples
are partitioned randomly into training and test sets in each trial. In all of the simulations  we report an
n/2 ≥ Tα) which is the proportion of the number of times the statistic ˆλte
empirical estimate of P(ˆλte
n/2
is above Tα. This quantity is an estimate of type-I error under H0  and corresponds to test power
when H1 is true. We set α = 0.01 in all the experiments. All the code and preprocessed data are
available at https://github.com/wittawatj/interpretable-test.
Optimization The parameter tuning objective ˆλtr
n/2(θ) is a function of θ consisting of one real-valued
σ and J test locations each of d dimensions. The parameters θ can thus be regarded as a Jd + 1
Euclidean vector. We take the derivative of ˆλtr
n/2(θ) with respect to θ  and use gradient ascent to
maximize it. J is pre-speciﬁed and ﬁxed. For the ME test  we initialize the test locations with
realizations from two multivariate normal distributions ﬁtted to samples from P and Q; this ensures
that the initial locations are well supported by the data. For the SCF test  initialization using the
standard normal distribution is found to be sufﬁcient. The parameter γn is not optimized; we set
the regularization parameter γn to be as small as possible while being large enough to ensure that
(Sn + γnI)−1 can be stably computed. We emphasize that both the optimization and testing are
linear in n. The testing cost O(J 3 + J 2n + dJn) and the optimization costs O(J 3 + dJ 2n) per
gradient ascent iteration. Runtimes of all methods are reported in Sec. C in the appendix.
1. Informative features: simple demonstration We begin with a demonstration that the proxy
ˆλtr
n/2(θ) for the test power is informative for revealing the difference of the two samples in the ME
1Chwialkowski et al. (2015) chooses the Gaussian width that minimizes the median of the p-values  a
heuristic that does not directly address test power. Here  we perform a grid search to choose the best Gaussian
width by maximizing ˆλtr

n/2 as done in ME-full and SCF-full.

5

−10−50510−10−50510Blobs data. Sample from P.−10−50510−10−50510Blobs data. Sample from Q.(a) SG. d = 50.

(b) GMD. d = 100.

(c) GVD. d = 50.

(d) Blobs.

Figure 2: Plots of type-I error/test power against the test sample size nte in the four toy problems.

n/2(v1  v2).

test. We consider the Gaussian Mean Difference (GMD) problem (see Table 1)  where both P and Q
are two-dimensional normal distributions with the difference in means. We use J = 2 test locations
v1 and v2  where v1 is ﬁxed to the location indicated by the black triangle in Fig. 1. The contour plot
shows v2 (cid:55)→ ˆλtr
Fig. 1 (top) suggests that ˆλtr
n/2 is maximized when v2 is placed in either of the two regions that
captures the difference of the two samples i.e.  the region in which the probability masses of P and
Q have less overlap. Fig. 1 (bottom)  we consider placing v1 in one of the two key regions. In this
case  the contour plot shows that v2 should be placed in the other region to maximize ˆλtr
n/2  implying
that placing multiple test locations in the same neighborhood will not increase the discriminability.
The two modes on the left and right suggest two ways to place the test location in a region that
reveals the difference. The non-convexity of the ˆλtr
n/2 is an indication of many informative ways to
detect differences of P and Q  rather than a drawback. A convex objective would not capture this
multimodality.
2. Test power vs. sample size n We now demonstrate the rate of in-
crease of test power with sample size. When the null hypothesis holds  the
type-I error stays at the speciﬁed level α. We consider the following four
toy problems: Same Gaussian (SG)  Gaussian mean difference (GMD) 
Gaussian variance difference (GVD)  and Blobs. The speciﬁcations of
P and Q are summarized in Table. 1. In the Blobs problem  P and Q are
deﬁned as a mixture of Gaussian distributions arranged on a 4 × 4 grid in
R2. This problem is challenging as the difference of P and Q is encoded
at a much smaller length scale compared to the global structure (Gretton
et al.  2012b). Speciﬁcally  the eigenvalue ratio for the covariance of each
Gaussian distribution is 2.0 in P   and 1.0 in Q. We set J = 5 in this
experiment.
The results are shown in Fig. 2 where type-I error (for SG problem)  and
test power (for GMD  GVD and Blobs problems) are plotted against test
sample size. A number of observations are worth noting. In the SG
problem  we see that the type-I error roughly stays at the speciﬁed level:
the rate of rejection of H0 when it is true is roughly at the speciﬁed level
α = 0.01.
GMD with 100 dimensions turns out to be an easy problem for all the
tests except MMD-lin. In the GVD and Blobs cases  ME-full and SCF-
full achieve substantially higher test power than ME-grid and SCF-grid 
respectively  suggesting a clear advantage from optimizing the test locations. Remarkably  ME-full
consistently outperforms the quadratic-time MMD across all test sample sizes in the GVD case. When
the difference of P and Q is subtle as in the Blobs problem  ME-grid  which uses randomly drawn
test locations  can perform poorly (see Fig. 2d) since it is unlikely that randomly drawn locations will
be placed in the key regions that reveal the difference. In this case  optimization of the test locations
can considerably boost the test power (see ME-full in Fig. 2d). Note also that SCF variants perform
signiﬁcantly better than ME variants on the Blobs problem  as the difference in P and Q is localized
in the frequency domain; ME-full and ME-grid would require many more test locations in the spatial
domain to match the test powers of the SCF variants. For the same reason  SCF-full does much better
than the quadratic-time MMD across most sample sizes  as the latter represents a weighted distance
between characteristic functions integrated across the entire frequency domain (Sriperumbudur et al. 
2010  Corollary 4).

Figure 1: A contour plot
of ˆλtr
n/2 as a function of
v2 when J = 2 and
v1 is ﬁxed (black trian-
gle). The objective ˆλtr
n/2
is high in the regions that
reveal the difference of
the two samples.

6

10002000300040005000Test sample size0.0000.0050.0100.0150.020Type-I error10002000300040005000Test sample size0.00.20.40.60.81.0Test power10002000300040005000Test sample size0.00.20.40.60.81.0Test power10002000300040005000Test sample size0.00.20.40.60.81.0Test powerME-fullME-gridSCF-fullSCF-gridMMD-quadMMD-linT2v2↦^¸trn=2(v1;v2)020406080100120140160v2↦^¸trn=2(v1;v2)128136144152160168176184192(a) SG

(b) GMD

(c) GVD

Figure 3: Plots of type-I error/test power against the dimensions d in the four toy problems in Table 1.

Table 2: Type-I errors and powers of various tests in the problem of distinguishing NIPS papers from
two categories. α = 0.01. J = 1. nte denotes the test sample size of each of the two samples.

Problem
Bayes-Bayes
Bayes-Deep
Bayes-Learn
Bayes-Neuro
Learn-Deep
Learn-Neuro

nte ME-full ME-grid
215
216
138
394
149
146

.012
.954
.990
1.00
.956
.960

.018
.034
.774
.300
.052
.572

SCF-full

SCF-grid MMD-quad MMD-lin

.012
.688
.836
.828
.656
.590

.004
.180
.534
.500
.138
.360

.022
.906
1.00
.952
.876
1.00

.008
.262
.238
.972
.500
.538

3. Test power vs. dimension d We next investigate how the dimension (d) of the problem can
affect type-I errors and test powers of ME and SCF tests. We consider the same artiﬁcial problems:
SG  GMD and GVD. This time  we ﬁx the test sample size to 10000  set J = 5  and vary the
dimension. The results are shown in Fig. 3. Due to the large dimensions and sample size  it is
computationally infeasible to run MMD-quad.
We observe that all the tests except the T-test can maintain type-I error at roughly the speciﬁed
signiﬁcance level α = 0.01 as dimension increases. The type-I performance of the T-test is incorrect
at large d because of the difﬁculty in accurately estimating the covariance matrix in high dimensions.
It is interesting to note the high performance of ME-full in the GMD problem in Fig. 3b. ME-full
achieves the maximum test power of 1.0 throughout and matches the power T-test  in spite of being
nonparametric and making no assumption on P and Q (the T-test is further advantaged by its excessive
Type-I error). However  this is true only with optimization of the test locations. This is reﬂected in
the test power of ME-grid in Fig. 3b which drops monotonically as dimension increases  highlighting
the importance of test location optimization. The performance of MMD-lin degrades quickly with
increasing dimension  as expected from Ramdas et al. (2015).

4. Distinguishing articles from two categories We now turn to performance on real data. We ﬁrst
consider the problem of distinguishing two categories of publications at the conference on Neural
Information Processing Systems (NIPS). Out of 5903 papers published in NIPS from 1988 to 2015 
we manually select disjoint subsets related to Bayesian inference (Bayes)  neuroscience (Neuro) 
deep learning (Deep)  and statistical learning theory (Learn) (see Sec. B). Each paper is represented
as a bag of words using TF-IDF (Manning et al.  2008) as features. We perform stemming  remove
all stop words  and retain only nouns. A further ﬁltering of document-frequency (DF) of words that
satisﬁes 5 ≤ DF ≤ 2000 yields approximately 5000 words from which 2000 words (i.e.  d = 2000
dimensions) are randomly selected. See Sec. B for more details on the preprocessing. For ME
and SCF tests  we use only one test location i.e.  set J = 1. We perform 1000 permutations to
approximate the null distribution of MMD-quad in this and the following experiments.
Type-I errors and test powers are summarized in Table. 2. The ﬁrst column indicates the categories of
the papers in the two samples. In Bayes-Bayes problem  papers on Bayesian inference are randomly
partitioned into two samples in each trial. This task represents a case in which H0 holds. Among all
the linear-time tests  we observe that ME-full has the highest test power in all the tasks  attaining a
maximum test power of 1.0 in the Bayes-Neuro problem. This high performance assures that although
different test locations V may be selected in different trials  these locations are each informative. It
is interesting to observe that ME-full has performance close to or better than MMD-quad  which
requires O(n2) runtime complexity. Besides clear advantages of interpretability and linear runtime
of the proposed tests  these results suggest that evaluating the differences in expectations of analytic
functions at particular locations can yield an equally powerful test at a much lower cost  as opposed to

7

530060090012001500Dimension0.0000.0050.0100.0150.0200.025Type-I error530060090012001500Dimension0.00.20.40.60.81.0Test power5100200300400500Dimension0.00.20.40.60.81.0Test powerME-fullME-gridSCF-fullSCF-gridMMD-linT2Table 3: Type-I errors and powers in the problem of distinguishing positive (+) and negative (-) facial
expressions. α = 0.01. J = 1.

Problem nte ME-full ME-grid
± vs. ± 201
+ vs. − 201

.010
.998

.012
.656

SCF-full

SCF-grid MMD-quad MMD-lin

.014
1.00

.002
.750

.018
1.00

.008
.578

j ∈ {0  1} be an indicator variable taking value 1 if ˜vt

j ∈ {1  . . .   d}  and 0 otherwise. Deﬁne ηj :=(cid:80)

computing the RKHS norm of the witness function as done in MMD. Unlike Blobs  however  Fourier
features are less powerful in this setting.
We further investigate the interpretability of the ME test by the following procedure. For the learned
test location vt ∈ Rd (d = 2000) in trial t  we construct ˜vt = (˜vt
j = |vt
j|.
j is among the top ﬁve largest for all
Let ηt
j as a proxy indicating the signiﬁcance of word
j i.e.  ηj is high if word j is frequently among the top ﬁve largest as measured by ˜vt
j. The top seven
words as sorted in descending order by ηj in the Bayes-Neuro problem are spike  markov  cortex 
dropout  recurr  iii  gibb  showing that the learned test locations are highly interpretable. Indeed 
“markov” and “gibb” (i.e.  stemmed from Gibbs) are discriminative terms in Bayesian inference
category  and “spike” and “cortex” are key terms in neuroscience. We give full lists of discriminative
terms learned in all the problems in Sec. B.1. To show that not all the randomly selected 2000 terms
j is modiﬁed to consider the least important words (i.e.  ηj
are informative  if the deﬁnition of ηt
is high if word j is frequently among the top ﬁve smallest as measured by ˜vt
j)  we instead obtain
circumfer  bra  dominiqu  rhino  mitra  kid  impostor  which are not discriminative.

d) such that ˜vt

1  . . .   ˜vt

t ηt

(a) HA (b) NE (c) SU

5. Distinguishing positive and negative emotions
In the ﬁ-
nal experiment  we study how well ME and SCF tests can dis-
tinguish two samples of photos of people showing positive and
negative facial expressions. Our emphasis is on the discrimi-
native features of the faces identiﬁed by ME test showing how
the two groups differ. For this purpose  we use Karolinska Di-
rected Emotional Faces (KDEF) dataset (Lundqvist et al.  1998)
containing 5040 aligned face images of 70 amateur actors  35 fe-
males and 35 males. We use only photos showing front views of
the faces. In the dataset  each actor displays seven expressions:
happy (HA)  neutral (NE)  surprised (SU)  sad (SA)  afraid (AF) 
angry (AN)  and disgusted (DI). We assign HA  NE  and SU
faces into the positive emotion group (i.e.  samples from P )  and
AF  AN and DI faces into the negative emotion group (samples
from Q). We denote this problem as “+ vs. −”. Examples of
six facial expressions from one actor are shown in Fig. 4. Photos
of the SA group are unused to keep the sizes of the two samples
the same. Each image of size 562 × 762 pixels is cropped to exclude the background  resized to
48 × 34 = 1632 pixels (d)  and converted to grayscale.
We run the tests 500 times with the same setting used previously i.e.  Gaussian kernels  and J = 1.
The type-I errors and test powers are shown in Table 3. In the table  “± vs. ±” is a problem in which
all faces expressing the six emotions are randomly split into two samples of equal sizes i.e.  H0 is
true. Both ME-full and SCF-full achieve high test powers while maintaining the correct type-I errors.
As a way to interpret how positive and negative emotions differ  we take an average across trials of
the learned test locations of ME-full in the “+ vs. −” problem. This average is shown in Fig. 4g.
We see that the test locations faithfully capture the difference of positive and negative emotions by
giving more weights to the regions of nose  upper lip  and nasolabial folds (smile lines)  conﬁrming
the interpretability of the test in a high-dimensional setting.

Figure 4: (a)-(f): Six facial expres-
sions of actor AM05 in the KDEF
data. (g): Average across trials of
the learned test locations v1.

(d) AF (e) AN (f) DI

(g) v1

Acknowledgement

We thank the Gatsby Charitable Foundation for the ﬁnancial support.

8

References
L. Baringhaus and C. Franz. On a new multivariate two-sample test. Journal of Multivariate Analysis  88:

190–206  2004.

M. Bilodeau and D. Brenner. Theory of multivariate statistics. Springer Science & Business Media  2008.

S. Bird  E. Klein  and E. Loper. Natural Language Processing with Python. O’Reilly Media  1st edition  2009.

O. Bousquet. New approaches to statistical learning theory. Annals of the Institute of Statistical Mathematics 

55:371–389  2003.

K. Chwialkowski  A. Ramdas  D. Sejdinovic  and A. Gretton. Fast two-sample testing with analytic representa-

tions of probability measures. In NIPS  pages 1972–1980  2015.

G. P. Cinzia Carota and N. G. Polson. Diagnostic measures for model criticism. Journal of the American

Statistical Association  91(434):753–762  1996.

M. Eric  F. R. Bach  and Z. Harchaoui. Testing for homogeneity with kernel Fisher discriminant analysis. In

NIPS  pages 609–616. 2008.

M. Fromont  B. Laurent  M. Lerasle  and P. Reynaud-Bouret. Kernels based tests with non-asymptotic bootstrap

approaches for two-sample problems. In COLT  pages 23.1–23.22  2012.

A. Gretton  K. M. Borgwardt  M. J. Rasch  B. Schölkopf  and A. Smola. A kernel two-sample test. Journal of

Machine Learning Research  13:723–773  2012a.

A. Gretton  D. Sejdinovic  H. Strathmann  S. Balakrishnan  M. Pontil  K. Fukumizu  and B. K. Sriperumbudur.

Optimal kernel choice for large-scale two-sample tests. In NIPS  pages 1205–1213  2012b.

M. R. Kosorok. Introduction to Empirical Processes and Semiparametric Inference. Springer  2008.

J. R. Lloyd and Z. Ghahramani. Statistical model criticism using kernel two sample tests. In NIPS  pages

829–837  2015.

J. R. Lloyd  D. Duvenaud  R. Grosse  J. B. Tenenbaum  and Z. Ghahramani. Automatic construction and

Natural-Language description of nonparametric regression models. In AAAI  pages 1242–1250  2014.

D. Lundqvist  A. Flykt  and A. Öhman. The Karolinska directed emotional faces-KDEF. Technical report  ISBN

91-630-7164-9  1998.

C. D. Manning  P. Raghavan  and H. Schütze. Introduction to information retrieval. Cambridge University Press 

2008.

J. Mueller and T. Jaakkola. Principal differences analysis: Interpretable characterization of differences between

distributions. In NIPS  pages 1693–1701  2015.

A. Ramdas  S. Jakkam Reddi  B. Póczos  A. Singh  and L. Wasserman. On the decreasing power of kernel and

distance based nonparametric hypothesis tests in high dimensions. In AAAI  pages 3571–3577  2015.

D. Sejdinovic  B. Sriperumbudur  A. Gretton  and K. Fukumizu. Equivalence of distance-based and RKHS-based

statistics in hypothesis testing. Annals of Statistics  41(5):2263–2291  2013.

A. Smola  A. Gretton  L. Song  and B. Schölkopf. A Hilbert space embedding for distributions. In ALT  pages

13–31  2007.

N. Srebro and S. Ben-David. Learning bounds for support vector machines with learned kernels. In COLT 

pages 169–183  2006.

B. Sriperumbudur  A. Gretton  K. Fukumizu  B. Schoelkopf  and G. Lanckriet. Hilbert space embeddings and

metrics on probability measures. Journal of Machine Learning Research  11:1517–1561  2010.

B. K. Sriperumbudur  K. Fukumizu  and G. R. Lanckriet. Universality  characteristic kernels and RKHS

embedding of measures. The Journal of Machine Learning Research  12:2389–2410  2011.

I. Steinwart and A. Christmann. Support Vector Machines. Springer  2008.

G. Székely and M. Rizzo. Testing for equal distributions in high dimension. InterStat  (5)  2004.

A. van der Vaart and J. Wellner. Weak Convergence and Empirical Processes: With Applications to Statistics

(Springer Series in Statistics). Springer  2000.

W. Zaremba  A. Gretton  and M. Blaschko. B-test: A non-parametric  low variance kernel two-sample test. In

NIPS  pages 755–763  2013.

9

,Wittawat Jitkrittum
Zoltán Szabó
Kacper Chwialkowski
Arthur Gretton