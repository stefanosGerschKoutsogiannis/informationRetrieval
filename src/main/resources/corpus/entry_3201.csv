2018,Life-Long Disentangled Representation Learning with Cross-Domain Latent Homologies,Intelligent behaviour in the real-world requires the ability to acquire new knowledge from an ongoing sequence of experiences while preserving and reusing past knowledge. We propose a novel algorithm for unsupervised representation learning from piece-wise stationary visual data: Variational Autoencoder with Shared Embeddings (VASE). Based on the Minimum Description Length principle  VASE automatically detects shifts in the data distribution and allocates spare representational capacity to new knowledge  while simultaneously protecting previously learnt representations from catastrophic forgetting. Our approach encourages the learnt representations to be disentangled  which imparts a number of desirable properties: VASE can deal sensibly with ambiguous inputs  it can enhance its own representations through imagination-based exploration  and most importantly  it exhibits semantically meaningful sharing of latents between different datasets. Compared to baselines with entangled representations  our approach is able to reason beyond surface-level statistics and perform semantically meaningful cross-domain inference.,Life-Long Disentangled Representation

Learning with Cross-Domain Latent Homologies

Alessandro Achille  Tom Eccles  Loic Matthey  Christopher P Burgess 

Nick Watters  Alexander Lerchner  Irina Higgins

{eccles lmatthey cpburgess nwatters lerchner irinah}@google.com

UCLA  DeepMind
achille@cs.ucla.edu 

Abstract

Intelligent behaviour in the real-world requires the ability to acquire new knowledge
from an ongoing sequence of experiences while preserving and reusing past knowl-
edge. We propose a novel algorithm for unsupervised representation learning from
piece-wise stationary visual data: Variational Autoencoder with Shared Embeddings
(VASE). Based on the Minimum Description Length principle  VASE automatically
detects shifts in the data distribution and allocates spare representational capacity to
new knowledge  while simultaneously protecting previously learnt representations
from catastrophic forgetting. Our approach encourages the learnt representations
to be disentangled  which imparts a number of desirable properties: VASE can
deal sensibly with ambiguous inputs  it can enhance its own representations through
imagination-based exploration  and most importantly  it exhibits semantically
meaningful sharing of latents between different datasets. Compared to baselines
with entangled representations  our approach is able to reason beyond surface-level
statistics and perform semantically meaningful cross-domain inference.

1

Introduction

A critical feature of biological intelligence is its capacity for life-long learning [10] – the ability to
acquire new knowledge from a sequence of experiences to solve progressively more tasks  while
maintaining performance on previous ones. This  however  remains a serious challenge for current
deep learning approaches. While current methods are able to outperform humans on many individual
problems [53  37  20]  these algorithms suffer from catastrophic forgetting [14  34  35  43  17].
Training on a new task or environment can be enough to degrade their performance from super-human
to chance level [47]. Another critical aspect of life-long learning is the ability to sensibly reuse
previously learnt representations in new domains (positive transfer). For example  knowing that
strawberries and bananas are not edible when they are green could be useful when deciding whether to
eat a green peach in the future. Finding semantic homologies between visually distinctive domains can
remove the need to learn from scratch on every new environment and hence help with data efﬁciency
– another major drawback of current deep learning approaches [16  30].
But how can an algorithm maximise the informativeness of the representation it learns on one domain
for positive transfer on other domains without knowing a priori what experiences are to come? One
approach might be to capture the important structure of the current environment in a maximally
compact way (to preserve capacity for future learning). Such learning is likely to result in positive
transfer if future training domains share some structural similarity with the old ones. This is a
reasonable expectation to have for most natural (non-adversarial) tasks and environments  since they
tend to adhere to the structure of the real world (e.g. relate to objects and their properties) governed by
the consistent rules of chemistry or physics. A similar motivation underlies the Minimum Description
Length (MDL) principle [45] and disentangled representation learning [8].

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

A

B

C

Figure 1: A: Schematic representation of the life-long learning data distribution. Each dataset/environment
corresponds to a cluster s. Data samples x constituting each cluster can be described by a local set of coordinates
(data generative factors zn). Different clusters may share some data generative factors. B: VASE model architecture
C: Schematic of the “dreaming” feedback loop. We use a snapshot of the model with the old parameters (old 
✓old) to generate an imaginary batch of data xold for a previously experienced dataset sold. While learning in the
current environment  we ensure that the representation is still consistent on the hallucinated “dream” data  and can
reconstruct it (see red dashed lines).

Recent state of the art approaches to unsupervised disentangled representation learning [21  9  25  29]
use a modiﬁed Variational AutoEncoder (VAE) [27  44] framework to learn a representation of
the data generative factors. These approaches  however  only work on independent and identically
distributed (IID) data from a single visual domain. This paper extends this line of work to life-long
learning from piece-wise stationary data  exploiting this setting to learn shared representations across
domains where applicable. The proposed Variational Autoencoder with Shared Embeddings (VASE 
see ﬁg. 1B) automatically detects shifts in the training data distribution and uses this information to
allocate spare latent capacity to novel dataset-speciﬁc disentangled representations  while reusing
previously acquired representations of latent dimensions where applicable. We use latent masking and
a generative “dreaming” feedback loop (similar to [42  51  50  5]) to avoid catastrophic forgetting. Our
approach outperforms [42]  the only other VAE based approach to life-long learning we are aware of.
Furthermore  we demonstrate that the pressure to disentangle endows VASE with a number of useful
properties: 1) dealing sensibly with ambiguous inputs; 2) learning richer representations through
imagination-based exploration; 3) performing semantically meaningful cross-domain inference by
ignoring irrelevant aspects of surface-level appearance.

2 Related work

The existing approaches to continual learning can be broadly separated into three categories: data- 
architecture- or weights-based. The data-based approaches augment the training data on a new task
with the data collected from the previous tasks  allowing for simultaneous multi-task learning on
IID data [11  46  43  34  15]. The architecture-based approaches dynamically augment the network
with new task-speciﬁc modules  which often share intermediate representations to encourage positive
transfer [47  40  48  49]. Both of these types of approaches  however  are inefﬁcient in terms of the
memory requirements once the number of tasks becomes large. The weights-based approaches do
not require data or model augmentation. Instead  they prevent catastrophic forgetting by slowing down
learning in the weights that are deemed to be important for the previously learnt tasks [28  55  39]. This
is a promising direction  however  its application is limited by the fact that it typically uses knowledge
of the task presentation schedule to update the loss function after each switch in the data distribution.
Most of the continual learning literature  including all of the approaches discussed above  have been
developed in task-based settings  where representations are learnt implicitly. While deep networks
learn well in such settings [1  52]  this often comes at a cost of reduced positive transfer. This is
because the implicitly learnt representations often overﬁt to the training task by discarding information
that is irrelevant to the current task but may be required for solving future tasks [1  2  3  52  22]. The
acquisition of useful representations of complex high-dimensional data without task-based overﬁtting
is a core goal of unsupervised learning. Past work [2  4  21] has demonstrated the usefulness of
information-theoretic methods in such settings. These approaches can broadly be seen as efﬁcient
implementations of the Minimum Description Length (MDL) principle for unsupervised learning
[45  18]. The representations learnt through such methods have been shown to help in transfer
scenarios and with data efﬁciency for policy learning in the Reinforcement Learning (RL) context [22].
These approaches  however  do not immediately generalise to non-stationary data. Indeed  life-long
unsupervised representation learning is relatively under-developed [51  50  39]. The majority of recent
work in this direction has concentrated on implicit generative models [51  50]  or non-parametric

2

approaches [36]. Since these approaches do not possess an inference mechanism  they are unlikely
to be useful for subsequent task or policy learning. Furthermore  none of the existing approaches
explicitly investigate meaningful sharing of latent representations between environments.

3 Framework

3.1 Problem formalisation
We assume that there is an a priori unknown set S ={s1 s2 ... sK} of K environments which  between
them  share a setZ ={z1 z2 ... zN} of N independent data generative factors. We assume z⇠N (0  I).
Since we aim to model piece-wise stationary data  it is reasonable to assume s⇠ Cat(⇡1 ... K)  where
⇡k is the probability of observing environment sk. Two environments may use the same generative
factors but render them differently  or they may use a different subset of factors altogether. Given an
environment s  and an environment-dependent subset Z s✓Z of the ground truth generative factors 
it is possible to synthesise a dataset of images xs⇠ p(·|zs s). In order to keep track of which subset
of the N data generative factors is used by each environment s to generate images xs  we introduce
an environment-dependent mask as with dimensionality |a| = N  where as
n = 1 if zn 2Z s and zero
otherwise. A similar masking has also been used by [24] to enforce disentanglement in a single
environment  but assuming additional side-information about the generative factors. Hence  we assume
n is the probability that factor zn is used in environment s. This leads
as ⇠ Bern(!s
to the following generative process (where “” is element-wise multiplication):
1 ... N ) 

1 ... N )  where !s

z⇠N (0  I) 

s⇠ Cat(⇡1 ... K) 

as⇠ Bern(!s

zs = asz 

xs⇠ p(· | zs s)

(1)

Intuitively  we assume that the piece-wise stationary observed data x can be split into clusters
(environments s) (note evidence for similar experience clustering from the animal literature [6]).
Each cluster has a set of standard coordinate axes (a subset of the generative factors z chosen by the
latent mask as) that can be used to parametrise the data in that cluster (ﬁg. 1A). Given a sequence
x = (xs1  xs2  ...) of datasets generated according to the process in eq. (1)  where sk⇠ p(s) is the k-th
sample of the environment  the aim of life-long representation learning can be seen as estimating the
full set of generative factors Z⇡ Sk q(zsk|xsk ) from the environment-speciﬁc subsets of z inferred

on each stationary data cluster xsk. Henceforth  we will drop the subscript k for simplicity of notation.

Inferring the data generative factors

3.2
Observations xs cannot contain information about the generative factors zn that are not relevant for
the environment s. Hence  we use the following form for representing the data generative factors:

q(zs|xs) = as N (µ(x)  (x))+(1as) N (0  I).

(2)
Note that µ and  in eq. (2) depend only on the data x and not on the environment s. This is important
to ensure that the semantic meaning of each latent dimension zn remains consistent for different
environments s. We model the representation q(zs|xs) of the data generative factors as a product of
independent normal distributions to match the assumed prior p(z)⇠N (0  I).
In order to encourage the representation q(zs|xs) to be semantically meaningful  we encourage it to
capture the generative factors of variation within the data xs by following the MDL principle. We
aim to ﬁnd a representation zs that minimises the reconstruction error of the input data xs conditioned
on zs under a constraint on the quantity of information in zs. This leads to the following loss function:
(3)

LMDL( ✓) =Ezs⇠q(·|xs)[log p✓(x | zs s)]
}

Reconstruction error

{z

|

+ |KL(q(zs|xs)||p(z))
}
|

Representation capacity

{z

The loss in eq. (3) is closely related to the -VAE [21] objective L = Ez⇠q(·|x)[log p✓(x|z)] +
 KL(q(z|x)||p(z))  which uses a Lagrangian to limit the latent bottleneck capacity  rather than
an explicit target C. It was shown that optimising the -VAE objective helps with learning a more
semantically meaningful disentangled representation q(z|x) of the data generative factors [21].
However  [9] showed that progressively increasing the target capacity C in eq. (3) throughout training
further improves the disentanglement results reported in [21]  while simultaneously producing sharper

|2

 C

Target

|{z}

3

reconstructions. Progressive increase of the representational capacity also seems intuitively better
suited to continual learning where new information is introduced in a sequential manner. Hence  VASE
optimises the objective function in eq. (3) over a sequence of datasets xs. This  however  requires
a way to infer s and as  as discussed next.

3.3

Inferring the latent mask

↵n =KLExs

batch) ] || p(zn).

Given a dataset xs  we want to infer which latent dimensions zn were used in its generative process
(see eq. (1)). This serves multiple purposes: 1) helps identify the environment s (see next section);
2) helps ignore latent factors zn that encode useful information in some environment but are not used
in the current environment s  in order to prevent retraining and subsequent catastrophic forgetting;
and 3) promotes latent sharing between environments. Remember that eq. (3) indirectly optimises
for Exs[q(zs|xs)] ⇡ p(z) after training on a dataset s. If a new dataset uses the same generative
factors as xs  then the marginal behaviour of the corresponding latent dimensions zn will not change.
On the other hand  if a latent dimension encodes a data generative factor that is irrelevant to the new
dataset  then it will start behaving atypically and stray away from the prior. We capture this intuition
by deﬁning the atypicality score ↵n for each latent dimension zn on a batch of data xs

batch:

(4)
The atypical components are unlikely to be relevant to the current environment  so we mask them out:

batch[ q(zs

n|xs

as

n =⇢ 1  if ↵n <

0  otherwise

(5)

where  is a threshold hyperparameter (see appendices A.2 and A.3 for more details). Note that the
uninformative latent dimensions zn that have not yet learnt to represent any data generative factors  i.e.
n) = p(zn)  are automatically unmasked in this setup (as they will have ↵n⇡ 0). This allows
q(zn|xs
them to be available as spare latent capacity to learn new generative factors when exposed to a new
dataset. Fig. 2 (bottom third panel) shows the sharp changes in ↵n at dataset boundaries during training.

3.4

Inferring the environment

Given the generative process introduced in eq. (1)  it may be tempting to treat the environment s as
a discrete latent variable and learn it through amortised variational inference. However  we found that
in the continual learning scenario this is not a viable strategy. Parametric learning is slow  yet we have
to infer each new data cluster s extremely fast to avoid catastrophic forgetting. Hence  we opt for a fast
non-parametric meta-algorithm motivated by the following intuition. Having already experienced r
datasets during life-long learning  there are two choices when it comes to inferring the current one s: it
is either a new dataset sr+1  or it is one of the r datasets encountered in the past. Intuitively  one way to
check for the former is to see whether the current data xs seems likely under any of the previously seen
environments. This condition on its own is not sufﬁcient though. First  it is possible that environment s
uses a subset of the generative factors used by another environmentZ s✓Z t  in which case environment
t will explain the data xs well  yet it will be an incorrect inference. Hence  we have to ensure that the
subset of the relevant generative factors zs inferred for the current data xs according to section 3.3
matches that of the candidate past dataset t. Second  ﬁnding a past dataset that matches the current
one on the subset of the relevant generative factors without checking the reconstruction accuracy is not
sufﬁcient. For example  an environment with a moving square should not be classiﬁed as being the same
as the environment with a moving triangle  despite the two environments sharing the same generative
factors (the object position). Hence the reconstruction error should be involved in the inference.
Given the considerations above  we infer the environment s for a batch xs

batch according to:

 

if Ezˆs[ p✓(xs

s =⇢ ˆs
batch) is the output of an auxiliary classiﬁer trained to infer the most likely
where ˆs = argmaxs q(s|xs
previously experienced environment ˆs given the current batch xs
batch  Lˆs is the average reconstruction
error observed for the environment ˆs when it was last experienced  and  is a threshold hyperparameter
(see appendix A.2 for details).

batch|zˆs ˆs) ]  Lˆs ^ as = aˆs

sr+1  otherwise

(6)

4

3.5 Preventing catastrophic forgetting
So far we have discussed how VASE integrates knowledge from the current environment into its
representation q(z|x)  but we haven’t yet discussed how we ensure that past knowledge is not
forgotten in the process. Most standard approaches to preventing catastrophic forgetting discussed
in section 2 are either not applicable to a variational context  or do not scale well due to memory
requirements. However  thanks to learning a generative model of the observed environments  we
can prevent catastrophic forgetting by periodically hallucinating (i.e. generating samples) from past
environments using a snapshot of VASE  and making sure that the current version of VASE is still
able to model these samples. A similar “dreaming” feedback loop was used in [42  51  50  5].
More formally  we follow the generative process in eq. (1) to create a batch of samples
xold ⇠ q✓old(·|z sold) using a snapshot of VASE with parameters (old ✓ old) (see ﬁg. 1C). We then
update the current version of VASE according to the following (replacing old with 0 for brevity):

Lpast( ✓) =Ez s0 x0h D[q(z|x0)  q0(z0|x0)]
+D[q✓(x|z s0)  q✓0(x0|z s0)]
|
}
{z
}
where D is a distance between two distributions. For the decoder  which is a product of Bernoulli
random variables  we use the KL divergence as the distance D. For the Gaussian encoder  we tried
0 ⌃1/2
both the KL divergence and the Wasserstein distance W =kµ0µ1k2+k⌃1/2
1 k2. We did not
observe signiﬁcant differences between the two distance metrics for the majority of the hyperparameter
settings. However  we found the gradients of the Wasserstein distance W to be better behaved. Hence 
we use the Wasserstein distance for the encoder and the KL distance for the decoder in all experiments.
The snapshot parameters get synced to the current trainable parameters old   ✓old ✓ every ⌧
training steps  where ⌧ is a hyperparameter. The expectation over simulators sold and latents z in eq. (7)
is done using Monte Carlo sampling (see appendix A.2 for details).

Decoder proximity

Encoder proximity

{z

|

i 

(7)

3.6 Model summary
To summarise  we train our model using a meta-algorithm with both parametric and non-parametric
components. The latter is needed to quickly associate new experiences to an appropriate cluster  so that
learning can happen inside the current experience cluster  without disrupting unrelated clusters. We
initialise the latent representation z to have at least as many dimensions as the total number of the data
generative factors |z||Z| = N  and the softmax layer of the auxiliary environment classiﬁer to be at
least as large as the number of datasets |S| = K. As we observe the sequence of training data  we detect
changes in the environment and dynamically update the internal estimate of r K datasets experienced
so far according to eq. (6). We then train VASE by minimising the following objective function:

L( ✓) =Ezs⇠q(·|xs))[logp✓(x|zs s)] + |KL(q(zs|xs)||p(z))C|2
|
}
+Ez s0 x0h D[q(z|x0)  q0(z0|x0)]+D[q✓(x|z s0)  q✓0(x0|z s0)]i.
|
}

{z
{z

“Dreaming” feedback on past data

MDL on current data

+

4 Experiments

(8)

Continual learning with disentangled shared latents First  we qualitatively assess whether VASE
is able to learn good representations in a continual learning setup. We use a sequence of three datasets:
(1) a moving version of Fashion-MNIST [54] (shortened to moving Fashion)  (2) MNIST [31]  and (3)
a moving version of MNIST (moving MNIST). During training we expect VASE to detect shifts in the
data distribution and dynamically create new experience clusters s  learn a disentangled representation
of each environment without forgetting past environments  and share disentangled factors between
environments in a semantically meaningful way. Fig. 2 (top) compares the performance of VASE to that
of Controlled Capacity Increase-VAE (CCI-VAE) [9]  a model for disentangled representation learning
with the same architecture as VASE but without the modiﬁcations introduced in this paper to allow for
continual learning. It can be seen that unlike VASE  CCI-VAE forgot moving Fashion at the end of the
training sequence. Both models were able to disentangle position from object identity  however  only
VASE was able to meaningfully share latents between the different datasets - the two positional latents

5

Figure 2: We compare VASE to a CCI-VAE baseline. Both are trained on a sequence of three datasets: moving
fashion MNIST (moving Fashion) ! MNIST ! moving MNIST. Top: latent traversals at the end of training
seeded with samples from the three datasets. The value of each latent zn is traversed between -2 and 2 one at a time 
and the corresponding reconstructions are shown. Rows correspond to latent dimensions zn  columns correspond
to the traversal values. Latent use progression throughout training is demonstrated in colour. Bottom: performance
of MNIST and Fashion object classiﬁers and a position regressor trained on the latent space z throughout training.
Note the relative stability of the curves for VASE compared to the baseline. The atypicality proﬁle shows the values
of ↵n through training (different colours indicate different latent dimensions)  with the threshold  indicated by
the dashed black line.

Figure 3: Latent traversals (A) and classiﬁcation accuracy (B) (both as in ﬁg. 2) for VASE trained on a sequence of
moving MNIST ! Fashion ! inverse Fashion ! MNIST ! moving Fashion. See ﬁg. 8 for larger traversals.
are active for two moving datasets but not for the static MNIST. VASE also has moving Fashion- and
MNIST-speciﬁc latents  while CCI-VAE shares all latents between all datasets. VASE use only 8/24 la-
tent dimensions at the end of training. The rest remained as spare capacity for learning on future datasets.

Learning representations for tasks We train object identity classiﬁers (one each for moving
Fashion and MNIST) and an object position regressor on top of the latent representation z⇠ q(z|x)
at regular intervals throughout the continual learning sequence. Good accuracy on these measures
would indicate that at the point of measurement  the latent representation z contained dataset
relevant information  and hence could be useful  e.g. for subsequent policy learning in RL agents.
Figure 2 (bottom) shows that both VASE and CCI-VAE learn progressively more informative latent
representations when exposed to each dataset s  as evidenced by the increasing classiﬁcation accuracy
and decreasing mean squared error (MSE) measures within each stage of training. However  with
CCI-VAE  the accuracy and MSE measures degrade sharply once a domain shift occurs. This is not
the case for VASE  which retains a relatively stable representation.

Ablation study Here we perform a full ablation study to test the importance of the proposed
components for unsupervised life-long representation learning: 1) regularisation towards disentangled
representations (section 3.2)  2) latent masking (section 3.3 - A)  3) environment clustering (section 3.4
- S)  and 4) “dreaming” feedback loop (section 3.5 - D). We use the constraint capacity loss in eq. (3)
for the disentangled experiments  and the standard VAE loss [27  44] for the entangled experiments

6

MNISTFashion MNISTInverted Fashion MNISTMoving Fashion MNISTMoving MNISTLatents (ordered)AddedUnusedUnusedUnusedAddedAddedAddedReusedReusedReusedReusedReusedReusedFrozenFrozenFrozenFrozenFrozenObject ID Classification AccuracyABDISENTANGLED

ENTANGLED

POSITION MSE

CHANGE (*1E-4)

POSITION MSE

CHANGE (*1E-4)

OBJECT ID ACCURACY
CHANGE (%) MIN (*1E-4)
MAX (%)
3.5 (±0.05)
-15.2 (±2.8)
88.6 (±0.4)
3.4 (±0.05)
-13.9 (±1.9)
88.9 (±0.5)
3.3 (±0.04)
-14.4 (±1.9)
88.6 (±0.3)
86.7 (±1.9)
-24.5 (±1.0)
3.3 (±0.04)
87.1 (±1.8)
-28.1 (±0.08)
3.3 (±0.04)
86.3 (±2.5)
-25.2 (±0.5)
3.3 (±0.04)
3.4 (±0.05)
-12.9 (±1.9)
88.3 (±0.3)
-5.4 (±0.3)
88.6 (±0.4)
3.2 (±0.03)

ABLATION
-
S
D
A
SA
DA
SD
SD-[42]
VASE (SDA)
Table 1: Average change in classiﬁcation accuracy/MSE and maximum/minimum average accuracy/MSE when
training an object/position classiﬁer/regressor on top of the learnt representation on the moving Fashion ! MNIST
! moving MNIST sequence. We do a full ablation study of VASE  where D - dreaming feedback loop  S - cluster
inference q(s|xs)  and A - atypicality based latent mask as inference. We compare two versions of our model - one
that is encouraged to learn a disentangled representation through the capacity increase regularisation in eq. (3)  and
an entangled VAE baseline ( = 1). The unablated disentangled version of VASE (SDA) has the best performance.

OBJECT ID ACCURACY
CHANGE (%) MIN (*1E-4)
MAX (%)
4.2 (±0.7)
-12.1 (±0.8)
91.8 (±0.4)
4.5 (±0.8)
-12.2 (±0.03)
91.7 (±0.4)
4.3 (±0.7)
-12.4 (±0.7)
91.8 (±0.4)
88.6 (±0.3)
-19.7 (±0.5)
4.5 (±0.7)
89.9 (±1.3)
-18.3 (±0.4)
4.8 (±0.7)
88.8 (±0.3)
-19.4 (±0.4)
4.6 (±0.7)
4.3 (±0.5)
-11.7 (±0.6)
91.4 (±0.3)
91.9 (±0.1)
-11.6 (±1.1)
4.7 (±0.8)
91.5 (±0.1)
-6.5 (±0.7)
4.2 (±0.4)

24.8 (±13.5)
22.5 (±12.2)
21.4 (±4.9)
67.6 (±107.0)
78.9 (±109.0)
72.2 (±90.0)
20.0 (±3.5)
3.0 (±0.2)

-

10.5 (±2.6)
10.9 (±3.1)
11.7 (±3.2)
47.1 (±26.2)
41.8 (±20.6)
40.2 (±19.2)
11.6 (±1.9)
10.2 (±1.8)
3.9 (±1.1)

-

-

-

Figure 4: A Cross-domain reconstructions on NatLab (outdoors) or EDE (indoors) DM Lab levels. The disentan-
gled VASE ﬁnds semantic homologies between the two datasets (e.g. cacti ! red objects). The entangled VASE
only maps lower level statistics. B Cross-domain reconstructions of samples from moving Fashion into each of the
ﬁve training datasets: moving MNIST (1) ! Fashion (2) ! inverse Fashion (3) ! MNIST (4) ! moving Fashion
(5).

[21]. For each condition we report the average change in the classiﬁcation metrics reported above 
and the average maximum values achieved (see appendix A.6 for details). Table 1 shows that the
unablated VASE (SDA) has the best performance. Note that the entangled baselines perform worse
than the disentangled equivalents  and that the capacity constraint of the CCI-VAE framework does
not signiﬁcantly affect the maximal classiﬁcation accuracy compared to the VAE. It is also worth
noting that VASE outperforms the “SD-[42]” condition  which is similar to the only other VAE-based
approach to continual learning that we are aware of  see [42]. The difference between the SD and
SD-[42] conditions is that the latter also disables the decoder proximity term in eq. (7) to match the
model setup in [42]. The only difference between the SD-[42] and the [42] approaches is that we do not
use variational inference to learn the value of s  opting for a classiﬁcation-based heuristic instead. This
difference is motivated by [42]’s aim to compute a valid variational lower-bound in a life-long setting 
while our aim is to learn semantically shared factors. Hence  we sacriﬁce the probabilistic framework
for a better performing heuristic (see Section 3.4 for more details). Our SD-[42] also does not use
the Information Gain regularizer of [42]  since it would not change the performance of the heuristic.
We have also trained VASE on longer sequences of datasets (moving MNIST ! Fashion ! inverse
Fashion ! MNIST ! moving Fashion) and found similar levels of performance (see ﬁg. 3).
Semantic transfer Here we test whether VASE can learn more sophisticated cross-domain latent
homologies than the positional latents on the moving MNIST and Fashion datasets described above.
Hence  we trained VASE on a sequence of two visually challenging DMLab-30 1 [7] datasets: the
Exploit Deferred Effects (EDE) environment and a randomized version of the Natural Labyrinth
(NatLab) environment (Varying Map Randomized). While being visually very distinct (one being
indoors and the other outdoors)  the two datasets share many data generative factors that have to do with

1https://github.com/deepmind/lab/tree/master/game_scripts/levels/contributed/

dmlab30#dmlab-30

7

NatLab/EDE Cross-Domain ReconstructionsOrigNatLabEDEReconstructions asOrigNatLabEDEReconstructions asDisentangledEntangledOrig(1)Reconstructions as(2)(3)(4)(5)5-Dataset Cross-Domain ReconstructionsDisentangledBAFigure 5: A Top: Ambiguous input examples created by using different interpolation weights between samples
from CelebA and Fashion  and corresponding inferred parameters µ (y axis) and  (light colour range) of q(z|x);
red corresponds to Fashion-speciﬁc latents  blue to CelebA-speciﬁc latents. Middle: Reconstruction samples
p✓(xs|zs s) for different levels of ambiguity conditioned on either dataset. Bottom: Inferred q (s = CelebA
given different levels of input ambiguity (x axis) and different number of ambiguous vs real data samples (y
axis) for the two datasets. VASE deals well with ambiguity  shows context-dependent categorical perception
and uncertainty within its inferred representation parameters. B Imagination-based exploration allows VASE to
imagine the possibility of moving MNIST digits during static MNIST training by using position latents acquired
on moving Fashion. This helps it learn a moving MNIST classiﬁer during static MNIST training without ever
seeing real translations of MNIST digits.

the 3D geometry of the world (e.g. horizon  walls/terrain  objects/cacti) and the agent’s movements
(ﬁrst person optic ﬂow). Hence  the two domains share many semantically related factors z  but these
are rendered into very different visuals x. We compared cross-domain reconstructions of VASE and
an equivalent entangled VAE ( = 1) baseline. The reconstructions were produced by ﬁrst inferring
a latent representation based on a batch from one domain  e.g. zNatLab = q(·|xNatLab)  and then
reconstructing them conditioned on the other domain xxRec = q✓(·|zNatLab sEDE). Figure 4A shows that
VASE discovered the latent homologies between the two domains  while the entangled baseline failed
to do so. VASE learnt the semantic equivalence between the cacti in NatLab and the red objects in
EDE  the brown fog corresponding to the edge of the NatLab world and the walls in EDE (top leftmost
reconstruction)  and the horizon lines in both domains. The entangled baseline  on the other hand 
seemed to rely on the surface-level pixel statistics and hence struggled to produce meaningful cross-
domain reconstructions  attempting to match the texture rather than the semantics of the other domain.
Figure 4B demonstrates that VASE also learns to share semantically meaningful factors in the more
challenging 5-dataset cross-domain reconstruction task (see Figure 8 and Figure 9 for more details).
Note how the position inferred from the moving Fashion dataset is re-used when reconstructing the
image as a moving MNIST digit. Furthermore  the clothing type inferred from the moving Fashion
is largely shared with the static Fashion and the inverted Fashion datasets. This is not always perfect 
however  which highlights one of the limits of our approach. Since the algorithm has only visual
information to work with  the “semantics” can sometimes become entangled with the shallow visual
statistics – e.g. the clothing categories in the normal and the inverted Fashion are sometimes confused
due to the spurious pixel level similarities. The addition of multi-sensory information  or the ability
to interact with the environment may help alleviate this problem by integrating different sensory
modalities and/or affordances of the environment into the semantic representation.

Dealing with ambiguity Natural stimuli are often ambiguous and may be interpreted differently
based on contextual clues. Examples of such processes are common  e.g. visual illusions like the
Necker cube [38]  and may be driven by the functional organisation and the heavy top-down inﬂuences
within the ventral visual stream of the brain [19  41]. To evaluate the ability of VASE to deal with

8

AccuracyTraining stepExplorationmoving Fashion MNISTmoving MNISTTraining stepCelebA/Fashion Interpolation100% / 0%0% / 100%OrigReconstruction samplesprob CelebANo explorationmoving FashionMNISTmoving MNISTInferred q(s=CelebA) - Fashion contextInterpolation (CelebA/Fashion)100% / 0%0% / 100%23% / 77%56% / 44%as Fashionas CelebAas Fashionas CelebAas Fashionas CelebAas Fashionas CelebAprob FashionCelebA: 100%Fashion: 0%CelebA: 0%Fashion: 100%Inferred q(s=CelebA) - CelebA context Number of ambiguous samples (out of 64) Number of ambiguous samples (out of 64)100%/0%0%/100%40%/60%60%/40%100%/0%0%/100%40%/60%60%/40%Interpolation (CelebA/Fashion)01BAambiguous inputs based on the context  we train it on a CelebA [33] ! inverse Fashion sequence  and
test it using ambiguous linear interpolations between samples from the two datasets (ﬁg. 5A  ﬁrst row).
To measure the effects of ambiguity  we varied the interpolation weights between the two datasets. To
measure the effects of context  we presented the ambiguous samples in a batch with real samples from
one of the training datasets  varying the relative proportions of the two. Figure 5A (bottom) shows
the inferred probability of interpreting the ambiguous samples as CelebA q(s = celebA|x). VASE
shows a sharp boundary between interpreting input samples as Fashion or CelebA despite smooth
changes in input ambiguity. Such categorical perception is also characteristic of biological intelligence
[12  13  32]. The decision boundary for categorical perception is affected by the context in which the
ambiguous samples are presented. VASE also represents its uncertainty about the ambiguous inputs
by increasing the inferred variance of the relevant latent dimensions (ﬁg. 5A  second row).

Imagination-driven exploration If we learn a factor of variation in a past environment (e.g.  that
objects can move)  it may be reasonable to hypothesise that it may also be applicable in the current
environment  even if it is not directly observed (e.g in an environment with static objects). Given the
ability to act on an environment  we may then try to realise an imagined conﬁguration to test whether
our hypothesis is correct (e.g. try to move the static objects)  resulting in a form of imagination-driven
exploration. In Appendix A.4 we show how such exploration can be implemented using VASE.
Figure 5B shows that on a moving Fashion ! MNIST ! moving MNIST life-long learning setup 
VASE is able to imagine and learn the concept of “moving MNIST digits” before actually experiencing
it in the moving MNIST training condition.

5 Conclusions

We have introduced VASE  a novel approach to life-long unsupervised representation learning
that builds on recent work on disentangled factor learning [21  9] by introducing several new key
components. Unlike other approaches to continual learning  our algorithm does not require us to
maintain a replay buffer of past datasets  or to change the loss function after each dataset switch. In fact 
it does not require any a priori knowledge of the dataset presentation sequence  since these changes in
data distribution are automatically inferred. We have demonstrated that VASE can learn a disentangled
representation of a sequence of datasets. It does so without experiencing catastrophic forgetting
and by dynamically allocating spare capacity to represent new information. It resolves ambiguity
in a manner that is analogous to the categorical perception characteristic of biological intelligence.
Most importantly  VASE allows for semantically meaningful sharing of latents between different
datasets  which enables it to perform cross-domain inference and imagination-driven exploration.
Taken together  these properties make VASE a promising algorithm for learning representations that
are conducive to subsequent robust and data-efﬁcient RL policy learning.

Acknowledgements

We thank Shakir Mohamed and James Kirkpatrick for useful discussions and feedback.

References
[1] A. Achille and S. Soatto. Emergence of Invariance and Disentangling in Deep Representations. Proceedings

of the ICML Workshop on Principled Approaches to Deep Learning  2017.

[2] A. Achille and S. Soatto. Information dropout: Learning optimal representations through noisy computation.

IEEE Transactions on Pattern Analysis and Machine Intelligence  PP(99):1–1  2018.

[3] A. Achille and S. Soatto. A separation principle for control in the age of deep learning. Annual Review

of Control  Robotics  and Autonomous Systems  1(1):null  2018.

[4] A. A. Alemi  I. Fischer  J. V. Dillon  and K. Murphy. Deep variational information bottleneck. arXiv preprint

arXiv:1612.00410  2016.

[5] B. Ans and S. Rousset. Avoiding catastrophic forgetting by coupling two reverberating neural networks.

Comptes Rendus de l’Académie des Sciences - Series III - Sciences de la Vie  320(12):989–997  1997.

[6] A. Auchter  L. K. Cormack  Y. Niv  F. Gonzalez-Lima  and M. H. Monﬁls. Reconsolidation-extinction
interactions in fear memory attenuation: the role of inter-trial interval variability. Frontiers in behavioral
neuroscience  11:2  2017.

9

[7] C. Beattie  J. Z. Leibo  D. Teplyashin  T. Ward  M. Wainwright  H. Küttler  A. Lefrancq  S. Green  V. Valdés 
A. Sadik  J. Schrittwieser  K. Anderson  S. York  M. Cant  A. Cain  A. Bolton  S. Gaffney  H. King 
D. Hassabis  S. Legg  and S. Petersen. Deepmind lab. arXiv preprint arXiv:1612.03801  2016.

[8] Y. Bengio  A. Courville  and P. Vincent. Representation learning: A review and new perspectives. IEEE

transactions on pattern analysis and machine intelligence  35(8):1798–1828  2013.

[9] C. P. Burgess  I. Higgins  A. Pal  L. Matthey  N. Watters  G. Desjardins  and A. Lerchner. Understanding

disentangling in -VAE. NIPS Workshop of Learning Disentangled Features  2017.

[10] J. Cichon and W.-B. Gan. Branch-speciﬁc dendritic ca2+ spikes cause persistent synaptic plasticity. Nature 

520(7546):180–185  2015.

[11] L. Espeholt  H. Soyer  R. Munos  K. Simonyan  V. Mnih  T. Ward  Y. Doron  V. Firoiu  T. Harley  I. Dunning 
S. Legg  and K. Kavukcuoglu. Impala: Scalable distributed deep-rl with importance weighted actor-learner
architectures. arxiv  2018.

[12] N. L. Etcoff and J. J. Magee. Categorical perception of facial expressions. Cognition  44:227–240  1992.
[13] D. J. Freedman  M. Riesenhuber  T. Poggio  and E. K. Miller. Categorical representation of visual stimuli

in the primate prefrontal cortex. Science  291:312–316  2001.

[14] R. M. French. Catastrophic forgetting in connectionist networks. Trends in cognitive sciences  3(4):128–135 

[15] T. Furlanello  J. Zhao  A. M. Saxe  L. Itti  and B. S. Tjan. Active long term memory networks. arXiv preprint

[16] M. Garnelo  K. Arulkumaran  and M. Shanahan. Towards deep symbolic reinforcement learning. arXiv

1999.

arXiv:1606.02355  2016.

preprint arXiv:1609.05518  2016.

2016.

[17] I. J. Goodfellow  M. Mirza  D. Xiao  A. Courville  and Y. Bengio. An empirical investigation of catastrophic

forgetting in gradient-based neural networks. arxiv  2013.

[18] P. D. Grünwald. The minimum description length principle. MIT press  2007.
[19] B. Gulyas  D. Ottoson  and P. E. Roland. Functional Organisation of the Human Visual Cortex. Wenner–Gren

[20] K. He  X. Zhang  S. Ren  and J. Sun. Delving deep into rectiﬁers: Surpassing human-level performance

International Series  1993.

on imagenet classiﬁcation. ICCV  2015.

[21] I. Higgins  L. Matthey  A. Pal  C. Burgess  X. Glorot  M. Botvinick  S. Mohamed  and A. Lerchner. -VAE:

Learning basic visual concepts with a constrained variational framework. ICLR  2017.

[22] I. Higgins  A. Pal  A. Rusu  L. Matthey  C. Burgess  A. Pritzel  M. Botvinick  C. Blundell  and A. Lerchner.

DARLA: Improving zero-shot transfer in reinforcement learning. ICML  2017.

[23] M. Jaderberg  K. Simonyan  A. Zisserman  et al. Spatial transformer networks. In Advances in neural

information processing systems  pages 2017–2025  2015.

[24] T. Karaletsos  S. Belongie  and G. Rätsch. Bayesian representation learning with oracle constraints. ICLR 

[25] H. Kim and A. Mnih. Disentangling by factorising. arxiv  2017.
[26] D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. ICLR  2015.
[27] D. P. Kingma and M. Welling. Auto-encoding variational bayes. ICLR  2014.
[28] J. Kirkpatrick  R. Pascanu  N. Rabinowitz  J. Veness  G. Desjardins  A. A. Rusu  K. Milan  J. Quan 
T. Ramalho  A. Grabska-Barwinska  D. Hassabis  C. Clopath  D. Kumaran  and R. Hadsell. Overcoming
catastrophic forgetting in neural networks. PNAS  114(13):3521–3526  2017.

[29] A. Kumar  P. Sattigeri  and A. Balakrishnan. Variational inference of disentangled latent concepts from

unlabeled observations. ICLR  2018.

[30] B. M. Lake  T. D. Ullman  J. B. Tenenbaum  and S. J. Gershman. Building machines that learn and think

like people. Behavioral and Brain Sciences  pages 1–101  2016.

[31] Y. LeCun  L. Bottou  Y. Bengio  and P. Haffner. Gradient-based learning applied to document recognition.

Proceedings of the IEEE  86(11):2278–2324  1998.

[32] Y. Liu and B. Jagadeesh. Neural selectivity in anterior inferotemporal cortex for morphed photographic

images during behavioral classiﬁcation or ﬁxation. J. Neurophysiol.  100:966–982  2008.

[33] Z. Liu  P. Luo  X. Wang  and X. Tang. Deep learning face attributes in the wild. ICCV  2015.
[34] J. L. McClelland  B. L. McNaughton  and R. C. O’Reilly. Why there are complementary learning systems in
the hippocampus and neocortex: insights from the successes and failures of connectionist models of learning
and memory. Psychological review  102(3):419  1995.

[35] M. McCloskey and N. J. Cohen. Catastrophic interference in connectionist networks: The sequential

learning problem. The psychology of learning and motivation  24(92):109–165  1989.

[36] K. Milan  J. Veness  J. Kirkpatrick  D. Hassabis  A. Koop  and M. Bowling. The forget-me-not process.

NIPS  2016.

[37] V. Mnih  K. Kavukcuoglu  D. S. Silver  A. A. Rusu  J. Veness  M. G. Bellemare  A. Graves  M. Riedmiller 
A. K. Fidjeland  G. Ostrovski  S. Petersen  C. Beattie  A. Sadik  I. Antonoglou  H. King  D. Kumaran 
D. Wierstra  S. Legg  and D. Hassabis. Human-level control through deep reinforcement learning. Nature 
518(7540):529–533  2015.

10

[38] L. Necker. Observations on some remarkable optical phaenomena seen in switzerland; and on an optical
phaenomenon which occurs on viewing a ﬁgure of a crystal or geometrical solid. London and Edinburgh
Philosophical Magazine and Journal of Science  1(5):329–337  1832.

[39] C. V. Nguyen  Y. Li  T. D. Bui  and R. E. Turner. Variational continual learning. ICLR  2018.
[40] E. Parisotto  J. L. Ba  and R. Salakhutdinov. Actor-mimic: Deep multitask and transfer reinforcement

[41] A. Przybyszewski. Vision: Does top-down processing help us to see? Current Biology  8:135–139  1998.
[42] J. Ramapuram  M. Gregorova  and A. Kalousis. Lifelong generative modeling.
arXiv preprint

learning. ICLR  2015.

arXiv:1705.09847  2017.

[43] R. Ratcliff. Connectionist models of recognition memory: constraints imposed by learning and forgetting

functions. Psychological review  97(2):285  1990.

[44] D. J. Rezende  S. Mohamed  and D. Wierstra. Stochastic backpropagation and approximate inference in

deep generative models. ICML  32(2):1278–1286  2014.

[45] J. Rissanen. Modeling by shortest data description. Automatica  14(5):465–471  1978.
[46] A. Robins. Catastrophic forgetting  rehearsal and pseudorehearsal. Connection Science  7(2):123–146  1995.
[47] A. A. Rusu  N. C. Rabinowitz  G. Desjardins  H. Soyer  J. Kirkpatrick  K. Kavukcuoglu  R. Pascanu  and

R. Hadsell. Progressive neural networks. arxiv  2016.

[48] P. Ruvolo and E. Eaton. Ella: An efﬁcient lifelong learning algorithm. ICML  2013.
[49] J. Schwarz  J. Luketina  W. M. Czarnecki  A. Grabska-Barwinska  Y. W. Teh  R. Pascanu  and R. Hadsell.

Progress & compress: A scalable framework for continual learning. ICML  2018.

[50] A. Seff  A. Beatson  D. Suo  and H. Liu. Continual learning in generative adversarial nets. NIPS  2017.
[51] H. Shin  J. K. Lee  J. Kim  and J. Kim. Continual learning with deep generative replay. NIPS  2017.
[52] R. Shwartz-Ziv and N. Tishby. Opening the black box of deep neural networks via information. arXiv

preprint arXiv:1703.00810  2017.

[53] D. Silver  A. Huang  C. J. Maddison  A. Guez  L. Sifre  G. van den Driessche  J. Schrittwieser  I. Antonoglou 
V. Panneershelvam  M. Lanctot  S. Dieleman  D. Grewe  J. Nham  N. Kalchbrenner  I. Sutskever  T. Lillicrap 
M. Leach  K. Kavukcuoglu  T. Graepel  and D. Hassabis. Mastering the game of Go with deep neural
networks and tree search. Nature  529(7587):484–489  2016.

[54] H. Xiao  K. Rasul  and R. Vollgraf. Fashion-mnist: a novel image dataset for benchmarking machine

learning algorithms. arxiv  2017.

[55] F. Zenke  B. Poole  and S. Ganguli. Continual learning through synaptic intelligence. ICML  2017.

11

,Alessandro Achille
Tom Eccles
Loic Matthey
Chris Burgess
Nicholas Watters
Alexander Lerchner
Irina Higgins