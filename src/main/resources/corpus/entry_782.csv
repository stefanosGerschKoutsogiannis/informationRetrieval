2013,Better Approximation and Faster Algorithm Using the Proximal Average,It is a common practice to approximate complicated'' functions with more friendly ones. In large-scale machine learning applications  nonsmooth losses/regularizers that entail great computational challenges are usually approximated by smooth functions. We re-examine this powerful methodology and point out a nonsmooth approximation which simply pretends  the linearity of the proximal map. The new approximation is justified using a recent convex analysis tool---proximal average  and yields a novel proximal gradient algorithm that is strictly better than the one based on smoothing  without incurring any extra overhead. Numerical experiments conducted on two important applications  overlapping group lasso and graph-guided fused lasso  corroborate the theoretical claims.",Better Approximation and Faster Algorithm Using

the Proximal Average

Department of Computing Science  University of Alberta  Edmonton AB T6G 2E8  Canada

yaoliang@cs.ualberta.ca

Yaoliang Yu

Abstract

It is a common practice to approximate “complicated” functions with more
friendly ones.
In large-scale machine learning applications  nonsmooth
losses/regularizers that entail great computational challenges are usually approxi-
mated by smooth functions. We re-examine this powerful methodology and point
out a nonsmooth approximation which simply pretends the linearity of the proxi-
mal map. The new approximation is justiﬁed using a recent convex analysis tool—
proximal average  and yields a novel proximal gradient algorithm that is strictly
better than the one based on smoothing  without incurring any extra overhead. Nu-
merical experiments conducted on two important applications  overlapping group
lasso and graph-guided fused lasso  corroborate the theoretical claims.

1

Introduction

In many scientiﬁc areas  an important methodology that has withstood the test of time is the ap-
proximation of “complicated” functions by those that are easier to handle. For instance  Taylor’s
expansion in calculus [1]  essentially a polynomial approximation of differentiable functions  has
fundamentally changed analysis  and mathematics more broadly. Approximations are also ubiq-
uitous in optimization algorithms  e.g. various gradient-type algorithms approximate the objective
function with a quadratic upper bound. In some (if not all) cases  there are multiple ways to make
the approximation  and one usually has this freedom of choice. It is perhaps not hard to convince
oneself that there is no approximation that would work best in all scenarios. And one would prob-
ably also agree that a speciﬁc form of approximation should be favored if it well suits our ultimate
goal. Despite of all these common-sense  in optimization algorithms  the smooth approximations are
still dominating  bypassing some recent advances on optimizing nonsmooth functions [2  3]. Part of
the reason  we believe  is the lack of new technical tools.
We consider the composite minimization problem where the objective consists of a smooth loss func-
tion and a sum of nonsmooth functions. Such problems have received increasing attention due to the
arise of structured sparsity [4]  notably the overlapping group lasso [5]  the graph-guided fused lasso
[6] and some others. These structured regularizers  although greatly enhance our modeling capabil-
ity  introduce signiﬁcant new computational challenges as well. Popular gradient-type algorithms
dealing with such composite problems include the generic subgradient method [7]  (accelerated)
proximal gradient (APG) [2  3]  and the smoothed accelerated proximal gradient (S-APG) [8]. The
subgradient method is applicable to any nonsmooth function  although the convergence rate is rather
slow. APG  being a recent advance  can handle simple functions [9] but for more complicated struc-
tured regularizers  an inner iterative procedure is needed  resulting in an overall convergence rate
that could be as slow as the subgradient method [10]. Lastly  S-APG simply runs APG on a smooth
approximation of the original objective  resulting in a much improved convergence rate.
Our work is inspired by the recent advance on nonsmooth optimization [2  3]  of which the building
block is the proximal map of the nonsmooth function. This proximal map is available in closed-form

1

for simple functions but can be quite expensive for more complicated functions such as a sum of
nonsmooth functions we consider here. A key observation we make is that oftentimes the proximal
map for each individual summand can be easily computed  therefore a bold idea is to simply use the
sum of proximal maps  pretending that the proximal map is a linear operator. Somewhat surprisingly 
this naive choice  when combined with APG  results in a novel proximal algorithm that is strictly
better than S-APG  while keeping per-step complexity unchanged. We justify our method via a
new tool from convex analysis—the proximal average [11]. In essence  instead of smoothing the
nonsmooth function  we use a nonsmooth approximation whose proximal map is cheap to evaluate 
after all this is all we need to run APG.
We formally state our problem in Section 2  along with the proposed algorithm. After recalling
the relevant tools from convex analysis in Section 3 we provide the theoretical justiﬁcation of our
method in Section 4. Related works are discussed in Section 5. We test the proposed algorithm in
Section 6 and conclude in Section 7.

2 Problem Formulation

We are interested in solving the following composite minimization problem:

K(cid:88)

k=1

(cid:96)(x) + ¯f (x)  where

¯f (x) =

αkfk(x).

(1)

Here (cid:96) is convex with L0-Lipschitz continuous gradient w.r.t. the Euclidean norm (cid:107) · (cid:107)  and αk ≥
k αk = 1. The usual regularization constant that balances the two terms in (1) is absorbed into

the loss (cid:96). For the functions fk  we assume
Assumption 1. Each fk is convex and Mk-Lipschitz continuous w.r.t. the Euclidean norm (cid:107) · (cid:107).

min
x∈Rd

0 (cid:80)
The abbreviation M 2 =(cid:80)K

k=1 αkM 2

k is adopted throughout.

We are interested in the general case where the functions fk need not be differentiable. As men-
tioned in the introduction  a generic scheme that solves (1) is the subgradient method [7]  of which
each step requires merely an arbitrary subgradient of the objective. With a suitable stepsize  the sub-
gradient method converges1 in at most O(1/2) steps where  > 0 is the desired accuracy. Although
being general  the subgradient method is exceedingly slow  making it unsuitable for many practical
applications.
Another recent algorithm for solving (1) is the (accelerated) proximal gradient (APG) [2  3]  of
which each iteration needs to compute the proximal map of the nonsmooth part ¯f in (1):

P1/L0

¯f

(x) = argmin

y

L0

2 (cid:107)x − y(cid:107)2 + ¯f (y).

(Recall that L0 is the Lipschitz constant of the gradient of the smooth part (cid:96) in (1).) Provided that
√
the proximal map can be computed in constant time  it can be shown that APG converges within
) complexity  signiﬁcantly better than the subgradient method. For some simple functions 
O(1/
the proximal map indeed is available in closed-form  see [9] for a nice survey. However  for more
complicated functions such as the one we consider here  the proximal map itself is expensive to
compute and an inner iterative subroutine is required. Somewhat disappointingly  recent analysis
has shown that such a two-loop procedure can be as slow as the subgradient method [10].
Yet another approach  popularized by Nesterov [8]  is to approximate each nonsmooth component
fk with a smooth function and then run APG. By carefully balancing the approximation and the
convergence requirement of APG  the smoothed accelerated proximal gradient (S-APG) proposed

in [8] converges in at most O((cid:112)1/2 + 1/) steps  again much better than the subgradient method.

The main point of this paper is to further improve S-APG  in perhaps a surprisingly simple way.
The key assumption that we will exploit is the following:
Assumption 2. Each proximal map Pµ
fk

can be computed “easily” for any µ > 0.

1In this paper we satisfy ourselves with convergence in terms of function values  although with additional

assumptions/efforts it is possible to argue for convergence in terms of the iterates.

2

Algorithm 1: PA-APG.
1: Initialize x0 = y1  µ  η1 = 1.
2: for t = 1  2  . . . do
zt = yt − µ∇(cid:96)(yt) 
3:
k αk · Pµ
4:

xt =(cid:80)

√
ηt+1 = 1+
yt+1 = xt + ηt−1

fk
1+4η2
t
2

(zt) 
 
(xt − xt−1).

ηt+1

5:
6:
7: end for

Algorithm 2: PA-PG.

1: Initialize x0  µ.
2: for t = 1  2  . . . do

xt =(cid:80)

4:
5: end for

3:

zt = xt−1 − µ∇(cid:96)(xt−1) 

k αk · Pµ

fk

(zt).

?≈ K(cid:88)

We prefer to leave the exact meaning of “easily” unspeciﬁed  but roughly speaking  the proximal
map should be no more expensive than computing the gradient of the smooth part (cid:96) so that it does
not become the bottleneck. Both Assumption 1 and Assumption 2 are satisﬁed in many important
applications (examples will follow). As it will also become clear later  these assumptions are exactly
those needed by S-APG.
Unfortunately  in general  there is no known efﬁcient way that reduces the proximal map of the
average ¯f to the proximal maps of its individual components fk  therefore the fast scheme APG is
not readily applicable. The main difﬁculty  of course  is due to the nonlinearity of the proximal map
Pµ
f   when treated as an operator on the function f. Despite of this fact  we will “naively” pretend
that the proximal map is linear and use

Pµ
¯f

αkPµ
fk

.

(2)

k=1

Under this approximation  the fast scheme APG can be applied. We give one particular realization
(PA-APG) in Algorithm 1 based on the FISTA in [2]. A simpler (though slower) version (PA-PG)
based on ISTA [2] is also provided in Algorithm 2. Clearly both algorithms are easily parallelizable
if K is large. We remark that any other variation of APG  e.g. [8]  is equally well applicable. Of
course  when K = 1  our algorithm reduces to the corresponding APG scheme.
At this point  one might be suspicious about the usefulness of the “naive” approximation in (2).
Before addressing this well-deserved question  let us ﬁrst point out two important applications where
Assumption 1 and Assumption 2 are naturally satisﬁed.
Example 1 (Overlapping group lasso  [5]). In this example  fk(x) = (cid:107)xgk(cid:107) where gk is a group
(subset) of variables and xg denotes a copy of x with all variables not contained in the group g
set to 0. This group regularizer has been proven quite useful in high-dimensional statistics with the
capability of selecting meaningful groups of features [5]. In the general case where the groups could
overlap as needed  Pµ
Clearly each fk is convex and 1-Lipschitz continuous w.r.t. (cid:107) · (cid:107)  i.e.  Mk = 1 in Assumption 1.
Moreover  the proximal map Pµ
fk

is simply a re-scaling of the variables in group gk  that is

¯f cannot be computed easily.

j (cid:54)∈ gk
j ∈ gk
where (λ)+ = max{λ  0}. Therefore  both of our assumptions are met.
Example 2 (Graph-guided fused lasso  [6]). This example is an enhanced version of the fused lasso
[12]  with some graph structure exploited to improve feature selection in biostatistic applications
[6]. Speciﬁcally  given some graph whose nodes correspond to the feature variables  we let fij(x) =
|xi − xj| for every edge (i  j) ∈ E. For a general graph  the proximal map of the regularizer

(1 − µ/(cid:107)xgk(cid:107))+xj 

(cid:26)xj 

(x)]j =

[Pµ
fk

(3)

 

¯f =(cid:80)

(i j)∈E αijfij  with αij ≥ 0 (cid:80)

(i j)∈E αij = 1  is not easily computable.

Similar as above  each fij is 1-Lipschitz continuous w.r.t.
proximal map Pµ
fij

is easy to compute:

the Euclidean norm. Moreover  the

(cid:26)xs 

[Pµ
fij

(x)]s =

xs − sign(xi − xj) min{µ |xi − xj|/2} 

s (cid:54)∈ {i  j}
s ∈ {i  j} .

(4)

Again  both our assumptions are satisﬁed.

3

Note that in both examples we could have incorporated weights into the component functions fk
or fij  which amounts to changing αk or αij accordingly. We also remark that there are other
applications that fall into our consideration  but for illustration purposes we shall contend ourselves
with the above two examples. More conveniently  both examples have been tried with S-APG [13] 
thus constitute a natural benchmark for our new algorithm.

3 Technical Tools

To justify our new algorithm  we need a few technical tools from convex analysis [14]. Let our
domain H be a real Hilbert space with the inner product (cid:104)· ·(cid:105) and the induced norm (cid:107)·(cid:107). Denote Γ0
as the set of all lower semicontinuous proper convex functions f : H → R∪{∞}. It is well-known
that the Fenchel conjugation

f∗(y) = sup

(cid:104)x  y(cid:105) − f (x)

x

2(cid:107) · (cid:107)2
is a bijection and involution on Γ0 (i.e. (f∗)∗ = f). For convenience  throughout we let q = 1
(q for “quadratic”). Note that q is the only function which coincides with its Fenchel conjugate.
Another convention that we borrow from convex analysis is to write (f µ)(x) = µf (µ−1x) for
µ > 0. We easily verify (µf )∗ = f∗µ and also (f µ)∗ = µf∗.
For any f ∈ Γ0  we deﬁne its Moreau envelop (with parameter µ > 0) [14  15]

1

2µ(cid:107)x − y(cid:107)2 + f (y) 

(5)

and correspondingly the proximal map

Mµ

f (x) = min

y

1

2µ(cid:107)x − y(cid:107)2 + f (y).

Pµ

y

f (x) = argmin

(6)
Since f is closed convex and (cid:107) · (cid:107)2 is strongly convex  the proximal map is well-deﬁned and single-
valued. As mentioned before  the proximal map is the key component of fast schemes such as APG.
We summarize some nice properties of the Moreau envelop and the proximal map as:
Proposition 1. Let µ  λ > 0  f ∈ Γ0  and Id be the identity map  then
i). Mµ

f )∗ = f∗ + µq;
f (x) = inf x f (x)  and argminx Mµ

f ∈ Γ0 and (Mµ
f ≤ f  inf x Mµ
f is differentiable with ∇Mµ
λf = λMλµ
λf = Pλµ

f and Pµ

ii). Mµ

iii). Mµ

iv). Mµ

f = 1

µ (Id − Pµ
f );
f λ−1)λ;

f = (Pµ

f (x) = argminx f (x);

v). Mλ

Mµ
f

= Mλ+µ

f

and Pλ

Mµ
f

= µ

λ+µ Id + λ

λ+µ Pλ+µ

f

;

vi). µMµ

f + (M1/µ

f∗ )µ = q and Pµ

f + (P1/µ

f∗ )µ = Id.

f )∗ in general is different from Mµ
f∗.

i) is the well-known duality between inﬁmal convolution and summation. ii)  albeit being trivial  is
the driving force behind the proximal point algorithm [16]. iii) justiﬁes the “niceness” of the Moreau
envelop and connects it with the proximal map. iv) and v) follow from simple algebra. And lastly
vi)  known as Moreau’s identity [15]  plays an important role in the early development of convex
analysis. We remind that (Mµ
Fix µ > 0. Let SCµ ⊆ Γ0 denote the class of µ-strongly convex functions  that is  functions f
such that f − µq is convex. Similarly  let SSµ ⊆ Γ0 denote the class of ﬁnite-valued functions
the norm (cid:107) · (cid:107)). A well-known duality between
whose gradient is µ-Lipschitz continuous (w.r.t.
strong convexity and smoothness is that for f ∈ Γ0  we have f ∈ SCµ iff f∗ ∈ SS1/µ  cf. [17 
Theorem 18.15]. Based on this duality  we have the next result which turns out to be critical. (Proof
in Appendix A)
Proposition 2. Fix µ > 0. The Moreau envelop map Mµ : Γ0 → SS1/µ that sends f ∈ Γ0 to Mµ
bijective  increasing  and concave on any convex subset of Γ0 (under the pointwise order).

f is

4

k=1 αk = 1. Recall that ¯f =(cid:80)

average—the key object to us. Fix constants αk ≥ 0 with(cid:80)K

It is clear that SS1/µ is a convex subset of Γ0  which motivates the deﬁnition of the proximal
k αkfk
with each fk ∈ Γ0  i.e. ¯f is the convex combination of the component functions {fk} under the
weight {αk}. Note that we always assume ¯f ∈ Γ0 (the exception ¯f ≡ ∞ is clearly uninteresting).
Deﬁnition 1 (Proximal Average  [11  15]). Denote f = (f1  . . .   fK) and f∗ = (f∗
K). The
proximal average Aµ
f  α  or simply Aµ when the component functions and weights are clear from
context  is the unique function h ∈ Γ0 such that Mµ
Indeed  the existence of the proximal average follows from the surjectivity of Mµ while the unique-
ness follows from the injectivity of Mµ  both proven in Proposition 2. The main property of the
proximal average  as seen from its deﬁnition  is that its Moreau envelop is the convex combination
of the Moreau envelops of the component functions. By iii) of Proposition 1 we immediately obtain

h =(cid:80)K

1   . . .   f∗

k=1 αkMµ
fk

.

Pµ

Aµ =

αkPµ
fk

.

(7)

Recall that the right-hand side is exactly the approximation we employed in Section 2.
Interestingly  using the properties we summarized in Proposition 1  one can show that the Fenchel
conjugate of the proximal average  denoted as (Aµ)∗  enjoys a similar property [11]:
αk(q − µMµ

µ = q − µMµ

Aµ = q − µ

M1/µ

(cid:104)

(cid:105)

αkMµ
fk

(Aµ)∗

=

fk

)

K(cid:88)
(cid:35)

k=1

K(cid:88)

k=1

K(cid:88)
(cid:34) K(cid:88)

k=1

k=1

K(cid:88)

k=1

(cid:32)(cid:16) K(cid:88)

f  α)∗ = (cid:80)K

that is  M1/µ
(Aµ
Proposition 2:

=

αk[(M1/µ
f∗

k

)µ] =

αkM1/µ
f∗

k

µ 

k=1 αkM1/µ
f∗

k

= M1/µ
A1/µ
f∗  α

  therefore by the injective property established in

(8)
From its deﬁnition it is also possible to derive an explicit formula for the proximal average (although
for our purpose only the existence is needed):

(Aµ

f  α)∗ = A1/µ
f∗ α.
(cid:33)∗

(cid:17)∗ − µq

=

(cid:16) K(cid:88)

(cid:17)∗ − qµ 

αkM1/µ
f∗

k

Aµ

f  α =

αkMµ
fk

k=1

k=1

(9)

where the second equality is obtained by conjugating (8) and applying the ﬁrst equality to the con-
jugate. By the concavity and monotonicity of Mµ  we have the inequality
Aµ ⇐⇒ ¯f ≥ Aµ.

¯f ≥ K(cid:88)

αkMµ
fk

= Mµ

(10)

Mµ

k=1

f → f pointwise [14]  which  under the Lipschitz assumption 

The above results (after Deﬁnition 1) are due to [11]  although our treatment is slightly different.
It is well-known that as µ → 0  Mµ
can be strengthened to uniform convergence (Proof in Appendix B):
Proposition 3. Under Assumption 1 we have 0 ≤ ¯f − Mµ
Aµ ≤ µM 2
2 .
For the proximal average  [11] showed that Aµ → ¯f pointwise  which again can be strengthened to
uniform convergence (proof follows from (10) and Proposition 3 since Aµ ≥ Mµ
Proposition 4. Under Assumption 1 we have 0 ≤ ¯f − Aµ ≤ µM 2
2 .

Aµ):

As it turns out  S-APG approximates the nonsmooth function ¯f with the smooth function Mµ
Aµ while
our algorithm operates on the nonsmooth approximation Aµ (note that it can be shown that Aµ is
smooth iff some component fi is smooth). By (10) and ii) in Proposition 1 we have

(11)

Aµ ≤ Aµ ≤ ¯f  
Mµ

5

Aµ ≤ Aµ ≤ ¯f. Observe that the proximal
Figure 1: See Example 3 for context. As predicted Mµ
Aµ is smooth everywhere. For x ≥ 0  f1 = f2 =
average Aµ remains nondifferentiable at 0 while Mµ
¯f = Aµ (the red circled line)  thus the proximal average Aµ is a strictly tighter approximation than
smoothing. When µ is small (right panel)  ¯f ≈ Mµ
Aµ ≈ Aµ.

meaning that the proximal average Aµ is a better under-approximation of ¯f than Mµ
Let us compare the proximal average Aµ with the smooth approximation Mµ
Example 3. Let f1(x) = |x|  f2(x) = max{x  0}. Clearly both are 1-Lipschitz continuous. More-
over  Pµ
f1

(x) = (x − µ)+ + x − (x)+ 

(x) = sign(x)(|x| − µ)+  Pµ

Aµ on a 1-D example.

Aµ.

f2

(cid:40) x2

0 

x2
2µ  
x − µ/2 

x ≤ 0
0 ≤ x ≤ µ
otherwise

.

Mµ
f1

(x) =

2µ  
|x| − µ/2 

|x| ≤ µ
otherwise

  and Mµ
f2

(x) =

Finally  using (9) we obtain (with α1 = α  α2 = 1 − α)

x 

Aµ(x) =

x2
2µ  

α
1−α
−αx − (1 − α) αµ

2   x ≤ (α − 1)µ

x ≥ 0
(α − 1)µ ≤ x ≤ 0

.

Figure 1 depicts the case α = 0.5 with different values of the smoothing parameter µ.

4 Theoretical Justiﬁcation
Given our development in the previous section  it is now clear that our proposed algorithm aims at
solving the approximation

(cid:96)(x) + Aµ(x).

min

x

(12)

The next important piece is to show how a careful choice of µ would lead to a strictly better conver-
gence rate than S-APG.
Recall that using APG to slove (12) requires computing the following proximal map in each iteration:

P1/L0

Aµ

(x) = argmin

y

L0

2 (cid:107)x − y(cid:107)2 + Aµ(y) 

which  unfortunately  is not yet amenable to efﬁcient computation  due to the mismatch of the con-
stants 1/L0 and µ (recall that in the decomposition (7) the superscript and subscript must both be µ).
In general  there is no known explicit formula that would reduce P1/L0
f for different positive
constants L0 and µ [17  p. 338]  see also iv) in Proposition 1. Our ﬁx is almost trivial: If necessary 
we use a bigger Lipschitz constant L0 = 1/µ so that we can compute the proximal map easily. This
is indeed legitimate since L0-Lipschitz implies L-Lipschitz for any L ≥ L0. Said differently  all we
need is to tune down the stepsize a little bit in APG. We state formally the convergence property of
our algorithm as (Proof in Appendix C):
Theorem 1. Fix the accuracy  > 0. Under Assumption 1 and the choice µ = min{1/L0  2/ M 2} 
after at most

(cid:113) 2
µ(cid:107)x0 − x(cid:107) steps  the output of Algorithm 1  say ˜x  satisﬁes

to Pµ

f

The same guarantee holds for Algorithm 2 after at most 1

2µ(cid:107)x0 − x(cid:107)2 steps.

(cid:96)(˜x) + ¯f (˜x) ≤ (cid:96)(x) + ¯f (x) + 2.

6

−10−505100246810α=0.5 µ=10  f1f2¯fMη¯fAη−10−505100246810α=0.5 µ=5  f1f2¯fMη¯fAη−10−505100246810α=0.5 µ=1  f1f2¯fMη¯fAηrate O((cid:112)1/)  even though we approximate the nonsmooth function ¯f by the proximal average

Aµ  we would end up with the optimal (overall)

Note that if we could reduce P1/L0

efﬁciently to Pµ

Aµ. In other words  approximation itself does not lead to an inferior rate. It is our incapability to
(efﬁciently) relate proximal maps that leads to the sacriﬁce in convergence rates.

Aµ

5 Discussions

recall

let us

(cid:113)

(cid:113)

max{L0  M 2/(2)}(cid:112)1/) of our approach. In other words  we have managed to

L0 + M 2/(2)(cid:112)1/) steps since the Lipschitz constant of the gradient of (cid:96) + Mµ

To ease our discussion with related works  let us ﬁrst point out a fact that is not always explicitly
recognized  that is  S-APG essentially relies on approximating the nonsmooth function ¯f with Mµ
Aµ.
Indeed  consider ﬁrst the case K = 1. The smoothing idea introduced in [8] purports the superﬁcial
max-structure assumption  that is  f (x) = maxy∈C (cid:104)x  y(cid:105)− h(y) where C is some bounded convex
set and h ∈ Γ0. As it is well-known (also easily veriﬁed from deﬁnition)  f ∈ Γ0 is M-Lipschitz
the norm (cid:107) · (cid:107)) iff dom f∗ ⊆ B(cid:107)·(cid:107)(0  M )  the ball centered at the origin with
continuous (w.r.t.
radius M. Thus the function f ∈ Γ0 admits the max-structure iff it is Lipschitz continuous  i.e. 
satisfying our Assumption 1  in which case h = f∗ and C = dom f∗. [8] proceeded to add some
“distance” function d to obtain the approximation fµ(x) = maxy∈C (cid:104)x  y(cid:105) − f∗(y) − µd(y). For
simplicity  we will only consider d = q  thus fµ = (f∗ + µq)∗ = Mµ
f . The other assumption of
S-APG [8] is that fµ and the maximizer in its expression can be easily computed  which is precisely
our Assumption 2. Finally for the general case where ¯f is an average of K nonsmooth functions  the
smoothing technique is applied in a component by component way  i.e.  approximate ¯f with Mµ
Aµ.
that S-APG ﬁnds a 2 accurate solution in at most
For comparison 
Aµ is up-
O(
per bounded by L0 + M 2/(2) (under the choice of µ in Theorem 1). This is strictly worse than the
complexity O(
remove the secondary term in the complexity bound of S-APG. We should emphasize that this strict
improvement is obtained under exactly the same assumptions and with an algorithm as simple (if not
simpler) as S-APG. In some sense it is quite remarkable that the seemingly “naive” approximation
that pretends the linearity of the proximal map not only can be justiﬁed but also leads to a strictly
better result.
Let us further explain how the improvement is possible. As mentioned  S-APG approximates ¯f with
the smooth function Mµ
Aµ. This smooth approximation is beneﬁcial if our capability is limited to
smooth functions. Put differently  S-APG implicitly treats applying the fast gradient algorithms as
the ultimate goal. However  the recent advances on nonsmooth optimization have broadened the
range of fast schemes: It is not smoothness but the proximal map that allows fast convergence. Just
as how APG improves upon the subgradient method  our approach  with the ultimate goal to enable
efﬁcient computation of the proximal map  improves upon S-APG. Another lesson we wish to point
out is that unnecessary “over-smoothing”  as in S-APG  does hurt the performance since it always
increases the Lipschitz constant. To summarize  smoothing is not free and it should be used when
truly needed.
Lastly  we note that our algorithm shares some similarity with forward-backward splitting proce-
dures and alternating direction methods [9  18  19]  although a detailed examination will not be
given here. Due to space limits  we refer further extensions and improvements to [20  Chapter 3].
6 Experiments

We compare the proposed algorithm with S-APG on two important problems: overlapping group
lasso and graph-guided fused lasso. See Example 1 and Example 2 for details about the nonsmooth
function ¯f. We note that S-APG has been demonstrated with superior performance on both problems
in [13]  therefore we will only concentrate on comparing with it. Bear in mind that the purpose of our
experiment is to verify the theoretical improvement as discussed in Section 5. We are not interested
in ﬁne tuning parameters here (despite its practical importance)  thus for a fair comparison  we use
the same desired accuracy   Lipschitz constant L0 and other parameters for all methods. Since both
our method and S-APG have the same per-step complexity  we will simply run them for a maximum
number of iterations (after which saturation is observed) and report all the intermediate objective
values.

7

Figure 2: Objective value vs. iteration on overlapping group lasso.

Figure 3: Objective value vs. iteration on graph-guided fused lasso.

1

Overlapping Group Lasso: Following [13] we generate the data as follows: We set (cid:96)(x) =
2λK(cid:107)Ax − b(cid:107)2 where A ∈ Rn×d whose entries are sampled from i.i.d. normal distributions 
xj = (−1)j exp(−(j − 1)/100)  and b = Ax + ξ with the noise ξ sampled from zero mean and unit
variance normal distribution. Finally  the groups in the regularizer ¯f are deﬁned as

{{1  . . .   100} {91  . . .   190}  . . .  {d − 99  . . .   d}} 

where d = 90K + 10. That is  there are K groups  each containing 100 variables  and the groups
overlap by 10 consecutive variables. We adopt the uniform weight αk = 1/K and set λ = K/5.
Figure 2 shows the results for n = 5000 and K = 50  with three different accuracy parameters.
For completeness  we also include the results for the non-accelerated versions (PA-PG and S-PG).
Clearly  accelerated algorithms are much faster than their non-accelerated cousins. Observe that our
algorithms (PA-APG and PA-PG) converge consistently faster than S-APG and S-PG  respectively 
with a big margin in the favorable case (middle panel). Again we emphasize that this improvement
is achieved without any overhead.
Graph-guided Fused Lasso: We generate (cid:96) similarly as above. Following [13]  the graph edges E
are obtained by thresholding the correlation matrix. The case n = 5000  d = 1000  λ = 15 is shown
in Figure 3  under three different desired accuracies. Again  we observe that accelerated algorithms
are faster than non-accelerated versions and our algorithms consistently converge faster.

7 Conclusions

We have considered the composite minimization problem which consists of a smooth loss and a sum
of nonsmooth regularizers. Different from smoothing  we considered a seemingly naive nonsmooth
approximation which simply pretends the linearity of the proximal map. Based on the proximal
average  a new tool from convex analysis  we proved that the new approximation leads to a novel al-
gorithm that strictly improves the state-of-the-art. Experiments on both overlapping group lasso and
graph-guided fused lasso veriﬁed the superiority of the proposed method. An interesting question
arose from this work  also under our current investigation  is in what sense certain approximation is
optimal? We also plan to apply our algorithm to other practical problems.

Acknowledgement
The author thanks Bob Williamson and Xinhua Zhang from NICTA—Canberra for their hospitality
during the author’s visit when this work was performed; Warren Hare and Yves Lucet from UBC—
Okanagan for drawing his attention to the proximal average; and the reviewers for their valuable
comments.

8

0501001501001011021031041052ε = 2/L0  PA−PGS−PGPA−APGS−APG0501001501001011021031041052ε = 1/L0  PA−PGS−PGPA−APGS−APG0501001501001011021031041052ε = 0.5/L0  PA−PGS−PGPA−APGS−APG02040608010010−11001011021032ε = 2/L0  PA−PGS−PGPA−APGS−APG02040608010010−11001011021032ε = 1/L0  PA−PGS−PGPA−APGS−APG02040608010010−11001011021032ε = 0.5/L0  PA−PGS−PGPA−APGS−APGReferences
[1] Walter Rudin. Principles of mathematical analysis. McGraw-Hill  3rd edition  1976.
[2] Amir Beck and Marc Teboulle. A fast iterative shrinkage-thresholding algorithm for linear

inverse problems. SIAM Journal on Imaging Sciences  2(1):183–202  2009.

[3] Yurii Nesterov. Gradient methods for minimizing composite functions. Mathematical Pro-

gramming  Series B  140:125–161  2013.

[4] Francis Bach  Rodolphe Jenatton  Julien Mairal  and Guillaume Obozinski. Structured sparsity

through convex optimization. Statistical Science  27(4):450–468  2012.

[5] Peng Zhao  Guilherme Rocha  and Bin Yu. The composite absolute penalties family for

grouped and hierarchical variable selection. Annals of Statistics  37(6A):3468–3497  2009.

[6] Seyoung Kim and Eric P. Xing. Statistical estimation of correlated genome associations to a

quantitative trait network. PLoS Genetics  5(8):1–18  2009.

[7] Naum Z. Shor. Minimization Methods for Non-Differentiable Functions. Springer  1985.
[8] Yurii Nesterov. Smooth minimization of non-smooth functions. Mathematical Programming 

103(1):127–152  2005.

[9] Patrick L. Combettes and Jean-Christophe Pesquet. Proximal splitting methods in signal pro-
cessing. In Fixed-Point Algorithms for Inverse Problems in Science and Engineering  pages
185–212. Springer  2011.

[10] Silvia Villa  Saverio Salzo  Luca Baldassarre  and Alessandro Verri. Accelerated and inexact

forward-backward algorithms. SIAM Journal on Optimization  23(3):1607–1633  2013.

[11] Heinz H. Bauschke  Rafal Goebel  Yves Lucet  and Xianfu Wang. The proximal average:

Basic theory. SIAM Journal on Optimization  19(2):766–785  2008.

[12] Robert Tibshirani  Michael Saunders  Saharon Rosset  Ji Zhu  and Keith Knight. Sparsity and
smoothness via the fused lasso. Journal of the Royal Statistical Society: Series B  67:91–108 
2005.

[13] Xi Chen  Qihan Lin  Seyoung Kim  Jaime G. Carbonell  and Eric P. Xing. Smoothing proximal
gradient method for general structured sparse regression. The Annals of Applied Statistics  6
(2):719–752  2012.

[14] Ralph Tyrell Rockafellar and Roger J-B Wets. Variational Analysis. Springer  1998.
[15] Jean J. Moreau. Proximit´e et dualtit´e dans un espace Hilbertien. Bulletin de la Soci´et´e

Math´ematique de France  93:273–299  1965.

[16] Ralph Tyrrell Rockafellar. Monotone operators and the proximal point algorithm. SIAM Jour-

nal on Control and Optimization  14(5):877–898  1976.

[17] Heinz H. Bauschke and Patrick L. Combettes. Convex Analysis and Monotone Operator The-

ory in Hilbert Spaces. Springer  1st edition  2011.

[18] Hua Ouyang  Niao He  Long Q. Tran  and Alexander Gray. Stochastic alternating direction

method of multipliers. In International Conference on Machine Learning  2013.

[19] Taiji Suzuki. Dual averaging and proximal gradient descent for online alternating direction

multiplier method. In International Conference on Machine Learning  2013.

[20] Yaoliang Yu. Fast Gradient Algorithms for Stuctured Sparsity. PhD thesis  University of

Alberta  2013.

9

,Yao-Liang Yu
Yijun Li
Chen Fang
Jimei Yang
Zhaowen Wang
Xin Lu
Ming-Hsuan Yang
Minhyuk Sung
Hao Su
Ronald Yu
Leonidas Guibas
Bichuan Guo
Yuxing Han
Jiangtao Wen