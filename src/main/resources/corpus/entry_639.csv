2014,Augmentative Message Passing for Traveling Salesman Problem and Graph Partitioning,The cutting plane method is an augmentative constrained optimization procedure that is often used with continuous-domain optimization techniques such as linear and convex programs. We investigate the viability of a similar idea within message passing -- for integral solutions -- in the context of two combinatorial problems: 1) For Traveling Salesman Problem (TSP)  we propose a factor-graph based on Held-Karp formulation  with an exponential number of constraint factors  each of which has an exponential but sparse tabular form. 2) For graph-partitioning (a.k.a. community mining) using modularity optimization  we introduce a binary variable model with a large number of constraints that enforce formation of cliques. In both cases we are able to derive surprisingly simple message updates that lead to competitive solutions on benchmark instances. In particular for TSP we are able to find near-optimal solutions in the time that empirically grows with $N^3$  demonstrating that augmentation is practical and efficient.,Augmentative Message Passing for Traveling
Salesman Problem and Graph Partitioning

Siamak Ravanbakhsh

Department of Computing Science

University of Alberta

Edmonton  AB T6G 2E8

mravanba@ualberta.ca

Reihaneh Rabbany

Department of Computing Science

University of Alberta

Edmonton  AB T6G 2E8

rabbanyk@ualberta.ca

Russell Greiner

Department of Computing Science

University of Alberta

Edmonton  AB T6G 2E8

rgreiner@ualberta.ca

Abstract

The cutting plane method is an augmentative constrained optimization procedure
that is often used with continuous-domain optimization techniques such as linear
and convex programs. We investigate the viability of a similar idea within message
passing – for integral solutions in the context of two combinatorial problems: 1)
For Traveling Salesman Problem (TSP)  we propose a factor-graph based on Held-
Karp formulation  with an exponential number of constraint factors  each of which
has an exponential but sparse tabular form. 2) For graph-partitioning (a.k.a. com-
munity mining) using modularity optimization  we introduce a binary variable
model with a large number of constraints that enforce formation of cliques. In
both cases we are able to derive simple message updates that lead to competitive
solutions on benchmark instances. In particular for TSP we are able to ﬁnd near-
optimal solutions in the time that empirically grows with N 3  demonstrating that
augmentation is practical and efﬁcient.

1

Introduction

Probabilistic Graphical Models (PGMs) provide a principled approach to approximate constraint op-
timization for NP-hard problems. This involves a message passing procedure (such as max-product
Belief Propagation; BP) to ﬁnd an approximation to maximum a posteriori (MAP) solution. Mes-
sage passing methods are also attractive as they are easily mass parallelize. This has contributed to
their application in approximating many NP-hard problems  including constraint satisfaction [1  2] 
constrained optimization [3  4]  min-max optimization [5]  and integration [6].
The applicability of PGMs to discrete optimization problems is limited by the size and number of
factors in the factor-graph. While many recent attempts have been made to reduce the complexity
of message passing over high-order factors [7  8  9]  to our knowledge no published result addresses
the issues of dealing with large number of factors. We consider a scenario where a large number
of factors represent hard constraints and ask whether it is possible to ﬁnd a feasible solution by
considering only a small fraction of these constraints.
The idea is to start from a PGM corresponding to a tractible subsset of constraints  and after obtain-
ing an approximate MAP solution using min-sum BP  augment the PGM with the set of constraints
that are violated in the current solution. This general idea has been extensively studied under the

1

term cutting plane methods in different settings. Dantzig et al. [10] ﬁrst investigated this idea in the
context of TSP and Gomory et al.[11] provided a elegant method to generate violated constraints
in the context of ﬁnding integral solutions to linear programs (LP). It has since been used to also
solve a variety of nonlinear optimization problems. In the context of PGMs  Sontag and Jaakkola
use cutting plane method to iteratively tighten the marginal polytope – that enforces the local con-
sistency of marginals – in order to improve the variational approximation [12]. This differs from our
approach  where the augmentation changes the factor-graph (i.e.  the inference problem) rather than
improving the approximation of inference.
Recent studies show that message passing can be much faster than LP in ﬁnding approximate MAP
assignments for structured optimization problems [13]. This further motivates our inquiry regarding
the viability of augmentation for message passing. We present an afﬁrmative answer to this question
in application to two combinatorial problems. Section 2 introduces our factor-graph formulations
for Traveling Salesman Problem (TSP) and graph-partitioning. Section 3 derives simple message
update equations for these factor-graphs and reviews our augmentation scheme. Finally  Section 4
presents experimental results for both applications.

energy function f (x) (cid:44) (cid:80)I∈F fI(xI) where F denotes the set of factors. Here the goal of

2 Background and Representation
Let x = {x1  . . .   xD} ∈ X = X1 ×X2 . . .×XD denote an instance of a tuple of discrete variables.
Let xI refer to a sub-tuple  where I ⊆ {1  . . .   D} indexes a subset of these variables. Deﬁne the
inference is to ﬁnd an assignment with minimum energy x∗ = argx min f (x). This model can be
conveniently represented using a bipartite graph  known as factor-graph [14]  where a factor node
fI(xI) is connected to a variable node xi iff i ∈ I.

2.1 Traveling Salesman Problem

A Traveling Salesman Problem (TSP) seeks the minimum length tour of N cities that visits each
city exactly once. TSP is NP-hard  and for general distances  no constant factor approximation to
this problem is possible [15]. The best known exact solver  due to Held et al.[16]  uses dynamic
programming to reduce the cost of enumerating all orderings from O(N !) to O(N 22N ). The de-
velopment of many (now) standard optimization techniques  such as simulated annealing  mixed
integer linear programming  dynamic programming  and ant colony optimization are closely linked
with advances in solving TSP. Since Dantzig et al.[10] manually applied the cutting plane method
to 49-city problem  a combination of more sophisticated cuts  used with branch-and-bound tech-
niques [17]  has produced the state-of-the-art TSP-solver  Concorde [18]. Other notable results on
very large instances have been reported by LinKernighan heuristic [19] that continuously improves
a solution by exchanging nodes in the tour. In a related work  Wang et al.[20] proposed a message
passing solution to TSP. However their method does not scale beyond small toy problems (authors
experimented with N = 5 cities). For a readable historical background of the state-of-the-art in TSP
and its various applications  see [21].

2.1.1 TSP Factor-Graph
Let G = (V E) denote a graph  where V = {v1  . . .   vN} is the set of nodes and the set of edges
E contains ei−j iff vi and vj are connected. Let x = {xe1  . . .   xeM} ∈ X = {0  1}M be a set of
binary variables  one for each edge in the graph (i.e.  M = |E|) where we will set xem = 1 iff em is
in the tour. For each node vi  let ∂vi = {ei−j | ei−j ∈ E} denote the edges adjacent to vi. Given a
distance function d : E → (cid:60)  deﬁne the local factors for each edge e ∈ E as fe(xe) = xe d(e) – so
this is either d(e) or zero. Any valid tour satisﬁes the following necessary and sufﬁcient constraints
– a.k.a. Held-Karp constraints [22]:
1. Degree constraints: Exactly two edges that are adjacent to each vertex should be in the tour.
Deﬁne the factor f∂vi (x∂vi ) : {0  1}|∂vi| → {0 ∞} to enforce this constraint

f∂vi (x∂vi ) (cid:44) I∞

xe = 2

∀vi ∈ V

(cid:33)

(cid:32)(cid:88)

e∈∂vi

2

where I∞(condition) (cid:44) 0 iff the condition is satisﬁed and +∞ otherwise.

2. Subtour constraints: Ensure that there are no short-circuits – i.e.  there are no loops that contain
strict subsets of nodes. To enforce this  for each S ⊂ V  deﬁne δ(S) (cid:44) {ei−j ∈ E | vi ∈ S  vj /∈ S}
to be the set of edges  with one end in S and the other end in V \ S.
We need to have at least two edges leaving each subset S. The following set of factors enforce these
constraints

(cid:33)

fδ(S)(xδ(S)) = I∞

xe ≥ 2

∀S ⊂ V  S (cid:54)= ∅

(cid:32)(cid:88)

xe∈S

These three types of factors deﬁne a factor-graph  whose minimum energy conﬁguration is the small-
est tour for TSP.

2.2 Graph Partitioning

Graph partitioning –a.k.a. community mining– is an active ﬁeld of research that has recently pro-
duced a variety of community detection methods (e.g.  see [23] and its references)  a notable one
of which is Modularity maximization [24]. However  exact optimization of Modularity is NP-hard
[25]. Modularity is closely related to fully connected Potts graphical models [26]. However  due to
full connectivity of PGM  message passing is not able to ﬁnd good solutions. Many have proposed
various other heuristics for modularity optimization [27  28  26  29  30]. We introduce a factor-graph
representation of this problem that has a large number of factors. We then discuss a stochastic but
sparse variation of modularity that enables us to efﬁciently partition relatively large sparse graphs.

2.2.1 Clustering Factor-Graph

Let G = (V E) be a graph  with a weight function (cid:101)ω : V × V → (cid:60)  where (cid:101)ω(vi  vj) (cid:54)= 0
iff ei:j ∈ E. Let Z = (cid:80)
Also let ω(∂vi) (cid:44) (cid:80)

2Z be the normalized weights.
ω(vi  vj) denote the normalized degree of node vi. Graph clustering us-
ing modularity optimization seeks a partitioning of the nodes into unspeciﬁed number of clusters
C = {C1  . . .  CK}  maximizing
q(C) =

ω(vi  vj) − ω(∂vi) ω(∂vj)

v1 v2∈V(cid:101)ω(v1  v2) and ω(vi  vj) (cid:44) (cid:101)ω
(cid:88)

(cid:88)

(cid:18)

(cid:19)

(1)

vj

Ci∈C

vi vj∈Ci

The ﬁrst term of modularity is proportional to within-cluster edge-weights. The second term is
proportional to the expected number of within cluster edge-weights for a null model with the same
weighted node degrees for each node vi.
Here the null model is a fully-connected graph. We generate a random sparse null model with
Mnull < αM weighted edges (Enull)  by randomly sampling two nodes  each drawn indepen-

dently from P(vi) ∝(cid:112)ω(∂vi)  and connecting them with a weight proportional to(cid:101)ωnull(vi  vj) ∝
(cid:112)ω(∂vi)ω(∂vj). If they have been already connected  this weight is added to their current weight.
We repeat this process αM times  however since some of the edges are repeated  the total number
(cid:101)ωnull(vi vj )
of edges in the null model may be under αM. Finally the normalized edge-weight in the sparse
vi vj (cid:101)ωnull(vi vj ) . It is easy to see that this generative process in
null model is ωnull(vi  vj) (cid:44)
expectation produces the fully connected null model.1
Here we use the following binary-valued factor-graph formulation. Let x = {xi1:j1  . . .   xiL:jL} =
{0  1}L be a set of binary variables  one for each edge ei:j ∈ E ∪ Enull – i.e.  |E ∪ Enull| = L.
Deﬁne the local factor for each variable as fi:j(xi:j) = −xi−j(ω(vi  vj) − ωnull(vi  vj)). The
idea is to enforce formation of cliques  while minimizing the sum of local factors. By doing so the

2(cid:80)

1The choice of using square root of weighted degrees for both sampling and weighting is to reduce the
variance. One may also use pure importance sampling (i.e.  use the product of weighted degrees for sampling
and set the edge-weights in the null model uniformly)  or uniform sampling of edges  where the edge-weights
of the null model are set to the product of weighted degrees.

3

negative sum of local factors evaluates to modularity (eq 1). For each three edges ei:j  ej:k  ei:k ∈
E ∪ Enull  i < j < k that form a triangle  deﬁne a clique constraint as

f{i:j j:k i:k}(xi:j  xj:k  xi:k) (cid:44) I∞(xi:j + xj:k + xi:k (cid:54)= 2)

These factors ensure the formation of cliques – i.e.  if the weights of two edges that are adjacent to
the same node are non-zero  the third edge in the triangle should also have non-zero weight. The
computational challenge here is the large number of clique constraints. Brandes et al.[25] use a
similar LP formulation. However  since they include all the constraints from the beginning and the
null model is fully connected  their method is only applied to small toy problems.

3 Message Passing

Min-sum belief propagation is an inference procedure  in which a set of messages are exchanged be-
tween variables and factors. The factor-to-variable (νI→e) and variable-to-factor (νe→I) messages
are deﬁned as

νe→I(xe) (cid:44) (cid:88)
(cid:26)

νI→e(xe) (cid:44) min

I(cid:48)(cid:51)e I(cid:48)(cid:54)=I

νI(cid:48)→e(xe)

fI(xI\e  xe)

(cid:88)

e(cid:48)∈I\e

(cid:27)

νe(cid:48)→I(xe(cid:48))

xI\e

(2)

(3)

often prevents oscillations: νI→e(xe) = λ(cid:101)νI→e(xe) + (1 − λ)νI→e(xe). Here(cid:101)νI→e is the new

exact  the set of local beliefs µe(xe) (cid:44) (cid:80)I(cid:51)e νI→e(xe) indicate the minimum value that can be

where I (cid:51) e indexes all factors that are adjacent to the variable xe on the factor-graph. Starting
from an initial set of messages  this recursive update is performed until convergence.
This procedure is exact on trees  factor-graphs with single cycle as well as some special settings
[4]. However it is found to produce good approximations in general loopy graphs. When BP is
obtained for a particular assignment of xe. When there are no ties  the joint assignment x∗  obtained
by minimizing individual local beliefs  is optimal.
When BP is not exact or the marginal beliefs are tied  a decimation procedure can improve the
quality of ﬁnal assignment. Decimation involves ﬁxing a subset of variables to their most biased
values  and repeating the BP update. This process is repeated until all variables are ﬁxed.
Another way to improve performance of BP when applied to loopy graphs is to use damping  which
message as calculated by eq 3 and λ ∈ (0  1] is the damping parameter. Damping can also be applied
to variable-to-factor messages.
When applying BP equations eqs 2  3 to the TSP and clustering factor-graphs  as deﬁned above 
we face two computational challenges: (a) Degree constraints for TSP can depend on N variables 
resulting in O(2N ) time complexity of calculating factor-to-variable messages. For subtour con-
straints  this is even more expensive as fS (xδ(S)) depends on O(M ) (recall M = |E| which can be
O(N 2)) variables. (b) The complete TSP factor-graph has O(2N ) subtour constraints. Similarly the
clustering factor-graph can contain a large number of clique constraints. For the fully connected null
model  we need O(N 3) such factors and even using the sparse null model – assuming a random edge
probability a.k.a. Erdos-Reny graph – there are O( L3
N 3 ) triangles in the graph (recall
that L = |E ∪ Enull|). In the next section  we derive the compact form of BP messages for both
problems. In the case of TSP  we show how to exploit the sparsity of degree and subtour constraints
to calculate the factor-to-variable messages in O(N ) and O(M ) respectively.

N 6 N 3) = O( L3

3.1 Closed Form of Messages
For simplicity we work with normalized message νI→e (cid:44) νI→e(1)− νI→e(0)  which is equivalent
to assuming νI→e(0) = 0 ∀I  e. The same notation is used for variable-to-factor message  and
marginal belief. We refer to the normalized marginal belief  µe = µe(1) − µ(0)e as bias.
Despite their exponentially large tabular form  both degree and subtour constraint factors for TSP
are sparse. Similar forms of factors is studied in several previous works [7  8  9]. By calculating

4

Figure 1: (left) The message passing results after each augmentation step for the complete graph of
printing board instance from [31]. The blue lines in each ﬁgure show the selected edges at the end
of message passing. The pale red lines show the edges with the bias that  although negative (µe <
0)  were close to zero. (middle) Clustering of power network (N = 4941) by message passing.
Different clusters have different colors and the nodes are scaled by their degree. (right) Clustering
of politician blogs network (N = 1490) by message passing and by meta-data – i.e.  liberal or
conservative.

 

the closed form of these messages for TSP factor-graph  we observe that they have a surprisingly
simple form. Rewriting eq 3 for degree constraint factors  we get:
ν∂vi→e(1) = min{νe(cid:48)→∂vi}e(cid:48)∈∂vi\e
ν∂vi→e(0) = min{νe(cid:48)→∂vi + νe(cid:48)(cid:48)→∂vi}e(cid:48) e(cid:48)(cid:48)∈∂vi\e (4)
where we have dropped the summation and the factor from eq 3. For xe = 1  in order to have
f∂vi(x∂i) < ∞  only one other xe(cid:48) ∈ x∂vi should be non-zero. On the other hand  we know that
messages are normalized such that νe→∂vi(0) = 0 ∀vi  e ∈ ∂vi  which means they can be ignored
in the summation. For xe = 0  in order to satisfy the constraint factor  two of the adjacent variables
should have a non-zero value. Therefore we seek two such incoming messages with minimum
values. Let min[k]A denote the kth smallest value in the set A – i.e.  minA ≡ min[1]A. We
combine the updates above to get a “normalized message”  ν∂vi→e  which is simply the negative of
the second largest incoming message (excluding νe→∂vi) to the factor f∂vi:

ν∂vi→e = ν∂vi→e(1) − ν∂vi→e(0) = − min[2]{νe(cid:48)→∂vi}e(cid:48)∈∂vi\e

(5)

Following a similar procedure  factor-to-variable messages for subtour constraints is given by

νδ(S)→e = − max{0  min[2]{νe(cid:48)→δ(S)}e(cid:48)∈δ(S)\e}}

(6)
Here while we are searching for the minimum incoming message  if we encounter two messages
with negative or zero values  we can safely assume νδ(S)→e = 0  and stop the search. This results
in signiﬁcant speedup in practice. Note that both eq 5 and eq 6 only need to calculate the second
smallest message in the set {νe(cid:48)→δ(S)}e(cid:48)∈δ(S)\e. In the asynchronous calculation of messages  this
minimization should be repeated for each outgoing message. However in a synchronous update by
ﬁnding three smallest incoming messages to each factor  we can calculate all the factor-to-variable
messages at the same time.
For the clustering factor-graph  the clique factor is satisﬁed only if either zero  one  or all three of
the variables in its domain are non-zero. The factor-to-variable messages are given by

ν{i:j j:k i:k}→i:j(0) = min{0  νj:k→{i:j j:k i:k}  νi:k→{i:j j:k i:k}}
ν{i:j j:k i:k}→i:j(1) = min{0  νj:k→{i:j j:k i:k} + νi:k→{i:j j:k i:k}}

(7)
For xi:j = 0  the minimization is over three feasible cases (a) xj:k = xi:k = 0  (b) xj:k = 1  xi:k = 0
and (c) xj:k = 0  xi:k = 1. For xi:j = 1  there are two feasible cases (a) xj:k = xi:k = 0 and
(b) xj:k = xi:k = 1. Normalizing these messages we have

ν{i:j j:k i:k}→i:j = min{0  νj:k→{i:j j:k i:k} + νi:k→{i:j j:k i:k}}−

min{0  νj:k→{i:j j:k i:k}  νi:k→{i:j j:k i:k}}

(8)

3.2 Finding Violations

Due to large number of factors  message passing for the full factor-graph in our applications is not
practical. Our solution is to start with a minimal set of constraints. For TSP  we start with no subtour
constraints and for clustering  we start with no clique constraint. We then use message passing to
ﬁnd marginal beliefs µe and select the edges with positive bias µe > 0.

5

Figure 2: Results of message passing for TSP on different benchmark problems. From left to right  the
plots show: (a) running time  (b) optimality ratio (compared to Concorde)  (c) iterations of augmentation and
(d) number of subtours constraints – all as a function of number of nodes. The optimality is relative to the
result reported by Concorde. Note that all plots except optimality are log-log plots where a linear trend shows
a monomial relation (y = axm) between the values on the x and y axis  where the slope shows the power m.

We then ﬁnd the constraints that are violated. For TSP  this is achieved by ﬁnding connected com-
ponents C = {Si ⊂ V} of the solution in O(N ) time and deﬁne new subtour constraints for each
Si ∈ C (see Figure 1(left)).
For graph partitioning  we simply look at pairs of positively ﬁxed edges around each node and if
the third edge of the triangle is not positively ﬁxed  we add the corresponding clique factor to the
factor-graph; see Appendix A for more details.

4 Experiments
4.1 TSP
Here we evaluate our method over ﬁve benchmark datasets: (I) TSPLIB  which contains a variety
of real-world benchmark instances  the majority of which are 2D or 3D Euclidean or geographic

6

Table 1: Comparison of different modularity optimization methods.

message passing (full)

message passing (sparse)

Spin-glass

L-Eigenvector

FastGreedy

Louvian

?
d
e
t
h
g
i
e

W
y
y
n
n
y
n
n
y
y

s
e
d
o
N
105
115
34
1589
62
77
297
1490
34

s
e
g
d
E
441
615
78
2742
159
254
2359
19090

78

y
t
i
r
a
l
u
d
o
M

t
s
o
L C

5461
6554
562
NA
1892
2927
43957
NA
562

NA

5.68% 0.511
27.85% 0.591
12.34% 0.431
NA
14.02% 0.508
5.14% 0.531
16.70% 0.391
NA
14.32% 0.355

NA

y
t
i
r
a
l
u
d
o
M

t
s
o
L C

3624
5635
431
53027
1269
1601
21380
156753
423

13.55% 0.506
17.12% 0.594
15.14% 0.401
.0004% 0.941
6.50% 0.521
1.7%
0.534
3.16% 0.404
.14%
0.411
17.54% 0.390

i

e
m
T
.04
0.14
0
2.01
0.01
0.01
2.82
32.75
0

y
t
i
r
a
l
u
d
o
M
0.525
0.601
0.444
0.907
0.523
0.529
0.406
0.427
0.417

i

e
m
T
1.648
0.87
0.557
8.459
0.728
1.31
5.849
67.674
0.531

y
t
i
r
a
l
u
d
o
M
0.467
0.487
0.421
0.889
0.491
0.483
0.278
0.425
0.393

i

e
m
T
0.179
0.151
0.095
0.303
0.109
0.081
0.188
0.33
0.086

y
t
i
r
a
l
u
d
o
M
0.501
0.548
0.410
0.926
0.495
0.472
0.367
0.427
0.380

i

e
m
T
0.643
0.08
0.085
0.154
0.107
0.073
0.12
0.305
0.079

y
t
i
r
a
l
u
d
o
M
0.489
0.602
0.443
0.948
0.517
0.566
0.435
0.426
0.395

i

e
m
T
0.03
0.019
0.027
0.218
0.011
0.011
0.031
0.099
0.009

i

e
m
T
.07
0.41
0
NA
0.01
0
10.89
NA
0

m
e
l
b
o
r
P

polbooks
football
wkarate
netscience
dolphins
lesmis

celegansneural

polblogs
karate

distances.2 (II) Euclidean distance between random points in 2D. (III) Random (symmetric) dis-
tance matrices. (IV) Hamming distance between random binary vectors with ﬁxed length (20 bits).
This appears in applications such as data compression [32] and radiation hybrid mapping in ge-
nomics [33]. (V) Correlation distance between random vectors with 5 random features (e.g.  using
TSP for gene co-clustering [34]). In producing random points and features as well as random dis-
tances (in (III))  we used uniform distribution over [0  1].
For each of these cases  we report the (a) run-time  (b) optimality  (c) number of iterations of aug-
mentation and (d) number of subtour factors at the ﬁnal iteration. In all of the experiments  we use
Concorde [18] with its default settings to obtain the optimal solution.3 Since there are very large
number of TSP solvers  comparison with any particular method is pointless. Instead we evaluate the
quality of message passing against the “optimal” solution. The results in Figure 2(2nd column from
left) reports the optimality ratio – i.e.  ratio of the tour found by message passing  to the optimal
tour. To demonstrate the non-triviality of these instance  we also report the optimality ratio for two
heuristics that have optimality guarantees for metric instances [35]: (a) nearest neighbour heuristic
(O(N 2))  which incrementally adds the to any end of the current path the closest city that does not
form a loop; (b) greedy algorithm (O(N 2 log(N )))  which incrementally adds a lowest cost edge to
the current edge-set  while avoiding subtours.
In all experiments  we used the full graph G = (V E)  which means each iteration of message
passing is O(N 2τ )  where τ is the number of subtour factors. All experiments use Tmax = 200
iterations  max = median{d(e)}e∈E and damping with λ = .2. We used decimation  and ﬁxed
10% of the remaining variables (out of N) per iteration of decimation.4 This increases the cost of
message passing by an O(log(N )) multiplicative factor  however it often produces better results.
All the plots in Figure 2  except for the second column  are in log-log format. When using log-log
plot  a linear trend shows a monomial relation between x and y axes – i.e.  y = axm. Here m
indicates the slope of the line in the plot and the intercept corresponds to log(a). By studying the
slope of the linear trend in the run-time (left column) in Figure 2  we observe that  for almost all
instances  message passing seems to grow with N 3 (i.e.  slope of ∼ 3). Exceptions are TSPLIB
instances  which seem to pose a greater challenge  and random distance matrices which seem to be
easier for message passing. A similar trend is suggested by the number of subtour constraints and
iterations of augmentation  which has a slope of ∼ 1  suggesting a linear dependence on N. Again
the exceptions are TSPLIB instances that grow faster than N and random distance matrices that
seem to grow sub-linearly.5 Finally  the results in the second column suggests that message passing
is able to ﬁnd near optimal (in average ∼ 1.1-optimal) solutions for almost all instances and the
quality of tours does not degrade with increasing number of nodes.

2Geographic distance is the distance on the surface of the earth as a large sphere.
3For many larger instances  Concorde (with default setting and using CPLEX as LP solver) was not able
to ﬁnd the optimal solution. Nevertheless we used the upper-bound on the optimal produced by Concord in
evaluating our method.
4Note that here we are only ﬁxing the top N variables with positive bias. The remaining M − N variables

5Since we measured the time in milliseconds  the ﬁrst column does not show the instances that had a running

are automatically clamped to zero.

time of less than a millisecond.

7

4.2 Graph Partitioning

For graph partitioning  we experimented with a set of classic benchmarks6. Since the optimization
criteria is modularity  we compared our method only against best known “modularity optimization”
heuristics: (a) FastModularity[27]  (b) Louvain [30]  (c) Spin-glass [26] and (d) Leading eigenvec-
tor [28]. For message passing  we use λ = .1  max = median{|ω(e) − ωnull(e)|}e∈E∪Enull and
Tmax = 10. Here we do not perform any decimation and directly ﬁx the variables based on their
bias µe > 0 ⇔ xe = 1.
Table 1 summarizes our results (see also Figure 1(middle right)). Here for each method and each
data-set  we report the time (in seconds) and the Modularity of the communities found by each
method. The table include the results of message passing for both full and sparse null models  where
we used a constant α = 20 to generate our stochastic sparse null model. For message passing  we
also included L = |E + Enull| and the saving in the cost using augmentation. This column shows
the percentage of the number of all the constraints considered by the augmentation. For example 
the cost of .14% for the polblogs data-set shows that augmentation and sparse null model meant
using .0014 times fewer clique-factors  compared to the full factor-graph.
Overall  the results suggest that our method is comparable to state-of-the-art in terms both time and
quality of clustering. But more importantly it shows that augmentative message passing is able to
ﬁnd feasible solutions using a small portion of the constraints.

5 Conclusion

We investigate the possibility of using cutting-plane-like  augmentation procedures with message
passing. We used this procedure to solve two combinatorial problems; TSP and modularity optimiza-
tion. In particular  our polynomial-time message passing solution to TSP often ﬁnds near-optimal
solutions to a variety of benchmark instances.
Despite losing the guarantees that make cutting plane method very powerful  our approach has sev-
eral advantages: First  message passing is more efﬁcient than LP for structured optimization [13]
and it is highly parallelizable. Moreover by directly obtaining integral solutions  it is much easier
to ﬁnd violated constraints. (Note the cutting plane method for combinatorial problems operates
on fractional solutions  whose rounding may eliminate its guarantees.) For example  for TSPs 
our method simply adds violated constraints by ﬁnding connected components. However  due to
non-integral assignments  cutting plane methods require sophisticated tricks to ﬁnd violations [21].
Although powerful branch-and-cut methods  such as Concorde  are able to exactly solve instances
with few thousands of variables  their general run-time on benchmark instances remains exponen-
tial [18  p495]  while our approximation appears to be O(N 3). Overall our studies indicate that
augmentative message passing is an efﬁcient procedure for constraint optimization with large num-
ber of constraints.

References

[1] M. Mezard  G. Parisi  and R. Zecchina  “Analytic and algorithmic solution of random satisﬁability prob-

lems ” Science  2002.

[2] S. Ravanbakhsh and R. Greiner  “Perturbed message passing for constraint satisfaction problems ” arXiv

preprint arXiv:1401.6686  2014.

[3] B. Frey and D. Dueck  “Clustering by passing messages between data points ” Science  2007.
[4] M. Bayati  D. Shah  and M. Sharma  “Maximum weight matching via max-product belief propagation ”

in ISIT  2005.

[5] S. Ravanbakhsh  C. Srinivasa  B. Frey  and R. Greiner  “Min-max problems on factor-graphs ” ICML 

2014.

[6] B. Huang and T. Jebara  “Approximating the permanent with belief propagation ” arXiv preprint

arXiv:0908.1769  2009.

6Obtained form Mark Newman’s website:

netdata/

http://www-personal.umich.edu/˜mejn/

8

[7] B. Potetz and T. S. Lee  “Efﬁcient belief propagation for higher-order cliques using linear constraint

nodes ” Computer Vision and Image Understanding  vol. 112  no. 1  pp. 39–54  2008.

[8] R. Gupta  A. A. Diwan  and S. Sarawagi  “Efﬁcient inference with cardinality-based clique potentials ” in

ICML  2007.

[9] D. Tarlow  I. E. Givoni  and R. S. Zemel  “Hop-map: Efﬁcient message passing with high order poten-

tials ” in International Conference on Artiﬁcial Intelligence and Statistics  pp. 812–819  2010.

[10] G. Dantzig  R. Fulkerson  and S. Johnson  “Solution of a large-scale traveling-salesman problem ” J

Operations Research society of America  1954.

[11] R. E. Gomory et al.  “Outline of an algorithm for integer solutions to linear programs ” Bulletin of the

American Mathematical Society  vol. 64  no. 5  pp. 275–278  1958.

[12] D. Sontag and T. S. Jaakkola  “New outer bounds on the marginal polytope ” in Advances in Neural

Information Processing Systems  pp. 1393–1400  2007.

[13] C. Yanover  T. Meltzer  and Y. Weiss  “Linear programming relaxations and belief propagation–an empir-

ical study ” JMLR  2006.

[14] F. Kschischang and B. Frey  “Factor graphs and the sum-product algorithm ” Information Theory  IEEE 

2001.

[15] C. H. Papadimitriou  “The euclidean travelling salesman problem is np-complete ” Theoretical Computer

Science  vol. 4  no. 3  pp. 237–244  1977.

[16] M. Held and R. M. Karp  “A dynamic programming approach to sequencing problems ” Journal of the

Society for Industrial & Applied Mathematics  vol. 10  no. 1  p. 196210  1962.

[17] M. Padberg and G. Rinaldi  “A branch-and-cut algorithm for the resolution of large-scale symmetric

traveling salesman problems ” SIAM review  vol. 33  no. 1  pp. 60–100  1991.

[18] D. Applegate  R. Bixby  V. Chvatal  and W. Cook  “Concorde TSP solver ” 2006.
[19] K. Helsgaun  “General k-opt submoves for the lin–kernighan tsp heuristic ” Mathematical Programming

Computation  2009.

[20] C. Wang  J. Lai  and W. Zheng  “Message-passing for the traveling salesman problem ”
[21] D. Applegate  The traveling salesman problem: a computational study. Princeton  2006.
[22] M. Held and R. Karp  “The traveling-salesman problem and minimum spanning trees ” Operations Re-

search  1970.

[23] J. Leskovec  K. Lang  and M. Mahoney  “Empirical comparison of algorithms for network community

detection ” in WWW  2010.

[24] M. Newman and M. Girvan  “Finding and evaluating community structure in networks ” Physical Review

E  2004.

[25] U. Brandes  D. Delling  et al.  “on clustering ” IEEE KDE  2008.
[26] J. Reichardt and S. Bornholdt  “Detecting fuzzy community structures in complex networks with a potts

model ” Physical Review Letters  vol. 93  no. 21  p. 218701  2004.

[27] A. Clauset  “Finding local community structure in networks ” Physical Review E  2005.
[28] M. Newman  “Finding community structure in networks using the eigenvectors of matrices ” Physical

review E  2006.

[29] P. Ronhovde and Z. Nussinov  “Local resolution-limit-free potts model for community detection ” Physi-

cal Review E  vol. 81  no. 4  p. 046114  2010.

[30] V. Blondel  J. Guillaume  et al.  “Fast unfolding of communities in large networks ” J Statistical Mechan-

ics  2008.

[31] G. Reinelt  “Tspliba traveling salesman problem library ” ORSA journal on computing  vol. 3  no. 4 

pp. 376–384  1991.

[32] D. Johnson  S. Krishnan  J. Chhugani  S. Kumar  and S. Venkatasubramanian  “Compressing large

Boolean matrices using reordering techniques ” in VLDB  2004.

[33] A. Ben-Dor and B. Chor  “On constructing radiation hybrid maps ” J Computational Biology  1997.
[34] S. Climer and W. Zhang  “Take a walk and cluster genes: A TSP-based approach to optimal rearrangement

clustering ” in ICML  2004.

[35] D. Johnson and L. McGeoch  “The traveling salesman problem: A case study in local optimization ”

Local search in combinatorial optimization  1997.

9

,Siamak Ravanbakhsh
Reihaneh Rabbany
Russell Greiner