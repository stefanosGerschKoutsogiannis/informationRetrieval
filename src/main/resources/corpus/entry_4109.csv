2019,Optimal Pricing in Repeated Posted-Price Auctions with Different Patience of the Seller and the Buyer,We study revenue optimization pricing algorithms for repeated posted-price auctions where a seller interacts with a single strategic buyer that holds a fixed private valuation.
When the participants non-equally discount their cumulative utilities  we show that the optimal constant pricing (which offers the Myerson price) is no longer optimal. 
In the case of more patient seller  we propose a novel multidimensional optimization functional --- a generalization of the one used to determine Myerson's price. This functional allows to find the optimal algorithm and to boost revenue of the optimal static pricing by an efficient low-dimensional approximation.
Numerical experiments are provided to support our results.,Optimal Pricing in Repeated Posted-Price Auctions
with Different Patience of the Seller and the Buyer

Arsenii Vanunts

Yandex

Moscow  Russia

avanunts@yandex.ru

Alexey Drutsa
Yandex; MSU
Moscow  Russia

adrutsa@yandex.ru

Abstract

We study revenue optimization pricing algorithms for repeated posted-price auc-
tions where a seller interacts with a single strategic buyer that holds a ﬁxed private
valuation. When the participants non-equally discount their cumulative utilities 
we show that the optimal constant pricing (which offers the Myerson price) is no
longer optimal. In the case of more patient seller  we propose a novel multidimen-
sional optimization functional — a generalization of the one used to determine
Myerson’s price. This functional allows to ﬁnd the optimal algorithm and to boost
revenue of the optimal static pricing by an efﬁcient low-dimensional approximation.
Numerical experiments are provided to support our results.

1

Introduction

Auctions have been studied for decades [82] and remain the main instrument for extracting revenue
in Internet advertising for many years [36]. Revenue optimization problem in static (i.e.  one-period)
auctions is well studied and has proved its great worth to the Internet industry [64  2]  while the same
problem in dynamic auctions is still understudied [57]  although the major part of web advertisement
sales has repeated nature [7  32]. Consider the following example: an RTB platform (a seller) tracks
a user and repeatedly sells impressions on the user’s screen to advertisers (buyers) until the user is
out of the RTB’s sight. This example is naturally modeled by a sequence of repeated auctions  in
which buyers have ﬁxed valuation for a good all the way through.
For more than eleven years generalized second-price (GSP) auctions remain the leading instrument for
selling ads [79] and  as argued by [7  8  61  30  32  33]  a signiﬁcant part of auctions in AdExchanges
involve only a single buyer. Single-buyer GSP auctions are known in the literature as posted-price
auctions [51]. Repeated setting of them is referred to as repeated posted-price auctions in studies on
worst-case regret minimization [8  32] and as a ﬁshmonger’s problem in studies on expected revenue
maximization [29]. The setting of the ﬁshmonger’s problem relies on the assumption that the seller
knows the distribution of the buyer valuation of a good. This assumption is realistic for advertising
auctions  since most Internet companies possess rich historical bidding data [58  67].
We study the ﬁshmonger’s problem in which the seller repeatedly sells goods through a posted-price
mechanism to the same buyer that holds a ﬁxed private valuation for a good. The buyer seeks to
maximize his cumulative surplus  which is a discounted sum of his instant utilities over all rounds.
The seller knows the valuation distribution and the buyer’s discount sequence; so  she applies a pricing
algorithm that sets prices in each round in order to learn the valuation and extract more revenue. The
algorithm is announced to the buyer in advance [61]  thus  the buyer picks an optimal strategy w.r.t.
the announced algorithm  the valuation  and his discount sequence. The seller optimizes her expected
cumulative revenue — a discounted sum of her instant expected utilities over all rounds — w.r.t. her
discount sequence  the valuation distribution  and the buyer’s discount sequence.

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

When both the seller and the buyer equally discount their utilities  an optimal pricing is known
from a “folklore wisdom" [29]: it is the constant pricing algorithm that proposes the Myerson
optimal price [64] each round. Thus  the seller cannot advantageously apply any dynamic learning
of prices (based on previous decisions of the buyer) to improve her revenue with respect to a much
simpler approach that offers the optimal static constant price over all rounds. However  in many real
applications  the equal discount assumption may not hold due to an imbalance between the sides in
the patience to wait for utility [7  8  61] or their ability to estimate the probability that the game do
not terminates in a round [75  61]. The case of our setting where the time discounts of the seller and
the buyer are different was never studied before1. In this work  we attempt to ﬁll this gap.
In the case of less patient seller (i.e.  the seller discount is less than the buyer one)  we show that the
“folklore wisdom" technique can be easily adapted to prove that “Big deal" algorithm2 is optimal. The
expected revenue of this pricing is shown to be strictly greater than the one of the optimal constant
algorithm  if the seller is strictly less patient. In the inverse case (the buyer is less patient)  we show
that the problem is much more challenging and cannot be resolved by the “folklore wisdom" or
Myerson techniques. The problem in the initial form has structure similar to a saddle-point problem:
the revenue depends on an algorithm via argmax over buyer strategies and the derivatives of such
dependence have exponential number of jump discontinuities (Sec. 4). Hence  the initial revenue
optimization problem can be numerically solved only via a brute-force search.
In our work  ﬁrst  for the game with a ﬁnite horizon T   we reduce the problem to the optimization of
a novel multivariate functional (Th. 3) that constitutes a generalization of the one used to determine
Myerson’s price. This functional has a simple bilinear-like structure and is continuously differentiable
as many times as the CDF of the valuation distribution. This allows to ﬁnd the optimal pricing
algorithm by means of a variety of efﬁcient gradient-based methods. Second  for any game  we make
a low-dimensional approximation of the optimal revenue problem by an optimal τ-step algorithm3 
which can be found using our reduction approach as well (Sec. 5). In this way  our multivariate
functional constitutes a powerful and simple technique that allows the seller to signiﬁcantly increase
her revenue (w.r.t. the optimal static pricing) even in the games with large T . So  we provide the
rule of thumb: choose τ to ﬁt your computational capabilities (e.g.  τ= 2 3)  ﬁnd the optimal τ-step
pricing by the functional  and apply the prices learned in this way to get a boost in revenue.
Finally  we support our ﬁndings by an extensive numerical experimentation for a variety of discount
rates. We demonstrate that optimal algorithms are non-trivial  may be non-consistent [30  32]  have
prices noticeably dependent on the discounts  and generate revenue larger than the constant algorithm
with Myerson’s price (Sec. 5). Overall  our main contribution is our reduction approach that allows
both to ﬁnd the optimal algorithm (even with possible structural constraints) and to boost revenue by
the efﬁcient low-dimensional approximation in the case of less patient buyer.

2 Problem statement and preliminaries

Setup. A single seller and a single buyer interact repeatedly over a sequence of T rounds  where
the horizon T is either ﬁnite  or inﬁnite. The seller possess a fresh copy of a good each round
and the buyer values each copy of this good by a ﬁxed private valuation v ∈ R+. At each round
t ∈ [T ] :={1  ...  T} the seller sets a price pt for a new copy of the good and the buyer answers with
a decision at ∈ {0  1}: an accept 1 or a reject 0. Sequences of the buyer’s answers are denoted by
bold Latin letters  e.g.  a = {at}T
t=1  and are referred to as buyer strategies. The price pt depends on
the previous answers of the buyer a1  ..  at−1  i.e. the seller uses a deterministic pricing algorithm A
to set prices [30].
Given an algorithm A and a strategy a  the price sequence {pt}T
t=1 is uniquely determined. The
instant utilities of the buyer and the seller are at(v − pt) and atpt  respectively  in round t. The
instant utilities contribute to the buyer’s (the seller’s) total utility w.r.t. a discount γB
t   resp.).
Total utilities of the buyer and the seller are referred to as the buyer surplus and the seller revenue:
t atpt  resp. Both the buyer and the
seller are rational and risk-neutral agents [52]. Discount sequences γB ={γB
t }T
t=1
1There were works (e.g.  [7  8  30  32  33])  where only buyer utilities were discounted  while the seller’s
ones did not. But  those studies considered worst-case regret optimization  which is different from our setting.

t at(v−pt) and Revγ S (A  a) :=(cid:80)T

Surγ B (A  a  v) :=(cid:80)T

t=1 γB

2This pricing offers an up-front payment for all copies of a good for Myerson’s price in the ﬁrst round.
3A τ-step algorithm plays all the T rounds  but its prices do not change after the round τ < T .

t (γS

t=1 γS

t }T

t=1 and γS ={γS

2

B

t > 0 ∀t  and have ﬁnite sums: ΓB:=(cid:80)T

t   γS

t   ΓS:=(cid:80)T

t=1 γS

and γS

t = γt−1

S

t=1 γB

t < ∞. For simplicity
are positive  γB
of presentation  from here on in our paper we assume that the discounts decrease geometrically:
t = γt−1
for some γB  γS > 0. However  our results hold for a larger variety of
γB
discounts (see Remarks 1 and 2).
Our setting is based on two standard assumptions: (1) the buyer knows the pricing algorithm A in
advance (i.e.  the seller commits to it at the beginning of the ﬁrst round); and (2) the seller knows the
distribution D from which the private buyer valuation v (unknown to her) is drawn. Assumption (1)
matches the practice in Internet advertising [61] since RTB platforms run hundreds of millions
auctions a day [7  30] (see App. F for mode details). Assumption (2) is realistic since most Internet
companies have access to rich historical data [67]. We also assume that the seller knows the exact
buyer discount sequence.4 The CDF and the density of D is denoted by FD and fD  resp. The
random valuation is denoted by V   V ∼ D.
Our rational buyer with the private valuation v that knows the algorithm A in advance is referred to as a
strategic buyer [7] and exploits an optimal strategy aOpt(A  v  γB) := argmaxa∈ST Surγ B(A  a  v) 
where ST :={0  1}T is the set of all possible strategies. This leads us to the deﬁnition of the strategic
revenue of the pricing A  which faces the strategic buyer with a valuation v:
SRevγ S γ B (A  v) := Revγ S(A  aOpt(A  v  γB)).

(1)
We consider the problem of pricing optimization from the seller’s point of view. This problem is stated
as follows: ﬁnd such algorithm A∗ that its expected strategic revenue (ESR) EV ∼D[SRevγ S γ B(A∗ V )]
is not less than the ESR of any other algorithm (i.e. the ESR of the algorithm A∗ is the maximum).
Notations and auxiliary deﬁnitions. Following [51  61  30  32]  we associate a deterministic pricing
algorithm with a perfect (T−1)-depth binary tree with labeled nodes. Let NT be the set of nodes of
the tree and A(n) be a label of a node n ∈ NT . In the ﬁrst round  the current node is the root e ∈ NT .
Let n be the current node in a round t (the depth |n| of n is t − 1); then the algorithm offers the price
A(n). If this price is rejected  the current node moves to the n’s left child denoted by n0  otherwise
the current node moves to the n’s right child denoted by n1. We denote nodes by ﬁnite strings over
the alphabet {0  1}: the root is the empty string e  its left child is 0  the right one is 1  the right child
of 0 is 01  etc. (e.g. 0k is the string of k zeros). Thus  NT :={n∈{0  1}∗ | |n| < T}  where |n| is the
length of the string n  and the set of algorithms AT is the set of maps from NT to R+: AT = RNT
+ .
Research questions. One of standard interpretations5 of a discount factor γt−1
) is the
participant’s estimate of the probability that the repeated auctions will last at least t rounds [29  32].
While the constant Myerson algorithm (see Sec. 3) is a well-known folklore solution for the case
of equal discounts [29]  the case of different discounts  in our setup  was never considered earlier 
although it is more realistic. In Internet advertising  the seller and the buyer are usually companies of
different sizes  with different opportunities and capabilities (e.g.  an RTB platform vs. a web site with
an advertisement  see App. F for an example as well). In this way  they may have different data (or
access to them) that are used to make an estimation of the game-continuation probability (i.e.  the
discount factor). For instance  most likely that the RTB platform has more data and may know which
data are not available to the advertiser. As a result  the auction participants have different discounts.
In the case when the buyer overestimates the discount factor γB > γS  we show that the seller
can obtain (1 − γS)/(1 − γB) times larger expected revenue than the one of the constant Myerson
algorithm: she should apply the "Big deal" pricing algorithm (Sec.3). The inverse case appears to
be non-trivial  and  in our study  we primarily address the following research questions in the case
of γS > γB (Sec. 4 and 5): (1) What is the optimal algorithm and its expected strategic revenue?
(2) How much more is the maximal ESR than the constant Myerson’s one? (3) Can the seller extract
expected revenue more than in the static Myerson pricing having limits on computational resources?
Related work. There are two series of works that are most relevant to ours. The ﬁrst one studied
repeated posted-price auctions in the worst-case scenario [51  7  8  61  30  31  32]  where our setting
of the strategic buyer with a ﬁxed private valuation is considered. Amin et al. [7] proposed to seek for
algorithms that have the lowest possible asymptotic upper bound on the strategic regret for the worst
case valuation of the buyer. Recently  Drutsa [30  32  33] has found pricings with optimal regret

(or γt−1

B

S

4Our results still can be applied in the case when the seller possesses only incomplete information about the

buyer’s discount sequence. See 6 for more details.

5Alternatively  a discount factor can model the patience level of a participant to wait for instant revenue [7  30].

3

bound. In contrast to these studies  ﬁrst  we search for a pricing algorithm that maximizes the strategic
revenue expected over buyer valuations  which matches the practice of ad exchanges and optimization
goals in classical auction theory [52]. Second  our revenue optimization problem is solved exactly
(not via optimization of lower/upper bounds). Third  our study considers a more general setup in
which not only the buyer’s surplus is discounted over rounds  but also the seller’s revenue does.
The second series studied repeated posted-price auctions with an incomplete information and in the
absence of the ability to commit [43  75  29  47]. The authors of [43  75] showed that  in the case of
non-commitment  the seller is forced to sell a good for a minimal possible price until last few rounds.
Devanur et al. [29] showed that the seller can obtain non-trivial revenue  if she is able to partially
commit  e.g. to commit not to raise prices. Enhancing the competition was shown to allow the
seller to extract non-trivial revenue as well [47]. However  all these works treated the "commitment"
revenue as a unachievable benchmark. Hence  in our case of repeated auctions that is motivated
by Internet advertisement sales  where the seller is able to commit6  it is unreasonable to consider
the non-commitment case. Our setting (but in the case of equal discounts) can be considered as a
more general dynamic mechanism design problem studied  e.g. in [49  71  70  13]. To the best of our
knowledge this line of work never considered scenarios with different discounts. It would be a great
future study to generalize our results for different discounts to more general dynamic mechanisms.
3 Less patient seller: the case of γS ≤ γB
Our study begins with the analysis of the case γS ≤ γB in two steps. First  the subcase of equal
discounts γS = γB can be resolved by means of the classical auction theory [64]. Second  we reduce
the whole case γS ≤ γB to the subcase γS = γB by showing that  for γS ≤ γB  the seller can obtain the
same strategic revenue as if her discount was γB instead. Two simple optimal algorithms are provided.
Equal discounts: a constant algorithm. Let γS =γB =γ  then one can apply the almost folklore
technique of reducing this subcase to a single-round feasible mechanism [29]. Key steps of this
technique are provided in App. A.1.1 for completeness of our study on different discounts. The
D(1 −
expected revenue of the obtained feasible mechanism is known [64] to be no greater than p∗
FD(p∗
D is the Myerson price  i.e. 
the price that maximizes the functional HD(p) := pP[V ≥ p] = p(1 − FD(p))7. Thus  the following
D)) ∀A ∈ AT . This bound is achieved  in
upper bound holds: E [SRevγ γ(A  V )] ≤ Γp∗
particular  by the algorithm A∗
D  i.e.  ∀n A∗
D  and is
referred to as the optimal constant algorithm. Overall  the following theorem holds:
Theorem 1 ([29]). Let the discount rates be equal: γS = γB = γ. Then the optimal constant algorithm
A∗
1 is optimal among all pricing algorithms AT and the optimal revenue is Γp∗
“Big deal" for less patient seller. Let us consider the whole case of less patient seller: γS ≤ γB. It
is easy to see that Revγ1 (A  a)≤ Revγ2 (A  a) for any A and a  when γ1 ≤ γ2. Hence  for any A 
v  and γ1≤ γ2  the inequality SRevγ1 γ B (A  v)≤ SRevγ2 γ B (A  v) holds as well  since the optimal
strategy aOpt does not depend on the seller’s discount γS. So  taking γ1 = γS and γ2 = γB  one gets:
(2)

D))  where FD is the CDF of our valuation variable V ∼ D and p∗

1 which constantly offers the price p∗

D(1 − F (p∗

D)).

D(1 − F (p∗

E [SRevγ B γ B(A  V )] = ΓBp∗

D(1 − FD(p∗

D)).

1(n) = p∗

maxA∈AT

E [SRevγ S γ B(A  V )] ≤ maxA∈AT

The latter identity in Eq. (2) is from Th. 1. The bound in Eq. (2) is achievable as well. Namely  let us
consider the following algorithm A∗
bd (referred to as the “big deal") given γB and V ∼ D: the ﬁrst
price is Abd(e) = ΓBp∗
D; if the buyer accepts it  prices in further rounds will be Abd(1 ◦ n) = 0 ∀n;
otherwise Abd(0 ◦ n) = p∗
D ∀n. An attentive reader may note that the strategic buyer accepts the ﬁrst
D. Hence  similarly to the algorithm A∗
bd(e) ⇔ v > p∗
price A∗
1  it is easy to show that the ESR of
A∗
D(1 − F (p∗
D)). The key idea behind the algorithm A∗
bd is ΓBp∗
bd is quite simple. Roughly speaking 
the seller “accumulates" all her revenue at the ﬁrst round by proposing the buyer a “big deal" that
incentivises him to pay a large price at the ﬁrst round and get all goods in the subsequent rounds for
free  or  otherwise  get nothing8. Overall  the following theorem holds:
Theorem 2. Let the discount rates be s.t. γS ≤ γB. Then the “big-deal" algorithm A∗
among all pricing algorithms AT and the optimal revenue is ΓBp∗(1 − FD(p∗)).

bd is optimal

6RTB platforms run 108 auctions a day: commitment violation will be easily seen by advertisers  see App.F.
7This price can be ﬁnd by the equation p=(1−FD(p))/fD(p)  when D has continuous probability density fD.
8A similar pricing was in [49] for mechanism environments with multiplicative separability.

4

Th. 2 implies that  ﬁrst  the optimal constant algorithm A∗
1 is not the unique optimal one in the
subcase of equal discounts γS = γB. Second  in the other subcase of γS < γB  the constant algorithm
1 is no longer optimal: the relative ESR of the optimal algorithm A∗
A∗
bd w.r.t. the optimal constant one
A∗
9; i.e. the optimal revenue is larger than the one obtained by
1 is ΓB/ΓS  which is > 1  when γS<γB
offering the Myerson price constantly. This result is quite inspiring for the seller  since the dominance
of the buyer’s discount γB over the seller’s one γS suggests a hypothesis that the seller should earn
lower than with γB (e.g.  see the revenue of A∗
1). But the ability of the seller to apply the trick of
“accumulation" of all her revenue at the ﬁrst round allows her to get the payments for all goods
discounted by the buyer’s γB at the ﬁrst round and to boost thus her revenue over the constant pricing.
Remark 1. All results of the section hold even for non-geometric discounts s.t. γS≤γB (see App.A.1).
4 Less patient buyer (γS ≥ γB): reduction to an optimization functional
This section provides the central fundamental results of our study. They are obtained for ﬁnite games 
but  further  we show how to use them to get approximately optimal algorithms even for inﬁnite
games. In contrast to the case γS≤γB  ﬁnding an optimal pricing for γS≥γB is much more difﬁcult
problem since the technique used in Sec. 3 to upper bound the expected strategic revenue is no longer
applicable (because it relies on the condition γS≤γB) and a generalization of the functional HD(·)
to a multivariate analogue is required. Note that the optimization problem of the ESR has structure
similar to a saddle-point problem: the ESR depends on A via aOpt which is an argmax over the
set of strategies ST . Moreover  the derivative of such dependences are piecewise continuous with
jump discontinuities on the boundaries of pieces (there are 22T −3 pieces with derivatives of different
forms). Hence  the problem in the initial form can be numerically solved only via brute-force search.
In order to make numerical solution of the problem more feasible  we will reduce it into the form of
a multidimensional maximization of a simple bilinear-like function (namely  L(v) in Eq.(4)) that is
continuously differentiable as many times as the CDF FD and its derivatives have simple form and
can be easily computed. The key steps are: (1) ﬁnd a class of algorithms whose prices (2) can be
linearly parametrized by points in the support of D s.t. (3) the strategic revenue is constant between
these points. For the sake of presentation  we consider regular discounts.
Deﬁnition 1. A discount sequence γ is regular  if γ·a1(cid:54)= γ·a2 for any strategies a1  a2∈ ST   i.e.  any
t atbt).
Deﬁnition 2. Let γ be a discount  then an algorithm A ∈ AT is said to be completely active (CA)
for γ  if for any strategy a ∈ ST there exists a valuation v ∈ R+ s.t. Sa(v) = S(v)  where
Sa(v) := Surγ(A  a  v) and S(v) := SaOpt(A v γ)(v)  i.e.  the surplus function Sa (as a line) is
tangent to the optimal surplus function S. We denote the set of all CA algorithms for γ by ˜AT (γ).

buyer strategy a ∈ ST results in a unique discounted quantity of purchased goods (a · b :=(cid:80)

B

A CA algorithm is such that any node in its labeled tree can be reached by the strategic buyer for at
least one valuation v  i.e.  be active. Surprisingly  any algorithm can be transformed to a completely
active one for γB with no loss in the expected strategic revenue. Indeed  let A be a non-CA algorithm
for γB  then there exists an inactive strategy a ∈ ST (i.e. ∀v ≥ 0 Sa(v) < S(v)). We tune A
in such a way that Sa becomes tangent to S without affecting the other surplus functions Sb for
b (cid:54)= a (it is visualized in Fig. A.1 in App. A.2.1). Namely  let τ be the index of the last 1 in a
and n := a1:τ−1 be the (τ−1)-round substrategy of a. We decrease p := A(n) until Sa becomes
tangent to S. This operation will move also all Sb s.t. b1:τ = a1:τ to the left. In order to make them
unaffected  we simultaneously increase ps :=A(n ◦ 10s) for 0≤ s≤ T − τ − 1 in such a way that
ps = const. Hence  aOpt(A  v  γB) is unaffected for all v except the point of tangency. Since
p + γs+1
γS > γB  the revenues Revγ S (A  v  b) only increase after our tuning  when b1:τ = a1:τ   otherwise
they are not changed for b(cid:54)= a what infers that SRevγ S γ B (A  · ) increases in all points except one.
Tuning of the algorithm by “activating" all inactive strategies one by one in descending order of τ
(this ensures that decreasing of p will not result in negative prices) gives us a CA (for γB) algorithm
without loss in the ESR. Formally  the following proposition holds (the proof is in App. A.2.1).
}T
Proposition 1. Let T ∈ N and γS  γB be discount rates s.t. γS ≥ γB and the sequence γB ={γt−1
is regular. Then  for any pricing algorithm A ∈ AT   there exists a CA algorithm ˜A ∈ ˜AT (γB) s.t.
(3)
and goes to +∞ as γB→1− for a ﬁxed γS.

E(cid:2)SRevγ S γ B (A  V )(cid:3) ≤ E(cid:2)SRevγ S γ B( ˜A  V )(cid:3).

9Moreover  for T =∞  this revenue improvement is ΓB/ΓS= 1−γS
1−γB

B

t=1

5

j=1

The fundamental property of a CA algorithm: it bijectively corresponds to the break (discontinuity)
points of the derivative of its surplus function S(·)  which is piecewise linear10. Namely  the class
˜AT can be linearly mapped onto ∆k :={v={vj}k
j=1 ∈Rk|0≤v1≤...≤vk}  where k:=k(T ):=2T−1.
The key intuition is as follows. Number the buyer strategies ST = {a0  ...  ak} in ascending order
of the slope γB · ai of the corresponding γB-discounted surplus function Sai (the γB-dependent
natural order). Let (vi  si) be the coordinates of the intersection of the straight lines Sai(·) and
Sai−1 (·). An algorithm is CA iff these intersections are on the envelop S(·) and vi−1 ≤ vi ∀i ≤ k.
The linear parametrization holds since the break point vi is linearly expressed in terms of the slopes
and intercepts of the lines Sai(·) and Sai−1 (·)  while the intercepts are linear in the algorithm prices.
Formally  this dependence is the product ZT (γB)JT KT (γB  γB) of k × k matrices  where JT is
a two-diagonal one with 1 on the diagonal and −1 under the diagonal; ZT (γ) = diag(z1  ..  zk) 
zj = (γ · aj − γ · aj−1)−1 for j = 1  ..  k; and KT (γB  γ(cid:48)) = ((κij))i j=1 .. k  where κij = γ(cid:48)
t if
tai
the path ai ∈ ST passes through the node nj ∈ NT whose round is t=|nj|+1  and κij = 0  otherwise 
for some ﬁxed numbering of the nodes NT = {nj}k
11. All technical details are in App. A.2.2.
Finally  the parametrization via the break points {vi}k
i=1 allows to easily calculate the ESR of the
algorithm. Indeed  the revenue SRevγ S γ B(A  v) is constant on the intervals (vi  vi+1)  because γB
is regular and the strategic buyer chooses only the strategy ai  when his valuation v is in (vi  vi+1).
Hence  the ESR is the sum of constant revenues on the intervals weighted by their probabilities:
i=1(FD(vi+1) − FD(vi))Revγ S (A  ai)  where Revγ S (A  ai) can be lin-
early expressed in terms of the algorithm prices and  thus  in terms of the break points {vi}k
i=1 (by
means of our matrices introduced above). Integration by parts makes the ESR be a bilinear form of
{1−FD(vi)}k
i=1. We formalize it in the following proposition (the proof is in App. A.2.3) 
which implies Th. 3 since the class of CA algorithms ˜AT contains an optimal pricing (by Prop. 1).
Proposition 2. Let T ∈ N  γS be a discount  γB be a regular discount  the strategies ST be naturally
ordered by γB and the matrix notations be introduced as above. Then there exists an invertible linear
transformation wγ B : ˜AT (γB) → ∆k  k = k(T )  s.t.  for any completely active pricing algorithm
A ∈ ˜AT (γB)  its ESR has the form EV ∼D [SRevγ S γ B (A  V )] = LD γ S γ B(wγ B (A))  where

E [SRevγ S γ B (A  V )] =(cid:80)k

LD γ S γ B(v) := (1 − FD(v))
ΞT (γS  γB) := JT · KT (γB  γS)KT (γB  γB)−1J−1
depends only on the discounts; and the vector (1 − FD(v)) := {1−FD(vi)}k
Theorem 3. Let T ∈ N and γS  γB be discount rates s.t. γS ≥ γB and the sequence γB ={γt−1
t=1
is regular. The optimization problem of ﬁnding an optimal algorithm is equivalent to maximization of
the multivariate functional LD γ S γ B (·) over the set ∆k ={v ∈ Rk| 0≤ v1≤ ...≤ vk}  k = 2T −1  i.e. 
(5)

(4)
T ZT (γB)−1 is the invertible k × k matrix that
}T

ΞT (γS  γB)v  v ∈ ∆k;

i=1 and {vi}k

i=1 ∈ Rk.

EV ∼D[SRevγ B γ S(A  V )] = max
v∈∆k

LD γ S γ B (v) 

maxA∈AT

(cid:124)

B

where LD γ S γ B is deﬁned in Eq. (4) and depends only on the discounts and the distribution D.

It is quite important to emphasize that the k-dimensional functional LD γ S γ B is a bilinear form
applied to the vectors v and 1 − FD(v). This bilinear form is independent of the distribution
D and is deﬁned by the matrix ΞT (γS  γB). In this view  there is a strong relationship between
our optimization functional LD γ S γ B and the function HD (see Sec. 3): the functional LD γ S γ B
constitutes the key basis of optimal algorithms in dynamic setting and is fundamental for them as the
function HD(p) = pPV ∼D[V ≥ p] is fundamental for optimal pricing in static auctions. Moreover 
in the case of equal discounts γS = γB  the optimization of LD γ B γ B reduces to the maximization of
HD (simple algebra is in App. A.2.4). Since  in the particular case of γS = γB  the optimization of
LD γ B γ B has no closed form solution (it reduces to the optimization of HD)  we thus expect that  in
the other cases  generally  our optimization problem does not admit a closed form solution as well.
In contrast to the initial form of our problem  numerical optimization of the functional LD γ B γ B
is much easier (though it still has the same number of variables as the initial problem). First  the
functional is continuously differentiable as many times as the CDF FD. Second  its derivatives
l(1 − FD(vl))ξli  ∂vi∂vj L(v) =
10In a piece (an interval (vi  vi+1)) the function S(·) equals to the function Sai (·) for some strategy ai which

have simple form  i  j = 1  ..  k: ∂viL(v) =−fD(vi)(cid:80)
is a linear function of v: Sai (v) = ((cid:80)
11Note: by the deﬁnition  the i-th component of the vector KT (γ B  γ(cid:48))A is equal to(cid:80)T

l ξilvl +(cid:80)

t)v − ((cid:80)

tpt)  see Def. 2.

t γB

t γB

tA(ai
t=1γ(cid:48)
tai

1...ai

t−1).

t ai

t ai

6

D(vi)(cid:80)

vi

L(v) =−2fD(vi)ξii−f(cid:48)

−fD(vi)ξij−fD(vj)ξji for i (cid:54)= j  and ∂2
l ξilvl  where ξij is the
ij-th element of ΞT (γS  γB). The derivatives can be easily computed: see App. I for the pseudo-code
that calculates ξij. Third  the domain ∆k is convex (moreover is closed when the support of FD is
bounded) and has a simple form of simplex. Finally  the matrix ΞT (γS  γB) is positive deﬁnite on ∆k.
Hence  a variety of gradient methods can be used to ﬁnd the solution (see our experiments in Sec. 5).
The step-by-step instruction to ﬁnd the optimal pricing. Remind that  for static pricing  the op-
timal (Myerson) price can be found from maximization of the functional HD(p) = p(1 − FD(p)).
In our dynamic case  the optimal pricing algorithm can be found similarly as follows: (I) construct
the matrix Ξ (the pseudo-code to calculate its elements is in Appendix I); (II) construct the func-
tional LD γ B γ B (·) from Eq. (4); (III) ﬁnd a vector vOpt s.t. it maximizes LD γ B γ B (v)  e.g.  an apply
numerical method using derivatives of LD γ B γ B (·) provided in the previous paragraph; (IV) convert
γ B (·) 
the vector vOpt to the prices of the optimal algorithm by means of the linear transformation w−1
which is mentioned in Prop. 2 and whose matrix is KT (γB  γB)−1J−1
T ZT (γB)−1 (see App. A.2.2).
Remark 2. In Appendix A.2  we show that all results of this section hold also for non-geometric
discounts γS = {γS
t ≤ γS
Remark 3. The regularity of the discount γB is used to get: the uniqueness of γ-dependent natural
order of the strategies ST (for Prop. 2); zero probability of valuations for which the optimal buyer
strategy is not unique (in Prop. 1). Ways to relax this restriction are discussed in App. D. In any way 
non-regular discounts are rare  and do not affect our qualitative results in Sec. 5.

t=1 and γB = {γB

t=1 such that γB

t .
t+1/γS

t+1/γB

t }T

t }T

5 Efﬁcient approximation  constrained optimization  numerical experiments
Approximation by optimal τ-step pricing (γS ≥ γB). In the case of inﬁnite games  we have no
similar powerful instrument to ﬁnd an optimal pricing (unlike to the case of ﬁnite games in Sec. 4).
Moreover  when the horizon T is ﬁnite but sufﬁciently large  the optimization problem even in the
simpliﬁed form of Eq. (5) suffers from dimensional complexity since the number of variables is
2T − 1. In both cases  however  we can approximate the optimal algorithm by an algorithm that
is optimal in some ﬁnite dimensional subclass of AT   T ∈ N∪{∞}. Namely  for τ ∈ N  let us say
that A is a τ-step pricing algorithm  if ∀a  t > τ : A(a1:t−1) = A(a1:τ−1)  i.e.  it is constant
from the τ-th round on. The set of all τ-step algorithms is denoted by Aτ
T . An attentive reader
may note that the problem of ﬁnding an optimal τ-step algorithm A∈ Aτ
T for the ﬁnite or inﬁnite
game is equivalent to ﬁnding an optimal algorithm for the τ-round ﬁnite game with "shortened"
discount sequences γS τ := (γS
t ). Hence  one
can apply the optimization technique from Th. 3 (which holds for γB τ and γS τ due to Remark 2).
The following proposition (the proof is in App. A.3.1) formally states that the expected revenue of the
T converges to one of the optimal pricing A∗ ∈ AT when τ → T .
optimal τ-step algorithm A∗
Proposition 3. Let T ∈ N ∪ {∞} and γS  γB be discount sequences s.t. γB
τ :=

τ−1 (cid:80)T

τ−1 (cid:80)T

t ) and γB τ := (γB

τ ∈ Aτ

t ≤ γS

1  ..  γB

1  ..  γS

t+1/γS

t+1/γB

t=τ γB

t=τ γS

t   ΓS

(cid:80)T

t=τ +1 γS
E[SRevγ S γ B (A V )]≤ maxA∈AT

t for τ ∈ N  τ < T . Then the following bounds hold:
E [SRevγ S γ B(A V )] ≤ maxA∈Aτ

T

maxA∈Aτ

T

E [SRevγ S γ B(A  V )]+ΓS

τ

E [V ] .

(6)

S

1

E [V ] /ΓS

E [V ] = γτ−1

First  Prop. 3 provides the seller with a tool to make a trade-off between the achievable fraction of
the maximal revenue and the computational complexity of the optimization problem to be solved.
In particular  she is able to choose the parameter τ s.t. her computational capabilities on the dimen-
sion 2τ − 1 of the optimization functional L are ﬁtted and the boost in the relative regret bound
is minimal. Note that the seller can improve her revenue obtained from an
ΓS
τ
optimal constant algorithm just by applying an optimal τ-step algorithm for small τ. For instance  for
τ = 4  this algorithm can be easily found in 2τ − 1 = 15-dimensional space and provides noticeable
boost in revenue (revenue improvement is illustrated in Fig. 1). Second  from Eq. (6)  we have that
τ = γS. On the one
the convergence bound is ΓS
hand  it means that the smaller γS is  the faster the revenue of the suboptimal algorithm A∗
τ converges
to the optimal revenue  and  thus  the functional L in Eq. (4) with the smaller dimension should be
optimized to reach revenue close to the optimal one within  error   > 012. On the other hand  the
((1−γS)E[V ]) to be -close to the optimal revenue. Note that τγS D →γS→0 0.

S /(1 − γS) and the convergence rate is ΓS

12Take τ > τγS D  := logγS

τ +1/ΓS

τ = γτ

7

4 and the relative expected strategic revenue (w.r.t. A∗

4(n)  for nodes n∈ N s.t. |n|≤ 3  of the
Figure 1: Inﬁnite game T = ∞  uniform D. The prices A∗
optimal 4-step algorithm A∗
1) of the optimal
τ-step algorithm A∗
τ   τ = 2  .. 6  for discounts: (a) γS=0.8 and various γB; (b) γB=0.2 and various γS.
slower convergence rate is  the more revenue can be extracted from non-static pricing. Namely  the
closer γS to 1 is  the larger the improvement of the revenue of the optimal τ-step pricing is w.r.t. the
constant pricing (for ﬁxed γB and τ). This is both supported by our experiments (see growing relative
revenue in Fig. 1(b  bottom) & Fig.C7 as γS grows) and in line with the intuition: the larger γS is  the
more revenue could be earned in future rounds (and hence the more proﬁtable dynamic pricing is).
Optimal algorithms with constraints. One more structural insight of our reduction in Sec. 4:
optimization over the set of break points {vi} of the surplus envelope S allows to ﬁnd optimal
algorithms with constraints that can be expressed in terms of these break points. In particular  the
seller is able to control the probability of buyer usage of each strategy ai∈ ST through a constraint
on F (vi+1)−F (vi) (e.g.  setting it to zero). E.g.  the seller is looking for an algorithm s.t. strategies
active with positive probability are monotone  i.e. of the form 0n1T−n for some n≤ T . Hence  if ai
is not monotone  then vi = vi+1  i.e. the line Sai is tangent to the envelope S in only one point. To
ﬁnd an optimal algorithm among those for which vi = vi+1  one needs slightly update the functional
L: replace i-th and (i+1)-th rows in the matrix Ξ by their sum  do the same with i-th and (i+1)-th
columns  and remove i-th components from the vectors 1−F (v) and v. The modiﬁed optimization
functional for the problem with constraints will have T +1 variables since it is equal to the number of
strategies that are active with positive probability. So  the dimensionality of the optimization problem
can be reduced by means of constraints on the form of the algorithm  that can thus be ﬁnd efﬁciently.
Lower bound on the maximal revenue for γS = 1. In this case  the algorithm PRRFES [30][Th.5]
with optimal upper regret bound can be used to get a lower bound on the optimal ESR. Using PRRFES 
the seller is able to increase her revenue w.r.t. the optimal constant pricing by up to E[V ]/HD(p∗
D) > 1
(e.g.  it is +100% when D is uniform on [0  1]) as T → +∞. See details in App. G.
Numerical experiments13. To show the practical proﬁt and properties of optimal algorithms obtained
via our functional L from Eq. (4) for the case γS ≥ γB  we conducted numerical experiments in
several representative games. We seek for optimal τ-step algorithms A∗
τ   τ = 2  ..  6  in inﬁnite
games with the valuation V uniformly distributed in [0  1]14  i.e.  FD(v) = v. Hence  the functional
LD γ S γ B becomes thus quadratic and is optimized numerically using the Sequential Least Squares
Programming. The ESR of the algorithms are compared with the expected revenue HD(p∗(D))ΓS of
the optimal constant pricing A∗
1 (see Sec. 3)  which is treated as the baseline from here on. Fig. 1
contains: the obtained in this way prices A∗
4(n) for all nodes n (at the top) and the relative expected
strategic revenue of A∗
τ (w.r.t. A∗
1) for τ=2  ..  6 (at the bottom). The results in Fig. 1(a) are for γS=0.8
and γB∈{0.01+i·0.005}148
First  at the bottom of Fig. 1  we see that the optimal τ-step algorithms A∗
τ outperform the baseline
optimal constant pricing A∗
1 for any observed pair of discounts. Moreover  Fig. 1 demonstrates that
the signiﬁcant increase in revenue can be obtained even when the minimal possible step aside from the
constant pricing is made (τ = 2). E.g.  the seller can extract up to +20% revenue by just maximizing
the functional Eq. (4) in the 3-dimensional space (since 2τ − 1 = 3 for τ = 2): e.g.  the revenue
improvement is larger than 20% for γS = 0.9  γB = 0.2  larger than 16% for γS = 0.8  γB = 0.5 
and larger than 10% for γS = 0.8  γB = 0.55. Second  we see that the expected strategic revenue of
A∗
τ converges quite quickly to the optimal one (which thus larger than the revenue of the baseline
A∗
1 as well). This observation constitutes the empirical evidence of Prop. 3  which suggests that

i=0  while the ones in Fig. 1(b) for γB=0.2 and γS∈{0.2+i·0.005}159
i=0.

13The code of all our experiments is avail. at https://github.com/theonlybars/neurips-2019-rppa.
14Experiments for other distributions and horizons are presented in App. C. The results for them are similar.

8

0.10.20.30.40.50.60.70.8(b) gamma_b = 0.2A(000)A(00)A(001)A(0)A(010)A(01)A(011)A()A(100)A(10)A(101)A(1)A(110)A(11)A(111)0.10.20.30.40.50.60.70.8Optimal algorithm prices(a) gamma_s = 0.80.20.30.40.50.60.70.80.9gamma_s1.01.11.21.31.41.51.6BaselineOptimal tau = 2Optimal tau = 3Optimal tau = 4Optimal tau = 5Optimal tau = 60.00.10.20.30.40.50.60.70.8gamma_b1.01.11.21.31.4Relative expected strategic revenuethe convergence rate is equal to γS. Third  the top part of Fig. 1 demonstrates us that an optimal
algorithm may be non-consistent: e.g.  the reverse order of the prices A∗
4(001) for γB >
≈ 0.57 in Fig. 1(a). Fourth  if the distance between the discount rates γS and γB converges to 0  then
the optimal algorithm A∗ converges to the optimal constant one A∗
1 (what experimentally supports
that HD is a special case of LD γ S γ B). More details and observations are in App. C.2.3. Overall  we
conclude that learning of prices even in several starting rounds allow to extract revenue signiﬁcantly
larger than the one of optimal static pricing.

4(e) < A∗

6

Incomplete information about buyer discount sequence

t   γ1

t ]}T

t ; γ1

ˆγB  then she can apply “Big deal"  which prices are calculated using ˆγB: Abd(e) = (cid:80)
still accepts the ﬁrst proposed price  hence  the seller gets at least(cid:80)

Our results can also be applied in the case of a weak assumption on the seller’s information about
the buyer’s discount sequence. The weak assumption: the seller does not know the exact discount
sequence of the buyer  but rather knows a set of intervals {[γ0
t=1 s.t. the discount coefﬁcient γB
t
t ]. We provide the interpretation of the model  which explains the foundation of
is located in [γ0
the weak assumption. We also show the performance of our results adapted to the weak assumption
setting. For the sake of exposition  all discount sequences are geometrical from here on in the section.
The discount in our model can be interpreted as the continuation probability  i.e.  γ is the probability
that the game will continue for one more round. E.g.  in the example from Sec. 1 (see App. F for an
extended version as well)  γ is the probability that the user does not click on the ad and follows a
link that is in the sight of the RTB platform. In this interpretation  the discount γ is common. The
difference in discounts appears  because the seller and the buyer do not know γ exactly  but rather
estimate it based on available information about the user. Let γ = γ(ξ1  ξ2)  where ξ1  ξ2 are user
features. Assume that the seller observes both ξ1 and ξ2  while the buyer observes only ξ1. Then the
seller is able to estimate γ accurately as well as to recover the buyer’s estimate γB(ξ1). To sum up: it
is likely that the seller in our model can at least recover the buyer discount γB with high accuracy.
Let us consider two cases. Case (1): if the seller knows only a lower bound ˆγB for γB s.t. γS <
t ˆγt−1
p∗
D;
D ∀n. Buyer (whose discount γB ≥ ˆγB) with valuation v > p∗
Abd(1 ◦ n) = 0 ∀n; Abd(0 ◦ n) = T p∗
D)). This is
less than the optimal revenue (when γB is known exactly)  but strictly larger than the one of static
pricing. Similarly  modiﬁcations of “Big deal" can be applied when seller knows only distribution
of γB  γB ≥ γS. Case (2): The seller uses the functional L to ﬁnd an optimal algorithm  assumes
buyer’s discount is γ(cid:48)
B = γB + ε  but faces a buyer with true
discount γB. We evaluate the loss in revenue by the following
numerical experimentation: T = 5  V ∼ U [0; 1] (uniform
on [0; 1]) and γS = 0.5 (different sets of parameters give
qualitatively the same results). In ﬁgure above  the expected
strategic revenue (ESR) of this seller is divided by the ESR
of a well-informed seller (i.e. s.t. ε = 0). We see: (a) if ε is
small enough (for ε = 0.02  or ≥ 4% of γB)  then S still able
to extract over 99% of the optimal ESR; (b) even if ε is very
large (for ε = 0.1  or ≥ 20% of γB) S still able to extract
over 97% of the optimal ESR for most cases (γB ≤ 0.4); and
(c) if S is able to just separate γB of γS with a decent margin  then she is able to gain extra revenue.

D(1 − F (p∗
p∗

t ˆγt−1

B

B

D

7 Conclusions

We studied online learning algorithms that maximize expected cumulative revenue of repeated posted-
price auctions with a strategic buyer that holds a ﬁxed private valuation. First  when the participants
non-equally discount their cumulative utilities  we showed that the constant pricing  surprisingly  is no
longer optimal. Second  for the case of more patient seller  we introduced a novel multidimensional
optimization functional which is a multivariate analogue of the one used to determine Myerson’s price.
This functional can be used (1) to ﬁnd an optimal dynamic pricing  i.e.  by efﬁcient gradient-based
methods; and (2) to construct an optimal τ-step algorithm (low-dimensional approximation) that
allows the seller to improve her revenue even in the game with a large horizon T . Finally  we
conducted extensive numerical analysis to show that optimal algorithms are non-trivial  may be
non-consistent  and generate larger expected revenue than the constant pricing with Myerson’s price.

9

0.200.250.300.350.400.450.50Gamma_B (true buyer discount)0.880.900.920.940.960.981.00Expected Strategic Revenue relative to optimalESR relative to optimal in case of estimation error; g_S = 0.5; v ~ U[0; 1]; T = 5;eps = 0.0eps = -0.1eps = -0.05eps = -0.02eps = -0.01eps = 0.01eps = 0.02eps = 0.05eps = 0.1const MyersonReferences
[1] D. Agarwal  S. Ghosh  K. Wei  and S. You. Budget pacing for targeted online advertisements at linkedin.

In KDD’2014  pages 1613–1619  2014.

[2] G. Aggarwal  A. Goel  and R. Motwani. Truthful auctions for pricing search keywords. In Proceedings of

the 7th ACM conference on Electronic commerce  pages 1–7. ACM  2006.

[3] G. Aggarwal  G. Goel  and A. Mehta. Efﬁciency of (revenue-) optimal mechanisms. In EC’2009  pages

235–242  2009.

[4] G. Aggarwal  S. Muthukrishnan  D. Pál  and M. Pál. General auction mechanism for search advertising. In

WWW’2009  pages 241–250  2009.

[5] K. Amin  M. Kearns  P. Key  and A. Schwaighofer. Budget optimization for sponsored search: Censored

learning in mdps. In UAI’2012  pages 54–63  2012.

[6] K. Amin  M. Kearns  and U. Syed. Bandits  query learning  and the haystack dimension. In COLT  2011.

[7] K. Amin  A. Rostamizadeh  and U. Syed. Learning prices for repeated auctions with strategic buyers. In

NIPS’2013  pages 1169–1177  2013.

[8] K. Amin  A. Rostamizadeh  and U. Syed. Repeated contextual auctions with strategic buyers. In NIPS’2014 

2014.

[9] I. Ashlagi  C. Daskalakis  and N. Haghpanah. Sequential mechanisms with ex-post participation guarantees.

In EC’2016  2016.

[10] I. Ashlagi  B. G. Edelman  and H. S. Lee. Competing ad auctions. Harvard Business School NOM Unit

Working Paper  (10-055)  2013.

[11] M. Babaioff  S. Dughmi  R. Kleinberg  and A. Slivkins. Dynamic pricing with limited supply. ACM

Transactions on Economics and Computation  3(1):4  2015.

[12] Y. Bachrach  S. Ceppi  I. A. Kash  P. Key  and D. Kurokawa. Optimising trade-offs among stakeholders in

ad auctions. In EC’2014  pages 75–92  2014.

[13] S. Balseiro  O. Besbes  and G. Y. Weintraub. Dynamic mechanism design with budget constrained buyers

under limited commitment. In EC’2016  2016.

[14] S. R. Balseiro  O. Besbes  and G. Y. Weintraub. Repeated auctions with budgets in ad exchanges:

Approximations and design. Management Science  61(4):864–884  2015.

[15] D. Bergemann and M. Said. Dynamic auctions. Wiley Encyclopedia of Operations Research and Manage-

ment Science  2010.

[16] D. Besanko. Multi-period contracts between principal and agent with adverse selection. Economics Letters 

17(1-2):33–37  1985.

[17] H. Bester and R. Strausz. Contracting with imperfect commitment and the revelation principle: the single

agent case. Econometrica  69(4):1077–1098  2001.

[18] C. Borgs  J. Chayes  N. Immorlica  K. Jain  O. Etesami  and M. Mahdian. Dynamics of bid optimization in

online advertisement auctions. In WWW’2007  pages 531–540  2007.

[19] C. Borgs  J. Chayes  N. Immorlica  M. Mahdian  and A. Saberi. Multi-unit auctions with budget-constrained
bidders. In Proceedings of the 6th ACM conference on Electronic commerce  pages 44–51. ACM  2005.

[20] L. E. Celis  G. Lewis  M. M. Mobius  and H. Nazerzadeh. Buy-it-now or take-a-chance: a simple sequential

screening mechanism. In WWW’2011  pages 147–156  2011.

[21] N. Cesa-Bianchi  C. Gentile  and Y. Mansour. Regret minimization for reserve prices in second-price

auctions. In SODA’2013  pages 1190–1204  2013.

[22] D. Charles  N. R. Devanur  and B. Sivan. Multi-score position auctions. In WSDM’2016  pages 417–425 

2016.

[23] S. Chawla  N. R. Devanur  A. R. Karlin  and B. Sivan. Simple pricing schemes for consumers with evolving

values. In SODA’2016  pages 1476–1490  2016.

10

[24] X. Chen and Z. Wang. Bayesian dynamic learning and pricing with strategic customers. SSRN  2016.

[25] Y. Chen and V. F. Farias. Robust dynamic pricing with strategic customers. In EC’2015  pages 777–777 

2015.

[26] M. Chhabra and S. Das. Learning the demand curve in posted-price digital goods auctions.

ICAAMS’2011  pages 63–70  2011.

In

[27] M. C. Cohen  I. Lobel  and R. Paes Leme. Feature-based dynamic pricing. In EC’2016  2016.

[28] A. V. den Boer. Dynamic pricing and learning: historical origins  current research  and new directions.

Surveys in operations research and management science  20(1):1–18  2015.

[29] N. R. Devanur  Y. Peres  and B. Sivan. Perfect bayesian equilibria in repeated sales. In SODA’2015  2015.

[30] A. Drutsa. Horizon-independent optimal pricing in repeated auctions with truthful and strategic buyers. In

WWW’2017  pages 33–42  2017.

[31] A. Drutsa. On consistency of optimal pricing algorithms in repeated posted-price auctions with strategic

buyer. CoRR  abs/1707.05101  2017.

[32] A. Drutsa. Weakly consistent optimal pricing algorithms in repeated posted-price auctions with strategic

buyer. In ICML’2018  pages 1318–1327  2018.

[33] A. Drutsa. Reserve pricing in repeated second-price auctions with strategic bidders. CoRR  abs/1906.09331 

2019.

[34] P. Dütting  M. Henzinger  and I. Weber. An expressive mechanism for auctions on the web. In WWW’2011 

pages 127–136  2011.

[35] B. Edelman and M. Ostrovsky. Strategic bidder behavior in sponsored search auctions. Decision support

systems  43(1):192–198  2007.

[36] B. Edelman  M. Ostrovsky  and M. Schwarz. Internet advertising and the generalized second-price auction:

Selling billions of dollars worth of keywords. American economic review  97(1):242–259  2007.

[37] M. Feldman  T. Koren  R. Livni  Y. Mansour  and A. Zohar. Online pricing with strategic and patient

buyers. In NIPS’2016  pages 3864–3872  2016.

[38] G. Goel and M. R. Khani. Revenue monotone mechanisms for online advertising. In WWW’2014  2014.

[39] G. Goel  M. R. Khani  and R. P. Leme. Core-competitive auctions. In EC’2015  pages 149–166  2015.

[40] R. Gomes and V. Mirrokni. Optimal revenue-sharing double auctions with applications to ad exchanges.

In WWW’2014  pages 19–28  2014.

[41] R. Gonen and E. Pavlov. An incentive-compatible multi-armed bandit mechanism. In Proceedings of the
twenty-sixth annual ACM symposium on Principles of distributed computing  pages 362–363. ACM  2007.

[42] A. Greenwald  J. Li  and E. Sodomka. Approximating equilibria in sequential auctions with incomplete

information and multi-unit demand. In NIPS’2012  pages 2321–2329  2012.

[43] O. D. Hart and J. Tirole. Contract renegotiation and coasian dynamics. The Review of Economic Studies 

55(4):509–540  1988.

[44] D. He  W. Chen  L. Wang  and T.-Y. Liu. A game-theoretic machine learning approach for revenue

maximization in sponsored search. In IJCAI’2013  pages 206–212  2013.

[45] H. Heidari  M. Mahdian  U. Syed  S. Vassilvitskii  and S. Yazdanbod. Pricing a low-regret seller. In

ICML’2016  pages 2559–2567  2016.

[46] P. Hummel and P. McAfee. Machine learning in an auction environment. In WWW’2014  pages 7–18 

2014.

[47] N. Immorlica  B. Lucier  E. Pountourakis  and S. Taggart. Repeated sales with multiple strategic buyers. In

EC’2017  pages 167–168  2017.

[48] K. Iyer  R. Johari  and M. Sundararajan. Mean ﬁeld equilibria of dynamic auctions with learning. ACM

SIGecom Exchanges  10(3):10–14  2011.

11

[49] S. M. Kakade  I. Lobel  and H. Nazerzadeh. Optimal dynamic mechanism design and the virtual-pivot

mechanism. Operations Research  61(4):837–854  2013.

[50] Y. Kanoria and H. Nazerzadeh. Dynamic reserve prices for repeated auctions: Learning from bids. SSRN 

2017.

[51] R. Kleinberg and T. Leighton. The value of knowing a demand curve: Bounds on regret for online

posted-price auctions. In Foundations of Computer Science  pages 594–605  2003.

[52] V. Krishna. Auction theory. Academic press  2009.

[53] T. Lin  J. Li  and W. Chen. Stochastic online greedy learning with semi-bandit feedbacks. In NIPS’2015 

2015.

[54] B. Lucier  R. Paes Leme  and E. Tardos. On revenue in the generalized second price auction. In WWW’2012 

pages 361–370  2012.

[55] A. M. Medina and S. Vassilvitskii. Revenue optimization with approximate bid predictions. In NIPS’2017 

2017.

[56] A. Mehta  A. Saberi  U. Vazirani  and V. Vazirani. Adwords and generalized on-line matching. In 46th
Annual IEEE Symposium on Foundations of Computer Science (FOCS’05)  pages 264–273. IEEE  2005.

[57] V. Mirrokni  R. Paes Leme  P. Tang  and S. Zuo. Non-clairvoyant dynamic mechanism design. 2017.

[58] M. Mohri and A. M. Medina. Learning theory and algorithms for revenue optimization in second price

auctions with reserve. In ICML’2014  pages 262–270  2014.

[59] M. Mohri and A. M. Medina. Non-parametric revenue optimization for generalized second price auctions.

In UAI’2015  2015.

[60] M. Mohri and A. M. Medina. Learning algorithms for second-price auctions with reserve. JMLR 

17(74):1–25  2016.

[61] M. Mohri and A. Munoz. Optimal regret minimization in posted-price auctions with strategic buyers. In

NIPS’2014  pages 1871–1879  2014.

[62] M. Mohri and A. Munoz. Revenue optimization against strategic buyers. In NIPS’2015  pages 2530–2538 

2015.

[63] J. H. Morgenstern and T. Roughgarden. On the pseudo-dimension of nearly optimal auctions. In NIPS’2015 

2015.

[64] R. B. Myerson. Optimal auction design. Mathematics of operations research  6(1):58–73  1981.

[65] N. Nisan  T. Roughgarden  E. Tardos  and V. V. Vazirani. Algorithmic game theory. v.1 CUPC  2007.

[66] G. Noti  N. Nisan  and I. Yaniv. An experimental evaluation of bidders’ behavior in ad auctions. In

WWW’2014  pages 619–630  2014.

[67] M. Ostrovsky and M. Schwarz. Reserve prices in internet advertising auctions: A ﬁeld experiment. In

EC’2011  pages 59–60  2011.

[68] R. Paes Leme  M. Pál  and S. Vassilvitskii. A ﬁeld guide to personalized reserve prices. In WWW’2016 

2016.

[69] S. Pandey and C. Olston. Handling advertisements of unknown quality in search advertising. In Advances

in neural information processing systems  pages 1065–1072  2007.

[70] A. Pavan  I. Segal  and J. Toikka. Dynamic mechanism design: A myersonian approach. Econometrica 

82(2):601–653  2014.

[71] A. Pavan  I. R. Segal  and J. Toikka. Dynamic mechanism design: Incentive compatibility  proﬁt maxi-

mization and information disclosure. 2009.

[72] A. Radovanovic and W. D. Heavlin. Risk-aware revenue maximization in display advertising.

WWW’2012  pages 91–100  2012.

In

[73] T. Roughgarden and J. R. Wang. Minimizing regret with multiple reserves. In EC’2016  pages 601–616 

2016.

12

[74] M. R. Rudolph  J. G. Ellis  and D. M. Blei. Objective variables for probabilistic revenue maximization in

second-price auctions with reserve. In WWW’2016  pages 1113–1122  2016.

[75] K. M. Schmidt. Commitment through incomplete information in a simple repeated bargaining game.

Journal of Economic Theory  60(1):114–139  1993.

[76] Y. Sun  Y. Zhou  and X. Deng. Optimal reserve prices in weighted gsp auctions. Electronic Commerce

Research and Applications  13(3):178–187  2014.

[77] D. R. Thompson and K. Leyton-Brown. Revenue optimization in the generalized second-price auction. In

EC’2013  pages 837–852  2013.

[78] D. Vainsencher  O. Dekel  and S. Mannor. Bundle selling by online estimation of valuation functions. In

ICML’2011  pages 1137–1144  2011.

[79] H. R. Varian. Position auctions. international Journal of industrial Organization  25(6):1163–1178  2007.

[80] H. R. Varian. Online ad auctions. The American Economic Review  99(2):430–434  2009.

[81] H. R. Varian and C. Harris. The vcg auction in theory and practice. The A.E.R.  104(5):442–445  2014.

[82] W. Vickrey. Counterspeculation  auctions  and competitive sealed tenders. The Journal of ﬁnance 

16(1):8–37  1961.

[83] J. Weed  V. Perchet  and P. Rigollet. Online learning in repeated auctions. JMLR  49:1–31  2016.

[84] S. Yuan  J. Wang  B. Chen  P. Mason  and S. Seljan. An empirical study of reserve price optimisation in

real-time bidding. In KDD’2014  pages 1897–1906  2014.

[85] Y. Zhu  G. Wang  J. Yang  D. Wang  J. Yan  J. Hu  and Z. Chen. Optimizing search engine revenue in

sponsored search. In SIGIR’2009  pages 588–595  2009.

[86] M. Zoghi  Z. S. Karnin  S. Whiteson  and M. De Rijke. Copeland dueling bandits. In NIPS’2015  2015.

13

,Raif Rustamov
Leonidas Guibas
Shuhang Gu
Lei Zhang
Xiangchu Feng
Peter Flach
Meelis Kull
Arsenii Vanunts
Alexey Drutsa