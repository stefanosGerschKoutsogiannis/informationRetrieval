2009,Estimating image bases for visual image reconstruction from human brain activity,Image representation based on image bases provides a framework for understanding neural representation of visual perception. A recent fMRI study has shown that arbitrary contrast-defined visual images can be reconstructed from fMRI activity patterns using a combination of multi-scale local image bases. In the reconstruction model  the mapping from an fMRI activity pattern to the contrasts of the image bases was learned from measured fMRI responses to visual images. But the shapes of the images bases were fixed  and thus may not be optimal for reconstruction. Here  we propose a method to build a reconstruction model in which image bases are automatically extracted from the measured data. We constructed a probabilistic model that relates the fMRI activity space to the visual image space via a set of latent variables. The mapping from the latent variables to the visual image space can be regarded as a set of image bases. We found that spatially localized  multi-scale image bases were estimated near the fovea  and that the model using the estimated image bases was able to accurately reconstruct novel visual images. The proposed method provides a means to discover a novel functional mapping between stimuli and brain activity patterns.,Estimating image bases for visual image
reconstruction from human brain activity

Yusuke Fujiwara1 Yoichi Miyawaki2;1 Yukiyasu Kamitani1

1ATR Computational Neuroscience Laboratories

2National Institute of Information and Communications Technology

2-2-2 Hikaridai  Seika-cho  Kyoto  Japan

yureisoul@gmail.com yoichi m@atr.jp kmtn@atr.jp

Abstract

Image representation based on image bases provides a framework for understand-
ing neural representation of visual perception. A recent fMRI study has shown
that arbitrary contrast-deﬁned visual images can be reconstructed from fMRI ac-
tivity patterns using a combination of multi-scale local image bases. In the recon-
struction model  the mapping from an fMRI activity pattern to the contrasts of the
image bases was learned from measured fMRI responses to visual images. But the
shapes of the images bases were ﬁxed  and thus may not be optimal for reconstruc-
tion. Here  we propose a method to build a reconstruction model in which image
bases are automatically extracted from the measured data. We constructed a prob-
abilistic model that relates the fMRI activity space to the visual image space via a
set of latent variables. The mapping from the latent variables to the visual image
space can be regarded as a set of image bases. We found that spatially localized 
multi-scale image bases were estimated near the fovea  and that the model using
the estimated image bases was able to accurately reconstruct novel visual images.
The proposed method provides a means to discover a novel functional mapping
between stimuli and brain activity patterns.

1 Introduction

The image basis is a key concept for understanding neural representation of visual images. Using
image bases  we can consider natural scenes as a combination of simple elements corresponding
to neural units. Previous works have shown that image bases similar to receptive ﬁelds of simple
cells are learned from natural scenes by the sparse coding algorithm [4  9]. A recent fMRI study
has shown that visual images can be reconstructed using a linear combination of multi-scale image
bases (1x1  1x2  2x1  and 2x2 pixels covering an entire image)  whose contrasts were predicted
from the fMRI activity pattern [6]. The multi-scale bases produced more accurate reconstruction
than the pixel-by-pixel prediction  and each scale contributed to reconstruction in a way consistent
with known visual cortical representation. However  the predeﬁned shapes of image bases may not
be optimal for image reconstruction.
Here  we developed a method to automatically extract image bases from measured fMRI responses
to visual stimuli  and used them for image reconstruction. We employed the framework of canonical
correlation analysis (CCA)  in which two multi-dimensional observations are related via a common
coordinate system. CCA ﬁnds multiple correspondences between a weighted sum of voxels and
a weighted sum of pixels. These correspondences provide an efﬁcient mapping between the two
observations. The pixel weights for each correspondence can be thought to deﬁne an image basis.
As the early visual cortex is known to be organized in a retinotopic manner  one can assume that
a small set of pixels corresponds to a small set of voxels. To facilitate the mapping between small

1

Figure 1: Model for estimating image bases. (a) Illustration of the model framework. The visual
image I (pixels) and an fMRI activity pattern r (voxels) is linked by latent variables z. The links
from each latent variable to image pixels deﬁne an image basis WI  and the links from each latent
variable to fMRI voxels is called a weight vector Wr. (b) Graphical representation of the model.
Circles indicate model parameters to be estimated and squares indicate observations. The matrices
WI and Wr  the common latent variable z  and the inverse variances (cid:11)I and (cid:11)r are simultaneously
estimated using the variational Bayesian method. Using the estimated parameters  the predictive
distribution for a visual image given a new brain activity pattern is constructed (dashed line).

sets of pixels and voxels  we extended CCA to Bayesian CCA [10] with sparseness priors. Bayesian
CCA treats the multiple correspondences as latent variables with two transformation matrices to two
sets of observations. The transformation matrix to the visual image can be regarded as a set of image
bases. The matrices are assumed to be random variables with hyper-parameters. We introduced a
sparseness prior into each element of the matrices  such that only small subsets of voxels and pixels
are related with non-zero matrix elements.
The Bayesian CCA model was applied to the data set of Miyawaki et al. [6]. We show that spa-
tially localized image bases were extracted  especially around the foveal region  whose shapes were
similar to those used in the previous work. We also demonstrate that the model using the estimated
image bases produced accurate visual image reconstruction.

2 Method

We constructed a model in which a visual image is related with an fMRI activity pattern via latent
variables (Figure 1). Each latent variable has links to a set of pixels  which can be regarded as
an image basis because links from a single latent variable construct an element of a visual image.
The latent variable also has multiple links to a set of fMRI voxels  which we call a weight vector.
This model is equivalent to CCA: each latent variable corresponds to a canonical coefﬁcient [3] that
bundles a subset of fMRI voxels responding to a speciﬁc visual stimulus. We then extended the CCA
model to the Bayesian CCA model that can conduct a sparse selection of these links automatically.

2.1 Canonical Correlation Analysis

We ﬁrst consider the standard CCA for estimating image bases given visual images I and fMRI
activity patterns r. Let I be an N (cid:2) 1 vector and r be a K (cid:2) 1 vector where N is the number
of image pixels  K is the number of fMRI voxels and t is a sample index. Both data sets are
(cid:1) I(t)
independent identically distributed (i.i.d.) samples. CCA ﬁnds linear combinations u1(t) = a0
(cid:1) r(t) such that the correlation between u1 and v1 is maximized. The variables u1
and v1(t) = b0
and v1 are called the ﬁrst canonical variables and the vectors a1 and b1 are called the canonical
(cid:1) r(t) are sought
coefﬁcients. Then  the second canonical variables u2(t) = a0
by maximizing the correlation of u2 and v2 while the second canonical variables are orthogonalized
to the ﬁrst canonical variables. This procedure is continued up to a pre-deﬁned number of times M.
The number M is conventionally set to the smaller dimension of the two sets of observations: in
our case  M = N because the number of visual-image pixels is much smaller than that of the fMRI

(cid:1) I(t) and v2(t) = b0

1

1

2

2

2

(a)(b)voxels (N < K). The M sets of canonical variables are summarized as

(1)
(2)
where u(t) and v(t) are M (cid:2) 1 vectors  A is an M (cid:2) N matrix  and B is a M (cid:2) K matrix. The
matrices A and B are obtained by solving the eigen problem of the covariance matrix between I
and r [1]. The visual image can be reconstructed by

u(t) = A (cid:1) I(t);
v(t) = B (cid:1) r(t);

I(t) = A

(cid:0)1 (cid:1) B (cid:1) r(t);

(3)

where each column vector of the inverse matrix A(cid:0)1 is an image basis.

2.2 Bayesian CCA

Bayesian CCA introduces common latent variables that relate a visual image I and the fMRI ac-
tivity pattern r with image basis set WI and weight vector set Wr (Figure 1 (b)). These variables
are treated as random variables and prior distributions are assumed for each variable. Hyper-prior
distributions are also assumed for an inverse variance of each element of the image bases and the
weight vectors. The image bases and the weight vectors are estimated as a posterior distribution by
the variational Bayesian method [2]. After the parameters are determined  a predictive distribution
for the visual image can be calculated.
We assume two likelihood functions. One is for visual images that are generated from latent vari-
ables. The other is for fMRI activity patterns that are generated from the same latent variables.
When observation noises for visual images and fMRI voxels are assumed to follow a Gaussian dis-
tribution with zero mean and spherical covariance  the likelihood functions of the visual image I and
the fMRI activity pattern r are

jjI(t) (cid:0) WI (cid:1) z(t)jj2

(4)

P (IjWI; z) / exp

[
[
P (rjWr; z) / exp

(cid:0)1

2 (cid:12)I

(cid:0)1

T∑
T∑

t=1

jjr(t) (cid:0) Wr (cid:1) z(t)jj2

2 (cid:12)r

(5)
where WI is an N (cid:2) M matrix representing M image bases  each of which consists of N pixels 
Wr is a K(cid:2)M matrix representing M weight vectors  each of which consist of K voxels  z(t) is an
M (cid:2) 1 vector representing latent variables  (cid:12)
are scalar variables representing unknown
noise variances of the visual image and fMRI activity pattern  and T is the number of observations.
The latent variables are treated as the following Gaussian prior distribution 

and (cid:12)

(cid:0)1
I

(cid:0)1
r

t=1

;

]
]

;

where (cid:11)I(n;m) and (cid:11)r(k;m) are the inverse variances of the elements in WI and Wr  respectively 
which are assumed to be mutually independent.
We also assume hyper-prior distributions for the inverse variances (cid:11)I(n;m) and (cid:11)r(k;m) 

The image bases and weight vectors are regarded as random variables  and the prior distributions of
them are assumed as 

:

(6)

]

[
P0(z) / exp
[
P0(WIj(cid:11)I) / exp
[
P0(Wrj(cid:11)r) / exp

(cid:0)1
2

(cid:0)1
2

T∑

t=1

(cid:0)1
2

N∑
K∑

n=1

M∑
M∑

m=1

k=1

m=1

jjz(t)jj2
(
(

(cid:11)I(n;m)

(cid:11)r(k;m)

]
]

)2
)2

;

;

WI(n;m)

Wr(k;m)

P0((cid:11)I) =

P0((cid:11)r) =

G((cid:11)I(n;m)j (cid:22)(cid:11)I(n;m); (cid:13)I(n;m));
G((cid:11)I(k;m)j (cid:22)(cid:11)r(k;m); (cid:13)r(k;m));

∏
∏

n

∏
∏

m

k

m

3

(7)

(8)

(9)

(10)

where G((cid:11)j(cid:22)(cid:11); (cid:13)) represents the Gamma distribution with mean (cid:22)(cid:11) and conﬁdence parameter (cid:13). For
our analysis  all the means (cid:22)(cid:11)I(n;m) and (cid:22)(cid:11)r(k;m) were set to 1 and all the conﬁdence parameters
(cid:13)I(n;m) and (cid:13)r(k;m) were set to 0.
This conﬁguration of the prior and hyper-prior settings is known as the automatic relevance deter-
mination (ARD)  where non-effective parameters are automatically driven to zero [7]. In the current
case  these priors and hyper-priors lead to a sparse selection of links from each latent variable to
pixels and voxels.
Prior distributions of observation noise are assumed as non-informative priors  which are described
by the observation noise 

P0((cid:12)I) =

P0((cid:12)r) =

1
(cid:12)I
1
(cid:12)r

;

:

(11)

(12)

2.3 Parameter estimation by the variational Bayesian method
The image bases and weight vectors are estimated as a posterior distribution P (WI; WrjI; r)  given
the likelihood functions (Eqs. (4) and (5))  the prior distributions (Eqs. (6) - (8)  (11) and (12))  and
the hyper-prior distributions (Eqs. (9) and (10)). This posterior distribution is obtained by marginal-
izing the joint posterior distribution P (WI; Wr; z; (cid:11)I; (cid:11)r; (cid:12)I; (cid:12)rjI; r) with respect to latent vari-
ables and variance parameters 
P (WI; WrjI; r) =

dzd(cid:11)Id(cid:11)rd(cid:12)Id(cid:12)rP (WI; Wr; z; (cid:11)I; (cid:11)r; (cid:12)I; (cid:12)rjI; r):

∫

(13)

Since the joint posterior distribution cannot be calculated analytically  we approximate it using a
trial distribution based on the variational Bayesian (VB) method [2].
In the VB method  a trial
distribution Q(WI; Wr; z; (cid:11)I; (cid:11)r; (cid:12)I; (cid:12)r) with the following factorization is assumed 

Q(WI; Wr; z; (cid:11)I; (cid:11)r; (cid:12)I; (cid:12)r) = Qw(WI)Qw(Wr)Qz(z)Q(cid:11)((cid:11)I; (cid:11)r; (cid:12)I; (cid:12)r):

(14)
The joint posterior distribution P (WI; Wr; z; (cid:11)I; (cid:11)r; (cid:12)I; (cid:12)rjI; r) is approximated by the factorized
distribution (Eq. (14)). According to the standard calculation of the VB method  the trial distribution
N∏
M∏
of the image bases Qw(WI) is derived as

Qw(WI) =

where

n=1

m=1

(cid:0)1
I(n;m));

N (WI(n;m)jWI(n;m); (cid:27)
T∑

In(t)zm(t);

)

t=1

m(t) + T (cid:6)
z2

(cid:0)1
z(m;m)

+ (cid:11)I(n;m);

WI(n;m) = (cid:22)(cid:12)I(cid:27)

(cid:27)I(n;m) = (cid:22)(cid:12)I

(cid:0)1
I(n;m)

( T∑

t=1

(15)

(16)

(17)

(cid:0)1) represents a Gaussian distribution with mean (cid:22)x and variance (cid:27)

and N (xj(cid:22)x; (cid:27)
(cid:0)1. The trial distri-
bution of the weight vectors Qw(Wr) is obtained in a similar way  by replacing I with r  n with k 
and N with K in Eqs. (15-17). The trial distribution of the latent variables Qz(z) is obtained by

where

Qz(z) =
(

(

(cid:0)1
z );

N (z(t)jz(t); (cid:6)
)
)

(

(cid:0)1
z(t) = (cid:6)
z
(cid:6)z = (cid:22)(cid:12)I
W

(cid:22)(cid:12)IW
0
IWI + (cid:6)

0
II(t) + (cid:22)(cid:12)rW
+ (cid:22)(cid:12)r

(cid:0)1
wI

;

0
rr(t)
0
rWr + (cid:6)
W

(cid:0)1
wr

)

+ E:

(18)

(19)
(20)

T∏

t=1

4

In Eq. (20)  E is an identity matrix  and (cid:6)wI and (cid:6)wr are deﬁned as

(cid:6)wI = diag

(cid:27)I(n;M )

;

(21)

([ N∑
([ K∑

n=1

N∑
K∑

n=1

(cid:27)I(n;1);(cid:1)(cid:1)(cid:1) ;

(cid:27)r(k;1);(cid:1)(cid:1)(cid:1) ;

])
])

)

(cid:6)wr = diag

(22)
Finally  the distribution of the inverse variances Q(cid:11)((cid:11)I; (cid:11)r; (cid:12)I; (cid:12)r) is further factorized into
Q(cid:11)((cid:11)I)Q(cid:11)((cid:11)r)Q(cid:11)((cid:12)I)Q(cid:11)((cid:12)r)  each having a function form equivalent to a gamma distribution.
The expectation of (cid:11)I(n;m) is given by

(cid:27)r(k;M )

k=1

k=1

:

(

1
2

)(

1
2

and that of (cid:12)I is given by

(cid:22)(cid:11)I(n;m) =

+ (cid:13)I0(n;m)

(WI(n;m))2 +

{
T∑

t=1

[
jjI(t) (cid:0) WI(cid:22)z(t)jj2 + Tr

( T∑

t=1

(cid:22)(cid:12)I = N T

1
2 (cid:27)

(cid:0)1
I(n;m) + (cid:13)I0(n;m)(cid:11)

(cid:0)1
I0(n;m)

(cid:0)1
wI

(cid:6)

z(t)z

0(t) + T (cid:6)

(cid:0)1
z

+ T (cid:6)

(cid:0)1
z W

0
IWI

)(cid:0)1

;

(23)

]}(cid:0)1

:

(24)
The expectations of Q(cid:11)((cid:11)r) and Q(cid:11)((cid:12)r) are obtained in a similar way  by replacing I with r  n
with k  and N with K in Eq. (23) and Eq. (24)  respectively. The expectations of these distributions
are used in the calculation of Qw(WI)  Qw(Wr) and Qz(z) (Eqs. (15) - (20)). The algorithm
estimates the joint posterior by successive calculations of 1) Qw(WI) and Qw(Wr)  2) Qz(z)  and
3) Q(cid:11)((cid:11)I; (cid:11)r; (cid:12)I; (cid:12)r). After the algorithm converges  image bases WI are calculated by taking the
expectation of Q(WI).

2.4 Predictive distribution for visual image reconstruction

Using the estimated parameters  we can derive the predictive distribution for a visual image Inew
given a new brain activity rnew (Figure 1 (b)  dashed line). Note that Inew and rnew were taken
from the data set reserved for testing the model  independent of the data set to estimate the model
parameters. The predictive distribution P (Inewjrnew) is constructed from the likelihood of the visual
image (Eq. (4))  the estimated distribution of image bases Q(WI) (Eqs. (15) - (17))  and a posterior
distribution of latent variables P (znewjrnew) as follows 

P (Inewjrnew) =

dWIdznewP (InewjWI; znew)Q(WI)P (znewjrnew):

(25)

∫

Because the multiple integral over the random variable WI and znew is intractable  we replace the
random variable WI with the estimated image bases WI to vanish the integral over WI. Then the
predictive distribution becomes

∫

P (Inewjrnew) ’

dznewP (Inewjznew)P (znewjrnew);
]
[
P (Inewjznew) / exp

(cid:22)(cid:12)IjjInew (cid:0) WIznewjj2

:

(cid:0)1
2

(27)
Since P (znewjrnew) is an unknown distribution  we approximate P (znewjrnew) based on the trial

distribution Q(z) (Eqs. (18) - (20)). We construct an approximate distribution eQz(znew)  by omit-

ting the terms related to the visual image in Eqs. (18) - (20) 

eQz(znew) = N (zj(cid:22)znew; (cid:6)

where

where

(

(cid:22)znew = (cid:22)(cid:12)r(cid:6)
(cid:6)znew = (cid:22)(cid:12)r

(cid:0)1
znewW
W

0
rrnew;
0
rWr + (cid:6)

5

(cid:0)1
znew);

)

(cid:0)1
wr

+ E:

(26)

(28)

(29)
(30)

Finally  the predictive distribution is obtained by

P (Inewjrnew) ’

dznewP (Inewjznew)eQz(znew)

∫
= N (Inewj(cid:22)Inew; (cid:6)

(cid:0)1
Inew);

where

0
(cid:0)1
(cid:22)Inew = (cid:22)(cid:12)rWI(cid:6)
rrnew;
znewW
0
(cid:0)1
(cid:0)1
I + (cid:22)(cid:12)
(cid:6)Inew = WI(cid:6)
I E:
znewW

(31)

(32)
(33)

The reconstructed visual image is calculated by taking the expectation of the predictive distribution.

2.5

fMRI data

We used the data set from Miyawaki et al. [6]  in which fMRI signals were measured while subjects
viewed visual images consisting of contrast-deﬁned 10 (cid:2) 10 patches. The data set contained two
independent sessions. One is a “random image session”  in which spatially random patterns were
sequentially presented for 6 s followed by a 6 s rest period. A total of 440 different random patterns
were presented for each subject. The other is a “ﬁgure image session”  in which alphabetical letters
and simple geometric shapes were sequentially presented for 12 s followed by a 12 s rest period.
Five alphabetical letters and ﬁve geometric shapes were presented six or eight times per subject. We
used fMRI data from V1 for the analyses. See Miyawaki et al. [6] for details.

3 Results

We estimated image bases and weight vectors using the data from the “random image session”.
Then  reconstruction performance was evaluated with the data from the “ﬁgure image session”.

3.1 Estimated image bases

Figure 2 (a) shows representative image bases estimated by Bayesian CCA (weight values are in-
dicated by a gray scale). The estimation algorithm extracted spatially localized image bases whose
shapes were consistent with those used in the previous study [6] (1 (cid:2) 1  1 (cid:2) 2  and 2 (cid:2) 1 shown
in 1st and 2nd row of Figure 2 (a)). We also found image bases with other shapes (e.g.  L-shape 
3 (cid:2) 1 and 1 (cid:2) 3  3rd row of Figure 2 (a)) that were not assumed in the previous study. We repeated
the estimation using data resampled from the random image session  and calculated the distribution
of the image bases (deﬁned by a pixel cluster with magnitudes over 3 SD of all pixel values) over
eccentricity for different sizes (Figure 2 (a)  right). The image bases of the smallest size (1 (cid:2) 1)
were distributed over the visual ﬁeld  and most of them were within three degrees of eccentricity.
The size of the image basis tended to increase with eccentricity. For comparison  we also performed
the image basis estimation using CCA  but it did not produce spatially localized image bases (Fig-
ure 2 (b)). Estimated weight vectors for fMRI voxels had high values around the retinotopic region
corresponding the location of the estimated basis (data not shown).

3.2 Visual image reconstruction using estimated image bases

The reconstruction model with the estimated image bases was tested on ﬁve alphabet letters and ﬁve
geometric shapes (Figure 3 (a)  1st row). The images reconstructed by Bayesian CCA captured the
essential features of the presented images (Figure 3 (a)  2nd row). In particular  they showed ﬁne
reconstruction for ﬁgures consisting of thin lines such as small frames and alphabet letters. However 
the peripheral reconstruction was poor and often lacked shapes of the presented images. This may
be due to the lack of estimated image bases in the peripheral regions (Figure 2 (a)  right). The
standard CCA produced poorer reconstruction with noise scattered over the entire image (Figure
3 (a)  3rd row)  as expected from the non-local image bases estimated by CCA (Figure 2 (b)).
Reconstruction using ﬁxed image bases [6] showed moderate accuracy for all image types (Figure
3 (a)  4th row). To evaluate the reconstruction performance quantitatively  we calculated the spatial
correlation between the presented and reconstructed images (Figure 3 (b)). The correlation values

6

Figure 2: Image basis estimation: (a) Representative bases estimated by Bayesian CCA (left 
sorted by the number of pixels)  and their frequency as a function of eccentricity (right). 3-pixel
bases (L-shape  3x1 and 1x3) were not assumed in Miyawaki et al. [6]. Negative (dark) bases were
often associated with negative voxel weights  thus equivalent to positive bases with positive voxel
weights. (b) Examples of image bases estimated by the standard CCA.

were not signiﬁcantly different between Bayesian CCA and the ﬁxed basis method when the alphabet
letters and the geometric shapes were analyzed together. However  Bayesian CCA outperformed the
ﬁxed basis method for the alphabet letters  while the ﬁxed basis method outperformed Bayesian
CCA for the geometric shapes (p < :05). This is presumably because the alphabet letters consist
of more foveal pixels  which overlap the region covered by the image bases estimated by Bayesian
CCA. The reconstruction performance of CCA was lowest in all cases.

4 Discussion

We have proposed a new method to estimate image bases from fMRI data and presented visual
stimuli. Our model consists of the latent variables and two matrices relating the two sets of obser-
vations. The previous work used ﬁxed image bases and estimated the weights between the image
bases and fMRI voxels. This estimation was conducted by the sparse logistic regression that as-
sumed sparsenes in the weight values  which effectively removed irrelevant voxels [8]. The proposed
method introduced sparseness priors not only for fMRI voxels but also for image pixels. These pri-
ors lead to automatic extraction of images bases  and the mappings between a small number of fMRI
voxels and a small number of image pixels. Using this model  we successfully extracted spatially
localized image bases including those not used in the previous work [6]. Using the set of image
bases  we were able to accurately reconstruct arbitrary contrast-deﬁned visual images from fMRI
activity patterns. The sparseness priors played an important role to estimate spatially localized im-
age bases  and to improve reconstruction performance  as demonstrated by the comparison with the
results from standard CCA (Figure 2 and 3).
Our method has several limitations. First  as the latent variables were assumed to have an orthogo-
nal Gaussian distribution  it may be difﬁcult to obtain non-orthogonal image bases  which have been

7

(a) Estimated image bases by Bayesian CCA040123456FrequencyEccentricity [deg]3x11x2L-shape00.5-0.5(b) Estimated image bases by CCA1x22x11x33-pixel basis1-pixel basis2-pixel basis040040Figure 3: Visual image reconstruction: (a) Presented images (1st row  alphabet letters and geo-
metric shapes) and the reconstructed images obtained from Bayesian CCA  the standard CCA  and
the ﬁxed basis model (2nd - 4th rows). (b) Spatial correlation between presented and reconstructed
images.

shown to provide an effective image representation in the framework of sparse coding [4 9]. Differ-
ent types of image bases could be generated by introducing non-orthogonality and/or non-lineality
in the model. The shape of estimated image bases may also depend on the visual stimuli used for
the training of the reconstruction model. Although we used random images as visual stimuli  other
types of images including natural scenes may lead to more effective image bases that allow for ac-
curate reconstruction. Finally  our method failed to estimate peripheral image bases  and as a result 
only poor reconstruction was achieved for peripheral pixels. The cortical magniﬁcation factor of the
visual cortex [5] suggests that a small number of voxels represent a large number of image pixels in
the periphery. Elaborate assumptions about the degree of sparseness depending on eccentricity may
help to improve basis estimation and image reconstruction in the periphery.

Acknowledgments

This study was supported by the Nissan Science Foundation  SCOPE (SOUMU) and SRPBS
(MEXT).

8

Spatial CorrelationFixed bases (Miyawaki et al.)Bayesian CCA00.40.8PresentedReconstructedAllGeometricshapesAlphabetLettersGeometric shapesAlphabet letters(a)(b)CCA Bayesian CCAFixed bases (Miyawaki et al.)CCAReferences
[1] Anderson  T.W. (2003). An Introduction to Multivariate Statistical Analysis. 3rd ed. Wiley

Interscience.

[2] Attias  H. (1999). Inferring parameters and structure of latent variable models by variational

Bayes. Proc. 15th Conference on Uncertainty in Artiﬁcial Intelligence  21-30.

[3] Bach  F.R. and Jordan  M.I. (2005). A probabilistic interpretation of canonical correlation anal-

ysis. Dept. Statist.  Univ. California  Berkeley  CA  Tech. Repo. 688.

[4] Bell  A.J. and Sejnowski  T.J. (1997) The independent components of natural scenes are edge

ﬁlter. Vision Res. 27(23)  3327-3338.

[5] Engel  S.A.  Glover  G.H. and Wandell  B.A. (1997) Retinotopic organization in human visual

cortex and the spatial precision of functional MRI. Cereb. Cortex 7  181-192.

[6] Miyawaki  Y.  Uchida  H.  Yamashita  O.  Sato  MA.  Morito  Y.  Tanabe  HC.  Sadato  N. and
Kamitani  Y. (2008). Visual image reconstruction from human brain activity using a combina-
tion of multiscale local image decoders. Neuron 60(5)  915-929.

[7] Neal  R.M. (1996). Bayesian learning for Neural Networks. Springer-Verlag.
[8] Yamashita  O.  Sato  MA.  Yoshioka  T.  Tong  F.  Kamitani  Y. (2008) Sparse estimation au-
tomatically selects voxels relevant for the decoding of fMRI activity patterns. Neuroimage.
42(4)  1414-29.

[9] Olshausen  B.A. and Field  D.J. (1996). Emergence of simple-cell receptive ﬁeld properties by

learning a sparse code for natural images. Nature 381  607-609.

[10] Wang  C. (2007). Variatonal Bayesian Approach to Canonical Correlation Analysis. IEEE

Trans Neural Netw. 18(3)  905-910.

9

,Sewoong Oh
Jiaming Xu
Sejun Park
Jinwoo Shin