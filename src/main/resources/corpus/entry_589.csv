2017,Approximation and Convergence Properties of Generative Adversarial Learning,Generative adversarial networks (GAN) approximate a target data distribution by jointly optimizing an objective function through a "two-player game" between a generator and a discriminator.  Despite their empirical success  however  two very basic questions on how well they can approximate the target distribution remain unanswered. First  it is not known how restricting the discriminator family affects the approximation quality. Second  while a number of different objective functions have been proposed  we do not understand when convergence to the global minima of the objective function leads to convergence to the target distribution under various notions of distributional convergence.   In this paper  we address these questions in a broad and unified setting by defining a notion of adversarial divergences that includes a number of recently proposed objective functions. We show that if the objective function is an adversarial divergence with some additional conditions  then using a restricted discriminator family has a moment-matching effect. Additionally  we show that for objective functions that are strict adversarial divergences  convergence in the objective function implies weak convergence  thus generalizing previous results.,Approximation and Convergence Properties of

Generative Adversarial Learning

Shuang Liu

University of California  San Diego

Olivier Bousquet

Google Brain

shuangliu@ucsd.edu

obousquet@google.com

Kamalika Chaudhuri

University of California  San Diego

kamalika@cs.ucsd.edu

Abstract

Generative adversarial networks (GAN) approximate a target data distribution by
jointly optimizing an objective function through a "two-player game" between a
generator and a discriminator. Despite their empirical success  however  two very
basic questions on how well they can approximate the target distribution remain
unanswered. First  it is not known how restricting the discriminator family affects
the approximation quality. Second  while a number of different objective functions
have been proposed  we do not understand when convergence to the global minima
of the objective function leads to convergence to the target distribution under
various notions of distributional convergence.
In this paper  we address these questions in a broad and uniÔ¨Åed setting by deÔ¨Åning
a notion of adversarial divergences that includes a number of recently proposed
objective functions. We show that if the objective function is an adversarial
divergence with some additional conditions  then using a restricted discriminator
family has a moment-matching effect. Additionally  we show that for objective
functions that are strict adversarial divergences  convergence in the objective
function implies weak convergence  thus generalizing previous results.

1

Introduction

Generative adversarial networks (GANs) have attracted an enormous amount of recent attention in
machine learning. In a generative adversarial network  the goal is to produce an approximation to
a target data distribution  from which only samples are available. This is done iteratively via two
components ‚Äì a generator and a discriminator  which are usually implemented by neural networks.
The generator takes in random (usually Gaussian or uniform) noise as input and attempts to transform
it to match the target distribution ; the discriminator aims to accurately discriminate between
samples from the target distribution and those produced by the generator. Estimation proceeds by
iteratively reÔ¨Åning the generator and the discriminator to optimize an objective function until the
target distribution is indistinguishable from the distribution induced by the generator. The practical
success of GANs has led to a large volume of recent literature on variants which have many desirable
properties; examples are the f-GAN [10]  the MMD-GAN [5  9]  the Wasserstein-GAN [2]  among
many others.
In spite of their enormous practical success  unlike more traditional methods such as maximum
likelihood inference  GANs are theoretically rather poorly-understood. In particular  two very basic
questions on how well they can approximate the target distribution   even in the presence of a very
large number of samples and perfect optimization  remain largely unanswered. The Ô¨Årst relates to the

31st Conference on Neural Information Processing Systems (NIPS 2017)  Long Beach  CA  USA.

role of the discriminator in the quality of the approximation. In practice  the discriminator is usually
restricted to belong to some family  and it is not understood in what sense this restriction affects the
distribution output by the generator. The second question relates to convergence; different variants of
GANs have been proposed that involve different objective functions (to be optimized by the generator
and the discriminator). However  it is not understood under what conditions minimizing the objective
function leads to a good approximation of the target distribution. More precisely  does a sequence
of distributions output by the generator that converges to the global minimum under the objective
function always converge to the target distribution  under some standard notion of distributional
convergence?
In this work  we consider these two questions in a broad setting. We Ô¨Årst characterize a very general
class of objective functions that we call adversarial divergences  and we show that they capture
the objective functions used by a variety of existing procedures that include the original GAN [7] 
f-GAN [10]  MMD-GAN [5  9]  WGAN [2]  improved WGAN [8]  as well as a class of entropic
regularized optimal transport problems [6]. We then deÔ¨Åne the class of strict adversarial divergences
‚Äì a subclass of adversarial divergences where the minimizer of the objective function is uniquely the
target distribution. This characterization allows us to address the two questions above in a uniÔ¨Åed
setting  and translate the results to an entire class of GANs with little effort.
First  we address the role of the discriminator in the approximation in Section 4. We show that if the
objective function is an adversarial divergence that obeys certain conditions  then using a restricted
class of discriminators has the effect of matching generalized moments. A concrete consequence of
this result is that in linear f-GANs  where the discriminator family is the set of all afÔ¨Åne functions over
a vector of features maps  and the objective function is an f-GAN  the optimal distribution  output
by the GAN will satisfy Ex[ (x)] = Ex[ (x)] regardless of the speciÔ¨Åc f-divergence chosen
in the objective function. Furthermore  we show that a neural network GAN is just a supremum of
linear GANs  therefore has the same moment-matching effect.
We next address convergence in Section 5. We show that convergence in an adversarial divergence
implies some standard notion of topological convergence. Particularly  we show that provided an
objective function is a strict adversarial divergence  convergence to  in the objective function implies
weak convergence of the output distribution to . While convergence properties of some isolated
objective functions were known before [2]  this result extends them to a broad class of GANs. An
additional consequence of this result is the observation that as the Wasserstein distance metrizes
weak convergence of probability distributions (see e.g. [14])  Wasserstein-GANs have the weakest1
objective functions in the class of strict adversarial divergences.

2 Notations

We use bold constants (e.g.  0  1  x0) to denote constant functions. We denote by f  g the function
composition of f and g. We denote by Y X the set of functions maps from the set X to the set Y . We
denote by  
  the product measure of  and . We denote by int(X) the interior of the set X. We
denote by E[f ] the integral of f with respect to measure  .
Let f : R ! R [ f+1g be a convex function  we denote by dom f the effective domain of f 
that is  dom f = fx 2 R; f (x) < +1g; and we denote by f the convex conjugate of f  that is 
f(x) = supx2R fx  x  f (x)g.
For a topological space 
  we denote by C(
) the set of continuous functions on 
  Cb(
) the set of
bounded continuous functions on 
  rca(
) the set of Ô¨Ånite signed regular Borel measures on 
  and
P(
) the set of probability measures on 
.
Given a non-empty subspace Y of a topological space X  denote by X=Y the quotient space equipped
with the quotient topology Y   where for any a; b 2 X  a Y b if and only if a = b or a; b both
belong to Y . The equivalence class of each element a 2 X is denoted as [a] = fb : a Y bg.

1Weakness is actually a desirable property since it prevents the divergence from being too discriminative
(saturate)  thus providing more information about how to modify the model to approximate the true distribution.

2

3 General Framework

Let  be the target data distribution from which we can draw samples. Our goal is to Ô¨Ånd a generative
model  to approximate . Informally  most GAN-style algorithms model this approximation as
solving the following problem

inf


sup
f2F

Ex; y [f (x; y)] ;

where F is a class of functions. The process is usually considered adversarial in the sense that it
can be thought of as a two-player minimax game  where a generator  is trying to mimick the true
distribution   and a adversary f is trying to distinguish between the true and generated distributions.
However  another way to look at it is as the minimization of the following objective function

 7! sup
f2F

Ex; y [f (x; y)]

(1)

This objective function measures how far the target distribution  is from the current estimate .
Hence  minimizing this function can lead to a good approximation of the target distribution .
This leads us to the concept of adversarial divergence.
DeÔ¨Ånition 1 (Adversarial divergence). Let X be a topological space  F  Cb(X 2)  F 6= ;. An
adversarial divergence  over X is a function

P(X)  P(X) ! R [ f+1g

(; ) 7!  (jj) = sup
f2F

E
 [f ] :

(2)

Observe that in DeÔ¨Ånition 1 if we have a Ô¨Åxed target distribution   then (2) is reduced to the objective
function (1). Also  notice that because  is the supremum of a family of linear functions (in each of
the variables  and  separately)  it is convex in each of its variables.
DeÔ¨Ånition 1 captures the objective functions used by a variety of existing GAN-style procedures. In
practice  although the function class F can be complicated  it is usually a transformation of a simple
function class V  which is the set of discriminators or critics  as they have been called in the GAN
literature. We give some examples by specifying F and V for each objective function.

(a) GAN [7].

F = fx; y 7! log(u(x)) + log(1  u(y)) : u 2 Vg
V = (0; 1)X \ Cb(X):

(b) f-GAN [10]. Let f : R ! R [ f1g be a convex lower semi-continuous function. Assume
f(x)  x for any x 2 R  f is continuously differentiable on int(dom f)  and there
exists x0 2 int(dom f) such that f(x0) = x0.

F = fx; y 7! v(x)  f(v(y)) : v 2 Vg ;
V = (dom f)X \ Cb(X):

(c) MMD-GAN [5  9]. Let k : X 2 ! R be a universal reproducing kernel. Let M be the set of

signed measures on X.

F = fx; y 7! v(x)  v(y) : v 2 Vg ;
V =x 7! E [k(x;)] :  2 M; E2 [k]  1	 :

(d) Wasserstein-GAN (WGAN) [2]. Assume X is a metric space.
F = fx; y 7! v(x)  v(y) : v 2 Vg ;
V =nv 2 Cb(X) : kvkLip  Ko ;

where K is a positive constant  kkLip denotes the Lipschitz constant.

(e) WGAN-GP (Improved WGAN) [8]. Assume X is a convex subset of a Euclidean space.

F = fx; y 7! v(x)  v(y)  EtU [(krv(tx + (1  t)y)k2  1)p] : v 2 Vg;
V = C 1(X);

where U is the uniform distribution on [0; 1]   is a positive constant  p 2 (1;1).

3

(f) (Regularized) Optimal Transport [6].

2 Let c : X 2 ! R be some transportation cost
(3)

function    0 be the strength of regularization. If  = 0 (no regularization)  then
F = fx; y 7! u(x) + v(y) : (u; v) 2 Vg ;
V = f(u; v) 2 Cb(X)  Cb(X); u(x) + v(y)  c(x; y) for any x; y 2 Xg ;
 : u; v 2 V ;
F =x; y 7! u(x) + v(y)   exp u(x) + v(y)  c(x; y)
V = Cb(X):

if  > 0  then



(4)

In order to study an adversarial divergence   it is critical to Ô¨Årst understand at which points the diver-
gence is minimized. More precisely  let  be an adversarial divergence and  be the target probability
measure. We are interested in the set of probability measures that minimize the divergence  when
the Ô¨Årst argument of  is set to   i.e.  the set arg min  (jj) = f :  (jj) = inf   (jj)g.
Formally  we deÔ¨Åne the set OPT; as follows.
DeÔ¨Ånition 2 (OPT;). Let  be an adversarial divergence over a topological space X   2 P(X).
DeÔ¨Åne OPT; to be the set of probability measures that minimize the function  (jj). That is 

OPT; 4= 2 P(X) :  (jj) = inf

02P(X)

 (jj0) :

Ideally  the target probability measure  should be one and the only one that minimizes the objective
function. The notion of strict adversarial divergence captures this property.
DeÔ¨Ånition 3 (Strict adversarial divergence). Let  be an adversarial divergence over a topological
space X   is called a strict adversarial divergence if for any  2 P(X)  OPT; = fg.
For example  if the underlying space X is a compact metric space  then examples (c) and (d) induce
metrics on P(X) (see  e.g.  [12])  therefore are strict adversarial divergences.
In the next two sections  we will answer two questions regarding the set OPT;: how well do the
elements in OPT; approximate the target distribution  when restricting the class of discrimina-
tors? (Section 4); and does a sequence of distributions that converges in an adversarial divergence
also converges to OPT; under some standard notion of distributional convergence? (Section 5)

4 Generalized Moment Matching

To motivate the discussion in this section  recall example (b) in Section 3). It can be shown that
under some mild conditions    the objective function of f-GAN  is actually the f-divergence  and
the minimizer of  (jj) is only  [10]. However  in practice  the discriminator class V is usually
implemented by a feedforward neural network  and it is known that a Ô¨Åxed neural network has limited
capacity (e.g.  it cannot implement the set of all the bounded continuous function). Therefore  one
could ask what will happen if we restrict V to a sub-class V0? Obviously one would expect  not be
the unique minimizer of  (jj) anymore  that is  OPT; contains elements other than . What
can we say about the elements in OPT; now? Are all of them close to  in a certain sense? In this
section we will answer these questions.
More formally  we consider F = fm  r :  2 g to be a function class indexed by a set .
We can think of  as the parameter set of a feedforward neural network. Each m is thought to
be a matching between two distributions  in the sense that  and  are matched under m if and
only if E
[m] = 0. In particular  if each m is corresponding to some function v such that
m(x; y) = v(x)  v(y)  then  and  are matched under m if and only if some generalized
moment of  and  are equal: E[v] = E[v]. Each r can be thought as a residual.
We will now relate the matching condition to the optimality of the divergence. In particular  deÔ¨Åne

M 4= f : 8 2 ; E [v] = E[v]g ;
We will give sufÔ¨Åcients conditions for members of M to be in OPT;.

2To the best of our knowledge  neither (3) or (4) was used in any GAN algorithm. However  since our focus
in this paper is not implementing new algorithms  we leave experiments with this formulation for future work.

4

Theorem 4. Let X be a topological space    Rn  V = fv 2 Cb(X) :  2 g  R =
r 2 Cb(X 2) :  2 	. Let m(x; y) = v(x)  v(y).
If there exists c 2 R such that for
any ;  2 P(X)  inf 2 E
[r] = c and there exists some 
 ] = c and
 2  such that E
[r
E
 [m  r] is an adversarial divergence over X and
 ]  0  then  (jj) = sup2
E
[m
for any  2 P(X)  OPT;  M :
We now review the examples (a)-(e) in Section 3  show how to write each f 2 F into m  r  and
specify 

 in each case such that the conditions of Theorem 4 can be satisÔ¨Åed.

(a) GAN. Note that for any x 2 (0; 1)  log (1=(x(1  x)))  log(4). Let u

2 
 = 1

f(x; y) = log(u(x)) + log(1  u(y))
= log(u(x))  log(u(y))
}
|
 i=0

m(x;y)note E
hm

{z



 log (1= (u(y)(1  u(y))))
}

r(x;y)note r(x;y)r

{z

|

(x;y)=log(4)




:

=

(5)

:

:





{z

0

{z

(b) f-GAN. Recall that f(x)  x  0 for any x 2 R and f(x0) = x0. Let v

 = x0 

{z

 i=0



(x;y)=0

f(x; y) =

r(x;y)note r(x;y)r

 i=0
 = 0 


(f(v(y))  v(y))
}
|

|{z}
r(x;y)note r(x;y)=r
(e) WGAN-GP. Note that the function x 7! xp is nonnegative on R. Let
i=1 xi]  E[Pn

f(x; y) = v(x)  f(v(y))
v(x)  v(y)
}
|
m(x;y)note E
hm
(c  d) MMD-GAN or Wasserstein-GAN. Let v
v(x)  v(y)
|
}
m(x;y)note E
hm
 =((x1; x2; ; xn) 7! Pn
i=1 xipn
;
(x1; x2; ; xn) 7! Pn
i=1 xipn
 EtU [(krv(tx + (1  t)y)k2  1)p]
v(x)  v(y)
}
|
}
|
m(x;y)note E
hm
We now reÔ¨Åne the previous result and show that under some additional conditions on m and r  the
optimal elements of  are fully characterized by the matching condition  i.e. OPT; = M.
Theorem 5. Under the assumptions of Theorem 4  if 
 7! E
[r] have gradients at 

 2 int() and both  7! E
[m] and
(6)

if E[Pn

otherwise;

r(x;y)note r(x;y)r

f(x; y) =

i=1 xi] 

(x;y)=0

(x;y)=0

   and



 i0

E
[m

 ] = 0 and 90; E
 [m0 ] 6= 0 =) r



Then for any  2 P(X)  OPT; = M :
We remark that Theorem 4 is relatively intuitive  while Theorem 5 requires extra conditions  and is
quite counter-intuitive especially for algorithms like f-GANs.

E
 [m] 6= 0:

{z

{z










v

;

:

4.1 Example: Linear f-GAN

We Ô¨Årst consider a simple algorithm called linear f-GAN. Suppose we are provided with a feature
map that maps each point x in the sample space X to a feature vector ( 1(x); 2(x); ; n(x))
where each i 2 Cb(X). We are satisÔ¨Åed that any distribution  is a good approximation of the
target distribution  as long as E [ ] = E[ ]. For example  if X  R and k(x) = xk  to
say E [ ] = E[ ] is equivalent to say the Ô¨Årst n moments of  and  are matched. Recall that
in the standard f-GAN (example (b) in Section 3)  V = (dom f)X \ Cb(X). Now instead of
using the discriminator class V  we use a restricted discriminator class V0  V  containing the linear
(or more precisely  afÔ¨Åne) transformations of ‚Äì the set V0 = T( ; 1) :  2 	  V; where
 =  2 Rn+1 : 8x 2 X; T( (x); 1) 2 dom f	. We will show that now OPT; contains

exactly those  such that E [ ] = E[ ]  regardless of the speciÔ¨Åc f chosen. Formally 

5

linear f-GAN

Corollary 6 (linear f-GAN). Let X be a compact topological space. Let f be a function as deÔ¨Åned
i=1 be a vector of continuously differentiable functions on
in example (b) of Section 3. Let = ( i)n

X. Let  = 2 Rn+1 : 8x 2 X; T( (x); 1) 2 dom f	. Let  be the objective function of the
Then for any  2 P(X)  OPT; = f :  (jj) = 0g = f : E [ ] = E[ ]g 3 :
A very concrete example of Corollary 6 could be  for example  the linear KL-GAN  where f (u) =
u log u  f(t) = exp(t  1)  = ( i)n

2E[T( ; 1)]  E[f  (T( ; 1))] :

i=1   = Rn+1. The objective function is

 (jj) = sup

 (jj) = sup

2Rn+1E[T( ; 1)]  E[exp(T( ; 1)  1)] ;

4.2 Example: Neural Network f-GAN

Next we consider a more general and practical example: an f-GAN where the discriminator class
V0 = fv :  2 g is implemented through a feedforward neural network with weight parameter set
. We assume that all the activation functions are continuously differentiable (e.g.  sigmoid  tanh) 
and the last layer of the network is a linear transformation plus a bias. We also assume dom f = R
(e.g.  the KL-GAN where f(t) = exp(t  1)).
Now observe that when all the weights before the last layer are Ô¨Åxed  the last layer acts as a
discriminator in a linear f-GAN. More precisely  let pre be the index set for the weights before
the last layer. Then each pre 2 pre corresponds to a feature map pre. Let the linear f-GAN that
corresponds to pre be pre  the adversarial divergence induced by the Neural Network f-GAN is

 (jj) = sup
pre2pre

pre (jj)

Clearly OPT; Tpre2pre
OPTpre ;. For the other direction  note that by Corollary 6  for any
pre 2 pre  pre (jj)  0 and pre (jj) = 0. Therefore  (jj)  0 and  (jj) = 0. If
 2 OPT;  then  (jj) = 0. As a consequence  pre (jj) = 0 for any pre 2 pre. Therefore
OPT; Tpre2pre

OPTpre ;. Therefore  by Corollary 6 

OPTpre ; = f : 8 2 ; E [v] = E[v]g :

OPT; = \pre2pre

That is  the minimizer of the Neural Network f-GAN are exactly those distributions that are indistin-
guishable under the expectation of any discriminator network v.

5 Convergence

To motivate the discussion in this section  consider the following question. Let x0 be the delta
distribution at x0 2 R  that is  x = x0 with probability 1. Now  does the sequence of delta
distributions 1=n converges to 1? Almost all the people would answer no. However  does the
sequence of delta distributions 1=n converges to 0? Most people would answer yes based on the
intuition that 1=n ! 0 and so does the sequence of corresponding delta distributions  even though
the support of 1=n never has any intersection with the support of 0. Therefore  convergence can be
deÔ¨Åned for distributions not only in a point-wise way  but in a way that takes consideration of the
underlying structure of the sample space.
Now returning to our adversarial divergence framework. Given an adversarial divergence   is it
possible that  (1jj1=n) convreges to the global minimum of  (1jj)? How to we deÔ¨Åne convergence
to a set of points instead of only one point  in order to explain the convergence behaviour of any
adversarial divergence? In this section we will answer these questions.
We start from two standard notions from functional analysis.
DeÔ¨Ånition 7 (Weak-* topology on P(X) (see e.g. [11])). Let X be a compact metric space. By
associating with each  2 rca(X) a linear function f 7! E[f ] on C(X)  we have that rca(X)

6

is the continuous dual of C(X) with respect to the uniform norm on C(X) (see e.g. [4]). Therefore
we can equip rca(X) (and therefore P(X)) with a weak-* topology  which is the coarsest topology
on rca(X) such that f 7! E[f ] : f 2 C(X)g is a set of continuous linear functions on rca(X).
DeÔ¨Ånition 8 (Weak convergence of probability measures (see e.g. [11])). Let X be a compact metric
space. A sequence of probability measures (n) in P(X) is said to weakly converge to a measure
 2 P(X)  if 8f 2 C(X)  En [f ] ! E [f ]; or equivalently  if (n) is weak-* convergent to .
The deÔ¨Ånition of weak-* topology and weak convergence respect the topological structure of the
sample space. For example  it is easy to check that the sequence of delta distributions 1=n weakly
converges to 0  but not to 1.
Now note that DeÔ¨Ånition 8 only deÔ¨Ånes weak convergence of a sequence of probability measures to a
single target measure. Here we generalize the deÔ¨Ånition for the single target measure to a set of target
measures through quotient topology as follows.
DeÔ¨Ånition 9 (Weak convergence of probability measures to a set). Let X be a compact metric space 
equip P(X) with the weak-* topology and let A be a non-empty subspace of P(X). A sequence of
probability measures (n) in P(X) is said to weakly converge to the set A if ([n]) converges to A
in the quotient space P(X)=A.
With everything properly deÔ¨Åned  we are now ready to state our convergence result. Note that
an adversarial divergence is not necessarily a metric  and therefore does not necessarily induce a
topology. However  convergence in an adversarial divergence can still imply some type of topological
convergence. More precisely  we show a convergence result that holds for any adversarial divergence
 as long as the sample space is a compact metric space. Informally  we show that for any target
probability measure  if  (jjn) converges to the global minimum of  (jj)  then n weakly
converges to the set of measures that achieve the global minimum. Formally 
Theorem 10. Let X be a compact metric space   be an adversarial divergence over X   2 P(X) 
then OPT; 6= ;. Let (n) be a sequence of probability measures in P(X). If  (jjn) !
inf 0  (jj0)  then (n) weakly converges to the set OPT;.
As a special case of Theorem 10  if  is a strict adversarial divergence  i.e.  OPT; = fg  then
converging to the minimizer of the objective function implies the usual weak convergence to the
target probability measure. For example  it can be checked that the objective function of f-GAN is a
strict adversarial divergence  therefore converging in the objective function of an f-GAN implies the
usual weak convergence to the target probability measure.
To compare this result with our intuition  we return to the example of a sequence of delta distributions
and show that as long as  is a strict adversarial divergence   (1jj1=n) does not converge to the
global minimum of  (1jj). Observe that if  (1jj1=n) converges to the global minimum of  (1jj) 
then according to Theorem 10  1=n will weakly converge to 1  which leads to a contradiction.
However Theorem 10 does more than excluding undesired possibilities. It also enables us to give
general statements about the structure of the class of adversarial divergences. The structural result
can be easily stated under the notion of relative strength between adversarial divergences  which is
deÔ¨Åned as follows.
DeÔ¨Ånition 11 (Relative strength between adversarial divergences). Let 1 and 2 be two adversarial
divergences  if for any sequence of probability measures (n) and any target probability measure
  1(jjn) ! inf  1(jj) implies 2(jjn) ! inf  2(jj)  then we say 1 is stronger
than 2 and 2 is weaker than 1. We say 1 is equivalent to 2 if 1 is both stronger and weaker than
2. We say 1 is strictly stronger (strictly weaker) than 2 if 1 is stronger (weaker) than 2 but not
equivalent. We say 1 and 2 are not comparable if 1 is neither stronger nor weaker than 2.
Not much is known about the relative strength between different adversarial divergences. If the
underlying sample space is nice (e.g.  subset of Euclidean space)  then the variational (GAN-style)
formulation of f-divergences using bounded continuous functions coincides with the original deÔ¨Åni-
tion [15]  and therefore f-divergences are adversarial divergences. [2] showed that the KL-divergence
is stronger than the JS-divergence  which is equivalent to the total variation distance  which is strictly
stronger than the Wasserstein-1 distance.
However  the novel fact is that we can reach the weakest strict adversarial divergence. Indeed 
one implicatoin of Theorem 10 is that if X is a compact metric space and  is a strict adversarial

7

Figure 1: Structure of the class of strict adversarial divergences

divergence over   then -convergence implies the usual weak convergence on probability measures.
In particular  since the Wasserstein distance metrizes weak convergence of probability distributions
(see e.g. [14])  as a direct consequence of Theorem 10  the Wasserstein distance is in the equivalence
class of the weakest strict adversarial divergences. In the other direction  there exists a trivial strict
adversarial divergence

Trivial (jj) 4=0;
+1;

if  =  
otherwise;

(7)

that is stronger than any other strict adversarial divergence. We now incorporate our convergence
results with some previous results and get the following structural result.
Corollary 12. The class of strict adversarial divergences over a bounded and closed subset of a
Euclidean space has the structure as shown in Figure 1  where Trivial is deÔ¨Åned as in (7)  MMD is
corresponding to example (c) in Section 3  Wasserstein is corresponding to example (d) in Section 3  and
KL  Reverse-KL  TV  JS  Hellinger are corresponding to example (b) in Section 3 with f (x) being x log(x) 
2 ) + x log(x)  (px  1)2  respectively. Each rectangle in
 log(x)  1
Figure 1 represents an equivalence class  inside of which are some examples. In particular  Trivial is in
the equivalence class of the strongest strict adversarial divergences  while MMD and Wasserstein are in the
equivalence class of the weakest strict adversarial divergences.

2jx  1j  (x + 1) log( x+1

6 Related Work

There has been an explosion of work on GANs over the past couple of years; however  most of the
work has been empirical in nature. A body of literature has looked at designing variants of GANs
which use different objective functions. Examples include [10]  which propose using the f-divergence
between the target  and the generated distribution   and [5  9]  which propose the MMD distance.
Inspired by previous work  we identify a family of GAN-style objective functions in full generality
and show general properties of the objective functions in this family.
There has also been some work on comparing different GAN-style objective functions in terms
of their convergence properties  either in a GAN-related setting [2]  or in a general IPM setting
[12]. Unlike these results  which look at the relationship between several speciÔ¨Åc strict adversarial
divergences  our results apply to an entire class of GAN-style objective functions and establish their
convergence properties. For example  [2] shows that KL-divergnce  JS-divergence  total-variation
distance are all stronger than the Wasserstein distance  while our results generalize this part of their
result and says that any strict adversarial divergence is stronger than the Wasserstein distance and its
equivalences. Furthermore  our results also apply to non-strict adversarial divergences.
That being said  it does not mean our results are a complete generalization of the previous convergence
results such as [2  12]. Our results do not provide any methods to compare two strict adversarial
divergences if none of them is equivalent to the Wasserstein distance or the trivial divergence. In
contrast  [2] show that the KL-divergence is stronger than the JS-divergence  which is equivalent to
the total variation distance  which is strictly stronger than the Wasserstein-1 distance.
Finally  there has been some additional theoretical literature on understanding GANs  which consider
orthogonal aspects of the problem. [3] address the question of whether we can achieve generalization
bounds when training GANs. [13] focus on optimizing the estimating power of kernel distances. [5]
study generalization bounds for MMD-GAN in terms of fat-shattering dimension.

8

7 Discussion and Conclusions

In conclusion  our results provide insights on the cost or loss functions that should be used in GANs.
The choice of cost function plays a very important role in this case ‚Äì more so  for example  than data
domains or network architectures. For example  most works still use the DCGAN architecture  while
changing the cost functions to achieve different levels of performance  and which cost function is
better is still a matter of debate. In particular we provide a framework for studying many different
GAN criteria in a way that makes them more directly comparable  and under this framework  we
study both approximation and convergence properties of various loss functions.

8 Acknowledgments

We thank Iliya Tolstikhin  Sylvain Gelly  and Robert Williamson for helpful discussions. The work
of KC and SL were partially supported by NSF under IIS 1617157.

References
[1] C. D. Aliprantis and O. Burkinshaw. Principles of real analysis. Academic Press  1998.

[2] M. Arjovsky  S. Chintala  and L. Bottou. Wasserstein GAN. CoRR  abs/1701.07875  2017.

[3] S. Arora  R. Ge  Y. Liang  T. Ma  and Y. Zhang. Generalization and equilibrium in generative

adversarial nets (gans). CoRR  abs/1703.00573  2017.

[4] H. G. Dales  J. F.K. Dashiell  A.-M. Lau  and D. Strauss. Banach Spaces of Continuous
Functions as Dual Spaces. CMS Books in Mathematics. Springer International Publishing 
2016.

[5] G. K. Dziugaite  D. M. Roy  and Z. Ghahramani. Training generative neural networks via

maximum mean discrepancy optimization. In UAI 2015.

[6] A. Genevay  M. Cuturi  G. Peyr√©  and F. R. Bach. Stochastic optimization for large-scale

optimal transport. In NIPS 2016.

[7] I. Goodfellow  J. Pouget-Abadie  M. Mirza  B. Xu  D. Warde-Farley  S. Ozair  A. Courville  and

Y. Bengio. Generative adversarial nets. In NIPS 2014.

[8] I. Gulrajani  F. Ahmed  M. Arjovsky  V. Dumoulin  and A. C. Courville. Improved training of

wasserstein gans. CoRR  abs/1704.00028  2017.

[9] Y. Li  K. Swersky  and R. Zemel. Generative moment matching networks. In ICML 2015.

[10] S. Nowozin  B. Cseke  and R. Tomioka. f-GAN: Training generative neural samplers using

variational divergence minimization. In NIPS 2016.

[11] W. Rudin. Functional Analysis. International Series in Pure and Applied Mathematics. McGraw-

Hill  Inc  1991.

[12] B. K. Sriperumbudur  A. Gretton  K. Fukumizu  B. Sch√∂lkopf  and G. R. G. Lanckriet. Hilbert
space embeddings and metrics on probability measures. Journal of Machine Learning Research 
11:1517‚Äì1561  2010.

[13] D. J. Sutherland  H. F. Tung  H. Strathmann  S. De  A. Ramdas  A. J. Smola  and A. Gretton.
Generative models and model criticism via optimized maximum mean discrepancy. In ICLR
2017.

[14] C. Villani. Optimal transport  old and new. Grundlehren der mathematischen Wissenschaften.

Springer-Verlag Berlin Heidelberg  2009.

[15] Y. Wu. Lecture notes: Information-theoretic methods for high-dimensional statistics. 2017.

9

,Shuang Liu
Olivier Bousquet
Kamalika Chaudhuri