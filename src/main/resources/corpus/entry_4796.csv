2016,Rényi Divergence Variational Inference,This paper introduces the variational Rényi bound (VR) that extends traditional variational inference to Rényi's alpha-divergences. This new family of variational methods unifies a number of existing approaches  and enables a smooth interpolation from the evidence lower-bound to the log (marginal) likelihood that is controlled by the value of alpha that parametrises the divergence. The reparameterization trick  Monte Carlo approximation and stochastic optimisation methods are deployed to obtain a tractable and unified framework for optimisation. We further consider negative alpha values and propose a novel variational inference method as a new special case in the proposed framework. Experiments on Bayesian neural networks and variational auto-encoders demonstrate the wide applicability of the VR bound.,Rényi Divergence Variational Inference

Yingzhen Li

University of Cambridge
Cambridge  CB2 1PZ  UK

yl494@cam.ac.uk

Richard E. Turner

University of Cambridge
Cambridge  CB2 1PZ  UK

ret26@cam.ac.uk

Abstract

This paper introduces the variational Rényi bound (VR) that extends traditional vari-
ational inference to Rényi’s α-divergences. This new family of variational methods
uniﬁes a number of existing approaches  and enables a smooth interpolation from
the evidence lower-bound to the log (marginal) likelihood that is controlled by the
value of α that parametrises the divergence. The reparameterization trick  Monte
Carlo approximation and stochastic optimisation methods are deployed to obtain a
tractable and uniﬁed framework for optimisation. We further consider negative α
values and propose a novel variational inference method as a new special case in
the proposed framework. Experiments on Bayesian neural networks and variational
auto-encoders demonstrate the wide applicability of the VR bound.

1

Introduction

Approximate inference  that is approximating posterior distributions and likelihood functions  is at the
core of modern probabilistic machine learning. This paper focuses on optimisation-based approximate
inference algorithms  popular examples of which include variational inference (VI)  variational Bayes
(VB) [1  2] and expectation propagation (EP) [3  4]. Historically  VI has received more attention
compared to other approaches  although EP can be interpreted as iteratively minimising a set of local
divergences [5]. This is mainly because VI has elegant and useful theoretical properties such as the
fact that it proposes a lower-bound of the log-model evidence. Such a lower-bound can serve as
a surrogate to both maximum likelihood estimation (MLE) of the hyper-parameters and posterior
approximation by Kullback-Leibler (KL) divergence minimisation.
Recent advances of approximate inference follow three major trends. First  scalable methods 
e.g. stochastic variational inference (SVI) [6] and stochastic expectation propagation (SEP) [7  8] 
have been developed for datasets comprising millions of datapoints. Recent approaches [9  10  11]
have also applied variational methods to coordinate parallel updates arising from computations
performed on chunks of data. Second  Monte Carlo methods and black-box inference techniques have
been deployed to assist variational methods  e.g. see [12  13  14  15] for VI and [16] for EP. They all
proposed ascending the Monte Carlo approximated variational bounds to the log-likelihood using
noisy gradients computed with automatic differentiation tools. Third  tighter variational lower-bounds
have been proposed for (approximate) MLE. The importance weighted auto-encoder (IWAE) [17]
improved upon the variational auto-encoder (VAE) [18  19] framework  by providing tighter lower-
bound approximations to the log-likelihood using importance sampling. These recent developments
are rather separated and little work has been done to understand their connections.
In this paper we try to provide a uniﬁed framework from an energy function perspective that
encompasses a number of recent advances in variational methods  and we hope our effort could
potentially motivate new algorithms in the future. This is done by extending traditional VI to Rényi’s
α-divergence [20]  a rich family that includes many well-known divergences as special cases. After
reviewing useful properties of Rényi divergences and the VI framework  we make the following
contributions:

30th Conference on Neural Information Processing Systems (NIPS 2016)  Barcelona  Spain.

Table 1: Special cases in the Rényi divergence family.

α

α → 1

α = 0.5
α → 0

α = 2
α → +∞

Deﬁnition

(cid:82) p(θ) log p(θ)
− log(cid:82)

−2 log(1 − Hel2[p||q])

q(θ) dθ

p(θ)>0 q(θ)dθ
− log(1 − χ2[p||q])
log maxθ∈Θ

p(θ)
q(θ)

Notes
Kullback-Leibler (KL) divergence 
used in VI (KL[q||p]) and EP (KL[p||q])
function of the square Hellinger distance
zero when supp(q) ⊆ supp(p)
(not a divergence)
proportional to the χ2-divergence
worst-case regret in
minimum description length principle [24]

• We introduce the variational Rényi bound (VR) as an extension of VI/VB. We then discuss
connections to existing approaches  including VI/VB  VAE  IWAE [17]  SEP [7] and black-box
alpha (BB-α) [16]  thereby showing the richness of this new family of variational methods.
• We develop an optimisation framework for the VR bound. An analysis of the bias introduced
by stochastic approximation is also provided with theoretical guarantees and empirical results.
• We propose a novel approximate inference algorithm called VR-max as a new special case.
Evaluations on VAEs and Bayesian neural networks show that this new method is often
comparable to  or even better than  a number of the state-of-the-art variational methods.

2 Background

This section reviews Rényi’s α-divergence and variational inference upon which the new framework
is based. Note that there exist other α-divergence deﬁnitions [21  22] (see appendix). However we
mainly focus on Rényi’s deﬁnition as it enables us to derive a new class of variational lower-bounds.

1

log

(cid:90)

α − 1

Dα[p||q] =

p(θ)αq(θ)1−αdθ.

2.1 Rényi’s α-divergence
We ﬁrst review Rényi’s α-divergence [20  23]. Rényi’s α-divergence  deﬁned on {α : α > 0  α (cid:54)=
1 |Dα| < +∞}  measures the “closeness” of two distributions p and q on a random variable θ ∈ Θ:
(1)
The deﬁnition is extended to α = 0  1  +∞ by continuity. We note that when α → 1 the Kullback-
Leibler (KL) divergence is recovered  which plays a crucial role in machine learning and information
theory. Some other special cases are presented in Table 1. The method proposed in this work also
considers α ≤ 0 (although (1) is no longer a divergence for these α values)  and we include from
[23] some useful properties for forthcoming derivations.
Proposition 1. (Monotonicity) Rényi’s α-divergence deﬁnition (1)  extended to negative α  is contin-
uous and non-decreasing on α ∈ {α : −∞ < Dα < +∞}.
Proposition 2. (Skew symmetry) For α (cid:54)∈ {0  1}  Dα[p||q] = α
1−α D1−α[q||p]. This implies
Dα[p||q] ≤ 0 for α < 0. For the limiting case D−∞[p||q] = −D+∞[q||p].
A critical question that is still in active research is how to choose a divergence in this rich family to
obtain optimal solution for a particular application  an issue which is discussed in the appendix.

2.2 Variational inference

Next we review the variational inference algorithm [1  2] using posterior approximation as a running
example. Consider observing a dataset of N i.i.d. samples D = {xn}N
n=1 from a probabilistic model
p(x|θ) parametrised by a random variable θ that is drawn from a prior p0(θ). Bayesian inference
involves computing the posterior distribution of the parameters given the data 
n=1 p(xn|θ  ϕ)
p(D|ϕ)

p0(θ|ϕ)(cid:81)N

p(θ D|ϕ)
p(D|ϕ)

p(θ|D  ϕ) =

(2)

=

 

2

(a) Approximated posterior.

(b) Hyper-parameter optimisation.

Figure 1: Mean-Field approximation for Bayesian linear regression.
In this case ϕ = σ the
observation noise variance. The bound is tight as σ → +∞  biasing the VI solution to large σ values.

where p(D|ϕ) =(cid:82) p0(θ|ϕ)(cid:81)N

n=1 p(xn|θ  ϕ)dθ is called marginal likelihood or model evidence.
The hyper-parameters of the model are denoted as ϕ which might be omitted henceforth for notational
ease. For many powerful models the exact posterior is typically intractable  and approximate inference
introduces an approximation q(θ) in some tractable distribution family Q to the exact posterior. One
way to obtain this approximation is to minimise the KL divergence KL[q(θ)||p(θ|D)]  which is
also intractable due the difﬁcult term p(D). Variational inference (VI) sidesteps this difﬁculty by
considering an equivalent optimisation problem that maximises the variational lower-bound:

LVI(q;D  ϕ) = log p(D|ϕ) − KL[q(θ)||p(θ|D  ϕ)] = Eq

log

.

(3)

(cid:20)

(cid:21)

p(θ D|ϕ)

q(θ)

The variational lower-bound can also be used to optimise the hyper-parameters ϕ.
To illustrate the approximation quality of VI we present a mean-ﬁeld approximation example to
Bayesian linear regression in Figure 1(a) (in magenta). Readers are referred to the appendix for
details  but essentially a factorised Gaussian approximation is ﬁtted to the true posterior  a correlated
Gaussian in this case. The approximation recovers the posterior mean correctly  but is over-conﬁdent.
Moreover  as LVI is the difference between the marginal likelihood and the KL divergence  hyper-
parameter optimisation can be biased away from the exact MLE towards the region of parameter
space where the KL term is small [25] (see Figure 1(b)).

3 Variational Rényi bound

Recall from Section 2.1 that the family of Rényi divergences includes the KL divergence. Perhaps
variational free-energy approaches can be generalised to the Rényi case? Consider approximating
the exact posterior p(θ|D) by minimizing Rényi’s α-divergence Dα[q(θ)||p(θ|D)] for some selected
α > 0. Now we consider the equivalent optimization problem maxq∈Q log p(D)−Dα[q(θ)||p(θ|D)] 
and when α (cid:54)= 1  whose objective can be rewritten as

(cid:34)(cid:18) p(θ D)

(cid:19)1−α(cid:35)

Lα(q;D) :=

1

1 − α

log Eq

q(θ)

.

(4)

We name this new objective the variational Rényi (VR) bound. Importantly the above deﬁnition can
be extend to α ≤ 0  and the following theorem is a direct result of Proposition 1.
Theorem 1. The objective Lα(q;D) is continuous and non-increasing on α ∈ {α : |Lα| < +∞}.
Especially for all 0 < α+ < 1 and α− < 0 

LVI(q;D) = lim
α→1

Lα(q;D) ≤ Lα+(q;D) ≤ L0(q;D) ≤ Lα− (q;D)
Also L0(q;D) = log p(D) if and only if the support supp(p(θ|D)) ⊆ supp(q(θ)).
Theorem 1 indicates that the VR bound can be useful for model selection by sandwiching the marginal
likelihood with bounds computed using positive and negative α values  which we leave to future
work. In particular L0 = log p(D) under the mild assumption that q is supported where the exact

3

(VI)posterior is supported. This assumption holds for many commonly used distributions  e.g. Gaussians
are supported on the entire space  and in the following we assume that this condition is satisﬁed.
Choosing different alpha values allows the approximation to balance between zero-forcing (α →
+∞  when using uni-modal approximations it is usually called mode-seeking) and mass-covering
(α → −∞) behaviour. This is illustrated by the Bayesian linear regression example  again in Figure
1(a). First notice that α → +∞ (in cyan) returns non-zero uncertainty estimates (although it is more
over-conﬁdent than VI) which is different from the maximum a posteriori (MAP) method that only
i p(θi|D) and the exact
marginal likelihood log p(D) (Figure 1(b)). Also the approximate MLE is less biased for α = 0.5 (in
blue) since now the tightness of the bound is less hyper-parameter dependent.

returns a point estimate. Second  setting α = 0.0 (in green) returns q(θ) =(cid:81)

4 The VR bound optimisation framework

This section addresses several issues of the VR bound optimisation by proposing further approxi-
mations. First when α (cid:54)= 1  the VR bound is usually just as intractable as the marginal likelihood
for many useful models. However Monte Carlo (MC) approximation is applied here to extend the
set of models that can be handled. The resulting method can be applied to any model that MC-VI
[12  13  14  15] is applied to. Second  Theorem 1 suggests that the VR bound is to be minimised
when α < 0  which performs disastrously in MLE context. As we shall see  this issue is solved also
by the MC approximation under certain conditions. Third  a mini-batch training method is developed
for large-scale datasets in the posterior approximation context. Hence the proposed optimisation
framework of the VR bound enables tractable application to the same class of models as SVI.

4.1 Monte Carlo approximation of the VR bound

Consider learning a latent variable model with MLE as a running example  where the model is
speciﬁed by a conditional distribution p(x|h  ϕ) and a prior p(h|ϕ) on the latent variables h.
Examples include models treated by the variational auto-encoder (VAE) approach [18  19] that
parametrises the likelihood with a (deep) neural network. MLE requires log p(x) which is obtained
by marginalising out h and is often intractable  so the VR bound is considered as an alternative
optimisation objective. However instead of using exact bounds  a simple Monte Carlo (MC) method
is deployed  which uses ﬁnite samples hk ∼ q(h|x)  k = 1  ...  K to approximate Lα ≈ ˆLα K:

(cid:34)(cid:18) p(hk  x)

q(hk|x)

K(cid:88)

k=1

(cid:19)1−α(cid:35)

ˆLα K(q; x) =

1

1 − α

log

1
K

.

(5)

k=1

k=1

k=1

[ ˆLα K(q; x)]

[ ˆLα K(q; x)] → Lα as K → +∞;

The importance weighted auto-encoder (IWAE) [17] is a special case of this framework with α = 0
and K < +∞. But unlike traditional VI  here the MC approximation is biased. Fortunately we can
characterise the bias by the following theorems proved in the appendix.
[| ˆLα K(q; x)|] < +∞ and |Lα| < +∞. Then E{hk}K
Theorem 2. Assume E{hk}K
as a function of α ∈ R and K ≥ 1 is:
1) non-decreasing in K for ﬁxed α ≤ 1  and non-increasing in K for ﬁxed α ≥ 1;
2) E{hk}K
3) continuous and non-increasing in α with ﬁxed K.
Corollary 1. For ﬁnite K  either E{hk}K
such that E{hk}K
Also αK is non-decreasing in K if exists  with limK→1 αK = −∞ and limK→+∞ αK = 0.
The intuition behind the theorems is visualised in Figure 2(a). By deﬁnition  the exact VR bound
is a lower-bound or upper-bound of log p(x) when α > 0 or α < 0  respectively. However the
MC approximation E[ ˆLα K] biases the estimate towards LVI  where the approximation quality can
be improved using more samples. Thus for ﬁnite samples and under mild conditions  negative
alpha values can potentially be used to improve the accuracy of the approximation  at the cost of
losing the upper-bound guarantee. Figure 2(b) shows an empirical evaluation by computing the
exact and the MC approximation of the Rényi divergences. In this example p  q are 2-D Gaussian
distributions with µp = [0  0]  µq = [1  1] and Σp = Σq = I. The sampling procedure is repeated

[ ˆLα K(q; x)] < log p(x) for all α  or there exists αK ≤ 0
[ ˆLα K(q; x)] > log p(x) for all α < αK.

[ ˆLαK  K(q; x)] = log p(x) and E{hk}K

k=1

k=1

k=1

4

(a) MC approximated VR bounds.

(b) Simulated MC approximations.

Figure 2: (a) An illustration for the bounding properties of MC approximations to the VR bounds. (b)
The bias of the MC approximation. Best viewed in colour and see the main text for details.

200 times to estimate the expectation. Clearly for K = 1 it is equivalent to an unbiased estimate
of the KL-divergence for all α (even though now the estimation is biased for Dα). For K > 1 and
α < 1  the MC method under-estimates the VR bound  and the bias decreases with increasing K. For
α > 1 the inequality is reversed also as predicted.

4.2 Uniﬁed implementation with the reparameterization trick
Readers may have noticed that LVI has a different form compared to Lα with α (cid:54)= 1. In this section
we show how to unify the implementation for all ﬁnite α settings using the reparameterization trick
[13  18] as an example. This trick assumes the existence of the mapping θ = gφ()  where the
distribution of the noise term  satisﬁes q(θ)dθ = p()d. Then the expectation of a function F (θ)
over distribution q(θ) can be computed as Eq(θ)[F (θ)] = Ep()[F (gφ())]. One prevalent example
is the Gaussian reparameterization: θ ∼ N (µ  Σ) ⇒ θ = µ + Σ 1
2    ∼ N (0  I). Now we apply
the reparameterization trick to the VR bound

Lα(qφ; x) =

1

1 − α

log E

(cid:34)(cid:18) p(gφ()  x)

(cid:19)1−α(cid:35)

q(gφ())

.

(cid:21)

wα(; φ  x)∇φ log

(cid:20)(cid:16) p(gφ() x)

(cid:17)1−α(cid:21)

p(gφ()  x)

q(gφ())

 

(6)

(7)

(cid:20)

E

(cid:20)

K(cid:88)

k=1

Then the gradient of the VR bound w.r.t. φ is (similar for ϕ  see appendix for derivation)

∇φLα(qφ; x) = E

(cid:17)1−α(cid:30)
(cid:16) p(gφ() x)
(cid:17)1−α
ˆwα k(k; φ  x) ∝(cid:16) p(gφ(k) x)

q(gφ())

q(gφ(k))

where wα(; φ  x) =
denotes the normalised importance
weight. One can show that this recovers the the stochastic gradients of LVI by setting α = 1 in (7)
since now w1(; φ  x) = 1  which means the resulting algorithm uniﬁes the computation for all
ﬁnite α settings. For MC approximations  we use K samples to approximately compute the weight

q(gφ())

  k = 1  ...  K  and the stochastic gradient becomes

∇φ ˆLα K(qφ; x) =

ˆwα k(k; φ  x)∇φ log

p(gφ(k)  x)

q(gφ(k))

.

(8)

When α = 1  ˆw1 k(k; φ  x) = 1/K  and it recovers the stochastic gradient VI method [18].
To speed-up learning [17] suggested back-propagating only one sample j with j ∼ pj = ˆwα j  which
can be easily extended to our framework. Importantly  the use of different α < 1 indicates the degree
of emphasis placed upon locations where the approximation q under-estimates p  and in the extreme
case α → −∞  the algorithm chooses the sample that has the maximum unnormalised importance
weight. We name this approach VR-max and summarise it and the general case in Algorithm 1. Note
that VR-max (and VR-α with α < 0 and MC approximations) does not minimise D1−α[p||q]. It is
true that Lα ≥ log p(x) for negative α values. However Corollary 1 suggests that the tightest MC
approximation for given K has non-positive αK value  or might not even exist. Furthermore αK
becomes more negative as the mismatch between q and p increases  e.g. VAE uses a uni-modal q
distribution to approximate the typically multi-modal exact posterior.

5

(cid:21)

Algorithm 1 One gradient step for VR-α/VR-max
with single backward pass. Here ˆw(k; x) short-
hands ˆw0 k(k; φ  x) in the main text.
1: given the current datapoint x  sample

1  ...  K ∼ p()

2: for k = 1  ...  K  compute the unnormalised weight
log ˆw(k; x) = log p(gφ(k)  x)−log q(gφ(k)|x)

3: choose the sample j to back-propagate:
if |α| < ∞: j ∼ pk where pk ∝ ˆw(k; x)1−α
if α = −∞: j = arg maxk log ˆw(k; x)

4: return the gradients ∇φ log ˆw(j; x)

Figure 3: Connecting local and global
divergence minimisation.

4.3 Stochastic approximation for large-scale learning

VR bounds can also be applied to full Bayesian inference with posterior approximation. However for
large datasets full batch learning is very inefﬁcient. Mini-batch training is non-trivial here since the
VR bound cannot be represented by the expectation on a datapoint-wise loss  except when α = 1.
This section introduces two proposals for mini-batch training  and interestingly  this recovers two
existing algorithms that were motivated from a different perspective. In the following we deﬁne the
N . Hence the joint distribution can be rewritten as
p(θ D) = p0(θ) ¯fD(θ)N . Also for a mini-batch of M datapoints S = {xn1  ...  xnM} ∼ D  we

“average likelihood” ¯fD(θ) = [(cid:81)N
deﬁne the “subset average likelihood” ¯fS (θ) = [(cid:81)M

n=1 p(xn|θ)] 1

m=1 p(xnm|θ)] 1
M .

The ﬁrst proposal considers ﬁxed point approximations with mini-batch sub-sampling. It ﬁrst derives
the ﬁxed point conditions for the variational parameters (e.g. the natural parameters of q) using the
exact VR bound (4)  then design an iterative algorithm using those ﬁxed point equations  but with
¯fD(θ) replaced by ¯fS (θ). The second proposal also applies this subset average likelihood approx-
imation idea  but directly to the VR bound (4) (so this approach is named energy approximation):

˜Lα(q;S) =

1

1 − α

log Eq

(cid:34)(cid:18) p0(θ) ¯fS (θ)N

(cid:19)1−α(cid:35)

q(θ)

.

(9)

In the appendix we demonstrate with detailed derivations that ﬁxed point approximation returns
Stochastic EP (SEP) [7]  and black box alpha (BB-α) [16] corresponds to energy approximation. Both
algorithms were originally proposed to approximate (power) EP [3  26]  which usually minimises
α-divergences locally  and considers M = 1  α ∈ [1 − 1/N  1) and exponential family distributions.
These approximations were done by factor tying  which signiﬁcantly reduces the memory overhead
of full EP and makes both SEP and BB-α scalable to large datasets just as SVI. The new derivation
derivation provides a theoretical justiﬁcation from energy perspective  and also sheds lights on the
connections between local and global divergence minimisations as depicted in Figure 3. Note that
all these methods recover SVI when α → 1  in which global and local divergence minimisation are
equivalent. Also these results suggest that recent attempts of distributed posterior approximation (by
carving up the dataset into pieces with M > 1 [10  11]) can be extended to both SEP and BB-α.
Monte Carlo methods can also be applied to both proposals. For SEP the moment computation can be
approximated with MCMC [10  11]. For BB-α one can show in the same way as to prove Theorem
2 that simple MC approximation in expectation lower-bounds the BB-α energy when α ≤ 1. In
general it is also an open question how to choose α for given the mini-batch size M and the number
of samples K  but there is evidence that intermediate α values can be superior [27  28].

5 Experiments

We evaluate the VR bound methods on Bayesian neural networks and variational auto-encoders. All
the experiments used the ADAM optimizer [29]  and the detailed experimental set-up (batch size 
learning rate  etc.) can be found in the appendix. The implementation of all the experiments in Python
is released at https://github.com/YingzhenLi/VRbound.

6

VREPSEPBB-globallocalmini-batchsub-samplingfactortyingenergyapprox.ﬁxed pointapprox.Figure 4: Test LL and RMSE results for Bayesian neural network regression. The lower the better.

5.1 Bayesian neural network

The ﬁrst experiment considers Bayesian neural network regression. The datasets are collected from
the UCI dataset repository.1 The model is a single-layer neural network with 50 hidden units (ReLUs)
for all datasets except Protein and Year (100 units). We use a Gaussian prior θ ∼ N (θ; 0  I) for
the network weights and Gaussian approximation to the true posterior q(θ) = N (θ; µq  diag(σq)).
We follow the toy example in Section 3 to consider α ∈ {−∞  0.0  0.5  1.0  +∞} in order to
examine the effect of mass-covering/zero-forcing behaviour. Stochastic optimisation uses the energy
approximation proposed in Section 4.3. MC approximation is also deployed to compute the energy
function  in which K = 100  10 is used for small and large datasets (Protein and Year)  respectively.
We summarise the test negative log-likelihood (LL) and RMSE with standard error (across different
random splits except for Year) for selected datasets in Figure 4  where the full results are provided in
the appendix. These results indicate that for posterior approximation problems  the optimal α may
vary for different datasets. Also the MC approximation complicates the selection of α (see appendix).
Future work should develop algorithms to automatically select the best α values  although a naive
approach could use validation sets. We observed two major trends that zero-forcing/mode-seeking
methods tend to focus on improving the predictive error  while mass-covering methods returns better
calibrated uncertainty estimate and better test log-likelihood. In particular VI returns lower test
log-likelihood for most of the datasets. Furthermore  α = 0.5 produced overall good results for both
test LL and RMSE  possibly because the skew symmetry is centred at α = 0.5 and the corresponding
divergence is the only symmetric distance measure in the family.

5.2 Variational auto-encoder

The second experiments considers variational auto-encoders for unsupervised learning. We mainly
compare three approaches: VAE (α = 1.0)  IWAE (α = 0)  and VR-max (α = −∞)  which are
implemented upon the publicly available code.2 Four datasets are considered: Frey Face (with 10-fold
cross validation)  Caltech 101 Silhouettes  MNIST and OMNIGLOT. The VAE model has L = 1  2
stochastic layers with deterministic layers stacked between  and the network architecture is detailed
in the appendix. We reproduce the IWAE experiments to obtain a fair comparison  since the results in
the original publication [17] mismatches those evaluated on the publicly available code.
We report test log-likelihood results in Table 2 by computing log p(x) ≈ ˆL0 5000(q; x) following
[17]. We also present some samples from the trained models in the appendix. Overall VR-max is
almost indistinguishable from IWAE. Other positive alpha settings (e.g. α = 0.5) return worse results 
e.g. 1374.64 ± 5.62 for Frey Face and −85.50 for MNIST with α = 0.5  L = 1 and K = 5. These
worse results for α > 0 indicate the preference of getting tighter approximations to the likelihood
function for MLE problems. Small negative α values (e.g. α = −1.0 −2.0) returns better results on
different splits of the Frey Face data  and overall the best α value is dataset-speciﬁc.

1http://archive.ics.uci.edu/ml/datasets.html
2https://github.com/yburda/iwae

7

mass-coveringzero-forcingTable 2: Average Test log-likelihood. Results for VAE on
MNIST and OMNIGLOT are collected from [17].
Dataset
Frey Face
(± std. err.)
Caltech 101
Silhouettes
MNIST

L K
1
5

1

1

VR-max
1377.40
±4.59
-118.01
-117.10
-85.42
-84.81
-84.04
-83.44
-106.33
-105.05
-104.71
-103.72

VAE
1322.96
±10.03
-119.69
-119.61
-86.47
-86.35
-85.01
-84.78
-107.62
-107.80
-106.31
-106.30

IWAE
1380.30
±4.60
-117.89
-117.21
-85.41
-84.80
-83.92
-83.05
-106.30
-104.68
-104.64
-103.25

5
50
5
50
5
50
5
50
5
50

OMNIGLOT

2

1
1
2
2

Figure 5: Bias of sampling approx-
imation to. Results for K = 5  50
samples are shown on the left and
right  respectively.

(a) Log of ratio R = wmax/(1 − wmax)

(b) Weights of samples.

Figure 6: Importance weights during training  see main text for details. Best viewed in colour.

VR-max’s success might be explained by the tightness of the bound. To evaluate this  we compute
the VR bounds on 100 test datapoints using the 1-layer VAE trained on Frey Face  with K = {5  50}
and α ∈ {0 −1 −5 −50 −500}. Figure 5 presents the estimated gap ˆLα K − ˆL0 5000. The results
indicates that ˆLα K provides a lower-bound  and that gap is narrowed as α → −∞. Also increasing
K provides improvements. The standard error of estimation is almost constant for different α (with
K ﬁxed)  and is negligible when compared to the MC approximation bias.
Another explanation for VR-max’s success is that  the sample with the largest normalised importance
weight wmax dominates the contributions of all the gradients. This is conﬁrmed by tracking R =
during training on Frey Face (Figure 6(a)). Also Figure 6(b) shows the 10 largest importance
wmax
1−wmax
weights from K = 50 samples in descending order  which exhibit an exponential decay behaviour 
with the largest weight occupying more than 75% of the probability mass. Hence VR-max provides a
fast approximation to IWAE when tested on CPUs or multiple GPUs with high communication costs.
Indeed our numpy implementation of VR-max achieves up to 3 times speed-up compared to IWAE
(9.7s vs. 29.0s per epoch  tested on Frey Face data with K = 50 and batch size M = 100  CPU info:
Intel Core i7-4930K CPU @ 3.40GHz). However this speed advantage is less signiﬁcant when the
gradients can be computed very efﬁciently on a single GPU.

6 Conclusion

We have introduced the variational Rényi bound and an associated optimisation framework. We
have shown the richness of the new family  not only by connecting to existing approaches including
VI/VB  SEP  BB-α  VAE and IWAE  but also by proposing the VR-max algorithm as a new special
case. Empirical results on Bayesian neural networks and variational auto-encoders indicate that VR
bound methods are widely applicable and can obtain state-of-the-art results. Future work will focus
on both experimental and theoretical sides. Theoretical work will study the interaction of the biases
introduced by MC approximation and datapoint sub-sampling. A guide on choosing optimal α values
are needed for practitioners when applying the framework to their applications.

Acknowledgements

We thank the Cambridge MLG members and the reviewers for comments. YL thanks the Schlum-
berger Foundation FFTF fellowship. RET thanks EPSRC grants # EP/M026957/1 and EP/L000776/1.

8

References
[1] M. I. Jordan  Z. Ghahramani  T. S. Jaakkola  and L. K. Saul  “An introduction to variational methods for

graphical models ” Machine learning  vol. 37  no. 2  pp. 183–233  1999.

[2] M. J. Beal  Variational algorithms for approximate Bayesian inference. PhD thesis  University College

[3] T. Minka  “Expectation propagation for approximate Bayesian inference ” in Conference on Uncertainty in

London  2003.

Artiﬁcial Intelligence (UAI)  2001.

[4] M. Opper and O. Winther  “Expectation consistent approximate inference ” The Journal of Machine

Learning Research  vol. 6  pp. 2177–2204  2005.

[5] T. Minka  “Divergence measures and message passing ” tech. rep.  Microsoft Research  2005.
[6] M. D. Hoffman  D. M. Blei  C. Wang  and J. W. Paisley  “Stochastic variational inference ” Journal of

Machine Learning Research  vol. 14  no. 1  pp. 1303–1347  2013.

[7] Y. Li  J. M. Hernández-Lobato  and R. E. Turner  “Stochastic expectation propagation ” in Advances in

Neural Information Processing Systems (NIPS)  2015.

[8] G. Dehaene and S. Barthelmé  “Expectation propagation in the large-data limit ” arXiv:1503.08060  2015.
[9] T. Broderick  N. Boyd  A. Wibisono  A. C. Wilson  and M. I. Jordan  “Streaming variational Bayes ” in

Advances in Neural Information Processing Systems (NIPS)  2013.

[10] A. Gelman  A. Vehtari  P. Jylänki  C. Robert  N. Chopin  and J. P. Cunningham  “Expectation propagation

as a way of life ” arXiv:1412.4869  2014.

[11] M. Xu  B. Lakshminarayanan  Y. W. Teh  J. Zhu  and B. Zhang  “Distributed Bayesian posterior sampling

via moment sharing ” in Advances in Neural Information Processing Systems (NIPS)  2014.

[12] J. Paisley  D. Blei  and M. Jordan  “Variational Bayesian inference with stochastic search ” in Proceedings

of The 29th International Conference on Machine Learning (ICML)  2012.

[13] T. Salimans and D. A. Knowles  “Fixed-form variational posterior approximation through stochastic linear

regression ” Bayesian Analysis  vol. 8  no. 4  pp. 837–882  2013.

[14] R. Ranganath  S. Gerrish  and D. M. Blei  “Black box variational inference ” in Proceedings of the 17th

International Conference on Artiﬁcial Intelligence and Statistics (AISTATS)  2014.

[15] A. Kucukelbir  R. Ranganath  A. Gelman  and D. M. Blei  “Automatic variational inference in Stan ” in

Advances in Neural Information Processing Systems (NIPS)  2015.

[16] J. M. Hernández-Lobato  Y. Li  M. Rowland  D. Hernández-Lobato  T. Bui  and R. E. Turner  “Black-box
α-divergence minimization ” in Proceedings of The 33rd International Conference on Machine Learning
(ICML)  2016.

[17] Y. Burda  R. Grosse  and R. Salakhutdinov  “Importance weighted autoencoders ” in International Confer-

ence on Learning Representations (ICLR)  2016.

[18] D. P. Kingma and M. Welling  “Auto-encoding variational Bayes ” in International Conference on Learning

Representations (ICLR)  2014.

[19] D. J. Rezende  S. Mohamed  and D. Wierstra  “Stochastic backpropagation and approximate inference
in deep generative models ” in Proceedings of The 30th International Conference on Machine Learning
(ICML)  2014.

[20] A. Rényi  “On measures of entropy and information ” Fourth Berkeley symposium on mathematical

statistics and probability  vol. 1  1961.

[21] S.-i. Amari  Differential-Geometrical Methods in Statistic. New York: Springer  1985.
[22] C. Tsallis  “Possible generalization of Boltzmann-Gibbs statistics ” Journal of statistical physics  vol. 52 

no. 1-2  pp. 479–487  1988.

[23] T. Van Erven and P. Harremoës  “Rényi divergence and Kullback-Leibler divergence ” Information Theory 

IEEE Transactions on  vol. 60  no. 7  pp. 3797–3820  2014.

[24] P. Grünwald  Minimum Description Length Principle. MIT press  Cambridge  MA  2007.
[25] R. E. Turner and M. Sahani  “Two problems with variational expectation maximisation for time-series
models ” in Bayesian Time series models (D. Barber  T. Cemgil  and S. Chiappa  eds.)  ch. 5  pp. 109–130 
Cambridge University Press  2011.

[26] T. Minka  “Power EP ” Tech. Rep. MSR-TR-2004-149  Microsoft Research  2004.
[27] T. D. Bui  D. Hernández-Lobato  Y. Li  J. M. Hernández-Lobato  and R. E. Turner  “Deep gaussian processes
for regression using approximate expectation propagation ” in Proceedings of The 33rd International
Conference on Machine Learning (ICML)  2016.

[28] S. Depeweg  J. M. Hernández-Lobato  F. Doshi-Velez  and S. Udluft  “Learning and policy search in

stochastic dynamical systems with bayesian neural networks ” arXiv preprint arXiv:1605.07127  2016.

[29] D. P. Kingma and J. Ba  “Adam: A method for stochastic optimization ” in International Conference on

Learning Representations (ICLR)  2015.

9

,Yingzhen Li
Richard Turner