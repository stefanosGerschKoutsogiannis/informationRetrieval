2018,Bayesian Model Selection Approach to Boundary Detection with Non-Local Priors,Based on non-local prior distributions  we propose a Bayesian model selection (BMS) procedure for boundary detection in a sequence of data with multiple systematic mean changes. The BMS method can effectively suppress the non-boundary spike points with large instantaneous changes. We speed up the algorithm by reducing the multiple change points to a series of single change point detection problems. We establish the consistency of the estimated number and locations of the change points under various prior distributions. Extensive simulation studies are conducted to compare the BMS with existing methods  and our approach is illustrated with application to the magnetic resonance imaging guided radiation therapy data.,Bayesian Model Selection Approach to Boundary

Detection with Non-Local Priors

Fei Jiang

Department of Statistics and Actuarial Science

The University of Hong Kong

feijiang@hku.hk

Guosheng Yin

Dominici Francesca

Department of Statistics and Actuarial Science

Harvard T.H. Chan School of Public Health

The University of Hong Kong

gyin@hku.hk

Harvard University

fdominic@hsph.harvard.edu

Abstract

Based on non-local prior distributions  we propose a Bayesian model selection
(BMS) procedure for boundary detection in a sequence of data with multiple
systematic mean changes. The BMS method can effectively suppress the non-
boundary spike points with large instantaneous changes. We speed up the algorithm
by reducing the multiple change points to a series of single change point detection
problems. We establish the consistency of the estimated number and locations of
the change points under various prior distributions. Extensive simulation studies
are conducted to compare the BMS with existing methods  and our approach is
illustrated with application to the magnetic resonance imaging guided radiation
therapy data.

1

Introduction

Traditional change point detection algorithms often apply to the situation where the occurrence
frequency of the change points is relatively consistent across the signals. For example  the narrowest-
over-threshold (NOT) algorithm [1] is more suitable when different segments between the change
points have comparable lengths  and the stepwise marginal likelihood (SML) method [5] works better
to identify frequent change points. However  in practice it is often the case that distances between
consecutive change points may vary dramatically  while only those with certain distance gaps are of
interest. For such settings  we develop a computationally efﬁcient Bayesian model selection (BMS)
approach to identifying multiple change points.
The inconsistent gaps between the change points can be observed from the signals generated by
the magnetic resonance imaging guided radiation therapy (MRgRT). When radiations travel in the
magnetic ﬁeld  the dose can be signiﬁcantly enhanced near the boundaries between different tissues or
organs inside human bodies. As shown by Figure 1  the Duke Mid-sized Optical-CT System (DMOS)
is developed to identify the dose changes near the region of such boundary artifact. It also exhibits
the proﬁle of dose intensities as the radiation travels through the dosimeter  where the boundaries on
and inside the dosimeter can be distinguished by the notable peaks in the signals. In the experiment 
radiations enter the cylindrical dosimeter from different directions  and a sequence of dose intensities
ordered by their distances to the sources are recorded. Because the dosimeter is circular and there is a

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

Figure 1: Reconstructed image of a slice in a cylindrical dosimeter with a cavity in the middle (left) and a
typical line proﬁle through the center of the cavity (right). Radiations enter the dosimeter from the hole on the
left of the cylindrical dosimeter  which rotates 360 degrees so that radiations can enter from different directions.

cavity in the middle  radiations from different directions would hit the boundaries in the dosimeter at
similar distances from their sources.
In the MRgRT data  radiations in certain directions may experience temporary changes at non-
boundary locations  which may result from the abnormal status of the DMOS system rather than the
true dose changes. The temporary change points  appearing in the data sequence as the spike points 
are often mixed up with those on the boundary (i.e.  the peak locations in the right panel of Figure
1)  which makes the boundary detection extremely challenging. Figures A.1 in Appendix shows the
change points in the MRgRT data identiﬁed by the NOT [1] and SML [5] algorithms respectively 
while neither can correctly identify the true boundaries. This motivates us to propose a new approach
to detecting the systematic changes when the segment lengths have dramatic differences.
Our preliminary analysis of the MRgRT data demonstrates that the local control of the discovery is
crucial. To avoid picking the spike points  we enforce a minimal distance between adjacent change
points. Moreover  we adopt a computationally efﬁcient local scan routine and propose a systematic
two-stage procedure to speed up the change point detection. More speciﬁcally  the local scan method
ﬁrst identiﬁes the candidate points with a minimal distance based on the local data  and then optimizes
an utility function to obtain the estimates for the locations and the total number of change points.
Because the change points are deﬁned based on the mean changes between two consecutive segments 
the local data are sufﬁcient to detect the systemic changes [6  7  8  13  14  16  18  19].
To perserve the positive detection rate of the change points and reduce the false detection rate of the
non-change points  we take a Bayesian marginal likelihood function as the utility  and develop a new
BMS procedure for identifying change points. We show that the selection consistency is achieved
under both the local [2  3  4  17] and non-local priors [11]  whereas the convergence rate is faster
under the later. Our BMS procedure is cast in the model selection framework  which is faster than
the dynamic programming in the SML framework. For example  for the MRgRT data  BMS takes
1.3 seconds and SML takes 3.1 seconds when the maximum number of change points is capped at
100. The efﬁciency of BMS is mainly due to the fact that it reduces the search space dramatically by
selecting a small set of candidate change points. Once the candidate points are selected  BMS only
needs to evaluate two consecutive segments at a time  which greatly facilitates parallel computation.

2 Bayesian multiple change points detection

2.1 Probability model

tp0 among n observations Yn

Y1  . . .   Yn .
Suppose there are p0 true change points t1
tj and  minj 0 ... p0 j. We
As a convention  let t0
n 1. Denote j
tj 1
1 and ⌧Kn 1
n 1  while selection of
consider a set of Kn candidate points ⌧1  . . .  ⌧ Kn  with ⌧0
⌧j  and nI minj 0 ... Kn 1 nj 
the candidate points is discussed in Section 2.3. Deﬁne nj
⌧j 1
nI denote the set of candidate change
. Let H nI
1  . . .   Kn  ⌧j 1
nI
⌧j
1  . . .   p0 denote the set of true change points. Not only does the
points  and let T0 p0
speciﬁcation of the candidate points allow BMS to be implemented in a lower dimensional space with
the most inﬂuential points  but it also guarantees that there are a sufﬁcient number of non-change
points surrounding the true change points so that the consistency conditions are met. The probability

1 and t p0 1

⌧j : j
tj : j

2

model takes the form of

Yl

⌫⌧j

✏l 

l

⌧j ⌧ j 1  

where the random errors ✏l are independent with mean zero and variance 2
 maxj 0 ... p0 j.
For ease of exposition  we ﬁrst consider the case where the locations of the candidate change points
are given and T0 p0
Yl  which is the sample average for the
1. If the candidate point ⌧k is not a change point  then the points
j
in ⌧k ⌧ k 1 should have the same mean as those in ⌧k 1 ⌧ k ; otherwise there should be a mean
shift between the segments ⌧k ⌧ k 1 and ⌧k 1 ⌧ k . Hence  we can formulate the model and prior
distribution for l

H nI . Deﬁne ¯Y⌧j

1 th segment ⌧j 1 ⌧ j   j

j . Further  we deﬁne

⌧1 as follows:

⌧j 1
l ⌧j 1

n 1
j 1

Yl

¯Y⌧k
µk
µk

⇠l 

⌧k ⌧ k 1  

l
if ⌧k is a change point 

µk
⇡ µk  
0  with probability 1  if ⌧k is an nI-ﬂat point 

where ⇠l is a mean-zero error term and ⇡
is a prior distribution. The nI-ﬂat point is deﬁned as
a non-change point which is at least nI apart from any change points. We require the nI distance
between the true change points and the ﬂat ones so that there are sufﬁcient neighborhood samples to
achieve the estimation consistency.
0 is the lower bound of µk0 
Let µk0 be the true value of µk  and we assume µk0
for the k’s with ⌧k
T0 p0 . The prior distribution of µk determines the convergence rate of the
BMS procedure. We explore three types of priors: the local prior [9]  the non-local moment prior and
the inverse moment prior [11] as follows:

  where 

Local prior: ⇡L µ
Moment prior: ⇡M µ
Inverse moment prior: ⇡I µ
where CM is the normalizing constant.
Let Mk represent the model that ⌧k is the sole change point. We deﬁne the marginal likelihood with
the Gaussian kernel as
Kn

N 0 ! 2  
µ2v CM 1
s⌫q 2  q 2s µ q 1 exp

2⇡ exp µ2 2  

µ2 ⌫

⌧k 1 1

⌧j 1 1

s  

¯Y⌧k

µ 2 ⇡ µ dµ.

Pr Yn Mk

exp

Yl

j 1 j k

l ⌧j

¯Y⌧j

2

exp

Yl

l ⌧k

The posterior model probability of Mk given Yn is

Pr Mk Yn

Pr Yn Mk Pr Mk
Kn
j 1 Pr Yn Mj Pr Mj

Pr Yn Mk
Kn
j 1 Pr Yn Mj

 

when Mj takes a discrete uniform prior  j
1  . . .   Kn. It is not necessary for Yn to be normally
distributed to ensure the selection consistency in detecting mean changes  while the Gaussian kernel
is used here because it tends to be large when the difference between the true and the hypothetical
segment means is small. Hence  as n
  Pr Mk Yn approaches 1 when ⌧k is a true change point
and the ⌧j’s j

k are nI-ﬂat points.

2.2 Detection of change points
We start with the simplest case where there is only one mean shift in the data  i.e.  p0
1 is ﬁxed
a priori. We select the candidate point ⌧k corresponding to the largest Pr Mk Yn   i.e.  the largest
marginal likelihood Pr Yn Mk . It can be shown that

Pr Mk Yn

1

Kn

j k

Pr Yn Mj
Pr Yn Mk

1

 

where for j

k 

Pr Yn Mj

⌧j 1 1
l ⌧j

exp
⌧j 1 1
l ⌧j

Yl

exp

¯Y⌧j
Yl

µ 2 ⇡ µ dµ
¯Y⌧j

2

 

3

k we replace above ⌧j and ⌧j 1 by ⌧k and ⌧k 1 respectively. As a result  the selection

and for j
consistency is determined by the evidence in favor of µk
For the case with multiple change points (p0
largest Pr Mk Yn   for which the selection consistency is presented as follows.
Theorem 1. Let M Mk ⌧ k

. If it holds that

⇡ µk and µj

1)  we select the points corresponding to the p0

0 for j

k.

(1)

T0 p0
Pr Yn Mj
I  

Op anj  
  then

for ⌧j

T0 p0   anj

op 1   and n1 2
Pr Mk Yn

1 Op KnanI exp nI2

.

Hence  as nI log n

Mk M
c

0  nI

  we have

Pr Mk Yn

p 1.

Mk M

n 1 2
j

for local prior ⇡L µ ; anj

The proof of Theorem 1 is delineated in Appendix. The selection consistency depends on the
convergence rate of anI   which is determined by the prior ⇡ . Lemmas 2–4 in Appendix show
that anj
for
⇡I µ . Hence  the selection consistency is achieved at the fastest rate using the non-local inverse
moment prior.
When p0 is unknown  let T p be the set containing p points obtained by the procedure described
above. We deﬁne the marginal likelihood given T p as

for ⇡M µ and anj

n v 1 2
j

ns s 1
j

exp

⌧j 1 1

Pr Yn T p

⌧j T p

l ⌧j

exp

Yl

¯Y⌧j

2

⌧k 1 1

l ⌧k

exp

Yl

¯Y⌧k

µ 2 ⇡ µ dµ.

⌧k T p

We can estimate the locations and the number of change points in two steps: First for any given p  we
obtain T p using the procedure described in the previous section; and second we estimate p0 by
p by maximizing Pr Yn T p with respect to p  which is merely implemented in one dimension.
In contrast  SML [5] simultaneously estimates the locations and the number of change points by
maximizing the marginal likelihood with respect to both T p and p.
2.3 Selection of candidate points
Previous discussions rely upon a critical assumption that the candidate points are speciﬁed in advance.
that is close
To facilitate the implementation of BMS  we need to ﬁnd a candidate set Hc nI
to H nI . For the selection consistency of the change points  we require for each tj there is a
⌧k Hc nI   such that Pr tj

1 Op min exp nI2   anI

. Deﬁne

Ri

⌧k
i nI 1
l

i

nI
exp
i nI 1
l

i

Yl
exp

¯Yi
Yl

µ 2 ⇡ µ dµ
¯Yi

2

 

n 1
I

i 1
j i nI

where ¯Yi
Yj. By the argument similar to that in Lemma 1  Ri goes to inﬁnity when
i is a true change point  and Ri approaches zero in probability when i is an nI-ﬂat point. Hence 
the value of Ri can distinguish a change point from a set of nI-ﬂat points. To further eliminate
the non-change points that are also not nI-ﬂat  we implement the non-maximum suppression that
removes the points which do not yield the largest Ri’s in their nI-neighborhood. Speciﬁcally  the
screening procedure for selecting candidate points is described as follows.

Algorithm 1 : Screening

(i) For each i in nI  n
(ii) If Ri max Rj : j
(iii) Scan through the entire data sequence  and obtain a set of Kn candidate points Hc nI .

  then i is selected as a candidate point.

nI   compute Ri.
i

nI  i

nI

4

The screening algorithm is comparable to that in [15]  as by the Laplace approximation we have

Dn

Ri

exp

i nI 1
l

i
i nI 1
l

i

exp
i nI 1

ˇµ 2 ⇡ ˇµ
2

Yl

¯Yi

Yl

¯Yi
i 1

1

op 1

Dn exp 2

Yl

Yj

ˇµ

nI ˇµ2 ⇡ ˇµ 1

op 1  

l

i

j i nI

where Dn is a constant of order Op n 1 2
Yl
log⇡ µ . The magnitude of the leading term in Ri is strongly associated with n 1

and ˇµ is the maximizer of

i nI 1
l

I

i

I

¯Yi
i nI 1
l

µ 2
Yl

i

i 1
j i nI

Yj  which is the local diagnosis function with h
The screening procedure identiﬁes a candidate set Hc nI
Proposition 1. Assume that n1 2
that Pr tj

I  

nI ⌧

nI

  and for each tj

1 O min exp nI2   anI

⌧

.

nI in [15].

that would lead to the consistency result.
T0 p0   there is a ⌧ Hc nI   such

tj maximizes Ri in the nI-neighborhood of tj asymptotically. By selecting the local
In theory  i
maximal Ri in the screening procedure  Hc nI would cover the nI-neighborhood of T0 p0 as
indicates that the effect size cannot be too small in order
n
to ﬁnd the candidate points around the true change points. After selecting the candidate points  we
perform a reﬁnement step to identify the locations and the total number of change points.

. Also the condition n1 2

I  

Algorithm 2 : Reﬁnement
Scanning

(i) Compute Pr Yn Mk by scanning over all the candidate points in Hc nI .
(ii) For each p  obtain a set of change points T p corresponding to the p largest Pr Yn Mk  

k

1  . . .   Kn.

Optimization

(iii) Select p that maximizes Pr Yn T p .

Theorem 2. Assume that nI log n
holds. Let Hc nI be the set of candidate points such that ⌧k 1
a ⌧k Hc nI   Pr tj

⌧k
1 Op min exp nI2   anI

I  

0  n1 2

nI

⌧k

c

  lim supn

nI 

1 2  and (1)
nI  and for each tj there is
. Then 

Pr p

p0

1 Op max exp nI2   anI

 

and furthermore 

Pr

Pr

sup
tj T p

inf

tj T0 p0

sup
tj T0 p0

inf
tj T p

tj

tj n

nI n

1 O exp nI2

 

tj

tj n

nI n

1 O anI .

Theorem 2 shows that BMS controls both the over- and under-segmentation errors. The ra-
tionale is that for any T p different from T0 p0  
T p whose nI-neighborhood does not contain true change points. Then the likelihood ratio
goes to 0 with probability 1  because the ratio contains at least
Pr Yn T p
T0 p0   which converges to 0 in
one of Pr Yn Mj and Pr Yn Mj
probability by Lemma 1 and (1). As the computational time for Pr Yn Mk grows at the speed of
O n for k
1  . . .   Kn  that for the reﬁnement stage grows with the sample size at the speed of
O nKn .

there is at least a chosen point ⌧

T0 p0 and ⌧j

Pr Yn T0 p0

1 for ⌧k

5

3 Simulations

3.1 Data sequence without spikes
To evaluate the performance of the proposed BMS method in the settings without spike points  we
generate data from two different models. Model I takes the form of

Model I : Yi

h J xi

✏i 

2.01  2.51  1.51  2.01  2.51  2.11  1.05  2.16  1.56  2.56  2.11 with p0

11 
where h
 
the error ✏i N 0  1   and 
is a sign function  and the xi’s are equally spaced on [0  1]. The true change points are
where sgn
0.1  0.13  0.15  0.23  0.25  0.40  0.44  0.65  0.76  0.78  0.81 . The errors
tj n  j
1  . . .   p0
are generated from three distributions: N 0  1 ; t distribution with 5 degrees of freedom t 5  
standardized to have variance 1; and the log-normal distribution LN 0  1   standardized to have
variance 1. Model II considers heteroscedastic errors across segments 

0.5. We set J xi

1  . . .   p0

sgn nxi

1

tj

2  j

Model II : Yi

h J ti

✏i

vj 

1 J ti

j 1

where vj  j
the same as those in model I. The over- and under-segmentation errors are respectively deﬁned as

1  0.5  3  2 3  0.5  3  2 3  0.5  3  2 3  0.5 . Other speciﬁcations remain

1  . . .   11

d Gn Gn

sup
b Gn

inf
a Gn

a

b   d Gn Gn

a

b .

sup
b Gn

inf
a Gn

log n 1.5h  where h

p0 on average for each prior. Both the selection error and p

For the BMS procedure  we consider three different priors for ⇡   corresponding to the local prior 
non-local moment prior and non-local inverse moment prior. Figure 2 presents the relationship
between the maximum of the over- and under-segmentation errors  p
p0 and the value of h with
0.65 leading to the smallest segmentation error. We take the
sample size 1000  which indicates h
minimum distance between candidate points nI
0.5 generally works
well in the simulations.
Furthermore  we assess the performance of BMS using different priors under model I with a normal
error  when p0 is not prespeciﬁed. In Figure 3  we present the selection error which is deﬁned as
the maximum of the number of selected change points that are not in T0 p0 and the number of
true change points that are not in T p . The tuning parameters are calibrated to yield the smallest
segmentation error and p
p0
leads to the best convergence among the
decrease as the sample size increases  and the prior ⇡I
three prior choices.
For a comprehensive comparison with existing methods  we assess BMS under the non-local inverse
moment prior ⇡I
6 against existing methods including PELT [12] 
WBS [7]  NOT with normal or heavy-tail distributions [1] and SML [5]. Table 1 summarizes
the numerical results under model I and model II with normal  Student’s t  and log-normal error
distributions and their heteroscedastic counterparts. On average  BMS performs the best in selecting
the number of change points and balancing both over- and under-segmentation errors. It is expected
that the performances of WBS  PELT  and SML deteriorate when the errors do not follow a normal
distribution  because they all rely upon parametric model assumptions and thus are not robust to model
misspeciﬁcations. In contrast  both BMS and NOT behave well under various error distributions.
Also  NOT and SML perform the best in controlling the over-segmentation errors  while the resulting
estimator p tends to be larger than the true p0. On the other hand  BMS allows for slightly larger
over-segmentation errors in order to maintain p to be more concentrated around p0.

2 and s

with q

⌫

3.2 Data sequence with spikes
We further evaluate the BMS  NOT and SML methods based on the data sequences contaminated
with spike points. Assuming normal noises  we generate 500 sequences and each contains n
1000
points with mean changes of 0.01 and
0.01 at the 400th and 440th observations  respectively. We
set the standard deviation of the noise to be 0.002. We further generate 10 random samples uniformly
in the ranges of
0.07  0.08 and 0.07  0.08   and add them to the original sequence at random

6

5
3

0
3

5
2

0
2

5
1

0
1

5

r
o
r
r
e

 

n
o

i
t

a

t

n
e
m
a
g
e
s
 
m
u
m
x
a
M

i

Model I
Model II

5

.

3

0

.

3

5

.

2

0

.

Model I
Model II

2

0
p
−
p^

5

.

1

0

.

1

5

.

0

0

.

0

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1.0

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1.0

h

h

Figure 2: The maximum segmentation error (left) and p
in the minimum distance between candidate points) over 100 simulations with sample size n

p0 (right) versus h (the tuning parameter
1000.

0
1

8

r
o
r
r
e

 

n
o

6

i
t
c
e
e
S

l

 

4

2

πL
πM
πI

πL
πM
πI

7

6

5

4

0
p
−
p^

3

2

1

0

200

400

600

800

1000

200

400

600

800

1000

Sample size

Sample size

Figure 3: The selection error (left) and p
p0 (right) averaged over 500 simulations under three
different prior distributions: the local prior ⇡L  non-local moment prior ⇡M  and non-local inverse
moment prior ⇡I.

locations to form the spike points. These conﬁgurations are chosen to mimic the real data setting. We
implement BMS  NOT  and SML on the simulated samples  and for BMS we select nI
12 which
is the largest integer that is smaller than 0.65 log n 1.5.
Table 2 shows that BMS  resulting in the smallest p
p0 on average  is insensitive to the spike
points. Figure 4 illustrates the change points detection results for three simulated data sequences. It is
observed that NOT ignores both the change points with small signal-noise ratios and the spike signals
with small segment lengths  because NOT is more appropriate for settings where the segments are
of comparable lengths. On the other hand  SML is sensitive to extreme values  as it is developed to
handle frequent and irregular change points. It appears that BMS is the most suitable procedure for
this case  because not only does it reinforce the minimal segment length to avoid false identiﬁcation
of spike signals but it also retains the minimal segment length to detect change points with small
distance gaps.

7

Table 1: Comparison results averaged over 200 simulations among the BMS  PELT  WBS  NOT and
SML methods under models I and II with three error distributions: N 0  1   t 5   and log-normal
LN 0  1   and those with heteroscedastic variances. Standard deviations are given in parentheses.
Error
Distribution Method
N 0  1

3

3

BMS
PELT
WBS
NOT
SML
BMS
PELT
NOT
SML
BMS
PELT
NOT
SML
BMS
PELT
NOT
SML
BMS
PELT
NOT
SML
BMS
PELT
NOT
SML

t 5

LN 0  1

Hetero-
scedastic
N 0  1

Hetero-
scedastic
t 5

Hetero-
scedastic
LN 0  1

p
1
1
37
0
0
0
8
31
3
0
12
21
4
0
13
31
0
0
14
35
5
0
20
21
4
0

p0
0
197
162
194
192
132
190
165
184
42
180
135
183
0
176
169
150
119
181
159
179
43
173
142
183
2

2
0
1
0
0
0
0
4
0
0
0
2
1
0
0
0
0
0
0
4
1
0
0
2
0
0

0
0
0
0
0
0
0
0
0
0
1
0
0
0
0
0
0
0
0
0
0
0
0
0
0

1
2
0
6
7
52
2
0
3
34
6
15
7
0
8
0
23
55
4
2
10
22
7
22
7
1

2
0
0
0
1
13
0
0
6
44
1
23
1
4
3
0
21
20
1
0
2
41
0
12
4
0

0
0
0
0
3
0
0
4
80
2
3
4
196
0
0
6
6
0
0
3
94
0
1
2
197

d Gn Gn
2.41 (6.06)
0.91 (1.19)
1.22 (4.13)
1.93 (8.04)
12.94 (42.98)
2.15 (5.76)
0.95 (1.03)
7.57 (27.70)
40.13 (53.68)
3.69 (12.12)
12.10 (29.63)
6.06 (26.32)
111.77 (52.05)
3.69 (7.08)
1.49 (1.53)
7.52 (12.60)
6.75 (23.98)
2.79 (4.87)
1.50 (1.83)
8.15 (25.01)
26.74 (35.42)
3.73 (11.72)
6.07 (16.09)
6.32 (24.67)
68.05 (47.15)

d Gn Gn
1.96 (3.94)
6.32 (11.92)
0.86 (0.79)
0.75 (0.80)
0.78 (0.90)
2.83 (7.01)
6.24 (12.24)
1.51 (2.57)
0.88 (0.87)
3.11 (6.89)
7.22 (13.32)
1.18 (4.45)
0.73 (1.33)
3.88 (7.36)
6.15 (11.44)
1.66 (1.68)
1.37 (1.52)
4.21 (8.17)
7.76 (13.48)
2.36 (4.70)
1.27 (1.59)
4.20 (7.85)
8.10 (13.93)
1.42 (3.70)
0.87 (1.67)

l

e
v
e

l

l

a
n
g
S

i

l

l

e
v
e
e
l
v
 
e
 
l
l
a
l
a
n
n
g
g
S
i
S

i

l

e
v
e

l

l

a
n
g
S

i

5
0

.

0

0
0

.

0

5
0
0
-

.

5
0

.

0

0
0

.

0

5
0
0
-

.

5
0
.
0

0
0
.
0

5
0
.
0
-

Index

Index

Observation Index

Index

Figure 4: Detection of change points for three simulated data sequences with spike points using BMS
(the red solid line)  NOT (the blue dashed line) and SML (the brown dotted line).

4 MRgRT data

We illustrate the BMS method with application to the MRgRT data which contain 2265 observations
ordered by the distances from the sources of the radiations. The R code for implementing the BMS
method can be downloaded from our GitHub repository [10]. Throughout the implementation  we
use the non-local inverse moment prior ⇡I µ with q

2  and we set nI

2 and ⌫

13.

8

Table 2: Comparison results averaged over 500 simulations among the BMS  NOT and SML methods
based on the data sequences with spike points.

Method
BMS
NOT
SML

3

0
0
0

2
0
0
0

p

1
31
387
0

p0
0
276
32
0

1
113
20
0

2
67
11
0

3
13
50
500

By varying s from 2 to 10  the left panel in Figure 5 shows that when s is small  BMS identiﬁes more
change points  and as s grows the number of identiﬁed change points decreases. This phenomenon is
consistent with Lemma 4 that the convergence rate for the non-local prior is Op exp ns 1 s
.
When s is small  the Bayes factor vanishes slowly and hence the algorithm picks more spurious
change points. When s is sufﬁciently large  the convergence rate approaches Op exp nI
  and
hence the algorithm eliminates the ﬂat points more effectively.

I

Y

l

e
v
e

l
 
l

Y
a
n
g
S

i

Y

0
1
0

.

0

5
0
0

.

0

0
0
0

.

0

5
0
0
0
-

.

0
1
0

.

0
-
0
1
0

.

0

5
0
0

.

0

0
0
0

.

0

5
0
0

.

0
-

.

0
1
0
0
-
0
1
0

.

0

5
0
0

.

0

0
0
0

.

0

5
0
0
0
-

.

0
1
0
0
-

.

Distance from the source

Distance from the source

l

e
v
e
l
 
l
a
n
g
S

i

0
1
0
.
0

5
0
0
.
0

0
0
0
.
0

5
0
0
.
0
-

0
1
0
.
0
-

s= 2

s= 5

s = 10

0

12

24

35

47

59

71

83

95

123

Distance from the source

Distance from the source

0

12

24

36

49

63

75

87

101

Distance from the source

2  5  and 10
Figure 5: The left panel shows the detection of change points using BMS with s
respectively; the right panel shows the detection of change points after restricting the data in the
range of
10 (the red solid line)  NOT (the blue dashed line)  and
SML (the brown dotted line).

0.01  0.01 using BMS with s

0.01  0.01 . By
We further remove the spike points  and thus keep the data within the range of
ﬁxing s
10  we implement BMS  NOT and SML on the truncated data sequence. The right panel in
Figure 5 shows that the change point detection results using the three methods are largely overlapped.
The BMS and NOT methods lead to similar results  and both outperform SML. This implies that
removing the spike points improves the accuracy of boundary detection for all the three methods.

5 Conclusion

The proposed BMS method can consistently identify multiple mean changes in a data sequence 
which effectively removes the ﬂat points without sacriﬁcing the detection accuracy. Our method is
particularly useful when the data sequence contains spike points that are not of interest as they are not
real change points. The BMS is applied to analyze the MRgRT data for detecting mean changes in the
signals  while the NOT  SMT and other methods fail to correctly detect the boundaries. We explore
the performance of BMS with different tuning parameters  and the resulting patterns are consistent
with the theoretical properties. Moreover  we demonstrate the robustness of BMS to various error
distributions.

9

Acknowledgment
The authors would like to thank Dr. Zhou Shouhao from Department of Biostatistics  M.D. Anderson
Cancer Center for providing the data. The research is partially supported by grants from the Research
Grants Council of Hong Kong (grant number 27304117 for Jiang and 17326316 for Yin).

References
[1] Baranowski  R.  Chen  Y.  and Fryzlewicz  P. (2016). Narrowest-over-threshold detection of

multiple change-points and change-point-like features. arXiv preprint arXiv:1609.00293 .

[2] Bertolino  F.  Racugno  W.  and Moreno  E. (2000). Bayesian model selection approach to

analysis of variance under heteroscedasticity. The Statistician pages 503–517.

[3] Conigliani  C. and O’Hagan  A. (2000). Sensitivity of the fractional bayes factor to prior

distributions. Canadian Journal of Statistics 28  343–352.

[4] De Santis  F. and Spezzaferri  F. (2001). Consistent fractional bayes factor for nested normal

linear models. Journal of Statistical Planning and Inference 97  305–321.

[5] Du  C.  Kao  C.-L. M.  and Kou  S. (2016). Stepwise signal extraction via marginal likelihood.

Journal of the American Statistical Association 111  314–330.

[6] Eiauer  P. and Hackl  P. (1978). The use of MOSUMS for quality control. Technometrics 20 

431–436.

[7] Fryzlewicz  P. (2014). Wild binary segmentation for multiple change-point detection. The Annals

of Statistics 42  2243–2281.

[8] Glaz  J.  Naus  J. I.  Wallenstein  S.  Wallenstein  S.  and Naus  J. I. (2001). Scan Statistics.

Springer.

[9] Jeffreys  H. (1998). The Theory of Probability. Oxford University Press.
[10] Jiang  F.  Yin  G.  and Dominici  F. (2018). Bayesian model selection approach to boundary

detection with non-local priors. https://github.com/homebovine/BCP.git.

[11] Johnson  V. E. and Rossell  D. (2010). On the use of non-local prior densities in Bayesian

hypothesis tests. Journal of the Royal Statistical Society: Series B 72  143–170.

[12] Killick  R.  Fearnhead  P.  and Eckley  I. (2012). Optimal detection of change points with a

linear computational cost. Journal of the American Statistical Association 107  1590–1598.

[13] Kirch  C. and Muhsal  B. (2014). A MOSUM procedure for the estimation of multiple random

change points. Preprint .

[14] Lavielle  M. and Ludeña  C. (2000). The multiple change-points problem for the spectral

distribution. Bernoulli 6  845–869.

[15] Niu  Y. S. and Zhang  H. (2012). The screening and ranking algorithm to detect dna copy

number variations. The Annals of Applied Statistics 6  1306–1326.

[16] Preuss  P.  Puchstein  R.  and Dette  H. (2015). Detection of multiple structural breaks in

multivariate time series. Journal of the American Statistical Association 110  654–668.

[17] Walker  S. G. (2004). Modern Bayesian asymptotics. Statistical Science pages 111–117.
[18] Yao  Y.-C. (1987). Approximating the distribution of the maximum likelihood estimate of
the change-point in a sequence of independent random variables. The Annals of Statistics 15 
1321–1328.

[19] Yau  C. Y. and Zhao  Z. (2015). Inference for multiple change points in time series via likelihood

ratio scan statistics. Journal of the Royal Statistical Society: Series B 78  895–916.

10

,Haizi Yu
Tianxi Li
Lav Varshney
Fei Jiang
Guosheng Yin
Francesca Dominici