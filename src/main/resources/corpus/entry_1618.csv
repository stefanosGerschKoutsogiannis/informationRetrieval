2019,Don't take it lightly: Phasing optical random projections with unknown operators,In this paper we tackle the problem of recovering the phase of complex linear measurements when only magnitude information is available and we control the input. We are motivated by the recent development of dedicated optics-based hardware for rapid random projections which leverages the propagation of light in random media. A signal of interest $\mathbf{\xi} \in \mathbb{R}^N$ is mixed by a random scattering medium to compute the projection $\mathbf{y} = \mathbf{A} \mathbf{\xi}$  with $\mathbf{A} \in \mathbb{C}^{M \times N}$ being a realization of a standard complex Gaussian iid random matrix. Such optics-based matrix multiplications can be much faster and energy-efficient than their CPU or GPU counterparts  yet two difficulties must be resolved: only the intensity ${|\mathbf{y}|}^2$ can be recorded by the camera  and the transmission matrix $\mathbf{A}$ is unknown. We show that even without knowing $\mathbf{A}$  we can recover the unknown phase of $\mathbf{y}$ for some equivalent transmission matrix with the same distribution as $\mathbf{A}$. Our method is based on two observations: first  conjugating or changing the phase of any row of $\mathbf{A}$ does not change its distribution; and second  since we control the input we can interfere $\mathbf{\xi}$ with arbitrary reference signals. We show how to leverage these observations to cast the measurement phase retrieval problem as a Euclidean distance geometry problem. We demonstrate appealing properties of the proposed algorithm in both numerical simulations and real hardware experiments. Not only does our algorithm accurately recover the missing phase  but it mitigates the effects of quantization and the sensitivity threshold  thus improving the measured magnitudes.,Don’t take it lightly: Phasing optical random

projections with unknown operators

Sidharth Gupta

University of Illinois at Urbana-Champaign

gupta67@illinois.edu

Rémi Gribonval

Univ Rennes  Inria  CNRS  IRISA

remi.gribonval@inria.fr

Laurent Daudet
LightOn  Paris

laurent@lighton.ai

Ivan Dokmani´c

University of Illinois at Urbana-Champaign

dokmanic@illinois.edu

Abstract

In this paper we tackle the problem of recovering the phase of complex linear
measurements when only magnitude information is available and we control the
input. We are motivated by the recent development of dedicated optics-based
hardware for rapid random projections which leverages the propagation of light
in random media. A signal of interest ξ ∈ RN is mixed by a random scattering
medium to compute the projection y = Aξ  with A ∈ CM×N being a realization
of a standard complex Gaussian iid random matrix. Such optics-based matrix
multiplications can be much faster and energy-efﬁcient than their CPU or GPU
counterparts  yet two difﬁculties must be resolved: only the intensity |y|2 can be
recorded by the camera  and the transmission matrix A is unknown. We show
that even without knowing A  we can recover the unknown phase of y for some
equivalent transmission matrix with the same distribution as A. Our method is
based on two observations: ﬁrst  conjugating or changing the phase of any row
of A does not change its distribution; and second  since we control the input
we can interfere ξ with arbitrary reference signals. We show how to leverage
these observations to cast the measurement phase retrieval problem as a Euclidean
distance geometry problem. We demonstrate appealing properties of the proposed
algorithm in both numerical simulations and real hardware experiments. Not
only does our algorithm accurately recover the missing phase  but it mitigates the
effects of quantization and the sensitivity threshold  thus improving the measured
magnitudes.

1

Introduction

Random projections are at the heart of many algorithms in machine learning  signal processing and
numerical linear algebra. Recent developments ranging from classiﬁcation with random features [16] 
kernel approximation [25] and sketching for matrix optimization [24  27]  to sublinear-complexity
transforms [26] and randomized linear algebra are all enabled by random projections. Computing
random projections for realistic signals such as images  videos  and modern big data streams is
computation- and memory-intensive. Thus  from a practical point of view  any increase in the size
and speed at which one can do the required processing is highly desirable.
This fact has motivated work on using dedicated hardware based on physics rather than traditional
CPU and GPU computation to obtain random projections. A notable example is the scattering of
light in random media (Figure 1 (left)) with an optical processing unit (OPU). The OPU enables
rapid (20 kHz) projections of high-dimensional data such as images  with input dimension scaling up

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

Random scattering medium

Camera taking
8-bit measurements

Laser
light
source

DMD encoding
of (xq − xr)

| (cid:104)a  xq − xr(cid:105) |2 = |yq − yr|2
a

iid∼ N (0  I) + jN (0  I)

Im

yq

|yq − yr|2

yr

φ

Re

yrq

yq

|yq − yr|2

yr

yrq

Figure 1: Left: The optical processing unit (OPU) is an example application of where the MPR
problem appears. A coherent laser beam spatially encodes a signal (xq − xr) via a digital micro-
mirror device (DMD) which is then shined through a random medium. A camera measures the
squared magnitude of the scattered light which is equivalent to the Euclidean distance between
complex numbers yq ∈ C and yr ∈ C. Furthermore the camera takes quantized measurements; Right:
yq and yr are points on the two-dimensional complex plane. We can measure the squared Euclidean
distance between points and use these distances to localize points on the complex plane and obtain
their phase. Note that transformations such as rotations and reﬂections do not change the distances.

to one million and output dimension also in the million range. It works by “imprinting” the input
data ξ ∈ RN onto a coherent light beam using a digital micro-mirror device (DMD) and shining the
modulated light through a multiple scattering medium such as titanium dioxide white paint. The
scattered lightﬁeld in the sensor plane can then be written as

y = Aξ

where A ∈ CM×N is the transmission matrix of the random medium with desirable properties.
One of the major challenges associated with this approach is that A is in general unknown. Though it
could in principle be learned via calibration [6]  such a procedure is slow and inconvenient  especially
at high resolution. On the other hand  the system can be designed so that the distribution of A
is approximately iid standard complex Gaussian. Luckily  this fact alone is sufﬁcient for many
algorithms and the actual values of A are not required.
Another challenge is that common light sensors are only sensitive to intensity  so we can only
measure the intensity of scattered light  |y|2  where | · | is the elementwise absolute value. The
phase information is thus lost. While the use of interferometric measurements with a reference could
enable estimating the phase  the practical setup is more complex  sensitive  and it does not share the
convenience and simplicity of the one illustrated in Figure 1 (left).
This motivates us to consider the measurement phase retrieval (MPR) problem. The MPR sensor data
is modeled as

b = |y|2 + η = |Aξ|2 + η 

(1)
where b ∈ RM   ξ ∈ RN   A ∈ CM×N   y ∈ CM   and η ∈ RM is noise. The goal is to recover the
phase of each complex-valued element of y  yi for 1 ≤ i ≤ M  from its magnitude measurements
b when ξ is known and the entries of A are unknown. The classical phase retrieval problem which
has received much attention over the last decade [15  4] has the same quadratic form as (1) but with
a known A and the task being to recover ξ instead of y. While at a glance it might seem that not
knowing A precludes computing the phase of Aξ  we show in this paper that it is in fact possible via
an exercise in distance geometry.
The noise η is primarily due to quantization because standard camera sensors measure low precision
values  8-bit in our case (integers between 0 and 255 inclusive). Furthermore  cameras may perform
poorly at low intensities. This is another data-dependent noise source which is modelled in (2) by
a binary mask vector w ∈ RM which is zero when the intensity is below some threshold and one
otherwise; (cid:12) denotes the elementwise product.

b = w (cid:12)(cid:16)|y|2 + η

(cid:17)

= w (cid:12)(cid:16)|Aξ|2 + η

(cid:17)

(2)

The distribution of A follows from the properties of random scattering media [14  6]. It has iid
standard complex Gaussian entries  amn ∼ N (0  1) + jN (0  1) for all 1 ≤ m  n ≤ M  N.

2

The usefulness of phase is obvious. While in some applications having only the magnitude of the
random projection is enough (see [17] for an example related to elliptic kernels)  most applications
require the phase. For example  with the phase one can implement a more diverse range of kernels as
well as randomized linear algebra routines like randomized singular value decomposition (SVD). We
report the results of the latter on real hardware in Section 3.1.

Our contributions. We develop an algorithm based on distance geometry to solve the MPR
problem (1). We exploit the fact that we control the input to the system  which allows us to mix ξ
with arbitrary reference inputs. By interpreting each pixel value as a point in the complex plane  this
leads to a formulation of the MPR problem as a pure distance geometry problem (see Section 2.2
and Figure 1 (right)). With enough pairwise distances (corresponding to reference signals) we can
localize the points on the complex plane via a variant of multidimensional scaling (MDS) [23  5] 
and thus compute the missing phase.
As we demonstrate  the proposed algorithm not only accurately recovers the phase  but also improves
the number of useful bits of the magnitude information thanks to the multiple views. Established
Euclidean distance geometry bounds imply that even with many distances below the sensitivity
threshold and coarse quantization  the proposed algorithm allows for accurate recovery. This fact 
which we verify experimentally  could have bearing on the design of future random projectors by
navigating the tradeoff between physics and computation.

1.1 Related work

The classical phase retrieval problem looks at the case where A is known and ξ has to be recovered
from b in (1) [7  21  10]. A modiﬁed version of the classical problem known as holographic phase
retrieval is related to our approach: a known reference signal is concatenated with ξ to facilitate the
phase estimation [1]. Interference with known references for classical phase retrieval has also been
studied for known (Fourier) operators [3  11] .
An optical random projection setup similar to the one we consider has been used for kernel-based
classiﬁcation [17]  albeit using only magnitudes. A phaseless approach to classiﬁcation with the
measured magnitudes fed into a convolutional neural network was reported by Satat et al. [18].
An alternative to obtaining the measurement phase is to measure  or calibrate  the unknown trans-
mission matrix A. This has been attempted in compressive imaging applications but the process
is impractical at even moderate pixel counts [6  14]. Estimating A can take days and even the
latest GPU-accelerated methods take hours for moderately sized A [20]. Other approaches forego
calibration and use the measured magnitudes to learn an inverse map of x (cid:55)→ |Ax|2 for use with the
magnitude measurements [9].
Leaving hardware approaches aside  there have been multiple algorithmic efforts to improve the speed
of random projections [12  25] for machine learning and signal processing tasks. Still  efﬁciently
handling high-dimensional input remains a formidable challenge.

2 The measurement phase retrieval problem
We will denote the signal of interest by ξ ∈ RN   and the K reference anchor signals by rk ∈ RN
for 1 ≤ k ≤ K. To present the full algorithm we will need to use multiple signals of interest
which we will then denote ξ1  . . .   ξS; each ξs is called a frame. We set the last  Kth anchor to be
the origin  rK = 0. We ascribe ξ and the anchors to the columns of the matrix X ∈ RN×Q  so
that X = [ξ  r1  r2 ···   rK] and let Q = K + 1. The qth column of X is denoted xq. For any
1 ≤ q  r ≤ Q  we let yq = Axq and yqr := A(xq − xr)  with yqr m being its mth entry. Finally 
the mth row of A will be denoted by am so that yqr m = (cid:104)am  xq − xr(cid:105).

2.1 Problem statement and recovery up to a reference phase and conjugation

Since we do not know A  it is clear that recovering the absolute phase of Aξ is impossible. On the
other hand  many algorithms do not require any knowledge of A except that it is iid standard complex
Gaussian  and that it does not change throughout the computations.

3

Let R be an operator which adds a constant phase to each row of its argument (multiplies it by
diag(ejφ1  . . .   ejφm) for some φ1  . . .   φm) and conjugates a subset of its rows. Since a standard
complex Gaussian is circularly symmetric  R(A) has the same distribution as A. Therefore  since we
do not know A  it does not matter whether we work with A itself or with R(A) for some possibly
unknown R. As long as the same effective R is used for all inputs during algorithm operation  the
relative phases between the frames will be the same whether we use R(A) or A.1
Problem 1. Given a collection of input frames ξ1  . . .   ξS to be randomly projected and a device
illustrated in Figure 1 (left) with an unknown transmission matrix A ∈ CM×N and a b-bit camera 
compute the estimates of projections ˆy1  . . .   ˆyS up to a global row-wise phase and conjugation; that
is  so that there exists some R such that ˆys ≈ R(ys) for all 1 ≤ s ≤ S.
2.2 MPR as a distance geometry problem

Since the rows of A are statistically independent  we can explain our algorithm for a single row and
then repeat the same steps for the remaining rows. We will therefore omit the row subscript/superscript
m except where explicitly necessary.
Instead of randomly projecting ξ and measuring the corresponding projection magnitude |Aξ|2 
consider randomly projecting the difference between ξ and some reference vector  or more generally
a difference between two columns in X  thus measuring |(cid:104)a  xq − xr(cid:105)|2 = |yq − yr|2. Interpreting
yq and yr as points in the complex plane  we see that the camera sensor measures exactly the squared
Euclidean distance between them. Since we control the input to the OPU  we can indeed set it to
xq − xr and measure |yq − yr|2 for all 1 ≤ q  r ≤ Q.
This is the key point: as we can measure pairwise distances between a collection of two-dimensional
vectors in the two-dimensional complex plane  we can use established distance geometry algorithms
such as multidimensional scaling (MDS) to localize points and get their phase. This is illustrated in
Figure 1 (right). The same ﬁgure also illustrates the well known fact that rigid transformations of a
point set cannot be recovered from distance data. We need to worry about three things: translations 
reﬂections and rotations.
The translation ambiguity can be easily dealt with if one notes that for any column xq of X 
|yq| = |(cid:104)a  xq(cid:105)| gives us the distance of yq to the origin which is a ﬁxed point  ultimately resolving
the translation ambiguity. There is  however  no similar simple way to do away with the rotation and
reﬂection ambiguity  so it might seem that there is no way to uniquely determine the phase of (cid:104)a  ξ(cid:105).
This is where the discussion from the preceding subsection comes to the rescue. Since R is arbitrary 
as long as it is kept ﬁxed for all the frames  we can arbitrarily set the orientation of any given frame
and use it as a reference  making sure that the relative phases are computed correctly.

2.3 Proposed algorithm
As deﬁned previously  the columns of X ∈ RN×Q list the signal of interest and the anchors. Recall
that all the entries of X are known. Using the OPU  we can compute a noisy (quantized) version of

|yqr|2 = |(cid:104)a  xq − xr(cid:105)|2 = |yq − yr|2 

(3)
for all (q  r)  which gives us Q(Q − 1)/2 squared Euclidean distances between points {yq ∈ C}Q
q=1
on the complex plane. These distances can be used to populate a Euclidean (squared) distance matrix
D ∈ RQ×Q as D = (d2
q r=1  which we will use to localize all complex points
yq.
We start by deﬁning the matrix of all the complex points in R2 which we want to recover as

q r=1 = (|yqr|2)Q

qr)Q

(cid:20)Re(y1) Re(y2)

Im(y1)

Im(y2)

Υ =

(cid:21)
··· Re(yQ)
···
Im(yQ)
qr = (cid:107)υq − υr(cid:107)2

∈ R2×Q.

Denoting the qth column of Υ by υq  we have d2
that

2 = υT

q υq − 2υT

q υr + υT

r υr so

D = diag (G) 1T

Q − 2G + 1Q diag (G)T =: K (G)  

(4)

1Up to a sign.

4

where diag(G) ∈ RQ is the column vector of the diagonal entries in the Gram matrix G := ΥT Υ ∈
RQ×Q and 1Q ∈ RQ is the column vector of Q ones. This establishes a relationship between the
measured distances in D and the locations of the complex points in R2 which we seek. We denote by
J the geometric centering matrix  J := I − 1

Q 1Q1T

Q so that

(cid:98)G = − 1

(5)

2 J DJ = J GJ = (ΥJ )T (ΥJ )

centered point set and the geometric centering matrix because ΥJ is the points in Υ with their mean

is the Gram matrix of the centered point set in terms of Υ. (cid:98)G and J are know as the Gram matrix of the
subtracted. An estimate (cid:98)Υ of the centered point set  ΥJ  is then obtained by eigendecomposition as
(cid:98)G = V diag(λ1  . . .   λQ)V T and taking (cid:98)Υ = [

λ2v2]T where v1 and v2 are the ﬁrst and
second columns of V and assuming that the eigenvalue sequence is nonincreasing. This process is
the classical MDS algorithm [23  5]. Finally  the phases can be calculated via a four-quadrant inverse
tangent  φ(yq) = arctan(υq2  υq1).

λ1v1 

√

√

Procrustes analysis. As we recovered a centered point set via MDS with a geometric centering
matrix J  the point set will have its centroid at the origin. This is a consequence of the used algorithm 
and not the “true” origin. As described above  we know that |yq|2 deﬁnes squared distances to the
origin and yQ = (cid:104)a  xQ(cid:105) = 0 + 0j (as xQ was set to the origin)  meaning that we can correctly

center the recovered points by translating the point set  (cid:98)Υ  by −υQ.

The correct absolute rotation and reﬂection cannot be recovered. However  since we only care about
working with some effective R(A) with the correct distribution  we only need to ensure that the
relative phases between the frames are correct. We can thus designate the ﬁrst frame as the reference
frame and set the rotation (which directly corresponds to the phase) and reﬂection (corresponding to
conjugation) arbitrarily. Once these are chosen  the anchors r1  . . .   rK are ﬁxed  which in turn ﬁxes
the phasing–conjugation operator R.
Since A is unknown  R is also unknown  but ﬁxed anchors allow us to compute the correct relative
phase with respect to R(A) for the subsequent frames. Namely  upon receiving a new input ξs to
be randomly projected  we now localize it with respect to a ﬁxed set of anchors. This is achieved

by Procrustes analysis. Denoting by (cid:101)Υ1 our reference estimate of the anchor positions in frame 1
(columns 2  . . .   Q of (cid:98)Υ above which was recovered from (cid:98)G in (5))  and by (cid:101)Υs the MDS estimate
of anchor positions in frame s  adequately centered. Let (cid:101)Υs(cid:101)Υ
decomposition of (cid:101)Υs(cid:101)Υ
R = V U T so that R(cid:101)Υs ≈ (cid:101)Υ1 [19].

T
1 = U ΣV T be the singular value
T
1 . The optimal transformation matrix in the least squares sense is then

Finally  we note that with a good estimate of the anchors  one can imagine not relocalizing them in
every frame. The localization problem for ξ then boils down to multilateration  cf. Section C in the
supplementary material.

2.4 Sensitivity threshold and missing measurements

As we further elaborate in Section A of the supplementary material  in practice some measurements
fall below the sensitivity threshold of the camera and produce spurious values. A nice beneﬁt
of multiple “views” of ξ via its interaction with reference signals is that we can ignore those
measurements. This introduces missing values in D which can be modeled via a binary mask matrix
W . The recovery problem can be modeled as estimating Υ from W (cid:12) (D + E) where W ∈ RN×N
contains zeros for the entries which fall below some prescribed threshold  and ones otherwise.
We can predict the performance of the proposed method when modeling the entries of W as iid
Bernoulli random variables with parameter p  where 1 − p is the probability that an entry falls below
 
2(2b−1)
where b is the number of bits  and κ an upper bound on the entries of D (in our case 28 − 1 = 255).
Adapting existing results on the performance of multidimensional scaling [28] (by noting that E is
sub-Gaussian)  we can get the following scaling of the distance recovery error with the number of

the sensitivity threshold and E as uniform quantization noise distributed as U(cid:16)− κ

2(2b−1)  

(cid:17)

κ

5

Algorithm 1 MPR algorithm for S frames.

Input: Squared distances(cid:2)|yjQ m − ylQ m|2(cid:3)

1 ≤ m ≤ M; [· ]s denotes frame s

s for all 1 ≤ j  l ≤ Q for frames 1 ≤ s ≤ S and rows

(cid:46) Initialize Y

(cid:46) Solve each row separately
(cid:46) D ∈ RQ×Q
(cid:46) [Υ]1 ∈ R2×Q

Populate all frame s = 1 distances into distance matrix D
[Υ]1 ← MDS(D)
[Υ]1 ← GradientDescent(D  [Υ]1)
[Υ]1 ← [Υ]1 − [υQ]11T
s ← 2
while s ≤ S do

Output: Y ∈ CM×S containing all localized points such that ys = R(A)ξs for some ﬁxed R.
1: Y ← 0M×S
2: m ← 1
3: while m ≤ M do
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21: end while

Populate all frame s distances into distance matrix D
[Υ]s ← MDS(D)
[Υ]s ← GradientDescent(D  [Υ]s)
[Υ]s ← [Υ]s − [υQ]s1T
R ← Procrustes([υ2  . . .   υQ]1  [υ2  . . .   υQ]s)
[Υ]s ← Align([Υ]s  R  [υ2  . . .   υQ]1)
s ← s + 1

U ←(cid:2)[υ1]1  [υ1]2  . . .   [υ1]S

end while
ym ← u1 + ju2
m ← m + 1

(cid:46) U ∈ R2×S
(cid:46) Multiply second row of U with j and add to ﬁrst row

(cid:46) R aligns frames 1 and s anchors
(cid:46) Align anchors

(cid:46) Translate to align with origin

(cid:3)

anchors K (for K sufﬁciently large) 

E(cid:104)(cid:13)(cid:13)(cid:13) ˆD − D

(cid:13)(cid:13)(cid:13)F

(cid:105) (cid:46) κ√

1
K

(6)
where (cid:46) denotes inequality up to a constant which depends on the number of bits b  the sub-
Gaussian norm of the entries in E  and the dimension of the ambient space (here R2). An important
implication is that even for coarse quantization (small b) and for a large fraction of entries below the
sensitivity threshold (small p)  we can achieve arbitrarily small amplitude and phase errors per point
by increasing the number of reference signals K.

pK

 

Reﬁnement with gradient descent. The output of the classical MDS method described above can
be further reﬁned via a local search. A standard differentiable objective called the squared stress is
deﬁned as follows 

Z

Z

min

f (Υ) = min

(7)
where K(·) is as deﬁned in (4) and Z ∈ R2×Q is the point matrix induced by row m of A. In our
experiments we report the result of reﬁning the classical MDS results via gradient descent on (7).
Note that the optimization (7) is nonconvex. The complete procedure is thus analogous to the usual
approach to nonconvex phase retrieval by spectral initialization followed by gradient descent [15  4].
Algorithm 1 summarizes our proposed method.

ZT Z

F

 

(cid:13)(cid:13)(cid:13)W (cid:12)(cid:16)

D − K(cid:16)

(cid:17)(cid:17)(cid:13)(cid:13)(cid:13)2

3 Experimental veriﬁcation and application

We test the proposed MPR algorithm via simulations and experiments on a real OPU. For hardware
experiments  we use a scikit-learn interface to a publicly available cloud-based OPU.2

2https://www.lighton.ai/lighton-cloud/.

Reproducible code available at https://github.com/swing-research/opu_phase under the MIT License.

6

Evaluation metrics. The main challenge is to evaluate the performance without knowing the
transmission matrix A. To this end  we propose to use the linearity error. The rationale behind this
metric is that with the phase correctly recovered  the end-to-end system should be linear. That is  if we
recover y and z from |y|2 = |Aξ1|2 and |z|2 = |Aξ2|2  then we should get (y + z) when applying
the method to |v|2 = |A(ξ1 + ξ2)|2. With this notation  the relative linearity error is deﬁned as

linearity error =

1
M

|(ym + zm) − vm|

|vm|

.

(8)

M(cid:88)

m=1

The second metric we use is the number of “good” or correct bits. This metric can only be evaluated in
simulation since it requires the knowledge of the ground truth measurements. Letting |y|2 = |(cid:104)a  ξ(cid:105)|2
and ˆy be our estimate of y  the number of good bits is deﬁned as

good bits = − 20

6.02 log

(cid:16)||y|2 − |ˆy|2| /|y|2(cid:17)

.

It is proportional to the signal-to-quantization-noise ratio if the distances uniformly cover all quanti-
zation levels.3

3.1 Experiments

In all simulations  intensity measurements are quantized to 8 bits and all signals and references are
iid standard (complex) Gaussian random vectors.
We ﬁrst test the phase recovery performance by evaluating the linearity error. In simulation  we
draw random frames ξ1  ξ2  and A ∈ C100×642. We apply Algorithm 1 to |Aξ1|2  |Aξ2|2 and
|A(ξ1 + ξ2)|2 and calculate the linearity error (8). We use classical MDS and MDS with gradient
descent (MDS-GD). Figure 2a shows that the system is indeed approximately linear and that the
linearity error becomes smaller as the number of reference signals grows. In Figure 2b  we set the
sensitivity threshold to τ = 6 and zero the distances below the threshold per (2). Again  the linearity
error quickly becomes small as the number of anchors increases showing that the overall system is
robust and that it allows recovery of phase for small-intensity signals.
Next  we test the linearity error with a real hardware OPU. The OPU gives 8-bit unsigned integer
measurements. A major challenge is that the DMD (see Figure 1) only allows binary input signals.
This is a property of the particular OPU we use and while it imposes restrictions on reference design 
the method is unchanged as our algorithm does not assume a particular type of signal. Section
A in the supplementary material describes how we create binary references and addresses other
hardware-related practicalities.
Figure 2c reports the linearity error on the OPU with suitably designed references and the same size
A. The empirically determined sensitivity threshold of the camera is τ = 6  and the measurements
below the threshold were not used. We ignore rows of A which give points with small norms (less
than two) because they are prone to noise and disproportionately inﬂuence the relative error. Once
again  we observe that the end-to-end system with Algorithm 1 is approximately linear and that the
linearity improves as we increase the number of anchors.
Finally  we demonstrate the magnitude denoising performance. We draw a ∈ C100  a random signal
ξ ∈ R100 and a set of random reference anchor signals. We run our algorithm for number of anchors
varying between 2 and 15. For each number of anchors  we recover ˆy for |y|2 = |(cid:104)a  ξ(cid:105)|2 using
either classical MDS or MDS-GD. We then measure the number of good bits. The average results
over 100 trials are shown in Figure 3a. Figure 3b reports the same experiment with the sensitivity
threshold set to τ = 6 (that is  the entries below τ are zeroed in the distance matrix per (2)). Both
ﬁgures show that the proposed algorithm signiﬁcantly improves the estimated magnitudes in addition
to recovering the phases. The approximately 1 additional good bit with gradient descent in Figure
3b corresponds to the relative value of 21/28 ≈ 0.8% which is consistent with the gradient descent
improvement in Figure 2b.
We also test a scenario where the anchor positions on the complex plane are known exactly and
we only have to localize a single measurement. We compare this to localizing the anchors and the

3Note that the quantity registered by the camera is actually the squared magnitude  hence the factor 20.

7

(a)

(b)

(c)

Figure 2: Experiments in simulation and on real hardware to evaluate the linearity error as deﬁned
in (8). The input signals are of dimension 642  M in (8) is 100 and the number of anchors signals
are increased. The classical MDS and MDS with gradient descent (MDS-GD) are used. In all cases
the error decreases as the number of anchors increases. (a) In simulation with Gaussian signals and
Gaussian reference signals; (b) In simulation with Gaussian signals and Gaussian reference signals
with sensitivity threshold τ = 6; (c) On a real OPU with binary signals and binary references.

(a)

(b)

(c)

Figure 3: (a) Magnitude denoising performance of MDS and MDS-GD over 100 trials. Input signals
are Gaussian and of dimension 100; (b) Magnitude denoising performance of MDS and MDS-GD over
100 trials with 100-dimensional Gaussian signals and sensitivity threshold τ = 6; (c) Comparison
between recovering a single point and recovering the point and anchors at the same time. SR-LS is
used to locate a single point when anchors are known and MDS is used to locate all points when
anchors are unknown.

measurements jointly. Localizing a single point via multilateration is performed by minimizing the
SR-LS objective (see (9) in the supplementary material). The input signal dimension is 642 and
we recover ˆy for |y|2 = |(cid:104)a  ξ(cid:105)|2. We perform 100 trials and calculate the SNR of the recovered
complex points. Figure 3c shows that although having perfect knowledge of anchor locations helps 
classical MDS alone does not perform much worse.

Optical randomized singular value decomposition. We use Algorithm 1 to implement random-
ized singular value decomposition (RSVD) as described in Halko et al. [8] on the OPU. We use 5
anchors in all RSVD experiments. The original RSVD algorithm and a variant with adaptations for
the OPU are described in Algorithms 2 and 3 in the supplementary material.
One of the steps in the RSVD algorithm for an input matrix B ∈ RM×N requires the computation
of BΩ where Ω ∈ RN×2K is a standard real Gaussian matrix  K is the target number of singular
vectors  and 2K may be interpreted as the number of random projections for each row of B. We
use the OPU to compute this random matrix multiplication. An interesting observation is that since
in Algorithm 1 we recover the result of multiplications by a complex matrix with independent real
and imaginary parts  we can halve the number of projections when using the OPU with respect to
the original algorithm. By treating each row of B as an input frame  we can obtain Y ∈ CK×M
via Algorithm 1 when |Y |2 = |ABT|2 with A as deﬁned in Problem 1 with K rows. Then  we can
construct P = [Re(Y ∗)
Im(Y ∗)] ∈ RM×2K which would be equivalent to computing BΩ for
real Ω. Section B in the supplementary material describes this in more detail.

8

2468101214Number of anchors24681012Average relative error (%)MDSMDS-GD2468101214Number of anchors0102030405060Average relative error (%)MDSMDS-GD2468101214Number of anchors20304050Average relative error (%)MDSMDS-GD2468101214Number of anchors5.05.56.06.57.0Average good bitsMDSMDS-GDMeasured2468101214Number of anchors4.04.55.05.56.0Average good bitsMDSMDS-GDMeasured2468101214Number of anchors30.032.535.037.540.042.545.0SNR (dB)Single pointGroupFigure 4 shows the results when the OPU is used to perform the random matrix multiplication of the
RSVD algorithm on a matrix B. Figure 4 (left) reports experiments with a random binary matrix
B ∈ R10×104  different numbers of random projections (number of rows in A)  and ten trials per
number of projections. We plot the average error per entry when reconstructing B from its RSVD
matrices and singular values. Next  we take 500 28 × 28 samples from the MNIST dataset [13] 
threshold them to be binary  vectorize them  and stack them into a matrix B ∈ R500×282. Figure
4 (right) shows the seven leading right singular vectors reshaped to 28 × 28. The top row shows
the singular vectors that are obtained when using the OPU with 500 projections and the bottom row
shows the result when using Python. The error is negligible.

Figure 4: Left: Average RSVD error over 10 trials with varying number of projections on hardware
with an input matrix of size 10 × 1000; Right: Reshaped leading right singular vectors of an MNIST
matrix of size 500 × 282. The top rows shows the leading right singular vectors after performing
RSVD with the OPU and using our algorithm. The bottom row shows the leading right singular
vectors from Python. The relative error is below each singular vector.

4 Conclusion

Traditional computation methods are often too slow for processing tasks which involve large data
streams. This motivates alternatives which instead use fast physics to “compute” the desired functions.
In this work  we looked at using optics and multiple scattering media to obtain linear random
projections. A common difﬁculty with optical systems is that off-the-shelf camera sensors only
register the intensity of the scattered light. Our results show that there is nevertheless no need to
reach for more complicated and more expensive coherent setups. We showed that measurement
phase retrieval can be cast as a problem in distance geometry  and that the unknown phase of random
projections can be recovered even without knowing the transmission matrix of the medium.
Simulations and experiments on real hardware show that the OPU setup combined with our algo-
rithm indeed approximates an end-to-end linear system. What is more  we also improve intensity
measurements. The fact that we get full complex measurements allows us to implement a whole new
spectrum of randomized algorithms; we demonstrated the potential by the randomized singular value
decomposition. These beneﬁts come at the expense of a reduction in data throughput. Future work
will have to precisely quantify the smallest achievable data rate reduction due to allocating a part of
the duty cycle for reference measurements  though we note that the optical processing data rates are
very high to begin with.

Acknowledgement

Sidharth Gupta and Ivan Dokmani´c would like to acknowledge support from the National Science
Foundation under Grant CIF-1817577.

9

246810Number of projections101610131010107104Average error per entry3.79e-134.96e-128.36e-132.90e-123.97e-121.72e-122.67e-12Leading right singular vectorsOPUPythonRelative errorReferences
[1] David A Barmherzig  Ju Sun  Emmanuel J Candes  TJ Lane  and Po-Nan Li. Holographic phase

retrieval and optimal reference design. arXiv preprint arXiv:1901.06453  2019.

[2] Amir Beck  Petre Stoica  and Jian Li. Exact and approximate solutions of source localization

problems. IEEE Transactions on Signal Processing  56(5):1770–1778  2008.

[3] Robert Beinert. One-dimensional phase retrieval with additional interference intensity measure-

ments. Results in Mathematics  72(1-2):1–24  2017.

[4] Emmanuel J Candes  Xiaodong Li  and Mahdi Soltanolkotabi. Phase retrieval via wirtinger
ﬂow: Theory and algorithms. IEEE Transactions on Information Theory  61(4):1985–2007 
2015.

[5] Ivan Dokmanic  Reza Parhizkar  Juri Ranieri  and Martin Vetterli. Euclidean distance matrices:
essential theory  algorithms  and applications. IEEE Signal Processing Magazine  32(6):12–30 
2015.

[6] Angélique Drémeau  Antoine Liutkus  David Martina  Ori Katz  Christophe Schülke  Florent
Krzakala  Sylvain Gigan  and Laurent Daudet. Reference-less measurement of the transmission
matrix of a highly scattering material using a dmd and phase retrieval techniques. Optics express 
23(9):11898–11911  2015.

[7] James R Fienup. Phase retrieval algorithms: a comparison. Applied optics  21(15):2758–2769 

1982.

[8] Nathan Halko  Per-Gunnar Martinsson  and Joel A Tropp. Finding structure with randomness:
Probabilistic algorithms for constructing approximate matrix decompositions. SIAM review 
53(2):217–288  2011.

[9] Ryoichi Horisaki  Ryosuke Takagi  and Jun Tanida. Learning-based imaging through scattering

media. Optics express  24(13):13738–13743  2016.

[10] Kishore Jaganathan  Yonina C Eldar  and Babak Hassibi. Phase retrieval: An overview of recent

developments. arXiv preprint arXiv:1510.07713  2015.

[11] Wooshik Kim and Monson H Hayes. Phase retrieval using two fourier-transform intensities.

JOSA A  7(3):441–449  1990.

[12] Quoc Le  Tamás Sarlós  and Alex Smola. Fastfood-approximating kernel expansions in loglinear

time. In Proceedings of the international conference on machine learning  volume 85  2013.

[13] Yann LeCun  Léon Bottou  Yoshua Bengio  Patrick Haffner  et al. Gradient-based learning

applied to document recognition. Proceedings of the IEEE  86(11):2278–2324  1998.

[14] Antoine Liutkus  David Martina  Sébastien Popoff  Gilles Chardon  Ori Katz  Geoffroy Lerosey 
Sylvain Gigan  Laurent Daudet  and Igor Carron. Imaging with nature: Compressive imaging
using a multiply scattering medium. Scientiﬁc reports  4:5552  2014.

[15] Praneeth Netrapalli  Prateek Jain  and Sujay Sanghavi. Phase retrieval using alternating mini-

mization. In Advances in Neural Information Processing Systems  pages 2796–2804  2013.

[16] Ali Rahimi and Benjamin Recht. Random features for large-scale kernel machines. In Advances

in Neural Information Processing Systems  pages 1177–1184  2008.

[17] Alaa Saade  Francesco Caltagirone  Igor Carron  Laurent Daudet  Angélique Drémeau  Sylvain
Gigan  and Florent Krzakala. Random projections through multiple optical scattering: Approx-
imating kernels at the speed of light. In 2016 IEEE International Conference on Acoustics 
Speech and Signal Processing (ICASSP)  pages 6215–6219. IEEE  2016.

[18] Guy Satat  Matthew Tancik  Otkrist Gupta  Barmak Heshmat  and Ramesh Raskar. Object
classiﬁcation through scattering media with deep learning on time resolved measurement. Optics
express  25(15):17466–17479  2017.

10

[19] Peter Hans Schoenemann. A solution of the orthogonal Procrustes problem with applications to
orthogonal and oblique rotation. PhD thesis  University of Illinois at Urbana-Champaign  1964.

[20] Manoj Sharma  Christopher A Metzler  Sudarshan Nagesh  Oliver Cossairt  Richard G Baraniuk 
and Ashok Veeraraghavan. Inverse scattering via transmission matrices: Broadband illumination
and fast phase retrieval algorithms. IEEE Transactions on Computational Imaging  2019.

[21] Yoav Shechtman  Yonina C Eldar  Oren Cohen  Henry Nicholas Chapman  Jianwei Miao  and
Mordechai Segev. Phase retrieval with application to optical imaging: a contemporary overview.
IEEE signal processing magazine  32(3):87–109  2015.

[22] Petre Stoica and Jian Li. Lecture notes-source localization from range-difference measurements.

IEEE Signal Processing Magazine  23(6):63–66  2006.

[23] Warren S Torgerson. Multidimensional scaling: I. theory and method. Psychometrika  17(4):401–

419  1952.

[24] Joel A Tropp  Alp Yurtsever  Madeleine Udell  and Volkan Cevher. Practical sketching algo-
rithms for low-rank matrix approximation. SIAM Journal on Matrix Analysis and Applications 
38(4):1454–1485  2017.

[25] Yun Yang  Mert Pilanci  Martin J Wainwright  et al. Randomized sketches for kernels: Fast and

optimal nonparametric regression. The Annals of Statistics  45(3):991–1023  2017.

[26] Felix Xinnan X Yu  Ananda Theertha Suresh  Krzysztof M Choromanski  Daniel N Holtmann-
Rice  and Sanjiv Kumar. Orthogonal random features. In Advances in Neural Information
Processing Systems  pages 1975–1983  2016.

[27] Alp Yurtsever  Madeleine Udell  Joel A Tropp  and Volkan Cevher. Sketchy decisions: Convex

low-rank matrix optimization with optimal storage. arXiv preprint arXiv:1702.06838  2017.

[28] Huan Zhang  Yulong Liu  and Hong Lei. Localization from incomplete euclidean distance ma-
trix: Performance analysis for the svd-mds approach. IEEE Transactions on Signal Processing 
2019.

11

,Sidharth Gupta
Remi Gribonval
Laurent Daudet
Ivan Dokmanić