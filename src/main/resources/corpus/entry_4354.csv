2010,Practical Large-Scale Optimization for Max-norm Regularization,The max-norm was proposed as a convex matrix regularizer by Srebro et al (2004) and was shown to be empirically superior to the trace-norm for collaborative filtering problems. Although the max-norm can be computed in polynomial time  there are currently no practical algorithms for solving large-scale optimization problems that incorporate the max-norm. The present work uses a factorization technique of Burer and Monteiro (2003) to devise scalable first-order algorithms for convex programs involving the max-norm. These algorithms are applied to solve huge collaborative filtering  graph cut  and clustering problems. Empirically  the new methods outperform mature techniques from all three areas.,Practical Large-Scale Optimization

for Max-Norm Regularization

Institute of Computational and Mathematical Engineering

Jason Lee

Stanford University

email: jl115@yahoo.com

Benjamin Recht

Department of Computer Sciences
University of Wisconsin-Madison
email: brecht@cs.wisc.edu

Ruslan Salakhutdinov

Brain and Cognitive Sciences and CSAIL

Massachusetts Institute of Technology

email: rsalakhu@mit.edu

Nathan Srebro

Toyota Technological Institute at Chicago

email: nati@ttic.edu

Joel A. Tropp

Computing and Mathematical Sciences

California Institute of Technology

email: jtropp@acm.caltech.edu

Abstract

The max-norm was proposed as a convex matrix regularizer in [1] and was shown
to be empirically superior to the trace-norm for collaborative ﬁltering problems.
Although the max-norm can be computed in polynomial time  there are currently
no practical algorithms for solving large-scale optimization problems that incor-
porate the max-norm. The present work uses a factorization technique of Burer
and Monteiro [2] to devise scalable ﬁrst-order algorithms for convex programs
involving the max-norm. These algorithms are applied to solve huge collabora-
tive ﬁltering  graph cut  and clustering problems. Empirically  the new methods
outperform mature techniques from all three areas.

Introduction

1
A foundational concept in modern machine learning is to construct models for data by balancing
the complexity of the model against ﬁdelity to the measurements. In a wide variety of applications 
such as collaborative ﬁltering  multi-task learning  multi-class learning and clustering of multivariate
observations  matrices offer a natural way to tabulate data. For such matrix models  the matrix rank
provides an intellectually appealing way to describe complexity. The intuition behind this approach
holds that many types of data arise from a noisy superposition of a small number of simple (i.e. 
rank-one) factors.
Unfortunately  optimization problems involving rank constraints are computationally intractable ex-
cept in a few basic cases. To address this challenge  researchers have searched for alternative com-
plexity measures that can also promote low-rank models. A particular example of a low-rank reg-
ularizer that has received a huge amount of recent attention is the trace-norm  equal to the sum of
the matrix’s singular values (See the comprehensive survey [3] and its bibliography). The trace-
norm promotes low-rank decompositions because it minimizes the (cid:96)1 norm of the vector of singular
values  which encourages many zero singular values.
Although the trace-norm is a very successful regularizer in many applications  it does not seem to be
widely known or appreciated that there are many other interesting norms that promote low rank. The

1

paper [4] is one of the few articles in the machine learning literature that pursues this idea with any
vigor. The current work focuses on another rank-promoting regularizer  sometimes called the max-
norm  that has been proposed as an alternative to the rank for collaborative ﬁltering problems [1  5].
The max-norm can be deﬁned via matrix factorizations:

(cid:110)(cid:107)U(cid:107)2 ∞ (cid:107)V (cid:107)2 ∞ : X = U V (cid:48)(cid:111)

(cid:107)X(cid:107)max := inf

(1)

where (cid:107)·(cid:107)2 ∞ denotes the maximum (cid:96)2 row norm of a matrix:
(cid:17)1/2

(cid:16)(cid:88)

(cid:107)A(cid:107)2 ∞ := maxj

A2
jk

k

.

For general matrices  the computation of the max-norm can be rephrased as a semideﬁnite pro-
gram; see (4) below. When X is positive semideﬁnite  we may force U = V and then verify that
(cid:107)X(cid:107)max = maxj xjj  which should explain the terminology.
The fundamental result in the metric theory of tensor products  due to Grothendieck  states that the
max-norm is comparable with a nuclear norm (see Chapter 10 of [6]):

The factor of equivalence 1.676 ≤ κG ≤ 1.783 is called Grothendieck’s constant. The trace-norm 
on the other hand  is equal to

(cid:110)(cid:107)σ(cid:107)1 : X =(cid:88)
(cid:110)(cid:107)σ(cid:107)1 : X =(cid:88)

j

(cid:111)
j where (cid:107)uj(cid:107)∞ = 1 and (cid:107)vj(cid:107)∞ = 1
(cid:111)
j where (cid:107)uj(cid:107)2 = 1 and (cid:107)vj(cid:107)2 = 1

.

.

σjujv(cid:48)

σjujv(cid:48)

j

(cid:107)X(cid:107)max ≈ inf

(cid:107)X(cid:107)tr := inf

This perspective reveals that the max-norm promotes low-rank decompositions with factors in (cid:96)∞ 
rather than the (cid:96)2 factors produced by the trace-norm! Heuristically  we expect max-norm regular-
ization to be effective for uniformly bounded data  such as preferences.
The literature already contains theoretical and empirical evidence that the max-norm is superior to
the trace-norm for certain types of problems. Indeed  the max-norm offers better generalization
error bounds for collaborative ﬁltering [5]  and it outperforms the trace-norm in small-scale experi-
ments [1]. The paper [7] provides further evidence that the max-norm serves better for collaborative
ﬁltering with nonuniform sampling patterns.
We believe that the max-norm has not achieved the same prominence as the trace-norm because of an
apprehension that it is challenging to solve optimization problems involving a max-norm regularizer.
The goal of this paper is to refute this misconception.
We provide several algorithms that are effective for very large scale problems  and we demonstrate
the power of the max-norm regularizer using examples from a variety of applications. In particular 
we study convex programs of the form

min f(X) + µ(cid:107)X(cid:107)max

(2)

where f is a smooth function and µ is a positive penalty parameter. Section 4 outlines a proximal-
point method  based on the work of Fukushima and Mine [8]  for approaching (2). We also study
the bound-constrained problem

min f(X)

subject to

(cid:107)X(cid:107)max ≤ B.

(3)

Of course  (2) and (3) are equivalent for appropriate choices of µ and B  but we describe scenarios
where there may be a preference for one versus the other. Section 3 provides a projected gradient
method for (3)  and Section 5 develops a stochastic implementation that is appropriate for decom-
posable loss functions. These methods can be coded up in a few lines of numerical python or Matlab 
and they scale to huge instances  even on a standard desktop machine. In Section 6  we apply these
new algorithms to large-scale collaborative ﬁltering problems  and we demonstrate performance su-
perior to methods based on the trace-norm. We apply the algorithms to solve enormous instances
of graph cut problems  and we establish that clustering based on these cuts outperforms spectral
clustering on several data sets.

2

2 The SDP and Factorization Approaches
The max-norm of an m × n matrix X can be expressed as the solution to a semideﬁnite program:

(cid:21)

(cid:20)W1 X

X(cid:48) W2

(cid:107)X(cid:107)max = min t

subject to

(cid:23) 0 

diag(W1) ≤ t 

diag(W2) ≤ t.

(4)

Unfortunately  standard interior-point methods for this problem do not scale to matrices with more
than a few hundred rows or columns. For large-scale problems  we use an alternative formulation
suggested by (1) that explicitly works with a factorization of the decision variable X.
We employ an idea of Burer and Monteiro [2] that has far reaching consequences. The positive
deﬁnite constraint in the SDP formulation above is trivially satisﬁed if we deﬁne L and R via

(cid:21)

(cid:20)W1 X

X(cid:48) W2

=

(cid:20)L

(cid:21)(cid:20)L

(cid:21)(cid:48)

R

R

.

Burer and Monteiro showed that as long as L and R have sufﬁciently many columns  then the global
optimum of (4) is equal to that of
(cid:107)X(cid:107)max =

2 ∞  (cid:107)R(cid:107)2

max{(cid:107)L(cid:107)2

2 ∞} .

min

(5)

(L R) : LR(cid:48)=X

In particular  we may assume that the number of columns is less than m+ n. This formulation of the
max-norm is nonconvex because it involves a constraint on the product LR(cid:48)  but Burer and Mon-
teiro proved that each local minimum of the reformulated problem is also a global optimum [9]. If
we select L and R to have a very small number of columns  say r  then the number of real decision
variables in the optimization problems (2) and (3) is reduced from mn to r(m + n)  a dramatic
improvement in the dimensionality of the problem. On the other hand  the new formulation is non-
convex with respect to L and R so it might not be efﬁciently solvable. In what follows  we present
fast  ﬁrst-order methods for solving (2) and (3) via this low-dimensional factored representation.
3 Projected Gradient Method
The constrained formulation (3) admits a simple projected gradient algorithm. We replace X with
the product LR(cid:48) and use the factored form of the max-norm (5) to obtain
2 ∞  (cid:107)R(cid:107)2
(cid:21)(cid:19)

The projected gradient descent method ﬁxes a step size τ and computes updates with the rule

(cid:18)(cid:20) L − τ∇f(LR)R

minimize(L R)f(LR(cid:48))

subject to max{(cid:107)L(cid:107)2

2 ∞} ≤ B.

(cid:20)L

(cid:21)

(6)

← PB

R

R − τ∇f(LR)(cid:48)L

√

√

2 ∞  (cid:107)R(cid:107)2

B so their norms equal

B. Rows with norms less than

where PB denotes the Euclidean projection onto the set {(L  R) : max((cid:107)L(cid:107)2
2 ∞) ≤ B}.
√
This projection can be computed by re-scaling the rows of the current iterate whose norms exceed
B are unchanged by the projection. The
projected gradient algorithm is elegant and simple  and it has an online implementation  described
below. Moreover  using an Armijo line search rule to guarantee sufﬁcient decrease of the cost
function  we can guarantee convergence to a stationary point of (3); see [10  Sec. 2.3].
4 Proximal Point Method for Penalty Formulation
Solving (2) is slightly more complicated than its constrained counterpart. We employ a classical
proximal point method  proposed by Fukushima and Mine [8]  which forms the algorithmic foun-
dation of many popular ﬁrst-order methods of for (cid:96)1-norm minimization [11  12] and trace-norm
minimization [13  14]. The key idea is that our cost function is the sum of a smooth term plus a
convex term. At each iteration  we replace the smooth term by a linear approximation. The new
cost function can then be minimized in closed form. Before describing the proximal point algorithm
in detail  we ﬁrst discuss how a simple max-norm problem (the Frobenius norm plus a max-norm
penalty) admits an explicit formula for its unique optimal solution.
Consider the simple regularization problem

minimizeW (cid:107)W − V (cid:107)2

F + β (cid:107)W(cid:107)2

2 ∞

(7)

3

Algorithm 1 Compute W = squash(V   β)
Require: A d × D matrix V   a positive scalar β.
Ensure: A d × D matrix W ∈ arg minZ
1: for k = 1 to d set nk ← (cid:107)vk(cid:107)2
2: sort {nk} in descending order. Let π denote the sorting permutation such that nπ(j) is the jth

F + β (cid:107)Z(cid:107)2

(cid:107)Z − V (cid:107)2

2 ∞.

3: for k = 1 to d set sk ←(cid:80)k

largest element in the sequence.
i=1 nπ(i).
k+β}

4: q ← max{k : nπ(k) ≥ sk
5: η ← sq
6: for k = 1 to d  if k ≤ q  set wπ(k) ← ηvπ(k)/(cid:107)vπ(k)(cid:107)2. otherwise set wπ(k) ← vπ(k)

q+β

where W and V are d × D matrices. Just as with (cid:96)1-norm and trace-norm regularization  this
problem can be solved in closed form. An efﬁcient algorithm to solve (7) is given by Algorithm 1.
We call this procedure squash because the rows of V with large norm have their magnitude clipped
at a critical value η = η(V   β).

Proposition 4.1 squash(V   β) is an optimal solution of (7)

The proof of this proposition follows from an analysis of the KKT conditions for the regularized
problem. We include a full derivation in the appendix. Note that squash can be computed in
O(d max{log(d)  D}) ﬂops. Computing the row norms requires O(dD) ﬂops  and then the sort
requires O(d log d) ﬂops. Computing η and q require O(d) operations. Constructing W then re-
quires O(dD) operations.
With the squash function in hand  we can now describe our proximal-point algorithm. Replace
the decision variable X in (2) with LR(cid:48). With this substitution and the factored form of the max-
norm  (5)  Problem (2) reduces to

minimize(L R)f(LR(cid:48)) + µ max{(cid:107)L(cid:107)2

(8)

2 ∞  (cid:107)R(cid:107)2

2 ∞} .

(cid:21)
.
2 ∞}. Also let ˜f(A) denote f(LR(cid:48)) 

(cid:20) L

R

For ease of notation  deﬁne A to be the matrix of factors stacked on top of one another A =
With this notation  we have (cid:107)A(cid:107)2
and ϕ(A) := ˜f(A) + µ(cid:107)A(cid:107)2
2 ∞ .
Using the squash algorithm  we can solve

2 ∞ = max{(cid:107)L(cid:107)2

2 ∞  (cid:107)R(cid:107)2

minimize(cid:104)∇ ˜f(Ak)  A(cid:105) + τ−1

k (cid:107)A − Ak(cid:107)2

F + µ(cid:107)A(cid:107)2

2 ∞

(9)

in closed form. To see this  complete the square and multiply by τk. Then (9) is equivalent to (7)
with the identiﬁcations W = A  V = Ak − τk∇ ˜f(Ak)  β = τkµ. That is  the optimal solution
of (9) is squash

Ak − τk∇ ˜f(Ak)  τkµ

.

(cid:16)

(cid:17)

We can now directly apply the proximal-point algorithm of Fukushima and Mine  detailed in Algo-
rithm 2. Step 2 is the standard linearized proximal-point method that is prevalent in convex algo-
rithms like Mirror Descent and Nesterov’s optimal method. The cost function ˜f is replaced with a
quadratic approximation localized at the previous iterate Ak  and the resulting approximation (9)
can be solved in closed form. Step 3 is a backtracking line search that looks for a step that obeys
an Armijo step rule. This linesearch guarantees that the algorithm produces a sufﬁciently large de-
crease of the cost function at each iteration  but it may require several function evaluations to ﬁnd l.
This algorithm is guaranteed to converge to a critical point of (8) as long as the step sizes are chosen
commensurate with the norm of the Hessian [8]. In particular  Nesterov has recently shown that if ˜f
has a Lipschitz-continuous gradient with Lipschitz constant L  then the algorithm will converge at a
rate of 1/k where k is the iteration counter [15].

4

An initial point A0 = (L0  R0) and a counter k set to 0.

Algorithm 2 A proximal-point method for max-norm regularization
Require: Algorithm parameters α > 0  1 > γ > 0  tol > 0. A sequence of positive numbers {τk}.
Ensure: A critical point of (8).
1: repeat
2:
3:

Solve (9) to ﬁnd ˆAk. That is  ˆAk ← squash
Compute the smallest nonnegative integer l such that

Ak − τk∇ ˜f(Ak)  τkµ

(cid:16)

(cid:17)

.

ϕ(Ak + γl( ˆAk − Ak)) ≤ ϕ(Ak) − αγl(cid:107)Ak − ˆAk(cid:107)2
F .

set Ak+1 ← (1 − γl)Ak + γl ˆAk  k ← k + 1.

4:
5: until (cid:107)Ak− ˆAk(cid:107)2
(cid:107)Ak(cid:107)2

F

F

< tol

5 Stochastic Gradient

For many problems  including matrix completion and max-cut problems  the cost function decom-
poses over the individual entries in the matrix  so the function f(LR(cid:48)) takes the particularly simple
form:

(cid:96)(Yij  L(cid:48)

iRj)

(10)

f(L  R) = (cid:88)

i j∈S

where (cid:96) is some ﬁxed loss function  S is a set of row-column indices  Yij are some real numbers 
and Li and Rj denote the ith row of L and jth row of R respectively. When dealing with very
large datasets  S may consist of hundreds of millions of pairs  and there are algorithmic advantages
to utilizing stochastic gradient methods that only query a very small subset of S at each iteration.
Indeed  the above decomposition for f immediately suggests a stochastic gradient method: pick one
training pair (i  j) at random at each iteration  take a step in the direction opposite the gradient of
iRj) and then either apply the projection PB described in Section 3 or the squash function
(cid:96)(Yi j  L(cid:48)
described in 4.
The projection PB is particularly easy to compute in the stochastic setting. Namely  if (cid:107)Li(cid:107)2 > B 
we project it back so that (cid:107)Li(cid:107) =
B  otherwise we do not do anything (and similarly for Rj). We
need not look at any other rows of L and R. As we demonstrate in experimental results section  this
simple algorithm is computationally as efﬁcient as optimization with the trace-norm.
We can also implement an efﬁcient algorithm for stochastic gradient descent for problem (2). If we
wanted to apply the squash algorithm to such a stochastic gradient step  only the norms correspond-
ing to Li and Rj would be modiﬁed. Hence  in Algorithm 1  if the set of row norms of L and R
is sorted from the previous iteration  we can implement a balanced-tree data structure that allows us
to perform individual updates in amortized logarithmic time. We leave such an implementation to
future work. In the experiments  however  we demonstrate that the proximal point method is still
quite efﬁcient and fast when dealing with stochastic gradient updates corresponding to medium-size
batches {(i  j)} selected from S  even if a full sort is performed at each squash operation.

√

6 Numerical Experiments

Matrix Completion. We tested our proximal point and projected gradient methods on the Net-
ﬂix dataset  which is the largest publicly available collaborative ﬁltering dataset. The training set
contains 100 480 507 ratings from 480 189 anonymous users on 17 770 movie titles. Netﬂix also
provides a qualiﬁcation set  containing 1 408 395 ratings. The “qualiﬁcation set” pairs were selected
by Netﬂix from the most recent ratings for a subset of the users. As a baseline  Netﬂix provided the
test score of its own system trained on the same data  which is 0.9514. This dataset is interesting for
several reasons. First  it is very large  and very sparse (98.8% sparse). Second  the dataset is very
imbalanced  with highly nonuniform samples. It includes users with over 10 000 ratings as well as
users who rated fewer than 5 movies.

5

Algorithm

Proximal Point
Projected Gradient
Trace-norm
Weighted Trace-norm

f (X)

0.7676
0.7728

-
-

Training RMSE
(cid:107)X(cid:107)max

f (X) +
+ µ (cid:107)X(cid:107)max

2.5549
2.2500

-
-

0.7689
0.7739

-
-

Qual
f (X)

0.9150
0.9138
0.9235
0.9105

Figure 1: Performance of regularization methods on the Netﬂix dataset.

For the netﬂix dataset  we will evaluate our algorithms based on the root mean squared error (RMSE)
of their predictions. To this end  the objective we seek to minimize takes the following form:

minimizeL R

1
|S|

(Yij − L(cid:48)

iRj)2 + µ max{(cid:107)L(cid:107)2

2 ∞  (cid:107)R(cid:107)2

2 ∞}

(cid:88)

(i j)∈S

where S here represents the set of observed user-movie pairs and Yij denote the provided ratings.
For all of our experiments  we learned a factorization L(cid:48)R with k = 30 dimensions (factors).
In our experiments  all ratings were normalized to be zero-mean by subtracting 3.6.
To
speed up learning  we subdivided the Netﬂix dataset into minibatches  each containing 100 000
user/movie/rating triplets. Both proximal-point and projected gradient methods performed 40
epochs (or passes through the training set)  with parameters {L  R} updated after each minibatch.
For both algorithms we used momentum of 0.9  and a step size of 0.005  which was decreased by
a factor of 0.8 after each epoch. For the proximal-point method  µ was set to 5×10−4  and for
the projected gradient algorithm  B was set to 2.25. The running times of both algorithms on this
large-scale Netﬂix dataset is comparable. On a 2.5 GHz Intel Xeon  our implementation of projected
gradient takes 20.1 minutes per epoch  whereas the proximal-point method takes about 19.6 minutes.
Figure 1 shows predictive performance of both the proximal-point and projected gradient algorithms
on the training and qualiﬁcation set. Observe that the proximal-point algorithm converges consider-
ably faster than projected gradient  but both algorithms achieve a similar RMSE of 0.9150 (proximal
point) and 0.9138 (projected gradient) on the qualiﬁcation set. Figure 1  left panel  further shows that
the max-norm based regularization signiﬁcantly outperforms the corresponding trace-norm based
regularization  which is widely used in many large-scale collaborative ﬁltering applications. We
also note that the differences between the max-norm and the weighted trace-norm [7] are rather
small  with the weighted trace-norm slightly outperforming max-norm.

Gset Max-Cut Experiments.
we aim to solve the problem

In the MAX-CUT problem  we are given a graph G = (V  E)  and

(1 − xixj) subject to x2

i = 1 ∀i ∈ V

(i j)∈E

minimize (cid:88)
minimize (cid:88)
minimize (cid:88)

(i j)∈E

(i j)∈E

The heralded Goemans-Williamson relaxation [16] converts this problem into a constrained  sym-
metric max-norm problem:

(1 − Xij) subject to (cid:107)X(cid:107)max ≤ 1  X (cid:23) 0 .

In our nonconvex formulation  this optimization becomes

(1 − A(cid:48)

iAj) subject to (cid:107)A(cid:107)2

2 ∞ ≤ 1 .

Since the decision variable is symmetric and positive deﬁnite  we only need one factor A of size
|V | × r. In all of our experiments with MAX-CUT type problems  we ﬁxed r = 20. We used a
diminishing step size rule of τk = τ0√

where k is the iteration counter.

k

6

05101520253035400.750.80.850.90.9511.051.11.15Number of epochs RMSE  TrainingQualificationProximal PointProjected GradientPrimal
Obj.

14128.5
8007.4
7998.3
20116.6
15207.0
7736.4
9851.51
7800.4
11034.1
15639.6

Time
(.1%)
0.6
0.5
0.5
2
2.1
21.4
8.7
13.8
18.6
28.4

Iterations

(.1%)
150
200
200
300
400
2050
1700
2250
2150
2200

Time
(1%)
0.4
0.3
0.3
.7
0.29
1.3
.5
.6
.9
1.35

Iterations

(1%)
100
100
100
100
50
100
100
100
100
100

SDPLR

Obj.

14135.7
8014.6
8005.9
20135.90
15221.9
7744.1
9861.2
7808.2
11045.1
15655.2

SDPLR
Time

3
4
7
29
6
15
21
15
20
33

G22
G35
G36
G58
G60
G67
G70
G72
G77
G81

|V |
2000
2000
2000
5000
7000
10000
10000
10000
14000
20000

|E|
19990
11778
11766
29570
17148
20000
9999
20000
28000
40000

Table 1: Performance of projected gradient on Gset graphs. Columns show primal objective within .1% of
optimal  running time for .1% of optimal  number of iterations to reach .1% of optimal  running time for 1% of
optimal  number of iterations to reach 1% of optimal  primal objective using SDPLR  running time of SDPLR 
number of vertices  and number of edges. In our experiments  we set τ0 = 1.

(a) Spectral Clustering

(b) Max-cut clustering

Figure 2: Comparison of spectral clustering (left) with MAX-CUT clustering (right).

We tested our projected gradient algorithm on graphs drawn from the Gset  a collection of graphs
designed for testing the efﬁcacy of max-cut algorithms [17]. The results for a subset of these appears
in Table 1 along with a comparison against a C implementation of Burer’s SDPLR code which has
been optimized for the particular structure of the MAX-CUT problem [18]. On the same modern
hardware  a Matlab implementation of our projected gradient method can reach .1% of the optimal
value faster than the optimized and compiled SDPLR code.

(cid:16)−||xi−xj||2

(cid:17)

2σ2
i

2-class Clustering Experiments. For the 2-class clustering problem  we ﬁrst build a K-nearest
neighbor graph with K = 10 and weights wij deﬁned as wij = max(si(j)  sj(i))  with si(j) =
exp
and σi equal to the distance from xi to its Kth closest neighbor. We then choose
a scalar δ > 0 and deﬁne an inverse similarity adjacency matrix Q by Qij = δ−Wij. The parameter
δ controls the balancing of the clusters  a large value of δ forces the clusters to be of equal size. We
solve the MAX-CUT problem on the graph Q to ﬁnd our cluster assignments.
As a synthetic example  we generated a “two moons” dataset consisting of two half-circles in R2
with the bottom half circle shifted to the right by 1/2 and shifted up by 1/2. The data is then
embedded into RD and each embedded component is corrupted with Gaussian noise with variance
.02 as done in [19]. The
σ2. For the two moons experiments  we ﬁx D = 100  n = 2000 and σ =
parameters are set to δ = .01 and τ0 = 3/2; the algorithm was executed for 1500 iterations. For
the clustering experiments  we repeat the randomized rounding technique [16] for 100 trials  and we
choose the rounding with highest primal objective.
We compare our MAX-CUT clusterings with the spectral clustering method [20] and the Total Vari-
ation Graph Cut algorithm [19]. Figure 2 shows the clustering results for spectral clustering and
maxcut clustering. In all the trials  spectral clustering incorrectly clustered the two ends of both
half-circles. For the clustering problems  the two measures of performance we consider are mis-
classiﬁcation error rate (number of misclassiﬁed points divided by n) and cut cost. The cut cost is
i∈V1 j∈V2 Wij. The MAX-CUT clustering obtained smaller misclassiﬁcation error in 98

deﬁned as(cid:80)

of the 100 trials we performed and smaller cut cost in every trial.
On the MNIST database  we build the 10-NN graph described above on the digits 4 and 9  where
we set δ = .001 and r = 8. The NN-graph is of size 14  000 and the MAX-CUT algorithm takes

√

7

Two Moons
MNIST 4 and 9
MNIST 3 and 5

Error Rate

0.053
0.021
0.016

max-cut

Cost
311.9
1025.5
830.9

Time
13
90
53

min(|V1| |V2|)

|V1|+|V2|

.495
.493
.476

spectral

Error Rate

0.171
0.458
0.092

Cost
387.8
1486.5
2555.1

TV

Error Rate

0.082
N/A
N/A

Table 2: Clustering results. Error rate  cut cost  and running time comparison for MAX-CUT  spectral  and
total variation (TV) algorithms. The balance of the cut is computed as min(|V1| |V2|)
. The two moons results
|V1|+|V2|
are averaged over 100 trials.

approximately 1 minute to run 1 000 iterations. The same procedure is repeated for the digits 3 and
5. The results are shown in Table 2. Our MAX-CUT clustering algorithm again performs substantially
better than the spectral method.
7 Summary
In this paper we presented practical methods for solving very large scale optimization problems
involving a max-norm constraint or regularizer. Using this approaches  we showed evidence that
the max-norm can often be superior to established techniques such as trace-norm regularization and
spectral clustering  supplementing previous evidence on small-scale problems. We hope that the
increasing evidence of the utility of max-norm regularization  combined with the practical optimiza-
tion techniques we present here  will reignite interest in using the max-norm for various machine
learning applications.

Acknowledgements
RS supported by NSERC  Shell  and NTT Communication Sciences Laboratory. JAT supported by
ONR award N00014-08-1-0883  DARPA award N66001-08-1-2065  and AFOSR award FA9550-
09-1-0643. JL thanks TTI Chicago for hosting him while this work was completed.

A Proof of the correctness of squash

Rewrite (7) as the constrained optimization

minimizeW  t
subject to

Pd
i=1 (cid:107)wi − vi(cid:107)2 + βt

(cid:107)wi(cid:107)2 ≤ t

for 1 ≤ i ≤ d

Forming a Lagrangian with a vector of Lagrange multipliers p ≥ 0

L(W   t  p) =

(cid:107)wi − vi(cid:107)2 + βt +

dX

i=1

dX
vi  (b) p ≥ 0  (c)Pd

pi((cid:107)wi(cid:107)2 − t)  

i=1

the KKT conditions for this problem thus read (a) wi = 1
for 1 ≤ i ≤ d  (e) pi > 0 =⇒ (cid:107)wi(cid:107)2 = t  and (f) (cid:107)wi(cid:107)2 < t =⇒ pi = 0.
With our candidate W = squash(V   β)  we need only ﬁnd t and p to verify the optimality conditions. Let π
be as in Algorithm 1 and set t = η2 and

1+pi

i=1 pi = β  (d) (cid:107)wi(cid:107)2 ≤ t

( (cid:107)vk(cid:107)
η − 1 1 ≤ π(k) ≤ q

otherwise

pk =

0

This deﬁnition of p immediately gives (a). For (b)  note that by the deﬁnition of q  (cid:107)vk(cid:107) ≥ η for 1 ≤ π(k) ≤ q.
Thus  p ≥ 0. Moreover 

P
1≤π(k)≤q (cid:107)vk(cid:107)

pk =

η

dX

k=1

− q = q + β − q = β  

yielding (c). Also  by construction  (cid:107)wk(cid:107) = η if π(k) ≤ q verifying (e). Finally  again by the deﬁnition of q 
we have

(cid:107)vπ(q+1)(cid:107) <

1

β + q + 1

(cid:107)vπ(k)(cid:107) =

1

(cid:107)vπ(q+1)(cid:107) +

β + q + 1

β + q

β + q + 1

η

which implies (cid:107)vπ(q+1)(cid:107) < η. Since (cid:107)vk(cid:107) ≤ (cid:107)vπ(q+1)(cid:107) for π(k) > q  this gives (d) and the slackness
condition (f).

q+1X

k=1

8

References
[1] Nathan Srebro  Jason Rennie  and Tommi Jaakkola. Maximum margin matrix factorization. In Advances

in Neural Information Processing Systems  2004.

[2] Samuel Burer and R. D. C. Monteiro. A nonlinear programming algorithm for solving semideﬁnite

programs via low-rank factorization. Mathematical Programming (Series B)  95:329–357  2003.

[3] Benjamin Recht  Maryam Fazel  and Pablo Parrilo. Guaranteed minimum rank solutions of matrix
SIAM Review  2007. To appear. Preprint Available at

equations via nuclear norm minimization.
http://pages.cs.wisc.edu/˜brecht/publications.html.

[4] Francis R. Bach  Julien Marial  and Jean Ponce. Convex sparse matrix factorizations. Preprint available

at arxiv.org/abs/0812.1869  2008.

[5] Nathan Srebro and Adi Shraibman. Rank  trace-norm and max-norm.

Learning Theory (COLT)  2005.

In 18th Annual Conference on

[6] G. J. O. Jameson. Summing and Nuclear Norms in Banach Space Theory. Number 8 in London Mathe-

matical Society Student Texts. Cambridge University Press  Cambridge  UK  1987.

[7] Ruslan Salakhutdinov and Nathan Srebro. Collaborative ﬁltering in a non-uniform world: Learning with

the weighted trace norm. Preprint available at arxiv.org/abs/1002.2780  2010.

[8] Masao Fukushima and Hisashi Mine. A generalized proximal point algorithm for certain non-convex

minimization problems. International Journal of Systems Science  12(8):989–1000  1981.

[9] Samuel Burer and Changhui Choi. Computational enhancements in low-rank semideﬁnite programming.

Optimization Methods and Software  21(3):493–512  2006.

[10] Dimitri P. Bertsekas. Nonlinear Programming. Athena Scientiﬁc  Belmont  MA  2nd edition  1999.
[11] T Hale  W Yin  and Y Zhang. A ﬁxed-point continuation method for l 1-regularized minimization with
applications to compressed sensing. Dept. Computat. Appl. Math.  Rice Univ.  Houston  TX  Tech. Rep.
TR07-07  2007.

[12] Stephen J. Wright  Robert Nowak  and M´ario A. T. Figueiredo. Sparse reconstruction by separable ap-
proximation. Journal version  to appear in IEEE Transactions on Signal Processing. Preprint available at
http:http://www.optimization-online.org/DB_HTML/2007/10/1813.html  2007.
[13] Jian-Feng Cai  Emmanuel J. Cand`es  and Zuowei Shen. A singular value thresholding algorithm for
matrix completion. To appear in SIAM J. on Optimization. Preprint available at http://arxiv.org/
abs/0810.3286  2008.

[14] Shiqian Ma  Donald Goldfarb  and Lifeng Chen. Fixed point and Bregman iterative methods for matrix
rank minimization. Preprint available at http://www.optimization-online.org/DB_HTML/
2008/11/2151.html  2008.

[15] Yurii Nesterov. Gradient methods for minimizing composite objective function. To appear. Preprint
Available at http://www.optimization-online.org/DB_HTML/2007/09/1784.html 
September 2007.

[16] M. X. Goemans and D. P. Williamson. Improved approximation algorithms for maximum cut and satisﬁ-

ability problems using semideﬁnite programming. Journal of the ACM  42:1115–1145  1995.

[17] The Gset is available for download at http://www.stanford.edu/˜yyye/yyye/Gset/.
[18] Samuel Burer. Sdplr. Software available at http://dollar.biz.uiowa.edu/˜sburer/www/

doku.php?id=software#sdplr.

[19] Arthur Szlam and Xavier Bresson. A total variation-based graph clustering algorithm for cheeger
ratio cuts. To appear in ICML 2010. Preprint available at ftp://ftp.math.ucla.edu/pub/
camreport/cam09-68.pdf  2010.

[20] Jianbo Shi and Jitendra Malik. Normalized cuts and image segmentation. IEEE Transactions on Pattern

Analysis and Machine Intelligence  22(8):888–905  2000.

9

,Mohammad Irfan
Luis Ortiz
Nguyen Cuong
Huan Xu