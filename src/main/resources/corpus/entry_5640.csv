2018,Training Deep Models Faster with Robust  Approximate Importance Sampling,In theory  importance sampling speeds up stochastic gradient algorithms for supervised learning by prioritizing training examples. In practice  the cost of computing importances greatly limits the impact of importance sampling. We propose a robust  approximate importance sampling procedure (RAIS) for stochastic gradient de- scent. By approximating the ideal sampling distribution using robust optimization  RAIS provides much of the benefit of exact importance sampling with drastically reduced overhead. Empirically  we find RAIS-SGD and standard SGD follow similar learning curves  but RAIS moves faster through these paths  achieving speed-ups of at least 20% and sometimes much more.,Training Deep Models Faster with

Robust  Approximate Importance Sampling

Tyler B. Johnson

University of Washington  Seattle

tbjohns@washington.edu

Carlos Guestrin

University of Washington  Seattle
guestrin@cs.washington.edu

Abstract

In theory  importance sampling speeds up stochastic gradient algorithms for super-
vised learning by prioritizing training examples. In practice  the cost of computing
importances greatly limits the impact of importance sampling. We propose a robust 
approximate importance sampling procedure (RAIS) for stochastic gradient de-
scent. By approximating the ideal sampling distribution using robust optimization 
RAIS provides much of the beneﬁt of exact importance sampling with drastically
reduced overhead. Empirically  we ﬁnd RAIS-SGD and standard SGD follow
similar learning curves  but RAIS moves faster through these paths  achieving
speed-ups of at least 20% and sometimes much more.

1

Introduction

Deep learning models perform excellently on many tasks. Training such models is resource-intensive 
however  as stochastic gradient descent algorithms can require days or weeks to train effectively. After
a short period training  models usually perform well on some—or even most—training examples. As
training continues  frequently reconsidering such “easy” examples slows further improvement.
Importance sampling prioritizes training examples for SGD in a principled way. The technique
suggests sampling example i with probability proportional to the norm of loss term i’s gradient. This
distribution both prioritizes challenging examples and minimizes the stochastic gradient’s variance.
SGD with optimal importance sampling is impractical  however  since computing the sampling
distribution requires excessive time. [1] and [2] analyze importance sampling for SGD and convex
problems; practical versions of these algorithms sample proportional to ﬁxed constants. For deep
models  other algorithms attempt closer approximations of gradient norms [3  4  5]. But these
algorithms are not inherently robust. Without carefully chosen hyperparameters or additional forward
passes  these algorithms do not converge  let alone speed up training.
We propose RAIS  an importance sampling procedure for SGD with several appealing qualities. First 
RAIS determines each sampling distribution by solving a robust optimization problem. As a result 
each sampling distribution is minimax optimal with respect to an uncertainty set. Since RAIS trains
this uncertainty set in an adaptive manner  RAIS is not sensitive to hyperparameters.
In addition  RAIS maximizes the beneﬁt of importance sampling by adaptively increasing SGD’s
learning rate—an effective yet novel idea to our knowledge. This improvement invites the idea that
one RAIS-SGD iteration equates to more than one iteration of conventional SGD. Interestingly  when
plotted in terms of “epochs equivalent ” the learning curves of the algorithms align closely.
RAIS applies to any model that is trainable with SGD. RAIS also combines nicely with standard
“tricks ” including data augmentation  dropout  and batch normalization. We show this empirically in
§6. In this section  we also demonstrate that RAIS consistently improves training times. To provide
context for the paper  we include qualitative results from these experiments in Figure 1.

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

horse

bird

plane

ship

car

car

ship

horse

truck
(car)

deer
(cat)

dog
(cat)

bird
(plane)

cat
(dog)

truck
(ship)

car
(truck)

dog
(deer)

trout mower chimp

road

road

chair

sun-
key-
ﬂower board

shrew worm seal
(mouse) (snake)
(otter)

lion
(tiger)

baby
(girl)

shark spider
(whale)
(crab)

otter
(seal)

1

1

0

1

0

0

1

1

9 (0)

8 (4)

1 (7)

1 (2)

5 (7)

7 (2)

6 (9)

5 (6)

Figure 1: Nonpriority and priority training examples for image classiﬁcation. Left: Examples
that RAIS samples infrequently during training. Right: Examples that RAIS prioritizes. Bold denotes
the image’s label. Parentheses denote a different class that the model considers likely during training.
Datasets are CIFAR-10 (top)  CIFAR-100 (middle)  and rotated MNIST (bottom).

nPn

2 Problem formulation
Given loss functions f1  f2  . . .   fn and a tuning parameter  2 R0  our task is to efﬁciently solve
(P)

F (w)   where F (w) = 1

minimize

i=1 fi(w) + 

2 kwk2 .

w2Rd

A standard algorithm for solving (P) is stochastic gradient descent. Let w(t) denote the optimization
variables when iteration t begins. SGD updates these weights via
w(t+1) w(t)  ⌘(t)g(t) .

(1)
Above  ⌘(t) 2 R>0 is a learning rate  speciﬁed by a schedule: ⌘(t) = lr_sched (t). The vector g(t)
is an unbiased stochastic approximation of the gradient rF (w(t)). SGD computes g(t) by sampling
a minibatch of |M| indices from {1  2  . . .   n} uniformly at random (or approximately so). Denoting
this minibatch by M(t)  SGD deﬁnes the stochastic gradient as

g(t) = 1

|M|Pi2M(t) rfi(w(t)) + w(t) .

In this work  we assume an objective function  learning rate schedule  and minibatch size  and we
propose a modiﬁed algorithm called RAIS-SGD. RAIS prioritizes examples by sampling minibatches
non-uniformly  allowing us to train models using fewer iterations and less time.

(2)

(3)

3 SGD with oracle importance sampling

We now introduce an SGD algorithm with “oracle” importance sampling  which prioritizes examples
using exact knowledge of importance values. RAIS-SGD is an approximation of this algorithm.
Given w(t)  let us deﬁne the expected training progress attributable to iteration t as

E(t) = kw(t)  w?k2  Ehkw(t+1)  w?k2i

= 2⌘(t)hrF (w(t))  w(t)  w?i  [⌘(t)]2Ehkg(t)k2i .

Here w? denotes the solution to (P)  and the expectation is with respect to minibatch M(t). The
equality follows from plugging in (1) and applying the fact that g(t) is unbiased.
We refer to our oracle algorithm as O-SGD  and we refer to SGD with uniform sampling as U-SGD.
At a high level  O-SGD makes two changes to U-SGD in order to increase E(t). First  O-SGD
samples training examples non-uniformly in a way that minimizes the variance of the stochastic
gradient. This ﬁrst change is not new—see [1]  for example. Second  to compensate for the ﬁrst
improvement  O-SGD adaptively increases the learning rate. This second change  which is novel to
our knowledge  can be essential for obtaining large speed-ups.

2

3.1 Maximizing progress with oracle importance sampling
By sampling minibatches non-uniformly  O-SGD prioritizes training examples in order to decrease
E[kg(t)
i = 1.
O-SGD constructs minibatch M(t) by sampling independently |M| examples according to p(t).
Instead of (2)  the resulting stochastic gradient is

O k2]. During iteration t  O-SGD deﬁnes a discrete distribution p(t) 2 Rn

0  wherePi p(t)

g(t)
O = 1

|M|Pi2M(t)

1

i rfi(w(t)) + w(t) .
np(t)

(4)

i )1 ensures g(t)

Scaling the rfi terms by (np(t)
O-SGD deﬁnes p(t) as the sampling distribution that maximizes (3):
Proposition 3.1 (Oracle sampling distribution). In order to minimize E[kg(t)
each example i with probability proportional to the ith “gradient norm.” That is 

O remains an unbiased approximation of rF (w(t)).

O k2]  O-SGD samples

p(t)

j=1 krfj(w(t))k .

i = krfi(w(t))kPn
nPn
i=1 fi(w)  we write this second moment as
i krfi(w(t))k2  1

1
p(t)

i=1

|M|kr ¯f (w(t))k2 + krF (w(t))k2 .

(5)

Proof sketch. Deﬁning ¯f (w) = 1

Ehkg(t)

O k2i = 1

n2|M|Pn

Finding the distribution p(t) that minimizes (5) is a problem with a closed-form solution. The solution
is the distribution deﬁned by Proposition 3.1  which we show in Appendix A.

The oracle sampling distribution is quite intuitive. Training examples with largest gradient norm
are most important for further decreasing F   and these examples receive priority. Examples that the
model handles correctly have smaller gradient norm  and O-SGD deprioritizes these examples.

3.2 Adapting the learning rate
Because importance sampling reduces the stochastic gradient’s variance—possibly by a large amount—
we ﬁnd it important to adaptively increase O-SGD’s learning rate compared to U-SGD. For O-SGD 
we propose a learning rate that depends on the “gain ratio” r(t)

r(t)

O = Ehkg(t)

U k2i. Ehkg(t)

O 2 R1:
O k2i .

(6)

Above  g(t)
so that according to (3)  one O-SGD iteration results in as much progress as r(t)
Deﬁning the edge case r(0)

U is the stochastic gradient deﬁned by uniform sampling. O-SGD adapts the learning rate
O U-SGD iterations.

O = 1  this learning rate depends on the “effective iteration number”

Since the gain ratio exceeds 1  we have ˆt(t)

t0=1 r(t01)

O =Pt
ˆt(t)
O  t for all t. O-SGD deﬁnes the learning rate as

O

.

⌘(t)
O = r(t)

O lr_sched(ˆt(t)

O ) .

We justify this choice of learning rate schedule with the following proposition:

Proposition 3.2 (Equivalence of gain ratio and expected speed-up). Given w(t)  deﬁne E(t)
expected progress from iteration t of U-SGD with learning rate ⌘(t)
deﬁne E(t)
Then E(t)

U as the
U = lr_sched (t). For comparison 
O = r(t)
O ⌘(t)
U .
U . Relative to U-SGD  O-SGD multiplies the expected progress by r(t)
O .

O as the expected progress from iteration t of O-SGD with learning rate ⌘(t)
O = r(t)

O E(t)

Proof. Using (3)  we have

E(t)

U = 2⌘(t)

U hrF (w(t))  w(t)  w?i  [⌘(t)

U ]2Ehkg(t)

U k2i .

3

For O-SGD  we expect progress

E(t)

O = 2⌘(t)
= 2r(t)

O hrF (w(t))  w(t)  w?i  [⌘(t)
O ⌘(t)

U hrF (w(t))  w(t)  w?i  r(t)

O ]2Ehkg(t)
O k2i
U ]2Ehkg(t)

O [⌘(t)

U k2i = r(t)

O E(t)
U .

We remark that the purpose of this learning rate adjustment is not necessarily to speed up training—
whether the adjustment results in speed-up depends greatly on the original learning rate schedule.
Instead  the purpose of this rescaling is to make O-SGD (and hence RAIS-SGD) suitable as a drop-in
replacement for U-SGD. We show empirically that this is the case in §6.

4 Robust approximate importance sampling (RAIS)

O in (4).

Determining p(t) and r(t)

O in O-SGD depends on knowledge of many gradient norms (rfi(w(t))
for all examples  r ¯f (w(t))  and rF (w(t))). Computing these norms requires a time-

consuming pass over the data. To make importance sampling practical  we propose RAIS-SGD.

R   which takes the same form as g(t)

4.1 Determining a robust sampling distribution
Like O-SGD  RAIS selects the tth minibatch by sampling indices from a discrete distribution p(t).
We denote the stochastic gradient by g(t)
Let v⇤i = krfi(w(t))k and v⇤ = [v⇤1  v⇤2  . . .   v⇤n]T . RAIS deﬁnes p(t) by approximating v⇤. Naïve
algorithms approximate v⇤ using a point estimate ˆv. The sampling distribution becomes a multiple
of ˆv. [3]  [4]  and [6] propose algorithms based on similar point estimation strategies.
The drawback of the point estimation approach is extreme sensitivity to differences between ˆv and v⇤.
For this reason  [3  4  6] incorporate additive smoothing. They introduce a hyperparameter  which we
denote by   and sample example i with probability proportional to ˆvi +. This approach to robustness
is unconvincing  however  since performance becomes critically dependent on a hyperparameter. Too
small a  risks divergence  while too large a value greatly limits the beneﬁt of importance sampling.
Instead of a point estimate  RAIS approximates v⇤ with an uncertainty set U (t) ⇢ Rn
0  which we
expect contains (or nearly contains) v⇤. Given U (t)  RAIS deﬁnes p(t) by minimizing the worst-case
R k2] /Pi
value of E[kg(t)
(v⇤i )2 +c
for some c 2 R (according to (5))  RAIS deﬁnes p(t) as the solution to the following problem:
i=1 pi = 1o .

R k2] over all gradient norm possibilities in U (t). Noting E[kg(t)

p(t) = arginfnmaxPn

Such robust optimization problems are common for making decisions with data uncertainty [7].
It turns out (PRC) is straightforward to solve because the minimax theorem applies to (PRC) (we
prove this in Appendix D.1  assuming our deﬁnition of U (t) in §4.2). We ﬁrst minimize over p by
deﬁning pi = vi(Pn
j=1 vj)1. Plugging this into (PRC)’s objective leads to the simpliﬁed problem

(PRC’)
During each iteration t  RAIS solves (PRC’). After doing so  RAIS recovers the minimax optimal
sampling distribution by deﬁning p(t)

v(t) = argmax (Pn

i=1 vi)2 | v 2U (t) .

i | v 2U (t)  p 2 Rn

for all training examples.

>0 Pn

(PRC)

1
p(t)
i

v2

1
pi

i=1

i / v(t)

i

4.2 Modeling the uncertainty set
To deﬁne U (t)  RAIS uses features of SGD’s state that are predictive of the true gradient norms. For
each example i  we deﬁne a feature vector s(t)
is the gradient norm
krfi(w(t0))k  where t0 is the most recent iteration for which i 2M (t0). Since RAIS-SGD computes
rfi(w(t0)) during iteration t0  constructing this feature during iteration t should add little overhead.

0. A useful feature for s(t)

i 2 RdR

i

4

Given s(t)
for all examples  RAIS deﬁnes the uncertainty set as an axis-aligned ellipsoid. Since
i
v⇤  0  RAIS also intersects this ellipsoid with the positive orthant. RAIS parameterizes this
uncertainty set with two vectors  c 2 RdR
1:n to
parameters of the ellipsoid. Speciﬁcally  RAIS deﬁnes the uncertainty set as

0. These vectors map features s(t)

0 and d 2 RdR
  vi)  1   where Qcd(s  v) = (hc siv)2

0 1
cd =v 2 Rn
nPn
U (t)
Here we denote the uncertainty set by U (t)
this deﬁnition of U (t)
cd   (PRC’) has a simple closed-form solution (proven in Appendix B):
Proposition 4.1 (Solution to robust counterpart). For all i  the solution to (PRC’) satisﬁes

cd to emphasize the dependence of U (t) on c and d. With

i=1 Qcd(s(t)

hd si

.

i

i i + khd  s(t)

v(t)
i = hc  s(t)
i i an estimate of v⇤i and hd  s(t)

i i   where k =qnPn

j=1hd  s(t)
j i .

1

i=1hd  s(t)

i i + khd  s(t)

c  d = arginfnPn

R k2] small but still ensure v⇤ likely lies in U (t)

If we consider hc  s(t)
i i a measure of uncertainty in this estimate 
then Proposition 4.1 is quite interpretable. RAIS samples example i with probability proportional to
hc  s(t)
i i. The ﬁrst term is the v⇤i estimate  and the second term adds robustness to error.
4.3 Learning the uncertainty set
The uncertainty set parameters  c and d  greatly inﬂuence the performance of RAIS. If U (t)
cd is a small
region near v⇤  then RAIS’s sampling distribution is similar to O-SGD’s sampling distribution. If
U (t)
cd is less representative of v⇤  the variance of the stochastic gradient could become much larger.
In order to make E[kg(t)
cd   RAIS adaptively deﬁnes c
cd subject to a constraint that encourages v⇤ 2U (t)
and d. To do so  RAIS minimizes the size of U (t)
cd :
(PT)

i i c  d 2 RdR
|D|P|D|
0  1
Here we have deﬁned U (t)
cd ’s “size” as the sum of hd  s(t)
i i values. The constraint that encourages
v⇤ 2U (t) assumes weighted training data  ( ˜wi  ˜si  ˜vi)|D|
i=1. RAIS must deﬁne this training set so that
|D|P|D|
nPn
i=1 ˜wiQcd(˜si  ˜vi) ⇡ 1

That is  for any c and d  the mean of Qcd(˜s  ˜vi) over the weighted training set should approximately
equal the mean of Qcd(s(t)
i
To achieve this  RAIS uses gradients from recent minibatches. For entry j of the RAIS train-
ing set  RAIS considers an i and t0 for which i 2M (t0) and t0 < t. RAIS deﬁnes ˜sj = s(t0)
 
˜vj = krfi(w(t0))k  and ˜wj = (np(t0)
)1. The justiﬁcation for this choice is that the mean of
Qcd(s(t)
 krfi(w(t))k) over training examples tends to change gradually with t. Thus  the weighted
i
 rfi(w(t))) values.
mean over the RAIS training set approximates the mean of current Qcd(s(t)
i

4.4 Approximating the gain ratio
In addition to the sampling distribution  RAIS must approximate the gain ratio in O-SGD. Deﬁne
g(t)
R1 as a stochastic gradient of the form (4) using minibatch size 1 and RAIS sampling. Deﬁne g(t)
U1
in the same way but with uniform sampling. From (5)  we can work out that the gain ratio satisﬁes

i=1 ˜wiQcd(˜si  ˜vi)  1o .

  v⇤i )  which depends on current (unknown) gradient norms.

 krfi(w(t))k) .

i=1 Qcd(s(t)

Ehkg(t)

U k2i.Ehkg(t)

R1k2]⌘.E[kg(t)
R k2] .
To approximate the gain ratio  RAIS estimates the three moments on the right side of this equation.
RAIS estimates E[kg(t)
R k2 from recent iterations:

R k2] using an exponential moving average of kg(t)

R k2i = 1 + 1

|M|⇣E[kg(t)

U1k2]  E[kg(t)

(7)

i

i

i

E[kg(t)

R k2] ⇡ ↵hkg(t)

R k2 + (1  ↵)kg(t1)

R

k2 + (1  ↵)2kg(t2)

R

k2 + . . .i .

5

Algorithm 4.1 RAIS-SGD

cd 
i=1 vi)2 | v 2U (t)

input objective function F   minibatch size |M|  learning rate schedule lr_sched(·)
input RAIS training set size |D|  exponential smoothing parameter ↵ for gain estimate
initialize w(1) 2 Rd  c  d 2 RdR
0; ˆt(1) 1; r_estimator GainEstimator(↵)
for t = 1  2  . . .   T do
v(t) argmax (Pn
|M|Pi2M(t)

p(t) v(t)/kv(t)k1
M(t) sample_indices_from_distribution(p(t)  size = |M|)
g(t)
R 1
r_estimator.record_gradient_norms(kg(t)
ˆr(t) r_estimator.estimate_gain_ratio()
⌘(t) ˆr(t) · lr_sched(ˆt(t))
w(t+1) w(t)  ⌘(t)g(t)
ˆt(t+1) ˆt(t) + ˆr(t)
if mod(t  d|D|/|M|e) = 0 and t  (n + |D|)/|M| then
# see §4.2

R k  (krfi(w(t))k  p(t)

i rfi(w(t)) + w(t)
np(t)

i )i2M(t))

c  d train_uncertainty_model()

return w(T +1)

# see Proposition 4.1 for closed-form solution

1

R

# see §4.4

R1k2] and E[kg(t)

RAIS approximates E[kg(t)
R1k2] and E[kg(t)
U1k2] in a similar way. After computing gradients for
minibatch t  RAIS estimates E[kg(t)
U1k2] using appropriately weighted averages of
krfi(w(t))k2 for each i 2M (t) (for E[kg(t)
R1k2]  RAIS weights terms by (np(t)
U1k2] 
RAIS weights terms by (np(t)
i )1). Using the same exponential averaging parameter ↵  RAIS
averages these estimates from minibatch t with estimates from prior iterations.
RAIS approximates the gain ratio by plugging these moment estimates into (7). We denote the result

by ˆr(t). Analogous to O-SGD  RAIS uses learning rate ⌘(t) = ˆr(t)lr_schedˆt(t)  where ˆt(t) is the
effective iteration number: ˆt(t) =Pt

t0=1 ˆr(t01). Here we also deﬁne the edge case ˆr(0) = 1.

i )2; for E[kg(t)

4.5 Practical considerations

Algorithm 4.1 summarizes our RAIS-SGD algorithm. We next discuss important practical details.

Solving (PT) While computing p(t) requires a small number of length n operations (see Proposi-
tion 4.1)  learning the uncertainty set parameters requires more computation. For this reason  RAIS
should not solve (PT) during every iteration. Our implementation solves (PT) asynchronously after
every d|D|/|M|e minibatches  with updates to w(t) continuing during the process. We describe
our algorithm for solving (PT) in Appendix D.2. Since our features s(t)
1:n depend on past minibatch
updates  we do not use RAIS for the ﬁrst epoch of training—instead we sample examples sequentially.

Compatibility with common tricks RAIS combines nicely with standard training tricks for deep
learning. With no change  we ﬁnd RAIS works well with momentum [8  9]. Incorporating data
augmentation  dropout [10]  or batch normalization [11] adds variance to the model’s outputs and
gradient norms. RAIS elegantly compensates for such inconsistency by learning a larger uncertainty
set. Since the importance sampling distribution changes over time  we ﬁnd it important to compute
weighted batch statistics when using RAIS with batch normalization. That is  when computing
normalization statistics during training  we weight contributions from each example by (np(t)
i )1.

Protecting against outliers
In some cases—typically when the gain ratio is very large—we ﬁnd
Qcd(s(t)
  v⇤i ) can be quite small for most examples yet large for a small set of outliers. Typically
i
we ﬁnd RAIS does not require special treatment of such outliers. Even so  it is reasonable to protect
against outliers  so that an example with extremely large Qcd(s(t)
  v⇤i ) cannot greatly increase the
i
stochastic gradient’s variance. To achieve this  we use gradient clipping  and RAIS provides a natural

6

Figure 2: Supplemental plots. Left: Visualization of top-layer gradient norm approximation. The
model is an 18 layer ResNet after 30 epochs of training on CIFAR-10. Middle: Oracle importance
sampling results for MNIST and LeNet model. Right: RAIS time overhead for rot-MNIST.

way of doing so. We deﬁne an “outlier” as any example for which Qcd(s(t)
  v⇤i ) exceeds a threshold
i
⌧. For each outlier i  we temporarily scale fi during iteration t until Qcd(s(t)
i
In practice  we use ⌧ = 100; the fraction of outliers is often zero and rarely exceeds 0.1%.

 rfi(w(t))) = ⌧.

Approximating per-example gradient norms To train the uncertainty set  RAIS computes
krfi(w(t))k for each example in each minibatch. Unfortunately  existing software tools do not pro-
vide efﬁcient access to per-example gradient norms. Instead  libraries are optimized for aggregating
gradients over minibatches. Thus  to make RAIS practical  we must approximate the gradient norms.
We do so by replacing krfi(w(t))k with the norm of only the loss layer’s gradient (with respect to
this layer’s inputs). These values correlate strongly  since the loss layer begins the backpropagation
chain for computing rfi(w(t)). We show this empirically in Figure 2(left)  and we include additional
plots in Appendix E.1. We note this approximation may not work well for all models.

5 Relation to prior work

Prior strategies also consider importance sampling for speeding up deep learning. [3] proposes
distributing the computation of sampling probabilities. In parallel with regular training  [4] trains a
miniature neural network to predict importance values. [5] approximates importance values using
additional forward passes. [12] and [13] apply importance sampling to deep reinforcement learning.
With the exception of [5] (which requires considerable time to compute importance values)  these prior
algorithms are sensitive to errors in importance value estimates. For this reason  all require critical
smoothing hyperparameters to converge. In contrast  RAIS elegantly compensates for approximation
error by choosing a sampling distribution that is minimax optimal with respect to an uncertainty set.
Since RAIS adaptively trains this uncertainty set  RAIS does not require hyperparameter tuning.
Researchers have also considered other ways to prioritize training examples for deep learning. [14]
considers examples in order of increasing difﬁculty. Other researchers prioritize challenging training
examples [15  16]. And yet others prioritize examples closest to the model’s decision boundary [17].
Unlike RAIS  the primary goal of these approaches is improved model performance  not optimization
efﬁciency. Importance sampling may work well in conjunction with these strategies.
There also exist ideas for sampling minibatches non-uniformly outside the context of deep learning.
[18  19] consider sampling diverse minibatches via repulsive point processes. Another strategy
uses side information  such as class labels  for approximate importance sampling [6]. By choosing
appropriate features for the uncertainty set  RAIS can use side information in the same way.
In the convex setting  there are several importance sampling strategies for SGD with theoretical guar-
antees. This includes [1] and [2]  which sample training examples proportional to Lipschitz constants.
Leverage score sampling uses a closely related concept for matrix approximation algorithms [20  21].
For more general convex problems  some adaptive sampling strategies include [22] and [23].

6 Empirical comparisons

In this section  we demonstrate how RAIS performs in practice. We consider the very popular task of
training a convolutional neural network to classify images.

7

103100Fullgradientnorms105102Toplayergrad.norms36Epochs0.020.040.06F(w(t))36Epochs0.81.01.2Validationerror(%)0306090120150Epochs0200400600Elapsedtime(s)RAIS-SGDSGDOracleISSGDRAIS-SGDSGDSVHN

rot-MNIST

CIFAR-10

CIFAR-100

Figure 3: Learning curve comparison. RAIS consistently outperforms SGD with uniform sam-
pling  both in terms of objective value and generalization performance. Curves show the mean of ﬁve
trials with varying random seeds. Filled areas signify ±1.96 times standard error of the mean.

We ﬁrst train a LeNet-5 model [24] on the MNIST digits dataset. The model’s small size makes
it possible to compare with O-SGD. We use learning rate ⌘(t) = 3.4/p100 + t  L2 penalty  =
2.5 ⇥ 104  and batch size 32—the parameters are chosen so that SGD performs well. We do not use
momentum or data augmentation. Figure 2(middle) includes the results of this experiment. Oracle
sampling signiﬁcantly outperforms RAIS  and RAIS signiﬁcantly outperforms uniform sampling.
For our remaining comparisons  we consider street view house numbers [25]  rotated MNIST [26] 
and CIFAR tiny image [27] datasets. For rot-MNIST  we train a 7 layer CNN with 20 channels per
layer—a strong baseline from [28]. Otherwise  we train an 18 layer ResNet preactivation model
[29]. CIFAR-100 contains 100 classes  while the other problems contain 10. The number of training
examples is 6.0 ⇥ 105 for SVHN  1.2 ⇥ 104 for rot-MNIST  and 5.0 ⇥ 104 for the CIFAR problems.
We follow standard training procedures to attain good generalization performance. We use batch
normalization and standard momentum of 0.9. For rot-MNIST  we follow [28]  augmenting data with
random rotations and training with dropout. For the CIFAR problems  we augment the training set
with random horizontal reﬂections and random crops (pad to 40x40 pixels; crop to 32x32).
We train the SVHN model with batch size 64 and the remaining models with |M| = 128. For
each problem  we approximately optimize  and the learning rate schedule in order to achieve
good validation performance with SGD at the end of training. The learning rate schedule decreases
by a ﬁxed fraction after each epoch (n/|M| iterations). This fraction is 0.8 for SVHN  0.972 for
rot-MNIST  0.96 for CIFAR-10  and 0.96 for CIFAR-100. The initial learning rates are 0.15  0.09 
0.08  and 0.1  respectively. We use  = 3 ⇥ 103 for rot-MNIST and  = 5 ⇥ 104 otherwise.
For RAIS-SGD  we use |D| = 2 ⇥ 104 training examples to learn c and d and ↵ = 0.01 to estimate
ˆr(t). The performance of RAIS varies little with these parameters  since they only determine the
number of minibatches to consider when training the uncertainty set and estimating the gain ratio. For
the uncertainty set features  we use simple moving averages of the most recently computed gradient
norms for each example. We use moving averages of different lengths—1  2  4  8  and 16. For lengths
of at least four  we also include the variance and standard deviation of these prior gradient norm
values. We also incorporate a bias feature as well as the magnitude of the random crop offset.
We compare training curves of RAIS-SGD and SGD in Figure 3. Notice that RAIS-SGD consistently
outperforms SGD. The relative speed-up ranges from approximately 20% for the CIFAR-100 problem
to more than 2x for the SVHN problem. Due to varying machine loads  we plot results in terms of
epochs (not wall time)  but RAIS introduces very little time overhead. For example  Figure 2(right)
includes time overhead results for the rot-MNIST comparison  which we ran on an isolated machine.
Figure 4 provides additional details of these results. In the ﬁgure’s ﬁrst row  we see the speed-up in
terms of the gain ratio (the blue curve averages the value (ˆr(t)  1) · 100% over consecutive epochs).

8

081624Epochs1.001.051.101.151.201.25F(w(t))0306090120150Epochs0.450.500.550.600.65F(w(t))020406080100Epochs1.11.21.31.41.5F(w(t))020406080100Epochs1.21.41.61.8F(w(t))081624Epochs2345Validationerror(%)0306090120150Epochs5.05.56.06.57.07.5Validationerror(%)020406080100Epochs510152025Validationerror(%)020406080100Epochs242628303234Validationerror(%)RAIS-SGDSGDSVHN

rot-MNIST

CIFAR-10

CIFAR-100

SVHN

rot-MNIST

CIFAR-10

CIFAR-100

Figure 4: RAIS speed-up and alignment of epochs equivalent. Above: Blue shows increase in
optimization speed due to RAIS  as measured by estimated gain ratio; purple indicates time overhead
due to RAIS. Overhead is small compared to speed-up. Below: Objective value vs. epochs equivalent.
For RAIS  epochs equivalent equals |M|n
ˆt(t). The closely aligned curves suggest (i) RAIS-SGD is a
suitable drop-in replacement for SGD  and (ii) the gain ratio correctly approximates speed-up.

The gain ratio tends to increase as training progresses  implying RAIS is most useful during later
stages of training. We also plot the relative wall time overhead for RAIS  which again is very small.
In the second row of Figure 4  we compare RAIS-SGD and SGD in terms of epochs equivalent—the
number of epochs measured in terms of effective iterations. Interestingly  the curves align closely.
This alignment conﬁrms that our learning rate adjustment is reasonable  as it results in a suitable
drop-in replacement for SGD. This result contrasts starkly with [3]  for example  in which case
generalization performance differs signiﬁcantly for the importance sampling and standard algorithms.
Table 1 concludes these comparisons with a summary of results:

Epochs equivalent

Table 1: Quantities upon training completion.
Algorithm
RAIS-SGD
SGD
RAIS-SGD
SGD
RAIS-SGD
SGD

F (w(t)) Val. error Val. loss
0.121
0.121
0.149
0.161
0.256
0.277
0.962
0.989

114
24.0
214
150.
130.
100.
138
100.

1.01
1.02
0.431
0.460
1.08
1.10
1.21
1.25

0.0201
0.0226
0.0476
0.0512
0.0590
0.0607
0.236
0.236

Dataset
SVHN

rot-MNIST

CIFAR-10

CIFAR-100 RAIS-SGD

SGD

7 Discussion

We proposed a relatively simple and very practical importance sampling procedure for speeding up
the training of deep models. By using robust optimization to deﬁne the sampling distribution  RAIS
depends minimally on user-speciﬁed parameters. Additionally  RAIS introduces little computational
overhead and combines nicely with standard training strategies. All together  RAIS is a promising
approach with minimal downside and potential for large improvements in training speed.

Acknowledgements

We thank Marco Tulio Ribeiro  Tianqi Chen  Maryam Fazel  Sham Kakade  and Ali Shojaie for
helpful discussion and feedback. This work was supported by PECASE N00014-13-1-0023.

9

081624Epochs0100200300400500600Relativeimpact(%)0306090120150Epochs010203040506070Relativeimpact(%)020406080100Epochs01020304050Relativeimpact(%)020406080100Epochs020406080Relativeimpact(%)RAISgainRAIStimeoverhead081624Epochsequivalent1.001.051.101.151.201.25F(w(t))0306090120150Epochsequivalent0.450.500.550.600.65F(w(t))020406080100Epochsequivalent1.11.21.31.41.5F(w(t))020406080100Epochsequivalent1.21.41.61.8F(w(t))RAIS-SGDSGDReferences
[1] P. Zhao and T. Zhang. Stochastic optimization with importance sampling for regularized loss
minimization. In Proceedings of the 32nd International Conference on Machine Learning 
2015.

[2] D. Needell  R. Ward  and N. Srebro. Stochastic gradient descent  weighted sampling  and the
randomized Kaczmarz algorithm. In Advances in Neural Information Processing Systems 27 
2014.

[3] G. Alain  A. Lamb  C. Sankar  A. Courville  and Y. Bengio. Variance reduction in SGD by
distributed importance sampling. In 4th International Conference on Learning Representations
Workshop  2016.

[4] A. Katharopoulos and F. Fleuret. Biased importance sampling for deep neural network training.

arXiv:1706.00043  2017.

[5] A. Katharopoulos and F. Fleuret. Not all samples are created equal: Deep learning with
importance sampling. In Proceedings of the 35th International Conference on Machine Learning 
2018.

[6] S. Gopal. Adaptive sampling for SGD by exploiting side information. In Proceedings of the

33rd International Conference on Machine Learning  2016.

[7] A. Ben-Tal  L. El Ghaoui  and A. Nemirovski. Robust Optimization. Princeton University Press 

2009.

[8] B. T. Polyak. Some methods of speeding up the convergence of iteration methods. USSR

Computational Mathematics and Mathematical Physics  4(5):1–17  1964.

[9] I. Sutskever  J. Martens  G. Dahl  and G. Hinton. On the importance of initialization and
momentum in deep learning. In Proceedings of the 30th International Conference on Machine
Learning  2013.

[10] N. Srivastava  G. Hinton  A. Krizhevsky  I. Sutskever  and R. Salakhutdinov. Dropout: A
simple way to prevent neural networks from overﬁtting. Journal of Machine Learning Research 
15:1929–1958  2014.

[11] S. Ioffe and C. Szegedy. Batch normalization: Accelerating deep network training by reducing

internal covariate shift. In 32nd International Conference on Machine Learning  2015.

[12] T. Schaul  J. Quan  I. Antonoglou  and D. Silver. Prioritized experience replay. In 6th Interna-

tional Conference on Learning Representations  2016.

[13] D. Horgan  J. Quan  D. Budden  G. Barth-Maron  M. Hessel  H. van Hasselt  and D. Sil-
ver. Distributed prioritized experience replay. In 6th International Conference on Learning
Representations  2018.

[14] Y. Bengio  J. Louradour  R. Collobert  and J. Weston. Curriculum learning. In Proceedings of

the 26th International Conference on Machine Learning  2009.

[15] A. Shrivastava  A. Gupta  and R. Girshick. Training region-based object detectors with online
hard example mining. In Proceedings of the IEEE Conference on Computer Vision and Pattern
Recognition  2016.

[16] S. Shalev-Shwartz and Y. Wexler. Minimizing the maximal loss: How and why. In Proceedings

of the 33rd International Conference on Machine Learning  2016.

[17] A. McCallum H.-S. Chang  E. Learned-Miller. Active bias: Training more accurate neural
networks by emphasizing high variance samples. In Advances in Neural Information Processing
Systems 30  2017.

[18] C. Zhang  H. Kjellström  and S. Mandt. Determinantal point processes for mini-batch diversiﬁ-

cation. Conference in Uncertainty in Artiﬁcial Intelligence  2017.

[19] C. Zhang  C. Öztireli  S. Mandt  and G. Salvi. Active mini-batch sampling using repulsive point

processes. arXiv:1804.02772  2018.

[20] M. Mahoney. Randomized algorithms for matrices and data. Foundations and Trends in

Machine learning  3(2)  2011.

[21] P. Ma  B. Yu    and M. Mahoney. A statistical perspective on algorithmic leveraging.

Proceedings of the 31st International Conference on Machine Learning  2014.

In

10

[22] S. U. Stich  A. Raj  and M. Jaggi. Safe adaptive importance sampling. In Advances in Neural

Information Processing Systems 30  2017.

[23] Z. Borsos  A. Krause  and K. Y. Levy. Online variance reduction for stochastic optimization.

arXiv:1802.04715  2018.

[24] Y. Lecun  L. Bottou  Y. Bengio  and P. Haffner. Gradient-based learning applied to document

recognition. In Proceedings of the IEEE  1998.

[25] Y. Netzer  T. Wang  A. Coates  A. Bissacco  B. Wu  and A. Y. Ng. Reading digits in nat-
ural images with unsupervised feature learning. In NIPS Workshop on Deep Learning and
Unsupervised Feature Learning  2011.

[26] H. Larochelle  D. Erhan  A. Courville  J. Bergstra  and Y. Bengio. An empirical evaluation
of deep architectures on problems with many factors of variation. In Proceedings of the 24th
International Conference on Machine Learning  2007.

[27] A. Krizhevsky. Learning multiple layers of features from tiny images. Technical report  2009.
[28] T. S. Cohen and M. Welling. Group equivariant convolutional networks. In Proceedings of the

33rd International Conference on Machine Learning  2016.

[29] K. He  X. Zhang  S. Ren  and J. Sun. Identity mapping in deep residual networks. In European

Conference on Computer Vision  2016.

11

,Tyler Johnson
Carlos Guestrin