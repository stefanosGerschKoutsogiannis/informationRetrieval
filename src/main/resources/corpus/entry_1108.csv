2017,Consistent Multitask Learning with Nonlinear Output Relations,Key to multitask learning is exploiting the relationships between different tasks to improve prediction performance. Most previous methods have focused on the case where tasks relations can be modeled as linear operators and regularization approaches can be used successfully. However  in practice assuming the tasks to be linearly related is often restrictive  and allowing for nonlinear structures is a challenge. In this paper  we tackle this issue by casting the problem within the framework of structured prediction. Our main contribution is a novel algorithm for learning multiple tasks which are related by a system of nonlinear equations that their joint outputs need to satisfy. We show that our algorithm can be efficiently implemented and study its generalization properties  proving universal consistency and learning rates. Our theoretical analysis highlights the benefits of non-linear multitask learning over learning the tasks independently. Encouraging experimental results show the benefits of the proposed method in practice.,Consistent Multitask Learning with

Nonlinear Output Relations

Carlo Ciliberto • 1 Alessandro Rudi • ∗  2 Lorenzo Rosasco 3 4 5 Massimiliano Pontil 1 5

{c.ciliberto m.pontil}@ucl.ac.uk

1Department of Computer Science  University College London  London  UK.
2INRIA - Sierra Project-team and École Normale Supérieure  Paris  France.

alessandro.rudi@inria.fr

lrosasco@mit.edu

3Massachusetts Institute of Technology  Cambridge  USA.

4Università degli studi di Genova  Genova  Italy.
5Istituto Italiano di Tecnologia  Genova  Italy.

• Equal Contribution

Abstract

Key to multitask learning is exploiting the relationships between different tasks in
order to improve prediction performance. Most previous methods have focused on
the case where tasks relations can be modeled as linear operators and regularization
approaches can be used successfully. However  in practice assuming the tasks to
be linearly related is often restrictive  and allowing for nonlinear structures is a
challenge. In this paper  we tackle this issue by casting the problem within the
framework of structured prediction. Our main contribution is a novel algorithm for
learning multiple tasks which are related by a system of nonlinear equations that
their joint outputs need to satisfy. We show that our algorithm can be efﬁciently
implemented and study its generalization properties  proving universal consistency
and learning rates. Our theoretical analysis highlights the beneﬁts of non-linear
multitask learning over learning the tasks independently. Encouraging experimental
results show the beneﬁts of the proposed method in practice.

1

Introduction

Improving the efﬁciency of learning from human supervision is one of the great challenges in
machine learning. Multitask learning is one of the key approaches in this sense and it is based on
the assumption that different learning problems (i.e. tasks) are often related  a property that can
be exploited to reduce the amount of data needed to learn each individual tasks and in particular
to learn efﬁciently novel tasks (a.k.a.
transfer learning  learning to learn [1]). Special cases of
multitask learning include vector-valued regression and multi-category classiﬁcation; applications are
numerous  including classic ones in geophysics  recommender systems  co-kriging or collaborative
ﬁltering (see [2  3  4] and references therein). Diverse methods have been proposed to tackle this
problem  for examples based on kernel methods [5]  sparsity approaches [3] or neural networks [6].
Furthermore  recent theoretical results allowed to quantify the beneﬁts of multitask learning from a
generalization point view when considering speciﬁc methods [7  8].
A common challenge for multitask learning approaches is the problem of incorporating prior as-
sumptions on the task relatedness in the learning process. This can be done implicitly  as in neural
networks [6]  or explicitly  as done in regularization methods by designing suitable regularizers
[5]. This latter approach is ﬂexible enough to incorporate different notions of tasks’ relatedness
expressed  for example  in terms of clusters or a graph  see e.g. [9  10]. Further  it can be extended
to learn the tasks’ structures when they are unknown [3  11  12  13  14  15  16]. However  most

∗Work performed while A.R. was at the Istituto Italiano di Tecnologia.

31st Conference on Neural Information Processing Systems (NIPS 2017)  Long Beach  CA  USA.

regularization approaches are currently limited to imposing  or learning  tasks structures expressed by
linear relations (see Sec. 5). For example an adjacency matrix in the case of graphs or a block matrix
in the case of clusters. Clearly while such a restriction might make the problem more amenable to
statistical and computational analysis  in practice it might be a severe limitation.
Encoding and exploiting nonlinear task relatedness is the problem we consider in this paper. Previous
literature on the topic is scarce. Neural networks naturally allow to learn with nonlinear relations 
however it is unclear whether such relations can be imposed a-priori. As explained below  our
problem has some connections to that of manifold valued regression [17]. To our knowledge this
is the ﬁrst work addressing the problem of explicitly imposing nonlinear output relations among
multiple tasks. Close to our perspective is [18]  where however a different approach is proposed 
implicitly enforcing a nonlinear structure on the problem by requiring the parameters of each task
predictors to lie on a shared manifold in the hypotheses space.
Our main contribution is a novel method for learning multiple tasks which are nonlinearly related.
We address this problem from the perspective of structured prediction (see [19  20] and references
therein) building upon ideas recently proposed in [21]. Speciﬁcally we look at multitask learning
as the problem of learning a vector-valued function taking values in a prescribed set  which models
tasks’ interactions. We also discuss how to deal with possible violations of such a constraint set.
We study the generalization properties of the proposed approach  proving universal consistency and
learning rates. Our theoretical analysis allows also to identify speciﬁc training regimes in which
multitask learning is clearly beneﬁcial in contrast to learning all tasks independently.

2 Problem Formulation

Multitask learning (MTL) studies the problem of estimating multiple (real-valued) functions

f1  . . .   fT : X → R

(1)
i=1 with xit ∈ X and yit ∈ R  for t = 1  . . .   T . The key
from corresponding training sets (xit  yit)nt
idea in MTL is to estimate f1  . . .   fT jointly  rather than independently. The intuition is that if the
different tasks are related this strategy can lead to a substantial decrease of sample complexity  that is
the amount of data needed to achieve a given accuracy. The crucial question is then how to encode
and exploit such relations among the tasks.
Previous work on MTL has mostly focused on studying the case where the tasks are linearly related
(see Sec. 5). Indeed  this allows to capture a wide range of relevant situations and the resulting
problem can be often cast as a convex optimization  which can be solved efﬁciently. However  it
is not hard to imagine situations where different tasks might be nonlinearly related. As a simple
example consider the problem of learning two functions f1  f2 : [0  2π] → R  with f1(x) = cos(x)
and f2(x) = sin(x). Clearly the two tasks are strongly related one to the other (they need to satisfy
f1(x)2 + f2(x)2 − 1 = 0 for all x ∈ [0  2π]) but such structure in nonlinear (here an equation of
degree 2). More realistic examples can be found for instance in the context of modeling physical
systems  such as the case of a robot manipulator. A prototypical learning problem (see e.g. [22]) is to
associate the current state of the system (position  velocity  acceleration) to a variety of measurements
(e.g. torques) that are nonlinearly related one to the other by physical constraints (see e.g. [23]).
Following the intuition above  in this work we model tasks relations as a set of P equations. Speciﬁ-
cally we consider a constraint function γ : RT → RP and require that γ (f1(x)  . . .   fT (x)) = 0 for
all x ∈ X . When γ is linear  the problem reverts to linear MTL and can be addressed via standard
approaches (see Sec. 5). On the contrary  the nonlinear case becomes signiﬁcantly more challenging
and it is not clear how to address it in general. The starting point of our study is to consider the
tasks predictors as a vector-valued function f = (f1  . . .   fT ) : X → RT but then observe that γ
imposes constraints on its range. Speciﬁcally  in this work we restrict f : X → C to take values in
the constraint set

C =(cid:8)y ∈ RT | γ(y) = 0(cid:9) ⊆ RT

(2)
and formulate the nonlinear multitask learning problem as that of ﬁnding a good approximation

(cid:98)f : X → C to the solution of the multi-task expected risk minimization problem

(cid:90)

T(cid:88)

X×R

t=1

minimize

f :X→C

E(f ) 

E(f ) =

1
T

2

(cid:96)(ft(x)  y)dρt(x  y)

(3)

i=1 have been independently sampled.

where (cid:96) : R × R → R is a prescribed loss function measuring prediction errors for each individual
task and  for every t = 1  . . .   T   ρt is the distribution on X × R from which the training points
(xit  yit)nt
Nonlinear MTL poses several challenges to standard machine learning approaches. Indeed  when C
(cid:80)nt
is a linear space (e.g. γ is a linear map) the typical strategy to tackle problem (3) is to minimize the
i=1 (cid:96)(ft(xit)  yit) over some suitable space of hypotheses f : X → C
empirical risk 1
within which optimization can be performed efﬁciently. However  if C is a nonlinear subset of
T
RT   it is not clear how to parametrize a “good” space of functions since most basic properties
typically needed by optimization algorithms are lost (e.g. f1  f2 : X → C does not necessarily imply
f1 + f2 : X → C). To address this issue  in this paper we adopt the structured prediction perspective
proposed in [21]  which we review in the following.

(cid:80)T

1
nt

t=1

2.1 Background: Structured Prediction and the SELF Framework

The term structured prediction typically refers to supervised learning problems with discrete outputs 
such as strings or graphs [19  20  24]. The framework in [21] generalizes this perspective to account
for a more ﬂexible formulation of structured prediction where the goal is to learn an estimator
approximating the minimizer of

(cid:90)

minimize

f :X→C

X×Y

L(f (x)  y)dρ(x  y)

(4)

given a training set (xi  yi)n
i=1 of points independently sampled from an unknown distribution ρ on
X × Y  where L : Y × Y → R is a loss function. The output sets Y and C ⊆ Y are not assumed
to be linear spaces but can be either discrete (e.g. strings  graphs  etc.) or dense (e.g. manifolds 
distributions  etc.) sets of “structured” objects. This generalization will be key to tackle the question
of multitask learning with nonlinear output relations in Sec. 3 since it allows to consider the case
where C is a generic subset of Y = RT . The analysis in [21] hinges on the assumption that the loss L
is “bi-linearizable”  namely
Deﬁnition 1 (SELF). Let Y be a compact set. A function (cid:96) : Y × Y → R is a Structure Encoding
Loss Function (SELF) if there exists a continuous feature map ψ : Y → H  with H a reproducing
kernel Hilbert space on Y and a continuous linear operator V : H → H such that for all y  y(cid:48) ∈ Y
(5)

(cid:96)(y  y(cid:48)) = (cid:104)ψ(y)  V ψ(y(cid:48))(cid:105)H.

(cid:90)

In the original work the SELF deﬁnition was dubbed “loss trick” as a parallel to the kernel trick [25].
As we discuss in Sec. 4  most MTL loss functions indeed satisfy the SELF property. Under this
assumption  it can be shown that a solution f∗ : X → C to Eq. (4) must satisfy

f∗(x) = argmin

(cid:104)ψ(c)  V g∗(x)(cid:105)H

(6)
for all x ∈ X (see [21] or the Appendix). Since g∗ : X → H is a function with values in a linear

space  we can apply standard regression techniques to learn a(cid:98)g : X → H to approximate g∗ given

with

c∈C

Y

g∗(x) =

ψ(y) dρ(y|x)

i=1 and then obtain the estimator (cid:98)f : X → C as
(cid:104)ψ(c)   V (cid:98)g(x)(cid:105)H

(cid:98)f (x) = argmin

(xi  ψ(yi))n

∀x ∈ X .

(7)

1
n

c∈C

The intuition here is that if(cid:98)g is close to g∗  so it will be (cid:98)f to f∗ (see Sec. 4 for a rigorous analysis of
this relation). If(cid:98)g is the kernel ridge regression estimator obtained by minimizing the empirical risk
(cid:80)n
i=1 (cid:107)g(xi) − ψ(yi)(cid:107)2H (plus regularization)  Eq. (7) becomes
(cid:98)f (x) = argmin
since(cid:98)g can be written as the linear combination(cid:98)g(x) =(cid:80)n

i=1 αi(x) ψ(yi) and the loss function L is
SELF. In the above formula λ > 0 is a hyperparameter  I ∈ Rn×n the identity matrix  K ∈ Rn×n
the kernel matrix with elements Kij = k(xi  xj)  Kx ∈ Rn the vector with entries (Kx)i = k(x  xi)
and k : X × X → R a reproducing kernel on X .

α(x) = (α1(x)  . . .   αn(x))(cid:62) = (K + nλI)−1Kx

αi(x)L(c  yi) 

n(cid:88)

c∈C

(8)

i=1

3

kernel ridge regression in(cid:98)g  followed by a prediction step  where the vector c ∈ C minimizing the
operator V allow to derive the SELF estimator  their knowledge is not needed to evaluate (cid:98)f (x) in

The SELF structured prediction approach is therefore conceptually divided into two distinct phases:
a learning step  where the score functions αi : X → R are estimated  which consists in solving the
weighted sum in Eq. (8) is identiﬁed. Interestingly  while the feature map ψ  the space H and the
practice since the optimization at Eq. (8) depends exclusively on the loss L and the score functions
αi.

3 Structured Prediction for Nonlinear MTL

In this section we present the main contribution of this work  namely the extension of the SELF
framework to the MTL setting. Furthermore  we discuss how to cope with possible violations of the
constraint set in practice. We study the theoretical properties of the proposed estimator in Sec. 4. We
begin our analysis by applying the SELF approach to vector-valued regression which will then lead
to the MTL formulation.

3.1 Nonlinear Vector-valued Regression

T

c∈C

2 = ΠC (b(x)/a(x))

(9)

projection onto C

t=1(yt − y(cid:48)

t)2. Then  the SELF

Vector-valued regression (VVR) is a special instance of MTL where for each input  all output
(cid:80)
examples are available during training. In other words  the training sets can be combined into a single
i=1  with yi = (yi1  . . .   yit)(cid:62) ∈ RT . If we denote L : RT × RT → R the separable
dataset (xi  yi)n
loss L(y  y(cid:48)) = 1
t=1 (cid:96)(yt  y(cid:48)
Example 1 (Nonlinear VVR with Square Loss). Let L(y  y(cid:48)) =(cid:80)T
t)  nonlinear VVR coincides with the structured prediction problem
in Eq. (4). If L is SELF  we can therefore obtain an estimator according to Eq. (8).
estimator for nonlinear VVR can be obtained as (cid:98)f : X → C from Eq. (8) and corresponds to the
with a(x) = (cid:80)n

i=1 αi(x) yi. Interestingly  b(x) = (cid:80)n

(cid:98)f (x) = argmin
i=1 αi(x) and b(x) = (cid:80)n

(cid:107)c − b(x)/a(x)(cid:107)2

i=1 αi(x)yi =
Y (cid:62)(K +nλI)−1Kx corresponds to the solution of the standard vector-valued kernel ridge regression
without constraints (we denoted Y ∈ Rn×T the matrix with rows y(cid:62)
i ). Therefore  nonlinear VVR
consists in: 1) computing the unconstrained kernel ridge regression estimator b(x)  2) normalizing it
by a(x) and 3) projecting it onto C.

The example above shows that for speciﬁc loss functions the estimation of (cid:98)f (x) can be signiﬁcantly

simpliﬁed. In general  such optimization will depend on the properties of the constraint set C (e.g.
convex  connected  etc.) and the loss (cid:96) (e.g. convex  smooth  etc.). In practice  if C is a discrete
(or discretized) subset of RT   the computation can be performed efﬁciently via a nearest neighbor
search (e.g. using k-d trees based approaches to speed up computations [26]). If C is a manifold 
recent geometric optimization methods [27] (e.g. SVRG [28]) can be applied to ﬁnd critical points of
Eq. (8). This setting suggests a connection with manifold regression as discussed below.
Remark 1 (Connection to Manifold Regression). When C is a Riemannian manifold  the problem of
learning f : X → C shares some similarities to the manifold regression setting studied in [17] (see
also [29] and references therein). Manifold regression can be interpreted as a vector-valued learning
setting where outputs are constrained to be in C ⊆ RT and prediction errors are measured according
to the geodesic distance. However  note that the two problems are also signiﬁcantly different since 
1) in MTL noise could make output examples yi lie close but not exactly on the constraint set C and
moreover  2) the loss functions used in MTL typically measure errors independently for each task (as
in Eq. (3)  see also [5]) and rarely coincide with a geodesic distance.

3.2 Nonlinear Multitask Learning

Differently from nonlinear vector-valued regression  the SELF approach introduced in Sec. 2.1 cannot
be applied to the MTL setting. Indeed  the estimator at Eq. (8) requires knowledge of all tasks outputs
yi ∈ Y = RT for every training input xi ∈ X while in MTL we have a separate dataset (xit  yit)nt
for each task  with yit ∈ R (this could be interpreted as the vector yi to have “missing entries”).
i=1

4

Therefore  in this work we extend the SELF framework to nonlinear MTL. We begin by proving a
characterization of the minimizer f∗ : X → C of the expected risk E(f ) akin to Eq. (6).
Proposition 2. Let (cid:96) : R × R → R be SELF  with (cid:96)(y  y(cid:48)) = (cid:104)ψ(y)  V ψ(y(cid:48))(cid:105)H. Then  the expected
risk E(f ) introduced at Eq. (3) admits a measurable minimizer f∗ : X → C. Moreover  any such
minimizer satisﬁes  almost everywhere on X  

(cid:104)ψ(ct)  V g∗

t (x)(cid:105)H 

with

g∗
t (x) =

ψ(y) dρt(y|x).

(10)

f∗(x) = argmin

c∈C

T(cid:88)

t=1

(cid:90)

R

Prop. 2 extends Eq. (6) by relying on the linearity induced by the SELF assumption combined with
the Aumann’s principle [30]  which guarantees the existence of a measurable selector f∗ for the
minimization problem at Eq. (10) (see Appendix). By following the strategy outlined in Sec. 2.1  we
g∗

propose to learn T independent functions(cid:98)gt : X → H  each aiming to approximate the corresponding
t : X → H and then deﬁne (cid:98)f : X → C such that

We choose the(cid:98)gt to be the solutions to T independent kernel ridge regressions problems

t=1

T(cid:88)

c∈C

(cid:98)f (x) = argmin
nt(cid:88)

minimize
g∈H⊗G

1
nt

i=1

(cid:104) ψ(ct)   V (cid:98)gt(x) (cid:105)H

∀x ∈ X .

(cid:107)g(xit) − ψ(yit)(cid:107)2 + λt(cid:107)g(cid:107)2H⊗G

(11)

(12)

Proposition 3 (The Nonlinear MTL Estimator). Let k : X × X → R be a reproducing kernel with

for t = 1  . . .   T   where G is a reproducing kernel Hilbert space on X associated to a kernel
k : X × X → R and the candidate solution g : X → H is an element of H ⊗ G. The following result

shows that in this setting  evaluating the estimator (cid:98)f can be signiﬁcantly simpliﬁed.
associated reproducing kernel Hilbert space G. Let(cid:98)gt : X → H be the solution of Eq. (12) for
t = 1  . . .   T . Then the estimator (cid:98)f : X → C deﬁned at Eq. (11) is such that
(cid:98)f (x) = argmin

(α1t(x)  . . .   αntt(x))(cid:62) = (Kt + ntλtI)−1Ktx (13)

αit(x)(cid:96)(ct  yit) 

nt(cid:88)

T(cid:88)

c∈C

t=1

i=1

for all x ∈ X and t = 1  . . .   T   where Kt ∈ Rnt×nt denotes the kernel matrix of the t-th task 
namely (Kt)ij = k(xit  xjt)  and Ktx ∈ Rnt the vector with i-th component equal to k(x  xit).
Prop. 3 provides an equivalent characterization for nonlinear MTL estimator at Eq. (11) that is more
amenable to computations (it does not require explicit knowledge of H  ψ or V ) and generalizes the
SELF approach (indeed for VVR  Eq. (13) reduces to the SELF estimator at Eq. (8)). Interestingly 
the proposed strategy learns the score functions αim : X → R separately for each task and then
combines them in the joint minimization over C. This can be interpreted as the estimator weighting
predictions according to how “reliable” each task is on the input x ∈ X . We make this intuition more
clear in the following.
Example 2 (Nonlinear MTL with Square Loss). Let (cid:96) be the square loss. Then  analogously to
Example 1 we have that for any x ∈ X   the multitask estimator at Eq. (13) is

at(x)(cid:0)ct − bt(x)/at(x)(cid:1)2

(14)

T(cid:88)
(cid:98)f (x) = argmin
i=1 αit(x) and bt(x) = (cid:80)nt

c∈C

t=1

with at(x) = (cid:80)nt
jection (cid:98)f (x) = ΠA(x)C

i=1 αit(x)yit  which corresponds to perform the pro-
(w(x)) of the vector w(x) = (b1(x)/a1(x)  . . .   bT (x)/aT (x)) according to
the metric deformation induced by the matrix A(x) = diag(a1(x)  . . .   aT (x)). This suggests to
interpret at(x) as a measure of conﬁdence of task t with respect to x ∈ X . Indeed  tasks with small
at(x) will affect less the weighted projection ΠA(x)C

.

5

3.3 Extensions: Violating C
In practice  it is natural to expect the knowledge of the constraints set C to be not exact  for instance due
to noise or modeling inaccuracies. To address this issue  we consider two extensions of nonlinear MTL
that allow candidate predictors to slightly violate the constraints C and introduce a hyperparameter to
control this effect.
Robustness w.r.t. perturbations of C. We soften the effect of the constraint set by requiring
candidate predictors to take value within a radius δ > 0 from C  namely f : X → Cδ with

Cδ = { c + r | c ∈ C  r ∈ RT  (cid:107)r(cid:107) ≤ δ }.

(15)

The scalar δ > 0 is now a hyperparameter ranging from 0 (C0 = C) to +∞ (C∞ = RT ).
Penalizing w.r.t. the distance from C. We can penalize predictions depending on their distance
from the set C by introducing a perturbed version (cid:96)t

µ(y  z) = (cid:96)(yt  zt) + (cid:107)z − ΠC(z)(cid:107)2/µ
(cid:96)t

(16)
where ΠC : RT → C denotes the orthogonal projection onto C (see Example 1). Below we report the
closed-from solution for nonlinear vector-valued regression with square loss.
Example 3 (VVR and Violations of C). With the same notation as Example 1  let f0 : X → C denote
the solution at Eq. (9) of nonlinear VVR with exact constraints  let r = b(x)/a(x)−f0(x) ∈ RT . Then 
the solutions to the problem with robust constraints Cδ and perturbed loss function Lµ = 1
t (cid:96)t
µ
are respectively (see Appendix for the MTL)

(cid:80)

T

µ : RT × RT → R of the loss
for all y  z ∈ RT

(cid:98)fδ(x) = f0(x) + r min(1  δ/(cid:107)r(cid:107))

(cid:98)fµ(x) = f0(x) + r µ/(1 + µ).

and

(17)

4 Generalization Properties of Nonlinear MTL

We now study the statistical properties of the proposed nonlinear MTL estimator. Interestingly 
this will allow to identify speciﬁc training regimes in which nonlinear MTL achieves learning rates
signiﬁcantly faster than those available when learning the tasks independently. Our analysis revolves
around the assumption that the loss function used to measure prediction errors is SELF. To this end
we observe that most multitask loss functions are indeed SELF.
Proposition 4. Let ¯(cid:96) : [a  b] → R be differentiable almost everywhere with derivative Lipschitz
continuous almost everywhere. Let (cid:96) : [a  b] × [a  b] → R be such that (cid:96)(y  y(cid:48)) = ¯(cid:96)(y − y(cid:48))
or (cid:96)(y  y(cid:48)) = ¯(cid:96)(yy(cid:48)) for all y  y(cid:48) ∈ R. Then: (i) (cid:96) is SELF and (ii) the separable function
L : Y T × Y T → R such that L(y  y(cid:48)) = 1

t) for all y  y(cid:48) ∈ Y T is SELF.

(cid:80)T
t=1 (cid:96)(yt  y(cid:48)

T

Interestingly  most (mono-variate) loss functions used in multitask and supervised learning satisfy
the assumptions of Prop. 4. Typical examples are the square loss (y − y(cid:48))2  hinge max(0  1 − yy(cid:48))
or logistic log(1 − exp(−yy(cid:48))): the corresponding derivative with respect to z = y − y(cid:48) or z = yy(cid:48)
exists and it is Lipschitz almost everywhere on compact sets.
The nonlinear MTL estimator introduced in Sec. 3.2 relies on the intuition that if for each x ∈ X
t (x)  then

the kernel ridge regression solutions(cid:98)gt(x) are close to the conditional expectations g∗
also (cid:98)f (x) will be close to f∗(x). The following result formally characterizes the relation between
the two problems  proving what is often referred to as a comparison inequality in the context of
surrogate frameworks [31]. Throughout the rest of this section we assume ρt(x  y) = ρt(y|x)ρX (x)
ρX = L2(X  H  ρX ) norm of a function g : X → H
for each t = 1  . . .   T and denote (cid:107)g(cid:107)L2
according to the marginal distribution ρX .
t : X → H be deﬁned as in Eq. (10)  let(cid:98)gt : X → H be measurable functions
Theorem 5 (Comparison Inequality). With the same assumptions of Prop. 2  for t = 1  . . .   T let
f∗ : X → C and g∗

and let (cid:98)f : X → C satisfy Eq. (11). Let V ∗ be the adjoint of V . Then 
(cid:118)(cid:117)(cid:117)(cid:116) 1
E((cid:98)f ) − E(f∗) ≤ qC (cid:96) T

(cid:107)V ∗ψ(ct)(cid:107)2H.

(18)

(cid:118)(cid:117)(cid:117)(cid:116) 1

(cid:107)(cid:98)gt − g∗
t (cid:107)2

ρX the L2

T(cid:88)

 

Lρ2X

qC (cid:96) T = 2 sup
c∈C

T

t=1

T(cid:88)

t=1

T

6

The comparison inequality at Eq. (18) is key to study the generalization properties of our nonlinear
the true g∗
Theorem 6. Let C ⊆ [a  b]T   let X be a compact set and k : X × X → R a continuous universal

MTL estimator by showing that we can control its excess risk in terms of how well the(cid:98)gt approximate
reproducing kernel (e.g. Gaussian). Let (cid:96) : [a  b] × [a  b] → R be a SELF. Let (cid:98)fN : X → C denote

t (see Appendix for a proof of Thm. 5).

the estimator at Eq. (13) with N = (n1  . . .   nT ) training points independently sampled from ρt for
each task t = 1  . . .   T and λt = n

. Let n0 = min1≤t≤T nt. Then  with probability 1

−1/4
t

n0→+∞E((cid:98)fN ) = inf

lim

f :X→C E(f ).

(19)

E((cid:98)fN ) − inf

The proof of Thm. 6 relies on the comparison inequality in Thm. 5  which links the excess risk
of the MTL estimator to the square error between ˆgt and g∗
t . Standard results from kernel ridge
imposing further standard assumptions  we can also obtain generalization bounds on (cid:107)(cid:98)gt − g∗
regression allow to conclude the proof [32] (see a more detailed discussion in the Appendix). By
t (cid:107)L2
Theorem 7. With the same assumptions and notation of Thm. 6 let (cid:98)fN : X → C denote the estimator
t ∈ H ⊗ G  for all t = 1  . . .   T . Then for any τ > 0 we

that automatically apply to nonlinear MTL again via the comparison inequality  as shown below.

−1/2
and assume g∗
at Eq. (13) with λt = n
have  with probability at least 1 − 8e−τ   that
t

f :X→C E(f ) ≤ qC (cid:96) T h(cid:96) τ 2 n

−1/4
0

log T 

(20)

where qC (cid:96) T is deﬁned as in Eq. (18) and h(cid:96) is a constant independent of C  N  nt  λt  τ  T .
The the excess risk bound in Thm. 7 is comparable to that in [21] (Thm. 5). To our knowledge this is
the ﬁrst result studying the generalization properties of a learning approach to MTL with constraints.

√

4.1 Beneﬁts of Nonlinear MTL
The rates in Thm. 7 strongly depend on the constraints C via the constant qC (cid:96) T . The following result
studies two special cases that allow to appreciate this effect.
Lemma 8. Let B ≥ 1  B = [−B  B]T   S ⊂ RT be the sphere of radius B centered at the origin
and let (cid:96) be the square loss. Then qB (cid:96) T ≤ 2

To explain the effect of C on MTL  deﬁne n =(cid:80)T
rate of nonlinear MTL is of (cid:101)O(( T
MTL achieves a learning rate of (cid:101)O(( 1
a rate of (cid:101)O(n−1/2) which is comparable to the optimal rates available for kernel ridge regression

t=1 nt and assume that n0 = nt = n/T . Lemma 8
together with Thm. 7 shows that when the tasks are assumed not to be related (i.e. C = B) the learning
n )1/4)  as if the tasks were learned independently. On the other hand 
when the tasks have a relation (e.g. C = S  implying a quadratic relation between the tasks) nonlinear
nT )1/4)  which improves as the number of tasks increases and as
the total number of observed examples increases. Speciﬁcally  for T of the same order of n  we obtain

√
5 B2 and qS (cid:96) T ≤ 2

with only one task trained on the total number n of examples [32]. This observation corresponds to
the intuition that if we have many related tasks with few training examples each  we can expect to
achieve signiﬁcantly better generalization by taking advantage of such relations rather than learning
each task independently.

5 B2 T −1/2.

5 Connection to Previous Work: Linear MTL
In this work we formulated the nonlinear MTL problem as that of learning a function f : X → C
taking values in a set of constraints C ⊆ RT implicitly identiﬁed by a set of equations γ(f (x)) = 0. An
alternative approach would be to characterize the set C via an explicit parametrization θ : RQ → C  for
Q ∈ N  so that the multitask predictor can be decomposed as f = θ ◦ h  with h : X → RQ. We can
learn h : X → RQ using empirical risk minimization strategies such as Tikhonov regularization 

minimize

h=(h1 ... hQ)∈HQ

1
n

L(θ ◦ h(xi)  yi) + λ

(cid:107)hq(cid:107)2H

(21)

n(cid:88)

Q(cid:88)

i=1

q=1

7

Figure 1: (Bottom) MSE (logaritmic scale) of MTL methods for learning constrained on a circumference (Left)
or a Lemniscate (Right). Results are reported in a boxplot across 10 trials. (Top) Sample predictions of the three
methods trained on 100 points and compared with the ground truth.

to very different (cid:98)f = θ ◦(cid:98)h  which is not always desirable; 3) There are few results on empirical

since candidate h take value in RQ and therefore H can be a standard linear space of hypotheses.
However  while Eq. (21) is interesting from the modeling standpoint  it also poses several problems:
1) θ can be nonlinear or even non-continuous  making Eq. (21) hard to solve in practice even for
L convex; 2) θ is not uniquely identiﬁed by C and therefore different parametrizations may lead
risk minimization applied to generic loss functions L(θ(·) ·) (via so-called oracle inequalities  see
[30] and references therein)  and it is unclear what generalization properties to expect in this setting.
A relevant exception to the issues above is the case where θ is linear. In this setting Eq. (21)
becomes more amenable to both computations and statistical analysis and indeed most previous MTL
literature has been focused on this setting  either by designing ad-hoc output metrics [33]  linear
output encodings [34] or regularizers [5]. Speciﬁcally  in this latter case the problem is cast as that of
minimizing the functional

n(cid:88)

T(cid:88)

minimize

f =(f1 ... fT )∈HT

i=1

t s=1

L(f (xi)  yi) + λ

Ats(cid:104)ft  fs(cid:105)H

(22)

where the psd matrix A = (Ats)T
s t=1 encourages linear relations between the tasks. It can be
shown that this problem is equivalent to Eq. (21) when the θ ∈ RT×Q is linear and A is set to
the pseudoinverse of θθ(cid:62). As shown in [14]  a variety of situations are recovered considering the
approach above  such as the case where tasks are centered around a common average [9]  clustered
in groups [10] or sharing the same subset of features [3  35]. Interestingly  the above framework can
be further extended to estimate the structure matrix A directly from data  an idea initially proposed in
[12] and further developed in [2  14  16].

6 Experiments
Synthetic Dataset. We considered a model of the form y = f∗(x) +   with  ∼ N(0  σI) noise sam-
pled according to a normal distribution and f∗ : X → C  where C ⊂ R2 was either a circumference or
a lemniscate (see Fig. 1) of equation γcirc(y) = y2
2) = 0
for y ∈ R2. We set X = [−π  π] and f∗
lemn(x) = (sin(x)  sin(2x))
the parametric functions associated respectively to the circumference and Lemniscate. We sampled
from 10 to 1000 points for training and 1000 for testing  with noise σ = 0.05.
We trained and tested three regression models over 10 trials. We used a Gaussian kernel on the
input and chose the corresponding bandwidth and the regularization parameter λ by hold-out cross-
validation on 30% of the training set (see details in the appendix). Fig. 1 (Bottom) reports the mean

circ(x) = (cos(x)  sin(x)) or f∗

2 − 1 = 0 and γlemn(y) = y4

1 − (y2

1 − y2

1 + y2

8

Table 1: Explained variance of the robust (NL-MTL[R]) and perturbed (NL-MTL[P]) variants of nonlinear MTL 
compared with linear MTL methods on the Sarcos dataset reported from [16].

STL

MTL[36]

CMTL[10] MTRL[11] MTFL[13]

FMTL[16]

NL-MTL[R]

NL-MTL[P]

Expl.

40.5
Var. (%) ±7.6

34.5
±10.2

33.0
±13.4

41.6
±7.1

49.9
±6.3

50.3
±5.8

55.4
±6.5

54.6
±5.1

Table 2: Rank prediction error according to the weighted binary loss in [37  21].

NL-MTL

SELF[21]

Linear [37]

Hinge [38]

Logistic [39]

SVMStruct [20]

STL

MTRL[11]

Rank
Loss

0.271
±0.004

0.396
±0.003

0.430
±0.004

0.432
±0.008

0.432
±0.012

0.451
±0.008

0.581
0.003

0.613
±0.005

square error (MSE) of our nonlinear MTL approach (NL-MTL) compared with the standard least
squares single task learning (STL) baseline and the multitask relations learning (MTRL) from [11] 
which encourages tasks to be linearly dependent. However  for both circumference and Lemniscate 
the tasks are strongly nonlinearly related. As a consequence our approach consistently outperforms
its two competitors which assume only linear relations (or none at all). Fig. 1 (Top) provides a
qualitative comparison on the three methods (when trained with 100 examples) during a single trial.
Sarcos Dataset. We report experiments on the Sarcos dataset [22]. The goal is to predict the torque
measured at each joint of a 7 degrees-of-freedom robotic arm  given the current state  velocities and
accelerations measured at each joint (7 tasks/torques for 21-dimensional input). We used the 10
dataset splits available online for the dataset in [13]  each containing 2000 examples per task with 15
examples used for training/validation while the rest is used to measure errors in terms of the explained
variance  namely 1 - nMSE (as a percentage). To compare with results in [13] we used the linear
kernel on the input. We refer to the Appending for details on model selection.
Tab. 1 reports results from [13  16] for a wide range of previous linear MTL methods [36  10  3  11 
13  16]  together with our NL-MTL approach (both robust and perturbed versions). Since  we did not
ﬁnd Sarcos robot model parameters online  we approximated the constraint set C as a point cloud by
collecting 1000 random output vectors that did not belong to training or test sets in [13] (we sampled
them from the original dataset [22]). NL-MTL clearly outperforms the “linear” competitors. Note
indeed that the torques measured at different joints of a robot are highly nonlinear (see for instance
[23]) and therefore taking such structure into account can be beneﬁcial to the learning process.
Ranking by Pair-wise Comparison. We consider a ranking problem formulated withing the MTL
setting: given D documents  we learn T = D(D − 1)/2 functions fp q : X → {−1  0  1}  for
each pair of documents p  q = 1  . . .   D that predict whether one document is more relevant than
the other for a given input query x. The problem can be formulated as multi-label MTL with 0-1
loss: for a given training query x only some labels yp q ∈ {−1  0  1} are available in output (with
1 corresponding to document p being more relevant than q  −1 the opposite and 0 that the two are
equivalent). We have therefore T separate training sets  one for each task (i.e. pair of documents).
Clearly  not all possible combinations of outputs f : X → {−1  0  1}T are allowed since predictions
need to be consistent (e.g. if p (cid:31) q (read “p more relevant than q”) and q (cid:31) r  then we cannot have
r (cid:31) p). As shown in [37] these constraints are naturally encoded in a set DAG(D) in RT of all
vectors G ∈ RT that correspond to (the vectorized  upper triangular part of the adjacency matrix of)
a Directed Acyclic Graph with D vertices. The problem can be cast in our nonlinear MTL framework
with f : X → C = DAG(D) (see Appendix for details on how to perform the projection onto C).
We performed experiments on Movielens100k [40] (movies = documents  users = queries) to
compare our NL-MTL estimator with both standard MTL baselines as well as methods designed for
ranking problems. We used the (linear) input kernel and the train  validation and test splits adopted in
[21] to perform 10 independent trials with 5-fold cross-validation for model selection. Tab. 2 reports
the average ranking error and standard deviation of the (weighed) 0-1 loss function considered in
[37  21] for the ranking methods proposed in [38  39  37]  the SVMStruct estimator [20]  the SELF
estimator considered in [21] for ranking  the MTRL and STL baseline  corresponding to individual
SVMs trained for each pairwise comparison. Results for previous methods are reported from [21].
NL-MTL outperforms all competitors  achieving better performance than the the original SELF
estimator. For the sake of brevity we refer to the Appendix for more details on the experiments.
Acknowledgments. This work was supported in part by EPSRC grant EP/P009069/1.

9

References
[1] Sebastian Thrun and Lorien Pratt. Learning to learn. Springer Science & Business Media  2012.
[2] Mauricio A. Álvarez  Neil Lawrence  and Lorenzo Rosasco. Kernels for vector-valued functions: a review.

Foundations and Trends in Machine Learning  4(3):195–266  2012.

[3] Andreas Argyriou  Theodoros Evgeniou  and Massimiliano Pontil. Multi-task feature learning. Advances

in neural information processing systems  19:41  2007.

[4] Sinno Jialin Pan and Qiang Yang. A survey on transfer learning. IEEE Transactions on knowledge and

data engineering  22(10):1345–1359  2010.

[5] Charles A Micchelli and Massimiliano Pontil. Kernels for multi–task learning. In Advances in Neural

Information Processing Systems  pages 921–928  2004.

[6] Christopher M Bishop. Machine learning and pattern recognition. Information Science and Statistics.

Springer  Heidelberg  2006.

[7] Andreas Maurer and Massimiliano Pontil. Excess risk bounds for multitask learning with trace norm

regularization. In Conference on Learning Theory (COLT)  volume 30  pages 55–76  2013.

[8] Andreas Maurer  Massimiliano Pontil  and Bernardino Romera-Paredes. The beneﬁt of multitask represen-

tation learning. Journal of Machine Learning Research  17(81):1–32  2016.

[9] Theodoros Evgeniou  Charles A. Micchelli  and Massimiliano Pontil. Learning multiple tasks with kernel

methods. In Journal of Machine Learning Research  pages 615–637  2005.

[10] Laurent Jacob  Francis Bach  and Jean-Philippe Vert. Clustered multi-task learning: a convex formulation.

Advances in Neural Information Processing Systems  2008.

[11] Yu Zhang and Dit-Yan Yeung. A convex formulation for learning task relationships in multi-task learning.

In Conference on Uncertainty in Artiﬁcial Intelligence (UAI)  2010.

[12] Francesco Dinuzzo  Cheng S. Ong  Peter V. Gehler  and Gianluigi Pillonetto. Learning output kernels with

block coordinate descent. International Conference on Machine Learning  2011.

[13] Pratik Jawanpuria and J Saketha Nath. A convex feature learning formulation for latent task structure

discovery. International Conference on Machine Learning  2012.

[14] Carlo Ciliberto  Youssef Mroueh  Tomaso A Poggio  and Lorenzo Rosasco. Convex learning of multiple

tasks and their structure. In International Conference on Machine Learning (ICML)  2015.

[15] Carlo Ciliberto  Lorenzo Rosasco  and Silvia Villa. Learning multiple visual tasks while discovering their
structure. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition  pages
131–139  2015.

[16] Pratik Jawanpuria  Maksim Lapin  Matthias Hein  and Bernt Schiele. Efﬁcient output kernel learning for

multiple tasks. In Advances in Neural Information Processing Systems  pages 1189–1197  2015.

[17] Florian Steinke and Matthias Hein. Non-parametric regression between manifolds. In Advances in Neural

Information Processing Systems  pages 1561–1568  2009.

[18] Arvind Agarwal  Samuel Gerber  and Hal Daume. Learning multiple tasks using manifold regularization.

In Advances in neural information processing systems  pages 46–54  2010.

[19] Thomas Hofmann Bernhard Schölkopf Alexander J. Smola Ben Taskar Bakir  Gökhan and S.V.N Vish-

wanathan. Predicting structured data. MIT press  2007.

[20] Ioannis Tsochantaridis  Thorsten Joachims  Thomas Hofmann  and Yasemin Altun. Large margin methods

for structured and interdependent output variables. In Journal of Machine Learning Research  2005.

[21] Carlo Ciliberto  Lorenzo Rosasco  and Alessandro Rudi. A consistent regularization approach for structured

prediction. Advances in Neural Information Processing Systems 29 (NIPS)  pages 4412–4420  2016.

[22] Carl Edward Rasmussen and Christopher K. I. Williams. Gaussian processes for machine learning. The

MIT Press  2006.

[23] Lorenzo Sciavicco and Bruno Siciliano. Modeling and control of robot manipulators  volume 8. McGraw-

Hill New York  1996.

[24] Sebastian Nowozin  Christoph H Lampert  et al. Structured learning and prediction in computer vision.

Foundations and Trends in Computer Graphics and Vision  2011.

[25] Bernhard Schölkopf and Alexander J Smola. Learning with kernels: support vector machines  regulariza-

tion  optimization  and beyond. MIT press  2002.

[26] Thomas H Cormen. Introduction to algorithms. MIT press  2009.
[27] Suvrit Sra and Reshad Hosseini. Geometric optimization in machine learning. In Algorithmic Advances in

Riemannian Geometry and Applications  pages 73–91. Springer  2016.

10

[28] Hongyi Zhang  Sashank J. Reddi  and Suvrit Sra. Riemannian svrg: Fast stochastic optimization on

riemannian manifolds. In Advances in Neural Information Processing Systems 29. 2016.

[29] Florian Steinke  Matthias Hein  and Bernhard Schölkopf. Nonparametric regression between general

riemannian manifolds. SIAM Journal on Imaging Sciences  3(3):527–563  2010.

[30] Ingo Steinwart and Andreas Christmann. Support Vector Machines. Information Science and Statistics.

Springer New York  2008.

[31] Peter L Bartlett  Michael I Jordan  and Jon D McAuliffe. Convexity  classiﬁcation  and risk bounds.

Journal of the American Statistical Association  101(473):138–156  2006.

[32] Andrea Caponnetto and Ernesto De Vito. Optimal rates for the regularized least-squares algorithm.

Foundations of Computational Mathematics  7(3):331–368  2007.

[33] Vikas Sindhwani  Aurelie C. Lozano  and Ha Quang Minh. Scalable matrix-valued kernel learning and

high-dimensional nonlinear causal inference. CoRR  abs/1210.4792  2012.

[34] Rob Fergus  Hector Bernal  Yair Weiss  and Antonio Torralba. Semantic label sharing for learning with

many categories. European Conference on Computer Vision  2010.

[35] Guillaume Obozinski  Ben Taskar  and Michael I Jordan. Joint covariate selection and joint subspace

selection for multiple classiﬁcation problems. Statistics and Computing  20(2):231–252  2010.

[36] Theodoros Evgeniou and Massimiliano Pontil. Regularized multi–task learning. In Proceedings of the

tenth ACM SIGKDD international conference on Knowledge discovery and data mining. ACM  2004.

[37] John C Duchi  Lester W Mackey  and Michael I Jordan. On the consistency of ranking algorithms. In
Proceedings of the 27th International Conference on Machine Learning (ICML-10)  pages 327–334  2010.
[38] Ralf Herbrich  Thore Graepel  and Klaus Obermayer. Large margin rank boundaries for ordinal regression.

Advances in neural information processing systems  pages 115–132  1999.

[39] Ofer Dekel  Yoram Singer  and Christopher D Manning. Log-linear models for label ranking. In Advances

in neural information processing systems  page None  2004.

[40] F Maxwell Harper and Joseph A Konstan. The movielens datasets: History and context. ACM Transactions

on Interactive Intelligent Systems (TiiS)  5(4):19  2015.

11

,Kevin Scaman
Rémi Lemonnier
Nicolas Vayatis
Carlo Ciliberto
Alessandro Rudi
Lorenzo Rosasco
Massimiliano Pontil