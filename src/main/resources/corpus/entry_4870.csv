2014,Scalable Inference for Neuronal Connectivity from Calcium Imaging,Fluorescent calcium imaging provides a potentially powerful tool for inferring connectivity in neural circuits with up to thousands of neurons. However  a key challenge in using calcium imaging for connectivity detection is that current systems often have a temporal response and frame rate that can be orders of magnitude slower than the underlying neural spiking process. Bayesian inference based on expectation-maximization (EM) have been proposed to overcome these limitations  but they are often computationally demanding since the E-step in the EM procedure typically involves state estimation in a high-dimensional nonlinear dynamical system. In this work  we propose a computationally fast method for the state estimation based on a hybrid of loopy belief propagation and approximate message passing (AMP). The key insight is that a neural system as viewed through calcium imaging can be factorized into simple scalar dynamical systems for each neuron with linear interconnections between the neurons. Using the structure  the updates in the proposed hybrid AMP methodology can be computed by a set of one-dimensional state estimation procedures and linear transforms with the connectivity matrix. This yields a computationally scalable method for inferring connectivity of large neural circuits. Simulations of the method on realistic neural networks demonstrate good accuracy with computation times that are potentially significantly faster than current approaches based on Markov Chain Monte Carlo methods.,Scalable Inference for Neuronal Connectivity from

Calcium Imaging

Alyson K. Fletcher

Sundeep Rangan

Abstract

Fluorescent calcium imaging provides a potentially powerful tool for inferring
connectivity in neural circuits with up to thousands of neurons. However  a key
challenge in using calcium imaging for connectivity detection is that current sys-
tems often have a temporal response and frame rate that can be orders of magni-
tude slower than the underlying neural spiking process. Bayesian inference meth-
ods based on expectation-maximization (EM) have been proposed to overcome
these limitations  but are often computationally demanding since the E-step in the
EM procedure typically involves state estimation for a high-dimensional nonlin-
ear dynamical system. In this work  we propose a computationally fast method
for the state estimation based on a hybrid of loopy belief propagation and approx-
imate message passing (AMP). The key insight is that a neural system as viewed
through calcium imaging can be factorized into simple scalar dynamical systems
for each neuron with linear interconnections between the neurons. Using the struc-
ture  the updates in the proposed hybrid AMP methodology can be computed by a
set of one-dimensional state estimation procedures and linear transforms with the
connectivity matrix. This yields a computationally scalable method for inferring
connectivity of large neural circuits. Simulations of the method on realistic neural
networks demonstrate good accuracy with computation times that are potentially
signiﬁcantly faster than current approaches based on Markov Chain Monte Carlo
methods.

1

Introduction

Determining connectivity in populations of neurons is fundamental to understanding neural com-
putation and function. In recent years  calcium imaging has emerged as a promising technique for
measuring synaptic activity and mapping neural micro-circuits [1–4]. Fluorescent calcium-sensitive
dyes and genetically-encoded calcium indicators can be loaded into neurons  which can then be im-
aged for spiking activity either in vivo or in vitro. Current methods enable imaging populations of
hundreds to thousands of neurons with very high spatial resolution. Using two-photon microscopy 
imaging can also be localized to speciﬁc depths and cortical layers [5]. Calcium imaging also has
the potential to be combined with optogenetic stimulation techniques such as in [6].
However  inferring neural connectivity from calcium imaging remains a mathematically and com-
putationally challenging problem. Unlike anatomical methods  calcium imaging does not directly
measure connections. Instead  connections must be inferred indirectly from statistical relationships
between spike activities of different neurons. In addition  the measurements of the spikes from cal-
cium imaging are indirect and noisy. Most importantly  the imaging introduces signiﬁcant temporal
blurring of the spike times: the typical time constants for the decay of the ﬂuorescent calcium con-
centration  [Ca2+]  can be on the order of a second – orders of magnitude slower than the spike rates
and inter-neuron dynamics. Moreover  the calcium imaging frame rate remains relatively slow –
often less than 100 Hz. Hence  determining connectivity typically requires super-resolution of spike
times within the frame period.

1

To overcome these challenges  the recent work [7] proposed a Bayesian inference method to esti-
mate functional connectivity from calcium imaging in a systematic manner. Unlike “model-free”
approaches such as in [8]  the method in [7] assumed a detailed functional model of the neural dy-
namics with unknown parameters including a connectivity weight matrix W. The model parameters
including the connectivity matrix can then be estimated via a standard EM procedure [9]. While the
method is general  one of the challenges in implementing it is the computational complexity. As
we discuss below  the E-step in the EM procedure essentially requires estimating the distributions
of hidden states in a nonlinear dynamical system whose state dimension grows linearly with the
number of neurons. Since exact computation of these densities grows exponentially in the state di-
mension  [7] uses an approximate method based on blockwise Gibbs sampling where each block of
variables consists of the hidden states associated with one neuron. Since the variables within a block
are described as a low-dimensional dynamical system  the updates of the densities for the Gibbs
sampling can be computed efﬁciently via a standard particle ﬁlter [10  11]. However  simulations of
the method show that the mixing between blocks can still take considerable time to converge.
This paper provides a novel method that can potentially signiﬁcantly improve the computation time
of the state estimation. The key insight is to recognize that a high-dimensional neural system can be
“factorized” into simple  scalar dynamical systems for each neuron with linear interactions between
the neurons. As described below  we assume a standard leaky integrate-and-ﬁre model for each
neuron [12] and a ﬁrst-order AR process for the calcium imaging [13]. Under this model  the
dynamics of N neurons can be described by 2N systems  each with a scalar (i.e. one-dimensional)
state. The coupling between the systems will be linear as described by the connectivity matrix
W. Using this factorization  approximate state estimation can then be efﬁciently performed via
approximations of loopy belief propagation (BP) [14]. Speciﬁcally  we show that the loopy BP
updates at each of the factor nodes associated with the integrate-and-ﬁre and calcium imaging can
be performed via a scalar standard forward–backward ﬁlter. For the updates associated with the
linear transform W  we use recently-developed approximate message passing (AMP) methods.
AMP was originally proposed in [15] for problems in compressed sensing. Similar to expectation
propagation [16]  AMP methods use Gaussian and quadratic approximations of loopy BP but with
further simpliﬁcations that leverage the linear interactions. AMP was used for neural mapping from
multi-neuron excitation and neural receptive ﬁeld estimation in [17  18]. Here  we use a so-called
hybrid AMP technique proposed in [19] that combines AMP updates across the linear coupling
terms with standard loopy BP updates on the remainder of the system. When applied to the neural
system  we show that the estimation updates become remarkably simple: For a system with N
neurons  each iteration involves running 2N forward–backward scalar state estimation algorithms 
along with multiplications by W and WT at each time step. The practical complexity scales as
O(N T ) where T is the number of time steps. We demonstrate that the method can be signiﬁcantly
faster than the blockwise Gibbs sampling proposed in [7]  with similar accuracy.

2 System Model

We consider a recurrent network of N spontaneously ﬁring neurons. All dynamics are approximated
in discrete time with some time step ∆  with a typical value ∆ = 1 ms. Importantly  this time step
is typically smaller than the calcium imaging period  so the model captures the dynamics between
observations. Time bins are indexed by k = 0  . . .   T −1  where T is the number of time bins so that
T ∆ is the total observation time in seconds. Each neuron i generates a sequence of spikes (action
potentials) indicated by random variables sk
i taking values 0 or 1 to represent whether there was a
spike in time bin k or not. It is assumed that the discretization step ∆ is sufﬁciently small such that
there is at most one action potential from a neuron in any one time bin. The spikes are generated
via a standard leaky integrate-and-ﬁre (LIF) model [12] where the (single compartment) membrane
voltage vk

i evolve as

i of each neuron i and its corresponding spike output sequence sk
i = (1 − αIF )vk
˜vk+1

Wijsk−δ

j + bIF i 

qk
i =

i + qk

i + dk
vi

 

N(cid:88)
(cid:26)(˜vk

j=1

2

and

(vk+1

i

  sk+1

i

) =

i   0)
(0  1)

if vk
if ˜vk

i < µ 
i ≥ µ 

dk
vi

∼ N (0  τIF ) 

(1)

(2)

where αIF is a time constant for the integration leakage; µ is the threshold potential at which the
i is the increase in the membrane potential from the
neurons spikes; bIF i is a constant bias term; qk
pre-synaptic spikes from other neurons and dk
vi is a noise term including both thermal noise and
currents from other neurons that are outside the observation window. The voltage has been scaled
so that the reset voltage is zero. The parameter δ is the integer delay (in units of the time step
∆) between the spike in one neuron and the increase in the membrane voltage in the post-synaptic
neuron. An implicit assumption in this model is the post-synaptic current arrives in a single time bin
with a ﬁxed delay.
To determine functional connectivity  the key parameter to estimate will be the matrix W of the
weighting terms Wij in (1). Each parameter Wij represents the increase in the membrane voltage in
neuron i due to the current triggered from a spike in neuron j. The connectivity weight Wij will be
zero whenever neuron j has no connection to neuron i. Thus  determining W will determine which
neurons are connected to one another and the strengths of those connections.
For the calcium imaging  we use a standard model [7]  where the concentration of ﬂuorescent Cal-
cium has a fast initial rise upon an action potential followed by a slow exponential decay. Speciﬁ-
i = [Ca2+]k be the concentration of ﬂuorescent Calcium in neuron i in time bin k and
cally  we let zk
assume it evolves as ﬁrst-order auto-regressive AR(1) model 
i + sk
i  

(3)
where αCA is the Calcium time constant. The observed net ﬂuorescence level is then given by a
noisy version of zk
i  

i = (1 − αCA i)zk
zk+1

i = aCA izk
yk

i + bCA i + dk
yi

(4)
where aCA i and bCA i are constants and dyi is white Gaussian noise with variance τy. Nonlinearities
such as saturation described in [13] can also be modeled.
As mentioned in the Introduction  a key challenge in calcium imaging is the relatively slow frame
rate which has the effect of subsampling of the ﬂuorescence. To model the subsampling  we
let IF denote the set of time indices k on which we observe F k
i . We will assume that ﬂu-
orescence values are observed once every TF time steps for some integer period TF so that
IF = {0  TF   2TF   . . .   KTF} where K is the number of Calcium image frames.

∼ N (0  τy) 

 

dk
yi

3 Parameter Estimation via Message Passing

3.1 Problem Formulation

Let θ be set of all the unknown parameters 

θ = {W  τIF   τCA  αIF   bIF i  αCA  aCA i  bCA i  i = 1  . . .   N} 

(5)
which includes the connectivity matrix  time constants and various variances and bias terms. Esti-
mating the parameter set θ will provide an estimate of the connectivity matrix W  which is our main
goal.
To estimate θ  we consider a regularized maximum likelihood (ML) estimate
L(y|θ) + φ(θ)  L(y|θ) = − log p(y|θ) 

(cid:98)θ = arg max
y = {y1  . . .   yN}   yi =(cid:8)yk

(6)
where y is the set of observed values; L(y|θ) is the negative log likelihood of y given the parameters
θ and φ(θ) is some regularization function. For the calcium imaging problem  the observations y
are the observed ﬂuorescence values across all the neurons 
i  

(7)
where yi is the set of ﬂuorescence values from neuron i  and  as mentioned above  IF is the set of
time indices k on which the ﬂuorescence is sampled.
The regularization function φ(θ) can be used to impose constraints or priors on the parameters. In
this work  we will assume a simple regularizer that only constrains the connectivity matrix W 

k ∈ IF

(cid:9)  

θ

φ(θ) = λ(cid:107)W(cid:107)1 

(cid:107)W(cid:107)1 :=

|Wij| 

(8)

(cid:88)

ij

3

where λ is a positive constant. The (cid:96)1 regularizer is a standard convex function used to encourage
sparsity [20]  which we know in this case must be valid since most neurons are not connected to one
another.

3.2 EM Estimation

Exact computation of (cid:98)θ in (6) is generally intractable  since the observed ﬂuorescence values y

depend on the unknown parameters θ through a large set of hidden variables. Similar to [7]  we thus
use a standard EM procedure [9]. To apply the EM procedure to the calcium imaging problem  let
x be the set of hidden variables 

(9)
where v are the membrane voltages of the neurons  z the calcium concentrations  s the spike outputs
and q the linearly combined spike inputs. For any of these variables  we will use the subscript i (e.g.
vi) to denote the values of the variables of a particular neuron i across all time steps and superscript
k (e.g. vk) to denote the values across all neurons at a particular time step k. Thus  for the membrane
voltage

x = {v  z  q  s}  

v =(cid:8)vk

(cid:9)   vk =(cid:0)vk

i

1   . . .   vk
N

(cid:1)   vi =(cid:0)v0

i   . . .   vT−1

i

(cid:1) .

The EM procedure alternately estimates distributions on the hidden variables x given the current
parameter estimate for θ (the E-step); and then updates the estimates for parameter vector θ given
the current distribution on the hidden variables x (the M-step).

(10)
which is the posterior distribution of the hidden variables x given the observations y and

• E-Step: Given parameter estimates(cid:98)θ(cid:96)  estimate
P (x|y (cid:98)θ(cid:96)) 
current parameter estimate(cid:98)θ(cid:96).
E(cid:104)
L(x  y|θ)|(cid:98)θ(cid:96)(cid:105)

• M-step Update the parameter estimate via the minimization 

(cid:98)θ(cid:96)+1 = arg min

where L(x  y|θ) is the joint negative log likelihood 

θ

+ φ(θ) 

(11)

(12)
In (11) the expectation is with respect to the distribution found in (10) and φ(θ) is the
parameter regularization function.

L(x  y|θ) = − log p(x  y|θ).

The next two sections will describe how we approximately perform each of these steps.

3.3 E-Step estimation via Approximate Message Passing

i and N states for the bound Ca concentration levels zk

For the calcium imaging problem  the challenging step of the EM procedure is the E-step  since
the hidden variables x to be estimated are the states and outputs of a high-dimensional nonlinear
dynamical system. Under the model in Section 2  a system with N neurons will require N states
i   resulting in
for the membrane voltages vk
a total state dimension of 2N. The E-step for this system is essentially a state estimation problem 
and exact inference of the states of a general nonlinear dynamical system grows exponentially in the
state dimension. Hence  exact computation of the posterior distribution (10) for the system will be
intractable even for a moderately sized network.
As described in the Introduction  we thus use an approximate messaging passing method that ex-
ploits the separable structure of the system. For the remainder of this section  we will assume the

parameters θ in (5) are ﬁxed to the current parameter estimate(cid:98)θ(cid:96). Then  under the assumptions of

Section 2  the joint probability distribution function of the variables can be written in a factorized
form 

P (x  y) = P (q  v  s  z  y) =

1
Z

1{qk=Wsk}

ψIF

i

(qi  vi  si)ψCA

i

(si  zi  yi) 

(13)

T−1(cid:89)

N(cid:89)

k=0

i=1

4

membrane voltage

vi

Ca2+ concentration

zi

input currents

qi

ψIF
(qi  vi  si)
Integrate-and-ﬁre

i

dynamics

spike outputs

si

ψCA

(si  zi  yi)

i
Ca imaging
dynamics

observed

ﬂuorescence

yi

Neuron i  i = 1  . . .   N

qk = Wsk
Connectivity

between neurons

Time step k  k = 0  . . .   T −1

Figure 1: Factor graph plate representation of the system where the spike dynamics are described
by the factor node ψIF
(qi  vi  si) and the calcium image dynamics are represented via the factor
node ψCA
(si  zi  yi). The high-dimensional dynamical system is described as 2N scalar dynamical
systems (2 for each neuron) with linear interconnections  qk = Wsk between the neurons. A
computational efﬁcient approximation of loopy BP [19] is applied to this graph for approximate
Bayesian inference required in the E-step of the EM algorithm.

i

i

i

i

(qi  vi  si) is the potential function relating the summed
where Z is a normalization constant; ψIF
spike inputs qi to the membrane voltages vi and spike outputs si; ψCA
(si  zi  yi) relates the spike
outputs si to the bound calcium concentrations zi and observed ﬂuorescence values yi; and the term
1{qk=Wsk} indicates that the distribution is to be restricted to the set satisfying the linear constraints
qk = Wsk across all time steps k.
As in standard loopy BP [14]  we represent the distribution (13) in a factor graph as shown in
Fig. 1. Now  for the E-step  we need to compute the marginals of the posterior distribution p(x|y)
from the joint distribution (13). Using the factor graph representation  loopy BP iteratively updates
estimates of these marginal posterior distributions using a message passing procedure  where the
estimates of the distributions (called beliefs) are passed between the variable and factor nodes in
the graph. In general  the computationally challenging component of loopy BP is the updates on
the belief messages at the factor nodes. However  using the factorized structure in Fig. 1 along
with approximate message passing (AMP) simpliﬁcations as described in [19]  these updates can be
computed easily.
Details are given in the full paper [21]  but the basic procedure for the factor node updates and the
reasons why these computations are simple can be summarized as follows. At a high level  the factor
graph structure in Fig. 1 partitions the 2N-dimensional nonlinear dynamical system into N scalar
systems associated with each membrane voltage vk
i and an additional N scalar systems associated
i . The only coupling between these systems is through the
with each calcium concentration level zk
linear relationships qk = Wsk. As shown in Appendix ??  on each of the scalar systems  the factor
node updates required by loopy BP essentially reduces to a state estimation problem for this system.
Since the state space of this system is scalar (i.e. one-dimensional)  we can discretize the state space
well with a small number of points – in the experiments below we use L = 20 points per dimension.
Once discretized  the state estimation can be performed via a standard forward–backward algorithm.
If there are T time steps  the algorithm will have a computational cost of O(T L2) per scalar system.
Hence  all the factor node updates across all the 2N scalar systems has total complexity O(N T L2).
For the factor nodes associated with the linear constraints qk = Wsk  we use the AMP approxi-
mations [19]. In this approximation  the messages for the transform outputs qk
i are approximated as
Gaussians which is  at least heuristically  justiﬁed since the they are outputs of a linear transform of
a large number of variables  sk
i . In the AMP algorithm  the belief updates for the variables qk and
sk can then be computed simply by linear transformations of W and WT . Since W represents a
connectivity matrix  it is generally sparse. If each row of W has d non-zero values  multiplication

5

by W and WT will be O(N d). Performing the multiplications across all time steps results in a total
complexity of O(N T d).
Thus  the total complexity of the proposed E-step estimation method is O(N T L2 + N T d) per loopy
BP iteration. We typically use a small number of loopy BP iterations per EM update (in fact  in the
experiments below  we found reasonable performance with one loopy BP update per EM update).
In summary  we see that while the overall neural system is high-dimensional  it has a linear + scalar
structure. Under the assumption of the bounded connectivity d  this structure enables an approximate
inference strategy that scales linearly with the number of neurons N and time steps T . Moreover 
the updates in different scalar systems can be computed separately allowing a readily parallelizable
implementation.

3.4 Approximate M-step Optimization

The M-step (11) is computationally relatively simple. All the parameters in θ in (5) have a linear
relationship between the components of the variables in the vector x in (9). For example  the pa-
rameters aCA i and bCA i appear in the ﬂuorescence output equation (4). Since the noise dk
yi in this
equation is Gaussian  the negative log likelihood (12) is given by

L(x  y|θ) =

1
2τyi

i − aCA izk
(yk

i − bCA i)2 +

T
2

log(τyi) + other terms 

where “other terms” depend on parameters other than aCA i and bCA i.

E(L(x  y|θ)|(cid:98)θ(cid:96)) will then depend only on the mean and variance of the variables yk

The expectation
i   which
i and zk
are provided by the E-step estimation. Thus  the M-step optimization in (11) can be computed via a
simple least-squares problem. Using the linear relation (1)  a similar method can be used for αIF i
and bIF i  and the linear relation (3) can be used to estimate the calcium time constant αCA.
To estimate the connectivity matrix W  let rk = qk − Wsk so that the constraints in (13) is equiva-
lent to the condition that rk = 0. Thus  the term containing W in the expectation of the negative log

likelihood E(L(x  y|θ)|(cid:98)θ(cid:96)) is given by the negative log probability density of rk evaluated at zero.
imate the density as follows: Let(cid:98)q and(cid:98)s be the expectation of the variables q and s given by the
E-step. Hence  the expectation of rk is(cid:98)qk − W(cid:98)sk. As a simple approximation  we will then assume

In general  this density will be a complex function of W and difﬁcult to minimize. So  we approx-

that the variables rk
simplifying assumption  the M-step optimization of W with the (cid:96)1 regularizer (8) reduces to

i are Gaussian  independent and having some constant variance σ2. Under this

(cid:99)W = arg min

W

T−1(cid:88)

k=0

1
2

(cid:107)(cid:98)qk − W(cid:98)sk(cid:107)2 + σ2λ(cid:107)W(cid:107)1 

(cid:88)

k∈IF

(14)

For a given value of σ2λ  the optimization (14) is a standard LASSO optimization [22] which can be
evaluated efﬁciently via a number of convex programming methods. In this work  in each M-step 
we adjust the regularization parameter σ2λ to obtain a desired ﬁxed sparsity level in the solution W.

3.5

Initial Estimation via Sparse Regression

Since the EM algorithm cannot be guaranteed to converge a global maxima  it is important to pick
the initial parameter estimates carefully. The time constants and noise levels for the calcium image
can be extracted from the second-order statistics of ﬂuorescence values and simple thresholding can
provide a coarse estimate of the spike rate.
The key challenge is to obtain a good estimate for the connectivity matrix W. For each neuron i  we
i = 1|yi) from the observed ﬂuorescence
ﬁrst make an initial estimate of the spike probabilities P (sk
values yi  assuming some i.i.d. prior of the form P (st
i) = λ∆  where λ is the estimated average spike
rate per second. This estimation can be solved with the ﬁltering method in [13] and is also equivalent
to the method we use for the factor node updates. We can then threshold these probabilities to make
a hard initial decision on each spike: sk
i = 0 or 1. We then propose to estimate W from the spikes
as follows. Fix a neuron i and let wi be the vector of weights Wij  j = 1  . . .   N. Under the
assumption that the initial spike sequence sk
i is exactly correct  it is shown in the full paper [21]  that

6

Parameter
Number of neurons  N
Connection sparsity

Mean ﬁring rate per neuron
Simulation time step  ∆
Total simulation time  T ∆
Integration time constant  αIF
Conduction delay  δ
Integration noise  dk
vi
Ca time constant  αCA
Fluorescence noise  τCA
Ca frame rate   1/TF

Value
100
10% with random connections. All connections are excitatory
with the non-zero weights Wij being exponentially distributed.
10 Hz
1 ms
10 sec (10 000 time steps)
20 ms
2 time steps = 2 ms
Produced from two unobserved neurons.
500 ms
Set to 20 dB SNR
100 Hz

Table 1: Parameters for the Ca image simulation.

Figure 2: Typical network simulation
trace. Top panel: Spike traces for
the 100 neuron simulated network.
Bottom panel: Calcium image ﬂu-
orescence levels. Due to the ran-
dom network topology  neurons often
ﬁre together  signiﬁcantly complicat-
ing connectivity detection. Also  as
seen in the lower panel  the slow de-
cay of the ﬂuorescent calcium blurs
the spikes in the calcium image.

a regularized maximum likelihood estimate of wi and bias term bIF i is given by

((cid:98)wi (cid:98)bIF i) = arg min

wi bIF i

T−1(cid:88)

Lik(uT

k wi + cikbIF i − µ  sk

i ) + λ

|Wij| 

(15)

k=0

j=1

N(cid:88)

where Lik is a probit loss function and the vector uk and scalar cik can be determined from the
spike estimates. The optimization (15) is precisely a standard probit regression used in sparse linear
classiﬁcation [23]. This form arises due to the nature of the leaky integrate-and-ﬁre model (1) and
(2). Thus  assuming the initial spike sequences are estimated reasonably accurately  one can obtain
good initial estimates for the weights Wij and bias terms bIF i by solving a standard classiﬁcation
problem.

4 Numerical Example

The method was tested using realistic network parameters  as shown in Table 1  similar to those
found in neurons networks within a cortical column [24]. Similar parameters are used in [7]. The
network consisted of 100 neurons with each neuron randomly connected to 10% of the other neu-
rons. The non-zero weights Wij were drawn from an exponential distribution. As a simpliﬁcation 
all weights were positive (i.e. the neurons were excitatory – there were no inhibitory neurons in the
simulation). A typical random matrix W generated in this manner would not in general result in a
stable system. To stabilize the system  we followed the procedure in [8] where the system is simu-
lated multiple times. After each simulation  the rows of the matrix W were adjusted up or down to
increase or decrease the spike rate until all neurons spiked at a desired target rate. In this case  we
assumed a desired average spike rate of 10 Hz.

7

Figure 3: Weight estimation accuracy. Left: Normalized mean-squared error as a function of the
iteration number. Right: Scatter plot of the true and estimated weights.

From the parameters in Table 1  we can immediately see the challenges in the estimation. Most
importantly  the calcium imaging time constant αCA is set for 500 ms. Since the average neurons
spike rate is assumed to be 10 Hz  several spikes will typically appear within a single time constant.
Moreover  both the integration time constant and inter-neuron conduction time are much smaller
than the
A typical simulation of the network after the stabilization is shown in Fig. 2. Observe that due to
the random connectivity  spiking in one neuron can rapidly cause the entire network to ﬁre. This
appears as the vertical bright stripes in the lower panel of Fig. 2. This synchronization makes the
connectivity detection difﬁcult to detect under temporal blurring of Ca imaging since it is hard to
determine which neuron is causing which neuron to ﬁre. Thus  the random matrix is a particularly
challenging test case.
The results of the estimation are shown in Fig. 3. The left panel shows the relative mean squared
error deﬁned as

(cid:80)
ij |Wij − α(cid:99)Wij|2
(cid:80)
ij |Wij|2

 

minα

where(cid:99)Wij is the estimate for the weight Wij. The minimization over all α is performed since the

relative MSE =

method can only estimate the weights up to a constant scaling. The relative MSE is plotted as a
function of the EM iteration  where we have performed only a single loopy BP iteration for each
EM iteration. We see that after only 30 iterations we obtain a relative MSE of 7% – a number at
least comparable to earlier results in [7]  but with signiﬁcantly less computation. The right panel

shows a scatter plot of the estimated weights(cid:99)Wij against the true weights Wij.

(16)

5 Conclusions

We have presented a scalable method for inferring connectivity in neural systems from calcium
imaging. The method is based on factorizing the systems into scalar dynamical systems with linear
connections. Once in this form  state estimation – the key computationally challenging component
of the EM estimation – is tractable via approximating message passing methods. The key next step
in the work is to test the methods on real data and also provide more comprehensive computational
comparisons against current techniques such as [7].

References
[1] R. Y. Tsien  “Fluorescent probes of cell signaling ” Ann. Rev. Neurosci.  vol. 12  no. 1  pp. 227–253  1989.
[2] K. Ohki  S. Chung  Y. H. Ch’ng  P. Kara  and R. C. Reid  “Functional imaging with cellular resolution

reveals precise micro-architecture in visual cortex ” Nature  vol. 433  no. 7026  pp. 597–603  2005.

[3] J. Soriano  M. R. Mart´ınez  T. Tlusty  and E. Moses  “Development of input connections in neural cul-

tures ” Proc. Nat. Acad. Sci.  vol. 105  no. 37  pp. 13 758–13 763  2008.

[4] C. Stosiek  O. Garaschuk  K. Holthoff  and A. Konnerth  “In vivo two-photon calcium imaging of neu-

ronal networks ” Proc. Nat. Acad. Sci.  vol. 100  no. 12  pp. 7319–7324  2003.

8

[5] K. Svoboda and R. Yasuda  “Principles of two-photon excitation microscopy and its applications to neu-

roscience ” Neuron  vol. 50  no. 6  pp. 823–839  2006.

[6] O. Yizhar  L. E. Fenno  T. J. Davidson  M. Mogri  and K. Deisseroth  “Optogenetics in neural systems ”

Neuron  vol. 71  no. 1  pp. 9–34  2011.

[7] Y. Mishchenko  J. T. Vogelstein  and L. Paninski  “A Bayesian approach for inferring neuronal connec-
tivity from calcium ﬂuorescent imaging data ” Ann. Appl. Stat.  vol. 5  no. 2B  pp. 1229–1261  Feb. 2011.
[8] O. Stetter  D. Battaglia  J. Soriano  and T. Geisel  “Model-free reconstruction of excitatory neuronal
connectivity from calcium imaging signals ” PLoS Computational Biology  vol. 8  no. 8  p. e1002653 
2012.

[9] A. Dempster  N. M. Laird  and D. B. Rubin  “Maximum-likelihood from incomplete data via the EM

algorithm ” J. Roy. Statist. Soc.  vol. 39  pp. 1–17  1977.

[10] A. Doucet  S. Godsill  and C. Andrieu  “On sequential Monte Carlo sampling methods for Bayesian

ﬁltering ” Statistics and Computing  vol. 10  no. 3  pp. 197–208  2000.

[11] A. Doucet and A. M. Johansen  “A tutorial on particle ﬁltering and smoothing: Fifteen years later ”

Handbook of Nonlinear Filtering  vol. 12  pp. 656–704  2009.

[12] P. Dayan and L. F. Abbott  Theoretical Neuroscience. Computational and Mathematical Modeling of

Neural Systems. MIT Press  2001.

[13] J. T. Vogelstein  B. O. Watson  A. M. Packer  R. Yuste  B. Jedynak  and L. Paninski  “Spike inference
from calcium imaging using sequential monte carlo methods ” Biophysical J.  vol. 97  no. 2  pp. 636–655 
2009.

[14] M. J. Wainwright and M. I. Jordan  “Graphical models  exponential families  and variational inference ”

Found. Trends Mach. Learn.  vol. 1  2008.

[15] D. L. Donoho  A. Maleki  and A. Montanari  “Message-passing algorithms for compressed sensing ”

Proc. Nat. Acad. Sci.  vol. 106  no. 45  pp. 18 914–18 919  Nov. 2009.

[16] T. P. Minka  “A family of algorithms for approximate Bayesian inference ” Ph.D. dissertation  Mas-

sachusetts Institute of Technology  Cambridge  MA  2001.

[17] A. K. Fletcher  S. Rangan  L. Varshney  and A. Bhargava  “Neural reconstruction with approximate mes-

sage passing (NeuRAMP) ” in Proc. Neural Information Process. Syst.  Granada  Spain  Dec. 2011.

[18] U. S. Kamilov  S. Rangan  A. K. Fletcher  and M. Unser  “Approximate message passing with consistent

parameter estimation and applications to sparse learning ” in Proc. NIPS  Lake Tahoe  NV  Dec. 2012.

[19] S. Rangan  A. K. Fletcher  V. K. Goyal  and P. Schniter  “Hybrid generalized approximation message
passing with applications to structured sparsity ” in Proc. IEEE Int. Symp. Inform. Theory  Cambridge 
MA  Jul. 2012  pp. 1241–1245.

[20] D. L. Donoho  “Compressed sensing ” IEEE Trans. Inform. Theory  vol. 52  no. 4  pp. 1289–1306  Apr.

2006.

[21] A. K. Fletcher and S. Rangan  “Scalable inference for neuronal connectivity from calcium imaging ”

arXiv:1409.0289  Sep. 2014.

[22] R. Tibshirani  “Regression shrinkage and selection via the lasso ” J. Royal Stat. Soc.  Ser. B  vol. 58  no. 1 

pp. 267–288  1996.

[23] C. M. Bishop  Pattern Recognition and Machine Learning  ser. Information Science and Statistics. New

York  NY: Springer  2006.

[24] R. Sayer  M. Friedlander  and S. Redman  “The time course and amplitude of EPSPs evoked at synapses
between pairs of CA3/CA1 neurons in the hippocampal slice ” J. Neuroscience  vol. 10  no. 3  pp. 826–
836  1990.

9

,Alyson Fletcher
Sundeep Rangan
Maria-Florina Balcan
Hongyang Zhang