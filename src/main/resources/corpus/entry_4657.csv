2013,Regularized M-estimators with nonconvexity: Statistical and algorithmic theory for local optima,We establish theoretical results concerning all local optima of various regularized M-estimators  where both loss and penalty functions are allowed to be nonconvex. Our results show that as long as the loss function satisfies restricted strong convexity and the penalty function satisfies suitable regularity conditions  any local optimum of the composite objective function lies within statistical precision of the true parameter vector. Our theory covers a broad class of nonconvex objective functions  including corrected versions of the Lasso for errors-in-variables linear models; regression in generalized linear models using nonconvex regularizers such as SCAD and MCP; and graph and inverse covariance matrix estimation. On the optimization side  we show that a simple adaptation of composite gradient descent may be used to compute a global optimum up to the statistical precision epsilon in log(1/epsilon) iterations  which is the fastest possible rate of any first-order method. We provide a variety of simulations to illustrate the sharpness of our theoretical predictions.,Regularized M-estimators with nonconvexity:

Statistical and algorithmic theory for local optima

Po-Ling Loh

Department of Statistics

University of California  Berkeley

Berkeley  CA 94720

ploh@berkeley.edu

Martin J. Wainwright

Departments of Statistics and EECS
University of California  Berkeley

Berkeley  CA 94720

wainwrig@stat.berkeley.edu

Abstract

We establish theoretical results concerning local optima of regularized M-
estimators  where both loss and penalty functions are allowed to be nonconvex.
Our results show that as long as the loss satisﬁes restricted strong convexity and
the penalty satisﬁes suitable regularity conditions  any local optimum of the com-
posite objective lies within statistical precision of the true parameter vector. Our
theory covers a broad class of nonconvex objective functions  including corrected
versions of the Lasso for errors-in-variables linear models and regression in gen-
eralized linear models using nonconvex regularizers such as SCAD and MCP. On
the optimization side  we show that a simple adaptation of composite gradient de-
scent may be used to compute a global optimum up to the statistical precision stat
in log(1/stat) iterations  the fastest possible rate for any ﬁrst-order method. We
provide simulations to illustrate the sharpness of our theoretical predictions.

1

Introduction

Optimization of nonconvex functions is known to be computationally intractable in general [11  12].
Unlike convex functions  nonconvex functions may possess local optima that are not global optima 
and standard iterative methods such as gradient descent and coordinate descent are only guaranteed
to converge to local optima. Although statistical results regarding nonconvex M-estimation often
only provide guarantees about the accuracy of global optima  it is observed empirically that the local
optima obtained by various estimation algorithms seem to be well-behaved.
In this paper  we study the question of whether it is possible to certify “good” behavior  in both a
statistical and computational sense  for various nonconvex M-estimators. On the statistical level 
we provide an abstract result  applicable to a broad class of (potentially nonconvex) M-estimators 
which bounds the distance between any local optimum and the unique minimum of the population
risk. Although local optima of nonconvex objectives may not coincide with global optima  our
theory shows that any local optimum is essentially as good as a global optimum from a statistical
perspective. The class of M-estimators covered by our theory includes the modiﬁed Lasso as a
special case  but our results are much stronger than those implied by previous work [6].
In addition to nonconvex loss functions  our theory also applies to nonconvex regularizers  shedding
new light on a long line of recent work involving the nonconvex SCAD and MCP regularizers [3  2 
13  14]. Various methods have been proposed for optimizing convex loss functions with nonconvex
penalties [3  4  15]  but these methods are only guaranteed to generate local optima of the composite
objective  which have not been proven to be well-behaved. In contrast  our work provides a set
of regularity conditions under which all local optima are guaranteed to lie within a small ball of
the population-level minimum  ensuring that standard methods such as projected and composite
gradient descent [10] are sufﬁcient for obtaining estimators that lie within statistical error of the

1

truth. In fact  we establish that under suitable conditions  a modiﬁed form of composite gradient
descent only requires log(1/stat) iterations to obtain a solution that is accurate up to the statistical
precision stat.
Notation. For functions f (n) and g(n)  we write f (n) (cid:45) g(n) to mean that f (n) ≤ cg(n) for
some universal constant c ∈ (0 ∞)  and similarly  f (n) (cid:37) g(n) when f (n) ≥ c(cid:48)g(n) for some
universal constant c(cid:48) ∈ (0 ∞). We write f (n) (cid:16) g(n) when f (n) (cid:45) g(n) and f (n) (cid:37) g(n) hold
simultaneously. For a function h : Rp → R  we write ∇h to denote a gradient or subgradient  if it
exists. Finally  for q  r > 0  let Bq(r) denote the (cid:96)q-ball of radius r centered around 0.

2 Problem formulation

In this section  we develop some general theory for regularized M-estimators. We ﬁrst establish
notation  then discuss assumptions for nonconvex regularizers and losses studied in our paper.

2.1 Background

1 = {Z1  . . .   Zn}  drawn from a marginal distribution P over a
Given a collection of n samples Z n
space Z  consider a loss function Ln : Rp × (Z)n → R. The value Ln(β; Z n
1 ) serves as a measure
of the “ﬁt” between a parameter vector β ∈ Rp and the observed data. This empirical loss function
should be viewed as a surrogate to the population risk function L : Rp → R  given by

(cid:2)Ln(β; Z n
1 )(cid:3).

L(β) := EZ

L(β) that minimizes the population

Our goal is to estimate the parameter vector β∗ := arg min
β∈Rp
risk  assumed to be unique.
To this end  we consider a regularized M-estimator of the form

(cid:98)β ∈ arg min

{Ln(β; Z n

1 ) + ρλ(β)}  

g(β)≤R

separable across coordinates  and with a slight abuse of notation  we write ρλ(β) =(cid:80)p

(1)
where ρλ : Rp → R is a regularizer  depending on a tuning parameter λ > 0  which serves to
enforce a certain type of structure on the solution. In all cases  we consider regularizers that are
j=1 ρλ(βj).
Our theory allows for possible nonconvexity in both the loss function Ln and the regularizer ρλ.
Due to this potential nonconvexity  our M-estimator also includes a side constraint g : Rp → R+ 
which we require to be a convex function satisfying the lower bound g(β) ≥ (cid:107)β(cid:107)1  for all β ∈ Rp.
Consequently  any feasible point for the optimization problem (1) satisﬁes the constraint (cid:107)β(cid:107)1 ≤ R 
and as long as the empirical loss and regularizer are continuous  the Weierstrass extreme value

theorem guarantees that a global minimum(cid:98)β exists.

2.2 Nonconvex regularizers
We now state and discuss conditions on the regularizer  deﬁned in terms of ρλ : R → R.
Assumption 1.

(i) The function ρλ satisﬁes ρλ(0) = 0 and is symmetric around zero (i.e.  ρλ(t) = ρλ(−t)

for all t ∈ R).

(ii) On the nonnegative real line  the function ρλ is nondecreasing.
(iii) For t > 0  the function t (cid:55)→ ρλ(t)
(iv) The function ρλ is differentiable for all t (cid:54)= 0 and subdifferentiable at t = 0  with nonzero

is nonincreasing in t.

t

subgradients at t = 0 bounded by λL.

(v) There exists µ > 0 such that ρλ µ(t) := ρλ(t) + µt2 is convex.

Many regularizers that are commonly used in practice satisfy Assumption 1  including the (cid:96)1-norm 
ρλ(β) = (cid:107)β(cid:107)1  and the following commonly used nonconvex regularizers:

2

SCAD penalty: This penalty  due to Fan and Li [3]  takes the form

for |t| ≤ λ 
for λ < |t| ≤ aλ 
for |t| > aλ 
where a > 2 is a ﬁxed parameter. Assumption 1 holds with L = 1 and µ = 1

−(t2 − 2aλ|t| + λ2)/(2(a − 1)) 
(a + 1)λ2/2 

ρλ(t) :=

a−1.

λ|t| 

MCP regularizer: This penalty  due to Zhang [13]  takes the form

(cid:90) |t|

(cid:16)

0

(cid:17)

ρλ(t) := sign(t) λ ·

1 − z
λb

dz 

+

where b > 0 is a ﬁxed parameter. Assumption 1 holds with L = 1 and µ = 1
b .

(2)

(3)

2.3 Nonconvex loss functions and restricted strong convexity
Throughout this paper  we require the loss function Ln to be differentiable  but we do not require it
to be convex. Instead  we impose a weaker condition known as restricted strong convexity (RSC).
Such conditions have been discussed in previous literature [9  1]  and involve a lower bound on the
remainder in the ﬁrst-order Taylor expansion of Ln. In particular  our main statistical result is based
on the following RSC condition:

(cid:104)∇Ln(β∗ + ∆) − ∇Ln(β∗)  ∆(cid:105) ≥

 α1(cid:107)∆(cid:107)2

2 − τ1
α2(cid:107)∆(cid:107)2 − τ2

(cid:114)

log p

(cid:107)∆(cid:107)2
1 
(cid:107)∆(cid:107)1 

n
log p

n

∀(cid:107)∆(cid:107)2 ≤ 1 

∀(cid:107)∆(cid:107)2 ≥ 1 

(4a)

(4b)

where the αj’s are strictly positive constants and the τj’s are nonnegative constants.
To understand this condition  note that if Ln were actually strongly convex  then both these RSC
inequalities would hold with α1 = α2 > 0 and τ1 = τ2 = 0. However  in the high-dimensional
setting (p (cid:29) n)  the empirical loss Ln can never be strongly convex  but the RSC condition may
still hold with strictly positive (αj  τj). On the other hand  if Ln is convex (but not strongly convex) 
the left-hand expression in inequality (4) is always nonnegative  so inequalities (4a) and (4b) hold
trivially for (cid:107)∆(cid:107)1
log p  respectively. Hence  the RSC inequalities
(cid:107)∆(cid:107)2
only enforce a type of strong convexity condition over a cone set of the form
.

≥ (cid:113) α1n

τ1 log p and (cid:107)∆(cid:107)1
(cid:107)∆(cid:107)2

(cid:110)(cid:107)∆(cid:107)1

(cid:113) n

(cid:113) n

≥ α2

≤ c

(cid:111)

τ2

(cid:107)∆(cid:107)2

log p

3 Statistical guarantees and consequences

local minimum of the program (1):

We now turn to our main statistical guarantees and some consequences for various statistical models.

Our theory applies to any vector (cid:101)β ∈ Rp that satisﬁes the ﬁrst-order necessary conditions to be a
When(cid:101)β lies in the interior of the constraint set  condition (5) is the usual zero-subgradient condition.

(cid:104)∇Ln((cid:101)β) + ∇ρλ((cid:101)β)  β −(cid:101)β(cid:105) ≥ 0 

for all feasible β ∈ Rp.

(5)

3.1 Main statistical results

tion  and parameters  which guarantee that any local optimum (cid:101)β lies close to the target vector

Our main theorem is deterministic in nature  and speciﬁes conditions on the regularizer  loss func-
L(β). Corresponding probabilistic results will be derived in subsequent sections. For
β∗ = arg min
β∈Rp
proofs and more detailed discussion of the results contained in this paper  see the technical report [7].
Theorem 1. Suppose the regularizer ρλ satisﬁes Assumption 1  Ln satisﬁes the RSC conditions (4)
with α1 > µ  and β∗ is feasible for the objective. Consider any choice of λ such that

(cid:40)

(cid:114)

(cid:41)

· max

2
L

(cid:107)∇Ln(β∗)(cid:107)∞  α2

log p

n

≤ λ ≤ α2
6RL

 

(6)

3

log p. Then any vector (cid:101)β satisfying the ﬁrst-order necessary con-

and suppose n ≥ 16R2 max(τ 2
ditions (5) satisﬁes the error bounds

1  τ 2
2 )

α2
2

(cid:107)(cid:101)β − β∗(cid:107)2 ≤ 7λL

√

k
4(α1 − µ)

 

and

(cid:107)(cid:101)β − β∗(cid:107)1 ≤ 56λLk

4(α1 − µ)

 

(7)

(cid:113) log p

n and R proportional to 1

where k = (cid:107)β∗(cid:107)0.
From the bound (7)  note that the squared (cid:96)2-error grows proportionally with k  the number of non-
zeros in the target parameter  and with λ2. As will be clariﬁed in the following sections  choosing λ
λ will satisfy the requirements of Theorem 1 w.h.p. for
proportional to
many statistical models  in which case we have a squared (cid:96)2-error that scales as k log p
n   as expected.
Remark 1. It is worthwhile to discuss the quantity α1 − µ appearing in the denominator of the
bound in Theorem 1. Recall that α1 measures the level of curvature of the loss function Ln  while µ
measures the level of nonconvexity of the penalty ρλ. Intuitively  the two quantities should play op-
posing roles in our result: Larger values of µ correspond to more severe nonconvexity of the penalty 
resulting in worse behavior of the overall objective (1)  whereas larger values of α1 correspond to
more (restricted) curvature of the loss  leading to better behavior.

We now develop corollaries for various nonconvex loss functions and regularizers of interest.

3.2 Corrected linear regression

We begin by considering the case of high-dimensional linear regression with systematically cor-
rupted observations. Recall that in the framework of ordinary linear regression  we have the model

(cid:124) (cid:123)(cid:122) (cid:125)
yi = (cid:104)β∗  xi(cid:105)
(cid:80)p
j=1 β∗

j xij

+ i 

for i = 1  . . .   n 

(8)

where β∗ ∈ Rp is the unknown parameter vector and {(xi  yi)}n
and Wainwright [6]  assume we instead observe pairs {(zi  yi)}n
corrupted versions of the corresponding xi’s. Some examples include the following:

i=1 are observations. Following Loh
i=1  where the zi’s are systematically

(a) Additive noise: Observe zi = xi + wi  where wi ⊥⊥ xi  E[wi] = 0  and cov[wi] = Σw.
(b) Missing data: For ϑ ∈ [0  1)  observe zi ∈ Rp such that for each component j  we inde-

pendently observe zij = xij with probability 1 − ϑ  and zij = ∗ with probability ϑ.

We use the population and empirical loss functions

1
2

L(β) =

βT Σxβ − β∗T Σxβ 

where ((cid:98)Γ (cid:98)γ) are estimators for (Σx  Σxβ∗) depending on {(zi  yi)}n
βT(cid:98)Γβ −(cid:98)γT β + ρλ(β)

(cid:98)β ∈ arg min

From the formulation (1)  the corrected linear regression estimator is given by

(cid:26) 1

.

Ln(β) =

and

g(β)≤R

2

βT(cid:98)Γβ −(cid:98)γT β 
1
(9)
2
i=1. Then β∗ = arg minβ L(β).
(cid:27)

We now state a corollary in the case of additive noise (model (a))  where we take

(cid:98)Γ =

Z T Z

− Σw 

and

(cid:98)γ =

Z T y

.

When p (cid:29) n  the matrix(cid:98)Γ in equation (11) is always negative-deﬁnite  so the empirical loss function
Ln previously deﬁned (9) is nonconvex. Other choices of(cid:98)Γ are applicable to missing data (model

n

n

(b))  and also lead to nonconvex programs [6].

(10)

(11)

4

 

c

k

n

.

R

√

c0λ

and

c(cid:48)
0λk

Corollary 1. Suppose we have i.i.d. observations {(zi  yi)}n
sub-Gaussian additive noise. Suppose (λ  R) are chosen such that β∗ is feasible and
≤ λ ≤ c(cid:48)

Then given a sample size n ≥ C max{R2  k} log p  any local optimum (cid:101)β of the nonconvex pro-

i=1 from a corrupted linear model with

(cid:114)

log p

(cid:107)(cid:101)β − β∗(cid:107)2 ≤

gram (10) satisﬁes the estimation error bounds

with probability at least 1 − c1 exp(−c2 log p)  where (cid:107)β∗(cid:107)0 = k.

(cid:107)(cid:101)β − β∗(cid:107)1 ≤
Remark 2. When ρλ(β) = λ(cid:107)β(cid:107)1 and g(β) = (cid:107)β(cid:107)1  taking λ (cid:16)(cid:113) log p
are stated only for a global minimum(cid:98)β of the program (10)  whereas Corollary 1 is a much stronger
result holding for any local minimum (cid:101)β. Theorem 2 of our earlier paper [6] provides an indirect
route for establishing similar bounds on (cid:107)(cid:101)β − β∗(cid:107)1 and (cid:107)(cid:101)β − β∗(cid:107)2  since the projected gradient

k for some
constant b0 ≥ (cid:107)β∗(cid:107)2 yields the required scaling n (cid:37) k log p. Hence  the bounds in Corollary 1
agree with bounds in Theorem 1 of Loh and Wainwright [6]. Note  however  that the latter results

λmin(Σx) − 2µ
√

λmin(Σx) − 2µ

descent algorithm may become stuck in local minima. In contrast  our argument here does not rely
on an algorithmic proof and applies to a more general class of (possibly nonconvex) penalties.
Corollary 1 also has important consequences in the case where pairs {(xi  yi)}n
i=1 from the linear
model (8) are observed without corruption and ρλ is nonconvex. Then the empirical loss Ln is
equivalent to the least-squares loss  modulo a constant factor. Much existing work [3  14] only
establishes statistical consistency of global minima and then provides specialized algorithms for
obtaining speciﬁc local optima that are provably close to global optima. In contrast  our results
demonstrate that any optimization algorithm converging to a local optimum sufﬁces.

n and R = b0

 

3.3 Generalized linear models

Moving beyond linear regression  we now consider the case where observations are drawn from a
generalized linear model (GLM). Recall that a GLM is characterized by the conditional distribution

P(yi | xi  β  σ) = exp

(cid:26) yi(cid:104)β  xi(cid:105) − ψ(xT

i β)

(cid:27)

 

c(σ)

where σ > 0 is a scale parameter and ψ is the cumulant function. By standard properties of expo-
nential families [8  5]  we have

ψ(cid:48)(xT

i β) = E[yi | xi  β  σ].

In our analysis  we assume there exists αu > 0 such that ψ(cid:48)(cid:48)(t) ≤ αu for all t ∈ R. This bound-
edness assumption holds in various settings  including linear regression  logistic regression  and
multinomial regression. The bound is required to establish both statistical consistency results in the
present section and fast global convergence guarantees for our optimization algorithms in Section 4.
We will assume that β∗ is sparse and optimize the penalized maximum likelihood program

(cid:98)β ∈ arg min

(cid:40)

1
n

n(cid:88)

(cid:0)ψ(xT

(cid:41)

i β(cid:1) + ρλ(β)

i β) − yixT

.

(12)

g(β)≤R
We then have the following corollary:
Corollary 2. Suppose we have i.i.d. observations {(xi  yi)}n
sub-Gaussian. Suppose (λ  R) are chosen such that β∗ is feasible and

i=1

i=1 from a GLM  where the xi’s are

Given a sample size n ≥ CR2 log p  any local optimum(cid:101)β of the nonconvex program (12) satisﬁes

R

n

c

.

(cid:107)(cid:101)β − β∗(cid:107)2 ≤

√

c0λ

k

λmin(Σx) − 2µ

 

and

(cid:107)(cid:101)β − β∗(cid:107)1 ≤

c(cid:48)
0λk

λmin(Σx) − 2µ

 

with probability at least 1 − c1 exp(−c2 log p)  where (cid:107)β∗(cid:107)0 = k.

(cid:114)

log p

≤ λ ≤ c(cid:48)

5

4 Optimization algorithm

which is convex by Assumption 1. We may then write the program (1) as

We now describe how a version of composite gradient descent may be applied to efﬁciently optimize
the nonconvex program (1). We focus on a version of the optimization problem with the side function

gλ µ(β) :=

(cid:98)β ∈ arg min

gλ µ(β)≤R

(cid:111)

 

(cid:1)
(cid:125)

ρλ(β) + µ(cid:107)β(cid:107)2

2

1
λ

(cid:123)(cid:122)

(cid:110)
(cid:110)(cid:0)Ln(β) − µ(cid:107)β(cid:107)2
(cid:124)
(cid:13)(cid:13)(cid:13)(cid:13)β −

(cid:18)

¯Ln

η

2

βt − ∇Ln(βt)

(cid:40)

(cid:111)

+λgλ µ(β)

.

(13)

(14)

(cid:41)

(cid:19)(cid:13)(cid:13)(cid:13)(cid:13)2

2

+

λ
η

gλ µ(β)

 

(15)

The objective function then decomposes nicely into a sum of a differentiable but nonconvex function
and a possibly nonsmooth but convex penalty. Applied to the representation (14)  the composite
gradient descent procedure of Nesterov [10] produces a sequence of iterates {βt}∞
t=0 via the updates

βt+1 ∈ arg min

gλ µ(β)≤R

1
2

where 1

η is the stepsize. Deﬁne the Taylor error around β2 in the direction β1 − β2 by

T (β1  β2) := Ln(β1) − Ln(β2) − (cid:104)∇Ln(β2)  β1 − β2(cid:105).

(16)
For all vectors β2 ∈ B2(3) ∩ B1(R)  we require the following form of restricted strong convexity:
(17a)

∀(cid:107)β1 − β2(cid:107)2 ≤ 3 

(cid:107)β1 − β2(cid:107)2
1 

log p

 α1(cid:107)β1 − β2(cid:107)2

2 − τ1
α2(cid:107)β1 − β2(cid:107)2 − τ2

(cid:114)

n
log p

n

(cid:107)β1 − β2(cid:107)1 

∀(cid:107)β1 − β2(cid:107)2 ≥ 3.

(17b)

T (β1  β2) ≥

The conditions (17) are similar but not identical to the earlier RSC conditions (4). The main
difference is that we now require the Taylor difference to be bounded below uniformly over
β2 ∈ B2(3) ∩ B1(R)  as opposed to for a ﬁxed β2 = β∗. We also assume an upper bound:

T (β1  β2) ≤ α3(cid:107)β1 − β2(cid:107)2

2 + τ3

log p

(cid:107)β1 − β2(cid:107)2
1 

for all β1  β2 ∈ Rp 

(18)

n

a condition referred to as restricted smoothness in past work [1]. Throughout this section  we as-
sume αi > µ for all i  where µ is the coefﬁcient ensuring the convexity of the function gλ µ from
equation (13). Furthermore  we deﬁne α = min{α1  α2} and τ = max{τ1  τ2  τ3}.
The following theorem applies to any population loss function L for which the population minimizer
β∗ is k-sparse and (cid:107)β∗(cid:107)2 ≤ 1  and under the scaling n > Ck log p  for a constant C depending on
the αi’s and τi’s. We show that the composite gradient updates (15) exhibit a type of globally
geometric convergence in terms of the quantity

1 − α−µ

128τ k log p
n
α − µ
Under the stated scaling on the sample size  we are guaranteed that κ ∈ (0  1). Let

4η + ϕ(n  p  k)
1 − ϕ(n  p  k)

where ϕ(n  p  k) :=

κ :=

 

2 log

T ∗(δ) :=

δ2
log(1/κ)

+

where φ(β) := Ln(β) + ρλ(β)  and deﬁne stat := (cid:107)(cid:98)β − β∗(cid:107)2.
Assumption 1. Suppose(cid:98)β is any global minimum of the program (14)  with
(cid:40)
(cid:114)

Theorem 2. Suppose Ln satisﬁes the RSC/RSM conditions (17) and (18)  and suppose ρλ satisﬁes

(cid:114)

log(1/κ)

(cid:41)

log log

1 +

δ2

log 2

R

log p

n

≤ c 

and

λ ≥ 4
L

· max

(cid:107)∇Ln(β∗)(cid:107)∞  τ

log p

n

.

Then for any stepsize η ≥ 2 · max{α3 − µ  µ} and tolerance δ2 ≥ c2

stat

1−κ   we have

(cid:18) λRL

(cid:19)

.

 

(19)

(20)

(cid:16) φ(β0)−φ((cid:98)β)

(cid:17)

(cid:18)

(cid:19)

(cid:19)

(cid:107)βt −(cid:98)β(cid:107)2
2 ≤

2

α − µ

(cid:18)

 

∀t ≥ T ∗(δ).

(21)

δ2 +

δ4
τ

+ 128τ

k log p

n

2
stat

6

Remark 3. Note that for the optimal choice of tolerance parameter δ (cid:16) stat  the bound in inequal-
ity (21) takes the form c2
α−µ  meaning successive iterates are guaranteed to converge to a region
stat

within statistical accuracy of the true global optimum(cid:98)β. Combining Theorems 1 and 2  we have

(cid:110)(cid:107)βt −(cid:98)β(cid:107)2  (cid:107)βt − β∗(cid:107)2

(cid:111)

max

(cid:32)(cid:114)

(cid:33)

= O

k log p

n

 

∀t ≥ T (c(cid:48)stat).

5 Simulations
In this section  we report the results of simulations for two versions of the loss function Ln  corre-
sponding to linear and logistic regression  and three penalty functions: Lasso  SCAD  and MCP. In
all cases  we chose regularization parameters R = 1.1

(cid:113) log p

λ · ρλ(β∗) and λ =

n .

Linear regression:
noise according to the mechanism described in Section 3.2  giving the estimator

In the case of linear regression  we simulated covariates corrupted by additive

(cid:98)β ∈ arg min

gλ µ(β)≤R

(cid:26) 1

2

βT

(cid:18) X T X

n

(cid:19)

− Σw

β − yT Z
n

β + ρλ(β)

.

(22)

We generated i.i.d. samples xi ∼ N (0  I) and i ∼ N (0  (0.1)2)  and set Σw = (0.2)2I.

Logistic regression:
Since ψ(t) = log(1 + exp(t))  the program (12) becomes

In the case of logistic regression  we generated i.i.d. samples xi ∼ N (0  I).

{log(1 + exp((cid:104)β  xi(cid:105)) − yi(cid:104)β  xi(cid:105)} + ρλ(β)

.

(23)

(cid:27)

(cid:41)

(cid:98)β ∈ arg min

gλ µ(β)≤R

(cid:40)

n(cid:88)

i=1

1
n

We optimized the programs (22) and (23) using the composite gradient updates (15). Figure 1
different problem sizes p. In each case  β∗ is a k-sparse vector with k = (cid:98)√
shows the results of corrected linear regression with Lasso  SCAD  and MCP regularizers for three
p(cid:99)  where the nonzero
entries were generated from a normal distribution and the vector was then rescaled so (cid:107)β∗(cid:107)2 = 1.
when the estimation error (cid:107)(cid:98)β − β∗(cid:107)2 is plotted against the rescaled sample size
As predicted by Theorem 1  the curves corresponding to the same penalty function stack up nicely
k log p  and the (cid:96)2-
error decreases to zero as the number of samples increases  showing that the estimators (22) and (23)
are statistically consistent. We chose the parameter a = 3.7 for SCAD and b = 3.5 for MCP.

n

(a)

(b)

Figure 1. Plots showing statistical consistency of (a) linear and (b) logistic regression with Lasso 

SCAD  and MCP. Each point represents an average over 20 trials. The estimation error (cid:107)(cid:98)β − β∗(cid:107)2

n

k log p . Lasso  SCAD  and MCP results are represented by

is plotted against the rescaled sample size
solid  dotted  and dashed lines  respectively.

The simulations in Figure 2 depict the optimization-theoretic conclusions of Theorem 2. Each panel
shows two different families of curves  corresponding to statistical error (red) and optimization error

7

0102030405000.10.20.30.40.5n/(k log p)l2 norm errorcomparing penalties for corrected linear regression  p=128p=256p=5120204060801000.40.50.60.70.80.91n/(k log p)l2 norm errorcomparing penalties for logistic regression  p=128p=256p=512(blue). The vertical axis measures the (cid:96)2-error on a log scale  while the horizontal axis tracks the
starting points. We used p = 128  k = (cid:98)√
iteration number. The curves were obtained by running composite gradient descent from 10 random
p(cid:99)  and n = (cid:98)20k log p(cid:99). As predicted by our theory 
the optimization error decreases at a linear rate until it falls to the level of statistical error. Panels
(b) and (c) provide simulations for two values of the SCAD parameter a; the larger choice a = 3.7
corresponds to a higher level of curvature and produces a tighter cluster of local optima.

(a)

(b)

(c)

Figure 2. Plots illustrating linear rates of convergence for corrected linear regression with MCP and

SCAD. Red lines depict statistical error log(cid:0)(cid:107)(cid:98)β − β∗(cid:107)2
log(cid:0)(cid:107)βt −(cid:98)β(cid:107)2

(cid:1) and blue lines depict optimization error
(cid:1). As predicted by Theorem 2  the optimization error decreases linearly up to statistical

accuracy. Each plot shows the solution trajectory for 10 initializations of composite gradient descent.
Panel (a) shows results for MCP; panels (b) and (c) show results for SCAD with different values of a.

Figure 3 provides analogous results to Figure 2 for logistic regression  using p = 64  k = (cid:98)√
p(cid:99)  and
n = (cid:98)20k log p(cid:99). The plot shows solution trajectories for 20 different initializations of composite
local/global optimum(cid:98)β  SCAD and MCP produce multiple local optima.
gradient descent. Again  the log optimization error decreases at a linear rate up to the level of
statistical error  as predicted by Theorem 2. Whereas the convex Lasso penalty yields a unique

(a)

(b)

(c)

Figure 3. Plots showing linear rates of convergence on a log scale for logistic regression. Red lines
depict statistical error and blue lines depict optimization error. (a) Lasso penalty. (b) SCAD penalty.
(c) MCP. Each plot shows the solution trajectory for 20 initializations of composite gradient descent.

6 Discussion

We have analyzed theoretical properties of local optima of regularized M-estimators  where both
the loss and penalty function are allowed to be nonconvex. Our results are the ﬁrst to establish that
all local optima of such nonconvex problems are close to the truth  implying that any optimization
method guaranteed to converge to a local optimum will provide statistically consistent solutions. We
show that a variant of composite gradient descent may be used to obtain near-global optima in linear
time  and verify our theoretical results with simulations.

Acknowledgments

PL acknowledges support from a Hertz Foundation Fellowship and an NSF Graduate Research Fel-
lowship. MJW and PL were also partially supported by grants NSF-DMS-0907632 and AFOSR-
09NL184. The authors thank the anonymous reviewers for helpful feedback.

8

02004006008001000−12−10−8−6−4−202iteration countlog(||(cid:96)t − (cid:96)*||2)log error plot for corrected linear regression with MCP  b = 1.5  opt errstat err020040060080010001200−10−8−6−4−202iteration countlog(||(cid:96)t − (cid:96)*||2)log error plot for corrected linear regression with SCAD  a = 3.7  opt errstat err020040060080010001200−8−7−6−5−4−3−2−101iteration countlog(||(cid:96)t − (cid:96)*||2)log error plot for corrected linear regression with SCAD  a = 2.5  opt errstat err0500100015002000−7−6−5−4−3−2−101iteration countlog(||(cid:96)t − (cid:96)*||2)log error plot for logistic regression with Lasso  opt errstat err0500100015002000−4−3.5−3−2.5−2−1.5−1−0.500.5iteration countlog(||(cid:96)t − (cid:96)*||2)log error plot for logistic regression with SCAD  a = 3.7  opt errstat err0500100015002000−4−3.5−3−2.5−2−1.5−1−0.500.5iteration countlog(||(cid:96)t − (cid:96)*||2)log error plot for logistic regression with MCP  b = 3  opt errstat errReferences
[1] A. Agarwal  S. Negahban  and M. J. Wainwright. Fast global convergence of gradient methods

for high-dimensional statistical recovery. Annals of Statistics  40(5):2452–2482  2012.

[2] P. Breheny and J. Huang. Coordinate descent algorithms for nonconvex penalized regression 
with applications to biological feature selection. Annals of Applied Statistics  5(1):232–253 
2011.

[3] J. Fan and R. Li. Variable selection via nonconcave penalized likelihood and its oracle proper-

ties. Journal of the American Statistical Association  96:1348–1360  2001.

[4] D. R. Hunter and R. Li. Variable selection using MM algorithms. Annals of Statistics 

33(4):1617–1642  2005.

[5] E.L. Lehmann and G. Casella. Theory of Point Estimation. Springer Verlag  1998.
[6] P. Loh and M.J. Wainwright. High-dimensional regression with noisy and missing data: Prov-

able guarantees with non-convexity. Annals of Statistics  40(3):1637–1664  2012.

[7] P. Loh and M.J. Wainwright. Regularized M-estimators with nonconvexity: Statistical and
algorithmic theory for local optima. arXiv e-prints  May 2013. Available at http://arxiv.
org/abs/1305.2436.

[8] P. McCullagh and J. A. Nelder. Generalized Linear Models (Second Edition). London: Chap-

man & Hall  1989.

[9] S. Negahban  P. Ravikumar  M. J. Wainwright  and B. Yu. A uniﬁed framework for high-
dimensional analysis of M-estimators with decomposable regularizers. Statistical Science 
27(4):538–557  December 2012. See arXiv version for lemma/propositions cited here.

[10] Y. Nesterov. Gradient methods for minimizing composite objective function. CORE Discus-
sion Papers 2007076  Universit Catholique de Louvain  Center for Operations Research and
Econometrics (CORE)  2007.

[11] Y. Nesterov and A. Nemirovskii. Interior Point Polynomial Algorithms in Convex Program-
ming. SIAM studies in applied and numerical mathematics. Society for Industrial and Applied
Mathematics  1987.

[12] S. A. Vavasis. Complexity issues in global optimization: A survey. In Handbook of Global

Optimization  pages 27–41. Kluwer  1995.

[13] C.-H. Zhang. Nearly unbiased variable selection under minimax concave penalty. Annals of

Statistics  38(2):894–942  2010.

[14] C.-H. Zhang and T. Zhang. A general theory of concave regularization for high-dimensional

sparse estimation problems. Statistical Science  27(4):576–593  2012.

[15] H. Zou and R. Li. One-step sparse estimates in nonconcave penalized likelihood models.

Annals of Statistics  36(4):1509–1533  2008.

9

,Po-Ling Loh
Martin Wainwright
Iku Ohama
Issei Sato
Takuya Kida
Hiroki Arimura