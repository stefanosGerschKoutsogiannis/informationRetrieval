2011,Sparse Bayesian Multi-Task Learning,We propose a new sparse Bayesian model for multi-task regression and classification. The model is able to capture correlations between tasks  or more specifically a low-rank approximation of the covariance matrix  while being sparse in the features. We introduce a general family of group sparsity inducing priors based on matrix-variate Gaussian scale mixtures. We show the amount of sparsity can be learnt from the data by combining an approximate inference approach with type II maximum likelihood estimation of the hyperparameters. Empirical evaluations on data sets from biology and vision demonstrate the applicability of the model  where on both regression and classification tasks it achieves competitive predictive performance compared to previously proposed methods.,Sparse Bayesian Multi-Task Learning

C´edric Archambeau  Shengbo Guo  Onno Zoeter

{Cedric.Archambeau  Shengbo.Guo  Onno.Zoeter}@xrce.xerox.com

Xerox Research Centre Europe

Abstract

We propose a new sparse Bayesian model for multi-task regression and classiﬁca-
tion. The model is able to capture correlations between tasks  or more speciﬁcally
a low-rank approximation of the covariance matrix  while being sparse in the fea-
tures. We introduce a general family of group sparsity inducing priors based on
matrix-variate Gaussian scale mixtures. We show the amount of sparsity can be
learnt from the data by combining an approximate inference approach with type
II maximum likelihood estimation of the hyperparameters. Empirical evaluations
on data sets from biology and vision demonstrate the applicability of the model 
where on both regression and classiﬁcation tasks it achieves competitive predictive
performance compared to previously proposed methods.

1

Introduction

Learning multiple related tasks is increasingly important in modern applications  ranging from the
prediction of tests scores in social sciences and the classiﬁcation of protein functions in systems
biology to the categorisation of scenes in computer vision and more recently to web search and
ranking. In many real life problems multiple related target variables need to be predicted from a
single set of input features. A problem that attracted considerable interest in recent years is to label
an image with (text) keywords based on the features extracted from that image [26]. In general  this
multi-label classiﬁcation problem is challenging as the number of classes is equal to the vocabulary
size and thus typically very large. While capturing correlations between the labels seems appealing
it is in practice difﬁcult as it rapidly leads to numerical problems when estimating the correlations.
A naive solution is to learn a model for each task separately and to make predictions using the
independent models. Of course  this approach is unsatisfactory as it does not take advantage of
all the information contained in the data. If the model is able to capture the task relatedness  it
is expected to have generalisation capabilities that are drastically increased. This motivated the
introduction of the multi-task learning paradigm that exploits the correlations amongst multiple
tasks by learning them simultaneously rather than individually [12]. More recently  the abundant
literature on multi-task learning demonstrated that performance indeed improves when the tasks are
related [6  31  2  14  13].
The multi-task learning problem encompasses two main settings. In the ﬁrst one  for every input 
every task produces an output. If we restrict ourselves to multiple regression for the time being  the
most basic multi-task model would consider P correlated tasks1  the vector of covariates and targets
being respectively denoted by xn ∈ RD and yn ∈ RP :

yn = Wxn + µ + n 

(1)
where W ∈ RP×D is the matrix of weights and µ ∈ RP the task offsets and n ∈ RP the vector
residual errors with covariance Σ ∈ RP×P . In this setting  the output of all tasks is observed for
1While it is straightfoward to show that the maximum likelihood estimate of W would be the same as when

considering uncorrelated noise  imposing any prior on W would lead to a different solution.

n ∼ N (0  Σ) 

1

every input. In the second setting  the goal is to learn from a set of observed tasks and to generalise
to a new task. This approach views the multi-task learning problem as a transfer learning problem 
where it is assumed that the various tasks belong in some sense to the same environment and share
common properties [23  5]. In general only a single task output is observed for every input.
A recent trend in multi-task learning is to consider sparse solutions to facilitate the interpretation.
Many formulate the sparse multi-task learning problem in a (relaxed) convex optimization frame-
work [5  22  35  23]. If the regularization constant is chosen using cross-validation  regularization-
based approaches often overestimate the support [32] as they select more features than the set that
generated the data. Alternatively  one can adopt a Bayesian approach to sparsity in the context of
multi-task learning [29  21]. The main advantage of the Bayesian formalism is that it enables us to
learn the degree of sparsity supported by the data and does not require the user to specify the type
of penalisation in advance.
In this paper  we adopt the ﬁrst setting for multi-task learning  but we will consider a hierarchical
Bayesian model where the entries of W are correlated so that the residual errors are uncorrelated.
This is similar in spirit as the approach taken by [18]  where tasks are related through a shared kernel
matrix. We will consider a matrix-variate prior to simultaneously model task correlations and group
sparsity in W. A matrix-variate Gaussian prior was used in [35] in a maximum likelihood setting to
capture task correlations and feature correlations. While we are also interested in task correlations 
we will consider matrix-variate Gaussian scale mixture priors centred at zero to drive entire blocks
of W to zero. The Bayesian group LASSO proposed in [30] is a special case. Group sparsity [34]
is especially useful in presence of categorical features  which are in general represented as groups
of “dummy” variables. Finally  we will allow the covariance to be of low-rank so that we can deal
with problems involving a very large number of tasks.

2 Matrix-variate Gaussian prior

Before starting our discussion of the model  we introduce the matrix variate Gaussian as it plays a
key role in our work. For a matrix W ∈ RP×D  the matrix-variate Gaussian density [16] with mean
matrix M ∈ RP×D  row covariance Ω ∈ RD×D and column covariance Σ ∈ RP×P is given by

− 1

2 tr{Ω−1(W−M)(cid:62)Σ−1(W−M)}

.

N (M  Ω  Σ) ∝ e

2 vec(W−M)(cid:62)(Ω⊗Σ)−1vec(W−M) ∝ e
− 1

(2)
If we let Σ = E(W − M)(W − M)(cid:62)  then Ω = E(W − M)(cid:62)(W − M)/c where c ensures
the density integrates to one. While this introduces a scale ambiguity between Σ and Ω (easily
removed by means of a prior)  the use of a matrix-variate formulation is appealing as it makes
explicit the structure vec(W)  which is a vector formed by the concatenation of the columns of
W. This structure is reﬂected in its covariance matrix which is not of full rank  but is obtained by
computing the Kronecker product of the row and the column covariance matrices.
It is interesting to compare a matrix-variate prior for W in (1) with the classical multi-level approach
to multiple regression from statistics (see e.g. [20]). In a standard multi-level model  the rows of W
are drawn iid from a multivariate Gaussian with mean m and covariance S  and m is further drawn
from zero mean Gaussian with covariance R. Integrating out m leads then to a Gaussian distributed
vec(W) with mean zero and with a covariance matrix that has the block diagonal elements equal to
S + R and all off-diagonal elements equal to R. Hence  the standard multi-level model assumes a
very different covariance structure than the one based on (2) and incidentally cannot learn correlated
and anti-correlated tasks simultaneously.

3 A general family of group sparsity inducing priors

We seek a solution for which the expectation of W is sparse  i.e.  blocks of W are driven to zero. A
straightforward way to induce sparsity  and which would be equivalent to (cid:96)1-regularisation on blocks
of W  is to consider a Laplace prior (or double exponential). Although applicable in a penalised
likelihood framework  the Laplace prior would be computationally hard in a Bayesian setting as it
is not conjugate to the Gaussian likelihood. Hence  naively using this prior would prevent us from
computing the posterior in closed form  even in a variational setting. In order to circumvent this
problem  we take a hierarchical Bayesian approach.

2

τ

Zi

γi

V

Wi

σ2

yn

Ωi

υ  λ

Q

tn

N

ω  χ  φ

Figure 1: Graphical model for sparse Bayesian multiple regression (when excluding the dashed
arrow) and sparse Bayesian multiple classiﬁcation (when considering all arrows).

We assume that the marginal prior  or effective prior  on each block Wi ∈ RP×Di has the form of
a matrix-variate Gaussian scale mixture  a generalisation of the multivariate Gaussian scale mixture
[3]:

(cid:90) ∞

Q(cid:88)

(cid:19)

p(Wi) =

N (0  γ

−1
i Ωi  Σ) p(γi) dγi 

0

i=1

Di = D 

(3)

where Ωi ∈ RDi×Di  Σ ∈ RP×P and γi > 0 is the latent precision (i.e.  inverse scale) associated
to block Wi.
A sparsity inducing prior for Wi can then be constructed by choosing a suitable hyperprior for
γi. We impose a generalised inverse Gaussian prior (see Supplemental Appendix A for a formal
deﬁnition with special cases) on the latent precision variables:

γi ∼ N −1(ω  χ  φ) =

γω−1

i

e

− 1

2 (χγ

−1
i +φγi) 

concentration of the distribution and(cid:112)χ/φ deﬁnes its scale. The effective prior is then a symmetric

where Kω(·) is the modiﬁed Bessel function of the second kind  ω is the index 

χφ deﬁnes the

2Kω(

√

(4)

matrix-variate generalised hyperbolic distribution:

χ−ω(cid:0)√

χφ(cid:1)ω

√
χφ)

(cid:18)(cid:113)

K

ω+

p(Wi) ∝

P Di

(cid:32)(cid:114)

2

χ(φ + tr{Ω

−1
i W(cid:62)

i Σ−1Wi})
(cid:33)ω+

P Di

2

φ+tr{Ω

−1
i W(cid:62)

i Σ−1Wi}

χ

.

(5)

The marginal (5) has fat tails compared to the matrix-variate Gaussian. In particular  the family
contains the matrix-variate Student-t  the matrix-variate Laplace and the matrix-variate Variance-
Gamma as special cases. Several of the multivariate equivalents have recently been used as priors
to induce sparsity in the Bayesian paradigm  both in the context of supervised [19  11] and unsuper-
vised linear Gaussian models [4].

i=1  {Ωi}Q

4 Sparse Bayesian multiple regression
i=1 and {γ1  . . .   γD1  . . .   γ1  . . .   γDQ} as latent variables that need to
We view {Wi}Q
be marginalised over. This is motivated by the fact that overﬁtting is avoided by integrating out
all parameters whose cardinality scales with the model complexity  i.e.  the number of dimensions
and/or the number of tasks. We further introduce a latent projectoin matrix V ∈ RP×K and a set of
latent matrices {Zi}Q
i=1 to make a low-rank approximation of the column covariance Σ as explained
below. Note also that Ωi captures the correlations between the rows of group i.

3

The complete probabilistic model is given by

yn|W  xn ∼ N (Wxn  σ2IP ) 

Wi|V  Zi  Ωi  γi ∼ N (VZi  γ
−1
i Ωi  IK ) 

Zi|Ωi  γi ∼ N (0  γ

−1
i Ωi  τ IP ) 

V ∼ N (0  τ IP   IK ) 
Ωi ∼ W−1(υ  λIDi ) 
γi ∼ N −1(ω  χ  φ) 

(6)

where σ2 is the residual noise variance and τ is residual variance associated to W. The graphical
model is shown in Fig. 1. We reparametrise the inverse Wishart distribution and deﬁne it as follows:

Ω ∼ W−1(υ  Λ) =

4 (cid:81)p

p(p−1)

j=1 Γ(z + 1−j
2 ).

|Λ| D+υ−1
(D+υ−1)D
2

2

2

|Ω−1| 2D+υ
ΓD( D+υ−1

2

2

e− 1

2 tr{ΛΩ−1} 

υ > 0 

)

where Γp(z) = π
Using the compact notations W = (W1  . . .   WQ)  Z = (Z1  . . .   ZQ)  Ω = diag{Ω1  . . .   ΩQ}
and Γ = diag{γ1  . . .   γD1  . . .   γ1  . . .   γDQ}  we can compute the following marginal:

(cid:90)(cid:90)
(cid:90)

p(W|V  Ω) ∝

=

N (VZ  Γ

−1Ω  τ IP )N (0  Γ

−1Ω  IK )p(Γ)dZdΓ

N (0  Γ

−1Ω  VV

(cid:62)

+ τ IP )p(Γ)dΓ.

Thus  the probabilistic model induces sparsity in the blocks of W  while taking correlations between
the task parameters into account through the random matrix Σ ≈ VV(cid:62) + τ IP . This is especially
useful when there is a very large number of tasks.
The latent variables Z = {W  V  Z  Ω  Γ} are infered by variational EM [27]  while the hyperpa-
rameters ϑ = {σ2  τ  υ  λ  ω  χ  φ} are estimated by type II ML [8  25]). Using variational inference
is motivated by the fact that deterministic approximate inference schemes converge faster than tra-
ditional sampling methods such as Markov chain Monte Carlo (MCMC)  and their convergence can
easily be monitored. The choice of learning the hyperparameters by type II ML is preferred to the
option of placing vague priors over them  although this would also be a valid option.
the variational posterior q(Z) =
In order to ﬁnd a tractable solution  we assume that
q(W  V  Z  Ω  Γ) factorises as q(W)q(V)q(  Z)q(Ω)q(Γ) given the data D = {(yn  xn)}N
n=1 [7].
The variational EM combined to the type II ML estimation of the hyperparameters cycles through
the following two steps until convergence:

1. Update of the approximate posterior of the latent variables and parameters for ﬁxed hyper-

parameters. The update for W is given by

q(W) ∝ e(cid:104)ln p(D Z|ϑ)(cid:105)q(Z/W) 

(7)
where Z/W is the set Z with W removed and (cid:104)·(cid:105)q denotes the expectation with respect to
q. The posteriors of the other latent matrices have the same form.
2. Update of the hyperparameters for ﬁxed variational posteriors:
(cid:104)ln p(D Z |ϑ)(cid:105)q(Z) .

ϑ ← argmax

(8)

ϑ

Variational EM converges to a local maximum of the log-marginal likelihood. The convergence can
be checked by monitoring the variational lower bound  which monotonically increases during the op-
timisation. Next  we give the explicit expression of the variational EM steps and the updates for the
hyperparameters  whereas we show that of the variational bound in the Supplemental Appendix D.

4.1 Variational E step (mean ﬁeld)

Asssuming a factorised posterior enables us to compute it in closed form as the priors are each
conjugate to the Gaussian likelihood. The approximate posterior is given by

q(Z) = N (MW   ΩW   SW )N (MV   ΩV   SV )N (MZ  ΩZ  SZ)

(9)

×(cid:89)

W−1(υi  Λi)N −1(ωi  χi  φi).

i

The expression of posterior parameters are given in Supplemental Appendix C. The computational
bottleneck resides in the inversion of ΩW which is O(D3) per iteration. When D > N  we can use
the Woodbury identity for a matrix inversion of complexity O(N 3) per iteration.

4

4.2 Hyperparameter updates

To learn the degree of sparsity from data we optimise the hyperparameters. There are no closed
form updates for {ω  χ  φ}. Hence  we need to ﬁnd the root of the following expressions  e.g.  by
line search:

(cid:115)

ω : Q ln

χ :

φ
χ

− Q

d ln Kω(
dω

(cid:115)
Rω((cid:112)χφ) +
Rω((cid:112)χφ) −(cid:88)

φ
χ

− Q
2

Qω
χ

(cid:114) χ

φ : Q

φ

√

χφ)

(cid:88)
(cid:88)

i

i

1
2

(cid:104)γi(cid:105) = 0 

i

(cid:104)ln γi(cid:105) = 0 

(cid:104)γ

−1
i

(cid:105) = 0 

(10)

(11)

(12)

where (??) was invoked. Unfortunately  the derivative in the ﬁrst equation needs to be estimated
numerically. When considering special cases of the mixing density such as the Gamma or the inverse
Gamma simpliﬁed updates are obtained and no numerical differentiation is required.
Due to space constraints  we omit the type II ML updates for the other hyperparameters.

4.3 Predictions

follows: p(y∗|x∗) ≈(cid:82) p(y∗|W  x∗)q(W)dW = N (MW x∗  (σ2 + x(cid:62)

Predictions are performed by Bayesian averaging. The predictive distribution is approximated as

∗ ΩW x∗)IP ).

5 Sparse Bayesian multiple classiﬁcation

We restrict ourselves to multiple binary classiﬁers and consider a probit model in which the like-
lihood is derived from the Gaussian cumulative density. A probit model is equivalent to a Gaus-
sian noise and a step function likelihood [1]. Let tn ∈ RP be the class label vectors  with
tnp ∈ {−1  +1} for all n. The likelihood is replaced by

I(tnpynp) 

yn|W  xn ∼ N (Wxn  σ2IP ) 

(13)

tn|yn ∼(cid:89)

p

where I(z) = 1 for z (cid:62) 0 and 0 otherwise. The rest of the model is as before; we will set σ = 1.
The latent variables to infer are now Y and Z. Again  we assume a factorised posterior. We fur-
ther assume the variational posterior q(Y) is a product of truncated Gaussians (see Supplemental
Appendix B):

I(tnpynp)N (νnp  1) =

N+(νnp  1)

N−(νnp  1) 

(14)

n

p

tnp=+1

(cid:89)

(cid:89)

tnp=−1

q(Y) ∝(cid:89)

(cid:89)

where νnp is the pth entry of νn = MW xn. The other variational and hyperparameter updates are
unchanged  except that Y is replaced by matrix ν±. The elements of ν± are deﬁned in (??).

5.1 Bayesian classiﬁcation

In Bayesian classiﬁcation the goal is to predict the label with highest posterior probability. Based
on the variational approximation we propose the following classiﬁcation rule:

ˆt∗ = arg max
t∗

P (t∗|T) ≈ arg max
t∗

Nt∗p (ν∗p  1)dy∗p = arg max
t∗

Φ (t∗pν∗p)  

(15)

where ν∗ = MW x∗. Hence  to decide whether the label t∗p is −1 or +1 it is sufﬁcient to use the
sign of ν∗p as the decision rule. However  the probability P (t∗p|T) tells us also how conﬁdent we
are in the prediction we make.

5

(cid:90)

(cid:89)

p

(cid:89)

p

Figure 2: Results for the ground truth data set. Top left: Prediction accuracy on a test set as a
function of training set size. Top right: estimated and true Σ (top)  true underlying sparsity pattern
(middle) and inverse of the posterior mean of {γi}i showing that the sparsity is correctly captured
(bottom). Bottom diagrams: Hinton diagram of true W (bottom)  ordinary least squares learnt W
(middle) and the sparse Bayesian multi-task learnt W (top). The ordinary least squares learnt W
contains many non-zero elements.

6 A model study with ground truth data

√

.9 −√

.9 −√

.9

.9

√

.9](cid:62) and τ = 0.1  i.e.

To understand the properties of the model we study a regression problem with known parame-
√
ters. Figure 2 shows the results for 5 tasks and 50 features. Matrix W is drawn using V =
the covariance for vec(W) has 1’s on the
[
diagonal and ±.9 on the off-diagonal elements. The ﬁrst three tasks and the last two tasks are pos-
itively correlated. There is a negative correlation between the two groups. The active features are
randomly selected among the 50 candidate features. We evaluate the models with 104 test points
and repeated the experiment 25 times. Gaussian noise was added to the targets (σ = 0.1).
It can be observed that the proposed model performs better and converges faster to the optimal
performance when the data set size increases compared ordinary least squares. Note also that both
Σ and the sparsity pattern are correctly identiﬁed.

6

2030405060708090100012345678Training set sizeAverage Squared Test Error SPBMRCOrdinary Least SquaresPredict with ground truth WEstimated task covarianceTrue task covarianceSparsity pattern510152025303540455000.20.40.60.81E γ−1Feature indexSBMR estimated weight matrixOLS estimated weight matrixTrue weight matrixTable 1: Performance (with standard deviation) of classiﬁcation tasks on Yeast and Scene data sets in
terms of accuracy and AUC. LR: Bayesian logistic regression; Pooling: pooling all data and learning
a single model; Xue: the matrix stick-breaking process based multi-task learning model proposed in
[33]. K = 10 for the proposed models (i.e.  Laplace  Student-t  and ARD). Note that the ﬁrst ﬁve
rows for Yeast and Scene data sets are reported in [29]. The reported performances are averaged
over ﬁve randomized repetitions.

Yeast

Scene

Accuracy
0.5047
0.4983
0.5106
0.5212
0.5424

AUC
0.5049
0.5112
0.5105
0.5244
0.5406

Accuracy
0.7362
0.7862
0.7765
0.7756
0.7911

AUC
0.6153
0.5433
0.5603
0.6325
0.6416

Model

LR
Pool

Xue [33]

Model-1 [29]
Model-2 [29]

Chen [15]
Laplace
Student
ARD

NA

0.7987±0.0017
0.7988±0.0017
0.7987±0.0020

0.7987±0.0044
0.8349±0.0020
0.8349±0.0019
0.8349±0.0020

NA

0.8892±0.0038
0.8897±0.0034
0.8896±0.0044

0.9160±0.0038
0.9188±0.0041
0.9183±0.0041
0.9187±0.0042

7 Multi-task classiﬁcation experiments

In this section  we evaluate the proposed model on two data sets: Yeast [17] and Scene [9]  which
have been widely used as testbeds to evaluate multi-task learning approaches [28  29  15]. To demon-
strate the superiority of the proposed models  we conduct systematic empirical evaluations including
the comparisons with (1) Bayesian logistic regression (BLR) that learns tasks separately  (2) a pool-
ing model that pools data together and learns a single model collectively  and (3) the state-of-the-art
multi-task learning methods proposed in [33  29  15].
We follow the experimental setting as introduced in [29] for fair comparisons  and omit the detailed
setting due to space limitation. We evaluate all methods for the classiﬁcation task using two metrics:
(1) overall accuracy at a threshold of zero and (2) the average area under the curve (AUC). Results
on the Yeast and Scence data sets using these two metrics are reported in Table 7. It is interesting
to note that even for small values of K (fewer parameters in the column covariance) the proposed
model achieves good results. We also study how the performances vary with different K on a tuning
set  and observe that there are no signiﬁcant differences on performances using different K (not
shown in the paper). The results in Table 7 were produced with K = 10.
The proposed models (Laplace  Student-t  ARD) signiﬁcantly outperform the Bayesian logistic re-
gression approach that learns each task separately. This observation agrees with the previous work
[6  31  2  5] demonstrating that the multi-task approach is beneﬁcial over the naive approach of
learning tasks separately. For the Yeast data set  the proposed models are signiﬁcantly better than
“Xue” [33]  Model-1 and Model-2 [29]  and the best performing model in [15]. For the Scene data
set  our models and the model in [15] show comparable results.
The advantage of using hierarchical priors is particularly evident in a low data regime. To study
the impact of training set size on performance  we report the accuracy and AUC as functions of the
training set sizes in Figure 3. For this experiment  we use a single test set of size 1196  which repli-
cates the experimental setup in [29]. Figure 3 shows that the proposed Bayesian methods perform
well overall  but that the performances are not signiﬁcantly impacted when the number of data is
small. Similar results were obtained for the Yeast data set.

8 Conclusion

In this work we proposed a Bayesian multi-task learning model able to capture correlations between
tasks and to learn the sparsity pattern of the data features simultaneously. We further proposed a
low-rank approximation of the covariance to handle a very large number of tasks. Combining low-
rank and sparsity at the same time has been a long open standing issue in machine learning. Here 
we are able to achieve this goal by exploiting the special structure of the parameters set. Hence  the

7

Figure 3: Model comparisons in terms of classiﬁcation accuracy and AUC on the Scene data set
for K = 10. Error bars represent 3 times the standard deviation. Results for Bayesian logistic
regression (BLR)  Model-1 and Model-2 are obtained based on the measurements using a ruler from
Figure 2 in [29]  for which no error bars are given.

proposed model combines sparsity and low-rank in a different manner than in [10]  where a sum of
a sparse and low-rank matrix is considered.
By considering a matrix-variate Gaussian scale mixture prior we extended the Bayesian group
LASSO to a more general family of group sparsity inducing priors. This suggests the extension
of current Bayesian methodology to learn structured sparsity from data in the future. A possible
extension is to consider the graphical LASSO to learn sparse precision matrices Ω−1 abd Σ−1. A
similiar approach was explored in [35].

References

[1] J. H. Albers and S. Chib. Bayesian analysis of binary and polychotomous response data.

J.A.S.A.  88(422):669–679  1993.

[2] R. K. Ando and T. Zhang. A framework for learning predictive structures from multiple tasks

and unlabeled data. JMLR  6:1817–1853  2005.

[3] D. F. Andrews and C. L. Mallows. Scale mixtures of normal distributions. Journal of the Royal

Statistical Society B  36(1):99–102  1974.

[4] C. Archambeau and F. Bach. Sparse probabilistic projections. In NIPS. MIT Press  2008.
[5] A. Argyriou  T. Evgeniou  and M. Pontil. Convex multi-task feature learning. Machine Learn-

ing  73:243–272  2008.

[6] B. Bakker and T. Heskes. Task clustering and gating for bayesian multitask learning. JMLR 

4:83–99  2003.

[7] M. J. Beal. Variational Algorithms for Approximate Bayesian Inference. PhD thesis  Gatsby

Computational Neuroscience Unit  University College London  2003.

[8] J. O. Berger. Statistical Decision Theory and Bayesian Analysis. Springer  New York  1985.
[9] M. R. Boutell  J. Luo  X. Shen  and C. M. Brown. Learning multi-label scene classiﬁcation.

Pattern Recognition  37(9):1757–1771  2004.

[10] E. J. Cand`es  X. Li  Y. Ma  and J. Wright. Robust principal component analysis? Journal of

the ACM  58:1–37  June 2011.

[11] F. Caron and A. Doucet. Sparse Bayesian nonparametric regression. In ICML  pages 88–95.

ACM  2008.

[12] R. Caruana. Multitask learning. Machine Learning  28(1):41–75  1997.

8

40060080010000.50.60.70.80.9Scene data set  K=10Number of training samplesAccuracy ARDStudent−tLaplaceModel−2Model−1BLR40060080010000.50.60.70.80.9Scene data set  K=10Number of training samplesAUC[13] O. Chapelle  P. Shivaswamy  S. Vadrevu  K. Weinberger  Y. Zhang  and B. Tseng. Multi-task
learning for boosting with application to web search ranking. In SIGKDD  pages 1189–1198 
2010.

[14] R. Chari  W. W. Lockwood  B. P. Coe  A. Chu  D. Macey  A. Thomson  J. J. Davies 
C. MacAulay  and W. L. Lam. Sigma: A system for integrative genomic microarray analy-
sis of cancer genomes. BMC Genomics  7:324  2006.

[15] J. Chen  J. Liu  and J. Ye. Learning incoherent sparse and low-rank patterns from multiple

tasks. In SIGKDD  pages 1179–1188. ACM  2010.

[16] A. P. Dawid. Some matrix-variate distribution theory: Notational considerations and a bayesian

application. Biometrika  68(1):265–274  1981.

[17] A. Elisseeff and J. Weston. A kernel method for multi-labelled classiﬁcation. In NIPS. 2002.
[18] T. Evgeniou  C. A. Micchelli  and M. Pontil. Learning multiple tasks with kernel methods.

JMLR  6:615–637  2005.

[19] M. Figueiredo. Adaptive sparseness for supervised learning.

25:1150–1159  2003.

IEEE Transactions on PAMI 

[20] A. Gelman and J. Hill. Data Analysis Using Regression and Multilevel/Hiererarchical Models.

Cambridge University Press  2007.

[21] D. Hern´andez-Lobato  J. M. Hern´andez-Lobato  T. Helleputte  and P. Dupont. Expectation
propagation for Bayesian multi-task feature selection. In ECML-PKDD  pages 522–537  2010.
In

[22] L. Jacob  F. Bach  and J.-P. Vert. Clustered multi-task learning: A convex formulation.

NIPS  pages 745–752. 2009.

[23] T. Jebara. Multitask sparsity via maximum entropy discrimination. JMLR  12:75–110  2011.
Statistical Properties of the Generalized Inverse Gaussian Distribution.
[24] B. Jørgensen.
Springer  1982.

[25] D. J. C. MacKay. Bayesian interpolation. Neural Computation  4(3):415–447  1992.
[26] A. Makadia  V. Pavlovic  and S. Kumar. A new baseline for image annotation. In ECCV  2008.
[27] R. M. Neal and G. E. Hinton. A view of the EM algorithm that justiﬁes incremental  sparse 
and other variants. In M. I. Jordan  editor  Learning in Graphical Models  pages 355–368. MIT
press  1998.

[28] P. Rai and H. Daume. Multi-label prediction via sparse inﬁnite cca. In NIPS  pages 1518–1526.

2009.

[29] P. Rai and H. D. III. Inﬁnite predictor subspace models for multitask learning. In AISTATS 

pages 613–620  2010.

[30] S. Raman  T. J. Fuchs  P. J. Wild  E. Dahl  and V. Roth. The Bayesian group-Lasso for analyz-

ing contingency tables. In ICML  pages 881–888  2009.

[31] A. Torralba  K. P. Murphy  and W. T. Freeman. Sharing features: efﬁcient boosting procedures

for multiclass object detection. In CVPR  pages 762–769. IEEE Computer Society  2004.

[32] M. Wainwright. Sharp thresholds for high-dimensional and noisy sparsity recovery using
IEEE Transactions on Information Theory 

l1-constrained quadratic programming (lasso).
55(5):2183 –2202  2009.

[33] Y. Xue  D. Dunson  and L. Carin. The matrix stick-breaking process for ﬂexible multi-task

learning. In ICML  pages 1063–1070  2007.

[34] M. Yuan and Y. Lin. Model selection and estimation in regression with grouped variables. J.

R. Statistic. Soc. B  68(1):49–67  2006.

[35] Y. Zhang and J. Schneider. Learning multiple tasks with a sparse matrix-normal penalty. In

NIPS  pages 2550–2558. 2010.

9

,Sven Peter
Ferran Diego
Fred Hamprecht
Boaz Nadler