2016,Fast Mixing Markov Chains for Strongly Rayleigh Measures  DPPs  and Constrained Sampling,We study probability measures induced by set functions with constraints. Such measures arise in a variety of real-world settings  where prior knowledge  resource limitations  or other pragmatic considerations impose constraints. We consider the task of rapidly sampling from such constrained measures  and develop fast Markov chain samplers for them. Our first main result is for MCMC sampling from Strongly Rayleigh (SR) measures  for which we present sharp polynomial bounds on the mixing time. As a corollary  this result yields a fast mixing sampler for Determinantal Point Processes (DPPs)  yielding (to our knowledge) the first provably fast MCMC sampler for DPPs since their inception over four decades ago. Beyond SR measures  we develop MCMC samplers for probabilistic models with hard constraints and identify sufficient conditions under which their chains mix rapidly. We illustrate our claims by empirically verifying the dependence of mixing times on the key factors governing our theoretical bounds.,Fast Mixing Markov Chains for Strongly Rayleigh

Measures  DPPs  and Constrained Sampling

Chengtao Li

MIT

ctli@mit.edu

Stefanie Jegelka

MIT

stefje@csail.mit.edu

Suvrit Sra

MIT

suvrit@mit.edu

Abstract

We study probability measures induced by set functions with constraints. Such
measures arise in a variety of real-world settings  where prior knowledge  resource
limitations  or other pragmatic considerations impose constraints. We consider
the task of rapidly sampling from such constrained measures  and develop fast
Markov chain samplers for them. Our ﬁrst main result is for MCMC sampling
from Strongly Rayleigh (SR) measures  for which we present sharp polynomial
bounds on the mixing time. As a corollary  this result yields a fast mixing sampler
for Determinantal Point Processes (DPPs)  yielding (to our knowledge) the ﬁrst
provably fast MCMC sampler for DPPs since their inception over four decades
ago. Beyond SR measures  we develop MCMC samplers for probabilistic models
with hard constraints and identify sufﬁcient conditions under which their chains
mix rapidly. We illustrate our claims by empirically verifying the dependence of
mixing times on the key factors governing our theoretical bounds.

Introduction

1
Distributions over subsets of objects arise in a variety of machine learning applications. They occur
as discrete probabilistic models [5  20  28  36  38] in computer vision  computational biology and
natural language processing. They also occur in combinatorial bandit learning [9]  as well as in recent
applications to neural network compression [32] and matrix approximations [29].
Yet  practical use of discrete distributions can be hampered by computational challenges due to
their combinatorial nature. Consider for instance sampling  a task fundamental to learning  opti-
mization  and approximation. Without further restrictions  efﬁcient sampling can be impossible
[13]. Several lines of work thus focus on identifying tractable sub-classes  which in turn have had
wide-ranging impacts on modeling and algorithms. Important examples include the Ising model [22] 
matchings (and the matrix permanent) [23]  spanning trees (and graph algorithms) [2  6  16  37] 
and Determinantal Point Processes (DPPs) that have gained substantial attention in machine learn-
ing [3  17  24  26  28  30].
In this work  we extend the classes of tractable discrete distributions. Speciﬁcally  we consider
the following two classes of distributions on 2V (the set of subsets of a ground set V = [N ] :=
{1  . . .   N}): (1) strongly Rayleigh (SR) measures  and (2) distributions with certain cardinality or
matroid-constraints. We analyze Markov chains for sampling from both classes. As a byproduct of
our analysis  we answer a long-standing question about rapid mixing of MCMC sampling from DPPs.
SR measures are deﬁned by strong negative correlations  and have recently emerged as valuable
tools in the design of algorithms [2]  in the theory of polynomials and combinatorics [4]  and in
machine learning through DPPs  a special case of SR distributions. Our ﬁrst main result is the ﬁrst
polynomial-time sampling algorithm that applies to all SR measures (and thus a fortiori to DPPs).
General distributions on 2V with constrained support (case (2) above) typically arise upon incorporat-
ing prior knowledge or resource constraints. We focus on resource constraints such as bounds on

30th Conference on Neural Information Processing Systems (NIPS 2016)  Barcelona  Spain.

cardinality and bounds on including limited items from sub-groups. Such constraints can be phrased
as a family C✓ 2V of subsets; we say S satisﬁes the constraint C iff S 2C . Then the distribution of
interest is of the form
(1.1)

⇡C(S) / exp(F (S))JS 2CK 

Iverson bracket  and  a constant (also referred to as the inverse temperature). Most prior work on
sampling with combinatorial constraints (such as sampling the bases of a matroid)  assumes that

where F : 2V ! R is a set function that encodes relationships between items i 2 V  J·K is the
F breaks up linearly using element-wise weights wi  i.e.  F (S) =Pi2S wi. In contrast  we allow

generic  nonlinear functions  and obtain a mixing times governed by structural properties of F .

Contributions. We brieﬂy summarize the key contributions of this paper below.
– We derive a provably fast mixing Markov chain for efﬁcient sampling from strongly Rayleigh
measure ⇡ (Theorem 2). This Markov chain is novel and may be of independent interest. Our
results provide the ﬁrst polynomial guarantee (to our knoweldge) for Markov chain sampling from
a general DPP  and more generally from an SR distribution.1

– We analyze (Theorem 4) mixing times of an exchange chain when the constraint family C is the
set of bases of a special matroid  i.e.  |S| = k or S obeys a partition constraint. Both of these
constraints have high practical relevance [25  27  38].
– We analyze (Theorem 6) mixing times of an add-delete chain for the case |S| k  which  perhaps
surprisingly  turns out to be quite different from |S| = k. This constraint can be more practical
than the strict choice |S| = k  because in many applications  the user may have an upper bound on
the budget  but may not necessarily want to expend all k units.

Finally  a detailed set of experiments illustrates our theoretical results.

Related work. Recent work in machine learning addresses sampling from distributions with sub- or
supermodular F [19  34]  determinantal point processes [3  29]  and sampling by optimization [14  31].
Many of these works (necessarily) make additional assumptions on ⇡C  or are approximate  or cannot
handle constraints. Moreover  the constraints cannot easily be included in F : an out-of-the-box
application of the result in [19]  for instance  would lead to an unbounded constant in the mixing
time.
Apart from sampling  other related tracts include work on variational inference for combinatorial
distributions [5  11  36  38] and inference for submodular processes [21]. Special instances of (1.1)
include [27]  where the authors limit DPPs to sets that satisfy |S| = k; partition matroid constraints
are studied in [25]  while the budget constraint |S| k has been used recently in learning DPPs [17].
Important existing results show fast mixing for a sub-family of strongly Rayleigh distributions [3  15];
but those results do not include  for instance  general DPPs.

1.1 Background and Formal Setup
Before describing the details of our new contributions  let us brieﬂy recall some useful background
that also serves to set the notation. Our focus is on sampling from ⇡C in (1.1); we denote by
Z = PS✓V exp(F (S)) and ZC = PS✓C exp(F (S)). The simplest example of ⇡C is the
uniform distribution over sets in C  where F (S) is constant. In general  F may be highly nonlinear.
We sample from ⇡C using MCMC  i.e.  we run a Markov Chain with state space C. All our chains
are ergodic. The mixing time of the chain indicates the number of iterations t that we must perform
(after starting from an arbitrary set X0 2C ) before we can consider Xt as a valid sample from ⇡C.
Formally  if X0(t) is the total variation distance between the distribution of Xt and ⇡C after t steps 
then ⌧X0(") = min{t : X0(t0)  "  8t0  t} is the mixing time to sample from a distribution
✏-close to ⇡C in terms of total variation distance. We say that the chain mixes fast if ⌧X0 is polynomial
in N. The mixing time can be bounded in terms of the eigenvalues of the transition matrix  as the
following classic result shows:
Theorem 1 (Mixing Time [10]). Let i be the eigenvalues of the transition matrix  and max =
max{2 |N|} < 1. Then  the mixing time starting from an initial set X0 2C is bounded as

1The analysis in [24] is not correct since it relies on a wrong construction of path coupling.

⌧X0(")  (1  max)1(log ⇡C(X0)1 + log "1).

2

Most of the effort in bounding mixing times hence is devoted to bounding this eigenvalue.

2 Sampling from Strongly Rayleigh Distributions

In this section  we consider sampling from strongly Rayleigh (SR) distributions. Such distributions
capture the strongest form of negative dependence properties  while enjoying a host of other remark-
able properties [4]. For instance  they include the widely used DPPs as a special case. A distribution

is SR if its generating polynomial p⇡ : CN ! C  p⇡(z) =PS✓V ⇡(S)Qi2S zi is real stable. This
means if =(zi) > 0 for all arguments zi of p⇡(z)  then p⇡(z) > 0.
We show in particular that SR distributions are amenable to efﬁcient Markov chain sampling. Our
starting point is the observation of [4] on closure properties of SR measures; of these we use symmetric
homogenization. Given a distribution ⇡ on 2[N ]  its symmetric homogenization ⇡sh on 2[2N ] is

⇡sh(S) :=( ⇡(S \ [N ]) N

S\[N ]1

0

if |S| = N ;
otherwise.

If ⇡ is SR  so is ⇡sh. We use this property below in our derivation of a fast-mixing chain.
We use here a recent result of Anari et al. [3]  who show a Markov chain that mixes rapidly for
homogeneous SR distributions. These distributions are over all subsets S ✓ V of some ﬁxed size
|S| = k  and hence do not include general DPPs. Concretely  for any k-homogeneous SR distribution
⇡ : {0  1}N ! R+  a Gibbs-exchange sampler has mixing time

⌧X0(")  2k(N  k)(log ⇡(X0)1 + log "1).

This sampler uniformly samples one item in the current set  and one outside the current set  and
swaps them with an appropriate probability. Using these ideas we show how to obtain fast mixing
chains for any general SR distribution ⇡ on [N ]. First  we construct its symmetric homogenization
⇡sh  and sample from ⇡sh using a Gibbs-exchange sampler. This chain is fast mixing  thus we will
efﬁciently get a sample T ⇠ ⇡sh. The corresponding sample for ⇡ can be then obtained by computing
S = T \ V . Theorem 2  proved in the appendix  formally establishes the validity of this idea.
Theorem 2. If ⇡ is SR  then the mixing time of a Gibbs-exchange sampler for ⇡sh is bounded as

⌧X0(")  2N 2⇣log✓ N

|X0|◆ + log(⇡(X0))1 + log "1⌘.

(2.1)

For Theorem 2 we may choose the initial set such that X0 makes the ﬁrst term in the sum logarithmic
in N (X0 = T0 \ V in Algorithm 1).
Algorithm 1 Markov Chain for Strongly Rayleigh Distributions
Require: SR distribution ⇡

Initialize T ✓ [2N ] where |T| = N and take S = T \ V
while not mixed do

Draw q ⇠ Unif [0  1]
Draw t 2 V \S and s 2 S uniformly at random
if q 2 [0  (N|S|)2
else if q 2 [ (N|S|)2

S = S [{ t} with probability min{1  ⇡(S[{t})

2N ) then

  N|S|

) then

2N 2

2N 2

⇡(S) ⇥ |S|+1
N|S|}

S = S [{ t}\{s} with probability min{1  ⇡(S[{t}\{s})

⇡(S)

}

2N   |S|2+N (N|S|)

2N 2

) then

else if q 2 [ N|S|
else

S = S\{s} with probability min{1  ⇡(S\{s})
Do nothing

⇡(S) ⇥ |S|

N|S|+1}

end if
end while

. Add t

. Exchange s with t

. Delete s

Efﬁcient Implementation. Directly running a chain to sample N items from a (doubled) set of size
2N adds some computational overhead. Hence  we construct an equivalent  more space-efﬁcient

3

chain (Algorithm 1) on the initial ground set V = [N ] that only manintains S ✓ V . Interestingly 
this sampler is a mixture of add-delete and Gibbs-exchange samplers. This combination makes sense
intuitively  too: add-delete moves (also shown in Alg. 3) are needed since the exchange sampler
cannot change the cardinality of S. But a pure add-delete chain can stall if the sets concentrate
around a ﬁxed cardinality (low probability of a larger or smaller set). Exchange moves will not
suffer the same high rejection rates. The key idea underlying Algorithm 1 is that the elements
in {N + 1  . . .   2N} are indistinguishable  so it sufﬁces to maintain merely the cardinality of the
currently selected subset instead of all its indices. Appendix C contains a detailed proof.
Corollary 3. The bound (2.1) applies to the mixing time of Algorithm 1.
Remarks. By assuming ⇡ is SR  we obtain a clean bound for fast mixing. Compared to the bound
in [19]  our result avoids the somewhat opaque factor exp(⇣F ) that depends on F .
In certain cases  the above chain may mix slower in practice than a pure add-delete chain that was
used in previous works [19  24]  since its probability of doing nothing is higher. In other cases  it
mixes much faster than the pure add-delete chain; we observe both phenomena in our experiments in
Sec. 4. Contrary to a simple add-delete chain  in all cases  it is guaranteed to mix well.

3 Sampling from Matroid-Constrained Distributions
In this section we consider sampling from an explicitly-constrained distribution ⇡C where C speciﬁes
certain matroid base constraints (§3.1) or a uniform matroid of a given rank (§3.2).

3.1 Matroid Base Constraints
We begin with constraints that are special cases of matroid bases2:

1. Uniform matroid: C = {S ✓ V | |S| = k} 
2. Partition matroid: Given a partition V =Sk
element from each Pi: C = {S ✓ V | |S \P i| = 1 for all 1  i  k}.

i=1 Pi  we allow sets that contain exactly one

An important special case of a distribution with a uniform matroid constraint is the k-DPP [27].
Partition matroids are used in multilabel problems [38]  and also in probabilistic diversity models [21].

Algorithm 2 Gibbs Exchange Sampler for Matroid Bases
Require: set function F     matroid C✓ 2V

Initialize S 2C
while not mixed do

Let b = 1 with probability 0.5
if b = 1 then

Draw s 2 S and t 2 V \S (t 2P (s) \ {s}) uniformly at random
if S [{ t}\{s}2C then
end if

S S [{ t}\{s} with probability

⇡C (S[{t}\{s})

⇡C (S)+⇡C (S[{t}\{s})

end if
end while

The sampler is shown in Algorithm 2. At each iteration  we randomly select an item s 2 S and
t 2 V \S such that the new set S [{ t}\{s} satisﬁes C  and swap them with certain probability. For
uniform matroids  this means t 2 V \S; for partition matroids  t 2P (s) \ {s} where P(s) is the part
that s resides in. The fact that the chain has stationary distribution ⇡C can be inferred via detailed
balance. Similar to the analysis in [19] for unconstrained sampling  the mixing time depends on
a quantity that measures how much F deviates from linearity: ⇣F = maxS T2C |F (S) + F (T ) 
F (S \ T )  F (S [ T )|. Our proof  however  differs from that of [19]. While they use canonical
paths [10]  we use multicommodity ﬂows  which are more effective in our constrained setting.
Theorem 4. Consider the chain in Algorithm 2. For the uniform matroid  ⌧X0(") is bounded as

⌧X0(")  4k(N  k) exp((2⇣F ))(log ⇡C(X0)1 + log "1);
2Drawing even a uniform sample from the bases of an arbitrary matroid can be hard.

(3.1)

4

For the partition matroid  the mixing time is bounded as

⌧X0(")  4k2 max

i

|Pi| exp((2⇣F ))(log ⇡C(X0)1 + log "1).

(3.2)

Observe that if Pi’s form an equipartition  i.e.  |Pi| = N/k for all i  then the second bound becomes
eO(kN ). For k = O(log N )  the mixing times depend as O(N polylog(N )) = eO(N ) on N. For
uniform matroids  the time is equally small if k is close to N. Finally  the time depends on the
initialization  ⇡C(X0). If F is monotone increasing  one may run a simple greedy algorithm to ensure
that ⇡C(X0) is large. If F is monotone submodular  this ensures that log ⇡C(X0)1 = O(log N ).
Our proof uses a multicommodity ﬂow to upper bound the largest eigenvalue of the transition
matrix. Concretely  let H be the set of all simple paths between states in the state graph of Markov
chain  we construct a ﬂow f : H! R+ that assigns a nonnegative ﬂow value to any simple
path between any two states (sets) X  Y 2C . Each edge e = (S  T ) in the graph has a capacity
Q(e) = ⇡C(S)P (S  T ) where P (S  T ) is the transition probability from S to T . The total ﬂow sent
from X to Y must be ⇡C(X)⇡C(Y ): if HXY is the set of all simple paths from X to Y   then we
needPp2HXY
f (p) = ⇡C(X)⇡C(Y ). Intuitively  the mixing time relates to the congestion in any
edge  and the length of the paths. If there are many short paths X Y across which ﬂow can be
distributed  then mixing is fast. This intuition is captured in a fundamental theorem:
Theorem 5 (Multicommodity Flow [35]). Let E be the set of edges in the transition graph  and
P (X  Y ) the transition probability. Deﬁne

1

Q(e)Xp3e

where len(p) the length of the path p. Then max  1  1/⇢(f ).
With this property of multicommodity ﬂow  we are ready to prove Thm. 4.

⇢(f ) = max
e2E

f (p)len(p) 

Proof. (Theorem 4) We sketch the proof for partition matroids; the full proofs is in Appendix A.
For any two sets X  Y 2C   we distribute the ﬂow equally across all shortest paths X Y in the
transition graph and bound the amount of ﬂow through any edge e 2 E.
Consider two arbitrary sets X  Y 2C with symmetric difference |X  Y | = 2m  2k  i.e.  m
elements need to be exchanged to reach from X to Y . However  these m steps are a valid path in the
transition graph only if every set S along the way is in C. The exchange property of matroids implies
that this requirement is indeed true  so any shortest path X Y has length m. Moreover  there are
exactly m! such paths  since we can exchange the elements in X \ Y in any order to reach at Y . Note
that once we choose s 2 X \ Y to swap out  there is only one choice t 2 Y \ X to swap in  where t
lies in the same part as s in the partition matroid  otherwise the constraint will be violated. Since the
total ﬂow is ⇡C(X)⇡C(Y )  each path receives ⇡C(X)⇡C(Y )/m! ﬂow.
Next  let e = (S  T ) be any edge on some shortest path X Y ; so S  T 2C and T = S [{ j}\{i}
for some i  j 2 V . Let 2r = |X  S| < 2m be the length of the shortest path X S  i.e.  r elements
need to be exchanged to reach from X to S. Similarly  m  r  1 elements are exchanged to reach
from T to Y . Since there is a path for every permutation of those elements  the ratio of the total ﬂow
we(X  Y ) that edge e receives from pair X  Y   and Q(e)  becomes

we(X  Y )

Q(e) 

2r!(m  1  r)!kL

m!ZC

exp(2⇣F )(exp(F (S(X  Y ))) + exp(F (T (X  Y )))) 

(3.3)

where we deﬁne S(X  Y ) = X  Y  S = (X \ Y \ S)[ (X \ (Y [ S))[ (Y \ (X [ S)). To bound
the total ﬂow  we must count the pairs X  Y such that e is on their shortest path(s)  and bound the
ﬂow they send. We do this in two steps  ﬁrst summing over all (X  Y )’s that share the upper bound
(3.3) since they have the same difference sets US = S(X  Y ) and UT = T (X  Y )  and then we
r  pairs that share those difference
sum over all possible US and UT . For ﬁxed US  UT   there arem1
sets  since the only freedom we have is to assign r of the m  1 elements in S \ (X \ Y \ S) to Y  
and the rest to X. Hence  for ﬁxed US  UT . Appropriate summing and canceling then yields

X(X Y ): S (X Y )=US  

T (X Y )=UT

we(X  Y )

Q(e) 

2kL
ZC

exp(2⇣F )(exp(F (US)) + exp(F (UT ))).

(3.4)

5

Finally  we sum over all valid US (UT is determined by US). One can show that any valid US 2C  
and hencePUS
exp(F (US))  ZC  and likewise for UT . Hence  summing the bound (3.4) over all
possible choices of US yields
len(p)  4k2L exp(2⇣F ) 
where we upper bound the length of any shortest path by k  since m  k. Hence

⇢(f )  4kL exp(2⇣F ) max

p

⌧X0(")  4k2L exp(2⇣F )(log ⇡(X0)1 + log "1).

For more restrictive constraints  there are fewer paths  and the bounds can become larger. Appendix A
shows the general dependence on k (as k!). It is also interesting to compare the bound on uniform
matroid in Eq. (3.1) to that shown in [3] for a sub-class of distributions that satisfy the property
of being homogeneous strongly Rayleigh3. If ⇡C is homogeneous strongly Rayleigh  we have
⌧X0(")  2k(N  k)(log ⇡C(X0)1 + log "1). In our analysis  without additional assumptions on
⇡C  we pay a factor of 2 exp(2⇣F )) for generality. This factor is one for some strongly Rayleigh
distributions (e.g.  if F is modular)  but not for all.
3.2 Uniform Matroid Constraint
We consider constraints that is a uniform matroid of certain rank: C = {S : |S| k}. We employ the
lazy add-delete Markov chain in Algo. 3  where in each iteration  with probability 0.5 we uniformly
randomly sample one element from V and either add it to or delete it from the current set  while
respecting constraints. To show fast mixing  we consider using path coupling  which essentially says
that if we have a contraction of two (coupling) chains then we have fast mixing. We construct path
coupling (S  T ) ! (S0  T 0) on a carefully generated graph with edges E (from a proper metric).
With all details in Appendix B we end up with the following theorem:
Theorem 6. Consider the chain shown in Algorithm 3. Let ↵ = max(S T )2E{↵1 ↵ 2} where ↵1 and
↵2 are functions of edges (S  T ) 2 E and are deﬁned as

↵1 =1 Xi2T |p(T  i)  p(S  i)|+ J|S| < kKXi2[N ]\S
↵2 = min{p(S  s)  p(T  t)} Xi2R

|p(S  i)  p(T  i)|+

(p+(S  i)  p+(T  i))+;

J|S| < kK(min{p+(S  t)  p+(T  s)} Xi2[N ]\(S[T ) |p+(S  i)  p+(T  i)|) 

where (x)+ = max(0  x). The summations over absolute differences quantify the sensitivity of
transition probabilities to adding/deleting elements in neighboring (S  T ). Assuming ↵< 1  we get

⌧ (") 

2N log(N"1)

1  ↵

Algorithm 3 Gibbs Add-Delete Markov Chain for Uniform Matroid
Require: F the set function   the inverse temperature  V the ground set  k the rank of C
Ensure: S sampled from ⇡C

Initialize S 2C
while not mixed do

Let b = 1 with probability 0.5
if b = 1 then

Draw s 2 V uniformly randomly
if s /2 S and |S [{ s}|  k then
else

S S [{ s} with probability p+(S  s) =
S S\{s} with probability p(S  s) =

⇡C (S[{s})

⇡C (S)+⇡C (S[{s})

⇡C (S\{s})

⇡C (S)+⇡C (S\{s})

end if

end if
end while

Remarks. If ↵ is less than 1 and independent of N  then the mixing time is nearly linear in N.
The condition is conceptually similar to those in [29  34]. The fast mixing requires both ↵1 and ↵2 
speciﬁcally  the change in probability when adding or deleting single element to neighboring subsets 
to be small. Such notion is closely related to the curvature of discrete set functions.

3Appendix C contains details about strongly Rayleigh distributions.

6

4 Experiments

We next empirically study the dependence of sampling times on key factors that govern our theoretical
bounds. In particular  we run Markov chains on chain-structured Ising models on a partition matroid
base and DPPs on a uniform matroid  and consider estimating marginal and conditional probabilities
of a single variable. To monitor the convergence of Markov chains  we use potential scale reduction
factor (PSRF) [7  18] that runs several chains in parallel and compares within-chain variances to
between-chain variances. Typically  PSRF is greater than 1 and will converge to 1 in the limit; if it is
close to 1 we empirically conclude that chains have mixed well. Throughout experiments we run 10
chains in parallel for estimations  and declare “convergence” at a PSRF of 1.05.
We ﬁrst focus on small synthetic examples where we can compute exact marginal and conditional
probabilities. We construct a 20-variable chain-structured Ising model as

⇡C(S) / exp⇣⇣⇣X19

i=1

wi(si  si+1)⌘ + (1  )|S|⌘⌘JS 2CK 

where the si are 0-1 encodings of S  and the wi are drawn uniformly randomly from [0  1]. The
parameters (   ) govern bounds on the mixing time via exp(2⇣F ); the smaller   the smaller ⇣F .
C is a partition matroid of rank 5. We estimate conditional probabilities of one random variable
conditioned on 0  1 and 2 other variables and compare against the ground truth. We set (   ) to be
(1  1)  (3  1) and (3  0.5) and results are shown in Fig. 1. All marginals and conditionals converge to
their true values  but with different speed. Comparing Fig. 1a against 1b  we observe that with ﬁxed
  increase in  slows down the convergence  as expected. Comparing Fig. 1b against 1c  we observe
that with ﬁxed   decrease in  speeds up the convergence  also as expected given our theoretical
results. Appendix D.1 and D.2 illustrate the convergence of estimations under other (   ) settings.

0.15

0.1

0.05

r
o
r
r

E

Convergence for Inference

Marg
Cond-1
Cond-2

0.15

0.1

0.05

r
o
r
r

E

Convergence for Inference

Marg
Cond-1
Cond-2

0.15

0.1

0.05

r
o
r
r

E

Convergence for Inference

Marg
Cond-1
Cond-2

0

0

0.5

1

# Iter

1.5

2
×104

(a) (   ) = (1  1)

0

0

1

3

2

# Iter

4

5
×104

0

0

1

2

# Iter

3

4

5
×104

(b) (   ) = (3  1)

(c) (   ) = (3  0.5)

Figure 1: Convergence of marginal (Marg) and conditional (Cond-1 and Cond-2  conditioned on
1 and 2 other variables) probabilities of a single variable in a 20-variable Ising model with different
(   ). Full lines show the means and dotted lines the standard deviations of estimations.

We also check convergence on larger models. We use a DPP on a uniform matroid of rank 30 on
the Ailerons data (http://www.dcc.fc.up.pt/657~ltorgo/Regression/DataSets.
html) of size 200. Here  we do not have access to the ground truth  and hence plot the estimation
mean with standard deviations among 10 chains in 3a. We observe that the chains will eventually
converge  i.e.  the mean becomes stable and variance small. We also use PSRF to approximately
judge the convergence. More results can be found in Appendix D.3.
Furthermore  the mixing time depends on the size N of the ground set. We use a DPP on Ailerons and
vary N from 50 to 1000. Fig. 2a shows the PSRF from 10 chains for each setting. By thresholding
PSRF at 1.05 in Fig. 2b we see a clearer dependence on N. At this scale  the mixing time grows
almost linearly with N  indicating that this chain is efﬁcient at least at small to medium scale.
Finally  we empirically study how fast our sampler on strongly Rayleigh distribution converges. We
compare the chain in Algorithm 1 (Mix) against a simple add-delete chain (Add-Delete). We use a
DPP on Ailerons data4 of size 200  and the corresponding PSRF is shown in Fig. 3b. We observe that
Mix converges slightly slower than Add-Delete since it is lazier. However  the Add-Delete chain
does not always mix fast. Fig. 3c illustrates a different setting  where we modify the eigenspectrum
of the kernel matrix: the ﬁrst 100 eigenvalues are 500 and others 1/500. Such a kernel corresponds to

4http://www.dcc.fc.up.pt/657~ltorgo/Regression/DataSets.html

7

1.5

1.4

1.3

1.2

1.1

1

F
R
S
P

Potential Scale Reduction Factor

N=50
N=100
N=200
N=300
N=500
N=1000

0

1

2

3

4

6

7

8

9

10
×104

5

# Iter

(a)

s
r
e

t
I
 

#

7
6
5
4
3
2
1
0

×104

Approximate Mixing Time

0

200

400
600
Data Size
(b)

800

1000

Figure 2: Empirical mixing time analysis when varying dataset sizes  (a) PSRF’s for each set of
chains  (b) Approximate mixing time obtained by thresholding PSRF at 1.05.

almost an elementary DPP  where the size of the observed subsets sharply concentrates around 100.
Here  Add-Delete moves very slowly. Mix  in contrast  has the ability of exchanging elements
and thus converges way faster than Add-Delete.

0.6
0.5
0.4
0.3
0.2
0.1
0
-0.1
-0.2

l

a
V

Convergence for Inference
Marg
Cond-5
Cond-10

0

0.5

1.5

2
×104

1

# Iter

(a)

1.3

1.25

1.2

1.15

F
R
S
P

1.1

1.05

1

0

Potential Scale Reduction Factor
Add-Delete
Mix

2

4

# Iter

6

8

10
×104

(b)

1.3

1.25

1.2

1.15

F
R
S
P

1.1

1.05

1

0

Potential Scale Reduction Factor
Add-Delete
Mix

2

4

# Iter

6

8

10
×104

(c)

Figure 3: (a) Convergence of marginal and conditional probabilities by DPP on uniform matroid 
(b c) comparison between add-delete chain (Algorithm 3) and projection chain (Algorithm 1) for two
instances: slowly decaying spectrum and sharp step in the spectrum.

5 Discussion and Open Problems

We presented theoretical results on Markov chain sampling for discrete probabilistic models subject
to implicit and explicit constraints. In particular  under an implicit constraint that the probability
measure is strongly Rayleigh  we obtain an unconditional fast mixing guarantee. For distributions
with various explicit constraints we showed sufﬁcient conditions for fast mixing. We show empirically
that the dependencies of mixing times on various factors are consistent with our theoretical analysis.
There still exist many open problems in both implicitly- and explicitly-constrained settings. Many
bounds that we show depend on structural quantities (⇣F or ↵) that may not always be easy to quantify
in practice. It will be valuable to develop chains on special classes of distributions (like we did for
strongly Rayleigh) whose mixing time is independent of these factors. Moreover  we only considered
matroid bases or uniform matroids  while several important settings such as knapsack constraints
remain open. In fact  even uniform sampling with a knapsack constraint is not easy; a mixing time
of O(N 4.5) is known [33]. We defer the development of similar or better bounds  potentially with
structural factors like exp(⇣F )  on specialized discrete probabilistic models as our future work.
Acknowledgements. This research was partially supported by NSF CAREER 1553284 and a Google
Research Award.

8

References
[1] D. J. Aldous. Some inequalities for reversible Markov chains. Journal of the London Mathematical Society 

pages 564–576  1982.

[2] N. Anari and S. O. Gharan. Effective-resistance-reducing ﬂows and asymmetric tsp. In FOCS  2015.
[3] N. Anari  S. O. Gharan  and A. Rezaei. Monte Carlo Markov chain algorithms for sampling strongly

Rayleigh distributions and determinantal point processes. In COLT  2016.

[4] J. Borcea  P. Brändén  and T. Liggett. Negative dependence and the geometry of polynomials. Journal of

the American Mathematical Society  pages 521–567  2009.

[5] A. Bouchard-Côté and M. I. Jordan. Variational inference over combinatorial spaces. In NIPS  2010.
[6] A. Broder. Generating random spanning trees. In FOCS  pages 442–447  1989.
[7] S. P. Brooks and A. Gelman. General methods for monitoring convergence of iterative simulations. Journal

of computational and graphical statistics  pages 434–455  1998.

[8] R. Bubley and M. Dyer. Path coupling: A technique for proving rapid mixing in Markov chains. In FOCS 

pages 223–231  1997.

[9] N. Cesa-Bianchi and G. Lugosi. Combinatorial bandits. In COLT  2009.
[10] P. Diaconis and D. Stroock. Geometric bounds for eigenvalues of Markov chains. The Annals of Applied

Probability  pages 36–61  1991.

In NIPS  pages 244–252  2014.

and Algorithms  pages 285–317  1998.

[11] J. Djolonga and A. Krause. From MAP to marginals: Variational inference in bayesian submodular models.

[12] M. Dyer and C. Greenhill. A more rapidly mixing Markov chain for graph colorings. Random Structures

[13] M. Dyer  A. Frieze  and M. Jerrum. On counting independent sets in sparse graphs. In FOCS  1999.
[14] S. Ermon  C. P. Gomes  A. Sabharwal  and B. Selman. Embed and project: Discrete sampling with

universal hashing. In NIPS  pages 2085–2093  2013.

[15] T. Feder and M. Mihail. Balanced matroids. In STOC  pages 26–38  1992.
[16] A. Frieze  N. Goyal  L. Rademacher  and S. Vempala. Expanders via random spanning trees. SIAM Journal

[17] M. Gartrell  U. Paquet  and N. Koenigstein. Low-rank factorization of determinantal point processes for

[18] A. Gelman and D. B. Rubin. Inference from iterative simulation using multiple sequences. Statistical

on Computing  43(2):497–513  2014.

recommendation. arXiv:1602.05436  2016.

science  pages 457–472  1992.

[19] A. Gotovos  H. Hassani  and A. Krause. Sampling from probabilistic submodular models. In NIPS  2015.
[20] D. M. Greig  B. T. Porteous  and A. H. Seheult. Exact maximum a posteriori estimation for binary images.

Journal of the Royal Statistical Society  1989.

[21] R. Iyer and J. Bilmes. Submodular point processes. In AISTATS  2015.
[22] M. Jerrum and A. Sinclair. Polynomial-time approximation algorithms for the Ising model. SIAM J.

Computing  1993.

2319–2327  2013.

[23] M. Jerrum  A. Sinclair  and E. Vigoda. A polynomial-time approximation algorithm for the permanent of a

matrix with nonnegative entries. JACM  2004.

[24] B. Kang. Fast determinantal point process sampling with application to clustering.

In NIPS  pages

[25] T. Kathuria and A. Deshpande. On sampling from constrained diversity promoting point processes. 2016.
[26] M. Kojima and F. Komaki. Determinantal point process priors for Bayesian variable selection in linear

regression. arXiv:1406.2100  2014.

[27] A. Kulesza and B. Taskar. k-DPPs: Fixed-size determinantal point processes. In ICML  pages 1193–1200 

[28] A. Kulesza and B. Taskar. Determinantal point processes for machine learning.

arXiv preprint

arXiv:1207.6083  2012.

[29] C. Li  S. Jegelka  and S. Sra. Fast DPP sampling for Nyström with application to kernel methods. In ICML 

[30] C. Li  S. Sra  and S. Jegelka. Gaussian quadrature for matrix inverse forms with applications. In ICML 

2011.

2016.

2016.

[31] C. J. Maddison  D. Tarlow  and T. Minka. A* sampling. In NIPS  2014.
[32] Z. Mariet and S. Sra. Diversity networks. In ICLR  2016.
[33] B. Morris and A. Sinclair. Random walks on truncated cubes and sampling 0-1 knapsack solutions. SIAM

journal on computing  pages 195–226  2004.

[34] P. Rebeschini and A. Karbasi. Fast mixing for discrete point processes. In COLT  2015.
[35] A. Sinclair. Improved bounds for mixing rates of Markov chains and multicommodity ﬂow. Combinatorics 

probability and Computing  pages 351–370  1992.

[36] D. Smith and J. Eisner. Dependency parsing by belief propagation. In EMNLP  2008.
[37] D. Spielman and N. Srivastava. Graph sparsiﬁcation by effective resistances. In STOC  2008.
[38] J. Zhang  J. Djolonga  and A. Krause. Higher-order inference for multi-class log-supermodular models. In

ICCV  pages 1859–1867  2015.

9

,Chengtao Li
Suvrit Sra
Stefanie Jegelka
Yi Ding
Risi Kondor
Jonathan Eskreis-Winkler