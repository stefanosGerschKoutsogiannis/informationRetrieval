2008,Bounds on marginal probability distributions,We propose a novel bound on single-variable marginal probability distributions in factor graphs with discrete variables. The bound is obtained by propagating bounds (convex sets of probability distributions) over a subtree of the factor graph  rooted in the variable of interest. By construction  the method not only bounds the exact marginal probability distribution of a variable  but also its approximate Belief Propagation marginal (``belief''). Thus  apart from providing a practical means to calculate bounds on marginals  our contribution also lies in providing a better understanding of the error made by Belief Propagation. We show that our bound outperforms the state-of-the-art on some inference problems arising in medical diagnosis.,Bounds on marginal probability distributions

Joris Mooij

MPI for Biological Cybernetics

T¨ubingen  Germany

joris.mooij@tuebingen.mpg.de

b.kappen@science.ru.nl

Bert Kappen

Department of Biophysics

Radboud University Nijmegen  the Netherlands

Abstract

We propose a novel bound on single-variable marginal probability distributions in
factor graphs with discrete variables. The bound is obtained by propagating local
bounds (convex sets of probability distributions) over a subtree of the factor graph 
rooted in the variable of interest. By construction  the method not only bounds
the exact marginal probability distribution of a variable  but also its approximate
Belief Propagation marginal (“belief”). Thus  apart from providing a practical
means to calculate bounds on marginals  our contribution also lies in providing
a better understanding of the error made by Belief Propagation. We show that
our bound outperforms the state-of-the-art on some inference problems arising in
medical diagnosis.

1 Introduction

Graphical models are used in many different ﬁelds. A fundamental problem in the application of
graphical models is that exact inference is NP-hard [1]. In recent years  much research has focused
on approximate inference techniques  such as sampling methods and deterministic approximation
methods  e.g.  Belief Propagation (BP) [2]. Although the approximations obtained by these meth-
ods can be very accurate  there are only few useful guarantees on the error of the approximation 
and often it is not known (without comparing with the intractable exact solution) how accurate an
approximate result is. Thus it is desirable to calculate  in addition to the approximate results  tight
bounds on the approximation error.
There exist various methods to bound the BP error [3  4  5  6]  which can be used  in conjunction
with the results of BP  to calculate bounds on the exact marginals. Furthermore  upper bounds on
the partition sum  e.g.  [7  8]  can be combined with lower bounds on the partition sum  such as
the well-known mean ﬁeld bound or higher-order lower bounds [9]  to obtain bounds on marginals.
Finally  a method called Bound Propagation [10] directly calculates bounds on marginals. However 
most of these bounds (with the exception of [3  10]) have only been formulated for the special case
of pairwise interactions  which limits their applicability  excluding for example the interesting class
of Bayesian networks.
In this contribution we describe a novel bound on exact single-variable marginals in factor graphs
which is not limited to pairwise interactions. The original motivation for this work was to better
understand and quantify the BP error. This has led to bounds which are at the same time bounds
for the exact single-variable marginals as well as for the BP beliefs. A particularly nice feature of
our bounds is that their computational cost is relatively low  provided that the number of possible
values of each variable in the factor graph is small. On the other hand  the computational complexity
is exponential in the number of possible values of the variables  which limits application to factor
graphs in which each variable has a low number of possible values. On these factor graphs however 
our bound can signiﬁcantly outperform existing methods  either in terms of accuracy or in terms
of computation time (or both). We illustrate this on two toy problems and on real-world problems
arising in medical diagnosis.

The basic idea underlying our method is that we recursively propagate bounds over a particular sub-
tree of the factor graph. The propagation rules are similar to those of Belief Propagation; however 
instead of propagating messages  we propagate convex sets of messages. This can be done in such
a way that the ﬁnal “beliefs” at the root node of the subtree are convex sets which contain the exact
marginal of the root node (and  by construction  also its BP belief). In the next section  we describe
our method in more detail. Due to space constraints  we have omitted the proofs and other techni-
cal details; these are provided in a technical report [11]  which also reports additional experimental
results and presents an extension that uses self-avoiding-walk trees instead of subtrees (inspired by
[6]).

2 Theory

2.1 Preliminaries
Factorizing probability distributions. Let V := {1  . . .   N} and consider N discrete random
variables (xi)i∈V. Each variable xi takes values in a discrete domain Xi. We will use the following
multi-index notation: let A = {i1  i2  . . .   im} ⊆ V with i1 < i2 < . . . im; we write XA := Xi1 ×
Xi2 × ··· × Xim and for any family (Yi)i∈B with A ⊆ B ⊆ V  we write YA := (Yi1  Yi2  . . .   Yim).
We consider a probability distribution over x = (x1  . . .   xN ) ∈ XV that can be written as a product
of factors (ψI)I∈F :

(cid:89)

I∈F

P(x) =

1
Z

ψI(xNI ) 

where Z = (cid:88)

(cid:89)

x∈XV

I∈F

ψI(xNI ).

(1)

For each factor index I ∈ F  there is an associated subset NI ⊆ V of variable indices and the
factor ψI is a nonnegative function ψI : XNI → [0 ∞). For a Bayesian network  the factors are
(conditional) probability tables. In case of Markov random ﬁelds  the factors are often called poten-
tials. In general  the normalizing constant (“partition sum”) Z is not known and exact computation
of Z is infeasible  due to the fact that the number of terms to be summed is exponential in the
number of variables N. Similarly  computing marginal distributions P(xA) for subsets of variables
A ⊆ V is intractable in general. In this article  we focus on the task of obtaining rigorous bounds on

single-variable marginals P(xi) =(cid:80)

P(x).

xV\{i}

Factor graphs. We can represent the structure of the probability distribution (1) using a factor
graph (V F E). This is a bipartite graph  consisting of variable nodes i ∈ V  factor nodes I ∈ F 
and edges e ∈ E  with an edge {i  I} between i ∈ V and I ∈ F if and only if the factor ψI
depends on xi (i.e.  if i ∈ NI). We will represent factor nodes visually as rectangles and variable
nodes as circles. Figure 1(a) shows a simple example of a factor graph. The set of neighbors
of a factor node I is precisely NI; similarly  we denote the set of neighbors of a variable node i by
Ni := {I ∈ F : i ∈ NI}. We will assume throughout this article that the factor graph corresponding
to (1) is connected.
Convexity. We denote the set of extreme points of a convex set X ⊆ Rd by ext (X). For a subset
Y ⊆ Rd  the convex hull of Y is deﬁned as the smallest convex set X ⊆ Rd with Y ⊆ X; we denote
the convex hull of Y as conv (Y ).
Measures. For A ⊆ V  deﬁne MA := [0 ∞)XA as the set of nonnegative functions on XA. Each
element of MA can be identiﬁed with a ﬁnite measure on XA; therefore we will call the elements
of MA “measures on A”. We write M∗
Operations on measures. Adding two measures Ψ  Φ ∈ MA results in the measure Ψ + Φ in MA.
For A  B ⊆ V  we can multiply a measure on MA with a measure on MB to obtain a measure
on MA∪B; a special case is multiplication with a scalar. Note that there is a natural embedding of
MA in MB for A ⊆ B ⊆ V obtained by multiplying a measure Ψ ∈ MA by 1B\A ∈ MB\A 
the constant function with value 1 on XB\A. Another important operation is the partial summation:
Ψ to be the measure in MB\A obtained by summing
xA∈XA

given A ⊆ B ⊆ V and Ψ ∈ MB  deﬁne(cid:80)
Ψ over all xa ∈ XA  i.e. (cid:80)
Ψ : xB\A (cid:55)→(cid:80)

A := MA \ {0}.

Ψ(xA  xB\A).

xA

xA

Operations on sets of measures. We will deﬁne operations on sets of measures by applying the
operation on elements of these sets and taking the set of the resulting measures; e.g.  if we have two

xA

factorized measures on A  i.e.  QA := (cid:81)
i.e.  PA = {Ψ ∈ MA : (cid:80)

subsets ΞA ⊆ MA and ΞB ⊆ MB for A  B ⊆ V  we deﬁne the product of the sets ΞA and ΞB to be
the set of the products of elements of ΞA and ΞB  i.e.  ΞAΞB := {ΨAΨB : ΨA ∈ ΞA  ΨB ∈ ΞB}.
Completely factorized measures. For A ⊆ V  we will deﬁne QA to be the set of completely
a∈A M{a}. Note that MA is the convex hull of QA.
Indeed  we can write each measure Ψ ∈ MA as a convex combination of measures in QA which
are zero everywhere except at one particular value of their argument. We denote Q∗
A := QA \ {0}.
Normalized (probability) measures. We denote with PA the set of probability measures on A 
Ψ = 1}. The set PA is called a simplex. Note that a simplex is
convex; the simplex PA has precisely #(XA) extreme points  each of which corresponds to putting
all probability mass on one of the possible values of xA. We deﬁne the normalization operator N
which normalizes measures  i.e.  for Ψ ∈ M∗
Boxes. Let a  b ∈ Rd such that aα ≤ bα for all components α = 1  . . .   d. Then we de-
ﬁne the box with lower bound a and upper bound b by B (a  b) := {x ∈ Rd : aα ≤ xα ≤
bα for all α = 1  . . .   d}. Note that a box is convex; indeed  its extreme points are the “corners” of
which there are 2d.
Smallest bounding boxes. Let X ⊆ Rd be bounded. The smallest bounding box of X is deﬁned
as B (X) := B (a  b) where the lower bound a is given by the pointwise inﬁmum of X and the
upper bound b is given by the pointwise supremum of X  that is aα := inf{xα : x ∈ X} and
bα := sup{xα : x ∈ X} for all α = 1  . . .   d. Note that B (X) = B (conv (X)). Therefore  if
X is convex  the smallest bounding box for X depends only on the extreme points ext (X)  i.e. 
B (X) = B (ext (X)); this bounding box can be easily calculated if the number of extreme points is
not too large.

Z Ψ with Z =(cid:80)

A we deﬁne N Ψ := 1

Ψ.

xA

2.2 The basic tools

To calculate marginals of subsets of variables in some factor graph  several operations performed
on measures are relevant: normalization  taking products of measures  and summing over subsets of
variables. Here we study the interplay between convexity and these operations. This will turn out
to be useful later on  because our bounds make use of convex sets of measures that are propagated
over the factor graph.
The interplay between convexity and normalization  taking products and partial summation is de-
scribed by the following lemma.
Lemma 1 Let A ⊆ V and let Ξ ⊆ M∗

A. Then:

1. conv (N Ξ) = N (conv Ξ);
2. for all B ⊆ V  Ψ ∈ MB: conv (ΨΞ) = Ψ(conv Ξ);

3. for all B ⊆ A: conv(cid:0)(cid:80)

Ξ(cid:1) =(cid:80)

xB

xB

conv Ξ.

(cid:3)

The next lemma concerns the interplay between convexity and taking products; it says that if we
take the product of convex sets of measures on different spaces  the resulting set is contained in the
convex hull of the product of the extreme points of the convex sets.
Lemma 2 Let (At)t=1 ... T be disjoint subsets of V. For each t = 1  . . .   T   let Ξt ⊆ MAt be
. (cid:3)
convex with a ﬁnite number of extreme points. Then conv

(cid:16)(cid:81)T

(cid:16)(cid:81)T

= conv

(cid:17)

(cid:17)

t=1 ext Ξt

t=1 Ξt

The third lemma says that the product of several boxes on the same subset A of variables can be
easily calculated: the product of the boxes is again a box  with as lower (upper) bound the product
of the lower (upper) bounds of the boxes.
t=1 B(cid:0)Ψt  Ψt
(cid:81)T
Lemma 3 Let A ⊆ V and for each t = 1  . . .   T   let Ψt  Ψt ∈ MA such that Ψt ≤ Ψt. Then
(cid:3)

(cid:1) = B(cid:16)(cid:81)T

t=1 Ψt (cid:81)T

t=1 Ψt

(cid:17)

.

We are now ready to state the basic lemma. It basically says that one can bound the marginal of
a variable by replacing a factor depending on some other variables by a product of single-variable

(a)

i

(b)

i

(c)

i

(d)

i

(e)

J

K

J

K

J

K

J

K

Bi
i

BJ→i

BK→i

J

K

j

L

k

δ

j

j(cid:48)

k

L

j

?

j

k

L

Bj→J
j

BL→j

Pj

k

L

j(cid:48)

?

Bk→K
k
BL→k
L

Bj→L

Pj

Figure 1:
(a) Example factor graph with three variable nodes (i  j  k) and three factor nodes
(J  K  L)  with probability distribution P(xi  xj  xk) = 1
Z ψJ(xi  xj)ψK(xi  xk)ψL(xj  xk); (b)
Cloning node j by adding a new variable j(cid:48) and a factor ψδ(xj  xj(cid:48)) = δxj (xj(cid:48)); (c) Illustration
of the bound on P(xi) based on (b): “what can we say about the range of P(xi) when the factors
corresponding to the nodes marked with question marks are arbitrary?”; (d) Subtree of the factor
graph; (e) Propagating convex sets of measures (boxes or simplices) on the subtree (d)  leading to a
bound Bi on the marginal probability of xi in G.

factors and bounding the result. This can be exploited to simplify the computational complexity of
bounding the marginal. An example of its use will be given in the next subsection.
Lemma 4 Let A  B  C ⊆ V be mutually disjoint subsets of variables. Let Ψ ∈ MA∪B∪C such that

for each xC ∈ XC (cid:80)

xA∪B

(cid:32)

(cid:32) (cid:88)

Ψ > 0. Then:
ΨM∗
N

C

B

(cid:33)(cid:33)

(cid:32)

(cid:32) (cid:88)

= B

N

(cid:33)(cid:33)

ΨQ∗

C

.

xB  xC

xB  xC

Proof. Note that M∗
(cid:3)
The positivity condition is a technical condition  which in our experience is fulﬁlled for many prac-
tically relevant factor graphs.

C is the convex hull of Q∗

C and apply Lemma 1.

2.3 A simple example

Before proceeding to our main result  we ﬁrst illustrate for a simple case how the basic lemma can
be employed to obtain computationally tractable bounds on marginals. We derive a bound for the
marginal of the variable xi in the factor graph in Figure 1(a). We start by cloning the variable xj 
i.e.  adding a new variable xj(cid:48) that is constrained to take the same value as xj. In terms of the
factor graph  we add a variable node j(cid:48) and a factor node δ  connected to variable nodes j and j(cid:48) 
with corresponding factor ψδ(xj  xj(cid:48)) := δxj (xj(cid:48)); see also Figure 1(b). Clearly  the marginal of xi
satisﬁes:

P(xi) = N

ψJ ψKψL

ψJ ψKψLδxj (xj(cid:48))



where it should be noted that the ﬁrst occurrence of ψL is shorthand for ψL(xj  xk)  but the second
occurrence is shorthand for ψL(xj(cid:48)   xk). Noting that ψδ ∈ M∗
{j j(cid:48)} and applying the basic lemma
with A = {i}  B = {k}  C = {j  j(cid:48)} and Ψ = ψJ ψKψL yields:

P(xi) ∈ N

ψJ ψKψLM∗

xj
Applying the distributive law  we obtain (see also Figure 1(c)):

xk

xj

xj(cid:48)

P(xi) ∈ BN

ψJM∗
{j}

xj

xk

xj(cid:48)

(cid:88)

(cid:88)

(cid:88)

xj

xk

(cid:88)

(cid:88)

(cid:88)

xj

(cid:88)
 = N
 ∈ BN
(cid:88)

{j j(cid:48)}

(cid:88)

(cid:88)

xj(cid:48)

xk

(cid:88)
(cid:88)

ψK

 .

ψJ ψKψLQ∗

{j j(cid:48)}

(cid:88)

(cid:88)

xj(cid:48)

xk

ψLM∗

{j(cid:48)}

  

which we relax to

P(xi) ∈ BN

ψJP{j}

ψKBN

ψLP{j(cid:48)}

BN
(cid:88)
(cid:88)
BN

xj

BN
BN

xk

(cid:88)
(cid:88)

xj(cid:48)

(cid:88)
(cid:88)

 .
 .

Now it may seem that this smallest bounding box would be difﬁcult to compute. Fortunately  we
only need to compute the extreme points of these sets because of convexity. Since smallest bounding
boxes only depend on extreme points  we conclude that

P(xi) ∈ BN

ψJextP{j}

ψKBN

ψLextP{j(cid:48)}

which can be calculated efﬁciently if the number of possible values of each variable is small.

xj

xk

xj(cid:48)

2.4 The main result

The example in the previous subsection can be generalized as follows. First  one chooses a particular
subtree of the factor graph  rooted in the variable for which one wants to calculate a bound on its
marginal. Then  one propagates messages (which are either bounding boxes or simplices) over this
subtree  from the leaf nodes towards the root node. The update equations resemble those of Belief
Propagation. The resulting “belief” at the root node is a box that bounds the exact marginal of
the root node. The choice of the subtree is arbitrary; different choices lead to different bounds in
general. We now describe this “box propagation” algorithm in more detail.
Deﬁnition 5 Let (V F E) be a factor graph. We call the bipartite graph (V  F  E) a subtree of
(V F E) with root i if i ∈ V ⊆ V  F ⊆ F  E ⊆ E such that (V  F  E) is a tree with root i and for
all {j  J} ∈ E  j ∈ V and J ∈ F (i.e.  there are no “loose edges”).1 We denote the parent of j ∈ V
according to (V  F  E) by par(j) and similarly  we denote the parent of J ∈ F by par(J).
An illustration of a possible subtree of the factor graph in Figure 1(a) is the one shown in Figure
1(d). The bound that we will obtain using this subtree corresponds to the example described in the
previous subsection.
In the following  we will use the topology of the original factor graph (V F E) whenever we refer
to neighbors of variables or factors. Each edge of the subtree will carry one message  oriented such
that it “ﬂows” towards the root node. In addition  we deﬁne messages entering the subtree for all
“missing” edges in the subtree (see also Figure 1(e)). Because of the bipartite character of the factor
graph  we can distinguish two types of messages: messages BJ→j ⊆ Mj sent to a variable j ∈ V
from a neighboring factor J ∈ Nj  and messages Bj→J ⊆ Mj sent to a factor J ∈ F from a
neighboring variable j ∈ NJ. The messages entering the subtree are all deﬁned to be simplices;
more precisely  we deﬁne the incoming messages

Bj→J = Pj
BJ→j = Pj

for all J ∈ F   {j  J} ∈ E \ E
for all j ∈ V   {j  J} ∈ E \ E.

We propagate messages towards the root i of the tree using the following update rules (note the
similarity with the BP update rules). The message sent from a variable j ∈ V to its parent J =
par(j) ∈ F is deﬁned as

Bj→J =

BK→j

if all incoming BK→j are boxes
if at least one of the BK→j is the simplex Pj 

where the product of the boxes can be calculated using Lemma 3. The message sent from a factor
J ∈ F to its parent k = par(J) ∈ V is deﬁned as

(cid:89)

Bl→J

ψJ

l∈NJ\k

 = BN

 (cid:88)

(cid:89)

ψJ

xNJ \k

l∈NJ\k

extBl→J

(2)

  

BJ→k = BN

K∈Nj\J
Pj

(cid:89)


 (cid:88)

xNJ \k

1Note that this corresponds to the notion of subtree of a bipartite graph; for a subtree of a factor graph  one
sometimes imposes the additional constraint that for all factors J ∈ F   all its connecting edges {J  j} with
j ∈ NJ have to be in E; here we do not impose this additional constraint.

where the second equality follows from Lemmas 1 and 2. The ﬁnal “belief” Bi at the root node i is
calculated by

(cid:33)

BK→i

(cid:32) (cid:89)

K∈Ni

BN

Pi

Bi =

if all incoming BK→i are boxes
if at least one of the BK→i is the simplex Pi.

We can now formulate our main result  which gives a rigorous bound on the exact single-variable
marginal of the root node:
Theorem 6 Let (V F E) be a factor graph with corresponding probability distribution (1). Let
i ∈ V and (V  F  E) be a subtree of (V F E) with root i ∈ V . Apply the “box propagation”
algorithm described above to calculate the ﬁnal “belief” Bi on the root node i. Then P(xi) ∈ Bi.
Proof sketch The ﬁrst step consists in extending the subtree such that each factor node has the
right number of neighboring variables by cloning the missing variables. The second step consists
of applying the basic lemma where the set C consists of all the variable nodes of the subtree which
have connecting edges in E \ E  together with all the cloned variable nodes. Then we apply the
distributive law  which can be done because the extended subtree has no cycles. Finally  we relax
the bound by adding additional normalizations and smallest bounding boxes at each factor node in
the subtree. It should now be clear that the “box propagation” algorithm described above precisely
(cid:3)
calculates the smallest bounding box at the root node i that corresponds to this procedure.
Because each subtree of the orginal factor graph is also a subtree of the computation tree for i
[12]  the bounds on the (exact) marginals that we just derived are at the same time bounds on the
approximate Belief Propagation marginals (beliefs):
Corollary 7 In the situation described in Theorem 6  the ﬁnal bounding box Bi also bounds the
(approximate) Belief Propagation marginal of the root node i  i.e.  PBP (xi) ∈ Bi.
(cid:3)

2.5 Related work

We brieﬂy discuss the relationship of our bound to previous work. More details are provided in [11].
The bound in [6] is related to the bound we present here; however  the bound in [6] differs from ours
in that it (i) goes deeper into the computation tree by propagating bounds over self-avoiding-walk
(SAW) trees instead of mere subtrees  (ii) uses a different parameterization of the propagated bounds
and a different update rule  and (iii)  it is only formulated for the special case of factors depending
on two variables  while it is not entirely obvious how to extend the result to more general factor
graphs.
Another method to obtain bounds on exact marginals is “Bound Propagation” [10]. The idea un-
derlying Bound Propagation is very similar to the one employed in this work  with one crucial
pear in some factor in which i participates) and ∂i := ∆i \ {i} (the Markov blanket of i). Whereas
our method uses a cavity approach  using as basis equation

difference. For a variable i ∈ V  we deﬁne the sets ∆i :=(cid:83) Ni (consisting of all variables that ap-

(cid:33)

(cid:32)(cid:89)

I∈Ni

ψI

P\i(x∂i) 

P\i(x∂i) ∝ (cid:88)

(cid:89)

ψI

xV\∆i

I∈F\Ni

P(xi) ∝(cid:88)
Propagation is P(xi) =(cid:80)

x∂i

x∂i

and bound the quantity P(xi) by optimizing over P\i(x∂i)  the basis equation employed by Bound
P(xi | x∂i)P(x∂i) and the optimization is over P(x∂i). Unlike in our
case  the computational complexity of Bound Propagation is exponential in the size of the Markov
blanket  because of the required calculation of the conditional distribution P(xi | x∂i). On the other
hand  the advantage of this approach is that a bound on P(xj) for j ∈ ∂i is also a bound on P(x∂i) 
which in turn gives rise to a bound on P(xi). In this way  bounds can propagate through the graphical
model  eventually yielding a new (tighter) bound on P(x∂i). Although the iteration can result in
rather tight bounds  the main disadvantage of Bound Propagation is its computational cost: it is
exponential in the Markov blanket and often many iterations are needed for the bounds to become
tight.

Figure 2: Comparisons of various methods on different factor graphs: PROMEDAS (left)  a large grid
with strong interactions (middle) and a small grid with medium-strength interactions (right).

3 Experiments

In this section  we present only few empirical results due to space constraints. More details and
additional experimental results are given in [11]. We have compared different methods for calculat-
ing bounds on single-variable marginals; for each method and each variable  we calculated the gap
(tightness) of the bound  which we deﬁned as the (cid:96)∞ distance between the upper and lower bound of
the bounding box. We have investigated three different types of factor graphs; the results are shown
in Figure 2. The factor graphs used for our experiments are provided as supplementary material to
the electronic version of this article at books.nips.cc. We also plan to release the source code
of several methods as part of a new release of the approximate inference library libDAI [13]. For
our method  we chose the subtrees in a breadth-ﬁrst manner.
First  we applied our bound on simulated PROMEDAS patient cases [14]. These factor graphs have
binary variables and singleton  pairwise and triple interactions (containing zeros). We generated nine
different random instances. For each instance  we calculated bounds for each “ﬁnding” variable in
that instance using our method (“BOXPROP”) and the method in [10]. Note that the tightness of
both bounds varies widely depending on the instance and on the variable of interest. Our bound was
tighter than the bound from [10] for all but one out of 1270 variables. Furthermore  whereas [10]
had only ﬁnished on 7 out of 9 instances after running for 75000 s (after which we decided to abort
the calculation on the remaining two instances)  our method only needed 51 s to calculate all nine
instances.
We also compared our method with the method described in [6] on a large grid of 100 × 100 binary
(±1-valued) variables with strong interactions. Note that this is an intractable problem for exact
inference methods. The single-variable factors were chosen as exp(θixi) with θi ∼ N (0  1)  the
pair factors were exp(θijxixj) with θij ∼ N (0  1). We truncated the subtree to 400 nodes and the
SAW tree to 105 nodes. Note that our method yields the tightest bound for almost all variables.
Finally  we compared our method with several other methods referred to in Section 1 on a small
8 × 8 grid with medium-strength interactions (similarly chosen as for the large grid  but with
θi ∼ N (0  0.22) and θij ∼ N (0  0.22)). The small size of the grid was necessary because some
methods would need several days to handle a large grid. In this case  the method by [6] yields the
tightest bounds  followed by [10]  and our method gets a third place. Note that many methods return
completely uninformative bounds in this case.

4 Conclusion and discussion

We have described a novel bound on exact single-variable marginals  which is at the same time a
bound on the (approximate) Belief Propagation marginals. Contrary to many other existing bounds 
it is formulated for the general case of factor graphs with discrete variables and factors depending on
an arbitrary number of variables. The bound is calculated by propagating convex sets of measures
over a subtree of the factor graph  with update equations resembling those of BP. For variables with
a limited number of possible values  the bounds can be computed efﬁciently. We have compared our
bounds with existing methods and conclude that our method belongs to the best methods  but that
it is difﬁcult to say in general which method will yield the tightest bounds for a given variable in a

 0.0001 0.001 0.01 0.1 1 0.0001 0.001 0.01 0.1 1Gaps [10]Gaps BoxPropPROMEDAS 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1Gaps [6]Gaps BoxProp100x100 grid  strong interactions[4][5]BoxProp[6][10][3]+[8]MF-[8][9]-[8]MF-[7][9]-[7] 0.001 0.01 0.1 1Gaps8x8 toroidal grid  medium interactionsspeciﬁc factor graph. Our method could be further improved by optimizing over the choice of the
subtree.
Although our bounds are a step forward in quantifying the error of Belief Propagation  the actual
error made by BP is often at least one order of magnitude lower than the tightness of these bounds.
This is due to the fact that (loopy) BP cycles information through loops in the factor graph; this
cycling apparently often improves the results. The interesting and still unanswered question is why
it makes sense to cycle information in this way and whether this error reduction effect can be quan-
tiﬁed.

Acknowledgments

We thank Wim Wiegerinck for several fruitful discussions  Bastian Wemmenhove for providing the PROMEDAS
test cases  and Martijn Leisink for kindly providing his implementation of Bound Propagation. The research
reported here was supported by the Interactive Collaborative Information Systems (ICIS) project (supported by
the Dutch Ministry of Economic Affairs  grant BSIK03024)  the Dutch Technology Foundation (STW)  and the
IST Programme of the European Community  under the PASCAL2 Network of Excellence  IST-2007-216886.

References

[1] G.F. Cooper. The computational complexity of probabilistic inferences. Artiﬁcial Intelligence  42(2-

3):393–405  March 1990.

[2] J. Pearl. Probabilistic Reasoning in Intelligent systems: Networks of Plausible Inference. Morgan Kauf-

mann  San Francisco  CA  1988.

[3] M.J. Wainwright  T.S. Jaakkola  and A.S. Willsky. Tree-based reparameterization framework for analysis
IEEE Transactions on Information Theory  49(5):1120–1146 

of sum-product and related algorithms.
May 2003.

[4] S. C. Tatikonda. Convergence of the sum-product algorithm.

Theory Workshop  pages 222–225  April 2003.

In Proceedings 2003 IEEE Information

[5] Nobuyuki Taga and Shigeru Mase. Error bounds between marginal probabilities and beliefs of loopy

belief propagation algorithm. In MICAI  pages 186–196  2006.

[6] A. Ihler. Accuracy bounds for belief propagation.

In Proceedings of the 23th Annual Conference on

Uncertainty in Artiﬁcial Intelligence (UAI-07)  July 2007.

[7] T. S. Jaakkola and M. Jordan. Recursive algorithms for approximating probabilities in graphical models.

In Proc. Conf. Neural Information Processing Systems (NIPS 9)  pages 487–493  Denver  CO  1996.

[8] M. J. Wainwright  T. Jaakkola  and A. S. Willsky. A new class of upper bounds on the log partition

function. IEEE Transactions on Information Theory  51:2313–2335  July 2005.

[9] M. A. R. Leisink and H. J. Kappen. A tighter bound for graphical models. In Lawrence K. Saul  Yair
Weiss  and L´eon Bottou  editors  Advances in Neural Information Processing Systems 13 (NIPS*2000) 
pages 266–272  Cambridge  MA  2001. MIT Press.

[10] M. Leisink and B. Kappen. Bound propagation. Journal of Artiﬁcial Intelligence Research  19:139–154 

2003.

[11] J. M. Mooij and H. J. Kappen. Novel bounds on marginal probabilities. arXiv.org  arXiv:0801.3797

[math.PR]  January 2008. Submitted to Journal of Machine Learning Research.

[12] S. C. Tatikonda and M. I. Jordan. Loopy belief propagation and Gibbs measures. In Proc. of the 18th
Annual Conf. on Uncertainty in Artiﬁcial Intelligence (UAI-02)  pages 493–500  San Francisco  CA  2002.
Morgan Kaufmann Publishers.

[13] J. M. Mooij. libDAI: A free/open source C++ library for discrete approximate inference methods  2008.

http://mloss.org/software/view/77/.

[14] B. Wemmenhove  J. M. Mooij  W. Wiegerinck  M. Leisink  H. J. Kappen  and J. P. Neijt. Inference in
the Promedas medical expert system. In Proceedings of the 11th Conference on Artiﬁcial Intelligence in
Medicine (AIME 2007)  volume 4594 of Lecture Notes in Computer Science  pages 456–460. Springer 
2007.

,Gabriel Krummenacher
Brian McWilliams
Yannic Kilcher
Joachim Buhmann
Nicolai Meinshausen