2013,Auditing: Active Learning with Outcome-Dependent Query Costs,We propose a learning setting in which unlabeled data is free  and the cost of a label depends on its value  which is not known in advance. We study binary classification in an extreme case  where the algorithm only pays for negative labels. Our motivation are applications such as fraud detection  in which investigating an honest transaction should be avoided if possible. We term the setting auditing  and consider the auditing complexity of an algorithm: The number of negative points it labels to learn a hypothesis with low relative error. We design auditing algorithms for thresholds on the line and axis-aligned rectangles  and show that with these algorithms  the auditing complexity can be significantly lower than the active label complexity. We discuss a general approach for auditing for a general hypothesis class  and describe several interesting directions for future work.,Auditing: Active Learning with
Outcome-Dependent Query Costs

Sivan Sabato

Microsoft Research New England

sivan.sabato@microsoft.com

Anand D. Sarwate

TTI-Chicago

asarwate@ttic.edu

Technion-Israel Institute of Technology and TTI-Chicago

Nathan Srebro

nati@ttic.edu

Abstract

We propose a learning setting in which unlabeled data is free  and the cost of a
label depends on its value  which is not known in advance. We study binary clas-
siﬁcation in an extreme case  where the algorithm only pays for negative labels.
Our motivation are applications such as fraud detection  in which investigating
an honest transaction should be avoided if possible. We term the setting audit-
ing  and consider the auditing complexity of an algorithm: the number of negative
labels the algorithm requires in order to learn a hypothesis with low relative er-
ror. We design auditing algorithms for simple hypothesis classes (thresholds and
rectangles)  and show that with these algorithms  the auditing complexity can be
signiﬁcantly lower than the active label complexity. We also show a general com-
petitive approach for learning with outcome-dependent costs.

1

Introduction

Active learning algorithms seek to mitigate the cost of learning by using unlabeled data and sequen-
tially selecting examples to query for their label to minimize total number of queries. In some cases 
however  the actual cost of each query depends on the true label of the example and is thus not known
before the label is requested. For instance  in detecting fraudulent credit transactions  a query with
a positive answer is not wasteful  whereas a negative answer is the result of a wasteful investigation
of an honest transaction  and perhaps a loss of good-will. More generally  in a multiclass setting 
different queries may entail different costs  depending on the outcome of the query. In this work we
focus on the binary case  and on the extreme version of the problem  as described in the example of
credit fraud  in which the algorithm only pays for queries which return a negative label. We term
this setting auditing  and the cost incurred by the algorithm its auditing complexity.
There are several natural ways to measure performance for auditing. For example  we may wish
the algorithm to maximize the number of positive labels it ﬁnds for a ﬁxed “budget” of negative
labels  or to minimize the number of negative labels while ﬁnding a certain number or fraction of
positive labels. In this work we focus on the classical learning problem  in which one attempts to
learn a classiﬁer from a ﬁxed hypothesis class  with an error close to the best possible. Similar to
active learning  we assume we are given a large set of unlabeled examples  and aim to learn with
minimal labeling cost. But unlike active learning  we only incur a cost when requesting the label of
an example that turns out to be negative.
The close relationship between auditing and active learning raises natural questions. Can the au-
diting complexity be signiﬁcantly better than the label complexity in active learning? If so  should

1

algorithms be optimized for auditing  or do optimal active learning algorithms also have low audit-
ing complexity? To answer these questions  and demonstrate the differences between active learning
and auditing  we study the simple hypothesis classes of thresholds and of axis-aligned rectangles in
Rd  in both the realizable and the agnostic settings. We then also consider a general competitive
analysis for arbitrary hypothesis classes.

Other work. Existing work on active learning with costs (Margineantu  2007; Kapoor et al.  2007;
Settles et al.  2008; Golovin and Krause  2011) typically assumes that the cost of labeling each
point is known a priori  so the algorithm can use the costs directly to select a query. Our model is
signiﬁcantly different  as the costs depend on the outcome of the query itself. Kapoor et al. (2007)
do mention the possibility of class-dependent costs  but this possibility is not studied in detail. An
unrelated game-theoretic learning model addressing “auditing” was proposed by Blocki et al. (2011).

Notation and Setup
For an integer m  let [m] = {1  2  . . .   m}. The function I[A] is the indicator function of a set A.
For a function f and a sub-domain X  f|X is the restriction of f to X. For vectors a and b in Rd 
the inequality a ≤ b implies ai ≤ bi for all i ∈ [d].
We assume a data domain X and a distribution D over labeled data points in X × {−1  +1}. A
learning algorithm may sample i.i.d. pairs (X  Y ) ∼ D. It then has access to the value of X  but the
label Y remains hidden until queried. The algorithm returns a labeling function ˆh : X → {−1  +1}.
The error of a function h : X → {−1  +1} on D is err(D  h) = E(X Y )∼D[h(X) (cid:54)= Y ]. The error
of h on a multiset S ⊆ X × {−1  +1} is given by err(S  h) = 1|S|
I[h(x) (cid:54)= y]. The
passive sample complexity of an algorithm is the number of pairs it draws from D. The active label
complexity of an algorithm is the total number of label queries the algorithm makes. Its auditing
complexity is the number of queries the algorithm makes on points with negative labels.
We consider guarantees for learning algorithms relative to a hypothesis class H ⊆ {−1  +1}X . We
denote the error of the best hypothesis in H on D by err(D H) = minh∈H err(D  h). Similarly 
err(S H) = minh∈H err(S  h). We usually denote the best error for D by η = err(D H).
To describe our algorithms it will be convenient to deﬁne the following sample sizes  using universal
constants C  c > 0. Let δ ∈ (0  1) be a conﬁdence parameter  and let  ∈ (0  1) be an error parameter.
Let mag(  δ  d) = C(d + ln(c/δ))/2. If a sample S is drawn from D with |S| = mag(  δ  d) then
with probability 1 − δ  ∀h ∈ H  err(D  h) ≤ err(S  h) +  and err(S H) ≤ err(D H) +  (Bartlett
and Mendelson  2002). Let mν(  δ  d) = C(d ln(c/ν) + ln(c/δ))/ν2. Results of Vapnik and
Chervonenkis (1971) show that if H has VC dimension d and S is drawn from D with |S| = mν 
then for all h ∈ H 

(cid:80)

(x y)∈S

err(S  h) ≤ max{err(D  h)(1 + ν)  err(D  h) + ν} and
err(D  h) ≤ max{err(S  h)(1 + ν)  err(S  h) + ν} .

(1)

2 Active Learning vs. Auditing: Summary of Results

The main point of this paper is that the auditing complexity can be quite different from the active
label complexity  and that algorithms tuned to minimizing the audit label complexity give improve-
ments over standard active learning algorithms. Before presenting these differences  we note that in
some regimes  neither active learning nor auditing can improve signiﬁcantly over the passive sample
complexity. In particular  a simple adaptation of a result of Beygelzimer et al. (2009)  establishes
the following lower bound.
Lemma 2.1. Let H be a hypothesis class with VC dimension d > 1. If an algorithm always ﬁnds a
hypothesis ˆh with err(D  ˆh) ≤ err(D H)+ for  > 0  then for any η ∈ (0  1) there is a distribution
D with η = err(D H) such that the auditing complexity of this algorithm for D is Ω(dη2/2).
That is  when η is ﬁxed while  → 0  the auditing complexity scales as Ω(d/2)  similar to the
passive sample complexity. Therefore the two situations which are interesting are the realizable

2

case  corresponding to η = 0  and the agnostic case  when we want to guarantee an excess error 
such that η/ is bounded. We provide results for both of these regimes.
We will ﬁrst consider the realizable case  when η = 0. Here it is sufﬁcient to consider the case
where a ﬁxed pool S of m points is given and the algorithm must return a hypothesis ˆh such that
err(S  ˆh) = 0 with probability 1. A pool labeling algorithm can be used to learn a hypothesis
which is good for a distribution by drawing and labeling a large enough pool. We deﬁne auditing
complexity for an unlabeled pool as the minimal number of negative labels needed to perfectly
classify it. It is easy to see that there are pools with an auditing complexity at least the VC dimension
of the hypothesis class.
For the agnostic case  when η > 0  we denote α = /η and say that an algorithm (α  δ)-learns a
class of distributions D with respect to H if for all D ∈ D  with probability 1 − δ  ˆh returned by
the algorithm satisﬁes err(D  ˆh) ≤ (1 + α)η. By Lemma 2.1 an auditing complexity of Ω(d/α2)
is unavoidable  but we can hope to improve over the passive sample complexity lower bound of
Ω(d/ηα2) (Devroye and Lugosi  1995) by avoiding the dependence on η.
Our main results are summarized in Table 1  which shows the auditing and active learning complex-
ities in the two regimes  for thresholds on [0  1] and axis-aligned rectangles in Rd  where we assume
that the hypotheses label the points in the rectangle as negative and points outside as positive.

Realizable Thresholds
Rectangles
Thresholds Ω
Rectangles Ω

Agnostic

Active
Θ(ln m)

(cid:17)

m

(cid:16) 1
(cid:16) 1

η

(cid:16)
(cid:16)

ln

d

(cid:17)
(cid:17)(cid:17)

+ 1
α2

η + 1
α2

Auditing

1
2d

(cid:1)
O(cid:0) 1
(cid:17) · 1
d2 ln2(cid:16) 1
α2 ln(cid:0) 1

α2

η

α

(cid:1)(cid:17)

(cid:16)

O

Table 1: Auditing complexity upper bounds vs. active label complexity lower bounds for realizable
(pool size m) and agnostic (err(D H) = η) cases. Agnostic bounds are for (α  δ)-learning with a
ﬁxed δ  where α = /η.

In the realizable case  for thresholds  the optimal active learning algorithm performs binary search 
resulting in Ω(ln m) labels in the worst case. This is a signiﬁcant improvement over the passive label
complexity of m. However  a simple auditing procedure that scans from right to left queries only
a single negative point  achieving an auditing complexity of 1. For rectangles  we present a simple
coordinate-wise scanning procedure with auditing complexity of at most 2d  demonstrating a huge
gap versus active learning  where the labels of all m points might be required. Not all classes enjoy
reduced auditing complexity: we also show that for rectangles with positive points on the inside 
there exists pools of size m with an auditing complexity of m.
In the agnostic case we wish to (α  δ)-learn distributions with a true error of η = err(D H)  for
constant α  δ. For active learning  it has been shown that in some cases  the Ω(d/η) passive sample
complexity can be replaced by an exponentially smaller O(d ln(1/η)) active label complexity (Han-
neke  2011)  albeit sometimes with a larger polynomial dependence on d. In other cases  an Ω(1/η)
dependence exists also for active learning. Our main question is whether the dependence on η in the
active label complexity can be further reduced for auditing.
For thresholds  active learning requires Ω(ln(1/η)) labels (Kulkarni et al.  1993). Using auditing 
we show that the dependence on η can be completely removed  for any true error level η > 0  if
we know η in advance. We also show that if η is not known at least approximately  the logarithmic
dependence on 1/η is unavoidable also for auditing. For rectangles  we show that the active label
complexity is at least Ω(d/η). In contrast  we propose an algorithm with an auditing complexity
of O(d2 ln2(1/η))  reducing the linear dependence on 1/η to a logarithmic dependence. We do not
know whether a linear dependence on d is possible with a logarithmic dependence on 1/η.
Omitted proofs of results below are provided in the extended version of this paper (Sabato et al. 
2013).

3

3 Auditing for Thresholds on the Line

The ﬁrst question to ask is whether the audit label complexity can ever be signiﬁcantly smaller than
the active or passive label complexities  and whether a different algorithm is required to achieve this
improvement. The following simple case answers both questions in the afﬁrmative. Consider the
hypothesis class of thresholds on the line  deﬁned over the domain X = [0  1]. A hypothesis with
threshold a is ha(x) = I[x − a ≥ 0]. The hypothesis class is H(cid:97) = {ha | a ∈ [0  1]}. Consider
the pool setting for the realizable case. The optimal active label complexity of Θ(log2 m) can be
achieved by a binary search on the pool. The auditing complexity of this algorithm can also be as
large as Θ(log2(m)). However  auditing allows us to beat this barrier. This case exempliﬁes an in-
teresting contrast between auditing and active learning. Due to information-theoretic considerations 
any algorithm which learns an unlabeled pool S has an active label complexity of at least log2 |H|S|
(Kulkarni et al.  1993)  where H|S is the set of restrictions of functions in H to the domain S. For
H(cid:97)  log2 |H(cid:97)|S| = Ω(log2 m). However  the same considerations are invalid for auditing.
We showed that for the realizable case  the auditing label complexity for H(cid:97) is a constant. We now
provide a more complex algorithm that guarantees this for (α  δ)-learning in the agnostic case. The
intuition behind our approach is that to get the optimal threshold in a pool with at most k errors  we
can query from highest to lowest until observing k + 1 negative points and then ﬁnd the minimal
error threshold on the labeled points.
Lemma 3.1. Let S be a pool of size m in [0  1]  and assume that err(S H(cid:97)) ≤ k/m. Then the
procedure above ﬁnds ˆh such that err(S  ˆh) = err(S H(cid:97)) with an auditing complexity of k + 1.
Proof. Denote the last queried point by x0  and let ha∗ = argminh∈H(cid:97) err(S H(cid:97)). Since
err(S  ha∗ ) ≤ k/m  a∗ > x0. Denote by S(cid:48) ⊆ S the set of points queried by the procedure.
For any a > x0  err(S(cid:48)  ha) = err(S  ha) + |{(x  y) ∈ S | x < x0  y = 1}|/m. Therefore 
minimizing the error on S(cid:48) results in a hypothesis that minimizes the error on S.
To learn from a distribution  one can draw a random sample and use it as the pool in the procedure
above. However  the sample size required for passive (α  δ)-learning of thresholds is Ω(ln(1/η)/η).
Thus  the number of errors in the pool would be k = η·Ω(ln(1/η)/η) = Ω(ln(1/η))  which depends
on η. To avoid this dependence  the auditing algorithm we propose uses Alg. 1 below to select a
subset of the random sample  which still represents the distribution well  but its size is only Ω(1/η).
Lemma 3.2. Let δ  ηmax ∈ (0  1). Let S be a pool such that err(S H(cid:97)) ≤ ηmax. Let Sq be the
output of Alg. 1 with inputs S  ηmax  δ  and let ˆh = argminh∈H(cid:97) err(Sq H(cid:97)). Then with probability
1 − δ 

err(Sq  ˆh) ≤ 6ηmax

and

err(S  ˆh) ≤ 17ηmax.

The algorithm for auditing thresholds on the line in the agnostic case is listed in Alg. 2. This
algorithm ﬁrst achieves (C  δ) learning of H(cid:97) for a ﬁxed C (in step 7  based on Lemma 3.2 and
Lemma 3.1  and then improves its accuracy to achieve (α  δ)-learning for α > 0  by additional
passive sampling in a restricted region. The following theorem provides the guarantees for Alg. 2.

Algorithm 1: Representative Subset Selection
1: Input: pool S = (x1  . . .   xm) (with hidden labels)  xi ∈ [0  1]  ηmax ∈ (0  1]  δ ∈ (0  1).
2: T ← max{(cid:98)1/3ηmax(cid:99)  1}.
} be the multiset with T copies of each point in S.
3: Let U = {x1  . . .   x1

  . . .   xm  . . .   xm

(cid:124)

(cid:123)(cid:122)

(cid:125)

(cid:124)

(cid:123)(cid:122)

(cid:125)

T copies

T copies

4: Sort and rename the points in U such that x(cid:48)
5: Let Sq be an empty multiset.
6: for t = 1 to T do
(t−1)m+1  . . .   x(cid:48)
7:
8:

tm}.

S(t) ← {x(cid:48)
Draw 14 ln(8/δ) random points from S(t) independently uniformly at random and add them
to Sq (with duplications).

i ≤ x(cid:48)

i+1 for all i ∈ [T m].

9: end for
10: Return Sq (with the corresponding hidden labels).

4

Algorithm 2: Auditing for Thresholds with a constant α
1: Input: ηmax  δ  α ∈ (0  1)  access to distribution D such that err(D H(cid:97)) ≤ ηmax.
2: ν ← α/5.
3: Draw a random labeled pool (with hidden labels) S0 of size mν(η  δ/2  1) from D.
4: Draw a random sample S of size mag((1 + ν)ηmax  δ/2  1) uniformly from S0.
5: Get a subset Sq using Alg. 1 with inputs S  2(1 + ν)ηmax  δ/2.
6: Query points in Sq from highest to lowest. Stop after (cid:100)12|Sq|(1 + ν)ηmax(cid:101) + 1 negatives.
7: Find ˆa such that hˆa minimizes the error on the labeled part of Sq.
8: Let S1 be the set of the 36(1 + ν)ηmax|S0| closest points to ˆa in S from each side of ˆa.
9: Draw S2 of size mag(ν/72  δ/2  1) from S1 (see deﬁnition on page 2).
10: Query all points in S2  and return ˆh that minimizes the error on S2.

Theorem 3.3. Let ηmax  δ  α ∈ (0  1). Let D be a distribution with error err(D H(cid:97)) ≤ ηmax.
Alg. 2 with input ηmax  δ  α has an auditing complexity of O(ln(1/δ)/α2)  and returns ˆh such that
with probability 1 − δ  err(D  ˆh) ≤ (1 + α)ηmax.
It immediately follows that if η = err(D H) is known  (α  δ)-learning is achievable with an auditing
complexity that does not depend on η. This is formulated in the following corollary.
Corollary 3.4 ((α  δ)-learning for H(cid:97)). Let η  α  δ ∈ (0  1]. For any distribution D with error
err(D H(cid:97)) = η  Alg. 2 with inputs ηmax = η  α  δ (α  δ)-learns D with respect to H(cid:97) with an
auditing complexity of O(ln(1/δ)/α2).

A similar result holds if the error is known up to a multiplicative constant. But what if no bound
on η is known? The following lower bound shows that in this case  the best active complexity for
threshold this similar to the best active label complexity.
Theorem 3.5 (Lower bound on auditing H(cid:97) without ηmax). Consider any constant α ≥ 0. For any
δ ∈ (0  1)  if an auditing algorithm (α  δ)-learns any distribution D such that err(D H(cid:97)) ≥ ηmin 
then the algorithm’s auditing complexity is Ω(ln( 1−δ

δ ) ln(1/ηmin)).

In the next section show that there are classes with a signiﬁcant gap between active and auditing
complexities even without an upper bound on the error.

4 Axis Aligned Rectangles

A natural extension of thresholds to higher dimension is the class of axis-aligned rectangles  in which
the labels are determined by a d-dimensional hyperrectangle. This hypothesis class  ﬁrst introduced
in Blumer et al. (1989)  has been studied extensively in different regimes (Kearns  1998; Long and
Tan  1998)  including active learning (Hanneke  2007b). An axis-aligned-rectangle hypothesis is a
disjunction of 2d thresholds. For simplicity of presentation  we consider here the slightly simpler
class of disjunctions of d thresholds over the positive orthant Rd
+. It is easy to reduce learning of an
axis-aligned rectangle in Rd to learning of a disjunction of thresholds in R2d by mapping each point
x ∈ Rd to a point ˜x ∈ R2d such that for i ∈ [d]  ˜x[i] = max(x[i]  0) and ˜x[i + d] = max(0 −x[i])).
Thus learning the class of disjunctions is equivalent  up to a factor of two in the dimensionality  to
learning rectangles1. Because auditing costs are asymmetric  we consider two possibilities for label
assignment. For a vector a = (a[1]  . . .   a[d]) ∈ Rd

+  deﬁne the hypotheses ha and h−

a by

ha(x) = 2I[∃i ∈ [d]  x[i] ≥ a[i]] − 1 

a (x) = −ha(x).
h−

and
Deﬁne H2 = {ha | a ∈ Rd
+}. In H2 the positive points are outside
the rectangle and in H−
2 the negatives are outside. Both classes have VC dimension d. All of our
results for these classes can be easily extended to the corresponding classes of general axis-aligned
rectangles on Rd  with at most a factor of two penalty on the auditing complexity.

a | a ∈ Rd

+} and H−

2 = {h−

1This reduction sufﬁces if the origin is known to be in the rectangle. Our algorithms and results can all be
extended to the case where rectangles are not required to include the origin. To keep the algorithm and analysis
as simple as possible  we state the result for this special case.

5

4.1 The Realizable Case

We ﬁrst consider the pool setting for the realizable case  and show a sharp contrast between the
auditing complexity and the active label complexity for H2 and H−
2 . Assume a pool of size m.
While the active learning complexity for H2 and H−
2 can be as large as m  the auditing complexities
for the two classes are quite different. For H−
2   the auditing complexity can be as large as m  but for
H2 it is at most d. We start by showing the upper bound for auditing of H2.
Theorem 4.1 (Pool auditing upper bound for H2). The auditing complexity of any unlabeled pool
Su of size m with respect to H2 is at most d.
Proof. The method is a generalization of the approach to auditing for thresholds. Let h∗ ∈ H2 such
that err(S  h∗) = 0. For each i ∈ [d]  order the points x in S by the values of their i-th coordinates
x[i]. Query the points sequentially from largest value to the smallest (breaking ties arbitrarily) and
stop when the ﬁrst negative label is returned  for some point xi. Set a[i] ← xi[i]  and note that h∗
labels all points in {x | x[i] > a[i]} positive. Return the hypothesis ˆh = ha. This procedure clearly
queries at most d negative points and agrees with the labeling of h∗.
It is easy to see that a similar approach yields an auditing complexity of 2d for full axis-aligned
rectangles. We now provide a lower bound for the auditing complexity of H−
2 that immediately
implies the same lower bound for active label complexity of H−
2 ). For any m and any d ≥ 2  there is a pool
Theorem 4.2 (Pool auditing lower bound for H−
Su ⊆ Rd
Proof. The construction is a simple adaptation of a construction due to Dasgupta (2005)  originally
showing an active learning lower bound for the class of hyperplanes. Let the pool be composed of m
distinct points on the intersection of the unit circle and the positive orthant: Su = {(cos θj  sin θj)}
for distinct θj ∈ [0  π/2]. Any labeling which labels all the points in Su negative except any one
point is realizable for H−
2   and so is the all-negative labeling. Thus  any algorithm that distinguishes
between these different labelings with probability 1 must query all the negative labels.
2 ). For H2 and H−
Corollary 4.3 (Realizable active label complexity of H2 and H−
of size m such that its active label complexity is m.

2 and H2.
+ of size m such that its auditing complexity with respect to H−

2   there is a pool

2 is m.

4.2 The Agnostic Case
We now consider H2 in the agnostic case  where η > 0. The best known algorithm for ac-
tive learning of rectangles (2  δ)-learns a very restricted class of distributions (continuous product
distributions which are sufﬁciently balanced in all directions) with an active label complexity of
˜O(d3p(ln(1/η)p(ln(1/δ)))  where p(·) is a polynomial (Hanneke  2007b). However  for a general
distribution  active label complexity cannot be signiﬁcantly better than passive label complexity.
This is formalized in the following theorem.
Theorem 4.4 (Agnostic active label complexity of H2). Let α  η > 0  δ ∈ (0  1
2 ). Any learning
algorithm that (α  δ)-learns all distributions such that err(D H) = η for η > 0 with respect to H2
has an active label complexity of Ω(d/η).
In contrast  the auditing complexity of H2 can be much smaller  as we show for Alg. 3 below.
Theorem 4.5 (Auditing complexity of H2). For ηmin  α  δ ∈ (0  1)  there is an algorithm that
(α  δ)-learns all distributions with η ≥ ηmin with respect to H2 with an auditing complexity of
O( d2 ln(1/αδ)

ln2(1/ηmin)).

α2

If ηmin is polynomially close to the true η  we get an auditing complexity of O(d2 ln2(1/η))  com-
pared to the active label complexity of Ω(d/η)  an exponential improvement in η. It is an open
question whether the quadratic dependence on d is necessary here.
Alg. 3 implements a ‘low-conﬁdence’ version of the realizable algorithm. It sequentially queries
points in each direction  until enough negative points have been observed to make sure the thresh-
old in this direction has been overstepped. To bound the number of negative labels  the algorithm
iteratively reﬁnes lower bounds on the locations of the best thresholds  and an upper bound on the
negative error  deﬁned as the probability that a point from D with negative label is classiﬁed as

6

positive by a minimal-error classiﬁer. The algorithm uses queries that mostly result in positive la-
bels  and stops when the upper bound on the negative error cannot be reﬁned. The idea of iteratively
reﬁning a set of possible hypotheses has been used in a long line of active learning works (Cohn
et al.  1994; Balcan et al.  2006; Hanneke  2007a; Dasgupta et al.  2008). Here we reﬁne in a par-
ticular way that uses the structure of H2  and allows bounding the number of negative examples we
observe.
We use the following notation in Alg. 3. The negative error of a hypothesis is errneg(D  h) =
P(X Y )∼D[h(X) = 1 and Y = −1]. It is easy to see that the same convergence guarantees that
hold for err(· ·) using a sample size mν(  δ  d) hold also for the negative error errneg(· ·) (see
Sabato et al.  2013). For a labeled set of points S  an  ≤ (0  1) and a hypothesis class H  denote
Vν(S   H) = {h ∈ H | err(S  h) ≤ err(S H) + (2ν + ν2) · max(err(S H)  )}. For a vector
b ∈ Rd

+  deﬁne H2[b] = {ha ∈ H2 | a ≥ b}.

j ← 0
while j ≤ (cid:100)(1 + ν)ηt|St|(cid:101) + 1 do
If unqueried points exist  query the unqueried point with highest i’th coordinate;
If query returned −1  j ← j + 1.

end while
bt[i] ← the i’th coordinate of the last queried point  or 0 if all points were queried.

+ × {−1  +1}.

Algorithm 3: Auditing for H2
1: Input: ηmin > 0  α ∈ (0  1]  access to distribution D over Rd
2: ν ← α/25.
3: for t = 0 to (cid:98)log2(1/ηmin)(cid:99) do
ηt ← 2−t.
4:
Draw a sample St of size mν(ηt  δ/ log2(1/ηmin)  10d) with hidden labels.
5:
for i = 1 to d do
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
end if
19:
20: end for
21: Return ˆh ≡ argminh∈H2[bt] err(Sbt  h).

end for
Set Sbt to St  with unqueried labels set to −1.
Vt ← Vν(Sbt  ηt H2[bt]).
ˆηt ← maxh∈Vt errneg(Sbt  h).
if ˆηt > ηt/4 then
Skip to step 21

Theorem 4.5 is proven in Sabato et al. (2013).
. The proof idea is to show that at each round t 
Vt includes any h∗ ∈ argminh∈H err(D  h)  and ˆηt is an upper bound on errneg(D  h∗). Further 
at any given point minimizing the error on Sbt is equivalent to minimizing the error on the entire
(unlabeled) sample. We conclude that the algorithm obtains a good approximation of the total error.
Its auditing complexity is bounded since it queries a bounded number of negative points at each
round.

5 Outcome-dependent Costs for a General Hypothesis Class
In this section we return to the realizable pool setting and consider ﬁnite hypothesis classes H. We
address general outcome-dependent costs and a general space of labels Y  so that H ⊆ YX . Let
S ⊆ X be an unlabeled pool  and let cost : S × H → R+ denote the cost of a query: For x ∈ S
and h ∈ H  cost(x  h) is the cost of querying the label of x given that h is the true (unknown)
hypothesis. In the auditing setting  Y = {−1  +1} and cost(x  h) = I[h(x) = −1]. For active
learning  cost ≡ 1. Note that under this deﬁnition of cost function  the algorithm may not know the
cost of the query until it reveals the true hypothesis.
Deﬁne OPTcost(S) to be the minimal cost of an algorithm that for any labeling of S which is
consistent with some h ∈ H produces a hypothesis ˆh such that err(S  ˆh) = 0. In the active learning
setting  where cost ≡ 1  it is NP-hard to obtain OPTcost(S) for general H and S. This can be

7

shown by a reduction to set-cover (Hyaﬁl and Rivest  1976). A simple adaptation of the reduction
for the auditing complexity  which we defer to the full version of this work  shows that it is also
NP-hard to obtain OPTcost(S) in the auditing setting.
For active learning  and for query costs that do not depend on the true hypothesis (that is cost(x  h) ≡
cost(x))  Golovin and Krause (2011) showed an efﬁcient greedy strategy that achieves a cost of
O(OPTcost(S) · ln(|H|)) for any S. This approach has also been shown to provide considerable
performance gains in practical settings (Gonen et al.  2013). The greedy strategy consists of itera-
tively selecting a point whose label splits the set of possible hypotheses as evenly as possible  with
a normalization proportional on the cost of each query.
We now show that for outcome-dependent costs  another greedy strategy provides similar approx-
imation guarantees for OPTcost(S). The algorithm is deﬁned as follows: Suppose that so far the
algorithm requested labels for x1  . . .   xt and received the corresponding labels y1  . . .   yt. Letting
St = {(x1  y1)  . . .   (xt  yt)}  denote the current version space by V (St) = {h ∈ H|S | ∀(x  y) ∈
St  h(x) = y}. The next query selected by the algorithm is

x ∈ argmax

x∈S

min
h∈H

|V (St) \ V (St ∪ {(x  h(x))})|

cost(x  h)

.

That is  the algorithm selects the query that in the worst-case over the possible hypotheses  would
remove the most hypotheses from the version spaces  when normalizing by the outcome-dependent
cost of the query. The algorithm terminates when |V (St)| = 1  and returns the single hypothesis in
the version space.
Theorem 5.1. For any cost function cost  hypothesis class H  pool S  and true hypothesis h ∈ H 
the cost of the proposed algorithm is at most (ln(|H|S| − 1) + 1) · OPT.

If cost is the auditing cost  the proposed algorithm corresponds to the following intuitive strategy: At
every round  select a query such that  if its result is a negative label  then the number of hypotheses
removed from the version space is the largest. This strategy is consistent with a simple principle
based on a partial ordering of the points: For points x  x(cid:48) in the pool  deﬁne x(cid:48) (cid:22) x if {h ∈ H |
h(x(cid:48)) = −1} ⊇ {h ∈ H | h(x) = −1}  so that if x(cid:48) has a negative label  so does x. In the auditing
setting  it is always preferable to query x before querying x(cid:48). Therefore  for any realizable auditing
problem  there exists an optimal algorithm that adheres to this principle. It is thus encouraging that
our greedy algorithm is also consistent with it.
An O(ln(|H|S|)) approximation factor for auditing is less appealing than the same factor for active
learning. By information-theoretic arguments  active label complexity is at least log2(|H|S|) (and
hence the approximation at most squares the cost)  but this does not hold for auditing. Nonetheless 
hardness of approximation results for set cover (Feige  1998)  in conjunction with the reduction to
set cover of Hyaﬁl and Rivest (1976) mentioned above  imply that such an approximation factor
cannot be avoided for a general auditing algorithm.

6 Conclusion and Future Directions

As summarized in Section 2  we show that in the auditing setting  suitable algorithms can achieve
improved costs in the settings of thresholds on the line and axis parallel rectangles. There are many
open questions suggested by our work. First  it is known that for some hypothesis classes  active
learning cannot improve over passive learning for certain distributions (Dasgupta  2005)  and the
same is true for auditing. However  exponential speedups are possible for active learning on certain
classes of distributions (Balcan et al.  2006; Dasgupta et al.  2008)  in particular ones with a small
disagreement coefﬁcient (Hanneke  2007a). It is an open question whether a similar property of
the distribution can guarantee an improvement with auditing over active or passive learning. This
might be especially relevant to important hypothesis classes such as decision trees or halfspaces. An
interesting generalization of the auditing problem is a multiclass setting with a different cost for each
label. Finally  one may attempt to optimize other performance measures for auditing  as described
in the introduction. These measures are different from those studied in active learning  and may lead
to new algorithmic insights.

8

References
M. F. Balcan  A. Beygelzimer  and J. Langford. Agnostic active learning. In Proceedings of the

23rd international conference on Machine learning (ICML)  pages 65–72  2006.

P. L. Bartlett and S. Mendelson. Rademacher and Gaussian complexities: Risk bounds and structural

results. Journal of Machine Learning Research  3:463–482  2002.

A. Beygelzimer  S. Dasgupta  and J. Langford. Importance weighted active learning. In Proceedings
of the 26th Annual International Conference on Machine Learning (ICML)  pages 49–56. ACM 
2009.

J. Blocki  N. Christin  A. Dutta  and A. Sinha. Regret minimizing audits: A learning-theoretic basis
for privacy protection. In Proceedings of 24th IEEE Computer Security Foundations Symposium 
2011.

A. Blumer  A. Ehrenfeucht  D. Haussler  and M. K. Warmuth. Learnability and the Vapnik-

Chervonenkis dimension. Journal of the ACM  36(4):929–965  Oct. 1989.

D. Cohn  L. Atlas  and R. Ladner. Improving generalization with active learning. Machine Learning 

15:201–221  1994.

S. Dasgupta. Analysis of a greedy active learning strategy. In L. K. Saul  Y. Weiss  and L. Bot-
tou  editors  Advances in Neural Information Processing Systems 17  pages 337–344. MIT Press 
Cambridge  MA  2005.

S. Dasgupta  D. Hsu  and C. Monteleoni. A general agnostic active learning algorithm. In J. Platt 
D. Koller  Y. Singer  and S. Roweis  editors  Advances in Neural Information Processing Systems
20  pages 353–360. MIT Press  Cambridge  MA  2008.

L. Devroye and G. Lugosi. Lower bounds in pattern recognition and learning. Pattern Recognition 

28(7):1011–1018  1995.

U. Feige. A threshold of ln n for approximating set cover. Journal of the ACM (JACM)  45(4):

634–652  1998.

D. Golovin and A. Krause. Adaptive submodularity: Theory and applications in active learning and

stochastic optimization. Journal of Artiﬁcial Intelligence Research  42:427–486  2011.

A. Gonen  S. Sabato  and S. Shalev-Shwartz. Efﬁcient active learning of halfspaces: an aggressive

approach. In The 30th International Conference on Machine Learning (ICML)  2013.

S. Hanneke. A bound on the label complexity of agnostic active learning. In Proceedings of the 24th

international conference on Machine learning  pages 353–360. ACM  2007a.

S. Hanneke. Teaching dimension and the complexity of active learning. In Learning Theory  pages

66–81. Springer  2007b.

S. Hanneke. Rates of convergence in active learning. The Annals of Statistics  39(1):333–361  2011.
L. Hyaﬁl and R. L. Rivest. Constructing optimal binary decision trees is NP-complete. Information

Processing Letters  5(1):15–17  May 1976.

A. Kapoor  E. Horvitz  and S. Basu. Selective supervision: Guiding supervised learning with

decision-theoretic active learning. In Proceedings of IJCAI  2007.

M. Kearns. Efﬁcient noise-tolerant learning from statistical queries. Journal of the ACM (JACM) 

45(6):983–1006  1998.

S. R. Kulkarni  S. K. Mitter  and J. N. Tsitsiklis. Active learning using arbitrary binary valued

queries. Machine Learning  11(1):23–35  1993.

P. M. Long and L. Tan. PAC learning axis-aligned rectangles with respect to product distributions

from multiple-instance examples. Machine Learning  30(1):7–21  1998.

D. D. Margineantu. Active cost-sensitive learning. In Proceedings of IJCAI  2007.
S. Sabato  A. D. Sarwate  and N. Srebro. Auditing: Active learning with outcome-dependent query

costs. arXiv preprint arXiv:1306.2347  2013.

B. Settles  M. Craven  and L. Friedlan. Active learning with real annotation costs. In Proceedings

of the NIPS Workshop on Cost-Sensitive Learning  2008.

V. N. Vapnik and A. Y. Chervonenkis. On the uniform convergence of relative frequencies of events

to their probabilities. Theory of Probability and Its Applications  XVI(2):264–280  1971.

9

,Sivan Sabato
Anand Sarwate
Nati Srebro
Hemant Tyagi
Bernd Gärtner
Andreas Krause
Xiangyu Wang
Fangjian Guo
Katherine Heller
David Dunson
Daniel Ritchie
Anna Thomas
Pat Hanrahan
Noah Goodman