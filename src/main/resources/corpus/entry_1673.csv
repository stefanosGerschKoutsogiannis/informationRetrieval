2013,EDML for Learning Parameters in Directed and Undirected Graphical Models,EDML is a recently proposed algorithm for learning parameters in Bayesian networks.  It was originally derived in terms of approximate inference on a meta-network  which underlies the Bayesian approach to parameter estimation.  While this initial derivation helped discover EDML in the first place and provided a concrete context for identifying some of its properties (e.g.  in contrast to EM)  the formal setting was somewhat tedious in the number of concepts it drew on.  In this paper  we propose a greatly simplified perspective on EDML  which casts it as a general approach to continuous optimization. The new perspective has several advantages. First  it makes immediate some results that were non-trivial to prove initially. Second  it facilitates the design of EDML algorithms for new graphical models  leading to a new algorithm for learning parameters in Markov networks.  We derive this algorithm in this paper  and show  empirically  that it can sometimes learn better estimates from complete data  several times faster than commonly used optimization methods  such as conjugate gradient and L-BFGS.,EDML for Learning Parameters in

Directed and Undirected Graphical Models

Khaled S. Refaat  Arthur Choi  Adnan Darwiche

Computer Science Department

University of California  Los Angeles

{krefaat aychoi darwiche}@cs.ucla.edu

Abstract

EDML is a recently proposed algorithm for learning parameters in Bayesian net-
works. It was originally derived in terms of approximate inference on a meta-
network  which underlies the Bayesian approach to parameter estimation. While
this initial derivation helped discover EDML in the ﬁrst place and provided a con-
crete context for identifying some of its properties (e.g.  in contrast to EM)  the
formal setting was somewhat tedious in the number of concepts it drew on. In this
paper  we propose a greatly simpliﬁed perspective on EDML  which casts it as
a general approach to continuous optimization. The new perspective has several
advantages. First  it makes immediate some results that were non-trivial to prove
initially. Second  it facilitates the design of EDML algorithms for new graphical
models  leading to a new algorithm for learning parameters in Markov networks.
We derive this algorithm in this paper  and show  empirically  that it can sometimes
learn estimates more efﬁciently from complete data  compared to commonly used
optimization methods  such as conjugate gradient and L-BFGS.

1

Introduction

EDML is a recently proposed algorithm for learning MAP parameters of a Bayesian network from
incomplete data [5  16]. While it is procedurally very similar to Expectation Maximization (EM) [7 
11]  EDML was shown to have certain advantages  both theoretically and practically. Theoretically 
EDML can in certain specialized cases provably converge in one iteration  whereas EM may require
many iterations to solve the same learning problem. Some empirical evaluations further suggested
that EDML and hybrid EDML/EM algorithms can sometimes ﬁnd better parameter estimates than
vanilla EM  in fewer iterations and less time. EDML was originally derived in terms of approximate
inference on a meta-network used for Bayesian approaches to parameter estimation. This graphical
representation of the estimation problem lent itself to the initial derivation of EDML  as well to the
identiﬁcation of certain key theoretical properties  such as the one we just described. The formal
details  however  can be somewhat tedious as EDML draws on a number of different concepts. We
review EDML in such terms in the supplementary appendix.
In this paper  we propose a new perspective on EDML  which views it more abstractly in terms of
a simple method for continuous optimization. This new perspective has a number of advantages.
First  it makes immediate some results that were previously obtained for EDML  but through some
effort. Second  it facilitates the design of new EDML algorithms for new classes of models  where
graphical formulations of parameter estimation  such as meta-networks  are lacking. Here  we de-
rive  in particular  a new parameter estimation algorithm for Markov networks  which is in many
ways a more challenging task  compared to the case of Bayesian networks. Empirically  we ﬁnd that
EDML is capable of learning parameter estimates  under complete data  more efﬁciently than popu-
lar methods such as conjugate-gradient and L-BFGS  and in some cases  by an order-of-magnitude.

1

This paper is structured as follows. In Section 2  we highlight a simple iterative method for  approxi-
mately  solving continuous optimization problems. In Section 3  we formulate the EDML algorithm
for parameter estimation in Bayesian networks  as an instance of this optimization method. In Sec-
tion 4  we derive a new EDML algorithm for Markov networks  based on the same perspective. In
Section 5  we contrast the two EDML algorithms for directed and undirected graphical models  in
the complete data case. We empirically evaluate our new algorithm for parameter estimation under
complete data in Markov networks  in Section 6; review related work in Section 7; and conclude in
Section 8. Proofs of theorems appear in the supplementary appendix.

2 An Approximate Optimization of Real-Valued Functions

Consider a real-valued objective function f (x) whose input x is a vector of components:

x = (x1  . . .   xi  . . .   xn) 

where each component xi is a vector in Rki for some ki. Suppose further that we have a constraint
on the domain of function f (x) with a corresponding function g that maps an arbitrary point x to a
point g(x) satisfying the given constraint. We say in this case that g(x) is a feasibility function and
refer to the points in its range as feasible points.
Our goal here is to ﬁnd a feasible input vector x = (x1  . . .   xi  . . .   xn) that optimizes the func-
tion f (x). Given the difﬁculty of this optimization problem in general  we will settle for ﬁnding
stationary points x in the constrained domain of function f (x).
One approach for ﬁnding such stationary points is as follows. Let x(cid:63) = (x(cid:63)
feasible point in the domain of function f (x). For each component xi  we deﬁne a sub-function

i   . . .   x(cid:63)

1  . . .   x(cid:63)

n) be a

fx(cid:63) (xi) = f (x(cid:63)

1  . . .   x(cid:63)

i−1  xi  x(cid:63)

i+1  . . .   x(cid:63)

n).

That is  we use the n-ary function f (x) to generate n sub-functions fx(cid:63) (xi). Each of these sub-
functions is obtained by ﬁxing all inputs xj of f (x)  for j (cid:54)= i  to their values in x(cid:63)  while keeping
the input xi free. We further assume that these sub-functions are subject to the same constraints that
the function f (x) is subject to.
We can now characterize all feasible points x(cid:63) that are stationary with respect to the function f (x) 
in terms of local conditions on sub-functions fx(cid:63) (xi).

Claim 1 A feasible point x(cid:63) = (x(cid:63)
component x(cid:63)

i   . . .   x(cid:63)
i is stationary for sub-function fx(cid:63) (xi).

1  . . .   x(cid:63)

n) is stationary for function f (x) iff for all i 

This is immediate from the deﬁnition of a stationary point. Assuming no constraints  at a stationary
point x(cid:63)  the gradient ∇f (x(cid:63)) = 0  i.e.  ∇xif (x(cid:63)) = ∇fx(cid:63) (x(cid:63)
i ) = 0 for all xi  where ∇xif (x(cid:63))
denotes the sub-vector of gradient ∇f (x(cid:63)) with respect to component xi.1
With these observations  we can now search for feasible stationary points x(cid:63) of the constrained
function f (x) using an iterative method that searches instead for stationary points of the constrained
sub-functions fx(cid:63) (xi). The method works as follows:

1. Start with some feasible point xt of function f (x) for t = 0
2. While some xt

i is not a stationary point for constrained sub-function fxt (xi)
for each constrained sub-function fxt (xi)

(a) Find a stationary point yt+1
(b) xt+1 = g(yt+1)
(c) Increment t

i

The real computational work of this iterative procedure is in Steps 2(a) and 2(b)  although we shall
see later that such steps can  in some cases  be performed efﬁciently. With an appropriate feasibility
function g(y)  one can guarantee that a ﬁxed-point of this procedure yields a stationary point of the
constrained function f (x)  by Claim 1.2 Further  any stationary point is trivially a ﬁxed-point of this
procedure (one can seed this procedure with such a point).

1Under constraints  we consider points that are stationary with respect to the corresponding Lagrangian.
2We discuss this point further in the supplementary appendix.

2

As we shall show in the next section  the EDML algorithm—which has been proposed for parameter
estimation in Bayesian networks—is an instance of the above procedure with some notable obser-
vations: (1) the sub-functions fxt(xi) are convex and have unique optima; (2) these sub-functions
have an interesting semantics  as they correspond to posterior distributions that are induced by Naive
Bayes networks with soft evidence asserted on them; (3) deﬁning these sub-functions requires infer-
ence in a Bayesian network parameterized by the current feasible point xt; (4) there are already sev-
eral convergent  ﬁxed-point iterative methods for ﬁnding the unique optimum of these sub-functions;
and (5) these convergent methods produce solutions that are always feasible and  hence  the feasi-
bility function g(y) corresponds to the identity function g(y) = y in this case.
We next show this connection to EDML as proposed for parameter estimation in Bayesian networks.
We follow by deriving an EDML algorithm (another instance of the above procedure)  but for param-
eter estimation in undirected graphical models. We will also study the impact of having complete
data on both versions of the EDML algorithm  and ﬁnally evaluate the new instance of EDML by
comparing it to conjugate gradient and L-BFGS when applied to complete datasets.

3 EDML for Bayesian Networks

From here on  we use upper case letters (X) to denote variables and lower case letters (x) to denote
their values. Variable sets are denoted by bold-face upper case letters (X) and their instantiations
by bold-face lower case letters (x). Generally  we will use X to denote a variable in a Bayesian
network and U to denote its parents. A network parameter will therefore have the general form
θx|u  representing the probability Pr (X = x|U = u).
Consider a (possibly incomplete) dataset D with examples d1  . . .   dN   and a Bayesian network with
parameters θ. Our goal is to ﬁnd parameter estimates θ that minimize the negative log-likelihood:

f (θ) = −(cid:96)(cid:96)(θ|D) = − N(cid:88)

log Pr θ(di).

(1)

i=1

Here  θ = (. . .   θX|u  . . .) is a vector over the network parameters. Moreover  Pr θ is the distribution
induced by the Bayesian network structure under parameters θ. As such  Pr θ(di) is the probability
of observing example di in dataset D under parameters θ.
Each component of θ is a parameter set θX|u  which deﬁnes a parameter θx|u for each value x of
variable X and instantiation u of its parents U. The feasibility constraint here is that each component

θX|u satisﬁes the convex sum-to-one constraint:(cid:80)

x θx|u = 1.

The above parameter estimation problem is clearly in the form of the constrained optimization prob-
lem that we phrased in the previous section and  hence  admits the same iterative procedure proposed
in that section for ﬁnding stationary points. The relevant questions now are: What form do the sub-
functions fθ(cid:63) (θX|u) take in this context? What are their semantics? What properties do they have?
How do we ﬁnd their stationary points? What is the feasibility function g(y) in this case? Finally 
what is the connection to previous work on EDML? We address these questions next.

3.1 Form

We start by characterizing the sub-functions of the negative log-likelihood given in Equation 1.
Theorem 1 For each parameter set θX|u  the negative log-likelihood of Equation 1 has the sub-
function:

fθ(cid:63) (θX|u) = − N(cid:88)

i=1

(cid:16)

(cid:88)

x

(cid:17)

log

C i

u +

x|u · θx|u
C i

(2)

where C i

u and C i

x|u are constants that are independent of parameter set θX|u  given by
x|u

u = Pr θ(cid:63) (di) − Pr θ(cid:63) (u  di)
C i

and

C i

x|u = Pr θ(cid:63) (x  u  di)/θ(cid:63)

To compute the constants C i  we require inference on a Bayesian network with parameters θ(cid:63).3

3Theorem 1 assumes tacitly that θ(cid:63)

x|u (cid:54)= 0. More generally  however  C i

x|u = ∂Pr θ(cid:63) (di)/∂θx|u  which

can also be computed using some standard inference algorithms [6  14].

3

Figure 1: Estimation given independent soft observations.

3.2 Semantics

Equation 2 has an interesting semantics  as it corresponds to the negative log-likelihood of a root
variable in a naive Bayes structure  on which soft  not necessarily hard  evidence is asserted [5].4
This model is illustrated in Figure 1  where our goal is to estimate a parameter set θX  given soft
observations η = (η1  . . .   ηN ) on variables X1  . . .   XN   where each ηi has a strength speciﬁed by
a weight on each value xi of Xi. If we denote the distribution of this model by P  then (1) P(θ)
denotes a prior over parameters sets 5 (2) P(xi|θX = (. . .   θx  . . .)) = θx  and (3) weights P(ηi|xi)
denote the strengths of soft evidence ηi on value xi. The log likelihood of our soft observations η
is:

log P(η|θX ) =

log

P(ηi|xi)P(xi|θX ) =

log

P(ηi|xi) · θx

(3)

N(cid:88)

i=1

(cid:88)

xi

N(cid:88)

i=1

(cid:88)

xi

The following result connects Equation 2 to the above likelihood of a soft dataset  when we now
want to estimate the parameter set θX|u  for a particular variable X and parent instantiation u.
Theorem 2 Consider Equations 2 and 3  and assume that each soft evidence ηi has the strength
P(ηi|xi) = C i

x|u. It then follows that

u + C i

fθ(cid:63) (θX|u) = − log P(η|θX|u)

(4)

This theorem yields the following interesting semantics for EDML sub-functions. Consider a pa-
rameter set θX|u and example di in our dataset. The example can then be viewed as providing
“votes” on what this parameter set should be. In particular  the vote of example di for value x takes
the form of a soft evidence ηi whose strength is given by

P(ηi|xi) = Pr θ(cid:63) (di) − Pr θ(cid:63) (u  di) + Pr θ(cid:63) (x  u  di)/θ(cid:63)
x|u

The sub-function is then aggregating these votes from different examples and producing a corre-
sponding objective function on parameter set θX|u. EDML optimizes this objective function to
produce the next estimate for each parameter set θX|u.

3.3 Properties

Equation 2 is a convex function  and thus has a unique optimum.6 In particular  we have logs of a
linear function  which are each concave. The sum of two concave functions is also concave  thus our
sub-function fθ(cid:63) (θX|u) is convex  and is subject to a convex sum-to-one constraint [16]. Convex
functions are relatively well understood  and there are a variety of methods and systems that can be
used to optimize Equation 2; see  e.g.  [3]. We describe one such approach  next.

3.4 Finding the Unique Optima

In every EDML iteration  and for each parameter set θX|u  we seek the unique optimum for each
sub-function fθ(cid:63) (θX|u)  given by Equation 2. Refaat  et al.  has previously proposed a ﬁxed-point
4Soft evidence is an observation that increases or decreases ones belief in an event  but not necessarily to

the point of certainty. For more on soft evidence  see [4].

5Typically  we assume Dirichlet priors for MAP estimation. However  we focus on ML estimation here.
6More speciﬁcally  strict convexity implies a unique optimum  although under certain assumptions  we can

guarantee that Equation 2 is indeed strictly convex.

4

…	  …	  η1 η2 ηN !XX1X2XNalgorithm that monotonically improves the objective  and is guaranteed to converge [16]. Moreover 
the solutions it produces already satisfy the convex sum-to-one constraint and  hence  the feasibility
function g ends up being the identity function g(θ) = θ.
In particular  we start with some initial feasible estimates θt
following update equation until convergence:

N(cid:88)

i=1

C i

X|u at iteration t = 0  and then apply the
x|u) · θt
x|u
x(cid:48)|u · θt
x(cid:48) C i

x(cid:48)|u

(5)

(C i

u +(cid:80)

u + C i

θt+1
x|u =

1
N

Note here that constants C i are computed by inference on a Bayesian network structure under param-
eters θt (see Theorem 1 for the deﬁnitions of these constants). Moreover  while the above procedure
is convergent when optimizing sub-functions fθ(cid:63) (θX|u)  the global EDML algorithm that is opti-
mizing function f (θ) may not be convergent in general.

3.5 Connection to Previous Work

EDML was originally derived by applying an approximate inference algorithm to a meta-network 
which is typically used in Bayesian approaches to parameter estimation [5  16]. This previous
formulation of EDML  which is speciﬁc to Bayesian networks  now falls as a special instance of
the one given in Section 2. In particular  the “sub-problems” deﬁned by the original EDML [5  16]
correspond precisely to the sub-functions fθ(cid:63) (θX|u) described here. Further  both versions of EDML
are procedurally identical when they both use the same method for optimizing these sub-functions.
The new formulation of EDML is more transparent  however  at least in revealing certain properties
of the algorithm. For example  it now follows immediately (from Section 2) that the ﬁxed points
of EDML are stationary points of the log-likelihood—a fact that was not proven until [16]  using a
technique that appealed to the relationship between EDML and EM. Moreover  the proof that EDML
under complete data will converge immediately to the optimal estimates is also now immediate (see
Section 5). More importantly though  this new formulation provides a systematic procedure for
deriving new instances of EDML for additional models  beyond Bayesian networks. Indeed  in the
next section  we use this procedure to derive an EDML instance for Markov networks  which is
followed by an empirical evaluation of the new algorithm under complete data.

4 EDML for Undirected Models

In this section  we show how parameter estimation for undirected graphical models  such as Markov
networks  can also be posed as an optimization problem  as described in Section 2.
For Markov networks  θ = (. . .   θXa   . . .) is a vector over the network parameters. Component θXa
is a parameter set for a (tabular) factor a  assigning a number θxa ≥ 0 for each instantiation xa of
variables Xa. The negative log-likelihood −(cid:96)(cid:96)(θ|D) for a Markov network is:

−(cid:96)(cid:96)(θ|D) = N log Zθ − N(cid:88)

i=1

log Zθ(di)

(6)

f (θ) = − N(cid:88)

where Zθ is the partition function  and where Zθ(di) is the partition function after conditioning on
example di  under parameterization θ. Sub-functions with respect to Equation 6 may not be convex 
as was the case in Bayesian networks. Consider instead the following objective function  which we
shall subsequently relate to the negative log-likelihood:

log Zθ(di) 

(7)

i=1

with a feasibility constraint that the partition function Zθ equals some constant α. The following re-
sult tells us that it sufﬁces to optimize Equation 7 under the given constraint  to optimize Equation 6.
Theorem 3 Let α be a positive constant  and let g(θ) be a (feasibility) function satisfying Zg(θ) = α
and g(θxa ) ∝ θxa for all θxa.7 For every point θ  if g(θ) is optimal for Equation 7  subject to its
7Here  g(θxa ) denotes the component of g(θ) corresponding to θxa. Moreover  the function g(θ) can be
constructed  e.g.  by simply multiplying all entries of one parameter set by α/Zθ. In our experiments  we

5

constraint  then it is also optimal for Equation 6. Moreover  a point θ is stationary for Equation 6
iff the point g(θ) is stationary for Equation 7  subject to its constraint.

With Equation 7 as a new (constrained) objective function for estimating the parameters of a Markov
network  we can now cast it in the terms of Section 2. We start by characterizing its sub-functions.

Theorem 4 For a given parameter set θXa  the objective function of Equation 7 has sub-functions:

fθ(cid:63) (θXa ) = − N(cid:88)

(cid:88)

subject to (cid:88)

log

· θxa

C i
xa

Cxa · θxa = α

(8)

i=1

xa

xa

where C i
xa

and Cxa are constants that are independent of the parameter set θXa:
.

Cxa = Zθ(cid:63) (xa)/θ(cid:63)
xa

= Zθ(cid:63) (xa  di)/θ(cid:63)
xa

C i
xa

and

Note that computing these constants requires inference on a Markov network with parameters θ(cid:63).8
Interestingly  this sub-function is convex  as well as the constraint (which is now linear)  resulting in
a unique optimum  as in Bayesian networks. However  even when θ(cid:63) is a feasible point  the unique
optima of these sub-functions may not be feasible when combined. Thus  the feasibility function
g(θ) of Theorem 3 must be utilized in this case.
We now have another instance of the iterative algorithm proposed in Section 2  but for undirected
graphical models. That is  we have just derived an EDML algorithm for such models.

5 EDML under Complete Data

xa

of Theorem 4 reduces to: fθ(cid:63) (θXa ) = −(cid:80)

of Theorem 1 then reduces to: fθ(cid:63) (θX|u) = −(cid:80)

We consider now how EDML simpliﬁes under complete data for both Bayesian and Markov net-
works  identifying forms and properties of the corresponding sub-functions under complete data.
We start with Bayesian networks. Consider a variable X  and a parent instantiation u; and let
D#(xu) represent the number of examples that contain xu in the complete dataset D. Equation 2
x D#(xu) log θx|u + C  where C is a constant that
is independent of parameter set θX|u. Assuming that θ(cid:63) is feasible (i.e.  each θX|u satisﬁes the sum-
D#(xu)
D#(u)   which is guaranteed
to-one constraint)  the unique optimum of this sub-function is θx|u =
to yield a feasible point θ  globally. Hence  EDML produces the unique optimal estimates in its ﬁrst
iteration and terminates immediately thereafter.
The situation is different  however  for Markov networks. Under a complete dataset D  Equation 8
D#(xa) log θxa + C  where C is a constant that
is independent of parameter set θXa. Assuming that θ(cid:63) is feasible (i.e.  satisﬁes Zθ(cid:63) = α)  the
unique optimum of this sub-function has the closed form: θxa = α
  which is equivalent
N
to the unique optimum one would obtain in a sub-function for Equation 6 [15  13]. Contrary to
Bayesian networks  the collection of these optima for different parameter sets do not necessarily
yield a feasible point θ. Hence  the feasibility function g of Theorem 3 must be applied here.
The resulting feasible point  however  may no longer be a stationary point for the corresponding
sub-functions  leading EDML to iterate further. Hence  under complete data  EDML for Bayesian
networks converges immediately  while EDML for Markov networks may take multiple iterations.
Both results are consistent with what is already known in the literature on parameter estimation
for Bayesian and Markov networks. The result on Bayesian networks is useful in conﬁrming that
EDML performs optimally in this case. The result for Markov networks  however  gives rise to a
new algorithm for parameter estimation under complete data. We evaluate the performance of this
new EDML algorithm after considering the following example.
Let D be a complete dataset over three variables A  B and C  speciﬁed in terms of the number
of times that each instantiation a  b  c appears in D. In particular  we have the following counts:
normalize each parameter set to sum-to-one  but then update the constant α = Zθt for the subsequent iteration.

D#(xa)

Cxa

8Theorem 4 assumes that θ(cid:63)

xa (cid:54)= 0. In general  C i

xa = ∂Zθ(cid:63) (di)

∂θxa

  and Cxa = ∂Zθ(cid:63)
∂θxa

. See also Footnote 3.

6

Table 1: Speed-up results of EDML over CG and L-BFGS
i(cid:48)

problem

zero
one
two
three
four
ﬁve
six

seven
eight
nine

54.wcsp

or-chain-42
or-chain-45
or-chain-147
or-chain-148
or-chain-225

rbm20
Seg2-17
Seg7-11

Family2Dominant.1.5loci
Family2Recessive.15.5loci

grid10x10.f5.wrap
grid10x10.f10.wrap

average

#vars
256
256
256
256
256
256
256
256
256
256
67
385
715
410
463
467
40
228
235
385
385
100
100
275.65

icg
45
104
46
43
56
43
48
57
48
56

iedml
105
73
154
169
126
155
150
147
155
168
107.33 160.33
120.33
27
33.67
151
18.67
107.67
42.33
122.67
58
181.33
41 30.98
9
63
1.77
83.66
1.86
54.3
84
2.39
117.33
88
89.7
111.6
1.31
136.67
239 17.36
101.33
83.89 101.29

(S)
tcg
3.62
3.90x
8.25 13.26x
3.73
2.83x
2.52x
3.58
4.31x
4.59
2.70x
3.48
3.13x
3.93
4.64
3.37x
2.84x
3.82
3.15x
4.46
6.56
2.78x
0.12 31.27x
0.14 12.52x
3.27 80.72x
1.00 49.04x
0.79 44.14x
2.38x
7.00x
2.84x
5.90x
3.85x
6.26x
62.33 12.39 20.92x
5.39 13.55x

il-bfgs
24
58
21
52
61
49
20
23
57
45
68.33
110
94.33
105
80
137.67

edml
74
42
87
169
115
155
90
89
154
141
172
54.33
36.33
58.33
32
69
30 107.22
64.67
73.33
78.33
81.67
142 180.33
59
94.89

46.67
48.66
85.67
86.33

92.67
66.84

(S(cid:48))
tl-bfgs
1.64
1.98x
3.87
8.08x
1.54
1.54x
3.55
1.93x
3.90
3.22x
3.20
1.90x
1.47
1.40x
1.65
1.62x
3.83
2.28x
2.90
1.94x
1.80
0.72x
0.06
6.43x
0.06
4.85x
1.63 12.77x
0.28 14.24x
0.33 10.76x
0.99x
30.18
0.74
4.14x
2.32x
1.27
2.69x
1.04
2.18x
0.74
4.63x
10.30
5.94
9.70x
4.45x
3.56

D#(a  b  c) = 4  D#(a  b  ¯c) = 18  D#(a  ¯b  c) = 2  D#(a  ¯b  ¯c) = 13  D#(¯a  b  c) = 1 
D#(¯a  b  ¯c) = 1  D#(¯a  ¯b  c) = 42  and D#(¯a  ¯b  ¯c) = 19. Suppose we want to learn  from
this dataset  a Markov network with 3 edges  (A  B)  (B  C) and (A  C)  with the corresponding
parameter sets θAB  θBC and θAC. If the initial set of parameters θ(cid:63) = (θ(cid:63)
AC) is uniform 
XY = (1  1  1  1)  then Equation 8 gives the sub-function fθ(cid:63) (θAB) = −22 · log θab − 15 ·
i.e.  θ(cid:63)
log θa¯b − 2 · log θ¯ab − 61 · log θ¯a¯b. Moreover  we have Zθ(cid:63) = 2 · θab + 2 · θa¯b + 2 · θ¯ab + 2 · θ¯a¯b.
Minimizing fθ(cid:63) (θAB) under Zθ(cid:63) = α = 2 corresponds to solving a convex optimization problem 
100 ). We solve similar convex
which has the unique solution: (θab  θa¯b  θ¯ab  θa¯b) = ( 22
optimization problems for the other parameter sets θBC and θAC  to update estimates θ(cid:63). We then
apply an appropriate feasibility function g (see Footnote 7)  and repeat until convergence.

100   61

100   15

100   2

AB  θ(cid:63)

BC  θ(cid:63)

6 Experimental Results

We evaluate now the efﬁciency of EDML  conjugate gradient (CG) and Limited-memory BFGS
(L-BFGS)  when learning Markov networks under complete data.9 We ﬁrst learned grid-structured
pairwise MRFs from the CEDAR dataset of handwritten digits  which has 10 datasets (one for each
digit) of 16×16 binary images. We also simulated datasets from networks used in the probabilistic
inference evaluations of UAI-2008  2010 and 2012  that are amenable to jointree inference.10 For
each network  we simulated 3 datasets of size 210 examples each  and learned parameters using the
original structure. Experiments were run on a 3.6GHz Intel i5 CPU with access to 8GB RAM.
We used the CG implementation in the Apache Commons Math library  and the L-BFGS implemen-
tation in Mallet.11 Both are Java libraries  and our implementation of EDML is also in Java. More
importantly  all of the CG  L-BFGS  and EDML methods rely on the same underlying engine for

benchmarks  as it invokes inference many times more often than the methods we considered.

9We also considered Iterative Proportional Fitting (IPF) as a baseline. However  IPF does not scale to our
10Network 54.wcsp is a weighted CSP problem; or-chain-{42  45  147  148  225} are from the Pro-
medas suite; rbm-20 is a restricted Boltzmann machine; Seg2-17  Seg7-11 are from the Segmentation
suite;
family2-recessive.15.5loci are genetic linkage analysis networks; and
grid10x10.f5.wrap  grid10x10.10.wrap are 10x10 grid networks.

family2-dominant.1.5loci 

11Available at http://commons.apache.org/ and http://mallet.cs.umass.edu/.

7

exact inference.12 For EDML  we damped parameter estimates at each iteration  which is typical for
algorithms like loopy belief propagation  which EDML was originally inspired by [5].13 We used
Brent’s method with default settings for line search in CG  which was the most efﬁcient over all
univariate solvers in Apache’s library  which we evaluated in initial experiments.
We ﬁrst run CG until convergence (or after exceeding 30 minutes) to obtain parameter estimates of
some quality qcg (in log likelihood)  recording the number of iterations icg and time tcg required
in minutes. EDML is then run next until it obtains an estimate of the same quality qcg  or better 
recording also the number of iterations iedml and time tedml in minutes. The time speed-up S
of EDML over CG is computed as tcg/tedml. We also performed the same comparison with L-
BFGS instead of CG  recording the corresponding number of iterations (il-bfgs  i(cid:48)
edml) and time
taken (tl-bfgs  t(cid:48)
edml)  giving us the speed-up of EDML over L-BFGS as S(cid:48) = tl-bfgs/t(cid:48)
edml.
Table 1 shows results for both sets of experiments. It shows the number of variables in each net-
work (#vars)  the average number of iterations taken by each algorithm  and the average speed-up
achieved by EDML over CG (L-BFGS).14 On the given benchmarks  we see that on average EDML
was roughly 13.5× faster than CG  and 4.5× faster than L-BFGS. EDML was up to an order-of-
magnitude faster than L-BFGS in some cases. In many cases  EDML required more iterations but
was still faster in time. This is due in part by the number of times inference is invoked by CG and
L-BFGS (in line search)  whereas EDML only needs to invoke inference once per iteration.

7 Related Work

As an iterative ﬁxed-point algorithm  we can view EDML as a Jacobi-type method  where updates
are performed in parallel [1]. Alternatively  a version of EDML using Gauss-Seidel iterations would
update each parameter set in sequence using the most recently computed update. This leads to an
algorithm that monotonically improves the log likelihood at each update. In this case  we obtain a
coordinate descent algorithm  Iterative Proportional Fitting (IPF) [9]  as a special case of EDML.
The notion of ﬁxing all parameters  except for one  has been exploited before for the purposes of
optimizing the log likelihood of a Markov network  as a heuristic for structure learning [15]. This
notion also underlies the IPF algorithm; see  e.g.  [13]  Section 19.5.7. In the case of complete data 
the resulting sub-function is convex  yet for incomplete data  it is not necessarily convex.
Optimization methods such as conjugate gradient  and L-BFGS [12]  are more commonly used to
optimize the parameters of a Markov network. For relational Markov networks or Markov networks
that otherwise assume a feature-based representation [8]  evaluating the likelihood is typically in-
tractable  in which case one typically optimizes instead the pseudo-log-likelihood [2]. For more on
parameter estimation in Markov networks  see [10  13].

8 Conclusion

In this paper  we provided an abstract and simple view of the EDML algorithm  originally proposed
for parameter estimation in Bayesian networks  as a particular method for continuous optimization.
One consequence of this view is that it is immediate that ﬁxed-points of EDML are stationary points
of the log-likelihood  and vice-versa [16]. A more interesting consequence  is that it allows us to
propose an EDML algorithm for a new class of models  Markov networks. Empirically  we ﬁnd that
EDML can more efﬁciently learn parameter estimates for Markov networks under complete data 
compared to conjugate gradient and L-BFGS  sometimes by an order-of-magnitude. The empirical
evaluation of EDML for Markov networks under incomplete data is left for future work.

Acknowledgments

This work has been partially supported by ONR grant #N00014-12-1-0423.

12For exact inference in Markov networks  we employed a jointree algorithm from the SAMIAM inference

library  http://reasoning.cs.ucla.edu/samiam/.

13 We start with an initial factor of 1
14 For CG  we used a threshold based on relative change in the likelihood at 10−4. We used Mallet’s default

2   which we tighten as we iterate.

convergence threshold for L-BFGS.

8

References
[1] Dimitri P. Bertsekas and John N. Tsitsiklis. Parallel and Distributed Computation: Numerical

Methods. Prentice-Hall  1989.

[2] J. Besag. Statistical Analysis of Non-Lattice Data. The Statistician  24:179–195  1975.
[3] Stephen Boyd and Lieven Vandenberghe. Convex Optimization. Cambridge University Press 

2004.

[4] Hei Chan and Adnan Darwiche. On the revision of probabilistic beliefs using uncertain evi-

dence. AIJ  163:67–90  2005.

[5] Arthur Choi  Khaled S. Refaat  and Adnan Darwiche. EDML: A method for learning parame-

ters in Bayesian networks. In UAI  2011.

[6] Adnan Darwiche. A differential approach to inference in Bayesian networks.

50(3):280–305  2003.

JACM 

[7] A.P. Dempster  N.M. Laird  and D.B. Rubin. Maximum likelihood from incomplete data via

the EM algorithm. Journal of the Royal Statistical Society B  39:1–38  1977.

[8] Pedro Domingos and Daniel Lowd. Markov Logic: An Interface Layer for Artiﬁcial Intelli-
gence. Synthesis Lectures on Artiﬁcial Intelligence and Machine Learning. Morgan & Clay-
pool Publishers  2009.

[9] Radim Jirousek and Stanislav Preucil. On the effective implementation of the iterative propor-

tional ﬁtting procedure. Computational Statistics & Data Analysis  19(2):177–189  1995.

[10] Daphne Koller and Nir Friedman. Probabilistic Graphical Models: Principles and Techniques.

MIT Press  2009.

[11] S. L. Lauritzen. The EM algorithm for graphical association models with missing data. Com-

putational Statistics and Data Analysis  19:191–201  1995.

[12] D. C. Liu and J. Nocedal. On the Limited Memory BFGS Method for Large Scale Optimiza-

tion. Mathematical Programming  45(3):503–528  1989.

[13] Kevin Patrick Murphy. Machine Learning: A Probabilistic Perspective. MIT Press  2012.
[14] James Park and Adnan Darwiche. A differential semantics for jointree algorithms. AIJ 

156:197–216  2004.

[15] Stephen Della Pietra  Vincent J. Della Pietra  and John D. Lafferty. Inducing features of random

ﬁelds. IEEE Trans. Pattern Anal. Mach. Intell.  19(4):380–393  1997.

[16] Khaled S. Refaat  Arthur Choi  and Adnan Darwiche. New advances and theoretical insights

into EDML. In UAI  pages 705–714  2012.

9

,Khaled Refaat
Arthur Choi
Adnan Darwiche
Jingjing Zheng
Zhuolin Jiang
Rama Chellappa
Jonathon Phillips