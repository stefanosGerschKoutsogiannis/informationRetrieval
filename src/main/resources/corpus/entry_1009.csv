2014,Combinatorial Pure Exploration of Multi-Armed Bandits,We study the {\em combinatorial pure exploration (CPE)} problem in the stochastic multi-armed bandit setting  where a learner explores a set of arms with the objective of identifying the optimal member of a \emph{decision class}  which is a collection of subsets of arms with certain combinatorial structures such as size-$K$ subsets  matchings  spanning trees or paths  etc. The CPE problem represents a rich class of pure exploration tasks which covers not only many existing models but also novel cases where the object of interest has a non-trivial combinatorial structure. In this paper  we provide a series of results for the general CPE problem. We present general learning algorithms which work for all decision classes that admit offline maximization oracles in both fixed confidence and fixed budget settings. We prove problem-dependent upper bounds of our algorithms. Our analysis exploits the combinatorial structures of the decision classes and introduces a new analytic tool. We also establish a general problem-dependent lower bound for the CPE problem. Our results show that the proposed algorithms achieve the optimal sample complexity (within logarithmic factors) for many decision classes. In addition  applying our results back to the problems of top-$K$ arms identification and multiple bandit best arms identification  we recover the best available upper bounds up to constant factors and partially resolve a conjecture on the lower bounds.,Combinatorial Pure Exploration of

Multi-Armed Bandits

Shouyuan Chen1⇤ Tian Lin2
1The Chinese University of Hong Kong
1{sychen king lyu}@cse.cuhk.edu.hk

Irwin King1 Michael R. Lyu1 Wei Chen3

2lint10@mails.tsinghua.edu.cn 3weic@microsoft.com

2Tsinghua University

3Microsoft Research Asia

Abstract

We study the combinatorial pure exploration (CPE) problem in the stochastic multi-armed
bandit setting  where a learner explores a set of arms with the objective of identifying
the optimal member of a decision class  which is a collection of subsets of arms with
certain combinatorial structures such as size-K subsets  matchings  spanning trees or paths 
etc. The CPE problem represents a rich class of pure exploration tasks which covers not
only many existing models but also novel cases where the object of interest has a non-
trivial combinatorial structure. In this paper  we provide a series of results for the general
CPE problem. We present general learning algorithms which work for all decision classes
that admit ofﬂine maximization oracles in both ﬁxed conﬁdence and ﬁxed budget settings.
We prove problem-dependent upper bounds of our algorithms. Our analysis exploits the
combinatorial structures of the decision classes and introduces a new analytic tool. We also
establish a general problem-dependent lower bound for the CPE problem. Our results show
that the proposed algorithms achieve the optimal sample complexity (within logarithmic
factors) for many decision classes. In addition  applying our results back to the problems
of top-K arms identiﬁcation and multiple bandit best arms identiﬁcation  we recover the
best available upper bounds up to constant factors and partially resolve a conjecture on the
lower bounds.
Introduction

1
Multi-armed bandit (MAB) is a predominant model for characterizing the tradeoff between explo-
ration and exploitation in decision-making problems. Although this is an intrinsic tradeoff in many
tasks  some application domains prefer a dedicated exploration procedure in which the goal is to
identify an optimal object among a collection of candidates and the reward or loss incurred during
exploration is irrelevant. In light of these applications  the related learning problem  called pure ex-
ploration in MABs  has received much attention. Recent advances in pure exploration MABs have
found potential applications in many domains including crowdsourcing  communication network
and online advertising.
In many of these application domains  a recurring problem is to identify the optimal object with
certain combinatorial structure. For example  a crowdsourcing application may want to ﬁnd the best
assignment from workers to tasks such that overall productivity of workers is maximized. A network
routing system during the initialization phase may try to build a spanning tree that minimizes the
delay of links  or attempts to identify the shortest path between two sites. An online advertising
system may be interested in ﬁnding the best matching between ads and display slots. The literature
of pure exploration MAB problems lacks a framework that encompasses these kinds of problems
where the object of interest has a non-trivial combinatorial structure. Our paper contributes such
a framework which accounts for general combinatorial structures  and develops a series of results 
including algorithms  upper bounds and lower bounds for the framework.
In this paper  we formulate the combinatorial pure exploration (CPE) problem for stochastic multi-
armed bandits. In the CPE problem  a learner has a ﬁxed set of arms and each arm is associated with
an unknown reward distribution. The learner is also given a collection of sets of arms called decision
class  which corresponds to a collection of certain combinatorial structures. During the exploration
period  in each round the learner chooses an arm to play and observes a random reward sampled from

⇤This work was done when the ﬁrst two authors were interns at Microsoft Research Asia.

1

the associated distribution. The objective is when the exploration period ends  the learner outputs a
member of the decision class that she believes to be optimal  in the sense that the sum of expected
rewards of all arms in the output set is maximized among all members in the decision class.
The CPE framework represents a rich class of pure exploration problems. The conventional pure ex-
ploration problem in MAB  whose objective is to ﬁnd the single best arm  clearly ﬁts into this frame-
work  in which the decision class is the collection of all singletons. This framework also naturally
encompasses several recent extensions  including the problem of ﬁnding the top K arms (henceforth
TOPK) [18  19  8  20  31] and the multi-bandit problem of ﬁnding the best arms simultaneously
from several disjoint sets of arms (henceforth MB) [12  8]. Further  this framework covers many
more interesting cases where the decision classes correspond to collections of non-trivial combina-
torial structures. For example  suppose that the arms represent the edges in a graph. Then a decision
class could be the set of all paths between two vertices  all spanning trees or all matchings of the
graph. And  in these cases  the objectives of CPE become identifying the optimal paths  spanning
trees and matchings through bandit explorations  respectively. To our knowledge  there are no results
available in the literature for these pure exploration tasks.
The CPE framework raises several interesting challenges to the design and analysis of pure explo-
ration algorithms. One challenge is that  instead of solving each type of CPE task in an ad-hoc way 
one requires a uniﬁed algorithm and analysis that support different decision classes. Another chal-
lenge stems from the combinatorial nature of CPE  namely that the optimal set may contain some
arms with very small expected rewards (e.g.  it is possible that a maximum matching contains the
edge with the smallest weight); hence  arms cannot be eliminated simply based on their own re-
wards in the learning algorithm or ignored in the analysis. This differs from many existing approach
of pure exploration MABs. Therefore  the design and analysis of algorithms for CPE demands novel
techniques which take both rewards and combinatorial structures into account.
Our results. In this paper  we propose two novel learning algorithms for general CPE problem: one
for the ﬁxed conﬁdence setting and one for the ﬁxed budget setting. Both algorithms support a wide
range of decision classes in a uniﬁed way. In the ﬁxed conﬁdence setting  we present Combinatorial
Lower-Upper Conﬁdence Bound (CLUCB) algorithm. The CLUCB algorithm does not need to know
the deﬁnition of the decision class  as long as it has access to the decision class through a maximiza-
tion oracle. We upper bound the number of samples used by CLUCB. This sample complexity bound
depends on both the expected rewards and the structure of decision class. Our analysis relies on a
novel combinatorial construction called exchange class  which may be of independent interest for
other combinatorial optimization problems. Specializing our result to TOPK and MB  we recover
the best available sample complexity bounds [19  13  20] up to constant factors. While for other de-
cision classes in general  our result establishes the ﬁrst sample complexity upper bound. We further
show that CLUCB can be easily extended to the ﬁxed budget setting and PAC learning setting and
we provide related theoretical guarantees in the supplementary material.
Moreover  we establish a problem-dependent sample complexity lower bound for the CPE problem.
Our lower bound shows that the sample complexity of the proposed CLUCB algorithm is optimal
(to within logarithmic factors) for many decision classes  including TOPK  MB and the decision
classes derived from matroids (e.g.  spanning tree). Therefore our upper and lower bounds provide
a nearly full characterization of the sample complexity of these CPE problems. For more general
decision classes  our results show that the upper and lower bounds are within a relatively benign
factor. To the best of our knowledge  there are no problem-dependent lower bounds known for pure
exploration MABs besides the case of identifying the single best arm [24  1]. We also notice that
our result resolves the conjecture of Bubeck et al. [8] on the problem-dependent sample complexity
lower bounds of TOPK and MB problems  for the cases of Gaussian reward distributions.
In the ﬁxed budget setting  we present a parameter-free algorithm called Combinatorial Successive
Accept Reject (CSAR) algorithm. We prove a probability of error bound of the CSAR algorithm. This
bound can be shown to be equivalent to the sample complexity bound of CLUCB within logarithmic
factors  although the two algorithms are based on quite different techniques. Our analysis of CSAR
re-uses exchange classes as tools. This suggests that exchange classes may be useful for analyzing
similar problems. In addition  when applying the algorithm to back TOPK and MB  our bound
recovers the best known result in the ﬁxed budget setting due to Bubeck et al. [8] up to constant
factors.

2

2 Problem Formulation
In this section  we formally deﬁne the CPE problem. Suppose that there are n arms and the arms
are numbered 1  2  . . .   n. Assume that each arm e 2 [n] is associated with a reward distribution
'e. Let w =w(1)  . . .   w(n)T denote the vector of expected rewards  where each entry w(e) =
EX⇠'e[X] denotes the expected reward of arm e. Following standard assumptions of stochastic
MABs  we assume that all reward distributions have R-sub-Gaussian tails for some known constant
R > 0. Formally  if X is a random variable drawn from 'e for some e 2 [n]  then  for all t 2 R 
one has E⇥ exp(tX  tE[X])⇤  exp(R2t2/2). It is known that the family of R-sub-Gaussian tail
distributions encompasses all distributions that are supported on [0  R] as well as many unbounded
distributions such as Gaussian distributions with variance R2 (see e.g.  [27  28]).
We deﬁne a decision class M✓ 2[n] as a collection of sets of arms. Let M⇤ = arg maxM2M w(M )
denote the optimal member of the decision class M which maximizes the sum of expected rewards1.
A learner’s objective is to identify M⇤ from M by playing the following game with the stochastic
environment. At the beginning of the game  the decision class M is revealed to the learner while
the reward distributions {'e}e2[n] are unknown to her. Then  the learner plays the game over a
sequence of rounds; in each round t  she pulls an arm pt 2 [n] and observes a reward sampled
from the associated reward distribution 'pt. The game continues until certain stopping condition is
satisﬁed. After the game ﬁnishes  the learner need to output a set Out 2M .
We consider two different stopping conditions of the game  which are known as ﬁxed conﬁdence
setting and ﬁxed budget setting in the literature. In the ﬁxed conﬁdence setting  the learner can stop
the game at any round. She need to guarantee that Pr[Out = M⇤]  1   for a given conﬁdence
parameter . The learner’s performance is evaluated by her sample complexity  i.e.  the number of
pulls used by the learner. In the ﬁxed budget setting  the game stops after a ﬁxed number T of rounds 
where T is given before the game starts. The learner tries to minimize the probability of error  which
is formally Pr[Out 6= M⇤]  within T rounds. In this setting  her performance is measured by the
probability of error.
3 Algorithm  Exchange Class and Sample Complexity
In this section  we present Combinatorial Lower-Upper Conﬁdence Bound (CLUCB) algorithm  a
learning algorithm for the CPE problem in the ﬁxed conﬁdence setting  and analyze its sample com-
plexity. En route to our sample complexity bound  we introduce the notions of exchange classes and
the widths of decision classes  which play an important role in the analysis and sample complexity
bound. Furthermore  the CLUCB algorithm can be extended to the ﬁxed budget and PAC learning
settings  the discussion of which is included in the supplementary material (Appendix B).
Oracle. We allow the CLUCB algorithm to access a maximization oracle. A maximization oracle
takes a weight vector v 2 Rn as input and ﬁnds an optimal set from a given decision class M with
respect to the weight vector v. Formally  we call a function Oracle: Rn !M a maximization oracle
for M if  for all v 2 Rn  we have Oracle(v) 2 arg maxM2M v(M ). It is clear that a wide range
of decision classes admit such maximization oracles  including decision classes corresponding to
collections of matchings  paths or bases of matroids (see later for concrete examples). Besides the
access to the oracle  CLUCB does not need any additional knowledge of the decision class M.
Algorithm. Now we describe the details of CLUCB  as shown in Algorithm 1. During its execution 
the CLUCB algorithm maintains empirical mean ¯wt(e) and conﬁdence radius radt(e) for each arm
e 2 [n] and each round t. The construction of conﬁdence radius ensures that |w(e)  ¯wt(e)|
radt(e) holds with high probability for each arm e 2 [n] and each round t > 0. CLUCB begins
with an initialization phase in which each arm is pulled once. Then  at round t  n  CLUCB uses
the following procedure to choose an arm to play. First  CLUCB calls the oracle which ﬁnds the
set Mt = Oracle( ¯wt). The set Mt is the “best” set with respect to the empirical means ¯wt. Then 
CLUCB explores possible reﬁnements of Mt. In particular  CLUCB uses the conﬁdence radius to
compute an adjusted expectation vector ˜wt in the following way: for each arm e 2 Mt  ˜wt(e) is
equal to to the lower conﬁdence bound ˜wt(e) = ¯wt(e) radt(e); and for each arm e 62 Mt  ˜wt(e) is
equal to the upper conﬁdence bound ˜wt(e) = ¯wt(e) + radt(e). Intuitively  the adjusted expectation
vector ˜wt penalizes arms belonging to the current set Mt and encourages exploring arms out of

1We deﬁne v(S)  Pi2S v(i) for any vector v 2 Rn and any set S ✓ [n]. In addition  for convenience 

we will assume that M⇤ is unique.

3

Initialize: Play each arm e 2 [n] once. Initialize empirical means ¯wn and set Tn(e) 1 for all e.

Algorithm 1 CLUCB: Combinatorial Lower-Upper Conﬁdence Bound
Require: Conﬁdence  2 (0  1); Maximization oracle: Oracle(·) : Rn !M
1: for t = n  n + 1  . . . do
2:
Mt Oracle( ¯wt)
3:
Compute conﬁdence radius radt(e) for all e 2 [n]
for e = 1  . . .   n do
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:

if e 2 Mt then ˜wt(e) ¯wt(e)  radt(e)
else ˜wt(e) ¯wt(e) + radt(e)

˜Mt Oracle( ˜wt)
if ˜wt( ˜Mt) = ˜wt(Mt) then

pt arg maxe2( ˜Mt\Mt)[(Mt\ ˜Mt) radt(e)
Pull arm pt and observe the reward
Update empirical means ¯wt+1 using the observed reward
Update number of pulls: Tt+1(pt) Tt(pt) + 1 and Tt+1(e) Tt(e) for all e 6= pt

Out Mt
return Out

. radt(e) is deﬁned later in Theorem 1

. break ties arbitrarily

Mt. CLUCB then calls the oracle using the adjusted expectation vector ˜wt as input to compute a
reﬁned set ˜Mt = Oracle( ˜wt). If ˜wt( ˜Mt) = ˜wt(Mt) then CLUCB stops and returns Out = Mt.
Otherwise  CLUCB pulls the arm that belongs to the symmetric difference between Mt and ˜Mt and
has the largest conﬁdence radius (intuitively the largest uncertainty). This ends the t-th round of
CLUCB. We note that CLUCB generalizes and uniﬁes the ideas of several different ﬁxed conﬁdence
algorithms dedicated to the TOPK and MB problems in the literature [19  13  20].
3.1 Sample complexity
Now we establish a problem-dependent sample complexity bound of the CLUCB algorithm. To for-
mally state our result  we need to introduce several notions.
Gap. We begin with deﬁning a natural hardness measure of the CPE problem. For each arm e 2 [n] 
we deﬁne its gap e as

e =⇢w(M⇤)  maxM2M:e2M w(M )

(1)
where we adopt the convention that the maximum value of an empty set is 1. We also deﬁne the
hardness H as the sum of inverse squared gaps
(2)

w(M⇤)  maxM2M:e62M w(M )

if e 62 M⇤ 
if e 2 M⇤ 

2
e .

H = Xe2[n]

We see that  for each arm e 62 M⇤  the gap e represents the sub-optimality of the best set that
includes arm e; and  for each arm e 2 M⇤  the gap e is the sub-optimality of the best set that does
not include arm e. This naturally generalizes and uniﬁes previous deﬁnitions of gaps [1  12  18  8].
Exchange class and the width of a decision class. A notable challenge of our analysis stems from
the generality of CLUCB which  as we have seen  supports a wide range of decision classes M.
Indeed  previous algorithms for special cases including TOPK and MB require a separate analysis
for each individual type of problem. Such strategy is intractable for our setting and we need a uniﬁed
analysis for all decision classes. Our solution to this challenge is a novel combinatorial construction
called exchange class  which is used as a proxy for the structure of the decision class. Intuitively 
an exchange class B for a decision class M can be seen as a collection of “patches” (borrowing
concepts from source code management) such that  for any two different sets M  M0 2M   one can
transform M to M0 by applying a series of patches of B; and each application of a patch yields a
valid member of M. These patches are later used by our analysis to build gadgets that interpolate
between different members of the decision class and serve to bridge key quantities. Furthermore  the
maximum patch size of B will play an important role in our sample complexity bound.
Now we formally deﬁne the exchange class. We begin with the deﬁnition of exchange sets  which
formalize the aforementioned “patches”. We deﬁne an exchange set b as an ordered pair of disjoint
sets b = (b+  b) where b+ \ b = ; and b+  b ✓ [n]. Then  we deﬁne operator  such that  for
any set M ✓ [n] and any exchange set b = (b+  b)  we have M  b   M\b [ b+. Similarly  we
also deﬁne operator such that M b   M\b+ [ b.

4

We call a collection of exchange sets B an exchange class for M if B satisﬁes the following property.
For any M  M0 2M such that M 6= M0 and for any e 2 (M\M0)  there exists an exchange set
(b+  b) 2B which satisﬁes ﬁve constraints: (a) e 2 b  (b) b+ ✓ M0\M  (c) b ✓ M\M0  (d)
(M  b) 2M and (e) (M0 b) 2M .
Intuitively  constraints (b) and (c) resemble the concept of patches in the sense that b+ contains
only the “new” elements from M0 and b contains only the “old” elements of M; constraints (d)
and (e) allow one to transform M one step closer to M0 by applying a patch b 2B to yield (M 
b) 2M (and similarly for M0 b). These transformations are the basic building blocks in our
analysis. Furthermore  as we will see later in our examples  for many decision classes  there are
exchange classes representing natural combinatorial structures  e.g.  augmenting paths and cycles of
matchings.
In our analysis  the key quantity of exchange class is called width  which is deﬁned as the size of the
largest exchange set as follows

width(B) = max

(b+ b)2B |b+| + |b|.

(3)

Let Exchange(M) denote the family of all possible exchange classes for M. We deﬁne the width
of a decision class M as the width of the thinnest exchange class

width(M) =

min

B2Exchange(M)

width(B).

(4)

Sample complexity. Our main result of this section is a problem-dependent sample complexity
bound of the CLUCB algorithm which show that  with high probability  CLUCB returns the optimal

set M⇤ and uses at most ˜O width(M)2H samples.
Theorem 1. Given any  2 (0  1)  any decision class M✓ 2[n] and any expected rewards w 2 Rn.
Assume that the reward distribution 'e for each arm e 2 [n] has mean w(e) with an R-sub-Gaussian
tail. Let M⇤ = arg maxM2M w(M ) denote the optimal set. Set radt(e) = Rq2 log 4nt3
  /Tt(e)
for all t > 0 and e 2 [n]. Then  with probability at least 1    the CLUCB algorithm (Algorithm 1)
returns the optimal set Out = M⇤ and

(5)
where T denotes the number of samples used by Algorithm 1  H is deﬁned in Eq. (2) and width(M)
is deﬁned in Eq. (4).

T  OR2 width(M)2H lognR2H/  

largest expected reward can be modeled by decision class MTOPK(K) = {M ✓ [n] |M = K}.

3.2 Examples of decision classes
Now we investigate several concrete types of decision classes  which correspond to different CPE
tasks. We analyze the width of these decision classes and apply Theorem 1 to obtain the sample
complexity bounds. A detailed analysis and the constructions of exchange classes can be found in
the supplementary material (Appendix F). We begin with the problems of top-K arm identiﬁcation
(TOPK) and multi-bandit best arms identiﬁcation (MB).
Example 1 (TOPK and MB). For any K 2 [n]  the problem of ﬁnding the top K arms with the
Let A = {A1  . . .   Am} be a partition of [n]. The problem of identifying the best arms from each
group of arms A1  . . .   Am can be modeled by decision class MMB(A) = {M ✓ [n] |8 i 2
[m] |M \ Ai| = 1}. Note that maximization oracles for these two decision classes are trivially the
functions of returning the top k arms or the best arms of each group.
Then we have width(MTOPK(K))  2 and width(MMB(A))  2 (see Fact 2 and 3 in the sup-
plementary material) and therefore the sample complexity of CLUCB for solving TOPK and MB is
OH log(nH/)  which matches previous results in the ﬁxed conﬁdence setting [19  13  20] up to

constant factors.

Next we consider the problem of identifying the maximum matching and the problem of ﬁnding
the shortest path (by negating the rewards)  in a setting where arms correspond to edges. For these
problems  Theorem 1 establishes the ﬁrst known sample complexity bound.

5

Example 2 (Matchings and Paths). Let G(V  E) be a graph with n edges and assume there is a one-
to-one mapping between edges E and arms [n]. Suppose that G is a bipartite graph. Let MMATCH(G)
correspond to the set of all matchings in G. Then we have width(MMATCH(G)) | V | (In fact  we
construct an exchange class corresponding to the collection of augmenting cycles and augmenting
paths of G; see Fact 4).
Next suppose that G is a directed acyclic graph and let s  t 2 V be two vertices. Let MPATH(G s t)
correspond to the set of all paths from s to t. Then we have width(MPATH(G s t)) | V | (In fact 
we construct an exchange class corresponding to the collection of disjoint pairs of paths; see
Fact 5). Therefore the sample complexity bounds of CLUCB for decision classes MMATCH(G) and
MPATH(G s t) are O|V |2H log(nH/).
Last  we investigate the general problem of identifying the maximum-weight basis of a matroid.
Again  Theorem 1 is the ﬁrst sample complexity upper bound for this type of pure exploration tasks.
Example 3 (Matroids). Let T = (E I) be a ﬁnite matroid  where E is a set of size n (called
ground set) and I is a family of subsets of E (called independent sets) which satisﬁes the axioms of
matroids (see Footnote 3 in Appendix F). Assume that there is a one-to-one mapping between E and
[n]. Recall that a basis of matroid T is a maximal independent set. Let MMATROID(T ) correspond
to the set of all bases of T . Then we have width(MMATROID(T ))  2 (derived from strong basis
exchange property of matroids; see Fact 1) and the sample complexity of CLUCB for MMATROID(T )
is OH log(nH/).
The last example MMATROID(T ) is a general type of decision class which encompasses many pure
exploration tasks including TOPK and MB as special cases  where TOPK corresponds to uniform
matroids of rank K and MB corresponds to partition matroids. It is easy to see that MMATROID(T )
also covers the decision class that contains all spanning trees of a graph. On the other hand  it has
been established that matchings and paths cannot be formulated as matroids since they are matroid
intersections [26].
4 Lower Bound
In this section  we present a problem-dependent lower bound on the sample complexity of the CPE
problem. To state our results  we ﬁrst deﬁne the notion of -correct algorithm as follows. For any
 2 (0  1)  we call an algorithm A a -correct algorithm if  for any expected reward w 2 Rn  the
probability of error of A is at most   i.e.  Pr[M⇤ 6= Out]    where Out is the output of A.
We show that  for any decision class M and any expected rewards w  a -correct algorithm A must
use at least ⌦H log(1/) samples in expectation.
Theorem 2. Fix any decision class M✓ 2[n] and any vector w 2 Rn. Suppose that  for each
arm e 2 [n]  the reward distribution 'e is given by 'e = N (w(e)  1)  where we let N (µ  2)
denote Gaussian distribution with mean µ and variance 2. Then  for any  2 (0  e16/4) and any
-correct algorithm A  we have

(6)

E[T ] 

1
16

H log✓ 1
4◆  

where T denote the number of total samples used by algorithm A and H is deﬁned in Eq. (2).

In Example 1 and Example 3  we have seen that
the sample complexity of CLUCB is
O(H log(nH/)) for pure exploration tasks including TOPK  MB and more generally the CPE
tasks with decision classes derived from matroids  i.e.  MMATROID(T ) (including spanning trees).
Hence  our upper and lower bound show that the CLUCB algorithm achieves the optimal sample
complexity within logarithmic factors for these pure exploration tasks. In addition  we remark that
Theorem 2 resolves the conjecture of Bubeck et al. [8] that the lower bounds of sample complexity
of TOPK and MB problems are ⌦H log(1/)  for the cases of Gaussian reward distributions.
On the other hand  for general decision classes with non-constant widths  we see that there is a gap of
˜⇥(width(M)2) between the upper bound Eq. (5) and the lower bound Eq. (6). Notice that we have
width(M)  n for any decision class M and therefore the gap is relatively benign. Our lower bound
also suggests that the dependency on H of the sample complexity of CLUCB cannot be improved up
to logarithmic factors. Furthermore  we conjecture that the sample complexity lower bound might
inherently depend on the size of exchange sets. In the supplementary material (Appendix C.2)  we

6

provide evidences on this conjecture which is a lower bound on the sample complexity of exploration
of the exchange sets.
5 Fixed Budget Algorithm
In this section  we present Combinatorial Successive Accept Reject (CSAR) algorithm  which is a
parameter-free learning algorithm for the CPE problem in the ﬁxed budget setting. Then  we upper
bound the probability of error CSAR in terms of gaps and width(M).
Constrained oracle. The CSAR algorithm requires access to a constrained oracle  which is a func-
tion denoted as COracle : Rn ⇥ 2[n] ⇥ 2[n] ! M [ {?} and satisﬁes
COracle(v  A  B) =(arg maxM2MA B v(M )

if MA B 6= ;
if MA B = ; 

(7)

?

where we deﬁne MA B = {M 2M | A ✓ M  B \ M = ;} as the collection of feasible sets
and ? is a null symbol. Hence we see that COracle(v  A  B) returns an optimal set that includes all
elements of A while excluding all elements of B; and if there are no feasible sets  the constrained
oracle COracle(v  A  B) returns the null symbol ?. In the supplementary material (Appendix G) 
we show that constrained oracles are equivalent to maximization oracles up to a transformation on
the weight vector. In addition  similar to CLUCB  CSAR does not need any additional knowledge of
M other than accesses to a constrained oracle for M.
Algorithm. The idea of the CSAR algorithm is as follows. The CSAR algorithm divides the budget
of T rounds into n phases. In the end of each phase  CSAR either accepts or rejects a single arm. If
an arm is accepted  then it is included into the ﬁnal output. Conversely  if an arm is rejected  then it
is excluded from the ﬁnal output. The arms that are neither accepted nor rejected are sampled for an
equal number of times in the next phase.
Now we describe the procedure of the CSAR algorithm for choosing an arm to accept/reject. Let
At denote the set of accepted arms before phase t and let Bt denote the set of rejected arms before
phase t. We call an arm e to be active if e 62 At [ Bt. In the beginning of phase t  CSAR samples
each active arm for ˜Tt  ˜Tt1 times  where the deﬁnition of ˜Tt is given in Algorithm 2. Next 
CSAR calls the constrained oracle to compute an optimal set Mt with respect to the empirical means
¯wt  accepted arms At and rejected arms Bt  i.e.  Mt = COracle( ¯wt  At  Bt). It is clear that the
output of COracle( ¯wt  At  Bt) is independent from the input ¯wt(e) for any e 2 At [ Bt. Then  for
each active arm e  CSAR estimates the “empirical gap” of e in the following way. If e 2 Mt  then
CSAR computes an optimal set ˜Mt e that does not include e  i.e.  ˜Mt e = COracle( ¯wt  At  Bt [
{e}). Conversely  if e 62 Mt  then CSAR computes an optimal ˜Mt e which includes e  i.e.  ˜Mt e =
COracle( ¯wt  At[{e}  Bt). Then  the empirical gap of e is calculated as ¯wt(Mt) ¯wt( ˜Mt e). Finally 
CSAR chooses the arm pt which has the largest empirical gap. If pt 2 Mt then pt is accepted 
otherwise pt is rejected. The pseudo-code CSAR is shown in Algorithm 2. We note that CSAR can
be considered as a generalization of the ideas of the two versions of SAR algorithm due to Bubeck
et al. [8]  which are designed speciﬁcally for the TOPK and MB problems respectively.
5.1 Probability of error
In the following theorem  we bound the probability of error of the CSAR algorithm.
Theorem 3. Given any T > n  any decision class M✓ 2[n] and any expected rewards w 2
Rn. Assume that the reward distribution 'e for each arm e 2 [n] has mean w(e) with an R-sub-
Gaussian tail. Let (1)  . . .   (n) be a permutation of 1  . . .   n (deﬁned in Eq. (1)) such that
(1)  . . . . . . (n). Deﬁne H2   maxi2[n] i2
(i) . Then  the CSAR algorithm uses at most T
samples and outputs a solution Out 2 M [ {?} such that
Pr[Out 6= M⇤]  n2 exp✓
i=1 i1  M⇤ = arg maxM2M w(M ) and width(M) is deﬁned in Eq. (4).

where ˜log(n)  Pn
One can verify that H2 is equivalent to H up to a logarithmic factor: H2  H  log(2n)H2 (see
[1]). Therefore  by setting the probability of error (the RHS of Eq. (8)) to a constant  one can see
that CSAR requires a budget of T = ˜O(width(M)2H) samples. This is equivalent to the sample
complexity bound of CLUCB up to logarithmic factors. In addition  applying Theorem 3 back to
TOPK and MB  our bound matches the previous ﬁxed budget algorithm due to Bubeck et al. [8].

18R2 ˜log(n) width(M)2H2◆  

(T  n)

(8)

7

1
i

i=1

.

. set ¯wt(e) = 0  8e 2 At [ Bt

. deﬁne ¯wt(?) = 1; break ties arbitrarily

pt arg maxe2[n]\(At[Bt) ¯wt(Mt)  ¯wt( ˜Mt e)
if pt 2 Mt then
else

At+1 At [{ pt}  Bt+1 Bt
At+1 At  Bt+1 Bt [{ pt}

fail: set Out ? and return Out
if e 2 Mt then ˜Mt e COracle( ¯wt  At  Bt [{ e})
else ˜Mt e COracle( ¯wt  At [{ e}  Bt)

˜Tt l
Pull each arm e 2 [n]\(At [ Bt) for ˜Tt  ˜Tt1 times
Update the empirical means ¯wt for each arm e 2 [n]\(At [ Bt)
Mt COracle( ¯wt  At  Bt)
if Mt = ? then
for each e 2 [n]\(At [ Bt) do

Algorithm 2 CSAR: Combinatorial Successive Accept Reject
Require: Budget: T > 0; Constrained oracle: COracle : Rn ⇥ 2[n] ⇥ 2[n] !M[{?}
1: Deﬁne ˜log(n)  Pn
2: ˜T0 0  A1 ;  B1 ;
3: for t = 1  . . .   n do
˜log(n)(nt+1)m
4:
Tn
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18: Out An+1
19: return Out
6 Related Work
The multi-armed bandit problem has been extensively studied in both stochastic and adversarial
settings [22  3  2]. We refer readers to [5] for a survey on recent advances. Many work in MABs focus
on minimizing the cumulative regret  which is an objective known to be fundamentally different
from the objective of pure exploration MABs [6]. Among these work  a recent line of research
considers a generalized setting called combinatorial bandits in which a set of arms (satisfying certain
combinatorial constraints) are played on each round [9  17  25  7  10  14  23  21]. Note that the
objective of these work is to minimize the cumulative regret  which differs from ours.
In the literature of pure exploration MABs  the classical problem of identifying the single best arm
has been well-studied in both ﬁxed conﬁdence and ﬁxed budget settings [24  11  6  1  13  15  16].
A ﬂurry of recent work extend this classical problem to TOPK and MB problems and obtain algo-
rithms with upper bounds [18  12  13  19  8  20  31] and worst-case lower bounds of TOPK [19  31].
Our framework encompasses these two problems as special cases and covers a much larger class of
combinatorial pure exploration problems  which have not been addressed in current literature. Ap-
plying our results back to TOPK and MB  our upper bounds match best available problem-dependent
bounds up to constant factors [13  19  8] in both ﬁxed conﬁdence and ﬁxed budget settings; and our
lower bound is the ﬁrst proven problem-dependent lower bound for these two problems  which are
conjectured earlier by Bubeck et al. [8].
7 Conclusion
In this paper  we proposed a general framework called combinatorial pure exploration (CPE) that
can handle pure exploration tasks for many complex bandit problems with combinatorial constraints 
and have potential applications in various domains. We have shown a number of results for the
framework  including two novel learning algorithms  their related upper bounds and a novel lower
bound. The proposed algorithms support a wide range of decision classes in a unifying way and our
analysis introduced a novel tool called exchange class  which may be of independent interest. Our
upper and lower bounds characterize the complexity of the CPE problem: the sample complexity of
our algorithm is optimal (up to a logarithmic factor) for the decision classes derived from matroids
(including TOPK and MB)  while for general decision classes  our upper and lower bounds are
within a relatively benign factor.
Acknowledgments. The work described in this paper was partially supported by the National Grand
Fundamental Research 973 Program of China (No. 2014CB340401 and No. 2014CB340405)  the
Research Grants Council of the Hong Kong Special Administrative Region  China (Project No.
CUHK 413212 and CUHK 415113)  and Microsoft Research Asia Regional Seed Fund in Big Data
Research (Grant No. FY13-RES-SPONSOR-036).

8

References
[1] J.-Y. Audibert  S. Bubeck  and R. Munos. Best arm identiﬁcation in multi-armed bandits. In COLT  2010.
[2] P. Auer  N. Cesa-Bianchi  and P. Fischer. Finite-time analysis of the multiarmed bandit problem. Machine

learning  47(2-3):235–256  2002.

[3] P. Auer  N. Cesa-Bianchi  Y. Freund  and R. E. Schapire. The nonstochastic multiarmed bandit problem.

SIAM Journal on Computing  32(1):48–77  2002.

[4] C. Berge. Two theorems in graph theory. PNAS  1957.
[5] S. Bubeck and N. Cesa-Bianchi. Regret analysis of stochastic and nonstochastic multi-armed bandit

problems. Foundations and Trends in Machine Learning  5:1–122  2012.

[6] S. Bubeck  R. Munos  and G. Stoltz. Pure exploration in ﬁnitely-armed and continuous-armed bandits.

Theoretical Computer Science  412:1832–1852  2010.

[7] S. Bubeck  N. Cesa-bianchi  S. M. Kakade  S. Mannor  N. Srebro  and R. C. Williamson. Towards mini-

max policies for online linear optimization with bandit feedback. In COLT  2012.

[8] S. Bubeck  T. Wang  and N. Viswanathan. Multiple identiﬁcations in multi-armed bandits.

pages 258–265  2013.

In ICML 

[9] N. Cesa-Bianchi and G. Lugosi. Combinatorial bandits. JCSS  78(5):1404–1422  2012.
[10] W. Chen  Y. Wang  and Y. Yuan. Combinatorial multi-armed bandit: General framework and applications.

In ICML  pages 151–159  2013.

[11] E. Even-Dar  S. Mannor  and Y. Mansour. Action elimination and stopping conditions for the multi-armed

bandit and reinforcement learning problems. JMLR  2006.

[12] V. Gabillon  M. Ghavamzadeh  A. Lazaric  and S. Bubeck. Multi-bandit best arm identiﬁcation. In NIPS.

2011.

[13] V. Gabillon  M. Ghavamzadeh  and A. Lazaric. Best arm identiﬁcation: A uniﬁed approach to ﬁxed budget

and ﬁxed conﬁdence. In NIPS  2012.

[14] A. Gopalan  S. Mannor  and Y. Mansour. Thompson sampling for complex online problems. In ICML 

pages 100–108  2014.

[15] K. Jamieson and R. Nowak. Best-arm identiﬁcation algorithms for multi-armed bandits in the ﬁxed

conﬁdence setting. In Information Sciences and Systems (CISS)  pages 1–6. IEEE  2014.

[16] K. Jamieson  M. Malloy  R. Nowak  and S. Bubeck.

multi-armed bandits. COLT  2014.

lil’UCB: An optimal exploration algorithm for

[17] S. Kale  L. Reyzin  and R. E. Schapire. Non-stochastic bandit slate problems. In NIPS  2010.
[18] S. Kalyanakrishnan and P. Stone. Efﬁcient selection of multiple bandit arms: Theory and practice. In

ICML  pages 511–518  2010.

[19] S. Kalyanakrishnan  A. Tewari  P. Auer  and P. Stone. PAC subset selection in stochastic multi-armed

bandits. In ICML  pages 655–662  2012.

[20] E. Kaufmann and S. Kalyanakrishnan. Information complexity in bandit subset selection. In COLT  2013.
[21] B. Kveton  Z. Wen  A. Ashkan  H. Eydgahi  and B. Eriksson. Matroid bandits: Fast combinatorial opti-

mization with learning. In UAI  2014.

[22] T. L. Lai and H. Robbins. Asymptotically efﬁcient adaptive allocation rules. Advances in applied mathe-

matics  6(1):4–22  1985.

[23] T. Lin  B. Abrahao  R. Kleinberg  J. Lui  and W. Chen. Combinatorial partial monitoring game with linear

feedback and its application. In ICML  2014.

[24] S. Mannor and J. N. Tsitsiklis. The sample complexity of exploration in the multi-armed bandit problem.

The Journal of Machine Learning Research  5:623–648  2004.

[25] G. Neu  A. Gy¨orgy  and C. Szepesv´ari. The online loop-free stochastic shortest-path problem. In COLT 

pages 231–243  2010.

[26] J. G. Oxley. Matroid theory. Oxford university press  2006.
[27] D. Pollard. Asymptopia. Manuscript  Yale University  Dept. of Statist.  New Haven  Connecticut  2000.
[28] O. Rivasplata. Subgaussian random variables: An expository note. 2012.
[29] S. M. Ross. Stochastic processes  volume 2. John Wiley & Sons New York  1996.
[30] N. Spring  R. Mahajan  and D. Wetherall. Measuring ISP topologies with rocketfuel. ACM SIGCOMM

Computer Communication Review  32(4):133–145  2002.

[31] Y. Zhou  X. Chen  and J. Li. Optimal PAC multiple arm identiﬁcation with applications to crowdsourcing.

In ICML  2014.

9

,Shouyuan Chen
Tian Lin
Irwin King
Michael Lyu
Wei Chen