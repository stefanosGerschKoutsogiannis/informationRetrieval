2011,Finite Time Analysis of Stratified Sampling for Monte Carlo,We consider the problem of stratified sampling for Monte-Carlo integration. We model this problem in a multi-armed bandit setting  where the arms represent the strata  and the goal is to estimate a weighted average of the mean values of the arms. We propose a strategy that samples the arms according to an upper bound on their standard deviations and compare its estimation quality to an ideal allocation that would know the standard deviations of the arms. We provide two regret analyses: a distribution-dependent bound O(n^{-3/2}) that depends on a measure of the disparity of the arms  and a distribution-free bound O(n^{-4/3}) that does not. To the best of our knowledge  such a finite-time analysis is new for this problem.,Finite-Time Analysis of Stratiﬁed Sampling

for Monte Carlo

Alexandra Carpentier
INRIA Lille - Nord Europe

alexandra.carpentier@inria.fr

R´emi Munos

INRIA Lille - Nord Europe

remi.munos@inria.fr

Abstract

We consider the problem of stratiﬁed sampling for Monte-Carlo integration.
We model this problem in a multi-armed bandit setting  where the arms
represent the strata  and the goal is to estimate a weighted average of the
mean values of the arms. We propose a strategy that samples the arms
according to an upper bound on their standard deviations and compare
its estimation quality to an ideal allocation that would know the standard
deviations of the strata. We provide two regret analyses: a distribution-

dependent bound �O(n−3/2) that depends on a measure of the disparity of
the strata  and a distribution-free bound �O(n−4/3) that does not.

1

Introduction

Consider a polling institute that has to estimate as accurately as possible the average income
of a country  given a ﬁnite budget for polls. The institute has call centers in every region in
the country  and gives a part of the total sampling budget to each center so that they can
call random people in the area and ask about their income. A naive method would allocate
a budget proportionally to the number of people in each area. However some regions show
a high variability in the income of their inhabitants whereas others are very homogeneous.
Now if the polling institute knew the level of variability within each region  it could adjust
the budget allocated to each region in a more clever way (allocating more polls to regions
with high variability) in order to reduce the ﬁnal estimation error.

This example is just one of many for which an eﬃcient method of sampling a function with
natural strata (i.e.  the regions) is of great interest. Note that even in the case that there
are no natural strata  it is always a good strategy to design arbitrary strata and allocate
a budget to each stratum that is proportional to the size of the stratum  compared to a
crude Monte-Carlo. There are many good surveys on the topic of stratiﬁed sampling for
Monte-Carlo  such as (Rubinstein and Kroese  2008)[Subsection 5.5] or (Glasserman  2004).

The main problem for performing an eﬃcient sampling is that the variances within the
strata (in the previous example  the income variability per region) are usually unknown.
One possibility is to estimate the variances online while sampling the strata. There is
some interesting research along this direction  such as (Arouna  2004) and more recently
(Etor´e and Jourdain  2010  Kawai  2010). The work of Etor´e and Jourdain (2010) matches
exactly our problem of designing an eﬃcient adaptive sampling strategy. In this article they
propose to sample according to an empirical estimate of the variance of the strata  whereas
Kawai (2010) addresses a computational complexity problem which is slightly diﬀerent from
ours. The recent work of Etor´e et al. (2011) describes a strategy that enables to sample
asymptotically according to the (unknown) standard deviations of the strata and at the same
time adapts the shape (and number) of the strata online. This is a very diﬃcult problem 
especially in high dimension  that we will not address here  although we think this is a very
interesting and promising direction for further researches.

1

These works provide asymptotic convergence of the variance of the estimate to the targeted
stratiﬁed variance1 divided by the sample size. They also prove that the number of pulls
within each stratum converges to the desired number of pulls i.e. the optimal allocation
if the variances per stratum were known. Like Etor´e and Jourdain (2010)  we consider a
stratiﬁed Monte-Carlo setting with ﬁxed strata. Our contribution is to design a sampling
strategy for which we can derive a ﬁnite-time analysis (where ’time’ refers to the number of
samples). This enables us to predict the quality of our estimate for any given budget n.

We model this problem using the setting of multi-armed bandits where our goal is to estimate
a weighted average of the mean values of the arms. Although our goal is diﬀerent from a usual
bandit problem where the objective is to play the best arm as often as possible  this problem
also exhibits an exploration-exploitation trade-oﬀ. The arms have to be pulled both in
order to estimate the initially unknown variability of the arms (exploration) and to allocate
correctly the budget according to our current knowledge of the variability (exploitation).

Our setting is close to the one described in (Antos et al.  2010) which aims at estimating
uniformly well the mean values of all the arms. The authors present an algorithm  called
GAFS-MAX  that allocates samples proportionally to the empirical variance of the arms 
while imposing that each arm is pulled at least √n times to guarantee a suﬃciently good
estimation of the true variances.

Note though that in the Master Thesis (Grover  2009)  the author presents an algorithm
named GAFS-WL which is similar to GAFS-MAX and has an analysis close to the one of
GAFS-MAX. It deals with stratiﬁed sampling  i.e. it targets an allocation which is propor-
tional to the standard deviation (and not to the variance) of the strata times their size2.
Some questions remain open in this work  notably that no distribution independent regret
bound is provided for GAFS-WL. We clarify this point in Section 4. Our objective is similar 
and we extend the analysis of this setting.

In this paper  we introduce a new algorithm based on Upper-Conﬁdence-
Contributions:
Bounds (UCB) on the standard deviation. They are computed from the empirical standard
deviation and a conﬁdence interval derived from Bernstein’s inequalities. We provide a
ﬁnite-time analysis of its performance. The algorithm  called MC-UCB  samples the arms
proportionally to an UCB3 on the standard deviation times the size of the stratum. Note
that the idea is similar to the one in (Carpentier et al.  2011). Our contributions are the
following:

• We derive a ﬁnite-time analysis for the stratiﬁed sampling for Monte-Carlo setting
by using an algorithm based on upper conﬁdence bounds. We show how such a
family of algorithm is particularly interesting in this setting.

depends on the disparity of the stratas (a measure of the problem complexity)  and
which corresponds to a stationary regime where the budget n is large compared to

• We provide two regret analysis: (i) a distribution-dependent bound �O(n−3/2)4 that
this complexity. (ii) A distribution-free bound �O(n−4/3) that does not depend on

the the disparity of the stratas  and corresponds to a transitory regime where n is
small compared to the complexity. The characterization of those two regimes and
the fact that the corresponding excess error rates diﬀer enlightens the fact that a
ﬁnite-time analysis is very relevant for this problem.

The rest of the paper is organized as follows. In Section 2 we formalize the problem and
introduce the notations used throughout the paper. Section 3 introduces the MC-UCB algo-
rithm and reports performance bounds. We then discuss in Section 4 about the parameters
of the algorithm and its performances. In Section 5 we report numerical experiments that

1The target is deﬁned in [Subsection 5.5] of (Rubinstein and Kroese  2008) and later in this

paper  see Equation 4.

2This is explained in (Rubinstein and Kroese  2008) and will be formulated precisely later.
3Note that we consider a sampling strategy based on UCBs on the standard deviations of the
arms whereas the so-called UCB algorithm of Auer et al. (2002)  in the usual multi-armed bandit
setting  computes UCBs on the mean rewards of the arms.

4The notation �O(·) corresponds to O(·) up to logarithmic factors.

2

illustrate our method on the problem of pricing Asian options as introduced in (Glasserman
et al.  1999). Finally  Section 6 concludes the paper and suggests future works.

2 Preliminaries

The allocation problem mentioned in the previous section is formalized as a K-armed bandit
problem where each arm (stratum) k = 1  . . .   K is characterized by a distribution νk with
mean value µk and variance σ2
k. At each round t ≥ 1  an allocation strategy (or algorithm) A
selects an arm kt and receives a sample drawn from νkt independently of the past samples.
Note that a strategy may be adaptive  i.e.  the arm selected at round t may depend on
past observed samples. Let {wk}k=1 ... K denote a known set of positive weights which sum
to 1. For example in the setting of stratiﬁed sampling for Monte-Carlo  this would be the
probability mass in each stratum. The goal is to deﬁne a strategy that estimates as precisely
as possible µ = �K
Let us write Tk t = �t
Tk t�

I{ks = k} the number of times arm k has been pulled up to time
Xk s the empirical estimate of the mean µk at time t  where Xk s

k=1 wkµk using a total budget of n samples.

t  and ˆµk t =

s=1

1
Tk t

denotes the sample received when pulling arm k for the s-th time.
After n rounds  the algorithm A returns the empirical estimate ˆµk n of all the arms. Note
that in the case of a deterministic strategy  the expected quadratic estimation error of the
weighted mean µ as estimated by the weighted average ˆµn = �K
k=1 w2
k

k=1 wk(ˆµk n − µk)�2� = �K

E��ˆµn − µ�2� = E���K

Eνk��ˆµk n − µk�2�.

k=1 wk ˆµk n satisﬁes:

s=1

We thus use the following measure for the performance of any algorithm A:

Ln(A) = �K

k=1 w2
k

E�(µk − ˆµk n)2� .

(1)

The goal is to deﬁne an allocation strategy that minimizes the global loss deﬁned in Equa-
tion 1. If the variance of the arms were known in advance  one could design an optimal
static5 allocation strategy A∗ by pulling each arm k proportionally to the quantity wkσk.
Indeed  if arm k is pulled a deterministic number of times T ∗

k n  then

Ln(A∗) = �K

k=1 w2
k

σ2
k
T ∗

k n

.

(2)

By choosing T ∗
optimal static allocation (up to rounding eﬀects) of algorithm A∗ is to pull each arm k 

k n such as to minimize Ln under the constraint that �K

k=1 T ∗

k n = n  the

(3)

(4)

times  and achieves a global performance

T ∗
k n =

wkσk
i=1 wiσi

�K

n  

Ln(A∗) =

Σ2
w
n

 

where Σw = �K

i=1 wiσi. In the following  we write λk =

the optimal allocation
proportion for arm k and λmin = min1≤k≤K λk. Note that a small λmin means a large
disparity of the wkσk and  as explained later  provides for the algorithm we build in Section
3 a characterization of the hardness of a problem.

k n

n = wkσk
Σw

T ∗

However  in the setting considered here  the σk are unknown  and thus the optimal allocation
is out of reach. A possible allocation is the uniform strategy Au  i.e.  such that T u
k =

n. Its performance is

wk
i=1 wi

�K

Ln(Au) = �K

k=1 wk�K

k=1

wkσ2
n = Σw 2
k

n

 

5Static means that the number of pulls allocated to each arm does not depend on the received

samples.

3

k=1 wkσ2

k. Note that by Cauchy-Schwartz’s inequality  we have Σ2

where Σw 2 = �K
w ≤ Σw 2
with equality if and only if the (σk) are all equal. Thus A∗ is always at least as good as
Au. In addition  since �i wi = 1  we have Σ2
w − Σw 2 = −�k wk(σk − Σw)2. The diﬀerence
between those two quantities is the weighted quadratic variation of the σk around their
weighted mean Σw. In other words  it is the variance of the (σk)1≤k≤K. As a result the
gain of A∗ compared to Au grow with the disparity of the σk.
We would like to do better than the uniform strategy by considering an adaptive strategy A
that would estimate the σk at the same time as it tries to implement an allocation strategy
as close as possible to the optimal allocation algorithm A∗. This introduces a natural
trade-oﬀ between the exploration needed to improve the estimates of the variances and the
exploitation of the current estimates to allocate the pulls nearly-optimally.
In order to assess how well A solves this trade-oﬀ and manages to sample according to the
true standard deviations without knowing them in advance  we compare its performance to
that of the optimal allocation strategy A∗. For this purpose we deﬁne the notion of regret
of an adaptive algorithm A as the diﬀerence between the performance loss incurred by the
algorithm and the optimal algorithm:
(5)

Rn(A) = Ln(A) − Ln(A∗).

The regret indicates how much we loose in terms of expected quadratic estimation error
by not knowing in advance the standard deviations (σk). Note that since Ln(A∗) = Σ2
n  
a consistent strategy i.e.  asymptotically equivalent to the optimal strategy  is obtained
whenever its regret is neglectable compared to 1/n.

w

3 Allocation based on Monte Carlo Upper Conﬁdence Bound

3.1 The algorithm

In this section  we introduce our adaptive algorithm for the allocation problem  called Monte
Carlo Upper Conﬁdence Bound (MC-UCB). The algorithm computes a high-probability
bound on the standard deviation of each arm and samples the arms proportionally to their
bounds times the corresponding weights. The MC-UCB algorithm  AM C−U CB  is described
in Figure 1.
It requires three parameters as inputs: c1 and c2 which are related to the
shape of the distributions (see Assumption 1)  and δ which deﬁnes the conﬁdence level of
the bound. In Subsection 4.2  we discuss a way to reduce the number of parameters from
three to one. The amount of exploration of the algorithm can be adapted by properly tuning
these parameters.

Input: c1  c2  δ. Let b = 2�2 log(2/δ)�c1 log(c2/δ) +

√2c1δ(1+log(c2/δ))n1/2

(1−δ)

.

Initialize: Pull each arm twice.
for t = 2K + 1  . . .   n do

Compute Bk t = wk
Pull an arm kt ∈ arg max1≤k≤K Bk t
end for
Output: ˆµk t for each arm 1 ≤ k ≤ K

Tk t−1�ˆσk t−1 + b� 1

Tk t−1� for each arm 1 ≤ k ≤ K

Figure 1: The pseudo-code of the MC-UCB algorithm. The empirical standard deviations
ˆσk t−1 are computed using Equation 6.

The algorithm starts by pulling each arm twice in rounds t = 1 to 2K. From round t = 2K+1
on  it computes an upper conﬁdence bound Bk t on the standard deviation σk  for each arm
k  and then pulls the one with largest Bk t. The upper bounds on the standard deviations
are built by using Theorem 10 in (Maurer and Pontil  2009)6 and based on the empirical
standard deviation ˆσk t−1 :

ˆσ2
k t−1 =

1

Tk t−1 − 1

Tk t−1�

i=1

(Xk i − ˆµk t−1)2 

(6)

6We could also have used the variant reported in (Audibert et al.  2009).

4

where Xk i is the i-th sample received when pulling arm k  and Tk t−1 is the number of pulls
allocated to arm k up to time t − 1. After n rounds  MC-UCB returns the empirical mean
ˆµk n for each arm 1 ≤ k ≤ K.
3.2 Regret analysis of MC-UCB

Before stating the main results of this section  we state the assumption that the distributions
are sub-Gaussian  which includes e.g.  Gaussian or bounded distributions. See (Buldygin
and Kozachenko  1980) for more precisions.

Assumption 1 There exist c1  c2 > 0 such that for all 1 ≤ k ≤ K and any � > 0 

PX∼νk (|X − µk| ≥ �) ≤ c2 exp(−�2/c1) .

(7)

We provide two analyses  a distribution-dependent and a distribution-free  of MC-UCB 
which are respectively interesting in two regimes  i.e.  stationary and transitory regimes  of
the algorithm. We will comment on this later in Section 4.

A distribution-dependent result: We now report the ﬁrst bound on the regret of MC-
UCB algorithm. The proof is reported in (Carpentier and Munos  2011). and relies on
upper- and lower-bounds on Tk t − T ∗
k t  i.e.  the diﬀerence in the number of pulls of each
arm compared to the optimal allocation (see Lemma 3).
Theorem 1 Under Assumption 1 and if we choose c2 such that c2 ≥ 2Kn−5/2  the regret
of MC-UCB run with parameter δ = n−7/2 with n ≥ 4K is bounded as
w + 720c1(c2 + 1) log(n)2�.
Rn(AM C−U CB) ≤

�112Σw + 6K� +

minn2�KΣ2

log(n)c1(c2 + 2)

λ3

19

n3/2λ3/2
min

Note that this result crucially depends on the smallest proportion λmin which is a measure
of the disparity of the standard deviations times their weight. For this reason we refer to it
as “distribution-dependent” result.

A distribution-free result: Now we report our second regret bound that does not depend
on λmin but whose rate is poorer. The proof is reported in (Carpentier and Munos  2011)
and relies on other upper- and lower-bounds on Tk t − T ∗
Theorem 2 Under Assumption 1 and if we choose c2 such that c2 ≥ 2Kn−5/2  the regret
of MC-UCB run with parameter δ = n−7/2 with n ≥ 4K is bounded as
n3/2�129c1(c2 + 2)2K 2 log(n)2 + KΣ2
w�.
Rn(AM C−U CB) ≤
This bound does not depend on 1/λmin. Note that the bound is not entirely distribution
free since Σw appears. But it can be proved using Assumption 1 that Σ2
w ≤ c1c2. This is

200√c1(c2 + 2)ΣwK

k t detailed in Lemma 4.

log(n) +

n4/3

365

obtained at the price of the slightly worse rate �O(n−4/3).

4 Discussion on the results

4.1 Distribution-free versus distribution-dependent

Theorem 1 provides a regret bound of order �O(λ−5/2
min n−3/2)  whereas Theorem 2 provides a
bound in �O(n−4/3) independently of λmin. Hence  for a given problem i.e.  a given λmin  the

distribution-free result of Theorem 2 is more informative than the distribution-dependent
result of Theorem 1 in the transitory regime  that is to say when n is small compared to
λ−1
min. The distribution-dependent result of Theorem 1 is better in the stationary regime i.e. 
for large n. This distinction reminds us of the diﬀerence between distribution-dependent
and distribution-free bounds for the UCB algorithm in usual multi-armed bandits7.

7The distribution dependent bound is in O(K log n/Δ)  where Δ is the diﬀerence between the
mean value of the two best arms  and the distribution-free bound is in O(√nK log n) as explained
in (Auer et al.  2002  Audibert and Bubeck  2009).

5

Although we do not have a lower bound on the regret yet  we believe that the rate n−3/2
cannot be improved for general distributions. As explained in the proof in Appendix B
of (Carpentier and Munos  2011)  this rate is a direct consequence of the high probability
bounds on the estimates of the standard deviations of the arms which are in O(1/√n)  and
those bounds are tight. A natural question is whether there exists an algorithm with a regret
of order �O(n−3/2) without any dependence in λ−1
min. Although we do not have an answer
to this question  we can say that our algorithm MC-UCB does not satisfy this property. In
Appendix D.1 of (Carpentier and Munos  2011)  we give a simple example where λmin = 0
and for which the rate of MC-UCB cannot be better than �O(n−4/3). This shows that our

analysis of MC-UCB is tight.

The problem dependent upper bound is similar to the one provided for GAFS-WL in
(Grover  2009). We however expect that GAFS-WL has for some problems a sub-optimal
behavior: it is possible to ﬁnd cases where Rn(AGAF S−W L) = Ω(1/n)  see Appendix D.1
of (Carpentier and Munos  2011). Note however that when there is an arm with 0 standard
deviation  GAFS-WL is likely to perform better than MC-UCB  as it will only sample this
arm O(√n) times while MC-UCB samples it �O(n2/3) times.

4.2 The parameters of the algorithm

(1−δ)

Our algorithm takes three parameters as input  namely c1  c2 and δ  but we only use a com-
bination of them in the algorithm  with the introduction of b = 2�2 log(2/δ)�c1 log(c2/δ)+
√2c1δ(1+log(c2/δ))n1/2

. For practical use of the method  it is enough to tune the algorithm
with a single parameter b. By the choice of the value assigned to δ in the two theorems 
b should be chosen of order c log(n)  where c can be interpreted as a high probability
bound on the range of the samples. We thus simply require a rough estimate of the mag-
nitude of the samples. Note that in the case of bounded distributions  b can be chosen as

2 c�log(n) where c is a true bound on the variables. This result is easy to deduce

b = 4� 5

by simplifying Lemma 1 in Appendix A of (Carpentier and Munos  2011) for the case of
bounded variables.

5 Numerical experiment: Pricing of an Asian option

We consider the pricing problem of an Asian option introduced in (Glasserman et al.  1999)
and later considered in (Kawai  2010  Etor´e and Jourdain  2010). This uses a Black-Schole
model with strike C and maturity T . Let (W (t))0≤t≤1 be a Brownian motion that is
discretized at d equidistant times {i/d}1≤i≤d  which deﬁnes the vector W ∈ Rd with com-
ponents Wi = W (i/d). The discounted payoﬀ of the Asian option is deﬁned as a function
of W   by:

F (W ) = exp(−rT ) max� 1

d �d

i=1 S0 exp�(r − 1
2 s2

0) iT

d + s0√T Wi� − C  0� 

(8)

where S0  r  and s0 are constants  and the price is deﬁned by the expectation p = EW F (W ).

We want to estimate the price p by Monte-Carlo simulations (by sampling on W =
(Wi)1≤i≤d).
In order to reduce the variance of the estimated price  we can stratify the
space of W . Glasserman et al. (1999) suggest to stratify according to a one dimensional
projection of W   i.e.  by choosing a projection vector u ∈ Rd and deﬁne the strata as the set
of W such that u · W lies in intervals of R. They further argue that the best direction for
stratiﬁcation is to choose u = (0 ···   0  1)  i.e.  to stratify according to the last component
Wd of W . Thus we sample Wd and then conditionally sample W1  ...  Wd−1 according to a
Brownian Bridge as explained in (Kawai  2010). Note that this choice of stratiﬁcation is also
intuitive since Wd has the largest exponent in the payoﬀ (8)  and thus the highest volatility.
Kawai (2010) and Etor´e and Jourdain (2010) also use the same direction of stratiﬁcation.
Like in (Kawai  2010) we consider 5 strata of equal weight. Since Wd follows a N (0  1) 
the strata correspond to the 20-percentile of a normal distribution. The left plot of Figure
2 represents the cumulative distribution function of Wd and shows the strata in terms of

6

percentiles of Wd. The right plot represents  in dot line  the curve E[F (W )|Wd = x] versus
P(Wd < x) parameterized by x  and the box plot represents the expectation and standard
deviations of F (W ) conditioned on each stratum. We observe that this stratiﬁcation pro-
duces an important heterogeneity of the standard deviations per stratum  which indicates
that a stratiﬁed sampling would be proﬁtable compared to a crude Monte-Carlo sampling.

Expectation of the payoff in every strata for W
 with C=90
d
1000

E[F(W)|W
=x]
d
∈ strata]
E[F(W)|W
d

900

800

700

600

d

500

]
x
=
W
|
)
W
(
F
[
E

400

300

200

100

0

−100
0

0.1

0.2

0.3

0.4

0.6

0.5
P(W
<x)
d

0.7

0.8

0.9

1

Figure 2: Left: Cdf of Wd and the deﬁnition of the strata. Right: expectation and standard
deviation of F (W ) conditioned on each stratum for a strike C = 90.

We choose the same numerical values as Kawai (2010): S0 = 100  r = 0.05  s0 = 0.30  T = 1
and d = 16. Note that the strike C of the option has a direct impact on the variability of
the strata. Indeed  the larger C  the more probable F (W ) = 0 for strata with small Wd 
and thus  the smaller λmin.

Our two main competitors are the SSAA algorithm of Etor´e and Jourdain (2010) and GAFS-
WL of Grover (2009). We did not compare to (Kawai  2010) which aims at minimizing the
computational time and not the loss considered here8. SSAA works in Kr rounds of length
Nk where  at each round  it allocates proportionally to the empirical standard deviations
computed in the previous rounds. Etor´e and Jourdain (2010) report the asymptotic consis-
tency of the algorithm whenever k
goes to 0 when k goes to inﬁnity. Since their goal is
Nk
not to obtain a ﬁnite-time performance  they do not mention how to calibrate the length
and number of rounds in practice. We choose the same parameters as in their numerical
experiments (Section 3.2.2 of (Etor´e and Jourdain  2010)) using 3 rounds. In this setting
where we know the budget n at the beginning of the algorithm  GAFS-WL pulls each arm
a√n times and then pulls at time t + 1 the arm kt+1 that maximizes wk ˆσk t
. We set a = 1.
As mentioned in Subsection 4.2  an advantage of our algorithm is that it requires a single
parameter to tune. We chose b = 1000 log(n) where 1000 is a high-probability range of the
variables (see right plot of Figure 2). Table 5 reports the performance of MC-UCB  GAFS-
WL  SSAA  and the uniform strategy  for diﬀerent values of strike C i.e.  for diﬀerent values
of λ−1
(�k wkσk)2 . The total budget is n = 105. The results are averaged
on 50000 trials. We notice that MC-UCB outperforms SSAA  the uniform strategy  and
GAFS-WL strategy. Note however that  in the case of GAFS-WL strategy  the small gain
could come from the fact that there are more parameters in MC-UCB  and that we were
thus able to adjust them (even if we kept the same parameters for the three values of C).

min and Σw 2/Σ2

Tk t

w = � wkσ2

k

In the left plot of Figure 3  we plot the rescaled regret Rnn3/2  averaged over 50000 trials 
as a function of n  where n ranges from 50 to 5000. The value of the strike is C = 120.
Again  we notice that MC-UCB performs better than Uniform and SSAA because it adapts

8In that paper  the computational costs for each stratum vary  i.e. it is faster to sample in some
strata than in others  and the aim of their paper is to minimize the global computational cost while
achieving a given performance.

7

C
60
90
120

1

λmin
6.18
15.29
744.25

Σw 2/Σ2
w

1.06
1.24
3.07

Uniform
2.52 10−2
3.32 10−2
3.56 10−2

SSAA

5.87 10−3
6.14 10−3
6.22 10−3

GAFS-WL MC-UCB
7.29 10−4
8.25 10−4
8.07 10−4
8.58 10−4
9.89 10−4
9.28 10−4

Table 1: Characteristics of the distributions (λ−1
SSAA  and MC-UCB strategies  for diﬀerent values of the strike C.

min and Σw 2/Σ2

w) and regret of the Uniform 

faster to the distributions of the strata. But it performs very similarly to GAFS-WL. In
addition  it seems that the regret of Uniform and SSAA grows faster than the rate n3/2 
whereas MC-UCB  as well as GAFS-WL  grow with this rate. The right plot focuses on the
MC-UCB algorithm and rescales the y−axis to observe the variations of its rescaled regret
more accurately. The curve grows ﬁrst and then stabilizes. This could correspond to the
two regimes discussed previously.

5

x 10

3

2.5

2

1.5

1

0.5

0
0

Rescaled Regret w.r.t. n for C=120

MC−UCB
Uniform Allocation
SSAA
GAFS−WL

Rescaled regret w.r.t. n for C=120

MC−UCB

12000

11000

10000

9000

n

R

2
/
3

n

500

1000

1500

2000

2500
n

3000

3500

4000

4500

5000

8000

7000

6000

5000
0

500

1000

1500

2000

2500
n

3000

3500

4000

4500

5000

Figure 3: Left: Rescaled regret (Rnn3/2) of the Uniform  SSAA  and MC-UCB strategies.
Right: zoom on the rescaled regret for MC-UCB that illustrates the two regimes.

6 Conclusions

which is of interest when n is large compared to a measure of disparity λ−1

We provided a ﬁnite-time analysis for stratiﬁed sampling for Monte-Carlo in the case of
min )
min of the standard

ﬁxed strata. We reported two bounds: (i) a distribution dependent bound �O(n−3/2λ−5/2
deviations (stationary regime)  and (ii) a distribution free bound in �O(n−4/3) which is of

interest when n is small compared to λ−1

min (transitory regime).

Possible directions for future work include: (i) making the MC-UCB algorithm anytime
(i.e. not requiring the knowledge of n)  (ii) investigating whether their exists an algorithm
min  and (iii) deriving distribution-dependent

with �O(n−3/2) regret without dependency on λ−1

and distribution-free lower-bounds for this problem.

Acknowledgements
We thank Andr´as Antos for several comments that helped us to improve the quality of the pa-
per. This research was partially supported by Region Nord-Pas-de-Calais Regional Council 
French ANR EXPLO-RA (ANR-08-COSI-004)  the European Communitys Seventh Frame-
work Programme (FP7/2007-2013) under grant agreement 231495 (project CompLACS) 
and by Pascal-2.

8

References

Andr´as Antos  Varun Grover  and Csaba Szepesv´ari. Active learning in heteroscedastic

noise. Theoretical Computer Science  411:2712–2728  June 2010.

B. Arouna. Adaptative monte carlo method  a variance reduction technique. Monte Carlo

Methods and Applications  10(1):1–24  2004.

J.Y. Audibert and S. Bubeck. Minimax policies for adversarial and stochastic bandits. In

22nd annual conference on learning theory  2009.

J.Y. Audibert  R. Munos  and Cs. Szepesv´ari. Exploration-exploitation tradeoﬀ using vari-
ance estimates in multi-armed bandits. Theoretical Computer Science  410(19):1876–1902 
2009.

P. Auer  N. Cesa-Bianchi  and P. Fischer. Finite-time analysis of the multiarmed bandit

problem. Machine learning  47(2):235–256  2002.

VV Buldygin and Y.V. Kozachenko. Sub-gaussian random variables. Ukrainian Mathemat-

ical Journal  32(6):483–489  1980.

A. Carpentier and R. Munos. Finite-time analysis of stratiﬁed sampling for monte carlo.

Technical Report inria-00636924  INRIA  2011.

A. Carpentier  A. Lazaric  M. Ghavamzadeh  R. Munos  and P. Auer. Upper-conﬁdence-
In Algorithmic Learning

bound algorithms for active learning in multi-armed bandits.
Theory  pages 189–203. Springer  2011.

Pierre Etor´e and Benjamin Jourdain. Adaptive optimal allocation in stratiﬁed sampling

methods. Methodol. Comput. Appl. Probab.  12(3):335–360  September 2010.

Pierre Etor´e  Gersende Fort  Benjamin Jourdain  and ´Eric Moulines. On adaptive stratiﬁ-

cation. Ann. Oper. Res.  2011. to appear.

P. Glasserman. Monte Carlo methods in ﬁnancial engineering. Springer Verlag  2004. ISBN

0387004513.

P. Glasserman  P. Heidelberger  and P. Shahabuddin. Asymptotically optimal importance
sampling and stratiﬁcation for pricing path-dependent options. Mathematical Finance  9
(2):117–152  1999.

V. Grover. Active learning and its application to heteroscedastic problems. Department of

Computing Science  Univ. of Alberta  MSc thesis  2009.

R. Kawai. Asymptotically optimal allocation of stratiﬁed sampling with adaptive vari-
ance reduction by strata. ACM Transactions on Modeling and Computer Simulation
(TOMACS)  20(2):1–17  2010. ISSN 1049-3301.

A. Maurer and M. Pontil. Empirical bernstein bounds and sample-variance penalization. In
Proceedings of the Twenty-Second Annual Conference on Learning Theory  pages 115–124 
2009.

S.I. Resnick. A probability path. Birkh¨auser  1999.
R.Y. Rubinstein and D.P. Kroese. Simulation and the Monte Carlo method. Wiley-

interscience  2008. ISBN 0470177942.

9

,Soravit Changpinyo
Kuan Liu
Fei Sha
Suriya Gunasekar
Oluwasanmi Koyejo
Joydeep Ghosh