2018,Revisiting $(\epsilon  \gamma  \tau)$-similarity learning for domain adaptation,Similarity learning is an active research area in machine learning that tackles the problem of finding a similarity function tailored to an observable data sample in order to achieve efficient classification. This learning scenario has been generally formalized by the means of a $(\epsilon  \gamma  \tau)-$good similarity learning framework in the context of supervised classification and has been shown to have strong theoretical guarantees. In this paper  we propose to extend the theoretical analysis of similarity learning to the domain adaptation setting  a particular situation occurring when the similarity is learned and then deployed on samples following different probability distributions. We give a new definition of an $(\epsilon  \gamma)-$good similarity for domain adaptation and prove several results quantifying the performance of a similarity function on a target domain after it has been trained on a source domain. We particularly show that if the source distribution dominates the target one  then principally new domain adaptation learning bounds can be proved.,Revisiting (  γ  τ)-similarity learning for

domain adaptation

Soﬁen Dhouib

Univ Lyon  INSA-Lyon  Université Claude Bernard Lyon 1  UJM-Saint Etienne  CNRS 

Inserm  CREATIS UMR 5220  U1206  F-69100  LYON  France

sofiane.dhouib@creatis.insa-lyon.fr

Ievgen Redko∗

Univ Lyon  UJM-Saint-Etienne  CNRS  Institut d Optique Graduate School Laboratoire

Hubert Curien UMR 5516  F-42023  Saint-Etienne  France

ievgen.redko@univ-st-etienne.fr

Abstract

Similarity learning is an active research area in machine learning that tackles
the problem of ﬁnding a similarity function tailored to an observable data
sample in order to achieve eﬃcient classiﬁcation. This learning scenario has
been generally formalized by the means of a (  γ  τ)−good similarity learning
framework in the context of supervised classiﬁcation and has been shown to
have strong theoretical guarantees. In this paper  we propose to extend the
theoretical analysis of similarity learning to the domain adaptation setting 
a particular situation occurring when the similarity is learned and then
deployed on samples following diﬀerent probability distributions. We give
a new deﬁnition of an (  γ)−good similarity for domain adaptation and
prove several results quantifying the performance of a similarity function
on a target domain after it has been trained on a source domain. We
particularly show that if the source distribution dominates the target one 
then principally new domain adaptation learning bounds can be proved.

Introduction

1
Many popular supervised learning algorithms rely on pairwise metrics calculated based on
the instances of a given data set in order to learn a classiﬁer. For instance  a famous family
of k-nearest neighbors algorithms [1] uses distance matrices in order to deﬁne the label of a
given test point while support vector machines [2] can be extended to handle the non-linear
classiﬁcation using kernel functions. Despite a widespread use of metrics in machine learning 
existing distances often do not capture the intrinsic geometry of data with respect to the
labels of the available data points. To tackle this problem  the emerging ﬁeld of metric
learning [3  4] (also known as similarity learning) aims to provide solutions that allow to learn
pairwise metrics explicitly from the data  thus making them tailored for the classiﬁcation or
regression problem at hand.
From the theoretical point of view  similarity learning was extensively analyzed in two seminal
papers of [5  6] based on the (  γ  τ)−good similarity framework for binary classiﬁcation.

∗The author was at CREATIS when this work was done.

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

This framework formalizes an intuitive deﬁnition of a good similarity function: given a set
of landmarks (or reasonable points) of probability mass at least τ  most of data points (a
1 −  probability mass) should be on average more similar to reasonable points of their own
class than to points of the opposite class. Based on the proposed formalization  the authors
provided performance guarantees for a resulting linear classiﬁer after mapping data into a
new feature space deﬁned via the good similarity function. We refer the interested reader to
[7] and [8] for other theoretical studies on (  γ  τ)− framework in the supervised  and to [9]
and [10]) in the semi-supervised learning cases.
While most of the work based on the (  γ  τ) framework has been done in the classical
context where training and testing data have the same distribution  in several practical
scenarios  one may want to transfer the learned similarity function from one domain  usually
called source domain  to another  related yet diﬀerent domain  called target domain. This
framework  known as transfer learning  is a notorious research topic in machine learning
nowadays [11  12  13  14] often used in situations where the target domain contains few or
no labeled instances in order to reduce the time and eﬀort needed for manual labeling or
even collecting new data. As many domain adaptation algorithms proposed in the literature
are based on metric learning [15  16  17]  a question about the theoretical guarantees of the
general similarity framework naturally arises.
In this paper  we present a theoretical study of the (  γ  τ)− framework in the domain
adaptation context where only the marginal distributions across the source and the target
domains are assumed to change while the labeling functions remain the same2. Contrary
to the previous works on the analysis of metric learning algorithms in domain adaptation
[18  19]  we aim to consider a more general setting without being attached to a particular
algorithm in order to investigate to which extent a similarity that is good for a source domain
remains good for the target domain. The obtained results are novel in two diﬀerent ways.
First  they provide a complete theoretical study of similarity learning in domain adaptation 
a study that has never appeared in the literature before. Second  they show that under
certain assumptions on the richness of the source domain with respect to the target one  the
target error can be bounded by terms that all explicitly depend on the source domain error.
The rest of the paper is organized as follows. Section 2 presents the learning setting that we
consider with some necessary deﬁnitions and notations. Section 3 introduces a generalization
of the (  γ  τ)-goodness deﬁnition used to provide a theoretical result relating the source and
target goodnesses and presents a brief comparison of the obtained bound with the related
work. Apart from the source goodness  the established inequality contains a term reﬂecting
the distance between the distributions of two domains and a worst margin term measuring
the worst error obtainable by the similarity function for some instance from the learning
sample. We analyze the obtained worst margin term in Section 4 and measure the conﬁdence
of its empirical estimation. Section 5 is dedicated to the empirical evaluations of the obtained
theoretical results. We conclude our paper in Section 6 and give several possible future
perspectives of this work.

2 Preliminaries
In order to proceed  we ﬁrst introduce the basic elements related to the (  γ  τ)−good
similarity framework. In what follows  we denote by X ⊂ Rd and Y ⊂ {−1  1} the features
and labels spaces  respectively. For any real t  t+ denotes its positive part  i.e max(t  0). As
in [6]  we deﬁne a similarity function as a pairwise function K : X × X → [−1  1]. We now
recall the deﬁnition of the (  γ  τ)-goodness with hinge loss.
Deﬁnition 1 (Balcan et. al. 2008). A similarity function K is (  γ  τ)-good in hinge loss
for problem (distribution) P if there exists a (probabilistic) indicator function R of a set of
“reasonable points" such that:

#

"(cid:18)
(cid:19)
1 − y.g(x)
x0∼P [R(x0)] ≥ τ 
P

E

(x y)∼P

γ

+

≤  

(1)

(2)

2This assumption leads to a setting often called covariate shift problem in domain adaptation.

2

where g(x) =

E

(x0 y0)∼P

[y0K(x  x0)|R(x0)].

In this deﬁnition   is an upper bound for the expected hinge loss over all the margins g(x) 
every margin being the average signed similarity of an instance to reasonable points deﬁned
by R. To control the loss sensitivity to the margin  a division by 0 < γ ≤ 1 is applied.
Following this deﬁnition  the authors of [6] prove a theorem that guarantees the existence of
a linear separator in a new feature space deﬁned via an (  γ  τ)−good similarity function  a
result that is stated by the following theorem.
Theorem 1 (Balcan et. al. 2008). Let K be an (  γ  τ)−good similarity function in hinge
loss for a learning problem P. For any 1 > 0 and 0 < δ < γ1
n} be a
(potentially unlabeled) sample of size n = 2
Consider the mapping:

(cid:17) of landmarks drawn from P.

(cid:1)(cid:16)1 + 16

τ log(cid:0) 2

4   let S = {x0

1  ...  x0

(1γ)2

δ

Then with a probability at least 1 − δ over the draw of S  there exists β ∈ Rn such that:

φS : X → Rn

x 7→ (K(x  x0

n)).

1)  ...  K(x  x0
#

!

(cid:10)β  φS(x)(cid:11)

" 

≤  + 1.

E

(x y)∼P

1 −

γ

+

(3)

In other words  the induced distribution φS(P) in Rn has a linear separator achieving hinge
loss at most  + 1 at margin γ.
One can see this theorem as a variation of the kernel trick used in the SVM algorithm.
Indeed  if K is a kernel function and if τ = 1  the expected loss in Equation (3) becomes the
non-regularized loss of an SVM deﬁned via kernel K. The authors furthermore derive an
algorithm from this theorem that minimizes the empirical version of (3)  which boils down
to a linear programming problem that can be solved eﬃciently.
3 (  γ)−good similarity learning for domain adaptation
In this section  we introduce the main contributions of our paper. We start by giving a
deﬁnition of (  γ)-goodness with an arbitrary distribution of landmarks  and then propose a
generalization bound that relates the goodness of the same similarity function learned on
the source and target domains.

3.1 Problem setup
For the considered problem  we assume to have access to samples S and T drawn from
source and target probability distributions S and T   respectively. In the context of domain
adaptation  S ⊂ (X × Y)m is labeled whereas T can be partially or totally unlabeled. In the
rest of the paper  we suppose that the labeling is deterministic  meaning that there exists a
labeling function fS (resp. fT ) such that for every (x  y) in the source domain (resp. in the
target domain)  y = fS(x) (resp. y = fT (x)). Hence  we replace every (x  y) ∼ P by writing
simply x ∼ P for all probability distributions considered below. Moreover  since we assume
that

[y|x]  then we have fS = fT .

[y|x] = P

P

(x y)∼S

(x y)∼T

As hinted in [6  Note 2  Theorem 14]  the instances and landmarks can be potentially drawn
from diﬀerent distributions. Hence  we propose a modiﬁcation of Deﬁnition 1 given as follows.
Deﬁnition 2. A similarity function K is (  γ)-good in hinge loss for problem (P R) (where
P is the data distribution whereas R is the landmarks distribution) if:

E
x∼P

where gR(x) = E

x0∼R [y0K(x  x0)].

#

(cid:19)

+

≤  

"(cid:18)

1 − y.gR(x)

γ

3

x∼R [x ∈ A] = P

This is a generalization of Deﬁnition 1  and the two coincide when we consider the distribution
x∼P [x ∈ A|R(x) = 1] for all measurable sets A. As for parameter
R deﬁned by P
x∼P [x ∈ suppR] since in this case  we have
τ  it can be seen as an upper bound for P
suppR ⊂ {R(x) = 1}. This deﬁnition captures the intuition often used to design domain
adaptation algorithms as R can be thought of as a “universal landmarks domain" which
is independent of the source or target domains. In the case of sentiment classiﬁcation  for
example  it might correspond to negative or positive vocabulary used to express one’s opinion
independently of the type of the concerned product.
In the rest of the paper  we use the following notations for any data distribution P and
landmark distribution Q. We denote the goodness of K for problem (P Q) by

For simplicity  we further denote by lγ the γ-scaled hinge loss function deﬁned by:

#

(cid:19)

.

+

"(cid:18)
(cid:18)

EP Q(K) := E
x∼P

1 − y.gQ(x)

γ

(cid:19)

lγ : x 7→

1 − x
γ

.

+

We let µ be a probability distribution that dominates all the other probability distributions
used afterwards. In addition  MP Q(K) stands for the worst margin achieved by an element
of x ∈ suppP associated with landmark distribution Q  i.e:

MP Q(K) := sup
x∈supp P

lγ(ygQ(x)).

Note that since K takes values in [−1  1] (or even if we only assume that K is bounded) 
ygQ (x) is also bounded and consequently lγ(ygQ (x)) is bounded thanks to the continuity
of lγ. This ensures that MP Q(K) is ﬁnite. Finally  if B is a boolean expression  then
[B] := 1B is an indicator of the set on which B holds (Iverson bracket notation).

3.2 Relating the source and target goodnesses
Given a similarity function that is (  γ)-good in hinge loss for problem (S  R1)  our goal
is to bound its goodness on the target set for problem (T  R2)  where R1 and R2 are not
supposed to be equal.

3.2.1 Shared landmarks distribution
In order to prepare for a more general result that relates the goodness of a similarity K for
problems (S  R1) and (T   R2)  we ﬁrst provide a preparatory result that considers the same
landmark distribution R = R1 = R2. This result is given by the following lemma3.
Lemma 1 (same landmarks). Let K be an (  γ)-good similarity for problem (S R). Then
K is ( + 0  γ)-good for problem (T  R)  where:

with d1+ γ(T  S) = E
x∼µ
results holds with

where dχ2

+ γ(T  S) = E
x∼S

dµ

dµ − dS

(cid:20)(cid:16) dT
(cid:17)
0 =q
(cid:20)(cid:16)(cid:0) dT
dS − 1(cid:1)

+

0 = d1+ γ(T  S)Mµ R(K)

(cid:21)

√
(cid:21)
(cid:17)2
+ γ(T  S)MS R(K)
dχ2
[ygR (x) < γ]

.

+

 

[ygR (x) < γ]

. Moreover  if T (cid:28) S then the obtained

Several observations can be made based on these results. First  we note that the expectation
in both divergence terms is taken only on the support of the hinge loss  i.e for instances having
a signed margin smaller than γ  making these terms problem dependent. This dependence is

3Due to the limited space  all proofs are provided in the Supplementary material.

4

quite important as it allows to claim that the presented result can be informative in practice.
Second  the obtained bounds both contain the term Mµ R(K) which stands for the worst
margin achieved by K on some instance of supp µ. In the case of the SVM  this term is
analogous to the largest slack variable associated to an instance drawn from the dominating
measure µ. For several choices of µ  this term can be diﬃcult to control  as we can estimate
it only by observing data drawn from S. This limitation is tackled by assuming that S
dominates T thus motivating the bounds with χ2 distance. These latter clearly show the
beneﬁt of assuming T (cid:28) S: the distance term in the bound is multiplied by
 meaning
that having a similarity function achieving a low error on the source domain can leverage
the diﬀerence between the domains’ distributions. Note that the assumption T (cid:28) S is
quite common in the domain adaptation literature and has already been used in [20]. As
mentioned by the authors  it roughly means that the source domain is richer than the target
one  an assumption that is quite reasonable in practice.

√

3.2.2 Diﬀerent landmarks case
We now turn our attention to a more general case where the landmarks distributions vary
across two domains. To this end  we assume that a similarity function K is (  γ)-good for
(S R1). Given these assumptions  our goal now is to provide a learning guaranty for the
goodness of K for the (T  R2) learning problem. To proceed  we ﬁrst rewrite the diﬀerence
between ET  R2(K) and ES R1(K) as follows:

ET  R2(K) − ES R1(K) = ET  R1(K) − ES R1(K) + ET  R2(K) − ET  R1(K).

0 =q

√
+ γ(T  S)Mµ R(K)
dχ2

By analyzing the obtained expression  we note that the diﬀerence between the ﬁrst two
terms can be bounded using Lemma 1 as ET  R1(K) − ES R1(K) =  + 0 −  = 0 where
 when T (cid:28) S and d1+ γ(T  S)Mµ R2(K) otherwise. Con-
sequently  we further focus solely on the last two terms and  similar to the previous case 
provide a result based on both the L1 and χ2 distances. We prove the following theorem.
Theorem 2. Let K be an (  γ)-good similarity for problem (S R1). Then K is (+0+00  γ)-
γ d1(R1 R2) and 0 = d1+ γ(T  S)Mµ R2(K)  where
good for problem (T  R2)  with 00 = 1
d1(R1 R2) = E
. Moreover  if T (cid:28) S  then the obtained result holds with
x0∼µ

h(cid:12)(cid:12)(cid:12) dR1

(cid:12)(cid:12)(cid:12)i

0 =q

dµ − dR2
dµ
√

+ γ(T  S)Mµ R(K)
dχ2

.

The obtained result suggests that it is better to consider the same landmark distribution
R = R1 = R2 for the two domains  as this assumption minimizes the bound by setting 00 =
γ d1(R1 R2) = 0. This conclusion is rather intuitive: in many domain adaptation algorithms
1
the source and target domains are aligned using a shared set of invariant components and
landmarks can be seen as invariant points allowing to adapt the similarity measure eﬃciently
across domains. For this reason  we focus on the case of a shared landmark distribution in
the rest of the paper.

3.3 Comparison with other existing results
We now brieﬂy compare the obtained results with some previous related works. To this
end  we note that the vast majority of domain adaptation results [21  22  23  18] have the
following form

lT (h  fT ) ≤ lS(h  fS) + d(S T ) + λ 

(4)
x∼D [l(h(x)  fD(x))|] is the error function deﬁned over probability distribu-
where lD(h  fD) := E
tion D for hypothesis and labeling functions h  fD : X → Y with loss function l : Y×Y → R+;
d(· ·) is a divergence measure between two domains and λ is the non-estimable term related
to diﬃculty of the adaptation task. From (4)  we note that our result with χ2 distance
drastically diﬀers from the traditional domain adaptation bounds as  contrary to them  it
suggests that source error directly impacts all the terms in the bound. Indeed  the inequality
in (4) prompts us to minimize both the source error lS and the divergence term d(S T )
assuming that λ is small while our result shows that source error given by the goodness

5

of the similarity function can partially leverage the divergence between the two domains
as it multiplies the latter. To the best of our knowledge  the only two other results that
have this multiplicative dependence between the source error and the divergence term are
[24] and [25]  where the variations of Rényi divergence were considered. Contrary to their
contributions  our bound involves a divergence term that is restricted to the [y.gR (x) < γ]
set making it intrinsically linked to the considered hypothesis class. Furthermore  we note
that the bounds proposed in [25] involve a non-estimable term that  similar to λ in (4) is
assumed to be small while the worst margin term presented in our result is subject to the
analysis provided in the next section.

4 Analysis of the worst margin term
As the worst margin term Mµ R(K) is present in both bounds obtained in the previous
section  we proceed to its analysis below. It tells us that if there is at least one instance
from the source distribution (or from a distribution dominating it) that has a high loss  then
the deviation between the target error and the source error is expected to be large. In what
follows  we provide an analysis of this term showing ﬁrst that it can be bounded in terms of
γ and then presenting a guarantee allowing its ﬁnite sample approximation.

4.1 A simple bound for the worst margin
A ﬁrst simple bound for the worst margin term can be obtained as follows:

(cid:18)

lγ(ygR(x)) =

inf

1 − 1

(cid:19)
x0∼R [yy0K(x  x0)]
E

γ

x∈supp µ

+

(cid:19)
≤ 2

+

.

γ

y.gR(x)
≤ 1 + 1

γ

Mµ R(K) = sup
x∈supp µ
1 − 1

(cid:18)

=

γ

inf

x∈supp µ

The last inequality comes from the fact that K : X × X → [−1  1] and that 0 < γ ≤ 1.
Based on the obtained expression  we note from Lemma 1 that the target goodness can now
be bounded in terms of both values that characterize the similarity function in the source
domain. On the other hand  replacing the worst margin term in the bound by constant
γ prevents us from taking it into account when attempting to design a new adaptation
algorithm based on the obtained bounds. In this case  it can be useful to estimate this term
empirically from the observed data sample by taking the empirical maximum for the source
instances and the empirical mean for the landmarks.

r  y0

1  y0

1)  . . .   (x0

4.2 An empirical estimation of the worst margin
We intend to measure our conﬁdence in the empirical estimation of the worst margin term
by bounding the deviation between the real worst margin term and its empirical counterpart.
To this end  we suppose having access to a labeled data sample S = {(x1  y1)  ...  (xm  ym)} ⊂
(X × Y)m drawn from S  inducing an empirical distribution ˆS. Similarly  we deﬁne a sample
SR = {(x0
r)} and the corresponding empirical distribution ˆR. As the notion
of the Rademacher complexity is used to establish our result  we give its deﬁnition below.
Deﬁnition 3. Let G be a family of mappings from X to R and P be a probability distribution
on X . The Rademacher complexity of G w.r.t. P and to a sample size n is deﬁned as
Radn (G) = E
S∼P n
variables in {−1  +1} called Rademacher random variables and S = {s1  ...  sn}.
We can now prove the following result.
Theorem 3. Let K be a similarity function deﬁned on a feature space X . Let MS R(K)
denote its worst performance associated to loss function lγ and achieved by an example drawn
from S  where R is the landmarks distribution. Assume that S dominates T and that the
cumulative distribution function Flγ of the loss function associated with S and ˆR is k times
diﬀerentiable at MS  ˆR(K)  and that k > 0 is the minimum integer such that F
6= 0. Then

i=1 σig(si)(cid:3)(cid:3)   where σi are independent uniform random
Pn

(cid:2)supg∈G 1

(cid:2)Eσ

n

(k)
lγ

6

for all α > 1  r ≥ 1  there exists m0 ≥ 1 such that for all m ≥ m0  we have with probability
at least 1 − δ:

s

2

log(cid:0) 2

δ

(cid:1)

(−1)k+1 log(cid:0) 2α

δ

(cid:1) k!

 1

k

 

+

MS R(K) ≤ M ˆS  ˆR(K) + 2

Radr (H1(K)) + 1
γ2

r

γ

F

(k)
lγ

(MS  ˆR(K))m
where H1(K) is the hypothesis class deﬁned by H1(K) = {x0 7→ K(x  x0)  x ∈ suppS}.
This theorem shows that under certain conditions  the empirical maximum is guaranteed to
converge in probability to the real supremum of the distribution’s support. The convergence
rate depends heavily on the complexity of the similarity function search space represented
by the Rademacher complexity term and on the regularity of the loss distribution function
reﬂected by the m− 1
k term. This last term dominates the convergence rate when k > 2  and
−
we have in general a convergence rate that is O(m
Due to the bound’s dependence on the regularity of Flγ  knowing this cumulative distribution
function is necessary for an explicit computation of the bound. Furthermore  in the case when
k increases  it implies that we may need more data in order to have a truthful estimation
of the function’s regularity. Thus  this quantity may become non estimable  which goes in
line with several other theoretical contributions [18  21  22  23] where the learning bound
includes an a priori non estimable term.

max{2 k} ).

1

5 Experiments

The aim of this section is to empirically illustrate the usefulness of the bounds of Lemma 1
on synthetic data set. In what follows  we restrict the similarity search space to the class of
bilinear similarity functions parametrized by a matrix A ∈ Rd×d  where d is the dimension
of the feature space  i.e K(x  x0) = KA(x  x0) = hx  Ax0i. This class has been studied in
[7] in the context of (  γ  τ)−goodness and has been shown to beneﬁt from generalization
guarantees established based on the algorithmic stability theory [26].

Data generation We generate the source domain data as a set of 500 two-dimensional
points drawn from a mixture of two Gaussian distributions with the same isotropic covariance
matrices σ2I2 and mixing coeﬃcients  where σ is the chosen standard deviation4. Each
distribution represents one of the two classes 1 and −1 centered at (1  1) and (−1 −1) 
respectively. The target data is generated from the same distribution as the source data by
rotating clusters’ centers by angles varying from 0◦ to 90◦. Examples of the obtained data
samples are given in Figure 1. We note that increasing the angle of rotation leads to an
increasing divergence between the two domains.

Algorithmic implementation In accordance with Lemma 1  we consider two cases
depending on whether T (cid:28) S or not and for both we train a similarity function on the
generated data sample and search for a weighting function w : X → R such that the bounds
are minimized. Note that from theoretical point of view  the support of both distributions is
R2  but in practice the regions that are far from the cluster centers rarely have data points 
so the support can be considered in a limited neighborhood around the centers. For both
cases  we estimate the divergence term directly from the analytic expression of density of
the generating distribution using by calculating a two-dimensional integral.
As in [7]  we consider all of the source sample points as landmarks  and denote by ˆSW the
weighted sample empirical distribution deﬁned on SW = {wixi}m
i=1 where W := (w1  . . .   wm).
Depending on the assumption considered  we aim to solve the following optimization problem:
(5)

J(W  M)  s.t. M ≥ lγ(yi.gˆSW (xi))  ∀i ∈ {1  ...  m} 

min
W∈Rm
M≥0

4In the presented results  we set σ = 0.5 and provide the same results for other values of σ in the

Supplementary material.

7

Figure 1: Generated data for (left) 30◦  (middle) 60◦  (right) 90◦ degrees rotation.

Figure 2: Target goodness as a function of the rotation degree when (left) T 6(cid:28) S and
(middle) T (cid:28) S. For both cases  the similarity function is obtained by solving (5). (right)
Divergence values for both cases considered. We can observe that rotating the centers of the
generating distribution increases both L1 and χ2 divergences between the samples.

where

J(W  M) =

( E ˆS  ˆSW

E ˆS  ˆSW

(KA) +q

+ γ(T  S)ME ˆS  ˆSW
dχ2

(KA) + d1+ γ(T  S)M 

(KA) 

if T (cid:28) S 
otherwise.

Results
In Figure 2  we plot the goodness of the similarity function on the target data set
before and after adaptation  i.e after solving the minimization problems described above.
The results are computed for a rotation angle θ between 0◦ and 90◦  and after averaging over
30 draws of target samples. From this ﬁgure  we can see that the behaviour of the target
goodness remains in line with the obtained theoretical results. In both cases considered 
optimizing the bounds improves the performance over the "No adaptation" baseline. As
expected  in the case of T (cid:28) S  the target goodness remains lower than when no absolute
continuity is assumed due to the minimization of the source error and the worst margin term
that impact the entire bound on the target goodness. Note that in the performed empirical
evaluations  the divergence term remains constant for every considered rotation angle and
is used only as a trade-oﬀ parameter. This choice is deliberate as our goal is to show that
minimizing the worst margin term and the source error can partially leverage the discrepancy
between the two domains. Obviously  the obtained results can be improved by adding a
term that properly aligns the two domains distributions through instance-reweighting or
feature transformation.

6 Conclusions and future perspectives
In this paper  we provided general theoretical guarantees for the similarity learning framework
in the domain adaptation context. The obtained results contain a divergence term between
the two domains distributions that naturally appears when bounding the deviation between
the same similarity’s performance on them and a worst margin term measuring the worst
error obtainable by the similarity function for some instance from the learning sample.
Contrary to the previous generalization bounds established for domain adaptation problem 
we showed that when the source distribution dominates the target one  the bound can be
improved via a
 factor.We further analyzed the worst margin term and showed that its

√

8

convergence to the true value depends on the complexity of the search space of the similarity
function  as well as on the regularity of the hinge loss’s cumulative distribution function at
a neighborhood of its maximum (worst) value. In order to validate the usefulness of the
proposed results  we showed empirically that the minimization of the terms in appearing
in the obtained bounds allows to obtain an improved performance over the ”no adaptation”
baseline without explicitly minimizing the divergence term.
In the future  our work can be extended in multiple directions. First  in our new deﬁnition
of the (  γ)−goodness  the landmark distribution is assumed to be diﬀerent from that used
to generate source and target data samples and thus a question about the existence of a
landmark distribution that leads to tighter bounds naturally arises. Second  it would be
interesting to explore the semi-supervised scenario where the landmarks used to learn a
similarity function are drawn from the source and target distributions at the same time.
In this case  one can expect to obtain a result showing that the goodness of the similarity
learned with source landmarks only is worse than that learned on a mixture distribution.

Acknowledgements
This work beneﬁted from the support provided by the CNRS funding from the Déﬁ Imag’In.

References
[1] T. Cover and P. Hart. Nearest neighbor pattern classiﬁcation. IEEE Transactions Information

Theory  13(1):21–27  2006.

[2] Bernhard E. Boser  Isabelle M. Guyon  and Vladimir N. Vapnik. A training algorithm for

optimal margin classiﬁers. In COLT  pages 144–152  1992.

[3] Aurélien Bellet  Amaury Habrard  and Marc Sebban. A survey on metric learning for feature

vectors and structured data. arXiv preprint arXiv:1306.6709  2013.

[4] Brian Kulis. Metric learning: A survey. Foundations and Trends in Machine Learning 

5(4):287–364  2013.

[5] Maria-Florina Balcan  Avrim Blum  and Nathan Srebro. A theory of learning with similarity

functions. Machine Learning  72(1-2):89–112  2008.

[6] Maria-Florina Balcan  Avrim Blum  and Nathan Srebro. Improved guarantees for learning via

similarity functions. In COLT  pages 287–298  2008.

[7] Aurélien Bellet  Amaury Habrard  and Marc Sebban. Similarity learning for provably accurate

sparse linear classiﬁcation. In ICML  2012.

[8] Zheng-Chu Guo and Yiming Ying. Guaranteed classiﬁcation via regularized similarity learning.

Neural Computation  26(3):497–522  2014.

[9] Maria-Irina Nicolae  Éric Gaussier  Amaury Habrard  and Marc Sebban. Joint semi-supervised

similarity learning for linear classiﬁcation. In ECML/PKDD  pages 594–609  2015.

[10] Nicolae Irina  Marc Sebban  Amaury Habrard  Eric Gaussier  and Massih-Reza Amini. Algo-
rithmic Robustness for Semi-Supervised (  γ  τ )-Good Metric Learning. In ICONIP  page 10 
2015.

[11] Sinno Jialin Pan and Qiang Yang. A survey on transfer learning. IEEE Transactions on

Knowledge and Data Engineering  22(10):1345–1359  2010.

[12] Anna Margolis. A literature review on domain adaptation with unlabeled data  2011.
[13] Vishal M. Patel  Raghuraman Gopalan  Ruonan Li  and Rama Chellappa. Visual domain
adaptation: A survey of recent advances. IEEE Signal Processing Magazine  32(3):53–69  2015.
[14] Karl Weiss  Taghi M. Khoshgoftaar  and Ding Wang. A survey of transfer learning. Journal of

Big Data  3(1)  2016.

[15] B. Geng  D. Tao  and C. Xu. Daml: Domain adaptation metric learning. IEEE Transactions

on Image Processing  20(10):2980–2989  2011.

9

[16] B. Kulis  K. Saenko  and T. Darrell. What you saw is not what you get: Domain adaptation

using asymmetric kernel transforms. In CVPR  pages 1785–1792  2011.

[17] Bin Cao  Xiaochuan Ni  Jian-Tao Sun  Gang Wang  and Qiang Yang. Distance metric learning

under covariate shift. In IJCAI  pages 1204–1210  2011.

[18] Emilie Morvant  Amaury Habrard  and Stéphane Ayache. Parsimonious unsupervised and
semi-supervised domain adaptation with good similarity functions. Knowledge and Information
Systems  33(2):309–349  2012.

[19] Michaël Perrot and Amaury Habrard. A theoretical analysis of metric hypothesis transfer

learning. In ICML  pages 1708–1707  2015.

[20] Kun Zhang  Bernhard Schölkopf  Krikamol Muandet  and Zhikun Wang. Domain adaptation

under target and conditional shift. In ICML  pages 819–827  2013.

[21] Shai Ben-David  John Blitzer  Koby Crammer  Alex Kulesza  Fernando Pereira  and Jen-
nifer Wortman Vaughan. A theory of learning from diﬀerent domains. Machine Learning 
79(1-2):151–175  2010.

[22] Yishay Mansour  Mehryar Mohri  and Afshin Rostamizadeh. Domain adaptation: Learning

bounds and algorithms. In COLT  2009.

[23] Corinna Cortes and Mehryar Mohri. Domain adaptation in regression. In ALT  2011.
[24] Yishay Mansour  Mehryar Mohri  and Afshin Rostamizadeh. Multiple source adaptation and

the rÉnyi divergence. In UAI  pages 367–374  2009.

[25] Pascal Germain  Amaury Habrard  François Laviolette  and Emilie Morvant. A new pac-bayesian

perspective on domain adaptation. In ICML  volume 48  pages 859–868  2016.

[26] Olivier Bousquet and André Elisseeﬀ. Stability and generalization. J. Mach. Learn. Res. 

2:499–526  March 2002.

10

,Sofiane Dhouib
Ievgen Redko