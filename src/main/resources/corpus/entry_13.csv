2018,3D Steerable CNNs: Learning Rotationally Equivariant Features in Volumetric Data,We present a convolutional network that is equivariant to rigid body motions. The model uses scalar-  vector-  and tensor fields over 3D Euclidean space to represent data  and equivariant convolutions to map between such representations. These SE(3)-equivariant convolutions utilize kernels which are parameterized as a linear combination of a complete steerable kernel basis  which is derived analytically in this paper. We prove that equivariant convolutions are the most general equivariant linear maps between fields over R^3. Our experimental results confirm the effectiveness of 3D Steerable CNNs for the problem of amino acid propensity prediction and protein structure classification  both of which have inherent SE(3) symmetry.,3D Steerable CNNs: Learning Rotationally
Equivariant Features in Volumetric Data

Maurice Weiler*

University of Amsterdam

m.weiler@uva.nl

Mario Geiger*

EPFL

mario.geiger@epfl.ch

Max Welling

Wouter Boomsma

University of Amsterdam  CIFAR 

University of Copenhagen

Qualcomm AI Research

m.welling@uva.nl

wb@di.ku.dk

Taco Cohen

Qualcomm AI Research
taco.cohen@gmail.com

Abstract

We present a convolutional network that is equivariant to rigid body motions.
The model uses scalar-  vector-  and tensor ﬁelds over 3D Euclidean space to
represent data  and equivariant convolutions to map between such representations.
These SE(3)-equivariant convolutions utilize kernels which are parameterized
as a linear combination of a complete steerable kernel basis  which is derived
analytically in this paper. We prove that equivariant convolutions are the most
general equivariant linear maps between ﬁelds over R3. Our experimental results
conﬁrm the effectiveness of 3D Steerable CNNs for the problem of amino acid
propensity prediction and protein structure classiﬁcation  both of which have
inherent SE(3) symmetry.

Introduction

1
Increasingly  machine learning techniques are being applied in the natural sciences. Many problems
in this domain  such as the analysis of protein structure  exhibit exact or approximate symmetries.
It has long been understood that the equations that deﬁne a model or natural law should respect
the symmetries of the system under study  and that knowledge of symmetries provides a powerful
constraint on the space of admissible models. Indeed  in theoretical physics  this idea is enshrined
as a fundamental principle  known as Einstein’s principle of general covariance. Machine learning 
which is  like physics  concerned with the induction of predictive models  is no different: our models
must respect known symmetries in order to produce physically meaningful results.
A lot of recent work  reviewed in Sec. 2  has focused on the problem of developing equivariant
networks  which respect some known symmetry. In this paper  we develop the theory of SE(3)-
equivariant networks. This is far from trivial  because SE(3) is both non-commutative and non-
compact. Nevertheless  at run-time  all that is required to make a 3D convolution equivariant using our
method  is to parameterize the convolution kernel as a linear combination of pre-computed steerable
basis kernels. Hence  the 3D Steerable CNN incorporates equivariance to symmetry transformations
without deviating far from current engineering best practices.
The architectures presented here fall within the framework of Steerable G-CNNs [8  10  40  45] 
which represent their input as ﬁelds over a homogeneous space (R3 in this case)  and use steerable

* Equal Contribution. MG initiated the project  derived the kernel space constraint  wrote the ﬁrst network
implementation and ran the Shrec17 experiment. MW solved the kernel constraint analytically  designed the
anti-aliased kernel sampling in discrete space and coded / ran many of the CATH experiments.

Source code is available at https://github.com/mariogeiger/se3cnn.

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

ﬁlters [15  37] to map between such representations. In this paper  the convolution kernel is modeled
as a tensor ﬁeld satisfying an equivariance constraint  from which steerable ﬁlters arise automatically.
We evaluate the 3D Steerable CNN on two challenging problems: prediction of amino acid preferences
from atomic environments  and classiﬁcation of protein structure. We show that a 3D Steerable CNN
improves upon state of the art performance on the former task. For the latter task  we introduce a
new and challenging dataset  and show that the 3D Steerable CNN consistently outperforms a strong
CNN baseline over a wide range of trainingset sizes.

2 Related Work
There is a rapidly growing body of work on neural networks that are equivariant to some group
of symmetries [3  9  10  12  19  20  28  30–32  36  42  46]. At a high level  these models can
be categorized along two axes: the group of symmetries they are equivariant to  and the type of
geometrical features they use [8]. The class of regular G-CNNs represents the input signal in terms of
scalar ﬁelds on a group G (e.g. SE(3)) or homogeneous space G/H (e.g. R3 = SE(3)/ SO(3)) and
maps between feature spaces of consecutive layers via group convolutions [9  29]. Regular G-CNNs
can be seen as a special case of steerable (or induced) G-CNNs which represent features in terms
of more general ﬁelds over a homogeneous space [8  10  27  30  40]. The models described in this
paper are of the steerable kind  since they use general ﬁelds over R3. These ﬁelds typically consist of
multiple independently transforming geometrical quantities (vectors  tensors  etc.)  and can thus be
seen as a formalization of the idea of convolutional capsules [18  34].
Regular 3D G-CNNs operating on voxelized data via group convolutions were proposed in [43  44].
These architectures were shown to achieve superior data efﬁciency over conventional 3D CNNs
in tasks like medical imaging and 3D model recognition. In contrast to 3D Steerable CNNs  both
networks are equivariant to certain discrete rotations only.
The most closely related works achieving full SE(3) equivariance are the Tensor Field Network
(TFN) [40] and the N-Body networks (NBNs) [26]. The main difference between 3D Steerable
CNNs and both TFN and NBN is that the latter work on irregular point clouds  whereas our model
operates on regular 3D grids. Point clouds are more general  but regular grids can be processed
more efﬁciently on current hardware. The second difference is that whereas the TFN and NBN use
Clebsch-Gordan coefﬁcients to parameterize the network  we simply parameterize the convolution
kernel as a linear combination of steerable basis ﬁlters. Clebsch-Gordan coefﬁcient tensors have 6
indices  and depend on various phase and normalization conventions  making them tricky to work
with. Our implementation requires only a very minimal change from the conventional 3D CNN.
Speciﬁcally  we compute conventional 3D convolutions with ﬁlters that are a linear combination of
pre-computed basis ﬁlters. Further  in contrast to TFN  we derive this ﬁlter basis directly from an
equivariance constraint and can therefore prove its completeness.
The two dimensional analog of our work is the SE(2) equivariant harmonic network [45]. The
harmonic network and 3D steerable CNN use features that transform under irreducible representations
of SO(2) resp. SO(3)  and use ﬁlters related to the circular resp. spherical harmonics.
SE(3) equivariant models were already investigated in classical computer vision and signal processing.
In [33  38]  a spherical tensor algebra was utilized to expand signals in terms of spherical tensor
ﬁelds. In contrast to 3D Steerable CNNs  this expansion is ﬁxed and not learned. Similar approaches
were used for detection and crossing preserving enhancement of ﬁbrous structures in volumetric
biomedical images [13  21  22].

3 Convolutional feature spaces as ﬁelds
A convolutional network produces a stack of Kn feature maps fk in each layer n. In 3D  we can
model the feature maps as (well-behaved) functions fk : R3 → R. Written another way  we have a
map f : R3 → RKn that assigns to each position x a feature vector f (x) that lives in what we call
the ﬁber RKn at x. In practice f will have compact support  meaning that f (x) = 0 outside of some
compact domain Ω ∈ R3. We thus deﬁne the feature space Fn as the vector space of continuous
maps from R3 to RKn with compact support.
In this paper  we impose additional structure on the ﬁbers. Speciﬁcally  we assume the ﬁber consists
of a number of geometrical quantities  such as scalars  vectors  and tensors  stacked into a single

2

Kn-dimensional vector. The assignment of such a geometrical quantity to each point in space is
called a ﬁeld. Thus  the feature spaces consist of a number of ﬁelds  each of which consists of a
number of channels (dimensions).
Before deriving SE(3)-equivariant networks in Sec. 4 we discuss the transformation properties of
ﬁelds and the kinds of ﬁelds we use in 3D Steerable CNNs.

3.1 Fields  Transformations and Disentangling
What makes a geometrical quantity (e.g. a vector) anything more than an arbitrary grouping of feature
channels? The answer is that under rigid body motions  information ﬂows within the channels of
a single geometrical quantity  but not between different quantities. This idea is known as Weyl’s
principle  and has been proposed as a way of formalizing the notion of disentangling [6  23].

As an example  consider the three-dimensional
vector ﬁeld over R3  shown in Figure 1. At each
point x ∈ R3 there is a vector f (x) of dimension
K = 3. If the ﬁeld is translated by t  each vector
x − t would simply move to a new (translated)
position x. When the ﬁeld is rotated  however 
two things happen: the vector at r−1x is moved
to a new (rotated) position x  and each vector
is itself rotated by a 3 × 3 rotation matrix ρ(r).
Figure 1: To transform a vector ﬁeld (L) by a 90◦
Thus  the rotation operator π(r) for vector ﬁelds
is deﬁned as [π(r)f ](x) := ρ(r)f (r−1x). No-
rotation g  ﬁrst move each arrow to its new position (C) 
tice that in order to rotate this ﬁeld  we need all
keeping its orientation the same  then rotate the vector
itself (R). This is described by the induced representation
three channels: we cannot rotate each channel
SO(3) ρ  where ρ(g) is a 3 × 3 rotation matrix
π = IndSE(2)
independently  because ρ introduces a functional
dependency between them. For contrast  con-
that mixes the three coordinate channels.
sider the common situation where in the input
space we have an RGB image with K = 3 channels. Then f (x) ∈ R3  and the rotation can be
described using the same formula ρ(r)f (r−1x) if we choose ρ(r) = I3 to be the 3× 3 identity matrix
for all r. Since ρ(r) is diagonal for all r  the channels do not get mixed  and so in geometrical terms 
we would describe this feature space as consisting of three scalar ﬁelds  not a 3D vector ﬁeld. The
RGB channels each have an independent physical meaning  while the x and y coordinate channels of
a vector do not.
The RGB and 3D-vector cases constitute two examples of ﬁelds  each one determined by a different
choice of ρ. As one might guess  there is a one-to-one correspondence between the type of ﬁeld and
the type of transformation law (group representation) ρ. Hence  we can speak of a ρ-ﬁeld.
So far  we have concentrated on the behaviour of a ﬁeld under rotations and translations separately.
A 3D rigid body motion g ∈ SE(3) can always be decomposed into a rotation r ∈ SO(3) and a
translation t ∈ R3  written as g = tr. So the transformation law for a ρ-ﬁeld is given by the formula
(1)

[π(tr)f ](x) := ρ(r)f (r−1(x − t)).

The map π is known as the representation of SE(3) induced by the representation ρ of SO(3)  which
is denoted by π = IndSE(3)

SO(3) ρ. For more information on induced representations  see [5  8  17].

Irreducible SO(3) features

3.2
We have seen that there is a correspondence between the type of ﬁeld and the type of inducing
representation ρ  which describes the rotation behaviour of a single ﬁber. To get a better understanding
of the space of possible ﬁelds  we will now deﬁne precisely what it means to be a representation of
SO(3)  and explain how any such representation can be constructed from elementary building blocks
called irreducible representations.
A group representation ρ assigns to each element in the group an invertible n × n matrix. Here n is
the dimension of the representation  which can be any positive integer (or even inﬁnite). For ρ to be
called a representation of G  it has to satisfy ρ(gg(cid:48)) = ρ(g)ρ(g(cid:48))  where gg(cid:48) denotes the composition
of two transformations g  g(cid:48) ∈ G  and ρ(g)ρ(g(cid:48)) denotes matrix multiplication.

3

(cid:34) 2(cid:77)

(cid:35)

ρ(r) = Q−1

Dl(r)

Q 

(2)

To make this more concrete  and to introduce the concept of an irreducible representation  we consider
the classical example of a rank-2 tensor (i.e. matrix). A 3 × 3 matrix A transforms under rotations
as A (cid:55)→ R(r)AR(r)T   where R(r) is the 3 × 3 rotation matrix representation of the abstract group
element r ∈ SO(3). This can be written in matrix-vector form using the Kronecker / tensor product:
vec(A) (cid:55)→ [R(r) ⊗ R(r)] vec(A) ≡ ρ(r) vec(A). This is a 9-dimensional representation of SO(3).
One can easily verify that the symmetric and anti-symmetric parts of A remain symmetric respectively
anti-symmetric under rotations. This splits R3×3 into 6- and 3-dimensional linear subspaces that
transform independently. According to Weyl’s principle  these may be considered as distinct quanti-
ties  even if it is not immediately visible by looking at the coordinates Aij. The 6-dimensional space
can be further broken down  because scalar matrices Aij = αδij (which are invariant under rotation)
and traceless symmetric matrices also transform independently. Thus a rank-2 tensor decomposes
into representations of dimension 1 (trace)  3 (anti-symmetric part)  and 5 (traceless symmetric part).
In representation-theoretic terms  we have reduced the 9-dimensional representation ρ into irreducible
representations of dimension 1  3 and 5. We can write this as

where we use(cid:76) to denote the construction of a block-diagonal matrix with blocks Dl(r)  and Q is a

l=0

change of basis matrix that extracts the trace  symmetric-traceless and anti-symmetric parts of A.
More generally  it can be shown that any representation of SO(3) can be decomposed into irreducible
representations of dimension 2l + 1  for l = 0  1  2  . . .  ∞. The irreducible representation acting on
this 2l + 1 dimensional space is known as the Wigner-D matrix of order l  denoted Dl(r). Note that
the Wigner-D matrix of order 4 is a representation of dimension 9  it has the same dimension as the
representation ρ acting on A but these are two different representations.
Since any SO(3) representation can be decomposed into irreducibles  we only use irreducible features
in our networks. This means that the feature vector f (x) in layer n is a stack of Fn features

f i(x) ∈ R2li+1  so that Kn =(cid:80)Fn

i=1 2lin + 1.

4 SE(3)-Equivariant Networks

Our general approach to building SE(3)-equivariant networks will be as follows: First  we will
specify for each layer n a linear transformation law πn(g) : Fn → Fn  which describes how the
feature space Fn transforms under transformations of the input by g ∈ SE(3). Then  we will study
the vector space HomSE(3)(Fn Fn+1) of equivariant linear maps (intertwiners) Φ between adjacent
feature spaces:

HomSE(3)(Fn Fn+1) = {Φ ∈ Hom(Fn Fn+1)| Φπn(g) = πn+1(g)Φ  ∀g ∈ SE(3)}

(3)
Here Hom(Fn Fn+1) is the space of linear (not necessarily equivariant) maps from Fn to Fn+1.
By ﬁnding a basis for the space of intertwiners and parameterizing Φn as a linear combination of
basis maps  we can make sure that layer n + 1 transforms according to πn+1 if layer n transforms
according to πn  thus guaranteeing equivariance of the whole network by induction.
As explained in the previous section  ﬁelds transform according to induced representations [5  8  10 
17]. In this section we show that equivariant maps between induced representations of SE(3) can
always be expressed as convolutions with equivariant / steerable ﬁlter banks. The space of equivariant
ﬁlter banks turns out to be a linear subspace of the space of ﬁlter banks of a conventional 3D CNN.
The ﬁlter banks of our network are expanded in terms of a basis of this subspace with parameters
corresponding to expansion coefﬁcients.
Sec. 4.1 derives the linear constraint on the kernel space for arbitrary induced representations. From
Sec. 4.2 on we specialize to representations induced from irreducible representations of SO(3) and
derive a basis of the equivariant kernel space for this choice analytically. Subsequent sections discuss
choices of equivariant nonlinearities and the actual discretized implementation.

4

4.1 The Subspace of Equivariant Kernels
A continuous linear map between Fn and Fn+1 can be written using a continuous kernel κ with
signature κ : R3 × R3 → RKn+1×Kn  as follows:

[κ · f ](x) =

κ(x  y)f (y)dy

(4)

Lemma 1. The map f (cid:55)→ κ · f is equivariant if and only if for all g ∈ SE(3) 

(5)
Proof. For this map to be equivariant  it must satisfy κ · [π1(g)f ] = π2(g)[κ · f ]. Expanding the left
hand side of this constraint  using g = tr  and the substitution y (cid:55)→ gy  we ﬁnd:

κ(gx  gy) = ρ2(r)κ(x  y)ρ1(r)−1 

κ · [π1(g)f ](x) =

κ(x  gy)ρ1(r)f (y)dy

For the right hand side 

π2(g)[κ · f ](x) = ρ2(r)

κ(g−1x  y)f (y)dy.

(cid:90)

R3

(cid:90)

R3

(cid:90)

R3

(6)

(7)

(8)

(10)

(11)

Equating these  and using that the equality has to hold for arbitrary f ∈ Fn  we conclude:

ρ2(r)κ(g−1x  y) = κ(x  gy)ρ1(r).

Substitution of x (cid:55)→ gx and right-multiplication by ρ1(r)−1 yields the result.
Theorem 2. A linear map from Fn to Fn+1 is equivariant if and only if it is a cross-correlation with
a rotation-steerable kernel.
Proof. Lemma 1 implies that we can write κ in terms of a one-argument kernel  since for g = −x :
(9)

κ(x  y) = κ(0  y − x) ≡ κ(y − x).

Substituting this into Equation 4  we ﬁnd

(cid:90)

R3

(cid:90)

R3

[κ · f ](x) =

κ(x  y)f (y)dy =

κ(y − x)f (y)dy = [κ (cid:63) f ](x).

Cross-correlation is always translation-equivariant  but Eq. 5 still constrains κ rotationally:

A kernel satisfying this constraint is called rotation-steerable.

κ(rx) = ρ2(r)κ(x)ρ1(r)−1.

We note that κ (cid:63) f (Eq. 10) is exactly the operation used in a conventional convolutional network  just
written in an unconventional form  using a matrix-valued kernel (“propagator”) κ : R3 → RKn+1×Kn.
Since Eq. 11 is a linear constraint on the correlation kernel κ  the space of equivariant kernels (i.e.
those satisfying Eq. 11) forms a vector space. We will now proceed to compute a basis for this space 
so that we can parameterize the kernel as a linear combination of basis kernels.

4.2 Solving for the Equivariant Kernel Basis
As mentioned before  we assume that the Kn-dimensional feature vectors f (x) = ⊕if i(x) consist of
irreducible features f i(x) of dimension 2 lin + 1. In other words  the representation ρn(r) that acts
on ﬁbers in layer n is block-diagonal  with irreducible representation Dlin (r) as the i-th block. This
implies that the kernel κ : R3 → RKn+1×Kn splits into blocks1 κjl : R3 → R(2j+1)×(2l+1) mapping
between irreducible features. The blocks themselves are by Eq. 11 constrained to transform as

κjl(rx) = Dj(r)κjl(x)Dl(r)−1.

(12)

1For more details on the block structure see Sec. 2.7 of [10]

5

Figure 2: Angular part of the basis for the space of steerable kernels κjl (for j = l = 1  i.e. 3D vector ﬁelds as
input and output). From left to right we plot three 3 × 3 matrices  for j − l ≤ J ≤ j + l i.e. J = 0  1  2. Each
3 × 3 matrix corresponds to one learnable parameter per radial basis function ϕm. A seasoned eye will see the
identity  the curl (∇∧) and the gradient of the divergence (∇∇·).
To bring this constraint into a more manageable form  we vectorize these kernel blocks to vec(κjl(x)) 
so that we can rewrite the constraint as a matrix-vector equation2

vec(κjl(rx)) = [Dj ⊗ Dl](r) vec(κjl(x)) 

(13)
where we used the orthogonality of Dl. The tensor product of representations is itself a representation 
and hence can be decomposed into irreducible representations. For irreducible SO(3) representations
Dj and Dl of order j and l it is well known [17] that Dj ⊗ Dl can be decomposed in terms of
2 min(j  l) + 1 irreducible representations of order3 |j − l| ≤ J ≤ j + l. That is  we can ﬁnd a
change of basis matrix4 Q of shape (2l + 1)(2j + 1) × (2l + 1)(2j + 1) such that the representation
becomes block diagonal:

(cid:20)(cid:77)j+l

(cid:21)

[Dj ⊗ Dl](r) = QT

J=|j−l| DJ (r)

Q

Thus  we can change the basis to ηjl(x) := Q vec(κjl(x)) such that constraint 12 becomes

(cid:20)(cid:77)j+l

(cid:21)

ηjl(rx) =

J=|j−l| DJ (r)

ηjl(x).

(14)

(15)

(cid:77)j+l

The block diagonal form of the representation in this basis reveals that ηjl decomposes into
2 min(j  l) + 1 invariant subspaces of dimension 2J + 1 with separated constraints:

ηjl(x) =

J=|j−l| ηjl J (x)  

ηjl J (rx) = DJ (r)ηjl J (x)

(16)

This is a famous equation for which the unique and complete solution is well-known to be given
J (x)) ∈ R2J+1. More speciﬁcally  since x
by the spherical harmonics Y J (x) = (Y J−J (x)  . . .   Y J
lives in R3 instead of the sphere  the constraint only restricts the angular part of ηjl but leaves its
radial part free. Therefore  the solutions are given by spherical harmonics modulated by an arbitrary
continuous radial function ϕ : R+ → R as ηjl J (x) = ϕ((cid:107)x(cid:107))Y J (x/(cid:107)x(cid:107)).
To obtain a complete basis  we can choose a set of radial basis functions ϕm : R+ → R  and deﬁne
kernel basis functions ηjl Jm(x) = ϕm((cid:107)x(cid:107)) Y J (x/(cid:107)x(cid:107)). Following [42]  we choose a Gaussian
radial shell ϕm((cid:107)x(cid:107)) = exp (− 1
2 ((cid:107)x(cid:107) − m)2/σ2) in our implementation. The angular dependency
at a ﬁxed radius of the basis for j = l = 1 is shown in Figure 2.
By mapping each ηjl Jm back to the original basis via QT and unvectorizing  we obtain a basis
κjl Jm for the space of equivariant kernels between features of order j and l. This basis is indexed by
the radial index m and frequency index J. In the forward pass  we linearly combine the basis kernels
Jm wjl Jmκjl Jm using learnable weights w  and stack them into a complete kernel κ 

as κjl =(cid:80)

which is passed to a standard 3D convolution routine.

4.3 Equivariant Nonlinearities
In order for the whole network to be equivariant  every layer  including the nonlinearities  must
be equivariant. In a regular G-CNN  any elementwise nonlinearity will be equivariant because the
regular representation acts by permuting the activations. In a steerable G-CNN however  special
equivariant nonlinearities are required.

2vectorize correspond to ﬂatten it in numpy and the tensor product correspond to np.kron
3There is a fascinating analogy with the quantum states of a two particle system for which the angular

momentum states decompose in a similar fashion.

4Q can be expressed in terms of Clebsch-Gordan coefﬁcients  but here we only need to know it exists.

6

Trivial irreducible features  corresponding to scalar ﬁelds  do not transform under rotations. So for
these features we use conventional nonlinearities like ReLUs or sigmoids. For higher order features
we considered tensor product nonlinearities [26] and norm nonlinearities [45]  but settled on a novel
n(x) ∈ R2lin+1 in
gated nonlinearity. For each non-scalar irreducible feature κi
layer n  we produce a scalar gate σ(γi
n (cid:63) fn−1(x))  where σ denotes the sigmoid function and γi
n
is another learnable rotation-steerable kernel. Then  we multiply the feature (a non-scalar ﬁeld) by
the gate (a scalar ﬁeld): f i
n (cid:63) fn−1) is a
scalar ﬁeld  and multiplying any feature by a scalar is equivariant. See Section 1.3 and Figure 1 in the
Supplementary Material for details.

n (cid:63) fn−1 is a scalar ﬁeld  σ(γi

n (cid:63) fn−1(x)). Since γi

n (cid:63) fn−1(x) = f i

n(x) σ(γi

4.4 Discretized Implementation
In a computer implementation of SE(3) equivariant networks  we need to sample both the ﬁelds /
feature maps and the kernel on a discrete sampling grid in Z3. Since this could introduce aliasing
artifacts  care is required to make sure that high-frequency ﬁlters  corresponding to large values of J 
are not sampled on a grid of low spatial resolution. This is particularly important for small radii since
near the origin only a small number of pixels is covered per solid angle. In order to prevent aliasing
we hence introduce a radially dependent angular frequency cutoff. Aliasing effect originating from
the radial part of the kernel basis are counteracted by choosing a smooth Gaussian radial proﬁle as
described above. Below we describe how our implementation works in detail.

4.4.1 Kernel space precomputation
Before training  we compute basis kernels κjl Jm(xi) sampled on a s × s × s cubic grid of points
xi ∈ Z3  as follows. For each pair of output and input orders j and l we ﬁrst sample spherical
harmonics Y J  |j − l| ≤ J ≤ j + l in a radially independent manner in an array of shape (2J + 1) ×
s × s × s. Then  we transform the spherical harmonics back to the original basis by multiplying
by QJ ∈ R(2j+1)(2l+1)×(2J+1)  consisting of 2J + 1 adjacent columns of Q  and unvectorize the
resulting array to unvec(QJ Y J (xi)) which has shape (2j + 1) × (2l + 1) × s × s × s.
The matrix Q itself could be expressed in terms of Clebsch-Gordan coefﬁcients [17]  but we ﬁnd it
easier to compute it by numerically solving Eq. 14.
The radial dependence is introduced by multiplying the cubes with each windowing function ϕm. We
use integer means m = 0  . . .  (cid:98)s/2(cid:99) and a ﬁxed width of σ = 0.6 for the radial Gaussian windows.
Sampling high-order spherical harmonics will introduce aliasing effects  particularly near the origin.
max  and create basis functions only for |j − l| ≤
(cid:80)J m
Hence  we introduce a radius-dependent bandlimit J m
J ≤ J m
max. Each basis kernel is scaled to unit norm for effective signal propagation [42]. In total we
|j−l| 1 ≤ ((cid:98)s/2(cid:99) + 1)(2 min(j  l) + 1) basis kernels mapping between ﬁelds of

get B =(cid:80)(cid:98)s/2(cid:99)

order j and l  and thus a basis array of shape B × (2j + 1) × (2l + 1) × s × s × s.

m=0

max

4.4.2 Spatial dimension reduction
We found that the performance of the Steerable CNN models depends critically on the way of down-
sampling the ﬁelds. In particular  the standard procedure of downsampling via strided convolutions
performed poorly compared to smoothing features maps before subsampling. We followed [1] and
experiment with applying a low pass ﬁltering before performing the downsampling step which can be
implemented either via an additional strided convolution with a Gaussian kernel or via an average
pooling. We observed signiﬁcant improvements of the rotational equivariance by doing so. See
Table 2 in the Supplementary Material for a comparison between performances with and without low
pass ﬁltering.

4.4.3 Forward pass
At training time  we linearly combine the basis kernels using learned weights  and stack them together
into a full ﬁlter bank of shape Kn+1 × Kn × s × s × s  which is used in a standard convolution
routine. Once the network is trained  we can convert the network to a standard 3D CNN by linearly
combining the basis kernels with the learned weights  and storing only the resulting ﬁlter bank.

7

5 Experiments
We performed several experiments to gauge the performance and data efﬁciency of our model.

5.1 Tetris
In order to conﬁrm the equivariance of our model  we performed a variant of the Tetris experiments re-
ported by [40]. We constructed a 4-layer 3D Steerable CNN and trained it to classify 8 kinds of Tetris
blocks  stored as voxel grids  in a ﬁxed orientation. Then we test on Tetris blocks rotated by random ro-
tations in SO(3). As expected  the 3D Steerable CNN generalizes over rotations and achieves 99±2%
accuracy on the test set. In contrast  a conventional CNN is not able to generalize over larger unseen
rotations and gets a result of only 27±7%. For both networks we repeated the experiment over 17 runs.

3D model classiﬁcation

5.2
Moving beyond the simple Tetris blocks  we next con-
sidered classiﬁcation of more complex 3D objects. The
SHREC17 task [35]  which contains 51300 models of 3D
shapes belonging to 55 classes (chair  table  light  oven 
keyboard  etc)  has a ‘perturbed’ category where images
are arbitrarily rotated  making it a well-suited test case
for our model. We converted the input into voxel grids
of size 64x64x64  and used an architecture similar to the
Tetris case  but with an increased number of layers (see
Table 3 in the Supplementary Material). Although we have
not done extensive ﬁne-tuning on this dataset  we ﬁnd our
model to perform comparably to the current state of the art 
see Figure 3 and Table 4 in the Supplementary Material.

O
u
r
s

E
s
t

e
v
e
s

F
u
r
u
y
a

T
a
t
s
u
m
a

P
A
m
o
r
c
a
m
+
P
A
m
o
r
c
m

i

1.1

1.0

0.9

0.8

Z
h
o
u

K
a
n
e
z
a
k

i

D
e
n
g

105

106

107

108

number of parameters

Figure 3: Shrec17 results[2  7  14  16  24 
35  39]. Comparison of different architec-
tures by number of parameters and score. See
Table 4 in the Supplementary Material for all
the details.

5.3 Visualization of the equivariance property
We made a movie to show the action of rotating the input on the internal ﬁelds. We found that the
action are remarkably stable. A visualization is provided in https://youtu.be/ENLJACPHSEA.

5.4 Amino acid environments
Next  we considered the task of predicting amino acid preferences from the atomic environments  a
problem which has been studied by several groups in the last year [4  41]. Since physical forces are
primarily a function of distance  one of the previous studies argued for the use of a concentric grid 
investigated strategies for conducting convolutions on such grids  and reported substantial gains when
using such convolutions over a standard 3D convolution in a regular grid (0.56 vs 0.50 accuracy) [4].
Since the classiﬁcation of molecular environments involves the recognition of particular interactions
between atoms (e.g. hydrogen bonds)  one would expect rotational equivariant convolutions to be
more suitable for the extraction of relevant features. We tested this hypothesis by constructing the
exact same network as used in the original study  merely replacing the conventional convolutional
layers with equivalent 3D steerable convolutional layers. Since the latter use substantially fewer
parameters per channel  we chose to use the same number of ﬁelds as the number of channels in the
original model  which still only corresponds to roughly half the number of parameters (32.6M vs
61.1M (regular grid)  and 75.3M (concentric representation)). Without any alterations to the model
and using the same training procedure (apart from adjustment of learning rate and regularization
factor)  we obtained a test accuracy of 0.58  substantially outperforming the conventional CNN on
this task  and also providing an improvement over the state-of-the-art on this problem.

5.5 CATH: Protein structure classiﬁcation
The molecular environments considered in the task above are oriented based on the protein backbone.
Similar to standard images  this implies that the images have a natural orientation. For the ﬁnal
experiment  we wished to investigate the performance of our Steerable 3D convolutions on a problem
domain with full rotational invariance  i.e. where the images have no inherent orientation. For this
purpose  we consider the task of classifying the overall shape of protein structures.

8

We constructed a new data set  based on the CATH protein structure classiﬁcation database [11] 
version 4.2 (see http://cathdb.info/browse/tree). The database is a classiﬁcation hierarchy
containing millions of experimentally determined protein domains at different levels of structural
detail. For this experiment  we considered the CATH classiﬁcation-level of "architecture"  which
splits proteins based on how protein secondary structure elements are organized in three dimensional
space. Predicting the architecture from the raw protein structure thus poses a particularly challenging
task for the model  which is required to not only detect the secondary structure elements at any
orientation in the 3D volume  but also detect how these secondary structures orient themselves relative
to one another. We limited ourselves to architectures with at least 500 proteins  which left us with
10 categories. For each of these  we balanced the data set so that all categories are represented by
the same number of structures (711)  also ensuring that no two proteins within the set have more
than 40% sequence identity. See Supplementary Material for details. The new dataset is available at
https://github.com/wouterboomsma/cath_datasets.
We ﬁrst established a state-of-the-art baseline consisting of a conventional 3D CNN  by conducting a
range of experiments with various architectures. We converged on a ResNet34-inspired architecture
with half as many channels as the original  and global pooling at the end. The ﬁnal model consists of
15  878  764 parameters. For details on the experiments done to obtain the baseline  see Supplementary
Material.
Following the same ResNet template  we then constructed a 3D Steerable network by replacing each
layer by an equivariant version  keeping the number of 3D channels ﬁxed. The channels are allocated
such that there is an equal number of ﬁelds of order l = 0  1  2  3 in each layer except the last  where
we only used scalar ﬁelds (l = 0). This network contains only 143  560 parameters  more than a
factor hundred less than the baseline.
We used the ﬁrst seven of the ten splits for training  the eighth for validation and the last two for
testing. The data set was augmented by randomly rotating the input proteins whenever they were
presented to the model during training. Note that due to their rotational equivariance  3D Steerable
CNNs beneﬁt only marginally from rotational data augmentation compared to the baseline CNN. We
train the models for 100 epochs using the Adam optimizer [25]  with an exponential learning rate
decay of 0.94 per epoch starting after an initial burn-in phase of 40 epochs.
Despite having 100 times fewer parame-
ters  a comparison between the accuracy
on the test set shows a clear beneﬁt to the
3D Steerable CNN on this dataset (Figure 4 
leftmost value). We proceeded with an in-
vestigation of the dependency of this perfor-
mance on the size of the dataset by consid-
ering reductions of the size of each training
split in the dataset by increasing powers of
two  maintaining the same network archi-
tecture but re-optimizing the regularization
parameters of the networks. We found that
the proposed model outperforms the base-
line even when trained on a fraction of the
training set size. The results further demon-
strate the accuracy improvements across
these reductions to be robust (Figure 4).

Figure 4: Accuracy on the CATH test set as a function
of increasing reduction in training set size.

3D Steerable CNN
3D CNN

training set size reduction factor

0.55

0.50

0.65

0.60

y
c
a
r
u
c
c
a

t
s
e
t

23

24

20

21

22

6 Conclusion
In this paper we have presented 3D Steerable CNNs  a class of SE(3)-equivariant networks which
represents data in terms of various kinds of ﬁelds over R3. We have presented a comprehensive
theory of 3D Steerable CNNs  and have proven that convolutions with SO(3)-steerable ﬁlters provide
the most general way of mapping between ﬁelds in an equivariant manner  thus establishing SE(3)-
equivariant networks as a universal class of architectures. 3D Steerable CNNs require only a minor
adaptation to the code of a 3D CNN  and can be converted to a conventional 3D CNN after training.
Our results show that 3D Steerable CNNs are indeed equivariant  and that they show excellent
accuracy and data efﬁciency in amino acid propensity prediction and protein structure classiﬁcation.

9

References
[1] Aharon Azulay and Yair Weiss. Why do deep convolutional networks generalize so poorly to

small image transformations? arXiv preprint arXiv:1805.12177  abs/1805.12177  2018.

[2] Song Bai  Xiang Bai  Zhichao Zhou  Zhaoxiang Zhang  and Longin Jan Latecki. Gift: A
real-time and scalable 3d shape search engine. In Proceedings of IEEE Conference on Computer
Vision and Pattern Recognition (CVPR)  June 2016.

[3] Erik J Bekkers  Maxime W Lafarge  Mitko Veta  Koen AJ Eppenhof  and Josien PW Pluim.
Roto-translation covariant convolutional networks for medical image analysis. arXiv preprint
arXiv:1804.03393  2018.

[4] Wouter Boomsma and Jes Frellsen. Spherical convolutions and their application in molecular
modelling. In Advances in Neural Information Processing Systems 30  pages 3436–3446. 2017.

[5] Tullio Ceccherini-Silberstein  A Machì  Fabio Scarabotti  and Filippo Tolli. Induced representa-

tions and mackey theory. Journal of Mathematical Sciences  156(1):11–28  2009.

[6] Taco Cohen and Max Welling. Learning the irreducible representations of commutative lie
groups. In Proceedings of the 31st International Conference on Machine Learning (ICML) 
volume 31  pages 1755–1763  2014.

[7] Taco S. Cohen  Mario Geiger  Jonas Köhler  and Max Welling. Spherical CNNs. In International

Conference on Learning Representations (ICLR)  2018.

[8] Taco S Cohen  Mario Geiger  and Maurice Weiler.

Intertwiners between induced repre-
sentations (with applications to the theory of equivariant neural networks). arXiv preprint
arXiv:1803.10743  2018.

[9] Taco S Cohen and Max Welling. Group equivariant convolutional networks. In Proceedings of
The 33rd International Conference on Machine Learning (ICML)  volume 48  pages 2990–2999 
2016.

[10] Taco S Cohen and Max Welling. Steerable CNNs. In International Conference on Learning

Representations (ICLR)  2017.

[11] Natalie L Dawson  Tony E Lewis  Sayoni Das  Jonathan G Lees  David Lee  Paul Ashford 
Christine A Orengo  and Ian Sillitoe. CATH: an expanded resource to predict protein function
through structure and sequence. Nucleic acids research  45(D1):D289–D295  2016.

[12] Sander Dieleman  Jeffrey De Fauw  and Koray Kavukcuoglu. Exploiting cyclic symmetry in
convolutional neural networks. In International Conference on Machine Learning (ICML) 
2016.

[13] Remco Duits and Erik Franken. Left-invariant diffusions on the space of positions and orien-
tations and their application to crossing-preserving smoothing of hardi images. International
Journal of Computer Vision  92(3):231–264  2011.

[14] Carlos Esteves  Christine Allen-Blanchette  Ameesh Makadia  and Kostas Daniilidis. 3D
object classiﬁcation and retrieval with Spherical CNNs. arXiv preprint arXiv:1711.06721 
abs/1711.06721  2017.

[15] William T. Freeman and Edward H Adelson. The design and use of steerable ﬁlters. IEEE

Transactions on Pattern Analysis & Machine Intelligence  (9):891–906  1991.

[16] Takahiko Furuya and Ryutarou Ohbuchi. Deep aggregation of local 3d geometric features for
3d model retrieval. In Proceedings of the British Machine Vision Conference (BMVC)  pages
121.1–121.12  September 2016.

[17] David Gurarie. Symmetries and Laplacians: Introduction to Harmonic Analysis  Group Repre-

sentations and Applications. 1992.

[18] Geoffrey Hinton  Nicholas Frosst  and Sabour Sara. Matrix capsules with EM routing. In

International Conference on Learning Representations (ICLR)  2018.

10

[19] Emiel Hoogeboom  Jorn W T Peters  Taco S Cohen  and Max Welling. HexaConv.

International Conference on Learning Representations (ICLR)  2018.

In

[20] Truong Son Hy  Shubhendu Trivedi  Horace Pan  Brandon M. Anderson  and Risi Kondor.
Predicting molecular properties with covariant compositional networks. The Journal of Chemical
Physics  148(24):241745  2018.

[21] Michiel HJ Janssen  Tom CJ Dela Haije  Frank C Martin  Erik J Bekkers  and Remco Duits.
The hessian of axially symmetric functions on se (3) and application in 3d image analysis. In
International Conference on Scale Space and Variational Methods in Computer Vision  pages
643–655. Springer  2017.

[22] Michiel HJ Janssen  Augustus JEM Janssen  Erik J Bekkers  Javier Oliván Bescós  and Remco
Duits. Design and processing of invertible orientation scores of 3d images. Journal of Mathe-
matical Imaging and Vision  pages 1–32  2018.

[23] Kenichi Kanatani. Group-Theoretical Methods in Image Understanding. Springer-Verlag New

York  Inc.  Secaucus  NJ  USA  1990.

[24] Asako Kanezaki  Yasuyuki Matsushita  and Yoshifumi Nishida. Rotationnet: Joint object

categorization and pose estimation using multiviews from unsupervised viewpoints  2018.

[25] Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In Proceedings

of the International Conference on Learning Representations (ICLR)  2015.

[26] Risi Kondor. N-body networks: a covariant hierarchical neural network architecture for learning

atomic potentials. arXiv preprint arXiv:1803.01588  2018.

[27] Risi Kondor  Zhen Lin  and Shubhendu Trivedi. Clebsch–gordan nets: a fully fourier space
spherical convolutional neural network. In Neural Information Processing Systems (NIPS) 
2018.

[28] Risi Kondor  Hy Truong Son  Horace Pan  Brandon Anderson  and Shubhendu Trivedi. Co-
variant compositional networks for learning graphs. In International Conference on Learning
Representations (ICLR)  2018.

[29] Risi Kondor and Shubhendu Trivedi. On the generalization of equivariance and convolution in

neural networks to the action of compact groups. arXiv preprint arXiv:1802.03690  2018.

[30] Diego Marcos  Michele Volpi  Nikos Komodakis  and Devis Tuia. Rotation equivariant vector

ﬁeld networks. In International Conference on Computer Vision (ICCV)  2017.

[31] Chris Olah. Groups and group convolutions.

2014-12-Groups-Convolution/  2014.

https://colah.github.io/posts/

[32] Siamak Ravanbakhsh  Jeff Schneider  and Barnabas Poczos. Equivariance through parameter-

sharing. arXiv preprint arXiv:1702.08389  2017.

[33] Marco Reisert and Hans Burkhardt. Efﬁcient tensor voting with 3d tensorial harmonics. In
Computer Vision and Pattern Recognition Workshops  2008. CVPRW’08. IEEE Computer
Society Conference on  pages 1–7. IEEE  2008.

[34] Sara Sabour  Nicholas Frosst  and Geoffrey E Hinton. Dynamic routing between capsules. In

Advances in Neural Information Processing Systems 30  pages 3856–3866. 2017.

[35] Manolis Savva  Fisher Yu  Hao Su  Asako Kanezaki  Takahiko Furuya  Ryutarou Ohbuchi 
Zhichao Zhou  Rui Yu  Song Bai  Xiang Bai  Masaki Aono  Atsushi Tatsuma  S. Thermos 
A. Axenopoulos  G. Th. Papadopoulos  P. Daras  Xiao Deng  Zhouhui Lian  Bo Li  Henry
Johan  Yijuan Lu  and Sanjeev Mk. Large-Scale 3D Shape Retrieval from ShapeNet Core55. In
Ioannis Pratikakis  Florent Dupont  and Maks Ovsjanikov  editors  Eurographics Workshop on
3D Object Retrieval. The Eurographics Association  2017.

[36] Laurent Sifre and Stephane Mallat. Rotation  scaling and deformation invariant scattering for
texture discrimination. IEEE conference on Computer Vision and Pattern Recognition (CVPR) 
2013.

11

[37] Eero P Simoncelli and William T Freeman. The steerable pyramid: A ﬂexible architecture for
multi-scale derivative computation. In Image Processing  1995. Proceedings.  International
Conference on  volume 3  pages 444–447. IEEE  1995.

[38] Henrik Skibbe. Spherical Tensor Algebra for Biomedical Image Analysis. PhD thesis  2013.

[39] Atsushi Tatsuma and Masaki Aono. Multi-fourier spectra descriptor and augmentation with

spectral clustering for 3d shape retrieval. The Visual Computer  25(8):785–804  Aug 2009.

[40] Nathaniel Thomas  Tess Smidt  Steven Kearnes  Lusann Yang  Li Li  Kai Kohlhoff  and Patrick
Riley. Tensor Field Networks: Rotation-and Translation-Equivariant Neural Networks for 3D
Point Clouds. arXiv preprint arXiv:1802.08219  2018.

[41] Wen Torng and Russ B Altman. 3D deep convolutional neural networks for amino acid

environment similarity analysis. BMC Bioinformatics  18(1):302  June 2017.

[42] Maurice Weiler  Fred A Hamprecht  and Martin Storath. Learning steerable ﬁlters for rotation

equivariant CNNs. In Computer Vision and Pattern Recognition (CVPR)  2018.

[43] Marysia Winkels and Taco S Cohen. 3D G-CNNs for Pulmonary Nodule Detection. arXiv

preprint arXiv:1804.04656  2018.

[44] Daniel Worrall and Gabriel Brostow. CubeNet: Equivariance to 3D Rotation and Translation.

arXiv preprint arXiv:1804.04458  2018.

[45] Daniel E Worrall  Stephan J Garbin  Daniyar Turmukhambetov  and Gabriel J Brostow. Har-
monic networks: Deep translation and rotation equivariance. In Computer Vision and Pattern
Recognition (CVPR)  2017.

[46] Manzil Zaheer  Satwik Kottur  Siamak Ravanbakhsh  Barnabas Poczos  Ruslan R Salakhutdinov 
and Alexander J Smola. Deep sets. In Advances in Neural Information Processing Systems 
pages 3391–3401  2017.

12

,Maurice Weiler
Mario Geiger
Max Welling
Wouter Boomsma
Taco Cohen