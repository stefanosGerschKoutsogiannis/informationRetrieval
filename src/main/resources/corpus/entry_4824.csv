2017,Safe Adaptive Importance Sampling,Importance sampling has become an indispensable strategy to speed up optimization algorithms for large-scale applications. Improved adaptive variants -- using importance values defined by the complete gradient information which changes during optimization -- enjoy favorable theoretical properties  but are typically computationally infeasible. In this paper we propose an efficient approximation of gradient-based sampling  which is based on safe bounds on the gradient. The proposed sampling distribution is  (i) provably the \emph{best sampling} with respect to the given bounds   (ii) always better than uniform sampling and fixed importance sampling and  (iii) can efficiently be computed -- in many applications  at negligible extra cost. The proposed sampling scheme is generic and can easily be integrated into existing algorithms. In particular  we show that coordinate-descent (CD) and stochastic gradient descent (SGD) can enjoy significant a speed-up under the novel scheme. The proven efficiency of the proposed sampling is verified by extensive numerical testing.,Safe Adaptive Importance Sampling

Sebastian U. Stich

EPFL

Anant Raj

Max Planck Institute for Intelligent Systems

sebastian.stich@epfl.ch

anant.raj@tuebingen.mpg.de

Martin Jaggi

EPFL

martin.jaggi@epfl.ch

Abstract

Importance sampling has become an indispensable strategy to speed up optimiza-
tion algorithms for large-scale applications. Improved adaptive variants—using
importance values deﬁned by the complete gradient information which changes
during optimization—enjoy favorable theoretical properties  but are typically com-
putationally infeasible. In this paper we propose an efﬁcient approximation of
gradient-based sampling  which is based on safe bounds on the gradient. The
proposed sampling distribution is (i) provably the best sampling with respect to
the given bounds  (ii) always better than uniform sampling and ﬁxed importance
sampling and (iii) can efﬁciently be computed—in many applications at negligible
extra cost. The proposed sampling scheme is generic and can easily be integrated
into existing algorithms. In particular  we show that coordinate-descent (CD) and
stochastic gradient descent (SGD) can enjoy signiﬁcant a speed-up under the novel
scheme. The proven efﬁciency of the proposed sampling is veriﬁed by extensive
numerical testing.

1

Introduction

Modern machine learning applications operate on massive datasets. The algorithms that are used
for data analysis face the difﬁcult challenge to cope with the enormous amount of data or the vast
dimensionality of the problems. A simple and well established strategy to reduce the computational
costs is to split the data and to operate only on a small part of it  as for instance in coordinate
descent (CD) methods and stochastic gradient (SGD) methods. These kind of methods are state of
the art for a wide selection of machine learning  deep leaning and signal processing applications [9 
11  35  27]. The application of these schemes is not only motivated by their practical preformance 
but also well justiﬁed by theory [18  19  2].
Deterministic strategies are seldom used for the data selection—examples are steepest coordinate
descent [4  34  20] or screening algorithms [14  15]. Instead  randomized selection has become
ubiquitous  most prominently uniform sampling [27  29  7  8  28] but also non-uniform sampling based
on a ﬁxed distribution  commonly referred to as importance sampling [18  19  2  33  16  6  25  24].
While these sampling strategies typically depend on the input data  they do not adapt to the information
of the current parameters during optimization. In contrast  adaptive importance sampling strategies
constantly re-evaluate the relative importance of each data point during training and thereby often
surpass the performance of static algorithms [22  5  26  10  21  23]. Common strategies are gradient-
based sampling [22  36  37] (mostly for SGD) and duality gap-based sampling for CD [5  23].
The drawbacks of adaptive strategies are twofold: often the provable theoretical guarantees can be
worse than the complexity estimates for uniform sampling [23  3] and often it is computationally

31st Conference on Neural Information Processing Systems (NIPS 2017)  Long Beach  CA  USA.

inadmissible to compute the optimal adaptive sampling distribution. For instance gradient based
sampling requires the computation of the full gradient in each iteration [22  36  37]. Therefore one
has to rely on approximations based on upper bounds [36  37]  or stale values [22  1]. But in general
these approximations can again be worse than uniform sampling.
This makes it necessary to develop adaptive strategies that can efﬁciently be computed in every
iteration and that come with theoretical guarantees that show their advantage over ﬁxed sampling.

Our contributions.
In this paper we propose an efﬁcient approximation of the gradient-based
sampling in the sense that (i) it can efﬁciently be computed in every iteration  (ii) is provably better
than uniform or ﬁxed importance sampling and (iii) recovers the gradient-based sampling in the full-
information setting. The scheme is completely generic and can easily be added as an improvement to
both CD and SGD type methods.
As our key contributions  we

(1) show that gradient-based sampling in CD methods is theoretically better than the classical ﬁxed

sampling  the speed-up can reach a factor of the dimension n (Section 2);

(2) propose a generic and efﬁcient adaptive importance sampling strategy that can be applied in CD

and SGD methods and enjoys favorable properties—such as mentioned above (Section 3);

(3) demonstrate how the novel scheme can efﬁciently be integrated in CD and SGD on an important

class of structured optimization problems (Section 4);

(4) supply numerical evidence that the novel sampling performs well on real data (Section 5).
Notation. For x ∈ Rn deﬁne [x]i := (cid:104)x  ei(cid:105) with ei the standard unit vectors in Rn. We abbreviate
∇if := [∇f ]i. A convex function f : Rn → R with L-Lipschitz continuous gradient satisﬁes

(cid:107)u(cid:107)2

f (x + ηu) ≤ f (x) + η (cid:104)u ∇f (x)(cid:105) + η2Lu

(1)
for every direction u ∈ Rn and Lu = L. A function with coordinate-wise Li-Lipschitz continuous
gradients1 for constants Li > 0  i ∈ [n] := {1  . . .   n}  satisﬁes (1) just along coordinate directions 
i.e. u = ei  Lei = Li for every i ∈ [n]. A function is coordinate-wise L-smooth if Li ≤ L for
i = 1  . . .   n. For convenience we introduce vector l = (L1  . . .   n)(cid:62) and matrix L = diag(l). A
probability vector p ∈ ∆n := {x ∈ Rn≥0 : (cid:107)x(cid:107)1 = 1} deﬁnes a probability distribution P over [n]
and we denote by i ∼ p a sample drawn from P.

∀x ∈ Rn ∀η ∈ R  

2

2 Adaptive Importance Sampling with Full Information

In this section we argue that adaptive sampling strategies are theoretically well justiﬁed  as they
can lead to signiﬁcant improvements over static strategies. In our exhibition we focus ﬁrst on CD
methods  as we also propose a novel stepsize strategy for CD in this contribution. Then we revisit the
results regarding stochastic gradient descent (SGD) already present in the literature.

2.1 Coordinate Descent with Adaptive Importance Sampling
We address general minimization problems minx f (x). Let the objective f : Rn → R be convex with
coordinate-wise Li-Lipschitz continuous gradients. Coordinate descent methods generate sequences
{xk}k≥0 of iterates that satisfy the relation

xk+1 = xk − γk∇ik f (xk)eik .

(2)

Here  the direction ik is either chosen deterministically (cyclic descent  steepest descent)  or randomly
picked according to a probability vector pk ∈ ∆n. In the classical literature  the stepsize is often
chosen such as to minimize the quadratic upper bound (1)  i.e. γk = L−1
In this work we
propose to set γk = αk[pk]−1
where αk does not depend on the chosen direction ik. This leads to

ik

.

ik

1|∇if (x + ηei) − ∇if (x)| ≤ Li |η|  

∀x ∈ Rn ∀η ∈ R.

2

(cid:20)

(cid:21)

(3)

directionally-unbiased updates  like it is common among SGD-type methods. It holds
Eik∼pk

[f (xk+1) | xk]

(1)≤ Eik∼pk

(∇ik f (xk))2 | xk

f (xk) − αk
[pk]ik
= f (xk) − αk (cid:107)∇f (xk)(cid:107)2

2 +

(∇ik f (xk))2 +
n(cid:88)

Liα2
k
2[pk]i

i=1

Lik α2
k
2[pk]2
ik

(∇if (xk))2 .

In adaptive strategies we have the freedom to chose both variables αk and pk as we like. We therefore
propose to chose them in such a way that they minimize the upper bound (3) in order to maximize the
expected progress. The optimal pk in (3) is independent of αk  but the optimal αk depends on pk.
We can state the following useful observation.
Lemma 2.1. If αk = αk(pk) is the minimizer of (3)  then xk+1 := xk− αk
∇ik f (xk)eik satisﬁes
[pk]ik
(cid:107)∇f (xk)(cid:107)2
2 .

[f (xk+1) | xk] ≤ f (xk) − αk(pk)

Eik∼pk

(4)

2

Consider two examples. In the ﬁrst one we pick a sub-optimal  but very common [18] distribution:
Example 2.2 (Li-based sampling). Let pL ∈ ∆n deﬁned as [pL]i = Li
Tr[L] for i ∈ [n]  where
L = diag(L1  . . .   Ln). Then αk(pL) = 1

Tr[L] .

The distribution pL is often referred to as (ﬁxed) importance sampling. In the special case when
Li = L for all i ∈ [n]  this boils down to uniform sampling.
Example 2.3 (Optimal sampling2). Equation (3) is minimized for probabilities [p(cid:63)

k]i =

√
Li|∇if (xk)|
(cid:107)√
L∇f (xk)(cid:107)1

and αk(p(cid:63)

k) =

(cid:107)∇f (xk)(cid:107)2
(cid:107)√
L∇f (xk)(cid:107)2

2

1

. Observe

Tr[L] ≤ αk(p(cid:63)

k) ≤ 1

1

Lmin

  where Lmin := mini∈[n] Li.

Lemma 2.4. Deﬁne V (p  x) :=(cid:80)n

To prove this result  we rely on the following Lemma—the proof of which  as well as for the claims
above  is deferred to Section A.1 of the appendix. Here |·| is applied entry-wise.
. Then arg minp∈∆n V (p  x) =

Li[x]2
i

.

i=1

[p]i

|√
Lx|
(cid:107)√
Lx(cid:107)1

The ideal adaptive algorithm. We propose to chose the stepsize and the sampling distribution for
CD as in Example 2.3. One iteration of the resulting CD method is illustrated in Algorithm 1. Our
bounds on the expected one-step progress can be used to derive convergence rates of this algorithm
with the standard techniques. This is exempliﬁed in Appendix A.1. In the next Section 3 we develop
a practical variant of the ideal algorithm.

Efﬁciency gain. By comparing the estimates provided in the examples above  we see that the
expected progress of the proposed method is always at least as good as for the ﬁxed sampling. For
instance in the special case where L = Li for i ∈ [n]  the Li-based sampling is just uniform sampling
with αk(punif ) = 1
  which can be n times larger than
αk(punif ). The expected one-step progress in this extreme case coincides with the one-step progress
of steepest coordinate descent [20].

Ln. On the other hand αk(p(cid:63)

(cid:107)∇f (xk)(cid:107)2
L(cid:107)∇f (xk)(cid:107)2

k) =

1

2

2.2 SGD with Adaptive Sampling

(cid:80)n

SGD methods are applicable to objective functions which decompose as a sum

f (x) = 1
n

(5)
with each fi : Rd → R convex. In previous work [22  36  37] is has been argued that the following
gradient-based sampling [ ˜p(cid:63)
is optimal in the sense that it maximizes the
expected progress (3). Zhao and Zhang [36] derive complexity estimates for composite functions.
For non-composite functions it becomes easier to derive the complexity estimate. For completeness 
we add this simpler proof in Appendix A.2.

(cid:80)n
(cid:107)∇fi(xk)(cid:107)2
i=1(cid:107)∇fi(xk)(cid:107)2

i=1 fi(x)

k]i =

2Here “optimal” refers to the fact that p(cid:63)

k is optimal with respect to the given model (1) of the objective

function. If the model is not accurate  there might exist a sampling that yields larger expected progress on f.

3

Algorithm 1 Optimal sampling
Compute ∇f (xk)

(compute full gradient)

(deﬁne optimal sampling)
k) as in Example 2.3

k  α(cid:63)

Deﬁne (p(cid:63)
ik ∼ p(cid:63)

k

xk+1 := xk − α(cid:63)
k
k]ik

[p(cid:63)

∇ik f (xk)

Algorithm 2 Proposed safe sampling
(update l.- and u.-bounds)

Update (cid:96)  u

(compute safe sampling)

Deﬁne ( ˆpk  ˆαk) as in (7)
ik ∼ ˆpk
Compute ∇ik f (xk)
xk+1 := xk − ˆαk
[ ˆpk]ik

∇ik f (xk)

Algorithm 3 Fixed sampling

(deﬁne ﬁxed sampling)

Deﬁne (pL  ¯α) as in Example 2.2
ik ∼ pL
Compute ∇ik f (xk)
xk+1 := xk − ¯α
[pL]ik

∇ik f (xk)

Figure 1: CD with different sampling strategies. Whilst Alg. 1 requires to compute the full gradient 
the compute operation in Alg. 2 is as cheap as for ﬁxed importance sampling  Alg. 3. Deﬁning the
safe sampling ˆpk requires O(n log n) time.

3 Safe Adaptive Importance Sampling with Limited Information

In the previous section we have seen that gradient-based sampling (Example 2.3) can yield a massive
speed-up compared to a static sampling distribution (Example 2.2). However  sampling according
k in CD requires the knowledge of the full gradient ∇f (xk) in each iteration. And likewise 
to p(cid:63)
sampling from ˜p(cid:63)
k in SGD requires the knowledge of the gradient norms of all components—both
these operations are in general inadmissible  i.e. the compute cost would void all computational
beneﬁts of the iterative (stochastic) methods over full gradient methods.
However  it is often possible to efﬁciently compute approximations of p(cid:63)
k instead. In contrast
to previous contributions  we here propose a safe way to compute such approximations. By this we
mean that our approximate sampling is provably never worse than static sampling  and moreover  we
show that our solution is the best possible with respect to the limited information at hand.

k or ˜p(cid:63)

(cid:21)

(cid:20)

3.1 An Optimization Formulation for Sampling
Formally  we assume that we have in each iteration access to two vectors (cid:96)k  uk ∈ Rn≥0 that
provide safe upper and lower bounds on either the absolute values of the gradient entries ([(cid:96)k]i ≤
|∇if (xk)| ≤ [uk]i) for CD  or of the gradient norms in SGD: ([(cid:96)k]i ≤ (cid:107)∇fi(xk)(cid:107)2 ≤ [uk]i). We
postpone the discussion of this assumption to Section 4  where we give concrete examples.
The minimization of the upper bound (3) amounts to the equivalent problem3

−αk (cid:107)ck(cid:107)2

α2
k
2

⇔ min
pk∈∆n

V (pk  ck)
(cid:107)ck(cid:107)2

2

min
αk

min
pk∈∆n

2 +

V (pk  ck)

(6)
where ck ∈ Rn represents the unknown true gradient. That is  with respect to the bounds (cid:96)k  uk 
we can write ck ∈ Ck := {x ∈ Rn : [(cid:96)k]i ≤ [x]i ≤ [uk]i  i ∈ [n]}. In Example 2.3 we derived the
optimal solution for a ﬁxed ck ∈ Ck. However  this is not sufﬁcient to ﬁnd the optimal solution for
an arbitrary ck ∈ Ck. Just computing the optimal solution for an arbitrary (but ﬁxed) ck ∈ Ck is
unlikely to yield a good solution. For instance both extreme cases ck = (cid:96)k and ck = uk (the latter
choice is quite common  cf. [36  23]) might be poor. This is demonstrated in the next example.

Example 3.1. Let (cid:96) = (1  2)(cid:62)  u = (2  3)(cid:62)  c = (2  2)(cid:62) and L1 = L2 = 1. Then V(cid:0) (cid:96)(cid:107)(cid:96)(cid:107)1

  c(cid:1) =

2  whereas for uniform sampling V(cid:0) c(cid:107)c(cid:107)1

2  V(cid:0) u(cid:107)u(cid:107)1

9

12 (cid:107)c(cid:107)2

4 (cid:107)c(cid:107)2
The proposed sampling. As a consequence of these observations  we propose to solve the follow-
ing optimization problem to ﬁnd the best sampling distribution with respect to Ck:

2.

  c(cid:1) = 25

  c(cid:1) = 2(cid:107)c(cid:107)2
(αk  pk) :=(cid:0) 1

(cid:1)  

  ˆpk

vk

(7)

vk := min
p∈∆n

max
c∈Ck

V (p  c)
(cid:107)c(cid:107)2

2

 

and to set

where ˆpk denotes a solution of (7). The resulting algorithm for CD is summarized in Alg. 2.
In the remainder of this section we discuss the properties of the solution ˆpk (Theorem 3.2) and how
such a solution can be efﬁciently be computed (Theorem 3.4  Algorithm 4).

3Although only shown here for CD  an equivalent optimization problem arises for SGD methods  cf. [36].

4

3.2 Proposed Sampling and its Properties
Theorem 3.2. Let ( ˆp  ˆc) ∈ ∆n × Rn≥0 denote a solution of (7). Then Lmin ≤ vk ≤ Tr [L] and

2

(i) max
c∈Ck

  ∀p ∈ ∆n;

V ( ˆp  c)
(cid:107)c(cid:107)2

≤ max
c∈Ck
(ii) V ( ˆp  c) ≤ Tr [L] · (cid:107)c(cid:107)2
( ˆp is always better than Li-based sampling)
Remark 3.3. In the special case Li = L for all i ∈ [n]  the Li-based sampling boils down to uniform
sampling (Example 2.2) and ˆp is better than uniform sampling: V ( ˆp  c) ≤ Ln(cid:107)c(cid:107)2

V (p  c)
(cid:107)c(cid:107)2
2  ∀c ∈ Ck.

( ˆp has the best worst-case guarantee)

2

2  ∀c ∈ Ck.

Proof. Property (i) is an immediate consequence of (7). Moreover  observe that the Li-based
sampling pL is a feasible solution in (7) with value V (pL c)

Lmin ≤ (cid:107)√
Lc(cid:107)2
(8)
(cid:107)c(cid:107)2
for all c ∈ Ck  thus vk ∈ [Lmin  Tr [L]] and (ii) follows. We prove inequality (∗) in the appendix  by
showing that min and max can be interchanged in (7).

≡ Tr [L] for all c ∈ Ck. Hence

(cid:107)c(cid:107)2
(∗)≤ V ( ˆp  ˆc)
(cid:107)ˆc(cid:107)2

≤ V ( ˆp  c)
(cid:107)c(cid:107)2

V (p  c)
(cid:107)c(cid:107)2

(7)≤ max
c∈Ck

2.4= min
p∈∆n

= Tr [L]  

V (pL  c)

(cid:107)c(cid:107)2

2

1

2

2

2

2

2

√

A geometric interpretation. We show in Appendix B that the optimization problem (7) can
  where [l]i = Li for i ∈ [n].
equivalently be written as
The maximum is thus attained for vectors c ∈ Ck that minimize the angle with the vector l.
Theorem 3.4. Let c ∈ Ck  p =

(cid:104)√
l c(cid:105)
(cid:107)c(cid:107)2
2 · (cid:107)√
Lc(cid:107)−1

and denote m = (cid:107)c(cid:107)2

(cid:107)√
Lc(cid:107)1
(cid:107)c(cid:107)2

vk = maxc∈Ck

= maxc∈Ck

1 . If

√
(cid:107)√
Lc
Lc(cid:107)1

[uk]i

√
[(cid:96)k]i

[c]i =

if [uk]i ≤ √
if [(cid:96)k]i ≥ √

Lim  
Lim  

Lim otherwise 

∀i ∈ [n]  

(9)

then (p  c) is a solution to (7). Moreover  such a solution can be computed in time O(n log n).

Proof. This can be proven by examining the optimality conditions of problem (7). This is deferred to
Section B.1 of the appendix. A procedure that computes such a solution is depicted in Algorithm 4.
The algorithm makes extensive use of (9). For simplicity  assume ﬁrst L = In for now. In each
iteration t   a potential solution vector ct is proposed  and it is veriﬁed whether this vector satisﬁes all
optimality conditions. In Algorithm 4  ct is just implicit  with [ct]i = [c]i for decided indices i ∈ D
Lm]i for undecided indices i /∈ D. After at most n iterations a valid solution is found.
and [ct]i = [
L−1uk by their magnitude  at most a linear number of
By sorting the components of
inequality checks in (9) have to be performed in total. Hence the running time is dominated by the
O(n log n) complexity of the sorting algorithm. A formal proof is given in the appendix.

L−1(cid:96)k and

√

√

√

L−1u)  m = max((cid:96)sort)

√

√

if [(cid:96)sort](cid:96) > m then

L−1(cid:96))  usort := sort_asc(

√
Set corresponding [c]index := [
√
Set corresponding [c]index := [

Algorithm 4 Computing the Safe Sampling for Gradient Information (cid:96)  u
1: Input: 0n ≤ (cid:96) ≤ u  L  Initialize: c = 0n  u = 1  (cid:96) = n  D = ∅.
2: (cid:96)sort := sort_asc(
3: while u ≤ (cid:96) do
4:
5:
6:
7:
8:
9:
2 · (cid:107)√
10:
11: m := (cid:107)c(cid:107)2
√
12: end while
Lim for all i /∈ D and Return
13: Set [c]i :=

else if [usort]u < m then

Lc(cid:107)−1

break

end if

c  p =

(cid:16)

else

  v =

1

√
(cid:107)√
Lc
Lc(cid:107)1

(largest undecided lower bound is violated)

L(cid:96)sort](cid:96); (cid:96) := (cid:96) − 1; D := D ∪ {index}
Lusort]u; u := u + 1; D := D ∪ {index}

(smallest undecided upper bound is violated)

(no constraints are violated)

(update m as in (9))

(cid:17)

(cid:107)√
Lc(cid:107)2
(cid:107)c(cid:107)2

1

2

5

Competitive Ratio. We now compare the proposed sampling distribution ˆpk with the optimal
sampling solution in hindsight. We know that if the true (gradient) vector ˜c ∈ Ck would be given to
us  then the corresponding optimal probability distribution would be p(cid:63)(˜c) =
(Example 2.3).
Thus  for this ˜c we can now analyze the ratio V ( ˆpk ˜c)
V (p(cid:63)(˜c) ˜c). As we are interested in the worst case ratio
among all possible candidates ˜c ∈ Ck  we deﬁne
V ( ˆp  c)

√
(cid:107)√
L˜c
L˜c(cid:107)1

(10)

ρk := max
c∈Ck
(cid:107)√
Lc(cid:107)2
(cid:107)c(cid:107)2

1

= max
c∈Ck

(cid:107)√

V ( ˆp  c)
Lc(cid:107)2

.

V (p(cid:63)(c)  c)
. Then Lmin ≤ wk ≤ vk  and ρk ≤ vk

1

(≤ vk

2

Lemma 3.5. Let wk := minc∈Ck
Lemma 3.6. Let γ ≥ 1. If [Ck]i ∩ γ[Ck]i = ∅ and γ−1[Ck]i ∩ [Ck]i = ∅ for all i ∈ [n] (here [Ck]i
denotes the projection on the i-th coordinate)  then ρk ≤ γ4.
These two lemma provide bounds on the competitive ratio. Whilst Lemma 3.6 relies on a relative
accuracy condition  Lemma 3.5 can always be applied. However  the corresponding minimization
problem is non-convex. Note that knowledge of ρk is not needed to run the algorithm.

Lmin

).

wk

4 Example Safe Gradient Bounds

In this section  we argue that for a large class of objective functions of interest in machine learning 
suitable safe upper and lower bounds (cid:96)  u on the gradient along every coordinate direction can be
estimated and maintained efﬁciently during optimization. A similar argument can be given for the
efﬁcient approximation of component wise gradient norms in ﬁnite sum objective based stochastic
gradient optimization.
As the guiding example  we will here showcase the training of generalized linear models (GLMs) as
e.g. in regression  classiﬁcation and feature selection. These models are formulated in terms of a
given data matrix A ∈ Rd×n with columns ai ∈ Rd for i ∈ [n].

form f (x) := h(Ax) +(cid:80)n

Coordinate Descent - GLMs with Arbitrary Regularizers. Consider general objectives of the
i=1 ψi([x]i) with an arbitrary convex separable regularizer term given
by the ψi : R → R for i ∈ [n]. A key example is when h : Rd → R describes the least-squares
2 for a b ∈ Rd. Using that this h is twice differentiable
regression objective h(Ax) = 1
with ∇2h(Ax) = In  it is easy to see that we can track the evolution of all gradient entries  when
performing CD steps  as follows:

2 (cid:107)Ax − b(cid:107)2

∀i (cid:54)= ik .

∇if (xk+1) − ∇if (xk) = γk(cid:104)ai  aik(cid:105)  

(11)
for ik being the coordinate changed in step k (here we also used the separability of the regularizer).
Therefore  all gradient changes can be tracked exactly if the inner products of all datapoints are
available  or approximately if those inner products can be upper and lower bounded. For computa-
tional efﬁciency  we in our experiments simply use Cauchy-Schwarz |(cid:104)ai  aik(cid:105)| ≤ (cid:107)ai(cid:107)·(cid:107)aik(cid:107). This
results in safe upper and lower bounds [(cid:96)k+1]i ≤ ∇if (xk+1) ≤ [uk+1]i for all inactive coordinates
i (cid:54)= ik. (For the active coordinate ik itself one observes the true value without uncertainty). These
bounds can be updated in linear time O(n) in every iteration.
For general smooth h (again with arbitrary separable regularizers ψi)  (11) can readily be extended to
hold [32  Lemma 4.1]  the inner product change term becoming (cid:104)ai ∇2f (A ˜x)aik(cid:105) instead  when
assuming h is twice-differentiable. Here ˜x will be an element of the line segment [xk  xk+1].

(cid:80)n
Stochastic Gradient Descent - GLMs. We now present a similar result for ﬁnite sum problems (5)
i=1 hi(a(cid:62)
for the use in SGD based optimization  that is f (x) := 1
n
Lemma 4.1. Consider f : Rd → R as above  with twice differentiable hi : R → R. Let xk  xk+1 ∈
Rd denote two successive iterates of SGD  i.e. xk+1 := xk − ηk aik∇hik (a(cid:62)
xk) = xk + γk aik.
Then there exists ˜x ∈ Rd on the line segment between xk and xk+1  ˜x ∈ [xk  xk+1] with

i=1 fi(x) = 1
n

(cid:80)n

i x).

ik

∇fi(xk+1) − ∇fi(xk) = γk ∇2hi(a(cid:62)

i ˜x) (cid:104)ai  aik(cid:105) ai  

∀ i (cid:54)= ik .

(12)

6

This leads to safe upper and lower bounds for the norms of the partial gradient  [(cid:96)k]i ≤ (cid:107)∇fi(xk)(cid:107)2 ≤
[uk]i  that can be updated in linear time O(n)  analogous to the coordinate case discussed above.4
We note that there are many other ways to track safe gradient bounds for relevant machine learn-
ing problems  including possibly more tight ones. We here only illustrate the simplest variants 
highlighting the fact that our new sampling procedure works for any safe bounds (cid:96)  u.

Computational Complexity.
In this section  we have demonstrated how safe upper and lower
bounds (cid:96)  u on the gradient information can be obtained for GLMs  and argued that these bounds can
be updated in time O(n) per iteration of CD and SGD. The computation of the proposed sampling
takes O(n log n) time (Theorem 3.4). Hence  the introduced overhead in Algorithm 2 compared
to ﬁxed sampling (Algorithm 3) is of the order O(n log n) in every iteration. The computation of
one coordinate of the gradient  ∇ik f (xk)  takes time Θ(d) for general data matrices. Hence  when
d = Ω(n)  the introduced overhead reduces to O(log n) per iteration.

5 Empirical Evaluation

In this section we evaluate the empirical performance of our proposed adaptive sampling scheme on
relevant machine learning tasks. In particular  we illustrate performance on generalized linear models
with L1 and L2 regularization  as of the form (5) 

n(cid:88)

i=1

min
x∈Rd

1
n

hi(a(cid:62)

i x) + λ · r(x)

(13)

We use square loss  squared hinge loss as well as logistic loss for the data ﬁtting terms hi  and
(cid:107)x(cid:107)1 and (cid:107)x(cid:107)2
2 for the regularizer r(x). The datasets used in the evaluation are rcv1  real-sim and
news20.5 The rcv1 dataset consists of 20 242 samples with 47 236 features  real-sim contains 72 309
datapoints and 20 958 features and news20 contains 19 996 datapoints and 1 355 191 features. For
all datasets we set unnormalized features with all the non-zero entries set to 1 (bag-of-words features).
By real-sim’ and rcv1’ we denote a subset of the data chosen by randomly selecting 10 000 features
and 10 000 datapoints. By news20’ we denote a subset of the data chose by randomly selecting
15% of the features and 15% of the datapoints. A regularization parameter λ = 0.1 is used for all
experiments.
Our results show the evolution of the optimization objective over time or number of epochs (an epoch
corresponding to n individual updates). To compute safe lower and upper bounds we use the methods
presented in Section 4 with no special initialization  i.e. (cid:96)0 = 0n  u0 = ∞n.
Coordinate Descent.
Ln (denoted
as “small”) vs.
the time varying optimal stepsize (denoted as “big”) as discussed in Section 2.
Results are shown for optimal sampling p(cid:63)
k)  cf. Example 2.3)  our
proposed sampling ˆpk (with optimal stepsize αk( ˆpk) = v−1
k   cf. (7)) and uniform sampling (with
optimal stepsize αk(pL) = 1
Ln  as here L = LIn  cf. Example 2.2). As the experiment aligns
with theory—conﬁrming the advantage of the varying “big” stepsizes—we only show the results for
Algorithms 1–3 in the remaining plots.
Performance for squared hinge loss  as well as logistic regression with L1 and L2 regularization is
presented in Figure 3 and Figure 4 respectively. In Figures 5 and 6 we report the iteration complexity
vs. accuracy as well as timing vs. accuracy results on the full dataset for coordinate descent with
square loss and L1 (Lasso) and L2 regularization (Ridge).

In Figure 2 we compare the effect of the ﬁxed stepsize αk = 1

k (with optimal stepsize αk(p(cid:63)

Theoretical Sampling Quality. As part of the CD performance results in Figures 2–6 we include
an additional evolution plot on the bottom of each ﬁgure to illustrate the values vk which determine
the stepsize (ˆαk = v−1
k ) for the proposed Algorithm 2 (blue) and the optimal stepsizes of Algorithm 1
(black) which rely on the full gradient information. The plots show the normalized values
Tr[L]  i.e.
vk
the relative improvement over Li-based importance sampling. The results show that despite only
relying on very loose safe gradient bounds  the proposed adaptive sampling is able to strongly beneﬁt
from the additional information.

4Here we use the efﬁcient representation ∇fi(x) = θ(x) · ai for θ(x) ∈ R.
5All data are available at www.csie.ntu.edu.tw/˜cjlin/libsvmtools/datasets/

7

(a) rcv1’  L1 reg.

(b) rcv1’  L2 reg.

(a) rcv1’  L1 reg.

(b) real-sim’  L2 reg.

Figure 2: (CD  square loss) Fixed vs. adaptive
sampling strategies  and dependence on stepsizes.
With “big” αk = v−1
Tr[L].

and “small” αk = 1

k

Figure 3: (CD  squared hinge loss) Function
value vs. number of iterations for optimal step-
size αk = v−1
k .

(a) rcv1’  L1 reg.

(b) rcv1’  L2 reg.

(c) real-sim’  L1 reg.

(d) real-sim’  L2 reg.

Figure 4: (CD  logistic loss) Function value vs. number of iterations for different sampling strategies.
Bottom: Evolution of the value vk which determines the optimal stepsize (ˆαk = v−1
k ). The plots
Tr[L]  i.e. the relative improvement over Li-based importance sampling.
show the normalized values
vk

(a) rcv1  L1 reg.

(b) real-sim  L1 reg.

(a) real-sim  L1 reg.

(b) real-sim  L2 reg.

Figure 5: (CD  square loss) Function value vs.
number of iterations on the full datasets.

Figure 6: (CD  square loss) Function value vs.
clock time on the full datasets. (Data for the
optimal sampling omitted  as this strategy is not
competitive time-wise.)

(a) rcv1’  L1 reg.

(b) rcv1’  L2 reg.

(c) real-sim’  L1 reg.

(d) real-sim’  L2 reg.

Figure 7: (SGD  square loss) Function value vs. number of iterations.

(a) news20’  L1 reg.

(a) news20’  L1 reg.

Figure 8: (SGD  square loss) Function value vs.
number of iterations.

Figure 9: (SGD square loss) Function value vs.
clock time.

8

EpochsUniformProposed (big step)Proposed (small step)012561.000.990.980.970.960.950.94f(x )vkk100-1-2-3-4Epochs01256Optimal (big step)Optimal (small step)1.000.950.900.85f(x )vkk100-1-2-3-40.980.960.940.920.900.880.861.00f(x )vkk100-1-2-3-4Epochs01256UniformProposedOptimalUniformProposedOptimalf(x )vkkEpochs00.512.531.000.900.800.70100-1-2-3-40.950.850.750.65f(x )vkk100-1-2-3-4Epochs01256UniformProposedOptimal6.906.856.806.750.1 xEpochs01256UniformProposedOptimal0.690.680.670.66f(x )vkk100-1-2-3-4Epochs00.512.53UniformProposedOptimal0.690.680.670.660.650.64f(x )vkk100-1-2-3-4UniformProposedOptimalEpochs00.512.530.690.680.670.660.650.640.63f(x )vkk100-1-2-3-4UniformProposedOptimalEpochs00.511.533.51.000.950.900.850.80f(x )vkk100-1-2-3-4UniformProposedOptimalEpochs00.5121.000.950.900.850.800.750.70f(x )vkk100-1-2-3-4Time0241461612UniformProposed1.000.950.900.850.800.75f(x )vkk100-1-2-3-4UniformProposed1.000.950.900.850.800.75Time0241461612f(x )vkk100-1-2-3-465605550454035UniformProposedOptimalEpochs00.512.52UniformProposedOptimalEpochs00.512908070605040UniformProposedOptimalEpochs00.512.52140120100806040UniformProposedOptimalEpochs00.512.5210080604020UniformProposedOptimalEpochs0124765432UniformProposed40353025201510Time05102520Stochastic Gradient Descent. Finally  we also evaluate the performance of our approach when
used within SGD with L1 and L2 regularization and square loss. In Figures 7–8 we report the
iteration complexity vs. accuracy results and in Figure 9 the timing vs. accuracy results. The time
units in Figures 6 and 9 are not directly comparable  as the experiments were conducted on different
machines.
We observe that on all three datasets SGD with the optimal sampling performs only slightly better than
uniform sampling. This is in contrast with the observations for CD  where the optimal sampling yields
a signiﬁcant improvement. Consequently  the effect of the proposed sampling is less pronounced in
the three SGD experiments.

Summary. The main ﬁndings of our experimental study can be summarized as follows:

• Adaptive importance sampling signiﬁcantly outperforms ﬁxed importance sampling
in iterations and time. The results show that (i) convergence in terms of iterations is almost
as good as for the optimal (but not efﬁciently computable) gradient-based sampling and
(ii) the introduced computational overhead is small enough to outperform ﬁxed importance
sampling in terms of total computation time.
• Adaptive sampling requires adaptive stepsizes. The adaptive stepsize strategies of Algo-
rithms 1 and 2 allow for much faster convergence than conservative ﬁxed-stepsize strategies.
In the experiments  the measured value vk was always signiﬁcantly below the worst case
estimate  in alignment with the observed convergence.
• Very loose safe gradient bounds are sufﬁcient. Even the bounds derived from the the very
naïve gradient information obtained by estimating scalar products resulted in signiﬁcantly
better sampling than using no gradient information at all. Further  no initialization of the
gradient estimates is needed (at the beginning of the optimization process the proposed
adaptive method performs close to the ﬁxed sampling but accelerates after just one epoch).

6 Conclusion

In this paper we propose a safe adaptive importance sampling scheme for CD and SGD algorithms.
We argue that optimal gradient-based sampling is theoretically well justiﬁed. To make the computation
of the adaptive sampling distribution computationally tractable  we rely on safe lower and upper
bounds on the gradient. However  in contrast to previous approaches  we use these bounds in a novel
way: in each iteration  we formulate the problem of picking the optimal sampling distribution as a
convex optimization problem and present an efﬁcient algorithm to compute the solution. The novel
sampling provably performs better than any ﬁxed importance sampling—a guarantee which could
not be established for previous samplings that were also derived from safe lower and upper bounds.
The computational cost of the proposed scheme is of the order O(n log n) per iteration—this is on
many problems comparable with the cost to evaluate a single component (coordinate  sum-structure)
of the gradient  and the scheme can thus be implemented at no extra computational cost. This is
veriﬁed by timing experiments on real datasets.
We discussed one simple method to track the gradient information in GLMs during optimization.
However  we feel that the machine learning community could proﬁt from further research in that
direction  for instance by investigating how such safe bounds can efﬁciently be maintained on more
complex models. Our approach can immediately be applied when the tracking of the gradient is
delegated to other machines in a distributed setting  like for instance in [1].

References
[1] Guillaume Alain  Alex Lamb  Chinnadhurai Sankar  Aaron Courville  and Yoshua Bengio. Variance

Reduction in SGD by Distributed Importance Sampling. arXiv.org  February 2015.

[2] Zeyuan Allen-Zhu  Zheng Qu  Peter Richtárik  and Yang Yuan. Even Faster Accelerated Coordinate
Descent Using Non-Uniform Sampling. In ICML 2017 - Proceedings of the 34th International Conference
on Machine Learning  pages 1110–1119. June 2016.

[3] Ichiro Takeuchi Atsushi Shibagaki. Stochastic Primal Dual Coordinate Method with Non-Uniform

Sampling Based on Optimality Violations. arXiv.org  October 2017.

9

[4] Stephen P Boyd and Lieven Vandenberghe. Convex optimization. Cambridge University Press  2004.

[5] Dominik Csiba  Zheng Qu  and Peter Richtárik. Stochastic Dual Coordinate Ascent with Adaptive
Probabilities. In ICML 2015 - Proceedings of the 32th International Conference on Machine Learning 
February 2015.

[6] Dominik Csiba and Peter Richtárik. Importance Sampling for Minibatches. arXiv.org  February 2016.

[7] Jerome Friedman  Trevor Hastie  Holger Höﬂing  and Robert Tibshirani. Pathwise coordinate optimization.

The Annals of Applied Statistics  1(2):302–332  December 2007.

[8] Jerome Friedman  Trevor Hastie  and Robert Tibshirani. Regularization Paths for Generalized Linear

Models via Coordinate Descent. Journal of Statistical Software  33(1):1–22  2010.

[9] Wenjiang J. Fu. Penalized regressions: The bridge versus the lasso. Journal of Computational and

Graphical Statistics  7(3):397–416  1998.

[10] Xi He and Martin Takáˇc. Dual Free Adaptive Mini-batch SDCA for Empirical Risk Minimization.

arXiv.org  October 2015.

[11] Cho-Jui Hsieh  Kai-Wei Chang  Chih-Jen Lin  S Sathiya Keerthi  and S Sundararajan. A Dual Coordinate
Descent Method for Large-scale Linear SVM. In ICML 2008 - the 25th International Conference on
Machine Learning  pages 408–415  New York  USA  2008. ACM Press.

[12] Hidetoshi Komiya. Elementary proof for sion’s minimax theorem. Kodai Math. J.  11(1):5–7  1988.

[13] Simon Lacoste-Julien  Mark Schmidt  and Francis Bach. A simpler approach to obtaining an O(1/t)

convergence rate for projected stochastic subgradient descent. arXiv.org  December 2012.

[14] Jun Liu  Zheng Zhao  Jie Wang  and Jieping Ye. Safe Screening with Variational Inequalities and Its
Application to Lasso. In ICML 2014 - Proceedings of the 31st International Conference on Machine
Learning  pages 289–297  2014.

[15] Eugene Ndiaye  Olivier Fercoq  Alexandre Gramfort  and Joseph Salmon. Gap Safe screening rules for

sparsity enforcing penalties. JMLR  2017.

[16] Deanna Needell  Rachel Ward  and Nathan Srebro. Stochastic Gradient Descent  Weighted Sampling  and
the Randomized Kaczmarz algorithm. In NIPS 2014 - Advances in Neural Information Processing Systems
27  pages 1017–1025  2014.

[17] A. Nemirovski  A. Juditsky  G. Lan  and A. Shapiro. Robust stochastic approximation approach to

stochastic programming. SIAM Journal on Optimization  19(4):1574–1609  2009.

[18] Yurii Nesterov. Efﬁciency of Coordinate Descent Methods on Huge-Scale Optimization Problems. SIAM

Journal on Optimization  22(2):341–362  2012.

[19] Yurii Nesterov and Sebastian U. Stich. Efﬁciency of the accelerated coordinate descent method on

structured optimization problems. SIAM Journal on Optimization  27(1):110–123  2017.

[20] Julie Nutini  Mark W Schmidt  Issam H Laradji  Michael P Friedlander  and Hoyt A Koepke. Coordinate
Descent Converges Faster with the Gauss-Southwell Rule Than Random Selection. In ICML  pages
1632–1641  2015.

[21] Anton Osokin  Jean-Baptiste Alayrac  Isabella Lukasewitz  Puneet K. Dokania  and Simon Lacoste-Julien.
Minding the gaps for block frank-wolfe optimization of structured svms. In Proceedings of the 33rd
International Conference on International Conference on Machine Learning - Volume 48  ICML’16  pages
593–602. JMLR.org  2016.

[22] Guillaume Papa  Pascal Bianchi  and Stéphan Clémençon. Adaptive Sampling for Incremental Optimization
Using Stochastic Gradient Descent. ALT 2015 - 26th International Conference on Algorithmic Learning
Theory  pages 317–331  2015.

[23] Dmytro Perekrestenko  Volkan Cevher  and Martin Jaggi. Faster Coordinate Descent via Adaptive
Importance Sampling. In AISTATS 2017 - Proceedings of the 20th International Conference on Artiﬁcial
Intelligence and Statistics  volume 54  pages 869–877. PMLR  20–22 Apr 2017.

[24] Zheng Qu  Peter Richtárik  and Tong Zhang. Randomized Dual Coordinate Ascent with Arbitrary Sampling.

arXiv.org  November 2014.

10

[25] Peter Richtárik and Martin Takáˇc. On optimal probabilities in stochastic coordinate descent methods.

Optimization Letters  10(6):1233–1243  2016.

[26] Mark Schmidt  Reza Babanezhad  Mohamed Ahmed  Aaron Defazio  Ann Clifton  and Anoop Sarkar.
Non-Uniform Stochastic Average Gradient Method for Training Conditional Random Fields. In AISTATS
2015 - Proceedings of the Eighteenth International Conference on Artiﬁcial Intelligence and Statistics 
volume 38  pages 819–828. PMLR  09–12 May 2015.

[27] Shai Shalev-Shwartz  Yoram Singer  Nathan Srebro  and Andrew Cotter. Pegasos: Primal Estimated

Sub-Gradient Solver for SVM. Mathematical Programming  127(1):3–30  October 2010.

[28] Shai Shalev-Shwartz and Ambuj Tewari. Stochastic Methods for l1-regularized Loss Minimization. JMLR 

12:1865–1892  June 2011.

[29] Shai Shalev-Shwartz and Tong Zhang. Stochastic Dual Coordinate Ascent Methods for Regularized Loss

Minimization. JMLR  14:567–599  February 2013.

[30] Maurice Sion. On general minimax theorems. Paciﬁc Journal of Mathematics  8(1):171–176  1958.

[31] S. U. Stich  C. L. Müller  and B. Gärtner. Variable metric random pursuit. Mathematical Programming 

156(1):549–579  Mar 2016.

[32] Sebastian U. Stich  Anant Raj  and Martin Jaggi. Approximate steepest coordinate descent. In Doina
Precup and Yee Whye Teh  editors  ICML 2017 - Proceedings of the 34th International Conference on
Machine Learning  volume 70  pages 3251–3259. PMLR  06–11 Aug 2017.

[33] Thomas Strohmer and Roman Vershynin. A randomized kaczmarz algorithm with exponential convergence.

Journal of Fourier Analysis and Applications  15(2):262  2008.

[34] Paul Tseng and Sangwoon Yun. A coordinate gradient descent method for nonsmooth separable minimiza-

tion. Mathematical Programming  117(1):387–423  2009.

[35] Stephen J Wright. Coordinate descent algorithms. Mathematical Programming  151(1):3–34  2015.

[36] Peilin Zhao and Tong Zhang. Stochastic optimization with importance sampling for regularized loss
minimization. In ICML 2015 - Proceedings of the 32nd International Conference on Machine Learning 
volume 37  pages 1–9. PMLR  07–09 Jul 2015.

[37] Rong Zhu. Gradient-based sampling: An adaptive importance sampling for least-squares. In NIPS -

Advances in Neural Information Processing Systems 29  pages 406–414. 2016.

11

,Sebastian Stich
Anant Raj
Martin Jaggi