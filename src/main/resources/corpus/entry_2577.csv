2016,Improved Error Bounds for Tree Representations of Metric Spaces,Estimating optimal phylogenetic trees or hierarchical clustering trees from metric data is an important problem in evolutionary biology and data analysis. Intuitively  the goodness-of-fit of a metric space to a tree depends on its inherent treeness  as well as other metric properties such as intrinsic dimension. Existing algorithms for embedding metric spaces into tree metrics provide distortion bounds depending on cardinality. Because cardinality is a simple property of any set  we argue that such bounds do not fully capture the rich structure endowed by the metric. We consider an embedding of a metric space into a tree proposed by Gromov. By proving a stability result  we obtain an improved additive distortion bound depending only on the hyperbolicity and doubling dimension of the metric. We observe that Gromov's method is dual to the well-known single linkage hierarchical clustering (SLHC) method. By means of this duality  we are able to transport our results to the setting of SLHC  where such additive distortion bounds were previously unknown.,Improved Error Bounds for Tree Representations of

Metric Spaces

Samir Chowdhury

Department of Mathematics
The Ohio State University

Columbus  OH 43210

chowdhury.57@osu.edu

Department of Computer Science and Engineering

Facundo Mémoli

Department of Mathematics

The Ohio State University

Columbus  OH 43210
memoli@math.osu.edu

Department of Computer Science and Engineering

Zane Smith

The Ohio State University

Columbus  OH 43210
smith.9911@osu.edu

Abstract

Estimating optimal phylogenetic trees or hierarchical clustering trees from metric
data is an important problem in evolutionary biology and data analysis. Intuitively 
the goodness-of-ﬁt of a metric space to a tree depends on its inherent treeness  as
well as other metric properties such as intrinsic dimension. Existing algorithms for
embedding metric spaces into tree metrics provide distortion bounds depending on
cardinality. Because cardinality is a simple property of any set  we argue that such
bounds do not fully capture the rich structure endowed by the metric. We consider
an embedding of a metric space into a tree proposed by Gromov. By proving a
stability result  we obtain an improved additive distortion bound depending only on
the hyperbolicity and doubling dimension of the metric. We observe that Gromov’s
method is dual to the well-known single linkage hierarchical clustering (SLHC)
method. By means of this duality  we are able to transport our results to the setting
of SLHC  where such additive distortion bounds were previously unknown.

1

Introduction

Numerous problems in data analysis are formulated as the question of embedding high-dimensional
metric spaces into “simpler" spaces  typically of lower dimension. In classical multidimensional
scaling (MDS) techniques [18]  the goal is to embed a space into two or three dimensional Euclidean
space while preserving interpoint distances. Classical MDS is helpful in exploratory data analysis 
because it allows one to ﬁnd hidden groupings in amorphous data by simple visual inspection.
Generalizations of MDS exist for which the target space can be a tree metric space—see [13] for a
summary of some of these approaches  written from the point of view of metric embeddings. The
metric embeddings literature  which grew out of MDS  typically highlights the algorithmic gains
made possible by embedding a complicated metric space into a simpler one [13].
The special case of MDS where the target space is a tree has been of interest in phylogenetics for
quite some time [19  5]; the numerical taxonomy problem (NTP) is that of ﬁnding an optimal tree
embedding for a given metric space (X  dX )  i.e. a tree (X  tX ) such that the additive distortion 
deﬁned as (cid:107)dX − tX(cid:107)(cid:96)∞(X×X)  is minimal over all possible tree metrics on X. This problem turns
out to be NP-hard [3]; however  a 3-approximation algorithm exists [3]  and a variant of this problem 

30th Conference on Neural Information Processing Systems (NIPS 2016)  Barcelona  Spain.

that of ﬁnding an optimal ultrametric tree  can be solved in polynomial time [11]. An ultrametric
tree is a rooted tree where every point is equidistant from the root—for example  ultrametric trees
are the outputs of hierarchical clustering (HC) methods that show groupings in data across different
resolutions. A known connection between HC and MDS is that the output ultrametric of single linkage
hierarchical clustering (SLHC) is a 2-approximation to the optimal ultrametric tree embedding [16] 
thus providing a partial answer to the NTP. However  it appears that the existing line of work regarding
NTP does not address the question of quantifying the (cid:96)∞ distance between a metric (X  dX ) and its
optimal tree metric  or even the optimal ultrametric. More speciﬁcally  we can ask:
Question 1. Given a set X  a metric dX  and an optimal tree metric topt
X )  can one ﬁnd a nontrivial upper bound on (cid:107)dX − topt
uopt
depending on properties of the metric dX?

X (or an optimal ultrametric
X (cid:107)(cid:96)∞(X×X))

X (cid:107)(cid:96)∞(X×X) (resp. (cid:107)dX − uopt

The question of distortion bounds is treated from a different perspective in the discrete algorithms
literature. In this domain  tree embeddings are typically described with multiplicative distortion
bounds (described in §2) depending on the cardinality of the underlying metric space  along with
(typically) pathological counterexamples showing that these bounds are tight [4  10]. We remark
immediately that (1) multiplicative distortion is distinct from the additive distortion encountered
in the NTP  and (2) these embeddings are rarely used in machine learning  where HC and MDS
methods are the main workhorses. Moreover  such multiplicative distortion bounds do not take
two considerations into account: (1) the ubiquitousness of very large data sets means that a bound
dependent on cardinality is not desirable  and (2) “nice" properties such as low intrinsic dimensionality
or treeness of real-world datasets are not exploited in cardinality bounds.
We prove novel additive distortion bounds for two methods of tree embeddings: one into general
trees  and one into ultrametric trees. These additive distortion bounds take into account (1) whether
the data is treelike  and (2) whether the data has low doubling dimension  which is a measure of its
intrinsic dimension. Thus we prove an answer to Question 1 above  namely  that the approximation
error made by an optimal tree metric (or optimal ultrametric) can be bounded nontrivially.
Remark 1. The trivial upper bound is (cid:107)dX − topt
X (cid:107)(cid:96)∞(X×X) ≤ diam(X  dX ). To see this  observe
that any ultrametric is a tree  and that SLHC yields an ultrametric uX that is bounded above by dX.

An overview of our approach. A common measure of treeness is Gromov’s δ-hyperbolicity  which
is a local condition on 4-point subsets of a metric space. Hyperbolicity has been shown to be a useful
statistic for evaluating the quality of trees in [7]. The starting point for our work is a method used
by Gromov to embed metric spaces into trees  which we call Gromov’s embedding [12]. A known
result  which we call Gromov’s embedding theorem  is that if every 4-point subset of an n-point
metric space is δ-hyperbolic  then the metric space embeds into a tree with (cid:96)∞ distortion bounded
above by 2δ log2(2n). The proof proceeds by a linkage argument  i.e. by invoking the deﬁnition
of hyperbolicity at different scales along chains of points. By virtue of the embedding theorem 
one can argue that hyperbolicity is a measure of the “treeness" of a given metric space. It has been
shown in [1  2] that various real-world data sets  such as Internet latencies and biological  social  and
collaboration networks are inherently treelike  i.e. have low hyperbolicity. Thus  by Gromov’s result 
these real-world data sets can be embedded into trees with additive distortion controlled by their
respective cardinalities. The cardinality bound might of course be undesirable  especially for very
large data sets such as the Internet. However  it has been claimed without proof in [1] that Gromov’s
embedding can yield a 3-approximation to the NTP  independent of [3].
We note that the assumption of a metric input is not apparent in Gromov’s embedding theorem.
Moreover  the proof of the theorem does not utilize any metric property. This leads one to hope for
bounds where the dependence on cardinality is replaced by a dependence on some metric notion.
A natural candidate for such a metric notion is the doubling dimension of a space [15]  which has
already found applications in learning [17] and algorithm design [15]. In this paper  we present novel
upper bounds on the additive distortion of a Gromov embedding  depending only on the hyperbolicity
and doubling dimension of the metric space.
Our main tool is a stability theorem that we prove using a metric induced by a Voronoi partition. This
result is then combined with the results of Gromov’s linkage argument. Both the stability theorem
and Gromov’s theorem rely on the embedding satisfying a particular linkage condition  which can
be described as follows: for any embedding f : (X  dX ) → (X  tX )  and any x  x(cid:48) ∈ X  we have
tX (x  x(cid:48)) = maxc mini Ψ(xi  xi+1)  where c = {xi}k
i=0 is a chain of points joining x to x(cid:48) and Ψ

2

is some function of dX. A dual notion is to ﬂip the order of the max  min operations. Interestingly 
under the correct objective function Ψ  this leads to the well-studied notion of SLHC. By virtue of this
duality  the arguments of both the stability theorem and the scaling theorem apply in the SLHC setting.
We introduce a new metric space statistic that we call ultrametricity (analogous to hyperbolicity)  and
are then able to obtain novel lower bounds  depending only on doubling dimension and ultrametricity 
for the distortion incurred by a metric space when embedding into an ultrametric tree via SLHC.
We remark that just by virtue of the duality between Gromov’s embedding and the SLHC embedding 
it is possible to obtain a distortion bound for SLHC depending on cardinality. We were unable to
ﬁnd such a bound in the existing HC literature  so it appears that even the knowledge of this duality 
which bridges the domains of HC and MDS methods  is not prevalent in the community.
The paper is organized as follows. The main thrust of our work is explained in §1. In §2 we
develop the context of our work by highlighting some of the surrounding literature. We provide
all deﬁnitions and notation  including the Voronoi partition construction  in §3. In §4 we describe
Gromov’s embedding and present Gromov’s distortion bound in Theorem 3. Our contributions begin
with Theorem 4 in §4 and include all the results that follow: namely the stability results in §5  the
improved distortion bounds in §6  and the proof of tightness in §7.
The supplementary material contains (1) an appendix with proofs omitted from the body  (2) a
practical demonstration in §A where we apply Gromov’s embedding to a bitmap image of a tree
and show that our upper bounds perform better than the bounds suggested by Gromov’s embedding
theorem  and (3) Matlab .m ﬁles containing demos of Gromov’s embedding being applied to various
images of trees.

2 Related Literature

MDS is explained thoroughly in [18]. In metric MDS [18] one attempts to ﬁnd an embedding of the
data X into a low dimensional Euclidean space given by a point cloud Y ⊂ Rd (where often d = 2
or d = 3) such that the metric distortion (measured by the Frobenius norm of the difference of the
Gram matrices of X and Y ) is minimized. The most common non-metric variant of MDS is referred
to as ordinal embedding  and has been studied in [14].
A common problem with metric MDS is that when the intrinsic dimension of the data is higher than
the embedding dimension  the clustering in the original data may not be preserved [21]. One variant
of MDS that preserves clusters is the tree preserving embedding [20]  where the goal is to preserve
the single linkage (SL) dendrogram from the original data. This is especially important for certain
types of biological data  for the following reasons: (1) due to speciation  many biological datasets are
inherently “treelike"  and (2) the SL dendrogram is a 2-approximation to the optimal ultrametric tree
embedding [16]  so intuitively  preserving the SL dendrogram preserves the “treeness" of the data.
Preserving the treeness of a metric space is related to the notion of ﬁnding an optimal embedding into
a tree  which ties back to the numerical taxonomy problem. The SL dendrogram is an embedding of
a metric space into an ultrametric tree  and can be used to ﬁnd the optimal ultrametric tree [8].
The quality of an embedding is measured by computing its distortion  which has different deﬁnitions
in different domain areas. Typically  a tree embedding is deﬁned to be an injective map f : X → Y
between metric spaces (X  dX ) and (Y  tY )  where the target space is a tree. We have deﬁned the
additive distortion of a tree embedding in an (cid:96)∞ setting above  but (cid:96)p notions  for p ∈ [1 ∞)  can
also be deﬁned. Past efforts to embed a metric into a tree with low additive distortion are described
in [19  Chapter 7]. One can also deﬁne a multiplicative distortion [4  10]  but this is studied in the
domain of discrete algorithms and is not our focus in the current work.

3 Preliminaries on metric spaces  distances  and doubling dimension

A ﬁnite metric space (X  dX ) is a ﬁnite set X together with a function dX : X × X → R+
such that: (1) dX (x  x(cid:48)) = 0 ⇐⇒ x = x(cid:48)  (2) dX (x  x(cid:48)) = dX (x(cid:48)  x)  and (3) dX (x  x(cid:48)) ≤
dX (x  x(cid:48)(cid:48)) + dX (x(cid:48)(cid:48)  x(cid:48)) for any x  x(cid:48)  x(cid:48)(cid:48) ∈ X. A pointed metric space is a triple (X  dX   p)  where
(X  dX ) is a ﬁnite metric space and p ∈ X. All the spaces we consider are assumed to be ﬁnite.

3

For a metric space (X  dX )  the diameter is deﬁned to be diam(X  dX ) := maxx x(cid:48)∈X dX (x  x(cid:48)).
The hyperbolicity of (X  dX ) was deﬁned by Gromov [12] as follows:

hyp(X  dX ) :=

Ψhyp

X (x1  x2  x3  x4) : = 1
2

max

Ψhyp

x1 x2 x3 x4∈X

X (x1  x2  x3  x4)  where

(cid:16)
− max(cid:0)dX (x1  x3) + dX (x2  x4)  dX (x1  x4) + dX (x2  x3)(cid:1)(cid:17)

dX (x1  x2) + dX (x3  x4)

.

A tree metric space (X  tX ) is a ﬁnite metric space such that hyp(X  tX ) = 0 [19]. In our work  we
strengthen the preceding characterization of trees to the special class of ultrametric trees. Recall that
an ultrametric space (X  uX ) is a metric space satisfying the strong triangle inequality:

uX (x  x(cid:48)) ≤ max(uX (x  x(cid:48)(cid:48))  uX (x(cid:48)(cid:48)  x(cid:48)))  ∀x  x(cid:48)  x(cid:48)(cid:48) ∈ X.

Deﬁnition 1. We deﬁne the ultrametricity of a metric space (X  dX ) as:
X (x1  x2  x3)  where

X (x1  x2  x3) := dX (x1  x3) − max(cid:0)dX (x1  x2)  dX (x2  x3)(cid:1).

ult(X  dX ) := max

x1 x2 x3∈X

Ψult

Ψult

X

|dX (x  x(cid:48)) − d(cid:48)

X as follows:
X (x  x(cid:48))|.

We introduce ultrametricity to quantify the deviation of a metric space from being ultrametric. Notice
that (X  uX ) is an ultrametric space if and only if ult(X  uX ) = 0. One can verify that an ultrametric
space is a tree metric space.
We will denote the cardinality of a set X by writing |X|. Given a set X and two metrics dX   d(cid:48)
deﬁned on X × X  we denote the (cid:96)∞ distance between dX and d(cid:48)

X(cid:107)(cid:96)∞(X×X) := max
x x(cid:48)∈X
X(cid:107)∞ to mean (cid:107)dX−d(cid:48)

(cid:107)dX − d(cid:48)
We use the shorthand (cid:107)dX−d(cid:48)
X(cid:107)(cid:96)∞(X×X). We write ≈ to mean “approximately
equal to." Given two functions f  g : N → R  we will write f (cid:16) g to mean asymptotic tightness  i.e.
that there exist constants c1  c2 such that c1|f (n)| ≤ |g(n)| ≤ c2|f (n)| for sufﬁciently large n ∈ N.
Induced metrics from Voronoi partitions. A key ingredient of our stability result involves a
Voronoi partition construction. Given a metric space (X  dX ) and a subset A ⊆ X  possibly with its
{x1  . . .   xn}. For each 1 ≤ i ≤ n  we deﬁne (cid:101)Vi := {x ∈ X : dX (x  xi) ≤ minj(cid:54)=i dX (x  xj)} .
X on X × X using a Voronoi partition. First write A =
Then X =(cid:83)n
own metric dA  we can deﬁne a new metric dA
Then X =(cid:70)n

i=1(cid:101)Vi. Next we perform the following disjointiﬁcation trick:
V1 := (cid:101)V1  V2 := (cid:101)V2 \(cid:101)V1  . . .   Vn := (cid:101)Vn \(cid:0) n−1(cid:91)
(cid:101)Vi

i=1 Vi  a disjoint union of Voronoi cells Vi.

Next deﬁne the nearest-neighbor map η : X → A by η(x) = xi for each x ∈ Vi. The map η
simply sends each x ∈ X to its closest neighbor in A  up to a choice when there are multiple nearest
neighbors. Then we can deﬁne a new (pseudo)metric dA

X : X × X → R+ as follows:

(cid:1).

i=1

X (x  x(cid:48)) := dA(η(x)  η(x(cid:48))).
dA

X (x  x(cid:48)) = 0 if and only if x  x(cid:48) ∈ Vi for some 1 ≤ i ≤ n. Symmetry also holds  as

Observe that dA
does the triangle inequality.
A special case of this construction occurs when A is an ε-net of X endowed with a restriction of
the metric dX. Given a ﬁnite metric space (X  dX )  an ε-net is a subset X ε ⊂ X such that: (1)
for any x ∈ X  there exists s ∈ X ε such that dX (x  s) < ε  and (2) for any s  s(cid:48) ∈ X ε  we have
dX (s  s(cid:48)) ≥ ε [15]. For notational convenience  we write dε
X . In this case  we obtain:

X to refer to dX ε

(cid:107)dX − dε

X(cid:107)(cid:96)∞(X×X) = max
x x(cid:48)∈X
= max
1≤i j≤n
= max
1≤i j≤n
≤ max
1≤i j≤n

(cid:12)(cid:12)dX (x  x(cid:48)) − dε

X (x  x(cid:48))(cid:12)(cid:12)
(cid:12)(cid:12)dX (x  x(cid:48)) − dε
X (x  x(cid:48))(cid:12)(cid:12)
(cid:12)(cid:12)dX (x  x(cid:48)) − dX (xi  xj)(cid:12)(cid:12)
(cid:0)dX (x  xi) + dX (x(cid:48)  xj)(cid:1) ≤ 2ε.

max

x∈Vi x(cid:48)∈Vj

max

x∈Vi x(cid:48)∈Vj

max

x∈Vi x(cid:48)∈Vj

4

(1)

(cid:26)

n ∈ N : X ⊂ n(cid:91)

Covering numbers and doubling dimension. For a ﬁnite metric space (X  dX )  the open ball of
radius ε centered at x ∈ X is denoted B(x  ε). The ε-covering number of (X  dX ) is deﬁned as:

NX (ε) := min

B(xi  ε) for x1  . . .   xn ∈ X

.

i=1

Notice that the ε-covering number of X is always bounded above by the cardinality of an ε-net. A
related quantity is the doubling dimension ddim(X  dX ) of a metric space (X  dX )  which is deﬁned
to be the minimal value ρ such that any ε-ball in X can be covered by at most 2ρ ε/2-balls [15]. The
covering number and doubling dimension of a metric space (X  dX ) are related as follows:
Lemma 2. Let (X  dX ) be a ﬁnite metric space with doubling dimension bounded above by ρ > 0.

Then for all ε ∈ (0  diam(X)]  we have NX (ε) ≤(cid:0)8 diam(X)/ε(cid:1)ρ

.

(cid:27)

4 Duality between Gromov’s embedding and SLHC
Given a metric space (X  dX ) and any two points x  x(cid:48) ∈ X  we deﬁne a chain from x to x(cid:48) over X
as an ordered set of points in X starting at x and ending at x(cid:48):

c = {x0  x1  x2  . . .   xn : x0 = x  xn = x(cid:48)  xi ∈ X for all 0 ≤ i ≤ n} .

The set of all chains from x to x(cid:48) over X will be denoted CX (x  x(cid:48)). The cost of a chain c =
{x0 . . .   xn} over X is deﬁned to be costX (c) := max0≤i<n dX (xi  xi+1).
For any metric space (X  dX ) and any p ∈ X  the Gromov product of X with respect to p is a map
gX p : X × X → R+ deﬁned by:

(cid:0)dX (x  p) + dX (x(cid:48)  p) − dX (x  x(cid:48))(cid:1).

We can deﬁne a map gT

gX p(x  x(cid:48)) := 1
X p : X × X → R+ as follows:
gT
X p(x  x(cid:48))p := max
c∈CX (x x(cid:48))
This induces a new metric tX p : X × X → R+:

2

min

xi xi+1∈c

gX p(xi  xi+1).

tX p(x  x(cid:48)) := dX (x  p) + dX (x(cid:48)  p) − 2gT

X p(x  x(cid:48)).

Gromov observed that the space (X  tX p) is a tree metric space  and that tX p(x  x(cid:48)) ≤ dX (x  x(cid:48))
for any x  x(cid:48) ∈ X [12]. This yields the trivial upper bound:

(cid:107)dX − tX(cid:107)∞ ≤ diam(X  dX ).

The Gromov embedding T is deﬁned for any pointed metric space (X  dX   p) as T (X  dX   p) :=
(X  tX p). Note that each choice of p ∈ X will yield a tree metric tX p that depends  a priori  on p.
Theorem 3 (Gromov’s embedding theorem [12]). Let (X  dX   p) be an n-point pointed metric space 
and let (X  tX p) = T (X  dX   p). Then 

(cid:107)tX p − dX(cid:107)l∞(X×X) ≤ 2 log2(2n) hyp(X  dX ).

Gromov’s embedding is an MDS method where the target is a tree. We observe that its construction is
dual—in the sense of swapping max and min operations—to the construction of the ultrametric space
produced as an output of SLHC. Recall that the SLHC method H is deﬁned for any metric space
(X  dX ) as H(X  dX ) = (X  uX )  where uX : X × X → R+ is the ultrametric deﬁned below:

uX (x  x(cid:48)) := min

c∈CX (x x(cid:48))

costX (c).

As a consequence of this duality  we can bound the additive distortion of SLHC as below:
Theorem 4. Let (X  dX ) be an n-point metric space  and let (X  uX ) = H(X  dX ). Then we have:

(cid:107)dX − uX(cid:107)(cid:96)∞(X×X) ≤ log2(2n) ult(X  dX ).

Moreover  this bound is asymptotically tight.

The proof of Theorem 4 proceeds by invoking the deﬁnition of ultrametricity at various scales along
chains of points; we provide details in Appendix B. We remark that the bounds in Theorems 3  4
depend on both a local (ultrametricity/hyperbolicity) and a global property (cardinality); however  a
natural improvement would be to exploit a global property that takes into account the metric structure
of the underlying space. The ﬁrst step in this improvement is to prove a set of stability theorems.

5

5 Stability of SLHC and Gromov’s embedding

It is known that SLHC is robust to small perturbations of the input data with respect to the Gromov-
Hausdorff distance between metric spaces  whereas other HC methods  such as average linkage and
complete linkage  do not enjoy this stability [6]. We prove a particular stability result for SLHC
involving the (cid:96)∞ distance  and then we exploit the duality observed in §4 to prove a similar stability
result for Gromov’s embedding.
Theorem 5. Let (X  dX ) be a metric space  and let (A  dA) be any subspace with the restriction
metric dA := dX|A×A. Let H denote the SLHC method. Write (X  uX ) = H(X  dX ) and (A  uA) =
H(A  dA). Also write uA

X (x  x(cid:48)) := uA(η(x)  η(x(cid:48))) for x  x(cid:48) ∈ X. Then we have:
X(cid:107)∞.

(cid:107)H(X  dX ) − H(A  dA)(cid:107)∞ := (cid:107)uX − uA

X(cid:107)∞ ≤ (cid:107)dX − dA

Theorem 6. Let (X  dX   p) be a pointed metric space  and let (A  dA  a) be any subspace with the
restriction metric dA := dX|A×A such that η(p) = a. Let T denote the Gromov embedding. Write
(X  tX p) = T (X  dX   p) and (A  tA a) = T (A  dA  a). Also write tA
X p(x  x(cid:48)) := tA a(η(x)  η(x(cid:48)))
for x  x(cid:48) ∈ X. Then we have:

(cid:107)T (X  dX   p) − T (A  dA  a)(cid:107)∞ := (cid:107)tX p − tA

X p(cid:107)∞ ≤ 5(cid:107)dX − dA

X(cid:107)∞.

The proofs for both of these results use similar techniques  and we present them in Appendix B.

6

Improvement via Doubling Dimension

Our main theorems  providing additive distortion bounds for Gromov’s embedding and for SLHC 
are stated below. The proofs for both theorems are similar  so we only present that of the former.
Theorem 7. Let (X  dX ) be a n-point metric space with doubling dimension ρ  hyperbolicity
hyp(X  dX ) = δ  and diameter D. Let p ∈ X  and write (X  tX ) = T (X  dX   p). Then we obtain:
(2)

Covering number bound:

(cid:107)dX − tX(cid:107)∞ ≤ min
ε∈(0 D]

Also suppose D ≥ δρ

6 ln 2 . Then 

Doubling dimension bound:

(cid:107)dX − tX(cid:107)∞ ≤ 2δ + 2δρ

Theorem 8. Let (X  dX ) be a n-point metric space with doubling dimension ρ  ultrametricity
ult(X  dX ) = ν  and diameter D. Write (X  uX ) = H(X  dX ). Then we obtain:

2 + log2

(cid:16) D

(cid:0)12ε + 2δ log2(2NX (ε))(cid:1).
(cid:16) 13
(cid:17)(cid:17)
(cid:0)4ε + ν log2(2NX (ε))(cid:1).
(cid:16)

(cid:17)(cid:17)

δρ

.

(cid:16) D

νρ

6 + log2

.

(3)

(4)

(5)

Covering number bound:

Also suppose D ≥ νρ

4 ln 2 . Then 

Doubling dimension bound:

(cid:107)dX − uX(cid:107)∞ ≤ min
ε∈(0 D]

(cid:107)dX − uX(cid:107)∞ ≤ ν + νρ

X (cid:107)∞ using the bounds in Theorem 7.

Remark 9 (A remark on the NTP). We are now able to return to Question 1 and provide some
answers. Consider a metric space (X  dX ). We can upper bound (cid:107)dX − uopt
X (cid:107)∞ using the bounds in
Theorem 8  and (cid:107)dX − topt
Remark 10 (A remark on parameters). Notice that as hyperbolicity δ approaches 0 (or ultrametricity
approaches 0)  the doubling dimension bounds (hence the covering number bounds) approach 0. Also
note that as ε ↓ 0  we get NX (ε) ↑ |X|  so Theorems 7 8 reduce to Theorems 3 4. Experiments lead
us to believe that the interesting range of ε values is typically a subinterval of (0  D].
Proof of Theorem 7. Fix ε ∈ (0  D] and let X ε = {x1  x2  ...  xk} be a collection of k = NX (ε)
X on X × X as in §3. Subsequent
points that form an ε-net of X. Then we may deﬁne dε
application of Theorem 3 and Lemma 2 gives the bound

X and tε

(cid:107)dε

X − tε

X(cid:107)(cid:96)∞(X×X) ≤ (cid:107)dX ε − tX ε(cid:107)(cid:96)∞(X ε×X ε) ≤ 2δ log2(2k) ≤ 2δ log2(2Cε−ρ) 

6

where we deﬁne C := (8D)ρ. Then by the triangle inequality for the (cid:96)∞ distance  the stability of T
(Theorem 6)  and using the result that (cid:107)dX − dε

X(cid:107)(cid:96)∞(X×X) ≤ 2ε (Inequality 1)  we get:

X − tε
(cid:107)dX − tX(cid:107)∞ ≤ (cid:107)dX − dε
≤ 6(cid:107)dX − dε
X − tε
≤ 12ε + 2δ log2(2NX (ε)).

X(cid:107)∞ + (cid:107)dε
X(cid:107)∞ + (cid:107)dε

X(cid:107)∞ + (cid:107)tε
X(cid:107)∞

X − tX(cid:107)∞

Since ε ∈ (0  D] was arbitrary  this sufﬁces to prove Inequality 2. Applying Lemma 2 yields:

(cid:107)dX − tX(cid:107)∞ ≤ 12ε + 2δ log2(2Cε−ρ).

Notice that Cε−ρ ≥ NX (ε) ≥ 1  so the term on the right of the inequality above is positive. Consider
the function

f (ε) = 12ε + 2δ + 2δ log2 C − 2δρ log2 ε.

The minimizer of this function is obtained by taking a derivative with respect to ε:

f(cid:48)(ε) = 12 − 2δρ
ε ln 2

= 0 =⇒ ε =

δρ

.

6 ln 2

6 ln 2 ). By assumption  D ≥ δρ

Since ε takes values in (0  D]  and limε→0 f (ε) = +∞  the value of f (ε) is minimized at
6 ln 2. Since (cid:107)dX − tX(cid:107)∞ ≤ f (ε) for all ε ∈ (0  D]  it
(cid:19)(cid:19)
δρ
min(D 
follows that:
(cid:107)dX −tX(cid:107)∞ ≤ f

(cid:18) 48D ln 2

(cid:18) δρ

≤ 2δ +2δρ

(cid:18) 13

(cid:18) D

+2δ +2δρ log2

+ log2

(cid:19)

(cid:19)

=

2δρ
ln 2

6 ln 2

δρ

2

.

δρ

7 Tightness of our bounds in Theorems 7 and 8

By the construction provided below  we show that our covering number bound for the distortion of
SLHC is asymptotically tight. A similar construction can be used to show that our covering number
bound for Gromov’s embedding is also asymptotically tight.
Proposition 11. There exists a sequence (Xn  dXn)n∈N of ﬁnite metric spaces such that as n → ∞ 

(cid:0)4ε + νn log2(2NXn (ε))(cid:1) → 0.

(cid:107)dXn − uXn(cid:107)∞ (cid:16) min
ε∈(0 Dn]

Here we have written (Xn  uXn ) = H(Xn  dXn)  νn = ult(Xn  dXn )  and Dn = diam(Xn  dXn ).
Proof of Proposition 11. After deﬁning Xn for n ∈ N below  we will denote the error term  our
covering number upper bound  and our Gromov-style upper bound as follows:
En := (cid:107)dXn − uXn(cid:107)∞  Bn := min
ε∈(0 Dn]
ρ : N × [0 ∞) → R is deﬁned by ρ(n  ε) = 4ε + νn log2(2NXn (ε)).
Here we write |S| to denote the cardinality of a set S. Recall that the separation of a ﬁnite metric space
(X  dX ) is the quantity sep(X  dX ) := minx(cid:54)=x(cid:48)∈X dX (x  x(cid:48)). Let (V  uV ) be the ﬁnite ultrametric
space consisting of two equidistant points with common distance 1. For each n ∈ N  let Ln denote
the line metric space obtained by choosing (n + 1) equally spaced points with separation 1
n2 from the
n ]  and endowing this set with the restriction of the Euclidean metric  denoted dLn. One
interval [0  1
2n. Finally  for each n ∈ N we deﬁne Xn := V × Ln  and endow
can verify that ult(Ln  dLn ) ≈ 1
Xn with the following metric:

ρ(n  ε)  Gn := log2(2|Xn|) ult(Xn  dXn)  where

(cid:0)(v  l)  (v(cid:48)  l(cid:48))(cid:1) := max(cid:0)dV (v  v(cid:48))  dLn (l  l(cid:48))(cid:1) 

v  v(cid:48) ∈ V  l  l(cid:48) ∈ Ln.

dXn

Claim 1. ult(Xn  dXn) = ult(Ln  dLn ) ≈ 1
Claim 2. En (cid:16) diam(Ln  dLn ) = 1
n . To see this  let n ∈ N  and let x = (v  l)  x(cid:48) = (v(cid:48)  l(cid:48)) ∈ Xn
be two points realizing En. Suppose ﬁrst that v = v(cid:48). Then an optimal chain from (v  l)  (v  l(cid:48)) only

2n . For a proof  see Appendix B.

7

has to incur the cost of moving along the Ln coordinate. As such  we obtain uXn (x  x(cid:48)) ≤ 1
equality if and only if l (cid:54)= l(cid:48). Then 

n2   with

En = max
x x(cid:48)∈Xn

|dXn (x  x(cid:48)) − uXn(x  x(cid:48))| = max
l l(cid:48)∈Ln

|dLn (l  l(cid:48)) − 1

n2| = 1

n − 1

n2 (cid:16) 1
n .

Note that the case v (cid:54)= v(cid:48) is not allowed  because then we would obtain dXn (x  x(cid:48)) = dV (v  v(cid:48)) =
uXn (x  x(cid:48))  since sep(V  dV ) ≥ diam(Ln  dLn ) and all the points in V are equidistant. Thus we
would obtain |dXn (x  x(cid:48)) − uXn (x  x(cid:48))| = 0  which is a contradiction because we assumed that x  x(cid:48)
realize En.
Claim 3. For each n ∈ N  ε ∈ (0  Dn]  we have:

NV (ε)

|V |
|V |NLn (ε)

NXn (ε) =

: ε > sep(V  dV ) 
: diam(Ln  dLn ) < ε ≤ sep(V  dV ) 
: ε ≤ diam(Ln  dLn ).

To see this  note that in the ﬁrst two cases  any ε-ball centered at a point (v  l) automatically contains
all of {v} × Ln  so NXn(ε) = NV (ε). Speciﬁcally in the range diam(Ln  dLn) < ε ≤ sep(V  dV ) 
we need exactly one ε-ball for each v ∈ V to cover Xn. Finally in the third case  we need NLn (ε)
ε-balls to cover {v} × Ln for each v ∈ V . This yields the stated estimate.
By the preceding claims  we now have the following for each n ∈ N  ε ∈ (0  Dn]:

4ε + 1

4ε + 1
4ε + 1

2n log2(2NXn (ε)) =

ρ(n  ε) ≈ 4ε + 1

2n log2(2NV (ε))
2n log2(2|V |)
2n log2(2|V |NLn (ε))
Notice that for sufﬁciently large n  inf ε>diam(Ln) ρ(n  ε) = ρ(n  1
ρ(n  ε) ≤ ρ(n  1

n ≤ En ≤ Bn = min
ε∈(0 Dn]

1

n ). Then we have:
n ) ≈ C
n  

: ε > sep(V ) 
: diam(Ln) < ε ≤ sep(V ) 
: ε ≤ diam(Ln).

for some constant C > 0. Here the ﬁrst inequality follows from the proof of Claim 2  the second
from Theorem 8  and the third from our observation above. It follows that En (cid:16) Bn (cid:16) 1
Remark 12. Given the setup of the preceding proof  note that the Gromov-style bound behaves as:

n → 0.

Gn = ρ(n  0) = 1

2n log2(2|V |(n + 1)) ≈ C(cid:48) log2(n+1)

n

 

for some constant C(cid:48) > 0. So Gn approaches 0 at a rate strictly slower than that of En and Bn.

8 Discussion

We are motivated by a particular aspect of the numerical taxonomy problem  namely  the distortion
incurred when passing from a metric to its optimal tree embedding. We describe and explore a
duality between a tree embedding method proposed by Gromov and the well known SLHC method
for embedding a metric space into an ultrametric tree. Motivated by this duality  we propose a novel
metric space statistic that we call ultrametricity  and give a novel  tight bound on the distortion of the
SLHC method depending on cardinality and ultrametricity. We improve this Gromov-style bound
by replacing the dependence on cardinality by a dependence on doubling dimension  and produce a
family of examples proving tightness of this dimension-based bound. By invoking duality again  we
are able to improve Gromov’s original bound on the distortion of his tree embedding method. More
speciﬁcally  we replace the dependence on cardinality—a set-theoretic notion—by a dependence on
doubling dimension  which is truly a metric notion.
Through Proposition 11  we are able to prove that our bound is not just asymptotically tight  but that
it is strictly better than the corresponding Gromov-style bound. Indeed  Gromov’s bound can perform
arbitrarily worse than our dimension-based bound. We construct an explicit example to verify this
claim in Appendix A  Remark 14  where we also provide a practical demonstration of our methods.

8

References
[1] Ittai Abraham  Mahesh Balakrishnan  Fabian Kuhn  Dahlia Malkhi  Venugopalan Ramasubra-
manian  and Kunal Talwar. Reconstructing approximate tree metrics. In Proceedings of the
26th annual ACM symposium on Principles of distributed computing. ACM  2007.

[2] Muad Abu-Ata and Feodor F. Dragan. Metric tree-like structures in real-life networks: an

empirical study. arXiv preprint arXiv:1402.3364  2014.

[3] Richa Agarwala  Vineet Bafna  Martin Farach  Mike Paterson  and Mikkel Thorup. On the
approximability of numerical taxonomy (ﬁtting distances by tree metrics). SIAM Journal on
Computing  28(3):1073–1085  1998.

[4] Yair Bartal. Probabilistic approximation of metric spaces and its algorithmic applications. In

Foundations of Computer Science. IEEE  1996.

[5] Jean-Pierre Barthélemy and Alain Guénoche. Trees and proximity representations. 1991.

[6] Gunnar Carlsson and Facundo Mémoli. Characterization  stability and convergence of hierar-

chical clustering methods. The Journal of Machine Learning Research  2010.

[7] John Chakerian and Susan Holmes. Computational tools for evaluating phylogenetic and

hierarchical clustering trees. Journal of Computational and Graphical Statistics  2012.

[8] Victor Chepoi and Bernard Fichet. (cid:96)∞ approximation via subdominants. Journal of mathemati-

cal psychology  44(4):600–616  2000.

[9] Michel Marie Deza and Elena Deza. Encyclopedia of distances. Springer  2009.

[10] Jittat Fakcharoenphol  Satish Rao  and Kunal Talwar. A tight bound on approximating arbitrary
metrics by tree metrics. In Proceedings of the thirty-ﬁfth annual ACM symposium on Theory of
computing  pages 448–455. ACM  2003.

[11] Martin Farach  Sampath Kannan  and Tandy Warnow. A robust model for ﬁnding optimal

evolutionary trees. Algorithmica  13(1-2):155–179  1995.

[12] Mikhael Gromov. Hyperbolic groups. Springer  1987.

[13] Piotr Indyk and Jiri Matousek. Low-distortion embeddings of ﬁnite metric spaces. in in

handbook of discrete and computational geometry  pages 177–196  2004.

[14] Matthäus Kleindessner and Ulrike von Luxburg. Uniqueness of ordinal embedding. In COLT 

pages 40–67  2014.

[15] Robert Krauthgamer and James R Lee. Navigating nets: simple algorithms for proximity search.
In Proceedings of the ﬁfteenth annual ACM-SIAM symposium on Discrete algorithms  pages
798–807. Society for Industrial and Applied Mathematics  2004.

[16] Mirko Krivanek. The complexity of ultrametric partitions on graphs. Information processing

letters  27(5):265–270  1988.

[17] Yi Li and Philip M. Long. Learnability and the doubling dimension. In Advances in Neural

Information Processing Systems  pages 889–896  2006.

[18] Kantilal Varichand Mardia  John T. Kent  and John M. Bibby. Multivariate analysis. 1980.

[19] Charles Semple and Mike A. Steel. Phylogenetics  volume 24. Oxford University Press on

Demand  2003.

[20] Albert D. Shieh  Tatsunori B. Hashimoto  and Edoardo M. Airoldi. Tree preserving embed-
ding. Proceedings of the National Academy of Sciences of the United States of America 
108(41):16916–16921  2011.

[21] Laurens Van der Maaten and Geoffrey Hinton. Visualizing data using t-sne. Journal of Machine

Learning Research  9(2579-2605):85  2008.

9

,Samir Chowdhury
Facundo Mémoli
Zane Smith
Yonatan Belinkov
James Glass