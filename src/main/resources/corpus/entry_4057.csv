2010,Online Learning: Random Averages  Combinatorial Parameters  and Learnability,We develop a theory of online learning by defining several complexity measures. Among them are analogues of Rademacher complexity  covering numbers and fat-shattering dimension from statistical learning theory. Relationship among these complexity measures  their connection to online learning  and tools for bounding them are provided. We apply these results to various learning problems. We provide a complete characterization of online learnability in the supervised setting.,Online Learning: Random Averages  Combinatorial

Parameters  and Learnability

Alexander Rakhlin
Department of Statistics
University of Pennsylvania

Karthik Sridharan

Toyota Technological Institute

at Chicago

Ambuj Tewari

Computer Science Department
University of Texas at Austin

Abstract

We develop a theory of online learning by deﬁning several complexity measures.
Among them are analogues of Rademacher complexity  covering numbers and fat-
shattering dimension from statistical learning theory. Relationship among these
complexity measures  their connection to online learning  and tools for bounding
them are provided. We apply these results to various learning problems. We
provide a complete characterization of online learnability in the supervised setting.

1

Introduction

In the online learning framework  the learner is faced with a sequence of data appearing at discrete
time intervals.
In contrast to the classical “batch” learning scenario where the learner is being
evaluated after the sequence is completely revealed  in the online framework the learner is evaluated
at every round. Furthermore  in the batch scenario the data source is typically assumed to be i.i.d.
with an unknown distribution  while in the online framework we relax or eliminate any stochastic
assumptions on the data source. As such  the online learning problem can be phrased as a repeated
two-player game between the learner (player) and the adversary (Nature).
Let F be a class of functions and X some set. The Online Learning Model is deﬁned as
the following T -round interaction between the learner and the adversary: On round t = 1  . . .   T  
the Learner chooses ft ∈ F  the Adversary picks xt ∈ X   and the Learner suffers loss ft(xt). At
the end of T rounds we deﬁne regret as the difference between the cumulative loss of the player
as compared to the cumulative loss of the best ﬁxed comparator. For the given pair (F X )  the
problem is said to be online learnable if there exists an algorithm for the learner such that regret
grows sublinearly. Learnability is closely related to Hannan consistency [13  9].
There has been a lot of interest in a particular setting of the online learning model  called online
convex optimization. In this setting  we write xt(ft) as the loss incurred by the learner  and the
assumption is made that the function xt is convex in its argument. The particular convexity structure
enables the development of optimization-based algorithms for learner’s choices. Learnability and
precise rates of growth of regret have been shown in a number of recent papers (e.g. [33  25  1]). The
online learning model also subsumes the prediction setting. In the latter  the learner’s choice of a Y-
valued function gt leads to the loss of (cid:96)(gt(zt)  yt) according to a ﬁxed loss function (cid:96) : Y ×Y (cid:55)→ R.
The choice of the learner is equivalently written as ft(x) = (cid:96)(gt(z)  y)  and xt = (zt  yt) is the
choice of the adversary. In Section 6 we discuss the prediction setting in more detail.
In the “batch” learning scenario  data {(xi  yi)}T
i=1 is presented as an i.i.d. draw from a ﬁxed
distribution over some product X × Y. Learnability results have been extensively studied in the
PAC framework [29] and its agnostic extensions [14  17].
It is well-known that learnability in
the binary case (that is  Y = {−1  +1}) is completely characterized by ﬁniteness of the Vapnik-
Chervonenkis combinatorial dimension of the function class [32  31]. In the real-valued case  a
number of combinatorial quantities have been proposed: P -dimension [23]  V -dimension  as well
as the scale-sensitive versions Pγ-dimension [17  5] and Vγ-dimension [3]. The last two dimensions

1

were shown to be characterizing learnability [3] and uniform convergence of means to expectations
for function classes.
In contrast to the classical learning setting  there has been surprisingly little work on characterizing
learnability for the online learning framework. Littlestone [19] has shown that  in the setting of
prediction of binary outcomes  a certain combinatorial property of the binary-valued function class
characterizes learnability in the realizable case. The result has been extended to the non-realizable
case by Shai Ben-David  D´avid P´al and Shai Shalev-Shwartz [7] who named this combinatorial
quantity the Littlestone’s dimension. In parallel to [7]  minimax analysis of online convex optimiza-
tion yielded new insights into the value of the game  its minimax dual representation  as well as
algorithm-independent upper and lower bounds [1  27]. In this paper  we build upon these results
and the ﬁndings of [7] to develop a theory of online learning.
We show that in the online learning model  a notion which we call Sequential Rademacher complex-
ity allows us to easily prove learnability for a vast array of problems. The role of this complexity
is similar to the role of the Rademacher complexity in statistical learning theory. Next  we ex-
tend Littlestone’s dimension to the real-valued case. We show that ﬁniteness of this scale-sensitive
version  which we call the fat-shattering dimension  is necessary and sufﬁcient for learnability in
the prediction setting. Extending the binary-valued result of [7]  we introduce a generic algorithm
which plays the role similar to that of empirical risk minimization for i.i.d. data: if the problem
is learnable in the supervised setting  then it is learnable by this algorithm. Along the way we de-
velop analogues of Massart’s ﬁnite class lemma  the Dudley integral upper bound on the Sequential
Rademacher complexity  appropriately deﬁned packing and covering numbers  and even an analogue
of the Sauer-Shelah combinatorial lemma. In the full version of this paper  we introduce a general-
ization of the uniform law of large numbers for non-i.i.d. distributions and show that ﬁniteness of
the fat-shattering dimension implies this convergence.
Many of the results come with more work than their counterparts in statistical learning theory. In
particular  instead of training sets we have to work with trees  making the results somewhat involved.
For this reason  we state our results without proofs  deferring the details to the full version of this
paper. While the spirit of the online theory is that it provides a “temporal” generalization of the
“batch” learning problem  not all the results from statistical learning theory transfer to our setting.
For instance  two distinct notions of a packing set exist for trees  and these notions can be seen
to coincide in “batch” learning. The fact that many notions of statistical learning theory can be
extended to the online learning model is indeed remarkable.

2 Preliminaries

By phrasing the online learning model as a repeated game and considering its minimax value  we
naturally arrive at an important object in combinatorial game theory: trees. Unless speciﬁed  all
trees considered in this paper are rooted binary trees with equal-depth paths from the root to the
leaves. While it is useful to have the tree picture in mind when reading the paper  it is also necessary
to precisely deﬁne trees as mathematical objects. We opt for the following deﬁnition. Given some
set Z  a Z-valued tree of depth T is a sequence (z1  . . .   zT ) of T mappings zi : {±1}i−1 (cid:55)→ Z.
The root of the tree z is the constant function z1 ∈ Z. Armed with this deﬁnition  we can talk about
various operations on trees. For a function f : Z (cid:55)→ U  f(x) denotes the U-valued tree deﬁned by
the mappings (f◦x1  . . .   f◦xT ). A path of length T is a sequence  = (1  . . .   T−1) ∈ {±1}T−1.
We shall abuse notation by referring to xi(1  . . .   i−1) by xi(). Clearly xi only depends on the
ﬁrst i − 1 elements of .
We denote (ya  . . .   yb) by ya:b. The set of all functions from X to Y is denoted by YX   and the
t-fold product X × . . . × X is denoted by X t. For any T ∈ N  [T ] denotes the set {1  . . .   T}.
Whenever the variable in sup (inf) is not quantiﬁed  it ranges over the set of all possible values.

3 Value of the Game
Fix the sets F and X and consider the online learning model stated in the introduction. We assume
that F is a separable metric space. Let Q be the set of Borel probability measures on F. Assume that
Q is weakly compact. We consider randomized learners who predict a distribution qt ∈ Q on every

2

(cid:34) T(cid:88)

t=1

(cid:35)

T(cid:88)

t=1

round. Formally  deﬁne a learner’s strategy π as a sequence of mappings πt : X t−1 × F t−1 (cid:55)→ Q
for each t ∈ [T ]. We deﬁne the value of the game as

(cid:34) T(cid:88)

t=1

VT (F X ) = inf

q1∈Q sup
x1∈X

Ef1∼q1 ···

qT ∈Q sup
inf
xT ∈X

EfT ∼qT

ft(xt) − inf
f∈F

f(xt)

(1)

where ft has distribution qt. We consider here the adaptive adversary who gets to choose each xt
based on the history of moves f1:t−1 and x1:t−1.
Note that our assumption that F is a separable metric space implies that Q is tight [28] and
Prokhorov’s theorem states that compactness of Q under weak topology is equivalent to tightness
[28]. Hence we have that Q is compact under weak topology and this is essentially what we need to
apply a modiﬁcation of Theorem 1 of [1]. Speciﬁcally we show the following:
Theorem 1. Let F and X be the sets of moves for the two players  satisfying the necessary con-
ditions for the minimax theorem to hold. Denote by Q and P the sets of probability distributions
(mixed strategies) on F and X   respectively. Then

VT (F X ) = sup

p1

Ex1∼p1 . . . sup

pT

ExT ∼pT

inf
ft∈F

Ext∼pt [ft(xt)] − inf
f∈F

f(xt)

.

(2)

The question of learnability in the online learning model is now reduced to the study of VT (F X ) 
taking Eq. (2) as the starting point. In particular  under our deﬁnition  showing that the value grows
sublinearly with T is equivalent to showing learnability.
Deﬁnition 1. A class F is said to be online learnable with respect to the given X if

VT (F X )

= 0 .

lim sup
T→∞

T

The rest of the paper is aimed at understanding the value of the game VT (F X ) for various function
classes F. Since complexity of F is the focus of the paper  we shall often write VT (F)  and the
dependence on X will be implicit. One of the key notions introduced in this paper is the complexity
which we term Sequential Rademacher complexity. A natural generalization of Rademacher com-
plexity [18  6  21]  the sequential analogue possesses many of the nice properties of its classical
cousin. The properties are proved in Section 7 and then used to show learnability for many of the
examples in Section 8. The ﬁrst step  however  is to show that Sequential Rademacher complexity
upper bounds the value of the game. This is the subject of the next section.

(cid:35)

T(cid:88)

t=1

4 Random Averages
Deﬁnition 2. The Sequential Rademacher Complexity of a function class F ⊆ RX is deﬁned as

(cid:34)

T(cid:88)

t=1

(cid:35)

RT (F) = sup

x

E

sup
f∈F

tf(xt())

where the outer supremum is taken over all X -valued trees of depth T and  = (1  . . .   T ) is a
sequence of i.i.d. Rademacher random variables.
Theorem 2. The minimax value of a randomized game is bounded as VT (F) ≤ 2RT (F) .
Theorem 2 relies on a technical lemma  whose proof requires considerably more work than the
classical symmetrization proof [11  21] due to the non-i.i.d. nature of the sequences. We mention
that under strong assumptions on the space of functions  the Sequential Rademacher and the classical
Rademacher complexities coincide (see [1]). In general  however  the two complexities are very
different. For example  the discrepancy is exhibited by a class of linear threshold functions.

5 Covering Numbers and Combinatorial Parameters

In online learning  the notion characterizing learnability for binary prediction in the realizable case
has been introduced by Littlestone [19] and extended to the non-realizable case of binary predic-
tion by Shai Ben-David  D´avid P´al and Shai Shalev-Shwartz [7]. Next  we deﬁne the Littlestone’s

3

dimension [19  7] and propose its scale-sensitive versions for real-valued function classes. In the
sequel  these combinatorial parameters are shown to control the growth of covering numbers on
trees. In the setting of prediction  the combinatorial parameters are shown to exactly characterize
learnability (see Section 6).
Deﬁnition 3 ([19  7]). An X -valued tree x of depth d is shattered by a function class F ⊆ {±1}X
if for all  ∈ {±1}d  there exists f ∈ F such that f(xt()) = t for all t ∈ [d]. The Littlestone
dimension Ldim(F X ) is the largest d such that F shatters an X -valued tree of depth d.
Deﬁnition 4. An X -valued tree x of depth d is α-shattered by a function class F ⊆ RX   if there
exists an R-valued tree s of depth d such that

∀ ∈ {±1}d  ∃f ∈ F s.t. ∀t ∈ [d]  t(f(xt()) − st()) ≥ α/2

The tree s is called the witness to shattering. The fat-shattering dimension fatα(F X ) at scale α is
the largest d such that F α-shatters an X -valued tree of depth d.
With these deﬁnitions it is easy to see that fatα(F X ) = Ldim(F X ) for a binary-valued function
class F ⊆ {0  1}X for any 0 < α ≤ 1. When X and/or F is understood from the context  we will
simply write fatα or fatα(F) instead of fatα(F X ).
Let us mention that if trees x are deﬁned by constant mappings xt() = xt  the combinatorial pa-
rameters coincide with the Vapnik-Chervonenkis dimension and with the scale-sensitive dimension
Pγ. Therefore  the notions we are studying are a strict “temporal” generalizations of the VC theory.
As in statistical learning theory  the combinatorial parameters are only useful if they can be shown to
capture that aspect of F which is important for learnability. In particular  a “size” of a function class
is known to be related to complexity of learning from i.i.d. data.  and the classical way to measure
“size” is through a cover or a packing set. We propose the following deﬁnitions for online learning.
Deﬁnition 5. A set V of R-valued trees of depth T is an α-cover (with respect to (cid:96)p-norm) of
F ⊆ RX on a tree x of depth T if

∀f ∈ F  ∀ ∈ {±1}T ∃v ∈ V s.t.

1
T

|vt() − f(xt())|p ≤ αp

The covering number Np(α F  x) of a function class F on a given tree x is the size of the smallest
cover. Further deﬁne Np(α F  T ) = supx Np(α F  x)  the maximal (cid:96)p covering number of F over
depth T trees.
In particular  a set V of R-valued trees of depth T is a 0-cover of F ⊆ RX on a tree x of depth T if
for all f ∈ F and  ∈ {±1}T   there exists v ∈ V s.t. vt() = f(xt()). We denote by N (0 F  x)
the size of a smallest 0-cover on x and N (0 F  T ) = supx N (0 F  x). The 0-cover should not be
mistaken for the size |{f(x) : f ∈ F}| of the projection of F onto the tree x  and the same care
should be taken when dealing with α-covers.
We would like to comment that while in the i.i.d. setting there is a notion of packing number that
upper and lower bounds covering number  in the sequential counterpart such an analog fails.

5.1 A Combinatorial Upper Bound

We now relate the combinatorial parameters introduced in the previous section to the size of a cover.
In the binary case (k = 1 below)  a reader might notice a similarity of Theorem 3 to the classical
results due to Sauer [24]  Shelah [26] (also  Perles and Shelah)  and Vapnik and Chervonenkis [32].
There are several approaches to proving what is often called the Sauer-Shelah lemma. We opt for
the inductive-style proof (e.g. Alon and Spencer [4]). Dealing with trees  however  requires more
work than in the VC case.
Theorem 3. Let F ⊆ {0  . . .   k}X be a class of functions with fat1(F) = d1  fat2(F) = d2. Then

T(cid:88)

t=1

N∞(1/2 F  T ) ≤ d2(cid:88)

i=0

(cid:18)T

(cid:19)

i

N (0 F  T ) ≤ d1(cid:88)

i=0

(cid:18)T

(cid:19)

i

ki ≤ (ekT )d1 .

ki ≤ (ekT )d2  

4

Of particular interest is the case k = 1  when fat1(F) = Ldim(F) . Armed with Theorem 3  we
can reduce the problem of bounding the size of a cover at an α scale by a discretization trick. For
the classical case of a cover based on a set points  the discretization idea appears in [3  22]. We now
show that the covering numbers are bounded in terms of the fat-shattering dimension.
Corollary 4. Suppose F is a class of [−1  1]-valued functions on X . Then for any α > 0  any
T > 0  and any X -valued tree x of depth T  

N1(α F  x) ≤ N2(α F  x) ≤ N∞(α F  x) ≤ (2eT /α)fatα(F )

When bounding deviations of means from expectations uniformly over the function class  the usual
approach proceeds by a symmetrization argument [12] followed by passing to a cover of the function
class and a union bound (e.g. [21]). Alternatively  a more reﬁned chaining analysis integrates over
covering at different scales (e.g. [30]). By following the same path  we are able to prove a number
of similar results for our setting. Next  we present a bound similar to Massart’s ﬁnite class lemma
[20  Lemma 5.2]. This result will be used when integrating over different scales for the cover.

5.2 Finite Class Lemma and the Chaining Method
Lemma 5. For any ﬁnite set V of R-valued trees of depth T we have that

"

TX

t=1

#

vuut2 log(|V |) max

E

max
v∈V

tvt()

≤

v∈V

max

∈{±1}T

vt()2

TX

t=1

A simple consequence of the above lemma is that if F ⊆ [0  1]X is a ﬁnite class  then for any given

tree x we obtain a(cid:112)2T log(|F|) upper bound. If f ∈ F is associated with an “expert” (see [9]) 

this result combined with Theorem 2 yields a bound given by the expert’s algorithm. In Section 8
we discuss this case in more detail. However  as we show next  Lemma 5 goes well beyond just
ﬁnite classes and can be used to get an analog of Dudley entropy bound [10] for the online setting
through a chaining argument.
Deﬁnition 6. The Integrated complexity of a function class F ⊆ [−1  1]X is deﬁned as



pT log N2(δ F  T ) dδ

ﬀ

.

Z 1

α

DT (F) = inf

α

4T α + 12

The basic idea in the proof of the following theorem is the same as in statistical learning: RT (F) is
bounded by controlling the complexity along the chain of coverings. The argument for trees  though 
is more involved than the classical case.
Theorem 6. For any function class F ⊆ [−1  1]X   RT (F) ≤ DT (F)

6 Supervised Learning
In this section we study the supervised learning problem where player picks a function ft ∈ RX
at any time t and the adversary provides input target pair (xt  yt) and the player suffers loss
|ft(xt) − yt|. Note that if F ⊆ {±1}X and each yt ∈ {±1} then the problem boils down to binary
classiﬁcation problem. As we are interested in prediction  we allow ft to be outside of F. Though
we use the absolute loss in this section  it is easy to see that all the results hold (with modiﬁed rates)
for any loss (cid:96)(f(x)  y) which is such that for all f  x and y  φ((cid:96)(ˆy  y)) ≤ |ˆy− y| ≤ Φ((cid:96)(ˆy  y)) where
Φ and φ are monotonically increasing functions. For instance the squared loss is a classic example.
To formally deﬁne the value of the online supervised learning game  ﬁx a set of labels Y ⊆ [−1  1].
Given F  deﬁne the associated loss class  FS = {(x  y) (cid:55)→ |f(x)−y| : f ∈ F} . Now  the supervised
game is obtained using the pair (FS X ×Y) and we accordingly deﬁne VS
T (F) = VT (FS X ×Y) .
Binary classiﬁcation is  of course  a special case when Y = {±1} and F ⊆ {±1}X . In that case 
we simply use VBinary

for VS
T .

T

5

Proposition 7. For the supervised learning game played with a function class F ⊆ [−1  1]X   for
any T ≥ 1

√
1
4

2

sup

α

n

αpT min{fatα  T}o ≤ 1
(

2

≤ RT (F) ≤ DT (F) ≤ inf

V S
T (F)

s

Z 1

√
T

„ 2eT

«

)

4T α + 12

(3)
Theorem 8. For any function class F ⊆ [−1  1]X   F is online learnable in the supervised setting
if and only if fatα(F) is ﬁnite for any α > 0. Moreover  if the function class is online learnable 
then the value of the supervised game VS
T (F)  the Sequential Rademacher complexity R(F)  and
the Integrated complexity D(F) are within a multiplicative factor of O(log3/2 T ) of each other.
Corollary 9. For the binary classiﬁcation game played with function class F we have that

fatβ log

dβ

β

α

α

(cid:112)T min{Ldim(F)  T} ≤ VBinary

(cid:112)T Ldim(F) log T

(F) ≤ K2

K1

for some universal constants K1  K2. This recovers the result of [7].
We wish to point out that lower bound of Proposition 7 also holds for “improper” supervised learning
algorithms  i.e. those simply output a prediction ˆyt ∈ Y rather than a function ft ∈ F. Since a
proper learning strategy can always be used as an improper learning strategy  we trivially have that
if class is online learnable in the supervised setting then it is improperly online learnable. Because
the above mentioned property of lower bound of Proposition 7  we also have the non-trivial reverse
implication: if a class is improperly online learnable in the supervised setting  it is online learnable.

T

6.1 Generic Algorithm

We shall now present a generic improper learning algorithm for the supervised setting that achieves
a low regret bound whenever the function class is online learnable. For any α > 0 deﬁne an α-
discretization of the [−1  1] interval as Bα = {−1 + α/2 −1 + 3α/2  . . .  −1 + (2k + 1)α/2  . . .}
for 0 ≤ k and (2k + 1)α ≤ 4. Also for any a ∈ [−1  1] deﬁne (cid:98)a(cid:99)α = argmin
|r − a|. For a set of
r∈Bα
functions V ⊆ F  any r ∈ Bα and x ∈ X deﬁne V (r  x) = {f ∈ V | f(x) ∈ (r − α/2  r + α/2]}.
The algorithm proceeds by generating“experts” in a way similar to [7]. Using these experts along
with exponentially weighted experts algorithm we shall provide the generic algorithm for online
supervised learning.
Algorithm 1 Expert (F  α  1 ≤ i1 < . . . < iL ≤ T  Y1  . . .   YL)

V1 ← F
for t = 1 to T do

P

Rt(x) = {r ∈ Bα : fatα(Vt(r  x)) = maxr(cid:48)∈Bα fatα(Vt(r(cid:48)  x))}
For each x ∈ X   let f(cid:48)
if t ∈ {i1  . . .   iL} then

t(x) = 1

r∈Rt(x) r

|Rt(x)|

∀x ∈ X   ft(x) = Yj where j is s.t. t = ij.
Play ft  receive xt  and update Vt+1 = Vt(ft(xt)  xt)
Play ft = f(cid:48)

t  receive xt  and set Vt+1 = Vt

else

end if
end for

et : X t−1 (cid:55)→ F. The number of unique experts is |ET| = (cid:80)fatα

For each L ≤ fatα(F) and every possible choice of 1 ≤ i1 < . . . < iL ≤ T and Y1  . . .   YL ∈ Bα
we generate an expert. Denote this set of experts as ET . Each expert outputs a function ft ∈ F
at every round T . Hence each expert e ∈ ET can be seen as a sequence (e1  . . .   eT ) of mappings
Using an argument similar to [7]  for any f ∈ F there exists e ∈ ET such that for any t ∈ [T ] 
|f(xt) − e(x1:t−1)(xt)| ≤ α .
Theorem 10. For any α > 0 if we run the exponentially weighted experts algorithm with the set ET
of experts then the expected regret of the algorithm is bounded as

(cid:1) (|Bα| − 1)L ≤ (cid:0) 2T

(cid:1)fatα

(cid:0)T

L=0

L

α

ft(xt) − inf
f∈F

≤ αT +

T fatα log

s

„ 2T

«

α

" TX

t=1

E

TX

t=1

#

f (xt)

6

Further if F be bounded by 1 then by running an additional experts algorithm over the experts for
discretizations over α  we can provide regret guarantee of

" TX

t=1

E

TX

t=1

ft(xt) − inf
f∈F

(

s

#

≤ inf

α

„ 2T

«

α

√

+

„

««)

„ 1

α

f (xt)

αT +

T fatα log

T

3 + 2 log log

7 Structural Results

Being able to bound complexity of a function class by a complexity of a simpler class is of great
utility for proving bounds. In statistical learning theory  such structural results are obtained through
properties of Rademacher averages [21  6]. In particular  the contraction inequality due to Ledoux
and Talagrand  allows one to pass from a composition of a Lipschitz function with a class to the
function class itself. This wonderful property permits easy convergence proofs for a vast array of
problems. We show that the notion of Sequential Rademacher complexity also enjoys many of the
same properties. In Section 8  the effectiveness of the results is illustrated on a number of examples.
First  we prove the contraction inequality.
Lemma 11. Fix a class F ⊆ RZ and a function φ : R × Z (cid:55)→ R. Assume  for all z ∈ Z  φ(·  z) is
a L-Lipschitz function. Then R(φ(F)) ≤ L · R(F) where φ(F) = {z (cid:55)→ φ(f(z)  z) : f ∈ F}.

The next lemma bounds the Sequential Rademacher complexity for the product of classes.
Lemma 12. Let F = F1 × . . . × Fk where each Fj ⊂ RX . Also let φ : Rk (cid:55)→ R be L-Lipschitz

w.r.t. (cid:107) · (cid:107)∞ norm. Then we have that R(φ ◦ F) ≤ LO(cid:16)
valued functions  R(g(F1  . . .  Fk)) ≤ O(cid:16)
(cid:17)(cid:80)k

log3/2(T )

Corollary 13. For a ﬁxed binary function b : {±1}k (cid:55)→ {±1} and classes F1  . . .  Fk of {±1}-

j=1 R(Fj) .

(cid:17)(cid:80)k

log3/2(T )

j=1 R(Fj) .

In the next proposition  we summarize some basic properties of Sequential Rademacher complexity
(see [21  6] for the results in the i.i.d. setting):
Proposition 14. Sequential Rademacher complexity satisﬁes the following properties: (i) if F ⊂ G 
then R(F) ≤ R(G); (ii) R(F) = R(conv(F)); (iii) R(cF) = |c|R(F) for all c ∈ R; (iv) If
φ : R (cid:55)→ R is L-Lipschitz  then R(φ(F)) ≤ LR(F); (v) For any h  R(F + h) = R(F) where
F + h = {f + h : f ∈ F}.

8 Examples and Applications
Example: Linear Function Classes Suppose FW is a class consisting of linear functions x (cid:55)→
(cid:104)w  x(cid:105) where the weight vector w comes from some set W  FW = {x (cid:55)→ (cid:104)w  x(cid:105) : w ∈ W}. Often 
it is possible to ﬁnd a strongly convex function Ψ(w) ≥ 0 such that Ψ(w) ≤ Ψmax < ∞ for all
w ∈ W (for example the function (cid:107)w(cid:107)2
Theorem 15. Let W be a class of weight vectors such that 0 ≤ Ψ(w) ≤ Ψmax for all w ∈ W.
Suppose that Ψ is σ-strongly convex w.r.t. a given norm (cid:107) · (cid:107). Then  we have  RT (FW ) ≤
(cid:107)X(cid:107)(cid:63)
input space.

p2 Ψmax T /σ   where (cid:107)X(cid:107)(cid:63) = supx∈X (cid:107)x(cid:107)(cid:63)  the maximum dual norm of any vector in the

2 on any bounded subset of Rd).

T ) regret bounds of online mirror descent
The above result actually allows us to recover the O(
(including Zinkevich’s online gradient descent) obtained in the online convex optimization literature.
There  the set X is set of convex Lipschitz functions on a convex set F. We interpret f(x) as x(f).
It is easy to bound the value of the convex game by that of the linear game [2]  i.e. one in which X
is the set of linear functions. Then we directly appeal to the above theorem to bound the value of
√
the linear game. The online convex optimization setting includes supervised learning using convex
T ) regret algorithms
losses and linear predictors and so our theorem also proves existence of O(
in that setting.

√

Example: Margin Based Regret We prove a general margin based mistake bound for binary
classiﬁcation. This shows the generality of our framework since we do not require assumptions

7

like convexity to bound the minimax regret. The proof of the following result uses a non-convex
Lipschitz “ramp” function along with Lemma 11. As far as we know  this is the ﬁrst general margin
based mistake bound in the online setting for a general function class.
Theorem 16. For any function class F ⊂ RX bounded by B  there exists a randomized player
strategy π such that for any sequence (x1  y1)  . . .   (xT   yT ) ∈ (X × {±1})T  
TX

„ B

TX

(

√

«)

1{f (xt)yt < γ} +

RT (F) +

T log log

t=1

Eft∼πt(x1:t−1) [1{ft(xt)yt < 0}] ≤ inf
)
(

γ>0

inf
f∈F

t=1

w1

j xj

x (cid:55)→X

˛˛ (cid:107)w(cid:107)1 ≤ B1

Example : Neural Networks and Decision Trees We now consider a k-layer 1-norm neural
(
network. To this end let function class F1 be given by
x (cid:55)→X
F1 =
for 2 ≤ i ≤ k. The theory we have developed provides us with enough tools to control the sequential
Rademacher complexity of classes like the above that are built using simpler components. The
following result shows that neural networks can be learned online. A similar result  but for statistical
learning  appeared in [6]. Let X ⊂ Rd  and X∞ be such that ∀x ∈ X   (cid:107)x(cid:107)∞ ≤ X∞.
Theorem 17. Let σ : R (cid:55)→ [−1  1] be L-Lipschitz. Then

jσ (fj(x)) ˛˛ ∀j fj ∈ Fi−1 (cid:107)wi(cid:107)1 ≤ Bi

  and Fi =

wi

j

j

)

4
γ

γ

  kY

i=1

!

Lk−1X∞p2T log d.

RT (Fk) ≤

Bi

First  consider transductive learning  where the set X = {z1}n

We can also prove online learnability of decision trees under appropriate restrictions on their depth
and number of leaves. We skip the formal statement in the interest of space but the proof proceeds
in a fashion similar to the decision tree result in [6]. The structural results enjoyed by the sequential
Rademacher complexity (esp. Corollary 13) are key to making the proof work.
Example: Transductive Learning and Prediction of Individual Sequences Let F ⊂ RX and

depend on n. Assuming that F ⊂ [0  1]X   the value of the game is upper bounded by 2DT (F) ≤
√
4
In particular  for binary prediction  using the Sauer-Shelah lemma ensures that the

let (cid:98)N∞(α F) be the classical pointwise (over X ) covering number at scale α. It is easy to verify that
N∞(α F  T ) ≤ (cid:98)N∞(α F) for all T . This simple observation can be applied in several situations.
learnability  it is sufﬁcient to consider an assumption on the dependence of (cid:98)N∞(α F) on α. An
obvious example of such a class is a VC-type class with (cid:98)N∞(α F) ≤ (c/α)d for some c which can
value of the game is at most 4(cid:112)dT log(eT )  matching the result of [15] up to a constant 2.
puts us in the setting considered earlier with n = T . We immediately obtain 4(cid:112)dT log(eT )  match-
ing the results on [8  p. 1873]. For the case of a ﬁnite number of experts  clearly (cid:98)N∞ ≤ N which

In the context of prediction of individual sequences  Cesa-Bianchi and Lugosi [8] proved upper
bounds in terms of the (classical) Rademacher complexity and the (classical) Dudley integral. The
particular assumption made in [8] is that experts are static. Formally  we deﬁne static experts as map-
pings f : {1  . . .   T} (cid:55)→ [0  1]  and let F denote a class of such experts. Deﬁning X = {1  . . .   T}

i=1 is a ﬁnite set. To ensure online

dT log c.

√

gives the classical O(

T log N) bound [9].

Example: Isotron Recently  Kalai and Sastry [16] introduced a method called Isotron for learn-
ing Single Index Models (SIM)  which generalize linear and logistic regression  generalized linear
models  and classiﬁcation by linear threshold functions. A natural open question posed by the au-
thors is whether there is an online variant of Isotron. Before even attempting a quest for such an
algorithm  we can ask a more basic question: is the (Idealized) SIM problem even learnable in the
online framework? We answer the question in positive with the tools we have developed by proving
that the following class (with X a Euclidean ball in Rd and Y = [−1  1]) is learnable:
H = {f (x  y) = (y − u((cid:104)w  x(cid:105)))2 | u : [−1  1] (cid:55)→ [−1  1] is non-decreasing 1-Lipschitz   (cid:107)w(cid:107)2 ≤ 1} (4)
where u and w range over the possibilities. Using the machinery we developed  it is not hard to
show that the class H is online learnable in the supervised setting. Moreover  VT (H X × Y) =
√
O(

T log3/2 T ).

8

References
[1] J. Abernethy  A. Agarwal  P. Bartlett  and A. Rakhlin. A stochastic view of optimal regret through mini-

max duality. In Proceedings of the 22nd Annual Conference on Learning Theory  2009.

[2] J. Abernethy  P. L. Bartlett  A. Rakhlin  and A. Tewari. Optimal strategies and minimax lower bounds for

online convex games. In COLT  pages 414–424  2008.

[3] N. Alon  S. Ben-David  N. Cesa-Bianchi  and D. Haussler. Scale-sensitive dimensions  uniform conver-

gence  and learnability. Journal of the ACM  44:615–631  1997.

[4] N. Alon and J. Spencer. The Probabilistic Method. John Wiley & Sons  2nd edition  2000.
[5] P. L. Bartlett  P. M. Long  and R. C. Williamson. Fat-shattering and the learnability of real-valued func-

tions. Journal of Computer and System Sciences  52(3):434–452  1996. (special issue on COLT‘94).

[6] P. L. Bartlett and S. Mendelson. Rademacher and gaussian complexities: risk bounds and structural

results. J. Mach. Learn. Res.  3:463–482  2003.

[7] S. Ben-David  D. Pal  and S. Shalev-Shwartz. Agnostic online learning. In COLT  2009.
[8] N. Cesa-Bianchi and G. Lugosi. On prediction of individual sequences. A. of S.  pages 1865–1895  1999.
[9] N. Cesa-Bianchi and G. Lugosi. Prediction  Learning  and Games. Cambridge University Press  2006.
[10] R. M. Dudley. The sizes of compact subsets of Hilbert space and continuity of Gaussian processes.

Journal of Functional Analysis  1(3):290–330  1967.

[11] R. M. Dudley. Uniform Central Limit Theorems. Cambridge University Press  1999.
[12] E. Gin´e and J. Zinn. Some limit theorems for empirical processes. Ann. of Prob.  12(4):929–989  1984.
[13] J. Hannan. Approximation to Bayes risk in repeated play. Contr. to Theo. of Games  3:97–139  1957.
[14] D. Haussler. Decision theoretic generalizations of the PAC model for neural net and other learning appli-

cations. Information and Computation  100(1):78–150  1992.

[15] S. M. Kakade and A. Kalai. From batch to transductive online learning. In NIPS  2005.
[16] A. Tauman Kalai and R. Sastry. The isotron algorithm: High-dimensional isotonic regression. In Pro-

ceedings of the 22th Annual Conference on Learning Theory  2009.

[17] M. J. Kearns and R. E. Schapire. Efﬁcient distribution-free learning of probabilistic concepts. Journal of

Computer and System Sciences  48(3):464–497  1994.

[18] V. Koltchinskii and D. Panchenko. Rademacher processes and bounding the risk of function learning.

High Dimensional Probability II  47:443–459  2000.

[19] N. Littlestone. Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm.

Machine Learning  2(4):285–318  04 1988.

[20] P. Massart. Some applications of concentration inequalities to statistics. Annales de la Facult´e des Sci-

ences de Toulouse  IX(2):245–303  2000.

[21] S. Mendelson. A few notes on statistical learning theory. In MLSS 2002  pages 1–40. 2003.
[22] S. Mendelson and R. Vershynin. Entropy and the combinatorial dimension. Inventiones mathematicae 

152:37–55  2003.

[23] D. Pollard. Empirical Processes: Theory and Applications  volume 2. Hayward  CA  1990.
[24] N. Sauer. On the density of families of sets. J. Combinatorial Theory  13:145–147  1972.
[25] S. Shalev-Shwartz and Y. Singer. Convex repeated games and fenchel duality. In NIPS  pages 1265–1272.

MIT Press  Cambridge  MA  2007.

[26] S. Shelah. A combinatorial problem: Stability and order for models and theories in inﬁnitary languages.

Pac. J. Math  4:247–261  1972.

[27] K. Sridharan and A. Tewari. Convex games in banach spaces. In COLT  2010.
[28] A. W. Van Der Vaart and J. A. Wellner. Weak Convergence and Empirical Processes : With Applications

to Statistics. Springer Series  March 1996.

[29] L. Valiant. A theory of the learnable. Communications of the ACM  27(11):1134–1142  1984.
[30] S.A. van de Geer. Empirical Processes in M-Estimation. Cambridge University Press  2000.
[31] V. N. Vapnik. Estimation of Dependences Based on Empirical Data (Springer Series in Statistics).

Springer-Verlag New York  Inc.  Secaucus  NJ  USA  1982.

[32] V. N. Vapnik and A. Ya. Chervonenkis. On the uniform convergence of relative frequencies of events to

their probabilities. Theory of Probability and its Applications  16(2):264–280  1971.

[33] M. Zinkevich. Online convex programming and generalized inﬁnitesimal gradient ascent. In ICML  pages

928–936  2003.

9

,Brendan McMahan
Jacob Abernethy
Stephan Mandt
David Blei
Shakir Mohamed
Danilo Jimenez Rezende
Stéphanie van der Pas
Veronika Ročková
Faidra Georgia Monachou
Itai Ashlagi