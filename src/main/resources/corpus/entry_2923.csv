2013,Learning Hidden Markov Models from Non-sequence Data via Tensor Decomposition,Learning dynamic models from observed data has been a central issue in many scientific  studies or engineering tasks. The usual setting is that data are collected sequentially  from trajectories of some dynamical system operation.   In quite a few modern scientific modeling tasks  however  it turns out that  reliable sequential data are rather difficult to gather  whereas out-of-order snapshots are much easier to obtain. Examples include the modeling of galaxies  chronic diseases such Alzheimer's  or certain biological processes.  Existing methods for learning dynamic model from non-sequence data are mostly based on Expectation-Maximization  which involves non-convex optimization and is thus hard to analyze.  Inspired by recent advances in spectral learning methods  we propose to study this problem  from a different perspective: moment matching and spectral decomposition. Under that framework   we identify reasonable assumptions on the generative process of non-sequence data   and propose learning algorithms based on the tensor decomposition method  \cite{anandkumar2012tensor} to \textit{provably} recover first-order Markov models and hidden Markov models. To the best of our knowledge  this is the first formal guarantee on learning from non-sequence data. Preliminary simulation results confirm our theoretical findings.,Learning Hidden Markov Models from Non-sequence

Data via Tensor Decomposition

Tzu-Kuo Huang

Machine Learning Department

Carnegie Mellon University

Pittsburgh  PA 15213

Jeff Schneider
Robotics Institute

Carnegie Mellon University

Pittsburgh  PA 15213

tzukuoh@cs.cmu.edu

schneide@cs.cmu.edu

Abstract

Learning dynamic models from observed data has been a central issue in many
scientiﬁc studies or engineering tasks. The usual setting is that data are collected
sequentially from trajectories of some dynamical system operation. In quite a few
modern scientiﬁc modeling tasks  however  it turns out that reliable sequential
data are rather difﬁcult to gather  whereas out-of-order snapshots are much eas-
ier to obtain. Examples include the modeling of galaxies  chronic diseases such
Alzheimer’s  or certain biological processes.
Existing methods for learning dynamic model from non-sequence data are mostly
based on Expectation-Maximization  which involves non-convex optimization and
is thus hard to analyze. Inspired by recent advances in spectral learning methods 
we propose to study this problem from a different perspective: moment matching
and spectral decomposition. Under that framework  we identify reasonable as-
sumptions on the generative process of non-sequence data  and propose learning
algorithms based on the tensor decomposition method [2] to provably recover ﬁrst-
order Markov models and hidden Markov models. To the best of our knowledge 
this is the ﬁrst formal guarantee on learning from non-sequence data. Preliminary
simulation results conﬁrm our theoretical ﬁndings.

1

Introduction

Learning dynamic models from observed data has been a central issue in many ﬁelds of study  scien-
tiﬁc or engineering tasks. The usual setting is that data are collected sequentially from trajectories of
some dynamical system operation  and the goal is to recover parameters of the underlying dynamic
model. Although many research and engineering efforts have been devoted to that setting  it turns
out that in quite a few modern scientiﬁc modeling problems  another situation is more frequently en-
countered: observed data are out-of-order (or partially-ordered) snapshots rather than full sequential
samples of the system operation. As pointed out in [7  8]  this situation may appear in the modeling
of celestial objects such as galaxies or chronic diseases such as Alzheimer’s  because observations
are usually taken from different trajectories (galaxies or patients) at unknown  arbitrary times. Or it
may also appear in the study of biological processes  such as cell metabolism under external stimuli 
where most measurement techniques are destructive  making it very difﬁcult to repetitively collect
observations from the same individual living organisms as they change over time. However  it is
much easier to take single snapshots of multiple organisms undergoing the same biological process
in a fully asynchronous fashion  hence the lack of timing information. Rabbat et al. [9] noted that in
certain network inference problems  the only available data are sets of nodes co-occurring in random
walks on the network without the order in which they were visited  and the goal is to reconstruct
the network structure from such co-occurrence data. This problem is essentially about learning a
ﬁrst-order Markov chain from data lacking sequence information.

1

As one can imagine  dynamic model learning in a non-sequential setting is much more difﬁcult
than in the sequential setting and has not been thoroughly studied. One issue is that the notion
of non-sequence data is vague because there can be many different generative processes resulting
in non-sequence data. Without any restrictions  one can easily ﬁnd a case where no meaningful
dynamic model can be learnt. It is therefore important to ﬁgure out what assumptions on the data
and the model would lead to successful learning. However  existing methods for non-sequential
settings  e.g.  [9  11  6  8]  do not shed much light on this issue because they are mostly based
on Expectation-Maximization (EM)  which require non-convex optimization. Regardless of the
assumptions we make  as long as the resulting optimization problem remains non-convex  formal
analysis of learning guarantees is still formidable.

We thus propose to take a different approach  based on another long-standing estimation principle:
the method of moments (MoM). The basic idea of MoM is to ﬁnd model parameters such that the
resulting moments match or resemble the empirical moments. For some estimation problems  this
approach is able to give unique and consistent estimates while the maximum-likelihood method gets
entangled in multiple and potentially undesirable local maxima. Taking advantage of this property 
an emerging area of research in machine learning has recently developed MoM-based learning al-
gorithms with formal guarantees for some widely used latent variable models  such as Gaussian
mixture models[5]  Hidden Markov models [3]  Latent Dirichlet Allocation [1  4]  etc. Although
many learning algorithms for these models exist  some having been very successful in practice 
barely any formal learning guarantee was given until the MoM-based methods were proposed. Such
breakthroughs seem surprising  but it turns out that they are mostly based on one crucial property:
for quite a few latent variable models  the model parameters can be uniquely determined from spec-
tral decompositions of certain low-order moments of observable quantities.

In this work we demonstrate that under the MoM and spectral learning framework  there are reason-
able assumptions on the generative process of non-sequence data  under which the tensor decompo-
sition method [2]  a recent advancement in spectral learning  can provably recover the parameters
of ﬁrst-order Markov models and hidden Markov models. To the best of our knowledge  ours is the
ﬁrst work that provides formal guarantees for learning from non-sequence data. Interestingly  these
assumptions bear much similarity to the usual idea behind topic modeling: with the bag-of-words
representation which is invariant to word orderings  the task of inferring topics is almost impossi-
ble given one single document (no matter how long it is!)  but becomes easier as more documents
touching upon various topics become available. For learning dynamic models  what we need in the
non-sequence data are multiple sets of observations  where each set contains independent samples
generated from its own initial distribution  and the many different initial distributions together cover
the entire (hidden) state space. In some of the aforementioned scientiﬁc applications  such as bi-
ological studies  this type of assumptions might be realized by running multiple experiments with
different initial conﬁgurations or amounts of stimuli.

The main body of the paper consists of four sections. Section 2 brieﬂy reviews the essentials of
the tensor decomposition framework [2]; Section 3 details our assumptions on non-sequence data 
tensor-decomposition based learning algorithms  and theoretical guarantees; Section 4 reports some
simulation results conﬁrming our theoretical ﬁndings  followed by conclusions in Section 5. Proofs
of theoretical results are given in the appendices in the supplementary material.

2 Tensor Decomposition

We mainly follow the exposition in [2]  starting with some preliminaries and notations. A real p-th
order tensor A is a member of the tensor product spaceNp
Rmi of p Euclidean spaces. For a vec-
tor x ∈ Rm  we denote by x⊗p := x⊗ x⊗···⊗ x ∈Np
Rm its p-th tensor power. A convenient
way to represent A ∈Np
Rm is through a p-way array of real numbers [Ai1i2···ip]1≤i1 i2 ... ip≤m 
where Ai1i2···ip denotes the (i1  i2  . . .   ip)-th coordinate of A with respect to a canonical basis.
With this representation  we can view A as a multi-linear map that  given a set of p matrices
{Xi ∈ Rm×mi}p
Rmi with
the following p-way array representation:

i=1  produces another p-th order tensor A(X1  X2 ···   Xp) ∈ Np

i=1

i=1

i=1

i=1

A(X1  X2 ···   Xp)i1i2···ip := X1≤j1 j2 ... jp≤m

Aj1j2···jp(X1)j1i1(V2)j2i2 ··· (Xp)jpip.

(1)

2

Figure 1: Running example of Markov chain with three states

In this work we consider tensors that are up to the third-order (p ≤ 3) and  for most of the time 
also symmetric  meaning that their p-way array representations are invariant under permutations of
array indices. More speciﬁcally  we focus on second and third-order symmetric tensors in or slightly
perturbed from the following form:

M2 :=

kXi=1

ωiµi ⊗ µi  M3 :=

kXi=1

ωiµi ⊗ µi ⊗ µi 

(2)

satisfying the following non-degeneracy conditions:
Condition 1. ωi ≥ 0 ∀ 1 ≤ i ≤ k  {µi ∈ Rm}k
i=1 and {µi}k
As described in later sections  the core of our learning task involves estimating {ωi}k
i=1
from perturbed or noisy versions of M2 and M3. We solve this estimation problem with the tensor
decomposition method recently proposed by Anandkumar et al. [2]. The algorithm and its theoreti-
cal guarantee are summarized in Appendix A. The key component of this method is a novel tensor
power iteration procedure for factorizing a symmetric orthogonal tensor  which is robust against
input perturbation.

i=1 are linearly independent  and k ≤ m.

3 Learning from Non-sequence Data

We ﬁrst describe a generative process of non-sequence data for ﬁrst-order Markov models and
demonstrate how to apply tensor decomposition methods to perform consistent learning. Then
we extend these ideas to hidden Markov models and provide theoretical guarantees on the sam-
ple complexity of the proposed learning algorithm. For notational conveniences we deﬁne the
following vector-matrix cross product ⊗d∈{1 2 3} : (v ⊗1 M )ijk := vi(M )jk  (v ⊗2 M )ijk =
vj(M )ik  (v ⊗3 M )ijk = vk(M )ij. For a matrix M we denote by Mi its i-th column.
3.1 First-order Markov Models

Let P ∈ [0  1]m×m be the transition probability matrix of a discrete  ﬁrst-order  ergodic Markov
chain with m states and a unique stationary distribution π. Let P be of full rank and 1⊤P = 1⊤.
To give a high-level idea of what makes it possible to learn P from non-sequence data  we use the
simple Markov chain with three states shown in Figure 1 as our running example  demonstrating
step by step how to extend from a very restrictive generative setting of the data to a reasonably
general setting  along with the assumptions made to allow consistent parameter estimation. In the
usual setting where we have sequences of observations  say {x(1)  x(2)  . . .} with parenthesized
superscripts denoting time  it is straightforward to consistently estimate P . We simply calculate the
empirical frequency of consecutive pairs of states:

cPij := Pt

Pt

Alternatively  suppose for each state j  we have an i.i.d. sample of its immediate next state Dj :=
2   . . . | x(0) = j}  where subscripts are data indices. Consistent estimation in this case
{x
is also easy: the empirical distribution of Dj consistently estimates Pj  the j-th column of P . For

(1)
1   x

(1)

(x(t+1) = i  x(t) = j)

.

(x(t) = j)

3

example  the Markov chain in Figure 1 may produce the following three samples  whose empirical
distributions estimate the three columns of P respectively:

D1 = {2  1  2  2  2  2  2  2  2  2} ⇒ cP1 = [0.1 0.9 0.0]⊤ 
D2 = {3  3  2  3  2  3  3  2  3  3} ⇒ cP2 = [0.0 0.3 0.7]⊤ 
D3 = {1  1  3  1  3  3  1  3  3  1} ⇒ cP3 = [0.5 0.0 0.5]⊤.

A nice property of these estimates is that  unlike in the sequential setting  they do not depend on
any particular ordering of the observations in each set. Nevertheless  such data are not quite non-
sequenced because all observations are made at exactly the next time step. We thus consider the
following generalization: for each state j  we have Dj := {x
  . . . | x(0) = j}  i.e. 
independent samples of states drawn at unknown future times {t1  t2  . . .}. For example  our data in
this setting might be

(t2)
2

(t1)
1

  x

D1 = {2  1  2  3  2  3  3  2  2  3} 
D2 = {3  3  2  3  2  1  3  2  3  1} 
D3 = {1  1  3  1  2  3  2  3  3  2}.

(3)

Obviously it is hard to extract information about P from such data. However  if we assume that
the unknown times {ti} are i.i.d. random variables following some distribution independent of the
initial state j  it can then be easily shown that Dj’s empirical distribution consistently estimates Tj 
the j-th column of the the expected transition probability matrix T := Et[P t]:

D1 = {2  1  2  3  2  3  3  2  2  3} ⇒ cT1 = [0.1 0.5 0.4]⊤ 
D2 = {3  3  2  3  2  1  3  2  3  1} ⇒ cT2 = [0.2 0.3 0.5]⊤ 
D3 = {1  1  3  1  2  3  2  3  3  2} ⇒ cT3 = [0.3 0.3 0.4]⊤.

In general there exist many P ’s that result in the same T . Therefore  as detailed later  we make
a speciﬁc distributional assumption on {ti} to enable unique recovery of the transition matrix P
from T (Assumption A.1). Next we consider a further generalization  where the unknowns are not
only the time stamps of the observations  but also the initial state j. In other words  we only know
each set was generated from the same initial state  but do not know the actual initial state. In this
case  the empirical distributions of the sets consistently estimate the columns of T in some unknown
permutation Π:

DΠ(3) = {1  1  3  1  2  3  2  3  3  2} ⇒ [TΠ(3) = [0.3 0.3 0.4]⊤.
DΠ(2) = {3  3  2  3  2  1  3  2  3  1} ⇒ [TΠ(2) = [0.2 0.3 0.5]⊤ 
DΠ(1) = {2  1  2  3  2  3  3  2  2  3} ⇒ [TΠ(1) = [0.1 0.5 0.4]⊤.

In order to be able to identify Π  we will again resort to randomness and assume the unknown initial
states are random variables following a certain distribution (Assumption A.2) so that the data carry
information about Π. Finally  we generalize from a single unknown initial state to an unknown
initial state distribution  where each set of observations D := {x
(0)} consists of
independent samples of states drawn at random times from some unknown initial state distribution
(0). For example  the data may look like:
π

  . . . | π

(t2)
2

(t1)
1

  x

Dπ

Dπ

Dπ

(0)
1

(0)
2

(0)
3

= {1  3  3  1  2  3  2  3  3  2} 
= {3  1  2  3  2  1  3  2  3  1} 
= {2  1  2  3  3  3  3  1  2  3} 
...

With this ﬁnal generalization  most would agree that the generated data are non-sequenced and that
the generative process is ﬂexible enough to model the real-world situations described in Section
1. However  simple estimation with empirical distributions no longer works because each set may
now contain observations from multiple initial states. This is where we take advantage of the tensor

4

decomposition framework outlined in Section 2  which requires proper assumptions on the initial
state distribution π

(0) (Assumption A.3).

Now we are ready to give the deﬁnition of our entire generative process. Assume we have N sets
of non-sequence data each containing n observations  and each set of observations {xi}n
i=1 were
independently generated by the following:

• Draw an initial distribution

i=1 αi) = π 

(0) ∼ Dirichlet(α) 
π
(0)] = α/(Pm
E[π
• For i = 1  . . .   n 
– Draw a discrete time ti ∼ Geometric(r)  ti ∈ {1  2  3  . . .}.
– Draw an initial state si ∼ Multinomial(π0)  si ∈ {0  1}m.
– Draw an observation xi ∼ Multinomial(P ti si)  xi ∈ {0  1}m.

πi 6= πj ∀ i 6= j.

(Assumption A.3)
(Assumption A.2)

(Assumption A.1)

The above generative process has several properties. First  all the data points in the same set share
the same initial state distribution but can have different initial states; the initial state distribution
varies across different sets and yet centers at the stationary distribution of the Markov chain. As
mentioned in Section 1  this may be achieved in biological studies by running multiple experiments
with different input stimuli  so the data collected in the same experiment can be assumed to have the
same initial state distribution. Second  each data point is drawn from an independent trajectory of
the Markov chain  a similar situation in the modeling of galaxies or Alzheimer’s  and random time
steps could be used to compensate for individual variations in speed: a small/large ti corresponds
to a slowly/fast evolving individual object. Finally  the geometric distribution can be interpreted as
an overall measure of the magnitude of speed variation: a large success probability r would result
in many small ti’  meaning that most objects evolve at similar speeds  while a small r would lead to
ti’s taking a wide range of values  indicating a large speed variation.
To use the tensor decomposition method in Appendix A  we need the tensor structure (2) in certain
low-order moments of observed quantities. The following theorem identiﬁes such quantities:
Theorem 1. Deﬁne the expected transition probability matrix T := Et[P t] = rP (I − (1 − r)P )−1
and let α0 :=Pi αi  C2 := E[x1x⊤

2 ] and C3 := E[x1 ⊗ x2 ⊗ x3]. Then the following holds:
α0+1 T diag(π)T ⊤ + α0

E[x1] = π  C2 = 1

(4)

⊤ 

C3 =

M2

M3

2

(α0+2)(α0+1)Pi πiT ⊗3
:= (α0 + 1)C2 − α0ππ
C3 − (α0+1)α0
:= (α0+2)(α0+1)

i + α0
⊤ = T diag(π)T ⊤ 

α0+1 ππ
d=1 π ⊗d C2 −

α0+2P3
d=1 π ⊗d C2 + α2

2

0π

2 P3

2α2
0

(α0+2)(α0+1) π

⊗3 

⊗3 =Pi πiT ⊗3

i

.

(5)

(6)
(7)

The proof is in Appendix B.1  which relies on the special structure in the moments of the Dirichlet
distribution (Assumption A.3). It is clear that M2 and M3 have the desired tensor structure. As-

suming α0 is known  we can form estimates cM2 and cM3 by computing empirical moments from

the data. Note that the xi’s are exchangeable  so we can use all pairs and triples of data points to
compute the estimates. Interestingly  these low-order moments have a very similar structure to those
in Latent Dirichlet Allocation [1]. Indeed  according to our generative process  we can view a set
of non-sequence data points as a document generated by an LDA model with the expected transi-
tion matrix T as the topic matrix  the stationary distribution π as the topic proportions  and most
importantly  the states as both the words and the topics. The last property is what distinguishes our
generative process from a general LDA model: because both the words and the topics correspond to
the states  the topic matrix is no longer invariant to column permutations. Since the tensor decompo-

sition method may return bT under any column permutation  we need to recover the correct matching
between its rows and columns. Note that the bπ returned by the tensor decomposition method under-
goes the same permutation as bT ’s columns. Because all πi’s have different values by Assumption
A.2  we may recover the correct matching by sorting both the returned bπ and the mean ¯π of all data.
A ﬁnal issue is estimating P and r from bT . This is in general difﬁcult even when the exact T

is available because multiple choices of P and r may result in the same T . However  if the true
transition matrix P has at least one zero entry  then unique recovery is possible:

5

Theorem 2. Let P ∗  r∗  T ∗ and π
∗ denote the true values of the transition probability matrix 
the success probability  the expected transition matrix  and the stationary distribution  respectively.
Assume that P ∗ is ergodic and of full rank  and P ∗
ij = 0 for some i and j. Let S := {λ/(λ − 1) |
λ is a real negative eigenvalue of T ∗} ∪ {0}. Then the following holds:

• 0 ≤ max(S) < r∗ ≤ 1.
• For all r ∈ (0  1] \ S  P (r) := (rI + (1 − r)T ∗)−1T ∗ is well-deﬁned and

1⊤P (r) = 1⊤  P (r)π
P (r)ij ≥ 0 ∀ i  j ⇐⇒ r ≥ r∗.

∗ = π

∗  P ∗ = P (r∗) 

That is  P (r) is a stochastic matrix if and only if r ≥ r∗.
The proof is in Appendix C. This theorem indicates that we can determine r∗ from T ∗ by doing
bi-section on (0  1]. But this approach fails when we replace T ∗ by an estimate bT because even
bP (r∗) might contain negative values. A more practical estimation procedure is the following: for
each value of r in a decreasing sequence starting from 1  project bP (r) := (rI + (1 − r)bT )−1bT onto
of r and projected bP (r) as our estimates.

the space of stochastic matrices and record the projection distance. Then search in the sequence of
projection distances for the ﬁrst sudden increase1 starting from 1  and take the corresponding value

Assuming the true r and α0 are known  with the empirical moments being consistent estimators for
the true moments and the tensor decomposition method guaranteed to return accurate estimates un-
der small input perturbation  we can conclude that the estimates described above will converge (with
high probability) to the true quantities as the sample size N increases. We give sample complexity
bound on estimation error in the next section for hidden Markov models.

3.2 Hidden Markov Models

Let P and π now be deﬁned over the hidden discrete state space of size k and have the same
properties as the ﬁrst-order Markov model. The generative process here is almost identical to (and
therefore share the same interpretation with) the one in Section 3.1  except for an extra mapping
from the discrete hidden state to a continuous observation space:

• Draw a state indicator vector hi ∼ Multinomial(P ti si)  hi ∈ {0  1}k.
• Draw an observation: xi = U hi + ǫi  where U ∈ Rm×k denotes a rank-k matrix of
mean observation vectors for the k hidden states  and the random noise vectors ǫi’s are i.i.d
satisfying E[ǫi] = 0 and Var[ǫi] = σ2I.

Note that a spherical covariance2 is required for the tensor decomposition method to be applicable.
The low-order moments that lead to the desired tensor structure are given in the following:
Theorem 3. Deﬁne the expected hidden state transition matrix T := Et[P t] = rP (I − (1− r)P )−1
and let α0 := Pi αi  V1 := E[x1]  V2 := E[x1x⊤
2 ] and C3 :=
E[x1 ⊗ x2 ⊗ x3]. Then the following holds:

1 ]  C2 := E[x1x⊤

1 ]  V3 := E[x⊗3

V1 = U π  V2 = Udiag(π)U ⊤ + σ2I 
M2
C2 =

:= V2 − σ2I = Udiag(π)U ⊤  M3 := V3 −P3

α0+1 U T diag(π)(U T )⊤ + α0

α0+1 V1V ⊤
1  

1

V3 = Pi πiU ⊗3

i +P3

d=1 V1 ⊗d (σ2I) 
d=1 V1 ⊗d (σ2I) =Pi πiU ⊗3
 

i

2

C3 =
M ′
2
M ′
3

(α0+2)(α0+1)Pi πi(U T )⊗3
C3 − (α0+1)α0

:= (α0 + 1)C2 − α0V1V ⊤
:= (α0+2)(α0+1)

2

d=1 V1 ⊗d C2 −

α0+2P3
d=1 V1 ⊗d C2 + α2

1 = U T diag(π)(U T )⊤ 

i + α0

2 P3

2α2
0

(α0+2)(α0+1) V ⊗3

1

0V ⊗3

1 =Pi πi(U T )⊗3

i

.

1Intuitively the jump should be easier to locate as P gets sparser  but we do not have a formal result.
2We may allow different covariances σ2

I for different hidden states. See Section 3.2 of [2] for details.

j

6

Algorithm 1 Tensor decomposition method for learning HMM from non-sequence data
input N sets of non-sequence data points  the success probability r  the Dirichlet parameter α0  the

number of hidden states k  and numbers of iterations L and N.

3

⊤

).

2  cM ′

4: Run Algorithm A.2 (Appendix A) k times each with numbers of iterations L and N  the input

output Estimates bπ  eP and eU possibly under permutation of state labels.
1: Compute empirical averagescV1 cV2 cV3 cC2 cC3  andcσ2 := λmin(cV2 −cV1cV1
2: Compute cM2  cM3  cM ′
3: Run Algorithm A.1 (Appendix A) on cM2 and cM3 with the number of hidden states k to obtain
a symmetric tensor bT ∈ Rk×k×k and a whitening transformation cW ∈ Rm×k.
tensor in the ﬁrst run set to bT and in each subsequent run set to the deﬂated tensor returned by
the previous run  resulting in k pairs of eigenvalue/eigenvector {( ˆλi  bvi)}k
i  bv′
2 and cM ′
5: Repeat Steps 4 and 5 on cM ′
3 to obtaincT ′  cW ′ and {( ˆλ′
i=1.
i)}k
i  bv′
i=1 with {( ˆλ′
i=1 and { ˆλ′
6: Match {( ˆλi  bvi)}k
i=1 by sorting { ˆλi}k
i=1.
i)}k
i}k
7: Obtain estimates of HMM parameters:
bU := (cW ⊤)†bVbΛ 
dU T := (cW ′)†cV ′bΛ′ 
bπ := [ ˆλ′
bP := (rbU + (1 − r)dU T )†dU T  

where bV := [cv1 ···cvk] bΛ := diag([ ˆλ1 ··· ˆλk]⊤);cV ′ and bΛ′ are deﬁned in the same way.
8: (Optional) Project bπ onto the simplex and bP onto the space of stochastic matrices.

··· ˆλ′

i=1.

]⊤ 

−2

−2

1

k

The proof is in Appendix B.2. This theorem suggests that  unlike ﬁrst-order Markov models  HMMs
require two applications of the tensor decomposition methods  one on M2 and M3 for extracting
3 for extracting the matrix product
the mean observation vectors U  and the other on M ′
U T . Another issue is that the estimates for M2 and M3 require an estimate for the noise variance
σ2  which is not directly observable. Nevertheless  since M2 and M3 are in the form of low-order
moments of spherical Gaussian mixtures  we may use the existing result (Theorem 3.2  [2]) to obtain
an estimatebσ2 = λmin(cV2 − bV1bV ⊤
1 ). The situation regarding permutations of the estimates is also
different here. First note that P = (rU +(1−r)U T )†U T  which implies that permuting the columns
of U and the columns of U T in the same manner has the effect of permuting both the rows and the
columns of P   essentially re-labeling the hidden states. Hence we can only expect to recover P up
to some simultaneous row and column permutation. By the assumption that πi’s are all different  we

2 and M ′

can sort the two estimates bπ and bπ′ to match the columns of bU anddU T   and obtain bP if r is known.
When r is unknown  a similar heuristics to the one for ﬁrst-order Markov models can be used to
estimate r  based on the fact that P = (rU + (1 − r)U T )†U T = (rI + (1 − r)T )−1T   suggesting
that Theorem 2 remains true when expressing P by U and U T .
Algorithm 1 gives the complete procedure for learning HMM from non-sequence data. Combining
the perturbation bounds of the tensor decomposition method (Appendix A)  the whitening procedure
(Appendix D.1) and the matrix pseudoinverse [10]  and concentration bounds on empirical moments
(Appendix D.3)  we provide a sample complexity analysis:
Theorem 4. Suppose the numbers of iterations N and L for Algorithm A.2 satisfy the conditions in
Theorem A.1 (Appendix A)  and the number of hidden states k  the success probability r  and the
Dirichlet parameter α0 are all given. For any η ∈ (0  1) and ǫ > 0  if the number of sets N satisﬁes
N ≥
ǫ2σk(rU + (1 − r)U T )4 min(σk(U T )  σk(U )  1)4(cid:19)  
max(cid:18) 225000
where c is some constant  ν := max(σ2 + maxi j(|Uik|2)  1)  δmin := mini j |1/√πj − 1/√πj| 
and σi(·) denotes the i-th largest singular value  then the bP and bU returned by Algorithm 1 satisfy
(cid:19) ≥ 1 − η 
Prob(kP − bPk ≤ ǫ) ≥ 1 − η

and Prob(cid:18)kU − bUk ≤

η
4600
2)  σk(M2))2  

42000c2σ1(U T )2 max(σ1(U T )  σ1(U )  1)2

12 max(k2  m)m3ν3(α0 + 2)2(α0 + 1)2

ǫσk(rU + (1 − r)U T )2

min(σk(M ′

6σ1(U T )

δ2
min

·

 

7

(a) Matrix estimation error

(b) Projection distance

Figure 2: Simulation results

where P and U may undergo label permutation.

The proof is in Appendix E. In this result  the sample size N exhibits a fairly high-order polynomial
dependency on m  k  ǫ−1 and scales with 1/η linearly instead of logarithmically  as is common in
sample complexity results on spectral learning. This is because we do not impose any constraints
on the observation model and simply use the Markov inequality for bounding the deviation in the
empirical moments. If we make stronger assumptions such as boundedness or sub-Gaussianity  it
is possible to use stronger  exponential tail bounds to obtain better sample complexity. Also worth
noting is that δ−2
min acts as a threshold. As shown in our proof  as long as the operator norm of
the tensor perturbation is sufﬁciently smaller than δmin  which measures the gaps between different
πi’s  we can correctly match the two sets of estimated tensor eigenvalues. Lastly  the lower bound
of N  as one would expect  depends on conditions of the matrices being estimated as reﬂected in
the various ratios of singular values. An interesting quantity missing from the sample analysis is the
size of each set n. To simplify the analysis we essentially assume n = 3  but understanding how
n might affect the sample complexity may have a critical impact in practice: when collecting more
data  should we collect more sets or larger sets? What is the trade-off between them? This is an
interesting direction for future work.

4 Simulation

Our HMM has m = 40 and k = 5 with Gaussian noise σ2 = 2. The mean vectors U were sampled
from independent univariate standard normal and then normalized to lie on the unit sphere. The
transition matrix P contains one zero entry. For the generative process  we set α0 = 1  r = 0.3  n =
1000  and N ∈ 1000{20  21  . . .   210}. The numbers of iterations for Algorithm A.2 were N = 200
and L = 1000. Figure 2(a) plots the relative matrix estimation error (in spectral norm) against the
sample size N for P   U  and U T obtained by Algorithm 1 given the true r. It is clear that U is
the easiest to learn  followed by U T   and P is the most difﬁcult  and that all three errors converge
to a very small value for sufﬁciently large N. Note that in Theorem 4 the bounds for P and U are
different. With the model used here  the extra multiplicative factor in the bound for U is less than
0.007  suggesting that U is indeed easier to estimate than P . Figure 2(b) demonstrates the heuristics
for determining r  showing projection distances (in logarithm) versus r. As N increases  the take-off
point gets closer to the true r = 0.3. The large peak indicates a pole (the set S in Theorem 2).

5 Conclusions

We have demonstrated that under reasonable assumptions  tensor decomposition methods can prov-
ably learn ﬁrst-order Markov models and hidden Markov models from non-sequence data. We
believe this is the ﬁrst formal guarantee on learning dynamic models in a non-sequential setting.
There are several ways to extend our results. No matter what distribution generates the random time
steps  tensor decomposition methods can always learn the expected transition probability matrix T .
Depending on the application  it might be better to use some other distribution for the missing time.
The proposed algorithm can be modiﬁed to learn discrete HMMs under a similar generative process.
Finally  applying the proposed methods to real data should be the most interesting future direction.

8

References

[1] A. Anandkumar  D. P. Foster  D. Hsu  S. M. Kakade  and Y.-K. Liu. A spectral algorithm for

latent dirichlet allocation. arXiv preprint arXiv:1204.6703v4  2013.

[2] A. Anandkumar  R. Ge  D. Hsu  S. M. Kakade  and M. Telgarsky. Tensor decompositions for

learning latent variable models. arXiv preprint arXiv:1210.7559v2  2012.

[3] A. Anandkumar  D. Hsu  and S. M. Kakade. A method of moments for mixture models and

hidden Markov models. arXiv preprint arXiv:1203.0683  2012.

[4] S. Arora  R. Ge  Y. Halpern  D. Mimno  A. Moitra  D. Sontag  Y. Wu  and M. Zhu. A practical
algorithm for topic modeling with provable guarantees. arXiv preprint arXiv:1212.4777  2012.
[5] D. Hsu and S. M. Kakade. Learning mixtures of spherical gaussians: moment methods and
spectral decompositions. In Proceedings of the 4th conference on Innovations in Theoretical
Computer Science  pages 11–20. ACM  2013.

[6] T.-K. Huang and J. Schneider. Learning linear dynamical systems without sequence infor-
In Proceedings of the 26th International Conference on Machine Learning  pages

mation.
425–432  2009.

[7] T.-K. Huang and J. Schneider. Learning auto-regressive models from sequence and non-
sequence data. In Advances in Neural Information Processing Systems 24  pages 1548–1556.
2011.

[8] T.-K. Huang  L. Song  and J. Schneider. Learning nonlinear dynamic models from non-
sequenced data. In Proceedings of the 13th International Conference on Artiﬁcial Intelligence
and Statistics  2010.

[9] M. G. Rabbat  M. A. Figueiredo  and R. D. Nowak. Network inference from co-occurrences.

Information Theory  IEEE Transactions on  54(9):4053–4068  2008.

[10] G. Stewart. On the perturbation of pseudo-inverses  projections and linear least squares prob-

lems. SIAM review  19(4):634–662  1977.

[11] X. Zhu  A. B. Goldberg  M. Rabbat  and R. Nowak. Learning bigrams from unigrams. In the
Proceedings of 46th Annual Meeting of the Association for Computational Linguistics: Human
Language Technology  Columbus  OH  2008.

9

,Tzu-Kuo Huang
Jeff Schneider
Evan Archer
Urs Koster
Jonathan Pillow
Jakob Macke
Nikolaos Tziavelis
Ioannis Giannakopoulos
Katerina Doka
Nectarios Koziris
Panagiotis Karras