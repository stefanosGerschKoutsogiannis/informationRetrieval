2011,Learning Auto-regressive Models from Sequence and Non-sequence Data,Vector Auto-regressive models (VAR) are useful tools for analyzing time series  data. In quite a few modern time series modelling tasks  the collection of reliable  time series turns out to be a major challenge  either due to the slow progression of  the dynamic process of interest  or inaccessibility of repetitive measurements of  the same dynamic process over time. In those situations  however  we observe that  it is often easier to collect a large amount of non-sequence samples  or snapshots  of the dynamic process of interest. In this work  we assume a small amount of time  series data are available  and propose methods to incorporate non-sequence data  into penalized least-square estimation of VAR models. We consider non-sequence  data as samples drawn from the stationary distribution of the underlying VAR  model  and devise a novel penalization scheme based on the discrete-time Lyapunov  equation concerning the covariance of the stationary distribution. Experiments  on synthetic and video data demonstrate the effectiveness of the proposed  methods.,Learning Auto-regressive Models from Sequence and

Non-sequence Data

Tzu-Kuo Huang

Machine Learning Department

Carnegie Mellon University
tzukuoh@cs.cmu.edu

Jeff Schneider
Robotics Institute

Carnegie Mellon University
schneide@cs.cmu.edu

Abstract

Vector Auto-regressive models (VAR) are useful tools for analyzing time series
data. In quite a few modern time series modelling tasks  the collection of reliable
time series turns out to be a major challenge  either due to the slow progression of
the dynamic process of interest  or inaccessibility of repetitive measurements of
the same dynamic process over time. In those situations  however  we observe that
it is often easier to collect a large amount of non-sequence samples  or snapshots
of the dynamic process of interest. In this work  we assume a small amount of time
series data are available  and propose methods to incorporate non-sequence data
into penalized least-square estimation of VAR models. We consider non-sequence
data as samples drawn from the stationary distribution of the underlying VAR
model  and devise a novel penalization scheme based on the Lyapunov equation
concerning the covariance of the stationary distribution. Experiments on synthetic
and video data demonstrate the effectiveness of the proposed methods.

1

Introduction

Vector Auto-regressive models (VAR) are an important class of models for analyzing multivariate
time series data. They have proven to be very useful in capturing and forecasting the dynamic
properties of time series in a number of domains  such as ﬁnance and economics [18  13]. Recently 
researchers in computational biology applied VAR models in the analysis of genomic time series
[12]  and found interesting results that were unknown previously.

In quite a few scientiﬁc modeling tasks  a major difﬁculty turns out to be the collection of reliable
time series data. In some situations  the dynamic process of interest may evolve slowly over time 
such as the progression of Alzheimer’s or Parkinson’s diseases  and researchers may need to spend
months or even years tracking the dynamic process to obtain enough time series data for analysis.
In other situations  the dynamic process of interest may not be able to undergo repetitive measure-
ments  so researchers have to measure multiple instances of the same process while maintaining
synchronization among these instances. One such example is gene expression time series. In their
study  [19] measured expression proﬁles of yeast genes along consecutive metabolic cycles. Due to
the destructive nature of the measurement technique  they collected expression data from multiple
yeast cells. In order to obtain reliable time series data  they spent a lot of effort developing a stable
environment to synchronize the cells during the metabolic cycles. Yet  they point out in their discus-
sion that such a synchronization scheme may not work for other species  e.g.  certain bacteria and
fungi  as effectively as for yeast.

While obtaining reliable time series can be difﬁcult  we observe that it is often easier to collect non-
sequence samples  or snapshots of the dynamic process of interest1. For example  a scientist studying

1 In several disciplines  such as social and medical sciences  the former is usually referred to as a longitudi-

nal study  while the latter is similar to what is called a cross-sectional study.

1

Alzheimer’s or Parkinson’s can collect samples from his or her current pool of patients  each of
whom may be in a different stage of the disease. Or in gene expression analysis  current technology
already enables large-scale collection of static gene expression data. Previously [6] investigated
ways to extract dynamics from such static gene expression data  and more recently [8  9] proposed
methods for learning ﬁrst-order dynamic models from general non-sequence data. However  most
of these efforts suffer from a fundamental limitation: due to lack of temporal information  multiple
dynamic models may ﬁt the data equally well and hence certain characteristics of dynamics  such as
the step size of a discrete-time model and the overall temporal direction  become non-identiﬁable.

In this work  we aim to combine these two types of data to improve learning of dynamic models. We
assume that a small amount of sequence samples and a large amount of non-sequence samples are
available. Our aim is to rely on the few sequence samples to obtain a rough estimate of the model 
while reﬁning this rough estimate using the non-sequence samples. We consider the following ﬁrst-
order p-dimensional vector auto-regressive model:

xt+1 = xtA + ǫ

t+1 

(1)

where xt ∈ R1×p is the state vector at time t  A ∈ Rp×p is the transition matrix  and ǫ
t is a white-
noise process with a time-invariant variance σ2I. Given a sequence sample  a common estimation
method for A is the least-square estimator  whose properties have been studied extensively (see e.g. 
[7]). We assume that the process (1) is stable  i.e.  the eigenvalues of A have modulus less than one.
As a result  the process (1) has a stationary distribution  whose covariance Q is determined by the
following discrete-time Lyapunov equation:

A⊤QA + σ2I = Q.

(2)

ǫ

Linear quadratic Lyapunov theory (see e.g.  [1]) gives that Q is uniquely determined if and only if
λi(A)λj(A) 6= 1 for 1 ≤ i  j ≤ p  where λi(A) is the i-th eigenvalue of A. If the noise process
t follows a normal distribution  the stationary distribution also follows a normal distribution  with
covariance Q determined as above. Since our goal is to estimate A  a more relevant perspective is
viewing (2) as a system of constraints on A. What motivates this work is that the estimation of Q
requires only samples drawn from the stationary distribution rather than sequence data. However 
even if we have the true Q and σ2  we still cannot uniquely determine A because (2) is an under-
determined system2 of A. We thus rely on the few sequence samples to resolve the ambiguity.
We describe the proposed methods in Section 2  and demonstrate their performance through exper-
iments on synthetic and video data in Section 3. Our ﬁnding in short is that when the amount of
sequence data is small and our VAR model assumption is valid  the proposed methods of incorporat-
ing non-sequence data into estimation signiﬁcantly improve over standard methods  which use only
the sequence data. We conclude this work and discuss future directions in Section 4.

2 Proposed Methods

Let {xi}T
estimator for the transition matrix A is the solution to the following minimization problem:

i=1 be a sequence of observations generated by the process (1). The standard least-square

min

A

kY − XAk2
F  

(3)

where Y ⊤ := [(x2)⊤ (x3)⊤ · · · (xT )⊤]  X ⊤ := [(x1)⊤ (x2)⊤ · · · (xT −1)⊤]  and k · kF denotes
the matrix Frobenius norm. When p > T   which is often the case in modern time series modeling
tasks  the least square problem (3) has multiple solutions all achieving zero squared error  and the
resulting estimator overﬁtts the data. A common remedy is adding a penalty term on A to (3) and
minimizing the resulting regularized sum of squared errors. Usual penalty terms include the ridge
penalty kAk2

F and the sparse penalty kAk1 :=Pi j |Aij|.

Now suppose we also have a set of non-sequence observations {zi}n
i=1 drawn independently from
the stationary distribution of (1). Note that we use superscripts for time indices and subscripts for
data indices. As described in Section 1  the size n of the non-sequence sample can usually be much
larger than the size T of the sequence data. To incorporate the non-sequence observations into the

2If we further require A to be symmetric  (2) would be a simpliﬁed Continuous-time Algebraic Riccati

Equation  which has a unique solution under some conditions (c.f. [1]).

2

A = (cid:20)−0.4280

−1.0428 −0.7144(cid:21)

0.5723

(5)

(a) SSE and Ridge

(b) Lyap

(c) SSE+Ridge+ 1

2 Lyap

Figure 1: Level sets of different functions in a bivariate AR example

estimation procedure  we ﬁrst obtain a covariance estimate bQ of the stationary distribution from

the non-sequence sample  and then turn the Lyapunov equation (2) into a regularization term on A.
More precisely  in addition to the usual ridge or sparse penalty terms  we also consider the following
regularization:

(4)
which we refer to as the Lyapunov penalty. To compare (4) with the ridge penalty and the sparse
penalty  we consider (3) as a multiple-response regression problem and view the i-th column of A as
the regression coefﬁcient vector for the i-th output dimension. From this viewpoint  we immediately
see that both the ridge and the sparse penalizations treat the p regression problems as unrelated. On
the contrary  the Lyapunov penalty incorporates relations between pairs of columns of A by using a

kA⊤bQA + σ2I − bQk2

F  

covariance estimate bQ. In other words  although the non-sequence sample does not provide direct

information about the individual regression problems  it does reveal how the regression problems
are related to one another. To illustrate how the Lyapunov penalty may help to improve learning  we
give an example in Figure 1. The true transition matrix is

and ǫ

t ∼ N (0  I). We generate a sequence of 4 points  draw a non-sequence sample of 20 points

independently from the stationary distribution and obtain the sample covariance bQ. We ﬁx the

second column of A but vary the ﬁrst  and plot in Figure 1(a) the resulting level sets of the sum of
squared errors on the sequence (SSE) and the ridge penalty (Ridge)  and in Figure 1(b) the level
sets of the Lyapunov penalty (Lyap). We also give coordinates of the true [A11 A21]⊤  the minima
of SSE  Ridge  and Lyap  respectively. To see the behavior of the ridge regression  we trace out
a path of the ridge regression solution by varying the penalization parameter  as indicated by the
red-to-black curve in Figure 1(a). This path is pretty far from the true model  due to insufﬁcient
sequence data. For the Lyapunov penalty  we observe that it has two local minima  one of which is
very close to the true model  while the other  also the global minimum  is very far. Thus  neither
ridge regression nor the Lyapunov penalty can be used on its own to estimate the true model well.
But as shown in Figure 1(c)  the combined objective  SSE+Ridge+ 1
2 Lyap  has its global minimum
very close to the true model. This demonstrates how the ridge regression and the Lyapunov penalty
may complement each other: the former by itself gives an inaccurate estimation of the true model 
but is just enough to identify a good model from the many candidate local minima provided by the
latter.

In the following we describe our proposed methods for incorporating the Lyapunov penalty (4) into
ridge and sparse least-square estimation. We also discuss robust estimation for the covariance Q.

2.1 Ridge and Lyapunov penalty

Here we estimate A by solving the following problem:

min

A

1
2

kY − XAk2

F +

λ1
2

kAk2

F +

λ2
4

3

kA⊤bQA + σ2I − bQk2

F  

(6)

where bQ is a covariance estimate obtained from the non-sequence sample. We treat λ1  λ2 and σ2

as hyperparameters and determine their values on a validation set. Given these hyperparameters  we
solve (6) by gradient descent with back-tracking line search for the step size. The gradient of the
objective function is given by

(7)
As mentioned before  (6) is a non-convex problem and thus requires good initialization. We use the
following two initial estimates of A:

− X ⊤Y + X ⊤XA + λ1A + λ2bQA(A⊤bQA + σ2I − bQ).

where (·)† denotes the Moore-Penrose pseudo inverse of a matrix  making bAlsq the minimum-norm

solution to the least square problem (3). We run the gradient descent algorithm with these two initial
estimates  and choose the estimated A that gives a smaller objective.

and

bAridge := (X ⊤X + λ1I)−1X ⊤Y 

bAlsq := (X ⊤X)†X ⊤Y

(8)

2.2 Sparse and Lyapunov penalty

Sparse learning for vector auto-regressive models has become a useful tool in many modern time
series modeling tasks  where the number p of states in the system is usually larger than the length
T of the time series. For example  an important problem in computational biology is to understand
the progression of certain biological processes from some measurements  such as temporal gene
expression data.

Using an idea similar to (6)  we estimate A by

1
2

min

kY − XAk2

F +

A
s.t. kAk1 ≤ λ1.

λ2
4

kA⊤bQA + σ2I − bQk2

F  

(9)

Instead of adding a sparse penalty on A to the objective function  we impose a constraint on the
ℓ1 norm of A. Both the penalty and the constraint formulations have been considered in the sparse
learning literature  and shown to be equivalent in the case of a convex objective. Here we choose
the constraint formulation because it can be solved by a simple projected gradient descent method.
On the contrary  the penalty formulation leads to a non-smooth and non-convex optimization prob-
lem  which is difﬁcult to solve with standard methods for sparse learning. In particular  the soft-
thresholding-based coordinate descent method for LASSO does not apply due to the Lyapunov
regularization term. Moreover  most of the common methods for non-smooth optimization  such
as bundle methods  solve convex problems and need non-trivial modiﬁcation in order to handle
non-convex problems [14].

Let J(A) denote the objective function in (9) and A(k) denote the intermediate solution at the k-th
iteration. Our projected gradient method updates A(k) to A(k+1) by the following rule:

(10)
where η(k) > 0 denotes a proper step size  ∇J(A(k)) denotes the gradient of J(·) at A(k)  and Π(·)
denotes the projection onto the feasible region kAk1 ≤ λ1. More precisely  for any p-by-p real
matrix V we deﬁne

A(k+1) ← Π(A(k) − η(k)∇J(A(k))) 

Π(V ) := arg min

kAk1≤λ1

kA − V k2
F .

(11)

To compute the projection  we use the efﬁcient ℓ1 projection technique given in Figure 2 of [5] 
whose expected running time is linear in the size of V .

For choosing a proper step size η(k)  we consider the simple and effective Armijo rule along the
projection arc described in [2]. This procedure is given in Algorithm 1  and the main idea is to
ensure a sufﬁcient decrease in the objective value per iteration (13). [2] proved that there always
exists η(k) = βrk > 0 satisfying (13)  and every limit point of {A(k)}∞
k=0 is a stationary point of
(9). In our experiments we set c = 0.01 and β = 0.1  both of which are typical values used in
gradient descent. As in the previous section  we need good initializations for the projected gradient
descent method. Here we use these two initial estimates:

bAlsq′

:= arg min

kAk≤λ1

F

kA − bAlsqk2

and

bAsp := arg min

kAk≤λ1

where bAlsq is deﬁned in (8)  and then choose the one that leads to a smaller objective value.

1
2

kY − XAk2
F  

(12)

4

Algorithm 1: Armijo’s rule along the projection arc
Input
Output: A(k+1)

: A(k)  ∇J(A(k))  0 < β < 1  0 < c < 1.

1 Find η(k) = max{βrk |rk ∈ {0  1  . . .}} such that A(k+1) := Π(A(k) − η(k)∇J(A(k))) satisﬁes

J(A(k+1)) − J(A(k)) ≤ c trace(cid:16)∇J(A(k))⊤(A(k+1) − A(k))(cid:17)

(13)

2.3 Robust estimation of covariance matrices

To obtain a good estimator for A using the proposed methods  we need a good estimator for the
covariance of the stationary distribution of (1). Given an independent sample {zi}n
i=1 drawn from
the stationary distribution  the sample covariance is deﬁned as

S :=

1

n − 1

nXi=1

(zi − ¯z)⊤(zi − ¯z)  where ¯z := Pn

i=1
n

zi

.

(14)

Although unbiased  the sample covariance is known to be vulnerable to outliers  and ill-conditioned
when the number of sample points n is smaller than the dimension p. Both issues arise in many
real world problems  and the latter is particularly common in gene expression analysis. Therefore 
researchers in many ﬁelds  such as statistics [17  20  11]  ﬁnance [10]  signal processing [3  4]  and
recently computational biology [15]  have investigated robust estimators of covariances. Most of
these results originate from the idea of shrinkage estimators  which shrink the covariance matrix
towards some target covariance with a simple structure  such as a diagonal matrix.
It has been
shown in  e.g.  [17  10] that shrinking the sample covariance can achieve a smaller mean-squared
error (MSE). More speciﬁcally  [10] considers the following linear shrinkage:

bQ = (1 − α)S + αF
E(kbQ − Qk2

α∗ := arg min
0≤α≤1

F ) 

(15)

(16)

(19)

(20)

for 0 < α < 1 and some target covariance F   and derive a formula for the optimal α that minimizes
the mean-squared error:

which involves unknown quantities such as true covariances of S. [15] proposed to estimate α∗ by
replacing all the population quantities appearing in α∗ by their unbiased empirical estimates  and

use the estimator proposed in [15] with the following F :

derived the resulting estimatorbα∗ for several types of target F . For the experiments in this paper we

1 ≤ i  j ≤ p.

(17)

Fij =(cid:26)Sij 

0

if i = j 
otherwise 

Denoting the sample correlation matrix as R  we give the ﬁnal estimator bQ (Table 1 in [15]) below:
bQij :=(Sij 

if i = j 
otherwise 

if i = j 
otherwise 

(18)

n

bRijpSiiSjj
bα∗ := Pi6=j cVar(Rij)
Pi6=j R2

ij

bRij :=(cid:26)1 
= Pi6=j

where

k=1(wkij − ¯wij)2

Rij min(1  max(0  1 −bα∗))
(n−1)3Pn
Pi6=j R2
¯wij := Pn

k=1 wkij

n

ij

 

 

wkij := (˜zk)i(˜zk)j 

and {˜zi}n

i=1 are standardized non-sequence samples.

5

(a)

(b)

(c)

(d) Eigenvalues in modulus

Figure 2: Testing performances and eigenvalues in modulus for the dense model

3 Experiments

To evaluate the proposed methods  we conduct experiments on synthetic and video data. In both sets

of experiments we use the following two performance measures for a learnt model bA:

1

Normalized error:

kxt+1 − xtk2 .

T −1Xt=1
kxt+1 − xtbAk2
kxt+1 − xtkkxtbA − xtk(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
T −1Xt=1
(xt+1 − xt)⊤(xtbA − xt)

.

T − 1

1

T − 1(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

Cosine score:

t+1  ǫ

out that a constant prediction ˆxt+1 = xt leads to a normalized error of 1  and a random-walk
t+1 being a white-noise process  results in a nearly-zero cosine
prediction ˆxt+1 = xt + ǫ

To give an idea of how a good estimate bA would perform under these two measures  we point
score. Thus  when the true model is more than a simple random walk  a good estimate bA should
matrix A  so we consider a third criterion  the matrix error: kbA − AkF /kAkF .

achieve a normalized error much smaller than 1 and a cosine score way above 0. We also note that
the cosine score is upper-bounded by 1. In experiments on synthetic data we have the true transition

In all our experiments  we have a training sequence  a testing sequence  and a non-sequence sample.
To choose the hyper-parameters λ1  λ2 and σ2  we split the training sequence into two halves and
use the second half as the validation sequence. Once we ﬁnd the best hyper-parameters according to
the validation performance  we train a model on the full training sequence and predict on the testing
sequence. For λ1 and λ2  we adopt the usual grid-search scheme with a suitable range of values.

For σ2  we observe that (2) implies bQ − σ2I should be positive semideﬁnite  and thus search the set
{0.9j mini λi(bQ) | 1 ≤ j ≤ 3}. In most of our experiments  we ﬁnd that the proposed methods are

much less sensitive to σ2 than to λ1 and λ2.

3.1 Synthetic Data

We consider the following two VAR models with a Gaussian white noise process ǫ

t ∼ N (0  I).

Dense Model:

A =

0.95M

max(|λi(M )|)

  Mij ∼ N (0  1)  1 ≤ i  j ≤ 200.

Sparse Model:

A =

0.95(M ⊙ B)

max(|λi(M ⊙ B)|)

  Mij ∼ N (0  1)  Bij ∼ Bern (1/8)  1 ≤ i  j ≤ 200 

where Bern(h) is the Bernoulli distribution with success probability h  and ⊙ denotes the entrywise
product of two matrices. By setting h = 1/8  we make the sparse transition matrix A have roughly
40000/8 = 5000 non-zero entries. Both models are stable  and the stationary distribution for each
model is a zero-mean Gaussian. We obtain the covariance Q of each stationary distribution by
solving the Lyapunov equation (2). For a single experiment  we generate a training sequence and a
testing sequence  both initialized from the stationary distribution  and draw a non-sequence sample
independently from the stationary distribution. We set the length of the testing sequence to be

6

(a)

(b)

(c)

(d) Eigenvalues in modulus

Figure 3: Testing performances and eigenvalues in modulus for the sparse model

800  and vary the training sequence length T and the non-sequence sample size n: for the dense
model  T ∈ {50  100  150  200  300  400  600  800} and n ∈ {50  400  1600}; for the sparse model 
T ∈ {25  75  150  400} and n ∈ {50  400  1600}. Under each combination of T and n  we compare
the proposed Lyapunov penalization method with the baseline approach of penalized least square 
which uses only the sequence data. To investigate the limit of the proposed methods  we also use the
true Q for the Lyapunov penalization. We run 10 such experiments for the dense model and 5 for the
sparse model  and report the overall performances of both the proposed and the baseline methods.

3.1.1 Experimental results for the dense model

We give boxplots of the three performance measures in the 10 experiments in Figures 2(a) to 2(c).
The ridge regression approach and the proposed Lyapunov penalization method (6) are abbreviated
as Ridge and Lyap  respectively. For normalized error and cosine score  we also report the perfor-
mance of the true A on testing sequences.
We observe that Lyap improves over Ridge more signiﬁcantly when the training sequence length
T is small (≤ 200) and the non-sequence sample size n is large (≥ 400). When T is large  Ridge
already performs quite well and Lyap does not improve the performance much. But with the true
stationary covariance Q  Lyap outperforms Ridge signiﬁcantly for all T . When n is small  the

covariance estimate bQ is far from the true Q and the Lyapunov penalty does not provide useful

information about A.
In this case  the value of λ2 determined by the validation performance is
usually quite small (0.5 or 1) compared to λ1 (256)  so the two methods perform similarly on testing
sequences. We note that if instead of the robust covariance estimate in (18) and (19) we use the
sample covariance  the performance of Lyap can be marginally worse than Ridge when n is small.

qualitative assessment of the estimated transition matrices  in Figure 2(d) we plot the eigenvalues in

A precise statement on how the estimation error in Q affects bA is worth studying in the future. As a
modulus of the true A and the bA’s obtained by different methods when T = 50 and n = 1600. The

eigenvalues are sorted according to their modulus. Both Ridge and Lyap severely under-estimate the
eigenvalues in modulus  but Lyap preserves the spectrum much better than Ridge.

3.1.2 Experimental results for the sparse model

We give boxplots of the performance measures in the 5 experiments in Figures 3(a) to 3(c)  and the

and the proposed method (9) are abbreviated as Sparse and Lyap  respectively.

eigenvalues in modulus of the true A and some bA’s in Figure 3(d). The sparse least-square method

We observe the same type of improvement as in the dense model: Lyap improves over Sparse more
signiﬁcantly when T is small and n is large. But the largest improvement occurs when T = 75  not
the shortest training sequence length T = 25. A major difference lies in the impact of the Lyapunov

penalization on the spectrum of bA  as revealed in Figure 3(d). When T is as small as 25  the sparse

least-square method shrinks all the eigenvalues but still keep most of them non-zero  while Lyap
with a non-sequence sample of size 1600 over-estimates the ﬁrst few largest eigenvalues in modulus
but shrink the rest to have very small modulus. In contrast  Lyap with the true Q preserves the
spectrum much better. We may thus need an even better covariance estimate for the sparse model.

7

r
o
r
r
e

 

d
e
z

i
l

a
m
r
o
N

2

1.5

1

0.5

0
 

 

Ridge
Lyap

T=6

T=10

T=20

T=50

(a) The pendulum

(b) Normalized error

1

0.8

e
r
o
c
s
 

i

e
n
s
o
C

0.6

0.4

0.2

0
 

Ridge
Lyap

 

T=6

T=10

T=20

T=50

(c) Cosine score

Figure 4: Results on the pendulum video data

3.2 Video Data

We test our methods using a video sequence of a periodically swinging pendulum3  which consists
of 500 frames of 75-by-80 grayscale images. One such frame is given in Figure 4(a) The period
is about 23 frames. To further reduce the dimension we take the second-level Gaussian pyramids 
resulting in images of size 9-by-11. We then treat each reduced image as a 99-dimensional vector 
and normalize each dimension to be zero-mean and standard deviation 1. We analyze this sequence
with a 99-dimensional ﬁrst-order VAR model. To check whether a VAR model is a suitable choice 
we estimate a transition matrix from the ﬁrst 400 frames by ridge regression while choosing the
penalization parameter on the next 50 frames  and predict on the last 50 frames. The best penal-
ization parameter is 0.0156  and the testing normalized error and cosine score are 0.33 and 0.97 
respectively  suggesting that the dynamics of the video sequence is well-captured by a VAR model.

We compare the proposed method (6) with the ridge regression for two lengths of the training se-
quence: T ∈ {6  10  20  50}  and treat the last 50 frames as the testing sequence. For both methods 
we split the training sequence into two halves and use the second half as a validation sequence. For
the proposed method  we simulate a non-sequence sample by randomly choosing 300 frames from
between the (T + 1)-st frame and the 450-th frame without replacement. We repeat this 10 times.
The testing normalized errors and cosine scores of both methods are given in Figures 4(b) and 4(c).
For the proposed method  we report the mean performance measures over the 10 simulated non-
sequence samples with standard deviation. When T ≤ 20  which is close to the period  the proposed
method outperforms ridge regression very signiﬁcantly except when T = 10 the cosine score of
Lyap is barely better than Ridge. However  when we increase T to 50  the difference between the
two methods vanishes  even though there is still much room for improvement as indicated by the
result of our model sanity check before. This may be due to our use of dependent data as the non-
sequence sample  or simply insufﬁcient non-sequence data. As for λ1 and λ2  their values decrease
respectively from 512 and 2 048 to less than 32 as T increases  but since we ﬁx the amount of non-
sequence data  the interaction between their value changes is less clear than on the synthetic data.

4 Conclusion

We propose to improve penalized least-square estimation of VAR models by incorporating non-
sequence data  which are assumed to be samples drawn from the stationary distribution of the
underlying VAR model. We construct a novel penalization term based on the discrete-time Lya-
punov equation concerning the covariance (estimate) of the stationary distribution. Preliminary
experimental results demonstrate that our methods can improve signiﬁcantly over standard penal-
ized least-square methods when there are only few sequence data but abundant non-sequence data

and when the model assumption is valid. In the future  we would like to investigate the impact of bQ
on bA in a precise manner. Also  we may consider noise processes ǫ

t with more general covariances 
and incorporate the noise covariance estimation into the proposed Lyapunov penalization scheme.
Finally and the most importantly  we aim to apply the proposed methods to real scientiﬁc time series
data and provide a more effective tool for those modelling tasks.

3A similar video sequence has been used in [16].

8

References

[1] P. Antsaklis and A. Michel. Linear systems. Birkhauser  2005. 2
[2] D. P. Bertsekas. Nonlinear Programming. Athena Scientiﬁc  Belmont  MA 02178-9998  sec-

ond edition  1999. 4

[3] Y. Chen  A. Wiesel  Y. C. Eldar  and A. O. Hero. Shrinkage algorithms for mmse covariance

estimation. IEEE Transactions on Signal Processing  58:5016–5029  2010. 5

[4] Y. Chen  A. Wiesel  and A. O. Hero. Robust shrinkage estimation of high-dimensional covari-

ance matrices. Technical report  arXiv:1009.5331v1 [stat.ME]  September 2010. 5

[5] J. Duchi  S. Shalev-Shwartz  Y. Singer  and T. Chandra. Efﬁcient projections onto the ℓ1-
ball for learning in high dimensions. In Proceedings of the 25th International Conference on
Machine Learning  pages 272–279  2008. 4

[6] A. Gupta and Z. Bar-Joseph. Extracting dynamics from static cancer expression data.
IEEE/ACM Transactions on Computational Biology and Bioinformatics  5:172–182  2008. 2

[7] J. Hamilton. Time series analysis. Princeton Univ Pr  1994. 2
[8] T.-K. Huang and J. Schneider. Learning linear dynamical systems without sequence infor-
In Proceedings of the 26th International Conference on Machine Learning  pages

mation.
425–432  2009. 2

[9] T.-K. Huang  L. Song  and J. Schneider. Learning nonlinear dynamic models from non-
sequenced data. In Proceedings of the 13th International Conference on Artiﬁcial Intelligence
and Statistics  2010. 2

[10] O. Ledoit and M. Wolf. Improved estimation of the covariance matrix of stock returns with an

application to portfolio selection. Journal of Empirical Finance  10:603–621  2003. 5

[11] O. Ledoit and M. Wolf. A well-conditioned estimator for large-dimensional covariance matri-

ces. Journal of Multivariate Analysis  88:365–411  2004. 5

[12] A. Lozano  N. Abe  Y. Liu  and S. Rosset. Grouped graphical granger modeling for gene

expression regulatory networks discovery. Bioinformatics  25(12):i110  2009. 1

[13] T. C. Mills. The Econometric Modelling of Financial Time Series. Cambridge University Press 

second edition  1999. 1

[14] D. Noll  O. Prot  and A. Rondepierre. A proximity control algorithm to minimize nonsmooth

and nonconvex functions. Paciﬁc Journal of Optimization  4(3):569–602  2008. 4

[15] J. Sch¨afer and K. Strimmer. A shrinkage approach to large-scale covariance matrix estimation
and implications for functional genomics. Statistical Applications in Genetics and Molecular
Biology  4  2005. 5

[16] S. M. Siddiqi  B. Boots  and G. J. Gordon. Reduced-rank hidden Markov models. In Pro-
ceedings of the 13th International Conference on Artiﬁcial Intelligence and Statistics  2010.
8

[17] C. Stein. Estimation of a covariance matrix. In Rietz Lecture  39th Annual Meeting  Atlanta 

GA  1975. 5

[18] R. S. Tsay. Analysis of ﬁnancial time series. Wiley-Interscience  2005. 1
[19] B. P. Tu  A. Kudlicki  M. Rowicka  and S. L. McKnight. Logic of the yeast metabolic cycle:
Temporal compartmentalization of cellular processes. Science  310(5751):1152–1158  2005.
1

[20] R. Yang and J. O. Berger. Estimation of a covariance matrix using the reference prior. Annals

of Statistics  22:1195–1211  1994. 5

9

,Giulia Fanti
Pramod Viswanath