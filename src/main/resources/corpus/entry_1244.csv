2015,Covariance-Controlled Adaptive Langevin Thermostat for Large-Scale Bayesian Sampling,Monte Carlo sampling for Bayesian posterior inference is a common approach used in machine learning. The Markov Chain Monte Carlo procedures that are used are often discrete-time analogues of associated stochastic differential equations (SDEs). These SDEs are guaranteed to leave invariant the required posterior distribution. An area of current research addresses the computational benefits of stochastic gradient methods in this setting. Existing techniques rely on estimating the variance or covariance of the subsampling error  and typically assume constant variance. In this article  we propose a covariance-controlled adaptive Langevin thermostat that can effectively dissipate parameter-dependent noise while maintaining a desired target distribution. The proposed method achieves a substantial speedup over popular alternative schemes for large-scale machine learning applications.,Covariance-Controlled Adaptive Langevin

Thermostat for Large-Scale Bayesian Sampling

Xiaocheng Shang∗
University of Edinburgh
x.shang@ed.ac.uk

Zhanxing Zhu∗

University of Edinburgh

zhanxing.zhu@ed.ac.uk

Benedict Leimkuhler
University of Edinburgh

b.leimkuhler@ed.ac.uk

Amos J. Storkey

University of Edinburgh
a.storkey@ed.ac.uk

Abstract

Monte Carlo sampling for Bayesian posterior inference is a common approach
used in machine learning. The Markov chain Monte Carlo procedures that are
used are often discrete-time analogues of associated stochastic differential equa-
tions (SDEs). These SDEs are guaranteed to leave invariant the required posterior
distribution. An area of current research addresses the computational beneﬁts of
stochastic gradient methods in this setting. Existing techniques rely on estimating
the variance or covariance of the subsampling error  and typically assume constant
variance. In this article  we propose a covariance-controlled adaptive Langevin
thermostat that can effectively dissipate parameter-dependent noise while main-
taining a desired target distribution. The proposed method achieves a substantial
speedup over popular alternative schemes for large-scale machine learning appli-
cations.

1

Introduction

In machine learning applications  direct sampling with the entire large-scale dataset is computation-
ally infeasible. For instance  standard Markov chain Monte Carlo (MCMC) methods [16]  as well
as typical hybrid Monte Carlo (HMC) methods [3  6  9]  require the calculation of the acceptance
probability and the creation of informed proposals based on the whole dataset.
In order to improve the computational efﬁciency  a number of stochastic gradient methods [4  5  20 
21] have been proposed in the setting of Bayesian sampling based on random (and much smaller)
subsets to approximate the likelihood of the whole dataset  thus substantially reducing the com-
putational cost in practice. Welling and Teh proposed the so-called stochastic gradient Langevin
dynamics (SGLD) [21]  combining the ideas of stochastic optimization [18] and traditional Brow-
nian dynamics  with a sequence of stepsizes decreasing to zero. A ﬁxed stepsize is often adopted
in practice which is the choice in this article as in Vollmer et al. [20]  where a modiﬁed SGLD
(mSGLD) was also introduced that was designed to reduce the sampling bias.
SGLD generates samples from ﬁrst order Brownian dynamics  and thus  with a ﬁxed timestep  one
can show that it is unable to dissipate excess noise in gradient approximations while maintaining the
desired invariant distribution [4]. A stochastic gradient Hamiltonian Monte Carlo (SGHMC) method
was proposed by Chen et al. [4]  which relies on second order Langevin dynamics and incorporates a
parameter-dependent diffusion matrix that is intended to effectively offset the stochastic perturbation
of the gradient. However  it is difﬁcult to accommodate the additional diffusion term in practice.

∗The ﬁrst and second authors contributed equally  and the listed author order was decided by lot.

1

Moreover  as pointed out in [5]  poor estimation of it may have a signiﬁcant adverse inﬂuence on the
sampling of the target distribution; for example  the effective system temperature may be altered.
The “thermostat” idea  which is widely used in molecular dynamics [7  13]  was recently adopted
in the stochastic gradient Nos´e-Hoover thermostat (SGNHT) by Ding et al. [5] in order to adjust
the kinetic energy during simulation in such a way that the canonical ensemble is preserved (i.e. so
that a prescribed constant temperature distribution is maintained). In fact  the SGNHT method is
essentially equivalent to the adaptive Langevin (Ad-Langevin) thermostat proposed earlier by Jones
and Leimkuhler [10] in the molecular dynamics setting (see [15] for discussions).
Despite the substantial interest generated by these methods 
the mathematical foundation for
stochastic gradient methods has been incomplete. The underlying dynamics of the SGNHT
method [5] was taken up by Leimkuhler and Shang [15]  together with the design of discretiza-
tion schemes with high effective order of accuracy. SGNHT methods are designed based on the
assumption of constant noise variance. In this article  we propose a covariance-controlled adaptive
Langevin (CCAdL) thermostat  that can handle parameter-dependent noise  improving both robust-
ness and reliability in practice  and which can effectively speed up the convergence to the desired
invariant distribution in large-scale machine learning applications.
The rest of the article is organized as follows. In Section 2  we describe the setting of Bayesian
sampling with noisy gradients and brieﬂy review existing techniques. Section 3 considers the con-
struction of the novel CCAdL method that can effectively dissipate parameter-dependent noise while
maintaining the correct distribution. Various numerical experiments are performed in Section 4 to
verify the usefulness of CCAdL in a wide range of large-scale machine learning applications. Final-
ly  we summarize our ﬁndings in Section 5.

2 Bayesian Sampling with Noisy Gradients

π(θ|X) ∝ π(X|θ)π(θ)  

In the typical setting of Bayesian sampling [3  19]  one is interested in drawing states from a posterior
distribution deﬁned as

(1)
where θ ∈ RNd is the parameter vector of interest  X denotes the entire dataset  and  π(X|θ)
and π(θ) are the likelihood and prior distributions  respectively. We introduce a potential energy
function U (θ) by deﬁning π(θ|X) ∝ exp(−βU (θ))  where β is a positive parameter and can be
interpreted as being proportional to the reciprocal temperature in an associated physical system  i.e.
β−1 = kBT (kB is the Boltzmann constant and T is the temperature). In practice  β is often set to
be unity for notational simplicity. Taking the logarithm of (1) yields
U (θ) = − log π(X|θ)−log π(θ) .

(2)
Assuming the data are independent and identically distributed (i.i.d.)  the logarithm of the likelihood
can be calculated as

log π(X|θ) =

log π(xi|θ)  

(3)

where N is the size of the entire dataset.
However  as already mentioned  it is computationally infeasible to deal with the entire large-scale
dataset at each timestep as would typically be required in MCMC and HMC methods. Instead  in
order to improve the efﬁciency  a random (and much smaller  i.e. n (cid:28) N) subset is preferred in
stochastic gradient methods  in which the likelihood of the dataset for given parameters is approxi-
mated by

log π(X|θ) ≈ N
n

log π(xri|θ)  

(4)

N(cid:88)

i=1

n(cid:88)

i=1

2

where {xri}n
as

i=1 represents a random subset of X. Thus  the “noisy” potential energy can be written

˜U (θ) = − N
n

log π(xri|θ)−log π(θ)  

(5)

where the negative gradient of the potential is referred to as the “noisy” force  i.e. ˜F(θ) = −∇ ˜U (θ).

n(cid:88)

i=1

˜F(θ) = −∇U (θ)+(cid:112)Σ(θ)M1/2R  

Our goal is to correctly sample the Gibbs distribution ρ(θ) ∝ exp(−βU (θ)) (1). As in [4  5]  the
gradient noise is assumed to be Gaussian with mean zero and unknown variance  in which case one
may rewrite the noisy force as

R is a vector of i.i.d. standard normal random variables. Note that(cid:112)Σ(θ)M1/2R here is actually

(6)
where M typically is a diagonal matrix  Σ(θ) represents the covariance matrix of the noise  and 
equivalent to N (0  Σ(θ)M).
In a typical setting of numerical integration with associated stepsize h  one has

(cid:16)−∇U (θ)+(cid:112)Σ(θ)M1/2R
(cid:17)

h ˜F(θ) = h

(7)
and therefore  assuming a constant covariance matrix (i.e. Σ = σ2I  where I is the identity matrix) 
the SGNHT method by Ding et al. [5] has the following underlying dynamics  written as a standard
It¯o stochastic differential equation (SDE) system [15]:

M1/2R  

h

(cid:16)(cid:112)hΣ(θ)

(cid:17)

√

= −h∇U (θ)+

dθ = M−1pdt  
dp = −∇U (θ)dt+σ

dξ = µ−1(cid:2)pT M−1p−NdkBT(cid:3) dt  

√

hM1/2dW−ξpdt+

(cid:112)

2Aβ−1M1/2dWA  

(8)

often informally denoted by N (0  dtI) [4]. The coefﬁcient(cid:112)2Aβ−1M1/2 represents the strength

where  colloquially  dW and dWA represent vectors of independent Wiener increments; and are

of artiﬁcial noise added into the system to improve ergodicity  and A  which can be termed the “ef-
fective friction”  is a positive parameter and proportional to the variance of the noise. The auxiliary
variable ξ ∈ R is governed by a Nos´e-Hoover device [8  17] via a negative feedback mechanism 
i.e. when the instantaneous temperature (average kinetic energy per degree of freedom) calculated
as

(9)
is below the target temperature  the “dynamical friction” ξ would decrease allowing an increase
of temperature  while ξ would increase when the temperature is above the target. µ is a coupling
parameter which is referred to as the “thermal mass” in the molecular dynamics setting.
Proposition 1 (See Jones and Leimkuhler [10]). The SGNHT method (8) preserves the modiﬁed
Gibbs (stationary) distribution:

˜ρβ(θ  p  ξ) = Z−1 exp (−βH(θ  p)) exp(cid:0)−βµ(ξ− ¯ξ)2/2(cid:1)  

where Z is the normalizing constant  H(θ  p) = pT M−1p/2+U (θ) is the Hamiltonian  and

kBT = pT M−1p/Nd

(10)

¯ξ = A+βhσ2/2 .

(11)
Proposition 1 tells us that the SGNHT method can adaptively dissipate excess noise pumped into
the system while maintaining the correct distribution. The variance of the gradient noise  σ2  does
not need to be known a priori. As long as σ2 is constant  the auxiliary variable ξ will be able to
automatically ﬁnd its mean value ¯ξ on the ﬂy. However  with a parameter-dependent covariance
matrix Σ(θ)  the SGNHT method (8) would not produce the required target distribution (10).
Ding et al. [5] claimed that it is reasonable to assume the covariance matrix Σ(θ) is constant when
the size of the dataset  N  is large  in which case the variance of the posterior of θ is small. The
magnitude of the posterior variance does not actually relate to the constancy of the Σ  however 
in general  Σ is not constant. Simply assuming the non-constancy of the Σ can have a signiﬁcant
impact on the performance of the method (most notably the stability measured by the largest usable
stepsize). Therefore  it is essential to have an approach that can handle parameter-dependent noise.
In the following section  we propose a covariance-controlled thermostat that can effectively dissipate
parameter-dependent noise while maintaining the target stationary distribution.

3 Covariance-Controlled Adaptive Langevin Thermostat

As mentioned in the previous section  the SGNHT method (8) can only dissipate noise with a con-
stant covariance matrix. When the covariance matrix becomes parameter-dependent  in general  a
parameter-dependent covariance matrix does not imply the required “thermal equilibrium”  i.e. the
system cannot be expected to converge to the desired invariant distribution (10)  typically resulting
in poor estimation of functions of parameters of interest. In fact  in that case it is not clear whether
or not there exists an invariant distribution at all.

3

In order to construct a stochastic-dynamical system that preserves the canonical distribution  we
suggest adding a suitable damping (viscous) term to effectively dissipate the parameter-dependent
gradient noise. To this end  we propose the following covariance-controlled adaptive Langevin
(CCAdL) thermostat:

dθ = M−1pdt  

dp = −∇U (θ)dt+(cid:112)hΣ(θ)M1/2dW−(h/2)βΣ(θ)pdt−ξpdt+
dξ = µ−1(cid:2)pT M−1p−NdkBT(cid:3) dt .

(cid:112)

2Aβ−1M1/2dWA  

(12)

Proposition 2. The CCAdL thermostat (12) preserves the modiﬁed Gibbs (stationary) distribution:
(13)

ˆρβ(θ  p  ξ) = Z−1 exp (−βH(θ  p)) exp(cid:0)−βµ(ξ−A)2/2(cid:1) .
+ξ∇p·(pρ)+Aβ−1∇p·(M∇pρ)−µ−1(cid:2)pT M−1p−NdkBT(cid:3)∇ξρ .

Proof. The Fokker-Planck equation corresponding to (12) is
ρt = L†ρ := −M−1p·∇θρ+∇U (θ)·∇pρ+(h/2)∇p·(Σ(θ)M∇pρ)+(h/2)β∇p·(Σ(θ)pρ)

Just insert ˆρβ (13) into the Fokker-Planck operator L† to see that it vanishes.
The incorporation of the parameter-dependent covariance matrix Σ(θ) in (12) is intended to offset
the covariance matrix coming from the gradient approximation. However  in practice  one does not
know Σ(θ) a priori. Thus instead one must estimate Σ(θ) during the simulation  a task which will
be addressed in Section 3.1. This procedure is related to the method used in the SGHMC method
proposed by Chen et al. [4]  which uses dynamics of the following form:

dp = −∇U (θ)dt+(cid:112)hΣ(θ)M1/2dW−Apdt+(cid:112)2β−1 (AI−βhΣ(θ)/2)M1/2dWA .

dθ = M−1pdt  

It can be shown that the SGHMC method preserves the Gibbs canonical distribution:

ρβ(θ  p) = Z−1 exp (−βH(θ  p)) .

(14)

(15)

Although both CCAdL (12) and SGHMC (14) preserve their respective invariant distributions  let
us note several advantages of the former over the latter in practice:

(i) CCAdL and SGHMC both require estimation of the covariance matrix Σ(θ) during simu-
lation  which can be costly in high dimension. In numerical experiments  we have found
that simply using the diagonal of the covariance matrix  at signiﬁcantly reduced computa-
tional cost  works quite well in CCAdL. By contrast  it is difﬁcult to ﬁnd a suitable value
of the parameter A in SGHMC since one has to make sure the matrix AI−βhΣ(θ)/2 is
positive semi-deﬁnite. One may attempt to use a large value of the “effective friction” A
and/or a small stepsize h. However  too-large a friction would essentially reduce SGHMC
to SGLD  which is not desirable  as pointed out in [4]  while extremely small stepsize
would signiﬁcantly impact the computational efﬁciency.

(ii) Estimation of the covariance matrix Σ(θ) unavoidably introduces additional noise in both
CCAdL and SGHMC. Nonetheless  CCAdL can still effectively control the system tem-
perature (i.e. maintaining the correct distribution of the momenta) due to the use of the
stabilizing Nos´e-Hoover control  while in SGHMC  poor estimation of the covariance ma-
trix may lead to signiﬁcant deviations of the system temperature (as well as the distribution
of the momenta)  resulting in poor sampling of the parameters of interest.

3.1 Covariance Estimation of Noisy Gradients

Under the assumption that the noise of the stochastic gradient follows a normal distribution  we
apply a similar method to that of [2] to estimate the covariance matrix associated with the noisy
gradient. If we let g(θ; x) = ∇θ log π(x|θ) and assume that the size of subset n is large enough for
the central limit theorem to hold  we have

g(θt; xri) ∼ N

Ex[g(θt; x)] 

(16)

(cid:80)n
where It = Cov[g(θt; x)] is the covariance of the gradient at θt. Given the noisy (stochastic)
gradient based on the current subset ∇ ˜U (θt) = − N
i=1 g(θt; xri)−∇ log π(θt) and the clean

i=1

n

n(cid:88)

1
n

(cid:19)

1
n

It

 

(cid:18)

4

t=1.

Algorithm 1 Covariance-Controlled Adaptive Langevin (CCAdL) Thermostat
1: Input: h  A  {κt} ˆT
2: Initialize θ0  p0  I0  and ξ0 = A.
3: for t = 1  2  . . .   ˆT do
θt = θt−1 +pt−1h;
4:
Estimate ˆIt using Eq. (18);
5:
pt = pt−1−∇ ˜U (θt)h− h
6:
7:
8: end for

ˆItpt−1h−ξt−1pt−1h+

ξt = ξt−1 +(cid:0)pT

t pt/Nd−1(cid:1) h;
(full) gradient ∇U (θt) = −(cid:80)N

2AhN (0  I);

N 2
n

√

2

and thus

i=1 g(θt; xi)−∇ log π(θt)  we have Ex[∇ ˜U (θt)] = Ex[∇U (θt)] 
∇ ˜U (θt) = ∇U (θt)+N

(17)

0 

It

 

(cid:19)

(cid:18)

N 2
n

i.e. Σ(θt) = N 2It/n. Assuming θt does not change dramatically over time  we use the moving
average update to estimate It:

ˆIt = (1−κt)ˆIt−1 +κtV(θt)  

(18)

where κt = 1/t and

V(θt) =

1
n−1

n(cid:88)

i=1

(g(θt; xri)−¯g(θt)) (g(θt; xri)−¯g(θt))T

(19)

is the empirical covariance of the gradient. ¯g(θt) represents the mean gradient of the log likelihood
computed from a subset. As proved in [2]  this estimator has a convergence order of O(1/N ).
As already mentioned  estimating the full covariance matrix is computationally infeasible in high
dimension. However  we have found that employing a diagonal approximation of the covariance
matrix (i.e. estimating the variance only along each dimension of the noisy gradient) works quite
well in practice  as demonstrated in Section 4.
The procedure of the CCAdL method is summarized in Algorithm 1  where we simply used M = I 
β = 1  and µ = Nd in order to be consistent with the original implementation of SGNHT [5].
Note that this is a simple  ﬁrst order (in terms of the stepsize) algorithm. A recent article [15] has
introduced higher order of accuracy schemes which can improve accuracy  but our interest here is in
the direct comparison of the underlying machinery of SGHMC  SGNHT  and CCAdL  so we avoid
further modiﬁcations and enhancements related to timestepping at this stage.
In the following section  we compare the newly established CCAdL method with SGHMC and
SGNHT on various machine learning tasks to demonstrate the beneﬁts of CCAdL in Bayesian sam-
pling with a noisy gradient.

4 Numerical Experiments

4.1 Bayesian Inference for Gaussian Distribution

We ﬁrst compare the performance of the newly established CCAdL method with SGHMC and
SGNHT for a simple task using synthetic data  i.e. Bayesian inference of both the mean and vari-
ance of a one-dimensional normal distribution. We apply the same experimental setting as in [5]. We
generated N = 100 samples from a standard normal distribution N (0  1). We used the likelihood
function of N (xi|µ  γ−1) and assigned a Normal-Gamma distribution as their prior distribution  i.e.
µ  γ ∼ N (µ|0  γ)Gam(γ|1  1). Then the corresponding posterior distribution is another Normal-
Gamma distribution  i.e. (µ  γ)|X ∼ N (µ|µN   (κN γ)−1)Gam(γ|αN   βN )  with
µN =

(xi− ¯x)2

κN = 1+N  

N(cid:88)

αN = 1+

βN = 1+

N ¯x2

+

 

 

 

i=1 xi/N. A random subset of size n = 10 was selected at each timestep to approxi-

mate the full gradient  resulting in the following stochastic gradients:

∇µ ˜U = (N +1)µγ− γN
n

xri  

∇γ ˜U = 1− N +1
2γ

+

µ2
2

+

N
2n

2

2(1+N )

i=1

n(cid:88)
(xri−µ)2 .

i=1

N ¯x
N +1

where ¯x =(cid:80)N

n(cid:88)

i=1

N
2

5

It can be seen that the variance of the stochastic gradient noise is no longer constant and actually
depends on the size of the subset  n  and the values of µ and γ in each iteration. This directly violates
the constant noise variance assumption of SGNHT [5]  while CCAdL adjusts to the varying noise
variance.
The marginal distributions of µ and γ obtained from various methods with different combinations
of h and A were compared and plotted in Figure 1  with Table 1 consisting of the corresponding
root mean square error (RMSE) of the distribution and autocorrelation time from 106 samples. In
most of the cases  both SGNHT and CCAdL easily outperform the SGHMC method possibly due
to the presence of the Nos´e-Hoover device  with SGHMC only showing superiority with a small
value of h and a large value of A  neither of which is desirable in practice as discussed in Section 3.
Between SGNHT and the newly proposed CCAdL method  the latter achieves better performance in
each of the cases investigated  highlighting the importance of the covariance control with parameter-
dependent noise.

(a) h = 0.001  A = 1

(b) h = 0.001  A = 10

(c) h = 0.01  A = 1

(d) h = 0.01  A = 10

Figure 1: Comparisons of marginal distribution (density) of µ (top row) and γ (bottom row) with various
values of h and A indicated in each column. The peak region is highlighted in the inset.

Table 1: Comparisons of (RMSE  Autocorrelation time) of (µ  γ) of various methods for Bayesian inference
of the mean and variance of a Gaussian distribution.

Methods
SGHMC
SGNHT
CCAdL

h = 0.001  A = 1
(0.0148  236.12)
(0.0037  238.32)
(0.0034  238.06)

h = 0.001  A = 10
(0.0029  333.04)
(0.0035  406.71)
(0.0031  402.45)

h = 0.01  A = 1
(0.0531  29.78)
(0.0044  26.71)
(0.0021  26.71)

h = 0.01  A = 10
(0.0132  39.33)
(0.0043  55.00)
(0.0035  54.43)

4.2 Large-scale Bayesian Logistic Regression

hood function of π(cid:0){xi  yi}N

i=1|w(cid:1) ∝(cid:81)N

i=1 1/(cid:0)1+exp(−yiwT xi)(cid:1) and the prior distribution of

We then consider a Bayesian logistic regression model trained on the benchmark MNIST dataset
for binary classiﬁcation of digits 7 and 9 using 12  214 training data points  with a test set of size
2037. A 100-dimensional random projection of the original features was used. We used the likeli-
π(w) ∝ exp(−wT w/2). A subset of size n = 500 was used at each timestep. Since the dimen-
sionality of this problem is not that high  a full covariance estimation was used for CCAdL.
We investigate in Figure 2 (top row) the convergence speed of each method through measuring test
log likelihood using the posterior mean against the number of passes over the entire dataset. CCAdL
displays signiﬁcant improvements over SGHMC and SGNHT with different values of h and A:
(1) CCAdL converges much faster than the other two  which also indicates its faster mixing speed
and shorter burn-in period; (2) CCAdL shows robustness in different values of the effective friction
A  with SGHMC and SGNHT relying on a relative large value of A (especially for the SGHMC
method)  which is intended to dominate the gradient noise.
To compare the sample quality obtained from each method  Figure 2 (bottom row) plots the two-
dimensional marginal posterior distribution in randomly selected dimensions of 2 and 5 based on
106 samples from each method after the burn-in period (i.e. we start to collect samples when the test

6

−0.500.501234µDensity TrueSGHMCSGNHTCCAdL−0.500.501234µDensity TrueSGHMCSGNHTCCAdL−0.500.501234µDensity TrueSGHMCSGNHTCCAdL−0.500.501234µDensity TrueSGHMCSGNHTCCAdL0.511.50123γDensity TrueSGHMCSGNHTCCAdL0.511.50123γDensity TrueSGHMCSGNHTCCAdL0.511.50123γDensity TrueSGHMCSGNHTCCAdL0.511.50123γDensity TrueSGHMCSGNHTCCAdLlog likelihood stabilizes). The true (reference) distribution was obtained by a sufﬁciently long run of
standard HMC. We implemented 10 runs of standard HMC and found there was no variation between
these runs  which guarantees its qualiﬁcation as the true (reference) distribution. Again  CCAdL
shows much better performance than SGHMC and SGNHT. Note that the contour of SGHMC does
not even ﬁt in the region of the plot  and in fact it shows signiﬁcant deviation even in the estimation
of the mean.

(a) h = 0.2×10−4

(b) h = 0.5×10−4

(c) h = 1×10−4

Figure 2: Comparisons of Bayesian logistic regression of various methods on the MNIST dataset of digits 7
and 9 with various values of h and A: (top row) test log likelihood using the posterior mean against the number
of passes over the entire dataset; (bottom row) two-dimensional marginal posterior distribution in (randomly
selected) dimensions 2 and 5 with A = 10 ﬁxed  based on 106 samples from each method after the burn-in
period (i.e. we start to collect samples when the test log likelihood stabilizes). Magenta circle is the true
(reference) posterior mean obtained from standard HMC and crosses represent the sample means computed
from various methods. Ellipses represent iso-probability contours covering 95% probability mass. Note that
the contour of SGHMC is well beyond the scale of the plot especially in the large stepsize regime  in which
case we do not include it here.
4.3 Discriminative Restricted Boltzmann Machine (DRBM)

DRBM [11] is a self-contained non-linear classiﬁer  and the gradient of its discriminative objective
can be explicitly computed. Due to the limited space  we refer the readers to [11] for more details.
We trained a DRBM on different large-scale multi-class datasets from the LIBSVM1 dataset col-
lection  including connect-4  letter  and SensIT Vehicle acoustic. The detailed information of these
datasets are presented in Table 2.
We selected the number of hidden units using cross-validation to achieve their best results. Since the
dimension of parameters  Nd  is relatively high  we used only diagonal covariance matrix estimation
for CCAdL to signiﬁcantly reduce the computational cost  i.e. estimating the variance only along
each dimension. The size of the subset was chosen as 500–1000 to obtain a reasonable variance
estimation. For each dataset  we chose the ﬁrst 20% of the total number of passes over the entire
dataset as the burn-in period and collected the remaining samples for prediction.

Table 2: Datasets used in DRBM with corresponding parameter conﬁgurations.

training/test set
54 046/13 511
10 500/5 000
78 823/19 705

classes

3
26
3

features

126
16
50

hidden units

20
100
20

total number of parameters Nd

2603
4326
1083

Datasets
connect-4

letter

acoustic

The error rates computed by various methods on the test set using the posterior mean against the
number of passes over the entire dataset were plotted in Figure 3. It can be observed that SGHMC
and SGNHT only work well with a large value of the effective friction A  which corresponds to a
strong random walk effect and thus slows down the convergence. On the contrary  CCAdL works

1http://www.csie.ntu.edu.tw/˜cjlin/libsvmtools/datasets/multiclass.html

7

0200400600−800−700−600−500−400−300Number of PassesTest Log Likelihood SGHMC  A=1SGHMC  A=10SGNHT  A=1SGNHT  A=10CCAdL  A=1CCAdL  A=100100200300−800−700−600−500−400−300Number of PassesTest Log Likelihood SGHMC  A=1SGHMC  A=10SGNHT  A=1SGNHT  A=10CCAdL  A=1CCAdL  A=100100200300−800−700−600−500−400−300Number of PassesTest Log Likelihood SGHMC  A=1SGHMC  A=10SGNHT  A=1SGNHT  A=10CCAdL  A=1CCAdL  A=100.030.0350.040.0450.050.055−5051015x 10−3w2w5 True(HMC)SGHMCSGNHTCCAdL0.030.0350.040.0450.050.055−5051015x 10−3w2w5 True(HMC)SGHMCSGNHTCCAdL0.030.0350.040.0450.050.055−5051015x 10−3w2w5 True(HMC)SGHMCSGNHTCCAdLreliably (much better than the other two) in a wide range of A  and more importantly in the large
stepsize regime  which speeds up the convergence rate in relation to the computational work per-
formed. It can be easily seen that the performance of SGHMC heavily relies on using a small value
of h and a large value of A  which signiﬁcantly limits its usefulness in practice.

(1a) connect-4  h = 0.5×10−3

(1b) connect-4  h = 1×10−3

(1c) connect-4  h = 2×10−3

(2a) letter  h = 1×10−3

(2b) letter  h = 2×10−3

(2c) letter  h = 5×10−3

(3a) acoustic  h = 0.2×10−3

(3b) acoustic  h = 0.5×10−3

(3c) acoustic  h = 1×10−3

Figure 3: Comparisons of DRBM on datasets connect-4 (top row)  letter (middle row)  and acoustic (bottom
row) with various values of h and A indicated: test error rates of various methods using the posterior mean
against the number of passes over the entire dataset.

5 Conclusions and Future Work

In this article  we have proposed a novel CCAdL formulation that can effectively dissipate
parameter-dependent noise while maintaining a desired invariant distribution. CCAdL combines
ideas of SGHMC and SGNHT from the literature  but achieves signiﬁcant improvements over each
of these methods in practice. The additional error introduced by covariance estimation is expected
to be small in a relative sense  i.e. substantially smaller than the error arising from the noisy gradi-
ent. Our ﬁndings have been veriﬁed in large-scale machine learning applications. In particular  we
have consistently observed that SGHMC relies on a small stepsize h and a large friction A  which
signiﬁcantly reduces its usefulness in practice as discussed. The techniques presented in this article
could be of use in more general settings of large-scale Bayesian sampling and optimization  which
we leave for future work.
A naive nonsymmetric splitting method has been applied for CCAdL for fair comparison in this
article. However  we point out that optimal design of splitting methods in ergodic SDE systems has
been explored recently in the mathematics community [1  13  14]. Moreover  it has been shown
in [15] that a certain type of symmetric splitting method for the Ad-Langevin/SGNHT method with
a clean (full) gradient inherits the superconvergence property (i.e. fourth order convergence to the
invariant distribution for conﬁgurational quantities) recently demonstrated in the setting of Langevin
dynamics [12  14]. We leave further exploration of this direction in the context of noisy gradients
for future work.

8

501001502000.270.280.290.30.310.320.33Number of PassesTest Error SGHMC  A=10SGHMC  A=50SGNHT  A=10SGNHT  A=50CCAdL  A=10CCAdL  A=50501001502000.270.280.290.30.310.320.33Number of PassesTest Error SGHMC  A=10SGHMC  A=50SGNHT  A=10SGNHT  A=50CCAdL  A=10CCAdL  A=50501001502000.270.280.290.30.310.320.33Number of PassesTest Error SGHMC  A=10SGHMC  A=50SGNHT  A=10SGNHT  A=50CCAdL  A=10CCAdL  A=501002003004000.10.150.20.25Test ErrorNumber of Passes SGHMC  A=1SGHMC  A=10SGNHT  A=1SGNHT  A=10CCAdL  A=1CCAdL  A=101002003004000.10.150.20.25Test ErrorNumber of Passes SGHMC  A=1SGHMC  A=10SGNHT  A=1SGNHT  A=10CCAdL  A=1CCAdL  A=101002003004000.10.150.20.25Test ErrorNumber of Passes SGHMC  A=1SGHMC  A=10SGNHT  A=1SGNHT  A=10CCAdL  A=1CCAdL  A=10501001502000.250.30.350.4Number of PassesTest Error SGHMC  A=1SGHMC  A=10SGNHT  A=1SGNHT  A=10CCAdL  A=1CCAdL  A=10501001502000.250.30.350.4Number of PassesTest Error SGHMC  A=1SGHMC  A=10SGNHT  A=1SGNHT  A=10CCAdL  A=1CCAdL  A=10501001502000.250.30.350.4Number of PassesTest Error SGHMC  A=1SGHMC  A=10SGNHT  A=1SGNHT  A=10CCAdL  A=1CCAdL  A=10References
[1] A. Abdulle  G. Vilmart  and K. C. Zygalakis. Long time accuracy of Lie-Trotter splitting

methods for Langevin dynamics. SIAM Journal on Numerical Analysis  53(1):1–16  2015.

[2] S. Ahn  A. Korattikara  and M. Welling. Bayesian posterior sampling via stochastic gradient
Fisher scoring. In Proceedings of the 29th International Conference on Machine Learning 
pages 1591–1598  2012.

[3] S. Brooks  A. Gelman  G. Jones  and X.-L. Meng. Handbook of Markov Chain Monte Carlo.

CRC Press  2011.

[4] T. Chen  E. B. Fox  and C. Guestrin. Stochastic gradient Hamiltonian Monte Carlo. In Pro-
ceedings of the 31st International Conference on Machine Learning  pages 1683–1691  2014.
[5] N. Ding  Y. Fang  R. Babbush  C. Chen  R. D. Skeel  and H. Neven. Bayesian sampling using
stochastic gradient thermostats. In Advances in Neural Information Processing Systems 27 
pages 3203–3211  2014.

[6] S. Duane  A. D. Kennedy  B. J. Pendleton  and D. Roweth. Hybrid Monte Carlo. Physics

Letters B  195(2):216–222  1987.

[7] D. Frenkel and B. Smit. Understanding Molecular Simulation: From Algorithms to Applica-

tions  Second Edition. Academic Press  2001.

[8] W. G. Hoover. Computational Statistical Mechanics  Studies in Modern Thermodynamics.

Elsevier Science  1991.

[9] A. M. Horowitz. A generalized guided Monte Carlo algorithm. Physics Letters B  268(2):247–

252  1991.

[10] A. Jones and B. Leimkuhler. Adaptive stochastic methods for sampling driven molecular sys-

tems. The Journal of Chemical Physics  135(8):084125  2011.

[11] H. Larochelle and Y. Bengio. Classiﬁcation using discriminative restricted Boltzmann ma-
In Proceedings of the 25th International Conference on Machine Learning  pages

chines.
536–543  2008.

[12] B. Leimkuhler and C. Matthews. Rational construction of stochastic numerical methods for

molecular sampling. Applied Mathematics Research eXpress  2013(1):34–56  2013.

[13] B. Leimkuhler and C. Matthews. Molecular Dynamics: With Deterministic and Stochastic

Numerical Methods. Springer  2015.

[14] B. Leimkuhler  C. Matthews  and G. Stoltz. The computation of averages from equilibrium and
nonequilibrium Langevin molecular dynamics. IMA Journal of Numerical Analysis  36(1):13–
79  2016.

[15] B. Leimkuhler and X. Shang. Adaptive thermostats for noisy gradient systems. SIAM Journal

on Scientiﬁc Computing  2016.

[16] N. Metropolis  A. W. Rosenbluth  M. N. Rosenbluth  A. H. Teller  and E. Teller. Equation of
state calculations by fast computing machines. The Journal of Chemical Physics  21(6):1087 
1953.

[17] S. Nos´e. A uniﬁed formulation of the constant temperature molecular dynamics methods. The

Journal of Chemical Physics  81(1):511  1984.

[18] H. Robbins and S. Monro. A stochastic approximation method. Annals of Mathematical

Statistics  22(2):400–407  1951.

[19] C. Robert and G. Casella. Monte Carlo Statistical Methods  Second Edition. Springer  2004.
(Non-) asymptotic properties of stochastic
[20] S. J. Vollmer  K. C. Zygalakis  and Y. W. Teh.

gradient Langevin dynamics. arXiv preprint arXiv:1501.00438  2015.

[21] M. Welling and Y. W. Teh. Bayesian learning via stochastic gradient Langevin dynamics. In
Proceedings of the 28th International Conference on Machine Learning  pages 681–688  2011.

9

,Xiaocheng Shang
Zhanxing Zhu
Benedict Leimkuhler
Amos Storkey