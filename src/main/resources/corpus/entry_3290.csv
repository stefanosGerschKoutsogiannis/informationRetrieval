2014,Low-dimensional models of neural population activity in sensory cortical circuits,Neural responses in visual cortex are influenced by visual stimuli and by ongoing spiking activity in local circuits. An important challenge in computational neuroscience is to develop models that can account for both of these features in large multi-neuron recordings and to reveal how stimulus representations interact with and depend on cortical dynamics. Here we introduce a statistical model of neural population activity that integrates a nonlinear receptive field model with a latent dynamical model of ongoing cortical activity. This model captures the temporal dynamics  effective network connectivity in large population recordings  and correlations due to shared stimulus drive as well as common noise. Moreover  because the nonlinear stimulus inputs are mixed by the ongoing dynamics  the model can account for a relatively large number of idiosyncratic receptive field shapes with a small number of nonlinear inputs to a low-dimensional latent dynamical model. We introduce a fast estimation method using online expectation maximization with Laplace approximations. Inference scales linearly in both population size and recording duration. We apply this model to multi-channel recordings from primary visual cortex and show that it accounts for a large number of individual neural receptive fields using a small number of nonlinear inputs and a low-dimensional dynamical model.,Low-dimensional models of neural population activity

in sensory cortical circuits

Evan Archer1 2  Urs K¨oster3  Jonathan Pillow4  Jakob H. Macke1 2

1Max Planck Institute for Biological Cybernetics  T¨ubingen
2Bernstein Center for Computational Neuroscience  T¨ubingen

3Redwood Center for Theoretical Neuroscience  University of California at Berkeley
4Princeton Neuroscience Institute  Department of Psychology  Princeton University

evan.archer@tuebingen.mpg.de  urs@nervanasys.com

pillow@princeton.edu  jakob@tuebingen.mpg.de

Abstract

Neural responses in visual cortex are inﬂuenced by visual stimuli and by ongo-
ing spiking activity in local circuits. An important challenge in computational
neuroscience is to develop models that can account for both of these features in
large multi-neuron recordings and to reveal how stimulus representations interact
with and depend on cortical dynamics. Here we introduce a statistical model of
neural population activity that integrates a nonlinear receptive ﬁeld model with a
latent dynamical model of ongoing cortical activity. This model captures temporal
dynamics and correlations due to shared stimulus drive as well as common noise.
Moreover  because the nonlinear stimulus inputs are mixed by the ongoing dynam-
ics  the model can account for a multiple idiosyncratic receptive ﬁeld shapes with
a small number of nonlinear inputs to a low-dimensional dynamical model. We
introduce a fast estimation method using online expectation maximization with
Laplace approximations  for which inference scales linearly in both population
size and recording duration. We test this model to multi-channel recordings from
primary visual cortex and show that it accounts for neural tuning properties as
well as cross-neural correlations.

1

Introduction

Neurons in sensory cortices organize into highly-interconnected circuits that share common input 
dynamics  and function. For example  across a cortical column  neurons may share stimulus de-
pendence as a result of sampling the same location of visual space  having similar orientation
preference [1] or receptive ﬁelds with shared sub-units [2]. As a result  a substantial fraction of
stimulus-information can be redundant across neurons [3]. Recent advances in electrophysiology
and functional imaging allow us to simultaneously probe the responses of the neurons in a column.
However  the high dimensionality and (relatively) short duration of the resulting data renders analy-
sis a difﬁcult statistical problem.
Recent approaches to modeling neural activity in visual cortex have focused on characterizing the re-
sponses of individual neurons by linearly projecting the stimulus on a small feature subspace that op-
timally drives the cell [4  5]. Such “systems-identiﬁcation” approaches seek to describe the stimulus-
selectivity of single neurons separately  treating each neuron as an independent computational unit.
Other studies have focused on providing probabilistic models of the dynamics of neural populations 
seeking to elucidate the internal dynamics underlying neural responses [6  7  8  9  10  11]. These
approaches  however  typically do not model the effect of the stimulus (or do so using only a linear
stimulus drive). To realize the potential of modern recording technologies and to progress our un-

1

derstanding of neural population coding  we need methods for extracting both the features that drive
a neural population and the resulting population dynamics [12].
We propose the Quadratic Input Latent Dynamical System (QLDS) model  a statistical model that
combines a low-dimensional representation of population dynamics [9] with a low-dimensional de-
scription of stimulus selectivity [13]. A low-dimensional dynamical system governs the population
response  and receives a nonlinear (quadratic) stimulus-dependent input. We model neural spike
responses as Poisson (conditional on the latent state)  with exponential ﬁring rate-nonlinearities. As
a result  population dynamics and stimulus drive interact multiplicatively to modulate neural ﬁr-
ing. By modeling dynamics and stimulus dependence  our method captures correlations in response
variability while also uncovering stimulus selectivity shared across a population.

Figure 1: Schematic illustrating the Quadratic input latent dynamical system model (QLDS).
The sensory stimulus is ﬁltered by multiple units with quadratic stimulus selectivity (only one of
which is shown) which model the feed-forward input into the population. This stimulus-drive pro-
vides input into a multi-dimensional linear dynamical system model which models recurrent dynam-
ics and shared noise within the population. Finally  each neuron yi in the population is inﬂuenced
by the dynamical system via a linear readout. QLDS therefore models both the stimulus selectivity
as well as the spatio-temporal correlations of the population.

2 The Quadratic Input Latent Dynamical System (QLDS) model

2.1 Model

We summarize the collective dynamics of a population using a linear  low-dimensional dynamical
system with an n-dimensional latent state xt. The evolution of xt is given by

xt = Axt1 + f(ht) + ✏t 

(1)
where A is the n ⇥ n dynamics matrix and ✏ is Gaussian innovation noise with covariance matrix
Q  ✏t ⇠N (0  Q). Each stimulus ht drives some dimensions of xt via a nonlinear function of the
stimulus  f  with parameters   where the exact form of f (·) will be discussed below. The log
ﬁring rates zt of the population couple to the latent state xt via a loading matrix C 
(2)
Here  we also include a second external input st  which is used to model the dependence of the
ﬁring rate of each neuron on its own spiking history [14]. We deﬁne D ⇤ st to be that vector
whose k-th element is given by (D ⇤ st)k ⌘PNs
i=1 Dk isk ti. D therefore models single-neuron
properties that are not explained by shared population dynamics  and captures neural properties such
as burstiness or refractory periods. The vector d represents a constant  private spike rate for each
neuron. The vector xt represents the n-dimensional state of m neurons. Typically n < m  so the
model parameterizes a low-dimensional dynamics for the population.
We assume that  conditional on zt  the observed activity yt of m neurons is Poisson-distributed 

zt = Cxt + D ⇤ st + d.

(3)
While the Poisson likelihood provides a realistic probabilistic model for the discrete nature of spik-
ing responses  it makes learning and inference more challenging than it would be for a Gaussian
model. As we discuss in the subsequent section  we rely on computationally-efﬁcient approxima-
tions to perform inference under the Poisson observation model for QLDS.

yk t ⇠ Poisson(exp(zk t)).

2

stimulus...quadraticlinearfilterspopulation spikeresponseintrinsicnoiselinearupdatelineardynamics+Anonlinearfunctionnoise2.2 Nonlinear stimulus dependence

Individual neurons in visual cortex respond selectively to only a small subset of stimulus features
[4  15]. Certain subpopulations of neurons  such as in a cortical column  share substantial receptive
ﬁeld overlap. We model such a neural subpopulation as sensitive to stimulus variation in a linear
subspace of stimulus space  and seek to characterize this subspace by learning a set of basis vectors 
or receptive ﬁelds  wi. In QLDS  a subset of latent states receives a nonlinear stimulus drive  each
of which reﬂects modulation by a particular receptive ﬁeld wi. We consider three different forms
of stimulus model: a fully linear model  and two distinct quadratic models. Although it is possi-
ble to incorporate more complicated stimulus models within the QLDS framework  the quadratic
models’ compact parameterization and analytic elegance make them both ﬂexible and computation-
ally tractable. What’s more  quadratic stimulus models appear in many classical models of neural
computation  e.g. the Adelson-Bergen model for motion-selectivity [16]; quadratic models are also
sometimes used in the classiﬁcation of simple and complex cells in area V1 [4].
We express our stimulus model by the function f(ht)  where  represents the set of parameters de-
scribing the stimulus ﬁlters wi and mixing parameters ai  bi and ci (in the case of the quadratic mod-
els). When fB(ht) is identically 0 (no stimulus input)  the QLDS with Poisson observations reduces
to what has been previously studied as the Poisson Latent Dynamical System (PLDS) [17  18  9].
We brieﬂy review three stimulus models we consider  and discuss their computational properties.

Linear: The simplest stimulus model we consider is a linear function of the stimulus 

(4)
where the rows of B as linear ﬁlters  and  = {B}. This baseline model is identical to [18  9] and
captures simple cell-like receptive ﬁelds since the input to latent states is linear and the observation
process is generalized linear.

f (ht) = Bht 

Quadratic: Under the linear model  latent dynamics receive linear input from the stimulus along
a single ﬁlter dimension  wi.
In the quadratic model  we permit the input to each state to be a
quadratic function of wi. We describe the quadratic by including three additional parameters per
latent dimension  so that the stimulus drive takes the form

fB i(ht) = aiwT

(5)
Here  the parameters  = {wi  ai  bi  ci : i = 1  . . .   m} include multiple stimulus ﬁlters wi and
quadratic parameters (ai  bi  ci). Equation 5 might result in a stimulus input that has non-zero mean
with respect to the distribution of the stimulus ht  which may be undesirable. Given the covariance
of ht  it is straightforward to constrain the input to be zero-mean by setting ci = aiwT
i ⌃wi  where
⌃ is the covariance of ht and we assume the stimulus to have zero mean as well. The quadratic model
enables QLDS to capture phase-invariant responses  like those of complex cells in area V1.

i ht + ci.

+ biwT

i ht2

Quadratic with multiplicative interactions:
In the above model  there are no interactions be-
tween different stimulus ﬁlters  which makes it difﬁcult to model suppressive or facilitating interac-
tions between features [4]. Although contributions from different ﬁlters combine in the dynamics
of x  any interactions are linear. Our third stimulus model allows for multiplicative interactions
between r < m stimulus ﬁlters  with the i-th dimension of the input given by

f i(ht) =

Tht + ci.
Again  we constrain this function to have zero mean by setting ci = Pr

j ht + biwi

ThtwT

ai jwi

rXj=1

j=1 ai jwT

i ⌃wj.

2.3 Learning & Inference

We learn all parameters via the expectation-maximization (EM) algorithm. EM proceeds by alter-
nating between expectation (E) and maximization (M) steps  iteratively maximizing a lower-bound
to the log likelihood [19]. In the E-step  one infers the distribution over trajectories xt  given data
and the parameter estimates from the previous iteration. In the M-step  one updates the current pa-
rameter estimates by maximizing the expectation of the log likelihood  a lower bound on the log
likelihood. EM is a standard method for ﬁtting latent dynamical models; however  the Poisson
observation model complicates computation and requires the use of approximations.

3

E-step: With Gaussian latent states xt  posterior inference amounts to computing the posterior
means µt and covariances Qt of the latent states  given data and current parameters. With Pois-
son observations exact inference becomes intractable  so that approximate inference has to be used
[18  20  21  22]. Here  we apply a global Laplace approximation [20  9] to efﬁciently (linearly
in experiment duration T ) approximate the posterior distribution by a Gaussian. We note that each
fB(ht) in the E-step is deterministic  making posterior inference identical to standard PLDS models.
We found a small number of iterations of Newton’s method sufﬁcient to perform the E-step.

M-step:
In the M-step  each parameter is updated using the means µt and covariances Qt inferred
in the E-step. Given µt and Qt  the parameters A and Q have closed-form update rules that are
derived in standard texts [23]. For the Poisson likelihood  the M-step requires nonlinear optimization
to update the parameters C  D and d [18  9]. While for linear stimulus functions f(ht) the M-
step has a closed-form solution  for nonlinear stimulus functions we optimize  numerically. The
objective function for  given by

g() = 

1
2

TXt=2⇥(µt  Aµt1  f(ht))TQ1(µt  Aµt1  f(ht))⇤ + const. 

where µt = E[xt|yt1  ht]. If  is represented as a vector concatenating all of its parameters  the
gradient of g() takes the form

@g()

@

= Q1

TXt=2

(µt  Aµt1  f(ht))

@f (ht)

@

.

For the quadratic nonlinearity  the gradients with respect to f (ht) take the form

= 2hai⇣ht

Twi⌘ + bii ht

= ht

Twi 

@f (ht)

@wi

@f (ht)

@bi

T 

@f (ht)

@ai

@f (ht)

@ci

=⇣ht

Twi⌘2

= 1.

(6)

(7)

(8)

 

Gradients for the quadratic model with multiplicative interactions take a similar form. When con-
strained to be 0-mean  the gradient for ci disappears  and is replaced by an additional term in the
gradients for a and wi (arising from the constraint on c).
We found both computation time and quality of ﬁt for QLDS to depend strongly upon the optimiza-
tion procedure used. For long time series  we split the data into small minibatches. The QLDS E-step
and M-step each naturally parallelize across minibatches. Neurophysiological experiments are often
naturally segmented into separate trials across different stimuli and experimental conditions  making
it possible to select minibatches without boundary effects.

3 Application to simulated data

We illustrate the properties of QLDS using a simulated population recording of 100 neurons  each
responding to a visual stimulus of binary  white spatio-temporal noise of dimensionality 240. We
simulated a recording with T = 50000 samples and a 10-dimensional latent dynamical state. Five of
the latent states received stimulus input from a bank of 5 stimulus ﬁlters (see Fig. 2A  top row)  and
the remaining latent dimensions only had recurrent dynamics and noise. We aimed to approximate
the properties of real neural populations in early sensory cortex. In particular  we set the dynamics
matrix A by ﬁtting the model to a single neuron recording from V1 [4]. When ﬁtting the model 
we assumed the same dimensionalities (10 latent states  5 stimulus inputs) as those used to generate
the data. We ran 100 iterations of EM  which—-for the recording length and dimensionality of this
system—took about an hour on a 12–core intel Xeon CPU at 3.5GHz.
The model recovered by EM matched the statistics of the true model well. Linear dynamical system
and quadratic models of stimulus selectivity both commonly have invariances that render a particular
parameterization unidentiﬁable [4  15]  and QLDS is no exception: the latent state (and its parame-
ters) can be rotated without changing the model’s properties. Hence it is possible only to compare
the subspace recovered by the model  and not the individual ﬁlters. In order to visualize subspace
recovery  we computed the best `2 approximation of the 5 “true” ﬁlters in the subspace spanned by

4

A

B

C

l

s
n
o
i
t
a
e
r
r
o
c
 
l
a
t
o
T

l

s
n
o
i
t
a
e
r
r
o
c
 
s
u
u
m

l

0.2

0.1

0

−0.1

−0.2

0.2

0.1

0

−0.1

i
t

S

−0.2

0.2

0.1

0

−0.1

−0.2

l

s
n
o
i
t
a
e
r
r
o
c
 
e
s
o
N

i

20

40
60
80
100

20
40
60
80
100

20
40
60
80
100

D

0.5 eigenvalues of A

t
i
f

true
20 40 60 80 100

i

y
r
a
n
g
a
m

i

0

−0.5

E

l

n
o
i
t
a
e
r
r
o
c
 
e
s
o
n

i

0.2
0.15
0.1
0.05
0
−0.05

t
i
f

true
20 40 60 80 100

t
i
f

true
20 40 60 80 100

F

y
t
i
l
i

b
a
b
o
r
p

0.4

0.3

0.2

0.1

0

0.2 0.4 0.6 0.8
noise vs stimulus

real

correlations

0

0.2
stimulus correlation

0.1

true
fit

20

60
synchronous spikes

40

Figure 2: Results on simulated data. Low-dimensional subspace recovery from a population of
100 simulated neurons in response to a white noise stimulus. (A) Simulated neurons receive shared
input from 5 spatio-temporal receptive ﬁelds (top row). QLDS recovers a subspace capable of
representing the original 5 ﬁlters (bottom row). (B) QLDS permits a more compact representation
than the conventional approach of mapping receptive ﬁelds for each neuron. For comparison with
the representation in panel A  we here show the spike-triggered averages of the ﬁrst 60 neurons in the
population. (C) QLDS also models shared variability across neurons  as visualised here by the three
different measures of correlation. Top: Total correlation coefﬁcients between each pair of neurons.
Values below the diagonal are from the simulated data  above the diagonal correspond to correlations
recovered by the model. Center: Stimulus correlations Bottom: Noise correlations. (D) Eigenvalues
of dynamics matrix A (black is ground truth  red is estimated). (E) In this model  stimulus and noise
correlations are dependent on each other  for the parameters chosen in this stimulation  there is a
linear relationship between them. (F) Distribution of population spike counts  i.e. total number of
spikes in each time bin across the population.

reconstruction performance

vs population size

B

linear
quadratic
quadratic cross

l

)
e
a
c
s
 
g
o
l
(
 

E
S
M

A

l

)
e
a
c
s
 
g
o
l
(
 

E
S
M

1

0

−1

−2

−3

−4

400

200
Population Size (# Cells)

600

800 1000

2
1
0
−1
−2
−3
−4
−5

reconstruction performance

vs experiment length

5000

15000
Experiment length (# samples)

10000

Figure 3: Recovery of stimulus subspace as a function of population size (A) and experiment dura-
tion (B). Each point represents the best ﬁlter reconstruction performance of QLDS over 20 distinct
simulations from the same “true” model  each initialized randomly and ﬁt using the same number
of EM iterations. Models were ﬁt with each of three distinct stimulus nonlinearities  linear s (blue) 
quadratic (green)  and quadratic with multiplicative interactions (red). Stimulus input of the “true”
was a quadratic with multiplicative interactions  and therefore we expect only the multiplicative
model (red) to each low error rates.

the estimated ˆwi (see Fig. 2 A bottom row). In QLDS  different neurons share different ﬁlters  and
therefore these 5 ﬁlters provide a compact description of the stimulus selectivity of the population
[24]. In contrast  for traditional single-neuron analyses [4] ‘fully-connected’ models such as GLMs
[14] one would estimate the receptive ﬁelds of each of the 100 ﬁlters in the population  resulting in a
much less compact representation with an order of magnitude more parameters for the stimulus-part
alone (see Fig. 2B).

5

QLDS captures both the stimulus-selectivity of a population and correlations across neurons. In
studies of neural coding  correlations between neurons (Fig. 2C  top) are often divided into stimulus-
correlations and noise-correlations. Stimulus correlations capture correlations explainable by sim-
ilarity in stimulus dependence (and are calculated by shufﬂing trials)  whereas noise-correlations
capture correlations not explainable by shared stimulus drive (which are calculated by correlating
residuals after subtracting the mean ﬁring rate across multiple presentations of the same stimulus).
The QLDS-model was able to recover both the total  stimulus and noise correlations in our simula-
tion (Fig. 2C)  although it was ﬁt only to a single recording without stimulus repeats. Finally  the
model also recovered the eigenvalues of the dynamics (Fig. 2D)  the relationship between noise and
stimulus correlations (Fig. 2E) and the distribution of population spike counts (Fig. 2F).
We assume that all stimulus dependence is captured by the subspace parameterized by the ﬁlters
of the stimulus model.
If this assumption holds  increasing the size of the population increases
statistical power and makes identiﬁcation of the stimulus selectivity easier rather than harder  in
a manner similar to that of increasing the duration of the experiment. To illustrate this point  we
generated multiple data-sets with larger population sizes  or with longer recording times  and show
that both scenarios lead to improvements in subspace-recovery (see Fig. 3).

4 Applications to Neural Data

Cat V1 with white noise stimulus: We evaluate the performance of the QLDS on multi-electrode
recordings from cat primary visual cortex. Data were recorded from anaesthetized cats in response to
a single repeat of a 20 minute long  full-ﬁeld binary noise movie  presented at 30 frames per second 
and 60 repeats of a 30s long natural movie presented at 150 frames per second. Spiking activity
was binned at the frame rate (33 ms for noise  6.6 ms for natural movies). For noise  we used the
ﬁrst 18000 samples for training  and 5000 samples for model validation. For the natural movie  40
repeats were used for training and 20 for validation. Silicon polytrodes (Neuronexus) were employed
to record multi-unit activity (MUA) from a single cortical column  spanning all cortical layers with
32 channels. Details of the recording procedure are described elsewhere [25]. For our analyses  we
used MUA without further spike-sorting from 22 channels for noise data and 25 channels for natural
movies. We ﬁt a QLDS with 3 stimulus ﬁlters  and in each case a 10-dimensional latent state  i.e. 7
of the latent dimensions received no stimulus drive.
Spike trains in this data-set exhibited “burst-like” events in which multiple units were simultaneously
active (Fig. 4A). The model captured these events by using a dimension of the latent state with
substantial innovation noise  leading substantial variability in population activity across repeated
stimulus presentations. We also calculated pairwise (time-lagged) cross-correlations for each unit
pair  as well as the auto-correlation function for each unit in the data (Fig. 4B  7 out of 22 neurons
shown  results for other units are qualitatively similar.). We found that samples from the model
(Fig. 4B  red) closely matched the correlations of the data for most units and unit-pairs  indicating
the QLDS provided an accurate representation of the spatio-temporal correlation structure of the
population recording. The instantaneous correlation matrix across all 22 cells was very similar
between the physiological and sampled data (Fig. 4C). We note that receptive ﬁelds (Fig. 4F) in this
data did not have spatio-temporal proﬁles typical of neurons in cat V1 (this was also found when
using conventional analyses such as spike-triggered covariance). Upon inspection  this was likely a
consequence of an LGN afferent also being included in the raw MUA. In our analysis  a 3-feature
model captured stimulus correlations (in held out data) more accurately than 1- and 2- ﬁlter models.
However  10-fold cross validation revealed that 2- and 3- ﬁlter models do not improve upon a 1-ﬁlter
model in terms of one-step-ahead prediction performance (i.e. trying to predict neural activity on
the next time-step using past observations of population activity and the stimulus).

Macaque V1 with drifting grating stimulus: We wanted to evaluate the ability of the model to
capture the correlation structure (i.e. noise and signal correlations) of a data-set containing multiple
repetitions of each stimulus. To this end  we ﬁt QLDS with a Poisson observation model to the
population activity of 113 V1 neurons from an anaesthetized macaque  as described in [26]. Drift-
ing grating stimuli were presented for 1280ms  followed by a 1280ms blank period  with each of
72 grating orientations repeated 50 times. We ﬁt a QLDS with a 20-dimensional latent state and 15
stimulus ﬁlters  where the stimulus was paramterized as a set of phase-shifted sinusoids at the appro-
priate spatial and temporal frequency (making ht 112-dimensional). We ﬁt the QLDS to 35 repeats 

6

B

0.4

0.2

0

−20

0.4

0.2

0

−20

0.4

0.2

0

−20

0.4

0.2

0

−20

0.4

0.2

0

−20

0.4

0.2

0

−20

0.4

0.2

0

−20

0

0

0

0

20

20

20

20

0

20

0

20

0

20

0.4

0.2

0

−20

0.4

0.2

0

−20

0.4

0.2

0

−20

0.4

0.2

0

−20

0.4

0.2

0

−20

0.4

0.2

0

−20

eigenvalues of A

C
1

0.5

0

−0.5

−1

5
10

15
20

Total correlations

t
i
f

true
5
10

15

20

0

20

0

20

0

20

0

20

0.4

0.2

0

−20

0.4

0.2

0

−20

0.4

0.2

0

−20

0

20

0

20

0

20

0.4

0.2

0

−20

0.4

0.2

0

−20

0

20

0

20

0.4

0.2

0

−20

0

20

0

0

0

20

20

20

0

20

0

20

0

20

0.4

0.2

0

−20

0.4

0.2

0

−20

0.4

0.2

0

−20

0.4

0.2

0

−20

0.4

0.2

0

−20

F

0

0

20

20

0

20

0

20

0

20

0.4

0.2

0

−20

0.4

0.2

0

−20

0.4

0.2

0

−20

0.4

0.2

0

−20

A

a
t
a
d

l

s
u
u
m

i

i
t
s
 
e
s
o
n
 
l
a
c
i
t
n
e
d
i
 
o
t
 
s
t
a
e
p
e
r
 
d
e
t
a
u
m
S

i

l

10 20 30 40 50 60 70 80 90

5
10
15
20

5
10
15
20

5
10
15
20

time (s)

10 20 30 40 50 60 70 80 90
E

noise vs stimulus

 correlation

D

n
o

i
t

l

a
e
r
r
o
c
 
e
s
o
n

i

0.8

0.6

0.4

0.2

y
r
a
n
g
a
m

i

i

0.5

0

−0.5

0

0.5

real

1

0.6

0.4
stimulus correlation

0.8

feature 1

feature 2

feature 3

−165ms

−132ms −99ms −66ms −33ms

0ms

Figure 4: QLDS ﬁt to V1 cells with noise stimuli. We ﬁt QLDS to T = 18000 samples of 22
neurons responding to a white noise stimulus  data binned at 33 ms. We used the quadratic with
multiplicative interactions as the stimulus nonlinearity. The QLDS has a 10-dimensional latent state
with 3 stimulus inputs. All results shown here are compared against T = 5000 samples of test-data 
not used to train the model. (A) Top row: Rasters from recordings from 22 cells in cat visual cortex 
where cell index appears on the y axis  and time in seconds on the x. Second and third row: Two in-
dependent samples from the QLDS model responding to the same noise stimuli. Note that responses
are highly variable across trials. (B) Auto- and cross-correlations for data (black) and model (red)
cells. For the model  we average across 60 independent samples  thickness of red curves reﬂects 1
standard deviation from the mean. Panel (i  j) corresponds to cross-correlation between units with
indices i and j  panels along the diagonal show auto-correlations. (C) Total correlations for the true
(lower diagonal) and model (upper diagonal) populations. (D) Noise correlations scattered against
stimulus correlations for the model. As we did not have repeat data for this population  we were not
able to reliably estimate noise correlations  and thereby evaluate the accuracy of this model-based
(F) Three stimulus ﬁlters recovered by
prediction.
QLDS. We selected the 3-ﬁlter QLDS by inspection  having observed that ﬁtting with larger number
of stimulus ﬁlters did not improve the ﬁt. We note that although two of the ﬁlters appear similar 
that they drive separate latent dimensions with distinct mixing weights ai  bi and ci.

(E) Eigenvalues of the dynamics matrix A.

and held out 15 for validation. The QLDS accurately captured the stimulus and noise correlations of
the full population (Fig. 5A). Further  a QLDS with 15 shared receptive ﬁelds captured simple and
complex cell behavior of all 113 cells  as well as response variation across orientation (Fig. 5B).

5 Discussion

We presented QLDS  a statistical model for neural population recordings from sensory cortex that
combines low-dimensional  quadratic stimulus dependence with a linear dynamical system model.
The stimulus model can capture simple and complex cell responses  while the linear dynamics cap-
ture temporal dynamics of the population and shared variability between neurons. We applied QLDS
to population recordings from primary visual cortex (V1). The cortical microcircuit in V1 consists of
highly-interconnected cells that share receptive ﬁeld properties such as orientation preference [27] 
with a well-studied laminar organization [1]. Layer IV cells have simple cell receptive ﬁeld proper-
ties  sending excitatory connections to complex cells in the deep and superﬁcial layers. Quadratic

7

Figure 5: QLDS ﬁt to 113 V1 cells across 35 repeats of each of 72 grating orientations. (A)
Comparison of total correlations in the data and generated from the model  (B) For two cells (cells
49 and 50  using the index scheme from A) and 6 orientations (0  45  90  135  180  and 225 degrees) 
we show the posterior mean prediction performance (red traces) in in comparison to the average
across 15 held-out trials (black traces).
In each block  we show predicted and actual spike rate
(y-axis) over time binned at 10 ms (x-axis). Stimulus offset is denoted by a vertical blue line.

stimulus models such as the classical “energy model” [16] of complex cells reﬂect this structure.
The motivation of QLDS is to provide a statistical description of receptive ﬁelds in the different
cortical layers  and to parsimoniously capture both stimulus dependence and correlations across an
entire population.
Another prominent neural population model is the GLM (Generalized Linear Model  e.g. [14]; or
the “common input model”  [28])  which includes a separate receptive ﬁeld for each neuron  as
well as spike coupling terms between neurons. While the GLM is a successful model of a popula-
tion’s statistical response properties  its fully–connected parameterization scales quadratically with
population size. Furthermore  the GLM supposes direct couplings between pairs of neurons  while
monosynaptic couplings are statistically unlikely for recordings from a small number of neurons
embedded in a large network.
In QLDS  latent dynamics mediate both stimulus and noise correlations. This reﬂects the structure
of the cortex  where recurrent connectivity gives rise to both stimulus-dependent and independent
correlations. Without modeling a separate receptive ﬁeld for each neuron  the model complexity of
QLDS grows only linearly in population size  rather than quadratically as in fully-connected models
such as the GLM [14]. Conceptually  our modeling approach treats the entire recorded population
as a single “computational unit”  and aims to characterize its joint feature-selectivity and dynamics.
Neurophysiology and neural coding are progressing toward recording and analyzing datasets of ever
larger scale. Population-level parameterizations  such as QLDS  provide a scalable strategy for
representing and analyzing the collective computational properties of neural populations.

Acknowledgements

We are thankful to Arnulf Graf and the co-authors of [26] for sharing the data used in Fig. 5  and to
Memming Park for comments on the manuscript. JHM and EA were funded by the German Federal
Ministry of Education and Research (BMBF; FKZ: 01GQ1002  Bernstein Center T¨ubingen) and the
Max Planck Society  and UK by National Eye Institute grant #EY019965. Collaboration between
EA  JP and JHM initiated at the ‘MCN’ Course at the Marine Biological Laboratory  Woods Hole.

8

Stimulus correlations2040608010020406080100−1−0.500.51cell indexcell index 20406080100Noise correlations−0.1−0.0500.050.1modeldatamodeldata0.20.40.6spike rate000.20.40.650010001500time (ms)spike rate50010001500time (ms)50010001500time (ms)50010001500time (ms)50010001500time (ms)50010001500time (ms)0 degrees45 degrees90 degrees135 degrees180 degrees225 degreesCell 49Cell 50stimulus off AB2013.

References
[1] D. Hubel and T. Wiesel  “Receptive ﬁelds  binocular interaction and functional architecture in the cat’s

visual cortex ” J Physiol  pp. 106–154  1962.

[2] S. L. Smith and M. H¨ausser  “Parallel processing of visual space by neighboring neurons in mouse visual

cortex ” Nature Neurosci  vol. 13  no. 9  pp. 1144–9  2010.

[3] D. S. Reich  F. Mechler  and J. D. Victor  “Independent and redundant information in nearby cortical

neurons ” Science  vol. 294  pp. 2566–2568  2001.

[4] N. C. Rust  O. Schwartz  J. A. Movshon  and E. P. Simoncelli  “Spatiotemporal elements of macaque v1

receptive ﬁelds ” Neuron  vol. 46  no. 6  pp. 945–56  2005.

[5] T. O. Sharpee  “Computational identiﬁcation of receptive ﬁelds ” Annu Rev Neurosci  vol. 36  pp. 103–20 

[6] M. M. Churchland  B. M. Yu  M. Sahani  and K. V. Shenoy  “Techniques for extracting single-trial activity

patterns from large-scale neural recordings ” vol. 17  no. 5  pp. 609–618  2007.

[7] B. M. Yu  J. P. Cunningham  G. Santhanam  S. I. Ryu  K. V. Shenoy  and M. Sahani  “Gaussian-process
factor analysis for low-dimensional single-trial analysis of neural population activity ” vol. 102  no. 1 
pp. 614–635  2009.

[8] W. Truccolo  L. R. Hochberg  and J. P. Donoghue  “Collective dynamics in human and monkey sensori-

motor cortex: predicting single neuron spikes ” Nat Neurosci  vol. 13  no. 1  pp. 105–111  2010.

[9] J. H. Macke  L. B¨using  J. P. Cunningham  B. M. Yu  K. V. Shenoy  and M. Sahani.  “Empirical models

of spiking in neural populations ” in Adv in Neural Info Proc Sys  vol. 24  2012.

[10] D. Pfau  E. A. Pnevmatikakis  and L. Paninski  “Robust learning of low-dimensional dynamics from large

neural ensembles ” in Adv in Neural Info Proc Sys  pp. 2391–2399  2013.

[11] V. Mante  D. Sussillo  K. V. Shenoy  and W. T. Newsome  “Context-dependent computation by recurrent

dynamics in prefrontal cortex ” Nature  vol. 503  pp. 78–84  Nov. 2013.

[12] A. Fairhall  “The receptive ﬁeld is dead. long live the receptive ﬁeld? ” Curr Opin Neurobiol  vol. 25 

pp. ix–xii  2014.

[13] I. M. Park  E. W. Archer  N. Priebe  and J. W. Pillow  “Spectral methods for neural characterization using

generalized quadratic models ” in Adv in Neural Info Proc Sys 26  pp. 2454–2462  2013.

[14] J. W. Pillow  J. Shlens  L. Paninski  A. Sher  A. M. Litke  E. J. Chichilnisky  and E. P. Simoncelli  “Spatio-
temporal correlations and visual signalling in a complete neuronal population ” Nature  vol. 454  no. 7207 
pp. 995–999  2008.

[15] J. W. Pillow and E. P. Simoncelli  “Dimensionality reduction in neural models: an information-theoretic
generalization of spike-triggered average and covariance analysis ” J Vis  vol. 6  no. 4  pp. 414–28  2006.
[16] E. H. Adelson and J. R. Bergen  “Spatiotemporal energy models for the perception of motion ” J Opt Soc

[17] A. C. Smith and E. N. Brown  “Estimating a state-space model from point process observations ” vol. 15 

[18] J. E. Kulkarni and L. Paninski  “Common-input models for multiple neural spike-train data ” Network 

Am A  vol. 2  no. 2  pp. 284–99  1985.

no. 5  pp. 965–991  2003.

vol. 18  no. 4  pp. 375–407  2007.

[19] A. P. Dempster  N. M. Laird  and D. B. Rubin  “Maximum likelihood from incomplete data via the em

algorithm ” J R Stat Soc Ser B  vol. 39  no. 1  pp. 1–38  1977.

[20] L. Paninski  Y. Ahmadian  D. Ferreira  S. Koyama  K. Rahnama Rad  M. Vidne  J. Vogelstein  and W. Wu 

“A new look at state-space models for neural data ” vol. 29  pp. 107–126  2010.

[21] A. Z. Mangion  K. Yuan  V. Kadirkamanathan  M. Niranjan  and G. Sanguinetti  “Online variational in-
ference for state-space models with point-process observations ” Neural Comput  vol. 23  no. 8  pp. 1967–
1999  2011.

[22] M. Emtiyaz Khan  A. Aravkin  M. Friedlander  and M. Seeger  “Fast dual variational inference for non-

conjugate latent gaussian models ” in Proceedings of ICML  2013.

[23] Z. Ghahramani and G. E. Hinton  “Parameter estimation for linear dynamical systems ” Univ. Toronto

[24] J. H. Macke  G. Zeck  and M. Bethge  “Receptive ﬁelds without spike-triggering ” in Adv in Neural Info

Tech Report  vol. 6  no. CRG-TR-96-2  1996.

Proc Sys  vol. 20  pp. 969–976  2008.

[25] U. K¨oster  J. Sohl-Dickstein  C. M. Gray  and B. A. Olshausen  “Modeling higher-order correlations

within cortical microcolumns ” PLoS Comput Bio  vol. 10  no. 7  p. e1003684  2014.

[26] A. B. Graf  A. Kohn  M. Jazayeri  and J. A. Movshon  “Decoding the activity of neuronal populations in

macaque primary visual cortex ” Nature neuroscience  vol. 14  no. 2  pp. 239–245  2011.

[27] V. Mountcastle  “Modality and topographic properties of single neurons of cat’s somatic sensory cortex ”

J Neurophysiol  1957.

[28] M. Vidne  Y. Ahmadian  J. Shlens  J. Pillow  J. Kulkarni  A. Litke  E. Chichilnisky  E. Simoncelli  and
L. Paninski  “Modeling the impact of common noise inputs on the network activity of retinal ganglion
cells ” J Comput Neurosci  2011.

9

,Tzu-Kuo Huang
Jeff Schneider
Evan Archer
Urs Koster
Jonathan Pillow
Jakob Macke
Nikolaos Tziavelis
Ioannis Giannakopoulos
Katerina Doka
Nectarios Koziris
Panagiotis Karras