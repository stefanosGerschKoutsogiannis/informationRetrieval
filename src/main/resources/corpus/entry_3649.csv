2016,Multistage Campaigning in Social Networks,We consider control problems for multi-stage campaigning over social networks. The dynamic programming framework is employed to balance the high present reward and large penalty on low future outcome in the presence of extensive uncertainties. In particular  we establish theoretical foundations of optimal campaigning over social networks where the user activities are modeled as a multivariate Hawkes process  and we derive a time dependent linear relation between the intensity of exogenous events and several commonly used objective functions of campaigning. We further develop a convex dynamic programming framework for determining the optimal intervention policy that prescribes the required level of external drive at each stage for the desired campaigning result. Experiments on both synthetic data and the real-world MemeTracker dataset show that our algorithm can steer the user activities for optimal campaigning much more accurately than baselines.,Multistage Campaigning in Social Networks

Mehrdad Farajtabar∗

Xiaojing Ye⋄

Sahar Harati†

Georgia Institute of Technology∗

Le Song∗

Hongyuan Zha∗

Georgia State University⋄

Emory University†

mehrdad@gatech.edu

xye@gsu.edu

sahar.harati@emory.edu

{lsong zha}@cc.gatech.edu

Abstract

We consider the problem of how to optimize multi-stage campaigning over social
networks. The dynamic programming framework is employed to balance the high
present reward and large penalty on low future outcome in the presence of exten-
sive uncertainties. In particular  we establish theoretical foundations of optimal
campaigning over social networks where the user activities are modeled as a mul-
tivariate Hawkes process  and we derive a time dependent linear relation between
the intensity of exogenous events and several commonly used objective functions
of campaigning. We further develop a convex dynamic programming framework
for determining the optimal intervention policy that prescribes the required level
of external drive at each stage for the desired campaigning result. Experiments on
both synthetic data and the real-world MemeTracker dataset show that our algo-
rithm can steer the user activities for optimal campaigning much more accurately
than baselines.

1 Introduction
Obama was the ﬁrst US president in history who successfully leveraged online social media in pres-
idential campaigning  which has been popularized and become a ubiquitous approach to electoral
politics (such as in the on-going 2016 US presidential election) in contrast to the decreasing rele-
vance of traditional media such as TV and newspapers [1  2]. The power of campaigning via social
media in modern politics is a consequence of online social networking being an important part of
people’s regular daily social lives. It has been quite common that individuals use social network sites
to share their ideas and comment on other people’s opinions. In recent years  large organizations 
such as governments  public media  and business corporations  also start to announce news  spread
ideas  and/or post advertisements in order to steer the public opinion through social media platform.
There has been extensive interest for these entities to inﬂuence the public’s view and manipulate
the trend by incentivizing inﬂuential users to endorse their ideas/merits/opinions at certain monetary
expenses or credits. To obtain most cost-effective trend manipulations  one needs to design an opti-
mal campaigning strategy or policy such that quantities of interests  such as inﬂuence of opinions 
exposure of a campaign  adoption of new products  can be maximized or steered towards the target
amount given realistic budget constraints.
The key factor differentiating social networks from traditional media is peer inﬂuence. In fact  events
in an online social network can be categorized roughly into two types: endogenous events where
users just respond to the actions of their neighbors within the network  and exogenous events where
users take actions due to drives external to the network. Then it is natural to raise the following
fundamental questions regarding optimal campaigning over social networks: can we model and
exploit those event data to steer the online community to a desired exposure level? More speciﬁcally 
can we drive the overall exposure to a campaign to a certain level (e.g.  at least twice per week per
user) by incentivizing a small number of users to take more initiatives? What about maximizing the
overall exposure for a target group of people?

30th Conference on Neural Information Processing Systems (NIPS 2016)  Barcelona  Spain.

More importantly  those exposure shaping tasks are more effective when the interventions are imple-
mented in multiple stages. Due to the inherent uncertainty in social behavior  the outcome of each
intervention may not be fully predictable but can be anticipated to some extent before the next in-
tervention happens. A key aspect of such situations is that interventions can’t be viewed in isolation
since one must balance the desire for high present reward with the penalty of low future outcome.
In this paper  the dynamic programming framework [3] is employed to tackle the aforementioned
issues. In particular  we ﬁrst establish the fundamental theory of optimal campaigning over social
networks where the user activities are modeled as a multivariate Hawkes process (MHP) [4  5] since
MHP can capture both endogenous and exogenous event intensities. We also derive a time dependent
linear relation between the intensity of exogenous events and the overall exposure to the campaign.
Exploiting this connection  we develop a convex dynamic programming framework for determining
the optimal intervention policy that prescribes the required level of external drive at each stage in
order for the campaign to reach a desired exposure proﬁle. We propose several objective functions
that are commonly considered as campaigning criteria in social networks. Experiments on both
synthetic data and real world network of news websites in the MemeTracker dataset show that our
algorithms can shape the exposure of campaigns much more accurately than baselines.
2 Basics and Background
An n-dimensional temporal point process is a random process whose realization consists of a
list of discrete events in time and their associated dimension  {(tk  dk)} with tk ∈ R+ and
dk ∈{ 1  . . .   n}. Many different types of data produced in online social networks can be rep-
resented as temporal point processes  such as likes and tweets. A temporal point process can be
equivalently represented as a counting process  N (t) = (N 1(t)  . . .  N n(t))⊤ associated to n users
in the social network. Here  N i(t) records the number of events user i performs before time t for
1 ≤ i ≤ n. Let the history Hi(t) be the list of times of events {t1  t2  . . .   tk} of the i-th user up
to time t. Then  the number of observed events in a small time window [t  t + dt) of length dt is
dN i(t) =!tk∈Hi(t) δ(t − tk) dt  and hence N i(t) =" t
0 dN i(s)  where δ(t) is a Dirac delta func-
tion. The point process representation of temporal data is fundamentally different from the discrete
time representation typically used in social network analysis. It directly models the time interval
between events as random variables  avoids the need to pick a time window to aggregate events  and
allows temporal events to be modeled in a ﬁne grained fashion. Moreover  it has a remarkably rich
theoretical support [6].
An important way to characterize temporal point processes is via the conditional intensity function
— a stochastic model for the time of the next event given all the times of previous events. Formally 
the conditional intensity function λi(t) (intensity  for short) of user i is the conditional probability

of observing an event in a small window [t  t + dt) given the history H(t) =#H1(t)  . . .  Hn(t)$:

λi(t)dt := P{user i performs event in [t  t + dt)|H(t)} = E[dN i(t)|H(t)] 

(1)
where one typically assumes that only one event can happen in a small window of size dt. The
functional form of the intensity λi(t) is often designed to capture the phenomena of interests.
The Hawkes process [7] is a class of self and mutually exciting point process models 

λi(t) = µi(t) + %k:tk<t

n%j=1& t

0

φidk (t  tk) = µi(t) +

φij(t  s)dN j(s) 

(2)

where the intensity is history dependent. φij(t  s) is the impact function capturing the temporal
inﬂuence of an event by user j at time s to the future events of user j at time t ! s. Here  the ﬁrst term
µi(t) is the exogenous event intensity modeling drive outside the network and indecent of the history 

and the second term!k:tk<t φidk (t  tk) is the endogenous event intensity modeling interactions

within the network [8]. Deﬁning Φ(t  s) = [φij(t  s)]i j=1...n  and λ(t) = (λ1(t)  . . .  λ n(t))⊤  and
µ(t) = (µ1(t)  . . .   µn(t))⊤ we can compactly rewrite Eq 2 in matrix form:

λ(t) = µ(t) +& t
(3)
In practice it is standard to employ shift-invariant impact function  i.e.  Φ(t  s) =Φ( t − s). Then 
by using notation of convolution f (t) ∗ g(t) =" t

0 f (t − s)g(s)ds we have

Φ(t  s)dN (s).

λ(t) = µ(t) +Φ( t) ∗ dN (t).

(4)

0

2

3 From Intensity to Average Activity
In this section we will develop a closed form relation between the expected total intensity E[λ(t)]
and the intensity µ(t) of exogenous events. This relation establish the basis of our campaigning
framework. First  deﬁne the mean function as M(t) := E[N (t)] = EH(t)[E(N (t)|H(t))]. Note that
M(t) is history independent  and it gives the average number of events up to time t for each of the
dimension. Similarly  the rate function η(t) is given by η(t)dt := dM(t). On the other hand 
(5)
dM(t) = dE[N (t)] = EH(t)[E(dN (t)|H(t))] = EH(t)[λ(t)|H(t)]dt = E[λ(t)]dt.
Therefore η(t) = E[λ(t)] which serves as a measure of activity in the network. In what follows we
will ﬁnd an analytical form for the average activity. Proofs are presented in Appendix C.
Lemma 1. Suppose Ψ: [0   T ] → Rn×n is a non-increasing matrix function  then for every ﬁxed
constant intensity µ(t) = c ∈ Rn

+  ηc(t) :=Ψ( t)c solves the semi-inﬁnite integral equation

if and only if Ψ(t) satisﬁes

∀t ∈ [0  T ] 

Φ(t − s)η(s)ds 

η(t) = c +& t
Ψ(t) = I +& t
Ψ(t) = e(A−ωI )t + ω(A − ωI )−1(e(A−ωI )t − I)

Φ(t − s)Ψ(s)ds 

∀t ∈ [0  T ].

0

0

In particular  if Φ(t) = Ae−ωt1≥0(t) = [aije−ωt1≥0(t)]ij where 0 ≤ ω/∈ Spectrum(A)  then

(6)

(7)

(8)

(9)

(11)

(12)

for t ∈ [0  T ]  where  1≥0(t) is an indicator function for t ≥ 0.
Let µ : [0  T ] → Rn

+ be a right-continuous piecewise constant function

µ(t) =

cm1[τm−1 τm)(t) 

M%m=1

where 0 = τ0 <τ 1 < ··· <τ M = T is a ﬁnite partition of time interval [0  T ] and function
1[τm−1 τm)(t) indicates τm−1 ≤ t <τ m. The next theorem shows that if Ψ(t) satisﬁes (7)  then one
can calculate η(t) for piecewise constant intensity µ : [0  T ] of form (9).
Theorem 2. Let Ψ(t) satisfy (7) and µ(t) be a right-continuous piecewise constant intensity function
of form (9)  then the rate function η(t) is given by

η(t) =

Ψ(t − τk)(ck − ck−1) 

(10)

m%k=0

for all t ∈ (τm−1 τ m] and m = 1  . . .   M  where c−1 := 0 by convention.
Using the above lemma  for the ﬁrst time  we derive the average intensity for a general exogenous
intensity. Appendix E includes a few experiments to investigate these results empirically.
Theorem 3. If Ψ ∈ C1([0  T ]) and satisﬁes (7)  and exogenous intensity µ is bounded and piece-
wise absolutely continuous on [0  T ] where µ(t+) = µ(t) at all discontinuous points t  then µ is
differentiable almost everywhere  and the semi-indeﬁnite integral

yields a rate function η : [0  T ] → Rn

Φ(t − s)η(s)ds 

∀t ∈ [0  T ] 

0

η(t) = µ(t) +& t
η(t) =& t

+ given by

0

Ψ(t − s)dµ(s).

Corollary 4. Suppose Ψ and µ satisfy the same conditions as in Thm. 3  and deﬁne ψ =Ψ ′  then
the rate function is η(t) = (ψ ∗ µ)(t). In particular  if Φ(t) = Ae−ωt1≥0(t) = [aije−ωt1≥0(t)]ij
then the rate function η(t) = µ(t) + A" t

0 e(A−wI)(t−s)µ(s)ds.

3

4 Multi-stage Closed-loop Control Problem
Given the analytical relation between exogenous intensity and expected overall intensity (rate func-
tion)  one can solve a single one-stage campaigning problem to ﬁnd the optimal constant intervention
intensity [8]. Alternatively  the time window can be partitioned into multiple stages and one can im-
pose different levels of interventions in these stages. This yields an open-loop optimization of the
cost function where one selects all the intervention actions at initial time 0. More effectively  we
tackle the campaigning problem in a dynamic and adaptive manner where we can postpone deciding
the intervention by observing the process until the next stage begins. This is called the closed-loop
optimization of the objective function.
In this section  we establish the foundation to formulate the problem as a multi-stage closed-loop op-
timal control problem. We assume that n users are generating events according to multi-dimensional
Hawkes process with exogenous intensity µ(t) ∈ Rn and impact function Φ(t  s) ∈ Rn×n.
Event exposure. Event exposure is the quantity of major interests in campaigning. The exposure
process is mathematically represented as a counting process  E(t) = (E 1(t)  . . .  E n(t))⊤: Here 
E i(t) records the number of times user i is exposed (she or one of her neighbors performs an activity)
to the campaign by time t. Let B be the adjacency matrix of the user network  i.e.  bij = 1 if user
i follows user j or equivalently user j inﬂuences user i. We assume bii = 1 for all i. Then the
exposure process is given by E(t) = B N (t).
Stages and interventions. Let [0  T ] be the time horizon and 0 = τ0 <τ 1 < . . . <τ M−1 <
τM = T be a partition into the M stages. In order to steer the activities of network towards a
desired level (criteria given below) at these stages  we impose a constant intervention um ∈ Rn to
the existing exogenous intensity µ during time [τm τ m+1) for each stage m = 0  1  . . .   M − 1. The
activity intensity at the m-th stage is λm(t) = µ + um +" t
0 Φ(t  s) dN (s) for τm ≤ t <τ m+1
where N (t) tracks the counting process of activities since t = 0. Note that the intervention itself
exhibits a stochastic nature: adding ui
m to µi is equivalent to incentivizing user i to increase her
activity rate but it is still uncertain when she will perform an activity  which appropriately mimics
the randomness in real-world campaigning.
States and state evolution. Note that the Hawkes process is non-Markov and one needs complete
knowledge of the history to characterize the entire process. However  the conditional intensity λ(t)
only depends on the state of process at time t when the standard exponential kernel Φ(t  s) =
Ae−ω(t−s)1≥0(t − s) is employed. In this case  the activity rate at stage m is

(13)

τm

+& t
’

Ae−ω(t−s) dN (s)
*

()

current stage

λm(t) = µ + um +& τm
’

0

Ae−ω(t−s) dN (s)
*

from previous stages

()
Deﬁne xm := λm−1(τm) − um−1 − µ (and x0 = 0 by convention) then the intensity due to events
of all previous m stages can be written as" τm
0 Ae−ω(t−s) dN (s) = xme−ω(t−τm). In other words 
xm is sufﬁcient to encode the information of activity in the past m stages that is relevant to future.
This is in sharp contrast to the general case where the state space grows with the number of events.
Objective function. For a sequence of controls u(t) =!M−1
m=0 um1[τm τm+1)(t)  the activity count-
ing process N (t) is generated by intensity λ(t) = µ + u(t) +" t
0 Ae−ω(t−s) dN (s). For each stage
m from 0 to M − 1  xm encodes the effects from previous m stages as above and um is the current
control imposed at this stage. Let E i
dN i(s) be the number of times user i is
exposed to the campaign by time t ∈ [τm τ m+1) in stage m  then the goal is to steer the expected
total number of exposure ¯E i
m(τm+1; xm  um)] to a desired level. In what follows 
we introduce several instances of the objective function g(xm  um) in terms of { ¯E i
m(xm  um)}n
i=1
in each stage m that characterize different exposure shaping tasks. Then the overall control problem
is to ﬁnd u(t) that optimizes the total objective!M−1
• Capped Exposure Maximization (CEM): In real networks  there is a cap on the exposure each user
can tolerate due to the limited attention of a user. Suppose we know the upper bound βi
m   on user
i’s exposure tolerance over which the extra exposure is not counted towards the objective. Then 
we can form the following capped exposure maximization

m(t; xm  um) := B" t

m(xm  um) := E[E i

m=0 gm(xm  um).

τm

gm(xm  um) =

1
n

n%i=1

min# ¯E i

m(xm  um) β i

m$

(14)

4

Algorithm 1: Closed-loop Multi-stage Dynamic Programming

Input: Intervention constraints: c0 . . . cM−1  C0 . . . CM−1  α0 . . .α M−1 
Input: Objective-speciﬁc constraints: β0 . . .β M−1 for CEM and γ0 . . .γ M−1 for LES
Input: Time: T   Hawkes parameters: A  ω
Output: Optimal intervention u0 . . . uM−1  Optimal cost: Cost
Set x0 ← 0 and Cost ← 0
for l ← 0 : M − 1 do

(vl . . . vM−1) = open loop(xl) (Problems (24)  (25)  (26) for CEM  MEM  LES respectively)
Set ul ← vl and drop vl+1 . . . vM−1
Update next state xl+1 ← fl(xl  ul) and Cost = Cost + gl(xl  ul)

• Minimum Exposure Maximization (MEM): Suppose our goal is instead to maintain the exposure
of campaign on each user above a certain minimum level  at each stage or  alternatively to make
the user with the minimum exposure as exposed as possible  we can consider the following cost
function:

gm(xm  um) = min

(15)
• Least-squares Exposure Shaping (LES): Sometimes we want to achieve a pre-speciﬁed target ex-
posure levels  γm ∈ Rn  for the users. For example  we may like to divide users into groups and
desire a different level of exposure in each group. To this end  we can perform least-squares cam-
paigning task with the following cost function where D encodes potentially additional constraints
(e.g.  group partitions):

¯E i
m(xm  um)

i

gm(xm  um) = −

1
n∥D ¯Em(xm  um) − γm∥2

(16)

Policy and actions. By observing the counting process in previous stages (summarized in a se-
quence of xm) and taking the future uncertainty into account  the control problem is to design a
policy π = {πm : Rn → Rn : m = 0  . . .   M − 1} such that the controls um = πm(xm) can maxi-
mize the total objective!M−1
m=0 gm(xm  um). In addition  we may have constraints on the amount of
control. For example  a budget constraint on the sum of all interventions to users at each stage  or  a
cap over the amount of intensity a user can handle. A feasible set or an action space over which we
ﬁnd the best intervention is represented as Um :=#um ∈ Rn|c⊤mum ≤ Cm  0 " um " αm$. Here 
+ contains the price of each person per unit increase of exogenous intensity and Cm ∈ R+
cm ∈ Rn
is the total budget at stage m. Also  αm ∈ Rn
To summarize  the following problem is formulated to ﬁnd the optimal control policy π:

+ is the cap on the amount of activities of the users.

maximize

π

gm(xm π m(xm))  subject to πm(xm) ∈U m  for m = 0  . . .   M − 1.

(17)

M−1%m=0

5 Closed-loop Dynamic Programming Solution
We have formulated the control problem as an optimization in (17). However  when control
policy πm is to be implemented  only xm is observed and there are still uncertainties in future
{xm+1  . . .   xM−1}. For instance  when πm is implemented according to xm starting from time
τm  the intensity xm+1 := f (xm π m(xm)) at time τm+1 depends on xm and the control πm(xm) 
but is also random due to the stochasticity of the process during time [τm τ m+1). Therefore  the
design of π needs to take future uncertainties into considerations.
Suppose we have arrived at stage M at time τM−1 with observation xM−1  then the optimal policy
πM−1 satisﬁes gM−1(xM−1 π M−1(xM−1)) = maxu∈UM−1 gM−1(xM−1  u) =: JM−1(xM−1).
We then repeat this procedure for m from M − 1 to 0 backward to ﬁnd the sequence of controls via
dynamic programming such that the control πm(xm) ∈U m yields optimal objective value
(18)

E[gm(xm  um) + Jm+1(f (xm  um))]

Jm(xm) = max
um∈Um

Approximate Dynamic Programming. Solving (18) for ﬁnding Jm(xm) analytically is intractable.
Therefore  we will adopt an approximate dynamic programming scheme. In fact approximate con-
trol is as essential part of dynamic programming as the optimization is usually intractable due to

5

curse of dimensionality except a few especial cases [3]. Here we adopt a suboptimal control scheme 
certainty equivalent control (CEC)  which applies at each stage the control that would be optimal
if the uncertain quantities were ﬁxed at some typical values like the average behavior. It results in
an optimal control sequence  the ﬁrst component of which is used at the current stage  while the re-
maining components are discarded. The procedure is repeated for the remaining stages. Algorithm 1
summarizes the dynamic programing steps. This algorithm has two parts: (i) certainty equivalence
which the random behavior is replaced by its average; and (ii) the open-loop optimization. Let’s
assume we are at the beginning of stage l of the Alg. 1 with state vector xl at τl.

Certainty equivalence. We use the machinery developed in Sec. 3 to compute the average of
exposure at any stage m = l  l + 1  . . .   M − 1.
¯Em(xm  um) = BE[N (τm+1) −N (τm)] = BE+& τm+1
where ηm(t) = E[λm(t)] and λm(t) = µ + um + xle−ω(t−τl) +" t
Ae−ω(t−s)dN (s) for t ∈
[τm τ m+1). Now  we use the superposition property of point processes [4] to decompose the process
as N (t) = N c(t) + N v(t) corresponding to λm(t) = λc
m(t) =
µ + um +" t
Ae−ω(t−s)dN c(s) consists of events caused by exogenous intensity at current stage m
m(t) = xle−ω(t−τl) +" t
and the second λv
Ae−ω(t−s)dN v(s) is due to activities in previous stages.
According to Thm. 2 we have

dN (s)  = B& τm+1

m(t) where the ﬁrst λc

m(t) + λv

ηm(s) ds

(19)

τm

τm

τl

τl

τl

m(t) := E[λc
ηc

m(t)] = Ψ(t − τl)µ +Ψ( t − τl)ul +

and according to Thm. 3 we have

m−1%k=l+1

Ψ(t − τk)(uk − uk−1) 

(20)

m(t)] =& t

τl

m(t) := E[λv
ηv

Ψ(t − s) d(xle−ω(s−τl)1[τl ∞)(s)).

(21)

m(t) + ηv

m(t) yields:

From now on  for simplicity  we assume stages are based on equal partition of [0  T ] to M segments
where each has length ∆M. Combining Eq. (19) and ηm(t) = ηc
¯Em(xm  um) =Γ((m − l + 1)∆M )ul + Γ((m − l)∆M )(ul+1 − ul) + . . .

+ Γ(∆M )(um − um−1) + Γ((m − l + 1)∆M )µ +Υ(( m − l + 1)∆M )xl
where Γ(t) and Υ(t) are matrices independent of um’s and are deﬁned in Appendix D. Note the
linear relation between average exposure ¯Em(xm  um) and intervention values ul  . . .   um−1.
Open-loop optimization. Having found the average exposure at stages m = l  . . .   M−1 we formu-
late an open-loop optimization to ﬁnd optimal ul  ul+1  . . .   uM−1. Deﬁning ˆul = (ul; . . . ; uM−1)
and ˆEl = ( ¯El(xl  ul); . . . ; ¯EM−1(xM−1  uM−1)) we can write

(22)

Xl ˆul + Ylµ + Wlxl = ˆEl where Zl ˆul ≤ zl

(23)

and Xl  Yl  Wl  Zl  and zl are independent of ˆul  µ  and xl as deﬁned in Appendix D.
Deﬁning the expanded form of constraint variables as ˆcl = (cl; . . . ; cM−1)  ˆCl = (Cl; . . . ; CM−1) 
and ˆαl = (αl; . . . ; αM−1) we provide the optimization from of the above exposure shaping tasks.
For CEM consider ˆβl = (βl; . . .  β M−1). Then the problem

maximizeˆh ˆul

1

n 1⊤ˆh subject to Xl ˆul + Ylµ + Wlxl ≥ ˆh  ˆβl ≥ ˆh  Zl ˆul ≤ zl 

(24)

solves CEM where h is an auxiliary vector of size n(M − l).
For MEM consider the auxiliary h as a vector of size M − l and ˆh a vector of size n(M − 1).
ˆh = (h(1); . . . ; h(1); h(2); . . .   h(2); . . .   h(M − l); . . . ; h(M − l)) where each h(k) is repeated n
times. Then MEM is equivalent to

maximizeˆh ˆul

1⊤ˆh subject to Xl ˆul + Ylµ + Wlxl ≥ ˆh  ˆβl ≥ ˆh  Zl ˆul ≤ zl

(25)

6

e
r
u
s
o
p
x
e

 
f

 

o
m
u
s

350

300

250

200

150

100

CLL OPL RND PRK WEI

e
r
u
s
o
p
x
e
m
u
m
n
m

 

i

i

5

4.5

4

3.5

3

2.5

2

1.5

CLL OPL RND WFL PRP

e
c
n
a

i

 

t
s
d
e
g
a
r
e
v
a

×104

1.5

1

0.5

CLL OPL RND GRD REL

a) Capped maximization b) Minimum maximization c) Least-squares shaping

Figure 1: The objective on simulated events and synthetic network; n = 300  M = 6  T = 40

For LES let ˆγl = (γl; . . . ; γM−1) and ˆDl = diag(D  . . .   D)  then

1

minimizeˆul

subject to Zl ˆul ≤ zl

n∥ ˆDl(Xl ˆul + Ylµ + Wlxl) − ˆγl∥2

(26)
All the three tasks involve convex (and linear) objective function with linear constraints which im-
pose a convex feasible set. Therefore  one can use the rich and well-developed literature on convex
optimization and linear programming to ﬁnd the optimum intervention.
6 Experiments
We evaluate our campaigning framework using both simulated and real world data and show that
our approach signiﬁcantly outperforms several baselines1.
Campaigning results on synthetic networks. In this section  we experiment with a synthetic net-
work of 300 nodes. Details of the experimental setup and parameter setting are found in appendix
F. We focus on three tasks: capped exposure maximization  minimax exposure shaping  and least
square exposure shaping. To compare the methods we simulate the network with the prescribed
intervention intensity and compute the objective function based on the events happened during the
simulation. The mean and standard deviation of the objective function out of 10 runs are reported.
Fig. 1 summarizes the performance of the proposed algorithm (CLL) and 4 other baselines on dif-
ferent campaigning tasks. For CEM  our approach consistently outperforms the others by at least
10. This means it exposes each user to the campaign at least 10 times more than the rest consuming
the same budget and within the same constraints. The extra 20 units of exposures of over OPL or
value of information shows how much we gain by incorporating a dynamic closed-loop solution
as opposed to open-loop one-time optimization over all stages. For MEM  the proposed method
outperforms the others by a smaller margin  however  the 0.1 exposure difference with the second
best method is not triﬂing. This is expected as lifting the minimum exposure is a difﬁcult task [8].
For LES  results demonstrate the superiority of CLL by a large margin. The 103 difference with the

second best algorithm aggregated over 6 stages roughly is translated to-103/6 ∼ 13 difference in

the number of exposures per user. Given the heterogeneity of the network activity and target shape 
this is a signiﬁcant improvement over the baselines. Appendix F includes further results on varying
number of nodes  number of stages  and duration of each stage.
Campaigning results on real world networks. We also evaluate the proposed framework on real
world data. To this end  we utilize the MemeTracker dataset [9] which contains the information ﬂows
captured by hyperlinks between different sites with timestamps during 9 months. This data has been
previously used to validate Hawkes process models of social activity [5  10]. For the real data  we
utilize two evaluation procedures. First  similar to the synthetic case  we simulate the network  but
now on a network based on the learned parameters from real data. However  the more interesting
evaluation scheme would entail carrying out real intervention in a social media platform. Since this
is very challenging to do  instead  in this evaluation scheme we used held-out data to mimic such
procedure. Second  we form 10 pairs of clusters/cascades by selecting any 2 combinations of 5
largest clusters in the Memetracker data. Each is a cascade of events around a common subject. For
any of these 10 pairs  the methods are faced to the question of predicting which cascade will reach
the objective function better. They should be able to answer this by measuring how similar their
prescription is to the real exogenous intensity. The key point here is that the real events happened
are used to evaluate the objective function of the methods. Then the results are reported on average
prediction accuracy on all stages over 10 runs of random constraint and parameter initialization on
10 pairs of cascades. The details of the experimental setup is further explained in Appendix F.
Fig. 2  left column illustrates the performance with respect to increasing the number of users in the
network. The performance drops slightly with the network size. This means that prediction becomes

1codes are available at http://www.cc.gatech.edu/~mfarajta/

7

CLL OPL RND PRK WEI

CLL OPL RND PRK WEI

n
o
i
t
a
z
i
m
i
x
a
M
d
e
p
p
a
C

n
o
i
t
a
z
i
m
i
x
a
M
m
u
m
i
n
i
M

g
n
i
p
a
h
S
s
e
r
a
u
q
s
-
t
s
a
e
L

y
c
a
r
u
c
c
a
 
n
o
i
t
c
d
e
r
p

i

y
c
a
r
u
c
c
a
 
n
o
i
t
c
d
e
r
p

i

y
c
a
r
u
c
c
a

 

n
o

i

i
t
c
d
e
r
p

0.75

0.7

0.65

0.6

50

0.65

0.6

0.55

0.5

0.45

50

0.65

0.6

0.55

0.5

50

100

150

200

250

network size

CLL OPL RND WFL PRP

100

150

200

250

network size

CLL OPL RND GRD REL

100

150

200

250

network size

y
c
a
r
u
c
c
a
 
n
o
i
t
c
d
e
r
p

i

y
c
a
r
u
c
c
a
 
n
o
i
t
c
d
e
r
p

i

y
c
a
r
u
c
c
a
n
o

 

i

i
t
c
d
e
r
p

0.8

0.75

0.7

0.65

0.6

2

0.65

0.6

0.55

0.5

0.45

0.4

2

0.65

0.6

0.55

0.5

0.45

2

4
8
intervention points

6

10

CLL OPL RND WFL PRP

4
8
intervention points

6

10

CLL OPL RND GRD REL

8
4
intervention points

6

10

e
r
u
s
o
p
x
e

 
f

 

o
m
u
s

20

15

10

5

CLL OPL RND PRK WEI

methods

e
r
u
s
o
p
x
e
m
u
m
n
m

 

i

i

1.5

1

0.5

0

CLL OPL RND WFL PRP

methods

7000

6500

e
c
n
a

i

 

t
s
d
e
g
a
r
e
v
a

6000

5500

5000

CLL OPL RND GRD REL

methods

Performance vs. # users

Performance vs. # points

Figure 2: real world dataset results; n = 300  M = 6  T = 40

Objective function

more difﬁcult as more random variables are involved. The middle panel shows the performance with
respect to increasing the number of intervention points. Here  a slight increase in the performance
is apparent. As the number of intervention points increases the algorithm has more control over the
outcome and can reach the objective function better.
Fig. 2 top row summarizes the results of CEM. The left panel demonstrates the predictive perfor-
mance of the algorithms. CLL consistently outperforms the rest. With 65-70 % of accuracy in
predicting the optimal cascade. The right panel shows the objective function simulated 10 times
with the learned parameters for network of n = 300 users on 6 intervention points. The extra 2.5
extra exposure per user compared to the second best method with the same budget and constraint
would be a signiﬁcant advertising achievement. Among the competitors OPL and RND seem to
perform good. If there where no cap over the resultant exposure  all methods would perform com-
parably because of the linearity of sum of exposure. However  the successful method is the one who
manage to maximize exposure considering the cap. Failure of PRK and WEI indicates that structural
properties are not enough to capture the inﬂuence. Compared to these two  RND performs better in
average  however exhibits a larger variance as expected.
Fig. 2 middle row summarizes the results for MEM and shows CLL outperforms others consistently.
CLL still is the best algorithm and OPL and RND are the signiﬁcant baselines. Failure of WFL and
PRP shows the network structure plays a signiﬁcant role in the activity and exposure processes.
The bottom row in Fig. 2 demonstrates the results of LES. CLL is still the best method. OPL is still
strong but RND is not performing well. The objective function is summation of the square of the
gap between target and current exposure. This explains why GRD is showing a comparable success 
since  it starts with the highest gap in the exposure and greedily allocates the budget.
Conclusion. In this paper  we introduced the optimal multistage campaigning problem  which is a
generalization of the activity shaping and inﬂuence maximization problems  and it allows for more
elaborate goal functions. Our model of social activity is based on multivariate Hawkes process 
and for the ﬁrst time  we manage to derive a linear connection between a time-varying exogenous
intensity and the overall network exposure of the campaign.
Acknowledgement. The work is supported in part by NSF/NIH BIGDATA R01 GM108341  NSF
IIS-1639792  NSF DMS-1620345  and NSF DMS-1620342.

8

References

[1] D M West. Air Wars: Television Advertising and Social Media in Election Campaigns  1952-2012:

Television Advertising and Social Media in Election Campaigns  1952-2012. Sage  2013.

[2] M Vergeer  L Hermans  and S Sams. Online social networks and micro-blogging in political campaigning

the exploration of a new campaign tool and a new campaign style. Party Politics  2013.

[3] Dimitri P Bertsekas. Dynamic programming and optimal control  volume 1.
[4] D J Daley and D Vere-Jones. An introduction to the theory of point processes. Springer Science &

Business Media  2007.

[5] K Zhou  H Zha  and L Song. Learning social infectivity in sparse low-rank networks using multi-

dimensional hawkes processes. In AISTATS  2013.

[6] O Aalen  O Borgan  and H Gjessing. Survival and event history analysis: a process point of view.

Springer  2008.

[7] A G Hawkes. Spectra of some self-exciting and mutually exciting point processes. Biometrika  1971.
[8] M Farajtabar  N Du  M Gomez-Rodriguez  I Valera  L Song  and H Zha. Shaping social activity by

incentivizing users. NIPS  2014.

[9] J Leskovec  L Backstrom  and J Kleinberg. Meme-tracking and the dynamics of the news cycle.

SIGKDD  2009.

[10] SH Yang and H Zha. Mixture of mutually exciting processes for viral diffusion. ICML  2013.
[11] D Kempe  J Kleinberg  and E Tardos. Maximizing the spread of inﬂuence through a social network.

SIGKDD  2003.

[12] FB Hanson. Applied stochastic processes and control for Jump-diffusions: modeling  analysis  and

computation  volume 13. Siam  2007.

[13] A De  I Valera  N Ganguly  S Bhattacharya  and M Gomez Rodriguez. Modeling opinion dynamics in

diffusion networks. arXiv:1506.05474  2015.

[14] Y Wang  E Theodorou  A Verma  and L Song. Steering opinion dynamics in information diffusion

networks. arXiv:1603.09021  2016.

[15] D Bloembergen  B Ranjbar Sahraei  H Bou-Ammar  K Tuyls  and G Weiss. Inﬂuencing social networks:

An optimal control study. In ECAI  2014.

[16] K Kandhway and J Kuri. Campaigning in heterogeneous social networks: Optimal control of si infor-

mation epidemics. 2015.

[17] Pin-Yu Chen  Shin-Ming Cheng  and Kwang-Cheng Chen. Optimal control of epidemic information

dissemination over networks. Cybernetics  IEEE Transactions on  2014.

[18] W Lian  R Henao  V Rao  J Lucas  and L Carin. A multitask point process predictive model. ICML 

2015.

[19] AP Parikh  A Gunawardana  and C Meek. Conjoint modeling of temporal dependencies in event streams.

UAI  2012.

[20] PO Perry and PJ Wolfe. Point process modeling for directed interaction networks. Journal of the Royal

Statistical Society  2013.

[21] SW Linderman and RP Adams. Discovering latent network structure in point process data. ICML  2014.
[22] C Blundell  J Beck  and KA Heller. Modelling reciprocating relationships with hawkes processes. NIPS 

2012.

[23] T Iwata  A Shah  and Z Ghahramani. Discovering latent inﬂuence in online social activities via shared

cascade poisson processes. SIGKDD  2013.

[24] O Hijab. Introduction to calculus and classical analysis. Springer  2007.
[25] GB Folland. Real analysis: modern techniques and their applications. John Wiley & Sons  2013.
[26] R Bracewell. The fourier transform and iis applications. New York  5  1965.
[27] AH Al-Mohy and MJ Higham. Computing the action of the matrix exponential  with an application to

exponential integrators. SIAM journal on scientiﬁc computing  2011.

9

,Mehrdad Farajtabar
Xiaojing Ye
Sahar Harati
Le Song
Hongyuan Zha