2018,Critical initialisation for deep signal propagation in noisy rectifier neural networks,Stochastic regularisation is an important weapon in the arsenal of a deep learning practitioner. However  despite recent theoretical advances  our understanding of how noise influences signal propagation in deep neural networks remains limited. By extending recent work based on mean field theory  we develop a new framework for signal propagation in stochastic regularised neural networks. Our \textit{noisy signal propagation} theory can incorporate several common noise distributions  including additive and multiplicative Gaussian noise as well as dropout. We use this framework to investigate initialisation strategies for noisy ReLU networks. We show that no critical initialisation strategy exists using additive noise  with signal propagation exploding regardless of the selected noise distribution. For multiplicative noise (e.g.\ dropout)  we identify alternative critical initialisation strategies that depend on the second moment of the noise distribution.  Simulations and experiments on real-world data confirm that our proposed initialisation is able to stably propagate signals in deep networks  while using an initialisation disregarding noise fails to do so. Furthermore  we analyse correlation dynamics between inputs. Stronger noise regularisation is shown to reduce the depth to which discriminatory information about the inputs to a noisy ReLU network is able to propagate  even when initialised at criticality. We support our theoretical predictions for these trainable depths with simulations  as well as with experiments on MNIST and CIFAR-10.,Critical initialisation for deep signal propagation in

noisy rectiﬁer neural networks

Arnu Pretorius∗

Computer Science Division

CAIR†

Stellenbosch University

Elan Van Biljon

Computer Science Division

Stellenbosch University

Steve Kroon

Computer Science Division

Stellenbosch University

Herman Kamper

Department of Electrical and Electronic Engineering

Stellenbosch University

Abstract

Stochastic regularisation is an important weapon in the arsenal of a deep learning
practitioner. However  despite recent theoretical advances  our understanding of
how noise inﬂuences signal propagation in deep neural networks remains limited.
By extending recent work based on mean ﬁeld theory  we develop a new framework
for signal propagation in stochastic regularised neural networks. Our noisy signal
propagation theory can incorporate several common noise distributions  including
additive and multiplicative Gaussian noise as well as dropout. We use this frame-
work to investigate initialisation strategies for noisy ReLU networks. We show that
no critical initialisation strategy exists using additive noise  with signal propagation
exploding regardless of the selected noise distribution. For multiplicative noise
(e.g. dropout)  we identify alternative critical initialisation strategies that depend
on the second moment of the noise distribution. Simulations and experiments on
real-world data conﬁrm that our proposed initialisation is able to stably propagate
signals in deep networks  while using an initialisation disregarding noise fails to do
so. Furthermore  we analyse correlation dynamics between inputs. Stronger noise
regularisation is shown to reduce the depth to which discriminatory information
about the inputs to a noisy ReLU network is able to propagate  even when initialised
at criticality. We support our theoretical predictions for these trainable depths with
simulations  as well as with experiments on MNIST and CIFAR-10.‡

1

Introduction

Over the last few years  advances in network design strategies have made it easier to train large
networks and have helped to reduce overﬁtting. These advances include improved weight initialisation
strategies (Glorot and Bengio  2010; Saxe et al.  2014; Sussillo and Abbott  2014; He et al.  2015;
Mishkin and Matas  2016)  non-saturating activation functions (Glorot et al.  2011) and stochastic
regularisation techniques (Srivastava et al.  2014). Authors have noted  for instance  the critical
dependence of successful training on noise-based methods such as dropout (Krizhevsky et al.  2012;
Dahl et al.  2013).

∗Correspondence: arnupretorius@gmail.com
†CSIR/SU Centre for Artiﬁcial Intelligence Research.
‡Code to reproduce all the results is available at https://github.com/ElanVB/noisy_signal_prop

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

Figure 1: Noisy layer recursion. The input xl−1 from the previous layer gets corrupted by the sampled
noise l−1  either by vector addition or component-wise multiplication  producing the noisy inputs
˜xl−1. The lth layer’s corrupted pre-activations are then computed by multiplication with the layer
weight matrix W l  followed by a vector addition of the biases bl. Finally  the inputs to the next layer
are simply the activations of the current layer  i.e. xl = φ(˜hl).

In many cases  successful results arise only from effective combination of these advances. Despite
this interdependence  our theoretical understanding of how these mechanisms and their interactions
affect neural networks remains impoverished.
One approach to studying these effects is through the lens of deep neural signal propagation. By
modelling the empirical input variance dynamics at the point of random initialisation  Saxe et al.
(2014) were able to derive equations capable of describing how signal propagates in nonlinear fully
connected feed-forward neural networks. This “mean ﬁeld” theory was subsequently extended by
Poole et al. (2016) and Schoenholz et al. (2017)  in particular  to analyse signal correlation dynamics.
These analyses highlighted the existence of a critical boundary at initialisation  referred to as the “edge
of chaos”. This boundary deﬁnes a transition between ordered (vanishing)  and chaotic (exploding)
regimes for neural signal propagation. Subsequently  the mean ﬁeld approximation to random neural
networks has been employed to analyse other popular neural architectures (Yang and Schoenholz 
2017; Xiao et al.  2018; Chen et al.  2018).
This paper focuses on the effect of noise on signal propagation in deep neural networks. Firstly we
ask: How is signal propagation in deep neural networks affected by noise? To gain some insight into
this question  we extend the mean ﬁeld theory developed by Schoenholz et al. (2017) for the special
case of dropout noise  into a generalised framework capable of describing the signal propagation
behaviour of stochastically regularised neural networks for different noise distributions.
Secondly we ask: How much are current weight initialisation strategies affected by noise-induced
regularisation in terms of their ability to initialise at a critical point for stable signal propagation?
Using our derived theory  we investigate this question speciﬁcally for rectiﬁed linear unit (ReLU)
networks. In particular  we show that no such critical initialisation exists for arbitrary zero-mean
additive noise distributions. However  for multiplicative noise  such an initialisation is shown to be
possible  given that it takes into account the amount of noise being injected into the network. Using
these insights  we derive novel critical initialisation strategies for several different multiplicative
noise distributions.
Finally  we ask: Given that a network is initialised at criticality  in what way does noise inﬂuence
the network’s ability to propagate useful information about its inputs? By analysing the correlation
between inputs as a function of depth in random deep ReLU networks  we highlight the following:
even though the statistics of individual inputs are able to propagate arbitrarily deep at criticality 
discriminatory information about the inputs becomes lost at shallower depths as the noise in the
network is increased. This is because in the later layers of a random noisy network  the internal
representations from different inputs become uniformly correlated. Therefore  the application of
noise regularisation directly limits the trainable depth of critically initialised ReLU networks.

2 Noisy signal propagation

We begin by presenting mean ﬁeld equations for stochastically regularised fully connected feed-
forward neural networks  allowing us to study noisy signal propagation for a variety of noise
distributions. To understand how noise inﬂuences signal propagation in a random network given an
input x0 ∈ RD0  we inject noise into the model

˜hl = W l(xl−1 (cid:12) l−1) + bl  spa for l = 1  ...  L

(1)

2

˜xl−1xl−1l−1Wlbl˜hlxl(cid:12)+×φw/Dl−1 and σ2

using the operator (cid:12) to denote either addition or multiplication where l is an input noise vector 
sampled from a pre-speciﬁed noise distribution. For additive noise  the distribution is assumed to be
zero mean  for multiplicative noise distributions  the mean is assumed to be equal to one. The weights
W l ∈ RDl×Dl−1 and biases bl ∈ RDl are sampled i.i.d. from zero mean Gaussian distributions
with variances σ2
b   respectively  where Dl denotes the dimensionality of the lth hidden
layer in the network. The hidden layer activations xl = φ(˜hl) are computed element-wise using
an activation function φ(·)  for layers l = 1  ...  L. Figure 1 illustrates this recursive sequence of
operations.
To describe forward signal propagation for the model in (1)  we make use of the mean ﬁeld approxi-
mation as in Poole et al. (2016) and analyse the statistics of the internal representations of the network
in expectation over the parameters and the noise. Since the weights and biases are sampled from zero
mean Gaussian distributions with pre-speciﬁed variances  we can approximate the distribution of the
pre-activations at layer l  in the large width limit  by a zero mean Gaussian with variance

(cid:26)

(cid:20)

(cid:16)(cid:112)

(cid:17)2(cid:21)

(cid:27)

˜ql = σ2
w

Ez

φ

˜ql−1z

(cid:12) µl−1

2

+ σ2
b  

(2)

where z ∼ N (0  1) (see Section A.1 in the supplementary material). Here  µl
2 = E[(l)2] is the
second moment of the noise distribution being sampled from at layer l. The initial input variance is
x0 · x0. Furthermore  to study the behaviour of a pair of signals from two different
given by q0 = 1
D0
inputs  x0 a and x0 b  passing through the network  we can compute the covariance at each layer as

(cid:112)

where ˜u1 =

˜ql−1
aa z1 and ˜u2 =

ab = σ2
˜ql
w
˜ql−1

(cid:113)
(cid:113)

bb

(cid:104)

Ez1 [Ez2 [φ(˜u1)φ(˜u2)]] + σ2

˜cl−1z1 +(cid:112)1 − (˜cl−1)2z2

b

(cid:105)

(3)

  with the correlation between

ab/

bb. Here  ql

aa is the variance of ˜hl a

inputs at layer l given by ˜cl = ˜ql
aa ˜ql
˜ql
supplementary material for more details).
For the backward pass  we use the equations derived in Schoenholz et al. (2017) to describe error
signal propagation.1 In the context of mean ﬁeld theory  the expected magnitude of the gradient at
each layer can be shown to be proportional to the variance of the error  ˜δl
˜δl+1
j W l+1
.
This allows for the distribution of the error signal at layer l to be approximated by a zero mean
Gaussian with variance

i)(cid:80)Dl+1

(see Section A.2 in the

i = φ(cid:48)(˜hl

j=1

ji

j

(cid:20)
φ(cid:48)(cid:16)(cid:112)

(cid:17)2(cid:21)

δ = ˜ql+1
˜ql

δ

Dl+1
Dl

Ez

σ2
w

˜qlz

.

(4)

Similarly  for noise regularised networks  the covariance between error signals can be shown to be

ab δ = ˜ql+1
˜ql
ab δ

Dl+1
Dl+2

Ez1 [Ez2 [φ(cid:48)(˜u1)φ(cid:48)(˜u2)]]  

σ2
w

(5)

where ˜u1 and ˜u2 are deﬁned as was done in the forward pass.
Equations (2)-(5) fully capture the relevant statistics that govern signal propagation for a random
network during both the forward and the backward pass. In the remainder of this paper  we consider 
as was done by Schoenholz et al. (2017)  the following necessary condition for training: “for a
random network to be trained information about the inputs should be able to propagate forward
through the network  and information about the gradients should be able to propagate backwards
through the network.” The behaviour of the network at this stage depends on the choice of activation 
noise regulariser and initial parameters. In the following section  we will focus on networks that use
the Rectiﬁed Linear Unit (ReLU) as activation function. The chosen noise regulariser is considered a
design choice left to the practitioner. Therefore  whether a random noisy ReLU network satisﬁes the
above stated necessary condition for training largely depends on the starting parameter values of the
network  i.e. its initialisation.

1It is  however  important to note that the derivation relies on the assumption that the weights used in the

forward pass are sampled independently from those used during backpropagation.

3

Figure 2: Deep signal propagation with and without noise. (a): Iterative variance map. (b): Variance
dynamics during forward signal propagation. In (a) and (b)  lines correspond to theoretical predictions
and points to numerical simulations (means over 50 runs with shaded one standard deviation bounds) 
for noiseless tanh (yellow) and noiseless ReLU (purple) networks  as well as for noisy tanh (red)
and noisy ReLU (brown) networks regularised using additive noise from a standard Gaussian. Both
√
tanh networks use (σw  σb) = (1  0)  the “Xavier” initialisation (Glorot and Bengio  2010)  while the
ReLU networks use (σw  σb) = (
2  0) the “He” initialisation (He et al.  2015). In our experiments 
we use network layers consisting of 1000 hidden units (see Section C in the supplementary material
for more details on all our simulated experiments).

3 Critical initialisation for noisy rectiﬁer networks

Unlike the tanh nonlinearity investigated in previous work (Poole et al.  2016; Schoenholz et al. 
2017)  rectifying activation functions such as ReLU are unbounded. This means that the statistics of
signal propagation through the network is not guaranteed to naturally stabilise through saturating
activations  as shown in Figure 2.
A point on the identity line in Figure 2 (a) represents a ﬁxed point to the recursive variance map
in equation (2). At a ﬁxed point  signal will stably propagate through the remaining layers of the
network. For tanh networks  such a ﬁxed point always exists irrespective of the initialisation  or
the amount of noise injected into the network. For ReLU networks  this is not the case. Consider
the “He” initialisation (He et al.  2015) for ReLU  commonly used in practice. In (b)  we plot the
variance dynamics for this initialisation in purple and observe stable behaviour. But what happens
when we inject noise into each network? In the case of tanh (shown in red)  the added noise simply
shifts the ﬁxed point to a new stable value. However  for ReLU  the noise entirely destroys the ﬁxed
point for the “He” initialisation  making signal propagation unstable. This can be seen in (a)  where
the variance map for noisy ReLU (shown in brown) moves off the identity line entirely  causing the
signal in (b) to explode.
Therefore  to investigate whether signal can stably propagate through a random noisy ReLU network 
we examine (2) more closely  which for ReLU becomes (see Section B.1 in supplementary material)

(cid:20) ˜ql−1

2

(cid:21)

(cid:12) µ2

+ σ2
b .

˜ql = σ2
w

(6)
2 = µ2 ∀l. A critical
For ease of exposition we assume equal noise levels at each layer  i.e. µl
initialisation for a noisy ReLU network occurs when the tuple (σw  σb  µ2) provides a ﬁxed point ˜q∗ 
to the recurrence in (6). This at least ensures that the statistics of individual inputs to the network will
be preserved throughout the ﬁrst forward pass. The existence of such a solution depends on the type
2 ˜q∗ + µ2σ2
of noise that is injected into the network. In the case of additive noise  ˜q∗ = σ2
√
b  
w + σ2
implying that the only critical point initialisation for non-zero ˜q∗ is given by (σw  σb  µ2) = (
2  0  0).
Therefore  critical initialisation is not possible using any amount of zero-mean additive noise 
regardless of the noise distribution. For multiplicative noise  ˜q∗ = σ2
b   so the solution
provides a critical initialisation for noise distributions with mean
(σw  σb  µ2) =
one and a non-zero second moment µ2. For example  in the case of multiplicative Gaussian noise 
. For dropout noise 
µ2 = σ2

 + 1  yielding critical initialisation with (σw  σb) =

(cid:16)(cid:113) 2

(cid:16)(cid:113) 2

1

2 ˜q∗µ2 + σ2

w

  0  µ2

µ2

(cid:17)

1

w

(cid:17)

σ2+1   0

4

02468101214Inputvariance(ql−1)02468101214Outputvariance(ql)IterativevariancemapIdentitylinetanh-Nonetanh-AddGauss(σ2=1)ReLU-NoneReLU-AddGauss(σ2=1)02468101214Layer(l)02468101214Variance(ql)Dynamicsofq(a)(b)Table 1: Critical point initialisation for noisy ReLU networks.

DISTRIBUTION
— ADDITIVE NOISE —
GAUSSIAN

LAPLACE

— MULTIPLICATIVE NOISE —

GAUSSIAN

LAPLACE

POISSON

DROPOUT

P()

N (0  σ2
 )

Lap(0  β)

N (1  σ2
 )

µ2

σ2


2β2

(σ2

 + 1)

CRITICAL INITIALISATION

√
(σw  σb  σ) = (
√
(σw  σb  β) = (
2  0  0)

2  0  0)

(σw  σb  σ) =

 +1   0  σ
σ2

(cid:16)(cid:113) 2
(cid:16)(cid:113) 2

(cid:17)
(cid:17)

Lap(1  β)

(2β2 + 1)

(σw  σb  β) =

2β2+1   0  β

P oi(1)

P( = 1
P( = 0) = 1 − p

p ) = p 

2

1
p

(σw  σb  λ) = (1  0  1)

√
(σw  σb  p) = (
2p  0  p)

Figure 3: Critical initialisation for noisy ReLU networks. (a): Iterative variance map. (b): Vari-
ance dynamics during forward signal propagation. In (a) and (b)  lines correspond to theoretical
predictions and points to numerical simulations. Dropout (p = 0.6) is shown in green for dif-
ferent initialisations  σ2
(exploding sig-
w = 2(0.6) = 2
µ2
(vanishing signal). Similarly  multiplicative Gaussian noise
nal) and σ2
(0.6)−1 < 2
w = (0.85)2
µ2
(σ = 0.25) is shown in red with σ2
(exploding) and
w =
( vanishing). (c): Variance critical boundary for initialisation  separating numerical
w = (0.75)2 2
σ2
µ2
overﬂow and underﬂow signal propagation regimes.

w = (1.25)2 2
µ2

(0.25)2+1 = 2
µ2

(0.6)−1 > 2
µ2

w = (1.15)2

(critical)  σ2

2

2

(critical)  σ2

2

√
µ2 = 1/p (with p the probability of retaining a neuron); thus  to initialise at criticality  we must
set (σw  σb) = (
2p  0). Table 1 summarises critical initialisations for some commonly used
noise distributions. We also note that similar results can be derived for other rectifying activation
functions; for example  for multiplicative noise the critical initialisation for parametric ReLU (PReLU)
activations (with slope parameter α) is given by (σw  σb  µ2) =

(cid:16)(cid:113) 2

(cid:17)

.

µ2(α2+1)   0  µ2

To see the effect of initialising on or off the critical point for ReLU networks  Figure 3 compares
the predicted versus simulated variance dynamics for different initialisation schemes. For schemes
not initialising at criticality  the variance map in (a) no longer lies on the identity line and as a result
the forward propagating signal in (b) either explodes  or vanishes. In contrast  the initialisations
derived above lie on the critical boundary between these two extremes  as shown in (c) as a function
of the noise. By compensating for the amount of injected noise  the signal corresponding to the
initialisation σ2
is preserved in (b) throughout the entire forward pass  with roughly constant
variance dynamics.

w = 2
µ2

5

051015Inputvariance(ql−1)0.02.55.07.510.012.515.0Outputvariance(ql)σ2w>2µ2σ2w<2µ2σ2w=2µ2Iterativevariancemap051015Layer(l)0.02.55.07.510.012.515.0Variance(ql)DynamicsofqMultGaussdropout1.01.21.41.61.82.0Weightinitialisation(σ2w)1.01.21.41.61.82.0Secondmomentofnoisedist.(µ2)Overﬂow(σ2w>2µ2)Underﬂow(σ2w<2µ2)σ2w=2µ2VariancepropagationdynamicsVariancecriticalboundary(a)(b)(c)Figure 4: Propagating correlation information in noisy ReLU networks. (a): Iterative correlation
map with ﬁxed points indicated by “X” marks on the identity line. (b): Correlation dynamics during
forward signal propagation. In (a) and (b)  lines correspond to theoretical predictions and points to
numerical simulations. All simulated networks were initialised at criticality for each noise type and
level. (c): Slope at the ﬁxed point correlation as a function of the amount of noise injected into the
network.

Next  we investigate the correlation dynamics between inputs. Assuming that (6) is at its ﬁxed point
˜q∗  which exists only if σ2
  the correlation map for a noisy ReLU network is given by (see
Section B.2 in supplementary material)

w = 2
µ2

(cid:40)

˜cl−1sin−1(cid:0)˜cl−1(cid:1) +(cid:112)1 − (˜cl−1)2

.

(7)

(cid:41)

˜cl−1
2

+

˜cl =

1
µ2

π

Figure 4 plots this theoretical correlation map against simulated dynamics for different noise types
and levels. For no noise  the ﬁxed point c∗ in (a) is situated at one (marked with an “X” on the blue
line). The slope of the blue line indicates a non-decreasing function of the input correlations. After a
certain depth  inputs end up perfectly correlated irrespective of their starting correlation  as shown in
(b). In other words  random deep ReLU networks lose discriminatory information about their inputs
as the depth of the network increases  even when initialised at criticality. When noise is added to the
network  inputs decorrelate and c∗ moves away from one. However  more importantly  correlation
information in the inputs become lost at shallower depths as the noise level increases  as can be seen
in (b).
How quickly a random network loses information about its inputs depends on the rate of convergence
to the ﬁxed point c∗. Using this observation  Schoenholz et al. (2017) derived so-called depth scales
ξc  by assuming |cl − c∗| ∼ e−l/ξc. These scales essentially control the feasible depth at which
networks can be considered trainable  since they may still allow useful correlation information to
propagate through the network. In our case  the depth scale for a noisy ReLU network under this
assumption can be shown to be (see Section B.3 in supplementary material)

where

χ(c∗) =

1
µ2π

ξc = −1/ln [χ(c∗)]  

(cid:104)

sin−1 (c∗) +

(cid:105)

.

π
2

(8)

(9)

The exponential rate assumption underlying the derivation of (8) is supported in Figure 5  where
for different noise types and levels  we plot |cl − c∗| as a function of depth on a log-scale  with
corresponding linear ﬁts (see panels (a) and (c)). We then compare the theoretical depth scales from
(8) to actual depth scales obtained through simulation (panels (b) and (d))  as a function of noise
and observe a good ﬁt for non-zero noise levels.4 We thus ﬁnd that noise limits the depth at which
critically initialised ReLU networks are expected to perform well through training.

4We note Hayou et al. (2018) recently showed that the rate of convergence for noiseless ReLU networks is
not exponential  but polynomial instead. Interestingly  keeping with the exponential rate assumption  we indeed
ﬁnd that the discrepancy between our theoretical depth scales from (8) and our simulated depth scales  is largest
at very low noise levels. However  at more typical noise levels  such as a dropout rate of p = 0.5 for example 
the assumption seems to provide a close ﬁt  with good agreement between theory and simulation.

6

0.00.51.0Inputcorrelation(cl−1)0.00.51.0Outputcorrelation(cl)Iterativecorrelationmapnonedropout(p=0.6)dropout(p=0.8)MultGauss(σ=0.25)MultGauss(σ=2)0102030Layer(l)0.00.51.0Correlation(cl)Dynamicsofc246810Secondmomentofnoisedistribution(µ2)0.00.20.40.60.81.0Slopeatﬁxedpoint(χ(c∗))Orderedregime(vanishinggradients)PhasediagramNoisecriticalinitialisationEdgeofchaos(a)(b)(c)Figure 5: Noise dependent depth scales for training. (a): Linear ﬁts (dashed lines) to |cl − c∗| as a
function of depth on a log-scale (solid lines) for varying amounts of dropout (p = 0.1 to p = 0.9
by 0.1). (b): Theoretical depth scales (solid lines) versus empirically inferred scales (dashed lines)
per dropout rate. Scales are inferred noting that if |cl − c∗| ∼ e−l/ξc  then a linear ﬁt  al + b  in
the logarithmic domain gives ξc ≈ − 1
a  for large l. In other words  the negative inverse slope of a
linear ﬁt to the log differences in correlation should match the theoretical values for ξc. Therefore 
we compare ξc = −1/ln [χ(c∗)] to − 1
a for different levels of noise. (c) - (d): Similar to (a) and (b) 
but for Gaussian noise (σ = 0.1 to σ = 1.9 by 0.15).

We next brieﬂy discuss error signal propagation during the backward pass for noise regularised ReLU
networks. When critically initialised  the error variance recurrence relation in (4) for these networks
is (see Section B.4 in supplementary material)

δ = ˜ql+1
˜ql

δ

Dl+1
Dlµ2

 

(10)

with the covariance between error signals in (5)  given by (see Section B.5 in supplementary material)

ab δ = ˜ql+1
˜ql
ab δ

χ(c∗).

Dl+1
Dl+2

(11)

Note the explicit dependence on the width of the layers of the network in (10) and (11). We ﬁrst
consider constant width networks  where Dl+1 = Dl  for all l = 1  ...  L. For any amount of
multiplicative noise  µ2 > 1  and we see from (10) that gradients will tend to vanish for large depths.
Furthermore  Figure 4 (c) plots χ(c∗) as a function of µ2. As µ2 increases from one  χ(c∗) decreases
from one. Therefore  from (11)  we also ﬁnd that error signals from different inputs will tend to
decorrelate at large depths.
Interestingly  for non-constant width networks  stable gradient information propagation may still be
possible. If the network architecture adapts to the amount of noise being injected by having the widths
of the layers grow as Dl+1 = Dlµ2  then (10) should be at its ﬁxed point solution. For example  in
the case of dropout Dl+1 = Dl/p  which implies that for any p < 1  each successive layer in the
network needs to grow in width by a factor of 1/p to promote stable gradient ﬂow. Similarly  for
multiplicative Gaussian noise  Dl+1 = Dl(σ2
 + 1)  which requires the network to grow in width
 = 0. Similarly  if Dl+2 = Dl+1χ(c∗) = Dlµ2χ(c∗) in (11)  the covariance of the error
unless σ2
signal should be preserved during the backward pass  for arbitrary values of µ2 and χ(c∗).

7

05101520253010−1510−1210−910−610−3100|cl−c∗|RateofconvergencetoﬁxedpointSimulationLinearﬁt2468100.51.01.52.0ξcTwoinputdepthscalesTheorySimulation051015202530Layer(l)10−1610−1310−1010−710−410−1|cl−c∗|SimulationLinearﬁt1.01.52.02.53.03.54.04.5µ2123456ξcTheorySimulation(a)(b)(c)(d)Figure 6: Depth scale experiments on MNIST and CIFAR-10. (a) Variance propagation dynamics for
MNIST on and off the critical point initialisation (dashed black line) with dropout (p = 0.6). The
cyan curve represents the theoretical boundary at which numerical instability issues are predicted
to occur and is computed as L∗ = ln(K)/ln( σ2
2 µ2)  where K is the largest (or smallest) positive
number representable by the computer. Speciﬁcally  we use 32-bit ﬂoating point numbers and set
K = 3.4028235 × 1038  if σ2
. (b) Depth scales ﬁt
to the training loss on MNIST for networks initialised at criticality for dropout rates p = 0.1 (severe
dropout) to p = 1 (no dropout). (c) Depth scales ﬁt to the validation loss on MNIST. (d) - (f): Similar
to (a) - (c)  but for CIFAR-10. For each plot we highlight trends by smoothing the colour grid (for
non smoothed versions see Section C.5 in the supplementary material).

and K = 1.1754944 × 10−38  if σ2

w > 2
µ2

w < 2
µ2

w

4 Experimental results

From our analysis of deep noisy ReLU networks in the previous section  we expect that a necessary
condition for such a network to be trainable  is that the network be initialised at criticality. However 
whether the layer widths are varied or not for the sake of backpropagation  the correlation dynamics
in the forward pass may still limit the depth at which these networks perform well.
We therefore investigate the performance of noise-regularised deep ReLU networks on real-world
data. First  we validate the derived critical initialisation. As the depth of the network increases  any
initialisation strategy that does not factor in the effects of noise  will cause the forward propagating
signal to become increasingly unstable. For very deep networks  this might cause the signal to either
explode or vanish  even within the ﬁrst forward pass  making the network untrainable. To test this 
we sent inputs from MNIST and CIFAR-10 through ReLU networks using dropout (with p = 0.6) at
varying depths and for different initialisations of the network. Figure 6 (a) and (d) shows the evolution
of the input statistics as the input propagates through each network for the different data sets. For
initialisations not at criticality  the variance grows or shrinks rapidly to the point of causing numerical
overﬂow or underﬂow (indicated by black regions). For deep networks  this can happen well before
any signal is able to reach the output layer. In contrast  initialising at criticality (as shown by the
dashed black line)  allows for the signal to propagate reliably even at very large depths. Furthermore 
  we can predict the depth at which numerical overﬂow
given the ﬂoating point precision  if σ2
q0  where K is the largest (or
smallest) positive number representable by the computer (see Section C.4 in supplementary material).
These predictions are shown by the cyan line and provide a good ﬁt to the empirical limiting depth
from numerical instability.
We now turn to the issue of limited trainability. Due to the loss of correlation information between
inputs as a function of noise and network depth  we expect noisy ReLU networks not to be able to
perform well beyond certain depths. We investigated depth scales for ReLU networks with dropout
initialised at criticality: we trained 100 networks on MNIST and CIFAR-10 for 200 epochs using SGD
and a learning rate of 10−3 with dropout rates ranging from 0.1 to 1 for varying depths. The results

(or underﬂow) will occur by solving for L∗ in K = (cid:0)σ2

wµ2/2(cid:1)L∗

w (cid:54)= 2

µ2

8

0.30.60.91.21.51.82.1Weightinitialisation(σ2w)02004006008001000NumberoflayersUnderﬂowOverﬂowMNIST-Variancepropagationdepth:dropoutwithp=0.6 crit.init.atσ2w=1.2Theorycriticality0.51.01.52.0Criticalinitialisationforp(σ2w)10203040NumberoflayersMNIST-Depthatcriticality0.51.01.52.0Criticalinitialisationforp(σ2w)10203040NumberoflayersMNIST-Depthatcriticality0.30.60.91.21.51.82.1Weightinitialisation(σ2w)02004006008001000NumberoflayersUnderﬂowOverﬂowCIFAR-10-Variancepropagationdepth:dropoutwithp=0.6 crit.init.atσ2w=1.2Theorycriticality0.51.01.52.0Criticalinitialisationforp(σ2w)10203040NumberoflayersCIFAR-10-Depthatcriticality0.51.01.52.0Criticalinitialisationforp(σ2w)10203040NumberoflayersCIFAR-10-Depthatcriticality−80−60−40−20020406080log(ql)0.070.080.090.100.11Trainloss0.10.20.30.40.50.60.70.80.91.0p0.070.080.090.100.11Val.loss0.10.20.30.40.50.60.70.80.91.0p−80−60−40−20020406080log(ql)0.0500.0750.1000.1250.1500.1750.2000.2250.250Trainloss0.10.20.30.40.50.60.70.80.91.0p0.0500.0750.1000.1250.1500.1750.2000.2250.250Val.loss0.10.20.30.40.50.60.70.80.91.0p(a)(b)(c)(d)(e)(f)are shown in Figure 6 (see Section C.5 of the supplementary material for additional experimental
results). For each network conﬁguration and noise level  the critical initialisation σ2
was
used. We indeed observe a relationship between depth and noise on the loss of a network  even at
criticality. Interestingly  the line 6ξc (Schoenholz et al.  2017)  seems to track the depth beyond
which the relative performance on the validation loss becomes poor  more so than on the training loss.
However  in both cases  we ﬁnd that even modest amounts of noise can limit performance.

w = 2
µ2

5 Discussion

By developing a general framework to study signal propagation in noisy neural networks  we were
able to show how different stochastic regularisation strategies may impact the ﬂow of information
in a deep network. Focusing speciﬁcally on ReLU networks  we derived novel critical initialisation
strategies for multiplicative noise distributions and showed that no such critical initialisations exist
for commonly used additive noise distributions. At criticality however  our theory predicts that the
statistics of the input should remain within a stable range during the forward pass and enable reliable
signal propagation for noise regularised deep ReLU networks. We veriﬁed these predictions by
comparing them with numerical simulations as well as experiments on MNIST and CIFAR-10 using
dropout and found good agreement.
Interestingly  we note that a dropout rate of p = 0.5 has often been found to work well for ReLU
√
networks (Srivastava et al.  2014). The critical initialisation corresponding to this rate is (σw  σb) =
2p  0) = (1  0). This is exactly the “Xavier” initialisation proposed by Glorot and Bengio (2010) 
(
which prior to the development of the “He” initialisation  was often used in combination with
dropout (Simonyan and Zisserman  2014). This could therefore help to explain the initial success
associated with this speciﬁc dropout rate. Similarly  Srivastava et al. (2014) reported that adding
multiplicative Gaussian noise where  ∼ N (1  σ2
 = 1  also seemed to perform well  for
= (1  0)  again corresponding to the “Xavier” method.
which the critical initialisation is

(cid:16)(cid:113) 2

 )  with σ2

(cid:17)

 +1   0
σ2

Although our initialisations ensure that individual input statistics are preserved  we further analysed
the correlation dynamics between inputs and found the following: at large depths inputs become
predictably correlated with each other based on the amount of noise injected into the network. As a
consequence  the representations for different inputs to a deep network may become indistinguishable
from each other in the later layers of the network. This can make training infeasible for noisy ReLU
networks of a certain depth and depends on the amount of noise regularisation being applied.
We now note the following shortcomings of our work: ﬁrstly  our ﬁndings only apply to fully
connected feed-forward neural networks and focus almost exclusively on the ReLU activation
function. Furthermore  we limit the scope of our architectural design to a recursive application of a
dense layer followed by a noise layer  whereas in practice a larger mix of layers is usually required to
solve a speciﬁc task.
Ultimately  we are interested in reducing the number of decisions that need to made when designing
deep neural networks and understanding the implications of those decisions on network behaviour
and performance. Any machine learning engineer exploring a neural network based solution to a
practical problem will be faced with a large number of possible design decisions. All these decisions
cost valuable time to explore. In this work  we hope to have at least provided some guidance in this
regard  speciﬁcally when choosing between different initialisation strategies for noise regularised
ReLU networks and understanding their associated implications.

Acknowledgements

We would like to thank the reviewers for their insightful comments which improved the quality of this
work. Furthermore  we would like to thank Google  the CSIR/SU Centre for Artiﬁcial Intelligence
Research (CAIR) as well as the Science Faculty and the Postgraduate and International Ofﬁce of
Stellenbosch University for ﬁnancial support. Finally  we gratefully acknowledge the support of
NVIDIA Corporation with the donation of a Titan Xp GPU used for this research.

9

References
X. Glorot and Y. Bengio  “Understanding the difﬁculty of training deep feedforward neural networks ”
in Proceedings of the International Conference on Artiﬁcial Intelligence and Statistics  2010  pp.
249–256.

A. M. Saxe  J. L. McClelland  and S. Ganguli  “Exact solutions to the nonlinear dynamics of
learning in deep linear neural networks ” Proceedings of the International Conference on Learning
Representations  2014.

D. Sussillo and L. Abbott  “Random walk initialization for training very deep feedforward networks ”

arXiv preprint arXiv:1412.6558  2014.

K. He  X. Zhang  S. Ren  and J. Sun  “Delving deep into rectiﬁers: Surpassing human-level per-
formance on ImageNet classiﬁcation ” in Proceedings of the IEEE International Conference on
Computer Vision  2015  pp. 1026–1034.

D. Mishkin and J. Matas  “All you need is a good init ” Proceedings of International Conference on

Learning Representations  2016.

X. Glorot  A. Bordes  and Y. Bengio  “Deep sparse rectiﬁer neural networks ” in Proceedings of the

International Conference on Artiﬁcial Intelligence and Statistics  2011  pp. 315–323.

N. Srivastava  G. E. Hinton  A. Krizhevsky  I. Sutskever  and R. Salakhutdinov  “Dropout: a simple
way to prevent neural networks from overﬁtting.” Journal of Machine Learning Research  vol. 15 
no. 1  pp. 1929–1958  2014.

A. Krizhevsky  I. Sutskever  and G. E. Hinton  “ImageNet classiﬁcation with deep convolutional
neural networks ” in Advances in Neural Information Processing Systems  2012  pp. 1097–1105.

G. E. Dahl  T. N. Sainath  and G. E. Hinton  “Improving deep neural networks for LVCSR using
rectiﬁed linear units and dropout ” in Proceedings of the IEEE International Conference on
Acoustics  Speech and Signal Processing  2013  pp. 8609–8613.

B. Poole  S. Lahiri  M. Raghu  J. Sohl-Dickstein  and S. Ganguli  “Exponential expressivity in deep
neural networks through transient chaos ” in Advances in Neural Information Processing Systems 
2016  pp. 3360–3368.

S. S. Schoenholz  J. Gilmer  S. Ganguli  and J. Sohl-Dickstein  “Deep information propagation ”

Proceedings of the International Conference on Learning Representations  2017.

G. Yang and S. Schoenholz  “Mean ﬁeld residual networks: On the edge of chaos ” in Advances in

Neural Information Processing Systems  2017  pp. 7103–7114.

L. Xiao  Y. Bahri  J. Sohl-Dickstein  S. S. Schoenholz  and J. Pennington  “Dynamical isometry and
a mean ﬁeld theory of CNNs: How to train 10 000-layer vanilla convolutional neural networks ”
Proceedings of the International Conference on Machine Learning  2018.

M. Chen  J. Pennington  and S. S. Schoenholz  “Dynamical isometry and a mean ﬁeld theory of RNNs:
Gating enables signal propagation in recurrent neural networks ” Proceedings of the International
Conference on Machine Learning  2018.

S. Hayou  A. Doucet  and J. Rousseau  “On the selection of initialization and activation function for

deep neural networks ” arXiv preprint arXiv:1805.08266  2018.

K. Simonyan and A. Zisserman  “Very deep convolutional networks for large-scale image recognition ”

arXiv preprint arXiv:1409.1556  2014.

10

,Arnu Pretorius
Elan van Biljon
Steve Kroon
Herman Kamper