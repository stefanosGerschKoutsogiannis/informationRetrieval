2009,An Infinite Factor Model Hierarchy Via a Noisy-Or Mechanism,The Indian Buffet Process is a Bayesian nonparametric approach that models objects as arising from an infinite number of latent factors. Here we extend the latent factor model framework to two or more unbounded layers of latent factors. From a generative perspective  each layer defines a conditional \emph{factorial} prior distribution over the binary latent variables of the layer below via a noisy-or mechanism. We explore the properties of the model with two empirical studies  one digit recognition task and one music tag data experiment.,AnInﬁniteFactorModelHierarchyViaaNoisy-OrMechanismAaronC.Courville DouglasEckandYoshuaBengioDepartmentofComputerScienceandOperationsResearchUniversityofMontr´ealMontr´eal Qu´ebec Canada{courvila eckdoug bengioy}@iro.umontreal.caAbstractTheIndianBuffetProcessisaBayesiannonparametricapproachthatmodelsob-jectsasarisingfromaninﬁnitenumberoflatentfactors.Hereweextendthelatentfactormodelframeworktotwoormoreunboundedlayersoflatentfactors.Fromagenerativeperspective eachlayerdeﬁnesaconditionalfactorialpriordistributionoverthebinarylatentvariablesofthelayerbelowviaanoisy-ormechanism.Weexplorethepropertiesofthemodelwithtwoempiricalstudies onedigitrecogni-tiontaskandonemusictagdataexperiment.1IntroductionTheIndianBuffetProcess(IBP)[5]isaBayesiannonparametricapproachthatmodelsobjectsasarisingfromanunboundednumberoflatentfeatures.OneofthemainmotivationsfortheIBPisthedesireforafactorialrepresentationofdata witheachelementofthedatavectormodelledindependently i.e.asacollectionoffactorsratherthanasmonolithicwholesasassumedbyothermodelingparadigmssuchasmixturemodels.ConsidermusictagdatacollectedthroughtheinternetserviceproviderLast.fm.Usersoftheservicelabelsongsandartistswithdescriptivetagsthatcollectivelyformarepresentationofanartistorsong.Thesetagscanthenbeusedtoorganizeplaylistsaroundcertainthemes suchasmusicfromthe80’s.Thetop8tagsforthepopularbandRADIOHEADare:alternative rock alternativerock indie electronic britpop british andindierock.Thetagspointtovariousfacetsoftheband forexamplethattheyarebasedinBritain thattheymakeuseofelectronicmusicandthattheirstyleofmusicisalternativeand/orrock.Thesefacetsorfeaturesarenotmutuallyexclusivepropertiesbutrepresentsomesetofdistinctaspectsoftheband.ModelingsuchdatawithanIBPallowsustocapturethelatentfactorsthatgiverisetothetags includinginferringthenumberoffactorscharacterizingthedata.HowevertheIBPassumestheselatentfeaturesareindependentacrossobjectinstances.Yetinmanysituations amorecompactand/oraccuratedescriptionofthedatacouldbeobtainedifwewerepreparedtoconsiderdependen-ciesbetweenlatentfactors.Despitetherebeingawealthofdistinctfactorsthatcollectivelydescribeanartist itisclearthattheco-occurrenceofsomefeaturesismorelikelythanothers.Forexample factorsassociatedwiththetagalternativearemorelikelytoco-occurwiththoseassociatedwiththetagindiethanthoseassociatedwithtagclassical.Themaincontributionofthisworkistopresentamethodforextendinginﬁnitelatentfactormod-elstotwoormoreunboundedlayersoffactors withupper-layerfactorsdeﬁningafactorialpriordistributionoverthebinaryfactorsofthelayerbelow.Inthisframework theupper-layerfactorsexpresscorrelationsbetweenlower-layerfactorsviaanoisy-ormechanism.ThusourmodelmaybeinterpretedasaBayesiannonparametricversionofthenoisy-ornetwork[6 8].Inspecifyingthemodelandinferencescheme wemakeuseoftherecentstick-breakingconstructionoftheIBP[10].1Forsimplicityofpresentation wefocusonatwo-layerhierarchy thoughthemethodextendsreadilytohigher-ordercases.WeshowhowthecompletemodelisamenabletoefﬁcientinferenceviaaGibbssamplingprocedureandcompareperformanceofourhierarchicalmethodwiththestandardIBPconstructiononbothadigitmodelingtask andamusicgenre-taggingtask.2LatentFactorModelingConsiderasetofNobjectsorexemplars:x1:N=[x1 x2 ... xN].Wemodelthenthobjectwiththedistributionxn|zn 1:K θ∼F(zn 1:K θ1:K) withmodelparametersθ1:K=[θk]Kk=1(whereθk∼Hindep.∀k)andfeaturevariableszn 1:K=[znk]Kk=1whichwetaketobebinary:znk∈{0 1}.Wedenotethepresenceoffeaturekinexamplenasznk=1anditsabsenceasznk=0.Featurespresentinanobjectaresaidtobeactivewhileabsentfeaturesareinactive.Collectively thefeaturesformatypicallysparsebinaryN×Kfeaturematrix whichwedenoteasz1:N 1:K orsimplyZ.Foreachfeaturekletµkbethepriorprobabilitythatthefeatureisactive.ThecollectionofKprobabilities:µ1:K areassumedtobemutuallyindependent anddistributedaccordingtoaBeta(α/K 1)prior.Summarizingthefullmodel wehave(indep.∀n k):xn|zn 1:K θ∼F(zn 1:K θ)znk|µk∼Bernoulli(µk)µk|α∼Beta!αK 1"AccordingtothestandarddevelopmentoftheIBP wecanmarginalizeovervariablesµ1:KandtakethelimitK→∞torecoveradistributionoveranunboundedbinaryfeaturematrixZ.Inthedevelopmentoftheinferenceschemeforourhierarchicalmodel wemakeuseofanalternativecharacterizationoftheIBP:theIBPstick-breakingconstruction[10].Aswiththestick-breakingconstructionoftheDirichletprocess(DP) theIBPstick-breakingconstructionprovidesadirectcharacterizationoftherandomlatentfeatureprobabilitiesviaanunboundedsequence.Consideronceagaintheﬁnitelatentfactormodeldescribedabove.LettingK→∞ Znowpossessesanunboundednumberofcolumnswithacorrespondingunboundedsetofrandomprobabilities[µ1 µ2 ...].Re-arrangedindecreasingorder:µ(1)>µ(2)>... thesefactorprobabilitiescanbeexpressedrecursivelyas:µ(k)=U(k)µ(k−1)=#(l)U(l) whereU(k)i.i.d∼Beta(α 1).3AHierarchyofLatentFeaturesViaaNoisy-ORMechanismInthissectionweextendtheinﬁnitelatentfeaturesframeworktoincorporateinteractionsbetweenmultiplelayersofunboundedfeatures.Webeginbydeﬁningaﬁniteversionofthemodelbeforeconsideringthelimitingprocess.Weconsiderherethesimplesthierarchicallatentfactormodelconsistingoftwolayersofbinarylatentfeatures:anupper-layerbinarylatentfeaturematrixYwithelementsynj andalower-layerbinarylatentfeaturematrixZwithelementsznk.TheprobabilitydistributionovertheelementsynjisdeﬁnedaspreviouslyinthelimitconstructionoftheIBP:ynj|µj∼Bernoulli(µj) withµj|αµ∼Beta(αµ/J 1).ThelowerbinaryvariablesznkarealsodeﬁnedasBernoullidistributedrandomquantities:znk|yn : V: k∼Bernoulli(1−$j(1−ynjVjk))indep.∀n k.(1)However heretheprobabilitythatznk=1isafunctionoftheupperbinaryvariablesyn :andthekthcolumnoftheweightmatrixV withprobabilitiesVjk∈[0 1]connectingynjtoznk.Thecruxofthemodelishowynjinteractswithznkviaanoisy-ormechanismdeﬁnedinEq.(1).ThebinaryynjmodulatestheinvolvementoftheVjktermsintheproduct whichinturnmodulatesP(znk=1|yn : V: k).Thenoisy-ormechanisminteractspositivelyinthesensethatchanginganelementynjfrominactivetoactivecanonlyincreaseP(znk=1|yn: V:k) orleaveitunchangedinthecasewhereVjk=0.Weinterprettheactiveyn :tobepossiblecausesoftheactivationoftheindividualznk ∀k.ThroughtheweightmatrixV everyelementofYn 1:JisconnectedtoeveryelementofZn 1:K thusVisarandommatrixofsizeJ×K.InthecaseofﬁniteJandK anobviouschoiceofpriorforVis:Vjki.i.d∼Beta(a b) ∀j k.However lookingaheadtothecasewhereJ→∞andK→∞ theprioroverVwillrequiresomeadditionalstructure.Recently [11]introducedtheHierarchicalBetaProcess(HBP)andelucidatedtherelationshipbe-tweenthisandtheIndianBuffetProcess.WeuseavariantoftheHBPtodeﬁneaprioroverV:νk∼Beta(αν/K 1)Vjk|νk∼Beta(cνk c(1−νk)+1)indep.∀k j (2)2xnznkynjVjk!k(cid:78)k(cid:77)jK(cid:109)(cid:100)J(cid:109)(cid:100)N(cid:65)(cid:77)(cid:65)(cid:78)HQli.i.d∼Beta(αµ 1) µj=j$lQlRli.i.d∼Beta(αν 1) νk=k$lRlVjk∼Beta(cνk c(1−νk)+1)ynj∼Bern(µj)znk∼Bern(1−$j(1−ynjVjk)).Figure1:Left:Agraphicalrepresentationofthe2-layerhierarchyofinﬁnitebinaryfactormodels.Right:Summaryofthehierarchicalinﬁnitenoisy-orfactormodelinthestick-breakingparametrization.whereeachcolumnofV(indexedbyk)isconstrainedtoshareacommonprior.StructuringthepriorthiswayallowsustomaintainawellbehavedpriorovertheZmatrixasweletK→∞ groupingthevaluesofVjkacrossjwhileE[νk]→0.Howeverbeyondtheregionofverysmallνk(0<νk<<1) wewouldliketheweightsVjktovarymoreindependently.Thuswemodifythemodelof[11]toincludethe+1termtotheprioroverVjk(inEq.(2))andwelimitc≤1.Fig.1showsagraphicalrepresentationofthecomplete2-layerhierarchicalnoisy-orfactormodel asJ→∞andK→∞.Finally weaugmentthemodelwithanadditionalrandommatrixAwithmultinomialelementsAnk assigningeachinstanceofznk=1toanindexjcorrespondingtotheactiveupper-layerunitynjresponsibleforcausingtheevent.TheprobabilitythatAnk=jisdeﬁnedviaafamil-iarstick-breakingscheme.Byenforcingan(arbitrary)orderingovertheindicesj=[1 J] wecanviewthenoisy-ormechanismdeﬁnedinEq.(1)asspecifying foreachznk anorderedseriesofbinarytrials(i.e.coinﬂips).Foreachznk weproceedthroughtheorderedsetofelements {Vjk ynj}j=1 2 ... performingrandomtrials.Withprobabilityyn j∗Vj∗ k trialj∗isdeemeda“suc-cess”andwesetznk=1 Ank=j∗ andnofurthertrialsareconductedfor{n k j>j∗}.Conversely withprobability(1−ynj∗Vj∗k)thetrialisdeemeda“failure”andwemoveontotrialj∗+1.Sincealltrialsjassociatedwithinactiveupper-layerfeaturesarefailureswithprobabil-ityone(becauseynj=0) weneedonlyconsiderthetrialsforwhichynj=1.If foragivenznk alltrialsjforwhichynj=1(active)arefailures thenwesetznk=0withprobabilityone.Theprobabilityassociatedwiththeeventznk=0isthereforegivenbytheproductofthefailureprobabilitiesforeachoftheJtrials:P(znk=0|yn : V: k)=#Jj=1(1−ynjVjk) andwithP(znk=1|yn : V: k)=1−P(znk=0|yn : V: k) wearriveatthenoisy-ormechanismgiveninEq.(1).ThisprocessissimilartothesamplingprocessassociatedwiththeDirichletprocessstick-breakingconstruction[7].Indeed theprocessdescribedabovespeciﬁesastick-breakingcon-structionofageneralizedDirichletdistribution[1]overthemultinomialprobabilitiescorrespondingtotheAnk.ThegeneralizedDirichletdistributiondeﬁnedinthiswayhastheimportantpropertythatitisconjugatetomultinomialsampling.Withthegenerativeprocessspeciﬁedasabove wecandeﬁnetheposteriordistributionovertheweightsVgiventheassignmentmatrixAandthelatentfeaturematrixY.LetMjk=%Nn=1I(Ank=j)bethenumberoftimesthatthejthtrialwasasuccessforz: k(i.e.thenumberoftimesynjcausedtheactivationofznk)andletNjk=%Nn=1ynjI(Ank>j) thatisthenumberoftimesthatthej-thtrialwasafailureforznkdespiteynjbeingactive.Finally letusalsodenotethenumberoftimesy: jisactive:Nj=%Nn=1ynj.Giventhesequantities theposteriordistributionsforthemodelparametersµjandVjkaregivenby:µj|Y∼Beta(αµ/J+Nj 1+N−Nj)(3)Vjk|Y A∼Beta(cνk+Mjk c(1−νk)+Njk+1)(4)TheseconjugaterelationshipsareexploitedintheGibbssamplingproceduredescribedinSect.4.ByintegratingoutVjk wecanrecover(uptoaconstant)theposteriordistributionoverνk:3p(νk|A: k)∝ναν/K−1kJ$j=1Γ(cνk+Mjk)Γ(cνk)Γ(c(1−νk)+Njk+1)Γ(c(1−νk)+1)(5)OnepropertyofthemarginallikelihoodisthatwhollyinactiveelementsofY whichwedenoteasy: j"=0 donotimpactthelikelihoodasNj" k=0 Mj" k=0.ThisbecomesparticularlyimportantasweletJ→∞.Havingdeﬁnedtheﬁnitemodel itremainstotakethelimitasbothK→∞andJ→∞.TakingthelimitofJ→∞isrelativelystraightforwardastheupper-layerfactormodelnaturallytendstoanIBP:Y∼IBP anditsinvolvementintheremainderofthemodelislimitedtothesetofactiveelementsofY whichremainsﬁniteforﬁnitedatasets.IntakingK→∞ thedistributionovertheunboundedνkconvergestothatoftheIBP whiletheconditionaldistributionoverthenoisy-orweightsVjkremainsimplebetadistributionsgiventhecorrespondingνk(asinEq.(4)).4InferenceInthissection wedescribeaninferencestrategytodrawsamplesfromthemodelposterior.ThealgorithmisbasedjointlyontheblockedGibbssamplingstrategyfortruncatedDirichletdistribu-tions[7]andontheIBPsemi-orderedslicesampler[10] whichweemployateachlayerofthehierarchy.Becausebothalgorithmsarebasedonthestrategyofdirectlysamplinganinstantiationofthemodelparameters theirusetogetherpermitsustodeﬁneanefﬁcientextendedblockedGibbssamplerovertheentiremodelwithoutapproximation.Tofacilitateourdescriptionofthesemi-orderedslicesampler weseparateµ1:∞intotwosubsets:µ+1:J+andµo1:∞ whereµ+1:J+aretheprobabilitiesassociatedwiththesetofJ+activeupper-layerfactorsY+(thosethatappearatleastonceinthedataset i.e.∃i:y+ij"=1 1≤j$≤J+)andµo1:∞areassociatedwiththeunboundedsetofinactivefeaturesYo(thosenotappearinginthedataset).Similarly weseparateν1:∞intoν+1:K+andνo1:∞ andZintocorrespondingactiveZ+andinactiveZowhereK+isthenumberofactivelower-layerfactors.4.1Semi-orderedslicesamplingoftheupper-layerIBPTheIBPsemi-orderedslicesamplermaintainsanunorderedsetofactivey+1:N 1:J+withcorrespond-ingµ+1:J+andV1:J+ 1:K whileexploitingtheIBPstick-breakingconstructiontosamplefromthedistributionoforderedinactivefeatures uptoanadaptivelychosentruncationlevelcontrolledbyanauxiliaryslicevariablesy.Samplesy.Theuniformlydistributedauxiliaryslicevariables sycontrolsthetruncationleveloftheupper-layerIBP whereµ∗isdeﬁnedasthesmallestprobabilityµcorrespondingtoanactivefeature:sy|Y µ1:∞∼Uniform(0 µ∗) µ∗=min&1 min1≤j"≤J+µ+j"’.(6)Asdiscussedin[10] thejointdistributionisgivenbyp(sy µ1:∞ Y)=p(Y µ1:∞)×p(sy|Y µ1:∞) wheremarginalizingoversypreservestheoriginaldistributionoverYandµ1:∞.How-ever givensy theconditionaldistributionp(ynj"=1|Z sy µ1:∞)=0foralln j$suchthatµj"<sy.Thisisthecruxoftheslicesamplingapproach:Eachsamplesyadaptivelytruncatesthemodel withµ1:J>sy.Yetbymarginalizingoversy wecanrecoversamplesfromtheoriginalnon-truncateddistributionp(Y µ1:∞)withoutapproximation.Sampleµo1:Jo.Fortheinactivefeatures weuseadaptiverejectionsampling(ARS)[4]tosequen-tiallydrawanorderedsetofJoposteriorfeatureprobabilitiesfromthedistribution:p(µoj|µoj−1 yo: ≥j=0)∝exp(αµN)n=11n(1−µoj)n*·(µoj)αµ−1(1−µoj)NI(0≤µoj≤µoj−1) untilµoJo+1<sy.TheaboveexpressionarisesfromusingtheIBPstick-breakingconstructiontomarginalizeovertheinactiveelementsofµ:[10].ForeachoftheJoinactivefeaturesdrawn the4correspondingfeaturesyo1:N 1:JoareinitializedtozeroandthecorrespondingweightVo1:Jo 1:KaresampledfromtheirpriorinEq.(2).Withtheprobabilitiesforboththeactiveandatruncatedsetofinactivefeaturessampled thesetoffeaturesarere-integratedintoasetofJ=J++JofeaturesY=[y+1:N 1:J+ yo1:N 1:Jo]withprobabilitiesµ1:J=[µ+1:J+ µo1:Jo] andcorrespondingweightsVT=[(V+1:J+ 1:K)T (Vo1:Jo 1:K)T].SampleY.Giventheupper-layerfeatureprobabilitiesµ1:J weightmatrixV andthelower-layerbinaryfeaturevaluesznk weupdateeachynjasfollows:p(ynj=1|µj zn : µ∗)∝µjµ∗K$k=1p(znk|ynj=1 yn ¬j V: k)(7)Thedenominatorµ∗issubjecttochangeifchangingynjinducesachangeinµ∗(asdeﬁnedinEq.(6));yn ¬jrepresentsallelementsyn 1:JexceptynjTheconditionalprobabilityofthelower-layerbinaryvariablesisgivenby:p(znk|yn : V: k)=(1−#j(1−ynjVjk)).Sampleµ+1:J+.OnceagainweseparateYandµ1:∞intoasetofactivefeatures:Y+withprob-abilitiesµ+1:J+;andasetofinactivefeaturesYowithµo1:∞.Theinactivesetisdiscardedwhiletheactivesetofµ+1:J+areresampledfromtheposteriordistribution:µ+j|y+: j∼Beta(Nj 1+N−Nj).Atthispointwealsoseparatethelower-layerfactorsintoanactivesetofK+factorsZ+withcor-respondingν+1:K+ V+1:J+ 1:K+anddatalikelihoodparametersθ+;andadiscardedinactiveset.4.2Semi-orderedslicesamplingofthelower-layerfactormodelSamplingthevariablesofthelower-layerIFMmodelproceedsanalogouslytotheupper-layerIBP.HoweverthepresenceofthehierarchicalrelationshipbetweentheνkandtheV: k(asdeﬁnedinEqs.(3)and(4))doesrequiresomeadditionalattention.Weproceedbymakinguseofthemarginaldistributionovertheassignmentprobabilitiestodeﬁneasecondauxiliaryslicevariable sz.Samplesz.Theauxiliaryslicevariableissampledaccordingtothefollowing whereν∗isdeﬁnedasthesmallestprobabilitycorrespondingtoanactivefeature:sz|Z ν1:∞∼Uniform(0 ν∗) ν∗=min&1 min1≤k"≤K+ν+k"’.Sampleνo1:Ko.GivenszandY therandomprobabilitiesovertheinactivelower-layerbinaryfeatures νo1:∞ aresampledsequentiallytodrawasetofKofeatureprobabilities untilνKo+1<sz.Thesamplesaredrawnaccordingtothedistribution:p(νok|νok−1 Y+ zo: ≥k=0)∝I(0≤νok≤νok−1)(νok)αν−1 JYj=1Γ(c(1−νok)+Nj)Γ(c(1−νok))!×exp ανJYj=1Γ(c)Γ(c+Nj)N1+···+NJXi=0wiciiXl=11l(1−νok)l!·(8)Eq.(8)arisesfromthestick-breakingconstructionoftheIBPandfromtheexpressionforP(zo: >k=0|νok Y+)derivedinthesupplementarymaterial[2].HerewesimplynotethatthewiareweightsderivedfromtheexpansionofaproductoftermsinvolvingunsignedStirlingnum-bersoftheﬁrstkind.Thedistributionovertheorderedinactivefeaturesislog-concaveinlogνk andisthereforeamenabletoefﬁcientsampleviaadaptiverejectionsampling(aswasdoneinsamplingµo1:Jo).EachoftheKoinactivefeaturesareinitializedtozeroforeverydataobject Zo=0 whilethecorrespondingVoandlikelihoodparametersθoaredrawnfromtheirpriors.Oncetheν1:Koaredrawn boththeactiveandinactivefeaturesofthelower-layerarere-integratedintothesetofK=K++KofeaturesZ=[Z+ Zo]withprobabilitiesν1:K=[ν+1:K+ νo1:Ko]andcorrespondingweightmatrixV=[V+1:J+ 1:K+ Vo1:J+ 1:Ko]andparametersθ=[θ+ θo].5SampleZ.GivenY+andVweuseEq.(1)tospecifytheprioroverz1:N 1:K∗.Then conditionalonthisprior thedataXandparametersθ wesamplesequentiallyforeachznk:p(znk|y+n : V: k zn ¬k θ ν∗)=1ν∗0@1−J+Yj=1(1−y+njVjk)1Af(xn|zn : θ) wheref(xn|zn : θ)isthelikelihoodfunctionforthenthdataobject.SampleA.Givenznk y+n :andV: k wedrawthemultinomialvariableAnktoassignresponsibil-ity intheeventzik=1 tooneoftheupper-layerfeaturesy+nj p(Ank=j|znk=1 y+n : V: k)=Vjk"j−1Yi=1(1−y+niVik)# (9)andify+n j"=0 ∀j$>j† thenp(Ank=j†|znk=1 y+n : V: k)=#j†−1i=1(1−y+niVik)toensurenormalizationofthedistribution.Ifznk=0 thenP(Ank=∞)=1.SampleVandν+1:K+.ConditionalonY+ ZandA theweightsVareresampledfromEq.(4) followingtheblockedGibbssamplingprocedureof[7].GiventheassignmentsA theposteriorofν+kisgiven(uptoaconstant)byEq.(5).Thisdistributionislogconcaveinν+k thereforewecanonceagainuseARStodrawsamplesoftheposteriorofν+k 1≤k≤K+.5ExperimentsInthissection wepresenttwoexperimentstohighlightthepropertiesandcapabilitiesofourhier-archicalinﬁnitefactormodel.Ourgoalistoassess inthesetwocases theimpactofincludinganadditionalmodelinglayer.Tothisend andineachexperiment wecompareourhierarchicalmodeltotheequivalentIBPmodel.Ineachcase hyperparametersarespeciﬁedwithrespecttotheIBP(us-ingcross-validationbyevaluatingthelikelihoodofaholdoutset)andheldﬁxedforthehierarchicalfactormodel.Finallyallhyperparametersofthehierarchicalmodelthatwerenotmarginalizedoutwereheldconstantoverallexperiments inparticularc=1andαν=1.5.1ExperimentI:DigitsInthisexperimentwetookexamplesofimagesofhand-writtendigitsfromtheMNISTdataset.Following[10] thedatasetconsistedof1000examplesofimagesofthedigit3wherethehandwrit-tendigitimagesareﬁrstpreprocessedbyprojectingontotheﬁrst64PCAcomponents.TomodelMNISTdigits weaugmentboththeIBPandthehierarchicalmodelwithamatrixGofthesamesizeasZandwithi.i.d.zeromeanandunitvarianceelements.Eachdataobject xnismodeledas:xn|Z G θ σ2x∼N((zn :+gn :)θ σ2XI)where+istheHadamard(element-wise)product.TheinclusionofGintroducesanadditionalsteptoourGibbssamplingprocedure howevertherestofthehierarchicalinﬁnityfactormodelisasdescribedinSect.3.InordertoassessthesuccessofourhierarchicalIFMincapturinghigher-orderfactorspresentintheMNISTdata weconsiderade-noisingtask.Randomnoise(std=0.5)wasaddedtoapost-processedtestsetandthemodelswereevaluatedinitsabilitytorecoverthenoise-freeversionofasetof500examplesnotusedintraining.Fig.2(a)presentsacomparisonoftheloglikelihoodofthe(noise-free)test-setforboththehierarchicalmodelandtheIBPmodel.Theﬁgureshowsthatthe2-layernoisy-ormodelgivessig-niﬁcantlymorelikelihoodtothepre-corrupteddatathantheIBP indicatingthatthenoisy-ormodelwasabletolearnusefulhigher-orderstructurefromMNISTdata.Oneofthepotentialbeneﬁtsofthestyleofmodelweproposehereisthatthereistheopportunityforlatentfactorsatonelayertosharefeaturesatalowerlayer.Fig.2illustratestheconditionalmodeoftherandomweightmatrixV(conditionalonasampleoftheothervariables)andshowsthatthereissigniﬁcantsharingoflow-levelfeaturesbythehigher-layerfactors.Fig.2(d)-(e)comparethefeatures(sampledrowsoftheθmatrix)learnedbyboththeIBPandbythehierarchicalnoisy-orfactormodel.Interestingly thesampledfeatureslearnedinthehierarchicalmodelappeartobeslightlymorespatiallylocalizedandsparse.Fig.2(f)-(i)illustratessomeofthemarginalsthatarisefromtheGibbssamplinginferenceprocess.Interestingly theIBPmodelinfersagreaternumberoflatentfactorsthatdidthe2-layer600.511.522.533.544.5x 104−4.5−4−3.5−3−2.5−2−1.5x 104log likelihoodMCMC iterations  IBP2−layer Noisy−Or model  10203040506070809010051015202500.10.20.30.40.50.60.70.80.9120140160180200010002000300040005000num. active featuresnum. MCMC iterations  010203040050100150200250300num. of objectsnum. active features  123450100200300400500600num. active featuresnum. of objects202530354002000400060008000num. MCMC iterationsnum. active featuresIBPHierarchicalIBPHierarchical(cid:8)(cid:70)(cid:9)(cid:8)(cid:71)(cid:9)(cid:8)(cid:72)(cid:9)(cid:8)(cid:73)(cid:9)(cid:8)(cid:65)(cid:9)(cid:8)(cid:66)(cid:9)(cid:8)(cid:67)(cid:9)(cid:8)(cid:68)(cid:9)(cid:8)(cid:69)(cid:9)Figure2:(a)Theloglikelihoodofade-noisedtestset.Corrupted(with0.5-stdGaussiannoise)versionsoftestexampleswereprovidedtothefactormodelsandthelikelihoodofthenoise-freetestsetwasevaluatedforbothanIBP-basedmodelaswellasforthe2-layernoisy-ormodel.Thetwolayermodelshownsubstantialimprovementinloglikelihood.(b)Reconstructionofnoisyexamples.Thetoprowshowstheoriginalvaluesforacollectionofdigits.Thesecondrowshowstheircorruptedversions;whilethethirdandfourthrowshowthereconstructionsfortheIBP-basedmodelandthe2layernoisy-orrespectively.(c)AsubsetoftheVmatrix.TherowsofVareindexedbyjwhilethecolumnsofVareindexedbyk.Theverticalstripingpatternisevidenceofsigniﬁcantsharingoflower-layerfeaturesamongtheupper-layerfactors.(d)-(e)Themostfrequent64features(rowsoftheθmatrix)for(d)theIBPandfor(e)the2-layerinﬁnitenoisy-orfactormodel.(f)AcomparisonofthedistributionsofthenumberofactiveelementsbetweentheIBPandthenoisy-ormodel.(g)Acomparisonofthenumberofactive(lower-layer)factorspossessedbyanobjectbetweentheIBPandthehierarchicalmodel.(h)thedistributionofupper-layeractivefactorsand(i)thenumberofactivefactorsfoundinanobject.noisy-ormodel(attheﬁrstlayer).However thedistributionoverfactorsactiveforeachdataobjectisnearlyidentical.ThissuggeststhepossibilitythattheIBPismaintainingspecializedfactorsthatpossiblyrepresentasuperpositionoffrequentlyco-occurringfactorsthatthenoisy-ormodelhascapturedmorecompactly.5.2ExperimentII:MusicTagsReturningtoourmotivatingexamplefromtheintroduction weextractedtagsandtagfrequenciesfromthesocialmusicwebsiteLast.fmusingtheAudioscrobblerwebservice.Thedataisintheformofcounts1oftagassignmentforeachartist.Ourgoalinmodelingthisdataistoreducethisoftennoisycollectionoftagstoasparserepresentationforeachartist.WewilladoptadifferentapproachtothestandardLatentDirichletAllocation(LDA)documentprocessingstrategyofmodelingthedocument–orinthiscasetagcollection–ashavingbeengeneratedfromamixtureoftagmultino-mials.Wewishtodistinguishbetweenanartistthateveryoneagreesisbothcountryandrockversusanartistthatpeoplearedividedwhethertheyarerockorcountry.Tothisend wecanagainmakeuseoftheconjugatenoisy-ormodeltomodelthecountdataintheformofbinomialprobabilities i.e.tothemodeldeﬁnedinSect.3 weaddtherandomweightsWkti.i.d∼Beta(a b) ∀k.tconnectingZtothedataXviathedistribution:Xnt∼Binomial(1−#k(1−znkW) C)whereCisthelimitonthenumberofpossiblecountsachievable.Thiswouldcorrespondtothenumberofpeoplewhoevercontributedatagtothatartist.InthecaseoftheLast.fmdataC=100.MaintainingconjugacyoverWwillrequireustoaddanassignmentparameter1Thepubliclyavailabledataisnormalizedtomaximumvalue100.7801001201401600200400600800num. active featuresMCMC iterations02468050100150200250300num. active featuresnum. objects012340100200300400500600num. active featuresnum. objects2030405060700500100015002000num. active featuresMCMC iterations(cid:8)(cid:65)(cid:9)(cid:8)(cid:66)(cid:9)(cid:8)(cid:67)(cid:9)(cid:8)(cid:68)(cid:9)Figure3:Thedistributionofactivefeaturesforthenoisy-ormodelatthe(a)lower-layerand(c)theupper-layer.Thedistributionoveractivefeaturesperdataobjectforthe(b)upper-layerand(d)lower-layer.BntwhoseroleisanalogoustoAnk.Withthemodelthusspeciﬁed wepresentadatasetof1000artistswithavocabularysizeof100tagsrepresentingatotalof312134counts.Fig.3showstheresultrunningtheGibbssamplerfor10000iterations.Astheﬁgureshows bothlayersarequitesparse.Generally mostofthefeatureslearnedintheﬁrstlayeraredominatedbyonetothreetags.Mostfeaturesatthesecondlayercoverabroaderrangeoftags.Thetwomostprobablefactorstoemergeattheupperlayerareassociatedwiththetags(inorderofprobability):1.electronic electronica chillout ambient experimental2.pop rock 80s dance 90sTheabilityofthe2-layernoisy-ormodeltocapturehigher-orderstructureinthetagdatawasagainassessedthoughacomparisontothestandardIBPusingthenoisy-orobservationmodelabove.Themodelwasalsocomparedagainstamorestandardlatentfactormodelwiththelatentrepresentationηnkmodelingthedatathroughageneralizedlinearmodel:Xnt∼Binomial(Logistic(ηn :O: t) C) wherethefunctionLogistic(.)isthelogisticsigmoidlinkfunctionandthelatentrepresentationηnk∼N(0 Ση)arenormallydistributed.Inthiscase inferenceisperformedviaaMetropolis-HastingsMCMCmethodthatmixesreadily.Thetestdatawasmissing90%ofthetagsandthemod-elswereevaluatedbytheirsuccessinimputingthemissingdatafromthe10%thatremained.Hereagain the2-LayerNoisy-Ormodelachievedsuperiorperformance asmeasuredbythemarginalloglikelihoodonaholdoutsetof600artist-tagcollections.Interestinglybothsparsemodels–theIBPandthenoisy-ormodel–dramaticallyoutperformedthegeneralizedlatentlinearmodel.MethodNLLGen.latentlinearmodel(BestDim=30)8.7781e05±0.02e05IBP5.638e05±0.001e052-LayerNoisy-OrIFM5.542e05±0.001e056DiscussionWehavedeﬁnedanoisy-ormechanismthatallowsoneinﬁnitefactormodeltoactasapriorforanotherinﬁnitefactormodel.Themodelpermitshigh-orderstructuretobecapturedinafactormodelframeworkwhilemaintaininganefﬁcientsamplingalgorithm.ThemodelpresentedhereissimilarinspirittothehierarchicalBetaprocess [11]inthesensethatbothmodelsdeﬁneahierarchyofunboundedlatentfactormodels.However whilethehierarchicalBetaprocesscanbeseenasawaytogroupobjectsinthedata-setwithsimilarfeatures ourmodelprovidesawaytogroupfeaturesthatfrequentlyco-occurinthedata-set.Itisperhapsmoresimilarinspirittotheworkof[9]whoalsosoughtameansofassociatinglatentfactorsinanIBP howevertheirworkdoesnotactdirectlyontheunboundedbinaryfactorsasoursdoes.Recentlythequestionofhowtodeﬁneahierarchicalfactormodeltoinducecorrelationsbetweenlower-layerfactorswasaddressedby[3]withtheirIBP-IBPmodel.However unlikeourmodel wherethedependenciesinducedbytheupper-layerfactorsviaannoisy-ormechanism theIBP-IBPmodelmodelscorrelationsviaanANDconstructthroughtheinteractionofbinaryfactors.AcknowledgmentsTheauthorsacknowledgethesupportofNSERCandtheCanadaResearchChairsprogram.WealsothankLast.fmformakingthetagdatapubliclyavailableandPaulLamereforhishelpinprocessingthetagdata.8References[1]RobertJ.ConnorandJamesE.Mosimann.ConceptsofindependenceforproportionswithageneralizationoftheDirichletdistribution.JournaloftheAmericanStatisticalAssociation 64(325):194–206 1969.[2]AaronC.Courvile DouglasEck andYoshuaBengio.Aninﬁnitefactormodelhierarchyviaanoisy-ormechanism:Supplementalmaterial.SupplementtotheNIPSpaper.[3]FinaleDoshi-VelezandZoubinGhahramni.Correlatednonparametriclatentfeaturemodels.InProceedingsofthe25thConferenceonUncertaintyinArtiﬁcialIntelligence 2009.[4]W.R.GilksandP.Wild.AdaptiverejectionsamplingforGibbssampling.AppliedStatistics 41(2):337–348 1992.[5]TomGrifﬁthsandZoubinGhahramani.Inﬁnitelatentfeaturemodelsandtheindianbuffetprocess.InAdvancesinNeuralInformationProcessingSystems18 Cambridge MA 2006.MITPress.[6]MaxHenrion.Practicalissuesinconstructingabayes’beliefnetwork.InProceedingsoftheProceedingsoftheThirdConferenceAnnualConferenceonUncertaintyinArtiﬁcialIntelli-gence(UAI-87) page132?139 NewYork NY 1987.ElsevierScience.[7]HemantIshwaranandLancelotF.James.Gibbssamplingmethodsforstick-breakingpriors.AmericanStatisticalAssociation 96(453):161–173 2001.[8]MichaelKearnsandYishayMansour.Exactinferenceofhiddenstructurefromsampledatainnoisy-ornetworks.InProceedingsofthe14thConferenceonUncertaintyinArtiﬁcialIntelligence pages304–310 1998.[9]PiyushRaiandHalDaum´eIII.Theinﬁnitehierarchicalfactorregressionmodel.InDaphneKoller DaleSchuurmans YoshuaBengio andL´eonBottou editors AdvancesinNeuralIn-formationProcessingSystems21 2009.[10]YeeWhyeTeh DilanG¨or¨ur andZoubinGhahramani.Stick-breakingconstructionfortheindianbuffetprocess.InProceedingsoftheEleventhInternationalConferenceonArtiﬁcalIntelligenceandStatistics(AISTAT2007). 2007.[11]RomainThibauxandMichaelI.Jordan.Hierarchicalbetaprocessandtheindianbuffetpro-cess.InProceedingsoftheEleventhInternationalConferenceonArtiﬁcalIntelligenceandStatistics(AISTAT2007). 2007.9,Qian Wang
Jiaxing Zhang
Sen Song
Zheng Zhang
Guruprasad Raghavan
Matt Thomson