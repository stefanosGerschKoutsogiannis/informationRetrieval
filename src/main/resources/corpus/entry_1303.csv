2019,Debiased Bayesian inference for average treatment effects,Bayesian approaches have become increasingly popular in causal inference problems due to their conceptual simplicity  excellent performance and in-built uncertainty quantification ('posterior credible sets'). We investigate Bayesian inference for average treatment effects from observational data  which is a challenging problem due to the missing counterfactuals and selection bias. Working in the standard potential outcomes framework  we propose a data-driven modification to an arbitrary (nonparametric) prior based on the propensity score that corrects for the first-order posterior bias  thereby improving performance. We illustrate our method for Gaussian process (GP) priors using (semi-)synthetic data. Our experiments demonstrate significant improvement in both estimation accuracy and uncertainty quantification compared to the unmodified GP  rendering our approach highly competitive with the state-of-the-art.,Debiased Bayesian inference for average treatment

effects

Kolyan Ray

Department of Mathematics

King’s College London
kolyan.ray@kcl.ac.uk

Botond Szabó

b.t.szabo@math.leidenuniv.nl

Mathematical Institute

Leiden University

Abstract

Bayesian approaches have become increasingly popular in causal inference prob-
lems due to their conceptual simplicity  excellent performance and in-built uncer-
tainty quantiﬁcation (‘posterior credible sets’). We investigate Bayesian inference
for average treatment effects from observational data  which is a challenging prob-
lem due to the missing counterfactuals and selection bias. Working in the standard
potential outcomes framework  we propose a data-driven modiﬁcation to an ar-
bitrary (nonparametric) prior based on the propensity score that corrects for the
ﬁrst-order posterior bias  thereby improving performance. We illustrate our method
for Gaussian process (GP) priors using (semi-)synthetic data. Our experiments
demonstrate signiﬁcant improvement in both estimation accuracy and uncertainty
quantiﬁcation compared to the unmodiﬁed GP  rendering our approach highly
competitive with the state-of-the-art.

1

Introduction

Inferring the causal effect of a treatment or condition is an important problem in many applications 
such as healthcare [11  17  38]  education [20]  economics [16]  marketing [6] and survey sampling
[13] amongst others. While carefully designed experiments are the gold standard for measuring
causal effects  these are often impractical due to ethical  ﬁnancial or time-constraints. For example 
when evaluating the effectiveness of a new medicine it may not be ethically feasible to randomly
assign a patient to a particular treatment irrespective of their particular circumstances. An alternative
is to use observational data which  while typically much easier to obtain  requires careful analysis.
A common framework for causal inference is the potential outcomes setup [19]  where every in-
dividual possesses two ‘potential outcomes’ corresponding to the individual’s outcomes with and
without treatment. For every subject in the observation cohort we thus observe only one of these two
outcomes and not the ‘missing’ counterfactual outcome  without which we cannot observe the true
treatment effect. This problem differs from standard supervised learning in that we must thus account
for the missing counterfactuals  which is the well-known missing data problem in causal inference.
A further complication is that in practice  particularly in observational studies  individuals are often
assigned treatments in a biased manner [36] so that a simple comparison of the two groups may be
misleading. A common way to deal with selection bias is to measure features  called confounders 
that are believed to inﬂuence both the treatment assignment and outcomes. The discrepancy in feature
distributions for the treated and control subject groups can be expressed via the propensity score 
which is then used to apply a correction to the estimate. Under the assumption of unconfoundedness 
namely that the treatment assignment and outcome are conditionally independent given the features 
one can then identify the causal effect. Widely used methods include propensity score matching
[32  34  36] and double robust methods [5  31  33].

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

In recent years  Bayesian methods have become increasingly popular for causal inference due to
their excellent performance  for example Gaussian processes [1–4  11  23  38] and BART [13  15  17 
18  20  35] amongst other priors [6]. Apart from excellent estimation precision  advantages of the
Bayesian approach are its conceptual simplicity  ability to incorporate prior knowledge and access to
uncertainty quantiﬁcation via posterior credible sets.
In this work we are interested in Bayesian inference for the (population) average treatment effect
(ATE) of a causal intervention  which is relevant when policy makers are interested in evaluating
whether to apply a single intervention to the entire population. This may be the case when one no
longer observes feature measurements of new individuals outside the dataset. This problem is an
example of estimating a one-dimensional functional (the ATE) of a complex Bayesian model (the
full response surface). In such situations  the induced marginal posterior for the functional can often
contain a signiﬁcant bias in its centering  leading to poor estimation and uncertainty quantiﬁcation
[7  8  27]. This is indeed the case in our setting  where it is known that a naive choice of prior can
yield badly biased inference for the ATE in casual inference/missing data problems [14  26  30]. For
instance  Gaussian process (GP) priors will typically not be correctly centered  see Figure 1 below.
Correcting for this is a delicate issue since even when the prior is perfectly calibrated (i.e. all tuning
parameters are set optimally to recover the treatment response surface)  the posterior can still induce
a large bias in the marginal posterior for the ATE [25].
Our main contribution is to propose a data-driven modiﬁcation to an arbitrary nonparametric prior
based on the estimated propensity score that corrects for the ﬁrst-order posterior bias for the ATE. By
correctly centering the posterior for the ATE  this improves performance for both estimation accuracy
and uncertainty quantiﬁcation. We numerically illustrate our method on simulated and semi-synthetic
data using GP priors  where our prior correction corresponds to a simple data-driven alteration to the
covariance kernel. Our experiments demonstrate signiﬁcant improvement in performance from this
debiasing. This method should be viewed as a way to increase the efﬁciency of a given Bayesian
prior  selected for modelling or computational reasons  when estimating the ATE.
Our method provides the same beneﬁts for inference on the conditional average treatment effect
(CATE). We further show that randomization of the feature distribution is not necessary for accurate
uncertainty quantiﬁcation for the CATE  but is helpful for the ATE. Since this approach provides
similar estimation accuracy irrespective of whether the feature distribution is randomized  this
highlights that care must be taken when using ﬁner properties of the posterior  such as uncertainty
quantiﬁcation.
Organization: in Section 2 we present the causal inference problem  in Section 3 our main idea for
debiasing an arbitrary Bayesian prior  with the speciﬁc case of GPs treated in Section 4. Simulations
and further discussion are in Sections 5 and 6  respectively. Additional technical details  some
motivation based on semiparametric statistics and further simulation results are in the supplement.

2 Problem setup

i

i

i

and Y (0)

i − Y (0)

Consider the situation where a binary treatment with heterogeneous treatment effects is applied
to a population. Working in the potential outcomes setup [19]  every individual i possesses a d-
dimensional feature Xi ∈ Rd and two ‘potential outcomes’ Y (1)
  corresponding to the
individual’s outcomes with and without treatment  respectively. We wish to make inference on the
treatment effect Y (1)
  but since we only observe one out of each pair of outcomes  and not
the corresponding (missing) counterfactual outcome  we do not directly observe samples of the
treatment effect. In this paper we are interested in estimating the average treatment effect (ATE)
ψ = E[Y (1) − Y (0)].
For Ri ∈ {0  1} the treatment assignment indicator  we observe outcome Y (Ri)
  which can also be
expressed as observing Y = RiY (1) + (1 − Ri)Y (0). The treatment assignment policy generally
depends on the features Xi and is expressed by the conditional probability π(x) = P (R = 1|X = x)
i ⊥⊥ Ri|Xi for all
called the propensity score (PS). We assume unconfoundedness  namely Y (1)
Xi ∈ Rd  which is a standard assumption in the potential outcomes framework [19]. Unconfound-
edness (or strong ignorability) says that the outcomes Y (1)
are independent of the treatment

  Y (0)

i

i

  Y (0)

i

i

2

assignment Ri given the measured features Xi  i.e. any dependence can be fully explained through
Xi. Without such an assumption the ATE is typically not even identiﬁable [32].
We work in the standard nonparametric regression framework for causal inference with mean-zero
additive errors [2  14  15  18  23]

(1)
where εi ∼iid N (0  σ2
n)  Ri ∈ {0  1} is the indicator variable for whether treatment is applied and
Xi ∈ Rd represents measured feature information about individual i. We assume the general feature
information is unbiased Xi ∼iid F   but the treatment assignment π(x) = P (R = 1|X = x) may be
heavily biased. Our goal is to estimate the average treatment effect (ATE)

Yi = m(Xi  Ri) + εi 

ψ = E[Y (1) − Y (0)] =

=

E[Y |R = 1  X = x] − E[Y |R = 0  X = x]dF (x)

m(x  1) − m(x  0)dF (x)

(2)

(cid:90)
(cid:90)

Rd

Rd

n(cid:88)

i=1

based on an observational dataset Dn consisting of n i.i.d. samples of the triplet (Xi  Ri  Yi). A
related quantity is the conditional average treatment effect (CATE)

ψc = ψc(X1  . . .   Xn) =

1
n

E[Y (1)

i − Y (0)

i

|Xi] =

1
n

m(Xi  1) − m(Xi  0) 

(3)

distribution F in the deﬁnition (2) of ψ with its empirical counterpart n−1(cid:80)n

which represents the average treatment effect over the measured individuals. Compared to the
ATE  this quantity ignores the randomness in the feature data  replacing the true population feature
i=1 δXi with δx the

Dirac measure (point mass) at x.

n(cid:88)

i=1

3 Bayesian causal inference for average treatment effects

We ﬁt a nonparametric prior to the model (F  π  m) and consider the ATE ψ as a functional of
these three components  studying the one-dimensional marginal posterior for ψ induced by the full
nonparametric posterior. More concretely  one can sample from the marginal posterior for ψ by
drawing a full posterior sample (F  π  m) and computing the corresponding draw ψ according to the
formula (2). Note that this yields the full posterior for the ATE ψ  which is much more informative
than simply the posterior mean  for instance also providing credible intervals for ψ. This is the natural
Bayesian approach to modelling ψ and it is indeed typically necessary to fully model (F  π  m) rather
than ψ directly when considering heterogeneous treatment effects.
Assuming the distribution F has a density f  the likelihood for data Dn arising from model (1) is
(1−Ri)(Yi−m(Xi 0))2

n(cid:89)

Ri(Yi−m(Xi 1))2− 1
2σ2
n

f (Xi)π(Xi)Ri(1 − π(Xi))1−Ri

− 1
2σ2
n

e

.

1√
2πσn

i=1

Since this factorizes in the model parameters (f  π  m)  placing a product prior on these three
parameters yields a product posterior  i.e. f  π  m are (conditionally) independent under the posterior.
As this is particularly computationally efﬁcient  we pursue this approach. In this case  since π does
not appear in the ATE ψ  the π terms will cancel from the marginal posterior for ψ and the prior
on π is irrelevant for estimating the ATE. We thus need not specify the π component of the prior.
These properties hold even when F has no density and so a likelihood cannot be deﬁned  see the
supplement.
A Bayesian will typically endow the response surface m with a nonparametric prior for either
modelling or computational reasons. As already mentioned  the induced marginal posterior for ψ will
then often have a signiﬁcant bias term in its centering  see Figure 1 for an example arising from a
standard GP prior. Our main idea is to augment a given Bayesian prior for m by efﬁciently using an
estimate ˆπ of the PS  since it is well-known that using PS information can improve estimation of the
ATE [32]. We model (F  m) using the following prior:

m(x  r) = W (x  r) + νnλ

 

F ∼ DP 

(4)

(cid:19)

− 1 − r
1 − ˆπ(x)

(cid:18) r

ˆπ(x)

3

Figure 1: Plot of marginal posterior distributions for the ATE with true ATE (red)  histogram of
10 000 posterior draws (blue)  posterior mean (solid black)  90% credible interval (dotted black)
and best ﬁtting Gaussian distribution (orange). Data arises from the synthetic simulation (HOM) in
Section 5 with n = 500 and Gaussian process prior described in Section 4. Left/right: without/with
bias correction. Note the incorrect centering on the left-hand side.

where W : Rd × {0  1} → R is a stochastic process  DP denotes the Dirichlet process with a ﬁnite
base measure [12]  νn > 0 is a scaling parameter and λ is a real-valued random variable  with W  F  λ
independent. Estimating the PS is a standard binary classiﬁcation problem and one can use any
suitable estimator ˆπ  from logistic regression to more advanced machine learning methods. It may
be practically advantageous to truncate the estimator ˆπ away from 0 and 1 for numerical stability.
For estimating the CATE  we propose the same prior (4) but with the Dirichlet process prior for F

replaced by a plug-in estimate consisting of the empirical distribution Fn = n−1(cid:80)n

i=1 δXi.

The prior (4) increases/decreases the prior correlation within/across treatment groups in a hetero-
geneous manner compared to the unmodiﬁed prior (νn = 0). For example  in regions with few
observations in the treatment group (small π(x))  (4) signiﬁcantly increases the prior correlation with
other treated individuals  thereby borrowing more information across individuals to account for the
lack of data. Conversely  in observation rich areas (large π(x))  (4) borrows less information  instead
using the (relatively) numerous local observations.
Using an unmodiﬁed prior (νn = 0)  the posterior will make a bias-variance tradeoff aimed at
estimating the full regression function m rather than the smooth one-dimensional functional ψ.
In particular  the bias for the ATE ψ will dominate  leading to poor estimation and uncertainty
quantiﬁcation unless the true m and f = F (cid:48) are especially easy to estimate. The idea behind the
prior (4) is to use a data-driven correction to (ﬁrst-order) debias the resulting marginal posterior
for ψ. The quantity r/π(x) − (1 − r)/(1 − π(x)) corresponds in a speciﬁc technical sense to the
‘derivative’ of the ATE ψ with respect to the model (1)  the so-called ‘least favorable direction’ of ψ.
Heuristically  Taylor expanding ψ|Dn − ψ0  where ψ|Dn and ψ0 are the posterior and ‘true’ ATE 
the hyperparameter λ is introduced to help the posterior remove the ﬁrst-order (bias) term in this
expansion  see Figure 1 for an illustration. Since the true π is unknown  the natural approach is to
replace it with an estimator ˆπ. A more technical explanation can be found in the supplement.
Such a bias correction will help most when (F  m) are difﬁcult to estimate  for instance in high-
dimensional feature settings. Higher-order bias corrections have also been considered using estimating
equations [28  29]  but it is unclear how to extend this to the Bayesian setting. A similar idea has been
investigated theoretically in [25]  where it is shown that in a related idealized model  priors correctly
calibrated to the unknown true functions (i.e. non-adaptive) satisfy a semiparametric Bernstein-von
Mises theorem  i.e. the marginal posterior for the ATE is asymptotically normal with optimal variance
in the large data setting. Figure 1 suggests the shape also holds in the present setting.
A good choice of prior for W is still essential  since poor modelling of m can also induce bias.
In particular  νn should be picked so that the second term in (4) is of smaller order than W in
order to have relatively little effect on the full posterior for m. If the Bernstein-von Mises theorem
holds  the marginal posterior for ψ ﬂuctuates on a 1/
n scale (see [25] for a related model)  which
suggests taking νn ∼ 1/
n. On this scale the bias correction is sufﬁciently large to meaningfully

√

√

4

affect the marginal posterior  but not so large as to dominate. Simulations indicate that taking
νn signiﬁcantly larger than this can cause the bias correction to dominate in small data situations 
reducing performance. In a data-rich situation  larger values of νn are also admissible since the
posterior can calibrate the value of λ based on the data. Thus correct calibration of νn is mainly
important for small or moderate sample performance  see Section 4.
One can also take a fully Bayesian approach by placing a prior on π in (4). While such an approach
may be philosophically appealing  it can cause computational difﬁculties since the priors for (π  m) 
and hence also the corresponding posteriors  are no longer independent. For Gaussian processes
(GPs)  considered in detail in Section 4  one can then only sample from the fully Bayesian posterior
using a Metropolis-Hastings-within-Gibbs-sampling algorithm  which is far slower in practice. In
contrast  the ‘empirical Bayes’ approach we advocate in (4) maintains this independence and is thus
computationally more efﬁcient  e.g. in the GP case  the resulting prior for m remains a GP.
It is known that for estimating a smooth one-dimensional functional of a nonparametric model 
selecting an undersmoothing prior can be advantageous [8]. As well as being computationally
efﬁcient due to conjugacy  the choice of Dirichlet process for F is thus also theoretically motivated 
since it can be viewed as a considerable undersmoothing (f = F (cid:48) does not even exist as F is a
discrete probability measure with prior probability one).
One can also directly plug-in an estimator Fn of F in (2)  such as the empirical distribution  and
randomize only m from its posterior. This provides an estimate of both the ATE (2) and CATE (3) 
but is only suitable for uncertainty quantiﬁcation regarding the CATE. Not randomizing F causes the
posterior to ignore the uncertainty in the features  leading to an underestimation of the variance for
ψ. The resulting credible intervals will then be too narrow  giving wrong uncertainty quantiﬁcation
as we see in the supplementary material. The message here is that even when different (empirical)
Bayes methods give equally good estimation  as these two do  one must be careful about assuming
that ﬁner aspects of the posteriors behave similarly well  for example uncertainty quantiﬁcation.
In summary  we view the prior modiﬁcation (4) as a way to increase the efﬁciency of a given Bayesian
prior for estimating the ATE and CATE.
A related approach is Bayesian Causal Forests (BCF) [15]  where the estimated PS is directly added
as an additional input feature to a BART model  yielding better performance. This approach is
designed to improve nonparametric estimation of the entire response surface (i.e. the heterogeneous
treatment effects themselves)  which will also lead to some improvement when estimating the ATE.
However  it is known that even when the prior is perfectly calibrated (i.e. all tuning parameters are
set optimally) and recovers the entire response surface at the optimal rate  the posterior can still
induce a bias in the marginal posterior for the ATE ψ that prevents efﬁcient estimation and destroys
uncertainty quantiﬁcation (see e.g. [25]).
As discussed above  the speciﬁc form in which we include the PS in our prior (4) is very deliberate 
being motivated by semiparametric statistical theory and speciﬁcally designed for estimating the
ATE. When either the PS or response surface are especially difﬁcult to estimate  we expect that
incorporating the PS as a feature as in BCF will still induce a bias for the ATE (the theory in [25]
predicts this). We emphasize  however  that the main goal of BCF is to estimate the entire response
surface  which is a different problem to estimating the ATE we consider here. An alternative Bayesian
approach to estimating the ATE is to reparametrize the model to force π into the likelihood [14  26].

4 Gaussian process priors

In recent years  Gaussian process (GP) priors have found especial uptake in causal inference problems
[1–4  23]  for example in healthcare [11  38]. We therefore concretely illustrate the prior (4) for W a
mean-zero GP with covariance kernel K  λ ∼ N (0  1) independent and scaling parameter νn > 0 to
be deﬁned below. Under the prior (4)  m is again a mean-zero GP with data-driven covariance kernel
Em(x  r)m(x(cid:48)  r(cid:48)) = K((x  r)  (x(cid:48)  r(cid:48))) + ν2

(cid:19)(cid:18) r(cid:48)

(cid:18) r

(cid:19)

. (5)

− 1 − r
1 − ˆπ(x)

− 1 − r(cid:48)
1 − ˆπ(x(cid:48))

ˆπ(x(cid:48))

n

ˆπ(x)

For GPs  our debiasing corresponds to a simple and easy to implement modiﬁcation to the covariance
kernel. One should use the original covariance kernel K that was considered suitable for estimating
m (e.g. squared exponential  Matérn)  since accurately modelling the regression surface is also
necessary.

5

For our simulations in Section 5  we compute ˆπ using logistic regression based on the same data 
truncating our estimator to [0.1  0.9] for numerical stability in (5). We take K equal to the squared
exponential kernel (also called radial basis function) with automatic relevance determination (ARD) 

(cid:32)

− 1
2

d(cid:88)

(cid:33)

(cid:18)

(xi − x(cid:48)
i)2
(cid:96)2
i

exp

− 1
2

(r − r(cid:48))2

(cid:96)2
d+1

(cid:19)

K((x  r)  (x(cid:48)r(cid:48))) = ρ2

m exp

i=1 the length scale parameters and ρ2

i=1
with ((cid:96)i)d+1
m > 0 the kernel variance [24]. The data-driven
length scales (cid:96)i can be interpreted as the relevance of the ith feature to the regression surface m
and are particularly important for high-dimensional data  where some features may play little role.
ARD has been used successfully for removing irrelevant inputs by several authors (see Chapter 5.1
[24]) and can thus be viewed as a form of automatic (causal) feature selection. We optimize the
hyperparameters ((cid:96)i)d+1
i=1   ρm and σn (noise variance) by maximizing the marginal likelihood (using
the scaled conjugate gradient method option in the GPy package). We set νn = 0.2ρm/(
nMn) for
i=1[Ri/ˆπ(Xi) + (1 − Ri)/(1 − ˆπ(Xi))] the average absolute value of the last part of
(5). This places the second term in (5) on the same scale as the original covariance kernel K.
We assign F|Dn the Bayesian bootstrap (BB) distribution [12]  namely a Dirichlet process with base
i=1 δXi of the observations. When n is moderate
or large  the BB distribution will be very close to that of the true DP posterior. The advantage
of the BB is that samples are particularly easy to generate: using that F|Dn can be represented
i=1 ViδXi for (V1  . . .   Vn) ∼ Dir(n; 1  . . .   1) and that m and F are independent under the

Mn = n−1(cid:80)n
measure equal to the rescaled empirical measure(cid:80)n
as(cid:80)n

√

n(cid:88)

i=1

posterior  the posterior mean and draws for the ATE can be written as
E[ψ|Dn] =

E [m(Xi  1) − m(Xi  0)|Dn]   ψ|Dn =

respectively. Using the representation Vi = Ui/(cid:80)n

1
n

i=1

n(cid:88)

j=1 Uj for Ui ∼iid exp(1)  sampling (V1  . . .   Vn)
is particularly simple. One also needs to generate an n-dimensional multivariate Gaussian random
variable (m(Xi  1) − m(Xi  0))n
i=1  whose covariance can be directly obtained from the posterior
GP process (m(x  r) : x ∈ Rd  r ∈ {0  1})|Dn evaluated at the observations and their counterfactual
values. This follows from the usual formula for the mean and covariance of a posterior GP in
regression with Gaussian noise (Chapter 2.2 of [24]) and the whole procedure is summarized in
Algorithm 11. Using this scheme  we may sample directly from the marginal posterior for the ATE ψ.
To show the importance of randomizing F for uncertainty quantiﬁcation  we also consider the
i=1 δXi for F in (2). This yields the same
posterior mean as in (6)  while sampling ψ|Dn corresponds to the right-hand side of (6) with Vi
replaced by 1/n. We expect this to yield similar prediction to the posterior mean in (6) but worse
uncertainty quantiﬁcation for the ATE (but not CATE). This is indeed what we see in the supplement.

posterior where one plugs in the empirical measure n−1(cid:80)n

Vi (m(Xi  1) − m(Xi  0))   (6)

5 Simulations

We numerically illustrate the improved performance of our debiased GP method (GP+PS) versus
the original GP approach  both with (GP and GP+PS) and without randomization (GP (noRand)
and GP + PS (noRand)) of the feature distribution F . The methods are implemented as described
in Section 4. Credible intervals are computed by sampling 2 000 posterior draws and taking the
empirical 95% credible interval  see Figure 1. We measure estimation accuracy via the absolute error
between the posterior mean and true (C)ATE. We also report the average size and coverage of the
resulting credible/conﬁdence intervals (CI) and the Type II error  which measures the fraction of
times the method does not identity a statistically signiﬁcant (C)ATE.
We further compare their performance with standard state-of-art-methods for estimating the ATE and
CATE  namely Bayesian Additive Regression Trees (BART) [10  18  15] both with and without using
the PS as a feature  Bayesian Causal Forests (BCF) [15]  Causal Forests (CF) with average inverse

1Lines 8-9 in Algorithm 1 are the usual predictive mean and covariance computations for a posterior GP.
In particular  these can be more efﬁciently solved using for example Cholesky factorization  see Chapter 2.2
of [24]. Similarly  m can be efﬁciently generated by once taking the Cholesky factor LΣ of Σ  generating
W ∼ N2n(0  I2n) and setting m = µ + LΣW

6

Algorithm 1 Debiased GP with PS correction
1: Input: X (features)  R (treatment assignments)  Y (outcomes)  K (covariance kernel)
2: Run logistic regression on (X1  R1)  . . .   (Xn  Rn) and return estimates ˆπ(X1)  . . .   ˆπ(Xn)
3: wf =

(factual)

(cid:16) R1
(cid:16) 1−R1
ˆπ(X1) − 1−R1
ˆπ(X1) − R1
(cid:18)X

ˆπ(Xn) − 1−Rn
1−ˆπ(X1)   . . .   Rn
1−ˆπ(Xn)
ˆπ(Xn) − Rn
1−ˆπ(X1)   . . .   1−Rn
(cid:19)
4: wc =
1−ˆπ(Xn)
5: Optimize hyperparameters of k (including σ2
6: Z = (X R) and Z∗ =

n) and then ν2 (see Section 4)

(counterfactual)

(cid:17)
(cid:17)

nIn]−1Y

R
X 1 − R
7: K f c = K(Z∗  Z) + ν2(wf wc)T wf
8: µ = K f c[K(Z  Z) + ν2wf
T wf + σ2
9: Σ = K(Z∗  Z∗) + ν2(wf wc)T (wf wc) − K f c[K(Z  Z) + ν2wf
10: Compute ˆψ = E[ψ|Dn] from µ according to the left hand side of (6)
11: for l = 1 . . . P (# posterior samples) do
12:
13:
14:
15: Compute credible interval (CI) based on quantiles of ψ1  . . .   ψP
16: Output: ˆψ (posterior mean)  CI (credible interval)  ψ1  . . .   ψP (posterior samples)

Generate (V1  . . .   Vn) ∼ Dir(n; 1  . . .   1)
Generate m ∼ N2n(µ  Σ)
Compute ψl from m and V1  . . .   Vn according to the right hand side of (6)

T wf + σ2

nIn]−1K

T
f c

(x1  ...  x100) is assigned (non-randomly) to the treatment group if(cid:80)5
generated as Y |X = x  R = r ∼ N ((cid:80)5
effect. In case (HET)  Y is generated as Y |X = x  R = r ∼ N ((cid:80)5

propensity weighting (AIPW) and targeted maximum likelihood estimation (TMLE) [39]  Propensity
Score Matching (PSM) [36]  ordinary least squares (OLS)  and Covariate Balancing (CB) with the
standard inverse PS weights and weights computed by constrained minimization (CM) [9]. Details of
these benchmarks are provided in the supplementary material. We ran all simulations 200 times and
report average values.
Synthetic dataset. We consider two versions of synthetic data generated following the protocol used
iid∼ N (0  1).
in [21  22  37]. We take sample sizes n = 500  1000 and d = 100 features x1  x2  ...  x100
The response surface and treatment assignments are deﬁned via the following ten functions: g1(x) =
x − 0.5  g2(x) = (x − 0.5)2 + 2  g3(x) = x2 − 1/3  g4(x) = −2 sin(2x)  g5(x) = e−x − e−1 − 1 
g6(x) = e−x  g7(x) = x2  g8(x) = x  g9(x) = Ix>0  g10(x) = cos(x). A subject with features x =
k=1 gk(xk) > 0 and otherwise
to the control group. Given the features and treatment assignment  in case (HOM) the outcome Y is
k=1 gk+5(xk)+r  1)  which models a homogeneous treatment
k=1 gk+5(xk) + r(1 + 2x2x5)  1) 
which models heterogeneous treatment effects. In both cases  the ﬁrst ﬁve features affect both the
treatment and outcome  representing confounders  while the remaining 95 features are noise. The
ATE is 1 in both cases. Some results are in Table 1 with the remainder in the supplement.
IHDP dataset with simulated outcomes. Since simulated covariates often do not accurately repre-
sent “real world” examples  we consider a semi-synthetic dataset with real features and treatment
assignments from the Infant Health and Development Program (IHDP)  but simulated responses.
The IHDP consisted of a randomized experiment studying whether low-birth-weight and premature
infants beneﬁted from intensive high-quality child care. The data contains d = 25 pretreatment
variables per subject. Following [18] (also used in [2  21])  an observational study is created by
removing a non-random portion of the treatment group  namely all children with non-white mothers.
This leaves a dataset of 747 subjects  with 139 in the treatment group and 608 in the control group.
We consider a slight modiﬁcation of the non-linear “Response Surface B” of [18]  taking

Y (0)|X = x ∼ N (e(x+w)β  1)

and Y (1)|X = x ∼ N (xT β − ωβ  1) 

where x ∈ Rd are the features  w = (0.5  . . .   0.5) is an offset vector  β is a vector of regres-
sion coefﬁcients with each entry randomly sampled from {0  0.1  0.2  0.3  0.4} with probabilities
(0.6  0.1  0.1  0.1  0.1). For each simulation of β  ωβ is then selected so that the CATE equals 4.
Here  we can only measure estimation quality of the CATE and not the ATE since the true feature
distribution F is unknown. Results are in Table 2.

7

Table 1: Results for synthetic dataset (HET) with n = 1000.

Abs. error± sd Size CI± sd
Coverage Type II error
Method
0.613 ± 0.027
0.321 ± 0.027
0.38
GP
0.321 ± 0.027
0.427 ± 0.017
0.00
GP (noRand)
0.063 ± 0.042 0.883 ± 0.040 1.00
GP PS
GP PS (noRand) 0.063 ± 0.042 0.766 ± 0.037 1.00
1.723 ± 0.490 1.00
0.228 ± 0.186
BART
0.741 ± 0.079
0.134 ± 0.092
BART (PS)
0.99
0.144 ± 0.109
0.535 ± 0.066
BCF
0.87
0.138 ± 0.097 0.695 ± 0.103 0.96
CF (AIPW)
0.136 ± 0.099
CF (TMLE)
0.99
0.725 ± 0.160
0.00
OLS
0.606 ± 0.324
0.68
CB (IPW)
0.234 ± 0.178
PSM
0.97

0.891 ± 0.156
0.361 ± 0.034
1.467 ± 0.418
1.282 ± 0.158

0.00
0.00
0.00
0.00
0.50
0.00
0.00
0.00
0.01
0.26
0.01
0.06

Table 2: Results for semi-synthetic IHDP dataset.

Coverage Type II error

Abs. error± sd Size CI± sd
Method
0.246 ± 0.398
1.383 ± 1.458
GP
0.95
1.096 ± 1.305
0.246 ± 0.398
GP (noRand)
0.89
1.445 ± 1.013
0.189 ± 0.234
GP + PS
0.97
GP +PS (noRand) 0.189 ± 0.234
1.162 ± 0.822
0.93
0.945 ± 0.745
0.234 ± 0.282
0.91
BART
0.238 ± 0.342
0.906 ± 0.682
BART (PS)
0.89
0.108 ± 0.106 0.526 ± 0.151 0.95
BCF
0.245 ± 0.236
1.052 ± 0.811
0.91
CF (AIPW)
0.242 ± 0.240
1.087 ± 0.842
0.91
CF (TMLE)
0.127 ± 0.101
0.815 ± 0.537
OLS
0.98
0.238 ± 0.180
1.200 ± 0.860
CB (IPW)
0.91
0.961 ± 0.765
0.134 ± 0.117
CB (CM)
0.93
0.136 ± 0.108
2.052 ± 1.701 1.00
PSM

0.01
0.01
0.01
0.01
0.00
0.00
0.00
0.01
0.01
0.00
0.00
0.00
0.01

Both of these simulations contain unbalanced treatment groups  with roughly 90% and 20% of subjects
in the treatment group in the synthetic and IHDP simulations  respectively. Like PS reweighting-
based methods  our bias corrected GP method (5) is designed with problems satisfying the standard
overlap assumption [19] (namely 0 < P (R = 1|X = x) < 1 for all x ∈ Rd) in mind. In the
synthetic simulation the treatment assignment is fully deterministic so this condition is not satisﬁed;
in particular the data generation process was not selected to favour our method.
Results. We see from Tables 1 and 2 that our methods (GP + PS and GP + PS (noRand)) substantially
improve upon the performance of the vanilla GP methods (GP and GP (noRand)) [also true in the
additional simulations in the supplement]. In both cases we obtain signiﬁcantly improved estimation
accuracy and uncertainty quantiﬁcation. As an example of what can go wrong  in the synthetic
simulation the absolute errors of the vanilla GP methods barely decrease as the sample size increases
(Table 1 and the supplementary tables) since the posterior for the ATE contains a non-vanishing
bias. Moreover  since the posterior variance shrinks rapidly with the sample size (at rate 1/n for the
ATE [25])  the posterior will concentrate tightly around the wrong value  giving poor uncertainty
quantiﬁcation that actually worsens with increasing data  see Figure 1 and Table 1. This is a typical
aspect of causal inference problems with difﬁcult to estimate PS and response surfaces  particularly

8

in high feature dimensions. In contrast  our debiased method explicitly corrects for this bias at
the expense of a (smaller) increase in variance  as can be seen from the average CI length. The
substantially improved coverage from our method is the result of the debiasing rather than the increase
in posterior variance.
Asymptotic theory predicts the frequentist coverage of our method should converge to exactly 0.95 as
the sample size increases due to the semiparametric Bernstein-von Mises theorem [25]. However  it
is a subtle question as to when the asymptotic regime applies and our examples seem insufﬁciently
data rich for this to be the case (e.g. d = 100 input features  but only n = 1000 observations).
We see that our method makes the previously underperforming GP method highly competitive with
state-of-the-art methods  even outperforming them in certain cases. In the synthetic simulation  our
method performs best yielding substantially better estimation accuracy. It further provides reliable
and informative uncertainty quantiﬁcation  performing similarly to BART (PS)  CF (AIPW) and CF
(TMLE). On the IHDP dataset  our debiased methods outperform the widely used BART and CF for
estimation accuracy  but BCF performs best. While OLS and CB (CM) also performed well here  we
note that in the synthetic simulation  OLS performed especially badly while CB (CM) did not even
run. Regarding uncertainty quantiﬁcation  our method provides excellent coverage though larger CIs
than BART (whose coverage is slightly lower)  but BCF again performs best.
We lastly note that not randomizing the feature distribution (noRand) yields narrower CIs and lower
coverage as expected. This does not make a substantial difference in Tables 1 and 2  but can have a
signiﬁcant impact  see the tables in the supplement. We recall that randomization is generally helpful
for uncertainty quantiﬁcation for the ATE  but is conservative for the CATE.

6 Discussion

We have introduced a general data-driven modiﬁcation that can be applied to any given prior that
corrects for ﬁrst-order posterior bias when estimating (conditional) average treatment effects (ATEs)
in a causal inference regression model. We illustrated this experimentally on both simulated and
semi-synthetic data for the example of Gaussian process (GP) priors. We showed that by correctly
incorporating an estimate of the propensity score into the covariance kernel  one can substantially
improve the precision of both the posterior mean and posterior uncertainty quantiﬁcation. In particular 
this makes the modiﬁed GP method highly competitive with state-of-the-art methods.
There are many avenues for future work. First  GP methods scale poorly with data size and there has
been extensive research on scalable alternatives  including sparse GP approximations  variational
Bayes and distributed computing approaches. Since in the GP case our approach simply returns a
GP with modiﬁed covariance kernel  all these existing methods should be directly applicable and
can be investigated. Second  it would be particularly interesting to see if our prior correction can be
efﬁciently implemented to improve the already excellent performance of BART and its derivatives in
causal inference problems [15  18]. Third  it is unclear if and how one can perform higher order bias
corrections using Bayes for especially difﬁcult problems as has been done using estimating equations
[28  29].
Acknowledgements: Botond Szabó received funding from the Netherlands Organization for Scien-
tiﬁc Research (NWO) under Project number: 639.031.654. We thank 3 reviewers for their useful
comments that helped improve the presentation of this work.

References
[1] ALAA  A.  AND VAN DER SCHAAR  M. Limits of estimating heterogeneous treatment effects:
Guidelines for practical algorithm design. In Proceedings of the 35th International Conference
on Machine Learning (2018)  pp. 129–138.

[2] ALAA  A. M.  AND VAN DER SCHAAR  M. Bayesian inference of individualized treatment
effects using multi-task Gaussian processes. In Advances in Neural Information Processing
Systems 30. 2017  pp. 3424–3432.

[3] ALAA  A. M.  AND VAN DER SCHAAR  M. Deep multi-task Gaussian processes for survival
analysis with competing risks. In Advances in Neural Information Processing Systems 30. 2017 
pp. 2329–2337.

9

[4] ANTONELLI  J.  AND DOMINICI  F. A Bayesian semiparametric framework for causal inference

in high-dimensional data. arXiv e-prints (May 2018)  arXiv:1805.04899.

[5] ATHEY  S.  IMBENS  G.  PHAM  T.  AND WAGER  S. Estimating average treatment effects:
Supplementary analyses and remaining challenges. American Economic Review 107  5 (May
2017)  278–81.

[6] BRODERSEN  K. H.  GALLUSSER  F.  KOEHLER  J.  REMY  N.  AND SCOTT  S. L. Inferring
causal impact using Bayesian structural time-series models. Ann. Appl. Stat. 9  1 (2015) 
247–274.

[7] CASTILLO  I. Semiparametric bernstein–von mises theorem and bias  illustrated with gaussian

process priors. Sankhya A 74  2 (Aug 2012)  194–221.

[8] CASTILLO  I.  AND ROUSSEAU  J. A Bernstein–von Mises theorem for smooth functionals in

semiparametric models. Ann. Statist. 43  6 (2015)  2353–2383.

[9] CHAN  K. C. G.  YAM  S. C. P.  AND ZHANG  Z. Globally efﬁcient non-parametric inference
of average treatment effects by empirical balancing calibration weighting. Journal of the Royal
Statistical Society: Series B (Statistical Methodology) 78  3 (2016)  673–700.

[10] CHIPMAN  H. A.  GEORGE  E. I.  AND MCCULLOCH  R. E. BART: Bayesian additive

regression trees. Ann. Appl. Stat. 4  1 (03 2010)  266–298.

[11] FUTOMA  J.  HARIHARAN  S.  AND HELLER  K. Learning to detect sepsis with a multitask
Gaussian process RNN classiﬁer. In Proceedings of the 34th International Conference on
Machine Learning (2017)  pp. 1174–1182.

[12] GHOSAL  S.  AND VAN DER VAART  A. W. Fundamentals of Nonparametric Bayesian
Inference. Cambridge Series in Statistical and Probabilistic Mathematics. Cambridge University
Press  Cambridge  2017.

[13] GREEN  D. P.  AND KERN  H. L. Modeling Heterogeneous Treatment Effects in Survey
Experiments with Bayesian Additive Regression Trees. Public Opinion Quarterly 76  3 (09
2012)  491–511.

[14] HAHN  P. R.  CARVALHO  C. M.  PUELZ  D.  AND HE  J. Regularization and confounding in

linear regression for treatment effect estimation. Bayesian Anal. 13  1 (2018)  163–182.

[15] HAHN  P. R.  MURRAY  J. S.  AND CARVALHO  C. Bayesian regression tree models for causal
inference: regularization  confounding  and heterogeneous effects. arXiv e-prints (Jun 2017) 
arXiv:1706.09523.

[16] HECKMAN  J. J.  ICHIMURA  H.  AND TODD  P. Matching As An Econometric Evaluation

Estimator. The Review of Economic Studies 65  2 (04 1998)  261–294.

[17] HILL  J.  AND SU  Y.-S. Assessing lack of common support in causal inference using Bayesian
nonparametrics: implications for evaluating the effect of breastfeeding on children’s cognitive
outcomes. Ann. Appl. Stat. 7  3 (2013)  1386–1420.

[18] HILL  J. L. Bayesian nonparametric modeling for causal inference. J. Comput. Graph. Statist.

20  1 (2011)  217–240. Supplementary material available online.

[19] IMBENS  G. W.  AND RUBIN  D. B. Causal Inference for Statistics  Social  and Biomedical

Sciences: An Introduction. Cambridge University Press  New York  NY  USA  2015.

[20] KERN  H. L.  STUART  E. A.  HILL  J.  AND GREEN  D. P. Assessing methods for generalizing
experimental impact estimates to target populations. Journal of Research on Educational
Effectiveness 9  1 (2016)  103–127. PMID: 27668031.

[21] LI  S.  AND FU  Y. Matching on balanced nonlinear representations for treatment effects

estimation. In Advances in Neural Information Processing Systems 30. 2017  pp. 929–939.

10

[22] LI  S.  VLASSIS  N.  KAWALE  J.  AND FU  Y. Matching via dimensionality reduction
In Proceedings of the
for estimation of treatment effects in digital marketing campaigns.
Twenty-Fifth International Joint Conference on Artiﬁcial Intelligence (2016)  pp. 3768–3774.

[23] MUELLER  J.  RESHEF  D.  DU  G.  AND JAAKKOLA  T. Learning Optimal Interventions.
In Proceedings of the 20th International Conference on Artiﬁcial Intelligence and Statistics
(2017)  pp. 1039–1047.

[24] RASMUSSEN  C. E.  AND WILLIAMS  C. K. I. Gaussian processes for machine learning.

Adaptive Computation and Machine Learning. MIT Press  Cambridge  MA  2006.

[25] RAY  K.  AND VAN DER VAART  A. W. Semiparametric Bayesian causal inference. Ann.

Statist.  to appear.

[26] RITOV  Y.  BICKEL  P. J.  GAMST  A. C.  AND KLEIJN  B. J. K. The Bayesian analysis of

complex  high-dimensional models: can it be CODA? Statist. Sci. 29  4 (2014)  619–639.

[27] RIVOIRARD  V.  AND ROUSSEAU  J. Bernstein-von Mises theorem for linear functionals of

the density. Ann. Statist. 40  3 (2012)  1489–1523.

[28] ROBINS  J.  LI  L.  TCHETGEN  E.  AND VAN DER VAART  A. Higher order inﬂuence
functions and minimax estimation of nonlinear functionals. In Probability and statistics: essays
in honor of David A. Freedman  vol. 2 of Inst. Math. Stat. (IMS) Collect. Inst. Math. Statist. 
Beachwood  OH  2008  pp. 335–421.

[29] ROBINS  J. M.  LI  L.  MUKHERJEE  R.  TCHETGEN  E. T.  AND VAN DER VAART  A.
Minimax estimation of a functional on a structured high-dimensional model. Ann. Statist. 45  5
(2017)  1951–1987.

[30] ROBINS  J. M.  AND RITOV  Y. Toward a curse of dimensionality appropriate (CODA)
asymptotic theory for semi-parametric models. Statistics in Medicine 16  3 (1997)  285–319.

[31] ROBINS  J. M.  AND ROTNITZKY  A. Semiparametric efﬁciency in multivariate regression

models with missing data. J. Amer. Statist. Assoc. 90  429 (1995)  122–129.

[32] ROSENBAUM  P. R.  AND RUBIN  D. B. The central role of the propensity score in observa-

tional studies for causal effects. Biometrika 70  1 (1983)  41–55.

[33] ROTNITZKY  A.  AND ROBINS  J. M. Semi-parametric estimation of models for means and

covariances in the presence of missing data. Scand. J. Statist. 22  3 (1995)  323–333.

[34] RUBIN  D. B. Bayesian inference for causal effects: the role of randomization. Ann. Statist. 6 

1 (1978)  34–58.

[35] SIVAGANESAN  S.  MÜLLER  P.  AND HUANG  B. Subgroup ﬁnding via Bayesian additive

regression trees. Stat. Med. 36  15 (2017)  2391–2403.

[36] STUART  E. A. Matching methods for causal inference: a review and a look forward. Statist.

Sci. 25  1 (2010)  1–21.

[37] SUN  W.  WANG  P.  YIN  D.  YANG  J.  AND CHANG  Y. Causal inference via sparse additive
models with application to online advertising. In Twenty-Ninth AAAI Conference on Artiﬁcial
Intelligence (2015).

[38] URTEAGA  I.  ALBERS  D. J.  WHEELER  M. V.  DRUET  A.  RAFFAUF  H.  AND ELHADAD 
N. Towards Personalized Modeling of the Female Hormonal Cycle: Experiments with Mecha-
nistic Models and Gaussian Processes. NIPS 2017 Workshop: “Machine Learning for Health”
(2017).

[39] WAGER  S.  AND ATHEY  S. Estimation and inference of heterogeneous treatment effects using
random forests. Journal of the American Statistical Association 113  523 (2018)  1228–1242.

11

,Kolyan Ray
Botond Szabo