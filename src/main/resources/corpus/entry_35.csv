2011,A Collaborative Mechanism for Crowdsourcing Prediction Problems,Machine Learning competitions such as the Netflix Prize have proven reasonably successful as a method of “crowdsourcing” prediction tasks. But these compe- titions have a number of weaknesses  particularly in the incentive structure they create for the participants. We propose a new approach  called a Crowdsourced Learning Mechanism  in which participants collaboratively “learn” a hypothesis for a given prediction task. The approach draws heavily from the concept of a prediction market  where traders bet on the likelihood of a future event. In our framework  the mechanism continues to publish the current hypothesis  and par- ticipants can modify this hypothesis by wagering on an update. The critical in- centive property is that a participant will profit an amount that scales according to how much her update improves performance on a released test set.,A Collaborative Mechanism for Crowdsourcing

Prediction Problems

Jacob Abernethy

Division of Computer Science

University of California at Berkeley

jake@cs.berkeley.edu

Rafael M. Frongillo

Division of Computer Science

University of California at Berkeley

raf@cs.berkeley.edu

Abstract

Machine Learning competitions such as the Netﬂix Prize have proven reasonably
successful as a method of “crowdsourcing” prediction tasks. But these compe-
titions have a number of weaknesses  particularly in the incentive structure they
create for the participants. We propose a new approach  called a Crowdsourced
Learning Mechanism  in which participants collaboratively “learn” a hypothesis
for a given prediction task. The approach draws heavily from the concept of a
prediction market  where traders bet on the likelihood of a future event. In our
framework  the mechanism continues to publish the current hypothesis  and par-
ticipants can modify this hypothesis by wagering on an update. The critical in-
centive property is that a participant will proﬁt an amount that scales according to
how much her update improves performance on a released test set.

1

Introduction

The last several years has revealed a new trend in Machine Learning: prediction and learning prob-
lems rolled into prize-driven competitions. One of the ﬁrst  and certainly the most well-known  was
the Netﬂix prize released in the Fall of 2006. Netﬂix  aiming to improve the algorithm used to pre-
dict users’ preferences on its database of ﬁlms  released a dataset of 100M ratings to the public and
asked competing teams to submit a list of predictions on a test set withheld from the public. Netﬂix
offered $1 000 000 to the ﬁrst team achieving prediction accuracy exceeding a given threshold  a
goal that was eventually met. This competitive model for solving a prediction task has been used
for a range of similar competitions since  and there is even a new company (kaggle.com) that
creates and hosts such competitions. Such prediction competitions have proven quite valuable for
a couple of important reasons: (a) they leverage the abilities and knowledge of the public at large 
commonly known as “crowdsourcing”  and (b) they provide an incentivized mechanism for an indi-
vidual or team to apply their own knowledge and techniques which could be particularly beneﬁcial
to the problem at hand. This type of prediction competition provides a nice tool for companies and
institutions that need help with a given prediction task yet can not afford to hire an expert. The po-
tential leverage can be quite high: the Netﬂix prize winners apparently spent more than $1 000 000
in effort on their algorithm alone.
Despite the extent of its popularity  is the Netﬂix competition model the ideal way to “crowdsource”
a learning problem? We note several weaknesses:
It is anti-collaborative. Competitors are strongly incentivized to keep their techniques private.
This is in stark contrast to many other projects that rely on crowdsourcing – Wikipedia being a
prime example  where participants must build off the work of others. Indeed  in the case of the
Netﬂix prize  not only do leading participants lack incentives to share  but the work of non-winning
competitors is effectively wasted.

1

The incentives are skewed and misaligned. The winner-take-all prize structure means that sec-
ond place is as good as having not competed at all. This ultimately leads to an equilibrium where
only a few teams are actually competing  and where potential new teams never form since catching
up seems so unlikely. In addition  the ﬁxed achievement benchmark  set by Netﬂix as a 10% im-
provement in prediction RMSE over a baseline  leads to misaligned incentives. Effectively  the prize
structure implies that an improvement of %9.9 percent is worth nothing to Netﬂix  whereas a 20%
improvement is still only worth $1 000 000 to Netﬂix. This is clearly not optimal.
The nature of the competition precludes the use of proprietary methods. By requiring that the
winner reveal the winning algorithm  potential competitors utilizing non-open software or propri-
etary techniques will be unwilling to compete. By participating in the competition  a user must
effectively give away his intellectual property.
In this paper we describe a new and very general mechanism to crowdsource prediction/learning
problems. Our mechanism requires participants to place bets  yet the space they are betting over
is the set of hypotheses for the learning task at hand. At any given time the mechanism publishes
the current hypothesis w and participants can wager on a modiﬁcation of w to w(cid:48)  upon which the
modiﬁed w(cid:48) is posted. Eventually the wagering period ﬁnishes  a set of test data is revealed  and
each participant receives a payout according to their bets. The critical property is that every trader’s
proﬁt scales according to how well their modiﬁcation improved the solution on the test data.
The framework we propose has many qualities similar to that of an information or prediction market 
and many of the ideas derive from recent research on the design of automated market makers [7  8 
3  4  1]. Many information markets already exist; at sites like Intrade.com and Betfair.com 
individuals can bet on everything ranging from election outcomes to geopolitical events. There has
been a burst of interest in such markets in recent years  not least of which is due to their potential
for combining large amounts of information from a range of sources. In the words of Hanson et
al [9]: “Rational expectations theory predicts that  in equilibrium  asset prices will reﬂect all of
the information held by market participants. This theorized information aggregation property of
prices has lead economists to become increasingly interested in using securities markets to predict
future events.” In practice  prediction markets have proven impressively accurate as a forecasting
tool [11  2  12].
The central contribution of the present paper is to take the framework of a prediction market as a
tool for information aggregation and to apply this tool for the purpose of “aggregating” a hypothesis
(classiﬁer  predictor  etc.) for a given learning problem. The crowd of ML researchers  practitioners 
and domain experts represents a highly diverse range of expertise and algorithmic tools. In contrast
to the Netﬂix prize  which pitted teams of participants against each other  the mechanism we propose
allows for everyone to contribute whatever knowledge they may have available towards the ﬁnal
solution. In a sense  this approach decentralizes the process of solving the task  as individual experts
can potentially apply their expertise to a subset of the problem on which they have an advantage.
Whereas a market price can be thought of as representing a consensus estimate of the value of an
asset  our goal is to construct a consensus hypothesis reﬂecting all the knowledge and capabilities
about a particular learning problem1.
Layout: We begin in Section 2.1 by introducing the simple notion of a generalized scoring rule
L(· ·) representing the “loss function” of the learning task at hand. In Section 2.2 we describe our
proposed Crowdsourced Learning Mechanism (CLM) in detail  and discuss how to structure a CLM
for a particular scoring function L  in order that the traders are given incentives to minimize L.
In Section 3 we give an example based on the design of Huffman codes. In Section 4 we discuss
previous work on the design of prediction markets using an automated prediction market maker
(APMM). In Section 5 we ﬁnish by considering two learning settings (e.g. linear regression) and we
construct a CLM for each. The proofs have been omitted throughout  but these are available in the
full version of the present paper.
Notation: Given a smooth strictly convex function R : Rd → R  and points x  y ∈ dom(R)  we
deﬁne the Bregman divergence DR(x  y) as the quantity R(x) − R(y) − ∇R(y) · (x − y). For any
convex function R  we let R∗ denote the convex conjugate of R  that is R∗(y) := supx∈dom(R) y ·
x − R(x). We shall use ∆(S) to refer to the set of integrable probability distributions over the set

1It is worth noting that Barbu and Lay utilized concepts from prediction markets to design algorithms for

classiﬁer aggregation [10]  although their approach was unrelated to crowdsourcing.

2

denote the entropy function  that is H(p) := −(cid:80)n
that is KL(p; q) :=(cid:80)n

S  and ∆n to refer to the set of probability vectors p ∈ Rn. The function H : ∆n → R shall
i=1 p(i) log p(i). We use the notation KL(p; q)
to describe the relative entropy or Kullback-Leibler divergence between distributions p  q ∈ ∆n 
q(i) . We will also use ei ∈ Rn to denote the ith standard basis

i=1 p(i) log p(i)

vector  having a 1 in the ith coordinate and 0’s elsewhere.

2 Scoring Rules and Crowdsourced Learning Mechanisms

2.1 Generalized Scoring Rules
For the remainder of this section  we shall let H denote some set of hypotheses  which we will
assume is a convex subset of Rn. We let O be some arbitrary set of outcomes. We use the symbol
X to refer to either an element of O  or a random variable taking values in O.
We recall the notion of a scoring rule  a concept that arises frequently in economics and statistics [6].
Deﬁnition 1. Let P ⊆ ∆(O) be some convex set of distributions on an outcome space O. A scoring
rule is a function S : P × O → R where  for all P ∈ P  P ∈ argmaxQ∈P EX∼P S(Q  X).
In other words  if you are paid S(P  X) upon stating belief P ∈ P and outcome X occurring  then
you maximize your expected utility by stating your true belief. We offer a much weaker notion:
Deﬁnition 2. Given a convex hypothesis space H ⊂ Rn and an outcome space O  let L : H×O →
R be a continuous function. Given any P ∈ ∆(O)  let WL(P ) := argminw∈H EX∼P [L(w; X)].
Then we say that L is a Generalized Scoring Rule (GSR) if WL(P ) is a nonempty convex set for
every P ∈ ∆(O).
The generalized scoring rule shall represent the “loss function” for the learning problem at hand 
and in Section 2.2 we will see how L is utilized in the mechanism. The hypothesis w shall represent
the advice we receive from the crowd  X shall represent the test data to be revealed at the close of
the mechanism  and L(w; X) shall represent the loss of the advised w on the data X. Notice that
we do not deﬁne L to be convex in its ﬁrst argument as this does not hold for many important cases.
Instead  we require the weaker condition that EX [L(w; X)] is minimized on a convex set for any
distribution on X.
Our scoring rule differs from traditional scoring rules in an important way. Instead of starting with
the desire know about the true value of X  and then designing a scoring rule which incentivizes
participants to elicit their belief P ∈ P  our objective is precisely to minimize our scoring rule.
In other words  traditional scoring rules were a means to an end (eliciting P ) but our generalized
scoring rule is the end itself. One can recover the traditional scoring rule deﬁnition by setting H = P
and imposing the constraint that P ∈ WL(P ).
A useful class of GSRs L are those based on a Bregman divergence.
Deﬁnition 3. We say that a GSR L : H × O → R is divergence-based if there exists an alternative
hypothesis space H(cid:48) ⊂ Rm  for some m  where we can write

L(w; X) ≡ DR(ρ(X)  ψ(w)) + f (X)

(1)
for arbitrary maps ρ : O → H(cid:48)  f : O → R  and ψ : H → H(cid:48)  and any closed strictly convex
R : H(cid:48) → R whose convex conjugate R∗ is ﬁnite on all of Rm.
This property allows us to think of L(w; X) as a kind of distance between ρ(X) and ψ(w). Clearly
then  the minimum value of L for a given X will be attained when ψ(w) = ρ(X)  given that
DR(x  x) = 0 for any Bregman divergence. In fact  as the following proposition shows  we can
even think of the expected value E[L(w; X)]  as a distance between E[ρ(X)] and ψ(w).
Proposition 1. Given a divergence-based GSR L(w; X) = DR(ρ(X)  ψ(w)) + f (X) and a belief

distribution P on O  we have WL(P ) = ψ−1(cid:0)EX∼P [ρ(X)](cid:1).

We now can see that the divergence-based property greatly simpliﬁes the task of minimizing L; in-
stead of worrying about E[L(·; X)] one can simply base the hypothesis directly on the expectation
E[ρ(X)]. As we will see in section 4  this also leads to efﬁcient prediction markets and crowdsourc-
ing mechanisms.

3

2.2 The Crowdsourced Learning Mechanism

We will now deﬁne our actual mechanism rigorously.
Deﬁnition 4. A Crowdsourced Learning Mechanism (CLM) is the procedure in Algorithm 1 as
deﬁned by the tuple (H O  Cost  Payout). The function Cost : H × H → R sets the cost charged
to a participant that makes a modiﬁcation to the posted hypothesis. The function Payout : H×H×
O → R determines the amount paid to each participant when the outcome is revealed to be X.
Algorithm 1 Crowdsourced Learning Mechanism for (H O  Cost  Payout)
1: Mechanism sets initial hypothesis to some w0 ∈ H
2: for rounds t = 0  1  2  . . . do
3: Mechanism posts current hypothesis wt ∈ H
4:
5: Mechanism charges participant Cost(wt  w(cid:48))
6: Mechanisms updates hypothesis wt+1 ← w(cid:48)
7: end for
8: Market closes after T rounds and the outcome (test data) X ∈ O is revealed
9: for each t do
10:
11: end for

Participant responsible for the update wt (cid:55)→ wt+1 receives Payout(wt  wt+1; X)

Some participant places a bid on the update wt (cid:55)→ w(cid:48)

The above procedure describes the process by which participants can provide advice to the mecha-
nism to select a good w  and the proﬁt they earn by doing so. Of course  this proﬁt will precisely
determine the incentives of our mechanism  and hence a key question is: how can we design Cost
and Payout so that participants are incentivized to provide good hypotheses? The answer is that we
shall structure the incentives around a GSR L(w; X) chosen by the mechanism designer.
Deﬁnition 5. For a CLM A = (H O  Cost  Payout)  denote the ex-post proﬁt for the bid (w (cid:55)→
w(cid:48)) when the outcome is X ∈ O by Profit(w  w(cid:48); X) := Payout(w  w(cid:48); X) − Cost(w  w(cid:48)). We
say that A implements a GSR L : H(cid:48) × O → R if there exists a surjective map ϕ : H → H(cid:48) such
that for all w1  w2 ∈ H and X ∈ O 

Profit(w1  w2; X) = L(ϕ(w1); X) − L(ϕ(w2); X).

(2)

If additionally H(cid:48) = H and ϕ = idH  we call A an L-CLM and say that A is L-incentivized.
When a CLM implements a given L  the incentives are structured in order that the participants will
work to minimize L(w; X). Of course  the input X is unknown to the participants  yet we can
assume that the mechanism has provided a public “training set” to use in a learning algorithm. The
participants are thus asked not only to propose a “good” hypothesis wt but to wager on whether the
update wt−1 (cid:55)→ wt improves generalization error. It is worth making clear that knowledge of the
true distribution on X provides a straightforward optimal strategy.
Proposition 2. Given a GSR L : H×O → R and an L-CLM (Cost  Payout)  any participant who
knows the true distribution P ∈ P over X will maximize expected proﬁt by modifying the hypothesis
to any w ∈ WL(P ).

Cost of operating a CLM.
It is clear that the agent operating the mechanism must pay the par-
ticipants at the close of the competition  and is thus at risk of losing money (in fact  it is pos-
(cid:55)→ wt+1) made by
sible he may gain). How much money is lost depends on the bets (wt
the participants  and of course the ﬁnal outcome X. The agent has a clear interest in knowing
(cid:80)T
precisely the potential cost – fortunately this cost is easy to compute. The loss to the agent is
clearly the total ex-post proﬁt earned by the participants  and by construction this sum telescopes:
t=0 Profit(wt  wt+1; X) = L(w0; X) − L(wT ; X). This is a simple yet appealing property of
the CLM: the agent pays only as much in reward to the participants as it beneﬁts from the improve-
ment of wT over the initial w0. It is worth noting that this value could be negative when wT is
actually “worse” than w0; in this case  as we shall see in section 3  the CLM can act as an insurance
policy with respect to the mistakes of the participants. A more typical scenario  of course  is where
the participants provide an improved hypothesis  in which case the CLM will run at a cost. We can
compute the WorstCaseLoss(L-CLM) := maxw∈H X∈O (L(w0; X) − L(w; X)). Given a budget

4

of size $B  the mechanism can always rescale L in order that WorstCaseLoss(L-CLM) = B. This
requires  of course  that the WorstCaseLoss is ﬁnite.

Computational efﬁciency of operating a CLM. We shall say that a CLM has the efﬁcient com-
putation (EC) property if both Cost and Payout are efﬁciently computable functions. We shall say
a CLM has the tractable trading (TT) property if  given a current hypothesis w  a belief P ∈ ∆(O)
and a budget B  one can efﬁciently compute an element of the set

(cid:110)EX∼P

(cid:2)Profit(w  w(cid:48)  X)(cid:3) : Cost(w  w(cid:48)) ≤ B

(cid:111)

.

argmin
w(cid:48)∈H

The EC property ensures that the mechanism operator can run the CLM efﬁciently. The TT property
says that participants can compute the optimal hypothesis to bet on given a belief on the outcome
and a budget. This is absolutely essential for the CLM to successfully aggregate the knowledge and
expertise of the crowd – without it  despite their motivation to lower L(; )  the participants would
not be able to compute the optimal bet.

Suitable collateral requirements. We say that a CLM has the escrow (ES) property if the Cost
and Payout functions are structured in order that  given any wager (w (cid:55)→ w(cid:48))  we have that
Payout(w  w(cid:48); X) ≥ 0 for all X ∈ O.
It is clear that  when designing an L-CLM for a par-
ticular L  the Payout function is fully speciﬁed once Cost is ﬁxed  since we have the relation
Payout(w  w(cid:48); X) = L(w; X) − L(w(cid:48); X) + Cost(w  w(cid:48)) for every w  w(cid:48) ∈ H and X ∈ O. A
curious reader might ask  why not simply set Cost(w  w(cid:48)) ≡ 0 and Payout ≡ Profit? The prob-
lem with this approach is that potentially Payout(w  w(cid:48); X) < 0 which implies that the participant
who wagered on (w (cid:55)→ w(cid:48)) can be indebted to the mechanism and could default on this obligation.
Thus the Cost function should be set in order to require every participant to deposit at least enough
collateral in escrow to cover any possible losses.

Subsidizing with a voucher pool. One practical weakness of a wagering-based mechanism is
that individuals may be hesitant to participate when it requires depositing actual money into the
system. This can be allayed to a reasonable degree by including a voucher pool where each of the
ﬁrst m participants may receive a voucher in the amount of $C. These candidates need not pay to
participate  yet have the opportunity to win. Of course  these vouchers must be paid for by the agent
running the mechanism  and hence a value of mC is added to the total operational cost.

3 A Warm-up: Compressing an Unfamiliar Data Stream

Let us now introduce a particular setting motivated by a well-known problem in information theory.
Imagine a ﬁrm is looking to do compression on an unfamiliar channel  and from this channel the
ﬁrm will receive a stream of m characters from an n-sized alphabet which we shall index by [n]. The
goal is to select a binary encoding of this alpha in such a way that minimizes the total bits required
to store the data  as a cost of $1 is required for each bit.
A ﬁrst-order approach to encode such a stream is to assign a probability distribution q ∈ ∆n to
the alphabet  and to select an encoding of character i with a binary word of length log(1/q(i)) (we
ignore round-off for simplicity). This can be achieved using Huffman Codes for example  and we
refer the reader to Cover and Thomas ([5]  Chapter 5) for more details. Thus  given a distribution
q  the ﬁrm pays L(q; i) = − log q(i) for each character i. It is easy to see that if the characters
are sampled from some “true” distribution p  then the expected cost L(q; p) := Ei∼p [L(q; i)] =
KL(p; q) + H(p)  which is minimized at q = p. Not knowing the true distribution p  the ﬁrm is
thus interested in ﬁnding a q with a low expected cost L(q; p).
An attractive option available to the ﬁrm is to crowdsource the task of lowering this cost L(·;·) by
setting up an L-CLM. It is reasonably likely that outside individuals have private information about
the behavior of the channel and  in particular  may be able to provide a better estimate q of the true
distribution of the characters in the channel. As just discussed  the better the estimate the cheaper
the compression.
We set H = ∆n and O = [n]  where a hypothesis q represents the proposed distribution over the n
characters  and X is some character sampled uniformly from the stream after it has been observed.

5

We deﬁne Cost and Payout as
Cost(q  q(cid:48)) := max
i∈[n]

log(q(i)/q(cid:48)(i)) 

Payout(q  q(cid:48); i) := log(q(i)/q(cid:48)(i)) + Cost(q  q(cid:48)) 

which is clearly an L-CLM for the loss deﬁned above. It is worth noting that L is a divergence-based
GSR if we take R(q) = −H(q)  ρ(i) = ei  f ≡ 0  ψ ≡ id∆n  using the convention 0 log 0 = 0 (in
fact  L is the LMSR). Finally  the ﬁrm will initially set q0 to be its best guess of p  which we will
assume to be uniform (but need not be).
We have devised this payout scheme according to the selection of a single character i  and it is
worth noting that because this character is sampled uniformly at random from the stream (with
private randomness)  the participants cannot know which character will be released. This forces the
participants to wager on the empirical distribution ˆp of the characters from the stream. A reasonable
alternative  and one which lowers the payment variance  is to payout according to the L(q; ˆp)  which
is also equal to the average of L(q; i) when i is chosen uniformly from the stream.
The obvious question to ask is: how does this CLM beneﬁt the ﬁrm that wants to design the encod-
ing? More precisely  if the ﬁrm uses the ﬁnal estimate qT from the mechanism  instead of the initial
guess q0  what is the trade-off between the money paid to participants and the money gained by us-
ing the crowdsourced hypothesis? At ﬁrst glance  it appears that this trade-off can be arbitrarily bad:
the worst case cost of encoding the stream using the ﬁnal estimate qT is supi qT − log(qT (i)) = ∞.
Amazingly  however  by virtue of the aligned incentives  the ﬁrm has a very strong control of its total
cost (the CLM cost plus the encoding cost). Suppose the ﬁrm scales L by a parameter α  to separate
the scale of the CLM from the scale of the encoding cost (which we assumed to be $1 per bit). Then
given any initial estimate q0 and ﬁnal estimate qT   the expected total cost over p is

(cid:122)

(cid:125)(cid:124)

(cid:123)

Encoding cost of using qT given p

(cid:122)

(cid:125)(cid:124)

Mechanism’s cost of getting advice qT

α(KL(p; q0) − KL(p; qT ))

(cid:123)

Total expected cost =

H(p) + KL(p; qT )

+

= H(p) + (1 − α)KL(p; qT ) + αKL(p; q0)

Let us spend a moment to analyze the above expression. Imagine that the ﬁrm set α = 1. Then
the total cost of the ﬁrm would be H(p) + KL(p; q0)  which is bounded by log n for q0 uniform.
Notice that this expression does not depend on qT – in fact  this cost precisely corresponds to the
scenario where the ﬁrm had not set up a CLM and instead used the initial estimate q0 to encode. In
other words  for α = 1  the ﬁrm is entirely neutral to the quality of the estimate qT ; even if the CLM
provided an estimate qT which performed worse than q0  the cost increase due to the bad choice of
q is recouped from payments of the ill-informed participants.
The ﬁrm may not want to be neutral to the estimate of the crowd  however  and under the reasonable
assumption that the ﬁnal estimate qT will improve upon q0  the ﬁrm should set 0 < α < 1 (of
course  positivity is needed for nonzero payouts). In this case  the ﬁrm will strictly gain by using the
CLM when KL(p; qT ) < KL(p; q0)  but still has some insurance policy if the estimate qT is poor.

4 Prediction Markets as a Special Case

Let us brieﬂy review the literature for the type of prediction markets relevant to the present work. In
such a prediction market  we imagine a future event to reveal one of n uncertain outcomes. Hanson
[7  8] proposed a framework in which traders make “reports” to the market about their internal
belief in the form of a distribution p ∈ ∆n. Each trader would receive a reward (or loss) based on a
function of their proposed belief and the belief of the previous trader  and the function suggested by
Hanson was the Logarithmic Market Scoring Rule (LMSR). It was shown later that the LMSR-based
market is equivalent to what is known as a cost function based automated market makers  proposed
by Chen and Pennock [3]. More recently a much broader equivalence was established by Chen and
Wortman Vaughan [4] between markets based on cost functions and those based on scoring rules.
The market framework proposed by Chen and Pennock allows traders to buy and sell Arrow-Debreu
securities (equivalently: shares  contracts)  where an Arrow-Debreu security corresponding to out-
come i pays out $1 if and only if i is realized. All shares are bought and sold through an automated
market maker  which is the entity managing the market and setting prices. At any time period  traders
can purchase bundles of contracts r ∈ Rn  where r(i) represents the number of shares purchased on

6

outcome i. The price of a bundle r is set as C(s + r) − C(s)  where C is some differentiable con-
vex cost function and s ∈ Rn is the “quantity vector” representing the total number of outstanding
shares. The LMSR cost function is C(s) := 1

η log ((cid:80)n

i=1 exp(ηs(i))).

This cost function framework was extended by Abernethy et al. [1] to deal with prohibitively large
outcome spaces. When the set of potential outcomes O is of exponential size or even inﬁnite 
the market designer can offer a restricted number of contracts  say n ((cid:28) |O|)  rather than offer
an Arrow-Debreu contract for each member of O. To determine the payout structure  the market
designer chooses a function ρ : O → Rn  where contract i returns a payout of ρi(X) and  thus  a
contract bundle r pays ρ(X) · r. As with the framework of Chen and Pennock  the contract prices
are set according to a cost function C  so that a bundle r has a price of C(s + r)− C(s). The design
of the function C is addressed at length in Abernethy et al.  to which we refer the reader.
For the remainder of this section we shall discuss the prediction market template of Abernethy et al.
as it provides the most general model; we shall refer to such a market as an Automated Prediction
Market Maker. We now precisely state the ingredients of this framework.
Deﬁnition 6. An Automated Prediction Market Maker (APMM) is deﬁned by a tuple (S O  ρ  C)
where S is the share space of the market  which we will assume to be the linear space Rn; O is the set
of outcomes; C : S → R is a smooth and convex cost function with ∇C(S) = relint(∇C(S)) (here 
we use ∇C(S) := {∇C(s) | s ∈ S} to denote the derivative space of C); and ρ : O → ∇C(S) is a
payoff function2.
Fortunately  we need not provide a full description of the procedure of the APMM mechanism: The
APMM is precisely a special case of a CLM! Indeed  the APMM framework can be described as a
CLM (H O  Cost  Payout) where

H = S(= Rn)

Cost(s  s(cid:48)) = C(s(cid:48)) − C(s)

Payout(s  s(cid:48); X) = ρ(X) · (s(cid:48) − s).

(3)

Hence we can think of APMM prediction markets in terms of our learning mechanism. Markets
of this form are an important special class of CLMs – in particular  we can guarantee that they are
efﬁcient to work with  as we show in the following proposition.
Proposition 3. An APMM (S O  ρ  C) with efﬁciently computable C satisﬁes EC and TT.
We now ask  what is the learning problem that the participants of an APMM are trying to solve?
More precisely  when we think of an APMM as a CLM  does it implement a particular L?
Theorem 1. Given APMM A := (S O  ρ  C)  then A implements L : ∇C(S)×O → R deﬁned by
(4)

L(w; X) = DC∗ (ρ(X)  w) 

where C∗ is the conjugate dual of the function C.
There is another more subtle beneﬁt to APMMs – and  in fact  to most prediction market mechanisms
in practice – which is that participants make bets via purchasing of shares or share bundles. When a
trader makes a bet  she purchases a contract bundle r  is charged C(s + r)− C(s) (when the current
quantity vector is s)  and shall receive payout ρ(X) · r if and when X is realized. But at any point
before X is observed and trading is open  the trader can sell off this bundle  to the APMM or another
trader  and hence neutralize her risk. In this sense bets made in an APMM are stateless  whereas for
an arbitrary CLM this may not be the case: the wager deﬁned by (wt (cid:55)→ wt+1) can not necessarily
be sold back to the mechanism  as the posted hypothesis may no longer remain at wt+1.
Given a learning problem deﬁned by the GSR L : H × O → R  it is natural to ask whether we
can design a CLM which implements this L and has this “share-based property” of APMMs. More
precisely  under what conditions is it possible to implement L with an APMM?
Theorem 2. For any divergence-based GSR L(w; X) = DR(ρ(X)  ψ(w)) + f (X)  with ψ : H →
H(cid:48) one-to-one  H(cid:48) = relint(H(cid:48))  and ρ(O) ⊆ ψ(H)  there exists an APMM which implements L.
We point out  as a corollary  that if an APMM implements some arbitrary L  then we must be able to
write L as a divergence function. This fully speciﬁes the class of problems solvable using APMMs.
2The conditions that ρ(O) ⊆ ∇C(S) and ∇C(S) = relint(∇C(S)) are technical but important  and we
do not address these details in the present extended abstract although they will be considered in the full version.
More relevant discussion can also be found in Abernethy et al. [1].

7

Corollary 1. If APMM (S O  ρ  C) implements a GSR L : H×O → R  then L is divergence-based.

Theorem 1 establishes a strong connection between prediction markets and a natural class of GSRs.
One interpretation of this result is that any GSR based on a Bregman divergence has a “dual” char-
acterization as a share-based market  where participants buy and sell shares rather than directly
altering the share prices (the hypothesis). This has many advantages for prediction markets  not
least of which is that shares are often easier to think about than the underlying hypothesis space.
Our notion of a CLM offers another interpretation. In light of Proposition 3  any machine learning
problem whose hypotheses can be evaluated in terms of a divergence leads to a tractable crowdsourc-
ing mechanism  as was the case in Section 3. Moreover  this theorem does not preclude efﬁcient yet
non-divergence-based loss functions as we see in the next section.

5 Example CLMs for Typical Machine Learning Tasks

α
2n

(cid:2)Profit(w  w(cid:48)  X)(cid:3) for every P . A budget-constrained proﬁt-maximizing

Regression. We now construct a CLM for a typical regression problem. We let H be the
(cid:96)2-norm ball of radius 1 in Rd  and we shall let an outcome be a batch of a data 
that is
(cid:80)n
X := {(x1  y1)  . . .   (xn  yn)} where for each i we have xi ∈ Rd  yi ∈ [−1  1]  and we as-
sume (cid:107)xi(cid:107)2 ≤ 1. We construct a GSR according to the mean squared error  L(w;{(xi  yi)}n
i=1) =
i=1(w· xi − yi)2 for some parameter α > 0. It is worth noting that L is not divergence-based.
In order to satisfy the escrow property (ES)  we can set Cost(w  w(cid:48)) := 2α(cid:107)w − w(cid:48)(cid:107)2 because
the function L(w; X) is 2α-lipschitz with respect to w for any X. To ensure that the CLM is
L-incentivized  we must set Payout(w  w(cid:48); X) := Cost(w  w(cid:48)) + L(w; X) − L(w(cid:48); X).
If we set the initial hypothesis w0 = 0  it is easy to check that WorstCaseLoss = α/2.
It re-
mains to check whether this CLM is tractable.
It’s clear that we can efﬁciently compute Cost
and Payout  hence the EC property holds. Given how Cost is deﬁned  it is clear that the set
{w(cid:48) : Cost(w  w(cid:48)) ≤ B} is just an (cid:96)2-norm ball. Also  since L is convex in w for each X  so
is the function EX∼P
participant must simply solve a convex optimization problem  and hence the TT property holds.
Betting Directly on the Labels. Let us return our attention to the Netﬂix Prize model as discussed
in the Introduction. For this style of competition a host releases a dataset for a given prediction task.
The host then requests participants to provide predictions on a speciﬁed set of instances on which
it has correct labels. For every submission the agent computes an error measure  say the MSE  and
reports this to the participants. Of course  the correct labels are withheld throughout.
Our CLM framework is general enough to apply to this problem framework as well. Deﬁne H =
O = K m where K ⊆ R bounded is the set of valid labels  and m is the number of requested test set
predictions. For some w ∈ H and y ∈ O  w(k) speciﬁes the kth predicted label  and y(k) speciﬁes
k=1(w(k)−y(k))2.
Of course  this approach is quite different from the Netﬂix Prize model  in two key respects: (a) the
participants have to wager on their predictions and (b) by participating in the mechanism they are
required to reveal their modiﬁcation to all of the other players. Hence while we have structured a
competitive process the participants are de facto forced to collaborate on the solution.
A reasonable critique of this collaborative mechanism approach to a Netﬂix-style competition is that
it does not provide the instant feedback of the “leaderboard” where individuals observe performance
improvements in real time. However  we can adjust our mechanism to be online with a very simple
modiﬁcation of the CLM protocol  which we sketch here. Rather than make payouts in a large batch
at the end  the competition designer could perform a mini-payout at the end of each of a sequence
of time intervals. At each interval  the designer could select a (potentially random) subset S of
user/movie pairs in the remaining test set  freeze updates on the predictions w(k) for all k ∈ S  and
perform payouts to the participants on only these labels. What makes this possible  of course  is that
the generalized scoring rule we chose decomposes as a sum over the individual labels.
Acknowledgments. We gratefully acknowledge the support of the NSF under award DMS-
0830410  a Google University Research Award  and the National Defense Science and Engineering
Graduate (NDSEG) Fellowship  32 CFR 168a.

the true label. A natural scoring function is the total squared loss  L(w; y) :=(cid:80)m

8

References
[1] J. Abernethy  Y. Chen  and J. Wortman Vaughan. An optimization-based framework for auto-
mated market-making. In Proceedings of the 12th ACM Conference on Electronic Commerce 
2011.

[2] J. E. Berg  R. Forsythe  F. D. Nelson  and T. A. Rietz. Results from a dozen years of election
In C. A. Plott and V. Smith  editors  Handbook of Experimental

futures markets research.
Economic Results. 2001.

[3] Y. Chen and D. M. Pennock. A utility framework for bounded-loss market makers. In Pro-

ceedings of the 23rd Conference on Uncertainty in Artiﬁcial Intelligence  2007.

[4] Y. Chen and J. Wortman Vaughan. A new understanding of prediction markets via no-regret

learning. In Proceedings of the 11th ACM Conference on Electronic Commerce  2010.

[5] T.M. Cover  J.A. Thomas  J. Wiley  et al. Elements of information theory  volume 6. Wiley

Online Library  1991.

[6] T. Gneiting and A.E. Raftery. Strictly proper scoring rules  prediction  and estimation. Journal

of the American Statistical Association  102(477):359–378  2007.

[7] R. Hanson. Combinatorial information market design.

5(1):105–119  2003.

Information Systems Frontiers 

[8] R. Hanson. Logarithmic market scoring rules for modular combinatorial information aggrega-

tion. Journal of Prediction Markets  1(1):3–15  2007.

[9] R. Hanson  R. Oprea  and D. Porter. Information aggregation and manipulation in an experi-

mental market. Journal of Economic Behavior & Organization  60(4):449–459  2006.

[10] Nathan Lay and Adrian Barbu. Supervised aggregation of classiﬁers using artiﬁcial prediction

markets. In ICML  pages 591–598  2010.

[11] J. Ledyard  R. Hanson  and T. Ishikida. An experimental test of combinatorial information

markets. Journal of Economic Behavior and Organization  69:182–189  2009.

[12] J. Wolfers and E. Zitzewitz. Prediction markets. Journal of Economic Perspective  18(2):107–

126  2004.

9

,Nilesh Tripuraneni
Shixiang (Shane) Gu
Hong Ge
Zoubin Ghahramani
Andrea Giovannucci
Johannes Friedrich
Matt Kaufman
Anne Churchland
Dmitri Chklovskii
Liam Paninski
Eftychios Pnevmatikakis