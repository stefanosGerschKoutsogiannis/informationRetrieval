2018,Approximate Knowledge Compilation by Online Collapsed Importance Sampling,We introduce collapsed compilation  a novel approximate inference algorithm for discrete probabilistic graphical models. It is a collapsed sampling algorithm that incrementally selects which variable to sample next based on the partial compila- tion obtained so far. This online collapsing  together with knowledge compilation inference on the remaining variables  naturally exploits local structure and context- specific independence in the distribution. These properties are used implicitly in exact inference  but are difficult to harness for approximate inference. More- over  by having a partially compiled circuit available during sampling  collapsed compilation has access to a highly effective proposal distribution for importance sampling. Our experimental evaluation shows that collapsed compilation performs well on standard benchmarks. In particular  when the amount of exact inference is equally limited  collapsed compilation is competitive with the state of the art  and outperforms it on several benchmarks.,Approximate Knowledge Compilation by
Online Collapsed Importance Sampling

Tal Friedman

Computer Science Department

University of California
Los Angeles  CA 90095

tal@cs.ucla.edu

Guy Van den Broeck

Computer Science Department

University of California
Los Angeles  CA 90095
guyvdb@cs.ucla.edu

Abstract

We introduce collapsed compilation  a novel approximate inference algorithm for
discrete probabilistic graphical models. It is a collapsed sampling algorithm that
incrementally selects which variable to sample next based on the partial compila-
tion obtained so far. This online collapsing  together with knowledge compilation
inference on the remaining variables  naturally exploits local structure and context-
speciﬁc independence in the distribution. These properties are used implicitly
in exact inference  but are difﬁcult to harness for approximate inference. More-
over  by having a partially compiled circuit available during sampling  collapsed
compilation has access to a highly effective proposal distribution for importance
sampling. Our experimental evaluation shows that collapsed compilation performs
well on standard benchmarks. In particular  when the amount of exact inference is
equally limited  collapsed compilation is competitive with the state of the art  and
outperforms it on several benchmarks.

1

Introduction

Modern probabilistic inference algorithms for discrete graphical models are designed to exploit
key properties of the distribution. In addition to classical conditional independence  they exploit
local structure in the individual factors  determinism coming from logical constraints (Darwiche 
2009)  and the context-speciﬁc independencies that arise in such distributions (Boutilier et al.  1996).
The knowledge compilation approach in particular forms the basis for state-of-the-art probabilistic
inference algorithms in a wide range of models  including Bayesian networks (Chavira & Darwiche 
2008)  factor graphs (Choi et al.  2013)  statistical relational models (Chavira et al.  2006; Van den
Broeck  2013)  probabilistic programs (Fierens et al.  2015)  probabilistic databases (Van den Broeck
& Suciu  2017)  and dynamic Bayesian networks (Vlasselaer et al.  2016). Based on logical reasoning
techniques  knowledge compilation algorithms construct an arithmetic circuit representation of
the distribution on which inference is guaranteed to be efﬁcient (Darwiche  2003). The inference
algorithms listed above have one common limitation: they perform exact inference by compiling a
worst-case exponentially-sized arithmetic circuit representation. Our goal in this paper is to upgrade
these techniques to allow for approximate probabilistic inference  while still naturally exploiting
the structure in the distribution. We aim to open up a new direction towards scaling up knowledge
compilation to larger distributions.
When knowledge compilation produces circuits that are too large  a natural solution is to sample some
random variables and do exact compilation on the smaller distribution over the remaining variables.
This collapsed sampling approach suffers from two problems. First  collapsed sampling assumes that
one can determine a priori which variables need to be sampled to make the distribution amenable to
exact inference. When dealing with large amounts of context-speciﬁc independence  it is difﬁcult to

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

ﬁnd such a set  because the independencies are a function of the particular values that variables get
instantiated to. Second  collapsed sampling assumes that one has access to a proposal distribution
that determines how to sample each variable  and the success of inference largely depends on the
quality of this proposal. In practice  the user often needs to specify the proposal distribution manually 
and it is difﬁcult to automatically construct one that is general purpose.
As our ﬁrst contribution  Section 2 introduces online collapsed importance sampling  where the
sampler chooses which variable to sample next based on the values sampled for previous variables.
This algorithm is a solution to the ﬁrst problem identiﬁed above: based on the context of each
individual sample  it allows the sampler to determine which subset of the variables is amenable to
exact inference. We show that the sampler corresponds to a classical collapsed importance sampler
on an augmented graphical model and prove conditions for it to be asymptotically unbiased.
Section 3 describes our second contribution: a collapsed compilation algorithm that maintains a
partially-compiled arithmetic circuit during online collapsed importance sampling. This circuit
provides a solution to the second problem identiﬁed above: it serves as a highly-effective proposal
distribution at each step of the algorithm. Moreover  by setting a limit on the circuit size as we
compile more factors into the model  we are able to sample exactly as many variables as needed to
ﬁt the arithmetic circuit into memory. This allows us to maximize the amount of exact inference
performed by the algorithm. Crucially  through online collapsing  the set of collapsed variables
changes with every sample  exploiting different independencies in each sample’s arithmetic circuit.
We provide an open-source Scala implementation of this collapsed compilation algorithm.1
Finally  we experimentally validate the performance of collapsed compilation on standard benchmarks.
We begin by empirically examining properties of collapsed compilation  to show the value of the
proposal distribution and pick apart where performance improvements are coming from. Then  in a
setting where the amount of exact inference is ﬁxed  we ﬁnd that collapsed compilation is competitive
with state-of-the-art approximate inference algorithms  outperforming them on several benchmarks.

2 Online Collapsed Importance Sampling

We begin with a brief review of collapsed importance sampling  before motivating the need for
dynamically selecting which variables to sample. We then demonstrate that we can select variables
in an online fashion while maintaining the desired unbiasedness property of the sampler  using an
algorithm we call online collapsed importance sampling.
We denote random variables with uppercase letters (X )  and their instantiation with lowercase letters
(x). Bold letters denote sets of variables (X) and their instantiations (x). We refer to Koller &
Friedman (2009) for notation and formulae related to (collapsed) importance sampling.

2.1 Collapsed Importance Sampling
The basic principle behind collapsed sampling is that we can reduce the variance of an estimator by
making part of the inference exact. That is  suppose we partition our variables into two sets: Xp 
and Xd. In collapsed importance sampling  the distribution of variables in Xp will be estimated via
importance sampling  while those in Xd will be estimated by computing exactly P (Xd|xp) for each
sample xp. In particular  suppose we have some function f (x) where x is a complete instantiation of
Xp [ Xd  and a proposal distribution Q over Xp. Then we estimate the expectation of f by

m=1 w[m](EP (Xd|xp[m])[f (xp[m]  Xd)])

(1)

ˆE(f ) = PM

m=1 w[m]

PM

m=1 drawn from a proposal distribution Q. For each sample  we analytically
on samples {xp[m]}M
ˆP (xp[m])
compute the importance weights w[m] =
Q(xp[m])  and the exact expectation of f conditioned on
the sample  that is  EP (Xd|xp[m])[f (xp[m]  Xd)]. Due to the properties of importance samplers  the
estimator given by (1) is asymptotically unbiased. Moreover  if we compute P (xp[m]) exactly rather
than the unnormalized ˆP (xp[m])  then the estimator is unbiased (Tokdar & Kass  2010).

1The code is available at https://github.com/UCLA-StarAI/Collapsed-Compilation. It uses the

SDD library for knowledge compilation (Darwiche  2011) and the Scala interface by Bekker et al. (2015).

2

F12
F13
F23

1
0
1

V1

V2

V3

V1

V2

V5

V7

V6

V9

V4

V10

V3

V8

V4

V5

V2

V1

V3

V6

V7

V8

V9

V10

(a) Sampled Friendships

(b) Induced Dependencies

(c) Induced Network G1

(d) Induced Network G2

Figure 1: Different samples for F can have a large effect on the resulting dependencies between V.

2.2 Motivation

A critical decision that needs to be made when doing collapsed sampling is selecting a partition –
which variables go in Xp and which go in Xd. The choice of partition can have a large effect on
the quality of the resulting estimator  and the process of choosing such a partition requires expert
knowledge. Furthermore  selecting a partition a priori that works well is not always possible  as we
will show in the following example. All of this raises the question whether it is possible to choose the
partition on the ﬂy for each sample  which we will discuss in Section 2.3.
Suppose we have a group of n people  denoted 1  ...  n. For every pair of people (i  j)  i < j  there is
a binary variable Fij indicating whether i and j are friends. Additionally  we have features Vi for
each person i  and Fij = 1 (that is i  j are friends) implies that Vi and Vj are correlated. Suppose
we are performing collapsed sampling on the joint distribution over F and V  and that we have
already decided to place all friendship indicators Fij in Xp to be sampled. Next  we need to decide
which variables in V to include in Xp for the remaining inference problem over Xd to become
tractable. Observe that given a sampled F  due to the independence properties of V relying on F  a
graphical model G is induced over V (see Figures 1a 1b). Moreover  this graphical model can vary
greatly between different samples of F. For example  G1 in Figure 1c densely connects {V1  ...  V6}
making it difﬁcult to perform exact inference. Thus  we will need to sample some variables from this
set. However  exact inference over {V7  ...  V10} is easy. Conversely  G2 in Figure 1d depicts the
opposite scenario: {V1  ...  V5} forms a tree  which is easy for inference  whereas {V6  ...  V10} is
now intractable. It is clearly impossible to choose a small subset of V to sample that ﬁts all cases 
thus demonstrating a need for an online variable selection during collapsed sampling.

2.3 Algorithm

We now introduce our online collapsed importance sampling algorithm. It decides at sampling time
which variables to sample and which to do exact inference on.
To gain an intuition  suppose we are in the standard collapsed importance sampling setting. Rather
than sampling an instantiation xp jointly from Q  we can instead ﬁrst sample xp1 ⇠ Q(Xp1)  then
xp2 ⇠ Q(Xp2|xp1)  and so on using the chain rule of probability. In online collapsed importance
sampling  rather than deciding Xp1  Xp2  Xp3  . . . a priori  we select which variable will be Xp2 based
on the previous sampled value xp1  we select which will be Xp3 based on xp1 and xp2  and so on.

Deﬁnition 1. Let y be an instantiation of Y ⇢ X.
A variable selection policy ⇡ takes y and either stops
sampling or returns a distribution over which variable
in X \ Y should be sampled next.
For example  a naive policy could be to select a remain-
ing variable uniformly at random. Once the policy ⇡
stops sampling  we are left with an instantiation xp
and a set of remaining variables Xd  where both are
speciﬁc to the choices made for that particular sample.
Algorithm 1 shows more precisely how online col-
lapsed importance sampling generates a single sample 
given a full set of variables X  a variable selection
policy ⇡  and proposal distributions QXi|xp for any

3

Algorithm 1: Online Collapsed IS
Input :X: The set of all variables 
⇡: Variable selection policy 
QXi|xp: Proposal distributions

d   xm

p   w[m]

Result: A sampleXm
1 xp {} ; Xd X
2 while ⇡ does not stop do
Xi ⇠ ⇡ (xp)
3
xi ⇠ QXi|xp(Xi|xp)
4
xp xp [{ xi}
5
Xd Xd \ {Xi}
6
ˆP (xp)

7 return⇣Xd  xp 

Q(xp)⌘

d to do exact inference for  an
choice of Xi and xp. This sample consists of a set of variables Xm
instantiation of the sampled variables xm
p   and the corresponding importance weights w[m]  all
indexed by the sample number m. Note that xp is a set of variables together with their instantiations 
while Xd is just a set of variables. The global joint proposal Q(xp)  denoting the probability that
Algorithm 1 returns xp  is left abstract for now (see Section 2.4.2 for a concrete instance). In general 
it is induced by variable selection policy ⇡ and the individual local proposals QXi|xp.

sampling  the online collapsed importance sampling estimator of f is

d   xm

m=1 produced by online collapsed importance

Deﬁnition 2. Given M samplesXm
ˆE(f ) = PM

p   w[m] M
PM

m=1 w[m]

m=1 w[m](EP (Xm

d |xm

p )[f (xm

p   Xm

d )])

.

(2)

Note that the only difference compared to Equation 1 is that sets Xm

p and Xm

d vary with each sample.

2.4 Analysis
Our algorithm for online collapsed importance sampling raises two questions: does Equation 2 yield
unbiased estimates  and how does one compute the proposal Q(xp)? We study both questions next.

2.4.1 Unbiasedness of Estimator
If we let ⇡ be a policy that always returns the same variables in the same order  then we recover
classical ofﬂine collapsed importance sampling - and thus retain all of its properties. In order to make
a similar statement for any arbitrary policy ⇡  we will use the augmented factor graph construction
presented in Figure 2. Our goal is to reduce online collapsed importance sampling on F to a problem
of doing ofﬂine collapsed importance sampling on FA.

X2:n

f

X1

X2:n

f

X1

fau

S1

X⇤1

(a) Original factor graph F

(b) Augmented factor graph FA

Figure 2: Online collapsed sampling corresponds to collapsed sampling on an augmented graph

to the factor graph  representing a copy variable of Xi. We design
Intuitively  we add variable X ⇤i
our ofﬂine collapsed sampler on augmented graph FA such that we are always sampling X ⇤i and
computing Xi exactly. To make this possible without actually inferring the entire distribution exactly 
we add variable Si to the model (also always to be sampled). Each Si acts as an indicator for whether
X ⇤i and Xi are constrained to be equal. Si can also be thought of as indicating whether or not we are
sampling Xi in our original factor graph F when doing online collapsed importance sampling. These
dependencies are captured in the new factor fau. We are now ready to state the following results.
Theorem 1. For any factor graph F and its augmented graph FA  we have 8x   PF (x) = PFA(x).
Theorem 2. Let F be a factor graph and let FA be its augmented factor graph. The collapsed
importance sampling estimator (Eq. 1) with Xp = X⇤ [ S and Xd = X on FA is equivalent to the
online collapsed importance sampling estimator (Eq. 2) on F .
Corollary 1. The estimator given by Eq. 2 is asymptotically unbiased.

Proofs and the details of this construction can be found in Appendix A.

2.4.2 Computing the Proposal Distribution
Our next question is how to compute the global joint proposal distribution Q(xp)  given that we
have variable selection policy ⇡ and each local proposal distribution QXi|xp. Notice that since these
QXi|xp are unconstrained and unrelated distributions  the computation is not easy in general. In
particular  considering |Xp| = n and our previous example of a uniformly random policy ⇡  then for
any given instantiation xp  there are n! different ways xp could be sampled by Algorithm 1 – one for

4

A

f1

B

f2

C

A B

f1

0
0
1
1

0
1
0
1

2
2
2
5

B

0
0
1
1

C

0
1
0
1

f2

3
8
8
8

B

f1(A  B)

+

+

+

⇥

⇥

A ¬A

2

⇥
⇥

5

¬B

B

⇥

f2(B  C)

+

+

+

⇥

8

C ¬C

⇥
⇥

3

¬B

f1(A  B) · f2(B  C)

+

+

+

⇥
+

⇥

C

⇥

3

¬B

2

⇥
+

⇥

B

5

⇥

8
¬C

A ¬A

Figure 3: Multiplying Arithmetic Circuits: Factor graph and ACs for individual factors which multiply
into a single AC for the joint distribution. Given an AC  inference is tractable by propagating inputs.

each ordering that arrives at xp. In this case  computing Q(xp) requires summing over exponentially
many terms  which is undesirable. Instead  we restrict the variable selection policies we use to the
following class.
Deﬁnition 3. A deterministic variable selection policy ⇡(xp) is a function with a range of X \ Xp.
Theorem 3. For any sample xp and deterministic variable selection policy ⇡(xp)  there is exactly
one order Xp1  Xp2  . . .   Xp|Xp|
in which the variables Xp could have been sampled. Therefore  the
joint proposal distribution is given by Q(xp) =Q|Xp|

Hence  computing the joint proposal Q(xp) becomes easy given a deterministic selection policy ⇡.

i=1 QXpi|xp1:i1

(xpi|xp1:i1).

3 Collapsed Compilation

Online collapsed importance sampling presents us with a powerful technique for adapting to problems
traditional collapsed importance sampling may struggle with. However  it also demands we solve
several difﬁcult tasks: one needs a good proposal distribution over any subset of variables  an efﬁcient
way of exactly computing an expectation given a sample  and an efﬁcient way of ﬁnding the true
probability of sampled variables. In this section  we introduce collapsed compilation  which tackles
all three of these problems at once using techniques from knowledge compilation.

3.1 Knowledge Compilation Background

We begin with a short review of how to perform exact inference on a probabilistic graphical model
using knowledge compilation to arithmetic circuits (ACs).
Suppose we have a factor graph (Koller & Friedman  2009) consisting of three binary variables A  B
and C  and factors f1  f2 as depicted in Figure 3. Each of these factors  as well as their product can be
represented as an arithmetic circuit. These circuits have inputs corresponding to variable assignments
(e.g.  A and ¬A) or constants (e.g.  5). Internal nodes are sums or products. We can encode a
complete instantiation of the random variables by setting the corresponding variable assignments to 1
and the opposing assignments to 0. Then  the root of the circuit for a factor evaluates to the value of
the factor for that instantiation. However  ACs can also represent products of factors. In that case  the
AC’s root evaluates to a weight that is the product of factor values. Under factor graph semantics  this
weight represents the unnormalized probability of a possible world.
The use of ACs for probabilistic inference stems from two important properties. Product nodes are
decomposable  meaning that their inputs are disjoint  having no variable inputs in common. Sum
nodes are deterministic  meaning that for any given complete input assignment to the circuit  at most
one of the sum’s inputs evaluates to a non-zero value. Because of decomposability  we are able
to perform marginal inference on ACs: by setting both assignments for the same variable to 1  we
effectively marginalize out that variable. For example  by setting all inputs to 1  the arithmetic circuit
evaluates to the sum of weights of all worlds  which is the partition function of the graphical model.
We refer to Darwiche (2009) for further details on how to reason with arithmetic circuits.
In practice  arithmetic circuits are often compiled from graphical models by encoding graphical
model inference into a logical task called weighted model counting  followed by using Boolean
circuit compilation techniques on the weighted model counting problem. We refer to Choi et al.
(2013) and Chavira & Darwiche (2008) for details. As our Boolean circuit compilation target  we
will use the sentential decision diagram (SDD) (Darwiche  2011). Given any two SDDs representing

5

factors f1  f2  we can efﬁciently compute the SDD representing the factor multiplication of f1 and f2 
as well as the result of conditioning the factor graph on any instantiation x. We call such operations
APPLY  and they are the key to using knowledge compilation for doing online collapsed importance
sampling. An example of multiplying two arithmetic circuits is depicted in Figure 3.
As a result of SDDs supporting the APPLY operations  we can directly compile graphical models to
circuits in a bottom-up manner. Concretely  we start out by compiling each factor into a corresponding
SDD representation using the encoding of Choi et al. (2013). Next  these SDDs are multiplied in order
to obtain a representation for the entire model. As shown by Choi et al. (2013)  this straightforward
approach can be used to achieve state-of-the-art exact inference on probabilistic graphical models.

3.2 Algorithm

Now that we have proposed online collapsed importance sampling and given background on knowl-
edge compilation  we are ready to introduce collapsed compilation  an algorithm that uses knowledge
compilation to do online collapsed importance sampling.
Collapsed compilation begins by multiplying factors represented as SDDs. When the resulting SDD
becomes too large  we invoke online collapsed importance sampling to instantiate one of the variables.
On the arithmetic circuit representation  sampling a variable replaces one input by 1 and the other
by 0. This conditioning operation allows us to simplify the SDD until it is sufﬁciently small again.
At the end  the sampled variables form xp  and the variables remaining in the SDD form Xd.
Concretely  collapsed compilation repeatedly performs a few simple steps  following Algorithm 1:

1. Choose an order  and begin multiplying compiled factors into the current SDD until the size

limit is reached.

2. Select a variable X using the given policy ⇡.

3. Sample X according to its marginal probability in the current SDD  corresponding to the

partially compiled factor graph conditioned on prior instantiations.

4. Condition the SDD on the sampled value for X .

We are taking advantage of knowledge compilation in a few subtle ways. First  to obtain the
importance weights  we compute the partition function on the ﬁnal resulting circuit  which corresponds
to the unnormalized probability of all sampled variables  that is  ˆP (xp) in Algorithm 1. Second 
Step 3 presents a non-trivial and effective proposal distribution  which due to the properties of SDDs is
efﬁcient to compute in the size of the circuit. Third  all APPLY operations on SDDs can be performed
tractably (Van den Broeck & Darwiche  2015)  which allows us to multiply factors and condition
SDDs on sampled instantiations.
The full technical description and implementation details can be found in Appendix B and C.

4 Experimental Evaluation

Data & Evaluation Criteria To empirically investigate collapsed compilation  we evaluate the
performance of estimating a single marginal on a series of commonly used graphical models. Each
model is followed in parentheses by its number of random variable nodes and factors.
From the 2014 UAI inference competition  we evaluate on linkage(1077 1077)  Grids(100 300) 
DBN(40  440)  and Segmentation(228 845) problem instances. From the 2008 UAI inference
competition  we use two semi-deterministic grid instances  50-20(400  400) and 75-26(676  676).
Here the ﬁrst number indicates the percentage of factor entries that are deterministic  and the second
indicates the size of the grid. Finally  we generated a randomized frustrated Ising model on a
16x16 grid  frust16(256  480). Beyond these seven benchmarks  we experimented on ten additional
standard benchmarks. Because those were either too easy (showing no difference between collapsed
compilation and the baselines)  or similar to other benchmarks  we do not report on them here.

6

H(P  Q) =

(ppi  pqi)2.

kXi=1

1

p2vuut

For evaluation  we run all sampling-based methods 5 times for 1 hour each. We report the median
Hellinger distance across all runs  which for discrete distributions P and Q is given by

Compilation Order Once we have compiled an SDD for each factor in the graphical model 
collapsed compilation requires us to choose in which order to multiply these SDDs. We look at two
orders: BFS and revBFS. The ﬁrst begins from the marginal query variable  and compiles outwards
in a breadth-ﬁrst order. The second does the same  but in exactly the opposite order arriving at the
query variable last.

Variable Selection Policies We evaluate three variable selection policies:
The ﬁrst policy RBVar explores the idea of picking the variable that least increases the Rao-Blackwell
variance of the query (Darwiche  2009). For a given query ↵  to select our next variable from X  we

use argminX2XPx P (↵|X )2P (X ). This quantity can be computed in time linear in the size of the

current SDD.
The next policy we look at is MinEnt  which selects the variable with the smallest entropy. Intuitively 
this is selecting the variable for which sampling assumes the least amount of unknown information.
Finally  we examine a graph-based policy FD (FrontierDistance). At any given point in our compilation
we have some frontier F  which is the set of variables that have some but not all factors included in
the current SDD. Then we select the variable in our current SDD that is  on the graph of our model 
closest to the “center” induced by F. That is  we use argminX2X maxF2F distance(X   F ).
In our experiments  policy RBVar is used with the compilation order BFS  while policies MinEnt and
FrontierDist are used with order RevBFS.

4.1 Understanding Collapsed Compilation
We begin our evaluation with experiments designed to shed some light on different components in-
volved in collapsed compilation. First  we evaluate our choice in proposal distribution by comparison
to marginal-based proposals. Then  we examine the effects of setting different size thresholds for
compilation on the overall performance  as well as the sample count and quality.

Evaluating the Proposal Distribution Selecting an effective proposal distribution is key to suc-
cessfully using importance sampling estimation (Tokdar & Kass  2010). As discussed in Section 3 
one requirement of online collapsed importance sampling is that we must provide a proposal distribu-
tion over any subset of variables  which in general is challenging.
To evaluate the quality of collapsed compilation’s proposal distribution  we compare it to using
marginal-based proposals  and highlight the problem with such proposals. First  we compare to a
dummy uniform proposal. Second  we compare to a proposal that uses the true marginals for each
variable. Experiments on the 50-20 benchmark are shown in Table 1a. Note that these experiments
were run for 3 hours rather than 1 hour  so the numbers can not be compared exactly to other tables.
Particularly with policies FrontierDist and MinEnt  the results underline the effectiveness of
collapsed compilation’s proposal distribution over baselines. This is the effect of conditioning – even
sampling from the true posterior marginals does not work very well  due to the missed correlation
between variables. Since we are already conditioning for our partial exact inference  collapsed
compilation’s proposal distribution is providing this improvement for very little added cost.

Choosing a Size Threshold A second requirement for collapsed compilation is to set a size
threshold for the circuit being maintained. Setting the threshold to be inﬁnity leaves us with exact
inference which is in general intractable  while setting the threshold to zero leaves us with importance
sampling using what is likely a poor proposal distribution (since we can only consider one factor at a
time). Clearly  the optimal choice ﬁnds a trade-off between these two considerations.
Using benchmark 50-20 again  we compare the performance on three different settings for the circuit
size threshold: 10 000  100 000  and 1 000 000. Table 1b shows that generally  100k gives the best

7

Table 1: Internal comparisons for collapsed compilation. Values represent Hellinger distances.

(a) Comparison of proposal distributions

Policy
FD
MinEnt
RBVar

Dummy
2.37e4
3.29e4
5.81e3

True
1.77e4
1.31e3
5.71e3

SDD
3.72e7
2.10e8
7.34e3

(c) Comparison of size thresholds (50 samples)
Policy
FD
MinEnt
RBVar

1m
1.27e6
7.24e6
3.07e2

100k
5.08e7
1.84e6
1.52e1

10k
1.63e3
1.69e2
1.94e2

Policy
FD
MinEnt
RBVar

10k
7.33e5
1.44e3
2.96e2

(b) Comparison of size thresholds
1m
7.53e6
8.07e4
8.81e3
(d) Number of samples taken in 1 hour by size
Size Threshold
1m
4.7
Number of Samples

100k
9.77e6
1.50e5
2.66e2

10k
561.3

100k
33.5

performance  but the results are often similar. To further investigate this  Table 1c and Table 1d show
performance with exactly 50 samples for each size  and number of samples per hour respectively.
This is more informative as to why 100k gave the best performance - there is a massive difference in
performance for a ﬁxed number of samples between 10k and 100k or 1m. The gap between 100k and
1m is quite small  so as a result the increased number of samples for 100k leads to better performance.
Intuitively  this is due to the nature of exact circuit compilation  where at a certain size point of
compilation you enter an exponential regime. Ideally  we would like to stop compiling right before
we reach that point. Thus  we proceed with 100k as our size-threshold setting for further experiments.

4.2 Memory-Constrained Comparison

In this section  we compare collapsed compilation to two related state-of-the-art methods: edge-
deletion belief propagation (EDBP) (Choi & Darwiche  2006)  and IJGP-Samplesearch (SS) (Gogate
& Dechter  2011). Generally  for example in past UAI probabilistic inference competitions  comparing
methods in this space involves a ﬁxed amount of time and memory being given to each tool. The
results are then directly compared to determine the empirically best performing algorithm. While this
is certainly a useful metric  it is highly dependent on efﬁciency of implementation  and moreover
does not provide as good of an understanding of the effects of being allowed to do more or less exact
inference. To give more informative results  in addition to a time limit  we restrict our comparison at
the algorithmic level  by controlling for the level of exact inference being performed.

Edge-Deletion Belief Propagation EDBP performs approximate inference by increasingly running
more exact junction tree inference  and approximating the rest via belief propagation (Choi &
Darwiche  2006; Choi et al.  2005). To constrain EDBP  we limit the corresponding circuit size for
the junction tree used. In our experiments we set these limits at 100 000 and 1 000 000.

IJGP-Samplesearch IJGP-Samplesearch (SS) is an importance sampler augmented with constraint
satisfaction search (Gogate & Dechter  2011  2007). It uses iterative join-graph propagation (Dechter
et al.  2002) together with w-cutset sampling (Bidyuk & Dechter  2007) to form a proposal  and then
uses search to ensure that no samples are rejected. To constrain SS  we limit treewidth w at either 15 
12  or 10. For reference  a circuit of size 100 000 corresponds to a treewidth between 10 and 12.
Appendix D describes both baselines as well as the experimental setup in further detail.

4.2.1 Discussion
Table 2 shows the experimental results for this setting. Overall  we have found that when restricting all
methods to only do a ﬁxed amount of exact inference  collapsed compilation has similar performance
to both Samplesearch and EDBP. Furthermore  given a good choice of variable selection policy  it can
often perform better. In particular  we highlight DBN  where we see that collapsed compilation with
the RBVar or MinEnt policies is the only method that manages to achieve reasonable approximate
inference. This follows the intuition discussed in Section 2.2: a good choice of a few variables in a
densely connected model can lead to relatively easy exact inference for a large chunk of the model.

8

Table 2: Hellinger distances across methods with internal treewidth and size bounds
frust
4.73e3
4.73e3
1.05e2
5.27e4
6.23e3
5.96e6
3.10e2
2.30e3

Segment
1.63e6
1.93e7
3.11e7
3.11e7
3.11e7
6.00e8
3.40e7
3.01e7

linkage
6.54e8
5.98e8
4.93e2
1.10e3
4.06e6
5.99e6
6.16e5
2.02e2

50-20
2.19e3
7.40e7
2.51e2
6.96e3
9.09e6
9.77e6
1.50e5
2.66e2

75-26
3.17e5
2.21e4
2.22e3
1.02e3
1.09e4
1.87e3
3.29e2
4.39e1

Method
EDBP-100k
EDBP-1m
SS-10
SS-12
SS-15
FD
MinEnt
RBVar

DBN
6.39e1
6.39e1
6.37e1
6.27e1
(Exact)
1.24e1
1.83e2
6.27e3

Grids
1.24e3
1.98e7
3.10e1
2.48e1
8.74e4
1.98e4
3.61e3
1.20e1

Another factor differentiating collapsed compilation from both EDBP and Samplesearch is the lack
of reliance on some type of belief propagation algorithm. Loopy belief propagation is a cornerstone
of approximate inference in graphical models  but it is known to have problems converging to a good
approximation on certain classes of models (Murphy et al.  1999). The problem instance frust16 is
one such example – it is an Ising model with spins set up such that potentials can form loops  and the
performance of both EDBP and Samplesearch highlights these issues.

4.3 Probabilistic Program Inference

Method
EDBP-1m
SS-15
FD

As an additional point of comparison  we introduce a new type of
benchmark. We use the probabilistic logic programming language
ProbLog (De Raedt & Kimmig  2015) to model a graph with prob-
abilistic edges  and then query for the probability of two nodes
being connected. This problem presents a unique challenge  as every
non-unary factor is deterministic.
Table 3 shows the results for this benchmark  with the underlying
graph being a 12x12 grid. We see that EDBP struggles here due to the
large number of deterministic factors  which stop belief propagation
from converging in the allowed number of iterations. Samplesearch and collapsed compilation show
similarly decent results  but interestingly they are not happening for the same reason. To contextualize
this discussion  consider the stability of each method. Collapsed compilation draws far fewer samples
than SS – some of this is made up for by how powerful collapsing is as a variance reduction technique 
but it is indeed less stable than SS. For this particular instance  we found that while different runs for
collapsed compilation tended to give different marginals fairly near the true value  SS consistently
gave the same incorrect marginal. This suggests that if we ran each algorithm until convergence 
collapsed compilation would tend toward the correct solution  while SS would not  and appears to
have a bias on this benchmark.

Table 3: Hellinger distances
for ProbLog benchmark

Prob12
3.18e1
3.87e3
1.50e3

5 Related Work and Conclusions

We have presented online collapsed importance sampling  an asymptotically unbiased estimator
that allows for doing collapsed importance sampling without choosing which variables to collapse
a priori. Using techniques from knowledge compilation  we developed collapsed compilation  an
implementation of online collapsed importance sampling that draws its proposal distribution from
partial compilations of the distribution  and naturally exploits structure in the distribution.
In related work  Lowd & Domingos (2010) study arithmetic circuits as a variational approximation
of graphical models. Approximate compilation has been used for inference in probabilistic (logic)
programs (Vlasselaer et al.  2015). Other approximate inference algorithms that exploit local structure
include samplesearch and the family of universal hashing algorithms (Ermon et al.  2013; Chakraborty
et al.  2014). Finally  collapsed compilation can be viewed as an approximate knowledge compilation
method: each drawn sample presents a partial knowledge base along with the corresponding correction
weight. This means that it can be used to approximate any query which can be performed efﬁciently
on an SDD – for example the most probable explanation (MPE) query (Chan & Darwiche  2006;
Choi & Darwiche  2017). We leave this as an interesting direction for future work.

9

Acknowledgements
We thank Jonas Vlasselaer and Wannes Meert for initial discussions. Additionally  we thank Arthur
Choi  Yujia Shen  Steven Holtzen  and YooJung Choi for helpful feedback. This work is partially
supported by a gift from Intel  NSF grants #IIS-1657613  #IIS-1633857  #CCF-1837129  and DARPA
XAI grant #N66001-17-2-4032.

References
Bekker  Jessa  Davis  Jesse  Choi  Arthur  Darwiche  Adnan  and Van den Broeck  Guy. Tractable
learning for complex probability queries. In Advances in Neural Information Processing Systems 
pp. 2242–2250  2015.

Bidyuk  Bozhena and Dechter  Rina. Cutset sampling for Bayesian networks. Journal of Artiﬁcial

Intelligence Research (JAIR)  28:1–48  2007.

Boutilier  Craig  Friedman  Nir  Goldszmidt  Moises  and Koller  Daphne. Context-speciﬁc indepen-

dence in Bayesian networks. In Proceedings of UAI  pp. 115–123  1996.

Chakraborty  Supratik  Fremont  Daniel J  Meel  Kuldeep S  Seshia  Sanjit A  and Vardi  Moshe Y.
In Proceedings of AAAI 

Distribution-aware sampling and weighted model counting for sat.
volume 14  pp. 1722–1730  2014.

Chan  Hei and Darwiche  Adnan. On the Robustness of Most Probable Explanations. In Proceedings

of UAI  pp. 63–71  Arlington  Virginia  United States  2006. AUAI Press.

Chavira  Mark and Darwiche  Adnan. On probabilistic inference by weighted model counting.

Artiﬁcial Intelligence  172:772–799  2008.

Chavira  Mark  Darwiche  Adnan  and Jaeger  Manfred. Compiling relational Bayesian networks for

exact inference. IJAR  42(1-2):4–20  2006.

Choi  Arthur and Darwiche  Adnan. An edge deletion semantics for belief propagation and its
practical impact on approximation quality. In Proceedings of AAAI  volume 21  pp. 1107  2006.

Choi  Arthur and Darwiche  Adnan. On relaxing determinism in arithmetic circuits. In ICML  2017.

Choi  Arthur  Chan  Hei  and Darwiche  Adnan. On Bayesian network approximation by edge
deletion. In Proceedings of the Twenty-First Conference on Uncertainty in Artiﬁcial Intelligence 
pp. 128–135  Arlington  Virginia  United States  2005. AUAI Press. ISBN 0-9749039-1-4.

Choi  Arthur  Kisa  Doga  and Darwiche  Adnan. Compiling Probabilistic Graphical Models Using

Sentential Decision Diagrams. In ECSQARU  2013.

Darwiche  Adnan. Compiling Knowledge into Decomposable Negation Normal Form. In Proceedings

of IJCAI  1999.

Darwiche  Adnan. Decomposable negation normal form. J. ACM  48:608–647  2001.

Darwiche  Adnan. A Differential Approach to Inference in Bayesian Networks. J. ACM  50(3):

280–305  May 2003. ISSN 0004-5411.

Darwiche  Adnan. Modeling and reasoning with Bayesian networks. Cambridge University Press 

2009.

Darwiche  Adnan. SDD: A New Canonical Representation of Propositional Knowledge Bases. In

Proceedings of IJCAI  2011.

De Raedt  Luc and Kimmig  Angelika. Probabilistic (logic) programming concepts. Machine

Learning  100(1):5–47  2015.

Dechter  Rina  Kask  Kalev  and Mateescu  Robert. Iterative join-graph propagation. In Proceedings of
the Eighteenth conference on Uncertainty in artiﬁcial intelligence  pp. 128–136. Morgan Kaufmann
Publishers Inc.  2002.

10

Ermon  Stefano  Gomes  Carla P  Sabharwal  Ashish  and Selman  Bart. Embed and project: Discrete
sampling with universal hashing. In Advances in Neural Information Processing Systems  pp.
2085–2093  2013.

Fierens  Daan  Van den Broeck  Guy  Renkens  Joris  Shterionov  Dimitar  Gutmann  Bernd  Thon 
Ingo  Janssens  Gerda  and De Raedt  Luc. Inference and learning in probabilistic logic programs
using weighted boolean formulas. TPLP  15(3):358–401  2015.

Gogate  Vibhav and Dechter  Rina. Samplesearch: A scheme that searches for consistent samples. In

Artiﬁcial Intelligence and Statistics  pp. 147–154  2007.

Gogate  Vibhav and Dechter  Rina. Samplesearch: Importance sampling in presence of determinism.

Artiﬁcial Intelligence  175(2):694–729  2011.

Koller  Daphne and Friedman  Nir. Probabilistic graphical models: principles and techniques. 2009.
Lowd  Daniel and Domingos  Pedro. Approximate inference by compilation to arithmetic circuits. In

NIPS  pp. 1477–1485  2010.

Murphy  Kevin P  Weiss  Yair  and Jordan  Michael I. Loopy belief propagation for approximate
inference: An empirical study. In Proceedings of UAI  pp. 467–475. Morgan Kaufmann Publishers
Inc.  1999.

Tokdar  Surya T and Kass  Robert E. Importance sampling: a review. Wiley Interdisciplinary Reviews:

Computational Statistics  2(1):54–60  2010.

Van den Broeck  Guy. Lifted Inference and Learning in Statistical Relational Models. PhD thesis 

KU Leuven  January 2013.

Van den Broeck  Guy and Darwiche  Adnan. On the role of canonicity in knowledge compilation. In

Proceedings of the 29th Conference on Artiﬁcial Intelligence (AAAI)  2015.

Van den Broeck  Guy and Suciu  Dan. Query Processing on Probabilistic Data: A Survey. Foundations

and Trends in Databases. Now Publishers  2017. doi: 10.1561/1900000052.

Vlasselaer  Jonas  Van den Broeck  Guy  Kimmig  Angelika  Meert  Wannes  and De Raedt  Luc.
Anytime inference in probabilistic logic programs with Tp-compilation. In Proceedings of IJCAI 
pp. 1852–1858  July 2015.

Vlasselaer  Jonas  Meert  Wannes  Van den Broeck  Guy  and De Raedt  Luc. Exploiting local and
repeated structure in dynamic Bayesian networks. Artiﬁcial Intelligence  232:43 – 53  March 2016.
ISSN 0004-3702. doi: 10.1016/j.artint.2015.12.001.

11

,Tal Friedman
Guy Van den Broeck