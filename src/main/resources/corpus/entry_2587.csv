2016,Improved Techniques for Training GANs,We present a variety of new architectural features and training procedures that we apply to the generative adversarial networks (GANs) framework. Using our new techniques  we achieve state-of-the-art results in semi-supervised classification on MNIST  CIFAR-10 and SVHN. The generated images are of high quality as confirmed by a visual Turing test: Our model generates MNIST samples that humans cannot distinguish from real data  and CIFAR-10 samples that yield a human error rate of 21.3%. We also present ImageNet samples with unprecedented resolution and show that our methods enable the model to learn recognizable features of ImageNet classes.,Improved Techniques for Training GANs

Tim Salimans

tim@openai.com

Ian Goodfellow
ian@openai.com

Wojciech Zaremba
woj@openai.com

Vicki Cheung

vicki@openai.com

Alec Radford

alec@openai.com

Xi Chen

peter@openai.com

Abstract

We present a variety of new architectural features and training procedures that we
apply to the generative adversarial networks (GANs) framework. Using our new
techniques  we achieve state-of-the-art results in semi-supervised classiﬁcation on
MNIST  CIFAR-10 and SVHN. The generated images are of high quality as con-
ﬁrmed by a visual Turing test: our model generates MNIST samples that humans
cannot distinguish from real data  and CIFAR-10 samples that yield a human error
rate of 21.3%. We also present ImageNet samples with unprecedented resolution
and show that our methods enable the model to learn recognizable features of
ImageNet classes.

1

Introduction

Generative adversarial networks [1] (GANs) are a class of methods for learning generative models
based on game theory. The goal of GANs is to train a generator network G(z; θ(G)) that produces
samples from the data distribution  pdata(x)  by transforming vectors of noise z as x = G(z; θ(G)).
The training signal for G is provided by a discriminator network D(x) that is trained to distinguish
samples from the generator distribution pmodel(x) from real data. The generator network G in turn
is then trained to fool the discriminator into accepting its outputs as being real.
Recent applications of GANs have shown that they can produce excellent samples [2  3]. However 
training GANs requires ﬁnding a Nash equilibrium of a non-convex game with continuous  high-
dimensional parameters. GANs are typically trained using gradient descent techniques that are
designed to ﬁnd a low value of a cost function  rather than to ﬁnd the Nash equilibrium of a game.
When used to seek for a Nash equilibrium  these algorithms may fail to converge [4].
In this work  we introduce several techniques intended to encourage convergence of the GANs game.
These techniques are motivated by a heuristic understanding of the non-convergence problem. They
lead to improved semi-supervised learning peformance and improved sample generation. We hope
that some of them may form the basis for future work  providing formal guarantees of convergence.
All code and hyperparameters may be found at https://github.com/openai/improved-gan.

2 Related work

Several recent papers focus on improving the stability of training and the resulting perceptual quality
of GAN samples [2  3  5  6]. We build on some of these techniques in this work. For instance  we
use some of the “DCGAN” architectural innovations proposed in Radford et al. [3]  as discussed
below.
One of our proposed techniques  feature matching  discussed in Sec. 3.1  is similar in spirit to
approaches that use maximum mean discrepancy [7  8  9] to train generator networks [10  11].

30th Conference on Neural Information Processing Systems (NIPS 2016)  Barcelona  Spain.

Another of our proposed techniques  minibatch features  is based in part on ideas used for batch
normalization [12]  while our proposed virtual batch normalization is a direct extension of batch
normalization.
One of the primary goals of this work is to improve the effectiveness of generative adversarial
networks for semi-supervised learning (improving the performance of a supervised task  in this case 
classiﬁcation  by learning on additional unlabeled examples). Like many deep generative models 
GANs have previously been applied to semi-supervised learning [13  14]  and our work can be seen
as a continuation and reﬁnement of this effort. In concurrent work  Odena [15] proposes to extend
GANs to predict image labels like we do in Section 5  but without our feature matching extension
(Section 3.1) which we found to be critical for obtaining state-of-the-art performance.

3 Toward Convergent GAN Training

Training GANs consists in ﬁnding a Nash equilibrium to a two-player non-cooperative game.
Each player wishes to minimize its own cost function  J (D)(θ(D)  θ(G)) for the discriminator and
J (G)(θ(D)  θ(G)) for the generator. A Nash equilibirum is a point (θ(D)  θ(G)) such that J (D) is at a
minimum with respect to θ(D) and J (G) is at a minimum with respect to θ(G). Unfortunately  ﬁnd-
ing Nash equilibria is a very difﬁcult problem. Algorithms exist for specialized cases  but we are not
aware of any that are feasible to apply to the GAN game  where the cost functions are non-convex 
the parameters are continuous  and the parameter space is extremely high-dimensional.
The idea that a Nash equilibrium occurs when each player has minimal cost seems to intuitively mo-
tivate the idea of using traditional gradient-based minimization techniques to minimize each player’s
cost simultaneously. Unfortunately  a modiﬁcation to θ(D) that reduces J (D) can increase J (G)  and
a modiﬁcation to θ(G) that reduces J (G) can increase J (D). Gradient descent thus fails to converge
for many games. For example  when one player minimizes xy with respect to x and another player
minimizes −xy with respect to y  gradient descent enters a stable orbit  rather than converging to
x = y = 0  the desired equilibrium point [16]. Previous approaches to GAN training have thus
applied gradient descent on each player’s cost simultaneously  despite the lack of guarantee that this
procedure will converge. We introduce the following techniques that are heuristically motivated to
encourage convergence:

3.1 Feature matching
Feature matching addresses the instability of GANs by specifying a new objective for the generator
that prevents it from overtraining on the current discriminator. Instead of directly maximizing the
output of the discriminator  the new objective requires the generator to generate data that matches
the statistics of the real data  where we use the discriminator only to specify the statistics that we
think are worth matching. Speciﬁcally  we train the generator to match the expected value of the
features on an intermediate layer of the discriminator. This is a natural choice of statistics for the
generator to match  since by training the discriminator we ask it to ﬁnd those features that are most
discriminative of real data versus data generated by the current model.
Letting f (x) denote activations on an intermediate layer of the discriminator  our new objective for
the generator is deﬁned as: ||Ex∼pdataf (x) − Ez∼pz(z)f (G(z))||2
2. The discriminator  and hence
f (x)  are trained in the usual way. As with regular GAN training  the objective has a ﬁxed point
where G exactly matches the distribution of training data. We have no guarantee of reaching this
ﬁxed point in practice  but our empirical results indicate that feature matching is indeed effective in
situations where regular GAN becomes unstable.

3.2 Minibatch discrimination
One of the main failure modes for GAN is for the generator to collapse to a parameter setting where
it always emits the same point. When collapse to a single mode is imminent  the gradient of the
discriminator may point in similar directions for many similar points. Because the discriminator
processes each example independently  there is no coordination between its gradients  and thus no
mechanism to tell the outputs of the generator to become more dissimilar to each other. Instead 
all outputs race toward a single point that the discriminator currently believes is highly realistic.
After collapse has occurred  the discriminator learns that this single point comes from the generator 
but gradient descent is unable to separate the identical outputs. The gradients of the discriminator

2

then push the single point produced by the generator around space forever  and the algorithm cannot
converge to a distribution with the correct amount of entropy. An obvious strategy to avoid this type
of failure is to allow the discriminator to look at multiple data examples in combination  and perform
what we call minibatch discrimination.
The concept of minibatch discrimination is quite general: any discriminator model that looks
at multiple examples in combination  rather than in isolation  could potentially help avoid col-
lapse of the generator.
In fact  the successful application of batch normalization in the dis-
criminator by Radford et al. [3] is well explained from this perspective. So far  however  we
have restricted our experiments to models that explicitly aim to identify generator samples that
are particularly close together. One successful speciﬁcation for modelling the closeness between
examples in a minibatch is as follows: Let f (xi) ∈ RA denote a vector of features for in-
put xi  produced by some intermediate layer in the discriminator. We then multiply the vector
f (xi) by a tensor T ∈ RA×B×C  which results in a matrix Mi ∈ RB×C. We then compute
the L1-distance between the rows of the resulting matrix Mi across samples i ∈ {1  2  . . .   n}
cb(xi  xj) = exp(−||Mi b − Mj b||L1) ∈ R.
and apply a negative exponential (Fig. 1):
The output o(xi) for this minibatch layer for a sample xi
is then deﬁned as the sum of the cb(xi  xj)’s to all other
samples:

o(xi)b =

cb(xi  xj) ∈ R

n(cid:88)
(cid:104)

j=1

(cid:105) ∈ RB

o(xi)1  o(xi)2  . . .   o(xi)B

o(xi) =
o(X) ∈ Rn×B

Next  we concatenate the output o(xi) of the minibatch
layer with the intermediate features f (xi) that were its
input  and we feed the result into the next layer of the
discriminator. We compute these minibatch features sep-
arately for samples from the generator and from the train-
ing data. As before  the discriminator is still required to
output a single number for each example indicating how
likely it is to come from the training data: The task of the discriminator is thus effectively still to
classify single examples as real data or generated data  but it is now able to use the other examples in
the minibatch as side information. Minibatch discrimination allows us to generate visually appealing
samples very quickly  and in this regard it is superior to feature matching (Section 6). Interestingly 
however  feature matching was found to work much better if the goal is to obtain a strong classiﬁer
using the approach to semi-supervised learning described in Section 5.

Figure 1: Figure sketches how mini-
batch discrimination works. Features
f (xi) from sample xi are multiplied
through a tensor T   and cross-sample
distance is computed.

(cid:80)t
3.3 Historical averaging
When applying this technique  we modify each player’s cost to include a term ||θ − 1
i=1 θ[i]||2 
where θ[i] is the value of the parameters at past time i. The historical average of the parameters can
be updated in an online fashion so this learning rule scales well to long time series. This approach is
loosely inspired by the ﬁctitious play [17] algorithm that can ﬁnd equilibria in other kinds of games.
We found that our approach was able to ﬁnd equilibria of low-dimensional  continuous non-convex
games  such as the minimax game with one player controlling x  the other player controlling y  and
value function (f (x) − 1)(y − 1)  where f (x) = x for x < 0 and f (x) = x2 otherwise. For
these same toy games  gradient descent fails by going into extended orbits that do not approach the
equilibrium point.

t

3.4 One-sided label smoothing
Label smoothing  a technique from the 1980s recently independently re-discovered by Szegedy et.
al [18]  replaces the 0 and 1 targets for a classiﬁer with smoothed values  like .9 or .1  and was
recently shown to reduce the vulnerability of neural networks to adversarial examples [19].
Replacing positive classiﬁcation targets with α and negative targets with β  the optimal discriminator
becomes D(x) = αpdata(x)+βpmodel(x)
pdata(x)+pmodel(x) . The presence of pmodel in the numerator is problematic
because  in areas where pdata is approximately zero and pmodel is large  erroneous samples from

3

pmodel have no incentive to move nearer to the data. We therefore smooth only the positive labels to
α  leaving negative labels set to 0.

3.5 Virtual batch normalization
Batch normalization greatly improves optimization of neural networks  and was shown to be highly
effective for DCGANs [3]. However  it causes the output of a neural network for an input example
x to be highly dependent on several other inputs x(cid:48) in the same minibatch. To avoid this problem
we introduce virtual batch normalization (VBN)  in which each example x is normalized based on
the statistics collected on a reference batch of examples that are chosen once and ﬁxed at the start
of training  and on x itself. The reference batch is normalized using only its own statistics. VBN is
computationally expensive because it requires running forward propagation on two minibatches of
data  so we use it only in the generator network.

4 Assessment of image quality

to
Generative adversarial networks lack an objective function  which makes it difﬁcult
compare performance of different models.
One intuitive metric of performance can be
obtained by having human annotators judge the visual quality of samples [2]. We
automate this process using Amazon Mechanical Turk (MTurk) 
using the web in-
terface in ﬁgure Fig. 2 (live at http://infinite-chamber-35121.herokuapp.com/
cifar-minibatch/)  which we use to ask annotators to distinguish between generated data
and real data. The resulting quality assessments of our models are described in Section 6.

Figure 2: Web interface given to anno-
tators. Annotators are asked to distin-
guish computer generated images from
real ones.

A downside of using human annotators is that the metric
varies depending on the setup of the task and the moti-
vation of the annotators. We also ﬁnd that results change
drastically when we give annotators feedback about their
mistakes: By learning from such feedback  annotators are
better able to point out the ﬂaws in generated images  giv-
ing a more pessimistic quality assessment. The left col-
umn of Fig. 2 presents a screen from the annotation pro-
cess  while the right column shows how we inform anno-
tators about their mistakes.

the model to generate varied images  so the marginal(cid:82) p(y|x = G(z))dz should have high entropy.

As an alternative to human annotators  we propose an automatic method to evaluate samples  which
we ﬁnd to correlate well with human evaluation: We apply the Inception model1 [20] to every
generated image to get the conditional label distribution p(y|x). Images that contain meaningful
objects should have a conditional label distribution p(y|x) with low entropy. Moreover  we expect
Combining these two requirements  the metric that we propose is: exp(ExKL(p(y|x)||p(y)))  where
we exponentiate results so the values are easier to compare. Our Inception score is closely related
to the objective used for training generative models in CatGAN [14]: Although we had less success
using such an objective for training  we ﬁnd it is a good metric for evaluation that correlates very
well with human judgment. We ﬁnd that it’s important to evaluate the metric on a large enough
number of samples (i.e. 50k) as part of this metric measures diversity.

5 Semi-supervised learning

Consider a standard classiﬁer for classifying a data point x into one of K possible classes. Such
a model takes in x as input and outputs a K-dimensional vector of logits {l1  . . .   lK}  that can
(cid:80)K
be turned into class probabilities by applying the softmax: pmodel(y = j|x) =
k=1 exp(lk). In
supervised learning  such a model is then trained by minimizing the cross-entropy between the
observed labels and the model predictive distribution pmodel(y|x).

exp(lj )

1We use the pretrained Inception model from http://download.tensorflow.org/models/image/
imagenet/inception-2015-12-05.tgz. Code to compute the Inception score with this model will be made
available by the time of publication.

4

We can do semi-supervised learning with any standard classiﬁer by simply adding samples from
the GAN generator G to our data set  labeling them with a new “generated” class y = K + 1  and
correspondingly increasing the dimension of our classiﬁer output from K to K + 1. We may then
use pmodel(y = K + 1 | x) to supply the probability that x is fake  corresponding to 1 − D(x) in
the original GAN framework. We can now also learn from unlabeled data  as long as we know that
it corresponds to one of the K classes of real data by maximizing log pmodel(y ∈ {1  . . .   K}|x).
Assuming half of our data set consists of real data and half of it is generated (this is arbitrary)  our
loss function for training the classiﬁer then becomes

L = −Ex y∼pdata(x y)[log pmodel(y|x)] − Ex∼G[log pmodel(y = K + 1|x)]
= Lsupervised + Lunsupervised  where

Lsupervised = −Ex y∼pdata(x y) log pmodel(y|x  y < K + 1)
Lunsupervised = −{Ex∼pdata(x) log[1 − pmodel(y = K + 1|x)] + Ex∼G log[pmodel(y = K + 1|x)]} 

where we have decomposed the total cross-entropy loss into our standard supervised loss function
Lsupervised (the negative log probability of the label  given that the data is real) and an unsupervised
loss Lunsupervised which is in fact the standard GAN game-value as becomes evident when we substi-
tute D(x) = 1 − pmodel(y = K + 1|x) into the expression:

Lunsupervised = −{Ex∼pdata(x) log D(x) + Ez∼noise log(1 − D(G(z)))}.

is

to

optimal

solution

for minimizing

both Lsupervised

and Lunsupervised

The
have
exp[lj(x)] = c(x)p(y=j  x)∀j<K+1 and exp[lK+1(x)] = c(x)pG(x) for some undeter-
mined scaling function c(x). The unsupervised loss is thus consistent with the supervised loss in
the sense of Sutskever et al. [13]  and we can hope to better estimate this optimal solution from
the data by minimizing these two loss functions jointly. In practice  Lunsupervised will only help if
it is not trivial to minimize for our classiﬁer and we thus need to train G to approximate the data
distribution. One way to do this is by training G to minimize the GAN game-value  using the
discriminator D deﬁned by our classiﬁer. This approach introduces an interaction between G and
our classiﬁer that we do not fully understand yet  but empirically we ﬁnd that optimizing G using
feature matching GAN works very well for semi-supervised learning  while training G using GAN
with minibatch discrimination does not work at all. Here we present our empirical results using this
approach; developing a full theoretical understanding of the interaction between D and G using this
approach is left for future work.
Finally  note that our classiﬁer with K + 1 outputs is over-parameterized: subtracting a general
function f (x) from each output logit  i.e. setting lj(x) ← lj(x) − f (x)∀j  does not change the
output of the softmax. This means we may equivalently ﬁx lK+1(x) = 0∀x  in which case Lsupervised
becomes the standard supervised loss function of our original classiﬁer with K classes  and our
discriminator D is given by D(x) = Z(x)

Z(x)+1   where Z(x) =(cid:80)K

k=1 exp[lk(x)].

Importance of labels for image quality

5.1
Besides achieving state-of-the-art results in semi-supervised learning  the approach described above
also has the surprising effect of improving the quality of generated images as judged by human
annotators. The reason appears to be that the human visual system is strongly attuned to image
statistics that can help infer what class of object an image represents  while it is presumably less
sensitive to local statistics that are less important for interpretation of the image. This is supported
by the high correlation we ﬁnd between the quality reported by human annotators and the Inception
score we developed in Section 4  which is explicitly constructed to measure the “objectness” of a
generated image. By having the discriminator D classify the object shown in the image  we bias it to
develop an internal representation that puts emphasis on the same features humans emphasize. This
effect can be understood as a method for transfer learning  and could potentially be applied much
more broadly. We leave further exploration of this possibility for future work.

5

6 Experiments

We performed semi-supervised experiments on MNIST  CIFAR-10 and SVHN  and sample gener-
ation experiments on MNIST  CIFAR-10  SVHN and ImageNet. We provide code to reproduce the
majority of our experiments.

6.1 MNIST
The MNIST dataset contains 60  000 labeled
images of digits. We perform semi-supervised
training with a small randomly picked fraction
of these  considering setups with 20  50  100 
and 200 labeled examples. Results are averaged
over 10 random subsets of labeled data  each
chosen to have a balanced number of examples
from each class. The remaining training images
are provided without labels. Our networks have
5 hidden layers each. We use weight normaliza-
tion [21] and add Gaussian noise to the output
of each layer of the discriminator. Table 1 sum-
marizes our results.
Samples generated by the generator during
semi-supervised learning using feature match-
ing (Section 3.1) do not look visually appealing
(left Fig. 3). By using minibatch discrimination
instead (Section 3.2) we can improve their visual quality. On MTurk  annotators were able to dis-
tinguish samples in 52.4% of cases (2000 votes total)  where 50% would be obtained by random
guessing. Similarly  researchers in our institution were not able to ﬁnd any artifacts that would al-
low them to distinguish samples. However  semi-supervised learning with minibatch discrimination
does not produce as good a classiﬁer as does feature matching.

Figure 3: (Left) samples generated by model dur-
ing semi-supervised training. Samples can be
clearly distinguished from images coming from
MNIST dataset. (Right) Samples generated with
minibatch discrimination.
Samples are com-
pletely indistinguishable from dataset images.

Model

DGN [22]

Virtual Adversarial [23]

CatGAN [14]

Skip Deep Generative Model [24]

Ladder network [25]

Auxiliary Deep Generative Model [24]

Our model

Ensemble of 10 of our models

Number of incorrectly predicted test examples

for a given number of labeled samples

20

50

100

333 ± 14

200

212

191 ± 10
132 ± 7
106 ± 37
96 ± 2
93 ± 6.5
86 ± 5.6

Table 1: Number of incorrectly classiﬁed test examples for the semi-supervised setting on permuta-
tion invariant MNIST. Results are averaged over 10 seeds.

1677 ± 452
1134 ± 445

221 ± 136
142 ± 96

90 ± 4.2
81 ± 4.3

6.2 CIFAR-10

Model

Ladder network [25]

CatGAN [14]
Our model

Test error rate for

a given number of labeled samples

1000

2000

4000

8000

Ensemble of 10 of our models

21.83±2.01
19.22±0.54

19.61±2.09
17.25±0.66

20.40±0.47
19.58±0.46
18.63±2.32
15.59±0.47

17.72±1.82
14.87±0.89

Table 2: Test error on semi-supervised CIFAR-10. Results are averaged over 10 splits of data.

CIFAR-10 is a small  well studied dataset of 32 × 32 natural images. We use this data set to study
semi-supervised learning  as well as to examine the visual quality of samples that can be achieved.
For the discriminator in our GAN we use a 9 layer deep convolutional network with dropout and
weight normalization. The generator is a 4 layer deep CNN with batch normalization. Table 2
summarizes our results on the semi-supervised learning task.

6

Figure 4: Samples generated during semi-supervised training on CIFAR-10 with feature matching
(Section 3.1  left) and minibatch discrimination (Section 3.2  right).

When presented with 50% real and 50% fake data generated by our best CIFAR-10 model  MTurk
users correctly categorized 78.7% of images correctly. However  MTurk users may not be sufﬁ-
ciently familiar with CIFAR-10 images or sufﬁciently motivated; we ourselves were able to catego-
rize images with > 95% accuracy. We validated the Inception score described above by observing
that MTurk accuracy drops to 71.4% when the data is ﬁltered by using only the top 1% of samples
according to the Inception score. We performed a series of ablation experiments to demonstrate that
our proposed techniques improve the Inception score  presented in Table 3. We also present images
for these ablation experiments—in our opinion  the Inception score correlates well with our subjec-
tive judgment of image quality. Samples from the dataset achieve the highest value. All the models
that even partially collapse have relatively low scores. We caution that the Inception score should be
used as a rough guide to evaluate models that were trained via some independent criterion; directly
optimizing Inception score will lead to the generation of adversarial examples [26].

-VBN+BN
7.54 ± .07

-L+HA

6.86 ± .06

-LS

6.83 ± .06

-L

4.36 ± .04

-MBF

3.87 ± .03

Samples
Model
Score ± std.

Real data

11.24 ± .12

Our methods
8.09 ± .07

Table 3: Table of Inception scores for samples generated by various models for 50  000 images.
Score highly correlates with human judgment  and the best score is achieved for natural images.
Models that generate collapsed samples have relatively low score. This metric allows us to avoid
relying on human evaluations. “Our methods” includes all the techniques described in this work 
except for feature matching and historical averaging. The remaining experiments are ablation exper-
iments showing that our techniques are effective. “-VBN+BN” replaces the VBN in the generator
with BN  as in DCGANs. This causes a small decrease in sample quality on CIFAR. VBN is more
important for ImageNet. “-L+HA” removes the labels from the training process  and adds historical
averaging to compensate. HA makes it possible to still generate some recognizable objects. Without
HA  sample quality is considerably reduced (see ”-L”). “-LS” removes label smoothing and incurs a
noticeable drop in performance relative to “our methods.” “-MBF” removes the minibatch features
and incurs a very large drop in performance  greater even than the drop resulting from removing the
labels. Adding HA cannot prevent this problem.

6.3 SVHN
For the SVHN data set  we used the same architecture and experimental setup as for CIFAR-10.
Figure 5 compares against the previous state-of-the-art  where it should be noted that the model

7

of [24] is not convolutional  but does use an additional data set of 531131 unlabeled examples. The
other methods  including ours  are convolutional and do not use this data.

Model

Percentage of incorrectly predicted test examples

for a given number of labeled samples

500

1000

2000

Virtual Adversarial [23]

Stacked What-Where Auto-Encoder [27]

DCGAN [3]

Skip Deep Generative Model [24]

Our model

Ensemble of 10 of our models

24.63
23.56
22.48

16.61±0.24
8.11 ± 1.3
5.88 ± 1.0

18.44 ± 4.8

6.16 ± 0.58

Figure 5: (Left) Error rate on SVHN. (Right) Samples from the generator for SVHN.

ImageNet

6.4
We tested our techniques on a dataset of unprecedented scale: 128 × 128 images from the
ILSVRC2012 dataset with 1 000 categories. To our knowledge  no previous publication has ap-
plied a generative model to a dataset with both this large of a resolution and this large a number
of object classes. The large number of object classes is particularly challenging for GANs due to
their tendency to underestimate the entropy in the distribution. We extensively modiﬁed a publicly
available implementation of DCGANs2 using TensorFlow [28] to achieve high performance  using
a multi-GPU implementation. DCGANs without modiﬁcation learn some basic image statistics and
generate contiguous shapes with somewhat natural color and texture but do not learn any objects.
Using the techniques described in this paper  GANs learn to generate objects that resemble animals 
but with incorrect anatomy. Results are shown in Fig. 6.

Figure 6: Samples generated from the ImageNet dataset. (Left) Samples generated by a DCGAN.
(Right) Samples generated using the techniques proposed in this work. The new techniques enable
GANs to learn recognizable features of animals  such as fur  eyes  and noses  but these features are
not correctly combined to form an animal with realistic anatomical structure.

7 Conclusion

Generative adversarial networks are a promising class of generative models that has so far been
held back by unstable training and by the lack of a proper evaluation metric. This work presents
partial solutions to both of these problems. We propose several techniques to stabilize training
that allow us to train models that were previously untrainable. Moreover  our proposed evaluation
metric (the Inception score) gives us a basis for comparing the quality of these models. We apply
our techniques to the problem of semi-supervised learning  achieving state-of-the-art results on a
number of different data sets in computer vision. The contributions made in this work are of a
practical nature; we hope to develop a more rigorous theoretical understanding in future work.

2https://github.com/carpedm20/DCGAN-tensorﬂow

8

References

[1] Ian Goodfellow  Jean Pouget-Abadie  Mehdi Mirza  et al. Generative adversarial nets. In NIPS  2014.
[2] Emily Denton  Soumith Chintala  Arthur Szlam  and Rob Fergus. Deep generative image models using a

laplacian pyramid of adversarial networks. arXiv preprint arXiv:1506.05751  2015.

[3] Alec Radford  Luke Metz  and Soumith Chintala. Unsupervised representation learning with deep convo-

lutional generative adversarial networks. arXiv preprint arXiv:1511.06434  2015.

[4] Ian J Goodfellow. On distinguishability criteria for estimating generative models.

arXiv preprint

arXiv:1412.6515  2014.

[5] Daniel Jiwoong Im  Chris Dongjoo Kim  Hui Jiang  and Roland Memisevic. Generating images with

recurrent adversarial networks. arXiv preprint arXiv:1602.05110  2016.

[6] Donggeun Yoo  Namil Kim  Sunggyun Park  Anthony S Paek  and In So Kweon. Pixel-level domain

transfer. arXiv preprint arXiv:1603.07442  2016.

[7] Arthur Gretton  Olivier Bousquet  Alex Smola  and Bernhard Sch¨olkopf. Measuring statistical depen-

dence with hilbert-schmidt norms. In Algorithmic learning theory  pages 63–77. Springer  2005.

[8] Kenji Fukumizu  Arthur Gretton  Xiaohai Sun  and Bernhard Sch¨olkopf. Kernel measures of conditional

dependence. In NIPS  volume 20  pages 489–496  2007.

[9] Alex Smola  Arthur Gretton  Le Song  and Bernhard Sch¨olkopf. A hilbert space embedding for distribu-

tions. In Algorithmic learning theory  pages 13–31. Springer  2007.

[10] Yujia Li  Kevin Swersky  and Richard S. Zemel. Generative moment matching networks. CoRR 

abs/1502.02761  2015.

[11] Gintare Karolina Dziugaite  Daniel M Roy  and Zoubin Ghahramani. Training generative neural networks

via maximum mean discrepancy optimization. arXiv preprint arXiv:1505.03906  2015.

[12] Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by reducing

internal covariate shift. arXiv preprint arXiv:1502.03167  2015.

[13] Ilya Sutskever  Rafal Jozefowicz  Karol Gregor  et al. Towards principled unsupervised learning. arXiv

preprint arXiv:1511.06440  2015.

[14] Jost Tobias Springenberg. Unsupervised and semi-supervised learning with categorical generative adver-

sarial networks. arXiv preprint arXiv:1511.06390  2015.

[15] Augustus Odena.

Semi-supervised learning with generative adversarial networks.

arXiv preprint

[16] Ian Goodfellow  Yoshua Bengio  and Aaron Courville. Deep Learning. 2016. MIT Press.
[17] George W Brown.

Iterative solution of games by ﬁctitious play. Activity analysis of production and

arXiv:1606.01583  2016.

allocation  13(1):374–376  1951.

[18] C. Szegedy  V. Vanhoucke  S. Ioffe  J. Shlens  and Z. Wojna. Rethinking the Inception Architecture for

Computer Vision. ArXiv e-prints  December 2015.

[19] David Warde-Farley and Ian Goodfellow. Adversarial perturbations of deep neural networks. In Tamir
Hazan  George Papandreou  and Daniel Tarlow  editors  Perturbations  Optimization  and Statistics  chap-
ter 11. 2016. Book in preparation for MIT Press.

[20] Christian Szegedy  Vincent Vanhoucke  Sergey Ioffe  Jonathon Shlens  and Zbigniew Wojna. Rethinking

the inception architecture for computer vision. arXiv preprint arXiv:1512.00567  2015.

[21] Tim Salimans and Diederik P Kingma. Weight normalization: A simple reparameterization to accelerate

training of deep neural networks. arXiv preprint arXiv:1602.07868  2016.

[22] Diederik P Kingma  Shakir Mohamed  Danilo Jimenez Rezende  and Max Welling. Semi-supervised

learning with deep generative models. In Neural Information Processing Systems  2014.

[23] Takeru Miyato  Shin-ichi Maeda  Masanori Koyama  Ken Nakae  and Shin Ishii. Distributional smoothing

by virtual adversarial examples. arXiv preprint arXiv:1507.00677  2015.

[24] Lars Maaløe  Casper Kaae Sønderby  Søren Kaae Sønderby  and Ole Winther. Auxiliary deep generative

models. arXiv preprint arXiv:1602.05473  2016.

[25] Antti Rasmus  Mathias Berglund  Mikko Honkala  Harri Valpola  and Tapani Raiko. Semi-supervised

learning with ladder networks. In Advances in Neural Information Processing Systems  2015.

[26] Christian Szegedy  Wojciech Zaremba  Ilya Sutskever  et al.

Intriguing properties of neural networks.

[27] Junbo Zhao  Michael Mathieu  Ross Goroshin  and Yann Lecun. Stacked what-where auto-encoders.

arXiv preprint arXiv:1312.6199  2013.

arXiv preprint arXiv:1506.02351  2015.

[28] Mart´ın Abadi  Ashish Agarwal  Paul Barham  et al. TensorFlow: Large-scale machine learning on het-

erogeneous systems  2015. Software available from tensorﬂow.org.

9

,Matthias Hein
Simon Setzer
Leonardo Jost
Syama Sundar Rangapuram
Tim Salimans
Ian Goodfellow
Wojciech Zaremba
Vicki Cheung
Alec Radford
Xi Chen
Chang Xiao
Peilin Zhong
Changxi Zheng