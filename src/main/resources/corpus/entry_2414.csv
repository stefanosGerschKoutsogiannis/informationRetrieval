2014,Hardness of parameter estimation in graphical models,We consider the problem of learning the canonical parameters specifying an undirected graphical model (Markov random field) from the mean parameters. For graphical models representing a minimal exponential family  the canonical parameters are uniquely determined by the mean parameters  so the problem is feasible in principle. The goal of this paper is to investigate the computational feasibility of this statistical task. Our main result shows that parameter estimation is in general intractable: no algorithm can learn the canonical parameters of a generic pair-wise binary graphical model from the mean parameters in time bounded by a polynomial in the number of variables (unless RP = NP). Indeed  such a result has been believed to be true (see the monograph by Wainwright and Jordan) but no proof was known. Our proof gives a polynomial time reduction from approximating the partition function of the hard-core model  known to be hard  to learning approximate parameters. Our reduction entails showing that the marginal polytope boundary has an inherent repulsive property  which validates an optimization procedure over the polytope that does not use any knowledge of its structure (as required by the ellipsoid method and others).,Hardness of parameter estimation

in graphical models

Guy Bresler1 David Gamarnik2 Devavrat Shah1

Laboratory for Information and Decision Systems

{gbresler gamarnik devavrat}@mit.edu

Department of EECS1 and Sloan School of Management2

Massachusetts Institute of Technology

Abstract

We consider the problem of learning the canonical parameters specifying an undi-
rected graphical model (Markov random ﬁeld) from the mean parameters. For
graphical models representing a minimal exponential family  the canonical param-
eters are uniquely determined by the mean parameters  so the problem is feasible
in principle. The goal of this paper is to investigate the computational feasibil-
ity of this statistical task. Our main result shows that parameter estimation is in
general intractable: no algorithm can learn the canonical parameters of a generic
pair-wise binary graphical model from the mean parameters in time bounded by a
polynomial in the number of variables (unless RP = NP). Indeed  such a result has
been believed to be true (see [1]) but no proof was known.
Our proof gives a polynomial time reduction from approximating the partition
function of the hard-core model  known to be hard  to learning approximate pa-
rameters. Our reduction entails showing that the marginal polytope boundary has
an inherent repulsive property  which validates an optimization procedure over
the polytope that does not use any knowledge of its structure (as required by the
ellipsoid method and others).

1

Introduction

Graphical models are a powerful framework for succinct representation of complex high-
dimensional distributions. As such  they are at the core of machine learning and artiﬁcial intelli-
gence  and are used in a variety of applied ﬁelds including ﬁnance  signal processing  communica-
tions  biology  as well as the modeling of social and other complex networks. In this paper we focus
on binary pairwise undirected graphical models  a rich class of models with wide applicability. This
is a parametric family of probability distributions  and for the models we consider  the canonical
parameters ✓ are uniquely determined by the vector µ of mean parameters  which consist of the
node-wise and pairwise marginals.
Two primary statistical tasks pertaining to graphical models are inference and parameter estimation.
A basic inference problem is the computation of marginals (or conditional probabilities) given the
model  that is  the forward mapping ✓ 7! µ. Conversely  the backward mapping µ 7! ✓ corresponds
to learning the canonical parameters from the mean parameters. The backward mapping is deﬁned
only for µ in the marginal polytope M of realizable mean parameters  and this is important in what
follows. The backward mapping captures maximum likelihood estimation of parameters; the study
of the statistical properties of maximum likelihood estimation for exponential families is a classical
and important subject.
In this paper we are interested in the computational tractability of these statistical tasks. A basic
question is whether or not these maps can be computed efﬁciently (namely in time polynomial in

1

the problem size). As far as inference goes  it is well known that approximating the forward map
(inference) is computational hard in general. This was shown by Luby and Vigoda [2] for the hard-
core model  a simple pairwise binary graphical model (deﬁned in (2.1)). More recently  remarkably
sharp results have been obtained  showing that computing the forward map for the hard-core model
is tractable if and only if the system exhibits the correlation decay property [3  4]. In contrast  to the
best of our knowledge  no analogous hardness result exists for the backward mapping (parameter
estimation)  despite its seeming intractability [1].
Tangentially related hardness results have been previously obtained for the problem of learning the
graph structure underlying an undirected graphical model. Bogdanov et al. [5] showed hardness
of determining graph structure when there are hidden nodes  and Karger and Srebro [6] showed
hardness of ﬁnding the maximum likelihood graph with a given treewidth. Computing the backward
mapping  in comparison  requires estimation of the parameters when the graph is known.
Our main result  stated precisely in the next section  establishes hardness of approximating the
backward mapping for the hard-core model. Thus  despite the problem being statistically feasible 
it is computationally intractable.
The proof is by reduction  showing that the backward map can be used as a black box to efﬁciently
estimate the partition function of the hard-core model. The reduction  described in Section 4  uses
the variational characterization of the log-partition function as a constrained convex optimization
over the marginal polytope of realizable mean parameters. The gradient of the function to be min-
imized is given by the backward mapping  and we use a projected gradient optimization method.
Since approximating the partition function of the hard-core model is known to be computationally
hard  the reduction implies hardness of approximating the backward map.
The main technical difﬁculty in carrying out the argument arises because the convex optimization
is constrained to the marginal polytope  an intrinsically complicated object. Indeed  even deter-
mining membership (or evaluating the projection) to within a crude approximation of the polytope
is NP-hard [7]. Nevertheless  we show that it is possible to do the optimization without using any
knowledge of the polytope structure  as is normally required by ellipsoid  barrier  or projection meth-
ods. To this end  we prove that the polytope boundary has an inherent repulsive property that keeps
the iterates inside the polytope without actually enforcing the constraint. The consequence of the
boundary repulsion property is stated in Proposition 4.6 of Section 4  which is proved in Section 5.
Our reduction has a close connection to the variational approach to approximate inference [1]. There 
the conjugate-dual representation of the log-partition function leads to a relaxed optimization prob-
lem deﬁned over a tractable bound for the marginal polytope and with a simple surrogate to the
entropy function. What our proof shows is that accurate approximation of the gradient of the en-
tropy obviates the need to relax the marginal polytope.
We mention a related work of Kearns and Roughgarden [8] showing a polynomial-time reduction
from inference to determining membership in the marginal polytope. Note that such a reduction
does not establish hardness of parameter estimation: the empirical marginals obtained from samples
are guaranteed to be in the marginal polytope  so an efﬁcient algorithm could hypothetically exist
for parameter estimation without contradicting the hardness of marginal polytope membership.
After completion of our manuscript  we learned that Montanari [9] has independently and simulta-
neously obtained similar results showing hardness of parameter estimation in graphical models from
the mean parameters. His high-level approach is similar to ours  but the details differ substantially.

2 Main result

In order to establish hardness of learning parameters from marginals for pairwise binary graphical
models  we focus on a speciﬁc instance of this class of graphical models  the hard-core model.
Given a graph G = (V  E) (where V = {1  . . .   p})  the collection of independent set vectors
I(G) ✓{ 0  1}V consist of vectors  such that i = 0 or j = 0 (or both) for every edge {i  j}2 E.
Each vector  2I (G) is the indicator vector of an independent set. The hard-core model assigns
nonzero probability only to independent set vectors  with

P✓() = exp✓Xi2V

✓ii  (✓)◆ for each  2I (G) .

(2.1)

2

This is an exponential family with vector of sufﬁcient statistics () = (i)i2V 2{ 0  1}p and
vector of canonical parameters ✓ = (✓i)i2V 2 Rp. In the statistical physics literature the model
is usually parameterized in terms of node-wise fugacity (or activity) i = e✓i. The log-partition
function

(✓) = log X2I(G)

exp✓Xi2V

✓ii◆!

serves to normalize the distribution; note that (✓) is ﬁnite for all ✓ 2 Rp. Here and throughout  all
logarithms are to the natural base.
The set M of realizable mean parameters plays a major role in the paper  and is deﬁned as

M = {µ 2 Rp| there exists a ✓ such that E✓[()] = µ} .

For the hard-core model (2.1)  the set M is a polytope equal to the convex hull of independent set
vectors I(G) and is called the marginal polytope. The marginal polytope’s structure can be rather
complex  and one indication of this is that the number of half-space inequalities needed to represent
M can be very large  depending on the structure of the graph G underlying the model [10  11].
The model (2.1) is a regular minimal exponential family  so for each µ in the interior M of the
marginal polytope there corresponds a unique ✓(µ) satisfying the dual matching condition

E✓[()] = µ .

We are concerned with approximation of the backward mapping µ 7! ✓  and we use the following
notion of approximation.
Deﬁnition 2.1. We say that ˆy 2 R is a -approximation to y 2 R if y(1  )  ˆy  (1 + ). A
vector ˆv 2 Rp is a -approximation to v 2 Rp if each entry ˆvi is a -approximation to vi.
We next deﬁne the appropriate notion of efﬁcient approximation algorithm.
Deﬁnition 2.2. A fully polynomial randomized approximation scheme (FPRAS) for a mapping fp :
Xp ! R is a randomized algorithm that for each > 0 and input x 2X p  with probability at
least 3/4 outputs a -approximation ˆfp(x) to fp(x) and moreover the running time is bounded by a
polynomial Q(p  1).

Our result uses the complexity classes RP and NP  deﬁned precisely in any complexity text (such
as [12]). The class RP consists of problems solvable by efﬁcient (randomized polynomial) algo-
rithms  and NP consists of many seemingly difﬁcult problems with no known efﬁcient algorithms.
It is widely believed that NP 6= RP. Assuming this  our result says that there cannot be an efﬁcient
approximation algorithm for the backward mapping in the hard-core model (and thus also for the
more general class of binary pairwise graphical models).
We recall that approximating the backward mapping entails taking a vector µ as input and producing
an approximation of the corresponding vector of canonical parameters ✓ as output. It should be noted
that even determining whether a given vector µ belongs to the marginal polytope M is known to be
an NP-hard problem [7]. However  our result shows that the problem is NP-hard even if the input
vector µ is known a priori to be an element of the marginal polytope M.
Theorem 2.3. Assuming NP 6= RP  there does not exist an FPRAS for the backward mapping
µ 7! ✓.
As discussed in the introduction  Theorem 2.3 is proved by showing that the backward mapping
can be used as a black-box to efﬁciently estimate the partition function of the hard core model 
known to be hard. This uses the variational characterization of the log-partition function as well as a
projected gradient optimization method. Proving validity of the projected gradient method requires
overcoming a substantial technical challenge: we show that the iterates remain within the marginal
polytope without explicitly enforcing this (in particular  we do not project onto the polytope). The
bulk of the paper is devoted to establishing this fact  which may be of independent interest.
In the next section we give necessary background on conjugate-duality and the variational character-
ization as well as review the result we will use on hardness of computing the log-partition function.
The proof of Theorem 2.3 is then given in Section 4.

3

3 Background

3.1 Exponential families and conjugate duality

We now provide background on exponential families (as can be found in the monograph by Wain-
wright and Jordan [1]) specialized to the hard-core model (2.1) on a ﬁxed graph G = (V  E).
General theory on conjugate duality justifying the statements of this subsection can be found in
Rockafellar’s book [13].
The basic relationship between the canonical and mean parameters is expressed via conjugate (or
Fenchel) duality. The conjugate dual of the log-partition function (✓) is

⇤(µ) := sup

✓2Rdnhµ  ✓i  (✓)o .

(✓) = sup

µ2Mnh✓  µi  ⇤(µ)o  
µ2M nh✓  µi  ⇤(µ)o .

Note that for our model (✓) is ﬁnite for all ✓ 2 Rp and furthermore the supremum is uniquely
attained. On the interior M of the marginal polytope  ⇤ is the entropy function. The log-
partition function can then be expressed as

(3.1)

with

µ(✓) = arg max

(3.2)
The forward mapping ✓ 7! µ is speciﬁed by the variational characterization (3.2) or alternatively by
the gradient map r: Rp !M .
As mentioned earlier  for each µ in the interior M there is a unique ✓(µ) satisfying the dual match-
ing condition E✓(µ)[()] = (r)(✓(µ)) = µ.
For mean parameters µ 2M   the backward mapping µ 7! ✓(µ) to the canonical parameters is
given by

✓2Rp nhµ  ✓i  (✓)o
r⇤(µ) = ✓(µ) .
The latter representation will be the more useful one for us.

or by the gradient

✓(µ) = arg max

3.2 Hardness of inference

We describe an existing result on the hardness of inference and state the corollary we will use. The
result says that  subject to widely believed conjectures in computational complexity  no efﬁcient
algorithm exists for approximating the partition function of certain hard-core models. Recall that
the hard-core model with fugacity  is given by (2.1) with ✓i = ln  for each i 2 V .
Theorem 3.1 ([3  4]). Suppose d  3 and > c(d) = (d1)d1
(d2)d . Assuming NP 6= RP  there exists
no FPRAS for computing the partition function of the hard-core model with fugacity  on regular
graphs of degree d. In particular  no FPRAS exists when  = 1 and d  5.
We remark that the source of hardness is the long-range dependence property of the hard-core model
for > c(d). It was shown in [14] that for < c(d) the model exhibits decay of correlations
and there is an FPRAS for the log-partition function (in fact there is a deterministic approximation
scheme as well). We note that a number of hardness results are known for the hardcore and Ising
models  including [15  16  3  2  4  17  18  19]. The result stated in Theorem 3.1 sufﬁces for our
purposes.
From this section we will need only the following corollary  proved in the Appendix. The proof 
standard in the literature  uses the self-reducibility of the hard-core model to express the partition
function in terms of marginals computed on subgraphs.
Corollary 3.2. Consider the hard-core model (2.1) on graphs of degree most d with parameters
✓i = 0 for all i 2 V . Assuming NP 6= RP  there exists no FPRAS ˆµ(0) for the vector of marginal
probabilities µ(0)  where error is measured entry-wise as per Deﬁnition 2.1.

4

4 Reduction by optimizing over the marginal polytope

In this section we describe our reduction and prove Theorem 2.3. We deﬁne polynomial constants

✏ = p8  

q = p5  

(4.1)

which we will leave as ✏  q  and s to clarify the calculations. Also  given the asymptotic nature of the
results  we assume that p is larger than a universal constant so that certain inequalities are satisﬁed.
Proposition 4.1. Fix a graph G on p nodes. Let ˆ✓ : M ! Rp be a black box giving a -
approximation for the backward mapping µ 7! ✓ for the hard-core model (2.1). Using 1/✏2 calls
to ˆ✓  and computation bounded by a polynomial in p  1/  it is possible to produce a 4p7/2/q✏2-
approximation ˆµ(0) to the marginals µ(0) corresponding to all zero parameters.

and s = ✏
2p2  

We ﬁrst observe that Theorem 2.3 follows almost immediately.

⇤(µ) .

Proof of Theorem 2.3. A standard median ampliﬁcation trick (see e.g. [20]) allows to decrease the
probability 1/4 of erroneous output by a FPRAS to below 1/p✏2 using O(log(p✏2)) function calls.
Thus the assumed FPRAS for the backward mapping can be made to give a -approximation ˆ✓ to ✓
on 1/✏2 successive calls  with probability of no erroneous outputs equal to at least 3/4. By taking
 = ˜q✏ 2p7/2/2 in Proposition 4.1 we get a ˜-approximation to µ(0) with computation bounded
by a polynomial in p  1/˜. In other words  the existence of an FPRAS for the mapping µ 7! ✓ gives
an FPRAS for the marginals µ(0)  and by Corollary 3.2 this is not possible if NP 6= RP.
We now work towards proving Proposition 4.1  the goal being to estimate the vector of marginals
µ(0) for some ﬁxed graph G. The desired marginals are given by the solution to the optimiza-
tion (3.2) with ✓ = 0:

µ(0) =  arg min
µ2M

(4.2)
We know from Section 3 that for x 2M  the gradient r⇤(x) = ✓(x)  that is  the backward
mapping amounts to a gradient ﬁrst order (gradient) oracle. A natural approach to solving the
optimization problem (4.2) is to use a projected gradient method. For reasons that will be come clear
later  instead of projecting onto the marginal polytope M  we project onto the shrunken marginal
polytope M1 ⇢M deﬁned as
(4.3)

M1 = {µ 2M\ [q✏  1)p : µ + ✏ · ei 2M for all i}  

where ei is the ith standard basis vector.
As mentioned before  projecting onto M1 is NP-hard  and this must therefore be avoided if we
are to obtain a polynomial-time reduction. Nevertheless  we temporarily assume that it is possible
to do the projection and address this difﬁculty later. With this in mind  we propose to solve the
optimization (4.2) by a projected gradient method with ﬁxed step size s 

xt+1 = PM1(xt  sr⇤(xt)) = PM1(xt  s✓(xt))  

(4.4)
In order for the method (4.4) to succeed a ﬁrst requirement is that the optimum is inside M1. The
following lemma is proved in the Appendix.
Lemma 4.2. Consider the hard core model (2.1) on a graph G with maximum degree d on p  2d+1
nodes and canonical parameters ✓ = 0. Then the corresponding vector of mean parameters µ(0) is
in M1.
One of the beneﬁts of operating within M1 is that the gradient is bounded by a polynomial in p 
and this will allow the optimization procedure to converge in a polynomial number of steps. The
following lemma amounts to a rephrasing of Lemmas 5.3 and 5.4 in Section 5 and the proof is
omitted.
Lemma 4.3. We have the gradient bound kr⇤(x)k1 = k✓(x)k1  p/✏ = p9 for any x 2M 1.
Next  we state general conditions under which an approximate projected gradient algorithm con-
verges quickly. Better convergence rates are possible using the strong convexity of ⇤ (shown in
Lemma 4.5 below)  but this lemma sufﬁces for our purposes. The proof is standard (see [21] or
Theorem 3.1 in [22] for a similar statement) and is given in the Appendix for completeness.

5

T PT

Lemma 4.4 (Projected gradient method). Let G : C ! R be a convex function deﬁned over a com-
pact convex set C with minimizer x⇤ 2 arg minx2C G(x). Suppose we have access to an approxi-
mate gradient oracledrG(x) for x 2 C with error bounded as supx2C kdrG(x)rG(x)k1  /2.
Let L = supx2C kdrG(x)k. Consider the projected gradient method xt+1 = PC(xt  sdrG(xt))
starting at x1 2 C and with ﬁxed step size s = /2L2. After T = 4kx1  x⇤k2L2/2 iterations the
average ¯xT = 1

t=1 xt satisﬁes G(¯xT )  G(x⇤)  .

2 -strongly convex. As a consequence  if ⇤(x) 

To translate accuracy in approximating the function ⇤(x⇤) to approximating x⇤  we use the fact that
⇤ is strongly convex. The proof (in the Appendix) uses the equivalence between strong convexity
of ⇤ and strong smoothness of the Fenchel dual   the latter being easy to check. Since we
only require the implication of the lemma  we defer the deﬁnitions of strong convexity and strong
smoothness to the appendix where they are used.
Lemma 4.5. The function ⇤ : M ! R is p 3
⇤(x⇤)   for x 2M  and x⇤ = arg miny2M ⇤(y)  then kx  x⇤k  2p 3
2 .
At this point all the ingredients are in place to show that the updates (4.4) rapidly approach µ(0) 
but a crucial difﬁculty remains to be overcome. The assumed black box ˆ✓ for approximating the
mapping µ 7! ✓ is only deﬁned for µ inside M  and thus it is not at all obvious how to evaluate
the projection onto the closely related polytope M1. Indeed  as shown in [7]  even approximate
projection onto M is NP-hard  and no polynomial time reduction can require projecting onto M1
(assuming P 6= NP).
The goal of the subsequent Section 5 is to prove Proposition 4.6 below  which states that the opti-
mization procedure can be carried out without any knowledge about M or M1. Speciﬁcally  we
show that thresholding coordinates sufﬁces  that is  instead of projecting onto M1 we may project
onto the translated non-negative orthant [q✏  1)p. Writing P for this projection  we show that the
original projected gradient method (4.4) has identical iterates xt as the much simpler update rule

xt+1 = P(xt  s✓(xt)) .

(4.5)
Proposition 4.6. Choose constants as per (4.1). Suppose x1 2M 1  and consider the iterates
xt+1 = P(xt  sˆ✓(xt)) for t  1  where ˆ✓(xt) is a -approximation of ✓(xt) for all t  1. Then
xt 2M 1  for all t  1  and thus the iterates are the same using either P or PM1.
The next section is devoted to the proof of Proposition 4.6. We now complete the reduction.

p   1

p   . . .   1

2p   1

2p   . . .   1

2p  q✏  for all i.

Proof of Proposition 4.1. We start the gradient update procedure xt+1 = P(xt  sˆ✓(xt)) at the
point x1 = ( 1
2p )  which we claim is within M1 for any graph G for p = |V | large
enough. To see this  note that ( 1
p ) is in M  because it is a convex combination (with
weight 1/p each) of the independent set vectors e1  . . .   ep. Hence x1+ 1
2p·ei 2M   and additionally
i = 1
x1
We establish that xt 2M 1 for each t  1 by induction  having veriﬁed the base case t = 1 in
the preceding paragraph. Let xt 2M 1 for some t  1. At iteration t of the update rule we make
a call to the black box ˆ✓(xt) giving a -approximation to the backward mapping ✓(xt)  compute
xt  sˆ✓(xt)  and then project onto [q✏  1)p. Proposition 4.6 ensures that xt+1 2M 1. Therefore 
the update xt+1 = P(xt  sˆ✓(xt)) is the same as xt+1 = PM1(xt  sˆ✓(xt)).
Now we can now apply Lemma 4.4 with G = ⇤  C = M1   = 2p2/✏ and L =

supx2C kdrG(x)k2 pp(p/✏)2 = p3/2/✏. After

iterations the average ¯xT = 1
Lemma 4.5 implies that k¯xT  x⇤k2  2p 3
i  x⇤i| 2p 3
|¯xT

T PT

T = 4kx1  x⇤k2L2/2  4p(p3/✏2)/(42p4/✏2) = 1/2

t=1 xt satisﬁes G(¯xT )  G(x⇤)  .

2 x⇤i /q✏ for each i 2 V . Hence ¯xT is a 4p7/2/q✏2-approximation for x⇤.

2   and since x⇤i  q✏  we get the entry-wise bound

6

5 Proof of Proposition 4.6

In Subsection 5.1 we prove estimates on the parameters ✓ corresponding to µ close to the boundary
of M1  and then in Subsection 5.2 we use these estimates to show that the boundary of M1 has a
certain repulsive property that keeps the iterates inside.

5.1 Bounds on gradient
We start by introducing some helpful notation. For a node i  let N (i) = {j 2 [p] : (i  j) 2 E}
denote its neighbors. We partition the collection of independent set vectors as

where

I = Si [ Si [ S↵i

 

Si = { 2I : i = 1} = {Ind sets containing i}
Si = {  ei :  2 Si} = {Ind sets where i can be added}
S↵i = { 2I : j = 1 for some j 2N (i)} = {Ind sets conﬂicting with i} .

For a collection of independent set vectors S ✓I we write P(S) as shorthand for P✓( 2 S) and

f (S) = P(S) · e(✓) =X2S

exp✓Xj2V

✓jj◆ .

We can then write the marginal at node i as µi = P(Si)  and since Si  Si   S↵i partition I  the space
of all independent sets of G  1 = P(Si) + P(Si ) + P(S↵i ). For each i let

⌫i = P(S↵i ) = P(a neighbor of i is in ) .

The following lemma speciﬁes a condition on µi and ⌫i that implies a lower bound on ✓i.
Lemma 5.1. If µi + ⌫i  1   and ⌫i  1  ⇣ for ⇣> 1  then ✓i  ln(⇣  1).
Proof. Let ↵ = e✓i  and observe that f (Si) = ↵f (Si ). We want to show that ↵  ⇣  1.
The ﬁrst condition µi + ⌫i  1   implies that

f (Si) + f (S↵i )  (1  )(f (Si) + f (S↵i ) + f (Si ))

= (1  )(f (Si) + f (S↵i ) + ↵1f (Si))  

and rearranging gives

f (S↵i ) + f (Si) 

1  


↵1f (Si) .

(5.1)

(5.2)

The second condition ⌫i  1  ⇣ reads f (S↵i )  (1  ⇣)(f (Si) + f (S↵i ) + f (Si )) or

f (S↵i ) 

1  ⇣
⇣

f (Si)(1 + ↵1)

Combining (5.1) and (5.2) and simplifying results in ↵  ⇣  1.
We now use the preceding lemma to show that if a coordinate is close to the boundary of the shrunken
marginal polytope M1  then the corresponding parameter is large.
Lemma 5.2. Let r be a positive real number. If µ 2M 1 and µ + r✏· ei /2M   then ✓i  ln q
r  1.
Proof. We would like to apply Lemma 5.1 with ⇣ = q/r and  = r✏  which requires showing that
(a) ⌫i  1  q✏ and (b) µi + ⌫i  1  r✏. To show (a)  note that if µ 2M 1  then µi  q✏ by
deﬁnition of M1. It follows that ⌫i  1  µi  1  q✏.
We now show (b). Since µi = P(Si)  ⌫i = P(S↵i )  and 1 = P(Si) + P(S↵i ) + P (Si )  (b)
is equivalent to P(Si )  r✏. We assume that µ + r✏ · ei /2M and suppose for the sake of

7

⌘ + ⌘ei
0
⌘

if  2 Si
if  2 Si
otherwise .

⌘0 =8<:

contradiction that P(Si ) > r✏ . Writing ⌘ = P() for  2I   so that µ =P2I ⌘ ·   we deﬁne

a new probability measure

One can check that µ0 =P2I ⌘0 has µ0j = µj for each i 6= j and µ0i = µi + P(Si ) > µi + r✏.
The point µ0  being a convex combination of independent set vectors  must be in M  and hence so
must µ + r✏ · ei. But this contradicts the hypothesis and completes the proof of the lemma.
The proofs of the next two lemmas are similar in spirit to Lemma 8 in [23] and are proved in the
Appendix. The ﬁrst lemma gives an upper bound on the parameters (✓i)i2V corresponding to an
arbitrary point in M1.
Lemma 5.3. If µ + ✏ · ei 2M   then ✓i  p/✏. Hence if µ 2M 1  then ✓i  p/✏ for all i.
The next lemma shows that if a component µi is not too small  the corresponding parameter ✓i is
also not too negative. As before  this allows to bound from below the parameters corresponding to
an arbitrary point in M1.
Lemma 5.4. If µi  q✏  then ✓i  p/q✏. Hence if µ 2M 1  then ✓i  p/q✏ for all i.
5.2 Finishing the proof of Proposition 4.6

We sketch the remainder of the proof here; full detail is given in Section D of the Supplement.
Starting with an arbitrary xt in M1  our goal is to show that xt+1 = P(xt  sˆ✓(xt)) remains
in M1. The proof will then follow by induction  because our initial point x1 is in M1 by the
hypothesis.
The argument considers separately each hyperplane constraint for M of the form hh  xi  1. The
distance of x from the hyperplane is 1  hh  xi. Now  the deﬁnition of M1 implies that if x 2M 1 
then x + ✏· ei 2M 1 for all coordinates i  and thus 1hh  xi  ✏khk1 for all constraints. We call a
constraint hh  xi  1 critical if 1  hh  xi <✏ khk1  and active if ✏khk1  1  hh  xi < 2✏khk1.
For xt 2M 1 there are no critical constraints  but there may be active constraints.
We ﬁrst show that inactive constraints can at worst become active for the next iterate xt+1  which
requires only that the step-size is not too large relative to the magnitude of the gradient (Lemma 4.3
gives the desired bound). Then we show (using the gradient estimates from Lemmas 5.2  5.3 
and 5.4) that the active constraints have a repulsive property and that xt+1 is no closer than xt
to any active constraint  that is  hh  xt+1i  hh  xti. The argument requires care  because the pro-
i  sˆ✓i(xt) being very negative if xt
jection P may prevent coordinates i from decreasing despite xt
is already small. These arguments together show that xt+1 remains in M1  completing the proof.
6 Discussion

i

This paper addresses the computational tractability of parameter estimation for the hard-core model.
Our main result shows hardness of approximating the backward mapping µ 7! ✓ to within a small
polynomial factor. This is a fairly stringent form of approximation  and it would be interesting
to strengthen the result to show hardness even for a weaker form of approximation. A possible
goal would be to show that there exists a universal constant c > 0 such that approximation of the
backward mapping to within a factor 1 + c in each coordinate is NP-hard.

Acknowledgments
GB thanks Sahand Negahban for helpful discussions. Also we thank Andrea Montanari for sharing
his unpublished manuscript [9]. This work was supported in part by NSF grants CMMI-1335155
and CNS-1161964  and by Army Research Ofﬁce MURI Award W911NF-11-1-0036.

8

References
[1] M. Wainwright and M. Jordan  “Graphical models  exponential families  and variational infer-

ence ” Foundations and Trends in Machine Learning  vol. 1  no. 1-2  pp. 1–305  2008.

[2] M. Luby and E. Vigoda  “Fast convergence of the glauber dynamics for sampling independent

sets ” Random Structures and Algorithms  vol. 15  no. 3-4  pp. 229–241  1999.

[3] A. Sly and N. Sun  “The computational hardness of counting in two-spin models on d-regular

graphs ” in FOCS  pp. 361–369  IEEE  2012.

[4] A. Galanis  D. Stefankovic  and E. Vigoda  “Inapproximability of the partition function for the

antiferromagnetic Ising and hard-core models ” arXiv preprint arXiv:1203.2226  2012.

[5] A. Bogdanov  E. Mossel  and S. Vadhan  “The complexity of distinguishing Markov random
ﬁelds ” Approximation  Randomization and Combinatorial Optimization  pp. 331–342  2008.
[6] D. Karger and N. Srebro  “Learning Markov networks: Maximum bounded tree-width graphs ”

in Symposium on Discrete Algorithms (SODA)  pp. 392–401  2001.

[7] D. Shah  D. N. Tse  and J. N. Tsitsiklis  “Hardness of low delay network scheduling ” Infor-

mation Theory  IEEE Transactions on  vol. 57  no. 12  pp. 7810–7817  2011.

[8] T. Roughgarden and M. Kearns  “Marginals-to-models reducibility ” in Advances in Neural

Information Processing Systems  pp. 1043–1051  2013.

[9] A. Montanari  “Computational implications of reducing data to sufﬁcient statistics.” unpub-

lished  2014.

[10] M. Deza and M. Laurent  Geometry of cuts and metrics. Springer  1997.
[11] G. M. Ziegler  “Lectures on 0/1-polytopes ” in Polytopes—combinatorics and computation 

pp. 1–41  Springer  2000.

[12] C. H. Papadimitriou  Computational complexity. John Wiley and Sons Ltd.  2003.
[13] R. T. Rockafellar  Convex analysis  vol. 28. Princeton university press  1997.
[14] D. Weitz  “Counting independent sets up to the tree threshold ” in Proceedings of the thirty-

eighth annual ACM symposium on Theory of computing  pp. 140–149  ACM  2006.

[15] M. Dyer  A. Frieze  and M. Jerrum  “On counting independent sets in sparse graphs ” SIAM

Journal on Computing  vol. 31  no. 5  pp. 1527–1541  2002.

[16] A. Sly  “Computational transition at the uniqueness threshold ” in FOCS  pp. 287–296  2010.
[17] F. Jaeger  D. Vertigan  and D. Welsh  “On the computational complexity of the jones and tutte

polynomials ” Math. Proc. Cambridge Philos. Soc  vol. 108  no. 1  pp. 35–53  1990.

[18] M. Jerrum and A. Sinclair  “Polynomial-time approximation algorithms for the Ising model ”

SIAM Journal on computing  vol. 22  no. 5  pp. 1087–1116  1993.

[19] S. Istrail  “Statistical mechanics  three-dimensionality and NP-completeness: I. universality
of intracatability for the partition function of the Ising model across non-planar surfaces ” in
STOC  pp. 87–96  ACM  2000.

[20] M. R. Jerrum  L. G. Valiant  and V. V. Vazirani  “Random generation of combinatorial struc-
tures from a uniform distribution ” Theoretical Computer Science  vol. 43  pp. 169–188  1986.
[21] Y. Nesterov  Introductory lectures on convex optimization: A basic course  vol. 87. Springer 

2004.

[22] S. Bubeck 

“Theory of convex optimization for machine learning.” Available at

http://www.princeton.edu/ sbubeck/pub.html.

[23] L. Jiang  D. Shah  J. Shin  and J. Walrand  “Distributed random access algorithm: scheduling

and congestion control ” IEEE Trans. on Info. Theory  vol. 56  no. 12  pp. 6182–6207  2010.

[24] D. P. Bertsekas  Nonlinear programming. Athena Scientiﬁc  1999.
[25] S. M. Kakade  S. Shalev-Shwartz  and A. Tewari  “Regularization techniques for learning with

matrices ” J. Mach. Learn. Res.  vol. 13  pp. 1865–1890  June 2012.

[26] J. M. Borwein and J. D. Vanderwerff  Convex functions: constructions  characterizations and

counterexamples. No. 109  Cambridge University Press  2010.

9

,Guy Bresler
David Gamarnik
Devavrat Shah