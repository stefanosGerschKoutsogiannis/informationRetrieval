2016,Algorithms and matching lower bounds for approximately-convex optimization,In recent years  a rapidly increasing number of applications in practice requires solving non-convex objectives  like training neural networks  learning graphical models  maximum likelihood estimation etc. Though simple heuristics such as gradient descent with very few modifications tend to work well  theoretical understanding is very weak.   We consider possibly the most natural class of non-convex functions where one could hope to obtain provable guarantees: functions that are ``approximately convex''  i.e. functions $\tf: \Real^d \to \Real$ for which there exists a \emph{convex function} $f$ such that for all $x$  $|\tf(x) - f(x)| \le \errnoise$ for a fixed value $\errnoise$. We then want to minimize $\tf$  i.e. output a point $\tx$ such that $\tf(\tx) \le \min_{x} \tf(x) + \err$.   It is quite natural to conjecture that for fixed $\err$  the problem gets harder for larger $\errnoise$  however  the exact dependency of $\err$ and $\errnoise$ is not known. In this paper  we strengthen the known \emph{information theoretic} lower bounds on the trade-off between $\err$ and $\errnoise$ substantially  and exhibit an algorithm that matches these lower bounds for a large class of convex bodies.,Algorithms and matching lower bounds for

approximately-convex optimization

Yuanzhi Li

Princeton University
Princeton  NJ  08450

Andrej Risteski

Princeton University
Princeton  NJ  08450

Department of Computer Science

Department of Computer Science

yuanzhil@cs.princeton.edu

risteski@cs.princeton.edu

Abstract

In recent years  a rapidly increasing number of applications in practice requires
optimizing non-convex objectives  like training neural networks  learning graphical
models  maximum likelihood estimation. Though simple heuristics such as gradient
descent with very few modiﬁcations tend to work well  theoretical understanding
is very weak.
We consider possibly the most natural class of non-convex functions where one
could hope to obtain provable guarantees: functions that are “approximately con-
vex”  i.e. functions ˜f : Rd → R for which there exists a convex function f such
that for all x  | ˜f (x) − f (x)| ≤ ∆ for a ﬁxed value ∆. We then want to minimize
˜f  i.e. output a point ˜x such that ˜f (˜x) ≤ minx
It is quite natural to conjecture that for ﬁxed   the problem gets harder for larger
∆  however  the exact dependency of  and ∆ is not known. In this paper  we
signiﬁcantly improve the known lower bound on ∆ as a function of  and an
algorithm matching this lower bound for a natural class of convex bodies. More
precisely  we identify a function T : R+ → R+ such that when ∆ = O(T ()) 
we can give an algorithm that outputs a point ˜x such that ˜f (˜x) ≤ minx
˜f (x) + 

(cid:1). On the other hand  when ∆ = Ω(T ())  we also prove an

˜f (x) + .

within time poly(cid:0)d  1



information theoretic lower bound that any algorithm that outputs such a ˜x must
use super polynomial number of evaluations of ˜f.

1

Introduction

Optimization of convex functions over a convex domain is a well studied problem in machine
learning  where a variety of algorithms exist to solve the problem efﬁciently. However  in recent years 
practitioners face ever more often non-convex objectives – e.g. training neural networks  learning
graphical models  clustering data  maximum likelihood estimation etc. Albeit simple heuristics such
as gradient descent with few modiﬁcations usually work very well  theoretical understanding in these
settings are still largely open.
The most natural class of non-convex functions where one could hope to obtain provable guarantees
is functions that are “approximately convex”: functions ˜f : Rd → R for which there exists a convex
function f such that for all x  | ˜f (x) − f (x)| ≤ ∆ for a ﬁxed value ∆. In this paper  we focus on zero
order optimization of ˜f: an algorithm that outputs a point ˜x such that ˜f (˜x) ≤ minx
˜f (x) +   where
the algorithm in the course of its execution is allowed to pick points x ∈ Rd and query the value of
˜f (x).

30th Conference on Neural Information Processing Systems (NIPS 2016)  Barcelona  Spain.

Trivially  one can solve the problem by constructing a -net and search through all the net points.

However  such an algorithm requires Ω(cid:0) 1
poly(cid:0)d  1

(cid:1) (in particular  this implies the algorithm makes poly(cid:0)d  1

(cid:1)d evaluations of ˜f  which is highly inefﬁcient in high

dimension. In this paper  we are interested in efﬁcient algorithms: algorithms that run in time

(cid:1) evaluations of ˜f).







One extreme case of the problem is ∆ = 0  which is just standard convex optimization  where
algorithms exist to solve it in polynomial time for every  > 0. However  even when ∆ is any
quantity > 0  none of these algorithms extend without modiﬁcation. (Indeed  we are not imposing
any structure on ˜f − f like stochasticity.) Of course  when ∆ = +∞  the problem includes any
non-convex optimization  where we cannot hope for an efﬁcient solution for any ﬁnite . Therefore 
the crucial quantity to study is the optimal tradeoff of  and ∆: For which   ∆ the problem can be
solved in polynomial time  and for which it can not.
In this paper  we study the rate of ∆ as a function of : We identify a function T : R+ → R+ such that
when ∆ = O(T ())  we can give an algorithm that outputs a point ˜x such that ˜f (˜x) ≤ minx
˜f (x) + 

(cid:1) over a natural class of well-conditioned convex bodies. On the other hand 

within time poly(cid:0)d  1

when ∆ = ˜Ω(T ())1  we also prove an information theoretic lower bound that any algorithm outputs
such ˜x must use super polynomial number of evaluations of ˜f. Our result can be summarized as the
following two theorems:
Theorem (Algorithmic upper bound  informal). There exists an algorithm A that for any function ˜f
over a well-conditioned convex set in Rd of diameter 1 which is ∆ close to an 1-Lipschitz convex
function 2 f  and



∆ = O

(cid:1)

 

d


d

max

(cid:27)(cid:19)(cid:19)

(cid:18)(cid:26) 2√

(cid:18)
˜f (x) +  within time poly(cid:0)d  1
(cid:18)

(cid:27)(cid:19)

(cid:26) 2√


d

 

d

∆ = ˜Ω

max

A ﬁnds a point ˜x such that ˜f (˜x) ≤ minx
The notion of well-conditioning will formally be deﬁned in section 3  but intuitively captures the
notion that the convex body “curves” in all directions to a good extent.
Theorem (Information theoretic lower bound  informal). For every algorithm A  every d  ∆   with



there exists a function ˜f on a convex set in Rd of diameter 1  and ˜f is ∆ close to an 1-Lipschitz
convex function f  such that A can not ﬁnd a point ˜x with ˜f (˜x) ≤ minx
evaluations of ˜f.



˜f (x) +  in poly(cid:0)d  1

(cid:1)

2 Prior work

To the best of our knowledge  there are three works on the problem of approximately convex
optimization  which we summarize brieﬂy below.
On the algorithmic side  the classical paper by [DKS14] considered optimizing smooth convex
functions over convex bodies with smooth boundaries. More precisely  they assume a bound on both
the gradient and the Hessian of F . Furthermore  they assume that for every small ball centered at a
point in the body  a large proportion of the volume of the ball lies in the body. Their algorithm is local
search: they show that for a sufﬁciently small r  in a ball of radius r there is with high probability a
point which has a smaller value than the current one  as long as the current value is sufﬁciently larger
than the optimum. For constant-smooth functions only  their algorithm applies when ∆ = O( √
).
Also on the algorithmic side  the work by [BLNR15] considers 1-Lipschitz functions  but their
algorithm only applies to the case where ∆ = O( 
)). Their
methods rely on sampling log-concave distribution via hit and run walks. The crucial idea is to show
that for approximately convex functions  one needs to sample from “approximately log-concave”

d ) (so not optimal unless  = O( 1√

d

d

1The ˜Ω notation hides polylog(d/) factors.
2The assumptions on the diameter of K and the Lipschitz condition are for convenience of stating the results.

(See Section ?? to extend to arbitrary diameter and Lipschitz constant)

2

distributions  which they show can be done by a form of rejection sampling together with classical
methods for sampling log-concave distributions.
Finally  [SV15] consider information theoretic lower bounds. They show that when ∆ = 1/d1/2−δ
2 − δ  when optimizing a convex function
no algorithm can  in polynomial time  achieve achieve  = 1
over the hypercube. This translates to a super polynomial information theoretic lower bound when
∆ = Ω( √
). They additionally give lower bounds when the approximately convex function is
d
multiplicatively  rather than additively  close to a convex function. 3
We also note a related problem is zero-order optimization  where the goal is to minimize a function
we only have value oracle access to. The algorithmic motivations here come from various applications
where we only have black-box access to the function we are optimizing  and there is a classical line of
work on characterizing the oracle complexity of convex optimization.[NY83  NS  DJWW15]. In all
of these settings however  the oracles are either noiseless  or the noise is stochastic  usually because
the target application is in bandit optimization. [AD10  AFH+11  Sha12]

3 Overview of results

Formally  we will consider the following scenario.
Deﬁnition 3.1. A function ˜f : K → Rd will be called ∆-approximately convex if there exists a
1-Lipschitz convex function f : K → Rd  s.t. ∀x ∈ K | ˜f (x) − f (x)| ≤ ∆.
For ease of exposition  we also assume that K has diameter 14. We consider the problem of optimizing
˜f  more precisely  we are interesting in ﬁnding a point ˜x ∈ K  such that

˜f (˜x) ≤ min
x∈K

˜f (x) + 

We give the following results:
Theorem 3.1 (Information theoretic lower bound). For very constant c ≥ 1  there exists a constant
dc such that for every algorithm A  every d ≥ dc  there exists a convex set K ⊆ Rd with diameter 1 
an ∆-approximate convex function ˜f : K → R and  ∈ [0  1/64) 5 such that

(cid:26) 2√

 

d

(cid:27)

×


d

(cid:18)

13c log

(cid:19)2

d


∆ ≥ max

Such that A fails to output  with probability ≥ 1/2  a point ˜x ∈ K with ˜f (˜x) ≤ minx∈K{ ˜f (x)} + 
in o(( d

 )c) time.

≤ µ.

In order to state the upper bounds  we will need the deﬁnition of a well-conditioned body:
Deﬁnition 3.2 (µ-well-conditioned). A convex body K is said to be µ-well-conditioned for µ ≥ 1 
if there exists a function F : Rd → R such that K = {x|F (x) ≤ 0} and for every x ∈ ∂K:
(cid:107)∇2F (x)(cid:107)2
(cid:107)∇F (x)(cid:107)2
This notion of well-conditioning of a convex body to the best of our knowledge has not been deﬁned
before  but it intuitively captures the notion that the convex body should “curve” in all directions to a
certain extent. In particular  the unit ball has µ = 1.
Theorem 3.2 (Algorithmic upper bound). Let d be a positive integer  δ > 0 be a positive real number 
  ∆ be two positive real number such that
∆ ≤ max

(cid:26) 2

× 1

(cid:27)

√
µ

d

 


d

16348

Then there exists an algorithm A such that on given any ∆-approximate convex function ˜f over a
µ-rounded convex set K ⊆ Rd of diameter 1  A returns a point ˜x ∈ K with probability 1 − δ in time

poly(cid:0)d  1

   log 1

δ

(cid:1) such that

˜f (˜x) ≤ min
x∈K

˜f (x) + 

bounded by 1.

3Though these are not too difﬁcult to derive from the additive ones  considering the convex body has diameter

4Generalizing to arbitrary Lipschitz constants and diameters is discussed in Section 6.
5Since we normalize f to be 1-Lipschitz and K to have diameter 1  the problem is only interesting for  ≤ 1

3

For the reader wishing to digest a condition-free version of the above result  the following weaker
result is also true (and much easier to prove):
Theorem 3.3 (Algorithmic upper bound (condition-free)). Let d be a positive integer  δ > 0 be a
positive real number    ∆ be two positive real number such that
× 1

(cid:26) 2√

∆ ≤ max

(cid:27)


d

 

d

16348

Then there exists an algorithm A such that on given any ∆-approximate convex function ˜f over a
µ-rounded convex set K ⊆ Rd of diameter 1  A returns a point ˜x ∈ K with probability 1 − δ in time

poly(cid:0)d  1

   log 1

δ

(cid:1) such that

˜f (˜x) ≤ min

x∈S(K −)

˜f (x) + 

Where S(K −) = {x ∈ K|B(x) ⊆ K}
The result merely states that we can output a value that competes with points “well-inside” the convex
body – around which a ball of radius of  still lies inside the body.
The assumptions on the diameter of K and the Lipschitz condition are for convenience of stating
the results. It’s quite easy to extend both the lower and upper bounds to an arbitrary diameter and
Lipschitz constant  as we discuss in Section 6.

3.1 Proof techniques

We brieﬂy outline the proof techniques we use. We proceed with the information theoretic lower
bound ﬁrst. The idea behind the proof is the following. We will construct a function G(x) and a family
of convex functions {fw(x)} depending on a direction w ∈ S d (S d is the unit sphere in Rd). On one
hand  the minimal value of G and fw are quite different: minx G(x) ≥ 0  and minx fw(x) ≤ −2.
On the other hand  the approximately convex function ˜fw(x) for fw(x) we consider will be such
that ˜fw(x) = G(x) except in a very small cone around w. Picking w at random  no algorithm with
small number of queries will  with high probability  every query a point in this cone. Therefore  the
algorithm will proceed as if the function is G(x) and fail to optimize ˜fw.
Proceeding to the algorithmic result  since [BLNR15] already shows the existence of an efﬁcient
d )  we only need to give an algorithm that solves the problem when
algorithm when ∆ = O( 
d ) and ∆ = O( 2√
) (i.e. when   ∆ are large). There are two main ideas for the algorithm.
∆ = Ω( 
First  we show that the gradient of a smoothed version of ˜fw (in the spirit of [FKM05]) at any point
x will be correlated with x∗ − x  where x∗ = argminx∈K ˜fw(x). The above strategy will however
require averaging the value of ˜fw along a ball of radius   which in many cases will not be contained
in K (especially when  is large). Therefore  we come up with a way to extend ˜fw outside of K in a
manner that maintains the correlation with x∗ − x.

d

4

Information-theoretic lower bound

In this section  we present the proof of Theorem 3.1.
The idea is to construct a function G(x)  a family of convex functions {fw(x)} depending on a
direction w ∈ S d  such that minx G(x) ≥ 0  minx fw(x) ≤ −2  and an approximately convex
˜fw(x) for fw(x) such that ˜fw(x) = G(x) except in a very small “critical” region depending on w.
Picking w at random  we want to argue that the algorithm will with high probability not query the
critical region. The convex body K used in the lower bound will be arguably the simplest convex
body imaginable: the unit ball B1(0).
We might hope to prove a lower bound for even a linear function fw for a start  similarly as in [SV15].
A reasonable candidate construction is the following: we set fw(x) = −(cid:104)w  x(cid:105) for some random
chosen unit vector w and deﬁne ˜f (x) = 0 when |(cid:104)x  w(cid:105)| ≤ log d
(cid:107)x(cid:107)2 and ˜f (x) = fw(x) otherwise.6
√
d
6For the proof sketch only  to maintain ease of reading all of the inequalities we state will be only correct up

to constants. In the actual proofs we will be completely formal.

4

d

d

Observe  this translates to ∆ = log d
√
. It’s a standard concentration of measure fact that for “most”
d
of the points x in the unit ball  |(cid:104)x  w(cid:105)| ≤ log d
(cid:107)x(cid:107)2. This implies that any algorithm that makes a
√
d
polynomial number of queries to ˜f will with high probability see 0 in all of the queries  but clearly
min ˜f (x) = −. However  this idea fails to generalize to optimal range as ∆ = 1√
 is tight for
linear  even smooth functions.7
In order to obtain the optimal bound  we need to modify the construction to a non-linear  non-smooth
function. We will  in a certain sense  “hide” a random linear function inside a non-linear function.
For a random unit vector w  we consider two regions inside the unit ball: a core C = Br(0) for
r = max{  1√
(cid:107)x(cid:107)2}. The convex function f
for some α > 0 outside C ∪ A and −(cid:104)w  x(cid:105) for x ∈ C ∪ A. We construct
will look like (cid:107)x(cid:107)1+α
˜f as ˜f = f when f (x) is sufﬁciently large (e.g. |f (x)| > ∆
2 otherwise. Clearly  such ˜f
obtain its minimal at point w  with ˜f (w) = −. However  since ˜f = (cid:107)x(cid:107)1+α
outside C or A  the
algorithm needs either query A or query C ∩ Ac to detect w. The former happens with exponentially
small probability in high dimensions  and for any x ∈ C ∩ Ac |f (x)| = |(cid:104)w  x(cid:105)| ≤  log d
(cid:107)x(cid:107)2 ≤
√
d
 log d
√
2 . Therefore  the algorithm will
d

}  and a “critical angle” A = {x | |(cid:104)x  w(cid:105)| ≥ log d
√
d

2   which implies that ˜f (x) = ∆

d} × log d
  

2 in Rd centered at 0. 8

fail with high probability.
Now  we move on to the detailed of the constructions. We will consider K = B 1
radius 1
4.1 The family {fw(x)}
Before delving into the construction we need the following deﬁnition:
Deﬁnition 4.1 (Lower Convex Envelope (LCE)). Given a set S ⊆ Rd  a function F : S → R 
deﬁne the lower convex envelope FLCE = LCE(F ) as a function FLCE : Rd → R such that for every
x ∈ Rd 

(0): the ball of

r ≤ max{ 2√

2 ) and ∆

 ≤ ∆

2

d

2

2

FLCE(x) = max

y∈S {(cid:104)x − y ∇F (y)(cid:105) + F (y)}

Proposition 4.1. LCE(F ) is convex.
Proof. LCE(F) is the pointwise maximum of linear functions  so the claim follows.
Remark : The LCE of a function F is a function deﬁned over the entire Rd  while the input function
F is only deﬁned in a set S (not necessarily convex set). When the input function F is convex 
LCE(F ) can be considered as an extension of F to the entire Rd.
To deﬁne the family fw(x)  we will need four parameters: a power factor α > 0  a shrinking factor β 
and a radius factor γ > 0  and a vector w ∈ Rd such that (cid:107)w(cid:107)2 = 1
2  which we specify in a short bit.
Construction 4.1. Given w  α  β  γ  deﬁne the core C = Bγ(0)  the critical angle A = {x |
|(cid:104)x  w(cid:105)| ≥ β(cid:107)x(cid:107)2} and let H = K ∩ C ∩ A. Let ˜h : H → R be deﬁned as

(cid:107)x(cid:107)1+α
and deﬁne lw(x) = −8(cid:104)x  w(cid:105). Finally let fw : K → Rd as

˜h(x) =

1
2

2

(cid:110)˜hLCE(x)  lw(x)
(cid:111)

fw(x) = max

Where ˜hLCE = LCE(˜h) as in Deﬁnition 4.1.
We then construct the “hard” function ˜fw as the following:
Construction 4.2. Consider the function ˜fw : K → R:

(cid:26) fw(x)

˜fw(x) =

max{fw(x)  1

2 ∆}

if x ∈ K ∩(cid:0)C ∪ A(cid:1) ;

otherwise.

7This follows from the results in [DKS14]
8We pick B 1

(0) instead of the unit ball in order to ensure the diameter is 1.

2

5

Consider the following settings of the parameters β  γ  α (depending on the magnitude of ):

√

≤  ≤ 1
√

(log d)2 : β =

d

• Case 1  1√
• Case 2   ≤ 1√
• Case 3  1

d

: β =
64 ≥  ≥ 1

(log d)2 : β =

√
c log d/

d

c log d
√

d

  γ = 10c(log d

 )1.5  α =

1

log(1/γ).

(log d/)3/2  α =

1

log(1/γ).

  γ = 10c√
√

c log d√

d
  γ = 1

d

2  α = 1.

Then  the we formalize the proof intuition from the previous section with the following claims.
Following the the proof outline  we ﬁrst show the minimum of fw is small  in particular we will show
fw(w) ≤ −2.
Lemma 4.1. fw(w) = −2
Finally  we show that ˜fw is indeed a ∆-approximately convex  by showing ∀x ∈ K |fw − ˜fw| ≤ ∆
and fw is 1-Lipschitz and convex.
Proposition 4.2. ˜fw is a ∆-approximately convex.

Next  we construct G(x)  which does not depend on w  we want to show that for an algorithm with
small number of queries of ˜fw  it can not distinguish fw from this function.
Construction 4.3. Let G : K → R be deﬁned as:

(cid:26) max(cid:8) 1+α

1

2(cid:107)x(cid:107)1+α

2

G(x) =

4 (cid:107)x(cid:107)2 − α

4 γ  1

2 ∆(cid:9) if x ∈ K ∩ C ;

otherwise.

The following is true:
Lemma 4.2. G(x) ≥ 0 and {x ∈ K | G(x) (cid:54)= ˜fw(x)} ⊆ A
We show how Theorem 3.1 is implied given these statements:

Proof of Theorem 3.1. With everything prior to this set up  the ﬁnal claim is somewhat standard.
We want to show that no algorithm can  with probability ≥ 1
2  output a point x  s.t. ˜fw(x) ≤
˜fw(x) + . Since we know that ˜fw(x) agrees with G(x) everywhere except in K ∩ A  and
minx
G(x) satisﬁes minx G(x) ≥ minx
˜fw(x) +   we only need to show that with high probability  any
polynomial time algorithm will not query any point in K ∩ A.
Consider a (potentially) randomized algorithm A  making random choices R1  R2  . . .   Rm. Condi-
tioned on a particular choice of randomness r1  r2  . . .   rm  for a random choice of w  each ri lies in
A with probability at most exp(−c log(d/))  by a standard Gaussian tail bound. Union bounding 
since m = o(( d
 )c)  the probability that at least of the
queries of A lies in A is at most 1
2.
But the claim is true for any choice r1  r2  . . .   rm of the randomness  by averaging  the claim holds
for r1  r2  . . .   rm being sampled according to the randomness of the algorithm.

 )c) for an algorithm that runs in time o(( d

The proofs of all of the lemmas above have been ommited due to space constraints  and are included
in the appendix in full.

5 Algorithmic upper bound

d )  so we only
As mentioned before  the algorithm in [BLNR15] covers the case when ∆ = O( 
need to give an algorithm when ∆ = Ω( 
d ). Our approach will not be making use
of simulated annealing  but a more robust version of gradient descent. The intuition comes from
[FKM05] who use estimates of the gradient of a convex function derived from Stokes’ formula:

d ) and ∆ = O( 2

(cid:20) d

r

Ew∼S d

(cid:21)

(cid:90)

B

∇f (x)dx

f (x + rw)w

=

6

where w ∼ S d denotes w being a uniform sample from the sphere S d. Our observation is the gradient
estimation is robust to noise if we instead use ˜f in the left hand side. Crucially  robust is not in the
sense that it approximates the gradient of f  but it preserves the crucial property of the gradient of
f we need: (cid:104)−∇f (x)  x∗ − x(cid:105) ≥ f (x) − f (x∗). In words  this means if we move x at direction
−∇f (x) for a small step  then x will be closer to x∗  and we will show the property is preserved by
˜f when ∆ ≤ 2√

d

r

(cid:21)

(cid:28)

  x∗ − x

˜f (x + rw)w

(cid:20) d
(cid:20)(cid:28) d
(cid:20)(cid:28) d

. Indeed  we have that:
−Ew∼S d
≥ −Ew∼S d

(cid:29)
(cid:29)(cid:21)
(cid:29)(cid:21)
f (x + rw)w  x∗ − x
r ∆Ew∼U (Sd) [|(cid:104)w  x∗ − x(cid:105)|] is bounded by O( ∆

f (x + rw)w  x∗ − x

r

d

r

The usual [FKM05] calculation shows that

r

√

√

Ew∼S d)

= Ω (f (x) − f (x∗) − 2r)
)  since Ew∼U (Sd) [|(cid:104)w  x∗ − x(cid:105)|] = O( 1√
).
whenever f (x) − f (x∗) ≥ . Choosing the optimal

4 and ∆ ≤ 2√

and d
Therefore  we want f (x) − f (x∗) − 2r ≥ ∆
parameter leads to r = 
This intuitive calculation basically proves the simple upper bound guarantee (Theorem 3.3). On
the other hand  the argument requires sampling from a ball of radius Ω() around point x. This is
problematic when  > 1√
: many convex bodies (e.g. the simplex  L1 ball after rescaling to diameter
one) will not contain a ball of radius even 1√
. The idea is then to make the sampling possible by
“extending” ˜f outside of K. Namely  we deﬁne a new function g : Rd → R such that (ΠK(x) is the
projection of x to K)

d

r

.

d

d

d

d

g(x) will not be in general convex  but we instead directly bound (cid:104)Ew∼(cid:2) 1

g(x) = ˜f (ΠK(x)) + d(x K)

for x ∈ K and show that it behaves like (cid:104)−∇f (x)  x∗ − x(cid:105) ≥ f (x) − f (x∗).

r g(x + rw)w(cid:3)   x − x∗(cid:105)

Algorithm 1 Noisy Convex Optimization
1: Input: A convex set K ⊂ Rd with diam(K) = 1 and 0 ∈ K. A ∆-approximate convex function
2: Deﬁne: g : R → R as:

˜f

where ΠK is the projection to K and d(x K) is the Euclidean distance from x to K.

˜g(x) = ˜f (ΠK(x)) + d(x K)

− d∆
r

Ew∼S d [|(cid:104)w  x∗ − x(cid:105)|]

128µ   η =

3

4194304d2   T = 8388608d2

4

.

3: Initial: x1 = 0  r = 
4: for t = 1  2  ....  T do
5:
6:

Let vt = ˜f (xt).
Estimate up to accuracy



4194304 in l2 norm (by uniformly randomly sample w):

(cid:20) d

r

(cid:21)

gt = Ew∼S d

˜g(xt + rw)w

where w ∼ S d means w is uniform sample from the unit sphere.
Update xt+1 = ΠK(xt − ηgt)

7:
8: end for
9: Output mint∈[T ]{vt}

The rest of this section will be dedicated to showing the following main lemma for Algorithm 1.
Lemma 5.1 (Main  algorithm). Suppose ∆ <
x∗ ∈ K such that ˜f (x∗) < ˜f (xt) − 2  then

  we have: For every t ∈ [T ]  if there exists

2
16348

√

d

(cid:104)−gt  x∗ − xt(cid:105) ≥ 
64

7

Assuming this Lemma  we can prove Theorem 3.2.

Proof of Theorem 3.2. We ﬁrst focus on the number of iterations:
For every t ≥ 1  suppose ˜f (x∗) < ˜f (xt) − 2  then we have: (since (cid:107)gt(cid:107) ≤ 2d/r ≤ 256d

)



(cid:107)x∗ − xt+1(cid:107)2

2 ≤ (cid:107)x∗ − (xt − ηgt)(cid:107)2

2

2

= (cid:107)x∗ − xt(cid:107)2
≤ (cid:107)x∗ − xt(cid:107)2
≤ (cid:107)x∗ − xt(cid:107)2
= (cid:107)x∗ − xt(cid:107)2

+ η2 65536d2
4

2 − 2η(cid:104)x∗ − xt  gt(cid:105) + η2(cid:107)gt(cid:107)2
2 − η
64
2 −
2 −

8388608d2 +

4194304d2

4

4

2

8388608d2
Since originally (cid:107)x∗ − x1(cid:107) ≤ 1  the algorithm ends in poly(d  1
Now we consider the sample complexity. Since we know that
≤ 64d


˜g(xt + rw)w

(cid:13)(cid:13)(cid:13)(cid:13) d

(cid:13)(cid:13)(cid:13)(cid:13)2

r

 ) iterations.

By standard concentration bound we know that we need poly(d  1
tion up to error

2097152 per iteration.



 ) samples to estimate the expecta-

Due to space constraints  we forward the proof of Lemma 5.1 to the appendix.

6 Discussion and open problems

6.1 Arbitrary Lipschitz constants and diameter
We assumed throughout the paper that the convex function f is 1-Lipschitz and the convex set K
has diameter 1. Our results can be easily extended to arbitrary functions and convex sets through a
simple linear transformation. For f with Lipschitz constant (cid:107)f(cid:107)Lip and K with diameter D  and the
˜f (rx). (Where K
corresponding approximately convex ˜f  deﬁne ˜g : K
D is the
rescaling of K by a factor of 1
. But g(x) = f (Rx)
is
R(cid:107)f(cid:107)Lip
1-Lipschitz over a set K
R of diameter 1. Therefore  for general functions over a general convex sets 
our result trivially implies the rate for being able to optimize approximately-convex functions is

D → R as ˜g(x) = 1
D(cid:107)f(cid:107)Lip
D .) This translates to (cid:107)˜g(x) − g(x)(cid:107)2 ≤ ∆
R(cid:107)f(cid:107)Lip
(cid:41)

(cid:40)

(cid:19)2

(cid:18)

∆

R(cid:107)f(cid:107)Lip

(cid:110)

= max

2√

dR(cid:107)f(cid:107)Lip

  
d

(cid:111)

1√
d
.



R(cid:107)f(cid:107)Lip

 

1
d



R(cid:107)f(cid:107)Lip

which simpliﬁes to ∆ = max

6.2 Body speciﬁc bounds

Our algorithmic result matches the lower bound on well-conditioned bodies. The natural open
problem is to resolve the problem for arbitrary bodies. 9
Also note the lower bound can not hold for any convex body K in Rd: for example  if K is just a one
dimensional line in Rd  then the threshold should not depend on d at all. But even when the “inherent
dimension” of K is d  the result is still body speciﬁc: one can show that for ˜f over the simplex in Rd 
when  ≥ 1√
Finally  while our algorithm made use of the well-conditioning – what is the correct prop-
erty/parameter of the convex body that governs the rate of T () is a tantalizing question to explore in
future work.

  it is possible to optimize ˜f in polynomial time even when ∆ is as large as . 10

d

9We do not show it here  but one can prove the upp/lower bound still holds over the hypercube and when one

can ﬁnd a ball of radius  that has most of the mass in the convex body K.

10Again  we do not show that here  but essentially one can search through the d + 1 lines from the center to

the d + 1 corners.

8

References

[AD10] Alekh Agarwal and Ofer Dekel. Optimal algorithms for online convex optimization

with multi-point bandit feedback. In COLT  pages 28–40. Citeseer  2010.

[AFH+11] Alekh Agarwal  Dean P Foster  Daniel J Hsu  Sham M Kakade  and Alexander Rakhlin.
Stochastic convex optimization with bandit feedback. In Advances in Neural Information
Processing Systems  pages 1035–1043  2011.

[BLNR15] Alexandre Belloni  Tengyuan Liang  Hariharan Narayanan  and Alexander Rakhlin.
Escaping the local minima via simulated annealing: Optimization of approximately
convex functions. In Proceedings of The 28th Conference on Learning Theory  pages
240–265  2015.

[DJWW15] John C Duchi  Michael I Jordan  Martin J Wainwright  and Andre Wibisono. Opti-
mal rates for zero-order convex optimization: The power of two function evaluations.
Information Theory  IEEE Transactions on  61(5):2788–2806  2015.

[DKS14] Martin Dyer  Ravi Kannan  and Leen Stougie. A simple randomised algorithm for

convex optimisation. Mathematical Programming  147(1-2):207–229  2014.

[FKM05] Abraham D Flaxman  Adam Tauman Kalai  and H Brendan McMahan. Online convex
optimization in the bandit setting: gradient descent without a gradient. In Proceedings
of the sixteenth annual ACM-SIAM symposium on Discrete algorithms  pages 385–394.
Society for Industrial and Applied Mathematics  2005.

[NS] Yurii Nesterov and Vladimir Spokoiny. Random gradient-free minimization of convex

functions. Foundations of Computational Mathematics  pages 1–40.

[NY83] Arkadii Nemirovskii and David Borisovich Yudin. Problem complexity and method
efﬁciency in optimization. Wiley-Interscience series in discrete mathematics. Wiley 
Chichester  New York  1983. A Wiley-Interscience publication.

[Sha12] Ohad Shamir. On the complexity of bandit and derivative-free stochastic convex opti-

mization. arXiv preprint arXiv:1209.2388  2012.

[SV15] Yaron Singer and Jan Vondrák. Information-theoretic lower bounds for convex optimiza-
tion with erroneous oracles. In Advances in Neural Information Processing Systems 
pages 3186–3194  2015.

9

,Andrej Risteski
Yuanzhi Li