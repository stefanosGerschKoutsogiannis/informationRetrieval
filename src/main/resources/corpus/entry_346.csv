2016,Achieving the KS threshold in the general stochastic block model with linearized acyclic belief propagation,The stochastic block model (SBM) has long been studied in machine learning and network science as a canonical model for clustering and community detection. In the recent years  new developments have demonstrated the presence of threshold phenomena for this model  which have set new challenges for algorithms. For the {\it detection} problem in symmetric SBMs  Decelle et al.\ conjectured that the so-called Kesten-Stigum (KS) threshold can be achieved efficiently. This was proved for two communities  but remained open from three communities. We prove this conjecture here  obtaining a more general result that applies to arbitrary SBMs with linear size communities. The developed algorithm is a linearized acyclic belief propagation (ABP) algorithm  which mitigates the effects of cycles while provably achieving the KS threshold in $O(n \ln n)$ time. This extends prior methods by achieving universally the KS threshold while reducing or preserving the computational complexity. ABP is also connected to a power iteration method on a generalized nonbacktracking operator  formalizing the spectral-message passing interplay described in Krzakala et al.  and extending results from Bordenave et al.,Achieving the KS threshold in the general stochastic
block model with linearized acyclic belief propagation

Applied and Computational Mathematics and EE Dept.

Emmanuel Abbe

Princeton University

eabbe@princeton.edu

Colin Sandon

Department of Mathematics

Princeton University

sandon@princeton.edu

Abstract

The stochastic block model (SBM) has long been studied in machine learning and
network science as a canonical model for clustering and community detection. In
the recent years  new developments have demonstrated the presence of threshold
phenomena for this model  which have set new challenges for algorithms. For
the detection problem in symmetric SBMs  Decelle et al. conjectured that the
so-called Kesten-Stigum (KS) threshold can be achieved efﬁciently. This was
proved for two communities  but remained open for three and more communities.
We prove this conjecture here  obtaining a general result that applies to arbitrary
SBMs with linear size communities. The developed algorithm is a linearized
acyclic belief propagation (ABP) algorithm  which mitigates the effects of cycles
while provably achieving the KS threshold in O(n ln n) time. This extends prior
methods by achieving universally the KS threshold while reducing or preserving the
computational complexity. ABP is also connected to a power iteration method on a
generalized nonbacktracking operator  formalizing the spectral-message passing
interplay described in Krzakala et al.  and extending results from Bordenave et al.

1

Introduction

The stochastic block model (SBM) is widely used as a model for community detection and as a
benchmark for clustering algorithms. The model emerged in multiple scientiﬁc communities  in
machine learning and statistics under the SBM [1  2  3  4]  in computer science as the planted partition
model [5  6  7]  and in mathematics as the inhomogeneous random graph model [8]. Although the
model was deﬁned as far back as the 80s  mainly studied for the exact recovery problem  it resurged
in the recent years due in part to fascinating conjectures on the detection problem  established in
[9] (and backed in [10]) from deep but non-rigorous statistical physics arguments. For efﬁcient
algorithms  the following was conjectured:
Conjecture 1. (See formal deﬁnitions below) In the stochastic block model with n vertices  k
balanced communities  edge probability a/n inside the communities and b/n across  it is possible to
detect communities in polynomial time if and only if
(a − b)2

(1)

k(a + (k − 1)b)

> 1.

In other words  the problem of detecting efﬁciently communities is conjectured to have a sharp
threshold at the above  which is called the Kesten-Stigum (KS) threshold. Establishing such thresholds
is of primary importance for the developments of algorithms. A prominent example is Shannon’s
coding theorem  that gives a sharp threshold for coding algorithms at the channel capacity  and
which has led the development of coding algorithms used in communication standards. In the area of

30th Conference on Neural Information Processing Systems (NIPS 2016)  Barcelona  Spain.

clustering  where establishing rigorous benchmarks is a challenge  the quest of sharp thresholds is
likely to also have fruitful outcomes.
Interestingly  classical clustering algorithms do not seem to sufﬁce for achieving the threshold in (1).
This includes spectral methods based on the adjacency matrix or Laplacians  as well as SDPs. For
standard spectral methods  a ﬁrst issue is that the ﬂuctuations in the node degrees produce high-degree
nodes that disrupt the eigenvectors from concentrating on the clusters. This issue is further enhanced
on real networks where degree variations are important. A classical trick is to trim such high-degree
nodes [11  12]  throwing away some information  but this does not seem to sufﬁce. SDPs are a natural
alternative  but they also stumble before the threshold [13  14]  focusing on the most likely rather
than typical clusterings.
Signiﬁcant progress has already been achieved on Conjecture 1. In particular  the conjecture is set
for k = 2  with the achievability part proved in [15  16] and [17]  and the impossibility part in [10].
Achievability results were also obtained in [17] for SBMs with multiple communities that satisfy a
certain asymmetry condition (see Theorem 5 in [17]). Conjecture 1 remained open for k ≥ 3.
In their original paper [9]  Decelle et al. conjectured that belief propagation (BP) achieves the KS
threshold. The main issue when applying BP to the SBM is the classical one: the presence of cycles
in the graph makes the behavior of the algorithm difﬁcult to understand  and BP is susceptible to
settle down in the wrong ﬁxed points. While empirical studies of BP on loopy graph have shown
that convergence still takes place in some cases [18]  obtaining rigorous results in the context of
loopy graphs remains a long standing challenge for message passing algorithms  and achieving the
KS threshold requires precisely running BP to an extent where the graph is not even tree-like. We
address this challenge in the present paper  with a linearized version of BP that mitigates cycles.
Note that establishing formally the converse of Conjecture 1 (i.e.  that efﬁcient detection is impossible
below the threshold) for arbitrary k seems out of reach at the moment  as the problem behaves very
differently for small rather than arbitrary k. Indeed  except for a few low values of k  it is proven in
[19  20] that the threshold in (1) does not coincide with the information-theoretic threshold. Since it
is possible to detect below the threshold with non-efﬁcient algorithms  proving formally the converse
of Conjecture 1 would require major headways in complexity theory. On the other hand  [9] provides
already non-rigourous arguments that the converse hold.

1.1 This paper

This paper proves the achievability part of conjecture 1. Our main result applies to a more general
context  with a generalized notion of detection that applies to arbitrary SBMs. In particular 
• we show that an approximate belief propagation (ABP) algorithm that mitigates cycles achieves
the KS threshold universally. The simplest linearized1 version of BP is to repeatedly update
beliefs about a vertex’s community based on its neighbor’s suspected communities while avoiding
backtrack. However  this only works ideally if the graph is a tree. The correct response to a
cycle would be to discount information reaching the vertex along either branch of the cycle to
compensate for the redundancy of the two branches. Due to computational issues we simply
prevent information from cycling around constant size cycles.
• we show how ABP can be interpreted as a power iteration method on a generalized r-
nonbacktracking operator  i.e.  a spectral algorithm that uses a matrix counting the number of
r-nonbacktracking walks rather than the adjacency matrix. The random initialization of the beliefs
in ABP corresponds to the random vector to which the power iteration is applied  formalizing the
connection described in [22]. While using r = 2 backtracks may sufﬁce to achieve the threshold 
larger backtracks are likely to help mitigating the presence of small loops in networks.

Our results are closest to [16  17]  while diverging in several key parts. A few technical expansions in
the paper are similar to those carried in [16]  such as the weighted sums over nonbacktracking walks
and the SAW decomposition in [16]  similar to our compensated nonbacktracking walk counts and
Shard decomposition. Our modiﬁcations are developed to cope with the general SBM  in particular
to compensation for the dominant eigenvalues in the latter setting. Our algorithm complexity is also
slightly reduced by a logarithmic factor.

1Other forms of approximate message passing algorithms have been studied for dense graphs  in particular

[21] for compressed sensing.

2

Our algorithm is also closely related to [17]  which focuses on extracting the eigenvectors of the
standard nonbacktracking operator. Our proof technique is different than the one in [17]  so that we
can cope with the setting of Conjecture 1. We also implement the eigenvector extractions in a belief
propagation fashion. Another difference with [17] is that we rely on nonbacktracking operators of
higher orders r. While r = 2 is arguably the simplest implementation and may sufﬁce for the sole
purpose of achieving the KS threshold  a larger r is likely to be beneﬁcial in practice. For example 
an adversary may add triangles for which ABP with r = 2 would fail while larger r would succeed.
Finally  the approach of ABP can be extended beyond the linearized setting to move from detection
to an optimal accuracy as discussed in Section 5.

2 Results

2.1 A general notion of detection

The stochastic block model (SBM) is a random graph model with clusters deﬁned as follows.
Deﬁnition 1. For k ∈ Z+  a probability distribution p ∈ (0  1)k  a k × k symmetric matrix Q with
nonnegative entries  and n ∈ Z+  we deﬁne SBM(n  p  Q/n) as the probability distribution over
ordered pairs (σ  G) of an assignment of vertices to one of k communities and an n-vertex graph
generated by the following procedure. First  each vertex v ∈ V (G) is independently assigned a
community σv under the probability distribution p. Then  for every v (cid:54)= v(cid:48)  an edge is drawn in G
between v and v(cid:48) with probability Qσv σv(cid:48) /n  independently of other edges. We sometimes say that
G is drawn under SBM(n  p  Q/n) without specifying σ and deﬁne Ωi = {v : σv = i}.
Deﬁnition 2. The SBM is called symmetric if p is uniform and if Q takes the same value on the
diagonal and the same value off the diagonal.

Our goal is to ﬁnd an algorithm that can distinguish between vertices from one community and
vertices from another community in a non trivial way.
Deﬁnition 3. Let A be an algorithm that takes a graph as input and outputs a partition of its vertices
into two sets. A solves detection (or weak recovery) in graphs drawn from SBM(n  p  Q/n) if
there exists  > 0 such that the following holds. When (σ  G) is drawn from SBM(n  p  Q/n) and
A(G) divides its vertices into S and Sc  with probability 1 − o(1)  there exist i  j ∈ [k] such that
|Ωi ∩ S|/|Ωi| − |Ωj ∩ S|/|Ωj| > .
In other words  an algorithm solves detection if it divides the graph’s vertices into two sets such that
vertices from different communities have different probabilities of being assigned to one of the sets.
An alternate deﬁnition (see for example Decelle et al. [9]) requires the algorithm to divide the vertices
into k sets such that there exists  > 0 for which there exists an identiﬁcation of the sets with the
communities labelling at least max pi +  of the vertices correctly with high probability. In the 2
community symmetric case  the two deﬁnitions are equivalent. In a two community asymmetric case
where p = (.2  .8)  an algorithm that could ﬁnd a set containing 2/3 of the vertices from the large
community and 1/3 of the vertices from the small community would satisfy Deﬁnition 3  however  it
would not satisfy previous deﬁnition due to the biased prior. If all communities have the same size 
this distinction is meaningless and we have the following equivalence:
Lemma 1. Let k > 0  Q be a k × k symmetric matrix with nonnegative entries  p be the uni-
form distribution over k sets  and A be an algorithm that solves detection in graphs drawn from
SBM(n  p  Q/n). Then A also solves detection according to Decelle et al.’s criterion [9]  provided
that we consider it as returning k − 2 empty sets in addition to its actual output.
Proof. Let (σ  G) ∼ SBM(n  p  Q/n) and A(G) return S and S(cid:48). There exists  > 0 such that with
high probability (whp) there exist i  j such that |Ωi ∩ S|/|Ωi| − |Ωj ∩ S|/|Ωj| > . So  if we map S
to community i and S(cid:48) to community j  the algorithm classiﬁes at least |Ωi ∩ S|/n + |Ωj ∩ S(cid:48)|/n =
|Ωj|/n + |Ωi ∩ S|/n − |Ωj ∩ S|/n ≥ 1/k + /k − o(1) of the vertices correctly whp.

2.2 Achieving efﬁciently and universally the KS threshold

Given parameters p and Q for the SBM  let P be the diagonal matrix such that Pi i = pi for each
i ∈ [k]. Also  let λ1  ...  λh be the distinct eigenvalues of P Q in order of nonincreasing magnitude.

3

Deﬁnition 4. The signal to noise ratio of SBM(n  p  Q/n) is deﬁned by SNR := λ2
Theorem 1. Let k ∈ Z+  p ∈ (0  1)k be a probability distribution  Q be a k × k symmetric matrix
with nonnegative entries  and G be drawn under SBM(n  p  Q/n). If SNR > 1  then there exist
r ∈ Z+  c > 0  and m : Z+ → Z+ such that ABP(G  m(n)  r  c  (λ1  ...  λh)) described in the next
section solves detection and runs in O(n log n) time.

2/λ1.

For the symmetric SBM  this settles the achievability part of Conjecture 1  as the condition SNR > 1
reads in this case SNR = ( a−b

) = (a − b)2/(k(a + (k − 1)b)) > 1.

k )2/( a+(k−1)b

k

3 The linearized acyclic belief propagation algorithm (ABP)

3.1 Vanilla version

We present ﬁrst a simpliﬁed version of our algorithm that captures the essence of the algorithm while
avoiding technicalities required for the proof  described in Section 3.3.
ABP∗(G  m  r  λ1):
1. For each vertex v  randomly draw xv with a Normal distribution. For all adjacent v  v(cid:48) in G  set

v v(cid:48) = xv(cid:48) and set y(t)
y(1)
2. For each 1 < t ≤ m  set

v v(cid:48) = 0 whenever t < 1.

(cid:88)

(v(cid:48)(cid:48) v(cid:48)(cid:48)(cid:48))∈E(G)

y(t−1)
v(cid:48)(cid:48) v(cid:48)(cid:48)(cid:48)

(2)

for all adjacent v  v(cid:48). For each adjacent v  v(cid:48) that are not part of a cycle of length r or less  set

v v(cid:48) = y(t−1)
z(t−1)

v v(cid:48) −

1

2|E(G)|

(cid:88)

y(t)
v v(cid:48) =

v(cid:48)(cid:48):(v(cid:48) v(cid:48)(cid:48))∈E(G) v(cid:48)(cid:48)(cid:54)=v

z(t−1)
v(cid:48) v(cid:48)(cid:48)

(cid:88)

and for the other adjacent v  v(cid:48) in G  let the other vertex in the cycle that is adjacent to v be v(cid:48)(cid:48)(cid:48) 
the length of the cycle be r(cid:48)  and set

(cid:88)

y(t)
v v(cid:48) =

v(cid:48)(cid:48):(v(cid:48) v(cid:48)(cid:48))∈E(G) v(cid:48)(cid:48)(cid:54)=v

z(t−1)
v(cid:48) v(cid:48)(cid:48) −

v v(cid:48) =(cid:80)

unless t = r(cid:48)  in which case  set y(t)

3. Set y(cid:48)

v(cid:48):(v(cid:48) v)∈E(G) y(m)

v v(cid:48) for every v ∈ G and return ({v : y(cid:48)

v(cid:48)(cid:48):(v(cid:48) v(cid:48)(cid:48))∈E(G) v(cid:48)(cid:48)(cid:54)=v z(t−1)

v(cid:48)(cid:48):(v v(cid:48)(cid:48))∈E(G) v(cid:48)(cid:48)(cid:54)=v(cid:48) v(cid:48)(cid:48)(cid:54)=v(cid:48)(cid:48)(cid:48)
v(cid:48) v(cid:48)(cid:48) − z(1)
v(cid:48)(cid:48)(cid:48) v.
v > 0} {v : y(cid:48)

v ≤ 0}).

v =(cid:80)

z(t−r(cid:48))
v v(cid:48)(cid:48)

if

(v  v(cid:48))

(cid:80)r

r(cid:48)=1

is

in multiple cycles of

length r or

the algorithm does

= (cid:80)

v(cid:48)(cid:48)(cid:48) v v(cid:48)(cid:80)

Remarks. (1) In the r = 2 case  one can exit step 2 after the second line. As mentioned above  we
rely on a less compact version of the algorithm to prove the theorem  but expect that the above also
succeeds at detection as long as m > 2 ln(n)/ ln(SNR).
(2) What
is unspeciﬁed as
SBM. This can be modiﬁed for more general settings 
dependently for each such cycle 

there is no such edge with probability 1 − o(1)

applying the adjustment
v(cid:48)(cid:48):(v(cid:48) v(cid:48)(cid:48))∈E(G) v(cid:48)(cid:48)(cid:54)=v z(t−1)
v(cid:48)(cid:48):(v v(cid:48)(cid:48))∈E(G) v(cid:48)(cid:48)(cid:54)=v(cid:48) v(cid:48)(cid:48)(cid:54)=v(cid:48)(cid:48)(cid:48) z(t−r(cid:48))
v(cid:48)(cid:48)(cid:48) v v(cid:48)
v v(cid:48)(cid:48)

(cid:80)
v(cid:48)(cid:48)(cid:48):(v v(cid:48)(cid:48)(cid:48))∈E(G) C (r(cid:48))

less
in the sparse
in-
v(cid:48) v(cid:48)(cid:48) −
de-

notes the number of length r(cid:48) cycles that contain v(cid:48)(cid:48)(cid:48)  v  v(cid:48) as consecutive vertices.
(3) The purpose of setting z(t−1)
as in step (2) is to ensure that the average value of the y(t) is
v v(cid:48)
approximately 0  and thus that the eventual division of the vertices into two sets is roughly even. An
v v(cid:48) = y(t−1)
alternate way of doing this is to simply let z(t−1)
and then compensate for any bias of y(t)
v v(cid:48)
towards positive or negative values at the end. More speciﬁcally  deﬁne Y to be the n× m matrix such
v v(cid:48)  and M to be the m × m matrix such that Mi i = 1
em 

and Mi i+1 = −λ1 for all i  and all other entries of M are equal to 0. Then set y(cid:48) = Y M m(cid:48)
where em ∈ Rm denotes the unit vector with 1 in the m-th entry  and m(cid:48) is a suitable integer.

that for all t and v  Yv t =(cid:80)

v(cid:48):(v(cid:48) v)∈E(G) y(t)

  where C (r(cid:48))

setting y(t)
v v(cid:48)

4

3.2 Spectral implementation

One way of looking at this algorithm for r = 2 is the following. Given a vertex v in community i 
the expected number of vertices v(cid:48) in community j that are adjacent to v is approximately ej · P Qei.
For any such v(cid:48) the expected number of vertices in community j(cid:48) that are adjacent to v(cid:48) not counting
v is approximately ej(cid:48) · P Qej  and so on. In order to explore this connection  deﬁne the graph’s
nonbacktracking walk matrix W as the 2|E(G)| × 2|E(G)| matrix such that for all v ∈ V (G) and
all distinct v(cid:48) and v(cid:48)(cid:48) adjacent to v  W(v v(cid:48)(cid:48)) (v(cid:48) v) = 1  and all other entries in W are 0.
Now  let w be an eigenvector of P Q with eigenvalue λi and w ∈ R2|E(G)| be the vector such that
w(v v(cid:48)) = wσv(cid:48) /pσv(cid:48) for all (v  v(cid:48)) ∈ E(G). For any small t  we would expect that w · W tw ≈
i||w||2
2  which strongly suggests that w is correlated with an eigenvector of W with eigenvalue λi.
λt
For any such w with i > 1  dividing G’s vertices into those with positive entries in w and those
with negative entries in w would put all vertices from some communities in the ﬁrst set  and all
vertices from the other communities in the second. So  we suspect that an eigenvector of W with its
eigenvalue of second greatest magnitude would have entries that are correlated with the corresponding
vertices’ communities.
We could simply extract this eigenvector  but a faster approach would be to take a random vector
y and then compute W my for some suitably large m. That will be approximately equal to a
linear combination of W ’s dominant eigenvectors. Its dominant eigenvector is expected to have an
eigenvalue of approximately λ1 and to have all of its entries approximately equal  so if instead we
compute (W − λ1
2|E(G)| J)my where J is the vector with all entries equal to 1  the component of y
proportional to W ’s dominant eigenvector will be reduced to negligable magnitude  leaving a vector
that is approximately proportional to W ’s eigenvector of second largest eigenvalue. This is essentially
what the ABP algorithm does for r = 2.
This vanilla approach does however not extend obviously to the case with multiple eigenvalues. In
such cases  we will have to subtract multiples of the identity matrix instead of J because we will
not know enough about W ’s eigenvectors to ﬁnd a matrix that cancels out one of them in particular.
These are signiﬁcant challenges to overcome to prove the general result and Conjecture 1.
For higher values of r  the spectral view of ABP can be understood as described above but introducing
the following generalized nonbacktracking operator as a replacement to W :
Deﬁnition 5. Given a graph  deﬁne the r-nonbacktracking matrix W (r) of dimension equal to the
number of r − 1 directed paths in the graph and with entry W (r)
r) equal to 1 if
i+1 = vi for each 1 ≤ i < r and v(cid:48)
v(cid:48)

1 (cid:54)= vr  and equal to 0 otherwise.

(v1 v2 ... vr) (v(cid:48)

1 v(cid:48)

2 ... v(cid:48)

Figure 1: Two paths of length 3 that contribute to an entry of 1 in W (4).

3.3 Full version

The main modiﬁcations in the proof are as follows. First  at the end we assign vertices to sets with
probabilities that scale linearly with their entries in y(cid:48) instead of simply assigning them based on the
signs of their entries. This allows us to convert the fact that the average values of y(cid:48)
v for v in different
communities is different into a detection result. Second  we remove a small fraction of the edges
from the graph at random at the beginning of the algorithm (the graph-splitting step)  deﬁning y(cid:48)(cid:48)
to be the sum of y(cid:48)
v(cid:48) over all v(cid:48) connected to v by paths of a suitable length with removed edges at
v
their ends in order to eliminate some dependency issues. Also  instead of just compensating for P Q’s
dominant eigenvalue  we also compensate for some of its smaller eigenvalues  and subtract multiples
of y(t−1) from y(t) for some t instead of subtracting the average value of y(t) from all of its entries
for all t. We refer to [19] for the full description of the algorithm. Note that while it is easier to prove
that the ABP algorithm works  the ABP∗ algorithm should work at least as well in practice.

5

4 Proof technique

For simplicity  consider ﬁrst the two community symmetric case. Consider determining the commu-
nity of v using belief propagation  assuming some preliminary guesses about the vertices t edges
away from it  and assuming that the subgraph of G induced by the vertices within t edges of v is a tree.
For any vertex v(cid:48) such that d(v  v(cid:48)) < t  let Cv(cid:48) be the set of the children of v(cid:48). If we believe based
on either our prior knowledge or propagation of beliefs up to these vertices that v(cid:48)(cid:48) is in community 1
2 v(cid:48)(cid:48) for each v(cid:48)(cid:48) ∈ Cv(cid:48)  then the algorithm will conclude that v(cid:48) is in community
with probability 1
2 + 1
1 with a probability of
(cid:81)

2 + a−b

v(cid:48)(cid:48)∈Cv(cid:48) ( a+b

2 v(cid:48)(cid:48))

.

(cid:81)
2 + a−b

2 v(cid:48)(cid:48) ) +(cid:81)

v(cid:48)(cid:48)∈Cv(cid:48) ( a+b

2 − a−b

2 v(cid:48)(cid:48))

If all of the v(cid:48)(cid:48) are close to 0  then this is approximately equal to (see also [9  22])

a−b
a+b v(cid:48)(cid:48)
v(cid:48)(cid:48)∈Cv(cid:48) (−1) a−b

a+b v(cid:48)(cid:48)

=

1
2

+

a − b
a + b

(cid:88)

v(cid:48)(cid:48)∈Cv(cid:48)

1
2

v(cid:48)(cid:48) .

2 +(cid:80)

v(cid:48)(cid:48)∈Cv(cid:48)

v(cid:48)(cid:48)∈Cv(cid:48) ( a+b

a−b

v(cid:48)(cid:48)∈Cv(cid:48)

1 +(cid:80)
a+b v(cid:48)(cid:48) +(cid:80)
a+b )t(cid:80)

2 + 1

2 ( a−b

That means that the belief propagation algorithm will ultimately assign an average probability of
approximately 1
v(cid:48)(cid:48):d(v v(cid:48)(cid:48))=t v(cid:48)(cid:48) to the possibility that v is in community 1. If there
exists  such that Ev(cid:48)(cid:48)∈Ω1 [v(cid:48)(cid:48) ] =  and Ev(cid:48)(cid:48)∈Ω2[v(cid:48)(cid:48)] = − (recall that Ωi = {v : σv = i})  then
 to v being
on average we would expect to assign a probability of approximately 1
in its actual community  which is enhanced as t increases when SNR > 1. Note that since the
variance in the probability assigned to the possibility that v is in its actual community will also grow
as
  the chance that this will assign a probability of greater than 1/2 to v being in its actual

(cid:16) (a−b)2

(cid:16) (a−b)2

(cid:17)t

(cid:17)t

2 + 1

2(a+b)

2

2(a+b)

(cid:18)(cid:16) (a−b)2

(cid:17)t/2(cid:19)

2(a+b)

.

community will be 1

2 + Θ

2

>

2(a+b)

(cid:17)t

(cid:17)t/2

n  we have that

(cid:16) (a+b)

(cid:16) (a−b)2

One idea for the initial estimate is to simply guess the vertices’ communities at random  in the
√
expectation that the fractions of the vertices from the two communities assigned to a community
will differ by θ(1/
n) by the Central Limit Theorem. Unfortunately  for any t large enough that
√
> n which means that our approximation breaks down
before t gets large enough to detect communities. In fact  t would have to be so large that not only
would neighborhoods not be tree like  but vertices would have to be exhausted.
One way to handle this would be to stop counting vertices that are t edges away from v  and instead
count each vertex a number of times equal to the number of length t paths from v to it.2 Unfortunately 
ﬁnding all length t paths starting at v can be done efﬁciently enough only for values of t that are
smaller than what is needed to amplify a random guess to the extent needed here. We could instead
calculate the number of length t walks from v to each vertex more quickly  but this count would
probably be dominated by walks that go to a high degree vertex and then leave and return to it
repeatedly  which would throw the calculations off. On the other hand  most reasonably short
nonbacktracking walks are likely to be paths  so counting each vertex a number of times equal to the
number of nonbacktracking walks of length t from v to it seems like a reasonable modiﬁcation. That
said  it is still possible that there is a vertex that is in cycles such that most nonbacktracking walks
simply leave and return to it many times. In order to mitigate this  we use r-nonbacktracking walks 
walks in which no vertex reoccurs within r steps of a previous occurrence  such that walks cannot
return to any vertex more than t/r times.
Unfortunately  this algorithm would not work because the original guesses will inevitably be biased
towards one community or the other. So  most of the vertices will have more r-nonbacktracking
walks of length t from them to vertices that were suspected of being in that community than the other.
One way to deal with this bias would be to subtract the average number of r-nonbacktracking walks
to vertices in each set from each vertex’s counts. Unfortunately  that will tend to undercompensate
for the bias when applied to high degree vertices and overcompensate for it when applied to low

2This type of approach is considered in [23].

6

degree vertices. So  we modify the algorithm that counts the difference between the number of
r-nonbacktracking walks leading to vertices in the two sets to subtract off the average at every step in
order to prevent a major bias from building up.
One of the features of our approach is that it extends fairly naturally to the general SBM. Despite the
potential presence of more than 2 communities  we still only assign one value to each vertex  and
output a partition of the graph’s vertices into two sets in the expectation that different communities
will have different fractions of their vertices in the second set. One complication is that the method of
preventing the results from being biased towards one comunity does not work as well in the general
case. The problem is  by only assigning one value to each vertex  we compress our beliefs onto one
dimension. That means that the algorithm cannot detect biases orthogonal to that dimension  and
thus cannot subtract them off. So  we cancel out the bias by subtracting multiples of the counts of the
numbers of r-nonbacktracking walks of some shorter length that will also have been affected by it.
More concretely  we assign each vertex an initial value  xv  at random. Then  we compute a matrix Y
such that for each v ∈ G and 0 ≤ t ≤ m  Yv t is the sum over all r-nonbacktracking walks of length
t ending at v of the initial values associated with their starting vertices. Next  for each v we compute
a weighted sum of Yv 1  Yv 2  ...  Yv m where the weighting is such that any biases in the entries of Y
resulting from the initial values should mostly cancel out. We then use these to classify the vertices.
Proof outline for Theorem 1. If we were going to prove that ABP∗ worked  we would proba-
bly deﬁne Wr[S]((v0  ...  vm)) to be 1 if for every consecutive subsequence (i1  . . .   im(cid:48)) ⊆
is a r-nonbacktracking walk  and 0 otherwise. Next  de-
S  we have that vi1−1  ...  vim(cid:48)
S⊆(1 ... m)(−2|E(G)|)−|S|Wr[S]((v0  ...  vm)) and Wm(x  v) =
v = Wm(x  v) for x and y(cid:48)
as in ABP ∗. As explained above  we rely on a different approach to cope with the general SBM.
In order to prove that the algorithm works  we make the following deﬁnitions.
Deﬁnition 6. For any r ≥ 1 and series of vertices v0  ...  vm  let Wr((v0  ...  vm)) be 1 if v0  ...  vm
is an r-nonbacktracking walk and 0 otherwise. Also  for any r ≥ 1  series of vertices v0  ...  vm and
c0  ...  cm ∈ Rm+1  let

ﬁne Wr((v0  ...  vm)) = (cid:80)
(cid:80)
v0 ... vm∈G:vm=v xv0Wr((v0  ...  vm))  and we would have that y(cid:48)

 (cid:89)

 Wr((vi0  vi1  ...  vim(cid:48) )).

(−ci/n)

W(c0 ... cm)[r]((v0  ...  vm)) =

(i0 ... im(cid:48) )∈(0 ... m)

i(cid:54)∈(i0 ... im(cid:48) )

In other words  W(c0 ... cm)[r]((v0  ...  vm)) is the sum over all subsequences of (v0  ...  vm) that form
r-nonbacktracking walks of the products of the negatives of the ci/n corresponding to the elements
of (v0  ...  vm) that are not in the walks. Finally  let

Wm/{ci}(x  v) =

xv0W(c0 ... cm)[r]((v0  ...  vm)).

v0 ... vm∈G:vm=v

The reason these deﬁnitions are important is that for each v and t  we have that

(cid:88)

(cid:88)
(cid:88)

Yv t =

xv0Wr((v0  ...  vt))

v0 ... vt∈G:vt=v

v

and y(m)
is equal to Wm/{ci}(x  v) for suitable (c0  ...  cm). For the full ABP algorithm  both terms
in the above equality refer to G as it is after some of its edges are removed at random in the ‘graph
splitting’ step (which explains the presence of 1 − γ factors in [19]). One can easily prove that if
v0  ...  vt are distinct  σv0 = i and σvt = j  then

E[W(c0 ... ct)[r]((v0  ...  vt))] = ei · P −1(P Q)tej/nt 

and most of the rest of the proof centers around showing that W(c0 ... cm)[r]((v0  ...  vm)) such that
v0  ...  vm are not all distinct do not contribute enough to the sums to matter. That starts with a bound
on |E[W(c0 ... cm)[r]((v0  ...  vm))]| whenever there is no i  j (cid:54)= j(cid:48) such that vj = vj(cid:48)  |i− j| ≤ r  and
ci (cid:54)= 0; and continues with an explanation of how to re-express any W(c0 ... cm)[r]((v0  ...  vm)) as a
linear combination of expressions of the form W(c(cid:48)
m(cid:48))) which have this property.

0  ...  v(cid:48)

0 ... c(cid:48)

m(cid:48) )[r]((v(cid:48)

7

Then we use these to prove that for suitable (c0  ...  cm)  the sum of |E[W(c0 ... cm)[r]((v0  ...  vm))]|
for all sufﬁciently repetitive (v0  ...  vm) is sufﬁciently small. Next  we observe that

W(c0 ... cm)[r]((v0  ...  vm))W(c(cid:48)(cid:48)
= W(c0 ... cm 0 ... 0 c(cid:48)(cid:48)

m))
0 )[r]((v0  ...  vm  u1  ...  ur  v(cid:48)(cid:48)

m ... c(cid:48)(cid:48)

0  ... c(cid:48)(cid:48)

m)[r]((v(cid:48)(cid:48)

0   ...  v(cid:48)(cid:48)

n  ...v(cid:48)(cid:48)
0 ))

if u1  ...  ur are new vertices that are connected to all other vertices  and use that fact to translate
bounds on expected values to bounds on variances.
That allows us to show that if m and (c0  ...  cm) have the appropriate properties and w is an
eigenvector of P Q with eigenvalue λj and magnitude 1  then with high probability

wσv /pσv Wm/{ci}(x  v)| = O(

|λj − ci| +

|λs − ci|)

(cid:89)

0≤i≤m

√

n

(cid:89)

√

n

log(n)

0≤i≤m

|λj − ci|).

(cid:89)

| (cid:88)

√
wσv /pσv Wm/{ci}(x  v)| = Ω(

n

| (cid:88)

v∈V (G)

and

0≤i≤m

v∈V (G)

We also show that under appropriate conditions Var[Wm/{ci}(x  v)] = O((1/n)(cid:81)

0≤i≤m(λs−ci)2).
Together  these facts would allow us to prove that the differences between the average values of
Wm/{ci}(x  v) in different communities are large enough relative to the variance of Wm/{ci}(x  v)
to let us detect communities  except for one complication. Namely  these bounds are not quite
good enough to rule out the possibility that there is a constant probability scenario in which the
empirical variance of {Wm/{ci}(x  v)} is large enough to disrupt our efforts at using Wm/{ci}(x  v)
for detection. Although we do not expect this to actually happen  we rely on the graph splitting step
described in Section 3.3 to discard this potential scenario.

5 Conclusions and extensions

This algorithm is intended to classify vertices with an accuracy nontrivially better than that attained
by guessing randomly  but it is not hard to convert this to an algorithm that classiﬁes vertices with
optimal accuracy. Once one has reasonable initial guesses of which communities the vertices are in 
one can simply run full belief propagation on these guesses. This requires bridging the gap from
dividing the vertices into two sets that are correlated with their communities in an unknown way  and
assigning each vertex a nontrivial probability distribution for how likely it is to be in each community.
One way to do this is to divide G’s vertices into those that have positive and negative values of y(cid:48) 
and divide its directed edges into those that have positive and negative values of y(m). We would
generally expect that edges from vertices in different communities will have different probabilities of
corresponding to positive values of y(m). Now  let d(cid:48) be the largest integer such that at least
n of the
vertices have degree at least d(cid:48)  let S be the set of vertices with degree exactly d(cid:48)  and for each v ∈ S 
(v v(cid:48)) > 0}|. We would expect that for any given community i  the
let ξv = |{v(cid:48) : (v  v(cid:48)) ∈ E(G)  y(cid:48)
probability distribution of ξv for v ∈ Ωi would be essentially a binomial distribution with parameters
d(cid:48) and some unknown probability. So  compute probabilities such that the observed distribution of
values of ξv approximately matches the appropriate weighted sum of k binomial distributions.
Next  go through all identiﬁcations of the communities with these binomial distributions that are con-
sistent with the community sizes and determine which one most accurately predicts the connectivity
rates between vertices that have each possible value of ξ when the edge in question is ignored  and
treat this as the mapping of communities to binomial distributions. Then  for each adjacent v and v(cid:48) 
determine the probability distribution of what community v is in based on the signs of y(cid:48)
(v(cid:48)(cid:48) v) for all
v(cid:48)(cid:48) (cid:54)= v(cid:48). Finally  use these as the starting probabilities for BP with a depth of ln(n)/3 ln(λ1).

√

Acknowledgments

This research was supported by NSF CAREER Award CCF-1552131 and ARO grant W911NF-16-1-
0051.

8

References
[1] P. W. Holland  K. Laskey  and S. Leinhardt. Stochastic blockmodels: First steps. Social Networks 

5(2):109–137  1983.

[2] Peter J. Bickel and Aiyou Chen. A nonparametric view of network models and Newman-Girvan and other

modularities. Proceedings of the National Academy of Sciences  106(50):21068–21073  2009.

[3] B. Karrer and M. E. J. Newman. Stochastic blockmodels and community structure in networks. Phys. Rev.

E  83:016107  Jan 2011.

[4] C. Gao  Z. Ma  A. Y. Zhang  and H. H. Zhou. Achieving Optimal Misclassiﬁcation Proportion in Stochastic

Block Model. ArXiv e-prints  May 2015.

[5] T.N. Bui  S. Chaudhuri  F.T. Leighton  and M. Sipser. Graph bisection algorithms with good average case

behavior. Combinatorica  7(2):171–191  1987.

[6] R.B. Boppana. Eigenvalues and graph bisection: An average-case analysis. In 28th Annual Symposium on

Foundations of Computer Science  pages 280–285  1987.

[7] F. McSherry. Spectral partitioning of random graphs.

In Foundations of Computer Science  2001.

Proceedings. 42nd IEEE Symposium on  pages 529–537  2001.

[8] Béla Bollobás  Svante Janson  and Oliver Riordan. The phase transition in inhomogeneous random graphs.

Random Struct. Algorithms  31(1):3–122  August 2007.

[9] A. Decelle  F. Krzakala  C. Moore  and L. Zdeborová. Asymptotic analysis of the stochastic block model

for modular networks and its algorithmic applications. Phys. Rev. E  84:066106  December 2011.

[10] Elchanan Mossel  Joe Neeman  and Allan Sly. Reconstruction and estimation in the planted partition

model. Probability Theory and Related Fields  162(3):431–461  2015.

[11] A. Coja-Oghlan. Graph partitioning via adaptive spectral techniques. Comb. Probab. Comput.  19(2):227–

284  March 2010.

[12] V. Vu. A simple svd algorithm for ﬁnding hidden partitions. ArXiv:1404.3918  April 2014.

[13] Olivier Guédon and Roman Vershynin. Community detection in sparse networks via grothendieck’s

inequality. Probability Theory and Related Fields  165(3):1025–1049  2016.

[14] Andrea Montanari and Subhabrata Sen. Semideﬁnite programs on sparse random graphs and their
application to community detection. In Proceedings of the 48th Annual ACM SIGACT Symposium on
Theory of Computing  STOC 2016  pages 814–827  New York  NY  USA  2016. ACM.

[15] L. Massoulié. Community detection thresholds and the weak Ramanujan property. In STOC 2014: 46th

Annual Symposium on the Theory of Computing  pages 1–10  New York  United States  June 2014.

[16] E. Mossel  J. Neeman  and A. Sly. A proof of the block model threshold conjecture. Available online at

arXiv:1311.4115 [math.PR]  January 2014.

[17] Charles Bordenave  Marc Lelarge  and Laurent Massoulie. Non-backtracking spectrum of random graphs:
Community detection and non-regular ramanujan graphs. In FOCS ’15  pages 1347–1357  Washington 
DC  USA  2015. IEEE Computer Society.

[18] Kevin P. Murphy  Yair Weiss  and Michael I. Jordan. Loopy belief propagation for approximate inference:
An empirical study. In Proceedings of the Fifteenth Conference on Uncertainty in Artiﬁcial Intelligence 
UAI’99  pages 467–475  San Francisco  CA  USA  1999. Morgan Kaufmann Publishers Inc.

[19] E. Abbe and C. Sandon. Detection in the stochastic block model with multiple clusters: proof of the
achievability conjectures  acyclic BP  and the information-computation gap. ArXiv:1512.09080  Dec. 2015.

[20] J. Banks and C. Moore. Information-theoretic thresholds for community detection in sparse networks.

ArXiv:1601.02658  January 2016.

[21] David L. Donoho  Arian Maleki  and Andrea Montanari. Message-passing algorithms for compressed

sensing. Proceedings of the National Academy of Sciences  106(45):18914–18919  2009.

[22] Florent Krzakala  Cristopher Moore  Elchanan Mossel  Joe Neeman  Allan Sly  Lenka Zdeborova  and
Pan Zhang. Spectral redemption in clustering sparse networks. Proceedings of the National Academy of
Sciences  110(52):20935–20940  2013.

[23] S. Bhattacharyya and P. J. Bickel. Community Detection in Networks using Graph Distance.

ArXiv:1401.3915  January 2014.

9

,Mehmet Gönen
Adam Margolin
Emmanuel Abbe
Colin Sandon
Dong Liu
Haochen Zhang
Zhiwei Xiong