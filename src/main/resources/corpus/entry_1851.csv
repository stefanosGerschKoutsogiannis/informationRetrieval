2017,Estimating Accuracy from Unlabeled Data: A Probabilistic Logic Approach,We propose an efficient method to estimate the accuracy of classifiers using only unlabeled data. We consider a setting with multiple classification problems where the target classes may be tied together through logical constraints. For example  a set of classes may be mutually exclusive  meaning that a data instance can belong to at most one of them. The proposed method is based on the intuition that: (i) when classifiers agree  they are more likely to be correct  and (ii) when the classifiers make a prediction that violates the constraints  at least one classifier must be making an error. Experiments on four real-world data sets produce accuracy estimates within a few percent of the true accuracy  using solely unlabeled data. Our models also outperform existing state-of-the-art solutions in both estimating accuracies  and combining multiple classifier outputs. The results emphasize the utility of logical constraints in estimating accuracy  thus validating our intuition.,Estimating Accuracy from Unlabeled Data:

A Probabilistic Logic Approach

Emmanouil A. Platanios
Carnegie Mellon University

Pittsburgh  PA

e.a.platanios@cs.cmu.edu

Tom M. Mitchell

Carnegie Mellon University

Pittsburgh  PA

tom.mitchell@cs.cmu.edu

Hoifung Poon

Microsoft Research

Redmond  WA

hoifung@microsoft.com

Eric Horvitz

Microsoft Research

Redmond  WA

horvitz@microsoft.com

Abstract

We propose an efﬁcient method to estimate the accuracy of classiﬁers using only
unlabeled data. We consider a setting with multiple classiﬁcation problems where
the target classes may be tied together through logical constraints. For example  a
set of classes may be mutually exclusive  meaning that a data instance can belong to
at most one of them. The proposed method is based on the intuition that: (i) when
classiﬁers agree  they are more likely to be correct  and (ii) when the classiﬁers
make a prediction that violates the constraints  at least one classiﬁer must be making
an error. Experiments on four real-world data sets produce accuracy estimates
within a few percent of the true accuracy  using solely unlabeled data. Our models
also outperform existing state-of-the-art solutions in both estimating accuracies 
and combining multiple classiﬁer outputs. The results emphasize the utility of
logical constraints in estimating accuracy  thus validating our intuition.

1

Introduction

Estimating the accuracy of classiﬁers is central to machine learning and many other ﬁelds. Accuracy
is deﬁned as the probability of a system’s output agreeing with the true underlying output  and thus
is a measure of the system’s performance. Most existing approaches to estimating accuracy are
supervised  meaning that a set of labeled examples is required for the estimation. Being able to
estimate the accuracies of classiﬁers using only unlabeled data is important for many applications 
including: (i) any autonomous learning system that operates under no supervision  as well as (ii)
crowdsourcing applications  where multiple workers provide answers to questions  for which the
correct answer is unknown. Furthermore  tasks which involve making several predictions which are
tied together by logical constraints are abundant in machine learning. As an example  we may have
two classiﬁers in the Never Ending Language Learning (NELL) project [Mitchell et al.  2015] which
predict whether noun phrases represent animals or cities  respectively  and we know that something
cannot be both an animal and a city (i.e.  the two categories are mutually exclusive). In such cases  it
is not hard to observe that if the predictions of the system violate at least one of the constraints  then
at least one of the system’s components must be wrong. This paper extends this intuition and presents
an unsupervised approach (i.e.  only unlabeled data are needed) for estimating accuracies that is able
to use information provided by such logical constraints. Furthermore  the proposed approach is also
able to use any available labeled data  thus also being applicable to semi-supervised settings.

31st Conference on Neural Information Processing Systems (NIPS 2017)  Long Beach  CA  USA.

Figure 1: System overview diagram. The classiﬁer outputs (corresponding to the function approx-
imation outputs) and the logical constraints make up the system inputs. The representation of the
logical constraints in terms of the function approximation error rates is described in section 3.2. In
the logical constraints box  blue arrows represent subsumption constraints  and labels connected by
a red dashed line represent a mutually exclusive set. Given the inputs  the ﬁrst step is grounding
(computing all feasible ground predicates and rules that the system will need to perform inference
over) and is described in section 3.3.2. In the ground rules box  ∧  ¬  → correspond to the logic AND 
OR  and IMPLIES. Then  inference is performed in order to infer the most likely truth values of the
unobserved ground predicates  given the observed ones and the ground rules (described in detail in
section 3.3). The results constitute the outputs of our system and they include: (i) the estimated error
rates  and (ii) the most likely target function outputs (i.e.  combined predictions).

1   . . .   ˆf d

We consider a “multiple approximations” problem setting in which we have several different ap-
proximations  ˆf d
N d  to a set of target boolean classiﬁcation functions  f d : X (cid:55)→ {0  1} for
d = 1  . . .   D  and we wish to know the true accuracies of each of these different approximations 
using only unlabeled data  as well as the response of the true underlying functions  f d. Each value
of d characterizes a different domain (or problem setting) and each domain can be interpreted as a
class or category of objects. Similarly  the function approximations can be interpreted as classifying
inputs as belonging or not to these categories. We consider the case where we may have a set of
logical constraints deﬁned over the domains. Note that  in contrast with related work  we allow the
function approximations to provide soft responses in the interval [0  1] (as opposed to only allowing
binary responses — i.e.  they can now return the probability for the response being 1)  thus allowing
modeling of their “certainty”. As an example of this setting  to which we will often refer throughout
this paper  let us consider a part of NELL  where the input space of our functions  X   is the space of
all possible noun phrases (NPs). Each target function  f d  returns a boolean value indicating whether
the input NP belongs to a category  such as “city” or “animal”  and these categories correspond to our
domains. There also exist logical constraints between these categories that may be hard (i.e.  strongly
enforced) or soft (i.e.  enforced in a probabilistic manner). For example  “city” and “animal” may
be mutually exclusive (i.e.  if an object belongs to “city”  then it is unlikely that it also belongs to
“animal”). In this case  the function approximations correspond to different classiﬁers (potentially
using a different set of features / different views of the input data)  which may return a probability
for a NP belonging to a class  instead of a binary value. Our goal is to estimate the accuracies of
these classiﬁers using only unlabeled data. In order to quantify accuracy  we deﬁne the error rate of
classiﬁer j in domain d as ed
j (X) (cid:54)= f d(X)]  for the binary case  for j = 1  . . .   N d  where
j

(cid:44) PD[ ˆf d

2

animalfishbird. . . Logical Constraintssharkanimal99%fish95%bird5%. . .sparrowanimal95%fish10%bird26%. . .. . .Classiﬁer #1sharkanimal99%fish95%bird5%. . .sparrowanimal95%fish2%bird84%. . .. . .Classiﬁer #2InstanceCategoryProbabilityClassiﬁer Outputs. . .SUB(animal fish)^¬ˆfanimal1(shark)^ffish(shark)!eanimal1...ME(fish bird)^ˆffish1(sparrow)^fbird(sparrow)!efish1Ground Rulesˆfanimal1(shark)=0.99ˆffish1(shark)=0.95ˆfbird1(shark)=0.05ˆfanimal1(sparrow)=0.95ˆffish1(sparrow)=0.10ˆfbird1(sparrow)=0.26...SUB(animal fish)=1SUB(animal bird)=1ME(fish bird)=1eanimal1efish1ebird1...fanimal(shark)ffish(shark)fbird(shark)fanimal(sparrow)ffish(sparrow)fbird(sparrow)ObservedUnobservedError RatesCombined PredictionsResultsClassiﬁer #1animal1%fish5%bird57%. . .Classiﬁer #2animal1%fish2%bird9%. . .. . .sparrowanimal95%fish4%bird75%. . .sharkanimal99%fish95%bird8%. . .. . .GroundingInputs: Predicted probability for each classiﬁer-object-category.Outputs: Set of object-category classiﬁcation pairs and category-classiﬁer error-rate pairs that are not directly constrained to be 0 or 1 from the logical constraints.Description: Section 3.3.2.Probabilistic InferenceInputs: Ground predicates and rules.Step 1: Create a Markov Random Field (MRF).Step 2: Perform probabilistic inference to obtain the most likely values for the unobserved ground predicates. Inference is performed using a modiﬁed version of the Probabilistic Soft Logic (PSL) framework.Outputs: Classiﬁer error rates and underlying function values.Description: Section 3.3.Ground PredicatesD is the true underlying distribution of the input data. Note that accuracy is equal to one minus error
rate. This deﬁnition may be relaxed for the case where ˆf d
j (X) ∈ [0  1] representing a probability:
j (X))PD[f d(X)(cid:54)= 0]  which resembles an expected probabil-
ed
j
ity of error. Even though our work is motivated by the use of logical constraints deﬁned over the
domains  we also consider the setting where there are no such constraints.

j (X)PD[f d(X)(cid:54)= 1] + (1 − ˆf d

(cid:44) ˆf d

2 Related Work

The literature covers many projects related to estimating accuracy from unlabeled data. The setting
we are considering was previously explored by Collins and Singer [1999]  Dasgupta et al. [2001] 
Bengio and Chapados [2003]  Madani et al. [2004]  Schuurmans et al. [2006]  Balcan et al. [2013] 
and Parisi et al. [2014]  among others. Most of their approaches made some strong assumptions 
such as assuming independence given the outputs  or assuming knowledge of the true distribution
of the outputs. None of the previous approaches incorporated knowledge in the form of logical
constraints. Collins and Huynh [2014] review many methods that were proposed for estimating the
accuracy of medical tests in the absence of a gold standard. This is effectively the same problem that
we are considering  applied to the domains of medicine and biostatistics. They present a method
for estimating the accuracy of tests  where these tests are applied in multiple different populations
(i.e.  different input data)  while assuming that the accuracies of the tests are the same across the
populations  and that the test results are independent conditional on the true “output”. These are
similar assumptions to the ones made by several of the other papers already mentioned  but the idea
of applying the tests to multiple populations is new and interesting. Platanios et al. [2014] proposed a
method relaxing some of these assumptions. They formulated the problem of estimating the error
rates of several approximations to a function as an optimization problem that uses agreement rates
of these approximations over unlabeled data. Dawid and Skene [1979] were the ﬁrst to formulate
the problem in terms of a graphical model and Moreno et al. [2015] proposed a nonparametric
extension to that model applied to crowdsourcing. Tian and Zhu [2015] proposed an interesting
max-margin majority voting scheme for combining classiﬁer outputs  also applied to crowdsourcing.
However  all of these approaches were outperformed by the models of Platanios et al. [2016]  which
are most similar to the work of Dawid and Skene [1979] and Moreno et al. [2015]. To the best of
our knowledge  our work is the ﬁrst to use logic for estimating accuracy from unlabeled data and  as
shown in our experiments  outperforms all competing methods. Logical constraints provide additional
information to the estimation method and this partially explains the performance boost.

3 Proposed Method

j   in terms of the error rates ed

Our method consists of: (i) deﬁning a set of logic rules for modeling the logical constraints between
the f d and the ˆf d
j and the known logical constraints  and (ii) performing
probabilistic inference using these rules as priors  in order to obtain the most likely values of the
j and the f d  which are not observed. The intuition behind the method is that if the constraints
ed
are violated for the function approximation outputs  then at least one of these functions has to be
making an error. For example  in the NELL case  if two function approximations respond that a
NP belongs to the “city” and the “animal” categories  respectively  then at least one of them has to
be making an error. We deﬁne the form of the logic rules in section 3.2 and then describe how to
perform probabilistic inference over them in section 3.3. An overview of our system is shown in
ﬁgure 1. In the next section we introduce the notion of probabilistic logic  which fuses classical logic
with probabilistic reasoning and that forms the backbone of our method.

3.1 Probabilistic Logic

In classical logic  we have a set of predicates (e.g.  mammal(x) indicating whether x is a mammal 
where x is a variable) and a set of rules deﬁned in terms of these predicates (e.g.  mammal(x) →
animal(x)  where “→” can be interpreted as “implies”). We refer to predicates and rules deﬁned for
a particular instantiation of their variables as ground predicates and ground rules  respectively (e.g. 
mammal(whale) and mammal(whale) → animal(whale)). These ground predicates and rules take
boolean values (i.e.  are either true or false — for rules  the value is true if the rule holds). Our goal

3

is to infer the most likely values for a set of unobserved ground predicates  given a set of observed
ground predicate values and logic rules.
In probabilistic logic  we are instead interested in inferring the probabilities of these ground predicates
and rules being true  given a set of observed ground predicates and rules. Furthermore  the truth
values of ground predicates and rules may be continuous and lie in the interval [0  1]  instead of being
boolean  representing the probability that the corresponding ground predicate or rule is true. In this
case  boolean logic operators  such as AND (∧)  OR (∨)  NOT (¬)  and IMPLIES (→)  need to be
redeﬁned. For the next section  we will assume their classical logical interpretation.

3.2 Model

As described earlier  our goal is to estimate the true accuracies of each of the function approximations 
ˆf d
1   . . .   ˆf d
N d for d = 1  . . .   D  using only unlabeled data  as well as the response of the true
underlying functions  f d. We now deﬁne the logic rules that we perform inference over in order to
achieve that goal. The rules are deﬁned in terms of the following predicates  for d = 1  . . .   D:
• Function Approximation Outputs: ˆf d

j (X)  deﬁned over all approximations j = 1  . . .   N d  and
inputs X ∈ X   for which the corresponding function approximation has provided a response. Note
that the values of these ground predicates lie in [0  1] due to their probabilistic nature (i.e.  they do
not have to be binary  as in related work)  and some of them are observed.
• Target Function Outputs: f d(X)  deﬁned over all inputs X ∈ X . Note that  in the purely
unsupervised setting  none of these ground predicate values are observed  in contrast with the
semi-supervised setting.

• Function Approximation Error Rates: ed

j   deﬁned over all approximations j = 1  . . .   N d. Note
that none of these ground predicate values are observed. The primary goal of this paper is to infer
their values.

The goal of the logic rules we deﬁne is two-fold: (i) to combine the function approximation outputs
in a single output value  and (ii) to account for the logical constraints between the domains. We aim
to achieve both goals while accounting for the error rates of the function approximations. We ﬁrst
deﬁne a set of rules that relate the function approximation outputs with the true underlying function
output. We call this set of rules the ensemble rules and we describe them in the following section.
We then discuss how to account for the logical constraints between the domains.

3.2.1 Ensemble Rules

j →¬f d(X) 
j → f d(X) 

j (X) ∧ ¬ed
j (X) ∧ ed

j → f d(X)  ¬ ˆf d
j →¬f d(X)  and ¬ ˆf d

This ﬁrst set of rules speciﬁes a relation between the target function outputs  f d(X)  and the function
approximation outputs  ˆf d
j (X)  independent of the logical constraints:
ˆf d
j (X) ∧ ¬ed
ˆf d
j (X) ∧ ed

(1)
(2)
for d = 1  . . .   D  j = 1  . . .   N d  and X ∈ X . In words: (i) the ﬁrst set of rules state that if a
function approximation is not making an error  its output should match the output of the target
function  and (ii) the second set of rules state that if a function approximation is making an error  its
output should not match the output of the target function.
An interesting point to make is that the ensemble rules effectively constitute a weighted majority
vote for combining the function approximation outputs  where the weights are determined by the
error rates of the approximations. These error rates are implicitly computed based on agreement
between the function approximations. This is related to the work of Platanios et al. [2014]. There 
the authors try to answer the question of whether consistency in the outputs of the approximations
implies correctness. They directly use the agreement rates of the approximations in order to estimate
their error rates. Thus  there exists an interesting connection in our work in that we also implicitly
use agreement rates to estimate error rates  and our results  even though improving upon theirs
signiﬁcantly  reinforce their claim.

Identiﬁability. Let us consider ﬂipping the values of all error rates (i.e.  setting them to one minus
their value) and the target function responses. Then  the ensemble logic rules would evaluate to
the same value as before (e.g.  satisﬁed or unsatisﬁed). Therefore  the error rates and the target
function values are not identiﬁable when there are no logical constraints. As we will see in the next

4

section  the constraints may sometimes help resolve this issue as  often  the corresponding logic
rules do not exhibit that kind of symmetry. However  for cases where that symmetry exists  we
can resolve it by assuming that most of the function approximations have error rates better than
chance (i.e.  < 0.5). This can be done by considering the two rules: (i) ˆf d
j (X) → f d(X)  and
¬ ˆf d
j (X) → ¬f d(X)  for d = 1  . . .   D  j = 1  . . .   N d  and X ∈ X . Note that all that these rules
imply is that ˆf d
j (X) = f d(X) (i.e.  they represent the prior belief that function approximations are
correct). As will be discussed in section 3.3  in probabilistic frameworks where rules are weighted
with a real value in [0  1]  these rules will be given a weight that represents their signiﬁcance or
strength. In such a framework  we can consider using a smaller weight for these prior belief rules 
compared to the remainder of the rules  which would simply correspond to a regularization weight.
This weight can be a tunable or even learnable parameter.

3.2.2 Constraints

The space of possible logical constraints is huge; we do not deal with every possible constraint in
this paper. Instead  we focus our attention on two types of constraints that are abundant in structured
prediction problems in machine learning  and which are motivated by the use of our method in the
context of NELL:
• Mutual Exclusion: If domains d1 and d2 are mutually exclusive  then f d1 = 1 implies that f d2 = 0.
For example  in the NELL setting  if a NP belongs to the “city” category  then it cannot also belong
to the “animal” category.

• Subsumption: If d1 subsumes d2  then if f d2 = 1  we must have that f d1 = 1. For example  in
the NELL setting  if a NP belongs to the “cat” category  then it must also belong to the “animal”
category.

This set of constraints is sufﬁcient to model most ontology constraints between categories in NELL 
as well as a big subset of the constraints more generally used in practice.

Mutual Exclusion Rule. We ﬁrst deﬁne the predicate ME(d1  d2)  indicating that domains d1 and
d2 are mutually exclusive1. This predicate has value 1 if domains d1 and d2 are mutually exclusive 
and value 0 otherwise  and its truth value is observed for all values of d1 and d2. Furthermore  note
that it is symmetric  meaning that if ME(d1  d2) is true  then ME(d2  d1) is also true. We deﬁne the
mutual exclusion logic rule as:

ME(d1  d2) ∧ ˆf d1

(3)
for d1 (cid:54)= d2 = 1  . . .   D  j = 1  . . .   N d1  and X ∈ X . In words  this rule says that if f d2(X) = 1
and domains d1 and d2 are mutually exclusive  then ˆf d1
j (X) must be equal to 0  as it is an approxi-
mation to f d1(X) and ideally we want that ˆf d1
j must
be making an error.

j (X) = f d1 (X). If that is not the case  then ˆf d1

j (X) ∧ f d2(X) → ed1
j  

Subsumption Rule. We ﬁrst deﬁne the predicate SUB(d1  d2)  indicating that domain d1 subsumes
domain d2. This predicate has value 1 if domain d1 subsumes domain d2  and 0 otherwise  and its
truth value is always observed. Note that  unlike mutual exclusion  this predicate is not symmetric.
We deﬁne the subsumption logic rule as:

SUB(d1  d2) ∧ ¬ ˆf d1

j (X) ∧ f d2(X) → ed1
j  

(4)
for d1  d2 = 1  . . .   D  j = 1  . . .   N d1  and X ∈ X . In words  this rule says that if f d2 (X) = 1 and
d1 subsumes d2  then ˆf d1
j (X) must be equal to 1  as it is an approximation to f d1(X) and ideally we
want that ˆf d1
Having deﬁned all of the logic rules that comprise our model  we now describe how to perform
inference under such a probabilistic logic model  in the next section. Inference in this case comprises
determining the most likely truth values of the unobserved ground predicates  given the observed
predicates and the set of rules that comprise our model.

j (X) = f d1(X). If that is not the case  then ˆf d1

j must be making an error.

1A set of mutually-exclusive domains can be reduced to pairwise ME constraints for all pairs in that set.

5

3.3

Inference

In section 3.1 we introduced the notion of probabilistic logic and we deﬁned our model in terms
of probabilistic predicates and rules. In this section we discuss in more detail the implications of
using probabilistic logic  and the way in which we perform inference in our model. There exist
various probabilistic logic frameworks  each making different assumptions. In what is arguably the
most popular such framework  Markov Logic Networks (MLNs) [Richardson and Domingos  2006] 
inference is performed over a constructed Markov Random Field (MRF) based on the model logic
rules. Each potential function in the MRF corresponds to a ground rule and takes an arbitrary positive
value when the ground rule is satisﬁed and the value 0 otherwise (the positive values are often called
rule weights and can be either ﬁxed or learned). Each variable is boolean-valued and corresponds
to a ground predicate. MLNs are thus a direct probabilistic extension to boolean logic. It turns out
that due to the discrete nature of the variables in MLNs  inference is NP-hard and can thus be very
inefﬁcient. Part of our goal in this paper is for our method to be applicable at a very large scale (e.g. 
for systems like NELL). We thus resorted to Probabilistic Soft Logic (PSL) [Bröcheler et al.  2010] 
which can be thought of as a convex relaxation of MLNs.
Note that the model proposed in the previous section  which is also the primary contribution of this
paper  can be used with various probabilistic logic frameworks. Our choice  which is described in
this section  was motivated by scalability. One could just as easily perform inference for our model
using MLNs  or any other such framework.

3.3.1 Probabilistic Soft Logic (PSL)

In PSL  models  which are composed of a set of logic rules  are represented using hinge-loss
Markov random ﬁelds (HL-MRFs) [Bach et al.  2013]. In this case  inference amounts to solving a
convex optimization problem. Variables of the HL-MRF correspond to soft truth values of ground
predicates. Speciﬁcally  a HL-MRF  f  is a probability density over m random variables  Y =
{Y1  . . .   Ym} with domain D = [0  1]m  corresponding to the unobserved ground predicate values.
Let X = {X1  . . .   Xn} be an additional set of variables with known values in the domain [0  1]n 
corresponding to observed ground predicate values. Let φ = {φ1  . . .   φk} be a ﬁnite set of k
continuous potential functions of the form φj(X  Y) = (max{(cid:96)j(X  Y)  0})pj   where (cid:96)j is a linear
function of X and Y  and pj ∈ {1  2}. We will soon see how these functions relate to the ground
rules of the model. Given the above  for a set of non-negative free parameters λ = {λ1  . . .   λk} (i.e. 
the equivalent of MLN rule weights)  the HL-MRF density is deﬁned as:

λjφj(X  Y) 

(5)

where Z is a normalizing constant so that f is a proper probability density function. Our goal is to
infer the most probable explanation (MPE)  which consists of the values of Y that maximize the
likelihood of our data2. This is equivalent to solving the following convex problem:

f (Y) =

1
Z

exp−

k(cid:88)

j=1

k(cid:88)

j=1

min

Y∈[0 1]m

λjφj(X  Y).

(6)

Each variable Xi or Yi corresponds to a soft truth value (i.e.  Yi ∈ [0  1]) of a ground predicate.
Each function (cid:96)j corresponds to a measure of the distance to satisﬁability of a logic rule. The set
of rules used is what characterizes a particular PSL model. The rules represent prior knowledge
we might have about the problem we are trying to solve. For our model  these rules were deﬁned
in section 3.2. As mentioned above  variables are allowed to take values in the interval [0  1]. We
thus need to deﬁne what we mean by the truth value of a rule and its distance to satisﬁability. For
the logical operators AND (∧)  OR (∨)  NOT (¬)  and IMPLIES (→)  we use the deﬁnitions from
Łukasiewicz Logic [Klir and Yuan  1995]: P ∧Q (cid:44) max{P + Q − 1  0}  P ∨Q (cid:44) min{P + Q  1} 
¬P (cid:44) 1 − P   and P → Q (cid:44) min{1 − P + Q  1}. Note that these operators are a simple continuous
relaxation of the corresponding boolean operators  in that for boolean-valued variables  with 0
corresponding to FALSE and 1 to TRUE  they are equivalent. By writing all logic rules in the form
B1 ∧ B2 ∧ ··· ∧ Bs → H1 ∨ H2 ∨ ··· ∨ Ht  it is easy to observe that the distance to satisﬁability
2As opposed to performing marginal inference which aims to infer the marginal distribution of these values.

6

Figure 2: Illustration of the NELL-11 data set constraints. Each box represents a label  each blue
arrow represents a subsumption constraint  and each set of labels connected by a red dashed line
represents a mutually exclusive set of labels. For example  Animal subsumes Vertebrate and
Bird  Fish  and Mammal are mutually exclusive.

i=1 Bi −

(i.e.  1 minus its truth value) of a rule evaluates to max{0 (cid:80)s

(cid:80)t
j=1 Ht + 1 − s}. Note
that any set of rules of ﬁrst-order predicate logic can be represented in this form [Bröcheler et al. 
2010]  and that minimizing this quantity amounts to making the rule “more satisﬁed”.
In order to complete our system description we need to describe: (i) how to obtain a set of ground
rules and predicates from a set of logic rules of the form presented in section 3.2 and a set of
observed ground predicates  and deﬁne the objective function of equation 6  and (ii) how to solve
the optimization problem of that equation to obtain the most likely truth values for the unobserved
ground predicates. These two steps are described in the following two sections.

3.3.2 Grounding

Grounding is the process of computing all possible groundings of each logic rule to construct the
inference problem variables and the objective function. As already described in section 3.3.1  the
variables X and Y correspond to ground predicates and the functions (cid:96)j correspond to ground rules.
The easiest way to ground a set of logic rules would be to go through each one and create a ground
rule instance of it  for each possible value of its arguments. However  if a rule depends on n variables
and each variable can take m possible values  then mn ground rules would be generated. For example 
the mutual exclusion rule of equation 3 depends on d1  d2  j  and X  meaning that D2×N d1×|X|
ground rule instances would be generated  where |X| denotes the number of values that X can
take. The same applies to predicates; ˆf d1
j (X) would result in D× N d1 ×|X| ground instances 
which would become variables in our optimization problem. This approach would thus result in a
huge optimization problem rendering it impractical when dealing with large scale problems such as
NELL. The key to scaling up the grounding procedure is to notice that many of the possible ground
rules are always satisﬁed (i.e.  have distance to satisﬁability equal to 0)  irrespective of the values
of the unobserved ground predicates that they depend upon. These ground rules would therefore
not inﬂuence the optimization problem solution and can be safely ignored. Since in our model we
are only dealing with a small set of predeﬁned logic rule forms  we devised a heuristic grounding
procedure that only generates those ground rules and predicates that may inﬂuence the optimization.
Our grounding algorithm is shown in the supplementary material and is based on the idea that a
ground rule is only useful if the function approximation predicate that appears in its body is observed.
It turns out that this approach is orders of magnitude faster than existing state-of-the-art solutions
such as the grounding solution used by Niu et al. [2011].

3.3.3 Solving the Optimization Problem

For large problems  the objective function of equation 6 will be a sum of potentially millions of
terms  each one of which only involving a small set of variables. In PSL  the method used to solve
this optimization problem is based on the consensus Alternating Directions Method of Multipliers
(ADMM). The approach consists of handling each term in that sum as a separate optimization
problem using copies of the corresponding variables  while adding the constraint that all copies of
each variable must be equal. This allows for solving the subproblems completely in parallel and
is thus scalable. The algorithm is summarized in the supplementary material. More details on this
algorithm and on its convergence properties can be found in the latest PSL paper [Bach et al.  2015].
We propose a stochastic variation of this consensus ADMM method that is even more scalable.
During each iteration  instead of solving all subproblems and aggregating their solutions in the
consensus variables  we sample K << k subproblems to solve. The probability of sampling each

7

AnimalVertebrateInvertebrateRiverLakeCityCountryBirdFishMammalArthropodMolluskLocationTable 1: Mean absolute deviation (MAD) of the error rate rankings and the error rate estimates (lower
MAD is better)  and area under the curve (AUC) of the label estimates (higher AUC is better). The
best results for each experiment  across all methods  are shown in bolded text and the results for our
proposed method are highlighted in blue.

MAJ
AR-2
AR
BEE
CBEE
HCBEE
LEE
−2

×10

MAJ
GIBBS-SVM
GD-SVM
DS
AR-2
AR
BEE
CBEE
HCBEE
LEE
−1

×10

MAJ
GIBBS-SVM
GD-SVM
DS
AR-2
BEE
CBEE
HCBEE
LEE

MADerror rank

7.71
12.0
11.4
6.00
6.00
5.03
3.71

MADerror rank

23.3
102.0
26.7
170.0
48.3
48.3
40.0
40.0
81.7
30.0

NELL-7
MADerror
0.238
0.261
0.260
0.231
0.232
0.229
0.152

uNELL-All
MADerror

0.47
2.05
0.42
7.08
2.63
2.60
0.60
0.61
2.53
0.37

AUCtarget
0.372
0.378
0.374
0.314
0.314
0.452
0.508

AUCtarget
99.9
28.6
71.3
12.1
96.7
96.7
99.8
99.8
99.4
96.5

MADerror rank

7.54
10.8
11.1
5.69
5.69
5.14
4.77

MADerror rank

33.3
101.7
93.3
180.0
50.0
48.3
31.7
118.0
81.7
30.0

NELL-11
MADerror
0.303
0.350
0.350
0.291
0.291
0.324
0.180

uNELL-10%

MADerror
0.54
2.15
1.90
6.96
2.56
2.52
0.64
45.40
2.45
0.43

AUCtarget
0.447
0.455
0.477
0.368
0.368
0.462
0.615

AUCtarget

87.7
28.2
67.8
12.3
96.4
96.4
79.5
55.4
84.9
97.3

MADerror rank

uBRAIN-All

MADerror

AUCtarget

MADerror rank

uBRAIN-10%

MADerror

AUCtarget

8.76
7.77
7.60
7.77
16.40
7.98
10.90
28.10
7.60

0.57
0.43
0.44
0.44
0.87
0.40
0.43
0.85
0.38

8.49
4.65
5.24
8.76
9.71
9.32
9.34
9.20
9.95

1.52
1.51
1.50
1.32
2.28
1.38
1.77
3.25
1.32

0.68
0.66
0.68
0.63
0.97
0.63
0.89
0.97
0.47

7.84
5.28
8.56
4.59
9.89
9.35
9.30
9.37
9.98

subproblem is proportional to the distance of its variable copies from the respective consensus
variables. The intuition and motivation behind this approach is that at the solution of the optimization
problem  all variable copies should be in agreement with the consensus variables. Therefore  priori-
tizing subproblems whose variables are in greater disagreement with the consensus variables might
facilitate faster convergence. Indeed  this modiﬁcation to the inference algorithm allowed us to apply
our method to the NELL data set and obtain results within minutes instead of hours.

4 Experiments

Our implementation as well as the experiment data sets are available at https://github.com/
eaplatanios/makina.

Data Sets. First  we considered the following two data sets with logical constraints:
• NELL-7: Classify noun phrases (NPs) as belonging to a category or not (categories correspond
to domains in this case). The categories considered for this data set are Bird  Fish  Mammal 
City  Country  Lake  and River. The only constraint considered is that all these categories
are mutually exclusive.

• NELL-11: Perform the same task  but with the categories and constraints illustrated in ﬁgure 2.
For both of these data sets  we have a total of 553 940 NPs and 6 classiﬁers  which act as our function
approximations and are described in [Mitchell et al.  2015]. Not all of the classiﬁers provide a
response every input NP. In order to show the applicability of our method in cases where there are no
logical constraints between the domains  we also replicated the experiments of Platanios et al. [2014]:
• uNELL: Same task as NELL-7  but without considering the constraints and using 15 categories  4

classiﬁers  and about 20 000 NPs per category.

8

• uBRAIN: Classify which of two 40 second long story passages corresponds to an unlabeled 40
second time series of Functional Magnetic Resonance Imaging (fMRI) neural activity. 11 classiﬁers
were used and the domain in this case is deﬁned by 11 different locations in the brain  for each of
which we have 924 examples. Additional details can be found in [Wehbe et al.  2014].

Methods. Some of the methods we compare against do not explicitly estimate error rates. Rather 
they combine the classiﬁer outputs to produce a single label. For these methods  we produce an
estimate of the error rate using these labels and compare against this estimate.
1. Majority Vote (MV): This is the most intuitive method and it consists of taking the most common

output among the provided function approximation responses  as the combined output.

2. GIBBS-SVM/GD-SVM: Methods of Tian and Zhu [2015].
3. DS: Method of Dawid and Skene [1979].
4. Agreement Rates (AR): This is the method of Platanios et al. [2014]. It estimates error rates
but does not infer the combined label. To that end  we use a weighted majority vote  where the
classiﬁers’ predictions are weighted according to their error rates in order to produce a single
output label. We also compare against a method denoted by AR-2 in our experiments  which is
the same method  except only pairwise function approximation agreements are considered.

5. BEE/CBEE/HCBEE: Methods of Platanios et al. [2016].
In the results  LEE stands for Logic Error Estimation and refers to the proposed method of this paper.

Evaluation. We compute the sample error rate estimates using the true target function labels (which
are always provided)  and we then compute three metrics for each domain and average over domains:
• Error Rank MAD: We rank the function approximations by our estimates and by the sample
estimates to produce two vectors with the ranks. We then compute the mean absolute deviation
(MAD) between the two vectors  where by MAD we mean the (cid:96)1 norm of the vectors’ difference.
• Error MAD: MAD between the vector of our estimates and the vector of the sample estimates 
where each vector is indexed by the function approximation index.
• Target AUC: Area under the precision-recall curve for the inferred target function values  relative

to the true function values that are observed.

Results. First  note that the largest execution time of our method among all data sets was about 10
minutes  using a 2013 15-inch MacBook Pro. The second best performing method  HCBEE  required
about 100 minutes. This highlights the scalability of our approach. Results are shown in table 1.
1. NELL-7 and NELL-11 Data Sets: In this case we have logical constraints and thus  this set of
results is most relevant to the central research claims in this paper (our method was motivated by
the use of such logical constraints). It is clear that our method outperforms all existing methods 
including the state-of-the-art  by a signiﬁcant margin. Both the MADs of the error rate estimation 
and the AUCs of the target function response estimation  are signiﬁcantly better.

2. uNELL and uBRAIN Data Sets: In this case there exist no logical constraints between the domains.
Our method still almost always outperforms the competing methods and  more speciﬁcally  it
always does so in terms of error rate estimation MAD. This set of results makes it clear that our
method can also be used effectively in cases where there are no logical constraints.

Acknowledgements

We would like to thank Abulhair Saparov and Otilia Stretcu for the useful feedback they provided in
early versions of this paper. This research was performed during an internship at Microsoft Research 
and was also supported in part by NSF under award IIS1250956  and in part by a Presidential
Fellowship from Carnegie Mellon University.

References
S. H. Bach  B. Huang  B. London  and L. Getoor. Hinge-loss Markov Random Fields: Convex
Inference for Structured Prediction. In Conference on Uncertainty in Artiﬁcial Intelligence  2013.

9

S. H. Bach  M. Broecheler  B. Huang  and L. Getoor. Hinge-loss markov random ﬁelds and
probabilistic soft logic. CoRR  abs/1505.04406  2015. URL http://dblp.uni-trier.de/
db/journals/corr/corr1505.html#BachBHG15.

M.-F. Balcan  A. Blum  and Y. Mansour. Exploiting Ontology Structures and Unlabeled Data for

Learning. International Conference on Machine Learning  pages 1112–1120  2013.

Y. Bengio and N. Chapados. Extensions to Metric-Based Model Selection. Journal of Machine

Learning Research  3:1209–1227  2003.

M. Bröcheler  L. Mihalkova  and L. Getoor. Probabilistic Similarity Logic.

Uncertainty in Artiﬁcial Intelligence  pages 73–82  2010.

In Conference on

J. Collins and M. Huynh. Estimation of Diagnostic Test Accuracy Without Full Veriﬁcation: A

Review of Latent Class Methods. Statistics in Medicine  33(24):4141–4169  June 2014.

M. Collins and Y. Singer. Unsupervised Models for Named Entity Classiﬁcation. In Joint Conference

on Empirical Methods in Natural Language Processing and Very Large Corpora  1999.

S. Dasgupta  M. L. Littman  and D. McAllester. PAC Generalization Bounds for Co-training. In

Neural Information Processing Systems  pages 375–382  2001.

A. P. Dawid and A. M. Skene. Maximum Likelihood Estimation of Observer Error-Rates Using the
EM Algorithm. Journal of the Royal Statistical Society. Series C (Applied Statistics)  28(1):20–28 
1979.

G. J. Klir and B. Yuan. Fuzzy Sets and Fuzzy Logic: Theory and Applications. Prentice-Hall  Inc. 

Upper Saddle River  NJ  USA  1995. ISBN 0-13-101171-5.

O. Madani  D. Pennock  and G. Flake. Co-Validation: Using Model Disagreement on Unlabeled Data

to Validate Classiﬁcation Algorithms. In Neural Information Processing Systems  2004.

T. Mitchell  W. W. Cohen  E. Hruschka Jr  P. Pratim Talukdar  J. Betteridge  A. Carlson  B. Dalvi 
M. Gardner  B. Kisiel  J. Krishnamurthy  N. Lao  K. Mazaitis  T. Mohamed  N. Nakashole  E. A.
Platanios  A. Ritter  M. Samadi  B. Settles  R. Wang  D. Wijaya  A. Gupta  X. Chen  A. Saparov 
M. Greaves  and J. Welling. Never-Ending Learning. In Association for the Advancement of
Artiﬁcial Intelligence  2015.

P. G. Moreno  A. Artés-Rodríguez  Y. W. Teh  and F. Perez-Cruz. Bayesian Nonparametric Crowd-

sourcing. Journal of Machine Learning Research  16  2015.

F. Niu  C. Ré  A. Doan  and J. Shavlik. Tuffy: Scaling up statistical inference in markov logic networks
using an rdbms. Proc. VLDB Endow.  4(6):373–384  Mar. 2011. ISSN 2150-8097. doi: 10.14778/
1978665.1978669. URL http://dx.doi.org/10.14778/1978665.1978669.

F. Parisi  F. Strino  B. Nadler  and Y. Kluger. Ranking and combining multiple predictors without

labeled data. Proceedings of the National Academy of Sciences  2014.

E. A. Platanios  A. Blum  and T. M. Mitchell. Estimating Accuracy from Unlabeled Data.

Conference on Uncertainty in Artiﬁcial Intelligence  2014.

In

E. A. Platanios  A. Dubey  and T. M. Mitchell. Estimating Accuracy from Unlabeled Data: A
Bayesian Approach. In International Conference on Machine Learning  pages 1416–1425  2016.

M. Richardson and P. Domingos. Markov Logic Networks. Mach. Learn.  62(1-2):107–136  2006.

D. Schuurmans  F. Southey  D. Wilkinson  and Y. Guo. Metric-Based Approaches for Semi-

Supervised Regression and Classiﬁcation. In Semi-Supervised Learning. 2006.

T. Tian and J. Zhu. Max-Margin Majority Voting for Learning from Crowds. In Neural Information

Processing Systems  2015.

L. Wehbe  B. Murphy  P. Talukdar  A. Fyshe  A. Ramdas  and T. Mitchell. Predicting brain activity

during story processing. in review  2014.

10

,Emmanouil Platanios
Hoifung Poon
Tom Mitchell
Eric Horvitz