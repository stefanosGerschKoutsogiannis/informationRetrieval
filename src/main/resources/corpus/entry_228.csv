2014,A Synaptical Story of Persistent Activity with Graded Lifetime in a Neural System,Persistent activity refers to the phenomenon that cortical neurons keep firing even after the stimulus triggering the initial neuronal responses is moved. Persistent activity is widely believed to be the substrate for a neural system retaining a memory trace of the stimulus information. In a conventional view  persistent activity is regarded as an attractor of the network dynamics  but it faces a challenge of how to be closed properly. Here  in contrast to the view of attractor  we consider that the stimulus information is encoded in a marginally unstable state of the network which decays very slowly and exhibits persistent firing for a prolonged duration. We propose a simple yet effective mechanism to achieve this goal  which utilizes the property of short-term plasticity (STP) of neuronal synapses. STP has two forms  short-term depression (STD) and short-term facilitation (STF)  which have opposite effects on retaining neuronal responses. We find that by properly combining STF and STD  a neural system can hold persistent activity of graded lifetime  and that persistent activity fades away naturally without relying on an external drive. The implications of these results on neural information representation are discussed.,A Synaptical Story of Persistent Activity with

Graded Lifetime in a Neural System

Yuanyuan Mi 

Luozheng Li

State Key Laboratory of Cognitive Neuroscience & Learning 

Beijing Normal University  Beijing 100875  China

miyuanyuan0102@163.com 

liluozheng@mail.bnu.edu.cn

State Key Laboratory of Cognitive Neuroscience & Learning 

School of System Science  Beijing Normal University Beijing 100875  China

Dahui Wang

wangdh@bnu.edu.cn

Si Wu

State Key Laboratory of Cognitive Neuroscience & Learning 

IDG/McGovern Institute for Brain Research 

Beijing Normal University  Beijing 100875  China

wusi@bnu.edu.cn

Abstract

Persistent activity refers to the phenomenon that cortical neurons keep ﬁring even
after the stimulus triggering the initial neuronal responses is moved. Persistent
activity is widely believed to be the substrate for a neural system retaining a mem-
ory trace of the stimulus information. In a conventional view  persistent activity is
regarded as an attractor of the network dynamics  but it faces a challenge of how
to be closed properly. Here  in contrast to the view of attractor  we consider that
the stimulus information is encoded in a marginally unstable state of the network
which decays very slowly and exhibits persistent ﬁring for a prolonged duration.
We propose a simple yet effective mechanism to achieve this goal  which utilizes
the property of short-term plasticity (STP) of neuronal synapses. STP has two
forms  short-term depression (STD) and short-term facilitation (STF)  which have
opposite effects on retaining neuronal responses. We ﬁnd that by properly combin-
ing STF and STD  a neural system can hold persistent activity of graded lifetime 
and that persistent activity fades away naturally without relying on an external
drive. The implications of these results on neural information representation are
discussed.

1 Introduction

Stimulus information is encoded in neuronal responses. Persistent activity refers to the phenomenon
that cortical neurons keep ﬁring even after the stimulus triggering the initial neural responses is
removed [1  2  3]. It has been widely suggested that persistent activity is the substrate for a neu-
ral system to retain a memory trace of the stimulus information [4]. For instance  in the classical
delayed-response task where an animal needs to memorize the stimulus location for a given pe-
riod of time before taking an action  it was found that neurons in the prefrontal cortex retained
high-frequency ﬁring during this waiting period  indicating that persistent activity may serve as the

1

neural substrate of working memory [2]. Understanding the mechanism of how persistent activity is
generated in neural systems has been at the core of theoretical neuroscience for decades [5  6  7].
In a conventional view  persistent activity is regarded as an emergent property of network dynamic-
s: neurons in a network are reciprocally connected with each other via excitatory synapses  which
form a positive feedback loop to maintain neural responses in the absence of an external drive; and
meanwhile a matched inhibition process suppresses otherwise explosive neural activities. Mathe-
matically  this view is expressed as the dynamics of an attractor network  in which persistent activity
corresponds to a stationary state (i.e.  an attractor) of the network. The notion of attractor dynamics
is appealing  which qualitatively describes a number of brain functions  but its detailed implementa-
tion in neural systems remains to be carefully evaluated.
A long-standing debate on the feasibility of attractor dynamics is on how to properly close the at-
tractor states in a network: once a neural system is evolved into a self-sustained active state  it will
stay there forever until an external force pulls it out. Solutions including applying a strong global in-
hibitory input to shut-down all neurons simultaneously  or applying a strong global excitatory input
to excite all neurons and force them to fall into the refractory period simultaneously  were suggest-
ed [9]  but none of them appears to be natural or feasible in all conditions. From the computational
point of view  it is also unnecessary for a neural system to hold a mathematically perfect attractor
state lasting forever. In reality  the brain only needs to hold the stimulus information for a ﬁnite
amount of time necessary for the task. For instance  in the delayed-response task  the animal only
needed to memorize the stimulus location for the waiting period [1].
To address the above issues  here we propose a novel mechanism to retain persistent activity in neu-
ral systems  which gives up the concept of prefect attractor  but rather consider that a neural system
is in a marginally unstable state which decays very slowly and exhibits persistent ﬁring for a pro-
longed period. The proposed mechanism utilizes a general feature of neuronal interaction  i.e.  the
short-term plasticity (STP) of synapses [10  11]. STP has two forms: short-term depression (STD)
and short-term facilitation (STF). The former is due to depletion of neurotransmitters after neural
ﬁring  and the latter is due to elevation of calcium level after neural ﬁring which increases the re-
lease probability of neurotransmitters. STD and STP have opposite effects on retaining prolonged
neuronal responses: the former weakens neuronal interaction and hence tends to suppress neuronal
activities; whereas  the latter strengthens neuronal interaction and tends to enhance neuronal activ-
ities. Interestingly  we ﬁnd that the interplay between the two processes endows a neural system
with the capacity of holding persistent activity with desirable properties  including: 1) the lifetime
of persistent activity can be arbitrarily long depending on the parameters; and 2) persistent activity
fades away naturally in a network without relying on an external force. The implications of these
results on neural information representation are discussed.

2 The Model

Without loss of generality  we consider a homogeneous network in which neurons are randomly and
sparsely connected with each other with a small probability p. The dynamics of a single neuron is
described by an integrate-and-ﬁre process  which is given by

= −(vi − VL) + Rmhi;

(cid:28)

dvi
dt

for i = 1 : : : N;

(1)

where vi is the membrane potential of the ith neuron and (cid:28) the membrane time constant. VL is the
resting potential. hi is the synaptic current and Rm the membrane resistance. A neuron ﬁres when
its potential exceeds the threshold  i.e.  vi > Vth  and after that vi is reset to be VL. N the number
of neurons.
The dynamics of the synaptic current is given by

dhi
dt

= −hi +

1
N p

(cid:28)s

(2)
where (cid:28)s is the synaptic time constant  which is about 2 ∼ 5ms. Jij is the absolute synaptic efﬁcacy
from neurons j to i. Jij = J0 if there is a connection from the neurons j to i  and Jij = 0 otherwise.
tsp
j denotes the spiking moment of the neuron j. All neurons in the network receive an external input

Jiju+
j x

);

j (cid:14)(t − tsp
−

j ) + I ext(cid:14)(t − text

i

∑

j

2

in the form of Poisson spike train. I ext represents the external input strength and text
of the Poisson spike train the neuron i receives.
The variables uj and xj measure  respectively  the STF and STD effects on the synapses of the jth
neuron  whose dynamics are given by [12  13]

the moment

i

(cid:28)f

(cid:28)d

(4)

duj
dt
dxj
dt

j )(cid:14)(t − tsp
= −uj + (cid:28)f U (1 − u
−
j );
= 1 − xj − (cid:28)du+
j (cid:14)(t − tsp
−
j x
j );
−
where uj is the release probability of neurotransmitters  with u+
j and u
j denoting  respectively 
the values of uj just after and just before the arrival of a spike. (cid:28)f is the time constant of STF.
−
U controls the increment of uj produced by a spike. Upon the arrival of a spike  u+
j +
j = u
U (1 − u
−
j and x
j denoting 
respectively  the values of xj just after and just before the arrival of a spike. (cid:28)d is the recover time
−
of neurotransmitters. Upon the arrival of a spike  x+
j . The time constants (cid:28)f and (cid:28)d
are typically in the time order of hundreds to thousands of milliseconds  much larger than (cid:28) and (cid:28)s 
that is  STP is a slow process compared to neural ﬁring.

−
j ). xj represents the fraction of available neurotransmitters  with x+

(3)

−
j = x
j

− u+
j x

2.1 Mean-ﬁeld approximation

As to be conﬁrmed by simulation  neuronal ﬁrings in the state of persistent activity are irregular and
largely independent to each other. Therefore  we can assume that the responses of individual neurons
are statistically equivalent in the state of persistent activity. Under this mean-ﬁeld approximation 
the dynamics of a single neuron  and so does the mean activity of the network  can be written as [7]

(cid:28)s

(cid:28)f

(cid:28)d

dh
dt
du
dt
dx
dt

= −h + J0uxR + I;
= −u + (cid:28)f U (1 − u)R;
= 1 − x − (cid:28)duxR;

(5)

(6)

(7)

where the state variables are the same for all neurons. R is the ﬁring rate of a neuron  which is also
the mean activity of the neuron ensemble. I = I ext(cid:21) denotes the external input with (cid:21) the rate of
the Poisson spike train. The exact relationship between the ﬁring rate R and the synaptic input h is
difﬁcult to obtain. Here  we assume it to be of the form 

R = max((cid:12)h; 0);

(8)

with (cid:12) a positive constant.

3 The Mechanism

By using the mean-ﬁeld model  we ﬁrst elucidate the working mechanism underlying the generation
of persistent activity of ﬁnite lifetime. Later we carry out simulation to conﬁrm the theoretical
analysis.

3.1 How to generate persistent activity of ﬁnite lifetime

For the illustration purpose  we only study the dynamics of the ﬁring rate R and assume that the
variables u and x reach to their steady values instantly. This approximation is in general inaccurate 
since u and x are slow variables compared to R. Nevertheless  it gives us insight into understanding
the network dynamics.
By setting du=dt = 0 and dx=dt = 0 in Eqs.(6 7) and substituting them into Eqs.(5 8)  we get that 
for I = 0 and R ≥ 0 

= −R +

(cid:28)s

dR
dt

J0(cid:12)(cid:28)f U R2

1 + (cid:28)f U R + (cid:28)d(cid:28)f U R2

≡ F (R):

(9)

3

Figure 1: The steady states of the network  i.e.  the solutions of Eq.(9)  have three forms depending
on the parameter values. The three lines correspond to the different neuronal connection strenghths 
which are J0 = 4; 4:38; 5  respectively. The other parameters are: (cid:28)s = 5ms; (cid:28)d = 100ms; (cid:28)f =
700ms; (cid:12) = 1; U = 0:05 and Jc = 4:38.

(

√

)

Deﬁne a critical connection strength Jc ≡
=(cid:12)  which is the point the network
dynamics experiences saddle-node bifurcation (see Figure 1). Depending on the parameters  the
steady states of the network have three forms

(cid:28)d=((cid:28)f U )

1 + 2

• When J0 < Jc  F (R) = 0 has only one solution at R = 0  i.e.  the network is only stable
at the silent state;
• When J0 > Jc  F (R) = 0 has three solutions  and the network can be stable at the silent
state and an active state;
• When J0 = Jc  F (R) = 0 has two solutions  one is the stable silent state  and the other is
a neutral stable state  referred to as R

∗.

−
The interesting behavior occurs at J0 = J
c   i.e.  J0 is slightly smaller than the critical connection
strength Jc. In this case  the network is only stable at the silent state. However  since near to the
∗  F (R) is very close to zero (and so does |dR=dt|)  the decay of the network activity is very
state R
∗  under the
slow in this region (Figure 2A). Suppose that the network is initially at a state R > R
∗
network dynamics  the system will take a considerable amount of time to pass through the state R
before reaching to silence. This is manifested by that the decay of the network activity exhibits a
∗ before dropping to silence rapidly (Figure 2B). Thus  persistent activity of
long plateau around R
ﬁnite lifetime is achieved.
The lifetime of persistent activity  which is dominated by the time of the network state passing
through the point R

∗  is calculated to be (see Appendix A) 

(10)
) = d2F (R)=d2R|R(cid:3). By varying the STP effects  such as (cid:28)d and (cid:28)f   the value of
) is changed  and the lifetime of persistent activity can be adjusted.

F (R∗)F ′′(R∗)

;

where F
)F
F (R

∗

′′
′′

∗
∗

(R
(R

√

T ∼

2(cid:28)s

3.2 Persistent activity of graded lifetime

We formally analyze the condition for the network holding persistent activity of ﬁnite lifetime.
Inspired by the result in the proceeding section  we focus on the parameter regime of J0 = Jc  i.e. 
the situation when the network has the stable silent state and a neutral stable active state.
Denote (R
dynamics at this point  we obtain

) to be the neutral stable state of the network at J0 = Jc. Linearizing the network

; u

; x

∗

∗

∗

;

(11)

(

d
dt

R − R
∗
u − u∗
x − x∗

)

R − R
∗
u − u∗
x − x
∗

)

(

≃ A

4

0RF(R) J0<JcJ0>JcJ0=JcR*−
c  
Figure 2: Persistent activity of ﬁnite lifetime. Obtained by solving Eqs.(5-8). (A) When J0 = J
∗. Around this point  the
the function F (R)  and so does dR=dt  is very close to zero at the state R
∗. (B) An
network activity decays very slowly. The inset shows the ﬁne structure in the vicinity of R
external input (indicated by the red bar) triggers the network response. After removing the external
input  the network activity ﬁrst decays quickly  and then experiences a long plateau before dropping
to silence rapidly. The parameters are: (cid:28)s = 5ms; (cid:28)d = 10ms; (cid:28)f = 800ms; (cid:12) = 1; U = 0:5 
I = 10  Jc = 1:316 and J0 = 1:315.

∗

∗

; x

; u

where A is the Jacobian matrix (see Appendix B).
It turns out that the matrix A always has one eigenvector with vanishing eigenvalue  a property due to
∗
) is the neutral stable state of the network dynamics. As demonstrated in Sec.3.1  by
that (R
−
c   we expect that the network state will decay very slowly along the eigenvector of
choosing J0 = J
vanishing eigenvalue  which we call the decay-direction. To ensure this always happens  it requires
that the real parts of the other two eigenvalues of A are negative  so that any perturbation of the
network state away from the decay-direction will be pulled back; otherwise  the network state may
approach to silence rapidly via other routes avoiding the state (R
). This idea is illustrated
in Fig.3.
The condition for the real parts of the other two eigenvalues of A being smaller than zero is calcu-
lated to be (see Appendix B):

; u

; x

∗

∗

∗

√

√

1

2

(cid:28)f (cid:28)d

+

1
(cid:28)d

1

+

U
(cid:28)f (cid:28)d
−
c form the condition for the network holding persistent activity

(cid:28)f U
(cid:28)d

(12)

(cid:28)d(cid:28)s

> 0:

1 +

− 1
(cid:28)f (cid:28)s

This inequality together with J0 = J
of ﬁnite lifetime.

Figure 3: Illustration of the slow-decaying process of the network activity. The network dynamics
experiences a long plateau before dropping to silence quickly. The inset presents a 3-D view of the
local dynamics in the plateau region  where the network state is attracted to the decay-direction to
ensure slow-decaying.

By solving the network dynamics Eqs.(5-8)  we calculate how the lifetime of persistent activity
changes with the STP effect. Fig.4A presents the results of ﬁxing U and J0 and varying (cid:28)d and

5

0RF(R)R*0AB02468R*t(s)R(Hz)tRR*3-D viewDecay-direction(cid:28)f   We see that below the critical line J0 = Jc  which is the region for J0 > Jc  the network has
prefect attractor states never decaying; and above the critical line  the network has only the stable
silent state. Close to the critical line  the network activity decays slowly and displays persistent
activity of ﬁnite lifetime. Fig.4B shows a case that when the STF strength ((cid:28)f ) is ﬁxed  the lifetime
of persistent activity decreases with the STD strength ((cid:28)d). This is understandable  since STD tends
to suppress neuronal responses. Fig.4C shows a case that when (cid:28)d is ﬁxed  the lifetime of persistent
activity increases with (cid:28)f   due to that STF enhances neuronal responses. These results demonstrate
that by regulating the effects of STF and STD  the lifetime of persistent activity can be adjusted.

Figure 4: (A). The lifetimes of the network states with respect to (cid:28)f and (cid:28)d when U and J0 are ﬁxed.
We use an external input to trigger a strong response of the network and then remove the input. The
lifetime of a network state is measured from the offset of the external input to the moment when the
network returns to silence. The white line corresponds to the condition of J0 = Jc  below which
the network has attractors lasting forever; and above which  the lifetime of a network state gradually
decreases (coded by colour). (B) When (cid:28)f = 1250ms is ﬁxed  the lifetime of persistent activity
decreases with (cid:28)d (the vertical dashed line in A). (C) When (cid:28)d = 260ms is ﬁxed  the lifetime of
persistent activity increases with (cid:28)f (the horizontal dashed line in A). The other parameters are:
(cid:28)s = 5ms  (cid:12) = 1  U = 0:05 and J0 = 5.

4 Simulation Results

We carry out simulation with the spiking neuron network model given by Eqs.(1-4) to further conﬁrm
the above theoretical analysis. A homogenous network with N = 1000 neurons is used  and in the
network neurons are randomly and sparsely connected with each other with a probability p = 0:1.
At the state of persistent activity  neurons ﬁre irregularly (the mean value of Coefﬁcient of Variation
is 1.29)and largely independent to each other(the mean correlation of all spike train pairs is 0.30)
with each other (Fig.5A). Fig.5 present the examples of the network holding persistent activity with
varied lifetimes  through different combinations of STF and STD satisfying the condition Eq.(12).

5 Conclusions

In the present study  we have proposed a simple yet effective mechanism to generate persistent
activity of graded lifetime in a neural system. The proposed mechanism utilizes the property of STP 
a general feature of neuronal synapses  and that STF and STD have opposite effects on retaining
neuronal responses. We ﬁnd that with properly combined STF and STD  a neural system can be in a
marginally unstable state which decays very slowly and exhibits persistent ﬁring for a ﬁnite lifetime.
This persistent activity fades away naturally without relying on an external force  and hence avoids
the difﬁculty of closing an active state faced by the conventional attractor networks.
STP has been widely observed in the cortex and displays large diversity in different region-
s [14  15  16]. Compared to static ones  dynamical synapses with STP greatly enriches the response
patterns and dynamical behaviors of neural networks  which endows neural systems with informa-
tion processing capacities which are otherwise difﬁcult to implement using purely static synapses.
The research on the computational roles of STP is receiving increasing attention in the ﬁeld [12]. In

6

00.511.50510τd (s)Decay time (s)00.511.50510τf (s)Decay time (s)attractorABCFigure 5: The simulation results of the spiking neural network. (A) A raster plot of the responses of
50 example neurons randomly chosen from the network. The external input is applied for the ﬁrst
0.5 second. The persistent activity lasts about 1100ms. The parameters are: (cid:28)f = 800ms; (cid:28)d =
500ms; U = 0:5; J0 = 28:6. (B) The ﬁring rate of the network for the case (A). (C) An example
of persistent activity of negligible lifetime. The parameters are:(cid:28)f = 800ms; (cid:28)d = 1800ms; U =
0:5; J0 = 28:6. (D) An example of persistent activity of around 400ms lifetime. The parameters
are:(cid:28)f = 600ms; (cid:28)d = 500ms; U = 0:5; J0 = 28:6. (E) An example of the network holding an
attractor lasting forever. The parameters are: (cid:28)f = 800ms; (cid:28)d = 490ms; U = 0:5; J0 = 28:6.

terms of information presentation  a number of appealing functions contributed by STP were pro-
posed. For instances  Mongillo et al. proposed an economical way of using the facilitated synapses
due to STF to realize working memory in the prefrontal cortex without recruiting neural ﬁring [8];
Pﬁster et al. suggested that STP enables a neuron to estimate the membrane potential information
of the pre-synaptic neuron based on the spike train it receives [17]. Torres et al. found that STD
induces instability of attractor states in a network  which could be useful for memory searching [18];
Fung et al. found that STD enables a continuous attractor network to have a slow-decaying state in
the time order of STD  which could serve for passive sensory memory [19]. Here  our study reveals
that through combining STF and STD properly  a neural system can hold stimulus information for
an arbitrary time  serving for different computational purposes. In particular  STF tends to increase
the lifetime of persistent activity; whereas  STD tends to decrease the lifetime of persistent activity.
This property may justify the diverse distribution of STF and STD in different cortical regions. For
instances  in the prefrontal cortex where the stimulus information often needs to be held for a long
time in order to realize higher cognitive functions  such as working memory  STF is found to be
dominating; whereas  in the sensory cortex where the stimulus information will be forwarded to
higher cortical regions shortly  STD is found to be dominating. Furthermore  our ﬁndings suggest
that a neural system may actively regulate the combination of STF and STD  e.g.  by applying ap-
propriate neural modulators [10]  so that it can hold the stimulus information for a ﬂexible amount
of time depending on the actual computational requirement. Further experimental and theoretical
studies are needed to clarify these interesting issues.

6 Acknowledgments

This work is supported by grants from National Key Basic Research Program of China
(NO.2014CB846101)  and National Foundation of Natural Science of China (No.11305112  Y.Y.M.;
No.31261160495  S.W.; No.31271169 D.H.W.)  and the Fundamental Research Funds for the cen-
tral Universities (No.31221003  S.W.)  and SRFDP (No.20130003110022  S.W)  and Natural Sci-
ence Foundation of Jiangsu Province BK20130282.

7

ABCDEAppendix A: The lifetime of persistent activity

∗

) is slightly smaller than zero (Fig.2A). Starting from a state R > R

Consider the network dynamics Eq.(9). When J0 = Jc  the network has a stable silent state (R = 0)
−
and an unstable active state  referred to as R
c . In this case 
∗  the network will take
F (R
∗  since dR=dt is very small in this region  and
a considerable amount of time to cross the point R
the network exhibits persistent activity for a considerable amount of time. We estimate the time
∗.
consuming for the network crossing the point R
According to Eq.(9)  we have

∗ (Fig.1). We consider that J0 = J

T∫

dt =

0

=

=

(cid:3)

R

+∫
√
√

(cid:3)
(cid:0)

R

dR ≈

(cid:28)s

F (R)

2(cid:28)s

2(cid:28)s

F (R∗)F ′′(R∗)

F (R∗)F ′′(R∗)

(cid:3)

R

+∫
[

(cid:3)
(cid:0)

R

∗

);

G(R

(cid:28)sdR

F (R∗) + (R − R∗)2F ′′(R∗)=2
√

− R

− arctg

∗
+

R

F (R∗)=F ′′(R∗)

∗

;

√

arctg

− − R
∗

∗

R

F (R∗)=F ′′(R∗)

]

;

(13)

∗
− denote  respectively  the points slightly larger or smaller than R

(R)=dR|R(cid:3). To get the above result  we used the second-order

∗  F

) = dF

) =

(R

∗

′

′

∗  and the condition F

′

∗

(R

) = 0.

∗
+ and R

∗

′′

where R
dF (R)=dR|R(cid:3)  and F
Taylor expansion of F (R) at R
∗
In the limit of F (R
is in the order of

(R

) → 0  the value of G(R
√

T ∼

∗

) is bounded. Thus  the lifetime of persistent activity

2(cid:28)s

F (R∗)F ′′(R∗)

:

(14)

Appendix B: The condition for the network holding persistent activity of ﬁnite
lifetime

) to be the neutral stable state of the network when J0 = Jc  which is calculated

∗

∗

Denote (R
to be (by solving Eqs.(5-8)) 

; x

; u

∗

√

∗

R

=

1=(cid:28)f (cid:28)dU ; u

∗

=

∗

(cid:28)f U R
1 + (cid:28)f U R∗ ; x

∗

=

∗

1 + (cid:28)f U R

1 + (cid:28)f U R∗ + (cid:28)f (cid:28)dU R∗2 :
)

(

Linearizing the network dynamics at this point  we obtain Eq.(12)  in which the Jacobian matrix A
is given by

∗ − 1)=(cid:28)s;
∗
x
(J0u
U (1 − u
∗
−u
∗
∗
x

);

∗

∗
=(cid:28)s;
R
J0x
−1=(cid:28)f − U R
∗
−x
∗
∗

R

;

∗
∗
=(cid:28)s
J0u
−1=(cid:28)d − u
∗

R
0

A =

(16)
The eigenvalues of the Jacobian matrix satisfy the equality |A − (cid:21)I| = 0. Utilizing Eqs.(15)  this
equality becomes

R

∗

;

;

:

(cid:21)((cid:21)2 + b(cid:21) + c(cid:21)) = 0;

(15)

(17)

where the coefﬁcients b and c are given by

b =

c =

1
(cid:28)d

+

1
(cid:28)f

+ u

√

∗

∗

R

+ U R

∗

;

2

(cid:28)f (cid:28)d

+

1
(cid:28)d

U
(cid:28)f (cid:28)d

+

1

(cid:28)d(cid:28)s

1 +

√

1

− 1
(cid:28)f (cid:28)s

:

(cid:28)f U
(cid:28)d

(18)

(19)

From Eq.(17)  we see that the matrix A has three eigenvalues. One eigenvalue  referred to as (cid:21)1  is
always zero. The other two eigenvalues satisfy that (cid:21)2 + (cid:21)3 = −b and (cid:21)2(cid:21)3 = c. Since b > 0  the
condition for the real parts of (cid:21)2 and (cid:21)3 being negative is c > 0.

8

References
[1] J. Fuster and G. Alexander. Neuron activity related to short-term memory. Science 173  652-

654 (1971).

[2] S. Funahashi  C. J. Bruce and P.S. Goldman-Rakic. Mnemonic coding of visual space in the

monkeys dorsolateral prefrontal cortex. J. Neurophysiol. 61  331-349 (1989).

[3] R. Romo  C. D. Brody  A. Hernandez. Lemus L. Neuronal correlates of parametric working

memory in the prefrontal cortex. Nature 399  470-473 (1999).

[4] D.J. Amit. Modelling brain function. New York: Cambridge University Press. (1989)
[5] S. Amari. Dynamics of pattern formation in lateral-inhibition type neural ﬁelds. Biol. Cybern.

27  77-87 (1977).

[6] X.J. Wang. Synaptic basis of cortical persistent activity: the importance of NMDA receptors

to working memory. J. Neurosci. 19  9587-9603 (1999).

[7] O. Barak and M. Tsodyks. Persistent Activity in Neural Networks with Dynamic Synapses.

PLoS Computational Biology.3(2): e35(2007).

[8] G. Mongillo  O. Barak and M. Tsodyks. Synaptic theory of working memory. Science

319 1543-1546(2008).

[9] B. Gutkin  C. Laing  C. Colby  C. Chow  and B. Ermentrout. Turning on and off with excitation:
the role of spike-timing asynchrony and synchrony in sustained neural activity. J. Comput.
Neurosci. 11  121C134 (2001).

[10] H. Markram and M. Tsodyks. Redistribution of synaptic efﬁcacy between neocortical pyrami-

dal neurons. Nature. 382(6594): 807-810(1996).

[11] L. F. Abbott and W. G. Regehr. Synaptic computation. Nature. 431(7010): 796-803(2004).
[12] M. Tsodyks and S. Wu. Short-Term Synaptic Plasticity. Scholarpedia  8(10): 3153(2013).
[13] M. Tsodyks  K. Pawelzik and H. Markram. Neural Networks with Dynamic Synapses. Neural

Computation. 10(4): 821-835(1998).

[14] H. Markram  Y. Wang and M. Tsodyks. Differential signaling via the same axon of neocor-
tical pyramidal neurons. Proceedings of the National Academy of Sciences. 95(9): 5323-
5328(1998).

[15] J. S. Dittman  A. C. Kreitzer and W. G. Regehr. Interplay between facilitation  depression  and

residual calcium at three presynaptic terminals. J. Neurosci. 20: 1374-1385(2000).

[16] Y. Wang  H. Markram  P. H. Goodman  T. K. Berger  J. Y. Ma and P. S. Goldman-Rakic.
Heterogeneity in the pyramidal network of the medial prefrontal cortex. Nature Neuroscience.
9(4): 534-542(2006).

[17] J. P. Pﬁster  P. Dayan and M. Lengyel. Synapses with short-term plasticity are optimal estima-

tors of presynaptic membrane potentials. Nature Neuroscience 13 1271-1275(2010).

[18] J.J. Torres  J. M. Cortes  J. Marro and H. J. Kappen. Competition Between Synaptic Depression
and Facilitation in Attractor Neural Networks. Neural Computation. 19(10): 2739-2755(2007).
[19] C. C. Fung  K. Y. Michael Wong  H. Wang and S. Wu. Dynamical Synapses Enhance Neural In-
formation Processing: Gracefulness  Accuracy and Mobility. Neural Computation 24(5):1147-
1185(2012).

9

,Yuanyuan Mi
Luozheng Li
Dahui Wang
Si Wu
Francisco Ruiz
Michalis Titsias RC AUEB
David Blei