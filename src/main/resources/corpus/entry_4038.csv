2018,Online Improper Learning with an Approximation Oracle,We study the following question: given an efficient approximation algorithm for an optimization problem  can we learn efficiently in the same setting? We give a formal affirmative answer to this question in the form of a reduction from online learning to offline approximate optimization using an efficient algorithm that guarantees near optimal regret. The algorithm is efficient in terms of the number of oracle calls to a given approximation oracle – it makes only logarithmically many such calls per iteration. This resolves an open question by Kalai and Vempala  and by Garber. Furthermore  our result applies to the more general improper learning problems.,Online Improper Learning with an Approximation

Oracle⇤

Elad Hazan

Princeton University & Google AI Princeton

ehazan@cs.princeton.edu

Wei Hu

Princeton University

huwei@cs.princeton.edu

Yuanzhi Li

Stanford University

yuanzhil@stanford.edu

Zhiyuan Li

Princeton University

zhiyuanli@cs.princeton.edu

Abstract

We study the following question: given an efﬁcient approximation algorithm for an
optimization problem  can we learn efﬁciently in the same setting? We give a formal
afﬁrmative answer to this question in the form of a reduction from online learning
to ofﬂine approximate optimization using an efﬁcient algorithm that guarantees
near optimal regret. The algorithm is efﬁcient in terms of the number of oracle calls
to a given approximation oracle – it makes only logarithmically many such calls
per iteration. This resolves an open question by Kalai and Vempala  and by Garber.
Furthermore  our result applies to the more general improper learning problems.

1

Introduction

A fundamental question in learning theory is whether one can efﬁciently learn a given problem using
an optimization oracle. Namely  does efﬁcient ofﬂine optimization for a certain problem imply
efﬁcient learning algorithm for the same setting?
For online learning in games  it was shown by Kalai and Vempala (2005) that an optimization oracle
giving the best decision in hindsight is sufﬁcient for attaining optimal regret. However  in many
non-convex settings  such an optimization oracle is either unavailable or NP-hard to compute. In the
face of NP-hardness  algorithm designers resort to approximation algorithms that are guaranteed to
return a solution within a certain multiplicative factor of the optimum. We give numerous examples
in Section 1.2.
Kakade et al. (2009) considered the question of whether such an approximation algorithm is sufﬁcient
to obtain vanishing regret compared with an approximation to the best solution in hindsight. They
gave an algorithm for this ofﬂine-to-online conversion. However  their reduction is inefﬁcient in
the number of per-iteration queries to the approximation oracle  which grows linearly with time.
Ideally  an efﬁcient reduction should call the oracle only a constant number of times per iteration and
guarantee optimal regret at the same time  and this was considered an open question in the literature.
Various authors have improved upon this original online-to-ofﬂine reduction under certain cases 
as we survey below. Recently  Garber (2017) made signiﬁcant progress by giving a more efﬁcient
reduction  which improves the number of oracle calls in both full information and bandit settings. He
explicitly asked whether a near-optimal reduction with only logarithmically many calls per iteration
exists.

⇤The full version of this paper can be found on https://arxiv.org/abs/1804.07837.

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

1.1 Problem Setting and Our Results
In this paper we resolve this question on the positive side and in a more general setting  which we
formally deﬁne now.

Formal description of problem setting. We consider the standard setting of online linear opti-
mization which is known to generalize statistical learning (Hazan  2016; Shalev-Shwartz  2012). In a
repeated game  in round t a player chooses a point xt from a decision set K✓ Rd while an adversary
chooses a loss vector ft 2 Rd  which determines the loss of the player f>t xt in this round. The loss
vector ft is revealed to the player after her choice xt is made. We sometimes treat ft as a function on
Rd  i.e.  ft(x) := f>t x.
Since we consider computationally intractable problems like maximum cut or minimum-rank matrix
completion  we assume that the player has access to an ofﬂine optimization oracle. This oracle may
return a point which does not belong to the target set K⇤  but rather to a different set K. For example 
in matrix completion the oracle may return a low-trace-norm matrix rather than a low-rank matrix.
This notion is formally captured by an optimization oracle OK K⇤. Given an input v 2 Rd  this oracle
outputs a point OK K⇤(v) 2K which dominates all points in K⇤ in the direction v  that is

v>OK K⇤(v)  min
x⇤2K⇤
The goal for the player is to minimize her regret  which is the difference between her cumulative loss
and that of the best single decision (in K⇤) in hindsight:

v>x⇤.

RegK K⇤(T ) :=

TXt=1

f>t xt  min
x⇤2K⇤

f>t x⇤.

TXt=1

We remark that the above problem setting is similar in spirit to the notion of improper learning  where
one is allowed to output a hypothesis not from the target set. Therefore  we view the problem setting
described above as an online version of improper learning.
In the special case of K⇤ = ↵K (↵> 1)  OK ↵K becomes an ↵-approximation oracle on K  and the
setting and the notation of regret are the same with those studied in (Kakade et al.  2009; Garber 
2017)  i.e.  RegK ↵K(T ) :=PT

t=1 f>t xt  ↵ minx2KPT

Our results.
In this setting  we give two different algorithms  one based on the online mirror
descent (OMD) method and another based on the continuous multiplicative weight update (CMWU)
algorithm. Both of them give nearly optimal regret as well as oracle efﬁciency  while applying to
general loss vectors. Our results are summarized in Table 1 below. We present these two algorithms
and their guarantees in Sections 3 and Appendix B.

t=1 f>t x. This is called the ↵-regret.

Regret over T rounds Oracle calls per round

Algorithm

Kakade et al. (2009)

Garber (2017)

Alg. 1 (this paper)
Alg. 6 (this paper)

O(pT )
O(pT )
O(pT )
˜O(pT )

O(T )
˜O(pT )
O(log T )
O(log T )

Loss vectors

general

non-negative

PNIP property (Def. 2.4)

general

Table 1: Summary of results in the full information setting. The ˜O notation hides constant and
logarithmic factors.

Algorithm

Regret over T rounds Oracle calls in T rounds

Loss vectors

Kakade et al. (2009)

Garber (2017)

Alg. 3 (this paper)

O(T 2
3 )
O(T 2
3 )
O(T 2
3 )

O(T 4
3 )
˜O(T )
˜O(T 2
3 )

general

non-negative
non-negative

Table 2: Summary of results in the bandit setting.

In addition to these two algorithms  we give an improved result in the bandit setting. In this more
difﬁcult setting  the player cannot observe ft  but rather only the loss she has suffered  namely the

2

scalar f>t xt. We show how to extend our mirror descent-based algorithm to the bandit setting and
obtain the same O(T 2/3) regret as in (Kakade et al.  2009; Garber  2017)  but with a signiﬁcantly
lower computational cost. See Table 2 for a comparison. We present our bandit result in Section 4.

1.2 Applications

The setting of online learning with approximation algorithms has been well studied since (Kalai and
Vempala  2005) with numerous applications.
For example  in the online max-cut problem  a learner iteratively predicts a cut over a set of vertices
V   and afterwards the adjacency information for two vertices is revealed. The loss is zero or one 
depending on whether the learner correctly predicted the connectivity of the two vertices. The
ofﬂine version of this problem is NP-hard  but admits SDP-based approximation algorithms such
as the famous 0.878-approximation by Goemans and Williamson (1995). Our results imply an
online algorithm that can predict as accurate as the best 0.878-approximation to the maximum cut in
hindsight  and calls the SDP relaxation only logarithmically many times per iteration.
Numerous other examples exist for combinatorial graph optimization problems such as the traveling
salesman problem  sparsest graph cut  etc. Other applications include prominent machine learning
problems whose ofﬂine optimization problem is NP-hard  for example  matrix completion and
recommendation systems. The reader is referred to (Kakade et al.  2009; Garber  2017) for more
detailed exposition of applications.

1.3 Related Work

The reduction from online learning to ofﬂine approximation algorithms was already considered
by Kalai and Vempala (2005). Their scheme  based on the follow-the-perturbed-leader (FTPL)
algorithm  requires very strong approximation guarantee from the approximation oracle  namely  a
fully polynomial time approximation scheme (FPTAS)  and requires an approximation that improves
with time. Balcan and Blum (2006) used the same approach in the context of mechanism design.
Kalai and Vempala (2005) also proposed a specialized reduction that works under certain conditions
on the approximation oracle  satisﬁed by some known algorithms for problems such as MAX-CUT.
Fujita et al. (2013) further gave more general reductions that apply to problems whose approximation
algorithms are based on convex relaxations of mathematical programs. Their scheme is also based on
the FTPL method.
Recent advancements on black-box online-to-ofﬂine reductions were made in (Kakade et al.  2009;
Dudík et al.  2016; Garber  2017). Hazan and Koren (2016) showed that efﬁcient reductions are
in general impossible  unless special structure is present. In the settings we consider this special
structure is a linear cost function over the space.
Our algorithms fall into one of two templates. The ﬁrst is the online mirror descent method  which
is an adaptive version of the follow-the-regularized-leader (FTRL) algorithm. The second is the
continuous multiplicative weight update method  which dates back to Cover’s portfolio selection
method (Cover  1991) and Vovk’s aggregating algorithm (Vovk  1990). The reader is referred to
the books (Cesa-Bianchi and Lugosi  2006; Shalev-Shwartz  2012; Hazan  2016) for details and
background on these prediction frameworks. We also make use of polynomial-time algorithms for
sampling from log-concave distributions (Lovász and Vempala  2007).

2 Preliminaries

For x 2 Rd and r > 0  denote by B(x  r) the Euclidean ball in Rd of radius r centered at x.For
S S0 ✓ Rd   2 R  y 2 Rd and A 2 Rd0⇥d  deﬁne S + S0 := {x + x0 : x 2S   x0 2S 0} 
S := {x : x 2S}   x + S := {x + y : y 2S}   and AS := {Ax : x 2S} . The convex hull of
S✓ Rd is denoted by CH(S). Denote by Vol(S) the volume (Lebesgue measure) of a set S✓ Rd.
Denote by k1 the probability simplex in Rk.
A set C✓ Rd is called a cone if for any   0 we have C✓C . For any S✓ Rd  deﬁne the dual
cone of S as S :=y 2 Rd : x>y  0  8x 2S . S is always a convex cone  even when S is

3

Algorithm 1 Online Mirror Descent using a Projection-and-Separation Oracle
Input: Learning rate ⌘> 0  tolerance ✏> 0  regularizer '  convex cone W   time horizon T 2 N+
1: y1 arg miny2Dom(') '(y).
2: for t = 1 to T do
3:
4:
5: r'(yt+1) r'(xt)  ⌘ft
6: end for

(xt  V = (v1  . . .   vk)  p) PAD (yt ✏  W ' )
Play ˜xt = vi with probability pi (i 2 [k])  and observe the loss vector ft.

neither convex nor a cone. For any closed set S✓ Rd  deﬁne ⇧S : Rd !S to be the projection onto
S  namely ⇧S(x) := arg minx02S kx0  xk2.
Deﬁnition 2.1. A strictly convex function f : A! R (A✓ Rd is convex) is Legendre if rf is
continuous in int(A) and for any sequence x1  x2 ··· 2 A converging to a boundary point of A 
limn!1 krf (xn)k = 1.
Deﬁnition 2.2. For a Legendre function ' : A! R  the Bregman divergence with respect to ' is
deﬁned as D'(x  y) := '(x)  '(y)  r'(y)>(x  y) (8x  y 2A ).
Lemma 2.3 (Generalized Pythagorean theorem  see e.g. Lemma 11.3 in (Cesa-Bianchi and Lugosi 
2006)). For any closed convex set S✓ Rd  x 2 Rd  y 2S   and any Legendre function ' : Rd ! R 
letting z = arg minx02S D'(x0  x)  we must have D'(y  x)  D'(y  z) + D'(z  x).
Deﬁnition 2.4 (Pairwise non-negative inner product). For a twice-differentiable Legendre function
' : A! R with domain A✓ Rd and a convex cone W ✓ Rd  we say ('  W ) satisﬁes the
pairwise non-negative inner product (PNIP) property  if for all w  w0 2 W and H 2 CH(H)  where
H = {r2'(x) : x 2A}   it holds that w>H1w0  0.
Examples. ('  W ) satisﬁes the PNIP property if:

1. '(x) = 1

2kxk2  x 2 Rd and W ✓ W   such as the non-negative orthant Rd

+  the positive

semideﬁnite matrix cone  and the Lorentz cone Ld+1 = {(x  z) 2 Rd ⇥ R : kxk2  z}.
2. '(x) =Pd

i=1 xi(log xi  1) (with domain Rd
2 x>Q1x (with domain Rd)  where Q = M M>  M 2 Rd⇥d is an invertible

+) and W = Rd
+;

3. '(x) = 1

matrix  and W = (M>)1Rd
+.

This is useful in our bandit algorithm in Section 4.

Log-concave distributions. A distribution over Rd with a density function f is log-concave if
log(f ) is a concave function. For a convex set S equipped with a membership oracle  there exist
polynomial-time algorithms for sampling from any log-concave distribution over S (Lovász and
Vempala  2007). This can be used to approximately compute the mean of any log-concave distribution.
For ease of presentation  we will assume that we can compute the mean of bounded-supported log-
concave distributions exactly. Detailed explanation is provided in Appendix D.

3 Mirror Descent with an Approximation Oracle

In this section  we give an efﬁcient online improper linear optimization algorithm (Algorithm 1) in
the full information setting based on online mirror descent (OMD) equipped with a strongly convex
regularizer '  which achieves O(pT ) regret when the regularizer ' and the domain of linear loss
functions W satisfy the pairwise non-negative inner product (PNIP) property (Deﬁnition 2.4).
We suppose K K⇤ ✓ B(0  R)  and the loss vectors {ft} come from a convex cone W ✓ Rd and
kftk  L (R  L > 0). Omitted proofs in this section are given in Appendix A.
Theorem 3.1. Suppose ('  W ) satisﬁes the PNIP property (Deﬁnition 2.4). Then for any ✏  ⌘ > 0 
Algorithm 1 satisﬁes the following regret guarantee:

8x⇤ 2K ⇤ : E" TXt=1

(ft(˜xt)  ft(x⇤))# 

1

⌘ '(x⇤)  '(y1) +

D'(xt  yt+1)! + ✏LT.

TXt=1

4

In particular  if ' is µ-strongly convex and A  maxx⇤2K⇤('(x⇤)  '(y1))  setting ✏ = R
⌘ = 1

T and

T   we have

Lq 2µA

8x⇤ 2K ⇤ : E" TXt=1

(ft(˜xt)  ft(x⇤))#  Ls 2AT
Rq A

µ

+ LR 

and in this case  Algorithm 1 makes at mostl5d log⇣⇣6pT + 4

round.

µ + 4⌘ T⌘m calls of OK K⇤ per

For the problem of ↵-regret minimization using an ↵-approximation oracle  we have the following
regret guarantee  which is an immediate corollary of Theorem 3.1.
Corollary 3.2. If W ✓ Rd
+  K✓ B(0  R)  K⇤ = ↵K  '(x) = 1
2kxk2  setting ✏ = ↵R
Algorithm 1 has the following regret guarantee:
TXt=1

ft(↵x⇤)#  ↵LR(pT + 1).

8x⇤ 2K : E" TXt=1

ft(x⇤)# = E" TXt=1

T   ⌘ = ↵R
LpT

ft(˜xt)  ↵

ft(˜xt) 

TXt=1

 

Algorithm 1 is a variant of the OMD algorithm that makes use of a projection-and-decomposition
(PAD) oracle  deﬁned as follows:
Deﬁnition 3.3 (Projection-and-decomposition oracle). A projection-and-decomposition (PAD) oracle
onto K⇤  PAD(y  ✏  W  ' )  is deﬁned as a procedure that given y 2 Rd  ✏> 0  a convex cone W
and a Legendre function ' produces a tuple (y0  V  p)  where y0 2 Rd  V = (v1  . . .   vk) 2 Rd⇥k
and p = (p1  . . .   pk)> 2 k1  such that:

i=1 pivi + c  y0k  ✏.

1. y0 is “closer” to K⇤ than y with respect to the Bregman divergence of ' (and hence is an
“infeasible projection”): 8x⇤ 2K ⇤  D'(x⇤  y0)  D'(x⇤  y);
2. v1  . . .   vk 2K   andPk
W . In other words  there exists c 2 W  such that kPk

i=1 pivi is a point that “almost dominates” y0 in all directions in

The purpose of the PAD oracle is the following. Suppose the OMD algorithm tells us to play a point
y. Since y might not be in the feasible set K  we can call the PAD oracle to ﬁnd another point y0 as
well as a distribution p over points v1  . . .   vk 2K . The ﬁrst property in Deﬁnition 3.3 is sufﬁcient to
ensure that playing y0 also gives low regret  and the second property further ensures that we have a
distribution of points in K that suffers less loss than y0 for every possible loss function so we can play
according to that distribution.
Assuming the availability of a PAD oracle  one can use a standard analysis of OMD to prove a regret
bound for Algorithm 1 as in Theorem 3.1. The proof is given in Appendix A.
Next we show how to construct a PAD oracle using the optimization oracle OK K⇤. Our construction
is given in Algorithm 2. Theorem 3.4 gives its guarantee.
Theorem 3.4. Suppose ('  W ) satisﬁes PNIP condition (Deﬁnition 2.4) and ' is µ-strongly convex.
⇡
Then for any y 2 Rd ✏ 2 (0  R]  Algorithm 2 terminates in⇠5d log 4R+2p2 minx⇤2K⇤ D'(x⇤ y)/µ
iterations  and it correctly implements the projection-and-decomposition oracle PAD(y  ✏  W  ' ) 
i.e.  its output (y0  V  p) satisﬁes the two properties in Deﬁnition 3.3.
Remark. We can use random walk methods to compute an 1
T -approximation of the gravity center
(line 3 in Algorithm 2) in poly(T ) time  which is enough for the purpose of bounding regret. We
can also replace the center of gravity method with the ellipsoid method  or any other optimization
method with a similar “optimization interface” (i.e.  any method that is based on separation queries
and guarantees similar bounds on the number of iterations required to ﬁnd a feasible point)  as
pointed out by Garber (2017). Speciﬁcally  using the ellipsoid method  we can signiﬁcantly reduce
the computational complexity to depend only polynomially in log T (rather than T )  at the cost of
a slightly higher oracle complexity  namely O(d2 log T ) calls to the oracle per round. We choose
center of gravity over other optimization methods only because it has the best oracle complexity 
which is the main focus of this paper.

✏

5

Algorithm 2 Projection-and-Decomposition Oracle  PAD(y  ✏  W  ' )
Input: Point y 2 Rd  tolerance ✏> 0  convex cone W   regularizer ' 
Output: (y0  V  p)  where y0 2 Rd  V = (v1  . . .   vk) 2 Rd⇥k for some k such that vi 2K
(8i 2 [k])  and p = (p1  . . .   pk)> 2 k1
1: W1 W \ B(0  1) 
i 0
2: while i < 5d log 2(R+kzi+1k)
i i + 1  wi RWi
wdw
3:
4:
zi+1 
5: end while
6: k i and solve
7: return y0 = zk+1  V = (v1  . . .   vk)  p

D'(z  zi)  Wi+1 Wi \{ w 2 Rd : w>(vi  zi+1)  0}.

p2k1 c2W  kPk

i=1 pivi + c  zk+1k to get p

z1 y 
do
Vol(Wi)  

vi O K K⇤(wi).

z2Rd w>i (zvi)0

arg min

min

✏

We break the proof of Theorem 3.4 into several lemmas.
Lemma 3.5. If ('  W ) satisﬁes the PNIP condition (Deﬁnition 2.4)  then z1  . . .   zk+1 computed in
Algorithm 2 satisfy zi+1  zi 2 W  for all i 2 [k].
Proof. Since we have zi+1 =

D'(z  zi)  by the KKT condition  we have

arg min

z2Rd:w>i (zvi)0

0 =

@

@z D'(z  zi)  w>i (z  vi)z=zi+1

= r'(zi+1)  r'(zi)  wi

✏

⇡ iterations.

for some   0. On the other hand  note that r'(zi+1)  r'(zi) =R 1
0 r2'(zi+1 + (1  )zi) ·
(zi+1  zi)d = H(zi+1  zi)  for some H 2 CH(H)  where H = r2'(x) : x 2 Dom(') .
Therefore  for all w 2 W we have w>(zi+1  zi) = w>H1H(zi+1  zi) = w>H1wi  0.
This means zi+1  zi 2 W .
Lemma 3.6. Under the setting of Theorem 3.4  Algorithm 2 terminates in at most
⇠5d log 4R+2p2 minx⇤2K⇤ D'(x⇤ y)/µ
Proof. According to the algorithm  for each i  zi+1 is the Bregman projection of zi onto a half-
space containing K⇤  since the oracle OK K⇤ ensures w>i vi  w>i x⇤ for all x⇤ 2K ⇤. Then by
the generalized Pythagorean theorem (Lemma 2.3) we know D'(x⇤  zi+1)  D'(x⇤  zi) for all
x⇤ 2K ⇤ and i. Therefore we have D'(x⇤  zi)  D'(x⇤  z1) = D'(x⇤  y) for all x⇤ 2K ⇤ and i.
Let P := minx⇤2K⇤ D'(x⇤  y). Then there exists x⇤ 2K ⇤ such that P = D'(x⇤  y) 
D'(x⇤  zi)  µ
2kx⇤  zik2 for all i  where the last inequality is due to the µ-strong convexity of '.
µ for all i. Therefore  when i  5d log 4R+2p2P/µ
This implies kzik  kx⇤k +q 2P
 
we must have i  5d log 2(R+kzi+1k)
Lemma 3.7. Under Theorem 3.4’s setting  8w 2 W kwk = 1  9i 2 [k]  such that w>(vi  y0)  ✏.
Proof. We assume for contradiction that there exists a unit vector h 2 W such that mini2[k] h>(vi 
y0) >✏ . Note that kvi  y0k  kvik + ky0k  R + ky0k. Letting r :=
2(R+ky0k)  we have
8w 2 h
2 +(W\B(0  1/2)) ✓ W\B(0  1) = W1. By
Since r  1
the algorithm  we know that for all w 2 W1\ Wk+1  there exists i 2 [k] such that w>(vi zi+1)  0.
Notice that from Lemma 3.5 we know zj+1  zj 2 W  for all j 2 [k]. Thus for all w 2 W1 \ Wk+1
there exists i 2 [k] such that w>(vi  y0) = w>(vi  zk+1)  wT (vi  zi+1)  0. In other words 
we have 8w 2 W1 \ Wk+1 : mini2[k] w>(vi  y0)  0.

✏
  which means the loop must have terminated at this time.

2 + (W \ B(0  r)) : mini2[k] w>(vi  y0) > 0.

µ  R +q 2P

2 for ✏  R  we have h

2 +(W\B(0  r)) ✓ h

✏

✏

6

2 + (W \ B(0  r)) ✓ Wk+1. We also have Vol(Wi+1)  (1 
Therefore  we must have h
1/(2e))Vol(Wi) for each i 2 [k] from Lemma D.2  since Wi+1 is the intersection of Wi with
a half-space that does not contain Wi’s centroid wi in the interior. Then we have

Vol(W1) = Vol(W \ B(0  1)) = rdVol(W \ B(0  r))  rdVol(Wk+1)

 rd(1  1/(2e))kVol(W1) < Vol(W1) 

= 5d log 2(R+kzk+1k)
where the last step is due to k  5d log 1
according to the termination condition of the loop. Therefore we have a contradiction.

r = 5d log 2(R+ky0k)

✏

✏

  which is true

The following lemma is a more general version of Lemma 6 in (Garber  2017).
Lemma 3.8. Given v1  . . .   vk 2 Rd  ✏  0 and a convex cone W 2 Rd  for any x 2 Rd  the
following two statements are equivalent:
(A) There exists p = (p1  . . .   pk)> 2 k1 and c 2 W  such that kPk
(B) For all w 2 W   kwk = 1  there exists i 2 [k] such that w>(vi  x)  ✏.

i=1 pivi + c  xk  ✏.

W

W 

CH(V ) + W 

⇧F (x)

x0

v4

x

v1

CH(V )

v3

v2

(a) Convex cone W and its dual cone W 

(b) An example for CH(V ) + W   where V =
{vi}4

i=1.

Figure 1: Geometric Interpretation of Lemma 3.8.

Geometric interpretation of Lemma 3.8. We defer the proof of Lemma 3.8 to Appendix A  and
discuss its geometric intuition here. For simplicity of illustration  we only consider ✏ = 0 here
(Figure 1). First we look at the case where W = Rd  W  = {0}. In this case the lemma simply
degenerated to the fact

x 2 CH({vi}k

i=1) () There is no hyperplane that separates x and all vi’s.

In the general case where W ✓ Rd is an arbitrary convex cone  lemma 3.8 becomes

x 2 CH({vi}k

i=1) + W  () There is no direction w 2 W such that w>x < w>vi for all i.

i=1) + W . For the “)” side  if x 2 F   it is clear that for all w 2 W we
Denote F := CH({vi}k
must have w>x  w>vi for some i. For the “(” side  if x /2 F   then w =⇧ F (x)  x satisﬁes
w>x < w>vi for all i. Moreover it is easy to see ⇧F (x)  x 2 W   which completes the proof.
Theorem 3.4 can be proved now using the above lemmas.

Proof of Theorem 3.4. The upper bound on the number of iterations is proved in Lemma 3.6. In the
proof of Lemma 3.6  we have shown D'(x⇤  zi+1)  D'(x⇤  zi) for all x⇤ 2K ⇤ and i. This implies
D'(x⇤  y0) = D'(x⇤  zk+1)  D'(x⇤  zk) ··· D'(x⇤  z1) = D'(x⇤  y) for all x⇤ 2K ⇤ 
which veriﬁes the ﬁrst property in Deﬁnition 3.3. The second property is a direct consequence of
combining Lemmas 3.7 and 3.8.

7

Algorithm 3 Online Stochastic Mirror Descent with Barycentric Regularization
Input: Learning rate ⌘> 0  tolerance ✏> 0  {q1  . . .   qd} - a -BS(K) for some > 0  exploration
1: Instantiate Algorithm 1 with parameters ⌘  ✏  '(x) = 1
2: for t = 1 to T do
3:

probability  2 (0  1)  time horizon T 2 N+

Receive ˜xt (the point to play in round t) from Algorithm 1

2 x>Q1x  W 0 = (M>)1Rd

+  and T

if bt = EXPLORE then

bt ⇢EXPLORE  with probability 
EXPLOIT  with probability 1  
Sample it 2 [d] uniformly at random  and play qit
Receive loss lt = q>it ft
˜ft d
else
Play ˜xt and receive loss lt = ˜x>t ft
˜ft 0
end if
Feed ˜ft to Algorithm 1 as the loss vector for round t (Note that when ˜ft = 0  in the next round
Algorithm 1 can simply play according to the distribution computed in this round without any
oracle calls.)

 ltQ1qit

4:

5:
6:
7:
8:
9:
10:
11:
12:
13:

14: end for

4 ↵-Regret Minimization in the Bandit Setting

In this section we consider the ↵-regret minimization problem in the bandit setting  where W = Rd
+ 
+ \ B(0  R) and K⇤ = ↵K. Suppose the loss vectors {ft} come from Rd and kftk  L.
K✓ Rd
Similar to (Kakade et al.  2009)  we assume we know a -barycentric spanner for K. This concept
was ﬁrst introduced by Awerbuch and Kleinberg (2004).
Deﬁnition 4.1 (Barycentric spanner). A set of d linearly independent vectors {q1  . . .   qd}⇢ Rd is
a -barycentric spanner for a set K⇢ Rd  denoted by -BS(K)  if {q1  . . .   qd}✓K and for all
x 2K   there exist 1  . . .   d 2 [   ] such that x =Pd
Given {q1  . . .   qd} which is a -BS(K)  deﬁne Q :=Pd
q>i Q2qi  .

i=1 iqi.
i=1 qiq>i and M := (q1  . . .   qd) 2 Rd⇥d.
The need for a new regularization. The bandit algorithm of Garber (2017) additionally requires
a certain boundedness property of barycentric spanners  namely:

However  for certain bounded sets this quantity may be unbounded  such as the two-dimensional axis-
aligned rectangle with one axis being of size unity  and the other arbitrarily small. This unboundedness
creates problems with the unbiased estimator of loss vector  whose variance can be as large as certain
geometric properties of the decision set. To circumvent this issue  we design a new regularizer called
barycentric regularizer  which gives rise to an unbiased estimator coupled with an online mirror
descent variant that automatically ensures constant variance.
Similar to (Kakade et al.  2009; Garber  2017)  our bandit algorithm also simulates the full information
algorithm with estimated loss vectors. Namely  our algorithm implements Algorithm 1 with a speciﬁc
barycentric regularizer '(x) = 1
2 x>Q1x. The algorithm is detailed in Algorithm 3  and its regret
guarantee is given in Theorem 4.2. We prove Theorem 4.2 in Appendix C.
Theorem 4.2. Denote by zt the point played by Algorithm 3 in round t.
Suppose we set ⌘ = ↵4/3
Then we have

T 1/3 in Algorithm 3 (assuming T > 2d3 so < 1).

T and  = 2/3d

LRT 2/3   ✏ = ↵R

max
i2[d]

8x⇤ 2K : E" TXt=1

(ft(zt)  ↵ft(x⇤))#  ↵LR⇣3d(T )2/3 + 1⌘  

and the expected total number of oracle calls to OK ↵K in T rounds is at most Od2(T )2/3 log T.

8

5 Conclusion and Open Problems

We have described two different algorithmic approaches to reducing regret minimization to ofﬂine
approximation algorithms and maintaining optimal regret and poly-logarithmic oracle complexity per
iteration  resolving previously stated open questions.
An intriguing open problem remaining is to ﬁnd an efﬁcient algorithm in the bandit setting that
guarantees both ˜O(pT ) regret and poly(log T ) oracle complexity per iteration (at least on average).

References
Awerbuch  B. and Kleinberg  R. D. (2004). Adaptive routing with end-to-end feedback: Distributed
learning and geometric approaches. In Proceedings of the thirty-sixth annual ACM symposium on
Theory of computing  pages 45–53. ACM.

Balcan  M.-F. and Blum  A. (2006). Approximation algorithms and online mechanisms for item
pricing. In Proceedings of the 7th ACM Conference on Electronic Commerce  pages 29–35. ACM.
Cesa-Bianchi  N. and Lugosi  G. (2006). Prediction  learning  and games. Cambridge university

press.

Cover  T. M. (1991). Universal portfolios. Mathematical Finance  1(1):1–29.
Dudík  M.  Haghtalab  N.  Luo  H.  Schapire  R. E.  Syrgkanis  V.  and Vaughan  J. W. (2016).

Oracle-efﬁcient online learning and auction design. arXiv preprint arXiv:1611.01688.

Fujita  T.  Hatano  K.  and Takimoto  E. (2013). Combinatorial online prediction via metarounding.

In International Conference on Algorithmic Learning Theory  pages 68–82. Springer.

Garber  D. (2017). Efﬁcient online linear optimization with approximation algorithms. In Advances

in Neural Information Processing Systems  pages 627–635.

Goemans  M. X. and Williamson  D. P. (1995). Improved approximation algorithms for maximum

cut and satisﬁability problems using semideﬁnite programming. J. ACM  42(6):1115–1145.

Hazan  E. (2016).

Optimization  2(3-4):157–325.

Introduction to online convex optimization. Foundations and Trends R in

Hazan  E. and Koren  T. (2016). The computational power of optimization in online learning. In
Proceedings of the forty-eighth annual ACM symposium on Theory of Computing  pages 128–141.
ACM.

Kakade  S. M.  Kalai  A. T.  and Ligett  K. (2009). Playing games with approximation algorithms.

SIAM Journal on Computing  39(3):1088–1106.

Kalai  A. and Vempala  S. (2005). Efﬁcient algorithms for online decision problems. Journal of

Computer and System Sciences  71(3):291–307.

Lovász  L. and Vempala  S. (2007). The geometry of logconcave functions and sampling algorithms.

Random Structures & Algorithms  30(3):307–358.

Prékopa  A. (1973). On logarithmic concave measures and functions. Acta Scientiarum Mathemati-

carum  34:335–343.

Shalev-Shwartz  S. (2012). Online learning and online convex optimization. Foundations and
Trends R in Machine Learning  4(2):107–194.
Vovk  V. G. (1990). Aggregating strategies. In Proceedings of the Third Annual Workshop on

Computational Learning Theory  COLT ’90  pages 371–386.

9

,Elad Hazan
Wei Hu
Yuanzhi Li
Zhiyuan Li