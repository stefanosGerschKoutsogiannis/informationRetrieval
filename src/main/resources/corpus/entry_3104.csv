2013,Learning the Local Statistics of Optical Flow,Motivated by recent progress in natural image statistics  we use newly available datasets with ground truth optical flow to learn the  local statistics of optical flow and rigorously compare the learned model to prior models assumed by computer vision optical flow algorithms.  We find that a Gaussian mixture model with 64 components provides a significantly better model for local flow statistics when compared to commonly used models. We investigate the source of the GMMs success and show it is related to an explicit representation of flow boundaries. We also learn a model that jointly models the local intensity pattern and the local optical flow. In accordance with the assumptions often made in computer vision  the model learns that flow boundaries are more likely at intensity boundaries. However  when evaluated on a large dataset  this dependency is very weak and the benefit of conditioning flow estimation on the local intensity pattern is marginal.,Learning the Local Statistics of Optical Flow

Dan Rosenbaum1  Daniel Zoran2  Yair Weiss1 2
1 CSE   2 ELSC   Hebrew University of Jerusalem
{danrsm daniez yweiss}@cs.huji.ac.il

Abstract

Motivated by recent progress in natural image statistics  we use newly available
datasets with ground truth optical ﬂow to learn the local statistics of optical ﬂow
and compare the learned models to prior models assumed by computer vision
researchers. We ﬁnd that a Gaussian mixture model (GMM) with 64 components
provides a signiﬁcantly better model for local ﬂow statistics when compared to
commonly used models. We investigate the source of the GMM’s success and
show it is related to an explicit representation of ﬂow boundaries. We also learn
a model that jointly models the local intensity pattern and the local optical ﬂow.
In accordance with the assumptions often made in computer vision  the model
learns that ﬂow boundaries are more likely at intensity boundaries. However 
when evaluated on a large dataset  this dependency is very weak and the beneﬁt of
conditioning ﬂow estimation on the local intensity pattern is marginal.

1

Introduction

Sintel MPI

KITTI

Figure 1: Samples of frames and ﬂows from new ﬂow databases. We leverage these newly available
resources to learn the statistics of optical ﬂow and compare this to assumptions used by computer
vision researchers.

The study of natural image statistics is a longstanding research topic with both scientiﬁc and engi-
neering interest. Recent progress in this ﬁeld has been achieved by approaches that systematically
compare different models of natural images with respect to numerical criteria such as log likelihood
on held-out data or coding efﬁciency [1  10  14]. Interestingly  the best models in terms of log like-
lihood  when used as priors in image restoration tasks  also yield state-of-the-art performance [14].
Many problems in computer vision require good priors. A notable example is the computation of
optical ﬂow: a vector at every pixel that corresponds to the two dimensional projection of the motion

1

at that pixel. Since local motion information is often ambiguous  nearly all optical ﬂow estimation
algorithms work by minimizing a cost function that has two terms: a local data term and a “prior”
term (see. e.g. [13  11] for some recent reviews).
Given the success in image restoration tasks  where learned priors give state-of-the-art performance 
one might expect a similar story in optical ﬂow estimation. However  with the notable exception
of [9] (which served as a motivating example for this work and is discussed below) there have been
very few attempts to learn priors for optical ﬂow by modeling local statistics. Instead  the state-of-
the-art methods still use priors that were formulated by computer vision researchers. In fact  two
of the top performing methods in modern optical ﬂow benchmarks use a hand-deﬁned smoothness
constraint that was suggested over 20 years ago [6  2].
One big difference between image statistics and ﬂow statistics is the availability of ground truth
data. Whereas for modeling image statistics one merely needs a collection of photographs (so that
the amount of data is essentially unlimited these days)  for modeling ﬂow statistics one needs to
obtain the ground truth motion of the points in the scene. In the past  the lack of availability of
ground truth data did not allow for learning an optical ﬂow prior from examples. In the last two
years  however  two ground truth datasets have become available. The Sintel dataset (ﬁgure 1)
consists of a thousand pairs of frames from a highly realistic computer graphics ﬁlm with a wide
variety of locations and motion types. Although it is synthetic  the work in [3] convincingly show
that both in terms of image statistics and in terms of ﬂow statistics  the synthetic frames are highly
similar to real scenes. The KITTI dataset (ﬁgure 1) consists of frames taken from a vehicle driving
in a European city [5]. The vehicle was equipped with accurate range ﬁnders as well as accurate
localization of its own motion  and the combination of these two sources allow computing optical
ﬂow for points that are stationary in the world. Although this is real data  it is sparse (only about
50% of the pixels have ground truth ﬂow).
In this paper we leverage the availability of ground truth datasets to learn explicit statistical models
of optical ﬂow. We compare our learned model to the assumptions made by computer vision algo-
rithms for estimating ﬂow. We ﬁnd that a Gaussian mixture model with 64 components provides a
signiﬁcantly better model for local ﬂow statistics when compared to commonly used models. We
investigate the source of the GMM’s success and show that it is related to an explicit representation
of ﬂow boundaries. We also learn a model that jointly models the local intensity pattern and the
local optical ﬂow. In accordance with the assumptions often made in computer vision  the model
learns that ﬂow boundaries are more likely at intensity boundaries. However  when evaluated on a
large dataset  this dependency is very weak and the beneﬁt of conditioning ﬂow estimation on the
local intensity pattern is marginal.

1.1 Priors for optical ﬂow

One of the earliest methods for optical ﬂow that is still used in applications is the celebrated Lucas-
Kanade algorithm [7]. It overcomes the local ambiguity of motion analysis by assuming that the
optical ﬂow is constant within a small image patch and ﬁnds this constant motion by least-squares
estimation. Another early algorithm that is still widely used is the method of Horn and Schunck [6].
It ﬁnds the optical ﬂow by minimizing a cost function that has a data term and a “smoothness” term.
Denoting by u the horizontal ﬂow and v the vertical ﬂow  the smoothness term is of the form:

(cid:88)

x y

JHS =

u2
x + u2

y + v2

x + v2
y

where ux  uy are the spatial derivatives of the horizontal ﬂow u and vx  vy are the spatial derivatives
of the vertical ﬂow v. When combined with modern optimization methods  this algorithm is often
among the top performing methods on modern benchmarks [11  5].
Rather than using a quadratic smoothness term  many authors have advocated using more robust
terms that would be less sensitive to outliers in smoothness. Thus the Black and Anandan [2] algo-
rithm uses:

(cid:88)

JBA =

ρ(ux) + ρ(uy) + ρ(vx) + ρ(vy)

where ρ(t) is a function that grows slower than a quadratic. Popular choices for ρ include the
Lorentzian  the truncated quadratic and the absolute value ρ(x) = |x| (or a differentiable approxi-
mation to it ρ(x) =
 + x2)[11]. Both the Lorentzian and the absolute value robust smoothness

√

x y

2

terms were shown to outperform quadratic smoothness in [11] and the absolute value was better
among the two robust terms.
Several authors have also suggested that the smoothness term be based on the local intensity pattern 
since motion discontinuities are more likely to occur at intensity boundaries. Ren [8] modiﬁed
the weights in the Lucas and Kanade least-squares estimation so that pixels that are on different
sides of an intensity boundary will get lower weights. In the context of Horn and Shunck  several
authors suggest using weights to the horizontal and vertical ﬂow derivatives  where the weights had
an inverse relationship with the image derivatives: large image derivatives lead to low weight in the
ﬂow smoothness (see [13] and references within for different variations on this idea). Perhaps the
simplest such regularizer is of the form:

(cid:88)

JHSI =

w(Ix)(u2

x + v2

x) + w(Iy)(u2

y + v2
y)

(1)

x y

As we discuss below  this prior can be seen as a Gaussian prior on the ﬂow that is conditioned on
the intensity.
In contrast to all the previously discussed priors  Roth and Black [9] suggested learning a prior from
a dataset. They used a training set of optical ﬂow obtained by simulating the motion of a camera in
natural range images. The prior learned by their system was similar to a robust smoothness prior 
but the ﬁlters are not local derivatives but rather more random-looking high pass ﬁlters. They did not
observe a signiﬁcant improvement in performance when using these ﬁlters  and standard derivative
ﬁlters are still used in most smoothness based methods.
Given the large number of suggested priors  a natural question to ask is: what is the best prior to use?
One way to answer this question is to use these priors as a basis for an optical ﬂow estimation algo-
rithm and see which algorithm gives the best performance. Although such an approach is certainly
informative it is difﬁcult to get a deﬁnitive answer using it. For example  Sun et al. [11] reported that
adding a non-local smoothness term to a robust smoothness prior signiﬁcantly improved results on
the Middlebury benchmark  while Geiger et al. [5] reported that this term decreased performance on
KITTI benchmark. Perhaps the main difﬁculty with this approach is that the prior is only one part of
an optical ﬂow estimation algorithm. It is always combined with a non-convex likelihood term and
optimized using a nonlinear optimization algorithm. Often the parameters of the optimization have
a very large inﬂuence on the performance of the algorithm.
In this paper we take an alternative approach. Motivated by recent advances in natural image statis-
tics and the availability of new datasets  we compare different priors in terms of (1) log likelihood
on held-out data and (2) inference performance with tractable posteriors. Our results allow us to
rigorously compare different prior assumptions.

2 Comparing priors as density models

In order to compare different prior models as density models  we generate a training set and test
set of optical ﬂow patches from the ground truth databases. Denoting by f a single vector that
concatenates all the optical ﬂow in a patch (e.g. if we consider 8 × 8 patches  f is a vector of length
128 where the ﬁrst 64 components denote u and the last 64 components denote v). Given a prior
probability model Pr(f ; θ) we use the training set to estimate the free parameters of the model θ and
then we measure the log likelihood of held out patches from the test set.
From Sintel  we divided the pairs of frames for which ground truth is available into 708 pairs which
we used for training and 333 pairs which we used for testing. The data is divided into scenes and we
made sure that different scenes are used in training and testing. We created a second test set from
the KITTI dataset by choosing a subset of patches for which full ground truth ﬂow was available.
Since we only consider full patches  this set is smaller and hence we use it only for testing  not for
training.
The priors we compared are:

• Lucas and Kanade. This algorithm is equivalent to the assumption that the observed ﬂow is
generated by a constant (u0  v0) that is corrupted by IID Gaussian noise. If we also assume

3

pOOt + σ2

that u0  v0 have a zero mean Gaussian distribution  Pr(f ) is a zero mean multidimensional
nI where O is a binary 128 × 2 matrix and
Gaussian with covariance given by σ2
σp the standard deviation of u0  v0 and σn the standard deviation of the noise.
• Horn and Schunck. By exponentiating JHS we see that Pr(f ; θ) is a multidimensional
Gaussian with covariance matrix λDDT where D is a 256 × 128 derivative matrix that
computes the derivatives of the ﬂow ﬁeld at each pixel and λ is the weight given to the
prior relative to the data term. This covariance matrix is not positive deﬁnite  so we use
λDDT + I and determine λ   using maximum likelihood.
• L1. We exponentiate JBA and obtain a multidimensional Laplace distribution. As in Horn
and Schunck  this distribution is not normalizeable so we multiply it by an IID Laplacian
prior on each component with variance 1/. This again gives two free parameters (λ  )
which we ﬁnd using maximum likelihood. Unlike the Gaussian case  the solution of the
ML parameters and the normalization constant cannot be done in closed form  and we use
Hamiltonian Annealed Importance Sampling [10].

• Gaussian Mixture Models (GMM). Motivated by the success of GMMs in modeling natural
image statistics [14] we use the training set to estimate GMM priors for optical ﬂow. Each
mixture component is a multidimensional Gaussian with full covariance matrix and zero
mean and we vary the number of components between 1 and 64. We train the GMM using
the standard Expectation-Maximization (EM) algorithm using mini-batches. Even with a
few mixture components  the GMM has far more free parameters than the previous models
but note that we are measuring success on held out patches so that models that overﬁt
should be penalized.

The summary of our results are shown in ﬁgure 2 where we show the mean log likelihood on the
Sintel test set. One interesting thing that can be seen is that the local statistics validate some as-
sumptions commonly used by computer vision researchers. For example  the Horn and Shunck
smoothness prior is as good as the optimal Gaussian prior (GMM1) even though it uses local ﬁrst
derivatives. Also  the robust prior (L1) is much better than Horn and Schunck. However  as the num-
ber of Gaussians increase the GMM is signiﬁcantly better than a robust prior on local derivatives.
A closer inspection of our results is shown in ﬁgure 3. Each ﬁgure shows the histogram of log like-
lihood of held out patches: the more shifted the histogram is to the right  the better the performance.
It can be seen that the GMM is indeed much better than the other priors including cases where the
test set is taken from KITTI (rather than Sintel) and when the patch size is 12× 12 rather than 8× 8.

Figure 2: mean log likelihood of the different models for 8 × 8 patches extracted from held out data
from Sintel. The GMM outperforms the models that are assumed by computer vision researchers.

2.1 Comparing models using tractable inference

A second way of comparing the models is by their ability to restore corrupted patches of optical
ﬂow. We are not claiming that optical ﬂow restoration is a real-world application (although using
priors to “ﬁll in” holes in optical ﬂow is quite common  e.g. [12  8]). Rather  we use it because
for the models we are discussing the inference can either be done in closed form or using convex
optimization  so we would expect that better priors will lead to better performance.
We perform two ﬂow restoration tasks. In “ﬂow denoising” we take the ground truth ﬂow and add
IID Gaussian noise to all ﬂow vectors. In “ﬂow inpainting” we add a small amount of noise to all

4

LKHSL1GMM1GMM2GMM4GMM8GMM16GMM64012345Modelslog-likelihoodSintel

KITTI

8
×
8

p
a
t
c
h
e
s

1
2
×
1
2

p
a
t
c
h
e
s

Figure 3: Histograms of log-likelihood of different models on the KITTI and Sintel test sets with
two different patch sizes. As can be seen  the GMM outperforms other models in all four cases.

ﬂow vectors and a very big amount of noise to some of the ﬂow vectors (essentially meaning that
these ﬂow vectors are not observed). For the Gaussian models and the GMM models the Bayesian
Least Squares (BLS) estimator of f given y can be computed in closed form. For the Laplacian
model  we use MAP estimation which leads to a convex optimization problem. Since MAP may be
suboptimal for this case  we optimize the parameters λ   for MAP inference performance.
Results are shown in ﬁgures 4 5. The standard deviation of the ground truth ﬂow is approximately
11.6 pixels and we add noise with standard deviations 10  20 and 30 pixel. Consistent with the
log likelihood results  L1 outperforms the Gaussian methods but is outperformed by the GMM. For
small noise values the difference between L1 and the GMM is small  but as the amount of noise
increases L1 becomes similar in performance to the Gaussian methods and is much worse than the
GMM.

3 The secret of the GMM

We now take a deeper look at how the GMM models optical ﬂow patches. The ﬁrst (and not surpris-
ing) thing we found is that the covariance matrices learned by the model are block diagonal (so that
the u and v components are independent given the assignment to a particular component).
More insight can be gained by considering the GMM as a local subspace model: a patch which
is generated by component k is generated as a linear combination of the eigenvectors of the kth
covariance. The coefﬁcients of the linear combination have energy that decays with the eigenvalue:
so each patch can be well approximated by the leading eigenvectors of the corresponding covariance.
Unlike global subspace models  different subspace models can be used for different patches  and
during inference with the model one can infer which local subspace is most likely to have generated
the patch.
Figure 6 shows the dominant leading eigenvectors of all 32 covariance matrices in the GMM32
model: the eigenvectors of u are followed by the eigenvectors of v. The number of eigenvectors
displayed in each row is set so that they capture 99% of the variance in that component. The rows
are organized by decreasing mixing weight. The right hand half of each row shows (u v) patches
that are sampled from that Gaussian.

5

−200−150−100−500−15−10−50log-likelihoodlog(fractionofpatches)  LKHSL1GMM64−6−4−202−10−8−6−4−20log-likelihoodlog(fractionofpatches)  LKHSL1GMM64−200−150−100−500−15−10−50log-likelihoodlog(fractionofpatches)  LKHSL1GMM64−6−4−202−8−6−4−20log-likelihoodlog(fractionofpatches)  LKHSL1GMM64Denoising: σ = 10

σ = 20

σ = 30

Inpainting: 2 × 2

4 × 4

6 × 6

Figure 4: Denoising with different noise values and inpainting with different hole sizes.

Figure 5: Visualizing denoising performance (σ = 30).

It can be seen that the ﬁrst 10 components or so model very smooth components (in fact the samples
appear to be completely ﬂat). A closer examination of the eigenvalues shows that these ten com-
ponents correspond to smooth motions of different speeds. This can also be seen by comparing the
v samples on the top row which are close to gray with those in the next two rows which are much
closer to black or white (since the models are zero mean  black and white are equally likely for any
component).
As can be seen in the ﬁgure  almost all the energy in the ﬁrst components is captured by uniform
motions. Thus these components are very similar to a non-local smoothness assumption similar to
the one suggested in [11]): they not only assume that derivatives are small but they assume that all
the 8 × 8 patch is constant. However  unlike the suggestion in [11] to enforce non-local smoothness
by applying a median ﬁlter at all pixels  the GMM only applies non-local smoothness at a subset of
patches that are inferred to be generated by such components.
As we go down in the ﬁgure towards more rare components. we see that the components no longer
model ﬂat components but rather motion boundaries. This can be seen both in the samples (rightmost
rows) and also in the leading eigenvectors (shown on the left) which each control one side of a
boundary. For example  the bottom row of the ﬁgure illustrates a component that seems to generate
primarily diagonal motion boundaries.
Interestingly  such local subspace models of optical ﬂow have also been suggested by Fleet et al. [4].
They used synthetic models of moving occlusion boundaries and bars to learn linear subspace mod-
els of the ﬂow. The GMM seems to support their intuition that learning separate linear subspace
models for ﬂat vs motion boundary is a good idea. However  unlike the work of Fleet et al.
the
separation into “ﬂat” vs. “motion boundary” was learned in an unsupervised fashion directly from
the data.

6

20406080100−10−8−6−4−2PSNRlog(fractionofpatches)  LKHSL1GMM6420406080100−10−8−6−4−2PSNRlog(fractionofpatches)  LKHSL1GMM6420406080100−10−8−6−4−2PSNRlog(fractionofpatches)  LKHSL1GMM6420406080100−10−8−6−4−2PSNRlog(fractionofpatches)  LKHSL1GMM6420406080100−10−8−6−4−2PSNRlog(fractionofpatches)  LKHSL1GMM6420406080100−10−8−6−4−20PSNRlog(fractionofpatches)  LKHSL1GMM64leading eigenvectors

patch samples

u

v

u

v

Figure 6: The eigenvectors and samples of the GMM components. GMM is better because it explic-
itly models edges and ﬂat patches separately.

4 A joint model for optical ﬂow and intensity

As mentioned in the introduction  many authors have suggested modifying the smoothness assump-
tion by conditioning it on the local intensity pattern and giving a higher penalty for motion discon-
tinuities in the absence of intensity discontinuities. We therefore ask  does conditioning on the local
intensity give better log likelihood on held out ﬂow patches? Does it give better performance in
tractable inference tasks?
We evaluated two ﬂow models that are conditioned on the local intensity pattern. The ﬁrst one is a
conditional Gaussian (eq. 1) with exponential weights  i.e. w(Ix) = exp(−I 2
x/σ2) and the variance
parameter σ2 is optimized to maximize performance. The second one is a Gaussian mixture model
that simultaneously models both intensity and ﬂow.
The simultaneous GMM we use includes a 200 component GMM to model the intensity together
with a 64 dimensional GMM to model the ﬂow. We allow a dependence between the hidden variable
of the intensity GMM and that of the ﬂow GMM. This is equivalent to a hidden Markov model
(HMM) with 2 hidden variables: one represents the intensity component and one represents the
ﬂow component (ﬁgure 8). We learn the HMM using the EM algorithm.
Initialization is given
by independent GMMs learned for the intensity (we actually use the one learned by [14] which is
available on their website) and for the ﬂow. The intensity GMM is not changed during the learning.
Conditioned on the intensity pattern  the ﬂow distribution is still a GMM with 64 components (as in
the previous section) but the mixing weights depend on the intensity.
Given these two conditional models  we now ask: will the conditional models give better perfor-
mance than the unconditional ones? The answer  shown in ﬁgure 7 was surprising (to us). Condi-
tioning on the intensity gives basically zero improvement in log likelihood and a slight improvement
in ﬂow denoising only for very large amounts of noise. Note that for all models shown in this ﬁgure 
the denoised estimate is the Bayesian Least Squares (BLS) estimate  and is optimal given the learned
models.
To investigate this effect  we examine the transition matrix between the intensity components and
the ﬂow components (ﬁgure 8). If intensity and ﬂow were independent  we would expect all rows
of the transition matrix to be the same. If an intensity boundary always lead to a ﬂow boundary 
we would expect the bottom rows of the matrix to have only one nonzero element. By examining
the learned transition matrix we ﬁnd that while there is a dependency structure  it is not very strong.

7

Regardless of whether the intensity component corresponds to a boundary or not  the most likely
ﬂow components are ﬂat. When there is an intensity boundary  the ﬂow boundary in the same
orientation becomes more likely. However  even though it is more likely than in the unconditioned
case  it is still less likely than the ﬂat components.
To rule out that this effect is due to a local optimum found by EM  we conducted additional exper-
iments whereby the emission probabilities were held ﬁxed to the GMMs learned independently for
ﬂow and motion and each patch in the training set was assigned one intensity and one ﬂow compo-
nent. We then estimated the joint distribution over ﬂow and motion components by simply counting
the relative frequency in the training set. The results were nearly identical to those found by EM.
In summary  while our learned model supports the standard intuition that motion boundaries are
more likely at intensity boundaries  it suggests that when dealing with a large dataset with high
variability  there is very little beneﬁt (if any) in conditioning ﬂow models on the local intensity.

Hidden Markov model

Likelihood

Denoising: σ = 90

Figure 7: The hidden Markov model we use to jointly model intensity and ﬂow. Both log likelihood
and inference evaluations show almost no improvement of conditioning ﬂow on intensity.

un-conditional mixing-weights

intensity

conditional mixing-weights

Figure 8: Left: the transition matrix learned by the HMM. Right: comparing rows of the matrix
to the unconditional mixing weights. Conditioned on an intensity boundary  motion boundaries
become more likely but are still less likely than a ﬂat motion.

5 Discussion

Optical ﬂow has been an active area of research for over 30 years in computer vision  with many
methods based on assumed priors over ﬂow ﬁelds. In this paper  we have leveraged the availability
of large ground truth databases to learn priors from data and compare our learned models to the
assumptions typically made by computer vision researchers. We ﬁnd that many of the assumptions
are actually supported by the statistics (e.g.
the Horn and Schunck model is close to the opti-
mal Gaussian model  robust models are better  intensity discontinuities make motion discontinuities
more likely). However  a learned GMM model with 64 components signiﬁcantly outperforms the
standard models used in computer vision  primarily because it explicitly distinguishes between ﬂat
patches and boundary patches and then uses a different form of nonlocal smoothness for the different
cases.

Acknowledgments

Supported by the Israeli Science Foundation  Intel ICRI-CI and the Gatsby Foundation.

8

hintensityhflowintensityflow−20−15−10−50−15−10−50log-likelihoodlog(fractionofpatches)  HSHSIGMMHMM20406080100−10−8−6−4−2PSNRlog(fractionofpatches)  HSHSIGMMHMMhﬂowhintensity10203040506050100150200References
[1] M. Bethge. Factorial coding of natural images: how effective are linear models in removing

higher-order dependencies? 23(6):1253–1268  June 2006.

[2] Michael J. Black and P. Anandan. A framework for the robust estimation of optical ﬂow. In

ICCV  pages 231–236  1993.

[3] Daniel J. Butler  Jonas Wulff  Garrett B. Stanley  and Michael J. Black. A naturalistic open

source movie for optical ﬂow evaluation. In ECCV (6)  pages 611–625  2012.

[4] David J. Fleet  Michael J. Black  Yaser Yacoob  and Allan D. Jepson. Design and use of linear
models for image motion analysis. International Journal of Computer Vision  36(3):171–193 
2000.

[5] Andreas Geiger  Philip Lenz  and Raquel Urtasun. Are we ready for autonomous driving? the

kitti vision benchmark suite. In CVPR  pages 3354–3361  2012.

[6] Berthold KP Horn and Brian G Schunck. Determining optical ﬂow. Artiﬁcial intelligence 

17(1):185–203  1981.

[7] Bruce D Lucas  Takeo Kanade  et al. An iterative image registration technique with an appli-
cation to stereo vision. In Proceedings of the 7th international joint conference on Artiﬁcial
intelligence  1981.

[8] Xiaofeng Ren. Local grouping for optical ﬂow. In CVPR  2008.
[9] Stefan Roth and Michael J. Black. On the spatial statistics of optical ﬂow.

Journal of Computer Vision  74(1):33–50  2007.

International

[10] J Sohl-Dickstein and BJ Culpepper. Hamiltonian annealed importance sampling for partition

function estimation. 2011.

[11] Deqing Sun  Stefan Roth  and Michael J Black. Secrets of optical ﬂow estimation and their
principles. In Computer Vision and Pattern Recognition (CVPR)  2010 IEEE Conference on 
pages 2432–2439. IEEE  2010.

[12] Li Xu  Zhenlong Dai  and Jiaya Jia. Scale invariant optical ﬂow. In Computer Vision–ECCV

2012  pages 385–399. Springer  2012.

[13] Henning Zimmer  Andr´es Bruhn  and Joachim Weickert. Optic ﬂow in harmony. International

Journal of Computer Vision  93(3):368–388  2011.

[14] Daniel Zoran and Yair Weiss. Natural images  gaussian mixtures and dead leaves. In NIPS 

pages 1745–1753  2012.

9

,Dan Rosenbaum
Daniel Zoran
Yair Weiss