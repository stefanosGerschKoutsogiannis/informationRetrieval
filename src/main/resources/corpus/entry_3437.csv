2018,Metric on Nonlinear Dynamical Systems with Perron-Frobenius Operators,The development of a metric for structural data is a long-term problem in pattern recognition and machine learning. In this paper  we develop a general metric for comparing nonlinear dynamical systems that is defined with Perron-Frobenius operators in reproducing kernel Hilbert spaces. Our metric includes the existing fundamental metrics for dynamical systems  which are basically defined with principal angles between some appropriately-chosen subspaces  as its special cases. We also describe the estimation of our metric from finite data. We empirically illustrate our metric with an example of rotation dynamics in a unit disk in a complex plane  and evaluate the performance with real-world time-series data.,Metric on Nonlinear Dynamical Systems

with Perron-Frobenius Operators

Isao Ishikawa†‡  Keisuke Fujii†  Masahiro Ikeda†‡  Yuka Hashimoto†‡  Yoshinobu Kawahara†§

†RIKEN Center for Advanced Intelligence Project

‡School of Fundamental Science and Technology  Keio University
§The Institute of Scientiﬁc and Industrial Research  Osaka University

{isao.ishikawa  keisuke.fujii.zh  masahiro.ikeda}@riken.jp

yukahashimoto@keio.jp  ykawahara@sanken.osaka-u.ac.jp

Abstract

The development of a metric for structural data is a long-term problem in pattern
recognition and machine learning. In this paper  we develop a general metric for
comparing nonlinear dynamical systems that is deﬁned with Perron-Frobenius
operators in reproducing kernel Hilbert spaces. Our metric includes the existing
fundamental metrics for dynamical systems  which are basically deﬁned with
principal angles between some appropriately-chosen subspaces  as its special cases.
We also describe the estimation of our metric from ﬁnite data. We empirically
illustrate our metric with an example of rotation dynamics in a unit disk in a
complex plane  and evaluate the performance with real-world time-series data.

1

Introduction

Classiﬁcation and recognition has been one of the main focuses of research in machine learning
for the past decades. When dealing with some structural data other than vector-valued ones  the
development of an algorithm for this problem according to the type of the structure is basically
reduced to the design of an appropriate metric or kernel. However  not much of the existing literature
has addressed the design of metrics in the context of dynamical systems. To the best of our knowledge 
the metric for ARMA models based on comparing their cepstrum coefﬁcients [12] is one of the
ﬁrst papers to address this problem. De Cock and De Moor extended this to linear state-space
models by considering the subspace angles between the observability subspaces [6]. Meanwhile 
Vishwanathan et al. developed a family of kernels for dynamical systems based on the Binet-Cauchy
theorem [25]. Chaudhry and Vidal extended this to incorporate the invariance on initial conditions [4].
As mentioned in some of the above literature  the existing metrics for dynamical systems that
have been developed are deﬁned with principal angles between some appropriate subspaces such
as column subspaces of observability matrices. However  those are basically restricted to linear
dynamical systems although Vishwanathan et al. mentioned an extension with reproducing kernels
for some speciﬁc metrics [25]. Recently  Fujii et al. discussed a more general extension of these
metrics to nonlinear systems with Koopman operator [8]. Mezic et al. propose metrics of dynamcal
systems in the context of ergodic theory via Koopman operators on L2-spaces[14  15]. The Koopman
operator  also known as the composition operator  is a linear operator on an observable for a nonlinear
dynamical system [10]. Thus  by analyzing the operator in place of directly nonlinear dynamics 
one could extract more easily some properties about the dynamics. In particular  spectral analysis
of Koopman operator has attracted attention with its empirical procedure called dynamic mode
decomposition (DMD) in a variety of ﬁelds of science and engineering [18  2  17  3].
In this paper  we develop a general metric for nonlinear dynamical systems  which includes the
existing fundamental metrics for dynamical systems mentioned above as its special cases. This metric

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

is deﬁned with Perron-Frobenius operators in reproducing kernel Hilbert spaces (RKHSs)  which are
shown to be essentially equivalent to Koopman operators  and allows us to compare a pair of datasets
that are supposed to be generated from nonlinear systems. We also describe the estimation of our
metric from ﬁnite data. We empirically illustrate our metric using an example of rotation dynamics in
a unit disk in a complex plane  and evaluate the performance with real-world time-series data.
The remainder of this paper is organized as follows. In Section 2  we ﬁrst brieﬂy review the deﬁnition
of Koopman operator  especially the one deﬁned in RKHSs. In Section 3  we give the deﬁnition of
our metric for comparing nonlinear dynamical systems (NLDSs) with Koopman operators and  then 
describe the estimation of the metric from ﬁnite data. In Section 4  we describe the relation of our
metric to the existing ones. In Section 5  we empirically illustrate our metric with synthetic data and
evaluate the performance with real-world data. Finally  we conclude this paper in Section 6.

Kg = g  f  

2 Perron-Frobenius operator in RKHS
Consider a discrete-time nonlinear dynamical system xt+1 = f (xt) with time index t 2 T := {0}[N
and deﬁned on a state space M (i.e.  x 2M )  where x is the state vector and f : M!M is
a (possibly  nonlinear) state-transition function. Then  the Koopman operator (also known as the
composition operator)  which is denoted by K here  is a linear operator in a function space X deﬁned
by the rule
(1)
where g is an element of X. The domain D(K) of the Koopman operator K is D(K) := {g 2
X | g  f 2 X}  where  denotes the composition of g with f [10]. The choice of X depends on
the problem considered. In this paper  we consider X as an RKHS. The function g is referred as an
observable. We see that K acts linearly on the function g  even though the dynamics deﬁned by f may
be nonlinear. In recent years  spectral decomposition methods for this operator has attracted attention
in a variety of scientiﬁc and engineering ﬁelds because it could give a global modal description of
a nonlinear dynamical system from data. In particular  a variant of estimation algorithms  called
dynamic mode decomposition (DMD)  has been successfully applied in many real-world problems 
such as image processing [11]  neuroscience [3]  and system control [16]. In the community of
machine learning  several algorithmic improvements have been investigated by a formulation with
reproducing kernels [9] and in a Bayesian framework [22].
Now  let Hk be the RKHS endowed with a dot product h· ·i and a positive deﬁnite kernel k : X⇥X !
C (or R)  where X is a set. Here  Hk is a function space on X . The corresponding feature map is
denoted by  : X!H k. Also  assume M⇢X   and deﬁne the closed subspace Hk M ⇢H k by
the closure of the vector space generated by (x) for 8x 2M   i.e. Hk M := span{(x) | x 2M} .
Then  the Perron-Frobenius operator in RKHS associated with f (see [9]  note that Kf is called
Koopman operator on the feature map  in the literature)  Kf : Hk M !H k M  is deﬁned as a linear
operator with dense domain D(Kf ) := span ((M)) satisfying for all x 2M  
(2)
Since Kf is densely deﬁned  there exists the adjoint operator K⇤f . In the following proposition  we
see that K⇤f is essentially the same as Koopman operator K.
Proposition 2.1. Let X = H be the RKHS associated with the positive deﬁnite kernel k|M⇥M
deﬁned by the restriction of k to M⇥M   which is a function space on M. Let ⇢ : Hk M ! H be a
linear isomorphism deﬁned via the restriction of functions from X to M. Then  we have

Kf [(x)] = (f (x)).

⇢K⇤f ⇢1 = K 

where (·)⇤ means the Hermitian transpose.
Proof. Let g 2 D(K). Since the feature map for H is the same as ⇢    by the reproducing property 
hg  ⇢Kf ((x))iH = hg  ⇢  (f (x))iH = g  f (x) = hKg  ⇢  (x)iH. Thus the deﬁnitions (1) 
(2)  and the fact ⇢⇤ = ⇢1 show the statement.

3 Metric on NLDSs with Perron-Frobenius Operators in RKHSs

We propose a general metric for the comparison of nonlinear dynamical systems  which is deﬁned with
Perron-Frobenius operators in RKHSs. Intuitively  the metric compares the behaviors of dynamical

2

systems over inﬁnite time. To ensure the convergence property  we consider the ratio of metrics 
namely angles instead of directly considering exponential decay terms. We ﬁrst give the deﬁnition in
Subsection 3.1  and then derive an estimator of the metric from ﬁnite data in Subsection 3.2.

3.1 Deﬁnition
Let Hob be a Hilbert space and M⇢X a subset. Let h : M!H ob be a map  often called
an observable. We deﬁne the observable operator for h by a linear operator Lh : Hk M !H ob
such that h = Lh  . We give two examples here: First  in the case of Hob = Cd and h(x) =
(g1(x)  . . .   gm(x)) for some g1  . . .   gm 2H k  the observable operator is Lh(v) := (hgi  vi)m
i=1.
This situation appears  for example  in the context of DMD  where observed data is obtained by
values of functions in RKHS. Secondly  in the case of Hob = Hk M and h = |M  the observable
operator is Lh(v) = v. This situation appears when we can observe the state space X   and we try to
get more detailed information by observing data sent to RKHS via the feature map.
Let Hin be a Hilbert space. we refer to Hin as an initial value space. We call a linear operator
I : Hin !H k M an initial value operator on M if I is a bounded operator. Initial value operators
are regarded as expressions of initial values in terms of linear operators. In fact  in the case of
Hin = CN and let x1  . . .   xN 2M . Let I := ((x1)  . . .   (xN )) be an initial value operator on
i=1) =Pi ai(xi). Let Kf be a Perron-Frobenius
M  which is a linear operator deﬁned by I ((ai)N
operator associated with a dynamical system f : M!M . Then for any positive integer n > 0 
i=1) =Pi ai(f n(xi))  and Kn
we have Kn
f I is a linear operator including information at
time n of the orbits of the dynamical system f with inital values x1  . . .   xN.
Now  we deﬁne triples of dynamical systems. A triple of a dynamical system with respect to an
initial value space Hin and an observable space Hob is a triple (f   h  I )  where the ﬁrst component
f : M!M is a dynamical system on a subset M⇢X (M depends on f) with Perron-Frobenius
operator Kf   the second component h : M!H ob is an observable with an observable operator
Lh  and the third component I : Hin !H k M is an initial value operator on M  such that for
any r  0  the composition LhKr
f I is well-deﬁned and a Hilbert Schmidt operator. We denote by
T (Hin Hob) the set of triples of dynamical systems with respect to an initial value space Hin and an
observable space Hob.
For two triples D1 = (f1  h1  I1)  D2 = (f2  h2  I2) 2 T (Hin Hob)  and for T  m 2 N  we ﬁrst
deﬁne

f I ((ai)N

KT

m (D1  D2) := tr m^ T1Xr=0Lh2Kr

f2I2⇤ Lh1Kr

f1I1! 2 C 

where the symbol ^m is the m-th exterior product (see Appendix A). We note that since Kfi is
bounded  we regard Kfi as a unique extension of Kfi to a bounded linear operator with domain
Hk M.
Proposition 3.1. The function KT

m is a positive deﬁnite kernel on T (Hin Hob).

Proof. See Appendix B

Next  for positive number "> 0  we deﬁne AT

m with KT

m by

AT

m (D1  D2) := lim
✏!+0

(✏ + KT

m (D2  D2)) 2 [0  1].

We remark that for D 2 T (Hin Hob) KT
T =1 is a non-negative increasing sequence.
Now  we denote by `1 the Banach space of bounded sequences of complex numbers  and deﬁne
Am : T (Hin Hob)2 ! `1 by

m (D1  D1)) (✏ + KT

m (D1  D2)2
✏ + KT
m(D  D)1
Am :=AT
m1

T =1

Moreover  we introduce Banach limits for elements of `1. The Banach limit is a bounded linear
functional B : `1 ! C satisfying B ((1)1n=1) = 1  B ((zn)1n=1) = B ((zn+1)1n=1) for any (zn)n 
and B((zn)1n=1)  0 for any non-negative real sequence (zn)1n=1  namely zn  0 for all n  1.
We remark that if (zn)n 2 `1 converges a complex number ↵  then for any Banach limit B 
B ((zn)1n=1) = ↵. The existence of the Banach limits is ﬁrst introduced by Banach [1] and proved
through the Hahn-Banach theorem. In general  the Banach limit is not unique.

3

Deﬁnition 3.1. For an integer m > 0 and a Banach limit B  a positive deﬁnite kernel A Bm is deﬁned
by

A Bm := B (Am) .

We remark that positive deﬁniteness of A Bm follows Proposition 3.1 and the properties of the Banach
limit. We then simply denote A Bm (D1  D2) by Am(D1  D2) if Am(D1  D2) converges since that is
independent of the choice of B.
In general  a Banach limit B is hard to compute. However  under some assumption and suitable
choice of B  we prove that A Bm is computable in Proposition 3.6 below. Thus  we obtain an estimation
formula of A Bm (see [20]  [21]  [7] for other results on the estimation of Banach limit). In the
following proposition  we show that we can construct a pseudo-metric from the positive deﬁnite
kernel A Bm:

Proposition 3.2. Let B be a Banach limit. For m > 0  p1  A Bm (· ·) is a pseudo-metric on
T (Hin Hob).
Proof. See Appendix C.

Remark 3.3. Although we deﬁned KT
m with RKHS  it can be deﬁned in a more general situation
as follows. Let H  H0 and H00 be Hilbert spaces. For i = 1  2  let Vi ⇢H be a closed subspace 
Ki : Vi ! Vi and Li : Vi !H 00 linear operators  and let Ii : H0 ! Vi be a bounded operator. Then 
we can deﬁne KT

m between the triples (K1  L1  I1) and (K2  L2  I2) in the similar manner.

3.2 Estimation from ﬁnite data

vi := I ((0  . . .   0 

i
1  0  . . .   0)).

i=1 7! PN

i
1  0  . . .   0))  we have I = (v1  . . .   vN ).

Now we derive an formula to compute the above metric from ﬁnite data  which allows us to compare
several time-series data generated from dynamical systems just by evaluating the values of kernel func-
tions. First  we argue the computability of A Bm (D1  D2) and then state the formula for computation.
In this section  the initial value space is of ﬁnite dimension: Hin = CN  and for v1  . . .   vN 2H k M.
We deﬁne a linear operator (v1  . . .   vN ) : CN !H k M by (ai)N
i=1 aivi. We note
that any linear operator I : Hin = CN !H k M is an initial value operator)  and  by putting
vi := I ((0  . . .   0 
Deﬁnition 3.4. Let D = (f   h  I ) 2 TCN  Hob. We call D admissible if there exists Kf ’s
eigen-vectors '1 ' 2 ··· 2 H k M with ||'n|| = 1 and Kf 'n = n'n for all n  0 such that
|1|| 2| . . . and each vi is expressed as vi =P1n=1 ai n'n withP1n=1 |ai n| < 1  where
Deﬁnition 3.5. The triple D = (f   h  I ) 2 TCN  Hob is semi-stable if D is admissible and
|1| 1.
Then  we have the following asymptotic properties of Am.
Proposition 3.6. Let D1  D2 2 TCN  Hob. If D1 and D2 are semi-stable  then the sequence
Am (D1  D2) converges and the limit is equal to A Bm (D1  D2) for any Banach limit B. Similarly 
let C be the Cesàro operator  namely  C is deﬁned to be C((xn)1n=1) :=n1Pn
n=1. If D1
and D2 are admissible  then CAm (D1  D2) converges and the limit is equal to A Bm (D1  D2) for
any Banach limit B with BC = B.
Proof. See Appendix D.

k=1 xn1

We note that it is proved that there exists a Banach limit with BC = B [19  Theorem 4]. The
admissible or semi-stable condition holds in many cases  for example  in our illustrative example
(Section 5.1).
Now  we derive an estimation formula of the above metric from ﬁnite time-series data. To this end 
we ﬁrst need the following lemma:

4

m(D1  D2)

have the following formula:
KT

Lemma 3.7. Let D1 = f1  h1  (v1 l)N
T1Xt1 ... tm=0 X0<s1<...

<smNDLhiKt1

=

fi

l=1   D2 = f2  h2  (v2 l)N

vi s1 ^···^ LhiKtm

fi

vi sm  Lhj Kt1
fj

l=1 2 TCN  Hob. Then we
vj smE

vj s1 ^···^ Lhj Ktm

fj

Proof. See Appendix E.

KT

=

i t)  xl

i t = hi(xl

i 0 2M i.

i t+1 = fixl

i t   yl

For i = 1  2  we consider N time-series sequences {yl
i 2  . . .}⇢H ob in an observable
space (l = 1  . . .   N)  which are supposed to be generated from dynamical system fi on Mi ⇢X
and observed via hi. That is  we consider  for i = 1  2  t 2 T  and l = 1  . . .   N 
(3)

i 0  yl

i 1  yl

xl

m(D1  D2)

Lemma 3.7  we have

Assume for i = 1  2  the triple Di = ⇣fi  hi (xl
l=1⌘ is in TCN  Hob. Then  from
i 0)N
T1Xt1 ... tm=0 X0<s1<...
j t1 ^···^ Lhj xsm
<smN⌦Lhixs1
i t1 ^···^ Lhixsm
j tm↵
i tm   Lhj xs1
1CCA .
det0BB@
j tm↵Hob
⌦ys1
j t1↵Hob
i t1  ysm
i t1  ys1
T1Xt1 ... tm=0 X0<s1<···<smN
...
...
⌦ysm
j tm↵Hob
j t1↵Hob
i tm  ysm
i tm  ys1
In the case of Hob = Hk and hi = |Mi  we see that⌦ysa
j td↵Hob

j td). Therefore 
by Proposition 3.6  if Di’s are semi-stable or admissible  then we can compute an convergent estimator
of A Bm through AT

m just by evaluating the values of kernel functions.

···
...
···
i tb  ysc

⌦ys1
⌦ysm

i tb  xsc

= k(xsa

(4)

=

4 Relation to Existing Metrics on Dynamical Systems

In this section  we show that our metric covers the existing metrics deﬁned in the previous works
[12  6  25]. That is  we describe the relation to the metric via subspace angles and Martin’s metric in
Subsection 4.1 and the one to the Binet-Chaucy metric for dynamical systems in Subsection 4.2 as
the special cases of our metric.

4.1 Relation to metric via principal angles and Martin’s metric
In this subsection  we show that in a certain situation  our metric reconstruct the metric (Deﬁnition
2 in [12]) for the ARMA models introduced by Martin [12] and DeCock-DeMoor [6]. Moreover 
our formula generalizes their formula to the non-stable case  that is  we do not need to assume the
eigenvalues are strictly smaller than 1.
We here consider two linear dynamical systems. That is  in Eqs. (3)  let fi : Rq ! Rq and hi : Rq !
Rr be linear maps for i = 1  2 with l = 1  which we respectively denote by Ai and Ci. Then 
De Cock and De Moor propose to compare these two models by using the subspace angles as

d((A1  C1)  (A2  C2)) =  log

cos2 ✓i 

(5)

(CiAi)> (CiA2

where ✓i is the i-th subspace angle between the column spaces of the extended observability matrices
i )> ··· ] for i = 1  2. Meanwhile  Martin deﬁne a distance on AR
Oi := [C>i
models via cepstrum coefﬁcients  which is later shown to be equivalent to the distance (5) [6].
Now  we regard X = Rq. The positive deﬁnite kernel here is the usual inner product of Rq and the
associated RKHS is canonically isomorphic to Cq. Let Hin = Cq and Hob = Cr. Note that for

mYi=1

5

i = 1  2  Di = (Ai  Ci  Iq) 2 T (Cq  Cr)  and for any linear maps f : Rq ! Rq and h : Rq ! RN 
Kf = f and Lh = h.
Then we have the following theorem:
Proposition 4.1. The sequence Aq (D1  D2) converges. In the case that the systems are observable
and stable  this limit Aq (D1  D2) is essentially equal to (5).

Proof. See Appendix F.

Therefore  we can deﬁne a metric between linear dynamical systems with (A1  C1) and (A2  C2) by
Aq (D1  D2).
Moreover  the value Aq (D1  D2) captures an important characteristic of behavior of dynamical
systems. We here illustrate it in the situation where the state space models come from AR models.
We will see that Aq (D1  D2) has a sensitive behavior on the unit circle  and gives a reasonable
generalization of Martin’s metric [12] to the non-stable case.
For i = 1  2  we consider an observable AR model:

(6)
where ai k 2 R for k 2{ 1 ···   q}. Let Ci = (1  0  . . .   0) 2 C1⇥q  and let Ai be the companion
matrix for Mi. And  let i 1  . . .   i q be the roots of the equation yq  ai 1yq1 ··· ai q = 0.
For simplicity  we assume these roots are distinct complex numbers. Then  we deﬁne

(Mi) yt = ai 1yt1 + ··· + ai qytq 

As a result  if |P1| = |P2|  |R1| = |R2|  and Q1 = Q2  we have

Pi :=ni n |i n| > 1o   Qi :=ni n |i n| = 1o   and Ri :=ni n |i n| < 1o .
· Y↵ 2R11  ↵ · Y↵ 2R21  ↵
= Y↵ 2P11  ↵ · Y↵ 2P21  ↵

Aq (D1  D2)

 

(7)

Y↵2P1 2P2

|1  ↵|2

Y↵2R1 2R2

|1  ↵|2

and  otherwise  Aq (D1  D2) = 0. The detail of the derivation is in Appendix G.
Through this metric  we can observe a kind of “phase transition” of linear dynamical systems on the
unit circle  and the metric has sensitive behavior when eigen values on it. We note that in the case of
Pi = Qi = ;  the formula (7) is essentially equivalent to the distance (5) (see Theorem 4 in [6]).
4.2 Relation to the Binet-Cauchy metric on dynamical systems

Here  we discuss the relation between our metric and the Binet-Cauchy kernels on dynamical systems
deﬁned by Vishwanathan et al. [25  Section 5]. Let us consider two linear dynamical systems as
in Subsection 4.1. In [25  Section 5]  they give two kernels to measure the distance between two
systems (for simplicity  here we disregard the expectations over variables); the trace kernels ktr and
the determinant kernels kdet  which are respectively deﬁned by

ktr((x1 0  f1  h1)  (x2 0  f2  h2)) =

ety>1 ty2 t 

kdet((x1 0  f1  h1)  (x2 0  f2  h2)) = det 1Xt=1

ety1 ty>2 t!  

1Xt=1

where > 0 is a positive number satisfying e||f1||||f2||<1 to make the limits convergent. And
x1 0 and x2 0 are initial state vectors  which affect the kernel values through the evolutions of the
observation sequences. Vishwanathan et al. discussed a way of removing the effect of initial values
by taking expectations over those by assuming some distributions.

6

These kernels can be described in terms of our notation as follows (see also Remark 3.3). That
is  let us regard Hk = Cq. For i = 1  2  we deﬁne Di := (efi  hi  xi 0) 2 T (C  Cr)  and
D⇤i := (ef⇤i   x⇤i 0  h⇤i ) 2 T (Cr  C). Then these are described as
KT

ktr ((x1 0  f1  h1)  (x2 0  f2  h2)) = lim
T!1
kdet ((x1 0  f1  h1)  (x2 0  f2  h2)) = lim
T!1

1 (D1  D2)  
r (D⇤1  D⇤2) .
KT

Note that  introducing the exponential discounting e is a way to construct a mathematically valid
kernel to compare dynamical systems. However  in a certain situation  this method does not work
effectively. In fact  if we consider three dynamical systems on R: ﬁx a small positive number ✏> 0
and let f1(x) = (1 + ✏)x  f2(x) = x  and f3(x) = (1  ✏)x be linear dynamical systems. We
choose 1 2 R as the initial value. Here  it would be natural to regard these dynamical systems are
"different" each other even with almost zero ✏. However  if we compute the kernel deﬁned via the
exponential discounting  these dynamical systems are judged to be similar or almost the same. Instead
of introducing such an exponential discounting  our idea to construct a mathematically valid kernel is
considering the limit of the ratio of kernels deﬁned via ﬁnite series of the orbits of dynamical systems.
As a consequence  we do not need to introduce the exponential discounting. It enables ones to deal
with a wide range of dynamical systems  and capture the difference of the systems effectively. In fact 
in the above example  our kernel judges these dynamical systems are completely different  i.e.  the
value of A1 for each pair among them takes zero.

5 Empirical Evaluations

We empirically illustrate how our metric works with synthetic data of the rotation dynamics on the
unit disk in a complex plane in Subsection 5.1  and then evaluate the discriminate performance of our
metric with real-world time-series data in Subsection 5.2.

Illustrative example: Rotation on the unit disk

5.1
We use the rotation dynamics on the unit disk in the complex plane since we can compute the analytic
solution of our metric for this dynamics. Here  we regard X = D := {z 2 C | |z| < 1} and let
k(z  w) := (1  zw)1 be the Szegö kernel for z  w 2 D. The corresponding RKHS Hk is the
space of holomorphic functions f on D with the Taylor expansion f (z) =Pn0 an(f )zn such that
Pn0 |an(f )|2 < 1. For f  g 2H k  the inner product is deﬁned by hf  gi :=Pn0 an(f )an(g).
Let Hin = C and Hob = Hk.
For ↵ 2 C with |↵| 1  let R↵ : D ! D; z 7! ↵z. We denote by K↵ the Koopman operator for
RKHS deﬁned by R↵. We note that since K↵ is the adjoint of the composition operator deﬁned by
R↵  by Littlewood subordination theorem  K↵ is bounded. Now  we deﬁne z : Hk ! C; f 7! f (z)
and z w : Hk ! C2; f 7! (f (z)  f (w)). Then we deﬁne D1
↵ z := (R↵   ⇤z ) 2 T (C Hk) and
↵ z := (R↵   ⇤z ↵z ) 2 T (C2 Hk).
D2
By direct computation  we have the following formula (see Appendix H and Appendix I for the
derivation): For A1  we have

A1D1

↵ z  D1

 w =

For A2 we have

|1(zw)q|2

(1|z|2)(1|w|2)
(1 | z|2)(1 | w|2)
1 | z|2
1 | w|2
1

|↵| = || = 1 and ↵ = e2⇡ip/q with (p  q) = 1 
|↵| = || = 1 and ↵ = e2⇡i with /2 Q 
|↵| = 1 || < 1 
|↵| < 1 || = 1 
|↵| || < 1.

(8)

(9)

8>>>>><>>>>>:
 w =8>>><>>>:

↵ z  D2

A2D2

O(|zw|2µ(↵ ))
0
0
(1|↵|2)(1||2)

|1↵|2

|1+↵|2

(1+|↵|2)(1+||2) + O(|zw|2)

·

|↵| = || = 1
|↵| = 1 || < 1 
|↵| < 1 || = 1 
|↵| || < 1.

where  µ(↵  ) is a positive scalar value described in Appendix I. From the above  we see that A1
depends on the initial values of z and w  but A2 could independently discriminate the dynamics.

7

1: 

 = 1/3  |

| = 1

2: 

 = 1/3  |

| = 0.9

3: 

 = 1/3  |

| = 0.3

z0

A1

A10
1

A100

1

1

0.5

0

-0.5

-1

1

0.5

0

-0.5

-1

1

0.5

0

-0.5

-1

-1

4: 

 = 1/4  |

| = 1

5: 

 = 1/4  |

| = 0.9

6: 

 = 1/4  |

| = 0.3

7: 

 = 

/3  |

| = 1

8: 

 = 

/3  |

| = 0.9

9: 

 = 

/3  |

| = 0.3

0

1

-1

0

1

-1

0

1

0.9

0.3

(a)

(b)

(c)

Figure 1: Orbits of rotation dynamics
by multiplying ↵ = |↵|e2⇡i✓ on the unit
disk with the same initial values.

(d)

(e)

(f)

Figure 2: Comparison of empirical values (4) and
theoretical values (8) of the kernels AT
1 and A1 of
rotation dynamics with initial values z0

Szegö kernel

A100

1

A100

2

Gaussian kernel
2

A100

A100

1

KDMD[8]

Akkp

(a)

(b)

(c)

(d)

(e)

z0

0.9

0.3

(f)

(g)

(h)

(i)

(j)

Figure 3: Discrimination results of various metrics for rotation dynamics with initial values z0.
Vertical and horizontal axes correspond to the dynamics in Figure 1.

Next  we show empirical results with Eq. (4) from ﬁnite data for this example.1 For A1  we consider
↵ t = ↵tz0  where ↵ = |↵|e2⇡i✓. And for A2  we consider x1
↵ t = ↵tz0 and x2
x1
↵ t = ↵t+1z0 =
↵tz1. The graphs in Figure 1 show the dynamics on the unit disk with ✓ = {1/3  1/4 ⇡/ 3} and
|↵| = {1  0.9  0.3}. For simplicity  all of the initial values were set so that |z0| = 0.9.
Figure 3 shows the confusion matrices for the above dynamics to see the discriminative performances
of the proposed metric using the Szegö kernel (Figure 3a  3b  3f  and 3g)  using radial basis function
(Gaussian) kernel (Figure 3c  3d  3h  and 3i)  and the comparable previous metric (Figure 3e and
3j) [8]. For the Gaussian kernel  the kernel width was set as the median of the distances from data.
The last metric called Koopman spectral kernels [8] generalized the kernel deﬁned by Vishwanathan
et al. [25] to the nonlinear dynamical systems and outperformed the method. Among the above
kernels  we used Koopman kernel of principal angle (Akkp) between the subspaces of the estimated
Koopman mode  showing the best discriminative performance [8].
The discriminative performance in A1 when T = 100 shown in Figure 2c converged to the analytic
solution when considering T ! 1 in Figure 2a compared with that when T = 10 in Figure 2b. As
guessed from the theoretical results  although A1 did not discriminate the difference between the
dynamics converging to the origin while rotating and that converging linearly  A2 in Figure 3b did.
A2 using the Gaussian kernel (Ag2) in Figure 3d achieved almost perfect discrimination  whereas
A1 using Gaussian kernel (Ag1) in Figure 3c and Akkp in Figure 3e did not. Also  we examined the

1The Matlab code is available at https://github.com/keisuke198619/metricNLDS

8

a

e

i

b

f

j

c

g

k

d

h

l

Figure 4: Embeddings of four time series data using t-SNE for Ag1 (a-d)  Ag2 (e-h)  and Akkp
(i-l). (a e i) Sony AIBO robot surface I and (b f j) II datasets. (c g k) Star light curve dataset. (d h l)
Computers dataset. The markers x  o  and triangle represent the class 1  2  and 3 in the datasets.

case of small initial values in Figure 3f-3j so that |z0| = 0.3 for all the dynamics. A2 (Figure 3g  3i)
discriminated the two dynamics  whereas the remaining metrics did not (Figure 3f  3h  and 3j).

5.2 Real-world time-series data
In this section  we evaluated our algorithm for discrimination using dynamical properties in time-
series datasets from various real-world domains. We used the UCR time series classiﬁcation archive
as open-source real-world data [5]. It should be noted that our algorithm in this paper primarily target
the deterministic dynamics; therefore  we selected the examples apparently with smaller noises and
derived from some dynamics (For random dynamical systems  see e.g.  [13  26  23]). From the above
viewpoints  we selected two Sony AIBO robot surface (sensor data)  star light curve (sensor data) 
computers (device data) datasets. We used Am by Proposition 3.6 because we conﬁrmed that the data
satisfying the semi-stable condition in Deﬁnition 3.5 using the approximation of Kf deﬁned in [9].
We compared the discriminative performances by embedding of the distance matrices computed by
the proposed metric and the conventional Koopman spectral kernel used above. For clear visualization 
we randomly selected 20 sequences for each label from validation data  because our algorithms do
not learn any hyper-parameters using training data. All of these data are one-dimensional time-series
but for comparison  we used time-delay coordinates to create two-dimensional augmented time-series
matrices. Note that it would be difﬁcult to apply the basic estimation methods of Koopman modes
assuming high-dimensional data  such as DMD and its variants. In addition  we evaluated the
classiﬁcation error using k-nearest neighbor classiﬁer (k = 3) for simplicity. We used 40 sequences
for each label and computed averaged 10-fold cross-validation error (over 10 random trials).
Figure 4 shows examples of the embedding of the Ag1  Ag2  and Akkp using t-SNE [24] for four
time-series data. In the Sony AIBO robot surface datasets  D in Figure 4a b e f (classiﬁcation error:
0.025  0.038  0.213  and 0.150) had better discriminative performance than Akkp in Figure 4i j
(0.100 and 0.275). This tendency was also observed in the star light curve dataset in Figure 4c g k
(0.150  0.150  and 0.217)  where one class (circle) was perfectly discriminated using Ag1 and Ag2
but the distinction in the remaining two class was less obvious. In computers dataset  Ag2  and Akkp
in Figure 4h l (0.450 and 0.450) show slightly better discrimination than Akkp in Figure 4d (0.500).

6 Conclusions

In this paper  we developed a general metric for comparing nonlinear dynamical systems that is
deﬁned with Koopman operator in RKHSs. We described that our metric includes Martin’s metric and
Binet-Cauchy kernels for dynamical systems as its special cases. We also described the estimation of
our metric from ﬁnite data. Finally  we empirically showed the effectiveness of our metric using an
example of rotation dynamics in a unit disk in a complex plane and real-world time-series data.
Several perspectives to be further investigated related to this work would exist. For example  it would
be interesting to see discriminate properties of the metric in more details with speciﬁc algorithms.
Also  it would be important to develop models for prediction or dimensionality reduction for nonlinear
time-series data based on mathematical schemes developed in this paper.

9

References
[1] S. Banach. Théorie des óperations linéaires. Chelsea Publishing Co.  1995.
[2] E. Berger  M. Sastuba  D. Vogt  B. Jung  and H.B. Amor. Estimation of perturbations in robotic

behavior using dynamic mode decomposition. Advanced Robotics  29(5):331–343  2015.

[3] B.W. Brunton  J.A. Johnson  J.G. Ojemann  and J.N. Kutz. Extracting spatial-temporal coherent
patterns in large-scale neural recordings using dynamic mode decomposition. Journal of
Neuroscience Methods  258:1–15  2016.

[4] R. Chaudhry and R. Vidal. Initial-state invariant Binet-Cauchy kernels for the comparison of
linear dynamical systems. In Proc. of the 52nd IEEE Conf. on Decision and Control (CDC’13) 
pages 5377–5384  2014.

[5] Y. Chen  E. Keogh  B. Hu  N. Begum  A. Bagnall  A. Mueen  and G. Batista. The UCR
Time Series Classiﬁcation Archive  2015. URL: www.cs.ucr.edu/~eamonn/time_series_
data/.

[6] K. De Cock and B. De Moor. Subspace angles between ARMA models. Systems & Control

Letters 46  pages 265–270  2002.

[7] B. Q. Feng and J. L. Li. Some estimations of Banach limits. J. Math. Anal. Appl.  323:481–496 

2006.

[8] K. Fujii  Y. Inaba  and Y. Kawahara. Koopman spectral kernels for comparing complex dynamics:
Application to multiagent sport plays. In Proc. of the 2017 European Conf. on Machine Learning
and Principles and Practice of Knowledge Discovery in Databases (ECML-PKDD’17)  pages
127–139. 2017.

[9] Y. Kawahara. Dynamic mode decomposition with reproducing kernels for koopman spectral

analysis. In Advances in Neural Information Processing Systems 29  pages 911–919. 2016.

[10] B.O. Koopman. Hamiltonian systems and transformation in hilbert space. Proceedings of the

National Academy of Sciences  17(5):315–318  1931.

[11] J.N. Kutz  X. Fu  and S.L. Brunton. Multiresolution dynamic mode decomposition. SIAM

Journal on Applied Dynamical Systems  15(2):713–735  2016.

[12] R.J. Martin. A metric for ARMA processes. IEEE Trans. Signal Process. 48  page 1164–1170 

2000.

[13] I. Mezi´c. Spectral properties of dynamical systems  model reduction and decompositions.

Nonlinear Dynamics  41(1):309–325  2005.

[14] I. Mezic. Comparison of dynamics of dissipative ﬁnite- time systems using koopman operator

methods. IFAC-PaperOnline 49-18  page 454–461  2016.

[15] I. Mezic and A. Banaszuk. Comparison of systems with complex behavior. Physica D 

197:101–133  2004.

[16] J.L. Proctor  S.L. Brunton  and J.N. Kutz. Dynamic mode decomposition with control. SIAM

Journal on Applied Dynamical Systems  15(1):142–161  2016.

[17] J.L. Proctor and P.A. Eckhoff. Discovering dynamic patterns from infectious disease data using

dynamic mode decomposition. International health  7(2):139–145  2015.

[18] C.W. Rowley  I. Mezi´c  S. Bagheri  P. Schlatter  and D.S. Henningson. Spectral analysis of

nonlinear ﬂows. Journal of Fluid Mechanics  641:115–127  2009.

[19] E. M. Semenov and F. A. Sukochev. Invariant banach limits and applications. Journal of

Functional Analysis  259:1517–1541  2010.

[20] L. Sucheston. On existence of ﬁnite invariant measures. Math. Z.  86:327–336  1964.
[21] L. Sucheston. Banach limits. In Amer. Math. Monthly  volume 74  pages 308–311. 1967.
[22] N. Takeishi  Y. Kawahara  Y. Tabei  and T. Yairi. Bayesian dynamic mode decomposition. In
Proc. of the 26th Int’l Joint Conf. on Artiﬁcial Intelligence (IJCAI’17)  pages 2814–2821  2017.
[23] N. Takeishi  Y. Kawahara  and T. Yairi. Subspace dynamic mode decomposition for stochastic

koopman analysis. Physical Review E  96:033310  2017.

[24] Laurens van der Maaten and Geoffrey Hinton. Visualizing data using t-SNE. Journal of Machine

Learning Research  9:2579–2605  2008.

10

[25] S.V.N. Vishwanathan  A.J. Smola  and R. Vidal. Binet-Cauchy kernels on dynamical systems
and its application to the analysis of dynamic scenes. Int’l J. of Computer Vision  73(1):95–119 
2007.

[26] M.O. Williams  I.G. Kevrekidis  and C.W. Rowley. A data-driven approximation of the koopman
operator: Extending dynamic mode decomposition. Journal of Nonlinear Science  25(6):1307–
1346  2015.

11

,Isao Ishikawa
Keisuke Fujii
Masahiro Ikeda
Yuka Hashimoto
Yoshinobu Kawahara