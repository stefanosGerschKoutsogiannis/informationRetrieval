2008,Supervised Exponential Family Principal Component Analysis via Convex Optimization,Recently  supervised dimensionality reduction has been gaining attention  owing to the realization that data labels are often available and strongly suggest important underlying structures in the data. In this paper  we present a novel convex supervised dimensionality reduction approach based on exponential family PCA and provide a simple but novel form to project new testing data into the embedded space. This convex approach successfully avoids the local optima of the EM learning. Moreover  by introducing a sample-based multinomial approximation to exponential family models  it avoids the limitation of the prevailing Gaussian assumptions of standard PCA  and produces a kernelized formulation for nonlinear supervised dimensionality reduction. A training algorithm is then devised based on a subgradient bundle method  whose scalability can be gained through a coordinate descent procedure. The advantage of our global optimization approach is demonstrated by empirical results over both synthetic and real data.,Supervised Exponential Family Principal Component

Analysis via Convex Optimization

Yuhong Guo

Computer Sciences Laboratory
Australian National University

yuhongguo.cs@gmail.com

Abstract

Recently  supervised dimensionality reduction has been gaining attention  owing
to the realization that data labels are often available and indicate important under-
lying structure in the data. In this paper  we present a novel convex supervised
dimensionality reduction approach based on exponential family PCA  which is
able to avoid the local optima of typical EM learning. Moreover  by introduc-
ing a sample-based approximation to exponential family models  it overcomes the
limitation of the prevailing Gaussian assumptions of standard PCA  and produces
a kernelized formulation for nonlinear supervised dimensionality reduction. A
training algorithm is then devised based on a subgradient bundle method  whose
scalability can be gained using a coordinate descent procedure. The advantage of
our global optimization approach is demonstrated by empirical results over both
synthetic and real data.

1 Introduction

Principal component analysis (PCA) has been extensively used for data analysis and processing.
It provides a closed-form solution for linear unsupervised dimensionality reduction through singu-
lar value decomposition (SVD) on the data matrix [8]. Probabilistic interpretations of PCA have
also been provided in [9  16]  which formulate PCA using a latent variable model with Gaussian
distributions. To generalize PCA to better suit non-Gaussian data  many extensions to PCA have
been proposed that relax the assumption of a Gaussian data distribution. Exponential family PCA
is the most prominent example  where the underlying dimensionality reduction principle of PCA
is extended to the general exponential family [4  7  13]. Previous work has shown that improved
quality of dimensionality reduction can be obtained by using exponential family models appropri-
ate for the data at hand [4  13]. Given data from a non-Gaussian distribution these techniques are
better able than PCA to capture the intrinsic low dimensional structure. However  most existing
non-Gaussian dimensionality reduction methods rely on iterative local optimization procedures and
thus suffer from local optima  with the sole exception of [7] which shows a general convex form can
be obtained for dimensionality reduction with exponential family models.

Recently  supervised dimensionality reduction has begun to receive increased attention. As the goal
of dimensionality reduction is to identify the intrinsic structure of a data set in a low dimensional
space  there are many reasons why supervised dimensionality reduction is a meaningful topic to
study. First  data labels are almost always assigned based on some important intrinsic property of
the data. Such information should be helpful to suppress noise and capture the most useful aspects
of a compact representation of the data. Moreover  there are many high dimensional data sets with
label information available  e.g.  face and digit images  and it is unwise to ignore them. A few su-
pervised dimensionality reduction methods based on exponential family models have been proposed
in the literature. For example  a supervised probabilistic PCA (SPPCA) model was proposed in
[19]. SPPCA extends probabilistic PCA by assuming that both features and labels have Gaussian

distributions and are generated independently from the latent low dimensional space through linear
transformations. The model is learned by maximizing the marginal likelihood of the observed data
using an alternating EM procedure. A more general supervised dimensionality reduction approach
with generalized linear models (SDR GLM) was proposed in [12]. SDR GLM views both features
and labels as exponential family random variables and optimizes a weighted linear combination of
their conditional likelihood given latent low dimensional variables using an alternating EM-style
procedure with closed-form update rules. SDR GLM is able to deal with different data types by
using different exponential family models. Similar to SDR GLM  the linear supervised dimension-
ality reduction method proposed in [14] also takes advantage of exponential family models to deal
with different data types. However  it optimizes the conditional likelihood of labels given observed
features within a mixture model framework using an EM-style optimization procedure. Beyond the
PCA framework  many other supervised dimensionality reduction methods have been proposed in
the literature. Linear (ﬁsher) discriminant analysis (LDA) is a popular alternative [5]  which max-
imizes between-class variance and minimizes within-class variance. Moreover  a kernelized ﬁsher
discriminant analysis (KDA) has been studied in [10]. Another notable nonlinear supervised dimen-
sionality reduction approach is the colored maximum variance unfolding (MVU) approach proposed
in [15]  which maximizes the variance aligning with the side information (e.g.  label information) 
while preserving the local distance structures from the data. However  colored MVU has only been
evaluated on training data.

In this paper  we propose a novel supervised exponential family PCA model (SEPCA). In the SEPCA
model  observed data x and its label y are assumed to be generated from the latent variables z via
conditional exponential family models; dimensionality reduction is conducted by optimizing the
conditional likelihood of the observations (x  y). By exploiting convex duality of the sub-problems
and eigenvector properties  a solvable convex formulation of the problem can be derived that pre-
serves solution equivalence to the original. This convex formulation allows efﬁcient global op-
timization algorithms to be devised. Moreover  by introducing a sample-based approximation to
exponential family models  SEPCA does not suffer from the limitations of implicit Gaussian as-
sumptions and is able to be conveniently kernelized to achieve nonlinearity. A training algorithm
is then devised based on a subgradient bundle method  whose scalability can be gained through a
coordinate descent procedure. Finally  we present a simple formulation to project new testing data
into the embedded space. This projection can be used for other supervised dimensionality reduction
approach as well. Our experimental results over both synthetic and real data suggest that a more
global  principled probabilistic approach  SEPCA  is better able to capture subtle structure in the
data  particularly when good label information is present.

The remainder of this paper is organized as follows. First  in Section 2 we present the proposed
supervised exponential family PCA model and formulate a convex nondifferentiable optimization
problem. Then  an efﬁcient global optimization algorithm is presented in Section 3. In Section 4 
we present a simple projection method for new testing points. We then present the experimental
results in Section 5. Finally  in Section 6 we conclude the paper.

2 Supervised Exponential Family PCA

observation Xi:; thus Pk

We assume we are given a t × n data matrix  X  consisting of t observations of n-dimensional
feature vectors  Xi:  and a t×k indicator matrix  Y   with each row to indicate the class label for each
j=1 Yij = 1. For simplicity  we assume features in X are centered; that is 
their empirical means are zeros. We aim to recover a d-dimensional re-representation  a t × d matrix
Z  of the data (d < n). This is typically viewed as discovering a latent low dimensional manifold
in the high dimensional feature space. Since the label information Y is exploited in the discovery
process  this is called supervised dimensionality reduction. For recovering Z  a key restriction that
one would like to enforce is that the features used for coding  Z:j  should be linearly independent;
that is  one would like to enforce the constraint Z ⊤Z = I  which ensures that the codes are expressed
by orthogonal features in the low dimensional representation.

Given the above setup  in this paper  we are attempting to address the problem of supervised dimen-
sionality reduction using a probabilistic latent variable model. Our intuition is that the important
intrinsic structure (underlying feature representation) of the data should be able to accurately gener-
ate/predict the original data features and labels.

In this section  we formulate the low-dimensional principal component discovering problem as a
conditional likelihood maximization problem based on exponential family model representations 
which can be reformulated into an equivalent nondifferentiable convex optimization problem. We
then exploit a sample-based approximation to unify exponential family models for different data
types.

2.1 Convex Formulation of Supervised Exponential Family PCA

As with the generalized exponential family PCA [4]  we attempt to ﬁnd low-dimensional represen-
tation by maximizing the conditional likelihood of the observation matrix X and Y given the latent
matrix Z  log P (X  Y |Z) = log P (X|Z) + log P (Y |Z). Using the general exponential family
representation  a regularized version of this maximization problem can be formulated as

max

Z:Z⊤Z=I

max
W Ω b

log P (X|Z  W ) −

β
2

tr¡W W ⊤¢ + log P (Y |Z  Ω  b) −

β

2 ¡tr¡ΩΩ⊤¢ + b⊤b¢

= max

Z:Z⊤Z=I

max
W Ω b

(A(Zi:  W ) − log P0(Xi:)) −

β
2

tr¡W W ⊤¢

(1)

tr¡ZW X ⊤¢ −Xi
+tr¡ZΩY ⊤¢ + 1⊤Y b −Xi

A(Zi:  Ω  b) −

β

2 ¡tr¡ΩΩ⊤¢ + b⊤b¢

where W is a d × n parameter matrix for conditional model P (X|Z); Ω is a d × k parameter matrix
for conditional model P (Y |Z) and b is a k × 1 bias vector; 1 denotes the vector of all 1s; A(Zi:  W )
and A(Zi:  Ω  b) are the log normalization functions to ensure valid probability distributions:

A(Zi:  W ) = logZ exp (Zi:W x) P0(x) dx .

A(Zi:  Ω  b) = log

k

Xℓ=1

exp¡Zi:Ω1ℓ + 1⊤
ℓ b¢

(2)

(3)

where 1ℓ denotes a zero vector with a single 1 in the ℓth entry.
Note that the class variable y is discrete  thus maximizing log P (Y |Z  Ω  b) is a discriminative
classiﬁcation training. In fact  the second part of the objective function in (1) is simply a multi-class
logistic regression. That is why we have incorporated an additional bias term b into the model.

Theorem 1 The optimization problem (1) is equivalent to

min
U x U y

max

M :IºM º0  tr(M )=d Xi
+Xi

(A∗(U x

i: ) + log P0(Xi:)) +

1
2β

tr¡(X −U x)(X −U x)⊤M¢

A∗(U y

i:) +

1
2β

tr¡(Y −U y)(Y −U y)⊤(M + E)¢

(4)

i: ) and
where E is a t × t matrix with all 1s; U x is a t × n matrix; U y is a t × k matrix; A∗(U x
A∗(U y
i:) are the Fenchel conjugates of A(Zi:  W ) and A(Zi:  Ω  b) respectively; M = ZZ ⊤ and Z
can be recovered by taking the top d eigenvectors of M; and the model parameters W  Ω  b can be
recovered by

W =

1
β

Z ⊤(X − U x)  Ω =

1
β

Z ⊤(Y − U y)  b =

1
β

(Y − U y)⊤1

Proof: The proof is simple and based on standard results. Due to space limitation  we only provide
a summarization of the key steps here. There are three steps. The ﬁrst step is to derive the Fenchel
conjugate dual for each log partition function  A(Z  .)  following [18  Section 3.3.3]; which can be
used to yield

max

Z:Z⊤Z=I

min

U x U y Xi
+Xi

(A∗(U x

i: ) + log P0(Xi:)) +

1
2β

tr¡(X −U x)(X −U x)⊤ZZ ⊤¢

A∗(U y

i:) +

1
2β

tr¡(Y −U y)(Y −U y)⊤(ZZ ⊤ + E)¢

(5)

that is equivalent to the original problem (1). The second step is based on exploiting the strong
min-max property [2] and the relationships between different constraint sets

{M : M = ZZ ⊤ for some Z such that Z ⊤Z = I} ⊆ {M : I º M º 0  tr(M ) = d} 

which allows one to further show the optimization (4) is an upper bound relaxation of (5). The ﬁnal
equivalence proof is based on the result of [11]  which suggests the substitution of ZZ ⊤ with matrix
M does not produce relaxation gap.
Note that (4) is a min-max optimization problem. Moreover  for each ﬁxed M  the outer minimiza-
tion problem is obviously convex  since the Fenchel conjugates  A∗(U x
i:)  are convex
functions of U x and U y respectively [2]; that is  the objective function for the outer minimization is a
pointwise supremum over an inﬁnite set of convex functions. Thus the overall min-max optimization
is convex [3]  but apparently not necessarily differentiable. We will address the nondifferentiable
training issue in Section 3.

i: ) and A∗(U y

2.2 Sample-based Approximation

In the previous section  we have formulated our supervised exponential family PCA as a convex
optimization problem (4). However  before attempting to devise a training algorithm to solve it  we
have to provide some concrete forms for the Fenchel conjugate functions A∗(U x
i:). For
different exponential family models  the Fenchel conjugate functions A∗ are different; see [18  Table
2]. For example  since the y variable in our model is a discrete class variable  it takes a multinomial
distribution. Thus the Fenchel conjugate function A∗(U y

i: ) and A∗(U y

A∗(U y

i:) = A∗(Θy

i:) = tr³Θy

i: log Θy⊤

i:) is given by
i: ´   where Θy ≥ 0  Θy1 = 1

The speciﬁc exponential family model is determined by the data type and distribution. PCA and
SPPCA use Gaussian models  thus their performances might be degraded when the data distribution
is non-Gaussian. However  it is tedious and sometimes hard to choose the most appropriate expo-
nential family model to use for each speciﬁc application problem. Moreover  the log normalization
function A and its Fenchel conjugate A∗ might not be easily computable. For these reasons  we pro-
pose to use a sample-based approximation to the integral (2) and achieve an empirical approximation
to the true underlying exponential family model as follows. If one replaces the integral deﬁnition (2)

with an empirical deﬁnition  A(Zi:  W ) = logPj exp¡Zi:W X ⊤

can be given by

j:¢ /t  then the conjugate function

(6)

(7)

(8)

(9)

A∗(U x

i: ) = A∗(Θx

i:) = tr¡Θx

i: log Θx⊤

i: ¢ − log(1/t)  where Θx ≥ 0  Θx1 = 1

With this sample-based approximation  problem (4) can be expressed as

min
Θx Θy

max

M :IºM º0  tr(M )=d

tr (Θx log Θx) +

+ tr (Θy log Θy) +

1
2β
1
2β

tr¡(I −Θx)K(I −Θx)⊤M¢
tr¡(Y −Θy)(Y −Θy)⊤(M + E)¢

subject to

Θx ≥ 0  Θx1 = 1; Θy ≥ 0  Θy1 = 1

One beneﬁt of working with this sample-based approximation is that it is automatically kernelized 
K = XX ⊤  to enable non-linearity to be conveniently introduced.

3 Efﬁcient Global Optimization

The optimization (8) we derived in the previous section is a convex-concave min-max optimization
problem. The inner maximization of (8) is a well known problem with a closed-form solution [11]:
M ∗ = Z ∗Z ∗⊤ and Z ∗ = Qd
max(D)
denotes the matrix formed by the top d eigenvectors of D. However  the overall outer minimization
problem is nondifferentiable with respect to Θx and Θy. Thus the standard ﬁrst-order or second-
order optimization techniques that rely on the standard gradients can not be applied here. In this
section  we deploy a bundle method to solve this nondifferentiable min-max optimization.

max¡(I −Θx)K(I −Θx)⊤ + (Y −Θy)(Y −Θy)⊤¢  where Qd

3.1 Bundle Method for Min-Max Optimization

The bundle method is an efﬁcient subgradient method for nondifferentiable convex optimization; it
relies on the computation of subgradient terms of the objective function. A vector g is a subgradient
of function f at point x  if f (y) ≥ f (x) + g⊤(y − x)  ∀y. To adapt standard bundle methods to our
speciﬁc min-max problem  we need to ﬁrst address the critical issue of subgradient computation.

Proposition 1 Consider a joint function h(x  y) deﬁned over x ∈ X and y ∈ Y  satisfying: (1)
h(·  y) is convex for all y ∈ Y; (2) h(x  ·) is concave for all x ∈ X . Let f (x) = maxy h(x  y) 
and q(x0) = arg maxy h(x0  y). Assume that g is a gradient of h(·  q(x0)) at x = x0  then g is a
subgradient of f (x) at x = x0.
Proof:

h(x  y) ≥ h(x  q(x0))

f (x) = max

y

≥ h(x0  q(x0)) + g⊤(x − x0)
= f (x0) + g⊤(x − x0)

(by the deﬁnitions of f (x) and q(x0))
Thus g is a subgradient of f (x) at x = x0 according to the deﬁnition of subgradient.
According to Proposition 1  the subgradients of our outer minimization objective function f in (8)
over Θx and Θy can be given by

(since h(·  y) is convex for all y ∈ Y)

1
β

1
β

(10)

∂Θxf ∋ ¡ log Θx + 1 −

M ∗(I − Θx)K¢  ∂Θy f ∋ ¡ log Θy + 1 −

M ∗(Y − Θy)¢

where M ∗ is the optimal inner maximization solution at the current point [Θx  Θy].
Algorithm 1 illustrates the bundle method we developed to solve the inﬁnite min-max optimiza-
tion (8)  where the linear constraints (9) over Θx and Θy can be conveniently incorporated into the
quadratic bound optimization. One important issue in this algorithm is how to manage the size of the
linear lower bound constraints formed from the active set B (deﬁned in Algorithm 1)  as it incremen-
tally increases with new points being explored. To solve this problem  we noticed the Lagrangian
dual parameters α for the lower bound constraints obtained by the quadratic optimization in step 1
is a sparse vector  indicating that many lower bound constraints can be turned off. Moreover  any
constraint that is turned off will mostly stay off in the later steps. Therefore  for the bundle method
we developed  whenever the size of B is larger than a given constant b  we will keep the active points
of B that correspond to the ﬁrst b largest α values  and drop the remaining ones.

3.2 Coordinate Descent Procedure

An important factor affecting the running efﬁciency is the size of the problem. The convex opti-
mization (8) works in the dual parameter space  where the size of the parameters Θ = {Θx  Θy} 
t × (t + k)  depends only on the number of training samples  t  not on the feature size  n. For high
dimensional small data sets (n ≫ t)  our dual optimization is certainly a good option. However 
with the increase of t  our problem size will increase in an order of O(t2). It might soon become too
large to handle for the quadratic optimization step of the bundle method.

On the other hand  the optimization problem (8) possesses a nice semi-decomposable structure:
one equality constraint in (9) involves only one row of the Θ; that is  the Θ can be separated into
rows without affecting the equality constraints. Based on this observation  we develop a coordinate
descent procedure to obtain scalability of the bundle method over large data sets. Speciﬁcally  we
put an outer loop above the bundle method. Within each of this outer loop iteration  we randomly
separate the Θ parameters into m groups  with each group containing a subset rows of Θ; and
we then use bundle method to sequentially optimize each subproblem deﬁned on one group of
Θ parameters while keeping the remaining rows of Θ ﬁxed. Although coordinate descent with a
nondifferentiable convex objective is not guaranteed to converge to a minimum in general [17]  we
have found that this procedure performs quite well in practice  as shown in the experimental results.

4 Projection for Testing Data

One important issue for supervised dimensionality reduction is to map new testing data into the
dimensionality-reduced principal dimensions. We deploy a simple procedure for this purpose. After

Algorithm 1 Bundle Method for Min-Max Optimization in (8)

Input: ¯δ > 0  m ∈ (0  1)  b ∈ IN  µ ∈ IR
Initial: Find an initial point θ∗ satisfying the linear constraints in (9); compute f (θ∗).

Let ℓ = 1  θℓ = θ∗  compute gℓ ∈ ∂θℓf by (10); eℓ = f (θ∗) − f (θℓ) − gℓ⊤(θ∗ − θℓ).
Let B = {(eℓ  gℓ)}  ˆε = Inf  ˆg = 0; ℓ = ℓ + 1.

repeat

1. Solve quadratic minimization for solution ˆθ  and Lagrangian dual parameters α w.r.t. the
lower bound linear constraints in B [1]:

µ
2

kθ − θ∗k2  subject to the linear constraints in (9)

θ

ψℓ(θ) +

ˆθ = arg min
where ψℓ(θ) = f (θ∗) + max© − ˆε + ˆg⊤(θ − θ∗)  max
2 kˆθ − θ∗k2 ≥ 0. If δℓ < ˆδ  return.

(ei gi)∈B

2. Deﬁne δℓ = f (θ∗) − [ψℓ(ˆθ) + µ
3. Conduct line search to minimize f (θℓ) with θℓ = γθ∗ + (1 − γ)ˆθ  for 0 < γ < 1.
4. Compute gℓ ∈ ∂θℓf by (10); eℓ = f (θ∗)−f (θℓ)−gℓ⊤(θ∗ −θℓ); update B = B∪{(eℓ  gℓ)}.
5. If f (θ∗) − f (θℓ) ≥ mδℓ  then take a serious step:

{−ei + ˆgi⊤(θ − θ∗)}ª

(1) update: ei = ei + f (θℓ) − f (θ∗) + gi⊤(θ∗ − θℓ);

(2) update the aggregation: ˆg = Pi αigi  ˆε = Pi αiei;

(3) update the stored solution: θ∗ = θℓ  f (θ∗) = f (θℓ).

6. If |B| > b  reduce B set according to α.
7. ℓ = ℓ + 1.

until maximum iteration number is reached

training  we obtain a low-dimensional representation Z for X  where Z can be viewed as a linear
projection of X in some transformed space ψ(X) through a parameter matrix U; such that Z =
ψ(X)U = ψ(X)ψ(X)⊤K +ψ(X)U  where K + denotes the pseudo inverse of K = ψ(X)ψ(X)⊤.
Then a new testing sample x∗ can be projected by

z∗ = ψ(x∗)ψ(X)⊤K +ψ(X)U = k(x∗  X)K +Z

(11)

5 Experimental Results

In order to evaluate the performance of the proposed supervised exponential family PCA (SEPCA)
approach  we conducted experiments over both synthetic and real data  and compared to supervised
dimensionality reduction with generalized linear models (SDR GLM)  supervised probabilistic PCA
(SPPCA)  linear discriminant analysis (LDA)  and colored maximum variance unfolding (MVU).
The projection procedure (11) is used for colored MVU as well. In all the experiments  we used
µ = 1 for Algorithm 1  and used α = 0.0001 for SDR GLM as suggested in [12].

5.1 Experiments on Synthetic Data

Two synthetic experiments were conducted to compare the ﬁve approaches under controlled con-
ditions. The ﬁrst synthetic data set is formed by ﬁrst generating four Gaussian clusters in a two-
dimensional space  with each corresponding to one class  and then adding the third dimension to
each point by uniformly sampling from a ﬁxed interval. This experiment attempts to compare the
performance of the ﬁve approaches in the situation where the data distribution does not satisfy the
Gaussian assumption. Figure 1 shows the projection results for each approach in a two dimensional
space for 120 testing points after being trained on a set with 80 points. In this case  SEPCA and
LDA outperform all the other three approaches.

The second synthetic experiment is designed to test the capability of performing nonlinear dimen-
sionality reduction. The synthetic data is formed by ﬁrst generating two circles in a two dimensional
space (one circle is located inside the other one)  with each circle corresponding to one class  and
then the third dimension sampled uniformly from a ﬁxed interval. As SDR GLM does not provide
a nonlinear form  we conducted the experiment with only the remaining four approaches. For LDA 
we used its kernel variant  KDA. A Gaussian kernel with σ = 1 was used for SEPCA  SPPCA and
KDA. Figure 2 shows the projection results for each approach in a two dimensional space for 120

SEPCA

SDR−GLM

SPPCA

LDA

0.25

0.2

0.15

0.1

0.05

0

−0.05

−0.1

−0.15

−0.2

60

50

40

30

20

10

0

−10

−20

1

0.5

0

−0.5

−1

2

1.5

1

0.5

0

−0.5

−1

−1.5

−2

−2.5

−0.25

−0.4

−0.3

−0.2

−0.1

0

0.1

0.2

−30

−30

0.3

−20

−10

0

10

20

−1.5
−1

30

−0.5

0

0.5

1

1.5

−3
−4

−3

−2

−1

0

1

2

4

2

0

−2

−4

−6

−8
−7

Colored−MVU

−6

−5

−4

−3

−2

−1

0

1

2
x 10−7

Figure 1: Projection results on test data for synthetic experiment 1. Each color indicates one class.

SEPCA

0.15

0.1

0.05

0

−0.05

−0.1

−0.15

0.01

0.005

0

−0.005

−0.01

−0.015

SPPCA

KDA

Colored−MVU

0.02

0.01

0

−0.01

−0.02

−0.03

−0.04

2.5

2

1.5

1

0.5

0

−0.5

−1

−1.5

−2

−0.2
−0.25

−0.2

−0.15

−0.1

−0.05

0

0.05

0.1

0.15

−0.02

−20

−15

−10

−5

0

5
x 10−3

−0.05

−0.35

−0.3

−0.25

−0.2

−0.15

−0.1

−0.05

−2.5

5.85

0

5.9

5.95

6

6.05

6.1

6.15

6.2

6.25

6.3

6.35

Figure 2: Projection results on test data for synthetic experiment 2. Each color indicates one class.

testing points after being trained on a set with 95 points. Again  SEPCA and KDA achieve good
class separations and outperform the other two approaches.

5.2 Experiments on Real Data

To better characterize the performance of dimensionality reduction in a supervised manner  we con-
ducted some experiments on a few high dimensional multi-class real world data sets. The left side
of Table 1 provides the information about these data sets. Our experiments were conducted in the
following way. We randomly selected 3∼5 examples from each class to form the training set and
used the remaining examples as the test set. For each approach  we ﬁrst learned the dimensionality
reduction model on the training set. Moreover  we also trained a logistic regression classiﬁer us-
ing the projected training set in the reduced low dimensional space. (Note  for SEPCA  a classiﬁer
was trained simultaneously during the process of dimensionality reduction optimization.) Then the
test data were projected into the low dimensional space according to each dimensionality reduction
model. Finally  the projected test set for each approach were classiﬁed using each corresponding
logistic regression classiﬁer. The right side of Table 1 shows the classiﬁcation accuracies on the test
set for each approach. To better understand the quality of the classiﬁcation using projected data  we
also included the standard classiﬁcation results  indicated as ’FULL’  using the original high dimen-
sional data. (Note  we are not able to obtain any result for SDR GLM on the newsgroup data as it is
inefﬁcient for very high dimensional data.) The results reported here are averages over 20 repeated
runs  and the projection dimension d = 10. Still the proposed SEPCA presents the best performance
among the compared approaches. But different from the synthetic experiments  LDA does not work
well on these real data sets.

The results on both synthetic and real data show that SEPCA outperforms the other four approaches.
This might be attributed to its adaptive exponential family model approximation and its global opti-
mization  while SDR GLM and SPPCA apparently suffer from local optima.

6 Conclusions

In this paper  we propose a supervised exponential family PCA (SEPCA) approach  which can
be solved efﬁciently to ﬁnd global solutions. Moreover  SEPCA overcomes the limitation of the
Gaussian assumption of PCA and SPPCA by using a data adaptive approximation for exponential
family models. A simple  straightforward projection method for new testing data has also been
constructed. Empirical study suggests that this SEPCA outperforms other supervised dimensionality
reduction approaches  such as SDR GLM  SPPCA  LDA and colored MVU.

Table 1: Data set statistics and test accuracy results (%)

Dataset

#Data

#Dim #Class

FULL SEPCA GLM SPPCA LDA

SDR

Yale
YaleB
11 Tumor
Usps3456
Newsgroup

165
2414
174
120
19928

4096
1024
12533
256
25284

15
38
11
4
20

65.3
47.0
77.6
82.1
32.1

64.4
20.5
88.9
79.7
16.9

58.8
19.0
63.5
77.9
–

51.6
9.8
63.0
78.5
6.9

31.0
6.2
23.7
74.3
10.0

colored
MVU

21.1
2.8
40.2
75.8
10.4

References

[1] A. Belloni. Introduction to bundle methods. Technical report  MIT  2005.
[2] J. Borwein and A. Lewis. Convex Analysis and Nonlinear Optimization. Springer  2000.
[3] S. Boyd and L. Vandenberghe. Convex Optimization. Cambridge U. Press  2004.
[4] M. Collins  S. Dasgupta  and R. Schapire. A generalization of principal component analysis to
the exponential family. In Advances in Neural Information Processing Systems (NIPS)  2001.
[5] R. Fisher. The use of multiple measurements in taxonomic problems. Annals of Eugenics 

7:179–188  1936.

[6] Y. Guo and D. Schuurmans. Convex relaxations of latent variable training. In Advances in

Neural Information Processing Systems (NIPS)  2007.

[7] Y. Guo and D. Schuurmans. Efﬁcient global optimization for exponential family PCA and
low-rank matrix factorization. In Allerton Conf. on Commun.  Control  and Computing  2008.

[8] I. Jolliffe. Principal Component Analysis. Springer Verlag  2002.
[9] N. Lawrence. Probabilistic non-linear principle component analysis with gaussian process

latent variable models. Journal of Machine Learning Research  6:1783–1816  2005.

[10] S. Mika  G. Ratsch  J. Weston  B. Scholkopf  and K. Muller. Fisher discriminant analysis with

kernels. In IEEE Neural Networks for Signal Processing Workshop  1999.

[11] M. Overton and R. Womersley. Optimality conditions and duality theory for minimizing sums

of the largest eigenvalues of symmetric matrices. Math. Prog.  62:321–357  1993.

[12] I. Rish  G. Grabarnilk  G. Cecchi  F. Pereira  and G. Gordon. Closed-form supervised dimen-
sionality reduction with generalized linear models. In Proceedings of International Conference
on Machine Learning (ICML)  2008.

[13] Sajama and A. Orlitsky. Semi-parametric exponential family PCA.

Information Processing Systems (NIPS)  2004.

In Advances in Neural

[14] Sajama and A. Orlitsky. Supervised dimensionality reduction using mixture models. In Pro-

ceedings of the International Conference on Machine Learning (ICML)  2005.

[15] L. Song  A. Smola  K. Borgwardt  and A. Gretton. Colored maximum variance unfolding. In

Advances in Neural Information Processing Systems (NIPS)  2007.

[16] M. Tipping and C. Bishop. Probabilistic principal component analysis. Journal of the Royal

Statistical Society  B  6(3):611–622  1999.

[17] P. Tseng. Convergence of a block coordinate descent method for nondifferentiable minimiza-

tion. Journal of Optimization Theory and Applications  109:457–494  2001.

[18] M. Wainwright and M. Jordan. Graphical models  exponential families  and variational infer-

ence. Technical Report TR-649  UC Berkeley  Dept. Statistics  2003.

[19] S. Yu  K. Yu  V. Tresp  H. Kriegel  and M. Wu. Supervised probabilistic principal component

analysis. In Proceedings of 12th ACM SIGKDD International Conf. on KDD  2006.

,Yin Cheng Ng
Nicolò Colombo
Ricardo Silva