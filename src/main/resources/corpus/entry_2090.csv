2014,Feedforward Learning of Mixture Models,We develop a biologically-plausible learning rule that provably converges to the class means of general mixture models. This rule generalizes the classical BCM neural rule within a tensor framework  substantially increasing the generality of the learning problem it solves. It achieves this by incorporating triplets of samples from the mixtures  which provides a novel information processing interpretation to spike-timing-dependent plasticity. We provide both proofs of convergence  and a close fit to experimental data on STDP.,Feedforward Learning of Mixture Models

Matthew Lawlor∗
Applied Math
Yale University

New Haven  CT 06520

mflawlor@gmail.com

Steven W. Zucker
Computer Science
Yale University

New Haven  CT 06520

zucker@cs.yale.edu

Abstract

We develop a biologically-plausible learning rule that provably converges to the
class means of general mixture models. This rule generalizes the classical BCM
neural rule within a tensor framework  substantially increasing the generality of
the learning problem it solves. It achieves this by incorporating triplets of samples
from the mixtures  which provides a novel information processing interpretation
to spike-timing-dependent plasticity. We provide both proofs of convergence  and
a close ﬁt to experimental data on STDP.

1

Introduction

Spectral tensor methods and tensor decomposition are emerging themes in machine learning  but
they remain global rather than “online.” While incremental (online) learning can be useful for ap-
plications  it is essential for neurobiology. Error back propagation does operate incrementally  but
its neurobiological relevance remains a question for debate. We introduce a triplet learning rule
for mixture distributions based on a tensor formulation of the BCM biological learning rule. It is
implemented in a feedforward fashion  removing the need for backpropagation of error signals.
The triplet requirement is natural biologically. Informally imagine your eyes microsaccading during
a ﬁxation  so that a tiny image fragment is “sampled” repeatedly until the next ﬁxation. Viewed
from visual cortex  edge selective neurons will ﬁre repeatedly.
Importantly  they exhibit strong
statistical dependencies due to the geometry of objects and their relationships in the world. “Hidden”
information such as edge curvatures  the presence of textures  and lighting discontinuities all affect
the probability distribution of ﬁring rates among orientation selective neurons  leading to complex
statistical interdependencies between neurons.
Latent variable models are powerful tools in this context. They formalize the idea that highly coupled
random variables can be simply explained by a small number of hidden causes. Conditioned on these
causes  the input distribution should be simple. For example  while the joint distribution of edges in
a small patch of a scene might be quite complex  the distribution conditioned on the presence of a
curved object at a particular location might be comparatively simple [14]. The speciﬁc question is
whether brains can learn these mixture models  and how.
Example: Imagine a stimulus space of K inputs. These could be images of edges at particular
orientations  or audio tones at K frequencies. These stimuli are fed into a network of n Linear-
Nonlinear Poisson (LNP) spiking neurons. Let rij denote the ﬁring rate of neuron i to stimulus j.
Assuming the stimuli are drawn independently with probability αk  then the number of spikes d in
an interval where a single stimulus is shown is distributed according to a mixture model.

P (d) =

1Now at Google Inc.

αkPk(d)

(cid:88)

k

1

where Pk(d) is a vector of independent Poisson distributions  and the rate parameter of the ith
component is rik. We seek a ﬁlter that responds (in expectation) to one and only one stimulus. To
do this  we must learn a set of weights that are orthogonal to all but one of the vectors of rates r·j.
Each rate vector corresponds to the mean of one of the mixtures. Our problem is thus to learn the
means of mixtures. We will demonstrate that this can be done non-parametrically over a broad class
of ﬁring patterns  not just Poisson spiking neurons.
Although ﬁtting mixture models can be exponentially hard  under a certain multiview assumption 
non-parametric estimation of mixture means can be done by tensor decomposition [2][1]. This
multiview assumption requires access to at least 3 independent copies of the samples; i.e.  multiple
samples drawn from the same mixture component. For the LNP example above  this multiview
assumption requires only that we have access to the number of spikes in three disjoint intervals 
while the stimulus remains constant. After these intervals  the stimulus is free to change – in vision 
say  after a saccade – after which point another sample triple is taken.
Our main result is that  with a slight modiﬁcation of classical Bienenstock-Cooper-Munro [5] synap-
tic update rule a neuron can perform a tensor decomposition of the input data. By incorporating the
interactions between input triplets  our online learning rule can provably learn the mixture means
under an extremely broad class of mixture distributions and noise models.
(The classical BCM
learning rule will not converge properly in the presence of noise.) Speciﬁcally we show how the
classical BCM neuron performs gradient ascent in a tensor objective function  when the data con-
sists of discrete input vectors  and how our modiﬁed rule converges when the data are drawn from a
general mixture model.
The multiview requirement has an intriguing implication for neuroscience. Since spikes arrive in
waves  and spike trains matter for learning [9]  our model suggests that the waves of spikes arriv-
ing during adjacent epochs in time provide multiple samples of a given stimulus. This provides an
unusual information processing interpretation for the functional role of spike trains. To realize it
fully  we point out that classical BCM can be implemented via spike timing dependent plasticity
[17][10][6][18]. However  most of these approaches require much stronger distributional assump-
tions on the input data (generally Poisson)  or learn a much simpler decomposition of the data than
our algorithm. Other  Bayesian methods [16]  require the computation of a posterior distribution
which requires an implausible normalization step. Our learning rule successfully avoids these is-
sues  and has provable guarantees of convergence to the true mixture means. At the end of this
paper we show how our rule predicts pair and triple spike timing dependent plasticity data.

2 Tensor Notation

Let ⊗ denote the tensor product. We denote application of a k-tensor to k vectors by T (w1  ...  wk) 
so in the simple case where T = v1 ⊗ ... ⊗ vk 
(cid:88)

We further denote the application of a k-tensor to k matrices by T (M1  ...  Mk) where

T (w1  ...  wk) =

(cid:104)vj  wj(cid:105)

(cid:89)

j

T (M1  ...  Mk)i1 ... ik =

Tj1 ... jk [M1]j1 i1...[Mk]jk ik

j1 ... jk

Thus if T is a symmetric 2-tensor  T (M1  M2) = M T
Similarly  T (v1  v2) = vT
We say that T has an orthogonal tensor decomposition if

1 T v2.

1 T M2 with ordinary matrix multiplication.

(cid:88)

k

T =

αkvk ⊗ vk ⊗ ... ⊗ vk and (cid:104)vi  vj(cid:105) = δij

3 Connection Between BCM Neuron and Tensor Decompositions

The BCM learning rule was introduced in 1982 in part to correct failings of the classical Hebbian
learning rule [5]. The Hebbian learning rule [11] is one of the simplest and oldest learning rules. It

2

posits that the selectivity of a neuron to input i  mt(i) is increased in proportion to the post-synaptic
activity of that neuron ct = (cid:104)mt−1  dt(cid:105)  where m is a vector of synaptic weights.

mt − mt−1 = γtctdt

This learning rule will become increasingly correlated with its input. As formulated this rule does
not converge for most input  as (cid:107)m(cid:107) → ∞. In addition  in the presence of multiple inputs Hebbian
learning rule will always converge to an “average” of the inputs  rather than becoming selective to
one particular input. It is possible to choose a normalization of m such that m will converge to
the ﬁrst eigenvector of the input data. The BCM rule tries to correct for the lack of selectivity  and
for the stabilization problems. Like the Hebbian learning rule  it always updates its weights in the
direction of the input  however it also has a sliding threshold that controls the magnitude and sign of
this weight update.
The original formulation of the BCM rule is as follows: Let c be the post-synaptic ﬁring rate  d ∈ RN
be the vector of presynaptic ﬁring rates  and m be the vector of synaptic weights. Then the BCM
synaptic modiﬁcation rule is

c = (cid:104)m  d(cid:105)
˙m = φ(c  θ)d

φ is a non-linear function of the ﬁring rate  and θ is a sliding threshold that increases as a superlinear
function of the average ﬁring rate.
There are many different formulations of the BCM rule. The primary features that are required are
φ(c  θ) is convex in c  φ(0  θ) = 0  φ(θ  θ) = 0  and θ is a super-linear function of E[c].
These properties guarantee that the BCM learning rule will not grow without bound. There have
been many variants of this rule. One of the most theoretically well analyzed variants is the Intrator
and Cooper model [12]  which has the following form for φ and θ.
φ(c  θ) = c(c − θ) with θ = E[c2]

Deﬁnition 3.1 (BCM Update Rule). With the Intrator and Cooper deﬁnition  the BCM rule is deﬁned
as

(1)
(cid:80)
t γt → ∞ and(cid:80)
where ct = (cid:104)mt−1  dt(cid:105) and θ = E[c2]. γt is a sequence of positive step sizes with the property that

mt = mt−1 + γtct(ct − θt−1)dt

t γ2

t < ∞

The traditional application of this rule is a system where the input d is drawn from linearly in-
dependent vectors {d1  ...  dk} with probabilities α1  ...  αK  with K = N  the dimension of the
space.
These choices are quite convenient because they lead to the following objective function formulation
of the synaptic update rule.

(cid:104)m  d(cid:105)3(cid:105)
(cid:104)

1
3

E

(cid:104)

(cid:104)m  d(cid:105)2(cid:105)2

1
4

E

−

(cid:104)m  d(cid:105)2 d − E[(cid:104)m  d(cid:105)2](cid:104)m  d(cid:105) d

R(m) =

Thus 

(cid:104)

∇R = E

(cid:105)

= E[c(c − θ)d]
= E[φ(c  θ)d]

So in expectation  the BCM rule performs a gradient ascent in R(m). For random  discrete input
this rule would then be a form of stochastic gradient ascent.
With this model  we observe that the objective function can be rewritten in tensor notation. Note
that this input model can be seen as a kind of degenerate mixture model.

3

This objective function can be written as a tensor objective function  by noting the following:

(cid:88)
(cid:88)

k

k
1
3

T =

M =

R(m) =

αkdk ⊗ dk ⊗ dk

αkdk ⊗ dk

T (m  m  m) −

1
4

M (m  m)2

(2)

For completeness  we present a proof that the stable points of the expected BCM update are selective
for only one of the data vectors.
The stable points of the expected update occur when E[ ˙m] = 0. Let ck = (cid:104)m  dk(cid:105) and φk =
φ(ck  θ). Let c = [c1  . . .   cK]T and Φ = [φ1  . . .   φK]T .

DT = [d1|···|dK]
P = diag(α)

k ek or m = α−1

Theorem 3.2. (Intrator 1992) Let K = N  let each dk be linearly independent  and let αk > 0 and
distinct. Then stable points (in the sense of Lyapunov) of the expected update ˙m = ∇R occur when
k D−1ek. ek is the unit basis vector  so there is activity for only one stimuli.
c = α−1

Proof. E[ ˙m] = DT P Φ which is 0 only when Φ = 0. Note θ =(cid:80)
(cid:88)

ck = θ. Let S+ = {k : ck (cid:54)= 0}  and S− = {k : ck = 0}. Then for all k ∈ S+  ck = βS+

k. φk = 0 if ck = 0 or

−1

(cid:88)

k αkc2

βS+ =

αi = 0

αi

βS+ − β2

S+

k∈S+

k∈S+

Therefore the solutions of the BCM learning rule are c = 1S+βS+  for all subsets S+ ⊂ {1  . . .   K}.
We now need to check which solutions are stable. The stable points (in the sense of Lyapunov) are
points where the matrix

H =

∂E[ ˙m]

∂m

= DT P

(cid:18) ∂Φ

(cid:19) ∂c

∂c

∂m

(cid:18) ∂Φ

(cid:19)

∂c

= DT P

D

is negative semideﬁnite.
Let S be an index set S ⊂ {1  . . .   n}. We will use the following notation for the diagonal matrix
IS:

(cid:26)1

0

(IS)ii =

i ∈ S
i /∈ S

(3)

So IS + ISc = I  and eieT

a quick calculation shows(cid:18) ∂φi

(cid:19)

i = I{i}

= βS+ IS+ − βS+IS− − 2β2

S+ diag(α) 1S+1T
S+

∂cj

This is negative semideﬁnite iff A = IS+ − 2βS+ diag(α) 1S+1T
Assuming a non-degeneracy of the probabilities α  and assume |S+| > 1. Let j = arg mink∈S+ αk.
Then βS+αj < 1
2 so A is not negative semi-deﬁnite. However  if |S+| = 1 then A = −IS+ so the
stable points occur when c = 1
αi

is negative semideﬁnite.

ei

S+

The triplet version of BCM can be viewed as a modiﬁcation of the classical BCM rule which allows
it to converge in the presence of zero-mean noise. This indicates that the stable solutions of this
learning rule are selective for only one data vector  dk.
Building off of the work of [2] we will use this characterization of the objective function to build a
triplet BCM update rule which will converge for general mixtures  not just discrete data points.

4

d1

m1

m2

d2

(a) Geometry of stable solutions. Each stable
solution is selective in expectation for a single
mixture. Note that the classical BCM rule will
not converge to these values in the presence of
noise.

(b) Noise response of triplet BCM update
rule vs BCM update. Input data was a mix-
ture of Gaussians with standard deviation σ.
The selectivity of the triplet BCM rule re-
mains unchanged in the presence of noise.

4 Triplet BCM Rule

We now show that by modifying the update rule to incorporate information from triplets of input
vectors  the generality of the input data can be dramatically increased. Our new BCM rule will learn
selectivity for arbitrary mixture distributions  and learn weights which in expectation are selective
for only one mixture component. Assume that

(cid:88)

P (d) =

αkPk(d)

k

where EPk [d] = dk. For example  the data could be a mixture of axis-aligned Gaussians  a mixture
of independent Poisson variables  or mixtures of independent Bernoulli random variables to name a
few. We also require EPk [(cid:107)d(cid:107)2] < ∞. We emphasize that we do not require our data to come from
any parametric distribution.
We interpret k to be a latent variable that signals the hidden cause of the underlying input distribu-
tion  with distribution Pk. Critically  we assume that the hidden variable k changes slowly compared
to the inter-spike period of the neuron. In particular  we need at least 3 samples from each Pk. This
corresponds to the multi-view assumption of [2]. A particularly relevant model meeting this as-
sumption is that of spike counts in disjoint intervals under a Poisson process  with a discrete  time
varying rate parameter. For the purpose of this paper  we assume the number of mixed distributions 
k  is equal to the number of dimensions  n  however it is possible to relax this to k < n.
Let {d1  d2  d3} be a triplet of independent copies from some Pk(d)  i.e. each are drawn from
the same mixture. It is critical to note that if {d1  d2  d3} are not drawn from the same class  this
update will not converge to the global maximum. Numerical experiments show this assumption can
be violated somewhat without severe changes to the ﬁxed points of the algorithm. Our sample is

then a sequence of triplets  each triplet drawn from the same latent distribution. Let ci =(cid:10)di  m(cid:11).

With these independent triples  we note that the tensors T and M from equation (2) can be written
as moments of the independent triplets

T = E[d1 ⊗ d2 ⊗ d3]
M = E[d1 ⊗ d2]

R(m) =

1
3

T (m  m  m) −

1
4

M (m  m)2

This is precisely the same objective function optimized by the classical BCM update  with the con-
ditional means of the mixture distributions taking the place of discrete data points. With access to
independent triplets  selectivity for signiﬁcantly richer input distributions can be learned.

5

−10−5051015202502468101214(cid:104)m1 d(cid:105)−10−505101520250246810121416182022(cid:104)m2 d(cid:105)10−210−11001010123Noiseσkm−m0kNoisesensitivityofmafter10e6stepsTripletRuleBCMAs with classical BCM  we can perform gradient ascent in this objective function which leads to the
expected update

E[∇R] = E[c1c2d3 + (c1d2 + c2d1)(c3 − 2θ)]

where θ = E[c1c2]. This update is rather complicated  and couples pre and post synaptic ﬁring rates
across multiple time intervals. Since each ci and di are identically distributed  this expectation is
equal to

E[c2(c3 − θ)d1]

which suggests a much simpler update. This ordering was chosen to match the spike timing depen-
dency of synaptic modiﬁcation. This update depends on the presynaptic input  and the postsynaptic
excitation in two disjoint time periods.
Deﬁnition 4.1 (Full-rank Triplet BCM). The full-rank Triplet BCM update rule is:

where φ(c2  c3  θ) = c2(c3 − θ)  the step size γt obeys(cid:80)

(4)
t < ∞. π is a
projection into an arbitrary large compact ball  which is needed for technical reasons to guarantee
convergence.

t γt → ∞  and(cid:80)

mt = π(mt−1 + γtφ(c2  c3  θt−1)d1)

t γ2

5 Stochastic Approximation

Having found the stable points of the expected update for BCM and triplet BCM  we now turn to
a proof of convergence for the stochastic update generated by mixture models. For this  we turn to
results from the theory of stochastic approximation.
We will decompose our update into two parts  the expected update  and the (random) deviation.
This deviation will be a L2 bounded martingale  while the expected update will be a ODE with the
previously calculated stable points. Since the expected update is the gradient of a objective function
R  the Lyapunov functions required for the stability analysis are simply this objective function.
The decomposition of the triplet BCM stochastic process is as follows:

mt − mt−1 = γtφ(c2

t   c3

t   θt−1)d1

= γnE[φ(c2  c3  θt−1)d1] + γn
= γth(mt) − γtηt

(cid:0)φ(c2  c3  θt−1)d1 − E[φ(c2  c3  θt−1)d1](cid:1)

Here  h(mt) is the deterministic expected update  and ηt is a martingale. All our expectations are
taken with respect to triplets of input data. The decomposition for classical BCM is similar.
This is the Doob decomposition [8] of the sequence. Using a theorem of Delyon [7]  we will show
that our triplet BCM algorithm will converge with probability 1 to the stable points of the expected
update. As was shown previously  these stable points are selective for one and only one mixture
component in expectation.
Theorem 5.1. For the full rank case  the projected update converges w.p. 1 to the zeros of ∇Φ
Proof. See supplementary material  or an extended discussion in a forthcoming arXiv preprint [13].

6 Triplet BCM Explains STDP Up to Spike Triplets

Biophysically synaptic efﬁciency in the brain is more closely modeled by spike timing dependent
plasticity (STDP). It depends precisely on the interval between pre- and post-synaptic spikes. Initial
research on spike pairs [15  3] showed that a presynaptic spike followed in close succession by
a postsynaptic spike tended to strengthen a synapse  while the reverse timing weakened it. Later
work on natural spike chains [9]  triplets of spikes [4  19]  and quadruplets have shown interaction
effects beyond pairs. Most closely to ours  recent work by Pﬁster and Gerstner [17] suggested that
a synaptic modiﬁcation function depending only on spike triplets is sufﬁcient to explain all current
experimental data. Furthermore  their rule resembles a BCM learning rule when the pre- and post-
synaptic ﬁring distributions are independent Poisson.

6

We now demonstrate that our learning rule can model both the pairwise and triplet results from
Pﬁster and Gerstner using a smaller number of free parameters and without the introduction of
hidden leaky timing variables. Instead  we work directly with the pre- and post-synaptic voltages 
and model the natural voltage decay during the falling phase of an action potential. Our (four)
free variables are the voltage decay  which we set within reasonable biological limits; a bin width 
controlling the distance between spiking triplet periods; θ  our sliding voltage threshold; and an
overall multiplicative constant. We emphasize that our model was not designed to ﬁt these data; it
was designed to learn selectivity for the multi-view mixture task. Spike timing dependence falls out
as a natural consequence of our multi-view assumption.

Figure 2: Fit of triplet BCM learning rule to synaptic strength STDP curve from [3]. Data points
were recreated from [3] . Spike timing measures the time between post synaptic and presynaptic
spikes  tpost − tpre. A positive time means the presynaptic spike was followed by a postsynaptic
spike.

We ﬁrst model hippocampus data from Mu-ming Poo [3]  who applied repeated electrical stimula-
tion to the pre- and post-synaptic neurons in a pairing protocol within which the relative timing of
the two spike chains was varied. After repeated stimulation at a ﬁxed timing offset  the change in
synaptic strength (postsynaptic current) was measured.
We take the average voltage in triplet intervals to be the measure of pre- and post-synaptic activity 
and consider a one-dimensional version of our synaptic update:

(5)
where c2 and c3 are the postsynaptic voltage averaged over the second and third time bins  and d1
is the presynaptic voltage averaged over the ﬁrst time bin. We assume our pre and post synaptic
voltages are governed by the differential equation:

δm = Ac2(c3 − θ)d1

dV
dt

= −τ V

(6)
such that  if t = sk where sk is the kth spike  V (t) → 1. That is  the voltage is set to 1 at each spike
time before decaying again.
Let Vpre be the presynaptic voltage trace  and Vpost be the postsynaptic voltage trace. They are
determined by the timing of pre- and post-synaptic spikes  which occur at r1  r2  . . .   rn for the
presynaptic spikes  and o1  o2  . . . om for the postsynaptic spikes.
To model the pairwise experiments  we let ri = r0 + iT where T = 1000ms  a large time constant.
Then oi = ri + δt where δt is the spike timing. Let δb be the size of the bins. That is to say 

(cid:90) t+

δb
2

δb
2

t−

Vpre(t(cid:48) + δb)dt(cid:48)

c2(t) =

Vpost(t(cid:48))dt(cid:48)

Vpost(t(cid:48) − δb)dt(cid:48)

Vpost(t) = Vpre(t − δt)

(cid:90) t+
(cid:90) t+

t−

δb
2

δb
2
δb
2

δb
2

t−

d1(t) =

c3(t) =

Then the overall synaptic modiﬁcation is given by

(cid:90)

t

Ac2(t)(c3(t) − θ)d1(t)dt

7

−100−80−60−40−20020406080100−50050100Spike Timing (ms)Change in EPSC Amplitude (%)We ﬁt A  τ  θ  and the bin size of integration. Recall that the sliding threshold  θ is a function of the
expected ﬁring rate of the neuron. Therefore we would not expect it to be a ﬁxed constant. Instead 
it should vary slowly over a time period much longer than the data sampling period. For the purpose
of these experiments it would be at an unknown level that depends on the history of neural activity.
See ﬁgure 2 for the ﬁt for Mu-ming Poo’s synaptic modiﬁcation data.
Froemke and Dan also investigated higher order spike chains  and found that two spikes in short
succession did not simply multiply in their effects. This would be the expected result if the spike
timing dependence treated each pair in a triplet as an independent event. Instead  they found that a
presynaptic spike followed by two postsynaptic spikes resulted in signiﬁcantly less excitation than
expected if the two pairs were treated as independent events. They posited that repeated spikes
interacted suppressively  and ﬁt a model based on that hypothesis. They performed two triplet ex-
periments with pre- pre-post triplets  and pre-post-post triplets. Results of their experiment along
with the predictions based on our model are presented in ﬁgure 3.

Figure 3: Measured excitation and inhibition for spike triplets from Froemke and Dan are demar-
cated in circles and triangles. A red circle or triangle indicates excitation  while a blue circle or
triangle indicates inhibition. The predicted results from our model are indicated by the background
color. Numerical results for our model  with boundaries for the Froemke and Dan model are repro-
duced.
Left ﬁgure is pairs of presynaptic spikes  and a single post-synaptic spike. The right ﬁgure is pairs of
postsynaptic spikes  and a presynaptic spike. For each ﬁgure  t1 measures the time between the ﬁrst
paired spike with the singleton spike  with the convention that each t is positive if the presynaptic
spike happens before the post synaptic spike. See paired STDP experiments for our spiking model.
For the top ﬁgure  θ = .65  our bin width was 2ms  and our spike voltage decay rate τ = 8ms. For
the right ﬁgure θ = .45. Red is excitatory  blue is inhibitory  white is no modiﬁcation. A positive t
indicates a presynaptic spike occurred before a postsynaptic spike.

7 Conclusion

We introduced a modiﬁed formulation of the classical BCM neural update rule. This update rule
drives the synaptic weights toward the components of a tensor decomposition of the input data.
By further modifying the update to incorporate information from triplets of input data  this ten-
sor decomposition can learn the mixture means for a broad class of mixture distributions. Unlike
other methods to ﬁt mixture models  we incorporate a multiview assumption that allows us to learn
asymptotically exact mixture means  rather than local maxima of a similarity measure. This is in
stark contrast to EM and other gradient ascent based methods  which have limited guarantees about
the quality of their results. Conceptually our model suggests a different view of spike waves during
adjacent time epochs: they provide multiple independent samples of the presynaptic “image.”
Due to size constraints  this abstract has has skipped some details  particularly in the experimental
sections. More detailed explanations will be provided in future publications.
Research supported by NSF  NIH  The Paul Allen Foundation  and The Simons Foundation.

8

References
[1] Animashree Anandkumar  Dean P Foster  Daniel Hsu  Sham M Kakade  and Yi-Kai Liu. Two
svds sufﬁce: Spectral decompositions for probabilistic topic modeling and latent dirichlet al-
location. CoRR  abs/1204.6703  1  2012.

[2] Animashree Anandkumar  Rong Ge  Daniel Hsu  Sham M Kakade  and Matus Telgarsky. Ten-
sor decompositions for learning latent variable models. arXiv preprint arXiv:1210.7559  2012.
[3] Guo-qiang Bi and Mu-ming Poo. Synaptic modiﬁcations in cultured hippocampal neurons:
dependence on spike timing  synaptic strength  and postsynaptic cell type. The Journal of
Neuroscience  18(24):10464–10472  1998.

[4] Guo-Qiang Bi and Huai-Xing Wang. Temporal asymmetry in spike timing-dependent synaptic

plasticity. Physiology & behavior  77(4):551–555  2002.

[5] Elie L Bienenstock  Leon N Cooper  and Paul W Munro. Theory for the development of neuron
selectivity: orientation speciﬁcity and binocular interaction in visual cortex. The Journal of
Neuroscience  2(1):32–48  1982.

[6] Natalia Caporale and Yang Dan. Spike timing-dependent plasticity: a hebbian learning rule.

Annual Review Neuroscience  31:25–46  2008.

[7] Bernard Delyon. General results on the convergence of stochastic algorithms. Automatic

Control  IEEE Transactions on  41(9):1245–1255  1996.

[8] Joseph L Doob. Stochastic processes  volume 101. New York Wiley  1953.
[9] Robert C Froemke and Yang Dan. Spike-timing-dependent synaptic modiﬁcation induced by

natural spike trains. Nature  416(6879):433–438  2002.

[10] Julijana Gjorgjieva  Claudia Clopath  Juliette Audet  and Jean-Pascal Pﬁster. A triplet
spike-timing–dependent plasticity model generalizes the bienenstock–cooper–munro rule to
higher-order spatiotemporal correlations. Proceedings of the National Academy of Sciences 
108(48):19383–19388  2011.

[11] DO Hebb. The organization of behavior; a neuropsychological theory. 1949.
[12] Nathan Intrator and Leon N Cooper. Objective function formulation of the bcm theory of visual
cortical plasticity: Statistical connections  stability conditions. Neural Networks  5(1):3–17 
1992.

[13] Matthew Lawlor and Steven S. W. Zucker. An online algorithm for learning selectivity to

mixture means. arXiv preprint  2014.

[14] Matthew Lawlor and Steven W Zucker. Third-order edge statistics: Contour continuation 
curvature  and cortical connections. In Advances in Neural Information Processing Systems 
pages 1763–1771  2013.

[15] WB Levy and O Steward. Temporal contiguity requirements for long-term associative poten-

tiation/depression in the hippocampus. Neuroscience  8(4):791–797  1983.

[16] Bernhard Nessler  Michael Pfeiffer  and Wolfgang Maass. Stdp enables spiking neurons to
detect hidden causes of their inputs. In Advances in neural information processing systems 
pages 1357–1365  2009.

[17] Jean-Pascal Pﬁster and Wulfram Gerstner. Triplets of spikes in a model of spike timing-

dependent plasticity. The Journal of neuroscience  26(38):9673–9682  2006.

[18] Sen Song  Kenneth D Miller  and Larry F Abbott. Competitive hebbian learning through spike-

timing-dependent synaptic plasticity. Nature neuroscience  3(9):919–926  2000.

[19] Huai-Xing Wang  Richard C Gerkin  David W Nauen  and Guo-Qiang Bi. Coactivation and
timing-dependent integration of synaptic potentiation and depression. Nature neuroscience 
8(2):187–193  2005.

9

,Matthew Lawlor
Steven Zucker
Matthias Hein
Maksym Andriushchenko
Amir Dezfouli
Hassan Ashtiani
Omar Ghattas
Richard Nock
Peter Dayan
Cheng Soon Ong