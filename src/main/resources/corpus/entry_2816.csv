2011,Large-Scale Category Structure Aware Image Categorization,Most previous research on image categorization has focused on medium-scale data sets  while large-scale image categorization with millions of images from thousands of categories remains a challenge. With the emergence of structured large-scale dataset such as the ImageNet  rich information about the conceptual relationships between images  such as a tree hierarchy among various image categories  become available. As human cognition of complex visual world benefits from underlying semantic relationships between object classes  we believe a machine learning system can and should leverage such information as well for better performance. In this paper  we employ such semantic relatedness among image categories for large-scale image categorization. Specifically  a category hierarchy is utilized to properly define loss function and select common set of features for  related categories. An efficient optimization method based on proximal approximation and accelerated parallel gradient method is introduced. Experimental results on a subset of ImageNet containing 1.2 million images from 1000 categories demonstrate the effectiveness and promise of our proposed approach.,Large-Scale Category Structure Aware Image

Categorization

Bin Zhao

School of Computer Science
Carnegie Mellon University

Li Fei-Fei

Computer Science Department

Stanford University

Eric P. Xing

School of Computer Science
Carnegie Mellon University

binzhao@cs.cmu.edu

feifeili@cs.stanford.edu

epxing@cs.cmu.edu

Abstract

Most previous research on image categorization has focused on medium-scale
data sets  while large-scale image categorization with millions of images from
thousands of categories remains a challenge. With the emergence of structured
large-scale dataset such as the ImageNet  rich information about the conceptual
relationships between images  such as a tree hierarchy among various image cat-
egories  become available. As human cognition of complex visual world beneﬁts
from underlying semantic relationships between object classes  we believe a ma-
chine learning system can and should leverage such information as well for better
performance. In this paper  we employ such semantic relatedness among image
categories for large-scale image categorization. Speciﬁcally  a category hierarchy
is utilized to properly deﬁne loss function and select common set of features for
related categories. An efﬁcient optimization method based on proximal approxi-
mation and accelerated parallel gradient method is introduced. Experimental re-
sults on a subset of ImageNet containing 1.2 million images from 1000 categories
demonstrate the effectiveness and promise of our proposed approach.

1 Introduction

Image categorization / object recognition has been one of the most important research problems in
the computer vision community. While most previous research on image categorization has focused
on medium-scale data sets  involving objects from dozens of categories  there is recently a growing
consensus that it is necessary to build general purpose object recognizers that are able to recognize
many more different classes of objects.
(A human being has little problem recognizing tens of
thousands of visual categories  even with very little “training” data.) The Caltech 101/256 [14  18]
is a pioneer benchmark data set on that front. LabelMe [31] provides 30k labeled and segmented
images  covering around 200 image categories. Moreover  the newly released ImageNet [12] data
set goes a big step further  in that it further increases the number of classes to over 15000  and has
more than 1000 images for each class on average. Similarly  TinyImage [36] contains 80 million
32 × 32 low resolution images  with each image loosely labeled with one of 75 062 English nouns.
Clearly  these are no longer artiﬁcial visual categorization problems created for machine learning 
but instead more like a human-level cognition problem for real world object recognition with a
much bigger set of objects. A natural way to formulate this problem is a multi-way or multi-task
classiﬁcation  but the seemingly standard formulation on such gigantic data set poses a completely
new challenge both to computer vision and machine learning. Unfortunately  despite the well-known
advantages and recent advancements of multi-way classiﬁcation techniques [1  19  4] in machine
learning  complexity concerns have driven most research on such super large-scale data set back
to simple methods such as nearest neighbor search [6]  least square regression [16] or learning
thousands of binary classiﬁers [24].

1

(a)

(b)

(c)

Figure 1: (a) Image category hierarchy in ImageNet; (b) Overlapping group structure; (3) Semantic relatedness
measure between image categories.
The hierarchical semantic structure stemmed from the WordNet over image categories in the Im-
ageNet data makes it distinctive from other existing large-scale dataset  and it reassembles how
human cognitive system stores visual knowledge. Figure 1(a) shows an example such as a tree
hierarchy  where leaf nodes are individual categories  and each internal node denotes the cluster
of categories corresponding to the leaf nodes in the subtree rooted at the given node. As human
cognition of complex visual world beneﬁts from underlying semantic relationships between object
classes  we believe a machine learning system can and should leverage such information as well for
better performance. Speciﬁcally  we argue that instead of formulating the recognition task as a ﬂat
classiﬁcation problem  where each category is treated equally and independently  a better strategy
is to utilize the rich information residing in the concept hierarchy among image categories to train
a system that couples all different recognition tasks over different categories. It should be noted
that our proposed method is applicable to any tree structure for image category  such as the category
structure learned to capture visual appearance similarities between image classes [32  17  13].
To the best of our knowledge  our attempt in this paper represents an initial foray to systematically
utilizing information residing in concept hierarchy  for multi-way classiﬁcation on super large-scale
image data sets. More precisely  our approach utilizes the concept hierarchy in two aspects: loss
function and feature selection. First  the loss function used in our formulation weighs differentially
for different misclassiﬁcation outcomes: misclassifying an image to a category that is close to its
true identity should receive less penalty than misclassifying it to a totally unrelated one. Second 
in an image classiﬁcation problem with thousands of categories  it is not realistic to assume that
all of the classes share the same set of relevant features. That is to say  a subset of highly re-
lated categories may share a common set of relevant features  whereas weakly related categories
are less likely to be affected by the same features. Consequently  the image categorization problem
is formulated as augmented logistic regression with overlapping-group-lasso regularization. The
corresponding optimization problem involves a non-smooth convex objective function represented
as summation over all training examples. To solve this optimization problem  we introduce the
Accelerated Parallel ProximaL gradiEnT (APPLET) method  which tackles the non-smoothness of
overlapping-group-lasso penalty via proximal gradient [20  9]  and the huge number of training sam-
ples by Map-Reduce parallel computing [10]. Therefore  the contributions made in this paper are:
(1) We incorporate the semantic relationships between object classes  into an augmented multi-class
logistic regression formulation  regularized by the overlapping-group-lasso penalty. The sheer size
of the ImageNet data set that our formulation is designed to tackle singles out our work from previ-
ous attempts on multi-class classiﬁcation  or transfer learning. (2) We propose a proximal gradient
based method for solving the resulting non-smooth optimization problem  where the super large
scale of the problem is tackled by map-reduce parallel computation.
The rest of this paper is organized as follows. Detailed explanation of the formulation is provided in
Section 2. Section 3 introduces the Accelerated Parallel ProximaL gradiEnT (APPLET) method for
solving the corresponding large-scale non-smooth optimization problem. Section 4 brieﬂy reviews
several related works. Section 5 demonstrates the effectiveness of the proposed algorithm using
millions of training images from 1000 categories  followed by conclusions in Section 6.

2 Category Structure Aware Image Categorization

2.1 Motivation

ImageNet organizes the different classes of images in a densely populated semantic hierarchy.
Speciﬁcally  image categories in ImageNet are interlinked by several types of relations  with the

2

 0.10.20.30.40.50.60.70.80.91“IS-A” relation being the most comprehensive and useful [11]  resulting in a tree hierarchy over im-
age categories. For example  the ’husky’ category follows a path in the tree composed of ’working
dog’  ’dog’  ’canine’  etc. The distance between two nodes in the tree depicts the difference between
the two corresponding image categories. Consequently  in the category hierarchy in ImageNet  each
internal node near the bottom of the tree shows that the image categories of its subtree are highly
correlated  whereas the internal node near the root represents relatively weaker correlations among
the categories in its subtree.
The class hierarchy provides a measure of relatedness between image classes. Misclassifying an
image to a category that is close to its true identity should receive less penalty than misclassifying it
to a totally unrelated one. For example  although horses are not exactly ponies  we expect the loss for
classifying a “pony” as a “horse” to be lower than classifying it as a “car”. Instead of using 0-1 loss
as in conventional image categorization  which treats image categories equally and independently 
our approach utilizes a loss function that is aware of the category hierarchy.
Moreover  highly related image categories are more likely to share common visual patterns. For
example  in Figure 1(a)  husky and shepherd share similar object shape and texture. Consequently 
recognition of these related categories are more likely to be affected by the same features. In this
work  we regularize the sparsity pattern of weight vectors for related categories. This is equivalent
to learning a low dimensional representation that is shared across multiple related categories.

2.2 Logistic Regression with Category Structure

Given N training images  each represented as a J-dimensional input vector and belonging to one
of the K categories. Let X denote the J × N input matrix  where each column corresponds to
an instance. Similarly  let Y denote the N × 1 output vector  where each element corresponds
to the label for an image. Multi-class logistic regression deﬁnes a weight vector wk for each class
= arg maxy2f1;:::;kg P (y|x  W)  with the conditional
k ∈ {1  . . .   K} and classiﬁes sample z by y
∑
likelihood computed as

(cid:3)

The optimal weight vectors W

(cid:3)

xi)
k xi)

exp(wT
yi
k exp(wT

P (yi|xi  W) =
(cid:3)
K] are
log P (yi|xi  W) + λΩ(W)

− N∑

(cid:3)
1  . . .   w

= [w

(cid:3)

W

= arg min

W

i=1

(1)

(2)

where Ω(W) is a regularization term deﬁned on W and λ is the regularization parameter.

2.2.1 Augmented Soft-Max Loss Function

Using the tree hierarchy on image categories  we could calculate a semantic relatedness (a.k.a. sim-
ilarity) matrix S ∈ RK(cid:2)K over all categories  where Sij measures the semantic relatedness of class
i and j. Using the semantic relatedness measure  the likelihood of xi belonging to category yi could
be modiﬁed as follows

ˆP (yi|xi  W) ∝ K∑
∑

Syi;rP (r|xi  W) ∝ K∑
∑
ˆP (r|xi  W) = 1  consequently 
∑

ˆP (yi|xi  W) =

K
r=1

r=1

r=1

Since

∑

∑

Syi;r

exp(wT
r xi)
k exp(wT

k xi)

∝ K∑

r=1

K
r=1 Syi;r exp(wT

r xi)
K
k=1 Sk;r exp(wT

r xi)

K
r=1

Syi;r exp(wT

r xi)

(3)

(4)

For the special case where the semantic relatedness matrix S is an identity matrix  meaning each
class is only related to itself  Eq. (4) simpliﬁes to Eq. (1). Using this modiﬁed softmax loss function 
the image categorization problem could be formulated as
− log

(∑

(∑

N∑

∑

)]

+ λΩ(W)

)

Sk;r exp(wT

Syi;r exp(wT

[

(5)

log

r xi)

r xi)

min
W

i=1

r

k

r

3

2.2.2 Semantic Relatedness Matrix

To compute semantic relatedness matrix S in the above formulation  we ﬁrst deﬁne a metric mea-
suring the semantic distance between image categories. A simple way to compute semantic distance
in a structure such as the one provided by ImageNet is to utilize the paths connecting the two corre-
sponding nodes to the root node. Following [7] we deﬁne the semantic distance Dij between class i
and class j as the number of nodes shared by their two parent branches  divided by the length of the
longest of the two branches

Dij =

intersect(path(i)  path(j))

max(length(path(i))  length(path(j)))

(6)

where path(i) is the path from the root node to node i and intersect(p1  p2) counts the number of
nodes shared by two paths p1 and p2. We construct the semantic relatedness matrix S = exp(−κ(1−
D))  where κ is a constant controlling the decay factor of semantic relatedness with respect to
semantic distance. Figure 1(c) shows the semantic relatedness matrix computed with κ = 5.

2.3 Tree-Guided Sparse Feature Coding

In ImageNet  image categories are grouped at multiple granularity as a tree hierarchy. As illustrated
in Section 2.1  the image categories in each internal node are likely to be inﬂuenced by a common set
of features. In order to achieve this type of structured sparsity at multiple levels of the hierarchy  we
utilize an overlapping-group-lasso penalty recently proposed in [21] for genetic association mapping
problem  where the goal is to identify a small number of SNPs (inputs) out of millions of SNPs that
inﬂuence phenotypes (outputs) such as gene expression measurements.
Speciﬁcally  given the tree hierarchy T = (V E) over image categories  each node v ∈ V of tree T
is associated with group Gv  composed of all leaf nodes in the subtree rooted at v  as illustrated in
Figure 1(b). Clearly  each group Gv is a subset of the power set of {1  . . .   K}. Given these groups
G = {Gv}v2V of categories  we deﬁne the following overlapping-group-lasso penalty [21]:

∑

∑

v2V

Ω(W) =

(7)
where wjGv is the weight coefﬁcients {wjk  k ∈ Gv} for input j ∈ {1  . . .   J} associated with cate-
gories in Gv  and each group Gv is associated with weight γv that reﬂects the strength of correlation
within the group. It should be noted that we do not require groups in G to be mutually exclusive 
and consequently  each leaf node would belong to multiple groups at various granularity.
Inserting the above overlapping-group-lasso penalty into (5)  we formulate the category structure
aware image categorization as follows:

j

γv||wjGv

||2

)]

∑

∑

+λ

v2V

j

γv||wj

Gv

||2 (8)

[
N∑

(∑
∑

min
W

log

i=1

r

k

)

−log

(∑

r

Sk;r exp(wT

r xi)

Syi;r exp(wT

r xi)

3 Accelerated Parallel ProximaL gradiEnT (APPLET) Method

The challenge in solving problem (8) lies in two facts: the non-separability of W in the non-smooth
overlapping-group-lasso penalty Ω(W)  and the huge number N of training samples. Convention-
ally  to handle the non-smoothness of Ω(W)  we could reformulate the problem as either second
order cone programming (SOCP) or quadratic programming (QP) [35]. However  the state-of-the-
art approach for solving SOCP and QP based on interior point method requires solving a Newton
system to ﬁnd search direction  and is computationally very expensive even for moderate-sized prob-
lems. Moreover  due to the huge number of samples in the training set  off-the-shelf optimization
solvers are too slow to be used.
In this work  we adopt a proximal-gradient method to handle the non-smoothness of Ω(W). Specif-
ically  we ﬁrst reformulate the overlapping-group-lasso penalty Ω(W) into a max problem over
auxiliary variables using dual norm  and then introduce its smooth lower bound [20  9]. Instead of
optimizing the original non-smooth penalty  we run the accelerated gradient descent method [27]
under a Map-Reduce framework [10] to optimize the smooth lower bound. The proposed approach
enjoys a fast convergence rate and low per-iteration complexity.

4

 (cid:11)1g1

...

(cid:11)1gjGj

A =



. . . (cid:11)Jg1
...
...
. . . (cid:11)JgjGj

3.1 Reformulate the Penalty
For referring convenience  we number the elements in the set G = {Gv}v2V as G = {g1  . . .   gjGj}
according to an arbitrary order  where |G| denotes the total number of elements in G. For each input
∑
∈ Rjgij.
j and group gi associated with wjgi  we introduce a vector of auxiliary variables (cid:11)jgi
Since the dual norm of L2 norm is also an L2 norm  we can reformulate ||wjgi
||2 =
g2G |g| × J matrix
maxjj(cid:11)jgi

wjgi. Moreover  deﬁne the following

||2 as ||wjgi

jj2(cid:20)1 (cid:11)T
jgi

(9)

(11)

in domain O = {A|||(cid:11)jgi
group-lasso penalty in (8) can be equivalently reformulated as

||2 ≤ 1 ∀j ∈ {1  . . .   J}  gi ∈ G}. Following [9]  the overlapping-
∑

∑

γi max

(cid:11)T

Ω(W) =

wjgi = max
A2O

i

j

jgi

jj2(cid:20)1
jj(cid:11)jgi
∑
where i = 1  . . .  |G|  j = 1  . . .   J  C ∈ R
g2G jgj(cid:2)K  and ⟨U  V⟩ = Tr(UT V) is the inner
product of two matrices. Moreover  the matrix C is deﬁned with rows indexed by (s  gi) such that
s ∈ gi and i ∈ {1  . . .  |G|}  columns indexed by k ∈ {1  . . .   K}  and the value of the element at
row (s  gi) and column k set to C(s;gi);k = γi if s = k and 0 otherwise.
After the above reformulation  (10) is still a non-smooth function of W  and this makes the opti-
mization challenging. To tackle this problem  we introduce an auxiliary function [20  9] to construct
a smooth approximation of (10). Speciﬁcally  our smooth approximation function is deﬁned as:

(10)

⟨CWT   A⟩

f(cid:22)(W) = max
A2O

⟨CWT   A⟩ − µd(A)

where µ is the positive smoothness parameter and d(A) is an arbitrary smooth strongly-convex
function deﬁned on O. The original penalty term can be viewed as f(cid:22)(W) with µ = 0. Since our
algorithm will utilize the optimal solution W
F so that we can
(cid:3). Clearly  f(cid:22)(W) is a lower bound of f0(W)  with the gap
obtain the closed form solution for A
computed as D = maxA2O d(A) = maxA2O 1
2
Theorem 1 For any µ > 0  f(cid:22)(W) is a convex and continuously differentiable function in W  and
the gradient of f(cid:22)(W) can be computed as ∇f(cid:22)(W) = A
(cid:3) is the optimal solution
to (11).

(cid:3) to (11)  we choose d(A) = 1

(cid:3)T C  where A

2 J|G|.

||A||2

||A||2

F = 1

2

According to Theorem 1  f(cid:22)(W) is a smooth function for any µ > 0  with a simple form of gradient
and can be viewed as a smooth approximation of f0(W) with the maximum gap of µD. Finally  the
optimal solution A
)  where S is the shrinkage operator
deﬁned as follows:

{

(cid:3) of (11) is composed of (cid:11)
(cid:3)
jgi
ujjujj2
u 

S(u) =

(cid:22)

= S( (cid:13)iwjgi
||u||2 > 1
||u||2 ≤ 1

 

(12)

3.2 Accelerated Parallel Gradient Method

Given the smooth approximation of Ω(W) in (11) and the corresponding gradient presented in The-
orem 1  we could apply gradient descent method to solve the problem. Speciﬁcally  we replace the
overlapping-group-lasso penalty in (8) with its smooth approximation f(cid:22)(W) to obtain the follow-
ing optimization problem

where g(W) =
is the aug-
mented logistic regression loss function. The gradient of g(W) w.r.t. wk could be calculated as
follows

r Syi;r exp(wT

k Sk;r exp(wT

r xi)

r xi)

log

N
i=1

∑

[

min
W

(∑
∑
[ ∑
N∑
∑
∑

r

xi

i=1

r

∂g(W)

∂wk

=

˜f (W) = g(W) + λf(cid:22)(W)

) − log

(∑
∑

− Syi;k exp(wT
r Syi;r exp(wT

k xi)

r xi)

q Sk;q exp(wT

k xi)

q Sr;q exp(wT

r xi)

5

)]
]

(13)

(14)

Therefore  the gradient of g(W) w.r.t. to W could be computed as ∇g(W) = [ @g(W)
According to Theorem 1  the gradient of ˜f (W) is given by
∇ ˜f (W) = ∇g(W) + λA

(cid:3)T C

@w1

  . . .   @g(W)
@wK

].

(15)

Although ˜f (W) is a smooth function of W  it is represented as a summation over all training sam-
ples. Consequently  ∇ ˜f (W) could only be computed by summing over all N training samples. Due
to the huge number of samples in the training set  we adopt a Map-Reduce parallel framework [10]
to compute ∇g(W) as shown in Eq.(14). While standard gradient schemes have a slow conver-
gence rate  they can often be accelerated. This stems from the pioneering work of Nesterov in [27] 
which is a deterministic algorithm for smooth optimization. In this paper  we adopt this accelerated
gradient method   and the whole algorithm is shown in Algorithm 1.

Algorithm 1 Accelerated Parallel ProximaL gradiEnT method (APPLET)
Input: X  Y C  desired accuracy ϵ  step parameters {ηt}
Initialization: B0 = 0
for t = 1  2  . . .  until convergence do
∑
Map-step: Distribute data to M cores {X1  . . .  XM}  compute in parallel ∇gm(Bt(cid:0)1) for Xm
Reduce-step:
(1) ∇ ˜f (Bt(cid:0)1) =
(2) Wt = Bt(cid:0)1 − ηt∇ ˜f (Bt(cid:0)1)
t+2 (Wt − Wt(cid:0)1)
(3) Bt = Wt + t(cid:0)1
end for
Output: ˆW = Wt

∇gm(Bt(cid:0)1) + λA

(cid:3)T C

M
m=1

4 Related Works

Various attempts in sharing information across related image categories have been explored. Early
approaches stem from the neural networks  where the hidden layers are shared across different
classes [8  23]. Recent approaches transfer information across classes by regularizing the parame-
ters of the classiﬁers across classes [37  28  15  33  34  2  26  30]. Common to all these approaches
is that experiments are always performed with relatively few classes [16]. It is unclear how these
approaches would perform on super large-scale data sets containing thousands of image categories.
Some of these approaches would encounter severe computational bottleneck when scaling up to
thousands of classes [16].
Another line of research is the ImageNet Large Scale Visual Recognition Challenge 2010
(ILSVRC10) [3]  where best performing approaches use techniques such as spatial pyramid match-
ing [22]  locality-constrained linear coding [38]  the Fisher vector [29]  and linear SVM trained
using stochastic gradient descent. Success has been witnessed in ILSVRC10 even with simple ma-
chine learning techniques. However  none of these approaches utilize the semantic relationships
deﬁned among image categories in ImageNet  which we argue is a crucial source of information for
further improvement in such super large scale classiﬁcation problem.

5 Experiments

In this section  we test the performance of APPLET on a subset of ImageNet used in ILSVRC10 
containing 1.2 million images from 1000 categories  divided into distinct portions for training  val-
idation and test. The number of images for each category ranges from 668 to 3047. We use the
provided validation set for parameter selection and the ﬁnal results are obtained on the test set.
Before presenting the classiﬁcation results  we’d like to make clear that the goal and contributions
of this work is different from the aforementioned approaches proposed in ILSVRC10. Those ap-
proaches were designed to enter a performance competition  where heavy feature engineering and
post processing (such as ad hoc voting for multiple algorithms) were used to achieve high accuracy.
Our work  on the other hand  looks at this problem from a different angle  focusing on principled

6

methodology that explores the beneﬁt of utilizing class structure in image categorization and propos-
ing a model and related optimization technique to properly incorporate such information. We did
not use the full scope of all the features  and post processing schemes to boost our classiﬁcation
results as the ILSVRC10 competition teams did. Therefore we argue that the results of our work is
not directly comparable with the ILSVRC10 competitions.

5.1

Image Features

Each image is resized to have a max side length of 300 pixels. SIFT [25] descriptors are computed
on 20 × 20 overlapping patches with a spacing of 10 pixels. Images are further downsized to 1
of the side length and then 1
4 of the side length  and more descriptors are computed. We then
perform k-means clustering on a random subset of 10 million SIFT descriptors to form a visual
vocabulary of 1000 visual words. Using this learned vocabulary  we employ Locality-constrained
Linear Coding (LLC) [38]  which has shown state-of-the-art performance on several benchmark data
sets  to construct a vector representation for each image. Finally  a single feature vector is computed
for each image using max pooling on a spatial pyramid [22]. The pooled features from various
locations and scales are then concatenated to form a spatial pyramid representation of the image.
Consequently  each image is represented as a vector in a 21 000 dimensional space.

2

5.2 Evaluation Criteria

We adopt the same performance measures used in ILSVRC10. Speciﬁcally  for every image  each
tested algorithm will produce a list of 5 object categories in the descending order of conﬁdence.
Performance is measured using the top-n error rate  n = 1  . . .   5 in our case  and two error measures
are reported. The ﬁrst is a ﬂat error which equals 1 if the true class is not within the n most conﬁdent
predictions  and 0 otherwise. The second is a hierarchical error  reporting the minimum height of
the lowest common ancestors between true and predicted classes. For each of the above two criteria 
the overall error score for an algorithm is the average error over all test images.

Table 1: Classiﬁcation results (both ﬂat and hierarchical errors) of various algorithms.

LR
ALR

Algorithm Top 1
0.797
0.796
0.786
0.779

GroupLR
APPLET

Flat Error

Top 3
0.678
0.668
0.642
0.634

Top 2
0.726
0.723
0.699
0.698

Top 4
0.639
0.624
0.600
0.589

Top 5
0.607
0.587
0.568
0.565

Top 1
8.727
8.259
7.620
7.208

Hierarchical Error

Top 2
6.974
6.234
5.460
4.985

Top 3
5.997
5.061
4.322
3.798

Top 4
5.355
4.269
3.624
3.166

Top 5
4.854
3.659
3.156
3.012

Figure 2: Left: image classes with highest accuracy. Right: image classes with lowest accuracy.

5.3 Comparisons & Classiﬁcation Results

We have conducted comprehensive performance evaluations by testing our method under differ-
ent circumstances. Speciﬁcally  to better understand the effect of augmenting logistic regression
with semantic relatedness and use of overlapping-group-lasso penalty to enforce group level fea-
ture selection  we study the model adding only augmented logistic regression loss and adding only
overlapping-group-lasso penalty separately  and compare with the APPLET method. We use the
conventional L2 regularized logistic regression [5] as baseline. The algorithms that we evaluated are
listed below: (1)L2 regularized logistic regression (LR) [5]; (2) Augmented logistic regression with
L2 regularization (ALR); (3) Logistic regression with overlapping-group-lasso regularization (Grou-
pLR); (4) Augmented logistic regression with overlapping-group-lasso regularization (APPLET).
Table 1 presents the classiﬁcation results of various algorithms. According to the classiﬁcation
results  we could clearly see the advantage of APPLET over conventional logistic regression  es-
pecially on the top-5 error rate. Speciﬁcally  comparing the top-5 error rate  APPLET outperforms
LR by a margin of 0.04 on ﬂat loss  and a margin of 1.84 on hierarchical loss. It should be noted

7

that hierarchical error is measured by the height of the lowest common ancestor in the hierarchy 
and moving up a level can more than double the number of descendants. Table 1 also compares the
performance of ALR with LR. Speciﬁcally  ALR outperforms LR slightly when using the top-1 pre-
diction results. However  on top-5 prediction results  ALR performs clearly better than LR. Similar
phenomenon is observed when comparing the classiﬁcation results of GroupLR with LR. Moreover 
Figure 2 shows the image categories with highest and lowest classiﬁcation accuracy.
One key reason for introducing the augmented loss function is to ensure that predicted image class
falls not too far from its true class on the semantic hierarchy. Results in Table 2 demonstrate that
even though APPLET cannot guarantee to make the correct prediction on each image  it produces
labels that are closer to the true one than LR  which generates labels far from correct ones.

True class
APPLET

LR

laptop
laptop(0)
laptop(0)

linden

live oak(3)
log wood(3)

gordon setter
Irish setter(2)

alp(11)

gourd
acorn(2)
olive(2)

bullfrog

woodfrog(2)
water snake(9)

volcano
volcano(0)
geyser(4)

odometer
odometer(0)
odometer(0)

earthworm
earthworm(0)

slug(8)

Table 2: Example prediction results of APPLET and LR. Numbers indicate the hierarchical error of the
misclassiﬁcation  deﬁned in Section 5.2.

As shown in Table 1  a systematic reduction in classiﬁcation error using APPLET shows that ac-
knowledging semantic relationships between image classes enables the system to discriminate at
more informative semantic levels. Moreover  results in Table 2 demonstrate that classiﬁcation re-
sults of APPLET can be signiﬁcantly more informative  as labeling a “bullfrog” as “woodfrog” gives
a more useful answer than “water snake”  as it is still correct at the “frog” level.

5.4 Effects of λ and κ on the Performance of APPLET

We present in Figure 3 how categorization performance scales with λ and κ. According to Figure 3 
APPLET achieves lowest categorization error around λ = 0.01. Moreover  the error rate increases

Figure 3: Classiﬁcation results (ﬂat error and hierarchical error) of APPLET with various (cid:21) and (cid:20).

when λ is larger than 0.1  when excessive regularization hampers the algorithm from differentiating
semantically related categories. Similarly  APPLET achieves best performance with κ = 5. When
κ is too small  a large number of categories are mixed together  resulting in a much higher ﬂat loss.
On the other hand  when κ ≥ 50  the semantic relatedness matrix is close to diagonal  resulting in
treating all categories independently  and categorization performance becomes similar as LR.

6 Conclusions

In this paper  we argue the positive effect of incorporating category hierarchy information in super
large scale image categorization. The sheer size of the problem considered here singles out our work
from any previous works on multi-way classiﬁcation or transfer learning. Empirical study using 1.2
million training images from 1000 categories demonstrates the effectiveness and promise of our
proposed approach.

Acknowledgments

E. P. Xing is supported by NSF IIS-0713379  DBI-0546594  Career Award  ONR N000140910758 
DARPA NBCH1080007 and Alfred P. Sloan Foundation. L. Fei-Fei is partially supported by an
NSF CAREER grant (IIS-0845230) and an ONR MURI grant.

8

10−310−210−11001010.550.60.650.70.750.80.850.9LambdaFlat Error Top−1Top−2Top−3Top−4Top−510−310−210−1100101345678910LambdaHierarchical Error Top−1Top−2Top−3Top−4Top−50.55505000.50.550.60.650.70.750.80.850.90.951KappaFlat Error Top−1Top−2Top−3Top−4Top−50.5550500345678910KappaHierarchical Error Top−1Top−2Top−3Top−4Top−5References
[1] B. Bakker and T. Heskes. Task clustering and gating for bayesian multitask learning. JMLR  4:83–99 

[2] E. Bart and S. Ullman. Cross-generalization: learning novel classes from a single example by feature

[3] A. Berg  J. Deng  and L. Fei-Fei. Large scale visual recognition challenge 2010. http://www.image-

2003.

replacement. In CVPR  2005.

net.org/challenges/LSVRC/2010/  2010.

[4] A. Binder  K.-R. Mller  and M. Kawanabe. On taxonomies for multi-class image categorization. IJCV 

[5] C. Bishop. Pattern Recognition and Machine Learning. Springer-Verlag New York  Inc.  2006.
[6] O. Boiman  E. Shechtman  and M. Irani. In defense of nearest-neighbor based image classiﬁcation. In

pages 1–21  2011.

CVPR  2008.

[7] A. Budanitsky and G. Hirst. Evaluating wordnet-based measures of lexical semantic relatedness. Comput.

Linguist.  32:13–47  March 2006.

[8] R. Caruana. Multitask learning. Machine Learning  28:41–75  1997.
[9] X. Chen  Q. Lin  S. Kim  J. Carbonell  and E. P. Xing. Smoothing proximal gradient method for general

structured sparse learning. In UAI  2011.

[10] C. Chu  S. Kim  Y. Lin  Y. Yu  G.  A. Ng  and K. Olukotun. Map-reduce for machine learning on multicore.

In NIPS. 2007.

In ECCV  2010.

[11] J. Deng  A. Berg  K. Li  and L. Fei-Fei. What does classifying more than 10 000 image categories tell us?

[12] J. Deng  W. Dong  R. Socher  L.-J. Li  K. Li  and L. Fei-Fei.

ImageNet: A Large-Scale Hierarchical

Image Database. In CVPR  2009.

scale object recognition. In NIPS  2011.

[13] J. Deng  S. Satheesh  A. Berg  and L. Fei-Fei. Fast and balanced: Efﬁcient label tree learning for large

[14] L. Fei-Fei  R. Fergus  and P. Perona. Learning generative visual models from few training examples: an
incremental bayesian approach tested on 101 object categories. In CVPR Workshop on Generative-Model
Based Vision  2004.

[15] L. Fei-Fei  R. Fergus  and P. Perona. One-shot learning of object categories. PAMI  28:594–611  2006.
[16] R. Fergus  H. Bernal  Y. Weiss  and A. Torralba. Semantic label sharing for learning with many categories.

In ECCV  ECCV’10  2010.

ICCV  2011.

[17] T. Gao and D. Koller. Discriminative learning of relaxed hierarchy for large-scale visual recognition. In

[18] G. Grifﬁn  A. Holub  and P. Perona. Caltech-256 object category dataset. Technical Report 7694  Cali-

fornia Institute of Technology  2007.

[19] L. Jacob  F. Bach  and J.-P. Vert. Clustered multi-task learning: A convex formulation. In NIPS  2008.
[20] R. Jenatton  J. Mairal  G. Obozinski  and F. Bach. Proximal methods for sparse hierarchical dictionary

[21] S. Kim and E. Xing. Tree-guided group lasso for multi-task regression with structured sparsity. In ICML 

learning. In ICML  2010.

2010.

natural scene categories. In CVPR  2006.

Proc. IEEE  86:2278–2324  1998.

[22] S. Lazebnik  C. Schmid  and J. Ponce. Beyond bags of features: Spatial pyramid matching for recognizing

[23] Y. LeCun  L. Bottou  Y. Bengio  and P. Haffner. Gradient-based learning applied to document recognition.

[24] Y. Lin  F. Lv  S. Zhu  M. Yang  T. Cour  K. Yu  L. Cao  and T. Huang. Large-scale image classiﬁcation:

fast feature extraction and svm training. In CVPR  2011.

[25] D. Lowe. Distinctive image features from scale-invariant keypoints. IJCV  60:91–110  2004.
[26] E. Miller  N. Matsakis  and P. Viola. Learning from one example through shared densities on transforms.

In CVPR  2000.

[27] Y. Nesterov. A method for unconstrained convex minimization problem with the rate of convergence

o( 1

k2 ). Doklady AN SSSR (translated as Soviet. Math. Docl.)  269:543–547  1983.

[28] A. Opelt  A. Pinz  and A. Zisserman.

Incremental learning of object detectors using a visual shape

[29] F. Perronnin  J. Sanchez  and T. Mensink. Improving the ﬁsher kernel for large-scale image classiﬁcation.

[30] A. Quattoni  M. Collins  and T. Darrell. Transfer learning for image classiﬁcation with sparse prototype

[31] B. Russell  A. Torralba  K. Murphy  and W. Freeman. Labelme: A database and web-based tool for image

[32] R. Salakhutdinov  A. Torralba  and Josh Tenenbaum. Learning to share visual appearance for multiclass

alphabet. In CVPR  2006.

In ECCV  2010.

representations. In CVPR  2008.

annotation. IJCV  77:157–173  2008.

object detection. In CVPR  2011.

and parts. In CVPR  2005.

12:1247–1283  2000.

[33] E. Sudderth  A. Torralba  W. Freeman  and A. Willsky. Learning hierarchical models of scenes  objects 

[34] J. Tenenbaum and W. Freeman. Separating style and content with bilinear models. Neural Computation 

[35] R. Tibshirani  M. Saunders  S. Rosset  J. Zhu  and K. Knight. Sparsity and smoothness via the fused lasso.

Journal of the Royal Statistical Society Series B  pages 91–108  2005.

[36] A. Torralba  R. Fergus  and W. Freeman. 80 million tiny images: A large data set for nonparametric object

and scene recognition. PAMI  30:1958–1970  2008.

[37] A. Torralba  K. Murphy  and W. Freeman. Sharing features: efﬁcient boosting procedures for multiclass

[38] J. Wang  J. Yang  K. Yu  F. Lv  T. Huang  and Y. Gong. Locality-constrained linear coding for image

object detection. In CVPR  2004.

classiﬁcation. In CVPR  2010.

9

,Joon Hee Choi
S. Vishwanathan