2019,Multi-objective Bayesian optimisation with preferences over objectives,We present a  multi-objective Bayesian optimisation algorithm that allows the user to express preference-order constraints on the objectives of the type objective A is more important than objective B. These preferences are defined based on the stability of the obtained solutions with respect to preferred objective functions. Rather than attempting to find a representative subset of the complete Pareto front  our algorithm selects those Pareto-optimal points that satisfy these constraints. We formulate a new acquisition function based on expected improvement in dominated hypervolume (EHI) to ensure that the subset of Pareto front satisfying the constraints is thoroughly explored. The hypervolume calculation is weighted by the probability of a point satisfying the constraints from a gradient Gaussian Process model. We demonstrate our algorithm on both synthetic and real-world problems.,Multi-objective Bayesian optimisation with

preferences over objectives

Majid Abdolshah  Alistair Shilton  Santu Rana  Sunil Gupta  Svetha Venkatesh

The Applied Artiï¬cial Intelligence Institute (A2I2) 

Deakin University  Australia

{majid alistair.shilton santu.rana sunil.gupta svetha.venkatesh}

@deakin.edu.au

Abstract

We present a multi-objective Bayesian optimisation algorithm that allows the user
to express preference-order constraints on the objectives of the type â€œobjective A
is more important than objective Bâ€. These preferences are deï¬ned based on the
stability of the obtained solutions with respect to preferred objective functions.
Rather than attempting to ï¬nd a representative subset of the complete Pareto front 
our algorithm selects those Pareto-optimal points that satisfy these constraints. We
formulate a new acquisition function based on expected improvement in dominated
hypervolume (EHI) to ensure that the subset of Pareto front satisfying the con-
straints is thoroughly explored. The hypervolume calculation is weighted by the
probability of a point satisfying the constraints from a gradient Gaussian Process
model. We demonstrate our algorithm on both synthetic and real-world problems.

1

Introduction

In many real world problems  practitioners are required to sequentially evaluate a noisy black-box and
expensive to evaluate function f with the goal of ï¬nding its optimum in some domain X. Bayesian
optimisation is a well-known algorithm for such problems. There are a variety of studies such as
hyperparameter tuning [27  13  12]  expensive multi-objective optimisation for Robotics [2  1]  and
experimentation optimisation in product design such as short polymer ï¬ber materials [16].
Multi-objective Bayesian optimisation involves at least two conï¬‚icting  black-box  and expensive to
evaluate objectives to be optimised simultaneously. Multi-objective optimisation usually assumes
that all objectives are equally important  and solutions are found by seeking the Pareto front in the
objective space [4  5  3]. However  in most cases  users can stipulate preferences over objectives. This
information will impart on the relative importance on sections of the Pareto front. Thus using this
information to preferentially sample the Pareto front will boost the efï¬ciency of the optimiser  which
is particularly advantageous when the objective functions are expensive.
In this study  preferences over objectives are stipulated based on the stability of the solutions with
respect to a set of objective functions. As an example  there are scenarios when investment strategists
are looking for Pareto optimal investment strategies that prefer stable solutions for return (objective
1) but more diverse solutions with respect to risk (objective 2) as they can later decide their appetite
for risk. As can be inferred  the stability in one objective produces more diverse solutions for the
other objectives. We believe in many real-world problems our proposed method can be useful in order
to reduce the cost  and improve the safety of experimental design.
Whilst multi-objective Bayesian optimisation for sample efï¬cient discovery of Pareto front is an
established research track [9  18  8  15]  limited work has examined the incorporation of preferences.
Recently  there has been a study [18] wherein given a user speciï¬ed preferred region in objective space 

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

(a)

(b)

(c)

and âˆ‚f1(x)

âˆ‚x

âˆ‚x

Figure 1: (a) Local Pareto optimality for 2 objective example with 1D design space. Local optimality
implies âˆ‚f0(x)
have opposite signs since the weighted sum of gradients of the objectives
âˆ‚x || >
with respect to x must be zero: sT âˆ‚
âˆ‚x ||  so perturbation of x will cause relatively more change in f1 than f0 - i.e. such solutions
|| âˆ‚f0(x)
âˆ‚x || favoring
are (relatively) stable in objective f0. (c) Shows the converse  namely || âˆ‚f0(x)
solutions that are (relatively) stable in objective f1 and diverse in f0.

âˆ‚x f (x) = 0. In (b) we additionally require that || âˆ‚f1(x)

âˆ‚x || > || âˆ‚f1(x)

the optimiser focuses its sampling to derive the Pareto front efï¬ciently. However  such preferences
are based on the assumption of having an accurate prior knowledge about objective space and the
preferred region (generally a hyperbox) for Pareto front solutions. The main contribution of this study
is formulating the concept of preference-order constraints and incorporating that into a multi-objective
Bayesian optimisation framework to address the unavailability of prior knowledge and boosting the
performance of optimisation in such scenarios.
We are formulating the preference-order constraints through ordering of derivatives and incorporating
that into multi-objective optimisation using the geometry of the constraints space whilst needing
no prior information about the functions. Formally  we ï¬nd a representative set of Pareto-optimal
solutions to the following multi-objective optimisation problem:

D(cid:63) âŠ‚ X(cid:63) = argmax
xâˆˆX

f (x)

(1)

subject to preference-order constraints - that is  assuming f = [f0  f1  . . .   fm]  f0 is more important
(in terms of stability) than f1 and so on. Our algorithm aims to maximise the dominated hypervolume
of the solution in a way that the solutions that meet the constraints are given more weights.
To formalise the concept of preference-order constraints  we ï¬rst note that a point is locally Pareto
optimal if any sufï¬ciently small perturbation of a single design parameter of that point does not
simultaneously increase (or decrease) all objectives. Thus  equivalently  a point is locally Pareto
optimal if we can deï¬ne a set of weight vectors such that  for each design parameter  the weighted sum
of gradients of the objectives with respect to that design parameter is zero (see Figure 1a). Therefore 
the weight vectors deï¬ne the relative importance of each objective at that point. Figure 1b illustrates
this concept where the blue box deï¬nes the region of stability for the function f0. Since in this section
the magnitude of partial derivative for f0 is smaller compared to that of f1  the weights required to
satisfy Pareto optimality would need higher weight corresponding to the gradient of f0 compared to
that of f1 (see Figure 1b). Conversely  in Figure 1c  the red box highlights the section of the Pareto
front where solutions have high stability in f1. To obtain samples from this section of the Pareto front 
we need to make the weights corresponding to the gradient of f0 to be smaller to that of the f1.
Our solution is based on understanding the geometry of the constraints in the weight space. We show
that preference order constraints gives rise to a polyhedral proper cone in this space. We show that
for the pareto-optimality condition  it necessitates the gradients of the objectives at pareto-optimal
points to lie in a perpendicular cone to that polyhedral. We then quantify the posterior probability
that any point satisï¬es the preference-order constraints given a set of observations. We show how
these posterior probabilities may be incorporated into the EHI acquisition function [11] to steer the
Bayesian optimiser toward Pareto optimal points that satisfy the preference-order constraint and away
from those that do not.

2

01ğœ•1ğœ•ğ‘¥ğœ•0ğœ•ğ‘¥ğœ•0ğœ•ğ‘¥ğœ•1ğœ•ğ‘¥OR01ğœ•1ğœ•ğ‘¥ğœ•0ğœ•ğ‘¥ğœ•0ğœ•ğ‘¥ğœ•1ğœ•ğ‘¥ğ‘ 0>ğ‘ 1OR01ğœ•0ğœ•ğ‘¥ğœ•1ğœ•ğ‘¥ğœ•1ğœ•ğ‘¥ğœ•0ğœ•ğ‘¥ORğ‘ 1>ğ‘ 02 Notation
Sets are written A  B  C  . . . where R+ is the positive reals  Â¯R+ = R+ âˆª {0}  Z+ = {1  2  . . .} 
and Zn = {0  1  . . .   n âˆ’ 1}. |A| is the cardinality of the set A. Tuples (ordered sets) are denoted
A  B  C  . . .. Distributions are denoted A B C  . . .. column vectors are bold lower case a  b  c  . . ..
Matrices bold upper case A  B  C  . . .. Element i of vector a is ai  and element i  j of matrix A is
Ai j (all indexed i  j = 0  1  . . .). The transpose is denoted aT  AT. I is the identity matrix  1 is a
vector of 1s  0 is a vector of 0s  and ei is a vector e(i)j = Î´ij  where Î´ij is the Kronecker-Delta.
âˆ‡x = [ âˆ‚
]T  sgn(x) is the sign of x (where sgn(0) = 0)  and the indicator function
. . .
is denoted as 1(A).

âˆ‚xnâˆ’1

âˆ‚x0

âˆ‚x1

âˆ‚

âˆ‚

3 Background

3.1 Gaussian Processes
Let X âŠ‚ Rn be compact. A Gaussian process [23] GP(Âµ  K) is a distribution on the function
space f : X â†’ R deï¬ned by mean Âµ : X â†’ R (assumed zero without loss of generality) and
kernel (covariance) K : X Ã— X â†’ R. If f (x) âˆ¼ GP(0  K(x  x(cid:48))) then the posterior of f given D =
{(x(j)  y(j)) âˆˆ RnÃ—R|y(j) = f (x(j))+   âˆ¼ N (0  Ïƒ2)  j âˆˆ ZN}  f (x)|D âˆ¼ N (ÂµD(x)  ÏƒD(x  x(cid:48))) 
where:

ÂµD (x) = kT (x)(cid:0)K + Ïƒ2I(cid:1)âˆ’1
ÏƒD (x  x(cid:48)) = K (x  x(cid:48)) âˆ’ kT (x)(cid:0)K + Ïƒ2I(cid:1)âˆ’1

k (x(cid:48))
and y  k(x) âˆˆ R|D|  K âˆˆ R|D|Ã—|D|  k(x)j = K(x  x(j))  Kjk = K(x(j)  x(k)).
Since differentiation is a linear operation  the derivative of a Gaussian process is also a Gaussian
process [17  22]. The posterior of âˆ‡xf given D is âˆ‡xf (x)|D âˆ¼ N (Âµ(cid:48)D(x)  Ïƒ(cid:48)D(x  x(cid:48)))  where:

(2)

y

Âµ(cid:48)D (x) =(cid:0)âˆ‡xkT (x)(cid:1)(cid:0)K + Ïƒ2I(cid:1)âˆ’1

Ïƒ(cid:48)D (x  x(cid:48)) = âˆ‡xâˆ‡T

x(cid:48)K (x  x(cid:48)) âˆ’(cid:0)âˆ‡xkT (x)(cid:1) (K + Ïƒ2

i I)âˆ’1(cid:0)âˆ‡x(cid:48)kT (x(cid:48))(cid:1)T

y

(3)

3.2 Multi-Objective Optimisation

A multi-objective optimisation problem has the form:

argmax

f (x)

xâˆˆX

(4)
where the components of f : X âŠ‚ Rn â†’ Y âŠ‚ Rm represent the m distinct objectives fi : X â†’ R.
X and Y are called design space and objective space  respectively. A Pareto-optimal solution is
a point x(cid:63) âˆˆ X for which it is not possible to ï¬nd another solution x âˆˆ X such that fi(x) >
fi(x(cid:63)) for all objectives f0  f1  . . . fmâˆ’1. The set of all Pareto optimal solutions is the Pareto set
X(cid:63) = { x(cid:63) âˆˆ X| (cid:64)x âˆˆ X : f (x) (cid:31) f (x(cid:63))} where y (cid:31) y(cid:48) (y dominates y(cid:48)) means y (cid:54)= y(cid:48)  yi â‰¥ y(cid:48)
âˆ€i  and y (cid:23) y(cid:48) means y (cid:31) y(cid:48) or y = y(cid:48).
i
Given observations D = {(x(j)  y(j)) âˆˆ Rn Ã— Rm|y(j) = f (x(j)) +   i âˆ¼ N (0  Ïƒ2
i )}
of f the dominant set Dâˆ— = { (xâˆ—  yâˆ—) âˆˆ D| (cid:64) (x  y) âˆˆ D : y (cid:23) yâˆ—} is the most optimal sub-
set of D (in the Pareto sense). The â€œgoodnessâ€ of D is often measured by the domi-
to some reference point z âˆˆ Rm:
nated hypervolume (S-metric  [31  10]) with respect

yâ‰¥z 1(cid:0)âˆƒy(i) âˆˆ D(cid:12)(cid:12) y(i) (cid:23) y(cid:1) dy. Thus our aim is to ï¬nd the set D that max-

imises the hypervolume. Optimised algorithms exist for calculating hypervolume [29  25]  S(D) 
which is typically calculated by sorting the dominant observations along each axis in objective space
to form a grid. Dominated hypervolume (with respect to z) is then the sum of the hypervolumes of

S (D) = S (Dâˆ—) =(cid:82)
the dominated cells (ck) - i.e. S (D) =(cid:80)

k vol (ck) .

3.3 Bayesian Multi-Objective Optimisation

In the multi-objective case one typically assumes that the components of f are draws from independent
Gaussian processes  i.e. fi(x) âˆ¼ GP(0  K(i)(x  x(cid:48)))  and fi and fi(cid:48) are independent âˆ€i (cid:54)= i(cid:48). A

3

popular acquisition function for multi-objective Bayesian optimisation is expected hypervolume
improvement (EHI). The EHI acquisition function is deï¬ned by:

at ( x| D) = Ef (x)|D [S (D âˆª {(x  f (x))}) âˆ’ S (D)]

(5)

[26  30] and represents the expected change in the dominated hypervolume by the set of observations
based on the posterior Gaussian process.

4 Problem Formulation
Let f : X âŠ‚ Rn â†’ Y âŠ‚ Rm be a vector of m independent draws fi âˆ¼ GP(0  K(i)(x  x)) from zero-
mean Gaussian processes. Assume that f is expensive to evaluate. Our aim is to ï¬nd a representative
set of Pareto-optimal solutions to the following multi-objective optimisation problem:

D(cid:63) âŠ‚ X(cid:63) = argmax
xâˆˆXIâŠ‚X

f (x)

(6)

subject to preference-order constraints. Speciï¬cally  we want to explore only that subset of solutions
XI âŠ‚ X that place more importance on one objective fi0 than objective fi1  and so on  as speciï¬ed
by the (ordered) preference tuple I = (i0  i1  . . . iQ|{i0  i1  . . .} âŠ‚ Zm  ik (cid:54)= ik(cid:48)âˆ€k (cid:54)= k(cid:48))  where
Q âˆˆ Zm is the number of deï¬ned preferences over objectives.

(cid:1) f (x(cid:63)) /âˆˆ Rm

equivalently (cid:0)Î´xTâˆ‡x

4.1 Preference-Order Constraints
Let x(cid:63) âˆˆ int(X)âˆ©X(cid:63) be a Pareto-optimal point in the interior of X. Necessary (but not sufï¬cient  local)
Pareto optimality conditions require that  for all sufï¬ciently small Î´x âˆˆ Rn  f (x(cid:63) + Î´x) (cid:7) f (x)  or 
+ . A necessary (again not sufï¬cient) equivalent condition is that 
for each axis j âˆˆ Zn in design space  sufï¬ciently small changes in xj do not cause all objectives to
simultaneously increase (and/or remain unchanged) or decrease (and/or remain unchanged). Failure of
this condition would indicate that simply changing design parameter xj could improve all objectives 
and hence that x(cid:63) was not in fact Pareto optimal. In summary  local Pareto optimality requires that
âˆ€j âˆˆ Zn there exists s(j) âˆˆ Â¯Rm

+\{0} such that:

sT
(j)

âˆ‚
âˆ‚xj

f (x) = 0

(7)

It is important to note that this is not the same as the optimality conditions that may be derived from
linear scalarisation  as the optimality conditions that arrise from linear scalarisation additionally
require that s(0) = s(1) = . . . = s(nâˆ’1). Moreover (7) applies to all Pareto-optimal points  whereas
linear scalarisation optimisation conditions fail for Pareto points on non-convex regions [28].
Deï¬nition 1 (Preference-Order Constraints) Let I = (i0  i1  . . . iQ|{i0  i1  . . .} âŠ‚ Zm  ik (cid:54)=
ik(cid:48)âˆ€k (cid:54)= k(cid:48)) be an (ordered) preference tuple. A vector x âˆˆ X satisï¬es the associated preference-order
constraint if âˆƒs(0)  s(1)  . . .   s(nâˆ’1) âˆˆ SI such that:

where SI (cid:44)(cid:8) s âˆˆ Â¯Rm

âˆ‚
âˆ‚xj

+\{0}(cid:12)(cid:12) si0 â‰¥ si1 â‰¥ si2 â‰¥ . . .(cid:9) . Further we deï¬ne XI to be the set of all

f (x) = 0 âˆ€j âˆˆ Zn

sT
(j)

x âˆˆ X satisfying the preference-order constraint. Equivalently:

(cid:44)(cid:8) x âˆˆ X|âˆƒs âˆˆ SI  sTx = 0(cid:9) .

XI = {x âˆˆ X| âˆ‚

âˆ‚xj

where SâŠ¥

I

f (x) âˆˆ SâŠ¥

I âˆ€j âˆˆ Zn}

It is noteworthy to mention that (7) and Deï¬nition 1 are the key for calculating the compliance of
a recommended solution with the preference-order constraints. Having deï¬ned preference-order
constraints we then calculate the posterior probability that x âˆˆ XI  and showing how these posterior
probabilities may be incorporated into the EHI acquisition function to steer the Bayesian optimiser
toward Pareto optimal points that satisfy the preference-order constraint. Before proceeding  however 
it is necessary to brieï¬‚y consider the geometry of SI and SâŠ¥
I .

4

I   SI and the vectors a(0)  a(1) for a 2D case where I = (0  1)  so s0 > s1 
I is the union of two sub-spaces.
I implies a solution complying with preference-order constraints. b0 and b1 are the projection
I   it is necessary that âˆƒs âˆˆ SI s.t. vT s = 0 or

Figure 2: Illustration of SâŠ¥
SI is a proper cone representing the preference-order constraints; SâŠ¥
v âˆˆ SâŠ¥
of v over Ëœa(0) and Ëœa(1). In order to satisfy v âˆˆ SâŠ¥
equivalently v = 0 or b0 = ËœaT

(1)v have different signs.

(0)v and b1 = ËœaT

4.2 The geometry of SI and SâŠ¥

I

In the following we assume  w.l.o.g  that the preference-order constraints follows the order of indices
in objective functions (reorder  otherwise)  and that there is at least one constraint.
We now deï¬ne the preference-order constraints by assumption I = (0  1  . . .   Q|Q âˆˆ Zm\{0}) 
where Q > 0. This deï¬nes the sets SI and SâŠ¥
I   which in turn deï¬ne the constraints that must be met
f (x) = 0 âˆ€j âˆˆ Zn
by the gradients of f (x) - either âˆƒs(0)  s(1)  . . .   s(nâˆ’1) âˆˆ SI such that sT
or  equivalently

I âˆ€j âˆˆ Zn. Next  Theorem 1 deï¬nes the representation of SI.

f (x) âˆˆ SâŠ¥

âˆ‚
âˆ‚xj

(j)

âˆ‚
âˆ‚xj

Theorem 1 Let I = (0  1  . . .   Q|Q âˆˆ Zm\{0}) be an (ordered) preference tuple. Deï¬ne SI as per
deï¬nition 1. Then SI is a polyhedral (ï¬nitely-generated) proper cone (excluding the origin) that may
be represented using either a polyhedral representation:

(cid:110)

s âˆˆ Rm| aT

(i)s â‰¥ 0âˆ€i âˆˆ Zm

(cid:12)(cid:12) c âˆˆ Â¯Rm

+

ciËœa(i)

(cid:111)\{0}
(cid:111)\{0}

SI =

or a generative representation:

where âˆ€i âˆˆ Zm:

SI =

a(i) =

Ëœa(i) =

iâˆˆZm

(cid:110) (cid:80)
(cid:26) 1âˆš
(cid:40) 1âˆš

2
ei

ei

(cid:80)

(ei âˆ’ ei+1) if i âˆˆ ZQ
otherwise
if i âˆˆ ZQ+1
otherwise

lâˆˆZi+1

el

i+1

(8)

(9)

and e0  e1  . . .   emâˆ’1 are the Euclidean basis of Rm.

Proof of Theorem 1 is available in the supplementary material. To test if a point satisï¬es this require-
ment we need to understand the geometry of the set SI. The Theorem 1 shows that SIâˆª{0} is a polyhe-
dral (ï¬nitely generated) proper cone  represented either in terms of half-space constraints (polyhedral
form) or as a positive span of extreme directions (generative representation). The geometrical intuition
for this is given in Figure 2 for a simple  2-objective case with a single preference order constraint.

5

Sâ„‘s1Sâ„‘âŠ¥~a(0)Sâ„‘âŠ¥a(0)a(1)~a(1)s0Ve0e1~a(0)b1b0~a(1)~a(0)VAlgorithm 1 Test if v âˆˆ SâŠ¥
I .
Input: Preference tuple I
Test vector v âˆˆ Rm.
Output: 1(v âˆˆ SâŠ¥
I ).
// Calculate 1(v âˆˆ SâŠ¥
I ).
(j)v âˆ€j âˆˆ Zm.
Let bj = ËœaT
if âˆƒi (cid:54)= k âˆˆ Zm : sgn(bi) (cid:54)= sgn(bk) return
TRUE
elseif b = 0 return TRUE
else return FALSE.

Algorithm 2 Preference-Order Constrained
Bayesian Optimisation (MOBO-PC).
Input: preference-order tuple I.
Observations D = {(x(i)  y(i)) âˆˆ X Ã— Y}.
for t = 0  1  . . .   T âˆ’ 1 do

Select the test point:
aPEHI
x = argmax
t

(x|Dt).

xâˆˆX
is evaluated using algorithm 4).

(aPEHI
Perform Experiment y = f (x) + .
Update Dt+1 := Dt âˆª {(x  y)}.

t

end for

Algorithm 3 Calculate Pr(x âˆˆ XI|D).

Algorithm 4 Calculate aPEHI

t

(x|D).

Input: Observations D = {(x(i)  y(i)) âˆˆ
X Ã— Y}.
Number of Monte Carlo samples R.
Test vector x âˆˆ X.
Output: Pr(x âˆˆ XI|D).
Let q = 0.
for k = 0  1  . . .   R âˆ’ 1 do
//Construct samples
v(0)  v(1)  . . .   v(nâˆ’1) âˆˆ Rm.
Let v(j) = 0 âˆ€j âˆˆ Zn.
for i = 0  1  . . .   m âˆ’ 1 do

Sample u âˆ¼ N (Âµ(cid:48)Di(x)  Ïƒ(cid:48)Di(x  x))
(see (3)).
Let [v(0)i  v(1)i  . . .   v(nâˆ’1)i] := uT.

end for
//T est if v(j) âˆˆ SâŠ¥

Let q := q + (cid:81)

I âˆ€j âˆˆ Zn.
1(v(j) âˆˆ SâŠ¥

jâˆˆZn

I ) (see algo

rithm 1).

end for
Return q
R .

Input: Observations D = {(x(i)  y(i)) âˆˆ
X Ã— Y}.
Number of Monte Carlo samples ËœR.
Test vector x âˆˆ X.
Output: aPEHI
Using algorithm 3  calculate:

(x|D).
sx = Pr ( x âˆˆ XI| D)

s(j) = Pr(cid:0) x(j) âˆˆ XI

(cid:12)(cid:12) D(cid:1) âˆ€(cid:0)x(j)  y(j)

(cid:1) âˆˆ D

t

Let q = 0.
for k = 0  1  . . .   ËœR âˆ’ 1 do

Sample yi âˆ¼ N (ÂµDi(x)  ÏƒDi(x))) âˆ€i âˆˆ
Zm (see (2)).
Construct cells c0  c1  . . . from Dâˆª
{(x  y)} by sorting along each axis in
objective space to form a grid.
Calculate:
q = q+

(cid:80)

vol (ck)

jâˆˆZN :y(j)(cid:23)Ëœyck

(cid:81)

(cid:0)1 âˆ’ s(j)

(cid:1)

sx

k:y(cid:23)Ëœyck

end for
Return q/ ËœR.

I . We will use this algorithm to test if âˆ‚
âˆ‚xj

The subsequent corollary allows us to construct a simple algorithm (algorithm 1) to test if a vector v
I âˆ€j âˆˆ Zn - that is  if x satisï¬es
lies in the set SâŠ¥
the preference-order constraints. The proof of corollary 1 is available in the supplementary material.
Corollary 1 Let I = (0  1  . . .   Q|Q âˆˆ Zm\{0}) be an (ordered) preference tuple. Deï¬ne SâŠ¥
I as per
I if and only if v = 0 or âˆƒi (cid:54)= k âˆˆ Zm such that
deï¬nition 1. Using the notation of Theorem 1  v âˆˆ SâŠ¥
sgn(ËœaT

f (x) âˆˆ SâŠ¥

(k)v)  where sgn(0) = 0.

(i)v) (cid:54)= sgn(ËœaT

5 Preference Constrained Bayesian Optimisation

In this section we do two things. First  we show how the Gaussian process models of the objectives
fi (and their derivatives) may be used to calculate the posterior probability that x âˆˆ XI deï¬ned
by I = (0  1  . . .   Q|Q âˆˆ Zm\{0}). Second  we show how the EHI acquisition function may be
modiï¬ed and calculated to incorporate these probabilities and hence only reward points that satisfy
the preference-order conditions. Finally  we give our algorithm using this acquisition function.

5.1 Calculating Posterior Probabilities
Given that fi âˆ¼ GP(0  K(i)(x  x)) are draws from independent Gaussian processes  and
given observations D  we wish to calculate the posterior probability that x âˆˆ XI -

6

i.e.: Pr ( x âˆˆ XI| D) = Pr
âˆ‡xfi(x)|D âˆ¼ Ni (cid:44) N (Âµ(cid:48)Di(x)  Ïƒ(cid:48)Di(x  x(cid:48)))  as deï¬ned by (3). Hence:

I âˆ€j âˆˆ Zn

f (x) âˆˆ SâŠ¥

âˆ‚xj

. As fi âˆ¼ GP(0  K(i)(x  x)) it follows that

Pr ( x âˆˆ XI| D) = Pr

(cid:16) âˆ‚

(cid:17)
ï£«ï£¬ï£¬ï£­v(j) âˆˆ SâŠ¥

âˆ€j âˆˆ Zn

I

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

ï£®ï£¯ï£¯ï£° v(0)i

v(1)i
...

v(nâˆ’1)i

ï£¹ï£ºï£ºï£»âˆ¼ Niâˆ€i âˆˆ Zm

ï£¶ï£·ï£·ï£¸

where v âˆ¼ P (âˆ‡xf|D). We estimate it using Monte-Carlo [6] sampling as per algorithm 3.

5.2 Preference-Order Constrained Bayesian Optimisation Algorithm (MOBO-PC)

Our complete Bayesian optimisation algorithm with Preference-order constraints is given in algorithm
2. The acquisition function introduced in this algorithm gives higher importance to points satisfying
the preference-order constraints. Unlike standard EHI  we take expectation over both the expected
experimental outcomes fi(x) âˆ¼ N (ÂµDi(x)  ÏƒDi(x  x))  âˆ€i âˆˆ Zm  and the probability that points
x(i) âˆˆ XI and x âˆˆ XI satisfy the preference-order constraints. We deï¬ne our preference-based EHI
acquisition function as:

aPEHI
t

( x| D) = E [ SI (D âˆª {(x  f (x))}) âˆ’ SI (D)| D]

(10)
where SI(D) is the hypervolume dominated by the observations (x  y) âˆˆ D satisfying the
preference-order constraints. The calculation of SI(D) is illustrated in the supplementary material.
The expectation of SI(D) given D is:

E [ SI (D)| D] =(cid:80)
=(cid:80)

vol (ck) (1 âˆ’

k

k

(cid:81)

(x y)âˆˆD:y(cid:23)Ëœyck

vol (ck) Pr(âˆƒ (x  y)âˆˆD| y(cid:23) Ëœyck âˆ§ . . . x âˆˆ XI) . . .

(1 âˆ’ Pr ( x âˆˆ XI| D)))

where Ëœyck is the dominant corner of cell ck  vol(ck) is the hypervolume of cell ck  and the cells
ck are constructed by sorting D along each axis in objective space. The posterior probabilities
Pr(x âˆˆ XI|D) are calculated using algorithm 3. It follows that:

( x| D) = Pr ( x âˆˆ XI| D) E(cid:104) (cid:80)

aPEHI
t

(cid:81)

(cid:0)1 âˆ’ Pr(cid:0) x(j) âˆˆ XI

(cid:12)(cid:12) D(cid:1)(cid:1)(cid:12)(cid:12)(cid:12)yi âˆ¼ . . .
(cid:105)

N (ÂµDi (x)   ÏƒDi (x)) âˆ€i âˆˆ Zm
where the cells ck are constructed using the set D âˆª {(x  y)} by sorting along the axis in objective
space.We estimate this acquisition function using Monte-Carlo simulation shown in algorithm 4.

vol (ck)

k:y(cid:23)Ëœyck

jâˆˆZN :y(j)(cid:23)Ëœyck

6 Experiments

We conduct a series of experiments to test the empirical performance of our proposed method
MOBO-PC and compare with other strategies. These experiments including synthetic data as well as
optimizing the hyper-parameters of a feed-forward neural network. For Gaussian process  we use
maximum likelihood estimation for setting hyperparameters [21].

6.1 Baselines

To the best of our knowledge there are no studies aiming to solve our proposed problem  however we
are using PESMO  SMSego  SUR  ParEGO and EHI [9  20  19  14  7] to conï¬rm the validity of the
obtained Pareto front solutions. The obtained Pareto front must be in the ground-truth whilst also
satisfying the preference-order constraints. We compare our results with MOBO-RS [18] by suitably
specifying bounding boxes in the objective space that can replicate a preference-order constraint.

6.2 Synthetic Functions

We begin with a comparison on minimising synthetic function Schaffer function N. 1 with 2 conï¬‚icting
objectives f0  f1 and 1-dimensional input. (see [24]). Figure 3a shows the ground-truth Pareto front

7

(a) Full Pareto front

(b) Case 1  s0 â‰ˆ s1

(c) Case 2  s0 < s1

(d) Case 3  s0 > s1

(e)

(f)

Figure 3: Finding Pareto front which comply with the preference-order constraint. Figure 3a shows
the full Pareto front solution (with no preferences). Figure 3b illustrates the Pareto front by assuming
stability of ï¬rst objective f0 is similar to second objective f1. In Figure 3c  stability of f1 is preferred
over f0. Figure 3d shows more stable results for f0 than f1 (s0 > s1). Figure 3e and 3f shows the
results obtained by MOBO-RS and the corresponding bounding boxes. The gradient color of the
Pareto front points in Figure 3b-3d indicates their degree of compliance with the constraints.

constraints SI (cid:44)(cid:8) s âˆˆ Â¯Rm

+\{0}(cid:12)(cid:12) s0 â‰ˆ s1

for this function. To illustrate the behavior of our method  we impose distinct preferences. Three test
cases are designed to illustrate the effects of imposing preference-order constraints on the objective
functions for stability. Case (1): s0 â‰ˆ s1  Case (2): s0 < s1 and Case (3): s0 > s1. For our method
it is only required to deï¬ne the preference-order constraints  however for MOBO-RS  additional
information as a bounding box is obligatory. Figure 3b (case 1)  shows the results of preference-order

(cid:9) for our proposed method  where s0 represents the

importance of stability in minimising f0 and s1 is the importance of stability in minimising f1. Due to
same importance of both objectives  a balanced optimisation is expected. Higher weights are obtained
for the Pareto front points in the middle region with highest stability for both objectives. Figure
3c (case 2) is based on the preference-order of s0 < s1 that implies the importance of stability in
f1 is more than f0. The results show more stable Pareto points for f1 than f0. Figure 3d (case 3)
shows the results of s0 > s1 preference-order constraint. As expected  we see more number of stable
Pareto points for the important objective (i.e. f0 in this case). We deï¬ned two bounding boxes for
MOBO-RS approach which can represent the preference-order constraints in our approach (Figure
3e and 3f). There are inï¬nite possible bounding boxes can serve as constraints on objectives in
such problems  consequently  the instability of results is expected across the various deï¬nitions of
bounding boxes. We believe our method can obtain more stable Pareto front solutions especially
when prior information is sparse. Also  having extra information as the weight (importance) of the
Pareto front points is another advantage.
Figure 4 illustrates a special test case in which s0 > s1 and s2 > s1  yet no preferences speciï¬ed over
f2 and f0 while minimising Viennet function. The proposed complex preference-order constraint
does not form a proper cone as elaborated in Theorem 1. However  s0 > s1 independently constructs
a proper cone  likewise for s2 > s1. Figure 4a shows the results of processing these two independent
constraints separately  merging their results and ï¬nding the Pareto front. Figure 4b implies more
stable solutions for f0 comparing to f1. Figure 4c shows the Pareto front points comply with s2 > s1.

8

024f0024f1FullPareto024f001234f1MOBOâˆ’PC30Weight024f001234f1MOBOâˆ’PC30Weight024f001234f1MOBOâˆ’PC30Weight01234f001234f1MOBOâˆ’RS3001234f001234f1MOBOâˆ’RS30(a) Obtained Pareto points

(b) Projection of Pareto points in f0
and f1 space

(c) Projection of Pareto points in f1
and f2 space

Figure 4: Finding Pareto front points with partial constraints as speciï¬ed by s0 > s1 and s2 > s1.
Figure 4a shows the 3D plot of the obtained Pareto front points satisfying preference-order constraints
with the color indicating the degree of compliance. Figure 4b illustrates the projection of Pareto
optimal points on f0 Ã— f1 sub-space  and ï¬gure 4c shows the projection on f1 Ã— f2 sub-space.

Figure 5: Average Pareto fronts obtained by proposed method in comparison to other methods. This
experiment deï¬nes s1 > s0 i.e. stability of run time is more important than the error. For MOBO-RS 
[[0.02  0]  [0.03  2]] is an additional information used as bounding box. The other methods do not
incorporate preferences. The results are shown for 100 evaluations of the objectives (left) and 200
evaluations of the objectives (right).
6.3 Finding a Fast and Accurate Neural Network
Next  we train a neural network with two objectives of minimising both prediction error and prediction
time  as per [9]. These are conï¬‚icting objectives because reducing the prediction error generally
involves larger networks and consequently longer testing time. We are using MNIST dataset and the
tuning parameters include number of hidden layers (x1 âˆˆ [1  3])  the number of hidden units per layer
(x2 âˆˆ [50  300])  the learning rate (x3 âˆˆ (0  0.2])  amount of dropout (x4 âˆˆ [0.4  0.8])  and the level
of l1 (x5 âˆˆ (0  0.1]) and l2 (x6 âˆˆ (0  0.1]) regularization. For this problem we assume stability of
f1(time) in minimising procedure is more important than the f0(error). For MOBO-RS method 
we selected [[0.02  0]  [0.03  2]] bounding box to represent an accurate prior knowledge (see Figure
5). The results were averaged over 5 independent runs. Figure 5 illustrates that one can simply ask
for more stable solutions with respect to test time (without any prior knowledge) of a neural network
while optimising the hyperparameters. As all the solutions found with MOBO-PC are in range of
(0  5) test time. In addition  it seems the proposed method ï¬nds more number of Pareto front solutions
in comparison with MOBO-RS.
7 Conclusion
In this paper we proposed a novel multi-objective Bayesian optimisation algorithm with preferences
over objectives. We deï¬ne objective preferences in terms of stability and formulate a common
framework to focus on the sections of the Pareto front where preferred objectives are more stable  as
is required. We evaluate our method on both synthetic and real-world problems and show that the
obtained Pareto fronts comply with the preference-order constraints.
Acknowledgments
This research was partially funded by Australian Government through the Australian Research Council
(ARC). Prof Venkatesh is the recipient of an ARC Australian Laureate Fellowship (FL170100006).

9

f02468f115.015.415.816.216.6f2âˆ’0.10âˆ’0.050.000.050.100.15FullParetopointsParetopoints45505560Weight(Ã—10âˆ’3)12345f015.015.516.016.517.0f1Paretopoints15.015.516.016.517.0f1âˆ’0.10âˆ’0.050.000.050.100.15f2Paretopoints0.0150.0200.0250.030f0(error)051015f1(time)SURâˆ’100PESMOâˆ’100PAREGOâˆ’100SMSEGOâˆ’100MOBOâˆ’PCâˆ’100MOBOâˆ’RSâˆ’1000.0150.0200.0250.030f0(error)051015f1(time)SURâˆ’200PESMOâˆ’200PAREGOâˆ’200SMSEGOâˆ’200MOBOâˆ’PCâˆ’200MOBOâˆ’RSâˆ’200References
[1] Roberto Calandra  Nakul Gopalan  AndrÃ© Seyfarth  Jan Peters  and Marc Peter Deisenroth.
Bayesian gait optimization for bipedal locomotion. In International Conference on Learning
and Intelligent Optimization  pages 274â€“290. Springer  2014.

[2] Roberto Calandra  AndrÃ© Seyfarth  Jan Peters  and Marc Peter Deisenroth. Bayesian optimiza-
tion for learning gaits under uncertainty. Annals of Mathematics and Artiï¬cial Intelligence 
76(1-2):5â€“23  2016.

[3] Kalyanmoy Deb. Multi-objective optimization. In Search methodologies  pages 273â€“316.

Springer  2005.

[4] Kalyanmoy Deb. Multi-objective optimization. In Search methodologies  pages 403â€“449.

Springer  2014.

[5] Kalyanmoy Deb  Samir Agrawal  Amrit Pratap  and Tanaka Meyarivan. A fast elitist non-
dominated sorting genetic algorithm for multi-objective optimization: Nsga-ii. In International
conference on parallel problem solving from nature  pages 849â€“858. Springer  2000.

[6] Pierre Del Moral  Arnaud Doucet  and Ajay Jasra. Sequential monte carlo samplers. Journal of

the Royal Statistical Society: Series B (Statistical Methodology)  68(3):411â€“436  2006.

[7] Michael Emmerich and Jan-willem Klinkenberg. The computation of the expected improve-
ment in dominated hypervolume of pareto front approximations. Rapport technique  Leiden
University  34  2008.

[8] Paul Feliot  Julien Bect  and Emmanuel Vazquez. A bayesian approach to constrained single-and

multi-objective optimization. Journal of Global Optimization  67(1-2):97â€“133  2017.

[9] Daniel HernÃ¡ndez-Lobato  Jose Hernandez-Lobato  Amar Shah  and Ryan Adams. Predictive
In International Conference on

entropy search for multi-objective bayesian optimization.
Machine Learning  pages 1492â€“1501  2016.

[10] Simon Huband  Phil Hingston  Lyndon While  and Luigi Barone. An evolution strategy with
probabilistic mutation for multi-objective optimisation. In Proceedings of the IEEE Congress
on Evolutionary Computation  volume 4  pages 2284â€“2291  2003.

[11] Iris Hupkens  AndrÃ© Deutz  Kaifeng Yang  and Michael Emmerich. Faster exact algorithms for
computing expected hypervolume improvement. In International Conference on Evolutionary
Multi-Criterion Optimization  pages 65â€“79. Springer  2015.

[12] Ilija Ilievski  Taimoor Akhtar  Jiashi Feng  and Christine Annette Shoemaker. Efï¬cient hy-
perparameter optimization for deep learning algorithms using deterministic rbf surrogates. In
Thirty-First AAAI Conference on Artiï¬cial Intelligence  2017.

[13] Aaron Klein  Stefan Falkner  Simon Bartels  Philipp Hennig  and Frank Hutter.

Fast
bayesian optimization of machine learning hyperparameters on large datasets. arXiv preprint
arXiv:1605.07079  2016.

[14] Joshua Knowles. Parego: a hybrid algorithm with on-line landscape approximation for expen-
sive multiobjective optimization problems. IEEE Transactions on Evolutionary Computation 
10(1):50â€“66  2006.

[15] Marco Laumanns and Jiri Ocenasek. Bayesian optimization algorithms for multi-objective
optimization. In International Conference on Parallel Problem Solving from Nature  pages
298â€“307. Springer  2002.

[16] Cheng Li  David RubÃ­n de Celis Leal  Santu Rana  Sunil Gupta  Alessandra Sutti  Stewart
Greenhill  Teo Slezak  Murray Height  and Svetha Venkatesh. Rapid bayesian optimisation for
synthesis of short polymer ï¬ber materials. Scientiï¬c reports  7(1):5683  2017.

[17] A. Oâ€™Hagan. Some bayesian numerical analysis. Bayesian Statistics  7:345â€“363  1992.

10

[18] Biswajit Paria  Kirthevasan Kandasamy  and BarnabÃ¡s PÃ³czos. A ï¬‚exible multi-objective

bayesian optimization approach using random scalarizations. CoRR  abs/1805.12168  2018.

[19] Victor Picheny. Multiobjective optimization using gaussian process emulators via stepwise

uncertainty reduction. Statistics and Computing  25(6):1265â€“1280  2015.

[20] Wolfgang Ponweiser  Tobias Wagner  Dirk Biermann  and Markus Vincze. Multiobjective
optimization on a limited budget of evaluations using model-assisted s-metric selection. In
International Conference on Parallel Problem Solving from Nature  pages 784â€“794. Springer 
2008.

[21] Carl Edward Rasmussen. Gaussian processes in machine learning. In Advanced lectures on

machine learning  pages 63â€“71. Springer  2004.

[22] Carl Edward Rasmussen. Gaussian processes to speed up hybrid monte carlo for expensive

bayesian integrals. Bayesian statistics  7:651â€“659  2008.

[23] Carl Edward Rasmussen and Christopher K. I. Williams. Gaussian Processes for Machine

Learning. MIT Press  2006.

[24] James David Schaffer. Some experiments in machine learning using vector evaluated genetic

algorithms (artiï¬cial intelligence  optimization  adaptation  pattern recognition). 1984.

[25] Alistair Shilton  Santu Rana  Sinil Kumar Gupta  and Svetha Venkatesh. A simple recursive al-
gorithm for calculating expected hypervolume improvement. In BayesOpt2017 NIPS Workshop
on Bayesian Optimisation  2017.

[26] Ofer M. Shir  Michael Emmerich  Thomas Back  and Marc J. J. Vrakking. The application of
evolutionary multi-criteria optimization to dynamic molecular aligment. In Proceedings of 2007
IEEE Congress on Evolutionary Computation  2007.

[27] Jasper Snoek  Hugo Larochelle  and Ryan P Adams. Practical bayesian optimization of machine
learning algorithms. In Advances in neural information processing systems  pages 2951â€“2959 
2012.

[28] Kristof Van Moffaert  Madalina M Drugan  and Ann NowÃ©. Scalarized multi-objective reinforce-
ment learning: Novel design techniques. In Adaptive Dynamic Programming and Reinforcement
Learning (ADPRL)  pages 191â€“199  2013.

[29] Lyndon While  Philip Hingston  Luigi Barone  and Simon Huband. A faster algorithm for
calculating hypervolume. IEEE Transactions on Evolutionary Computation  10(1):29â€“38  2006.

[30] Martin Zaefferer  Thomax Bartz-Beielstein  Boris Naujoks  Tobias Wagner  and Michael Em-
merich. A case study on multi-criteria optimization of an event detection software under limited
budgets. In Proceedings of the 2013 International Conference on Evolutionary Multi-Criterion
Optimization  pages 756â€“770. Springer  2013.

[31] Eckart Zitzler. Evolutionary Algorithms for Multiobjective Optimization: Methods and Applica-

tions. PhD thesis  Swiss Federal Institute of Technology Zurich  1999.

11

,Majid Abdolshah
Alistair Shilton
Santu Rana
Sunil Gupta
Svetha Venkatesh