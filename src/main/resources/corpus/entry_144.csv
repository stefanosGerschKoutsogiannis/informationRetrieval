2019,A New Perspective on Pool-Based Active Classification and False-Discovery Control,In many scientific settings there is a need for adaptive experimental design to guide the process of identifying regions of the search space that contain as many true positives as possible subject to a low rate of false discoveries (i.e. false alarms). Such regions of the search space could differ drastically from a predicted set that minimizes 0/1 error and accurate identification could require very different sampling strategies. Like active learning for binary classification  this experimental design cannot be optimally chosen a priori  but rather the data must be taken sequentially and adaptively in a closed loop. However  unlike classification with 0/1 error  collecting data adaptively to find a set with high true positive rate and low false discovery rate (FDR) is not as well understood. In this paper  we provide the first provably sample efficient adaptive algorithm for this problem. Along the way  we highlight connections between classification  combinatorial bandits  and FDR control making contributions to each.,A New Perspective on Pool-Based Active
Classiﬁcation and False-Discovery Control

{lalitj  jamieson}@cs.washington.edu

Paul G. Allen School of Computer Science & Engineering

Lalit Jain  Kevin Jamieson

University of Washington  Seattle  WA

Abstract

In many scientiﬁc settings there is a need for adaptive experimental design to guide
the process of identifying regions of the search space that contain as many true
positives as possible subject to a low rate of false discoveries (i.e. false alarms).
Such regions of the search space could differ drastically from a predicted set
that minimizes 0/1 error and accurate identiﬁcation could require very different
sampling strategies. Like active learning for binary classiﬁcation  this experimental
design cannot be optimally chosen a priori  but rather the data must be taken
sequentially and adaptively. However  unlike classiﬁcation with 0/1 error  collecting
data adaptively to ﬁnd a set with high true positive rate and low false discovery
rate (FDR) is not as well understood. In this paper we provide the ﬁrst provably
sample efﬁcient adaptive algorithm for this problem. Along the way we highlight
connections between classiﬁcation  combinatorial bandits  and FDR control making
contributions to each.

1

Introduction

As machine learning has become ubiquitous in the biological  chemical  and material sciences  it
has become irresistible to use these techniques not only for making inferences about previously
collected data  but also for guiding the data collection process  closing the loop on inference and
data collection [10  38  41  39  33  31]. However  though collecting data randomly or non-adaptively
can be inefﬁcient  ill-informed ways of collecting data adaptively can be catastrophic: a procedure
could collect some data  adopt an incorrect belief  collect more data based on this belief  and leave
the practitioner with insufﬁcient data in the right places to infer anything with conﬁdence.
In a recent high-throughput protein synthesis experiment [33]  thousands of short amino acid se-
quences (length less than 60) were evaluated with the goal of identifying and characterizing a subset
of the pool of all possible sequences ( ≈ 1080) containing many sequences that will fold into stable
proteins. That is  given an evaluation budget that is just a minuscule proportion of the total number
of sequences  the researchers sought to make predictions about individual sequences that would
never be evaluated. An initial ﬁrst round of sequences uniformly sampled from a predeﬁned subset
were synthesized to observe whether each sequence was in the set of sequences that will fold  H1 
or in H0 = Hc
1. Treating this as a classiﬁcation problem  a linear logistic regression classiﬁer was
trained  using these labels and physics based features. Then a set of sequences to test in the next
round were chosen to maximize the probability of folding according to this empirical model - a
procedure repeated twice more. This strategy suffers two ﬂaws. First  selecting a set to maximize
the likelihood of hits given past rounds’ data is effectively using logistic regression to perform
optimization similar to follow-the-leader strategies [14]. While more of the sequences evaluated
may fold  these observations may provide little information about whether sequences that were not
evaluated will fold or not. Second  while it is natural to employ logistic regression or the SVM

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

Figure 1: The distribution of a feature that is highly correlated with the ﬁtted logistic model (bottom plot) and
the proportion of sequences that fold (top plot). The distribution of this feature for the sequences drifts right.
to discriminate between binary outcomes (e.g.  fold/not-fold)  in many scientiﬁc applications the
property of interest is incredibly rare and an optimal classiﬁer will just predict a single class e.g.
not fold. This is not only an undesirable inference for prediction  but a useless signal for collecting
data to identify those regions with higher  but still unlikely  probabilities of folding. Consider the
data of [33] reproduced in Figure 1  where the proportion of sequences that fold along with their
distributions for a particularly informative feature (Buried NPSA) are shown in each round for two
different protein topologies (notated βαββ and ααα). In the last column of Figure 1  even though
most of the sequences evaluated are likely to fold  we are sampling in a small part of the overall
search space. This limits our overall ability to identify under-explored regions that could potentially
contain many sequences that fold  even though the logistic model does not achieve its maximum
there. On the other hand  in the top plot of Figure 1  sequences with topology βαββ (shown in blue)
so rarely folded that a near-optimal classiﬁer would predict “not fold” for every sequence.
Instead of using a procedure that seeks to maximize the probability of folding or classifying sequences
as fold or not-fold  a more natural objective is to predict a set of sequences π in such a way as to
maximize the true positive rate (TPR) |H1 ∩ π|/|H1| while minimizing the false discovery rate (FDR)
i.e. |H0 ∩ π|/|π|. That is  π is chosen to contain a large number of sequences that fold while the
proportion of false-alarms among those predicted is relatively small. For example  if a set π for βαββ
was found that maximized TPR subject to FDR being less than 9/10 then π would be non-empty
with the guarantee that at least one in every 10 suggestions was a true-positive; not ideal  but making
the best of a bad situation. In some settings  such as for topology ααα (shown in orange)  training
a classiﬁer to minimize 0/1 loss may be reasonable. Of course  before seeing any data we would
not know whether classiﬁcation is a good objective so it is far more conservative to optimize for
maximizing the number of discoveries.
Contributions. We propose the ﬁrst provably sample-efﬁcient adaptive sampling algorithm for
maximizing TPR subject to an FDR constraint. This problem has deep connections to active binary
classiﬁcation (e.g.  active learning) and pure-exploration for combinatorial bandits that are necessary
steps towards motivating our algorithm. We make the following contributions:
1. We improve upon state of the art sample complexity for pool-based active classiﬁcation in the
agnostic setting providing novel sample complexity bounds that do not depend on the disagreement-
coefﬁcient for sampling with or without replacement. Our bounds are more granular than previous
results as they describe the contribution of a single example to the overall sample complexity.

2. We highlight an important connection between active classiﬁcation and combinatorial bandits.
Our results follow directly from our improvements to the state of the art in combinatorial bandits 
extending methods to be near-optimal for classes that go beyond matroids where one need not
sample every arm at least once.

3. Our main contribution is the development and analysis of an adaptive sampling algorithm that
minimizes the number of samples to identify the set that maximizes the true positive rate subject
to a false discovery constraint. To the best of our knowledge  this is the ﬁrst work to demonstrate a
sample complexity for this problem that is provably better than non-adaptive sampling.

1.1 Pool Based Classiﬁcation and FDR Control

Here we describe what is known as the pool-based setting for active learning with stochastic labels.
Throughout the following we assume access to a ﬁnite set of items [n] = {1 ···   n} with an
associated label space {0  1}. The items can be ﬁxed vectors {xi}n
i=1 ∈ Rd but we do not restrict

2

20304050600.00.51.0Proportion FoldingRound 120304050600.00.51.0Round 220304050600.00.51.0Round 320304050600.00.51.0Round 42030405060Buried NPSA (Å/res)0.000.050.10Distribution2030405060Buried NPSA (Å/res)0.000.050.102030405060Buried NPSA (Å/res)0.000.050.102030405060Buried NPSA (Å/res)0.000.050.10to this case. Associated to each i ∈ [n] there is a Bernoulli distribution Ber(ηi) with ηi ∈ [0  1].
We imagine a setting where in each round a player chooses It ∈ [n] and observes an independent
random variable YIt t. For any i  Yi t ∼ Ber(ηi) are i.i.d. Borrowing from the multi-armed bandit
literature  we may also refer to the items as arms  and pulling an arm is receiving a sample from
its corresponding label distribution. We will refer to this level of generality as the stochastic noise
setting. The case when ηi ∈ {0  1}  i.e. each point i ∈ [n] has a deterministic label Yi j = ηi
for all j ≥ 1  will be referred to as the persistent noise setting. In this setting we can deﬁne
H1 = {i : ηi = 1} H0 = [n] \ H1. This is a natural setting if the experimental noise is negligible
so that performing the same measurement multiple times gives the same result. A classiﬁer is a
decision rule f : [n] → {0  1} that assigns each item i ∈ [n] a ﬁxed label. We can identify any such
decision rule with the set of items it maps to 1  i.e. the set π = {i : i ∈ [n]  f (i) = 1}. Instead of
considering all possible sets π ⊂ [n]  we will restrict ourselves to a smaller class Π ⊂ 2[n]. With this
interpretation  one can imagine Π being a combinatorial class  such as the collection of all subsets of
[n] of size k  or if we have features  Π could be the sets induced by the set of all linear separators
over {xi}.
The classiﬁcation error  or risk of a classiﬁer is given by the expected number of incorrect labels  i.e.

R(π) = Pi∼Unif([n]) Yi∼Ber(ηi) (π(i) (cid:54)= Yi) =

1
n

(

ηi +

(cid:88)

i(cid:54)∈π

(cid:88)

(1 − ηi))

i∈π
|π∩H0|+|πc∩H1|

n

for any π ∈ Π. In the case of persistent noise the above reduces to R(π) =
where A∆B = (A ∪ B) − (A ∩ B) for any sets A  B.

|H1∆π|

n

=

Problem 1:(Classiﬁcation) Given a hypothesis class Π ⊆ 2[n] identify π∗ := argmin
π∈Π
requesting as few labels as possible.

R(π) by

alarms π ∩ H0. Deﬁne ηπ :=(cid:80)

As described in the introduction  in many situations we are not interested in ﬁnding the lowest risk
classiﬁer  but instead returning π ∈ Π that contains many discoveries π ∩ H1 without too many false
i∈π ηx. The false discovery rate (FDR) and true positive rate (TPR)

of a set π in the stochastic noise setting are given by

F DR(π) := 1 − ηπ|π|

T P R(π) :=

and
|π| = 1 − |H1∩π|
|H0∩π|
|π|

ηπ
η[n]
and T P R(π) =

In the case of persistent noise  F DR(π) =
. A
convenient quantity that we can use to reparametrize these quantities is the true positives: T P (π) :=

(cid:80)
i∈π ηi. Throughout the following we let Πα = {π ∈ Π : F DR(π) ≤ α}.
Problem 2:(Combinatorial FDR Control) Given an α ∈ (0  1) and hypothesis class Π ⊆ 2[n]
identify π∗

T P R(π) by requesting as few labels as possible.

argmax

|H1∩π|
|H1|

α =

π∈Π F DR(π)≤α

In this work we are agnostic about how η relates to Π  ala [2  20]. For instance we do not assume the
Bayes classiﬁer  argminB∈{0 1}n R(B) is contained in Π.

2 Related Work

Active Classiﬁcation. Active learning for binary classiﬁcation is a mature ﬁeld (see surveys [36  25]
and references therein). The major theoretical results of the ﬁeld can coarsely be partitioned into the
streaming setting [2  6  20  26] and the pool-based setting [19  24  32]  noting that algorithms for the
former can be used for the latter  [2]  an inspiration for our algorithm  is such an example. These
results rely on different complexity measures known as the splitting index  the teaching dimension 
and (arguably the most popular) the disagreement coefﬁcient.
Computational Considerations. While there have been remarkable efforts to make some of these
methods more computationally efﬁcient [6  26]  we believe even given inﬁnite computation  many of
these previous works are fundamentally inefﬁcient from a sample complexity perspective. This stems
from the fact that when applied to common combinatorial classes (for example the collection of all
subsets of size k)  these algorithms have sample complexities that are off by at least log(n) factors
from the best algorithms for these classes. Consequently  in our work we focus on sample complexity
alone  and leave matters of computational efﬁciency for future work.

3

Other Measures. Given a static dataset  the problem of ﬁnding a set or classiﬁer that maximizes
TPR subject to FDR-control in the information retrieval community is also known as ﬁnding a
binary classiﬁer that maximizes recall for a given precision level. There is extensive work on the
non-adaptive sample complexity of computing measures related to precision and recall such as AUC 
and F-scores [35  9  1]. However  there have been just a few works that consider adaptively collecting
data with the goal of maximizing recall with precision constraints [34  5]  with the latter work being
the most related. We will discuss it further after the statement of our main result. In [34]  the problem
of adaptively estimating the whole ROC curve for a threshold class is considered under a monotonicity
assumption on the true positives; our algorithm is agnostic to this assumption.
Combinatorial Bandits: The pure-exploration combinatorial bandit game has been studied for the
case of all subsets of [n] of size k known as the Top-K problem [22  29  30  28  37  17]  the bases of a
rank-k matroid (for which Top-K is a particular instance) [18  23  15]  and in the general case [11  16].
The combinatorial bandit component of our work (see Section 3.2) is closest to [11]. The algorithm
of [11] uses a disagreement-based algorithm in the spirit of Successive Elimination for bandits [22] 
or the A2 for binary classiﬁcation [2]. Exploring precisely what log factors are necessary has been an
active area. [16] demonstrates a family of instances in which they show in the worst-case  the sample
complexity must scale with log(|Π|). However  there are many classes like best-arm identiﬁcation
and matroids where sample complexity does not scale with log(|Π|) (see references above). Our own
work provides some insight into what log factors are necessary by presenting our results in terms
of VC dimension. In addition  we discuss situtations when a log(n) could potentially be avoided by
appealing to Sauer’s lemma in the supplementary material.
Multiple Hypothesis Testing. Finally  though this work shares language with the adaptive multiple-
hypothesis testing literature [12  27  42  40]  the goals are different. In that setting  there is a set of
n hypothesis tests  where the null is that the mean of each distribution is zero and the alternative is
that it is nonzero. [27] designs a procedure that adaptively allocates samples and uses the Benjamini-
Hochberg procedure [4] on p-values to return an FDR-controlled set. We are not generally interested
in ﬁnding which individual arms have means that are above a ﬁxed threshold  but instead  given a
hypothesis class we want to return an FDR controlled set in the hypothesis class with high TPR. This
is the situation in many structured problems in scientiﬁc discovery where the set of arms corresponds
to an extremely large set of experiments and we have feature vector associated with each arm. We
can’t run each one but we may have some hope of identifying a region of the search space which
contains many discoveries. In summary  unlike the setting of [27]  Π encodes structure among the
sets  we do not insist each item is sampled  and we are allowing for persistent labels - overall we are
solving a different and novel problem.

3 Pool Based Active Classiﬁcation

µi

i=1

1
n

i=1

ηi +

1
n

R(π) =

ηi − 1
n

R(π) = argmax

π∈Π

(cid:88)

i∈π

(cid:88)

i∈π

We ﬁrst establish a pool based active classiﬁcation algorithm that motivates our development of an
adaptive algorithm for FDR-control. For each i deﬁne µi := 2ηi − 1 ∈ [−1  1] so ηi = 1+µi
. By a
simple manipulation of the deﬁnition of R(π) above we have

2

(2ηi − 1) =

n(cid:88)
(cid:80)
i∈π µi. Deﬁne µπ :=(cid:80)

n(cid:88)
1
n
i∈π µi. If for some i ∈ [n] we map the jth
so that argmin
π∈Π
draw of its label Yi j (cid:55)→ 2Yi j − 1  then E[2Yi j − 1] = µi and returning an optimal classiﬁer in the
set is equivalent to returning π ∈ Π with the largest µπ. Algorithm 1 exploits this.
The algorithm maintains a collection of active sets Ak ⊆ Π and an active set of items Tk ⊆ [n] which
is the symmetric difference of all sets in Ak. To see why we only sample in Tk  if i ∈ ∩π∈Ak π then
(cid:98)µπ −(cid:98)µπ(cid:48) =(cid:98)µπ\π(cid:48) −(cid:98)µπ(cid:48)\π for all π  π(cid:48) ∈ Ak so we should not pay to sample it. In each round sets
π and π(cid:48) agree on the label of item i  and any contribution of arm i is canceled in each difference
(cid:80)t
π with lower empirical means that fall outside of the conﬁdence interval of sets with higher empirical
estimator(cid:98)µπ(cid:48) k −(cid:98)µπ k = n
means are removed. There may be some concern that samples from previous rounds are reused. The
s=1 RIt s(1(Is ∈ π(cid:48) \ π) − 1(Is ∈ π \ π(cid:48))) depends on all t samples
up to the t-th round  each of which is uniformly and independently drawn at each step. Thus each
summand is an unbiased estimate of µπ(cid:48) − µπ. However  for π  π(cid:48) active in round k  as explained

t

4

It ∈ Tk so the estimate of(cid:98)µπ(cid:48) k −(cid:98)µπ k is unbiased.
above  a summand is only non-zero if Is ∈ π∆π(cid:48) ⊂ Tk hence we only need to observe RIt s if

In practice  since the number of samples that land in Tk follow a binomial distribution  instead of
using rejection sampling we could instead have drawn a single sample from a binomial distribution
and sampled that many uniformly at random from Tk.

Input: δ  Π ⊂ 2[n]  Conﬁdence bound C(π(cid:48)  π  t  δ).
Let A1 = Π  T1 = (∪π∈A1 π) − (∩π∈A1 π)  k = 1  Ak will be the active sets in round k
for t = 1  2 ···
if t == 2k:

Set δk = .5δ/k2. For each π  π(cid:48) let

s=1 RIs s1{Is ∈ π(cid:48) \ π} −(cid:80)t
t ((cid:80)t
(cid:98)µπ(cid:48) k −(cid:98)µπ k = n
Set Ak+1 = Ak −(cid:8)π ∈ Ak : ∃π
Set Tk+1 =(cid:0)∪π∈Ak+1 π(cid:1) −(cid:0)∩π∈Ak+1 π(cid:1).

(cid:48) ∈ Akwith(cid:98)µπ(cid:48) k −(cid:98)µπ k > C(π

s=1 RIs s1{Is ∈ π \ π(cid:48)})

  π  t  δk)(cid:9).

(cid:48)

k ← k + 1

endif
Stochastic Noise:

Persistent Noise:

If Tk = ∅  Break. Otherwise  draw It uniformly at random from [n] and if It ∈ Tk receive an
associated reward RIt t = 2YIt t − 1  YIt t
If Tk = ∅ or t > n  Break. Otherwise  draw It uniformly at random from [n] \ {Is : 1 ≤ s < t}
and if It ∈ Tk receive associated reward RIt t = 2YIt t − 1  YIt t = ηIt.

iid∼ Ber(ηIt ).
Output: π(cid:48) ∈ Ak such that(cid:98)µπ(cid:48) k −(cid:98)µπ k ≥ 0 for all π ∈ Ak \ π(cid:48)
For any A ⊆ 2[n] deﬁne V (A) as the VC-dimension of a collection of sets A. Given a family of sets 
Π ⊆ 2[n]  deﬁne B1(k) := {π ∈ Π : |π| = k}  B2(k  π(cid:48)) := {π ∈ Π : |π∆π(cid:48)| = k}. Also deﬁne
the following complexity measures:

Algorithm 1: Action Elimination for Active Classiﬁcation

Vπ := V (B1(|π|)) ∧ |π| and Vπ π(cid:48) := max{V (B2(|π∆π(cid:48)|  π)  V (B2(|π∆π(cid:48)|  π(cid:48)))} ∧ |π∆π(cid:48)|

In general Vπ  Vπ π(cid:48) ≤ V (Π). A contribution of our work is the development of conﬁdence intervals
that do not depend on a union bound over the class but instead on local VC dimensions. These are
described carefully in Lemma 1 in the supplementary materials.
Theorem 1 For each i ∈ [n] let µi ∈ [−1  1] be ﬁxed but unknown and assume {Ri j}∞
|µπ − µπ∗|/|π∆π∗|  and

i.i.d sequence of random variables such that E[Ri j] = µi and Ri j ∈ [−1  1]. Deﬁne (cid:101)∆π =

j=1 is an

(cid:16)

n log((cid:101)∆−2

(cid:17)

log

π )/δ

.

τπ =

1(cid:101)∆2
(cid:113) 8|π∆π(cid:48)|nVπ π(cid:48) log( n

Vπ π∗
|π∗∆π|

π

i=1 min{1  maxπ∈Π:i∈π∆π∗ τπ}

Using C(π  π(cid:48)  t  δ) :=
for a ﬁxed constant c  with probability
greater than 1 − δ  in the stochastic noise setting Algorithm 1 returns π∗ after a number of samples
i=1 maxπ∈Π:i∈π∆π∗ τπ and in the persistent noise setting the number of samples

δ )

4nVπ π(cid:48) log( n
δ )

+

3t

t

no more than c(cid:80)n
needed is no more than c(cid:80)n
Heuristically  the expression 1/|π∆π∗|(cid:101)∆2

π roughly captures the number of times we would have to
sample each i ∈ π∆π∗ to ensure that we can show µπ∗ > µπ. Thus in the more general case  we
may expect that we can stop pulling a speciﬁc i once each set π such that i ∈ π∆π∗ is removed -
accounting for the expression maxπ∈Π i∈π∆π∗ τπ. The VC-dimension and the logarithmic term in
τπ is discussed further below and primarily comes from a careful union bound over the class Π. One
always has 1/|π∗∆π| ≤ Vπ π∗ /|π∗∆π| ≤ 1 and both bounds are achievable by different classes Π.

In addition  in terms of risk(cid:101)∆π = |µπ − µπ∗|/|π∆π∗| = n|R(π)− R(π∗)|/|π∆π∗|. Since sampling

is done without replacement for persistent noise  there are improved conﬁdence intervals that one
can use in that setting described in Lemma 1 in the supplementary materials. Finally  if we had
sampled non-adaptively  i.e. without rejection sampling  we would have had a sample complexity of
O(n maxi∈[n] maxπ:Π:i∈π∆π∗ τπ).

5

3.1 Comparison with previous Active Classiﬁcation results.

|π∆π∗| 1(cid:101)∆2

π

2 + sign(z−i/n)

2

= [i] and takes a value of(cid:0) 1+α

One Dimensional Thresholds: In the bound of Theorem 1  a natural question to ask is whether
the log(n) dependence can be improved. In the case of nested classes  such as thresholds on a
line  we can replace the log(n) with a log log(n) using empirical process theory. This leads to
conﬁdence intervals dependent on log log(n) that can be used in place of C(π(cid:48)  π  t  δ) in Algorithm 1
(see sections C for the conﬁdence intervals and 3.2 for a longer discussion). Under speciﬁc noise
models we can give a more interpretable sample complexity. Let h ∈ (0  1]  α ≥ 0  z ∈ [0  1]
for some i ∈ [n − 1] and assume that ηi = 1
h|z − i/n|α so that µi = h|z −
i/n|αsign(z − i/n) (this would be a reasonable noise model for topology ααα in the introduction).
Let Π = {[k] : k ≤ n}. In this case  inspecting the dominating term of Theorem 1 for i ∈ π∗
n−1(z − i/n)−2α−1.
we have arg maxπ∈Π:i∈π∆π∗ Vπ π∗
Upper bounding the other terms and summing  the sample complexities can be calculated to be
O(log(n) log(log(n)/δ)/h2) if α = 0  and O(n2α log(log(n)/δ)/h2) if α > 0. These rates match
the minimax lower bound rates given in [13] up to log log factors. Unlike the algorithms given there 
our algorithm works in the agnostic setting  i.e. it is making no assumptions about whether the Bayes
classiﬁer is in the class. In the case of non-adaptive sampling  the sum is replaced with the max times
n yielding n2α+1 log(log(n)/δ)/h2 which is substantially worse than adaptive sampling.
Comparison to previous algorithms: One of the foundational works on active learning is the DHM
algorithm of [20] and the A2 algorithm that preceded it [2]. Similar in spirit to our algorithm  DHM
requests a label only when it is uncertain how π∗ would label the current point. In general the
analysis of the DHM algorithm can not characterize the contribution of each arm to the overall sample
complexity leading to sub-optimal sample complexity for combinatorial classes. For example in
the the case when Π = {[i]}n
i=1  with i∗ = arg maxi∈[n] µi  ignoring logarithmic factors  one can
show for this problem the bound of Theorem 1 of [20] scales like n2 maxi(cid:54)=i∗ (µi∗ − µ−2
) which is
. Similar arguments
can be made for other combinatorial classes such as all subsets of size k. While we are not particularly
interested in applying algorithms like DHM to this speciﬁc problem  we note that the style of its
analysis exposes such a gross inconsistency with past analyses of the best known algorithms that the
approach leaves much to be desired. For more details  please see A.2 in the supplementary materials.

substantially worse than our bound for this problem which scales like(cid:80)

i(cid:54)=i∗ ∆−2

i

(cid:1)2

h

i

3.2 Connections to Combinatorial Bandits

µi ∈ [−1  1]. Given a collection of sets Π ⊆ 2[n]  for each π ∈ Π we deﬁne µπ :=(cid:80)

A closely related problem to classiﬁcation is the pure-exploration combinatorial bandit problem. As
above we have access to a set of arms [n]  and associated to each arm is an unknown distribution νi
with support in [−1  1] - which is arbitrary not just a Bernoulli label distribution. We let {Ri j}∞
be a sequence of random variables where Ri j ∼ νi is the jth (i.i.d.) draw from νi satisfying
j=1
E[Ri j] = µi ∈ [−1  1].
In the persistent noise setting we assume that νi is a point mass at
i∈π µi the
sum of means in π. The pure-exploration for combinatorial bandit problem asks  given a hypothesis
class Π ⊆ 2[n] identify π∗ = argmax
µπ by requesting as few labels as possible. The combinatorial
π∈Π
bandit extends many problems considered in the multi-armed bandit literature. For example setting
Π = {{i} : i ∈ [n]} is equivalent to the best-arm identiﬁcation problem.
The discussion at the start of Section 3 shows that the classiﬁcation problem can be mapped to
combinatorial bandits - indeed minimizing the 0/1 loss is equivalent to maximizing µπ. In fact 
Algorithm 1 gives state of the art results for the pure exploration combinatorial bandit problem
and furthermore Theorem 1 holds verbatim. Algorithm 1 is similar to previous action elimination
algorithms for combinatorial bandits in the literature  e.g. Algorithm 4 in [11]. However  unlike
previous algorithms  we do not insist on sampling each item once  an unrealistic requirement for
classiﬁcation settings - indeed  not having this constraint allows us to reach minimax rates for
classiﬁcation in one dimensions as discussed above. In addition  this resolves a concern brought up in
[11] for elimination being used for PAC-learning. We prove Theorem 1 in this more general setting
in the supplementary materials  see A.3.
The connection between FDR control and combinatorial bandits is more direct: we are seeking to
ﬁnd π ∈ Π with maximum ηπ subject to FDR-constraints. This already highlights a key difference

6

A1 = Π  C1 = ∅  S1 = ∪π∈Ππ  T1 =(cid:83)

Input: Conﬁdence bounds C1(π  t  δ)  C2(π  π(cid:48)  t  δ)
Ak ⊂ Π will be the set of active sets in round k. Ck ⊂ Π is the set of FDR-controlled policies in round k.
for t = 1  2 ···

π∈Π π −(cid:84)

π∈Π π  k = 1.

if t = 2k:

(cid:80)t
Let δk = .25δ/k2
For each set π ∈ Ak  and each pair π(cid:48)  π ∈ Ak update the estimates:
(cid:0)(cid:80)t
(cid:100)T P (π
) −(cid:100)T P (π) := n
(cid:92)F DR(π) := 1 − n|π|t
s=1 YIs s1{Is ∈ π}

Js s1{Js ∈ π(cid:48)\π} −(cid:80)t

s=1 Y (cid:48)

s=1 Y (cid:48)

(cid:48)

t

Js s1{Js ∈ π\π(cid:48)}(cid:1)

Set Ck+1 = Ck ∪ {π ∈ Ak \ Ck : (cid:92)F DR(π) + C1(π  t  δk)/|π| ≤ α}
Set Ak+1 = Ak
Remove any π from Ak+1 and Ck+1 such that one of the conditions is true:
1. (cid:92)F DR(π) − C1(π  t  δk)/|π| > α

2. ∃π(cid:48) ∈ Ck+1 with(cid:100)T P (π(cid:48)) −(cid:100)T P (π) > C2(π  π(cid:48)  t  δk) and add π to a set R
Set Sk+1 :=(cid:83)

Remove any π from Ak+1 and Ck+1 such that:
3. ∃π(cid:48) ∈ Ck+1 ∪ R  such that π ⊂ π(cid:48).
and
k ← k + 1

Tk+1 =(cid:83)

π −(cid:84)

π∈Ak+1\Ck+1

π∈Ak+1

π∈Ak+1

π.

π 

endif
Stochastic Noise:

Persistent Noise:

if |Ak| = 1  Break. Otherwise:
Sample It ∼ Unif([n]). If It ∈ Sk  then receive a label YIt t ∼ Ber(ηIt ).
Jt t ∼ Ber(ηJt ).
Sample Jt ∼ Unif([n]). If Jt ∈ Tk  then receive a label Y (cid:48)
If |Ak| = 1 or t > n  Break. Otherwise:
Sample It ∼ [n]\{Is : 1 ≤ s < t}. If It ∈ Sk  then receive a label YIt t = ηIt.
Sample Jt ∼ [n]\{Js : 1 ≤ s < t}. If Jt ∈ Tk  then receive a label Y (cid:48)
Jt t = ηJt.

Return maxt∈Ck+1(cid:100)T P (π)

Algorithm 2: Active FDR control in persistent and bounded noise settings.

between classiﬁcation and FDR-control. In one we choose to sample to maximize ηπ subject to FDR
constraints where each ηi ∈ [0  1]  whereas in classiﬁcation we are trying to maximize µπ where
each µi ∈ [−1  1]. A major consequence of this difference is that ηπ ≤ ηπ(cid:48) whenever π ⊆ π(cid:48)  but
such a condition does not hold for µπ  µπ(cid:48).
Motivating the sample complexity: As mentioned above  the general combinatorial bandit problem
is considered in [11]. There they present an algorithm with sample complexity 

This complexity parameter is difﬁcult to interpret directly so we compare it to one more familiar
in statistical learning - the VC dimension. To see how this sample complexity relates to ours in
Theorem 1  note that log2 |B(k  π∗)| ≤ log2
V (B(r  π∗)) (cid:46) log2(|B(r  π∗)|) (cid:46) min{V (B(r  π∗))  r} log2(n) where (cid:46) hides a constant. The
proof of the conﬁdence intervals in the supplementary effectively combines these two facts along
with a union bound over all sets in B(r  π∗).

(cid:1) (cid:46) k log2(n). Thus by the Sauer-Shelah lemma 

(cid:0)n

k

4 Combinatorial FDR Control
Algorithm 2 provides an active sampling method for determining π ∈ Π with F DR(π) ≤ α
and maximal T P R  which we denote as π∗
α. Since T P R(π) = T P (π)/η[n]  we can ignore the
denominator and so maximizing the T P R is the same as maximizing T P . The algorithm proceeds in
epochs. At all times a collection Ak ⊆ Π of active sets is maintained along with a collection of FDR-
controlled sets Ck ⊆ Ak. In each time step  random indexes It and Jt are sampled from the union
Sk = ∪π∈Ak\Ck π and the symmetric difference Tk = ∪π∈Ak π − ∩π∈Ak π respectively. Associated
random labels YIt t  YJt t ∈ {0  1} are then obtained from the underlying label distributions Ber(ηIt)
and Ber(ηJt). At the start of each epoch  any set with a F DR that is statistically known to be

7

n(cid:88)

i=1

C

max

π:i∈π∆π∗

1

|π∆π∗|

1(cid:101)∆2

π

(cid:16)

max(|B(|π∆π∗|  π)| |B(|π∆π∗|  π∗)|)

log

(cid:17)

n
δ

Figure 2: Example run of Algorithm 2  showing the evolution of sampling regions Sk (blue stripes)  Tk (pink
stripes) and FDR controlled sets Ck (orange ﬁll) at each time kt.
under α is added to Ck  and any sets whose F DR are greater than α are removed from Ak in
condition 1. Similar to the active classiﬁcation algorithm of Figure 1  a set π ∈ Ak is removed in
condition 2 if T P (π) is shown to be statistically less than T P (π(cid:48)) for some π(cid:48) ∈ Ck that  crucially 
is FDR controlled. In general there may be many sets π ∈ Π such that T P (π) > T P (π∗
α) that are
not FDR-controlled. Finally in condition 3  we exploit the positivity of the ηi’s: if π ⊂ π(cid:48) then
deterministically T P (π) ≤ T P (π(cid:48))  so if π(cid:48) is FDR controlled it can be used to eliminate π. The
choice of Tk is motivated by active classiﬁcation: we only need to sample in the symmetric difference.
To determine which sets are FDR-controlled it is important that we sample in the entirety of the union
of all π ∈ Ak \ Ck  not just the symmetric difference of the Ak  which motivates the choice of Sk.
In practical experiments persistent noise is not uncommon and avoids the potential for unbounded
sample complexities that potentially occur when F DR(π) ≈ α. Figure 2 demonstrates a model run
of the algorithm in the case of ﬁve sets Π = {π1  . . .   π5}.
Recall that Πα is the subset of Π that is FDR-controlled so that π∗
α = arg maxπ∈Πα T P (π). The
following gives a sample complexity result for the number of rounds before the algorithm terminates.

1
∆2

π α

sF DR
π

=

and (cid:101)∆π = |T P (π∗
α) − T P (π)|/|π∆π∗| = |T P (π∗
Vπ|π|

Theorem 2 Assume that for each i ≤ n there is an associated ηi ∈ [0  1] and {Yi j}∞
j=1 is an i.i.d.
sequence of random variables such that Yi j ∼ Ber(ηi). For any π ∈ Π deﬁne ∆π α = |F DR(π)−α| 
(cid:17)
α)|/|π∆π∗|  and
α \ π) − T P (π \ π∗
n log((cid:101)∆−2
1(cid:101)∆2
Vπ π∗
|π∆π∗
α|
(cid:113) 4|π|nVπ log( n
}  minπ(cid:48)∈Πα
π⊂π(cid:48)

log(cid:0)n log(∆−2

π α)/δ(cid:1)  

In addition deﬁne T F DR

sF DR
π(cid:48)

π∗
}. Using C1(π  t  δ) :=

π
4nVπ log( n
δ )
1 − δ  in the stochastic noise setting Algorithm 2 returns π∗

and C2 = C for C deﬁned in Theorem 1  for a ﬁxed constant c  with probability at least
α after a number of samples no more than

}  minπ(cid:48)∈Πα
π⊂π(cid:48)

= min{max{sT P

= min{sF DR

  max{sT P

π   sF DR

π∗

} and

π   sF DR

α

sT P
π =

sF DR
π(cid:48)

δ )

+

α

log

π )/δ

(cid:16)

π

π

T T P

3t

π

t

(cid:123)(cid:122)

max

π∈Π:i∈π

T F DR
π

max

π∈Πα:i∈π∆π∗

α

T T P
π

F DR−Control

T P R−Elimination

(cid:123)(cid:122)

(cid:125)

α

n(cid:88)
(cid:124)

i=1

c

n(cid:88)
(cid:124)

i=1

(cid:125)

+c

8

and

c(cid:80)n

in

i=1 min

(cid:16)

(cid:110)

the
1 

persistent

noise
maxπ∈Π:i∈π T F DR

π

setting

returns

+ maxπ∈Πα:i∈π∆π∗

α

T T P

π

(cid:17)(cid:111)

π∗

α

after

no

more

than

π

π

π

Though this result is complicated  each term is understood by considering each way a set can be
removed and the time at which an arm i will stop being sampled. Effectively the sample complexity
decomposes into two parts  the complexity of showing that a set is FDR-controlled or not  and
how long it takes to eliminate it based on TPR. To motivate sF DR
  if we have a single set π then
1/(|π|∆2
π α) roughly captures the number of times we have to sample each element in π to decide
whether it is FDR-controlled or not - so in particular in the general case we have to roughly sample an
arm i  maxπ∈Π i∈π sπ times. However  we can remove a set before showing it is FDR controlled using
other conditions which T F DR
captures. The term in the sample complexity for elimination using
TPR is similarly motivated. We now unpack the underbraced terms more carefully simultaneously
explaining the sample complexity and the motivation for the proof of Theorem 2.
Sample Complexity of FDR-Control In any round where there exists a set π ∈ Ak \ Ck with arm
i ∈ π  i.e. π is not yet FDR controlled  there is the potential for sampling i ∈ Sk. A set π only leaves
Ak if i) it is shown to not be FDR controlled (condition 1 of the algorithm)  ii) because an FDR
controlled set eliminates it on the basis of TP (condition 2)  or iii) it is contained in an FDR controlled
set (condition 3). These three cases reﬂect the three arguments of the min in the deﬁned quantity
  respectively. Taking the maximum over all sets containing an arm i and summing over all i
T F DR
π
gives the total FDR-control term. This is a large savings relative to naive non-adaptive algorithms that
) samples.
sample until every set π in Π was FDR controlled which would take O(n maxπ∈Π sF DR
Sample Complexity of TPR-Elimination An FDR-controlled set π ∈ Πα is only removed from Ck
when eliminated by an FDR-controlled set with higher T P or if it is removed because it is contained
in an FDR-controlled set. In general we can upper bound the former time by the samples needed for
π∗
α to eliminate π once we know π∗
π .
T T P
Note that sets are removed in a procedure mimicking active classiﬁcation and so the active gains
there apply to this setting as well. A naive passive algorithm that continues to sample until both the
FDR of every set is determined  and π∗
α has higher TP than every other FDR-controlled set gives a
signiﬁcantly worse sample complexity of O(n max{maxπ∈Πα sF DR
Comparison with [5]. Similar to our proposed algorithm  [5] samples in the union of all active sets
and maintains statistics on the empirical FDR of each set  along the way removing sets that are not
FDR-controlled or have lower TPR than an FDR-controlled set. However  they fail to sample in the
symmetric difference  missing an important link between FDR-control and active classiﬁcation. In
particular  the conﬁdence intervals they use are far looser as a result. They also only consider the
case of persistent noise. Their proven sample complexity results are no better than those achieved by
the passive algorithm that samples each item uniformly  which is precisely the sample complexity
described at the end of the previous paragraph.
One Dimensional Thresholds Consider a stylized modeling of the topology βαββ from the introduc-
tion in the persistent noise setting where Π = {[t] : t ≤ n}  ηi ∼ Ber(β1{i ≤ z}) with β < .5  and
z ∈ [n] is assumed to be small  i.e.  we assume that there is only a small region in which positive labels
can be found and the Bayes classiﬁer is just to predict 0 for all points. Assuming α > 1 − β  one can
show the sample complexity of Algorithm 2 satisﬁes O((1−α)−2(log(n/(1−α))+(1+β)z/(1−α)))
while any naive non-adaptive sampling strategy will take at least O(n) samples.
Implementation. For simple classes Π such as thresholds or axis aligned rectangles  our algorithm
can be made computationally efﬁcient. But for more complex classes there may be a wide gap
between theory and practice  just as in classiﬁcation [36  20]. However  the algorithm motivates
two key ideas - sample in the union of potentially good sets to learn which are FDR controlled  and
sample in the symmetric difference to eliminate sets. The latter insight was originally made by A2 in
the case of classiﬁcation and has justiﬁed heuristics such as uncertainty sampling [36]. Developing
analogous heuristics for the former case of FDR-control is an exciting avenue of future work.

α is FDR controlled - this gives rise to maxπ∈Πα:i∈π∆π∗

  maxπ(cid:54)∈Πα sT P

π }).

π

α

9

References
[1] Shivani Agarwal  Thore Graepel  Ralf Herbrich  Sariel Har-Peled  and Dan Roth. Generalization
bounds for the area under the roc curve. Journal of Machine Learning Research  6(Apr):393–
425  2005.

[2] Maria-Florina Balcan  Alina Beygelzimer  and John Langford. Agnostic active learning. Journal

of Computer and System Sciences  75(1):78–89  2009.

[3] Rémi Bardenet  Odalric-Ambrym Maillard  et al. Concentration inequalities for sampling

without replacement. Bernoulli  21(3):1361–1385  2015.

[4] Yoav Benjamini and Yosef Hochberg. Controlling the false discovery rate: a practical and
powerful approach to multiple testing. Journal of the Royal statistical society: series B
(Methodological)  57(1):289–300  1995.

[5] Paul N Bennett  David M Chickering  Christopher Meek  and Xiaojin Zhu. Algorithms for
active classiﬁer selection: Maximizing recall with precision constraints. In Proceedings of the
Tenth ACM International Conference on Web Search and Data Mining  pages 711–719. ACM 
2017.

[6] Alina Beygelzimer  Sanjoy Dasgupta  and John Langford. Importance weighted active learning.

arXiv preprint arXiv:0812.4952  2008.

[7] Stéphane Boucheron  Gábor Lugosi  and Pascal Massart. Concentration inequalities: A

nonasymptotic theory of independence. Oxford university press  2013.

[8] Olivier Bousquet. A bennett concentration inequality and its application to suprema of empirical

processes. Comptes Rendus Mathematique  334(6):495–500  2002.

[9] Kendrick Boyd  Kevin H Eng  and C David Page. Area under the precision-recall curve: Point
estimates and conﬁdence intervals. In Joint European Conference on Machine Learning and
Knowledge Discovery in Databases  pages 451–466. Springer  2013.

[10] Diogo M Camacho  Katherine M Collins  Rani K Powers  James C Costello  and James J

Collins. Next-generation machine learning for biological networks. Cell  2018.

[11] Tongyi Cao and Akshay Krishnamurthy. Disagreement-based combinatorial pure exploration:
Efﬁcient algorithms and an analysis with localization. arXiv preprint arXiv:1711.08018  2017.

[12] Rui M Castro et al. Adaptive sensing performance lower bounds for sparse signal detection and

support estimation. Bernoulli  20(4):2217–2246  2014.

[13] Rui M Castro and Robert D Nowak. Minimax bounds for active learning. IEEE Transactions

on Information Theory  54(5):2339–2353  2008.

[14] Nicolo Cesa-Bianchi and Gabor Lugosi. Prediction  learning  and games. Cambridge university

press  2006.

[15] Lijie Chen  Anupam Gupta  and Jian Li. Pure exploration of multi-armed bandit under matroid

constraints. In Conference on Learning Theory  pages 647–669  2016.

[16] Lijie Chen  Anupam Gupta  Jian Li  Mingda Qiao  and Ruosong Wang. Nearly optimal
sampling algorithms for combinatorial pure exploration. In Conference on Learning Theory 
pages 482–534  2017.

[17] Lijie Chen  Jian Li  and Mingda Qiao. Nearly instance optimal sample complexity bounds for

top-k arm selection. In Artiﬁcial Intelligence and Statistics  pages 101–110  2017.

[18] Shouyuan Chen  Tian Lin  Irwin King  Michael R Lyu  and Wei Chen. Combinatorial pure
exploration of multi-armed bandits. In Advances in Neural Information Processing Systems 
pages 379–387  2014.

[19] Sanjoy Dasgupta. Coarse sample complexity bounds for active learning. In Advances in neural

information processing systems  pages 235–242  2006.

10

[20] Sanjoy Dasgupta  Daniel J Hsu  and Claire Monteleoni. A general agnostic active learning

algorithm. In Advances in neural information processing systems  pages 353–360  2008.

[21] Devdatt P Dubhashi and Alessandro Panconesi. Concentration of measure for the analysis of

randomized algorithms. Cambridge University Press  2009.

[22] Eyal Even-Dar  Shie Mannor  and Yishay Mansour. Action elimination and stopping conditions
for the multi-armed bandit and reinforcement learning problems. Journal of machine learning
research  7(Jun):1079–1105  2006.

[23] Victor Gabillon  Alessandro Lazaric  Mohammad Ghavamzadeh  Ronald Ortner  and Peter
Bartlett. Improved learning complexity in combinatorial pure exploration bandits. In Artiﬁcial
Intelligence and Statistics  pages 1004–1012  2016.

[24] Steve Hanneke. Teaching dimension and the complexity of active learning. In International

Conference on Computational Learning Theory  pages 66–81. Springer  2007.

[25] Steve Hanneke et al. Theory of disagreement-based active learning. Foundations and Trends R(cid:13)

in Machine Learning  7(2-3):131–309  2014.

[26] Tzu-Kuo Huang  Alekh Agarwal  Daniel J Hsu  John Langford  and Robert E Schapire. Efﬁcient
and parsimonious agnostic active learning. In Advances in Neural Information Processing
Systems  pages 2755–2763  2015.

[27] Kevin Jamieson and Lalit Jain. A bandit approach to multiple testing with false discovery

control. In Advances in Neural Information Processing Systems  2018.

[28] Kevin Jamieson  Matthew Malloy  Robert Nowak  and Sébastien Bubeck. lil’ucb: An optimal
exploration algorithm for multi-armed bandits. In Conference on Learning Theory  pages
423–439  2014.

[29] Shivaram Kalyanakrishnan  Ambuj Tewari  Peter Auer  and Peter Stone. Pac subset selection in

stochastic multi-armed bandits. In ICML  volume 12  pages 655–662  2012.

[30] Zohar Karnin  Tomer Koren  and Oren Somekh. Almost optimal exploration in multi-armed

bandits. In International Conference on Machine Learning  pages 1238–1246  2013.

[31] Armaghan W Naik  Joshua D Kangas  Devin P Sullivan  and Robert F Murphy. Active machine
learning-driven experimentation to determine compound effects on protein patterns. Elife 
5:e10047  2016.

[32] Robert D Nowak. The geometry of generalized binary search. IEEE Transactions on Information

Theory  57(12):7893–7906  2011.

[33] Gabriel J Rocklin  Tamuka M Chidyausiku  Inna Goreshnik  Alex Ford  Scott Houliston 
Alexander Lemak  Lauren Carter  Rashmi Ravichandran  Vikram K Mulligan  Aaron Chevalier 
et al. Global analysis of protein folding using massively parallel design  synthesis  and testing.
Science  357(6347):168–175  2017.

[34] Ashish Sabharwal and Yexiang Xue. Adaptive stratiﬁed sampling for precision-recall estimation.

pages 825–834  2018.

[35] Christoph Sawade  Niels Landwehr  and Tobias Scheffer. Active estimation of f-measures. In

Advances in Neural Information Processing Systems  pages 2083–2091  2010.

[36] Burr Settles. Active learning. Synthesis Lectures on Artiﬁcial Intelligence and Machine

Learning  6(1):1–114  2012.

[37] Max Simchowitz  Kevin Jamieson  and Benjamin Recht. The simulator: Understanding adaptive
sampling in the moderate-conﬁdence regime. In Conference on Learning Theory  pages 1794–
1834  2017.

[38] Yuriy Sverchkov and Mark Craven. A review of active learning approaches to experimental
design for uncovering biological networks. PLoS computational biology  13(6):e1005466  2017.

11

[39] Lorillee Tallorin  JiaLei Wang  Woojoo E Kim  Swagat Sahu  Nicolas M Kosa  Pu Yang 
Matthew Thompson  Michael K Gilson  Peter I Frazier  Michael D Burkart  et al. Discovering
de novo peptide substrates for enzymes using machine learning. Nature communications 
9(1):5253  2018.

[40] Fanny Yang  Aaditya Ramdas  Kevin G Jamieson  and Martin J Wainwright. A framework for
multi-a (rmed)/b (andit) testing with online fdr control. In Advances in Neural Information
Processing Systems  pages 5957–5966  2017.

[41] Lu Zhang  Jianjun Tan  Dan Han  and Hao Zhu. From machine learning to deep learning:
progress in machine intelligence for rational drug discovery. Drug discovery today  22(11):1680–
1685  2017.

[42] Martin J Zhang  James Zou  and David Tse. Adaptive monte carlo multiple testing via multi-

armed bandits. arXiv preprint arXiv:1902.00197  2019.

12

,Lalit Jain
Kevin Jamieson