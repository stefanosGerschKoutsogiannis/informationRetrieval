2013,Statistical Active Learning Algorithms,We describe a framework for designing efficient active learning algorithms that are tolerant to random classification noise. The framework is based on active learning algorithms that are statistical in the sense that they rely on estimates of expectations of functions of filtered random examples. It builds on the powerful statistical query framework of Kearns (1993).  We show that any efficient active statistical learning algorithm can be automatically converted to an efficient active learning algorithm which is tolerant to random classification noise as well as other forms of uncorrelated" noise. The complexity of the resulting algorithms has information-theoretically optimal quadratic dependence on $1/(1-2\eta)$  where $\eta$ is the noise rate.  We demonstrate the power of our framework by showing that commonly studied concept classes including thresholds  rectangles  and linear separators can be efficiently actively learned in our framework. These results combined with our generic conversion lead to the first known computationally-efficient algorithms for actively learning some of these concept classes in the presence of random classification noise that provide exponential improvement in the dependence on the error $\epsilon$ over their passive counterparts. In addition  we show that our algorithms can be automatically converted to efficient active differentially-private algorithms. This leads to the first differentially-private active learning algorithms with exponential label savings over the passive case.",Statistical Active Learning Algorithms

Maria Florina Balcan

Georgia Institute of Technology
ninamf@cc.gatech.edu

Vitaly Feldman

IBM Research - Almaden

vitaly@post.harvard.edu

Abstract

We describe a framework for designing efﬁcient active learning algorithms that are
tolerant to random classiﬁcation noise and differentially-private. The framework
is based on active learning algorithms that are statistical in the sense that they rely
on estimates of expectations of functions of ﬁltered random examples. It builds
on the powerful statistical query framework of Kearns [30].
We show that any efﬁcient active statistical learning algorithm can be automati-
cally converted to an efﬁcient active learning algorithm which is tolerant to ran-
dom classiﬁcation noise as well as other forms of “uncorrelated” noise. We show
that commonly studied concept classes including thresholds  rectangles  and lin-
ear separators can be efﬁciently actively learned in our framework. These results
combined with our generic conversion lead to the ﬁrst computationally-efﬁcient
algorithms for actively learning some of these concept classes in the presence of
random classiﬁcation noise that provide exponential improvement in the depen-
dence on the error  over their passive counterparts. In addition  we show that our
algorithms can be automatically converted to efﬁcient active differentially-private
algorithms. This leads to the ﬁrst differentially-private active learning algorithms
with exponential label savings over the passive case.

1

Introduction

Most classic machine learning methods depend on the assumption that humans can annotate all the
data available for training. However  many modern machine learning applications have massive
amounts of unannotated or unlabeled data. As a consequence  there has been tremendous interest
both in machine learning and its application areas in designing algorithms that most efﬁciently uti-
lize the available data  while minimizing the need for human intervention. An extensively used and
studied technique is active learning  where the algorithm is presented with a large pool of unlabeled
examples and can interactively ask for the labels of examples of its own choosing from the pool 
with the goal to drastically reduce labeling effort. This has been a major area of machine learning
research in the past decade [19]  with several exciting developments on understanding its underlying
statistical principles [27  18  4  3  29  21  15  7  31  10  34  6]. In particular  several general character-
izations have been developed for describing when active learning can in principle have an advantage
over the classic passive supervised learning paradigm  and by how much. However  these efforts
were primarily focused on sample size bounds rather than computation  and as a result many of the
proposed algorithms are not computationally efﬁcient. The situation is even worse in the presence
of noise where active learning appears to be particularly hard. In particular  prior to this work  there
were no known efﬁcient active algorithms for concept classes of super-constant VC-dimension that
are provably robust to random and independent noise while giving improvements over the passive
case.
Our Results: We propose a framework for designing efﬁcient (polynomial time) active learning
algorithms which is based on restricting the way in which examples (both labeled and unlabeled) are
accessed by the algorithm. These restricted algorithms can be easily simulated using active sampling
and  in addition  possess a number of other useful properties. The main property we will consider is

1

tolerance to random classiﬁcation noise of rate η (each label is ﬂipped randomly and independently
with probability η [1]). Further  as we will show  the algorithms are tolerant to other forms of noise
and can be simulated in a differentially-private way.
In our restriction  instead of access to random examples from some distribution P over X × Y the
learning algorithm only gets “active” estimates of the statistical properties of P in the following
sense. The algorithm can choose any ﬁlter function χ(x) : X → [0  1] and a query function φ :
X × Y → [−1  1] for any χ and φ. For simplicity we can think of χ as an indicator function of
some set χS ⊆ X of “informative” points and of φ as some useful property of the target function.
For this pair of functions the learning algorithm can get an estimate of E(x y)∼P [φ(x  y) | x ∈ χS].
For τ and τ0 chosen by the algorithm the estimate is provided to within tolerance τ as long as
E(x y)∼P [x ∈ χS] ≥ τ0 (nothing is guaranteed otherwise). Here the inverse of τ corresponds to
the label complexity of the algorithm and the inverse of τ0 corresponds to its unlabeled sample
complexity. Such a query is referred to as active statistical query (SQ) and algorithms using active
SQs are referred to as active statistical algorithms.
Our framework builds on the classic statistical query (SQ) learning framework of Kearns [30] de-
ﬁned in the context of PAC learning model [35]. The SQ model is based on estimates of expectations
of functions of examples (but without the additional ﬁlter function) and was deﬁned in order to de-
sign efﬁcient noise tolerant algorithms in the PAC model. Despite the restrictive form  most of the
learning algorithms in the PAC model and other standard techniques in machine learning and statis-
tics used for problems over distributions have SQ analogues [30  12  11  ?]1. Further  statistical
algorithms enjoy additional properties: they can be simulated in a differentially-private way [11] 
automatically parallelized on multi-core architectures [17] and have known information-theoretic
characterizations of query complexity [13  26]. As we show  our framework inherits the strengths of
the SQ model while  as we will argue  capturing the power of active learning.
At a ﬁrst glance being active and statistical appear to be incompatible requirements on the algorithm.
Active algorithms typically make label query decisions on the basis of examining individual samples
(for example as in binary search for learning a threshold or the algorithms in [27  21  22]). At the
same time statistical algorithms can only examine properties of the underlying distribution. But
there also exist a number of active learning algorithms that can be seen as applying passive learning
techniques to batches of examples that are obtained from querying labels of samples that satisfy the
same ﬁlter. These include the general A2 algorithm [4] and  for example  algorithms in [3  20  9  8].
As we show  we can build on these techniques to provide algorithms that ﬁt our framework.
We start by presenting a general reduction showing that any efﬁcient active statistical learning al-
gorithm can be automatically converted to an efﬁcient active learning algorithm which is tolerant to
random classiﬁcation noise as well as other forms of “uncorrelated” noise. We then demonstrate the
generality of our framework by showing that the most commonly studied concept classes includ-
ing thresholds  balanced rectangles  and homogenous linear separators can be efﬁciently actively
learned via active statistical algorithms. For these concept classes  we design efﬁcient active learn-
ing algorithms that are statistical and provide the same exponential improvements in the dependence
on the error  over passive learning as their non-statistical counterparts.
The primary problem we consider is active learning of homogeneous halfspaces  a problem that has
attracted a lot of interest in the theory of active learning [27  18  3  9  22  16  23  8  28]. We de-
scribe two algorithms for the problem. First  building on insights from margin based analysis [3  8] 
we give an active statistical learning algorithm for homogeneous halfspaces over all isotropic log-
concave distributions  a wide class of distributions that includes many well-studied density functions
and has played an important role in several areas including sampling  optimization  and learning
[32]. Our algorithm for this setting proceeds in rounds; in round t we build a better approximation
wt to the target function by using a passive SQ learning algorithm (e.g.  the one of [24]) over a
distribution Dt that is a mixture of distributions in which each component is the original distribution
conditioned on being within a certain distance from the hyperplane deﬁned by previous approxima-
tions wi. To perform passive statistical queries relative to Dt we use active SQs with a corresponding
real valued ﬁlter. This algorithm is computationally efﬁcient and uses only poly(d  log(1/)) active
statistical queries of tolerance inverse-polynomial in the dimension d and log(1/).

1The sample complexity of the SQ analogues might increase sometimes though.

2

√

d) and ﬁlter tolerance of Ω(1/).

For the special case of the uniform distribution over the unit ball we give a new  simpler and substan-
tially more efﬁcient active statistical learning algorithm. Our algorithm is based on measuring the
error of a halfspace conditioned on being within some margin of that halfspace. We show that such
measurements performed on the perturbations of the current hypothesis along the d basis vectors
can be combined to derive a better hypothesis. This approach differs substantially from the previous
algorithms for this problem [3  22]. The algorithm is computationally efﬁcient and uses d log(1/)
active SQs with tolerance of Ω(1/
These results  combined with our generic simulation of active statistical algorithms in the presence
of random classiﬁcation noise (RCN) lead to the ﬁrst known computationally efﬁcient algorithms
for actively learning halfspaces which are RCN tolerant and give provable label savings over the
passive case. For the uniform distribution case this leads to an algorithm with sample complexity of
O((1 − 2η)−2 · d2 log(1/) log(d log(1/))) and for the general isotropic log-concave case we get
sample complexity of poly(d  log(1/)  1/(1 − 2η)). This is worse than the sample complexity in
the noiseless case which is just O((d + log log(1/)) log(1/)) [8]. However  compared to passive
learning in the presence of RCN  our algorithms have exponentially better dependence on  and es-
sentially the same dependence on d and 1/(1 − 2η). One issue with the generic simulation is that
it requires knowledge of η (or an almost precise estimate). Standard approach to dealing with this
issue does not always work in the active setting and for our log-concave and the uniform distribu-
tion algorithms we give a specialized argument that preserves the exponential improvement in the
dependence on .

Differentially-private active learning: In many application of machine learning such as medical
and ﬁnancial record analysis  data is both sensitive and expensive to label. However  to the best
of our knowledge  there are no formal results addressing both of these constraints. We address
the problem by deﬁning a natural model of differentially-private active learning. In our model we
assume that a learner has full access to unlabeled portion of some database of n examples S ⊆
X × Y which correspond to records of individual participants in the database.
In addition  for
every element of the database S the learner can request the label of that element. As usual  the
goal is to minimize the number of label requests (such setup is referred to as pool-based active
learning [33]). In addition  we would like to preserve the differential privacy of the participants in
the database  a now-standard notion of privacy introduced in [25]. Informally speaking  an algorithm
is differentially private if adding any record to S (or removing a record from S) does not affect the
probability that any speciﬁc hypothesis will be output by the algorithm signiﬁcantly.
As ﬁrst shown by [11]  SQ algorithms can be automatically translated into differentially-private
algorithms. Using a similar approach  we show that active SQ learning algorithms can be automat-
ically transformed into differentially-private active learning algorithms. Using our active statistical
algorithms for halfspaces we obtain the ﬁrst algorithms that are both differentially-private and give
exponential improvements in the dependence of label complexity on the accuracy parameter .

Additional related work: As we have mentioned  most prior theoretical work on active learning
focuses on either sample complexity bounds (without regard for efﬁciency) or the noiseless case.
For random classiﬁcation noise in particular  [6] provides a sample complexity analysis based on
the splitting index that is optimal up to polylog factors and works for general concept classes and
distributions  but it is not computationally efﬁcient. In addition  several works give active learning
algorithms with empirical evidence of robustness to certain types of noise [9  28];
In [16  23] online learning algorithms in the selective sampling framework are presented  where
labels must be actively queried before they are revealed. Under the assumption that the label con-
ditional distribution is a linear function determined by a ﬁxed target vector  they provide bounds
on the regret of the algorithm and on the number of labels it queries when faced with an adaptive
adversarial strategy of generating the instances. As pointed out in [23]  these results can also be
converted to a distributional PAC setting where instances xt are drawn i.i.d. In this setting they
obtain exponential improvement in label complexity over passive learning. These interesting results
and techniques are not directly comparable to ours. Our framework is not restricted to halfspaces.
Another important difference is that (as pointed out in [28]) the exponential improvement they give
is not possible in the noiseless version of their setting. In other words  the addition of linear noise
deﬁned by the target makes the problem easier for active sampling. By contrast RCN can only make
the classiﬁcation task harder than in the realizable case.

3

Due to space constraint details of most proofs and further discussion appear in the full version of
this paper [5].

2 Active Statistical Algorithms

Let X be a domain and P be a distribution over labeled examples on X. We represent such a
distribution by a pair (D  ψ) where D is the marginal distribution of P on X and ψ : X → [−1  1]
is a function deﬁned as ψ(z) = E(x (cid:96))∼P [(cid:96) | x = z]. We will be primarily considering learning in
the PAC model (realizable case) where ψ is a boolean function  possibly corrupted by random noise.
When learning with respect to a distribution P = (D  ψ)  an active statistical learner has access to
active statistical queries. A query of this type is a pair of functions (χ  φ)  where χ : X → [0  1]
is the ﬁlter function which for a point x  speciﬁes the probability with which the label of x should
be queried. The function φ : X × {−1  1} → [−1  1] is the query function and depends on both
point and the label. The ﬁlter function χ deﬁnes the distribution D conditioned on χ as follows:
for each x the density function D|χ(x) is deﬁned as D|χ(x) = D(x)χ(x)/ED[χ(x)]. Note that if
χ is an indicator function of some set S then D|χ is exactly D conditioned on x being in S. Let
P|χ denote the conditioned distribution (D|χ  ψ). In addition  a query has two tolerance parameters:
ﬁlter tolerance τ0 and query tolerance τ. In response to such a query the algorithm obtains a value
µ such that if ED[χ(x)] ≥ τ0 then

(cid:12)(cid:12)µ − EP|χ[φ(x  (cid:96))](cid:12)(cid:12) ≤ τ

(and nothing is guaranteed when ED[χ(x)] < τ0).
An active statistical learning algorithm can also ask target-independent queries with tolerance τ
which are just queries over unlabeled samples. That is for a query ϕ : X → [−1  1] the algorithm
obtains a value µ  such that |µ − ED[ϕ(x)]| ≤ τ. Such queries are not necessary when D is
known to the learner. Also for the purposes of obtaining noise tolerant algorithms one can relax the
requirements of model and give the learning algorithm access to unlabelled samples.
Our deﬁnition generalizes the statistical query framework of Kearns [30] which does not include
ﬁltering function  in other words a query is just a function φ : X × {−1  1} → [−1  1] and it has a
single tolerance parameter τ. By deﬁnition  an active SQ (χ  φ) with tolerance τ relative to P is the
same as a passive statistical query φ with tolerance τ relative to the distribution P|χ. In particular  a
(passive) SQ is equivalent to an active SQ with ﬁlter χ ≡ 1 and ﬁlter tolerance 1.
We note that from the deﬁnition of active SQ we can see that

EP|χ[φ(x  (cid:96))] = EP [φ(x  (cid:96)) · χ(x)]/EP [χ(x)].

This implies that an active statistical query can be estimated using two passive statistical queries.
However to estimate EP|χ[φ(x  (cid:96))] with tolerance τ one needs to estimate EP [φ(x  (cid:96)) · χ(x)] with
tolerance τ · EP [χ(x)] which can be much lower than τ. Tolerance of a SQ directly corresponds to
the number of examples needed to evaluate it and therefore simulating active SQs passively might
require many more labeled examples.

2.1 Simulating Active Statistical Queries

We ﬁrst note that a valid response to a target-independent query with tolerance τ can be obtained 
with probability at least 1 − δ  using O(τ−2 log (1/δ)) unlabeled samples.
A natural way of simulating an active SQ is by ﬁltering points drawn randomly from D: draw a
random point x  let B be drawn from Bernoulli distribution with probability of success χ(x); ask
for the label of x when B = 1. The points for which we ask for a label are distributed according to
D|χ. This implies that the empirical average of φ(x  (cid:96)) on O(τ−2 log (1/δ)) labeled examples will
then give µ. Formally we get the following theorem.
Theorem 2.1. Let P = (D  ψ) be a distribution over X ×{−1  1}. There exists an active sampling
algorithm that given functions χ : X → [0  1]  φ : X × {−1  1} → [−1  1]  values τ0 > 0 
τ > 0  δ > 0  and access to samples from P   with probability at least 1 − δ  outputs a valid
response to active statistical query (χ  φ) with tolerance parameters (τ0  τ ). The algorithm uses
O(τ−2 log (1/δ)) labeled examples from P and O(τ−1
0 τ−2 log (1/δ)) unlabeled samples from D.

4

A direct way to simulate all the queries of an active SQ algorithm is to estimate the response to each
query using fresh samples and use the union bound to ensure that  with probability at least 1 − δ  all
queries are answered correctly. Such direct simulation of an algorithm that uses at most q queries can
be done using O(qτ−2 log(q/δ)) labeled examples and O(qτ−1
0 τ−2 log (q/δ)) unlabeled samples.
However in many cases a more careful analysis can be used to reduce the sample complexity of
simulation.
Labeled examples can be shared to simulate queries that use the same ﬁlter χ and do not depend on
each other. This implies that the sample size sufﬁcient for simulating q non-adaptive queries with the
same ﬁlter scales logarithmically with q. More generally  given a set of q query functions (possibly
chosen adaptively) which belong to some set Q of low complexity (such as VC dimension) one can
reduce the sample complexity of estimating the answers to all q queries (with the same ﬁlter) by
invoking the standard bounds based on uniform convergence (e.g. [14]).

2.2 Noise tolerance

0 τ−2(1 − 2η)−2 log (1/δ)) unlabeled samples from D.

An important property of the simulation described in Theorem 2.1 is that it can be easily adapted
to the case when the labels are corrupted by random classiﬁcation noise [1]. For a distribution
P = (D  ψ) let P η denote the distribution P with the label ﬂipped with probability η randomly and
independently of an example. It is easy to see that P η = (D  (1 − 2η)ψ). We now show that  as in
the SQ model [30]  active statistical queries can be simulated given examples from P η.
Theorem 2.2. Let P = (D  ψ) be a distribution over examples and let η ∈ [0  1/2) be a noise
rate. There exists an active sampling algorithm that given functions χ : X → [0  1]  φ : X ×
{−1  1} → [−1  1]  values η  τ0 > 0  τ > 0  δ > 0  and access to samples from P η  with
probability at least 1 − δ  outputs a valid response to active statistical query (χ  φ) with tolerance
parameters (τ0  τ ). The algorithm uses O(τ−2(1− 2η)−2 log (1/δ)) labeled examples from P η and
O(τ−1
Note that the sample complexity of the resulting active sampling algorithm has information-
theoretically optimal quadratic dependence on 1/(1 − 2η)  where η is the noise rate.
Remark 2.3. This simulation assumes that η is given to the algorithm exactly. It is easy to see from
1−2η(cid:48) ∈ [1 − τ /4  1 + τ /4] can be used in place of η (with
the proof  that any value η(cid:48) such that 1−2η
2 (φ(x  1) − φ(x −1)) · (cid:96)] set to (1 − 2η)τ /4). In some learning
the tolerance of estimating EP η|χ
[ 1
scenarios even an approximate value of η is not known but it is known that η ≤ η0 < 1/2. To address
this issue one can construct a sequence η1  . . .   ηk of guesses of η  run the learning algorithm with
each of those guesses in place of the true η and let h1  . . .   hk be the resulting hypotheses [30]. One
can then return the hypothesis hi among those that has the best agreement with a suitably large
sample. It is not hard to see that k = O(τ−1 · log(1/(1− 2η0))) guesses will sufﬁce for this strategy
to work [2].
Passive hypothesis testing requires Ω(1/) labeled examples and might be too expensive to be used
with active learning algorithms. It is unclear if there exists a general approach for dealing with
unknown η in the active learning setting that does not increase substantially the labelled example
complexity. However  as we will demonstrate  in the context of speciﬁc active learning algorithms
variants of this approach can be used to solve the problem.

We now show that more general types of noise can be tolerated as long as they are “uncorrelated”
with the queries and the target function. Namely  we represent label noise using a function Λ : X →
[0  1]  where Λ(x) gives the probability that the label of x is ﬂipped. The rate of Λ when learning
with respect to marginal distribution D over X is ED[Λ(x)]. For a distribution P = (D  ψ) over
examples  we denote by P Λ the distribution P corrupted by label noise Λ. It is easy to see that
P Λ = (D  ψ · (1 − 2Λ)). Intuitively  Λ is “uncorrelated” with a query if the way that Λ deviates
from its rate is almost orthogonal to the query on the target distribution.
Deﬁnition 2.4. Let P = (D  ψ) be a distribution over examples and τ(cid:48) > 0. For functions χ :
X → [0  1]  φ : X × {−1  1} → [−1  1]  we say that a noise function Λ : X → [0  1] is (η  τ(cid:48))-
uncorrelated with φ and χ over P if 

(cid:12)(cid:12)(cid:12)(cid:12)ED|χ

(cid:20) φ(x  1) − φ(x −1)

2

(cid:21)(cid:12)(cid:12)(cid:12)(cid:12) ≤ τ(cid:48) .

ψ(x) · (1 − 2(Λ(x) − η))

5

In this deﬁnition (1− 2(Λ(x)− η)) is the expectation of {−1  1} coin that is ﬂipped with probability
Λ(x)− η  whereas (φ(x  1)− φ(x −1))ψ(x) is the part of the query which measures the correlation
with the label. We now give an analogue of Theorem 2.2 for this more general setting.
Theorem 2.5. Let P = (D  ψ) be a distribution over examples  χ : X → [0  1]  φ : X ×{−1  1} →
[−1  1] be a query and a ﬁlter functions  η ∈ [0  1/2)  τ > 0 and Λ be a noise function that is
(η  (1 − 2η)τ /4)-uncorrelated with φ and χ over P . There exists an active sampling algorithm that
given functions χ and φ  values η  τ0 > 0  τ > 0  δ > 0  and access to samples from P Λ  with
probability at least 1 − δ  outputs a valid response to active statistical query (χ  φ) with tolerance
parameters (τ0  τ ). The algorithm uses O(τ−2(1− 2η)−2 log (1/δ)) labeled examples from P Λ and
O(τ−1

0 τ−2(1 − 2η)−2 log (1/δ)) unlabeled samples from D.

An immediate implication of Theorem 2.5 is that one can simulate an active SQ algorithm A using
examples corrupted by noise Λ as long as Λ is (η  (1 − 2η)τ /4)-uncorrelated with all A’s queries of
tolerance τ for some ﬁxed η.

2.3 Simple examples

Thresholds: We show that a classic example of active learning a threshold function on an interval
can be easily expressed using active SQs. For simplicity and without loss of generality we can
assume that the interval is [0  1] and the distribution is uniform over it (as usual  we can bring the
distribution to be close enough to this form using unlabeled samples or target-independent queries).
Assume that we know that the threshold θ belongs to the interval [a  b] ⊆ [0  1]. We ask a query
φ(x  (cid:96)) = ((cid:96)+1)/2 with ﬁlter χ(x) which is the indicator function of the interval [a  b] with tolerance
1/4 and ﬁlter tolerance b − a. Let v be the response to the query. By deﬁnition  E[χ(x)] = b − a
and therefore we have that |v − E[φ(x  (cid:96)) | x ∈ [a  b]]| ≤ 1/4. Note that 
E[φ(x  (cid:96)) | x ∈ [a  b]] = (b − θ)/(b − a) .

We can therefore conclude that (b − θ)/(b − a) ∈ [v − 1/4  v + 1/4] which means that θ ∈
[b − (v + 1/4)(b − a)  b − (v − 1/4)(b − a)] ∩ [a  b]. Note that the length of this interval is at most
(b − a)/2. This means that after at most log2(1/) + 1 iterations we will reach an interval [a  b]
of length at most . In each iteration only constant 1/4 tolerance is necessary and ﬁlter tolerance is
never below . A direct simulation of this algorithm can be done using log(1/) · log(log(1/)/δ)
labeled examples and ˜O(1/) · log(1/δ) unlabeled samples.
Learning of thresholds can also be easily used to obtain a simple algorithm for learning axis-aligned
rectangles whose weight under the target distribution is not too small.

A2 : We now note that the general and well-studied A2 algorithm of [4] falls naturally into our
framework. At a high level  the A2 algorithm is an iterative  disagreement-based active learning
algorithm. It maintains a set of surviving classiﬁers Ci ⊆ C  and in each round the algorithm asks
for the labels of a few random points that fall in the current region of disagreement of the surviving
classiﬁers. Formally  the region of disagreement DIS(Ci) of a set of classiﬁers Ci is the of set of
instances x such that for each x ∈ DIS(Ci) there exist two classiﬁers f  g ∈ Ci that disagree about
the label of x. Based on the queried labels  the algorithm then eliminates hypotheses that were
still under consideration  but only if it is statistically conﬁdent (given the labels queried in the last
round) that they are suboptimal. In essence  in each round A2 only needs to estimate the error rates
(of hypotheses still under consideration) under the conditional distribution of being in the region of
disagreement. This can be easily done via active statistical queries. Note that while the number of
active statistical queries needed to do this could be large  the number of labeled examples needed
to simulate these queries is essentially the same as the number of labeled examples needed by the
known A2 analyses [29]. While in general the required computation of the disagreement region
and manipulations of the hypothesis space cannot be done efﬁciently  efﬁcient implementation is
possible in a number of simple cases such as when the VC dimension of the concept class is a
constant.
It is not hard to see that in these cases the implementation can also be done using a
statistical algorithm.

6

3 Learning of halfspaces

In this section we outline our reduction from active learning to passive learning of homogeneous
linear separators based on the analysis of Balcan and Long [8]. Combining it with the SQ learning
algorithm for halfspaces by Dunagan and Vempala [24]  we obtain the ﬁrst efﬁcient noise-tolerant
active learning of homogeneous halfspaces for any isotropic log-concave distribution. One of the
key point of this result is that it is relatively easy to harness the involved results developed for SQ
framework to obtain new active statistical algorithms.
Let Hd denote the concept class of all homogeneous halfspaces. Recall that a distribution over Rd
is log-concave if log f (·) is concave  where f is its associated density function. It is isotropic if its
mean is the origin and its covariance matrix is the identity. Log-concave distributions form a broad
class of distributions: for example  the Gaussian  Logistic  Exponential  and uniform distribution
over any convex set are log-concave distributions. Using results in [24] and properties of log-concave
distributions  we can show:
Theorem 3.1. There exists a SQ algorithm LearnHS that learns Hd to accuracy 1 −  over any
distribution D|χ  where D is an isotropic log-concave distribution and χ : Rd → [0  1] is a ﬁlter
function. Further LearnHS outputs a homogeneous halfspace  runs in time polynomial in d 1/
and log(1/λ) and uses SQs of tolerance ≥ 1/poly(d  1/  log(1/λ))  where λ = ED[χ(x)].
We now state the properties of our new algorithm formally.
Theorem 3.2. There exists an active SQ algorithm ActiveLearnHS-LogC (Algorithm 1) that
for any isotropic log-concave distribution D on Rd  learns Hd over D to accuracy 1 −  in time
poly(d  log(1/)) and using active SQs of tolerance ≥ 1/poly(d  log(1/)) and ﬁlter tolerance Ω().

Algorithm 1 ActiveLearnHS-LogC: Active SQ learning of homogeneous halfspaces over
isotropic log-concave densities
1: %% Constants c  C1  C2 and C3 are determined by the analysis.
2: Run LearnHS with error C2 to obtain w0.
3: for k = 1 to s = (cid:100)log2(1/(c))(cid:101) do
4:
5:
6:
7:

Let bk−1 = C1/2k−1
Let µk equal the indicator function of being within margin bk−1 of wk−1

Run LearnHS over Dk = D|χk with error C2/k by using active queries with ﬁlter χk and
ﬁlter tolerance C3 to obtain wk

Let χk = ((cid:80)

i≤k µi)/k

8: end for
9: return ws

We remark that  as usual  we can ﬁrst bring the distribution to an isotropic position by using target
independent queries to estimate the mean and the covariance matrix of the distribution. Therefore
our algorithm can be used to learn halfspaces over general log-concave densities as long as the target
halfspace passes through the mean of the density.
We can now apply Theorem 2.2 (or more generally Theorem 2.5) to obtain an efﬁcient active learn-
ing algorithm for homogeneous halfspaces over log-concave densities in the presence of random
classiﬁcation noise of known rate. Further since our algorithm relies on LearnHS which can also
be simulated when the noise rate is unknown (see Remark 2.3) we obtain an active algorithm which
does not require the knowledge of the noise rate.
Corollary 3.3. There exists a polynomial-time active learning algorithm that for any η ∈ [0  1/2) 
learns Hd over any log-concave distributions with random classiﬁcation noise of rate η to error 
using poly(d  log(1/)  1/(1 − 2η)) labeled examples and a polynomial number of unlabeled sam-
ples.

For the special case of the uniform distribution on the unit sphere (or  equivalently for our purposes 
unit ball) we give a substantially simpler and more efﬁcient algorithm in terms of both sample and
computational complexity. This setting was previously studied in [3  22]. The detailed presentation
of the technical ideas appears in the full version of the paper [5].

7

Theorem 3.4. There exists an active SQ algorithm ActiveLearnHS-U that learns Hd over
the uniform distribution on the (d − 1)-dimensional unit sphere to accuracy 1 −   uses (d +
√
1) log(1/) active SQs with tolerance of Ω(1/
d) and ﬁlter tolerance of Ω(1/) and runs in time
d · poly(log (d/)).

4 Differentially-private active learning

In this section we show that active SQ learning algorithms can also be used to obtain differentially
private active learning algorithms. Formally  for some domain X × Y   we will call S ⊆ X × Y a
database. Databases S  S(cid:48) ⊂ X×Y are adjacent if one can be obtained from the other by modifying
a single element. Here we will always have Y = {−1  1}. In the following  A is an algorithm that
takes as input a database D and outputs an element of some ﬁnite set R.
Deﬁnition 4.1 (Differential privacy [25]). A (randomized) algorithm A : 2X×Y → R is α-
differentially private if for all r ∈ R and every pair of adjacent databases S  S(cid:48)  we have
Pr[A(S) = r] ≤ e Pr[A(S(cid:48)) = r].

Here we consider algorithms that operate on S in an active way. That is the learning algorithm
receives the unlabeled part of each point in S as an input and can only obtain the label of a point
upon request. The total number of requests is the label complexity of the algorithm.
Theorem 4.2. Let A be an algorithm that learns a class of functions H to accuracy 1 −  over dis-
tribution D using M1 active SQs of tolerance τ and ﬁlter tolerance τ0 and M2 target-independent
queries of tolerance τu. There exists a learning algorithm A(cid:48) that given α > 0  δ > 0 and ac-
tive access to database S ⊆ X × {−1  1} is α-differentially private and uses at most O([ M1
ατ +
τ 2 ] log(M1/δ)) labels. Further  for some n = O([ M1
] log((M1 + M2)/δ)) 
M1
if S consists of at least n examples drawn randomly from D then with  probability at least 1 − δ  A(cid:48)
outputs a hypothesis with accuracy ≥ 1 −  (relative to distribution D). The running time of A(cid:48) is
the same as the running time of A plus O(n).

ατ0τ + M1

τ0τ 2 + M2
ατu

+ M2
τ 2
u

An immediate consequence of Theorem 4.2 is that for learning of homogeneous halfspaces over
uniform or log-concave distributions we can obtain differential privacy while essentially preserving
the label complexity. For example  by combining Theorems 4.2 and 3.4  we can efﬁciently and
differentially-privately learn homogeneous halfspaces under the uniform distribution with privacy
parameter α and error parameter  by using only O(d
d log(1/))/α + d2 log(1/)) labels. How-
ever  it is known that any passive learning algorithm  even ignoring privacy considerations and noise
d and small enough  we get better

(cid:1)(cid:1) labeled examples. So for α ≥ 1/

requires Ω(cid:0) d

 log(cid:0) 1

√

 + 1
label complexity.

δ

√

5 Discussion

Our work suggests that  as in passive learning  active statistical algorithms might be essentially
as powerful as example-based efﬁcient active learning algorithms. It would be interesting to ﬁnd
more general evidence supporting this claim or  alternatively  a counterexample. A nice aspect of
(passive) statistical learning algorithms is that it is possible to prove unconditional lower bounds on
such algorithms using SQ dimension [13] and its extensions. It would be interesting to develop an
active analogue of these techniques and give meaningful lower bounds based on them.

Acknowledgments We thank Avrim Blum and Santosh Vempala for useful discussions. This work
was supported in part by NSF grants CCF-0953192 and CCF-1101215  AFOSR grant FA9550-09-
1-0538  ONR grant N00014-09-1-0751  and a Microsoft Research Faculty Fellowship.

References
[1] D. Angluin and P. Laird. Learning from noisy examples. Machine Learning  2:343–370  1988.
[2] J. Aslam and S. Decatur. Speciﬁcation and simulation of statistical query algorithms for efﬁciency and

noise tolerance. JCSS  56:191–208  1998.

[3] M. Balcan  A. Broder  and T. Zhang. Margin based active learning. In COLT  pages 35–50  2007.

8

[4] M. F. Balcan  A. Beygelzimer  and J. Langford. Agnostic active learning. In ICML  2006.
[5] M. F. Balcan and V. Feldman. Statistical active learning algorithms  2013. ArXiv:1307.3102.
[6] M.-F. Balcan and S. Hanneke. Robust interactive learning. In COLT  2012.
[7] M.-F. Balcan  S. Hanneke  and J. Wortman. The true sample complexity of active learning. In COLT 

2008.

[8] M.-F. Balcan and P. M. Long. Active and passive learning of linear separators under log-concave distri-

butions. JMLR - COLT proceedings (to appear)  2013.

[9] A. Beygelzimer  S. Dasgupta  and J. Langford. Importance weighted active learning. In ICML  pages

49–56  2009.

[10] A. Beygelzimer  D. Hsu  J. Langford  and T. Zhang. Agnostic active learning without constraints. In

NIPS  2010.

[11] A. Blum  C. Dwork  F. McSherry  and K. Nissim. Practical privacy: the SuLQ framework. In Proceedings

of PODS  pages 128–138  2005.

[12] A. Blum  A. Frieze  R. Kannan  and S. Vempala. A polynomial time algorithm for learning noisy linear

threshold functions. Algorithmica  22(1/2):35–52  1997.

[13] A. Blum  M. Furst  J. Jackson  M. Kearns  Y. Mansour  and S. Rudich. Weakly learning DNF and charac-

terizing statistical query learning using Fourier analysis. In STOC  pages 253–262  1994.

[14] A. Blumer  A. Ehrenfeucht  D. Haussler  and M. Warmuth. Learnability and the Vapnik-Chervonenkis

dimension. Journal of the ACM  36(4):929–965  1989.

[15] R. Castro and R. Nowak. Minimax bounds for active learning. In COLT  2007.
[16] N. Cesa-Bianchi  C. Gentile  and L. Zaniboni. Learning noisy linear classiﬁers via adaptive and selective

sampling. Machine Learning  2010.

[17] C. Chu  S. Kim  Y. Lin  Y. Yu  G. Bradski  A. Ng  and K. Olukotun. Map-reduce for machine learning on

multicore. In Proceedings of NIPS  pages 281–288  2006.

[18] S. Dasgupta. Coarse sample complexity bounds for active learning. In NIPS  volume 18  2005.
[19] S. Dasgupta. Active learning. Encyclopedia of Machine Learning  2011.
[20] S. Dasgupta and D. Hsu. Hierarchical sampling for active learning. In ICML  pages 208–215  2008.
[21] S. Dasgupta  D.J. Hsu  and C. Monteleoni. A general agnostic active learning algorithm. NIPS  20  2007.
[22] S. Dasgupta  A. Tauman Kalai  and C. Monteleoni. Analysis of perceptron-based active learning. Journal

of Machine Learning Research  10:281–299  2009.

[23] O. Dekel  C. Gentile  and K. Sridharan. Selective sampling and active learning from single and multiple

teachers. JMLR  2012.

[24] J. Dunagan and S. Vempala. A simple polynomial-time rescaling algorithm for solving linear programs.

In STOC  pages 315–320  2004.

[25] C. Dwork  F. McSherry  K. Nissim  and A. Smith. Calibrating noise to sensitivity in private data analysis.

In TCC  pages 265–284  2006.

[26] V. Feldman. A complete characterization of statistical query learning with applications to evolvability.

Journal of Computer System Sciences  78(5):1444–1459  2012.

[27] Y. Freund  H.S. Seung  E. Shamir  and N. Tishby. Selective sampling using the query by committee

algorithm. Machine Learning  28(2-3):133–168  1997.

[28] A. Gonen  S. Sabato  and S. Shalev-Shwartz. Efﬁcient pool-based active learning of halfspaces. In ICML 

2013.

[29] S. Hanneke. A bound on the label complexity of agnostic active learning. In ICML  2007.
[30] M. Kearns. Efﬁcient noise-tolerant learning from statistical queries. JACM  45(6):983–1006  1998.
[31] V. Koltchinskii. Rademacher complexities and bounding the excess risk in active learning.

JMLR 

11:2457–2485  2010.

[32] L. Lov´asz and S. Vempala. The geometry of logconcave functions and sampling algorithms. Random

Struct. Algorithms  30(3):307–358  2007.

[33] A. McCallum and K. Nigam. Employing EM in pool-based active learning for text classiﬁcation.

ICML  pages 350–358  1998.

In

[34] M. Raginsky and A. Rakhlin. Lower bounds for passive and active learning. In NIPS  pages 1026–1034 

2011.

[35] L. G. Valiant. A theory of the learnable. Communications of the ACM  27(11):1134–1142  1984.

9

,Maria-Florina Balcan
Vitaly Feldman