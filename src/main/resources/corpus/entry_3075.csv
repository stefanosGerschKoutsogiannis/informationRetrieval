2017,Learning from uncertain curves: The 2-Wasserstein metric for Gaussian processes,We introduce a novel framework for statistical analysis of populations of non-degenerate Gaussian processes (GPs)  which are natural representations of uncertain curves. This allows inherent variation or uncertainty in function-valued data to be properly incorporated in the population analysis. Using the 2-Wasserstein metric we geometrize the space of GPs with L2 mean and covariance functions over compact index spaces. We prove uniqueness of the barycenter of a population of GPs  as well as convergence of the metric and the barycenter of their finite-dimensional counterparts. This justifies practical computations. Finally  we demonstrate our framework through experimental validation on GP datasets representing brain connectivity and climate development. A Matlab library for relevant computations will be published at https://sites.google.com/view/antonmallasto/software.,Learning from uncertain curves:

The 2-Wasserstein metric for Gaussian processes

Anton Mallasto

Department of Computer Science

University of Copenhagen

mallasto@di.ku.dk

Aasa Feragen

Department of Computer Science

University of Copenhagen

aasa@di.ku.dk

Abstract

We introduce a novel framework for statistical analysis of populations of non-
degenerate Gaussian processes (GPs)  which are natural representations of uncertain
curves. This allows inherent variation or uncertainty in function-valued data to be
properly incorporated in the population analysis. Using the 2-Wasserstein metric we
geometrize the space of GPs with L2 mean and covariance functions over compact
index spaces. We prove uniqueness of the barycenter of a population of GPs  as well
as convergence of the metric and the barycenter of their ﬁnite-dimensional counter-
parts. This justiﬁes practical computations. Finally  we demonstrate our framework
through experimental validation on GP datasets representing brain connectivity and
climate development. A MATLAB library for relevant computations will be pub-
lished at https://sites.google.com/view/antonmallasto/software.

1

Introduction

Gaussian processes (GPs  see Fig. 1) are the
counterparts of Gaussian distributions (GDs)
over functions  making GPs natural objects to
model uncertainty in estimated functions. With
the rise of GP modelling and probabilistic nu-
merics  GPs are increasingly used to model un-
certainty in function-valued data such as seg-
mentation boundaries [17  19  30]  image regis-
tration [38] or time series [28]. Centered GPs  or
covariance operators  appear as image features
in computer vision [12 16 25 26] and as features
of phonetic language structure [23]. A natural
next step is therefore to analyze populations of
GPs  where performance depends crucially on
proper incorporation of inherent uncertainty or
variation. This paper contributes a principled
framework for population analysis of GPs based on Wasserstein  a.k.a. earth mover’s  distances.
The importance of incorporating uncertainty into population analysis is emphasized by the example
in Fig. 2  where each data point is a GP representing the minimal temperature in the Siberian city
Vanavara over the course of one year [9  34]. A naïve way to compute its average temperature curve
is to compute the per-day mean and standard deviation of the yearly GP mean curves. This is shown
in the bottom right plot  and it is clear that the temperature variation is grossly underestimated 
especially in the summer season. The top right ﬁgure shows the mean GP obtained with our proposed
framework  which preserves a far more accurate representation of the natural temperature variation.

Figure 1: An illustration of a GP  with mean func-
tion (in black) and conﬁdence bound (in grey). The
colorful curves are sample paths of this GP.

31st Conference on Neural Information Processing Systems (NIPS 2017)  Long Beach  CA  USA.

Figure 2: Left: Example GPs describing the daily minimum temperatures in a Siberian city (see
Sec. 4). Right top: The mean GP temperature curve  computed as a Wasserstein barycenter. Note
that the inherent variability in the daily temperature is realistically preserved  in contrast with the
naïve approach. Right bottom: A naïve estimation of the mean and standard deviation of the daily
temperature  obtained by taking the day-by-day mean and standard deviation of the temperature. All
ﬁgures show a 95% conﬁdence interval.

We propose analyzing populations of GPs by geometrizing the space of GPs through the Wasserstein
distance  which yields a metric between probability measures with rich geometric properties. We
contribute i) closed-form solutions for arbitrarily good approximation of the Wasserstein distance by
showing that the 2-Wasserstein distance between two ﬁnite-dimensional GP representations converges
to the 2-Wasserstein distance of the two GPs; and ii) a characterization of a non-degenerate barycenter
of a population of GPs  and a proof that such a barycenter is unique  and can be approximated by its
ﬁnite-dimensional counterpart.
We evaluate the Wasserstein distance in two applications. First  we illustrate the use of the Wasserstein
distance for processing of uncertain white-matter trajectories in the brain segmented from noisy
diffusion-weighted imaging (DWI) data using tractography. It is well known that the noise level and
the low resolution of DWI images result in unreliable trajectories (tracts) [24]. This is problematic as
the estimated tracts are e.g. used for surgical planning [8]. Recent work [17  30] utilizes probabilistic
numerics [29] to return uncertain tracts represented as GPs. We utilize the Wassertein distance to
incorporate the estimated uncertainty into typical DWI analysis tools such as tract clustering [37]
and visualization. Our second study quantiﬁes recent climate development based on data from
Russian meteorological stations using permutation testing on population barycenters  and supplies
interpretability of the climate development using GP-valued kernel regression.

Related work. Multiple frameworks exist for comparing Gaussian distributions (GDs) represented
by their covariance matrices  including the Frobenius  Fisher-Rao (afﬁne-invariant)  log-Euclidean
and Wasserstein metrics. Particularly relevant to our work is the 2-Wasserstein metric on GDs  whose
Riemannian geometry is studied in [33]  and whose barycenters are well understood [1  4].
A body of work exists on generalizing the aforementioned metrics to the inﬁnite-dimensional
covariance operators. As pointed out in [23]  extending the afﬁne-invariant and Log-Euclidean
metrics is problematic as covariance operators are not compatible with logarithmic maps and their
inverses are unbounded. These problems are avoided in [25  26] by regularizing the covariance
operators  but unfortunately  this also alters the data in a non-unique way. The Procrustes metric
from [23] avoids this  but as it is  only deﬁnes a metric between covariance operators.
The 2-Wasserstein metric  on the other hand  generalizes naturally from GDs to GPs  does not require
regularization  and can be arbitrarily well approximated by a closed form expression  making the
computations cheap. Moreover  the theory of optimal transport [5  6  36] shows that the Wasserstein
metric yields a rich geometry  which is further demonstrated by the previous work on GDs [33].
After this work was presented in NIPS  a preprint appeared [20] which also studies convergence
results and barycenters of GPs in the Wasserstein geometry  in a more general setting.

2

Structure. Prior to introducing the Wasserstein distance between GPs  we review GPs  their Hilbert
space covariance operators and the corresponding Gaussian measures in Sec. 2. In Sec. 3 we introduce
the Wasserstein metric and its barycenters for GPs and prove convergence properties of the metric
and barycenters  when GPs are approximated by ﬁnite-dimensional GDs. Experimental validation is
found in Sec. 4  followed by discussion and conclusion in Sec. 5.

2 Prerequisites

Gaussian processes and measures. A Gaussian process (GP) f is a collection of random variables 
i=1 has a joint Gaussian distribution  where xi ∈ X 
such that any ﬁnite restriction of its values (f (xi))N
and X is the index set. A GP is entirely characterized by the pair

m(x) = E [f (x)]   k(x  x(cid:48)) = E [(f (x) − m(x))(f (x(cid:48)) − m(x(cid:48)))]  

(1)
where m and k are called the mean function and covariance function  respectively. We use the
notation f ∼ GP(m  k) for a GP f with mean function m and covariance function k. It follows from
the deﬁnition that the covariance function k is symmetric and positive semideﬁnite. We say that f is
non-degenerate  if k is strictly positive deﬁnite. We will assume the GPs used to be non-degenerate.
GPs relate closely to Gaussian measures on Hilbert spaces. Given probability spaces (X  ΣX   µ) and
(Y  ΣY   ν)  we say that the measure ν is a push-forward of µ if ν(A) = µ(T −1(A)) for a measurable
T : X → Y and any A ∈ ΣY . Denote this by T#µ = ν. A Borel measure µ on a separable Hilbert
space H is a Gaussian measure  if its push-forward with respect to any non-zero continuous element
of the dual space of H is a non-degenerate Gaussian measure on R (i.e.  the push-forward gives a
univariate Gaussian distribution). A Borel-measurable set B is a Gaussian null set  if µ(B) = 0 for
any Gaussian measure µ on X. A measure ν on H is regular if ν(B) = 0 for any Gaussian null set
B. Note that regular Gaussian measures correspond to non-degenerate GPs.
Covariance operators. Denote by L2(X) the space of L2-integrable functions from X to R. The
covariance function k has an associated integral operator K : L2(X) → L2(X) deﬁned by

[Kφ](x) =

k(x  s)φ(s)ds  ∀φ ∈ L2(X)  

(2)

X

called the covariance operator associated with k. As a by-product of the 2-Wasserstein metric
on centered GPs  we get a metric on covariance operators. The operator K is Hilbert-Schmidt 
self-adjoint  compact  positive  and of trace class  and the space of such covariance operators is a
convex space. Furthermore  the assignment k (cid:55)→ K from L2(X × X) is an isometric isomorphism
onto the space of Hilbert-Schmidt operators on L2(X) [7  Prop. 2.8.6]. This justiﬁes us to write both
f ∼ GP(m  K) and f ∼ GP(m  k).

Trace of an operator. The Wasserstein distance between GPs admits an analytical formula using
traces of their covariance operators  as we will see below. Let (H (cid:104)· ·(cid:105)) be a separable Hilbert space
with the orthonormal basis {ek}∞
k=1. Then the trace of a bounded linear operator T on H is given by
(3)

∞(cid:88)

(cid:104)T ek  ek(cid:105)  

Tr T :=

which is absolutely convergent and independent of the choice of the basis if Tr (T ∗T ) 1
T ∗ denotes the adjoint operator of T and T 1
class operator. For positive self-adjoint operators  the trace is the sum of their eigenvalues.

2 < ∞  where
2 is the square-root of T . In this case T is called a trace

k=1

(cid:90)

The Wasserstein metric. The Wasserstein metric on probability measures derives from the optimal
transport problem introduced by Monge and made rigorous by Kantorovich. The p-Wasserstein
distance describes the minimal cost of transporting the unit mass of one probability measure into the
unit mass of another probability measure  when the cost is given by a Lp distance [5  6  36].
Let (M  d) be a Polish space (complete and separable metric space) and denote by Pp(M ) the set
M dp(x  x0)dµ(x) < ∞ for some x0 ∈ M. The
p-Wasserstein distance between two probability measures µ  ν ∈ Pp(M ) is given by

of all probability measures µ on M satisfying(cid:82)

Wp(µ  ν) =

inf

γ∈Γ[µ ν]

M×M

dp(x1  x2)dγ(x1  x2)

  (x1  x2) ∈ M × M 

(4)

(cid:18)

(cid:90)

(cid:19) 1

p

3

where Γ[µ  ν] is the set of joint measures on M × M with marginals µ and ν. Deﬁned as above  Wp
satisﬁes the properties of a metric. Furhermore  a minimizer in (4) is always achieved.

3 The Wasserstein metric for GPs

We will now study the Wasserstein metric with p = 2 between GPs. For GDs  this has been studied
in [11  14  18  22  33].
From now on  assume that all GPs f ∼ GP(m  k) are indexed over a compact X ⊂ Rn so that
H := L2(X) is separable. Furthermore  we assume m ∈ L2(X)  k ∈ L2(X × X)  so that
observations of f live almost surely in H. Let f1 ∼ GP(m1  k1) and f2 ∼ GP(m2  k2) be GPs with
associated covariance operators K1 and K2   respectively. As the sample paths of f1 and f2 are in H 
they induce Gaussian measures µ1  µ2 ∈ P2(H) on H  as there is a 1-1 correspondence between GPs
having sample paths almost surely on a L2(X) space and Gaussian measures on L2(X) [27].
The 2-Wasserstein metric between the Gaussian measures µ1  µ2 is given by [13]

W 2

2 (µ1  µ2) = d2

2(m1  m2) + Tr (K1 + K2 − 2(K

1
2

1 K2K

1
2

1 )

1

2 ) 

(5)

where d2 is the canonical metric on L2(X). Using this  we get the following deﬁnition
Deﬁnition 1. Let f1  f2 be GPs as above  and the induced Gaussian measures of f1 and f2 be µ1
and µ2  respectively. Then  their squared 2-Wasserstein distance is given by
2(m1  m2) + Tr (K1 + K2 − 2(K

2 (f1  f2) := W 2

2 (µ1  µ2) = d2

1 K2K

1
2 ) .

W 2

1 )

1
2

1
2

Remark 2. Note that the case m1 = m2 = 0 deﬁnes a metric for the covariance operators K1  K2 
as (5) shows that the space of GPs is isometric to the cartesian product of L2(X) and the covariance
operators. We will denote this metric by W 2
2 (K1  K2). Furthermore  as GDs are just a subset of GPs 
W 2

2 yields also the 2-Wasserstein metric between GDs studied in [11  14  18  22  33].

Barycenters of Gaussian processes. Next  we deﬁne and study barycenters of populations of GPs 
in a similar fashion as the GD case in [1].
Given a population {µi}N
separable Hilbert space  the solution ¯µ of the problem

i=1 ⊂ P2(H) and weights {ξi ≥ 0}N

i=1 with(cid:80)N

i=1 ξi = 1  and H a

N(cid:88)

(P)

inf

ξiW 2

2 (µi  µ) 

µ∈P2(H)
i=1 with barycentric coordinates {ξi}N

i=1

is the barycenter of the population {µi}N
for GPs is deﬁned to be the barycenter of the associated Gaussian measures.
Remark 3. The following theorems require the assumption that the barycenter is non-degenerate; it
is still a conjecture that the barycenter of non-degenerate GPs is nondegenerate [20]  but this holds
in the ﬁnite-dimensional case of GDs.

i=1. The barycenter

We now state the main theorem of this section  which follows from Prop. 5 and Prop. 6 below.
Theorem 4. Let {fi}N
barycenter ¯f ∼ GP( ¯m  ¯K) with barycentric coordinates (ξi)N
¯K satisfy

i=1 be a population of GPs with fi ∼ GP(mi  Ki)  then there exists a unique
i=1. If ¯f is non-degenerate  then ¯m and

N(cid:88)

N(cid:88)

(cid:16) ¯K

(cid:17) 1

2

¯m =

ξimi 

ξi

1

2 Ki ¯K

1
2

= ¯K.

i=1

i=1

i=1 ⊂ P2(H) and ¯µ be a barycenter with barycentric coordinates (ξi)N
i=1.

Proposition 5. Let {µi}N
Assume µi is regular for some i  then ¯µ is the unique minimizer of (P).
Proof. We ﬁrst show that the map ν (cid:55)→ W 2
measure. To see this  let νi ∈ P2(H) and γ∗

2 (µ  ν) is convex  and strictly convex if µ is a regular
i ∈ Γ[µ  νi] be the optimal transport plans between µ and

4

(cid:90)

νi for i = 1  2  then λγ∗

1 + (1 − λ)γ∗

2 ∈ Γ[µ  λν1 + (1 − λ)ν2] for λ ∈ [0  1]. Therefore

2 (µ  λν1 + (1 − λ)ν2) =
W 2
≤

(cid:90)

inf

γ∈Γ[µ λν1+(1−λ)ν2]

d2(x  y)d(λγ∗

d2(x  y)dγ

H×H
1 + (1 − λ)γ∗
2 )

H×H
= λW 2

2 (µ  ν1) + (1 − λ)W 2
which gives convexity. Note that for λ ∈]0  1[  the transport plan λγ∗
2 splits mass.
Therefore it cannot be the unique optimal plan between µ and (1 − t)ν1 + tν2. As µ is regular 
the optimal plan does not split mass  as it is induced by a map [3  Thm. 6.2.10]  so we have strict
convexity. From this follows the strict convexity of the object function in (P).

2 (µ  ν2) 
1 + (1 − λ)γ∗

Next we characterize the barycenter  assuming it is non-degenerate  in the spirit of the ﬁnite-
dinemsional case in [1  Thm. 6.1].
Proposition 6. Let {fi}N
i=1 be a population of centered GPs  fi ∼ GP(0  Ki). Then (P) has a
unique solution ¯f ∼ GP(0  ¯K). If ¯f is non-degenerate  then ¯K is the unique bounded self-adjoint
positive linear operator satisfying

(cid:16)

N(cid:88)

i=1

(cid:17) 1

2

ξi

K

1

2 KiK

1
2

= K.

(6)

Proof. Existence can be shown following the proof for the ﬁnite dimensional case [1  Prop. 4.2] 
which uses multimarginal optimal transport; this appears in the preprint [20  Cor. 9]. For the
characterization  assume ¯f to be non-degenerate  and let

BC(f ) =

ξiW 2

2 (fi  f ) 

N(cid:88)

i=1

N(cid:88)

be the barycentric expression  and assume that the minimizer ¯f of BC is non-degenerate. Let
0 < λ1  λ2  ... be the eigenvalues of ¯K with eigenfunctions e1  e2  .... Then  by [10  Prop. 2.2.] the
transport map between ¯f and fk is given by

∞(cid:88)

∞(cid:88)

i=1

j=1

Tk(x) =

(cid:104)x  ej(cid:105)(cid:104)( ¯K 1
2 Kk ¯K 1
1
λ
i λ
2
j

1
2

2 ej  ei(cid:105)

2 ) 1

ei(x) .

(7)

Using [6  Thm. 8.4.7]  we can write the gradient of the barycentric expression. We furthermore
know that the expression is strictly convex  thus the gradient at ¯f equals zero if and only if ¯f is the
minimizer. Now let Id be the identity operator  then

∇BC( ¯f ) =

(Tk − Id ) = 0 

substituting in (7)  we get

i=1

K

1

2 KiK

1
2

(cid:17) 1

2

= K.

(cid:16)

ξi

N(cid:88)

i=1

Proof of Theorem 4. Use Prop. 6  the properties of a barycenter in a Hilbert space  and that the space
of GPs is isometric to the cartesian product of L2(X) and the covariance operators.

Remark 7. For the practical computations of barycenters of GDs approximating GPs  to be discussed
below  a ﬁxed-point iteration scheme with a guarantee of convergence exists [4  Thm. 4.2].

5

n(cid:88)

∞(cid:88)

k=1

∞(cid:88)

k=1

n(cid:88)

Convergence properties. Now  we show that the 2-Wasserstein metric for GPs can be approxi-
mated arbitrarily well by the 2-Wasserstein metric for GDs. This is important  as in real-life we
observe ﬁnite-dimensional representations of the covariance operators.
Let {ei}∞
and Kin of mi and Ki  i = 1  2  on Vn = span(e1  ...  en) by

i=1 be an orthonormal basis for L2(X). Then we deﬁne the GDs given by restrictions min

min(x) =

(cid:104)mi  ek(cid:105)ek(x)  Kinφ =

(cid:104)φ  ek(cid:105)Kiek  ∀φ ∈ Vn  ∀x ∈ X  

(8)

k=1
and prove the following:
Theorem 8. The 2-Wasserstein metric between GDs on ﬁnite samples converges to the Wasserstein
metric between GPs  that is  if fin ∼ N (min  Kin)  fi ∼ GP(mi  Ki) for i = 1  2  then

k=1

n→∞ W 2
lim

2 (f1n  f2n) = W 2

2 (f1  f2).

By the same argument  it also follows that W 2
topology.
Proof. Kin → Ki in operator norm as n → ∞. Because taking a sum  product and square-root of
operators are all continuous with respect to the operator norm  it follows that

2 (· ·) is continuous in both arguments in operator norm

1
1 )
2 .
Note that for any sequence An → A with convergence in operator norm  we have

1nK2nK

1 K2K

1n)

2 → K1 + K2 − 2(K

K1n + K2n − 2(K

1
2

1
2

1
2

1
2

1

|Tr A − Tr An| ≤

|(cid:104)(A − An)ek  ek(cid:105)| Cauchy-Schwarz

≤

(cid:107)(A − An)ek(cid:107)L2

MCT→ 0  

(9)

(cid:107)(A − An)v(cid:107)L2 = 0 due to the convergence in operator norm. Here MCT stands

as lim

n→∞ sup
v∈L2

ω(X)

for the monotone convergence theorem. Thus we have

W 2

2 (f1n  f2n) = d2

2(m1n  m2n) + Tr (K1n + K2n − 2(K
2(m1  m2) + Tr (K1 + K2 − 2(K
2 (f1  f2).

n→∞→ d2
= W 2

1
2

1
2

1nK2nK

1n)

1
2

1
2 )

1 K2K

1 )

1
2

1
2 )

The importance of Proposition 8 is that it justiﬁes computations of distances using ﬁnite representa-
tions of GPs as approximations for the inﬁnite-dimensional case.
Next  assuming the barycenter is non-degenerate  we show that we can also approximate the barycenter
of a population of GPs by computing the barycenters of populations of GDs converging to these GPs.
In the degenerate case  see [20  Thm. 11].
Theorem 9. Assuming the barycenter of a population of GPs is non-degenerate  then it varies
continuously  that is  the map (f1  ...  fN ) (cid:55)→ ¯f is continuous in the operator norm. Especially  this
implies that the barycenter ¯fn of the ﬁnite-dimensional restrictions {fin}N
First  we show that if fi ∼ GP(mi  Ki) and ¯f = GP( ¯m  ¯K)  then that the map (K1  ...  KN ) (cid:55)→ ¯K
is continuous. Continuity of (m1  ...  mN ) (cid:55)→ ¯m is clear.
Let K be a covariance operator  denote its maximal eigenvalue by λmax(K). Note that this map is
well-deﬁned  as K is also bounded  normal operator  thus λmax(K) = (cid:107)K(cid:107)op < ∞ holds. Now let
a = (K1  ...  KN ) be a population of covariance operators  denote ith as a(i) = Ki  then deﬁne the
continuous function β and correspondence (a set valued map) Φ as follows

i=1 converges to ¯f.

  Φ : a (cid:55)→ Kβ(a) = {K ∈ HS(H) | β(a)I ≥ K ≥ 0}.

(cid:32) N(cid:88)

(cid:33)2
(cid:112)λmax(a(i))

ξi

β : a (cid:55)→

i=1

6

Then the ﬁxed point of (6) can be found in Φ(a)  as the map

F (K) =

ξi

K

1

2 KiK

1
2

(cid:16)

N(cid:88)

i=1

(cid:17) 1

2

 

lim

n→∞ bn = b 

is a compact operator  Φ(a) is bounded  and so the closure of F (Φ(a)) is compact. Furthermore  do
note that F is a map from Φ(a) to itself  so by Schauder’s ﬁxed point theorem  there exists a ﬁxed
point.
Now  we want to show that this correspondence is continuous in order to put the Maximum theorem to
use. A correspondence Φ : A → B is upper hemi-continuous at a ∈ A  if all convergent sequences
(an) ∈ A  (bn) ∈ Φ(an) satisfy lim
n→∞ an = a and b ∈ Φ(a). The correspondence is
lower hemi-continuous at a ∈ A  if for all convergent sequences an → a in A and any b ∈ Φ(a) 
there is a subsequence ank  so that we have a sequence bk ∈ Φ(ank ) which satisﬁes bk → b. If the
correspondence is both upper and lower hemi-continuous  we say that it is continuous. For more
about the Maximum theorem and hemi-continuity  see [2].
Lemma 10. The correspondence Φ : a (cid:55)→ Kβ(a) is continuous as correspondence.
Proof. First  we show the correspondence is lower hemi-continuous. Let (an)∞
n=1 be a sequence of
populations of covariance operators of size N  that converges an → a. Use the shorthand notation
βn := β(an)  then βn → β∞ := β(a)  and let b ∈ Φ(a) = Kβ∞.
Pick subsequence (ank )∞
k=1 is increasing or decreasing. If it was decreasing  then
Kβ∞ ⊆ Kβnk
for every nk. Thus the proof would be ﬁnished by choosing bk = b for every k.
. Now let γ(t) = (1 − t)b1 + tb 
Hence assume the sequence is increasing  so that Kβnk
where b1 ∈ Kβ1  and let tnk be the solution to (1 − t)β1 + tβ∞ = βnk  then bk := γ(tnk ) ∈ Kβnk
and bk → b.
For upper hemicontinuity  assume that an → a  bn ∈ Kβn and that bn → b. Then using the
deﬁnition of Φ  we get the positive sequence (cid:104)(βnI − bn)x  x(cid:105) ≥ 0 indexed by n  then by continuity
and the positivity of this sequence it follows that

k=1 so that (βnk )∞

⊆ Kβnk+1

0 ≤ lim

n→∞(cid:104)(βnI − bn)x  x(cid:105) = (cid:104)(β∞I − b)x  x(cid:105).

One can check the criterion b ≥ 0 similarly  and so we are done.

Proof of Theorem 9. Now let a = (K1  ...  Kn)  f (K  a) := (cid:80)N
(cid:80)N

2 (K  Ki) and F (K) :=
2   then the unique minimizer ¯K of f is the ﬁxed point of F . Furthermore  the
closure cl(F (Kβ(a))) is compact  a (cid:55)→ cl(F (Kβ(a))) is a continuous correspondence as the closure
of composition of two continuous correspondence. Additionally  we know that ¯K ∈ cl(F (Kβ(a))) 
so applying the maximum theorem  we have shown that the barycenter of a population of covariance
operators varies continuously  i.e. the map (K1  ...  KN ) (cid:55)→ ¯K is continuous  ﬁnishing the proof.

i=1 ξi(K 1

i=1 ξiW 2

2 KiK 1

2 ) 1

4 Experiments

We illustrate the utility of the Wasserstein metric in two different applications: Processing of uncertain
white-matter tracts estimated from DWI  and analysis of climate development via temperature curve
GPs.

Experimental setup. The white-matter tract GPs are estimated for a single subject from the
Human Connectome Project [15  32  35]  using probabilistic shortest-path tractography [17]. See
the supplementary material for details on the data and its preprocessing. From daily minimum
temperatures measured at a set of 30 randomly sampled Russian metereological stations [9  34] 
GP regression was used to estimate a GP temperature curve per year and station for the period
1940 − 2009 using maximum likelihood parameters. All code for computing Wasserstein distances
and barycenters was implemented in MATLAB and ran on a laptop with 2 7 GHz Intel Core i5
processor and 8 GB 1867 MHz DDR3 memory. On the temperature GP curves (represented by 50
samples)  the average runtime of the 2-Wasserstein distance computation was 0.048 ± 0.014 seconds
(estimated from 1000 pairwise distance computations)  and the average runtime of the 2-Wasserstein
barycenter of a sample of size 10 was 0.69 ± 0.11 seconds (estimated from 200 samples).

7

White-matter tract processing. The inferior longitudinal fasiculus is a white-matter bundle which
splits into two separate bundles. Fig. 3 (top) shows the results of agglomerative hierarchical clustering
of the GP tracts using average Wasserstein distance. The per-cluster Wasserstein barycenter can
be used to represent the tracts; its overlap with the individual GP mean curves is shown in Fig. 3
(bottom).
The individual GP tracts are visualized via their mean curves  but they are in fact a population of GPs.
To conﬁrm that the two clusters are indeed different also when the covariance function is taken into
account  we perform a permutation test for difference between per-cluster Wasserstein barycenters 
and already with 50 permutations we observe a p-value of p = 0.0196  conﬁrming that the two
clusters are signiﬁcantly different at a 5% signiﬁcance level.

Quantifying climate change. Using the Wasserstein
barycenters we perform nonparametric kernel regression to
visualize how yearly temperature curves evolve with time 
based on the Russian yearly temperature GPs. Fig. 4 shows
snapshots from this evolution  and a continuous movie ver-
sion climate.avi is found in the supplementary material.
The regressed evolution indicates an increase in overall
temperature as we reach the ﬁnal year 2009. To quan-
tify this observation  we perform a permutation test using
the Wasserstein distance between population Wasserstein
barycenters to compare the ﬁnal 10 years 2000-2009 with
the years 1940-1999. Using 50 permutations we obtain a
p-value of 0.0392  giving signiﬁcant difference in temper-
ature curves at a 95% conﬁdence level.

Signiﬁcance. Note that the state-of-the-art in tract anal-
ysis as well as in functional data analysis would be to
ignore the covariance of the estimated curves and treat
the mean curves as observations. We contribute a frame-
work to incorporate the uncertainty into the population
analysis – but why would we want to retain uncertainty?
In the white-matter tracts  the GP covariance represents
spatial uncertainty in the estimated curve trajectory. The
individual GPs represent connections between different
endpoints. Thus  they do not represent observations of
the exact same trajectory  but rather of distinct  nearby
trajectories. It is common in diffusion MRI to represent
such sets of estimated trajectories by a few prototype tra-
jectories for visualization and comparative analysis; we obtain prototypes through the Wasserstein
barycenter. To correctly interpret the spatial uncertainty  e.g. for a brain surgeon [8]  it is crucial
that the covariance of the prototype GP represents the covariances of the individual GPs  and not
smaller. If you wanted to reduce uncertainty by increasing sample size  you would need more images 
not more curves – because the noise is in the image. But more images are not usually available. In
the climate data  the GP covariance models natural temperature variation  not measurement noise.
Increasing the sample size decreases the error of the temperature distribution  but should not decrease
this natural variation (i.e. the covariance).

Figure 3: Top: The mean functions of
the individual GPs  colored by cluster
membership  in the context of the corre-
sponding T1-weighted MRI slices. Bot-
tom: The tract GP mean functions and
the cluster mean GPs with 95% conﬁ-
dence bounds.

5 Discussion and future work

We have shown that the Wasserstein metric for GPs is both theoretically and computationally well-
founded for statistics on GPs: It deﬁnes unique barycenters  and allows efﬁcient computations
through ﬁnite-dimensional representations. We have illustrated its use in two different applications:
Processing of uncertain estimates of white-matter trajectories in the brain  and analysis of climate
development via GP representations of temperature curves. We have seen that the metric itself is
discriminative for clustering and permutation testing  and we have seen how the GP barycenters allow
truthful interpretation of uncertainty in the white matter tracts and of variation in the temperature
curves.

8

Figure 4: Snapshots from the kernel regression giving yearly temperature curves 1940-2009. We
observe an apparent temperature increase which is conﬁrmed by the permutation test.

Future work includes more complex learning algorithms  starting with preprocessing tools such as
PCA [31]  and moving on to supervised predictive models. This includes a better understanding of
the potentially Riemannian structure of the inﬁnite-dimensional Wasserstein space  which would
enable us to draw on existing results for learning with manifold-valued data [21].
The Wasserstein distance allows the inherent uncertainty in the estimated GP data points to be
appropriately accounted for in every step of the analysis  giving truthful analysis and subsequent
interpretation. This is particularly important in applications where uncertainty or variation is crucial:
Variation in temperature is an important feature in climate change  and while estimated white-matter
trajectories are known to be unreliable  they are used in surgical planning  making uncertainty about
their trajectories a highly relevant parameter.

6 Acknowledgements

This research was supported by Centre for Stochastic Geometry and Advanced Bioimaging  funded
by a grant from the Villum Foundation. Data were provided [in part] by the Human Connec-
tome Project  WU-Minn Consortium (Principal Investigators: David Van Essen and Kamil Ugurbil;
1U54MH091657) funded by the 16 NIH Institutes and Centers that support the NIH Blueprint for
Neuroscience Research; and by the McDonnell Center for Systems Neuroscience at Washington Uni-
versity. The authors would also like to thank Mads Nielsen for valuable discussions and supervision.
Finally  the authors would like to thank Victor Panaretos for valuable discussions and  in particular 
for pointing out an error in an earlier version of the manuscript.

References
[1] M. Agueh and G. Carlier. Barycenters in the Wasserstein space. SIAM Journal on Mathematical Analysis 

[2] C. Aliprantis and K. Border. Inﬁnite dimensional analysis: a hitchhiker’s guide. Studies in Economic

43(2):904–924  2011.

Theory  4  1999.

[3] P. Álvarez-Esteban  E. Del Barrio  J. Cuesta-Albertos  C. Matrán  et al. Uniqueness and approximate com-
putation of optimal incomplete transportation plans. In Annales de l’Institut Henri Poincaré  Probabilités
et Statistiques  volume 47  pages 358–375. Institut Henri Poincaré  2011.

[4] P. C. Álvarez-Esteban  E. del Barrio  J. Cuesta-Albertos  and C. Matrán. A ﬁxed-point approach to
barycenters in Wasserstein space. Journal of Mathematical Analysis and Applications  441(2):744–762 
2016.

[5] L. Ambrosio and N. Gigli. A user’s guide to optimal transport. In Modelling and optimisation of ﬂows on

networks  pages 1–155. Springer  2013.

[6] L. Ambrosio  N. Gigli  and G. Savaré. Gradient ﬂows: in metric spaces and in the space of probability

measures. Springer Science & Business Media  2008.

[7] W. Arveson. A short course on spectral theory  volume 209. Springer Science & Business Media  2006.
[8] J. Berman. Diffusion MR tractography as a tool for surgical planning. Magnetic resonance imaging clinics

of North America  17(2):205–214  2009.

[9] O. Bulygina and V. Razuvaev. Daily temperature and precipitation data for 518 russian meteorological
stations. Carbon Dioxide Information Analysis Center  Oak Ridge National Laboratory  US Department of
Energy  Oak Ridge  Tennessee  2012.

[10] J. Cuesta-Albertos  C. Matrán-Bea  and A. Tuero-Diaz. On lower bounds for the l2-Wasserstein metric in

a Hilbert space. Journal of Theoretical Probability  9(2):263–283  1996.

9

[11] D. Dowson and B. Landau. The Fréchet distance between multivariate normal distributions. Journal of

multivariate analysis  12(3):450–455  1982.

[12] M. Faraki  M. T. Harandi  and F. Porikli. Approximate inﬁnite-dimensional region covariance descriptors
for image classiﬁcation. In Acoustics  Speech and Signal Processing (ICASSP)  2015 IEEE International
Conference on  pages 1364–1368. IEEE  2015.

[13] M. Gelbrich. On a formula for the L2 Wasserstein metric between measures on Euclidean and Hilbert

spaces. Mathematische Nachrichten  147(1):185–203  1990.

[14] C. R. Givens  R. M. Shortt  et al. A class of Wasserstein metrics for probability distributions. The Michigan

Mathematical Journal  31(2):231–240  1984.

[15] M. F. Glasser  S. N. Sotiropoulos  J. A. Wilson  T. S. Coalson  B. Fischl  J. L. Andersson  J. Xu  S. Jbabdi 
M. Webster  J. R. Polimeni  et al. The minimal preprocessing pipelines for the Human Connectome project.
Neuroimage  80:105–124  2013.

[16] M. Harandi  M. Salzmann  and F. Porikli. Bregman divergences for inﬁnite dimensional covariance
matrices. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition  pages
1003–1010  2014.

[17] S. Hauberg  M. Schober  M. Liptrot  P. Hennig  and A. Feragen. A random Riemannian metric for
probabilistic shortest-path tractography. In International Conference on Medical Image Computing and
Computer-Assisted Intervention  pages 597–604. Springer  2015.

[18] M. Knott and C. S. Smith. On the optimal mapping of distributions. Journal of Optimization Theory and

Applications  43(1):39–49  1984.

[19] M. Lê  J. Unkelbach  N. Ayache  and H. Delingette. GPSSI: Gaussian process for sampling segmentations
of images. In International Conference on Medical Image Computing and Computer-Assisted Intervention 
pages 38–46. Springer  2015.

[20] V. Masarotto  V. M. Panaretos  and Y. Zemel. Procrustes metrics on covariance operators and optimal

transportation of gaussian processes. arXiv preprint arXiv:1801.01990  2018.

[21] J. Masci  D. Boscaini  M. Bronstein  and P. Vandergheynst. Geodesic convolutional neural networks
on Riemannian manifolds. In Proceedings of the IEEE international conference on computer vision
workshops  pages 37–45  2015.

[22] I. Olkin and F. Pukelsheim. The distance between two random vectors with given dispersion matrices.

Linear Algebra and its Applications  48:257–263  1982.

[23] D. Pigoli  J. A. Aston  I. L. Dryden  and P. Secchi. Distances and inference for covariance operators.

Biometrika  101(2):409–422  2014.

[24] S. Pujol  W. Wells  C. Pierpaoli  C. Brun  J. Gee  G. Cheng  B. Vemuri  O. Commowick  S. Prima  A. Stamm 
et al. The DTI challenge: toward standardized evaluation of diffusion tensor imaging tractography for
neurosurgery. Journal of Neuroimaging  25(6):875–882  2015.

[25] M. H. Quang and V. Murino. From covariance matrices to covariance operators: Data representation from
ﬁnite to inﬁnite-dimensional settings. In Algorithmic Advances in Riemannian Geometry and Applications 
pages 115–143. Springer  2016.

[26] M. H. Quang  M. San Biagio  and V. Murino. Log-Hilbert-Schmidt metric between positive deﬁnite
operators on Hilbert spaces. In Advances in Neural Information Processing Systems  pages 388–396  2014.
[27] B. S. Rajput. Gaussian measures on Lp spaces  1 ≤ p < ∞. Journal of Multivariate Analysis  2(4):382–

403  1972.

[28] S. Roberts  M. Osborne  M. Ebden  S. Reece  N. Gibson  and S. Aigrain. Gaussian processes for time-series

modelling. Phil. Trans. R. Soc. A  371(1984):20110550  2013.

[29] M. Schober  D. K. Duvenaud  and P. Hennig. Probabilistic ODE solvers with Runge-Kutta means. In

Advances in neural information processing systems  pages 739–747  2014.

[30] M. Schober  N. Kasenburg  A. Feragen  P. Hennig  and S. Hauberg. Probabilistic shortest path tractography
in DTI using Gaussian Process ODE solvers. In International Conference on Medical Image Computing
and Computer-Assisted Intervention  pages 265–272. Springer  2014.

[31] V. Seguy and M. Cuturi. Principal geodesic analysis for probability measures under the optimal transport

metric. In Advances in Neural Information Processing Systems  pages 3312–3320  2015.

[32] S. Sotiropoulos  S. Moeller  S. Jbabdi  J. Xu  J. Andersson  E. Auerbach  E. Yacoub  D. Feinberg  K. Set-
sompop  L. Wald  et al. Effects of image reconstruction on ﬁber orientation mapping from multichannel
diffusion MRI: reducing the noise ﬂoor using SENSE. Magnetic resonance in medicine  70(6):1682–1689 
2013.

[33] A. Takatsu et al. Wasserstein geometry of Gaussian measures. Osaka Journal of Mathematics  48(4):1005–

1026  2011.

[34] R. Tatusko and J. A. Mirabito. Cooperation in climate research: An evaluation of the activities conducted
under the US-USSR agreement for environmental protection since 1974. National Climate Program Ofﬁce 
1990.

[35] D. C. Van Essen  S. M. Smith  D. M. Barch  T. E. Behrens  E. Yacoub  K. Ugurbil  W.-M. H. Consortium 

et al. The wu-minn Human Connectome project: an overview. Neuroimage  80:62–79  2013.

10

[36] C. Villani. Topics in optimal transportation. Number 58. American Mathematical Soc.  2003.
[37] D. Wassermann  L. Bloy  E. Kanterakis  R. Verma  and R. Deriche. Unsupervised white matter ﬁber
clustering and tract probability map generation: Applications of a Gaussian process framework for white
matter ﬁbers. NeuroImage  51(1):228–241  2010.

[38] X. Yang and M. Niethammer. Uncertainty quantiﬁcation for LDDMM using a low-rank Hessian approxi-
mation. In International Conference on Medical Image Computing and Computer-Assisted Intervention 
pages 289–296. Springer  2015.

11

,Anton Mallasto
Aasa Feragen