2012,Accuracy at the Top,We introduce a new notion of classification accuracy based on the top $\tau$-quantile values of a scoring function  a relevant criterion in a number of problems arising for search engines. We define an algorithm optimizing a convex surrogate of the corresponding loss  and show how its solution can be obtained by solving several convex optimization problems. We also present margin-based guarantees for this algorithm based on the $\tau$-quantile of the functions in the hypothesis set. Finally  we report the results of several experiments evaluating the performance of our algorithm. In a comparison in a bipartite setting with several algorithms seeking high precision at the top  our algorithm achieves a better performance in precision at the top.,Accuracy at the Top

Stephen Boyd

Stanford University

Packard 264

Stanford  CA 94305
boyd@stanford.edu

Mehryar Mohri

Courant Institute and Google

251 Mercer Street

New York  NY 10012
mohri@cims.nyu.edu

Corinna Cortes
Google Research
76 Ninth Avenue

New York  NY 10011
corinna@google.com

Ana Radovanovic
Google Research
76 Ninth Avenue

New York  NY 10011

anaradovanovic@google.com

Abstract

We introduce a new notion of classiﬁcation accuracy based on the top ⌧-quantile
values of a scoring function  a relevant criterion in a number of problems aris-
ing for search engines. We deﬁne an algorithm optimizing a convex surrogate of
the corresponding loss  and discuss its solution in terms of a set of convex opti-
mization problems. We also present margin-based guarantees for this algorithm
based on the top ⌧-quantile value of the scores of the functions in the hypothesis
set. Finally  we report the results of several experiments in the bipartite setting
evaluating the performance of our solution and comparing the results to several
other algorithms seeking high precision at the top. In most examples  our solution
achieves a better performance in precision at the top.

1

Introduction

The accuracy of the items placed near the top is crucial for many information retrieval systems such
as search engines or recommendation systems  since most users of these systems browse or consider
only the ﬁrst k items. Different criteria have been introduced in the past to measure this quality 
including the precision at k (Precision@k)  the normalized discounted cumulative gain (NDCG)
and other variants of DCG  or the mean reciprocal rank (MRR) when the rank of the most relevant
document is critical. A somewhat different but also related criterion adopted by [1] is based on the
position of the top irrelevant item.
Several machine learning algorithms have been recently designed to optimize these criteria and other
related ones [6  12  11  21  7  14  13]. A general algorithm inspired by the structured prediction
technique SVMStruct [22] was incorporated in an algorithm by [15] which can be used to optimize
a convex upper bound on the number of errors among the top k items. The algorithm seeks to
solve a convex problem with exponentially many constraints via several rounds of optimization
with a smaller number of constraints  augmenting the set of constraints at each round with the
most violating one. Another algorithm  also based on structured prediction ideas  is proposed in
an unpublished manuscript of [19] and covers several criteria  including Precision@k and NDCG.
A regression-based solution is suggested by [10] for DCG in the case of large sample sizes. Some
other methods have also been proposed to optimize a smooth version of a non-convex cost function
in this context [8]. [1] discusses an optimization solution for an algorithm seeking to minimize the
position of the top irrelevant item.

1

However  one obvious shortcoming of all these algorithms is that the notion of top k does not gen-
eralize to new data. For what k should one train if the test data in some instances is half the size and
in other cases twice the size? In fact  no generalization guarantee is available for such precision@k
optimization or algorithm.
A more principled approach in all the applications already mentioned consists of designing algo-
rithms that optimize accuracy in some top fraction of the scores returned by a real-valued hypothe-
sis. This paper deals precisely with this problem. The desired objective is to learn a scoring function
that is as accurate as possible for the items whose scores are above the top ⌧-quantile. To be more
speciﬁc  when applied to a set of size n  the number of top items is k = ⌧n for a ⌧-quantile  while
for a different set of size n0 6= n  this would correspond to k0 = ⌧n0 6= k.
The implementation of the Precision@k algorithm in [15] indirectly acknowledges the problem that
the notion of top k does not generalize since the command-line ﬂag requires k to be speciﬁed as a
fraction of the positive samples. Nevertheless  the formulation of the problem as well as the solution
are still in terms of the top k items of the training set. A study of various statistical questions related
to the problem of accuracy at the top is discussed by [9]. The authors also present generalization
bounds for the speciﬁc case of empirical risk minimization (ERM) under some assumptions about
the hypothesis set and the distribution. But  to our knowledge  no previous publication has given
general learning guarantees for the problem of accuracy in the top quantile scoring items or carefully
addressed the corresponding algorithmic problem.
We discuss the formulation of this problem (Section 3.1) and deﬁne an algorithm optimizing a
convex surrogate of the corresponding loss in the case of linear scoring functions. We discuss the
solution of this problem in terms of several simple convex optimization problems and show that these
problems can be extended to the case where positive semi-deﬁnite kernels are used (Section 3.2).
In Section 4  we present a Rademacher complexity analysis of the problem and give margin-based
guarantees for our algorithm based on the ⌧-quantile value of the functions in the hypothesis set.
In Section 5  we also report the results of several experiments evaluating the performance of our
algorithm.
In a comparison in a bipartite setting with several algorithms seeking high precision
at the top  our algorithm achieves a better performance in precision at the top. We start with a
presentation of notions and notation useful for the discussion in the following sections.

2 Preliminaries

Let X denote the input space and D a distribution over X⇥X . We interpret the presence
of a pair (x  x0) in the support of D as the preference of x0 over x. We denote by S =
(x1  x01)  . . .   (xm  x0m) 2 (X⇥X )m a labeled sample of size m drawn i.i.d. according to D
and denote by bD the corresponding empirical distribution. D induces a marginal distribution over
X that we denote by D0  which in the discrete case can be deﬁned via

D0(x) =

1

2 Xx02XD(x  x0) + D(x0  x).

We also denote by bD0 the empirical distribution associated to D0 based on the sample S.
The learning problems we are studying are deﬁned in terms of the top ⌧-quantile of the values taken
by a function h: X! R  that is a score q such that Prx⇠D0[h(x) > q] = ⌧ (see Figure 1(a)). In
general  q is not unique and this equality may hold for all q in an interval [qmin  qmax]. We will be
particularly interested in the properties of the set of points x whose scores are above a quantile  that
is sq = {x: h(x) > q}. Since for any (q  q0) 2 [qmin  qmax]2  sq and sq0 differ only by a set of
measure zero  the particular choice of q in that interval has no signiﬁcant consequence. Thus  in
what follows  when it is not unique  we will choose the quantile value to be the maximum  qmax.
For any ⌧ 2 [0  1]  let ⇢⌧ denote the function deﬁned by

8u 2 R ⇢

⌧ (u) = ⌧(u) + (1  ⌧)(u)+ 

where (u)+ = max(u  0) and (u) = min(u  0) (see Figure 1(b)). ⇢⌧ is convex as a sum
of two convex functions since u 7! (u)+ is convex  u 7! (u) concave. We will denote by
argMinu f(u) the largest minimizer of function f.
It is known (see for example [17]) that the

2

τ-Quantile
⌧ 2 [0  1]
Set   .

U = {u1  . . .   un}  R

 top τ fraction 

of scores

ρτ

Mehryar Mohri - Courant & Google

page

5

(a)

0

(b)

u

Figure 1: (a) Illustration of the ⌧-quantile. (b) Graph of function ⇢⌧ for ⌧ = .25.

(maximum) ⌧-quantile value bq of a sample of real numbers X = (u1  . . .   un) 2 Rn can be
given by bq = argMinu2R F⌧ (u)  where F⌧ is the convex function deﬁned for all u 2 R by

nPn
i=1 ⇢⌧ (ui  u).

F⌧ (u) = 1

Mehryar Mohri - Courant & Google

page

1

3 Accuracy at the top (AATP)

3.1 Problem formulation and algorithm

The learning problem we consider is that of accuracy at the top (AATP) which consists of achieving
an ordering of all items so that items whose scores are among the top ⌧-quantile are as relevant as
possible. Ideally  all preferred items are ranked above the quantile and non-preferred ones ranked
below. Thus  the loss or generalization error of a hypothesis h: X! R with top ⌧-quantile value
qh is the average number of non-preferred elements that h ranks above qh and preferred ones ranked
below:

R(h) =

1
2

E

(x x0)⇠D⇥1h(x)>qh + 1h(x0)<qh⇤.

qh can be deﬁned as follows in terms of the distribution D0: qh = argMinu2R Ex⇠D0[⇢⌧ (h(x)u)].
The quantile value qh depends on the true distribution D. To deﬁne the empirical error of h for a

sample S =(x1  x01)  . . .   (xm  x0m)2 (X⇥X )m  we will use instead an empirical estimatebqh of
qh: bqh = argMinu2R Ex⇠bD0[⇢⌧ (h(x)  u)]. Thus  we deﬁne the empirical error of h for a labeled

sample as follows:

bR(h) =

1
2m

mXi=1⇥1h(xi)>bqh + 1h(x0i)<bqh⇤.

In the following  we will assume that ⌧ is a multiple of 1/2m  otherwise it can be rounded to the
nearest such value.

3.2 Analysis of the optimization problem

Problem (1) is not a convex optimization problem since  while the objective function is convex  the
equality constraint is not afﬁne. Here  we further analyze the problem and discuss a solution.

3

We ﬁrst assume that X is a subset of RN for some N  1 and consider a hypothesis set H of linear
functions h: x 7! w · x. We will use a surrogate empirical loss taking into consideration how much
the score w·xi of a non-preferred item xi exceedsbqh  and similarly how much lower the score w·x0i
for a preferred point x0i is thanbqh  and seek a solution w minimizing a trade-off of that surrogate

loss and the norm squared kwk2. This leads to the following optimization problem for AATP:

min
w

1

2kwk2 + Ch mXi=1w · xi bqw + 1+ +bqw  w · x0i + 1+i

Q⌧ (w  u) 

(1)

where C  0 is a regularization parameter and Q⌧ the quantile function deﬁned as follows for a
sample S  for any w 2 RN and u 2 R:

u2R

subject to bqw = argMin
2mh mXi=1

Q⌧ (w  u) =

1

⇢⌧(w · xi)  u) + ⇢⌧(w · x0i)  u)i.

The equality constraint could be written as an inﬁnite number of inequalities of Q⌧ (w bqw) 

Q⌧ (w  u) for all u 2 R. Observe  however  that the quantile value qw must coincide with the score
of one of training points xk or x0k  that is w · xk or w · x0k. Thus  Problem (1) can be equivalently
written with a ﬁnite number of constraints as follows:

1

min
w

subject to bqw 2{ w · xk  w · x0k : k 2 [1  m]}

2kwk2 + Ch mXi=1w · xi bqw + 1+ +bqw  w · x0i + 1+i
8k 2 [1  m]  Q⌧ (w bqw)  Q⌧ (w  w · xk) 8k 2 [1  m]  Q⌧ (w bqw)  Q⌧ (w  w · x0k).

The inequality constraints do not correspond to non-positivity constraints on convex functions.
Thus  the problem is not a standard convex optimization problem  but our analysis leads us
to a simple approximate solution for the problem. For convenience  let (z1  . . .   z2m) denote
(x1  . . .   xm  x01  . . .   x0m). Our method consists of solving the convex quadratic programming (QP)
problem for each value of k 2 [1  2m]:

min
w

1

2kwk2 + Ch mXi=1w · xi bqw + 1+ +bqw  w · x0i + 1+i

(2)

subject to bqw = w · zk.

Let wk be the solution of Problem (2). For each k 2 [1  2m]  we determine the ⌧-quantile value
of the scores {wk·zi : i 2 [1  2m]}. This can be checked straightforwardly in time O(m log m) by
sorting the scores. Then  the solution w⇤ we return is the wk for which wk ·zk is closest to the
⌧-quantile value  the one for which the objective function is the smallest in the presence of ties. The
method for determining w⇤ is thus based on the solution of 2m simple QPs. Our solution naturally
parallelizes so that on a distributed computing environment  the computational time for solving the
problem can be reduced to roughly the same as that of solving a single QP.

3.3 Kernelized formulation
For any i2[1  2m]  let yi =1 if i m  yi =+1 otherwise. Then  Problem (2) admits the following
equivalent dual optimization problem similar to that of SVMs:

max
↵

1
2

↵i 

2mXi=1

2mXi j=1

subject to: 8i 2 [1  2m]  0  ↵i  C 

↵i↵jyiyj(zi  zk) · (zj  zk)

(3)

which depends only on inner products between points of the training set. The vector w can be
obtained from the solution via w =P2m
i=1 ↵iyi(zizk). The algorithm can therefore be generalized
by using equivalently any positive semi-deﬁnite kernel symmetric (PDS) kernel K : X⇥X! R
instead of the inner product in the input space  thereby also extending it to the case of non-vectorial
input spaces X . The corresponding hypothesis set H is that of linear functions h: x 7! w · (x)
where : X! H is a feature mapping to a Hilbert space H associated to K and w an element of
H. In view of (3)  for any k 2 [1  2m]  the dual problem of (2) can then be expressed as follows:

max
↵

1
2

↵i 

2mXi=1

2mXi j=1

subject to: 8i 2 [1  2m]  0  ↵i  C 

↵i↵jyiyjKk(zi  zj)

(4)

where  for any k 2 [1  2m]  Kk is the PDS kernel deﬁned by Kk : (z  z0) 7! K(z  z0)  K(z  zk) 
K(zk  z0) + K(zk  zk). Our solution can therefore also be found in the dual by solving the 2m QPs
deﬁned by (4).

4 Theoretical guarantees

We here present margin-based generalization bounds for the AATP learning problem.

4

1
2

R(h  t) =

Let ⇢ : R ! [0; 1] be the function deﬁned by ⇢ : x 7! 1x0 + (1  x/⇢)+1x>0. For any ⇢> 0
and t2 R  we deﬁne the generalization error R(h  t) and empirical margin loss bR⇢(h  t)  both with
respect to t  by
mXi=1⇥⇢(t  h(xi)) + ⇢(h(x0i)  t)⇤.
In particular  R(h  qh) corresponds to the generalization error and bR⇢(h  qh) to the empirical margin
loss of a hypothesis h for AATP. For any t > 0  the empirical margin loss bR⇢(h  t) is upper bounded

by the average of the fraction of non-preferred elements xi that h ranks above t or less than ⇢ below
t  and the fraction of preferred ones x0i it ranks below t or less than ⇢ above t:

(x x0)⇠D⇥1h(x)>t + 1h(x0)<t⇤ bR⇢(h  t) =

1
2m

E

bR⇢(h  t) 

1
2m

mXi=1⇥1th(xi)<⇢ + 1h(x0i)t<⇢⇤.

(5)

m (H) the Rademacher complexity of H with respect to the marginal distribution D1  that is

We denote by D1 the marginal distribution of the ﬁrst element of the pairs in X⇥X derived from
D  and by D2 the marginal distribution with respect to the second element. Similarly  S1 is the
sample derived from S by keeping only the ﬁrst element of each pair: S1 = x1  . . .   xm and
S2 the one obtained by keeping only the second element: S2 = x01  . . .   x0m. We also denote
by RD1
m (H) = E[bRS1(H)]  and RD2
RD1
Theorem 1 Let H be a set of real-valued functions taking values in [M  +M] for some M > 0.
Fix ⌧ 2 [0  1] and ⇢> 0  then  for any > 0  with probability at least 1   over the choice of a
sample S of size m  each of the following inequalities holds for all h 2 H and t 2 [M  +M]:

m (H) = E[bRS2(H)].

R(h  t)  bR⇢(h  t)+
R(h  t)  bR⇢(h  t)+

1

m (H) +

m (H) + RD2

⇢✓RD1
⇢✓bRS1(H) +bRS2(H) +

1

2M

pm◆+rlog 1/
pm◆+3rlog 2/

2M

2m

2m

.

Proof. Let eH be the family of hypotheses mapping (X⇥X ) to R deﬁned by eH = {z = (x  x0) 7!
t  h(x): h 2 H  t 2 [M  +M]} and similarly eH0 = {z = (x  x0) 7! h(x0)  t: h 2 H  t 2
[M  +M]}. Consider the two families of functions eH and eH0 taking values in [0  1] deﬁned by
eH = {⇢  f : f 2 eH} and eH0 = {⇢  f : f 2 eH0}. By the general Rademacher complexity
bounds for functions taking values in [0  1] [18  3  20]  with probability at least 1   

1
2

E⇥⇢(t  h(x)) + ⇢(h(x0)  t)⇤  bR⇢(h  t) + 2Rm⇣1

2

(eH + eH0)⌘ +rlog 1/
 bR⇢(h  t) + Rm(eH) + Rm(eH0 +rlog 1/

2m

2m

 

for all h 2 H. Since 1u<0  ⇢(u) for all u 2 R  the generalization error R(h  t) is a lower bound
on left-hand side: R(h  t)  1

2 E⇥⇢(t  h(x)) + ⇢(h(x0)  t)⇤  we obtain
R(h  t)  bR⇢(h  t) + Rm(eH) + Rm(eH0 +rlog 1/
Since ⇢ is 1/⇢-Lipschitz  by Talagrand’s contraction lemma  we have RmeH  (1/⇢)Rm(eH)
and RmeH0  (1/⇢)Rm(eH0). By deﬁnition of the Rademacher complexity 
S⇠Dm " sup
ih(xi)#
Rm(eH)=
h

S "sup
i(t  h(xi))#=
mXi=1
ih(xi).
 sup
ii+
mXi=1

mXi=1
mXi=1

it + sup
h2H

t2[M +M ]

mXi=1

h2H t

1
m

1
m

1
m

1
m

h2H

sup

2m

=

E

E

E

E

t

.

t

5

E

i

M

i=1 i<0

E

sup

i=1 i>0

MtM

mXi=1

mXi=1

m XPm
i2i 1

m XPm
"
mXi=1

Since the random variables i and i follow the same distribution  the second term coincides with
m (H). The ﬁrst term can be rewritten and upper bounded as follows using Jensen’s inequality:
RD1
"
1
m

it# = M

i 

Pr[]

Pr[]

= M
m

ii 1

2 = M
m

h mXi=1

i# 
(1/p2). Similarly  we can show that Rm(eH0)  RD2

2 = M
pm
Note that  by the Kahane-Khintchine inequality  the last upper bound used is tight modulo a constant
m (H)+M/pm. This proves the ﬁrst inequality
of the theorem; the second inequality can be derived from the ﬁrst one using the standard bound
relating the empirical and true Rademacher complexity. 2
Since the bounds of the theorem hold uniformly for all t 2 [M  +M]  they hold in particular for
any quantile value qh.
Corollary 1 (Margin bounds for AATP) Let H be a set of real-valued functions taking values in
[M  +M] for some M > 0. Fix ⌧ 2 [0  1] and ⇢> 0  then  for any > 0  with probability at least
1   over the choice of a sample S of size m  for all h 2 H it holds that:

mXi=1
h mXi=1

M
m

E

E

2

.

R(h)bR⇢(h  qh)+
R(h)bR⇢(h  qh)+

1

m (H) +

m (H) + RD2

⇢✓RD1
⇢✓bRS1(H) +bRS2(H) +

1

2M

pm◆+rlog 1/
pm◆+3rlog 2/

2M

2m

2m

.

A more explicit version of this corollary can be derived for kernel-based hypotheses (Appendix A).
In the results of the previous theorem and corollary  the right-hand side of the generalization bounds
is expressed in terms of the empirical margin loss with respect to the true quantile value qh  which
is upper bounded (see (5)) by half the fraction of non-preferred points in the sample whose score is
above qh  ⇢ and half the fraction of the preferred points whose score is less than qh + ⇢. These
fractions are close to the same fractions with qh replaced withbqh since the probability that a score
falls between qh andbqh can be shown to be uniformly bounded by a term in O(1/pm).1 Altogether 

this analysis provides a strong support for our algorithm which is precisely seeking to minimize the
sum of an empirical margin loss based on the quantile and a term that depends on the complexity  as
in the right-hand side of the learning guarantees above.

5 Experiments

This section reports the results of experiments with our AATP algorithm on several datasets. To
measure the effectiveness of our algorithm  we compare it to two other algorithms  the INFINITE-
PUSH algorithm [1] and the SVMPERF algorithm [15]  which are both algorithms seeking to em-
phasize the accuracy near the top. Our experiments are carried out using three data sets from the
UC Irvine Machine Learning Repository http://archive.ics.uci.edu/ml/datasets.html:
Ionosphere  Housing  and Spambase. (Results for Spambase can be found in Appendix C). In ad-
dition  we use the TREC 2003 (LETOR 2.0) data set which is available for download from the
following Microsoft Research URL: http://research.microsoft.com/letor.
All the UC Irvine data sets we experiment with are for two-group classiﬁcation problems. From
these we construct bipartite ranking problems where a preference pair consists of one positive and
one negative example. To explicitly indicate the dependency on the quantile  we denote by q⌧ the
value of the top ⌧-th quantile of the score distribution of a hypothesis. We will use N to denote the
number of instances in a particular data set  as well as si  i = 1  . . .   N  to denote the particular
score values. If n+ denotes the number of positive examples in the data set and n denotes the
number of negative examples  then N = n+ + n and the number of preferences is m = n+n.

1Note that the Bahadur-Kiefer representation is known to provide a uniform convergence bound on the
difference of the true and empirical quantiles when the distribution admits a density [2  16]  a stronger result
than what is needed in our context.

6

Table 1: Ionosphere data: for each top quantile ⌧ and each evaluation metric  the three rows cor-
respond to AATP (top)  SVMPERF(middle) and INFINITEPUSH (bottom). For the INFINITEPUSH
algorithm we only report mean values over the folds.

⌧ (%)

P@⌧

AP

DCG@⌧

NDCG@⌧ Positives@top

27.83

0.85

0.87

0.80

0.80

19

14

10.32

12.1 ± 12.5
0.89 ± 0.04 0.86 ± 0.03 29.21 ± 0.10 0.92 ± 0.06
6.00 ± 11.1
0.89 ± 0.06 0.83 ± 0.04 28.88 ± 1.37 0.89 ± 0.11
0.91 ± 0.05 0.84 ± 0.03 28.15 ± 0.95 0.91 ± 0.07 13.31 ± 12.5
0.82 ± 0.11 0.79 ± 0.04 27.02 ± 1.37 0.75 ± 0.16
4.10 ± 11.1
9.50 0.93 ± 0.06 0.84 ± 0.03 28.15 ± 0.95 0.91 ± 0.09 13.31 ± 12.49
0.77 ± 0.18 0.79 ± 0.04 27.02 ± 1.35 0.70 ± 0.21
4.50 ± 10.9
0.91 ± 0.14 0.84 ± 0.03 28.15 ± 0.95 0.89 ± 0.15 13.31 ± 12.49
0.66 ± 0.27 0.79 ± 0.04 27.02 ± 1.36 0.60 ± 0.30
4.60 ± 11.0
0.85 ± 0.24 0.84 ± 0.03 28.15 ± 0.95 0.88 ± 0.19 13.30 ± 12.53
0.35 ± 0.41 0.79 ± 0.04 27.02 ± 1.36 0.34 ± 0.41
4.50 ± 11.0

27.90

27.91

27.90

11.51

11.51

0.87

0.89

5

1

0.80

0.81

0.80

0.85

0.87

0.86

0.90

0.86

0.85

27.91

11.59

11.50

5.1 Implementation

We solved the convex optimization problems (2) using the CVX solver http://cvxr.com/. As
already noted  the AATP problem can be solved efﬁciently using a distributed computing envi-
ronment. The convex optimization problem of the INFINITEPUSH algorithm (see (3.9) of [1])
can also be solved using CVX. However  this optimization problem has as many variables as
the product of the numbers of positively and negatively labeled instances (n+n)  which makes
it prohibitive to solve for large data sets within a runtime of a few days. Thus  we experi-
mented with the INFINITEPUSH algorithm only on the Ionosphere data set. Finally  for SVM-
PERF’s training and score prediction we used the binary executables downloaded from the URL
http://www.cs.cornell.edu/people/tj and used the SVMPERF’s settings that are the clos-
est to our optimization formulation. Thus  we used L1-norm for slack variables and allowed the
constraint cache and the tolerance for termination criterion to grow in order to control the algo-
rithm’s convergence  especially for larger values of the regularization constant.

5.2 Evaluation measures

To evaluate and compare the AATP  INFINITEPUSH  and SVMPERF algorithms  we used a number
of standard metrics: Precision at the top (P@⌧)  Average Precision (AP)  Number of positives at the
absolute top (Positives@top)  Discounted Cumulative Gain (DCG@⌧)  and Normalized Discounted
Cumulative Gain (NDCG@⌧). Deﬁnitions are included in Appendix B.

5.3 Ionosphere data

The data set’s 351 instances represent radar signals collected from phased antennas  where ‘good’
signals (225 positively labeled instances) are those that reﬂect back toward the antennas and ‘bad’
signals (126 negatively labeled instances) are those that pass through the ionosphere. The data has
34 features. We split the data set into 10 independent sets of instances  say S1  . . .   S10. Then  we
ran 10 experiments  where we used 3 consecutive sets for learning and the rest (7 sets) for testing.
We evaluated and compared the algorithms for 5 different top quantiles ⌧ 2{ 19  14  9.5  5  1} (%) 
which would correspond to the top 20  15  10  5  1 items  respectively. For each ⌧  the regulariza-
tion parameter C was selected based on the average value of P@⌧. The performance of AATP is
signiﬁcantly better than that of the other algorithms  particularly for the smallest top quantiles. The
two main criteria on which to evaluate the AATP algorithm are Precision at the top  (P@⌧)  and
Number of positive at the top  (Positives@top). For ⌧ = 5% the AATP algorithm obtains a stellar
91% accuracy with an average of 13.3 positive elements at the top (Table 1).

7

Table 2: Housing data: for each quantile value ⌧ and each evaluation metric  there are two rows
corresponding to AATP (top) and SVMPERF(bottom).
DCG@⌧

NDCG@⌧ Positives@top

AP

⌧ (%)

P@⌧

6

5

4

3

2

1

0.14 ± 0.05 0.11 ± 0.03 4.64 ± 0.40 0.13 ± 0.08
0.13 ± 0.05 0.10 ± 0.02 4.81 ± 0.46 0.16 ± 0.09
0.17 ± 0.07 0.10 ± 0.03 4.69 ± 0.26 0.16 ± 0.07
0.12 ± 0.10 0.09 ± 0.03 4.76 ± 0.60 0.16 ± 0.14
0.19 ± 0.13 0.12 ± 0.03 4.83 ± 0.45 0.18 ± 0.15
0.14 ± 0.05 0.10 ± 0.02 4.66 ± 0.25 0.13 ± 0.07
0.20 ± 0.12 0.10 ± 0.03 4.70 ± 0.26 0.18 ± 0.11
0.17 ± 0.12 0.09 ± 0.02 4.65 ± 0.40 0.18 ± 0.13
0.23 ± 0.10 0.10 ± 0.03 4.69 ± 0.26 0.19 ± 0.11
0.25 ± 0.17 0.10 ± 0.03 4.89 ± 0.48 0.27 ± 0.16
0.20 ± 0.27 0.12 ± 0.03 4.80 ± 0.45 0.17 ± 0.23
0.30 ± 0.27 0.09 ± 0.02 4.74 ± 0.56 0.29 ± 0.27

0.20 ± 0.45
0.21 ± 0.45
0.00 ± 0.00
0.20 ± 0.48
0.00 ± 0.00
0.00 ± 0.00
0.00 ± 0.00
0.00 ± 0.00
0.00 ± 0.00
0.20 ± 0.46
0.00 ± 0.00
0.20 ± 0.45

5.4 Housing data

The Boston Housing data set has 506 examples  35 positive and 471 negative  described by 13
features. We used feature 4 as the binary target value. Two thirds of the data instances was randomly
selected and used for training  and the rest for testing. We created 10 experimental folds analogously
as in the case of the Ionosphere data. The Housing data is very unbalanced with less than 7%
positive examples. For this dataset we obtain results very comparable to SVMPERF for the very top
quantiles  see Table 2. Naturally  the standard deviations are large as a result of the low percentage
of positive examples  so the results are not always signiﬁcant. For higher top quantiles  e.g.  top
4%  the AATP algorithm signiﬁcantly outperforms SVMPERF  obtaining 19% accuracy at the top
(P@⌧). For the highest top quantiles the difference in performance between the two algorithms is
not signiﬁcant.

5.5 LETOR 2.0

This data set corresponds to a relatively hard ranking problem  with an average of only 1% relevant
query-URL pairs per query. It consists of 5 folds. Our Matlab implementation (with CVX) of the
algorithms prevented us from trying our approach on larger data sets. Hence from each training fold
we randomly selected 500 items for training. For testing  we selected 1000 items at random from the
test fold. Here  we only report results for P@1%. SVMPERF obtained an accuracy of 1.5% ± 1.5%
while the AATP algorithm obtained an accuracy of 4.6% ± 2.4%. This signiﬁcantly better result
indicates the power of the algorithm proposed.

6 Conclusion

We presented a series of results for the problem of accuracy at the top quantile  including an AATP
algorithm  a margin-based theoretical analysis in support of that algorithm  and a series of experi-
ments with several data sets demonstrating the effectiveness of our algorithm. These results are of
practical interest in applications where the accuracy among the top quantile is sought. The analysis
of problems based on other loss functions depending on the top ⌧-quantile scores is also likely to
beneﬁt form the theoretical and algorithmic results we presented.
The optimization algorithm we discussed is highly parallelizable  since it is based on solving 2m
independent QPs. Our initial experiments reported here were carried out using Matlab with CVX 
which prevented us from evaluating our approach on larger data sets  such as the full LETOR 2.0
data set. However  we have now designed a solution for very large m based on the ADMM (Al-
ternating Direction Method of Multipliers) framework [4]. We have implemented that solution and
will present and discuss it in future work.

8

References
[1] S. Agarwal. The inﬁnite push: A new support vector ranking algorithm that directly optimizes
accuracy at the absolute top of the list. In Proceedings of the SIAM International Conference
on Data Mining  2011.

[2] R. R. Bahadur. A note on quantiles in large samples. Annals of Mathematical Statistics  37 

1966.

[3] P. L. Bartlett and S. Mendelson. Rademacher and Gaussian complexities: Risk bounds and

structural results. Journal of Machine Learning Research  3:2002  2002.

[4] S. Boyd  N. Parikh  E. Chu  B. Peleato  and J. Eckstein. Distributed optimization and statis-
tical learning via the alternating direction method of multipliers. Foundations and Trends in
Machine Learning  3(1):1–122  2011.

[5] S. Boyd and L. Vandenberghe. Convex Optimization. Cambridge University Press  2004.
[6] J. S. Breese  D. Heckerman  and C. M. Kadie. Empirical analysis of predictive algorithms for
collaborative ﬁltering. In UAI ’98: Proceedings of the Fourteenth Conference on Uncertainty
in Artiﬁcial Intelligence. Morgan Kaufmann  1998.

[7] C. Burges  T. Shaked  E. Renshaw  A. Lazier  M. Deeds  N. Hamilton  and G. Hullender.
Learning to rank using gradient descent. In Proceedings of the 22nd international conference
on Machine learning  ICML ’05  pages 89–96  New York  NY  USA  2005. ACM.

[8] C. J. C. Burges  R. Ragno  and Q. V. Le. Learning to rank with nonsmooth cost functions. In

NIPS  pages 193–200  2006.

[9] S. Cl´emenc¸on and N. Vayatis. Ranking the best instances. Journal of Machine Learning

Research  8:2671–2699  2007.

[10] D. Cossock and T. Zhang. Statistical analysis of Bayes optimal subset ranking. IEEE Trans-

actions on Information Theory  54(11):5140–5154  2008.

[11] K. Crammer and Y. Singer. PRanking with ranking. In Neural Information Processing Systems

(NIPS 2001). MIT Press  2001.

[12] Y. Freund  R. Iyer  R. E. Schapire  and Y. Singer. An efﬁcient boosting algorithm for combining

preferences. J. Mach. Learn. Res.  4  December 2003.

[13] R. Herbrich  K. Obermayer  and T. Graepel. Advances in Large Margin Classiﬁers  chapter

Large Margin Rank Boundaries for Ordinal Regression. MIT Press  2000.

[14] T. Joachims. Optimizing search engines using clickthrough data. In Proceedings of the eighth
ACM SIGKDD international conference on Knowledge discovery and data mining  KDD ’02 
pages 133–142  New York  NY  USA  2002. ACM.

[15] T. Joachims. A support vector method for multivariate performance measures. In ICML  pages

377–384  2005.

[16] J. Kiefer. On Bahadur’s representation of sample quantiles. Annals of Mathematical Statistics 

38  1967.

[17] R. Koenker. Quantile Regression. Cambridge University Press  2005.
[18] V. Koltchinskii and D. Panchenko. Empirical margin distributions and bounding the general-

ization error of combined classiﬁers. Annals of Statistics  30  2002.

[19] Q. V. Le  A. Smola  O. Chapelle  and C. H. Teo. Optimization of ranking measures. Unpub-

lished  2009.

[20] M. Mohri  A. Rostamizadeh  and A. Talwalkar. Foundations of Machine Learning. The MIT

Press  2012.

[21] C. Rudin  C. Cortes  M. Mohri  and R. E. Schapire. Margin-based ranking meets boosting in

the middle. In COLT  pages 63–78  2005.

[22] I. Tsochantaridis  T. Joachims  T. Hofmann  and Y. Altun. Large margin methods for structured
and interdependent output variables. Journal of Machine Learning Research  6:1453–1484 
2005.

9

,Francis Bach
Eric Moulines
James Ridgway
Pierre Alquier
Nicolas Chopin
Feng Liang
Noam Brown
Tuomas Sandholm