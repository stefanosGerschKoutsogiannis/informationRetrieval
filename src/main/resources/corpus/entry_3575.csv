2007,Multi-Task Learning via Conic Programming,When we have several related tasks  solving them simultaneously is shown to be more effective than solving them individually. This approach is called multi-task learning (MTL) and has been studied extensively. Existing approaches to MTL often treat all the tasks as \emph{uniformly related to each other and the relatedness of the tasks is controlled globally. For this reason  the existing methods can lead to undesired solutions when some tasks are not highly related to each other  and some pairs of related tasks can have significantly different solutions. In this paper  we propose a novel MTL algorithm that can overcome these problems. Our method makes use of a task network  which describes the relation structure among tasks. This allows us to deal with intricate relation structures in a systematic way. Furthermore  we control the relatedness of the tasks locally  so all pairs of related tasks are guaranteed to have similar solutions. We apply the above idea to support vector machines (SVMs) and show that the optimization problem can be cast as a second order cone program  which is convex and can be solved efficiently. The usefulness of our approach is demonstrated through simulations with protein super-family classification and ordinal regression problems.,Multi-Task Learning via Conic Programming

Tsuyoshi Kato(cid:2) ◦

  Hisashi Kashima

  Masashi Sugiyama

(cid:2) Graduate School of Frontier Sciences  The University of Tokyo 
◦
Institute for Bioinformatics Research and Development (BIRD) 

‡

  Kiyoshi Asai(cid:2) (cid:3)

†

Japan Science and Technology Agency (JST)
†
Tokyo Research Laboratory  IBM Research 

‡

(cid:3)

Department of Computer Science  Tokyo Institute of Technology 

AIST Computational Biology Research Center 

kato-tsuyoshi@cb.k.u-tokyo.ac.jp 

kashi pong@yahoo.co.jp 

sugi@cs.titech.ac.jp 

asai@cbrc.jp

Abstract

When we have several related tasks  solving them simultaneously is shown to be
more effective than solving them individually. This approach is called multi-task
learning (MTL) and has been studied extensively. Existing approaches to MTL
often treat all the tasks as uniformly related to each other and the relatedness of
the tasks is controlled globally. For this reason  the existing methods can lead
to undesired solutions when some tasks are not highly related to each other  and
some pairs of related tasks can have signiﬁcantly different solutions. In this pa-
per  we propose a novel MTL algorithm that can overcome these problems. Our
method makes use of a task network  which describes the relation structure among
tasks. This allows us to deal with intricate relation structures in a systematic way.
Furthermore  we control the relatedness of the tasks locally  so all pairs of related
tasks are guaranteed to have similar solutions. We apply the above idea to sup-
port vector machines (SVMs) and show that the optimization problem can be cast
as a second order cone program  which is convex and can be solved efﬁciently.
The usefulness of our approach is demonstrated through simulations with protein
super-family classiﬁcation and ordinal regression problems.

1 Introduction

In many practical situations  a classiﬁcation task can often be divided into related sub-tasks. Since
the related sub-tasks tend to share common factors  solving them together is expected to be more
advantageous than solving them independently. This approach is called multi-task learning (MTL 
a.k.a. inductive transfer or learning to learn) and has theoretically and experimentally proven to be
useful [4  5  8].

Typically  the ‘relatedness’ among tasks is implemented as imposing the solutions of related tasks to
be similar (e.g. [5]). However  the MTL methods developed so far have several limitations. First  it
is often assumed that all sub-tasks are related to each other [5]. However  this may not be always true
in practice—some are related but others may not be. The second problem is that the related tasks
are often imposed to be close in the sense that the sum of the distances between solutions over all
pairs of related tasks is upper-bounded [8] (which is often referred to as the global constraint [10]).
This implies that all the solutions of related tasks are not necessarily close  but some can be quite
different.

In this paper  we propose a new MTL method which overcomes the above limitations. We settle the
ﬁrst issue by making use of a task network that describes the relation structure among tasks. This
enables us to deal with intricate relation structures in a systematic way. We solve the second problem

1

by directly upper-bounding each distance between the solutions of related task pairs (which we call
local constraints).

We apply this ideas in the framework of support vector machines (SVMs) and show that linear SVMs
can be trained via a second order cone program (SOCP) [3] in the primal. An SOCP is a convex
problem and the global solution can be computed efﬁciently. We further show that the kernelized
version of the proposed method can be formulated as a matrix-fractional program (MFP) [3] in the
dual  which can be again cast as an SOCP; thus the optimization problem of the kernelized variant is
still convex and the global solution can be computed efﬁciently. Through experiments with artiﬁcial
and real-world protein super-family classiﬁcation data sets  we show that the proposed MTL method
compares favorably with existing MTL methods.

We further test the performance of the proposed approach in ordinal regression scenarios [9]  where
the goal is to predict ordinal class labels such as users’ preferences (‘like’/‘neutral’/‘dislike’) or
students’ grades (from ‘A’ to ‘F’). The ordinal regression problems can be formulated as a set of
one-versus-one classiﬁcation problems  e.g.  ‘like’ vs. ‘neutral’ and ‘neutral’ vs. ‘dislike’. In ordinal
regression  the relatedness among tasks is highly structured. That is  the solutions (decision bound-
aries) of adjacent problems are expected to be similar  but others may not be related  e.g.  ‘A’ vs. ‘B’
and ‘B’ vs. ‘C’ would be related  but ‘A’ vs. ‘B’ and ‘E’ vs. ‘F’ may not be. Our experiments
demonstrate that the proposed method is also useful in the ordinal regression scenarios and tends to
outperform existing approaches [9  8]

2 Problem Setting

In this section  we formulate the MTL problem.
Let us consider M binary classiﬁcation tasks  which all share the common input-output space X ×
{±1}. For the time being  we assume X ⊂ Rd for simplicity; later in Section 4  we extend it to
reproducing kernel Hilbert spaces. Let {x t  yt}(cid:3)
t=1 be the training set  where xt ∈ X and yt ∈ {±1}
for t = 1  . . .   (cid:2). Each data sample (xt  yt) has its target task; we denote the set of sample indices
of the i-th task by Ii. We assume that each sample belongs only to a single task  i.e.  the index sets
are exclusive:
(cid:4)
The goal is to learn the score function of each classiﬁcation task: f i(x; wi  bi) = w
i x + bi  for
i = 1  . . .   M  where wi ∈ Rd and bi ∈ R are the model parameters of the i-th task. We assume that
a task network is available. The task network describes the relationships among tasks  where each
node represents a task and two nodes are connected by an edge if they are related to each other 1. We
denote the edge set by E ≡ {(ik  jk)}K

(cid:2)M
i=1 |Ii| = (cid:2) and Ii ∩ Ij = null  ∀i (cid:6)= j.

k=1.

3 Local MTL with Task Network: Linear Version

In this section  we propose a new MTL method.

3.1 Basic Idea

When the relation among tasks is not available  we may just solve M penalized ﬁtting problems
individually:

(cid:8)wi(cid:8)2 + Cα

1
2

(cid:3)
t∈Ii

Hinge(fi(xt; wi  bi)  yt) 

(1)
where Cα ∈ R+ is a regularization constant and Hinge(· ·) is the hinge loss function:
Hinge(f  y) ≡ max(1 − f y  0). This individual approach tends to perform poorly if the number
of training samples in each task is limited—the performance is expected to be improved if more
training samples are available. Here  we can exploit the information of the task network. A naive

for i = 1  . . .   M 

1More generally  the tasks can be related in an inhomogeneous way  i.e.  the strength of the relationship
among tasks can be dependent on tasks. This general setting can be similarly formulated by a weighted network 
where edges are weighted according to the strength of the connections. All the discussions in this paper can be
easily extended to weighted networks  but for simplicity we focus on unweighted networks.

2

idea would be to use the training samples of neighboring tasks in the task network for solving the
target ﬁtting problem. However  this does not fully make use of the network structure since there are
many other indirectly connected tasks via some paths on the network.

To cope with this problem  we take another approach here  which is based on the expectation that
the solutions of related tasks are close to each other. More speciﬁcally  we impose the following
constraint on the optimization problem (1):
− wjk

for ∀k = 1  . . .   K.

(cid:8)2 ≤ ρ 

(cid:8)wik

(2)

1
2

Namely  we upper-bound each difference between the solutions of related task pairs by a positive
scalar ρ ∈ R+. We refer to this constraint as local constraint following [10]. Note that we do
not impose a constraint on the bias parameter b i since the bias could be signiﬁcantly different even
among related tasks. The constraint (2) allows us to implicitly increase the number of training
samples over the task network in a systematic way through the solutions of related tasks.

Following the convention [8]  we blend Eqs.(1) and (2) as

M(cid:3)

1
2M

(cid:8)wi(cid:8)2 + Cα

i=1

i=1

M(cid:3)

(cid:3)
t∈Ii

Hinge(fi(xt; θ)  yt) + Cρρ 

(3)

where Cρ is a positive trade-off parameter. Then our optimization problem is summarized as follows:
Problem 1.

M(cid:3)

i=1

min

1
2M
(cid:8)wik
1
where w ≡ (cid:6)
2

subj. to

(cid:8)2 ≤ ρ  ∀k 

− wjk
(cid:4)
1   . . .   w

w

(cid:4)
M

(cid:7)(cid:4)

 

(cid:8)wi(cid:8)2 + Cα(cid:8)ξ(cid:8)1 + Cρρ  wrt. w ∈ R

Md  b ∈ R

(cid:4)

and

and

w

(cid:4)
i xt + bi
yt
ξα ≡ [ξα

1   . . .   ξα
(cid:3) ]

(cid:4) .

(cid:3)

+  and ρ ∈ R+ 

M   ξα ∈ R
(cid:5) ≥ 1 − ξα

t   ∀t ∈ Ii ∀i

(4)

3.2 Primal MTL Learning by SOCP

f

z

n

min

subj. to

wrt z ∈ R

The second order cone program (SOCP) is a class of convex programs of minimizing a linear func-
tion over an intersection of second-order cones [3]: 2
Problem 2.
(cid:4)

(cid:8)Aiz + bi(cid:8) ≤ c
(cid:4)
i z + di 
where f ∈ Rn  Ai ∈ R(ni−1)×n  bi ∈ Rni−1  ci ∈ Rn  di ∈ R.
Linear programs  quadratic programs  and quadratically-constrained quadratic programs are actually
special cases of SOCPs. SOCPs are a sub-class of semideﬁnite programs (SDPs) [3]  but SOCPs can
be solved more efﬁciently than SDPs. Successful optimization algorithms for both SDP and SOCP
are interior-point algorithms. The SDP solvers (e.g. [2]) consume O(n 2
i ) time complexity
for solving Problem 2  but the SOCP-specialized solvers that directly solve Problem 2 take only
O(n2
We can show that Problem 1 is cast as an SOCP using hyperbolic constraints [3].
Theorem 1. Problem 1 can be reduced to an SOCP and it can be solved with O((M d+(cid:2)) 2(Kd+(cid:2)))
computation.

(cid:2)
i ni) computation [7]. Thus  SOCPs can be solved more efﬁciently than SDPs.

for i = 1  . . .   N 

(cid:2)

i n2

(5)

4 Local MTL with Task Network: Kernelization

The previous section showed that a linear version of the proposed MTL method can be cast as an
SOCP. In this section  we show how the kernel trick could be employed for obtaining a non-linear
variant.

2More generally  an SOCP can include linear equality constraints  but they can be eliminated  for example 

by some projection method.

3

4.1 Dual Formulation

(cid:8)

Let Kfea be a positive semideﬁnite matrix with the (s  t)-th element being the inner-product of
s t ≡ (cid:11)xs  xt(cid:12) . This is a kernel matrix of feature vectors. We also
feature vectors xs and xt: Kfea
introduce a kernel among tasks. Using a new K-dimensional non-negative parameter vector λ ∈
RK
+   we deﬁne the kernel matrix of tasks by
Knet(λ) ≡

where Uλ ≡ (cid:2)K
k=1 λkUk  Uk ≡ Eikik + Ejkjk − Eikjk − Ejkik   and E (i j) ∈ RM×M is the
sparse matrix whose (i  j)-th element is one and all the others are zero. Note that this is the graph
Laplacian kernel [11]  where the k-th edge is weighted according to λ k. Let Z ∈ NM×(cid:3) be the
indicator of a task and a sample such that Z i t = 1 if t ∈ Ii and Zi t = 0 otherwise. Then the
information about the tasks are expressed by the (cid:2) × (cid:2) kernel matrix Z
Knet(λ) Z. We integrate
the two kernel matrices Kfea and Z

M IM + Uλ
1

Knet(λ) Z by

(cid:9)−1

(cid:4)

(cid:4)

 

(6)
where ◦ denotes the Hadamard product (a.k.a element-wise product). This parameterized ma-
trix Kint(λ) is guaranteed to be positive semideﬁnite [6].
Based on the above notations  the dual formulation of Problem 1 can be expressed using the param-
eterized integrated kernel matrix K int(λ) as follows:
Problem 3.

Knet(λ) Z

Z

 

Kint(λ) ≡ Kfea ◦(cid:4)

(cid:4)

(cid:5)

min

1
(cid:4)
2 α

diag(y)Kint(λ) diag(y)α − (cid:8)α(cid:8)1 

wrt. α ∈ R

(cid:3)

+  and λ ∈ R

subj. to α ≤ Cα1(cid:3)  Z diag(y) α = 0M  

(cid:8)λ(cid:8)1 ≤ Cρ.

M
+  

(7)

We note that the solutions α and λ tend to be sparse due to the (cid:2) 1 norm.
Changing the deﬁnition of Kfea from the linear kernel to an arbitrary kernel  we can extend the
proposed linear MTL method to non-linear domains. Furthermore  we can also deal with non-
vectorial structured data by employing a suitable kernel such as the string kernel and the Fisher
kernel.
In the test stage  a new sample x in the j-th task is classiﬁed by

(cid:3)(cid:3)

M(cid:3)

fj(x) =

αtytkfea(xt  x)knet(i  j)Zi t + bj 

(8)

where kfea(· ·) and knet(· ·) are the kernel functions over features and tasks  respectively.

t=1

i=1

4.2 Dual MTL Learning by SOCP

Here  we show that the above dual problem can also be reduced to an SOCP. To this end  we ﬁrst
introduce a matrix-fractional program (MFP) [7]:
Problem 4.

p

(cid:4)

P (z)

−1 (F z + g)

+ subj. to P (z) ≡ P0 +

wrt. z ∈ R
+  F ∈ Rn×p  and g ∈ Rn. Here Sn

min (F z + g)
where Pi ∈ Sn
and strictly positive deﬁnite cone of n × n matrices  respectively.
Let us re-deﬁne d as the rank of the feature kernel matrix K fea. We introduce a matrix Vfea ∈ R(cid:3)×d
which decomposes the feature kernel matrix as K fea = VfeaVfea
. Deﬁne the (cid:2)-dimensional vectors
fh ∈ R(cid:3) of the h-th feature as Vfea ≡ [f1 
. . .   fd] ∈ R(cid:3)×d and the matrices Fh ≡ Z diag(fh ◦
(cid:8)
(cid:9)−1
y)  for h = 1  . . .   d. Using those variables  the objective function in Problem 3 can be rewritten as

++ denote the positive semideﬁnite cone

ziPi ∈ S

+ and Sn

n
++ 

i=1

(cid:4)

p(cid:3)

(cid:4)

(cid:4)
F
h

α

M IM + Uλ
1

Fhα − α

(cid:4)1(cid:3).

(9)

d(cid:3)

h=1

1
2

JD =

4

This implies that Problem 3 can be transformed into the combination of a linear program and d
MFPs.
−ejk  where eik is a unit vector
Let us further introduce the vector v k ∈ RM for each edge: vk = eik
with the ik-th element being one. Let Vlap be a matrix deﬁned by Vlap = [v1  . . .   vK] ∈ R
M×K.
Then we can re-express the graph Lagrangian matrix of tasks as Uλ = V lap diag(λ)Vlap
Given the fact that an MFP can be reduced to an SOCP [7]  we can reduce Problem 3 to the following
SOCP:
Problem 5.

(cid:4).

M   uh = [u1 h  . . .   uK h]

(cid:4) ∈ R

K

∀k  ∀h

(cid:10)(cid:10)(cid:10)(cid:10)

Kλ ≤ Cρ 
(cid:11)
1(cid:4)
2u0 h
s0 h − 1

(cid:12)(cid:10)(cid:10)(cid:10)(cid:10) ≤ s0 h + 1 

∀h

∀k  ∀h

(10)

(11)
(12)
(13)

(14)

(15)

min − 1(cid:4)

(cid:3) α +

1
2

s0 h + s1 h + ··· + sK h 

d(cid:3)

h=1

wrt

s0 h ∈ R  sk h ∈ R  u0 h ∈ R
λ ∈ R

+   α ∈ R

(cid:3)
+ 

K

subj. to α ≤ Cα1(cid:3)  Z diag(y) α = 0M  

M−1/2u0 h + Vlapuh = Fhα 
(cid:11)
2uk h
sk h − λk

(cid:12)(cid:10)(cid:10)(cid:10)(cid:10) ≤ sk h + λk

(cid:10)(cid:10)(cid:10)(cid:10)

Consequently  we obtain the following result:
Theorem 2. The dual problem of CoNs learning (Problem 3) can be reduced to the SOCP in Prob-
lem 5 and it can be solved with O((Kd + (cid:2))2((M + K)d + (cid:2))) computation.

5 Discussion

In this section  we discuss the properties of the proposed MTL method and the relation to existing
methods.

MTL with Common Bias A possible variant of the proposed MTL method would be to share the
common bias parameter with all tasks (i.e. b 1 = b2 = ··· = bM ). The idea is expected to be useful
particularly when the number of samples in each task is very small. We can also apply the common
bias idea in the kernelized version just by replacing the constraint Z diag(y)α = 0 M in Problem 3
by y

α = 0.

(cid:4)

− wjk

(cid:2)K
k=1 (cid:8)wik

Global vs. Local Constraints Micchelli and Pontil
[8] have proposed a related MTL
method which upper-bounds the sum of
i.e. 
(cid:8)2 ≤ ρ. We call it the global constraint. This global constraint can also have
1
2
a similar effect to our local constraint (2)  i.e.  the related task pairs tend to have close solutions.
However  the global constraint can allow some of the distances to be large since only the sum is
upper-bounded. This actually causes a signiﬁcant performance degradation in practice  which will
be experimentally demonstrated in Section 6. We note that the idea of local constraints is also used
in the kernel learning problem [10].

the differences of K related task pairs 

Relation to Standard SVMs By construction  the proposed MTL method includes the standard
SVM learning algorithm a special case. Indeed  when the number of tasks is one  Problem 3 is
reduced to the standard SVM optimization problem. Thus  the proposed method may be regarded
as a natural extension of SVMs.

Ordinal Regression As we mentioned in Section 1  MTL approaches are useful in ordinal regres-
sion problems. Ordinal regression is a task of learning multiple quantiles  which can be formulated
as a set of one-versus-one classiﬁcation problems. A naive approach to ordinal regression is to
individually train M SVMs with score functions f i(x) = (cid:11)wi  x(cid:12) + bi  i = 1  . . .   M . Shashua

5

1

0.5

0

-0.5

1

0.5

0

-0.5

1

0.5

0

-0.5

1

0.5

0

-0.5

1

0.5

0

-0.5

1

0.5

0

-0.5

1

0.5

0

-0.5

1

0.5

0

-0.5

1

0.5

0

-0.5

1

0.5

0

-0.5

-1

-1 -0.5 0

0.5

1

-1

-1 -0.5 0

0.5

1

-1

-1 -0.5 0

0.5

1

-1

-1 -0.5 0

0.5

1

-1

-1 -0.5 0

0.5

1

-1

-1 -0.5 0

0.5

1

-1

-1 -0.5 0

0.5

1

-1

-1 -0.5 0

0.5

1

-1

-1 -0.5 0

0.5

1

-1

-1 -0.5 0

0.5

1

1

0.5

0

-0.5

1

0.5

0

-0.5

1

0.5

0

-0.5

1

0.5

0

-0.5

1

0.5

0

-0.5

1

0.5

0

-0.5

1

0.5

0

-0.5

1

0.5

0

-0.5

1

0.5

0

-0.5

1

0.5

0

-0.5

-1

-1 -0.5 0

0.5

1

-1

-1 -0.5 0

0.5

1

-1

-1 -0.5 0

0.5

1

-1

-1 -0.5 0

0.5

1

-1

-1 -0.5 0

0.5

1

-1

-1 -0.5 0

0.5

1

-1

-1 -0.5 0

0.5

1

-1

-1 -0.5 0

0.5

1

-1

-1 -0.5 0

0.5

1

-1

-1 -0.5 0

0.5

1

(a) True classiﬁcation boundaries

(b) IL-SVMs

1

0.5

0

-0.5

1

0.5

0

-0.5

1

0.5

0

-0.5

1

0.5

0

-0.5

1

0.5

0

-0.5

1

0.5

0

-0.5

1

0.5

0

-0.5

1

0.5

0

-0.5

1

0.5

0

-0.5

1

0.5

0

-0.5

-1

-1 -0.5 0

0.5

1

-1

-1 -0.5 0

0.5

1

-1

-1 -0.5 0

0.5

1

-1

-1 -0.5 0

0.5

1

-1

-1 -0.5 0

0.5

1

-1

-1 -0.5 0

0.5

1

-1

-1 -0.5 0

0.5

1

-1

-1 -0.5 0

0.5

1

-1

-1 -0.5 0

0.5

1

-1

-1 -0.5 0

0.5

1

1

0.5

0

-0.5

1

0.5

0

-0.5

1

0.5

0

-0.5

1

0.5

0

-0.5

1

0.5

0

-0.5

1

0.5

0

-0.5

1

0.5

0

-0.5

1

0.5

0

-0.5

1

0.5

0

-0.5

1

0.5

0

-0.5

-1

-1 -0.5 0

0.5

1

-1

-1 -0.5 0

0.5

1

-1

-1 -0.5 0

0.5

1

-1

-1 -0.5 0

0.5

1

-1

-1 -0.5 0

0.5

1

-1

-1 -0.5 0

0.5

1

-1

-1 -0.5 0

0.5

1

-1

-1 -0.5 0

0.5

1

-1

-1 -0.5 0

0.5

1

-1

-1 -0.5 0

0.5

1

(c) MTL-SVM(global/full)

(d) MTL-SVM(local/network)

Figure 1: Toy multi classiﬁcation tasks. Each subﬁgure contains the 10-th  30-th  50-th  70-th  and
90-th tasks in the top row and the 110-th  130-th  150-th  170-th  and 190-th tasks in the bottom row.

and Levin [9] proposed an ordinal regression method called the support vector ordinal regres-
sion (SVOR)  where the weight vectors are shared by all SVMs (i.e. w 1 = w2 = ··· = wM )
and only the bias parameter is learned individually.
The proposed MTL method can be naturally employed in ordinal regression by constraining the
weight vectors as (cid:8)wi − wi+1(cid:8)2 ≤ ρ  i = 1  . . .   M − 1  i.e.  the task network only has a weight be-
tween consecutive tasks. This method actually includes the above two ordinal regression approaches
as special cases—Cρ = 0 (i.e.  ignoring the task network) yields the independent training of SVMs
and Cρ = ∞ (i.e.  the weight vectors of all SVMs agree) is reduced to SVOR. Thus  in the context
of ordinal regression  the proposed method smoothly bridges two extremes and allows us to control
the belief of task constraints.

6 Experiments

In this section  we show the usefulness of the proposed method through experiments.

6.1 Toy Multiple Classiﬁcation Tasks

First  we illustrate how the proposed method behaves using a 2-dimensional toy data set  which
includes 200 tasks (see Figure 1(a)). Each task possesses a circular-shaped classiﬁcation boundary
with different centers and a ﬁxed radius 0.5. The location of the center in the i-th task is (−1 +
0.02(i − 1)  0) for 1 ≤ i ≤ 100 and (0 −1 + 0.02(i − 101)) for 101 ≤ i ≤ 200. For each task 
only two positive and two negative samples are generated following the uniform distribution. We
construct a task network where consecutive tasks are connected in a circular manner  i.e.  (1  2) 
(2  3)  . . .  (99  100)  and (100  1) for the ﬁrst 100 tasks and (101  102)  (102  103)  . . .  (199  200) 
and (200  1) for the last 100 tasks; we further add (50  150)  which connects the clusters of the ﬁrst
100 and the last 100 nodes.
We compare the following methods: a naive method where 200 SVMs are trained indivisually (in-
dividually learned SVM  ‘IL-SVM’)  the MTL-SVM algorithm where the global constraint and the
fully connected task network are used [5] (‘MTL-SVM(global/full)’)  and the proposed method which
uses local constraints and the properly deﬁned task network (‘MTL-SVM(local/network)’).

The results are exhibited in Figure 1  showing that IL-SVM can not capture the circular shape due
to the small sample size in each task. MTL-SVM(global/full) can successfully capture closed-loop
boundaries by making use of the information from other tasks. However  the result is still not
so reliable since non-consecutive unrelated tasks heavily damage the solutions. On the other hand 
MTL-SVM(local/network) nicely captures the circular boundaries and the results are highly reliable.
Thus  given an appropriate task network  the proposed MTL-SVM(local/network) can effectively
exploit information of the related tasks.

6

Table 1: The accuracy of each method in the protein super-family classiﬁcation task.

Dataset

IL-SVM

d-f
d-s
d-o
f-s
f-o
s-o

0.908 (0.023)
0.638 (0.067)
0.725 (0.032)
0.891 (0.036)
0.792 (0.046)
0.663 (0.034)

One-SVM
0.941 (0.015)
0.722 (0.030)
0.747 (0.017)
0.886 (0.021)
0.819 (0.029)
0.695 (0.034)

MTL-SVM
(global/full)
0.945 (0.013)
0.698 (0.036)
0.748 (0.021)
0.918 (0.020)
0.834 (0.021)
0.692 (0.050)

MTL-SVM

(global/network)
0.933 (0.017)
0.695 (0.032)
0.749 (0.023)
0.911 (0.022)
0.828 (0.015)
0.663 (0.068)

MTL-SVM

(local/network)
0.952 (0.015)
0.747 (0.020)
0.764 (0.028)
0.918 (0.025)
0.838 (0.018)
0.703 (0.036)

6.2 Protein Super-Family Classiﬁcation

Next  we test the performance of the proposed method with real-world protein super-family classiﬁ-
cation problems.

The input data are amino acid sequences from the SCOP database [1] (not SOCP). We counted
2-mers for extraction of feature vectors. There are 20 kinds of amino acids. Hence  the number
of features is 202 = 400. We use RBF kernels  where the kernel width σ 2
rbf is set to the average
of the squared distances to the ﬁfth nearest neighbors. Each data set consists of two folds. Each
fold is divided into several super-families. We here consider the classiﬁcation problem into the
super-families. A positive class is chosen from one fold  and a negative class is chosen from the
other fold. We perform multi-task learning from all the possible combinations. For example  three
super-families are in DNA/RNA binding  and two in SH3. The number of combinations is 3· 2 = 6.
So the data set d-s has the six binary classiﬁcation tasks. We used four folds: DNA/RNA binding 
Flavodoxin  OB-fold and SH3. From these folds  we generate six data sets: d-f  d-f  d-o  f-o  f-s 
and o-s  where the fold names are abbreviated to d  f  o  and s  respectively.

The task networks are constructed as follows: if the positive super-family or the negative super-
family is common to two tasks  the two tasks are regarded as a related task pair and connected by
an edge. We compare the proposed MTL-SVM(local/network) with IL-SVM  ‘One-SVM’  MTL-
SVM(global/full)  and MTL-SVM(global/network). One-SVM regards the multiple tasks as one big
task and learns the big task once by a standard SVM. We set C α = 1 for all the approaches. The
value of the parameter Cρ for three MTL-SVM approaches is determined by cross-validation over
the training set. We randomly pick ten training sequences from each super-family  and use them for
training. We compute the classiﬁcation accuracies of the remaining test sequences. We repeat this
procedure 10 times and take the average of the accuracies.
The results are described in Table 1  showing that the proposed MTL-SVM(local/network) com-
pares favorably with the other methods. In this simulation  the task network is constructed rather
heuristically. Even so  the proposed MTL-SVM(local/network) is shown to signiﬁcantly outperform
MTL-SVM(global/full)  which does not use the network structure. This implies that the proposed
method still works well even when the task network contains small errors. It is interesting to note
that MTL-SVM(global/network) actually does not work well in this simulation  implying that the
task relatedness are not properly controlled by the global constraint. Thus the use of the local con-
straints would be effective in MTL scenarios.

6.3 Ordinal Regression

As discussed in Section 5  MTL methods are useful in ordinal regression. Here we create ﬁve ordinal
regression data sets described in Table 2  where all the data sets are originally regression and the out-
put values are divided into ﬁve quantiles. Therefore  the overall task can be divided into four isolated
classiﬁcation tasks  each of which estimates a quantile. We compare MTL-SVM(local/network) with
IL-SVM  SVOR [9] (see Section 5)  MTL-SVM(full/network) and MTL-SVM(global/network). The
value of the parameter Cρ for three MTL-SVM approaches is determined by cross-validation over
the training set. We set Cα = 1 for all the approaches. We use RBF kernels  where the parame-
ter σ2
rbf is set to the average of the squared distances to the ﬁfth nearest neighbors. We randomly
picked 200 samples for training. The remaining samples are used for evaluating the classiﬁcation
accuracies.

7

Table 2: The accuracy of each method in ordinal regression tasks.

Data set
pumadyn

stock

0.643 (0.007)
0.894 (0.012)
0.781 (0.003)
bank-8fh
bank-8fm 0.854 (0.004)
calihouse
0.648 (0.003)

IL-SVM

SVOR

MTL-SVM
(global/full)
0.629 (0.025)
0.872 (0.010)
0.772 (0.006)
0.832 (0.013)
0.640 (0.005)

MTL-SVM

(global/network)
0.645 (0.018)
0.888 (0.010)
0.773 (0.006)
0.847 (0.009)
0.646 (0.007)

MTL-SVM

(local/network)
0.661 (0.007)
0.902 (0.007)
0.779 (0.002)
0.854 (0.009)
0.650 (0.004)

0.661 (0.006)
0.878 (0.011)
0.777 (0.006)
0.845 (0.010)
0.642 (0.008)

The averaged performance over ﬁve runs is described in Table 2  showing that the proposed MTL-
SVM(local/network) is also promising in ordinal regression scenarios.

7 Conclusions

In this paper  we proposed a new multi-task learning method  which overcomes the limitation of
existing approaches by making use of a task network and local constraints. We demonstrated through
simulations that the proposed method is useful in multi-task learning scenario; moreover  it also
works excellently in ordinal regression scenarios.

The standard SVMs have a variety of extensions and have been combined with various techniques 
e.g.  one-class SVMs  SV regression  and the ν-trick. We expect that such extensions and techniques
can also be applied similarly to the proposed method. Other possible future works include the
elucidation of the entire regularization path and the application to learning from multiple networks;
developing algorithms for learning probabilistic models with a task network is also a promising
direction to be explored.

Acknowledgments

This work was partially supported by a Grant-in-Aid for Young Scientists (B)  number 18700287 
from the Ministry of Education  Culture  Sports  Science and Technology  Japan.

References
[1] A. Andreeva  D. Howorth  S. E. Brenner  T. J. P. Hubbard  C. Chothia  and A. G. Murzin. SCOP database
in 2004: reﬁnements integrate structure and sequence family data. Nucl. Acid Res.  32:D226–D229  2004.
[2] B. Borchers. CSDP  a C library for semideﬁnite programming. Optimization Methods and Software 

11(1):613–623  1999.

[3] Stephen Boyd and Lieven Vandenberghe. Convex Optimization. Cambridge University Press  2004.
[4] R. Caruana. Multitask learning. Machine Learning  28(1):41–75  1997.
[5] T. Evgeniou and M. Pontil. Regularized multitask learning. In Proc. of 17-th SIGKDD Conf. on Knowl-

edge Discovery and Data Mining  2004.

[6] D. Haussler. Convolution kernels on discrete structures. Technical Report UCSC-CRL-99-10  UC Santa

Cruz  July 1999.

[7] M. Lobo  L. Vandenberghe  S. Boyd  and H. Lebret. Applications of second-order cone programming.

Linear Algebra and its Applications  284:193–228  1998.

[8] C. A. Micchelli and M. Pontil. Kernels for multi-task learning. In Lawrence K. Saul  Yair Weiss  and L´eon
Bottou  editors  Advances in Neural Information Processing Systems 17  pages 921–928  Cambridge  MA 
2005. MIT Press.

[9] A. Shashua and A. Levin. Ranking with large margin principle: two approaches. In Advances in Neural

Information Processing Systems 15  pages 937–944  Cambridge  MA  2003. MIT Press.

[10] K. Tsuda and W.S. Noble. Learning kernels from biological networks by maximizing entropy. Bioinfor-

matics  20(Suppl. 1):i326–i333  2004.

[11] X. Zhu  J. Kandola  Z. Ghahramani  and J. Lafferty. Nonparametric transforms of graph kernels for
semi-supervised learning. In Lawrence K. Saul  Yair Weiss  and Lon Bottou  editors  Advances in Neural
Information Processing Systems 17  Cambridge  MA  2004. MIT Press.

8

,Miguel Carreira-Perpinan
Ramin Raziperchikolaei