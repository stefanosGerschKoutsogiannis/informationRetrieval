2014,Learning Mixtures of Submodular Functions for Image Collection Summarization,We address the problem of image collection summarization by learning mixtures of submodular functions. We argue that submodularity is very natural to this problem  and we show that a number of previously used scoring functions are submodular — a property not explicitly mentioned in these publications. We provide classes of submodular functions capturing the necessary properties of summaries  namely coverage  likelihood  and diversity. To learn mixtures of these submodular functions as scoring functions  we formulate summarization as a supervised learning problem using large-margin structured prediction. Furthermore  we introduce a novel evaluation metric  which we call V-ROUGE  for automatic summary scoring. While a similar metric called ROUGE has been successfully applied to document summarization [14]  no such metric was known for quantifying the quality of image collection summaries. We provide a new dataset consisting of 14 real-world image collections along with many human-generated ground truth summaries collected using mechanical turk. We also extensively compare our method with previously explored methods for this problem and show that our learning approach outperforms all competitors on this new dataset. This paper provides  to our knowledge  the first systematic approach for quantifying the problem of image collection summarization  along with a new dataset of image collections and human summaries.,Learning Mixtures of Submodular Functions for

Image Collection Summarization

Sebastian Tschiatschek

Department of Electrical Engineering

Graz University of Technology
tschiatschek@tugraz.at

Rishabh Iyer

Department of Electrical Engineering

University of Washington

rkiyer@u.washington.edu

Haochen Wei

Jeff Bilmes

LinkedIn & Department of Electrical Engineering

Department of Electrical Engineering

University of Washington
weihch90@gmail.com

University of Washington

bilmes@u.washington.edu

Abstract

We address the problem of image collection summarization by learning mixtures of
submodular functions. Submodularity is useful for this problem since it naturally
represents characteristics such as ﬁdelity and diversity  desirable for any summary.
Several previously proposed image summarization scoring methodologies  in fact 
instinctively arrived at submodularity. We provide classes of submodular compo-
nent functions (including some which are instantiated via a deep neural network)
over which mixtures may be learnt. We formulate the learning of such mixtures as a
supervised problem via large-margin structured prediction. As a loss function  and
for automatic summary scoring  we introduce a novel summary evaluation method
called V-ROUGE  and test both submodular and non-submodular optimization
(using the submodular-supermodular procedure) to learn a mixture of submodular
functions. Interestingly  using non-submodular optimization to learn submodular
functions provides the best results. We also provide a new data set consisting of
14 real-world image collections along with many human-generated ground truth
summaries collected using Amazon Mechanical Turk. We compare our method
with previous work on this problem and show that our learning approach outper-
forms all competitors on this new data set. This paper provides  to our knowledge 
the ﬁrst systematic approach for quantifying the problem of image collection sum-
marization  along with a new data set of image collections and human summaries.

1

Introduction

The number of photographs being uploaded online is growing at an unprecedented rate. A recent
estimate is that 500 million images are uploaded to the internet every day (just considering Flickr 
Facebook  Instagram and Snapchat)  a ﬁgure which is expected to double every year [22]. Organizing
this vast amount of data is becoming an increasingly important problem. Moreover  the majority
of this data is in the form of personal image collections  and a natural problem is to summarize
such vast collections. For example  one may have a collection of images taken on a holiday trip 
and want to summarize and arrange this collection to send to a friend or family member or to post
on Facebook. Here the problem is to identify a subset of the images which concisely represents
all the diversity from the holiday trip. Another example is scene summarization [28]  where one
wants to concisely represent a scene  like the Vatican or the Colosseum. This is relevant for creating
a visual summary of a particular interest point  where we want to identify a representative set of
views. Another application that is gaining importance is summarizing video collections [26  13] in
order to enable efﬁcient navigation of videos. This is particularly important in security applications 
where one wishes to quickly identify representative and salient images in massive amounts of video.

1

These problems are closely related and can be uniﬁed via the problem of ﬁnding the most repre-
sentative subset of images from an entire image collection. We argue that many formulations of
this problem are naturally instances of submodular maximization  a statement supported by the fact
that a number of scoring functions previously investigated for image summarization are (apparently
unintentionally) submodular [30  28  5  29  8].
A set function f (·) is said to be submodular if for any element v and sets A ⊆ B ⊆ V \{v}  where
V represents the ground set of elements  f (A ∪ {v}) − f (A) ≥ f (B ∪ {v}) − f (B). This is
called the diminishing returns property and states  informally  that adding an element to a smaller
set increases the function value more than adding that element to a larger set. Submodular functions
naturally model notions of coverage and diversity in applications  and therefore  a number of machine
learning problems can be modeled as forms of submodular optimization [11  20  18]. In this paper 
we investigate structured prediction methods for learning weighted mixtures of submodular functions
for image collection summarization.
Related Work:
Previous work on image summarization can broadly be categorized into (a)
clustering-based approaches  and (b) approaches which directly optimize certain scoring functions.
The clustering papers include [12  8  16]. For example  [12] proposes a hierarchical clustering-based
summarization approach  while [8] uses k-medoids-based clustering to generate summaries. Sim-
ilarly [16] proposes top-down based clustering. A number of other methods attempt to directly
optimize certain scoring functions. For example  [28] focuses on scene summarization and poses an
objective capturing important summarization metrics such as likelihood  coverage  and orthogonality.
While they do not explicitly mention this  their objective function is in fact a submodular function.
Furthermore  they propose a greedy algorithm to optimize their objective. A similar approach was pro-
posed by [30  29]  where a set cover function (which incidentally also is submodular) is used to model
coverage  and a minimum disparity formulation is used to model diversity. Interestingly  they optimize
their objective using the same greedy algorithm. Similarly  [15] models the problem of diverse image
retrieval via determinantal point processes (DPPs). DPPs are closely related to submodularity  and in
fact  the MAP inference problem is an instance of submodular maximization. Another approach for
image summarization was posed by [5]  where they deﬁne an objective function using a graph-cut func-
tion  and attempt to solve it using a semideﬁnite relaxation. They unintentionally use an objective that
is submodular (and approximately monotone [18]) that can be optimized using the greedy algorithm.
Our Contributions: We introduce a family of submodular function components for image collection
summarization over which a convex mixture can be placed  and we propose a large margin formulation
for learning the mixture. We introduce a novel data set of fourteen personal image collections  along
with ground truth human summaries collected via Amazon mechanical Turk  and then subsequently
cleaned via methods described below. Moreover  in order to automatically evaluate the quality of
novel summaries  we introduce a recall-based evaluation metric  which we call V-ROUGE  to compare
automatically generated summaries to the human ones. We are inspired by ROUGE [17]  a well-
known evaluation criterion for evaluating summaries in the document summarization community  but
we are unaware of any similar efforts in the computer vision community for image summarization. We
show evidence that V-ROUGE correlates well with human evaluation. Finally  we extensively validate
our approach on these data sets  and show that it outperforms previously explored methods developed
for similar problems. The resulting learnt objective  moreover  matches human summarization
performance on test data.

2

Image Collection Summarization

Summarization is a task that most humans perform intuitively. Broadly speaking  summarization is
the task of extracting information from a source that is both minimal and most important. The precise
meaning of most important (relevance) is typically subjective and thus will differ from individual
to individual and hence is difﬁcult to precisely quantify. Nevertheless  we can identify two general
properties that characterize good image collection summarizes [19  28]:
Fidelity: A summary should have good coverage  meaning that all of the distinct “concepts” in
the collection have at least one representative in the summary. For example  a summary of a photo
collection containing both mountains and beaches should contain images of both scene types.
Diversity: Summaries should be as diverse as possible  i.e.  summaries should not contain images
that are similar or identical to each other. Other words for this concept include diversity or dispersion.
In computer vision  this property has been referred to as orthogonality [28].

2

Note that [28] also includes the notion of “likelihood ” where summary images should have high
similarity to many other images in the collection. We believe  however  that such likelihood is
covered by ﬁdelity. I.e.  a summary that only has images similar to many in the collection might miss
certain outlier  or minority  concepts in the collection  while a summary that has high ﬁdelity should
include a representative image for every both majority and minority concept in the collection.Also 
the above properties could be made very high without imposing further size or budget constraints.
I.e.  the goal of a summary is to ﬁnd a small or within-budget subset having the above properties.

2.1 Problem Formulation

We cast the problem of image collection summarization as a subset selection problem: given a
collection of images I = (I1  I2 ···   I|V |) represented by an index set V and given a budget c  we
aim to ﬁnd a subset S ⊆ V |S| ≤ c  which best summarizes the collection. Though alternative
approaches are possible  we aim to solve this problem by learning a scoring function F : 2V → R+ 
such that high quality summaries are mapped to high scores and low quality summaries to low scores.
Then  image collection summarization can be performed by computing:

S∗ ∈ argmaxS⊆V |S|≤c F (S).

(1)
For arbitrary set functions  computing S∗ is intractable  but for monotone submodular functions
we rely on the classic result [25] that the greedy algorithm offers a constant-factor mathematical
quality guarantee. Computational tractability notwithstanding  submodular functions are natural for
measuring ﬁdelity and diversity [19] as we argue in Section 4.

2.2 Evaluation Criteria: V-ROUGE

Before describing practical submodular functions for mixture components  we discuss a crucial ele-
ment for both summarization evaluation and for the automated learning of mixtures: an objective evalu-
ation criterion for judging the quality of summaries. Our criterion is constructed similar to the popular
ROUGE score used in multi-document summarization [17] and that correlates well with human per-
ception. For document summarization  ROUGE (which in fact  is submodular [19  20]) is deﬁned as:

w∈W(cid:80)
(cid:80)
(cid:80)
w∈W(cid:80)

rS (A) =

S∈S cw(S)

S∈S min (cw(A)  cw(S))

( (cid:44) r(A) when S is clear from the context) 

(2)
where S is a set of human-generated reference summaries  W is a set of features (n-grams)  and where
cw(A) is the occurrence-count of w in summary A. We may extend r(·) to handle images by letting W
be a set of visual words  S a set of reference summaries  and cw(A) be the occurrence-counts of visual
word w in summary A. Visual words can for example be computed from SIFT-descriptors [21] as com-
mon in the popular bag-of-words framework in computer vision [31]. We call this V-ROUGE (visual
ROUGE). In our experiments  we use visual words extracted from color histograms  from super-pixels 
and also from OverFeat [27]  a deep convolutional network — details are given in Section 5.

submodular functions f1  f2  . . .   fm  i.e. Fw(S) = (cid:80)m
wi ≥ 0 (cid:80)

3 Learning Framework
We construct our submodular scoring functions Fw(·) as convex combinations of non-negative
i=1 wifi(S)  where w = (w1  . . .   wm) 
i wi = 1. The functions fi are submodular components and assumed to be normalized:
i.e.  fi(∅) = 0  and fi(V ) = 1 for polymatroid functions and maxA⊆V fi(A) ≤ 1 for non-monotone
functions. This ensures that the components are compatible with each other. Obviously  the merit of
the scoring function Fw(·) depends on the selection of the components. In Section 4  we provide a
large number of natural component choices  mixtures over which span a large diversity of submodular
functions. Many of these component functions have appeared individually in past work and are
uniﬁed into a single framework in our approach.
Large-margin Structured Prediction: We optimize the weights w of the scoring function Fw(·)
in a large-margin structured prediction framework  i.e. the weights are optimized such that human
summaries S are separated from competitor summaries by a loss-dependent margin:

(3)
where (cid:96)(·) is the considered loss function  and where Y is a structured output space (for example Y
is the set of summaries that satisfy a certain budget c  i.e. Y = {S(cid:48) ⊆ V : |S(cid:48)| ≤ c}). We assume

Fw(S) ≥ Fw(S(cid:48)) + (cid:96)(S(cid:48)) 

∀S ∈ S  S(cid:48) ∈ Y \ S 

3

(cid:21)

(cid:20)

(cid:88)

the loss to be normalized  0 ≤ (cid:96)(S(cid:48)) ≤ 1 ∀S(cid:48) ⊆ V   to ensure mixture and loss are calibrated.
Equation (3) can be stated as Fw(S) ≥ maxS(cid:48)∈Y [Fw(S(cid:48)) + (cid:96)(S(cid:48))]  ∀S ∈ S which is called loss-
augmented inference. We introduce slack variables and minimize the regularized sum of slacks [20]:

+

λ
2

min

max

S∈S

(cid:107)w(cid:107)2
2 

w≥0 (cid:107)w(cid:107)1=1

S(cid:48)∈Y [Fw(S(cid:48)) + (cid:96)(S(cid:48))] − Fw(S)

(4)
where the non-negative orthant constraint  w ≥ 0  ensures that the ﬁnal mixture is submodular. Note
a 2-norm regularizer is used on top of a 1-norm constraint (cid:107)w(cid:107)1 = 1 which we interpret as a prior to
encourage higher entropy  and thus more diverse mixture  distributions. Tractability depends on the
choice of the loss function. An obvious choice is (cid:96)(S) = 1 − r(S)  which yields a non-submodular
optimization problem suitable for optimization methods such as [10] (and which we try in Section 7).
We also consider other loss functions that retain submodularity in loss augmented inference. For
now  assume that ˜S = maxS(cid:48)∈Y [Fw(S(cid:48)) + (cid:96)(S(cid:48))] can be estimated efﬁciently. The objective in (4)
can then be minimized using standard stochastic gradient descent methods  where the gradient for
sample S with respect to weight wi is given as

(cid:18)

∂
∂wi

(cid:19)

Fw( ˜S) + (cid:96)( ˜S) − Fw(S) +

(cid:107)w(cid:107)2

2

λ
2

= fi( ˜S) − fi(S) + λwi.

(5)

S

w∈W c

(cid:80)

S∈S(cid:80)

Loss Functions: A natural loss function is (cid:96)1−R(S) = 1 − r(S) where r(S) = V-ROUGE(S).
Because r(S) is submodular  1 − r(S) is supermodular and hence maximizing Fw(S(cid:48)) + (cid:96)(S(cid:48))
requires difference-of-submodular set function maximization [24] which is NP-hard [10]. We
also consider two alternative loss functions [20]  complement V-ROUGE and surrogate V-ROUGE.
Complement V-ROUGE sets (cid:96)c(S) = r(V \ S) and is still submodular but it is non-monotone.
(cid:96)c(·) does have the necessary characteristics of a proper loss: summaries S+ with large V-ROUGE
score are mapped to small values and summaries S− with small V-ROUGE score are mapped to
large values. In particular  submodularity means r(S) + r(V \ S) ≥ r(V ) + r(∅) = r(V ) or
r(V \ S) ≥ r(V )− r(S) = 1− r(S)  so complement rouge is a submodular upper bound of the ideal
supermodular loss. We deﬁne surrogate V-ROUGE as (cid:96)surr(A) = 1
cw(A)  where
W c
Z
S is the set of visual words that do not appear in reference summary S and Z is a normalization
constant. Here  a summary has a high loss if it contains many visual words that do not occur in
reference summaries and a low loss if it mainly contains visual words that occur in the reference
summaries. Surrogate V-ROUGE is not only monotone submodular  it is modular.
Loss augmented Inference: Depending on the loss function  different algorithms for performing
loss augmented inference  i.e. computation of the maximum in (4)  must be used. When using the
surrogate loss lsurr(·)  the mixture function together with the loss  i.e. fL(S) = Fw(S) + (cid:96)(S)  is
submodular and monotone. Hence  the greedy algorithm [25] can be used for maximization. This
algorithm is extremely simple to implement  and starting at S0 = ∅  iteratively chooses an element
j /∈ St that maximizes fL(St ∪ j)  until the budget constraint is violated. While the complexity of
this simple procedure is O(n2) function evaluations  it can be signiﬁcantly accelerated  thanks again
to submodularity [23]  which in practice we ﬁnd is almost linear time. When using complement rouge
(cid:96)c(·) as the loss  fL(S) is still submodular but no longer monotone  so we utilize the randomized
greedy algorithm [2] (which is essentially a randomized variant of the greedy algorithm above  and
has approximation guarantees). Finally  when using loss 1-V-ROUGE  Fw(S) + (cid:96)(S) is neither
submodular nor monotone and approximate maximization is intractable. However  we resort to well
motivated and scalable heuristics  such as the submodular-supermodular procedures that have shown
good performance in various applications [24  10].
Runtime Inference: Having learnt the weights for the mixture components  the resulting function
i=1 wifi(S) is monotone submodular  which can be optimized by the accelerated greedy

Fw(S) =(cid:80)m

algorithm [23]. Thanks to submodularity  we can obtain near optimal solutions very efﬁciently.

4 Submodular Component Functions
In this section  we consider candidate submodular component functions to use in Fw(·). We consider
ﬁrst functions capturing more of the notion of ﬁdelity  and then next diversity  although the distinction
is not entirely crystal clear in these functions as some have aspects of both. Many of the components
are graph-based. We deﬁne a weighted graph G(V  E  s)  with V representing a the full set of images
and E is every pair of elements in V . Each edge (i  j) ∈ E has weight si j computed from the visual
features as described in Section 7. The weight si j is a similarity score between images i and j.

4

4.1 Fidelity-like Functions

A function representing the ﬁdelity of a subset to the whole is one that gets a large value when
the subset faithfully represents that whole. An intuitively reasonable property for such a function
is one that scores a summary highly if it is the case that the summary  as a whole  is similar to a
large majority of items in the set V . In this case  if a given summary A has a ﬁdelity of f (A)  then
any superset B ⊃ A should  if anything  have higher ﬁdelity  and thus it seems natural to use only
monotone non-decreasing functions as ﬁdelity functions. Submodularity is also a natural property
since as more and more properties of an image collection are covered by a summary  the less chance
any given image not part of the summary would have in offering additional coverage — in other
words  submodularity is a natural model for measuring the inherent redundancy in any summary.
Given this  we brieﬂy describe some possible choices for coverage functions:
Facility Location. Given a summary S ⊆ V   we can quantify coverage of the whole image collection
V by the similarity between i ∈ V and its closest image j ∈ S. Summing these similarities yields the
i∈V maxj∈S si j. The facility location function has been

used for scene summarization in [28] and as one of the components in [20].
Sum Coverage. Here  we compute the average similarity in S rather than the similarity of the best
element in S only. From the graph perspective (G) we sum over the weights of edges with at least

facility location function ffac.loc.(S) =(cid:80)
one vertex in S. Thus  fsum cov.(S) =(cid:80)
in S  we threshold the inner sum. Deﬁne σi(S) =(cid:80)
cause of the objective getting large  we deﬁne fthresh.sum(S) =(cid:80)

j∈S si j.

Thresholded sum/truncated graph cut This function has been used in document summariza-
tion [20] and is similar to the sum coverage function except that instead of summing over all elements
j∈S si j  i.e. informally  σi(S) conveys how
much of image i is covered by S. In order to keep an element i from being overly covered by S as the
i∈V min(σi(S)  α σi(V ))  which is
both monotone and submodular [20]. Under budget constraints  this function avoids summaries that
over-cover any images.
Feature functions. Consider a bag-of-words image model where for i ∈ V   bi = (bi w)w∈W
is a bag-of-words representation of image i indexed by the set of visual words W (cf. Section 5).
We can then deﬁne a feature coverage function [14]  deﬁned using the visual words  as follows:

(cid:1)  where g(·) is a monotone non-decreasing concave function.

ffeat.cov.(S) =(cid:80)

w∈W g(cid:0)(cid:80)

This class is both monotone and submodular  and an added beneﬁt of scalability  since it does not
require computation of a O(n2) similarity matrix like the graph-based functions proposed above.

i∈I bi w

(cid:80)

i∈V

4.2 Diversity

i∈S

(cid:80)

over all pairs as follows: fdissim.(S) = −(cid:80)
takes the form −(cid:80)

Diversity is another trait of a good summary  and there are a number of ways to quantify it. In this
case  while submodularity is still quite natural  monotonicity sometimes is not.
Penalty based diversity/dispersion Given a set S  we penalize similarity within S by summing
j∈S j>i si j [28] (a variant  also submodular 
i j∈S si j [19]). These functions are submodular  and monotone decreasing  so
when added to other functions can yield non-monotone submodular functions. Such functions have
occurred before in document summarization [19]  as a dispersion function [1]  and even for scene
summarization [28] (in this last case  the submodularity property was not explicitly mentioned).
Diversity reward based on clusters. As in [20]  we deﬁne a cluster based function rewarding
diversity. Given clusters P1  P2 ···   Pk obtained by some clustering algorithm. We deﬁne diversity
j=1 g(S ∩ Pj)  where g(·) is a monotone submodular function
so that fdiv.reward(·) is also monotone and submodular. Given a budget  fdiv.reward(S) is maximized
by selecting S as diverse  over different clusters  as possible because of diminishing credit when
repeatedly choosing an item in a cluster.

reward functions fdiv.reward(S) =(cid:80)k

5 Visual Words for Evaluation

V-ROUGE (see Section 2.2) depends on a visual “bag-of-words” vocabulary  and to construct a visual
vocabulary  multitude choices exists. Common choices include SIFT descriptors [21]  color descrip-
tors [34]  raw image patches [7]  etc. For encoding  vector quantization (histogram encoding) [4] 
sparse coding [35]  kernel codebook encoding [4]  etc. can all be used. For the construction of our

5

V-ROUGE metric  we computed three lexical types and used their union as our visual vocabulary. The
different types are intended to capture information about the images at different scales of abstraction.
Color histogram. The goal here is to capture overall image information via color information. We
follow the method proposed in [34]: Firstly  we extract the most frequent colors in RGB color space
from the images in an image collection using 10 × 10 pixel patches. Secondly  these frequent colors
are clustered by k-means into 128 clusters  resulting in 128 cluster centers. Finally  we quantize the
most frequent colors in every 10 × 10 pixel image patch using nearest neighbor vector quantization.
For every image  the resulting bag-of-colors is normalized to unit (cid:96)1-norm.
Super pixels. Here  we wish to capture information about small objects or image regions that are
identiﬁed by segmentation. Images are ﬁrst segmented using the quick shift algorithm implemented
in VLFeat [33]. For every segment  dense SIFT descriptors are computed and clustered into 200
clusters. Then  a patch-wise intermediate bag of words bpatch is computed by vector quantization
and the RGB color histogram of the corresponding patch cpatch is appended to that set of words.
This results in intermediate features φpatch = [bpatch  cpatch]. These intermediate features are again
clustered into 200 clusters. Finally  the intermediate features are vector-quantized according to their
(cid:96)1-distance. This ﬁnal bag-of-words representation is normalized to unit (cid:96)1-norm.
Deep convolutional neural network. Our deep neural network based words are meant to capture
high-level information from the images. We use OverFeat [27]  i.e. an image recognizer and feature
extractor based on a convolutional neural network for extracting medium to high level image features.
A sliding window is moved across an input picture such that every image is divided into 10 × 10
blocks (using a 50% overlap) and the pixels within the window are presented to OverFeat as input.
The activations on layer 17 are taken as intermediate features φk and clustered by k-means into 300
clusters. Then  each φk is encoded by kernel codebook encoding [4]. For every image  the resulting
bag-of-words representation is normalized to the unit (cid:96)1-norm.

6 Data Collection

Dataset. One major contribution of our paper is our new data set which we plan soon to publicly
release. Our data set consists of 14 image collections  each comprising 100 images. The image
collections are typical real world personal image collections as they  for the most part  were taken
during holiday trips. For each collection  human-generated summaries were collected using Amazon
mechanical Turk. Workers were asked to select a subset of 10 images from an image collection such
that it summarizes the collection in the best possible way.1 In contrast to previous work on movie
summarization [13]  Turkers were not tested for their ability to produce high quality summaries.
Every Turker was rewarded 10 US cents for every summary.
Pruning of poor human-generated summaries. The summaries collected using Amazon
mechanical Turk differ drastically in quality. For example  some of the collected summaries have low
quality because they do not represent an image collection properly  e.g. they consist only of pictures
of the same people but no pictures showing  say  architecture. Even though we went through several
distinct iterations of summary collection via Amazon Turk  improving the quality of our instructions
each time  it was impossible to ensure that all individuals produced meaningful summaries. Such
low quality summaries can drastically degrade performance of the learning algorithm. We thus
developed a strategy to automatically prune away bad summaries  where “bad” is deﬁned as the
worst V-ROUGE score relative to a current set of human summaries. The strategy is depicted in
Algorithm 1. Each pruning step removes the worst human summary  and then creates a new instance
of V-ROUGE using the updated pruned summaries. Pruning proceeds as long as a signiﬁcant fraction
(greater than a desired “p-value”) of null-hypothesis summarizes (generated uniformly at random)
scores better than the worst human summary. We chose a signiﬁcant value of p = 0.10.

7 Experiments
To validate our approach  we learned mixtures of submodular functions with 594 component
functions using the data set described in Section 6. In this data set  all human generated reference
summaries are size 10  and we evaluated performance of our learnt mixtures also by producing size
10 summaries. The component functions were the monotone submodular functions described in

1We did not provide explicit instructions on precisely how to summarize an image collection and instead
only asked that they choose a representative subset. We relied on their high-level intuitive understanding that the
gestalt of the image collection should be preserved in the summary.

6

Algorithm 1 Algorithm for pruning poor human-generated summaries.
Require: Conﬁdence level p  human summaries S  number of random summaries N

(cid:80)

Sample N uniformly at random size-10 image sets  to be used as summaries R = (R1  . . .   RN )
Instantiate V-ROUGE-score rS (·) instantiated with summaries S
o ← 1|R|
while o > p do
S ← S \ (argminS∈S rS (S))
Re-instantiate V-ROUGE score rS (·) using updated pruned human summaries S.
Recompute overlap o as above  but with updated V-ROUGE score.

R∈R 1{rS (R)>minS∈S rS (S)} // fraction of random summaries better than worst human

end while
return Pruned human summaries S

Figure 1: Three example 10×10 image collections from our new data set.

Section 4 using features described in Section 5. For weight optimization  we used AdaGrad [6]  an
adaptive subgradient method allowing for informative gradient-based learning. We do 20 passes
through the samples in the collection.
We considered two types of experiments: 1) cheating experiments to verify that our proposed mixture
components can effectively learn good scoring functions; and 2) a 14-fold cross-validation experiment
to test our approach in real- world scenarios. In the cheating experiments  training and testing is
performed on the same image collection  and this is repeated 14 times. By contrast  for our 14-fold
cross-validation experiments  training is performed on 13 out of 14 image collections and testing is
performed on the held out summary  again repeating this 14 times. In both experiment types  since
our learnt functions are always monotone submodular  we compute summaries S∗ of size 10 that
approximately maximize the scoring functions using the greedy algorithm. For these summaries 
we compute the V-ROUGE score r(S∗). For easy score interpretation  we normalize it according to
sc(S∗) = (r(S∗) − R)/(H − R)  where R is the average V-ROUGE score of random summaries
(computed from 1000 summaries) and where H is the average V-ROUGE score of the collected ﬁnal
pruned human summaries. The result sc(S∗) is smaller than zero if S∗ scores worse than the average
random summary and larger than one if it scores better than the average human summary.
The best cheating results are shown as Cheat in Table 1  learnt using 1-V-ROUGE as a loss. The
results in column Min are computed by constrainedly minimizing V-ROUGE via the methods of [11] 
and the results in column Max are computed by maximizing V-ROUGE using the greedy algorithm.
Therefore  the Max column is an approximate upper bound on our achievable performance. Clearly 
we are able to learn good scoring functions  as on average we signiﬁcantly exceed average human
performance  i.e.  we achieve an average score of 1.42 while the average human score is 1.00.
Results for cross-validation experiments are presented in Table 1. In the columns Our Methods
we present the performance of our mixtures learnt using the proposed loss functions described in
Section 3. We also present a set of baseline comparisons  using similarity scores computed via a
histogram intersection [32] method over the visual words used in the construction of V-ROUGE. We
present baseline results for the following schemes:

FL the facility location objective ffac.loc.(S) alone;

FLpen the facility location objective mixed with a λ-weighted penalty  i.e. ffac.loc.(S) + λfdissim.(S);
MMR Maximal marginal relevance [3]  using λ to tradeoff between relevance and diversity;
GCpen Graphcut mixed with a λ-weighted penalty  similar to FLpen but where graphcut is used in

place of facility location;
kM K-Medoids clustering [9  Algorithm 14.2]. Initial cluster centers were selected uniformly at
random. As a dissimilarity score between images i and j  we used 1 − si j. Clustering was
run 20 times  and we used the cluster centers of the best clustering as the summary.

7

In each of the above cases where a λ weight is used  we take for each image collection the λ ∈
{0  0.1  0.2  . . .   0.9  1.0} that produced a submodular function that when maximized produced the
best average V-ROUGE score on the 13 training image sets. This approach  therefore  selects the best
baseline possible when performing a grid-search on the training sets. Note that both λ-dependent
functions  i.e. FLpen and GCpen  are non-monotone submodular. Therefore  we used the randomized
greedy algorithm [2] for maximization which has a mathematical guarantee (we ran the algorithm 10
times and used the best result).
Table 1 shows that using 1-V-ROUGE as a loss signiﬁcantly outperforms the other methods. Further-
more  the performance is on average better than human performance  i.e. we achieve an average score
of 1.13 while the average human score is 1.00. This indicates that we can efﬁciently learn scoring
functions suitable for image collection summarization. For the other two losses  i.e. surrogate and
complement V-ROUGE  performance is signiﬁcantly worse. Thus  in this case it seems advantageous
to use the proper (supermodular) loss and heuristic optimization (the submodular-supermodular
procedure [24  10]) for loss-augmented inference during training  compared to using an approximate
(submodular or modular) loss in combination with an optimization algorithm for loss-augmented
inference with strong guarantees. This could  however  perhaps be circumvented by constructing a
more accurate strictly submodular surrogate loss but we leave this to future work.

Table 1: Cross-Validation Experiments (see text for details). Average human performance is 1.00 
average random performance is 0.00. For each image collection  the best result achieved by any of
Our Methods and by any of the Baseline Methods is highlighted in bold.

Limits

Our Methods

Baseline Methods

FLpen MMR GCpen
1.06
0.82
0.21
0.58
0.94
-0.53
1.01
-0.02
-1.28
0.93
0.20
1.16
-0.84
0.70
-1.27
0.38
0.94
-0.59
0.07
0.99
0.56
0.05
-0.01
0.54
-0.04
-0.06
0.14
-0.80
-0.27
0.69

-0.51
0.65
0.85
0.51
0.95
-0.08
-0.33
0.57
0.09
-0.26
-0.29
0.02
0.52
0.22
0.21

kM
1.23
0.89
0.52
1.32
0.70
1.05
0.97
0.91
0.38
0.73
0.26
0.63
0.02
0.29
0.71

No. Min Max Cheat
1.71
1.38
1.64
1.42
1.60
1.81
1.07
1.45
1.73
1.39
1.22
1.57
0.77
1.07
1.42

-2.55
-2.06
-2.07
-3.20
-1.65
-2.83
-2.44
-1.66
-2.32
-1.46
-1.55
-1.74
-0.94
-1.46
-2.00

2.78
2.22
2.24
2.04
1.92
2.40
2.07
2.04
2.59
2.34
1.85
2.39
1.72
1.75
2.17

1
2
3
4
5
6
7
8
9
10
11
12
13
14
Avg.

(cid:96)1−R
1.51
1.27
1.46
1.04
1.11
1.47
1.07
1.13
1.21
1.06
0.95
1.11
0.32
1.08
1.13

(cid:96)c
0.87
1.26
0.95
0.81
1.06
0.65
0.96
0.96
1.13
0.78
0.92
0.58
0.53
0.97
0.89

(cid:96)surr
-0.36
0.44
0.23
-0.18
0.58
0.27
0.15
0.07
0.51
0.14
-0.08
0.12
0.14
0.77
0.20

FL
1.45
0.18
0.47
0.71
0.96
1.26
0.93
0.62
0.81
1.58
0.43
0.78
0.02
0.23
0.75

8 Conclusions and Future Work
We have considered the task of automated summarization of image collections. A new data set
together with many human generated ground truth summaries was presented and a novel automated
evaluation metric called V-ROUGE was introduced. Based on large-margin structured prediction 
and either submodular or non-submodular optimization  we proposed a method for learning scoring
functions for image collection summarization and demonstrated its empirical effectiveness. In future
work  we would like to scale our methods to much larger image collections. A key step in this
direction is to consider low complexity and highly scalable classes of submodular functions. Another
challenge for larger image collections is how to collect ground truth  as it would be difﬁcult for a
human to summarize a collection of  say  10 000 images.
Acknowledgments: This material is based upon work supported by the National Science Foundation
under Grant No. (IIS-1162606)  the Austrian Science Fund under Grant No. (P25244-N15)  a Google
and a Microsoft award  and by the Intel Science and Technology Center for Pervasive Computing.
Rishabh Iyer is also supported by a Microsoft Research Fellowship award.
References
[1] A. Borodin  H. C. Lee  and Y. Ye. Max-sum diversiﬁcation  monotone submodular functions and dynamic
updates. In Proc. of the 31st symposium on Principles of Database Systems  pages 155–166. ACM  2012.
[2] N. Buchbinder  M. Feldman  J. Naor  and R. Schwartz. Submodular maximization with cardinality

constraints. In SODA  2014.

8

[3] J. Carbonell and J. Goldstein. The use of MMR  diversity-based reranking for reordering documents and

producing summaries. In Research and Development in Information Retrieval  pages 335–336  1998.

[4] K. Chatﬁeld  V. Lemtexpitsky  A. Vedaldi  and A. Zisserman. The devil is in the details: an evaluation of

recent feature encoding methods. In British Machine Vision Conference (BMVC)  2011.

[5] T. Denton  M. Demirci  J. Abrahamson  A. Shokoufandeh  and S. Dickinson. Selecting canonical views for

view-based 3-d object recognition. In ICPR  volume 2  pages 273–276  Aug 2004.

[6] J. Duchi  E. Hazan  and Y. Singer. Adaptive subgradient methods for online learning and stochastic

optimization. Journal of Machine Learning Research (JMLR)  12:2121–2159  July 2011.

[7] R. Fergus  P. Perona  and A. Zisserman. Object class recognition by unsupervised scale-invariant learning.

In CVPR  volume 2  pages 264–271. IEEE  June 2003.

[8] Y. Hadi  F. Essannouni  and R. O. H. Thami. Video summarization by k-medoid clustering. In Symposium

on Applied Computing (SAC)  pages 1400–1401  2006.

[9] T. Hastie  R. Tibshirani  and J. Friedman. The elements of statistical learning  volume 2. Springer New

York  2nd edition  2009.

[10] R. Iyer and J. Bilmes. Algorithms for approximate minimization of the difference between submodular

functions  with applications. In UAI  2012.

[11] R. Iyer  S. Jegelka  and J. Bilmes. Fast semidifferential-based submodular function optimization. In ICML 

2013.

[12] A. Jaffe  M. Naaman  T. Tassa  and M. Davis. Generating summaries and visualization for large collections

of geo-referenced photographs. In MIR  pages 89–98. ACM  2006.

[13] A. Khosla  R. Hamid  C.-J. Lin  and N. Sundaresan. Large-scale video summarization using web-image

priors. In Conference on Computer Vision and Pattern Recognition (CVPR)  June 2013.

[14] K. Kirchhoff and J. Bilmes. Submodularity for data selection in machine translation. In Empirical Methods

in Natural Language Processing (EMNLP)  October 2014.

[15] A. Kulesza and B. Taskar. k-DPPs: Fixed-size determinantal point processes. In Proceedings of the 28th

International Conference on Machine Learning  2011.

[16] X. Li  L. Chen  L. Zhang  F. Lin  and W.-Y. Ma. Image annotation by large-scale content-based image

retrieval. In Proc. 14th ann. ACM Int. Conf. on Multimedia  pages 607–610. ACM  2006.

[17] C.-Y. Lin. Rouge: A package for automatic evaluation of summaries. In Text Summarization Branches

Out: Proceedings of the ACL-04 Workshop  pages 74–81  July 2004.

[18] H. Lin and J. Bilmes. Multi-document summarization via budgeted maximization of submodular functions.

[19] H. Lin and J. Bilmes. A class of submodular functions for document summarization. In ACL/HLT-2011 

In NAACL  2010.

Portland  OR  June 2011.

[20] H. Lin and J. Bilmes. Learning mixtures of submodular shells with application to document summarization.

In Conference on Uncertainty in Artiﬁcial Intelligence (UAI)  pages 479–490  2012.

[21] D. Lowe. Object recognition from local scale-invariant features. In International Conference on Computer

Vision (ICCV)  volume 2  pages 1150–1157  1999.

[22] M. Meeker and L. Wu. Internet trends. Technical report  Kleiner Perkins Cauﬁeld & Byers  2013.
[23] M. Minoux. Accelerated greedy algorithms for maximizing submodular set functions. Optimization

Techniques  pages 234–243  1978.

[24] M. Narasimhan and J. Bilmes. A submodular-supermodular procedure with applications to discriminative
structure learning. In Conference on Uncertainty in Artiﬁcial Intelligence (UAI)  Edinburgh  Scotland  July
2005. Morgan Kaufmann Publishers.

[25] G. Nemhauser  L. Wolsey  and M. Fisher. An analysis of approximations for maximizing submodular set

functions–i. Mathematical Programming  14(1):265–294  1978.

[26] C.-W. Ngo  Y.-F. Ma  and H. Zhang. Automatic video summarization by graph modeling. In International

Conference on Computer Vision (ICCV)  pages 104–109 vol.1  Oct 2003.

[27] P. Sermanet  D. Eigen  X. Zhang  M. Mathieu  R. Fergus  and Y. LeCun. OverFeat: Integrated Recognition 

Localization and Detection using Convolutional Networks. ArXiv e-prints  Dec. 2013.

[28] I. Simon  N. Snavely  and S. M. Seitz. Scene Summarization for Online Image Collections. ICCV  2007.
[29] P. Sinha and R. Jain. Extractive summarization of personal photos from life events. In International

Conference on Multimedia and Expo (ICME)  pages 1–6  2011.

[30] P. Sinha  S. Mehrotra  and R. Jain. Summarization of personal photologs using multidimensional content

and context. In International Conference on Multimedia Retrieval (ICMR)  pages 1–8  2011.

[31] J. Sivic  B. Russell  A. Efros  A. Zisserman  and W. Freeman. Discovering objects and their location in

images. In International Conference on Computer Vision (ICCV)  volume 1  pages 370–377  Oct 2005.

[32] M. J. Swain and D. H. Ballard. Color indexing. Int. journal of computer vision  7(1):11–32  1991.
[33] A. Vedaldi and B. Fulkerson. VLFeat: An open and portable library of computer vision algorithms.

http://www.vlfeat.org/  2008.

[34] C. Wengert  M. Douze  and H. J´egou. Bag-of-colors for improved image search.

In International

Conference on Multimedia (MM)  pages 1437–1440. ACM  2011.

[35] J. Yang  K. Yu  Y. Gong  and T. S. Huang. Linear spatial pyramid matching using sparse coding for image

classiﬁcation. In CVPR  pages 1794–1801  2009.

9

,Sebastian Tschiatschek
Rishabh Iyer
Jeff Bilmes
Alaa Saade
Florent Krzakala
Lenka Zdeborová
Qinshi Wang
Wei Chen