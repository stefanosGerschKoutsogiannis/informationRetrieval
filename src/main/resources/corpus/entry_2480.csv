2016,Homotopy Smoothing for Non-Smooth Problems with Lower Complexity than $O(1/\epsilon)$,In this paper  we develop a novel {\bf ho}moto{\bf p}y  {\bf s}moothing (HOPS) algorithm for solving a family of non-smooth problems that is composed of a non-smooth term with an explicit max-structure and  a smooth term or  a simple non-smooth term whose proximal mapping is easy to compute. The best known iteration complexity for solving such non-smooth optimization problems is $O(1/\epsilon)$ without any assumption on the strong convexity. In this work  we will show that the proposed  HOPS achieved a lower iteration complexity of $\tilde O(1/\epsilon^{1-\theta})$ with $\theta\in(0 1]$ capturing the local sharpness of the objective function around the optimal solutions. To the best of our knowledge  this is the lowest iteration complexity achieved so far for the considered non-smooth optimization problems without strong convexity assumption.  The HOPS algorithm employs Nesterov's smoothing technique and Nesterov's accelerated gradient method and runs in stages  which gradually decreases the smoothing parameter in a stage-wise manner until it yields a sufficiently good approximation of the original function. We show that HOPS enjoys a linear convergence for many well-known non-smooth problems (e.g.  empirical risk minimization with a piece-wise linear loss function and $\ell_1$ norm regularizer  finding a point in a polyhedron  cone programming  etc). Experimental results verify the effectiveness of HOPS in comparison with Nesterov's smoothing algorithm and the primal-dual style of first-order methods.,Homotopy Smoothing for Non-Smooth Problems

with Lower Complexity than O(1/)

Yi Xu†∗  Yan Yan‡∗  Qihang Lin(cid:92)  Tianbao Yang u†

† Department of Computer Science  University of Iowa  Iowa City  IA 52242

‡ QCIS  University of Technology Sydney  NSW 2007  Australia

(cid:92) Department of Management Sciences  University of Iowa  Iowa City  IA 52242

{yi-xu  qihang-lin  tianbao-yang}@uiowa.edu  yan.yan-3@student.uts.edu.au

Abstract

In this paper  we develop a novel homotopy smoothing (HOPS) algorithm for
solving a family of non-smooth problems that is composed of a non-smooth
term with an explicit max-structure and a smooth term or a simple non-smooth
term whose proximal mapping is easy to compute. The best known iteration
complexity for solving such non-smooth optimization problems is O(1/) without
any assumption on the strong convexity. In this work  we will show that the
proposed HOPS achieved a lower iteration complexity of ˜O(1/1−θ) 1with θ ∈
(0  1] capturing the local sharpness of the objective function around the optimal
solutions. To the best of our knowledge  this is the lowest iteration complexity
achieved so far for the considered non-smooth optimization problems without
strong convexity assumption. The HOPS algorithm employs Nesterov’s smoothing
technique and Nesterov’s accelerated gradient method and runs in stages  which
gradually decreases the smoothing parameter in a stage-wise manner until it yields
a sufﬁciently good approximation of the original function. We show that HOPS
enjoys a linear convergence for many well-known non-smooth problems (e.g. 
empirical risk minimization with a piece-wise linear loss function and (cid:96)1 norm
regularizer  ﬁnding a point in a polyhedron  cone programming  etc). Experimental
results verify the effectiveness of HOPS in comparison with Nesterov’s smoothing
algorithm and the primal-dual style of ﬁrst-order methods.

Introduction

1
In this paper  we consider the following optimization problem:
F (x) (cid:44) f (x) + g(x)

min
x∈Ω1

(1)

where g(x) is a convex (but not necessarily smooth) function  Ω1 is a closed convex set and f (x) is a
convex but non-smooth function which can be explicitly written as

(cid:104)Ax  u(cid:105) − φ(u)

f (x) = max
u∈Ω2

(2)
where Ω2 ⊂ Rm is a closed convex bounded set  A ∈ Rm×d and φ(u) is a convex function  and (cid:104)· ·(cid:105)
is scalar product. This family of non-smooth optimization problems has applications in numerous
domains  e.g.  machine learning and statistics [7]  image processing [6]  cone programming [11] 
and etc. Several ﬁrst-order methods have been developed for solving such non-smooth optimization
∗The ﬁrst two authors make equal contributions. The work of Y. Yan was done when he was a visiting student

at Department of Computer Science of the University of Iowa.

1 ˜O() suppresses a logarithmic factor.

30th Conference on Neural Information Processing Systems (NIPS 2016)  Barcelona  Spain.

problems including the primal-dual methods [15  6]  Nesterov’s smoothing algorithm [16] 2  and they
can achieve O(1/) iteration complexity for ﬁnding an -optimal solution  which is faster than the
corresponding black-box lower complexity bounds by an order of magnitude.
In this paper  we propose a novel homotopy smoothing (HOPS) algorithm for solving the problem
in (1) that achieves a lower iteration complexity than O(1/). In particular  the iteration complexity
of HOPS is given by ˜O(1/1−θ)  where θ ∈ (0  1] captures the local sharpness (deﬁned shortly) of
the objective function around the optimal solutions. The proposed HOPS algorithm builds on the
Nesterov’s smoothing technique  i.e.  approximating the non-smooth function f (x) by a smooth
function and optimizing the smoothed function to a desired accuracy level.
The striking difference between HOPS and Nesterov’s smoothing algorithm is that Nesterov uses
a ﬁxed small smoothing parameter that renders a sufﬁciently accurate approximation of the non-
smooth function f (x)  while HOPS adopts a homotopy strategy for setting the value of the smoothing
parameter. It starts from a relatively large smoothing parameter and gradually decreases the smoothing
parameter in a stage-wise manner until the smoothing parameter reaches a level that gives a sufﬁciently
good approximation of the non-smooth objective function. The beneﬁt of using a homotopy strategy
is that a larger smoothing parameter yields a smaller smoothness constant and hence a lower iteration
complexity for smoothed problems in earlier stages. For smoothed problems in later stages with
larger smoothness constants  warm-start can help reduce the number of iterations to converge. As
a result  solving a series of smoothed approximations with a smoothing parameter from large to
small and with warm-start is faster than solving one smoothed approximation with a very small
smoothing parameter. To the best of our knowledge  this is the ﬁrst work that rigorously analyzes
such a homotopy smoothing algorithm and establishes its theoretical guarantee on lower iteration
complexities. The keys to our analysis of lower iteration complexity are (i) to leverage a global error
inequality (Lemma 1) [21] that bounds the distance of a solution to the  sublevel set by a multiple
of the functional distance; and (ii) to explore a local error bound condition to bound the multiplicative
factor.

2 Related Work
In this section  we review some related work for solving the considered family of non-smooth
optimization problems.
In the seminal paper by Nesterov [16]  he proposed a smoothing technique for a family of structured
non-smooth optimization problems as in (1) with g(x) being a smooth function and f (x) given in (2).
By adding a strongly convex prox function in terms of u with a smoothing parameter µ into the
deﬁnition of f (x)  one can obtain a smoothed approximation of the original objective function. Then
he developed an accelerated gradient method with an O(1/t2) convergence rate for the smoothed
objective function with t being the number of iterations  which implies an O(1/t) convergence rate for
the original objective function by setting µ ≈ c/t with c being a constant. The smoothing technique
has been exploited to solving problems in machine learning  statistics  cone programming [7  11  24].
The primal-dual style of ﬁrst-order methods treat the problem as a convex-concave minimization
problem  i.e. 

min
x∈Ω1

max
u∈Ω2

g(x) + (cid:104)Ax  u(cid:105) − φ(u)

Nemirovski [15] proposed a mirror prox method  which has a convergence rate of O(1/t) by assuming
that both g(x) and φ(u) are smooth functions. Chambolle & Pock [6] designed ﬁrst-order primal-dual
algorithms  which tackle g(x) and φ(u) using proximal mapping and achieve the same convergence
rate of O(1/t) without assuming smoothness of g(x) and φ(u). When g(x) or φ(u) is strongly
convex  their algorithms achieve O(1/t2) convergence rate. The effectiveness of their algorithms
was demonstrated on imaging problems. Recently  the primal-dual style of ﬁrst-order methods have
been employed to solve non-smooth optimization problems in machine learning where both the loss
function and the regularizer are non-smooth [22]. Lan et al. [11] also considered Nemirovski’s prox
method for solving cone programming problems.
The key condition for us to develop an improved convergence is closely related to local error bounds
(LEB) [17] and more generally the Kurdyka-Łojasiewicz property [12  4]. The LEB characterizes

2The algorithm in [16] was developed for handling a smooth component g(x)  which can be extended to

handling a non-smooth component g(x) whose proximal mapping is easy to compute.

2

the relationship between the distance of a local solution to the optimal set and the optimality gap
of the solution in terms of objective value. The Kurdyka-Łojasiewicz property characterizes that
property of a function that whether it can be made “sharp” by some transformation. Recently 
these conditions/properties have been explored for feasible descent methods [13]  non-smooth
optimization [8]  gradient and subgradient methods [10  21]. It is notable that our local error bound
condition is different from the one used in [13  25] which bounds the distance of a point to the optimal
set by the norm of the projected or proximal gradient at that point instead of the functional distance 
consequentially it requires some smoothness assumption about the objective function. By contrast 
the local error bound condition in this paper covers a much broad family of functions and thus it is
more general. Recent work [14  23] have shown that the error bound in [13  25] is a special case of
our considered error bound with θ = 1/2. Two mostly related work leveraging a similar error bound
to ours are discussed in order. Gilpin et al. [8] considered the two-person zero-sum games  which is a
special case of (1) with g(x) and φ(u) being zeros and Ω1 and Ω2 being polytopes. The present work
is a non-trivial generalization of their work that leads to improved convergence for a much broader
family of non-smooth optimization problems. In particular  their result is just a special case of our
result when the constant θ that captures the local sharpness is one for problems whose epigraph is
a polytope. Recently  Yang & Lin [21] proposed a restarted subgradient method by exploring the
local error bound condition or more generally the Kurdyka-Łojasiewicz property  resulting in an
˜O(1/2(1−θ)) iteration complexity with the same constant of θ. In contrast  our result is an improved
iteration complexity of ˜O(1/1−θ).
It is worth emphasizing that the proposed homotopy smoothing technique is different from recently
proposed homotopy methods for sparse learning (e.g.  (cid:96)1 regularized least-squares problem [20]) 
though a homotopy strategy on an involved parameter is also employed to boost the convergence. In
particular  the involved parameter in the homotopy methods for sparse learning is the regularization
parameter before the (cid:96)1 regularization  while the parameter in the present work is the introduced
smoothing parameter.
In addition  the beneﬁt of starting from a relatively large regularization
parameter in sparse learning is the sparsity of the solution  which makes it possible to explore the
restricted strong convexity for proving faster convergence. We do not make such assumption of
the data and we are mostly interested in that when both f (x) and g(x) are non-smooth. Finally 
we note that a similar homotopy (a.k.a continuation) strategy is employed in Nesterov’s smoothing
algorithm for solving an (cid:96)1 norm minimization problem subject to a constraint for recovering a sparse
solution [3]. However  we would like to draw readers’ attention to that they did not provide any
theoretical guarantee on the iteration complexity of the homotopy strategy and consequentially their
implementation is ad-hoc without guidance from theory. More importantly  our developed algorithms
and theory apply to a much broader family of problems.

3 Preliminaries
We present some preliminaries in this section. Let (cid:107)x(cid:107) denote the Euclidean norm on the primal
variable x. A function h(x) is L-smooth in terms of (cid:107) · (cid:107)  if (cid:107)∇h(x) − ∇h(y)(cid:107) ≤ L(cid:107)x − y(cid:107). Let
(cid:107)u(cid:107)+ denote a norm on the dual variable  which is not necessarily the Euclidean norm. Denote by
ω+(u) a 1-strongly convex function of u in terms of (cid:107) · (cid:107)+.
For the optimization problem in (1)  we let Ω∗  F∗ denote the set of optimal solutions and optimal
value  respectively  and make the following assumption throughout the paper.
Assumption 1. For a convex minimization problem (1)  we assume (i) there exist x0 ∈ Ω1 and
0 ≥ 0 such that F (x0) − minx∈Ω1 F (x) ≤ 0; (ii) f (x) is characterized as in (2)  where φ(u) is
a convex function; (iii) There exists a constant D such that maxu∈Ω2 ω+(u) ≤ D2/2; (iv) Ω∗ is a
non-empty convex compact set.
Note that: 1) Assumption 1(i) assumes that the objective function is lower bounded; 2) Assump-
tion 1(iii) assumes that Ω2 is a bounded set  which is also required in [16].
In addition  for brevity we assume that g(x) is simple enough 3 such that the proximal mapping
deﬁned below is easy to compute similar to [6]:

Pλg(x) = min
z∈Ω1

1
2

(cid:107)z − x(cid:107)2 + λg(z)

(3)

3If g(x) is smooth  this assumption can be relaxed. We will defer the discussion and result on a smooth

function g(x) to the supplement.

3

Relying on the proximal mapping  the key updates in the optimization algorithms presented below
take the following form:

Πc

v λg(x) = arg min
z∈Ω1

(4)
For any x ∈ Ω1  let x∗ denote the closest optimal solution in Ω∗ to x measured in terms of (cid:107) · (cid:107)  i.e. 
x∗ = arg minz∈Ω∗ (cid:107)z − x(cid:107)2  which is unique because Ω∗ is a non-empty convex compact set We
denote by L the -level set of F (x) and by S the -sublevel set of F (x)  respectively  i.e. 

(cid:107)z − x(cid:107)2 + (cid:104)v  z(cid:105) + λg(z)

c
2

L = {x ∈ Ω1 : F (x) = F∗ + }  S = {x ∈ Ω1 : F (x) ≤ F∗ + }

It follows from [18] (Corollary 8.7.1) that the sublevel set S is bounded for any  ≥ 0 and so as the
level set L due to that Ω∗ is bounded. Deﬁne dist(L  Ω∗) to be the maximum distance of points on
the level set L to the optimal set Ω∗  i.e. 
dist(L  Ω∗) = max
x∈L

(cid:107)x − z(cid:107)
Due to that L and Ω∗ are bounded  dist(L  Ω∗) is also bounded. Let x†
the -sublevel set to x  i.e. 

dist(x  Ω∗) (cid:44) min
z∈Ω∗

 denote the closest point in

(cid:20)

(cid:21)

(5)

.

x†
 = arg min
z∈S

(cid:107)z − x(cid:107)2

(6)

It is easy to show that x†

 ∈ L when x /∈ S (using the KKT condition).

4 Homotopy Smoothing
4.1 Nesterov’s Smoothing
We ﬁrst present the Nesterov’s smoothing technique and accelerated proximal gradient methods for
solving the smoothed problem due to that the proposed algorithm builds upon these techniques. The
idea of smoothing is to construct a smooth function fµ(x) that well approximates f (x). Nesterov
considered the following function

fµ(x) = max
u∈Ω2

(cid:104)Ax  u(cid:105) − φ(u) − µω+(u)

It was shown in [16] that fµ(x) is smooth w.r.t (cid:107) · (cid:107) and its smoothness parameter is given by
Lµ = 1

µ(cid:107)A(cid:107)2 where (cid:107)A(cid:107) is deﬁned by (cid:107)A(cid:107) = max(cid:107)x(cid:107)≤1 max(cid:107)u(cid:107)+≤1(cid:104)Ax  u(cid:105). Denote by

uµ(x) = arg max
u∈Ω2

(cid:104)Ax  u(cid:105) − φ(u) − µω+(u)

The gradient of fµ(x) is computed by ∇fµ(x) = A(cid:62)uµ(x). Then
fµ(x) ≤ f (x) ≤ fµ(x) + µD2/2

(7)
From the inequality above  we can see that when µ is very small  fµ(x) gives a good approximation
of f (x). This motivates us to solve the following composite optimization problem

Fµ(x) (cid:44) fµ(x) + g(x)

min
x∈Ω1

Many works have studied such an optimization problem [2  19] and the best convergence rate is
given by O(Lµ/t2)  where t is the total number of iterations. We present a variant of accelerated
proximal gradient (APG) methods in Algorithm 1 that works even with (cid:107)x(cid:107) replaced with a general
norm as long as its square is strongly convex. We make several remarks about Algorithm 1: (i) the
variant here is similar to Algorithm 3 in [19] and the algorithm proposed in [16] except that the prox
function d(x) is replaced by (cid:107)x − x0(cid:107)2/2 in updating the sequence of zk  which is assumed to be
σ1-strongly convex w.r.t (cid:107) · (cid:107); (ii) If (cid:107) · (cid:107) is simply the Euclidean norm  a simpliﬁed algorithm with
only one update in (4) can be used (e.g.  FISTA [2]); (iii) if Lµ is difﬁcult to compute  we can use the
backtracking trick (see [2  19]).
The following theorem states the convergence result for APG.
Theorem 2. ([19]) Let θk = 2
any x ∈ Ω1  we have

k+1   k ≥ 0 or αk+1 = θk+1 =

  k ≥ 0. For

k−θ2

k+4θ2
θ4

√

2

k

k+2   αk = 2
Fµ(xt) − Fµ(x) ≤ 2Lµ(cid:107)x − x0(cid:107)2

t2

(8)

4

Algorithm 1 An Accelerated Proximal Gradient Method: APG(x0  t  Lµ)
1: Input: the number of iterations t  the initial solution x0  and the smoothness constant Lµ
2: Let θ0 = 1  V−1 = 0  Γ−1 = 0  z0 = x0
3: Let αk and θk be two sequences given in Theorem 2.
4: for k = 0  . . .   t − 1 do
5:
6:
7:
8: end for
9: Output: xt

Compute yk = (1 − θk)xk + θkzk
Compute vk = ∇fµ(yk)  Vk = Vk−1 + vk
Compute zk+1 = ΠLµ/σ1

Vk Γkg(x0) and xk+1 = ΠLµ

  and Γk = Γk−1 + 1
αk

vk g(yk)

αk

Combining the above convergence result with the relation in (7)  we can establish the iteration
complexity of Nesterov’s smoothing algorithm for solving the original problem (1).
Corollary 3. For any x ∈ Ω1  we have

F (xt) − F (x) ≤ µD2/2 +

In particular in order to have F (xt) ≤ F∗ +   it sufﬁces to set µ ≤ 
where x∗ is an optimal solution to (1).

2Lµ(cid:107)x − x0(cid:107)2

t2

(9)
D2 and t ≥ 2D(cid:107)A(cid:107)(cid:107)x0−x∗(cid:107)



 

4.2 Homotopy Smoothing
From the convergence result in (9)  we can see that in order to obtain a very accurate solution  we
have to set µ - the smoothing parameter - to be a very small value  which will cause the blow-up of
the second term because Lµ ∝ 1/µ. On the other hand  if µ is set to be a relatively large value  then t
can be set to be a relatively small value to match the ﬁrst term in the R.H.S. of (9)  which may lead to
a not sufﬁciently accurate solution. It seems that the O(1/) is unbeatable. However  if we adopt a
homotopy strategy  i.e.  starting from a relatively large value µ and optimizing the smoothed function
with a certain number of iterations t such that the second term in (9) matches the ﬁrst term  which
will give F (xt) − F (x∗) ≤ O(µ). Then we can reduce the value of µ by a constant factor b > 1
and warm-start the optimization process from xt. The key observation is that although µ decreases
and Lµ increases  the other term (cid:107)x∗ − xt(cid:107) is also reduced compared to (cid:107)x∗ − x0(cid:107)  which could
cancel the blow-up effect caused by increased Lµ. As a result  we expect to use the same number of
iterations to optimize the smoothed function with a smaller µ such that F (x2t) − F (x∗) ≤ O(µ/b).
To formalize our observation  we need the following key lemma.
Lemma 1 ([21]). For any x ∈ Ω1 and  > 0  we have
  Ω∗)


(cid:107) ≤ dist(x†

(F (x) − F (x†
))

(cid:107)x − x†

 ∈ S is the closest point in the -sublevel set to x as deﬁned in (6).

where x†
The lemma is proved in [21]. We include its proof in the supplement. If we apply the above bound
into (9)  we will see in the proof of the main theorem (Theorem 5) that the number of iterations t for
solving each smoothed problem is roughly O( dist(L Ω∗)
 ) in light of
the local error bound condition given below.
Deﬁnition 4 (Local error bound (LEB)). A function F (x) is said to satisfy a local error bound
condition if there exist θ ∈ (0  1] and c > 0 such that for any x ∈ S

)  which will be lower than O( 1



dist(x  Ω∗) ≤ c(F (x) − F∗)θ

(10)
Remark: In next subsection  we will discuss the relationship with other types of conditions and
show that a broad family of non-smooth functions (including almost all commonly seen functions in
machine learning) obey the local error bound condition. The exponent constant θ can be considered
as a local sharpness measure of the function. Figure 1 illustrates the sharpness of F (x) = |x|p for
p = 1  1.5  and 2 around the optimal solutions and their corresponding θ.
With the local error bound condition  we can see that dist(L  Ω∗) ≤ cθ  θ ∈ (0  1]. Now  we
are ready to present the homotopy smoothing algorithm and its convergence guarantee under the

5

Algorithm 2 HOPS for solving (1)
1: Input: m  t  x0 ∈ Ω1  0  D2 and b > 1.
2: Let µ1 = 0/(bD2)
3: for s = 1  . . .   m do
4:
5:
6: end for
7: Output: xm

Let xs = APG(xs−1  t  Lµs)
Update µs+1 = µs/b

Figure 1: Illustration of local sharpness of three func-
tions and the corresponding θ in the LEB condition.

local error bound condition. The HOPS algorithm is presented in Algorithm 2  which starts from
a relatively large smoothing parameter µ = µ1 and gradually reduces µ by a factor of b > 1 after
running a number t of iterations of APG with warm-start. The iteration complexity of HOPS is
established in Theorem 5. We include the proof in the supplement.
Theorem 5. Suppose Assumption 1 holds and F (x) obeys the local error bound condition. Let
HOPS run with t = O( 2bcD(cid:107)A(cid:107)
 )(cid:101).
1−θ
Then F (xm) − F∗ ≤ 2. Hence  the iteration complexity for achieving an 2-optimal solution is
2bcD(cid:107)A(cid:107)

iterations for each stage  and m = (cid:100)logb( 0

) ≥ 2bcD(cid:107)A(cid:107)
1−θ

(cid:100)logb( 0

 )(cid:101) in the worst-case.

1−θ

min
x∈Rd

4.3 Local error bounds and Applications
In this subsection  we discuss the local error bound condition and its application in non-smooth
optimization problems.
The Hoffman’s bound and ﬁnding a point in a polyhedron. A polyhedron can be expressed as
P = {x ∈ Rd; B1x ≤ b1  B2x = b2}. The Hoffman’s bound [17] is expressed as

F (x) (cid:44)
1   u(cid:62)

dist(x P) ≤ c((cid:107)(B1x − b1)+(cid:107) + (cid:107)B2x − b2(cid:107)) ∃c > 0

(cid:104)B1x − b1  u1(cid:105) + (cid:104)B2x − b2  u2(cid:105)

(11)
where [s]+ = max(0  s). This can be considered as the error bound for the polyhedron feasibility
problem  i.e.  ﬁnding a x ∈ P  which is equivalent to

(cid:20)
(cid:107)(B1x − b1)+(cid:107) + (cid:107)B2x − b2(cid:107) = max
u∈Ω2
2 )(cid:62) and Ω2 = {u|u1 (cid:23) 0 (cid:107)u1(cid:107) ≤ 1 (cid:107)u2(cid:107) ≤ 1}. If there exists a x ∈ P  then
where u = (u(cid:62)
F∗ = 0. Thus the Hoffman’s bound in (11) implies a local error bound (10) with θ = 1. Therefore 
the HOPS has a linear convergence for ﬁnding a feasible solution in a polyhedron. If we let ω+(u) =
2(cid:107)u(cid:107)2 then D2 = 2 so that the iteration complexity is 2
1
Cone programming. Let U  V denote two vector spaces. Given a linear opearator E : U → V ∗ 4 
a closed convex set Ω ⊆ U  and a vector e ∈ V ∗  and a closed convex cone K ⊆ V   the general
constrained cone linear system (cone programing) consists of ﬁnding a vector x ∈ Ω such that
Ex − e ∈ K∗. Lan et al. [11] have considered Nesterov’s smoothing algorithm for solving the cone
programming problem with O(1/) iteration complexity. The problem can be cast into a non-smooth
optimization problem:

2bc max((cid:107)B1(cid:107) (cid:107)B2(cid:107))(cid:100)logb( 0

 )(cid:101).

(cid:21)

√

(cid:20)

(cid:21)

F (x) (cid:44)

dist(Ex − e K∗) =

max

(cid:107)u(cid:107)≤1 u∈−K

(cid:104)Ex − e  u(cid:105)

min
x∈Ω

Assume that e ∈ Range(E) − K∗  then F∗ = 0. Burke et al. [5] have considered the error bound for
such problems and their results imply that there exists c > 0 such that dist(x  Ω∗) ≤ c(F (x) − F∗)
as long as ∃x ∈ Ω  s.t. Ex − e ∈ int(K∗)  where Ω∗ denotes the optimal solution set. Therefore 
the HOPS also has a linear convergence for cone programming. Considering that both U and V are
2(cid:107)u(cid:107)2 then D2 = 1. Thus  the iteraction complexity of HOPS
Euclidean spaces  we set ω+(u) = 1
for ﬁnding an 2-solution is 2bc(cid:107)E(cid:107)(cid:100)logb( 0
Non-smooth regularized empirical loss (REL) minimization in Machine Learning The REL
consists of a sum of loss functions on the training data and a regularizer  i.e. 

 )(cid:101).
n(cid:88)

i=1

min
x∈Rd

F (x) (cid:44) 1
n

(cid:96)(x(cid:62)ai  yi) + λg(x)

4V ∗ represents the dual space of V . The notations and descriptions are adopted from [11].

6

−0.1−0.0500.050.100.020.040.060.080.1xF(x) |x|  θ=1|x|1.5  θ=2/3|x|2  θ=0.5where (ai  yi)  i = 1  . . .   n denote pairs of a feature vector and a label of training data. Non-smooth
loss functions include hinge loss (cid:96)(z  y) = max(0  1 − yz)  absolute loss (cid:96)(z  y) = |z − y|  which
can be written as the max structure in (2). Non-smooth regularizers include e.g.  g(x) = (cid:107)x(cid:107)1 
g(x) = (cid:107)x(cid:107)∞. These loss functions and regularizers are essentially piecewise linear functions 
whose epigraph is a polyhedron. The error bound condition has been developed for such kind of
problems [21]. In particular  if F (x) has a polyhedral epigraph  then there exists c > 0 such that
dist(x  Ω∗) ≤ c(F (x) − F∗) for any x ∈ Rd. It then implies HOPS has an O(log(0/)) iteration
complexity for solving a non-smooth REL minimization with a polyhedral epigraph. Yang et al. [22]
has also considered such non-smooth problems  but they only have O(1/) iteration complexity.
When F (x) is essentially locally strongly convex [9]

in terms of (cid:107) · (cid:107) such that 5

dist2(x  Ω∗) ≤ 2
σ

(F (x) − F∗) ∀x ∈ S

(12)

i=1 |a(cid:62)

p =(cid:80)n

then we can see that the local error bound holds with θ = 1/2  which implies the iteration complexity
of HOPS is ˜O( 1√
 )  which is up to a logarithmic factor the same as the result in [6] for a strongly
convex function. However  here only local strong convexity is sufﬁcient and there is no need to
develop a different algorithm and different analysis from the non-strongly convex case as done
i x − yi|p  p ∈ (1  2)  which
in [6]. For example  one can consider F (x) = (cid:107)Ax − y(cid:107)p
satisﬁes (12) according to [21].
The Kurdyka-Łojasiewicz (KL) property. The deﬁnition of KL property is given below.
Deﬁnition 6. The function F (x) is said to have the KL property at x∗ ∈ Ω∗ if there exist η ∈ (0 ∞] 
a neighborhood U of x∗ and a continuous concave function ϕ : [0  η) → R+ such that i) ϕ(0) = 0 
ϕ is continuous on (0  η)  ii) for all s ∈ (0  η)  ϕ(cid:48)(s) > 0  iii) and for all x ∈ U ∪ {x : F (x∗) <
F (x) < F (x∗) + η}  the KL inequality ϕ(cid:48)(F (x) − F (x∗))(cid:107)∂F (x)(cid:107) ≥ 1 holds.
The function ϕ is called the desingularizing function of F at x∗  which makes the function F (x)
sharp by reparameterization. An important desingularizing function is in the form of ϕ(s) = cs1−β
for some c > 0 and β ∈ [0  1)  which gives the KL inequality (cid:107)∂F (x)(cid:107) ≥ 1
c(1−β) (F (x) − F (x∗))β.
It has been established that the KL property is satisﬁed by a wide class of non-smooth functions
deﬁnable in an o-minimal structure [4]. Semialgebraic functions and (globally) subanalytic functions
are for instance deﬁnable in their respective classes. While the deﬁnition of KL property involves
a neighborhood U and a constant η  in practice many convex functions satisfy the above property
with U = Rd and η = ∞ [1]. The proposition below shows that a function with the KL property
with a desingularizing function ϕ(s) = cs1−β obeys the local error bound condition in (10) with
θ = 1 − β ∈ (0  1]  which implies an iteration complexity of ˜O(1/θ) of HOPS for optimizing such
a function.
Proposition 1. (Theorem 5 [10]) Let F (x) be a proper  convex and lower-semicontinuous function
that satisﬁes KL property at x∗ and U be a neighborhood of x∗. For all x ∈ U ∩ {x : F (x∗) <
F (x) < F (x∗) + η}  if (cid:107)∂F (x)(cid:107) ≥ 1
c(1−β) (F (x)− F (x∗))β  then dist(x  Ω∗) ≤ c(F (x)− F∗)1−β.

4.4 Primal-Dual Homotopy Smoothing (PD-HOPS)
Finally  we note that the required number of iterations per-stage t for ﬁnding an  accurate solution
depends on an unknown constant c and sometimes θ. Thus  an inappropriate setting of t may lead
to a less accurate solution. In practice  it can be tuned to obtain the fastest convergence. A way to
eschew the tuning is to consider a primal-dual homotopy smoothing (PD-HOPS). Basically  we also
apply the homotopy smoothing to the dual problem:

Φ(u) (cid:44) −φ(u) + min
x∈Ω1

max
u∈Ω2

(cid:104)A(cid:62)u  x(cid:105) + g(x)

Denote by Φ∗ the optimal value of the above problem. Under some mild conditions  it is easy to
see that Φ∗ = F∗. By extending the analysis and result to the dual problem  we can obtain that
F (xs) − F∗ ≤  + s and Φ∗ − Φ(us) ≤  + s after the s-th stage with a sufﬁcient number of
iterations per-stage. As a result  we get F (xs) − Φ(us) ≤ 2( + s). Therefore  we can use the
duality gap F (xs) − Φ(us) as a certiﬁcate to monitor the progress of optimization. As long as
the above inequality holds  we restart the next stage. Then with at most m = (cid:100)logb(0/)(cid:101) epochs

5This is true if g(x) is strongly convex or locally strongly convex.

7

Table 1: Comparison of different optimization algorithms by the number of iterations and running
time in second (mean ± standard deviation) for achieving a solution that satisﬁes F (x) − F∗ ≤ .

 = 10−4
9861 (1.58±0.02)
4918 (2.44±0.22)
3277 (1.33±0.01)
1012 (0.44±0.02)
1009 (0.46±0.02)
846 (0.36±0.01)

Linear Classiﬁcation
 = 10−5
27215 (4.33±0.06)
28600 (11.19±0.26)
19444 (7.69±0.07)
4101 (1.67±0.01)
4102 (1.69±0.04)
3370 (1.27±0.02)

Image Denoising

 = 10−3
8078 (22.01±0.51)
179204 (924.37±59.67)
14150 (40.90±2.28)
3542 (13.77±0.13)
2206 (6.99±0.15)
2538 (7.97±0.13)

 = 10−4
34292 (94.26±2.67)
1726043 (9032.69±539.01)
91380 (272.45±14.56)
4501 (17.38±0.10)
3905 (16.52±0.08)
3605 (11.39±0.10)

Matrix Decomposition
 = 10−4
3441 (5.65±0.20)
8622 (30.36±0.11)
4151 (9.16±0.10)
313 (1.51±0.03)
312 (1.23±0.01)
162 (0.64±0.01)

 = 10−3
2523 (4.02±0.10)
1967 (6.85±0.08)
1115 (3.76±0.06)
224 (1.36±0.02)
230 (0.91±0.01)
124 (0.45±0.01)

PD

APG-D
APG-F

HOPS-D
HOPS-F

PD-HOPS

we get F (xm) − Φ(um) ≤ 2( + m) ≤ 4. Similarly  we can show that PD-HOPS enjoys an
˜O(max{1/1−θ  1/1−˜θ}) iteration complexity  where ˜θ is the exponent constant in the local error
bound of the objective function for dual problem. For example  for linear classiﬁcation problems
with a piecewise linear loss and (cid:96)1 norm regularizer we can have θ = 1 and ˜θ = 1  and PD-HOPS
enjoys a linear convergence. Due to the limitation of space  we defer the details of PD-HOPS and its
analysis into the supplement.

5 Experimental Results
In this section  we present some experimental results to demonstrate the effectiveness of HOPS
and PD-HOPS by comparing with two state-of-the-art algorithms  the ﬁrst-order Primal-Dual (PD)
method [6] and the Nesterov’s smoothing with Accelerated Proximal Gradient (APG) methods. For
APG  we implement two variants  where APG-D refers to the variant with the dual averaging style of
update on one sequence of points (i.e.  Algorithm 1) and APG-F refers to the variant of the FISTA
style [2]. Similarly  we also implement the two variants for HOPS. We conduct experiments for
solving three problems: (1) an (cid:96)1-norm regularized hinge loss for linear classiﬁcation on the w1a
dataset 6; (2) a total variation based ROF model for image denoising on the Cameraman picture 7; (3)
a nuclear norm regularized absolute error minimization for low-rank and sparse matrix decomposition
on a synthetic data. More details about the formulations and experimental setup can be found in the
supplement.
To make fair comparison  we stop each algorithm when the optimality gap is less than a given  and
count the number of iterations and the running time that each algorithm requires. The optimal value
is obtained by running PD with a sufﬁciently large number of iterations such that the duality gap is
very small. We present the comparison of different algorithms on different tasks in Table 1  where
for PD-HOPS we only report the results of using the faster variant of APG  i.e.  APG-F. We repeat
each algorithm 10 times for solving a particular problem and then report the averaged running time
in second and the corresponding standard deviations. The running time of PD-HOPS only accounts
the time for updating the primal variable since the updates for the dual variable are fully decoupled
from the primal updates and can be carried out in parallel. From the results  we can see that (i) HOPS
converges consistently faster than their APG variants especially when  is small; (ii) PD-HOPS allows
for choosing the number of iterations at each epoch automatically  yielding faster convergence speed
than HOPS with manual tuning; (iii) both HOPS and PD-HOPS are signiﬁcantly faster than PD.

6 Conclusions
In this paper  we have developed a homotopy smoothing (HOPS) algorithm for solving a family of
structured non-smooth optimization problems with formal guarantee on the iteration complexities. We
show that the proposed HOPS can achieve a lower iteration complexity of ˜O(1/1−θ) with θ ∈ (0  1]
for obtaining an -optimal solution under a mild local error bound condition. The experimental results
on three different tasks demonstrate the effectiveness of HOPS.

Acknowlegements
We thank the anonymous reviewers for their helpful comments. Y. Xu and T. Yang are partially
supported by National Science Foundation (IIS-1463988  IIS-1545995).

6https://www.csie.ntu.edu.tw/∼cjlin/libsvmtools/datasets/
7http://pages.cs.wisc.edu/∼swright/TVdenoising/

8

References
[1] H. Attouch  J. Bolte  P. Redont  and A. Soubeyran. Proximal alternating minimization and projection
methods for nonconvex problems: An approach based on the kurdyka-lojasiewicz inequality. Math. Oper.
Res.  35:438–457  2010.

[2] A. Beck and M. Teboulle. A fast iterative shrinkage-thresholding algorithm for linear inverse problems.

SIAM J. Img. Sci.  2:183–202  2009.

[3] S. Becker  J. Bobin  and E. J. Candès. Nesta: A fast and accurate ﬁrst-order method for sparse recovery.

SIAM J. Img. Sci.  4:1–39  2011.

[4] J. Bolte  A. Daniilidis  and A. Lewis. The łojasiewicz inequality for nonsmooth subanalytic functions with

applications to subgradient dynamical systems. SIAM J. Optim.  17:1205–1223  2006.

[5] J. V. Burke and P. Tseng. A uniﬁed analysis of hoffman’s bound via fenchel duality. SIAM J. Optim. 

6(2):265–282  1996.

[6] A. Chambolle and T. Pock. A ﬁrst-order primal-dual algorithm for convex problems with applications to

imaging. J. Math. Img. Vis.  40:120–145  2011.

[7] X. Chen  Q. Lin  S. Kim  J. G. Carbonell  and E. P. Xing. Smoothing proximal gradient method for general

structured sparse regression. Ann. Appl. Stat.  6(2):719–752  06 2012.

[8] A. Gilpin  J. Peña  and T. Sandholm. First-order algorithm with log(1/epsilon) convergence for epsilon-

equilibrium in two-person zero-sum games. Math. Program.  133(1-2):279–298  2012.

[9] R. Goebel and R. T. Rockafellar. Local strong convexity and local lipschitz continuity of the gradient of

convex functions. J. Convex Anal.  15(2):263–270  2008.

[10] J. P. B. S. Jerome Bolte  Trong Phong Nguyen. From error bounds to the complexity of ﬁrst-order descent

methods for convex functions. CoRR  abs/1510.08234  2015.

[11] G. Lan  Z. Lu  and R. D. C. Monteiro. Primal-dual ﬁrst-order methods with O(1/e) iteration-complexity for

cone programming. Math. Program.  126(1):1–29  2011.

[12] S. Łojasiewicz. Ensembles semi-analytiques. Institut des Hautes Etudes Scientiﬁques  1965.

[13] Z.-Q. Luo and P. Tseng. Error bounds and convergence analysis of feasible descent methods: a general

approach. Ann. Oper. Res.  46(1):157–178  1993.

[14] I. Necoara  Y. Nesterov  and F. Glineur. Linear convergence of ﬁrst order methods for non-strongly convex

optimization. CoRR  abs/1504.06298  2015.

[15] A. Nemirovski. Prox-method with rate of convergence o(1/t) for variational inequalities with lipschitz
continuous monotone operators and smooth convex-concave saddle point problems. SIAM J. Optim. 
15(1):229–251  Jan. 2005.

[16] Y. Nesterov. Smooth minimization of non-smooth functions. Math. Program.  103(1):127–152  2005.
[17] J. Pang. Error bounds in mathematical programming. Math. Program.  79:299–332  1997.
[18] R. Rockafellar. Convex Analysis. Princeton mathematical series. Princeton University Press  1970.
[19] P. Tseng. On accelerated proximal gradient methods for convex-concave optimization. submitted to SIAM

J. Optim.  2008.

[20] L. Xiao and T. Zhang. A proximal-gradient homotopy method for the sparse least-squares problem. SIAM

J. Optim.  23(2):1062–1091  2013.

[21] T. Yang and Q. Lin. Rsg: Beating subgradient method without smoothness and strong convexity. CoRR 

abs/1512.03107  2016.

[22] T. Yang  M. Mahdavi  R. Jin  and S. Zhu. An efﬁcient primal-dual prox method for non-smooth optimization.

Machine Learning  2014.

[23] H. Zhang. New analysis of linear convergence of gradient-type methods via unifying error bound conditions.

arXiv:1606.00269  2016.

[24] X. Zhang  A. Saha  and S. Vishwanathan. Smoothing multivariate performance measures. JMLR 

13(Dec):3623–3680  2012.

[25] Z. Zhou and A. M.-C. So. A uniﬁed approach to error bounds for structured convex optimization problems.

CoRR  abs/1512.03518  2015.

9

,Yi Xu
Yan Yan
Qihang Lin
Tianbao Yang
Vincent Sitzmann
Michael Zollhoefer
Gordon Wetzstein