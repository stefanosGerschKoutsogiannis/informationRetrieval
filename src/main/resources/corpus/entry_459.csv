2011,Advice Refinement in Knowledge-Based SVMs,Knowledge-based support vector machines (KBSVMs) incorporate advice from domain experts  which can improve generalization significantly. A major limitation that has not been fully addressed occurs when the expert advice is imperfect  which can lead to poorer models. We propose a model that extends KBSVMs and is able to not only learn from data and advice  but also simultaneously improve the advice. The proposed approach is particularly effective for knowledge discovery in domains with few labeled examples. The proposed model contains bilinear constraints  and is solved using two iterative approaches: successive linear programming and a constrained concave-convex approach. Experimental results demonstrate that these algorithms yield useful refinements to expert advice  as well as improve the performance of the learning algorithm overall.,Advice Reﬁnement in Knowledge-Based SVMs

Gautam Kunapuli

Richard Maclin

Univ. of Wisconsin-Madison

Univ. of Minnesota  Duluth

1300 University Avenue

Madison  WI 53705

1114 Kirby Drive
Duluth  MN 55812

Jude W. Shavlik

Univ. of Wisconsin-Madison

1300 University Avenue

Madison  WI 53705

kunapuli@wisc.edu

rmaclin@d.umn.edu

shavlik@cs.wisc.edu

Abstract

Knowledge-based support vector machines (KBSVMs) incorporate advice from
domain experts  which can improve generalization signiﬁcantly. A major limita-
tion that has not been fully addressed occurs when the expert advice is imperfect 
which can lead to poorer models. We propose a model that extends KBSVMs
and is able to not only learn from data and advice  but also simultaneously im-
proves the advice. The proposed approach is particularly effective for knowledge
discovery in domains with few labeled examples. The proposed model contains
bilinear constraints  and is solved using two iterative approaches: successive linear
programming and a constrained concave-convex approach. Experimental results
demonstrate that these algorithms yield useful reﬁnements to expert advice  as
well as improve the performance of the learning algorithm overall.

1 Introduction
We are primarily interested in learning in domains where there is only a small amount of labeled data
but advice can be provided by a domain expert. The goal is to reﬁne this advice  which is usually
only approximately correct  during learning  in such scenarios  to produce interpretable models that
generalize better and aid knowledge discovery. For learning in complex environments  a number
of researchers have shown that incorporating prior knowledge from experts can greatly improve the
generalization of the model learned  often with many fewer labeled examples. Such approaches
have been shown in rule-learning methods [16]  artiﬁcial neural networks (ANNs) [21] and support
vector machines (SVMs) [10  17]. One limitation of these methods concerns how well they adapt
when the knowledge provided by the expert is inexact or partially correct. Many of the rule-learning
methods focus on rule reﬁnement to learn better rules  while ANNs form the rules as portions of
the network which are reﬁned by backpropagation. Further  ANN methods have been paired with
rule-extraction methods [3  20] to try to understand the resulting learned network and provide rules
that are easily interpreted by domain experts.

We consider the framework of knowledge-based support vector machines (KBSVMs)  in-
troduced by Fung et al.
[6]. KBSVMs have been extensively studied  and in addition to linear
classiﬁcation  they have been extended to incorporate kernels [5]  nonlinear advice [14] and for ker-
nel approximation [13]. Recently  Kunapuli et al. derived an online version of KBSVMs [9]  while
other approaches such as that of Le et al. [11] modify the hypothesis space rather than the optimiza-
tion problem. Extensive empirical results from this prior work establish that expert advice can be
effective  especially for biomedical applications such as breast-cancer diagnosis. KBSVMs are an
attractive methodology for knowledge discovery as they can produce good models that generalize
well with a small amount of labeled data.

Advice tends to be rule-of-thumb and is based on the expert’s accumulated experience in
the domain; it may not always be accurate. Rather than simply ignoring or heavily penalizing in-
accurate rules  the effectiveness of the advice can be improved through reﬁnement. There are two
main reasons for this: ﬁrst  reﬁned rules result in the improvement of the overall generalization 
and second  if the reﬁnements to the advice are interpretable by the domain experts  it will help in
the understanding of the phenomena underlying the applications for the experts  and consequently

1

Figure 1: (left) Standard SVM  trades off complexity and loss wrt the data; (center) Knowledge-based SVM 
also trades off loss wrt advice. A piece of advice set 1 extends over the margin  and is penalized as the advice
error. No part of advice set 2 touches the margin  i.e.  none of the rules in advice set 2 are useful as support
constraints. (right) SVM that reﬁnes advice in two ways: (1) advice set 1 is reﬁned so that no part of is on the
wrong side of the optimal hyperplane  minimizing advice error  (2) advice set 2 is expanded until it touches the
optimal margin thus maximizing coverage of input space.

greatly facilitate the knowledge-discovery process. This is the motivation behind this work. KB-
SVMs already have several desirable properties that make them an ideal target for reﬁnement. First 
advice is speciﬁed as polyhedral regions in input space  whose constraints on the features are easily
interpretable by non-experts. Second  it is well-known that KBSVMs can learn to generalize well
with small data sets [9]  and can even learn from advice alone [6]. Finally  owing to the simplicity of
the formulation  advice-reﬁnement terms for the rules can be incorporated directly into the model.
We further motivate advice reﬁnement in KBSVMs with the following example. Figure 1
(left) shows an SVM  which trades off regularization with the data error. Figure 1 (center) illustrates
KBSVMs in their standard form as shown in [6]. As mentioned before  expert rules are speciﬁed
in the KBSVM framework as polyhedral advice regions in input space. They introduce a bias to
focus the learner on a model that also includes the advice of the form ∀x  (x ∈ advice region i) ⇒
class(x) = 1. Advice regarding the regions for which class(x) = −1 can be speciﬁed similarly.

In the KBSVM (Figure 1  center)  each advice region contributes to the ﬁnal hypothesis in
a KBSVM via its advice vector  u1 and u2 (as introduced in [6]; also see Section 2). The individual
j components. As a piece of advice
constraints that touch or intersect the margin have non-zero ui
region 1 extends beyond the margin  u1 6= 0; furthermore  analogous to data error  this overlap is
penalized as the advice error. As no part of advice set 2 touches the margin  u2 = 0 and none of
its rules contribute anything to the ﬁnal classiﬁer. Again  analogous to support vectors  rules with
non-zero ui
j components are called support constraints [6]. Consequently  in the ﬁnal classiﬁer the
advice sets are incorporated with advice error (advice set 1) or are completely ignored (advice set
2). Even though the rules are inaccurate  they are able to improve generalization compared to the
SVM. However  simply penalizing advice that introduces errors can make learning difﬁcult as the
user must carefully trade off between optimizing data or advice loss.

Now  consider an SVM that is capable of reﬁning inaccurate advice (Figure 1  right). When
advice is inaccurate and intersects the hyperplane  it is truncated such that it minimizes the advice
error. Advice that was originally ignored is extended to cover as much of the input space as is
feasible. The optimal classiﬁer has now minimized the error with respect to the data and the reﬁned
advice and is able to further improve upon the performance of not just the SVM but also the KBSVM.
Thus  the goal is to reﬁne potentially inaccurate expert advice during learning so as to learn a model
with the best generalization.

Our approach generalizes the work of Maclin et al. [12]  to produce a model that corrects
the polyhedral advice regions of KBSVMs. The resulting mathematical program is no longer a
linear or quadratic program owing to bilinear correction factors in the constraints. We propose
two algorithmic techniques to solve the resulting bilinear program  one based on successive linear
programming [12]  and the other based on a concave-convex procedure [24]. Before we describe
advice reﬁnement  we brieﬂy introduce our notation and KBSVMs.

We wish to learn a linear classiﬁer (w′x = b) given ℓ labeled data (xj  yj)ℓ

j=1 with xj ∈ Rn
and labels yj ∈ {±1}. Data are collected row-wise in the matrix X ∈ Rℓ×n  while Y = diag(y) is
the diagonal matrix of the labels. We assume that m advice sets (Di  di  zi)m
i=1 are given in addition
to the data (see Section 2)  and if the i-th advice set has ki constraints  we have Di ∈ Rki×n 
di ∈ Rki and zi = {±1}. The absolute value of a scalar y is denoted |y|  the 1-norm of a vector x

2

i=1 Pq

i=1 |Aij|. Finally  e is a vector of ones of appropriate dimension.

i=1 |xi|  and the entrywise 1-norm of a m × n matrix A ∈ Rp×q is denoted

is denoted kxk1 = Pn
kAk1 = Pp
2 Knowledge-Based Support Vector Machines
In KBSVMs  advice can be speciﬁed about every potential data point in the input space that satisﬁes
certain advice constraints. For example  consider a task of learning to diagnose diabetes  based on
features such as age  blood pressure  body mass index (bmi)  plasma glucose concentration (gluc) 
etc. The National Institute for Health (NIH) provides the following guidelines to establish risk for
Type-2 Diabetes1: a person who is obese (bmi ≥ 30) with gluc ≥ 126 is at strong risk for diabetes 
while a person who is at normal weight (bmi ≤ 25) with gluc ≤ 100 is unlikely to have diabetes.
This leads to two advice sets  one for each class:
(bmi ≤ 25) ∧ (gluc ≤ 100) ⇒ ¬diabetes;

(bmi ≥ 30) ∧ (gluc ≥ 126) ⇒ diabetes 

(1)
where ¬ is the negation operator. In general  rules such as the ones above deﬁne a polyhedral region
of the input space and are expressed as the implication

Dix ≤ di ⇒ zi(w′x − b) ≥ 1 

(2)
where the advice label zi = +1 indicates that all points x that satisfy the constraints for the i-th
advice set  Dix ≤ di belong to class +1  while z = −1 indicates the same for the other class. The
standard linear SVM formulation (without incorporating advice) for binary classiﬁcation optimizes
model complexity + λ data loss:

min

ξ≥0 w b

kwk1 + λe′ξ 

s.t. Y (Xw − eb) + ξ ≥ e.

(3)

The implications (2)  for the i = 1  . . .   m  can be incorporated into (3) using the nonhomogeneous
Farkas theorem of the alternative [6] that introduces advice vectors ui. The advice vectors perform
the same role as the dual multipliers α in the classical SVM. Recall that points with non-zero α’s
are the support vectors which additively contribute to w. Similarly  the constraints of an advice set
which have non-zero uis are called support constraints. The resulting formulation is the KBSVM 
which optimizes model complexity + λ data loss + µ advice loss:
kwk1 + λe′ξ + µ Pm

i=1 (e′ηi + ζi)

w b (ξ ui ηi ζi)≥0

min

(4)

s.t.

Y (Xw − be) + ξ ≥ e 
−ηi ≤ D′
−di′

iui + ziw ≤ ηi 

ui − zib + ζi ≥ 1  i = 1  . . .   m.

In the case of inaccurate advice  the advice errors ηi and ζi soften the advice constraints analogous
to the data errors ξ. Returning to Figure 1  for advice set 1  η1  ζ1 and u1 are non-zero  while for
advice set 2  u2 = 0. The inﬂuence of data and advice is determined by the choice of the parameters
λ and µ which reﬂect the user’s trust in the data and advice respectively.

3 Advice-Reﬁning Knowledge-based Support Vector Machines
Previously  Maclin et al. [12] formulated a model to reﬁne advice in KBSVMs. However  their
model is limited as only the terms di are reﬁned  which as we discuss below  greatly restricts the
types of reﬁnements that are possible. They only consider reﬁnement terms f i for the right hand
side of the i-th advice set  and attempt to reﬁne each rule such that

Dix ≤ (di − f i) ⇒ zi(w′x − b) ≥ 1  i = 1  . . .   m.

(5)
The resulting formulation adds reﬁnement terms into the KBSVM model (4) in the advice con-
straints  as well as in the objective. The latter allows for the overall extent of the reﬁnement to be
controlled by the reﬁnement parameter ν > 0. This formulation was called Reﬁning-Rules Support
Vector Machine (RRSVM):

w b f i (ξ ui ηi ζi)≥0

min

s.t.

kwk1 + λe′ξ + µ Pm

i=1 (e′ηi + ζi) + ν Pm

Y (Xw − be) + ξ ≥ e 
−ηi ≤ D′
−(di − f i)′ui − zib + ζi ≥ 1  i = 1  . . .   m.

iui + ziw ≤ ηi 

i=1 kf ik1

(6)

1http://diabetes.niddk.nih.gov/DM/pubs/∼riskfortype2

3

This problem is no longer an LP owing to the bilinear terms f i′
ui which make the reﬁnement con-
straints non-convex. Maclin et al. solve this problem using successive linear programming (SLP)
wherein linear programs arising from alternately ﬁxing either the advice terms di or the reﬁnement
terms f i are solved iteratively.

We consider a full generalization of the RRSVM approach and develop a model where it is
possible to reﬁne the entire advice region Dx ≤ d. This allows for much more ﬂexibility in reﬁning
the advice based on the data  while still retaining interpretability of the resulting reﬁned advice.
In addition to the terms f i  we propose the introduction of additional reﬁnement terms Fi into the
model  so that we can reﬁne the rules in as general a manner as possible:

(Di − Fi)x ≤ (di − f i) ⇒ zi(w′x − b) ≥ 1  i = 1  . . .   m.

(7)
Recall that for each advice set we have Di ∈ Rki×n and di ∈ Rki  i.e.  the i-th advice set contains
ki constraints. The corresponding reﬁnement terms Fi and f i will have the same dimensions respec-
tively as Di and di. The formulation (6) now includes the additional reﬁnement terms Fi  and the
formulation optimizes:

w b Fi f i (ξ ui ηi ζi)≥0

min

s.t.

i=1 (e′ηi + ζi) + ν Pm

kwk1 + λe′ξ + µ Pm
Y (Xw − be) + ξ ≥ e 
−ηi ≤ (Di − Fi)′ui + ziw ≤ ηi 
−(di − f i)′ui − zib + ζi ≥ 1  i = 1  . . .   m.

i=1 (cid:0)kFik1 + kf ik1(cid:1)

(8)

The objective function of (8) trades-off the effect of reﬁnement in each of the advice sets via the
reﬁnement parameter ν. This is the Advice-Reﬁning KBSVM (arkSVM); it improves upon the work
of Maclin et al. in two important ways. First  reﬁning d alone is highly restrictive as it allows only
for the translation of the boundaries of the polyhedral advice; the generalized reﬁnement offered
by arkSVMs allows for much more ﬂexibility owing to the fact that the boundaries of the advice
can be translated and rotated (see Figure 2). Second  the newly added reﬁnement terms  F ′
i ui  are
bilinear also  and do not make the overall problem more complex; in addition to the successive
linear programming approach of [12]  we also propose a concave-convex procedure that leads to an
approach based on successive quadratic programming. We provide details of both approaches next.

3.1 arkSVMs via Successive Linear Programming
One approach to solving bilinear programming problems is to solve a sequence of linear programs
while alternately ﬁxing the bilinear variables. This approach is called successive linear program-
ming  and has been used to solve various machine learning formulations  for instance [1  2]. In this
approach  which was also adopted by [12]  we solve the LPs arising from alternatingly ﬁxing the
sources of bilinearity: (Fi  f i)m
i=1. Algorithm 1 describes the above approach. At the
t-th iteration  the algorithm alternates between the following steps:

i=1 and {ui}m

• (Estimation Step) When the reﬁnement terms  ( ˆF t

i=1  are ﬁxed the resulting LP
becomes a standard KBSVM which attempts to ﬁnd a data-estimate of the advice vectors
{ui}m

i=1 using the current reﬁnement of the advice region: (Dj − ˆF t

j ) x ≤ (dj − ˆf j t).

i   ˆf i t)m

• (Reﬁnement Step) When the advice-estimate terms {ˆui t}m

i=1 are ﬁxed  the resulting LP
i=1 and attempts to further reﬁne the advice regions based on estimates

solves for (Fi  f i)m
from data computed in the previous step.

Proposition 1 I. For ǫ = 0 
the sequence of objective values converges to the value
i=1 (cid:0)k ¯Fik1 + k¯f ik1(cid:1)  where the data and advice
k ¯wk1 + λe′ ¯ξ + µ Pm
errors ( ¯ξ  ¯ηi  ¯ζi) are computed from any accumulation point ( ¯w  ¯b  ¯ui  ¯Fi  ¯f i) of the sequence of
iterates ( ˆwt  ˆbt  ˆui t  ˆF t

i=1 (e′ ¯ηi + ¯ζi) + ν Pm
i   ˆf i t)∞

t=1 generated by Algorithm 1.

II. Such an accumulation point satisﬁes the local minimum condition

( ¯w  ¯b) ∈

kwk1 + λe′ξ + µ Pm
min
ui≥0
subject to Y (Xw − be) + ξ ≥ e 

w b (ξ ηiζi≥0)

i=1 (e′ηi + ζi)

−ηi ≤ (Di − ¯Fi)′ui + ziw ≤ ηi 
−(di − ¯f i)′ui − zib + ζi ≥ 1 

i = 1  . . .   m.

4

Algorithm 1 arkSVM via Successive Linear Programming (arkSVM-sla)
1: initialize: t = 1  ˆF 1
2: while feasible do
3:
4:

if x not feasible for (Di − ˆF t
(estimation step) solve for {ˆui t+1}m

i ) x ≤ (dj − ˆf i t)

i = 0  ˆf i 1 = 0

return failure

i=1

w b (ξ ui  η i  ζi)≥0

min

s.t.

i=1 (e′ηi + ζi)

kwk1 + λe′ξ + µ Pm
Y (Xw − be) + ξ ≥ e 
−ηi ≤ (Di − ˆF t
−(di − ˆf i t)′ui − zib + ζi ≥ 1  i = 1  . . .   m.

i )′ui + ziw ≤ ηi 

5:

(reﬁnement step) solve for ( ˆF t+1

i

  ˆf i t+1)m
i=1

w b Fi f i  (ξ η i  ζi)≥0

min

s.t.

i=1 (e′ηi + ζi) + ν Pm

kwk1 + λe′ξ + µ Pm
Y (Xw − be) + ξ ≥ e 
−ηi ≤ (Di − Fi)′ ˆui t+1 + ziw ≤ ηi 
−(di − f i)′ ˆui t+1 − zib + ζi ≥ 1  i = 1  . . .   m.

i=1 (cid:0)kFik1 + kf ik1(cid:1)

(termination test) if Pj (cid:0)kF t
(continue) t = t + 1

6:
7:
8: end while

j − F t+1

j

k + kf t

j − f t+1

j

k(cid:1) ≤ ǫ

then return solution

Algorithm 2 arkSVM via Successive Quadratic Programming (arkSVM-sqp)
1: initialize: t = 1  ˆF 1
2: while feasible do
3:
4:

if x not feasible for (Di − ˆF t
solve for {ˆui t+1}m

i ) x ≤ (dj − ˆf i t)

i = 0  ˆf i 1 = 0

return failure

i=1

min

Fi  f i  (ui ≥0)

w b (ξ η i ζi ≥0)

s.t.

i=1 (e′ηi + ζi) + ν Pm

kwk1 + λe′ξ + µ Pm
Y (Xw − be) + ξ ≥ e 
eqns (10–12)  i = 1  . . .   m  j = 1  . . .   n

i=1 (cid:0)kFik1 + kf ik1(cid:1)

(termination test) if Pj (cid:0)kF t
(continue) t = t + 1

5:
6:
7: end while

j − F t+1

j

k + kf t

j − f t+1

j

k(cid:1) ≤ ǫ

then return solution

D′

ij ui + ziwj − ηi

j +

kFij − uik2 ≤

kFij + uik2 

(9)

1
4

1
4

3.2 arkSVMs via Successive Quadratic Programming
In addition to the above approach  we introduce another algorithm (Algorithm 2) that is based on
successive quadratic programming. In the constraint (Di − Fi)′ui + ziw − ηi ≤ 0  only the re-
i ui is bilinear  while the rest of the constraint is linear. Denote the j-th components
ﬁnement term F ′
j respectively. A general bilinear term r′s  which is non-convex  can be
of w and ηi to be wj and ηi
written as the difference of two convex terms: 1
4 kr − sk2. Thus  we have the equivalent
constraint

4 kr + sk2 − 1

and both sides of the constraint above are convex and quadratic. We can linearize the right-hand side
of (9) around some current estimate of the bilinear variables ( ˆF t

ij   ˆui t):

D′

ij ui + ziwj − ηi

j + 1

4 kFij − uik2 ≤ 1
+ 1

4 k ˆF t
2 ( ˆF t

ij + ˆui tk2
ij + ˆui t)′ (cid:16)(Fij − ˆF t

ij ) + (ui − ˆui t)(cid:17) .

Similarly  the constraint −(Di − Fi)′ui − ziw − ηi ≤ 0  can be replaced by

−D′

ij ui − ziwj − ηi

j + 1

4 k ˆF t
4 kFij + uik2 ≤ 1
2 ( ˆF t
+ 1

ij − ˆui tk2
ij − ˆui t)′ (cid:16)(Fij − ˆF t

ij ) − (ui − ˆui t)(cid:17)  

5

(10)

(11)

Figure 2: Toy data set (Section 4.1) using (left) RRSVM (center) arkSVM-sla (right) arkSVM-sqp. Orange
and green unhatched regions show the original advice. The dashed lines show the margin  kwk∞. For each
method  we show the reﬁned advice: vertically hatched for Class +1  and diagonally hatched for Class −1.
while di′

ui ≤ 0 is replaced by

ui + zib + 1 − ζi − f i′
di′

ui + zib + 1 − ζi + 1

4 kf i − uik2 ≤ 1
+ 1

4 kˆf i t + ˆui tk2
2 (ˆf i t + ˆui t)′ (cid:16)(f i t − ˆf i t) + (ui − ˆui t)(cid:17) .

(12)

The right-hand sides in (10–12) are afﬁne and hence  the entire set of constraints are now convex.
Replacing the original bilinear non-convex constraints of (8) with the convexiﬁed relaxations results
in a quadratically-constrained linear program (QCLP). These quadratic constraints are more restric-
tive than their non-convex counterparts  which leads the feasible set of this problem to be a subset of
that of the original problem. Now  we can iteratively solve the resulting QCLP. At the t-th iteration 
the restricted problem uses the current estimate to construct a new feasible point and iterating this
procedure produces a sequence of feasible points with decreasing objective values. The approach
described here is essentially the constrained concave-convex procedure (CCCP) that has been dis-
covered and rediscovered several times. Most recently  the approach was described in the context
of machine learning approaches by Yuille and Rangarajan [24]  and Smola and Vishwanathan [19] 
who also derived conditions under which the algorithm converges to a local solution. The following
convergence theorem is due to [19].
Proposition 2 For Algorithm 2  the sequence of objective values converges to the value k ¯wk1 +
i=1 (cid:0)k ¯Fik1 + k¯f ik1(cid:1)  where ( ¯w  ¯b  ¯ui  ¯Fi  ¯f i  ¯ξ  ¯ηi  ¯ζi) is the
λe′ ¯ξ + µ Pm
local minimum solution of (8) provided that the constraints (10–12) in conjunction with the convex
constraints Y (Xw − eb) + ξ ≥ e  ξ ≥ 0  ui ≥ 0  ζi ≥ 0 satisfy suitable constraint qualiﬁcations
at the point of convergence of the algorithm.

i=1 (e′ ¯ηi + ¯ζi) + ν Pm

Both Algorithms 1 and 2 produce local minima solutions to the arkSVM formulation (8).
For either solution  the following proposition holds  which shows that either algorithm produces
a reﬁnement of the original polyhedral advice regions. The proof is a direct consequence of
[13][Proposition 2.1].
Proposition 3 Let ( ¯w  ¯b  ¯ui  ¯Fi  ¯f i  ¯ξ  ¯ηi  ¯ζi) be the local minimum solution produced by Algorithm
1 or Algorithm 2. Then  the following reﬁnement to the advice sets holds:

(Di − ¯Fi) ≤ (di − ¯f i) ⇒ zi( ¯w′x − ¯b) ≥ − ˆηi ′x − ¯ζi 

where − ¯ηi ≤ ˆηi ≤ ¯ηi such that D′

i ¯ui + ¯w + ˆηi = 0.

4 Experiments
We present the results of several experiments that compare the performance of three algorithms:
RRSVMs (which only reﬁne the d term in Dx ≤ d)  arkSVM-sla (successive linear programming)
and arkSVM-sqp (successive quadratic programming) with that of standard SVMs and KBSVMs.
The LPs were solved using QSOPT2  while the QCLPs were solved using SDPT-3 [22].

4.1 Toy Example
We illustrate the behavior of advice reﬁnement algorithms discussed previously geometrically using
a simple 2-dimensional example (Figure 2). This toy data set consists of 200 points separated by
x1 + x2 = 2. There are two advice sets: {S1 : (x1  x2) ≥ 0 ⇒ z = +1}  {S2 : (x1  x2) ≤ 0 ⇒

2http://www2.isye.gatech.edu/∼wcook/qsopt/

6

)

%

(
 
r
o
r
r

 

E
g
n

i
t
s
e
T

40

35

30

25

20

15

10

5

0
 
0

10

20

 

svm
kbsvm
rrsvm
arksvm−sla
arksvm−sqp

30

40

50

Number of Training Examples

60

70

80

90 100

Figure 3: Diabetes data set  Section 4.2; (left) Results averaged over 10 runs on a hold-out test set of 412
points  with parameters selected by ﬁve-fold cross validation; (right) An approximate decision-tree represen-
tation of Diabetes Rule 6 before and after reﬁnement. The left branch is chosen if the query at a node is
true  and the right branch otherwise. The leaf nodes classify the data point according to ?diabetes.

z = −1}. Both arkSVMs are able to reﬁne knowledge sets such that the no part of S1 lies on the
wrong side of the ﬁnal hyperplane. In addition  the reﬁnement terms allow for sufﬁcient modiﬁcation
of the advice sets Dx ≤ d so that they ﬁll the input space as much as possible  without violating
the margin. Comparing to RRSVMs  we see that reﬁnement is restrictive because corrections are
applied only to part of the advice sets  rather than fully correcting the advice.

4.2 Case Study 1: PIMA Indians Diabetes Diagnosis

The Pima Indians Diabetes data set [4] has been studied for several decades and is used as a standard
benchmark to test many machine learning algorithms. The goal is to predict the onset of diabetes in
768 Pima Indian women within the next 5 years based on current indicators (eight features): number
of times pregnant  plasma glucose concentration (gluc)  diastolic blood pressure  triceps skin fold
test  2-hour serum insulin  body mass index (bmi)  diabetes pedigree function (pedf) and age.
Studies [15] show that diabetes incidence among the Pima Indians is signiﬁcantly higher among
subjects with bmi ≥ 30. In addition  a person with impaired glucose tolerance is at a signiﬁcant
risk for  or worse  has undiagnosed diabetes [8]. This leads to the following expert rules:

(Diabetes Rule 1)
(Diabetes Rule 2)
(Diabetes Rule 3)
(Diabetes Rule 4)

(gluc ≤ 126)
⇒¬diabetes 
(gluc ≥ 126) ∧ (gluc ≤ 140) ∧ (bmi ≤ 30) ⇒¬diabetes 
(gluc ≥ 126) ∧ (gluc ≤ 140) ∧ (bmi ≥ 30) ⇒ diabetes 
⇒ diabetes.
(gluc ≥ 140)

The diabetes pedigree function was developed by Smith et al. [18]  and uses genetic information
from family relatives to provide a measure of the expected genetic inﬂuence (heredity) on the sub-
ject’s diabetes risk. The function also takes into account the age of relatives who do have diabetes;
on average  Pima Indians are only 36 years old3 when diagnosed with diabetes. A subject with high
heredity who is at least 31 is at a signiﬁcantly increased risk for diabetes in the next ﬁve years:

(Diabetes Rule 5)
(Diabetes Rule 6)

(pedf ≤ 0.5) ∧ (age ≤ 31) ⇒¬diabetes 
(pedf ≥ 0.5) ∧ (age ≥ 31) ⇒ diabetes.

Figure 3 (left) shows that unreﬁned advice does help initially  especially with as few as 30 data
points. However  as more data points are available  the effect of the advice diminishes. In contrast 
the advice reﬁning methods are able to generalize much better with few data points  and eventually
converge to a better solution. Finally  Figure 3 (right) shows an approximate tree representation of
Diabetes Rule 6 after reﬁnement. This tree was constructed by sampling the space around
reﬁned advice region uniformly  and then training a decision tree that covers as many of the sampled
points as possible. This naive approach to rule extraction from reﬁned advice is shown here only to
illustrate that it is possible to produce very useful domain-expert-interpretable rules from reﬁnement.
More efﬁcient and accurate rule extraction techniques inspired by SVM-based rule extraction (for
example  [7]) are currently under investigation.

7

 

svm
kbsvm
rrsvm
arksvm−sla
arksvm−sqp

)

%

(
 
r
o
r
r

 

E
g
n

i
t
s
e
T

30

25

20

15

10

5

0

 

20

Number of Training Examples

80

100

40

60

Figure 4: Wargus data set  Section 4.3; (left) An example Wargus scenario; (right) Results using 5-fold cross
validation on a hold out test set of 1000 points.

4.3 Case Study 2: Reﬁning GUI-Collected Human Advice in a Wargus Task
Wargus4 is a real-time strategy game in which two or more players gather resources  build bases and
control units in order to conquer opposing players. It has been widely used to study and evaluate
various machine learning and planning algorithms. We evaluate our algorithms on a classiﬁcation
task in the Wargus domain developed by Walker et al. [23] called tower-defense (Figure 4 
left). Advice for this task was collected from humans via a graphical  human-computer interface
(HCI) as detailed in [23]. Each scenario (example) in tower-defense  consists of a single tower
being attacked by a group of enemy units  and the task is to predict whether the tower will survive
the attack and defeat the attackers given the size and composition of the latter  as well as other
factors such as the environment. The data set consists of 80 features including information about
units (eg.  archers  ballista  peasants)  unit properties (e.g.  map location  health)  group properties
(e.g.  #archers  #footmen) and environmental factors (e.g.  ?hasMoat).

Walker et al. [23] used this domain to study the feasibility of learning from human teachers.
To this end  human players were ﬁrst trained to identify whether a tower would fall given a particular
scenario. Once the humans learned this task  they were asked to provide advice via a GUI-based
interface based on speciﬁc examples. This setting lends itself very well to reﬁnement as the advice
collected from human experts represents the sum of their experiences with the domain  but is by no
means perfect or exact. The following are some rules provided by human “domain experts”:

(Wargus Rule 1) (#footmen ≥ 3) ∧ (?hasMoat = 0)
⇒falls 
(Wargus Rule 2) (#archers ≥ 5)
⇒falls 
(Wargus Rule 3) (#ballistas ≥ 1)
⇒falls 
(Wargus Rule 4) (#ballistas = 0) ∧ (#archers = 0) ∧ (?hasMoat = 1) ⇒stands.

Figure 4 (right) shows the performance of the various algorithms on the Wargus data set. As with
the previous case study  the arkSVM methods are able to not only learn very effectively with a small
data set  they are also able to improve signiﬁcantly on the performances of standard knowledge-
based SVMs (KBSVMs) and rule-reﬁning SVMs (RRSVMs).

5 Conclusions and Future Work
We have presented two novel knowledge-discovery methods: arkSVM-sla and arkSVM-sqp  that
allow SVM methods to not only make use of advice provided by human experts but to reﬁne that
advice using labeled data to improve the advice. These methods are an advance over previous
knowledge-based SVM methods which either did not reﬁne advice [6] or could only reﬁne simple
aspects of the advice [12]. Experimental results demonstrate that our arkSVM methods can make
use of inaccurate advice to revise them to better ﬁt the data. A signiﬁcant aspect of these learn-
ing methods is that the system not only produces a classiﬁer but also produces human-inspectable
changes to the user-provided advice  and can do so using small data sets. In terms of future work  we
plan to explore several avenues of research including extending this approach to the nonlinear case
for more complex models  better optimization algorithms for improved efﬁciency  and interpretation
of reﬁned rules for non-AI experts.

3http://diabetes.niddk.nih.gov/dm/pubs/pima/kiddis/kiddis.htm
4http://wargus.sourceforge.net/index.shtml

8

Acknowledgements
The authors gratefully acknowledge support of the Defense Advanced Research Projects Agency under DARPA
grant FA8650-06-C-7606 and the National Institute of Health under NLM grant R01-LM008796. Views and
conclusions contained in this document are those of the authors and do not necessarily represent the ofﬁcial
opinion or policies  either expressed or implied of the US government or of DARPA.

References
[1] K. P. Bennett and E. J. Bredensteiner. A parametric optimization method for machine learning. INFORMS

Journal on Computing  9(3):311–318  1997.

[2] K. P. Bennett and O. L. Mangasarian. Bilinear separation of two sets in n-space. Computational Opti-

mization and Applications  2:207–227  1993.

[3] M. W. Craven and J. W. Shavlik. Extracting tree-structured representations of trained networks.

Advances in Neural Information Processing Systems  volume 8  pages 24–30  1996.

In

[4] A. Frank and A. Asuncion. UCI machine learning repository  2010.
[5] G. Fung  O. L. Mangasarian  and J. W. Shavlik. Knowledge-based nonlinear kernel classiﬁers. In Sixteenth

Annual Conference on Learning Theory  pages 102–113  2003.

[6] G. Fung  O. L. Mangasarian  and J. W. Shavlik. Knowledge-based support vector classiﬁers. In Advances

in Neural Information Processing Systems  volume 15  pages 521–528  2003.

[7] G. Fung  S. Sandilya  and R. B. Rao. Rule extraction from linear support vector machines.

In Proc.
Eleventh ACM SIGKDD Intl. Conference on Knowledge Discovery in Data Mining  pages 32–40  2005.
[8] M. I. Harris  K. M. Flegal  C. C. Cowie  M. S. Eberhardt  D. E. Goldstein  R. R. Little  H. M. Wiedmeyer 
and D. D. Byrd-Holt. Prevalence of diabetes  impaired fasting glucose  and impaired glucose tolerance in
U.S. adults. Diabetes Care  21(4):518–524  1998.

[9] G. Kunapuli  K. P. Bennett  A. Shabbeer  R. Maclin  and J. W. Shavlik. Online knowledge-based support

vector machines. In Proc. of the European Conference on Machine Learning  pages 145–161  2010.

[10] F. Lauer and G. Bloch. Incorporating prior knowledge in support vector machines for classiﬁcation: A

review. Neurocomputing  71(7–9):1578–1594  2008.

[11] Q. V. Le  A. J. Smola  and T. G¨artner. Simpler knowledge-based support vector machines. In Proceedings

of the Twenty-Third International Conference on Machine Learning  pages 521–528  2006.

[12] R. Maclin  E. W. Wild  J. W. Shavlik  L. Torrey  and T. Walker. Reﬁning rules incorporated into
In AAAI Twenty-Second

knowledge-based support vector learners via successive linear programming.
Conference on Artiﬁcial Intelligence  pages 584–589  2007.

[13] O. L. Mangasarian  J. W. Shavlik  and E. W. Wild. Knowledge-based kernel approximation. Journal of

Machine Learning Research  5:1127–1141  2004.

[14] O. L. Mangasarian and E. W. Wild. Nonlinear knowledge-based classiﬁcation. IEEE Transactions on

Neural Networks  19(10):1826–1832  2008.

[15] M. E. Pavkov  R. L. Hanson  W. C. Knowler  P. H. Bennett  J. Krakoff  and R. G. Nelson. Changing

patterns of Type 2 diabetes incidence among Pima Indians. Diabetes Care  30(7):1758–1763  2007.

[16] M. Pazzani and D. Kibler. The utility of knowledge in inductive learning. Mach. Learn.  9:57–94  1992.
[17] B. Sch¨olkopf  P. Simard  A. Smola  and V. Vapnik. Prior knowledge in support vector kernels. In Advances

in Neural Information Processing Systems  volume 10  pages 640–646  1998.

[18] J. W. Smith  J. E. Everhart  W. C. Dickson  W. C. Knowler  and R. S. Johannes. Using the ADAP learning
In Proc. of the Symposium on Comp. Apps. and

algorithm to forecast the onset of diabetes mellitus.
Medical Care  pages 261–265. IEEE Computer Society Press  1988.

[19] A. J. Smola and S. V. N. Vishwanathan. Kernel methods for missing variables. In Proceedings of the

Tenth International Workshop on Artiﬁcial Intelligence and Statistics  pages 325–332  2005.

[20] S. Thrun. Extracting rules from artiﬁcial neural networks with distributed representations. In Advances

in Neural Information Processing Systems  volume 8  1995.

[21] G. G. Towell and J. W. Shavlik. Knowledge-based artiﬁcial neural networks. Artiﬁcial Intelligence 

70(1–2):119–165  1994.

[22] R. H. T¨ut¨unc¨u  K. C. Toh  and M. J. Todd. Solving semideﬁnite-quadratic-linear programs using SDPT3.

Mathematical Programming  95(2)  2003.

[23] T. Walker  G. Kunapuli  N. Larsen  D. Page  and J. W. Shavlik.

Integrating knowledge capture and
supervised learning through a human-computer interface. In Proc. Fifth Intl. Conf. Knowl. Capture  2011.
[24] A. L. Yuille and A. Rangarajan. The concave-convex procedure (CCCP). In Advances in Neural Infor-

mation Processing Systems  volume 13  2001.

9

,Yang Liu
Yiling Chen
Binghui Chen
Weihong Deng
Haifeng Shen