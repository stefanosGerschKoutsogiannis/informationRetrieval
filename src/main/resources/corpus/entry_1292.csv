2019,Data-Dependence of Plateau Phenomenon in Learning with Neural Network --- Statistical Mechanical Analysis,The plateau phenomenon  wherein the loss value stops decreasing during the process of learning  has been reported by various researchers. The phenomenon is actively inspected in the 1990s and found to be due to the fundamental hierarchical structure of neural network models. Then the phenomenon has been thought as inevitable. However  the phenomenon seldom occurs in the context of recent deep learning. There is a gap between theory and reality. In this paper  using statistical mechanical formulation  we clarified the relationship between the plateau phenomenon and the statistical property of the data learned. It is shown that the data whose covariance has small and dispersed eigenvalues tend to make the plateau phenomenon inconspicuous.,Data-Dependence of Plateau Phenomenon in
Learning with Neural Network — Statistical

Mechanical Analysis

Department of Complexity Science and Engineering  Graduate School of Frontier Sciences 

Yuki Yoshida

Masato Okada

The University of Tokyo

5-1-5 Kashiwanoha  Kashiwa  Chiba 277-8561  Japan
{yoshida@mns  okada@edu}.k.u-tokyo.ac.jp

Abstract

The plateau phenomenon  wherein the loss value stops decreasing during the
process of learning  has been reported by various researchers. The phenomenon is
actively inspected in the 1990s and found to be due to the fundamental hierarchical
structure of neural network models. Then the phenomenon has been thought as
inevitable. However  the phenomenon seldom occurs in the context of recent
deep learning. There is a gap between theory and reality. In this paper  using
statistical mechanical formulation  we clariﬁed the relationship between the plateau
phenomenon and the statistical property of the data learned. It is shown that the
data whose covariance has small and dispersed eigenvalues tend to make the plateau
phenomenon inconspicuous.

1

Introduction

1.1 Plateau Phenomenon

Deep learning  and neural network as its essential component  has come to be applied to various
ﬁelds. However  these still remain unclear in various points theoretically. The plateau phenomenon
is one of them. In the learning process of neural networks  their weight parameters are updated
iteratively so that the loss decreases. However  in some settings the loss does not decrease simply  but
its decreasing speed slows down signiﬁcantly partway through learning  and then it speeds up again
after a long period of time. This is called as “plateau phenomenon”. Since 1990s  this phenomena
have been reported to occur in various practical learning situations (see Figure 1 (a) and Park et al.
[2000]  Fukumizu and Amari [2000]) . As a fundamental cause of this phenomenon  it has been
pointed out by a number of researchers that the intrinsic symmetry of neural network models brings
singularity to the metric in the parameter space which then gives rise to special attractors whose
regions of attraction have nonzero measure  called as Milnor attractor (deﬁned by Milnor [1985]; see
also Figure 5 in Fukumizu and Amari [2000] for a schematic diagram of the attractor).

1.2 Who moved the plateau phenomenon?

However  the plateau phenomenon seldom occurs in recent practical use of neural networks (see
Figure 1 (b) for example).
In this research  we rethink the plateau phenomenon  and discuss which situations are likely to cause
the phenomenon. First we introduce the student-teacher model of two-layered networks as an ideal
system. Next  we reduce the learning dynamics of the student-teacher model to a small-dimensional
order parameter system by using statistical mechanical formulation  under the assumption that the

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

input dimension is sufﬁciently large. Through analyzing the order parameter system  we can discuss
how the macroscopic learning dynamics depends on the statistics of input data. Our main contribution
is the following:

• Under the statistical mechanical formulation of learning in the two-layered perceptron  we
showed that macroscopic equations can be derived even when the statistical properties of
the input are generalized. In other words  we extended the result of Saad and Solla [1995]
and Riegler and Biehl [1995].

• By analyzing the macroscopic system we derived  we showed that the dynamics of learning

depends only on the eigenvalue distribution of the covariance matrix of the input data.

• We clariﬁed the relationship between the input data statistics and plateau phenomenon.
In particular  it is shown that the data whose covariance matrix has small and disparsed
eigenvalues tend to make the phenomenon inconspicuous  by numerically analyzing the
macroscopic system.

1.3 Related works

The statistical mechanical approach used in this research is ﬁrstly developed by Saad and Solla
[1995]. The method reduces high-dimensional learning dynamics of nonlinear neural networks to
low-dimensional system of order parameters. They derived the macroscopic behavior of learning
dynamics in two-layered soft-committee machine and by analyzing it they point out the existence
of plateau phenomenon. Nowadays the statistical mechanical method is applied to analyze recent
techniques (Hara et al. [2016]  Yoshida et al. [2017]  Takagi et al. [2019] and Straat and Biehl [2019]) 
and generalization performance in over-parameterized setting (Goldt et al. [2019]) and environment
with conceptual drift (Straat et al. [2018]). However  it is unknown that how the property of input
dataset itself can affect the learning dynamics  including plateaus.
Plateau phenomenon and singularity in loss landscape as its main cause have been studied by
Fukumizu and Amari [2000]  Wei et al. [2008]  Cousseau et al. [2008] and Guo et al. [2018]. On the
other hand  recent several works suggest that plateau and singularity can be mitigated in some settings.
Orhan and Pitkow [2017] shows that skip connections eliminate the singularity. Another work by
Yoshida et al. [2019] points out that output dimensionality affects the plateau phenomenon  in that
multiple output units alleviate the plateau phenomenon. However  the number of output elements
does not fully determine the presence or absence of plateaus  nor does the use of skip connections.
The statistical property of data just can affect the learning dynamics dramatically; for example  see
Figure 2 for learning curves with using different datasets and same network architecture. We focus
on what kind of statistical property of the data brings plateau phenomenon.

Figure 1:
(a) Training loss curves when two-layer perceptron with 4-4-3 units and ReLU activation
learns IRIS dataset. (b) Training loss curve when two-layer perceptron with 784-20-10 units and
ReLU activation learns MNIST dataset. For both (a) and (b)  results of 100 trials with random
initialization are overlaid. Minibatch size of 10 and vanilla SGD (learning rate: 0.01) are used.

2

02505007501000Epoch0.000.250.500.751.001.251.50Training Loss(a)02505007501000Epoch0.000.050.100.150.20Training Loss(b)Figure 2: Loss curves yielded by student-teacher learning with two-layer perceptron which has 2
hidden units  1 output unit and sigmoid activation  and with (a) IRIS dataset  (b) MNIST dataset  (c)
a dataset in R60000×784 drawn from standard normal distribution  as input distribution p(ξ). In every
subﬁgure  results for 20 trials with random initialization are overlaid. Vanilla SGD (learning rate:
(a)(b) 0.005  (c) 0.001) and minibatch size of 1 are used for all three settings.

2 Formulation

2.1 Student-Teacher Model

We consider a two-layer perceptron which has N input units  K hidden units and 1 output unit. We
i=1 wig(J i·ξ) ∈

denote the input to the network by ξ ∈ RN . Then the output can be written as s =(cid:80)K
t =(cid:80)M

R  where g is an activation function.
We consider the situation that the network learns data generated by another network  called “teacher
network”  which has ﬁxed weights. Speciﬁcally  we consider two-layer perceptron that outputs
n=1 vng(Bn · ξ) ∈ R for input ξ as the teacher network. The generated data (ξ  t) is then fed
to the student network stated above and learned by it in the on-line manner (see Figure 3). We assume
that the input ξ is drawn from some distribution p(ξ) every time independently. We adopt vanilla
stochastic gradient descent (SGD) algorithm for learning. We assume the squared loss function
ε = 1

2 (s − t)2  which is most commonly used for regression.

2.2 Statistical Mechanical Formulation

In order to capture the learning dynamics of nonlinear neural networks described in the previous
subsection macroscopically  we introduce the statistical mechanical formulation in this subsection.
Let xi := J i · ξ (1 ≤ i ≤ K) and yn := Bn · ξ (1 ≤ n ≤ M). Then

(x1  . . .   xK  y1  . . .   yM ) ∼ N(cid:0)0  [J 1  . . .   J K  B1  . . .   BM ]T Σ[J 1  . . .   J K  B1  . . .   BM ](cid:1)

holds with N → ∞ by generalized central limit theorem  provided that the input distribution p(ξ)
has zero mean and ﬁnite covariance matrix Σ.
Next  let us introduce order parameters as following: Qij := J T
(cid:104)xiyn(cid:105)  Tnm := BT

n ΣBm = (cid:104)ynym(cid:105) and Dij := wiwj  Ein := wivn  Fnm := vnvm. Then

i ΣJ j = (cid:104)xixj(cid:105)  Rin := J T

i ΣBn =

(x1  . . .   xK  y1  . . .   yM ) ∼ N (0 

(cid:18) Q R

RT

T

(cid:19)

).

The parameters Qij  Rin  Tnm  Dij  Ein  and Fnm introduced above capture the state of the system
macroscopically; therefore they are called as “order parameters.” The ﬁrst three represent the state
of the ﬁrst layers of the two networks (student and teacher)  and the latter three represent their
second layers’ state. Q describes the statistics of the student’s ﬁrst layer and T represents that of the
teacher’s ﬁrst layer. R is related to similarity between the student and teacher’s ﬁrst layer. D  E  F
is the second layers’ counterpart of Q  R  T . The values of Qij  Rin  Dij  and Ein change during
learning; their dynamics are what to be determined  from the dynamics of microscopic variables  i.e.
connection weights. In contrast  Tnm and Fnm are constant during learning.

3

102103104105Epoch109107105103101Training Loss(a)100101102103Epoch109107105103101Training Loss(b)100101102103Epoch109107105103101Training Loss(c)Figure 3: Overview of student-teacher model formulation.

2.2.1 Higher-order order parameters

The important difference between our situation and that of Saad and Solla [1995] is the covariance
matrix Σ of the input ξ is not necessarily equal to identity. This makes the matter complicated  since
higher-order terms Σe (e = 1  2  . . .) appear inevitably in the learning dynamics of order parameters.
In order to deal with these  here we deﬁne some higher-order version of order parameters.
in and T (e)
Let us deﬁne higher-order order parameters Q(e)
:=
i ΣeJ j  R(e)
J T
n ΣeBm. Note that they are identical to Qij 
Rin and Tnm in the case of e = 1. Also we deﬁne higher-order version of xi and yn  namely x(e)
and y(e)

nm for e = 0  1  2  . . .  as Q(e)
ij

n := ξT ΣeBn. Note that x(0)

:= ξT ΣeJ i  y(e)

in := J T

nm := BT

n   as x(e)

and T (e)

ij   R(e)

i = xi and y(0)

n = yn.

i ΣeBn 

i

i

3 Derivation of dynamics of order parameters

At each iteration of on-line learning  weights of the student network J i and wi are updated with
∆J i = − η
N

[(t − s) · wi]g(cid:48)(xi)ξ =

wjg(xj)

η
N

η
N

=

dε
dJ i

 · wi

 g(cid:48)(xi)ξ 

 M(cid:88)
vng(yn) − K(cid:88)
 M(cid:88)
vng(yn) − K(cid:88)

n=1

j=1

n=1

j=1

  

wjg(xj)

∆wi = − η
N

dε
dwi

=

η
N

g(xi)(t − s) =

η
N

g(xi)

in which we set the learning rate as η/N  so that our macroscopic system is N-independent.
Then  the order parameters Q(e)

in (e = 0  1  2  . . .) are updated with

ij and R(e)

(1)

∆Q(e)

ij = (J i + ∆J i)T Σe(J j + ∆J j) − J T

i Σe∆J j + J T

j Σe∆J i + ∆J T

i Σe∆J j

EipEjqg(cid:48)(xi)g(cid:48)(xj)g(yp)g(yq)

EipDjqg(cid:48)(xi)g(cid:48)(xj)g(yp)g(xq)

(cid:35)

 

(2)

=

η
N

Eipg(cid:48)(xi)x(e)

j g(yp) − K(cid:88)

i ΣeJ j = J T
Dipg(cid:48)(xi)x(e)

j g(xp)

p=1

p=1

Ejpg(cid:48)(xj)x(e)

i g(yp) − K(cid:88)

M(cid:88)
(cid:34)K K(cid:88)
DipEjqg(cid:48)(xi)g(cid:48)(xj)g(xp)g(yq) − M K(cid:88)

DipDjqg(cid:48)(xi)g(cid:48)(xj)g(xp)g(xq) +

p=1

p q

Djpg(cid:48)(xj)x(e)

i g(xp)

(cid:35)

(cid:34) M(cid:88)

p=1

+

− K M(cid:88)
(cid:34) M(cid:88)

p q

+

η2
N 2 ξT Σeξ

M M(cid:88)

p q

(cid:35)

∆R(e)

in = (J i + ∆J i)T ΣeBn − J T

i ΣeBn = ∆J T

n g(yp) − K(cid:88)

p q
i ΣeBn
Dipg(cid:48)(xi)y(e)

n g(xp)

.

=

η
N

Eipg(cid:48)(xi)y(e)

p=1

p=1

4

......Student Networkξ1ξ2ξNJ1JKw1wKs......Teacher Networkξ1ξ2ξNB1BMv1vMtξSamplingInput Distributionε=12(s−t)2Since

ξT Σeξ ≈ N µe+1

where µd :=

1
N

N(cid:88)

λd
i  

λ1  . . .   λN : eigenvalues of Σ

and the right hand sides of the difference equations are O(N−1)  we can replace these difference
equations with differential ones with N → ∞  by taking the expectation over all input vectors ξ:

i=1

  yp) − K(cid:88)

DipI3(xi  x(e)
j

  xp)

(cid:34) M(cid:88)

dQ(e)
ij
d˜α

= η

+ η2µe+1

EipEjqI4(xi  xj  yp  yq)

(3)

EipI3(xi  x(e)
j

i

+

p=1

p=1

p=1

p=1

EjpI3(xj  x(e)

  yp) − K(cid:88)

M(cid:88)
(cid:34)K K(cid:88)
DipEjqI4(xi  xj  xp  yq) − M K(cid:88)
− K M(cid:88)
(cid:34) M(cid:88)

n   yp) − K(cid:88)

DipDjqI4(xi  xj  xp  xq) +

p q

p q

p q

(cid:35)

  xp)

DjpI3(xj  x(e)

i

M M(cid:88)

(cid:35)

 

p q

EipDjqI4(xi  xj  yp  xq)

(cid:35)

DipI3(xi  y(e)

n   xp)

p=1

= η

EipI3(xi  y(e)

dR(e)
in
d˜α
I3(z1  z2  z3) := (cid:104)g(cid:48)(z1)z2g(z3)(cid:105)

p=1

and I4(z1  z2  z3  z4) := (cid:104)g(cid:48)(z1)g(cid:48)(z2)g(z3)g(z4)(cid:105).
where
(4)
In these equations  ˜α := α/N represents time (normalized number of steps)  and the brackets (cid:104)·(cid:105)
represent the expectation when the input ξ follows the input distribution p(ξ).
The differential equations for D and E are obtained in a similar way:

(cid:34) M(cid:88)
(cid:34) M(cid:88)

p=1

EipI2(xj  yp) − K(cid:88)
FpnI2(xi  yp) − K(cid:88)

p=1

p=1

p=1

dDij
d˜α

dEin
d˜α

= η

= η

DipI2(xj  xp) +

(cid:35)

EpnI2(xi  xp)

M(cid:88)

EjpI2(xi  yp) − K(cid:88)

p=1

p=1

(cid:35)

DjpI2(xi  xp)

 

(5)

I2(z1  z2) := (cid:104)g(z1)g(z2)(cid:105).

where

(6)
These differential equations (3) and (5) govern the macroscopic dynamics of learning. In addition 
2(cid:107)s − t(cid:107)2 over all input vectors ξ  is
the generalization loss εg  the expectation of loss value ε(ξ) = 1
represented as
εg = (cid:104) 1
2

DpqI2(xp  xq) −2

(cid:34)M M(cid:88)

(cid:107)s − t(cid:107)2(cid:105) =

FpqI2(yp  yq) +

K M(cid:88)

EpqI2(xp  yq)

K K(cid:88)

(cid:35)

1
2

.

p q

p q

p q

(7)

3.1 Expectation terms

Above we have determined the dynamics of order parameters as (3)  (5) and (7). However they have
expectation terms I2(z1  z2)  I3(z1  z(e)
2   z3) and I4(z1  z2  z3  z4)  where zs are either xi or yn. By
studying what distribution z follows  we can show that these expectation terms are dependent only
on 1-st and (e + 1)-th order parameters  namely  Q(1)  R(1)  T (1) and Q(e+1)  R(e+1)  T (e+1); for
example 

(cid:90)

I3(xi  x(e)
j

  yp) =

dz1dz2dz3 g(cid:48)(z1)z2g(z3) N (z|0 

5

 Q(1)

ii

Q(e+1)
ij
R(1)
ip

)

Q(e+1)

ij

∗

R(e+1)

jp

R(1)
ip
R(e+1)
jp
T (1)
pp

holds  where ∗ does not inﬂuence the value of this expression (see Supplementary Material A.1 for
more detailed discussion). Thus  we see the ‘speed’ of e-th order parameters (i.e. (3) and (5)) only
depends on 1-st and (e + 1)-th order parameters  and the generalization error εg (equation (7)) only
depends on 1-st order parameters. Therefore  with denoting (Q(e)  R(e)  T (e)) by Ω(e) and (D  E  F )
by χ  we can write

d
d˜α

Ω(e) = f (e)(Ω(1)  Ω(e+1)  χ) 

d
d˜α

χ = g(Ω(1)  χ) 

and

εg = h(Ω(1)  χ)

with appropriate functions f (e)  g and h. Additionally  a polynomial of Σ

d(cid:89)

d(cid:88)

P (Σ) :=

(Σ − λ(cid:48)

iIN ) =

ceΣe

where λ(cid:48)

1  . . .   λ(cid:48)

d

i=1

e=0

equals to 0  thus we get

Ω(d) = − d−1(cid:88)

ceΩ(e).

are distinct eigenvalues of Σ

(8)

Using this relation  we can reduce Ω(d) to expressions which contain only Ω(0)  . . .   Ω(d−1)  therefore
we can get a closed differential equation system with Ω(0)  . . .   Ω(d−1) and χ.
In summary  our macroscopic system is closed with the following order parameters:

e=0

ij   Q(1)
Order variables : Q(0)
Order constants :
(d: number of distinct eigenvalues of Σ)
T (0)
nm  T (1)
The order variables are governed by (3) and (5). For the lengthy full expressions of our macroscopic
system for speciﬁc cases  see Supplementary Material A.2.

ij
nm   Fnm.

  Dij  Ein

ij   . . .   Q(d−1)
nm  . . .   T (d−1)

  R(0)

in   R(1)

in   . . .   R(d−1)

in

3.2 Dependency on input data covariance Σ

The differential equation system we derived depends on Σ  through two ways; the coefﬁcient µe+1
of O(η2)-term  and how (d)-th order parameters are expanded with lower order parameters (as (8)).
Speciﬁcally  the system only depends on the eigenvalue distribution of Σ.

3.3 Evaluation of expectation terms for speciﬁc activation functions

Expectation terms I2  I3 and I4 can be analytically determined for some activation functions g 
including sigmoid-like g(x) = erf(x/
2) (see Saad and Solla [1995]) and g(x) = ReLU(x) (see
Yoshida et al. [2017]).

√

4 Analysis of numerical solutions of macroscopic differential equations

In this section  we analyze numerically the order parameter system  derived in the previous section1.
We assume that the second layers’ weights of the student and the teacher  namely wi and vn  are ﬁxed
to 1 (i.e. we consider the learning of soft-committee machine)  and that K and M are equal to 2  for
simplicity. Here we think of sigmoid-like activation g(x) = erf(x/

√

2).

4.1 Consistency between macroscopic system and microscopic system

First of all  we conﬁrmed the consistency between the macroscopic system we derived and the original
microscopic system. That is  we computed the dynamics of the generalization loss εg in two ways:
(i) by updating weights of the network with SGD (1) iteratively  and (ii) by solving numerically the
differential equations (5) which govern the order parameters  and we conﬁrmed that they accord with
each other very well (Figure 4). Note that we set the initial values of order parameters in (ii) as values
corresponding to initial weights used in (i). For dependence of the learning trajectory on the initial
condition  see Supplementary Material A.3.

1 We executed all computations on a standard PC.

6

Figure 4: Example dynamics of generalization error εg computed with (a) microscopic and (b)
macroscopic system. Network size: N-2-1. Learning rate: η = 0.1. Eigenvalues of Σ: λ1 = 0.4 with
multiplicity 0.5N  λ2 = 1.2 with multiplicity 0.3N  and λ3 = 1.6 with multiplicity 0.2N. Black
lines: dynamics of εg. Blue lines: Q11  Q12  Q22. Green lines: R11  R12  R21  R22.

4.2 Case of scalar input covariance Σ = σIN

As the simplest case  here we consider the case that the convariance matrix Σ is proportional to
unit matrix. In this case  Σ has only one eigenvalue λ = µ1 of multiplicity N  then our order
parameter system contains only parameters whose order is 0 (e = 0). For various values of µ1  we
solved numerically the differential equations of order parameters (5) and plotted the time evolution
of generalization loss εg (Figure 5(a)). From these plots  we quantiﬁed the lengths and heights of
the plateaus as following: we regarded the system is plateauing if the decreasing speed of log-loss is
smaller than half of its terminal converging speed  and we deﬁned the height of the plateau as the
median of loss values during plateauing. Quantiﬁed lengths and heights are plotted in Figure 5(b)(c).
It indicates that the plateau length and height heavily depend on µ1  the input scale. Speciﬁcally  as
µ1 decreases  the plateau rapidly becomes longer and lower. Though smaller input data lead to longer
plateaus  it also becomes lower and then inconspicuous. This tendency is consistent with Figure
2(a)(b)  since IRIS dataset has large µ1 (≈ 15.9) and MNIST has small µ1 (≈ 0.112). Considering
this  the claim that the plateau phenomenon does not occur in learning of MNIST is controversy; this
suggests the possibility that we are observing quite long and low plateaus.
Note that Figure 5(b) shows that the speed of growing of plateau length is larger than O(1/µ1). This
is contrast to the case of linear networks which have no activation; in that case  as µ1 decreases the
speed of learning gets exactly 1/µ1-times larger. In other words  this phenomenon is peculiar to
nonlinear networks.

Figure 5: (a) Dynamics of generalization error εg when input variance Σ has only one eigenvalue
λ = µ1 of multiplicity N. Plots with various values of µ1 are shown. (b) Plateau length and (b)
plateau height  quantiﬁed from (a).

7

050000100000Iterations 104103102101100Generalization loss gMicroscopic (N=100)(a)05001000Normalized Steps =/N104103102101100MacroscopicQijRing(b)(a)(b)(c)4.3 Case of different input covariance Σ with ﬁxed µ1

In the previous subsection we inspected the dependence of the learning dynamics on the ﬁrst moment
µ1 of the eigenvalues of the covariance matrix Σ. In this subsection  we explored the dependence of
the dynamics on the higher moments of eigenvalues  under ﬁxed ﬁrst moment µ1.
In this subsection  we consider the case in which the input covariance matrix Σ has two distinct
nonzero eigenvalues  λ1 = µ1 − ∆λ/2 and λ2 = µ1 + ∆λ/2  of the same multiplicity N/2 (Figure
6). With changing the control parameter ∆λ  we can get eigenvalue distributions with various values
of second moment µ2 = (cid:104)λ2
i(cid:105).

Figure 6: Eigenvalue distribution with ﬁxed µ1 parameterized by ∆λ  which yields various µ2.

Figure 7(a) shows learning curves with various µ2 while ﬁxing µ1 to 1. From these curves  we
quantiﬁed the lengths and heights of the plateaus  and plotted them in Figure 7(b)(c). These indicate
that the length of the plateau shortens as µ2 becomes large. That is  the more the distribution of
nonzero eigenvalues gets broaden  the more the plateau gets alleviated.

(a) Dynamics of generalization error εg when input variance Σ has two eigenvalues
Figure 7:
λ1 2 = µ1 ± ∆λ/2 of multiplicity N/2. Plots with various values of µ2 are shown. (b) Plateau length
and (c) plateau height  quantiﬁed from (a).

5 Conclusion

Under the statistical mechanical formulation of learning in the two-layered perceptron  we showed
that macroscopic equations can be derived even when the statistical properties of the input are
generalized. We showed that the dynamics of learning depends only on the eigenvalue distribution
of the covariance matrix of the input data. By numerically analyzing the macroscopic system  it is
shown that the statistics of input data dramatically affect the plateau phenomenon.
Through this work  we explored the gap between theory and reality; though the plateau phenomenon
is theoretically predicted to occur by the general symmetrical structure of neural networks  it is
seldom observed in practice. However  more extensive researches are needed to fully understand the
theory underlying the plateau phenomenon in practical cases.

8

Δλμ1+Δλ2μ1−Δλ2λ(a)(b)(c)Acknowledgement

This work was supported by JSPS KAKENHI Grant-in-Aid for Scientiﬁc Research(A) (No.
18H04106).

References
Florent Cousseau  Tomoko Ozeki  and Shun-ichi Amari. Dynamics of learning in multilayer percep-

trons near singularities. IEEE Transactions on Neural Networks  19(8):1313–1328  2008.

Kenji Fukumizu and Shun-ichi Amari. Local minima and plateaus in hierarchical structures of

multilayer perceptrons. Neural Networks  13(3):317–327  2000.

Sebastian Goldt  Madhu S Advani  Andrew M Saxe  Florent Krzakala  and Lenka Zdeborová.
Dynamics of stochastic gradient descent for two-layer neural networks in the teacher-student setup.
arXiv preprint arXiv:1906.08632  2019.

Weili Guo  Yuan Yang  Yingjiang Zhou  Yushun Tan  Haikun Wei  Aiguo Song  and Guochen Pang.
Inﬂuence area of overlap singularity in multilayer perceptrons. IEEE Access  6:60214–60223 
2018.

Kazuyuki Hara  Daisuke Saitoh  and Hayaru Shouno. Analysis of dropout learning regarded as
In International Conference on Artiﬁcial Neural Networks  pages 72–79.

ensemble learning.
Springer  2016.

John Milnor. On the concept of attractor. In The Theory of Chaotic Attractors  pages 243–264.

Springer  1985.

A Emin Orhan and Xaq Pitkow. Skip connections eliminate singularities.

arXiv:1701.09175  2017.

arXiv preprint

Hyeyoung Park  Shun-ichi Amari  and Kenji Fukumizu. Adaptive natural gradient learning algorithms

for various stochastic models. Neural Networks  13(7):755–764  2000.

Peter Riegler and Michael Biehl. On-line backpropagation in two-layered neural networks. Journal

of Physics A: Mathematical and General  28(20):L507  1995.

David Saad and Sara A Solla. On-line learning in soft committee machines. Physical Review E  52

(4):4225  1995.

Michiel Straat and Michael Biehl. On-line learning dynamics of relu neural networks using statistical

physics techniques. arXiv preprint arXiv:1903.07378  2019.

Michiel Straat  Fthi Abadi  Christina Göpfert  Barbara Hammer  and Michael Biehl. Statistical

mechanics of on-line learning under concept drift. Entropy  20(10):775  2018.

Shiro Takagi  Yuki Yoshida  and Masato Okada. Impact of layer normalization on single-layer
perceptron—statistical mechanical analysis. Journal of the Physical Society of Japan  88(7):
074003  2019.

Haikun Wei  Jun Zhang  Florent Cousseau  Tomoko Ozeki  and Shun-ichi Amari. Dynamics of

learning near singularities in layered networks. Neural computation  20(3):813–843  2008.

Yuki Yoshida  Ryo Karakida  Masato Okada  and Shun-ichi Amari. Statistical mechanical analysis
of online learning with weight normalization in single layer perceptron. Journal of the Physical
Society of Japan  86(4):044002  2017.

Yuki Yoshida  Ryo Karakida  Masato Okada  and Shun-ichi Amari. Statistical mechanical analysis
of learning dynamics of two-layer perceptron with multiple output units. Journal of Physics A:
Mathematical and Theoretical  2019.

9

,Siu On Chan
Ilias Diakonikolas
Rocco Servedio
Xiaorui Sun
Liang Zhang
Guangming Zhu
Lin Mei
Peiyi Shen
Syed Afaq Ali Shah
Mohammed Bennamoun
Yuki Yoshida
Masato Okada