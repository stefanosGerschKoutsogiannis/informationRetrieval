2009,STDP enables spiking neurons to detect hidden causes of their inputs,The principles by which spiking neurons contribute to the astounding computational power of generic cortical microcircuits  and how spike-timing-dependent plasticity (STDP) of synaptic weights could generate and maintain  this computational function  are unknown. We show here that STDP  in conjunction with a stochastic soft winner-take-all (WTA) circuit  induces spiking neurons to generate through their synaptic weights implicit internal models for subclasses (or causes") of the high-dimensional spike patterns of hundreds of pre-synaptic neurons. Hence these  neurons will fire after learning whenever the current input best matches their internal model. The resulting computational function of soft WTA circuits  a common network motif of cortical microcircuits  could therefore be a drastic dimensionality reduction of information streams  together with the autonomous creation of internal models for the probability distributions of their input patterns. We show that the autonomous generation and maintenance of this computational function can be explained on the basis of rigorous mathematical principles. In particular  we show that STDP is able to approximate a stochastic online Expectation-Maximization (EM) algorithm for modeling the input data. A corresponding result is shown for Hebbian learning in artificial neural networks.",STDP enables spiking neurons to
detect hidden causes of their inputs

Bernhard Nessler  Michael Pfeiffer  and Wolfgang Maass

Institute for Theoretical Computer Science  Graz University of Technology

A-8010 Graz  Austria

{nessler pfeiffer maass}@igi.tugraz.at

Abstract

The principles by which spiking neurons contribute to the astounding computa-
tional power of generic cortical microcircuits  and how spike-timing-dependent
plasticity (STDP) of synaptic weights could generate and maintain this compu-
tational function  are unknown. We show here that STDP  in conjunction with
a stochastic soft winner-take-all (WTA) circuit  induces spiking neurons to gen-
erate through their synaptic weights implicit internal models for subclasses (or
“causes”) of the high-dimensional spike patterns of hundreds of pre-synaptic neu-
rons. Hence these neurons will ﬁre after learning whenever the current input best
matches their internal model. The resulting computational function of soft WTA
circuits  a common network motif of cortical microcircuits  could therefore be
a drastic dimensionality reduction of information streams  together with the au-
tonomous creation of internal models for the probability distributions of their in-
put patterns. We show that the autonomous generation and maintenance of this
computational function can be explained on the basis of rigorous mathematical
principles. In particular  we show that STDP is able to approximate a stochastic
online Expectation-Maximization (EM) algorithm for modeling the input data. A
corresponding result is shown for Hebbian learning in artiﬁcial neural networks.

1

Introduction

It is well-known that synapses change their synaptic efﬁcacy (“weight”) w in dependence of the
difference tpost − tpre of the ﬁring times of the post- and presynaptic neuron according to variations
of a generic STDP rule (see [1] for a recent review). However  the computational beneﬁt of this
learning rule is largely unknown [2  3]. It has also been observed that local WTA-circuits form a
common network-motif in cortical microcircuits [4]. However  it is not clear how this network-motif
contributes to the computational power and adaptive capabilities of laminar cortical microcircuits 
out of which the cortex is composed. Finally  it has been conjectured for quite some while  on the
basis of theoretical considerations  that the discovery and representation of hidden causes of their
high-dimensional afferent spike inputs is a generic computational operation of cortical networks of
neurons [5]. One reason for this belief is that the underlying mathematical framework  Expectation-
Maximization (EM)  arguably provides the most powerful approach to unsupervised learning that
we know of. But one has so far not been able to combine these three potential pieces (STDP  WTA-
circuits  EM) of the puzzle into a theory that could help us to unravel the organization of computation
and learning in cortical networks of neurons.

We show in this extended abstract that STDP in WTA-circuits approximates EM for discovering
hidden causes of large numbers of input spike trains. We ﬁrst demonstrate this in section 2 in an
application to a standard benchmark dataset for the discovery of hidden causes. In section 3 we
show that the functioning of this demonstration can be explained on the basis of EM for simpler
non-spiking approximations to the spiking network considered in section 2.

1

2 Discovery of hidden causes for a benchmark dataset

We applied the network architecture shown in Fig. 1A to handwritten digits from the MNIST dataset
[6].1 This dataset consists of 70  000 28 × 28-pixel images of handwritten digits2  from which we
picked the subset of 20  868 images containing only the digits 0  3 and 4. Training examples were
randomly sampled from this subset with a uniform distribution of digit classes.

Simple STDP curve
Complex STDP curve

 

c · e

−wki -1

σ

-1

0
 − t

t
post

pre

i

k

w
∆

 

0

 

A

B

Figure 1: A) Architecture for learning with STDP in a WTA-network of spiking neurons. B) Learn-
ing curve for the two STDP rules that were used (with σ = 10ms). The synaptic weight wki is
changed in dependence of the ﬁring times tpre of the presynaptic neuron yi and tpost of the post-
synaptic neuron zk. If zk ﬁres at time t without a ﬁring of yi in the interval [t − σ  t + 2σ]  wki is
reduced by 1. The resulting weight change is in any case multiplied with the current learning rate η 
which was chosen in the simulations according to the variance tracking rule7.

Pixel values xj were encoded through population coding by binary variables yi (spikes were pro-
duced for each variable yi by a Poisson process with a rate of 40 Hz for yi = 1  and 0 Hz for yi = 0 
at a simulation time step of 1ms  see Fig. 2A). Every training example x was presented for 50ms.
Every neuron yi was connected to all K = 10 output neurons z1  . . .   z10. A Poisson process caused
ﬁring of one of the neurons zk on average every 5ms (see [8] for a more realistic ﬁring mechanism).
The WTA-mechanism ensured that only one of the output neurons could ﬁre at any time step. The
winning neuron at time step t was chosen from the soft-max distribution

p(zk ﬁres at time t|y) =

 

(1)

euk(t)
l=1 eul(t)

PK

where uk(t) =Pn

i=1 wki ˜yi(t) + wk0 represents the current membrane potential of neuron zk (with

˜yi(t) = 1 if yi ﬁred within the time interval [t − 10ms  t]  else ˜yi(t) = 0).3
STDP with the learning curves shown in Fig. 1B was applied to all synapses wki for an input consist-
ing of a continuous sequence of spike encodings of handwritten digits  each presented for 50ms (see

1A similar network of spiking neurons had been applied successfully in [7] to learn with STDP the classi-
ﬁcation of symbolic (i.e.  not handwritten) characters. Possibly our theoretical analysis could also be used to
explain their simulation result.

2Pixels were binarized to black/white. All pixels that were black in less than 5% of the training examples
were removed  leaving m = 429 external variables xj  that were encoded by n = 858 spiking neurons yi. Our
approach works just as well for external variables xj that assume any ﬁnite number of values  provided that
they are presented to the network through population coding with one variable yi for every possible value of
xj. In fact  the approach appears to work also for the commonly considered population coding of continuous
external variables.

3This amounts to a representation of the EPSP caused by a ﬁring of neuron yi by a step function  which facil-
itates the theoretical analysis in section 3. Learning with the spiking network works just as well for biologically
realistic EPSP forms.

2

Input Spike Trains

Output before Learning

Output after Learning

s
n
o
r
u
e
N

 
t

u
p
n

I

100

200

300

400

500

600

700

800

0

50

100

Time [ms]

A

1

2

3

4

5

6

7

8

9

s
n
o
r
u
e
N

 
t

u
p

t

u
O

150

10

0

50

100

Time [ms]

B

1

2

3

4

5

6

7

8

9

s
n
o
r
u
e
N

 
t

u
p

t

u
O

150

10

0

50

100

150

Time [ms]

C

Figure 2: Unsupervised classiﬁcation learning and sparsiﬁcation of ﬁring of output neurons after
training. For testing we presented three examples from an independent test set of handwritten digits
0  3  4 from the MNIST dataset  and compared the ﬁring of the output-neurons before and after
learning. A) Representation of the three handwritten digits 0  3  4 for 50ms each by 858 spiking
neurons yi. B) Response of the output neurons before training. C) Response of the output neurons
after STDP (according to Fig. 1B) was applied to their weights wki for a continuous sequence of
spike encodings of 4000 randomly drawn examples of handwritten digits 0  3  4  each represented
for 50ms (like in panel A). The three output neurons z4  z9  z6 that respond have generated internal
models for the three shown handwritten digits according to Fig. 3C.

Fig. 2A).4 The learning rate η was chosen locally according to the variance tracking rule7. Fig. 2C
shows that for subsequent representations of new handwritten samples of the same digits only one
neuron responds during each of the 50ms while a handwritten digit is shown. The implicit internal
models which the output neurons z1  . . .   z10 had created in their weights after applying STDP are
made explicit in Fig. 3B and C. Since there were more output neurons than digits  several output
neurons created internal models for different ways of writing the same digit. When after applying
STDP to 2000 random examples of handwritten digits 0 and 3 also examples of handwritten digit
4 were included in the next 2000 examples  the internal models of the 10 output neurons reorga-
nized autonomously  to include now also two internal models for different ways of writing the digit
4. The adaptation of the spiking network to the examples shown so far is measured in Fig. 3A by
the normalized conditional entropy H(L|Z)/H(L  Z)  where L denotes the correct classiﬁcation of
each handwritten digit y  and Z is the random variable which denotes the cluster assignment with
p(Z = k|y) = p(zk = 1|y)  the ﬁring probabilities at the presentation of digit y  see (1).
Since after training by STDP each of the output neurons ﬁre preferentially for one digit  we can
measure the emergent classiﬁcation capability of the network. The resulting weight-settings achieve
a classiﬁcation error of 2.19% on the digits 0 and 3 after 2000 training steps and 3.68% on all three
digits after 4000 training steps on independent test sets of 10 000 new samples each.

3 Underlying theoretical principles

We show in this section that one can analyze the learning dynamics of the spiking network con-
sidered in the preceding section (with the simple STDP curve of Fig. 1B with the help of Hebbian
learning (using rule (12)) in a corresponding non-spiking neural network Nw. Nw is a stochastic
artiﬁcial neural network with the architecture shown in Fig. 1A  and with a parameter vector w con-
sisting of thresholds wk0 (k = 1  . . .   K) for the K output units z1  . . .   zK and weights wki for the
connection from the ith input node yi (i = 1  . . .   n) to the kth output unit zk. We assume that this
network receives at each discrete time step a binary input vector y ∈ {0  1}n and outputs a binary
k=1 zk = 1  where the k such that zk = 1 is drawn from the distribution

4Whereas the weights in the theoretical analysis of section 3 will approximate logs of probabilities (see (6)) 
one can easily make all weights non-negative by restricting the range of these log-probabilities to [−5  0]  and
then adding a constant 5 to all weight values. This transformation gives rise to the factor c = e5 in Fig. 1B.

vector z ∈ {0  1}K withPK

3

Spiking Network (simple STDP curve)
Spiking Network (complex STDP curve)
Non−spiking Network (no missing attributes)
Non−spiking Network (35% missing attributes)

 

0.5

0.45

0.4

0.35

0.3

0.25

0.2

0.15

0.1

0.05

y
p
o
r
t

n
E

 
l

a
n
o

i
t
i

d
n
o
C

0
 
0

500

1000

1500
2500
Training Examples

2000

3000

3500

4000

A

B

C

Figure 3: Analysis of the learning progress of the spiking network for the MNIST dataset. A)
Normalized conditional entropy (see text) for the spiking network with the two variants of STDP
learning rules illustrated in Fig. 1B (red solid and blue dashed lines)  as well as two non-spiking
approximations of the network with learning rule (12) that are analyzed in section 3. According to
this analysis the non-spiking network with 35% missing attributes (dash-dotted line) is expected to
have a very similar learning behavior to the spiking network. 2000 random examples of handwritten
digits 0 and 3 were presented (for 50ms each) to the spiking network as the ﬁrst 2000 examples.
Then for the next 2000 examples also samples of handwritten digit 4 were included. B) The implicit
internal models created by the neurons after 2000 training examples are made explicit by drawing
for each pixel the difference wki − wk(i+1) of the weights for input yi and yi+1 that encode the two
possible values (black/white) of the variable xj that encodes this pixel value. One can clearly see
that neurons created separate internal models for different ways of writing the two digits 0 and 3. C)
Re-organized internal models after 2000 further training examples that included digit 4. Two output
neurons had created internal models for the newly introduced digit 4.

over {1  . . .   K} deﬁned by

p(zk = 1|y  w) =

euk
K

with uk =

wki yi + wk0 .

(2)

n

Xi=1

We consider the case where there are arbitrary discrete external variables x1  . . .   xm  each ranging
over {1  . . .   M } (we had M = 2 in section 2)  and assume that these are encoded through binary

eul

Pl=1

variables y1  . . .   yn for n = m · M withPn

y(j−1)·M +r = 1 ⇐⇒ xj = r  

i=1 yi = m according to the rule

for j = 1  . . .   m and r = 1  . . .   M .

(3)

In other words: the group Gj of variables y(j−1)·M +1  . . .   y(j−1)·M +M provides a population cod-
ing for the discrete variable xj.
We now consider a class of probability distributions that is particularly relevant for our analysis:
mixtures of multinomial distributions [9]  a generalization of mixtures of Bernoulli distributions
(see section 9.3.3 of [10]). This is a standard model for latent class analysis [11] in the case of
discrete variables. Mixtures of multinomial distributions are arbitrary mixtures of K distributions
p1(x)  . . .   pK (x) that factorize  i.e. 

m

pk(x) =

pkj(xj)

Yj=1

for arbitrary distributions pkj(xj) over the range {1  . . .   M } of possible values for xj. In other
k=1 zk = 1  where the

words: there exists some distribution over hidden binary variables zk withPK

k with zk = 1 is usually referred to as a hidden “cause” in the generation of x  such that

K

p(x) =

Xk=1

p(zk = 1) · pk(x).

4

(4)

We ﬁrst observe that any such distribution p(x) can be represented with some suitable weight vector
w by the neural network Nw  after recoding of the multinomial variables xj by binary variables yi
as deﬁned before:

for

p(y|w) =

eu∗

k

K

Xk=1

with

u∗

k :=

n

Xi=1

w∗

ki yi + w∗
k0

 

w∗

ki := log p(yi = 1|zk = 1)

and

w∗

k0 := log p(zk = 1) .

In addition  Nw deﬁnes for any weight vector w whose components are normalized  i.e.

K

Xk=1

ewk0 = 1 and Xi∈Gj

a mixture of multinomials of the type (4).

ewki = 1  

for j = 1  . . .   m; k = 1  . . .   K 

(5)

(6)

(7)

The problem of learning a generative model for some arbitrarily given input distribution p∗(x) (or
p∗(y) after recoding according to (3))  by the neural network Nw is to ﬁnd a weight vector w such
that p(y|w) deﬁned by (5) models p∗(y) as accurately as possible. As usual  we quantify this goal
by demanding that

Ep∗ [log p(y|w)]

(8)

is maximized.

Note that the architecture Nw is very useful from a functional point of view  because if (7) holds 
then the weighted sum uk at its unit zk has according to (2) the value log p(zk = 1|y  w)  and the
stochastic WTA rule of Nw picks the “winner” k with zk = 1 from this internally generated model
p(zk = 1|y  w) for the actual distribution p∗(zk = 1|y) of hidden causes. We will not enforce the
normalization (7) explicitly during the subsequently considered learning process  but rather use a
learning rule (12) that turns out to automatically approximate such normalization in the limit.
Expectation Maximization (EM) is the standard method for maximizing Ep∗ [log p(y|w)]. We will
show that the simple STDP-rule of Fig. 1B for the spiking network of section 2 can be viewed as
an approximation to an online version of this EM method. We will ﬁrst consider in section 3.1 the
standard EM-approach  and show that the Hebbian learning rule (12) provides a stochastic approxi-
mation to the maximization step.

3.1 Reduction to EM

The standard method for maximizing the expected log-likelihood Ep∗ [log p(y|w)] with a dis-

tribution p of the form p(y|w) = Pz p(y  z|w) with hidden variables z  is to observe that

Ep∗ [log p(y|w)] can be written for arbitrary distributions q(z|y) in the form

Ep∗ [log p(y|w)] = L(q  w) + Ep∗ [KL(q(z|y)||p(z|y  w))]

(9)

L(q  w) = Ep∗"Xz

q(z|y) log

p(y  z|w)

q(z|y) #  

(10)

where KL(.) denotes the Kullback-Leibler divergence.
old  thereby
In the E-step one sets q(z|y) = p(z|y  w
achieving Ep∗ [KL(q(z|y)||p(z|y  w
old by new parameters
w that maximize L(q  w) for this distribution q(z|y). One can easily show that this is achieved by
setting

old) for the current parameter values w = w

old))] = 0. In the M-step one replaces w

w∗

ki = log p∗(yi = 1|zk = 1) 

(11)
w∗
with values for the variables zk generated by q(z|y) = p(z|y  w
old)  while the values for the vari-
ables y are generated by the external distribution p∗. Note that this distribution of z is exactly the
distribution (2) of the output of the neural network Nw for inputs y generated by p∗.5 In the fol-
lowing section we will show that this M-step can be approximated by applying iteratively a simple
Hebbian learning rule to the weights w of the neural network Nw.

k0 = log p∗(zk = 1) 

and

5Hence one can extend p∗(y) for each ﬁxed w to a joint distribution p∗(y  z)  where the z are generated

for each y by Nw.

5

3.2 A Hebbian learning rule for the M-step

We show here that the target weight values (11) are the only equilibrium points of the following
Hebbian learning rule:

∆wki=(η (e−wki − 1) 

−η 
0 

if yi=1 and zk=1
if yi=0 and zk=1

if zk = 0 

∆wk0=(cid:26)η (e−wk0 − 1) 

−η 

if zk=1
if zk=0

(12)

It is obvious (using for the second equivalence the fact that yi is a binary variable) that

E[∆wki] = 0 ⇔
⇔

⇔
⇔

p∗(yi=1|zk=1)η(e−wki − 1) − p∗(yi=0|zk=1)η = 0
p∗(yi=1|zk=1)(e−wki − 1) + p∗(yi=1|zk=1) − 1 = 0
p∗(yi=1|zk=1)e−wki = 1
wki = log p∗(yi=1|zk=1) .

(13)

ki (in fact  exponentially fast).

Analogously one can show that E[∆wk0] = 0 ⇔ wk0 = log p∗(zk=1). With similar elementary
calculations one can show that E[∆wki] has for any w a value that moves wki in the direction of
w∗
One can actually show that one single step of (12) is a linear approximation of the ideal incremental
update of wki = log aki
  with aki and Nk representing the values of the corresponding sufﬁcient
Nk
statistics  as log aki+1
. This also reveals the
role of the learning rate η as the reciprocal of the equivalent sample size6.
In order to guarantee the stochastic convergence (see [12]) of the learning rule one has to use a

Nk+1 = wki + log(1 + ηe−wki) − log(1 + η) for η = 1

Nk

t=1(η(t))2 = 0.7

decaying learning rate η(t) such thatP∞

t=1 η(t) = ∞ andP∞

The learning rule (12) is similar to a rule that had been introduced in [13] in the context of supervised
learning and reinforcement learning. That rule had satisﬁed an equilibrium condition similar to (13).
But to the best of our knowledge  such type of rule has so far not been considered in the context of
unsupervised learning.
One can easily see the correspondence between the update of wki in (12) and in the simple STDP
rule of Fig. 1B. In fact  if each time where neuron zk ﬁres in the spiking network  each presynaptic
neuron yi that currently has a high ﬁring rate has ﬁred within the last σ = 10ms before the ﬁring
of zk  the two learning rules become equivalent. However since the latter condition could only be
achieved with biologically unrealistic high ﬁring rates  we need to consider in section 3.4 the case
for the non-spiking network where some attributes are missing (i.e.  yi = 0 for all i ∈ Gj; for some
group Gj that encodes an external variable xj via population coding).
We ﬁrst show that the Hebbian learning rule (12) is also meaningful in the case of online learning of
Nw  which better matches the online learning process for the spiking network.

3.3 Stochastic online EM

The preceding arguments justify an application of learning rule (12) for a number of steps within
p[log p(y|w)]. We now show that it is also
each M-step of a batch EM approach for maximizing E∗
meaningful to apply the same rule (12) in an online stochastic EM approach (similarly as in [14]) 
where at each combined EM-step only one example y is generated by p∗  and the learning rule (12)

6The equilibrium condition (13) only sets a necessary constraint for the the quotient of the two directions of

the update in (12). The actual formulation of (12) is motivated by the goal of updating a sufﬁcient statistics.

7In our experiments we used an adaptation of the variance tracking heuristic from [13]. If we assume that
the consecutive values of the weights represent independent samples of their true stochastic distribution at the
current learning rate  then this observed distribution is the log of a beta-distribution of the above mentioned
parameters of the sufﬁcient statistics. Analytically this distribution has the ﬁrst and second moments E[wki] ≈
log aki
. The
Ni
empirical estimates of these ﬁrst two moments can be gathered online by exponentially decaying averages
using the same learning rate ηki.

  leading to the estimate ηnew

ki] ≈ E[wki]2 + 1
aki

ki = 1
Ni

ki]−E[wki]2

= E[w2

and E[w2

e−E[wki ]+1

+ 1
Ni

6

is applied just once (for zk resulting from p(z|y  w) for the current weights w  or simpler: for the
zk that is output by Nw for the current input y).
Our strategy for showing that a single application of learning rule (12) is expected to provide
progress in an online EM-setting is the following. We consider the Lagrangian F for maximiz-
ing Ep∗ [log p(y|w)] under the constraints (7)  and show that an application of rule (12) is expected
to increase the value of F . We set

λkj
1 − Xi∈Gj

ewki
 .

(14)

i=1 wki yi + wk0. Hence one

K

K

m

Xk=1

ewk0! −

F (w  λ) = Ep∗ [log p(y|w)] − λ0 1 −

arrives at the following conditions for the Lagrange multipliers λ:

Xj=1
Xk=1
k=1 euk for uk = PK
According to (5) one can write p(y|w) = PK
] − λ0ewk0! = 0
Xk=1 Ep∗ [
PK
= Xi∈Gj Ep∗ [yi
] − λkjewki! = 0 
PK

euk
l=1 eul
euk
l=1 eul

Xk=1
Xi∈Gj

∂F
∂wki

∂F
∂wk0

=

K

K

(15)

(16)

euk

which yield λ0 = 1 and λkj = Ep∗ [

l=1 eul ].
Plugging these values for λ into ∇wF · E∗
p[∆w] with ∆w deﬁned by (12) shows that this vector
product is always positive. Hence even a single application of learning rule (12) to a single new
example y  drawn according to p∗  is expected to increase Ep∗[log p(y|w)] under the constraints
(7).

PK

3.4

Impact of missing attributes

We had shown at the end of 3.2 that learning in the spiking network corresponds to learning in the
non-spiking network Nw with missing attributes. A profound analysis of the correct handling of
missing attribute values in EM can be found in [15]. Their analysis implies that the correct learning
action is then not to change the weights wki for i ∈ Gj. However the STDP rule of Fig. 1B  as
well as (12)  reduce also these weights by η if zk ﬁres. This yields a modiﬁcation of the equilibrium
analysis (13):

E[∆wki] = 0 ⇔ (1 − r)(cid:0)p∗(yi=1|zk=1)η(e−wki − 1) − p∗(yi=0|zk=1)η(cid:1) − rη = 0

wki = log p∗(yi=1|zk=1) + log(1 − r)  

⇔

(17)

where r is the probability that i belongs to a group Gj where the value of xj is missing. Since
this probability r is independent of the neuron zk and also independent of the current value of the
external variable xi  this offset of log(1 − r) is expected to be the same for all weights. It can easily
be veriﬁed  that such an offset does not change the resulting probabilities of the competition in the
E-step according to (2).

3.5 Relationship between the spiking and the non-spiking network

As indicated at the end of section 3.2  the learning process for the spiking network from section 2
with the simple STDP curve from Fig. 1B (and external variables xj encoded by input spike trains
from neurons yi) is equivalent to a somewhat modiﬁed learning process of the non-spiking network
Nw with the Hebbian learning rule (12) and external variables xj encoded by binary variables yi.
Each ﬁring of a neuron zk at some time t corresponds to a discrete time step in Nw with an ap-
plication of the Hebbian learning rule (12). Each neuron yi that had ﬁred during the time interval
[t − 10ms  t] contributes a value ˜yi(t) = 1 to the membrane potential uk(t) of the neuron zk at time
t  and a value ˜yi(0) = 0 if it did not ﬁre during [t − 10ms  t]. Hence the weight updates at time t
according to the simple STDP curve are exactly equal to those of (12) in the non-spiking network.
However (12) will in general be applied to a corresponding input y where it may occur that for some

7

j ∈ {1  . . .   m} one has yi = 0 for all i ∈ Gj (since none of the neurons yi with i ∈ Gj ﬁred in the
spiking network during [t − 10ms  t]). Hence we arrive at an application of (12) to an input y with
missing attributes  as discussed in section 3.4.
Since several neurons zk are likely to ﬁre during the presentation of an external input x (each hand-
written digit was presented for 50ms in section 2; but a much shorter presentation time of 10ms also
works quite well)  this external input x gives in general rise to several applications of the STDP rule.
This corresponds to several applications of rule (12) to the same input (but with different choices
of missing attributes) in the non-spiking network. In the experiments in section 2  every example
in the non-spiking network with missing attributes was therefore presented for 10 steps  such that
the average number of learning steps is the same as in the spiking case. The learning process of
the spiking network corresponds to a slight variation of the stochastic online EM algorithm that is
implemented through (12) according to the analysis of section 3.3.

4 Discussion

The model for discovering hidden causes of inputs that is proposed in this extended abstract presents
an interesting shortcut for implementing and learning generative models for input data in networks
of neurons. Rather than building and adapting an explicit model for re-generating internally the dis-
tribution of input data  our approach creates an implicit model of the input distribution (see Fig. 3B)
that is encoded in the weights of neurons in a simple WTA-circuit. One might call it a Vapnik-style
[16] approach towards generative modeling  since it focuses directly on the task to represent the
most likely hidden causes of the inputs through neuronal ﬁring. As the theoretical analysis via non-
spiking networks in section 3 has shown  this approach also offers a new perspective for generating
self-adapting networks on the basis of traditional artiﬁcial neural networks. One just needs to add
the stochastic and non-feedforward parts required for implementing stochastic WTA circuits to a
1-layer feedforward network  and apply the Hebbian learning rule (12) to the feedforward weights.
One interesting aspect of the “implicit generative learning” approach that we consider in this ex-
tended abstract is that it retains important advantages of the generative learning approach  faster
learning and better generalization [17]  while retaining the algorithmic simplicity of the discrimina-
tive learning approach.

Our approach also provides a new method for analyzing details of STDP learning rules. The sim-
ulation results of section 2 show that a simpliﬁed STDP rule that can be understood clearly from
the perspective of stochastic online EM with a suitable Hebbian learning rule  provides good perfor-
mance in discovering hidden causes for a standard benchmark dataset. A more complex STDP rule 
whose learning curve better matches experimentally recorded average changes of synaptic weights 
provides almost the same performance. For a comparison of the STDP curves in Fig. 1B with ex-
perimentally observed STDP curves one should keep in mind  that most experimental data on STDP
curves are for very low ﬁring rates. The STDP curve of Fig. 7C in [18] for a ﬁring rate of 20Hz has 
similarly as the STDP curves in Fig. 1B of this extended abstract  no pronounced negative dip  and
instead an almost constant negative part.

In our upcoming paper [8] we will provide full proofs for the results announced in this extended
abstract  as well as further applications and extensions of the learning result. We will also demon-
strate  that the learning rules that we have proposed are robust to noise  and that they are matched
quite well by experimental data.

Acknowledgments

We would like to thank the anonymous reviewer for a hint in the notational formalism. Written under
partial support by the Austrian Science Fund FWF  project # P17229-N04  project # S9102-N04 
and project # FP6-015879 (FACETS) as well as # FP7-216593 (SECO) of the European Union.

8

References

[1] Y. Dan and M. Poo. Spike timing-dependent plasticity of neural circuits. Neuron  44:23–30  2004.
[2] L. F. Abbott and S. B. Nelson. Synaptic plasticity: taming the beast. Nature Neuroscience  3:1178–1183 

2000.

[3] A. Morrison  A. Aertsen  and M. Diesmann. Spike-timing-dependent plasticity in balanced random net-

works. Neural Computation  19:1437–1467  2007.

[4] R. J. Douglas and K. A. Martin. Neuronal circuits of the neocortex. Annu Rev Neurosci  27:419–451 

2004.

[5] G. E. Hinton and Z. Ghahramani. Generative models for discovering sparse distributed representations.

Philos Trans R Soc Lond B Biol Sci.  352(1358):1177–1190  1997.

[6] Y. LeCun  L. Bottou  Y. Bengio  and P. Haffner. Gradient-based learning applied to document recognition.

Proceedings of the IEEE  86(11):2278–2324  1998.

[7] A. Gupta and L. N. Long. Character recognition using spiking neural networks. IJCNN  pages 53–58 

2007.

[8] B. Nessler  M. Pfeiffer  and W. Maass. Spike-timing dependent plasticity performs stochastic expectation

maximization to reveal the hidden causes of complex spike inputs. (in preparation).

[9] M. Meil˘a and D. Heckerman. An experimental comparison of model-based clustering methods. Machine

Learning  42(1):9–29  2001.

[10] C. M. Bishop. Pattern Recognition and Machine Learning. Springer  New York  2006.
[11] G. McLachlan and D. Peel. Finite mixture models. Wiley  2000.
[12] J.H. Kushner and G.G. Yin. Stochastic approximation algorithms and applications. Springer  1997.
[13] B. Nessler  M. Pfeiffer  and W. Maass. Hebbian learning of bayes optimal decisions. In Advances in

Neural Information Processing Systems 21  pages 1169–1176. MIT Press  2009.

[14] M. Sato. Fast learning of on-line EM algorithm. Rapport Technique  ATR Human Information Processing

Research Laboratories  1999.

[15] Z. Ghahramani and M.I. Jordan. Mixture models for learning from incomplete data. Computational

Learning Theory and Natural Learning Systems  4:67–85  1997.

[16] V. Vapnik. Universal learning technology: Support vector machines. NEC Journal of Advanced Technol-

ogy  2:137–144  2005.

[17] A. Y. Ng and M. I. Jordan. On discriminative vs. generative classiﬁers: A comparison of logistic regression

and naive Bayes. Advances in Neural Information Processing Systems (NIPS)  14:841–848  2002.

[18] P. J. Sj¨ostr¨om  G. G. Turrigiano  and S. B. Nelson. Rate  timing  and cooperativity jointly determine

cortical synaptic plasticity. Neuron  32:1149–1164  2001.

9

,Harish Ramaswamy
Shivani Agarwal
Ambuj Tewari
Mehryar Mohri
Scott Yang
Pratik Kumar Jawanpuria
Maksim Lapin
Matthias Hein
Bernt Schiele