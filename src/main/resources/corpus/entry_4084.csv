2014,Online and Stochastic Gradient Methods for Non-decomposable Loss Functions,Modern applications in sensitive domains such as biometrics and medicine frequently require the use of non-decomposable loss functions such as precision@k  F-measure etc. Compared to point loss functions such as hinge-loss  these offer much more fine grained control over prediction  but at the same time present novel challenges in terms of algorithm design and analysis. In this work we initiate a study of online learning techniques for such non-decomposable loss functions with an aim to enable incremental learning as well as design scalable solvers for batch problems. To this end  we propose an online learning framework for such loss functions. Our model enjoys several nice properties  chief amongst them being the existence of efficient online learning algorithms with sublinear regret and online to batch conversion bounds. Our model is a provable extension of existing online learning models for point loss functions. We instantiate two popular losses  Prec @k and pAUC  in our model and prove sublinear regret bounds for both of them. Our proofs require a novel structural lemma over ranked lists which may be of independent interest. We then develop scalable stochastic gradient descent solvers for non-decomposable loss functions. We show that for a large family of loss functions satisfying a certain uniform convergence property (that includes Prec @k  pAUC  and F-measure)  our methods provably converge to the empirical risk minimizer. Such uniform convergence results were not known for these losses and we establish these using novel proof techniques. We then use extensive experimentation on real life and benchmark datasets to establish that our method can be orders of magnitude faster than a recently proposed cutting plane method.,Online and Stochastic Gradient Methods for

Non-decomposable Loss Functions

Purushottam Kar∗

Harikrishna Narasimhan†

∗Microsoft Research  INDIA

{t-purkar prajain}@microsoft.com  harikrishna@csa.iisc.ernet.in

†Indian Institute of Science  Bangalore  INDIA

Prateek Jain∗

Abstract

Modern applications in sensitive domains such as biometrics and medicine fre-
quently require the use of non-decomposable loss functions such as precision@k 
F-measure etc. Compared to point loss functions such as hinge-loss  these of-
fer much more ﬁne grained control over prediction  but at the same time present
novel challenges in terms of algorithm design and analysis. In this work we initiate
a study of online learning techniques for such non-decomposable loss functions
with an aim to enable incremental learning as well as design scalable solvers for
batch problems. To this end  we propose an online learning framework for such
loss functions. Our model enjoys several nice properties  chief amongst them be-
ing the existence of efﬁcient online learning algorithms with sublinear regret and
online to batch conversion bounds. Our model is a provable extension of existing
online learning models for point loss functions. We instantiate two popular losses 
Prec@k and pAUC  in our model and prove sublinear regret bounds for both of
them. Our proofs require a novel structural lemma over ranked lists which may
be of independent interest. We then develop scalable stochastic gradient descent
solvers for non-decomposable loss functions. We show that for a large family
of loss functions satisfying a certain uniform convergence property (that includes
Prec@k  pAUC  and F-measure)  our methods provably converge to the empirical
risk minimizer. Such uniform convergence results were not known for these losses
and we establish these using novel proof techniques. We then use extensive exper-
imentation on real life and benchmark datasets to establish that our method can be
orders of magnitude faster than a recently proposed cutting plane method.

1

Introduction

Modern learning applications frequently require a level of ﬁne-grained control over prediction per-
formance that is not offered by traditional “per-point” performance measures such as hinge loss.
Examples include datasets with mild to severe label imbalance such as spam classiﬁcation wherein
positive instances (spam emails) constitute a tiny fraction of the available data  and learning tasks
such as those in medical diagnosis which make it imperative for learning algorithms to be sensi-
tive to class imbalances. Other popular examples include ranking tasks where precision in the top
ranked results is valued more than overall precision/recall characteristics. The performance mea-
sures of choice in these situations are those that evaluate algorithms over the entire dataset in a
holistic manner. Consequently  these measures are frequently non-decomposable over data points.
More speciﬁcally  for these measures  the loss on a set of points cannot be expressed as the sum of
losses on individual data points (unlike hinge loss  for example). Popular examples of such measures
include F-measure  Precision@k  (partial) area under the ROC curve etc.
Despite their success in these domains  non-decomposable loss functions are not nearly as well
understood as their decomposable counterparts. The study of point loss functions has led to a deep

1

understanding about their behavior in batch and online settings and tight characterizations of their
generalization abilities. The same cannot be said for most non-decomposable losses. For instance  in
the popular online learning model  it is difﬁcult to even instantiate a non-decomposable loss function
as deﬁning the per-step penalty itself becomes a challenge.

1.1 Our Contributions

(cid:17)

T

to offer vanishing O(cid:16) 1√

Our ﬁrst main contribution is a framework for online learning with non-decomposable loss functions.
The main hurdle in this task is a proper deﬁnition of instantaneous penalties for non-decomposable
losses. Instead of resorting to canonical deﬁnitions  we set up our framework in a principled way
that fulﬁlls the objectives of an online model. Our framework has a very desirable characteristic that
allows it to recover existing online learning models when instantiated with point loss functions. Our
framework also admits online-to-batch conversion bounds.
We then propose an efﬁcient Follow-the-Regularized-Leader [1] algorithm within our framework.
We show that for loss functions that satisfy a generic “stability” condition  our algorithm is able
regret. Next  we instantiate within our framework  convex surrogates
for two popular performances measures namely  Precision at k (Prec@k) and partial area under the
ROC curve (pAUC) [2] and show  via a stability analysis  that we do indeed achieve sublinear
regret bounds for these loss functions. Our stability proofs involve a structural lemma on sorted
lists of inner products which proves Lipschitz continuity properties for measures on such lists (see
Lemma 2) and might be useful for analyzing non-decomposable loss functions in general.
A key property of online learning methods is their applicability in designing solvers for of-
ﬂine/batch problems. With this goal in mind  we design a stochastic gradient-based solver for
non-decomposable loss functions. Our methods apply to a wide family of loss functions (including
Prec@k  pAUC and F-measure) that were introduced in [3] and have been widely adopted [4  5  6]
in the literature. We design several variants of our method and show that our methods provably con-
verge to the empirical risk minimizer of the learning instance at hand. Our proofs involve uniform
convergence-style results which were not known for the loss functions we study and require novel
techniques  in particular the structural lemma mentioned above.
Finally  we conduct extensive experiments on real life and benchmark datasets with pAUC and
Prec@k as performance measures. We compare our methods to state-of-the-art methods that are
based on cutting plane techniques [7]. The results establish that our methods can be signiﬁcantly
faster  all the while offering comparable or higher accuracy values. For example  on a KDD 2008
challenge dataset  our method was able to achieve a pAUC value of 64.8% within 30ms whereas it
took the cutting plane method more than 1.2 seconds to achieve a comparable performance.

1.2 Related Work

Non-decomposable loss functions such as Prec@k  (partial) AUC  F-measure etc  owing to their
demonstrated ability to give better performance in situations with label imbalance etc  have gener-
ated signiﬁcant interest within the learning community. From their role in early works as indicators
of performance on imbalanced datasets [8]  their importance has risen to a point where they have
become the learning objectives themselves. Due to their complexity  methods that try to indirectly
optimize these measures are very common e.g. [9]  [10] and [11] who study the F-measure. How-
ever  such methods frequently seek to learn a complex probabilistic model  a task arguably harder
than the one at hand itself. On the other hand are algorithms that perform optimization directly via
structured losses. Starting from the seminal work of [3]  this method has received a lot of interest
for measures such as the F-measure [3]  average precision [4]  pAUC [7] and various ranking losses
[5  6]. These formulations typically use cutting plane methods to design dual solvers.
We note that the learning and game theory communities are also interested in non-additive notions
of regret and utility. In particular [12] provides a generic framework for online learning with non-
additive notions of regret with a focus on showing regret bounds for mixed strategies in a variety of
problems. However  even polynomial time implementation of their strategies is difﬁcult in general.
Our focus  on the other hand  is on developing efﬁcient online algorithms that can be used to solve
large scale batch problems. Moreover  it is not clear how (if at all) can the loss functions considered
here (such as Prec@k) be instantiated in their framework.

2

Recently  online learning for AUC maximization has received some attention [13  14]. Although
AUC is not a point loss function  it still decomposes over pairs of points in a dataset  a fact that [13]
and [14] crucially use. The loss functions in this paper do not exhibit any such decomposability.

2 Problem Formulation
Let x1:t := {x1  . . .   xt}  xi ∈ Rd and y1:t := {y1  . . .   yt}  yi ∈ {−1  1} be the observed data

points and true binary labels. We will use(cid:98)y1:t := {(cid:98)y1  . . .  (cid:98)yt} (cid:98)yi ∈ R to denote the predictions of a
learning algorithm. We shall  for sake of simplicity  restrict ourselves to linear predictors(cid:98)yi = w(cid:62)xi

for parameter vectors w ∈ Rd. A performance measure P : {−1  1}t × Rt → R+ shall be used to
evaluate the the predictions of the learning algorithm against the true labels. Our focus shall be on
non-decomposable performance measures such as Prec@k  partial AUC etc.
Since these measures are typically non-convex  convex surrogate loss functions are used instead (we
will use the terms loss function and performance measure interchangeably). A popular technique for
constructing such loss functions is the structural SVM formulation [3] given below. For simplicity 
we shall drop mention of the training points and use the notation (cid:96)P (w) := (cid:96)P (x1:T   y1:T   w).

(cid:96)P (w) =

max

¯y∈{−1 +1}T

Precision@k. The Prec@k measure ranks the data points in order of the predicted scores(cid:98)yi and then

returns the number of true positives in the top ranked positions. This is valuable in situations where
there are very few positives. To formalize this  for any predictor w and set of points x1:t  deﬁne
S(x  w) := {j : w(cid:62)x > w(cid:62)xj} to be the set of points which w ranks above x. Then deﬁne

i=1

(1)

(¯yi − yi)x(cid:62)

i w − P(¯y  y).

T(cid:88)

(cid:26)1 

0 

(cid:88)
t(cid:88)

(2)

(3)

(5)

Tβ t(x  w) =

if |S(x  w)| < (cid:100)βt(cid:101) 
otherwise.

i.e. Tβ t(x  w) is non-zero iff x is in the top-β fraction of the set. Then we deﬁne1

Prec@k(w) :=

I [yj = 1] .

j:Tk t(xj  w)=1

The structural surrogate for this measure is then calculated as 2
(¯yi − yi)xT

(cid:96)Prec@k (w) =

max

i w − t(cid:88)

yi ¯yi.

i=1

i=1

(cid:80)

¯y∈{−1 +1}t
i(¯yi+1)=2kt

Partial AUC. This measures the area under the ROC curve with the false positive rate restricted to
the range [0  β]. This is in contrast to AUC that considers the entire range [0  1] of false positive
rates. pAUC is useful in medical applications such as cancer detection where a small false positive
rate is desirable. Let us extend notation to use the indicator T−
β t(x  w) to select the top β fraction of
the negatively labeled points i.e. T−
t− is the number of negatives. Then we deﬁne

(cid:9)(cid:12)(cid:12) ≤ (cid:100)βt−(cid:101) where

pAUC(w) =

(4)
Let φ : R → R+ be any convex  monotone  Lipschitz  classiﬁcation surrogate. Then we can obtain
convex surrogates for pAUC(w) by replacing the indicator functions above with φ(·).

j:yj <0

β t(x  w) = 1 iff(cid:12)(cid:12)(cid:8)j : yj < 0  w(cid:62)x > w(cid:62)xj
(cid:88)
(cid:88)

(cid:88)
(cid:88)

β t(xj  w) · I[x(cid:62)
T−

i w ≥ x(cid:62)

j w].

i:yi>0

β t(xj  w) · φ(x(cid:62)
T−

i w − x(cid:62)

j w) 

(cid:96)pAUC(w) =

i:yi>0

j:yj <0

It can be shown [7  Theorem 4] that the structural surrogate for pAUC is equivalent to (5) with
φ(c) = max(0  1 − c)  the hinge loss function.
In the next section we will develop an online
learning framework for non-decomposable performance measures and instantiate loss functions such
as (cid:96)Prec@k and (cid:96)pAUC in our framework. Then in Section 4  we will develop stochastic gradient
methods for non-decomposable loss functions and prove error bounds for the same. There we will
focus on a much larger family of loss functions including Prec@k  pAUC and F-measure.

1An equivalent deﬁnition considers k to be the number of top ranked points instead.
2[3] uses a slightly modiﬁed  but equivalent  deﬁnition that considers labels to be Boolean.

3

3 Online Learning with Non-decomposable Loss Functions

t=1 Lt(wt) − arg minw∈W(cid:80)T

The goal is to minimize the regret i.e. (cid:80)T

We now present our online learning framework for non-decomposable loss functions. Traditional
online learning takes place in several rounds  in each of which the player proposes some wt ∈ W
while the adversary responds with a penalty function Lt : W → R and a loss Lt(wt) is incurred.
t=1 Lt(w). For point loss
functions  the instantaneous penalty Lt(·) is encoded using a data point (xt  yt) ∈ Rd × {−1  1}
as Lt(w) = (cid:96)P (xt  yt  w). However  for (surrogates of) non-decomposable loss functions such as
(cid:96)pAUC and (cid:96)Prec@k the deﬁnition of instantaneous penalty itself is not clear and remains a challenge.
To guide us in this process we turn to some properties of standard online learning frameworks. For
point losses  we note that the best solution in hindsight is also the batch optimal solution. This is
t=1 Lt(w) = arg minw∈W (cid:96)P (x1:T   y1:T   w) for non-
decomposable losses. Also  since the batch optimal solution is agnostic to the ordering of points 
t=1 Lt(w) to be invariant to permutations within the stream. By pruning away
several naive deﬁnitions of Lt using these requirements  we arrive at the following deﬁnition:
Lt(w) = (cid:96)P (x1:t  y1:t  w) − (cid:96)P (x1:(t−1)  y1:(t−1)  w).

equivalent to the condition arg minw∈W(cid:80)T
we should expect(cid:80)T

(6)

(cid:80)T
It turns out that the above is a very natural penalty function as it measures the amount of “extra”
online learning frameworks since for point losses  we have (cid:96)P (x1:t  y1:t  w) =(cid:80)t
penalty incurred due to the inclusion of xt into the set of points. It can be readily veriﬁed that
t=1 Lt(w) = (cid:96)P (x1:T   y1:T   w) as required. Also  this penalty function seamlessly generalizes
i=1 (cid:96)P (xi  yi  w)
and thus Lt(w) = (cid:96)P (xt  yt  w). We note that our framework also recovers the model for online
AUC maximization used in [13] and [14]. The notion of regret corresponding to this penalty is

R(T ) =

1
T

Lt(wt) − arg min
w∈W

1
T

(cid:96)P (x1:T   y1:T   w).

We note that Lt  being the difference of two loss functions  is non-convex in general and thus  stan-
dard online convex programming regret bounds cannot be applied in our framework. Interestingly  as
we show below  by exploiting structural properties of our penalty function  we can still get efﬁcient
low-regret learning algorithms  as well as online-to-batch conversion bounds in our framework.

T(cid:88)

t=1

3.1 Low Regret Online Learning

We propose an efﬁcient Follow-the-Regularized-Leader (FTRL) style algorithm in our framework.
Let w1 = arg minw∈W (cid:107)w(cid:107)2

2 and consider the following update:

wt+1 = arg min
w∈W

Lt(w) +

η
2

(cid:107)w(cid:107)2

2 = arg min

w∈W (cid:96)P (x1:t  y1:t  w) +

(cid:107)w(cid:107)2

2

η
2

(FTRL)

t(cid:88)

t=1

We would like to stress that despite the non-convexity of Lt  the FTRL objective is strongly convex
if (cid:96)P is convex and thus the update can be implemented efﬁciently by solving a regularized batch
problem on x1:t. We now present our regret bound analysis for the FTRL update given above.
Theorem 1. Let (cid:96)P (·  w) be a convex loss function and W ⊆ Rd be a convex set. Assume w.l.o.g.
(cid:107)xt(cid:107)2 ≤ 1 ∀t. Also  for the penalty function Lt in (6)  let |Lt(w) − Lt(w(cid:48))| ≤ Gt · (cid:107)w − w(cid:48)(cid:107)2 
for all t and all w  w(cid:48) ∈ W  for some Gt > 0. Suppose we use the update step given in ((FTRL)) to
obtain wt+1  0 ≤ t ≤ T − 1. Then for all w∗  we have

T(cid:88)

t=1

1
T

Lt(wt) ≤ 1
T

(cid:96)P (x1:T   y1:T   w∗) + (cid:107)w∗(cid:107)2

t=1 G2
t
T

.

(cid:113)

2(cid:80)T

See Appendix A for a proof. The above result requires the penalty function Lt to be Lipschitz
continuous i.e. be “stable” w.r.t. w. Establishing this for point losses such as hinge loss is relatively
straightforward. However  the same becomes non-trivial for non-decomposable loss functions as

4

j1

≥ z(cid:48)

≥ ··· ≥ z(cid:48)

Lt is now the difference of two loss functions  both of which involve Ω (t) data points. A naive
argument would thus  only be able to show Gt ≤ O(t) which would yield vacuous regret bounds.
Instead  we now show that for the surrogate loss functions for Prec@k and pAUC  this Lipschitz
continuity property does indeed hold. Our proofs crucially use a structural lemma given below that
shows that sorted lists of inner products are Lipschitz at each ﬁxed position.
Lemma 2 (Structural Lemma). Let x1  . . .   xt be t points with (cid:107)xi(cid:107)2 ≤ 1 ∀t. Let w  w(cid:48) ∈ W be any
two vectors. Let zi = (cid:104)w  xi(cid:105) − ci and z(cid:48)
i = (cid:104)w(cid:48)  xi(cid:105) − ci  where ci ∈ R are constants independent
of w  w(cid:48). Also  let {i1  . . .   it} and {j1  . . .   jt} be ordering of indices such that zi1 ≥ zi2 ≥ ··· ≥
. Then for any 1-Lipschitz increasing function g : R → R (i.e.
zit and z(cid:48)
|g(u) − g(v)| ≤ |u − v| and u ≤ v ⇔ g(u) ≤ g(v))  we have  ∀k |g(zik )− g(z(cid:48)
)| ≤ 3(cid:107)w− w(cid:48)(cid:107)2.
See Appendix B for a proof. Using this lemma we can show that the Lipschitz constant for (cid:96)Prec@k
regret bound for Prec@k (see Appendix C for
the proof). In Appendix D  we show that the same technique can be used to prove a stability result
for the structural SVM surrogate of the Precision-Recall Break Even Point (PRBEP) performance
measure [3] as well. The case of pAUC is handled similarly. However  since pAUC discriminates
between positives and negatives  our previous analysis cannot be applied directly. Nevertheless  we
can obtain the following regret bound for pAUC (a proof will appear in the full version of the paper).
Theorem 3. Let T+ and T− resp. be the number of positive and negative points in the stream and
let wt+1  0 ≤ t ≤ T − 1 be obtained using the FTRL algorithm ((FTRL)). Then we have

is bounded by Gt ≤ 8 which gives us a O(cid:16)(cid:113) 1

(cid:17)

jk

j2

jt

T

Lt(wt) ≤ min
w∈W

1

βT+T−

(cid:96)pAUC(x1:T   y1:T   w) + O

1
T+

+

1
T−

(cid:32)(cid:115)

(cid:33)

.

T(cid:88)

1

βT+T−

t=1

Notice that the above regret bound depends on both T+ and T− and the regret becomes large even
if one of them is small. This is actually quite intuitive because if  say T+ = 1 and T− = T − 1 
an adversary may wish to provide the lone positive point in the last round. Naturally the algorithm 
having only seen negatives till now  would not be able to perform well and would incur a large error.

3.2 Online-to-batch Conversion

(cid:80)T /s
t=1 Lt(wt) − arg minw∈W 1

To present our bounds we generalize our framework slightly: we now consider the stream of T
points to be composed of T /s batches Z1  . . .   ZT /s of size s each. Thus  the instantaneous penalty
is now deﬁned as Lt(w) = (cid:96)P (Z1  . . .   Zt  w) − (cid:96)P (Z1  . . .   Zt−1  w) for t = 1 . . . T /s and the
T (cid:96)P (x1:T   y1:T   w). Let RP denote
regret becomes R(T  s) = 1
the population risk for the (normalized) performance measure P. Then we have:
T
Theorem 4. Suppose the sequence of points (xt  yt) is generated i.i.d. and let w1  w2  . . .   wT /s
be an ensemble of models generated by an online learning algorithm upon receiving these T /s
batches. Suppose the online learning algorithm has a guaranteed regret bound R(T  s). Then for
w = 1
T /s

(cid:80)T /s
(cid:33)
t=1 wt  any w∗ ∈ W   ∈ (0  0.5] and δ > 0  with probability at least 1 − δ 
RP (w) ≤ (1 + )RP (w∗) + R(T  s) + e−Ω(s2) + ˜O
T ) and  = 4(cid:112)1/T gives us  with probability at least 1 − δ 

√
In particular  setting s = ˜O(

(cid:32)(cid:114)

s ln(1/δ)

T

.

RP (w) ≤ RP (w∗) + R(T 

T ) + ˜O

√

We conclude by noting that for Prec@k and pAUC  R(T 

√

(see Appendix E).

(cid:32)
(cid:114)
T ) ≤ O(cid:16) 4(cid:112)1/T

ln(1/δ)

T

4

(cid:33)
(cid:17)

.

4 Stochastic Gradient Methods for Non-decomposable Losses

The online learning algorithms discussed in the previous section present attractive guarantees in the
sequential prediction model but are required to solve batch problems at each stage. This rapidly

5

Algorithm 1 1PMB: Single-Pass with Mini-batches
Input: Step length scale η  Buffer B of size s
Output: A good predictor w ∈ W
1: w0 ← 0  B ← φ  e ← 0
2: while stream not exhausted do
3:

1)  . . .   (xe

1  ye

s  ye

s) in

Collect s data points (xe
buffer B
Set step length ηe ← η√

4:
5: we+1 ← ΠW [we + ηe∇w(cid:96)P (xe

1:s  we)]
//ΠW projects onto the set W

1:s  ye

e

Algorithm 2 2PMB: Two-Passes with Mini-batches
Input: Step length scale η  Buffers B+  B− of size s
Output: A good predictor w ∈ W

Pass 1: B+ ← φ
1: Collect random sample of pos. x+
Pass 2: w0 ← 0  B− ← φ  e ← 0

1   . . .   x+

s in B+

2: while stream of negative points not exhausted do
3:
in B−
4:

5: we+1 ← ΠW(cid:2)we + ηe∇w(cid:96)P (xe−

Collect s negative points xe−
Set step length ηe ← η√

1   . . .   xe−

1:s  we)(cid:3)

1:s  x+

e

s

//start a new epoch

//start a new epoch

Flush buffer B
e ← e + 1

6:
7:
8: end while
9: return w = 1
e

(cid:80)e

i=1 wi

Flush buffer B−
e ← e + 1

6:
7:
8: end while
9: return w = 1
e

(cid:80)e

i=1 wi

becomes infeasible for large scale data. To remedy this  we now present memory efﬁcient stochastic
gradient descent methods for batch learning with non-decomposable loss functions. The motivation
for our approach comes from mini-batch methods used to make learning methods for point loss
functions amenable to distributed computing environments [15  16]  we exploit these techniques to
offer scalable algorithms for non-decomposable loss functions.
Single-pass Method with Mini-batches. The method assumes access to a limited memory buffer
and takes a pass over the data stream. The stream is partitioned into epochs. In each epoch  the
method accumulates points in the stream  uses them to form gradient estimates and takes descent
steps. The buffer is ﬂushed after each epoch. Algorithm 1 describes the 1PMB method. Gradient
computations can be done using Danskin’s theorem (see Appendix H).
Two-pass Method with Mini-batches. The previous algorithm is unable to exploit relationships
between data points across epochs which may help improve performance for loss functions such as
pAUC. To remedy this  we observe that several real life learning scenarios exhibit mild to severe
label imbalance (see Table 2 in Appendix H) which makes it possible to store all or a large fraction
of points of the rare label. Our two pass method exploits this by utilizing two passes over the data:
the ﬁrst pass collects all (or a random subset of) points of the rare label using some stream sampling
technique [13]. The second pass then goes over the stream  restricted to the non-rare label points 
and performs gradient updates. See Algorithm 2 for details of the 2PMB method.

4.1 Error Bounds
Given a set of n labeled data points (xi  yi)  i = 1 . . . n and a performance measure P  our goal is to
approximate the empirical risk minimizer w∗ = arg min
(cid:96)P (x1:n  y1:n  w) as closely as possible.
w∈W
In this section we shall show that our methods 1PMB and 2PMB provably converge to the empirical
risk minimizer. We ﬁrst introduce the notion of uniform convergence for a performance measure.
Deﬁnition 5. We say that a loss function (cid:96) demonstrates uniform convergence with respect to a set of
randomly from an arbitrary set of n points {(x1  y1)  . . .   (xn  yn)} then w.p. at least 1− δ  we have

(cid:1)  when given a set of s points ¯x1  . . .   ¯xs chosen

predictors W if for some α(s  δ) = poly(cid:0) 1

s   log 1

δ

|(cid:96)P (x1:n  y1:n  w) − (cid:96)P (¯x1:s  ¯y1:s  w)| ≤ α(s  δ).

sup
w∈W

Such uniform convergence results are fairly common for decomposable loss functions such as the
squared loss  logistic loss etc. However  the same is not true for non-decomposable loss functions
barring a few exceptions [17  10]. To bridge this gap  below we show that a large family of surrogate
loss functions for popular non decomposable performance measures does indeed exhibit uniform
convergence. Our proofs require novel techniques and do not follow from traditional proof progres-
sions. However  we ﬁrst show how we can use these results to arrive at an error bound.
Theorem 6. Suppose the loss function (cid:96) is convex and demonstrates α(s  δ)-uniform convergence.
Also suppose we have an arbitrary set of n points which are randomly ordered  then the predictor

6

(a) PPI

(b) KDDCup08

(c) IJCNN

(d) Letter

Figure 1: Comparison of stochastic gradient methods with the cutting plane (CP) and projected
subgradient (PSG) methods on partial AUC maximization tasks. The epoch lengths/buffer sizes for
1PMB and 2PMB were set to 500.

(a) PPI

(b) KDDCup08

(c) IJCNN

(d) Letter

Figure 2: Comparison of stochastic gradient methods with the cutting plane (CP) method on Prec@k
maximization tasks. The epoch lengths/buffer sizes for 1PMB and 2PMB were set to 500.
w returned by 1PMB with buffer size s satisﬁes w.p. 1 − δ 
(cid:96)P (x1:n  y1:n  w) ≤ (cid:96)P (x1:n  y1:n  w∗) + 2α

(cid:18)(cid:114) s

+ O

(cid:19)

(cid:19)

(cid:18)

s 

sδ
n

n

We would like to stress that the above result does not assume i.i.d. data and works for arbitrary
datasets so long as they are randomly ordered. We can show similar guarantees for the two pass
method as well (see Appendix F). Using regularized formulations  we can also exploit logarithmic
regret guarantees [18]  offered by online gradient descent  to improve this result – however we do not
explore those considerations here. Instead  we now look at speciﬁc instances of loss functions that
possess the desired uniform convergence properties. As mentioned before  due to the combinatorial
nature of these performance measures  our proofs do not follow from traditional methods.
Theorem 7 (Partial Area under the ROC Curve). For any convex  monotone  Lipschitz  classiﬁcation
surrogate φ : R → R+  the surrogate loss function for the (0  β)-partial AUC performance measure

deﬁned as follows exhibits uniform convergence at the rate α(s  δ) = O(cid:16)(cid:112)log(1/δ)/s

(cid:17)

:

(cid:88)

(cid:88)

i:yi>0

j:yj <0

1

(cid:100)βn−(cid:101)n+

β t(xj  w) · φ(x(cid:62)
T−

i w − x(cid:62)

j w)

See Appendix G for a proof sketch. This result covers a large family of surrogate loss functions such
as hinge loss (5)  logistic loss etc. Note that the insistence on including only top ranked negative
points introduces a high degree of non-decomposability into the loss function. A similar result for
the special case β = 1 is due to [17]. We extend the same to the more challenging case of β < 1.
Theorem 8 (Structural SVM loss for Prec@k). The structural SVM surrogate for the Prec@k per-
.

formance measure (see (3)) exhibits uniform convergence at the rate α(s  δ) = O(cid:16)(cid:112)log(1/δ)/s

(cid:17)

We defer the proof to the full version of the paper. The above result can be extended to a large family
of performances measures introduced in [3] that have been widely adopted [10  19  8] such as F-
measure  G-mean  and PRBEP. The above indicates that our methods are expected to output models
that closely approach the empirical risk minimizer for a wide variety of performance measures. In
the next section we verify that this is indeed the case for several real life and benchmark datasets.

5 Experimental Results

We evaluate the proposed stochastic gradient methods on several real-world and benchmark datasets.

7

0123450.10.20.30.40.50.6Training time (secs)Average pAUC in [0  0.1] CPPSG1PMB2PMB00.20.40.60.80.20.40.6Training time (secs)Average pAUC in [0  0.1] CPPSG1PMB2PMB00.511.50.20.40.6Training time (secs)Average pAUC in [0  0.1] CPPSG1PMB2PMB00.10.20.30.10.20.30.40.50.6Training time (secs)Average pAUC in [0  0.1] CPPSG1PMB2PMB02468100.10.20.3Training time (secs)Average Prec@k CP1PMB2PMB01020300.10.20.30.4Training time (secs)Average Prec@k CP1PMB2PMB05100.20.40.6Training time (secs)Average Prec@k CP1PMB2PMB00.20.40.60.80.10.20.30.40.5Training time (secs)Average Prec@k CP1PMB2PMBMeasure
pAUC
Prec@k

1PMB

0.10 (68.2)
0.49 (42.7)

2PMB

0.15 (69.6)
0.55 (38.7)

CP

0.39 (62.5)
23.25 (40.8)

Table 1: Comparison of training time (secs) and accu-
racies (in brackets) of 1PMB  2PMB and cutting plane
methods for pAUC (in [0  0.1]) and Prec@k maximiza-
tion tasks on the KDD Cup 2008 dataset.

Figure 3: Performance of 1PMB and
2PMB on the PPI dataset with varying
epoch/buffer sizes for pAUC tasks.

Performance measures: We consider three measures  1) partial AUC in the false positive range
[0  0.1]  2) Prec@k with k set to the proportion of positives (PRBEP)  and 3) F-measure.
Algorithms: For partial AUC  we compare against the state-of-the-art cutting plane (CP) and pro-
jected subgradient methods (PSG) proposed in [7]; unlike the (online) stochastic methods considered
in this work  the PSG method is a ‘batch’ algorithm which  at each iteration  computes a subgradient-
based update over the entire training set. For Prec@k and F-measure  we compare our methods
against cutting plane methods from [3]. We used structural SVM surrogates for all the measures.
Datasets: We used several data sets for our experiments (see Table 2 in Appendix H); of these 
KDDCup08 is from the KDD Cup 2008 challenge and involves a breast cancer detection task [20] 
PPI contains data for a protein-protein interaction prediction task [21]  and the remaining datasets
are taken from the UCI repository [22].
Parameters: We used 70% of the data set for training and the remaining for testing  with the results
averaged over 5 random train-test splits. Tunable parameters such as step length scale were chosen
using a small validation set. The epoch lengths/buffer sizes were set to 500 in all experiments. Since
a single iteration of the proposed stochastic methods is very fast in practice  we performed multiple
passes over the training data (see Appendix H for details).
The results for pAUC and Prec@k maximization tasks are shown in the Figures 1 and 2. We found
the proposed stochastic gradient methods to be several orders of magnitude faster than the baseline
methods  all the while achieving comparable or better accuracies. For example  for the pAUC task
on the KDD Cup 2008 dataset  the 1PMB method achieved an accuracy of 64.81% within 0.03
seconds  while even after 0.39 seconds  the cutting plane method could only achieve an accuracy
of 62.52% (see Table 1). As expected  the (online) stochastic gradient methods were faster than
the ‘batch’ projected subgradient descent method for pAUC as well. We found similar trends on
Prec@k (see Figure 2) and F-measure maximization tasks as well. For F-measure tasks  on the KDD
Cup 2008 dataset  for example  the 1PMB method achieved an accuracy of 35.92 within 12 seconds
whereas  even after 150 seconds  the cutting plane method could only achieve an accuracy of 35.25.
The proposed stochastic methods were also found to be robust to changes in epoch lengths (buffer
sizes) till such a point where excessively long epochs would cause the number of updates as well as
accuracy to dip (see Figure 3). The 2PMB method was found to offer higher accuracies for pAUC
maximization on several datasets (see Table 1 and Figure 1)  as well as be more robust to changes
in buffer size (Figure 3). We defer results on more datasets and performance measures to the full
version of the paper.
The cutting plane methods were generally found to exhibit a zig-zag behaviour in performance
across iterates. This is because these methods solve the dual optimization problem for a given per-
formance measure; hence the intermediate models do not necessarily yield good accuracies. On the
other hand  (stochastic) gradient based methods directly offer progress in terms of the primal opti-
mization problem  and hence provide good intermediate solutions as well. This can be advantageous
in scenarios with a time budget in the training phase.

Acknowledgements

The authors thank Shivani Agarwal and Bharath K Sriperumbudur for their comments and helpful
discussions. They thank Andr´as Gy¨orgy for pointing out an omission in the proof of Theorem 1.
They also thank the anonymous reviewers for their suggestions. HN thanks support from a Google
India PhD Fellowship.

8

1001021040.420.440.460.480.50.520.54Epoch lengthAverage pAUC 1PMB1001021040.450.50.550.6Epoch lengthAverage pAUC 2PMBReferences
[1] Alexander Rakhlin. Lecture Notes on Online Learning. http://www-stat.wharton.upenn.

edu/˜rakhlin/papers/online_learning.pdf  2009.

[2] Harikrishna Narasimhan and Shivani Agarwal. A Structural SVM Based Approach for Optimizing Partial

AUC. In 30th International Conference on Machine Learning (ICML)  2013.

[3] Thorsten Joachims. A Support Vector Method for Multivariate Performance Measures. In ICML  2005.
[4] Yisong Yue  Thomas Finley  Filip Radlinski  and Thorsten Joachims. A Support Vector Method for

Optimizing Average Precision. In SIGIR  2007.

[5] Soumen Chakrabarti  Rajiv Khanna  Uma Sawant  and Chiru Bhattacharyya. Structured Learning for

Non-Smooth Ranking Losses. In KDD  2008.

[6] Brian McFee and Gert Lanckriet. Metric Learning to Rank. In ICML  2010.
[7] Harikrishna Narasimhan and Shivani Agarwal. SVMtight

Partial AUC Based on a Tight Convex Upper Bound. In KDD  2013.

pAUC: A New Support Vector Method for Optimizing

[8] Miroslav Kubat and Stan Matwin. Addressing the Curse of Imbalanced. Training Sets: One-Sided Selec-

tion. In 24th International Conference on Machine Learning (ICML)  1997.

[9] Krzysztof Dembczy´nski  Willem Waegeman  Weiwei Cheng  and Eyke H¨ullermeier. An Exact Algorithm

for F-Measure Maximization. In NIPS  2011.

[10] Nan Ye  Kian Ming A. Chai  Wee Sun Lee  and Hai Leong Chieu. Optimizing F-Measures: A Tale of

Two Approaches. In 29th International Conference on Machine Learning (ICML)  2012.

[11] Krzysztof Dembczy´nski  Arkadiusz Jachnik  Wojciech Kotlowski  Willem Waegeman  and Eyke
H¨ullermeier. Optimizing the F-Measure in Multi-Label Classiﬁcation: Plug-in Rule Approach versus
Structured Loss Minimization. In 30th International Conference on Machine Learning (ICML)  2013.

[12] Alexander Rakhlin  Karthik Sridharan  and Ambuj Tewari. Online Learning: Beyond Regret. In 24th

Annual Conference on Learning Theory (COLT)  2011.

[13] Purushottam Kar  Bharath K Sriperumbudur  Prateek Jain  and Harish Karnick. On the Generalization

Ability of Online Learning Algorithms for Pairwise Loss Functions. In ICML  2013.

[14] Peilin Zhao  Steven C. H. Hoi  Rong Jin  and Tianbao Yang. Online AUC Maximization. In ICML  2011.
[15] Ofer Dekel  Ran Gilad-Bachrach  Ohad Shamir  and Lin Xiao. Optimal Distributed Online Prediction

Using Mini-Batches. Journal of Machine Learning Research  13:165–202  2012.

[16] Yuchen Zhang  John C. Duchi  and Martin J. Wainwright. Communication-Efﬁcient Algorithms for Sta-

tistical Optimization. Journal of Machine Learning Research  14:3321–3363  2013.

[17] St´ephan Cl´emenc¸on  G´abor Lugosi  and Nicolas Vayatis. Ranking and empirical minimization of U-

statistics. Annals of Statistics  36:844–874  2008.

[18] Elad Hazan  Adam Kalai  Satyen Kale  and Amit Agarwal. Logarithmic Regret Algorithms for Online

Convex Optimization. In COLT  pages 499–513  2006.

[19] Sophia Daskalaki  Ioannis Kopanas  and Nikolaos Avouris. Evaluation of Classiﬁers for an Uneven Class

Distribution Problem. Applied Artiﬁcial Intelligence  20:381–417  2006.

[20] R. Bharath Rao  Oksana Yakhnenko  and Balaji Krishnapuram. KDD Cup 2008 and the Workshop on

Mining Medical Data. SIGKDD Explorations Newsletter  10(2):34–38  2008.

[21] Yanjun Qi  Ziv Bar-Joseph  and Judith Klein-Seetharaman. Evaluation of Different Biological Data and
Computational Classiﬁcation Methods for Use in Protein Interaction Prediction. Proteins  63:490–500 
2006.

[22] A. Frank and Arthur Asuncion. The UCI Machine Learning Repository. http://archive.ics.

uci.edu/ml  2010. University of California  Irvine  School of Information and Computer Sciences.

[23] Ankan Saha  Prateek Jain  and Ambuj Tewari. The interplay between stability and regret in online learn-

ing. CoRR  abs/1211.6158  2012.

[24] Martin Zinkevich. Online Convex Programming and Generalized Inﬁnitesimal Gradient Ascent. In ICML 

pages 928–936  2003.

[25] Robert J. Serﬂing. Probability Inequalities for the Sum in Sampling without Replacement. Annals of

Statistics  2(1):39–48  1974.

[26] Dimitri P. Bertsekas. Nonlinear Programming: 2nd Edition. Belmont  MA: Athena Scientiﬁc  2004.

9

,Purushottam Kar
Harikrishna Narasimhan
Prateek Jain