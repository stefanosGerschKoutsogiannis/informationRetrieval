2012,Minimizing Sparse High-Order Energies by Submodular Vertex-Cover,Inference on high-order graphical models has become increasingly important in recent years.  We consider energies with simple 'sparse' high-order potentials.  Previous work in this area uses either specialized message-passing  or transforms each high-order potential to the pairwise case. We take a fundamentally different approach  transforming the entire original problem into a comparatively small instance of a submodular vertex-cover problem. These vertex-cover instances can then be attacked by standard pairwise methods  where they run much faster (4--15 times) and are often more effective than on the original problem. We evaluate our approach on synthetic data  and we show that our algorithm can be useful in a fast hierarchical clustering and model estimation framework.,Minimizing Sparse High-Order Energies by

Submodular Vertex-Cover

Andrew Delong

University of Toronto

andrew.delong@gmail.com

Olga Veksler

Western University
olga@csd.uwo.ca

Anton Osokin

Moscow State University
anton.osokin@gmail.com

Yuri Boykov

Western University
yuri@csd.uwo.ca

Abstract

Inference in high-order graphical models has become important in recent years.
Several approaches are based  for example  on generalized message-passing  or
on transformation to a pairwise model with extra ‘auxiliary’ variables. We focus
on a special case where a much more efﬁcient transformation is possible. Instead
of adding variables  we transform the original problem into a comparatively small
instance of submodular vertex-cover. These vertex-cover instances can then be
attacked by existing algorithms (e.g. belief propagation  QPBO)  where they often
run 4–15 times faster and ﬁnd better solutions than when applied to the original
problem. We evaluate our approach on synthetic data  then we show applications
within a fast hierarchical clustering and model-ﬁtting framework.

1 Introduction

MAP inference on graphical models is a central problem in machine learning  pattern recognition 
and computer vision. Several algorithms have emerged as practical tools for inference  especially
for graphs containing only unary and pairwise factors. Prominent examples include belief propaga-
tion [30]  more advanced message passing methods like TRW-S [21] or MPLP [33]  combinatorial
methods like (cid:11)-expansion [6] (for ‘metric’ factors) and QPBO [32] (mainly for binary problems).
In terms of optimization  these algorithms are designed to minimize objective functions (energies)
containing unary and pairwise terms.
Many inference problems must be modeled using high-order terms  not just pairwise  and such
problems are increasingly important for many applications. Recent developments in high-order in-
ference include  for example  high-arity CRF potentials [19  38  25  31]  cardinality-based potentials
[13  34]  global potentials controlling the appearance of labels [24  26  7]  learning with high-order
loss functions [35]  among many others.
One standard approach to high-order inference is to transform the problem to the pairwise case and
then simply apply one of the aforementioned ‘pairwise’ algorithms. These transformations add many
‘auxiliary’ variables to the problem but  if the high-order terms are sparse in the sense suggested
by Rother et al. [31]  this can still be a very efﬁcient approach. There can be several equivalent
high-order-to-pairwise transformations  and this choice affects the difﬁculty of the resulting pair-
wise inference problem. Choosing the ‘easiest’ transformation is not trivial and has been explicitly
studied  for example  by Gallagher et al. [11].
Our work is about fast energy minimization (MAP inference) for particularly sparse  high-order “pat-
tern potentials” used in [25  31  29]: each energy term prefers a speciﬁc (but arbitrary) assignment
to its subset of variables. Instead of directly transforming the high-order problem to pairwise  we
transform the entire problem to a comparatively small instance of submodular vertex-cover (SVC).
The vertex-cover implicitly provides a solution to the original high-order problem. The SVC in-
stance can itself be converted to pairwise  and standard inference techniques run much faster and are
often more effective on this compact representation.

1

We also show that our ‘sparse’ high-order energies naturally appear when trying to solve hierarchi-
cal clustering problems using the algorithmic approach called fusion moves [27]  also conceptually
known as optimized crossover [1]. Fusion is a powerful very large-scale neighborhood search tech-
nique [3] that in some sense generalizes (cid:11)-expansion. The fusion approach is not standard for the
kind of clustering objective we will consider  but we believe it is an interesting optimization strategy.
The remainder of the paper is organized as follows. Section 2 introduces the class of high-order en-
ergies we consider  then derives the transformation to SVC and the subsequent decoding. Section 3
contains experiments that suggest signiﬁcant speedups  and discusses possible applications.

∏

2 Sparse High-Order Energies Reducible to SVC

∏
In what follows we use x to denote a vector of binary variables  xP to denote product
xQ to denote
always use i to denote a variable index from I  and j to denote a clique index from V.
It is well-known that any pseudo-boolean function (binary energy) can be written in the form

i∈P xi  and
i∈Q xi. It will be convenient to adopt the convention that x{} = 1 and x{} = 1. We

F (x) =

bjxPj xQj

(1)
where each clique j has coefﬁcient −bj with bj ≥ 0  and is deﬁned over variables in sets Pj; Qj ⊆ I.
Our approach will be of practical interest only when  roughly speaking  |V| ≪ |I|.
For example  if x = (x1; : : : ; x7) then a clique j with Pj = {2; 3} and Qj = {4; 5; 6} will explicitly
reward binary conﬁguration (· ; 1; 1; 0; 0; 0; ·) by the amount bj (depicted as b1 in Figure 1). If there
are several overlapping (and conﬂicting) cliques  then the minimization problem can be difﬁcult.
∑
A standard way to minimize F (x) would be to substitute each −bjxPj xQj term with a collection
In our experiments  we used the substitution −xPj xQj = −1 +
of equivalent pairwise terms.
miny∈{0;1} y +
xiy where y is an auxiliary variable. This is like the Type-II
i∈Qj
xiy +
transformation in [31]  and we found that it worked better than Type-I for our experiments. However 
we aim to minimize F (x) in a novel way  so ﬁrst we review the submodular vertex-cover problem.

∑

i∈Pj

∑

i∈I

aixi −

∑

j∈V

2.1 Review of Submodular Vertex-Cover

The classic minimum-weighted vertex-cover (VC) problem can be stated as a 0-1 integer program
where variable uj = 1 if and only if vertex j is included in the cover.

(VC) minimize

subject to uj + uj′ ≥ 1 ∀{j; j′} ∈ E

j∈V wjuj
uj ∈ {0; 1}:

∑

2

Without loss of generality one can assume wj > 0 and j ̸= j′ for all {j; j′} ∈ E. If the graph
(V;E) is bipartite  then we call the specialized problem VC-B and it can be solved very efﬁciently
by specialized bipartite maximum ﬂow algorithms such as [2].
A function f (x) is called submodular if f (x∧ y) + f (x∨ y) ≤ f (x) + f (y) for all x; y ∈ {0; 1}V
where (x ∧ y)j = xjyj and (x ∨ y)j = 1 − xjyj. A submodular function can be minimized in
strongly polynomial time by combinatorial methods [17]  but becomes NP-hard when subject to
arbitrary covering constraints like (3).
The submodular vertex-cover (SVC) problem generalizes VC by replacing the linear (modular)
objective (2) with an arbitrary submodular objective 

(SVC) minimize f (u)

subject to uj + uj′ ≥ 1 ∀{j; j′} ∈ E

uj ∈ {0; 1}:

Iwata & Nagano [18] recently showed that when f (·) ≥ 0 a 2-approximation can be found in
polynomial time and that this is the best constant-ratio bound achievable. It turns out that a half-
2 ; 1} (call this problem SVC-H)  followed by upward rounding  gives
integral relaxation uj ∈ {0; 1

(2)
(3)

(4)

a 2-approximation much like for standard VC. They also show how to transform any SVC-H
instance into a bipartite instance of SVC (see below); this extends a classic result by Nemhauser &
Trotter [28]  allowing specialized combinatorial algorithms like [17] to solve the relaxation.
In the bipartite submodular vertex-cover (SVC-B) problem  the graph nodes V can be partitioned
into sets J ;K so the binary variables are u ∈ {0; 1}J

; v ∈ {0; 1}K and we solve

(SVC-B) minimize f (u) + g(v)

subject to uj + vk ≥ 1 ∀{j; k} ∈ E

uj; vk ∈ {0; 1} ∀j ∈ J ; k ∈ K

(5)

where both f (·) and g(·) are submodular functions. This SVC-B formulation is a trivial extension
of the construction in [18] (they assume g = f)  and their proof of tractability extends easily to (5).

f (u) =

S∈S 0

∏

∑

∑

2.2 Solving Bipartite SVC with Min-Cut
It will be useful to note that if f and g above can be written in a special manner  SVC-B can
be solved by fast s-t minimum cut instead of by [17  15]. Suppose we have an SVC-B instance
(J ;K;E; f; g) where we can write submodular f and g as
wSuS; and g(v) =

(6)
Here S 0 and S 1 are collections of subsets of J and K respectively  and typescript uS denotes
product
Proposition 1. If wS ≤ 0 for all |S| ≥ 2 in (6)  then SVC-B reduces to s-t minimum cut.
Proof. We can deﬁne an equivalent problem over variables uj and zk = vk. With this substitution 
the covering constraints become uj ≥ zk. Since “g(v) submodular in v” implies “g(1−v) submod-
ular in v ” letting (cid:22)g(z) = g(z) = g(v) means (cid:22)g(z) is submodular as a function of z. Minimizing
f (u)+ (cid:22)g(z) subject to uj ≥ zk is equivalent to our original problem. Since uj ≥ zk can be enforced
by large (submodular) penalty on assignment ujzk  SVC-B is equivalent to
(cid:17) ujzk where (cid:17) = ∞.

j∈S uj throughout (as distinct from typescript u  which denotes a vector).

minimize f (u) + (cid:22)g(z) +

wSvS:

S∈S 1

∑
∑

(j;k)∈E

∏

(7)

When f and g take the form (6)  we have (cid:22)g(z) =
k∈S zk.
If wS ≤ 0 for all |S| ≥ 2  we can build an s-t minimum cut graph corresponding to (7) by directly
applying the constructions in [23  10]. We can do this because each term has coefﬁcient wS ≤ 0
when written as u1 ··· u|S| or z1 ··· z|S|  i.e. either all complemented or all uncomplemented.

S∈S 1 wSzS where zS denotes product

2.3 Transforming F (x) to SVC

To get a sense for how our transformation works  see Figure 1. The transformation is reminiscent of
the binary dual of a Constraint Satisfaction Problem (CSP) [37]. The vertex-cover construction of
[4] is actually a special linear (modular) case of our transformation (details in Proposition 2).

∑

7

i=1 aixi−b1x2x3x4x5x6−b2x1x2x3x4x5−b3x3x4x5x6x7.
Figure 1: Left: factor graph F (x) =
A small white square indicates ai > 0  a black square ai < 0. A hollow edge connecting xi to factor
j indicates i ∈ Pj  and a ﬁlled-in edge indicates i ∈ Qj. Right: factor graph of our corresponding
SVC instance. High-order factors of the original problem  shown with gray squares on the left  are
transformed into variables of SVC problem. Covering constraints are shown as dashed lines. Two
pairwise factors are formed with coefﬁcients w{1;3} = −a3 and w{1;2} = a4 + a5  both ≤ 0.

3

∗ ∈ {0; 1}V.

∗ ∈ {0; 1}I for
Theorem 1. For any F (x) there exists an instance of SVC such that an optimum x
F can be computed from an optimal vertex-cover u
Proof. First we give the construction for SVC instance (V;E; f ). Introduce auxiliary binary vari-
ables u ∈ {0; 1}V where uj = xPj xQj . Because each bj ≥ 0  minimizing F (x) is equivalent to the
0-1 integer program with non-linear constraints
minimize F (x; u)
subject to uj ≤ xPj xQj

(8)
Inequality (8) is sufﬁcient if bj ≥ 0 because  for any ﬁxed x  equality uj = xPj xQj holds for some
u that minimizes F (x; u).
We try to formulate a minimization problem solely over u. As a consequence of (8) we have uj =
0 ⇒ xPj = 1; xQj = 0. (We use typescript xS to denote vector (xi)i∈S  whereas xS denotes a
product—a scalar value.) Notice that  when some Pj and Qj′ overlap  not all u ∈ {0; 1}V can be
feasible with respect to assignments x ∈ {0; 1}I. For each i ∈ I  let us collect the cliques that i
participates in: deﬁne sets Ji; Ki ⊆ V where Ji = { j | i ∈ Pj} and Ki = { j | i ∈ Qj}. We show
≥ 1 for all i ∈ I  where uS denotes a product. In
that u can be feasible if and only if uJi + uKi
other words  u can be feasible if and only if  for each i 

∀j ∈ V:

∃ uj = 0; j ∈ Ji =⇒ uk = 1 ∀j ∈ Ki
∃ uk = 0; k ∈ Ki =⇒ uj = 1 ∀j ∈ Ji:

(9)
≥ 1 is necessary: if both uJi = 0 and
(⇒) If uj ≤ xPj xQj for all j ∈ V  then having uJi + uKi
uKi = 0 for any i it would mean there exists j ∈ Ji and k ∈ Ki for which xPj = 1 and xQk = 0 
contradicting any unique assignment to xi.
(⇐) If uJi + uKi
≥ 1 for all i ∈ I  then we can always choose some x ∈ {0; 1}I for which every
uj ≤ xPj xQj . It will be convenient to choose a minimum cost assignment for each xi  subject to the
constraints uJi = 0 ⇒ xi = 1 and uKi = 0 ⇒ xi = 0. If both uJi = uKi = 1 then xi could be
either 0 or 1 so choose the best  giving

{

x(u)i =

0
1

if uKi = 0
if uJi = 0
[ai < 0] otherwise.

The assignment x(u) is feasible with respect to (8) because for any uj = 1 we have x(u)Pj = 1
and x(u)Qj = 0.
≥ 1. To express
We have completed the proof that u can be feasible if and only if uJi + uKi
minimization of F solely in terms of u  ﬁrst write (10) in equivalent form

{

Again  this deﬁnition of x(u) minimizes F (x; u) over all x satisfying inequality (8). Use (11) to
write new SVC objective f (u) = F (x(u); u)  which becomes
−

bj(1 − uj)

f (u) =

aiuKi

x(u)i =

∑
∑

=

uKi
1 − uJi
∑

if ai < 0
otherwise.

∑

j∈V

∑

i : ai>0

i : ai<0

i : ai>0

i : ai<0

aiuKi +

bjuj + const:

j∈V

To collect coefﬁcients in the ﬁrst two summands of (12)  we must group them by each unique clique
that appears. We deﬁne set S = {S ⊆ V | (∃Ji = S) ∨ (∃Ki = S)} and write
)
+ bj if S = {j}

wSuS + const
−ai +

where wS =

∑

f (u) =

(

(13)

(14)

:

Since the high-order terms uS in (13) have non-positive coefﬁcients wS ≤ 0  then f (u) is submod-
ular [5]. Also note that for each i at most one of Ji or Ki contributes to the sum  so there are at most
|S| ≤ |I| unique terms uS with wS ̸= 0. If |S|;|V| ≪ |I| then our SVC instance will be small.
Finally  to ensure (9) holds we add a covering constraint uj + uk ≥ 1 whenever there exists i such
that j ∈ Ji; k ∈ Ki. For this SVC instance  an optimal covering u minimizes F (x(u); u).

(10)

(11)

(12)

∑
ai(1 − uJi) +
−aiuJi +
∑
∑

S∈S

i : ai>0;
Ji=S

ai
i : ai<0;
Ki=S

4

The construction in Theorem 1 suggests the entire minimization procedure below.

ai > 0 then wJi

MINIMIZE-BY-SVC(F ) where F is a pseudo-boolean function in the form of (1)
1 wfjg := bj 8j 2 V
2 for i 2 I do
∑
3
4
5
6 let f (u) =
(cid:3)
7 u
(cid:3)
8 return x(u

(cid:0) ai
if
else if ai < 0 then wKi := wKi + ai
E := E [ ffj; kgg 8j 2 Ji; k 2 Ki
:= SOLVE-SVC(V;E; f )

(distribute ai to high-order SVC coefﬁcients)
(where index sets Ji and Ki deﬁned in Theorem 1)
(cid:21) 1)
(add covering constraints to enforce uJi + uKi
(deﬁne SVC objective over clique indices V)
(solve with BP  QPBO  Iwata  etc.)
(decode the covering as in (10))

S2S wSuS

:= wJi

)

∏

∑

∑
≥ 1 (instead of O(|Ji|·|Ki|) constraints). An optimal covering y

One reviewer suggested an extension that scales better with the number of overlapping cliques. The
idea is to formulate SVC over the elements of S rather than V. Speciﬁcally  let y ∈ {0; 1}S and use
j∈S(bj + 1)yS y{j}  where the inner sum ensures
submodular objective f (y) =
j∈S y{j} at a local minimum because w{j} ≤ bj. For each unique pair {Ji; Ki}  add a
yS =
∗ of S
covering constraint yJi
then gives an optimal covering of V by assigning uj = y
∗
{j}. Here we use the original construction 
and still report signiﬁcant speedups. See [8] for discussion of efﬁcient implementation  and an
alternate proof of Theorem 1 based on LP relaxation.

S∈S wSyS +

+ yKi

2.4 Special Cases of Note
Proposition 2. If {Pj}j∈V are disjoint and  separately  {Qj}j∈V are disjoint (equivalently each
|Ji|;|Ki| ≤ 1)  then the SVC instance in Theorem 1 reduces to standard VC.
Proof. Each S ∈ S in objective (13) must be S = {j} for some j ∈ V. The objective then becomes
f (u) =

j∈V w{j}uj + const  a form of standard VC.

∑

Proposition 2 shows that the main result of [4] is a special case of our Theorem 1 when Ji = {j}
and Ki = {k} with j; k determined by two labelings being ‘fused’. In Section 3  this generalization
of [4] will allow us to apply a similar fusion-based algorithm to hierarchical clustering problems.
Proposition 3. If each particular j ∈ V has either Pj = {} or Qj = {}  then the construction in
Theorem 1 is an instance of SVC-B. Moreover  it is reducible to s-t minimum cut.
′ ∈ I  so sets J = {j : |Pj| ≥ 1} and
Proof. In this case Ji is disjoint with Ki′ for any i; i
K = {j : |Qj| ≥ 1} are disjoint. Since E contains pairs (j; k) with j ∈ J and k ∈ K  graph (V;E)
is bipartite. By the disjointness of any Ji and Ki′  the unique clique sets S can be partitioned into
S 0 = {S ⊆ J | ∃Ji = S} and S 1 = {S ⊆ K | ∃Ki = S} so that (13) can be written as in
Proposition 1 and thereby reduced to s-t minimum cut.
Corollary 1. If sets {Pj}j∈V and {Qj}j∈V satisfy the conditions of propositions 2 and 3  then
minimizing F (x) reduces to an instance of VC-B and can be solved by bipartite maximum ﬂow.

We should note that even though SVC has a 2-approximation algorithm [18]  this does not give us
a 2-approximation for minimizing F in general. Even if F (x) ≥ 0 for all x  it does not imply
f (u) ≥ 0 for conﬁgurations of u that violate the covering constraints  as would be required.

3 Applications

Even though any pseudo-boolean function can be expressed in form (1)  many interesting problems
would require an exponential number of terms to be expressed in that form. Only certain speciﬁc
applications will naturally have |V| ≪ |I|  so this is the main limitation of our approach. There may
be applications in high-order segmentation. For example  when P n-Potts potentials [19] are incor-
porated into (cid:11)-expansion  the resulting expansion step contains high-order terms that are compact
in this form; in the absence of pairwise CRF terms  Proposition 3 would apply.
The (cid:11)-expansion algorithm has also been extended to optimize the facility location objective [7]
commonly used for clustering (e.g. [24]). The resulting high-order terms inside the expansion step

5

Figure 2: Effectiveness of each algorithm as strength of high-order coefﬁcients is increased by factor
of (cid:21) ∈ {1::16}. For a ﬁxed (cid:21)  the ﬁnal energy of each algorithm was normalized between 0.0 (best
lower bound) and 1.0 (baseline ICM energy); the true energy gap between lower bound and baseline
is indicated at top  e.g. for (cid:21) = 1 the “lb+5” means ICM was typically within 5 of the lower bound.

also take the form (1) (in fact  Corollary 1 applies here); with no need to build the ‘full’ high-order
graph  this would allow (cid:11)-expansion to work as a fast alternative to the classic greedy algorithm
for facility location  very similar to the fusion-based algorithm in [4]. However  in Section 3.2 we
show that our generalized transformation allows for a novel way to optimize a hierarchical facility
location objective. We will use a recent geometric image parsing model [36] as a speciﬁc example.
First  Section 3.1 compares a number of methods on synthetic instances of energy (1).

3.1 Results on Synthetic Instances
Each instance is a function F (x) where x represents a 100 × 100 grid of binary variables with
random unary coefﬁcients ai ∈ [−10; 10]. Each instance also has |J | = 50 high-order cliques with
bj ∈ [250(cid:21); 500(cid:21)] (we will vary (cid:21))  where variable sets Pj and Qj each cover a random nj × nj and
mj × mj region respectively (here the region size nj; mj ∈ {10; : : : ; 15} is chosen randomly). If
Pj and Qj are not disjoint  then either Pj := Pj \ Qj or Qj := Qj \ Pj  as determined by a coin ﬂip.
We tested the following algorithms: BP [30]  TRW-S [21]  MPLP [33]  QPBO [14]  and extensions
QPBO-P and QPBO-I [32]. For BP we actually used the implementation provided by [21] which is
very fast but  we should note  does not support message-damping; convergence of BP may be more
reliable if this were supported. Algorithms were conﬁgured as follows: BP for 25 iterations (more
did not help); TRW-S for 800 iterations (epsilon 1); MPLP for 2000 initial iterations + 20 clusters
added + 100 iterations per tightening; QPBO-I with 5 random improve steps. We ran MPLP for a
particularly long time to ensure it had ample time to tighten and converge; indeed  it always yielded
the best lower bound. We also tested MINIMIZE-BY-SVC by applying each of these algorithms to
solve the resulting SVC problem  and in this case also tried the Iwata-Nagano construction [18].
To transform high-order potentials to quadratic  we report results using Type-II binary reduction [31]
∑
because for TRW-S/MPLP it dominated the Type-I reduction in our experiments  and for BP and the
others it made no difference. This runs counter to the conventional used of “number of supermodular
terms” as an estimate of difﬁculty: the Type-I reduction would generate one supermodular edge per
high-order term  whereas Type-II generates |Pj| supermodular edges for each term (
One minor detail is how to evaluate the ‘partial’ labelings returned by QPBO and QPBO-P. In the
case of minimizing F directly  we simply assigned such variables xi = [ai < 0]. In the case of
MINIMIZE-BY-SVC we included all unlabeled nodes in the cover  which means a variable xi with
uJi and uKi all unlabeled will similarly be assigned xi = [ai < 0].
Figure 2 shows the relative performance of each algorithm  on average. When (cid:21) = 1 the high-order
coefﬁcients are relatively weak compared to the unary terms  so even ICM succeeds at ﬁnding a
near-optimal energy. For larger (cid:21) the high-order terms become more important  and we make a
number of observations:

xiy).

i∈Pj

– ICM  BP  TRW-S  MPLP all perform much better when applied to the SVC problem.
– QPBO-based methods do not perform better when applied to the SVC problem.
– QPBO-I consistently gives good results; BP also gives good results if applied to SVC.
– The Iwata-Nagano construction is effectively the same as QBPO applied to SVC.

6

0.40.60.81ICMBPTRWSMPLPQPBOQPBOPlb+5+7300+20000+56000+12000000.2124816QPBOIλ =ICMSVC-ICMSVC-BPSVC-TRWSSVC-MPLPSVC-QPBOSVC-QPBOPlb+5+7300+20000+56000+120000124816SVC-QPBOPSVC-QPBOISVC-Iwataλ =We also observed that the TRW-S lower bound was the same with or without transformation to
SVC  but convergence took much fewer iterations when applied to SVC. In principle  TRW on
binary problems solves the same LP relaxation as QPBO [22]. The TRW-S code ﬁnds much better
solutions because it uses the ﬁnal messages as hints to decode a good solution  unlike for QPBO.
Table 1 gives typical running times for each of the cases in Figure 2 on a 2.66 GHz Intel Core2
processor. Code was written in C++  but the SVC transformation was not optimized at all. Still 
SVC-QBPOI is 20 times faster than QPBOI while giving similar energies on average. The overall
results suggest that SVC-BP or SVC-QPBOI are the fastest ways to ﬁnd a low-energy solution (bold
in Table 1) on problems containing many conﬂicting high-order terms of the form (1). Running
times were relatively consistent for all (cid:21) ≥ 2.

Table 1: Typical running times of each algorithm. First row uses Type-II binary reduction on F  
then directly runs each algorithm. Second row ﬁrst transforms to SVC  does Type-II reduction  runs
the algorithm  and decodes the result; times shown include all these steps.

directly minimize F

MINIMIZE-BY-SVC(F )

BP
22ms
5.2ms

TRW-S MPLP QPBO QPBO-P QPBO-I
670ms
140ms
7.2ms
19ms

25min
80sec

30ms
5.4ms

25sec
99ms

Iwata
N/A
5ms

3.2 Application: Hierarchical Model-Estimation / Clustering

∗ such that the crossover labeling l(x) = (lxi

In clustering and multi-model estimation  it is quite common to either explicitly constrain the num-
ber of clusters  or—more relevant to our work—to penalize the number of clusters in a solution.
Penalizing the number of clusters is a kind of complexity penalty on the solution. Recent examples
include [24  7  26]  but the basic idea has been used in many contexts over a long period. A classic
operations research problem with the same fundamental components is facility location: the clients
(data points) must be assigned to a nearby facility (cluster) but each facility costs money to open.
This can be thought of as a labeling problem  where each data point is a variable  and there is a label
for each cluster.
For hard optimization problems there is a particular algorithmic approach called fusion [27] or op-
timized crossover [1]. The basic idea is two take two candidate solutions (e.g. two attempts at clus-
tering)  and to ‘fuse’ the best parts of each solution  effectively stitching them together. To see this
more concretely  imagine a labeling problem where we wish to minimize E(l) where l = (li)i∈I
is a vector of label assignments. If l0 is the ﬁrst candidate labeling  and l1 is the second candidate
i )i∈I
labeling  a fusion operation seeks a binary string x
∗ identiﬁes the best possible ‘stitching’ of the two candidate
minimizes E(l(x)). In other words  x
solutions with respect to the energy.
In [4] we derived a fusion operation based on the greedy formulation of facility location  and found
that the subproblem reduced to minimum-weighted vertex-cover. We will now show that the fusion
operation for hierarchical facility location objectives requires minimizing an energy of the form (1) 
which we have already shown can be transformed to a submodular vertex-cover problem. Givoni
et al. [12] recently proposed a message-passing scheme for hierarchical facility location  with exper-
iments on synthetic and HIV strain data. We focus on more a computer vision-centric application:
detecting a hierarchy of lines and vanishing points in images using the geometric image parsing
objective proposed by Tretyak et al. [36].
The hierarchical energy proposed by [36] contains ﬁve ‘layers’: edges  line segments  lines  vanish-
ing points  and horizon. Each layer provides evidence for subsequent (higher) layers  and at each
level their is a complexity cost that regulates how much evidence is needed to detect a line  to detect
a vanishing point  etc. For simplicity we only model edges  lines  and vanishing points  but our
fusion-based framework easily extends to the full model. The purpose of our experiments are  ﬁrst
and foremost  to demonstrate that MINIMIZE-BY-SVC speeds up inference and  secondly  to sug-
gest that a hierarchical clustering framework based on fusion operations (similar to non-hierarchical
[4]) is an interesting and potentially worthwhile alternative to the greedy and local optimization used
in state-of-the-art methods like [36].

7

Let {yi}i∈I be a set of oriented edges yi = (xi; yi; i) where (x; y) is position in the image and 
is an angle; these bottom-level features are generated by a Canny edge detector. Let L be a set of
candidate lines  and let V be a set of candidate vanishing points. These sets are built by randomly
sampling: one oriented edge to generate each candidate line  and pairs of lines to generate each
candidate vanishing point. Each line j ∈ L is associated with one vanishing point kj ∈ V. (If a line
passes close to multiple vanishing points  a copy of the line is made for each.) We seek a labeling l
where li ∈ L ∪ ⊘ identiﬁes the line (and vanishing point) that edge i belongs to  or assigns outlier
label ⊘. Let Di(j) = distj(xi; yi) + distj( i) denote the spatial distance and angular deviation of
edge yi to line j  and let the outlier cost be Di(⊘) = const. Similarly  let Dj = distj(kj) be the
distance of line j and its associated vanishing point projected onto the Gaussian sphere (see [36]).
Finally let Cl and Cv denote positive constants that penalize the detection of a line and a vanishing
point respectively. The hierarchical energy we minimize is

∑

∑

E(l) =

Di(li) +

i∈I

j∈L

(Cl + Dj)·[∃li = j] +
∑

Cv·[∃kli = k]:
∑

This energy penalizes the number of unique lines  and the number of unique vanishing points that
labeling l depends on. Given two candidate labelings l0; l1  writing the fusion energy for (15) gives

i )xi +

− D0

E(l(x)) =

Cv·(1−xPk xQk )
k∈V
= k }  Qk = { i | kl1

(Cl + Dj)·(1−xPj xQj ) +
(16)
i + (D1
D0
i
j∈L
i = j }  and Pk = { i | kl0
= k }.
i = j }  Qj = { i | l1
where Pj = { i | l0
Notice that sets {Pj} are disjoint with each other  but each Pj is nested in subset Pkj   so overall
Proposition 2 does not apply  and so neither does the algorithm in [4].
For each image we used 10 000 edges  generated 8 000 candidate lines and 150 candidate vanishing
points. We then generated 4 candidate labelings  each by allowing vanishing points to be detected
in randomized order  and their associated lines to be detected in greedy order  and then we fused
the labelings together by minimizing (16). Overall inference with QPBOI took 2–6 seconds per
image  whereas SVC-QPBOI took 0.5-0.9 seconds per image with relative speedup of 4–6 times.
The simpliﬁed model is enough to show that hierarchical clustering can be done in this new and
potentially powerful way. As argued in [27]  fusion is a robust approach because it combines the
strengths—quite literally—of all methods used to generate candidates.

i

i

∑

k∈V

∑

i∈I

(15)

Figure 3: (Best seen in color.) Edge features color-coded by their detected vanishing point. Not
shown are the detected lines that make up the intermediate layer of inference (similar to [36]).
Images taken from York [9] and Eurasia [36] datasets.
Acknowledgements We thank Danny Tarlow for helpful discussion regarding MPLP  and an anonymous
reviewer for suggesting a more efﬁcient way to enforce covering constraints(!). This work supported by NSERC
Discovery Grant R3584A02  Canadian Foundation for Innovation (CFI)  and Early Researcher Award (ERA).

References

[1] Aggarwal  C.C.  Orlin  J.B.  & Tai  R.P. (1997) Optimized Crossover for the Independent Set Problem.

Operations Research 45(2):226–234.

[2] Ahuja  R.K.  Orlin  J.B.  Stein  C. & Tarjan  R.E. (1994) Improved algorithms for bipartite network ﬂow.

SIAM Journal on Computing 23(5):906–933.

[3] Ahuja  R.K.  Ergun  ¨O.  Orlin  J.B.  & Punnen  A.P. (2002) A survey of very large-scale neighborhood

search techniques. Discrete Applied Mathematics 123(1–3):75–202.

[4] Delong  A.  Veksler  O. & Boykov  Y. (2012) Fast Fusion Moves for Multi-Model Estimation. European

Conference on Computer Vision.

[5] Boros  E. & Hammer  P.L. (2002) Pseudo-Boolean Optimization. Discrete App. Math. 123(1–3):155–225.
[6] Boykov  Y.  Veksler  O.  & Zabih  R. (2001) Fast Approximate Energy Minimization via Graph Cuts.

IEEE Transactions on Pattern Recognition and Machine Intelligence. 23(11):1222–1239.

8

[7] Delong  A.  Osokin  A.  Isack  H.N.  & Boykov  Y. (20120) Fast Approximate Energy Minimization with

Label Costs. International Journal of Computer Vision 96(1):127. Earlier version in CVPR 2010.

[8] Delong  A.  Veksler  O.  Osokin  A.  & Boykov  Y. (2012) Minimizing Sparse High-Order Energies by

Submodular Vertex-Cover. Technical Report  Western University.

[9] Denis  P.  Elder  J.  & Estrada  F. (2008) Efﬁcient Edge-Based Methods for Estimating Manhattan Frames

in Urban Imagery. European Conference on Computer Vision.

[10] Freedman  D. & Drineas  P. (2005) Energy minimization via graph cuts: settling what is possible. IEEE

Conference on Computer Vision and Pattern Recognition.

[11] Gallagher  A.C.  Batra  D.  & Parikh  D. (2011) Inference for order reduction in Markov random ﬁelds.

IEEE Conference on Computer Vision and Pattern Recognition.

[12] Givoni  I.E.  Chung  C.  & Frey  B.J. (2011) Hierarchical Afﬁnity Propagation. Uncertainty in AI.
[13] Gupta  R.  Diwan  A.  & Sarawagi  S. (2007) Efﬁcient inference with cardinality-based clique potentials.

International Conference on Machine Learning.

[14] Hammer  P.L.  Hansen  P.  & Simeone  B. (1984) Roof duality  complementation and persistency in

quadratic 0-1 optimization. Mathematical Programming 28:121–155.

[15] Hochbaum  D.S. (2010) Submodular problems – approximations and algorithms. Arxiv preprint

arXiv:1010.1945.

[16] Iwata  S.  Fleischer  L. & Fujishige  S. (2001) A combinatorial  strongly polynomial-time algorithm for

minimizing submodular functions. Journal of the ACM 48:761–777.

[17] Iwata  S. & Orlin  J.B. (2009) A simple combinatorial algorithm for submodular function minimization.

ACM-SIAM Symposium on Discrete Algorithms.

[18] Iwata  S. & Nagano  K. (2009) Submodular Function Minimization under Covering Constraints. IEEE
[19] Kohli  P.  Kumar  M.P. & Torr  P.H.S. (2007) P 3 & Beyond: Solving Energies with Higher Order Cliques.

Symposium on Foundations of Computer Science.

IEEE Conference on Computer Vision and Pattern Recognition.

[20] Kolmogorov  V. (2010) Minimizing a sum of submodular functions. Arxiv preprint arXiv:1006.1990.
[21] Kolmogorov  V. (2006) Convergent Tree-Reweighted Message Passing for Energy Minimization. IEEE

Transactions on Pattern Analysis and Machine Intelligence 28(10):1568–1583.

[22] Kolmogorov  V.  & Wainwright  M.J. (2005) On the optimality of tree-reweighted max-product message-

passing. Uncertainty in Artiﬁcial Intelligence.

[23] Kolmogorov  V. & Zabih  R. (2004) What Energy Functions Can Be Optimized via Graph Cuts? IEEE

Transactions on Pattern Analysis and Machine Intelligence 26(2):147–159.

[24] Komodakis  N.  Paragios  N.  & Tziritas  G. (2008) Clustering via LP-based Stabilities. Neural Informa-

tion Processing Systems.

[25] Komodakis  N.  & Paragios  N. (2009) Beyond pairwise energies: Efﬁcient optimization for higher-order

MRFs. IEEE Computer Vision and Pattern Recognition.

[26] Ladick´y  L.  Russell  C.  Kohli  P.  & Torr  P.H.S (2010) Graph Cut based Inference with Co-occurrence

Statistics. European Conference on Computer Vision.

[27] Lempitsky  V.  Rother  C.  Roth  S.  & Blake  A. (2010) Fusion Moves for Markov Random Field

Optimization. IEEE Transactions on Pattern Analysis and Machine Inference. 32(9):1392–1405.

[28] Nemhauser  G.L. and Trotter  L.E. (1975) Vertex packings: Structural properties and algorithms.

Mathematical Programming 8(1):232–248.

[29] Osokin  A.  & Vetrov  D. (2012) Submodular relaxations for MRFs with high-order potentials. HiPot:

ECCV Workshop on Higher-Order Models and Global Constraints in Computer Vision.

[30] Pearl  J. (1988) Fusion  propagation  and structuring in belief networks. Artiﬁcial Intell. 29(3):251–288.
[31] Rother  C.  Kohli  P.  Feng  W.  & Jia  J. (2009) Minimizing sparse higher order energy functions of

discrete variables. IEEE Conference on Computer Vision and Pattern Recognition.

[32] Rother  C.  Kolmogorov  V.  Lempitsky  V.  & Szummer  M. (2007) Optimizing Binary MRFs via

Extended Roof Duality. IEEE Conference on Computer Vision and Pattern Recognition.

[33] Sontag  D.  Meltzer  T.  Globerson  A.  Jaakkola  T.  & Weiss  Y. (2008) Tightening LP relaxations for

MAP using message passing. Uncertainty in Artiﬁcial Intelligence.

[34] Tarlow  D.  Givoni  I.E.  & Zemel  R.S. (2010) HOPMAP: Efﬁcient message passing with high order

potentials. International Conference on Artiﬁcial Intelligence and Statistics.

[35] Tarlow  D.  & Zemel  R. (2012) Structured Output Learning with High Order Loss Functions. Interna-

tional Conference on Artiﬁcial Intelligence and Statistics.

[36] Tretyak  E.  Barinova  O.  Kohli  P.  & Lempitsky  V. (2011) Geometric Image Parsing in Man-Made

Environments. International Journal of Computer Vision 97(3):305–321.

[37] Tsang  E. (1993) Foundations of constraint satisfaction. Academic Press  London.
[38] Werner  T. (2008) High-arity Interactions  Polyhedral Relaxations  and Cutting Plane Algorithm for Soft

Constraint Optimisation (MAP-MRF). IEEE Conference on Computer Vision and Pattern Recognition.

9

,Kevin Jamieson
Daniel Haas
Benjamin Recht