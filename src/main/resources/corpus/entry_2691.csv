2019,Interlaced Greedy Algorithm for Maximization of Submodular Functions in Nearly Linear Time,A deterministic approximation algorithm is presented for the maximization of non-monotone submodular functions over a ground set of size $n$ subject to cardinality constraint $k$; the algorithm is based upon the idea of interlacing two greedy procedures. The algorithm uses interlaced  thresholded greedy procedures to obtain tight ratio $1/4 - \epsilon$ in $O \left( \frac{n}{\epsilon} \log \left( \frac{k}{\epsilon} \right) \right)$ queries of the objective function  which improves upon both the ratio and the quadratic time complexity of the previously fastest deterministic algorithm for this problem. The algorithm is validated in the context of two applications of non-monotone submodular maximization  on which it outperforms the fastest deterministic and randomized algorithms in prior literature.,Interlaced Greedy Algorithm for Maximization of

Submodular Functions in Nearly Linear Time

Alan Kuhnle

Department of Computer Science

Florida State University
Tallahassee  FL 32306
akuhnle@fsu.edu

Abstract

A deterministic approximation algorithm is presented for the maximization of
non-monotone submodular functions over a ground set of size n subject to cardi-
nality constraint k; the algorithm is based upon the idea of interlacing two greedy
procedures. The algorithm uses interlaced  thresholded greedy procedures to ob-

(cid:1)(cid:1) queries of the objective function  which

tain tight ratio 1/4 − ε in O(cid:0) n

ε log(cid:0) k

improves upon both the ratio and the quadratic time complexity of the previously
fastest deterministic algorithm for this problem. The algorithm is validated in
the context of two applications of non-monotone submodular maximization  on
which it outperforms the fastest deterministic and randomized algorithms in prior
literature.

ε

1

Introduction

A nonnegative function f deﬁned on subsets of a ground set U of size n is submodular iff for all
A  B ⊆ U  x ∈ U \ B  such that A ⊆ B  it holds that f (B ∪ x) − f (B) ≤ f (A ∪ x) − f (A).
Intuitively  the property of submodularity captures diminishing returns. Because of a rich variety of
applications  the maximization of a nonnegative submodular function with respect to a cardinality
constraint (MCC) has a long history of study (Nemhauser et al.  1978). Applications of MCC
include viral marketing (Kempe et al.  2003)  network monitoring (Leskovec et al.  2007)  video
summarization (Mirzasoleiman et al.  2018)  and MAP Inference for Determinantal Point Processes
(Gillenwater et al.  2012)  among many others. In recent times  the amount of data generated by many
applications has been increasing exponentially; therefore  linear or sublinear-time algorithms are
needed.
If a submodular function f is monotone1  greedy approaches for MCC have proven effective and
nearly optimal  both in terms of query complexity and approximation factor: subject to a cardinality
constraint k  a simple greedy algorithm gives a (1 − 1/e) approximation ratio in O(kn) queries
(Nemhauser et al.  1978)  where n is the size of the instance. Furthermore  this ratio is optimal
under the value oracle model (Nemhauser and Wolsey  1978). Badanidiyuru and Vondrák (2014)
the approximation ratio  while Mirzasoleiman et al. (2015) developed a randomized (1 − 1/e − ε)
approximation in O(n/ε) queries.
When f is non-monotone  the situation is very different; no subquadratic deterministic algorithm has
yet been developed. Although a linear-time  randomized (1/e− ε)-approximation has been developed

sped up the greedy algorithm to require O(cid:0) n
by Buchbinder et al. (2015)  which requires O(cid:0) n

(cid:1) queries while sacriﬁcing only a small ε > 0 in
(cid:1) queries  the performance guarantee of this

ε log n

ε

algorithm holds only in expectation. A derandomized version of the algorithm with ratio 1/e has been

ε2 log 1

ε

1The function f is monotone if for all A ⊆ B  f (A) ≤ f (B).

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

Table 1: Fastest algorithms for cardinality constraint

Time complexity Deterministic?

Algorithm

FastInterlaceGreedy (Alg. 2)

Gupta et al. (2010)

Buchbinder et al. (2015)

Ratio
1/4 − ε
1/6 − ε
1/e − ε

O(cid:0) n
O(cid:0)nk + n
O(cid:0) n

ε log k

ε2 log 1

ε

(cid:1)
(cid:1)
(cid:1)

ε

ε

Yes
Yes
No

developed by Buchbinder and Feldman (2018a) but has time complexity O(k3n). Therefore  in this
work  an emphasis is placed upon the development of nearly linear-time  deterministic approximation
algorithms.

Contributions

ε

ε log k

The deterministic approximation algorithm InterlaceGreedy (Alg. 1) is provided for maximization
of a submodular function subject to a cardinality constraint (MCC). InterlaceGreedy achieves ratio
1/4 in O(kn) queries to the objective function. A faster version of the algorithm is formulated in

FastInterlaceGreedy (Alg. 2)  which achieves ratio (1/4 − ε) in O(cid:0) n

(cid:1) queries. In Table 1 

the relationship is shown to the fastest deterministic and randomized algorithms for MCC in prior
literature.
Both algorithms operate by interlacing two greedy procedures together in a novel manner; that is 
the two greedy procedures alternately select elements into disjoint sets and are disallowed from
selection of the same element. This technique is demonstrated ﬁrst with the interlacing of two
standard greedy procedures in InterlaceGreedy  before interlacing thresholded greedy procedures
developed by Badanidiyuru and Vondrák (2014) for monotone submodular functions to obtain the
algorithm FastInterlaceGreedy.
The algorithms are validated in the context of cardinality-constrained maximum cut and social
network monitoring  which are both instances of MCC. In this evaluation  FastInterlaceGreedy
is more than an order of magnitude faster than the fastest deterministic algorithm (Gupta et al. 
2010) and is both faster and obtains better solution quality than the fastest randomized algorithm
(Buchbinder et al.  2015). The source code for all implementations is available at https://gitlab.
com/kuhnle/non-monotone-max-cardinality.

Organization The rest of this paper is organized as follows. Related work and preliminaries on
submodular optimization are discussed in the rest of this section. In Section 2  InterlaceGreedy and
FastInterlaceGreedy are presented and analyzed. Experimental validation is provided in Section 4.

Related Work

to obtain the same ratio in O(cid:0) n

The literature on submodular optimization comprises many works. In this section  a short review of
relevant techniques is given for MCC; that is  maximization of non-monotone  submodular functions
over a ground set of size n with cardinality constraint k. For further information on other types of
submodular optimization  interested readers are directed to the survey of Buchbinder and Feldman
(2018b) and references therein.
A deterministic local search algorithm was developed by Lee et al. (2010)  which achieves ratio
1/4 − ε in O(n4 log n) queries. This algorithm runs two approximate local search procedures in
succession. By contrast  the algorithm FastInterlaceGreedy employs interlacing of greedy procedures
formulated by Vondrák (2013)  which achieves ratio ≈ 0.309 in expectation.
Gupta et al. (2010) developed a deterministic  iterated greedy approach  wherein two greedy pro-
cedures are run in succession and an algorithm for unconstrained submodular maximization are
employed. This approach requires O(nk) queries and has ratio 1/(4 + α)  where α is the inverse
ratio of the employed subroutine for unconstrained  non-monotone submodular maximization; under
the value query model  the smallest possible value for α is 2  as shown by Feige et al. (2011)  so
this ratio is at most 1/6. The iterated greedy approach of Gupta et al. (2010) ﬁrst runs one standard
greedy algorithm to completion  then starts a second standard greedy procedure; this differs from
the interlacing procedure which runs two greedy procedures concurrently and alternates between

(cid:1) queries. In addition  a randomized local search algorithm was

ε log k

ε

2

the selection of elements. The algorithm of Gupta et al. (2010) is experimentally compared to
FastInterlaceGreedy in Section 4. The iterated greedy approach of Gupta et al. (2010) was extended
and analyzed under more general constraints by a series of works: Mirzasoleiman et al. (2016);
Feldman et al. (2017); Mirzasoleiman et al. (2018).
An elegant randomized greedy algorithm of Buchbinder et al. (2014) achieves expected ratio 1/e
in O(kn) queries for MCC; this algorithm was derandomized by Buchbinder and Feldman (2018a) 

but the derandomized version requires O(cid:0)k3n(cid:1) queries. The randomized version was sped up in
Buchbinder et al. (2015) to achieve expected ratio 1/e−ε and require O(cid:0) n
(cid:1) queries. Although

this algorithm has better time complexity than FastInterlaceGreedy  the ratio of 1/e − ε holds only
in expectation  which is much weaker than a deterministic approximation ratio. The algorithm of
Buchbinder et al. (2015) is experimentally evaluated in Section 4.
Recently  an improvement in the adaptive complexity of MCC was made by Balkanski et al. (2018).

Their algorithm  BLITS  requires O(cid:0)log2 n(cid:1) adaptive rounds of queries to the objective  where

ε2 log 1

ε

the queries within each round are independent of one another and thus can be parallelized easily.
Previously the best adaptivity was the trivial O(n). However  each round requires Ω(OP T 2) samples
to approximate expectations  which for the applications evaluated in Section 4 is Ω(n4). For this
reason  BLITS is evaluated as a heuristic in comparison with the proposed algorithms in Section 4.
Further improvements in adaptive complexity have been made by Fahrbach et al. (2019) and Ene and
Nguyen (2019).
Streaming algorithms for MCC make only one or a few passes through the ground set. Streaming
algorithms for MCC include those of Chekuri et al. (2015); Feldman et al. (2018); Mirzasoleiman
et al. (2018). A streaming algorithm with low adaptive complexity has recently been developed by
Kazemi et al. (2019). In the following  the algorithms are allowed to make an arbitrary number of
passes through the data.
Currently  the best approximation ratio of any algorithm for MCC is 0.385 of Buchbinder and
Feldman (2016). Their algorithm also works under a more general constraint than cardinality
constraint; namely  a matroid constraint. This algorithm is the latest in a series of works (e.g. (Naor
and Schwartz  2011; Ene and Nguyen  2016)) using the multilinear extension of a submodular
function  which is expensive to evaluate.

Preliminaries
Given n ∈ N  the notation [n] is used for the set {0  1  . . .   n − 1}. In this work  functions f with
domain all subsets of a ﬁnite set are considered; hence  without loss of generality  the domain of
the function f is taken to be 2[n]  which is all subsets of [n]. An equivalent characterization of
submodularity is that for each A  B ⊆ [n]  f (A ∪ B) + f (A ∩ B) ≤ f (A) + f (B). For brevity  the
notation fx(A) is used to denote the marginal gain f (A ∪ {x}) − f (A) of adding element x to set A.
In the following  the problem studied is to maximize a submodular function under a cardinality
constraint (MCC)  which is formally deﬁned as follows. Let f : 2n → R+ be submodular; let k ∈ [n].
Then the problem is to determine

arg max
A⊆[n]:|A|≤k

f (A).

An instance of MCC is the pair (f  k); however  rather than an explicit description of f  the function
f is accessed by a value oracle; the value oracle may be queried on any set A ⊆ [n] to yield f (A).
The efﬁciency or runtime of an algorithm is measured by the number of queries made to the oracle
for f.
Finally  without loss of generality  instances of MCC considered in the following satisfy n ≥ 4k. If
this condition does not hold  the function may be extended to [m] by adding dummy elements to the
domain which do not change the function value. That is  the function g : 2m → R+ is deﬁned as
g(A) = f (A ∩ [n]); it may be easily checked that g remains submodular  and any possible solution
to the MCC instance (g  k) maps2 to a solution of (f  k) of the same value. Hence  the ratio of any
solution to (g  k) to the optimal is the same as the ratio of the mapped solution to the optimal on
(f  k).

2The mapping is to discard all elements greater than n.

3

2 Approximation Algorithms

In this section  the approximation algorithms based upon interlacing greedy procedures are pre-
sented. In Section 2.1  the technique is demonstrated with standard greedy procedures in algorithm
InterlaceGreedy. In Section 2.2  the nearly linear-time algorithm FastInterlaceGreedy is introduced.

2.1 The InterlaceGreedy Algorithm

In this section  the InterlaceGreedy algorithm (InterlaceGreedy  Alg. 1) is introduced. InterlaceGreedy
takes as input an instance of MCC and outputs a set C.

ai ← arg maxx∈[n]\(Ai∪Bi) fx(Ai)
bi ← arg maxx∈[n]\(Ai+1∪Bi) fx(Bi)

Algorithm 1 InterlaceGreedy (f  k): The InterlaceGreedy Algorithm
1: Input: f : 2[n] → R+  k ∈ [n]
2: Output: C ⊆ [n]  such that |C| ≤ k.
3: A0 ← B0 ← ∅
4: for i ← 0 to k − 1 do
5:
6: Ai+1 ← Ai + ai
7:
8: Bi+1 ← Bi + bi
9: D1 ← E1 ← {a0}
10: for i ← 1 to k − 1 do
di ← arg maxx∈[n]\(Di∪Ei) fx(Di)
11:
12: Di+1 ← Di + di
ei ← arg maxx∈[n]\(Di+1∪Ei) fx(Ei)
13:
Ei+1 ← Ei + ei
14:
15: return C ← arg max{f (Ai)  f (Bi)  f (Di)  f (Ei) : i ∈ [k + 1]}

InterlaceGreedy operates by interlacing two standard greedy procedures. This interlacing is ac-
complished by maintaining two disjoint sets A and B  which are initially empty. For k iterations 
the element a (cid:54)∈ B with the highest marginal gain with respect to A is added to A  followed by
an analogous greedy selection for B; that is  the element b (cid:54)∈ A with the highest marginal gain
with respect to B is added to B. After the ﬁrst set of interlaced greedy procedures complete  a
modiﬁed version is repeated with sets D  E  which are initialized to the maximum-value singleton
{a0}. Finally  the algorithm returns the set with the maximum f-value of any query the algorithm
has made to f.
If f is submodular  InterlaceGreedy has an approximation ratio of 1/4 and query complexity O(kn);
the deterministic algorithm of Gupta et al. (2010) has the same time complexity to achieve ratio 1/6.
The full proof of Theorem 1 is provided in Appendix A.
Theorem 1. Let f : 2[n] → R+ be submodular  let k ∈ [n]  let O = arg max|S|≤k f (S)  and let
C = InterlaceGreedy (f  k). Then

f (C) ≥ f (O)/4 

and InterlaceGreedy makes O(kn) queries to f.

Proof sketch. The argument of Fisher et al. (1978) shows that the greedy algorithm is a (1/2)-
approximation for monotone submodular maximization with respect to a matroid constraint. This
argument also applies to non-monotone  submodular functions  but it shows only that f (S) ≥
2 f (O ∪ S)  where S is returned by the greedy algorithm. Since f is non-monotone  it is possible for
f (O ∪ S) < f (S). The main idea of the InterlaceGreedy algorithm is to exploit the fact that if S and
T are disjoint 

1

f (O ∪ S) + f (O ∪ T ) ≥ f (O) + f (O ∪ S ∪ T ) ≥ f (O) 

(1)
which is a consequence of the submodularity of f. Therefore  by interlacing two greedy procedures 
2 f (O ∪ A) and
two disjoint sets A B are obtained  which can be shown to almost satisfy f (A) ≥ 1
f (B) ≥ 1
2 f (O ∪ B)  after which the result follows from (1). There is a technicality wherein the
element a0 must be handled separately  which requires the second round of interlacing to address.

4

2.2 The FastInterlaceGreedy Algorithm

In this section  a faster interlaced greedy algorithm (FastInterlaceGreedy (FIG)  Alg. 2) is formulated 
which requires O(n log k) queries. As input  an instance (f  k) of MCC is taken  as well as a
parameter δ > 0.

Algorithm 2 FIG (f  k  δ): The FastInterlaceGreedy Algorithm
1: Input: f : 2[n] → R+  k ∈ [n]
2: Output: C ⊆ [n]  such that |C| ≤ k.
3: A0 ← B0 ← ∅
4: M ← τA ← τB ← maxx∈[n] f (x)
5: i ← −1  a−1 ← 0  b−1 ← 0
6: while τA ≥ δM/k or τB ≥ δM/k do
(ai+1  τA) ← ADD(A  B  ai  τA)
7:
(bi+1  τB) ← ADD(B  A  bi  τB)
8:
i ← i + 1
9:
10: D1 ← E1 ← {a0}  τD ← τE ← M
11: i ← 0  d0 ← 0  e0 ← 0
12: while τD ≥ δM/k or τE ≥ δM/k do
13:
14:
15:
16: return C ← arg max{f (A)  f (B)  f (D)  f (E)}

(di+1  τD) ← ADD(D  E  di  τD)
(ei+1  τE) ← ADD(E  D  ei  τE)
i ← i + 1

return (0  (1 − δ)τ )
for (x ← j; x < n; x ← x + 1) do

Algorithm 3 ADD (S  T  j  τ ): The ADD subroutine
1: Input: Two sets S  T ⊆ [n]  element j ∈ [n]  τ ∈ R+
2: Output: (i  τ )  such that i ∈ [n]  τ ∈ R+
3: if |S| = k then
4:
5: while τ ≥ δM/k do
6:
if x (cid:54)∈ T then
7:
8:
9:
10:
11:
12:
13: return (0  τ )

if fx(S) ≥ τ then
S ← S ∪ {x}
return (x  τ )

τ ← (1 − δ)τ
j ← 0

The algorithm FIG works as follows. As in InterlaceGreedy  there is a repeated interlacing of two
greedy procedures. However  to ensure a faster query complexity  these greedy procedures are
thresholded: a separate threshold τ is maintained for each of the greedy procedures. The interlacing
is accomplished by alternating calls to the ADD subroutine (Alg. 3)  which adds a single element
and is described below. When all of the thresholds fall below the value δM/k  the maximum of
the greedy solutions is returned; here  δ > 0 is the input parameter  M is the maximum value of a
singleton  and k ≤ n is the cardinality constraint.
The ADD subroutine is responsible for adding a single element above the input threshold and decreasing
the threshold. It takes as input four parameters: two sets S  T   element j  and threshold τ; furthermore 
ADD is given access to the oracle f  the budget k  and the parameter δ of FIG. As an overview  ADD
adds the ﬁrst3 element x ≥ j  such that x (cid:54)∈ T and such that the marginal gain fx(S) is at least τ. If
no such element x ≥ j exists  the threshold is decreased by a factor of (1 − δ) and the process is
repeated (with j set to 0). When such an element x is found  the element x is added to S  and the new
threshold value and position x are returned. Finally  ADD ensures that the size of S does not exceed k.
Next  the approximation ratio of FIG is proven.

3The ﬁrst element x > j in the natural ordering on [n] = {0  . . .   n − 1}.

5

Theorem 2. Let f : 2[n] → R+ be submodular  let k ∈ [n]  and let ε > 0. Let O =
arg max|S|≤k f (S). Choose δ such that (1 − 6δ)/4 > 1/4 − ε  and let C = FIG (f  k  δ). Then

f (C) ≥ (1 − 6δ)f (O)/4 ≥ (1/4 − ε) f (O).

Proof. Let A  B  C  D  E  M have their values at
Let A =
{a0  . . .   a|A|−1} be ordered by addition of elements by FIG into A. The proof requires the fol-
lowing four inequalities:

termination of FIG(f  k  δ).

f (O ∪ A) ≤ (2 + 2δ)f (A) + δM 
f ((O \ {a0}) ∪ B) ≤ (2 + 2δ)f (B) + δM 
f (O ∪ D) ≤ (2 + 2δ)f (D) + δM 
f (O ∪ E) ≤ (2 + 2δ)f (E) + δM.

(2)
(3)
(4)
(5)
Once these inequalities have been established  Inequalities 2  3  submodularity of f  and A ∩ B = ∅
imply
Similarly  from Inequalities 4  5  submodularity of f  and D ∩ E = {a0}  it holds that

f (O \ {a0}) ≤ 2(1 + δ)(f (A) + f (B)) + 2δM.
f (O ∪ {a0}) ≤ 2(1 + δ)(f (D) + f (E)) + 2δM.

Hence  from the fact that either a0 ∈ O or a0 (cid:54)∈ O and the deﬁnition of C  it holds that

(7)

(6)

f (O) ≤ 4(1 + δ)f (C) + 2δM.

Since f (C) ≤ f (O) and M ≤ f (O)  the theorem is proved.
The proofs of Inequalities 2–5 are similar. The proof of Inequality 3 is given here  while the proofs of
the others are provided in Appendix B.
Proof of Inequality 3. Let A = {a0  . . .   a|A|−1} be ordered as speciﬁed by FIG. Likewise  let
B = {b0  . . .   b|B|−1} be ordered as speciﬁed by FIG.
Lemma 1. O \ (B ∪ {a0}) = {o0  . . .   ol−1} can be ordered such that

foi(Bi) ≤ (1 + 2δ)fbi(Bi) 

(8)

for any i ∈ [|B|].
Proof. For each i ∈ [|B|]  deﬁne τBi to be the value of τ when bi was added into B by the ADD
subroutine. Order o ∈ (O \ (B ∪ {a0})) ∩ A = {o0  . . .   o(cid:96)−1} by the order in which these elements
were added into A. Order the remaining elements of O \ (B ∪ {a0}) arbitrarily. Then  when bi w;as
chosen by ADD  it holds that oi (cid:54)∈ Ai+1  since A1 = {a0} and a0 (cid:54)∈ O \ (B ∪ {a0}). Also  it holds
that oi (cid:54)∈ Bi since Bi ⊆ B; hence oi was not added into some (possibly non-proper) subset B(cid:48)
i of
Bi at the previous threshold value τBi
(1−δ). Since
fbi(Bi) ≥ τBi and δ < 1/2  inequality (8) follows.
Order ˆO = O \ (B ∪ {a0}) = {o0  . . .   ol−1} as deﬁned in the proof of Lemma 1  and let ˆOi =
{o0  . . .   oi−1}  if i ≥ 1  and let ˆO0 = ∅. Then

(1−δ). By submodularity  foi(Bi) ≤ foi(B(cid:48)

i) < τBi

(1 + 2δ)fbi(Bi) +

foi(B)

f ( ˆO ∪ B) − f (B) =

=

≤

≤

i=0

l−1(cid:88)
foi( ˆOi ∪ B)
|B|−1(cid:88)
|B|−1(cid:88)
|B|−1(cid:88)

foi( ˆOi ∪ B) +
l−1(cid:88)

foi (Bi) +

i=0

i=0

i=|B|

i=0

≤ (1 + 2δ)f (B) + δM 

6

l−1(cid:88)

i=|B|

foi ( ˆOi ∪ B)

foi(B)

l−1(cid:88)

i=|B|

where any empty sum is deﬁned to be 0; the ﬁrst inequality follows by submodularity  the second
follows from Lemma 1  and the third follows from the deﬁnition of B  and the facts that  for any i
such that |B| ≤ i < l  maxx∈[n]\A|B|+1 fx(B) < δM/k  l − |B| ≤ k  and oi (cid:54)∈ A|B|+1.
Theorem 3. Let f : 2[n] → R+ be submodular  let k ∈ [n]  and let δ > 0. Then the number of

queries to f by FIG(f  k  δ) is at most O(cid:0) n

(cid:1).

δ log k

δ

Proof. Recall [n] = {0  1  . . .   n − 1}. Let S ∈ {A  B  D  E}  and S = {s0  . . .   s|S|−1} in the
order in which elements were added to S. When ADD is called by FIG to add an element si ∈ [n] to
S  if the value of τ is the same as the value when si−1 was added to S  then si > si−1. Finally  once
ADD queries the marginal gain of adding (n − 1)  the threshold is revised downward by a factor of
(1 − δ).
Therefore  there are at most O(n) queries of f at each distinct value of τA  τB  τD  τE. Since at most
O( 1

δ ) values are assumed by each of these thresholds  the theorem follows.

δ log k

3 Tight Examples

In this section  examples are provided showing that InterlaceGreedy or FastInterlaceGreedy may
achieve performance ratio at most 1/4 + ε on speciﬁc instances  for each ε > 0. These examples
show that the analysis in the preceding sections is tight.
Let ε > 0 and choose k such that 1/k < ε. Let O and D be disjoint sets each of k distinct elements;
and let U = O ˙∪{a  b} ˙∪D. A submodular function f will be deﬁned on subsets of U as follows.
Let C ⊆ U.

• If both a ∈ C and b ∈ C  then f (C) = 0.
|C∩O|
• If a ∈ C xor b ∈ C  then f (C) =
k .
2k + 1
|C∩O|
• If a (cid:54)∈ C and b (cid:54)∈ C  then f (C) =

.

k

The following proposition is proved in Appendix D.
Proposition 1. The function f is submodular.
Next  observe that for any o ∈ O  fa(∅) = fb(∅) = fo(∅) = 1/k. Hence InterlaceGreedy or
FastInterlaceGreedy may choose a0 = a and b0 = b; after this choice  the only way to increase f
is by choosing elements of O. Hence ai  bi will be chosen in O until elements of O are exhausted 
which results in k/2 elements of O added to each of A and B. Thereafter  elements of D will be
chosen  which do not affect the function value. This yields

f (A) = f (B) ≤ 1/k + 1/4.

Next  D1 = E1 = {a}  and a similar situation arises  in which k/2 elements of O are added to D  E 
yielding f (D) = f (E) = f (A). Hence InterlaceGreedy or FastInterlaceGreedy may return A  while
f (O) = 1. So f (A)

f (O) ≤ 1/k + 1/4 ≤ 1/4 + ε.

4 Experimental Evaluation

In this section  performance of FastInterlaceGreedy (FIG) is compared with that of state-of-the-art
algorithms on two applications of submodular maximization: cardinality-constrained maximum cut
and network monitoring.

4.1 Setup

Algorithms The following algorithms are compared.
ated implementations of all algorithms
non-monotone-max-cardinality.

the evalu-
is available at https://gitlab.com/kuhnle/

Source code for

7

• FastInterlaceGreedy (Alg. 2): FIG is implemented as speciﬁed in the pseudocode  with the
following addition: a stealing procedure is employed at the end  which uses submodularity
to quickly steal4 elements from A  B  D  E into C in O(k) queries. This does not impact
the performance guarantee  as the value of C can only increase. The parameter δ is set to
0.1  yielding approximation ratio of 0.1.

• Gupta et al. (2010): The algorithm of Gupta et al. (2010) for cardinality constraint; as the
subroutine for the unconstrained maximization subproblems  the deterministic  linear-time
1/3-approximation algorithm of Buchbinder et al. (2012) is employed. This yields an overall
approximation ratio of 1/7 for the implementation used herein. This algorithm is the fastest
determistic approximation algorithm in prior literature.

(cid:1) randomized algorithm of Buchbinder et al.
• FastRandomGreedy (FRG): The O(cid:0) n
• BLITS: The O(cid:0)log2 n(cid:1)-adaptive algorithm recently introduced in Balkanski et al. (2018);

(2015) (Alg. 4 of that paper)  with expected ratio 1/e − ε; the parameter ε was set to
0.3  yielding expected ratio of ≈ 0.07 as evaluated herein. This algorithm is the fastest
randomized approximation algorithm in prior literature.

ε2 ln 1

ε

the algorithm is employed as a heuristic without performance ratio  with the same parameter
choices as in Balkanski et al. (2018). In particular  ε = 0.3 and 30 samples are used to
approximate the expections. Also  a bound on OPT is guessed in logarithmically many
iterations as described in Balkanski et al. (2018) and references therein.

Results for randomized algorithms are the mean of 10 trials  and the standard deviation is represented
in plots by a shaded region.

Applications Many applications with non-monotone  submodular objective functions exist. In this
section  two applications are chosen to demonstrate the performance of the evaluated algorithms.

• Cardinality-Constrained Maximum Cut: The archetype of a submodular  non-monotone
function is the maximum cut objective: given graph G = (V  E)  S ⊆ V   f (S) is deﬁned to
be the number of edges crossing from S to V \ S. The cardinality constrained version of
this problem is considered in the evaluation.

• Social Network Monitoring: Given an online social network  suppose it is desired to choose
k users to monitor  such that the maximum amount of content is propagated through these
users. Suppose the amount of content propagated between two users u  v is encoded as

weight w(u  v). Then f (S) =(cid:80)

u∈S v(cid:54)∈S w(u  v).

4.2 Results

In this section  results are presented for the algorithms on the two applications. In overview: in terms
of objective value  FIG and Gupta et al. (2010) were about the same and outperformed BLITS and
FRG. Meanwhile  FIG was the fastest algorithm by the metric of queries to the objective and was
faster than Gupta et al. (2010) by at least an order of magnitude.

Cardinality Constrained MaxCut For these experiments  two random graph models were em-
ployed: an Erd˝os-Rényi (ER) random graph with 1  000 nodes and edge probability p = 1/2  and a
Barabási–Albert (BA) graph with n = 10  000 and m = m0 = 100.
On the ER graph  results are shown in Figs. 1(a) and 1(b); the results on the BA graph are shown in
Figs. 1(c) and 1(d). In terms of cut value  the algorithm of Gupta et al. (2010) performed the best 
although the value produced by FIG was nearly the same. On the ER graph  the next best was FRG
followed by BLITS; whereas on the BA graph  BLITS outperformed FRG in cut value. In terms of
efﬁciency of queries  FIG used the smallest number on every evaluated instance  although the number
did increase logarithmically with budget. The number of queries used by FRG was higher  but after
a certain budget remained constant. The next most efﬁcient was Gupta et al. (2010) followed by
BLITS.

4Details of the stealing procedure are given in Appendix C.

8

(a) ER  Cut Value

(b) ER  Function Queries

(c) BA  Cut Value

(d) BA  Function Queries

(e) Total content monitored versus
budget k

(f) Number of Queries versus bud-
get k

Figure 1: (a)–(d): Objective value and runtime for cardinality-constrained maxcut on random graphs.
(e)–(f): Objective value and runtime for cardinality-constrained maxcut on ca-AstroPh with simulated
amounts of content between users. In all plots  the x-axis shows the budget k.

(a) ER instance  n = 1000

(b) BA instance  n = 10000

Figure 2: Effect of stealing procedure on solution quality of FIG.

Social Network Monitoring For the social network monitoring application  the citation network
ca-AstroPh from the SNAP dataset collection was used  with n = 18  772 users and 198  110 edges.
Edge weights  which represent the amount of content shared between users  were generated uniformly
randomly in [1  10]. The results were similar qualitatively to those for the unweighted MaxCut
problem presented previously. FIG is the most efﬁcient in terms of number of queries  and FIG is
only outperformed in solution quality by Gupta et al. (2010)  which required more than an order of
magnitude more queries.

Effect of Stealing Procedure
In Fig. 2 above  the effect of removing the stealing procedure is
shown on the random graph instances. Let CF IG be the solution returned by FIG  and CF IG∗ be
the solution returned by FIG with the stealing procedure removed. Fig. 2(a) shows that on the ER
instance  the stealing procedure adds at most 1.5% to the solution value; however  on the BA instance 
Fig. 2(b) shows that the stealing procedure contributes up to 45% increase in solution value  although
this effect degrades with larger k. This behavior may be explained by the interlaced greedy process
being forced to leave good elements out of its solution  which are then recovered during the stealing
procedure.

9

200400k2.55.07.510.012.5Value x 104FIGBlitsFRGGupta et al.200400k104105106Number of QueriesFIGBlitsFRGGupta et al.10002000k7.510.012.515.0Value x 104FIGBlitsFRGGupta et al.10002000k106107108Number of QueriesFIGBlitsFRGGupta et al.2505007501000k1234Value x 105FIGBlitsFRGGupta et al.2505007501000k106107108Number of QueriesFIGBlitsFRGGupta et al.100200300400k1.0051.0101.015f(CFIG)/f(CFIG*)500100015002000k1.21.31.4f(CFIG)/f(CFIG*)5 Acknowledgements

The work of A. Kuhnle was partially supported by Florida State University and the Informatics
Institute of the University of Florida. Victoria G. Crawford and the anonymous reviewers provided
helpful feedback which improved the paper.

References
Ashwinkumar Badanidiyuru and Jan Vondrák. Fast algorithms for maximizing submodular functions.

ACM-SIAM Symposium on Discrete Algorithms (SODA)  2014.

Eric Balkanski  Adam Breuer  and Yaron Singer. Non-monotone Submodular Maximization in
Exponentially Fewer Iterations. In Advances in Neural Information Processing Systems (NeurIPS) 
2018.

Niv Buchbinder and Moran Feldman. Constrained Submodular Maximization via a Non-symmetric

Technique. In arXiv preprint arXiv:1611.03253v1  2016.

Niv Buchbinder and Moran Feldman. Deterministic Algorithms for Submodular Maximization. ACM

Transactions on Algorithms  14(3)  2018a.

Niv Buchbinder and Moran Feldman. Submodular Functions Maximization Problems – A Survey. In
Teoﬁlo F. Gonzalez  editor  Handbook of Approximation Algorithms and Metaheuristics. Second
edition  2018b.

Niv Buchbinder  Moran Feldman  Joseph Sefﬁ Naor  and Roy Schwartz. A Tight Linear Time (1 /
2)-Approximation for Unconstrained Submodular Maximization. In Symposium on Foundations of
Computer Science (FOCS)  2012.

Niv Buchbinder  Moran Feldman  Joseph (Sefﬁ) Naor  and Roy Schwartz. Submodular Maximization
with Cardinality Constraints. ACM-SIAM Symposium on Discrete Algorithms (SODA)  pages
1433–1452  2014.

Niv Buchbinder  Moran Feldman  and Roy Schwartz. Comparing Apples and Oranges: Query
Tradeoff in Submodular Maximization. In ACM-SIAM Symposium on Discrete Algorithms (SODA) 
2015.

Chandra Chekuri  Shalmoli Gupta  and Kent Quanrud. Streaming Algorithms for Submodular
Function Maximization. In International Colloquium on Automata  Languages  and Programming
(ICALP)  2015.

Alina Ene and Huy L. Nguyen. Constrained Submodular Maximization: Beyond 1/e. In Symposium

on Foundations of Computer Science (FOCS)  2016.

Alina Ene and Huy L. Nguyen. Parallel Algorithm for Non-Monotone DR-Submodular Maximization.

In arXiv preprint arXiv 1905:13272  2019.

Matthew Fahrbach  Vahab Mirrokni  and Morteza Zadimoghaddam. Non-monotone Submodular
In International Conference on

Maximization with Nearly Optimal Adaptivity Complexity.
Machine Learning (ICML)  2019.

Uriel Feige  Vahab S. Mirrokni  and Jan Vondrák. Maximizing Non-Monotone Submodular Functions.

SIAM Journal on Computing  40(4):1133–1153  2011.

Moran Feldman  Christopher Harshaw  and Amin Karbasi. Greed is Good: Near-Optimal Submodular

Maximization via Greedy Optimization. In Conference on Learning Theory (COLT)  2017.

Moran Feldman  Amin Karbasi  and Ehsan Kazemi. Do less  get more: Streaming submodular
maximization with subsampling. In Advances in Neural Information Processing Systems (NeurIPS) 
2018.

M.L. Fisher  G.L. Nemhauser  and L.A. Wolsey. An analysis of approximations for maximizing

submodular set functions-II. Mathematical Programming  8:73–87  1978.

10

Jennifer Gillenwater  Alex Kulesza  and Ben Taskar. Near-Optimal MAP Inference for Determinantal

Point Processes. In Advances in Neural Information Processing Systems (NeurIPS)  2012.

Anupam Gupta  Aaron Roth  Grant Schoenebeck  and Kunal Talwar. Constrained non-monotone
submodular maximization: Ofﬂine and secretary algorithms. In International Workshop on Internet
and Network Economics (WINE)  2010.

Ehsan Kazemi  Marko Mitrovic  Morteza Zadimoghaddam  Silvio Lattanzi  and Amin Karbasi.
Submodular Streaming in All its Glory: Tight Approximation  Minimum Memory and Low
Adaptive Complexity. In International Conference on Machine Learning (ICML)  2019.

David Kempe  Jon Kleinberg  and Éva Tardos. Maximizing the spread of inﬂuence through a social
network. In ACM SIGKDD International Conference on Knowledge Discovery and Data Mining
(KDD)  2003.

Jon Lee  Vahab Mirrokni  Viswanath Nagarajan  and Maxim Sviridenko. Maximizing Nonmonotone
Submodular Functions under Matroid or Knapsack Constraints. Siam Journal of Discrete Math  23
(4):2053–2078  2010.

Jure Leskovec  Andreas Krause  Carlos Guestrin  Christos Faloutsos  Jeanne VanBriesen  and Na-
talie Glance. Cost-effective Outbreak Detection in Networks. In ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining (KDD)  2007.

Baharan Mirzasoleiman  Ashwinkumar Badanidiyuru  Amin Karbasi  Jan Vondrak  and Andreas
Krause. Lazier Than Lazy Greedy. In AAAI Conference on Artiﬁcial Intelligence (AAAI)  2015.

Baharan Mirzasoleiman  Ashwinkumar Badanidiyuru  and Amin Karbasi. Fast Constrained Submod-
ular Maximization : Personalized Data Summarization. In International Conference on Machine
Learning (ICML)  2016.

Baharan Mirzasoleiman  Stefanie Jegelka  and Andreas Krause. Streaming Non-Monotone Submodu-
lar Maximization: Personalized Video Summarization on the Fly. In AAAI Conference on Artiﬁcial
Intelligence  2018.

Joseph Sefﬁ Naor and Roy Schwartz. A Uniﬁed Continuous Greedy Algorithm for Submodular

Maximization. In Symposium on Foundations of Computer Science (FOCS)  2011.

G L Nemhauser and L A Wolsey. Best Algorithms for Approximating the Maximum of a Submodular

Set Function. Mathematics of Operations Research  3(3):177–188  1978.

G. L. Nemhauser  L. A. Wolsey  and M. L. Fisher. An analysis of approximations for maximizing

submodular set functions-I. Mathematical Programming  14(1):265–294  1978.

Jan Vondrák. Symmetry and Approximability of Submodular Maximization Problems. SIAM Journal

on Computing  42(1):265–304  2013.

11

,Qianli Liao
Joel Leibo
Tomaso Poggio
Alan Kuhnle