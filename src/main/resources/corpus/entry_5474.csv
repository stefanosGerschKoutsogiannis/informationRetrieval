2018,The Limit Points of (Optimistic) Gradient Descent in Min-Max Optimization,Motivated by applications in Optimization  Game Theory  and the training of Generative Adversarial Networks  the convergence properties of first order methods in min-max problems have received extensive study. It has been recognized that they may cycle  and there is no good understanding of their limit points when they do not. When they converge  do they converge to local min-max solutions? We characterize the limit points of two basic first order methods  namely Gradient Descent/Ascent (GDA) and Optimistic Gradient Descent Ascent (OGDA).  We show that both dynamics avoid unstable critical points for almost all initializations. Moreover  for small step sizes and under mild assumptions  the set of  OGDA-stable critical points is a superset of GDA-stable critical points  which is a superset of local min-max solutions (strict in some cases). The connecting thread is that the behavior of these dynamics can be studied from a dynamical systems perspective.,The Limit Points of (Optimistic) Gradient Descent in

Min-Max Optimization

Constantinos Daskalakis

CSAIL
MIT

Cambridge  MA 02138
costis@csail.mit.edu

Ioannis Panageas

ISTD
SUTD

Singapore  487371

ioannis@sutd.edu.sg

Abstract

Motivated by applications in Optimization  Game Theory  and the training of
Generative Adversarial Networks  the convergence properties of ﬁrst order methods
in min-max problems have received extensive study. It has been recognized that
they may cycle  and there is no good understanding of their limit points when they
do not. When they converge  do they converge to local min-max solutions? We
characterize the limit points of two basic ﬁrst order methods  namely Gradient
Descent/Ascent (GDA) and Optimistic Gradient Descent Ascent (OGDA). We
show that both dynamics avoid unstable critical points for almost all initializations.
Moreover  for small step sizes and under mild assumptions  the set of OGDA-stable
critical points is a superset of GDA-stable critical points  which is a superset of
local min-max solutions (strict in some cases). The connecting thread is that the
behavior of these dynamics can be studied from a dynamical systems perspective.

1

Introduction

The celebrated min-max theorem was a founding stone in the development of Game Theory [21]  and
is intimately related to strong linear programming duality [1]  Blackwell’s approachability theory [3] 
and the theory of no-regret learning [5]. The theorem states that if f (x  y) is a convex-concave
function  and X   Y are compact and concave subsets of Euclidean space  then

y∈Y min

x∈X f (x  y).

min
x∈X max

y∈Y f (x  y) = max

(1)
If f (x  y) represents the payment of the X player to the Y player under choices of strategies x ∈ X
and y ∈ Y by these two players  the min-max theorem reassures us that an equilibrium of the game
exists  and that the equilibrium payoffs to both players are unique.
What does not follow directly from the min-max theorem is whether there exist dynamics via which
players would arrive at equilibrium if they were to follow some simple rule to update their current
strategies. This has been the topic of a long line of investigation starting with Julia Robinson’s
celebrated analysis of ﬁctitious play [4  20]  and leading to the development of no-regret learning [5].
Renewed interest in this problem has been recently motivated by the task of training Generative
Adversarial Networks (GANs) [9  2]  where two deep neural networks  the generator and the discrim-
inator  are trained in tandem using ﬁrst order methods  aiming at solving a min-max problem  of the
following form  albeit typically with a non convex-concave objective function f (x  y):

x∈X sup
inf
y∈Y

f (x  y).

(2)

Here x represents the parameters of the generator deep neural net  y represents the parameters of the
discriminator neural net  and f (x  y) is some measure of how close the distribution generated by the
generator appears to the true distribution from the perspective of the discriminator.

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

Min-max optimization in non convex-concave settings is a central problem for many research
communities  however our knowledge is very limited from optimization perspective. Moreover  for
such applications of ﬁrst-order methods to min-max problems in Machine Learning  it is especially
important that the last-iterate maintained by the min and the max dynamics converges to a desirable
solution. Unfortunately  even when f (x  y) is convex-concave  it is rare that guarantees are known
for the last iterate (see [17  15  13] for continuous time learning dynamics that may cycle). Some
guarantees are known for continuous-time dynamics [6]  but for discrete-time dynamics it is typically
only shown that the average-iterates converge to min-max equilibrium. Recent work of [7] shows that 
while Gradient Descent/Ascent (GDA) dynamics performed by the min/max players may diverge  the
Optimistic version dynamics of [18] exhibit last iterate convergence to min-max solutions (which
we shall call Optimistic Gradient Descent/Ascent (OGDA))  whenever f (x  y) is linear in x and y1).
The goal of our paper is to understand the limit points of GDA and OGDA dynamics (points that
last iterate might converge to) for general functions f (x  y). In particular  we answer the following
questions:

• are the stable limit points of GDA and OGDA locally min-max solutions?
• how do the stable limit points of GDA and OGDA relate to each other?

We provide answers to these questions after deﬁning our dynamics of interest formally.
GDA and OGDA Dynamics. Assume from now on that X = Rn  Y = Rm and f is a real-valued
function in C 2  the space of twice-continuously differentiable functions (unconstrained case). Perhaps
the most natural approach to solve (2) is by doing gradient descent on x and gradient ascent on y
(GDA)  i.e. 

xt+1 = xt − α∇xf (xt  yt) 
yt+1 = yt + α∇yf (xt  yt) 

(3)

with some constant step size α > 02. However  there are examples (functions f and initial points
(x0  y0)) in which the system of equations (3) cycles (see [7]). To break down this behavior 
the authors in [7] analyzed another optimization algorithm which is called Optimistic Gradient
Descent/Ascent (OGDA)3  the equations of which boil down to the following:
xt+1 = xt − 2α∇xf (xt  yt) + α∇xf (xt−1  yt−1) 
yt+1 = yt + 2α∇yf (xt  yt) − α∇yf (xt−1  yt−1).

(4)

One of their key results was to show convergence to the min max solution for the case of bilinear
objective functions  namely f (x  y) = x(cid:62)Ay.

Our contribution and techniques: In this paper we analyze Gradient Descent/Ascent (GDA) and
Optimistic Gradient Descent/Ascent (OGDA) dynamics applied to min-max optimization problems.
Our starting point is to show that both dynamics avoid their unstable ﬁxed points (GDA-unstable and
OGDA-unstable respectively  as deﬁned in Section 1.1). This is shown by using techniques from
dynamical systems  following the line of work of recent papers in Optimization and Machine Learning
[14  11  10]. In a nutshell we show that the update rules of both dynamics are local diffeomorphisms4
and we then make use of Center-Stable manifold theorem A.1 (see supplementary material). These
results are given as Theorems 2.2  3.2. We note that it is very crucial to show that the update rule of
the dynamics is a diffeomorphism  otherwise avoiding “linearly" unstable points cannot be shown
globally. One important step in our approach is the construction of a dynamical system for OGDA in
order to apply dynamical systems’ techniques.
We next study the set of stable ﬁxed points of GDA dynamics and their relation to locally min-max
solutions  called local min-max.5). Informally  a local min-max critical point (x∗  y∗) satisﬁes the
following: compared to value f (x∗  y∗)  if we ﬁx x∗ and perturb y∗ inﬁnitesimally  the value of f
1We note that in their paper the dynamics is called Optimistic Mirror Descent  we changed the name because

the dynamics is a modiﬁed gradient descent.
2Note that α > 0 for the rest of this paper.
3We note that OGDA has some resemblance with Polyak’s heavy ball method. However  one important

difference is that OGDA has “negative momentum” while the heavy ball method has “positive momentum.”

4A local diffeomorphism is a function that locally is invertible  smooth and its (local) inverse is also smooth.
5In optimization literature they are called local saddles.

2

does not increase and similarly if we ﬁx y∗ and perturb x∗ inﬁnitesimally  the value of f does not
decrease. We show that the set of stable ﬁxed points of GDA is a superset of the set of local min-max
and there are functions in which this inclusion is strict. This is given in Lemmas 2.4  2.7  2.5.
Finally  we analyze OGDA dynamics which is a bit trickier than GDA due to the nature of the
dynamics  namely the existence of memory in the dynamics: the next iterate depends on the gradient
of the current and previous point. We construct a dynamical system that captures OGDA dynamics (see
Equation (7))  using a construction that is commonly employed in differential equations. Importantly 
we establish a mapping (relation) between the eigenvalues of the Jacobian of the update rules of both
GDA and OGDA  showing that OGDA stable ﬁxed points is a superset of GDA stable ones (under
mild assumptions on the stepsize)  namely (we suggest the reader to see ﬁrst Remark 1.5 to avoid
confusion):

Local min-max ⊂ GDA-stable ⊂ OGDA-stable

We note that the inclusion above are strict.
Notation: Vectors in Rn  Rm are denoted in boldface x  y. Time indices are denoted by subscripts.
Thus  a time indexed vector x at time t is denoted as xt. We denote by ∇xf (x  y) the gradient of f
with respect to variables in x (of dimension the same as x) and by ∇2
xyf the part of the Hessian in
which the derivative of f is taken with respect to a variable in x and then a variable in y. We use
the letter J to denote the Jacobian of a function (with appropriate subscript)  Ik  0k×l to denote the
identity and zero matrix of sizes k × k and k × l respectively6  ρ(A) for the spectral radius of matrix
A and ﬁnally we use f t to denote the composition of f by itself t times.
Finally  we would like to note that all the missing proofs can be found in the supplementary material.

1.1

Important Deﬁnitions

We have already stated our min-max problem of interest (2) as well as the Gradient Descent/Ascent
(GDA) dynamics (3) and Optimistic Gradient Descent/Ascent (OGDA) dynamics (4) that we plan to
analyze. We provide some further deﬁnitions.

Dynamical Systems. A recurrence relation of the form xt+1 = w(xt) is a discrete time dynamical
system  with update rule w : S → S for some convex set S ⊂ Rn. Function w is assumed to
be continuously differentiable for the purpose of this paper. The point z is called a ﬁxed point or
equilibrium of w if w(z) = z. We will be interested in the following standard notions of ﬁxed point
stability.
Deﬁnition 1.1 ((Linear) stability). Let w be continuously differentiable. We call a ﬁxed point z
linearly stable or just stable if  for the Jacobian J of w computed at z  it holds that its spectral radius
ρ(J) is at most one and otherwise we call it linearly unstable or just unstable.
Deﬁnition 1.2 (Lyapunov and Asymptotic Stability). A ﬁxed point z of w is called Lyapunov stable if 
for every  > 0  there exists a δ = δ() > 0 such that if x ∈ Bδ with Bδ = {y ∈ S : (cid:107)y − z(cid:107) < δ}7
we have that (cid:107)wn(x) − z(cid:107) <  for every n ≥ 0. That is  if dynamics starts close enough to z  it
remains close for all times.
A ﬁxed point z of w is called (locally) asymptotically stable (or attracting) if it is Lyapunov stable
and there exists a δ > 0 such that  for all x ∈ Bδ we have that (cid:107)wn(x) − z(cid:107) → 0 as n → ∞. That
is  there is a small neighborhood around z so that  for all initializations in that neighborhood  the
dynamics converges to z.
Deﬁnition 1.3 (Hyperbolicity). We call a ﬁxed point z hyperbolic iff the Jacobian J of w computed
at z has no eigenvalues with absolute value 1.

The following are well-known facts.
Proposition 1.4 (e.g. [8]). If the Jacobian of the update rule at a stable ﬁxed point z has spectral
radius less than one  then the ﬁxed point is asymptotically stable. Therefore  if a ﬁxed point z is
hyperbolic  then linear stability implies asymptotic stability.

6We also use 0 to denote the zero vector.
7Ball of radius δ.

3

Remark 1.5 (Fixed points of GDA  OGDA dynamics). It is easy to see that a ﬁxed point of the GDA
dynamics (3) arises whenever (xt+1  yt+1) = (xt  yt)  or in other words whenever (xt  yt) = (x  y)
such that ∇f (x  y) = 0.
Since the OGDA dynamics (4) has memory  it is more appropriate to think of the dynamics as
mapping a quadruple (xt  yt  xt−1  yt−1) to a quadruple (xt+1  yt+1  xt  yt). In this case  a ﬁxed
point arises whenever (xt+1  yt+1  xt  yt) = (xt  yt  xt−1  yt−1)  or in other words whenever
(xt  yt  xt−1  yt−1) = (x  y  x  y) and ∇f (x  y) = 0.
We should stress in particular that whenever we say that the set of OGDA-stable ﬁxed points is a
super-set of the GDA-stable ﬁxed points  we will be somewhat abusing notation  since the ﬁxed points
of OGDA lie in R2n+2m while the ﬁxed points of GDA lie in Rn+m. However  as discussed above  a
ﬁxed point of OGDA is of the form (x  y  x  y)  and we can thus project it to its ﬁrst two components
without any loss of information to obtain a point in Rn+m. When we relate ﬁxed points of OGDA to
ﬁxed points of GDA we will implicitly apply this projection.

Given Proposition 1.4  it follows that spectral analysis of the Jacobian of the ﬁxed points can give
us qualitative information about the local behavior of the dynamics. Unless otherwise speciﬁed 
throughout this paper  whenever we say “stable” we mean linearly stable. GDA/OGDA-stable critical
points are critical points that are stable with respect to GDA/OGDA dynamics (for ﬁxed stepsize α 
otherwise are unstable). Moreover since different choices of stepsize α might give different stability
for GDA and OGDA dynamics  we are interested in the case α is “sufﬁciently" small. Therefore
in the sections we characterize the GDA/OGDA-stable critical points  a point (x∗  y∗) is classiﬁed
as GDA/OGDA-stable if there exists a sufﬁciently small number β > 0 such that for all stepsizes
0 < α < β we have that the (x∗  y∗) is a stable ﬁxed point of GDA/OGDA dynamics (in case there
exists a small β > 0 so that for all stepsizes 0 < α < β we have that (x∗  y∗) is an unstable ﬁxed
point of GDA/OGDA dynamics  it is classiﬁed as GDA/OGDA-unstable).

Optimization. We use the following standard terminology.
Deﬁnition 1.6. For a min-max problem (2) where f is twice continuously differentiable 

• A point (x∗  y∗) is a critical point of f if ∇f (x∗  y∗) = 0.
• A critical point (x∗  y∗) is isolated if there is a neighborhood U around (x∗  y∗) where

(x∗  y∗) is the only critical point.8 Otherwise it is called non-isolated.

• A critical point (x∗  y∗) is a local min-max point if there exists a neighborhood U around

(x∗  y∗) so that for all (x  y) ∈ U we have that f (x∗  y) ≤ f (x∗  y∗) ≤ f (x  y∗).9
• A critical point (x∗  y∗) is a strongly local min-max point if λmin(∇2

xxf (x∗  y∗)) > 0 and

λmax(∇2

yyf (x∗  y∗)) < 0.

1.2 Formal Statement of Results

We present our main results for GDA and OGDA  to be proven in Sections 2 and 3. Some of our
claims make use of the following assumptions about the objective function f of (2):
Assumption 1.7 (Invertibility of Hessian of f). ∇2f (the Hessian of f) is invertible for all x  y.
Assumption 1.8 (Non-Imaginary GDA at a Critical Point). GDA is non-imaginary at a critical point
(x∗  y∗) of f iff

(cid:18) −∇2

(cid:19)

H =

xxf −∇2
xyf
∇2
∇2
yxf
yyf

(5)
α (J(x∗  y∗) − In+m) where J is

has no eigenvalue whose real part is 0. H captures the difference 1
the Jacobian of GDA dynamics and In+m the identity matrix.
Remark 1.9. To illustrate the nature of the above assumptions  we note that Assumption 1.7 is
2 x(cid:62)Qx 
generically true for quadratic functions. Take an arbitrary quadratic function f (x) = 1

8If the critical points are isolated then they are countably many or ﬁnite.
9In optimization literature these critical points are also called local saddle points. If U is the whole domain

then we call it global min-max.

4

2 x(cid:62)Ax where A is a matrix with random entries from some continuous
and deﬁne ˜f (x) = f (x) + 1
distribution (say uniform in [−  ] for  small enough). It is not hard to see that ∇2 ˜f is invertible with
probability one. This is intuitively a “hyperbolicity" assumption of the ﬁxed points of the dynamics.
We note that we use this assumption for Lemma 3.1 and also to show that OGDA avoids its unstable
ﬁxed points. The stability characterizations do not need this assumption. Moreover  we note that
Assumption 1.8 is satisﬁed when critical point (x∗  y∗) is strongly local min-max.

Our two main results are stated as follows:
Theorem 1.10 (Inclusion). Assume f is twice differentiable and ∇f is Lipschitz with constant L.
• Let (x∗  y∗) be a local min max critical point that satisﬁes Assumption 1.8. For α > 0
sufﬁciently small it holds that (x∗  y∗) is GDA-stable ﬁxed point. There is a function with
critical point (x∗  y∗) which violates Assumption 1.8  (x∗  y∗) is local min-max but not
GDA-stable for any 0 < α < 1
Additionally  if (x∗  y∗) is a strongly local min max critical point then Assumption 1.8 is
satisﬁed and for α > 0 sufﬁciently small we get (x∗  y∗) is GDA-stable (Remark 2.8).
Finally there is a function with a critical point (x∗  y∗) which is not local min-max but it is
GDA-stable (for sufﬁciently small α > 0  Lemma 2.5).

L (Lemmas 2.4  2.7 and 2.6).

• Let (x∗  y∗) be a GDA-stable ﬁxed point. For 0 < α < 1

2L it holds that (x∗  y∗) is OGDA-
stable. Moreover the inclusion is strict  i.e.  there is a function with critical point (x∗  y∗)
which is OGDA-stable but not GDA-stable (for small enough α > 0  Lemmas 3.4 and 3.5).
Theorem 1.11 (Avoid unstable). Assume f is twice differentiable and ∇f is Lipschitz with constant
L. The set of initial vectors (x0  y0) so that GDA converges to (linearly) GDA-unstable ﬁxed points
(critical points) is of measure zero. Under Assumption 1.7  the set of initial vectors (x1  y1  x0  y0)
so that OGDA converges to (linearly) OGDA-unstable ﬁxed points (critical points) is of measure zero.
These statements are captured by Theorems 2.2 and 3.2.

2 Analysis of Gradient Descent/Ascent

In this section we analyze the local behavior (which carries over to a global characterization under
Lemma 2.1 and Center-stable manifold theorem A.1) of GDA dynamics (3). In all our statements
(theorems  lemmas etc) we work with real-valued function f that is twice differentiable and we also
assume ∇f is Lipschitz with constant L and that the stepsize satisﬁes 0 < α < 1
L (unless stated
otherwise in the statement of a lemma/theorem).

2.1 Analyzing GDA

We need to show the following lemma in order to use the stable manifold theorem (see Theorem A.1).
Lemma 2.1 (GDA is a local diffeomorphism). Let f be twice differentiable and ∇f is Lipschitz
with constant L. Assume that 0 < α < 1
L . The update rule of the GDA dynamics (3) is a local
diffeomorphism.
Theorem 2.2 (Measure zero for GDA). Let f be twice differentiable and ∇f is Lipschitz with
L and let h be the update rule of the GDA dynamics (3)  (x∗  y∗)
constant L. Assume that 0 < α < 1
be a GDA-unstable critical point and WGDA(x∗  y∗) be its stable set  i.e. 

WGDA(x∗  y∗) = {(x0  y0) : lim

k

hk(x0  y0) = (x∗  y∗)}.

It holds that WGDA(x∗  y∗) is of Lebesgue measure zero. Moreover if WGDA is union of the stable sets
of all GDA-unstable critical points  then WGDA has also measure zero (namely the proof works for
non-isolated critical points).

The following corollary is immediate from Theorem 2.2.
Corollary 2.3. Let (x∗  y∗) be GDA-unstable. Assume µ is a measure of the starting points (x0  y0)
and is absolutely continuous with respect to the Lebesgue measure on Rn+m. Then it holds that

(xt  yt) = (x∗  y∗)] = 0.

Pr[lim
t

5

2.2 Characterizing GDA-stability

L and let (x∗  y∗) be a
Lemma 2.4 (Local min-max are GDA-stable). Assume that 0 < α < 1
local min-max critical point of f and matrix H (see equations (5)) computed at (x∗  y∗) has real
eigenvalues. It holds that (x∗  y∗) is GDA-stable.
Lemma 2.5. The converse of Lemma 2.4 is false. There are functions with critical points that are
GDA-stable but not local min-max. An example is f (x  y) = − 1

2 y2 + 6

10 xy10.

Proof. We provide an example with two variables (so that we can also give a ﬁgure). Let f (x  y) =
− 1
8 x2 − 1
10 xy. Computing the Jacobian of the update rule of dynamics (3) at point (0  0) we
get that

2 y2 + 6

JGDA =

(6)
L where L ≤ 1.34). Finally
Both eigenvalues of JGDA have magnitude less than 1 (for any 0 < α < 1
matrix HGDA has real eigenvalues. Therefore there exists a neighborhood U of (0  0) so that for all
(x0  y0) ∈ U  we get that limt(xt  yt) = (0  0) for GDA dynamics (3). However it is clear that (0  0)
is not a local min-max. See also Figure 1 for a pictorial illustration of the result.

6
10 α

 

8 x2 − 1
(cid:19)

(cid:18) 1 + 1

4 α − 6
10 α
1 − α

Figure 1: Function f (x  y) = − 1
10 xy and α = 0.001. The arrows point towards the
next step of the Gradient Descent/Ascent dynamics. We can see that the system converges to (0  0)
point (GDA-stable)  which is not a local min-max critical point.

8 x2 − 1

2 y2 + 6

We end Section 2 by characterizing the case in which H has complex eigenvalues.
Lemma 2.6 (Imaginary eigenvalues). There are functions with critical points that are not GDA-
stable but are local min-max when matrix H (see equations (5)) has imaginary eigenvalues.

We complete the characterization for the relation between GDA-stable critical points and local
min-max with the following lemma:
Lemma 2.7 (Real part nonzero). Let (x∗  y∗) be a local min-max critical point of f and matrix
H (see equations (5)) computed at (x∗  y∗) has all its eigenvalues with real part nonzero (i.e. 
Assumption 1.8). There is a small enough step-size α > 0 so that (x∗  y∗) is GDA-stable.

10See Figure 1.

6

-0.25-0.2-0.15-0.1-0.0500.050.10.150.20.25-0.2-0.15-0.1-0.0500.050.10.150.2Remark 2.8. If the critical point (x∗  y∗) is strongly local min-max then λmax(H) < 0 and
hence (x∗  y∗) is attracting under GDA dynamics  i.e.  it holds that Strongly Local min-max ⊂
GDA-stable.

3 Optimistic Gradient Descent/Ascent

The results of the previous section cannot carry over to Optimistic Gradient Descent/Ascent due to the
fact that the dynamics has memory and is more challenging to analyze. Here we show that Optimistic
Gradient Descent/Ascent avoid OGDA-unstable critical points and we also relate the eigenvalues
of the Jacobian of OGDA to the eigenvalues of the Jacobian of GDA. In particular we show that
GDA-stable ⊂ OGDA-stable (inclusion strict). In the beginning we will construct a dynamical
system that captures the dynamics of OGDA (4).

3.1 Constructing the Dynamical System
We deﬁne the function F to be F (x  y  z  w) = f (x  y) for all (x  y  z  w) ∈ X × Y × X × Y
(think of the last two vector components as dummy for function F   its value does not depend on
them). Hence it is clear that ∇zF (x  y  z  w) = 0 and ∇wF (x  y  z  w) = 0. The same holds for
∇xF (z  w  x  y) = 0 and ∇yF (z  w  x  y) = 0.
We deﬁne the following function g which consists of 4 components:

g(x  y  z  w) := (g1(x  y  z  w)  g2(x  y  z  w)  g3(x  y  z  w)  g4(x  y  z  w)) 
g1(x  y  z  w) := Inx − 2α∇xF (x  y  z  w) + α∇zF (z  w  x  y) 
g2(x  y  z  w) := Imy + 2α∇yF (x  y  z  w) − α∇wF (z  w  x  y) 
g3(x  y  z  w) := Inx 
g4(x  y  z  w) := Imy.

(7)

It is not hard to check that (xt+1  yt+1  xt  yt) = g(xt  yt  xt−1  yt−1)  so g captures exactly
the dynamics of OGDA (4). The idea behind the construction of the dynamical system above is
common in the literature of ODEs (ordinal differential equations) where in order to solve (typically
to understand the qualitative behavior) a higher order ODE  one approach is to express it as a linear
system of ODEs.

3.2 Analyzing OGDA via system (7)

As in the case of GDA  we need to show the following key lemma in order to use the Center-stable
manifold theorem.
Lemma 3.1 (OGDA is a local diffeomorphism). Let f is real-valued C 2 and ∇f is Lipschitz with
constant L and 0 < α < 1
L . Under the Assumption 1.7 we get that the update rule g of the OGDA
dynamics (7) is a local diffeomorphism.

Again as in Section 2  we are able to prove the following measure zero argument using Lemma 3.1
and Center-Stable manifold theorem.
Theorem 3.2 (Measure zero for OGDA). Let f be twice differentiable and ∇f is Lipschitz with
constant L. Suppose that Assumption 1.7 holds and 0 < α < 1
L . Let g be the update rule of the
OGDA dynamics (4)  (x∗  y∗  x∗  y∗) be a OGDA-unstable critical point and WOGDA(x∗  y∗  x∗  y∗)
be its stable set  i.e. 

WOGDA(x∗  y∗  x∗  y∗) = {(x1  y1  x0  y0) : lim

gk(x1  y1  x0  y0) = (x∗  y∗  x∗  y∗)}.

It holds that WOGDA(x∗  y∗  x∗  y∗) is of Lebesgue measure zero. Moreover if WOGDA is union of
the stable sets of all OGDA-unstable critical points  then WOGDA has also measure zero (namely the
proof works for non-isolated critical points).

k

The following corollary is immediate from Theorem 3.2.
Corollary 3.3. Let (x∗  y∗  x∗  y∗) be OGDA-unstable. Assume µ is a measure of the starting points
(x1  y1  x0  y0) and is absolutely continuous with respect to the Lebesgue measure on R2n+2m. Then
it holds that

(xt  yt  xt−1  yt−1) = (x∗  y∗  x∗  y∗)] = 0.

Pr[lim
t

7

3.3 Characterizing OGDA-stability

In this subsection we provide an analysis for the eigenvalues of the Jacobian matrix JOGDA of the
update rule g of the system (7) the equations of which can be found in the supplementary material.
We begin by claiming that the set of GDA-stable critical points is a subset of the set of OGDA-critical
points. We manage to show this by constructing a mapping between the eigenvalues of JGDA and
JOGDA.
Lemma 3.4 (GDA-stable are OGDA-stable). Let f be twice differentiable and ∇f be L-Lipschitz.
2L and suppose (x∗  y∗) is a critical point that is GDA-stable (i.e.  stable
Assume that 0 < α < 1
according to dynamics (3)). The critical point (x∗  y∗  x∗  y∗) is stable according to OGDA dynamics
(4).

We conclude the subsection with the following claim and a remark.
Lemma 3.5. There are functions with critical points that are OGDA-stable but not GDA-stable.
Remark 3.6. We would like to note that some of our results (e.g.  Lemma 3.1 and Theorem 3.2) are
not applicable to a generic bilinear function f (x  y) = x(cid:62)Ay  since if A is not a square matrix  the
Hessian ∇2f is not invertible (they are applicable only when A is square matrix and invertible).

4 Examples and Experiments
In this section we provide two examples/experiments  one 2-dimensional (function f : R2 →
R  x  y ∈ R) and one higher dimensional (f : R10 → R  x  y ∈ R5). The purpose of these
experiments is to get better intuition about our ﬁndings. In the 2-dimensional example  we construct
a function with local min-max  {GDA  OGDA}-unstable and {GDA  OGDA}-stable critical points.
Moreover  we get 10000 random initializations from the domain R = {(x  y) : −5 ≤ x  y ≤ 5}
and we compute the probability to reach each critical point for both GDA and OGDA dynamics. In
the higher dimensional experiment  we construct a polynomial function p(x  y) of degree 3 with
coefﬁcients sampled i.i.d from uniform distribution with support [−1  1] and then we plant a local
min max. Under 10000 random initializations in R  we analyze the convergence properties of GDA
and OGDA (as in the two dimensional case).

2 y2 + 6

8 x2 − 1

4.1 A 2D example
The function f1(x  y) = − 1
10 xy has the property that the critical point (0  0) is GDA-
stable but not local min-max (see Lemma 2.5). Moreover  consider f2(x  y) = 1
2 y2 + 4xy.
This function has the property that the critical point (0  0) is GDA-unstable and is easy to check
that is not a local min-max. We construct the polynomial function f (x  y) = f1(x  y)(x − 1)2(y −
1)2 + f2(x  y)x2y2. Function f has the property that around (0  0) behaves like f1 and around (1  1)
behaves like f2. The GDA dynamics of f can be seen in Figure 2. However more critical points are
created. There are ﬁve critical points  i.e  (0  0)  (0  1)  (1  0)  (1  1)  (0.3301  0.3357) (in interval R 
the last critical point is computed approximately). In Table 1 we observe that the critical point (0  0)
is stable for OGDA but unstable for GDA (essentially OGDA has more attracting critical points).
Moreover  our theorems of avoiding unstable ﬁxed points are veriﬁed with this experiment. Note
that there are some initial conditions that GDA and OGDA dynamics don’t converge (3% and 9.8%
respectively).

2 x2 + 1

Critical point

GDA-
stable
NO
(0  0)
NO
(0  1)
YES
(1  0)
YES
(1  1)
(0.3301  0.3357) NO

OGDA-
stable
YES
NO
YES
YES
NO

Local
min-max
NO
NO
YES
NO
NO

value of
f
0
0
0
0
0.109

Prob. GDA
converges
0%
0%
78%
19%
0%

Prob. OGDA
converges
25.8%
0%
35.4%
29%
0%

Table 1: Summary of critical points of f.

8

Figure 2: Construction of a function with points that are GDA-stable and local min-max  GDA-stable
and not local min-max and GDA-unstable (and hence not local min-max). The arrows point towards
the next step of the Gradient Descent/Ascent dynamics.

4.2 Higher dimensional

Let f (x  y) := p(x  y) · ((cid:80)5
mentioned above and w(x  y) =(cid:80)5

i=1 x3

i + y3

i ) + w(x  y)  where p is the random 3-degree polynomial as
i ). It is clear that f locally at (0  ...  0) behaves like
function w (which has 0 as a local min-max critical point). We run for 10000 uniformly random
points in R and it turns out that 87% of initial points converge to 0 in OGDA as opposed to GDA
which 79.3% fraction converged. This experiment indicates qualitative difference between the two
methods  where the area of region of attraction in OGDA is a bit larger.

i − y2

i=1(x2

5 Conclusion

In this paper we made a step towards understanding ﬁrst order methods which are used to solve
min-max optimization problems  by analyzing the local behavior of GDA and OGDA dynamics
around critical points. Our paper is an indication that important ﬁrst order methods we analyze fail to
converge to only local min-max solutions (standard concept in optimization literature). Whether or not
local min-max solutions is a good concept is out of the scope of this paper11. Local min-max solutions
might not be all equally good and some may be bad  which is really important in applications such as
training GANs. Nevertheless  even for minimization problems  ﬁnding good local minima is a hard
task that is not well understood in the literature (most ﬁrst order methods guarantee convergence to
some local minimum  without guarantees about its quality). A forteriori guaranteeing good solutions
in a min-max problem is a harder proposition and an important open question.

11Even characterizing whether a local min-max solution is good or not is not an easy/clear task.

9

-0.200.20.40.60.811.2-0.200.20.40.60.811.2Acknowledgments

Constantinos Daskalakis was supported by NSF awards CCF-1617730 and IIS-1741137  a Simons
Investigator Award  a Google Faculty Research Award  and an MIT-IBM Watson AI Lab research
grant. Ioannis Panageas was supported by SRG ISTD 2018 136. This work was done when Ioannis
was a postdoctoral fellow at MIT.

References
[1] Ilan Adler. The equivalence of linear programs and zero-sum games. In International Journal

of Game Theory  pages 165–177  2013.

[2] Martín Arjovsky  Soumith Chintala  and Léon Bottou. Wasserstein generative adversarial
networks. In Proceedings of the 34th International Conference on Machine Learning  ICML
2017  Sydney  NSW  Australia  6-11 August 2017  pages 214–223  2017.

[3] David Blackwell. An analog of the minimax theorem for vector payoffs. In Paciﬁc J. Math. 

pages 1–8  1956.

[4] G.W Brown. Iterative solutions of games by ﬁctitious play. In Activity Analysis of Production

and Allocation  1951.

[5] Nikolo Cesa-Bianchi and Gabor Lugosi. Prediction  Learning  and Games. Cambridge

University Press  2006.

[6] Ashish Cherukuri  Bahman Gharesifard  and Jorge Cortés. Saddle-point dynamics: Conditions
for asymptotic stability of saddle points. SIAM J. Control and Optimization  55(1):486–511 
2017.

[7] Constantinos Daskalakis  Andrew Ilyas  Vasilis Syrgkanis  and Haoyang Zeng. Training gans

with optimism. ICLR  2018.

[8] Oded Galor. Discrete Dynamical Systems. Springer  2007.

[9] Ian J. Goodfellow  Jean Pouget-Abadie  Mehdi Mirza  Bing Xu  David Warde-Farley  Sherjil
Ozair  Aaron C. Courville  and Yoshua Bengio. Generative adversarial nets. In Advances
in Neural Information Processing Systems 27: Annual Conference on Neural Information
Processing Systems 2014  December 8-13 2014  Montreal  Quebec  Canada  pages 2672–2680 
2014.

[10] Chi Jin  Yuchen Zhang  Sivaraman Balakrishnan  Martin J. Wainwright  and Michael I. Jordan.
Local maxima in the likelihood of gaussian mixture models: Structural results and algorithmic
consequences. In Advances in Neural Information Processing Systems 29: Annual Conference
on Neural Information Processing Systems 2016  December 5-10  2016  Barcelona  Spain 
pages 4116–4124  2016.

[11] Jason D. Lee  Ioannis Panageas  Georgios Piliouras  Max Simchowitz  Michael I. Jordan  and
Benjamin Recht. First-order methods almost always avoid saddle points. CoRR  abs/1710.07406 
2017.

[12] L. Lessard  B. Recht  and A. Packard. Analysis and design of optimization algorithms via

integral quadratic constraints. In SIAM Journal on Optimization  2016.

[13] Tung Mai  Milena Mihail  Ioannis Panageas  Will Ratcliff  Vijay V. Vazirani  and Peter Yunker.
Rock-paper-scissors  differential games and biological diversity. To appear in Economics and
Computation (EC)  2018.

[14] Ruta Mehta  Ioannis Panageas  and Georgios Piliouras. Natural selection as an inhibitor of
genetic diversity: Multiplicative weights updates algorithm and a conjecture of haploid genetics.
In Innovations in Theoretical Computer Science  ITCS  2015.

10

[15] Panayotis Mertikopoulos  Christos Papadimitriou  and Georgios Piliouras. Cycles in adversarial
In Proceedings of the Twenty-Ninth Annual ACM-SIAM Symposium
regularized learning.
on Discrete Algorithms  SODA 2018  New Orleans  LA  USA  January 7-10  2018  pages
2703–2717  2018.

[16] V. Nagarajan and J. Zico Kolter. Gradient descent gan optimization is locally stable. In NIPS 

2017.

[17] Gerasimos Palaiopanos  Ioannis Panageas  and Georgios Piliouras. Multiplicative weights
update with constant step-size in congestion games: Convergence  limit cycles and chaos.
In Advances in Neural Information Processing Systems 30: Annual Conference on Neural
Information Processing Systems 2017  4-9 December 2017  Long Beach  CA  USA  pages
5874–5884  2017.

[18] Alexander Rakhlin and Karthik Sridharan. Online learning with predictable sequences. In
COLT 2013 - The 26th Annual Conference on Learning Theory  June 12-14  2013  Princeton
University  NJ  USA  pages 993–1019  2013.

[19] Lillian J. Ratliff  Samuel A. Burden  and S. Shankar Sastry. Characterization and computation

of local nash equilibria in continuous games. In Allerton  2013.

[20] J. Robinson. An iterative method of solving a game. In Annals of Mathematics  pages 296–301 

1951.

[21] J Von Neumann. Zur theorie der gesellschaftsspiele. In Math. Ann.  pages 295–320  1928.

11

,Constantinos Daskalakis
Ioannis Panageas