2013,Reciprocally Coupled Local Estimators Implement Bayesian Information Integration Distributively,Psychophysical experiments have demonstrated that the brain integrates information from multiple sensory cues in a near Bayesian optimal manner. The present study proposes a novel mechanism to achieve this. We consider two reciprocally connected networks  mimicking the integration of heading direction information between the dorsal medial superior temporal (MSTd) and the ventral intraparietal (VIP) areas. Each network serves as a local estimator and receives an independent cue  either the visual or the vestibular  as direct input for the external stimulus. We find that positive reciprocal interactions can improve the decoding accuracy of each individual network as if it implements Bayesian inference from two cues. Our model successfully explains the experimental finding that both MSTd and VIP achieve Bayesian multisensory integration  though each of them only receives a single cue as direct external input. Our result suggests that the brain may implement optimal information integration distributively at each local estimator through the reciprocal connections between cortical regions.,Reciprocally Coupled Local Estimators Implement
Bayesian Information Integration Distributively

Wen-hao Zhang1;2;3 

Si Wu1

1State Key Laboratory of Cognitive Neuroscience and Learning  and

IDG/McGovern Institute for Brain Research  Beijing Normal University  China.

2Institute of Neuroscience  Chinese Academy of Sciences  Shanghai  China.

3University of Chinese Academy of Sciences  Shanghai  China.

whzhang@ion.ac.cn 

wusi@bnu.edu.cn

Abstract

Psychophysical experiments have demonstrated that the brain integrates informa-
tion from multiple sensory cues in a near Bayesian optimal manner. The present
study proposes a novel mechanism to achieve this. We consider two reciprocally
connected networks  mimicking the integration of heading direction information
between the dorsal medial superior temporal (MSTd) and the ventral intraparietal
(VIP) areas. Each network serves as a local estimator and receives an independent
cue  either the visual or the vestibular  as direct input for the external stimulus.
We ﬁnd that positive reciprocal interactions can improve the decoding accuracy
of each individual network as if it implements Bayesian inference from two cues.
Our model successfully explains the experimental ﬁnding that both MSTd and VIP
achieve Bayesian multisensory integration  though each of them only receives a
single cue as direct external input. Our result suggests that the brain may imple-
ment optimal information integration distributively at each local estimator through
the reciprocal connections between cortical regions.

1 Introduction

In our daily life  we sense the world through multiple sensory systems. For instance  while walk-
ing  we perceive heading direction through either the visual cue (optic ﬂow)  or the vestibular cue
generated by body movement  or both of them [1  2]. In reality  because of noises  which arise
due to signal ambiguity and/or ﬂuctuations in neural transmission  our perception of the input infor-
mation is often uncertain. In order to achieve an accurate or improved representation of the input
information  it is critical for the brain to integrate information from multiple sensory modalities.
Mathematically  Bayesian inference provides an optimal way to estimate the stimulus value based
on multiple uncertain information resources. Consider the task of inferring heading direction θ
based on the visual and vestibular cues. Suppose that with a single cue cl (l = vi  ve correspond
to the visual and the vestibular cues  respectively)  the estimation of heading direction satisﬁes the
Gaussian distribution p(cl|θ)  which has the mean µl and the variance σ2
l . Under the condition that
noises from different cues are independent to each other  the Bayes’ theorem states that

p(θ|cvi  cve) ∝ p(cvi|θ)p(cve|θ)p(θ) 

(1)
where p(θ|cvi  cve) is the posterior distribution of the stimulus when two cues are presented  and
p(θ) the prior distribution. In the case of no prior knowledge  i.e.  p(θ) is uniform  p(θ|cvi  cve) also

1

satisﬁes the Gaussian distribution with the mean and variance given by

µb =

1
σ2
b

=

µvi +

σ2
ve

σ2
vi + σ2
ve
1
1
σ2
σ2
ve
vi

+

.

σ2
vi

σ2
vi + σ2
ve

µve 

(2)

(3)

A number of elegant psychophysical experiments have demonstrated that humans and animals in-
tegrate multisensory information in an optimal Bayesian way. These include  for instances  using
visual and auditory cues together to infer object location [3]  getting the hand position from the visu-
al and proprioceptive cues simultaneously [4]  the combination of visual and haptic input to perceive
object height [5]  the integration of visual and vestibular cues to derive heading direction [6  7]  and
the integration of texture and motion information to obtain depth [8]. Nevertheless  the detailed
neural mechanism underlying Bayesian information integration remains largely unclear. Ma et. al. 
proposed a feed-forward mechanism to achieve Bayesian integration [9]. In their framework  a cen-
tralized network integrates information from multiple resources. In particular  in their model  the
improved decoding accuracy after combining input cues (i.e.  the decreased uncertainty given by
Eq.3) depends on the linear response nature of neurons  a feature in accordance with the statistics
of Poisson spiking train. However  it is unclear how well this result can be extended to non-Poisson
statistics. Moreover  it is not clear where this centralized network responsible for information inte-
gration locates in the cortex.
In this work  we propose a novel mechanism to implement Bayesian information integration  which
relies on the excitatory reciprocal interactions between local estimators  with each local estimator
receiving an independent cue as external input. Although our idea may be applicable to general cas-
es  the present study focuses on two reciprocally connected networks  mimicking the integration of
heading direction information between the dorsal medial superior temporal (MSTd) area and ventral
intraparietal (VIP) area. It is known that MSTd and VIP receive the visual and the vestibular cues
as external input  respectively. We model each network as a continuous attractor neural network
(CANN)  reﬂecting the property that neurons in MSTd and VTP are widely tuned by heading di-
rection [10  11]. Interestingly  we ﬁnd that with positive reciprocal interactions  both networks read
out heading direction optimally in Bayesian sense  despite the fact that each network only receives a
single cue as directly external input. This agrees well with the experimental ﬁnding that both MSTd
and VIP integrate the visual and vestibular cues optimally [6  7]. Our result suggests that the brain
may implement Bayesian information integration distributively at each local area through reciprocal
connections between cortical regions.

2 The Model

We consider two reciprocally connected networks  each of which receives the stimulus information
from an independent sensory cue (see Fig.1A). The two networks may be regarded as representing 
respectively  the neural circuits in MSTd and VIP. Anatomical and fMRI data have revealed that
there exist abundant reciprocal interactions between MSTd and VIP [12–14]. Neurons in MSTd and
VIP are tuned to heading direction  relying on the visual and the vestibular cues [10  15].
CANNs  also known as neural ﬁeld model  have been successfully applied to describe the encoding
of head-direction in neural systems [16]. Therefore  we build each network as a CANN. Denote
θ to be the stimulus value (i.e. the heading direction) encoded by both networks  and the neuronal
preferred stimuli are in the range of −π < θ ≤ π with periodic boundary condition. Denote Ul(θ  t) 
for l = 1  2  the synaptic input at time t to the neurons having the preferred stimulus θ in the l-th
network. The dynamics of Ul(θ  t) is determined by the recurrent inputs from other neurons in the
same network  the reciprocal inputs from neurons in the other network  the external input I ext
(θ  t) 
and its own relaxation. It is written as

l

]

∫ [

][

]

[

]

[

]

[

−

′
′

τ

∂
∂t

U1(θ  t)
U2(θ  t)

= ρ

W11 W12
W21 W22

r1(θ
r2(θ

  t)
  t)

′

dθ

+

I ext
1
I ext
2

(θ  t)
(θ  t)

U1(θ  t)
U2(θ  t)

 

(4)

where τ is the time constant for synaptic current  which is typically in the order of 2-5ms. ρ is
the neural density. rl(θ  t) is the ﬁring rate of neurons  which increases with the synaptic input but
saturates when the synaptic input is sufﬁciently large. The saturation is mediated by the contribution

2

Figure 1: Network structure and stationary state. (A). The two networks are reciprocally connect-
ed and each of them forms a CANN. Each disk represents an excitatory neuron with its preferred
heading direction indicated by the arrow inside. The gray disk in the middle of the network repre-
sents the inhibitory neuron pool which sums the total activities of excitatory neurons and generates
divisive normalization (Eq.5). The solid line with arrow is excitatory connection with the gray level
indicating the strength. The gray dashed line with dots represents inhibitory connection. (B). The
stationary states of two networks  which can locate at anywhere in the perceptual space. Parameters:
N = 100  k = 10

−3  a = 0.5  L = 7  J11 = J22 = 1.5Jc  J12 = J21 = 0.5J11.

∫

[Ul(θ  t)]2
+
(cid:18)′[Ul(θ′  t)]2

[
− (θ − µl)2

]

4(all)2

of inhibitory neurons not explicitly presented in our framework. A solvable model captures these
features is given by divisive normalization [17  18] 

1 + kρ

rl(θ  t) =

(5)
where the symbol [x]+ denotes a half-rectifying function  i.e.  [x]+ = 0  for x ≤ 0 and [x]+ = x 
for x > 0  and k reﬂects the strength of global inhibition.
′ in the network m to the neurons θ in the
) denotes the connection from the neurons θ
) are the recurrent connections within the same network  and
) the reciprocal connections between the networks. We assume they are of

) and W22(θ  θ

+dθ′  

′

′

′

Wlm(θ  θ
network l. W11(θ  θ
′
) and W21(θ  θ
W12(θ  θ
the Gaussian form  i.e. 

′

′

Jlm√
2πalm

exp

) =

Wlm(θ  θ

(6)
where alm determines the neuronal interaction range. In the text below  we consider alm ≪ π and
effectively take −∞ < θ < ∞ in the theoretical analysis. We choose Jlm > 0  for l  m = 1  2 
implying excitatory recurrent and reciprocal neuronal interactions. The contribution of inhibitory
neurons is implicitly included in the divisive normalization.
The external inputs to two networks are given by

2a2

lm

 

[

− (θ − θ

′

)2

]

I ext
l

(θ  t) = αlexp

+ ηlξl(θ  t) 

(7)

where µl denotes the stimulus value conveyed to the network l by the corresponding sensory cue.
This can be understood as I ext
drives the network l to be stable at µl when no reciprocal interaction
and noise exist. αl is the input strength  and ξl(θ  t) is the Gaussian white noise of zero mean
and unit variance  with ηl the noise amplitude. The noise term causes the uncertainty of the input
is not critical
information  which induces ﬂuctuations of the network state. The exact form of I ext
here  as long as it has an unimodal form.

l

l

2.1 The dynamics of uncoupled networks

It is instructive to ﬁrst review the dynamics of two networks without reciprocal connection (by
setting Wlm = 0 for l ̸= m in Eq.4). In this case  the dynamics of each network is independent

3

ABNet 2(VIP)Net 1(MSTd)W11W22W12W21I2ext(vestibular cue)02550−3−2−1012302550r2(θ)θθI1ext(visual cue)r1(θ)from the other. Because of the translation-invariance of the recurrent connections Wll(θ  θ
)  each
network can support a continuous family of active stationary states even when the external input is
removed [19]. These attractor states are of Gaussian-shape  called bumps  which are given by 

′

[
− (θ − zl)2

]

4(all)2

 

~Ul(x) = U 0

l exp

(8)
√
l = [1 + (1 −
kall/ρ  the

√

π). The bumps are stable for Jll > Jc  with Jc = 2
l = 0  exist.

√
where zl is a free parameter  representing the peak position of the bump  and U 0
Jc/Jll)1=2]Jll/(4allk
2(2π)1=4
critical connection strength below which only silent states  U 0
In response to external inputs  the bump position zl is interpreted as the population decoding result
of the network. It has been proven that for a strong transient or a weak constant input  the network
bump will move toward and be stable at a position having the maximum overlap with the noisy input 
realizing the so called template-matching operation [17  18]. For temporally ﬂuctuating inputs  the
bump position also ﬂuctuates in time  and the variance of bump position measures the network
decoding uncertainty.
In a CANN  its stationary states form a continuous manifold in which the network is neutrally
stable  i.e.  the network state can translate smoothly when the external input changes continuously
[18  20]. This neutral stability is the key that enables the neural system to track moving direction 
head-direction and spatial location of objects smoothly [16  21  22]. Due to the special structure of
a CANN  it has been proved that the dynamics of a CANN is dominated by a few motion modes 
corresponding to distortions in the height  position and other higher order features of the Gaussian
bump [19]. In the weak input limit  it is enough to project the network dynamics onto the ﬁrst few
dominating motion modes and neglect the higher order ones then simplify the network dynamics
signiﬁcantly. The ﬁrst two dominating motion modes we are going to use are 

(
height : ϕ0(θ|z) = exp
position : ϕ1(θ|z) =

− (θ − z)2
[
)

4a2

exp

[
θ − z
a

]
− (θ − z)2

 

4a2

]

 

(9)

(10)

∫

(cid:18) ϕ(θ|z)dθ.

∫
where a is the width of the basis function  whose value is determined by the bump width the network
holds. By projecting a function f (θ) on a motion mode ϕ(θ|z)  we mean to compute the quantity 
(cid:18) f (θ)ϕ(θ|z)dθ/
When reciprocal connections are included  the dynamics of the two networks interact with each
other. The bump position of each network is no longer solely determined by its own input  but is
also affected by the input to the other network  enabling both networks to integrate two sensory
)  for l ̸= m 
cues via reciprocal connections. We consider the reciprocal connections  Wlm(θ  θ
also translation-invariant (Eq.6)  so that two networks still hold the key property of CANNs. That
is  they can hold a continuous family of stationary states and track time-varying inputs smoothly
(Fig.1B).

′

3 Dynamics of Coupled Networks

It is in general difﬁcult to analyze the dynamics of two coupled networks. In the text below  we
will consider the weak input limit and use a projection method to simplify the network dynamics.
The simpliﬁed model allows us to solve the network decoding performances analytically and gives
us insight into the understanding of how reciprocal connections help both networks to integrate
information optimally from independent cues.
For simplicity  we consider two networks that are completely symmetric  i.e.  they have the same
structure  i.e.  J11 = J22 ≡ Jrc  J12 = J21 ≡ Jrp  and alm = a; and they receive the same mean
input value and input strength  i.e.  µ1 = µ2 ≡ µ  α1 = α2 ≡ α and η1 = η2 ≡ η. They receive 
however  independent noises  i.e.  ⟨ξ1ξ2⟩ = 0  implying that two cues are independent to each other
given the stimulus.
In the weak input limit (i.e.  for small enough α)  we ﬁnd that the network states have approximately
Gaussian shape and their variations are dominated by the height and position changes of the bump

4

Figure 2: Characters of the network dynamics. (A). Two networks receive the same external input 
whose value jumps from −1 to 1 abruptly. The network states move smoothly from the initial to the
target position  and their main changes are the height and the position of the Gaussian bumps. (B)
The basis functions for the two dominating motion modes. (C) The simpliﬁed network dynamics
after projecting onto the two dominating motion modes. Parameters: α1 = α2 = 0.2U 0  η1 = η2 =
0  and others are the same as Fig.1.

(see Fig.2). Thus  we take the Gaussian ansatz and assume the network states to be

Ul(θ  t) ≈ A(t)exp

rl(θ  t) ≈ B(t)exp

[
− (θ − zl(t))2
[
− (θ − zl(t))2

4a2

]
]

2a2

 

 

(11)

(12)

√
2πkρa[A]2

+/(1 +

where A(t) represents the bump height  z(t) the bump position in the network l  a the bump width
and B = [A]2
+) according to Eq.(5). Note that the bumps in two networks have
the same shape but different positions due to independent noises.
Substituting Eqs.(11 12) and (7) into the network dynamics Eq.(4)  and projecting them onto the
height and position motion modes (9-10)  we obtain the dynamics for the height and position of the
bumps in two networks (see Supplemental information 1)  which are

τ

τ

dA
dt
dz1
dt

τ

dz2
dt

= −A + ( ~Jrc + ~Jrp)B + α 

=

=

~JrpB
A
~JrpB
A

(z2 − z1) +
(z1 − z2) +

α
A

α
A

√
a
√
a

2η

2η

(2π)1=4A

(13)

(14)

ξ1(t) 

ξ2(t) 

(15)

√
where ~J ≡ ρJ/
2 for simplifying notation. By removing the external inputs (by setting α = 0 in
Eq.(13))  we can get the necessary condition for the networks holding self-sustained bump states 
which is (see Supplemental information 2)
√
Jrc + Jrp ≥ 2

2(2π)1=4

ka/ρ.

(16)

(2π)1=4A

It indicates that positive reciprocal interactions Jrp help the networks to retain attractor states.
To get clear understanding of the effect of reciprocal connections  we decouple the dynamics of
z1 and z2 by studying the dynamics of their their difference  zd = z1 − z2  and their summation 
zs = z1 + z2. From Eqs.(14) and (15)  we obtain
= − α + 2 ~JrpB

(17)

τ

ϵd(t) 

zd +

(µ − z1) +
(µ − z2) +
√

√
√
2
2η
a
√
√
(2π)1=4A
2
a
2η
(2π)1=4A

ϵs(t) 

dzd
dt

A

τ

dzs
dt

= − α
A

zs +

2α
A

µ +

5

(18)

Height02040−11tτ)Positionφ0−3−2−10123φ1BasisProjection−3−2−1012302550−3−2−1012302550ABCθθr2(θ)r1(θ)(cid:182)(cid:169)f((cid:169))(θ(cid:95)z)d(cid:169)(cid:182)(cid:169)(θ(cid:95)z)d(cid:169)02550Az(1√
where ϵd(t) and ϵs(t) are independent Gaussian white noises re-organized from ξ1(t) and ξ2(t)
2ϵ = ξ1 ± ξ2).
(
By solving the above stochastic differential equations  we get the means and variances of zd and zs
in the limit of t = ∞  which are

⟨zd⟩ = 0 

Var(zd) ≡ ⟨
Var(zs) ≡ ⟨

⟩
⟨zs⟩ = 2µ 
(zd − ⟨zd⟩)2
⟩
(zs − ⟨zs⟩)2

=

1

α + 2 ~JrpB

4η2a√
2πτ A
4η2a√
2πτ Aα

 

(19)

(20)

 

=

(21)
where the symbol ⟨·⟩ represents averaging over many trails. Eq.(20) indicates that the positive re-
ciprocal connections ~Jrp tend to decrease the variance of zd  i.e  the difference between the states in
two networks (in practice  varying ~Jrp also induces mild changes in A  B and a; we have conﬁrmed
in simulation that for a wide range of parameters  increasing ~Jrp indeed decrease Var(zd)).
The decoding error of each network  measured by the variance of zl  is calculated to be (two net-
works have the same result due to the symmetry) 

⟨zl⟩ = µ 

for

l = 1  2 

Var(zl) = [Var(zd) + Var(zs)] /4 

=

η2a√
2πτ A

1
α

+

1

α + 2 ~JrpB

.

(

)

(22)

(23)

We see that the network decoding is unbiased and their errors tend to decrease with the reciprocal
connection strength ~Jrp (see the second term in the right-hand of Eq.23). It is easy to check that in
the extreme cases and assuming the bump shape is unchanged (which is not true but is still a good
indication)  the network decoding variance with vanishing reciprocal interaction ( ~Jrp = 0) is two-
fold of that with inﬁnitely strong reciprocal interactions ( ~Jrp = ∞). Thus  reciprocal connections
between networks do provide an effective way to integrate information from independent input cues.
To further display the advantage of reciprocal connection  we also calculate the situation when a
√
single network receives both input cues. This equals to setting the external input to a single CANN
−(x−(cid:22))2=4a2
to be I ext(x  t) = 2αe
2ηξ(x  t) (see Eq.(7) and consider the independence between
√
√
two cues). The result in this case can be obtained straightforwardly from Eq.(23) by choosing
~Jrp = 0 and replacing η with
2πτ Aα).
2η and α with 2α  which gives Var(z)single = 2η2a/(
This result equals to the error when two networks are uncoupled and is larger than that of the coupled
case.
In the weak input limit  the decoding errors in general situations when two networks are not sym-
metric can also be calculated  (see Supplemental information 3)

+

Var(z1) =

2a√
2πτ

1 + ( ~J12B2)2η2
[( ~J12B2α2 + ~J21B1α1 + α1α2)A2/A1 + ( ~J21B1 + α2)2]η2
( ~J12B2A2 + α1A2 + ~J21B1A1 + α2A1)( ~J12B2α2 + ~J21B1α1 + α1α2)

2

. (24)

Var(z2) has the same form as Var(z1) except that the indexes 1 and 2 are interchanged.

4 Coupled Networks Implement Bayesian Information Integration

In this section  we compare the network performances with experimental ﬁndings. Mimicking the
experimental setting for exploring the integration of visual and vestibular cues in the inference of
heading direction [6  7]  we apply three input conditions to two networks (see Fig.3A)  which are:

• Only visual cue:
• Only vestibular cue: α1 = 0 
• Combined cues:

α1 = α  α2 = 0.
α2 = α.
α1 = α  α2 = α.

In three conditions  the noise amplitude is unchanged and the reciprocal connections are intact.

6

Figure 3: Two coupled-networks implement (nearly) Bayesian inference. (A). The three input con-
ditions to two networks. (B). The bump position of the network 1 ﬂuctuates around the true stimulus
value 0. The right panel displays the bump position distributions in three input conditions  from
which we estimate the mean and variance of the decoding results. (C) (D). Compared the network
decoding results with two cues with the predictions of Bayesian inference. (C) for the mean val-
ue and (D) for the variance. Different combinations of the input strengths αl and the reciprocal
connection strengths Jrp are chosen. Parameters: µ1 = −0.07  µ2 = 0.07  η1 = η2 = 0.5 
αi ∈ [0.1  0.5]U 0  Jrp ∈ [0.3  1]Jrc  and the others are the same as Fig.1.

Considering the symmetric structures of two networks and ignoring the mild changes in the bump
shape in the weak input limit  we can obtain from Eq.(24) the decoding variance in the three input
conditions  which are (because of the symmetry  only the results for the network 1 are shown)

Var(z1|cvi) =
Var(z1|cve) =

Var(z1|cb) =

2aη2√
2πτ αA
2aη2√
2πτ αA
2aη2√
2πτ αA

 

~JrpB + α

~JrpB

 

(25)

(26)

(27)
where Var(z1|cvi)  Var(z1|cve) and Var(z1|cb) denote  respectively  the decoding errors when only
the visual cue  only the vestibular cue and both cues are presented. It is straightforward to check that

 

~JrpB + α
2 ~JrpB + α

1

Var(z1|cb)

=

1

Var(z1|cvi)

+

1

Var(z1|cve)

.

(28)

Thus  in the weak input limit  the coupled CANNs implements Bayesian inference perfectly (com-
pare Eq.(28) to the Bayesian criterion Eq.(3)).
We carry out simulations to further conﬁrm the above theoretical analysis. We run the network
dynamics under three input conditions for many trials  and calculate the means and variances of
the bump positions in each condition. Fig.3B shows that the bump position ﬂuctuations become

7

Net 1 (MSTd)Net 2 (VIP)Visual cueVestibular cueBoth cuesInput conditionA0100200300400500−0.0500.05t (τ)zP(|c)BCDI2extI1extI1extI2ext(z |c  )1vi(z |c   )1ve(z |c  )1bl1z1−0.0500.05−0.0500.05Bayesian estimate of meanNetwork mean  Net 1Net 200.51x 10−400.51x 10−4Bayesian estimate of varianceNetwork varianceFigure 4: The decoding mean of the network 1
shifts toward the more reliable cue. The col-
or encodes the ratio of the input strengths to t-
wo networks α1/α2  which generates varied re-
liability for two cues. For increasing the ratio
Var(z1|cvi)/Var(z1|cve)  i.e.  the vestibular cue
becomes more reliable than the visual one  the
network estimation shifts to the stimulus value
µ2 conveyed by the vestibular cue. Parameters:
µ1 = 0.07  µ2 = −0.07  η1 = η2 = 0.01 and the
others are the same as Fig.1.

narrower in the combined cue input condition  indicating greater accuracy in the decoding. We
compare the result when both cues are presented with the prediction of the Bayesian inference 
obtained by using Eqs.(2  3). Fig.3C and D show that two networks indeed achieve near Bayesian
optimal inference for a wide range of input amplitudes and reciprocal connection strengths.
A salient feature of Bayesian inference is that its decoding value is biased to the more reliable cue.
The reliability of cues is quantiﬁed by their variance ratio  e.g.  (σvi)2 < (σve)2 means that vi-
sual cue is more reliable than vestibular cue. From Eq.2  we see that Bayesian inference gives a
larger weight to the more reliable cue. This property has been used as a criterion in experiment
to check the implementation of Bayesian inference  called “reliability based cue weighting” [23].
We also test this property in our model. To achieve different reliability of the cues  we adjust the
input strength α1  and keep the other input parameters unchanged  mimicking the experimental
ﬁnding that the ﬁring rate of MT neuron  the earlier stage before MSTd  increases with the input
coherence for its preferred stimuli [24]. With varying input strengths α1  and hence varied ratios
Var(z1|cvi)/Var(z1|cve)  we calculate the mean of the network decoding. Fig. 4 shows that the de-
coded mean in the combined cues condition indeed shifts towards to the more reliable cue  agreeing
with the experimental ﬁnding and the property of Bayesian inference.

5 Conclusion

In the present study  we have proposed a novel mechanism to implement Bayesian information inte-
gration. We consider two networks which are reciprocally connected  and each of them is modeled
as a CANN receiving the stimulus information from an independent cue. Our network model may
be regarded as mimicking the information integration on heading direction between the neural cir-
cuits in MSTd and VIP. Experimental data has revealed that the two areas are densely connected in
reciprocity and that neurons in both areas are widely tuned by heading direction  favoring our model
assumptions.
We use a projection method to solve the network dynamics in the weak input limit analytically
and get insights into how positive reciprocal connections enable one network to effectively inte-
grate information from the other. We then carry out simulations to conﬁrm the theoretical analysis 
following the experimental protocols. Our results show that both networks realize near Bayesian op-
timal decoding for a wide range of parameters  supporting the experimental ﬁnding that both MSTd
and VIP optimally integrate the visual and the vestibular cues in heading direction inference  though
each of them only receives a single cue directly.
Our study may have a far-reaching implication on neural information processing. It suggests that
the brain can implement efﬁcient information integration in a distributive manner through reciprocal
connections between cortical regions. Compared to centralized information integration  distributive
processing is more robust to local failures and facilitates parallel computation.

6 Acknowledgements

This work is supported by National Foundation of Natural Science of China (No.91132702 and
No.31261160495).

8

(     )(     )00.511.52−0.0700.07Var(z1|c   )vi/Var(z1|c   )veµbµviµ  ve  α1/α20.511.522.5References
[1] L. R. Harris  M. Jenkin  D. C. Zikovitz  Experimental Brain Research 135  12 (2000).
[2] R. Bertin  A. Berthoz  Experimental Brain Research 154  11 (2004).
[3] B. E. Stein  T. R. Stanford  Nature Reviews Neuroscience 9  255 (2008).
[4] R. J. van Beers  A. C. Sittig  J. J. D. van der Gon  Journal of Neurophysiology 81  1355 (1999).
[5] M. O. Ernst  M. S. Banks  Nature 415  429 (2002).
[6] Y. Gu  D. E. Angelaki  G. C. DeAngelis  Nature Neuroscience 11  1201 (2008).
[7] A. Chen  G. C. DeAngelis  D. E. Angelaki  The Journal of Neuroscience 33  3567 (2013).
[8] R. A. Jacobs  Vision Research 39  3621 (1999).
[9] W. J. Ma  J. M. Beck  P. E. Latham  A. Pouget  Nature Neuroscience 9  1432 (2006).
[10] Y. Gu  P. V. Watkins  D. E. Angelaki  G. C. DeAngelis  The Journal of Neuroscience 26  73

(2006).

[11] A. Chen  G. C. DeAngelis  D. E. Angelaki  The Journal of Neuroscience 31  3082 (2011).
[12] D. Boussaoud  L. G. Ungerleider  R. Desimone  Journal of Comparative Neurology 296  462

(1990).

[13] J. S. Baizer  L. G. Ungerleider  R. Desimone  The Journal of Neuroscience 11  168 (1991).
[14] J. Vincent  et al.  Nature 447  83 (2007).
[15] A. Chen  G. C. DeAngelis  D. E. Angelaki  The Journal of Neuroscience 31  12036 (2011).
[16] K. Zhang  The Journal of Neuroscience 16  2112 (1996).
[17] S. Deneve  P. Latham  A. Pouget  Nature Neuroscience 2  740 (1999).
[18] S. Wu  S.-I. Amari  H. Nakahara  Neural Computation 14  999 (2002).
[19] C. A. Fung  K. M. Wong  S. Wu  Neural Computation 22  752 (2010).
[20] S.-I. Amari  Biological Cybernetics 27  77 (1977).
[21] A. P. Georgopoulos  M. Taira  A. Lukashin  et al.  Science 260  47 (1993).
[22] A. Samsonovich  B. L. McNaughton  The Journal of Neuroscience 17  5900 (1997).
[23] C. R. Fetsch  A. Pouget  G. C. DeAngelis  D. E. Angelaki  Nature Neuroscience 15  146 (2011).
[24] K. H. Britten  M. N. Shadlen  W. T. Newsome  J. A. Movshon  et al.  Visual Neuroscience 10 

1157 (1993).

9

,Wen-Hao Zhang
Si Wu
Chelsea Finn
Ian Goodfellow
Sergey Levine