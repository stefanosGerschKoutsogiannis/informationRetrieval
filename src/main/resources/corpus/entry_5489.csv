2007,The Noisy-Logical Distribution and its Application to Causal Inference,We describe a novel noisy-logical distribution for representing the distribution of a binary output variable conditioned on multiple binary input variables. The distribution is represented in terms of noisy-or's and noisy-and-not's of causal features which are conjunctions of the binary inputs. The standard noisy-or and noisy-and-not models  used in causal reasoning and artificial intelligence  are special cases of the noisy-logical distribution. We prove that the noisy-logical distribution is complete in the sense that it can represent all conditional distributions provided a sufficient number of causal factors are used. We illustrate the noisy-logical distribution by showing that it can account for new experimental findings on how humans perform causal reasoning in more complex contexts. Finally  we speculate on the use of the noisy-logical distribution for causal reasoning and artificial intelligence.,The Noisy-Logical Distribution and its Application to

Causal Inference

University of California at Los Angeles

University of California at Los Angeles

Hongjing Lu

Department of Psychology

Los Angeles  CA 90095
hongjing@ucla.edu

Alan Yuille

Department of Statistics

Los Angeles  CA 90095

yuille@stat.ucla.edu

Abstract

We describe a novel noisy-logical distribution for representing the distribution of
a binary output variable conditioned on multiple binary input variables. The distri-
bution is represented in terms of noisy-or’s and noisy-and-not’s of causal features
which are conjunctions of the binary inputs. The standard noisy-or and noisy-and-
not models  used in causal reasoning and artiﬁcial intelligence  are special cases
of the noisy-logical distribution. We prove that the noisy-logical distribution is
complete in the sense that it can represent all conditional distributions provided a
sufﬁcient number of causal factors are used. We illustrate the noisy-logical dis-
tribution by showing that it can account for new experimental ﬁndings on how
humans perform causal reasoning in complex contexts. We speculate on the use
of the noisy-logical distribution for causal reasoning and artiﬁcial intelligence.

1 Introduction

The noisy-or and noisy-and-not conditional probability distributions are frequently studied in cog-
nitive science for modeling causal reasoning [1]  [2] [3] and are also used as probabilistic models
for artiﬁcial intelligence [4]. It has been shown  for example  that human judgments of the power of
causal cues in experiments involving two cues [1] can be interpreted in terms of maximum likelihood
estimation and model selection using these types of models [3].
But the noisy-or and noisy-and-not distributions are limited in the sense that they can only represent
a restricted set of all possible conditional distributions. This restriction is sometimes an advantage
because there may not be sufﬁcient data to determine the full conditional distribution. Nevertheless it
would be better to have a representation that can expand to represent the full conditional distribution 
if sufﬁcient data is available  but can be reduced to simpler forms (e.g. standard noisy-or) if there is
only limited data.
This motivates us to deﬁne the noisy-logical distribution. This is deﬁned in terms of noisy-or’s
and noisy-and-not’s of causal features which are conjunctions of the basic input variables (inspired
by the use of conjunctive features in [2] and the extensions in [5]). By restricting the choice of
causal features we can obtain the standard noisy-or and noisy-and-not models. We prove that the
noisy-logical distribution is complete in the sense that it can represent any conditional distribution
provided we use all the causal features. Overall  it gives a distribution whose complexity can be
adjusted by restricting the number of causal features.
To illustrate the noisy-logical distribution we apply it to modeling some recent human experiments
on causal reasoning in complex environments [6]. We show that noisy-logical distributions involv-
ing causal factors are able to account for human performance. By contrast  an alternative linear
model gives predictions which are the opposite of the observed trends in human causal judgments.
Section (2) presents the noisy-logical distribution for the case with two input causes (the case com-
monly studied in causal reasoning). In section (3) we specify the full noisy-logical distribution and

1

we prove its completeness in section (4). Section (5) illustrates the noisy-logical distribution by
showing that it accounts for recent experimental ﬁndings in causal reasoning.

2 The Case with N = 2 causes

In this section we study the simple case when the binary output effect E depends only on two binary-
valued causes C1  C2. This covers most of the work reported in the cognitive science literature
[1] [3]. In this case  the probability distribution is speciﬁed by the four numbers P (E = 1|C1  C2) 
for C1 ∈ {0  1}  C2 ∈ {0  1}.
To deﬁne the noisy-logical distribution over two variables P (E = 1|C1  C2)  we introduce three
concepts. Firstly  we deﬁne four binary-valued causal features Ψ0(.)  Ψ1(.)  Ψ2(.)  Ψ3(.) which are
functions of the input state (cid:126)C = (C1  C2). They are deﬁned by Ψ0( (cid:126)C) = 1  Ψ1( (cid:126)C) = C1  Ψ2( (cid:126)C) =
C2  Ψ3( (cid:126)C) = C1∧C2  where ∧ denotes logical-and operation(i.e. C1∧C2 = 1 if C1 = C2 = 1 and
C1 ∧ C2 = 0 otherwise). Ψ3( (cid:126)C) is the conjunction of C1 and C2. Secondly  we introduce binary-
valued hidden states E0  E1  E2  E3 which are caused by the corresponding features Ψ0  Ψ1  Ψ2  Ψ3.
We deﬁne P (Ei = 1|Ψi; ωi) = ωiΨi with ωi ∈ [0  1]  for i = 1  ...  4 with (cid:126)ω = (ω1  ω2  ω3  ω4).
Thirdly  we deﬁne the output effect E to be a logical combination of the states E0  E1  E2  E3
which we write in form δE f (E0 E1 E2 E3)  where f(.  .  .  .) is a logic function which is formed by a
combination of three logic operations AN D  OR  N OT . This induces the noisy-logical distribution
Pnl(E| (cid:126)C; (cid:126)ω) =
The noisy-logical distribution is characterized by the parameters ω0  ...  ω3 and the choice of the
logic function f(.  .  .  .). We can represent the distribution by a circuit diagram where the output E
is a logical function of the hidden states E0  ...  E3 and each state is caused probabilistically by the
corresponding causal features Ψ0  ...  Ψ3  as shown in Figure (1).

(cid:81)3
i=0 P (Ei|Ψi( (cid:126)C); ωi).

E0 ... E3 δE f (E0 E1 E2 E3)

(cid:80)

Figure 1: Circuit diagram in the case with N = 2 causes.

(cid:88)

E1 E2

The noisy-logical distribution includes the commonly known distributions  noisy-or and noisy-and-
not  as special cases. To obtain the noisy-or  we set E = E1 ∨ E2 (i.e. E1 ∨ E2 = 0 if E1 = E2 = 0
and E1 ∨ E2 = 1 otherwise). A simple calculation shows that the noisy-logical distribution reduces
to the noisy-or Pnor(E|C1  C2; ω1  ω2) [4]  [1]:

Pnl(E = 1|C1  C2; ω1  ω2) =

δ1 E1∨E2P (E1|Ψ1( (cid:126)C); ω1)P (E2|Ψ2( (cid:126)C); ω2)
= ω1C1(1 − ω2C2) + (1 − ω1C1)ω2C2 + ω1ω2C1C2
= ω1C1 + ω2C2 − ω1ω2C1C2 = Pnor(E = 1|C1  C2; ω1  ω2)(1)
To obtain the noisy-and-not  we set E = E1 ∧ ¬E2 (i.e. E1 ∧ ¬E2 = 1 if E1 = 1  E2 = 0
and E1 ∧ ¬E2 = 0 otherwise). The noisy-logical distribution reduces to the noisy-and-not
Pn−and−not(E|C1  C2; ω1  ω2) [4] [?]:

(cid:88)

Pnl(E = 1|C1  C2; ω1  ω2) =

δ1 E1∧¬E2P (E1|Ψ1( (cid:126)C); ω1)P (E2|Ψ2( (cid:126)C); ω2)

E1 E2

= ω1C1{1 − ω2C2} = Pn−and−not(E = 1|C1  C2; ω1  ω2) (2)

2

We claim that noisy-logical distributions of this form can represent any conditional distribution
P (E| (cid:126)C). The logical function f(E0  E1  E2  E3) will be expressed as a combination of logic oper-
ations AND-NOT  OR. The parameters of the distribution are given by ω0  ω1  ω2  ω3.
The proof of this claim will be given for the general case in the next section. To get some insight 
we consider the special case where we only know the values P (E|C1 = 1  C2 = 0) and P (E|C1 =
1  C2 = 1). This situation is studied in cognitive science where C1 is considered to be a background
cause which always takes value 1  see [1] [3]. In this case  the only causal features are considered 
Ψ1( (cid:126)C) = C1 and Ψ2( (cid:126)C) = C2.
Result. The noisy-or and the noisy-and-not models  given by equations (1 2) are sufﬁcient to ﬁt any
values of P (E = 1|1  0) and P (E = 1|1  1). (In this section we use P (E = 1|1  0) to denote
P (E = 1|C1 = 1  C2 = 0) and use P (E = 1|1  1) to denote P (E = 1|C1 = 1  C2 = 1).)
The noisy-or and noisy-and-not ﬁt the cases when P (E = 1|1  1) ≥ P (E = 1|1  0) and P (E =
1|1  1) ≤ P (E = 1|1  0) respectively. In Cheng’s terminology [1] C2 is respectively a generative or
preventative cause).
Proof. We can ﬁt both the noisy-or and noisy-and-not models to P (E|1  0) by setting ω1 = P (E =
1|1  0)  so it remains to ﬁt the models to P (E|1  1). There are three cases to consider: (i) P (E =
1|1  1) > P (E = 1|1  0)  (ii) P (E = 1|1  1) < P (E = 1|1  0)  and (iii) P (E = 1|1  1) =
P (E = 1|1  0).
It follows directly from equations (1 2) that Pnor(E = 1|1  1) ≥ Pnor(E =
1|1  0) and Pn−and−not(E = 1|1  1) ≤ Pn−and−not(E = 1|1  0) with equality only if P (E =
1|1  1) = P (E = 1|1  0). Hence we must ﬁt a noisy-or and a noisy-and-not model to cases (i)
and (ii) respectively. For case (i)  this requires solving P (E = 1|1  1) = ω1 + ω2 − ω1ω2 to
obtain ω2 = {P (E = 1|1  1) − P (E = 1|1  0)}/{1 − P (E = 1|1  0)} (note that the condition
P (E = 1|1  1) > P (E = 1|1  0) ensures that ω2 ∈ [0  1]). For case (ii)  we must solve P (E =
1|1  1) = ω1 − ω1ω2 which gives ω2 = {P (E = 1|1  0) − P (E = 1|1  1)}/P (E = 1|1  0) (the
condition P (E = 1|1  1) < P (E = 1|1  0) ensures that ω2 ∈ [0  1]). For case (iii)  we can ﬁt either
model by setting ω2 = 0.

3 The Noisy-Logical Distribution for N causes

We next consider representing probability distributions of form P (E| (cid:126)C)  where E ∈ {0  1} and
(cid:126)C = (C1  ...  CN ) where Ci ∈ {0  1}  ∀i = 1  ..  N. These distributions can be characterized by
the values of P (E = 1| (cid:126)C) for all possible 2N values of (cid:126)C.
We deﬁne the set of 2N binary-valued causal features {Ψi( (cid:126)C) : i = 0  ...  2N − 1}. These features
are ordered so that Ψ0( (cid:126)C) = 1  Ψi( (cid:126)C) = Ci : i = 1  ..  N  ΨN +1( (cid:126)C) = C1 ∧ C2 is the conjunction
of C1 and C2  and so on. The feature Ψ( (cid:126)C) = Ca ∧ Cb ∧ ... ∧ Cg will take value 1 if Ca = Cb =
... = Cg = 1 and value 0 otherwise.
We deﬁne binary variables {Ei : i = 0  ...  2N − 1} which are related to the causal features {Ψi :
i = 0  ...  2N − 1} by distributions P (Ei = 1|Ψi; ωi) = ωiΨi  speciﬁed by parameters {ωi : i =
0  ...  2N − 1}.
Then we deﬁne the output variable E to be a logical (i.e. deterministic) function of the {Ei
:
i = 0  ...  2N − 1}. This can be thought of as a circuit diagram. In particular  we deﬁne E =
f(E0  ...  E2N−1) = (((((E1 ⊗ E2) ⊗ E3) ⊗ E4....) where E1 ⊗ E2 can be E1 ∨ E2 or E1 ∧ ¬E2
(where ¬E means logical negation). This gives the general noisy-logical distribution  as shown in
Figure (2).

(cid:88)

2N−1(cid:89)

P (E = 1| (cid:126)C; (cid:126)ω) =

δE f (E0 ... E2N −1)

P (Ei = 1|Ψi; ωi).

(3)

(cid:126)E

i=0

4 The Completeness Result

This section proves that the noisy-logical distribution is capable of representing any conditional
distribution. This is the main theoretical result of this paper.

3

Figure 2: Circuit diagram in the case with N causes. All conditional distributions can be represented
in this form if we use all possible 2N causal features Ψ  choose the correct parameters ω  and select
the correct logical combinations ⊗.

Result We can represent any conditional distribution P (E| (cid:126)C) deﬁned on binary variables in terms
of a noisy logical distribution given by equation (3).
Proof. The proof is constructive. We show that any distribution P (E| (cid:126)C) can be expressed as a
noisy-logical distribution.
We order the states (cid:126)C0  ...  (cid:126)C2N−1. This ordering must obey Ψi( (cid:126)Ci) = 1 and Ψi( (cid:126)Cj) = 0  ∀j < i.
This ordering can be obtained by setting (cid:126)C0 = (0  ...  0)  then selecting the terms with a single
conjunction (i.e. only one Ci is non-zero)  then those with two conjunctions (i.e.
two Ci’s are
non-zero)  then with three conjunctions  and so on.
The strategy is to use induction to build a noisy-logical distribution which agrees with P (E| (cid:126)C)
for all values of (cid:126)C. We loop over the states and incrementally construct the logical function
f(E0  ...  E2N−1) and estimate the parameters ω0  ...  ω2N−1. It is convenient to recursively de-
ﬁne a variable Ei+1 = Ei ⊗ Ei  so that f(E0  ...  E2N−1) = E2N−1.
We start the induction using feature Ψ0( (cid:126)C) = 1. Set E0 = E0 and ω0 = P (E|0  ...  0). Then
P (E0| (cid:126)C0; ω0) = P (E| (cid:126)C0)  so the noisy-logical distribution ﬁts the data for input (cid:126)C0.
Now proceed by induction to determine EM +1 and ωM +1  assuming that we have determined EM
and ω0  ...  ωM such that P (EM = 1| (cid:126)Ci; ω0  ...  ωM ) = P (E = 1| (cid:126)Ci)  for i = 0  ...  M. There are
three cases to consider which are analogous to the cases considered in the section with two causes.
Case 1. If P (E = 1| (cid:126)CM +1) > P (EM = 1| (cid:126)CM +1; ω0  ...  ωM ) we need ΨM +1( (cid:126)C) to be a genera-
tive feature. Set EM +1 = EM ∨ EM +1 with P (EM +1 = 1|ΨM +1; ωM +1) = ωM +1ΨM +1. Then
we obtain:
P (EM +1 = 1| (cid:126)CM +1; ω0  .  ωM +1) = P (EM = 1| (cid:126)CM +1; ω0  .  ωM )+P (EM +1|ΨM +1( (cid:126)C); ωM +1)

−P (EM = 1| (cid:126)CM +1; ω0  .  ωM )P (EM +1 = 1|ΨM +1( (cid:126)C); ωM +1) =

P (EM = 1| (cid:126)CM +1; ω0  .  ωM )+ωM +1ΨM +1( (cid:126)C)−P (EM = 1| (cid:126)CM +1; ω0  .  ωM )ωM +1ΨM +1( (cid:126)C)
In particular  we see that P (EM +1 = 1| (cid:126)Ci; ω0  ...  ωM +1) = P (EM = 1| (cid:126)Ci; ω0  ...  ωM ) =
P (E = 1| (cid:126)Ci) for i < M + 1 (using ΨM +1( (cid:126)Ci) = 0  ∀i < M + 1). To determine the value
of ωM +1  we must solve P (E = 1| (cid:126)CM +1) = P (EM = 1| (cid:126)CM +1; ω0  ...  ωM ) + ωM +1 − P (EM =
1| (cid:126)CM +1; ω0  ...  ωM )ωM +1 (using ΨM +1( (cid:126)CM +1) = 1). This gives ωM +1 = {P (E = 1| (cid:126)CM +1) −
P (EM = 1| (cid:126)CM +1; ω0  ...  ωM )}/{1 − P (EM = 1| (cid:126)CM +1; ω0  ...  ωM +1)} (the conditions ensure
that ωM +1 ∈ [0  1]).
Case 2. If P (E = 1| (cid:126)CM +1) < P (EM = 1| (cid:126)CM +1; ω0  ...  ωM ) we need ΨM +1( (cid:126)C) to be a preven-
tative feature. Set EM +1 = EM ∧ ¬EM +1 with P (EM +1 = 1|ΨM +1; ωM +1) = ωM +1ΨM +1.
Then we obtain:
P (EM +1 = 1| (cid:126)CM +1; ω0  ...  ωM +1) = P (EM = 1| (cid:126)CM +1; ω0  ...  ωM ){1 − ωM +1ΨM +1( (cid:126)C)}.
(4)

4

As for the ﬁrst case  P (EM +1 = 1| (cid:126)Ci; ω0  ...  ωM +1) = P (EM = 1| (cid:126)Ci; ω0  ...  ωM ) = P (E =
1| (cid:126)Ci) for i < M + 1 (because ΨM +1( (cid:126)Ci) = 0  ∀i < M + 1). To determine the value of
ωM +1 we must solve P (E = 1| (cid:126)CM +1) = P (EM = 1| (cid:126)CM +1; ω0  ...  ωM ){1 − ωM +1} (us-
ing ΨM +1( (cid:126)CM +1) = 1). This gives ωM +1 = {P (EM = 1| (cid:126)CM +1; ω0  ...  ωM ) − P (E =
1| (cid:126)CM +1)}/P (EM = 1| (cid:126)CM +1; ω0  ...  ωM ) (the conditions ensure that ωM +1 ∈ [0  1]).
Case 3. If P (E = 1| (cid:126)CM +1) = P (EM = 1| (cid:126)CM +1; ω0  ...  ωM )  then we do nothing.

5 Cognitive Science Human Experiments

We illustrate noisy-logical distributions by applying them to model two recent cognitive science
experiments by Liljeholm and Cheng which involve causal reasoning in complex environments [6].
In these experiments  the participants are asked questions about the causal structure of the data.
But the participants are not given enough data to determine the full distribution (i.e. not enough
to determine the causal structure with certainty). Instead the experimental design forces them to
choose between two different causal structures.
We formulate this as a model selection problem [3].
Formally  we specify distributions
P (D|(cid:126)ω  Graph) for generating the data D from a causal model speciﬁed by Graph and parameter-
ized by (cid:126)ω. These distributions will be of simple noisy-logical form. We set the prior distributions
P ((cid:126)ω|Graph) on the parameter values to be the uniform distribution. The evidence for the causal
model is given by:

(cid:90)

P (D|Graph) =

d(cid:126)ωP (D|(cid:126)ω  Graph)P ((cid:126)ω|Graph).

(5)

We then evaluate the log-likelihood ratio log P (D|Graph1)
P (D|Graph2) between two causal models Graph1
Graph2  called the causal support [3] and use this to predict the performance of the participants.
This gives good ﬁts to the experimental results.
As an alternative theoretical model  we consider the possibility that the participants use the same
causal structures  speciﬁed by Graph1 and Graph2  but use a linear model to combine cues.
Formally  this corresponds to a model P (E = 1|C1  ...  CN ) = ω1C1 + ... + ωN CN (with
ωi ≥ 0  ∀i = 1  ...  N and ω1 + ... + ωN ≤ 1). This model corresponds [1  3] to the classic
Rescorla-Wagner learning model [8].
It cannot be expressed in simple noisy-logical form. Our
simulations show that this model does not account for human participant performance .
We note that previous attempts to model experiments with multiple causes and conjunctions by
Novick and Cheng [2] can be interpreted as performing maximum likelihood estimation of the pa-
rameters of noisy-logical distributions (their paper helped inspire our work). Those experiments 
however  were simpler than those described here and model selection was not used. The extensive
literatures on two cases [1  3] can also be interpreted in terms of noisy-logical models.

5.1 Experiment I: Multiple Causes

In Experiment 1 of [6]  the cover story involves a set of allergy patients who either did or did not
have a headache  and either had or had not received allergy medicines A and B. The experimental
participants were informed that two independent studies had been conducted in different labs us-
ing different patient groups. In the ﬁrst study  patients were administered medicine A  whereas in
the second study patients were administered both medicines A and B. A simultaneous presenta-
tion format [7] was used to display the speciﬁc contingency conditions used in both studies to the
experimental subjects. The participants were then asked whether medicine B caused the headache.
We represent this experiment as follows using binary-valued variables E  B1  B2  C1  C2. The vari-
able E indicates whether a headache has occurred (E = 1) or not (E = 0). B1 = 1 and B2 = 1 no-
tate background causes for the two studies (which are always present). C1 and C2 indicate whether
medicine A and B are present respectively (e.g. C1 = 1 if A is present  C1 = 0 otherwise). The
data D shown to the subjects can be expressed as D = (D1  D2) where D1 is the contingency table
Pd(E = 1|B1 = 1  C1 = 0  C2 = 0)  Pd(E = 1|B1 = 1  C1 = 1  C2 = 0) for the ﬁrst study

5

and D2 is the contingency table Pd(E = 1|B2 = 1  C1 = 0  C2 = 0)  Pd(E = 1|B2 = 1  C1 =
1  C2 = 1) for the second study.
The experimental design forces the participants to choose between the two causal models shown
on the left of ﬁgure (3).
These causal models differ by whether C2 (i.e. medicine B)
can have an effect or not. We set P (D|(cid:126)ω  Graph) = P (D1|(cid:126)ω1  Graph)P (D2|(cid:126)ω2  Graph) 
i )} (for i = 1  2) is the contingency data. We express these distribu-
where Di = {(Eµ  (cid:126)C µ
tions in form P (Di|(cid:126)ωi  Graph) =
i   Graph). For Graph1  P1(.) and P2(.)
are P (E|B1  C1  ωB1  ωC1) and P (E|B2  C1  ωB2  ωC1).
For Graph2  P1(.) and P2(.) are
P (E|B1  C1  ωB1  ωC1) and P (E|B2  C1  C2  ωB2  ωC1  ωC2). All these P (E|.) are noisy-or dis-
tributions.
For Experiment 1 there are two conditions [6]  see table (1). In the ﬁrst power-constant condition
[6]  the data is consistent with the causal structure for Graph1 (i.e. C2 has no effect) using noisy-or
distributions. In the second ∆P-constant condition [6]  the data is consistent with the causal structure
for Graph1 but with noisy-or replaced by the linear distributions (e.g. P (E = 1|C1  ...  Cn) =
ω1C1 + ... + ωnCn)).

µ Pi(Eµ| (cid:126)C µ

(cid:81)

i   (cid:126)ωµ

Table 1: Experimental conditions (1) and (2) for Experiment 1
(1) Pd(E = 1|B1 = 1  C1 = 0  C2 = 0)  Pd(E = 1|B1 = 1  C1 = 1  C2 = 0)
Pd(E = 1|B2 = 1  C1 = 0  C2 = 0)  Pd(E = 1|B2 = 1  C1 = 1  C2 = 1)
(2) Pd(E = 1|B1 = 1  C1 = 0  C2 = 0)  Pd(E = 1|B1 = 1  C1 = 1  C2 = 0)
Pd(E = 1|B2 = 1  C1 = 0  C2 = 0)  Pd(E = 1|B2 = 1  C1 = 1  C2 = 1)

16/24  22/24
0/24 18/24
0/24  6/24
16/24 22/24

5.2 Experiment I: Results

We compare Liljeholm and Cheng’s experimental results with our theoretical simulations. These
comparisons are shown on the right-hand-side of ﬁgure (3). The left panel shows the proportion
of participants who decide that medicine B causes a headache for the two conditions. The right
panel shows the predictions of our model (labeled ”noisy-logical”) together with predictions of a
model that replaces the noisy-logical distributions by a linear model (labeled ”linear”). The simu-
lations show that the noisy-logical model correctly predicts that participants (on average) judge that
medicine B has no effect in the ﬁrst experimental condition  but B does have an effect in the second
condition. By contrast  the linear model makes the opposite (wrong) prediction. In summary  model
selection comparing two noisy-logical models gives a good prediction of participant performance.

Figure 3: Causal model and results for Experiment I. Left panel: two alternative causal models for
the two studies. Right panel: the experimental results (proportion of patients who think medicine
B causes headaches)) for the Power-constant and ∆P-constant conditions [6]. Far right  the causal
support for the noisy-logic and linear models.

6

5.3 Experiment II: Causal Interaction

Liljeholm and Cheng [6] also investigated causal interactions. The experimental design was identical
to that used in Experiment 1  except that participants were presented with three studies in which only
one medicine (A) was tested. Participants were asked to judge whether medicine A interacts with
background causes that vary across the three studies. We deﬁne the background causes as B1 B2 B3
for the three studies  and C1 for medicine A. This experiment was also run under two different
conditions  see table (2). The ﬁrst power-constant condition [6] was consistent with a noisy-logical
model  but the second power-varying condition [6] was not.

Table 2: Experimental conditions (1) and (2) for Experiment 2
(1) P (E = 1|B1 = 1  C1 = 0)  P (E = 1|B1 = 1  C1 = 1)
P (E = 1|B2 = 1  C1 = 0)  P (E = 1|B2 = 1  C1 = 1)
P (E = 1|B3 = 1  C1 = 0)  P (E = 1|B3 = 1  C1 = 1)
(2) P (E = 1|B1 = 1  C1 = 0)  P (E = 1|B1 = 1  C1 = 1)
P (E = 1|B2 = 1  C1 = 0)  P (E = 1|B2 = 1  C1 = 1)
P (E = 1|B3 = 1  C1 = 0)  P (E = 1|B3 = 1  C1 = 1)

16/24  22/24
8/24 20/24
0/24 18/24
0/24  6/24
0/24 12/24
0/24 18/24

The experimental design caused participants to choose between two causal models shown on the
left panel of ﬁgure (4). The probability of generating the data is given by P (D|(cid:126)ω  Graph) =
P (D1|(cid:126)ω1  Graph)P (D2|(cid:126)ω2  Graph)P (D3|(cid:126)ω3  Graph).
the P (Di|.) are noisy-
or distributions P (E|B1  C1  ωB1  ωC1)  P (E|B2  C1  ωB2  ωC1)  P (E|B3  C1  ωB3  ωC1).
For
the P (Di|.) are P (E|B1  C1  ωB1  ωC1)  P (E|B2  C1  B2C1  ωB2  ωC1  ωB2C1) and
Graph2 
P (E|B3  C1  B3C1  ωB3  ωC1  ωB3C1).
All the distributions are noisy-or on the unary causal features (e.g. B  C1)  but the nature of the
conjunctive cause B ∧ C1 is unknown (i.e. not speciﬁed by the experimental design). Hence our
theory considers the possibilities that it is a noisy-or (e.g. can produce headaches) or noisy-and-not
(e.g. can prevent headaches)  see graph 2 of Figure (4).

For Graph1 

5.4 Results of Experiment II

Figure (4) shows human and model performance for the two experimental conditions. Our noisy-
logical model is in agreement with human performance – i.e. there is no interaction between causes
in the power-constant condition  but there is interaction in the power-varying condition. By contrast 
the linear model predicts interaction in both conditions and hence fails to model human performance.

Figure 4: Causal model and results for Experiment II. Left panel: two alternative causal models (one
involving conjunctions) for the three studies . Right panel: the proportion of participants who think
that there is an interaction (conjunction) between medicine A and the background for the power-
constant and power-varying conditions [6]. Far right  the causal support for the noisy-logical and
linear models.

7

6 Summary

The noisy-logical distribution gives a new way to represent conditional probability distributions
deﬁned over binary variables. The complexity of the distribution can be adjusted by restricting
the set of causal factors. If all the causal factors are allowed  then the distribution can represent
any conditional distribution. But by restricting the set of causal factors we can obtain standard
distributions such as the noisy-or and noisy-and-not.
We illustrated the noisy-logical distribution by modeling experimental ﬁndings on causal reasoning.
Our results showed that this distribution ﬁtted the experimental data and  in particular  accounted for
the major trends (unlike the linear model). This is consistent with the success of noisy-or and noisy-
and-not models for accounting for experiments involving two causes [1]  [2] [3]. This suggests that
humans may make use of noisy-logical representations for causal reasoning.
One attraction of the noisy-logical representation is that it helps clarify the relationship between
logic and probabilities. Standard logical relationships between causes and effects arise in the limit
as the ωi take values 0 or 1. We can  for example  bias the data towards a logical form by using
a prior on the (cid:126)ω. This may be useful  for example  when modeling human cognition – evidence
suggests that humans ﬁrst learn logical relationships and  only later  move to probabilities.
In summary  the noisy-logical distribution is a novel way to represent conditional probability distri-
butions deﬁned on binary variables. We hope this class of distributions will be useful for modeling
cognitive phenomena and for applications to artiﬁcial intelligence.

Acknowledgements

We thank Mimi Liljeholm  Patricia Cheng  Adnan Darwiche  Keith Holyoak  Iasonas Kokkinos  and
YingNian Wu for helpful discussions. Mimi and Patricia kindly gave us access to their experimental
data. We acknowledge funding support from the W.M. Keck foundation and from NSF 0413214.

References
[1] P. W. Cheng. From covariation to causation: A causal power theory. Psychological Review 

104  367405. 1997.

[2] L.R. Novick and P.W. Cheng. Assessing interactive causal inﬂuence. Psychological Review 

111  455-485. 2004.

[3] T. L. Grifﬁths  and J. B. Tenenbaum. Structure and strength in causal induction. Cognitive

Psychology  51  334-384  2005.

[4] J. Pearl  Probabilistic Reasoning in Intelligent Systems. Morgan-Kauffman  1988.
[5] C.N. Glymour. The Mind’s Arrow: Bayes Nets and Graphical Causal Models in Psychology.

MIT Press. 2001.

[6] M. Liljeholm and P. W. Cheng. When is a Cause the ”Same”? Coherent Generalization across

Contexts. Psychological Science  in press. 2007.

[7] M. J. Buehner  P. W. Cheng  and D. Clifford. From covariation to causation: A test of the
assumption of causal power. Journal of Experimental Psychology: Learning  Memory  and
Cognition  29  1119-1140  2003.

[8] R. A. Rescorla  and A. R. Wagner. A theory of Pavlovian conditioning: Variations in the effec-
tiveness of reinforcement and nonreinforcement. In A. H. Black and W. F. Prokasy (Eds.)  Clas-
sical conditioning II: Current theory and research (pp. 64-99). New York: Appleton-Century
Crofts. 1972.

8

,Boqing Gong
Kristen Grauman
Fei Sha
Lingqiao Liu
Chunhua Shen
Lei Wang
Anton van den Hengel
Chao Wang