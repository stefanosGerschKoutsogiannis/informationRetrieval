2019,Accurate Uncertainty Estimation and Decomposition in Ensemble Learning,Ensemble learning is a standard approach to building machine learning systems that capture complex phenomena in real-world data. An important aspect of these systems is the complete and valid quantification of model uncertainty. We introduce a Bayesian nonparametric ensemble (BNE) approach that augments an existing ensemble model to account for different sources of model uncertainty. BNE augments a model’s prediction and distribution functions using Bayesian nonparametric machinery. It has a theoretical guarantee in that it robustly estimates the uncertainty patterns in the data distribution  and can decompose its overall predictive uncertainty into distinct components that are due to different sources of noise and error. We show that our method achieves accurate uncertainty estimates under complex observational noise  and illustrate its real-world utility in terms of uncertainty decomposition and model bias detection for an ensemble in predict air pollution exposures in Eastern Massachusetts  USA.,Accurate Uncertainty Estimation and Decomposition

in Ensemble Learning

Jeremiah Zhe Liu∗

Google Research & Harvard University

zhl112@mail.harvard.edu

Marianthi-Anna Kioumourtzoglou

Columbia University

mk3961@cumc.columbia.edu

John Paisley

Columbia University

jpaisley@columbia.edu

Brent A. Coull

Harvard University

bcoull@hsph.harvard.edu

Abstract

Ensemble learning is a standard approach to building machine learning systems
that capture complex phenomena in real-world data. An important aspect of
these systems is the complete and valid quantiﬁcation of model uncertainty. We
introduce a Bayesian nonparametric ensemble (BNE) approach that augments an
existing ensemble model to account for different sources of model uncertainty.
BNE augments a model’s prediction and distribution functions using Bayesian
nonparametric machinery. It has a theoretical guarantee in that it robustly estimates
the uncertainty patterns in the data distribution  and can decompose its overall
predictive uncertainty into distinct components that are due to different sources of
noise and error. We show that our method achieves accurate uncertainty estimates
under complex observational noise  and illustrate its real-world utility in terms of
uncertainty decomposition and model bias detection for an ensemble in predict air
pollution exposures in Eastern Massachusetts  USA.

1

Introduction

Ensemble learning has a long history in areas such as robust engineering system design [4]  ﬁnancial
investment management [20]  and weather and climate forecasting [35]  where high-risk decisions
and critical projections are made in the presence of noise and uncertainty. Failure to accurately
quantify the predictive uncertainty in these ensemble systems can lead to severe consequences [1] 
such as the market crash of 2008.
To properly quantify predictive uncertainty  it is important
for an ensemble learning system to recognize different types
of uncertainties that arise in the modeling process. In ma-
chine learning modeling  two distinct types of uncertain-
ties exist: aleatoric uncertainty and epistemic uncertainty
[22] (see Figure 1). Aleatoric uncertainty arises due to the
stochastic variability inherent in the data generating process 
for example due to an imperfect sensor  and is described
by the cumulative distribution function (CDF) F(y|x Θ) of
the data speciﬁed by a given model. On the other hand 
epistemic uncertainty arises due to our lack of knowledge
about the data generating mechanism. A model’s epistemic

Figure 1: A decomposition of different
types of uncertainty by the Bayesian
Nonparametric Ensemble (BNE).

∗Work done at Harvard University.

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

OverallUncertaintyEpistemicParametricωStructural(i.e.ModelMisspeciﬁcation)PredictionFunctionδDistributionFunctionGAleatoricuncertainty can be reduced by collecting more data  whereas aleatoric uncertainty is irreducible since
it is inherent to the data generating mechanism. A machine learning model’s epistemic uncertainty
can arise from two sources [42]: parametric uncertainty that reﬂects uncertainty associated with
estimating the model parameters under the current model speciﬁcation  which can be described
by a Bayesian model’s posterior p(Θ|y x); and structural uncertainty that reﬂects the uncertainty
about whether a given model speciﬁcation is sufﬁcient for describing the data  i.e. whether there
exists a systematic discrepancy between CDF F(y|x Θ) based on the model and the data-generating
distribution F∗(y|x).
The goal of uncertainty estimation is to properly characterize both a model’s aleatoric and epistemic
uncertainties [24  42]. In regions that are well represented by the training data  a model’s aleatoric
uncertainty should accurately estimate the data-generating distribution by ﬂexibly capturing the
stochastic pattern in the data (i.e.  calibration [19])  while in regions unexplored by the training data 
the model’s epistemic uncertainty should increase to capture the model’s lack of conﬁdence in the
resulting predictions (i.e. out-of-distribution generalization [24]). Within the epistemic uncertainty 
the structural uncertainty needs to be estimated to identify the sources of structural biases in the
ensemble model  and to quantify how these structural biases may impact the model output  something
necessary for the continuous model validation and reﬁnement of a running ensemble system [40  34].
A comprehensive framework for quantifying these three types of uncertainties is currently lacking
in the ensemble learning literature. We refer readers to Supplementary Section A for a full review
and how our work is related to existing literature. Brieﬂy  existing methods typically handle the
aleatoric uncertainty using an assumed distribution family (e.g.  Gaussian) [24  48] that may not
capture the stochastic patterns in the data (e.g. asymmetry  heavy-tailedness  multimodality  or their
combinations). Work exists on quantifying epistemic uncertainty  although ensemble methods mainly
work with collections of base models of the same class  and usually do not explicitly characterize the
model’s structural uncertainty [6  9  10  50  24  51  27].
In this work  we develop an ensemble model that addresses all three sources of predictive uncer-
tainty. Our speciﬁc contributions are: 1) We propose Bayesian Nonparametric Ensemble (BNE) 
an augmentation framework that mitigates misspeciﬁcation in the original ensemble model and
ﬂexibly quantiﬁes all three sources of predictive uncertainty (Section 2). 2) We establish BNE’s
model properties in uncertainty characterization  including its theoretical guarantee with respect
to consistent estimation of aleatoric uncertainty  and its ability to decompose different sources of
epistemic uncertainties (Section 3). 3) We demonstrate through experiments that the proposed method
achieves accurate uncertainty estimation under complex observational noise and improves predictive
accuracy (Section 4)  and illustrate our method by predicting ambient ﬁne particle pollution in Eastern
Massachusetts  USA by ensembling three different existing prediction models developed by multiple
research groups (Section 5).

2 Bayesian Nonparametric Ensemble

In this section  we introduce the Bayesian Nonparametric Ensemble (BNE)  an augmentation frame-
work for ensemble learning. We focus on the application of BNE to regression tasks. Given an
ensemble model  BNE mitigates the original model’s misspeciﬁcation in the prediction function and
in the distribution function using Bayesian nonparametric machinery. As a result  BNE enables an
ensemble to ﬂexibly quantify aleatoric uncertainty in the data  and account for both the parametric
and the structural uncertainties.
We build the full BNE model by starting from the classic ensemble model. Denoting F∗(y|x) the CDF
of data-generating distribution for an continuous outcome. Given an observation pair {x y} ∈ Rp ×R
where y ∼ F∗(y|x) and a set of base model predictors { fk}K
k=1  a classic ensemble model assumes the
form

Y =

K

∑

k=1

fk(x)ωk + ε 

(1)

where ω = {ωk}K
k=1 are the ensemble weights assigned to each base model  and ε is a random variable
describing the distribution of the outcome. For simplicity of exposition  in the rest of this section we
assume ω and ε follow independent Gaussian priors  which corresponds to a classic stacking model
assuming a Gaussian outcome [10].

2

In practice  given a set of predictors { fk}K
k=1’s built by domain experts  a practitioner needs to ﬁrst
specify a distribution family for ε (e.g. Gaussian such that ε ∼ N(0 σε ))  then estimate ω and ε using
collected data. During this process  two types of model biases can arise: bias in prediction function
µ = ∑K
k=1 fk(x)ωk caused by the systematic bias shared among all the base predictors fk’s; and bias
in distribution speciﬁcation caused by assuming a distribution family for ε that fails to capture the
stochastic pattern in the data  producing inaccurate estimates of aleatoric uncertainty. BNE mitigates
these two types of biases that exist in (1) using Bayesian nonparametric machinery.

Mitigate prediction bias using residual process δ To mitigate model’s structural bias in pre-
diction  BNE ﬁrst adds to (1) a ﬂexible residual process δ (x)  so the ensemble model becomes a
semiparametric model [11  39]:

Y =

K

∑

k=1

fk(x)ωk + δ (x) + ε.

(2)

In this work  we model δ (x) nonparametrically using a Gaussian process (GP) with zero mean
function 0(x) = 0 and kernel function kδ (x x(cid:48)). The residual process δ (x) adds additional ﬂexibility
of the model’s mean function E(Y|x)  and domain experts can select a ﬂexible kernel for δ to best
approximate the data-generating function of interest (e.g.  a RBF kernel to approximate arbitrary
continuous functions over a compact support [33]). As a result  in densely-sampled regions that are
well captured by the training data  δ (x) will conﬁdently mitigate the prediction bias between the
observation y and the prediction function ∑K
k=1 fk(x)ωk. However  in sparsely-sampled regions  the
posterior mean of δ (x) will be shrunk back towards 0(x) = 0  so as to leave the predictions of the
original ensemble (1) intact (since these expert-built base models presumably have been specially
designed for the problem being considered) and the posterior uncertainty of δ (x) will be larger to
reﬂect the model’s increased structural uncertainty in its prediction function at location x.
We recommend selecting kδ from the shift-invariant kernel family k(x x(cid:48)) = g(x−x(cid:48)). Shift-invariant
kernels are well suited for characterizing a model’s epistemic uncertainty  since the resulting predictive
variances are explicitly characterized by the distance from the training data  which yields predictive
uncertainty that increases as the prediction location of interest is farther away from data [36].
We write the model CDF of (2) as Φε (y|x  µ). In the case ε ∼ N(0 σ 2
with mean µ and variance σ 2
hierarchical Gaussian process with mean function ∑K

ε )  Φε is a Gaussian CDF
ε . Notice that since δ (x) is a Gaussian process  (2) speciﬁes Y as a
k=1 fk(x)ωk and kernel function kδ (x x(cid:48)) + σ 2
ε .
Mitigate distribution bias using calibration function G Although ﬂexible in its mean prediction 
the model in (2) can still be restrictive in its distributional assumptions. That is  at a given location
x ∈ Rp  because the model corresponds to a Gaussian process speciﬁcation for Y   the posterior of
(2) still follows a Gaussian distribution [36]. Consequently  when the data distribution is multi-
modal  non-symmetric  or heavy-tailed  the model in (2) can still fail to capture the underlying
data-generating distribution F∗(y|x)  resulting in systematic discrepancy between Φε (y|x  µ) and
F∗(y|x).
To mitigate this bias in the speciﬁcation of the data distribution  BNE further augments Φε (y|x  µ) by
using a nonparametric function G to "calibrate" the model’s distributional assumption using observed

data z = {y x}  i.e.  BNE models its CDF as F(y|x  µ) = G(cid:2)Φε (y|x  µ)(cid:3). As a result  the full BNE

model’s CDF is a ﬂexible nonparametric function capable of modeling a wide range of complex
distributions. In this work  we model G using a Gaussian process with identity mean function I(x) = x
and kernel function kG  and we impose probit-based likelihood constraints on G so it respects the
mathematical property of a CDF (i.e. monotonic and bounded between [0 1]  see Section B for detail).
As a result  the full BNE model’s CDF follows a constrained Gaussian process (CGP) [29  30  38]:

(cid:16)
Φε (y|x  µ)  kG
(3)
√
3d/l) ∗
where z = {y x}. In this work  we set kG to the Matérn 3
exp(−√
2 Gaussian process corresponds
to the space of Hölder continuous functions that are at least once differentiable  allowing F to ﬂexibly
model the space of (Lipschitz) continuous CDFs F∗(y|x) whose probability density function (PDF)
exist [46]. Consequently  in regions well represented by the training data  the BNE’s model CDF will

3d/l) where d = ||x− x(cid:48)||2. The sample space of a Matérn 3

2 kernel kMatérn 3/2(d) = (1 +

F(y|x  µ) ∼ CGP

(cid:0)z z(cid:48)(cid:1)(cid:17)

 

3

ﬂexibly capture the complex patterns in the data distribution. In regions outside the training data  the
BNE’s model CDF will fall back to Φε (y|x  µ)  not interfering with the generalization behavior of
the original ensemble model. Additionally  the posterior uncertainty in (3) will reﬂect the model’s
additional structural uncertainty with respect to its distribution speciﬁcation.

Figure 2: Illustrative example illustrating impact of G on model’s posterior predictive distribution.
Dashed Line: True Distribution F∗(y|x)  Black Ticks: Observations  Red Shade: predictive density of
∑k fkωk  Grey Shade: predictive density of Φε (y|x  µ) (Gaussian assumption)  Blue Shade: predictive
density of G◦ Φε (y|x  µ) (nonparametric noise correction).
To further illustrate the role G plays in the BNE’s ability to ﬂexibly characterize an outcome distribu-
tion  we consider an illustrative example where we run the BNE model both with and without G to
predict y at a ﬁxed location of x (i.e. estimating the conditional distribution F∗(y|x) at ﬁxed location
of x) where y|x ∼ Gamma(1.5 2) (Figure 2). As shown  the posterior distribution of Φε (y|x  µ) (grey
shade) fails to capture the skewness in the data’s empirical distribution  and consequently yields a
biased maximum a posterior (MAP) estimate due to its restrictive distributional assumptions. On

the other hand  the full BNE model F(y|x  µ) = G(cid:2)Φε (y|x  µ)(cid:3) is able to calibrate its predictive

distribution (blue shade) toward the data distribution using G  and consequently produces improved
characterization of F∗(y|x) and improved MAP estimate.

Model Summary To recap  given a classic ensemble model (1)  BNE nonparametrically augments
the model’s prediction function with a residual process δ   and augments the model’s distribution
function with a calibration function G. Speciﬁcally  for data y|x that is generated from the distribution
F∗(y|x)  the full BNE assumes the following model:

F∗(y|x) = G(cid:2)Φε (y|x  µ)(cid:3)  µ =

K

∑

k=1

fk(x)ωk + δ (x).

(4)

The priors are deﬁned to be

G ∼ CGP(I kG) 

δ ∼ GP(0 kδ )  ω ∼ N(0 σ 2

ωI) 

where kG is the Matérn 3
2 kernel  and kδ is a shift-invariant kernel to be chosen by the domain expert
(we set it to Matérn 3
2 in this work). The zero-mean GP ensures the ensemble bias term δ reverts to
zero out of sample  while the identity-mean GP allows the noise process to be white Gaussian noise ε
out of sample. In other words  this prior structure allows BNE to ﬂexibly capture data distribution
where data exists  and revert to the classic ensemble otherwise.
BNE’s hyper-parameters are the Matérn length-scale parameters lδ and lG  and the prior variances
σω and σε. Consistent with the existing GP approaches  we place the inverse-Gamma priors on the
lδ and lG and the Half Normal priors on σω and σε [43]. Posterior sampling is performed using
Hamiltonian Monte Carlo (HMC) [2]  for which we pre-orthogonalize kernel matrices with respect
to their mean functions to avoid parameter non-identiﬁability [31  37]. The time complexity for
sampling from the BNE posterior is O(N3) due to the need to invert the N × N kernel matrices. For
large datasets  we can consider the parallel MCMC scheme proposed in [26] which partitions the data
into K subsets and estimates the predictive intervals with reduced complexity O(N3/K2). Section C
describes posterior inference in further detail.

3 Characterizing Model Uncertainties with BNE

3.1 Mitigating Model Bias under Uncertainty

In this section we study the contribution of BNE’s model components to an ensemble’s prediction
and predictive uncertainty estimation. For a model with predictive CDF F(y|x)  we notice that

4

is expressed as E(y|x) =(cid:82)

the model’s predictive behavior is completely characterized by F(y|x): a model’s predictive mean
y∈R[I(y > 0)− F(y|x)]dy  and a model’s (1− q)% predictive interval is
expressed as Uq(y|x) = [F−1(1− q
2|x)] [12]. Consequently  BNE improves upon an
ensemble model’s prediction and uncertainty estimation by building a ﬂexible model for F that better
captures the data-generating F∗(y|x).

2|x)  F−1(1 + q

Bias Correction for Prediction and Uncertainty Estimation We can express the predictive mean
of BNE as:

E(y|x ω δ  G) =

K

∑
k=1

fk(x)ωk + δ (x)

+

(cid:124)(cid:123)(cid:122)(cid:125)

due to δ

(cid:90)
(cid:124)

y∈Y

Φ(y|x  µ)− G(cid:2)Φ(y|x  µ)(cid:3)(cid:105)
(cid:104)

(cid:123)(cid:122)

due to G

dy

.

(5)

(cid:125)

See Supplementary E for derivation. As shown  the predictive mean for the full BNE is composed of
three parts: 1) the predictive mean of the original ensemble ∑K
k=1 fk(x)ωk; 2) the term δ representing

BNE’s "direct correction" to the prediction function; and 3) the term(cid:82)(cid:2)Φ(y|x  µ)− G[Φ(y|x  µ)](cid:3)dy

representing BNE’s "indirect correction" to prediction obtained upon the relaxation of the original
Gaussian assumption in model CDF. We denote these two error-correction terms as Dδ (y|x) and
DG(y|x).
To express BNE’s estimated predictive uncertainty  we denote as Φε ω the predictive CDF of the
original ensemble (1) (i.e. with mean ∑k fkωk and variance σ 2
ε ). Then BNE’s predictive interval is:
+ δ (x)  Φ−1
ε ω

Uq(y|x ω δ  G) =

(cid:16)
G−1(1− q
2

Φ−1
ε ω

Comparing (6) to the predictive interval of original ensemble [Φ−1
2 )]  we see
that the locations of the BNE predictive interval endpoints are adjusted by the residual process δ  
while the spread of the predictive interval (i.e. the predictive uncertainty) is calibrated by G.

.

+ δ (x)
ε ω (1 + q

(cid:16)

(cid:17)
q
G−1(1 +
|x)
2
ε ω (1− q
2 ) Φ−1

(cid:17)

|x)

(cid:104)

(cid:105)

(6)

P(cid:0)Dδ

Quantifying Uncertainty in Bias Correction A salient feature of BNE is that it can quantify its
uncertainty in bias correction. This is because the bias correction terms Dδ and DG are random
quantities that have posterior distributions (since they are functions of δ and G). Speciﬁcally  we
can quantify the posterior uncertainty in whether Dδ and DG are different from zero by estimating

(cid:0)y|x(cid:1) > 0(cid:1)  i.e.  the percentiles of 0 in the posterior distribution of Dδ

(cid:0)y|x(cid:1) > 0(cid:1) and P(cid:0)DG

and DG. Values close to 0 or 1 indicate strong evidence that model bias impacts model prediction.
Values close to 0.5 indicate a lack of evidence of this impact  since the posterior distributions of
these error-correction terms are roughly centered around zero. This approach can be generalized to
describe the impact of the distribution biases on other properties of the predictive distribution (e.g.
skewness  multi-modality  etc. see Section E for detail).

3.2 Consistent Estimation of Aleatoric Uncertainty

2|x)  F−1(1 + q

Recall that a model characterize the aleatoric uncertainty in data through its model CDF. As it
is clear from the expression of predictive interval Uq(y|x) = [F−1(1− q
2|x)]  for a
model to reliably estimate its predictive uncertainty  the model CDF F should be estimated to be
consistent with the data-generating CDF F∗(y|x)  such that  for example  the 95% predictive interval
U0.95(y|x) indeed contains the observations y ∼ F∗(y|x) 95% of the time. This consistency property
is known in the probabilistic forecast literature as calibration [19]  and deﬁnes a mathematically
rigorous condition for a model to achieve reliable estimation of its predictive uncertainty. To this end 
using the ﬂexible calibration function G  BNE enables its model CDF to consistently capturing the
data-generating F∗(y|x):
Theorem 1 (Posterior Consistency). Let F = G[Φ] be a realization of the CGP prior deﬁned in
(3). Suppose that the true data-generating CDF F∗(y|x) is contained in the support of F. Given
{yi xi}n
i=1  a random sample from F∗(y|x)  denote the expectation with respect to F∗ as E∗ and
denote the posterior distribution as Πn. There exists a sequence εn → 0 and sufﬁciently large M such
that

(cid:16)||F∗ − F||2 ≥ Mεn

(cid:12)(cid:12)(cid:12){yi xi}n

i=1

(cid:17) → 0.

E∗Πn

5

We defer the full proof to Section D. This result states that  as the sample size grows  the BNE’s
posterior distribution of F concentrates around the true data-generating CDF F∗  therefore consistently
capture the aleatoric uncertainty in the data distribution. By setting kG to the Matérn 3
2 kernel  the
prior support of BNE is large and contains the space of compactly supported  Lipschitz continuous
F∗’s whose PDF exist [5  46]. The convergence speed of the posterior F depends both on the distance
of F∗ relative to the prior distribution  and on how close the smoothness of the Matérn prior matches
the smoothness of F∗ [44  45]. To this end  the BNE improves its speed of convergence by centering
F’s prior mean to Φ(y|x ω) and by estimating the kernel hyperparameter lG adaptively through an
inverse Gamma prior.

3.3 Uncertainty Decomposition

For an ensemble model that is augmented by BNE  the goal of uncertainty decomposition is to
understand how different sources of uncertainty combine to impact the ensemble model’s predictive
distribution  and to distinguish the contribution of each source in driving the overall predictive
uncertainty. As shown in Figure 1  the posterior uncertainty in each of a BNE’s model parameters
{ω δ  G} accounts for an important source of model uncertainty. Consequently  both the aleatoric and
epistemic uncertainties are quantiﬁed by the BNE’s posterior distribution  and can be distinguished
through a careful decomposition of the model posterior.
We ﬁrst show how to separate the aleatoric and epistemic uncertainties in BNE’s posterior predictive
distribution. Consistent with existing approaches  we use entropy to measure the overall uncertainty
y∈Y f (y|θ )∗ log f (y|θ )dy [18  32]. Entropy
measures the average amount of information contained in a distribution  and is reduced to a function
of variance when the distribution is Gaussian. Given a posterior distribution of the model parameters
p(ω δ  G)  we separate the aleatoric and epistemic uncertainties in the ensemble model’s predictive

in a model’s predictive distribution: H (y|x θ ) = −(cid:82)
distribution p(y|x) =(cid:82) f (y|x G δ  ω)d p(ω δ  G) as [15]:
(cid:124)

H (y|x) = I(cid:0)(ω δ  G) y(cid:12)(cid:12)x(cid:1)
(cid:125)

(cid:105)
(cid:104)H (y(cid:12)(cid:12)x G δ  ω)
(cid:125)
(cid:123)(cid:122)

+EG δ  ω

(cid:123)(cid:122)

(cid:124)

(7)

 

epistemic

aleatoric

where the second term measures the model’s aleatoric uncertainty (i.e. which describes the noise
patterns inherence to y) by computing the expected entropy coming from the model distribution
f (y|x G δ  ω) that is averaged over the model’s posterior belief about {G δ  ω}. The ﬁrst term is
the mutual information between p(ω δ  G) and p(y|x)  and measures a model’s overall epistemic
uncertainty (both parametric and structural) encoded in the joint posterior p(ω δ  G) [14  18].
We now show how to separate the overall epistemic uncertainty I ((ω δ  G) y|x) into its parametric
and structural components. This further decomposition is important in understanding how the
ensemble model’s predictive uncertainty changes by accounting for the fact that its prediction and
distribution functions may be misspeciﬁed. Speciﬁcally  recall that an ensemble model’s parametric
uncertainty is the uncertainty about the ensemble weights under the current model speciﬁcation
(i.e. by assuming δ = 0 G = I). Therefore the model’s parametric uncertainty is encoded in the
conditional posterior p(ω|δ = 0 G = I) and can be measured by the conditional mutual information
I (ω y|x δ = 0 G = I). The model’s structural uncertainty contains two components: (1) uncertainty
about the prediction function (accounted by δ ) and (2) uncertainty about the distribution function
(accounted by G). The ﬁrst component describes the model’s additional uncertainty about ω and δ
under current distribution assumption (i.e. by assuming G = I)  which is encoded in the difference
between p(ω δ|G = I) and p(ω|δ = 0 G = I). The second component describes the model’s
additional uncertainty about ω  δ and G by relaxing also the distribution assumption  which is
encoded in the difference between p(ω δ  G) and p(ω δ|G = I). By measuring these additional
uncertainties using differences between mutual information  we decompose the overall epistemic
uncertainty as:

I(cid:0)(ω δ  G) y(cid:12)(cid:12)x(cid:1) = I ((ω δ  G) y|x)− I ((ω δ ) y|x G = I)
(cid:125)

(cid:124)

+

(cid:124)

I ((ω δ ) y|x G = I)− I (ω y|x δ = 0 G = I)

+ I (ω y|x δ = 0 G = I)

.

(cid:125)

(cid:124)

(cid:123)(cid:122)

parametric

(cid:125)

where I (θ  y|θ(cid:48)) =(cid:82) f (θ  y|θ(cid:48))log

f (θ|θ(cid:48)) f (y|θ(cid:48))dθdy denotes the conditional mutual information.
All three uncertainty terms in the above expression are non-negative (see Section F.1). Computing

(cid:123)(cid:122)
(cid:123)(cid:122)

structural G

structural δ

f (θ  y|θ(cid:48))

6

these uncertainty terms is straightforward since under BNE  p(ω|δ = 0 G = I) and p(ω δ|G = I)
both have closed form  which correspond to the posterior of (1) and (2)  respectively. We present an
example of such a decomposition in the air pollution application (Section 5).

4 Experiments
This section reports an in-depth validation of the proposed method on a nonlinear function approxima-
tion task with complex (heterogeneous and heavy-tailed) observation noise. We illustrate the method’s
ability in uncertainty decomposition and bias detection by visualizing the decomposition of model’s
predictive distribution into their aleatoric  parametric  and structural components  and also visualize
the impact of model bias to the model’s output distribution using method described in Section 3.1.
We then interrogate the method’s operating characteristics in prediction (RMSE to true E∗(y|x)) and
uncertainty quantiﬁcation (L1 distance to true F∗(y|x))  and these metrics’ convergence behavior with
respect to the increasing sample sizes. We consider a time series problem with heterosdecastic noise
with varying degree of skewness in P(y|x) and with imbalanced sampling probability in x (see Figure
3). The detailed experiment settings are documented in Supplementary G.

(a)

(d)

(b)

(e)

(c)

(f)

Figure 3: First Column: (a) Uncertainty decomposition in the original ensemble; (d) Posterior
conﬁdence in 3a’s bias in predictive mean due to prediction function misspeciﬁcation. Second
Column: (b) Uncertainty decomposition in the BNE model without G; (e) Posterior conﬁdence
in 3b’s bias in predictive mean and variance due to distribution misspeciﬁcation. Third Column:
(c) Uncertainty decomposition in the full BNE model; (f) Data generation mechanism. Blue Line:
Posterior Mean Prediction. Shaded Region: 90% posterior credible intervals for model’s parametric 
structural and aleatoric uncertainties.

Uncertainty Quantiﬁcation and Decomposition Figure 3 visually illustrates the role each model
component play in BNE’s ability in prediction (predictive mean) and uncertainty quantiﬁcation
(90% predictive intervals)  and furthermore  how the structural uncertainty encoded in δ and G
is used to diagnose the impact of model bias on its predictive distribution. We run the original
Bayesian ensemble (i.e. BNE without δ and G)  the Bayesian Additive Ensemble (BAE) (i.e. BNE
without G)  and the full BNE model on 100 data points (red dots in Figure 3a-3e). As shown  the
original ensemble model (Figure 3a)  restricted by its parametric assumption  produces a predictive
distribution that fail to capture observations even in the training set. The BAE (Figure 3b) improves
the original ensemble by mitigating the systematic bias in prediction  and help the model to better
account for its epistemic uncertainty by increasing the predictive uncertainty at locations where data
is scarse. However  BAE’s aleatoric uncertainty is still biased in that it is roughly constant throughout
the range of x  failing to account for the heterogeneity in observation’s variance  a pattern that is
evident in data’s empirical distribution. Finally  the full BNE model (Figure 3c) ﬂexibly transforms
its predictive distribution to better capture the empirical distribution of the data. As a result  it is able
to properly account for the heterogeneity in the observation noise  and at the same time produced
improved prediction. Figure 3d and 3e quantify the impact of original ensemble’s model bias on
model’s predictive mean and variances (see Section G for further description).

7

1.51.00.50.00.51.01.50.000.250.500.751.00Predictive Mean Bias0.00.10.20.30.40.50.60.70.80.91.0Operating Characteristics We benchmark BNE against its abalated version (BAE) and also classic
and recent nonparametric and ensemble methods: the classic Kernel Conditional Distribution Esti-
mator (CondKDE) that ﬁts the conditional distribution nonparametrically using kernel estimators
with cross-validated bandwidth [28]. The Bayesian Mixture of Experts (BME) combines the predic-
tive distributions adaptively using softmax-transformed Gaussian weights as ∑k πk(x)φ (y| fk σk) [50].
The recent Bayesian Stacking (stack) [51] which uses non-adaptive weights ∑k πkφ (y| fk σk) but
calibrates πk using leave-one-out cross validation  and ﬁnally the Deep Ensemble (DeepEns)  which
ﬁts a mixture of Gaussians parametrized using neural networks [24]. We vary sample size between
E(y|x) =(cid:82) [I(y > 0)− F(y|x)]dy  a model’s improvement in estimating F is reﬂected directly in the
100 and 1000  and repeat the simulation 50 times in each setting. Figure 4 shows the results. We ﬁrst
observe that the patterns of change in RMSE and L1 distance are similar. This is due to the fact that

improvement in RMSE. As shown  the RMSE and L1 distance for both stack and BAE stabilized
at higher values due to their lack of ﬂexibility in capturing the heterogeneity in the data  producing
biased model estimates even in large sample. On the other hand  the mixture-of-Gaussian estimators
(BME and DeepEns) and nonparametric estimators (CondKDE and BNE) continuously improve due
to the ﬂexibility in their distribution assumptions. Comparing between the best performing models
(DeepEns  CondKDE and BNE)  we notice that DeepEns has worse generalization performance in
small samples  likely due to the instability of neural network estimators in the low data regime. The
performance for BNE and CondKDE are comparable in this time series experiment. However we
note that it is usually difﬁcult to generalize kernel density estimators to higher dimensions [41].

(cid:82) |F(y|x)− F∗(y|x)|dy.

Figure 4: Model’s convergence behavior in prediction and uncertainty estimation with respect to
F∗(y|x). Left: RMSE. Right: L1 distance L(F F∗) = ∑x∈X
5 Application: Spatial integration of air pollution models in Massachusetts
In this section  we apply BNE to a real-world air pollution prediction ensemble system in Eastern
Massachusetts consisted of three state-of-the-art PM2.5 exposure models ([23  16  47]). We introduce
the background of air pollution ensemble systems in Section H. Our goals are to understand the
driving factors behind the ensemble system’s uncertainty  and detect the ensemble model’s systematic
bias in predicting annual air pollution concentrations. We implement our ensemble framework on the
base models’ out-of-sample predictions at 43 monitors in Eastern Massachusetts in 2011.
Figure 5 visualizes the BNE’s posterior predictions and uncertainty decomposition across the study
region. Further results are summarized in Section H. As shown  due to the sparsity in monitoring
locations (only 43 in this modeling area)  the model’s overall uncertainty is driven mainly by the
two types of epistemic uncertainties. More speciﬁcally  the model’s parametric uncertainty in 5(c)
highlights spatial regions where the disagreement in base model predictions has substantial inﬂuence
on the overall model uncertainty (e.g.  the regions northwest to the City of Boston)  suggesting further
investigations of the performance of individual model predictions in these regions. Further  BNE’s
posterior estimates in the base models’ systematic bias  i.e. P(Dδ (y|x) > 0)  suggests evidence of
over-estimated PM2.5 concentrations slightly north of Boston by the coast  and also around a monitor
west from Boston  in Worcester  MA (see Supplementary Figure H.3).

6 Discussion and Future Work
We developed a principled Bayesian nonparametric augmentation framework for ensemble learning
to: 1) mitigate model bias in the prediction and distribution function  and 2) account for model

8

(a) Posterior Mean

(b) Overall Uncertainty

(c) Parametric Uncertainty

(d) Structural Uncertainty

Figure 5: Posterior Mean and Uncertainty Decomposition in the BNE model.

uncertainties from different sources (aleatoric  parametric  structural) for a continuous outcome
with complex observational noise. The main features of this method are accurate estimation of the
aleatoric uncertainty  and principled detection and quantiﬁcation of model misspeciﬁcation in terms
of its impact on model prediction. Experiments showed that the method produces well-calibrated
estimation of aleatoric uncertainty and improved prediction under complex observational noise 
and also a complete quantiﬁcation of different sources of epistemic uncertainty. Application to a
real-world air pollution prediction problem shows how this method can help in understanding the
factors driving model uncertainty  and in detecting the systematic errors in the ensemble system.
There are three important future directions for this work. The ﬁrst direction is to adapt the BNE
framework developed here to high dimension scenarios. This can be achieved by choosing kernel
functions for δ and G that are suitable for high-dimensional problems. Example choices include
the additive kernel [17] or (deep) neural network kernel [3  25]. Alternatively  one could also
build variable selection into the model using shrinkage priors such as the Automatic Relevance
Determination (ARD)  spike-and-slab  or Horseshoe [7  49]. The second direction is to develop
inference algorithm for BNE that are scalable to large dataset and at the same time produces rigorous
uncertainty estimates. This is difﬁcult with traditional variational inference algorithms since they
usually does not enjoys a guarantee in fully capturing the posterior distribution. The third direction is
to develop methods to model other important sources of uncertainty (e.g. algorithmic [8  13  21] and
data uncertainty [14  32]) and to quantify their impact on model prediction.
Acknowledgement Authors would like to thank Lorenzo Trippa  Jeff Miller  Boyu Ren at Harvard
Biostatistics  Yoon Kim at Harvard CS and Ge Liu at MIT EECS for the insightful comments and
fruitful discussion. This publication was made possible by USEPA grant RD-83587201. Its contents
are solely the responsibility of the grantee and do not necessarily represent the ofﬁcial views of the
USEPA. Further  USEPA does not endorse the purchase of any commercial products or services
mentioned in the publication. Funding was also provided by NIH grants ES030616 and ES000002.

9

References
[1] D. Amodei  C. Olah  J. Steinhardt  P. Christiano  J. Schulman  and D. Mané. Concrete Problems

in AI Safety. arXiv:1606.06565 [cs]  June 2016. arXiv: 1606.06565.

[2] C. Andrieu and J. Thoms. A tutorial on adaptive MCMC. Statistics and Computing  18(4):343–

373  Dec. 2008.

[3] F. Bach. Breaking the Curse of Dimensionality with Convex Neural Networks. arXiv:1412.8690

[cs  math  stat]  Dec. 2014. arXiv: 1412.8690.

[4] H.-G. Beyer and B. Sendhoff. Robust optimization – A comprehensive survey. Computer

Methods in Applied Mechanics and Engineering  196(33):3190–3218  July 2007.

[5] P. Billingsley. Probability and Measure. Wiley  Hoboken  N.J  anniversary edition edition  Feb.

2012.

[6] C. H. Bishop and K. T. Shanley. Bayesian Model Averaging’s Problematic Treatment of Extreme
Weather and a Paradigm Shift That Fixes It. Monthly Weather Review  136(12):4641–4652  Dec.
2008.

[7] J. F. Bobb  L. Valeri  B. Claus Henn  D. C. Christiani  R. O. Wright  M. Mazumdar  J. J.
Godleski  and B. A. Coull. Bayesian kernel machine regression for estimating the health effects
of multi-pollutant mixtures. Biostatistics (Oxford  England)  16(3):493–508  July 2015.

[8] L. Bottou and O. Bousquet. The Tradeoffs of Large Scale Learning. In J. C. Platt  D. Koller 
Y. Singer  and S. T. Roweis  editors  Advances in Neural Information Processing Systems 20 
pages 161–168. Curran Associates  Inc.  2008.

[9] L. Breiman. Bagging predictors. Machine Learning  24(2):123–140  Aug. 1996.

[10] L. Breiman. Stacked regressions. Machine Learning  24(1):49–64  July 1996.

[11] A. Buja  T. Hastie  and R. Tibshirani. Linear Smoothers and Additive Models. The Annals of

Statistics  17(2):453–510  June 1989.

[12] G. Casella and R. L. Berger. Statistical Inference. Duxbury Press  Australia ; Paciﬁc Grove 

CA  2nd edition edition  June 2001.

[13] Y.-C. Chen. Statistical Inference with Local Optima. arXiv:1807.04431 [math  stat]  July 2018.

arXiv: 1807.04431.

[14] S. Depeweg  J.-M. Hernandez-Lobato  F. Doshi-Velez  and S. Udluft. Decomposition of Uncer-
tainty in Bayesian Deep Learning for Efﬁcient and Risk-sensitive Learning. In International
Conference on Machine Learning  pages 1184–1193  July 2018.

[15] S. Depeweg  J. M. Hernández-Lobato  F. Doshi-Velez  and S. Udluft. Uncertainty Decomposi-
tion in Bayesian Neural Networks with Latent Variables. arXiv:1706.08495 [stat]  June 2017.
arXiv: 1706.08495.

[16] Q. Di  P. Koutrakis  and J. Schwartz. A hybrid prediction model for PM2.5 mass and components
using a chemical transport model and land use regression. Atmospheric Environment  131:390–
399  Apr. 2016.

[17] N. Durrande  D. Ginsbourger  O. Roustant  and L. Carraro. Additive Covariance Kernels for
High-Dimensional Gaussian Process Modeling. arXiv:1111.6233 [stat]  Nov. 2011. arXiv:
1111.6233.

[18] Y. Gal. Uncertainty in Deep Learning. PhD Thesis  University of Cambridge  2016.

[19] T. Gneiting  F. Balabdaoui  and A. E. Raftery. Probabilistic forecasts  calibration and sharpness.
Journal of the Royal Statistical Society: Series B (Statistical Methodology)  69(2):243–268  Apr.
2007.

[20] L. Guiso and G. Parigi.

Investment and Demand Uncertainty. The Quarterly Journal of

Economics  114(1):185–227  1999.

10

[21] S. Gupta  A. Agrawal  K. Gopalakrishnan  and P. Narayanan. Deep Learning with Limited
Numerical Precision. In International Conference on Machine Learning  pages 1737–1746 
June 2015.

[22] A. D. Kiureghian and O. Ditlevsen. Aleatory or epistemic? Does it matter? Structural Safety 

31(2):105–112  Mar. 2009.

[23] I. Kloog  A. A. Chudnovsky  A. C. Just  F. Nordio  P. Koutrakis  B. A. Coull  A. Lyapustin 
Y. Wang  and J. Schwartz. A new hybrid spatio-temporal model for estimating daily multi-year
PM2.5 concentrations across northeastern USA using high resolution aerosol optical depth data.
Atmospheric Environment  95:581–590  Oct. 2014.

[24] B. Lakshminarayanan  A. Pritzel  and C. Blundell. Simple and Scalable Predictive Uncertainty
Estimation using Deep Ensembles. In I. Guyon  U. V. Luxburg  S. Bengio  H. Wallach  R. Fergus 
S. Vishwanathan  and R. Garnett  editors  Advances in Neural Information Processing Systems
30  pages 6402–6413. Curran Associates  Inc.  2017.

[25] K. Lee  H. Lee  K. Lee  and J. Shin. Training Conﬁdence-calibrated Classiﬁers for Detecting

Out-of-Distribution Samples. Nov. 2017.

[26] C. Li  S. Srivastava  and D. B. Dunson. Simple  scalable and accurate posterior interval

estimation. Biometrika  104(3):665–680  Sept. 2017.

[27] M. Li and D. B. Dunson. Comparing and weighting imperfect models using D-probabilities.

Journal of the American Statistical Association  pages 1–33  Apr. 2019.

[28] Q. Li and J. Racine. Cross-validated local linear nonparametric regression. Statistica Sinica 

14(2):485–512  2004.

[29] J. Z. Liu. Gaussian Process Regression and Classiﬁcation under Mathematical Constraints with

Learning Guarantees. arXiv:1904.09632 [cs  math  stat]  Apr. 2019. arXiv: 1904.09632.

[30] M. Lorenzi and M. Filippone. Constraining the Dynamics of Deep Probabilistic Models.

arXiv:1802.05680 [stat]  Feb. 2018. arXiv: 1802.05680.

[31] S. N. MacEachern. Comment on article by Jain and Neal. Bayesian Analysis  2(3):483–494 

Sept. 2007.

[32] A. Malinin and M. Gales.

Predictive Uncertainty Estimation via Prior Networks.

arXiv:1802.10501 [cs  stat]  Feb. 2018. arXiv: 1802.10501.

[33] C. A. Micchelli  Y. Xu  and H. Zhang. Universal Kernels. J. Mach. Learn. Res.  7:2651–2667 

Dec. 2006.

[34] T. F. R. B. of Governors in Washington DC. The Federal Reserve Supervision and Regulation

Letters 11-7: Guidance on Model Risk Management  Apr. 2011.

[35] Y. Qian  C. Jackson  F. Giorgi  B. Booth  Q. Duan  C. Forest  D. Higdon  Z. J. Hou  and
G. Huerta. Uncertainty Quantiﬁcation in Climate Modeling and Projection. Bulletin of the
American Meteorological Society  97(5):821–824  Jan. 2016.

[36] C. E. Rasmussen and C. K. I. Williams. Gaussian Processes for Machine Learning. University

Press Group Limited  Jan. 2006. Google-Books-ID: vWtwQgAACAAJ.

[37] B. J. Reich  J. S. Hodges  and V. Zadnik. Effects of residual smoothing on the posterior of the

ﬁxed effects in disease-mapping models. Biometrics  62(4):1197–1206  Dec. 2006.

[38] J. Riihimäki and A. Vehtari. Gaussian processes with monotonicity information. In Proceedings
of the Thirteenth International Conference on Artiﬁcial Intelligence and Statistics  pages 645–
652  Mar. 2010.

[39] D. Ruppert  M. P. Wand  and R. J. Carroll. Semiparametric Regression. Cambridge University

Press  Cambridge ; New York  1 edition edition  July 2003.

11

[40] R. G. Sargent. Veriﬁcation and validation of simulation models. In Proceedings of the 2010

Winter Simulation Conference  pages 166–183  Dec. 2010.

[41] D. W. Scott. The Curse of Dimensionality and Dimension Reduction. In Multivariate Density

Estimation  pages 217–240. John Wiley & Sons  Ltd  2015.

[42] T. J. Sullivan. Introduction to Uncertainty Quantiﬁcation. Texts in Applied Mathematics.

Springer International Publishing  2015.

[43] S. D. Team. Stan User’s Guide. 2018.

[44] A. van der Vaart and H. van Zanten. Rates of contraction of posterior distributions based on

Gaussian process priors. The Annals of Statistics  36(3):1435–1463  June 2008.

[45] A. W. van der Vaart and J. H. van Zanten. Adaptive Bayesian Estimation Using a Gaussian
Random Field with Inverse Gamma Bandwidth. The Annals of Statistics  37(5B):2655–2675 
2009.

[46] A. W. van der Vaart and J. H. van Zanten. Information rates of nonparametric Gaussian process

methods. Journal of Machine Learning Research  12:2–95–2119  2011.

[47] A. van Donkelaar  R. V. Martin  R. J. D. Spurr  and R. T. Burnett. High-Resolution Satellite-
Derived PM2.5 from Optimal Estimation and Geographically Weighted Regression over North
America. Environmental Science & Technology  49(17):10482–10491  Sept. 2015.

[48] T. Vandal  E. Kodra  J. Dy  S. Ganguly  R. Nemani  and A. R. Ganguly. Quantifying Uncertainty
in Discrete-Continuous and Skewed Data with Bayesian Deep Learning. Proceedings of the
24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining - KDD
’18  pages 2377–2386  2018. arXiv: 1802.04742.

[49] G. Vo and D. Pati. Sparse Additive Gaussian Process with Soft Interactions. Open Journal of

Statistics  07(04):567–588  2017.

[50] S. R. Waterhouse  D. MacKay  and A. J. Robinson. Bayesian Methods for Mixtures of Experts.
In D. S. Touretzky  M. C. Mozer  and M. E. Hasselmo  editors  Advances in Neural Information
Processing Systems 8  pages 351–357. MIT Press  1996.

[51] Y. Yao  A. Vehtari  D. Simpson  and A. Gelman. Using Stacking to Average Bayesian Predictive

Distributions (with Discussion). Bayesian Analysis  13(3):917–1003  Sept. 2018.

12

,Jeremiah Liu
John Paisley
Marianthi-Anna Kioumourtzoglou
Brent Coull