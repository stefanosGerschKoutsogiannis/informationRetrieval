2017,Learning with Feature Evolvable Streams,Learning with streaming data has attracted much attention during the past few years.Though most studies consider data stream with fixed features  in real practice the features may be evolvable. For example  features of data gathered by limited lifespan sensors will change when these sensors are substituted by new ones. In this paper  we propose a novel learning paradigm: Feature Evolvable Streaming Learning where old features would vanish and new features would occur. Rather than relying on only the current features  we attempt to recover the vanished features and exploit it to improve performance. Specifically  we learn two models from the recovered features and the current features  respectively. To benefit from the recovered features  we develop two ensemble methods. In the first method  we combine the predictions from two models and theoretically show that with the assistance of old features  the performance on new features can be improved. In the second approach  we dynamically select the best single prediction and establish a better performance guarantee when the best model switches. Experiments on both synthetic and real data validate the effectiveness of our proposal.,Learning with Feature Evolvable Streams

Bo-Jian Hou Lijun Zhang Zhi-Hua Zhou

National Key Laboratory for Novel Software Technology 

Nanjing University  Nanjing  210023  China

{houbj zhanglj zhouzh}@lamda.nju.edu.cn

Abstract

Learning with streaming data has attracted much attention during the past few years.
Though most studies consider data stream with ﬁxed features  in real practice the
features may be evolvable. For example  features of data gathered by limited-
lifespan sensors will change when these sensors are substituted by new ones. In
this paper  we propose a novel learning paradigm: Feature Evolvable Streaming
Learning where old features would vanish and new features would occur. Rather
than relying on only the current features  we attempt to recover the vanished
features and exploit it to improve performance. Speciﬁcally  we learn two models
from the recovered features and the current features  respectively. To beneﬁt from
the recovered features  we develop two ensemble methods. In the ﬁrst method 
we combine the predictions from two models and theoretically show that with the
assistance of old features  the performance on new features can be improved. In the
second approach  we dynamically select the best single prediction and establish a
better performance guarantee when the best model switches. Experiments on both
synthetic and real data validate the effectiveness of our proposal.

1

Introduction

In many real tasks  data are accumulated over time  and thus  learning with streaming data has attracted
much attention during the past few years. Many effective approaches have been developed  such
as hoeffding tree [7]  Bayes tree [27]  evolving granular neural network (eGNN) [17]  Core Vector
Machine (CVM) [29]  etc. Though these approaches are effective for certain scenarios  they have a
common assumption  i.e.  the data stream comes with a ﬁxed stable feature space. In other words 
the data samples are always described by the same set of features. Unfortunately  this assumption
does not hold in many streaming tasks. For example  for ecosystem protection one can deploy many
sensors in a reserve to collect data  where each sensor corresponds to an attribute/feature. Due to its
limited-lifespan  after some periods many sensors will wear out  whereas some new sensors can be
spread. Thus  features corresponding to the old sensors vanish while features corresponding to the
new sensors appear  and the learning algorithm needs to work well under such evolving environment.
Note that the ability of adapting to environmental change is one of the fundamental requirements for
learnware [37]  where an important aspect is the ability of handling evolvable features.
A straightforward approach is to rely on the new features and learn a new model to use. However 
this solution suffers from some deﬁciencies. First  when new features just emerge  there are few data
samples described by these features  and thus  the training samples might be insufﬁcient to train a
strong model. Second  the old model of vanished features is ignored  which is a big waste of our data
collection effort. To address these limitations  in this paper we propose a novel learning paradigm:
Feature Evolvable Streaming Learning (FESL). We formulate the problem based on a key observation:
in general features do not change in an arbitrary way; instead  there are some overlapping periods in
which both old and new features are available. Back to the ecosystem protection example  since the
lifespan of sensors is known to us  e.g.  how long their battery will run out is a prior knowledge  we

31st Conference on Neural Information Processing Systems (NIPS 2017)  Long Beach  CA  USA.

usually spread a set of new sensors before the old ones wear out. Thus  the data stream arrives in a
way as shown in Figure 1  where in period T1  the original set of features are valid and at the end of
T1  period B1 appears  where the original set of features are still accessible  but some new features
are included; then in T2  the original set of features vanish  only the new features are valid but at the
end of T2  period B2 appears where newer features come. This process will repeat again and again.
Note that the T1 and T2 periods are usually long  whereas the B1 and B2 periods are short because 
as in the ecosystem protection example  the B1 and B2 periods are just used to switch the sensors
and we do not want to waste a lot of lifetime of sensors for such overlapping periods.
In this paper  we propose to solve the FESL
problem by utilizing the overlapping period to
discover the relationship between the old and
new features  and exploiting the old model even
when only the new features are available. Specif-
ically  we try to learn a mapping from new fea-
tures to old features through the samples in the
overlapping period. In this way  we are able to
reconstruct old features from new ones and thus
the old model can still be applied. To beneﬁt
from additional features  we develop two ensem-
ble methods  one is in a combination manner
and the other in a dynamic selection manner. In
the ﬁrst method  we combine the predictions from two models and theoretically show that with the
assistance of old features  the performance on new features can be improved. In the second approach 
we dynamically select the best single prediction and establish a better performance guarantee when
the best model switches at an arbitrary time. Experiments on synthetic and real datasets validate the
effectiveness of our proposal.
The rest of this paper is organized as follows. Section 2 introduces related work. Section 3 presents
the formulation of FESL. Our proposed approaches with corresponding analyses are presented in
section 4. Section 5 reports experimental results. Finally  Section 6 concludes.

Figure 1: Illustration that how data stream comes.

2 Related Work

Data stream mining contains several tasks  including classiﬁcation  clustering  frequency counting 
and time series analysis. Our work is most related to the classiﬁcation task and we can also solve
the regression problem. Existing techniques for data stream classiﬁcation can be divided into two
categories  one only considers a single classiﬁer and the other considers ensemble classiﬁers. For the
former  several methods origin from approaches such as decision tree [7]  Bayesian classiﬁcation [27] 
neural networks [17]  support vector machines [29]  and k-nearest neighbour [1]. For the latter 
various ensemble methods have been proposed including Online Bagging & Boosting [22]  Weighted
Ensemble Classiﬁers [30  20]  Adapted One-vs-All Decision Trees (OVA) [12] and Meta-knowledge
Ensemble [33]. For more details  please refer to [9  10  2  6  21]. These traditional streaming data
algorithms often assume that the data samples are described by the same set of features  while in
many real streaming tasks feature often changes. We want to emphasize that though concept-drift
happens in streaming data where the underlying data distribution changes over time [2  10  4]  the
number of features in concept-drift never changes which is different from our problem. Most studies
correlated to features changing are focusing on feature selection and extraction [26  35] and to the
best of our knowledge  none of them consider the evolving of feature set during the learning process.
Data stream mining is a hot research direction in the area of data mining while online learning [38  14]
is a related topic from the area of machine learning. Yet online learning can also tackle the streaming
data problem since it assumes that the data come in a streaming way. Online learning has been
extensively studied under different settings  such as learning with experts [5] and online convex
optimization [13  28]. There are strong theoretical guarantees for online learning  and it usually uses
regret or the number of mistakes to measure the performance of the learning procedure. However 
most of existing online learning algorithms are limited to the case that the feature set is ﬁxed.
Other related topics involving multiple feature sets include multi-view learning [18  19  32]  transfer
learning [23  24] and incremental attribute learning [11]. Although both our approaches and multi-
view learning exploit the relation between different sets of features  there exists a fundamental

2

Feature EvolutionData StreamingFeature Set𝑆1𝑆2𝑆3…data with feature set𝑆1datawithfeatureset𝑆1and𝑆2datawithfeatureset𝑆2datawithfeatureset𝑆2and𝑆3𝑇2𝑇1𝐵1𝐵2difference: multi-view learning assumes that every sample is described by multiple feature sets
simultaneously  whereas in FESL only few samples in the feature switching period have two sets
of features  and no matter how many periods there are  the switching part involves only two sets of
features. Transfer learning usually assumes that data are in batch mode  few of them consider the
streaming cases where data arrives sequentially and cannot be stored completely. One exception is
online transfer learning [34] in which data from both sets of features arrive sequentially. However 
they assume that all the feature spaces must appear simultaneously during the whole learning process
while such an assumption is not available in FESL. When it comes to incremental attribute learning 
old sets of features do not vanish or do not vanish entirely while in FESL  old ones will vanish
thoroughly when new sets of features come.
The most related work is [15]  which also handles evolving features in streaming data. Different to
our setting where there are overlapping periods  [15] handles situations where there is no overlapping
period but there are overlapping features. Thus  the technical challenges and solutions are different.

3 Preliminaries

We focus on both classiﬁcation and regression
tasks. On each round of the learning process  the
algorithm observes an instance and gives its pre-
diction. After the prediction has been made  the
true label is revealed and the algorithm suffers
a loss which reﬂects the discrepancy between
the prediction and the groundtruth. We deﬁne
“feature space" in our paper by a set of features.
That the feature space changes means both the
underlying distribution of the feature set and the
number of features change. Consider the pro-
cess with three periods where in the ﬁrst period
large amount of data stream come from the old
feature space; then in the second period named
as overlapping period  few of data come from
both the old and the new feature space; soon
afterwards in the third period  data stream only
come from the new feature space. We call this whole process a cycle. As can be seen from Figure 1 
each cycle merely includes two feature spaces. Thus  we only need to focus on one cycle and it is
easy to extend to the case with multiple cycles. Besides  we assume that the old features in one cycle
will vanish simultaneously by considering the example that in ecosystem protection  all the sensors
share the same expected lifespan and thus they will wear out at the same time. We will study the case
where old features do not vanish simultaneously in the future work.
Based on the above discussion  we only consider two feature spaces denoted by S1 and S2  respec-
tively. Suppose that in the overlapping period  there are B rounds of instances both from S1 and S2.
As can be seen from Figure 2  the process can be concluded as follows.
• For t = 1  . . .   T1 − B  in each round  the learner observes a vector xS1
t ∈ Rd1 sampled
from S1 where d1 is the number of features of S1  T1 is the number of total rounds in S1.
• For t = T1 − B + 1  . . .   T1  in each round  the learner observes two vectors xS1
t ∈ Rd1 and
t ∈ Rd2 from S1 and S2  respectively where d2 is the number of features of S2.
xS2
• For t = T1 + 1  . . .   T1 + T2  in each round  the learner observes a vector xS2
t ∈ Rd2
sampled from S2 where T2 is the number of rounds in S2. Note that B is small  so we can
omit the streaming data from S2 on rounds T1 − B + 1  . . .   T1 since they have minor effect
on training the model in S2.

Figure 2: Speciﬁc illustration with one cycle.

We use (cid:107)x(cid:107) to denote the (cid:96)2-norm of a vector x ∈ Rdi  i = 1  2. The inner product is denoted by
(cid:104)· ·(cid:105). Let Ω1 ⊆ Rd1 and Ω2 ⊆ Rd2 be two sets of linear models that we are interested in. We deﬁne
the projection ΠΩi (b) = argmina∈Ωi (cid:107)a − b(cid:107)  i = 1  2. We restrict our prediction function in i-th
feature space and t-th round to be linear which takes the form (cid:104)wi t  xSi
t (cid:105) where wi t ∈ Rdi  i = 1  2.
The loss function (cid:96)(w(cid:62)x  y) is convex in its ﬁrst argument and in implementing algorithms  we use

3

Feature EvolutionData StreamingFeature Space𝑆1Feature Space𝑆2𝐱1𝑆1…𝐱𝑇1−𝐵𝑆1𝐱𝑇1−𝐵+1𝑆1𝐱𝑇1−𝐵+1𝑆2……𝐱𝑇1𝑆1𝐱𝑇1𝑆2𝐱𝑇1+1𝑆2…𝐱𝑇1+𝑇2𝑆2𝑇1𝐵𝑇2Algorithm 1 Initialize
1: Initialize w1 1 ∈ Ω1 randomly  M1 = 0  and M2 = 0;
2: for t = 1  2  . . .   T1 do
3:
4:
5:
6: M∗ = M

t ∈ Rd1 and predict ft = w(cid:62)
1 txS1
Receive xS1
√
Update w1 t using (1) where τt = 1/
t;
if t > T1 − B then M1 = M1 + xS2
t xS2

−1
1 M2.

t

t ∈ R; Receive the target yt ∈ R  and suffer loss (cid:96)(ft  yt);
(cid:62)

(cid:62)

and M2 = M2 + xS2

t xS1

t

;

logistic loss for classiﬁcation task  namely (cid:96)(w(cid:62)x  y) = (1/ ln 2) ln(1 + exp(−y(w(cid:62)x))) and square
loss for regression task  namely (cid:96)(w(cid:62)x  y) = (y − w(cid:62)x)2.
The most straightforward or baseline algorithm is to apply online gradient descent [38] on rounds
1  . . .   T1 with streaming data xS1
  and invoke it again on rounds T1 + 1  . . .   T1 + T2 with streaming
t
data xS2
t

. The models are updated according to (1)  where τt is a varied step size:

(cid:16)

(cid:17)

wi t − τt∇(cid:96)(w(cid:62)

i txSi

t   yt)

  i = 1  2.

(1)

wi t+1 = ΠΩi

4 Our Proposed Approach

In this section  we ﬁrst introduce the basic idea of the solution to FESL  then two different kinds of
approaches with the corresponding analyses are proposed.
The major limitation of the baseline algorithm mentioned above is that the model learned on rounds
1  . . .   T1 is ignored on rounds T1 + 1  . . .   T1 + T2. The reason is that from rounds t > T1  we
cannot observe data from feature space S1  and thus the model w1 T1  which operates in S1  cannot
be used directly. To address this challenge  we assume there is a certain relationship ψ : Rd2 → Rd1
between the two feature spaces  and we try to discover it in the overlapping period. There are several
methods to learn a relationship between two sets of features including multivariate regression [16] 
streaming multi-label learning [25]  etc. In our setting  since the overlapping period is very short  it is
unrealistic to learn a complex relationship between the two spaces. Instead  we use a linear mapping
to approximate ψ. Assume the coefﬁcient matrix of the linear mapping is M  then during rounds
T1 − B + 1  . . .   T1  the estimation of M can be based on least squares
t (cid:107)2
2.

(cid:88)T1

(cid:107)xS1

min

M∈Rd2×d1

t=T1−B+1

The optimal solution M∗ to the above problem is given by

(cid:32)

T1(cid:88)

M∗ =

xS2
t xS2

t

t=T1−B+1

(cid:62)(cid:33)−1(cid:32)

t − M(cid:62)xS2
T1(cid:88)

t=T1−B+1

(cid:62)(cid:33)

.

xS2
t xS1

t

t ∈ Rd2 from S2  we can recover an instance in S1 by
Then if we only observe an instance xS2
ψ(xS2) ∈ Rd1  to which w1 T1 can be applied. Based on this idea  we will make two changes to the
baseline algorithm:

• During rounds T1−B +1  . . .   T1  we will learn a relationship ψ from (xS1

T1−B+1  xS2
• From rounds t > T1  we will keep on updating w1 t using the recovered data ψ(xS2

. . .   (xS1
T1

  xS2
T1

).

predict the target by utilizing the predictions of w1 t and w2 t.

T1−B+1) 

t ) and

1 t(ψ(xS2

In round t > T1  the learner can calculate two base predictions based on models w1 t and w2 t:
f1 t = w(cid:62)
. By utilizing the two base predictions in each round  we
propose two methods  both of which are able to follow the better base prediction empirically and
theoretically. The process to obtain the relationship mapping ψ and w1 T1 during rounds 1  . . .   T1
are concluded in Algorithm 1.

t )) and f2 t = w(cid:62)

2 txS2

t

4

Algorithm 2 FESL-c(ombination)
1: Initialize ψ and w1 T1 during 1  . . .   T1 using Algorithm 1;
2: α1 T1 = α2 T1 = 1
2 ;
3: Initialize w2 T1+1 randomly and w1 T1+1 by w1 T1;
4: for t = T1 + 1  T1 + 2  . . .   T1 + T2 do
5:
6:
7:
8:

Predict(cid:98)pt ∈ R using (2)  then receive the target yt ∈ R  and suffer loss (cid:96)((cid:98)pt  yt);
Update weights using (3) where η =(cid:112)8(ln 2)/T2;

√
Update w1 t and w2 t using (4) and (1) respectively where τt = 1/

t ∈ RS2 and predict f1 t = w(cid:62)

t )) and f2 t = w(cid:62)

Receive xS2

1 t(ψ(xS2

t − T1;

2 txS2

;

t

4.1 Weighted Combination

We ﬁrst propose an ensemble method by combining predictions with weights based on exponential of
the cumulative loss [5]. The prediction at time t is the weighted average of all the base predictions:

(cid:98)pt = α1 tf1 t + α2 tf2 t

(2)

where αi t is the weight of the i-th base prediction. With the previous loss of each base model  we
can update the weights of the two base models as follows:
αi te−η(cid:96)(fi t yt)
j=1 αj te−η(cid:96)(fj t yt)

(cid:80)2

  i = 1  2 

αi t+1 =

(3)

where η is a tuned parameter. The updating rule of the weights shows that if the loss of one of
the models on previous round is large  then its weight will decrease in an exponential rate in next
round  which is reasonable and can derive a good theoretical result shown in Theorem 1. Algorithm 2
summarizes our ﬁrst approach for FESL named as FESL-c(ombination). We ﬁrst learn a model w1 T1
using online gradient descent on rounds 1  . . .   T1  during which  we also learn a relationship ψ for
t = T1 − B + 1  . . .   T1. For t = T1 + 1  . . .   T1 + T2  we learn a model w2 t on each round and
keep updating w1 t on the recovered data ψ(xS2

t ) showed in (4) where τt is a varied step size:

w1 t+1 = ΠΩi

w1 t − τt∇(cid:96)(w(cid:62)

1 t(ψ(xS2

t ))  yt)

.

(4)

(cid:16)

(cid:17)

Then we combine the predictions of the two models by weights calculated in (3).

Analysis
In this paragraph  we borrow the regret from online learning to measure the performance
of FESL-c. Speciﬁcally  we give a loss bound as follows which shows that the performance will be
improved with assistance of the old feature space. For the sake of soundness  we put the proof of our
theorems in the supplementary ﬁle. We deﬁne that LS1 and LS2 are two cumulative losses suffered
by base models on rounds T1 + 1  . . .   T1 + T2 

T1+T2(cid:88)

T1+T2(cid:88)

(5)

LS1 =

(cid:96)(f1 t  yt)  LS2 =

(cid:96)(f2 t  yt) 

t=T1+1

t=T1+1

t=T1+1 (cid:96)((cid:98)pt  yt). Then we have:

Theorem 1. Assume that the loss function (cid:96) is convex in its ﬁrst argument and that it takes value
in [0 1]. For all T2 > 1 and for all yt ∈ Y with t = T1 + 1  . . .   T1 + T2  LS12 with parameter

and LS12 is the cumulative loss suffered by our methods: LS12 =(cid:80)T1+T2
ηt =(cid:112)8(ln 2)/T2 satisﬁes
LS12 ≤ min(LS1  LS2 ) +(cid:112)(T2/2) ln 2
is comparable to the minimum of LS1 and LS2. Furthermore  we deﬁne C = (cid:112)(T2/2) ln 2. If

This theorem implies that the cumulative loss LS12 of Algorithm 2 over rounds T1 + 1  . . .   T1 + T2
LS2 − LS1 > C  it is easy to verify that LS12 is smaller than LS2. In summary  on rounds T1 +
1  . . .   T1 + T2  when w1 t is better than w2 t to certain degree  the model with assistance from S1 is
better than that without assistance.

(6)

5

Algorithm 3 FESL-s(election)
1: Initialize ψ and w1 T1 during 1  . . .   T1 using Algorithm 1;
2: α1 T1 = α2 T1 = 1
2 ;
3: Initialize w2 T1+1 randomly and w1 T1+1 by w1 T1;
4: for t = T1 + 1  T1 + 2  . . .   T1 + T2 do
5:
6:
7:
8:

t ∈ RS2 and predict f1 t = w(cid:62)

Receive xS2

Draw a model wi t according to the distribution (7) and predict(cid:98)pt = fi t according to the model;
Receive the target yt ∈ R  and suffer loss (cid:96)((cid:98)pt  yt); Update the weights using (8);

t )) and f2 t = w(cid:62)
2 txS2
√

1 t(ψ(xS2

Update w1 t and w2 t using (4) and (1) respectively  where τt = 1/

t − T1.

;

t

4.2 Dynamic Selection

The combination approach mentioned in the above subsection combines several base models to
improve the overall performance. Generally  combination of several classiﬁers performs better than
selecting only one single classiﬁer [36]. However  it requires that the performance of base models
should not be too bad  for example  in Adaboost the accuracy of the base classiﬁers should be no less
than 0.5 [8]. Nevertheless  in our FESL problem  on rounds T1 + 1  . . .   T1 + T2  w2 t cannot satisfy
the requirement in the beginning due to insufﬁcient training data and w1 t may become worse when
more and more data come causing a cumulation of recovered error. Thus  it may not be appropriate to
combine the two models all the time  whereas dynamically selecting the best single may be a better
choice. Hence we propose a method based on a new strategy  i.e.  dynamic selection  similar to the
Dynamic Classiﬁer Selection [36] which only uses the best single model rather than combining both
of them in each round. Note that  though we only select one of the models  we retain and utilize both
of them to update their weights. So it is still an ensemble method. The basic idea of dynamic selection
is to select the model of larger weight with higher probability. Algorithm 3 summarizes our second
approach for FESL named as FESL-s(election). Speciﬁcally  the steps in Algorithm 3 on rounds
1  . . .   T1 is the same as that in Algorithm 2. For t = T1 + 1  . . .   T1 + T2  we still update weights
of each model. However  when doing prediction  we do not combine all the models’ prediction  we
adopt the result of the “best" model’s according to the distribution of their weights

pi t =

i = 1  2.

(7)

(cid:80)2

αi t−1
j=1 αj t−1

To track the best model  we have a different way of updating weights which is given as follows [5].

vi t = αi t−1e−η(cid:96)(fi t yt)  i = 1  2  αi t = δ

where we deﬁne Wt = v1 t + v2 t  δ = 1/(T2 − 1)  η =(cid:112)8/T2 (2 ln 2 + (T2 − 1)H(1/(T2 − 1)))

and H(x) = −x ln x − (1 − x) ln(1 − x) is the binary entropy function deﬁned for x ∈ (0  1).

+ (1 − δ)vi t  i = 1  2 

Wt
2

(8)

Analysis From rounds t > T1  the ﬁrst model w1 t would become worse due to the cumulative
recovered error while the second model will become better by the large amount of coming data. Since
w1 t is initialized by w1 T 1 which is learnt from the old feature space and w2 t is initialized randomly 
it is reasonable to assume that w1 t is better than w2 t in the beginning  but inferior to w2 t after
sufﬁcient large number of rounds. Let s be the round after which w1 t is worse than w2 t. We deﬁne

Ls =(cid:80)s

t=T1+1 (cid:96)(f1 t  yt) +(cid:80)T2

t=s+1 (cid:96)(f2 t  yt)  we can verify that

min

T1+1≤s≤T1+T2

Ls ≤ min

i=1 2

LSi .

(9)

Then a more ambitious goal is to compare the proposed algorithm against w1 t from rounds T1 + 1
to s  and against the w2 t from rounds s to T1 + T2  which motivates us to study the following
performance measure LS12 − Ls. Because the exact value of s is generally unknown  we need to
bound the worst-case LS12 − minT1+1≤s≤T1+T2 Ls. An upper bound of LS12 is given as follows.
Theorem 2. For all T2 > 1  if the model is run with parameter δ = 1/(T2 − 1) and η =

(cid:112)8/T2 (2 ln 2 + (T2 − 1)H(1/T2 − 1))  then

(cid:115)

(cid:18)

(cid:19)

LS12 ≤

min

T1+1≤s≤T1+T2

Ls +

T2
2

2 ln 2 +

H(δ)

δ

where H(x) = −x ln x − (1 − x) ln(1 − x) is the binary entropy function.

(10)

6

Table 1: Detail description of datasets: let n be the number of examples  and d1 and d2 denote the dimensionality
of the ﬁrst and second feature space  respectively. The ﬁrst 9 datasets in the left column are synthetic datasets 
“r.EN-GR" means the dataset EN-GR comes from Reuter and “RFID" is the real dataset.
n

Dataset

n

d2

d2

Dataset
n
690
Australian
653
Credit-a
1 000
Credit-g
768
Diabetes
940
DNA
1 000
German
3 196
Kr-vs-kp
Splice
3 175
Svmguide3 1 284
RFID
940

d1

d1

d2
29
10
14
5

Dataset
d1
r.EN-FR 18 758 21 531 24 892 r.GR-IT 29 953 34 279 15 505
42
r.EN-GR 18 758 21 531 34 215 r.GR-SP 29 953 34 279 11 547
15
18 758 21 531 15 506 r.IT-EN 24 039 15 506 21 517
r.EN-IT
20
8
r.EN-SP
18 758 21 531 11 547 r.IT-FR
24 039 15 506 24 892
180 125 r.FR-EN 26 648 24 893 21 531 r.IT-GR 24 039 15 506 34 278
59
24 039 15 506 11 547
r.FR-GR 26 648 24 893 34 287 r.IT-SP
26 648 24 893 15 503 r.SP-EN 12 342 11 547 21 530
36
r.FR-IT
r.FR-SP
60
26 648 24 893 11 547 r.SP-FR 12 342 11 547 24 892
r.GR-EN 29 953 34 279 21 531 r.SP-GR 12 342 11 547 34 262
22
78
r.GR-FR 29 953 34 279 24 892 r.SP-IT
12 342 11 547 15 500

41
25
42
15
72

According to Theorem 2 we know that LS12 is comparable to minT1+1≤s≤T1+T2 Ls. Due to (9)  we
can conclude that the upper bound of LS12 in Algorithm 3 is tighter than that of Algorithm 2.

5 Experiments

In this section  we ﬁrst introduce the datasets we use. We want to emphasize that we collected one
real dataset by ourselves since our setting of feature evolving is relatively novel so that the required
datasets are not widely available yet. Then we introduce the compared methods and settings. Finally
experiment results are given.

5.1 Datasets

We conduct our experiments on 30 datasets consisting of 9 synthetic datasets  20 Reuter datasets and
1 real dataset. To generate synthetic data  we randomly choose some datasets from different domains
including economy and biology  etc1 whose scales vary from 690 to 3 196. They only have one
feature space at ﬁrst. We artiﬁcially map the original datasets into another feature space by random
Gaussian matrices  then we have data both from feature space S1 and S2. Since the original data are
in batch mode  we manually make them come sequentially. In this way  synthetic data are completely
generated. We also conduct our experiments on 20 datasets from Reuter [3]. They are multi-view
datasets which have large scale varying from 12 342 to 29 963. Each dataset has two views which
represent two different kinds of languages  respectively. We regard the two views as the two feature
spaces. Now they do have two feature spaces but the original data are in batch mode  so we will
artiﬁcially make them come in streaming way.
We use the RFID technique to collect the real data which contain 450 instances from S1 and S2
respectively. RFID technique is widely used to do moving goods detection [31]. In our case  we want
to utilize the RFID technique to predict the location’s coordinate of the moving goods attached by
RFID tags. Concretely  we arranged several RFID aerials around the indoor area. In each round  each
RFID aerial received the tag signals  then the goods with tag moved  at the same time  we recorded
the goods’ coordinate. Before the aerials expired  we arranged new aerials beside the old ones to
avoid the situation without aerials. So in this overlapping period  we have data from both old and new
feature spaces. After the old aerials expired  we continue to use the new ones to receive signals. Then
we only have data from feature space S2. So the RFID data we collect totally satisfy our assumptions.
The details of all the datasets we use are presented in Table 1.

5.2 Compared Approaches and Settings

We compare our FESL-c and FESL-s with three approaches. One is mentioned in Section 3  where
once the feature space changed  the online gradient descent algorithm will be invoked from scratch 
named as NOGD (Naive Online Gradient Descent). The other two approaches utilize the model
learned from feature space S1 by online gradient descent to do predictions on the recovered data. The

1Datasets can be found in http://archive.ics.uci.edu/ml/.

7

(a) australian

(b) credit-a

(c) credit-g

(d) diabetes

(e) r.EN-SP

(f) r.FR-SP

(g) r.GR-EN

(h) r.IT-FR

(i) RFID

legend

Figure 3: The trend of loss with three baseline methods and the proposed methods on synthetic data. The smaller
the cumulative loss  the better. All the average cumulative loss at any time of our methods is comparable to the
best of baseline methods and 8 of 9 are smaller.

the cumulative loss over 1  . . .   t(cid:48)  namely ¯(cid:96)t(cid:48) = (1/t(cid:48))(cid:80)t(cid:48)

difference between them is that one keeps updating with the recovered data while the other does not.
The one which keeps updating is called Updating Recovered Online Gradient Descent (ROGD-u)
and the other which keeps ﬁxed is called Fixed Recovered Online Gradient Descent (ROGD-f). We
evaluate the empirical performances of the proposed approaches on classiﬁcation and regression tasks
on rounds T1 + 1  . . .   T1 + T2. To verify that our analysis is reasonable  we present the trend of
average cumulative loss. Concretely  at each time t(cid:48)  the loss ¯(cid:96)t(cid:48) of every method is the average of
t=1 (cid:96)t. We also present the classiﬁcation
performance over all instances on rounds T1 + 1  . . .   T1 + T2 on synthetic and Reuter data. The
performances of all approaches are obtained by average results over 10 independent runs on synthetic
data. Due to the large scale of Reuter data  we only conduct 3 independent runs on Reuter data and
report the average results.
The parameters we need to set are the number of instances in overlapping period  i.e.  B  the number
of instances in S1 and S2  i.e.  T1 and T2 and the step size  i.e.  τt where t is time. For all baseline
methods and our methods  the parameters are the same. In our experiments  we set B 5 or 10 for
√
synthetic data  50 for Reuter data and 40 for RFID data. We set almost T1 and T2 to be half of the
t) where c is searched in the range {1  10  50  100  150}.
number of instances  and τt to be 1/(c
The detailed setting of c in τt for each dataset is presented in supplementary ﬁle.

5.3 Results

Here we only present part of the loss trend results  and other results are presented in the supplementary
ﬁle. Figure 3 gives the trend of average cumulative loss. (a-d) are the results on synthetic data  (e-h)
are the results on Reuter data  (i) is the result of the real data. The smaller the average cumulative loss 
the better. From the experimental results  we have the following observations. First  all the curves
with circle marks representing NOGD decrease rapidly which conforms to the fact that NOGD on
rounds T1 + 1  . . .   T1 + T2 becomes better and better with more and more data coming. Besides 
the curves with star marks representing ROGD-u also decline but not very apparent since on rounds
1  . . .   T1  ROGD-u already learned well and tend to converge  so updating with more recovered data
could not bring too much beneﬁts. Moreover  the curves with plus marks representing ROGD-f does
not drop down but even go up instead  which is also reasonable because it is ﬁxed and if there are some
recovering errors  it will perform worse. Lastly  our methods are based on NOGD and ROGD-u  so
their average cumulative losses also decrease. As can be seen from Figure 3  the average cumulative
losses of our methods are comparable to the best of baseline methods on all datasets and are smaller
than them on 8 datasets. And FESL-s exhibits slightly smaller average cumulative loss than FESL-c.
You may notice that NOGD is always worse than ROGD-u on synthetic data and real data while on
Reuter data NOGD becomes better than ROGD-u after a few rounds. This is because on synthetic data
and real data  we do not have enough rounds to let all methods converge while on Reuter data  large
amounts of instances ensure the convergence of every method. So when all the methods converge  we
can see that NOGD is better than other baseline methods since it always receives the real instances
while ROGD-u and ROGD-f receive the recovered instances which may contain recovered error. As
can be seen from (e-h)  in the ﬁrst few rounds  our methods are comparable to ROGD-u. When
NOGD is better than ROGD-u  our methods are comparable to NOGD which shows that our methods

8

70139208277Time0.060.080.100.120.14Loss66131196261326Time0.40.60.81.01.2Loss101201301401Time1234Loss77153229305381Time0.70.80.91.0Loss37675111261501Time0.20.40.60.81.01.2Loss5331065159721292661Time0.20.40.60.81.0Loss600119917982397Time0.20.40.60.81.0Loss481961144119212401Time0.20.40.60.8Loss91181271361Time1.01.52.02.53.0LossTable 2: Accuracy with its variance on synthetic datasets and Reuter datasets. The larger the better. The best
ones among all the methods are bold.
NOGD
.767±.009
.811±.006
.659±.010
.650±.002
.610±.013
.684±.006
.612±.005
.568±.005
.680±.010
.902±.004
.867±.005
.858±.014
.900±.002
.858±.007
.869±.004
.874±.005
.872±.001
.907±.000
.898±.001
.847±.011
.902±.001
.854±.003
.863±.002
.849±.004
.839±.006
.926±.002
.876±.005
.871±.013
.928±.002

Dataset
australian
credit-a
credit-g
diabetes
dna
german
kr-vs-kp
splice
svmguide3
r.EN-FR
r.EN-GR
r.EN-IT
r.EN-SP
r.FR-EN
r.FR-GR
r.FR-IT
r.FR-SP
r.GR-EN
r.GR-FR
r.GR-IT
r.GR-SP
r.IT-EN
r.IT-FR
r.IT-GR
r.IT-SP
r.SP-EN
r.SP-FR
r.SP-GR
r.SP-IT

FESL-s
.849±.009
.831±.009
.733±.006
.652±.009
.692±.021
.703±.004
.630±.016
.612±.022
.778±.010
.902±.005
.870±.003
.863±.013
.899±.002
.858±.007
.868±.003
.873±.005
.871±.002
.906±.000
.898±.000
.851±.017
.902±.001
.854±.003
.862±.003
.846±.004
.839±.006
.924±.001
.878±.012
.873±.013
.927±.002

ROGD-u
.849±.009
.826±.018
.733±.006
.652±.009
.691±.023
.700±.002
.621±.036
.612±.022
.779±.010
.849±.003
.836±.007
.847±.014
.848±.002
.776±.009
.774±.019
.780±.022
.778±.022
.850±.007
.827±.009
.851±.017
.845±.003
.760±.006
.753±.012
.736±.022
.753±.014
.860±.005
.873±.017
.827±.025
.861±.005

ROGD-f
.809±.025
.785±.051
.716±.011
.651±.006
.608±.064
.700±.002
.538±.024
.567±.057
.748±.012
.769±.069
.802±.036
.831±.018
.825±.001
.754±.012
.753±.021
.744±.040
.735±.013
.801±.035
.802±.023
.816±.006
.797±.012
.730±.024
.730±.020
.702±.012
.726±.005
.814±.021
.833±.042
.810±.026
.826±.005

FESL-c
.849±.009
.827±.014
.733±.006
.652±.007
.691±.023
.700±.001
.626±.028
.612±.022
.779±.010
.903±.003
.870±.002
.861±.010
.901±.001
.858±.007
.870±.004
.874±.005
.872±.001
.907±.001
.898±.001
.850±.018
.902±.001
.856±.002
.864±.002
.849±.004
.839±.007
.926±.002
.876±.014
.873±.013
.928±.003

are comparable to the best one all the time. Moreover  FESL-s performs worse than FESL-c in the
beginning while afterwards  it becomes slightly better than FESL-c.
Table 2 shows the accuracy results on synthetic datasets and Reuter datasets. We can see that for
synthetic datasets  FESL-s outperforms other methods on 8 datasets  FESL-c gets the best on 5
datasets and ROGD-u also gets 5. NOGD performs worst since it starts from scratch. ROGD-u is
better than NOGD and ROGD-f because ROGD-u exploits the old better trained model from old
feature space and keep updating with recovered instances. Our two methods are based on NOGD
and ROGD-u. We can see that our methods can follow the best baseline method or even outperform
it. For Reuter datasets  we can see that FESL-c outperforms other methods on 17 datasets  FESL-s
gets the best on 9 datasets and NOGD gets 8 while ROGD-u gets 1. In Reuter datasets  the period
on new feature space is longer than that in synthetic datasets so that NOGD can update itself to a
good model. Whereas ROGD-u updates itself with recovered data  so the model will become worse
when recovered error accumulates. ROGD-f does not update itself  thus it performs worst. Our two
methods can take the advantage of NOGD and ROGD-f and perform better than them.

6 Conclusion

In this paper  we focus on a new setting: feature evolvable streaming learning. Our key observation is
that in learning with streaming data  old features could vanish and new ones could occur. To make
the problem tractable  we assume there is an overlapping period that contains samples from both
feature spaces. Then  we learn a mapping from new features to old features  and in this way both
the new and old models can be used for prediction. In our ﬁrst approach FESL-c  we ensemble two
predictions by learning weights adaptively. Theoretical results show that the assistance of the old
feature space can improve the performance of learning with streaming data. Furthermore  we propose
FESL-s to dynamically select the best model with better performance guarantee.

9

Acknowledgement This research was supported by NSFC (61333014  61603177)  JiangsuSF
(BK20160658)  Huawei Fund (YBN2017030027) and Collaborative Innovation Center of Novel
Software Technology and Industrialization.

References
[1] C. C. Aggarwal  J. Han  J. Wang  and P. S. Yu. A framework for on-demand classiﬁcation of evolving data

streams. IEEE Transactions on Knowledge and Data Engineering  18:577–589  2006.

[2] C. C. Aggarwal. Data streams: An overview and scientiﬁc applications. In Scientiﬁc Data Mining and

Knowledge Discovery - Principles and Foundations  pages 377–397. Springer  2010.

[3] M.-R. Amini  N. Usunier  and C. Goutte. Learning from multiple partially observed views - an application
to multilingual text categorization. In Advances in Neural Information Processing Systems 22  pages 28–36 
2009.

[4] A. Bifet  G. Holmes  R. Kirkby  and B. Pfahringer. MOA: Massive online analysis. Journal of Machine

Learning Research  11:1601–1604  2010.

[5] N. Cesa-Bianchi and G. Lugosi. Prediction  Learning  and Games. Cambridge University Press  2006.

[6] J. de Andrade Silva  E. R. Faria  R. C. Barros  E. R. Hruschka  A. C. P. L. F. de Carvalho  and J. Gama. Data

stream clustering: A survey. ACM Computing Surveys.

[7] P. M. Domingos and G. Hulten. Mining high-speed data streams. In Proceedings of the 6th ACM SIGKDD

International Conference on Knowledge Discovery and Data Mining  pages 71–80  2000.

[8] Y. Freund and R. E. Schapire. A decision-theoretic generalization of on-line learning and an application to

boosting. Journal of Computer and System Sciences  55:119–139  1997.

[9] M. M. Gaber  A. B. Zaslavsky  and S. Krishnaswamy. Mining data streams: A review. SIGMOD Record 

34:18–26  2005.

[10] J. Gama and P. P. Rodrigues. An overview on mining data streams. In Foundations of Computational

Intelligence  pages 29–45. Springer  2009.

[11] S. U. Guan and S. Li. Incremental learning with respect to new incoming input attributes. Neural Processing

Letters  14:241–260  2001.

[12] S. Hashemi  Y. Yang  Z. Mirzamomen  and M. R. Kangavari. Adapted one-versus-all decision trees for

data stream classiﬁcation. IEEE Transactions on Knowledge and Data Engineering  21:624–637  2009.

[13] E. Hazan  A. Agarwal  and S. Kale. Logarithmic regret algorithms for online convex optimization. Maching

Learning  69:169–192  2007.

[14] S. Hoi  J. Wang  and P. Zhao. LIBOL: A library for online learning algorithms. Journal of Machine

Learning Research  15:495–499  2014.

[15] C. Hou and Z.-H. Zhou. One-pass learning with incremental and decremental features. ArXiv e-prints 

arXiv:1605.09082  2016.

[16] B. M. Golam Kibria. Bayesian statistics and marketing. Technometrics  49:230  2007.

[17] D. Leite  P. Costa Jr.  and F. Gomide. Evolving granular classiﬁcation neural networks. In Proceedings of

International Joint Conference on Neural Networks 2009  pages 1736–1743  2009.

[18] S.-Y. Li  Y. Jiang  and Z.-H. Zhou. Partial multi-view clustering.

Conference on Artiﬁcial Intelligence  pages 1968–1974  2014.

In Proceedings of the 28th AAAI

[19] I. Muslea  S. Minton  and C. Knoblock. Active + semi-supervised learning = robust multi-view learning.

In Proceedings of the 19th International Conference on Machine Learning  pages 435–442  2002.

[20] H.-L. Nguyen  Y.-K. Woon  W. K. Ng  and L. Wan. Heterogeneous ensemble for feature drifts in data
streams. In Proceedings of the 16th Paciﬁc-Asia Conference on Knowledge Discovery and Data Mining 
pages 1–12  2012.

[21] H.-L. Nguyen  Y.-K. Woon  and W. K. Ng. A survey on data stream clustering and classiﬁcation. Knowledge

and Information Systems  45:535–569  2015.

10

[22] N. C. Oza. Online bagging and boosting. In Proceedings of the IEEE International Conference on Systems 

Man and Cybernetics 2005  pages 2340–2345  2005.

[23] S. J. Pan and Q. Yang. A survey on transfer learning.

Engineering  22:1345–1359  2010.

IEEE Transactions on Knowledge and Data

[24] R. Raina  A. Battle  H. Lee  B. Packer  and A. Ng. Self-taught learning: Transfer learning from unlabeled

data. In Proceedings of the 24th International Conference on Machine Learning  pages 759–766  2007.

[25] J. Read  A. Bifet  G. Holmes  and B. Pfahringer. Streaming multi-label classiﬁcation. In Proceedings of

the 2nd Workshop on Applications of Pattern Analysis  pages 19–25  2011.

[26] K. Samina  K. Tehmina  and N. Shamila. A survey of feature selection and feature extraction techniques in

machine learning. In Proceedings of Science and Information Conference 2014  pages 372–378  2014.

[27] T. Seidl  I. Assent  P. Kranen  R. Krieger  and J. Herrmann. Indexing density models for incremental
learning and anytime classiﬁcation on data streams. In Proceedings of the 12th International Conference on
Extending Database Technology  pages 311–322  2009.

[28] S. Shalev-Shwartz. Online learning and online convex optimization. Foundations and Trends in Machine

Learning  4:107–194  2012.

[29] I. W. Tsang  A. Kocsor  and J. T. Kwok. Simpler core vector machines with enclosing balls. In Proceedings

of the 24th International Conference on Machine Learning  pages 911–918  2007.

[30] H. Wang  W. Fan  P. S. Yu  and J. Han. Mining concept-drifting data streams using ensemble classiﬁers. In
Proceedings of the 9th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining 
pages 226–235  2003.

[31] C. Wang  L. Xie  W. Wang  T. Xue  and S. Lu. Moving tag detection via physical layer analysis for
large-scale RFID systems. In Proceedings of the 35th Annual IEEE International Conference on Computer
Communications  pages 1–9  2016.

[32] C. Xu  D. Tao  and C. Xu. A survey on multi-view learning. ArXiv e-prints  arXiv:1304.5634  2013.

[33] P. Zhang  J. Li  P. Wang  B. J. Gao  X. Zhu  and L. Guo. Enabling fast prediction for ensemble models on
data streams. In Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery
and Data Mining  pages 177–185  2011.

[34] P. Zhao  S. Hoi  J. Wang  and B. Li. Online transfer learning. Artiﬁcial Intelligence  216:76–102  2014.

[35] G. Zhou  K. Sohn  and H. Lee. Online incremental feature learning with denoising autoencoders. In
Proceedings of the 15th International Conference on Artiﬁcial Intelligence and Statistics  pages 1453–1461 
2012.

[36] Z.-H. Zhou. Ensemble methods: Foundations and algorithms. CRC press  2012.

[37] Z.-H. Zhou. Learnware: On the future of machine learning. Frontiers of Computer Science  10:589–590 

2016.

[38] M. Zinkevich. Online convex programming and generalized inﬁnitesimal gradient ascent. In Proceedings

of the 20th International Conference on Machine Learning  pages 928–936  2003.

11

,Francesco Orabona
Michael Andersen
Ole Winther
Lars Hansen
Corinna Cortes
Giulia DeSalvo
Mehryar Mohri
Bo-Jian Hou
Lijun Zhang
Zhi-Hua Zhou
Horia Mania
Aurelia Guy
Benjamin Recht
Rui Li