2019,The Implicit Metropolis-Hastings Algorithm,Recent works propose using the discriminator of a GAN to filter out unrealistic samples of the generator. We generalize these ideas by introducing the implicit Metropolis-Hastings algorithm. For any implicit probabilistic model and a target distribution represented by a set of samples  implicit Metropolis-Hastings operates by learning a discriminator to estimate the density-ratio and then generating a chain of samples. Since the approximation of density ratio introduces an error on every step of the chain  it is crucial to analyze the stationary distribution of such chain. For that purpose  we present a theoretical result stating that the discriminator loss upper bounds the total variation distance between the target distribution and the stationary distribution. Finally  we validate the proposed algorithm both for independent and Markov proposals on CIFAR-10  CelebA  ImageNet datasets.,The Implicit Metropolis-Hastings Algorithm

Kirill Neklyudov

Samsung-HSE Laboratory
HSE∗  Moscow  Russia

Samsung AI Center Moscow
k.necludov@gmail.com

Evgenii Egorov

Skoltech†  Moscow  Russia
egorov.evgenyy@ya.ru

Abstract

Dmitry Vetrov

Samsung-HSE Laboratory
HSE∗  Moscow  Russia

Samsung AI Center Moscow

vetrovd@yandex.ru

Recent works propose using the discriminator of a GAN to ﬁlter out unrealistic
samples of the generator. We generalize these ideas by introducing the implicit
Metropolis-Hastings algorithm. For any implicit probabilistic model and a target
distribution represented by a set of samples  implicit Metropolis-Hastings operates
by learning a discriminator to estimate the density-ratio and then generating a
chain of samples. Since the approximation of density ratio introduces an error on
every step of the chain  it is crucial to analyze the stationary distribution of such
chain. For that purpose  we present a theoretical result stating that the discriminator
loss upper bounds the total variation distance between the target distribution and
the stationary distribution. Finally  we validate the proposed algorithm both for
independent and Markov proposals on CIFAR-10  CelebA and ImageNet datasets.

1

Introduction

Learning a generative model from an empirical target distribution is one of the key tasks in unsu-
pervised machine learning. Currently  Generative Adversarial Networks (GANs) (Goodfellow et al. 
2014) are among the most successful approaches in building such models. Unlike conventional
sampling techniques  such as Markov Chain Monte-Carlo (MCMC)  they operate by learning the
implicit probabilistic model  which allows for sampling but not for a density evaluation. Due to
the availability of large amounts of empirical data  GANs ﬁnd many applications in computer vi-
sion: image super-resolution (Ledig et al.  2017)  image inpainting (Yu et al.  2018)  and learning
representations (Donahue et al.  2016).
Despite the practical success  GANs remain hard for theoretical analysis and do not provide any
guarantees on the learned model. For now  most of the theoretical results assume optimality of the
learned discriminator (critic) what never holds in practice (Goodfellow et al.  2014; Nowozin et al. 
2016; Arjovsky et al.  2017). Moreover  there is empirical evidence that GANs do not learn to sample
from a target distribution (Arora & Zhang  2017).
Recently  the idea of a GAN postprocessing by ﬁltering the generator was proposed in several
works. Under the assumption that the learned discriminator evaluates the exact density-ratio they
ﬁlter samples from a generator by rejection sampling (Azadi et al.  2018) or by the independent
Metropolis-Hastings algorithm (Neklyudov et al.  2018; Turner et al.  2018). Since the assumption
of the discriminator optimality never holds in practice  we still cannot be sure that the resulting
distribution will be close to the target  we even cannot guarantee that we will improve the output of
the generator.
In this work  we present a theoretical result that justiﬁes the heuristic proposed by Neklyudov
et al. (2018); Turner et al. (2018) and generalize the proposed algorithm to the case of any implicit

∗National Research University Higher School of Economics
†Skolkovo Institute of Science and Technology

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

probabilistic models — both independent and Markov. To do that  we consider some  maybe not
optimal  discriminator in the Metropolis-Hastings test  and approach the problem from the MCMC
perspective. Under reasonable assumptions  we derive an upper bound on the total variation distance
between the target distribution and the stationary distribution of the produced chain  that can be
minimized w.r.t. parameters of the discriminator.
On real-world datasets (CIFAR-10  CelebA  ImageNet)  we validate our approach using different
deep generative models as independent proposals: DCGAN (Radford et al.  2015); Wasserstein GAN
with gradient penalty (Gulrajani et al.  2017); variational auto-encoder (Kingma & Welling  2014);
BigGAN (Brock et al.  2018); MMD-GAN (Li et al.  2017). Every model is learned independently
optimizing its original objective  what allows us to test the algorithm on a wide range of different
proposals. For every proposal  we learn the discriminator from scratch (except BigGAN) and observe
monotonous improvements of metrics throughout the learning. Further  we construct a Markov
proposal by traversing the latent space of WPGAN generator via a Markov chain. Our experiments
demonstrate that this proposal compares favorably against the independent proposal while using the
same generator network.
We consider the provided theoretical analysis and the empirical evaluation as a result that allows to
alleviate or even eliminate the bias of any generative model learned from the empirical distribution.
To be more factual  we summarize our main contributions as follows.

• We propose the implicit Metropolis-Hastings algorithm  that can be seen as an adaptation of
the classical Metropolis-Hastings algorithm to the case of an implicit probabilistic model
and an empirical target distribution (Section 3).

• We justify the algorithm proposed by Neklyudov et al. (2018) and Turner et al. (2018).
In particular  we demonstrate that learning the discriminator via the binary cross-entropy
minimizes an upper bound on the distance between the target distribution and the stationary
distribution of the chain (Section 3.5).

• We empirically validate the obtained theoretical result on real-world datasets (CIFAR-10 
CelebA  ImageNet) (Section 4.1). We also demonstrate empirical gains by applying our
algorithm for Markov proposals (Section 4.2).

2 Background

2.1 The Metropolis-Hastings algorithm

The MH algorithm allows for sampling from an analytic target distribution p(x) by ﬁltering samples
from a proposal distribution q(x| y) that is also given in the analytic form. It operates by sampling a
chain of correlated samples that converge in distribution to the target (see Algorithm 1).

Algorithm 1 The Metropolis-Hastings algorithm
input density of target distribution ˆp(x) ∝ p(x)
input proposal distribution q(x| y)

Algorithm 2 Metropolis-Hastings GAN
input target dataset D
input learned generator q(x)  discriminator d(·)

y ← random init
for i = 0 . . . n do

sample proposal point x ∼ q(x| y)
P = min{1  ˆp(x)q(y | x)
ˆp(y)q(x | y)}
xi =�x  with probability P

y  with probability (1 − P )

y ← xi

end for

y ∼ D initialize from the dataset
for i = 0 . . . n do
sample proposal point x ∼ q(x)
P = min{1  d(x)(1−d(y))
(1−d(x))d(y)}
xi =�x  with probability P

y  with probability (1 − P )

y ← xi

end for

output {x0  . . .   xn}
If we take a proposal distribution that is not conditioned on the previous point  we will obtain the
independent MH algorithm. It operates in the same way  but samples all of the proposal points
independently q(x| y) = q(x).

output {x0  . . .   xn}

2

2.2 Metropolis-Hastings GAN

Recent works (Neklyudov et al.  2018; Turner et al.  2018) propose to treat the generator of a GAN
as an independent proposal distribution q(x) and perform an approximate Metropolis-Hastings test
via the discriminator. Authors motivate this approximation by the fact that the optimal discriminator
evaluates the true density-ratio

d∗(x) =

p(x)

p(x) + q(x)

= arg min

d

� − Ex∼p(x) log d(x) − Ex∼q(x) log(1 − d(x))�.

(1)

Substituting the optimal discriminator in the acceptance test  one can obtain the Metropolis-Hastings
correction of a GAN  that is described in Algorithm 2.
In contrast to the previous works  we take the non-optimality of the discriminator as given and analyze
the stationary distribution of the resulting chain for both independent and Markov proposals. In
Section 3  we formulate the implicit Metropolis-Hastings algorithm and derive an upper bound on the
total variation distance between the target distribution and the stationary distribution of the chain.
Then  in Appendix F  we justify Algorithm 2 by relating the obtained upper bound with the binary
cross-entropy.

3 The Implicit Metropolis-Hastings Algorithm

Algorithm 3
The implicit Metropolis-Hastings algorithm
input target dataset D
input implicit model q(x| y)
input learned discriminator d(· ·)
y ∼ D initialize from the dataset
for i = 0 . . . n do

In this section  we describe the implicit
Metropolis-Hastings algorithm and present a the-
oretical analysis of its stationary distribution.
The Implicit Metropolis-Hastings algorithm is
aimed to sample from an empirical target dis-
tribution p(x)  x ∈ RD  while being able to
sample from an implicit proposal distribution
q(x| y). Given a discriminator d(x  y)  it gen-
erates a chain of samples as described in Algo-
rithm 3.
We build our reasoning by ﬁrst assuming that
the chain is generated using some discriminator
and then successively introducing conditions on
the discriminator and upper bounding the dis-
tance between the chain and the target. Finally 
we come up with an upper bound that can be
minimized w.r.t. parameters of the discriminator.
Here we consider the case of an implicit Markov proposal  but all of the derivations also hold for
independent proposals.
The transition kernel of the implicit Metropolis-Hastings algorithm is

sample proposal point x ∼ q(x| y)
P = min{1  d(x y)
d(y x)}
xi =�x  with probability P

y  with probability (1 − P )

output {x0  . . .   xn}

y ← xi

end for

d(x  y)

t(x| y) = q(x| y) min�1 
Firstly  we require the proposal distribution q(x| y) and the discriminator d(x  y) to be continuous
and positive on RD × RD. In Appendix A  we show that these requirements guarantee the following
properties of the transition kernel t:

d(y  x)� + δ(x − y)� dx�q(x� | y)�1 − min�1 

d(y  x�)��.

d(x�  y)

(2)

• the kernel t deﬁnes a correct conditional distribution;
• the Markov chain deﬁned by t is irreducible;
• the Markov chain deﬁned by t is aperiodic.

To ensure the existence of the unique invariant probabilistic measure of the chain  we should assume
the recurrence of the chain (Theorem 10.0.1  Meyn & Tweedie (2012)). We satisfy the assumption on
the recurrence by introducing the minorization condition in the next subsection (Orey  1971). Then
the aforementioned properties imply the convergence of the Markov chain deﬁned by the transition
kernel t(x| y) to the stationary distribution t∞ (Theorem 4  Roberts et al. (2004)) from any point y.

3

Further  we want the stationary distribution t∞ of our Markov chain to be as close as possible to the
target distribution p. To measure the closeness of distributions  we consider a standard metric for
analysis in MCMC — the total variation distance

�t∞ − p�T V =

1

2� |t∞(x) − p(x)|dx.

(3)

We assume the proposal q(x| y) to be given  but different d(x  y) may lead to different t∞. That is
why we want to derive an upper bound on the distance �t∞ − p�T V and minimize it w.r.t. parameters
of the discriminator d(x  y). We derive this upper bound in three steps in the following subsections.

3.1 Fast convergence
In practice  estimation of the stationary distribution t∞ by running a chain is impossible. Nevertheless 
if we know that the chain converges fast enough  we can upper bound the distance �t∞ − p�T V using
the distance �t1 − p�T V   where t1 is the one-step distribution t1(x) =� t(x| y)t0(y)dy  and t0 is
some initial distribution of the chain.
To guarantee fast convergence of a chain  we propose to use the minorization condition (Roberts
et al.  2004). For a transition kernel t(x| y)  it requires that exists such ε > 0 and a distribution ν that
the following condition is satisﬁed

t(x| y) > εν(x) ∀(x  y) ∈ RD × RD.

(4)

When a transition kernel satisﬁes the minorization condition  the Markov chain converges "fast" to
the stationary distribution. We formalize this statement in the following Proposition.
Proposition 1 Consider a transition kernel t(x| y) that satisﬁes the minorization condition t(x| y) >
εν(x) for some ε > 0  and distribution ν. Then the distance between two consequent steps decreases
as:

�tn+2 − tn+1�T V ≤ (1 − ε)�tn+1 − tn�T V  

where distribution tk+1(x) =� t(x| y)tk(y)dy.
This result could be considered as a corollary of Theorem 8 in Roberts et al. (2004). For consistency 
we provide an independent proof of Proposition 1 in Appendix B.
To guarantee minorization condition of our transition kernel t(x| y)  we require the proposal q(x| y)
to satisfy minorization condition with some constant ε and distribution ν (note that for an independent
proposal  the minorization condition holds automatically with ε = 1). Also  we limit the range of
the discriminator as d(x  y) ∈ [b  1] ∀x  y  where b is some positive constant that can be treated as a
hyperparameter of the algorithm. These requirements imply

(5)

t(x| y) ≥ bq(x| y) > bεν(x).

(6)

Using Proposition 1 and minorization condition (6) for t  we can upper bound the TV-distance
between an initial distribution t0 and the stationary distribution t∞ of implicit Metropolis-Hastings.

�t∞ − t0�T V ≤

∞�i=0

�ti+1 − ti�T V ≤

∞�i=0

(1 − bε)i �t1 − t0�T V =

1
bε �t1 − t0�T V

(7)

Taking the target distribution p(x) as the initial distribution t0(x) of our chain t(x| y)  we reduce
the problem of estimation of the distance �t∞ − p�T V to the problem of estimation of the distance
�t1 − p�T V :

�t∞ − p�T V ≤

1
bε �t1 − p�T V =

1
bε ·

1

2� dx����� t(x| y)p(y)dy − p(x)����.

(8)

However  the estimation of this distance raises two issues. Firstly  we need to get rid of the inner

integral� t(x| y)p(y)dy. Secondly  we need to bypass the evaluation of densities t(x| y) and p(x).

We address these issues in the following subsections.

4

3.2 Dealing with the integral inside of the nonlinearity
For now  assume that we have access to the densities t(x| y) and p(x). However  evaluation of the
density t1(x) is an infeasible problem in most cases. To estimate t1(x)  one would like to resort to
the Monte-Carlo estimation:

t1(x) =� t(x| y)p(y)dy = Ey∼p(y)t(x| y).

(9)

However  straightforward estimation of t1(x) results in a biased estimation of �t1 − p�T V   since the
expectation is inside of a nonlinear function. To overcome this problem  we upper bound this distance
in the following proposition.
Proposition 2 For the kernel t(x| y) of the implicit Metropolis-Hastings algorithm  the distance
between initial distribution p(x) and the distribution t1(x) has the following upper bound

 

(10)

�t1 − p�T V ≤ 2����q(y | x)p(x) − q(x| y)p(y)

d(x  y)

d(y  x)����T V

where the TV-distance on the right side is evaluated in the joint space (x  y) ∈ RD × RD.
For the proof of this proposition  see Appendix C. Note that the obtained upper bound no longer
requires evaluation of an integral inside of a nonlinear function. Moreover  the right side of (10) has
a reasonable motivation since it is an averaged l1 error of the density ratio estimation.

����q(y | x)p(x) − q(x| y)p(y)

d(x  y)

d(y  x)����T V

=

1

2� p(y)q(x| y)����

q(y | x)p(x)
q(x| y)p(y) −

In this formulation  we see that we still could achieve zero value of �t1 − p�T V if we could take such
discriminator that estimates the desired density ratio d(x y)

d(y x) = q(y | x)p(x)
q(x | y)p(y) .

d(x  y)

d(y  x)����dxdy (11)

3.3 Dealing with the evaluation of densities
For an estimation of the right side of (10)  we still need densities p(x) and q(x| y). To overcome this
issue  we propose to upper bound the obtained TV distance via KL-divergence. Then we show that
obtained KL divergence decomposes into two terms: the ﬁrst term requires evaluation of densities
but does not depend on the discriminator d(x  y)  and the second term can be estimated only by
evaluation of d(x  y) on samples from p(x) and q(x| y).
To upper bound the TV-distance �α − β�T V via KL-divergence KL(α�β) one can use well-known
Pinsker’s inequality:
(12)
However  Pinsker’s inequality assumes that both α and β are distributions  while it is not always true
for function q(x| y)p(y) d(x y)
d(y x) in (10). In the following proposition  we extend Pinsker’s inequality
to the case when one of the functions is not normalized.

T V ≤ KL(α�β).

2�α − β�2

Proposition 3 For a distribution α(x) and some positive function f (x) > 0 ∀x the following
inequality holds:

�α − f�2

T V ≤� 2Cf + 1

6

�(�KL(α�f ) + Cf − 1) 

where Cf is the normalization constant of function f: Cf =� f (x)dx  and �KL(α�f ) is the formal

evaluation of the KL divergence

(13)

dx.

(14)

�KL(α�f ) =� α(x) log

α(x)
f (x)

The proof of the proposition is in Appendix D.

5

d(y x) . For the multiplicative term (2C + 1)/6 

d(x  y)

≤� 2C + 1

Now we use this proposition to upper bound the right side of (10):
2

Here C is the normalization constant of q(x| y)p(y) d(x y)
we upper bound C as

d(y  x)����
����q(y | x)p(x) − q(x| y)p(y)
T V ≤
6 ���KL�q(y | x)p(x)����q(x| y)p(y)
d(y  x)� + C − 1�.
d(x  y)
dxdy ≤� q(x| y)p(y)
C =� q(x| y)p(y)
1
b
since we limit the range of the discriminator as d(x  y) ∈ [b  1] ∀x  y.
Summing up the results (8)  (10)  (15)  (16)  we obtain the ﬁnal upper bound as follows.
b2ε2����q(y | x)p(x) − q(x| y)p(y)
d(x  y)�
�

�t∞ − p�2
3ε2b3��E x ∼ p(x)
≤� 4 + 2b

d(y  x)����

T V ≤
d(y  x)
d(x  y)

1
b2ε2 �t1 − p�2

d(x  y)
d(y  x)

T V ≤

dxdy =

d(y  x)

d(x  y)

1
b

 

4

Minimization of the resulting upper bound w.r.t.
following optimization problem:

�

+

loss for the discriminator

y ∼ q(y | x)� log
��
y ∼ q(y | x)� log
d E x ∼ p(x)

min

2

T V ≤

−1 + KL�q(y | x)p(x)����q(x| y)p(y)��

the discriminator d(x  y) is equivalent to the

d(y  x)
d(x  y)

+

d(y  x)

d(x  y)�.

(18)

Thus  we derive the loss function that we can unbiasedly estimate and minimize w.r.t. parameters of
d(x  y). We analyze the optimal solution in the following subsection.

3.4 The optimal discriminator

By taking the derivative of objective (18)  we show (see Appendix E) that the optimal discriminator
d∗ must satisfy

q(y | x)p(x)
q(x| y)p(y)
When the loss function (18) achieves its minimum  it becomes

d∗(x  y)
d∗(y  x)

=

.

q(x| y)p(y)
q(y | x)p(x)

y ∼ q(y | x)� log
E x ∼ p(x)
Substituting this equation into (17)  we achieve �t∞ − p�T V = 0. However  since we limit the
range of the discriminator d(x  y) ∈ [b  1]  the optimal solution could be achieved only when the
density-ratio lies in the following range:

q(y | x)p(x)� = −KL�q(y | x)p(x)����q(x| y)p(y)� + 1 (20)

q(x| y)p(y)

+

(15)

(16)

(17)

(19)

(21)

∀x  y

q(y | x)p(x)
q(x| y)p(y) ∈ [b  b−1].

Therefore  b should be chosen small enough that range [b  b−1] includes all the possible values of
density-ratio. Such b > 0 exists if the support of the target distribution is compact. Indeed  if we have
positive p(x) and q(x| y) on compact support  we can ﬁnd a minimum of the density-ratio and set
b to that minimum. Moreover  taking a positive q(x| y) on a compact support yields minorization
condition for the q(x| y).
If the support of target distribution is not compact  we may resort to the approximation of the target
distribution on some smaller compact support that contains say 99.9% of the whole mass of target
distribution. In practice  many problems of generative modeling are deﬁned on compact support  e.g.
the distribution of images lies in ﬁnite support since we represent an image by pixels values.

6

Table 1: Different losses for a density-ratio estimation.

Proposal

Name

Loss

Upper bound (UB)

Markov

Markov cross-entropy (MCE)

Independent Conventional cross-entropy (CCE)

+

d(y  x)

d(y  x)
d(x  y)

d(x  y)�

� dxdy p(x)q(y | x)� log
� dxdy p(x)q(y | x)[− log d(x  y) − log(1 − d(y  x))]
� dxdy p(x)q(y)[− log d(x)(1 − d(y))]

3.5 Relation to the cross-entropy

It is possible to upper bound the loss (18) by the binary cross-entropy. For a Markov proposal  it is

d(y  x)

d(y  x)
d(x  y)

b�. (22)
y ∼ q(y | x)� log
E x ∼ p(x)
In the case of an independent proposal  we factorize the discriminator as d(x  y) = d(x)(1 − d(y))
and obtain the following inequality (see Appendix F).

y ∼ q(y | x)�−log d(x  y)−log(1−d(y  x))+

d(x  y)� ≤ E x ∼ p(x)

+

1

y ∼ q(y | x)� log
E x ∼ p(x)

d(y  x)
d(x  y)

+

d(y  x)

d(x  y)� ≤ −Ex∼p(x) log d(x) − Ey∼q(y) log(1 − d(y)) +

1
b

(23)

Thus  learning a discriminator via the binary cross-entropy  we also minimize the distance
�t∞ − p�T V . This fact justiﬁes Algorithm 2.
4 Experiments

We present the empirical evaluation of the proposed algorithm and theory for both independent and
Markov proposals. For independent proposals  we validate our theoretical result by demonstrating
monotonous improvements of the sampling procedure throughout the learning of the discriminator.
Further  the implicit MH algorithm with a Markov proposal compares favorably against Algorithm 2
proposed by (Neklyudov et al.  2018; Turner et al.  2018). In both cases  sampling via the implicit MH
algorithm always improves over the straightforward sampling from the proposal. Code reproducing
all experiments is available online3.
To assess our theoretical result in practice  we demonstrate that the minimization of the derived upper
bounds (17)  (22)  (23) results in the minimization of the distance between the target distribution and
the distribution of the chain. Since one can evaluate the total variation distance only when explicit
densities are given  we show its monotonous fall only for synthetic examples (Appendix G). Also  we
provide an analysis of the algorithm with the growth of dimensionality (Appendix G).
For complex empirical distributions  we consider the problem of sampling from the space of images
(CIFAR-10  CelebA  ImageNet datasets) and resort to the conventional metrics for the performance
evaluation: the Inception Score (IS) (Salimans et al.  2016) and Frechet Inception Distance (FID)
(Heusel et al.  2017). Note that these metrics rely heavily on the implementation of Inception network
(Barratt & Sharma  2018); therefore  for all experiments  we use PyTorch version of the Inception V3
network (Paszke et al.  2017).

4.1

Independent proposals

Since we propose to use the implicit MH algorithm for any generative model learned from the
empirical distribution  we consider ﬁve models that are learned with completely different objec-
tives: Deep Convolutional GAN (DCGAN) (Radford et al.  2015)  Variational Auto-Encoder (VAE)
(Kingma & Welling  2014)  Wasserstein GAN with gradient penalty (WPGAN) (Gulrajani et al. 

3https://github.com/necludov/implicit-MH

7

2017)  MMD-GAN (Li et al.  2017)  BigGAN (Brock et al.  2018). We take the generative part
from each already learned model and treat it as an independent proposal distribution in Algorithm
3. For GANs  we take the generator  for VAE  we take the decoder and the prior. Then we learn
the discriminator from scratch for all models (except BigGAN; there we ﬁnetune the head of the
discriminator) and monitor the performance of the Algorithm 3 with iterations.
Our theoretical result says that the total variation distance between the stationary distribution and
the target can be upper bounded by different losses (see Table 1). Note  that we also can learn a
discriminator by UB and MCE for independent proposals; however  in practice  we found that CCE
performs slightly better. In Figure 8  we demonstrate that the minimization of CCE leads to better
IS and FID throughout the learning of a discriminator (see plots for all models in Appendix H).
However  for a ﬁnite empirical distribution  expressive enough discriminator could overﬁt to the target
dataset. In such a case  the implicit MH algorithm would become infeasible since it would accept
only samples that match points of the dataset. This can be averted by monitoring the acceptance rate
and early stopping to prevent overﬁtting.

Figure 1: Monotonous improvements in terms of FID and IS for the learning of discriminator by
CCE. During iterations  we evaluate metrics several times (scatter) and then average them (solid
lines). For a single metric evaluation  we use 10k samples. Higher values of IS and lower values of
FID are better. Performance for the original models corresponds to the 0th iteration on the plots.

4.2 Markov proposals

To simulate Markov proposals we take the same WPGAN as in the independent case and traverse its
latent space by a Markov chain. Taking the latent vector zy for the previous image y  we sample the
next vector zx via HMC and obtain the next image x = g(zx) by the generator g(·)  thus simulating
a Markov proposal q(x| y). Sampling via HMC from the Gaussian is equivalent to the interpolation
between the previous accepted point zy and the random vector v:

zx = cos(t)zy + sin(t)v 

v ∼ N (0  I).

(24)

In our experiments  we take t = π/3. For loss estimation  we condition samples from the proposal on
samples from the dataset x ∼ q(x| y)  y ∼ p(y). However  to sample an image x ∼ q(x| y) we need
to know the latent vector zy for an image y from the dataset. We ﬁnd such vectors by optimization in
the latent space  minimizing the l2 reconstruction error (reconstructions are in Fig. 2).
To ﬁlter a Markov proposal  we need to learn a pairwise discriminator  as suggested in Section 3. For
this purpose  we take the same architecture of the discriminator as in the independent case and put

8

�����������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������thedifferenceofitslogitsnet(·)intothesigmoid.d(x y)=11+exp(net(y)−net(x))(25)ThenwelearnthisdiscriminatorbyminimizationofUBandMCE(seeTable1).InFigure3 wedemonstratethatourMarkovproposalcomparesfavorablynotonlyagainsttheoriginalgeneratorofWPGAN butalsoagainstthechainobtainedbytheindependentsampler(Algorithm2).Toprovidethecomparison weevaluateboththeperformance(IS FID)andcomputationalefforts(rejectionrate) showingthatforthesamerejectionrate ourmethodresultsinbettermetrics.Figure2:SamplesfromCIFAR-10(topline)andtheirreconstructions(bottomline)����������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������Figure3:ComparisonbetweendifferentdiscriminatorsforthesamegeneratorofWPGANintermsofperformance(IS FID)andcomputationalefforts(rejectionrate).HighervaluesofISandlowervaluesofFIDarebetter.Forasinglemetricevaluation weuse10ksamples.Foreverysnapshotofadiscriminator weevaluatemetrics5times(scatter)andthenaveragethem(solidlines).5ConclusionInthispaper weproposetheimplicitMetropolis-Hastingsalgorithmforsamplingfromtheempiricaltargetdistribution assumingthattheproposalonlyabletogeneratesamples(withoutanaccesstothedensity).Inthetheoreticalpartofthepaper weupperboundthedistancebetweenthetargetdistributionandthestationarydistributionofthechain.Thecontributionofthederivedupperboundistwo-fold.Wejustifytheheuristicalgorithmproposedby(Neklyudovetal. 2018;Turneretal. 2018)andderivethelossfunctionsforthecaseofMarkovproposal.Moreover thepost-processingwiththeimplicitMetropolis-Hastingsalgorithmcanbeseenasthetheoreticaljustiﬁcationofanygenerativemodellearnedfromtheempiricaltargetdistribution.Intheexperimentalpartofthepaper weempiricallyvalidatetheproposedalgorithmonthereal-worlddatasets(CIFAR-10 CelebA ImageNet)usingdifferentgenerativemodelsasproposals.Forallmodelsanddatasetsﬁlteringviatheproposedalgorithmalleviatesthegapbetweentargetandproposaldistributions.6AcknowledgementsThisresearchisinpartbasedontheworksupportedbySamsungResearch SamsungElectronics.DmitryVetrovandKirillNeklyudovweresupportedbytheRussianScienceFoundationgrantno.19-71-30020.ReferencesArjovsky M. Chintala S. andBottou L.Wassersteingan.arXivpreprintarXiv:1701.07875 2017.Arora S.andZhang Y.Dogansactuallylearnthedistribution?anempiricalstudy.arXivpreprintarXiv:1706.08224 2017.9Azadi  S.  Olsson  C.  Darrell  T.  Goodfellow  I.  and Odena  A. Discriminator rejection sampling.

arXiv preprint arXiv:1810.06758  2018.

Barratt  S. and Sharma  R. A note on the inception score. arXiv preprint arXiv:1801.01973  2018.

Brock  A.  Donahue  J.  and Simonyan  K. Large scale gan training for high ﬁdelity natural image

synthesis. arXiv preprint arXiv:1809.11096  2018.

Donahue  J.  Krähenbühl  P.  and Darrell  T. Adversarial feature learning.

arXiv:1605.09782  2016.

arXiv preprint

Goodfellow  I.  Pouget-Abadie  J.  Mirza  M.  Xu  B.  Warde-Farley  D.  Ozair  S.  Courville  A.  and
Bengio  Y. Generative adversarial nets. In Advances in neural information processing systems  pp.
2672–2680  2014.

Gulrajani  I.  Ahmed  F.  Arjovsky  M.  Dumoulin  V.  and Courville  A. C. Improved training of
wasserstein gans. In Advances in Neural Information Processing Systems  pp. 5767–5777  2017.

Heusel  M.  Ramsauer  H.  Unterthiner  T.  Nessler  B.  and Hochreiter  S. Gans trained by a two
time-scale update rule converge to a local nash equilibrium. In Advances in Neural Information
Processing Systems  pp. 6626–6637  2017.

Kingma  D. P. and Welling  M. Auto-encoding variational bayes. ICLR  2014.

Ledig  C.  Theis  L.  Huszár  F.  Caballero  J.  Cunningham  A.  Acosta  A.  Aitken  A.  Tejani  A. 
Totz  J.  Wang  Z.  et al. Photo-realistic single image super-resolution using a generative adversarial
network. In Proceedings of the IEEE conference on computer vision and pattern recognition  pp.
4681–4690  2017.

Li  C.-L.  Chang  W.-C.  Cheng  Y.  Yang  Y.  and Póczos  B. Mmd gan: Towards deeper understanding
of moment matching network. In Advances in Neural Information Processing Systems  pp. 2203–
2213  2017.

Meyn  S. P. and Tweedie  R. L. Markov chains and stochastic stability. Springer Science & Business

Media  2012.

Neklyudov  K.  Shvechikov  P.  and Vetrov  D. Metropolis-hastings view on variational inference and

adversarial training. arXiv preprint arXiv:1810.07151  2018.

Nowozin  S.  Cseke  B.  and Tomioka  R. f-gan: Training generative neural samplers using variational
divergence minimization. In Advances in Neural Information Processing Systems  pp. 271–279 
2016.

Orey  S. Lecture notes on limit theorems for markov chain transition probabilities. 1971.

Paszke  A.  Gross  S.  Chintala  S.  Chanan  G.  Yang  E.  DeVito  Z.  Lin  Z.  Desmaison  A.  Antiga 

L.  and Lerer  A. Automatic differentiation in pytorch. 2017.

Pollard  D. Asymptopia. Manuscript  Yale University  Dept. of Statist.  New Haven  Connecticut 

2000.

Radford  A.  Metz  L.  and Chintala  S. Unsupervised representation learning with deep convolutional

generative adversarial networks. arXiv preprint arXiv:1511.06434  2015.

Roberts  G. O.  Rosenthal  J. S.  et al. Optimal scaling for various metropolis-hastings algorithms.

Statistical science  16(4):351–367  2001.

Roberts  G. O.  Rosenthal  J. S.  et al. General state space markov chains and mcmc algorithms.

Probability surveys  1:20–71  2004.

Salimans  T.  Goodfellow  I.  Zaremba  W.  Cheung  V.  Radford  A.  and Chen  X.

Improved
techniques for training gans. In Advances in Neural Information Processing Systems  pp. 2234–
2242  2016.

10

Turner  R.  Hung  J.  Saatci  Y.  and Yosinski  J. Metropolis-hastings generative adversarial networks.

arXiv preprint arXiv:1811.11357  2018.

Yu  J.  Lin  Z.  Yang  J.  Shen  X.  Lu  X.  and Huang  T. S. Generative image inpainting with
contextual attention. In Proceedings of the IEEE Conference on Computer Vision and Pattern
Recognition  pp. 5505–5514  2018.

11

,Kirill Neklyudov
Evgenii Egorov
Dmitry Vetrov