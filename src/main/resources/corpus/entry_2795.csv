2012,Label Ranking with Partial Abstention based on Thresholded Probabilistic Models,Several machine learning methods allow for abstaining from uncertain predictions. While being common for settings like conventional classification  abstention has been studied much less in learning to rank. We address abstention for the label ranking setting  allowing the learner to declare certain pairs of labels as being incomparable and  thus  to predict partial instead of total orders. In our method  such predictions are produced via thresholding the probabilities of pairwise preferences between labels  as induced by a predicted probability distribution on the set of all rankings. We formally analyze this approach for the Mallows and the Plackett-Luce model  showing that it produces proper partial orders as predictions and characterizing the expressiveness of the induced class of partial orders. These theoretical results are complemented by experiments demonstrating the practical usefulness of the approach.,Label Ranking with Partial Abstention based on

Thresholded Probabilistic Models

Weiwei Cheng

Mathematics and Computer Science

Philipps-Universit¨at Marburg

Marburg  Germany

Eyke H¨ullermeier

Mathematics and Computer Science

Philipps-Universit¨at Marburg

Marburg  Germany

cheng@mathematik.uni-marburg.de

eyke@mathematik.uni-marburg.de

Willem Waegeman

Mathematical Modeling  Statistics and

Bioinformatics  Ghent University

Ghent  Belgium

Volkmar Welker

Mathematics and Computer Science

Philipps-Universit¨at Marburg

Marburg  Germany

willem.waegeman@ugent.be

welker@mathematik.uni-marburg.de

Abstract

Several machine learning methods allow for abstaining from uncertain predic-
tions. While being common for settings like conventional classiﬁcation  absten-
tion has been studied much less in learning to rank. We address abstention for the
label ranking setting  allowing the learner to declare certain pairs of labels as being
incomparable and  thus  to predict partial instead of total orders. In our method 
such predictions are produced via thresholding the probabilities of pairwise pref-
erences between labels  as induced by a predicted probability distribution on the
set of all rankings. We formally analyze this approach for the Mallows and the
Plackett-Luce model  showing that it produces proper partial orders as predictions
and characterizing the expressiveness of the induced class of partial orders. These
theoretical results are complemented by experiments demonstrating the practical
usefulness of the approach.

1

Introduction

In machine learning  the notion of “abstention” commonly refers to the possibility of refusing a
prediction in cases of uncertainty. In classiﬁcation with a reject option  for example  a classiﬁer
may abstain from a class prediction if making no decision is considered less harmful than making an
unreliable and hence potentially false decision [7  1]. The same idea could be used in the context of
ranking  too  where a reject option appears to be even more interesting than in classiﬁcation. While
a conventional classiﬁer has only two choices  namely to predict a class or to abstain  a ranker can
abstain to some degree: The order relation predicted can be more or less complete  ranging from a
total order to the empty relation in which all alternatives are declared incomparable.
Our focus is on so-called label ranking problems [16  10]  to be introduced more formally in Sec-
tion 2 below. Label ranking has a strong relationship with the standard setting of multi-class classi-
ﬁcation  but each instance is now associated with a complete ranking of all labels instead of a single
label. Typical examples  which also highlight the need for abstention  include the ranking of can-
didates for a given job and the ranking of products for a given customer. In such applications  it is
desirable to avoid the expression of unreliable or unwarranted preferences. Thus  if a ranker cannot
reliably decide whether a ﬁrst label should precede a second one or the other way around  it should
abstain from this decision and instead declare these alternatives as being incomparable. Abstaining
in a consistent way  the relation thus produced should form a partial order [6].

1

In Section 4  we propose and analyze a new approach for abstention in label ranking that builds
on existing work on partial orders in areas like decision theory  probability theory and discrete
mathematics. We predict partial orders by thresholding parameterized probability distributions on
rankings  using the Plackett-Luce and the Mallows model. Roughly speaking  this approach is able
to avoid certain inconsistencies of a previous approach to label ranking with abstention [6]  to be
discussed in Section 3. By making stronger model assumptions  our approach simpliﬁes the con-
struction of consistent partial order relations. In fact  it obeys a number of appealing theoretical
properties. Apart from assuring proper partial orders as predictions  it allows for an exact character-
ization of the expressivity of a class of thresholded probability distributions in terms of the number
of partial orders that can be produced. The proposal and formal analysis of this approach constitute
our main contributions.
Last but not least  as will be shown in Section 5  the theoretical advantages of our approach in
comparison with [6] are also reﬂected in practical improvements.

2 Label Ranking with Abstention

In the setting of label ranking  each instance x from an instance space X is associated with a total
order of a ﬁxed set of class labels Y = {y1  . . .   yM}  that is  a complete  transitive  and antisym-
metric relation (cid:31) on Y  where yi (cid:31) yj indicates that yi precedes yj in the order. Since a ranking
can be considered as a special type of preference relation  we shall also say that yi (cid:31) yj indicates a
preference for yi over yj (given the instance x).
Formally  a total order (cid:31) can be identiﬁed with a permutation π of the set [M ] = {1  . . .   M}  such
that π(i) is the position of yi in the order. We denote the class of permutations of [M ] (the symmetric
group of order M) by Ω. Moreover  we identify (cid:31) with the mapping (relation) R : Y 2 −→ {0  1}
such that R(i  j) = 1 if yi (cid:31) yj and R(i  j) = 0 otherwise.
The goal in label ranking is to learn a “label ranker” in the form of an X −→ Ω mapping. As training
data  a label ranker uses a set of instances xn (n ∈ [N ])  together with preference information in the
form of pairwise comparisons yi (cid:31) yj of some (but not necessarily all) labels in Y  suggesting that
instance xn prefers label yi to yj.
The prediction accuracy of a label ranker is assessed by comparing the true ranking π with the
prediction ˆπ  using a distance measure D on rankings. Among the most commonly used measures
is the Kendall distance  which is deﬁned by the number of inversions  that is  pairs {i  j} ⊂ [M ]
(cid:80)M
such that sign(π(i) − π(j)) (cid:54)= sign(ˆπ(i) − ˆπ(j)). Besides  the sum of squared rank distances 
i=1(π(i) − ˆπ(i))2  is often used as an alternative distance; it is closely connected to Spearman’s
rank correlation (Spearman’s rho)  which is an afﬁne transformation of this number to the interval
[−1  +1].
Motivated by the idea of a reject option in classiﬁcation  Cheng et al. [6] introduced a variant of
the above setting in which the label ranker is allowed to partially abstain from a prediction. More
speciﬁcally  it is allowed to make predictions in the form of a partial order Q instead of a total order
R: If Q(i  j) = Q(j  i) = 0  the ranker abstains on the label pair (yi  yj) and instead declares these
labels as being incomparable. Abstaining in a consistent way  Q should still be antisymmetric and
transitive  hence a partial order relation. Note that a prediction Q can be associated with a conﬁdence
set  i.e.  a subset of Ω supposed to cover the true ranking π  namely the set of all linear extensions

of this partial order: C(Q) =(cid:8)π ∈ Ω| Q(i  j) = 1 ⇒ (π(i) < π(j)) for all i  j ∈ [M ](cid:9).

3 Previous Work

Despite a considerable amount of work on ranking in general and learning to rank in particular  the
literature on partial rankings is relatively sparse. Worth mentioning is work on a speciﬁc type of
partial orders  namely linear orders of unsorted or tied subsets (partitions  bucket orders) [13  17].
However  apart from the restriction to this type of order relation  the problems addressed in these
works are quite different from our goals. The authors in [17] speciﬁcally address computational
aspects that arise when working with distributions on partially ranked data  while [13] seeks to
discover an underlying bucket order from pairwise precedence information between the items.

2

More concretely  in the context of the label ranking problem  the aforementioned work [6] is the
only one so far that addresses the more general problem of learning to predict partial orders. This
method consists of two main steps and can be considered as a pairwise approach in the sense that 
as a point of departure for a prediction  a valued preference relation P : Y 2 −→ [0  1] is produced 
where P (i  j) is interpreted as a measure of support of the pairwise preference yi (cid:31) yj. Support
is commonly interpreted in terms of probability  hence P is assumed to be reciprocal: P (i  j) =
1 − P (j  i) for all i  j ∈ [M ].
Then  in a second step  a partial order Q is derived from P via thresholding:

(cid:26) 1 

Q(i  j) =(cid:74)P (i  j) > q(cid:75) =

if P (i  j) > q
otherwise

 

0 

(1)
where 1/2 ≤ q < 1 is a threshold. Thus  the idea is to predict only those pairwise preferences that
are sufﬁciently likely  while abstaining on pairs (i  j) for which P (i  j) ≈ 1/2.
The ﬁrst step of deriving the relation P is realized by means of an ensemble learning technique:
Training an ensemble of standard label rankers  each of which provides a prediction in the form of
a total order  P (i  j) is deﬁned by the fraction of ensemble members voting for yi (cid:31) yj. Other
possibilities are of course conceivable  and indeed  the only important point to notice here is that the
preference degrees P (i  j) are essentially independent of each other. Or  stated differently  they do
not guarantee any speciﬁc properties of the relation P except being reciprocal. In particular  P does
not necessarily obey any type of transitivity property.
For the relation Q derived from P via thresholding  this has two important consequences: First  if
the threshold q is not large enough  then Q may have cycles. Thus  not all thresholds in [1/2  1) are
actually feasible. In particular  if q = 1/2 cannot be chosen  this also implies that the method may
not be able to predict a total order as a special case. Second  even if Q does not have cycles  it is not
guaranteed to be transitive.
To overcome these problems  the authors devise an algorithm (of complexity O(|Y|3)) that ﬁnds
to be cycle-free for each threshold q ∈ [qmin  1). Then  since Q may still be non-transitive  it is
“repaired” in a second step by replacing it with its transitive closure [23].

the smallest feasible threshold qmin  namely the threshold that guarantees Q(i  j) =(cid:74)P (i  j) > q(cid:75)

4 Predicting Partial Orders based on Probabilistic Models

In order to tackle the problems of the approach in [6]  our idea is to restrict the relation P in (1) so
as to exclude the possibility of cycles and intransitivity from the very beginning  thereby avoiding
the need for a post-reparation of a prediction. To this end  we take advantage of methods for label
ranking that produce (parameterized) probability distributions over Ω as predictions. Our main the-
oretical result is to show that thresholding pairwise preferences induced by such distributions  apart
from being semantically meaningful due to their clear probabilistic interpretation  yields preference
relations with the desired properties  that is  partial order relations Q.

4.1 Probabilistic Models

Different types of probability models for rank data have been studied in the statistical literature
[11  20]  including the Mallows model and the Plackett-Luce (PL) model as the most popular rep-
resentatives of the class of distance-based and stagewise models  respectively. Both models have
recently attracted attention in machine learning [14  15  22  21  18] and  in particular  have been
used in the context of label ranking.
A label ranking method that produces predictions expressed in terms of the Mallows model is pro-
posed in [5]. The standard Mallows model

P(π | θ  π0) =

exp(−θD(π  π0))

(2)
is determined by two parameters: The ranking π0 ∈ Ω is the location parameter (mode  center
ranking) and θ ≥ 0 is a spread parameter. Moreover  D is a distance measure on rankings  and
φ = φ(θ) is a normalization factor that depends on the spread (but  provided the right-invariance

φ(θ)

3

of D  not on π0). Obviously  the Mallows model assigns the maximum probability to the center
ranking π0. The larger the distance D(π  π0)  the smaller the probability of π becomes. The spread
parameter θ determines how quickly the probability decreases  i.e.  how peaked the distribution is
around π0. For θ = 0  the uniform distribution is obtained  while for θ → ∞  the distribution
converges to the one-point distribution that assigns probability 1 to π0 and 0 to all other rankings.
Alternatively  the Plackett-Luce (PL) model was used in [4]. This model is speciﬁed by a parameter
vector v = (v1  v2  . . .   vM ) ∈ RM
+ :

M(cid:89)

P(π | v) =

vπ−1(i)

vπ−1(i) + vπ−1(i+1) + . . . + vπ−1(M )

i=1

(3)

It is a generalization of the well-known Bradley-Terry model for the pairwise comparison of alter-
natives  which speciﬁes the probability that “a wins against b” in terms of P(a (cid:31) b) = va
.
va+vb
Obviously  the larger va in comparison to vb  the higher the probability that a is chosen. Likewise 
the larger the parameter vi in (3) in comparison to the parameters vj  j (cid:54)= i  the higher the probability
that yi appears on a top rank.

4.2 Thresholded Relations are Partial Orders

Given a probability distribution P on the set of rankings Ω  the probability of a pairwise prefer-
ence yi (cid:31) yj (and hence the corresponding entry in the preference relation P ) is obtained through
marginalization:

P (i  j) = P(yi (cid:31) yj) =

P(π)  

(4)

(cid:88)

π∈E(i j)

where E(i  j) denotes the set of linear extensions of the incomplete ranking yi (cid:31) yj  i.e.  the set
of all rankings π ∈ Ω with π(i) < π(j). We start by stating a necessary and sufﬁcient condition
on P (i  j) for the threshold relation (1) to result in a (strict) partial order  i.e.  an antisymmetric 
irreﬂexive and transitive relation.
Lemma 1. Let P be a reciprocal relation and let Q be given by (1). Then Q deﬁnes a strict
partial order relation for all q ∈ [1/2  1) if and only if P satisﬁes partial stochastic transitivity 
i.e.  P (i  j) > 1/2 and P (j  k) > 1/2 implies P (i  k) ≥ min(P (i  j)  P (j  k)) for each triple
(i  j  k) ∈ [M ]3.

This lemma was ﬁrst proven by Fishburn [12]  together with a number of other characterizations of
subclasses of strict partial orders by means of transitivity properties on P (i  j). For example  replac-
ing partial stochastic transitivity by interval stochastic transitivity (now a condition on quadruples
instead of triplets) leads to a characterization of interval orders  a subclass of strict partial orders; a
partial order Q on [M ]2 is called an interval order if each i ∈ [M ] can be associated with an interval
(li  ui) ⊂ R such that Q(i  j) = 1 ⇔ ui ≤ lj.
Our main theoretical results below state that thresholding (4) yields a strict partial order relation Q 
both for the PL and the Mallows model. Thus  we can guarantee that a strict partial order relation
can be predicted by simple thresholding  and without the need for any further reparation. Moreover 
the whole spectrum of threshold parameters q ∈ [1/2  1) can be used.
Theorem 1. Let P in (4) be the PL model (3). Moreover  let Q be given by the threshold relation
(1). Then Q deﬁnes a strict partial order relation for all q ∈ [1/2  1).
Theorem 2. Let P in (4) be the Mallows model (2)  with a distance D having the so-called trans-
position property. Moreover  let Q be given by the threshold relation (1). Then Q deﬁnes a strict
partial order relation for all q ∈ [1/2  1).

Theorem 1 directly follows from the strong stochastic transitivity of the PL model [19]. The proof
of Theorem 2 is slightly more complicated and given below. Moreover  the result for Mallows is less
general in the sense that D must obey the transposition property. Actually  however  this property is
not very restrictive and indeed satisﬁed by most of the commonly used distance measures  including
the Kendall distance (see  e.g.  [9]). In the following  we always assume that the distance D in the
Mallows model (2) satisﬁes this property.

4

Deﬁnition 1. A distance D on Ω is said to have the transposition property  if the following holds: Let
π and π(cid:48) be rankings and let (i  j) be an inversion (i.e.  i < j and (π(i)− π(j))(π(cid:48)(i)− π(cid:48)(j)) < 0).
Let π(cid:48)(cid:48) ∈ Ω be constructed from π(cid:48) by swapping yi and yj  that is  π(cid:48)(cid:48)(i) = π(cid:48)(j)  π(cid:48)(cid:48)(j) = π(cid:48)(i)
and π(cid:48)(cid:48)(m) = π(cid:48)(m) for all m ∈ [M ] \ {i  j}. Then  D(π  π(cid:48)(cid:48)) ≤ D(π  π(cid:48)).
Lemma 2. If yi precedes yj in the center ranking π0 in (2)  then P(yi (cid:31) yj) ≥ 1/2. Moreover  if
P(yi (cid:31) yj) > q ≥ 1/2  then yi precedes yj in the center ranking π0.
Proof. For every ranking π ∈ Ω  let b(π) = π if yi precedes yj in π; otherwise  b(π) is deﬁned by
swapping yi and yj in π. Obviously  b(·) deﬁnes a bijection between E(i  j) and E(j  i). Moreover 
since D has the transposition property  D(b(π)  π0) ≤ D(π  π0) for all π ∈ Ω. Therefore  according
to the Mallows model  P(b(π)) ≥ P(π)  and hence

(cid:88)

P(π) ≥ (cid:88)

P(yi (cid:31) yj) =

(cid:88)

π∈E(i j)

π∈E(i j)

π∈E(j i)

P(b−1(π)) =

P(π) = P(yj (cid:31) yi)

Since  moreover  P(yi (cid:31) yj) = 1 − P(yj (cid:31) yi)  it follows that P(yi (cid:31) yj) ≥ 1/2. The second
part immediately follows from the ﬁrst one by way of contradiction: If yj would precede yi  then
P(yj (cid:31) yi) ≥ 1/2  and therefore P(yi (cid:31) yj) = 1 − P(yj (cid:31) yi) ≤ 1/2 ≤ q.
Lemma 3. If yi precedes yj and yj precedes yk in the center ranking π0 in (2)  then P(yi (cid:31) yk) ≥
max (P(yi (cid:31) yj)  P(yj (cid:31) yk)).
Proof. We show that P(yi (cid:31) yk) ≥ P(yi (cid:31) yj). The second inequality P(yi (cid:31) yk) ≥ P(yj (cid:31) yk)
is shown analogously. Let E(i  j  k) denote the set of linear extensions of yi (cid:31) yj (cid:31) yk 
i.e.  the set of rankings π ∈ Ω in which yi precedes yj and yj precedes yk. Now  for every
π ∈ E(k  j  i)  deﬁne b(π) by ﬁrst swapping yk and yj and then yk and yi in π. Obviously  b(·)
deﬁnes a bijection between E(k  j  i) and E(j  i  k). Moreover  due to the transposition property 
D(b(π)  π0) ≤ D(π  π0)  and therefore P(b(π)) ≥ P(π) under the Mallows model. Consequently 
since E(i  j) = E(i  j  k) ∪ E(i  k  j) ∪ E(k  i  j) and E(i  k) = E(i  k  j) ∪ E(i  j  k) ∪ E(j  i  k) 
π∈E(j i k) P(π) −

it follows that P(yi (cid:31) yk) − P(yi (cid:31) yj) = (cid:80)
(cid:80)
π∈E(k j i) P(π) =(cid:80)

π∈E(i k)\E(i j) P(π) = (cid:80)

π∈E(k j i) P(b(π)) − P(π) ≥ 0.

Lemmas 2 and 3 immediately imply the following lemma.
Lemma 4. The relation P derived via P (i  j) = P(yi (cid:31) yj) from the Mallows model satisﬁes the
following property (closely related to strong stochastic transitivity): If (P (i  j) > q and P (j  k) > q 
then P (i  k) ≥ max(P (i  j)  P (j  k))  for all q ≥ 1/2 and all i  j  k ∈ [M ].
Proof of Theorem 2. Since P(yi (cid:31) yj) = 1 − P(yj (cid:31) yi)  it obviously follows that Q(yi  yj) = 1
implies Q(yj  yi) = 0. Moreover  Lemma 4 implies that Q is transitive. Consequently  Q deﬁnes a
proper partial order relation.

The above statements guarantee that a strict partial order relation can be predicted by simple thresh-
olding  and without the need for any further reparation. Moreover  the whole spectrum of threshold
parameters q ∈ [1/2  1) can be used. As an aside  we mention that strict partial orders can also be
produced by thresholding other probabilistic preference learning models. All pairwise preference
models based on utility scores satisfy strong stochastic transitivity. This includes traditional sta-
tistical models such as the Thurstone Case 5 model [25] and the Bradley-Terry model [3]  as well
as modern learning models such as [8  2]. These models are usually not applied in label ranking
settings  however.

4.3 Expressivity of the Model Classes

So far  we have shown that predictions produced by thresholding probability distributions on rank-
ings are proper partial orders. Roughly speaking  this is accomplished by restricting P in (1) to
speciﬁc valued preference relations (namely marginals (4) of the Mallows or the PL model)  in con-
trast to the approach of [6]  where P can be any (reciprocal) relation. From a learning point of
view  one may wonder to what extent this restriction limits the expressivity of the underlying model
class. This expressivity is naturally deﬁned in terms of the number of different partial orders (up to

5

isomorphism) that can be represented in the form of a threshold relation (1). Interestingly  we can
show that  in this sense  the approach based on PL is much more expressive than the one based on
the Mallows model.
Theorem 3. Let QM denote the set of different partial orders (up to isomorphism) that can be
represented as a threshold relation Q deﬁned by (1)  where P is derived according to (4) from the
Mallows model (2) with D the Kendall distance. Then |QM| = M.

Proof. By the right invariance of D  different choices of π0 lead to the same set of isomorphism
classes QM . Hence we may assume that π0 is the identity. By Theorem 6.3 in [20] the (M × M )-
matrix with entries P (i  j) is a Toeplitz matrix  i.e.  P (i  j) = P (i + 1  j + 1) for all i  j ∈ [M − 1] 
with entries strictly increasing along rows  i.e.  P (i  j) < P (i  j + 1) for 1 ≤ i < j < M. Thus  by
Theorem 2  thresholding leads to M different partial orders.
More speciﬁcally  the partial orders in QM have a very simple structure that is purely rank-
dependent: The ﬁrst structure is the total order π = π0. The second structure is obtained by
removing all preferences between all direct neighbors  i.e.  labels yi and yj with adjacent ranks
(|π(i) − π(j)| = 1). The third structure is obtained from the second one by removing all prefer-
ences between 2-neighbors  i.e.  labels yi and yj with (|π(i) − π(j)| = 2)  and so forth.
The cardinality of QM increases for distance measures D other than Kendall (like Spearman’s rho
or footrule)  mainly since in general the matrix with entries P (i  j) is no longer Toeplitz. However 
for some measures  including the two just mentioned  the matrix will still be symmetric with respect
to the antidiagonal  i.e.  P (i  j) = P (M + 1 − i  M + 1 − j) for j > i) and have entries increasing
along rows. While the exact counting of QM appears to be very difﬁcult in such cases  an argument
similar to the one used in the proof of the next result shows that |QM| is bounded by the number of

(cid:1) (see Ch. 7 [24]). It is a simple consequence of

symmetric Dyck paths and hence |QM| ≤ (cid:0) M(cid:98) M

Theorem 4 below  showing that exponentially more orders can be produced based on the PL model.
Lemma 5. For ﬁxed q ∈ (1/2  1) and a set A of subsets of [M ]  the following are equivalent:

2 (cid:99)

(i) The set A is the set of maximal antichains of a partial order induced by (4) on [M ] for some

v1 > ··· > vM > 0.

(ii) The set A is a set of mutually incomparable intervals that cover [M ].

Proof. The fact that (i) implies (ii) is a simple calculation. Now assume (ii). For any interval
{a  a + 1  . . .   b} ∈ A we must have
≤ q for any c  d ∈ {a  a + 1  . . .   b} for which c < d.
From va ≥ vc > vd ≥ vb it follows that
=

≥ 1

vc+vd

va

vc

=

vc

1

.

va + vb

1 + vb
va

1 + vd
vc

vc + vd

vc

va

vc+vd

va+vb

≤ q for any
> q for any c < d which are not contained in an antichain from

Thus  it sufﬁces to show that there are real numbers v1 > ··· > vn > 0 such that
{a  a + 1  . . .   b} ∈ A and
A. We proceed by induction on M.
The induction base M = 1 is trivial. Assume M ≥ 2. Since all elements of A are intervals and
any two intervals are mutually incomparable  it follows that M is contained in exactly one set from
A—possibly the singleton {M}. Let A(cid:48) be the set A without the unique interval {a  a + 1  . . .   M}
containing M. Then A(cid:48) is a set of intervals that cover a proper subset [M(cid:48)] of [M ] and fulﬁll the
assumptions of (ii) for [M(cid:48)]. Hence by induction there is a choice of real numbers v1 > ··· >
vM(cid:48) > 0 such that the set of maximal antichains of the order on [M(cid:48)] induced by (4) is exactly A(cid:48).
We consider two cases: (i) a = M(cid:48) + 1. Then  by the considerations above  we need to choose
numbers vM(cid:48) > va > va+1 > ··· > vM > 0 such that
> q. The
> q for d ≤ M(cid:48) > a = M(cid:48) + 1 ≥ d ≥ M. But
latter implies
those are easily checked to exist. (ii) a ≤ M(cid:48). Since M(cid:48) is contained in at least one set from A(cid:48)
and since this set is not contained in {a  a + 1  . . .   M}  it follows that q ≥ va−1
va+vM(cid:48) .
In particular (1 − q)va < qvM(cid:48). Now choose vM(cid:48)+1 > vM(cid:48)+2 > ··· > vM > 0 such that
qvM(cid:48) > qvM(cid:48)+1 > qvM > va(1 − q). Note that here q > 1/2 is essential. Then one checks that all
desired inequalities are fulﬁlled.

va−1+vM(cid:48) > va

≥ vM(cid:48)
vM(cid:48) +va

≤ q and

= 1

vM(cid:48) +va

1+ vc
vd

va+vM

vd+vc

vM(cid:48)

va

d

6

Theorem 4. Let QP L denote the set of different partial orders (up to isomorphism) that can be
represented as a threshold relation Q deﬁned by (1)  where P is derived according to (4) from the
PL model (3). For any given threshold q ∈ [1/2  1)  the cardinality of this set is given by the M th
Catalan number:

|QP L| =

1

(cid:18)2M

(cid:19)

M + 1

M

v1 > ··· > vM > 0 .

Sketch of Proof. Without loss of generality  we can assume the parameters of the PL model to satisfy
(5)
Consider the (M×M )-matrix with entries P (i  j). By (5)  the main diagonal of this matrix is strictly
increasing along rows and columns. From the set {(i  j) | 0 ≤ i ≤ M + 1  0 ≤ i− 1 ≤ j ≤ M}  we
remove those (i  j)  1 ≤ i < j ≤ M  for which P (i  j) is above the given threshold. As a picture
in the plane  this yields a shape whose upper right boundary can be identiﬁed with a Dyck path—a
path on integer points consisting of 2M moves (1  0)  (0  1) from position (1  0) to (M + 1  M ) and
staying weakly above the (i + 1  i)-diagonal. It is immediate that each path uniquely determines
its partial order. Moreover  it is well-known that these Dyck paths are counted by the M th Catalan
number.
In order to verify that any Dyck path is induced by a suitable choice of parameters  one establishes a
bijection between Dyck paths from (1  0) to (M +1  M ) and maximal sets of mutually incomparable
intervals (in the natural order) in [M ]. To this end  consider for a Dyck path a peak at position (i  j) 
i.e.  a point on the path where a (1  0) move is followed by a (0  1) move. Then we must have j ≥ i 
and we identify this peak with the interval {i  i + 1  . . .   j}. It is a simple yet tedious task to check
that assigning to a Dyck path the set of intervals associated to its peaks is indeed a bijection to the
set of maximal sets of mutually incomparable intervals in [M ]. Again  it is easy to verify that the set
of intervals associated to a Dyck path is the set of maximal antichains of the partial order determined
by the Dyck path. Now  the assertion follows from Lemma 5.
Again  using Lemma 5  one checks that (5) implies that partial orders induced by (4) in the PL
model have a unique labeling up to poset automorphism. Hence our count is a count of isomorphism
classes.
We note that  from the above proof  it follows that the partial orders in QP L are the so called
semiorders. We refer the reader to Ch. 8 §2 [26] for more details. Indeed  the ﬁrst part of the proof
of Theorem 4 resembles the proof of Ch. 8 (2.11) [26]. Moreover  we remark that QM is not only
smaller in size than QP L  but the former is indeed strictly included in the latter: QM ⊂ QP L. This
can easily be seen by deﬁning the weights vi of the PL model as vi = 2M−i (i ∈ [M ])  in which
case the matrix with entries P (i  j) = 2j−i
Finally  given that we have been able to derive explicit (combinatorial) expressions for |QM| and
|QP L|  it might be interesting to note that  somewhat surprisingly at ﬁrst sight  no such expression
exists for the total number of partial orders on M elements.

1+2j−i is Toeplitz.

5 Experiments

We complement our theoretical results by an empirical study  in which we compare the different
approaches on the SUSHI data set 1 a standard benchmark for preference learning. Based on a
food-chain survey  this data set contains complete rankings of 10 types of sushi provided by 5000
customers  where each customer is characterized by 11 numeric features.
Our evaluation is done by measuring the tradeoff between correctness and completeness achieved
by varying the threshold q in (1). More concretely  we use the measures that were proposed in [6]:
correctness is measured by the gamma rank correlation between the true ranking and the predicted
partial order (with values in [−1  +1])  and completeness is deﬁned by one minus the fraction of
pairwise comparisons on which the model abstains. Obviously  the two criteria are conﬂicting:
increasing completeness typically comes along with reducing correctness and vice versa  at least if
the learner is effective in the sense of abstaining from those decisions that are indeed most uncertain.

1Available online at http://www.kamishima.net/sushi

7

Figure 1: Tradeoff between completeness and correctness for the SUSHI label ranking data set:
Existing pairwise method (direct) versus the probabilistic approach based on the PL model and
Mallows model with Spearman’s rho (MS) and Kendall (MK) as distance measure. The ﬁgure on
the right corresponds to the original data set with rankings of size 10  while and the ﬁgure on the left
shows results for rankings of size 6.

We compare the original method of [6] with our new proposal  calling the former direct  because
the pairwise preference degrees on which we threshold are estimated directly  and the latter derived 
because these degrees are derived from probability distributions on Ω. As a label ranker  we used
the instance-based approach of [5] with a neighborhood size of 50. We conducted a 10-fold cross
validation and averaged the completeness/correctness curves over all test instances. Due to compu-
tational reasons  we restricted the experiments with the Mallows model to a reduced data set with
only six labels  namely the ﬁrst six of the ten sushis. (The aforementioned label ranker is based
on an instance-wise maximum likelihood estimation of the probability distribution P on Ω; in the
case of the Mallows model  this involves the estimation of the center ranking π0  which is done by
searching the discrete space Ω  that is  a space of size |M !|.)
The experimental results are summarized in Figure 1. The main conclusion that can be drawn from
these results is that  as expected  our probabilistic approach does indeed achieve a better tradeoff
between completeness and correctness than the original one  especially in the sense that it spans
a wider range of values for the former. Indeed  with the direct approach  it is not possible to go
beyond a completeness of around 0.4  whereas our probabilistic methods always allow for predicting
complete rankings (i.e.  to achieve a completeness of 1). Besides  we observe that the tradeoff curves
of our new methods are even lifted toward a higher level of correctness. Among the probabilistic
models  the PL model performs particularly well  although the differences are rather small.
Similar results are obtained on a number of other benchmark data sets for label ranking. These
results can be found in the supplementary material.

6 Summary and Conclusions

The idea of producing predictions in the form of a partial order by thresholding a (valued) pairwise
preference relation is meaningful in the sense that a learner abstains on the most unreliable com-
parisons. While this idea has ﬁrst been realized in [6] in an ad-hoc manner  we put it on a ﬁrm
mathematical grounding that guarantees consistency and  via variation of the threshold  allows for
exploiting the whole spectrum between a complete ranking and an empty relation.
Both variants of our probabilistic approach  the one based on the Mallows and the other one based
the PL model  are theoretically sound  semantically meaningful  and show strong performance in
ﬁrst experimental studies. The PL model may appear especially appealing due to its expressivity 
and is also advantageous from a computational perspective.
An interesting question to be addressed in future work concerns the possibility of improving this
model further  namely by increasing its expressivity while still assuring consistency. In fact  the
transitivity properties guaranteed by PL seem to be stronger than what is necessarily needed. In this
regard  we plan to study models based on the notion of Luce-decomposability [20]  which include
PL as a special case.

8

00 10 20 30 40 500 20 40 60 81correctnesscompletenessderived-MSderived-MKderived-PLdirect00 20 40 60 8100 20 40 60 81correctnesscompletenessderived-PLdirectReferences
[1] P.L. Bartlett and M.H. Wegkamp. Classiﬁcation with a reject option using a hinge loss. Journal

of Machine Learning Research  9:1823–1840  2008.

[2] E.V. Bonilla  S. Guo  and S. Sanner. Gaussian process preference elicitation. In Proc. NIPS–

2010  pages 262–270  Vancouver  Canada  2010. MIT Press.

[3] R. Bradley and M. Terry. Rank analysis of incomplete block designs. I: The method of paired

comparisons. Biometrika  39:324–345  1952.

[4] W. Cheng  K. Dembczy´nski  and E. H¨ullermeier. Label ranking based on the Plackett-Luce

model. In Proc. ICML–2010  pages 215–222  Haifa  Israel  2010. Omnipress.

[5] W. Cheng  J. H¨uhn  and E. H¨ullermeier. Decision tree and instance-based learning for label

ranking. In Proc. ICML–2009  pages 161–168  Montreal  Canada  2009. Omnipress.

[6] W. Cheng  M. Rademaker  B. De Baets  and E. H¨ullermeier. Predicting partial orders: Rank-
ing with abstention. In Proc. ECML/PKDD–2010  pages 215–230  Barcelona  Spain  2010.
Springer.

[7] C. Chow. On optimum recognition error and reject tradeoff. IEEE Transactions on Information

Theory  16(1):41–46  1970.

[8] W. Chu and Z. Ghahramani. Preference learning with Gaussian processes. In Proc. ICML–

2005  pages 137–144  Bonn  Germany  2005. ACM.

[9] D. Critchlow  M. Fligner  and J. Verducci. Probability models on rankings. Journal of Mathe-

matical Psychology  35:294–318  1991.

[10] O. Dekel  CD. Manning  and Y. Singer. Log-linear models for label ranking. In Proc. NIPS–

2003  Vancouver  Canada  2003. MIT Press.

[11] P. Diaconis. Group representations in probability and statistics  volume 11 of Lecture Notes–

Monograph Series. Institute of Mathematical Statistics  Hayward  CA  1988.

[12] P.C. Fishburn. Binary choice probabilities: on the varieties of stochastic transitivity. Journal

of Mathematical Psychology  10:321–352  1973.

[13] A. Gionis  H. Mannila  K. Puolam¨aki  and A. Ukkonen. Algorithms for discovering bucket

orders from data. In Proc. KDD–2006  pages 561–566  Philadelphia  US  2006. ACM.

[14] I.C. Gormley and T.B. Murphy. A latent space model for rank data. In Proc. ICML–06  pages

90–102  Pittsburgh  USA  2006. Springer.

[15] J. Guiver and E. Snelson. Bayesian inference for Plackett-Luce ranking models.

ICML–2009  pages 377–384  Montreal  Canada  2009. Omnipress.

In Proc.

[16] S. Har-Peled  D. Roth  and D. Zimak. Constraint classiﬁcation: a new approach to multiclass

classiﬁcation. In Proc. ALT–2002  pages 365–379  L¨ubeck  Germany  2002. Springer.

[17] G. Lebanon and Y. Mao. Nonparametric modeling of partially ranked data. Journal of Machine

Learning Research  9:2401–2429  2008.

[18] T. Lu and C. Boutilier. Learning Mallows models with pairwise preferences. In Proc. ICML–

2011  pages 145–152  Bellevue  USA  2011. Omnipress.

[19] R. Luce and P. Suppes. Handbook of Mathematical Psychology  chapter Preference  Utility

and Subjective Probability  pages 249–410. Wiley  1965.

[20] J. Marden. Analyzing and Modeling Rank Data. Chapman and Hall  1995.
[21] M. Meila and H. Chen. Dirichlet process mixtures of generalized mallows models. In Proc.

UAI–2010  pages 358–367  Catalina Island  USA  2010. AUAI Press.

[22] T. Qin  X. Geng  and T.Y. Liu. A new probabilistic model for rank aggregation.

NIPS–2010  pages 1948–1956  Vancouver  Canada  2010. Curran Associates.

In Proc.

[23] M. Rademaker and B. De Baets. A threshold for majority in the context of aggregating partial

order relations. In Proc. WCCI–2010  pages 1–4  Barcelona  Spain  2010. IEEE.

[24] R.P. Stanley. Enumerative Combinatorics  Vol. 2. Cambridge University Press  1999.
[25] L. Thurstone. A law of comparative judgment. Psychological Review  79:281–299  1927.
[26] W.T. Trotter. Combinatorics and partially ordered sets: dimension theory. The Johns Hopkins

University Press  1992.

9

,Jamie Hayes
George Danezis