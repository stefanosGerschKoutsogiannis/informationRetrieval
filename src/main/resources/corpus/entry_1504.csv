2018,Dimensionality Reduction for Stationary Time Series via Stochastic Nonconvex Optimization,Stochastic optimization naturally arises in machine learning. Efficient algorithms with provable guarantees  however  are still largely missing  when the objective function is nonconvex and the data points are dependent. This paper studies this fundamental challenge through a streaming PCA problem for stationary time series data. Specifically  our goal is to estimate the principle component of time series data with respect to the covariance matrix of the stationary distribution. Computationally  we propose a variant of Oja's algorithm combined with downsampling to control the bias of the stochastic gradient caused by the data dependency. Theoretically  we quantify the uncertainty of our proposed stochastic algorithm based on diffusion approximations. This allows us to prove the asymptotic rate of convergence and further implies near optimal asymptotic sample complexity. Numerical experiments are provided to support our analysis.,Dimensionality Reduction for Stationary Time Series

via Stochastic Nonconvex Optimization

Minshuo Chen1 Lin F. Yang2 Mengdi Wang2 Tuo Zhao1

1Georgia Institute of Technology

2Princeton University

1{mchen393  tourzhao}@gatech.edu

2{lin.yang  mengdiw}@princeton.edu

Abstract

Stochastic optimization naturally arises in machine learning. Efﬁcient algorithms
with provable guarantees  however  are still largely missing  when the objective
function is nonconvex and the data points are dependent. This paper studies this
fundamental challenge through a streaming PCA problem for stationary time series
data. Speciﬁcally  our goal is to estimate the principle component of time series data
with respect to the covariance matrix of the stationary distribution. Computationally 
we propose a variant of Oja’s algorithm combined with downsampling to control
the bias of the stochastic gradient caused by the data dependency. Theoretically  we
quantify the uncertainty of our proposed stochastic algorithm based on diffusion
approximations. This allows us to prove the asymptotic rate of convergence and
further implies near optimal asymptotic sample complexity. Numerical experiments
are provided to support our analysis.

1

Introduction

Many machine learning problems can be formulated as a stochastic optimization problem in the
following form 

subject to u 2U  

u EZ⇠D[f (u  Z)]
min

(1.1)
where f is a possibly nonconvex loss function  Z denotes the random sample generated from some
underlying distribution D (also known as statistical model)  u is the parameter of our interest  and
U is a possibly nonconvex feasible set for imposing modeling constraints on u. For ﬁnite sample
settings  we usually consider n (possibly dependent) realizations of Z denoted by {z1  ...  zn}  and
the loss function in (1.1) is further reduced to an additive form  E[f (u  z)] = 1
i=1 f (u  zi). For
continuously differentiable f  Robbins and Monro (1951) propose a simple iterative stochastic search
algorithm for solving (1.1). Speciﬁcally  at the k-th iteration  we obtain zk sampled from D and take
(1.2)
where ⌘ is the step-size parameter (also known as the learning rate in machine learning literature) 
ruf (uk  zk) is an unbiased stochastic gradient for approximating ruEZ⇠Df (uk  Z)  i.e. 

uk+1 =⇧ U [uk  ⌘ruf (uk  zk)] 

nPn

Ezkruf (uk  zk) = ruEZ⇠Df (uk  Z) 

and ⇧U is a projection operator onto the feasible set U. This seminal work is the foundation of the
research on stochastic optimization  and has a tremendous impact on the machine learning community.
The theoretical properties of such a stochastic gradient descent (SGD) algorithm have been well
studied for decades  when both f and U are convex. For example  Sacks (1958); Bottou (1998);
Chung (2004); Shalev-Shwartz et al. (2011) show that under various regularity conditions  SGD
converges to a global optimum as k ! 1 at different rates. Such a line of research for convex and
smooth objective function f is fruitful and has been generalized to nonsmooth optimization (Duchi
et al.  2012b; Shamir and Zhang  2013; Dang and Lan  2015; Reddi et al.  2016).

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

When f is nonconvex  which appears more often in machine learning problems  however  the
theoretical studies on SGD are very limited. The main reason behind is that the optimization landscape
of nonconvex problems can be much more complicated than those of convex ones. Thus  conventional
optimization research usually focuses on proving that SGD converges to ﬁrst order optimal stationary
solutions (Nemirovski et al.  2009). More recently  some results in machine learning literature show
that SGD actually converges to second order optimal stationary solutions  when the nonconvex
optimization problem satisﬁes the so-called “strict saddle property” (Ge et al.  2015; Lee et al. 
2017). More precisely  when the objective has negative curvatures at all saddle points  SGD can
ﬁnd a way to escape from these saddle points. A number of nonconvex optimization problems in
machine learning and signal processing have been shown to satisfy this property  including principal
component analysis (PCA)  multiview learning  phase retrieval  matrix factorization  matrix sensing 
matrix completion  complete dictionary learning  independent component analysis  and deep linear
neural networks (Srebro and Jaakkola  2004; Sun et al.  2015; Ge et al.  2015; Sun et al.  2016; Li
et al.  2016; Ge et al.  2016; Chen et al.  2017).
These results further motivate many followup works. For example  Allen-Zhu (2017) improves the

functions  where ✏ is a pre-specifed optimization accuracy; Jain et al. (2016); Allen-Zhu and Li (2016)

iteration complexity of SGD from eO(✏4) in Ge et al. (2015) to eO(✏3.25) for general unconstrained
show that the iteration complexity of SGD for solving the eigenvalue problem is eO(✏1). Despite of

these progresses  we still lack systematic approaches for analyzing the algorithmic behavior of SGD.
Moreover  these results focusing on the convergence properties  however  cannot precisely capture the
uncertainty of SGD algorithms (e.g.  how to escape from saddle points)  which makes the theoretical
analysis less intuitive.
Besides nonconvexity  data dependency is another important challenge arising in stochastic opti-
mization for machine learning  since the samples zk’s are often collected with a temporal pattern.
For many applications (e.g.  time series analysis)  this may involve certain dependency. Taking
generalized vector autoregressive (GVAR) data as an example  our observed zk+1 2 Rm is generated
by zi
k+1 is the i-th component of
zk+1  p(·) denotes the density of the exponential family  and a>i zk is the natural parameter. There is
only limited literature on convex stochastic optimization for dependent data. For example  Duchi
et al. (2012a) investigate convex stochastic optimization algorithms for ergodic underlying data gener-
ating processes; Homem-de Mello (2008) investigates convex stochastic optimization algorithms for
dependent but identically distributed data. For nonconvex optimization problems in machine learning 
however  how to address such dependency is still quite open.
This paper proposes to attack stochastic nonconvex optimization problems for dependent data by
investigating a simple but fundamental problem in machine learning — Streaming PCA for stationary
time series. PCA has been well known as a powerful tool to reduce the dimensionality  and well
applied to data visualization and representation learning. Speciﬁcally  we solve the following
nonconvex problem 

k+1|zk ⇠ p(a>i zk)  where ai’s are unknown coefﬁcient vectors  zi

U⇤ 2 argmax
U2Rm⇥r

Trace(U>⌃U )

subject to U>U = Ir

(1.3)

where ⌃ is the covariance matrix of our interest. This is also known as an eigenvalue problem.
The column span of the optimal solution U⇤ equals the subspace spanned by the eigenvectors
corresponding to the ﬁrst r largest eigenvalues of ⌃. Existing literature usually assumes that at the
k-th iteration  we observe a random vector zk independently sampled from some distribution D with
E[zk] = 0 and E[zkz>k ] =⌃ . Our setting  however  assumes that zk is sampled from some time
series with a stationary distribution ⇡ satisfying E⇡[zk] = 0 and E⇡[zkz>k ] =⌃ . There are two key
computational challenges in such a streaming PCA problem:
• For time series  it is difﬁcult to get unbiased estimators of the covariance matrix of the stationary
distribution because of the data dependency. Taking GVAR as an example  the marginal distribution
of zk is different from the stationary distribution. As a result  the stochastic gradient at the k-th
iteration is biased  i.e.  E[zkz>k Uk|Uk] 6=⌃ Uk;
• The optimization problem in (1.3) is nonconvex  and its solution space is rotational-invariant. Given
any orthogonal matrix Q 2 Rr⇥r and any feasible solution U  the product U Q is also a feasible
solution and gives the same column span as U. When r > 1  this fact leads to the degeneracy in
the optimization landscape such that equivalent saddle points and optima are non-isolated. The
algorithmic behavior under such degeneracy is still quite open for SGD.

2

To address the ﬁrst challenge  we propose a variant of Oja’s algorithm to handle data dependency.
Speciﬁcally  inspired by Duchi et al. (2012a)  we use downsampling to generate weakly dependent
samples. Theoretically  we show that the downsampled data point yields a sequence of stochastic
approximations of the covariance matrix of the stationary distribution with controllable small bias.
Moreover  the block size for downsampling only logarithmically depends on the optimization accuracy 
which is nearly constant (see more details in Sections 2 and 3).
To attack nonconvexity and the degeneracy of the solution space  we establish new convergence
analysis based on principle angle between Uk and the eigenspace of ⌃. By applying diffusion
approximations  we show that the solution trajectory weakly converges to the solution of a stochastic
differential equation (SDE)  which enables us to quantify the uncertainty of the proposed algorithm
(see more details in Sections 3 and 5). Investigating the analytical solution of the SDE allows us to
characterize the algorithmic behavior of SGD in three different scenarios: escaping from saddle points 
traversing between stationary points  and converging to global optima. We prove that the stochastic
algorithm asymptotically converges and achieves nearly optimal asymptotic sample complexity.
There are several closely related works. Chen et al. (2017) study the streaming PCA problem for
r = 1 also based on diffusion approximations. However  r = 1 makes problem (1.3) admit an
isolated optimal solution  unique up to sign change. For r > 1  the global optima are nonisolated due
to the rotational invariance property. Thus  the analysis is more involved and challenging. Moreover 
Jain et al. (2016); Allen-Zhu and Li (2016) provide nonasymptotic analysis for the Oja’s algorithm for
streaming PCA. Their techniques are quite different from ours. Their nonasymptotic results  though
more rigorous in describing discrete algorithms  lack intuition and can only be applied to the Oja’s
algorithm with no data dependency. In contrast  our analysis handles data dependency and provides
detailed explanation to the asymptotic algorithmic behavior.
Notations: Given a vector v = (v1  . . .   vm)> 2 Rm  we deﬁne the Euclidean norm kvk2
2 = v>v.
Given a matrix A 2 Rm⇥n  we deﬁne the spectral norm kAk2 as the largest singular value of A
and the Frobenius norm kAk2
F = Trace(AA>). We also deﬁne r(A) as the r-th largest singular
value of A. For a diagonal matrix ⇥ 2 Rm⇥m  we deﬁne sin ⇥ = diag (sin(⇥11)  . . .   sin(⇥mm))
and cos ⇥ = diag (cos(⇥11)  . . .   cos(⇥mm)). We denote the canonical basis of Rm by ei for
i = 1  . . .   m with the i-th element being 1  and the canonical basis of Rr by e0j for j = 1  . . .   r.

2 Downsampled Oja’s Algorithm

We ﬁrst explain how to construct a nearly unbiased covariance estimator for the stationary distribution 
which is crucial for our proposed algorithm. Before proceed  we brieﬂy review geometric ergodicity
for time series  which characterizes the mixing time of a Markov chain.
Deﬁnition 2.1 (Geometric Ergodicity and Total Variation Distance). A Markov chain with state
space S and stationary distribution ⇡ on (S F) with F being a -algebra on S  is geometrically
ergodic  if it is positive recurrent and there exists an absolute constant ⇢ 2 (0  1) such that the total
variation distance satisﬁes

DTV (pn(x ·) ⇡ (·)) = supA2F |pn(x  A)  ⇡(A)| = O (⇢n)

for all x 2 S 

where pn(· ·) is the n-step transition kernel1.
Note that ⇢ is independent of n and only depends on the underlying transition kernel of the Markov
chain. The geometric ergodicity is equivalent to saying that the chain is -mixing with an exponen-
tially decaying coefﬁcient (Bradley et al.  2005).
As aforementioned  one key challenge of solving the streaming PCA problem for time series is that
it is difﬁcult to get unbiased estimators of the covariance matrix ⌃ of the stationary distribution.
However  when the time series is geometrically ergodic  the transition probability ph(zk  zk+h)
converges exponentially fast to the stationary distribution. This allows us to construct a nearly
unbiased estimator of ⌃ as shown in the next lemma.

1The formal deﬁnitions of positive recurrent and transition kernel can be found in Durrett (2010) Chapter 6.
In short  a positive recurrent Markov chain visits each state in a ﬁnite time almost surely  and transition kernel is
a generalization of transition probability to continuous state spaces.

3

Lemma 2.2. Let {zk}1k=1 be a geometrically ergodic Markov chain with parameter ⇢  and assume
zk is Sub-Gaussian. Given a pre-speciﬁed accuracy ⌧  there exists h = O⇢ log 1
Eh(z2h+k  zh+k)(z2h+k  zh+k)>/2zki =⌃+ E⌃
with kEk2  ⌧  where ⇢ is a constant depending on ⇢ and ⌃ is the covariance matrix of zk under
the stationary distribution.

⌧ such that

k+1|zk ⇠ p(a>i zk)  where zi

Lemma 2.2 shows that as h increases  the bias decreases to zero. This suggests that we can use the
downsampling method to reduce the bias of the stochastic gradient. Speciﬁcally  we divide the data
points into blocks of length 2h  i.e.  z1  z2  . . .   z2h   z2h+1  . . .   z4h   . . .   z2(b1)h+1  . . .   z2bh .
For the s-th block  we use data points z(2s1)h and z2sh to approximate ⌃ by Xs = 1
2 (z2sh 
z(2s1)h)(z2sh  z(2s1)h)>. Later we will show that the block size h only logarithmically depends
on the optimization accuracy. Thus  the downsampling is affordable. Moreover  if the stationary
distribution has zero mean  we only need the block size to be h and Xs = zshz>sh.
Many time series models in machine learning are geometrically ergodic. We discuss a few examples.
Example 2.3. The vector autoregressive (VAR) model follows the update zk+1 = Azk + ✏k  where
✏k’s are i.i.d. Sub-Gaussian random vectors with E[✏k] = 0 and E[✏k✏>k ] =   and A is the coefﬁcient
matrix. When ⇢ = kAk2 < 1  the model is stationary and geometrically ergodic (Tjøstheim  1990).
Moreover  the mean of its stationary distribution is 0.
Example 2.4. Recall that GVAR model follows zi
k+1’s are independent
conditioning on zk. The density function is p(x|✓) = h(x) exp (T (x)✓  B(✓))   where T (x) is a
statistic  and B(✓) is the log partition function. GVAR is stationary and geometrically ergodic under
certain regularity conditions (Hall et al.  2016).
As an illustrative example  we show that for Gaussian VAR with ⇢ = kAk2 < 1 and = I  the
bias of the covariance estimator can be controlled by choosing h = O⇣ 1
⌧⌘. The covariance
1⇢ log 1
matrix of the stationary distribution is ⌃= P1i=0 Ai(A>)i. One can check
E⇥zh+kz>h+k|zk⇤  ⌃= Ahzkz>k (A>)h +P1i=h Ai(A>)i.
hand side  since both terms are of the order O(⇢2h). As a result  the bias of E⇥zh+kz>h+k|zk⇤
decays to zero exponentially fast. We pick h = O⇣ 1
⌧⌘   and obtain E⇥zk+hz>k+h|zk⇤ =
⌃+ E⌃ with kEk2  ⌧.
We then propose a variant of Oja’s algorithm combined with our downsampling technique as sum-
marized in Algorithm 1. For simplicity  we assume the stationary distribution has mean zero.
The projection ⇧Orth(U ) denotes the orthogonal-
ization operator that performs on columns of U.
Speciﬁcally  for U 2 Rm⇥r  ⇧Orth(U ) returns a
matrix U0 2 Rm⇥r that has orthonormal columns.
Typical examples of such operators include Gram-
Schmidt method and Householder transformation.
The step 

Input: data points zk  block size h  step size ⌘
Initialize U1 with orthonormal columns.
Set s 1
repeat

Here the spectrum of A acts as the geometrically decaying factor for both terms on the right

Algorithm 1 Downsampled Oja’s Algorithm

1⇢ log 1

Us+1 =⇧ Orth(Us + ⌘XsUs) 

is essentially the original Oja’s update. Our vari-
ant manipulates on data points by downsampling
such that Xs is nearly unbiased. We emphasize
that s denotes the number of iterations  and k denotes the number of samples.

Take sample zsh  and set Xs zshz>sh
Us+1 ⇧Orth(Us + ⌘XsUs)
s s + 1
until Convergence
Output: Us

3 Theory

We exploit diffusion approximations to characterize the convergence of downsampled SGD in 3 stages.
Speciﬁcally  we use an ODE (Theorem 3.4) to analyze the global convergence and SDEs (Theorems
3.5 and 3.8) to capture the local dynamics around saddle points and global optima. By the weak

4

convergence of the discrete algorithm trajectory to the ODE and SDE  we show that downsampled
SGD achieves an nearly optimal asymptotic sample complexity (Corollary 3.10). Before proceed  we
impose some model assumptions on the problem.
Assumption 3.1 . There exists an eigengap in the covariance matrix ⌃ of the stationary distribution 
i.e.  1 ··· r > r+1 ··· m > 0  where i is the i-th eigenvalue of ⌃.
Assumption 3.2 . Data points {zk}k1 are generated from a geometrically ergodic time series with
parameter ⇢  and the stationary distribution has mean zero. Each zk is Sub-Gaussian  and the block
size is chosen as h = O (⇢ log(1/⌘)) for downsampling.
The eigengap in Assumption 3.1 implies that the optimal solution is identiﬁable. Speciﬁcally  the
optimal solution U⇤ is unique up to rotation. The positive deﬁnite assumption on ⌃ is for theoretical
simplicity. Assumption 3.2 implies that each zk has bounded moments of any order.
We also brieﬂy explain the optimization landscape of streaming PCA problems as follows. Speciﬁcally 
we consider the eigenvalue decomposition ⌃= R⇤R> with ⇤= diag(1  2  . . .   m). Recall that
ei is the canonical basis of Rm. We distinguish stationary points U of streaming PCA problems:
• U is a global optimum  if the column span of R>U equals the subspace spanned by {e1  . . .   er};
• U is a saddle point or a global minima  if the column span of R>U equals the subspace spanned by
{ea1  . . .   ear}  where Ar = {a1  . . .   ar}⇢{ 1  . . .   m} and Ar 6= {1  . . .   r}.
For convenience  if the column span of R>U coincides with {ea1  . . .   ear}  we say that U is a
stationary point corresponding to the set Ar = {a1  . . .   ar}.
To handle the rotational invariance of the solution space  we use principle angle to characterize the
distance between the column spans of U⇤ and Us. The notation is as follows. Given two matrices U 2
Rm⇥r1 and V 2 Rm⇥r2 with orthonormal columns  where 1  r1  r2  m  the principle angle
between these two matrices is  ⇥(U  V ) = diagarccos1(U>V )   . . .   arccosr1(U>V ) .
We show the consequence of using principle angle as follows. Speciﬁcally  any optimal solution
U⇤ satisﬁes ksin ⇥(Rr  U⇤)k2
F = 0  where Rr denotes the ﬁrst r columns
of R  and Rr denotes the last m  r columns of R. This essentially implies that the column span
of U⇤ is orthogonal to that of Rr. Thus  to prove the convergence of SGD  we only need to show
cos ⇥(Rr  Us)2
F ! 0. By the rotational invariance of principle angle  we obtain ⇥Rr  Us =
⇥R>Rr  R>Us =⇥ Er  R>Us   where Er = [er+1  . . .   em]. For notational simplicity  we
denote U s = R>Us. Then the convergence of the algorithm is equivalent tocos ⇥Er  U s2
0. We need such an orthogonal transformation  becausecos ⇥Er  U s2
cos ⇥Er  U s2
i s =e>i U s2

3.1 Global Convergence by ODE
Since the sequence {zsh  U s}1s=1 forms a discrete Markov process  we can apply diffusion ap-
proximations to establish global convergence of SGD. Speciﬁcally  by a continuous time interpo-
lation  we construct continuous time processes U ⌘(t) and X ⌘(t) such that U ⌘(t) = Ubt/⌘c+1 and
X ⌘(t) = Xbt/⌘c+1. The subscript bt/⌘c + 1 denotes the number of iterations  and the superscript ⌘
highlights the dependence on ⌘. We denote U
(t) = R>X ⌘(t)R. The con-
tinuous time version of 2
2. It is difﬁcult to directly characterize
the global convergence of 2
Lemma 3.3. Let Er = [e1  . . .   er] 2 Rm⇥r. Suppose U
E>r U

F = cos ⇥(Rr  U⇤)2

i ⌘(t). Thus  we introduce an upper bound of 2

F =Pm

i=r+1e>i U s2

F !
F can be expressed as

(t) has orthonormal columns and

2 =Pm

(t) is invertible. We have

(t) = R>U ⌘(t) and X

i=r+1 2

i s with 2

i ⌘(t) as follows.

i s is written as 2

i ⌘(t) = ke>i U

(t)k2

⌘

⌘

⌘

2 .

⌘

⌘

2

2  2

i ⌘(t).

(3.1)

(3.2)

⌘

⌘

(t)⇣E>r U

(t)⌘1
i ⌘(t) =e>i U
e2
The detailed proof is provided in Appendix B.1. We showe2
Theorem 3.4. As ⌘ ! 0  the processe2
de2
i = bie2

5

i ⌘(t) converges in the following theorem.

i ⌘(t) weakly converges to the solution of the ODE
i dt with bi  2(i  r) 

2

2

  and U (0) has orthonormal columns.

i (0) =e>i U (0)E>r U (0)1

wheree2
The detailed proof is provided in Appendix B.2. The analytical solution to (3.2) ise2
to derive the upper bound (3.1). Under this condition e2

i (0)ebit
with bi  2(r+1  r) < 0 for any i 2{ r + 1  . . .   m}. Note that we need E>r U (0) to be invertible
i (t) converges to zero. However  when
E>r U (0) is not invertible  the algorithm starts at a saddle point  and (3.2) no longer applies. As can
be seen  the ODE characterization is insufﬁcient to capture the local dynamics (e.g.  around saddle
points or global optima) of the algorithm.

i (t) =e2

⌘

i ⌘(t) as 2

3.2 Local Dynamics by SDE
The deterministic ODE characterizes the average behavior of the solution trajectory. To capture the
uncertainty of the local algorithmic behavior  we need to rescale the inﬂuence of the noise to bring
the randomness back  which leads us to a stochastic differential equation (SDE) approximation.
• Stage 1: Escape from Saddle Points Recall that ⇤= diag(1  . . .   m) collects all the eigenval-
ues of ⌃. We consider the eigenvalue decomposition U>(0)⇤U (0) = Q>e⇤Q  where Q 2 Rr⇥r
is orthogonal and e⇤= diag(e1  . . .  er). Again  by a continuous time interpolation  we denote
(t)]>ei  where e0j is the canonical basis in Rr. Then we decompose the
⇣ij ⌘(t) = ⌘1/2e0>j Q[U
principle angle 2
ij ⌘(t). Recall that U (0) is a saddle point  if the column
span of U (0) equals the subspace spanned by {ea1  . . .   ear} with Ar = {a1  . . .   ar}6 = {1  . . .   r}.
Therefore  if the algorithm starts around a saddle point  there exists some i 2{ 1  . . .   r} such that
i ⌘(0) ⇡ 0 and 2
i ⌘(t) around a saddle point is
2
captured in the following theorem.
Theorem 3.5. Suppose U (0) is initialized around a saddle point corresponding to Ar. As ⌘ ! 0 
i ⌘(t) = O(⌘) for some i 2{ 1  . . .   r}  ⇣ ij ⌘(t) weakly converges to
conditioning on the event2
the solution of the following stochastic differential equation
where Bt is a standard Brownian motion  and ar is the largest element in Ar.
The detailed proof is provided in Appendix B.3. We remark that the event 2
technical assumption. This does not cause any issue  since when ⌘12
has escaped from the saddle point. Note that (3.3) admits the analytical solution

d⇣ij = Kij⇣ijdt + GijdBt with Kij 2 [i  1  i  ar ] and G2

a ⌘(0) ⇡ 1 for a 2A r. The asymptotic behavior of 2

i ⌘(t) = O(⌘) is only a
i ⌘(t) is large  the algorithm

i ⌘(t) = ⌘Pr

ij < 1 

j=1 ⇣2

(3.3)

⇣ij(t) = ⇣ij(0)eKij t + GijZ t

0

(3.4)
which is known as an O-U process. We give the following implications on different values of Kij:

eKij (st)dB(s) 

(a). When Kij > 0  rewrite (3.4) as ⇣ij(t) =h⇣ij(0) + GijR t

0 eKij sdB(s)i eKij t. The exponential
term eKij t is dominant and increases to positive inﬁnity as t ! 1. While the remaining part on the
right hand side is a process with mean ⇣ij(0) and variance bounded by G2
ij/(2Kij). Hence  eKij t
acts as a driving force to increase ⇣ij(t) exponentially fast so that ⇣ij(t) quickly gets away from 0;
(b). When Kij < 0  the mean of ⇣ij(t) is ⇣ij(0)eKij t. The initial condition restricts ⇣ij(0) to be
small. Thus as t increases  the mean of ⇣ij(t) converges to zero. Thus  the drift term vanishes quickly.
The variance of ⇣ij(t) is bounded by G2
(c). When Kij = 0  the drift term is approximately zero  meaning that ⇣ij(t) also oscillates around 0.
We provide an example showing how the algorithm escapes from a saddle point. Suppose that the
algorithm starts at the saddle point corresponding to Ar = {1  . . .   q  1  q + 1  . . .   r  p}. Consider
q ⌘(t). By implication (a)  we have Kqr = qp > 0. Hence ⇣qr ⌘(t) increases
the principle angle 2
quickly away from zero. Thus  2
qr ⌘(t) also increases quickly  which drives the algorithm
away from the saddle point. Meanwhile  by (b) and (c)  2
i ⌘(t) stays at 1 for i < q because of the
vanishing drift. The algorithm tends to escape from the saddle point through reducing 2
p ⌘(t)  since
this yields the largest eigengap  q  p. When we have q = r and p = r + 1  the eigengap is
minimal. Thus  it is the worst situation for the algorithm to escape from a saddle point. We give the
following proposition characterizing the time for the algorithm to escape from a saddle point.

ij/(2Kij). Hence  ⇣ij(t) roughly oscillates around 0;

q ⌘(t)  ⌘⇣2

6

T1 ⇣

r  r+1

Proposition 3.6. Suppose that the algorithm starts around the saddle point corresponding to Ar =
{1  . . .   r  1  r + 1}. Given a pre-speciﬁed ⌫ and  = O(⌘ 1
log(K + 1) with K =

1

 

2 ) for a sufﬁciently small ⌘  we need
2(r  r+1)⌘12
)i2
h1( 1⌫/2
G2
rr

2

such that P2

r ⌘(T1)  2  1  ⌫  where  is the CDF of the standard Gaussian distribution.

The detailed proof is provided in Appendix B.4. This implies that  asymptotically  we need

S1 ⇣

T1
⌘ ⇣

log(K + 1)
⌘(r  r+1)

iterations to escape from a saddle point  and the algorithm enters the second stage.
• Stage 2: Traverse between Stationary Points After the algorithm escapes from the saddle
point  the gradient is dominant  and the noise is negligible. Thus  the algorithm behaves like
an almost deterministic traverse between stationary points  which can be viewed as a two-step
discretization of the ODE with an error of the order O(⌘) (Grifﬁths and Higham  2010). Hence 
i ⌘(t) to characterize the algorithmic behavior in this stage. Recall that we assume
we focus on 2
Ar = {1  . . .   r1  r+1}. When the algorithm escapes from the saddle point  we have 2
r ⌘(T1)  2 
which impliesPm
i ⌘(t)  1  2. The following proposition assumes that the algorithm starts
at this initial condition.
Proposition 3.7. Restarting the counter of time  for a sufﬁciently small ⌘ and  = O(⌘ 1
2 ). We need

i=r+1 2

such that PPm

i=r+1 2

i ⌘(t)  2  3

1

r  r+1

log

1
2

T2 ⇣
4.

The detailed proof is provided in Appendix B.5. This implies that  asymptotically  we need

S2 ⇣

T2
⌘ ⇣

1

log

1
2

⌘(r  r+1)
iterations to reach the neighborhood of the global optima.
• Stage 3: Converge to Global Optima Similar to stage 1  we focus on ⇣ij ⌘(t) to characterize the
dynamics of the algorithm around the global optima using an SDE approximation.
Theorem 3.8. Suppose U (0) is initialized around the global optima withPm
i ⌘(0) = O(⌘).
Then as ⌘ ! 0  for i = r + 1  . . .   m and j = 1  . . .   r  ⇣ij ⌘(t) weakly converges to the solution of
the following SDE
(3.5)
d⇣ij = Kij⇣ijdt + GijdBt with Kij 2 [i  1  i  r] and G2

ij < 1 

i=r+1 2

where Bt is a standard Brownian motion.
The detailed proof is provided in Appendix B.6. The analytical solution of (3.5) is

⇣ij(t) = ⇣ij(0)eKij t + GijZ t

0

eKij (st)dB(s).

We then establish the following proposition.
Proposition 3.9. For a sufﬁciently small ✏ and ⌘   = O(⌘ 1

2 )  restarting the counter of time  we need

1

T3 ⇣

log K0 with K0 =

8(r  r+1)2

 

such that we have PPm

r  r+1
i=r+1 2

i ⌘(T3)  ✏  3

(r  r+1)✏  4⌘rGm

4   where Gm = max1jrPm

The detailed proof is provided in Appendix B.7. The subscript m in Gm highlights its dependence on
the dimension m. Proposition 3.9 implies that  asymptotically  we need

ij.
i=r+1 G2

S3 ⇣

T3
⌘ ⇣

log K0

⌘(r  r+1)

iterations to converge to an ✏-optimal solution in the third stage. Combining all the results in three
stages  we know that after T1 + T2 + T3 time  the algorithm converges to an ✏-optimal solution
asymptotically. This further leads us to a more reﬁned result in the following corollary.

7

Corollary 3.10. For a sufﬁciently small ✏  we choose

⌘ ⇣

(r  r+1)✏

.

5rGm

⌘

2

4 .

Suppose we start the algorithm near a saddle point  then we need T = T1 + T2 + T3 such that

The detailed proof is provided in Appendix B.8. Recall that we choose the block size h of downsam-

F  ✏◆  3
⌘⌘. Thus  the asymptotic sample complexity satisﬁes

P✓cos ⇥⇣Er  U
(T )⌘
pling to be h = O⇣⇢ log 1
From the perspective of statistical recovery  the obtained estimatorbU enjoys a near-optimal asymptotic
rate of convergencecos ⇥(bU   U⇤)

✏(r  r+1)2 log2

  where N is the number of data points.

rGm log N

(rr+1)2N/⇢

✏(r  r+1)

N ⇣

T h
⌘ ⇣

4 Numerical Experiments

2

F ⇣

rGm

rGm

.

We demonstrate the effectiveness of our proposed algorithm using both simulated and real datasets.
• Simulated Data We ﬁrst verify our analysis of streaming PCA problems for time series using a
simulated dataset. We choose a Gaussian VAR model with dimension m = 16. The random vector
✏k’s are independently sampled from N (0  S)  where

S = diag(1  1  1  1  1  1  1  1  1  1  1  1  1  3  3  3).

We choose the coefﬁcient matrix A = V >DV   where V 2 R16⇥16 is an orthogonal matrix that we
randomly generate  and D = 0.1D0 is a diagonal matrix satisfying
D0 = diag(0.68  0.68  0.69  0.70  0.70  0.70  0.72  0.72  0.72  0.72  0.72  0.72  0.80  0.80  0.85  0.90).
By solving the discrete Lyapunov equation ⌃= A⌃A> + S  we calculate the covariance matrix of
the stationary distribution  which satisﬁes ⌃= U>⇤U  where U 2 R16⇥16 is orthogonal and

⇤= diag(3.0175  3.0170  3.0160  1.0077  1.0070  1.0061  1.0058  1.0052 
1.0052  1.0052  1.0052  1.0051  1.0049  1.0049  1.0047  1.0047).

We aim to ﬁnd the leading principle components of ⌃ corresponding to the ﬁrst 3 largest eigenvalues.
Thus  the eigengap is 3  4 = 2.0083. We initialize the solution at the saddle point whose column
span is the subspace spanned by the eigenvectors corresponding to 3.0175  3.0170 and 1.0077. The
step size is ⌘ = 3 ⇥ 105  and the algorithm runs with 8 ⇥ 105 total samples. The trajectories of
the principle angle over 20 independent simulations with block size h = 4 are shown in Figure 1a.
We can clearly distinguish three different stages. Figure 1c and 1d illustrate that entries of principle
angles  ⇣33 in stage 1 and ⇣42 in stage 3  are Ornstein-Uhlenbeck processes. Speciﬁcally  the estimated
distributions of ⇣33 and ⇣42 over 100 simulations follow Gaussian distributions. We can check that
the variance of ⇣33 increases in stage 1 as iteration increases  while the variance of ⇣42 in stage 3
approaches a ﬁxed value. All these simulated results are consistent with our theoretical analysis.

Stage 1

Stage 2

Stage 3

(a) Solution trajectories

(b) Different block sizes (c) Distribution of ⇣33(t) (d) Distribution of ⇣42(t)

Figure 1: Illustrations of various algorithmic behaviors in simulated examples: (a) presents three
stages of the algorithm; (b) compares the performance of different block sizes; (c) and (d) demonstrate
the Ornstein-Uhlenbeck processes of ⇣33 in stage 1 and ⇣42 in stage 3.
We further compare the performance of different block sizes of downsampling with step size annealing.
We keep using Gaussian VAR model with D = 0.9D0 and
S = diag(1.45  1.45  1.45  1.45  1.45  1.45  1.45  1.45  1.45  1.45  1.45  1.45  1.45  1.455  1.455  1.455).

8

The eigengap is 3  4 = 0.005. We run the algorithm with 5 ⇥ 105 samples and the chosen step
sizes vary according to the number of samples k. Speciﬁcally  we set the step size ⌘ = ⌘0 ⇥ h
4000 if
48000 if k 2 [5 ⇥ 104  10 ⇥ 104) 
k < 2 ⇥ 104  ⌘ = ⌘0 ⇥ h
120000 if k  10 ⇥ 104. We choose ⌘0 in {0.125  0.25  0.5  1  2} and report the ﬁnal
and ⌘ = ⌘0 ⇥ h
principle angles achieved by different block sizes h in Table 1. Figure 1b presents the averaged
principle angle over 5 simulations with ⌘0 = 0.5. As can be seen  choosing h = 4 yields the
best performance. Speciﬁcally  the performance becomes better as h increases from 1 to around 4.
However  the performance becomes worse  when h = 16 because of the lack of iterations.

8000 if k 2 [2 ⇥ 104  5 ⇥ 104)  ⌘ = ⌘0 ⇥ h

Table 1: The ﬁnal principle angles achieved by different block sizes with varying ⌘0.

⌘0 = 0.125

⌘0 = 0.25

h = 1
h = 2
h = 4
h = 6
h = 8
h = 16

0.7775
0.7792
0.7892
0.7542
0.7982
0.7783

0.3595
0.3569
0.3745
0.3655
0.3933
0.4324

⌘0 = 0.5
0.2320
0.2080
0.1130
0.1287
0.2828
0.3038

⌘0 = 1
0.2449
0.2477
0.3513
0.3317
0.3820
0.5647

⌘0 = 2
0.3773
0.2290
0.4730
0.3983
0.4102
0.6526

• Real Data We adopt the Air Quality dataset (De Vito et al.  2008)  which contains 9358 instances
of hourly averaged concentrations of totally 9 different gases in a heavily polluted area. We remove
measurements with missing data. We aim to estimate the ﬁrst 2 principle components of the series.
We randomly initialize the algorithm  and choose the block size of downsampling to be 1  3  5  10 
and 60. Figure 2 shows that the projection of each data point onto the leading and the second principle
components. We also present the result of projecting data points onto the eigenspace of sample
covariance matrix indicated by Batch in Figure 2. All the projections have been rotated such that
the leading principle component is parallel to the horizontal axis. As can be seen  when h = 1  the
projection yields some distortion in the circled area. When h = 3 and h = 5  the projection results are
quite similar to the Batch result. As h increases  however  the projection displays obvious distortion
again compared to the Batch result. The concentrations of gases are naturally time dependent. Thus 
we deduce that the distortion for h = 1 comes from the data dependency  while for the case h = 60 
the distortion comes from the lack of updates. This phenomenon coincides with our simulated data
experiments.

h = 1

h = 5

h = 10

h = 30

h = 60

Batch

Figure 2: Projections of air quality data onto the leading and the second principle components with
different block sizes of downsampling. We highlight the distortions for h = 1 and h = 60.

5 Discussions

We remark that our analysis characterizes how our proposed algorithm escapes from the saddle point.
This is not analyzed in the related work  Allen-Zhu and Li (2016)  since they use random initialization.
Note that our analysis also applies to random initialization  and directly starts with the second stage.
Our analysis is inspired by diffusion approximations in existing applied probability literature (Glynn 
1990; Freidlin and Wentzell  1998; Kushner and Yin  2003; Ethier and Kurtz  2009)  which target to
capture the uncertainty of stochastic algorithms for general optimization problems. Without explicitly
specifying the problem structures  these analyses usually cannot lead to concrete convergence
guarantees. In contrast  we dig into the optimization landscape of the streaming PCA problem.
This eventually allows us to precisely characterize the algorithmic dynamics and provide concrete
convergence guarantees  which further lead to a deeper understanding of the uncertainty in nonconvex
stochastic optimization.
The block size h of downsampled Oja’s algorithm is based on the mixing property of the time series.
We believe estimating the mixing coefﬁcient is an interesting problem. The procedure in Hsu et al.
(2015) estimates the mixing time of Markov chains  which may possibly be adapted to our time series
setting. Moreover  estimating the covariance matrix of the stationary distribution is also interesting
but challenging. We leave them for future investigation.

9

References
ALLEN-ZHU  Z. (2017). Natasha 2: Faster non-convex optimization than sgd. arXiv preprint

arXiv:1708.08694 .

ALLEN-ZHU  Z. and LI  Y. (2016). First efﬁcient convergence for streaming k-pca: a global 

gap-free  and near-optimal rate. arXiv preprint arXiv:1607.07837 .

BOTTOU  L. (1998). Online learning and stochastic approximations. On-line learning in neural

networks 17 142.

BRADLEY  R. C. ET AL. (2005). Basic properties of strong mixing conditions. a survey and some

open questions. Probability surveys 2 107–144.

CHEN  Z.  YANG  L. F.  LI  C. J. and ZHAO  T. (2017). Online partial least square optimization:
Dropping convexity for better efﬁciency and scalability. In International Conference on Machine
Learning.

CHUNG  K. L. (2004). On a stochastic approximation method. In Chance And Choice: Memorabilia.

World Scientiﬁc  79–99.

DANG  C. D. and LAN  G. (2015). Stochastic block mirror descent methods for nonsmooth and

stochastic optimization. SIAM Journal on Optimization 25 856–881.

DE VITO  S.  MASSERA  E.  PIGA  M.  MARTINOTTO  L. and DI FRANCIA  G. (2008). On ﬁeld
calibration of an electronic nose for benzene estimation in an urban pollution monitoring scenario.
Sensors and Actuators B: Chemical 129 750–757.

DUCHI  J. C.  AGARWAL  A.  JOHANSSON  M. and JORDAN  M. I. (2012a). Ergodic mirror descent.

SIAM Journal on Optimization 22 1549–1578.

DUCHI  J. C.  BARTLETT  P. L. and WAINWRIGHT  M. J. (2012b). Randomized smoothing for

stochastic optimization. SIAM Journal on Optimization 22 674–701.

DURRETT  R. (2010). Probability: theory and examples. Cambridge university press.
ETHIER  S. N. and KURTZ  T. G. (2009). Markov processes: characterization and convergence  vol.

282. John Wiley &amp; Sons.

FREIDLIN  M. I. and WENTZELL  A. D. (1998). Random perturbations. In Random Perturbations

of Dynamical Systems. Springer  15–43.

GE  R.  HUANG  F.  JIN  C. and YUAN  Y. (2015). Escaping from saddle points—online stochastic

gradient for tensor decomposition. In Conference on Learning Theory.

GE  R.  LEE  J. D. and MA  T. (2016). Matrix completion has no spurious local minimum. In

Advances in Neural Information Processing Systems.

GLYNN  P. W. (1990). Diffusion approximations. Handbooks in Operations research and manage-

ment Science 2 145–198.

GRIFFITHS  D. F. and HIGHAM  D. J. (2010). Numerical methods for ordinary differential equations:

initial value problems. Springer Science & Business Media.

HALL  E. C.  RASKUTTI  G. and WILLETT  R. (2016). Inference of high-dimensional autoregressive

generalized linear models. arXiv preprint arXiv:1605.02693 .

HOMEM-DE MELLO  T. (2008). On rates of convergence for stochastic optimization problems under
non–independent and identically distributed sampling. SIAM Journal on Optimization 19 524–551.
HSU  D. J.  KONTOROVICH  A. and SZEPESVÁRI  C. (2015). Mixing time estimation in reversible
markov chains from a single sample path. In Advances in neural information processing systems.
JAIN  P.  JIN  C.  KAKADE  S. M.  NETRAPALLI  P. and SIDFORD  A. (2016). Streaming pca:
In

Matching matrix bernstein and near-optimal ﬁnite sample guarantees for oja’s algorithm.
Conference on Learning Theory.

10

KUSHNER  H. and YIN  G. G. (2003). Stochastic approximation and recursive algorithms and

applications  vol. 35. Springer Science &amp; Business Media.

LEE  J. D.  PANAGEAS  I.  PILIOURAS  G.  SIMCHOWITZ  M.  JORDAN  M. I. and RECHT  B.
(2017). First-order methods almost always avoid saddle points. arXiv preprint arXiv:1710.07406 .
LI  X.  WANG  Z.  LU  J.  ARORA  R.  HAUPT  J.  LIU  H. and ZHAO  T. (2016). Symmetry  saddle
points  and global geometry of nonconvex matrix factorization. arXiv preprint arXiv:1612.09296 .
NEMIROVSKI  A.  JUDITSKY  A.  LAN  G. and SHAPIRO  A. (2009). Robust stochastic approxima-

tion approach to stochastic programming. SIAM Journal on optimization 19 1574–1609.

REDDI  S. J.  SRA  S.  POCZOS  B. and SMOLA  A. J. (2016). Proximal stochastic methods for
nonsmooth nonconvex ﬁnite-sum optimization. In Advances in Neural Information Processing
Systems.

ROBBINS  H. and MONRO  S. (1951). A stochastic approximation method. The annals of mathemat-

ical statistics 400–407.

SACKS  J. (1958). Asymptotic distribution of stochastic approximation procedures. The Annals of

Mathematical Statistics 29 373–405.

SHALEV-SHWARTZ  S.  SINGER  Y.  SREBRO  N. and COTTER  A. (2011). Pegasos: Primal

estimated sub-gradient solver for svm. Mathematical programming 127 3–30.

SHAMIR  O. and ZHANG  T. (2013). Stochastic gradient descent for non-smooth optimization:
Convergence results and optimal averaging schemes. In International Conference on Machine
Learning.

SREBRO  N. and JAAKKOLA  T. S. (2004). Linear dependent dimensionality reduction. In Advances

in Neural Information Processing Systems.

SUN  J.  QU  Q. and WRIGHT  J. (2015). Complete dictionary recovery over the sphere. In Sampling

Theory and Applications (SampTA)  2015 International Conference on. IEEE.

SUN  J.  QU  Q. and WRIGHT  J. (2016). A geometric analysis of phase retrieval. In Information

Theory (ISIT)  2016 IEEE International Symposium on. IEEE.

TJØSTHEIM  D. (1990). Non-linear time series and markov chains. Advances in Applied Probability

22 587–611.

11

,Minshuo Chen
Lin Yang
Mengdi Wang
Tuo Zhao