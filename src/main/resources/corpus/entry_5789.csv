2016,Unsupervised Risk Estimation Using Only Conditional Independence Structure,We show how to estimate a model’s test error from unlabeled data  on distributions very different from the training distribution  while assuming only that certain conditional independencies are preserved between train and test. We do not need to assume that the optimal predictor is the same between train and test  or that the true distribution lies in any parametric family. We can also efficiently compute gradients of the estimated error and hence perform unsupervised discriminative learning. Our technical tool is the method of moments  which allows us to exploit conditional independencies in the absence of a fully-specified model. Our framework encompasses a large family of losses including the log and exponential loss  and extends to structured output settings such as conditional random fields.,Unsupervised Risk Estimation Using Only

Conditional Independence Structure

Jacob Steinhardt
Stanford University

jsteinhardt@cs.stanford.edu

Abstract

Percy Liang

Stanford University

pliang@cs.stanford.edu

We show how to estimate a model’s test error from unlabeled data  on distributions
very different from the training distribution  while assuming only that certain con-
ditional independencies are preserved between train and test. We do not need to
assume that the optimal predictor is the same between train and test  or that the
true distribution lies in any parametric family. We can also efﬁciently compute
gradients of the estimated error and hence perform unsupervised discriminative
learning. Our technical tool is the method of moments  which allows us to exploit
conditional independencies in the absence of a fully-speciﬁed model. Our frame-
work encompasses a large family of losses including the log and exponential loss 
and extends to structured output settings such as conditional random ﬁelds.

1

Introduction

Can we measure the accuracy of a model at test time without any ground truth labels  and without
assuming the test distribution is close to the training distribution? This is the problem of unsupervised
risk estimation (Donmez et al.  2010): Given a loss function L(θ; x  y) and a ﬁxed model θ  estimate
the risk R(θ) def= Ex y∼p∗ [L(θ; x  y)] with respect to a test distribution p∗(x  y)  given access only
to m unlabeled examples x(1:m) ∼ p∗(x). Unsupervised risk estimation lets us estimate model
accuracy on a novel distribution  and is thus important for building reliable machine learning systems.
Beyond evaluating a single model  it also provides a way of harnessing unlabeled data for learning: by
minimizing the estimated risk over θ  we can perform unsupervised learning and domain adaptation.
Unsupervised risk estimation is impossible without some assumptions on p∗  as otherwise p∗(y | x)—
about which we have no observable information—could be arbitrary. How satisﬁed we should be
with an estimator depends on how strong its underlying assumptions are. In this paper  we present
an approach which rests on surprisingly weak assumptions—that p∗ satisﬁes certain conditional
independencies  but not that it lies in any parametric family or is close to the training distribution.
To give a ﬂavor for our results  suppose that y ∈ {1  . . .   k} and that the loss decomposes as a
v=1 fv(θ; xv  y)  where the xv (v = 1  2  3) are independent
conditioned on y. In this case  we show that we can estimate the risk to error  in poly(k)/2 samples 
independently of the dimension of x or θ  with only very mild additional assumptions on p∗. In
Sections 2 and 3 we generalize to a larger family of losses including the log and exponential losses 
and extend beyond the multiclass case to conditional random ﬁelds.
Some intuition behind our result is provided in Figure 1. At a ﬁxed value of x  we can think of each
fv as “predicting” that y = j if fv(xv  j) is low and fv(xv  j(cid:48)) is high for j(cid:48) (cid:54)= j. Since f1  f2  and
f3 all provide independent signals about y  their rate of agreement gives information about the model
accuracy. If f1  f2  and f3 all predict that y = 1  then it is likely that the true y equals 1 and the
loss is small. Conversely  if f1  f2  and f3 all predict different values of y  then the loss is likely

sum of three parts: L(θ; x  y) = (cid:80)3

30th Conference on Neural Information Processing Systems (NIPS 2016)  Barcelona  Spain.

f1

f2

f3

f1

f2

f3

1 2 3 4

1 2 3 4

1 2 3 4

1 2 3 4

1 2 3 4

1 2 3 4

y

y

y

y

y

y

Figure 1: Two possible loss proﬁles at a given value of x. Left: if f1  f2  and f3 are all minimized at
the same value of y  that is likely to be the correct value and the total loss is likely to be small. Right:
conversely  if f1  f2  and f3 are small at differing values of y  then the loss is likely to be large.
large. This intuition is formalized by Dawid and Skene (1979) when the fv measure the 0/1-loss of
independent classiﬁers; in particular  if rv is the prediction of a classiﬁer based on xv  then Dawid
v=1 p(rv | y = j).

and Skene model the rv as independent given y: p(r1  r2  r3) =(cid:80)k

j=1 p(y = j)(cid:81)3

They then use the learned parameters of this model to compute the 0/1-loss.
Partial speciﬁcation. Dawid and Skene’s approach relies on the prediction rv only taking on k values.
In this case  the full distribution p(r1  r2  r3) can be parametrized by k×k conditional probability
matrices p(rv | y) and marginals p(y). However  as shown in Figure 1  we want to estimate continuous
losses such as the log loss. We must therefore work with the prediction vector fv ∈ Rk rather than a
single predicted output rv ∈{1  . . .   k}. To fully model p(f1  f2  f3) would require nonparametric
estimation  resulting in an undesirable sample complexity exponential in k—in contrast to the discrete
case  conditional independence effectively only partially speciﬁes a model for the losses.
To sidestep this issue  we make use of the method of moments  which has recently been used to
ﬁt non-convex latent variable models (e.g. Anandkumar et al.  2012). In fact  it has a much older
history in the econometrics literature  where it is used as a tool for making causal identiﬁcations
under structural assumptions  even when no explicit form for the likelihood is known (Anderson and
Rubin  1949; 1950; Sargan  1958; 1959; Hansen  1982; Powell  1994; Hansen  2014). It is this latter
perspective that we draw upon. The key insight is that even in the absence of a fully-speciﬁed model 
certain moment equations–such as E[f1f2 | y] = E[f1 | y]E[f2 | y]–can be derived solely from the
assumed conditional independence. Solving these equations yields estimates of E[fv | y]  which can
in turn be used to estimate the risk. Importantly  our procedure avoids estimation of the full loss
distribution p(f1  f2  f3)  on which we make no assumptions other than conditional independence.
Our paper is structured as follows. In Section 2  we present our basic framework  and state and prove
our main result on estimating the risk. In Section 3  we extend our framework in several directions 
including to conditional random ﬁelds. In Section 4  we present a gradient-based learning algorithm
and show that the sample complexity needed for learning is d · poly(k)/2  where d is the dimension
of the parameters θ. In Section 5  we investigate how our method performs empirically.
Related Work. While the formal problem of unsupervised risk estimation was only posed recently
by Donmez et al. (2010)  several older ideas from domain adaptation and semi-supervised learning
are also relevant. The covariate shift assumption posits access to labeled samples from a training
distribution p0(x  y) for which p∗(y | x) = p0(y | x).
If p∗(x) and p0(x) are close  we can
approximate p∗ by p0 via importance weighting (Shimodaira  2000; Quiñonero-Candela et al.  2009).
If p∗ and p0 are not close  another approach is to assume a well-speciﬁed discriminative model family
Θ  such that p0(y | x) = p∗(y | x) = pθ∗ (y | x) for some θ∗ ∈ Θ; then the only error when moving
from p0 to p∗ is statistical error in the estimation of θ∗ (Blitzer et al.  2011; Li et al.  2011). Such
assumptions are restrictive—importance weighting only allows small perturbations from p0 to p∗  and
mis-speciﬁed models of p(y| x) are common in practice; many authors report that mis-speciﬁcation
can lead to severe issues in semi-supervised settings (Merialdo  1994; Nigam et al.  1998; Cozman
and Cohen  2006; Liang and Klein  2008; Li and Zhou  2015). More sophisticated approaches based
on discrepancy minimization (Mansour et al.  2009) or learning invariant representations (Ben-David
et al.  2006; Johansson et al.  2016) typically also make some form of the covariate shift assumption.
Our approach is closest to Dawid and Skene (1979) and some recent extensions (Zhang et al.  2014;
Platanios  2015; Jaffe et al.  2015; Fetaya et al.  2016). Similarly to Zhang et al. (2014) and Jaffe
et al. (2015)  we use the method of moments for estimating latent-variable models. However  those
papers use it for parameter estimation in the face of non-convexity  rather than as a way to avoid full
estimation of p(fv | y). The insight that the method of moments works under partial speciﬁcation lets
us extend beyond the simple discrete settings they consider to handle more complex continuous and
structured losses. The intriguing work of Balasubramanian et al. (2011) provides an alternate approach

2

label:

y

yt−2

yt−1

yt

yt+1

y

z

inputs:

x1

x2

x3

xt−2

xt−1

xt

xt+1

x1

x2

x3

Figure 2: Left: our basic 3-view setup (Assumption 1). Center: Extension 1  to CRFs; the embedding
of 3 views into the CRF is indicated in blue. Right: Extension 3  to include a mediating variable z.
to continuous losses; they show that the distribution of losses L| y is often approximately Gaussian 
and use that to estimate the risk. Among all this work  ours is the ﬁrst to perform gradient-based
learning and the ﬁrst to handle a structured loss (the log loss for conditional random ﬁelds).

2 Framework and Estimation Algorithm
We will focus on multiclass classiﬁcation; we assume an unknown true distribution p∗(x  y) over
X × Y  where Y = {1  . . .   k}  and are given unlabeled samples x(1)  . . .   x(m) drawn i.i.d. from
p∗(x). Given parameters θ ∈ Rd and a loss function L(θ; x  y)  our goal is to estimate the risk of θ
on p∗: R(θ) def= Ex y∼p∗ [L(θ; x  y)]. Throughout  we will make the 3-view assumption:
Assumption 1 (3-view). Under p∗  x can be split into x1  x2  x3  which are conditionally independent
given y (see Figure 2). Moreover  the loss decomposes additively across views: L(θ; x  y) =

A(θ; x) −(cid:80)3

v=1 fv(θ; xv  y)  for some functions A and fv.

exp(cid:0)θ(cid:62) (φ1(x1  y) + φ2(x2  y) + φ3(x3  y)) − A(θ; x)(cid:1)  where x1  x2  and x3 are independent

Note that each xv can be large (e.g. they could be vectors in Rd). If we have V > 3 views  we
can combine views to obtain V = 3 without loss of generality. It also sufﬁces for just the fv to be
independent rather than the xv. Given only 2 views  the risk can be shown to be unidentiﬁable in
general  although obtaining upper bounds may be possible.
We give some examples where Assumption 1 holds  then state and prove our main result (see Section 3
for additional examples). We start with logistic regression  which will be our primary focus later on:
Example 1 (Logistic Regression). Suppose that we have a log-linear model pθ(y | x) =
conditioned on y. If our loss function is the log-loss L(θ; x  y) = − log pθ(y | x)  then Assumption 1
holds with fv(θ; xv  y) = θ(cid:62)φv(xv  y) and A(θ; x) equal to the partition function of pθ.
Assumption 1 does not hold for the hinge loss (see Appendix A for details)  but it does hold for a
modiﬁed hinge loss  where we apply the hinge separately to each view:
v=1(1 + maxj(cid:54)=y θ(cid:62)φv(xv  j) −
θ(cid:62)φv(xv  y))+. In other words  L is the sum of 3 hinge losses  one for each view. Then Assumption 1
holds with A = 0  and −fv equal to the hinge loss for view v.
The model can also be non-linear within each view xv  as long as the views are combined additively:
Example 3 (Neural Networks). Suppose that for each view v we have a neural network whose output
is a score for each of the k classes  (fv(θ; xv  j))k
j=1. Sum the scores f1 + f2 + f3  apply a soft-max 
v=1 fv(θ; xv  y)  where A(θ; x) is the

Example 2 (Modiﬁed Hinge Loss). Suppose that L(θ; x  y) =(cid:80)3

and evaluate using the log loss; then L(θ; x  y) = A(θ; x) −(cid:80)3

log-normalization constant of the softmax  and hence L satisﬁes Assumption 1.

We are now ready to present our main result on recovering the risk R(θ). The key starting point is the
conditional risk matrices Mv ∈ Rk×k  deﬁned as (suppressing the dependence on θ)

(Mv)ij = E[fv(θ; xv  i) | y = j].

(1)
In the case of the 0/1-loss  the Mv are confusion matrices; in general  (Mv)ij measures how strongly
we predict class i when the true class is j. If we could recover these matrices along with the marginal
class probabilities πj

def= p∗(y = j)  then estimating the risk would be straightforward; indeed 

(cid:34)

A(θ; x) − 3(cid:88)

(cid:35)

= E[A(θ; x)] − k(cid:88)

3(cid:88)

R(θ) = E

fv(θ; xv  y)

πj

(Mv)j j 

(2)

v=1

j=1

v=1

3

where E[A(θ; x)] can be estimated from unlabeled data alone.
Caveat: Class permutation. Suppose that at training time  we learn to predict whether an image con-
tains the digit 0 or 1. At test time  nothing changes except the deﬁnitions of 0 and 1 are reversed. It is
clearly impossible to detect this from unlabeled data— mathematically  the risk matrices Mv are only
recoverable up to column permutation. We will end up computing the minimum risk over these permu-
tations  which we call the optimistic risk and denote ˜R(θ) def= minσ∈Sym(k) Ex y∼p∗ [L(θ; x  σ(y))].
This equals the true risk as long as θ is at least aligned with the correct classes in the sense that
Ex[L(θ; x  j) | y = j] ≤ Ex[L(θ; x  j(cid:48)) | y = j] for j(cid:48) (cid:54)= j. The optimal σ can be computed from

Mv and π in O(cid:0)k3(cid:1) time using maximum weight bipartite matching; see Section B for details.

Our main result  Theorem 1  says that we can recover both Mv and π up to permutation  with a
number of samples that is polynomial in k:
Theorem 1. Suppose Assumption 1 holds. Then  for any   δ ∈ (0  1)  we can estimate Mv and π up
to column permutation  to error  (in Frobenius and ∞-norm respectively). Our algorithm requires

m = poly(cid:0)k  π−1

min  λ−1  τ(cid:1) · log(2/δ)
p∗(y = j)  τ def= E(cid:2)(cid:80)

2

πmin

def=

k

min
j=1

samples to succeed with probability 1 − δ  where

v jfv(θ; xv  j)2(cid:3)  and λ def=

σk(Mv) 

(3)

3

min
v=1

k(cid:88)

k(cid:88)

2

and σk denotes the kth singular value. Moreover  the algorithm runs in time m · poly(k).
Estimates for Mv and π imply an estimate for ˜R via (2); see Algorithm 1 below for details. Im-
portantly  the sample complexity in Theorem 1 depends on the number of classes k  but not on the
dimension d of θ. Moreover  Theorem 1 holds even if p∗ lies outside the model family θ  and even if
the train and test distributions are very different (in fact  the result is agnostic to how the model θ was
produced). The only requirement is the 3-view assumption for p∗ and that λ  πmin (cid:54)= 0.
Let us interpret each term in (3). First  τ tracks the variance of the loss  and we should expect the
difﬁculty of estimating the risk to increase with this variance. The log(2/δ)
term is typical and shows
up even when estimating the parameter of a random variable to accuracy  from m samples. The
π−1
min term appears because  if one of the classes is very rare  we need to wait a long time to observe
even a single sample from that class  and even longer to estimate the risk on that class accurately.
Perhaps least intuitive is the λ−1 term  which is large e.g. when two classes have similar conditional
i=1 | y = j]. To see why this matters  consider an extreme where x1  x2 
risk vectors E[(fv(θ; xv  i))k
and x3 are independent not only of each other but also of y. Then p∗(y) is completely unconstrained 
and it is impossible to estimate R at all. Why does this not contradict Theorem 1? The answer is
that in this case  all rows of Mv are equal and hence Mv has rank 1  λ = 0  λ−1 = ∞  and we need
inﬁnitely many samples for Theorem 1 to hold; λ measures how close we are to this degenerate case.
Proof of Theorem 1. We now outline a proof of Theorem 1. Recall the goal is to estimate the
conditional risk matrices Mv  deﬁned as (Mv)ij = E[fv(θ; xv  i) | y = j]; from these we can
recover the risk itself using (2). The key insight is that certain moments of p∗(y | x) can be expressed
as polynomial functions of the matrices Mv  and therefore we can solve for the Mv even without
explicitly estimating p∗. Our approach follows the technical machinery behind the spectral method of
moments (e.g.  Anandkumar et al.  2012)  which we explain below for completeness.
Deﬁne the loss vector hv(xv) = (fv(θ; xv  i))k
i=1  which measures the loss that would be incurred
under each of the k classes. The conditional independence of the xv means that E[h1(x1)h2(x2)(cid:62) |
y] = E[h1(x1) | y]E[h2(x2) | y](cid:62)  and similarly for higher-order conditional moments. Marginal-
izing over y  we see that there is low-rank structure in the moments of h that we can exploit; in
particular (letting ⊗ denote outer product and A· j denote the jth column of A):

E[hv(xv)] =

πj·(Mv)· j  E[hv(xv)⊗hv(cid:48)(xv(cid:48))] =

πj·(Mv)· j⊗(Mv(cid:48))· j for v (cid:54)= v(cid:48)  and

k(cid:88)

j=1

E[h1(x1)⊗h2(x2)⊗h3(x3)] =

j=1

πj·(M1)· j⊗(M2)· j⊗(M3)· j.

(4)

The left-hand-side of each equation can be estimated from unlabeled data; using tensor decomposition
(Lathauwer  2006; Comon et al.  2009; Anandkumar et al.  2012; 2013; Kuleshov et al.  2015)  it is

j=1

4

Algorithm 1 Algorithm for estimating ˜R(θ) from unlabeled data.
1: Input: unlabeled samples x(1)  . . .   x(m) ∼ p∗(x).
2: Estimate the left-hand-side of each term in (4) using x(1:m).
3: Compute approximations ˆMv and ˆπ to Mv and π using tensor decomposition.

4: Compute σ maximizing(cid:80)k
(cid:80)m
i=1 A(θ; x(i)) −(cid:80)k

5: Output: estimated risk  1
m

v=1( ˆMv)j σ(j).

(cid:80)3

(cid:80)3

j=1 ˆπσ(j)

j=1 ˆπσ(j)

v=1( ˆMv)j σ(j) using maximum bipartite matching.

then possible to solve for Mv and π. In particular  we can recover M and π up to permutation: that is 
we recover ˆM and ˆπ such that Mi j ≈ ˆMi σ(j) and πj ≈ ˆπσ(j) for some permutation σ ∈ Sym(k).
This then yields Theorem 1; see Section C for a full proof.
Assumption 1 thus yields a set of moment equations (4) whose solution lets us estimate the risk
without any labels y. The procedure is summarized in Algorithm 1: we (i) approximate the left-hand-
side of each term in (4) by sample averages; (ii) use tensor decomposition to solve for π and Mv; (iii)
use maximum matching to compute the permutation σ; and (iv) use (2) to obtain ˜R from π and Mv.

3 Extensions

Theorem 1 provides a basic building block which admits several extensions to more complex model
structures. We go over several cases below  omitting most proofs to avoid tedium.
Extension 1 (Conditional Random Field). Most importantly  the variable y need not belong to a
small discrete set; we can handle structured outputs such as a CRF as long as p∗ has the right structure.
This contrasts with previous work on unsupervised risk estimation that was restricted to multiclass
classiﬁcation (though in a different vein  it is close to Proposition 8 of Anandkumar et al. (2012)).
Suppose that p∗(x1:T   y1:T ) factorizes as a hidden Markov model  and that pθ is a CRF respecting
t=1 gθ(yt  xt). For the log-loss
L(θ; x  y) = − log pθ(y1:T | x1:T )  we can exploit the decomposition

the HMM structure: pθ(y1:T | x1:T ) ∝ (cid:81)T

− log pθ(y1:T | x1:T ) =

− log pθ(yt−1  yt | x1:T )

− log pθ(yt | x1:T )

.

(5)

t satisfy Assumption 1 (see Figure 2; for (cid:96)t  the views are
t they are x1:t−1  xt  xt+1:T ). We use Theorem 1 to estimate
t] individually  and thus also the full risk E[L]. (We actually estimate the risk for

Each of the components (cid:96)t and (cid:96)(cid:48)
x1:t−2  xt−1:t  xt+1:T   and for (cid:96)(cid:48)
each E[(cid:96)t]  E[(cid:96)(cid:48)
y2:T−1 | x1:T due to the 3-view assumption failing at the boundaries.)
In general  the idea in (5) applies to any structured output problem that is a sum of local 3-view
structures. It would be interesting to extend our results to other structures such as more general
graphical models (Chaganty and Liang  2014) and parse trees (Hsu et al.  2012).
Extension 2 (Exponential Loss). We can also relax the additivity L = A−f1−f2−f3 in Assumption 1.
v=1 φv(xv  y)) is the exponential loss. Theorem 1
lets us estimate the matrices Mv corresponding to fv(θ; xv  y) = exp(−θ(cid:62)φv(xv  y)). Then

For instance  suppose L(θ; x  y) = exp(−θ(cid:62)(cid:80)3
(cid:35)
3(cid:89)
(cid:88)
by conditional independence  so the risk can be computed as(cid:80)
(cid:81)3
to any loss expressible as L(θ; x  y) = A(θ; x) +(cid:80)n

v=1(Mv)j j. This idea extends
j πj
i (θ; xv  y) for some functions f v
i .
v=1 f v
Extension 3 (Mediating Variable). Assuming that x1:3 are independent conditioned only on y may
not be realistic; there might be multiple subclasses of a class (e.g.  multiple ways to write the digit 4)
which would induce systematic correlations across views. To address this  we show that independence
need only hold conditioned on a mediating variable z  rather than on the class y itself.
Let z be a reﬁnement of y (in the sense that knowing z determines y) which takes on k(cid:48) values  and
suppose that the views x1  x2  x3 are independent conditioned on z  as in Figure 2. Then we can

E [fv(θ; xv  j) | y = j]

(cid:34) 3(cid:89)

fv(θ; xv  y)

(cid:81)3

R(θ) = E

(6)

v=1

v=1

πj

i=1

=

j

t=2 fθ(yt−1  yt) ·(cid:81)T
− T(cid:88)
(cid:125)
(cid:123)(cid:122)

t=1

(cid:124)

def= (cid:96)t

T(cid:88)

t=2

(cid:124)

(cid:123)(cid:122)

def= (cid:96)(cid:48)

t

(cid:125)

5

try to estimate the risk by deﬁning L(cid:48)(θ; x  z) = L(θ; x  y(z))  which satisﬁes Assumption 1. The
problem is that the corresponding risk matrices M(cid:48)
v will only have k distinct rows and hence have
rank k < k(cid:48). To ﬁx this  suppose that the loss vector hv(xv) = (fv(xv  j))k
j=1 can be extended
v(xv) ∈ Rk(cid:48)
to a vector h(cid:48)
v(xv) are hv(xv) and (ii) the
conditional risk matrix M(cid:48)
v has full rank. Then  Theorem 1 allows us to recover
M(cid:48)

  such that (i) the ﬁrst k coordinates of h(cid:48)
v corresponding to h(cid:48)

v and hence also Mv (since it is a sub-matrix of M(cid:48)

v) and thereby estimate the risk.

4 From Estimation to Learning
We now turn our attention to unsupervised learning  i.e.  minimizing R(θ) over θ ∈ Rd. Unsupervised
learning is impossible without some additional information  since even if we could learn the k classes 
we wouldn’t know which class had which label (this is the same as the class permutation issue from
before). Thus we assume that we have a small amount of information to break this symmetry:
Assumption 2 (Seed Model). We have access to a “seed model” θ0 such that ˜R(θ0) = R(θ0).

Assumption 2 is very weak — it merely asks for θ0 to be aligned with the true classes on average.
We can obtain θ0 from a small amount of labeled data (semi-supervised learning) or by training in a
nearby domain (domain adaptation). We deﬁne gap(θ0) to be the difference between R(θ0) and the
next smallest permutation of the classes–i.e.  gap(θ0) def= minσ(cid:54)=id E[L(θ0; x  σ(y)) − L(θ0; x  y)]–
which will affect the difﬁculty of learning.
For simplicity we will focus on the case of logistic regression  and show how to learn given only
Assumptions 1 and 2. Our algorithm extends to general losses  as we show in Section F.
Learning from moments. Note that for logistic regression (Example 1)  we have

(cid:104)
A(θ; x) − θ(cid:62) 3(cid:88)

R(θ) = E

(cid:105)

3(cid:88)

φv(xv  y)

= E[A(θ; x)] − θ(cid:62) ¯φ  where ¯φ def=

E[φv(xv  y)]. (7)

v=1

v=1

From (7)  we see that it sufﬁces to estimate ¯φ  after which all terms on the right-hand-side of (7)
are known. Given an approximation ˆφ to ¯φ (we will show how to obtain ˆφ below)  we can learn a
near-optimal θ by solving the following convex optimization problem:

ˆθ = arg min
(cid:107)θ(cid:107)2≤ρ

E[A(θ; x)] − θ(cid:62) ˆφ.

(8)

In practice we would need to approximate E[A(θ; x)] by samples  but we ignore this for simplicity
(it generally only contributes lower-order terms to the error). The reason for the (cid:96)2-constraint on θ is
that it imparts robustness to the error between ˆφ and ¯φ. In particular (see Section D for a proof):
Lemma 1. Suppose (cid:107) ˆφ− ¯φ(cid:107)2 ≤ . Then the output ˆθ from (8) satisﬁes R(ˆθ) ≤ min(cid:107)θ(cid:107)2≤ρ R(θ)+2ρ.
If the optimal θ∗ has (cid:96)2-norm at most ρ  Lemma 1 says that ˆθ nearly minimizes the risk: R(ˆθ) ≤
R(θ∗) + 2ρ. The problem of learning θ thus reduces to computing a good estimate ˆφ of ¯φ.
Computing ˆφ. Estimating ¯φ can be done in a manner similar to how we estimated R(θ) in Section 2.
In addition to the conditional risk matrix Mv ∈ Rk×k  we compute the conditional moment matrix
Gv ∈ Rdk×k  which tracks the conditional expectation of φv: (Gv)i+(r−1)k j
def= E[φv(θ; xv  i)r |

y = j]  where r indexes 1  . . .   d. We then have ¯φr =(cid:80)k
(since O(cid:0)k3d3(cid:1) memory is intractable for even moderate values of d). We take a standard approach
Then  given m = poly(cid:0)k  π−1

based on random projections (Halko et al.  2011) and described in Section 6.1.2 of Anandkumar et al.
(2013). We refer the reader to the aforementioned references for details  and cite only the resulting
sample complexity and runtime  which are both roughly d times larger than in Theorem 1.
Theorem 2. Suppose that Assumptions 1 and 2 hold. Let δ < 1 and  < min(1  gap(θ0)).
samples  where λ and τ are as deﬁned in (3) 

As in Theorem 1  we can solve for G1  G2  and G3 using a tensor factorization similar to (4)  though
some care is needed to avoid explicitly forming the (kd) × (kd) × (kd) tensor that would result

v=1(Gv)j+(r−1)k j.

min  λ−1  τ(cid:1) · log(2/δ)

2

(cid:80)3

j=1 πj

6

Figure 3: A few sample train images (left) and test images (right) from the modiﬁed MNIST data set.

(a)

(b)

(c)

i v (cid:107)φv(xv  i)(cid:107)2

B2 = E[(cid:80)
Gv requires (B/τ )2 · poly(cid:0)k  π−1

Figure 4: Results on the modiﬁed MNIST data set. (a) Risk estimation for varying degrees of
distortion a. (b) Domain adaptation with 10 000 training and 10 000 test examples. (c) Domain
adaptation with 300 training and 10 000 test examples.
with probability 1 − δ we can recover Mv and π to error   and Gv to error (B/τ )  where
2] measures the (cid:96)2-norm of the features. The algorithm runs in time
O (d (m + poly(k)))  and the errors are in Frobenius norm for M and G  and ∞-norm for π.
See Section E for a proof sketch. Whereas before we estimated the risk matrix Mv to error   now
we estimate the gradient matrix Gv (and hence ¯φ) to error (B/τ ). To achieve error  in estimating
samples  which is (B/τ )2 times as large as in
Theorem 1. The quantity (B/τ )2 typically grows as O(d)  and so the sample complexity needed to
estimate ¯φ is typically d times larger than the sample complexity needed to estimate R. This matches
the behavior of the supervised case where we need d times as many samples for learning as compared
to (supervised) risk estimation of a ﬁxed model.
Summary. We have shown how to perform unsupervised logistic regression  given only a seed model
θ0. This enables unsupervised learning under fairly weak assumptions (only the multi-view and seed
model assumptions) even for mis-speciﬁed models and zero train-test overlap  and without assuming
covariate shift. See Section F for learning under more general losses.

min  λ−1  τ(cid:1) log(2/δ)

2

5 Experiments

To better understand the behavior of our algorithms  we perform experiments on a version of the
MNIST data set that is modiﬁed to ensure that the 3-view assumption holds. To create an image
I  we sample a class in {0  . . .   9}  then sample 3 images I1  I2  I3 at random from that class 
letting every third pixel in I come from the respective image Iv. This guarantees there are 3
conditionally independent views. To explore train-test variation  we dim pixel p in the image by
exp (a ((cid:107)p − p0(cid:107)2 − 0.4))  where p0 is the image center and distances are normalized to be at most
1. We show example images for a = 0 (train) and a = 5 (a possible test distribution) in Figure 3.
Risk estimation. We use Algorithm 1 to perform unsupervised risk estimation for a model trained
on a = 0  testing on various values of a ∈ [0  10]. We trained the model with AdaGrad (Duchi
et al.  2010) on 10 000 training examples  and used 10 000 test examples to estimate the risk. To
solve for π and M in (4)  we ﬁrst use the tensor power method implemented by Chaganty and Liang
(2013) to initialize  and then locally minimize a weighted (cid:96)2-norm of the moment errors in (4) using
L-BFGS. We compared with two other methods: (i) validation error from held-out samples (which
j −pθ(j | x) log pθ(j | x) on the test set
(which would be valid if the predictions were well-calibrated). The results are shown in Figure 4a;
both the tensor method in isolation and tensor + L-BFGS estimate the risk accurately  with the latter
performing slightly better.
Unsupservised domain adaptation. We next evaluate our learning algorithm in an unsupervised
domain adaptation setting  where we receive labeled training data at a = 0 and unlabeled test data
at a different value of a. We use the training data to obtain a seed model θ0  and then perform

would be valid if train = test)  and (ii) predictive entropy(cid:80)

7

0246810Distortion(a)0.00.20.40.60.81.0EstimatedRiskvalidationerrorentropytensortensor+L-BFGStrue0246810Distortion(a)0.00.10.20.30.40.50.60.70.8RiskR(θ)baselinetensor+L-BFGSoracle0246810Distortion(λ)0.00.20.40.60.81.01.2RiskR(θ)baselinetensor+L-BFGSoracleunsupervised learning (Section 4)  setting ρ = 10 in (8). The results are shown in Figure 4b. For
small values of a  our algorithm performs worse than the baseline of directly using θ0  likely due
to ﬁnite-sample effects. However  our algorithm is far more robust as a increases  and tracks the
performance of an oracle that was trained on the same distribution as the test examples.
Because we only need to provide our algorithm with a seed model for disentangling the classes  we
do not need much data when training θ0. To verify this  we tried obtaining θ0 from only 300 labeled
examples. Tensor decomposition sometimes led to bad initializations in this limited data regime  in
which case we obtained a different θ0 by training with a smaller step size. The results are shown in
Figure 4c. Our algorithm generally performs well  but has higher variability than before  seemingly
due to higher condition number of the matrices Mv.
Summary. Our experiments show that given 3 views  we can estimate the risk and perform unsuper-
vised domain adaptation  even with limited labeled data from the source domain.

6 Discussion

We have presented a method for estimating the risk from unlabeled data  which relies only on
conditional independence structure and hence makes no parametric assumptions about the true
distribution. Our approach applies to a large family of losses and extends beyond classiﬁcation tasks
to conditional random ﬁelds. We can also perform unsupervised learning given only a seed model that
can distinguish between classes in expectation; the seed model can be trained on a related domain  on
a small amount of labeled data  or any combination of the two  and thus provides a pleasingly general
formulation highlighting the similarities between domain adaptation and semi-supervised learning.
Previous approaches to domain adaptation and semi-supervised learning have also exploited multi-
view structure. Given two views  Blitzer et al. (2011) perform domain adaptation with zero
source/target overlap (covariate shift is still assumed). Two-view approaches (e.g. co-training
and CCA) are also used in semi-supervised learning (Blum and Mitchell  1998; Ando and Zhang 
2007; Kakade and Foster  2007; Balcan and Blum  2010). These methods all assume some form of
low noise or low regret  as do  e.g.  transductive SVMs (Joachims  1999). By focusing on the central
problem of risk estimation  our work connects multi-view learning approaches for domain adaptation
and semi-supervised learning  and removes covariate shift and low-noise/low-regret assumptions
(though we make stronger independence assumptions  and specialize to discrete prediction tasks).
In addition to reliability and unsupervised learning  our work is motivated by the desire to build
machine learning systems with contracts  a challenge recently posed by Bottou (2015); the goal is for
machine learning systems to satisfy a well-deﬁned input-output contract in analogy with software
systems (Sculley et al.  2015). Theorem 1 provides the contract that under the 3-view assumption the
test error is close to our estimate of the test error; the typical (weak) contract of ML systems is that if
train and test are similar  then the test error is close to the training error. One other interesting contract
is to provide prediction regions that contain the truth with probability 1 −  (Shafer and Vovk  2008;
Khani et al.  2016)  which includes abstaining when uncertain as a special case (Li et al.  2011).
The most restrictive part of our framework is the three-view assumption  which is inappropriate if the
views are not completely independent or if the data have structure that is not captured in terms of
multiple views. Since Balasubramanian et al. (2011) obtain results under Gaussianity (which would
be implied by many somewhat dependent views)  we are optimistic that unsupervised risk estimation
is possible for a wider family of structures. Along these lines  we end with the following questions:
Open question. In the 3-view setting  suppose the views are not completely independent. Is it still
possible to estimate the risk? How does the degree of dependence affect the number of views needed?
Open question. Given only two independent views  can one obtain an upper bound on the risk R(θ)?
The results of this paper have caused us to adopt the following perspective: To leverage unlabeled
data  we should make generative structural assumptions  but still optimize discriminative model
performance. This hybrid approach allows us to satisfy the traditional machine learning goal of
predictive accuracy  while handling lack of supervision and under-speciﬁcation in a principled way.
Perhaps  then  what is truly needed for learning is understanding the structure of a domain.
Acknowledgments. This research was supported by a Fannie & John Hertz Foundation Fellowship 
a NSF Graduate Research Fellowship  and a Future of Life Institute grant.

8

References
A. Anandkumar  D. Hsu  and S. M. Kakade. A method of moments for mixture models and hidden Markov

A. Anandkumar  R. Ge  D. Hsu  S. M. Kakade  and M. Telgarsky. Tensor decompositions for learning latent

models. In COLT  2012.

variable models. arXiv  2013.

T. W. Anderson and H. Rubin. Estimation of the parameters of a single equation in a complete system of

stochastic equations. The Annals of Mathematical Statistics  pages 46–63  1949.

T. W. Anderson and H. Rubin. The asymptotic properties of estimates of the parameters of a single equation in a

complete system of stochastic equations. The Annals of Mathematical Statistics  pages 570–582  1950.

R. K. Ando and T. Zhang. Two-view feature generation model for semi-supervised learning. In COLT  2007.
K. Balasubramanian  P. Donmez  and G. Lebanon. Unsupervised supervised learning II: Margin-based classiﬁca-

tion without labels. JMLR  12:3119–3145  2011.

M. Balcan and A. Blum. A discriminative model for semi-supervised learning. JACM  57(3)  2010.
S. Ben-David  J. Blitzer  K. Crammer  and F. Pereira. Analysis of representations for domain adaptation. In

NIPS  pages 137–144  2006.

J. Blitzer  S. Kakade  and D. P. Foster. Domain adaptation with coupled subspaces. In AISTATS  2011.
A. Blum and T. Mitchell. Combining labeled and unlabeled data with co-training. In COLT  1998.
L. Bottou. Two high stakes challenges in machine learning. Invited talk at ICML  2015.
A. Chaganty and P. Liang. Spectral experts for estimating mixtures of linear regressions. In ICML  2013.
A. Chaganty and P. Liang. Estimating latent-variable graphical models using moments and likelihoods. In ICML 

2014.

P. Comon  X. Luciani  and A. L. D. Almeida. Tensor decompositions  alternating least squares and other tales.

Journal of Chemometrics  23(7):393–405  2009.

F. Cozman and I. Cohen. Risks of semi-supervised learning: How unlabeled data can degrade performance of

generative classiﬁers. In Semi-Supervised Learning. 2006.

A. P. Dawid and A. M. Skene. Maximum likelihood estimation of observer error-rates using the EM algorithm.

Applied Statistics  1:20–28  1979.

P. Donmez  G. Lebanon  and K. Balasubramanian. Unsupervised supervised learning I: Estimating classiﬁcation

and regression errors without labels. JMLR  11:1323–1351  2010.

J. Duchi  E. Hazan  and Y. Singer. Adaptive subgradient methods for online learning and stochastic optimization.

J. Edmonds and R. M. Karp. Theoretical improvements in algorithmic efﬁciency for network ﬂow problems.

In COLT  2010.

JACM  19(2):248–264  1972.

E. Fetaya  B. Nadler  A. Jaffe  Y. Kluger  and T. Jiang. Unsupervised ensemble learning with dependent

classiﬁers. In AISTATS  pages 351–360  2016.

N. Halko  P.-G. Martinsson  and J. Tropp. Finding structure with randomness: Probabilistic algorithms for

constructing approximate matrix decompositions. SIAM Review  53:217–288  2011.

L. P. Hansen. Large sample properties of generalized method of moments estimators. Econometrica  1982.
L. P. Hansen. Uncertainty outside and inside economic models. Journal of Political Economy  122(5)  2014.
D. Hsu  S. M. Kakade  and P. Liang. Identiﬁability and unmixing of latent parse trees. In NIPS  2012.
A. Jaffe  B. Nadler  and Y. Kluger. Estimating the accuracies of multiple classiﬁers without labeled data. In

AISTATS  pages 407–415  2015.

T. Joachims. Transductive inference for text classiﬁcation using support vector machines. In ICML  1999.
F. Johansson  U. Shalit  and D. Sontag. Learning representations for counterfactual inference. In ICML  2016.
S. M. Kakade and D. P. Foster. Multi-view regression via canonical correlation analysis. In COLT  2007.
F. Khani  M. Rinard  and P. Liang. Unanimous prediction for 100% precision with application to learning

semantic mappings. In ACL  2016.

V. Kuleshov  A. Chaganty  and P. Liang. Tensor factorization via matrix factorization. In AISTATS  2015.
L. D. Lathauwer. A link between the canonical decomposition in multilinear algebra and simultaneous matrix

diagonalization. SIAM Journal of Matrix Analysis and Applications  28(3):642–666  2006.

L. Li  M. L. Littman  T. J. Walsh  and A. L. Strehl. Knows what it knows: a framework for self-aware learning.

Machine learning  82(3):399–443  2011.

Y. Li and Z. Zhou. Towards making unlabeled data never hurt. IEEE TPAMI  37(1):175–188  2015.
P. Liang and D. Klein. Analyzing the errors of unsupervised learning. In HLT/ACL  2008.
Y. Mansour  M. Mohri  and A. Rostamizadeh. Domain adaptation: Learning bounds and algorithms. In COLT 

The MIT Press  2009.

B. Merialdo. Tagging English text with a probabilistic model. Computational Linguistics  20:155–171  1994.
K. Nigam  A. McCallum  S. Thrun  and T. Mitchell. Learning to classify text from labeled and unlabeled

documents. In Association for the Advancement of Artiﬁcial Intelligence (AAAI)  1998.

E. A. Platanios. Estimating accuracy from unlabeled data. Master’s thesis  Carnegie Mellon University  2015.
J. L. Powell. Estimation of semiparametric models. In Handbook of Econometrics  volume 4. 1994.
J. Quiñonero-Candela  M. Sugiyama  A. Schwaighofer  and N. D. Lawrence. Dataset shift in machine learning.

J. D. Sargan. The estimation of economic relationships using instrumental variables. Econometrica  1958.
J. D. Sargan. The estimation of relationships with autocorrelated residuals by the use of instrumental variables.

Journal of the Royal Statistical Society: Series B (Statistical Methodology)  pages 91–105  1959.

D. Sculley  G. Holt  D. Golovin  E. Davydov  T. Phillips  D. Ebner  V. Chaudhary  M. Young  J. Crespo  and

D. Dennison. Hidden technical debt in machine learning systems. In NIPS  pages 2494–2502  2015.

G. Shafer and V. Vovk. A tutorial on conformal prediction. JMLR  9:371–421  2008.
H. Shimodaira. Improving predictive inference under covariate shift by weighting the log-likelihood function.

Journal of Statistical Planning and Inference  90:227–244  2000.

J. Steinhardt  G. Valiant  and S. Wager. Memory  communication  and statistical queries. In COLT  2016.
N. Tomizawa. On some techniques useful for solution of transportation network problems. Networks  1971.
Y. Zhang  X. Chen  D. Zhou  and M. I. Jordan. Spectral methods meet EM: A provably optimal algorithm for

crowdsourcing. arXiv  2014.

2009.

9

,Jacob Steinhardt
Percy Liang
Zelda Mariet
Yaniv Ovadia
Jasper Snoek