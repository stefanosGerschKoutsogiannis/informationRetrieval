2016,Dimension-Free Iteration Complexity of Finite Sum Optimization Problems,Many canonical machine learning problems boil down to a convex optimization problem with a finite sum structure. However  whereas much progress has been made in developing faster algorithms for this setting  the inherent limitations of these problems are not satisfactorily addressed by existing lower bounds. Indeed  current bounds focus on first-order optimization algorithms  and only apply in the often unrealistic regime where the number of iterations is less than $\cO(d/n)$ (where $d$ is the dimension and $n$ is the number of samples). In this work  we extend the framework of Arjevani et al. \cite{arjevani2015lower arjevani2016iteration} to provide new lower bounds  which are dimension-free  and go beyond the assumptions of current bounds  thereby covering standard finite sum optimization methods  e.g.  SAG  SAGA  SVRG  SDCA without duality  as well as stochastic coordinate-descent methods  such as SDCA and accelerated proximal SDCA.,Dimension-Free Iteration Complexity of Finite Sum

Optimization Problems

Yossi Arjevani

Weizmann Institute of Science

Rehovot 7610001  Israel

yossi.arjevani@weizmann.ac.il

Ohad Shamir

Weizmann Institute of Science

Rehovot 7610001  Israel

ohad.shamir@weizmann.ac.il

Abstract

Many canonical machine learning problems boil down to a convex optimization
problem with a ﬁnite sum structure. However  whereas much progress has been
made in developing faster algorithms for this setting  the inherent limitations of
these problems are not satisfactorily addressed by existing lower bounds. Indeed 
current bounds focus on ﬁrst-order optimization algorithms  and only apply in
the often unrealistic regime where the number of iterations is less than O(d/n)
(where d is the dimension and n is the number of samples). In this work  we
extend the framework of Arjevani et al. [3  5] to provide new lower bounds  which
are dimension-free  and go beyond the assumptions of current bounds  thereby
covering standard ﬁnite sum optimization methods  e.g.  SAG  SAGA  SVRG 
SDCA without duality  as well as stochastic coordinate-descent methods  such as
SDCA and accelerated proximal SDCA.

1

Introduction

Many machine learning tasks reduce to Finite Sum Minimization (FSM) problems of the form

min
w∈Rd

F (w) :=

1
n

n(cid:88)

i=1

fi(w) 

(1)

where fi are L-smooth and µ-strongly convex. In recent years  a major breakthrough was made
when a linear convergence rate was established for this setting (SAG [16] and SDCA [18])  and since
then  many methods have been developed to achieve better convergence rate. However  whereas a
large body of literature is devoted for upper bounds  the optimal convergence rate with respect to the
problem parameters is not quite settled.
Let us discuss existing lower bounds for this setting  along with their shortcomings  in detail. One
approach to obtain lower bounds for this setting is to consider the average of carefully handcrafted
functions deﬁned on n disjoint sets of variables. This approach was taken by Agarwal and Bottou [1]
who derived a lower bound for FSM under the ﬁrst-order oracle model (see Nemirovsky and Yudin
[12]). In this model  optimization algorithms are assumed to access a given function by issuing queries
to an external ﬁrst-order oracle procedure. Upon receiving a query point in the problem domain  the
oracle reports the corresponding function value and gradient. The construction used by Agarwal and
Bottou consisted of n different quadratic functions which are adversarially determined based on the
ﬁrst-order queries being issued during the optimization process. The resulting bound in this case does
not apply to stochastic algorithms  rendering it invalid for current state-of-the-art methods. Another
instantiation of this approach was made by Lan [10] who considered n disjoint copies of a quadratic
function proposed by Nesterov in [13  Section 2.1.2]. This technique is based on the assumption that
any iterate generated by the optimization algorithm lies in the span of previously acquired gradients.

30th Conference on Neural Information Processing Systems (NIPS 2016)  Barcelona  Spain.

This assumption is rather permissive and is satisﬁed by many ﬁrst-order algorithms  e.g.  SAG and
SAGA [6]. However  the lower bound stated in the paper faces limitations in a few aspects. First  the
validity of the derived bound is restricted to d/n iterations. In many datasets  even if d  n are very
large  d/n is quite small. Accordingly  the admissible regime of the lower bound is often not very
interesting. Secondly  it is not clear how the proposed construction can be expressed as a Regularized
Loss Minimization (RLM) problem with linear predictors (see Section 4). This suggests that methods
specialized in dual RLM problems  such as SDCA and accelerated proximal SDCA [19]  can not be
addressed by this bound. Thirdly  at least the formal theorem requires assumptions (such as querying
in the span of previous gradients  or sampling from a ﬁxed distribution over the individual functions) 
which are not met by some state-of-the-art methods  such as coordinate descent methods  SVRG [9]
and without-replacements sampling algorithms [15].
Another relevant approach in this setting is to model the functional form of the update rules. This
approach was taken by Arjevani et al. [3] where new iterates are assumed to be generated by a
recurrent application of some ﬁxed linear transformation. Although this method applies to SDCA
and produces a tight lower bound of ˜Ω((n + 1/λ) ln(1/))  its scope is rather limited. In recent
work  Arjevani and Shamir [5] considerably generalized parts of this framework by introducing
the class of ﬁrst-order oblivious optimization algorithms  whose step sizes are scheduled regardless
of the function under consideration  and deriving tight lower bounds for general smooth convex
minimization problems (note that obliviousness rules out  e.g.  quasi-Newton methods where gradients
obtained at each iteration are multiplied by matrices which strictly depend on the function at hand 
see Deﬁnition 2 below).
In this work  building upon the framework of oblivious algorithms  we take a somewhat more
abstract point of view which allows us to easily incorporate coordinate-descent methods  as well
as stochastic algorithms. Our framework subsumes the vast majority of optimization methods for
machine learning problems  in particular  it applies to SDCA  accelerated proximal SDCA  SDCA
without duality [17]  SAG  SAGA  SVRG and acceleration schemes [7  11])  as well as to a large
number of methods for smooth convex optimization (i.e.  FSM with n = 1)  e.g.  (stochastic) Gradient
descent (GD)  Accelerated Gradient Descent (AGD  [13])  the Heavy-Ball method (HB  [14]) and
stochastic coordinate descent.
Under this structural assumption  we derive lower bounds for FSM (1)  according to which the
iteration complexity  i.e.  the number of iterations required to obtain an -optimal solution in terms of
function value  is at least1

˜Ω(n +(cid:112)n(κ − 1) ln(1/)) 

(2)

where κ denotes the condition number of F (w) (that is  the smoothness parameter over the strong
convexity parameter). To the best of our knowledge  this is the ﬁrst tight lower bound to address all
the algorithms mentioned above. Moreover  our bound is dimension-free and thus applies to settings
in machine learning which are not covered in the current literature (e.g.  when n is Ω(d)). We also
derive a dimension-free nearly-optimal lower bound for smooth convex optimization of

(cid:16)

(L(δ − 2)/)1/δ(cid:17)

Ω

 

for any δ ∈ (2  4)  which holds for any oblivious stochastic ﬁrst-order algorithm. It should be noted
that our lower bounds remain valid under any source of randomness which may be introduced into
the optimization process (by the oracle or by the optimization algorithm). In particular  our bounds
hold in cases where the variance of the iterates produced by the algorithm converges to zero  a highly
desirable property of optimization algorithms in this setting.
Two implications can be readily derived from this lower bound. First  obliviousness forms a real
barrier for optimization algorithms  and whereas non-oblivious algorithms may achieve a super-linear
convergence rate at later stages of the optimization process (e.g.  quasi-newton)  or practically zero
error after Θ(d) iterations (e.g. Center of Gravity method  MCG)  oblivious algorithms are bound
to linear convergence indeﬁnitely  as demonstrated by Figure 1. We believe that this indicates that
a major progress can be made in solving machine learning problems by employing non-oblivious
methods for settings where d (cid:28) n. It should be further noted that another major advantage of
1Following standard conventions  here tilde notation hides logarithmic factors in the parameters of a given

class of optimization problems  e.g.  smoothness parameter and number of components.

2

non-oblivious algorithms is their ability to obtain optimal convergence rates without an explicit
speciﬁcation of the problem parameters (e.g.  [5  Section 4.1]).

Figure 1: Comparison of ﬁrst-order methods based on the function used by Nesterov in [13  Section
2.1.2] over R500. Whereas L-BFGS (with a memory size of 100) achieves a super-linear convergence
rate after Θ(d) iterations  the convergence rate of GD  AGD and HB remains linear as predicted by
our bound.

Secondly  many practitioners have noticed that oftentimes sampling the individual functions without
replacement at each iteration performs better than sampling with replacement (e.g.  [18  15]  see also
[8  20]). The fact that our lower bound holds regardless of how the individual functions are sampled
and is attained using with-replacement sampling (e.g.  accelerated proximal SDCA)  implies that 
in terms of iteration complexity  one should expect to gain no more than log factors in the problem
parameters when using one method over the other (it is noteworthy that when comparing with and
without replacement samplings  apart from iteration complexity  other computational resources  such
as limited communication in distributed settings [4]  may signiﬁcantly affect the overall runtime).

2 Framework

2.1 Motivation

Due to difﬁculties which arise when studying the complexity of general optimization problems under
discrete computational models  it is common to analyze the computational hardness of optimization
algorithms by modeling the way a given algorithm interacts with the problem instances (without
limiting its computational resources). In the seminal work of Nemirovsky and Yudin [12]  it is shown
that algorithms which access the function at hand exclusively by querying a ﬁrst-order oracle require
at least

˜Ω(cid:0)min(cid:8)d 
κ(cid:9) ln(1/)(cid:1)  
˜Ω(min{d ln(1/) (cid:112)L/}) 

√

µ > 0

µ = 0

(3)

oracle calls to obtain an -optimal solution  where L and µ are the smoothness and the strong
convexity parameter  respectively (note that  here and throughout this section we refer to FSM
problems with n = 1). This lower bound is tight and its dimension-free part is attained by Nesterov’s
well-known accelerated gradient descent  and by MCG otherwise. The fact that this approach is
based on information considerations alone is very appealing and renders it valid for any ﬁrst-order
algorithm. However  discarding the resources needed for executing a given algorithm  in particular
the per-iteration cost (in time and space)  the complexity boundaries drawn by this approach are
too crude from a computational point of view. Indeed  the per-iteration cost of MCG  the only
method known with oracle complexity of O(d ln(1/))  is excessively high  rendering it prohibitive
for high-dimensional problems.
We are thus led into the question of how well can a given optimization algorithm perform assuming
that its per-iteration cost is constrained? Arjevani et al. [3  5] adopted a more structural approach

3

Number of Iterations05001000150020002500Error10-810-610-410-2100102104GDAGDHBL-BFGSLower Boundwhere instead of modeling how information regarding the function at hand is being collected  one
models the update rules according to which iterates are being generated. Concretely  they proposed
the framework of p-CLI optimization algorithms where  roughly speaking  new iterates are assumed
to form linear combinations of the previous p iterates and gradients  and the coefﬁcients of these
linear combinations are assumed to be either stationary (i.e.  remain ﬁxed throughout the optimization
√
process) or oblivious. Based on this structural assumption  they showed that the iteration complexity
of minimizing smooth and strongly convex functions is ˜Ω(
κ ln(1/)). The fact that this lower
bound is stronger than (3)  in the sense that it does not depend on the dimension  conﬁrms that
controlling the functional form of the update rules allows one to derive tighter lower bounds. The
framework of p-CLIs forms the nucleus of our formulation below.

2.2 Deﬁnitions

When considering lower bounds one must be very precise as to the scope of optimization algorithms
to which they apply. Below  we give formal deﬁnitions for oblivious stochastic CLI optimization algo-
rithms and iteration complexity (which serves as a crude proxy for their computational complexity).
Deﬁnition 1 (Class of Optimization Problems). A class of optimization problems is an ordered triple
(F I Of )  where F is a family of functions deﬁned over some domain designated by domF  I is
the side-information given prior to the optimization process and Of is a suitable oracle which upon
receiving x ∈ domF and θ in the parameter set Θ  returns Of (x  θ) ⊆ dom(F) for a given f ∈ F
(we shall omit the subscript in Of when f is clear from the context).
For example  in FSM  F contains functions as deﬁned in (1)  the side-information contains the
smoothness parameter L  the strong convexity parameter µ and the number of components n (although
it carries a crucial effect on the iteration complexity  e.g.  [5]  in this work  we shall ignore the side-
information and assume that all the parameters of the class are given). We shall assume that both
ﬁrst-order and coordinate-descent oracles (see 10 11 below) are allowed to be used during the
optimization process. Formally  this is done by introducing an additional parameter which indicates
which oracle is being addressed. This added degree of freedom does not violate our lower bounds.
We now turn to rigorously deﬁne CLI optimization algorithms. Note that  compared with the deﬁnition
of ﬁrst-order p-CLIs provided in [5]  here  in order to handle coordinate-descent and ﬁrst-order oracles
in a uniﬁed manner  we base our formulation on general oracle procedures.
Deﬁnition 2 (CLI). An optimization algorithm is called a Canonical Linear Iterative (CLI) opti-
mization algorithm over a class of optimization problems (F I Of )  if given an instance f ∈ F
and initialization points {w(0)
i }i∈J ⊆ dom(F)  where J is some index set  it operates by iteratively
generating points such that for any i ∈ J  
Of

∈(cid:88)

k = 0  1  . . .

w(k+1)

(cid:16)

(cid:17)

w(k)

j

; θ(k)
ij

 

i

j∈J

(4)

ij ∈ Θ are parameters chosen  stochastically or deterministically  by the algorithm 
holds  where θ(k)
possibly depending on the side-information. If the parameters do not depend on previously acquired
oracle answers  we say that the given algorithm is oblivious. Lastly  algorithms with |J | ≤ p  for
some p ∈ N  are denoted by p-CLI.

ij ∈ Θ
Note that assigning different weights to different terms in (4) can be done through θ(k)
(e.g.  oracle 10 below). This allows a succinct deﬁnition for obliviousness. Lastly  we deﬁne
iteration complexity.
Deﬁnition 3 (Iteration Complexity). The iteration complexity of a given CLI w.r.t. a given problem
class (F I Of ) is deﬁned to be the minimal number of iterations K such that

E[f (w(k)

1 ) − min

w∈domF f (w)] <  

∀f ∈ F  k ≥ K

where the expectation is taken over all the randomness introduced into the optimization process
(choosing w(k)

1 merely serves as a convention and is not necessary for our bounds to hold).

4

2.3 Proof Technique - Deriving Lower Bounds via Approximation Theory

Consider the following parametrized class of L-smooth and µ-strongly convex optimization problems 

(5)
Clearly  the minimizer of fη are w∗(η) := 1/η  with norm bounded by 1/µ. For simplicity  we will
consider a special case  namely  vanilla gradient descent (GD) with step size 1/L  which produces
new iterates as follows

w∈R fη(w) :=
min

2

ηw2

− w 

η ∈ [µ  L].

w(k+1)(η) = w(k)(η) − 1
L

f(cid:48)
η(w(k)(η)) =

1 − η
L

w(k)(η) +

1
L

.

Setting the initialization point to be w(0)(η) = 0  we derive an explicit expression for w(k)(η):

(cid:17)

(cid:16)
(cid:19)

(cid:18) k

i + 1

k−1(cid:88)

i=0

w(k)(η) =

1
L

(−1)i

(η/L)i.

(6)

Figure 2: The ﬁrst four iterates of GD and AGD  which form polynomials in η  the parameter of
problem (5)  are compared to 1/η over [1  4].

It turns out that each w(k)(η) forms a univariate polynomial whose degree is at most k. Furthermore 
since fη(w) are L-smooth µ-strongly convex for any η ∈ [µ  L]  standard convergence analysis for
2 |w∗(η)| 
GD (e.g.  [13]  Theorem 2.1.14) guarantees that |w(k)(η) − w∗(η)| ≤ (1 − 2/(1 + κ)) k
where κ denotes the condition number. Substituting Equation (6) for w(k)(η) yields

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) 1

L

k−1(cid:88)

i=0

max
η∈[µ L]

(cid:18) k

(cid:19)

i + 1

(−1)i

(η/L)i − 1/η

(cid:18)

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) ≤ 1

µ

(cid:19) k

2

.

1 − 2

1 + κ

Thus  we see that the faster the convergence rate of a given optimization algorithm is  the better
the induced sequence of polynomials (w(k)(η))k≥0 approximate 1/η w.r.t.
the maximum norm
(cid:107) · (cid:107)L∞([µ L]) over [µ  L]. In Fig. 2  we compare the ﬁrst 4 polynomials induced by GD and AGD.
Not surprisingly  AGD polynomials approximates 1/η better than those of GD.
Now  one may ask  assuming that iterates of a given optimization algorithm A for (5) can be
expressed as polynomials sk(η) whose degree does not exceed the iteration number  just how fast
can these iterates converge to the minimizer? Since the convergence rate is bounded from below by
(cid:107)sk(η) − 1/η(cid:107)L∞([µ L])  we may address the following question instead:

(7)
where Pk denotes the set of univariate polynomials whose degree does not exceed k. Problem (7) and
other related settings are main topics of study in approximation theory. Accordingly  our technique

min
s(η)∈Pk

(cid:107)s(η) − 1/η(cid:107)L∞([µ L]) 

5

11.522.533.540.20.30.40.50.60.70.80.91ApproximatingpolynomialsGD  w(1)(2)GD  w(2)(2)GD  w(3)(2)GD  w(4)(2)AGD  w(1)(2)AGD  w(2)(2)AGD  w(3)(2)AGD  w(4)(2)1/2for proving lower bounds makes an extensive use of tools borrowed from this area. Speciﬁcally  in a
paper from 1899 [21] Chebyshev showed that

(cid:13)(cid:13)(cid:13)(cid:13)s(η) − 1

η − c

(cid:13)(cid:13)(cid:13)(cid:13)L∞([−1 1])

min
s(η)∈Pk

≥ (c − √
c2 − 1

c2 − 1)k

 

c > 1 

(8)

(cid:90) L

√

κ ln(1/)).

by which we derive the following theorem (see Appendix A.1 for a detailed proof).
Theorem 1. The number of iterations required by A to get an -optimal solution is ˜Ω(
In the following sections  we apply oblivious CLI on various parameterized optimization problems
so that the resulting iterates are polynomials in the problem parameters. We then apply arguments
similar to the above
A similar reduction  from optimization problems to approximation problems  was used before in a
few contexts to analyze the iteration complexity of deterministic CLIs (e.g.  [5  Section 3]  see also
Conjugate Gradient convergence analysis [14]). But  what if we allow random algorithms? should we
expect the same iteration complexity? To answer this  we use Yao’s minimax principle according to
which the performance of a given stochastic optimization algorithm w.r.t. its worst input are bounded
from below by the performance of the best deterministic algorithm w.r.t. distributions over the input
space. Thus  following a similar reduction one can show that the convergence rate of stochastic
algorithms is bounded from below by

min
s(η)∈Pk

µ

|s(η) − 1/η|

1

L − µ

dη.

(9)

That is  a lower bound for the stochastic case can be attained by considering an approximation
problem w.r.t. weighted L1 with the uniform distribution over [µ  L]. Other approximation problems
considered in this work involve L2-norm and different distributions. We provide a schematic
description of our proof technique in Scheme 2.1.

SCHEME 2.1
GIVEN

CHOOSE
COMPUTE
BOUND

FROM OPTIMIZATION PROBLEMS TO APPROXIMATION PROBLEMS
A CLASS OF FUNCTIONS F   A SUITABLE ORACLE O
AND A SEQUENCE OF SETS OF FUNCTION Sk OVER SOME PARAMETERS SET H.
A SUBSET OF FUNCTIONS {fη ∈ F|η ∈ H}  S.T. wk(η) ∈ Sk.
THE MINIMIZER w∗(η) FOR ANY fη
FROM BELOW THE BEST APPROXIMATION FOR w∗(η) W.R.T. Sk
AND A NORM (cid:107) · (cid:107)  I.E.  min{(cid:107)s(η) − w∗(η)(cid:107) | s(η) ∈ Sk}

3 Lower Bound for Finite Sums Minimization Methods

Having described our analytic approach  we now turn to present some concrete applications  starting
with iteration complexity lower bounds in the context of FSM problems (1). In what follows  we
derive a lower bound on the iteration complexity of oblivious (possibly stochastic) CLI algorithms
equipped with ﬁrst-order and coordinate-descent oracles for FSM. Strictly speaking  we focus on
optimization algorithms equipped with both generalized ﬁrst order oracle 

O(w; A  B  c  j) = A∇fj(w) + Bw + c  A  B ∈ Rd×d  c ∈ Rd  j ∈ [n] 

(10)

and steepest coordinate-descent oracle
O(w; i  j) = w + t∗ei 

t∗ ∈ argmin
t∈R

fj(w1  . . .   wi−1  wi + t  wi+1  . . .   wd)  j ∈ [n] 

(11)

where ei denotes the i’th unit vector. We remark that coordinate-descent steps w.r.t. partial gradients
can be implemented using (10) by setting A to be some principal minor of the unit matrix. It should
be further noted that our results below hold for scenarios where the optimization algorithm is free to
call a different oracle at different iterations.
First  we sketch the proof of the lower bound for deterministic oblivious CLIs. Following Scheme
2.1  we restrict our attention to a parameterized subset of problems. We assume2 d > 1 and denote by
2Clearly  in order to derive a lower bound for coordinate-descent algorithms  we must assume d > 1. If only

a ﬁrst-order oracle is allowed  then the same lower bound as in Theorem 2 can be derived for d = 1.

6

HFSM the set of all (η1  . . .   ηn) ∈ Rn such that all the entries equal −(L − µ)/2  except for some
j ∈ [n]  for which ηj ∈ [−(L − µ)/2  (L − µ)/2]. Now  given η := (η1  . . .   ηn) ∈ HFSM we deﬁne

(cid:18) 1

n(cid:88)

2

i=1

L+µ

2
ηi

Fη(w) :=

Qηi :=

1
n



(cid:19)

w(cid:62)Qηiw − q(cid:62)w

ηi
L+µ

2

µ

...

µ

It is easy to verify that the minimizers of (12) are



w∗(η) =

(cid:16) L+µ

Rµ
2 + 1

n

(cid:80)n

i=1 ηi

(cid:17)  

(cid:16) L+µ

Rµ
2 + 1

n

√

2

√

2

  where

   q :=

(12)



Rµ√
2
Rµ√
2
0

...

 .

0

(cid:62)
(cid:17)   0  . . .   0

(cid:80)n

i=1 ηi

.

(13)

i

We would like to show that the coordinates of the iterates of deterministic oblivious CLIs  which
minimize Fη using ﬁrst-order and coordinate-descent oracles  form multivariate polynomials in η
of total degrees (the maximal sum of powers over all the terms) which does not exceed the iteration
number. Indeed  if the coordinates of w(k)
(η) are multivariate polynomial in η of total degree at
most k  then the coordinates of the vectors returned by both oracles
First-order oracle: O(w(k)
(14)
i − qi/(Qηj )iiei 
Coordinate-descent oracle: O(w(k)
are multivariate polynomials of total degree of at most k + 1  as all the parameters (A  B  C  i and j)
do not depend on η (due to obliviousness) and the rest of the terms (Qηj   q  I  1/(Qηj )ii  (Qηj )i ∗  ei
and qi) are either linear in ηj or constants. Now  since the next iterates are generated simply by
summing up all the oracle answers  they also form multivariate polynomials of total degree of at most
k + 1. Thus  denoting the ﬁrst coordinate of w(k)
1 (η) by s(η) and using Inequality (8)  we get the
following bound

; i  j) =(cid:0)I − (1/(Qηj )ii)ei(Qηj )i ∗(cid:1) w(k)

; A  B  c  j) = A(Qηj w(k)

i − q) + Bw(k)

i + c 

j

j

(cid:107)w(k)

1 (η) − w∗(η)(cid:107) ≥

max
η∈HFSM

(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)L∞([µ L])

(cid:17)

i=1 ηi

√

(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)s(η) −
(cid:16) L+µ
Rµ
(cid:113) κ−1

2 + 1
(cid:113) κ−1
n + 1 − 1
n + 1 + 1

2

n

(cid:80)n
k/n

 

≥ Ω(1)

(15)

(16)

where Ω(1) designates a constant which does not depend on k (but may depend on the problem
parameters). Lastly  this implies that for any deterministic oblivious CLI and any iteration number 
there exists some η ∈ HFSM such that the convergence rate of the algorithm  when applied on Fη 
is bounded from below by Inequality (16). We note that  as opposed to other related lower bounds 
e.g.  [10]  our proof is non-constructive. As discussed in subsection 2.3  this type of analysis can be
extended to stochastic algorithms by considering (15) w.r.t. other norms such as weighted L1-norm.
We now arrive at the following theorem whose proof  including the corresponding logarithmic factors
and constants  can be found in Appendix A.2.
Theorem 2. The iteration complexity of oblivious (possibly stochastic) CLIs for FSM (1) equipped
with ﬁrst-order (10) and coordinate-descent oracles (11)  is bounded from below by

˜Ω(n +(cid:112)n(κ − 1) ln(1/)).

The lower bound stated in Theorem 2 is tight and is attained by  e.g.  SAG combined with an
acceleration scheme (e.g.  [11]). Moreover  as mentioned earlier  our lower bound does not depend
on the problem dimension (or equivalently  holds for any number of iterations  regardless of d and

7

n)  and covers coordinate descent methods with stochastic or deterministic coordinate schedule
(in the special case where n = 1  this gives a lower bound for minimizing smooth and strongly
convex functions by performing steepest coordinate descent steps). Also  our bound implies that
using mini-batches for tackling FSM does not reduce the overall iteration complexity. Lastly  it is
noteworthy that the n term in the lower bound above holds for any algorithm accompanied with an
incremental oracle  which grants access to at most one individual function each time.
We also derive a nearly-optimal lower bound for smooth non-strongly convex functions for the more
restricted setting of n = 1 and ﬁrst-order oracle. The parameterized subset of functions we use
η ∈ (0  L]. The corresponding minimizer (as
(see Scheme 2.1) is gη(x) := η
a function of η) is x∗(η) = Re1  and in this case we seek to approximate it w.r.t. L2-norm using
k-degree univariate polynomials whose constant term vanishes. The resulting bound is dimension-free
and improves upon other bounds for this setting (e.g. [5]) in that it applies to deterministic algorithms 
as well as to stochastic algorithms (see A.3 for proof).
Theorem 3. The iteration complexity of any oblivious (possibly stochastic) CLI for L-smooth convex
functions equipped with a ﬁrst-order oracle  is bounded from below by

2 (cid:107)x(cid:107)2 − Rηe(cid:62)
1 x 

(cid:16)

(L(δ − 2)/)1/δ(cid:17)

Ω

  δ ∈ (2  4).

4 Lower Bound for Dual Regularized Loss Minimization with Linear

Predictors

The form of functions (12) discussed in the previous section does not readily adapt to general RLM
problems with linear predictors  i.e. 

min
w∈Rd

P (w) :=

1
n

φi((cid:104)xi  w(cid:105)) +

(cid:107)w(cid:107)2  

λ
2

(17)

where the loss functions φi are L-smooth and convex  the samples x1  . . .   xn are d-dimensional
vectors in Rd and λ is some positive constant. Thus  dual methods which exploit the added structure
of this setting through the dual problem [18] 

n(cid:88)

i=1

n(cid:88)

i=1

(cid:13)(cid:13)(cid:13)(cid:13)(cid:13) 1

λn

n(cid:88)

i=1

(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)2

min
α∈Rn

D(α) =

1
n

i (−αi) +
φ∗

λ
2

xiαi

 

(18)

such as SDCA and accelerated proximal SDCA  are not covered by Theorem 2. Accordingly  in
this section  we address the iteration complexity of oblivious (possibly stochastic) CLI algorithms
equipped with dual RLM oracles:

O(α; t  j) = α + t∇jD(α)ej 
O(α; j) = α + t∗ej 

t∗ = argmin

t ∈ R  j ∈ [n] 

t∈R

D(α1  . . .   αj−1  αj + t  αj+1  . . .   αd)  j ∈ [n] 

(19)

Following Scheme 2.1  we ﬁrst describe the relevant parametrized subset of RLM problems. For the
sake of simplicity  we assume that n is even (the proof for odd n holds mutatis mutandis). We denote
by HRLM the set of all (ψ1  . . .   ψn/2) ∈ Rn/2 such that all entries are 0  except for some j ∈ [n/2] 
for which ψj ∈ [−π/2  π/2]. Now  given ψ ∈ HRLM  we set Pψ (deﬁned in 17) as follows
i is odd
o.w.

(cid:26)cos(ψ(i+1)/2)ei + sin(ψ(i+1)/2)ei+1

(w + 1)2  xψ i =

φi(w) =

1
2

.

ei

We state below the corresponding lower bound  whose proof  including logarithmic factors and
constants  can be found in Appendix A.4.
Theorem 4. The iteration complexity of oblivious (possibly stochastic) CLIs for RLM (17) equipped
with dual RLM oracles (19) is bounded from below by

˜Ω(n +(cid:112)nL/λ ln(1/)).

This bound is tight w.r.t. the class of oblivious CLIs and is attained by accelerated proximal SDCA. As
mentioned earlier  a tighter lower bound of ˜Ω((n + 1/λ) ln(1/)) is known for SDCA [3]  suggesting
that a tighter bound might hold for the more restricted set of stationary CLIs (for which the oracle
parameters remain ﬁxed throughout the optimization process).

8

,Yossi Arjevani
Ohad Shamir