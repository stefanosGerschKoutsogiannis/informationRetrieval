2009,On Stochastic and Worst-case Models for Investing,In practice  most investing is done assuming a probabilistic model of stock price returns known as the Geometric Brownian Motion (GBM). While it is often an acceptable approximation  the GBM model is not always valid empirically. This motivates a worst-case approach to investing  called universal portfolio management  where the objective is to maximize wealth relative to the wealth earned by the best fixed portfolio in hindsight.  In this paper we tie the two approaches  and design an investment strategy which is universal in the worst-case  and yet capable of exploiting the mostly valid GBM model. Our method is based on new and improved regret bounds for online convex optimization with exp-concave loss functions.,On Stochastic and Worst-case Models for Investing

Elad Hazan

IBM Almaden Research Center

650 Harry Rd  San Jose  CA 95120
ehazan@cs.princeton.edu

Satyen Kale

Yahoo! Research

4301 Great America Parkway  Santa Clara  CA 95054

skale@yahoo-inc.com

Abstract

In practice  most investing is done assuming a probabilistic model of stock price
returns known as the Geometric Brownian Motion (GBM). While often an ac-
ceptable approximation  the GBM model is not always valid empirically. This
motivates a worst-case approach to investing  called universal portfolio manage-
ment  where the objective is to maximize wealth relative to the wealth earned by
the best ﬁxed portfolio in hindsight.
In this paper we tie the two approaches  and design an investment strategy which
is universal in the worst-case  and yet capable of exploiting the mostly valid GBM
model. Our method is based on new and improved regret bounds for online convex
optimization with exp-concave loss functions.

1 Introduction

“Average-case” Investing: Much of mathematical ﬁnance theory is devoted to the modeling of
stock prices and devising investment strategies that maximize wealth gain  minimize risk while doing
so  and so on. Typically  this is done by estimating the parameters in a probabilistic model of stock
prices. Investment strategies are thus geared to such average case models (in the formal computer
science sense)  and are naturally susceptible to drastic deviations from the model  as witnessed in
the recent stock market crash.
Even so  empirically the Geometric Brownian Motion (GBM) ([Osb59  Bac00]) has enjoyed great
predictive success and every year trillions of dollars are traded assuming this model. Black and
Scholes [BS73] used this same model in their Nobel prize winning work on pricing options on
stocks.
“Worst-case” Investing: The fragility of average-case models in the face of rare but dramatic de-
viations led Cover [Cov91] to take a worst-case approach to investing in stocks. The performance
of an online investment algorithm for arbitrary sequences of stock price returns is measured with
respect to the best CRP (constant rebalanced portfolio  see [Cov91]) in hindsight. A universal port-
folio selection algorithm is one that obtains sublinear (in the number of trading periods T ) regret 
which is the difference in the logarithms of the ﬁnal wealths obtained by the two.
Cover [Cov91] gave the ﬁrst universal portfolio selection algorithm with regret bounded by
O(log T ). There has been much follow-up work after Cover’s seminal work  such as [HSSW96 
MF92  KV03  BK97  HKKA06]  which focused on either obtaining alternate universal algorithms
or improving the efﬁciency of Cover’s algorithm. However  the best regret bound is still O(log T ).
This dependence of the regret on the number of trading periods is not entirely satisfactory for two
main reasons. First  a priori it is not clear why the online algorithm should have high regret (growing
with the number of iterations) in an unchanging environment. As an extreme example  consider a
setting with two stocks where one has an “upward drift” of 1% daily  whereas the second stock
remains at the same price. One would expect to “ﬁgure out” this pattern quickly and focus on the

1

ﬁrst stock  thus attaining a constant fraction of the wealth of the best CRP in the long run  i.e.
constant regret  unlike the worst-case bound of O(log T ).
The second problem arises from trading frequency. Suppose we need to invest over a ﬁxed period of
time  say a year. Trading more frequently potentially leads to higher wealth gain  by capitalizing on
short term stock movements. However  increasing trading frequency increases T   and thus one may
expect more regret. The problem is actually even worse: since we measure regret as a difference of
logarithms of the ﬁnal wealths  a regret bound of O(log T ) implies a poly(T ) factor ratio between the
ﬁnal wealths. In reality  however  experiments [AHKS06] show that some known online algorithms
actually improve with increasing trading frequency.
Bridging Worst-case and Average-case Investing: Both these issues are resolved if one can show
that the regret of a “good” online algorithm depends on total variation in the sequence of stock
returns  rather than purely on the number of iterations. If the stock return sequence has low variation 
we expect our algorithm to be able to perform better. If we trade more frequently  then the per
iteration variation should go down correspondingly  so the total variation stays the same.
We analyze a portfolio selection algorithm and prove that its regret is bounded by O(log Q)  where
Q (formally deﬁned in Section 1.2) is the sum of squared deviations of the returns from their mean.
Since Q ≤ T (after appropriate normalization)  we improve over previous regret bounds and retain
the worst-case robustness. Furthermore  in an average-case model such as GBM  the variation can
be tied very nicely to the volatility parameter  which explains the experimental observation the regret
doesn’t increase with increasing trading frequency. Our algorithm is efﬁcient  and its implementa-
tion requires constant time per iteration (independent of the number of game iterations).

1.1 New Techniques and Comparison to Related Work

Cesa-Bianchi  Mansour and Stoltz [CBMS07] initiated work on relating worst case regret to the
variation in the data for the related learning problem of prediction from expert advice  and conjec-
√
tured that the optimal regret bounds should depend on the observed variation of the cost sequence.
Recently  this conjectured was proved and regret bounds of ˜O(
Q) were obtained in the full infor-
mation and bandit linear optimization settings [HK08  HK09]  where Q is the variation in the cost
sequence. In this paper we give an exponential improvement in regret  viz. O(log Q)  for the case
of online exp-concave optimization  which includes portfolio selection as a special case.
Another approach to connecting worst-case to average-case investing was taken by Jamshidian
[Jam92] and Cross and Barron [CB03]. They considered a model of “continuous trading”  where
there are T “trading intervals”  and in each the online investor chooses a ﬁxed portfolio which is
rebalanced k times with k → ∞. They prove familiar regret bounds of O(log T ) (independent of
k) in this model w.r.t. the best ﬁxed portfolio which is rebalanced T × k times. In this model our
algorithm attains the tighter regret bounds of O(log Q)  although our algorithm has more ﬂexibility.
Furthermore their algorithms  being extensions of Cover’s algorithm  may require exponential time
in general1.
√
Our bounds of O(log Q) regret require completely different techniques compared to the ˜O(
Q)
regret bounds of [HK08  HK09]. These previous bounds are based on ﬁrst-order gradient descent
methods which are too weak to obtain O(log Q) regret. Instead we have to use the second-order
Newton step ideas based on [HKKA06] (in particular  the Hessian of the cost functions).
The second-order techniques of [HKKA06] are  however  not sensitive enough to obtain O(log Q)
bounds. This is because progress was measured in terms of the distance between successive portfo-
lios in the usual Euclidean norm  which is insensitive to variation in the cost sequence. In this paper 
we introduce a different analysis technique  based on analyzing the distance between successive
predictions using norms that keep changing from iteration to iteration and are actually sensitive to
the variation.
A key technical step in the analysis is a lemma (Lemma 6) which bounds the sum of differences of
successive Cesaro means of a sequence of vectors by the logarithm of its variation. This lemma 

1Cross and Barron give an efﬁcient implementation for some interesting special cases  under assumptions
on the variation in returns and bounds on the magnitude of the returns  and assuming k → ∞. A truly efﬁcient
implementation of their algorithm can probably be obtained using the techniques of Kalai and Vempala.

2

which may be useful in other contexts when variation bounds on the regret are desired  is proved
using the Kahn-Karush-Tucker conditions  and also improves the regret bounds in previous papers.

1.2 The model and statement of results

∆n = {(cid:80)

Portfolio management. In the universal portfolio management model [Cov91]  an online investor
iteratively distributes her wealth over n assets before observing the change in asset price. In each
iteration t = 1  2  . . . the investor commits to an n-dimensional distribution of her wealth  xt ∈
i xi = 1   x ≥ 0}. She then observes a price relatives vector rt ∈ Rn
+  where rt(i) is
(cid:81)
the ratio between the closing price of the ith asset on trading period t and the opening price. In the
(cid:80)
tth trading period  the wealth of the investor changes by a factor of (rt · xt). The overall change in
t(rt· xt). Since in a typical market wealth grows at an exponential rate  we measure
wealth is thus
(cid:81)
t log(rt · xt). A constant
performance by the exponential growth rate  which is log
rebalanced portfolio (CRP) is an investment strategy which rebalances the wealth in every iteration
t(rt · x).
to keep a ﬁxed distribution. Thus  for a CRP x ∈ ∆n  the change in wealth is
The regret of the investor is deﬁned to be the difference between the exponential growth rate of her
investment strategy and that of the best CRP strategy in hindsight  i.e.

t(rt · xt) =

(cid:81)

(cid:88)

(cid:88)

Regret := max
x∗∈∆n

log(rt · x∗) −

log(rt · xt)

t

t

Note that the regret doesn’t change if we scale all the returns in any particular period by the same
amount. So we assume w.l.o.g. that in all periods t  maxi rt(i) = 1. We assume that there is known
parameter r > 0  such that for all periods t  mint i rt(i) ≥ r. We call r the market variability
parameter. This is the only restriction we put on the stock price returns; they could be chosen
adversarially as long as they respect the market variability bound.
Online convex optimization. In the online convex optimization problem [Zin03]  which generalizes
universal portfolio management  the decision space is a closed  bounded  convex set K ∈ Rn  and
we are sequentially given a series of convex cost2 functions ft : K → R for t = 1  2  . . .. The
algorithm iteratively produces a point xt ∈ K in every round t  without knowledge of ft (but using
the past sequence of cost functions)  and incurs the cost ft(xt). The regret at time T is deﬁned to be

t denote

Usually  we will let
t=1. In this paper  we restrict our attention to convex cost functions
which can be written as ft(x) = g(vt · x) for some univariate convex function g and a parameter
vector vt ∈ Rn (for example  in the portfolio management problem  K = ∆n  ft(x) = − log(rt·x) 
g = − log  and vt = rt).
Thus  the cost functions are parametrized by the vectors v1  v2  . . .   vT . Our bounds will be ex-
pressed as a function of the quadratic variability of the parameter vectors v1  v2  . . .   vT   deﬁned
as

t=1

(cid:107)vt − µ(cid:107)2.

Q(v1  ...  vT ) := min
µ

(cid:80)T
t=1 vt  and thus the quadratic variation is just T − 1 times
This expression is minimized at µ = 1
the sample variance of the sequence of vectors {v1  ...  vt}. Note however that the sequence can be
T
generated adversarially rather than by some stochastic process. We shall refer to this as simply Q if
the vectors are clear from the context.
Main theorem. In the setup of the online convex optimization problem above  we have the following
algorithmic result:
Theorem 1. Let the cost functions be of the form ft(x) = g(vt·x). Assume that there are parameters
R  D  a  b > 0 such that the following conditions hold:

T(cid:88)

2Note the difference from the portfolio selection problem: here we have convex cost functions  rather than

concave payoff functions. The portfolio selection problem is obtained by using − log as the cost function.

3

T(cid:88)

t=1

T(cid:88)

t=1

ft(xt) − min
x∈K

ft(x).

(cid:80)

Regret :=

(cid:80)T

1. for all t  (cid:107)vt(cid:107) ≤ R 
2. for all x ∈ K  we have (cid:107)x(cid:107) ≤ D 
3. for all x ∈ K  and for all t  either g(cid:48)(vt · x) ∈ [0  a] or g(cid:48)(vt · x) ∈ [−a  0]  and
4. for all x ∈ K  and for all t  g(cid:48)(cid:48)(vt · x) ≥ b.

Then there is an algorithm that guarantees the following regret bound:

Regret = O((a2n/b) log(1 + bQ + bR2) + aRD log(2 + Q/R2) + D2).

n since all rt(i) ≤ 1  thus R =

√
eters. We have (cid:107)rt(cid:107) ≤ √
Now we apply Theorem 1 to the portfolio selection problem. First  we estimate the relevant param-
n. For any x ∈ ∆n  (cid:107)x(cid:107) ≤ 1  so D = 1.
(vt·x)2 ≥ 1  so
g(cid:48)(vt · x) = − 1
r . Finally  g(cid:48)(cid:48)(vt · x) = 1
r   0]  so a = 1
b = 1. Applying Theorem 1 we get the following corollary:
Corollary 2. For the portfolio selection problem over n assets  there is an algorithm that attains
the following regret bound:

(vt·x)  and thus g(cid:48)(vt · x) ∈ [− 1

(cid:179) n

(cid:180)
r2 log(Q + n)

.

Regret = O

2 Bounding the Regret by the Observed Variation in Returns

(cid:80)

2.1 Preliminaries
All matrices are assumed be real symmetric matrices in Rn×n  where n is the number of stocks. We
use the notation A (cid:186) B to say that A − B is positive semideﬁnite. We require the notion of a norm
√
of a vector x induced by a positive deﬁnite matrix M  deﬁned as (cid:107)x(cid:107)M =
x(cid:62)M x. The following
simple generalization of the Cauchy-Schwartz inequality is used in the analysis:

∀x  y ∈ Rn :

x · y ≤ (cid:107)x(cid:107)M(cid:107)y(cid:107)M−1.

We denote by |A| the determinant of a matrix A  and by A • B = Tr(AB) =
ij AijBij. As
we are concerned with logarithmic regret bounds  potential functions which behave like harmonic
series come into play. A generalization of harmonic series to high dimensions is the vector-harmonic
series  which is a series of quadratic forms that can be expressed as (here A (cid:194) 0 is a positive deﬁnite
matrix  and v1  v2  . . . are vectors in Rn):
2 (A + v1v(cid:62)
The following lemma is from [HKKA06]:
Lemma 3. For a vector harmonic series given by an initial matrix A and vectors v1  v2  . . .   vT   we
have

1 (A + v1v(cid:62)
v(cid:62)
1 )−1v1  v(cid:62)
T(cid:88)

τ =1vτ v(cid:62)
(cid:35)

2 )−1v2  . . .   v(cid:62)

τ )−1vt  . . .

1 + v2v(cid:62)

(cid:80)T

(cid:80)t

t (A +

(cid:34)

(cid:80)t

|A +

τ |
τ =1 vτ v(cid:62)
|A|

.

v(cid:62)
t (A +

τ =1vτ v(cid:62)

τ )−1vt ≤ log

t=1

The reader can note that in one dimension  if all vectors vt = 1 and A = 1  then the series above
reduces exactly to the regular harmonic series whose sum is bounded  of course  by log(T + 1).

2.2 Algorithm and analysis

We analyze the following algorithm and prove that it attains logarithmic regret with respect to the
observed variation (rather than number of iterations). The algorithm follows the generic algorithmic
scheme of “Follow-The-Regularized-Leader” (FTRL) with squared Euclidean regularization.
Algorithm Exp-Concave-FTL. In iteration t  use the point xt deﬁned as:

(cid:33)

xt (cid:44) arg min
x∈∆n

fτ (x) +

(cid:107)x(cid:107)2

1
2

(1)

(cid:195)

t−1(cid:88)

τ =1

Note the mathematical program which the algorithm solves is convex  and can be solved in time
polynomial in the dimension and number of iterations. The running time  however  for solving this

4

convex program can be quite high.
In the full version of the paper  for the speciﬁc problem of
portfolio selection  where ft(x) = − log(rt · x)  we give a faster implementation whose per itera-
tion running time is independent of the number of iterations  using the more sophisticated “online
Newton method” of [HKKA06]. In particular  we have the following result:
Theorem 4. For the portfolio selection problem  there is an algorithm that runs in O(n3) time per
iteration whose regret is bounded by

(cid:179) n

(cid:180)
r3 log(Q + n)

.

Regret = O

In this paper  we retain the simpler algorithm and analysis for an easier exposition. We now proceed
to prove the Theorem 1.

Proof. [Theorem 1] First  we note that the algorithm is running a “Follow-the-leader” procedure
2(cid:107)x(cid:107)2 is a ﬁctitious period 0 cost function. In
on the cost functions f0  f1  f2  . . . where f0(x) = 1
other words  in each iteration  it chooses the point that would have minimized the total cost under
all the observed functions so far (and  additionally  a ﬁctitious initial cost function f0). This point is
referred to as the leader in that round.
The ﬁrst step in analyzing such an algorithm is to use a stability lemma from [KV05]  which bounds
the regret of any Follow-the-leader algorithm by the difference in costs (under ft) of the current pre-
diction xt and the next one xt+1  plus an additional error term which comes from the regularization.
Thus  we have

Regret ≤ (cid:80)
≤ (cid:80)
(cid:80)

((cid:107)x∗(cid:107)2 − (cid:107)x0(cid:107)2)

1
2 D2

1
tft(xt) − ft(xt+1) +
2
1
t∇ft(xt) · (xt − xt+1) +
2 D2
tg(cid:48)(vt · xt)[vt · (xt − xt+1)] +
(cid:80)t
(cid:80)t
τ =0∇fτ (xt+1) − ∇fτ (xt)
(cid:80)t
τ =1[g(cid:48)
(cid:80)t
τ =1[∇g(cid:48)
τ =1g(cid:48)(cid:48)

τ (vτ · xt+1) − g(cid:48)
τ (vτ · ζ t

τ (vτ · ζ t

=

(2)
The second inequality is because ft is convex. The last equality follows because ∇ft(xt) = g(cid:48)(xt ·
vt)vt. Now  we need a handle on xt − xt+1. For this  deﬁne Ft =
τ =0fτ   and note that xt
minimizes Ft over K. Consider the difference in the gradients of Ft+1 evaluated at xt+1 and xt:

(cid:80)t−1

∇Ft+1(xt+1) − ∇Ft+1(xt) =
=
=
=

τ (vτ · xt)]vτ + (xt+1 − xt)
τ ) · (xt+1 − xt)]vτ + (xt+1 − xt)
τ (xt+1 − xt) + (xt+1 − xt).

(3)
(4)
τ (vτ · x) at
τ on the line segment joining xt and xt+1. The equation (4) follows from
τ (vτ · x) = g(cid:48)(cid:48)

Equation 3 follows by applying the Taylor expansion of the (multi-variate) function g(cid:48)
point xt  for some point ζ t
the observation that ∇g(cid:48)
τ )vtv(cid:62)
Deﬁne At =
equation (4) can be re-written as:

t + I  where I is the identity matrix  and ∆xt = xt+1 − xt. Then

(cid:80)t
τ =1g(cid:48)(cid:48)(vt · ζ t

τ (vτ · x)vτ .

τ )vτ v(cid:62)

∇Ft+1(xt+1) − ∇Ft(xt) − g(cid:48)(vt · xt)vt = At∆xt.

(5)
Now  since xt minimizes the convex function Ft over the convex set K  a standard inequality of
convex optimization (see [BV04]) states that for any point y ∈ K  we have ∇Ft(xt)· (y− xt) ≥ 0.
Thus  for y = xt+1  we get that ∇Ft(xt) · (xt+1 − xt) ≥ 0. Similarly  we get that ∇Ft+1(xt+1) ·
(xt − xt+1) ≥ 0. Putting these two inequalities together  we get that
(∇Ft+1(xt+1) − ∇Ft(xt)) · ∆xt ≤ 0.

(6)

Thus  using the expression for At∆xt from (5) we have

(cid:107)∆xt(cid:107)2

At = At∆xt · ∆xt

= (∇Ft+1(xt+1) − ∇Ft(xt) − g(cid:48)(vt · xt)vt) · ∆xt
≤ g(cid:48)(vt · xt)[vt · (xt − xt+1)]

(from (6))

(7)

5

t+1

g(cid:48)(vt · xt)[vt · (xt − xt+1)] ≤ a(vt · ∆xt).

(cid:80)t
(cid:80)
τ =1vτ . Then  we have
(cid:80)t
t˜vt · ∆xt +

Assume that g(cid:48)(vt · x) ∈ [−a  0] for all x ∈ K and all t. The other case is handled similarly.
Inequality (7) implies that g(cid:48)(vt · xt) and vt · (xt − xt+1) have the same sign. Thus  we can upper
bound
(8)
(cid:80)
Deﬁne ˜vt = vt − µt  µt = 1
tvt · ∆xt =
where ˜vt = vt − µt  µt = 1
Then we bound

(cid:80)T
(cid:80)T−1
t=2xt(µt−1 − µt) − x1µ1 + xT +1µT  
(9)
t=2xt(µt−1 − µt) − x1µ1 + xT +1µT ≤ (cid:80)T
(cid:80)T
t=1 (cid:107)µt+1 − µt(cid:107).
t=2(cid:107)xt(cid:107)(cid:107)µt−1 − µt(cid:107) + (cid:107)x1(cid:107)(cid:107)µ1(cid:107) + (cid:107)xT +1(cid:107)(cid:107)µT(cid:107)
(10)
We will bound ρ momentarily. For now  we turn to bounding the ﬁrst term of (9) using the Cauchy-
Schwartz generalization as follows:

τ =1vt. Now  deﬁne ρ = ρ(v1  . . .   vT ) =

≤ Dρ + 2DR.

t+1

˜vt · ∆xt ≤ (cid:107)˜vt(cid:107)A

−1
t

(cid:107)∆xt(cid:107)At.

(cid:113)(cid:80)

(cid:113)(cid:80)

(cid:113)(cid:80)

(cid:113)(cid:80)

(11)

ta(vt · ∆xt)

(cid:80)
t(cid:107)˜vt(cid:107)A

By the usual Cauchy-Schwartz inequality 

t(cid:107)∆xt(cid:107)2
At
from (7) and (8). We conclude  using (9)  (10) and (11)  that

t(cid:107)˜vt(cid:107)2

−1
t

−1
t

·

A

≤

(cid:107)∆xt(cid:107)At ≤
(cid:80)
ta(vt · ∆xt) ≤ a

(cid:113)(cid:80)

ta(vt · ∆xt) + aDρ + 2aDR.
This implies (using the AM-GM inequality applied to the ﬁrst term on the RHS) that

t(cid:107)˜vt(cid:107)2

−1
t

·

t(cid:107)˜vt(cid:107)2

A

·

−1
t

(cid:113)(cid:80)

−1
t
Plugging this into the regret bound (2) we obtain  via (8) 

A

A

ta(vt · ∆xt) ≤ a2(cid:80)
(cid:80)
Regret ≤ a2(cid:80)
(cid:163)

t(cid:107)˜vt(cid:107)2

A

t(cid:107)˜vt(cid:107)2

+ 2aDρ + 4aDR.

+ 2aDρ + 4aDR +

1
2 D2.

−1
t

τ =1

1 +

−1
t

A

1

τ =s

s=1

r<s

τ =s

1

s

(cid:164)

.

s=1

τ =s

(cid:33)

(cid:33)

b log

1

(τ +1)2

− 1

s +

≤ 3n

˜vτ ˜v(cid:62)

τ =

t(cid:88)

(cid:88)

Now 
vrv(cid:62)

1 + bQ + bR2

τ≤t vτ   we get that

(cid:80)
t(cid:107)˜vt(cid:107)2

(cid:80)
t +I. Since g(cid:48)(cid:48)(vt·ζ t
(cid:195)

The proof is completed by the following two lemmas (Lemmas 5 and 6) which bound the RHS. The
ﬁrst term is a vector harmonic series  and the second term can be bounded by a (regular) harmonic
series.
Lemma 5.

τ )vtv(cid:62)
Proof. We have At =
Using the fact that ˜vt = vt − µt and µt = 1
vsv(cid:62)
s +
s − 1

(cid:80)t
τ =1g(cid:48)(cid:48)(vt·ζ t
(cid:195)
t(cid:88)
t(cid:88)
t(cid:88)
(τ +1)2 ≤ (cid:82) t+1
(cid:80)t
τ (cid:185) t(cid:88)
t(cid:88)
(cid:162)
(cid:161)
s (cid:186) −[vrv(cid:62)
s + vsv(cid:62)
(cid:80)
vsv(cid:62)
vsv(cid:62)
s .
3  we get (cid:88)
(cid:88)
t . Note that the inequality above shows that 3 ˜At (cid:186) At. Thus  using Lemma
t ˜vt˜v(cid:62)

x2 dx = 1
r ]  and hence we have
t+1[vrv(cid:62)
r + vsv(cid:62)
(cid:88)

τ ) ≥ b  we have At (cid:186) I +b
t(cid:88)

t+1 . Since (vr + vs)(vr + vs)(cid:62) (cid:186) 0  we get that

s + vsv(cid:62)
r ].
t(cid:88)

s ] (cid:185) t(cid:88)

s (cid:185) 3
(cid:105)

(cid:80)
tvtv(cid:62)
t .

√
b˜vt](cid:62) ˜A−1
To bound the latter quantity note that | ˜A0| = |I| = 1  and that
t(cid:107)˜vt(cid:107)2

(cid:80)
t | ≤ (1 + b

t ˜vt ≤ 3
(cid:80)

(cid:80)
t (cid:107)˜vt − µt(cid:107)2. Lemma 7 (proved in the full version of the paper)  we
where ˜Q =
show that ˜Q ≤ Q + R2. This implies that | ˜AT| ≤ (1 + bQ + bR2)n and the proof is completed by
substituting this bound into (12).

√
b˜vt] ≤ 3
[

2)n = (1 + b ˜Q)n

| ˜AT| = |I + b

r + vsv(cid:62)
˜vτ ˜v(cid:62)

(cid:104)| ˜AT |

t (cid:107)˜vt(cid:107)2 =

Let ˜At = 1

t(cid:88)

(cid:88)

˜vtA−1

t˜vt˜v(cid:62)

[vrv(cid:62)

(cid:107)˜vt(cid:107)2

(cid:80)

vsv(cid:62)

3 I +b

2 + 1
s

1

(τ +1)2

| ˜A0|

.

1 + 1
s

=

−1
t

A

b log

τ =1

s=1

[

b

t

s +

s=1

r<s

(12)

t

t

s=1

s=1

(cid:161)

(cid:162)

t+1

1

t

6

(cid:176)(cid:176)(cid:176) 1
(cid:176)(cid:176)(cid:176) 1

(cid:107)µt+1 − µt(cid:107) =
=
≤ 1

t+2

t+2

(cid:80)T
τ =1(cid:107)vτ − µT +1(cid:107)2 = R2 + Q.
(cid:80)t
(cid:80)t+1
(cid:80)t+1
(cid:80)t
τ =0vτ − 1
(cid:80)t
τ =0uτ − 1
τ =0uτ
τ =0(cid:107)uτ(cid:107) + 1
t+1(cid:107)ut+1(cid:107)
(cid:180)

(cid:176)(cid:176)(cid:176)
(cid:176)(cid:176)(cid:176)

τ =0vτ

t+1

t+1

≤(cid:80)

t

Lemma 6. ρ(v1  . . .   vT ) ≤ 2R[log(2 + Q/R2) + 1].
Proof. Deﬁne  for τ ≥ 0  the vector uτ = vτ − µT +1. Note that by convention  we have v0 = 0.
We have

(cid:80)T
τ =0(cid:107)uτ(cid:107)2 = (cid:107)µT +1(cid:107)2 +

Furthermore 

Summing up over all iterations 

t(cid:107)µt+1−µt(cid:107) ≤(cid:80)
(cid:80)

t

(t+1)2

(cid:80)t
τ =0(cid:107)uτ(cid:107) + 1

(cid:179)

1

(t+1)2

t+1(cid:107)ut+1(cid:107)

t(cid:107)ut−1(cid:107) ≤ 2R[log(2+Q/R2)+1].
The last inequality follows from Lemma 8 (proved in the full version) below by setting xt =
(cid:107)ut−1(cid:107)/R  for t ≥ 1.
Lemma 7. ˜Q ≤ Q + R2.
Lemma 8. Suppose that 0 ≤ xt ≤ 1 and

(cid:80)T
t=1 xt/t ≤ log(1 + Q) + 1.

t ≤ Q. Then

(cid:80)

t x2

2

3 Implications in the Geometric Brownian Motion Model

We begin with a brief description of the model. The model assumes that stocks can be traded con-
tinuously  and that at any time  the fractional change in the stock price within an inﬁnitesimal time
interval is normally distributed  with mean and variance proportional to the length of the interval.
The randomness is due to many inﬁnitesimal trades that jar the price  much like particles in a physi-
cal medium are jarred about by other particles  leading to the classical Brownian motion.
Formally  the model is parameterized by two quantities  the drift µ  which is the long term trend
of the stock prices  and volatility σ  which characterizes deviations from the long term trend. The
parameter σ is typically speciﬁed as annualized volatility  i.e. the standard deviation of the stock’s
logarithmic returns in one year. Thus  a trading interval of [0  1] speciﬁes 1 year. The model pos-
tulates that the stock price at time t  St  follows a geometric Brownian motion with drift µ and
volatility σ:

dSt = µStdt + σStdWt 

where Wt is a continuous-time stochastic process known as the Wiener process or simply Brownian
motion. The Wiener process is characterized by three facts:

1. W0 = 0 
2. Wt is almost surely continuous  and
3. for any two disjoint time intervals [s1  t1] and [s2  t2]  the random variables Wt1 − Ws1 and
Wt2 − Ws2 are independent zero mean Gaussian random variables with variance t1 − s1
and t2 − s2 respectively.

Using It¯o’s lemma (see  for example  [KS04])  it can be shown that the stock price at time t is given
by

St = S0 exp((µ − σ2/2)t + σWt).

(13)

Now  we consider a situation where we have n stocks in the GBM model. Let µ = (µ1  µ2  . . .   µn)
be the vector of drifts  and σ = (σ1  σ2  . . .   σn) be the vector of (annualized) volatilities. Suppose
we trade for one year. We now study the effect of trading frequency on the quadratic variation
of the stock price returns. For this  assume that the year-long trading interval is sub-divided into
T equally sized intervals of length 1/T   and we trade at the end of each such interval. Let rt =
(rt(1)  rt(2)  . . .   rt(n)) be the vector of stock returns in the tth trading period. We assume that T is
“large enough”  which is taken to mean that it is larger than µ(i)  σ(i)  ( µ(i)

σ(i))2 for any i.

7

Then using the facts of the Wiener process stated above  we can prove the following lemma  which
shows that the expected quadratic variation  and its variance  is the essentially the same regardless
of trading frequency. The proof is a straightforward calculation and deferred to the full version of
this paper.
Lemma 9. In the setup of trading n stocks in the GBM model over one year with T trading periods 
there is a vector v such that

(cid:104)(cid:80)T
(cid:104)(cid:80)T

t=1 (cid:107)rt − v(cid:107)2
t=1 (cid:107)rt − v(cid:107)2

(cid:105)
(cid:105)

and

E

VAR

≤ (cid:107)σ(cid:107)2(1 + O( 1

T ))

≤ 6(cid:107)σ(cid:107)2(1 + O( 1

T )) 

regardless of how the stocks are correlated.

Applying this bound in our algorithm  we obtain the following regret bound from Corollary 2.
Theorem 10. In the setup of Lemma 9  for any δ > 0  with probability at least 1 − 2e−δ  we have

Regret ≤ O(n(log((cid:107)σ(cid:107)2 + n) + δ)).

Theorem 10 shows that one expects to achieve constant regret independent of the trading frequency 
as long as the total trading period is ﬁxed. This result is only useful if increasing trading frequency
improves the performance of the best constant rebalanced portfolio. Indeed  this has been observed
empirically (see e.g. [AHKS06]  and more empirical evidence is given in the full version of this
paper.).
To obtain a theoretical justiﬁcation for increasing trading frequency  we consider an example where
we have two stocks that follow independent Black-Scholes models with the same drifts  but different
volatilities σ1  σ2. The same drift assumption is necessary because in the long run  the best CRP is
the one that puts all its wealth on the stock with the greater drift. We normalize the drifts to be equal
to 0  this doesn’t change the performance in any qualitative manner.
Since the drift is 0  the expected return of either stock in any trading period is 1; and since the
returns in each period are independent  the expected ﬁnal change in wealth  which is the product
of the returns  is also 1. Thus  in expectation  any CRP (indeed  any portfolio selection strategy)
has overall return 1. We therefore turn to a different criterion for selecting a CRP. The risk of an
investment strategy is measured by the variance of its payoff; thus  if different investment strategies
have the same expected payoff  then the one to choose is the one with minimum variance. We
therefore choose the CRP with the least variance. We prove the following lemma in the full version
of the paper:
Lemma 11. In the setup where we trade two stocks with zero drift and volatilities σ1  σ2  the vari-
ance of the minimum variance CRP decreases as the trading frequency increases.

Thus  increasing the trading frequency decreases the variance of the minimum variance CRP  which
implies that it gets less risky to trade more frequently; in other words  the more frequently we trade 
the more likely the payoff will be close to the expected value. On the other hand  as we show
in Theorem 10  the regret does not change even if we trade more often; thus  one expects to see
improving performance of our algorithm as the trading frequency increases.

4 Conclusions and Future Work

We have presented an efﬁcient algorithm for regret minimization with exp-concave loss functions
whose regret strictly improves upon the state of the art. For the problem of portfolio selection 
the regret is bounded in terms of the observed variation in stock returns rather than the number of
iterations.
Recently  DeMarzo  Kremer and Mansour [DKM06] presented a novel game-theoretic framework
for option pricing. Their method prices options using low regret algorithms  and it is possible that
our analysis can be applied to options pricing via their method (although that would require a much
tighter optimization of the constants involved).
Increasing trading frequency in practice means increasing transaction costs. We have assumed no
transaction costs in this paper. It would be very interesting to extend our portfolio selection algorithm
to take into account transaction costs as in the work of Blum and Kalai [BK97].

8

[BK97]

[BS73]

[BV04]

[CB03]

[Bac00]

References
[AHKS06] Amit Agarwal  Elad Hazan  Satyen Kale  and Robert E. Schapire. Algorithms for port-

folio management based on the newton method. In ICML  pages 9–16  2006.
L. Bachelier. Th´eorie de la sp´eculation. Annales Scientiﬁques de l’ ´Ecole Normale
Sup´erieure  3(17):21–86  1900.
Avrim Blum and Adam Kalai. Universal portfolios with and without transaction costs.
In COLT  pages 309–313  New York  NY  USA  1997. ACM.
Fischer Black and Myron Scholes. The pricing of options and corporate liabilities.
Journal of Political Economy  81(3):637–654  1973.
Stephen Boyd and Lieven Vandenberghe. Convex Optimization. Cambridge University
Press  New York  NY  USA  2004.
Jason E Cross and Andrew R Barron. Efﬁcient universal portfolios for past dependent
target classes. Mathematical Finance  13(2):245–276  2003.
[CBMS07] Nicol`o Cesa-Bianchi  Yishay Mansour  and Gilles Stoltz.

Improved second-order

bounds for prediction with expert advice. Mach. Learn.  66(2-3):321–352  2007.
T. Cover. Universal portfolios. Math. Finance  1:1–19  1991.

[Cov91]
[DKM06] Peter DeMarzo  Ilan Kremer  and Yishay Mansour. Online trading algorithms and ro-
bust option pricing. In STOC ’06: Proceedings of the thirty-eighth annual ACM sym-
posium on Theory of computing  pages 477–486  New York  NY  USA  2006. ACM.
Elad Hazan and Satyen Kale. Extracting certainty from uncertainty: Regret bounded
by variation in costs. In Proceedings of 21st COLT  2008.
Elad Hazan and Satyen Kale. Better algorithms for benign bandits. In SODA  pages
38–47  Philadelphia  PA  USA  2009. Society for Industrial and Applied Mathematics.
[HKKA06] Elad Hazan  Adam Kalai  Satyen Kale  and Amit Agarwal. Logarithmic regret algo-

[HK08]

[HK09]

rithms for online convex optimization. In COLT  pages 499–513  2006.

[HSSW96] David P. Helmbold  Robert E. Schapire  Yoram Singer  and Manfred K. Warmuth. On-

line portfolio selection using multiplicative updates. In ICML  pages 243–251  1996.
F. Jamshidian. Asymptotically optimal portfolios. Mathematical Finance  2:131–150 
1992.
Ioannis Karatzas and Steven E. Shreve. Brownian Motion and Stochastic Calculus.
Springer Verlag  New York  NY  USA  2004.
Adam Kalai and Santosh Vempala. Efﬁcient algorithms for universal portfolios. J.
Mach. Learn. Res.  3:423–440  2003.
Adam Kalai and Santosh Vempala. Efﬁcient algorithms for online decision problems.
Journal of Computer and System Sciences  71(3):291–307  2005.
Neri Merhav and Meir Feder. Universal sequential learning and decision from individ-
ual data sequences. In COLT  pages 413–427  1992.

[Osb59] M. F. M. Osborne. Brownian motion in the stock market. Operations Research  2:145–

173  1959.
Martin Zinkevich. Online convex programming and generalized inﬁnitesimal gradient
ascent. In ICML  pages 928–936  2003.

[Jam92]

[KS04]

[KV03]

[KV05]

[MF92]

[Zin03]

9

,Ferran Diego Andilla
Fred Hamprecht