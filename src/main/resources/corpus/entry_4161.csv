2019,Optimizing Generalized Rate Metrics with Three Players,We present a general framework for solving a large class of learning problems with non-linear functions of classification rates. This includes problems where one wishes to optimize a non-decomposable performance metric such as the F-measure or G-mean  and constrained training problems where the classifier needs to satisfy non-linear rate constraints such as predictive parity fairness  distribution divergences or churn ratios. We extend previous two-player game approaches for constrained optimization to an approach with three players to decouple the classifier rates from the non-linear objective  and seek to find an equilibrium of the game. Our approach generalizes many existing algorithms  and makes possible new algorithms with more flexibility and tighter handling of non-linear rate constraints. We provide convergence guarantees for convex functions of rates  and show how our methodology can be extended to handle sums-of-ratios of rates. Experiments on different fairness tasks confirm the efficacy of our approach.,Optimizing Generalized Rate Metrics with

Three Players

Harikrishna Narasimhan  Andrew Cotter  Maya Gupta

Google Research

1600 Amphitheatre Pkwy  Mountain View  CA 94043

{hnarasimhan  acotter  mayagupta}@google.com

Abstract

We present a general framework for solving a large class of learning problems
with non-linear functions of classiﬁcation rates. This includes problems where
one wishes to optimize a non-decomposable performance metric such as the F-
measure or G-mean  and constrained training problems where the classiﬁer needs
to satisfy non-linear rate constraints such as predictive parity fairness  distribution
divergences or churn ratios. We extend previous two-player game approaches
for constrained optimization to an approach with three players to decouple the
classiﬁer rates from the non-linear objective  and seek to ﬁnd an equilibrium of the
game. Our approach generalizes many existing algorithms  and makes possible new
algorithms with more ﬂexibility and tighter handling of non-linear rate constraints.
We provide convergence guarantees for convex functions of rates  and show how
our methodology can be extended to handle sums-of-ratios of rates. Experiments
on different fairness tasks conﬁrm the efﬁcacy of our approach.

1

Introduction

In many real-world machine learning problems  the performance measures used to evaluate a clas-
siﬁcation model are non-linear functions of the classiﬁer’s prediction rates. Examples include the
F-measure and G-mean used in class-imbalanced classiﬁcation tasks [1–5]  metrics such as predictive
parity used to impose fairness goals [6]  the win-loss-ratio used to measure classiﬁer churn [7] 
KL-divergence based metrics used in quantiﬁcation tasks [8  9] and score-based metrics such as the
PR-AUC [10]. Because these goals are non-linear and are non-continuous in the model parameters  it
becomes very challenging to optimize with them  especially when they are used in constraints [11].
Prior work on optimizing generalized rate metrics has largely focused on unconstrained learning
problems. These approaches fall under two broad categories: surrogate-based methods that replace
the classiﬁer rates with convex relaxations [12–17]  and oracle-based methods that formulate multiple
cost-sensitive learning tasks  and solve them using an oracle [18–22  11]. Both these approaches
have notable deﬁciencies. The ﬁrst category of methods rely crucially on the surrogates being close
approximations to the rate metric  and perform poorly when this is not the case (see e.g. experiments
in [20]). The use of surrogates becomes particularly problematic with constrained training problems 
as relaxing the constraints with convex upper bounds can result in solutions that are over-constrained
or infeasible [23]. The second category of methods assume access to a near-optimal cost-sensitive
oracle  which is usually unrealistic in practice.
In this paper  we present a three-player approach for learning problems where both the objective
and constraints can be deﬁned by general functions of rates. The three players optimize over model
parameters  Lagrange multipliers and slack variables to produce a game equilibrium. Our approach
generalizes many existing algorithms (see Table 2)  and makes possible new algorithms with more
ﬂexibility and tighter handling of non-linear rate constraints. Speciﬁcally  we give a new method

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

(Algorithm 2) that can handle a wider range of performance metrics than previous surrogate methods
(such as e.g. KL-divergence based metrics that only take inputs from a restricted range)  and can be
applied to constrained training problems without the risk of over-constraining the model because it
needs to use surrogates less. To our knowledge  this is the ﬁrst practical  surrogate-based approach
that can handle constraints on generalized rate metrics.
We show convergence of our algorithms for objectives and constraints that are convex functions of
rates. This result builds on previous work by Cotter et al. [23  24] for handling linear rate constraints 
and additionally resolves an unanswered question in their work on the convergence of Lagrangian
optimizers for non-zero-sum games. We also extend our framework to develop a heuristic (Algorithm
3) for optimizing performance measures that are a sum-of-ratios of rates (e.g. constraints on predictive
parity and F-measure)  and demonstrate their utility on real-world tasks.
Related work: Many fairness goals can be expressed as linear constraints on a model’s prediction
rates [16  25]. Recent work has focused on optimizing with linear rate constraints by computing an
equilibrium of a game between players who optimize model parameters ✓ and Lagrange multipliers
 [26–28  23  24]. Of these  the closest to us is the work of Cotter et al. (2019) [23]  who propose
the idea of having only the ✓-player optimize a surrogate objective  and having the -player use the
original rates. We adapt and build on this idea to handle general functions of rates. Other game-based
formulations include the approach of Wang et al. [29] for optimizing multivariate evaluation metrics.
Their setup is very different from ours  with their players optimizing over (distributions on) all
possible labelings of the data. Moreover  they do not handle constraints on the classiﬁer.
There has also been a concentrated effort on optimizing performance measures such as the F-measure
that are fractional-linear functions of rates [18–20  30  31]. Many of these works exploit the pseudo-
convex structure of the F-measure  but this property is absent for the problems that we consider where
we need to handle sums or differences of ratios. Pan et al. [32] provide a heuristic approach for
unconstrained sums-of-ratios  and recently Celis et al. [33] handle constraints that are sums-of-ratios 
but do so by solving a large number of linearly constrained sub-problems  with the number of
sub-problems growing exponentially with the number of rates. In contrast  we provide a practical
algorithm that handles both objectives and constraints that are sums-of-ratios of rates.

2 Problem Setup
Let X✓ Rd and Y = {±1} be the instance and label spaces. Let f✓ : X! R be a prediction model 
parameterized by ✓ 2 ⇥. Given a distribution D over X⇥Y   we deﬁne the model’s rate on D as:

R(✓; D) = E(X Y )⇠D⇥IY = sign(f✓(X)) ⇤ .

For example  if DA denotes the distribution over a sub-population A ✓ X  then R(✓; DA) gives
us the accuracy of f✓ on this sub-population. If D+ denotes a conditional distribution over the
positively-labeled examples  then R(✓; D+) is the true-positive rate TPR(✓) of f✓ and 1  R(✓; D+)
is the false-negative rate FNR(✓) of f✓. Similarly  if D denotes a conditional distribution over
the negatively-labeled examples  then TNR(✓) = R(✓; D) is the true-negative rate of f✓  and
FPR(✓) = 1  R(✓; D) is the false-positive rate of f✓. Further  the true-positive and false-positive
proportions are given by TP(✓) = p TPR(✓) and FP(✓) = (1  p) FPR(✓)  where p = P(Y = 1);
we can similarly deﬁne the true negative proportion TN and false negative proportion FN.
We will consider several distributions D1  . . .   DK over X⇥Y   and use the short-hand Rk(✓)
to denote the rate function R(✓; Dk) 2 [0  1]. We will denote a vector of K rates as: R(✓) =
[R1(✓)  . . .   RK(✓)]>. We assume we have access to unbiased estimates of the rates ˆRk(✓) =
nkPnk
nk )}⇠ Dk.
1
We will also consider stochastic models which are deﬁned by distributions over the model parameters
⇥. Let ⇥ denote the set of all such distributions over ⇥  where for any µ 2 ⇥  µ(✓) is the
probability mass on model ✓. We deﬁne the rate Rk for a stochastic model µ to be the expected value
for random draw of a model from µ  so Rk(µ) = E✓⇠µ [Rk(✓)].
Generalized Rate Metrics as Objective. In many real-world applications the performance of a
model is evaluated by a function of multiple rates: (R1(✓)  . . .   RK(✓)) for some : [0  1]K ! R.
For example  a common evaluation metric used in class-imbalanced classiﬁcation tasks is the G-mean:
GM(✓) = 1 pTPR(✓) TNR(✓)  which is a convex function of rates [34  35]. Similarly  a popular

i ))   computed from samples S = {(xk

i=1 Iyk

i = sign(f✓(xk

1  yk

1 )  . . .   (xk

nk   yk

2

Table 1: Examples of generalized rate metrics. is either convex (C)  pseudo-convex (PC) or a sum
or difference of ratios (SR). p = P(Y = 1) and ˆp is the predicted proportion of positives. wins
(losses) is the fraction of correct (wrong) predictions by the new model among examples where it
disagrees with the old model. A and B refer to different protected groups or slices of the population.

Measure
G-mean [34  35]
H-mean [36]
Q-mean [5]
KLD [8  9]
F-measure [37]
Predictive parity [6]
F-measure parity
Churn [7]

PR-AUC [10]

Deﬁnition

2

1/TPR+1/TNR

1  pTPR ⇥ TNR
1 
1 pFPR2 + FNR2
ˆp ) + (1  p)log( 1p
p log( p
1ˆp )
1 
TPA

2TP + FP + FN
TPB

2TP

TPB+FNB
2TPB
2TPB+FPB+FNB

winsA

TPA+FNA 
2TPA
2TPA+FPA+FNA 
lossesA  winsB
MPM
1  1

m=1

lossesB

p log( p
z1

 

2

1  pz1 z2
1 
1/z1+1/z2
1 pz2
1 + z2
2
) + (1  p)log( 1p
1 
z1+z2  z3
z2  z3

2z1+z2+z3

2z4+z5+z6

z3+z4

2z4

2z1

z1

z2

z1

z4

)

Type

C
C
C
C
PC
SR
SR
SR

2z1

2z1+z2+z3 

TPm

TPm+FPm

  where TPm  FPm are evaluated

at the largest threshold ⌧ at which recall of f✓(X) + ⌧ is  m+0.5

M

evaluation metric used in text retrieval is the F-measure: F1(✓) =
2TP(✓) + FP(✓) + FN(✓)  which is a
fractional-linear or pseudo-convex function of rates [38]. See Table 1 for more examples. One can
consider directly optimizing these performance measures during training:

2TP(✓)

 (R1(✓)  . . .   RK(✓)) .

min
✓2⇥

(P1)



TPA(✓)

TPB(✓)

Generalized Rate Metrics as Constraints. There are also many applications  where one wishes
to impose constraints deﬁned by non-linear function of rates  for example to ensure group-
speciﬁc fairness metrics. Examples include: (i) Predictive parity fairness: Fair classiﬁcation
tasks where one wishes to match the precision of a model across different protected groups [6]:
TPA(✓) + FPA(✓) 
across different groups. (ii) Distribution matching: Fairness or quantiﬁcation tasks where one wishes
to match the distribution of a model’s outputs across different protected groups [9  15]. One way to
achieve this is to constrain the KL-divergence between the overall class proportion p and proportion
of predicted positives for each group ˆpA [11]  i.e. to enforce KLD(p  ˆpA)  ✏  where KLD is convex
in ˆpA. (iii) Churn: Problems where one wishes to replace a legacy model with a more accurate model
while limiting the changed predictions between the new and old models (possibly across different
slices of the user base). This is ideally framed as constraints on the win-loss ratio’s [24]  which can
be expressed as ratios of rates [7]. These and related problems can be framed generally as:

TPB(✓) + FPB(✓)  ✏. One may also want to match e.g. the F-measure of a model

(P2)
for some objective function g :⇥ ! R  and J constraint functions j : [0  1]K ! R. We also
consider a special case of (P2) with an objective and a constraint that is a sum-of-ratios of rates:

s.t. j (R1(✓)  . . .   RK(✓))  0  8j 2 [J] 

min
✓2⇥

g(✓)

s.t.

(P3)

min
✓2⇥

h↵m  R(✓)i
hm  R(✓)i   

2MXm=M +1
MXm=1
h↵m  R(✓)i
hm  R(✓)i
for coefﬁcients ↵m  m 2 RK
+   8m 2 [2M ] and slack  2 R.
Our setup can also be used to optimize score-based metrics  such as the area under the precision-
recall curve (PR-AUC)  that summarize the performance of a score model f✓ : X! R across
multiple thresholds. We use the approach of Eban et al. [10] to (approximately) express PR-AUC as
a Riemann summation of the precision of f✓ at thresholds ⌧1  . . .  ⌧ M 2 R at which the recall of f✓
is 0.5
M resp. This results in a formulation similar to (P3). See Appendix E for details.
We next provide a three-player framework for solving (P1)–(P3). We note that our formulations can be
equivalently regarded as two-player games where one player is in charge of the parameters that need
to be minimized  and the other player is in charge of the parameters that need to be maximized. We
however ﬁnd the three-player viewpoint to be a useful way to think about the problem algorithmically
in that the three sets of optimization parameters can use different algorithms (see Table 2).

M   . . .   M0.5

M   1.5

3

Table 2: Algorithms for (P1)–(P3) with 3 players. Frank-Wolfe [20]  SPADE [14]  NEMSIS [15] are
previous algorithms. Alg. 1–3 are the proposed methods. Each player can do Best Response (BR) 
Online Gradient Descent (OGD) or Follow-The-Leader (FTL)  and the game is zero-sum (ZS) or not.
The ﬁrst ﬁve algorithms ﬁnd an approximate Nash or Coarse-Correlated (C.C.) equilibrium assuming
 and j’s are convex. Since (P3) is non-convex in the rates  Alg. 3 may not ﬁnd an equilibrium.

Alg.
F-W
SPADE
NEMSIS
Alg. 1
Alg. 2
Alg. 3

P
⇠
-
P1
P1
L1
-
P1
P1-2 L1
P1-2 L1
P3
L1

✓



Player Objective


 min
⇠ L1(⇠;·) + L2(✓;·) L2
FTL
˜L2
OGD OGD 3
 min
⇠ L1(⇠;·) + ˜L2(✓;·)
˜L2
FTL OGD 3
OGD
BR
3
L2
˜L2
OGD OGD
7
˜L2 OGD OGD OGD
7

Player Strategy
✓
⇠
-
BR
BR
-
BR
BR

L1 + L2
L1 + L2
L1 + L2

L1 + ˜L2

ZS Equil
Nash
3
Nash
Nash
Nash
C. C.

-

3 Generalized Rate Metric Objective

We ﬁrst present algorithms for the unconstrained problem in (P1). We assume is strictly convex 
and is L-Lispchitz w.r.t. the `1-norm. For simplicity  we assume that is monotonically increasing
in all arguments and that r (0) = 0  although our approach easily extends to more general metrics
that are e.g. monotonically increasing in some arguments and monotonically decreasing in others.
Game Formulation. We equivalently re-write (P1) to de-couple the rates Rk from the non-linear
function by introducing auxiliary variables ⇠1  . . .  ⇠ K 2 [0  1]:

min

✓2⇥ ⇠ 2[0 1]K

 (⇠1  . . .  ⇠ K) s.t. Rk(✓)  ⇠k  8k 2 [K].

(1)

A standard approach for solving (1) is to write the Lagrangian for the problem with Lagrange
multipliers 1  . . .   K 2 R+ for the K constraints:

L(✓  ⇠; ) = (⇠) +

k (Rk(✓)  ⇠k) = (⇠) 

k⇠k

+

k Rk(✓)

.

Then one maximizes the Lagrangian over  2 RK

KXk=1

max
2RK

+

min
✓2⇥
⇠2[0 1]K

KXk=1
{z

KXk=1
|

|

L1(⇠;)

}
+   and minimizes it over ✓ 2 ⇥ and ⇠ 2 [0  1]K:
L1(⇠; ) + L2(✓; ) 

{z

L2(✓;)

}

(2)

Notice that L1 is convex in ⇠ (by convexity of )  while L1 and L2 are linear in . We pose this
max-min problem as a zero-sum game played with three players: a player who minimizes L1 + L2
over ✓  a player who minimizes L1 + L2 over ⇠  and a player who maximizes L1 + L2 over . Each
of the three players can now use different optimization algorithms customized for their problem. If
additionally the Lagrangian was convex in ✓  one could solve for an equilibrium of this game and
obtain a solution for the primal problem (1). However  since L2 is a weighted sum of rates Rk(✓)  it
need not be convex (or even continuous) in ✓.
To overcome this difﬁculty  we expand the solution space from deterministic models ⇥ to stochastic
models ⇥ [26  23  24  39]  and re-formulate (2) as a problem that is linear in µ  by replacing each
Rk(✓) with E✓⇠µ[Rk(✓)] in L2:

(3)

max
2⇤

min
µ2⇥
⇠2[0 1]K

L1(⇠; ) + L2(µ; ).

Here for technical reasons  we restrict the Lagrange multipliers to a bounded set ⇤= { 2
R+ |k k1  }; we will choose the radius > 0 later in our theoretical analysis. By solving
for an equilibrium of this expanded max-min problem  we can ﬁnd a stochastic model µ 2 ✓ that
minimizes (R1(µ)  . . .   RK(µ)).

4

k=1 k ˜Rk(✓).

There are two approaches that we can take to ﬁnd an equilibrium of the expanded game. The ﬁrst
approach is to assume access to an oracle that can perform the minimization of L2 over µ for a ﬁxed 
and ⇠. Since this is a linear optimization over the simplex  this amounts to performing a minimization
over deterministic models in ⇥. The second and more realistic approach is to work with surrogates
for the rates that are continuous and differentiable in ✓. Let ˜R1  . . .   ˜RK :⇥ ! R be differentiable
convex surrogate functions that are upper bounds on the rates: Rk(✓)  ˜Rk(✓)  8✓ 2 ⇥. We assume
access to unbiased stochastic sub-gradients for the surrogates r✓ ˜Rk(✓) with E[r✓ ˜Rk(✓)] 2 @✓ ˜Rk(✓).
We then deﬁne a surrogate-based approximation for L2:
˜L2(✓; ) = PK
(4)

All we need to do now is to choose the objective that each player seeks to optimize (true or surrogate
[23]) and the strategy that they use to optimize their objective  so that the players converge to an
equilibrium of the game. Each of these choices lead to a different algorithm for (approximately)
solving (P1). Table 2 summarizes different choices of strategies and objectives for the players  and
the type of equilibrium and the algorithm that results from these choices. As we shall see shortly (and
also elaborate in Appendix B.1)  many existing algorithms can be seen as instances of this template.
Oracle-based Lagrangian Optimizer. As a warm-up illustration of our approach  we ﬁrst describe
an idealized algorithm assuming access to an oracle that can approximately optimize L2 over ⇥ (this
oracle essentially optimizes a weighted-sum of rates  i.e. a cost-sensitive error objective [40]):
Deﬁnition 1. A ⇢-approximate cost-sensitive optimization (CSO) oracle takes  as input and outputs
a model ✓⇤ 2 ⇥ such that L2(✓⇤; )  min✓2⇥ L2(✓; ) + ⇢.
We have all three players optimize the true Lagrangians  with the ✓-player and ⇠-player playing best
responses to the opponents strategies  i.e. they perform full optimization over their parameter space 
and the -player running online gradient descent (OGD)  an algorithm with no-regret guarantees [41].
The ✓-player performs best response by using the above oracle to approximately minimize L2 over ✓.
For the ⇠-player  the best response optimization can be computed in closed-form:
Lemma 1. Let ⇤ : RK

+ ! R denote the Fenchel conjugate of . Then for any  s.t. kk1  L:

r ⇤() 2 argmin⇠2[0 1]K L1(⇠; ).

.The resulting algorithm outlined in Algorithm 1 is guaranteed to ﬁnd an approximate Nash equilibrium
of the max-min game in (3)  and yields an approximate solution to (P1):
Theorem 1. Let ✓1  . . .  ✓ T be the iterates generated by Algorithm 1 for (P1)  and let ¯µ be a stochastic
model with a probability mass of 1
T on ✓t. Deﬁne B  maxt krL(⇠t ✓ t; t)k2. Then setting
 = L and ⌘ = L

Bp2T

  we have w.p.  1   over draws of stochastic gradients:
◆ + ⇢.

 (R(µ)) + O✓r log(1/)

 (R(¯µ))  min
µ2⇥

T

Remark 1 (Frank-Wolfe: a special case). A previous oracle-based approach for optimizing convex
functions of rates is the Frank-Wolfe based method of Narasimhan et al. [14]. This method can be
recovered from our framework by reformulating the -player’s objective to include the minimization
over ⇠: LFW(  ✓) = min⇠ L1(⇠; ) +L2(✓; ) and having the -player play the Follow-The-Leader
(FTL) algorithm [42] to maximize this objective over . As before  the ✓-player plays best response
on L2 using the CSO oracle. See Appendix B.1 for details  where we use recent connections between
the classical Frank-Wolfe technique and equilibrium computation [43].

Surrogate-based Lagrangian Optimizer. While the CSO oracle may be available in some special
cases (e.g. when ⇥ is ﬁnite or when the underlying conditional-class probabilities can be estimated
accurately)  in many practical scenarios  it is not realistic to assume access to an oracle that can
optimize non-continuous rates. We now provide a more practical algorithm for solving (P1) where
the ✓-player optimizes the surrogate Lagrangian function ˜L2 in (4) instead of L2 using stochastic
gradients r✓ ˜L2(✓; ). The ⇠- and -players  however  continue to operate on the true Lagrangian
functions L1 and L2  which are continuous in the parameters ⇠ and  that these players optimize.
In our proposed approach  outlined in Algorithm 2  both the ✓-player and -player now run online
gradient descent algorithms  while the ⇠-player plays its best response at each iteration. Since it is

5

Algorithm 1 Oracle-based Optimizer

Algorithm 2 Surrogate-based Optimizer

if (P1) then

Initialize: 0
for t = 0 to T  1 do
⇠t = r ⇤(t)
else if (P2) then
⇠t 2 argmin⇠2[0 1]K L1(⇠; t)

end if
✓t 2 argmin✓2⇥ L2(✓; t)

t+1 =⇧ ⇤t + ⌘ r L(✓t ⇠ t; t)

end for
return ✓1  . . .  ✓ T

[CSO]

if (P1) then

Initialize: ✓0  0
for t = 0 to T  1 do
⇠t = r ⇤(t)
else if (P2) then
⇠t 2 argmin⇠2[0 1]K L1(⇠; t)
end if
✓t+1 ⇧⇥(✓t  ⌘✓ r✓ ˜L2(✓t; t))
t+1 ⇧⇤(t + ⌘ rL(✓t ⇠ t; t))
end for
return ✓1  . . .  ✓ T

k=1( ˆRk(✓t)  ⇠t

Figure 1: Optimizers for the unconstrained problem (P1) and constrained problem (P2). Here ⇧⇤
denotes the `1-projection onto ⇤ and ⇧⇥ denotes the `2-projection onto ⇥. We denote a (stochastic)
k)  where ˆRk(✓t) is an unbiased estimate of

gradient of L by rL(✓t ⇠ t; t) = PK
Rk(✓t). We denote a (stochastic) sub-gradient of ˜L2 by r✓ ˜L2(✓t; t) = PK

the ✓-player alone who optimizes a surrogate  the resulting game between the three players is no
longer zero-sum. Yet  we are able to show that the player strategies converge to an approximate
coarse-correlated (C. C.) equilibrium of the game  and yields an approximate solution to (P1).
Theorem 2. Let ✓1  . . .  ✓ T be the iterates of Algorithm 2 for (P1)  and let ¯µ be a stochastic model
T on ✓t. Let ˜⇥ be a convex set and ˜⇥= ✓ 2 ⇥| ˜R(✓) 2 [0  1]K . Let
with probability 1
B⇥  max✓2⇥ k✓k2  B✓  maxt kr✓ ˜L2(✓t; t)k2 and B  maxt krL(⇠t ✓ t; t)k2. Setting
 = L  ⌘✓ = B⇥
  we have w.p.  1   over draws of stochastic gradients:
B✓pT

k=1 k r✓ ˜Rk(✓t).

and ⌘ = L

Bp2T

 R(¯µ)  min

✓2 ˜⇥

◆.

  ˜R(✓) + O✓r log(1/)

T

Note the right-hand side contains the optimal value for the surrogate objective ( ˜R(·)) and not for
the original performance metric. This is unsurprising given the ✓-player’s inability to work with
the true rates. Also  while Algorithm 2 can be applied to optimize over a general (bounded) convex
model class ⇥  the comparator for our guarantee is a subset of models ˜⇥ ✓ ⇥ for which ( ˜R(✓)) is
deﬁned. This is needed as the surrogate ˜R(✓) may output values outside the domain of .
Remark 2 (SPADE  NEMSIS: special cases of our approach). Our approach includes two previ-
ous surrogate-based algorithms as special cases: SPADE [20] and NEMSIS [15]. SPADE can be
recovered from our framework by having the same player strategies as Algorithm 2 but with both
the ✓- and -players optimizing surrogate objectives  i.e. with the ✓-player minimizing ˜L2 and the
-player maximizing L1 + ˜L2. NEMSIS also uses surrogates for both the ✓ and  updates. It can be
recovered by having the ✓-player run OGD on ˜L2  and having the -player play FTL over  on the
combined objective min⇠ L1(⇠; ) + ˜L2(✓; ). See Appendix B.1 for details.
Remark 3 (Application to wider range of metrics). Because of their strong reliance on surrogates 
SPADE and NEMSIS cannot be applied directly to functions that take inputs from a restricted range
(e.g. KL-divergence)  unless the surrogates are also bounded in the same range. In Appendix D.1 
we point out scenarios where the NEMSIS method [15] fails to optimize the KL-divergence metric 
unless the model is sufﬁciently regularized to not output large negative values. Algorithm 2 has no
such restriction and can be applied even if the outputs of the surrogates are not within the domain of
 . This is because it uses the original rates for updates on . As a result  the game play between ⇠
and  never produces values that are outside the domain of .

4 Generalized Rate Metric Constraints

We next describe how to apply our approach to the constrained optimization problem in (P2) and
to the special case in (P3). We start with (P2) assuming that the constraints j’s are jointly convex 

6

monotonic in each argument and L-Lipschitz w.r.t. the `1-norm  and g is a bounded convex function.
For convenience  we assume that the j’s are monotonically increasing in all arguments. Constraints
on the KL-divergence and G-mean metrics are examples of this setting.
We introduce a set auxiliary variables ⇠1  . . .  ⇠ K for the K rate functions and re-write (P2) as:

min

g(✓)

✓2⇥ ⇠ 2[0 1]K

s.t. j (⇠1  . . .  ⇠ K)  0  8j 2 [J]  Rk(✓)  ⇠k  8k 2 [K].
The Lagrangian for the re-written problem is given below  where 1  . . .   J 2 R+ and
J+1  . . .   J+K 2 R+ are the Lagrange multipliers for the two sets of constraints:

JXj=1
|

KXk=1

L1(⇠;)

KXk=1
{z

L2(✓;)

}

(5)

(6)

}

|

J+k ⇠k

max
2⇤

+
min

J+k Rk(✓)

.

+ g(✓) +

L(✓  ⇠; ) =

µ2⇥ ⇠ 2[0 1]K L1(⇠; ) + L2(µ; ).

As before  we expand the search space to include stochastic models in ⇥  restrict the Lagrange

kk1     and formulate a max-min problem:

j j(⇠) 
{z
multipliers to a bounded set ⇤=  2 RJ+K
One can now apply Algorithm 1 and 2 to this problem. For Algorithm 1  the ✓-player uses the
CSO oracle to optimize the true Lagrangian L2  and for Algorithm 2  the ✓-player uses OGD to
optimize a surrogate Lagrangian ˜L2(µ; ) = PK
k=1 J+k ˜Rk(µ). In both cases  the ⇠-player plays
best response by minimizing L1 over ⇠ using an analytical solution (where available) or using a
convex optimization solver.
Theorem 3. Let ✓1  . . .  ✓ T be the iterates generated by Algorithm 1 for (P2)  and let ¯µ be a
stochastic model with a probability mass of 1
T on ✓t. Suppose there exists a µ0 2 ⇥ such that
j(R(µ0))    8j 2 [J]  for some > 0. Let Bg = max✓2⇥ g(✓). Let µ⇤ 2 ⇥ be such that
µ⇤ is feasible  i.e. j(R(µ⇤))  0  8j 2 [J]  and E✓⇠µ⇤ [g(✓)]  E✓⇠µ [g(✓)] for every µ 2 ⇥
that is feasible. Let B  maxt krL(⇠t ✓ t; t)k2. Then setting  = 2(L+1)Bg
 
Bp2T
we have w.p.  1   over draws of stochastic gradients:
E✓⇠¯µ [g(✓)]  E✓⇠µ⇤ [g(✓)] + O✓r log(1/)

+⇢◆ and j(R(¯µ)) O ✓r log(1/)

+⇢◆ 8j.

and ⌘ = 



T

T

We have thus shown that Algorithm 1 outputs a stochastic model that has an objective close to the
optimal feasible solution for (P2)  while also closely satisfying the constraints.
Theorem 4. Let ✓1  . . .  ✓ T be the iterates of Algorithm 1 for (P2)  and let ¯µ be a stochastic model
T on ✓t. Let ⇥ be convex and ˜⇥= ✓ 2 ⇥|8 j  ˜R(✓) 2 [0  1]K . Let ˜✓⇤ 2 ˜⇥ be such that
with prob. 1
it satisﬁes the surrogate-relaxed constraints j( ˜R(˜✓⇤))  0  8j 2 [J]  and g(˜✓⇤)  g(✓) for every
✓ 2 ˜⇥ that satisﬁes the same constraints. Let B⇥  max✓2⇥ k✓k2  B✓  maxt kr✓ ˜L2(✓t; t)k2
and B  maxt krL(⇠t ✓ t; t)k2. Then setting  = (L + 1)T ! for ! 2 (0  0.5)  ⌘✓ = B⇥
B✓p2T
and ⌘ = 
◆  8j.

E✓⇠¯µ [g(✓)]  g(˜✓⇤) + O✓plog(1/)

j(R(¯µ)) O ✓plog(1/)

  we have w.p.  1   over draws of stochastic gradients:

T 1/2  ! ◆ and

Bp2T

T !

The proof is an adaptation of the analysis in Agarwal et al. (2018) [26] to non-zero-sum games. We
point out that despite the ✓-player optimizing surrogate functions  the ﬁnal stochastic model is near-
feasible for the original rate metrics. We also note that this result holds even if the surrogates output
values outside the domain of the constraint functions j’s (e.g. with KL-divergence constraints).

While the above convergence rate is not as good as the standard O(1/pT ) rate achievable for
OGD  this is similar to the guarantees shown by e.g. Agarwal et al. [26] for linear rate-constrained
optimization problems.1 The reason for the poorer convergence rate is that we are unable to ﬁx the
radius  of the space of Lagrange multipliers ⇤ to a constant  and instead set it to a function of T .
1See Theorem 3 in their paper  where  for T = O(n4↵) iterations  the error bound is ˜O(n↵) = ˜O(T 1/4).

7

Algorithm 3 Surrogate-based Optimizer for (P3)

Initialize: a0  b0  ✓0  0
for t = 0 to T  1 do

at+1 =⇧ C (at  ⌘araLsr(✓t  at  bt; t));
bt+1 =⇧ C (bt  ⌘brbLsr(✓t  at  bt; t))  where C = {a  b 2 R | a  a  b  b}
✓t+1 =⇧ ⇥(✓t  ⌘✓ r✓ ˜Lsr(✓t; at  bt t))  where ˜Lsr is (7) with Rk replaced with ˜Rk
t+1 =⇧ ⇤ (t + ⌘ rLsr(✓t  at  bt; t))
end for
return ✓1  . . .  ✓ T

Remark 4 (Unanswered Question in Cotter et al.). Cotter et al. consider optimization problems
with linear rate constraints  formulate a non-zero-game like us  and consider two algorithms  one
where both the ✓- and -player seek to minimize external regret (through OGD updates)  and the
other where the ✓-player optimizes alone minimizes external regret  while the -player minimizes
swap regret. They are however able to show convergence guarantees only for a more complicated
swap regret algorithm  and leave the analysis of the external regret algorithm unanswered. Theorem
4 provides convergence guarantees for a generalization of their external regret algorithm. In their

paper  Cotter et al. do obtain a better O(1/pT ) convergence rate for their swap regret algorithm.

It is easy to show a similar convergence rate for an adaptation of this algorithm to our setting (see
Appendix C)  but we stick to our present algorithm because of its simplicity.

Case of Sum-of-ratios Metrics. Moving beyond convex functions of rates  we present a heuris-
tic algorithm for optimizing with objectives and constraints in (P3) that are sums-of-ratios of
rates. We assume that the numerators and denominators in each ratio term is bounded  i.e.
a  h↵m  R(✓)i  hm  R(✓)i  b  and a  h↵0m  R(✓)i  h0m  R(✓)i  b  8✓ 2 ⇥ for
some a  b > 0. Introducing slack variables a1  . . .   a2M  b1  . . .   b2M for the numerators and denomi-
nators respectively to decouple the rates from the ratio terms  we equivalently re-write (P3):

min
✓2⇥

MXm=1

am
bm

s.t.

2MXm=M +1

am
bm    am  h↵m  R(✓)i  bm  hm  R(✓)i  8m.

aambmb
We then formulate the Lagrangian for the above problem with multipliers  2 R4M +1
m=1 am/bm + 0P2M
m=M +1 am/bm  
Lsr(✓  a  b; ) = PM
(7)
m=1 m(h↵m  R(✓)i  am) + P2M
+P2M
m=1 2M +m(bm  hm  R(✓)i).
Because Lsr is non-convex in the slack variables a  b  strong duality may not hold  and an optimal
solution for the dual problem may not be optimal for (P3). Yet  by performing OGD updates for the
  ✓ and the slack variables  with the ✓-player alone optimizing the surrogate rates ˜Rk  we obtain a
heuristic to solve (P3). The details are given in Algorithm 3.

and get:

+

5 Experiments

We conduct two types of experiments. In the ﬁrst  we evaluate Algorithm 2 on the task of optimizing
a convex rate objective subject to linear rate constraints and show it often performs as well as an
oracle-based approach for this problem [11] (and does so without having to make an idealized oracle
assumption). In the second  we evaluate Algorithm 3 on the task of optimizing a sum-of-ratios
objective subject to sum-of-ratios constraints  and compare it against existing baselines.
Datasets. We use ﬁve datasets: (1) COMPAS  where the goal is to predict recidivism with gender as
the protected attribute [44]; (2) Communities & Crime  where the goal is to predict if a community in
the US has a crime rate above the 70th percentile [45]  and we consider communities having a black
population above the 50th percentile as protected [27]; (3) Law School  where the task is to predict
whether a law school student will pass the bar exam  with race (black or other) as the protected
attribute [46]; (4) Adult  where the task is to predict if a person’s income exceeds 50K/year  with
gender as the protected attribute [45]; (5) Wiki Toxicity  where the goal is to predict if a comment

8

Table 3: Optimizing KL-divergence fairness metric s.t. error rate constraints. For each method  we
report two metrics: A (B)  where A is the test fairness metric (lower is better) and B is the ratio of the
test error rate of the method and that of UncError (lower is better). During training  we constrain B to
be  1.1. Among the last 3 columns  the lowest fairness metric is highlighted in bold.

COMPAS
Crime
Law
Adult
Wiki

UncError
0.115 (1.00)
0.224 (1.00)
0.199 (1.00)
0.114 (1.00)
0.175 (1.00)

PostShift
0.000 (1.01)
0.005 (1.40)
0.001 (1.45)
0.000 (1.22)
0.001 (1.21)

COCO

0.043 (1.01)
0.252 (0.83)
0.043 (1.05)
0.011 (1.10)
0.134 (1.17)

Stochastic
0.000 (1.03)
0.120 (1.11)
0.054 (1.12)
0.014 (1.10)
0.133 (1.09)

Determ.

0.000 (1.03)
0.146 (1.08)
0.056 (1.08)
0.014 (1.10)
0.127 (1.18)

Table 4: Optimizing F-measure s.t. F-measure constraints. For each method  we report two metrics:
A (B)  where A is the overall test F-measure (higher is better) and B is the test constraint violation:
Fmeasureprt  Fmeasureother  0.02 (lower is better). The lowest constraint violation is in italic.

COMPAS
Crime
Law
Adult
Wiki

UncError
0.656 (0.13)
0.742 (0.19)
0.973 (0.10)
0.675 (0.03)
0.968 (0.18)

UncF1

0.666 (0.09)
0.752 (0.19)
0.975 (0.08)
0.688 (0.06)
0.967 (0.18)

Stochastic
0.627 (0.07)
0.711 (0.11)
0.927 (0.04)
0.660 (0.04)
0.826 (0.00)

Determ.

0.628 (0.07)
0.711 (0.11)
0.842 (-0.05)
0.647 (0.03)
0.782 (-0.05)

posted on a Wikipedia talk page contains non-toxic/acceptable content  with the comments containing
the term ‘gay’ considered as a protected group [47]. We use linear models  and hinge losses as
surrogates ˜Rk. All implementations are in Tensorﬂow.2 See Appendix G for additional details.
KL-divergence Based Fairness Objective. We consider a demographic-parity style fairness objec-
tive that seeks to match the proportion of positives predicted in each group ˆpG with the true proportion
of positives p in the data  measured using a KL-divergence metric:PG2{0 1}
KLD(p  ˆpG). Note that
this is convex in ˆpG. We additionally enforce a constraint that the error rate of the model is no more
than 10% higher than an unconstrained model that optimizes error rate  i.e. ˆerr(f✓)  1.1 ˆerr(func).
The only previous method that we are aware of that can handle constrained problems of this form
is the COCO method of Narasimhan (2018) [11]. This is an oracle-based approach and uses a
plug-in method to implement the cost-sensitive oracle. We compare Algorithm 2 with COCO  and the
post-shift method of Hardt et al. (2016) [48]  where we take a pre-trained logistic regression model
and assign different thresholds to the groups to correct for fairness disparity [48]. For our algorithm 
we report the performance of both the trained stochastic classiﬁer and the best deterministic classiﬁer
chosen through a ‘best iterate’ heuristic of Cotter et al. (2019) [23]. The results are shown in Table 3.
PostShift performs the best on the fairness metric  but on all datasets except COMPAS  fairs poorly
on the constraint. The proposed method and COCO achieve different trade-offs between optimizing
the objective and satisfying the error rate constraint. The stochastic classiﬁer trained by our method
closely satisﬁes the constraint on almost all datasets  and yields a lower objective than COCO on
three datasets. Moreover  the best deterministic classiﬁer often has a similar performance to the
stochastic classiﬁer. We present further analysis and additional comparisons in Appendix G.1.
F-measure Based Parity Constraints. We consider the fairness goal of training a classiﬁer that
yields at least as high a F-measure for the protected group as it does for the rest of the population 
and impose this as a constraint. Speciﬁcally  we seek to maximize the overall F-measure subject to
the constraint: Fmeasureprt  Fmeasureother  0.02. We apply Algorithm 3 and compare it with
an unconstrained classiﬁer that optimizes error rate (UncError) and a plug-in classiﬁer that optimizes
the F-measure without constraints (UncF1). As seen in Table 4  while UncF1 yields a better objective
than UncError  both the baselines fail to satisfy the constraint. On four of the datasets  the stochastic
classiﬁer trained by our approach yields moderate to signiﬁcant reduction in constraint violation.
On Adult  the trained stochastic classiﬁer yields a very small constraint violation on the training set
(0.004)  but does not perform as well on the test set. The deterministic classiﬁers have an equal or
lower constraint violation compared to the stochastic classiﬁers  but at the cost of a lower objective.

2https://github.com/google-research/google-research/tree/master/generalized_rates

9

Acknowledgments

We thank Qijia Jiang and Heinrich Jiang for helpful feedback on draft versions of this paper.

References
[1] D.D. Lewis. Evaluating text categorization. In HLT Workshop on Speech and Natural Language 

1991.

[2] J-D. Kim  Y. Wang  and Y. Yasunori. The Genia event extraction shared task  2013 edition-

overview. ACL  2013.

[3] Y. Sun  M.S. Kamel  and Y. Wang. Boosting for learning multiple classes with imbalanced class

distribution. In ICDM  2006.

[4] S. Wang and X. Yao. Multiclass imbalance problems: Analysis and potential solutions. IEEE
Transactions on Systems  Man  and Cybernetics  Part B: Cybernetics  42(4):1119–1130  2012.

[5] S. Lawrence  I. Burns  A. Back  A-C. Tsoi  and C.L. Giles. Neural network classiﬁcation and
prior class probabilities. In Neural Networks: Tricks of the Trade  LNCS  pages 1524:299–313.
Springer  1998.

[6] A. Chouldechova. Fair prediction with disparate impact: A study of bias in recidivism prediction

instruments. Big data  5(2):153–163  2017.

[7] M.M. Fard  Q. Cormier  K. Canini  and M. Gupta. Launch and iterate: Reducing prediction

churn. In NIPS  2016.

[8] A. Esuli and F. Sebastiani. Optimizing text quantiﬁers for multivariate loss functions. ACM

Transactions on Knowledge Discovery and Data  9(4):Article 27  2015.

[9] W. Gao and F. Sebastiani. Tweet sentiment: From classiﬁcation to quantiﬁcation. In ASONAM 

2015.

[10] E. Eban  M. Schain  A. Mackey  A. Gordon  R. Rifkin  and G. Elidan. Scalable learning of

non-decomposable objectives. In AISTATS  2017.

[11] H. Narasimhan. Learning with complex loss functions and constraints. In AISTATS  2018.

[12] T. Joachims. A support vector method for multivariate performance measures. In ICML  2005.

[13] Purushottam Kar  Harikrishna Narasimhan  and Prateek Jain. Online and stochastic gradient

methods for non-decomposable loss functions. In NIPS  2014.

[14] H. Narasimhan  P. Kar  and P. Jain. Optimizing non-decomposable performance measures: A

tale of two classes. In ICML  2015.

[15] P. Kar  S. Li  H. Narasimhan  S. Chawla  and F. Sebastiani. Online optimization methods for

the quantiﬁcation problem. In KDD  2016.

[16] G. Goh  A. Cotter  M. Gupta  and M.P. Friedlander. Satisfying real-world goals with dataset

constraints. In NIPS  2016.

[17] A. Sanyal  P. Kumar  P. Kar  S. Chawla  and F. Sebastiani. Optimizing non-decomposable

measures with deep networks. Machine Learning  107(8-10):1597–1620  2018.

[18] S.A.P. Parambath  N. Usunier  and Y. Grandvalet. Optimizing F-measures by cost-sensitive

classiﬁcation. In NIPS  2014.

[19] O. Koyejo  N. Natarajan  P. Ravikumar  and I.S. Dhillon. Consistent binary classiﬁcation with

generalized performance metrics. In NIPS  2014.

[20] H. Narasimhan  H.G. Ramaswamy  A. Saha  and S. Agarwal. Consistent multiclass algorithms

for complex performance measures. In ICML  2015.

10

[21] B. Yan  O. Koyejo  K. Zhong  and P. Ravikumar. Binary classiﬁcation with karmic  threshold-

quasi-concave metrics. In ICML  2018.

[22] D. Alabi  N. Immorlica  and A. Kalai. Unleashing linear optimizers for group-fair learning and

optimization. In COLT  2018.

[23] A. Cotter  H. Jiang  and K. Sridharan. Two-player games for efﬁcient non-convex constrained

optimization. In ALT  2019.

[24] A. Cotter  H. Jiang  S. Wang  T. Narayan  M. Gupta  S. You  and K. Sridharan. Optimization
with non-differentiable constraints with applications to fairness  recall  churn  and other goals.
JMLR (to appear)  arXiv preprint arXiv:1809.04198  2019.

[25] M. B. Zafar  I. Valera  M. Gomez-Rodriguez  and K. P. Gummadi. Fairness constraints:

Mechanisms for fair classiﬁcation. In AISTATS  2017.

[26] A. Agarwal  A. Beygelzimer  M. Dudik  J. Langford  and H. Wallach. A reductions approach to

fair classiﬁcation. In ICML  2018.

[27] M. Kearns  S. Neel  A. Roth  and Z.S. Wu. Preventing fairness gerrymandering: Auditing and

learning for subgroup fairness. In ICML  2018.

[28] M. Donini  L. Oneto  S. Ben-David  J.S. Shawe-Taylor  and M. Pontil. Empirical risk minimiza-

tion under fairness constraints. In NeurIPS  2018.

[29] H. Wang  W. Xing  K. Asif  and B. Ziebart. Adversarial prediction games for multivariate losses.

In NIPS  2015.

[30] R. Busa-Fekete  B. Szörényi  K. Dembczynski  and E. Hüllermeier. Online F-measure optimiza-

tion. In NIPS  2015.

[31] M. Liu  X. Zhang  X. Zhou  and T. Yang. Faster online learning of optimal threshold for

consistent F-measure optimization. In NeurIPS  2018.

[32] W. Pan  H. Narasimhan  P. Kar  P. Protopapas  and H. G. Ramaswamy. Optimizing the multiclass

F-measure via biconcave programming. In ICDM  2016.

[33] L. E. Celis  L. Huang  V. Keswani  and N. K. Vishnoi. Classiﬁcation with fairness constraints:

A meta-algorithm with provable guarantees. In FAT  2019.

[34] M. Kubat and S. Matwin. Addressing the curse of imbalanced training sets: One-sided selection.

In ICML  1997.

[35] S. Daskalaki  I. Kopanas  and N. Avouris. Evaluation of classiﬁers for an uneven class distribu-

tion problem. Applied Artiﬁcial Intelligence  20:381–417  2006.

[36] K. Kennedy  B.M. Namee  and S.J. Delany. Learning without default: A study of one-class

classiﬁcation and the low-default portfolio problem. In ICAICS  2009.

[37] C. D. Manning  P. Raghavan  and H. Schütze. Introduction to Information Retrieval. Cambridge

University Press  2008.

[38] D. D. Lewis and W. A. Gale. A sequential algorithm for training text classiﬁers. In SIGIR  1994.
[39] M. Gupta A. Cotter  H. Narasimhan. On making stochastic classiﬁers deterministic. In NeurIPS 

2019.

[40] C. Elkan. The foundations of cost-sensitive learning. In IJCAI  2001.
[41] M. Zinkevich. Online convex programming and generalized inﬁnitesimal gradient ascent. In

ICML  2003.

[42] S. Shalev-Shwartz. Online learning and online convex optimization. Foundations and Trends R

in Machine Learning  4(2):107–194  2012.

[43] J. D. Abernethy and J.-K. Wang. On Frank-Wolfe and equilibrium computation. In NIPS  2017.

11

[44] J. Angwin  J. Larson  S. Mattu  and L. Kirchner. Machine bias. ProPublica  May  23  2016.
[45] A. Frank and A. Asuncion. UCI machine learning repository. URL: http://archive.ics.

uci.edu/ml  2010.

[46] L. Wightman. Lsac national longitudinal bar passage study. Law School Admission Council 

1998.

[47] L. Dixon  J. Li  J. Sorensen  N. Thain  and L. Vasserman. Measuring and mitigating unintended

bias in text classiﬁcation. In AIES  2018.

[48] M. Hardt  E. Price  and N. Srebro. Equality of opportunity in supervised learning. In NIPS 

2016.

[49] J. Pennington  R. Socher  and C. Manning. Glove: Global vectors for word representation. In

EMNLP  2014.

[50] N. Cesa-Bianchi  A. Conconi  and C. Gentile. On the generalization ability of on-line learning

algorithms. IEEE Transactions on Information Theory  50(9):2050–2057  2004.

[51] X. Zhou. On the Fenchel duality between strong convexity and Lipschitz continuous gradient.

arXiv preprint arXiv:1803.06573  2018.

12

,Harikrishna Narasimhan
Andrew Cotter
Maya Gupta