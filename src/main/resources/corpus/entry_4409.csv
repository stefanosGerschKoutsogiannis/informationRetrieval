2019,Privacy-Preserving Classification of Personal Text Messages with Secure Multi-Party Computation,Classification of personal text messages has many useful applications in surveillance  e-commerce  and mental health care  to name a few. Giving applications access to personal texts can easily lead to (un)intentional privacy violations. We propose the first privacy-preserving solution for text classification that is provably secure. Our method  which is based on Secure Multiparty Computation (SMC)  encompasses both feature extraction from texts  and subsequent classification with logistic regression and tree ensembles. We prove that when using our secure text classification method  the application does not learn anything about the text  and the author of the text does not learn anything about the text classification model used by the application beyond what is given by the classification result itself. We perform end-to-end experiments with an application for detecting hate speech against women and immigrants  demonstrating excellent runtime results without loss of accuracy.,Privacy-Preserving Classiﬁcation of Personal Text
Messages with Secure Multi-Party Computation: An

Application to Hate-Speech Detection

Devin Reich1  Ariel Todoki1  Rafael Dowsley2  Martine De Cock1⇤  Anderson Nascimento1

1 School of Engineering and Technology

University of Washington Tacoma

Tacoma  WA 98402

rafael@dowsley.net

{dreich atodoki mdecock andclay}@uw.edu

2Department of Computer Science

Bar-Ilan University  5290002  Ramat-Gan  Israel

Abstract

Classiﬁcation of personal text messages has many useful applications in surveil-
lance  e-commerce  and mental health care  to name a few. Giving applications
access to personal texts can easily lead to (un)intentional privacy violations. We
propose the ﬁrst privacy-preserving solution for text classiﬁcation that is provably
secure. Our method  which is based on Secure Multiparty Computation (SMC) 
encompasses both feature extraction from texts  and subsequent classiﬁcation with
logistic regression and tree ensembles. We prove that when using our secure text
classiﬁcation method  the application does not learn anything about the text  and
the author of the text does not learn anything about the text classiﬁcation model
used by the application beyond what is given by the classiﬁcation result itself.
We perform end-to-end experiments with an application for detecting hate speech
against women and immigrants  demonstrating excellent runtime results without
loss of accuracy.

1

Introduction

The ability to elicit information through automated scanning of personal texts has signiﬁcant economic
and societal value. Machine learning (ML) models for classiﬁcation of text such as e-mails and SMS
messages can be used to infer whether the author is depressed [46]  suicidal [42]  a terrorist threat
[1]  or whether the e-mail is a spam message [2  49]. Other valuable applications of text message
classiﬁcation include user proﬁling for tailored advertising [32]  detection of hate speech [6]  and
detection of cyberbullying [51]. Some of the above are integrated in parental control applications2
that monitor text messages on the phones of children and alert their parents when content related to
drug use  sexting  suicide etc. is detected. Regardless of the clear beneﬁts  giving applications access
to one’s personal text messages and e-mails can easily lead to (un)intentional privacy violations.
In this paper  we propose the ﬁrst privacy-preserving (PP) solution for text classiﬁcation that is
provably secure. To the best of our knowledge  there are no existing Differential Privacy (DP) or
Secure Multiparty Computation (SMC) based solutions for PP feature extraction and classiﬁcation of
unstructured texts; the only existing method is based on Homomorphic Encryption (HE) and takes 19
minutes to classify a tweet [15] while leaking information about the text being classiﬁed. In our SMC

⇤Guest Professor at Dept. of Applied Mathematics  Computer Science  and Statistics  Ghent University
2https://www.bark.us/  https://kidbridge.com/  https://www.webwatcher.com/

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

Figure 1: Roles of Alice and Bob in SMC based text classiﬁcation

based solution  there are two parties  nick-named Alice and Bob (see Fig. 1). Bob has a trained ML
model that can automatically classify texts. Our secure text classiﬁcation protocol allows to classify a
personal text written by Alice with Bob’s ML model in such a way that Bob does not learn anything
about Alice’s text and Alice does not learn anything about Bob’s model. Our solution relies on PP
protocols for feature extraction from text and PP machine learning model scoring  which we propose
in this paper.
We perform end-to-end experiments with an application for PP detection of hate speech against
women and immigrants in text messages. In this use case  Bob has a trained logistic regression (LR)
or AdaBoost model that ﬂags hateful texts based on the occurrence of particular words. LR models
on word n-grams have been observed to perform comparably to more complex CNN and LSTM
model architectures for hate speech detection [35]. Using our protocols  Bob can label Alice’s texts
as hateful or not without learning which words occur in Alice’s texts  and Alice does not learn which
words are in Bob’s hate speech lexicon  nor how these words are used in the classiﬁcation process.
Moreover  classiﬁcation is done in seconds  which is two orders of magnitude better than the existing
HE solution despite the fact we use over 20 times more features and do not leak any information
about Alice’s text to the model owner (Bob). The solution based on HE leaks which words in the text
are present in Bob’s lexicon [15].
We build our protocols using a privacy-preserving machine learning (PPML) framework based on
SMC developed by us3 . All the existing building blocks can be composed within themselves or
with new protocols added to the framework. On top of existing building blocks  we also propose
a novel protocol for binary classiﬁcation over binary input features with an ensemble of decisions
stumps. While some of our building blocks have been previously proposed  the main contribution of
this work consists of the careful choice of the ML techniques  feature engineering and algorithmic
and implementation optimizations to enable end-to-end practical PP text classiﬁcation . Additionally 
we provide security deﬁnitions and proofs for our proposed protocols.

2 Preliminaries

We consider honest-but-curious adversaries  as is common in SMC based PPML (see e.g. [19  21]).
An honest-but-curious adversary follows the instructions of the protocol  but tries to gather additional
information. Secure protocols prevent the latter.
We perform SMC using additively secret shares to do computations modulo an integer q. A value x
is secret shared over Zq = {0  1  . . .   q  1} between parties Alice and Bob by picking xA  xB 2 Zq
uniformly at random subject to the constraint that x = xA + xB mod q  and then revealing xA to
Alice and xB to Bob. We denote this secret sharing by [[x]]q  which can be thought of as a shorthand
for (xA  xB). Secret-sharing based SMC works by ﬁrst having the parties split their respective inputs
in secret shares and send some of these shares to each other. Naturally  these inputs have to be mapped
appropriately to Zq. Next  Alice and Bob represent the function they want to compute securely as a
circuit consisting of addition and multiplication gates. Alice and Bob will perform secure additions
and multiplications  gate by gate  over the shares until the desired outcome is obtained. The ﬁnal
result can be recovered by combining the ﬁnal shares  and disclosed as intended  i.e. to one of the
parties or to both. It is also possible to keep the ﬁnal result distributed over shares.
In SMC based text classiﬁcation  as illustrated in Fig. 1  Alice’s input is a personal text x and Bob’s
input is an ML model M for text classiﬁcation. The function that they want to compute securely is

3https://bitbucket.org/uwtppml

2

f (x M) = M(x)  i.e. the class label of x when classiﬁed by M. To this end  Alice splits the text
in secret shares while Bob splits the ML model in secret shares. Both parties engage in a protocol
in which they send some of the input shares to each other  do local computations on the shares  and
repeat this process in an iterative fashion over shares of intermediate results (Step 1). At the end
of the joint computations  Alice sends her share of the computed class label to Bob (Step 2)  who
combines it with his share to learn the classiﬁcation result (Step 3). As mentioned above  the protocol
for Step 1 involves representing the function f as a circuit of addition and multiplication gates.
Given two secret sharings [[x]]q and [[y]]q  Alice and Bob can locally compute in a straightforward way
a secret sharing [[z]]q corresponding to z = x + y or z = x  y by simply adding/subtracting their
local shares of x and y modulo q. Given a constant c  they can also easily locally compute a secret
sharing [[z]]q corresponding to z = cx or z = x + c: in the former case Alice and Bob just multiply
their local shares of x by c; in the latter case Alice adds c to her share of x while Bob keeps his
original share. These local operations will be denoted by [[z]]q [[x]]q + [[y]]q  [[z]]q [[x]]q  [[y]]q 
[[z]]q c[[x]]q and [[z]]q [[x]]q + c  respectively. To allow for efﬁcient secure multiplication of
values via operations on their secret shares (denoted by [[z]]q [[x]]q[[y]]q)  we use a trusted initializer
that pre-distributes correlated randomness to the parties participating in the protocol before the start
of Step 1 in Fig. 1.4 The initializer is not involved in any other part of the execution and does not
learn any data from the parties. This can be straightforwardly extended to efﬁciently perform secure
multiplication of secret shared matrices. The protocol for secure multiplication of secret shared
matrices is denoted by ⇡DMM and for the special case of inner-product computation by ⇡IP. Details
about the (matrix) multiplication protocol can be found in [19]. We note that if a trusted initializer is
not available or desired  Alice and Bob can engage in pre-computations to securely emulate the role
of the trusted initializer  at the cost of introducing computational assumptions in the protocol [19].

3 Secure text classiﬁcation

Our general protocol for PP text classiﬁcation relies on several building blocks that are used together
to accomplish Step 1 in Fig. 1: a secure equality test  a secure comparison test  private feature
extraction  secure protocols for converting between secret sharing modulo 2 and modulo q > 2  and
private classiﬁcation protocols. Several of these building blocks have been proposed in the past.
However  to the best of our knowledge  this is the very ﬁrst time they are combined in order to achieve
efﬁcient text classiﬁcation with provable security.
We assume that Alice has a personal text message  and that Bob has a LR or AdaBoost classiﬁer that
is trained on unigrams and bigrams as features. Alice constructs the set A = {a1  a2  . . .   am} of
unigrams and bigrams occurring in her message  and Bob constructs the set B = {b1  b2  . . .   bn} of
unigrams and bigrams that occur as features in his ML model. We assume that all aj and bi are in the
form of bit strings. To achieve this  Alice and Bob convert each unigram and bigram on their end to a
number N using SHA 224 [44]  strictly for its ability to map the same inputs to the same outputs in a
pseudo-random manner. Next Alice and Bob map each N on their end to a number between 0 and
2l  1  i.e. a bit string of length l  using a random function in the universal hash family proposed by
Carter and Wegman [12].5 In the remainder we use the term “word” to refer to a unigram or bigram 
and we refer to the set B = {b1  b2  . . .   bn} as Bob’s lexicon.
Below we outline the protocols for PP text classiﬁcation. A correctness and security analysis of the
protocols is provided as an appendix. In the description of the protocols in this paper  we assume that
Bob needs to learn the result of the classiﬁcation  i.e. the class label  at the end of the computations. It
is important to note that the protocols described below can be straightforwardly adjusted to a scenario
where Alice instead of Bob has to learn the class label  or even to a scenario where neither Alice
nor Bob should learn what the class label is and instead it should be revealed to a third party or kept
in a secret sharing form. All these scenarios might be relevant use cases of PP text classiﬁcation 
depending on the speciﬁc application at hand.

4This technique for secure multiplication was originally proposed by Beaver [7] and is regularly used to
enable very efﬁcient solutions both in the context of PPML [20  17  33  19] as well as in other applications  e.g. 
[48  28  27  38  50  18].
5The hash function is deﬁned as ((a · N + b) mod p) mod 2l  1 where p is a prime and a and b are

random numbers less than p. In our experiments  p = 1  301  081  a = 972  and b = 52  097.

3

3.1 Cryptographic building blocks
Secure Equality Test: At the start of the secure equality test protocol  Alice and Bob have secret
shares of two bit strings x = x` . . . x1 and y = y` . . . y1 of length `. x corresponds to a word from
Alice’s message and y corresponds to a feature from Bob’s model. The bit strings x and y are secret
shared over Z2. Alice and Bob follow the protocol to determine whether x = y. The protocol ⇡EQ
outputs a secret sharing of 1 if x = y and of 0 otherwise.
Protocol ⇡EQ:
• For i = 1  . . .  `   Alice and Bob locally compute [[ri]]2 [[xi]]2 + [[yi]]2 + 1.
• Alice and Bob use secure multiplication to compute a secret sharing of z = r1 · r2 · . . . · r`. If
x = y  then ri = 1 for all bit positions i  hence z = 1; otherwise some ri = 0 and therefore z = 0.
The result is the secret sharing [[z]]2  which is the desired output of the protocol.

This protocol for equality test is folklore in the ﬁeld of SMC. The l  1 multiplications can be
organized in as binary tree with the result of the multiplication at the root of the tree. In this way 
the presented protocol has log(l) rounds. While there are equality test protocols that have a constant
number of rounds  the constant is prohibitively large for the parameters used in our implementation.

Secure Feature Vector Extraction: At the start of the feature extraction protocol  Alice has a set
A = {a1  a2  . . .   am} and Bob has a set B = {b1  b2  . . .   bn}. A is a set of bit strings that represent
Alice’s text  and B is a set of bit strings that represent Bob’s lexicon. Bob would like to extract words
from Alice’s text that appear in his lexicon. At the end of the protocol  Alice and Bob have secret
shares of a binary feature vector x which represents what words in Bob’s lexicon appear in Alice’s
text. The binary feature vector x of length n is deﬁned as

xi =⇢ 1

0

if bi 2 A
otherwise

(1)

Protocol ⇡FE:
• Alice and Bob secret share each aj (j = 1  . . .   m) and each bi (i = 1  . . .   n) with each other.
• For i = 1 . . . n: // Computation of secret shares of xi as deﬁned in Equation (1).

For j = 1 . . . m:

Alice and Bob run the secure equality test protocol ⇡EQ to compute secret shares

xij = 1 if aj = bi; xij = 0 otherwise

(2)

Alice and Bob locally compute the secret share [[xi]]2 Pm

The secure feature vector extraction can be seen as a private set intersection where the intersection is
not revealed but shared [13  31]. Our solution ⇡FE is tailored to be used within our PPML framework
(it uses only binary operations  it is secret sharing based  and is based on pre-distributed binary
multiplications). In principle  other protocols could be used here. The efﬁciency of our protocol can
be improved by using hashing techniques [45] at the cost of introducing a small probability of error.
The improvements due to hashing are asymptotic and for the parameters used in our fastest running
protocol these improvements were not noticeable. Thus  we restricted ourselves to the original
protocol without hashing and without any probability of failure.

j=1[[xij]]2.

Secure Comparison Test:
In our privacy-preserving AdaBoost classiﬁer we will use a secure
comparison protocol as a building block. At the start of the secure comparison test protocol  Alice
and Bob have secret shares over Z2 of two bit strings x = x` . . . x1 and y = y` . . . y1 of length `.
They run the secure comparison protocol ⇡DC of Garay et al. [34] with secret sharings over Z2 and
obtain a secret sharing of 1 if x  y and of 0 otherwise.
Secure Conversion between Zq and Z2: Some of our building blocks perform computations using
secret shares over Z2 (secure equality test  comparison and feature extraction)  while the secure inner
product works over Zq for q > 2. In order to be able to integrate these building blocks we need:
• A secure bit-decomposition protocol for secure conversion from Zq to Z2: Alice and Bob have as
input a secret sharing [[x]]q and without learning any information about x they should obtain as
output secret sharings [[xi]]2  where x` ··· x1 is the binary representation of x. We use the secure
bit-decomposition protocol ⇡decomp from De Cock et al. [19].

4

x1

x1 = 0

x1 = 1

xi

xn

xi = 0

xi = 1

...

...

xn = 0

xn = 1

0 : y1 0
1 : z1 0

0 : y1 1
1 : z1 1

0 : yi 0
1 : zi 0

0 : yi 1
1 : zi 1

0 : yn 0
1 : zn 0

0 : yn 1
1 : zn 1

Figure 2: Ensemble of decision stumps. Each root corresponds to a feature xi. The leaves contain
weights yi k for the votes for class label 0 and weights zi k for the votes for class label 1.

• A protocol for secure conversion from Z2 to Zq: Alice and Bob have as a input a secret sharing
[[x]]2 of a bit x and need to obtain a secret sharing [[x]]q of the binary value over a larger ﬁeld Zq
without learning any information about x. To this end  we use protocol ⇡2toQ:
– For the input [[x]]2  let xA 2{ 0  1} denote Alice’s share and xB 2{ 0  1} denote Bob’s share.
– Alice creates a secret sharing [[xA]]q by picking uniformly random shares that sum to xA and
– Alice and Bob compute [[y]]q [[xA]]q[[xB]]q.
– The output is computed as [[z]]q [[xA]]q + [[xB]]q  2[[y]]q.

delivers Bob’s share to him  and Bob proceeds similarly to create [[xB]]q.

Secure Logistic Regression (LR) Classiﬁcation: At the start of the secure LR classiﬁcation
protocol  Bob has a trained LR model M that requires a feature vector x of length n as its input  and
produces a label M(x) as its output. Alice and Bob have secret shares of the feature vector x which
represents what words in Bob’s lexicon appear in Alice’s text. At the end of the protocol  Bob gets
the result of the classiﬁcation M(x). We use an existing protocol ⇡LR for secure classiﬁcation with
LR models [19].6

Secure AdaBoost Classiﬁcation: The setting is the same as above  but the model M is an Ad-
aBoost ensemble of decision stumps instead of a LR model. While efﬁcient solutions for secure
classiﬁcation with tree ensembles were previously known [33]  we can take advantage of speciﬁc
facts about our use case to obtain a more efﬁcient solution. In more detail  in our use case: (1) all the
decision trees have depth 1 (i.e.  decision stumps); (2) each feature xi is binary and therefore when it
is used in a decision node  the left and right children correspond exactly to xi = 0 and xi = 1; (3)
the output class is binary; (4) the feature values were extracted in a PP way and are secret shared so
that no party alone knows their values. We can use the above facts in order to perform the AdaBoost
classiﬁcation by computing two inner products and then comparing their values.
Protocol ⇡AB:
• Alice and Bob hold secret sharings [[xi]]q of each of the n binary features xi. Bob holds the trained
AdaBoost model which consists of two weighted probability vectors y = (y1 0  y1 1  . . .   yn 0  yn 1)
and z = (z1 0  z1 1  . . .   zn 0  zn 1). For the i-th decision stump: yi k is the weighted probability
(i.e.  a probability multiplied by the weight of the i-th decision stump) that the model assigns to
the output class being 0 if xi = k  and zi k is deﬁned similarly for the output class 1 (see Fig. 2).
• Bob secret shares the elements of y and z  and Alice and Bob locally compute secret sharings [[w]]q
of the vector w = (1  x1  x1  1  x2  x2  . . .   1  xn  xn).
• Using the secure inner product protocol ⇡IP  Alice and Bob compute secret sharings of the inner
product p0 between y and w  and of the inner product p1 between z and w. p0 and p1 are the
aggregated votes for class label 0 and 1 respectively.

c  which is then open towards Bob.

• Alice and Bob use ⇡decomp to compute bitwise secret sharings of p0 and p1 over Z2.
• Alice and Bob use ⇡DC to compare p1 and p0  getting as output a secret sharing of the output class
To the best of our knowledge  this is the most efﬁcient provably secure protocol for binary classiﬁca-
tion over binary input features with an ensemble of decisions stumps.

6In our case the result of the classiﬁcation is disclosed to Bob (the party that owns the model) instead of
Alice (who has the original input to be classiﬁed) as in [19]  however it is trivial to modify their protocol so that
the ﬁnal secret share is open towards Bob instead of Alice. Note also that in our case  the feature vector that is
used for the classiﬁcation is already secret shared between Alice and Bob  while in their protocol Alice holds the
feature vector  which is then secret shared in the ﬁrst step of the protocol. This modiﬁcation is also trivial and
does not affect the security of the protocol.

5

Table 1: Accuracy (Acc) results using 5-fold cross-validation over the corpus of 10 000 tweets. Total
time (Tot) needed to securely classify a text with our framework  broken down in time needed for
feature vector extraction (Extr) and time for feature vector classiﬁcation (Class).

Ada; 50 trees; depth 1
Ada; 200 trees; depth 1
Ada; 500 trees; depth 1
Logistic regression (50 feat.)
Logistic regression (200 feat.)
Logistic regression (500 feat.)
Logistic regression (all feat.)

Unigrams

Acc

Time (in sec)

Extr Class
6.4
0.8
71.6%
6.4
2.8
73.0%
6.7
6.6
73.9%
0.8
3.7
72.4%
3.7
2.8
73.3%
3.8
73.4%
6.6
73.1% 318.0
6.1

Tot
7.2
9.2
13.3
4.5
6.5
10.4
324.1

Unigrams+Bigrams
Time (in sec)

Acc

Extr Class
6.6
1.5
73.3%
6.6
9.4
74.2%
6.7
21.6
74.4%
1.5
3.8
73.8%
3.8
9.4
73.7%
4.1
74.2%
21.6
73.8% 5 371.9
24.9

Tot
8.1
16.0
28.3
5.3
13.2
25.7
5 396.8

3.2 Privacy-preserving classiﬁcation of personal text messages

We now present our novel protocols for PP text classiﬁcation. They result from combining the
cryptographic building blocks we introduced previously. The PP protocol ⇡TCLR for classifying the
text using a logistic regression model works as follows:
Protocol ⇡TCLR:
• Alice and Bob execute the secure feature extraction protocol ⇡FE with input sets A and B in order

to obtain the secret sharesJxiK2 of the feature vector x.
• They run the protocol ⇡2toQ to obtain sharesJxiKq over Zq.

• Alice and Bob run the secure logistic regression classiﬁcation protocol ⇡LR in order to get the
result of the classiﬁcation. The LR model M is given as input to ⇡LR by Bob  and the secret shared
feature vector x by both of them. Bob gets the result of the classiﬁcation M(x).
The privacy-preserving protocol ⇡TCAB for classifying the text using AdaBoost works as follows:
Protocol ⇡TCAB:
• Alice and Bob execute the secure feature extraction protocol ⇡FE with input sets A and B in order

to obtain the secret sharesJxiK2 of the feature vector x.
• They run the protocol ⇡2toQ to obtain sharesJxiKq over Zq.

• Alice and Bob run the secure AdaBoost classiﬁcation protocol ⇡AB to obtain the result of the clas-
siﬁcation. The secret shared feature vector x is given as input to ⇡AB by both of them  and the two
weighted probability vectors y = (y1 0  y1 1  . . .   yn 0  yn 1) and z = (z1 0  z1 1  . . .   zn 0  zn 1)
that constitute the model are speciﬁed by Bob. Bob gets the output class c.

Detailed proofs of security are presented in the appendix.

4 Experimental results

We evaluate the proposed protocols in a use case for the detection of hate speech in short text
messages  using data from [6]. The corpus consists of 10 000 tweets  60% of which are annotated
as hate speech against women or immigrants. We convert all characters to lowercase  and turn each
tweet into a set of word unigrams and bigrams. There are 29 853 distinct unigrams and 93 629
distinct bigrams in the dataset  making for a total of 123 482 features.
Accuracy results for a variety of models trained to classify a tweet as hate speech vs. non-hate speech
are presented in Table 1. The models are evaluated using 5-fold cross-validation over the entire
corpus of 10 000 tweets. The top rows in Table 1 correspond to tree ensemble models consisting
of 50  200  and 500 decision stumps respectively; the root of each stump corresponds to a feature.
The bottom rows contain results for an LR model trained on 50  200  and 500 features (preselected
based on information gain)  and an LR model trained on all features. We ran experiments for feature
sets consisting of unigrams and bigrams  as well as for feature sets consisting of unigrams only 
observing that the inclusion of bigrams leads to a small improvement in accuracy. Note that designing
a model to obtain the highest possible accuracy is not the focus of this paper. Instead  our goal is to
demonstrate that PP text classiﬁcation based on SMC is feasible in practice.

6

We implemented the protocols from Section 3 in Java and ran experiments on AWS c5.9xlarge
machines with 36 vCPUs  72.0 GiB Memory.7 Each of the parties ran on separate machines (connected
with a Gigabit Ethernet network)  which means that the results in Table 1 cover communication time
in addition to computation time. Each runtime experiment was repeated 3 times and average results
are reported. In Table 1 we report the time (in sec) needed for converting a tweet into a feature vector
(Extr)  for classiﬁcation of the feature vector (Class)  and for the overall process (Tot).

4.1 Analysis

The best running times were obtained using unigrams  50 features and logistic regression (4.5 s) with
an accuracy of 72.4%. The highest accuracy (74.4%) was obtained by using unigram and bigrams 
500 features and AdaBoost with a running time equal to 28.3s. From these results  it is clear that
feature engineering plays a major role in optimizing privacy-preserving machine learning solutions
based on SMC. We managed to reduce the running time from 5 396.8s (logistic regression  unigram
and bigrams  all 123 482 features being used) to 5.3s (logistic regression  unigrams and bigrams  50
features) without any loss in accuracy and to 4.5s (logistic regression  unigrams only  50 features)
with a small loss.

4.2 Optimizing the computational and communication complexities

The feature extraction protocol requires n · m secure equality tests of bit strings. The equality test
relies on secure multiplication  which is the more expensive operation. To reduce the number of
required equality tests  Alice and Bob can each ﬁrst map their bit strings to p buckets A1  A2  . . .   Ap
and B1  B2  . . .   Bp respectively  so that bit strings from each Ai need to only be compared with bit
strings from Bi. Each bit string aj and bi is hashed and the ﬁrst t bits of the hash output are used to
deﬁne the bucket number corresponding to that bit string  using a total of p = 2t buckets. In order not
to leak how many elements are mapped to each bucket (which can leak some information about the
probability distribution of the elements  as the hash function is known by everyone)  each bucket has
a ﬁxed number of elements (s1 for Bob’s buckets and s2 for Alice’s buckets) and the empty spots in
the buckets are ﬁlled up with dummy elements. The feature extraction protocol now requires p· s1 · s2
equality tests  which can be substantially smaller than n · m. When using bucketization  the feature
vector of length n from Equation (1) is expanded to a feature vector of length p · s1  containing the
original n features as well as the p · s1  n dummy features that Bob created to ﬁll up his buckets.
These dummy features do not have any effect on the accuracy of the classiﬁcation because Bob’s
model does not take them into account: the trees with dummy features in an AdaBoost model have 0
weight for both class labels  and the dummy features’ coefﬁcients in an LR model are always 0.
The size of the buckets has to be chosen sufﬁciently large to avoid overﬂow. The choice depends
directly on the number p = 2t of buckets (which is kept constant for Alice and Bob) and the number
of elements to be placed in the buckets  i.e. n elements on Bob’s side and m elements on Alice’s side.
While for hash functions coming from a 2-universal family of hash functions the computation of these
probabilities is relatively straightforward  the same is not true for more complicated hash functions
[45]. In that case  numerical simulations are needed in order to bound the required probability.
The effect of using buckets is more signiﬁcant for large values of n and m. In our case  after
performing feature engineering for reducing the number of elements in each set  in the best case  we
end up with inputs for which there is no signiﬁcant difference between the original protocol (without
buckets) and the protocol that uses buckets. If the performance of these two cases is comparable  one
is better off using the version without buckets  since there will be no probability of information being
leaked due to bucket overﬂow.
Another way we could possibly improve the communication and computation complexities of the
protocol is by reducing the number of bits used to represent each feature albeit at the cost of increasing
the probability of collisions (different features being mapped into the same bit strings). We used 13
bits for representing unigrams and 17 bits for representing unigrams and bigrams. We did not observe
any collisions.

7https://bitbucket.org/uwtppml

7

Finally  we note that if the protocol is to be deployed over a wide area network  rather than a local
area network  Yao garbled circuits would become a preferable choice for the round intensive parts of
our solution (such as in the private feature extraction part).

5 Related work

The interest in privacy-preserving machine learning (PPML) has grown substantially over the last
decade. The best-known results in PPML are based on differential privacy (DP)  a technique that
relies on adding noise to answers  to prevent an adversary from learning information about any
particular individual in the dataset from revealed aggregate statistics [30]. While DP in an ML setting
aims at protecting the privacy of individuals in the training dataset  our focus is on protecting the
privacy of new user data that is classiﬁed with proprietary ML models. To this end  we use Secure
Multiparty Computation (SMC) [16]  a technique in cryptography that has successfully been applied
to various ML tasks with structured data (see e.g. [14  19  21  40] and references therein).
To the best of our knowledge there are no existing DP or SMC based solutions for PP feature
extraction and classiﬁcation of unstructured texts. Defenses against authorship attribution attacks that
fulﬁll DP in text classiﬁcation have been proposed [53]. These methods rely on distortion of term
frequency vectors and result in loss of accuracy. In this paper we address a different challenge: we
assume that Bob knows Alice  so no authorship obfuscation is needed. Instead  we want to process
Alice’s text with Bob’s classiﬁer  without Bob learning what Alice wrote  and without accuracy loss.
To the best of our knowledge  Costantino et al. [15] were the ﬁrst to propose PP feature extraction
from text. In their solution  which is based on homomorphic encryption (HE)  Bob learns which of
his lexicon’s words are present in Alice’s tweets  and classiﬁcation of a single tweet with a model
with less than 20 features takes 19 minutes. Our solution does not leak any information about Alice’s
words to Bob  and classiﬁcation is done in seconds  even for a model with 500 features.
Below we present existing work that is related to some of the building blocks we use in our PP text
classiﬁcation protocol (see Section 3.1).
Private equality tests have been proposed in the literature based on several different ﬂavors [3]. They
can be based on Yao Gates  Homomorphic Encryption  and generic SMC [52]. In our case  we
have chosen a simple protocol that depends solely on additions and multiplications over a binary
ﬁeld. While different (and possibly more efﬁcient) comparison protocols could be used instead  they
would either require additional computational assumptions or present a marginal improvement in
performance for the parameters used here.
Our private feature extraction can be seen as a particular case of private set intersection (PSI). PSI
is the problem of securely computing the intersection of two sets without leaking any information
except (possibly) the result  such as identifying the intersection of the set of words in a user’s text
message with the hate speech lexicon used by the classiﬁer. Several paradigms have been proposed to
realize PSI functionality  including a Naive hashing solution  Server-aided PSI  and PSI based on
oblivious transfer extension. For a complete survey  we refer to Pinkas et al. [45]. In our protocol for
PP text classiﬁcation  we implement private feature extraction by a straightforward application of
our equality test protocol. While more efﬁcient protocols could be obtained by using sophisticated
hashing techniques  we have decided to stick with our direct solution since it has no probability of
failure and works well for the input sizes needed in our problem. For larger input sizes  a more
sophisticated protocol would be a better choice [45].
We use two protocols for the secure classiﬁcation of feature vectors: an existing protocol ⇡LR for
secure classiﬁcation with LR models [19]; and a novel secure AdaBoost classiﬁcation protocol. The
logistic regression protocol uses solely additions and multiplications over a ﬁnite ﬁeld. The secure
AdaBoost classiﬁcation protocol is an novel optimized protocol that uses solely decision trees of
depth one  binary features and a binary output. All these characteristics were used in order to speed
up the resulting protocol. The ﬁnal secure AdaBoost classiﬁcation protocol uses only two secure
inner products and one secure comparison.
Generic protocols for private scoring of machine learning models have been proposed in [8]. The
solutions proposed in [8] cannot be used in our setting since they assume that the features’ description
are publicly known  and thus can be computed locally by Alice and Bob. However  in our case  the
features themselves are part of the model and cannot be made public.

8

Finally  we note that while we implemented our protocols using our own framework for privacy-
preserving machine learning 8  any other generic framework for SMC could be also used in principle
[47  22  41].

6 Conclusion

In this paper we have presented the ﬁrst provably secure method for privacy-preserving (PP) classiﬁ-
cation of unstructured text. We have provided an analysis of the correctness and security of solution.
As a side result  we also present a novel protocol for binary classiﬁcation over binary input features
with an ensemble of decisions stumps. An implementation of the protocols in Java  run on AWS
machines  allowed us to classify text messages securely within seconds. It is important to note that
this run time (1) includes both secure feature extraction and secure classiﬁcation of the extracted
feature vector; (2) includes both computation and communication costs  as the parties involved in the
protocol were run on separate machines; (3) is two orders of magnitude better than the only other
existing solution  which is based on HE. Our results show that in order to make PP text classiﬁcation
practical  one needs to pay close attention not only to the underlying cryptographic protocols but
also to the underlying ML algorithms. ML algorithms that would be a clear choice when used in the
clear might not be useful at all when transferred to the SMC domain. One has to optimize these ML
algorithms having in mind their use within SMC protocols. Our results provide the ﬁrst evidence that
provably secure PP text classiﬁcation is feasible in practice.

8https://bitbucket.org/uwtppml

9

Tracking terrorists online might

invade your privacy.

BBC 

References
[1] Peter Ray Allison.

http://www.bbc.com/future/story/20170808-tracking-terrorists-online-might-invade-your-
privacy  2017.

[2] Tiago A. Almeida  José María G. Hidalgo  and Akebo Yamakami. Contributions to the study
of SMS spam ﬁltering: new collection and results. In Proc. of the 11th ACM Symposium on
Document Engineering  pages 259–262  2011.

[3] Nuttapong Attrapadung  Goichiro Hanaoka  Shinsaku Kiyomoto  Tomoaki Mimoto  and Ja-
cob CN Schuldt. A taxonomy of secure two-party comparison protocols and efﬁcient construc-
tions. In 15th Annual Conference on Privacy  Security and Trust (PST)  2017.

[4] Boaz Barak  Ran Canetti  Jesper Buus Nielsen  and Rafael Pass. Universally composable

protocols with relaxed set-up assumptions. In FOCS 2004  pages 186–195  2004.

[5] Paulo S. L. M. Barreto  Bernardo David  Rafael Dowsley  Kirill Morozov  and Anderson C. A.
Nascimento. A framework for efﬁcient adaptively secure composable oblivious transfer in
the ROM. Cryptology ePrint Archive  Report 2017/993  2017. http://eprint.iacr.org/
2017/993.

[6] Valerio Basile  Cristina Bosco  Elisabetta Fersini  Debora Nozza  Viviana Patti  Francisco
Rangel  Paolo Rosso  and Manuela Sanguinetti. Semeval-2019 Task 5: Multilingual detection
of hate speech against immigrants and women in Twitter. In Proc. of the 13th International
Workshop on Semantic Evaluation (SemEval-2019). ACL  2019.

[7] Donald Beaver. Commodity-based cryptography (extended abstract). In STOC 1997  pages

446–455  1997.

[8] Raphael Bost  Raluca Ada Popa  Stephen Tu  and Shaﬁ Goldwasser. Machine learning classiﬁ-

cation over encrypted data. In NDSS  volume 4324  page 4325  2015.

[9] Ran Canetti. Universally composable security: A new paradigm for cryptographic protocols. In

FOCS 2001  pages 136–145  2001.

[10] Ran Canetti and Marc Fischlin. Universally composable commitments. In Crypto 2001  pages

19–40  2001.

[11] Ran Canetti  Yehuda Lindell  Rafail Ostrovsky  and Amit Sahai. Universally composable

two-party and multi-party secure computation. In STOC 2002  pages 494–503  2002.

[12] J. Lawrence Carter and Mark N. Wegman. Universal classes of hash functions. Journal of

Computer and System Sciences  18(2):143–154  1979.

[13] Michele Ciampi and Claudio Orlandi. Combining private set-intersection with secure two-party

computation. In SCN 2018  pages 464–482  2018.

[14] Chris Clifton  Murat Kantarcioglu  Jaideep Vaidya  Xiaodong Lin  and Michael Y. Zhu. Tools for
privacy preserving distributed data mining. ACM SIGKDD Explorations Newsletter  4(2):28–34 
2002.

[15] Gianpiero Costantino  Antonio La Marra  Fabio Martinelli  Andrea Saracino  and Mina Sheikhal-
ishahi. Privacy-preserving text mining as a service. In 2017 IEEE Symposium on Computers
and Communications (ISCC)  pages 890–897  2017.

[16] Ronald Cramer  Ivan Damgård  and Jesper Buus Nielsen. Secure Multiparty Computation and

Secret Sharing. Cambridge University Press  2015.

[17] Bernardo David  Rafael Dowsley  Raj Katti  and Anderson CA Nascimento. Efﬁcient uncondi-
tionally secure comparison and privacy preserving machine learning classiﬁcation protocols. In
International Conference on Provable Security  pages 354–367. Springer  2015.

10

[18] Bernardo David  Rafael Dowsley  Jeroen van de Graaf  Davidson Marques  Anderson C. A.
Nascimento  and Adriana C. B. Pinto. Unconditionally secure  universally composable privacy
preserving linear algebra. IEEE Transactions on Information Forensics and Security  11(1):59–
73  2016.

[19] Martine De Cock  Rafael Dowsley  Caleb Horst  Raj Katti  Anderson Nascimento  Wing-Sea
Poon  and Stacey Truex. Efﬁcient and private scoring of decision trees  support vector machines
and logistic regression models based on pre-computation. IEEE Transactions on Dependable
and Secure Computing  16(2):217–230  2019.

[20] Martine De Cock  Rafael Dowsley  Anderson C. A. Nascimento  and Stacey C. Newman. Fast 
privacy preserving linear regression over distributed datasets based on pre-distributed data. In
8th ACM Workshop on Artiﬁcial Intelligence and Security (AISec)  pages 3–14  2015.

[21] Sebastiaan de Hoogh  Berry Schoenmakers  Ping Chen  and Harm op den Akker. Practical
secure decision tree learning in a teletreatment application. In International Conference on
Financial Cryptography and Data Security  pages 179–194. Springer  2014.

[22] Daniel Demmler  Thomas Schneider  and Michael Zohner. Aby-a framework for efﬁcient

mixed-protocol secure two-party computation. In NDSS  2015.

[23] Nico Döttling  Daniel Kraschewski  and Jörn Müller-Quade. Unconditional and composable

security using a single stateful tamper-proof hardware token. pages 164–181.

[24] Rafael Dowsley. Cryptography Based on Correlated Data: Foundations and Practice. PhD

thesis  Karlsruhe Institute of Technology  Germany  2016.

[25] Rafael Dowsley  Jörn Müller-Quade  and Anderson C. A. Nascimento. On the possibility of
universally composable commitments based on noisy channels. In SBSEG 2008  pages 103–114 
Gramado  Brazil  September 1–5  2008.

[26] Rafael Dowsley  Jörn Müller-Quade  and Tobias Nilges. Weakening the isolation assumption of

tamper-proof hardware tokens. In ICITS 2015  pages 197–213  2015.

[27] Rafael Dowsley  Jörn Müller-Quade  Akira Otsuka  Goichiro Hanaoka  Hideki Imai  and
Anderson C. A. Nascimento. Universally composable and statistically secure veriﬁable secret
sharing scheme based on pre-distributed data. IEICE Transactions  94-A(2):725–734  2011.

[28] Rafael Dowsley  Jeroen Van De Graaf  Davidson Marques  and Anderson CA Nascimento. A
two-party protocol with trusted initializer for computing the inner product. In International
Workshop on Information Security Applications  pages 337–350. Springer  2010.

[29] Rafael Dowsley  Jeroen van de Graaf  Jörn Müller-Quade  and Anderson C. A. Nascimento.
On the composability of statistically secure bit commitments. Journal of Internet Technology 
14(3):509–516  2013.

[30] Cynthia Dwork. Differential privacy: A survey of results. In International Conference on

Theory and Applications of Models of Computation  pages 1–19. Springer  2008.

[31] Brett Hemenway Falk  Daniel Noble  and Rafail Ostrovsky. Private set intersection with linear
communication from general assumptions. Cryptology ePrint Archive  Report 2018/238  2018.
https://eprint.iacr.org/2018/238.

[32] Golnoosh Farnadi  Geetha Sitaraman  Shanu Sushmita  Fabio Celli  Michal Kosinski  David
Stillwell  Sergio Davalos  Marie-Francine Moens  and Martine De Cock. Computational
personality recognition in social media. User Modeling and User-Adapted Interaction  26(2-
3):109–142  2016.

[33] Kyle Fritchman  Keerthanaa Saminathan  Rafael Dowsley  Tyler Hughes  Martine De Cock 
Anderson Nascimento  and Ankur Teredesai. Privacy-preserving scoring of tree ensembles: A
novel framework for AI in healthcare. In Proc. of 2018 IEEE International Conference on Big
Data  pages 2412–2421  2018.

11

[34] Juan A. Garay  Berry Schoenmakers  and José Villegas. Practical and secure solutions for

integer comparison. In PKC 2007  pages 330–342  2007.

[35] Tommi Gröndahl  Luca Pajola  Mika Juuti  Mauro Conti  and N. Asokan. All you need is “love”:
Evading hate-speech detection. In Proc. of the 11th ACM Workshop on Artiﬁcial Intelligence
and Security (AISec)  2018.

[36] Dennis Hofheinz and Jörn Müller-Quade. Universally composable commitments using random

oracles. In TCC 2004  pages 58–76  2004.

[37] Dennis Hofheinz  Jörn Müller-Quade  and Dominique Unruh. Universally composable zero-

knowledge arguments and commitments from signature cards. In MoraviaCrypt 2005  2005.

[38] Yuval Ishai  Eyal Kushilevitz  Sigurd Meldgaard  Claudio Orlandi  and Anat Paskin-Cherniavsky.
On the power of correlated randomness in secure computation. In Theory of Cryptography 
pages 600–620. Springer  2013.

[39] Jonathan Katz. Universally composable multi-party computation using tamper-proof hardware.

In Eurocrypt 2007  pages 115–128  2007.

[40] Selim V Kaya  Thomas B Pedersen  Erkay Sava¸s  and Yücel Saygı`yn. Efﬁcient privacy preserv-
ing distributed clustering based on secret sharing. In Paciﬁc-Asia Conference on Knowledge
Discovery and Data Mining  pages 280–291. Springer  2007.

[41] Payman Mohassel and Yupeng Zhang. Secureml: A system for scalable privacy-preserving
machine learning. In 2017 IEEE Symposium on Security and Privacy (SP)  pages 19–38. IEEE 
2017.

[42] Bridianne O’Dea  Stephen Wan  Philip J. Batterham  Alison L. Calear  Cecile Paris  and Helen

Christensen. Detecting suicidality on Twitter. Internet Interventions  2(2):183–188  2015.

[43] Chris Peikert  Vinod Vaikuntanathan  and Brent Waters. A framework for efﬁcient and compos-

able oblivious transfer. In Crypto 2008  pages 554–571  2008.

[44] Wouter Penard and Tim van Werkhoven. On the secure hash algorithm family. In Cryptography

in Context  pages 1–18. 2008.

[45] Benny Pinkas  Thomas Schneider  and Michael Zohner. Scalable private set intersection based

on OT extension. ACM Transactions on Privacy and Security (TOPS)  21(2):7  2018.

[46] Andrew G. Reece  Andrew J. Reagan  Katharina L.M. Lix  Peter Sheridan Dodds  Christopher M.
Danforth  and Ellen J. Langer. Forecasting the onset and course of mental illness with Twitter
data. Scientiﬁc Reports  7(1):13006  2017.

[47] M Sadegh Riazi  Christian Weinert  Oleksandr Tkachenko  Ebrahim M Songhori  Thomas
Schneider  and Farinaz Koushanfar. Chameleon: A hybrid secure computation framework for
machine learning applications. In Proceedings of the 2018 on Asia Conference on Computer
and Communications Security  pages 707–721. ACM  2018.

[48] Ronald L. Rivest.

Unconditionally secure commitment and oblivious

schemes using private channels and a trusted initializer.
http://people.csail.mit.edu/rivest/Rivest- commitment.pdf  1999.

transfer
Preprint available at

[49] Mehran Sahami  Susan Dumais  David Heckerman  and Eric Horvitz. A Bayesian approach
to ﬁltering junk e-mail. In Learning for Text Categorization: Papers from the 1998 Workshop 
volume 62  pages 98–105  1998.

[50] Rafael Tonicelli  Anderson C. A. Nascimento  Rafael Dowsley  Jörn Müller-Quade  Hideki Imai 
Goichiro Hanaoka  and Akira Otsuka. Information-theoretically secure oblivious polynomial
evaluation in the commodity-based model.
International Journal of Information Security 
14(1):73–84  2015.

[51] Cynthia Van Hee  Gilles Jacobs  Chris Emmery  Bart Desmet  Els Lefever  Ben Verhoeven  Guy
De Pauw  Walter Daelemans  and Véronique Hoste. Automatic detection of cyberbullying in
social media text. PloS one  13(10):e0203794  2018.

12

[52] Thijs Veugen  Frank Blom  Sebastiaan JA de Hoogh  and Zekeriya Erkin. Secure comparison
protocols in the semi-honest model. IEEE Journal of Selected Topics in Signal Processing 
9(7):1217–1228  2015.

[53] Benjamin Weggenmann and Florian Kerschbaum. SynTF: Synthetic and differentially private
term frequency vectors for privacy-preserving text mining. In 41st International ACM SIGIR
Conference on Research & Development in Information Retrieval  pages 305–314  2018.

13

,Audrunas Gruslys
Remi Munos
Ivo Danihelka
Marc Lanctot
Alex Graves
Devin Reich
Ariel Todoki
Rafael Dowsley
Martine De Cock
anderson nascimento