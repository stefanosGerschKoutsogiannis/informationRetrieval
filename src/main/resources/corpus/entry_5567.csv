2016,Tight Complexity Bounds for Optimizing Composite Objectives,We provide tight upper and lower bounds on the complexity of minimizing the average of m convex functions using gradient and prox oracles of the component functions. We show a significant gap between the complexity of deterministic vs randomized optimization. For smooth functions  we show that accelerated gradient descent (AGD) and an accelerated variant of SVRG are optimal in the deterministic and randomized settings respectively  and that a gradient oracle is sufficient for the optimal rate. For non-smooth functions  having access to prox oracles reduces the complexity and we present optimal methods based on smoothing that improve over methods using just gradient accesses.,Tight Complexity Bounds for Optimizing Composite

Objectives

Toyota Technological Institute at Chicago

Toyota Technological Institute at Chicago

Blake Woodworth

Chicago  IL  60637
blake@ttic.edu

Nathan Srebro

Chicago  IL  60637
nati@ttic.edu

Abstract

We provide tight upper and lower bounds on the complexity of minimizing the
average of m convex functions using gradient and prox oracles of the component
functions. We show a signiﬁcant gap between the complexity of deterministic vs
randomized optimization. For smooth functions  we show that accelerated gradi-
ent descent (AGD) and an accelerated variant of SVRG are optimal in the deter-
ministic and randomized settings respectively  and that a gradient oracle is sufﬁ-
cient for the optimal rate. For non-smooth functions  having access to prox oracles
reduces the complexity and we present optimal methods based on smoothing that
improve over methods using just gradient accesses.

Introduction

1
We consider minimizing the average of m  2 convex functions:
fi(x))

x2X(F (x) :=

1
m

min

mXi=1

where

(1)

(3)

where X✓ Rd is a closed  convex set  and where the algorithm is given access to the following
gradient (or subgradient in the case of non-smooth functions) and prox oracle for the components:
(2)

hF (x  i  ) =⇥fi(x)  rfi(x)  proxfi(x  )⇤
2 kx  uk2

u2X ⇢fi(u) +

proxfi(x  ) = arg min



A natural question is how to leverage the prox oracle  and how much beneﬁt it provides over gradient
access alone. The prox oracle is potentially much more powerful  as it provides global  rather then
local  information about the function. For example  for a single function (m = 1)  one prox oracle
call (with  = 0) is sufﬁcient for exact optimization. Several methods have recently been suggested
for optimizing a sum or average of several functions using prox accesses to each component  both in
the distributed setting where each components might be handled on a different machine (e.g. ADMM
[7]  DANE [18]  DISCO [20]) or for functions that can be decomposed into several “easy” parts
(e.g. PRISMA [13]). But as far as we are aware  no meaningful lower bound was previously known
on the number of prox oracle accesses required even for the average of two functions (m = 2).
The optimization of composite objectives of the form (1) has also been extensively studied in the
context of minimizing empirical risk over m samples. Recently  stochastic methods such as SDCA
[16]  SAG [14]  SVRG [8]  and other variants  have been presented which leverage the ﬁnite nature
of the problem to reduce the variance in stochastic gradient estimates and obtain guarantees that
dominate both batch and stochastic gradient descent. As methods with improved complexity  such

30th Conference on Neural Information Processing Systems (NIPS 2016)  Barcelona  Spain.

Convex 
kxk  B

mLB

✏

(Section 3)

mLB

✏

(Section 4)

L-Lipschitz

-Strongly

Convex
mLp✏

(Section 3)

mLp✏

(Section 4)

r
e
p
p
U

c
i
t
s
i
n
i
m
r
e
t
e
D

d
e
z
i
m
o
d
n
a
R

r
e
w
o
L
r L2B2
e
p
p
U
r L2B2
e
w
o
L

✏2 ^⇣m log 1
✏2 ^⇣m+

(Section 5)

(SGD  A-SVRG)

✏ +

pmLB

✏ ⌘
✏ ⌘

pmLB

✏ +

(SGD  A-SVRG)

L2

✏^⇣m log 1
✏ ^⇣m+

L2

pmLp✏⌘ m log ✏0
pmLp✏⌘

(Section 5)

-Smooth

Convex 
kxk  B

(Section 4)

✏
(AGD)

mq B 2
mq B 2
✏ +qmB2
m +q mB2

✏
(Section 5)

(A-SVRG)

✏

✏

-Strongly
Convex

 log ✏0
(AGD)

✏

 log ✏0

✏

(Section 4)

mp 
mp 
m+pm
m +p m

(Section 5)

(A-SVRG)

 log ✏0

✏

 log ✏0

✏

Table 1: Upper and lower bounds on the number of grad-and-prox oracle accesses needed to ﬁnd ✏-suboptimal
solutions for each function class. These are exact up to constant factors except for the lower bounds for smooth

and strongly convex functions  which hide extra log / and logpm/ factors for deterministic and ran-

domized algorithms. Here  ✏0 is the suboptimality of the point 0.

as accelerated SDCA [17]  accelerated SVRG  and KATYUSHA [3]  have been presented  researchers
have also tried to obtain lower bounds on the best possible complexity in this settings—but as we
survey below  these have not been satisfactory so far.
In this paper  after brieﬂy surveying methods for smooth  composite optimization  we present meth-
ods for optimizing non-smooth composite objectives  which show that prox oracle access can indeed
be leveraged to improve over methods using merely subgradient access (see Section 3). We then
turn to studying lower bounds. We consider algorithms that access the objective F only through
the oracle hF and provide lower bounds on the number of such oracle accesses (and thus the run-
time) required to ﬁnd ✏-suboptimal solutions. We consider optimizing both Lipschitz (non-smooth)
functions and smooth functions  and guarantees that do and do not depend on strong convexity  dis-
tinguishing between deterministic optimization algorithms and randomized algorithms. Our upper
and lower bounds are summarized in Table 1.
As shown in the table  we provide matching upper and lower bounds (up to a log factor) for all
function and algorithm classes. In particular  our bounds establish the optimality (up to log fac-
tors) of accelerated SDCA  SVRG  and SAG for randomized ﬁnite-sum optimization  and also the
optimality of our deterministic smoothing algorithms for non-smooth composite optimization.

On the power of gradient vs prox oracles For non-smooth functions  we show that having access
to prox oracles for the components can reduce the polynomial dependence on ✏ from 1/✏2 to 1/✏  or
from 1/(✏) to 1/p✏ for -strongly convex functions. However  all of the optimal complexities for
smooth functions can be attained with only component gradient access using accelerated gradient
descent (AGD) or accelerated SVRG. Thus the worst-case complexity cannot be improved (at least
not signiﬁcantly) by using the more powerful prox oracle.

On the power of randomization We establish a signiﬁcant gap between deterministic and ran-
domized algorithms for ﬁnite-sum problems. Namely  the dependence on the number of components
must be linear in m for any deterministic algorithm  but can be reduced to pm (in the typically
signiﬁcant term) using randomization. We emphasize that the randomization here is only in the
algorithm—not in the oracle. We always assume the oracle returns an exact answer (for the re-
quested component) and is not a stochastic oracle. The distinction is that the algorithm is allowed
to ﬂip coins in deciding what operations and queries to perform but the oracle must return an exact
answer to that query (of course  the algorithm could simulate a stochastic oracle).

Prior Lower Bounds Several authors recently presented lower bounds for optimizing (1) in the
smooth and strongly convex setting using component gradients. Agarwal and Bottou [1] presented

a lower bound of ⌦m +p m

rithms (thus not including SDCA  SVRG  SAG  etc.)—we not only consider randomized algorithms 
but also show a much higher lower bound for deterministic algorithms (i.e. the bound of Agarwal

✏. However  their bound is valid only for deterministic algo-

 log 1

2

and Bottou is loose). Improving upon this  Lan [9] shows a similar lower bound for a restricted
class of randomized algorithms: the algorithm must select which component to query for a gradient
by drawing an index from a ﬁxed distribution  but the algorithm must otherwise be deterministic
in how it uses the gradients  and its iterates must lie in the span of the gradients it has received.
This restricted class includes SAG  but not SVRG nor perhaps other realistic attempts at improving
over these. Furthermore  both bounds allow only gradient accesses  not prox computations. Thus
SDCA  which requires prox accesses  and potential variants are not covered by such lower bounds.
We prove as similar lower bound to Lan’s  but our analysis is much more general and applies to any
randomized algorithm  making any sequence of queries to a gradient and prox oracle  and without
assuming that iterates lie in the span of previous responses. In addition to smooth functions  we
also provide lower bounds for non-smooth problems which were not considered by these previous
attempts. Another recent observation [15] was that with access only to random component subgradi-
ents without knowing the component’s identity  an algorithm must make ⌦(m2) queries to optimize
well. This shows how relatively subtle changes in the oracle can have a dramatic effect on the com-
plexity of the problem. Since the oracle we consider is quite powerful  our lower bounds cover a
very broad family of algorithms  including SAG  SVRG  and SDCA.
Our deterministic lower bounds are inspired by a lower bound on the number of rounds of communi-
cation required for optimization when each fi is held by a different machine and when iterates lie in
the span of certain permitted calculations [5]. Our construction for m = 2 is similar to theirs (though
in a different setting)  but their analysis considers neither scaling with m (which has a different role
in their setting) nor randomization.
Notation and Deﬁnitions We use k·k to denote the standard Euclidean norm on Rd. We say that
a function f is L-Lipschitz continuous on X if 8x  y 2X | f (x)  f (x)| Lkx  yk; -smooth
on X if it is differentiable and its gradient is -Lipschitz on X ; and -strongly convex on X if
2 kx  yk2. We consider optimizing (1) under
8x  y 2X
four combinations of assumptions: each component fi is either L-Lipschitz or -smooth  and either
F (x) is -strongly convex or its domain is bounded  X✓{ x : kxk  B}.
2 Optimizing Smooth Sums
We brieﬂy review the best known methods for optimizing (1) when the components are -smooth 
yielding the upper bounds on the right half of Table 1. These upper bounds can be obtained using
only component gradient access  without need for the prox oracle.
We can obtain exact gradients of F (x) by computing all m component gradients rfi(x). Running
accelerated gradient descent (AGD) [12] on F (x) using these exact gradients achieves the upper
complexity bounds for deterministic algorithms and smooth problems (see Table 1).
SAG [14]  SVRG [8] and related methods use randomization to sample components  but also lever-
age the ﬁnite nature of the objective to control the variance of the gradient estimator used. Ac-
celerating these methods using the Catalyst framework [10] ensures that for -strongly convex ob-

fi(y)  fi(x) + hrfi(x)  y  xi + 

jectives we have E⇥F (x(k))  F (x⇤)⇤ <✏ after k = Om +p m
✏ iterations  where
  log2 ✏0
F (0)  F (x⇤) = ✏0. KATYUSHA [3] is a more direct approach to accelerating SVRG which avoids
  log ✏0
extraneous log-factors  yielding the complexity k = Om +p m
✏ indicated in Table 1.
When F is not strongly convex  adding a regularizer to the objective and instead optimizing F(x) =
✏ ◆ log ✏0
✏◆.
F (x) + 
The log-factor in the second term can be removed using the more delicate reduction of Allen-Zhu
and Hazan [4]  which involves optimizing F(x) for progressively smaller values of   yielding the
upper bound in the table.
KATYUSHA and Catalyst-accelerated SAG or SVRG use only gradients of the components. Accel-
erated SDCA [17] achieves a similar complexity using gradient and prox oracle access.

2 kxk2 with  = ✏/B2 results in an oracle complexity of O✓✓m +q mB2

3 Leveraging Prox Oracles for Lipschitz Sums
In this section  we present algorithms for leveraging the prox oracle to minimize (1) when each
component is L-Lipschitz. This will be done by using the prox oracle to “smooth” each component 

3

and optimizing the new  smooth sum which approximates the original problem. This idea was used
in order to apply KATYUSHA [3] and accelerated SDCA [17] to non-smooth objectives. We are not
aware of a previous explicit presentation of the AGD-based deterministic algorithm  which achieves
the deterministic upper complexity indicated in Table 1.
The key is using a prox oracle to obtain gradients of the -Moreau envelope of a non-smooth func-
tion  f  deﬁned as:

f ()(x) = inf
u2X

f (u) +


2 kx  uk2

(4)

Lemma 1 ([13  Lemma 2.2]  [6  Proposition 12.29]  following [11]). Let f be convex and L-
Lipschitz continuous. For any > 0 

1. f () is -smooth
2. r(f ())(x) = (x  proxf (x  ))
3. f ()(x)  f (x)  f ()(x) + L2

2

Consequently  we can consider the smoothed problem

x2X( ˜F ()(x) :=

min

1
m

mXi=1

(x)) .

f ()
i

(5)

pmLB

✏

✏ +

✏ +

⌘ and O⇣m log ✏0

deterministic setting. When the functions are -strongly convex  smoothing with a ﬁxed  results in
a spurious log-factor. To avoid this  we again apply the reduction of Allen-Zhu and Hazan [4]  this

when used with AGD (see Appendix A for details).
Similarly  we can apply an accelerated randomized algorithm (such as KATYUSHA) to the smooth

While ˜F () is not  in general  the -Moreau envelope of F   it is -smooth  we can calculate the
gradient of its components using the oracle hF   and ˜F ()(x)  F (x)  ˜F ()(x) + L2
2 . Thus 
to obtain an ✏-suboptimal solution to (1) using hF   we set  = L2/✏ and apply any algorithm
which can optimize (5) using gradients of the L2/✏-smooth components  to within ✏/2 accuracy.
With the rates presented in Section 2  using AGD on (5) yields a complexity of O mLB
✏  in the
time optimizing ˜F () for increasingly large values of . This leads to the upper bound of O⇣ mLp✏⌘
pmLp✏⌘—this
problem ˜F () to obtain complexities of O⇣m log ✏0
matches the presentation of Allen-Zhu [3] and is similar to that of Shalev-Shwartz and Zhang [17].
Finally  if m > L2B2/✏2 or m > L2/(✏)  stochastic gradient descent is a better randomized
alternative  yielding complexities of O(L2B2/✏2) or O(L2/(✏)).
4 Lower Bounds for Deterministic Algorithms
We now turn to establishing lower bounds on the oracle complexity of optimizing (1). We ﬁrst
consider only deterministic optimization algorithms. What we would like to show is that for any
deterministic optimization algorithm we can construct a “hard” function for which the algorithm
cannot ﬁnd an ✏-suboptimal solution until it has made many oracle accesses. Since the algorithm
is deterministic  we can construct such a function by simulating the (deterministic) behavior of the
algorithm. This can be viewed as a game  where an adversary controls the oracle being used by
the algorithm. At each iteration the algorithm queries the oracle with some triplet (x  i  ) and
the adversary responds with an answer. This answer must be consistent with all previous answers 
but the adversary ensures it is also consistent with a composite function F that the algorithm is
far from optimizing. The “hard” function is then gradually deﬁned in terms of the behavior of the
optimization algorithm.
To help us formulate our constructions  we deﬁne a “round” of queries as a series of queries in which
2 e distinct functions fi are queried. The ﬁrst round begins with the ﬁrst query and continues until
d m
2 e unique functions have been queried. The second round begins with the next query  and
exactly d m
continues until exactly d m
2 e more distinct components have been queried in the second round  and so
on until the algorithm terminates. This deﬁnition is useful for analysis but requires no assumptions
about the algorithm’s querying strategy.

4

4.1 Non-Smooth Components
We begin by presenting a lower bound for deterministic optimization of (1) when each component
fi is convex and L-Lipschitz continuous  but is not necessarily strongly convex  on the domain
X = {x : kxk  B}. Without loss of generality  we can consider L = B = 1. We will construct
functions of the following form:

fi(x) =

1
p2 |b  hx  v0i| +

1
2pk

i r |hx  vr1i  hx  vri| .

(6)

kXr=1

where k = b 1
12✏c  b = 1pk+1  and {vr} is an orthonormal set of vectors in Rd chosen according to
the behavior of the algorithm such that vr is orthogonal to all points at which the algorithm queries
hF before round r  and where i r are indicators chosen so that i r = 1 if the algorithm does
not query component i in round r (and zero otherwise). To see how this is possible  consider the
following truncations of (6):

f t
i (x) =

1
p2 |b  hx  v0i| +

1
2pk

t1Xr=1

i r |hx  vr1i  hx  vri|

(7)

i

i are consistent with fi.

During each round t  the adversary answers queries according to f t
i   which depends only on vr  i r
for r < t  i.e. from previous rounds. When the round is completed  i t is determined and vt is
chosen to be orthogonal to the vectors {v0  ...  vt1} as well as every point queried by the algorithm
so far  thus deﬁning f t+1
for the next round. In Appendix B.1 we prove that these responses based
on f t
The algorithm can only learn vr after it completes round r—until then every iterate is orthogonal
to it by construction. The average of these functions reaches its minimum of F (x⇤) = 0 at x⇤ =
bPk
r=0 vr  so we can view optimizing these functions as the task of discovering the vectors vr—
even if only vk is missing  a suboptimality better than b/(6pk) >✏ cannot be achieved. Therefore 
the deterministic algorithm must complete at least k rounds of optimization  each comprising at
2⌥ queries to hF in order to optimize F . The key to this construction is that even though
least⌃ m
each term |hx  vr1i  hx  vri| appears in m/2 components  and hence has a strong effect on the
average F (x)  we can force a deterministic algorithm to make ⌦(m) queries during each round
before it ﬁnds the next relevant term. We obtain (for complete proof see Appendix B.1):
Theorem 1. For any L  B > 0  any 0 <✏< LB
12   any m  2  and any deterministic algorithm
✏   and m functions fi deﬁned over
A with access to hF   there exists a dimension d = O mLB
X =x 2 Rd : kxk  B   which are convex and L-Lipschitz continuous  such that in order to ﬁnd
a point ˆx for which F (ˆx)  F (x⇤) <✏   A must make ⌦ mLB
✏  queries to hF .
Furthermore  we can always reduce optimizing a function over kxk  B to optimizing a strongly
convex function by adding the regularizer ✏kxk2 /(2B2) to each component  implying (see complete
proof in Appendix B.2):
Theorem 2. For any L   > 0  any 0 <✏<
288  any m  2  and any deterministic algorithm
A with access to hF   there exists a dimension d = O⇣ mLp✏⌘  and m functions fi deﬁned over
X✓ Rd  which are L-Lipschitz continuous and -strongly convex  such that in order to ﬁnd a point
ˆx for which F (ˆx)  F (x⇤) <✏   A must make ⌦⇣ mLp✏⌘ queries to hF .

4.2 Smooth Components
When the components fi are required to be smooth  the lower bound construction is similar to (6) 
except it is based on squared differences instead of absolute differences. We consider the functions:

L2

1

8 i 1⇣hx  v0i2  2ahx  v0i⌘ + i k hx  vki2 +

kXr=1

i r (hx  vr1i  hx  vri)2! (8)

where i r and vr are as before. Again  we can answer queries at round t based only on i r  vr for
r < t. This construction yields the following lower bounds (full details in Appendix B.3):

fi(x) =

5

 log⇣ ✏0

Theorem 3. For any   B  ✏ > 0  any m  2  and any deterministic algorithm A with access to
hF   there exists a sufﬁciently large dimension d = OmpB 2/✏  and m functions fi deﬁned
over X =x 2 Rd : kxk  B   which are convex and -smooth  such that in order to ﬁnd a point
ˆx 2 Rd for which F (ˆx)  F (x⇤) <✏   A must make ⌦mpB 2/✏ queries to hF .
In the strongly convex case  we use a very similar construction  adding the term kxk2 /2  which
gives the following bound (see Appendix B.4):
Theorem 4. For any    > 0 such that 
   any m  2  and
any deterministic algorithm A with access to hF   there exists a sufﬁciently large dimension d =
✏⌘⌘  and m functions fi deﬁned over X✓ Rd  which are -smooth and -
strongly convex and where F (0)  F (x⇤) = ✏0  such that in order to ﬁnd a point ˆx for which

 > 73  any ✏> 0  any ✏0 > 3✏

 log⇣ ✏0

O⇣mp 
F (ˆx)  F (x⇤) <✏   A must make ⌦⇣mp 

✏⌘⌘ queries to hF .

5 Lower Bounds for Randomized Algorithms
We now turn to randomized algorithms for (1). In the deterministic constructions  we relied on
being able to set vr and i r based on the predictable behavior of the algorithm. This is impossible
for randomized algorithms  we must choose the “hard” function before we know the random choices
the algorithm will make—so the function must be “hard” more generally than before.
Previously  we chose vectors vr orthogonal to all previous queries made by the algorithm. For ran-
domized algorithms this cannot be ensured. However  if we choose orthonormal vectors vr randomly
in a high dimensional space  they will be nearly orthogonal to queries with high probability. Slightly
modifying the absolute or squared difference from before makes near orthogonality sufﬁcient. This
issue increases the required dimension but does not otherwise affect the lower bounds.
More problematic is our inability to anticipate the order in which the algorithm will query the com-
ponents  precluding the use of i r. In the deterministic setting  if a term revealing a new vr appeared
in half of the components  we could ensure that the algorithm must make m/2 queries to ﬁnd it.
However  a randomized algorithm could ﬁnd it in two queries in expectation  which would eliminate
the linear dependence on m in the lower bound! Alternatively  if only one component included the
term  a randomized algorithm would indeed need ⌦(m) queries to ﬁnd it  but that term’s effect on
suboptimality of F would be scaled down by m  again eliminating the dependence on m.
To establish a ⌦(pm) lower bound for randomized algorithms we must take a new approach. We

deﬁne⌅ m

2⇧ pairs of functions which operate on⌅ m

functions resembles the constructions from the previous section  but since there are many of them 
the algorithm must solve ⌦(m) separate optimization problems in order to optimize F .

2⇧ orthogonal subspaces of Rd. Each pair of

5.1 Lipschitz Continuous Components
First consider the non-smooth  non-strongly-convex setting and assume for simplicity m is even
(otherwise we simply let the last function be zero). We deﬁne the helper function c  which replaces
the absolute value operation and makes our construction resistant to small inner products between
iterates and not-yet-discovered components:

 c(z) = max (0 |z| c)
Next  we deﬁne m/2 pairs of functions  indexed by i = 1..m/2:

(9)

(10)

1
2pk

kXr even

 c (hx  vi r1i  hx  vi ri)

fi 1(x) =

1
p2 |b  hx  vi 0i| +
kXr odd

1
2pk

fi 2(x) =

 c (hx  vi r1i  hx  vi ri)
✏pm ). With c sufﬁciently
where {vi r}r=0..k i=1..m/2 are random orthonormal vectors and k =⇥(
small and the dimensionality sufﬁciently high  with high probability the algorithm only learns the

1

6

✏4

1pmk

pmLB

) =⇥( p✏/pm)  and the total number of queries is ⌦(mk) =⌦(

identity of new vectors vi r by alternately querying fi 1 and fi 2; so revealing all k + 1 vectors
requires at least k + 1 total queries. Until vi k is revealed  an iterate is ⌦(✏)-suboptimal on (fi 1 +
fi 2)/2. From here  we show that an ✏-suboptimal solution to F (x) can be found only after at
least k + 1 queries are made to at least m/4 pairs  for a total of ⌦(mk) queries. This time  since
the optimum x⇤ will need to have inner product b with ⇥(mk) vectors vi r  we need to have b =
pm
✏ ). The ⌦(m) term of
⇥(
the lower bound follows trivially since we require ✏ = O(1/pm)  (proofs in Appendix C.1):
Theorem 5. For any L  B > 0  any 0 <✏< LB
10pm  any m  2  and any randomized algorithm A
with access to hF   there exists a dimension d = O⇣ L4B6
✏ ⌘  and m functions fi deﬁned
log LB
over X =x 2 Rd : kxk  B   which are convex and L-Lipschitz continuous  such that to ﬁnd a
 queries to hF .
point ˆx for which E [F (ˆx)  F (x⇤)] <✏   A must make ⌦m +
200m  any m  2  and any randomized algorithm A
with access to hF   there exists a dimension d = O L4
3✏ log Lp✏  and m functions fi deﬁned over
X✓ Rd  which are L-Lipschitz continuous and -strongly convex  such that in order to ﬁnd a point
ˆx for which E [F (ˆx)  F (x⇤)] <✏   A must make ⌦m +

An added regularizer gives the result for strongly convex functions (see Appendix C.2):
Theorem 6. For any L   > 0  any 0 <✏<

pmLp✏ queries to hF .

The large dimension required by these lower bounds is the cost of omitting the assumption that the
algorithm’s queries lie in the span of previous oracle responses. If we do assume that the queries lie
in that span  the necessary dimension is only on the order of the number of oracle queries needed.

When ✏ =⌦( LB/pm) in the non-strongly convex case or ✏ =⌦ L2/(m) in the strongly
convex case  the lower bounds for randomized algorithms presented above do not apply. Instead  we
can obtain a lower bound based on an information theoretic argument. We ﬁrst uniformly randomly
choose a parameter p  which is either (1/2  2✏) or (1/2 + 2✏). Then for i = 1  ...  m  in the non-
strongly convex case we make fi(x) = x with probability p and fi(x) = x with probability 1 p.
Optimizing F (x) to within ✏ accuracy then implies recovering the bias of the Bernoulli random
variable  which requires ⌦(1/✏2) queries based on a standard information theoretic result [2  19].
2 kxk2 gives a ⌦(1/(✏)) lower bound in the -strongly convex setting. This
Setting fi(x) = ±x + 
is formalized in Appendix C.5.

L2

✏

5.2 Smooth Components
When the functions fi are smooth and not strongly convex  we deﬁne another helper function c:

c(z) =8<:

0
2(|z| c)2
z2  2c2

|z| c
c < |z| 2c
|z| > 2c

and the following pairs of functions for i = 1  ...  m/2:

(11)

(12)

fi 1(x) =

fi 2(x) =

1

16✓hx  vi 0i2  2ahx  vi 0i +
16✓c (hx  vi ki) +

1

kXr odd

c (hx  vi r1i  hx  vi ri)◆

kXr even

c (hx  vi r1i  hx  vi ri)◆

with vi r as before. The same arguments apply  after replacing the absolute difference with squared
difference. A separate argument is required in this case for the ⌦(m) term in the bound  which we
show using a construction involving m simple linear functions (see Appendix C.3).
Theorem 7. For any   B  ✏ > 0  any m  2  and any randomized algorithm A with access to hF  
there exists a sufﬁciently large dimension d = O⇣ 2B6
✏ ⌘ + B2m log m⌘ and m functions
fi deﬁned over X =x 2 Rd : kxk  B   which are convex and -smooth  such that to ﬁnd a point
ˆx 2 Rd for which E [F (ˆx)  F (x⇤)] <✏   A must make ⌦✓m +q mB2

✏ ◆ queries to hF .

log⇣ B 2

✏2

7

In the strongly convex case  we add the term kxk2 /2 to fi 1 and fi 2 (see Appendix C.4) to obtain:
Theorem 8. For any m  2  any    > 0 such that 
m  and
any randomized algorithm A  there exists a dimension d = O⇣ 2.5✏0
log m⌘ 
domain X✓ Rd  x0 2X   and m functions fi deﬁned on X which are -smooth and -strongly
convex  and such that F (x0)  F (x⇤) = ✏0 and such that in order to ﬁnd a point ˆx 2X such that
E [F (ˆx)  F (x⇤)] <✏   A must make ⌦⇣m +p m
✏q m

 > 161m  any ✏> 0  any ✏0 > 60✏p 
✏⌘ + m✏0
 log⇣ ✏0

2.5✏ log3⇣ ✏0
 ⌘⌘ queries to hF .

✏

Remark: We consider (1) as a constrained optimization problem  thus the minimizer of F could be
achieved on the boundary of X   meaning that the gradient need not vanish. If we make the additional
assumption that the minimizer of F lies on the interior of X (and is thus the unconstrained global
minimum)  Theorems 1-8 all still apply  with a slight modiﬁcation to Theorems 3 and 7. Since the
gradient now needs to vanish on X   0 is always O(B 2)-suboptimal  and only values of ✏ in the
range 0 <✏< B 2
128 result in a non-trivial lower bound (see Remarks at the end
of Appendices B.3 and C.3).

128 and 0 <✏< 9B 2

6 Conclusion

We provide a tight (up to a log factor) understanding of optimizing ﬁnite sum problems of the form
(1) using a component prox oracle.
Randomized optimization of (1) has been the subject of much research in the past several years  start-
ing with the presentation of SDCA and SAG  and continuing with accelerated variants. Obtaining
lower bounds can be very useful for better understanding the problem  for knowing where it might
or might not be possible to improve or where different assumptions would be needed to improve 
and for establishing optimality of optimization methods. Indeed  several attempts have been made
at lower bounds for the ﬁnite sum setting [1  9]. But as we explain in the introduction  these were
unsatisfactory and covered only limited classes of methods. Here we show that in a fairly general
sense  accelerated SDCA  SVRG  SAG  and KATYUSHA are optimal up to a log factor. Improv-
ing on their runtime would require additional assumptions  or perhaps a stronger oracle. However 
even if given “full” access to the component functions  all algorithms that we can think of utilize
this information to calculate a prox vector. Thus  it is unclear what realistic oracle would be more
powerful than the prox oracle we consider.
Our results highlight the power of randomization  showing that no deterministic algorithm can beat
the linear dependence on m and reduce it to the pm dependence of the randomized algorithms.
The deterministic algorithm for non-smooth problems that we present in Section 3 is also of inter-
est in its own right. It avoids randomization  which is not usually problematic  but makes it fully
parallelizable unlike the optimal stochastic methods. Consider  for example  a supervised learning
problem where fi(x) = `(hi  xi  yi) is the (non-smooth) loss on a single training example (i  yi) 
and the data is distributed across machines. Calculating a prox oracle involves applying the Fenchel
conjugate of the loss function `  but even if a closed form is not available  this is often easy to com-
pute numerically  and is used in algorithms such as SDCA. But unlike SDCA  which is inherently
sequential  we can calculate all m prox operations in parallel on the different machines  average the
resulting gradients of the smoothed function  and take an accelerated gradient step to implement our
optimal deterministic algorithm. This method attains a recent lower bound for distributed optimiza-
tion  resolving a question raised by Arjevani and Shamir [5]  and when the number of machines is
very large improves over all other known distributed optimization methods for the problem.
In studying ﬁnite sum problems  we were forced to explicitly study lower bounds for randomized
optimization as opposed to stochastic optimization (where the source of randomness is the oracle 
not the algorithm). Even for the classic problem of minimizing a smooth function using a ﬁrst order
oracle  we could not locate a published proof that applies to randomized algorithms. We provide a
simple construction using ✏-insensitive differences that allows us to easily obtain such lower bounds
without reverting to assuming the iterates are spanned by previous responses (as was done  e.g.  in
[9])  and could potentially be useful for establishing randomized lower bounds also in other settings.

Acknowledgements: We thank Ohad Shamir for his helpful discussions and for pointing out [4].

8

References
[1] Alekh Agarwal and Leon Bottou. A lower bound for the optimization of ﬁnite sums. arXiv preprint

arXiv:1410.0723  2014.

[2] Alekh Agarwal  Martin J Wainwright  Peter L Bartlett  and Pradeep K Ravikumar. Information-theoretic
lower bounds on the oracle complexity of convex optimization. In Advances in Neural Information Pro-
cessing Systems  pages 1–9  2009.

[3] Zeyuan Allen-Zhu. Katyusha: The ﬁrst truly accelerated stochastic gradient descent. arXiv preprint

arXiv:1603.05953  2016.

[4] Zeyuan Allen-Zhu and Elad Hazan. Optimal black-box reductions between optimization objectives. arXiv

preprint arXiv:1603.05642  2016.

[5] Yossi Arjevani and Ohad Shamir. Communication complexity of distributed convex learning and opti-

mization. In Advances in Neural Information Processing Systems  pages 1747–1755  2015.

[6] Heinz H Bauschke and Patrick L Combettes. Convex analysis and monotone operator theory in Hilbert

spaces. Springer Science & Business Media  2011.

[7] Stephen Boyd  Neal Parikh  Eric Chu  Borja Peleato  and Jonathan Eckstein. Distributed optimization
and statistical learning via the alternating direction method of multipliers. Foundations and Trends R in
Machine Learning  3(1):1–122  2011.

[8] Rie Johnson and Tong Zhang. Accelerating stochastic gradient descent using predictive variance reduc-

tion. In Advances in Neural Information Processing Systems  pages 315–323  2013.

[9] Guanghui Lan. An optimal randomized incremental gradient method. arXiv preprint arXiv:1507.02000 

2015.

[10] Hongzhou Lin  Julien Mairal  and Zaid Harchaoui. A universal catalyst for ﬁrst-order optimization. In

Advances in Neural Information Processing Systems  pages 3366–3374  2015.

[11] Yu Nesterov. Smooth minimization of non-smooth functions. Mathematical programming  103(1):127–

152  2005.

[12] Yurii Nesterov. A method of solving a convex programming problem with convergence rate o (1/k2).

Soviet Mathematics Doklady  27(2):372–376  1983.

[13] Francesco Orabona  Andreas Argyriou  and Nathan Srebro. Prisma: Proximal iterative smoothing algo-

rithm. arXiv preprint arXiv:1206.2372  2012.

[14] Mark Schmidt  Nicolas Le Roux  and Francis Bach. Minimizing ﬁnite sums with the stochastic average

gradient. arXiv preprint arXiv:1309.2388  2013.

[15] Shai Shalev-Shwartz. Stochastic optimization for machine learning. Slides of presentation at “Opti-
mization Without Borders 2016”  http://www.di.ens.fr/~aspremon/Houches/talks/Shai.pdf 
2016.

[16] Shai Shalev-Shwartz and Tong Zhang. Stochastic dual coordinate ascent methods for regularized loss.

The Journal of Machine Learning Research  14(1):567–599  2013.

[17] Shai Shalev-Shwartz and Tong Zhang. Accelerated proximal stochastic dual coordinate ascent for regu-

larized loss minimization. Mathematical Programming  155(1-2):105–145  2016.

[18] Ohad Shamir  Nathan Srebro  and Tong Zhang. Communication efﬁcient distributed optimization using

an approximate newton-type method. arXiv preprint arXiv:1312.7853  2013.

[19] Bin Yu. Assouad  fano  and le cam. In Festschrift for Lucien Le Cam  pages 423–435. Springer  1997.

[20] Yuchen Zhang and Lin Xiao. Communication-efﬁcient distributed optimization of self-concordant empir-

ical loss. arXiv preprint arXiv:1501.00263  2015.

9

,Somdeb Sarkhel
Parag Singla
Vibhav Gogate
Blake Woodworth
Nati Srebro
Tom Zahavy
Matan Haroush
Nadav Merlis
Daniel Mankowitz
Shie Mannor