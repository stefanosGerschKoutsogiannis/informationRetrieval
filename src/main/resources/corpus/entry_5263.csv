2017,Stochastic Submodular Maximization: The Case of Coverage Functions,Stochastic optimization of continuous objectives is at the heart of modern machine learning. However  many important problems are of discrete nature and often involve submodular objectives. We seek to unleash the power of stochastic continuous optimization  namely stochastic gradient descent and its variants  to such discrete problems. We first introduce the problem of stochastic submodular optimization  where one needs to optimize a submodular objective which is given as an expectation. Our model captures situations where the discrete objective arises as an empirical risk (e.g.  in the case of exemplar-based clustering)  or is given as an explicit stochastic model (e.g.  in the case of influence maximization in social networks). By exploiting that common extensions act linearly on the class of submodular functions  we employ projected stochastic gradient ascent and its variants in the continuous domain  and perform rounding to obtain discrete solutions. We focus on the rich and widely used family of weighted coverage functions. We show that our approach yields solutions that are guaranteed to match the optimal approximation guarantees  while reducing the computational cost by several orders of magnitude  as we demonstrate empirically.,Stochastic Submodular Maximization:

The Case of Coverage Functions

Mohammad Reza Karimi

Department of Computer Science

ETH Zurich

mkarimi@ethz.ch

Mario Lucic

Department of Computer Science

ETH Zurich

lucic@inf.ethz.ch

Department of Electrical and Systems Engineering

Department of Computer Science

Andreas Krause

ETH Zurich

krausea@ethz.ch

Hamed Hassani

University of Pennsylvania
hassani@seas.upenn.edu

Abstract

Stochastic optimization of continuous objectives is at the heart of modern ma-
chine learning. However  many important problems are of discrete nature and
often involve submodular objectives. We seek to unleash the power of stochastic
continuous optimization  namely stochastic gradient descent and its variants  to
such discrete problems. We ﬁrst introduce the problem of stochastic submodular
optimization  where one needs to optimize a submodular objective which is given
as an expectation. Our model captures situations where the discrete objective
arises as an empirical risk (e.g.  in the case of exemplar-based clustering)  or is
given as an explicit stochastic model (e.g.  in the case of inﬂuence maximization
in social networks). By exploiting that common extensions act linearly on the
class of submodular functions  we employ projected stochastic gradient ascent
and its variants in the continuous domain  and perform rounding to obtain discrete
solutions. We focus on the rich and widely used family of weighted coverage
functions. We show that our approach yields solutions that are guaranteed to match
the optimal approximation guarantees  while reducing the computational cost by
several orders of magnitude  as we demonstrate empirically.

1

Introduction

Submodular functions are discrete analogs of convex functions. They arise naturally in many
areas  such as the study of graphs  matroids  covering problems  and facility location problems.
These functions are extensively studied in operations research and combinatorial optimization [22].
Recently  submodular functions have proven to be key concepts in other areas such as machine
learning  algorithmic game theory  and social sciences. As such  they have been applied to a host
of important problems such as modeling valuation functions in combinatorial auctions  feature and
variable selection [23]  data summarization [27]  and inﬂuence maximization [20].
Classical results in submodular optimization consider the oracle model whereby the access to the
optimization objective is provided through a black box — an oracle. However  in many applications 
the objective has to be estimated from data and is subject to stochastic ﬂuctuations. In other cases
the value of the objective may only be obtained through simulation. As such  the exact computation
might not be feasible due to statistical or computational constraints. As a concrete example  consider
the problem of inﬂuence maximization in social networks [20]. The objective function is deﬁned
as the expectation of a stochastic process  quantifying the size of the (random) subset of nodes

31st Conference on Neural Information Processing Systems (NIPS 2017)  Long Beach  CA  USA.

inﬂuenced from a selected seed set. This expectation cannot be computed efﬁciently  and is typically
approximated via random sampling  which introduces an error in the estimate of the value of a seed
set. Another practical example is the exemplar-based clustering problem  which is an instance of the
facility location problem. Here  the objective is the sum of similarities of all the points inside a (large)
collection of data points to a selected set of centers. Given a distribution over point locations  the
true objective is deﬁned as the expected value w.r.t. this distribution  and can only be approximated
as a sample average. Moreover  evaluating the function on a sample involves computation of many
pairwise similarities  which is computationally prohibitive in the context of massive data sets.
In this work  we provide a formalization of such stochastic submodular maximization tasks. More
precisely  we consider set functions f : 2V ! R+  deﬁned as f (S) = E⇠[f(S)] for S ✓ V  
where  is an arbitrary distribution and for each realization  ⇠   the set function f : 2V ! R+ is
monotone and submodular (hence f is monotone submodular). The goal is to maximize f subject to
some constraints (e.g. the k-cardinality constraint) having access only to i.i.d. samples f⇠(·).
Methods for submodular maximization fall into two major categories: (i) The classic approach is to
directly optimize the objective using discrete optimization methods (e.g. the GREEDY algorithm and
its accelerated variants)  which are state-of-the-art algorithms (both in practice and theory)  at least in
the case of simple constraints  and are most widely considered in the literature; (ii) The alternative is
to lift the problem into a continuous domain and exploit continuous optimization techniques available
therein [7]. While the continuous approaches may lead to provably good results  even for more
complex constraints  their high computational complexity inhibits their practicality.
In this paper we demonstrate how modern stochastic optimization techniques (such as SGD  ADA-
GRAD [8] and ADAM [21])  can be used to solve an important class of discrete optimization problems
which can be modeled using weighted coverage functions. In particular  we show how to efﬁciently
maximize them under matroid constraints by (i) lifting the problem into the continuous domain
using the multilinear extension [37]  (ii) efﬁciently computing a concave relaxation of the multilinear
extension [32]  (iii) efﬁciently computing an unbiased estimate of the gradient for the concave relax-
ation thus enabling (projected) stochastic gradient ascent-style algorithms to maximize the concave
relaxation  and (iv) rounding the resulting fractional solution without loss of approximation quality
[7]. In addition to providing convergence and approximation guarantees  we demonstrate that our
algorithms enjoy strong empirical performance  often achieving an order of magnitude speedup
with less than 1% error with respect to GREEDY. As a result  the presented approach unleashes the
powerful toolkit of stochastic gradient based approaches to discrete optimization problems.

Our contributions.
In this paper we (i) introduce a framework for stochastic submodular opti-
mization  (ii) provide a general methodology for constrained maximization of stochastic submodular
objectives  (iii) prove that the proposed approach guarantees a (1  1/e)approximation in ex-
pectation for the class of weighted coverage functions  which is the best approximation guarantee
achievable in polynomial time unless P = NP  (iv) highlight the practical beneﬁt and efﬁciency
of using continuous-based stochastic optimization techniques for submodular maximization  (v)
demonstrate the practical utility of the proposed framework in an extensive experimental evaluation.
We show for the ﬁrst time that continuous optimization is a highly practical  scalable avenue for
maximizing submodular set functions.

2 Background and problem formulation

Let V be a ground set of n elements. A set function f : 2V ! R+ is submodular if for every
A  B ✓ V   it holds f (A) + f (B)  f (A \ B) + f (A [ B). Function f is said to be monotone if
f (A)  f (B) for all A ✓ B ✓ V . We focus on maximizing f subject to some constraints on S ✓ V .
The prototypical example is maximization under the cardinality constraint  i.e.  for a given integer
k  ﬁnd S ✓ V   |S| k  which maximizes f. Finding an exact solution for monotone submodular
functions is NP-hard [10]  but a (1  1/e)-approximation can be efﬁciently determined [30]. Going
beyond the (1  1/e)-approximation is NP-hard for many classes of submodular functions [30  24].
More generally  one may consider matroid constraints  whereby (V I) is a matroid with the family
of independent sets I  and maximize f such that S 2I . The GREEDY algorithm achieves a 1/2-
approximation [13]  but CONTINUOUS GREEDY introduced by Vondrák [37]  Calinescu et al. [6]
can achieve a (1  1/e)-optimal solution in expectation. Their approach is based on the multilinear

2

extension of f  F : [0  1]V ! R+  deﬁned as
F (x) = XS✓V

f (S)Yi2S

xiYj /2S

(1  xj) 

(1)

In other words  F (x) is the expected value of of f over
for all x = (x1 ···   xn) 2 [0  1]V .
sets wherein each element i is included with probability xi independently. Then  instead of opti-
mizing f (S) over I  we can optimize F over the matroid base polytope corresponding to (V I):
+ | x(S)  r(S) 8S ✓ V  x(V ) = r(V )}  where r(·) is the matroid’s rank
P = {x 2 Rn
function. The CONTINUOUS GREEDY algorithm then ﬁnds a solution x 2P which provides a
(1  1/e)approximation. Finally  the continuous solution x is then efﬁciently rounded to a feasible
discrete solution without loss in objective value  using PIPAGE ROUNDING [1  6]. The idea of
converting a discrete optimization problem into a continuous one was ﬁrst exploited by Lovász [28]
in the context of submodular minimization and this approach was recently applied to a variety of
problems [36  19  3].

f (S) = E⇠[f(S)] 

Problem formulation. The aforementioned results are based on the oracle model  whereby the
exact value of f (S) for any S ✓ V is given by an oracle. In absence of such an oracle  we face the
additional challenges of evaluating f  both statistical and computational. In particular  consider set
functions that are deﬁned as expectations  i.e. for S ✓ V we have

(2)
where  is an arbitrary distribution and for each realization  ⇠   the set function f : 2V ! R is
submodular. The goal is to efﬁciently maximize f subject to constraints such as the k-cardinality
constraint  or more generally  a matroid constraint.
As a motivating example  consider the problem of propagation of contagions through a network. The
objective is to identify the most inﬂuential seed set of a given size. A propagation instance (concrete
realization of a contagion) is speciﬁed by a graph G = (V  E). The inﬂuence fG(S) of a set of nodes
S in instance G is the fraction of nodes reachable from S using the edges E. To handle uncertainties
in the concrete realization  it is natural to introduce a probabilistic model such as the Independent
Cascade [20] model which deﬁnes a distribution G over instances G ⇠G that share a set V of nodes.
The inﬂuence of a seed set S is then the expectation f (S) = EG⇠G[fG(S)]  which is a monotone
submodular function. Hence  estimating the expected inﬂuence is computationally demanding  as it
requires summing over exponentially many functions fG. Assuming f as in (2)  one can easily obtain
an unbiased estimate of f for a ﬁxed set S by random sampling according to . The critical question
is  given that the underlying function is an expectation  can we optimize it more efﬁciently?
Our approach is based on continuous extensions that are linear operators on the class of set functions 
namely  linear continuous extensions. As a speciﬁc example  considering the multilinear extension 
we can write F (x) = E⇠[F(x)]  where F denotes the extension of f. As a consequence  the
value of F(x)  when  ⇠   is an unbiased estimator for F (x) and unbiased estimates of the
(sub)gradients may be obtained analogously. We explore this avenue to develop efﬁcient algorithms
for maximizing an important subclass of submodular functions that can be expressed as weighted
coverage functions. Our approach harnesses a concave relaxation detailed in Section 3.
Further related work. The emergence of new applications  combined with a massive increase in
the amount of data has created a demand for fast algorithms for submodular optimization. A variety
of approximation algorithms have been presented  ranging from submodular maximization subject
to a cardinality constraint [29  39  4]  submodular maximization subject to a matroid constraint
[6]  non-monotone submodular maximization [11]  approximately submodular functions [17]  and
algorithms for submodular maximization subject to a wide variety of constraints [25  12  38  18  9].
A closely related setting to ours is online submodular maximization [35]  where functions come one
at a time and the goal is to provide time-dependent solutions (sets) such that a cumulative regret
is minimized. In contrast  our goal is to ﬁnd a single (time-independent) set that maximizes the
objective (2). Another relevant setting is noisy submodular maximization  where the evaluations
returned by the oracle are noisy [16  34]. Speciﬁcally  [34] assumes a noisy but unbiased oracle (with
an independent sub-Gaussian noise) which allows one to sufﬁciently estimate the marginal gains of
items by averaging. In the context of cardinality constraints  some of these ideas can be carried to our
setting by introducing additional assumptions on how the values f(S) vary w.r.t. to their expectation
f (S). However  we provide a different approach that does not rely on uniform convergence and
compare sample and running time complexity comparison with variants of GREEDY in Section 3.

3

3 Stochastic Submodular Optimization

We follow the general framework of [37] whereby the problem is lifted into the continuous domain 
a continuous optimization algorithm is designed to maximize the transferred objective  and the
resulting solution is rounded. Maximizing f subject to a matroid constraint can then be done by
ﬁrst maximizing its multilinear extension F over the matroid base polytope and then rounding the
solution. Methods such as the projected stochastic gradient ascent can be used to maximize F over
this polytope.
Critically  we have to assure that the computed local optima are good in expectation. Unfortunately 
the multilinear extension F lacks concavity and therefore may have bad local optima. Hence  we
consider concave continuous extensions of F that are efﬁciently computable  and at most a constant
factor away from F to ensure solution quality. As a result  such a concave extension ¯F could then be
efﬁciently maximized over a polytope using projected stochastic gradient ascent which would enable
the application of modern continuous optimization techniques. One class of important functions for
which such an extension can be efﬁciently computed is the class of weighted coverage functions.

The class of weighted coverage functions (WCF). Let U be a set and let g be a nonnegative

modular function on U  i.e. g(S) =Pu2S w(u)  S ✓ U. Let V = {B1  . . .   Bn} be a collection of
subsets of U. The weighted coverage function f : 2V ! R+ deﬁned as
is monotone submodular. For all u 2 U  let us denote by Pu := {Bi 2 V | u 2 Bi} and by I(·) the
indicator function. The multilinear extension of f can be expressed in a more compact way:

8S ✓ V : f (S) = gSBi2S Bi
I(u 2 Bi for some Bi 2 S) · w(u)

F (x) = ES[f (S)] = ESXu2U

=Xu2U

w(u) · P(u 2 Bi for some Bi 2 S) =Xu2U

w(u)✓1 QBi2Pu

(1  xi)◆ (3)

where we used the fact that each element Bi 2 V was chosen with probability xi.
Concave upper bound for weighted coverage functions. To efﬁciently compute a concave upper
bound on the multilinear extension we use the framework of Seeman and Singer [32]. Given that all
the weights w(u)  u 2 U in (3) are non-negative  we can construct a concave upper bound for the
multilinear extension F (x) using the following Lemma. Proofs can be found in the Appendix A.
Lemma 1. For x 2 [0  1]` deﬁne ↵(x) := 1Q`
i=1(1 xi). Then the Fenchel concave biconjugate
of ↵(·) is (x) := minn1 P`

i=1 xio. Also
(1  1/e) (x)  ↵(x)  (x) 8x 2 [0  1]`.

Furthermore   is an extension of ↵  i.e. 8x 2{ 0  1}`: ↵(x) = (x).
Consequently  given a weighted coverage function f with F (x) represented as in (3)  we can deﬁne
xv

w(u) min⇢1  XBv2Pu

¯F (x) :=Xu2U

and conclude using Lemma 1 that (1  1/e) ¯F (x)  F (x)  ¯F (x)  as desired. Furthermore  ¯F has
three interesting properties: (1) It is a concave function over [0  1]V   (2) it is equal to f on vertices
of the hypercube  i.e. for x 2{ 0  1}n one has ¯F (x) = f ({i : xi = 1})  and (3) it can be computed
efﬁciently and deterministically given access to the sets Pu  u 2 U. In other words  we can compute
the value of ¯F (x) using at most O(|U|⇥| V |) operations. Note that ¯F is not the tightest concave
upper bound of F   even though we use the tightest concave upper bounds for each term of F .

(4)

Optimizing the concave upper bound by stochastic gradient ascent.
Instead of maximizing F
over a polytope P  one can now attempt to maximize ¯F over P. Critically  this task can be done
efﬁciently  as ¯F is concave  by using projected stochastic gradient ascent. In particular  one can

4

Algorithm 1 Stochastic Submodular Maximization via concave relaxation
Require: matroid M with base polytope P  ⌘t (step size)  T (maximum # of iterations)
1: x(0) starting point in P
2: for t 0 to T  1 do
3:
4:
5:
6: end for
7: ¯xT 1
8: S RANDOMIZED-PIPAGE-ROUND(¯xT )
9: return S such that S 2M   E[f (S)]  (1  1/e)f (OP T )  "(T ).

Choose gt at random from a distribution such that E[gt|x(0)  . . .   x(t)] 2 @ ¯F (x(t))
x(t+1/2) x(t) + ⌘t gt
x(t+1) ProjectP (x(t+1/2))

T PT

t=1 x(t)

control the convergence speed by choosing from the toolbox of modern continuous optimization
algorithms  such as SGD  ADAGRAD and ADAM. Let us denote a maximizer of ¯F over P by ¯x⇤  and
also a maximizer of F over P by x⇤. We can thus write

F (¯x⇤)  (1  1/e) ¯F (¯x⇤)  (1  1/e) ¯F (x⇤)  (1  1/e)F (x⇤) 

which is the exact guarantee that previous methods give  and in general is the best near-optimality ratio
that one can give in poly-time. Finally  to round the continuous solution we may apply RANDOMIZED-
PIPAGE-ROUNDING [7] as the quality of the approximation is preserved in expectation.

Matroid constraints. Constrained optimization can be efﬁciently performed by projected gradient
ascent whereby after each step of the stochastic ascent  we need to project the solution back onto
the feasible set. For the case of matroid constraints  it is sufﬁcient to consider projection onto the
matroid base polytope. This problem of projecting on the base polytope has been widely studied
and fast algorithms exist in many cases [2  5  31]. While these projection algorithms were used as a
key subprocedure in constrained submodular minimization  here we consider them for submodular
maximization. Details of a fast projection algorithm for the problems considered in this work are
presented the Appendix D. Algorithm 1 summarizes all steps required to maximize f subject to
matroid constraints.

Convergence rate. Since we are maximizing a concave function ¯F (·) over a matroid base polytope
P  convergence rate (and hence running time) depends on B := maxx2P ||x||  as well as maximum
gradient norm ⇢ (i.e. ||gt||  ⇢ with probability 1). 1 In the case of the base polytope for a matroid of
rank r  B is pr  since each vertex of the polytope has exactly r ones. Also  from (4)  one can build a
rough upper bound for the norm of the gradient:

||g||  ||Pu2U w(u)1Pu|| max
which depends on the weights w(u) as well as |Pu| and is hence problem-dependent. We will
provide tighter upper bounds for gradient norm in our speciﬁc examples in the later sections. With
⌘t = B/⇢pt  and classic results for SGD [33]  we have that

u2U |Pu|1/2Xu2U

w(u) 

¯F (x⇤)  E[ ¯F (¯xT )]  B⇢/pT  
where T is the total number of SGD iterations and ¯xT is the ﬁnal outcome of SGD (see Algorithm 1).
Therefore  for a given "> 0  after T  B2⇢2/"2 iterations  we have

¯F (x⇤)  E[ ¯F (¯xT )]  ".

Summing up  we will have the following theorem:
Theorem 2. Let f be a weighted coverage function  P be the base polytope of a matroid M  and ⇢
and B be as above. Then for each ✏> 0  Algorithm 1 after T = B2⇢2/"2 iterations  produces a set
S⇤ 2M such that E[f (S⇤)]  (1  1/e) maxS2M f (S)  ".
smooth or strongly concave.

1Note that the function ¯F is neither smooth nor strongly concave as functions such as min{1  x} are not

5

Remark.
Indeed this approximation ratio is the best ratio one can achieve  unless P=NP [10]. A
key point to make here is that our approach also works for more general constraints (in particular
is efﬁcient for simple matroids such as partition matroids). In the latter case  GREEDY only gives
2-approximation and fast discrete methods like STOCHASTIC-GREEDY [29] do not apply  whereas
1
our method still yields an (1  1/e)-optimal solution.
Time Complexity. One can compute an upper bound for the running time of Algorithm 1 by
estimating the time required to perform gradient computations  projection on P  and rounding. For
the case of uniform matroids  projection and rounding take O(n log n) and O(n) time  respectively
(see Appendix D). Furthermore  for the applications considered in this work  namely expected
inﬂuence maximization and exemplar-based clustering  we provide linear time algorithms to compute
the gradients. Also when our matroid is the k-uniform matroid (i.e. k-cardinality constraint)  we have

B = pk. By Theorem 2  the total computational complexity of our algorithm is O(⇢2kn(log n)/"2).
Comparison to GREEDY. Let us relate our results to the classical approach. When running the
GREEDY algorithm in the stochastic setting  one estimates ˆf (S) := 1
i=1 fi(S) where 1  . . .   s
are i.i.d. samples from . The following proposition bounds the sample and computational complexity
of GREEDY. The proof is detailed in the Appendix B.
Proposition 3. Let f be a submodular function deﬁned as (2). Suppose 0  f(S)  H for all
S ✓ V and all  ⇠ . Assume S⇤ denotes the optimal solution for f subject to k-cardinality
constraint and Sk denotes the solution computed by the greedy algorithm on ˆf after k steps. Then  in
order to guarantee

sPs

it is enough to have

i.i.d. samples from . The running time of GREEDY is then bounded by

P[f (Sk)  (1  1/e)f (S⇤)  "]  1   
s 2 ⌦✓H 2(k log n + log(1/))/"2◆ 
O✓⌧H 2nk(k log n + log(1/))/"2◆ 

where ⌧ is an upper bound on the computation time for a single evaluation of f(S).

As an example 
let us compare the worst-case complexity bound obtained for SGD (i.e.
O(⇢2kn(log n)/"2)) with that of GREEDY for the inﬂuence maximization problem. Each single
function evaluation for GREEDY amounts to computing the total inﬂuence of a set in a sample graph 
which makes ⌧ = O(n) (here we assume our sample graphs satisfy |E| = O(|V |)). Also  a crude
upper bound for the size of the gradient for each sample function is Hpn (see Appendix E.1). Hence 
we can deduce that SGD can have a factor k speedup w.r.t. to GREEDY.

4 Applications

We will now show how to instantiate the stochastic submodular maximization framework using
several prototypical discrete optimization problems.
Inﬂuence maximization. As discussed in Section 2  the Independent Cascade [20] model deﬁnes
a distribution G over instances G ⇠G that share a set V of nodes. The inﬂuence fG(S) of a set of
nodes S in instance G is the fraction of nodes reachable from S using the edges E(G). The following
Lemma shows that the inﬂuence belongs to the class of WCF.
Lemma 4. The inﬂuence function fG(·) is a WCF. Moreover 

FG(x) = ES[fG(S)] =

1

|V |Xv2V
min{1 Pu2Pv

1

|V |Xv2V

¯FG(x) =

xu} 
where Pv is the set of all nodes having a (directed) path to v.

(1 Qu2Pv

(1  xu))

(5)

(6)

6

We return to the problem of maximizing fG(S) = EG⇠G[fG(S)] given a distribution over graphs G
sharing nodes V . Since fG is a weighted sum of submodular functions  it is submodular. Moreover 

F (x) = ES[fG(S)] = ES[EG[fG(S)]] = EG[ES[fG(S)]] = EG[FG(x)]

Let U be the uniform distribution over vertices. Then 

(1 Qu2Pv

|V |Xv2V

= EG" 1
|V |Pv2V (1 Qu2Pv

F (x) = EG 1

and the corresponding upper bound would be

(1  xu))# .

(1  xu)) = EG Ev⇠U [1 Qu2Pv

(1  xu)] 

(7)

(8)

¯F (x) = EG Ev⇠U⇥min{1 Pu2Pv

xu}⇤.

This formulation proves to be helpful in efﬁcient calculation of subgradients  as one can obtain a
random subgradient in linear time. For more details see Appendix E.1. We also provide a more
efﬁcient  biased estimator of the expectation in the Appendix.
Facility location. Let G = (X ˙[Y  E) be a complete weighted bipartite graph with parts X and Y
and nonnegative weights wx y. The weights can be considered as utilities or some similarity metric.
We select a subset S ✓ X and each y 2 Y selects s 2 S with the highest weight ws y. Our goal is to
maximize the average weight of these selected edges  i.e. to maximize

f (S) =

1

|Y |Xy2Y

ws y

max
s2S

(9)

given some constraints on S. This problem is indeed the Facility Location problem  if one takes
X to be the set of facilities and Y to be the set of customers and wx y to be the utility of facility x
for customer y. Another interesting instance is the Exemplar-based Clustering problem  in which
X = Y is a set of objects and wx y is the similarity (or inverted distance) between objects x and y 
and one tries to ﬁnd a subset S of exemplars (i.e. centroids) for these objects.
The stochastic nature of this problem is revealed when one writes (9) as the expectation f (S) =
Ey⇠[fy(S)]  where  is the uniform distribution over Y and fy(S) := maxs2S ws y. One can also
consider this more general case  where y’s are drawn from an unknown distribution  and one tries to
maximize the aforementioned expectation.
First  we claim that fy(·) for each y 2 Y is again a weighted coverage function. For simplicity  let
X = {1  . . .   n} and set mi
Lemma 5. The utility function fy(·) is a WCF. Moreover 
i=1(mi  mi+1)(1 Qi
i=1(mi  mi+1) min{1 Pi

.
= wi y  with m1 ··· mn and mn+1
Fy(x) =Pn
¯Fy(x) =Pn

We remark that the gradient of both Fy and ¯Fy can be computed in linear time using a recursive
procedure. We refer to Appendix E.2 for more details.

j=1(1  xj)) 

j=1 xj}.

(10)
(11)

.
= 0.

5 Experimental Results

We demonstrate the practical utility of the proposed framework and compare it to standard baselines.
We compare the performance of the algorithms in terms of their wall-clock running time and the
obtained utility. We consider the following problems:
• Inﬂuence Maximization for the Epinions network2. The network consists of 75 879 nodes and
508 837 directed edges. We consider the subgraph induced by the top 10 000 nodes with the largest
out-degree and use the independent cascade model [20]. The diffusion model is speciﬁed by a
ﬁxed probability for each node to inﬂuence its neighbors in the underlying graph. We set this
probability p to be 0.02  and chose the number of seeds k = 50.
2http://snap.stanford.edu/

7

Figure 1: In the case of Facility location for Blog selection as well as on inﬂuence maximization
on Epinions  the proposed approach reaches the same utility signiﬁcantly faster. On the exemplar-
based clustering of CIFAR  the proposed approach is outperformed by STOCHASTIC-GREEDY  but
nevertheless reaches 98.4% of the GREEDY utility in a few seconds (after less than 1000 iterations).
On Inﬂuence Maximization over partition matroids  the proposed approach signiﬁcantly outperforms
GREEDY.

• Facility Location for Blog Selection. We use the data set used in [14]  consisting of 45 193
blogs  and 16 551 cascades. The goal is to detect information cascades/stories spreading over the
blogosphere. This dataset is heavy-tailed  hence a small random sample of the events has high
variance in terms of the cascade sizes. We set k = 100.
• Exemplar-based Clustering on CIFAR-10. The data set contains 60 000 color images with
resolution 32⇥ 32. We use a single batch of 10 000 images and compare our algorithms to variants
of GREEDY over the full data set. We use the Euclidean norm as the distance function and set
k = 50. Further details about preprocessing of the data as well as formulation of the submodular
function can be found in Appendix E.3.

Baselines.
In the case of cardinality constraints  we compare our stochastic continuous optimization
approach against the most efﬁcient discrete approaches (LAZY-)GREEDY and (LAZY-)STOCHASTIC-
GREEDY  which both provide optimal approximation guarantees. For STOCHASTIC-GREEDY 
we vary the parameter " in order to explore the running time/utility tradeoff. We also report the
performance of randomly selected sets. For the two facility location problems  when applying the
greedy variants we can evaluate the exact objective (true expectation). In the Inﬂuence Maximization
application  computing the exact expectation is intractable. Hence  we use an empirical average of s
samples (cascades) from the model. We note that the number of samples suggested by Proposition 3
is overly conservative  and instead we make a practical choice of s = 103 samples.

8

0100200300Cost(seconds)2468101214UtilityT=100KT=8Ke=0.9e=0.5e=0.3e=0.1e=0.01BlogsSSM/AdaGradLAZY-GREEDYLAZY-STOCH-GREEDYRANDOM-SELECT0204060Cost(seconds)2.142.162.182.202.22Utilitye=0.9e=0.5e=0.3e=0.1e=0.01T=8KCIFAR-10SSM/AdaGradLAZY-GREEDYLAZY-STOCH-GREEDYRANDOM-SELECT050010001500Cost(seconds)14.014.515.015.516.016.5Utilitye=0.9e=0.5e=0.1e=0.01T=106EpinionsSSM/AdaGradLAZY-GREEDYLAZY-STOCH-GREEDYRANDOM-SELECT01020304050k(#ofseeds)0.140.150.160.17UtilityEpinions(PartitionMatroid)SSM/AdaGradLAZY-GREEDYResults. The results are summarized in Figure 1. On the blog selection and inﬂuence maximization
applications  the proposed continuous optimization approach outperforms STOCHASTIC-GREEDY in
terms of the running time/utility tradeoff. In particular  for blog selection we can compute a solution
with the same utility 26⇥ faster than STOCHASTIC-GREEDY with " = 0.5. Similarly  for inﬂuence
maximization on Epinions we the solution 88⇥ faster than STOCHASTIC-GREEDY with " = 0.1.
On the exemplar-based clustering application STOCHASTIC-GREEDY outperforms the proposed
approach. We note that the proposed approach is still competitive as it recovers 98.4% of the value
after less than thousand iterations.
We also include an experiment on Inﬂuence Maximization over partition matroids for the Epinions
network. In this case  GREEDY only provides a 1/2 approximation guarantee and STOCHASTIC-
GREEDY does not apply. To create the partition  we ﬁrst sorted all the vertices by their out-degree.
Using this order on the vertices  we divided the vertices into two partitions  one containing vertices
with even positions  other containing the rest. Figure 1 clearly demonstrates that the proposed
approach outperforms GREEDY in terms of utility (as well as running time).

Acknowledgments The research was partially supported by ERC StG 307036. We would like to
thank Yaron Singer for helpful comments and suggestions.

References
[1] Alexander A Ageev and Maxim I Sviridenko. Pipage rounding: A new method of constructing
algorithms with proven performance guarantee. Journal of Combinatorial Optimization  8(3):
307–328  2004.

[2] Francis Bach et al. Learning with submodular functions: A convex optimization perspective.

Foundations and Trends R in Machine Learning  6(2-3):145–373  2013.

[3] Francis R. Bach. Convex analysis and optimization with submodular functions: a tutorial.

CoRR  abs/1010.4207  2010.

[4] Ashwinkumar Badanidiyuru and Jan Vondrák. Fast algorithms for maximizing submodular
functions. In Proceedings of the Twenty-Fifth Annual ACM-SIAM Symposium on Discrete
Algorithms  pages 1497–1514. SIAM  2014.

[5] P. Brucker. An o(n) algorithm for quadratic knapsack problems. Operations Research Letters  3

(3):163–166  1984.

[6] Gruia Calinescu  Chandra Chekuri  Martin Pál  and Jan Vondrák. Maximizing a submodular set
function subject to a matroid constraint. In International Conference on Integer Programming
and Combinatorial Optimization  pages 182–196. Springer  2007.

[7] Gruia Calinescu  Chandra Chekuri  Martin Pál  and Jan Vondrák. Maximizing a monotone
submodular function subject to a matroid constraint. SIAM Journal on Computing  40(6):
1740–1766  2011.

[8] John Duchi  Elad Hazan  and Yoram Singer. Adaptive subgradient methods for online learning

and stochastic optimization. Journal of Machine Learning Research  2011.

[9] Alina Ene and Huy L. Nguyen. Constrained submodular maximization: Beyond 1/e. pages

248–257  2016.

[10] Uriel Feige. A threshold of ln n for approximating set cover. Journal of the ACM  45(4):634 ?

652  1998.

[11] Uriel Feige  Vahab S Mirrokni  and Jan Vondrak. Maximizing non-monotone submodular

functions. SIAM Journal on Computing  40(4):1133–1153  2011.

[12] Moran Feldman  Joseph Naor  and Roy Schwartz. A uniﬁed continuous greedy algorithm for
submodular maximization. In Foundations of Computer Science (FOCS)  2011 IEEE 52nd
Annual Symposium on  pages 570–579. IEEE  2011.

9

[13] Marshall L Fisher  George L Nemhauser  and Laurence A Wolsey. An analysis of approximations
for maximizing submodular set functions. In Polyhedral combinatorics  pages 73–87. Springer 
1978.

[14] Natalie Glance  Matthew Hurst  Kamal Nigam  Matthew Siegler  Robert Stockton  and Takashi
Tomokiyo. Deriving marketing intelligence from online discussion. In Proceedings of the
eleventh ACM SIGKDD international conference on Knowledge discovery in data mining  pages
419–428  2005.

[15] Ryan Gomez and Andreas Krause. Budgeted nonparametric learning from data streams. Pro-

ceedings of the 27th International Conference on Machine Learning  2010.

[16] Avinatan Hassidim and Yaron Singer.

abs/1601.03095  2016.

Submodular optimization under noise. CoRR 

[17] Thibaut Horel and Yaron Singer. Maximizing approximately submodular functions. NIPS 

2016.

[18] Rishabh K Iyer and Jeff A Bilmes. Submodular optimization with submodular cover and
submodular knapsack constraints. In Advances in Neural Information Processing Systems 
pages 2436–2444  2013.

[19] Rishabh K. Iyer and Jeff A. Bilmes. Polyhedral aspects of submodularity  convexity and

concavity. Arxiv  CoRR  abs/1506.07329  2015.

[20] David Kempe  Jon Kleinberg  and Eva. Tardos. Maximizing the spread of inﬂuence through
a social network. 9th ACM SIGKDD Conference on Knowledge Discovery and Data Mining 
pages 137–146  2003.

[21] Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. ICLR  2015.

[22] Andreas Krause and Daniel Golovin. Submodular function maximization. Tractability: Practi-

cal Approaches to Hard Problems  3(19):8  2012.

[23] Andreas Krause and Carlos Guestrin. Near-optimal nonmyopic value of information in graphical

models. In Conference on Uncertainty in Artiﬁcial Intelligence (UAI)  July 2005.

[24] Andreas Krause and Carlos Guestrin. Near-optimal nonmyopic value of information in graphical
models. In Proceedings of the Twenty-First Conference on Uncertainty in Artiﬁcial Intelligence 
pages 324–331. AUAI Press  2005.

[25] Ariel Kulik  Hadas Shachnai  and Tami Tamir. Maximizing submodular set functions subject to
multiple linear constraints. In Proceedings of the twentieth Annual ACM-SIAM Symposium on
Discrete Algorithms  pages 545–554. Society for Industrial and Applied Mathematics  2009.

[26] K. S. Sesh Kumar and Francis Bach. Active-set methods for submodular minimization problems.

hal-01161759v3  2016.

[27] Hui Lin and Jeff Bilmes. A class of submodular functions for document summarization. In
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:
Human Language Technologies-Volume 1  pages 510–520. Association for Computational
Linguistics  2011.

[28] László Lovász. Submodular functions and convexity. In Mathematical Programming The State

of the Art  pages 235–257. Springer  1983.

[29] Baharan Mirzasoleiman  Ashwinkumar Badanidiyuru  Amin Karbasi  Jan Vondrak  and Andreas
Krause. Lazier than lazy greedy. Association for the Advancement of Artiﬁcial Intelligence 
2015.

[30] George L. Nemhauser  Laurence A. Wolsey  and Marshall L. Fisher. An analysis of approxima-
tions for maximizing submodular set functions - i. Mathematical Programming  14(1):265–294 
1978.

10

[31] P. M. Pardalos and N. Kovoor. An algorithm for a singly constrained class of quadratic programs

subject to upper and lower bounds. Mathematical Programming  46(1):321–328  1990.

[32] Lior Seeman and Yaron Singer. Adaptive seeding in social networks. pages 459–468  2013.
[33] Shai Shalev-Shwartz and Shai Ben-David. Understanding Machine Learning : From Theory to

Algorithms. Cambridge University Press  2014.

[34] Adish Singla  Sebastian Tschiatschek  and Andreas Krause. Noisy submodular maximization
via adaptive sampling with applications to crowdsourced image collection summarization. In
Proc. Conference on Artiﬁcial Intelligence (AAAI)  February 2016.

[35] Matthew Streeter and Daniel Golovin. An online algorithm for maximizing submodular

functions. NIPS  2008.

[36] Jan Vondrák. Submodularity in combinatorial optimization. Charles University  Prague  2007.
[37] Jan Vondrák. Optimal approximation for the submodular welfare problem in the value oracle
model. In Proceedings of the fortieth annual ACM symposium on Theory of computing  pages
67–74. ACM  2008.

[38] Jan Vondrák. Symmetry and approximability of submodular maximization problems. SIAM

Journal on Computing  42(1):265–304  2013.

[39] Kai Wei  Rishabh Iyer  and Jeff Bilmes. Fast multi-stage submodular maximization.

International Conference on Machine Learning (ICML)  Beijing  China  2014.

In

11

,Mohammad Karimi
Mario Lucic
Hamed Hassani
Andreas Krause
David Eriksson
Kun Dong
Eric Lee
David Bindel
Andrew Wilson