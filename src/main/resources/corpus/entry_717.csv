2013,Bayesian Estimation of Latently-grouped Parameters in Undirected Graphical Models,In large-scale applications of undirected graphical models  such as social networks and biological networks  similar patterns occur frequently and give rise to similar parameters. In this situation  it is beneficial to group the parameters for more efficient learning. We show that even when the grouping is unknown  we can infer these parameter groups during learning via a Bayesian approach. We impose a Dirichlet process prior on the parameters. Posterior inference usually involves calculating intractable terms  and we propose two approximation algorithms  namely a Metropolis-Hastings algorithm with auxiliary variables and a Gibbs sampling algorithm with stripped Beta approximation (Gibbs_SBA). Simulations show that both algorithms outperform conventional maximum likelihood estimation (MLE). Gibbs_SBA's performance is close to Gibbs sampling with exact likelihood calculation. Models learned with Gibbs_SBA also generalize better than the models learned by MLE on real-world Senate voting data.,Bayesian Estimation of Latently-grouped Parameters

in Undirected Graphical Models

Jie Liu

David Page

Dept of CS  University of Wisconsin

Dept of BMI  University of Wisconsin

Madison  WI 53706

jieliu@cs.wisc.edu

Madison  WI 53706

page@biostat.wisc.edu

Abstract

In large-scale applications of undirected graphical models  such as social networks
and biological networks  similar patterns occur frequently and give rise to simi-
lar parameters. In this situation  it is beneﬁcial to group the parameters for more
efﬁcient learning. We show that even when the grouping is unknown  we can in-
fer these parameter groups during learning via a Bayesian approach. We impose a
Dirichlet process prior on the parameters. Posterior inference usually involves cal-
culating intractable terms  and we propose two approximation algorithms  namely
a Metropolis-Hastings algorithm with auxiliary variables and a Gibbs sampling al-
gorithm with “stripped” Beta approximation (Gibbs SBA). Simulations show that
both algorithms outperform conventional maximum likelihood estimation (MLE).
Gibbs SBA’s performance is close to Gibbs sampling with exact likelihood cal-
culation. Models learned with Gibbs SBA also generalize better than the models
learned by MLE on real-world Senate voting data.

Introduction

1
Undirected graphical models  a.k.a. Markov random ﬁelds (MRFs)  have many real-world applica-
tions such as social networks and biological networks. In these large-scale networks  similar kinds
of relations can occur frequently and give rise to repeated occurrences of similar parameters  but the
grouping pattern among the parameters is usually unknown. For a social network example  suppose
that we collect voting data over the last 20 years from a group of 1 000 people who are related to each
other through different types of relations (such as family  co-workers  classmates  friends and so on) 
but the relation types are usually unknown. If we use a binary pairwise MRF to model the data  each
binary node denotes one person’s vote  and two nodes are connected if the two people are linked
in the social network. Eventually we want to estimate the pairwise potential functions on edges 
which can provide insights about how the relations between people affect their decisions. This can
be done via standard maximum likelihood estimation (MLE)  but the latent grouping pattern among
the parameters is totally ignored  and the model can be overparametrized. Therefore  two questions
naturally arise. Can MRF parameter learners automatically identify these latent parameter groups
during learning? Will this further abstraction make the model generalize better  analogous to the
lessons we have learned from hierarchical modeling [9] and topic modeling [5]?
This paper shows that it is feasible and potentially beneﬁcial to identify the latent parameter groups
during MRF parameter learning. Speciﬁcally  we impose a Dirichlet process prior on the parameters
to accommodate our uncertainty about the number of the parameter groups. Posterior inference can
be done by Markov chain Monte Carlo with proper approximations. We propose two approximation
algorithms  a Metropolis-Hastings algorithm with auxiliary variables and a Gibbs sampling algo-
rithm with stripped Beta approximation (Gibbs SBA). Algorithmic details are provided in Section
3 after we review related parameter estimation methods in Section 2. In Section 4  we evaluate
our Bayesian estimates and the classical MLE on different models  and both algorithms outperform
classical MLE. The Gibbs SBA algorithm performs very close to the Gibbs sampling algorithm with
exact likelihood calculation. Models learned with Gibbs SBA also generalize better than the models
learned by MLE on real-world Senate voting data in Section 5. We ﬁnally conclude in Section 6.

1

2 Maximum Likelihood Estimation and Bayesian Estimation for MRFs
Let X = {0  1  ...  m − 1} be a discrete space. Suppose that we have an MRF deﬁned on a random
vector X ∈ X d described by an undirected graph G(V E) with d nodes in the node set V and r
edges in the edge set E. The probability of one sample x from the MRF parameterized by θ is

where Z(θ) is the partition function. ˜P (x; θ)=(cid:81)

P (x; θ) = ˜P (x; θ)/Z(θ) 

(1)

I(Xu=Xv)(1−θc)

c∈C(G) φc(x; θc) is some unnormalized measure 
and C(G) is some subset of cliques in G  and φc is the potential function deﬁned on the clique c
parameterized by θc. In this paper  we consider binary pairwise MRFs for simplicity  i.e. C(G)=E
and m=2. We also assume that each potential function φc is parameterized by one parameter θc 
I(Xu(cid:54)=Xv) where I(Xu=Xv) indicates whether the two nodes
namely φc(X; θc)=θc
u and v connected by edge c take the same value  and 0<θc<1 ∀c=1  ... r. Thus  θ={θ1  ...  θr}.
Suppose that we have n independent samples X={x1  ...  xn} from (1)  and we want to estimate θ.
Maximum Likelihood Estimate: The MLE of θ maximizes the log-likelihood function L(θ|X)
(cid:80)n
which is concave w.r.t. θ. Therefore  we can use gradient ascent to ﬁnd the global maximum of
the likelihood function and ﬁnd the MLE of θ. The partial derivative of L(θ|X) with respect to θi
is ∂L(θ|X)
j=1 ψi(xj)−Eθψi=EXψi−Eθψi where ψi is the sufﬁcient statistic corresponding
to θi after we rewrite the density into the exponential family form  and Eθψi is the expectation of
ψi with respect to the distribution speciﬁed by θ. However the exact computation of Eθψi takes
time exponential in the treewidth of G. A few sampling-based methods have been proposed  with
different ways of generating particles and computing Eθψ from the particles  including MCMC-
MLE [11  34]  particle-ﬁltered MCMC-MLE [1]  contrastive divergence [15] and its variations such
as persistent contrastive divergence (PCD) [29] and fast PCD [30]. Note that contrastive divergence
is related to pseudo-likelihood [4]  ratio matching [17  16]  and together with other MRF parameter
estimators [13  31  12] can be uniﬁed as minimum KL contraction [18].
Bayesian Estimate: Let π(θ) be a prior of θ; then its posterior is P (θ|X) ∝ π(θ) ˜P (X; θ)/Z(θ).
The Bayesian estimate of θ is its posterior mean. Exact sampling from P (θ|X) is known as doubly-
intractable for general MRFs [21]. If we use the Metropolis-Hastings algorithm  then Metropolis-
Hastings ratio is

= 1
n

∂θi

∗|θ) =

a(θ

∗

∗

) ˜P (X; θ

π(θ
π(θ) ˜P (X; θ)Q(θ

)Q(θ|θ

∗

∗
)/Z(θ
∗|θ)/Z(θ)

)

 

(2)

∗

∗

 y∗)=Q(θ|θ

∗  and with probability min{1  a(θ

∗|θ) is some proposal distribution from θ to θ

∗. The real hurdle is that we have to evaluate the intractable Z(θ)/Z(θ

∗|θ)} we
where Q(θ
∗
accept the move from θ to θ
)
in the ratio. In [20]  Møller et al. introduce one auxiliary variable y on the same space as x  and
the state variable is extended to (θ  y). They set the new proposal distribution for the extended
state Q(θ  y|θ
) in (2). Therefore by ignoring
y  we can generate the posterior samples of θ via Metropolis-Hastings. Technically  this auxiliary
variable approach requires perfect sampling [25]  but [20] pointed out that other simpler Markov
chain methods also work with the proviso that it converges adequately to the equilibrium distribution.
3 Bayesian Parameter Estimation for MRFs with Dirichlet Process Prior
In order to model the latent parameter groups  we impose a Dirichlet process prior on θ  which
accommodates our uncertainty about the number of groups. Then  the generating model is

) ˜P (y; θ)/Z(θ) to cancel Z(θ)/Z(θ

∗

G ∼ DP(α0  G0)
θi|G ∼ G  i = 1  ...  r
xj|θ ∼ F (θ)  j = 1  ...  n 

(3)

where F (θ) is the distribution speciﬁed by (1). G0 is the base distribution (e.g. Unif(0  1))  and α0 is
the concentration parameter. With probability 1.0  the distribution G drawn from DP(α0  G0) is dis-
crete  and places its mass on a countably inﬁnite collection of atoms drawn from G0. In this model 
X={x1  ...  xn} is observed  and we want to perform posterior inference for θ = (θ1  θ2  ...  θr) 

2

a(c∗

=

π(c∗
π(ci  c−i)P (X; θ)Q(c∗

i |ci) is
i )Q(ci|c∗
∗
i   c−i)P (X; θ.
i )
i |ci)
∗
i )/Z(θ.
i )
i |ci)/Z(θ)

i |ci) =
i |c−i) ˜P (X; θ.
π(c∗
π(ci|c−i) ˜P (X; θ)Q(c∗
∗
i is the same as θ except its i-th ele-
. The conditional prior

i )Q(ci|c∗
∗

 

where θ.
ment is replaced with φc∗
π(c∗

i |c−i) is

i

(cid:40) n−i c

r−1+α0
r−1+α0

α0

  if c ∈ c−i
  if c (cid:54)∈ c−i

π(ci=c|c−i)=

(1)  ...  ˆθ

(T ); T samples of θ|X

Input: observed data X={x1  ...  xn}
Output: ˆθ
Procedure:
Perform PCD algorithm to get ˜θ  MLE of θ
Init. c and φ via K-means on ˜θ; K=(cid:98)α0 ln r(cid:99)
for t = 1 to T do

for i = 1 to r do

for l = 1 to M do

Draw a candidate c∗
If c∗
Set ci=c∗

i from Q(ci|c∗
i )
i (cid:54)∈ c  draw a value for φci from G0
i with prob min{1  a(c∗
i |ci)}

end for

and regard its posterior mean as its Bayesian estimate. We propose two Markov chain Monte Carlo
(MCMC) methods. One is a Metropolis-Hastings algorithm with auxiliary variables  as introduced
in Section 3.1. The second is a Gibbs sampling algorithm with stripped Beta approximation  as in-
troduced in Section 3.2. In both methods  the state of the Markov chain is speciﬁed by two vectors 
c and φ. In vector c = (c1  ...  cr)  ci denotes the group to which θi belongs. φ = (φ1  ...  φk)
records the k distinct values in {θ1  ...  θr} with φci = θi for i = 1  ...  r. This way of specifying the
Markov chain is more efﬁcient than setting the state variable directly to be (θ1  θ2  ...  θr) [22].

3.1 Metropolis-Hastings (MH) with Auxiliary Variables
In the MH algorithm (see Algorithm 1)  the initial state of the Markov chain is set by performing K-
means clustering on MLE of θ (e.g. from the PCD algorithm [29]) with K=(cid:98)α0 ln r(cid:99). The Markov
chain resembles Algorithm 5 in [22]  and it is ergodic. We move the Markov chain forward for T
steps. In each step  we update c ﬁrst and then update φ. We update each element of c in turn; when
resampling ci  we ﬁx c−i  all elements in c other than ci. When updating ci  we repeatedly for M
i |ci) and accept the move with probability
times propose a new value c∗
i according to proposal Q(c∗
min{1  a(c∗
i |ci)} where a(c∗
i |ci) is the MH ratio. After we update every element of c in the current
iteration  we draw a posterior sample of φ according to the current grouping c. We iterate T times 
and get T posterior samples of θ. Unlike the tractable Algorithm 5 in [22]  we need to introduce
auxiliary variables to bypass MRF’s intractable likelihood in two places  namely calculating the MH
ratio (in Section 3.1.1) and drawing samples of φ|c (in Section 3.1.2).
3.1.1 Calculating Metropolis-Hastings Ratio
The MH ratio of proposing a new value c∗
i for ci
according to proposal Q(c∗

Algorithm 1 The Metropolis-Hastings algorithm

end for
Draw a posterior sample of φ according to
current c  and set ˆθ(t)

where n−i c is the number of cj for j(cid:54)=i and
i |ci) to be the
cj=c. We choose proposal Q(c∗
i |c−i)  and the Metropolis-
conditional prior π(c∗
Hastings ratio can be further simpliﬁed as
∗
a(c∗
i ) is intractable. Similar to [20] 
we introduce an auxiliary variable Z on the same space as X  and the state variable is extended to
∗
(c  Z). When proposing a move  we propose c∗
i ﬁrst and then propose Z∗ with proposal P (Z; θ.
i )
∗
i ). We set the target distribution of Z to be P (Z; ˜θ) where ˜θ is
to cancel the intractable Z(θ)/Z(θ.
some estimate of θ (e.g. from PCD [29]). Then  the MH ratio with the auxiliary variable is

∗
∗
i )Z(θ)/ ˜P (X; θ)Z(θ.
i ). However  Z(θ)/Z(θ.

i =φci for i=1  ...  r.

i |ci)= ˜P (X; θ.

end for

a(c∗

i   Z∗|ci  Z) =

∗
P (Z∗; ˜θ) ˜P (X; θ.
i ) ˜P (Z; θ)
∗
P (Z; ˜θ) ˜P (X; θ) ˜P (Z∗; θ.
i )

=

∗
˜P (Z∗; ˜θ) ˜P (X; θ.
i ) ˜P (Z; θ)
∗
˜P (Z; ˜θ) ˜P (X; θ) ˜P (Z∗; θ.
i )

.

Thus  the intractable computation of the MH ratio is replaced by generating particles Z∗ and Z under
∗
i and θ respectively. Ideally  we should use perfect sampling [25]  but it is intractable for general
θ.
MRFs. As a compromise  we use standard Gibbs sampling with long runs to generate these particles.
3.1.2 Drawing Posterior Samples of φ|c
We draw posterior samples of φ under grouping c via the MH algorithm  again following [20]. The
state of the Markov chain is φ. The initial state of the Markov chain is set by running PCD [29] with

3

∗|φ) is a k-variate Gaussian N (φ  σ2
QIk) where
parameters tied according to c. The proposal Q(φ
QIk is the covariance matrix. The auxiliary variable Y is on the same space as X  and the state is
σ2
extended to (φ  Y). The proposal distribution for the extended state variable is Q(φ  Y|φ
∗
  Y∗) =
Q(φ|φ
∗
) ˜P (Y; φ)/Z(φ). We set the target distribution of Y to be P (Y; ˜φ) where ˜φ is some estimate
of φ such as the estimate from the PCD algorithm [29]. Then  the MH ratio for the extended state is

∗
a(φ

  Y∗|φ  Y) = I(φ

∗∈ Θ)

∗
˜P (Y∗; ˜φ) ˜P (X; φ
) ˜P (Y; φ)
∗
˜P (Y; ˜φ) ˜P (X; φ) ˜P (Y∗; φ
)

 

∗∈ Θ) indicates that every dimension of φ

where I(φ
the new values with probability min{1  a(φ
and get S samples of φ by ignoring Y. Eventually we draw one sample from them randomly.

∗ is in the domain of G0. We set the state to be
  Y∗|φ  Y)}. We move the Markov chain for S steps 

∗

3.2 Gibbs Sampling with Stripped Beta Approximation
In the Gibbs sampling algorithm (see Al-
gorithm 2)  the initialization of the Markov
chain is exactly the same as in the MH al-
gorithm in Section 3.1. The Markov chain
resembles Algorithm 2 in [22] and it can
be shown to be ergodic. We move the
Markov chain forward for T steps. In each
of the T steps  we update c ﬁrst and then
update φ. When we update c  we ﬁx the
values in φ  except we may add one new
value to φ or remove a value from φ. We
update each element of c in turn. When
we update ci  we ﬁrst examine whether ci
is unique in c. If so  we remove φci from
φ ﬁrst. We then update ci by assigning it
to an existing group or a new group with
a probability proportional to a product of
two quantities  namely

end for

Algorithm 2 The Gibbs sampling algorithm
Input: observed data X = {x1  x2  ...  xn}
Output: ˆθ
Procedure:
Perform PCD algorithm to get MLE ˜θ
Init. c and φ via K-means on ˜θ; K=(cid:98)α0 ln r(cid:99)
for t = 1 to T do

(T ); T posterior samples of θ|X

(1)  ...  ˆθ

for i = 1 to r do

If current ci is unique in c  remove φci from φ
Update ci according to (4).
If new ci(cid:54)∈c  draw a value for φci and add to φ
end for
Draw a posterior sample of φ according to current
c  and set ˆθ(t)

i = φci for i = 1  ...  r

P (ci = c|c−i  X  φc−i) ∝

(cid:40) n−i c

r−1+α0
r−1+α0

α0

P (X; φc  φc−i)  if c ∈ c−i

(cid:82) P (X; θi  φc−i) dG0(θi)  if c (cid:54)∈ c−i.

(4)

The ﬁrst quantity is n−i c  the number of members already in group c. For starting a new group 
the quantity is α0. The second quantity is the likelihood of X after assigning ci to the new value c
conditional on φc−i. When considering a new group  we integrate the likelihood w.r.t. G0. After ci
is resampled  it is either set to be an existing group or a new group. If a new group is assigned  we
draw a new value for φci  and add it to φ. After updating every element of c in the current iteration 
we draw a posterior sample of φ under the current grouping c. In total  we run T iterations  and
get T posterior samples of θ. This Gibbs sampling algorithm involves two intractable calculations 

namely (i) calculating P (X; φc  φc−i) and(cid:82) P (X; θi  φc−i ) dG0(θi) in (4) and (ii) drawing posterior
3.2.1 Calculating P (X; φc  φc−i) and(cid:82) P (X; θi  φc−i) dG0(θi) in (4)

samples for φ. We use a stripped Beta approximation in both places  as in Sections 3.2.1 and 3.2.2.

In Formula (4)  we evaluate P (X; φc  φc−i) for different φc values with φc−i ﬁxed and X =
{x1  x2  ...  xn} observed. For ease of notation  we rewrite this quantity as a likelihood function
of θi  L(θi|X  θ−i)  where θ−i = {θ1  ...  θi−1  θi+1  ...  θr} is ﬁxed. Suppose that the edge i con-
nects variables Xu and Xv  and we denote X−uv to be the variables other than Xu and Xv. Then
L(θi|X  θ−i)=

P (xj

u  xj

P (xj

v|xj−uv; θi  θ−i).
Above we approximate P (xj−uv; θi  θ−i) with P (xj−uv; θ−i) because the density of X−uv mostly
depends on θ−i. The term P (xj−uv; θ−i) can be dropped since θ−i is ﬁxed  and we only have

u  xj

u  xj

P (xj

j=1

v|xj−uv; θi  θ−i)P (xj−uv; θi  θ−i)

v|xj−uv; θi  θ−i)P (xj−uv; θ−i) ∝(cid:89)n

(cid:89)n
≈(cid:89)n

j=1

j=1

4

u  xj

v|xj−uv; θi  θ−i). Since θ−i is ﬁxed and we are conditioning on xj−uv  they
to consider P (xj
together can be regarded as a ﬁxed potential function telling how likely the rest of the graph thinks
Xu and Xv should take the same value. Suppose that this ﬁxed potential function (the message from
the rest of the network xj−uv) is parameterized as ηi (0 < ηi < 1). Then
I(xj

n(cid:80)

n(cid:80)

I(xj

u(cid:54)=xj
v)

I(xj

u=xj

v)(1−λ)

λ

I(xj

u(cid:54)=xj

v)=λ

j=1

u=xj
v)

(1−λ)

j=1

(5)

P (xj

n(cid:89)
eters ((cid:80)n

j=1

u  xj

v|xj−uv; θi  θ−i)∝ n(cid:89)
v)+1  n−(cid:80)n

u=xj

j=1

j=1

j=1

I(xj

I(xj

u=xj

The integral(cid:82) P (X; θi  φc−i) dG0(θi) in (4) can be calculated via Monte Carlo approximation. We

where λ=θiηi/{θiηi+(1−θi)(1−ηi)}. The end of (5) resembles a Beta distribution with param-
v)+1) except that only part of λ  namely θi  is ran-
dom. Now we want to use a Beta distribution to approximate the likelihood with respect to θi  and
we need to remove the contribution of ηi and only consider the contribution from θi. We choose
Beta((cid:98)n ˜θi(cid:99)+1  n−(cid:98)n ˜θi(cid:99)+1) where ˜θi is MLE of θi (e.g. from the PCD algorithm). This approxi-
mation is named the Stripped Beta Approximation. The simulation results in Section 4.2 indicate that
the performance of the stripped Beta approximation is very close to using exact calculation. Also
this approximation only requires as much computation as in the tractable tree-structure MRFs  and
it does not require generating expensive particles as in the MH algorithm with auxiliary variables.
draw a number of samples of θi from G0  and evaluate P (X; θi  φc−i ) and take the average.
3.2.2 Drawing Posterior Samples of φ|c
The stripped Beta approximation also allows us to draw posterior samples from φ|c approximately.
Suppose that there are k groups according to c  and we have estimates for φ  denoted as ˆφ =
( ˆφ1  ...  ˆφk). We denote the numbers of elements in the k groups by m = {m1  ...  mk}. For group
i  we draw a posterior sample for φi from Beta((cid:98)min ˆφi(cid:99)+1  min−(cid:98)min ˆφi(cid:99)+1).
4 Simulations
We investigate the performance of our Bayesian estimators on three models: (i) a tree-MRF  (ii)
a small grid-MRF whose likelihood is tractable  and (iii) a large grid-MRF whose likelihood is
intractable. We ﬁrst set the ground truth of the parameters  and then generate training and testing
samples. On training data  we apply our grouping-aware Bayesian estimators and two baseline
estimators  namely a grouping-blind estimator and an oracle estimator. The grouping-blind estimator
does not know groups exist in the parameters  and estimates the parameters in the normal MLE
fashion. The oracle estimator knows the ground truth of the groupings  and ties the parameters from
the same group and estimates them via MLE. For the tree-MRF  our Bayesian estimator is exact
since the likelihood is tractable. For the small grid-MRF  we have three variations for the Bayesian
estimator  namely Gibbs sampling with exact likelihood computation  MH with auxiliary variables 
and Gibbs sampling with stripped Beta approximation. For the large grid-MRF  the computational
burden only allows us to apply Gibbs sampling with stripped Beta approximation.
We compare the estimators by three measures. The ﬁrst is the average absolute error of estimate
i=1 |θi − ˆθi| where ˆθi is the estimate of θi. The second measure is the log likelihood of the
testing data  or the log pseudo-likelihood [4] of the testing data when exact likelihood is intractable.
Thirdly  we evaluate how informative the grouping yielded by the Bayesian estimator is. We use the
variation of information metric [19] between the inferred grouping ˆC and the ground truth grouping
C  namely VI( ˆC  C). Since VI( ˆC  C) is sensitive to the number of groups in ˆC  we contrast it
with VI( ¯C  C) where ¯C is a random grouping with its number of groups the same as ˆC. Eventually 
we evaluate ˆC via the VI difference  namely VI( ¯C  C)−VI( ˆC  C). A larger value of VI difference
indicates a more informative grouping yielded by our Bayesian estimator. Because we have one
grouping in each of the T MCMC steps  we average the VI difference yielded in each of the T steps.

1/r(cid:80)r

4.1 Simulations on Tree-structure MRFs
For the structure of the MRF  we choose a perfect binary tree of height 12 (i.e. 8 191 nodes and
8 190 edges). We assume there are 25 groups among the 8 190 parameters. The base distribution
G0 is Unif(0  1). We ﬁrst generate the true parameters for the 25 groups from Unif(0  1). We then
randomly assign each of the 8 190 parameters to one of the 25 groups. We then generate 1 000

5

Figure 1: Performance of the grouping-blind MLE  the oracle MLE and our Bayesian estimator on tree-structure
MRFs in terms of (a) error of estimate and (b) log-likelihood of test data. Subﬁgure (c) shows the VI difference
between the grouping yielded by our Bayesian estimator and random grouping.

testing samples and n training samples (n=100  200  ...  1 000). Eventually  we apply the grouping-
blind MLE  the oracle MLE  and our grouping-aware Bayesian estimator on the training samples.
For tree-structure MRFs  both MLE and Bayesian estimation have a closed form solution. For the
Bayesian estimator  we set the number of Gibbs sampling steps to be 500 and set α0=1.0. We
replicate the experiment 500 times  and the averaged results are in Figure 1.
Our grouping-aware Bayesian estimator has a
lower estimate error and a higher log likelihood of
test data  compared with the grouping-blind MLE 
demonstrating the “blessing of abstraction”. Our
Bayesian estimator performs worse than oracle
MLE  as we expect.
In addition  as the train-
ing sample size increases  the performance of our
Bayesian estimator approaches that of the oracle
MLE. The VI difference in Figure 1(c) indicates that the Bayesian estimator also recovers the latent
grouping to some extent  and the inferred groupings become more and more reliable as the training
size increases. The number of groups inferred by the Bayesian estimator and its running time are in
Figure 2. We also investigate the asymptotic performance of the estimators and their performance
when there are no parameter groups. The results are provided in the supplementary materials.

Figure 2: Number of groups inferred by the Bayesian
estimator and its run time.

4.2 Simulations on Small Grid-MRFs
For the structure of the MRF  we choose a 4×4 grid with 16 nodes and 24 edges. Exact likeli-
hood is tractable in this small model  which allows us to investigate how good the two types of
approximation are. We apply the grouping-blind MLE (the PCD algorithm)  the oracle MLE (the
PCD algorithm with the parameters from same group tied) and three Bayesian estimators: Gibbs
sampling with exact likelihood computation (Gibbs ExactL)  Metropolis-Hastings with auxiliary
variables (MH AuxVar)  and Gibbs sampling with stripped Beta approximation (Gibbs SBA). We
assume there are ﬁve parameter groups. The base distribution is Unif(0  1). We ﬁrst generate the
true parameters for the ﬁve groups from Unif(0  1). We then randomly assign each of the 24 pa-
rameters to one of the ﬁve groups. We then generate 1 000 testing samples and n training samples
(n=100  200  ...  1 000). For Gibbs ExactL and Gibbs SBA  we set the number of Gibbs sampling
steps to be 100. For MH AuxVar  we set the number of MH steps to be 500 and its proposal number
M to be 5. The parameter σQ in Section 3.1.2 is set to be 0.001 and the parameter S is set to be
100. For all three Bayesian estimators  we set α0=1.0. We replicate the experiment 50 times  and
the averaged results are in Figure 4.
Our grouping-aware Bayesian estimators have
a lower estimate error and a higher log likeli-
hood of test data  compared with the grouping-
blind MLE  demonstrating the blessing of ab-
straction. All three Bayesian estimators per-
form worse than oracle MLE  as we expect. The
VI difference in Figure 4(c) indicates that the
Bayesian estimators also recover the grouping to some extent  and the inferred groupings become
more and more reliable as the training size increases. In Figure 3  we provide the boxplots of the
number of groups inferred by Gibbs ExactL  MH AuxVar and Gibbs SBA. All three methods re-
cover a reasonable number of groups  and Gibbs SBA slightly over-estimates the number of groups.

Figure 3:
Gibbs ExactL  MH AuxVar and Gibbs SBA.

The number of groups

inferred by

6

llllllllll0.0000.0100.0200.030Error of Estimate1002003004005006007008009001000Training Sample Size(a)lMLEOracleBayesianllllllllll−4160−4150−4140−4130−4120Log−likelihood of Test Data1002003004005006007008009001000Training Sample Size(b)lMLEOracleBayesian5.05.56.06.57.0VI Difference1002003004005006007008009001000Training Sample Size(c)BayesianTraining Sample SizeNumber of Groups Inferred152025301002003004005006007008009001000llllllllllllllllllllllllllllllllllllllllll400410420430440450460Run Time (in seconds)1002003004005006007008009001000Training Sample Size(a) Gibbs_ExactLTraining Sample Size# Groups Inferred468101002003004005006007008009001000lllllllllllllllll(b) MH_AuxVarTraining Sample Size468101002003004005006007008009001000lllllllllll(c) Gibbs_SBATraining Sample Size468101002003004005006007008009001000lllllllllllllllllllllllllllllllFigure 4: Performance of grouping-blind MLE  oracle MLE  Gibbs ExactL  MH AuxVar  and Gibbs SBA on
the small grid-structure MRFs in terms of (a) error of estimate and (b) log-likelihood of test data. Subﬁgure (c)
shows the VI difference between the grouping yielded by our Bayesian estimators and random grouping.

Figure 5: Performance of the grouping-blind MLE  the oracle MLE and the Bayesian estimator (Gibbs SBA)
on large grid-structure MRFs in terms of (a) error of estimate and (b) log-likelihood of test data. Subﬁgure (c)
shows the VI difference between the grouping yielded by our Bayesian estimator and random grouping.

Table 1: The run time (in seconds) of Gibbs ExactL 
MH AuxVar and Gibbs SBA when training size is n.

Among the three Bayesian estimators 
Gibbs ExactL has the lowest estimate er-
ror and the highest log likelihood of test
data. Gibbs SBA also performs consid-
erably well  and its performance is close
to the performance of Gibbs ExactL.
MH AuxVar works slightly worse  espe-
cially when there is less training data. However  MH AuxVar recovers better groupings than
Gibbs SBA when there are more training data. The run times of the three Bayesian estimators are
listed in Table 1. Gibbs ExactL has a computational complexity that is exponential in the dimen-
sionality d  and cannot be applied to situations when d > 20. MH AuxVar is also computationally
intensive because it has to generate expensive particles. Gibbs SBA runs fast  with its burden mainly
from running PCD under a speciﬁc grouping in each Gibbs sampling step  and it scales well.

GIBBS EXACTL
MH AUXVAR
GIBBS SBA

n=100
88 136.3
540.2
8.1

n=500
91 055.0
3 342.2
10.8

n=1 000
92 503.4
4 546.7
14.2

4.3 Simulations on Large Grid-MRFs

The large grid consists of 30 rows and 30 columns (i.e. 900 nodes and 1 740 edges). Exact likeli-
hood is intractable for this large model  and we cannot run Gibbs ExactL. The high dimension also
prohibits MH AuxVar. Therefore  we only run the Gibbs SBA algorithm on this large grid-structure
MRF. We assume that there are 10 groups among the 1 740 parameters. We also evaluate the esti-
mators by the log pseudo-likelihood of testing data. The other settings of the experiments stay the
same as Section 4.2. We replicate the experiment 50 times  and the averaged results are in Figure 5.
For all 10 training sets  our Bayesian estima-
tor Gibbs SBA has a lower estimate error and
a higher log likelihood of test data  compared
with the grouping-blind MLE (via the PCD al-
gorithm). Gibbs SBA has a higher estimate error
and a lower pseudo-likelihood of test data than
the oracle MLE. The VI difference in Figure 5(c)
indicates that Gibbs SBA gradually recovers the
grouping as the training size increases. The number of groups inferred by Gibbs SBA and its run-
ning time are provided in Figure 6. Similarly to the observation in Section 4.2  Gibbs SBA over-
estimates the number of groups. Gibbs SBA ﬁnishes the simulations on 900 nodes and 1 740 edges
in hundreds of minutes (depending on the training size)  which is considered to be very fast.

Figure 6: Number of groups inferred by Gibbs SBA
and its run time.

7

llllllllll0.0050.0150.0250.035Error of Estimate1002003004005006007008009001000Training Sample Size(a)lMLEOracleGibbs_ExactLGibbs_SBAMH_AuxVarllllllllll−6920−6880−6840−6800Log−likelihood of Test Data1002003004005006007008009001000Training Sample Size(b)lMLEOracleGibbs_ExactLGibbs_SBAMH_AuxVar1.01.21.41.61.82.02.2VI Difference1002003004005006007008009001000Training Sample Size(c)Gibbs_ExactLGibbs_SBAMH_AuxVarllllllllll0.010.020.030.04Error of Estimate1002003004005006007008009001000Training Sample Size(a)lMLEOracleGibbs_SBAllllllllll−210000−206000−202000−198000Log−pseudolikelihood of Test Data1002003004005006007008009001000Training Sample Size(b)lMLEOracleGibbs_SBA0.51.01.52.0VI Difference1002003004005006007008009001000Training Sample Size(c)Gibbs_SBATraining Sample SizeNumber of Groups Inferred204060801002003004005006007008009001000lllllllllllllllllll15000200002500030000Run Time (in seconds)1002003004005006007008009001000Training Sample SizeTable 2: Log pseudo-likelihood (LPL) of training and testing data from MLE (PCD) and Bayesian estimate
(Gibbs SBA)  the number of groups inferred by Gibbs SBA  and its run time in the Senate voting experiments.

LPL-TRAIN

MLE

-10716.75
-8306.17

GIBBS SBA
-10721.34
-8322.34

EXP1
EXP2

LPL-TEST

MLE

-9022.01
-11490.47

GIBBS SBA # GROUPS
-8989.87
-11446.45

7.89
7.29

RUNTIME (MINS)

204
183

5 Real-world Application
We apply the Gibbs SBA algorithm on US Senate voting data from the 109th Congress (available
at www.senate.gov). The 109th Congress has two sessions  the ﬁrst session in 2005 and the second
session in 2006. There are 366 votes and 278 votes in the two sessions  respectively. There are 100
senators in both sessions  but Senator Corzine only served the ﬁrst session and Senator Menendez
only served the second session. We remove them. In total  we have 99 senators in our experiments 
and we treat the votes from the 99 senators as the 99 variables in the MRF. We only consider con-
tested votes  namely we remove the votes with less than ten or more than ninety supporters. In total 
there are 292 votes and 221 votes left in the two sessions  respectively. The structure of the MRF is
from Figure 13 in [2]. There are in total 279 edges. The votes are coded as −1 for no and 1 for yes.
We replace all missing votes with −1  staying consistent with [2]. We perform two experiments.
First  we train the MRF using the ﬁrst session data  and test on the second session data. Then  we
train on the second session and test on the ﬁrst session. We compare our Bayesian estimator (via
Gibbs SBA) and MLE (via PCD) by the log pseudo-likelihood of testing data since exact likelihood
is intractable. We set the number of Gibbs sampling steps to be 3 000. Both of the two experi-
ments are ﬁnished in around three hours on a single CPU. The results are summarized in Table 2.
In the ﬁrst experiment  the log pseudo-likelihood of test data is −9022.01 from MLE  whereas it
is −8989.87 from our Bayesian estimate. In the second experiment  the log pseudo-likelihood of
test data is −11490.47 from MLE  whereas it is −11446.45 from our Bayesian estimate. The in-
crease of log pseudo-likelihood is comparable to the increase of log (pseudo-)likelihood we gain in
the simulations (please refer to Figures 1b  4b and 5b at the points when we simulate 200 and 300
training samples). Both experiments indicate that the models trained with the Gibbs SBA algorithm
generalize considerably better than the models trained with MLE. Gibbs SBA also infers there are
around eight different types of relations among the senators. The two trained models are provided
in the supplementary materials  and the estimated parameters in the two models are consistent.

6 Discussion
Bayesian nonparametric approaches [23  10]  such as the Dirichlet process [7]  provide an elegant
way of modeling mixtures with an unknown number of components. These approaches have yielded
advances in different machine learning areas  such as the inﬁnite Gaussian mixture models [26]  the
inﬁnite mixture of Gaussian processes [27]  inﬁnite HMMs [3  8]  inﬁnite HMRFs [6]  DP-nonlinear
models [28]  DP-mixture GLMs [14]  inﬁnite SVMs [33  32]  and the inﬁnite latent attribute models
[24]. In this paper  we play the same trick of replacing the prior distribution with a prior stochas-
tic process to accommodate our uncertainty about the number of parameter groups. To the best of
our knowledge  this is the ﬁrst time a Bayesian nonparametric approach is applied to models whose
likelihood is intractable. Accordingly  we propose two types of approximation  namely a Metropolis-
Hastings algorithm with auxiliary variables and a Gibbs sampling algorithm with stripped Beta ap-
proximation. Both algorithms show superior performance over conventional MLE  and Gibbs SBA
can also scale well to large-scale MRFs. The Markov chains in both algorithms are ergodic  but
may not be in detailed balance because we rely on approximation. Thus  we guarantee that both
algorithms converge for general MRFs  but they may not exactly converge to the target distribution.
In this paper  we only consider the situation where the potential functions are pairwise and there is
only one parameter in each potential function. For graphical models with more than one parameter
in the potential functions  it is appropriate to group the parameters on the level of potential functions.
A more sophisticated base distribution G0 (such as some multivariate distribution) needs to be con-
sidered. In this paper  we also assume the structures of the MRFs are given. When the structures are
unknown  we still need to perform structure learning. Allowing structure learners to automatically
identify structure modules will be another very interesting topic to explore in the future research.
Acknowledgements
The authors acknowledge the support of NIGMS R01GM097618-01 and NLM R01LM011028-01.

8

References
[1] A. U. Asuncion  Q. Liu  A. T. Ihler  and P. Smyth. Particle ﬁltered MCMC-MLE with connections to

contrastive divergence. In ICML  2010.

[2] O. Banerjee  L. El Ghaoui  and A. d’Aspremont. Model selection through sparse maximum likelihood

estimation for multivariate Gaussian or binary data. JMLR  9:485–516  June 2008.

[3] M. J. Beal  Z. Ghahramani  and C. E. Rasmussen. The inﬁnite hidden Markov model. In NIPS  2002.
[4] J. Besag. Statistical analysis of non-lattice data. JRSS-D  24(3):179–195  1975.
[5] D. Blei  A. Ng  and M. Jordan. Latent Dirichlet allocation. JMLR  3:993–1022  2003.
[6] S. P. Chatzis and G. Tsechpenakis. The inﬁnite hidden Markov random ﬁeld model. In ICCV  2009.
[7] T. S. Ferguson. A Bayesian analysis of some nonparametric problems. The Annals of Statistics  1(2):209–

[8] J. V. Gael  Y. Saatci  Y. W. Teh  and Z. Ghahramani. Beam sampling for the inﬁnite hidden Markov

[9] A. Gelman and J. Hill. Data analysis using regression and multilevel/hierarchical models. Cambridge

230  1973.

model. In ICML  2008.

University Press  New York  2007.

Psychology  56(1):1–12  2012.

156–163  1991.

[10] S. J. Gershman and D. M. Blei. A tutorial on Bayesian nonparametric models. Journal of Mathematical

[11] C. J. Geyer. Markov chain Monte Carlo maximum likelihood. Computing Science and Statistics  pages

[12] M. Gutmann and J. Hirayama. Bregman divergence as general framework to estimate unnormalized

statistical models. In UAI  pages 283–290  Corvallis  Oregon  2011. AUAI Press.

[13] M. Gutmann and A. Hyv¨arinen. Noise-contrastive estimation: A new estimation principle for unnormal-

ized statistical models. In AISTATS  2010.

[14] L. A. Hannah  D. M. Blei  and W. B. Powell. Dirichlet process mixtures of generalized linear models.

[15] G. Hinton. Training products of experts by minimizing contrastive divergence. Neural Computation 

JMLR  12:1923–1953  2011.

14:1771–1800  2002.

[16] A. Hyvarinen. Connections between score matching  contrastive divergence  and pseudolikelihood for

continuous-valued variables. Neural Networks  IEEE Transactions on  18(5):1529–1531  2007.

[17] A. Hyv¨arinen. Some extensions of score matching. Computational statistics & data analysis  51(5):2499–

[18] S. Lyu. Unifying non-maximum likelihood learning objectives with minimum KL contraction. NIPS 

[19] M. Meila. Comparing clusterings by the variation of information. In COLT  2003.
[20] J. Møller  A. Pettitt  R. Reeves  and K. Berthelsen. An efﬁcient Markov chain Monte Carlo method for

distributions with intractable normalising constants. Biometrika  93(2):451–458  2006.

[21] I. Murray  Z. Ghahramani  and D. J. C. MacKay. MCMC for doubly-intractable distributions. In UAI 

[22] R. M. Neal. Markov chain sampling methods for Dirichlet process mixture models. Journal of Computa-

tional and Graphical Statistics  9(2):249–265  2000.

[23] P. Orbanz and Y. W. Teh. Bayesian nonparametric models.

In Encyclopedia of Machine Learning.

[24] K. Palla  D. A. Knowles  and Z. Ghahramani. An inﬁnite latent attribute model for network data.

In

[25] J. G. Propp and D. B. Wilson. Exact sampling with coupled Markov chains and applications to statistical

mechanics. Random structures and Algorithms  9(1-2):223–252  1996.
[26] C. E. Rasmussen. The inﬁnite Gaussian mixture model. In NIPS  2000.
[27] C. E. Rasmussen and Z. Ghahramani. Inﬁnite mixtures of Gaussian process experts. In NIPS  2001.
[28] B. Shahbaba and R. Neal. Nonlinear models using Dirichlet process mixtures. JMLR  10:1829–1850 

[29] T. Tieleman. Training restricted Boltzmann machines using approximations to the likelihood gradient. In

[30] T. Tieleman and G. Hinton. Using fast weights to improve persistent contrastive divergence. In ICML 

[31] D. Vickrey  C. Lin  and D. Koller. Non-local contrastive objectives. In Proc. of the International Confer-

ence on Machine Learning. Citeseer  2010.

[32] J. Zhu  N. Chen  and E. P. Xing. Inﬁnite latent SVM for classiﬁcation and multi-task learning. In NIPS 

[33] J. Zhu  N. Chen  and E. P. Xing. Inﬁnite SVM: a Dirichlet process mixture of large-margin kernel ma-

chines. In ICML  2011.

[34] S. C. Zhu and X. Liu. Learning in Gibbsian ﬁelds: How accurate and how fast can it be? IEEE Transac-

tions on Pattern Analysis and Machine Intelligence  24:1001–1006  2002.

2512  2007.

2011.

2006.

Springer  2010.

ICML  2012.

ICML  2008.

2009.

2009.

2011.

9

,Jie Liu
David Page
Prateek Jain
Nagarajan Natarajan
Ambuj Tewari
Timothy Rubin
Oluwasanmi Koyejo
Michael Jones
Tal Yarkoni
Yu-Chia Chen
Marina Meila