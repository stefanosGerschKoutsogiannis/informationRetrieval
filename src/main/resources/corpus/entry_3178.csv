2013,Learning with Noisy Labels,In this paper  we theoretically study the problem of binary classification in the presence of random classification noise --- the learner  instead of seeing the true labels  sees labels that have independently been flipped with some small probability. Moreover  random label noise is \emph{class-conditional} --- the flip probability depends on the class. We provide two approaches to suitably modify any given surrogate loss function. First  we provide a simple unbiased estimator of any loss  and obtain performance bounds for empirical risk minimization in the presence of iid data with noisy labels. If the loss function satisfies a simple symmetry condition  we show that the method leads to an efficient algorithm for empirical minimization. Second  by leveraging a reduction of risk minimization under noisy labels to classification with weighted 0-1 loss  we suggest the use of a simple weighted surrogate loss  for which we are able to obtain strong empirical risk bounds. This approach has a very remarkable consequence --- methods used in practice such as biased SVM and weighted logistic regression are provably noise-tolerant. On a synthetic non-separable dataset  our methods achieve over 88\% accuracy even when 40\% of the labels are corrupted  and are competitive with respect to recently proposed methods for dealing with label noise in several benchmark datasets.,Learning with Noisy Labels

Department of Computer Science  University of Texas  Austin.
{naga86 inderjit pradeepr}@cs.utexas.edu

Ambuj Tewari

Nagarajan Natarajan

Inderjit S. Dhillon

Pradeep Ravikumar

Department of Statistics  University of Michigan  Ann Arbor.

tewaria@umich.edu

Abstract

In this paper  we theoretically study the problem of binary classiﬁcation in the
presence of random classiﬁcation noise — the learner  instead of seeing the true la-
bels  sees labels that have independently been ﬂipped with some small probability.
Moreover  random label noise is class-conditional — the ﬂip probability depends
on the class. We provide two approaches to suitably modify any given surrogate
loss function. First  we provide a simple unbiased estimator of any loss  and ob-
tain performance bounds for empirical risk minimization in the presence of iid
data with noisy labels. If the loss function satisﬁes a simple symmetry condition 
we show that the method leads to an efﬁcient algorithm for empirical minimiza-
tion. Second  by leveraging a reduction of risk minimization under noisy labels
to classiﬁcation with weighted 0-1 loss  we suggest the use of a simple weighted
surrogate loss  for which we are able to obtain strong empirical risk bounds. This
approach has a very remarkable consequence — methods used in practice such
as biased SVM and weighted logistic regression are provably noise-tolerant. On
a synthetic non-separable dataset  our methods achieve over 88% accuracy even
when 40% of the labels are corrupted  and are competitive with respect to recently
proposed methods for dealing with label noise in several benchmark datasets.

1 Introduction
Designing supervised learning algorithms that can learn from data sets with noisy labels is a problem
of great practical importance. Here  by noisy labels  we refer to the setting where an adversary has
deliberately corrupted the labels [Biggio et al.  2011]  which otherwise arise from some “clean”
distribution; learning from only positive and unlabeled data [Elkan and Noto  2008] can also be cast
in this setting. Given the importance of learning from such noisy labels  a great deal of practical
work has been done on the problem (see  for instance  the survey article by Nettleton et al. [2010]).
The theoretical machine learning community has also investigated the problem of learning from
noisy labels. Soon after the introduction of the noise-free PAC model  Angluin and Laird [1988]
proposed the random classiﬁcation noise (RCN) model where each label is ﬂipped independently
with some probability ρ ∈ [0  1/2). It is known [Aslam and Decatur  1996  Cesa-Bianchi et al. 
1999] that ﬁniteness of the VC dimension characterizes learnability in the RCN model. Similarly  in
the online mistake bound model  the parameter that characterizes learnability without noise — the
Littestone dimension — continues to characterize learnability even in the presence of random label
noise [Ben-David et al.  2009]. These results are for the so-called “0-1” loss. Learning with convex
losses has been addressed only under limiting assumptions like separability or uniform noise rates
[Manwani and Sastry  2013].

In this paper  we consider risk minimization in the presence of class-conditional random label noise
(abbreviated CCN). The data consists of iid samples from an underlying “clean” distribution D.
The learning algorithm sees samples drawn from a noisy version Dρ of D — where the noise rates
depend on the class label. To the best of our knowledge  general results in this setting have not been
obtained before. To this end  we develop two methods for suitably modifying any given surrogate
loss function ℓ  and show that minimizing the sample average of the modiﬁed proxy loss function

1

˜ℓ leads to provable risk bounds where the risk is calculated using the original loss ℓ on the clean
distribution.

In our ﬁrst approach  the modiﬁed or proxy loss is an unbiased estimate of the loss function. The
idea of using unbiased estimators is well-known in stochastic optimization [Nemirovski et al.  2009] 
and regret bounds can be obtained for learning with noisy labels in an online learning setting (See
Appendix B). Nonetheless  we bring out some important aspects of using unbiased estimators of
loss functions for empirical risk minimization under CCN. In particular  we give a simple symmetry
condition on the loss (enjoyed  for instance  by the Huber  logistic  and squared losses) to ensure that
the proxy loss is also convex. Hinge loss does not satisfy the symmetry condition  and thus leads
to a non-convex problem. We nonetheless provide a convex surrogate  leveraging the fact that the
non-convex hinge problem is “close” to a convex problem (Theorem 6).

Our second approach is based on the fundamental observation that the minimizer of the risk (i.e.
probability of misclassiﬁcation) under the noisy distribution differs from that of the clean distribu-
tion only in where it thresholds η(x) = P (Y = 1|x) to decide the label. In order to correct for the
threshold  we then propose a simple weighted loss function  where the weights are label-dependent 
as the proxy loss function. Our analysis builds on the notion of consistency of weighted loss func-
tions studied by Scott [2012]. This approach leads to a very remarkable result that appropriately
weighted losses like biased SVMs studied by Liu et al. [2003] are robust to CCN.

The main results and the contributions of the paper are summarized below:

1. To the best of our knowledge  we are the ﬁrst to provide guarantees for risk minimization under
random label noise in the general setting of convex surrogates  without any assumptions on the
true distribution.

2. We provide two different approaches to suitably modifying any given surrogate loss function 
that surprisingly lead to very similar risk bounds (Theorems 3 and 11). These general results
include some existing results for random classiﬁcation noise as special cases.

3. We resolve an elusive theoretical gap in the understanding of practical methods like biased SVM

and weighted logistic regression — they are provably noise-tolerant (Theorem 11).

4. Our proxy losses are easy to compute — both the methods yield efﬁcient algorithms.
5. Experiments on benchmark datasets show that the methods are robust even at high noise rates.

The outline of the paper is as follows. We introduce the problem setting and terminology in Section
2. In Section 3  we give our ﬁrst main result concerning the method of unbiased estimators. In
Section 4  we give our second and third main results for certain weighted loss functions. We present
experimental results on synthetic and benchmark data sets in Section 5.

1.1 Related Work
Starting from the work of Bylander [1994]  many noise tolerant versions of the perceptron algorithm
have been developed. This includes the passive-aggressive family of algorithms [Crammer et al. 
2006]  conﬁdence weighted learning [Dredze et al.  2008]  AROW [Crammer et al.  2009] and the
NHERD algorithm [Crammer and Lee  2010]. The survey article by Khardon and Wachman [2007]
provides an overview of some of this literature. A Bayesian approach to the problem of noisy labels
is taken by Graepel and Herbrich [2000] and Lawrence and Sch¨olkopf [2001]. As Adaboost is very
sensitive to label noise  random label noise has also been considered in the context of boosting. Long
and Servedio [2010] prove that any method based on a convex potential is inherently ill-suited to
random label noise. Freund [2009] proposes a boosting algorithm based on a non-convex potential
that is empirically seen to be robust against random label noise.

Stempfel and Ralaivola [2009] proposed the minimization of an unbiased proxy for the case of
the hinge loss. However the hinge loss leads to a non-convex problem. Therefore  they proposed
heuristic minimization approaches for which no theoretical guarantees were provided (We address
the issue in Section 3.1). Cesa-Bianchi et al. [2011] focus on the online learning algorithms where
they only need unbiased estimates of the gradient of the loss to provide guarantees for learning with
noisy data. However  they consider a much harder noise model where instances as well as labels
are noisy. Because of the harder noise model  they necessarily require multiple noisy copies per
clean example and the unbiased estimation schemes also become fairly complicated. In particular 
their techniques break down for non-smooth losses such as the hinge loss. In contrast  we show
that unbiased estimation is always possible in the more benign random classiﬁcation noise setting.
Manwani and Sastry [2013] consider whether empirical risk minimization of the loss itself on the

2

noisy data is a good idea when the goal is to obtain small risk under the clean distribution. But
it holds promise only for 0-1 and squared losses. Therefore  if empirical risk minimization over
noisy samples has to work  we necessarily have to change the loss used to calculate the empirical
risk. More recently  Scott et al. [2013] study the problem of classiﬁcation under class-conditional
noise model. However  they approach the problem from a different set of assumptions — the noise
rates are not known  and the true distribution satisﬁes a certain “mutual irreducibility” property.
Furthermore  they do not give any efﬁcient algorithm for the problem.

2 Problem Setup and Background
Let D be the underlying true distribution generating (X  Y ) ∈ X × {±1} pairs from which n iid
samples (X1  Y1)  . . .   (Xn  Yn) are drawn. After injecting random classiﬁcation noise (indepen-
dently for each i) into these samples  corrupted samples (X1  ˜Y1)  . . .   (Xn  ˜Yn) are obtained. The
class-conditional random noise model (CCN  for short) is given by:

P ( ˜Y = −1|Y = +1) = ρ+1  P ( ˜Y = +1|Y = −1) = ρ−1  and ρ+1 + ρ−1 < 1

The corrupted samples are what the learning algorithm sees. We will assume that the noise rates
ρ+1 and ρ−1 are known1 to the learner. Let the distribution of (X  ˜Y ) be Dρ. Instances are denoted
by x ∈ X ⊆ Rd. Noisy labels are denoted by ˜y.
Let f : X → R be some real-valued decision function. The risk of f w.r.t. the 0-1 loss is given by
RD(f ) = E(X Y )∼D(cid:2)1{sign(f (X))6=Y }(cid:3). The optimal decision function (called Bayes optimal) that
minimizes RD over all real-valued decision functions is given by f ⋆(x) = sign(η(x) − 1/2) where
η(x) = P (Y = 1|x). We denote by R∗ the corresponding Bayes risk under the clean distribution
D  i.e. R∗ = RD(f∗). Let ℓ(t  y) denote a loss function where t ∈ R is a real-valued prediction and
y ∈ {±1} is a label. Let ˜ℓ(t  ˜y) denote a suitably modiﬁed ℓ for use with noisy labels (obtained using
methods in Sections 3 and 4). It is helpful to summarize the three important quantities associated
with a decision function f :

1. Empirical ˜ℓ-risk on the observed sample: bR˜ℓ(f ) := 1
2. As n grows  we expect bR˜ℓ(f ) to be close to the ˜ℓ-risk under the noisy distribution Dρ:

˜ℓ(f (Xi)  ˜Yi).

(f ) := E

R˜ℓ Dρ

nPn

i=1

(X  ˜Y )∼Dρh˜ℓ(f (X)  ˜Y )i .

3. ℓ-risk under the “clean” distribution D: Rℓ D(f ) := E(X Y )∼D [ℓ(f (X)  Y )].

Typically  ℓ is a convex function that is calibrated with respect to an underlying loss function such as
the 0-1 loss. ℓ is said to be classiﬁcation-calibrated [Bartlett et al.  2006] if and only if there exists a
convex  invertible  nondecreasing transformation ψℓ (with ψℓ(0) = 0) such that ψℓ(RD(f )− R∗) ≤
Rℓ D(f )−minf Rℓ D(f ). The interpretation is that we can control the excess 0-1 risk by controlling
the excess ℓ-risk.
If f is not quantiﬁed in a minimization  then it is implicit that the minimization is over all measurable
functions. Though most of our results apply to a general function class F  we instantiate F to be the
set of hyperplanes of bounded L2 norm  W = {w ∈ Rd : kwk2 ≤ W2} for certain speciﬁc results.
Proofs are provided in the Appendix A.

3 Method of Unbiased Estimators
Let F : X → R be a ﬁxed class of real-valued decision functions  over which the empirical risk is
minimized. The method of unbiased estimators uses the noise rates to construct an unbiased estima-
tor ˜ℓ(t  ˜y) for the loss ℓ(t  y). However  in the experiments we will tune the noise rate parameters
through cross-validation. The following key lemma tells us how to construct unbiased estimators of
the loss from noisy labels.
Lemma 1. Let ℓ(t  y) be any bounded loss function. Then  if we deﬁne 
(1 − ρ−y) ℓ(t  y) − ρy ℓ(t −y)

˜ℓ(t  y) :=

we have  for any t  y  E˜yh˜ℓ(t  ˜y)i = ℓ(t  y) .

1This is not necessary in practice. See Section 5.

1 − ρ+1 − ρ−1

3

We can try to learn a good predictor in the presence of label noise by minimizing the sample average

ˆf ← argmin
f∈F

bR˜ℓ(f ) .

By unbiasedness of ˜ℓ (Lemma 1)  we know that  for any ﬁxed f ∈ F  the above sample average
converges to Rℓ D(f ) even though the former is computed using noisy labels whereas the latter
depends on the true labels. The following result gives a performance guarantee for this procedure in
terms of the Rademacher complexity of the function class F. The main idea in the proof is to use
the contraction principle for Rademacher complexity to get rid of the dependence on the proxy loss
˜ℓ. The price to pay for this is Lρ  the Lipschitz constant of ˜ℓ.
Lemma 2. Let ℓ(t  y) be L-Lipschitz in t (for every y). Then  with probability at least 1 − δ 
where R(F ) := EXi ǫi(cid:2)supf∈F
n ǫif (Xi)(cid:3) is the Rademacher complexity of the function class F
and Lρ ≤ 2L/(1 − ρ+1 − ρ−1) is the Lipschitz constant of ˜ℓ. Note that ǫi’s are iid Rademacher
(symmetric Bernoulli) random variables.

(f )| ≤ 2LρR(F ) +r log(1/δ)

f∈F |bR˜ℓ(f ) − R˜ℓ Dρ

max

2n

1

The above lemma immediately leads to a performance bound for ˆf with respect to the clean distri-
bution D. Our ﬁrst main result is stated in the theorem below.
Theorem 3 (Main Result 1). With probability at least 1 − δ 

Rℓ D(f ) + 4LρR(F ) + 2r log(1/δ)

2n

.

Furthermore  if ℓ is classiﬁcation-calibrated  there exists a nondecreasing function ζℓ with ζℓ(0) = 0
such that 

Rℓ D( ˆf ) ≤ min
f∈F
RD( ˆf ) − R∗ ≤ ζℓ(cid:18) min

f∈F

Rℓ D(f ) − min

f

Rℓ D(f ) + 4LρR(F ) + 2r log(1/δ)
2n (cid:19) .

The term on the right hand side involves both approximation error (that is small if F is large) and
estimation error (that is small if F is small). However  by appropriately increasing the richness of
the class F with sample size  we can ensure that the misclassiﬁcation probability of ˆf approaches
the Bayes risk of the true distribution. This is despite the fact that the method of unbiased estimators
computes the empirical minimizer ˆf on a sample from the noisy distribution. Getting the optimal
empirical minimizer ˆf is efﬁcient if ˜ℓ is convex. Next  we address the issue of convexity of ˜ℓ.
3.1 Convex losses and their estimators
Note that the loss ˜ℓ may not be convex even if we start with a convex ℓ. An example is provided
by the familiar hinge loss ℓhin(t  y) = [1 − yt]+. Stempfel and Ralaivola [2009] showed that ˜ℓhin is
not convex in general (of course  when ρ+1 = ρ−1 = 0  it is convex). Below we provide a simple
condition to ensure convexity of ˜ℓ.
Lemma 4. Suppose ℓ(t  y) is convex and twice differentiable almost everywhere in t (for every y)
and also satisﬁes the symmetry property

∀t ∈ R  ℓ′′(t  y) = ℓ′′(t −y) .

Then ˜ℓ(t  y) is also convex in t.
Examples satisfying the conditions of the lemma above are the squared loss ℓsq(t  y) = (t − y)2  the
logistic loss ℓlog(t  y) = log(1 + exp(−ty)) and the Huber loss:
if yt < −1
if − 1 ≤ yt ≤ 1
if yt > 1

−4yt
(t − y)2
0

Consider the case where ˜ℓ turns out to be non-convex when ℓ is convex  as in ˜ℓhin. In the online
learning setting (where the adversary chooses a sequence of examples  and the prediction of a learner
at round i is based on the history of i − 1 examples with independently ﬂipped labels)  we could
use a stochastic mirror descent type algorithm [Nemirovski et al.  2009] to arrive at risk bounds (See
Appendix B) similar to Theorem 3. Then  we only need the expected loss to be convex and therefore

ℓHub(t  y) =

4

ℓhin does not present a problem. At ﬁrst blush  it may appear that we do not have much hope of
obtaining ˆf in the iid setting efﬁciently. However  Lemma 2 provides a clue.

(w). Since R˜ℓ Dρ

We will now focus on the function class W of hyperplanes. Even though bR˜ℓ(w) is non-convex  it
(w) = Rℓ D(w)  this shows that bR˜ℓ(w) is uniformly
is uniformly close to R˜ℓ Dρ
close to a convex function over w ∈ W. The following result shows that we can therefore approx-
imately minimize F (w) = bR˜ℓ(w) by minimizing the biconjugate F ⋆⋆. Recall that the (Fenchel)
biconjugate F ⋆⋆ is the largest convex function that minorizes F .
Lemma 5. Let F : W → R be a non-convex function deﬁned on function class W such it is ε-close
to a convex function G : W → R:
Then any minimizer of F ⋆⋆ is a 2ε-approximate (global) minimizer of F .
Now  the following theorem establishes bounds for the case when ˜ℓ is non-convex  via the solution
obtained by minimizing the convex function F ∗∗.
Theorem 6. Let ℓ be a loss  such as the hinge loss  for which ˜ℓ is non-convex. Let W = {w :
kw2k ≤ W2}  let kXik2 ≤ X2 almost surely  and let ˆwapprox be any (exact) minimizer of the
convex problem

∀w ∈ W  |F (w) − G(w)| ≤ ε

F ⋆⋆(w)  

min
w∈W

where F ⋆⋆(w) is the (Fenchel) biconjugate of the function F (w) = bR˜ℓ(w). Then  with probability
at least 1 − δ  ˆwapprox is a 2ε-minimizer of bR˜ℓ(·) where

ε =

2LρX2W2√n

+r log(1/δ)

2n

.

Therefore  with probability at least 1 − δ 

Rℓ D( ˆwapprox) ≤ min
w∈W

Rℓ D(w) + 4ε .

Numerical or symbolic computation of the biconjugate of a multidimensional function is difﬁcult 
in general  but can be done in special cases. It will be interesting to see if techniques from Compu-
tational Convex Analysis [Lucet  2010] can be used to efﬁciently compute the biconjugate above.
4 Method of label-dependent costs
We develop the method of label-dependent costs from two key observations. First  the Bayes clas-
siﬁer for noisy distribution  denoted ˜f∗  for the case ρ+1 6= ρ−1  simply uses a threshold different
from 1/2. Second  ˜f∗ is the minimizer of a “label-dependent 0-1 loss” on the noisy distribution. The
framework we develop here generalizes known results for the uniform noise rate setting ρ+1 = ρ−1
and offers a more fundamental insight into the problem. The ﬁrst observation is formalized in the
lemma below.
Lemma 7. Denote P (Y = 1|X) by η(X) and P ( ˜Y = 1|X) by ˜η(X). The Bayes classiﬁer under
the noisy distribution  ˜f∗ = argminf E(X  ˜Y )∼Dρ(cid:2)1

˜f∗(x) = sign(˜η(x) − 1/2) = sign(cid:18)η(x) −

{sign(f (X))6= ˜Y }(cid:3) is given by 
1 − ρ+1 − ρ−1(cid:19).

1/2 − ρ−1

Interestingly  this “noisy” Bayes classiﬁer can also be obtained as the minimizer of a weighted 0-1
loss; which as we will show  allows us to “correct” for the threshold under the noisy distribution.
Let us ﬁrst introduce the notion of “label-dependent” costs for binary classiﬁcation. We can write
the 0-1 loss as a label-dependent loss as follows:

1{sign(f (X))6=Y } = 1{Y =1}1{f (X)≤0} + 1{Y =−1}1{f (X)>0}

We realize that the classical 0-1 loss is unweighted. Now  we could consider an α-weighted version
of the 0-1 loss as:

Uα(t  y) = (1 − α)1{y=1}1{t≤0} + α1{y=−1}1{t>0} 

where α ∈ (0  1). In fact we see that minimization w.r.t.
the 0-1 loss is equivalent to that w.r.t.
U1/2(f (X)  Y ). It is not a coincidence that Bayes optimal f∗ has a threshold 1/2. The following
lemma [Scott  2012] shows that in fact for any α-weighted 0-1 loss  the minimizer thresholds η(x)
at α.

5

Lemma 8 (α-weighted Bayes optimal [Scott  2012]). Deﬁne Uα-risk under distribution D as

Rα D(f ) = E(X Y )∼D[Uα(f (X)  Y )].

Then  f∗α(x) = sign(η(x) − α) minimizes Uα-risk.
Now consider the risk of f w.r.t. the α-weighted 0-1 loss under noisy distribution Dρ:

Rα Dρ (f ) = E(X  ˜Y )∼Dρ(cid:2)Uα(f (X)  ˜Y )(cid:3).

At this juncture  we are interested in the following question: Does there exist an α ∈ (0  1) such
that the minimizer of Uα-risk under noisy distribution Dρ has the same sign as that of the Bayes
optimal f∗? We now present our second main result in the following theorem that makes a stronger
statement — the Uα-risk under noisy distribution Dρ is linearly related to the 0-1 risk under the
clean distribution D. The corollary of the theorem answers the question in the afﬁrmative.
Theorem 9 (Main Result 2). For the choices 
1 − ρ+1 + ρ−1

1 − ρ+1 − ρ−1

and Aρ =

α∗ =

 

2

2

there exists a constant BX that is independent of f such that  for all functions f  

Rα∗ Dρ (f ) = AρRD(f ) + BX .

Corollary 10. The α⋆-weighted Bayes optimal classiﬁer under noisy distribution coincides with
that of 0-1 loss under clean distribution:

argmin

f

Rα∗ Dρ(f ) = argmin

f

RD(f ) = sign(η(x) − 1/2).

4.1 Proposed Proxy Surrogate Losses
Consider any surrogate loss function ℓ; and the following decomposition:

ℓ(t  y) = 1{y=1}ℓ1(t) + 1{y=−1}ℓ−1(t)

where ℓ1 and ℓ−1 are partial losses of ℓ. Analogous to the 0-1 loss case  we can deﬁne α-weighted
loss function (Eqn. (1)) and the corresponding α-weighted ℓ-risk. Can we hope to minimize an α-
weighted ℓ-risk with respect to noisy distribution Dρ and yet bound the excess 0-1 risk with respect
to the clean distribution D? Indeed  the α⋆ speciﬁed in Theorem 9 is precisely what we need. We are
ready to state our third main result  which relies on a generalized notion of classiﬁcation calibration
for α-weighted losses [Scott  2012]:
Theorem 11 (Main Result 3). Consider the empirical risk minimization problem with noisy labels:

Deﬁne ℓα as an α-weighted margin loss function of the form:

ˆfα = argmin

ℓα(f (Xi)  ˜Yi).

1
n

nXi=1

f∈F

′

ρ ζℓα⋆(cid:18) min

ℓα(t  y) = (1 − α)1{y=1}ℓ(t) + α1{y=−1}ℓ(−t)

(1)
where ℓ : R → [0 ∞) is a convex loss function with Lipschitz constant L such that it is classiﬁcation-
(0) < 0). Then  for the choices α∗ and Aρ in Theorem 9  there exists a nonde-
calibrated (i.e. ℓ
creasing function ζℓα⋆ with ζℓα⋆ (0) = 0  such that the following bound holds with probability at
least 1 − δ:
RD( ˆfα∗ ) − R∗ ≤ A−1
Aside from bounding excess 0-1 risk under the clean distribution  the importance of the above the-
orem lies in the fact that it prescribes an efﬁcient algorithm for empirical minimization with noisy
labels: ℓα is convex if ℓ is convex. Thus for any surrogate loss function including ℓhin  ˆfα∗ can be
efﬁciently computed using the method of label-dependent costs. Note that the choice of α∗ above
is quite intuitive. For instance  when ρ−1 ≪ ρ+1 (this occurs in settings such as Liu et al. [2003]
where there are only positive and unlabeled examples)  α∗ < 1 − α∗ and therefore mistakes on
positives are penalized more than those on negatives. This makes intuitive sense since an observed
negative may well have been a positive but the other way around is unlikely. In practice we do not
need to know α∗  i.e.
the noise rates ρ+1 and ρ−1. The optimization problem involves just one
parameter that can be tuned by cross-validation (See Section 5).

Rα∗ Dρ(f ) + 4LR(F ) + 2r log(1/δ)
2n (cid:19).

Rα∗ Dρ(f ) − min

f∈F

f

6

5 Experiments
We show the robustness of the proposed algorithms to increasing rates of label noise on synthetic and
real-world datasets. We compare the performance of the two proposed methods with state-of-the-art
methods for dealing with random classiﬁcation noise. We divide each dataset (randomly) into 3
training and test sets. We use a cross-validation set to tune the parameters speciﬁc to the algorithms.
Accuracy of a classiﬁcation algorithm is deﬁned as the fraction of examples in the test set classiﬁed
correctly with respect to the clean distribution. For given noise rates ρ+1 and ρ−1  labels of the
training data are ﬂipped accordingly and average accuracy over 3 train-test splits is computed2. For
evaluation  we choose a representative algorithm based on each of the two proposed methods — ˜ℓlog
for the method of unbiased estimators and the widely-used C-SVM [Liu et al.  2003] method (which
applies different costs on positives and negatives) for the method of label-dependent costs.
5.1 Synthetic data
First  we use the synthetic 2D linearly separable dataset shown in Figure 1(a). We observe from
experiments that our methods achieve over 90% accuracy even when ρ+1 = ρ−1 = 0.4. Figure 1
shows the performance of ˜ℓlog on the dataset for different noise rates. Next  we use a 2D UCI
benchmark non-separable dataset (‘banana’). The dataset and classiﬁcation results using C-SVM
(in fact  for uniform noise rates  α∗ = 1/2  so it is just the regular SVM) are shown in Figure 2. The
results for higher noise rates are impressive as observed from Figures 2(d) and 2(e). The ‘banana’
dataset has been used in previous research on classiﬁcation with noisy labels.
In particular  the
Random Projection classiﬁer [Stempfel and Ralaivola  2007] that learns a kernel perceptron in the
presence of noisy labels achieves about 84% accuracy at ρ+1 = ρ−1 = 0.3 as observed from
our experiments (as well as shown by Stempfel and Ralaivola [2007])  and the random hyperplane
sampling method [Stempfel et al.  2007] gets about the same accuracy at (ρ+1  ρ−1) = (0.2  0.4) (as
reported by Stempfel et al. [2007]). Contrast these with C-SVM that achieves about 90% accuracy
at ρ+1 = ρ−1 = 0.2 and over 88% accuracy at ρ+1 = ρ−1 = 0.4.

100

80

60

40

20

0

−20

−40

−60

−80

100

80

60

40

20

0

−20

−40

−60

−80

100

80

60

40

20

0

−20

−40

−60

−80

100

80

60

40

20

0

−20

−40

−60

−80

100

80

60

40

20

0

−20

−40

−60

−80

−100

−100

−80

−60

−40

−20

0

20

40

60

80

100

−100

−100

−80

−60

−40

−20

0

20

40

60

80

100

−100

−100

−80

−60

−40

−20

0

20

40

60

80

100

−100

−100

−80

−60

−40

−20

0

20

40

60

80

100

−100

−100

−80

−60

−40

−20

0

20

40

60

80

100

(a)

(b)

(c)

(d)

(e)

Figure 1: Classiﬁcation of linearly separable synthetic data set using ˜ℓlog. The noise-free data is
shown in the leftmost panel. Plots (b) and (c) show training data corrupted with noise rates (ρ+1 =
ρ−1 = ρ) 0.2 and 0.4 respectively. Plots (d) and (e) show the corresponding classiﬁcation results.
The algorithm achieves 98.5% accuracy even at 0.4 noise rate per class. (Best viewed in color).

4

3

2

1

0

−1

−2

−3
−4

−3

−2

−1

0

1

2

3

4

3

2

1

0

−1

−2

−3
−4

−3

−2

−1

0

1

2

3

4

3

2

1

0

−1

−2

−3
−4

−3

−2

−1

0

1

2

3

4

3

2

1

0

−1

−2

−3
−4

−3

−2

−1

0

1

2

3

4

3

2

1

0

−1

−2

−3
−4

−3

−2

−1

0

1

2

3

(a)

(b)

(c)

(d)

(e)

Figure 2: Classiﬁcation of ‘banana’ data set using C-SVM. The noise-free data is shown in (a). Plots
(b) and (c) show training data corrupted with noise rates (ρ+1 = ρ−1 = ρ) 0.2 and 0.4 respectively.
Note that for ρ+1 = ρ−1  α∗ = 1/2 (i.e. C-SVM reduces to regular SVM). Plots (d) and (e) show
the corresponding classiﬁcation results (Accuracies are 90.6% and 88.5% respectively). Even when
40% of the labels are corrupted (ρ+1 = ρ−1 = 0.4)  the algorithm recovers the class structures as
observed from plot (e). Note that the accuracy of the method at ρ = 0 is 90.8%.

5.2 Comparison with state-of-the-art methods on UCI benchmark
We compare our methods with three state-of-the-art methods for dealing with random classi-
ﬁcation noise: Random Projection (RP) classiﬁer [Stempfel and Ralaivola  2007])  NHERD

2Note that training and cross-validation are done on the noisy training data in our setting. To account for
randomness in the ﬂips to simulate a given noise rate  we repeat each experiment 3 times — independent
corruptions of the data set for same setting of ρ+1 and ρ−1  and present the mean accuracy over the trials.

7

DATASET (d  n+  n−)
Breast cancer
(9  77  186)

Diabetes
(8  268  500)

Thyroid
(5  65  150)

German
(20  300  700)

Heart
(13  120  150)

Image
(18  1188  898)

ρ+1 = 0.3  ρ−1 = 0.1

ρ+1 = 0.3  ρ−1 = 0.1

Noise rates

ρ+1 = ρ−1 = 0.2
ρ+1 = ρ−1 = 0.4
ρ+1 = ρ−1 = 0.2
ρ+1 = ρ−1 = 0.4
ρ+1 = ρ−1 = 0.2
ρ+1 = ρ−1 = 0.4
ρ+1 = ρ−1 = 0.2
ρ+1 = ρ−1 = 0.4
ρ+1 = ρ−1 = 0.2
ρ+1 = ρ−1 = 0.4
ρ+1 = ρ−1 = 0.2
ρ+1 = ρ−1 = 0.4

ρ+1 = 0.3  ρ−1 = 0.1

ρ+1 = 0.3  ρ−1 = 0.1

ρ+1 = 0.3  ρ−1 = 0.1

ρ+1 = 0.3  ρ−1 = 0.1

˜ℓlog C-SVM PAM NHERD
64.90
65.68
56.50
73.18
74.74
71.09
78.49
87.78
85.95
67.80
67.80
54.80
82.96
81.48
52.59
77.76
79.39
69.61

69.34
67.79
67.05
69.53
65.89
65.36
96.22
86.85
70.98
63.80
67.80
67.80
69.63
62.22
53.33
92.90
89.55
73.15

67.85
67.81
67.79
66.41
66.41
65.89
94.31
92.46
66.32
68.40
68.40
68.40
61.48
57.04
54.81
91.95
89.26
63.47

70.12
70.07
67.79
76.04
75.52
65.89
87.80
80.34
83.10
71.80
71.40
67.19
82.96
84.44
57.04
82.45
82.55
63.47

RP
69.38
66.28
54.19
75.00
67.71
62.76
84.02
83.12
57.96
62.80
67.40
59.79
72.84
79.26
68.15
65.29
70.66
64.72

Table 1: Comparative study of classiﬁcation algorithms on UCI benchmark datasets. Entries within
1% from the best in each row are in bold. All the methods except NHERD variants (which
are not kernelizable) use Gaussian kernel with width 1. All method-speciﬁc parameters are esti-
mated through cross-validation. Proposed methods (˜ℓlog and C-SVM) are competitive across all the
datasets. We show the best performing NHERD variant (‘project’ and ‘exact’) in each case.
[Crammer and Lee  2010]) (project and exact variants3)  and perceptron algorithm with mar-
gin (PAM) which was shown to be robust to label noise by Khardon and Wachman [2007].
We use the standard UCI classiﬁcation datasets  preprocessed and made available by Gunnar
R¨atsch(http://theoval.cmp.uea.ac.uk/matlab). For kernelized algorithms  we use
Gaussian kernel with width set to the best width obtained by tuning it for a traditional SVM on
the noise-free data. For ˜ℓlog  we use ρ+1 and ρ−1 that give the best accuracy in cross-validation. For
C-SVM  we ﬁx one of the weights to 1  and tune the other. Table 1 shows the performance of the
methods for different settings of noise rates. C-SVM is competitive in 4 out of 6 datasets (Breast
cancer  Thyroid  German and Image)  while relatively poorer in the other two. On the other hand 
˜ℓlog is competitive in all the data sets  and performs the best more often. When about 20% labels are
corrupted  uniform (ρ+1 = ρ−1 = 0.2) and non-uniform cases (ρ+1 = 0.3  ρ−1 = 0.1) have similar
accuracies in all the data sets  for both C-SVM and ˜ℓlog. Overall  we observe that the proposed
methods are competitive and are able to tolerate moderate to high amounts of label noise in the data.
Finally  in domains where noise rates are approximately known  our methods can beneﬁt from the
knowledge of noise rates. Our analysis shows that the methods are fairly robust to misspeciﬁcation
of noise rates (See Appendix C for results).
6 Conclusions and Future Work
We addressed the problem of risk minimization in the presence of random classiﬁcation noise  and
obtained general results in the setting using the methods of unbiased estimators and weighted loss
functions. We have given efﬁcient algorithms for both the methods with provable guarantees for
learning under label noise. The proposed algorithms are easy to implement and the classiﬁcation
performance is impressive even at high noise rates and competitive with state-of-the-art methods on
benchmark data. The algorithms already give a new family of methods that can be applied to the
positive-unlabeled learning problem [Elkan and Noto  2008]  but the implications of the methods for
this setting should be carefully analysed. We could consider harder noise models such as label noise
depending on the example  and “nasty label noise” where labels to ﬂip are chosen adversarially.
7 Acknowledgments
This research was supported by DOD Army grant W911NF-10-1-0529 to ID; PR acknowledges the
support of ARO via W911NF-12-1-0390 and NSF via IIS-1149803  IIS-1320894.

3A family of methods proposed by Crammer and coworkers [Crammer et al.  2006  2009  Dredze et al. 
2008] could be compared to  but [Crammer and Lee  2010] show that the 2 NHERD variants perform the best.

8

References
D. Angluin and P. Laird. Learning from noisy examples. Mach. Learn.  2(4):343–370  1988.
Javed A. Aslam and Scott E. Decatur. On the sample complexity of noise-tolerant learning. Inf. Process. Lett. 

57(4):189–195  1996.

Peter L. Bartlett  Michael I. Jordan  and Jon D. McAuliffe. Convexity  classiﬁcation  and risk bounds. Journal

of the American Statistical Association  101(473):138–156  2006.

Shai Ben-David  D´avid P´al  and Shai Shalev-Shwartz. Agnostic online learning. In Proceedings of the 22nd

Conference on Learning Theory  2009.

Battista Biggio  Blaine Nelson  and Pavel Laskov. Support vector machines under adversarial label noise.

Journal of Machine Learning Research - Proceedings Track  20:97–112  2011.

Tom Bylander. Learning linear threshold functions in the presence of classiﬁcation noise. In Proc. of the 7th

COLT  pages 340–347  NY  USA  1994. ACM.

Nicol`o Cesa-Bianchi  Eli Dichterman  Paul Fischer  Eli Shamir  and Hans Ulrich Simon. Sample-efﬁcient

strategies for learning in the presence of noise. J. ACM  46(5):684–719  1999.

Nicol`o Cesa-Bianchi  Shai Shalev-Shwartz  and Ohad Shamir. Online learning of noisy data. IEEE Transac-

tions on Information Theory  57(12):7907–7931  2011.

K. Crammer and D. Lee. Learning via gaussian herding. In Advances in NIPS 23  pages 451–459  2010.
Koby Crammer  Ofer Dekel  Joseph Keshet  Shai Shalev-Shwartz  and Yoram Singer. Online passive-aggressive

algorithms. J. Mach. Learn. Res.  7:551–585  2006.

Koby Crammer  Alex Kulesza  and Mark Dredze. Adaptive regularization of weight vectors. In Advances in

NIPS 22  pages 414–422  2009.

Mark Dredze  Koby Crammer  and Fernando Pereira. Conﬁdence-weighted linear classiﬁcation. In Proceedings

of the Twenty-Fifth ICML  pages 264–271  2008.

C. Elkan and K. Noto. Learning classiﬁers from only positive and unlabeled data. In Proc. of the 14th ACM

SIGKDD intl. conf. on Knowledge discovery and data mining  pages 213–220  2008.

Yoav Freund. A more robust boosting algorithm  2009. preprint arXiv:0905.2138 [stat.ML] available

at http://arxiv.org/abs/0905.2138.

T. Graepel and R. Herbrich. The kernel Gibbs sampler. In Advances in NIPS 13  pages 514–520  2000.
Roni Khardon and Gabriel Wachman. Noise tolerant variants of the perceptron algorithm. J. Mach. Learn.

Res.  8:227–248  2007.

Neil D. Lawrence and Bernhard Sch¨olkopf. Estimating a kernel Fisher discriminant in the presence of label

noise. In Proceedings of the Eighteenth ICML  pages 306–313  2001.

Bing Liu  Yang Dai  Xiaoli Li  Wee Sun Lee  and Philip S Yu. Building text classiﬁers using positive and

unlabeled examples. In ICDM 2003.  pages 179–186. IEEE  2003.

Philip M. Long and Rocco A. Servedio. Random classiﬁcation noise defeats all convex potential boosters.

Mach. Learn.  78(3):287–304  2010.

Yves Lucet. What shape is your conjugate? a survey of computational convex analysis and its applications.

SIAM Rev.  52(3):505–542  August 2010. ISSN 0036-1445.

Naresh Manwani and P. S. Sastry. Noise tolerance under risk minimization. To appear in IEEE Trans. Syst.

Man and Cybern. Part B  2013. URL: http://arxiv.org/abs/1109.5231.

A. Nemirovski  A. Juditsky  G. Lan  and A. Shapiro. Robust stochastic approximation approach to stochastic

programming. SIAM J. on Opt.  19(4):1574–1609  2009.

David F. Nettleton  A. Orriols-Puig  and A. Fornells. A study of the effect of different types of noise on the

precision of supervised learning techniques. Artif. Intell. Rev.  33(4):275–306  2010.

Clayton Scott. Calibrated asymmetric surrogate losses. Electronic J. of Stat.  6:958–992  2012.
Clayton Scott  Gilles Blanchard  and Gregory Handy. Classiﬁcation with asymmetric label noise: Consistency

and maximal denoising. To appear in COLT  2013.

G. Stempfel and L. Ralaivola. Learning kernel perceptrons on noisy data using random projections. In Algo-

rithmic Learning Theory  pages 328–342. Springer  2007.

G. Stempfel  L. Ralaivola  and F. Denis. Learning from noisy data using hyperplane sampling and sample

averages. 2007.

Guillaume Stempfel and Liva Ralaivola. Learning SVMs from sloppily labeled data. In Proc. of the 19th Intl.

Conf. on Artiﬁcial Neural Networks: Part I  pages 884–893. Springer-Verlag  2009.

Martin Zinkevich. Online convex programming and generalized inﬁnitesimal gradient ascent. In Proceedings

of the Twentieth ICML  pages 928–936  2003.

9

,Nagarajan Natarajan
Inderjit Dhillon
Pradeep Ravikumar
Ambuj Tewari
Ralph Bourdoukan
Sophie Denève
Sepehr Assadi
Eric Balkanski
Renato Leme