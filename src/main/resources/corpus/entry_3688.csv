2017,Near-Optimal Edge Evaluation in Explicit Generalized Binomial Graphs,Robotic motion-planning problems  such as a UAV flying fast in a partially-known environment or a robot arm moving around cluttered objects  require finding collision-free paths quickly. Typically  this is solved by constructing a graph  where vertices represent robot configurations and edges represent potentially valid movements of the robot between theses configurations. The main computational bottlenecks are expensive edge evaluations to check for collisions. State of the art planning methods do not reason about the optimal sequence of edges to evaluate in order to find a collision free path quickly. In this paper  we do so by drawing a novel equivalence between motion planning and the Bayesian active learning paradigm of decision region determination (DRD). Unfortunately  a straight application of ex- isting methods requires computation exponential in the number of edges in a graph. We present BISECT  an efficient and near-optimal algorithm to solve the DRD problem when edges are independent Bernoulli random variables. By leveraging this property  we are able to significantly reduce computational complexity from exponential to linear in the number of edges. We show that BISECT outperforms several state of the art algorithms on a spectrum of planning problems for mobile robots  manipulators  and real flight data collected from a full scale helicopter. Open-source code and details can be found here: https://github.com/sanjibac/matlab_learning_collision_checking,Near-Optimal Edge Evaluation in Explicit

Generalized Binomial Graphs

Sanjiban Choudhury
The Robotics Institute

Carnegie Mellon University

sanjiban@cmu.edu

Shervin Javdani

The Robotics Institute

Carnegie Mellon University

sjavdani@cmu.edu

Siddhartha Srinivasa
The Robotics Institute

Carnegie Mellon University

siddh@cs.cmu.edu

Sebastian Scherer
The Robotics Institute

Carnegie Mellon University

basti@cs.cmu.edu

Abstract

Robotic motion-planning problems  such as a UAV ﬂying fast in a partially-known
environment or a robot arm moving around cluttered objects  require ﬁnding
collision-free paths quickly. Typically  this is solved by constructing a graph 
where vertices represent robot conﬁgurations and edges represent potentially valid
movements of the robot between these conﬁgurations. The main computational
bottlenecks are expensive edge evaluations to check for collisions. State of the art
planning methods do not reason about the optimal sequence of edges to evaluate
in order to ﬁnd a collision free path quickly. In this paper  we do so by drawing
a novel equivalence between motion planning and the Bayesian active learning
paradigm of decision region determination (DRD). Unfortunately  a straight ap-
plication of existing methods requires computation exponential in the number
of edges in a graph. We present BISECT  an efﬁcient and near-optimal algo-
rithm to solve the DRD problem when edges are independent Bernoulli random
variables. By leveraging this property  we are able to signiﬁcantly reduce compu-
tational complexity from exponential to linear in the number of edges. We show
that BISECT outperforms several state of the art algorithms on a spectrum of
planning problems for mobile robots  manipulators  and real ﬂight data collected
from a full scale helicopter. Open-source code and details can be found here:
https://github.com/sanjibac/matlab_learning_collision_checking

1

Introduction

Motion planning  the task of computing collision-free motions for a robotic system from a start to
a goal conﬁguration  has a rich and varied history [23]. Up until now  the bulk of the prominent
research has focused on the development of tractable planning algorithms with provable worst-case
performance guarantees such as computational complexity [3]  probabilistic completeness [24] or
asymptotic optimality [20]. In contrast  analysis of the expected performance of these algorithms
on the real world planning problems a robot encounters has received considerably less attention 
primarily due to the lack of standardized datasets or robotic platforms. However  recent advances in
affordable sensors and actuators have enabled mass deployment of robots that navigate  interact and
collect real data. This motivates us to examine the following question: “How can we design planning
algorithms that  subject to on-board computation constraints  maximize their expected performance
on the actual distribution of problems that a robot encounters?”
This paper addresses a class of robotic motion planning problems where path evaluation is expensive.
For example  in robot arm planning [12]  evaluation requires expensive geometric intersection

31st Conference on Neural Information Processing Systems (NIPS 2017)  Long Beach  CA  USA.

Figure 1: The feasible path identiﬁcation problem (a) The explicit graph contains dynamically feasible
maneuvers [27] for a UAV ﬂying fast  with a set candidate paths. The map shows the distribution of edge validity
for the graph. (b) Given a distribution over edges  our algorithm checks an edge  marks it as invalid (red) or
valid (green)  and updates its belief. We continue until a feasible path is identiﬁed as free. We aim to minimize
the number of expensive edge evaluations.

computations. In UAV path planning [9]  evaluation must be done online with limited computational
resources (Fig. 1).
State of the art planning algorithms [11] ﬁrst compute a set of unevaluated paths quickly  and then
evaluate them sequentially to ﬁnd a valid path. Oftentimes  candidate paths share common edges.
Hence  evaluation of a small number of edges can provide information about the validity of many
candidate paths simultaneously. Methods that check paths sequentially  however  do not reason about
these common edges.
This leads us naturally to the feasible path identiﬁcation problem - given a library of candidate
paths  identify a valid path while minimizing the cost of edge evaluations. We assume access to a
prior distribution over edge validity  which encodes how obstacles are distributed in the environment
(Fig. 1(a)). As we evaluate edges and observe outcomes  the uncertainty of a candidate path collapses.
Our ﬁrst key insight is that this problem is equivalent to decision region determination (DRD) [19  5])
- given a set of tests (edges)  hypotheses (validity of edges)  and regions (paths)  the objective is to
drive uncertainty into a single decision region. This linking enables us to leverage existing methods
in Bayesian active learning for robotic motion planning.
Chen et al. [5] provide a method to solve this problem by maximizing an objective function that
satisﬁes adaptive submodularity [15] - a natural diminishing returns property that endows greedy
policies with near-optimality guarantees. Unfortunately  naively applying this algorithm requires
O
We deﬁne the Bern-DRD problem  which leverages additional structure in robotic motion planning
by assuming edges are independent Bernoulli random variables 1  and regions correspond to sets of
edges evaluating to true. We propose Bernoulli Subregion Edge Cutting (BISECT)  which provides
a greedy policy to select candidate edges in O (E). We prove our surrogate objective also satisﬁes
adaptive submodularity [15]  and provides the same bounds as Chen et al. [5] while being more
efﬁcient to compute.
We make the following contributions:

(cid:0)2E(cid:1) computation to select an edge to evaluate  where E is the number of edges in all paths.

1. We show a novel equivalence between feasible path identiﬁcation and the DRD problem 

linking motion planning to Bayesian active learning.

(cid:0)2E(cid:1).

2. We develop BISECT  a near-optimal algorithm for the special case of Bernoulli tests  which

selects tests in O (E) instead of O
robots  manipulators  and real ﬂight data collected from a full scale helicopter.

3. We demonstrate the efﬁcacy of our algorithm on a spectrum of planning problems for mobile

1Generally  edges in this graph are correlated  as edges in collision are likely to have neighbours in collision.
Unfortunately  even measuring this correlation is challenging  especially in the high-dimensional non-linear
conﬁguration space of robot arms. Assuming independent edges is a common simpliﬁcation [23  25  7  2  11]

2

(a)(b)||&&⇥enabled⇥&&Xtcaseq⇥intentnotknownX!tcaseqX1||&&⇥enabled⇥&&Xtcaseq⇥intentnotknownX!tcaseqX1||&&⇥enabled⇥&&Xtcaseq⇥intentnotknownX!tcaseqX1||&&⇥enabled⇥&&Xtcaseq⇥intentnotknownX!tcaseqX12 Problem Formulation

2.1 Planning as Feasible Path Identiﬁcation on Explicit Graphs

Let G = (V  E) be an explicit graph that consists of a set of vertices V and edges E. Given
a pair of start and goal vertices  (vs  vg) ∈ V   a search algorithm computes a path ξ ⊆ E - a
connected sequence of valid edges. To ascertain the validity of an edge  it invokes an evaluation
function Eval : E → {0  1}. We address applications where edge evaluation is expensive  i.e.  the
computational cost c(e) of computing Eval(e) is signiﬁcantly higher than regular search operations2.
|E| which assigns to each edge a boolean validity
We deﬁne a world as an outcome vector o ∈ {0  1}
when evaluated  i.e. Eval(e) = o(e). We assume that the outcome vector is sampled from an
independent Bernoulli distribution P (o)  giving rise to a Generalized Binomial Graph (GBG) [13].
We make a second simpliﬁcation to the problem - from that of search to that of identiﬁcation. Instead
of searching G online for a path  we frame the problem as identifying a valid path from a library
of ‘good’ candidate paths Ξ = (ξ1  ξ2  . . .   ξm). The candidate set of paths Ξ is constructed ofﬂine 
while being cognizant of P (o)  and can be veriﬁed to ensure that all paths have acceptable solution
quality when valid. 3 Hence we care about completeness with respect to Ξ instead of G.
We wish to design an adaptive edge selector Select(o) which is a decision tree that operates on a
world o  selects an edge for evaluation and branches on its outcome. The total cost of edge evaluation
is c(Select(o)). Our objective is to minimize the cost required to ﬁnd a valid path:

(cid:89)

e∈ξ

min Eo∈P (o) [c(Select(o))] s.t ∀o ∃ξ :

o(e) = 1   ξ ⊆ Select(o)

(1)

2.2 Decision Region Determination with Independent Bernoulli Tests

if all tests in that region evaluate to true  which has probability P (R) = (cid:81)

We now deﬁne an equivalent problem - decision region determination with independent Bernoulli
tests (Bern-DRD). Deﬁne a set of tests T = {1  . . .   n}  where the outcome of each test is a Bernoulli
t (1− θt)1−xt. We deﬁne a set of hypotheses h ∈ H 
random variable Xt ∈ {0  1}  P (Xt = xt) = θxt
T mapping all tests t ∈ T to outcomes h(t). We deﬁne a
where each is an outcome vector h ∈ {0  1}
set of regions {Ri}m
i=1  each of which is a subset of tests R ⊆ T . A region is determined to be valid
|A|.
If a set of tests A ⊆ T are performed  let the observed outcome vector be denoted by xA ∈ {0  1}
Let the version space H(xA) be the set of hypotheses consistent with observation vector xA  i.e.
H(xA) = {h ∈ H | ∀t ∈ A  h(t) = xA(t)}.
We deﬁne a policy π as a mapping from observation vector xA to tests. A policy terminates when it
T be the ground
shows that at least one region is valid  or all regions are invalid. Let xT ∈ {0  1}
truth - the outcome vector for all tests. Denote the observation vector of a policy π given ground truth
xT as xA (π  xT ). The expected cost of a policy π is c(π) = ExT [c(xA (π  xT )] where c(xA) is
the cost of all tests t ∈ A. The objective is to compute a policy π∗ with minimum cost that ensures at
least one region is valid  i.e.
(2)

P (Xt = 1).

t∈R

∗

π

∈ arg min

c(π) s.t ∀xT  ∃Rd : P (Rd | xA (π  xT )) = 1
Note that we can cast problem (1) to (2) by setting E = T and Ξ = {Ri}m
i=1. That is  driving
uncertainty into a region is equivalent to identiﬁcation of a valid path (Fig. 2). This casting enables
us to leverage efﬁcient algorithms with near-optimality guarantees for motion planning.

π

3 Related Work
The computational bottleneck in motion planning varies with problem domain and that has led to a
plethora of planning techniques ([23]). When vertex expansions are a bottleneck  A* [17] is optimally
efﬁcient while techniques such as partial expansions [28] address graph searches with large branching
factors. The problem class we examine  that of expensive edge evaluation  has inspired a variety of

2It is assumed that c(e) is modular and non-zero. It can scale with edge length.
3Refer to supplementary on various methods to construct a library of good candidate paths

3

Figure 2: Equivalence between the feasible path identiﬁcation problem and Bern-DRD. A path ξi is equivalent
to a region Ri over valid hypotheses (blue dots). Tests eliminate hypotheses and the algorithm terminates when
uncertainty is pushed into a region (R1) and the corresponding path (ξ1) is determined to be valid.

‘lazy’ approaches. The Lazy Probabilistic Roadmap (PRM) algorithm [1] only evaluates edges on
the shortest path while Fuzzy PRM [26] evaluates paths that minimize probability of collision. The
Lazy Weighted A* (LWA*) algorithm [8] delays edge evaluation in A* search and is reﬂected in
similar techniques for randomized search [14  6]. An approach most similar in style to ours is the
LazyShortestPath (LazySP) framework [11] which examines the problem of which edges to evaluate
on the shortest path. Instead of the ﬁnding the shortest path  our framework aims to efﬁciently
identify a feasible path in a library of ‘good’ paths. Our framework is also similar to the Anytime
Edge Evaluation (AEE*) framework [25] which deals with edge evaluation on a GBG. However  our
framework terminates once a single feasible path is found while AEE* continues to evaluation in
order to minimize expected cumulative sub-optimality bound. Similar to Choudhury et al. [7] and
Burns and Brock [2]  we leverage priors on the distribution of obstacles to make informed planning
decisions.
We draw a novel connection between motion planning and optimal test selection which has a
wide-spread application in medical diagnosis [21] and experiment design [4]. Optimizing the ideal
metric  decision theoretic value of information [18]  is known to be NPPP complete [22]. For
hypothesis identiﬁcation (known as the Optimal Decision Tree (ODT) problem)  Generalized Binary
Search (GBS) [10] provides a near-optimal policy. For disjoint region identiﬁcation (known as the
Equivalence Class Determination (ECD) problem)  EC2 [16] provides a near-optimal policy. When
regions overlap (known as the Decision Region Determination (DRD) problem)  HEC [19] provides
a near-optimal policy. The DIRECT algorithm [5]  a computationally more efﬁcient alternative to
HEC  forms the basis of our approach.

4 The Bernoulli Subregion Edge Cutting Algorithm

The DRD problem in general is addressed by the Decision Region Edge Cutting (DIRECT) [5]
algorithm. The intuition behind the method is as follows - as tests are performed  hypotheses
inconsistent with test outcomes are pruned away. Hence  tests should be incentivized to push the
probability mass over hypotheses into any region as fast as possible. Chen et al. [5] derive a surrogate
objective function that provides such an incentive by creating separate sub-problems for each region
and combining them in a Noisy-OR fashion such that quickly solving any one sub-problem sufﬁces.
Importantly  this objective is adaptive submodular [15] - greedily maximizing such an objective
results in a near-optimal policy.
We adapt the framework of DIRECT to address the Bern-DRD problem. We ﬁrst provide a modi-
ﬁcation to the EC2 sub-problem objective which is simpler to compute when the distribution over
hypotheses is non-uniform  while providing the same guarantees. Unfortunately  naively apply-
ing DIRECT requires O
Bernoulli tests  we present a more efﬁcient Bernoulli Subregion Edge Cutting (BISECT) algorithm 
which computes each subproblem in O (T ) time. We provide a brief exposition deferring to the
supplementary for detailed derivations.

(cid:0)2T(cid:1) computation per sub-problem. For the special case of independent

4.1 A simple subproblem: One region versus all

Following Chen et al. [5]  we deﬁne a ‘one region versus all’ subproblem  the solution of which helps
address the Bern-DRD. Given a single region  the objective is to either push the version space to
H
that region  or collapse it to a single hypothesis. We view a region R as a version space R
⊆ H

4

R1R2R3R1R2R3R1R2R3⇠1⇠2⇠3⇠1⇠2⇠3⇠1⇠2⇠3(a)(b)(c)consistent with its constituent tests. We deﬁne this subproblem over a set of disjoint subregions Si.
H be S1. Every other hypothesis h ∈ RH is deﬁned as its
Let the hypotheses in the target region R
own subregion Si  i > 1  where RH is a set of hypothesis where a region is not valid. Determining
which subregion is valid falls under the framework of Equivalence Class Determination (ECD)  (a
special case of the DRD problem) and can be solved efﬁciently by the EC2 algorithm (Golovin et al.
[16]). This objective deﬁnes a graph with nodes as subregions and edges between distinct subregions 
where the weight of an edge is the product of probabilities of subregions. As tests are performed and
outcomes are received  the version space shrinks  and probabilities of different subregions are driven
to 0. This has the effect of decreasing the total weight of edges. Importantly  the problem is solved
i.f.f. the weight of all edges is zero. The weight over the set of subregions is:

w[16]({Si}) =

P (Sj)P (Sk)

(3)

(cid:88)

j(cid:54)=k

When hypotheses have uniform weight  this can be computed efﬁciently for the ‘one region versus

all’ subproblem. Let P (S1) = (cid:80)

i>1

P (Si):

(cid:18)

(cid:19)

1
|H|

w[16]({Si}) = P (S1)P (S1) + P (S1)

P (S1) −

(4)

(cid:88)

i(cid:54)=1

(cid:88)

i(cid:54)=1

P (Si)) + (

wEC({Si}) = P (S1)(

For non-uniform prior however  this quantity is more difﬁcult to compute. We modify this objective
slightly  adding self-edges on subregions Si  i > 1  enabling more efﬁcient computation while still
maintaining the same guarantees:

(cid:88)
j≥1
) + P (RH))
= P (S1)P (S1) + P (S1)2 = P (RH)(P (R
R(xA) = {h ∈ H | ∀t ∈ A ∩ R  h(t) = xA(t)}.
For region R  let the relevant version space be H
R(xA).
H consistent with relevant outcomes in xA is given by R
The set of all hypotheses in R
(cid:0)2T(cid:1). However  for the
R(xA)) allows us to quantify the progress made on
H
The terms P (R
determining region validity. Naively computing these terms would require computing all hypotheses
and assigning them to correct subregions  thus requiring a runtime of O
(cid:33)2
special case of Bernoulli tests  we can reduce this to O (T ) as we can see from the expression

R(xA)) and P (RH ∩ H

P (Sj))
H

P (Si))(

∩ H

∩ H

(5)

H

wEC({Si}∩H

R

(xA)) =

I(Xi = 1)

i∈(R∩A)

j∈(R\A)

k∈R∩A

θxA(k)

k

(1 − θk)1−xA(k)

(cid:89)

(cid:32) (cid:89)

θj

1 −

(cid:89)

(6)
We can further reduce this to O (1) when iteratively updated (see supplementary for derivations). We
now deﬁne a criterion that incentivizes removing edges quickly and has theoretical guarantees. Let
fEC(xA) be the weight of edges removed on observing outcome vector xA. This is evaluated as

fEC(xA) = 1 −

wEC({Si} ∩ H
wEC({Si})

(cid:32)

(cid:81)

R(xA))

I(Xi = 1) (cid:81)

i∈(R∩A)

(cid:19)2

(7)

θxA(k)

k

(1 − θk)1−xA(k)

(cid:33)(cid:18) (cid:81)
(cid:81)

k∈R∩A
θi

i∈R

θj

j∈(R\A)
1 −

1 −

= 1 −

Lemma 1. The expression fEC(xA) is strongly adaptive monotone and adaptive submodular.

4.2 Solving the Bern-DRD problem using BISECT
We now return to Bern-DRD problem (2) where we have multiple regions {R1  . . .  Rm} that
overlap. Each region Rr is associated with an objective f r
EC(xA) for solving the ‘one region versus
all’ problem. Since solving any one such subproblem sufﬁces  we combine them in a Noisy-OR

5

Algorithm 1: Decision Region Determination with Independent Bernoulli Test({Ri}m
1 A ← ∅ ;
2 while ((cid:64)Ri  P (Ri|xA) = 1) and (∃Ri  P (Ri|xA) > 0) do

i=1   θ  xT )

3
4
5
6

Tcand ← SelectCandTestSet(xA) ;
t∗ ← SelectTest(Tcand  θ  xA) ;
A ← A ∪ t∗;
xt∗ ← xT (t∗) ;

(cid:46) Using either (10) or (12)
(cid:46) Using either (11) (13) (14) (15) or (16)

(cid:46) Observe outcome for selected test

m(cid:81)
(cid:33)(cid:32) (cid:81)
formulation by deﬁning an objective fDRD(xA) = 1 −
(cid:81)

I(Xi = 1) (cid:81)

m(cid:89)

i∈(Rr∩A)

(cid:81)

(cid:32)

1 −

r=1

θj

j∈(Rr\A)
1 −

i∈Rr

k∈Rr∩A
θi

1 −

r=1



(1 − f r

EC(xA)) [5] which evaluates to

θxA(k)

k

(1 − θk)1−xA(k)

(cid:33)2

 (8)

Since fDRD(xA) = 1 iff f r
to Bern-DRD

∗

π

EC(xA) = 1 for at least one r  we deﬁne the following surrogate problem

∈ arg min

π

c(π) s.t ∀xT : fDRD(xA (π  xT )) ≥ 1

(9)

The surrogate problem has a structure that allows greedy policies to have near-optimality guarantees
Lemma 2. The expression fDRD(xA) is strongly adaptive monotone and adaptive submodular.
Theorem 1. Let m be the number of regions  ph
πDRD be the greedy policy and π∗ with the optimal policy. Then c(πDRD) ≤ c(π∗)(2m log 1
We now describe the BISECT algorithm. Algorithm 1 shows the framework for a general de-
cision region determination algorithm.
In order to specify BISECT  we need to deﬁne two
options - a candidate test set selection function SelectCandTestSet(xA) and a test selec-
tion function SelectTest(Tcand  θ  xA). The unconstrained version of BISECT implements
SelectCandTestSet(xA) to return the set of all tests Tcand that contains only unevaluated tests
belonging to active regions

min the minimum prior probability of any hypothesis 
+1).

ph

min

We now examine the BISECT test selection rule SelectTest(Tcand  θ  xA)

Tcand =

i=1

(cid:40) m(cid:91)
(cid:41)
{Ri | P (Ri|xA) > 0}
1 −
(cid:89)
(cid:89)
 (θxt

I(Xi = 1)

I(Xi = 1)

(cid:89)

i∈(Rr∩A)

j∈(Rr\A)

θj

 m(cid:89)
(cid:89)

r=1

\ A



θj

i∈(Rr∩A∪t)

j∈(Rr\A∪t)

t (1 − θt)1−xt)

(10)

m(cid:80)

k=1

2

I(t∈Rk)

 (11)

Ext

∗
t

∈ arg max
t∈Tcand

 m(cid:89)

r=1

c(t)

1

1 −

−

The intuition behind this update is that tests are selected to squash the probability of regions not being
valid. It also additionally incentivizes selection of tests on which multiple regions overlap.

4.3 Adaptively constraining test selection to most likely region

We observe in our experiments that the surrogate (8) suffers from a slow convergence problem -
fDRD(xA) takes a long time to converge to 1 when greedily optimized. To alleviate the convergence
problem  we introduce an alternate candidate selection function SelectCandTestSet(xA) that
assigns to Tcand the set of all tests that belong to the most likely region TmaxP which is evaluated as
follows (we will refer to this variant as MAXPROBREG)

(cid:40)

(cid:41)

TmaxP =

arg max

Ri=(R1 R2 ... Rm)

P (Ri|xA)

\ A

(12)

6

Applying the constraint in (12) leads to a dramatic improvement for any test selection policy as we
will show in Sec. 5.2. The following theorem offers a partial explanation
Theorem 2. A policy that greedily latches to a region according the the posterior conditioned on the
region outcomes has a near-optimality guarantee of 4 w.r.t the optimal region evaluation sequence.
Applying the constraint in (12) implies we are no longer greedily optimizing fDRD(xA). However 
(cid:17)
(cid:17)(cid:17)−1
(cid:16) 1
the following theorem bounds the sub-optimality of this policy.
Theorem 3. Let pmin = mini P (Ri)  ph
min = minh∈H P (h) and l = maxi |Ri|. The policy using
.
(12) has a suboptimality of α

2m log

(cid:16)

(cid:17)

(cid:16)

(cid:16)

+ 1

2
l
min

where α ≤

1 − max

(1 − pmin)2  p

ph

min

5 Experiments

We evaluate BISECT on a collection of datasets spanning across a spectrum of synthetic problems and
real-world planning applications. The synthetic problems are created by randomly selecting problem
parameters to test the general applicability of BISECT. The motion planning datasets range from
simplistic yet insightful 2D problems to more realistic high dimension problems as encountered by an
UAV or a robot arm. The 7D arm planning dataset is obtained from a high ﬁdelity simulation as shown
in Fig. 4(a). Finally  we test BISECT on experimental data collected from a full scale helicopter ﬂying
that has to avoid unmapped wires at high speed as it comes into land as shown in Fig. 4(b). Refer to
supplementary for exhaustive details on experiments and additional results. Open-source code and
details can be found here: https://github.com/sanjibac/matlab_learning_collision_checking

5.1 Heuristic approaches to solving the Bern-DRD problem

We propose a collection of competitive heuristics that can also be used to solve the Bern-DRD problem. These
heuristics are various SelectTest(Tcand  θ  xA) policies in the framework of Alg. 1. To simplify the setting 
we assume unit cost c(t) = 1 although it would be possible to extend these to nonuniform setting. The ﬁrst
heuristic RANDOM selects a test by sampling uniform randomly

(13)
We adopt our next heuristic MAXTALLY from Dellin and Srinivasa [11] where the test belonging to most regions
is selected. It uses the following criteria  which exhibits a ‘fail-fast’ characteristic

∗ ∈ Tcand
t

m(cid:88)

i=1

t

∗ ∈ arg max
t∈Tcand

I (t ∈ Ri  P (Ri|xA) > 0)

(14)

The next policy SETCOVER selects tests that maximize the expected number of ‘covered’ tests  i.e. if a selected
test is in collision  how many other tests does it remove from consideration.

(cid:40) m(cid:91)

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

{Ri | P (Ri|xA) > 0} − m(cid:91)

(cid:8)Rj

i=1

j=1

(cid:12)(cid:12) P (Rj|  xA 

Xt=0) > 0(cid:9)(cid:41)

t

∗ ∈ arg max
t∈Tcand

(1 − θt)

\ {A ∪ {t}}

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

(15)

Theorem 4. SETCOVER is a near-optimal policy for the problem of optimally checking all regions.
The last heuristic is derived from a classic heuristic in decision theory: myopic value of information (Howard
[18]). MVOI greedily chooses the test that maximizes the change in the probability mass of the most likely
region. This test selection works only with SelectCandTestSet(xA) = TmaxP.
P (Ri | xA  Xt = 0)

(1 − θt) max

(16)

t

∗ ∈ arg max
t∈TmaxP

i=1 ... m

We also evaluate against state of the art LAZYSP [11] planner which explicitly minimizes collision checking
effort while trying to guarantee optimality. We ran two variants of LazySP. The ﬁrst variant is the vanilla
unconstrained algorithm that searches for the shortest path on the entire graph  collision checks the path and
repeats. The second variant is constrained to the library of paths used by all other baselines.

5.2 Analysis of results

Table 1 shows the evaluation cost of all algorithms on various datasets normalized w.r.t BISECT. The two
numbers are lower and upper 95% conﬁdence intervals - hence it conveys how much fractionally poorer are
algorithms w.r.t BISECT. The best performance on each dataset is highlighted. We present a set of observations
to interpret these results.
O 1. BISECT has a consistently competitive performance across all datasets.

7

Figure 3: Performance (number of evaluated edges) of all algorithms on 2D geometric planning. Snapshots 
at start  interim and ﬁnal stages respectively  show evaluated valid edges (green)  invalid edges (red) and the
ﬁnal path (magenta). The utility of edges as computed by algorithms is shown varying from low (black) to high
(cream).

Figure 4: (a) A 7D arm has to perform pick and place tasks at high speed in a table with clutter. (b) Experimental
data from a full-scale helicopter that has to react quickly to avoid unmapped wires detected by the sensor.
BISECT (given an informative prior) checks a small number of edges around the detected wire and identiﬁes a
path. (c) Scenario where regions have size disparity. Unconstrained BISECT signiﬁcantly outperforms other
algorithms on such a scenario.

Table 1 shows that on 13 out of the 14 datasets  BISECT is at par with the best. On 7 of those it is exclusively
the best.
O 2. The MAXPROBREG variant improves the performance of all algorithms on most datasets

Table 1 shows that this is true on 12 datasets. The impact is greatest on RANDOM on the 2D Forest dataset -
performance improves from (19.45  27.66) to (0.13  0.30). However  this is not true in general. On datasets
with large disparity in region sizes as illustrated in Fig. 4(c)  unconstrained BISECT signiﬁcantly outperforms
other algorithms. In such scenarios  MAXPROBREG latches on to the most probable path which also happens to
have a large number of edges. It performs poorly on instances where this region is invalid  while the other region
containing a single edge is valid. Unconstrained BISECT prefers to evaluate the single edge belonging to region
1 before proceeding to evaluate region 2  performing optimally on those instances. Hence  the myopic nature of
MAXPROBREG is the reason behind its poor performance.
O 3. On planning problems  BISECT strikes a trade-off between the complimentary natures of MAXTALLY
and MVOI.

8

00.10.20.30.40.50.60.70.80.9100.10.20.30.40.50.60.70.80.9100.10.20.30.40.50.60.70.80.9100.10.20.30.40.50.60.70.80.9100.10.20.30.40.50.60.70.80.9100.10.20.30.40.50.60.70.80.9100.10.20.30.40.50.60.70.80.9100.10.20.30.40.50.60.70.80.9100.10.20.30.40.50.60.70.80.9100.10.20.30.40.50.60.70.80.9100.10.20.30.40.50.60.70.80.9100.10.20.30.40.50.60.70.80.9100.10.20.30.40.50.60.70.80.9100.10.20.30.40.50.60.70.80.9100.10.20.30.40.50.60.70.80.9100.10.20.30.40.50.60.70.80.9100.10.20.30.40.50.60.70.80.9100.10.20.30.40.50.60.70.80.9100.10.20.30.40.50.60.70.80.9100.10.20.30.40.50.60.70.80.9100.10.20.30.40.50.60.70.80.9100.10.20.30.40.50.60.70.80.9100.10.20.30.40.50.60.70.80.9100.10.20.30.40.50.60.70.80.91MVoI(|A|:28)SetCover(|A|:30)MaxTally(|A|:29)BiSECt(|A|:20)(a)(b)Wires in real ﬂight…Region 1: Single edge with low probabilityRegion 2: Many edges with high probability(c)Table 1: Normalized evaluation cost - (lower  upper) bound of 95% conﬁdence interval

LAZYSP
Unconstrained
Constrained

MVOI

RANDOM MAXTALLY
Unconstrained
Unconstrained
MaxProbReg
MaxProbReg

SETCOVER
Unconstrained
MaxProbReg

BISECT
Unconstrained
MaxProbReg

Synthetic Bernoulli Test: Variation across region overlap

2D Geometric Planning: Variation across environments

(0.00  0.08)

(0.00  0.00)
(−0.11  0.00)

(0.03  0.18)

(0.045  0.21)

(0.00  0.09)

(4.18  6.67)
(0.12  0.29)
(3.27  4.40)
(0.05  0.25)
(2.86  4.26)
(0.00  0.28)

(19.5  27.7)
(0.13  0.30)
(13.4  17.8)
(0.11  0.42)
(13.8  16.6)
(0.33  0.51)

(3.49  5.23)
(0.12  0.25)
(3.04  4.30)
(0.14  0.24)
(2.62  3.85)
(0.06  0.26)

(4.68  6.55)
(0.09  0.18)
(4.12  4.89)
(0.00  0.12)
(2.76  3.93)
(0.10  0.20)

(10.8  14.3)
(1.38  2.51)
(6.96  11.3)
(0.16  0.55)
(18.9  25.6)
(−0.17  0.01)

(5.82  12.1)
(0.00  0.57)
(5.43  10.02)
(−0.03  0.45)

2D Geometric Planning: Variation across region size

(0.00  0.17)

(0.00  0.14)

(12.1  16.0)
(0.12  0.42)
(13.3  16.8)
(0.09  0.27)

(4.47  5.13)
(0.06  0.24)
(2.18  3.77)
(−0.04  0.08)

Non-holonomic Path Planning: Variation across environments

(1.97  3.81)
(0.15  0.47)
(0.97  2.45)
(0.02  0.51)

(0.97  1.59)
(0.24  0.72)
(0.28  1.19)
(0.00  0.38)

(0.09  0.18)
(−0.11  0.11)
7D Arm Planning: Variation across environments

(9.79  11.14)
(0.25  0.38)
(8.40  11.47)
(0.21  0.28)

(22.4  29.7)
(0.46  0.79)
(13.0  15.8)
(0.00  0.12)

(2.63  5.28)
(0.00  0.00)
(3.72  4.54)
(−0.11  0.11)

(0.28  0.54)

(15.1  19.4)
(0.13  0.31)
(7.92  9.85)
(0.14  0.36)

(4.80  6.98)
(0.00  0.04)
(3.96  6.44)
(0.00  0.00)

(0.02  0.20)
Datasets with large disparity in region sizes

(3.00  3.50)

(6.60  10.5)

(6.50  8.00)
(3.00  4.50)
(9.50  11.3)
(6.90  10.8)

(5.50  6.50)
(5.00  7.50)
(2.80  6.10)
(6.80  8.30)

(1.36  2.17)
(0.00  0.11)
(1.42  2.07)
(0.00  0.11)

(3.00  3.50)
(3.00  3.50)
(6.60  10.5)
(6.60  10.5)

(1.77  3.01)
(0.18  0.40)
(3.55  4.67)
(0.14  0.33)
(2.94  3.71)
(0.09  0.22)

(3.53  5.07)
(0.00  0.09)
(1.36  2.11)
(0.14  0.29)
(2.07  2.94)
(0.00  0.00)

(2.00  3.41)
(0.00  0.38)
(1.04  1.62)
(0.00  0.14)

(1.42  2.36)
(0.00  0.00)
(1.77  2.64)
(0.00  0.00)
(1.33  1.81)
(0.00  0.00)

(1.90  2.46)
(0.00  0.00)
(0.76  1.20)
(0.00  0.00)
(0.91  1.44)
(0.00  0.00)

(0.94  1.42)
(0.00  0.00)
(0.41  0.91)
(0.00  0.00)

(1.54  2.46)
(0.00  0.00)
(3.28  3.78)
(0.00  0.00)

(0.32  0.67)
(0.00  0.00)
(1.23  1.75)
(0.00  0.00)

(0.00  0.00)
(3.00  3.50)
(0.00  0.00)
(7.30  11.2)

Small
m : 100
Medium
m : 500
Large
m : 1e3

Forest

OneWall

TwoWall

OneWall
m : 300
OneWall
m : 858

Forest

OneWall

Table

Clutter

Synth.
(T : 10)
2D Plan
(m : 2)

We examine this in the context of 2D planning as shown in Fig. 3. MAXTALLY selects edges belonging to many
paths which is useful for path elimination but does not reason about the event when the edge is not in collision.
MVOI selects edges to eliminate the most probable path but does not reason about how many paths a single edge
can eliminate. BISECT switches between these behaviors thus achieving greater efﬁciency than both heuristics.
O 4. BISECT checks informative edges in collision avoidance problems encountered a helicopter

Fig. 4(b) shows the efﬁcacy of BISECT on experimental ﬂight data from a helicopter avoiding wire.

6 Conclusion

In this paper  we addressed the problem of identiﬁcation of a feasible path from a library while minimizing the
expected cost of edge evaluation given priors on the likelihood of edge validity. We showed that this problem
is equivalent to a decision region determination problem where the goal is to select tests (edges) that drive
uncertainty into a single decision region (a valid path). We proposed BISECT  and efﬁcient and near-optimal
algorithm that solves this problem by greedily optimizing a surrogate objective.We validated BISECT on a
spectrum of problems against state of the art heuristics and showed that it has a consistent performance across
datasets. This works serves as a ﬁrst step towards importing Bayesian active learning approaches into the domain
of motion planning.

9

Acknowledgments

We would like to acknowledge the support from ONR grant N000141310821. We would like to thank Shushman
Choudhury for insightful discussions and the 7D arm planning datasets. We would like to thank Oren Salzaman 
Mohak Bhardwaj  Vishal Dugar and Paloma Sodhi for feedback on the paper.

References
[1] Robert Bohlin and Lydia E Kavraki. Path planning using lazy prm. In ICRA  2000.

[2] Brendan Burns and Oliver Brock. Sampling-based motion planning using predictive models. In ICRA 

2005.

[3] John F Canny. The complexity of robot motion planning. 1988.

[4] Kathryn Chaloner and Isabella Verdinelli. Bayesian experimental design: A review. Statistical Science 

pages 273–304  1995.

[5] Yuxin Chen  Shervin Javdani  Amin Karbasi  J. Andrew (Drew) Bagnell  Siddhartha Srinivasa  and Andreas

Krause. Submodular surrogates for value of information. In AAAI  2015.

[6] Sanjiban Choudhury  Jonathan D. Gammell  Timothy D. Barfoot  Siddhartha Srinivasa  and Sebastian
Scherer. Regionally accelerated batch informed trees (rabit*): A framework to integrate local information
into optimal path planning. In ICRA  2016.

[7] Shushman Choudhury  Christopher M Dellin  and Siddhartha S Srinivasa. Pareto-optimal search over

conﬁguration space beliefs for anytime motion planning. In IROS  2016.

[8] Benjamin Cohen  Mike Phillips  and Maxim Likhachev. Planning single-arm manipulations with n-arm

robots. In Eigth Annual Symposium on Combinatorial Search  2015.

[9] Hugh Cover  Sanjiban Choudhury  Sebastian Scherer  and Sanjiv Singh. Sparse tangential network (spartan):

Motion planning for micro aerial vehicles. In ICRA. IEEE  2013.

[10] Sanjoy Dasgupta. Analysis of a greedy active learning strategy. In NIPS  2004.

[11] Christopher M Dellin and Siddhartha S Srinivasa. A unifying formalism for shortest path problems with

expensive edge evaluations via lazy best-ﬁrst search over paths with edge selectors. In ICAPS  2016.

[12] Christopher M Dellin  Kyle Strabala  G Clark Haynes  David Stager  and Siddhartha S Srinivasa. Guided

manipulation planning at the darpa robotics challenge trials. In Experimental Robotics  2016.

[13] Alan Frieze and Michał Karo´nski. Introduction to random graphs. Cambridge Press  2015.

[14] Jonathan D. Gammell  Siddhartha S. Srinivasa  and Timothy D. Barfoot. Batch Informed Trees: Sampling-

based optimal planning via heuristically guided search of random geometric graphs. In ICRA  2015.

[15] Daniel Golovin and Andreas Krause. Adaptive submodularity: Theory and applications in active learning

and stochastic optimization. Journal of Artiﬁcial Intelligence Research  2011.

[16] Daniel Golovin  Andreas Krause  and Debajyoti Ray. Near-optimal bayesian active learning with noisy

observations. In NIPS  2010.

[17] Peter E Hart  Nils J Nilsson  and Bertram Raphael. A formal basis for the heuristic determination of

minimum cost paths. IEEE Trans. on Systems Science and Cybernetics  1968.

[18] Ronald A Howard. Information value theory. IEEE Tran. Systems Science Cybernetics  1966.

[19] Shervin Javdani  Yuxin Chen  Amin Karbasi  Andreas Krause  J. Andrew (Drew) Bagnell  and Siddhartha

Srinivasa. Near optimal bayesian active learning for decision making. In AISTATS  2014.

[20] Sertac Karaman and Emilio Frazzoli. Sampling-based algorithms for optimal motion planning. The

International Journal of Robotics Research  30(7):846–894  2011.

[21] Igor Kononenko. Machine learning for medical diagnosis: History  state of the art and perspective. Artiﬁcial

Intelligence in Medicine  2001.

[22] Andreas Krause and Carlos Guestrin. Optimal value of information in graphical models. Journal of

Artiﬁcial Intelligence Research  35:557–591  2009.

10

[23] S. M. LaValle. Planning Algorithms. Cambridge University Press  Cambridge  U.K.  2006.

[24] Steven M LaValle and James J Kuffner Jr. Randomized kinodynamic planning. IJRR  2001.

[25] Venkatraman Narayanan and Maxim Likhachev. Heuristic search on graphs with existence priors for

expensive-to-evaluate edges. In ICAPS  2017.

[26] Christian L Nielsen and Lydia E Kavraki. A 2 level fuzzy prm for manipulation planning. In IROS  2000.

[27] Mihail Pivtoraiko  Ross A Knepper  and Alonzo Kelly. Differentially constrained mobile robot motion

planning in state lattices. Journal of Field Robotics  2009.

[28] Takayuki Yoshizumi  Teruhisa Miura  and Toru Ishida. A* with partial expansion for large branching factor

problems. In AAAI/IAAI  pages 923–929  2000.

11

,Yang Song
Jun Zhu
Yong Ren
Sanjiban Choudhury
Shervin Javdani
Siddhartha Srinivasa
Sebastian Scherer