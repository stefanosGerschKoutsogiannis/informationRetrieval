2018,The Price of Privacy for Low-rank Factorization,In this paper  we study what  price one has to pay to release \emph{differentially private low-rank factorization} of a matrix. We consider various settings that are close to the real world applications of low-rank factorization: (i) the manner in which matrices are updated (row by row or in an arbitrary manner)  (ii) whether matrices are distributed or not  and (iii) how the output is produced (once at the end of all updates  also known as \emph{one-shot algorithms}  or continually). Even though these settings are well studied without privacy  surprisingly  there are no  private algorithm for these settings (except when a matrix is updated row by row). We present the first set of differentially private algorithms for all these settings.  

Our algorithms when private matrix is updated in an arbitrary manner promise differential privacy with respect to two stronger privacy guarantees than previously studied  use space and time \emph{comparable} to the non-private algorithm  and achieve \emph{optimal accuracy}. To complement our positive results  we also prove that the space required by our algorithms is optimal up to logarithmic factors. When data matrices are distributed over multiple servers  we give a non-interactive differentially private algorithm  with communication cost independent of dimension. In concise  we give algorithms that incur {\em optimal cost across all parameters of interest}. We also perform experiments  to verify that all our algorithms  perform well in practice and outperform the best known algorithm until now for large range of parameters.,The Price of Privacy for Low-rank Factorization

Jalaj Upadhyay

Johns Hopkins University

Baltimore  MD - 21201  USA.

jalaj@jhu.edu

Abstract

In this paper  we study what price one has to pay to release differentially private
low-rank factorization of a matrix. We consider various settings that are close
to the real world applications of low-rank factorization: (i) the manner in which
matrices are updated (row by row or in an arbitrary manner)  (ii) whether matrices
are distributed or not  and (iii) how the output is produced (once at the end of all
updates  also known as one-shot algorithms or continually). Even though these
settings are well studied without privacy  surprisingly  there are no private algorithm
for these settings (except when a matrix is updated row by row). We present the
ﬁrst set of differentially private algorithms for all these settings.
Our algorithms when private matrix is updated in an arbitrary manner promise
differential privacy with respect to two stronger privacy guarantees than previously
studied  use space and time comparable to the non-private algorithm  and achieve
optimal accuracy. To complement our positive results  we also prove that the space
required by our algorithms is optimal up to logarithmic factors. When data matrices
are distributed over multiple servers  we give a non-interactive differentially private
algorithm with communication cost independent of dimension. In concise  we
give algorithms that incur optimal cost across all parameters of interest. We also
perform experiments to verify that all our algorithms perform well in practice and
outperform the best known algorithm until now for large range of parameters.

1

Introduction

Low-rank factorization (LRF) of matrices is a fundamental component used in many applications  such
as clustering [15  19  43]  data mining [5]  recommendation systems [20]  information retrieval [49 
53]  learning distributions [2  34]  and web search [1  36]. In these applications  given an m × n
matrix A  a common approach is to ﬁrst compute three matrices: a diagonal positive semideﬁnite

matrix (cid:101)Σk ∈ Rk×k and two matrices  (cid:101)Uk ∈ Rm×k and (cid:101)Vk ∈ Rn×k  with orthonormal columns.
The requirement then is that the product B := (cid:101)U(cid:101)Σ(cid:101)VT is as close to A as possible. More formally 
target rank k  compute a rank-k matrix factorization (cid:101)Uk (cid:101)Σk  and (cid:101)Vk such that
(cid:105) ≥ 1 − β 

Problem 1. (α  β  γ  k)-LRF. Given parameters 0 < α  β < 1  γ  a matrix A ∈ Rm×n matrix  the

k(cid:107)F ≤ (1 + α)(cid:107)A − [A]k(cid:107)F + γ

(cid:104)(cid:107)A − (cid:101)Uk(cid:101)Σk(cid:101)VT

Pr

where (cid:107) · (cid:107)F denotes the Frobenius norm  and [A]k is the best rank-k approximation of A. We refer
to the parameter γ as the additive error and to α as the multiplicative error.

Practical matrices are often large  distributed over many servers and are dynamically updated [41  42]
and hence many works have considered these settings in order to reduce latency  synchronization
issues and resource overhead [6  9  16  13  14  17  27  40  44  48  52]. Moreover  these applications use
conﬁdential dataset and use of ad hoc mechanism can lead to serious privacy leaks [47]. Therefore 

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

Privacy

(cid:101)O((
(cid:101)O((
(cid:101)O((
(cid:101)O((

√
√

Updates
Turnstile
Turnstile
Turnstile
Turnstile
Row wise

Reference
Theorem 1
Theorem 2
Theorem 4
Theorem 4
Corollary 1
Theorem 5
Table 1: Our Results for (ε  Θ(n− log n))-Differentially Private Algorithms (T : stream length  m ≥ n).

Comments
A − A(cid:48) = uvT
One-shot
(cid:107)A − A(cid:48)(cid:107)F = 1
One-shot
Continually A − A(cid:48) = uvT
(cid:107)A − A(cid:48)(cid:107)F = 1
Continually
(cid:107)A − A(cid:48)(cid:107)F = 1
One-shot
(cid:107)A − A(cid:48)(cid:107)F = 1

√
Additive Error
mkα−1 +
√
mkα−2 +
√
kn)ε−1 log T )
√
kn)ε−1 log T )
−1 √

√
√
mkα−1 +
mkα−1 +
(αε)

(cid:16)
(cid:101)O
(cid:101)O(cid:0)kα−2−1√

kn)ε−1)
kn)ε−1)

(cid:17)
m(cid:1)

nk

−

Local

for any practical deployment [3  25]  one would like to simultaneously maintain strong privacy
guarantee and minimize space requirements  communication and computational costs.
Unfortunately  existing private algorithm for LRF do not consider these settings (except in central
model when matrices are received row by row [24]). For example  known algorithms either use
multiple pass over the data matrix [29  30  31  35] or cannot handle arbitrary updates [24]. Similarly 
known algorithms that continually release output are for monotonic functions [23]  thereby excluding
Problem 1. Private algorithms like [24  30] that can be extended to distributed setting use multiple
rounds of interaction  large communication cost  and/or result in trivial error bounds. Moreover 
known private algorithms are inefﬁcient compared to non-private algorithms: O(mnk) time and
O(mn) space compared to time linear in the sparsity of the matrix and O((m + n)k/α) space [9  13].
In fact  for rank-k matrices  Musco and Woodruff [45] state that Problem 1 is equivalent to the well

studied matrix completion for which one can have (cid:101)O(n · poly(k)) time non private algorithm [32].

Under same assumptions  private algorithm takes O(mnk) time [30]. This motivates the central
thesis of this paper: What is the price of privacy for non-trivial private algorithms?

1.1 Overview of the Results

We give a uniﬁed approach and ﬁrst set of algorithms for solving Problem 1 in various settings:
(i) when private matrix is updated row by row or in arbitrary manner  (ii) when private matrix is
distributed or not  and (iii) when the output is produced once at the end of all updates  also known as
one-shot algorithms or continually. We show that one does not have to pay the price of privacy (more
than what is required in terms of additive error and space). On a high level  we show the following:
1. When a private matrix is streamed  we propose differentially private algorithms with respect to two
stronger privacy guarantees than previously studied. We also show that these algorithms can be
extended to continual release model. Our algorithms uses basic linear algebra. This makes them
easy to code  and therefore  optimize.

2. We complement our positive results with a matching lower bound on the space required. Our

algorithms are also time efﬁcient and achieve optimal accuracy.

3. In the distributed setting  we give a non-interactive differentially private algorithm with communi-

cation cost independent of dimension.

All our results are summarized in Table 1.

2 Preliminaries

In this paper  we give algorithms that are private under the notion of differential privacy. Differential
privacy has emerged as a de facto notion of privacy over the last few years. Formally  it is deﬁned as
follows:
Deﬁnition 1 ((  δ)-differential privacy). A randomized algorithm M gives (ε  δ)-differential privacy 
if for all neighboring datasets A and A(cid:48)  and all measurable sets S in the range of M  Pr[M(A) ∈
S] ≤ exp(ε)Pr[M(A(cid:48)) ∈ S] + δ  where the probability is over the coin tosses of M.

We consider two stronger privacy guarantees than previously studied: Priv1 and Priv2. In Priv1  we
call two matrices A and A(cid:48) neighboring if A − A(cid:48) = uvT for some unit vectors u and v. In Priv2 
we consider two matrices A and A(cid:48) neighboring if (cid:107)A − A(cid:48)(cid:107)F ≤ 1.

2

Our algorithm relies heavily on some results from the theory of random projections.
Deﬁnition 2. A distribution DR of t×m matrices satisﬁes (α  δ)-subspace embedding for generalized
regression if it has the following property: for any matrices P ∈ Rm×n and Q ∈ Rm×n(cid:48)
such that

rank(P) ≤ r  with probability 1 − δ over Φ ∼ DR  if (cid:101)X = argminX (cid:107)Φ(PX − Q)(cid:107)F and (cid:98)X =
argminX∈Rn×n(cid:48) (cid:107)PX − Q(cid:107)F   then (cid:107)P(cid:101)X − Q(cid:107)F ≤ (1 + α)(cid:107)P(cid:98)X − Q(cid:107)F .

Deﬁnition 3. A distribution DA over v × m matrices satisﬁes (α  δ)-afﬁne subspace embedding if it
has the following property: for any matrices D ∈ Rm×n and E ∈ Rm×n(cid:48)
such that rank(D) ≤ r 
with probability 1 − δ over S ∼ DA  simultaneously for all X ∈ Rn×n(cid:48)
  (cid:107)S(DX − E)(cid:107)2
F =
(1 ± α)(cid:107)DX − E(cid:107)2
F .
An example distribution DR with t = O(α−2 log(1/δ)) is the distribution of random matrices whose
entries are sampled i.i.d. from N (0  1/t).

3 A Meta Low Space Differentially Private Algorithm

Our aim in this section is to present a uniﬁed algorithmic approach in the form of meta algorithm (see 
Algorithm 1). This serves the purpose of illustrating the key ideas. For example  since one of our
goals is private algorithms under turnstile model  we are restricted to only use linear sketches [38] 
but what we show is that advance yet inexpensive post-processing combined with careful analysis
can lead to a small error differentially private LRF.
Our Techniques. Our algorithm is based on two observations: (i) there is a way to maintain
differentially private sketches of A (henceforth  we call such sketches noisy sketches) that incurs
sub-optimal accuracy in terms of additive error and (ii) one can apply post-processing to these noisy
sketches to obtain optimal additive error.
To illustrate point (i) and why we need post-processing  consider the following vanilla algorithm
for approximating the right singular vector: compute B = ΦA + N1  where Φ satisﬁes certain
embedding property (for example  [44  Theorem 1]) and N1 ∼ N (0  ρ2
in Figure 1. The output is [B]k  the best rank-k approximation of B. This already gives a good
k be the singular value decomposition of [B]k.

approximation. Let m (cid:29) n2 and let [(cid:101)U]k[(cid:101)Σ]k[(cid:101)V]T
(cid:107)A − A[(cid:101)V]k[(cid:101)V]T
−1 (cid:107)B(I − [(cid:101)V]k[(cid:101)V]T

k(cid:107)F ≤ (cid:107)(A + Φ†N1) − (A + Φ†N1)[(cid:101)V]k[(cid:101)V]T

Then by embedding property of Φ [44  Theorem 1] 

1)(cid:101)O(n2)×n for ρ1 as deﬁned
k(cid:107)F + (cid:107)Φ†N1 + Φ†N1[(cid:101)V]k[(cid:101)V]T
k )(cid:107)F + O((cid:107)Φ†N1 + Φ†N1[(cid:101)V]k[(cid:101)V]T
k(cid:107)F
k )(cid:107)F + O((cid:107)Φ†N1 + Φ†N1[(cid:101)V]k[(cid:101)V]T
k(cid:107)F )
−1(cid:107)A − [A]k(cid:107)F + O((cid:107)Φ†N1(cid:107)F + (cid:107)Φ†N1[(cid:101)V]k[(cid:101)V]T
k(cid:107)F )

≤ (1 − α)
≤ (1 − α)(cid:107)B(I − [V]k[V]T
≤ (1 + α) (1 − α)

k(cid:107)F ).
The term in O(·) can be bounded using the embedding property of Φ  but this incurs large error. The
question is whether we can further improve it to get optimal additive error. We show that it is possible
using careful post-processing (point (ii) above). That is  we can extract top-k singular components of
the input matrix A from sketches that are appropriately perturbed to preserve differential privacy.
The underlying idea is as follows: suppose we know the singular value decomposition of [A]k :=
[U]k[Σ]k[V]T

k . Then for ﬁnding a matrix B such that B ≈ A  it sufﬁces to compute (cid:101)U that
approximates [U]k  (cid:101)Σ that approximates [Σ]k  and (cid:101)V that approximates [V]k  and set B := (cid:101)U(cid:101)Σ(cid:101)VT.

However  this over simplistic overview does not guarantee privacy. In the rest of this exposition  we
give a brief overview of how we turn this simplistic overview to a private algorithm.
Challenges in computing differentially private low-rank factorization. The two traditional meth-
ods to preserve privacy—input perturbation and output perturbation—do not provide both privacy
and small additive error. For example  if we use output perturbation to compute the sketches 
Yc = AΦ + N and Yr = ΨA + N(cid:48) for appropriate sketching matrices Φ and Ψ and noise ma-
trices N and N(cid:48)  and use known random projection results  then we get an additive error term
that can be arbitrarily large (more speciﬁcally  depends on the Frobenius norm of A and has
the form (cid:107)NLAN(cid:48)(cid:107)F for some linear function LA of A). More precisely  we can show that
minr(X)≤k (cid:107)YcXYr − A(cid:107)F ≤ (cid:107)A − [A]k(cid:107)F + (cid:107)NLAN(cid:48)(cid:107)F + (cid:107)NLAΨA(cid:107)F + (cid:107)AΦLAN(cid:48)(cid:107)F .

3

Algorithm 1 PRIVATE-OPTIMAL-LRF(A; (  δ); α; k)

1)t×(m+n) and N2 ∼ N (0  ρ2

Sample Φ ∼ N (0  1/t)(m+n)×m  Ψ ∼ N (0  1/t)t×m  S ∼ N (0  1/v)v×m  T ∼
N (0  1/v)v×(m+n) with every entry sampled i.i.d.
Sample N1 ∼
N (0  ρ2

1: Set η = max(cid:8)k  α−1(cid:9)  t = O(ηα−1 log(k/δ))  v = O(ηα−2 log(k/δ)) and σmin =
16 log(1/δ)(cid:112)t(1 + α)(1 − α)−1 ln(1/δ)/ε  ρ1 = (cid:112)(1 + α) ln(1/δ)/ε  ρ2 = (cid:112)(1 + α)ρ1.
2: Set (cid:98)A = (A σminIm) by padding σminIm to the columns of A  where Im denotes an m × m
identity matrix. Compute Yc = (cid:98)AΦ  Yr = Ψ(cid:98)A + N1  and Z = S(cid:98)ATT + N2.
4: Compute: SVD of SU := (cid:101)Us(cid:101)Σs(cid:101)VT
s ∈ Rv×t and a SVD of VTT := (cid:101)Ut(cid:101)Σt(cid:101)VT
5: Compute: SVD of (cid:101)Vs(cid:101)Σ†
s Z(cid:101)Vt]k(cid:101)Σ
s[(cid:101)UT
t(cid:101)UT
6: Output: (cid:101)U = UU(cid:48)  diagonal matrix (cid:101)Σ = Σ(cid:48)  and (cid:101)V = VTV(cid:48).

3: Compute: U ∈ Rm×t whose columns are orthonormal basis for the column space of Yc and

matrix V ∈ Rt×(m+n) whose rows are the orthonormal basis for the row space of Yr.

2)v×v. Keep N1  N2  Φ private.

from N (0  1).

†

t . Let it is be U(cid:48)Σ(cid:48)V(cid:48)T.

t ∈ Rt×v.

While minr(X)≤k (cid:107)YcXYr − A(cid:107)F can be lower bounded using the techniques we use in this paper 
the additive term (cid:107)NLAN(cid:48)(cid:107)F can have large Frobenius norm.
On the other hand  input perturbation of A followed by a multiplication by Gaussian matrices Ω1 and
Ω2 as in [8  57  58] can leak private data due to a subtle reason. Every row of Ω1A (and columns
of AΩ2) has a multivariate Gaussian distribution if the determinant of ATA (AAT  respectively)
is non zero. If m < n  one can prove that computing AΩ1 preserves privacy  but  since  A is not a
full-column rank matrix  the multivariate Gaussian distribution is not deﬁned. The trick to consider
the subspace orthogonal to the kernel space of A [8] does not work because span of A and A(cid:48) may
not coincide for neighboring matrices A and A(cid:48). If the span do not coincide  then one can easily
differentiate the two cases with high probability  violating differential privacy. In fact  until this
work  it was not even clear whether using input perturbation yields low rank approximation (see the
comment after Theorem IV.2 and discussion in Section V in Blocki et al. [8])!
Our Algorithm. We use input perturbation with a careful choice of parameter to one of the sketches
and output perturbation to the other two sketches and show that it incur optimal additive error and
preserve privacy. The intuitive reason why this incurs small additive error is the fact that only one
of the sketches  Yr or Yc  undergoes output perturbation  so there is no term like (cid:107)NLAN(cid:48)(cid:107)F as
above. This allows us to show that Yc and Yr (or equivalently  their orthonormal bases U and V as
formed in Algorithm 1) approximates the span of [U]k and [V]k up to a small additive error.
Once we have extracted a "good enough" U and V  our problem reduces to computing
argminrk(X)≤k (cid:107)A − UXV(cid:107)F . This would require storing the whole matrix A  something that
we wish to avoid. To avoid storing the whole A  we use the fact that S and T are sampled from
a distribution of random matrices with a property that  for all appropriate X  (cid:107)A − UXV(cid:107)F ≈
(cid:107)S(A − UXV)TT(cid:107)F . In other words  without privacy  argminrk(X)≤k (cid:107)S(A − UXV)TT(cid:107)F can
be used to get a “good" approximation of [Σ]k. The exact method to perform and analyze the approx-
imation of [Σ]k is slightly more involved because we only have access to the noisy version of SAT 
i.e.  Z (in fact  this is one of the places we need careful post processing to output an approximation to
Σk under a rotation and a small additive error).Finally  we arrive at the main result stated below for
the case when m ≤ n (the result when m > n can be derived by just swapping m and n).
Theorem 1 (Main result). Let m  n  k ∈ N and α  ε  δ be the input parameters (with m ≤ n). Let κ 
η  and σmin be as deﬁned in Algorithm 1. Given an m × n matrix A with nn(A) non-zero entries  let
(A 0) be a matrix formed by appending an all zero m × m matrix to A. Then PRIVATE-OPTIMAL-

LRF (Algorithm 1) is (3ε  3δ) differentially private under Priv1 and outputs a factorization (cid:101)U (cid:101)Σ (cid:101)V

such that
1. With probability 9/10 over the random coins of PRIVATE-SPACE-OPTIMAL-LRF 

(cid:107) (A 0) − (cid:101)U(cid:101)Σ(cid:101)VT(cid:107)F ≤ (1 + α)(cid:107)A − [A]k(cid:107)F + O(σmin

m + ε−1(cid:112)kn ln(1/δ)).

√

2. The space used by PRIVATE-SPACE-OPTIMAL-LRF is O((m + n)ηα−1 log(k/δ)).

Proof Sketch. The proof of Theorem 1 is presented in the supplementary material. Here  we give a
brief sketch of part 1 (for m ≤ n) to illustrate the key points. The intuition that there is no term like

4

(cid:107)NLAN(cid:48)(cid:107)F does not directly yield optimal additive error. This is because  even if we do not get
an additive error term with large value like (cid:107)NLAN(cid:48)(cid:107)F   if not analyzed precisely  one can either
get a non-analytic expression for the error terms or one that is difﬁcult to analyze. To get analytic
expressions for all the error terms that are also easier to analyze  we introduce two carefully chosen
optimization problems (equation (3)) so that the intermediate terms in our analysis satisfy certain

properties (see the proof sketch below for exact requirements). Let (cid:98)A be as deﬁned in Figure 1. Part 1
follows from the following chain of inequalities and bounding (cid:107)(cid:98)AΦLAN1(cid:107)F :

(cid:107)Mk − (A 0)(cid:107)F ≤ (cid:107)Mk − (cid:98)A(cid:107)F + O(σmin

√

≤ (1 + α)(cid:107)(cid:98)A − [(cid:98)A]k(cid:107)F + (cid:107)(cid:98)AΦLAN1(cid:107)F + O(σmin
≤ (1 + α)(cid:107)A − [A]k(cid:107)F + (cid:107)(cid:98)AΦLAN1(cid:107)F + O(σmin

m)

√
√

m)

(1)

m) 

min

rk(X)≤k

where the matrix LA satisﬁes the following properties: (a) (cid:107)(cid:98)AΦLAΨ(cid:98)A − (cid:98)A(cid:107)F ≤ (1 + α)(cid:107)(cid:98)A −
[(cid:98)A]k(cid:107)F   (b) LA has rank at most k  and (c) ΨAΦLA is a rank-k projection matrix. We use

subadditivity of norm to prove the ﬁrst inequality and Weyl’s perturbation theorem [7] to prove the
third inequality. Proving the second inequality is the technically involved part. For this  we need
to ﬁnd a candidate LA. We ﬁrst assume we have such a candidate LA with all the three properties.
Once we have such an LA  we can prove part (b) as follows:

(cid:107)UXV − B(cid:107)F ≤ (cid:107)(cid:98)AΦLAΨ(cid:98)A − (cid:98)A(cid:107)F + (cid:107)(cid:98)AΦLAN1(cid:107)F + (cid:107)S†N1(T†)T(cid:107)F
≤ (1 + α)(cid:107)(cid:98)A − [(cid:98)A]k(cid:107)F + (cid:107)(cid:98)AΦLAN1(cid:107)F + (cid:107)S†N2(TT)†(cid:107)F  

(2)
where B = A + S†N1(T†)T. The ﬁrst inequality follows from the subadditivity of Frobenius norm 
the fact that U and V are orthonormal bases of Yc and Yr  and property (b) to exploit that minimum
on the left hand side is over rank-k matrices. We then use the approximation guarantee of property
(a) to get the second inequality. Using the fact that S and T are Gaussian matrices  we can lower
bound the left hand side of equation (2) up to an additive term as follows:

(cid:107) (A 0) − (cid:101)U(cid:101)Σ(cid:101)VT(cid:107)F − (cid:107)S†N1(TT)†(cid:107)F ≤ (1 + α)3 min

(cid:107)UXV − B(cid:107)F  

where (cid:101)U (cid:101)Σ  and (cid:101)V are as in Algorithm 1. We upper bound the right hand side of equation (2) by

using Markov’s inequality combined with the fact that both S and T are Gaussian matrices and LA
satisﬁes property (c). Scaling the value of α by a constant gives part 1. So all that remains is to ﬁnd a
candidate matrix LA. We construct such an LA using the following two optimization problems:

rk(X)≤k

(cid:107)(cid:98)AΦ([(cid:98)A]kΦ)†X − (cid:98)A(cid:107)F .

(3)

(cid:107)Ψ((cid:98)AΦ([(cid:98)A]kΦ)†X − (cid:98)A)(cid:107)F

Prob1 : min
X

and Prob2 : min
X

We prove that a solution to Prob1 gives us a candidate LA. This completes the proof.

From Priv1 to Priv2. If we try to use the idea described above to prove differential privacy under
Priv2  we end up with an additive error that depends linearly on min{m  n}. This is because we need
to perturb the input matrix by a noise proportional to min{√
kn} to preserve differential privacy
under Priv2. We show that by maintaining noisy sketches Y = AΦ + N1 and Z = SA + N2 for
appropriately chosen noise matrices N1 and N2 and sketching matrices Φ and S  followed by some
post processing  we can have an optimal error differentially private algorithm under Priv2. Here  we
require S to satisfy the same property as in the case of Priv1. However  the lack of symmetry between
S and Φ requires us to decouple the effects of noise matrices to get a tight bound on the additive error.
In total  we get an efﬁcient (  δ)-differentially private algorithm that uses O((mα−1 + n)kα−1)

space and outputs (α  99/100  γ  k)-LRF for γ = (cid:101)O((

kn)(cid:112)log(1/δ)/−2).

kmα−2 +

km 

√

√

√

4 Differentially Private Algorithms for Streaming Matrices

We next give more details of our result when matrices are streamed. Unless speciﬁed  for the ease

of presentation  we assume that k ≥ 1/α  δ = Θ(n− log n)  and (cid:101)O(·) hides a poly log n factor. To

capture the scenarios where data matrices are constantly updated  we consider the turnstile update
model (see the survey [46] for further motivations). Formally  in a turnstile update model  a matrix

5

√
√

(cid:101)O((
(cid:101)O((
(cid:16)(cid:16)√
(cid:101)O
(cid:101)O(cid:0)(cid:0)k2√
(cid:16)√

√
Additive Error
kn)ε−1)
kmα−1 +
√
kn)ε−1)
kmα−2 +
√
km + kc
n
√

(cid:17)
ε−1(cid:17)
n + m(cid:1) ε−1(cid:1)
(cid:17)

Space Required

(cid:101)O((m + n)kα−1)
(cid:101)O((mα−1 + n)kα−1)
(cid:101)O((m + n)kα−1)

O(mn)

Streaming
Turnstile
Turnstile

×

Row-wise
Turnstile

This work
This work

Privacy Notion
A − A(cid:48) = uvT
(cid:107)A − A(cid:48)(cid:107)F = 1
Hardt-Roth [30] A − A(cid:48) = esvT
Upadhyay [57] A − A(cid:48) = esvT
All of the above
Lower Bounds

Ω((m + n)kα−1)
Table 2: Comparison of Results ((cid:107)u(cid:107)2 (cid:107)v(cid:107)2 = 1  es: standard basis  k ≤ 1/α).

km +

[30]

kn

Ω

A ∈ Rm×n is initialized to an all zero-matrix and is updated by a sequence of triples {i  j  ∆}  where
1 ≤ i ≤ m  1 ≤ j ≤ n  and ∆ ∈ R. Each update results in a change in the (i  j)-th entry of A as
follows: Ai j ← Ai j + ∆.
An algorithm is differentially private under turnstile update model if  for all possible matrices
updated in the turnstile update model and runs of the algorithm  the output of the algorithm is
(ε  δ)-differentially private. A straightforward application of known privacy techniques to make
known space-optimal non-private algorithms [9] differentially private incurs a large additive error.
In other words  it is an open question whether we can solve Problem 1 with good accuracy while
preserving differential privacy and receiving the matrix in the turnstile update model? We resolve
this question positively. We say two data streams are neighboring if they are formed by neighboring
matrices. We show the following:
Theorem 2. Let A be an m × n matrix streamed in a turnstile update model. Then there is an

efﬁcient (ε  δ)-differentially private algorithm under Priv1 that uses (cid:101)O((m + n)kα−1) space and
computes (α  99/100  γ  k)-LRF  where γ = (cid:101)O((
γ = (cid:101)O((

kn)/ε). There is also an efﬁcient
(  δ)-differentially private algorithm under Priv2 that computes an (α  99/100  γ  k)-LRF  where

mkα−1 +

mkα−2 +

kn)/ε).

√

√

√

√

Before we argue the tightness of Theorem 2 with respect to both space and additive error  we compare
our result with previous works. All the private algorithms prior to this work compute a low rank
approximation of either the matrix A or its covariance ATA. One can compute a factorization from
their output at the expense of an extra O(mn2) time and O(mn) space (Dwork et al. [24] requires
an extra O(n3) time and O(n2) space to output an LRF of ATA). Some works like [11  35  30  29]
compute LRF under the spectral norm instead of Frobenius norm.
In other words  Hardt and Roth [30] and Upadhyay [57] study a problem closest to ours (the
differences being that they do not consider turnstile updates and output a low rank matrix). Therefore 
we compare Theorem 2 only with these two results. We do not make any assumptions on the private
matrix. This allows us to cover matrices of all form and relaxations in an uniﬁed manner. We next
compare the accuracy  privacy guarantees  space  and time required in more detail (see Table 2).
Both Hardt and Roth [30] and Upadhyay [57] give rank-O(k) approximation instead of rank-k
(typically  p = Θ(k))  and m ≤ n. Therefore  for a reasonable comparison  we consider Theorem 2
when α = Θ(1) and m ≤ n. Our additive error is smaller than Upadhyay [57] by a factor of

approximation  incur a multiplicative error of(cid:112)1 + k/p  where p is an oversampling parameter
(cid:101)O(k3/2). To make a reasonable comparison with Hardt and Roth [30]  we consider their result
4.2 and 4.7] results in an additive error (cid:101)O((
their projection matrix. In other words  we improve Hardt and Roth [30] by an (cid:101)O(c

without incoherence assumption: which roughly says that no single row of the matrix is signiﬁcantly
correlated with any of the right singular vectors of the matrix. Then Hardt and Roth [30  Theorem
n)ε−1)  where c is the maximum entry in

k) factor.

km + ck

√

√

√

Our algorithms are more efﬁcient than previous algorithms in terms of space and time even though
earlier algorithms output a rank-O(k) matrix and cannot handle updates in the turnstile model.
Upadhyay [57] takes more time than Hardt and Roth [30]. The algorithm of Hardt and Roth [30]
uses O(mn) space since it is a private version of Halko et al. [28] and has to store the entire matrix:
both the stages of Halko et al. [28] require the matrix explicitly. One of the motivations mentioned in
Hardt and Roth [30] is sparse private incoherent matrices (see the discussion in Hardt and Roth [30 
Sec 1.1])  but their algorithm uses this only to reduce the additive error and not the running time.

6

√

√

kn +

√

kn +

On the other hand  our algorithms use sublinear space and almost matches the running time of most
efﬁcient non-private algorithm in the turnstile model [9  13].
Our privacy guarantees are also more general than previous works  who consider two matrices A
and A(cid:48) neighboring either if A − A(cid:48) = eieT
j [29  31  33] or A − A(cid:48) = eivT for some unit vector
v [24  30  57]  depending on whether a user’s data is an entry of the matrix or a row of the matrix. It
is easy to see that these privacy guarantees are special case of Priv1 and Priv2.
Tightness of Additive Error. Hardt and Roth [30] showed a lower bound of Ω(
km) on
additive error by showing a reduction to the linear reconstruction attack [18]. In other words  any
algorithm that outputs a low rank matrix with additive error o(
km) cannot be differentially
private! This lower bound holds even when the private algorithm can access the private matrix any
number of times. Our results show that one can match the lower bound for constant α  a setting
considered in Hardt and Roth [30]  up to a small logarithmic factor  while allowing access to the
private matrix only in the turnstile model.
Space Lower Bound and Optimality of the Algorithm Under Priv1. Our algorithms use same
space as non-private algorithm up to a logarithmic factor  which is known to be optimal for γ = 0 [12].
However  we incur a non-zero additive error  γ  which is inevitable [30]  and it is not clear if we can
achieve better space algorithm when γ (cid:54)= 0.
We complement Theorem 2 with a lower bound on the space required for low-rank approximation
with non-trivial additive error. Our result holds for any randomized algorithm; therefore  also hold
for any private algorithm. This we believe makes our result of independent interest.
Theorem 3. The space required by any randomized algorithm to solve (α  1/6  O(m + n)  k)-LRF
in the turnstile update model is Ω((n + m)kα−1).

kn). Moreover  known differentially

2 − 1. This thus prove optimality for all k ≥ 3.

√
Any differentially private incurs an additive error Ω(
private low-rank approximation [30] set α =
Under Bounded Norm Assumptions. In some practical applications  matrices are more structured.
One such special case is when the rows of private matrix A have bounded norm and one would like
to approximate ATA. This problem was studied by Dwork et al. [24]. We consider the matrices are
A(τ ) ∈ Rn  and iτ (cid:54)= iτ(cid:48) for all τ (cid:54)= τ(cid:48). We show the following by using ATA as the input matrix:
Corollary 1. Given an A ∈ Rm×n updated by inserting one row at a time such that every row
has a bounded norm 1 and m > n. Then there is an (ε  δ)-differentially private algorithm under

updated by row-wise: all the updates at time τ ≤ T are of the form(cid:8)iτ   A(τ )(cid:9)  where 1 ≤ iτ ≤ m 
Priv2 that uses (cid:101)O(nkα−2) space  and outputs a rank-k matrix B such that (cid:107)ATA − B(cid:107)F ≤
(1 + α)(cid:107)ATA − [ATA]k(cid:107)F + (cid:101)O(

nk/(αε)).

km +

√

√

√

√

We do not violate the lower bound of Dwork et al. [24] because their lower bound is valid when
α = 0  which is not possible for low space algorithms due to Theorem 3. Dwork et al. [24] bypassed
their lower bounds under a stronger assumption known as singular value separation: the difference
between k-th singular value and all k(cid:48)-th singular values for k(cid:48) > k is at least ω(
n). In other
words  our result shows that we do not need singular value separation while using signiﬁcantly less

space—(cid:101)O(nk/α2) as compared to O(n2)—if we are ready to pay for a small multiplicative error.

√

Adapting to Continual Release Model. Until now  we gave algorithms that produce the output only
at the end of the stream. There is a related model called (ε  δ)-differential privacy under T -continual
release [23]. In this model  the server receives a stream of length T and produces an output after
every update  such that every output is (ε  δ)-differentially private. We modify our meta algorithm to
work in this model by using the fact that we only store noisy linear sketches of the private matrix
during the updates and low-rank factorization is computed through post-processing on only the noisy
sketches. That is  we can use the generic transformation [23] to maintain the sketch of the updates. A
factorization for any time range can be done by aggregating the sketches for the speciﬁed range using
range queries. This gives the ﬁrst instance of algorithm that provides differentially private continual
release of LRF. We show the following.
Theorem 4. Let A ∈ Rm×n be the private matrix streamed over T time epochs. Then there is
an (ε  δ)-differentially private algorithm under Priv1 that outputs a rank-k factorization under the

continual release for T time epochs such that γ = (cid:101)O(ε−1(

mkα−1 +

kn) log T ).

√

√

7

5 Noninteractive Local Differentially Private PCA

the local model  we end up with an additive error (cid:101)O(

Till now  we have considered a single server that receives the private matrix in a streamed manner.
We next consider another variant of differential privacy known as local differential privacy (LDP)
[21  22  26  59]. In the local model  each individual applies a differentially private algorithm locally to
their data and shares only the output of the algorithm—called a report—with a server that aggregates
users’ reports. A multi-player protocol is ε-LDP if for all possible inputs and runs of the protocol  the
transcript of player i’s interactions with the server is ε-LDP.
One can study two variants of local differential privacy depending on whether the server and the users
interact more than once or not. In the interactive variant  the server sends several messages  each to a
subset of users. In the noninteractive variant  the server sends a single message to all the users at the
start of the protocol and sends no message after that. Smith  Thakurta  and Upadhyay [54] argued
that noninteractive locally private algorithms are ideal for implementation.
The natural extension of Problem 1 in the local model is when the matrix is distributed among the
users such that every user has one row of the matrix and users are responsible for the privacy of
their row vector. Unfortunately  known private algorithms (including the results presented till now)
do not yield non trivial additive error in the local model. For example  if we convert Theorem 2 to
kmn). This is worse than the trivial bound
√
mn)  for example  when A ∈ {0  1}m×n  a trivial output of all zero matrix incurs an error
√
of O(
√
mn). In fact  existing lower bounds in the local model suggests that one is likely to
at most O(
incur an error which is O(
m) factor worse than in the central model  where m is the number
of users. However  owing to the result of Dwork et al. [24]  we can hope to achieve non-trivial
result for differentially private principal component analysis. This problem has been studied without
privacy under the row-partition model [6  39  37  9  27  50  51  55]). We exploit the fact that our
meta algorithm only stores differentially private sketches of the input matrix to give a noninteractive
algorithm for low-rank principal component analysis (PCA) under local differential privacy. This
produces an (  δ)-locally differentially private algorithm; however  it is non-interactive. We then use
the generic transformation of Bun et al. [10] to get the following result.
Theorem 5. Let m  n ∈ N and α  ε  δ be the input parameters. Let k be the desired rank of
matrix A ∈ Rm×n distributed in a row-wise manner amongst m users  there is an efﬁcient ε-local
differentially private algorithm under Priv2 that uses O(v2) words of communications from users to
central server and outputs a rank-k orthonormal matrix U such that with probability 9/10 

the factorization and η = max(cid:8)k  α−1(cid:9). Let v = O(ηα−2 log(k/δ)). Given a private input

√

(cid:107)A − UUTA(cid:107)F ≤ (1 + O(α))(cid:107)A − [A]k(cid:107)F + O

6 Discussion on Neighboring Relation

(cid:16)

(cid:17)
v(cid:112)m log(1/δ)/

.

e = (u  v) ∈ E has weight(cid:80)

The two privacy guarantees considered in this paper have natural reasons to be considered. Priv1
generalizes the earlier privacy guarantees and captures the setting where any two matrices differ
in only one spectrum. Since Priv1 is deﬁned in terms of the spectrum of matrices  Priv1 captures
one of the natural privacy requirements in all the applications of LRF. Priv2 is stronger than Priv1.
To motivate the deﬁnition of Priv2  consider a graph  G := (V E) that stores career information
of people in a set P since their graduation. The vertex set V is the set of all companies. An edge
p∈P (tp e/tp)  where tp e is the time for which the person p held a job
at v after leaving his/her job at u  and tp is the total time lapsed since his/her graduation. Graphs
like G are useful because the weight on every edge e = (u  v) depends on the number of people who
changed their job status from u to v (and the time they spent at v). Therefore  data analysts might
want to mine such graphs for various statistics. In the past  graph statistics have been extensively
studied for static graph under edge-level privacy (see  for e.g.  [24  30  29  56  57]): the presence
or absence of a person corresponds to a change in a single edge. On the other hand  in graphs like
G  presence or absence of a person would be reﬂected on many edges. If we use earlier results on
edge-level privacy to such graphs  it would lead to either a large additive error or a loss in privacy
parameters ε  δ. Priv2 is an attempt to understand whether we can achieve any non-trivial guarantee
on the additive error without depreciating the privacy parameters.

8

Figure 1: Empirical Evaluation of Additive Error of Our Algorithm.

7 Empirical Evaluation of Our Algorithms

In this section  we give a glimpse of our experimental evaluations of additive error and compare it with
the best known results. The details and discussion of our empirical evaluations is in supplementary
materials. Two important parameters in our bounds are k and α – Hardt and Roth [30] consider
a constant α. Therefore  we analyze the additive error with respect to the change in α in order to
better understand the effect of differential privacy on low space low-rank approximation of matrices.
The result of our experiment is presented in Figure 1 ((a)-(d)) with the scale of y-axis (accuracy)
in logarithmic to better illustrate the accuracy improvement shown by our algorithm. In both these
experiments  we see that the additive error incurred by our algorithm is less than the additive error
incurred by Hardt and Roth [30]. We note that the matrices are highly incoherent as all the entries
are sampled i.i.d. We also consider the role of k in our locally-private algorithm. The results of our
experiment in presented in Figure 1 ((e)-(f)). The error of our algorithm is consistently less than the
expected error.

8 Conclusion

In this paper  we study differentially private low-rank approximation in various settings of practical
importance. We give ﬁrst algorithms with optimal accuracy  space requirements  and runtime for all
of these settings. Our results relies crucially on careful analysis and our algorithms heavily exploit
advance yet inexpensive post-processing. Prior to this work  only two known private algorithms
for Problem 1 use any form of post-processing for LRF: Hardt and Roth [30] uses simple pruning
of entries of a matrix formed in the intermediate step  while Dwork et al. [24] uses best rank-k
approximation of the privatized matrix. These post-processing either make the algorithm suited only
for static matrices or are expensive.
There are few key take aways from this paper: (i) maintaining a differentially private sketches of row
space and column space of a matrix already give a sub-optimal accuracy  but this can be signiﬁcantly
improved by careful inexpensive post-processing  and (ii) the structural properties of linear sketches
can be carefully exploited to get tight bound on the error. Prior to this work  it was not clear whether
the techniques we use in this paper yields low rank approximation (see the comment after Theorem
IV.2 and discussion in Section V in Blocki et al. [8]). Therefore  we believe our techniques will ﬁnd
use in many related private algorithms as evident by the recent result of Arora et al. [4].
Acknowledgements. The author would like to thank Adam Smith for useful feedback on this paper.
This research was supported in part by NSF BIGDATA grant IIS-1447700  NSF BIGDATA grant
IIS-154648  and NSF BIGDATA grant IIS-1838139.

9

References
[1] Dimitris Achlioptas  Amos Fiat  Anna R Karlin  and Frank McSherry. Web search via hub

synthesis. In FOCS  pages 500–509. IEEE  2001.

[2] Dimitris Achlioptas and Frank McSherry. On spectral learning of mixtures of distributions. In

Learning Theory  pages 458–469. Springer  2005.

[3] Apple. Apple tries to peek at user habits without violating privacy. The Wall Street Journal 

2016.

[4] Raman Arora  Vladimir Braverman  and Jalaj Upadhyay. Differentially private robust low-rank
approximation. In Advances in Neural Information Processing Systems  pages 4141–4149 
2018.

[5] Yossi Azar  Amos Fiat  Anna Karlin  Frank McSherry  and Jared Saia. Spectral analysis of data.

In STOC  pages 619–626. ACM  2001.

[6] Zheng-Jian Bai  Raymond H Chan  and Franklin T Luk. Principal component analysis for
distributed data sets with updating. In International Workshop on Advanced Parallel Processing
Technologies  pages 471–483. Springer  2005.

[7] Rajendra Bhatia. Matrix analysis  volume 169. Springer Science &amp; Business Media  2013.

[8] Jeremiah Blocki  Avrim Blum  Anupam Datta  and Or Sheffet. The Johnson-Lindenstrauss

Transform Itself Preserves Differential Privacy. In FOCS  pages 410–419  2012.

[9] Christos Boutsidis  David P. Woodruff  and Peilin Zhong. Optimal principal component analysis

in distributed and streaming models. In STOC  pages 236–249  2016.

[10] Mark Bun  Jelani Nelson  and Uri Stemmer. Heavy hitters and the structure of local privacy.

arXiv preprint arXiv:1711.04740  2017.

[11] Kamalika Chaudhuri  Anand D Sarwate  and Kaushik Sinha. Near-optimal differentially private

principal components. In NIPS  pages 998–1006  2012.

[12] Kenneth L. Clarkson and David P. Woodruff. Numerical linear algebra in the streaming model.

In STOC  pages 205–214  2009.

[13] Kenneth L Clarkson and David P Woodruff. Low rank approximation and regression in input

sparsity time. In STOC  pages 81–90. ACM  2013.

[14] Kenneth L Clarkson and David P Woodruff. Low-rank psd approximation in input-sparsity time.
In Proceedings of the Twenty-Eighth Annual ACM-SIAM Symposium on Discrete Algorithms 
pages 2061–2072. SIAM  2017.

[15] Michael B Cohen  Sam Elder  Cameron Musco  Christopher Musco  and Madalina Persu.
Dimensionality reduction for k-means clustering and low rank approximation. In STOC  pages
163–172. ACM  2015.

[16] Michael B Cohen  Cameron Musco  and Christopher Musco. Input sparsity time low-rank
approximation via ridge leverage score sampling. In Proceedings of the Twenty-Eighth Annual
ACM-SIAM Symposium on Discrete Algorithms  pages 1758–1777. SIAM  2017.

[17] Amit Deshpande and Santosh Vempala. Adaptive sampling and fast low-rank matrix approxi-
mation. In Approximation  Randomization  and Combinatorial Optimization. Algorithms and
Techniques  pages 292–303. Springer  2006.

[18] Irit Dinur and Kobbi Nissim. Revealing information while preserving privacy. In PODS  pages

202–210. ACM  2003.

[19] Petros Drineas  Alan Frieze  Ravi Kannan  Santosh Vempala  and V Vinay. Clustering large

graphs via the singular value decomposition. Machine learning  56(1-3):9–33  2004.

[20] Petros Drineas  Iordanis Kerenidis  and Prabhakar Raghavan. Competitive recommendation

systems. In STOC  pages 82–90. ACM  2002.

10

[21] John C Duchi  Michael I Jordan  and Martin J Wainwright. Local privacy and statistical minimax
rates. In Foundations of Computer Science (FOCS)  2013 IEEE 54th Annual Symposium on 
pages 429–438. IEEE  2013.

[22] Cynthia Dwork  Frank McSherry  Kobbi Nissim  and Adam Smith. Calibrating Noise to
Sensitivity in Private Data Analysis. In Shai Halevi and Tal Rabin  editors  TCC  volume 3876
of Lecture Notes in Computer Science  pages 265–284. Springer  2006.

[23] Cynthia Dwork  Moni Naor  Toniann Pitassi  and Guy N. Rothblum. Differential privacy under

continual observation. In STOC  pages 715–724  2010.

[24] Cynthia Dwork  Kunal Talwar  Abhradeep Thakurta  and Li Zhang. Analyze Gauss: Optimal
Bounds for Privacy-Preserving Principal Component Analysis. In STOC  pages 11–20  2014.

[25] Úlfar Erlingsson  Vasyl Pihur  and Aleksandra Korolova. Rappor: Randomized aggregatable
privacy-preserving ordinal response. In Proceedings of the 2014 ACM SIGSAC conference on
computer and communications security  pages 1054–1067. ACM  2014.

[26] Alexandre Evﬁmievski  Johannes Gehrke  and Ramakrishnan Srikant. Limiting privacy breaches

in privacy preserving data mining. In PODS  pages 211–222. ACM  2003.

[27] Dan Garber  Ohad Shamir  and Nathan Srebro. Communication-efﬁcient algorithms for dis-

tributed stochastic principal component analysis. arXiv preprint arXiv:1702.08169  2017.

[28] Nathan Halko  Per-Gunnar Martinsson  and Joel A Tropp. Finding structure with randomness:
Probabilistic algorithms for constructing approximate matrix decompositions. SIAM review 
53(2):217–288  2011.

[29] Moritz Hardt and Eric Price. The noisy power method: A meta algorithm with applications. In
Z. Ghahramani  M. Welling  C. Cortes  N.d. Lawrence  and K.q. Weinberger  editors  Advances
in Neural Information Processing Systems 27  pages 2861–2869. Curran Associates  Inc.  2014.

[30] Moritz Hardt and Aaron Roth. Beating randomized response on incoherent matrices. In STOC 

pages 1255–1268  2012.

[31] Moritz Hardt and Aaron Roth. Beyond worst-case analysis in private singular vector computa-

tion. In STOC  pages 331–340  2013.

[32] Prateek Jain  Praneeth Netrapalli  and Sujay Sanghavi. Low-rank matrix completion using
alternating minimization. In Proceedings of the forty-ﬁfth annual ACM symposium on Theory
of computing  pages 665–674. ACM  2013.

[33] Wuxuan Jiang  Cong Xie  and Zhihua Zhang. Wishart mechanism for differentially private

principal components analysis. arXiv preprint arXiv:1511.05680  2015.

[34] Ravindran Kannan  Hadi Salmasian  and Santosh Vempala. The spectral method for general

mixture models. In Learning Theory  pages 444–457. Springer  2005.

[35] Michael Kapralov and Kunal Talwar. On differentially private low rank approximation. In

SODA  volume 5  page 1. SIAM  2013.

[36] Jon M Kleinberg. Authoritative sources in a hyperlinked environment. Journal of the ACM

(JACM)  46(5):604–632  1999.

[37] Yann-Aël Le Borgne  Sylvain Raybaud  and Gianluca Bontempi. Distributed principal compo-

nent analysis for wireless sensor networks. Sensors  8(8):4821–4850  2008.

[38] Yi Li  Huy L. Nguyen  and David P. Woodruff. Turnstile streaming algorithms might as well be
linear sketches. In Symposium on Theory of Computing  STOC 2014  New York  NY  USA  May
31 - June 03  2014  pages 174–183  2014.

[39] Yingyu Liang  Maria-Florina F Balcan  Vandana Kanchanapally  and David Woodruff. Improved
In Advances in Neural Information Processing

distributed principal component analysis.
Systems  pages 3113–3121  2014.

11

[40] Avner Magen and Anastasios Zouzias. Low rank matrix-valued chernoff bounds and approxi-

mate matrix multiplication. In SODA  pages 1422–1436. SIAM  2011.

[41] Michael W Mahoney. Randomized algorithms for matrices and data. Foundations and Trends R(cid:13)

in Machine Learning  3(2):123–224  2011.

[42] Ivan Markovsky. Structured low-rank approximation and its applications. Automatica  44(4):891–

909  2008.

[43] Frank McSherry. Spectral partitioning of random graphs. In FOCS  pages 529–537. IEEE 

2001.

[44] Xiangrui Meng and Michael W Mahoney. Low-distortion subspace embeddings in input-sparsity

time and applications to robust linear regression. In STOC  pages 91–100. ACM  2013.

[45] Cameron Musco and David P Woodruff. Sublinear time low-rank approximation of positive

semideﬁnite matrices. arXiv preprint arXiv:1704.03371  2017.

[46] Shanmugavelayutham Muthukrishnan. Data streams: Algorithms and applications. Now

Publishers Inc  2005.

[47] Arvind Narayanan and Vitaly Shmatikov. Robust de-anonymization of large sparse datasets. In

Security and Privacy  2008. SP 2008. IEEE Symposium on  pages 111–125. IEEE  2008.

[48] Nam H Nguyen  Thong T Do  and Trac D Tran. A fast and efﬁcient algorithm for low-rank

approximation of a matrix. In STOC  pages 215–224. ACM  2009.

[49] Christos H Papadimitriou  Hisao Tamaki  Prabhakar Raghavan  and Santosh Vempala. Latent
semantic indexing: A probabilistic analysis. In Proceedings of the seventeenth ACM SIGACT-
SIGMOD-SIGART symposium on Principles of database systems  pages 159–168. ACM  1998.

[50] Jack Poulson  Bryan Marker  Robert A Van de Geijn  Jeff R Hammond  and Nichols A Romero.
Elemental: A new framework for distributed memory dense matrix computations. ACM
Transactions on Mathematical Software (TOMS)  39(2):13  2013.

[51] Yongming Qu  George Ostrouchov  Nagiza Samatova  and Al Geist. Principal component
analysis for dimension reduction in massive distributed data sets. In Proceedings of IEEE
International Conference on Data Mining (ICDM)  2002.

[52] Tamas Sarlos. Improved approximation algorithms for large matrices via random projections.

In FOCS  pages 143–152. IEEE  2006.

[53] John Shawe-Taylor and Nello Cristianini. Kernel methods for pattern analysis. Cambridge

university press  2004.

[54] A. Smith  A. Thakurata  and J. Upadhyay. Is Interaction Necessary for Distributed Private

Learning? To Appear in IEEE Symposium for Security & Privacy  2017.

[55] Françoise Tisseur and Jack Dongarra. A parallel divide and conquer algorithm for the symmetric
eigenvalue problem on distributed memory architectures. SIAM Journal on Scientiﬁc Computing 
20(6):2223–2236  1999.

[56] Jalaj Upadhyay. Random Projections  Graph Sparsiﬁcation  and Differential Privacy.

ASIACRYPT (1)  pages 276–295  2013.

In

[57] Jalaj Upadhyay. Differentially private linear algebra in the streaming model. arXiv preprint

arXiv:1409.5414  2014.

[58] Jalaj Upadhyay. Randomness efﬁcient fast-johnson-lindenstrauss transform with applications in

differential privacy and compressed sensing. arXiv preprint arXiv:1410.2470  2014.

[59] Stanley L. Warner. Randomized response: A survey technique for eliminating evasive answer

bias. Journal of the American Statistical Association  60(309):63–69  1965.

12

,Federico Monti
Michael Bronstein
Xavier Bresson
Jalaj Upadhyay