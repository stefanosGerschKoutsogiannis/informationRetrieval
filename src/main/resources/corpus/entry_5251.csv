2016,Stochastic Optimization for Large-scale Optimal Transport,Optimal transport (OT) defines a powerful framework to compare probability distributions in a geometrically faithful way. However  the practical impact of OT is still limited because of its computational burden. We propose a new class of stochastic optimization algorithms to cope with large-scale problems routinely encountered in machine learning applications. These methods are able to manipulate arbitrary distributions (either discrete or continuous) by simply requiring to be able to draw samples from them  which is the typical setup in high-dimensional learning problems. This alleviates the need to discretize these densities  while giving access to provably convergent methods that output the correct distance without discretization error. These algorithms rely on two main ideas: (a) the dual OT problem can be re-cast as the maximization of an expectation; (b) entropic regularization of the primal OT problem results in a smooth dual optimization optimization which can be addressed with algorithms that have a provably faster convergence. We instantiate these ideas in three different computational setups: (i) when comparing a discrete distribution to another  we show that incremental stochastic optimization schemes can beat the current state of the art finite dimensional OT solver (Sinkhorn's algorithm) ; (ii) when comparing a discrete distribution to a continuous density  a re-formulation (semi-discrete) of the dual program is amenable to averaged stochastic gradient descent  leading to better performance than approximately solving the problem by discretization ; (iii) when dealing with two continuous densities  we propose a stochastic gradient descent over a reproducing kernel Hilbert space (RKHS). This is currently the only known method to solve this problem  and is more efficient than discretizing beforehand the two densities. We backup these claims on a set of discrete  semi-discrete and continuous benchmark problems.,Stochastic Optimization for

Large-scale Optimal Transport

Aude Genevay

CEREMADE  Université Paris-Dauphine

INRIA – Mokaplan project-team

genevay@ceremade.dauphine.fr

Marco Cuturi
CREST  ENSAE

Université Paris-Saclay

marco.cuturi@ensae.fr

Gabriel Peyré

CNRS and DMA  École Normale Supérieure

INRIA – Mokaplan project-team

gabriel.peyre@ens.fr

Francis Bach

INRIA – Sierra project-team

DI  ENS

francis.bach@inria.fr

Abstract

Optimal transport (OT) deﬁnes a powerful framework to compare probability
distributions in a geometrically faithful way. However  the practical impact of OT
is still limited because of its computational burden. We propose a new class of
stochastic optimization algorithms to cope with large-scale OT problems. These
methods can handle arbitrary distributions (either discrete or continuous) as long
as one is able to draw samples from them  which is the typical setup in high-
dimensional learning problems. This alleviates the need to discretize these densities 
while giving access to provably convergent methods that output the correct distance
without discretization error. These algorithms rely on two main ideas: (a) the
dual OT problem can be re-cast as the maximization of an expectation; (b) the
entropic regularization of the primal OT problem yields a smooth dual optimization
which can be addressed with algorithms that have a provably faster convergence.
We instantiate these ideas in three different setups: (i) when comparing a discrete
distribution to another  we show that incremental stochastic optimization schemes
can beat Sinkhorn’s algorithm  the current state-of-the-art ﬁnite dimensional OT
solver; (ii) when comparing a discrete distribution to a continuous density  a semi-
discrete reformulation of the dual program is amenable to averaged stochastic
gradient descent  leading to better performance than approximately solving the
problem by discretization ; (iii) when dealing with two continuous densities  we
propose a stochastic gradient descent over a reproducing kernel Hilbert space
(RKHS). This is currently the only known method to solve this problem  apart
from computing OT on ﬁnite samples. We backup these claims on a set of discrete 
semi-discrete and continuous benchmark problems.

Introduction

1
Many problems in computational sciences require to compare probability measures or histograms.
As a set of representative examples  let us quote: bag-of-visual-words comparison in computer
vision [17]  color and shape processing in computer graphics [21]  bag-of-words for natural language
processing [11] and multi-label classiﬁcation [9]. In all of these problems  a geometry between the
features (words  visual words  labels) is usually known  and can be leveraged to compare probability
distributions in a geometrically faithful way. This underlying geometry might be for instance the
planar Euclidean domain for 2-D shapes  a perceptual 3D color metric space for image processing
or a high-dimensional semantic embedding for words. Optimal transport (OT) [24] is the canonical

30th Conference on Neural Information Processing Systems (NIPS 2016)  Barcelona  Spain.

way to automatically lift this geometry to deﬁne a metric for probability distributions. That metric is
known as the Wasserstein or earth mover’s distance. As an illustrative example  OT can use a metric
between words to build a metric between documents that are represented as frequency histograms of
words (see [11] for details). All the above-cited lines of work advocate  among others  that OT is the
natural choice to solve these problems  and that it leads to performance improvement when compared
to geometrically-oblivious distances such as the Euclidean or χ2 distances or the Kullback-Leibler
divergence. However  these advantages come at the price of an enormous computational overhead.
This is especially true because current OT solvers require to sample beforehand these distributions
on a pre-deﬁned set of points  or on a grid. This is both inefﬁcient (in term of storage and speed)
and counter-intuitive. Indeed  most high-dimensional computational scenarios naturally represent
distributions as objects from which one can sample  not as density functions to be discretized.
Our goal is to alleviate these shortcomings. We propose a class of provably convergent stochastic
optimization schemes that can handle both discrete and continuous distributions through sampling.
Previous works. The prevalent way to compute OT distances is by solving the so-called Kantorovitch
problem [10] (see Section 2 for a short primer on the basics of OT formulations)  which boils down
to a large-scale linear program when dealing with discrete distributions (i.e.  ﬁnite weighted sums of
Dirac masses). This linear program can be solved using network ﬂow solvers  which can be further
reﬁned to assignment problems when comparing measures of the same size with uniform weights [3].
Recently  regularized approaches that solve the OT with an entropic penalization [6] have been shown
to be extremely efﬁcient to approximate OT solutions at a very low computational cost. These regu-
larized approaches have supported recent applications of OT to computer graphics [21] and machine
learning [9]. These methods apply the celebrated Sinkhorn algorithm [20]  and can be extended
to solve more exotic transportation-related problems such as the computation of barycenters [21].
Their chief computational advantage over competing solvers is that each iteration boils down to
matrix-vector multiplications  which can be easily parallelized  streams extremely well on GPU  and
enjoys linear-time implementation on regular grids or triangulated domains [21].
These methods are however purely discrete and cannot cope with continuous densities. The only
known class of methods that can overcome this limitation are so-called semi-discrete solvers [1]  that
can be implemented efﬁciently using computational geometry primitives [12]. They can compute
distance between a discrete distribution and a continuous density. Nonetheless  they are restricted to
the Euclidean squared cost  and can only be implemented in low dimensions (2-D and 3-D). Solving
these semi-discrete problems efﬁciently could have a signiﬁcant impact for applications to density
ﬁtting with an OT loss [2] for machine learning applications  see [13]. Lastly  let us point out that
there is currently no method that can compute OT distances between two continuous densities  which
is thus an open problem we tackle in this article.
Contributions. This paper introduces stochastic optimization methods to compute large-scale optimal
transport in all three possible settings: discrete OT  to compare a discrete vs. another discrete measure;
semi-discrete OT  to compare a discrete vs. a continuous measure; and continous OT  to compare
a continuous vs. another continuous measure. These methods can be used to solve classical OT
problems  but they enjoy faster convergence properties when considering their entropic-regularized
versions. We show that the discrete regularized OT problem can be tackled using incremental
algorithms  and we consider in particular the stochastic averaged gradient (SAG) method [19]. Each
iteration of that algorithm requires N operations (N being the size of the supports of the input
distributions)  which makes it scale better in large-scale problems than the state-of-the-art Sinkhorn
algorithm  while still enjoying a convergence rate of O(1/k)  k being the number of iterations. We
√
show that the semi-discrete OT problem can be solved using averaged stochastic gradient descent
(SGD)  whose convergence rate is O(1/
k). This approach is numerically advantageous over the
brute force approach consisting in sampling ﬁrst the continuous density to solve next a discrete OT
problem. Lastly  for continuous optimal transport  we propose a novel method which makes use of an
expansion of the dual variables in a reproducing kernel Hilbert space (RKHS). This allows us for
the ﬁrst time to compute with a converging algorithm OT distances between two arbitrary densities 
under the assumption that the two potentials belong to such an RKHS.
Notations. In the following we consider two metric spaces X and Y. We denote by M1
+(X ) the set
of positive Radon probability measures on X   and C(X ) the space of continuous functions on X . Let
µ ∈ M1

+(X × Y) ; ∀(A  B) ⊂ X × Y  π(A × Y) = µ(A)  π(X × B) = ν(B)(cid:9)  

+(Y)  we deﬁne

+(X )  ν ∈ M1

Π(µ  ν) def.=(cid:8)π ∈ M1

2

the set of joint probability measures on X × Y with marginals µ and ν. The Kullback-Leibler
divergence between joint probabilities is deﬁned as

+(X × Y)2  KL(π|ξ) def.=(cid:82)

X×Y

(cid:0) log(cid:0) dπ

dξ (x  y)(cid:1) − 1(cid:1)dξ(x  y) 

∀(π  ξ) ∈ M1

(cid:8)µ ∈ RN

dξ the relative density of π with respect to ξ  and by convention KL(π|ξ) def.= +∞
where we denote dπ
if π does not have a density with respect to ξ. The Dirac measure at point x is δx. For a set C 
ιC(x) = 0 if x ∈ C and ιC(x) = +∞ otherwise. The probability simplex of N bins is ΣN =
the transpose of a matrix K. We denote 1N = (1  . . .   1)(cid:62) ∈ RN and 0N = (0  . . .   0)(cid:62) ∈ RN .

i µi = 1(cid:9). Element-wise multiplication of vectors is denoted by (cid:12) and K(cid:62) denotes

+ ; (cid:80)

(cid:90)

+(X )×M1

+(X ) and ν ∈ M1

2 Optimal Transport: Primal  Dual and Semi-dual Formulations
We consider the optimal transport problem between two measures µ ∈ M1
+(Y) 
deﬁned on metric spaces X and Y. No particular assumption is made on the form of µ and ν  we
only assume that they both can be sampled from to be able to apply our algorithms.
Primal  Dual and Semi-dual Formulations. The Kantorovich formulation [10] of OT and its
entropic regularization [6] can be conveniently written in a single convex optimization problem as
follows
∀(µ  ν) ∈ M1
c(x  y)dπ(x  y)+ε KL(π|µ⊗ν). (Pε)
Here c ∈ C(X × Y) and c(x  y) should be interpreted as the “ground cost” to move a unit of mass
from x to y. This c is typically application-dependent  and reﬂects some prior knowledge on the
data to process. We refer to the introduction for a list of previous work where various examples (in
imaging  vision  graphics or machine learning) of such costs are given.
When X = Y  ε = 0 and c = dp for p ≥ 1  where d is a distance on X   then W0(µ  ν)
p is known as
+(X ). Note that this deﬁnition can be used for any type of measure 
the p-Wasserstein distance on M1
both discrete and continuous. When ε > 0  problem (Pε) is strongly convex  so that the optimal π is
unique  and algebraic properties of the KL regularization result in computations that can be tackled
using the Sinkhorn algorithm [6].
For any c ∈ C(X × Y)  we deﬁne the following constraint set

+(Y)  Wε(µ  ν) def.= min
π∈Π(µ ν)

X×Y

1

def.= {(u  v) ∈ C(X ) × C(Y) ; ∀(x  y) ∈ X × Y  u(x) + v(y) ≤ c(x  y)}  

Uc

and deﬁne its indicator function as well as its “smoothed” approximation

ιε
Uc

(u  v) def.=

if

ε = 0 

X×Y exp( u(x)+v(y)−c(x y)

ε

)dµ(x)dν(y)

if

ε > 0.

For any v ∈ C(Y)  we deﬁne its c-transform and its “smoothed” approximation

(cid:26) ιUc(u  v)
ε(cid:82)
 min

(1)

(2)

∀x ∈ X  

vc ε(x) def.=

(cid:16)(cid:82)

y∈Y c(x  y) − v(y)
−ε log

Y exp( v(y)−c(x y)

ε

if

ε = 0 

(cid:17)

)dν(y)

if

ε > 0.

(cid:90)

The proposition below describes two dual problems. It is central to our analysis and paves the way
for the application of stochastic optimization methods.
Proposition 2.1 (Dual and semi-dual formulations). For ε ≥ 0  one has

(cid:90)

max

Wε(µ  ν) =

u(x)dµ(x) +

Fε(u  v) def.=

u∈C(X ) v∈C(Y)

(Dε)
(Sε)
is deﬁned in (1) and vc ε in (2). Furthermore  u solving (Dε) is recovered from an optimal
where ιε
v solving (Sε) as u = vc ε. For ε > 0  the solution π of (Pε) is recovered from any (u  v) solving
Uc
(Dε) as dπ(x  y) = exp( u(x)+v(y)−c(x y)

v(y)dν(y) − ε 

v(y)dν(y) − ιε

vc ε(x)dµ(x) +

)dµ(x)dν(y).

= max
v∈C(Y)

Hε(v) def.=

(u  v) 

Uc

X

X

ε

(cid:90)

Y

(cid:90)

Y

3

Proof. Problem (Dε) is the convex dual of (Pε)  and is derived using Fenchel-Rockafellar’s theorem.
The relation between u and v is obtained by writing the ﬁrst order optimality condition for v in (Dε).
Plugging this expression back in (Dε) yields (Sε).

Problem (Pε) is called the primal while (Dε) is its associated dual problem. We refer to (Sε) as the
“semi-dual” problem  because in the special case ε = 0  (Sε) boils down to the so-called semi-discrete
OT problem [1]. Both dual problems are concave maximization problems. The optimal dual variables
(u  v)—known as Kantorovitch potentials—are not unique  since for any solution (u  v) of (Dε) 
(u + λ  v − λ) is also a solution for any λ ∈ R. When ε > 0  they can be shown to be unique up to
this scalar translation [6]. We refer to the supplementary material for a discussion (and proofs) of the
convergence of the solutions of (Pε)  (Dε) and (Sε) towards those of (P0)  (D0) and (S0) as ε → 0.
A key advantage of (Sε) over (Dε) is that  when ν is a discrete density (but not necessarily µ) 
then (Sε) is a ﬁnite-dimensional concave maximization problem  which can thus be solved using
stochastic programming techniques  as highlighted in Section 4. By contrast  when both µ and ν are
continuous densities  these dual problems are intrinsically inﬁnite dimensional  and we propose in
Section 5 more advanced techniques based on RKHSs.
Stochastic Optimization Formulations. The fundamental property needed to apply stochastic
programming is that both dual problems (Dε) and (Sε) must be rephrased as maximizing expectations:

∀ε > 0  Fε(u  v) = EX Y [fε(X  Y  u  v)]

and ∀ε ≥ 0  Hε(v) = EX [hε(X  v)]  

(3)

where the random variables X and Y are independent and distributed according to µ and ν respec-
tively  and where  for (x  y) ∈ X × Y and (u  v) ∈ C(X ) × C(Y) 

∀ε > 0 

fε(x  y  u  v) def.= u(x) + v(y) − ε exp

∀ε ≥ 0 

hε(x  v) def.=

v(y)dν(y) + vc ε(x) − ε.

(cid:90)

Y

(cid:16) u(x) + v(y) − c(x  y)

(cid:17)

 

ε

This reformulation is at the heart of the methods detailed in the remainder of this article. Note that
the dual problem (Dε) cannot be cast as an unconstrained expectation maximization problem when
ε = 0  because of the constraint on the potentials which arises in that case.

When ν is discrete  i.e ν = (cid:80)J

ε

)

(cid:17)−1

(cid:16)(cid:80)J

j=1 νjδyj the potential v is a J-dimensional vector (vj)j={1...J}
and we can compute the gradient of hε. When ε > 0 the gradient reads ∇vhε(v  x) =
ε (π(x)π(x)T − diag(π(x))) where π(x)i =
ν − π(x) and the hessian is given by ∂2
v hε(v  x) = 1
j=1 exp( vj−c(x yj )
exp( vi−c(x yi)
. The eigenvalues of the hessian can be upper bounded
)
by 1
ε   which guarantees a lipschitz gradient  and lower bounded by 0 which does not ensure
strong convexity.
In the unregularized case  h0 is not smooth and a subgradient is given by
∇vh0(v  x) = ν − ˜π(x)  where ˜π(x)i = χi=j(cid:63) and j(cid:63) = arg minj∈{1...J} c(x  yj) − vj (when
several elements are in the argmin  we arbitrarily choose one of them to be j(cid:63)). We insist on the
lack of strong convexity of the semi-dual problem  as it impacts the convergence properties of the
stochastic algorithms (stochastic averaged gradient and stochastic gradient descent) described below.

ε

3 Discrete Optimal Transport

the form µ = (cid:80)I

ν = (cid:80)J

and

i=1 µiδxi

We assume in this section that both µ and ν are discrete measures  i.e. ﬁnite sums of Diracs  of
j=1 νjδyj   where (xi)i ⊂ X and (yj)j ⊂ Y  and the
histogram vector weights are µ ∈ ΣI and ν ∈ ΣJ. These discrete measures may come from the
evaluation of continuous densities on a grid  counting features in a structured object  or be empirical
measures based on samples. This setting is relevant for several applications  including all known
applications of the earth mover’s distance. We show in this section that our stochastic formulation
can prove extremely efﬁcient to compare measures with a large number of points.
Discrete Optimization and Sinkhorn. In this setup  the primal (Pε)  dual (Dε) and semi-dual (Sε)
problems can be rewritten as ﬁnite-dimensional optimization problems involving the cost matrix

4

c ∈ RI×J

+

deﬁned by ci j = c(xi  yj):

Wε(µ  ν) = min
π∈RI×J
= max

+

u∈RI  v∈RJ

= max
v∈RJ

(cid:111)

  ( ¯Pε)
( ¯Dε)
( ¯Sε)

(cid:17)
(cid:16) ui+vj−ci j

(cid:17)

ε

(cid:110)(cid:80)
(cid:16)
i j ci jπi j + ε(cid:80)
(cid:80)
i uiµi +(cid:80)
j vjνj − ε(cid:80)
¯Hε(v) =(cid:80)
(cid:40)−ε log((cid:80)
(cid:88)

i j exp
¯hε(xi  v)µi  where

log πi j
µiνj

i∈I

i j

minj (c(x  yj) − vj)

j∈J

− 1

πi j ; π1J = µ  π(cid:62)1I = ν

µiνj  (for ε > 0)

¯hε(x  v) =

vjνj +

j∈J exp( vj−c(x yj )

ε

)νj) − ε

if ε > 0 
if ε = 0 

(4)

Algorithm 1 SAG for Discrete OT
Input: C
Output: v

v ← 0J  d ← 0J  ∀i  gi ← 0J
for k = 1  2  . . . do

Sample i ∈ {1  2  . . .   I} uniform.
d ← d − gi
gi ← µi∇v
d ← d + gi ; v ← v + Cd

The state-of-the-art method to solve the discrete regularized OT (i.e. when ε > 0) is Sinkhorn’s
algorithm [6  Alg.1]  which has linear convergence rate [8]. It corresponds to a block coordinate
maximization  successively optimizing ( ¯Dε) with respect to either u or v. Each iteration of this algo-
rithm is however costly  because it requires a matrix-vector multiplication. Indeed  this corresponds
to a “batch” method where all the samples (xi)i and (yj)j are used at each iteration  which has thus
complexity O(N 2) where N = max(I  J). We now detail how to alleviate this issue using online
stochastic optimization methods.
Incremental Discrete Optimization when ε > 0. Stochastic gradient descent (SGD)  in which an
index k is drawn from distribution µ at each iteration can be used to minimize the ﬁnite sum that
appears in in ¯Sε. The gradient of that term ¯hε(xk ·) can be used as a proxy for the full gradient in a
standard gradient ascent step to maximize ¯Hε.
When ε > 0  the ﬁnite sum appearing in ( ¯Sε) sug-
gests to use incremental gradient methods—rather than
purely stochastic ones—which are known to converge
faster than SGD. We propose to use the stochastic av-
eraged gradient (SAG) [19]. As SGD  SAG operates at
each iteration by sampling a point xk from µ  to com-
pute the gradient corresponding to that sample for the
current estimate v. Unlike SGD  SAG keeps in memory
a copy of that gradient. Another difference is that SAG
applies a ﬁxed length update  in the direction of the
average of all gradients stored so far  which provides a
better proxy of the gradient corresponding to the entire
sum. This improves the convergence rate to | ¯Hε(v(cid:63)
ε is a minimizer
of ¯Hε  at the expense of storing the gradient for each of the I points. This expense can be mitigated
by considering mini-batches instead of individual points. Note that the SAG algorithm is adaptive to
strong-convexity and will be linearly convergent around the optimum. The pseudo-code for SAG
is provided in Algorithm 1  and we defer more details on SGD for Section 4  in which it will be
shown to play a crucial role. Note that the Lipschitz constant of all these terms is upperbounded by
L = maxi µi/ε.
Numerical Illustrations on Bags of Word-Embeddings. Comparing texts using a Wasserstein
distance on their representations as clouds of word embeddings has been recently shown to yield
state-of-the-art accuracy for text classiﬁcation [11]. The authors of [11] have however highlighted
that this accuracy comes at a large computational cost. We test our stochastic approach to discrete
OT in this scenario  using the complete works of 35 authors (names in supplementary material). We
use Glove word embeddings [14] to represent words  namely X = Y = R300. We discard all most
frequent 1  000 words that appear at the top of the ﬁle glove.840B.300d provided on the authors’
website. We sample N = 20  000 words (found within the remaining huge dictionary of relatively
rare words) from each authors’ complete work. Each author is thus represented as a cloud of 20  000
points in R300. The cost function c between the word embeddings is the squared-Euclidean distance 
re-scaled so that it has a unit empirical median on 2  000 points sampled randomly among all vector
embeddings. We set ε to 0.01 (other values are considered in the supplementary material). We
compute all (35 × 34/2 = 595) pairwise regularized Wasserstein distances using both the Sinkhorn
algorithm and SAG. Following the recommendations in [19]  SAG’s stepsize is tested for 3 different
settings  1/L  3/L and 5/L. The convergence of each algorithm is measured by computing the (cid:96)1
norm of the gradient of the full sum (which also corresponds to the marginal violation of the primal
transport solution that can be recovered with these dual variables[6])  as well as the (cid:96)2 norm of the

ε) − ¯Hε(vk)| = O(1/k)  where v(cid:63)

¯hε(xi  v)

end for

5

Figure 1: We compute all 595 pairwise word mover’s distances [11] between 35 very large corpora
of text  each represented as a cloud of I = 20  000 word embeddings. We compare the Sinkhorn
algorithm with SAG  tuned with different stepsizes. Each pass corresponds to a I × I matrix-vector
product. We used minibatches of size 200 for SAG. Left plot: convergence of the gradient (cid:96)1 norm
(average and ± standard deviation error bars). A stepsize of 3/L achieves a substantial speed-up
of ≈ 2.5  as illustrated in the boxplots in the center plot. Convergence to v(cid:63) (the best dual variable
across all variables after 4  000 passes) in (cid:96)2 norm is given in the right plot  up to 2  000 ≈ 211 steps.

deviation to the optimal scaling found after 4  000 passes for any of the three methods. Results are
presented in Fig. 1 and suggest that SAG can be more than twice faster than Sinkhorn on average
for all tolerance thresholds. Note that SAG retains exactly the same parallel properties as Sinkhorn:
all of these computations can be streamlined on GPUs. We used 4 Tesla K80 cards to compute both
SAG and Sinkhorn results. For each computation  all 4  000 passes take less than 3 minutes (far less
are needed if the goal is only to approximate the Wasserstein distance itself  as proposed in [11]).

4 Semi-Discrete Optimal Transport

that ν =(cid:80)J

In this section  we assume that µ is an arbitrary measure (in particular  it needs not to be discrete) and
j=1 νjδyj is a discrete measure. This corresponds to the semi-discrete OT problem [1  12].
The semi-dual problem (Sε) is then a ﬁnite-dimensional maximization problem  written in expectation
form as Wε(µ  ν) = max
v∈RJ

(cid:2)¯hε(X  v)(cid:3) where X ∼ µ and ¯hε is deﬁned in (4).

EX

def.= 1
N

(cid:80)N

Algorithm 2 Averaged SGD for
Semi-Discrete OT
Input: C
Output: v

Stochastic Semi-discrete Optimization. Since the expectation
is taken over an arbitrary measure  neither Sinkhorn algorithm nor
incremental algorithms such as SAG can be used. An alternative
is to approximate µ by an empirical measure ˆµN
i=1 δxi
where (xi)i=1 ... N are i.i.d samples from µ  and computing
Wε(ˆµN   ν) using the discrete methods (Sinkhorn or SAG) de-
tailed in Section 3. However this introduces a discretization noise
in the solution as the discrete problem is now different from the
original one and thus has a different solution. Averaged SGD
on the other hand does not require µ to be discrete and is thus
perfectly adapted to this semi-discrete setting. The algorithm
is detailed in Algorithm 2 (the expression for ∇¯hε being given
√
in Equation 4). The convergence rate is O(1/
k) thanks to
averaging ˜vk [15].
Numerical Illustrations. Simulations are performed in X = Y = R3. Here µ is a Gaussian mixture
(continuous density) and ν = 1
j=1 δyj with J = 10 and (xj)j are i.i.d. samples from another
J
gaussian mixture. Each mixture is composed of three gaussians whose means are drawn randomly in
[0  1]3  and their correlation matrices are constructed as Σ = 0.01(RT + R) + 3I3 where R is 3 × 3
ε a solution of (Sε)  which is approximated
with random entries in [0  1]. In the following  we denote v(cid:63)
by running SGD for 107 iterations  100 times more than those plotted  to ensure reliable convergence
curves. Both plots are averaged over 50 runs  lighter lines show the variability in a single run.

˜v ← 0J   v ← ˜v
for k = 1  2  . . . do
Sample xk from µ
˜v ← ˜v + C√
∇v
v ← 1
k ˜v + k−1
k v

(cid:80)J

¯hε(xk  ˜v)

k

end for

6

(a) SGD

(b) SGD vs. SAG

ε(cid:107)2 /(cid:107)v(cid:63)

0(cid:107)2 /(cid:107)v(cid:63)

(a) Plot of (cid:107)vk − v(cid:63)

0(cid:107)2 as a function of k  for SGD and different values of ε
ε(cid:107)2 as a function of k  for SGD and SAG

Figure 2:
(ε = 0 being un-regularized). (b) Plot of (cid:107)vk − v(cid:63)
with different number N of samples  for regularized OT using ε = 10−2.
0(cid:107)2 as a function of k. It highlights the inﬂuence
Figure 2 (a) shows the evolution of (cid:107)vk − v(cid:63)
of the regularization parameters ε on the iterates of SGD. While the regularized iterates converge
faster  they do not converge to the correct unregularized solution. This ﬁgure also illustrates the
convergence theorem of solution of (Sε) toward those (S0) when ε → 0  which can be found in the
supplementary material. Figure 2 (b) shows the evolution of (cid:107)vk − v(cid:63)
ε(cid:107)2 as a function of
k  for a ﬁxed regularization parameter value ε = 10−2. It compares SGD to SAG using different
numbers N of samples for the empirical measures ˆµN . While SGD converges to the true solution of
the semi-discrete problem  the solution computed by SAG is biased because of the approximation
error which comes from the discretization of µ. This error decreases when the sample size N is
increased  as the approximation of µ by ˆµN becomes more accurate.

0(cid:107)2 /(cid:107)v(cid:63)

ε(cid:107)2 /(cid:107)v(cid:63)

5 Continuous optimal transport using RKHS
In the case where neither µ nor ν are discrete  problem (Sε) is inﬁnite-dimensional  so it cannot be
solved directly using SGD. We propose in this section to solve the initial dual problem (Dε)  using
expansions of the dual variables in two reproducing kernel Hilbert spaces (RKHS). Choosing dual
variables (or test functions) in a RKHS is the fundamental assumption underlying the Maximum
Mean Discrepancy (MMD)[22]. It is thus tempting to draw parallels between the approach in this
section and the MMD. The two methods do not  however  share much beyond using RKHSs. Indeed 
unlike the MMD  problem (Dε) involves two different dual (test) functions u and v  one for each
. Recall ﬁnally that contrarily to the
measure; these are furthermore linked through a regularizer ιε
semi-discrete setting  we can only solve the regularized problem here (i.e. ε > 0)  since (Dε) cannot
Uc
be cast as an expectation maximization problem when ε = 0.
Stochastic Continuous Optimization. We consider two RKHS H and G deﬁned on X and on Y 
with kernels κ and (cid:96)  associated with norms (cid:107) · (cid:107)H and (cid:107) · (cid:107)G. Recall the two main properties of
RKHS: (a) if u ∈ H  then u(x) = (cid:104)u  κ(·  x)(cid:105)H and (b) κ(x  x(cid:48)) = (cid:104)κ(·  x)  κ(·  x(cid:48))(cid:105)H.
The dual problem (Dε) is conveniently re-written in (3) as the maximization of the expectation of
f ε(X  Y  u  v) with respect to the random variables (X  Y ) ∼ µ ⊗ ν. The SGD algorithm applied to
this problem reads  starting with u0 = 0 and v0 = 0 

(uk  vk) def.= (uk−1  vk−1) +

(5)
where (xk  yk) are i.i.d. samples from µ ⊗ ν. The following proposition shows that these (uk  vk)
iterates can be expressed as ﬁnite sums of kernel functions  with a simple recursion formula.
Proposition 5.1. The iterates (uk  vk) deﬁned in (5) satisfy

∇fε(xk  yk  uk−1  vk−1) ∈ H × G 

C√
k

i=1

αi(κ(·  xi)  (cid:96)(·  yi))  where αi

(uk  vk) def.=
(6)
where (xi  yi)i=1...k are i.i.d samples from µ ⊗ ν and ΠBr is the projection on the centered ball of
radius r. If the solutions of (Dε) are in the H × G and if r is large enough  the iterates (uk vk)
converge to a solution of (Dε).
The proof of proposition 5.1 can be found in the supplementary material.

ui−1(xi)+vi−1(yi)−c(xi yi)

def.= ΠBr

1 − e

i

ε

(cid:17)(cid:19)

 

k(cid:88)

(cid:18) C√

(cid:16)

7

(a) setting

(b) convergence of uk

(c) plots of uk

dx. (b) Plot of (cid:107)uk − ˆu(cid:63)(cid:107)2 /(cid:107)ˆu(cid:63)(cid:107)2 as a function of k with SGD in the
Figure 3: (a) Plot of dµ
RKHS  for regularized OT using ε = 10−1. (c) Plot of the iterates uk for k = 103  104  105 and the
proxy for the true potential ˆu(cid:63)  evaluated on a grid where µ has non negligible mass.

dx and dν

(cid:17)

(cid:82)

(cid:16)

1 − e

uk−1(xk )+vk−1(yk )−c(xk  yk )

ε

for k = 1  2  . . . do

def.= C√
k

αk
end for

i=1 αiκ(xk  xi)
i=1 αi(cid:96)(yk  yi)

Sample xk from µ
Sample yk from ν

uk−1(xk) def.=(cid:80)k−1
vk−1(yk) def.=(cid:80)k−1

Algorithm 3 Kernel SGD for continuous OT
Input: C  kernels κ and (cid:96)
Output: (αk  xk  yk)k=1 ...

Algorithm 3 describes our kernel SGD approach 
in which both potentials u and v are approxi-
mated by a linear combination of kernel func-
tions. The main cost lies in the computation of
the terms uk−1(xk) and vk−1(yk) which imply
a quadratic complexity O(k2). Several methods
exist to alleviate the running time complexity
of kernel algorithms  e.g. random Fourier fea-
tures [16] or incremental incomplete Cholesky
decomposition [25].
Kernels that are associated with dense RHKS
are called universal [23] and can approach any arbitrary potential. In Euclidean spaces X = Y = Rd 
where d > 0  a natural choice of universal kernel is the kernel deﬁned by κ(x  x(cid:48)) = exp(−(cid:107)x −
x(cid:48)(cid:107)2/σ2). Tuning its bandwidth σ is crucial to obtain a good convergence of the algorithm.
Finally  let us note that  while entropy regularization of the primal problem (Pε) was instrumental
to be able to apply semi-discrete methods in Sections 3 and 4  this is not the case here. Indeed 
since the kernel SGD algorithm is applied to the dual (Dε)  it is possible to replace KL(π|µ ⊗ ν)
appearing in (Pε) by other regularizing divergences. A typical example would be a χ2 divergence
X×Y ( dπ
Numerical Illustrations. We consider optimal transport in 1D between a Gaussian µ and a Gaussian
mixture ν whose densities are represented in Figure 3 (a). Since there is no existing benchmark for
continuous transport  we use the solution of the semi-discrete problem Wε(µ  ˆνN ) with N = 103
computed with SGD as a proxy for the solution and we denote it by ˆu(cid:63). We focus on the convergence
of the potential u  as it is continuous in both problems contrarily to v. Figure 3 (b) represents the plot
of (cid:107)uk − ˆu(cid:63)(cid:107)2/(cid:107)ˆu(cid:63)(cid:107)2 where u is the evaluation of u on a sample (xi)i=1...N(cid:48) drawn from µ. This
gives more emphasis to the norm on points where µ has more mass. The convergence is rather slow
but still noticeable. The iterates uk are plotted on a grid for different values of k in Figure 3 (c)  to
emphasize the convergence to the proxy ˆu(cid:63). We can see that the iterates computed with the RKHS
converge faster where µ has more mass  which is actually where the value of u has the greatest impact
in Fε (u being integrated against µ).
Conclusion
We have shown in this work that the computations behind (regularized) optimal transport can be
considerably alleviated  or simply enabled  using a stochastic optimization approach. In the discrete
case  we have shown that incremental gradient methods can surpass the Sinkhorn algorithm in
terms of efﬁciency  taken for granted that the (constant) stepsize has been correctly selected  which
should be possible in practical applications. We have also proposed the ﬁrst known methods that can
address the challenging semi-discrete and continuous cases. All of these three settings can open new
perspectives for the application of OT to high-dimensional problems.

dµdν (x  y))2dµ(x)dν(y) (with positivity constraints on π).

Acknowledgements GP was supported by the European Research Council (ERC SIGMA-Vision); AG by
Région Ile-de-France; MC by JSPS grant 26700002.

8

References
[1] F. Aurenhammer  F. Hoffmann  and B. Aronov. Minkowski-type theorems and least-squares clustering.

Algorithmica  20(1):61–76  1998.

[2] F. Bassetti  A. Bodini  and E. Regazzini. On minimum Kantorovich distance estimators. Statistics &

Probability Letters  76(12):1298–1302  2006.

[3] R. Burkard  M. Dell’Amico  and S. Martello. Assignment Problems. SIAM  2009.
[4] G. Carlier  V. Duval  G. Peyré  and B. Schmitzer. Convergence of entropic schemes for optimal transport

and gradient ﬂows. arXiv preprint arXiv:1512.02783  2015.

[5] R. Cominetti and J. San Martin. Asymptotic analysis of the exponential penalty trajectory in linear

programming. Mathematical Programming  67(1-3):169–187  1994.

[6] M. Cuturi. Sinkhorn distances: Lightspeed computation of optimal transport. In Adv. in Neural Information

Processing Systems  pages 2292–2300  2013.

[7] A. Dieuleveut and F. Bach. Non-parametric stochastic approximation with large step sizes. arXiv preprint

arXiv:1408.0361  2014.

[8] J. Franklin and J. Lorenz. On the scaling of multidimensional matrices. Linear Algebra and its applications 

114:717–735  1989.

[9] C. Frogner  C. Zhang  H. Mobahi  M. Araya  and T. Poggio. Learning with a Wasserstein loss. In Adv. in

Neural Information Processing Systems  pages 2044–2052  2015.

[10] L. Kantorovich. On the transfer of masses (in russian). Doklady Akademii Nauk  37(2):227–229  1942.
[11] M. J. Kusner  Y. Sun  N. I. Kolkin  and K. Q. Weinberger. From word embeddings to document distances.

In ICML  2015.

[12] Q. Mérigot. A multiscale approach to optimal transport. Comput. Graph. Forum  30(5):1583–1592  2011.
[13] G. Montavon  K.-R. Müller  and M. Cuturi. Wasserstein training of restricted Boltzmann machines. In Adv.

in Neural Information Processing Systems  2016.

[14] J. Pennington  R. Socher  and C.D. Manning. Glove: Global vectors for word representation. Proc. of the

Empirical Methods in Natural Language Processing (EMNLP 2014)  12:1532–1543  2014.

[15] B. T Polyak and A. B Juditsky. Acceleration of stochastic approximation by averaging. SIAM Journal on

Control and Optimization  30(4):838–855  1992.

[16] A. Rahimi and B. Recht. Random features for large-scale kernel machines. In Adv. in Neural Information

Processing Systems  pages 1177–1184  2007.

[17] Y. Rubner  C. Tomasi  and L. J. Guibas. The earth mover’s distance as a metric for image retrieval. IJCV 

40(2):99–121  November 2000.

[18] F. Santambrogio. Optimal transport for applied mathematicians. Birkäuser  NY  2015.
[19] M. Schmidt  N. Le Roux  and F. Bach. Minimizing ﬁnite sums with the stochastic average gradient.

Mathematical Programming  2016.

[20] R. Sinkhorn. A relationship between arbitrary positive matrices and doubly stochastic matrices. Ann. Math.

Statist.  35:876–879  1964.

[21] J. Solomon  F. de Goes  G. Peyré  M. Cuturi  A. Butscher  A. Nguyen  T. Du  and L. Guibas. Convolutional
Wasserstein distances: Efﬁcient optimal transportation on geometric domains. ACM Transactions on
Graphics (SIGGRAPH)  34(4):66:1–66:11  2015.

[22] Bharath K Sriperumbudur  Kenji Fukumizu  Arthur Gretton  Bernhard Schölkopf  Gert RG Lanckriet  et al.
On the empirical estimation of integral probability metrics. Electronic Journal of Statistics  6:1550–1599 
2012.

[23] I. Steinwart and A. Christmann. Support vector machines. Springer Science & Business Media  2008.
[24] C. Villani. Topics in Optimal Transportation. Graduate studies in Math. AMS  2003.
[25] G. Wu  E. Chang  Y. K. Chen  and C. Hughes. Incremental approximate matrix factorization for speeding
up support vector machines. In Proc. of the 12th ACM SIGKDD Intern. Conf. on Knowledge Discovery
and Data Mining  pages 760–766  2006.

9

,Tuo Zhao
Mo Yu
Yiming Wang
Raman Arora
Han Liu
Aude Genevay
Marco Cuturi
Gabriel Peyré
Francis Bach