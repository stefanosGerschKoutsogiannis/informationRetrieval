2009,Heterogeneous multitask learning with joint sparsity constraints,Multitask learning addressed the problem of learning related tasks whose information can be shared each other. Traditional problem usually deal with homogeneous tasks such as regression  classification individually. In this paper we consider the problem learning multiple related tasks where tasks consist of both continuous and discrete outputs from a common set of input variables that lie in a high-dimensional space. All of the tasks are related in the sense that they share the same set of relevant input variables  but the amount of influence of each input on different outputs may vary. We formulate this problem as a combination of linear regression and logistic regression and model the joint sparsity as L1/Linf and L1/L2-norm of the model parameters. Among several possible applications  our approach addresses an important open problem in genetic association mapping  where we are interested in discovering genetic markers that influence multiple correlated traits jointly. In our experiments  we demonstrate our method in the scenario of association mapping  using simulated and asthma data  and show that the algorithm can effectively recover the relevant inputs with respect to all of the tasks.,Heterogeneous Multitask Learning with Joint

Sparsity Constraints

Xiaolin Yang

Department of Statistics

Carnegie Mellon University

Pittsburgh  PA 15213

Seyoung Kim

Eric P. Xing

Machine Learning Department
Carnegie Mellon University

Machine Learning Department
Carnegie Mellon University

Pittsburgh  PA 15213

Pittsburgh  PA 15213

xyang@stat.cmu.edu

sssykim@cs.cmu.edu

epxing@cs.cmu.edu

Abstract

Multitask learning addresses the problem of learning related tasks that presum-
ably share some commonalities on their input-output mapping functions. Previ-
ous approaches to multitask learning usually deal with homogeneous tasks  such
as purely regression tasks  or entirely classiﬁcation tasks. In this paper  we con-
sider the problem of learning multiple related tasks of predicting both continu-
ous and discrete outputs from a common set of input variables that lie in a high-
dimensional feature space. All of the tasks are related in the sense that they share
the same set of relevant input variables  but the amount of inﬂuence of each input
on different outputs may vary. We formulate this problem as a combination of lin-
ear regressions and logistic regressions  and model the joint sparsity as L1/L∞ or
L1/L2 norm of the model parameters. Among several possible applications  our
approach addresses an important open problem in genetic association mapping 
where the goal is to discover genetic markers that inﬂuence multiple correlated
traits jointly. In our experiments  we demonstrate our method in this setting  using
simulated and clinical asthma datasets  and we show that our method can effec-
tively recover the relevant inputs with respect to all of the tasks.

1 Introduction

In multitask learning  one is interested in learning a set of related models for predicting multiple
(possibly) related outputs (i.e.  tasks) given a set of input variables [4]. In many applications  the
multiple tasks share a common input space  but have different functional mappings to different
output variables corresponding to different tasks. When the tasks and their corresponding models
are believed to be related  it is desirable to learn all of the models jointly rather than treating each
task as independent of each other and ﬁtting each model separately. Such a learning strategy that
allows us to borrow information across tasks can potentially increase the predictive power of the
learned models.
Depending on the type of information shared among the tasks  a number of different algorithms have
been proposed. For example  hierarchical Bayesian models have been applied when the parameter
values themselves are thought to be similar across tasks [2  14]. A probabilistic method for modeling
the latent structure shared across multiple tasks has been proposed [16]. For problems of which the
input lies in a high-dimensional space and the goal is to recover the shared sparsity structure across
tasks  a regularized regression method has been proposed [10].
In this paper  we consider an interesting and not uncommon scenario of multitask learning  where
the tasks are heterogeneous and bear a union support. That is  each task can be either a regression
or classiﬁcation problem  with the inputs lying in a very high-dimensional feature space  but only a
small number of the input variables (i.e.  predictors) are relevant to each of the output variables (i.e. 

1

responses). Furthermore  we assume that all of the related tasks possibly share common relevant
predictors  but with varying amount of inﬂuence on each task.
Previous approaches for multitask learning usually consider a set of homogeneous tasks  such as re-
gressions only  or classiﬁcations only. When each of these discrete or continuous prediction tasks is
treated separately  given a high-dimensional design  the lasso method that penalizes the loss function
with an L1 norm of the parameters has been a popular approach for variable selection [13  11]  since
the L1 regularization has the property of shrinking parameters corresponding to irrelevant predictors
exactly to zero. One of the successful extensions of the standard lasso is the group lasso that uses an
L1/L2 penalty deﬁned over predictor groups [15]  instead of just the L1 penalty ubiquitously over
all predictors. Recently  a more general L1/Lq-regularized regression scheme with q > 0 has been
thoroughly investigated [17]. When the L1/Lq penalty is used in estimating the regression function
for a single predictive task  it makes use of information about the grouping of input variables  and
applies the L1 penalty over the Lq norm of the regression coefﬁcients for each group of inputs. As
a result  variable selection can be effectively achieved on each group rather than on each individual
input variable. This type of regularization scheme can be also used against the output variables in
a single classiﬁcation task with multi-way (rather than binary) prediction  where the output is ex-
panded from univariate to multivariate with dummy variables for each prediction category. In this
situation the group lasso can promote selecting the same set of relevant predictors across all of the
dummy variables (which is desirable since these dummy variables indeed correspond to only a sin-
gle multi-way output). In our multitask learning problem  when the L1/L2 penalty of group lasso is
used for multitask regression [9  10  1]  the L2 norm is applied to the regression coefﬁcients for each
input across all tasks  and the L1 norm is applied to these L2 norms  playing the role of selecting
common input variables relevant to one or more tasks via a sparse union support recovery. Since the
parameter estimation problem formulated with such penalty terms has a convex objective function 
many of the algorithms developed for a general convex optimization problem can be used for solving
the learning problem. For example  an interior point method and a preconditioned conjugate gra-
dient algorithm have been used to solve a large-scale L1-regularized linear regression and logistic
regression [8]. In [6  13]  a coordinate-descent method was used in solving an L1-regularized linear
regression and generalized linear models  where the soft thresholding operator gives a closed-form
solution for each coordinate in each iteration.
In this paper  we consider the more challenging  but realistic scenario of having heterogenous out-
puts  i.e.  both continuous and discrete responses  in multitask learning. This means that the tasks
in question consist of both regression and classiﬁcation problems. Assuming a linear regression for
continuous-valued output and a logistic regression for discrete-valued output with dummy variables
for multiple categories  an L1/Lq penalty can be used to learn both types of tasks jointly for a sparse
union support recovery. Since the L1/Lq penalty selects the same relevant inputs for all dummy out-
puts for each classiﬁcation task  the desired consistency in chosen relevant inputs across the dummy
variables corresponding to the same multi-way response is automatically maintained. We consider
particular cases of L1/Lq regularizations with q = 2 and q = ∞.
Our work is primarily motivated by the problem of genetic association mapping based on genome-
wide genotype data of single nucleotide polymorphisms (SNPs)  and phenotype data such as disease
status  clinical traits  and microarray data collected over a large number of individuals. The goal in
this study is to identify the SNPs (or inputs) that explain the variation in the phenotypes (or outputs) 
while reducing false positives in the presence of a large number of irrelevant SNPs from the genome-
scale data. Since many clinical traits for a given disease are highly correlated  it is greatly beneﬁcial
to combine information across multiple such related phenotypes because the inputs often involve
millions of SNPs and the association signals of causal (or relevant) SNPs tend to be very weak
when computed individually. However  statistically signiﬁcant patterns can emerge when the joint
associations to multiple related traits are estimated properly. Over the recent years  researchers
started recognizing the importance of the joint analysis of multiple correlated phenotypes [5  18] 
but there has been a lack of statistical tools to systematically perform such analysis. In our previous
work [7]  we developed a regularized regression method  called a graph-guided fused lasso  for
multitask regression problem that takes advantage of the graph structure over tasks to encourage a
selection of common inputs across highly correlated traits in the graph. However  this method can
only be applied to the restricted case of correlated continuous-valued outputs. In reality  the set of
clinical traits related to a disease often contains both continuous- and discrete-valued traits. As we

2

demonstrate in our experiments  the L1/Lq regularization for the joint regression and classiﬁcation
can successfully handle this situation.
The paper is organized as follows. In Section 2  we introduce the notation and the basic formulation
for joint regression-classiﬁcation problem  and describe the L1/L∞ and L1/L2 regularized regres-
sions for heterogeneous multitask learning in this setting. In Section 3  we formulate the parameter
estimation as a convex optimization problem  and present an interior-point method for solving it.
Section 4 presents experimental results on simulated and asthma datasets. In Section 5  we conclude
with a brief discussion of future work.

2 Joint Multitask Learning of Linear Regressions and Multinomial Logistic

Regressions

Suppose that we have K tasks of learning a predictive model for the output variable  given a common
set of P input variables. In our joint regression-classiﬁcation setting  we assume that the K tasks
consist of Kr tasks with continuous-valued outputs and Kc tasks with discrete-valued outputs of an
arbitrary number of categories.
For each of the Kr regression problems  we assume a linear relationship between the input vector
X of size P and the kth output Yk as follows:
k0 + Xβ(r)

Yk = β(r)
kP )(cid:48) represents a vector of P regression coefﬁcients for the kth regression
k0 represents the

where β(r)
task  with the superscript (r) indicating that this is a parameter for regression; β(r)
intercept; and  denotes the residual.
Let yk = (yk1  . . .   ykN )(cid:48) represent the vector of observations for the kth output over N samples;
and X represent an N × P matrix X = (x1  . . .   xN )(cid:48) of the input shared across all of the K tasks 
where xi = (xi1  . . .   xiP )(cid:48) denotes the ith sample. Given these data  we can estimate the β(r)
k ’s by
minimizing the sum of squared error:

k1   . . .   β(r)

k = 1  ...  Kr 

k = (β(r)

k +  

Lr =

(yk − 1β(r)

k0 − Xβ(r)

k )(cid:48) · (yk − 1β(r)

k0 − Xβ(r)
k ) 

(1)

Kr(cid:88)

k=1

where 1 is an N-vector of 1’s.
For the tasks with discrete-valued output  we set up a multinomial (i.e.  softmax) logistic regression
for each of the Kc tasks  assuming that the kth task has Mk categories:

P (Yk = m|X = x) =

1 +
P (Yk = Mk|X = x) =

exp (β(c)

(cid:80)Mk−1
(cid:80)Mk−1

l=1

k0 + xβ(c)
km)
exp (β(c)

k0 + xβ(c)
kl )
1

 

for m = 1  . . .   Mk − 1 

 

l=1

exp (β(c)

k0 + xβ(c)
kl )

km = (β(c)

km1  . . .   β(c)

1 +
kmP )(cid:48)  m = 1  . . .   (Mk − 1)  is the parameter vector for the mth

where β(c)
category of the kth classiﬁcation task  and β(c)
Assuming that the measurements for the Kc output variables are collected for the same set of N
samples as in the regression tasks  we expand each output data yki for the kth task of the ith sample
into a set of Mk binary variables y(cid:48)
ki = (yk1i  . . .   ykMki)  where each ykmi  m = 1  . . .   Mk  takes
value 1 if the ith sample for the kth classiﬁcation task belongs to the mth category and value 0 oth-
m ykmi = 1. Using the observations for the output variable in this representation
erwise  and thus
and the shared input data X  one can estimate the parameters β(c)
km’s by minimizing the negative
log-likelihood given as below:

k0 is the intercept.

P(cid:88)

(cid:179)

Mk−1(cid:88)

P(cid:88)

(cid:80)
(cid:195)
Mk−1(cid:88)

Lc = − N(cid:88)

Kc(cid:88)

(2)

(cid:180)(cid:33)

ykmi(β(c)

k0 +

xijβ(c)

kmj) − log

1 +

exp (β(c)

k0 +

xijβ(c)

kmj)

.

(3)

i=1

k=1

m=1

j=1

m=1

j=1

3

In this joint regression-classiﬁcation problem  we form a global objective function by combining the
two empirical loss functions in Equations (1) and (3):
L = Lr + Lc.

(4)

This is equivalent to estimating the β(r)
km’s independently for each of the K tasks  assum-
ing that there are no shared patterns in the way that each of the K output variables is dependent
on the input variables. Our goal is to increase the performance of variable selection and prediction
power by allowing the sharing of information among the heterogeneous tasks.

k ’s and β(c)

3 Heterogeneous Multitask Learning with Joint Sparse Feature Selection

In real-world applications  often the covariates lie in a very high-dimensional space with only a
small fraction of them being involved in determining the output  and the goal is to recover the
sparse structure in the predictive model by selecting the true relevant covariates. For example  in
a genetic association mapping  often millions of genetic markers over a population of individuals
are examined to ﬁnd associations with the given phenotype such as clinical traits  disease status 
or molecular phenotypes. The challenge in this type of study is to locate the true causal SNPs that
inﬂuence the phenotype. We consider the case where the related tasks share the same sparsity pattern
such that they have a common set of relevant input variables for both the regression and classiﬁcation
tasks and the amount of inﬂuence of the relevant input variables on the output may vary across the
tasks. We introduce an L1/Lq regularization to the problem of the heterogeneous multitask learning
in Equation (4) as below:

L = Lr + Lc + λPq 

(5)
where Pq is the group penalty to the sum of linear regression loss and logistic loss  and λ is a
regularization parameter which determines the sparsity level and could be chosen by cross validation.
We consider two extreme cases of the L1/Lq penalty for group variable selection in our problem
which are L∞ norm and L2 norm across different tasks in one dimension.

(cid:180)

kj |  |β(c)
|β(r)
kmj|

or P2 =

|β(r)

j

  β(c)

j

|L2

 

(6)

(cid:181) P(cid:88)

(cid:179)

P∞ =

max
k m

j=1

(cid:180)(cid:182)

(cid:181) P(cid:88)

j=1

  β(c)

j

j

kj ’s and β(c)

where β(r)
are vector of parameters over all regression and classiﬁcation tasks  respectively 
for the jth dimension. Here  the L∞ and L2 norms over the parameters across different tasks can
regulate the joint sparsity among tasks. The L1/L∞ and L1/L2 norms encourage group sparsity
in a similar way in that the β(r)
kmj’s are set to 0 simultaneously for all of the tasks for
dimension j if the L∞ or L2 norm for that dimension is set to be 0. Similarly  if the L1 operator
selects a non-zero value for the L∞ or L2 norm of the β(r)
kmj’s for the jth input  the
same input is considered as relevant possibly to all of the tasks  and the β(r)
kmj’s can
have any non-zero values smaller than the maximum or satisfying the L2-norm constraints. The
L1/L∞ penalty tends to encourage the parameter values to be the same across all tasks for a given
input [17]  whereas under L1/L2 penalty the values of the parameters across tasks tend to be more
different for a given input than in the L1/L∞ penalty.

kj ’s and β(c)

kj ’s and β(c)

4 Optimization Method

Different methods such as gradient descent  steepest descent  Newton’s method and Quasi-Newton
method can be used to solve the problem in Equation (5). Although second-order methods have a
fast convergence near the global minimum of the convex objective functions  they involve comput-
ing a Hessian matrix and inverting it  which can be infeasible in a high-dimensional setting. The
coordinate-descent method iteratively updates each element of the parameter vector one at a time 
using a closed-form update equation given all of the other elements. However  since it is a ﬁrst-order
method  the speed of convergence becomes slow as the number of tasks and dimension increase. In
[8]  the truncated Newton’s method that uses a preconditionor and solves the linear system instead of
inverting the Hessian matrix has been proposed as a fast optimization method for a very large-scale

4

problem. The linear regression loss and logistic regression loss have different forms. The interior
method optimizes their original loss function without any transformation so that it is more intuitive
to see how the two heterogeneous tasks affect each other.
In this section  we discuss the case of the L1/L∞ penalty since the same optimization method can be
easily extended to handle the L1/L2 penalty. First  we re-write the problem of minimizing Equation
(5) with the nondifferentiable L1/L∞ penalty as

P(cid:88)

j=1

minimize Lr + Lc + λ

uj

(cid:180)

(cid:179)

subject to max
k m

|β(r)
kj |  |β(c)
kmj|

< uj  for j = 1  . . .   P  k = 1  . . .   Kr + Kc.

Further re-writing the constraints in the above problem  we obtain 2·P · (Kr +
inequality constraints as follows:

−uj < β(r)
−uj < β(c)

kj < uj 

kmj < uj 

for

for

k = 1  . . .   Kr  j = 1  . . .   P 
k = 1  . . .   Kc  j = 1  . . .   P  m = 1  . . .   Mk − 1.

(cid:80)Kc

(7)
k=1(Mk − 1))

Using the barrier method [3]  we re-formulate the objective function in Equation (7) into an uncon-
strained problem given as

LBarrier = Lr + Lc + λ

uj +

I−(−β(c)

kj − uj) + I−(β(c)

(cid:180)
kj − uj)

where

k=1

I−(−β(c)

kmj − uj) + I−(β(c)

kmj − uj) 

P(cid:88)
Kc(cid:88)

j=1

+

(cid:179)

P(cid:88)
P(cid:88)

j=1

j=1

k=1

Kr(cid:88)
Mk−1(cid:88)
(cid:189)

m=1

I−(x) =

0 x ≤ 0
∞ x > 0 .

Then  we apply the log barrier function I−(f(x)) = −(1/t) log(−f(x))  where t is an additional
parameter that determines the accuracy of the approximation.

k ’s and β(c)

km’s. Given a strictly feasible Θ  t = t(0) > 0 

Let Θ denote the set of parameters β(r)
µ > 1  and tolerance  > 0  we iterate the following steps until convergence.
Step 1 Compute Θ∗(t) by minimizing LBarrier  starting at Θ.
Step 2 Update: Θ := Θ∗(t)
Step 3 Stopping criterion: quit if m/t <  where m is the number of constraint functions.
Step 4 Increase t: t := tµ
In Step 1  we use the Newton’s method to minimize LBarrier at t.
In each iteration  we in-
crease t in Step 4  so that we have a more accurate approximation of I−(u) through I−(f(x)) =
−(1/t) log(−f(x)).
In Step 1  we ﬁnd the direction towards the optimal solution using Newton’s method:

(cid:34)

(cid:35)

H

∆β
∆u

= −g 

where ∆β and ∆u are the searching directions of the model parameters and bounding parameters.
The g in the above equation is the gradient vector given as g = [g(r)  g(c)  g(u)]T   where g(r) has
Kr components for regression tasks  g(c) has Kc × (Mk − 1) components for classiﬁcation tasks 
and H is the Hessian matrix given as:

  

 R

0

H =

0

D(r)

L D(c)

D(r) D(c)

F

5

(a)

(b)

(c)

(d)

Figure 1: The regularization path for L1/L∞-regularized methods. (a) Regression parameters esti-
mated from the heterogeneous task learning method  (b) regression parameters estimated from re-
gression tasks only  (c) logistic-regression parameters estimated from the heterogeneous task learn-
ing method  and (d) logistic-regression parameters estimated from classiﬁcation tasks only. Blue
curves: irrelevant inputs; Red curves: relevant inputs.

where R and L are second derivatives of the parameters β for regression tasks in the form of R =
∇2Lr + ∇2Pg|∂β(r)∂β(r)  L = ∇2Lc + ∇2Pg|∂β(c)∂β(c)  D = ∇2Pg|∂β∂u and F = D(r) + D(c).
In the overall interior-point method  the process of constructing and inverting Hessian matrix is the
most time-consuming part. In order to make the algorithm scalable to a large problem  we use a
preconditionor diag(H) of the Hessian matrix H  and apply the preconditioned conjugate-gradient
algorithm to compute the searching direction.

5 Experiments

We demonstrate our methods for heterogeneous multitask learning with L1/L∞ and L1/L2 regular-
izations on simulated and asthma datasets  and compare their performances with those from solving
two types of multitask-learning problems for regressions and classiﬁcations separately.

5.1 Simulation Study

k ’s and β(c)

In the context of genetic association analysis  we simulate the input and output data with known
model parameters as follows. We start from the 120 haplotypes of chromosome 7 from the popu-
lation of European ancestry in HapMap data [12]  and randomly mate the haplotypes to generate
genotype data for 500 individuals. We randomly select 50 SNPs across the chromosome as inputs.
In order to simulate the parameters β(r)
km’s  we assume six regression tasks and a single
classiﬁcation task with ﬁve categories  and choose ﬁve common SNPs from the total of 50 SNPs as
relevant covariates across all of the tasks. We ﬁll the non-zero entries in the regression coefﬁcients
k ’s with values uniformly distributed in the interval [a  b] with 5 ≤ a  b ≤ 10  and the non-zero
β(r)
entries in the logistic-regression parameters β(c)
km’s such that the ﬁve categories are separated in the
output space. Given these inputs and the model parameters  we generate the output values  using
the noise for regression tasks distributed as N(0  σ2
sim). In the classiﬁcation task  we expand the
single output into ﬁve dummy variables representing different categories that take values of 0 or 1
depending on which category each sample belongs to. We repeat this whole process of simulating
inputs and outputs to obtain 50 datasets  and report the results averaged over these datasets.
The regularization paths of the different multitask-learning methods with an L1/L∞ regularization
obtained from a single simulated dataset are shown in Figure 1. The results from learning all of the
tasks jointly are shown in Figures 1(a) and 1(c) for regression and classiﬁcation tasks  respectively 
whereas the results from learning the two sets of regression and classiﬁcation tasks separately are
shown in Figures 1(b) and 1(d). The red curves indicate the parameters for true relevant inputs  and
the blue curves for true irrelevant inputs. We ﬁnd that when learning both types of tasks jointly  the
parameters of the irrelevant inputs are more reliably set to zero along the regularization path than
learning the two types of tasks separately.
In order to evaluate the performance of the methods  we use two criteria of sensitivity/speciﬁcity
plotted as receiver operating characteristic (ROC) curves and prediction errors on test data. To obtain
ROC curves  we estimate the parameters  sort the input-output pairs according to the magnitude of
the estimated β(r)
kmj’s  and compare the sorted list with the list of input-output pairs with
true non-zero β(r)
kmj’s.

kj ’s and β(c)
kj ’s and β(c)

6

00.51−50510λ/max|λ|Parameters00.51−50510λ/max|λ|Parameters00.51−10−50510λ/max|λ|Parameters00.51−10−50510λ/max|λ|Parameters(a)

(b)

(c)

(d)

Figure 2: ROC curves for detecting true relevant input variables when the sample size N varies. (a)
Regression tasks with N = 100  (b) classiﬁcation tasks with N = 100  (c) regression tasks with
N = 200  and (d) classiﬁcation tasks with N = 200. Noise level N(0 1) was used. The joint
regression-classiﬁcation methods achieve nearly perfect accuracy  and their ROC curves are com-
pletely aligned with the axes.‘M’ indicates homogeneous multitask learning  and ‘HM’ heterogenous
multitask learning (This notation is the same for the following other ﬁgures).

(a)

(b)

(c)

(d)

Figure 3: Prediction errors when the sample size N varies. (a) Regression tasks with N=100  (b)
classiﬁcation tasks with N = 100  (c) regression tasks with N = 200  and (d) classiﬁcation tasks
with N = 200. Noise level N(0 1) was used.

We vary the sample size to N = 100 and 200  and show the ROC curves for detecting true relevant
inputs using different methods in Figure 2. We use σsim = 1 to generate noise in the regression
tasks. Results for the regression and classiﬁcation tasks with N = 100 are shown in Figure 2(a) and
(b) respectively  and similarly  the results with N = 200 in Figure 2(c) and (d). The results with
L1/L∞ penalty are shown with color blue and green to compare the homogeneous and heteroge-
neous methods. Red and yellow are results using the L1/L2 penalty. Although the performance of
learning the two types of tasks separately improves with a larger sample size  the joint estimation
performs signiﬁcantly better for both sample sizes. A similar trend can be seen in the prediction
errors for the same simulated datasets in Figure 3.
In order to see how different signal-to-noise ratios affect the performance  we vary the noise level
sim = 8  and plot the ROC curves averaged over 50 datasets with a sample size
to σ2
N = 300 in Figure 4. Our results show that for both of the signal-to-noise ratios  learning regression
and classiﬁcation tasks jointly improves the performance signiﬁcantly. The same observation can be
made from the prediction errors in Figure 5. We can see that the L1/L2 method tends to improve
the variable selection  but the tradeoff is that the prediction error will be high when the noise level
is low. While L1/L∞ has a good balance between the variable selection accuracy and prediction
error at a lower noise level  as the noise increases  the L1/L2 outperforms L1/L∞ in both variable
selection and prediction accuracy.

sim = 5 and σ2

(a)

(b)

(c)

(d)

Figure 4: ROC curves for detecting true relevant input variables when the noise level varies. (a)
Regression tasks with noise level N(0  5)  (b) classiﬁcation tasks with noise level N(0  5)  (c) re-
gression tasks with noise level N(0  8)  and (d) classiﬁcation tasks with noise level N(0  8). Sample
size N=300 was used.

7

00.20.40.60.8100.20.40.60.811−SpecificitySencitivity  M (L1/L∞)HM (L1/L∞)M (L1/L2)HM (L1/L2)00.20.40.60.8100.20.40.60.811−SpecificitySencitivity  M (L1/L∞)HM (L1/L∞)M (L1/L2)HM (L1/L2)00.20.40.60.8100.20.40.60.811−SpecificitySencitivity  M (L1/L∞)HM (L1/L∞)M (L1/L2)HM (L1/L2)00.20.40.60.8100.20.40.60.811−SpecificitySencitivity  M (L1/L∞)HM (L1/L∞)M (L1/L2)HM (L1/L2)Prediction error0100200300400500600700800       M      (L1/L∞)       HM     (L1/L∞)   M     (L1/L2)   HM    (L1/L2)Classification error00.050.10.150.20.250.30.350.4       M      (L1/L∞)       HM     (L1/L∞)   M     (L1/L2)   HM    (L1/L2)Prediction error0100200300400500600700800       M      (L1/L∞)       HM     (L1/L∞)   M     (L1/L2)   HM    (L1/L2)Classification error00.050.10.150.20.250.30.350.4       M      (L1/L∞)       HM     (L1/L∞)   M     (L1/L2)   HM    (L1/L2)00.20.40.60.8100.20.40.60.811−SpecificitySencitivity  M (L1/L∞)HM (L1/L∞)M (L1/L2)HM (L1/L2)00.20.40.60.8100.20.40.60.811−SpecificitySencitivity  M (L1/L∞)HM (L1/L∞)M (L1/L2)HM (L1/L2)00.20.40.60.8100.20.40.60.811−SpecificitySencitivity  M (L1/L∞)HM (L1/L∞)M (L1/L2)HM (L1/L2)00.20.40.60.8100.20.40.60.811−SpecificitySencitivity  M (L1/L∞)HM (L1/L∞)M (L1/L2)HM (L1/L2)(a)

(b)

(c)

(d)

Figure 5: Prediction errors when the noise level varies.
(a) Regression tasks with noise level
N(0  52)  (b) classiﬁcation tasks with noise level N(0  52)  (c) regression tasks with noise level
N(0  82)  and (d) classiﬁcation tasks with noise level N(0  82). Sample size N=300 was used.

(a)

(b)

Figure 6: Parameters estimated from the asthma dataset for discovery of causal SNPs for the cor-
related phenotypes. (a) Heterogeneous task learning method  and (b) separate analysis of multitask
regressions and multitask classiﬁcations. The rows represent tasks  and the columns represent SNPs.

5.2 Analysis of Asthma Dataset
We apply our method to the asthma dataset with 34 SNPs in the IL4R gene of chromosome 11
and ﬁve asthma-related clinical traits collected over 613 patients. The set of traits includes four
continuous-valued traits related to lung physiology such as baseline predrug FEV1  maximum
FEV1  baseline predrug FVC  and maximum FVC as well as a single discrete-valued trait with ﬁve
categories. The goal of this analysis is to discover whether any of the SNPs (inputs) are inﬂuenc-
ing each of the asthma-related traits (outputs). We ﬁt the joint regression-classiﬁcation method with
L1/L∞ and L1/L2 regularizations  and compare the results from ﬁtting L1/L∞ and L1/L2 regular-
ized methods only for the regression tasks or only for the classiﬁcation task. We show the estimated
parameters for the joint learning with L1/L∞ penalty in Figure 6(a) and the separate learning with
L1/L∞ penalty in Figure 6(b)  where the ﬁrst four rows correspond to the four regression tasks 
the next four rows are parameters for the four dummy variables of the classiﬁcation task  and the
columns represent SNPs. We can see that the heterogeneous multitask-learning method encourages
to ﬁnd common causal SNPs for the multiclass classiﬁcation task and the regression tasks.

6 Conclusions

In this paper  we proposed a method for a recovery of union support in heterogeneous multitask
learning  where the set of tasks consists of both regressions and classiﬁcations. In our experiments
with simulated and asthma datasets  we demonstrated that using L1/L2 or L1/L∞ regularizations
in the joint regression-classiﬁcation problem improves the performance for identifying the input
variables that are commonly relevant to multiple tasks.
The sparse union support recovery as was presented in this paper is concerned with ﬁnding inputs
that inﬂuence at least one task. In the real-world problem of association mapping  there is a cluster-
ing structure such as co-regulated genes  and it would be interesting to discover SNPs that are causal
to at least one of the outputs within the subgroup rather than all of the outputs. In addition  SNPs in
a region of chromosome are often correlated with each other because of the non-random recombi-
nation process during inheritance  and this correlation structure  called linkage disequilibrium  has
been actively investigated. A promising future direction would be to model this complex correlation
pattern in both the input and output spaces within our framework.
Acknowledgments EPX is supported by grant NSF DBI-0640543  NSF DBI-0546594  NSF IIS-0713379 
NIH grant 1R01GM087694  and an Alfred P. Sloan Research Fellowship.

8

Prediction error2628303234363840       M      (L1/L∞)       HM     (L1/L∞)   M     (L1/L2)   HM    (L1/L2)Classification error00.050.10.150.20.250.30.350.4       M      (L1/L∞)       HM     (L1/L∞)   M     (L1/L2)   HM    (L1/L2)Prediction error646668707274767880       M      (L1/L∞)       HM     (L1/L∞)   M     (L1/L2)   HM    (L1/L2)Classification error00.050.10.150.20.250.30.350.4       M      (L1/L∞)       HM     (L1/L∞)   M     (L1/L2)   HM    (L1/L2)  102030246800.20.40.60.81  102030246800.20.40.60.81References
[1] A. Argyriou  T. Evgeniou  and M. Pontil. Convex multi-task feature learning. Machine Learning 

73(3):243–272  2008.

[2] B. Bakker and T. Heskes. Task clustering and gating for bayesian multitask learning. Journal of Machine

Learning Research  4:83–99  2003.

[3] S. Boyd and L. Vandenberghe. Convex Optimization. Cambridge University Press  2004.
[4] R. Caruana. Multitask learning. Machine Learning  28:41–75  1997.
[5] V. Emilsson  G. Thorleifsson  B. Zhang  A.S. Leonardson  F. Zink  J. Zhu  S. Carlson  A. Helgason  G.B.
Walters  S. Gunnarsdottir  et al. Variations in dna elucidate molecular networks that cause disease. Nature 
452(27):423–28  2008.

[6] J. Friedman  T. Hastie  and R. Tibshirani. Regularization paths for generalized linear models via coordi-

nate descent. Technical Report 703  Department of Statistics  Stanford University  2009.

[7] S. Kim and E. P. Xing. Statistical estimation of correlated genome associations to a quantitative trait

network. PLoS Genetics  5(8):e1000587  2009.

[8] K. Koh  S. Kim  and S. Boyd. An interior-point method for large-scale l1-regularized logistic regression.

Journal of Machine Learning Research  8(8):1519–1555  2007.

[9] G. Obozinski  B. Taskar  and M. Jordan. Joint covariate selection for grouped classiﬁcation. Technical

Report 743  Department of Statistics  University of California  Berkeley  2007.

[10] G. Obozinski  M.J. Wainwright  and M.J. Jordan. High-dimensional union support recovery in multivari-

ate regression. In Advances in Neural Information Processing Systems 21  2008.

[11] M. Schmidt  G. Fung  and R. Rosales. Fast optimization methods for l1 regularization: a comparative
study and two new approaches. In Proceedings of the European Conference on Machine Learning  2007.
[12] The International HapMap Consortium. A haplotype map of the human genome. Nature  437:1399–1320 

2005.

[13] R. Tibshirani. Regression shrinkage and selection via the lasso. Journal of Royal Statistical Society 

Series B  58(1):267–288  1996.

[14] K. Yu  V. Tresp  and A. Schwaighofer. Learning gaussian processes from multiple tasks. In Proceedings

of the 22nd International Conference on Machine Learning  2005.

[15] M. Yuan and Y. Lin. Model selection and estimation in regression with grouped variables. Journal of

Royal Statistical Society  Series B  68(1):49–67  2006.

[16] J. Zhang  Z. Ghahramani  and Y. Yang. Flexible latent variable models for multi-task learning. Machine

Learning  73(3):221–242  2008.

[17] P. Zhao  G. Rocha  and B. Yu. Grouped and hierarchical model selection through composite absolute

penalties. Technical Report 703  Department of Statistics  University of California  Berkeley  2008.

[18] J. Zhu  B. Zhang  E.N. Smith  B. Drees  R.B. Brem  L. Kruglyak  R.E. Bumgarner  and E.E. Schadt.
Integrating large-scale functional genomic data to dissect the complexity of yeast regulatory networks.
Nature Genetics  40:854–61  2008.

9

,Xiaoxiao Guo
Satinder Singh
Richard Lewis
Ryan Rogers
Aaron Roth
Jonathan Ullman
Salil Vadhan