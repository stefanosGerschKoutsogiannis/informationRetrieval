2019,Divide and Couple: Using Monte Carlo Variational Objectives for Posterior Approximation,Recent work in variational inference (VI) has used ideas from Monte Carlo estimation to obtain tighter lower bounds on the log-likelihood to be used as objectives for VI. However  there is not a systematic understanding of how optimizing different objectives relates to approximating the posterior distribution. Developing such a connection is important if the ideas are to be applied to inference—i.e.  applications that require an approximate posterior and not just an approximation of the log-likelihood. Given a VI objective defined by a Monte Carlo estimator of the likelihood  we use a "divide and couple" procedure to identify augmented proposal and target distributions so that the gap between the VI objective and the log-likelihood is equal to the divergence between these distributions. Thus  after maximizing the VI objective  the augmented variational distribution may be used to approximate the posterior distribution.,Divide and Couple: Using Monte Carlo Variational

Objectives for Posterior Approximation

Justin Domke1 and Daniel Sheldon1 2

1 College of Information and Computer Sciences  University of Massachusetts Amherst

2 Department of Computer Science  Mount Holyoke College

Abstract

Recent work in variational inference (VI) uses ideas from Monte Carlo estimation to
tighten the lower bounds on the log-likelihood that are used as objectives. However 
there is no systematic understanding of how optimizing different objectives relates
to approximating the posterior distribution. Developing such a connection is
important if the ideas are to be applied to inference—i.e.  applications that require
an approximate posterior and not just an approximation of the log-likelihood. Given
a VI objective deﬁned by a Monte Carlo estimator of the likelihood  we use a "divide
and couple" procedure to identify augmented proposal and target distributions. The
divergence between these is equal to the gap between the VI objective and the
log-likelihood. Thus  after maximizing the VI objective  the augmented variational
distribution may be used to approximate the posterior distribution.

1

Introduction

Variational inference (VI) is a leading approximate inference method in which a posterior distribution
p(z|x) is approximated by a simpler distribution q(z) from some approximating family. The procedure
to select q is based on the decomposition that [29]

The ﬁrst term is the evidence lower bound (ELBO) [4]. Selecting q to maximize the ELBO tightens
the lower bound on log p(x) and simultaneously minimizes the KL-divergence in the second term.
This dual view is important because minimizing the KL-divergence justiﬁes using q to approximate
the posterior for making predictions.
Recent work has investigated tighter objectives [6  20  18  17  23  25]  based on the following
principle: Let R be an estimator of the likelihood—i.e.  a nonnegative random variable with E R =
p(x). By Jensen’s inequality  log p(x)  E log R  so log R is a stochastic lower bound on the
log-likelihood. Parameters of the estimator can be optimized to tighten the bound. Standard VI is the
case when R = p(z  x)/q(z) and z ⇠ q  which is parameterized in terms of q. Importance-weighted
autoencoders [IWAEs; 6] essentially use R = 1
m=1 p(zm  x)/q(zm) where z1 . . . zM ⇠ q are
iid. Sequential Monte Carlo (SMC) also gives a variational objective [20  18  17]. The principle
underlying these works is that likelihood estimators that are more concentrated lead to tighter bounds 
because the gap in Jensen’s inequality is smaller. To date  the main application has been for learning
parameters of the generative model p.
Our key question is: what are the implications of modiﬁed variational objectives for probabilistic in-
ference? Eq. (1) relates the standard ELBO to KL[qkp]  which justiﬁes using q for posterior inference.
If we optimize a variational objective obtained from a different estimator  does this still correspond to
minimizing some KL-divergence? It has been shown [10  20  11] that maximizing the IWAE objective
corresponds to minimizing (an upper bound to) KL[qIS(z)kp(z|x)]  where qIS is a version of q that is
33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

MPM

log p(x) = E

(1)

q(z) log

p(z  x)

q(z)  + KL[q(z)kp(z|x)].

Figure 1: Left: Naive VI on the running example. Right: A tighter bound using antithetic sampling.

Figure 2: A kernel density approximation of Q(z)
for the antithetic estimator in Fig. 1.

"corrected" toward p using importance sam-
pling; this justiﬁes using qIS to approximate the
posterior. Naesseth et al. [20] also show that
performing VI with an SMC objective can be
seen as minimizing (an upper bound to) a di-
vergence from the SMC sampling distribution
qSMC(z) to p(z|x). For an arbitrary estimator 
however  there is little understanding.
We establish a deeper connection between variational objectives and approximating families. Given a
non-negative Monte Carlo (MC) estimator R such that E R = p(x)  we show how to ﬁnd a distribution
Q(z) such that the divergence between Q(z) and p(z|x) is at most the gap between E log R and
log p(x). Thus  better estimators mean better posterior approximations. The approximate posterior
Q(z) can be found by a two-step "divide and couple" procedure. The “divide” step follows Le et al.
[17] and connects maximizing E log R to minimizing a divergence between two distributions  but not
necessarily involving p(z|x). The “couple” step shows how to ﬁnd Q(z) such that the divergence is
an upper bound to KL [Q(z)kp(z|x)]. We show how a range of ideas from the statistical literature—
such as antithetic sampling  stratiﬁed sampling  and quasi Monte Carlo [24]—can produce novel
variational objectives; then  using the divide and couple framework  we describe efﬁcient-to-sample
approximate posteriors Q(z) for each of these objectives. We contribute mathematical tools for
deriving new estimators and approximating distributions within this framework. Experiments show
that the novel objectives enabled by this framework can lead to improved likelihood bounds and
posterior approximations.
There is a large body of work using MC techniques to reduce the variance of gradient estimators of
the standard variational objective [26  5  19  31  13]. The aims of this paper are different: we use MC
techniques to change R to get a tighter objective.

2 Setup and Motivation

Imagine we have some distribution p(z  x). After observing data x  we wish to approximate the
posterior p(z|x). Traditional VI tries to both bound log p(x) and approximate p(z|x) using the
“ELBO decomposition” of Eq. (1). We already observed that a similar lower bound can be obtained
from any non-negative random variable R with E R = p(x)  since by Jensen’s inequality 

log p(x)  E log R.

q(z)

2

Traditional VI can be seen as deﬁning R = p(z  x)/q(z) for z ⇠ q and then optimizing the parameters
of q to maximize E log R. Many other estimators R of p(x) can be designed and their parameters
optimized to make E log R as large as possible. We want to know: what relationship does this have
to approximating the posterior p(z|x)?
2.1 Example
Fig. 1 shows a one dimensional target distribution p(z  x) as a function of z  and the Gaussian q(z)
obtained by standard VI  i.e. maximizing E log R for R = p(z  x)/q(z). The resulting bound is
E log R ⇡ 0.237  while the true value is log p(x) = 0. By Eq. (1)  the KL-divergence from q(z) to
p(z|x) is 0.237. Tightening the likelihood bound has made q close to p.
A Gaussian cannot exactly represent the main mode of p(z  x)  since it is asymmetric. Antithetic
sampling [24] can exploit this. Deﬁne
◆   z ⇠ q 
1

2✓ p(z  x) + p(T (z)  x)

R0 =

(2)

2 p(z  x) for z in that region.

where T (z) = µ  (z  µ) is z “reﬂected” around the mean µ of q. This is a valid estimator since
q(z) is constant under reﬂection. Tightening this bound over Gaussians q gives E log R0 ⇡ 0.060.
This is better  intuitively  since the right half of q is a good match to the main mode of p  i.e. since
q(z) ⇡ 1
What about p(z|x)? It is not true that antithetic sampling gives a q(z) with lower divergence (it is
around 7.34). After all  naive VI already found the optimal Gaussian. Is there some other distribution
that is close to p(z|x)? How can we ﬁnd it? These questions motivate this paper.
2.2 Notation and Conventions
We use sans-serif font for random variables. All estimators R may depend on the input x  but we
suppress this for simplicity. Similarly  a(z|!) may depend on x. Proofs for all results are in the
supplement. Objects such as P MC  Q  p  q are distributions of random variables and will be written
like densities: Q(!)  p(z  x). However  the results are more general: the supplement includes a
more rigorous version of our main results using probability measures. We write densities with Dirac
delta functions. These are not Lebesgue-integrable  but can be interpreted unambiguosuly as Dirac
measures: e.g.  a(z|!) = (z  !) means the conditional distribution of z given ! = ! is the Dirac
measure !. Throughout  x is ﬁxed  so p(z  x) and P MC(!  z  x) are unnormalized distributions over
the other variables  and p(z|x) and P MC(!  z|x) are the corresponding normalized distributions.
3 The Divide-and-Couple Framework

In this section we identify a correspondence between maximizing a likelihood bound and pos-
terior inference for general non-negative estimators using a two step “divide” and then “couple”
construction.

3.1 Divide
Let R(!) be a positive function of ! ⇠ Q(!) such that EQ(!) R(!) = p(x)  i.e.  R is an unbiased
likelihood estimator with sampling distribution Q(!). The “divide” step follows [17  Claim 1]: we
can interpret EQ(!) log R(!) as an ELBO by deﬁning P MC so that R(!) = P MC(!  x)/Q(!). That
is  P MC and Q “divide” to produce R. Speciﬁcally:
Lemma 1. Let ! be a random variable with distribution Q(!) and let R(!) be a positive estimator
such that EQ(!) R(!) = p(x). Then

P MC(!  x) = Q(!)R(!)

is an unnormalized distribution over ! with normalization constant p(x) and R(!) =
P MC(!  x)/Q(!) for Q(!) > 0. Furthermore as deﬁned above 

While this shows that it is easy to connect a stochastic likelihood bound to minimizing a KL-
divergence  this construction alone is not useful for probabilistic inference  since neither Q(!)

nor P MC(!  x) make any reference to z. Put another way: Even if KL⇥Q(!)P MC(!|x)⇤ is

small  so what? This motivates the coupling step below. More generally  P MC is deﬁned by letting
R = dP MC/dQ be the Radon-Nikodym derivative  a change of measure from Q to P MC; see
supplement.

3.2 Couple
If the distributions identiﬁed in the above lemma are going to be useful for approximating p(z|x) 
they must be connected somehow to z. In this section  we suggest coupling P MC(!  x) and p(z  x)
into some new distribution P MC(!  z  x) with P MC(z  x) = p(z  x). In practice  it is convenient
to describe couplings via a conditional distribution a(z|!) that augments P MC(!  x). There is
a straightforward condition for when a is valid: for the augmented distribution P MC(z  !  x) =
P MC(!  x)a(z|!) to be a valid coupling  we require thatR P MC(!  x)a(z|!)d! = p(z  x). An

equivalent statement of this requirement is as follows.

3

log p(x) = E
Q(!)

log R(!) + KL⇥Q(!)P MC(!|x)⇤ .

(3)

Deﬁnition. An estimator R(!) and a distribution a(z|!) are a valid estimator-coupling pair under
distribution Q(!) if
(4)

E
Q(!)

R(!)a(z|!) = p(z  x).

The deﬁnition implies that EQ(!) R(!) = p(x) as may be seen by integrating out z from both sides.
That is  the deﬁnition implies that R is an unbiased estimator for p(x).
Now  suppose we have a valid estimator/coupling pair and that R is a good (low variance) estimator.
How does this help us to approximate the posterior p(z|x)? The following theorem gives the “divide
and couple” framework.1
Theorem 2. Suppose that R(!) and a(z|!) are a valid estimator-coupling pair under Q(!). Then 
(5)
(6)

Q(z  !) = Q(!)a(z|!) 

P MC(z  !  x) = Q(!)R(!)a(z|!) 

are valid distributions  P MC(z  x) = p(z  x)  and

log p(x) = E
Q(!)

log R(!) + KL [Q(z)kp(z|x)] + KL⇥Q(!|z)P MC(!|z  x)⇤ .

(7)

The ﬁnal term in Eq. (7) is a conditional divergence [9  Sec. 2.5]. This is the divergence over !
between Q(!|z) and P MC(!|z  x)  averaged over z drawn from Q(z). At a high level  this theorem
is proved by applying Lem. 1  using the chain rule of KL-divergence  and simplifying using the fact
that a is a valid coupling. The point of this theorem is: if R is a good estimator  then E log R will be
close to log p(x). Since KL-divergences are non-negative  this means that the marginal Q(z) must be
close to the target p(z|x). A coupling gives us a way to transform Q(!) so as to approximate p(z|x).
To be useful  we need to access Q(z)  usually by sampling. We assume it is possible to sample from
Q(!) since this is part of the estimator. The user must supply a routine to sample from a(z|!). This is
why the “trivial coupling” of a(z|!) = p(z|x) is not helpful — if the user could sample from p(z|x) 
the inference problem is already solved! Some estimators may be pre-equipped with a method to
approximate p(z|x). For example  in SMC  ! include particles zi and weights wi such that selecting
a particle in proportion to its weight approximates p(z|x). This can be seen as a coupling a(z|!) 
which provides an alternate interpretation of the divergence bounds of [20]. The divide and couple
framework is also closely related to extended-space MCMC methods [2]  which also use extended
target distributions that admit p(z  x) as a marginal; see also Sec. 6. However  in these methods  the
estimators also seem to come with “obvious” couplings. There is no systematic understanding of how
to derive couplings for general estimators.

3.3 Example
Consider again the antithetic estimator from Eq. (2). We saw before that the antithetic estimator gives
a tighter variational bound than naive VI under the distribution in Fig. 1. However  that distribution is
less similar to the target than the one from naive VI. To reﬂect this (and match our general notation)
we now2 write ! ⇠ Q (instead of z ⇠ q).
Now  we again ask: Since Q(!) is a poor approximation of the target  can we ﬁnd some other
distribution that is a good approximation? Consider the coupling distribution

a(z|!) = ⇡(!) (z  !) + (1  ⇡(!)) (z  T (!)) ⇡

(!) =

p(!  x)

p(!  x) + p(T (!)  x)

.

Intuitively  a(z|!) is supported only on z = ! and on z = T (!)  with probability proportional
to the target distribution. It is simple to verify (by substitution  see Claim 5 in supplement) that
R and a form a valid estimator-coupling pair. Thus  the augmented variational distribution is
Q(!  z) = Q(!)a(z|!). To sample from this  draw ! ⇠ Q and select z = ! with probability ⇡(!) 
or z = T (!) otherwise. The marginal Q(z) is shown in Fig. 2. This is a much better approximation
of the target than naive VI.
1With measures instead of densities would write Q(z 2 B  ! 2 A) =RA a(z 2 B|!)dQ(!) where a is a
where ! ⇠ Q. Here and in the rest of this
paper  when p(· ·) has two arguments  the ﬁrst always plays the role of z.

2With this notation  Eq. (2) becomes R = 1
2

Markov kernel; see supplement.

p(! x)+p(T (!) x)

Q(!)

4

Table 1: Variance reduction methods jointly transform estimators and couplings. Take an estimator
R0(!) with coupling a0(z|!)  valid under Q0(!). Each line shows a new estimator R(·) and coupling
a(z|·). The method to simulate Q(·) is described in the left column. Here  F 1 is a mapping so that
if ! is uniform on [0  1]d  then F 1(!) has density Q0(!).

1 ··· !1

Mn ⇠ Q0 restricted to ⌦m 

Description
IID Mean
!1 ··· !M ⇠ Q0 i.i.d.
Stratiﬁed Sampling
⌦1 ··· ⌦M partition ⌦ 
!m
µm = Q0(! 2 ⌦m).
Antithetic Sampling
! ⇠ Q0. For all m  Tm(!) d= !.
Randomized Quasi Monte Carlo
! ⇠ Unif([0  1]d)  ¯!1 ··· ¯!M ﬁxed 
Tm(!) = F 1 (¯!m + ! (mod 1))
Latin Hypercube Sampling
!1 ···   !M jointly sampled from Latin
hypercube [24  Ch. 10.3]  T = F 1.

m=1 R0(!m)a0(z|!m)

m=1 R0(!m)

m=1

a(z|·)

µm
Nm

R(·)
1
M

MXm=1
MXm=1
MXm=1
MXm=1
MXm=1

1
M

1
M

1
M

R0(!m)

R0 (!m

PM
n ) PM
NmXn=1
R0 (Tm(!)) PM
R0 (Tm(!)) PM
R0 (T (!m)) PM

µm

m=1

PM
NmPNm
PM
PM
PM
PM

n ) a0(z|!m
n )

n=1 R0 (!m
µm

NmPNm

n=1 R0 (!m
n )

m=1 R0(Tm(!)) a0 (z|Tm(!))

m=1 R(Tm(!))

m=1 R0(Tm(!)) a0 (z|Tm(!))

m=1 R0(Tm(!))

m=1 R0(T (!m)) a0 (z|T (!m))

m=1 R0(T (!m))

4 Deriving Couplings
Thm. 2 says that if EQ(!) log R(!) is close to log p(x) and you have a tractable coupling a(z|!) 
then drawing ! ⇠ Q(!) and then z ⇠ a(z|!) yields samples from a distribution Q(z) close to
p(z|x). But how can we ﬁnd a tractable coupling?
Monte Carlo estimators are often created recursively using techniques that take some valid estimator
R and transform it into a new valid estimator R0. These techniques (e.g. change of measure  Rao-
Blackwellization  stratiﬁed sampling) are intended to reduce variance. Part of the power of Monte
Carlo methods is that these techniques can be easily combined. In this section  we extend some of
these techniques to transform valid estimator-coupling pairs into new valid estimator-coupling pairs.
The hope is that the standard toolbox of variance reduction techniques can be applied as usual  and
the coupling is derived “automatically”.
Table 1 shows corresponding transformations of estimators and couplings for several standard variance
reduction techniques. In the rest of this section  we will give two abstract tools that can be used to
create all the entries in this table. For concreteness  we begin with a trivial “base” estimator-coupling
pair. Take a distribution Q0(!) and let R0(!) = p(!  x)/Q0(!) and a0(z|!) = (z  !) (the
deterministic coupling). It is easy to check that these satisfy Eq. (4).

4.1 Abstract Transformations of Estimators and Couplings
Our ﬁrst abstract tool transforms an estimator-coupling pair on some space ⌦ into another estimator-
coupling pair on a space ⌦M ⇥{ 1 ···   M}. This can be thought of as having M “replicates” of
the ! in the original estimator  along with an extra integer-valued variable that selects one of them.
We emphasize that this result does not (by itself) reduce variance — in fact  R has exactly the same
distribution as R0.
Theorem 3. Suppose that R0(!) and a0(z|!) are a valid estimator-coupling pair under Q0(!). Let
Q(!1 ···   wM   m) be any distribution such that if (!1 ···   !M   m) ⇠ Q  then !m ⇠ Q0. Then 
(8)
(9)

R(!1 ···  ! M   m) = R0(!m)
a(z|!1 ···  ! M   m) = a0(z|!m)

are a valid estimator-coupling pair under Q(!1 ···   wM   m).
Rao-Blackwellization is a well-known way to transform an estimator to reduce variance; we want to
know how it affects couplings. Take an estimator R0(!  ⌫ ) with state space ⌦ ⇥ N and distribution

5

Figure 3: Stratiﬁed sampling and antithetic within stratiﬁed sampling on the running example.

Figure 4: A kernel density approximation of Q(z|x) for the estimators in Fig. 3.

Q0(!  ⌫ ). A new estimator R(!) = EQ0(⌫|!) R(!  ⌫) that analytically marginalizes out ⌫ has the
same expectation and equal or lesser variance  by the Rao-Blackwell theorem. The following result
shows that if R0 had a coupling  then it is easy to deﬁne a new coupling for R.
Theorem 4. Suppose that R0(!  ⌫ ) and a0(z|!  ⌫ ) are a valid estimator-coupling pair under
Q0(!  ⌫ ). Then

R(!) = E

R0 (!  ⌫)  

Q0(⌫|!)

1

E

R(!)

Q0(⌫|!)

a(z|!) =

[R0 (!  ⌫) a0(z|!  ⌫)]  

are a valid estimator-coupling pair under Q(!) =R Q0(!  ⌫ )d⌫.

4.2 Speciﬁc Variance Reduction Techniques

Each of the techniques in Table 1 can be derived by ﬁrst applying Thm. 3 and then Thm. 4. As a
simple example  consider the IID mean. Suppose R0(!) and a0(z|!) are valid under Q0. If we let
!1 ···   !M ⇠ Q0 i.i.d. and m uniform on {1 ···   M} then this satisﬁes the condition of Thm. 3
that !m ⇠ Q0. Thus we can deﬁne R and a as in Eq. (8) and Eq. (9). Applying Rao-Blackwellization
to marginalize out m gives exactly the form for R and a shown in the table. Details are in Sec. 9 of
the supplement
As another example  take stratiﬁed sampling. For simplicity  we assume one sample in each strata
(Nm = 1). Suppose ⌦1 ··· ⌦M partition the state-space and let !m ⇠ Q0(!|! 2 ⌦m) and m be
equal to m with probability µm = Q0(! 2 ⌦m). It is again the case that !m ⇠ Q0  and applying
Thm. 3 and then Thm. 4 produces the estimator-coupling pair shown in the table. Again  details are
in Sec. 9 of the supplement.

4.3 Example

We return to the example from Sec. 2.1 and Sec. 3.3. Fig. 3 shows the result of applying stratiﬁed
sampling to the standard VI estimator R = p(z  x)/q(z) and then adjusting the parameters of q to
tighten the bound. The bound is tighter than standard VI and slightly worse than antithetic sampling.
Why not combine antithetic and stratiﬁed sampling? Fig. 3 shows the result of applying antithetic
sampling inside of stratiﬁed sampling. Speciﬁcally  the estimator R(!m) for each stratum m is
replaced by 1
2 (R(!m) + R(Tm(!m))) where Tm is a reﬂection inside the stratum that leaves the
density invariant. A fairly tight bound results. For all of antithetic sampling (Fig. 2)  stratiﬁed
sampling (Fig. 3) and antithetic within stratiﬁed sampling (Fig. 3) tightening E log R ﬁnds Q(!)
such that all batches place some density on z in the main mode of p. Thus  the better sampling
methods permit a q with some coverage of the left mode of p while precluding the possibility that all
samples in a batch are simultaneously in a low-density region (which would result in R near zero 
and thus a very low value for E log R). What do these estimators say about p(z|x)? Fig. 4 compares
the resulting Q(z) for each estimator — the similarity to p(z|x) correlates with the likelihood bound.

6

Figure 5: Different sampling methods applied to Gaussian VI. Top row: Different methods to sample
from the unit cube. Middle row: these samples transformed using the “Cartesian” mapping. Bottom
row: Same samples transformed using the “Elliptical” mapping.

5

Implementation and Empirical Study

Our results are easy to put into practice  e.g. for variational inference with Gaussian approximating
distributions and the reparameterization trick to estimate gradients.. To illustrate this  we show a
simple but general approach. As shown in Fig. 5 the idea is to start with a batch of samples !1 ··· !M
generated from the unit hypercube. Different sampling strategies can give more uniform coverage of
the cube than i.i.d. sampling. After transformation  one obtains samples z1 ··· zM that have more
uniform coverage of the Gaussian. This better coverage often manifests as a lower-variance estimator
R. Our coupling framework gives a corresponding approximate posterior Q(z).
Formally  take any distribution Q(!1 ···  ! M ) such that each marginal Q(!m) is uniform over the
unit cube (but the different !m may be dependent). As shown in Fig. 5  there are various ways to
generate !1 ··· !M and to map them to samples z1 ··· zM from a Gaussian q(zm). Then  Fig. 6 gives
algorithms to generate an estimator R and to generate z from a distribution Q(z) corresponding to a
valid coupling. We use mappings ! F 1
! u T✓! z where t✓ = T✓  F 1 maps ! ⇠ Unif([0  1]d) to
t✓(!) ⇠ q✓ for some density q✓. The idea is to implement variance reduction to sample (batches of)
!  use F 1 to map ! to a “standard” distribution (typically in the same family as q✓)  and then use
T✓ to map samples from the standard distribution to samples from q✓.
The algorithms are again derived from Thm. 3 and Thm. 4. Deﬁne Q0(!) uniform on [0  1]d  R0(!) =
p(t✓(!)  x)/q✓(t✓(!)) and a0(z|!) = (z  t✓(!)). These deﬁne a valid estimator-coupling pair.
Let Q(!1 ···  ! M ) be as described (uniform marginals) and m uniform on {1 ···   M}. Then
Q(!1 ···  ! M   m) satisﬁes the assumptions of Thm. 3  so we can use that theorem then Thm. 4 to
Rao-Blackwellize out m. This produces the estimator-coupling pair in Fig. 6.

Algorithm (Generate R)
• Generate !1 ···  ! M from any distribution
where !m is marginally uniform over [0  1]d.
• Map to a standard dist. as um = F 1(!m).
• Map to q✓ as zm = T✓(um).
• Return R = 1
Figure 6: Generic methods to sample R (left) and Q(z) (right). Here  Q(!1 ···  ! M ) is any
distribution where the marginals Q(!m) are uniform over the unit hypercube.

Algorithm (Sample from Q(z))
• Generate z1 ··· zM as on the left.
• For all m compute weight wm = p(zm x)
q✓(zm) .
• Select m with probability
• Return zm

MPM

p(zm x)
q✓(zm)

.

wmPM

m0=1 wm0

m=1

7

The value of this approach is the many off-the-shelf methods to generate “batches” of samples
(!1 ···  ! M ) that have good “coverage” of the unit cube. This manifests as coverage of q✓ after
being mapped. Fig. 5 shows examples of this with multivariate Gaussians. As shown  there may
be multiple mappings F 1. These manifest as different coverage of q✓  so the choice of mapping
inﬂuences the quality of the estimator. We consider two examples: The “Cartesian” mapping F 1
N (!)
simply applies the inverse CDF of the standard Gaussian. An “elliptical” mapping  meanwhile 
uses the “elliptical” reparameterization of the Gaussian [11]: If r ⇠ d and v is uniform over the
unit sphere  then r v ⇠N (0  I). In Fig. 5 we generate r and v from the uniform distribution as
d (!1) and v = (cos(2⇡!2)  sin(2⇡!2))  and then set F 1(!) = r v. In higher dimensions 
r = F 1
it is easier to generate samples from the unit sphere using redundant dimensions. Thus  we use
d . The
! 2 Rd+1 and map the ﬁrst component to r again using the inverse  distribution CDF F 1
other components are mapped to the unit sphere by ﬁrst applying the Gaussian inverse CDF in each
component  then normalizing.
In the experiments  we use a multivariate Gaussian q✓ with parameters ✓ = (C  µ). The mapping is
T✓(u) = Cu + µ. To ensure a diverse test  we downloaded the corpus of models from the Stan [7]
model library [30] (see also Regier et al. [27]) and created an interface for automatic differentiation
in Stan to interoperate with automatic differentiation code written in Python. We compare VI in
terms of the likelihood bound and in terms of the (squared Frobenius norm) error in the estimated
posterior variance. As a surrogate for the true variance  we computed the empirical variance of
100 000 samples generated via Stan’s Hamiltonian Markov chain Monte Carlo (MCMC) method.
For tractability  we restrict to the 88 models where proﬁling indicates MCMC would take at most 10
hours  and evaluating the posterior for 10 000 settings of the latent variables would take at most 2
seconds. It was infeasible to tune stochastic gradient methods for all models. Instead we used a ﬁxed
batch of 50 000 batches !1 ···  ! M and optimized the empirical ELBO using BFGS  initialized
using Laplace’s method. A fresh batch of 500 000 samples was used to compute the ﬁnal likelihood
bound and covariance estimator. Fig. 7 shows example errors for a few models. The supplement
contains similar plots for all models  as well as plots aggregating statistics  and a visualization of how
the posterior density approximation changes.

6 Conclusions

Recent work has studied the use of improved Monte Carlo estimators for better variational likelihood
bounds. The central insight of this paper is that an approximate posterior can be constructed from an
estimator using a coupling. This posterior’s divergence is bounded by the looseness of the likelihood
bound. We suggest a framework of “estimator-coupling” pairs to make this coupling easy to construct
for many estimators.
Several recent works have viewed Monte Carlo VI bounds through the lens of augmented VI [3  10 
20  11  16]. These establish connections between particular likelihood estimators and approximate
posteriors through extended distributions. They differ from our work primarily in the “direction” of
the construction  the generality  or both. Most of the work uses the following reasoning  which starts
with an approximate posterior and arrives at a tractable likelihood estimator. Take a Monte Carlo
method (e.g. self-normalized importance sampling) to approximately sample from p(z|x). Call the
approximation q(z)  but suppose it is not tractable to evaluate q(z). A tractable likelihood estimator
can be obtained as R(!  z) = p(z  x)p(!|z  x)/q(!  z)  where q(!  z) is the (tractable) joint density
over the “internal randomness” ! of the Monte Carlo procedure and the ﬁnal sample z  and p(!|z  x)
is a conditional distribution used to extend the target to also contain these variables. Different choices
for the Monte Carlo procedure q(!  z) and the target extension p(!|z  x) lead to different estimators.
To arrive at a particular existing likelihood estimator R requires careful estimator-speciﬁc choices
and derivations. In contrast  our work proceeds in the opposite direction: we start with an arbitrary
estimator R and show (via coupling) how to ﬁnd a corresponding Monte Carlo procedure q(!  z).
We also provide a set of tools to “automatically” ﬁnd couplings for many types of estimators.
The idea of using extended state-spaces is common in (Markov chain) Monte Carlo inference methods
[12  2  21  22]. These works also identify extended target distributions that admit p(z  x) as a marginal 
i.e.  a coupling in our terminology. By running an Markov chain Monte Carlo (MCMC) sampler
on the extended target and dropping the auxiliary variables  they obtain an MCMC sampler for
p(z|x). Our work can be seen as the VI analogue of these MCMC methods. Other recent work
[6  18  10  20  17  11  8  28] that has explored the connection between using estimators in variational

8

Figure 7: Across all models  improvements in likelihood bounds correlate strongly with im-
provements in posterior accuracy. Better sampling methods can improve both. First row: the
common case where a simple Gaussian posterior is already very accurate. Here  only a tiny improve-
ment in the ELBO is possible  and improvement in the posterior is below the level detectable when
comparing to MCMC. The other rows show cases where larger improvements are possible.

bounds and auxiliary variational inference [1]. To the best of our knowledge  all of these works
consider situations in which the relevant extended state space (z  !) is known. Thus  in these works 
the estimator essentially comes with an “obvious” coupling distribution a(z|!). In contrast  the
goal of this paper is to consider an arbitrary estimator R(!)  where it is not obvious that a tractable
coupling distribution a(z|!) even exists. This is the situation in which our framework of estimator-
coupling pairs is likely to be useful. The alternative would be manual construction of extended
state-spaces for each individual estimator.

References
[1] Felix V. Agakov and David Barber. An Auxiliary Variational Method. In Neural Information
Processing  Lecture Notes in Computer Science  pages 561–566. Springer  Berlin  Heidelberg 
2004.

[2] Christophe Andrieu  Arnaud Doucet  and Roman Holenstein. Particle Markov chain Monte

Carlo methods. Journal of the Royal Statistical Society: Series B  72:269–342  2010.

[3] Philip Bachman and Doina Precup. Training Deep Generative Models: Variations on a Theme.

In NIPS Workshop: Advances in Approximate Bayesian Inference  2015.

[4] David M. Blei  Alp Kucukelbir  and Jon D. McAuliffe. Variational Inference: A Review for

Statisticians. Journal of the American Statistical Association  112(518):859–877  2017.

[5] Alexander Buchholz  Florian Wenzel  and Stephan Mandt. Quasi-Monte Carlo Variational

Inference. In ICML  2018.

[6] Yuri Burda  Roger Grosse  and Ruslan Salakhutdinov. Importance Weighted Autoencoders. In

ICLR  2015.

9

[7] Bob Carpenter  Andrew Gelman  Matthew D. Hoffman  Daniel Lee  Ben Goodrich  Michael
Betancourt  Marcus Brubaker  Jiqiang Guo  Peter Li  and Allen Riddell. Stan: A Probabilistic
Programming Language. Journal of Statistical Software  76(1)  2017.

[8] Christian Andersson Naesseth. Machine Learning Using Approximate Inference: Variational

and Sequential Monte Carlo Methods. PhD thesis  Linköping University  2018.

[9] T. M. Cover and Joy A. Thomas. Elements of Information Theory. Wiley-Interscience  Hoboken 

N.J  2nd ed edition  2006.

[10] Chris Cremer  Quaid Morris  and David Duvenaud. Reinterpreting Importance-Weighted

Autoencoders. arXiv:1704.02916 [stat]  2017.

[11] Justin Domke and Daniel Sheldon. Importance Weighting and Variational Inference. In NeurIPS 

2018.

[12] Axel Finke. On Extended State-Space Constructions for Monte Carlo Methods. PhD thesis 

University of Warwick  2015.

[13] Tomas Geffner and Justin Domke. Using Large Ensembles of Control Variates for Variational

Inference. In NeurIPS  2018.

[14] Robert M. Gray. Entropy and Information Theory. Springer  New York  2nd ed edition  2011.

OCLC: ocn669910367.

[15] Achim Klenke. Probability Theory: A Comprehensive Course. Universitext. Springer-Verlag 

London  2 edition  2014.

[16] John Lawson  George Tucker  Bo Dai  and Rajesh Ranganath. Energy-Inspired Models: Learn-

ing with Sampler-Induced Distributions. In NeurIPS  page 13  2019.

[17] Tuan Anh Le  Maximilian Igl  Tom Rainforth  Tom Jin  and Frank Wood. Auto-Encoding

Sequential Monte Carlo. In ICLR  2018.

[18] Chris J Maddison  John Lawson  George Tucker  Nicolas Heess  Mohammad Norouzi  Andriy

Mnih  Arnaud Doucet  and Yee Teh. Filtering Variational Objectives. In NeurIPS  2017.

[19] Andrew Miller  Nick Foti  Alexander D’ Amour  and Ryan P Adams. Reducing Reparameteri-

zation Gradient Variance. In NeurIPS  2017.

[20] Christian A. Naesseth  Scott W. Linderman  Rajesh Ranganath  and David M. Blei. Variational
Sequential Monte Carlo. In AISTATS  volume 84 of Proceedings of Machine Learning Research 
pages 968–977. PMLR  2018.

[21] Radford M. Neal. Annealed Importance Sampling. arXiv:physics/9803008  1998.
[22] Radford

Hamiltonian

Neal.

Importance

Sampling.

M.

http://www.cs.toronto.edu/pub/radford/his-talk.pdf  2005.

[23] Sebastian Nowozin. Debiasing Evidence Approximations: On Importance-Weighted Autoen-

coders and Jackknife Variational Inference. 2018.

[24] Art Owen. Monte Carlo Theory  Methods and Examples. 2013.
[25] Tom Rainforth  Adam R. Kosiorek  Tuan Anh Le  Chris J. Maddison  Maximilian Igl  Frank
Wood  and Yee Whye Teh. Tighter Variational Bounds are Not Necessarily Better. In ICML 
2018.

[26] Rajesh Ranganath  Sean Gerrish  and David M. Blei. Black Box Variational Inference. In

AISTATS  2014.

[27] Jeffrey Regier  Michael I Jordan  and Jon McAuliffe. Fast Black-box Variational Inference

through Stochastic Trust-Region Optimization. In NeurIPS  page 10  2017.

[28] Hongyu Ren  Shengjia Zhao  and Stefano Ermon. Adaptive Antithetic Sampling for Variance

Reduction. In ICML  pages 5420–5428  2019.

10

[29] L. K. Saul  T. Jaakkola  and M. I. Jordan. Mean Field Theory for Sigmoid Belief Networks.

Journal of Artiﬁcial Intelligence Research  4:61–76  1996.

[30] Stan developers. Example Models. https://github.com/stan-dev/example-models  2018.
[31] Michalis K. Titsias and Miguel Lázaro-Gredilla. Local Expectation Gradients for Black Box

Variational Inference. In NeurIPS  2015.

11

,Lei Shi
Justin Domke
Daniel Sheldon