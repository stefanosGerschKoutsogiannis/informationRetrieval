2014,Spectral Clustering of graphs with the Bethe Hessian,Spectral clustering is a standard approach to label nodes on a graph by studying the (largest or lowest) eigenvalues of a symmetric real matrix such as e.g. the adjacency or the Laplacian. Recently  it has been argued that using instead a more complicated  non-symmetric and higher dimensional operator  related to the non-backtracking walk on the graph  leads to improved performance in detecting clusters  and even to optimal performance for the stochastic block model. Here  we propose to use instead a simpler object  a symmetric real matrix known as the Bethe Hessian operator  or deformed Laplacian. We show that this approach combines the performances of the non-backtracking operator  thus detecting clusters all the way down to the theoretical limit in the stochastic block model  with the computational  theoretical and memory advantages of real symmetric matrices.,Spectral Clustering of Graphs with the Bethe Hessian

Alaa Saade

Laboratoire de Physique Statistique  CNRS UMR 8550
´Ecole Normale Superieure  24 Rue Lhomond Paris 75005

Florent Krzakala∗

Sorbonne Universit´es  UPMC Univ Paris 06

Laboratoire de Physique Statistique  CNRS UMR 8550

´Ecole Normale Superieure  24 Rue Lhomond

Paris 75005

Lenka Zdeborov´a

Institut de Physique Th´eorique

CEA Saclay and CNRS URA 2306

91191 Gif-sur-Yvette  France

Abstract

Spectral clustering is a standard approach to label nodes on a graph by study-
ing the (largest or lowest) eigenvalues of a symmetric real matrix such as e.g.
the adjacency or the Laplacian. Recently  it has been argued that using instead a
more complicated  non-symmetric and higher dimensional operator  related to the
non-backtracking walk on the graph  leads to improved performance in detecting
clusters  and even to optimal performance for the stochastic block model. Here 
we propose to use instead a simpler object  a symmetric real matrix known as the
Bethe Hessian operator  or deformed Laplacian. We show that this approach com-
bines the performances of the non-backtracking operator  thus detecting clusters
all the way down to the theoretical limit in the stochastic block model  with the
computational  theoretical and memory advantages of real symmetric matrices.

Clustering a graph into groups or functional modules (sometimes called communities) is a central
task in many ﬁelds ranging from machine learning to biology. A common benchmark for this prob-
lem is to consider graphs generated by the stochastic block model (SBM) [7  22]. In this case  one
considers n vertices and each of them has a group label gv ∈ {1  . . .   q}. A graph is then created
as follows: all edges are generated independently according to a q × q matrix p of probabilities 
with Pr[Au v = 1] = pgu gv. The group labels are hidden  and the task is to infer them from the
knowledge of the graph. The stochastic block model generates graphs that are a generalization of
the Erd˝os-R´enyi ensemble where an unknown labeling has been hidden.
We concentrate on the sparse case  where algorithmic challenges appear. In this case pab is O(1/n) 
and we denote pab = cab/n. For simplicity we concentrate on the most commonly-studied case
where groups are equally sized  cab = cin if a = b and cab = cout if a (cid:54)= b. Fixing cin > cout
is referred to as the assortative case  because vertices from the same group connect with higher
probability than with vertices from other groups. cout > cin is called the disassortative case. An
important conjecture [4] is that any tractable algorithm will only detect communities if

(1)
where c is the average degree. In the case of q = 2 groups  in particular  this has been rigorously
proven [15  12] (in this case  one can also prove that no algorithm could detect communities if this
condition is not met). An ideal clustering algorithm should have a low computational complexity
while being able to perform optimally for the stochastic block model  detecting clusters down to the
transition (1).

c  

∗This work has been supported in part by the ERC under the European Union’s 7th Framework Programme

Grant Agreement 307087-SPARCS

1

|cin − cout| > q

√

So far there are two algorithms in the literature able to detect clusters down to the transition (1). One
is a message-passing algorithm based on belief-propagation [5  4]. This algorithm  however  needs
to be fed with the correct parameters of the stochastic block model to perform well  and its compu-
tational complexity scales quadratically with the number of clusters  which is an important practical
limitation. To avoid such problems  the most popular non-parametric approaches to clustering are
spectral methods  where one classiﬁes vertices according to the eigenvectors of a matrix associated
with the network  for instance its adjacency matrix [11  16]. However  while this works remarkably
well on regular  or dense enough graphs [2]  the standard versions of spectral clustering are subop-
timal on graphs generated by the SBM  and in some cases completely fail to detect communities
even when other (more complex) algorithms such as belief propagation can do so. Recently  a new
class of spectral algorithms based on the use of a non-backtracking walk on the directed edges of the
graph has been introduced [9] and argued to be better suited for spectral clustering. In particular  it
has been shown to be optimal for graphs generated by the stochastic block model  and able to detect
communities even in the sparse case all the way down to the theoretical limit (1).
These results are  however  not entirely satisfactory. First  the use a of a high-dimensional matrix
(of dimension 2m - where m is the number of edges - rather than n  the number of nodes) can be
expensive  both in terms of computational time and memory. Secondly  linear algebra methods are
faster and more efﬁcient for symmetric matrices than non-symmetric ones. The ﬁrst problem was
partially resolved in [9] where an equivalent operator of dimensions 2n was shown to exist. It was
still  however  a non-symmetric one and more importantly  the reduction does not extend to weighted
graphs  and thus presents a strong limitation.
In this contribution  we provide the best of both worlds: a non-parametric spectral algorithm for clus-
tering with a symmetric n × n  real operator that performs as well as the non-backtracking operator
of [9]  in the sense that it identiﬁes communities as soon as (1) holds. We show numerically that our
approach performs as well as the belief-propagation algorithm  without needing prior knowledge of
any parameter  making it the simplest algorithmically among the best-performing clustering meth-
ods. This operator is actually not new  and has been known as the Bethe Hessian in the context of
statistical physics and machine learning [14  17] or the deformed Laplacian in other ﬁelds. However 
to the best of our knowledge  it has never been considered in the context of spectral clustering.
The paper is organized as follows. In Sec. 1 we give the expression of the Bethe Hessian operator.
We discuss in detail its properties and its connection with both the non-backtracking operator and an
Ising spin glass in Sec. 2. In Sec. 3  we study analytically the spectrum in the case of the stochastic
block model. Finally  in Sec. 4 we perform numerical tests on both the stochastic block model and
on some real networks.

1 Clustering based on the Bethe Hessian matrix
Let G = (V  E) be a graph with n vertices  V = {1  ...  n}  and m edges. Denote by A its adjacency
matrix  and by D the diagonal matrix deﬁned by Dii = di  ∀i ∈ V   where di is the degree of
vertex i. We then deﬁne the Bethe Hessian matrix  sometimes called the deformed Laplacian  as

H(r) := (r2 − 1)1 − rA + D  

(2)
where |r| > 1 is a regularizer that we will set to a well-deﬁned value |r| = rc depending on the
√
graph  for instance rc =
c in the case of the stochastic block model  where c is the average degree
of the graph (see Sec. 2.1).
The spectral algorithm that is the main result of this paper works as follows: we compute the eigen-
vectors associated with the negative eigenvalues of both H(rc) and H(−rc)  and cluster them with
a standard clustering algorithm such as k-means (or simply by looking at the sign of the components
in the case of two communities). The negative eigenvalues of H(rc) reveal the assortative aspects 
while those of H(−rc) reveal the disassortative ones.
stochastic block model. When r =±√
Figure 1 illustrates the spectral properties of the Bethe Hessian (2) for networks generated by the
c the informative eigenvalues (i.e. those having eigenvectors
correlated to the cluster structure) are the negative ones  while the non-informative bulk remains
positive. There are as many negative eigenvalues as there are hidden clusters. It is thus straight-
forward to select the relevant eigenvectors. This is very unlike the situation for the operators used
in standard spectral clustering algorithms (except  again  for the non-backtracking operator) where

2

Figure 1: Spectral density of the Bethe Hessian for various values of the regularizer r on the stochas-
tic block model. The red dots are the result of the direct diagonalization of the Bethe Hessian for a
graph of 104 vertices with 2 clusters  with c = 4  cin = 7  cout = 1. The black curves are the solutions
to the recursion (15) for c = 4  obtained from population dynamics (with a population of size 105) 
see section 3. We isolated the two smallest eigenvalues  represented as small bars for convenience.
The dashed black line marks the x = 0 axis  and the inset is a zoom around this axis. At large value of
r (top left) r = 5  the Bethe Hessian is positive deﬁnite and all eigenvalues are positive. As r decays 
the spectrum moves towards the x = 0 axis. The smallest (non-informative) eigenvalue reaches zero
for r = c = 4 (middle top)  followed  as r decays further  by the second (informative) eigenvalue at
r = (cin − cout)/2 = 3  which is the value of the second largest eigenvalue of B in this case [9] (top
c = 2 (bottom left). At this point  the information is in the
right). Finally  the bulk reaches 0 at rc =
negative part  while the bulk is in the positive part. Interestingly  if r decays further (bottom middle
and right) the bulk of the spectrum remains positive  but the informative eigenvalues blend back into
the bulk. The best choice is thus to work at rc =

c = 2.

√

√

one must decide in a somehow ambiguous way which eigenvalues are relevant (outside the bulk) or
not (inside the bulk). Here  on the contrary  no prior knowledge of the number of communities is
needed.

On more general graphs  we argue that the best choice for the regularizer is rc = (cid:112)ρ(B)  where

ρ(B) is the spectral radius of the non-backtracking operator. We support this claim both numerically 
on real world networks (sec. 4.2)  and analytically (sec. 3). We also show that ρ(B) can be computed
without building the matrix B itself  by efﬁciently solving a quadratic eigenproblem (sec. 2.1).
The Bethe Hessian can be generalized straightforwardly to the weighed case: if the edge (i  j) carries
a weight wij  then we can use the matrix ˜H(r) deﬁned by

˜H(r)ij = δij

1 +

 

(3)

(cid:16)

(cid:88)

k∈∂i

(cid:17) − rwijAij

r2 − w2

ij

w2
ik

r2 − w2

ik

where ∂i denotes the set of neighbors of vertex i. This is in fact the general expression of the Bethe
Hessian of a certain weighted statistical model (see section 2.2). If all weights are equal to unity  ˜H
reduces to (2) up to a trivial factor. Most of the arguments developed in the following generalize im-
mediately to ˜H  including the relationship with the weighted non-backtracking operator  introduced
in the conclusion of [9].

2 Derivation and relation to previous works

Our approach is connected to both the spectral algorithm using the non-backtracking matrix and
to an Ising spin glass model. We now discuss these connections  and the properties of the Bethe
Hessian operator along the way.

3

020406000.050.10.150.2ν(λ)r=5020406000.050.10.150.2r=4020406000.050.10.150.2r=3020406000.050.10.150.2λν(λ)r=2020406000.050.10.150.2λr=1.5020406000.050.10.150.2λr=1.1020406000.050.10.150.2ν(λ)r=5020406000.050.10.150.2r=4020406000.050.10.150.2r=3020406000.050.10.150.2λν(λ)r=2020406000.050.10.150.2λr=1.5020406000.050.10.150.2λr=1.1020406000.050.10.150.2ν(λ)r=5020406000.050.10.150.2r=4020406000.050.10.150.2r=3020406000.050.10.150.2λν(λ)r=2020406000.050.10.150.2λr=1.5020406000.050.10.150.2λr=1.1020406000.050.10.150.2ν(λ)r=5020406000.050.10.150.2r=4020406000.050.10.150.2r=3020406000.050.10.150.2λν(λ)r=2020406000.050.10.150.2λr=1.5020406000.050.10.150.2λr=1.1020406000.050.10.150.2ν(λ)r=5020406000.050.10.150.2r=4020406000.050.10.150.2r=3020406000.050.10.150.2λν(λ)r=2020406000.050.10.150.2λr=1.5020406000.050.10.150.2λr=1.1020406000.050.10.150.2ν(λ)r=5020406000.050.10.150.2r=4020406000.050.10.150.2r=3020406000.050.10.150.2λν(λ)r=2020406000.050.10.150.2λr=1.5020406000.050.10.150.2λr=1.1020406000.050.10.150.2ν(λ)r=5020406000.050.10.150.2r=4020406000.050.10.150.2r=3020406000.050.10.150.2λν(λ)r=2020406000.050.10.150.2λr=1.5020406000.050.10.150.2λr=1.1020406000.050.10.150.2ν(λ)r=5020406000.050.10.150.2r=4020406000.050.10.150.2r=3020406000.050.10.150.2λν(λ)r=2020406000.050.10.150.2λr=1.5020406000.050.10.150.2λr=1.1020406000.050.10.150.2ν(λ)r=5020406000.050.10.150.2r=4020406000.050.10.150.2r=3020406000.050.10.150.2λν(λ)r=2020406000.050.10.150.2λr=1.5020406000.050.10.150.2λr=1.1000000020406000.050.10.150.2ν(λ)r=5020406000.050.10.150.2r=4020406000.050.10.150.2r=3020406000.050.10.150.2λν(λ)r=2020406000.050.10.150.2λr=1.5020406000.050.10.150.2λr=1.1020406000.050.10.150.2ν(λ)r=5020406000.050.10.150.2r=4020406000.050.10.150.2r=3020406000.050.10.150.2λν(λ)r=2020406000.050.10.150.2λr=1.5020406000.050.10.150.2λr=1.1020406000.050.10.150.2ν(λ)r=5020406000.050.10.150.2r=4020406000.050.10.150.2r=3020406000.050.10.150.2λν(λ)r=2020406000.050.10.150.2λr=1.5020406000.050.10.150.2λr=1.1020406000.050.10.150.2ν(λ)r=5020406000.050.10.150.2r=4020406000.050.10.150.2r=3020406000.050.10.150.2λν(λ)r=2020406000.050.10.150.2λr=1.5020406000.050.10.150.2λr=1.1020406000.050.10.150.2ν(λ)r=5020406000.050.10.150.2r=4020406000.050.10.150.2r=3020406000.050.10.150.2λν(λ)r=2020406000.050.10.150.2λr=1.5020406000.050.10.150.2λr=1.1020406000.050.10.150.2ν(λ)r=5020406000.050.10.150.2r=4020406000.050.10.150.2r=3020406000.050.10.150.2λν(λ)r=2020406000.050.10.150.2λr=1.5020406000.050.10.150.2λr=1.10202020202022.1 Relation with the non-backtracking matrix
The non-backtracking operator of [9] is deﬁned as a 2m× 2m non-symmetric matrix indexed by the
directed edges of the graph i → j

Bi→j k→l = δjk(1 − δil) .

(4)

The remarkable efﬁciency of the non-backtracking operator is due to the particular structure of its
(complex) spectrum. For graphs generated by the SBM the spectrum decomposes into a bulk of

uninformative eigenvalues sharply constrained when n → ∞ to the disk of radius(cid:112)ρ(B)  where
(cid:112)ρ(B)  while the presence of disassortative communities yields real negative eigenvalues smaller
than −(cid:112)ρ(B). The authors of [9] showed that all eigenvalues λ of B that are different from ±1 are

ρ(B) is the spectral radius of B [20]  well separated from the real  informative eigenvalues  that
lie outside of this circle. It was also remarked that the number of real eigenvalues outside of the
circle is the number of communities  when the graph was generated by the stochastic block model.
More precisely  the presence of assortative communities yields real positive eigenvalues larger than

roots of the polynomial

det [(λ2 − 1)1 − λA + D] = det H(λ) .

(5)

This is known in graph theory as the Ihara-Bass formula for the graph zeta function. It provides
the link between B and the (determinant of the) Bethe Hessian (already noticed in [23]): a real
eigenvalue of B corresponds to a value of r such that the Bethe Hessian has a vanishing eigenvalue.
For any ﬁnite n  when r is large enough  H(r) is positive deﬁnite. Then as r decreases  a new
negative eigenvalue of H(r) appears when it crosses the zero axis  i.e whenever r is equal to a real
positive eigenvalue λ of B. The null space of H(λ) is related to the corresponding eigenvector of B.
Denoting (vi)1≤i≤n the eigenvector of H(λ) with eigenvalue 0  and (vi→j)(i j)∈E the eigenvector
of B with eigenvalue λ  we have [9]:

Therefore the vector (vi)1≤i≤n is correlated with the community structure when (vi→j)(i j)∈E is.
The numerical experiments of section 4 show that when r =
c < λ  the eigenvector (vi)1≤i≤n
corresponds to a strictly negative eigenvalue  and is even more correlated with the community struc-
ture than the eigenvector (vi→j)(i j)∈E. This fact still lacks a proper theoretical understanding. We
provide in section 2.2 a different  physical justiﬁcation to the relevance of the “negative” eigenvec-
tors of the Bethe Hessian for community detection. Of course  the same phenomenon takes place
when increasing r from a large negative value. In order to translate all the informative eigenvalues
of B into negative eigenvalues of H(r) we adopt

√

since all the relevant eigenvalues of B are outside the circle of radius rc. On the other hand  H(r =
1) is the standard  positive-semideﬁnite  Laplacian so that for r < rc  the negative eigenvalues of
H(r) move back into the positive part of the spectrum. This is consistent with the observation of
[9] that the eigenvalues of B come in pairs having their product close to ρ(B)  so that for each root
λ > rc of (5)  corresponding to the appearance of a new negative eigenvalue  there is another root
λ(cid:48) (cid:39) ρ(B)/λ < rc which we numerically found to correspond to the same eigenvalue becoming
positive again.
Let us stress that to compute ρ(B)  we do not need to actually build the non-backtracking matrix.
First  for large random networks of a given degree distribution  ρ(B) = (cid:104)d2(cid:105)/(cid:104)d(cid:105) − 1 [9]  where (cid:104)d(cid:105)
and (cid:104)d2(cid:105) are the ﬁrst and second moments of the degree distribution. In a more general setting  we
can efﬁciently reﬁne this initial guess by solving for the closest root of the quadratic eigenproblem
deﬁned by (5)  e.g. using a standard SLP algorithm [19]. With the choice (7)  the informative
eigenvalues of B are in one-to-one correspondance with the union of negative eigenvalues of H(rc)
and H(−rc). Because B has as many informative eigenvalues as there are (detectable) communities
in the network [9]  their number will therefore tell us the number of (detectable) communities in the
graph  and we will use them to infer the community membership of the nodes  by using a standard
clustering algorithm such as k-means.

4

(cid:88)

k∈∂i

vi =

vk→i .

rc =(cid:112)ρ(B) .

(6)

(7)

2.2 Hessian of the Bethe free energy
Let us deﬁne a pairwise Ising model on the graph G by the joint probability distribution:

 (cid:88)

(i j)∈E

  

(cid:16) 1

(cid:17)

r

atanh

xixj

P ({x}) =

1
Z

exp

where {x} := {xi}i∈{1..n} ∈ {±1}n is a set of binary random variables sitting on the nodes of the
graph G. The regularizer r is here a parameter that controls the strength of the interaction between
the variables: the larger |r| is  the weaker is the interaction.
In order to study this model  a standard approach in machine learning is the Bethe approximation
[21] in which the means (cid:104)xi(cid:105) and moments (cid:104)xixj(cid:105) are approximated by the parameters mi and ξij
that minimize the so-called Bethe free energy FBethe({mi} {ξij}) deﬁned as

(cid:16) 1 + mixi + mjxj + ξijxixj

(cid:17)

FBethe({mi} {ξij}) = − (cid:88)
(cid:88)

atanh

(cid:88)

(i j)∈E
(1 − di)

η

xi

+

i∈V

(cid:88)

xi xj

η

(cid:16) 1
(cid:17)
(cid:16) 1 + mixi

ξij +

r

(cid:88)
(cid:17)

(i j)∈E

 

2

4

(9)

where η(x) := x ln x. Such approach allows for instance to derive the belief propagation (BP)
algorithm. Here  however  we wish to restrict to a spectral one. At very high r the minimum of the
r . It turns out [14]
Bethe free energy is given by the so-called paramagnetic point mi = 0  ξij = 1
that mi = 0  ξij = 1
r is a stationarity point of the Bethe free energy for every r. Instead of consid-
ering the complete Bethe free energy  we will consider only its behavior around the paramagnetic
point. This can be expressed via the Hessian (matrix of second derivatives)  that has been studied
extensively  see e.g. [14]  [17]. At the paramagnetic point  the blocks of the Hessian involving one
derivative with respect to the ξij are 0  and the block involving two such derivatives is a positive
deﬁnite diagonal matrix [23]. We will therefore  somewhat improperly  call Hessian the matrix

Hij(r) =

∂FBethe
∂mi∂mj

(cid:12)(cid:12)(cid:12)mi=0 ξij = 1

r

.

(8)

(10)

(11)

In particular  at the paramagnetic point:
H(r) = 1 +

D

r2 − 1

− rA
r2 − 1

=

H(r)
r2 − 1

.

A more general expression of the Bethe Hessian in the case of weighted interactions atanh(wij/r)
(with weights rescaled to be in [0  1]) is given by eq. (3). All eigenvectors of H(r) and H(r) are the
same  as are the eigenvalues up to a multiplicative  positive factor (since we consider only |r| > 1).
The paramagnetic point is stable iff H(r) is positive deﬁnite. The appearance of each negative
eigenvalue of the Hessian corresponds to a phase transition in the Ising model at which a new cluster
(or a set of clusters) starts to be identiﬁable. The corresponding eigenvector will give the direction
towards the cluster labeling. This motivates the use of the Bethe Hessian for spectral clustering.
For tree-like graphs such as those generated by the SBM  model (8) can been studied analytically
in the asymptotic limit n→∞. The location of the possible phase transitions in model (8) are also
known from spin glass theory and the theory of phase transitions on random graphs (see e.g. [14 
5  4  17]). For positive r the trivial ferromagnetic phase appears at r = c  while the transitions
c < r < c. For
towards the phases corresponding to the hidden community structure arise between
c 
the model undergoes a spin glass phase transition. At this point all the relevant eigenvalues have
passed in the negative side (all the possible transitions from the paramagnetic states to the hidden
structure have taken place) while the bulk of non-informative ones remains positive. This scenario
is illustrated in Fig. 1 for the case of two assortative clusters.

disassortative communities  the situation is symmetric with r < −√

c. Interestingly  at r = ±√

√

3 The spectrum of the Bethe Hessian

The spectral density of the Bethe Hessian can be computed analytically on tree-like graphs such as
those generated by the stochastic block model. This will serve two goals: i) to justify independently

5

our choice for the value of the regularizer r and ii) to show that for all values of r  the bulk of
uninformative eigenvalues remains in the positive region. The spectral density is deﬁned by:

ν(λ) =

1
n

δ(λ − λi)  

(12)

where the λi’s are the eigenvalues of the Bethe Hessian. It can be shown [18] that it is also given by

n(cid:88)

i=1

n(cid:88)

i=1

(13)

(14)

where the ∆i are complex variables living on the vertices of the graph G  which are given by:

∆i =

ν(λ) =

1
πn

Im∆i(λ)  

(cid:16) − λ + r2 + di − 1 − r2(cid:88)
(cid:16) − λ + r2 + di − 1 − r2 (cid:88)

l∈∂i

l∈∂i\j

(cid:17)−1

∆l→i

 

(cid:17)−1

where di is the degree of node i in the graph  and ∂i is the set of neighbors of i. The ∆i→j are the
(linearly stable) solution of the following belief propagation recursion  or cavity method [13] 

∆i→j =

∆l→i

.

(15)

The ingredients to derive this formula are to turn the computation of the spectral density into a
marginalization problem for a graphical model on the graph G  and then write the belief propaga-
tion equations to solve it. It can be shown [3] that this approach leads to an asymptotically exact
description of the spectral density on random graphs such as those generated by the stochastic block
model  which are locally tree-like in the limit where n → ∞. We can solve equation (15) numer-
ically using a population dynamics algorithm [13]: starting from a pool of variables  we iterate by
drawing at each step a variable  its excess degree and its neighbors from the pool  and updating its
value according to (15). The results are shown on Fig. 1: the bulk of the spectrum is always positive.
We now justify analytically that the bulk of eigenvalues of the Bethe Hessian reaches 0 at r =

(cid:112)ρ(B). From (13) and (14)  we see that if the linearly stable solution of (15) is real  then the

corresponding spectral density will be equal to 0. We want to show that there exists an open set
U ⊂ R around 0 in which there exists a real  stable  solution to the BP recursion. Let us call
∆ ∈ R2m  where m is the number of edges in G  the vector which components are the ∆i→j. We
introduce the function F : (λ  ∆) ∈ R2m+1 → F (λ  ∆) ∈ R2m deﬁned by

(cid:16) − λ + r2 + di − 1 − r2 (cid:88)

(cid:17) − 1

∆i→j

∆l→i

l∈∂i\j

F (λ  ∆)i→j =

 

(16)

so that equation (15) can be rewritten as

F (λ  ∆) = 0 .

(17)

It is straightforward to check that when λ = 0  the assignment ∆i→j = 1/r2 is a real solution
of (17). Furthermore  the Jacobian of F at this point reads

JF (0 {1/r2}) =

(18)



−1
0
...

0

r2(r21 − B)

  

invertible whenever r >(cid:112)ρ(B). From the continuous differentiability of F around (0 {1/r2}) and

where B is the 2m×2m non-backtracking operator and 1 is the 2m×2m identity matrix. The square
submatrix of the Jacobian containing the derivatives with respect to the messages ∆i→j is therefore
the implicit function theorem  there exists an open set V containing 0 such that for all λ ∈ V   there
exists ˜∆(λ) ∈ R solution of (17)   and the function ˜∆ is continuous in λ. To show that the spectral

6

density is indeed 0 in an open set around λ = 0  we need to show that this solution is linearly stable.
Introducing the function Gλ : ∆ ∈ R2m → Gλ(∆) ∈ R2m deﬁned by

(cid:16) − λ + r2 + di − 1 − r2 (cid:88)

l∈∂i\j

(cid:17)−1

Gλ(∆)i→j =

∆l→i

 

(19)

it is enough to show that the Jacobian of Gλ at the point ˜∆(λ) has all its eigenvalues smaller than
1 in modulus  for λ close to 0. But since JGλ(∆) is continuous in (λ  ∆) in the neighborhood of
(0  ˜∆(0) = {1/r2})  and ˜∆(λ) is continuous in λ  it is enough to show that the spectral radius of
JG0 ({1/r2}) is smaller than 1. We compute

JG0({1/r2}) =

1
r2 B  

(20)
so that the spectral radius of JG0 ({1/r2}) is ρ(B)/r2  which is (strictly) smaller than 1 as long as
exists an open set U ⊂ V containing 0 such that ∀λ ∈ U  the solution ˜∆ of the BP recursion (15)
is real  so that the corresponding spectral density in U is equal to 0. This proves that the bulk of the

r > (cid:112)ρ(B). From the continuity of the eigenvalues of a matrix with respect to its entries  there
spectrum of H reaches 0 at r = rc =(cid:112)ρ(B)  further justifying our choice for the regularizer.

4 Numerical results

4.1 Synthetic networks

We illustrate the efﬁciency of the algorithm for graphs generated by the stochastic block model.
Fig. 2 shows the performance of standard spectral clustering methods  as well as that of the belief
propagation (BP) algorithm of [4]  believed to be asymptotically optimal in large tree-like graph.
The performance is measured in terms of the overlap with the true labeling  deﬁned as

(cid:32)

(cid:88)

u

1
N

(cid:33)(cid:30)(cid:18)

(cid:19)

δgu ˜gu − 1
q

1 − 1
q

 

(21)

where gu is the true group label of node u  and ˜gu is the label given by the algorithm  and we maxi-
mize over all q! possible permutation of the groups. The Bethe Hessian systematically outperforms
B and does almost as well as BP  which is a more complicated algorithm  that we have run here
assuming the knowledge of ”oracle parameters”: the number of communities  their sizes  and the
matrix pab [5  4]. The Bethe Hessian  on the other hand is non-parametric and infers the number of
communities in the graph by counting the number of negative eigenvalues.

4.2 Real networks

We ﬁnally turn towards actual real graphs to illustrate the performances of our approach  and to
show that even if real networks are not generated by the stochastic block model  the Bethe Hessian
operator remains a useful tool.
In Table 1 we give the overlap and the number of groups to be
identiﬁed. We limited our experiments to this list of networks because they have known  “ground
true” clusters. For each case we observed a large correlation to the ground truth  and at least equal
(and sometimes better) performances with respect to the non backtracking operator. The overlap
was computed assuming knowledge of the number of ground true clusters. The number of clusters is
correctly given by the number of negative eigenvalues of the Bethe Hessian in all the presented cases
except for the political blogs network (10 predicted clusters) and the football network (10 predicted
clusters). These differences either question the statistical signiﬁcance of some of the human-decided
labelling  or suggest the existence of additional relevant clusters. It is also interesting to note that
our approach works not only in the assortative case but also in the disassortative ones  for instance
for the word adjacency networks. A Matlab implementation to reproduce the results of the Bethe
Hessian for both real and synthetic networks is provided as supplementary material.

5 Conclusion and perspectives

We have presented here a new approach to spectral clustering using the Bethe Hessian and given ev-
idence that this approach combines the advantages of standard sparse symmetric real matrices  with

7

Figure 2: Performance of spectral clustering applied to graphs of size n = 105 generated from the
the stochastic block model. Each point is averaged over 20 such graphs. Left: assortative case with
q = 2 clusters (theoretical transition at 3.46); middle: disassortative case with q = 2 (theoretical
transition at -3.46); right: assortative case with q = 3 clusters (theoretical transition at 5.20). For
q = 2  we clustered according to the signs of the components of the eigenvector corresponding to
the second most negative eigenvalue of the Bethe Hessian operator. For q = 3  we used k-means on
the 3 “negative” eigenvectors. While both the standard adjacency (A) and symmetrically normalized
Laplacian (D−1/2(D−A)D−1/2) approaches fail to identify clusters in a large relevant region  both
the non-backtracking (B) and the Bethe Hessian (BH) approaches identify clusters almost as well as
using the more complicated belief propagation (BP) with oracle parameters. Note  however  that the
Bethe Hessian systematically outperforms the non-backtracking operator  at a smaller computational
cost. Additionally  clustering with the adjacency matrix and the normalized laplacian are run on the
largest connected component  while the Bethe Hessian doesn’t require any kind of pre-processing
of the graph. While our theory explains why clustering with the Bethe Hessian gives a positive
overlap whenever clustering with B does  we currently don’t have an explanation as to why the
Bethe Hessian overlap is actually larger.

Table 1: Overlap for some commonly used benchmarks for community detection  computed using
the signs of the second eigenvector for the networks with two communities  and using k-means
for those with three and more communities  compared to the man-made group assignment. The
non-backtracking operator detects communities in all these networks  with an overlap comparable
to the performance of other spectral methods. The Bethe Hessian systematically either equals or
outperforms the results obtained by the non-backtracking operator.

PART

Non-backtracking [9] Bethe Hessian

Polbooks (q = 3) [1]
Polblogs (q = 2) [10]
Karate (q = 2) [24]
Football (q = 12) [6]
Dolphins (q = 2) [16]
Adjnoun (q = 2) [8]

0.742857
0.864157

1

0.924111
0.741935
0.625000

0.757143
0.865794

1

0.924111
0.806452
0.660714

the performances of the more involved non-backtracking operator  or the use of the belief propaga-
tion algorithm with oracle parameters. Advantages over other spectral methods are that the number
of negative eigenvalues provides an estimate of the number of clusters  there is a well-deﬁned way
to set the parameter r  making the algorithm tuning-parameter free  and it is guaranteed to detect the
communities generated from the stochastic block model down to the theoretical limit. This answers
the quest for a tractable non-parametric approach that performs optimally in the stochastic block
model. Given the large impact and the wide use of spectral clustering methods in many ﬁelds of
modern science  we thus expect that our method will have a signiﬁcant impact on data analysis.

8

34500.20.40.60.81cin−coutoverlapq=2BHBANorm.Lap.BP-5-4-300.20.40.60.81cin−coutq=2BHBANorm.Lap.BP567800.20.40.60.81cin−coutq=3BHBANorm.Lap.BPReferences
[1] L. A Adamic and N. Glance. The political blogosphere and the 2004 us election: divided they
blog. In Proceedings of the 3rd international workshop on Link discovery  page 36. ACM 
2005.

[2] P. J Bickel and A. Chen. A nonparametric view of network models and newman–girvan and

other modularities. Proceedings of the National Academy of Sciences  106(50):21068  2009.

[3] Charles Bordenave and Marc Lelarge. Resolvent of large random graphs. Random Structures

and Algorithms  37(3):332–352  2010.

[4] A. Decelle  F. Krzakala  C. Moore  and L. Zdeborov´a. Asymptotic analysis of the stochas-
tic block model for modular networks and its algorithmic applications. Phys. Rev. E 
84(6):066106  2011.

[5] A. Decelle  F. Krzakala  C. Moore  and L. Zdeborov´a. Inference and phase transitions in the

detection of modules in sparse networks. Phys. Rev. Lett.  107(6):065701  2011.

[6] Michelle Girvan and Mark EJ Newman. Community structure in social and biological net-

works. Proceedings of the National Academy of Sciences  99(12):7821–7826  2002.

[7] Paul W. Holland  Kathryn Blackmond Laskey  and Samuel Leinhardt. Stochastic blockmodels:

First steps. Social Networks  5(2):109  1983.

[8] Valdis Krebs. The network can be found on http://www.orgnet.com/.
[9] F. Krzakala  C. Moore  E. Mossel  J. Neeman  A. Sly  L. Zdeborov´a  and P. Zhang. Spectral
redemption in clustering sparse networks. Proceedings of the National Academy of Sciences 
110(52):20935–20940  2013.

[10] D. Lusseau  K. Schneider  O. J. Boisseau  P. Haase  E. Slooten  and S. M Dawson. The bot-
tlenose dolphin community of doubtful sound features a large proportion of long-lasting asso-
ciations. Behavioral Ecology and Sociobiology  54(4):396–405  2003.

[11] Ulrike Luxburg. A tutorial on spectral clustering. Statistics and Computing  17(4):395  2007.
[12] Laurent Massoulie. Community detection thresholds and the weak ramanujan property. arXiv

preprint arXiv:1311.3085  2013.

[13] M. Mezard and A. Montanari.

Press  2009.

Information  Physics  and Computation. Oxford University

[14] Joris M Mooij  Hilbert J Kappen  et al. Validity estimates for loopy belief propagation on

binary real-world networks. In NIPS  2004.

[15] Elchanan Mossel  Joe Neeman  and Allan Sly. A proof of the block model threshold conjecture.

arXiv preprint arXiv:1311.4115  2013.

[16] Mark EJ Newman. Finding community structure in networks using the eigenvectors of matri-

ces. Phys. Rev. E  74(3):036104  2006.

[17] F. Ricci-Tersenghi. The bethe approximation for solving the inverse ising problem: a compar-

ison with other inference methods. J. Stat. Mech.: Th. and Exp.  page P08015  2012.

[18] Tim Rogers  Isaac P´erez Castillo  Reimer K¨uhn  and Koujin Takeda. Cavity approach to the

spectral density of sparse symmetric random matrices. Phys. Rev. E  78(3):031116  2008.

[19] Axel Ruhe. Algorithms for the nonlinear eigenvalue problem. SIAM Journal on Numerical

Analysis  10(4):674–689  1973.

[20] Alaa Saade  Florent Krzakala  and Lenka Zdeborov´a. Spectral density of the non-backtracking

operator on random graphs. EPL  107(5):50005  2014.

[21] M. J. Wainwright and M. I. Jordan. Graphical models  exponential families  and variational

inference. Foundations and Trends in Machine Learning  1  2008.

[22] Yuchung J Wang and George Y Wong. Stochastic blockmodels for directed graphs. Journal of

the American Statistical Association  82(397):8–19  1987.

[23] Yusuke Watanabe and Kenji Fukumizu. Graph zeta function in the bethe free energy and loopy

belief propagation. In NIPS  pages 2017–2025  2009.

[24] W Zachary. An information ﬂow model for conﬂict and ﬁssion in small groups1. Journal of

anthropological research  33(4):452–473  1977.

9

,Alaa Saade
Florent Krzakala
Lenka Zdeborová
Vu Dinh
Lam Ho
Binh Nguyen
Duy Nguyen