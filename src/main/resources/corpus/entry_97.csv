2013,A Graphical Transformation for Belief Propagation: Maximum Weight Matchings and Odd-Sized Cycles,Max-product ‘belief propagation’ (BP) is a popular distributed heuristic for finding the Maximum A Posteriori (MAP) assignment in a joint probability distribution represented by a Graphical Model (GM). It was recently shown that BP converges to the correct MAP assignment for a class of loopy GMs with the following common feature: the Linear Programming (LP) relaxation to the MAP problem is tight (has no integrality gap). Unfortunately  tightness of the LP relaxation does not  in general  guarantee convergence and correctness of the BP algorithm. The failure of BP in such cases motivates reverse engineering a solution – namely  given a tight LP  can we design a ‘good’ BP algorithm.  In this paper  we design a BP algorithm for the Maximum Weight Matching (MWM) problem over general graphs. We prove that the algorithm converges to the correct optimum if the respective LP relaxation  which may include inequalities associated with non-intersecting odd-sized cycles  is tight. The most significant part of our approach is the introduction of a novel graph transformation designed to force convergence of BP. Our theoretical result suggests an efficient BP-based heuristic for the MWM problem  which consists of making sequential  “cutting plane”  modifications to the underlying GM. Our experiments show that this heuristic performs as well as traditional cutting-plane algorithms using LP solvers on MWM problems.,A Graphical Transformation for Belief Propagation:
Maximum Weight Matchings and Odd-Sized Cycles

Jinwoo Shin

Department of Electrical Engineering

Korea Advanced Institute of Science and Technology

Daejeon  305-701  Republic of Korea

jinwoos@kaist.ac.kr

Andrew E. Gelfand ∗
Department of Computer Science
University of California  Irvine
Irvine  CA 92697-3435  USA
agelfand@ics.uci.edu

Michael Chertkov
Theoretical Division &

Center for Nonlinear Studies

Los Alamos National Laboratory
Los Alamos  NM 87545  USA

chertkov@lanl.gov

Abstract

Max-product ‘belief propagation’ (BP) is a popular distributed heuristic for ﬁnd-
ing the Maximum A Posteriori (MAP) assignment in a joint probability distribu-
tion represented by a Graphical Model (GM). It was recently shown that BP con-
verges to the correct MAP assignment for a class of loopy GMs with the following
common feature: the Linear Programming (LP) relaxation to the MAP problem is
tight (has no integrality gap). Unfortunately  tightness of the LP relaxation does
not  in general  guarantee convergence and correctness of the BP algorithm. The
failure of BP in such cases motivates reverse engineering a solution – namely 
given a tight LP  can we design a ‘good’ BP algorithm.
In this paper  we design a BP algorithm for the Maximum Weight Matching
(MWM) problem over general graphs. We prove that the algorithm converges
to the correct optimum if the respective LP relaxation  which may include in-
equalities associated with non-intersecting odd-sized cycles  is tight. The most
signiﬁcant part of our approach is the introduction of a novel graph transformation
designed to force convergence of BP. Our theoretical result suggests an efﬁcient
BP-based heuristic for the MWM problem  which consists of making sequential 
“cutting plane”  modiﬁcations to the underlying GM. Our experiments show that
this heuristic performs as well as traditional cutting-plane algorithms using LP
solvers on MWM problems.

1

Introduction

Graphical Models (GMs) provide a useful representation for reasoning in a range of scientiﬁc ﬁelds
[1  2  3  4]. Such models use a graph structure to encode the joint probability distribution  where
vertices correspond to random variables and edges (or lack of thereof) specify conditional depen-
dencies. An important inference task in many applications involving GMs is to ﬁnd the most likely
assignment to the variables in a GM - the maximum a posteriori (MAP) conﬁguration. Belief Prop-
agation (BP) is a popular algorithm for approximately solving the MAP inference problem. BP is
an iterative  message passing algorithm that is exact on tree structured GMs. However  BP often
shows remarkably strong heuristic performance beyond trees  i.e. on GMs with loops. Distributed
implementation  associated ease of programming and strong parallelization potential are among the
main reasons for the popularity of the BP algorithm  e.g.  see the parallel implementations of [5  6].
The convergence and correctness of BP was recently established for a certain class of loopy GM
formulations of several classic combinatorial optimization problems  including matchings [7  8  9] 
perfect matchings [10]  independent sets [11] and network ﬂows [12]. The important common

∗Also at Theoretical Division of Los Alamos National Lab.

1

feature of these instances is that BP converges to a correct MAP assignment when the Linear Pro-
gramming (LP) relaxation of the MAP inference problem is tight  i.e.  it shows no integrality gap.
While this demonstrates that LP tightness is necessary for the convergence and correctness of BP 
it is unfortunately not sufﬁcient in general. In other words  BP may not work even when the corre-
sponding LP relaxation to the MAP inference problem is tight. This motivates a quest for improving
BP-based MAP solvers so that they work when the LP is tight.
In this paper  we consider a speciﬁc class of GMs corresponding to the Maximum Weight Matching
(MWM) problem and study if BP can be used as an iterative  message passing-based LP solver
when the MWM LP (relaxation) is tight. It was recently shown [15] that a MWM can be found in
polynomial time by solving a carefully chosen sequence of LP relaxations  where the sequence of
LPs are formed by adding and removing sets of so-called “blossom” inequalities [13] to the base
LP relaxation. Utilizing successive LP relaxations to solve the MWM problem is an example of
the popular cutting plane method for solving combinatorial optimization problems [14]. While the
approach in [15] is remarkable in that one needs only a polynomial number of “cut” inequalities 
it unfortunately requires solving an emerging sequence of LPs via traditional  centralized methods
(e.g.  ellipsoid  interior-point or simplex) that may not be practical for large-scale problems. This
motivates our search for an efﬁcient and distributed BP-based LP solver for this class of problems.
Our work builds upon that of Sanghavi  Malioutov and Willsky [8]  who studied BP for the GM
formulation of the MWM problem on an arbitrary graph. The authors showed that max-product BP
converges to the correct  MAP solution if the base LP relaxation with no blossom - referred to herein
as MWM-LP - is tight. Unfortunately  the tightness is not guaranteed in general  and the convergence
and correctness for max-product BP do not readily extend to a GM with blossom constraints.
To resolve this issue  we propose a novel GM formulation of the MWM problem and show that max-
product BP on this new GM converges to the MWM assignment as long as the MWM-LP relaxation
with blossom constraints is tight. The only restriction placed on our GM construction is that the
set of blossom constraints added to the base MWM-LP be non-intersecting (in edges). Our GM
construction is motivated by the so-called ‘degree-two’ (DT) condition  which requires that every
variable in the GM be associated to at most two factor functions. The DT condition is necessary
for analysis of BP using the computational tree technique  developed and advanced in [7  8  12  16 
18  19]. Note  that the DT condition is not satisﬁed by the standard MWM GM formulation  and
hence  we design a new GM that satisﬁes the DT condition via a clever graphical transformation -
namely  collapsing odd-sized cycles and deﬁning new weights on the contracted graph. Importantly 
the MAP assignments of the two GMs are in one-to-one correspondence guaranteeing that a solution
to the original problem can be recovered.
Our theoretical result suggests a cutting-plane approach to the MWM problem  where BP is used
as the LP solver. In particular  we examine the BP solution to identify odd-sized cycle constraints
- “cuts” - to add to the MWM-LP relaxation; then construct a new GM using our graphical trans-
formation  run BP and repeat. We evaluate this heuristic empirically and show that its performance
is close to a traditional cutting-plane approach employing an LP solver rather than BP. Finally  we
note that the DT condition may neither be sufﬁcient nor necessary for BP to work. It was necessary 
however  to provide theoretical guarantees for the special class of GMs considered. To our knowl-
edge  our result is the ﬁrst to suggest how to “ﬁx” BP via a graph transformation so that it works
properly  i.e.  recovers the desired LP solution. We believe that our success in crafting a graphical
transformation will offer useful insight into the design and analysis of BP algorithms for a wider
class of problems.
Organization. In Section 2  we introduce a standard GM formulation of the MWM problem as well
as the corresponding BP and LP. In Section 3  we introduce our new GM and describe performance
guarantees of the respective BP algorithm. In Section 4  we describe a cutting-plane(-like) method
using BP for the MWM problem and show its empirical performance for random MWM instances.

2

2 Preliminaries

2.1 Graphical Model for Maximum Weight Matchings
A joint distribution of n (discrete) random variables Z = [Zi] ∈ Ωn is called a Graphical Model
(GM) if it factorizes as follows: for z = [zi] ∈ Ωn 

(1)
where F is a collection of subsets of Ω  zα = [zi : i ∈ α ⊂ Ω] is a subset of variables  and ψα is
some (given) non-negative function. The function ψα is called a factor (variable) function if |α| ≥ 2
(|α| = 1). For variable functions ψα with α = {i}  we simply write ψα = ψi. One calls z a valid
assignment if Pr[Z = z] > 0. The MAP assignment z∗ is deﬁned as

ψα(zα) 

α∈F

Pr[Z = z] ∝ (cid:89)

z∗ = arg max
z∈Ωn

Pr[Z = z].

Let us introduce the Maximum Weight Matching (MWM) problem and its related GM. Suppose we
are given an undirected graph G = (V  E) with weights {we : e ∈ E} assigned to its edges. A
matching is a set of edges without common vertices. The weight of a matching is the sum of cor-
responding edge weights. The MWM problem consists of ﬁnding a matching of maximum weight.
Associate a binary random variable with each edge X = [Xe] ∈ {0  1}|E| and consider the proba-
bility distribution: for x = [xe] ∈ {0  1}|E| 

Pr[X = x] ∝ (cid:89)

ewexe(cid:89)

e∈E

i∈V

ψi(x)

ψC(x) 

(cid:89)
(cid:40)
1 if (cid:80)

C∈C

and

ψC (x) =

0 otherwise

e∈E(C) xe ≤ |C|−1

2

where

ψi(x) =

(cid:40)
1 if (cid:80)

0 otherwise

e∈δ(i) xe ≤ 1

(2)

.

Here C is a set of odd-sized cycles C ⊂ 2V   δ(i) = {(i  j) ∈ E} and E(C) = {(i  j) ∈ E :
i  j ∈ C}. Throughout the manuscript  we assume that cycles are non-intersecting in edges  i.e. 
E(C1) ∩ E(C2) = ∅ for all C1  C2 ∈ C. It is easy to see that a MAP assignment x∗ for the GM (2)
induces a MWM in G. We also assume that the MAP assignment is unique.

2.2 Belief Propagation and Linear Programming for Maximum Weight Matchings

In this section  we introduce max-product Belief Propagation (BP) and the Linear Programming
(LP) relaxation to computing the MAP assignment in (2). We ﬁrst describe the BP algorithm for the
general GM (1)  then tailor the algorithm to the MWM GM (2). The BP algorithm updates the set of
i→α(zi) : zi ∈ Ω} between every variable i and its associated factors
2|Ω| messages {mt
(cid:88)
(cid:89)
α ∈ Fi = {α ∈ F : i ∈ α |α| ≥ 2} using the following update rules:

α→i(zi)  mt

(cid:89)

(cid:48)

and

mt+1

i→α(zi) = ψi(zi)

mt

α(cid:48)→i(zi).

mt

j→α(z

(cid:48)
j)

mt+1

α→i(zi) =

ψα(z

)

z(cid:48):z(cid:48)

i=zi

j∈α\i

Here t denotes time and initially m0
{mi→α(·)  mα→i(·))}  the BP (max-marginal) beliefs {ni(zi)} are deﬁned as follows:

α→i(·) = m0

i→α(·) = 1. Given a set of messages

ni(zi) = ψi(zi)

mα→i(zi).

α∈Fi

For the GM (2)  we let nt
the MAP estimate at time t  xBP(t) = [xBP

e(·) to denote the BP belief on edge e ∈ E at time t. The algorithm outputs
|E|  using the using the beliefs and the rule:

e (t)] ∈ [0  ?  1]

α(cid:48)∈Fi\α

xBP
e (t) =

e(0) < nt
ij(0) = nt
e(0) > nt

e(1)
e(1)
e(1)

.

The LP relaxation to the MAP problem for the GM (2) is:

(cid:88)

C-LP :

max

s.t. (cid:88)

wexe

e∈E
xe ≤ 1 

e∈δ(i)

∀i ∈ V 

xe ≤ |C| − 1

2

∀C ∈ C 

 

xe ∈ [0  1].

(cid:89)
1 if nt
(cid:88)

if nt
?
0 if nt

e∈E(C)

3

Observe that if the solution xC-LP to C-LP is integral  i.e.  xC-LP ∈ {0  1}|E|  then it is a MAP
assignment  i.e.  xC-LP = x∗. Sanghavi  Malioutov and Willsky [8] proved the following theorem
connecting the performance of BP and C-LP in a special case:
Theorem 2.1. If C = ∅ and the solution of C-LP is integral and unique  then xBP(t) under the GM
(2) converges to the MWM assignment x∗.
Adding small random component to every weight guarantees the uniqueness condition required by
Theorem 2.1. A natural hope is that Theorem 2.1 extends to a non-empty C since adding more cycles
can help to reduce the integrality gap of C-LP. However  the theorem does not hold when C (cid:54)= ∅. For
example  BP does not converge for a triangle graph with edge weights {2  1  1} and C consisting of
the only cycle. This is true even though the solution to its C-LP is unique and integral.

3 A Graphical Transformation for Convergent & Correct BP
The loss of convergence and correctness of BP when the MWM LP is tight (and unique) but C (cid:54)= ∅
motivates the work in this section. We resolve the issue by designing a new GM  equivalent to the
original GM  such that when BP is run on this new GM it converges to the MAP/MWM assignment
whenever the LP relaxation is tight and unique - even if C (cid:54)= ∅. The new GM is deﬁned on an
auxiliary graph G(cid:48) = (V (cid:48)  E(cid:48)) with new weights {w(cid:48)

e : e ∈ E(cid:48)}  as follows:

= E ∪ {(iC   j) : j ∈ V (C)  C ∈ C} \ {e : e ∈ ∪C∈CE(C)}

(cid:40) 1

= V ∪ {iC : C ∈ C} 

(cid:80)
e(cid:48)∈E(C)(−1)dC (j e(cid:48))we(cid:48)

E

(cid:48)

2

(cid:48)

V

(cid:48)
e =

w

we

if e = (iC   j)
otherwise

for some C ∈ C

.

Here dC(j  e) is the graph distance of j and e in cycle C = (j1  j2  . . .   jk)  e.g.  if e = (j2  j3) 
then dC(j1  e) = 1.

Figure 1: Example of original graph G (left) and new graph G(cid:48) (right) after collapsing cycle C =
(1  2  3  4  5). In the new graph G(cid:48)  edge weight w1C = 1/2(w12 − w23 + w34 − w45 + w15).

Associate a binary variable with each new edge and consider the new probability distribution on
y = [ye : e ∈ E(cid:48)] ∈ {0  1}|E(cid:48)|:

(cid:89)

C∈C

e∈E(cid:48)

Pr[Y = y] ∝ (cid:89)


ψC (y) =

ew(cid:48)

eye(cid:89)
0 if (cid:80)
0 if (cid:80)

e∈δ(iC )

i∈V

j∈V (C)
1 otherwise

where

ψi(y) =

1 if (cid:80)

e∈δ(i)
0 otherwise

ye ≤ 1

ψi(y)

ψC(y) 

(3)

ye > |C| − 1
(−1)dC (j e)yiC  j /∈ {0  2} for some e ∈ E(C)

.

It is not hard to check that the number of operations required to update messages at each round of
BP under the above GM is O(|V ||E|)  as messages updates involving factor ψC require solving a
MWM problem on a simple cycle – which can be done efﬁciently via dynamic programming in time
O(|C|) – and the summation of the numbers of edges of non-intersecting cycles is at most |E|. We
are now ready to state the main result of this paper.
Theorem 3.1. If the solution of C-LP is integral and unique  then the BP-MAP estimate yBP(t)
under the GM (3) converges to the corresponding MAP assignment y∗. Furthermore  the MWM
assignment x∗ is reconstructible from y∗ as:

(cid:40) 1

2

(cid:80)
j∈V (C)(−1)dC (j e)y∗

iC  j

x∗
e =

y∗

e

if e ∈(cid:83)

otherwise

C∈C E(C)

.

(4)

4

The proof of Theorem 3.1 is provided in the following sections. We also establish the convergence
time of the BP algorithm under the GM (3) (see Lemma 3.2). We stress that the new GM (3) is
designed so that each variable is associated to at most two factor nodes. We call this condition 
which did not hold for the original GM (2)  the ‘degree-two’ (DT) condition. The DT condition
will play a critical role in the proof of Theorem 3.1. We further remark that even under the DT
condition and given tightness/uniqueness of the LP  proving correctness and convergence of BP is
still highly non trivial. In our case  it requires careful study of the computation tree induced by BP
with appropriate truncations at its leaves.

3.1 Main Lemma for Proof of Theorem 3.1

Let us introduce the following auxiliary LP over the new graph and weights.

∀i ∈ V 

ye ∈ [0  1] 

∀e ∈ E

(cid:48)

 

(−1)dC (j e)yiC  j ∈ [0  2] 

∀e ∈ E(C) 

ye ≤ |C| − 1 

∀C ∈ C.

(5)

(6)

(cid:88)

e∈δ(iC )

(cid:88)

(cid:48)
eye

w

e∈E(cid:48)
ye ≤ 1 

C-LP(cid:48)

: max

s.t. (cid:88)
(cid:88)

e∈δ(i)

j∈V (C)

(cid:40)(cid:80)

Consider the following one-to-one linear mapping between x = [xe : e ∈ E] and y = [ye : e ∈ E(cid:48)]:

(cid:40) 1

(cid:80)

xe =

2

j∈V (C)(−1)dC (j e)yiC  j

ye

if e ∈(cid:83)

otherwise

C∈C E(C)

.

ye =

e(cid:48)∈E(C)∩δ(i) xe(cid:48)
xe

if e = (i  iC )
otherwise

Under the mapping  one can check that C-LP = C-LP(cid:48) and if the solution xC-LP of C-LP is unique
= y∗. Hence  (4) in Theorem 3.1
and integral  the solution yC-LP(cid:48)
e ] to C-LP(cid:48) is unique and integral  there exists c > 0
follows. Furthermore  since the solution y∗ = [y∗
such that

of C-LP(cid:48) is as well  i.e.  yC-LP(cid:48)

c =

y(cid:54)=y∗:y is feasible to C-LP(cid:48)

inf

w(cid:48) · (y∗ − y)

|y∗ − y|

 

e]. Using this notation  we establish the following lemma characterizing performance

where w(cid:48) = [w(cid:48)
of the max-product BP over the new GM (3). Theorem 3.1 follows from this lemma directly.
Lemma 3.2. If the solution yC-LP(cid:48)

of C-LP(cid:48) is integral and unique  i.e.  yC-LP(cid:48)

= y∗  then

e[1] > nt

e = 1  nt

• If y∗
• If y∗
e[·] denotes the BP belief of edge e at time t under the GM (3) and w(cid:48)

e[0] for all t > 6w(cid:48)
e[0] for all t > 6w(cid:48)

c + 6 

c + 6 

e = 0  nt

e[1] < nt

max

max

where nt

max = maxe∈E(cid:48) |w(cid:48)
e|.

3.2 Proof of Lemma 3.2
This section provides the complete proof of Lemma 3.2. We focus here on the case of y∗
translation of the result to the opposite case of y∗
assume that nt
the computational tree  using the following scheme:

e = 1  while
e = 0 is straightforward. To derive a contradiction 
e[0] and construct a tree-structured GM Te(t) of depth t + 1  also known as

e[1] ≤ nt

1. Add a copy of Ye ∈ {0  1} as the (root) variable (with variable function ew(cid:48)
2. Repeat the following t times for each leaf variable Ye on the current tree-structured GM.

eYe).

2-1. For each i ∈ V such that e ∈ δ(i) and ψi is not associated to Ye of the current model  add ψi
as a factor (function) with copies of {Ye(cid:48) ∈ {0  1} : e(cid:48) ∈ δ(i) \ e} as child variables (with
corresponding variable functions  i.e.  {ew(cid:48)
2-2. For each C ∈ C such that e ∈ δ(iC ) and ψC is not associated to Ye of the current model  add
ψC as a factor (function) with copies of {Ye(cid:48) ∈ {0  1} : e(cid:48) ∈ δ(iC )\ e} as child variables (with
corresponding variable functions  i.e.  {ew(cid:48)

e(cid:48) Ye(cid:48)}).

e(cid:48) Ye(cid:48)}).

5

It is known from [17] that there exists a MAP conﬁguration yTMAP on Te(t) with yTMAP
= 0 at the
root variable. Now we construct a new assignment yNEW on the computational tree Te(t) as follows.

e

1. Initially  set yNEW ← yTMAP and e is the root of the tree.
2. yNEW ← FLIPe(yNEW).
3. For each child factor ψ  which is equal to ψi (i.e.  e ∈ δ(i)) or ψC (i.e.  e ∈ δ(iC ))  associated with

e 
(a) If ψ is satisﬁed by yNEW and FLIPe(y∗) (i.e.  ψ(yNEW) = ψ(FLIPe(y∗)) = 1)  then do

nothing.

(b) Else if there exists a e’s child e(cid:48) through factor ψ such that yNEW

(cid:54)= y∗
FLIPe(cid:48) (yNEW) and FLIPe(cid:48) (FLIPe(y∗))  then go to the step 2 with e ← e(cid:48).

e(cid:48)

e(cid:48) and ψ is satisﬁed by

(c) Otherwise  report ERROR.

To aid readers understanding  we provide a ﬁgure describing an example of the above construction
in our technical report [21]. In the construction  FLIPe(y) is the 0-1 vector made by ﬂipping (i.e. 
changing from 0 to 1 or 1 to 0) the e’s position in y. We note that there exists exactly one child
factor ψ in step 3 and we only choose one child e(cid:48) in step (b) (even though there are many possible
candidates). Due to this reason  ﬂip operations induce a path structure P in tree Te(t).1 Now we
state the following key lemma for the above construction of yNEW.
Lemma 3.3. ERROR is never reported in the construction described above.

e

e(cid:48) = 0 and ﬂipping yNEW

is ﬂipped as 1 → 0 (i.e.  y∗

Proof. The case when ψ = ψi at the step 3 is easy  and we only provide the proof for the case when
ψ = ψC. We also assume that yNEW
e = 0)  where the proof for the
case 0 → 1 follows in a similar manner. First  one can observe that y satisﬁes ψC if and only if y
is the 0-1 indicator vector of a union of disjoint even paths in the cycle C. Since yNEW
is ﬂipped as
1 → 0  the even path including e is broken into an even (possibly  empty) path and an odd (always 
non-empty) path. We consider two cases: (a) there exists e(cid:48) within the odd path (i.e.  yNEW
e(cid:48) = 1)
as 1 → 0 broke the odd path into two even (disjoint) paths; (b)
such that y∗
there exists no such e(cid:48) within the odd path.
For the ﬁrst case (a)  it is easy to see that we can maintain the structure of disjoint even paths in
as 1 → 0  i.e.  ψ is satisﬁed by FLIPe(cid:48)(yNEW). For the second case (b) 
yNEW after ﬂipping yNEW
we choose e(cid:48) as a neighbor of the farthest end point (from e) in the odd path  i.e.  yNEW
e(cid:48) = 0 (before
e(cid:48) = 1 since y∗ satisﬁes factor ψC and induces a union of disjoint even paths in
ﬂipping). Then  y∗
as 0 → 1  then we can still maintain the structure of disjoint
the cycle C. Therefore  if we ﬂip yNEW
even paths in yNEW  ψ is satisﬁed by FLIPe(cid:48)(yNEW). The proof for the case of the ψ satisﬁed by
FLIPe(cid:48)(FLIPe(y∗)) is similar. This completes the proof of Lemma 3.3.

e(cid:48)

e(cid:48)

e(cid:48)

e

Due to how it is constructed yNEW is a valid conﬁguration  i.e.  it satisﬁes all the factor functions in
Te(t). Hence  it sufﬁces to prove that w(cid:48)(yNEW) > w(cid:48)(yTMAP)  which contradicts to the assumption
that yM AP is a MAP conﬁguration on Te(t). To this end  for (i  j) ∈ E(cid:48)  let n0→1
be the
number of ﬂip operations 0 → 1 and 1 → 0 for copies of (i  j) in the step 2 of the construction of
Te(t). Then  one derives

and n1→0

ij

ij

w(cid:48)(yNEW) = w(cid:48)(yTMAP) + w(cid:48) · n0→1 − w(cid:48) · n1→0 
] and n1→0 = [n1→0

ij

ij

where n0→1 = [n0→1
]. We consider two cases: (i) the path P does not arrive
at a leave variable of Te(t)  and (ii) otherwise. Note that the case (i) is possible only when the
condition in the step (a) holds during the construction of yNEW.
ij − n0→1
Case (i).
Lemma 3.4. y† is feasible to C-LP(cid:48) for small enough ε > 0.
Proof. We have to show that y† satisﬁes (5) and (6). Here  we prove that y† satisﬁes (6) for small
enough ε > 0  and the proof for (5) can be argued in a similar manner. To this end  for given C ∈ C 

)  and establish the following lemma.

In this case  we deﬁne y

ij + ε(n1→0

†
ij := y∗

ij

1P may not have an alternating structure since both yNEW

e

and its child yNEW

e(cid:48)

can be ﬂipped in a same way.

6

(cid:88)

(cid:88)

j∈V (C)

∀j ∈ C 

∀e ∈ E(C).

yiC  j ≤ |C| − 1 

(−1)dC (j e)yiC  j ∈ [0  2] 

C(i) = FLIPe(cid:48)(FLIPe(y∗

we consider the following polytope PC :
yiC  j ∈ [0  1] 
j∈V (C)
†
C = [ye : e ∈ δ(iC)] is within the polytope. It is easy to see that the
We have to show that y
condition of the step (a) never holds if ψ = ψC in the step 3. For the i-th copy of ψC in P ∩ Te(t) 
C(i) ∈ PC. Since the path P does not
we set y∗
(cid:88)N
hit a leave variable of Te(t)  we have

C)) in the step (b)  where y∗

C − n0→1
where N is the number of copies of ψC in P ∩ Te(t). Furthermore  1
C(i) ∈ PC. Therefore  y
y∗
The above lemma with w(cid:48)(y∗) > w(cid:48)(y†) (due to the uniqueness of y∗) implies that w(cid:48) · n0→1 >
w(cid:48) · n1→0  which leads to w(cid:48)(yNEW) > w(cid:48)(yTMAP).

†
C ∈ PC if ε ≤ 1/N. This completes the proof of Lemma 3.4.

(cid:80)N
i=1 y∗

C(i) ∈ PC due to

(cid:0)n1→0

y∗
C(i) = y∗

(cid:1)  

C +

1
N

1
N

i=1

N

C

Case (ii). We consider the case when only one end of P hits a leave variable Ye of Te(t) 
In this case  we deﬁne
where the proof of the other case follows in a similar manner.
‡
] is con-
y
ij
structed as follows:

)  where m1→0 = [m1→0

] and m0→1 = [m0→1

ij − m0→1

ij + ε(m1→0

:= y∗

ij

ij

ij

1. Initially  set m1→0  m0→1 by n1→0  n0→1.

2. If yNEW
m1→0

e
by 1 and

e

is ﬂipped as 1 → 0 and it is associated to a cycle parent factor ψC for some C ∈ C  then decrease

2-1 If the parent yNEW
by 1.
2-2 Else if there exists a ‘brother’ edge e(cid:48)(cid:48) ∈ δ(iC ) of e such that y∗

is ﬂipped from 1 → 0  then decrease m1→0

e(cid:48)

e(cid:48)

FLIPe(cid:48)(cid:48) (FLIPe(cid:48) (y∗))  then increase m0→1
e(cid:48)(cid:48)

by 1.

e(cid:48)(cid:48) = 1 and ψC is satisﬁed by

2-3 Otherwise  report ERROR.

3. If yNEW
e
m1→0
by 1.

e

is ﬂipped as 1 → 0 and it is associated to a vertex parent factor ψi for some i ∈ V   then decrease

4. If yNEW
m0→1
e(cid:48)

  m1→0

e

e

is ﬂipped as 0 → 1 and it is associated to a vertex parent factor ψi for some i ∈ V   then decrease

by 1  where e(cid:48) ∈ δ(i) is the ‘parent’ edge of e  and

4-1 If the parent yNEW

e(cid:48)

is associated to a cycle parent factor ψC 

is ﬂipped from 1 → 0  then decrease m1→0
4-1-1 If the grad-parent yNEW
e(cid:48)(cid:48)
4-1-2 Else if there exists a ‘brother’ edge e(cid:48)(cid:48)(cid:48) ∈ δ(iC ) of e(cid:48) such that y∗
e(cid:48)(cid:48)(cid:48) = 1 and ψC is satisﬁed by

by 1.

e(cid:48)(cid:48)

FLIPe(cid:48)(cid:48)(cid:48) (FLIPe(cid:48)(cid:48) (y∗))  then increase m0→1

e(cid:48)(cid:48)(cid:48) by 1.

4-1-3 Otherwise  report ERROR.

4-2 Otherwise  do nothing.

We establish the following lemmas.
Lemma 3.5. ERROR is never reported in the above construction.
Lemma 3.6. y‡ is feasible to C-LP(cid:48) for small enough ε > 0.
Proofs of Lemma 3.5 and Lemma 3.6 are analogous to those of Lemma 3.3 and Lemma 3.4  respec-
tively. From Lemma 3.6  we have

≤ ε(cid:0)w(cid:48)(m0→1 − m1→0)(cid:1)

ε(t − 3)

≤ ε(cid:0)w(cid:48)(n0→1 − n1→0) + 3w(cid:48)

ε(t − 3)

c ≤ w(cid:48) · (y∗ − y‡)
|y∗ − y‡|

(cid:1)

max

 

where |y∗ − y‡| ≥ ε(t − 3) follows from the fact that P hits a leave variable of Te(t) and there are
at most three increases or decreases in m0→1 and m1→0 in the above construction. Hence 

w(cid:48)(n0→1 − n1→0) ≥ c(t − 3) − 3w(cid:48)

max > 0

if

t >

7

3w(cid:48)
max
c

+ 3 

which implies w(cid:48)(yNEW) > w(cid:48)(yTMAP). If both ends of P hit leave variables of Te(t)  we need
t > 6w(cid:48)

c + 6. This completes the proof of Lemma 3.2.

max

4 Cutting-Plane Algorithm using Belief Propagation

In the previous section we established that BP on a carefully designed GM using non-intersecting
odd-sized cycles solves the MWM problem when the corresponding MWM-LP relaxation is tight.
However  ﬁnding a collection of odd-sized cycles to ensure tightness of the MWM-LP is a challeng-
ing task. In this section  we provide a heuristic algorithm which we call CP-BP (cutting-plane using
BP) for this task. It consists of making sequential  “cutting plane”  modiﬁcations to the underlying
LP (and corresponding GM) using the output of the BP algorithm in the previous step. CP-BP is
deﬁned as follows:

1. Initialize C = ∅.
2. Run BP on the GM in (3) for T iterations

3. For each edge e ∈ E  set ye =

1

if nT
if nT

e [1] > nT
e [1] < nT

0
1/2 otherwise

e [0] and nT−1
e [0] and nT−1

e

e

[1] > nT−1
[1] < nT−1

e

e

[0]
[0]

.

4. Compute x = [xe] using y = [ye] as per (4)  and terminate if x /∈ {0  1/2  1}|E|.
5. If there is no edge e with xe = 1/2  return x. Otherwise  add a non-intersecting odd-sized cycle of
edges {e : xe = 1/2} to C and go to step 2; or terminate if no such cycle exists.

In the above procedure  BP can be replaced by an LP solver to directly obtain x in step 4. This
results in a traditional cutting-plane LP (CP-LP) method for the MWM problem [20]. The primary
reason why we design CP-BP to terminate when x /∈ {0  1/2  1}|E| is because the solution x of
C-LP is always half integral 2. Note that x /∈ {0  1/2  1}|E| occurs when BP fails to ﬁnd the solution
to the current MWM-LP.
We compare CP-BP and CP-LP in order to gauge the effectiveness of BP as an LP solver for MWM
problems. We conducted experiments on two types of synthetically generated problems: 1) Sparse
Graph instances; and 2) Triangulation instances. The sparse graph instances were generated by
forming a complete graph on |V | = {50  100} nodes and independently eliminating edges with
probability p = {0.5  0.9}. Integral weights  drawn uniformly in [1  220]  are assigned to the re-
maining edges. The triangulation instances were generated by randomly placing |V | = {100  200}
points in the 220 × 220 square and computing a Delaunay triangulation on this set of points. Edge
weights were set to the rounded Euclidean distance between two points. A set of 100 instances were
generated for each setting of |V | and CP-BP was run for T = 100 iterations.
The results are summarized in Table 1 and show that: 1) CP-BP is almost as good as CP-LP for
solving the MWM problem; and 2) our graphical transformation allows BP to solve signiﬁcantly
more MWM problems than are solvable by BP run on the ‘bare’ LP without odd-sized cycles.

|V | / |E|
50 / 490
100 / 1963

50 % sparse graphs
# CP-BP
# Tight LPs

94 %
92 %

65 %
48 %

# CP-LP

98 %
95 %

|V | / |E|
50 / 121
100 / 476

90 % sparse graphs
# CP-BP
# Tight LPs

90 %
63 %

59 %
50 %

# CP-LP

91 %
63 %

Triangulation  |V | = 100  |E| = 285
# Correct / # Converged

Triangulation  |V | = 200  |E| = 583
# Correct / # Converged

Algorithm
CP-BP
CP-LP

33 / 36
34 / 100

Time (sec)
0.2 [0.0 0.4]
0.1 [0.0 0.3]

11 / 12
15 / 100

Time (sec)
0.9 [0.2 2.5]
0.8 [0.3 1.6]

Table 1: Evaluation of CP-BP and CP-LP on random MWM instances. Columns # CP-BP and # CP-LP indicate the percentage of instances
in which the cutting plane methods found a MWM. The column # Tight LPs indicates the percentage for which the initial MWM-LP is tight
(i.e. C = ∅). # Correct and # Converged indicate the number of correct matchings and number of instances in which CP-BP converged upon
termination  but we failed to ﬁnd a non-intersecting odd-sized cycle. The Time column indicates the mean [min max] time.

2A proof of 1

2 -integrality  which we did not ﬁnd in the literature  is presented in our technical report [21].

8

References
[1] J. Yedidia  W. Freeman  and Y. Weiss  “Constructing free-energy approximations and general-
ized belief propagation algorithms ” IEEE Transactions on Information Theory  vol. 51  no. 7 
pp. 2282 – 2312  2005.

[2] T. J. Richardson and R. L. Urbanke  Modern Coding Theory. Cambridge University Press 

2008.

[3] M. Mezard and A. Montanari  Information  physics  and computation  ser. Oxford Graduate

Texts. Oxford: Oxford Univ. Press  2009.

[4] M. J. Wainwright and M. I. Jordan  “Graphical models  exponential families  and variational

inference ” Foundations and Trends in Machine Learning  vol. 1  no. 1  pp. 1–305  2008.

[5] J. Gonzalez  Y. Low  and C. Guestrin. “Residual splash for optimally parallelizing belief propa-

gation ” in International Conference on Artiﬁcial Intelligence and Statistics  2009.

[6] Y. Low  J. Gonzalez  A. Kyrola  D. Bickson  C. Guestrin  and J. M. Hellerstein  “GraphLab:
A New Parallel Framework for Machine Learning ” in Conference on Uncertainty in Artiﬁcial
Intelligence (UAI)  2010.

[7] M. Bayati  D. Shah  and M. Sharma  “Max-product for maximum weight matching: Conver-
gence  correctness  and lp duality ” IEEE Transactions on Information Theory  vol. 54  no. 3 
pp. 1241 –1251  2008.

[8] S. Sanghavi  D. Malioutov  and A. Willsky  “Linear Programming Analysis of Loopy Belief
Propagation for Weighted Matching ” in Neural Information Processing Systems (NIPS)  2007
[9] B. Huang  and T. Jebara  “Loopy belief propagation for bipartite maximum weight b-matching ”

in Artiﬁcial Intelligence and Statistics (AISTATS)  2007.

[10] M. Bayati  C. Borgs  J. Chayes  R. Zecchina  “Belief-Propagation for Weighted b-Matchings
on Arbitrary Graphs and its Relation to Linear Programs with Integer Solutions ” SIAM Journal
in Discrete Math  vol. 25  pp. 989–1011  2011.

[11] S. Sanghavi  D. Shah  and A. Willsky  “Message-passing for max-weight independent set ” in

Neural Information Processing Systems (NIPS)  2007.

[12] D. Gamarnik  D. Shah  and Y. Wei  “Belief propagation for min-cost network ﬂow: conver-

gence & correctness ” in SODA  pp. 279–292  2010.

[13] J. Edmonds  “Paths  trees  and ﬂowers”  Canadian Journal of Mathematics  vol. 3  pp. 449–

467  1965.

[14] G. Dantzig  R. Fulkerson  and S. Johnson  “Solution of a large-scale traveling-salesman prob-

lem ” Operations Research  vol. 2  no. 4  pp. 393–410  1954.

[15] K. Chandrasekaran  L. A. Vegh  and S. Vempala. “The cutting plane method is polynomial for

perfect matchings ” in Foundations of Computer Science (FOCS)  2012

[16] R. G. Gallager  “Low Density Parity Check Codes ” MIT Press  Cambridge  MA  1963.
[17] Y. Weiss  “Belief propagation and revision in networks with loops ” MIT AI Laboratory  Tech-

nical Report 1616  1997.

[18] B. J. Frey  and R. Koetter  “Exact inference using the attenuated max-product algorithm ” Ad-
vanced Mean Field Methods: Theory and Practice  ed. Manfred Opper and David Saad  MIT
Press  2000.

[19] Y. Weiss  and W. T. Freeman  “On the Optimality of Solutions of the MaxProduct BeliefProp-
agation Algorithm in Arbitrary Graphs ” IEEE Transactions on Information Theory  vol. 47 
no. 2  pp. 736–744. 2001.

[20] M. Grotschel  and O. Holland  “Solving matching problems with linear programming ” Math-

ematical Programming  vol. 33  no. 3  pp. 243–259. 1985.

[21] J. Shin  A.E. Gelfand  and M. Chertkov  “A Graphical Transformation for Belief Propagation:
Maximum Weight Matchings and Odd-Sized Cycles ” arXiv preprint arXiv:1306.1167 (2013).

9

,Jinwoo Shin
Andrew Gelfand
Misha Chertkov
Isabel Valera
Francisco Ruiz
Lennart Svensson
Muhammad Yousefnezhad
Daoqiang Zhang