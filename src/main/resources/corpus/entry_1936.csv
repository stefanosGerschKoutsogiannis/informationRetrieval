2019,Exploring Algorithmic Fairness in Robust Graph Covering Problems,Fueled by algorithmic advances  AI algorithms are increasingly being deployed in settings subject to unanticipated challenges with complex social effects. Motivated by real-world deployment of AI driven  social-network based suicide prevention and landslide risk management interventions  this paper focuses on a robust graph covering problem subject to group fairness constraints. We show that  in the absence of fairness constraints  state-of-the-art algorithms for the robust graph covering problem result in biased node coverage: they tend to discriminate individuals (nodes) based on membership in traditionally marginalized groups. To remediate this issue  we propose a novel formulation of the robust covering problem with fairness constraints and a tractable approximation scheme applicable to real world instances. We provide a formal analysis of the price of group fairness (PoF) for this problem  where we show that uncertainty can lead to greater PoF. We demonstrate the effectiveness of our approach on several real-world social networks. Our method yields competitive node coverage while significantly improving group fairness relative to state-of-the-art methods.,Exploring Algorithmic Fairness in
Robust Graph Covering Problems

Aida Rahmattalabi ⇤
rahmatta@usc.edu

Phebe Vayanos ⇤

phebe.vayanos@usc.edu

Anthony Fulginiti †

anthony.fulginiti@du.edu

Eric Rice ⇤

ericr@usc.edu

Bryan Wilder ‡

bwilder@g.harvard.edu

Amulya Yadav §
amulya@psu.edu

Milind Tambe ‡

milind_tambe@harvard.edu

Abstract

Fueled by algorithmic advances  AI algorithms are increasingly being deployed in
settings subject to unanticipated challenges with complex social effects. Motivated
by real-world deployment of AI driven  social-network based suicide prevention
and landslide risk management interventions  this paper focuses on robust graph
covering problems subject to group fairness constraints. We show that  in the
absence of fairness constraints  state-of-the-art algorithms for the robust graph cov-
ering problem result in biased node coverage: they tend to discriminate individuals
(nodes) based on membership in traditionally marginalized groups. To mitigate
this issue  we propose a novel formulation of the robust graph covering problem
with group fairness constraints and a tractable approximation scheme applicable to
real-world instances. We provide a formal analysis of the price of group fairness
(PoF) for this problem  where we show that uncertainty can lead to greater PoF. We
demonstrate the effectiveness of our approach on several real-world social networks.
Our method yields competitive node coverage while signiﬁcantly improving group
fairness relative to state-of-the-art methods.

1

Introduction

Motivation. This paper considers the problem of selecting a subset of nodes (which we refer
to as ‘monitors’) in a graph that can ‘cover’ their adjacent nodes. We are mainly motivated by
settings where monitors are subject to failure and we seek to maximize worst-case node coverage.
We refer to this problem as the robust graph covering. This problem ﬁnds applications in several
critical real-world domains  especially in the context of optimizing social interventions on vulnerable
populations. Consider for example the problem of designing Gatekeeper training interventions for
suicide prevention  wherein a small number of individuals can be trained to identify warning signs of
suicide among their peers [32]. A similar problem arises in the context of disaster risk management in
remote communities wherein a moderate number of individuals are recruited in advance and trained to
watch out for others in case of natural hazards (e.g.  in the event of a landslide [40]). Previous research
has shown that social intervention programs of this sort hold great promise [32  40]. Unfortunately 

⇤University of Southern California
†University of Denver
‡Harvard University
§Pennsylvania State University

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

Network Name Network Size Worst-case coverage of individuals by racial group (%)

White Black Hispanic Mixed

SPY1
SPY2
SPY3
MFP1
MFP2

95
117
118
165
182

70
78
88
96
44

36
–
–
77
85

–
42
33
69
70

86
76
95
73
77

Other
94
67
69
28
72

Table 1: Racial discrimination in node coverage resulting from applying the algorithm in [45] on
real-world social networks from two homeless drop-in centers in Los Angeles  CA [4]  when 1/3 of
nodes (individuals) can be selected as monitors  out of which at most 10% will fail. The numbers
correspond to the worst-case percentage of covered nodes across all monitor availability scenarios.

in these real-world domains  intervention agencies often have very limited resources  e.g.  moderate
number of social workers to conduct the intervention  small amount of funding to cover the cost of
training. This makes it essential to target the right set of monitors to cover a maximum number of
nodes in the network. Further  in these interventions  the performance and availability of individuals
(monitors) is unknown and unpredictable. At the same time  robustness is desired to guarantee high
coverage even in worst-case settings to make the approach suitable for deployment in the open world.
Robust graph covering problems similar to the one we consider here have been studied in the literature 
see e.g.  [19  45]. Yet  a major consideration distinguishes our problem from previous work: namely 
the need for fairness. Indeed  when deploying interventions in the open world (especially in sensitive
domains impacting life and death like the ones that motivate this work)  care must be taken to ensure
that algorithms do not discriminate among people with respect to protected characteristics such as
race  ethnicity  disability  etc. In other words  we need to ensure that independently of their group 
individuals have a high chance of being covered  a notion we refer to as group fairness.
To motivate our approach  consider deploying in the open world a state-of-the art algorithm for
robust graph covering (which does not incorporate fairness considerations). Speciﬁcally  we apply
the solutions provided by the algorithm from [45] on ﬁve real-world social networks. The results
are summarized in Table 1 where  for each network  we report its size and the worst-case coverage
by racial group. In all instances  there is signiﬁcant disparity in coverage across racial groups. As
an example  in network SPY1 36% of Black individuals are covered in the worst-case compared to
70% (resp. 86%) of White (resp. Mixed race) individuals. Thus  when maximizing coverage without
fairness  (near-)optimal interventions end up mirroring any differences in degree of connectedness of
different groups. In particular  well-connected groups at the center of the network are more likely to
be covered (protected). Motivated by the desire to support those that are the less well off  we employ
ideas from maximin fairness to improve coverage of those groups that are least likely to be protected.
Proposed Approach and Contributions. We investigate the robust graph covering problem with
fairness constraints. Formally  given a social network  where each node belongs to a group  we
consider the problem of selecting a subset of I nodes (monitors)  when at most J of them may fail.
When a node is chosen as a monitor and does not fail  all of its neighbors are said to be ‘covered’
and we use the term ‘coverage’ to refer to the total number of covered nodes. Our objective is to
maximize worst-case coverage when any J nodes may fail  while ensuring fairness in coverage across
groups. We adopt maximin fairness from the Rawlsian theory of justice [41] as our fairness criterion:
we aim to maximize the utility of the groups that are worse-off. To the best of our knowledge  ours is
the ﬁrst paper enforcing fairness constraints in the context of graph covering subject to node failure.
We make the following contributions: (i) We achieve maximin group fairness by incorporating
constraints inside a robust optimization model  wherein we require that at least a fraction W of
each group is covered  in the worst-case; (ii) We propose a novel two-stage robust optimization
formulation of the problem for which near-optimal conservative approximations can be obtained as a
moderately-sized mixed-integer linear program (MILP). By leveraging the decomposable structure
of the resulting MILP  we propose a Benders’ decomposition algorithm augmented with symmetry
breaking to solve practical problem sizes; (iii) We present the ﬁrst study of price of group fairness
(PoF)  i.e.  the loss in coverage due to fairness constraints in the graph covering problem subject to
node failure. We provide upper bounds on the PoF for Stochastic Block Model networks  a widely

2

studied model of networks with community structure; (iv) Finally  we demonstrate the effectiveness of
our approach on several real-world social networks of homeless youth. Our method yields competitive
node coverage while signiﬁcantly improving group fairness relative to state-of-the-art methods.
Related Work. Our paper relates to three streams of literature which we review.
Algorithmic Fairness. With increase in deployments of AI  OR  and ML algorithms for decision and
policy-making in the open world has come increased interest in algorithmic fairness. A large portion
of this literature is focused on resource allocation systems  see e.g.  [13  33  50]. Group fairness in
particular has been studied in the context of resource allocation problems [22  42  43]. A nascent
stream of work proposes to impose fairness by means of constraints in an optimization problem  an
approach we also follow. This is for example proposed in [1]  and in [8  24]  and in [2] for machine
learning  resource allocation  and matching problems  respectively. Several authors have studied the
price of fairness. In [13]  the authors provide bounds for maximin fair optimization problems. Their
approach is restricted to convex and compact utility sets. In [6]  the authors study price of fairness for
indivisible goods with additive utility functions. In our graph covering problem  this property does not
hold. Several authors have investigated notions of fairness under uncertainty  see e.g  [5  28  36  50].
These papers all assume full distributional information about the uncertain parameters and cannot
be employed in our setting where limited data is available about node availability. Motivated by
data scarcity  we take a robust optimization approach to model uncertainty which does not require
distributional information. This problem is highly intractable due to the combinatorial nature of
both the decision and uncertainty spaces. When fair solutions are hard to compute  “approximately
fair” solutions have been considered [33]. In our work  we adopt an approximation scheme. As
such  our approach falls under the “approximately fair” category. Recently  several authors have
emphasized the importance of fairness when conducting interventions in socially sensitive settings 
see e.g.  [3  34  44]. Our work most closely relates to [44]  wherein the authors propose an algorithmic
framework for fair inﬂuence maximization. We note that  in their work  nodes are not subject to
failure and therefore their approach does not apply in our context.
Submodular Optimization. One can view the group-fair maximum coverage problem as a multi-
objective optimization problem  with the coverage of each community being a separate objective. In
the deterministic case  this problem reduces to the multi-objective submodular optimization prob-
lem [21]  as coverage has the submodularity (diminishing returns) property. In addition  moderately
sized problems of this kind can be solved optimally using integer programming technology. How-
ever  when considering uncertainty in node performance/availability  the objective function loses the
submodularity property while exact techniques fail to scale to even moderate problem sizes. Thus 
existing (exact or approximate) approaches do not apply. Our work more closely relates to the robust
submodular optimization literature. In [19  37]  the authors study the problem of choosing a set of
up to I items  out of which J fail (which encompasses as a special case the robust graph covering
problem without fairness constraints). They propose a greedy algorithm with a constant (0.387)
approximation factor  valid for J = o(pI)  and J = o(I)  respectively. Finally  in [45]  the authors
propose another greedy algorithm with a general bound based on the curvature of the submodular
function. These heuristics  although computationally efﬁcient  are coverage-centered and do not take
fairness into consideration. Thus  they may lead to discriminatory outcomes  see Table 1.
Robust Optimization. Our solution approach closely relates to the robust optimization paradigm which
is a computationally attractive framework for obtaining equivalent or conservative approximations
based on duality theory  see e.g.  [7  10  49]. Indeed  we show that the robust graph covering problem
can be written as a two-stage robust problem with binary second-stage decisions which is highly
intractable in general [14]. One stream of work proposes to restrict the functional form of the recourse
decisions to functions of benign complexity [12  15]. Other works rely on partitioning the uncertainty
set into ﬁnite sets and applying constant decision rules on each partition [15  17  31  38  47]. The last
stream of work investigates the so-called K-adaptability counterpart [11  20  31  39  46]  in which
K candidate policies are chosen in the ﬁrst stage and the best of these policies is selected after the
uncertain parameters are revealed. Our paper most closely relates to [31  39]. In [31]  the authors
show that for bounded polyhedral uncertainty sets  linear two-stage robust optimization problems can
be approximately reformulated as MILPs. Paper [39] extends this result to a special case of discrete
uncertainty sets. We prove that we can leverage this approximation to reformulate robust graph
covering problem with fairness constraints exactly for a much larger class of discrete uncertainty sets.

3

2 Fair and Robust Graph Covering Problem

We model a social network as a directed graph G = (N  E)  in which N := {1  . . .   N} is the set of
all nodes (individuals) and E is the set of all edges (social ties). A directed edge from ⌫ to n exists 
i.e.  (⌫  n) 2E   if node n can be covered by ⌫. We use (n) := {⌫ 2N : (⌫  n) 2E} to denote the
set of neighbors (friends) of n in G  i.e.  the set of nodes that can cover node n. Each node n 2N
is characterized by a set of attributes (protected characteristics) such as age  race  gender  etc.  for
which fair treatment is important. Based on these node characteristics  we partition N into C disjoint
groups Nc  c 2C := {1  . . .   C}  such that [c2CNc = N .
We consider the problem of selecting a set of I nodes from N to act as ‘peer-monitors’ for their
neighbors  given that the availability of each node is unknown a-priori and at most J nodes may fail
(be unavailable). We encode the choice of monitors using a binary vector x of dimension N whose nth
element is one iff the nth node is chosen. We require x 2X := {x 2{ 0  1}N : e>x  I}  where e is
a vector of all ones of appropriate dimension. Accordingly  we encode the (uncertain) node availability
using a binary vector ⇠ of dimension N whose nth element equals one iff node n does not fail (is
available). Given that data available to inform the distribution of ⇠ is typically scarce  we avoid making
distributional assumptions on ⇠. Instead  we view uncertainty as deterministic and set based  in the
spirit of robust optimization [7]. Thus  we assume that ⇠ can take-on any value from the set ⌅ which is
often referred to as the uncertainty set in robust optimization. The set ⌅ may for example conveniently
capture failure rate information. Thus  we require ⇠ 2 ⌅:= {⇠ 2{ 0  1}N : e>(e  ⇠)  J}. A
node n is counted as ‘covered’ if at least one of its neighbors is a monitor and does not fail (is
available). We let yn(x  ⇠) denote if n is covered for the monitor choice x and node availability ⇠.

yn(x  ⇠) := I⇣P⌫2(n) ⇠⌫x⌫  1⌘ .

The coverage is then expressible as FG(x  ⇠) := e>y(x  ⇠). The robust covering problem which
aims to maximize the worst-case (minimum) coverage under node failures can be written as

max
x2X

min
⇠2⌅

FG(x  ⇠).

(RC)

Problem (RC) ignores fairness and may result in discriminatory coverage with respect to (protected)
node attributes   see Table 1. We thus propose to augment the robust covering problem with fairness
constraints. Speciﬁcally  we propose to achieve max-min fairness by imposing fairness constraints on
each group’s coverage: we require that at least a fraction W of nodes from each group be covered.
In [44]  the authors show that by conducting a binary search for the largest W for which fairness
constraints are satisﬁed for all groups  the max-min fairness optimization problem is equivalent to the
one with fairness constraints. Thus  we write the robust covering problem with fairness constraints as

min

x2X

(max

FG c(x  ⇠) : FG c(x  ⇠)  W|Nc|8 c 2C   8⇠ 2 ⌅)  
⇠2⌅ Xc2C
(RCfair)
where FG c(x  ⇠) :=Pn2Nc
yn(x  ⇠) is the coverage of group c 2C . Note that if |C| = 1  Prob-
lem (RCfair) reduces to Problem (RC)  and if ⌅= {e}  Problem (RCfair) reduces to the deterministic
covering problem with fairness constraints. We emphasize that our approach can handle fairness with
respect to more than one protected attribute by either: (a) partitioning the network based on joint
values of the protected attributes and imposing a max-min fairness constraint for each group; or (b)
imposing max-min fairness constraints for each protected attribute separately. Problem (RCfair) is
computationally hard due to the combinatorial nature of both the uncertainty and decision spaces.
Lemma 1 characterizes its complexity. Proofs of all results are in the supplementary document.
Lemma 1. Problem (RCfair) is NP-hard.
3 Price of Group Fairness

In Section 2  we proposed a novel formulation of the robust covering problem incorporating fairness
constraints  Problem (RCfair). Unfortunately  adding fairness constraints to Problem (RC) comes at a
price to overall worst-case coverage. In this section  we study this price of group fairness.

4

Deﬁnition 1. Given a graph G  the Price of Group Fairness PoF(G  I  J) is the ratio of the coverage
loss due to fairness constraints to the maximum coverage in the absence of fairness constraints  i.e. 

PoF(G  I  J) := 1 

OPTfair(G  I  J)
OPT(G  I  J)

 

(1)

where OPTfair(G  I  J) and OPT(G  I  J) denote the optimal objective values of Problems (RCfair)
and (RC)  respectively  when I monitors can be chosen and at most J of them may fail.
In this work  we are motivated by applications related to social networks  where it has been observed
that people with similar (protected) characteristics tend to interact more frequently with one another 
forming friendship groups (communities). This phenomenon  known as homophily [35]  has been
observed for characteristics such as race  gender  education  etc.[23]. This motivates us to study the
PoF in Stochastic Block Model (SBM) networks [27]  a widely accepted model for networks with
community structure. In SBM networks  nodes are partitioned into C disjoint communities Nc  c 2C .
Within each community c  an edge between two nodes is present independently with probability pin
c .
Between a pair of communities c and c0 2C   edges exist independently with probability pout
cc0 and we
typically have pin
cc0 to capture homophily. Thus  SBM networks are very adequate models for
our purpose. We assume w.l.o.g. that the communities are labeled such that: |N1| . . . |N C|.
Deterministic Case. We ﬁrst study the PoF in the deterministic case for which J = 0. Lemma 2
shows that there are worst-case networks for which PoF can be arbitrarily bad.
Lemma 2. Given ✏> 0  there exists a budget I and a network G with N  4
PoF(G  I  0)  1  ✏.
Fortunately  as we will see  this pessimistic result is not representative of the networks that are seen
in practice. We thus investigate the loss in expected coverage due to fairness constraints  given by

✏ + 3 nodes such that

c > pout

PoF(I  J) := 1 

EG⇠SBM[OPTfair(G  I  J)]
EG⇠SBM[OPT(G  I  J)]

.

(2)

We emphasize that we investigate the loss in the expected coverage rather than the expected PoF for
analytical tractability reasons. We make the following assumptions about SBM network.
Assumption 1. For all communities c 2C   the probability of an edge between two individuals in the
community is inversely proportional to the size of the community  i.e.  pin
Assumption 2. For any two communities c  c0 2C   the probability of an edge between two nodes
n 2N c and ⌫ 2N c0 is pout
Assumption 1 is based on the observation that social networks are usually sparse. This means that
most individuals do not form too many links  even if the size of the network is very large. Sparsity
is characterized in the literature by the number of edges being proportional to the number of nodes
which is the direct result of Assumption 1. Assumption 2 is necessary for meaningful community
structure in the network. We now present results for the upper bound on PoF in SBM networks.
Proposition 1. Consider an SBM network model with parameters pin
Assumptions 1 and 2. If I = O(log N )  then

cc0 = O((|Nc| log2 |Nc|)1).

cc0  c  c0 2C   satisfying

c =⇥( |Nc|1).

c and pout

PoF(I  0) = 1 

Pc2C |Nc|

Pc2C |Nc|d(C)/d(c)  o(1)  where d(c) := log |Nc|(log log |Nc|)1.

Proof Sketch. First  we show that under Assumption 1  the coverage within each community is the
sum of the degrees of the monitoring nodes. Then  using the assumption on I in the premise of the
proposition (which can be interpreted as a “small budget assumption”)  we evaluate the maximum
coverage within each community. Next  we show that between-community coverage is negligible
compared to within-community coverage. Thus  we determine the distribution of the monitors  in the
presence and absence of fairness constraints. PoF is computed based on the these two quantities. ⌅
Uncertain Case. Here  imposing fairness is more challenging as we do not know a-priori which
nodes may fail. Thus  we must ensure that fairness constraints are satisﬁed under all failure scenarios.

5

cc0  c  c0 2C   satisfying

Proposition 2. Consider an SBM network model with parameters pin
Assumptions 1 and 2. If I = O(log N )  then

JPc2C\{C} d(c)
(I  J) ⇥ d(C)  o(1) 
where d(c) is as in Proposition 1 and ⌘ := (I  CJ)Pc2C |Nc|/d(c)1.

⌘Pc2C |Nc|
(I  J) ⇥ d(C) 

PoF(I  J) = 1 

c and pout

20

10

)

%

Proof Sketch. The steps of the proof are similar to those in the proof of Proposition 1 with the
difference that  under uncertainty  monitors should be distributed such that the fairness constraints are
satisﬁed even after J nodes fail. Thus  we quantify a minimum number of monitors that should be
allocated to each community. We then determine the worst-case coverage both in the presence and
absence of fairness constraints. PoF is computed based on these two quantities. ⌅
Propositions 1 and 2 show how PoF changes
with the relative sizes of the communities for
the deterministic and uncertain cases  respec-
tively. Our analysis shows that without fairness 
one should place all the monitors in the biggest
community. Under a fair allocation however
monitors are more evenly distributed (although
larger communities still receive a bigger share).
Figure 1 illustrates the PoF results in the case
of two communities for different failure rates
 (J = I )  ignoring the o(.) order terms. We
keep the size of the ﬁrst (smaller) community
ﬁxed and vary the size of the larger community.
In both cases  if |N1| = |N2|  the PoF is zero
since uniform distribution of monitors is opti-
mal. As |N2| increases  the PoF increases in
both cases. Further increases in |N2| result in a
decrease in the PoF for the deterministic case:
under a fair allocation  the bigger community
receives a higher share of monitors which is
aligned with the total coverage objective. Under
uncertainty however  the PoF is non-decreasing:
to guarantee fairness  additional monitors must
be allocated to the smaller groups. This also
explains why PoF increases with .

Figure 1: PoF in the uncertain (top) and determinis-
tic (bottom) settings for SBM networks consisting
of two communities (C = {1  2}) where the size
of the ﬁrst community is ﬁxed at |N1| = 20 and
the size of the other community is increased from
|N2| = 20 to 10  000. In the uncertain setting  
denotes the fraction of nodes that fail.

0
Relative Community Size

γ value
0.4
0.3
0.2
0.1
0

(
 
s
s
e
n
r
i
a
F
p
u
o
r
G

D
e
t
e
r
m
i
n
i
s
t
i
c

U
n
c
e
r
t
a
i
n

0
1.5

 
f
o

 
e
c
i
r
P

100

1.0

0.5

0.0

500

200

300

400

 

4 Solution Approach
Given the intractability of Problem (RCfair)  see Lemma 1  we adopt a conservative approximation
approach. To this end  we proceed in three steps. First  we note that a difﬁculty of Problem (RCfair) is
the discontinuity of its objective function. Thus  we show that (RCfair) can be formulated equivalently
as a two-stage robust optimization problem by introducing a ﬁctitious counting phase after ⇠ is
revealed. Second  we propose to approximate this decision made in the counting phase (which
decides  for each node  whether it is or not covered). Finally  we demonstrate that the resulting
approximate problem can be formulated equivalently as a moderately sized MILP  wherein the
trade-off between suboptimality and tractability can be controlled by a single design parameter.
Equivalent Reformulation. For any given choice of x 2X and ⇠ 2 ⌅  the objective FG(x  ⇠) can
be explicitly expressed as the optimal objective value of a covering problem. As a result  we can
express (RCfair) equivalently as the two-stage linear robust problem

max
x2X

min
⇠2⌅

max

y2Y8<:Xn2N

yn : yn  X⌫2(n)

⇠⌫x⌫  8n 2N 9=;

see Proposition 3 below. The second-stage binary decision variables y 2Y := {y 2{ 0  1}N :
Pn2Nc
yn  W|Nc|  8c 2C} admit a very natural interpretation: at an optimal solution  yn = 1 if
and only if node n is covered. Henceforth  we refer to y as a covering scheme.

 

(3)

6

Deﬁnition 2 (Upward Closed Set). A set X given as a subset of the partially ordered set [0  1]N
equipped with the element-wise inequality  is said to be upward closed if for all x 2X and
¯x 2 [0  1]N such that ¯x  x  it holds that ¯x 2X .
Intuitively  sets involving lower bound constraints on the (sums of) parameters satisfy this deﬁnition.
For example  sets that require a minimum fraction of nodes to be available. We can also consider
group-based availability and require a minimum fraction of nodes to be available in every group.
Assumption 3. We assume that: The set ⌅ is deﬁned through ⌅:= {0  1}N \T for some upward
closed set T given by T := {⇠ 2 RN : A⇠  b}  with A 2 RR⇥N and b 2 RR.
Proposition 3. Problems (RCfair) and (3) are equivalent.
K-adaptability Counterpart. Problem (3) has the advantage of being linear. Yet  its max-min-max
structure precludes us from solving it directly. We investigate a conservative approximation to
Problem (3) referred to as K-adaptability counterpart  wherein K candidate covering schemes are
chosen in the ﬁrst stage and the best (feasible and most accurate) of those candidates is selected after
⇠ is revealed. Formally  the K-adaptability counterpart of Problem (3) is

maximize
yk2Y  k2K

x2X

min
⇠2⌅

max

k2K 8<:Xn2N

yk
n : yk

n  X⌫2(n)

⇠⌫x⌫ 8n 2N 9=;

where yk denotes the kth candidate covering scheme  k 2K . We emphasize that the covering
schemes are not inputs but rather decision variables of the K-adaptability problem. Only the value K
is an input. The optimization problem will identify the best K covering schemes that satisfy all
the constraints including fairness constraints. The trade-off between optimality and computational
complexity of Problem (4) can conveniently be tuned using the single parameter K.
Reformulation as an MILP. We derive an exact reformulation for the K-adaptability counterpart (4)
of the robust covering problem as a moderately sized MILP. Our method extends the results from [39]
to signiﬁcantly more general uncertainty sets that are useful in practice  and to problems involving
constraints on the set of covered nodes. Henceforth  we let L := {0  . . .   N}K  and we deﬁne
L+ := {` 2L : ` > 0} and L0 := {` 2L : ` ⇧ 0}. We present a variant of the generic
K-adaptability Problem (4)  where the uncertainty set ⌅ is parameterized by vectors ` 2L . Each `
is a K-dimensional vector  whose kth component encodes if the kth covering scheme satisﬁes the
constraints of the second stage maximization problem. In this case  `k = 0. Else  if the kth covering
scheme is infeasible  `k is equal to the index of a constraint that is violated.
Theorem 1. Under Assumption 3  Problem (4) is equivalent to the mixed-integer bilinear program

 

(4)

max ⌧
s.t.

+  ⌫(`) 2 RK

+   (`) 2 K(`)

yk
nk

⌧ 2 R  x 2X   yk 2Y 8 k 2K
✓(`)  k(`) 2 RN
+   ↵(`) 2 RR
⌧  e>✓(`) + ↵(`)>b  Xk2K:
`k6=0yk
`k=0 Xn2N
. . . + Xk2K:
✓n(`)  A>↵(`) + Xk2K:
`k6=0 X⌫2(`k)
✓(`) 2 RN
+   ↵(`) 2 RR
+  ⌫(`) 2 RK
1  e>✓(`) + ↵(`)>b  Xk2K:
`k6=0yk
`k6=0 X⌫2(`k)
✓n(`)  A>↵(`) + Xk2K:

+

`k  1 ⌫k(`) + . . .
k(`)Xn2N
n(`) +Xk2K
x⌫⌫k(`)  Xk2K:
`k=0 X⌫2(n)
`k  1 ⌫k(`)

x⌫⌫k(`) 8n 2N

9>>>>>>>=>>>>>>>;

8` 2L + 

yk
n

x⌫k

n(`) 8n 2N

8` 2L 0

9>>>>>>>>>>>>>=>>>>>>>>>>>>>;

(5)

7

which can be reformulated equivalently as an MILP using standard “Big-M” techniques since all
bilinear terms are products continuous and binary variables. The size of this MILP scales with
|L| = (N + 1)K; it is polynomial in all problem inputs for any ﬁxed K.
Proof Sketch. The reformulation relies on three key steps: First  we partition the uncertainty set by
using the parameter `. Next  we show that by relaxing the integrality constraint on the uncertain
parameters ⇠  the problem remains unchanged. This is the key result that enables us to provide an
equivalent formulation for Problem (4). Finally  we employ linear programming duality theory  to
reformulate the robust optimization formulation over each subset. As a result  the formulation has
two sets of decision variable: (a) The decision variables of the original problem; (b) Dual variables
⌅
parameterized by ` which emerge from the dualization.

Bender’s Decomposition. In Problem (5)  once binary variables x and {yk}k2K are ﬁxed  the
problem decomposes across `  i.e.  all remaining variables are real valued and can be found by
solving a linear program for each `. Bender’s decomposition is an exact solution technique that
leverages such decomposable structure for more efﬁcient solution [9  16]. Each iteration of the
algorithm starts with the solution of a relaxed master problem  which is fed into the subproblems to
identify violated constraints to add to the master problem. The process repeats until no more violated
constraints can be identiﬁed. The formulations of master and subproblems are provided in Section E.
Symmetry Breaking Constraints. Problem (5) presents a large amount of symmetry. Indeed 
given K candidate covering schemes y1  . . .   yK  their indices can be permuted to yield another 
distinct  feasible solution with identical cost. The symmetry results in signiﬁcant slow down of
the Brand-and-Bound procedure [18]. Thus  we introduce symmetry breaking constraints in the
formulation (5) that stipulate the candidate covering schemes be lexicographically decreasing. We
refer to [46] for details.

5 Computational Study on Social Networks of Homeless Youth

We evaluate our approach on the ﬁve social networks from Table 1. Details on the data are provided in
Section A. We investigate the robust graph covering problem with maximin racial fairness constraints.
All experiments were ran on a Linux 16GB RAM machine with Gurobi v6.5.0.
First  we compare the performance of our approach against the greedy algorithm of [45] and the
degree centrality heuristic (DC). The results are summarized in Figure 2 (left). From the ﬁgure 
we observe that an increase in K results in an increase in performance along both axes  with a
signiﬁcant jump from K = 1 to K = 2  3 (recall that K controls complexity/optimality trade-off of
our approximation). We note that the gain starts diminishing from K = 2 to K = 3. Thus  we only
run up to K = 3. In addition the computational complexity of the problem increases exponentially
with K  limiting us to increase K beyond 3 for the considered instances. As demonstrated by our
results  K ⇠ 3 was sufﬁcient to considerably improve fairness of the covering at moderate price to
efﬁciency. Compared to the baselines  with K = 3  we signiﬁcantly improve the coverage of the
worse-off group over greedy (resp. DC) by 11% (resp. 23%) on average across the ﬁve instances.
Second  we investigate the effect of uncertainty on the coverage of the worse-off group and on the
PoF  for both the deterministic (J = 0) and uncertain (J > 0) cases as the number of monitors I
is varied in the set {N/3  N/5  N/7}. These settings are motivated by numbers seen in practice
(typically  the number of people that can be invited is 15-20% of network size). Our results are
summarized in Table 2. Indeed  from the table  we see for example that for I = N/3 and J = 0
our approach is able to improve the coverage of the worse-off group by 11-20% and for J > 0 the
improvement in the worse-case coverage of the worse-off group is 7-16%. On the other hand  the
PoF is very small: 0.3% on average for the deterministic case and at most 6.4% for the uncertain case.
These results are consistent across the range of parameters studied. We note that the PoF numbers
also match our analytical results on PoF in that uncertainty generally induces higher PoF.
Third  we perform a head-to-head comparison of our approach for K = 3 with the results in Table 1.
Our ﬁndings are summarized in Table 5 in Section A. As an illustration  in SPY3  the worst-case
coverage by racial group under our approach is: White 90%  Hispanic 44%  Mixed 85% and Other
87%. These numbers suggest that coverage of Hispanics (the worse-off group) has increased from

8

80

70

60

50

40

)

%

(
 
e
g
a
r
e
v
o
C
 
e
s
a
C
−
t
s
r
o
W

Approach

DC
Greedy
K=1
K=2
K=3

d
e
z
i
l
a
m
r
o
N

e
u
l
a
V
 
e
v
i
t
c
e
j
b
O

0.8
0.7
0.6
0.5
0.4
0.3

50

K=1

K=2

K=3

0

2

4

6 0 25 50 75 100 125 0

Solver Time (minutes)

30

60

90

30

20
Worst−Case Coverage of
Worse−Off Group (%)

40

Figure 2: Left ﬁgure: Solution quality (overall worst-case coverage versus worst-case coverage of the
group that is worse-off) for each approach (DC  Greedy  and K-adaptability for K = 1  2  3); The
points represent the results of each approach applied to each of the ﬁve real-world social networks
from Table 1; Each shaded area corresponds to the convex hull of the results associated with each
approach; Approaches that are more fair (resp. efﬁcient) are situated in the right- (resp. top-)most part
of the graph. Right ﬁgure: Average of the ratio of the objective value of the master problem to the
network size (across the ﬁve instances) in dependence of solver time for the Bender’s decomposition
approach (dotted line) and the Bender’s decomposition approach augmented with symmetry breaking
constraints (solid line). For both sets of experiments  the setting was I = N/3 and J = 3.

Improvement in Min. Percentage Covered (%)

PoF (%)

Name

Size N

95
117
118
165
182

SPY1
SPY2
SPY3
MFP1
MFP2
Avg. (I = N/3)
Avg. (I = N/5)
Avg. (I = N/7)

0
15
20
20
17
11
16.6
15.0
12.2

1
16
14
16
15
12
14.6
13.8
11.4

Uncertainty Level J
4
10
8
11
14
12
11.0
9.0
8.2

2
14
9
16
7
10
11.2
14.0
11.2

3
10
10
15
11
9
11.0
10.0
11.4

5
9
10
10
9
12
10.0
6.7
6.4

0
1.4
0.0
0.0
0.0
0.0
0.3
0.6
0.1

Uncertainty Level J
4
1
3.3
1.0
3.6
1.2
3.2
3.4
3.1
6.3
2.4
1.0
3.8
1.9
3.9
2.1
2.5
3.5

3
1.3
3.3
6.4
2.4
2.2
3.1
3.2
3.2

2
2.1
3.7
4.8
5.4
1.0
3.4
3.2
3.5

5
4.2
3.7
4.0
4.4
3.6
4.0
3.8
4.0

Table 2: Improvement on the worst-case coverage of the worse-off group and associated PoF for
each of the ﬁve real-world social networks from Table 1. The ﬁrst ﬁve rows correspond to the setting
I = N/3. In the interest of space  we only show averages for the settings I = N/5 and I = N/7. In
the deterministic case (J = 0)  the PoF is measured relative the coverage of the true optimal solution
(obtained by solving the integer programming formulation of the graph covering problem). In the
uncertain case (J > 0)  the PoF is measured relative to the coverage of the greedy heuristic of [45].

33% to 44%  a signiﬁcant improvement in fairness. To quantify the overall loss due to fairness  we
also compute PoF values. The maximum PoF across all instances was at most 4.2%  see Table 5.
Finally  we investigate the beneﬁts of augmenting our formulation with symmetry breaking constraints.
Thus  we solve all ﬁve instances of our problem with the Bender’s decomposition approach with and
without symmetry breaking constraints. The results are summarized in Figure 2 (right). Across our
experiments  we set a time limit of 2 hours since little improvement was seen beyond that. In all
cases  and in particular for K = 2 and 3  symmetry breaking results in signiﬁcant speed-ups. For
K = 3 (and contrary to Bender’s decomposition augmented with symmetry breaking)  Bender’s
decomposition alone fails to solve the master problem to optimality within the time limit. We would
like to remark that employing K-adaptability is necessary: indeed  Problem (RCfair) would not ﬁt in
memory. Similarly  using Bender’s decomposition is needed: even for moderate values of K (2 to 3) 
the K-adaptability MILP (5) could not be loaded in memory.
Conclusion. We believe that the robust graph covering problem with fairness constraints is worth-
while to investigate. It poses a huge number of challenges and holds great promise in terms of the
realm of possible real-world applications with important potential societal beneﬁts  e.g.  to prevent
suicidal ideation and death and to protect individuals during disasters such as landslides.

9

Acknowledgements

We are grateful to three anonymous referees whose comments helped substantially improve the
quality of this paper. This work was supported by the Smart & Connected Communities program
of the National Science Foundation under NSF award No. 1831770 and by the US Army Research
Ofﬁce under grant number W911NF1710445.

References
[1] Sina Aghaei  Mohammad Javad Azizi  and Phebe Vayanos. Learning optimal and fair deci-
sion trees for non-discriminative decision-making. In Proceedings of the Thirty-Third AAAI
Conference on Artiﬁcial Intelligence  2019.

[2] Faez Ahmed  John P. Dickerson  and Mark Fuge. Diverse weighted bipartite b-matching. In
Proceedings of the 26th International Joint Conference on Artiﬁcial Intelligence  pages 35–41.
AAAI Press  2017.

[3] Mohammad-Javad Azizi  Phebe Vayanos  Bryan Wilder  Eric Rice  and Milind Tambe. De-
signing fair  efﬁcient  and interpretable policies for prioritizing homeless youth for housing
resources. In International Conference on the Integration of Constraint Programming  Artiﬁcial
Intelligence  and Operations Research  pages 35–51. Springer  2018.

[4] Anamika Barman-Adhikari  Stephanie Begun  Eric Rice  Amanda Yoshioka-Maxwell  and
Andrea Perez-Portillo. Sociometric network structure and its association with methamphetamine
use norms among homeless youth. Social science research  58:292–308  2016.

[5] Mohammad-Hossein Bateni  Yiwei Chen  Dragos F. Ciocan  and Vahab Mirrokni. Fair resource
allocation in a volatile marketplace. In Proceedings of the 2016 ACM Conference on Economics
and Computation  pages 819–819. ACM  2016.

[6] Xiaohui Bei  Xinhang Lu  Pasin Manurangsi  and Warut Suksompong. The price of fairness
for indivisible goods. In Proceedings of the Twenty-Eighth International Joint Conference on
Artiﬁcial Intelligence  IJCAI-19  pages 81–87. International Joint Conferences on Artiﬁcial
Intelligence Organization  7 2019.

[7] Aharon Ben-Tal  Laurent El Ghaoui  and Arkadi Nemirovski. Robust optimization  volume 28.

Princeton University Press  2009.

[8] Nawal Benabbou  Mithun Chakraborty  Xuan-Vinh Ho  Jakub Sliwinski  and Yair Zick. Diver-
sity constraints in public housing allocation. In Proceedings of the 17th International Conference
on Autonomous Agents and MultiAgent Systems  pages 973–981. International Foundation for
Autonomous Agents and Multiagent Systems  2018.

[9] Jacques F. Benders. Partitioning procedures for solving mixed-variables programming problems.

Computational Management Science  2(1):3–19  2005.

[10] Dimitris Bertsimas  David B. Brown  and Constantine Caramanis. Theory and applications of

robust optimization. SIAM review  53(3):464–501  2011.

[11] Dimitris Bertsimas and Constantine Caramanis. Finite adaptability in multistage linear opti-

mization. IEEE Transactions on Automatic Control  55(12):2751–2766  2010.

[12] Dimitris Bertsimas and Iain Dunning. Multistage robust mixed-integer optimization with

adaptive partitions. Operations Research  64(4):980–998  2016.

[13] Dimitris Bertsimas  Vivek F Farias  and Nikolaos Trichakis. The price of fairness. Operations

Research  59(1):17–31  2011.

[14] Dimitris Bertsimas and Angelos Georghiou. Design of near optimal decision rules in multistage

adaptive mixed-integer optimization. Operations Research  63(3):610–627  2015.

[15] Dimitris Bertsimas and Angelos Georghiou. Binary decision rules for multistage adaptive

mixed-integer optimization. Mathematical Programming  167(2):395–433  2018.

10

[16] Dimitris Bertsimas and John Tsitsiklis. Introduction to linear programming. Athena Scientiﬁc 

1:997  1997.

[17] Dimitris Bertsimas and Phebe Vayanos. Data-driven learning in dynamic pricing using adaptive

optimization. Optimization Online  2017.

[18] Dimitris Bertsimas and Robert Weismantel. Optimization over integers  volume 13.
[19] Ilija Bogunovic  Slobodan Mitrovi´c  Jonathan Scarlett  and Volkan Cevher. Robust submodular
maximization: A non-uniform partitioning approach. In Proceedings of the 34th International
Conference on Machine Learning-Volume 70  pages 508–516. JMLR. org  2017.

[20] André Chassein  Marc Goerigk  Jannis Kurtz  and Michael Poss. Faster algorithms for min-
max-min robustness for combinatorial problems with budgeted uncertainty. European Journal
of Operational Research  2019.

[21] Chandra Chekuri  Jan Vondrak  and Rico Zenklusen. Dependent randomized rounding via
exchange properties of combinatorial structures. In 2010 IEEE 51st Annual Symposium on
Foundations of Computer Science  pages 575–584. IEEE  2010.

[22] Vincent Conitzer  Rupert Freeman  Nisarg Shah  and Jennifer W. Vaughan. Group fairness for
the allocation of indivisible goods. In Proceedings of the 33rd AAAI Conference on Artiﬁcial
Intelligence (AAAI)  2019.

[23] Sergio Currarini  Matthew O. Jackson  and Paolo Pin. An economic model of friendship:

Homophily  minorities  and segregation. Econometrica  77(4):1003–1045  2009.

[24] Hadi Elzayn  Shahin Jabbari  Christopher Jung  Michael Kearns  Seth Neel  Aaron Roth  and
Zachary Schutzman. Fair algorithms for learning in allocation problems. In Proceedings of the
Conference on Fairness  Accountability  and Transparency  pages 170–179. ACM  2019.

[25] Paul Erd6s. On the evolution of random graphs. Publ. Math. Inst. Hungar. Acad. Sci  5:17–61 

1960.

[26] Uriel Feige. A threshold of ln n for approximating set cover. Journal of the ACM (JACM) 

45(4):634–652  1998.

[27] Stephen E. Fienberg and Stanley S. Wasserman. Categorical data analysis of single sociometric

relations. Sociological methodology  12:156–192  1981.

[28] Benjamin Fish  Ashkan Bashardoust  Danah Boyd  Sorelle Friedler  Carlos Scheidegger  and
Suresh Venkatasubramanian. Gaps in information access in social networks? In The World
Wide Web Conference  pages 480–490. ACM  2019.

[29] Alan Frieze and Michał Karo´nski. Introduction to random graphs. Cambridge University Press 

2016.

[30] Edgar N Gilbert. Random graphs. The Annals of Mathematical Statistics  30(4):1141–1144 

1959.

[31] Grani A. Hanasusanto  Daniel Kuhn  and Wolfram Wiesemann. K-adaptability in two-stage

robust binary programming. Operations Research  63(4):877–891  2015.

[32] Michael Isaac  Brenda Elias  Laurence Y. Katz  Shay-Lee Belik  Frank P. Deane  Murray W.
Enns  Jitender Sareen  and Swampy Cree Suicide Prevention Team (12 members). Gatekeeper
training as a preventative intervention for suicide: a systematic review. The Canadian Journal
of Psychiatry  54(4):260–268  2009.

[33] Jon Kleinberg  Yuval Rabani  and Éva Tardos. Fairness in routing and load balancing. In 40th
Annual Symposium on Foundations of Computer Science (Cat. No. 99CB37039)  pages 568–578.
IEEE  1999.

[34] Amanda Kube  Sanmay Das  and Patrick Fowler. Allocating interventions based on predicted
outcomes: A case study on homelessness services. In Proceedings of the AAAI Conference on
Artiﬁcial Intelligence  2019.

11

[35] Miller McPherson  Lynn Smith-Lovin  and James M. Cook. Birds of a feather: Homophily in

social networks. Annual review of sociology  27(1):415–444  2001.

[36] Kaname Miyagishima. Fair criteria for social decisions under uncertainty. Journal of Mathe-

matical Economics  80:77–87  2019.

[37] James B. Orlin  Andreas Schulz  and Rajan Udwani. Robust monotone submodular func-
tion maximization. In International Conference on Integer Programming and Combinatorial
Optimization  pages 312–324  Waterloo  Canada  2016. Springer.

[38] Krzysztof Postek and Dick den Hertog. Multistage adjustable robust mixed-integer optimization
via iterative splitting of the uncertainty set. INFORMS Journal on Computing  28(3):553–574 
2016.

[39] Aida Rahmattalabi  Phebe Vayanos  and Milind Tambe. A robust optimization approach
In International

to designing near-optimal strategies for constant-sum monitoring games.
Conference on Decision and Game Theory for Security  pages 603–622. Springer  2018.

[40] Ab Rashid Ahmad  Zainal Arsad Md Amin  Che Hassandi Abdullah  and Siti Zarina Ngajam.
Public awareness and education programme for landslide management and evaluation using a
social research approach to determining “acceptable risk” and “tolerable risk” in landslide risk
areas in Malaysia. In Kyoji Sassa  Matjaž Mikoš  and Yueping Yin  editors  Advancing Culture
of Living with Landslides  pages 437–447. Springer International Publishing  2017.

[41] John Rawls. A theory of justice. Harvard university press  2009.
[42] Erel Segal-Halevi and Warut Suksompong. Democratic fair allocation of indivisible goods. In
Proceedings of the 27th International Joint Conference on Artiﬁcial Intelligence  pages 482–488.
AAAI Press  2018.

[43] Warut Suksompong. Approximate maximin shares for groups of agents. Mathematical Social

Sciences  92:40–47  2018.

[44] Alan Tsang  Bryan Wilder  Eric Rice  Milind Tambe  and Yair Zick. Group-fairness in inﬂuence
maximization. In Proceedings of the Twenty-Eighth International Joint Conference on Artiﬁcial
Intelligence  IJCAI-19  pages 5997–6005  2019.

[45] Vasileios Tzoumas  Konstantinos Gatsis  Ali Jadbabaie  and George J Pappas. Resilient mono-
tone submodular function maximization. In 2017 IEEE 56th Annual Conference on Decision
and Control (CDC)  pages 1362–1367. IEEE  2017.

[46] Phebe Vayanos  Angelos Georghiou  and Han Yu. Robust optimization with decision-dependent

information discovery. Available on Optimization Online.

[47] Phebe Vayanos  Daniel Kuhn  and Berç Rustem. Decision rules for information discovery in
multi-stage stochastic programming. In 2011 50th IEEE Conference on Decision and Control
and European Control Conference  pages 7368–7373. IEEE  2011.

[48] Jean Walrand. Lecture notes on probability theory and random processes. 2004.
[49] ˙Ihsan Yanıko˘glu  Bram L. Gorissen  and Dick den Hertog. A survey of adjustable robust

optimization. European Journal of Operational Research  277(3):799–813  2019.

[50] Chongjie Zhang and Julie A. Shah. Fairness in multi-agent sequential decision-making. In
Z. Ghahramani  M. Welling  C. Cortes  N. D. Lawrence  and K. Q. Weinberger  editors  Advances
in Neural Information Processing Systems 27  pages 2636–2644. Curran Associates  Inc.  2014.

12

,Aida Rahmattalabi
Phebe Vayanos
Anthony Fulginiti
Eric Rice
Amulya Yadav
Milind Tambe