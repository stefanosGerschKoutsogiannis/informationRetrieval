2013,Online Learning with Costly Features and Labels,This paper introduces the online probing" problem: In each round  the learner is able to purchase the values of a subset of feature values. After the learner uses this information to come up with a prediction for the given round  he then has the option of paying for seeing the loss that he is evaluated against. Either way  the learner pays for the imperfections of his predictions and whatever he chooses to observe  including the cost of observing the loss function for the given round and the cost of the observed features. We consider two variations of this problem  depending on whether the learner can observe the label for free or not. We provide algorithms and upper and lower bounds on the regret for both variants. We show that a positive cost for observing the label significantly increases the regret of the problem.",Online Learning with Costly Features and Labels

Navid Zolghadr

Department of Computing Science

University of Alberta

zolghadr@ualberta.ca

Department of Computer Science

G´abor Bart´ok

ETH Z¨urich

bartok@inf.ethz.ch

Russell Greiner

Andr´as Gy¨orgy

Csaba Szepesv´ari

Department of Computing Science  University of Alberta
{rgreiner gyorgy szepesva}@ualberta.ca

Abstract

This paper introduces the online probing problem: In each round  the learner is
able to purchase the values of a subset of feature values. After the learner uses
this information to come up with a prediction for the given round  he then has the
option of paying to see the loss function that he is evaluated against. Either way 
the learner pays for both the errors of his predictions and also whatever he chooses
to observe  including the cost of observing the loss function for the given round
and the cost of the observed features. We consider two variations of this problem 
depending on whether the learner can observe the label for free or not. We provide
algorithms and upper and lower bounds on the regret for both variants. We show
that a positive cost for observing the label signiﬁcantly increases the regret of the
problem.

Introduction

1
In this paper  we study a variant of online learning  called online probing  which is motivated by
practical problems where there is a cost to observing the features that may help one’s predictions.
Online probing is a class of online learning problems. Just like in standard online learning problems 
the learner’s goal is to produce a good predictor.
In each time step t  the learner produces his
prediction based on the values of some feature xt = (xt 1  . . .   xt d)> 2X⇢ Rd.1 However  unlike
in the standard online learning settings  if the learner wants to use the value of feature i to produce a
prediction  he has to purchase the value at some ﬁxed  a priori known cost  ci  0. Features whose
value is not purchased in a given round remain unobserved by the learner. Once a prediction ˆyt 2Y
is produced  it is evaluated against a loss function `t : Y! R. At the end of a round  the learner
has the option of purchasing the full loss function  again at a ﬁxed prespeciﬁed cost cd+1  0 (by
default  the loss function is not revealed to the learner). The learner’s performance is measured by his
regret as he competes against some prespeciﬁed set of predictors. Just like the learner  a competing
predictor also needs to purchase the feature values needed in the prediction. If st 2{ 0  1}d+1 is the
indicator vector denoting what the learner purchased in round t (st i = 1 if the learner purchased
xt i for 1  i  d  and purchased the label for i = d + 1) and c 2 [0 1)d+1 denotes the respective
costs  then the regret with respect to a class of prediction functions F⇢{ f | f : X!Y}
is deﬁned
by
`t(f (xt)))  

f2F(Th s(f )  c1:d i +

{`t(ˆyt) + h st  ci}  inf

RT =

where c1:d 2 Rd is the vector obtained from c by dropping its last component and for a given func-
tion f : Rd !Y   s(f ) 2{ 0  1}d is an indicator vector whose ith component indicates whether f
1We use > to denote the transpose of vectors. Throughout  all vectors x2Rd will denote column vectors.

TXt=1

TXt=1

1

is sensitive to its ith input (in particular  si(f ) = 0 by deﬁnition when f (x1  . . .   xi  . . .   xd) =
f (x1  . . .   x0i  . . .   xd) holds for all (x1  . . .   xi  . . .   xd)  (x1  . . .   x0i  . . .   xd) 2X ; otherwise
si(f ) = 1). Note that when deﬁning the best competitor in hindsight  we did not include the cost of
observing the loss function. This is because (i) the reference predictors do not need it; and (ii) if we
did include the cost of observing the loss function for the reference predictors  then the loss of each
predictor would just be increased by cd+1T   and so the regret RT would just be reduced by cd+1T  
making it substantially easier for the learner to achieve sublinear regret. Thus  we prefer the current
regret deﬁnition as it promotes the study of regret when there is a price attached to observing the
loss functions.
To motivate our framework  consider the problem of developing a computer-assisted diagnostic tool
to determine what treatment to apply to a patient in a subpopulation of patients. When a patient
arrives  the computer can order a number of tests that cost money  while other information (e.g.  the
medical record of the patient) is available for free. Based on the available information  the system
chooses a treatment. Following-up the patient may or may not incur additional cost. In this example 
there is typically a delay in obtaining the information whether the treatment was effective. However 
for simplicity  in this work we have decided not to study the effect of this delay. Several works in
the literature show that delays usually increase the regret in a moderate fashion (Mesterharm  2005;
Weinberger and Ordentlich  2006; Agarwal and Duchi  2011; Joulani et al.  2013).
As another example  consider the problem of product testing in a manufacturing process (e.g.  the
production of electronic consumer devices). When the product arrives  it can be subjected to a
large number of diagnostic tests that differ in terms of their costs and effectiveness. The goal is to
predict whether the product is defect-free. Obtaining the ground truth can also be quite expensive 
especially for complex products. The challenge is that the effectiveness of the various tests is often
a priori unknown and that different tests may provide complementary information (meaning that
many tests may be required). . Hence  it might be challenging to decide what form the most cost-
effective diagnostic procedure may take. Yet another example is the problem of developing a cost-
effective way of instrument calibration. In this problem  the goal is to predict one or more real-valued
parameters of some product. Again  various tests with different costs and reliability can be used as
the input to the predictor.
Finally  although we pose the task as an online learning problem  it is easy to show that the proce-
dures we develop can also be used to attack the batch learning problem  when the goal is to learn a
predictor that will be cost-efﬁcient on future data given a database of examples.
Obviously  when observing the loss is costly  the problem is related to active learning. However  to
our best knowledge  the case when observing the features is costly has not been studied before in
the online learning literature. Section 1.1 will discusses the relationship of our work to the existing
literature in more detail.
This paper analyzes two versions of the online problem. In the ﬁrst version  free-label online prob-
ing  there is no cost to seeing the loss function  that is  cd+1 = 0. (The loss function often compares
the predicted value with some label in a known way  in which case learning the value of the label
for the round means that the whole loss function becomes known; hence the choice of the name.)
Thus  the learner naturally will choose to see the loss function after he provides his prediction; this
provides feedback that the learner can use  to improve the predictor he produces. In the second
version  non-free-label online probing  the cost of seeing the loss function is positive: cd+1 > 0.
In Section 2 we study the case of free-label online probing. We give an algorithm that enjoys a regret

of O(p2dLT lnNT (1/(T L))) when the losses are L-equi-Lipschitz (Theorem 2.2)  where NT (")
is the "-covering number of F on sequences of length T . This leads to an ˜O(p2dLT ) regret bound

for typical function classes  such as the class of linear predictors with bounded weights and bounded
inputs. We also show that  in the worst case  the exponential dependence on the dimension cannot
be avoided in the bound. For the special case of linear prediction with quadratic loss  we give an

algorithm whose regret scales only as ˜O(pdt)  a vast improvement in the dependence on d.
The case of non-free-label online probing is treated in Section 3. Here  in contrast to the free-label
case  we prove that the minimax growth rate of the regret is of the order ˜⇥(T 2/3). The increase of
regret-rate stems from the fact that the “best competitor in hindsight” does not have to pay for the
label. In contrast to the previous case  since the label is costly here  if the algorithm decides to see the

2

label it does not even have to reason about which features to observe  as querying the label requires
paying a cost that is a constant over the cost of the best predictor in hindsight  already resulting in
the ˜⇥(T 2/3) regret rate. However  in practice (for shorter horizons) it still makes sense to select the
features that provide the best balance between the feature-cost and the prediction loss. Although we
do not study this  we note that by combining the algorithmic ideas developed for the free-label case
with the ideas developed for the non-free-label case  it is possible to derive an algorithm that reasons
actively about the cost of observing the features  too.
In the part dealing with the free-label problem  we build heavily on the results of Mannor and
Shamir (2011)  while in the part dealing with the non-free-label problem we build on the ideas of
(Cesa-Bianchi et al.  2006). Due to space limitations  all of our proofs are relegated to the appendix.

1.1 Related Work

This paper analyzes online learning when features (and perhaps labels) have to be purchased. The
standard “batch learning” framework has a pure explore phase  which gives the learner a set of
labeled  completely speciﬁed examples  followed by a pure exploit phase  where the learned pre-
dictor is asked to predict the label for novel instances. Notice the learner is not required (nor even
allowed) to decide which information to gather. By contrast  “active (batch) learning” requires
the learner to identify that information (Settles  2009). Most such active learners begin with com-
pletely speciﬁed  but unlabeled instances; they then purchase labels for a subset of the instances.
Our model  however  requires the learner to purchase feature values as well. This is similar to the
“active feature-purchasing learning” framework (Lizotte et al.  2003). This is extended in Kapoor
and Greiner (2005) to a version that requires the eventual predictor (as well as the learner) to pay
to see feature values as well. However  these are still in the batch framework: after gathering the
information  the learner produces a predictor  which is not changed afterwards.
Our problem is an online problem over multiple rounds  where at each round the learner is required
to predict the label for the current example. Standard online learning algorithms typically assume
that each example is given with all the features. For example  Cesa-Bianchi et al. (2005) provided
upper and lower bounds on the regret where the learner is given all the features for each example 
but must pay for any labels he requests. In our problem  the learner must pay to see the values of
the features of each example as well as the cost to obtain its true label at each round. This cost
model means there is an advantage to ﬁnding a predictor that involves few features  as long as it
is sufﬁciently accurate. The challenge  of course  is ﬁnding these relevant features  which happens
during this online learning process.
Other works  in particular Rostamizadeh et al. (2011) and Dekel et al. (2010)  assume the features
of different examples might be corrupted  missed  or partially observed due to various problems 
such as failure in sensors gathering these features. Having such missing features is realistic in many
applications. Rostamizadeh et al. (2011) provided an algorithm for this task in the online settings 

with optimal O(pT ) regret where T is the number of rounds. Our model differs from this model as

in our case the learner has the option to obtain the values of only the subset of the features that he
selects.

2 Free-Label Probing
In this section we consider the case when the cost of observing the loss function is zero. Thus 
we can assume without loss of generality that the learner receives the loss function at the end of
each round (i.e.  st d+1 = 1). We will ﬁrst consider the general setting where the only restriction is
that the losses are equi-Lipschitz and the function set F has a ﬁnite empirical worst-case covering
number. Then we consider the special case where the set of competitors are the linear predictors and
the losses are quadratic.

2.1 The Case of Lipschitz losses

In this section we assume that the loss functions  `t  are Lipschitz with a known  common Lipschitz
constant L over Y w.r.t. to some semi-metric dY of Y: for all t  1
y y02Y |`t(y)  `t(y0)| L dY (y  y0).

sup

(1)

3

Clearly  the problem is an instance of prediction with expert advice under partial information feed-
back (Auer et al.  2002)  where each expert corresponds to an element of F. Note that  if the learner
chooses to observe the values of some features  then he will also be able to evaluate the losses of
all the predictors f 2F that use only these selected features. This can be formalized as follows:
By a slight abuse of notation let st 2{ 0  1}d be the indicator showing the features selected by
the learner at time t (here we drop the last element of st as st d1 is always 1); similarly  we will
drop the last coordinate of the cost vector c throughout this section. Then  the learner can com-
pute the loss of any predictor f 2F such that s(f )  st  where  denotes the conjunction of the
component-wise comparison. However  for some loss functions  it may be possible to estimate the
losses of other predictors  too. We will exploit this when we study some interesting special cases of
the general problem. However  in general  it is not possible to infer the losses for functions such that
st i < s(f )i for some i (cf. Theorem 2.3).
The idea is to study ﬁrst the case when F is ﬁnite and then reduce the general case to the ﬁnite case
by considering appropriate ﬁnite coverings of the space F. The regret will then depend on how the
covering numbers of the space F behave.
Mannor and Shamir (2011) studied problems similar to this in a general framework  where in ad-
dition to the loss of the selected predictor (expert)  the losses of some other predictors are also
communicated to the learner in every round. The connection between the predictors is represented
by a directed graph whose nodes are labeled as elements of F (i.e.  as the experts) and there is an
edge from f 2F to g 2F if  when choosing f  the loss of g is also revealed to the learner. It is
assumed that the graph of any round t  Gt = (F  Et) becomes known to the learner at the beginning
of the round. Further  it is also assumed that (f  f ) 2 Et for every t  1 and f 2F . Mannor
and Shamir (2011) gave an algorithm  called ELP (exponential weights with linear programming) 
to solve this problem  which calls the Exponential Weights algorithm  but modiﬁes it to explore
less  exploiting the information structure of the problem. The exploration distribution is found by
solving a linear program  explaining the name of the algorithm. The regret of ELP is analyzed in the
following theorem.
Theorem 2.1 (Mannor and Shamir 2011). Consider a prediction with expert advice problem over
F where in round t  Gt = (F  Et) is the directed graph that encodes which losses become available
to the learner. Assume that for any t  1  at most (Gt) cliques of Gt can cover all vertices of Gt.
Let B be a bound on the non-negative losses `t: maxt1 f2F `t(f (xt))  B. Then  there exists
a constant CELP > 0 such that for any T > 0  the regret of Algorithm 2 (shown in the Appendix)
when competing against the best predictor using ELP satisﬁes

E[RT ]  CELPBvuut(ln|F|)

TXt=1
The algorithm’s computational cost in any given round is poly(|F|).
.
= {(f  g)| s(g)  s(f )}. Then clearly  (Gt)  2d. Further 
For a ﬁnite F  deﬁne Et ⌘ E
.
= C1 + `max (i.e.  C1 = kc1:dk1). Plugging these into (2) gives
B = kc1:dk1 + maxt1 y2Y `t(y)
(3)

E[RT ]  CELP(C1 + `max)q2dT ln|F| .

To apply this algorithm in the case when F is inﬁnite  we have to approximate F with a ﬁnite
set F0 ⇢{ f | f : X !Y} . The worst-case maximum approximation error of F using F0 over
sequences of length T can be deﬁned as

(Gt) .

(2)

AT (F0 F) = max
x2X T

sup
f2F

inf
f02F0

1
T

TXt=1

dY (f (xt)  f0(xt)) + h (s(f0)  s(f ))+  c1:d i  

where (s(f0)s(f ))+ denotes the coordinate-wise positive part of s(f0)s(f )  that is  the indicator
vector of the features used by f0 and not used by f. The average error can also be viewed as a
(normalized) dY-“distance” between the vectors (f (xt))1tT and (f0(xt))1tT penalized with
the extra feature costs. For a given positive number ↵  deﬁne the worst-case empirical covering
number of F at level ↵ and horizon T > 0 by

NT (F ↵ ) = min{ |F0| | F0 ⇢{ f | f : X !Y}   AT (F0 F)  ↵}.

4

We are going to apply the ELP algorithm to F0 and apply (3) to obtain a regret bound. If f0 uses
more features than f then the cost-penalized distance between f0 and f is bounded from below by
the cost of observing the extra features. This means that unless the problem is very special  F0 has
to contain  for all s 2{ s(f )| f 2F}   some f0 with s(f0) = s. Thus  if F contains a function for
all s 2{ 0  1}d  (Gt) = 2d. Selecting a covering F0 that achieves accuracy ↵  the approximation
error becomes T L↵ (using equation 1)  giving the following bound:
Theorem 2.2. Assume that the losses (`t)t1 are L-Lipschitz (cf. (1)) and ↵> 0. Then  there exists
an algorithm such that for any T > 0  knowing T   the regret satisﬁes

In particular  by choosing ↵ = 1/(T L)  we have

E[RT ]  CELP(C1 + `max)q2dT lnNT (F ↵ ) + T L↵.
E[RT ]  CELP(C1 + `max)q2dT lnNT (F  1/(T L)) + 1 .

We note in passing that the the dependence of the algorithm on the time horizon T can be alleviated 
using  for example  the doubling trick.
In order to turn the above bound into a concrete bound  one must investigate the behavior of the
metric entropy  lnNT (F ↵ ). In many cases  the metric entropy can be bounded independently of
T . In fact  often  lnNT (F ↵ ) = D ln(1 + c/↵) for some c  D > 0. When this holds  D is often
called the “dimension” of F and we get that

E [RT ]  CELP(C1 + `max)q2dT D ln(1 + cT L) + 1 .

As a speciﬁc example  we will consider the case of real-valued linear functions over a ball in a
Euclidean space with weights belonging to some other ball. For a normed vector space V with norm
k·k and dual norm k·k ⇤  x 2 V   r  0  let Bk·k(x  r) = {v 2 V |k vk  r} denote the ball in V
centered at x that has radius r. For X⇢ Rd  W⇢ Rd  let
(4)
be the space of linear mappings from X to reals with weights belonging to W. We have the following
lemma:
Lemma 2.1. Let X  W > 0  dY (y  y0) = |y  y0|  X⇢ Bk·k(0  X) and W⇢ Bk·k⇤
(0  W ).
Consider a set of real-valued linear predictors F⇢ Lin(X  W). Then  for any ↵> 0 

.
= {g : X! R| g(·) = h w ·i   w 2W}

F⇢ Lin(X  W)

lnNT (F ↵ )  d ln(1 + 2W X/↵).

The previous lemma  together with Theorem 2.2 immediately gives the following result:
Corollary 2.1. Assume that F⇢ Lin(X  W)  X⇢ Bk·k(0  X)  W⇢ Bk·k⇤
(0  W ) for some
X  W > 0. Further  assume that the losses (`t)t1 are L-Lipschitz. Then  there exists an algorithm
such that for any T > 0  the regret of the algorithm satisﬁes 
E [RT ]  CELP(C1 + `max)qd2dT ln(1 + 2T LW X) + 1 .

Note that if one is given an a priori bound p on the maximum number of features that can be used
in a single round (allowing the algorithm to use fewer than p  but not more features) then 2d in

i ⇡ dp  where the approximation assumes that

the above bound could be replaced byP1ipd

p < d/2. Such a bound on the number of features available per round may arise from strict bud-
getary considerations. When dp is small  this makes the bound non-vacuous even for small horizons
T . In addition  in such cases the algorithm also becomes computationally feasible. It remains an
interesting open question to study the computational complexity when there is no restriction on the
number of features used. In the next theorem  however  we show that the worst-case exponential
dependence of the regret on the number of features cannot be improved (while keeping the root-T
dependence on the horizon). The bound is based on the lower bound construction of Mannor and
Shamir (2011)  which reduces the problem to known lower bounds in the multi-armed bandit case.
Theorem 2.3. There exist an instance of free-label online probing such that the minimax regret of

any algorithm is ⌦⇣q d

d/2T⌘.

5

2.2 Linear Prediction with Quadratic Losses

In this section  we study the problem under the assumption that the predictors have a linear form and
the loss functions are quadratic. That is  F⇢ Lin(X  W) where W = {w 2 Rd |k wk⇤  wlim}
and X = {x 2 Rd |k xk  xlim} for some given constants wlim  xlim > 0  while `t(y) = (y  yt)2 
where |yt| xlimwlim. Thus  choosing a predictor is akin to selecting a weight vector wt 2W  
as well as a binary vector st 2G⇢{
0  1}d that encodes the features to be used in round t. The
prediction for round t is then ˆyt = h wt  st  xt i  where  denotes coordinate-wise product  while
the loss suffered is (ˆytyt)2. The set G is an arbitrary non-empty  a priori speciﬁed subset of {0  1}d
that allows the user of the algorithm to encode extra constraints on what subsets of features can be
selected.
In this section we show that in this case a regret bound of size ˜O(ppoly(d)T ) is possible. The key
idea that permits the improvement of the regret bound is that a randomized choice of a weight vector
Wt (and thus  of a subset) helps one construct unbiased estimates of the losses `t(h w  s  xt i)
for all weight vectors w and all subsets s 2G under some mild conditions on the distribution of
Wt. That the construction of such unbiased estimates is possible  despite that some feature values
are unobserved  is because of the special algebraic structure of the prediction and loss functions.
A similar construction has appeared in a different context  e.g.  in the paper of Cesa-Bianchi et al.
(2010).
The construction works as follows. Deﬁne the d⇥d matrix  Xt by (Xt)i j = xt ixt j (1  i  j  d).
Expanding the loss of the prediction ˆyt = h w  xt i  we get that the loss of using w 2W is

`t(w)

.
= `t(h w  xt i) = w>Xt w  2 w>xtyt + y2
t  

where with a slight abuse of notation we have introduced the loss function `t : W! R (we’ll keep
abusing the use of `t by overloading it based on the type of its argument). Clearly  it sufﬁces to
construct unbiased estimates of `t(w) for any w 2W .
We will use a discretization approach. Therefore  assume that we are given a ﬁnite subset W0 of
W that will be constructed later. In each step t  our algorithm will choose a random weight vector
Wt from a probability distribution supported on W0. Let pt(w) be the probability of selecting the
weight vector  w 2W 0. For 1  i  d  let

be the probability that s(Wt) will contain i  while for 1  i  j  d  let

qt(i) = Xw2W0:i2s(w)
qt(i  j) = Xw2W0:i j2s(w)

pt(w)  

pt(w)  

 

qt(i)

qt(i  j)

be the probability that both i  j 2 s(Wt).2 Assume that pt(·) is constructed such that qt(i  j) > 0
holds for any time t and indices 1  i  j  d. This also implies that qt(i) > 0 for all 1  i  d.
Deﬁne the vector ˜xt 2 Rd and matrix ˜Xt 2 Rd⇥d using the following equations:
( ˜Xt)i j = {i j2s(Wt)}xt ixt j
.
It can be readily veriﬁed that E [˜xt | pt] = xt and Eh ˜Xt | pti = Xt. Further  notice that both ˜xt

and ˜Xt can be computed based on the information available at the end of round t  i.e.  based on the
feature values (xt i)i2s(Wt). Now  deﬁne the estimate of prediction loss

˜xt i = {i2s(Wt)}xt i

˜`t(w) = w> ˜Xt w  2 w> ˜xtyt + y2
t .

(6)
Note that yt can be readily computed from `t(·)  which is available to the algorithm (equivalently 
we may assume that the algorithm observed yt). Due to the linearity of expectation  we have
Eh˜`t(w)|pti = `t(w). That is  ˜`t(w) provides an unbiased estimate of the loss `t(w) for any
w 2W . Hence  by adding a feature cost term we get ˜`t(w) + h s(w)  ci as an estimate of the loss
that the learner would have suffered at round t had he chosen the weight vector w.
2Note that  following our earlier suggestion  we view the d-dimensional binary vectors as subsets of

(5)

{1  . . .   d}.

6

Algorithm 1 The LQDEXP3 Algorithm

Parameters: Real numbers 0  ⌘  0 <  1  W0 ⇢W ﬁnite set  a distribution µ over W0 
horizon T > 0.
Initialization: u1(w) = 1 (w 2W 0).
for t = 1 to T do

Draw Wt 2W 0 from the probability mass function

ut(w)

Ut

+ µ(w) 

w 2W 0 .

pt(w) = (1  )
Obtain the features values  (xt i)i2s(Wt).
Predict ˆyt =Pi2s(Wt) wt ixt i.
for w 2W 0 do

Update the weights using (6) for the deﬁnitions of ˜`t(w):

ut+1(w) = ut(w)e⌘(˜`t(w)+h c s(w) i)  w 2W 0 .

end for

end for

2.2.1 LQDExp3 – A Discretization-based Algorithm
Next we show that the standard EXP3 Algorithm applied to a discretization of the weight space W
achieves O(pdT ) regret. The algorithm  called LQDEXP3 is given as Algorithm 1. In the name
of the algorithm  LQ stands for linear prediction with quadratic losses and D denotes discretization.
Note that if the exploration distribution µ in the algorithm is such that for any 1  i  j  d 
Pw2W 0:i j2s(w) µ(w) > 0 then qt(i  j) > 0 will be guaranteed for all time steps. Using the notation
ylim = wlimxlim and EG = maxs2G supw2W:kwk⇤=1 kw  sk⇤  we can state the following regret
bound on the algorithm
Theorem 2.4. Let wlim  xlim > 0  c 2 [0 1)d be given  W⇢ Bk·k⇤
(0  wlim) convex  X⇢
Bk·k(0  xlim) and ﬁx T  1. Then  there exist a parameter setting for LQDEXP3 such that the
following holds: Let RT denote the regret of LQDEXP3 against the best linear predictor from
Lin(W X ) when LQDEXP3 is used in an online free-label probing problem deﬁned with the se-
quence ((xt  yt))1tT (kxtk  xlim  |yt| ylim  1  t  T )  quadratic losses `t(y) = (y  yt)2 
and feature-costs given by the vector c. Then 

E [RT ]  CqT d (4y2

lim + kck1)(w2

limx2

lim + 2ylimwlimxlim + 4y2

lim + kck1) ln(EGT )  

where C > 0 is a universal constant (i.e.  the value of C does not depend on the problem parame-
ters).

The actual parameter setting to be used with the algorithm is constructed in the proof. The compu-
tational complexity of LQDEXP3 is exponential in the dimension d due to the discretization step 
hence quickly becomes impractical when the number of features is large. On the other hand  one
can easily modify the algorithm to run without discretization by replacing EXP3 with its continuous
version. The resulting algorithm enjoys essentially the same regret bound  and can be implemented
efﬁciently whenever efﬁcient sampling is possible from the resulting distribution. This approach
seems to be appealing  since  from a ﬁrst look  it seems to involve sampling from truncated Gaus-
sian distributions  which can be done efﬁciently. However  it is easy to see that when the sampling
probabilities of some feature are small  the estimated loss will not be convex as ˜Xt may not be pos-
itive semi-deﬁnite  and therefore the resulting distributions will not always be truncated Gaussians.
Finding an efﬁcient sampling procedure for such situations is an interesting open problem.
The optimality of LQDEXP3 can be seen by the following lower bound on the regret:
Theorem 2.5. Let d > 0  and consider the online free label probing problem with linear predictors 
where W = {w 2 Rd |k wk1  wlim} and X = {x 2 Rd |k xk1  1}. Assume  for all t  1 
that the loss functions are of the form `t(w) = (w>xt  yt)2 + h s(w)  ci  where |yt| 1 and
c = 1/2 ⇥ 1 2 Rd. Then  for any prediction algorithm and for any T 
8 ln(4/3)  there exists a

4d

7

sequence ((xt  yt))1tT 2 (X⇥ [1  1])T such that the regret of the algorithm can be bounded
from below as

E[RT ] 

3 Non-Free-Label Probing

pT d .

p2  1
p32 ln(4/3)

If cd+1 > 0  the learner has to pay for observing the true label. This scenario is very similar to the
well-known label-efﬁcient prediction case in online learning (Cesa-Bianchi et al.  2006). In fact 
the latter problem is a special case of this problem  immediately giving us that the regret of any
algorithm is at least of order T 2/3. It turns out that if one observes the (costly) label in a given round
then it does not effect the regret rate if one observes all the features at the same time. The resulting
“revealing action algorithm”  given in Algorithm 3 in the Appendix  achieves the following regret
bound for ﬁnite expert classes:
Lemma 3.1. Given any non-free-label online probing with ﬁnitely many experts  Algorithm 3 with
appropriately set parameters achieves

E[RT ]  C max⇣T 2/3(`2

maxkck1 ln|F|)1/3 ` maxpT ln|F|⌘

for some constant C > 0.

Using the fact that  in the linear prediction case  approximately (2T LW X + 1)d experts are needed
to approximate each expert in W with precision ↵ = 1
LT in worst-case empirical covering  we obtain
the following theorem (note  however  that the complexity of the algorithm is again exponential in
the dimension d  as we need to keep a weight for each expert):
Theorem 3.1. Given any non-free-label online probing with linear predictor experts and Lipschitz
prediction loss function with constant L  Algorithm 3 with appropriately set parameters running on
a sufﬁciently discretized predictor set achieves

E[RT ]  C max⇣T 2/3⇥`2

for some universal constant C > 0.

maxkck1 d ln(T LW X)⇤1/3

 ` maxpT d ln(T LW X)⌘

That Algorithm 3 is essentially optimal for linear predictions and quadratic losses is a consequence
of the following almost matching lower bound:
Theorem 3.2. There exists a constant C such that  for any non-free-label probing with linear pre-
i=1 ci  1/2d for every j = 1  . . .   d  the expected regret

dictors  quadratic loss  and cj > (1/d)Pd

of any algorithm can be lower bounded by

E[RT ]  C(cd+1d)1/3T 2/3 .

4 Conclusions

We introduced a new problem called online probing. In this problem  the learner has the option
of choosing the subset of features he wants to observe as well as the option of observing the true
label  but has to pay for this information. This setup produced new challenges in solving the online
problem. We showed that when the labels are free  it is possible to devise algorithms with optimal
regret rate ⇥(pT ) (up to logarithmic factors)  while in the non-free-label case we showed that only
⇥(T 2/3) is achievable. We gave algorithms that achieve the optimal regret rate (up to logarithmic
factors) when the number of experts is ﬁnite or in the case of linear prediction. Unfortunately either
our bounds or the computational complexity of the corresponding algorithms are exponential in
the problem dimension  and it is an open problem whether these disadvantages can be eliminated
simultaneously.

Acknowledgements

The authors thank Yevgeny Seldin for ﬁnding a bug in an earlier version of the paper. This work was
supported in part by DARPA grant MSEE FA8650-11-1-7156  the Alberta Innovates Technology
Futures  AICML  and the Natural Sciences and Engineering Research Council (NSERC) of Canada.

8

References
Agarwal  A. and Duchi  J. C. (2011). Distributed delayed stochastic optimization. In Shawe-Taylor 
J.  Zemel  R. S.  Bartlett  P. L.  Pereira  F. C. N.  and Weinberger  K. Q.  editors  NIPS  pages
873–881.

Auer  P.  Cesa-Bianchi  N.  Freund  Y.  and Schapire  R. E. (2002). The nonstochastic multiarmed

bandit problem. SIAM J. Comput.  32(1):48–77.

Bart´ok  G. (2012). The role of information in online learning. PhD thesis  Department of Computing

Science  University of Alberta.

Cesa-Bianchi  N. and Lugosi  G. (2006). Prediction  learning  and games. Cambridge Univ Pr.
Cesa-Bianchi  N.  Lugosi  G.  and Stoltz  G. (2005). Minimizing regret with label efﬁcient predic-

tion. IEEE Transactions on Information Theory  51(6):2152–2162.

Cesa-Bianchi  N.  Lugosi  G.  and Stoltz  G. (2006). Regret minimization under partial monitoring.

Math. Oper. Res.  31(3):562–580.

Cesa-Bianchi  N.  Shalev-Shwartz  S.  and Shamir  O. (2010). Efﬁcient learning with partially ob-

served attributes. CoRR  abs/1004.4421.

Dekel  O.  Shamir  O.  and Xiao  L. (2010). Learning to classify with missing and corrupted features.

Machine Learning  81(2):149–178.

Joulani  P.  Gy¨orgy  A.  and Szepesv´ari  C. (2013). Online learning under delayed feedback. In 30th

International Conference on Machine Learning  Atlanta  GA  USA.

Kapoor  A. and Greiner  R. (2005). Learning and classifying under hard budgets.

Conference on Machine Learning (ECML)  pages 166–173.

In European

Lizotte  D.  Madani  O.  and Greiner  R. (2003). Budgeted learning of naive-Bayes classiﬁers. In

Conference on Uncertainty in Artiﬁcial Intelligence (UAI).

Mannor  S. and Shamir  O. (2011). From bandits to experts: On the value of side-observations.

CoRR  abs/1106.2436.

Mesterharm  C. (2005). On-line learning with delayed label feedback. In Proceedings of the 16th
international conference on Algorithmic Learning Theory  ALT’05  pages 399–413  Berlin  Hei-
delberg. Springer-Verlag.

Rostamizadeh  A.  Agarwal  A.  and Bartlett  P. L. (2011). Learning with missing features. In UAI 

pages 635–642.

Settles  B. (2009). Active learning literature survey. Technical report.
Weinberger  M. J. and Ordentlich  E. (2006). On delayed prediction of individual sequences. IEEE

Trans. Inf. Theor.  48(7):1959–1976.

9

,Navid Zolghadr
Gabor Bartok
Russell Greiner
András György
Csaba Szepesvari
Nisheeth Srivastava
Ed Vul
Paul Schrater
Sashank J. Reddi
Suvrit Sra
Barnabas Poczos
Alexander Smola
Zhengyang Shen
Francois-Xavier Vialard
Marc Niethammer