2017,Expectation Propagation with Stochastic Kinetic Model in Complex Interaction Systems,Technological breakthroughs allow us to collect data with increasing spatio-temporal resolution from complex interaction systems. The combination of high-resolution observations  expressive dynamic models  and efficient machine learning algorithms can lead to crucial insights into complex interaction dynamics and the functions of these systems. In this paper  we formulate the dynamics of a complex interacting network as a stochastic process driven by a sequence of events  and develop expectation propagation algorithms to make inferences from noisy observations. To avoid getting stuck at a local optimum  we formulate the problem of minimizing Bethe free energy as a constrained primal problem and take advantage of the concavity of dual problem in the feasible domain of dual variables guaranteed by duality theorem. Our expectation propagation algorithms demonstrate better performance in inferring the interaction dynamics in complex transportation networks than competing models such as particle filter  extended Kalman filter  and deep neural networks.,Expectation Propagation with Stochastic Kinetic

Model in Complex Interaction Systems

Le Fang  Fan Yang  Wen Dong  Tong Guan  and Chunming Qiao

Department of Computer Science and Engineering

{lefang  fyang24  wendong  tongguan  qiao}@buffalo.edu

University at Buffalo

Abstract

Technological breakthroughs allow us to collect data with increasing spatio-
temporal resolution from complex interaction systems. The combination of high-
resolution observations  expressive dynamic models  and efﬁcient machine learning
algorithms can lead to crucial insights into complex interaction dynamics and the
functions of these systems. In this paper  we formulate the dynamics of a complex
interacting network as a stochastic process driven by a sequence of events  and
develop expectation propagation algorithms to make inferences from noisy obser-
vations. To avoid getting stuck at a local optimum  we formulate the problem of
minimizing Bethe free energy as a constrained primal problem and take advantage
of the concavity of dual problem in the feasible domain of dual variables guar-
anteed by duality theorem. Our expectation propagation algorithms demonstrate
better performance in inferring the interaction dynamics in complex transportation
networks than competing models such as particle ﬁlter  extended Kalman ﬁlter  and
deep neural networks.

1

Introduction

We live in a complex world  where many collective systems are difﬁcult to interpret. In this paper 
we are interested in complex interaction systems  also called complex interaction networks  which
are large systems of simple units linked by a network of interactions. Many research topics exem-
plify complex interaction systems in speciﬁc domains  such as neural activities in our brain  the
movement of people in an urban system  epidemic and opinion dynamics in social networks  and so
on. Modeling and inference for dynamics on these systems has attracted considerable interest since
it potentially provides valuable new insights  for example about functional areas of the brain and
relevant diagnoses[7]  about trafﬁc congestion and more efﬁcient use of roads [19]  and about where 
when and to what extent people are infected in an epidemic crisis [23]. Agent-based modeling and
simulation [22] is a classical way to address complex systems with interacting components to explore
general collective rules and principles  especially in the ﬁeld of systems biology. However  the actual
underlying dynamics of a speciﬁc real system are not in the scope. People are not satisﬁed with only
a macroscopic general description but aims to track down an evolving system.
Unprecedented opportunities for researchers in these ﬁelds have recently emerged due to the pros-
perous of social media and sensor tools. For instance  the functional magnetic resonance imaging
(fMRI) and the electroencephalogram (EEG) can directly measure brain activity  something never
possible before. Similarly  signal sensing technologies can now easily track people’s movement and
interactions [12  24]. Researchers no longer need to worry about acquiring abundant observation
data  and instead are pursuing more powerful theoretical tools to grasp the opportunities afforded by
that data. We  in the machine learning community  are interested in the inference problem — that is

31st Conference on Neural Information Processing Systems (NIPS 2017)  Long Beach  CA  USA.

recovering the hidden dynamics of a system given certain observations. However  challenges still
exist in these efforts  especially when facing systems with a large number of components.
Statistical inference on complex interaction systems has a close relationship with the statistical physics
of disordered ensembles  for instance  the established equivalence between loopy belief propagation
and the Bethe free energy formulation [25]. In the past  the main interaction between statistical physics
and statistical inference has focused on building stationary and equilibrium probability distributions
over the state of a system. However  temporal dynamics is omitted when only equilibrium state
is pursued. This leads not only to the loss of a signiﬁcant amount of interesting information  but
possibly also to qualitatively wrong conclusions. In terms of learning dynamics  one approach is
to solve stochastic differential equations (SDE) [20]. In each SDE  at least one term belongs to a
stochastic process  of which the most common is the Wiener process. The drift and diffusion terms in
these SDEs are what we need to recover from multiple realizations (sample paths) of the stochastic
process. Typically  an assumption of constant diffusion and linear drift makes the problem tractable 
but realistic dynamics generally cannot be modeled by rigid SDEs with simple assumptions.
Inference on complex interaction systems naturally corresponds to inference on large graphical
models  which is a classical topic in machine learning. Exact ﬁltering and smoothing algorithms
are impractical due to the exploding computational cost to make inferences about complex systems.
The hidden Markov model [17] faces an exponentially exploding size of the state transition kernel.
The Kalman ﬁlter [15] and its variants  such as the extended Kalman ﬁlter [14]  solves the linear or
nonlinear estimation problem assuming that the latent and observed variables are jointly Gaussian
distributions. Its scalability versus the number of components is O(M 3) due to the time cost in
matrix operations.
Approximate algorithms to make inferences with complex interaction systems can be divided roughly
into sampling-based and optimization-based methods. Among sampling based methods  particle ﬁlter
and smoother [4  18] use particles to represent the posterior distribution of a stochastic process given
noisy observations. However  particle based methods show weak scalability in a complex system: a
large number of particles is needed  even in moderate size complex systems where the number of
components becomes over thousands. A variety of Markov Chain Monte Carlo (MCMC) methods
have been proposed [6  5]  but these generally have issues with rapid convergence in high-dimension
systems. Among optimization based methods  expectation propagation (EP) [16  13] refers to a
family of approximate inference algorithms with local marginal projection. These methods adopt an
iterative approach to approximate each factor of the target distribution into a tractable family. EP
methods have been shown to be relatively efﬁcient  faster than sampling in many low-dimension
examples[16  13]. The equivalence between the EP energy minimization and Bethe free energy
minimization is justiﬁed [16]. Researches propose “double loop” algorithm to minimize Bethe free
energy [13] in order to digest the non-convex term in the objective. They formulate a saddle point
problem where strictly speaking the inner loop should be converged before moving to the outer
loop. However  the stability of saddle points is an issue in general. There are also ad hoc energy
optimization methods for speciﬁc network structures  for instance [21] for binary networks  but the
generality of these methods is unknown.
In this paper  we present new formulation of EP and apply it to solve the inference problem in
general large complex interaction systems. This paper makes the following contributions. First  we
formulated expectation propagation as an optimization problem to maximize a concave dual function 
where its local maximum is also its global maximum and provides a solution for Bethe free energy
minimization problem. To this end  we transformed concave terms in the Bethe free energy into
its Legendre dual and added regularization constraint to the primal problem. Second  we designed
gradient ascent and ﬁxed point algorithms to make inferences about complex interaction systems
with the stochastic kinetic model. In all the algorithms we make mean-ﬁeld inferences about the
individual components from observations about them according to the average interactions of all other
components. Third  we conducted experiments on our transportation network data to demonstrate
the performance of our proposed algorithms over the state of the art algorithms in inferring complex
network dynamics from noisy observations.
The remainder of this paper is organized as follows. In Section 2  we brieﬂy review some models
to specify complex system dynamics and the issues in minimizing Bethe free energy. In Section 3 
we formulate the problem of minimizing Bethe free energy as maximizing a concave dual function
satisfying dual feasible constraint  and develop gradient-based and ﬁxed-point methods to make

2

tractable inferences with the stochastic kinetic model. In Section 4  we detail empirical results from
applying the proposed algorithms to make inferences about transportation network dynamics. Section
5 concludes.

2 Background

In this section  we provide brief background about describing complex system dynamics and typical
issues in minimizing Bethe free energy.

2.1 Dynamic Bayesian Network and State-Space Model

t

t

t

t

t

t

  y(2)

| x(m)

m p(y(m)

1  ...  x(M )

) be the values and yt = (y(1)

t p(xt | xt−1)(cid:81)

path with observations p(x1 ...T   y1 ...T ) can be written as p(x1 ...T   y1 ...T ) =(cid:81)
xt) = (cid:81)

A dynamic Bayesian network (DBN) captures the dynamics of a complex interaction system by
specifying how the values of state variables at the current time are probabilistically dependent on
the values at previous time. Let xt = (x(1)
  ...  y(M )
)
be the observations made at these M state variables at time t. The probability measure of sample
t p(xt | xt−1)p(yt |
)  where p(xt | xt−1) is the state transition model and
p(yt | xt) is observation model. We can factorize state transition into miniature kernels involving
). The DBN inference problem is to infer p(xt | y1 ...T )
only variable x(m)
for given observations y1 ...T .
State-space models (SSM) use state variables to describe a system by a set of ﬁrst-order differential or
difference equations. For example  the state evolves as xt = Ftxt−1 + wt and we make observations
with yt = Htxt + vt. Typical ﬁltering and smoothing algorithms estimate series of xt from time
series of yt.
Both DBM and SSM face difﬁculties in directly capturing the complex interactions  since these
interactions seldom obey simple rigid equations and are too complex to be expressed by a joint
transition kernel  even allowing time-variance of such kernel. The SKM model that follows uses a
sequence of events to capture such nonlinear and time-variant dynamics.

and its parents Pa(x(m)

t

t

2.2 Stochastic Kinetic Model

The stochastic kinetic model (SKM) [9  23] has been successfully applied in many ﬁelds  especially
chemistry and system biology [1  22  8]. It describes the dynamics with chemical reactions occurring
stochastically at an adaptive rate. By analogy with a chemical reaction system  we consider a complex
interaction system involving M system components (species) and V types of events (reactions).
Generally  the system forms a Markov jump process [9] with a ﬁnite set of discrete events. Each
event v can be characterized by a “chemical equation”:

v X (M ) → p(1)
and p(m)

r(1)
v X (1) + ... + r(M )

v X (1) + ... + p(M )

v X (M )

(1)

where X (m) denotes the m-th component  r(m)
and products. Let x(m)
species at time t  an event will change populations (x(1)
r(2)
v   ...  p(M )
hv(xt  cv) is a function of the current state:

count the (relative) quantities of reactants
be the population count (or continuous number as concentration) of m
v −
). Events occur mutually independently of each other and each event rate

) by ∆v = (p(1)

v − r(M )

v − r(1)

  ...  x(M )

v   p(2)

  x(2)

v

v

v

t

t

t

t

(M )(cid:89)
where cv denotes the rate constant and(cid:81)(M )

hv(xt  cv) = cv

m=1

m=1

(M )(cid:89)

(cid:18)x(m)

(cid:19)

t
r(m)
v

g(m)
v

(x(m)

) = cv

t

(cid:0)x(m)

t
r(m)
v

m=1

(cid:1) counts the number of different ways for the

(2)

components to meet and trigger an event. When we consider time steps 1  2  .  t  ..T with sufﬁciently
small time interval τ  the probability of two or more events happening in the interval is negligible
[11]. Consider a sample path p(x1 ...T   v2 ...T   y1 ...T ) of the system with the sequence of states

3

x1  . . .   xT   happened events v2  . . .   vT and observations y1  . . .   yT . We can express the event-
based state transition kernel P (xt  vt|xt−1) in terms of event rate hv(xt  cv):

P (xt  vt|xt−1) = I (xt = xt−1 + ∆vtand xt ∈ (xmin  xmax)) · P (vt|xt−1)
= I (xt = xt−1 + ∆vtand xt ∈ (xmin  xmax)) ·

(cid:26)τ hv(xt−1  cv)
1 −(cid:80)

v τ hv(xt−1  cv)

if vt = v
if vt = ∅

(3)

where ∅ represents a null event that none of those V events happens and states don’t change; I(·)
is the indicator function; xmin  xmax are respectively lower bound and upper bound vectors  which
prohibit “ghost” transitions between out-of-scope xt−1 and xt. For instance  we generally need
to bound xt be non-negative in realistic complex systems. This natural constraint on xt leads to a
linearly truncated state space that realistic events lie.
Instead of state transitions possibly from any state to any other in DBN and state updates with a linear
(or nonlinear) transformation  state in the SKM evolves according to ﬁnite number of events between
time steps. The transition kernel is dependent on underlying system state and so is adaptive for
capturing the underlying system dynamics. We can now consider the inference problem of complex
interaction systems in the context of general DBN  with a speciﬁc event-based transition kernel from
SKM.

2.3 Bethe Free Energy

(cid:90)

t

dxtqt(xt) log qt(xt)

(cid:90)

t

minimize FBethe =

dxt−1 t ˆpt(xt−1 t) log

ˆpt(xt−1 t)
ψ(xt−1 t)

In general DBN  the expectation propagation algorithm to make inference aims to minimize Bethe
free energy FBethe [16  25  13]  subject to moment matching constraints. We have a non-convex prime
objective and its trivial dual function with dual variables in the full space is not concave. We take
the general notation that potential function is ψ(xt−1 t) = P (xt  yt | xt−1) and our optimization
problem becomes the following

subject to : (cid:104)f (xt)(cid:105) ˆpt(xt−1 t) = (cid:104)f (xt)(cid:105)qt(xt) = (cid:104)f (xt)(cid:105) ˆpt+1(xt t+1)

−(cid:88)
(cid:88)
t f (xt))+log(cid:82) dxt exp((αt+βt)(cid:62)f (xt))
t log(cid:82) dxt−1 t exp(α(cid:62)
maximize FDual = −(cid:80)
random variable xt to its statistics. Integrals (cid:104)f (xt)(cid:105) ˆpt(xt−1 t) =(cid:82) dxtf (xt)(cid:82) dxt−1 ˆpt(xt−1 t) and
In the above  ˆpt(xt−1 t) ≈ p(xt−1 t|y1 ···  T ) are approximate two-slice probabilities  qt(xt) ≈
p(xt|y1 ···  T ) are approximate one-slice probabilities. The vector-valued function f (xt) maps a
(or K-L divergence) between the approximate distribution(cid:81)
p(x1 ···  T|y1 ···  T ) =(cid:81)

so on are the mean parameters to be matched in the optimization. FBethe is the relative entropy
and the true distribution
t ψ(xt−1 t) to be minimized. With the method of Lagrange multipliers  one
can ﬁnd that ˆpt(xt−1 t) and qt(xt) are distributions in the exponential family parameterized either by
the mean parameters (cid:104)f (xt)(cid:105) ˆpt(xt−1 t) and (cid:104)f (xt)(cid:105)qt(xt) or by the natural parameters αt−1 and βt 
and the trivial dual target FDual is the negative log partition of the dynamic Bayesian network.
The problem with minimizing FBethe or maximizing FDual is that both have multiple local op-
tima and there is no guarantee how closely a local optimal solution approximates the true pos-
ψ(xt−1 t) is a convex term 

t−1f (xt−1))ψ(xt−1 t) exp(β(cid:62)

t

terior probability of the latent state. In FBethe (cid:82) dxt−1 t ˆpt(xt−1 t) log ˆpt(xt−1 t)
−(cid:80)

(cid:82) dxtqt(xt) log qt(xt) is concave  and the sum is not guaranteed to be convex. Similarly in

FDual  the minus log partition function of ˆpt (ﬁrst term) is concave  the log partition function of qt is
convex  and the sum is not guaranteed to be concave.
Another difﬁculty with expectation propagation is that the approximate probability distribution often
needs to satisfy some inequality constraints. For example  when approximating a target probability
distribution with the product of normal distributions in Gaussian expectation propagation  we require
that all factor normal distributions have positive variance. So far  the common heuristic is to set the
variances to very large numbers once they fall below zero.

ˆpt(xt−1 t)

t

qt(xt)

4

3 Methodology

As noted in Subsection 2.3  the difﬁculty in minimizing Bethe free energy is that both the FPrimal
and FDual have many local optima in the full space. Our formulation starts with transforming the
concave term to its Legendre dual and taking dual variables as additional variables. Thereafter we
drop the dependence over qt(xt) by utilizing the moment matching constraints  formulate EP as
a constrained minimization problem and derive its dual optimization problem (which is concave
under a dual feasible constraint). Our formulation also provides theoretical insights to avoid negative
variance in Gaussian expectation propagation.
We start by minimizing the Bethe free energy over the two-slice probabilities ˆpt and the one-slice
probabilities qt:

minimize over ˆpt(xt−1 t)  qt(xt) :

(cid:90)

(cid:88)

dxt−1 t ˆpt(xt−1 t) log

FBethe =
(cid:90)
subject to : (cid:104)f (xt)(cid:105) ˆpt(xt−1 t) = (cid:104)f (xt)(cid:105)qt(xt) = (cid:104)f (xt)(cid:105) ˆpt+1(xt t+1)  

(cid:90)

t

t

ˆpt(xt−1 t)
ψ(xt−1 t)

dxtqt(xt) log qt(xt)

(cid:90)

−(cid:88)

dxtqt(x) = 1 =

dxt−1 t ˆpt(xt−1 t).

We introduce the Legendre dual −(cid:82) dxtqt log qt= minγt
and replace (cid:104)f (xt)(cid:105)q(xt)
(cid:104)f (xt)(cid:105) ˆpt(xt−1 t) = (cid:104)f (xt)(cid:105)qt(xt).
we add a regularization constraint to bound it:
minimize over ˆpt(xt−1 t)  γt :

(cid:111)
· f (xt))
in the target with (cid:104)f (xt)(cid:105) ˆpt(xt−1 t) by utilizing the constraint
Instead of searching γt over the over-complete full space 

+ log(cid:82) dxt exp(γ(cid:62)

(cid:110)−γ(cid:62)

· (cid:104)f (xt)(cid:105)qt

(4)

t

t

−(cid:88)

t

γ(cid:62)

t

· (cid:104)f (xt)(cid:105) ˆpt
(cid:90)

(cid:90)

log

(cid:88)

t

+

dxt exp(γ(cid:62)

t

· f (xt))

FPrimal =

dxt−1 t ˆpt log

ˆpt(xt−1 t)
ψ(xt−1 t)

(cid:90)

(cid:88)

t

subject to : (cid:104)f (xt)(cid:105) ˆpt(xt−1 t) = (cid:104)f (xt)(cid:105) ˆpt+1(xt t+1)  

dxt−1 t ˆpt(xt−1 t) = 1  γ(cid:62)

t γt ≤ ηt.

(5)

t f (xt))/(cid:82) dxt exp(γ(cid:62)

t

In the primal problem  γt is the natural parameter of a probability in the exponential family: q(x; γt) =
· f (xt)). The primal problem (5) is equivalent with Bethe energy
exp(γ(cid:62)
minimization problem.
We solve the primal problem with the Lagrange duality theorem [3]. First  we deﬁne the La-
grangian function L by introducing the Lagrange multipliers αt  λt and ξt to incorporate the con-
straints. Second  we set the derivative over prime variables to zero. Third  we plug the optimum
point back into the Lagrangian. The Lagrange duality theorem implies that FDual(αt  λt  ξt) =
inf ˆpt(xt−1 t) γtL(ˆpt(xt−1 t)  γt  αt  λt  ξt). Thus the dual problem is as follows

FDual = −(cid:88)

maximize over αt  λt ≥ 0 for all t :
log

log Zt−1 t +

(cid:90)

dxt exp(γ(cid:62)

t f (xt)) +

(cid:88)

t

λt
2

(cid:0)γ(cid:62)

t γt − ηt

(cid:1)

(cid:88)
+ (cid:104)f (xt)(cid:105)γt
exp(α(cid:62)

t

t

where − (cid:104)f (xt)(cid:105) ˆpt
ˆpt(xt−1 t) =

1

Zt−1 t

+ λtγt = 0

t−1 · f (xt−1))ψ(xt−1 t) exp((γ(cid:62)

t − α(cid:62)

t ) · f (xt))

(6)

(7)

(8)

In the dual problem  we drop the dual variable ξt since it takes value to normalize ˆpt(xt−1 t) as a
valid primal probability. For any dual variable αt  λt  we map primal variables ˆpt(xt−1 t) and γt
as implicit functions deﬁned by the extreme point conditions Eq. (7) (8). We have the following
theoretic guarantee with proofs in the supplementary material. We name covγt (f (xt)  f (xt)) +

λtI −(cid:10)f (xt) · f (xt)(cid:62)(cid:11)

ˆpt(xt−1 t) (cid:31) 0 as the dual feasible constraint.

5

Proposition 1: The Lagrangian function has positive deﬁnite Hessian matrix under the dual
feasible constraint.

Proposition 1 ensures that the dual function is inﬁmum of Lagrangian function  the point wise
inﬁmum of a family of afﬁne functions of αt  λt  ξt  thus is concave. Instead of a full space of dual
variables αt  λt  we only consider the domain constrained by the dual feasible constraint.

Proposition 2: Eq. (7) and (8) have an unique solution under the dual feasible constraint.

The Lagrange dual problem is a maximization problem with a bounded domain  which can be reduced
to an unconstrained problem through barrier method or through penalizing constraint violation  and
be solved with a gradient ascent algorithm or a ﬁxed point algorithm. The partial derivatives of the
dual function over dual variables are the following:

(cid:0)γ(cid:62)

(cid:1)

∂FDual
∂αt

= −(cid:104)f (xt)(cid:105) ˆpt+1(xt t+1) + (cid:104)f (xt)(cid:105) ˆpt(xt−1 t)  

∂FDual

∂λt

=

1
2

t γt − ηt

(9)

t

set

t + γ

= α(old)

∂FDual
∂αt

= 0 ⇒forward:α(new)

where ˆpt(xt−1 t) and γt are implicit functions deﬁned by Eq. (7) (8). We can get a ﬁxed point
iteration through setting the ﬁrst derivatives to zero 1. Here γ(·) converts mean parameters to natural
parameters.

(cid:16)(cid:104)f (xt)(cid:105) ˆpt
(cid:17) − γ(old)
(cid:17)
(cid:16)(cid:104)f (xt)(cid:105) ˆpt+1
distributions  which pose implicit constraints on the primal and dual domains. Let(cid:80)
covariance matrix associated with ˆpt(xt−1 t)  γt and it requires(cid:80)
(cid:31) 0 (cid:80)
(cid:31) 0  covγt (f (xt)  f (xt)) + λtI −(cid:10)f (xt) · f (xt)(cid:62)(cid:11)

In terms of Gaussian EP  the prime variables ˆpt(xt−1 t)  γt correspond to multivariate Gaussian
be the
(cid:31) 0. The domain of

dual variables is deﬁned by the following constraints:

backward:γ(new)

 (cid:80)

ˆpt(xt−1 t) (cid:31) 0

= γ

γt

γt

ˆpt

ˆpt

t

t

(cid:31) 0 

(cid:88)

(cid:88)
λt ≥ 0 
+ (cid:104)f (xt)(cid:105)γt
where − (cid:104)f (xt)(cid:105) ˆpt
exp(α(cid:62)
ˆpt(xt−1 t) =

γt

ˆpt

1

Zt−1 t

+ λtγt = 0

t−1 · f (xt−1))P (xt  yt|xt−1) exp((γ(cid:62)

t − α(cid:62)

t ) · f (xt))

In this case  it is nontrivial to ﬁnd a starting point of αt  λt. We develop a phase I stage to ﬁnd a
strictly feasible starting point [3]. For convenience  we note αt  λt as x  rewrite above constraints
as inequality constraints gi(x) ≤ 0 and equality constraints gj(x) = 0. Start from a valid x0  s that
gi(x0) ≤ s gj(x0) = 0 and then solve the optimization problem

minimize s subject to gj(x0) = 0  gi(x0) ≤ s

over the variable s and x. The strict feasible point of x will be found when we arrive s < 0.
With the duality framework and SKM  we can solve the dual optimization problem to make inferences
about complex system dynamics from imperfect observations. The latent states (the populations in
SKM) can be formulated as either categorical or Gaussian random variables. In categorical case  the
max) ··· ) 
statistics are f (xt) = (I(x(1)
where x(1)
max are the maximum populations and I is the indicator function. In the Gaussian
 ··· ) and we force the natural parameters
case  the statistics are f (xt) = (x(1)
to satisfy the constraint that minus half of precision is negative. The potential ψ(xt−1 t) in the

t = 1) ···   I(x(1)

t = 1) ···   I(x(2)

max ···   x(M )

max)  I(x(2)

t = x(2)

t = x(1)

  x(2) 2

  x(1) 2

  x(2)

t

t

t

t

1Empirically  the ﬁxed point iteration converges even without the dual feasible constraint (λt = 0); In

general  λt is bounded by the dual feasible constraint and the derivative over λt is not zero.

6

distribution ˆpt+1(xt t+1) (Eq. (8)) has speciﬁc form(cid:80)

t

vt

(x(m)

t−1 t) ≈ (cid:104)f (xt)(cid:105) ˆpt(xt−1 t) for each species m  where ˆp(m)

P (xt  vt|xt−1)P (yt|xt) as Eq. (3)  which
t t+1) ≈ (cid:104)f (xt)(cid:105) ˆpt+1(xt t+1) and
facilitates a mean ﬁled approximation to evaluate (cid:104)f (xt)(cid:105) ˆp(m)
(cid:104)f (xt)(cid:105) ˆp(m)
t+1(x(m)
t−1 t) are
the marginal two-slice distributions for m and derived explicitly in the supplementary material. As
such  we establish linear complexity over number of species m and tractable inference in general
complex system dynamics.
To summarize  Algorithm 1 gives the mean-ﬁeld forward-backward algorithm and the gradient
ascent algorithm for making inferences with a stochastic kinetic model from noisy observations that
minimize Bethe free energy.

t t+1) and ˆp(m)

t+1(x(m)

(x(m)

t

Algorithm 1 Make inference of a stochastic kinetic model with expectation propagation.
Input: Discrete time SKM model (Eqs. (1) (2) (3)); Observation probabilities P (yt|xt) and initial
values of αt  γt  λt for all populations m and time t.
Expectation Propagation ﬁxed point: Alternate between forward and backward iterations until
convergence.

• For t = 1 ···   T   α(new)
• For t = T ···   1  γ(new)

t

t

= γ

= α(old)

(cid:16)(cid:104)f (xt)(cid:105) ˆpt(xt−1 t)
(cid:17)

(cid:16)(cid:104)f (xt)(cid:105) ˆpt+1(xt t+1)

t + γ

.

(cid:17) − γ(old)

t

.

Gradient ascent: Execute the following updates in alternating forward and backward sweeps  where
the gradients are deﬁned in Eq. (9)  under the dual feasible constraints.

• α(new)

t ← αt +  ∂Fdual

  λ(new)

t ← λt +  ∂FDual

.

∂αt

∂λt

Output: Optimum ˆpt(xt−1 t)  (cid:104)f (xt)(cid:105) ˆpt

as Eq. (7)  (8) for all populations m and time t.

4 Experiments on Transportation Dynamics

In this section  we evaluate and benchmark the performance of our proposed algorithms (Algorithm 1)
against mainstream state-of-the-art approaches. We have the ﬂexibility to specify species  states  and
events with different granularities in SKM  at either macroscopic or microscopic level. Consequently 
different levels of inference can be made by feeding in corresponding observations and model
speciﬁcations. For example  to track epidemics in a social network we can deﬁne each person as a
species and their health state as a hidden state  with infection and recovery as events. Using real-world
datasets about epidemic diffusion in a college campus  we efﬁciently inferred students’ health states
compared with ground truth from surveys [23]. In this section  we demonstrate population level
inference in the context of transportation dynamics2.

Transportation Dynamics A transportation system consists of residents and a network of locations.
The macroscopic description is the number of vehicles indexed by location and time  while the
microscopic description is the location of each vehicle at each time. Our goal is to infer the
macroscopic populations from noisy sensor network observations made at several selected roads.
Such inference problems in complex interaction networks are not trivial  for several reasons: the
system can be very large and contain large number of components (residents and locations) and
therefore many approaches fail due to resource costs; the interaction between components (i.e. the
mobility of residents) is by nature uncertain and time variant  and multiple variables (populations at
different locations) correlate together.
To model transportation dynamics  we classify people at the same location as one species. Let
l ∈ L index the locations and x(l)
t be the number of vehicles at location l at time t  which are
the latent states we want to identify. The events v that change system states can be generally
expressed as reaction li → lj  which represents one vehicle moving from location li to location
the same. The event rate reads
lj. It decrease x(li)
different possible vehicles to transit at li.
hv(xt  cv) = cv

by 1  increase x(lj )
t ) = cvx(li)
v (x(l)

by 1 and keep other x(l)
t

  as there are x(li)

(cid:81)(L)

l=1 g(l)

t

t

t

t

2Source code and a general function interface for other domains at both levels are here online

7

(l)
t
(l)
t

y

(l)
t
(l)
t

xp−y

(l)
y
t

t

n

| x(l)

(cid:80)

yi−fi

i

yi

(cid:1)(cid:30)(cid:0)xttl

t ) = (cid:0)x

is x(l)

t = xttly(l)
t vehicles at l is p(y(l)

t

(cid:1) ·(cid:0)xttl−x

t /xp. More strictly  the likelihood of observing y(l)

(cid:1). Our hidden state x(l)

Experiment Setup: We select a certain proportion  e.g. 20%  of vehicles as probe vehicles to build
the observation model  assuming that the probe vehicles are uniformly sampled from the system.
Let xttl be the total number of vehicles in the system  xp the total number of probe vehicles  x(l)
t
the number of vehicles at location l  y(l)
the number of probe vehicles observed at l. A rough point
t
estimation of x(l)
t probe vehicles
t
among x(l)
can be
represented as either a discrete variable or a univariate gaussian.
Dataset Description: We implement and benchmark algorithms on two representative datasets. In
the SynthTown dataset  we synthesize a mini road network (Fig. 1(a)). Virtual residents go to work in
the morning and back home in the evening. We synthesize their itineraries from MATSIM  a common
Multi-agent transportation simulator[2]. The number of residents and locations are respectively 2 000
and 25. In the Berlin dataset  we have a larger real world road network with 1 539 locations derived
from Open Street Map and 9 178 people’s itineraries synthesized from MATSIM. Both two datasets
span a whole day  from midnight to midnight.
Evaluation Metrics: To evaluate the accuracy of the model  we need compare the series of inferred
populations against the series of ground truths. We choose three appropriate metrics: the “coefﬁcient
the R2 tells the goodness of ﬁt of a model and is calculated as 1 − (cid:80)
of determination” (R2)  the mean percentage error (MPE) and mean squared error (MSE). In statistics 
(cid:80)
i(yi−fi)2
i(yi−¯y)2   where yi are the
ground truth values  ¯y their mean and fi the inferred values. Typically  R2ranges from 0 and 1: the
(cid:80)
closer it is to 1  the better the inference is. The MPE computes average of percentage errors by which
. MPE can be either positive or negative and the
fi differ from yi and is calculated as 100%
i(yi − fi)2 to measure the average deviation
closer it is to 0  the better. The MSE is calculated as 1
n
between y and f. The lower the MSE  the better the inference. We also consider the runtime as an
important metric to research scalability of different approaches.
Approaches for Benchmark: We implement three algorithms to instantiate the procedures in
Algorithm 1: the ﬁxed point algorithm with discrete latent state (DFP) or gaussian latent state (GFP)
and the gradient ascent algorithm with discrete latent state (DG). The pseudo codes are included in
the supplementary material. We also implement several other mainstream state-of-the-art approaches.
Particle Filter (PF): We implement a sampling importance resampling (SIR) [10] algorithm that
recursively approximates the posterior with a weighted set of particles  updates these particles and
resamples to cope with degeneracy problem. Performance is dependent on the number of particles
with a certain number is needed to achieve a good result. We selected the number of particles
empirically by increasing the number until no obvious accuracy improvement could be detected 
and ended up with thousands to tens of thousands of particles. Extended Kalman Filter (EKF):
We implement the standard EKF procedure with an alternating prediction step and update step.
Feedforward Neural Network (FNN): The FNN builds only a non-parametric model between input
nodes and output nodes  without “actually” learning the dynamics of the system. We implement
a ﬁve-layer FNN: one input layer accepting the inference time point and observations in certain
previous period (e.g. one hour)  three hidden layers and one output layer from which we directly
read the inference populations. The FNN and afterwards RNN are both trained by feeding ground
truth populations about each road into the network structures. We tune meta-parameters and train the
network with 30 days synthesized mobility data from MATSIM until obtaining optimum performance.
Recurrent Neural Network (RNN): The RNN is capable of exploiting previous inferred hidden states
recursively to improve current estimation. We implement a typical RNN  such that in each RNN
cell we take both the current observations and inferred population from a previous cell as input 
traverse one hidden layer  and then output the inferred populations. We train the RNN with 30 days
of synthesized mobility data from MATSIM until obtaining optimum performance.
Inference Performance and Scalability: Figure 1 plots the inferred population at several represen-
tative locations in Fig. 1(a). The lines above the shaded areas are the ground truths  and we plot the
error (i.e.  inferred populations minus ground truth) with different scales. For GFP  the inference
within µ ± 3σ conﬁdence intervals is shown in the colored “belt”. We can see that our proposed
algorithms generally deviate less from the ground truth than other approaches do.

8

Table 1: Performance and time scalability of all algorithms

Dataset
Metrics

DFP
GFP
DG
PF
EKF
FNN
RNN

SynthTown

R2 MPE MSE
181
0.85
-3%
0.85
161
-8%
-5%
0.87
104
-21% 663
0.50
-19% 679
0.51
11%
0.73
526
0.72
-14% 407

Time
47 sec
42 sec
157 sec
15 sec
2 sec

1 h training
8 h training

Berlin
R2 MPE MSE
20
0.66
3%
0.62
27
2.5%
26
0.61
2.8%
-6%
0.50
678
-40% 1046
0.45
-14% 540
0.31
0.51
-9%
800

Time
29 min
21 min
56 min
71min
14 hour

11 h training
28 h training

(a) Road Network

(b) Inference results

Figure 1: Road network and inference results with the SynthTown Dataset

Table 1 summarizes the performances in different metrics (mean values). There is both a training
phase and a running phase in making inferences with neural networks  with the training phase taking
longer. The neural network training time shown in the table ranges from several hours to around one
day  and is quadratic in the number of system components per batch per epoch. The neural network
running times in our experiments are comparable with EP running times. Theoretically  neural
network running times are quadratic in the number of system components to make one prediction  and
EP running times are linear in the number of system components to propagate marginal probabilities
from one time step to the next (EP algorithms empirically converge within a few iterations)  while PF
scales quadratically and EKF cubically with the number of locations.
Summary: Generally  our proposed algorithms have higher R2  “narrower” MPE and lower MSE 
followed by neural networks  PF and EKF. The neural networks sometimes provide comparable
performance. Our proposed algorithms  especially the DFP and GFP  experience lower time explosion
in bigger datasets. Overall  our algorithms generally outperform PF  EKF  FNN and RNN in terms of
accuracy metrics and scalability to a larger dataset.

5 Discussion

In this paper  we have introduced the stochastic kinetic model and developed expectation propagation
algorithms to make inferences about the dynamics of complex interacting systems from noisy
observations. To avoid getting stuck at a local optimum  we formulate the problem of minimizing
Bethe free energy as a maximization problem over a concave dual function in the feasible domain
of dual variables guaranteed by duality theorem. Our experiments show superior performance over
competing models such as particle ﬁlter  extended Kalman ﬁlter  and deep neural networks.

9

References
[1] Adam Arkin  John Ross  and Harley H McAdams. Stochastic kinetic analysis of developmental
pathway bifurcation in phage λ-infected escherichia coli cells. Genetics  149(4):1633–1648 
1998.

[2] Michael Balmer  Marcel Rieser  Konrad Meister  David Charypar  Nicolas Lefebvre  and Kai
Nagel. Matsim-t: Architecture and simulation times. In Multi-agent systems for trafﬁc and
transportation engineering  pages 57–78. IGI Global  2009.

[3] Stephen Boyd and Lieven Vandenberghe. Convex optimization. Cambridge university press 

2004.

[4] Pierre Del Moral. Non-linear ﬁltering: interacting particle resolution. Markov processes and

related ﬁelds  2(4):555–581  1996.

[5] Wen Dong  Alex Pentland  and Katherine A Heller. Graph-coupled hmms for modeling the

spread of infection. arXiv preprint arXiv:1210.4864  2012.

[6] Arnaud Doucet  Nando De Freitas  Kevin Murphy  and Stuart Russell. Rao-blackwellised
particle ﬁltering for dynamic bayesian networks. In Proceedings of the Sixteenth conference on
Uncertainty in artiﬁcial intelligence  pages 176–183. Morgan Kaufmann Publishers Inc.  2000.

[7] Karl Friston. Learning and inference in the brain. Neural Networks  16(9):1325–1352  2003.

[8] Daniel T Gillespie. Stochastic simulation of chemical kinetics. Annu. Rev. Phys. Chem. 

58:35–55  2007.

[9] Andrew Golightly and Colin S Gillespie. Simulation of stochastic kinetic models. In Silico

Systems Biology  pages 169–187  2013.

[10] Neil J Gordon  David J Salmond  and Adrian FM Smith. Novel approach to nonlinear/non-
gaussian bayesian state estimation. In IEE Proceedings F (Radar and Signal Processing) 
volume 140  pages 107–113. IET  1993.

[11] Winfried K Grassmann. Transient solutions in markovian queueing systems. Computers &

Operations Research  4(1):47–53  1977.

[12] Tong Guan  Wen Dong  Dimitrios Koutsonikolas  and Chunming Qiao. Fine-grained location
extraction and prediction with little known data. In Wireless Communications and Networking
Conference (WCNC)  2017 IEEE  pages 1–6. IEEE  2017.

[13] Tom Heskes and Onno Zoeter. Expectation propagation for approximate inference in dynamic
bayesian networks. In Proceedings of the Eighteenth conference on Uncertainty in artiﬁcial
intelligence  pages 216–223. Morgan Kaufmann Publishers Inc.  2002.

[14] Simon J Julier and Jeffrey K Uhlmann. Unscented ﬁltering and nonlinear estimation. Proceed-

ings of the IEEE  92(3):401–422  2004.

[15] Rudolph Emil Kalman et al. A new approach to linear ﬁltering and prediction problems. Journal

of basic Engineering  82(1):35–45  1960.

[16] Thomas P Minka. The ep energy function and minimization schemes. See www. stat. cmu. edu/˜

minka/papers/learning. html  2001.

[17] Lawrence R Rabiner. A tutorial on hidden markov models and selected applications in speech

recognition. Proceedings of the IEEE  77(2):257–286  1989.

[18] Vinayak Rao and Yee Whye Teh. Fast mcmc sampling for markov jump processes and continu-

ous time bayesian networks. arXiv preprint arXiv:1202.3760  2012.

[19] Claudia Tebaldi and Mike West. Bayesian inference on network trafﬁc using link count data.

Journal of the American Statistical Association  93(442):557–573  1998.

10

[20] Michail D Vrettas  Manfred Opper  and Dan Cornford. Variational mean-ﬁeld algorithm for
efﬁcient inference in large systems of stochastic differential equations. Physical Review E 
91(1):012148  2015.

[21] Max Welling and Yee Whye Teh. Belief optimization for binary networks: A stable alternative
to loopy belief propagation. In Proceedings of the Seventeenth conference on Uncertainty in
artiﬁcial intelligence  pages 554–561. Morgan Kaufmann Publishers Inc.  2001.

[22] Darren J Wilkinson. Stochastic modelling for systems biology. CRC press  2011.

[23] Zhen Xu  Wen Dong  and Sargur N Srihari. Using social dynamics to make individual predic-
tions: Variational inference with stochastic kinetic model. In Advances In Neural Information
Processing Systems  pages 2775–2783  2016.

[24] Fan Yang and Wen Dong. Integrating simulation and signal processing with stochastic social
kinetic model. In International Conference on Social Computing  Behavioral-Cultural Modeling
and Prediction and Behavior Representation in Modeling and Simulation  pages 193–203.
Springer  Cham  2017.

[25] Jonathan S Yedidia  William T Freeman  and Yair Weiss. Understanding belief propagation and
its generalizations. Exploring artiﬁcial intelligence in the new millennium  8:236–239  2003.

11

,Bahadir Ozdemir
Larry Davis
Le Fang
Fan Yang
Wen Dong