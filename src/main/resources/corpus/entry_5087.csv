2013,Solving the multi-way matching problem by permutation synchronization,The problem of matching not just two  but m different sets of objects to each other arises in a variety of contexts  including finding the correspondence between feature points across multiple images in computer vision. At present it is usually solved by matching the sets pairwise  in series. In contrast  we propose a new method  permutation synchronization  which finds all the matchings jointly  in one shot  via a relaxation to eigenvector decomposition. The resulting algorithm is both computationally efficient  and  as we demonstrate with theoretical arguments as well as experimental results  much more stable to noise than previous methods.,Solving the multi-way matching problem by

permutation synchronization

Deepti Pachauri y Risi Kondorx and Vikas Singhzy

yDept. of Computer Sciences  University of Wisconsin–Madison

zDept. of Biostatistics & Medical Informatics  University of Wisconsin–Madison
xDept. of Computer Science and Dept. of Statistics  The University of Chicago

pachauri@cs.wisc.edu risi@uchicago.edu vsingh@biostat.wisc.edu

Abstract

The problem of matching not just two  but m different sets of objects to each other
arises in many contexts  including ﬁnding the correspondence between feature
points across multiple images in computer vision. At present it is usually solved
by matching the sets pairwise  in series. In contrast  we propose a new method 
Permutation Synchronization  which ﬁnds all the matchings jointly  in one shot 
via a relaxation to eigenvector decomposition. The resulting algorithm is both
computationally efﬁcient  and  as we demonstrate with theoretical arguments as
well as experimental results  much more stable to noise than previous methods.

′

′
n

′
1; x

′
2; : : : ; x

1 Introduction
Finding the correct bijection between two sets of objects X = fx1; x2; : : : ; xng and X
=
g is a fundametal problem in computer science  arising in a wide range of con-
fx
texts [1]. In this paper  we consider its generalization to matching not just two  but m different sets
X1; X2; : : : ; Xm. Our primary motivation and running example is the classic problem of matching
landmarks (feature points) across many images of the same object in computer vision  which is a
key ingredient of image registration [2]  recognition [3  4]  stereo [5]  shape matching [6  7]  and
structure from motion (SFM) [8  9]. However  our approach is fully general and equally applicable
to problems such as matching multiple graphs [10  11].
Presently  multi-matching is usually solved sequentially  by ﬁrst ﬁnding a putative permutation (cid:28)12
matching X1 to X2  then a permutation (cid:28)23 matching X2 to X3  and so on  up to (cid:28)m(cid:0)1;m. While
one can conceive of various strategies for optimizing this process  the fact remains that when the
data are noisy  a single error in the sequence will typically create a large number of erroneous
pairwise matches [12  13  14]. In contrast  in this paper we describe a new method  Permutation
i;j=1 of assignments jointly  in a single shot 
Synchronization  that estimates the entire matrix ((cid:28)ji)m
and is therefore much more robust to noise.
For consistency  the recovered matchings must satisfy (cid:28)kj(cid:28)ji = (cid:28)ki. While ﬁnding an optimal matrix
of permutations satisfying these relations is  in general  combinatorially hard  we show that for the
most natural choice of loss function the problem has a natural relaxation to just ﬁnding the n leading
eigenvectors of the cost matrix. In addition to vastly reducing the computational cost  using recent
results from random matrix theory  we show that the eigenvectors are very effective at aggregating
information from all
pairwise matches  and therefore make the algorithm surprisingly robust to
noise. Our experiments show that in landmark matching problems Permutation Synchronization can
recover the correct correspondence between landmarks across a large number of images with small
error  even when a signiﬁcant fraction of the pairwise matches are incorrect.
The term “synchronization” is inspired by the recent celebrated work of Singer et al. on a similar
problem involving ﬁnding the right rotations (rather than matchings) between electron microscopic

(

)

m
2

1

images [15][16][17]. Historically  multi-matching has received relatively little attention. However 
independently of  and concurrently with the present work  Huang and Guibas [18] have recently
proposed a semideﬁnite programming based solution  which parallels our approach  and in problems
involving occlusion might perform even better.

1; xi

2; : : : ; xi
n

p (cid:24) xj

p in Xi has a natural counterpart xj

2 Synchronizing permutations
Consider a collection of m sets X1; X2; : : : ; Xm of n objects each  Xi = fxi
that for each pair (Xi; Xj)  each xi
computer vision  given m images of the same scene taken from different viewpoints  xi
might be n visual landmarks detected in image i  while xj
image j  in which case xi
(cid:28)ji(p) for some
Since the correspondence between Xi and Xj is a bijection  one can write it as xi
permutation (cid:28)ji : f1; 2; : : : ; ng ! f1; 2; : : : ; ng. Key to our approach to solving multi-matching is
((cid:28) (i))  the n! possible
that with respect to the natural deﬁnition of multiplication  ((cid:28)
permutations of f1; 2; : : : ; ng form a group  called the symmetric group of degree n  denoted Sn.
We say that the system of correspondences between X1; X2; : : : ; Xm is consistent if xi
q and
q (cid:24) xk
r. In terms of permutations this is equivalent to requiring that
xj
the array ((cid:28)ij)m

g  such
q in Xj. For example  in
2; : : : ; xi
n
n are n landmarks detected in

q correspond to the same physical feature.

r together imply that xi

q signiﬁes that xi

(1)
Alternatively  given some reference ordering of x1; x2; : : : ; xn  we can think of each Xi as realizing
its own permutation (cid:27)i (in the sense of xℓ (cid:24) xi

(cid:27)i(ℓ))  and then (cid:28)ji becomes

i;j=1 satisfy

8i; j; k:

p (cid:24) xk

p (cid:24) xj

p (cid:24) xj

(cid:28)kj(cid:28)ji = (cid:28)ki

(cid:28) )(i) := ((cid:28)

1; xj

2; : : : ; xj

p and xj

1; xi

′

′

(cid:0)1
(cid:28)ji = (cid:27)j(cid:27)
i

:

(2)

The existence of permutations (cid:27)1; (cid:27)2; : : : ; (cid:27)m satisfying (2) is equivalent to requiring that ((cid:28)ji)m
i;j=1
satisfy (1). Thus  assuming consistency  solving the multi-matching problem reduces to ﬁnding
just m different permutations  rather than O(m2). However  the (cid:27)i’s are of course not directly
observable. Rather  in a typical application we have some tentative (noisy) ~(cid:28)ji matchings which we
must synchronize into the form (2) by ﬁnding the underlying (cid:27)1; : : : ; (cid:27)m.
Given (~(cid:28)ji)m
mutation Synchronization as the combinatorial optimization problem

i;j=1 and some appropriate distance metric d between permutations  we formalize Per-

minimize

(cid:27)1;(cid:27)2;:::;(cid:27)m2Sn

(cid:0)1
d((cid:27)j(cid:27)
i

; ~(cid:28)ji):

(3)

The computational cost of solving (3) depends critically on the form of the distance metric d. In this
paper we limit ourselves to the simplest choice

N∑

i;j=1

2

where P ((cid:27)) 2 Rn(cid:2)n are the usual permutation matrices

{

d((cid:27); (cid:28) ) = n (cid:0) ⟨P ((cid:27)); P ((cid:28) )⟩ ;
∑

1 if (cid:27)(p) = q
0 otherwise;

[P ((cid:27))]q;p :=

and ⟨A; B⟩ is the matrix inner product ⟨A; B⟩ := tr(A
⊤
The distance (4) simply counts the number of objects assigned differently by (cid:27) and (cid:28). Further-
); P (~(cid:28)ji)⟩; suggesting the
more  it allows us to rewrite (3) as maximize(cid:27)1;(cid:27)2;:::;(cid:27)m
generalization

n
p;q=1 Ap;q Bp;q:
⟨P ((cid:27)j(cid:27)
⟩

m∑

∑

m
i;j=1

B) =

(cid:0)1
i

⟨

maximize
(cid:27)1;(cid:27)2;:::;(cid:27)m

i;j=1

P ((cid:27)j(cid:27)

(cid:0)1
i

); Tji

;

⊤
ji = Tij. Intuitively  each Tji is an objective
where the Tji’s can now be any matrices  subject to T
q in Xj. This
matrix  the (q; p) element of which captures the utility of matching xi
generalization is very useful when the assignments of the different xi
p’s have different conﬁdences.
For example  in the landmark matching case  if  due to occlusion or for some other reason  the
counterpart of xi

p is not present in Xj  then we can simply set [Tji]q;p = 0 for all q.

p in Xi to xj

(4)

(5)

2.1 Representations and eigenvectors

The generalized Permutation Synchronization problem (5) can also be written as

maximize
(cid:27)1;(cid:27)2;:::;(cid:27)m

⟨P; T ⟩ ;

where

P =

0B@ P ((cid:27)1(cid:27)

...
P ((cid:27)m(cid:27)

(cid:0)1
1 )

(cid:0)1
1 )

1CA

: : : P ((cid:27)1(cid:27)
...
...
: : : P ((cid:27)m(cid:27)

(cid:0)1
m )

(cid:0)1
m )

and

T =

0B@ T11

...
Tm1

: : : T1m
...
...
: : : Tmm

1CA :

(6)

(7)

A matrix valued function (cid:26) : Sn ! Cd(cid:2)d is said to be a representation of the symmetric group if
(cid:26)((cid:27)2) (cid:26)((cid:27)1) = (cid:26)((cid:27)2(cid:27)1) for any pair of permutations (cid:27)1; (cid:27)2 2 Sn. Clearly  P is a representation
of Sn (actually  the so-called deﬁning representation)  since P ((cid:27)2(cid:27)1) = P ((cid:27)2) P ((cid:27)1). Moreover 
⊤. Our
P is a so-called orthogonal representation  because each P ((cid:27)) is real and P ((cid:27)
fundamental observation is that this implies that P has a very special form.
Proposition 1. The synchronization matrix P is of rank n and is of the form P = U (cid:1) U

(cid:0)1) = P ((cid:27))

⊤  where

Proof. From P being a representation of Sn 

U =

0B@ P ((cid:27)1) P ((cid:27)1)

...

P ((cid:27)m) P ((cid:27)1)

⊤

⊤

P =

1CA ;

(8)

: : : P ((cid:27)1) P ((cid:27)m)
...
: : : P ((cid:27)m) P ((cid:27)m)

...

⊤

⊤

⊤. Since U has n columns  rank(P) is at most n. This rank is achieved because
implying P = U (cid:1) U
P ((cid:27)1) is an orthogonal matrix  therefore it has linearly independent columns  and consequently the
■
columns of U cannot be linearly dependent.

Corollary 1. Letting [P ((cid:27)i)]p denote the p’th column of P ((cid:27)i)  the normalized columns of U 

0B@ P ((cid:27)1)

...

1CA :

P ((cid:27)m)

0B@ [P ((cid:27)1)]ℓ

1CA

...

[P ((cid:27)m)]ℓ

uℓ =

1p
m

maximize
P2Mn

m

P = m

⟨P; T ⟩ ;
n∑

⊤
ℓ ;

vℓ v

ℓ=1

3

ℓ = 1; : : : ; n;

(9)

are mutually orthogonal unit eigenvectors of P with the same eigenvalue m  and together span the
row/column space of P.
Proof. The columns of U are orthogonal because the columns of each constituent P ((cid:27)i) are orthog-
onal. The normalization follows from each column of P ((cid:27)i) having norm 1. The rest follows by
■
Proposition 1.

2.2 An easy relaxation

Solving (6) is computationally difﬁcult  because it involves searching the combinatorial space of a
combination of m permutations. However  Proposition 1 and its corollary suggest relaxing it to

where Mm
are m. This is now just a generalized Rayleigh problem  the solution of which is simply

n is the set of mn–dimensional rank n symmetric matrices whose non-zero eigenvalues

(10)

(11)

where v1; v2; : : : ; vℓ are the n leading normalized eigenvectors of T . Equivalently  P = U (cid:1) U
where

⊤ 

( j

v1
j

p
m

U =

)

j
vn
j

j
v2
j

: : :
: : :
: : :

:

(12)

Thus  in contrast to the original combinatorial problem  (10) can be solved by just ﬁnding the m
leading eigenvectors of T .
Of course  from P we must still recover the in-
dividual permutations (cid:27)1; (cid:27)2; : : : ; (cid:27)m. How-
ever  as long as P is relatively close in form
(7)  this is quite a simple and stable process.
One way to do it is to let each (cid:27)i be the per-
mutation that best matches the (i; 1) block of
P in the linear assignment sense 

Compute the n leading eigenvectors (v1; v2; : : : ; vn)
of T and set U =
for i = 1 to m do

Algorithm 1 Permutation Synchronization
Input: the objective matrix T

m [v1; v2; : : : ; vn]

⊤
1:n; 1:n

Pi1 = U(i(cid:0)1)n+1:in; 1:n U
(cid:27)i = arg max(cid:27)2Sn

⟨Pi1; (cid:27)⟩ [Kuhn-Munkres]

p

(cid:27)i = arg min
(cid:27)2Sn

⟨P ((cid:27)); [P]i;1⟩ ;

which is solved in O(n3) time by the Kuhn–
Munkres algorithm [19]1  and then set (cid:28)ji =
(cid:0)1
  which will then satisfy the consistency
(cid:27)j(cid:27)
i
relations. The pseudocode of the full algo-
rithm is given in Algorithm 1.

3 Analysis of the relaxed algorithm

end for
for each (i; j) do

(cid:28)ji = (cid:27)j(cid:27)

end for

(cid:0)1
i

matchings

Output: the matrix ((cid:28)ji)m

i;j=1 of globally consistent

0B@ [P (~(cid:27)1)]ℓ

1CA

...

[P (~(cid:27)m)]ℓ

vℓ =

1p
m

Let us now investigate under what conditions we can expect the relaxation (10) to work well  in
particular  in what cases we can expect the recovered matchings to be exact.
In the absence of noise  i.e.  when Tji = P (~(cid:28)ji) for some array (~(cid:28)ji)j;i of permutations that al-
ready satisfy the consistency relations (1)  T will have precisely the same structure as described by
Proposition 1 for P. In particular  it will have n mutually orthogonal eigenvectors

ℓ = 1; : : : ; n

(13)

with the same eigenvalue m. Due to the n–fold degeneracy  however  the matrix of eigenvectors
(12) is only deﬁned up to multiplication by an arbitrary rotation matrix O on the right  which means
that instead of the “correct” U (whose columns are (13))  the eigenvector decomposition of T may
return any U

= U O. Fortunately  when forming the product

′

P = U

′ (cid:1) U

′⊤

= U O O

U

⊤

⊤

= U (cid:1) U

⊤

this rotation cancels  conﬁrming that our algorithm recovers P = T   and hence the matchings
(cid:28)ji = ~(cid:28)ji  with no error.
Of course  rather than the case when the solution is handed to us from the start  we are more in-
terested in how the algorithm performs in situations when either the Tji blocks are not permutation
matrices  or they are not synchronized. To this end  we set
T = T0 + N ;

algorithm solves forb(cid:28) = arg max(cid:28)2Sn

(14)
where T0 is the correct “ground truth” synchronization matrix  while N is a symmetric perturbation
matrix with entries drawn independently from a zero-mean normal distribution with variance (cid:17)2.
In general  to ﬁnd the permutation best aligned with a given n (cid:2) n matrix T   the Kuhn–Munkres
⟨P ((cid:28) ); T⟩ = arg max(cid:28)2Sn (vec(P ((cid:28) )) (cid:1) vec(T )). Therefore 
1 Note that we could equally well have matched the (cid:27)i’s to any other column of blocks  since they are only
deﬁned relative to an arbitrary reference permutation: if  for any ﬁxed (cid:27)0  each (cid:27)i is redeﬁned as (cid:27)i(cid:27)0  the
predicted relative permutations (cid:28)ji = (cid:27)j(cid:27)0((cid:27)i(cid:27)0)

(cid:0)1 = (cid:27)j(cid:27)

stay the same.

(cid:0)1
i

4

Figure 1: Singular value histogram of T under the noise model where each ~(cid:28)ji with probability p =
f0:10; 0:25; 0:85g is replaced by a random permutation (m = 100  n = 30). Note that apart from the ex-
tra peak at zero  the distribution of the stochastic eigenvalues is very similar to the semicircular distribution for
Gaussian noise. As long as the small cluster of deterministic eigenvalues is clearly separated from the noise 
Permutation Synchronization is feasible.

writing T = P ((cid:28)0) + ϵ  where P ((cid:28)0) is the “ground truth”  while ϵ is an error term  it is guaranteed
to return the correct permutation as long as

∥ vec(ϵ)∥ < min

(cid:28)′2 Snnf(cid:28)0g

∥ vec((cid:28)0) (cid:0) vec((cid:28)

′

)∥ =2:

2

By the symmetry of Sn  the right hand side is the same for any (cid:28)0  so w.l.o.g. we can set (cid:28)0 = e (the
′ is just a transposition  e.g.  the permutation
identity)  and ﬁnd that the minimum is achieved when (cid:28)
that swaps 1 with 2 and leaves 3; 4; : : : ; n in place. The corresponding permutation matrix differs
p
from the idenity in exactly 4 entries  therefore a sufﬁcient condition for correct reconstruction is that
4 = 1. As n grows  ∥ϵ∥Frob becomes tightly concentrated
∥ϵ∥Frob = ⟨ϵ; ϵ⟩1=2 = ∥vec(ϵ)∥ < 1
around (cid:17)n  so the condition for recovering the correct permutation is (cid:17) < 1=n.
Permutation Synchronization can achieve a lower error  especially in the large m regime  because
the eigenvectors aggregate information from all the Tji matrices  and tend to be very stable to per-
turbations. In general  perturbations of the form (14) exhibit a characteristic phase transition. As
long as the largest eigenvalue of the random matrix N falls below a given multiple of the smallest
non-zero eigenvalue of T0  adding N will have very little effect on the eigenvectors of T . On the
other hand  when the noise exceeds this limit  the spectra get fully mixed  and it becomes impossible
to recover T0 from T to any precision at all.
If N is a symmetric matrix with independent N (0; (cid:17)2) entries  as nm ! 1  its spectrum will tend to
Wigner’s famous semicircle distribution supported on the interval ((cid:0)2(cid:17)(nm)1=2; 2(cid:17)(nm)1=2)  and
with probability one the largest eigenvalue will approach 2(cid:17)(nm)1=2 [20  21]. In contrast  the non-
zero eigenvalues of T0 scale with m  which guarantees that for large enough m the two spectra will
be nicely separated and Permutation Synchronization will have very low error. While much harder
to analyze analytically  empirical evidence suggests that this type of phase transition behavior is
characteristic of any reasonable noise model  for example the one in which we take each block of T
and with some probability p replace it with a random permutation matrix (Figure 1).
To derive more quantitative results  we consider the case where N is a so-called (symmetric) Gaus-
sian Wigner matrix  which has independent N (0; (cid:17)2) entries on its diagonal  and N (0; (cid:17)2=2) entries
everywhere else. It has recently been proved that for this type of matrix the phase transition occurs
= 1=2  so to recover T0 to any accuracy at all we must have (cid:17) < (m=n)1=2 [22].
at (cid:21)det
Below this limit  to quantify the actual expected error  we write each leading normalized eigenvector
i is the projection of vi to the space U0 spanned by the
v1; v2; : : : ; vn of T as vi = v
?
(cid:3)
(cid:3)
i   where v
i + v
n of T0. By Theorem 2.2 of [22] as nm ! 1 
non-zero eigenvectors v0
2; : : : ; v0
1; v0
∥2 a:s:(cid:0)(cid:0)(cid:0)! 1 (cid:0) (cid:17)2 n
∥v
∥2 a:s:(cid:0)(cid:0)(cid:0)! (cid:17)2 n
∥v
(cid:3)
?
i
i
m
m
⟩ = ⟨vi; vj⟩ (cid:0) ⟨v
It is easy to see that ⟨v
a:s:(cid:0)(cid:0)! 0  which implies ⟨v
⟩
?
?
?
(cid:3)
(cid:3)
i ; v
i ; v
i ; v
so  setting (cid:21) = (1 (cid:0) (cid:17)2n=m)
j
j
(cid:0)1=2  the normalized vectors (cid:21)v
(cid:3)
p
1; : : : ; (cid:21)v
orthonormal basis for U0. Thus  U =
m [v0
by

(15)
a:s:(cid:0)(cid:0)! 0 
(cid:3)
n almost surely tend to an
1; : : : ; v0
n]

p
m [v1; : : : ; vn] is related to the “true” U0 =

min=(cid:21)stochastic

max

and

⟩

?
j

:

(cid:21)U a:s:(cid:0)(cid:0)! U0O + (cid:21)E

′

= (U0 + (cid:21)E)O;

′ has norm (cid:17)(n=m)1=2.
where O is some rotation and each column of the noise matrices E and E
Since multiplying U on the right by an orthogonal matrix does not affect P  and the Kuhn–Munkres

5

Figure 2: The fraction of ((cid:27)i)m
i=1 permutations that are incorrect when reconstructed by Permutation Synchro-
nization from an array (~(cid:28)ji)m
j;i=1  in which each entry  with probability p is replaced by a random permutation.
The plots show the mean and standard deviation of errors over 20 runs as a function of p for m = 10 (red) 
m = 50 (blue) and m = 100 (green). (Left) n = 10. (Center) n = 25. (Right) n = 30.

algorithm is invariant to scaling by a constant  this equation tells us that (almost surely) the effect
of (14) is equivalent to setting U = U0 + (cid:21)E. In terms of the individual Pji blocks of P = U U
⊤ 
neglecting second order terms 

Pji = (U 0

j + (cid:21)Ej)(U 0

⊤ (cid:25) P ((cid:28)ji) + (cid:21)U 0
j E
i and Ei denote the appropriate n (cid:2) n submatrices
where (cid:28)ji is the ground truth matching and U 0
of U 0 and E. Conjecturing that in the limit Ei and Ej follow rotationally invariant distributions 
almost surely

⊤
i + (cid:21)EjU 0⊤

i + (cid:21)Ei)

;

i

lim∥ U 0
j E

i + EjU 0⊤
⊤

i

∥Frob = lim∥ Ei + Ej ∥Frob (cid:20) 2 (cid:17)n=m:

Thus  plugging in to our earlier result for the error tolerance of the Kuhn–Munkres algorithm  Per-
mutation Synchronization will correctly recover (cid:28)ji with probability one provided 2(cid:21)(cid:17)n=m < 1  or 
equivalently 

(cid:17)2 <

m=n

1 + 4(m=n)(cid:0)1 :

This is much better than our (cid:17) < 1=n result for the naive algorithm  and remarkably only slightly
stricter than the condition (cid:17) < (m=n)1=2 for recovering the eigenvectors with any accuracy at all.
Of course  these results are asymptotic (in the sense of nm ! 1)  and strictly speaking only apply
to additive Gaussian Wigner noise. However  as Figure 2 shows  in practice  even when the noise is
in the form of corrupting entire permutations and nm is relatively small  qualitatively our algorithm
exhibits the correct behavior  and for large enough m Permutation Synchronization does indeed
recover all ((cid:28)ji)m

j;i=1 with no error even when the vast majority of the entries in T are incorrect.

4 Experiments

Since computer vision is one of the areas where improving the accuracy of multi-matching problems
is the most pressing  our experiments focused on this domain. For a more details of our results 
please see the extended version of the paper available on project website.

Stereo Matching. As a proof of principle  we considered the task of aligning landmarks in 2D
images of the same object taken from different viewpoints in the CMU house (m = 111 frames
of a video sequence of a toy house with n = 30 hand labeled landmark points in each frame) and
CMU hotel (m = 101 frames of a video sequence of a toy hotel  n = 30 hand labeled landmark
points in each frame) datasets. The baseline method is to compute (~(cid:28)ji)m
inde-
pendent linear assignment problems based on matching landmarks by their shape context features
[23]. Our method takes the same pairwise matches and synchronizes them with the eigenvector
based procedure. Figure 3 shows that this clearly outperforms the baseline  which tends to degrade
progressively as the number of images increases. This is due to the fact that the appearance (or de-
scriptors) of keypoints differ considerably for large offset pairs (which is likely when the image set
is large)  leading to many false matches. In contrast  our method improves as the size of the image
set increases. While simple  this experiment demonstrates the utility of Permutation Synchroniza-
tion for multi-view stereo matching  showing that instead of heuristically propagating local pairwise
matches  it can ﬁnd a much more accurate globally consistent matching at little additional cost.

i;j=1 by solving

(

)

m
2

6

(a)

Figure 3:
(a) Normalized error as m increases on the House dataset. Permutation Synchronization (blue)
vs. the pairwise Kuhn-Munkres baseline (red). (b-c) Matches found for a representative image pair. (Green
circles) landmarks  (green lines) ground truth  (red lines) found matches. (b) Pairwise linear assignment  (c)
Permutation Synchronization. Note that less visible green is good.

(b)

(c)

Figure 4: Matches for a representative image pairs from the Building (top) and Books (bottom) datasets.
(Green circles) landmark points  (green lines) ground truth matchings  (red lines) found matches. (Left) Pair-
wise linear assignment  (right) Permutation Synchronization. Note that less visible green is better (right).

Repetitive Structures. Next  we considered a dataset with severe geometric ambiguities due to
repetitive structures. There is some consensus in the community that even sophisticated features
(like SIFT) yield unsatisfactory results in this scenario  and deriving a good initial matching for
structure from motion is problematic (see [24] and references therein). Our evaluations included 16
images from the Building dataset [24]. We identiﬁed 25 “similar looking” landmark points in the
scene  and hand annotated them across all images. Many landmarks were occluded due to the camera
angle. Qualitative results for pairwise matching and Permutation Synchronization are shown in Fig 4
(top). We highlight two important observations. First  our method resolved geometrical ambiguities
by enforcing mutual consistency efﬁciently. Second  Permutation Synchronization robustly handles
occlusion: landmark points that are occluded in one image are seamlessly assigned to null nodes in
the other (see the set of unassigned points in the rightmost image in Fig 4 (top)) thanks to evidence
derived from the large number of additional images in the dataset. In contrast  pairwise matching
struggles with occlusion in the presence of similar looking landmarks (and feature descriptors). For
n = 25 and m = 16  the error from the baseline method (Pairwise Linear Assignment) was 0:74.
Permutation Synchronization decreased this by 10% to 0:64. The Books dataset (Fig 4  bottom)
contains m = 20 images of multiple books on a “L” shaped study table [24]  and suffers geometrical
ambiguities similar to the above with severe occlusion. Here we identiﬁed n = 34 landmark points 
many of which were occluded in most images. The error from the baseline method was 0:92  and
Permutation Synchronization decreased this by 22% to 0:70 (see extended version of the paper).
Keypoint matching with nominal user supervision. Our ﬁnal experiment deals with matching
problems where keypoints in each image preserve a common structure.
In the literature  this is
usually tackled as a graph matching problem  with the keypoints deﬁning the vertices  and their
structural relationships being encoded by the edges of the graph. Ideally  one wants to solve the
problem for all images at once but most practical solutions operate on image (or graph) pairs. Note

7

that in terms of difﬁculty  this problem is quite distinct from those discussed above.
In stereo 
the same object is imaged and what varies from one view to the other is the ﬁeld of view  scale 
or pose.
In contrast  in keypoint matching  the background is not controlled and even sophisti-
cated descriptors may go wrong. Recent solutions often leverage supervision to make the prob-
lem tractable [25  26]. Instead of learning parameters [25  27]  we utilize supervision directly to
provide the correct matches on a small subset of randomly picked image pairs (e.g.  via a crowd-
sourced platform like Mechanical Turk). We hope to exploit this ‘ground-truth’ to signiﬁcantly
boost accuracy via Permutation Synchronization. For our experiments  we used the baseline method
output to set up our objective matrix T but with a ﬁxed “supervision probability”  we replaced
the Tji block by the correct permutation matrix  and ran Permutation Synchronization. We con-
sidered the “Bikes” sub-class from the Caltech 256 dataset  which contains multiple images of
common objects with varying backdrops  and chose to match images in the “touring bike” class.
Our analysis included 28 out of 110 images in this dataset that
were taken “side-on”. SUSAN corner detector was used to
identify landmarks in each image. Further  we identiﬁed 6 in-
terest points in each image that correspond to the frame of the
bicycle. We modeled the matching cost for an image pair as
the shape distance between interest points in the pair. As be-
fore  the baseline was pairwise linear assignment. For a ﬁxed
degree of supervision  we randomly selected image pairs for
supervision and estimated matchings for the rest of the image
pairs. We performed 50 runs for each degree of supervision.
Mean error and standard deviation is shown in Fig 5 as super-
vision increases. Fig 6 demonstrates qualitative results by our
method (right) and pairwise linear assignment (left).

Figure 5: Normalized error as the
degree of supervision varies. Base-
line method PLA (red) and Permuta-
tion Synchronization (blue)

5 Conclusions

(

)

Estimating the correct matching between two sets from noisy similarity data  such as the visual
feature based similarity matrices that arise in computer vision is an error-prone process. However 
when we have not just two  but m different sets  the consistency conditions between the
pair-
wise matchings severely constrain the solution. Our eigenvector decomposition based algorithm 
Permutation Synchronization  exploits this fact and pools information from all pairwise similarity
matrices to jointly estimate a globally consistent array of matchings in a single shot. Theoretical
results suggest that this approach is so robust that no matter how high the noise level is  for large
enough m the error is almost surely going to be zero. Experimental results conﬁrm that in a range
of computer vision tasks from stereo to keypoint matching in dissimilar images  the method does
indeed signiﬁcantly improve performance (especially when m is large  as expected in video)  and
can get around problems such as occlusion that a pairwise strategy cannot handle. In future work we
plan to compare our method to [18] (which was published after the present paper was submitted)  as
well as investigate using the graph connection Laplacian [28].

m
2

Acknowledgments

We thank Amit Singer for invaluable comments and for drawing our attention to [18]. This work
was supported in part by NSF–1320344 and by funding from the University of Wisconsin Graduate
School.

Figure 6: A representative triplet from the “Touring bike” dataset. (Yellow circle) Interest points in each
image. (Green lines) Ground truth matching for image pairs (left-center) and (center-right). (Red lines) Matches
for the image pairs: (left) supervision=0.1  (right) supervision=0.5.

8

References
[1] R. E. Burkard  M. Dell’Amico  and S. Martello. Assignment problems. SIAM  2009.
[2] D. Shen and C. Davatzikos. Hammer: hierarchical attribute matching mechanism for elastic registration.

TMI  IEEE  21  2002.

[3] K. Duan  D. Parikh  D. Crandall  and K. Grauman. Discovering localized attributes for ﬁne-grained

recognition. In CVPR  2012.

[4] M.F. Demirci  A. Shokoufandeh  Y. Keselman  L. Bretzner  and S. Dickinson. Object recognition as

many-to-many feature matching. IJCV  69  2006.

[5] M. Goesele  N. Snavely  B. Curless  H. Hoppe  and S.M. Seitz. Multi-view stereo for community photo

collections. In ICCV  2007.

[6] A.C. Berg  T.L. Berg  and J. Malik. Shape matching and object recognition using low distortion corre-

spondences. In CVPR  2005.

[7] J. Petterson  T. Caetano  J. McAuley  and J. Yu. Exponential family graph matching and ranking. NIPS 

2009.

[8] S. Agarwal  Y. Furukawa  N. Snavely  I. Simon  B. Curless  S.M. Seitz  and R. Szeliski. Building Rome

in a day. Communications of the ACM  54  2011.

[9] I. Simon  N. Snavely  and S.M. Seitz. Scene summarization for online image collections. In ICCV  2007.
[10] P.A. Pevzner. Multiple alignment  communication cost  and graph matching. SIAM JAM  52  1992.
[11] S. Lacoste-Julien  B. Taskar  D. Klein  and M.I. Jordan. Word alignment via quadratic assignment. In

Proc. HLT - NAACL  2006.

[12] A.J. Smola  S.V.N. Vishwanathan  and Q. Le. Bundle methods for machine learning. NIPS  20  2008.
[13] I. Tsochantaridis  T. Joachims  T. Hofmann  Y. Altun  and Y. Singer. Large margin methods for structured

and interdependent output variables. JMLR  6  2006.

[14] M. Volkovs and R. Zemel. Efﬁcient sampling for bipartite matching problems. In NIPS  2012.
[15] A. Singer and Y. Shkolnisky. Three-dimensional structure determination from common lines in cryo-EM
by eigenvectors and semideﬁnite programming. SIAM Journal on Imaging Sciences  4(2):543–572  2011.
[16] R. Hadani and A. Singer. Representation theoretic patterns in three dimensional cryo-electron microscopy

I — the intrinsic reconstitution algorithm. Annals of Mathematics  174(2):1219–1241  2011.

[17] R. Hadani and A. Singer. Representation theoretic patterns in three-dimensional cryo-electron microscopy

II — the class averaging problem. Foundations of Computational Mathematics  11(5):589–616  2011.

[18] Qi-Xing Huang and Leonidas Guibas. Consistent shape maps via semideﬁnite programming. Computer

Graphics Forum  32(5):177–186  2013.

[19] H.W. Kuhn. The Hungarian method for the assignment problem. Naval Research Logistics Quarterly  2 

1955.

[20] E.P. Wigner. On the distribution of the roots of certain symmetric matrices. Ann. Math  67  1958.
[21] Z. F¨uredi and J. Koml´os. The eigenvalues of random symmetric matrices. Combinatorica  1  1981.
[22] F. Benaych-Georges and R.R. Nadakuditi. The eigenvalues and eigenvectors of ﬁnite  low rank perturba-

tions of large random matrices. Advances in Mathematics  227(1):494–521  2011.

[23] S. Belongie  J. Malik  and J. Puzicha. Shape matching and object recognition using shape contexts. PAMI 

24(4):509–522  2002.

[24] R. Roberts  S. Sinha  R. Szeliski  and D. Steedly. Structure from motion for scenes with large duplicate

structures. In CVPR  2011.

[25] T.S. Caetano  J.J. McAuley  L. Cheng  Q.V. Le  and A.J. Smola. Learning graph matching. PAMI 

31(6):1048–1058  2009.

[26] M. Leordeanu  M. Hebert  and R. Sukthankar. An integer projected ﬁxed point method for graph matching

and map inference. In NIPS  2009.

[27] T. Jebara  J. Wang  and S.F. Chang. Graph construction and b-matching for semi-supervised learning. In

ICML  2009.

[28] A. S. Bandeira  A. Singer  and D. A. Spielman. A Cheeger inequality for the graph connection Laplacian.

SIAM Journal on Matrix Analysis and Applications  34(4):1611–1630  2013.

9

,Deepti Pachauri
Risi Kondor
Vikas Singh