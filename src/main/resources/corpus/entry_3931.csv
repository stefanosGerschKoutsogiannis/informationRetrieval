2015,On Top-k Selection in Multi-Armed Bandits and Hidden Bipartite Graphs,This paper discusses how to efficiently choose from $n$ unknowndistributions the $k$ ones whose means are the greatest by a certainmetric  up to a small relative error. We study the topic under twostandard settings---multi-armed bandits and hidden bipartitegraphs---which differ in the nature of the input distributions. In theformer setting  each distribution can be sampled (in the i.i.d.manner) an arbitrary number of times  whereas in the latter  eachdistribution is defined on a population of a finite size $m$ (andhence  is fully revealed after $m$ samples). For both settings  weprove lower bounds on the total number of samples needed  and proposeoptimal algorithms whose sample complexities match those lower bounds.,On Top-k Selection in Multi-Armed Bandits and

Hidden Bipartite Graphs

Wei Cao1

Jian Li1
1Tsinghua University

1{cao-w13@mails  lijian83@mail  zz-li14@mails}.tsinghua.edu.cn

2taoyf@cse.cuhk.edu.hk

Yufei Tao2

Zhize Li1

2Chinese University of Hong Kong

Abstract

This paper discusses how to efﬁciently choose from n unknown distributions the k
ones whose means are the greatest by a certain metric  up to a small relative error.
We study the topic under two standard settings—multi-armed bandits and hidden
bipartite graphs—which differ in the nature of the input distributions. In the for-
mer setting  each distribution can be sampled (in the i.i.d. manner) an arbitrary
number of times  whereas in the latter  each distribution is deﬁned on a population
of a ﬁnite size m (and hence  is fully revealed after m samples). For both set-
tings  we prove lower bounds on the total number of samples needed  and propose
optimal algorithms whose sample complexities match those lower bounds.

Introduction

1
This paper studies a class of problems that share a common high-level objective: from a number n
of probabilistic distributions  ﬁnd the k ones whose means are the greatest by a certain metric.
Crowdsourcing. A crowdsourcing algorithm (see recent works [1  13] and the references therein)
summons a certain number  say k  of individuals  called workers  to collaboratively accomplish
a complex task. Typically  the algorithm breaks the task into a potentially very large number of
micro-tasks  each of which makes a binary decision (yes or no) by taking the majority vote from the
participating workers. Each worker is given an (often monetary) reward for every micro-task that
s/he participates in. It is therefore crucial to identify the most reliable workers that have the highest
rates of making correct decisions. Because of this  a crowdsourcing algorithm should ideally be
preceded by an exploration phase  which selects the best k workers from n candidates by a series of
“control questions”. Every control-question must be paid for in the same way as a micro-task. The
challenge is to ﬁnd the best workers with the least amount of money.
Frequent Pattern Discovery. Let B and W be two relations. Given a join predicate Q(b  w)  the
joining power of a tuple b ∈ B equals the number of tuples w ∈ W such that b and w satisfy Q. A
top-k semi-join [14  17] returns the k tuples in B with the greatest joining power. This type of semi-
joins is notoriously difﬁcult to process when the evaluation of Q is complicated  and thus unfriendly
to tailored-made optimization. A well-known example from graph databases is the discovery of
frequent patterns [14]  where B is a set of graph patterns  W a set of data graphs  and Q(b  w)
decides if a pattern b is a subgraph of a data graph w. In this case  top-k semi-join essentially returns
the set of k graph patterns most frequently found in the data graphs. Given a black box for resolving
subgraph isomorphism Q(b  w)  the challenge is to minimize the number of calls to the black box.
We refer to the reader to [14  15] for more examples of difﬁcult top-k semi-joins of this sort.
1.1 Problem Formulation
The paper studies four problems that capture the essence of the above applications.
Multi-Armed Bandit. We consider a standard setting of stochastic multi-armed bandit selection.
Speciﬁcally  there is a bandit with a set B of n arms  where the i-th arm is associated with a Bernoulli

1

distribution with an unknown mean θi ∈ (0  1]. In each round  we choose an arm  pull it  and then
collect a reward  which is an i.i.d. sample from the arm’s reward distribution.
Given a subset V ⊆ B of arms  we denote by ai(V ) the arm with the i-th largest mean in V   and
by θi(V ) the mean of ai(V ). Deﬁne θavg(V ) = 1
i=1 θi(V )  namely  the average of the means of
k
the top-k arms in V .
Our ﬁrst two problems aim to identify k arms whose means are the greatest either individually or
aggregatively:
n/2  we want to select a k-sized subset V of B such that  with probability at least 1− δ  it holds that

Problem 1 [Top-k Arm Selection (k-AS)] Given parameters  ∈ (cid:0)0  1

(cid:1)   δ ∈ (cid:0)0  1

(cid:1)  and k ≤

(cid:80)k

48

4

θi(V ) ≥ (1 − )θi(B)  ∀i ≤ k.

We further study a variation of k-AS where we change the multiplicative guarantee θi(V ) ≥ (1 −
)θi(B) to an additive guarantee θi(V ) ≥ θi(B) − (cid:48). We refer to the modiﬁed problem as Top-
kadd Arm Selection(kadd-AS). Due to the space constraint  we present all the details of kadd-AS in
Appendix C.
Problem 2 [Top-kavg Arm Selection (kavg-AS)] Given the same parameters as in k-AS  we want
to select a k-sized subset V of B such that  with probability at least 1 − δ  it holds that

θavg(V ) ≥ (1 − )θavg(B).

For both problems  the cost of an algorithm is the total number of arms pulled  or equivalently  the
total number of samples drawn from the arms’ distributions. For this reason  we refer to the cost
as the algorithm’s sample complexity. It is easy to see that k-AS is more stringent than kavg-AS;
hence  a feasible solution to the former is also a feasible solution to the latter  but not the vice versa.
Hidden Bipartite Graph. The second main focus of the paper is the exploration of hidden bipartite
graphs. Let G = (B  W  E) be a bipartite graph  where the nodes in B are colored black  and those
in W colored white. Set n = |B| and m = |W|. The edge set E is hidden in the sense that an
algorithm does not see any edge at the beginning. To ﬁnd out whether an edge exists between a
black vertex b and a white vertex w  the algorithm must perform a probe operation. The cost of the
algorithm equals the number of such operations performed.
If an edge exists between b and w  we say that there is a solid edge between them; otherwise 
we say that they have an empty edge. Let deg(b) be the degree of a black vertex b  namely  the
number of solid edges of b. Given a subset of black vertices V ⊆ B  we denote by bi(V ) the
black vertex with i-th largest degree in V   and by degi(V ) the degree of bi(V ). Furthermore  deﬁne
degavg(V ) = 1
k
We now state the other two problems studied in this work  which aim to identify k black vertices
whose degrees are the greatest either individually or aggregatively:

Problem 3 [k-Most Connected Vertex [14] (k-MCV)] Given parameters  ∈(cid:0)0  1

and k ≤ n/2  we want to select a k-sized subset V of B such that  with probability at least 1 − δ  it
holds that

(cid:1)   δ ∈(cid:0)0  1

i=1 degi(V ).

(cid:80)k

(cid:1) 

degi(V ) ≥ (1 − ) degi(B)  ∀i ≤ k.

Problem 4 [kavg-Most Connected Vertex (kavg-MCV)] Given the same parameters as in k-MCV 
we want to select a k-sized subset V of B such that  with probability at least 1 − δ  it holds that

4

48

degavg(V ) ≥ (1 − ) degavg(B).

A feasible solution to k-MCV is also feasible for kavg-MCV  but not the vice versa. We will refer to
the cost of an algorithm also as its sample complexity  by regarding a probe operation as “sampling”
the edge probed. For any deterministic algorithm  the adversary can force the algorithm to always
probe Ω(mn) edges. Hence  we only consider randomized algorithms.
k-MCV can be reduced to k-AS. Given a hidden bipartite graph (B  W  E)  we can treat every
black vertex b ∈ B as an “arm” associated with a Bernoulli reward distribution: the reward is 1 with
probability deg(b)/m (recall m = |W|)  and 0 with probability 1− deg(b)/m. Any algorithm A for
k-AS can be deployed to solve k-MCV as follows. Whenever A samples from arm b  we randomly
choose a white vertex w ∈ W   and probe the edge between b and w. A reward of 1 is returned to A
if and only if the edge exists.

2

(cid:48)2 log k

1

θk(B) log n

k-AS and k-MCV differ  however  in the size of the population that a reward distribution is deﬁned
on. For k-AS  the reward of each arm is sampled from a population of an indeﬁnite size  which can
even be inﬁnite. Consequently  k-AS nicely models situations such as the crowdsourcing application
mentioned earlier.
For k-MCV  the reward distribution of each “arm” (i.e.  a black vertex b) is deﬁned on a population
of size m = |W| (i.e.  the edges of b). This has three implications. First  k-MCV is a better
modeling of applications like top-k semi-join (where an edge exists between b ∈ B and w ∈ W
if and only if Q(b  w) is true). Second  the problem admits an obvious algorithm with cost O(nm)
(recall n = |B|): simply probe all the hidden edges. Third  an algorithm never needs to probe the
same edge between b and w twice—once probed  whether the edge is solid or empty is perpetually
revealed. We refer to the last implication as the history-awareness property.
The above discussion on k-AS and k-MCV also applies to kavg-AS and kavg-MCV. For each of
above problems  we refer to an algorithm which achieves the precision and failure requirements
prescribed by  and δ as an (  δ)-approximate algorithm.
1.2 Previous Results
Problem 1. Sheng et al. [14] presented an algorithm1 that solves k-AS with expected cost
δ ). No lower bound is known on the sample complexity of k-AS. The closest work
O( n
2
is due to Kalyanakrishnan et al. [11]. They considered the EXPLORE-k problem  where the goal
is to return a set V of k arms such that  with probability at least 1 − δ  the mean of each arm in
V is at least θk(B) − (cid:48). They showed an algorithm with sample complexity Θ( n
δ ) in ex-
pectation and establish a matching lower bound. Note that EXPLORE-k ensures an absolute-error
guarantee  which is weaker than the individually relative-error guarantee of k-AS. Therefore  the
same EXPLORE-k lower bound also applies to k-AS.
The readers may be tempted to set (cid:48) =  · θk(B) to derive a “lower bound” of Ω( n
(θk(B))2 log k
δ )
for k-AS. This  however  is clearly wrong because when θk(B) = o(1) (a typical case in practice)
this “lower bound” may be even higher than the upper bound of [14] mentioned earlier. The cause
of the error lies in that the hard instance constructed in [11] requires θk(B) = Ω(1).
Problem 2. The O( n
δ ) upper bound of [14] on k-AS carries over to kavg-AS (which  as
2
mentioned before  can be solved by any k-AS algorithm). Zhou et al. [16] considered an OPTMAI
problem whose goal is to ﬁnd a k-sized subset V such that θavg(V ) − θavg(B) ≤ (cid:48) holds with
probability at least 1− δ. Note  once again  that this is an absolute-error guarantee  as opposed to the
relative-error guarantee of kavg-AS. For OPTMAI  Zhou et al. presented an algorithm with sample
)) in expectation. Observe that if θavg(B) is available magically in
complexity O( n
advance  we can immediately apply the OPTMAI algorithm of [16] to settle kavg-AS by setting
(cid:48) =  · θavg(B). The expected cost of the algorithm becomes O( n
)) (which
is suboptimal. See the table).
No lower bound is known on the sample complexity of kavg-AS. For OPTMAI  Zhou et al. [16]
proved a lower bound of Ω( n
))  which directly applies to kavg-AS due to its stronger
quality guarantee.
Problems 3 and 4. Both problems can be trivially solved with cost O(nm). Furthermore  as
explained in Section 1.1  k-MCV and kavg-MCV can be reduced to k-AS and kavg-AS respectively.
Indeed  the best existing k-AS and kavg-AS algorithms (surveyed in the above) serve as the state of
the art for k-MCV and kavg-MCV  respectively.
Prior to this work  no lower bound results were known for k-MCV and kavg-MCV. Note that none
of the lower bounds for k-AS (or kavg-AS) is applicable to k-MCV (or kavg-MCV  resp.)  because
there is no reduction from the former problem to the latter.
1.3 Our Results
We obtain tight upper and lower bounds for all of the problems deﬁned in Section 1.1. Our main re-
sults are summarized in Table 1 (all bounds are in expectation). Next  we explain several highlights 
and provide an overview into our techniques.

(θavg(B))2 (1 + log(1/δ)

(cid:48)2 (1 + log(1/δ)

(cid:48)2 (1 + log(1/δ)

k

1

θk(B) log n

1

2

k

1

2

k

1The algorithm was designed for k-MCV  but it can be adapted to k-AS as well.

3

sample complexity
O

1

(cid:16) n
(cid:16) n
Ω(cid:0) n
(cid:16) n

2

2

O

(cid:17)
(cid:17)
(cid:17)

δ

δ

1

(cid:1)

θk(B) log n
θk(B) log k
2 log k
θk(B) log k
δ
θk(B) log n
δ )

1

1

δ

θavg(B)

(θavg(B))2

θavg(B)

k
1 + log(1/δ)

O

O

(cid:16)

Ω
2
O( n
2

1

1

2
1

2

2

2

Ω

Ω

O

min

(cid:16) n
(cid:16) n
(cid:16) n
(cid:16) n
(cid:110) n
(cid:110) n
(cid:110) n
(cid:16)

(cid:16)
(cid:16)
(cid:16)
(cid:110) n
(cid:110) n

min

2

2

2

2

m

m

m2

min

O
degk(B) log k

2

m

δ

k

k

(cid:17)(cid:17)

1 + log(1/δ)

1 + log(1/δ)

1 + log(1/δ)

(cid:16)
(cid:16)
(cid:16)

(cid:17)(cid:17)
(cid:17)(cid:17)
(cid:17)(cid:17)
(cid:111)(cid:17)
(cid:111)(cid:17)
if degk(B) ≥ Ω( 1
(cid:111)(cid:17)
(cid:17)
(cid:16)
(cid:16)
(cid:17)

δ   nm
1 + log(1/δ)

k
δ   nm
δ   nm

m

1 + log(1/δ)

k

(cid:17)(cid:17)

k

m

degk(B) log n
degk(B) log k

m

(cid:17)

degk(B) log n

degavg(B)

1 + log(1/δ)

k

(degavg(B))2

(cid:16) n
(cid:16)
(cid:16)
(cid:16) n

O

min

O

min

2

Ω
Ω(nm) if degk(B) < O( 1
 )

2 log n
δ )

(cid:111)(cid:17)
(cid:111)(cid:17)

  nm

  nm

(cid:40)

O

 Ω

source
[14]
new
[11]
new
[14]

[16]

new
[16]
new
[14]
new

new

[14]

[16]

new

new

Table 1: Comparison of our and previous results (all bounds are in expectation)
problem

k-AS

kavg-AS

k-MCV

kavg-MCV

upper
bound

lower
bound

upper
bound

lower
bound

upper
bound

lower
bound

upper
bound

lower
bound

2

degavg(B)

if degavg(B) ≥ Ω( 1

2 log n
δ )

Ω(nm) if degavg(B) < O( 1
 )

k-AS. Our algorithm improves the log n factor of [14] to log k (in practice k (cid:28) n)  thereby achiev-
ing the optimal sample complexity (Theorem 1).
Our analysis for k-AS is inspired by [8  10  11] (in particular the median elimination technique in
[8]). However  the details are very different and more involved than the previous ones (the applica-
tion of median elimination of [8] was in a much simpler context where the analysis was considerably
easier). On the lower bound side  our argument is similar to that of [11]  but we need to get rid of
the θk(B) = Ω(1) assumption (as explained in Section 1.2)  which requires several changes in the
analysis (Theorem 2).
kavg-AS. Our algorithm improves both existing solutions in [14  16] signiﬁcantly  noticing that both
θk(B) and (θavg(B))2 are never larger  but can be far smaller  than θavg(B). This improvement re-
sults from an enhanced version of median elimination  and once again  requires a non-trivial analysis
speciﬁc to our context (Theorem 4). Our lower bound is established with a novel reduction from the
1-AS problem (Theorem 5). It is worth nothing that the reduction can be used to simplify the proof
of the lower bound in [16  Theorem 5.5] .
k-MCV and kavg-MCV. The stated upper bounds for k-MCV and kavg-MCV in Table 1 can be
obtained directly from our k-AS and kavg-AS algorithms. In contrast  all the lower-bound arguments
for k-AS and kavg-AS—which crucially rely on the samples being i.i.d.—break down for the two
MCV problems  due to the history-awareness property explained in Section 1.1.
For k-MCV  we remedy the issue by (i) (when degk(B) is large) a reduction from k-AS  and (ii)
(when degk(B) is small) a reduction from a sampling lower bound for distinguishing two extremely
similar distributions (Theorem 3). Analogous ideas are deployed for kavg-MCV (Theorem 6). Note
δ ))  we do not have the
that for a small range of degk(B) (i.e.  Ω( 1
optimal lower bounds yet for k-MCV and kavg-MCV. Closing the gap is left as an interesting open
problem.

 ) < degk(B) < O( 1

2 log n

4

Algorithm 1: ME-AS
1 input: B    δ  k
2 for µ = 1/2  1/4  . . . do
S = ME(B    δ  µ  k);
3
{(ai  ˆθUS (ai)) | 1 ≤ i ≤ k} = US(S    δ  (1 − /2)µ  k);
4
if ˆθUS (ak) ≥ 2µ then
5
6

return {a1  . . .   ak};

sample every arm a ∈ S(cid:96) for Q(cid:96) = (12/2
for each arm a ∈ S(cid:96) do

Algorithm 2: Median Elimination (ME)
1 input: B    δ  µ  k
2 S1 = B  1 = /16  δ1 = δ/8  µ1 = µ  and (cid:96) = 1;
3 while |S(cid:96)| > 4k do
4
5
6
7
8
9
10 return S(cid:96);

(cid:96) )(1/µ(cid:96)) log(6k/δ(cid:96)) times;

its empirical value ˆθ(a) = the average of the Q(cid:96) samples from a;

a1  . . .   a|S(cid:96)| = the arms sorted in non-increasing order of their empirical values;
S(cid:96)+1 = {a1  . . .   a|S(cid:96)|/2};
(cid:96)+1 = 3(cid:96)/4  δ(cid:96)+1 = δ(cid:96)/2  µ(cid:96)+1 = (1 − (cid:96))µ(cid:96)  and (cid:96) = (cid:96) + 1;

its US-empirical value ˆθUS (a) = the average of the Q samples from a;

Algorithm 3: Uniform Sampling (US)
1 input: S    δ  µs  k
2 sample every arm a ∈ S for Q = (96/2)(1/µs) log(4|S|/δ) times;
3 for each arm a ∈ S do
4
5 a1  . . .   a|S| = the arms sorted in non-increasing order of their US-empirical values;
6 return {(a1  ˆθUS (a1))  . . .   (ak  ˆθUS (ak))}
2 Top-k Arm Selection
In this section  we describe a new algorithm for the k-AS problem. We present the detailed analysis
in Appendix B.
Our k-AS algorithm consists of three components: ME-AS  Median Elimination (ME)  and Uniform
Sampling (US)  as shown in Algorithms 1  2  and 3  respectively.
Given parameters B    δ  k (as in Problem 1)  ME-AS takes a “guess” µ (Line 2) on the value of
θk(B)  and then applies ME (Line 3) to prune B down to a set S of at most 4k arms. Then  at Line
4  US is invoked to process S. At Line 5  (as will be clear shortly) the value of ˆθUS (ak) is what
ME-AS thinks should be the value of θk(B); thus  the algorithm performs a quality check to see
whether ˆθUS (ak) is larger than but close to µ. If the check fails  ME-AS halves its guess µ (Line 2) 
and repeats the above steps; otherwise  the output of US from Line 4 is returned as the ﬁnal result.
ME runs in rounds. Round (cid:96) (= 1  2  ...) is controlled by parameters S(cid:96)  (cid:96)  δ(cid:96)  and µ(cid:96) (their values
for Round 1 are given at Line 1). In general  S(cid:96) is the set of arms from which we still want to sample.
For each arm a ∈ S(cid:96)  ME takes Q(cid:96) (Line 4) samples from a  and calculates its empirical value ˆθ(a)
(Lines 5 and 6). ME drops (at Lines 7 and 8) half of the arms in S(cid:96) with the smallest empirical
values  and then (at Line 9) sets the parameters of the next round. ME terminates by returning S(cid:96) as
soon as |S(cid:96)| is at most 4k (Lines 3 and 10).
US simply takes Q samples from each arm a ∈ S (Line 2)  and calculates its US-empirical value
ˆθUS (a) (Lines 3 and 4). Finally  US returns the k arms in S with the largest US-empirical values
(Lines 5 and 6).
Remark. If we ignore Line 3 of Algorithm 1 and simply set S = B  then ME-AS degenerates into
the algorithm in [14].

5

(cid:16) n

(cid:17)

4

48

Theorem 1 ME-AS solves the k-AS problem with expected cost O
We extends the proof in [11] and establish the lower bound for k-AS as shown in Theorem 2.

(cid:1)  given any algorithm  there is an instance of the

Theorem 2 For any  ∈ (cid:0)0  1

(cid:1) and δ ∈ (cid:0)0  1

θk(B) log k

2

.

1

δ

1

θk(B) log k

k-AS problem on which the algorithm must entail Ω( n
2
3 k-MOST CONNECTED VERTEX
This section is devoted to the k-MCV problem (Problem 3). We will focus on lower bounds because
our k-AS algorithm in the previous section also settles k-MCV with the cost claimed in Table 1 by
applying the reduction described in Section 1.1. We establish matching lower bounds below:

δ ) cost in expectation.

(cid:1) and δ ∈ (cid:0)0  1

(cid:1)  the following statements are true about any
(cid:1)  there is an instance on which the algorithm must probe

Theorem 3 For any  ∈ (cid:0)0  1
• when degk(B) ≥ Ω(cid:0) 1

k-MCV algorithm:

12

48

2 log n

δ

Ω( n
2

m

degk(B) log k

δ ) edges in expectation.

• when degk(B) < O( 1
edges in expectation.

 )  there is an instance on which the algorithm must probe Ω(nm)

For large degk(B) in Theorem 3  we utilize an instance for k-AS to construct a random hidden
bipartite graph and fed it to any algorithm solves k-MCV. By doing this  we reduce k-AS to k-
MCV and thus  establish our ﬁrst lower bound.
For small degk(B)  we deﬁne the single-vertex problem where the goal is to distinguish two ex-
tremely distributions. We prove the lower bound of single-vertex problem and reduce it to k-MCV.
Thus  we establish our second lower bound. The details are presented in Appendix D.
4 Top-kavg Arm Selection
Our kavg-AS algorithm QE-AS is similar to ME-AS described in Section 2  except that the parame-
ters are adjusted appropriately  as shown in Algorithm 4  5  6 respectively. We present the details in
Appendix E.
Theorem 4 QE-AS solves the kavg-AS problem with expected cost O
We establish the lower bound for kavg-AS as shown in Theorem 5.

1 + log(1/δ)

(cid:16) n

(cid:16)

2

k

(cid:1) and δ ∈ (cid:0)0  1

1

θavg(B)

(cid:17)(cid:17)
(cid:1)  given any (  δ)-approximate algo-
(cid:17)

(cid:16) n

log(1/δ)

.

1

and

2

θavg(B)

k

Theorem 5 For any  ∈ (cid:0)0  1
(cid:16) n
(cid:16) n

there is an instance of
1

We show that

rithm 
Ω

(cid:16)
(cid:17)

1 + log(1/δ)

(cid:17)(cid:17)

θavg(B)

2

k

12
the kavg-AS problem on which the algorithm must entail

48

cost in expectation.

the lower bound of kavg-AS is the maximum of Ω

1

2

θavg(B)

. Our proof of the ﬁrst lower bound is based on a novel reduction from 1-AS. We
Ω
stress that our reduction can be used to simplify the proof of the lower bound in [16  Theorem 5.5].
5 kavg-MOST CONNECTED VERTEX
Our kavg-AS algorithm  combined with the reduction described in Section 1.1  already settles kavg-
MCV with the sample complexity given in Table 1. We establish the following lower bound and
prove it in Appendix F.

(cid:1)  the following statements are true about any
(cid:1) and δ ∈ (cid:0)0  1
(cid:1)  there is an instance on which the algorithm must probe
(cid:18)
(cid:18) n

(cid:19)(cid:19)

log(1/δ)

2 log n

m

48

δ

Theorem 6 For any  ∈ (cid:0)0  1
• when degavg(B) ≥ Ω(cid:0) 1

kavg-MCV algorithm:

12

Ω

2

degavg(B)

1 +

k

edges in expectation.
• when degk(B) < O( 1
edges in expectation.

 )  there is an instance on which the algorithm must probe Ω(nm)

6

Algorithm 4: QE-AS
1 input: B    δ  k
2 for µ = 1/2  1/4  . . . do
S = QE(B    δ  µ  k);
3
{(ai | 1 ≤ i ≤ k)  ˆθU S
4
if ˆθU S
5
6

avg ≥ 2µ then
return {a1  . . .   ak};

avg} = US(S    δ  (1 − /2)µ  k);

sample every arm a ∈ S(cid:96) for Q(cid:96) = (48/2
for each arm a ∈ S(cid:96) do

Algorithm 5: Quartile Elimination (QE)
1 input: B    δ  µ  k
2 S1 = B  1 = /32  δ1 = δ/8  µ1 = µ  and (cid:96) = 1;
3 while |S(cid:96)| > 4k do
4
5
6
7
8
9
10 return S(cid:96);

(cid:16)

1 + log(2/δ(cid:96))

k

(cid:17)

times;

(cid:96) )(1/µ(cid:96))

its empirical value ˆθ(a) = the average of the Q(cid:96) samples from a;

a1  . . .   a|S(cid:96)| = the arms sorted in non-increasing order of their empirical values;
S(cid:96)+1 = {a1  . . .   a3|S(cid:96)|/4};
(cid:96)+1 = 7(cid:96)/8  δ(cid:96)+1 = δ(cid:96)/2  µ(cid:96)+1 = (1 − (cid:96))µ(cid:96)  and (cid:96) = (cid:96) + 1;

(cid:16)

(cid:17)

times;

i=1

1 + log(4/δ)

k

(cid:80)k

ˆθUS (ai)}

its US-empirical value ˆθUS (a) = the average of the Q samples from a;

Algorithm 6: Uniform Sampling (US)
1 input: S    δ  µs  k
2 sample every arm a ∈ S for Q = (120/2)(1/µs)
3 for each arm a ∈ S do
4
5 a1  . . .   a|S| = the arms sorted in non-increasing order of their US-empirical values;
6 return {(a1  . . .   ak)  ˆθU S
avg = 1
k
6 Experiment Evaluation
Due to the space constraint  we show only the experiments that compare ME-AS and AMCV [14] for
k-MCV problem. Additional experiments can be found in Appendix G. We use two synthetic data
sets and one real world data set to evaluate the algorithms. Each dataset is represented as a bipartite
graph with n = m = 5000. For the synthetic data  the degrees of the black vertices follow a power
law distribution. For each black vertex b ∈ B  its degree equals d with probability c(d + 1)−τ where
τ is the parameter to be set and c is the normalizing factor. Furthermore  for each black vertex with
degree d  we connected it to d randomly selected white vertices. Thus  we build two bipartite graphs
by setting the proper parameters in order to control the average degrees of the black vertices to be
50 and 3000 respectively. For the real world data  we crawl 5000 active users from twitter with their
corresponding relationships. We construct a bipartite graph G = (B  W  E) where each of B and
W represents all the users and E represents the 2-hop relationships. We say two users b ∈ B and
w ∈ W have a 2-hop relationship if they share at least one common friend.
As the theoretical analysis is rather pessimistic due to the extensive usage of the union bound  to
make a fair comparison  we adopt the same strategy as in [14]  i.e.  to divide the sample cost in
theory by a heuristic constant ξ. We use the same parameter ξ = 2000 for AMCV as in [14].
For ME-AS  we ﬁrst take ξ = 107 for each round of the median elimination step and then we use
the previous sample cost dividing 250 as the samples of the uniform sampling step. Notice that it
does not conﬂict the theoretical sample complexity since the median elimination step dominates the
sample complexity of the algorithm.
We ﬁx the parameters δ = 0.1  k = 20 and enumerate  from 0.01 to 0.1. We then calculate
the actual failure probability by counting the successful runs in 100 repeats. Recall that due to
the heuristic nature  the algorithm may not achieve the theoretical guarantees prescribed by (  δ).

7

Whenever this happens  we label the percentage of actual error a it achieves according to the failure
probability δ. For example 2.9 means the algorithm actually achieves an error a = 0.029 with
failure probability δ. The experiment result is shown in Fig 1.

(a) Power law with ¯deg = 50

(b) Power law with ¯deg = 3000

(c) 2-hop

Figure 1: Performance comparison for k-MCV vs. 

As we can see  ME-AS outperforms AMCV in both sample complexity and the actual error in all
data sets. We stress that in the worst case  it seems ME-AS only shows a difference when n (cid:29) k.
However for the most of the real world data  the degrees of the vertices usually follow a power
law distribution or a Gaussian distribution. For such cases  our algorithm only needs to take a
few samples in each round of the elimination step and drops half of vertices with high conﬁdence.
Therefore  the experimental result shows that the sample cost of ME-AS is much less than AMCV.
7 Related Work
Multi-armed bandit problems are classical decision problems with exploration-exploitation trade-
offs  and have been extensively studied for several decades (dating back to 1930s). In this line of
research  k-AS and kavg-AS ﬁt into the pure exploration category  which has attracted signiﬁcant
attentions in recent years due to its abundant applications such as online advertisement placemen-
t [6]  channel allocation for mobile communications [2]  crowdsourcing [16]  etc. We mention some
closely related work below  and refer the interested readers to a recent survey [4].
Even-Dar et al. [8] proposed an optimal algorithm for selecting a single arm which approximates
the best arm with an additive error at most  (a matching lower bound was established by Mannor et
al. [12]). Kalyanakrishnan et al. [10  11] considered the EXPLORE-k problem which we mentioned
δ ). Similarly 
in Section 1.2. They provided an algorithm with the sample complexity O( n
Zhou et al. [16] studied the OPTMAI problem which  again as mentioned in Section 1.2  is the
absolute-error version of kavg-AS.
Audibert et al. [2] and Bubeck et al. [4] investigated the ﬁxed budget setting where  given a ﬁxed
number of samples  we want to minimize the so-called misidentiﬁcation probability (informally  the
probability that the solution is not optimal). Buckeck et al. [5] also showed the links between the
simple regret (the gap between the arm we obtain and the best arm) and the cumulative regret (the
gap between the reward we obtained and the expected reward of the best arm). Gabillon et al.
[9]
provide a uniﬁed approach UGapE for EXPLORE-k in both the ﬁxed budget and the ﬁxed conﬁdence
settings. They derived the algorithms based on “lower and upper conﬁdence bound” (LUCB) where
the time complexity depends on the gap between θk(B) and the other arms . Note that each time
LUCB samples the two arms that are most difﬁcult to distinguish. Since our problem ensures an
individually guarantee  it is unclear whether only sampling the most difﬁcult-to-distinguish arms
would be enough. We leave it as an intriguing direction for future work. Chen et al. [6] studied how
to select the best arms under various combinatorial constraints.
Acknowledgements.
Jian Li  Wei Cao  Zhize Li were supported in part by the National Basic
Research Program of China grants 2015CB358700  2011CBA00300  2011CBA00301  and the Na-
tional NSFC grants 61202009  61033001  61361136003. Yufei Tao was supported in part by projects
GRF 4168/13 and GRF 142072/14 from HKRGC.

2 log k

8

0.010.030.050.070.09105106107108samplecost2.95.68.511.016.319.218.926.228.011.012.113.915.5AMCVME-AS0.010.030.050.070.09105106107108samplecost11.8AMCVME-AS0.010.030.050.070.09105106107108samplecost3.79.312.116.318.022.723.127.629.55.77.48.69.911.212.8AMCVME-ASReferences
[1] Y. Amsterdamer  S. B. Davidson  T. Milo  S. Novgorodov  and A. Somech. OASSIS: query

driven crowd mining. In SIGMOD  pages 589–600  2014.

[2] J.-Y. Audibert  S. Bubeck  et al. Best arm identiﬁcation in multi-armed bandits. COLT  2010.
[3] Z. Bar-Yossef. The complexity of massive data set computations. PhD thesis  University of

California  2002.

[4] S. Bubeck  N. Cesa-Bianchi  et al. Regret analysis of stochastic and nonstochastic multi-armed

bandit problems. Foundations and trends in machine learning  5(1):1–122  2012.

[5] S. Bubeck  R. Munos  and G. Stoltz. Pure exploration in ﬁnitely-armed and continuous-armed

bandits. Theoretical Computer Science  412(19):1832–1852  2011.

[6] S. Chen  T. Lin  I. King  M. R. Lyu  and W. Chen. Combinatorial pure exploration of multi-
armed bandits. In Advances in Neural Information Processing Systems  pages 379–387  2014.
[7] D. P. Dubhashi and A. Panconesi. Concentration of measure for the analysis of randomized

algorithms. Cambridge University Press  2009.

[8] E. Even-Dar  S. Mannor  and Y. Mansour. Action elimination and stopping conditions for the
multi-armed bandit and reinforcement learning problems. The Journal of Machine Learning
Research  7:1079–1105  2006.

[9] V. Gabillon  M. Ghavamzadeh  and A. Lazaric. Best arm identiﬁcation: A uniﬁed approach
to ﬁxed budget and ﬁxed conﬁdence. In Advances in Neural Information Processing Systems 
pages 3212–3220  2012.

[10] S. Kalyanakrishnan and P. Stone. Efﬁcient selection of multiple bandit arms: Theory and

practice. In ICML  pages 511–518  2010.

[11] S. Kalyanakrishnan  A. Tewari  P. Auer  and P. Stone. PAC subset selection in stochastic multi-

armed bandits. In ICML  pages 655–662  2012.

[12] S. Mannor and J. N. Tsitsiklis. The sample complexity of exploration in the multi-armed bandit

problem. The Journal of Machine Learning Research  5:623–648  2004.

[13] A. G. Parameswaran  S. Boyd  H. Garcia-Molina  A. Gupta  N. Polyzotis  and J. Widom.

Optimal crowd-powered rating and ﬁltering algorithms. PVLDB  7(9):685–696  2014.

[14] C. Sheng  Y. Tao  and J. Li. Exact and approximate algorithms for the most connected vertex

problem. TODS  37(2):12  2012.

[15] J. Wang  E. Lo  and M. L. Yiu. Identifying the most connected vertices in hidden bipartite

graphs using group testing. TKDE  25(10):2245–2256  2013.

[16] Y. Zhou  X. Chen  and J. Li. Optimal PAC multiple arm identiﬁcation with applications to

crowdsourcing. In ICML  pages 217–225  2014.

[17] M. Zhu  D. Papadias  J. Zhang  and D. L. Lee. Top-k spatial joins. TKDE  17(4):567–579 

2005.

9

,Wei Cao
Jian Li
Yufei Tao
Zhize Li