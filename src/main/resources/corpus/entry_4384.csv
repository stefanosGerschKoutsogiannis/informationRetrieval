2007,Predictive Matrix-Variate t Models,It is becoming increasingly important to learn from a partially-observed random matrix and predict its missing elements. We assume that the entire matrix is a single sample drawn from a matrix-variate t distribution and suggest a matrix-variate t model (MVTM) to predict those missing elements. We show that MVTM generalizes a range of known probabilistic models  and automatically performs model selection to encourage sparse predictive models. Due to the non-conjugacy of its prior  it is difficult to make predictions by computing the mode or mean of the posterior distribution. We suggest an optimization method that sequentially minimizes a convex upper-bound of the log-likelihood  which is very efficient and scalable. The experiments on a toy data and EachMovie dataset show a good predictive accuracy of the model.,Predictive Matrix-Variate t Models

Shenghuo Zhu

Kai Yu

Yihong Gong

NEC Labs America  Inc.

10080 N. Wolfe Rd. SW3-350

Cupertino  CA 95014

{zsh kyu ygong}@sv.nec-labs.com

Abstract

It is becoming increasingly important to learn from a partially-observed random
matrix and predict its missing elements. We assume that the entire matrix is a
single sample drawn from a matrix-variate t distribution and suggest a matrix-
variate t model (MVTM) to predict those missing elements. We show that MVTM
generalizes a range of known probabilistic models  and automatically performs
model selection to encourage sparse predictive models. Due to the non-conjugacy
of its prior  it is difﬁcult to make predictions by computing the mode or mean of
the posterior distribution. We suggest an optimization method that sequentially
minimizes a convex upper-bound of the log-likelihood  which is very efﬁcient and
scalable. The experiments on a toy data and EachMovie dataset show a good
predictive accuracy of the model.

1

Introduction

Matrix analysis techniques  e.g.  singular value decomposition (SVD)  have been widely used in
various data analysis applications. An important class of applications is to predict missing elements
given a partially observed random matrix. For example  putting ratings of users into a matrix form 
the goal of collaborative ﬁltering is to predict those unseen ratings in the matrix.

To predict unobserved elements in matrices  the structures of the matrices play an importance role 
for example  the similarity between columns and between rows. Such structures imply that elements
in a random matrix are no longer independent and identically-distributed (i.i.d.). Without the i.i.d.
assumption  many machine learning models are not applicable.

In this paper  we model the random matrix of interest as a single sample drawn from a matrix-
variate t distribution  which is a generalization of Student-t distribution. We call the predictive
model under such a prior by matrix-variate t model (MVTM). Our study shows several interesting
properties of the model. First  it continues the line of gradual generalizations across several known
probabilistic models on random matrices  namely  from probabilistic principle component analysis
(PPCA) [11]  to Gaussian process latent-variable models (GPLVMs)[7]  and to multi-task Gaussian
processes (MTGPs) [13]. MVTMs can be further derived by analytically marginalizing out the
hyper-parameters of these models. From a Bayesian modeling point of view  the marginalization of
hyper-parameters means an automatic model selection and usually leads to a better generalization
performance [8]; Second  the model selection by MVTMs explicitly encourages simpler predictive
models that have lower ranks. Unlike the direct rank minimization  the log-determinant terms in the
form of matrix-variate t prior offers a continuous optimization surface (though non-convex) for rank
constraint; Third  like multivariate Gaussian distributions  a matrix-variate t prior is consistent under
marginalization  that means  if a matrix follows a matrix-variate t distribution  its any sub-matrix
follows a matrix-variate t distribution as well. This property allows to generalize distributions for
ﬁnite matrices to inﬁnite stochastic processes.

S

R

S

T

Y

(a)

T

Y

(b)

T

Y

(c)

I

T

Y

(d)

Figure 1: Models for matrix prediction. (a) MVTM. (b) and (c) are two normal-inverse-Wishart
models  equivalent to MVTM when the covariance variable S (or R) is marginalized. (d) MTGP 
which requires to optimize the covariance variable S. Circle nodes represent for random variables 
shaded nodes for (partially) observable variables  text nodes for given parameters.

Under a Gaussian noise model  the matrix-variate t distribution is not a conjugate prior. It is thus dif-
ﬁcult to make predictions by computing the mode or mean of the posterior distribution. We suggest
an optimization method that sequentially minimizes a convex upper-bound of the log-likelihood 
which is highly efﬁcient and scalable. In the experiments  the algorithm shows very good efﬁciency
and excellent prediction accuracy.

This paper is organized as follows. We review three existing models and introduce the matrix-variate
t models in Section 2. The prediction methods are proposed in Section 3. In Section 4  the MVTM is
compared with some other models. We illustrate the MVTM with the experiments on a toy example
and on the movie-rating data in Section 5. We conclude in Section 6.

2 Predictive Matrix-Variate t Models

2.1 A Family of Probabilistic Models for Matrix Data

In this section we introduce three probabilistic models in the literature. Let Y be a p × m
observational matrix and T be the underlying p × m noise-free random matrix. We assume
Yi j = Ti j + i j   i j ∼ N (0  σ2)  where Yi j denotes the (i  j)-th element of Y.
If Y is
partially observed  then YI denotes the set of observed elements and I is the corresponding index
set.

Probabilistic Principal Component Analysis (PPCA) [11] assumes that yj  the j-th column vector
of Y  can be generated from a latent vector vj in a k-dimensional linear space (k < p). The model
is deﬁned as yj = Wvj + µ + j and vj ∼ Nk(vj; 0  Ik)  where j ∼ Np(j; 0  σ2Ip)  and
W is a p × k loading matrix. By integrating out vj  we obtain the marginal distribution yj ∼
Np(yj; µ  WW> + σ2Ip). Since the columns of Y are conditionally independent  letting S take
the place of WW>  PPCA is similar1 to

Yi j = Ti j + i j 

T ∼ Np m(T; 0  S  Im) 

where Np m(·; 0  S  Im) is a matrix-variate normal prior with zero mean  covariance S between
rows  and identity covariance Im between columns. PPCA aims to estimate the parameter W by
maximum likelihood.

Gaussian Process Latent-Variable Model (GPLVM) [7] formulates a latent-variable model in a
slightly unconventional way. It considers the same linear relationship from latent representation vj
to observations yj. Instead of treating vj as random variables  GPLVM assigns a prior on W and
see {vj} as parameters yj = Wvj + j  and W ∼ Np k(W; 0  Ip  Ik)  where the elements of W
are independent Gaussian random variables. By marginalizing out W  we obtain a distribution that
each row of Y is an i.i.d. sample from a Gaussian process prior with the covariance VV> + σ2Im
and V = [v1  . . .   vm]>. Letting R take the place of VV>  we rewrite a similar model as

Yi j = Ti j + i j 

T ∼ Np m(T; 0  Ip  R).

1Because it requires S to be positive deﬁnite and W is usually low rank  they are not equivalent.

S
W
S
W
S
W
S
From a matrix modeling point of view  GPLVM estimates the covariance between the rows and
assume the columns to be conditionally independent.

Multi-task Gaussian Process (MTGP) [13] is a multi-task learning model where each column of
Y is a predictive function of one task  sampled from a Gaussian process prior  yj = tj + j  and
tj ∼ Np(0  S)  where j ∼ Np(0  σ2Ip). It introduces a hierarchical model where an inverse-
Wishart prior is added for the covariance 

Yi j = Ti j + i j 

T ∼ Np m(T; 0  S  Im) 

S ∼ IW p(S; ν  Ip)

MTGP utilizes the inverse-Wishart prior as the regularization and obtains a maximum a posteriori
(MAP) estimate of S.

2.2 Matrix-Variate t Models

The models introduced in the previous section are closely related to each other. PPCA models the
row covariance of Y  GPLVM models the column covariance  and MTGP assigns a hyper prior to
prevent over-ﬁtting when estimating the (row) covariance. From a matrix modeling point of view 
capturing the dependence structure of Y by its row or column covariance is a matter of choices 
which are not fundamentally different.2 There is no reason to favor one choice over the other. By
introducing the matrix-variate t models (MVTMs)  they can be uniﬁed to be the same model.

From a Bayesian modeling viewpoint  one should marginalize out as many variables as possible
[8]. We thus extend the MTGP model in two directions: (1) assume T ∼ Np m(T; 0  S  Im) that
have covariances on both sides of the matrix; (2) marginalize the covariance S on one side (see
Figure 1(b)). Then we have a marginal distribution of T

Pr(T) =Z Np m(T; 0  S  Im)IW p(S; ν  Ip)dS = tp m(T; ν  0  Ip  Im) 

(1)

which is a matrix-variate t distribution. Because the inverse-Wishart distribution may have different
degree-of-freedom deﬁnition in literature  we use the deﬁnition in [5].

Following the deﬁnition in [6]  the matrix-variate t distribution of p × m matrix T is given by

tp m(T; ν  M  Σ  Ω) def=

1
Z

|Σ|− m

2 |Ω|− p

2 (cid:12)(cid:12)Ip + Σ−1(T − M)Ω−1(T − M)>(cid:12)(cid:12)− ν+m+p−1

2

 

where ν is the degree of freedom; M is a p × m matrix; Σ and Ω are positive deﬁnite matrices of
size p × p and m × m  respectively; Z = (νπ)
); Γp(·) is a multivariate
gamma function  and | · | stands for determinant.

)/Γp( ν+m+p−1

2 Γp( ν+p−1

mp

2

2

The model can be depicted as Figure 1(a). One important property of matrix-variate t distribution
is that the marginal distribution of its sub-matrix still follows a matrix-variate t distribution with the
same degree of freedom (see Section 3.1). Therefore  we can expand it to the inﬁnite dimensional
stochastic process. By Eq. (1)  we can see that Figure 1(a) and Figure 1(b) describe two equivalent
models. Comparing them with the MTGP model represented in Figure 1(d)  we can see that the
difference lies in whether S is point estimated or integrated out.

Interestingly  the same matrix-variate t distribution can be equivalently derived by putting another
hierarchical generative process on the covariance R  as described in Figure 1(c)  where R follows
an inverse-Wishart distribution. In other words  integrating the covariance on either side  we obtain
the same model. This implies that the model controls the complexity of the covariances on both
sides of the matrix. Neither PPCA nor GPLVM has such a property.

The matrix-variate t distribution involves a determinant term of T  which becomes a log-determinant
term in log-likelihood or KL-divergence. The log-determinant term encourages the sparsity of ma-
trix T with lower rank. This property has been used as the heuristic for minimizing the rank of the
matrix in [3]. Student’s t priors were applied to enforce sparse kernel machine [10].

Here we say a few words about the given parameters. Though we can use evidence framework[8]
or other methods to estimate ν  the results are not good in many cases(see [4]). Usually we just set

2GPLVM offers an advantage of using nonlinear covariance function based on attributes.

ν to a small number. Similar to ν  the estimated σ2 does not give us a good result either  but cross-
validation is a good choice. For the mean matrix M  in our experiments  we just use sample average
for all observed elements. For some tasks  when we have prior knowledge about the covariance
between columns or between rows  we can use the covariance matrices in the places of Im or Ip.

3 Prediction Methods

When the evaluation of the prediction is the sum of individual losses  the optimal prediction is to ﬁnd
the individual mode of the marginal posterior distribution  i.e.  arg maxTij Pr(Tij|YI). However 
there is no exact solution for the marginal posterior. We have two ways to approximate the optimal
prediction.

One way to make prediction is to compute the mode of the joint posterior distribution of T  i.e. the
prediction problem is

{ln Pr(YI|T) + ln Pr(T)} .

(2)

bT = arg max

T

The computation of this estimation is usually easy. We discuss it in Section 3.3.

An alternative way is to use the individual mean of the posterior distribution to approximate the
individual mode. Since the joint of individual mean happens to be the mean of the joint distribution 
we only need to compute the joint posterior distribution. The problem of prediction by means is
written as

T = E(T|YI).

(3)

However  it is usually difﬁcult to compute the exact mean. One estimation method is the Monte
Carlo method  which is computationally intensive. In Section 3.4  we discuss an approximation
to compute the mean. From our experiments  the prediction by means usually outperforms the
prediction by modes.

Before discussing the prediction methods  we introduce a few useful properties in Section 3.1 and
suggest an optimization method as the efﬁcient tool for prediction in Section 3.2.

3.1 Properties

The MVTM has a rich set of properties. We list a few in the following Theorem.

Theorem 1. If

then

n m
q Θ Φ

(cid:18)
p Ψ T(cid:19) ∼ tp+q m+n(·; ν  0  (cid:18)

q
Iq
0

p
0

Ip(cid:19)  (cid:18)

n m
In
0
0

Im(cid:19)) 

Pr(T) =tp m(T; ν  0  Ip  Im) 

Pr(T|Θ  Φ  Ψ) =tp m(T; ν + q + n  M  (Ip + ΨBΨ>)  (Im + Φ>AΦ)) 

Pr(Θ) =tq n(Θ; ν  0  Iq  In) 

Pr(Φ|Θ) =tq m(Φ; ν + n  0  A−1  Im) 

Pr(Ψ|Θ  Φ) =tp n(Ψ; ν + q  0  Ip  B−1) = Pr(Ψ|Θ) 

E(T|Θ  Φ  Ψ) =M 

Cov(cid:16)vec(cid:16)T>(cid:17) |Θ  Φ  Ψ(cid:17) =(ν + q + n − 2)−1(Ip + ΨBΨ>) ⊗ (Im + Φ>AΦ) 

where A

def

= (ΘΘ> + Iq)−1  B

def

= (Θ>Θ + In)−1  and M

def
= ΨΘ>AΦ = ΨBΘ>Φ.

(4)

(5)

(6)

(7)

(8)

(9)

(10)

(11)

This theorem can be directly derived from Theorem 4.3.1 and 4.3.9 in [6] with a little calculus. It
provides some insights about MVTMs. The marginal distribution in Eq. (5) has the same form as the
joint distribution  therefore the matrix-variate t distribution is extensible to an inﬁnite dimensional
stochastic process. As conditional distribution in Eq. (6) is still a matrix-variate t distribution  we
can use it to approximate the posterior distribution  which we use in Section 3.4.

We encounter log-determinant terms in computation of the mode or mean estimation. The following
theorem provides a quadratic upper bounds for the log-determinant terms  which makes it possible
to apply the optimization method in Section 3.2.
Lemma 1. If X is a p × p positive deﬁnite matrices  it holds that ln |X| ≤ tr (X) − p. The equality
holds when X is an orthonormal matrix.

Proof. Let {λ1  · · ·   λp} be the eigenvalues of X. We have ln |X| =Pi ln λi and tr (X) =Pi λi.

Since ln λi ≤ λi − 1  we have the inequality. The equality holds when λi = 1. Therefore  when X
is an orthonormal matrix (especially X = Ip)  the equality holds.

Theorem 2. If Σ is a p × p positive deﬁnite matrix  Ω is an m × m positive deﬁnite matrix  and T
and T0 are p × m matrices  it holds that

ln |Σ + TΩ−1T>| ≤ h(T; T0  Σ  Ω) + h0(T0  Σ  Ω) 

where

h(T; T0  Σ  Ω)

h0(T0  Σ  Ω)

∂
∂T

h(T; T0  Σ  Ω)(cid:12)(cid:12)(cid:12)(cid:12)T=T0

The equality holds when T = T0. Also it holds that

def

=tr(cid:16)(Σ + T0Ω−1T>

def

= ln |Σ + T0Ω−1T>

0 )−1TΩ−1T>(cid:17)  
0 | + tr(cid:16)(Σ + T0Ω−1T>

= 2(Σ + T0Ω−1T>

0 )−1T0Ω−1 =

∂
∂T

0 )−1Σ(cid:17) − p
ln |Σ + TΩ−1T>|(cid:12)(cid:12)(cid:12)(cid:12)T=T0

.

Applying Lemma 1 with X = (Σ + T0Ω−1T>
0 )−1(Σ + TΩ−1T>)  we obtain the inequality. By
some calculus we have the equality of the ﬁrst-order derivative. Actually h(·) is a quadratic convex
function with respect to T  as (Σ + T0Ω−1T>

0 )−1 and Ω−1 are positive deﬁnite matrices.

3.2 Optimization Method

Once the objective is given  the prediction becomes an optimization problem. We use an EM-
style optimization method to make the prediction. Suppose J (T) be the objective function to be
minimized. If we can ﬁnd an auxiliary function  Q(T; T0)  having the following properties  we can
apply this method.

1. J (T) ≤ Q(T; T0) and J (T0) = Q(T0; T0) 

2. ∂J (T)/∂T|T=T0 = ∂Q(T; T0)/∂T(cid:12)(cid:12)T=T0  

3. For a ﬁxed T0  Q(T; T0) is quadratic and convex with respect to T.

Starting from any T0  as long as we can ﬁnd a T1 such that Q(T1  T0) < Q(T0  T0)  we have
J (T0) = Q(T0  T0) > Q(T1  T0) ≥ J (T1). If there exists a global minimum point of J (T) 
there exists a global minimum point of Q(T; T0) as well  because Q(T; T0) is upper bound of
J (T). Since Q(T; T0) is quadratic with the respect to T  we can apply the Newton-Raphson
method to minimize Q(T; T0). As long as T0 is not a local minimum  maximum or saddle point of
J   we can ﬁnd a T to reduce Q(T; T0)  because Q(T; T0) has the same derivative as J (T) at T0.
Usually  a random starting point  T0 is unlikely to be a local maximum  then T1 can not be a local
maximum. If T0 is a local maximum  we can reselect a point  which is not. After we ﬁnd a Ti  we
repeat the procedure to ﬁnd a Ti+1 so that J (Ti+1) < J (Ti)  unless Ti is a local minimum or
saddle point of J . Repeating this procedure  Ti converges a local minimum or saddle point of J  
as long as T0 is not a local maximum.

3.3 Mode Prediction

Following Eq. (2)  the goal is to minimize the objective function

bJ (T) def= `(T) +

ν+m+p−1

2

ln(cid:12)(cid:12)(cid:12)Ip + TT>(cid:12)(cid:12)(cid:12)  

(12)

where `(T) def= − ln Pr(YI) = 1

2σ2 P(i j)∈I(Tij − Yij)2 + const.

introduce an auxiliary function 

Q(T; T0) def= `(T) + h(T; T0  Ip  Im) + h0(T0  Ip  Im).

As bJ contains a log-determinant term  minimizing bJ by nonlinear optimization is slow. Here  we
By Corollary 2  we have that bJ (T) ≤ Q(T; T0)  bJ (T0) = Q(T0  T0)  and Q(T  T0) has the same
ﬁrst-order derivative as bJ (T) at T0. Because l and h are quadratic and convex  Q is quadratic and
convex as well. Therefore  we can apply the optimization method in Section 3.2 to minimize bJ .
However  when the size of T is large  to ﬁnd bT is still time consuming and requires a very large
space. In many tasks  we only need to infer a small portion of bT. Therefore  we consider a low
matrix. The problem of Eq. (2) is approximated by arg minU V bJ (UV>). We can minimize J1 by
alternatively optimizing U and V. We can put the ﬁnal result in a canonical format as bT ≈ USV> 

where U and V are semi-orthonormal and S is a k × k diagonal matrix. This result can be consider
as the SVD of an incomplete matrix using matrix-variate t regularization. The details are skipped
because of the limit space.

rank approximation  using UV> to approximate T  where U is a p × k matrix and V is an m × k

(13)

3.4 Variational Mean Prediction

As the difﬁculty in explicitly computing the posterior distribution of T  we take a variational ap-
proach to approximate its posterior distribution by a matrix-variate t distribution via an expanded
model. We expand the model by adding matrix variate Θ  Φ and Ψ with distribution as Eq. (4).
Since the marginal distribution  Eq. (5)  is the same as the prior of T  we can derive the original
model by marginalizing out Θ  Φ and Ψ. However  instead of integrating out Θ  Φ and Ψ  we use
them as the parameters to approximate T’s posterior distribution. Therefore  the estimation of the
parameters is to minimize

− ln Pr(YI  Θ  Φ  Ψ) = − ln Pr(Θ  Φ  Ψ) − lnZ Pr(T|Θ  Φ  Ψ) Pr(YI|T)dT

(14)

over Θ  Φ and Ψ. The ﬁrst term in the RHS of Eq. (14) can be written as

− ln Pr(Θ  Φ  Ψ) = − ln Pr(Θ) − ln Pr(Φ|Θ) − ln Pr(Ψ|Θ  Φ)
ν+q+n+m−1

ν+q+n+p+m−1

=

2

ν+q+n+p−1

2

+

ln |Iq + ΘΘ>| +

2
ln |Ip + ΨBΨ>| + const.

ln |Im + Φ>AΦ|

(15)

Due to the convexity of negative logarithm  the second term in the RHS of Eq. (14) is bounded by

`(ΨB

1
2 Θ>A

1
2 Φ) +

1

2σ2(ν+q+n−2) X(i j)∈I

(1 + [ΨBΨ>]ii)(1 + [Φ>AΦ]jj) + const.

(16)

because − ln Pr(YI|T) is quadratic respective to T  thus we only need integration using the mean
and variance of Tij of Pr(T|Θ  Φ  Ψ)  which is given by Eq. (10) and (11). The parameter estima-
tion not only reduce the loss (the term of `(·))  but also reduce the variance. Because of this  the
prediction by means usually outperforms the prediction by modes.

Let J be the sum of the right-hand-side of Eq. (15) and (16)  which can be considered as the upper
bound of Eq. (14) (ignoring constants). Here  we estimate the parameters by minimizing J . Because
A and B involve the inverse of quadratic term of Θ  it is awkward to directly optimize Θ  Φ  Ψ.
def= Θ. We can easily apply the
We reparameterize J by U
optimization method in Section 3.2 to ﬁnd optimal U  V and S. After estimation U  V and S  by
Theorem 1  we can compute T = M = USV>. The details are skipped because of the limit space.

def= Φ>A1/2  and S

def= ΨB1/2  V

4 Related work

Maximum Margin Matrix Factorization (MMMF) [9] is not in the framework of stochastic matrix
analysis  but there are some similarities between MMMF and our mode estimation in Section 3.3.

Using trace norm on the matrix as regularization  MMMF overcomes the over-ﬁtting problem in
factorizing matrix with missing values. From the regularization viewpoint  the prediction by mode
of MVTM uses log-determinants as the regularization term in Eq. (12). The log-determinants en-
courage sparsity predictive models.

Stochastic Relational Models (SRMs) [12] extend MTGPs by estimating the covariance matrices
for each side. The covariance functions are required to be estimated from observation. By maxi-
mizing marginalized likelihood  the estimated S and R reﬂect the information of the dependency
structure. Then the relationship can be predicted with S and R. During estimating S and R  inverse-
Wishart priors with parameter Σ and Ω are imposed to S and R respectively. MVTM differs from
SRM in integrating out the hyper-parameters or maximizing out. As MacKay suggests [8]  “one
should integrate over as many variables as possible”.

Robust Probabilistic Projections (RPP)[1] uses Student-t distribution to extends PPCA by scaling
each feature vector by an independent random variable. Written in a matrix format  RPP is

T ∼ Np m(T; µ1>  WW>  U) 

U = diag {ui}  

ui ∼ IG(ui|

ν
2

 

ν
2

) 

where IG is inverse Gamma distribution. Though RPP unties the scale factors between feature vec-
tors  which could make the estimation more robust  it does not integrate out the covariance matrix 
which we did in MVTM. Moreover inherited from PPCA  RPP implicitly uses independence as-
sumption of feature vectors. Also RPP results different models depending on which side we assume
to be independent  therefore it is not suitable for matrix prediction.

5 Experiments

5

10

15

20

25

30

5

10

15

20

25

30

5

10

15

20

25

30

5

10

15

20

25

30

5

10

15

20

25

30

2

4

6

8

10

12

14

16

18

20

2

4

6

8

10

12

14

16

18

20

2

4

6

8

10

12

14

16

18

20

2

4

6

8

10

12

14

16

18

20

(a) Original Matrix

(b) With Noise (0.32)

(c) MMMF (0.27)

(d) PPCA (0.26)

5

10

15

20

25

30

5

10

15

20

25

30

5

10

15

20

25

30

2

4

6

8

10

12

14

16

18

20

2

4

6

8

10

12

14

16

18

20

2

4

6

8

10

12

14

16

18

20

2

4

6

8

10

12

14

16

18

20

(e) SRM (0.22)

(f) MVTM mode (0.20)

(g) MVTM mean (0.192)

(h) MCMC (0.185)

Figure 2: Experiments on synthetic data. RMSEs are shown in parentheses.

Synthetic data: We generate a 30 × 20 matrix (Fig-
ure 2(a))  then add noise with σ2 = 0.1 (Figure 2(b)). The
root mean squared noise is 0.32. We select 70% elements
as the observed data and the rest elements are for predic-
tion. We apply MMMF [9]  PPCA[11]  MTGP[13]  SRM
[12]  our MVTM prediction-by-means and prediction-
by-modes methods. The number of dimensions for low
rank approximation is 10. We also apply MCMC method
to infer the matrix. The reconstruction matrix and root
mean squared errors of prediction on the unobserved el-
ements (comparing to the original matrix) are shown in
Figure 2(c)-2(g)  respectively. MTGP has the similar re-
sult as PPCA  we do not show the result.

l

s
e
u
a
v
 
r
a
u
g
n
s

l

i

MMMF
MVTM-mode
MVTM-mean

 4
 3.5
 3
 2.5
 2
 1.5
 1
 0.5
 0

 1 2 3 4 5 6 7 8 9 10

index

Figure 3: Singular values of recovered
matrices in descent order.

MVTM is in favor of sparse predictive models. To verify this  we depict the singular values of
the MMMF method and two MVTM prediction methods in Figure 3. There are only two singular

RMSE
MAE

user mean movie mean MMMF
1.186
0.943

1.387
1.103

1.425
1.141

PPCA MVTM (mode) MVTM (mean)
1.165
0.915

1.162
0.898

1.151
0.887

Table 1: RMSE (root mean squred error) and MAE (mean absolute error) of experiments on Each-
movie data. All standard errors are 0.001 or less.

values of the MVTM prediction-by-means method are non-zeros. The singular values of the mode
estimation decrease faster than the MMMF ones at beginning  but decrease slower after a threshold.
This conﬁrms that the log-determinants automatically determine the intrinsic rank of the matrices.

Eachmovie data: We test our algorithms on Eachmovie from [2]. The dataset contains 74  424
users’ 2  811  718 ratings on 1  648 movies  i.e. about 2.29% are rated by zero-to-ﬁve stars. We put
all ratings into a matrix  and randomly select 80% as observed data to predict the remaining ratings.
The random selection was carried out 10 times independently. We compare our approach with other
three approaches: 1) USER MEAN predicting rating by the sample mean of the same user’ ratings;
2) MOVIE MEAN  predicting rating by the sample mean of users’ ratings of the same movie; 3)
MMMF[9]; 4) PPCA[11]. We do not have a scalable implementation for other approaches compared
in the previous experiment. The number of dimensions is 10. The results are shown in Table 1. Two
MVTM prediction methods outperform the other methods.

6 Conclusions

In this paper we introduce matrix-variate t models for matrix prediction. The entire matrix is mod-
eled as a sample drawn from a matrix-variate t distribution. An MVTM does not require the inde-
pendence assumption over elements. The implicit model selection of the MVTM encourages sparse
models with lower ranks. To minimize the log-likelihood with log-determinant terms  we propose an
optimization method by sequentially minimizing its convex quadratic upper bound. The experiments
show that the approach is accurate  efﬁcient and scalable.

References

[1] C. Archambeau  N. Delannay  and M. Verleysen. Robust probabilistic projections. In ICML  2006.

[2] J. Breese  D. Heckerman  and C. Kadie. Empirical analysis of predictive algorithms for collaborative

ﬁltering. In UAI-98  pages 43–52  1998.

[3] M. Fazel  H. Haitham  and S. P. Boyd. Log-det heuristic for matrix rank minimization with applications

to hankel and euclidean distance matrices. In Proceedings of the American Control Conference  2003.

[4] C. Fernandez and M. F. J. Steel. Multivariate Student-t regression models: Pitfalls and inference.

Biometrika  86(1):153–167  1999.

[5] A. Gelman  J. B. Carlin  H. S. Stern  and D. B. Rubin. Bayesian Data Analysis. Chapman & Hall/CRC 

New York  2nd edition  2004.

[6] A. K. Gupta and D. K. Nagar. Matrix Variate Distributions. Chapman & Hall/CRC  2000.

[7] N. Lawrence. Probabilistic non-linear principal component analysis with gaussian process latent variable

models. J. Mach. Learn. Res.  6:1783–1816  2005.

[8] D. J. C. MacKay. Comparison of approximate methods for handling hyperparameters. Neural Comput. 

11(5):1035–1068  1999.

[9] J. D. M. Rennie and N. Srebro. Fast maximum margin matrix factorization for collaborative prediction.

In ICML  2005.

[10] M. E. Tipping. Sparse bayesian learning and the relevance vector machine. Journal of Machine Learning

Research  1:211–244  2001.

[11] M. E. Tipping and C. M. Bishop. Probabilistic principal component analysis. Journal of the Royal

Statisitical Scoiety  B(61):611–622  1999.

[12] K. Yu  W. Chu  S. Yu  V. Tresp  and Z. Xu. Stochastic relational models for discriminative link prediction.

In Advances in Neural Information Processing Systems 19 (NIPS)  2006.

[13] K. Yu  V. Tresp  and A. Schwaighofer. Learning Gaussian processes from multiple tasks. In ICML  2005.

,Jason Xu
Eric Chi
Kenneth Lange