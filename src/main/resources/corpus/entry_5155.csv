2016,Spectral Learning of Dynamic Systems from Nonequilibrium Data,Observable operator models (OOMs) and related models are one of the most important and powerful tools for modeling and analyzing stochastic systems. They exactly describe dynamics of finite-rank systems and can be efficiently and consistently estimated through spectral learning under the assumption of identically distributed data. In this paper  we investigate the properties of spectral learning without this assumption due to the requirements of analyzing large-time scale systems  and show that the equilibrium dynamics of a system can be extracted from nonequilibrium observation data by imposing an equilibrium constraint. In addition  we propose a binless extension of spectral learning for continuous data. In comparison with the other continuous-valued spectral algorithms  the binless algorithm can achieve consistent estimation of equilibrium dynamics with only linear complexity.,Spectral Learning of Dynamic Systems from

Nonequilibrium Data

Hao Wu and Frank Noé

Department of Mathematics and Computer Science

Freie Universität Berlin

Arnimallee 6  14195 Berlin

{hao.wu frank.noe}@fu-berlin.de

Abstract

Observable operator models (OOMs) and related models are one of the most im-
portant and powerful tools for modeling and analyzing stochastic systems. They
exactly describe dynamics of ﬁnite-rank systems and can be efﬁciently and con-
sistently estimated through spectral learning under the assumption of identically
distributed data. In this paper  we investigate the properties of spectral learning
without this assumption due to the requirements of analyzing large-time scale
systems  and show that the equilibrium dynamics of a system can be extracted
from nonequilibrium observation data by imposing an equilibrium constraint. In
addition  we propose a binless extension of spectral learning for continuous data.
In comparison with the other continuous-valued spectral algorithms  the binless
algorithm can achieve consistent estimation of equilibrium dynamics with only
linear complexity.

1

Introduction

In the last two decades  a collection of highly related dynamic models including observable operator
models (OOMs) [1–3]  predictive state representations [4–6] and reduced-rank hidden Markov models
[7  8]  have become powerful and increasingly popular tools for analysis of dynamic data. These
models are largely similar  and all can be learned by spectral methods in a general framework of
multiplicity automata  or equivalently sequential systems [9  10]. In contrast with the other commonly
used models such as Markov state models [11  12]  Langevin models [13  14]  traditional hidden
Markov models (HMMs) [15  16]  Gaussian process state-space models [17  18] and recurrent
neural networks [19]  the spectral learning based models can exactly characterize the dynamics of a
stochastic system without any a priori knowledge except the assumption of ﬁnite dynamic rank (i.e. 
the rank of Hankel matrix) [10  20]  and the parameter estimation can be efﬁciently performed for
discrete-valued systems without solving any intractable inverse or optimization problem. We focus in
this paper only on stochastic systems without control inputs and all spectral learning based models
can be expressed in the form of OOMs for such systems  so we will refer to them as OOMs below.
In most literature on spectral learning  the observation data are assumed to be identically (possibly not
independently) distributed so that the expected values of observables associated with the parameter
estimation can be reliably computed by empirical averaging. However  this assumption can be
severely violated due to the limit of experimental technique or computational capacity in many
practical situations  especially where metastable physical or chemical processes are involved. A
notable example is the distributed computing project Folding@home [21]  which explores protein
folding processes that occur on the timescales of microseconds to milliseconds based on molecular
dynamics simulations on the order of nanoseconds in length. In such a nonequilibrium case where
distributions of observation data are time-varying and dependent on initial conditions  it is still unclear

30th Conference on Neural Information Processing Systems (NIPS 2016)  Barcelona  Spain.

if promising estimates of OOMs can be obtained. In [22]  a hybrid estimation algorithm was proposed
to improve spectral learning of large-time scale processes by using both dynamic and static data 
but it still requires assumption of identically distributed data. One solution to reduce the statistical
bias caused by nonequilibrium data is to discard the observation data generated before the system
reaches steady state  which is a common trick in applied statistics [23]. Obviously  this way suffers
from substantial information loss and is infeasible when observation trajectories are shorter than
mixing times. Another possible way would be to learn OOMs by likelihood-based estimation instead
of spectral methods  but there is no effective maximum likelihood or Bayesian estimator of OOMs
until now. The maximum pseudo-likelihood estimator of OOMs proposed in [24] demands high
computational cost and its consistency is yet unveriﬁed.
Another difﬁculty for spectral approaches is learning with continuous data  where density estimation
problems are involved. The density estimation can be performed by parametric methods such as the
fuzzy interpolation [25] and the kernel density estimation [8]. But these methods would reduce the
ﬂexibility of OOMs for dynamic modeling because of their limited expressive capacity. Recently  a
kernel embedding based spectral algorithm was proposed to cope with continuous data [26]  which
avoids explicit density estimation and learns OOMs in a nonparametric manner. However  the kernel
embedding usually yields a very large computational complexity  which greatly limits practical
applications of this algorithm to real-world systems.
The purpose of this paper is to address the challenge of spectral learning of OOMs from nonequilib-
rium data for analysis of both discrete- and continuous-valued systems. We ﬁrst provide a modiﬁed
spectral method for discrete-valued stochastic systems which allows us to consistently estimate
the equilibrium dynamics from nonequilibrium data  and then extend this method to continuous
observations in a binless manner. In comparison with the existing learning methods for continuous
OOMs  the proposed binless spectral method does not rely on any density estimator  and can achieve
consistent estimation with linear computational complexity in data size even if the assumption of iden-
tically distributed observations does not hold. Moreover  some numerical experiments are provided
to demonstrate the capability of the proposed methods.

2 Preliminaries

2.1 Notation
In this paper  we use P to denote probability distribution for discrete random variables and probability
density for continuous random variables. The indicator function of event e is denoted by 1e and
the Dirac delta function centered at x is denoted by δx (·). For a given process {at}  we write
the subsequence (ak  ak+1  . . .   ak(cid:48)) as ak:k(cid:48)  and E∞[at] (cid:44) limt→∞ E[at] means the equilibrium
expected value of at if the limit exists. In addition  the convergence in probability is denoted by p→.

2.2 Observable operator models
An m-dimensional observable operator model (OOM) with observation space O can be represented by
a tuple M = (ω {Ξ(x)}x∈O  σ)  which consists of an initial state vector ω ∈ R1×m  an evaluation
vector σ ∈ Rm×1 and an observable operator matrix Ξ(x) ∈ Rm×m associated to each element
x ∈ O. M deﬁnes a stochastic process {xt} in O as

(1)
´
under the condition that ωΞ(x1:t)σ ≥ 0  ωΞ(O)σ = 1 and ωΞ(x1:t)σ = ωΞ(x1:t)Ξ(O)σ hold
for all t and x1:t ∈ Ot [10]  where Ξ(x1:t) (cid:44) Ξ(x1) . . . Ξ(xt) and Ξ(A) (cid:44)
A dx Ξ (x). Two
OOMs M and M(cid:48) are said to be equivalent if P (x1:t|M) ≡ P (x1:t|M(cid:48)).

P (x1:t|M) = ωΞ(x1:t)σ

3 Spectral learning of OOMs

3.1 Algorithm
Here and hereafter  we only consider the case that the observation space O is a ﬁnite set. (Learning
with continuous observations will be discussed in Section 4.2.) A large number of largely similar

2

Algorithm 1 General procedure for spectral learning of OOMs
INPUT: Observation trajectories generated by a stochastic process {xt} in O
OUTPUT: ˆM = ( ˆω { ˆΞ(x)}x∈O  ˆσ)
PARAMETER: m: dimension of the OOM. D1  D2: numbers of feature functions. L: order of
1: Construct feature functions φ1 = (ϕ1 1  . . .   ϕ1 D1 )(cid:62) and φ2 = (ϕ2 1  . . .   ϕ2 D2)(cid:62)  where

feature functions.
each ϕi j is a mapping from OL to R and D1  D2 ≥ m.

2: Approximate

¯φ1

(cid:44) E [φ1(xt−L:t−1)]  

C1 2 (cid:44) E(cid:2)φ1(xt−L:t−1)φ2(xt:t+L−1)(cid:62)(cid:3)
C1 3 (x) (cid:44) E(cid:2)1xt=x · φ1(xt−L:t−1)φ2(xt+1:t+L)(cid:62)(cid:3)  

(cid:44) E [φ2(xt:t+L−1)]

¯φ2

∀x ∈ O

(5)
(6)
(7)

by their empirical means ˆ¯φ1  ˆ¯φ2  ˆC1 2 and ˆC1 3 (x) over observation data.
3: Compute F1 = UΣ−1 ∈ RD1×m and F2 = V ∈ RD2×m from the truncated singular value
decomposition ˆC1 2 ≈ UΣV(cid:62)  where Σ ∈ Rm×m is a diagonal matrix contains the top m
singular values of ˆC1 2  and U and V consist of the corresponding m left and right singular
vectors of ˆC1 2.

4: Compute

1

ˆσ = F(cid:62)
ˆΞ(x) = F(cid:62)
1
(cid:62)
ˆω = ˆ¯φ
2 F2

ˆ¯φ1
ˆC1 3(x)F2 

∀x ∈ O

(8)
(9)
(10)

spectral methods have been developed  and the generic learning procedure of these methods is
summarized in Algorithm 1 by omitting details of algorithm implementation and parameter choice
[27  7  28]. For convenience of description and analysis  we specify in this paper the formula for
calculating ˆ¯φ1  ˆ¯φ2  ˆC1 2 and ˆC1 3 (x) in Line 2 of Algorithm 1 as follows:

N(cid:88)

n=1

N(cid:88)

n=1

N(cid:88)

n=1

n) 

N(cid:88)

n=1

ˆ¯φ1 =

1
N

φ1((cid:126)s 1

ˆ¯φ2 =

1
N

φ2((cid:126)s 2
n)

ˆC1 2 =

1
N

φ1((cid:126)s 1

n)φ2((cid:126)s 2

n)(cid:62)

ˆC1 3 (x) =

1
N

1s2

n=xφ1((cid:126)s 1

n)φ2((cid:126)s 3

n)(cid:62) 

∀x ∈ O

(2)

(3)

(4)

n  s2

n  s2

n  (cid:126)s 3

n  (cid:126)s 3

n)}N

n = xt−L:t−1 and (cid:126)s 3

n) with some n  then (cid:126)s 1

Here {((cid:126)s 1
n=1 is the collection of all subsequences of length (2L + 1) appearing in observa-
tion data (N = T − 2L for a single observation trajectory of length T ). If an observation subsequence
xt−L:t+L is denoted by ((cid:126)s 1
n = xt+1:t+L represents
the preﬁx and sufﬁx of xt−L:t+L of length L  s2
n = xt is the intermediate observation value  and
n = xt:t+L−1 is an “intermediate part” of the subsequence of length L starting from time t (see
(cid:126)s 2
Fig. 1 for a graphical illustration).
Algorithm 1 is much more efﬁcient than the commonly used likelihood-based learning algorithms
and does not suffer from local optima issues. In addition  and more importantly  this algorithm can be
n) are (i) independently sampled from M or (ii) obtained from
shown to be consistent if ((cid:126)s 1
a ﬁnite number of trajectories which have fully mixed so that all observation triples are identically
distributed (see  e.g.  [8  3  10] for related works). However  the asymptotic correctness of OOMs
learned from short trajectories starting from nonequilibrium states has not been formally determined.

n  (cid:126)s 3

n  s2

3

T (cid:48)(cid:88)

t=1

1
T (cid:48)

Figure 1: Illustration of variables (cid:126)s 1
xt−L:t+L.

n  s2

n  (cid:126)s 3

n and (cid:126)s 2

n used in Eqs. (2)-(4) with ((cid:126)s 1

n  s2

n  (cid:126)s 3

n) =

3.2 Theoretical analysis

We now analyze statistical properties of the spectral algorithm without the assumption of identically
distributed observations. Before stating our main result  some assumptions on observation data are
listed as follows:
Assumption 1. The observation data consists of I independent trajectories of length T produced
by a stochastic process {xt}  and the data size tends to inﬁnity with (i) I → ∞ and T = T0 or (ii)
T → ∞ and I = I0.
Assumption 2. {xt} is driven by an m-dimensional OOM M = (ω {Ξ(x)}x∈O  σ)  and

p→ E∞ [f (xt:t+l−1)] = E∞ [f (xt:t+l−1)|x1:k]

ft

(11)

as T (cid:48) → ∞ for all k  l  x1:k and f : Ol (cid:55)→ R.
Assumption 3. The rank of the limit of ˆC1 2 is not less than m.
Notice that Assumption 2 only states the asymptotic stationarity of {xt} and marginal distributions of
observation triples are possibly time dependent if ω (cid:54)= ωΞ (O). Assumption 3 ensures that the limit
of ˆM given by Algorithm 1 is well deﬁned  which generally holds for minimal OOMs (see [10]).
Based on the above assumptions  we have the following theorem concerning the statistical consistency
of the OOM learning algorithm (see Appendix A.1 for proof):
Theorem 1. Under Assumptions 1-3  there exists an OOM M(cid:48) = (ω(cid:48) {Ξ(cid:48)(x)}x∈O  σ(cid:48)) which is
equivalent to ˆM and satisﬁes

σ(cid:48) p→ σ  Ξ(cid:48)(x)

p→ Ξ(x)  ∀x ∈ O

(12)

This theorem is central in this paper  which implies that the spectral learning algorithm can achieve
consistent estimation of all parameters of OOMs except initial state vectors even for nonequilibrium
p→ ω(cid:48) does not hold in most cases except when {xt} is stationary.). It can be further
data. ( ˆω
generalized according to requirements in more complicated situations where  for example  observation
trajectories are generated with multiple different initial conditions (see Appendix A.2).

4 Spectral learning of equilibrium OOMs

In this section  applications of spectral learning to the problem of recovering equilibrium properties
of dynamic systems from nonequilibrium data will be highlighted  which is an important problem in
practice especially for thermodynamic and kinetic analysis in computational physics and chemistry.

4.1 Learning from discrete data

According to the deﬁnition of OOMs 
(ω {Ξ(x)}x∈O  σ) can be described by an equilibrium OOM Meq = (ωeq {Ξ(x)}x∈O  σ) as

the equilibrium dynamics of an OOM M =

lim
t→∞
if the equilibrium state vector

P (xt+1:t+k = z1:k|M) = P (x1:t = z1:k|Meq)

(13)

(14)

ωeq = lim

t→∞ ωΞ(O)t

4

 (cid:1876)(cid:3047)(cid:2879)(cid:3013)⋯ (cid:1876)(cid:3047)(cid:2879)(cid:2869) (cid:1876)(cid:3047) (cid:1876)(cid:3047)(cid:2878)(cid:2869)⋯ (cid:1876)(cid:3047)(cid:2878)(cid:3013)(cid:1871)(cid:1318)(cid:3041)(cid:2869)(cid:1871)(cid:1318)(cid:3041)(cid:2871)(cid:1871)(cid:3041)(cid:2870)(cid:1871)(cid:1318)(cid:3041)(cid:2870)exists. From (13) and (14)  we have

(cid:26) ωeqΞ(O) = limt→∞ ωeqΞ(O)t+1 = ωeq
ωeqσ = limt→∞(cid:80)
(cid:13)(cid:13)(cid:13)2
(cid:13)(cid:13)(cid:13)w ˆΞ(O) − w

x∈O P (xt+1 = x) = 1

ˆωeq = arg

w∈{w|w ˆσ=1}

min

(15)

(16)

The above equilibrium constraint of OOMs motivates the following algorithm for learning equilibrium
OOMs: Perform Algorithm 1 to get ˆΞ (x) and ˆσ and calculate ˆωeq by a quadratic programming
problem

(See Appendix A.3 for a closed-form expression of the solution to (16).)
The existence and uniqueness of ωeq are shown in Appendix A.3  which yield the following theorem:
Theorem 2. Under Assumptions 1-3  the estimated equilibrium OOM ˆMeq = ( ˆωeq { ˆΞ(x)}x∈O  ˆσ)
provided by Algorithm 1 and Eq. (16) satisﬁes
x1:l = z1:l| ˆMeq

(cid:17) p→ lim

P (xt+1:t+l = z1:l)

P(cid:16)

(17)

t→∞

for all l and z1:l.
Remark 1. ˆωeq can also be computed as an eigenvector of ˆΞ(O). But the eigenvalue problem possibly
yields numerical instability and complex values because of statistical noise  unless some speciﬁc
feature functions φ1  φ2 are selected so that ˆωeq ˆΞ(O) = ˆωeq can be exactly solved in the real ﬁeld
[29].

4.2 Learning from continuous data

A straightforward way to extend spectral algorithms to handle continuous data is based on the
coarse-graining of the observation space. Suppose that {xt} is a stochastic process in a continuous
observation space O ⊂ Rd  and O is partitioned into J discrete bins B1  . . .  BJ. Then we can utilize
the algorithm in Section 4.1 to approximate the equilibrium transition dynamics between bins as

(18)
and obtain a binned OOM ˆMeq = ( ˆωeq { ˆΞ(x)}x∈O  ˆσ) for the continuous dynamics of {xt} with

P (xt+1 ∈ Bj1   . . .   xt+l ∈ Bjl ) ≈ ˆωeq ˆΞ (Bj1 ) . . . ˆΞ (Bjl ) ˆσ

lim
t→∞

ˆΞ(B (x))
vol(B (x))

ˆΞ(x) =

(19)
by assuming the observable operator matrices are piecewise constant on bins  where B (x) denotes
the bin containing x and vol(B) is the volume of B. Conventional wisdom dictates that the number
of bins is a key parameter for the coarse-graining strategy and should be carefully chosen for the
balance of statistical noise and discretization error. However  we will show in what follows that it is
justiﬁable to increase the number of bins to inﬁnity.
Let us consider the limit case where J → ∞ and bins are inﬁnitesimal with maxj vol(Bj) → 0. In
this case 

(cid:26) ˆWs2

n

0 

ˆΞ(B (x))
vol(B (x))

=

δs2

n

(x)   x = s2
n

otherwise

(20)

ˆΞ(x) =

lim

vol(B(x))→0

where

n)(cid:62)F2

F(cid:62)
1 φ1((cid:126)s 1

1
N

ˆWs2

n

=

n}N

n)φ2((cid:126)s 3

(21)
according to (9) in Algorithm 1. Then ˆMeq becomes a binless OOM over sample points X =
{s2
n=1 and can be estimated from data by Algorithm 2  where the feature functions can be selected
as indicator functions  radial basis functions or other commonly used activation functions for single-
layer neural networks in order to digest adequate dynamic information from observation data.
The binless algorithm presented here can be efﬁciently implemented in a linear computational
complexity O(N )  and is applicable to more general cases where observations are strings  graphs or
other structured variables. Unlike the other spectral algorithms for continuous data  it does not require

5

Algorithm 2 Procedure for learning binless equilibrium OOMs
INPUT: Observation trajectories generated by a stochastic process {xt} in O ⊂ Rd
OUTPUT: Binless OOM ˆM = ( ˆω { ˆΞ(x)}x∈O  ˆσ)
1: Construct feature functions φ1 : RLd (cid:55)→ RD1 and φ2 : RLd (cid:55)→ RD2 with D1  D2 ≥ m.
2: Calculate ˆ¯φ1  ˆ¯φ2  ˆC1 2 by (2) and (3).
3: Compute F1 = UΣ−1 ∈ RD1×m and F2 = V ∈ RD2×m from the truncated singular value
z∈X ˆWzδz (x) by (8)  (16) and (21)  where ˆΞ(O) =

4: Compute ˆσ  ˆω and ˆΞ(x) = (cid:80)
decomposition ˆC1 2 ≈ UΣV(cid:62).
O dx ˆΞ(x) =(cid:80)
´

z∈X ˆWz.

that the observed dynamics coincides with some parametric model deﬁned by feature functions. Lastly
but most importantly  as stated in the following theorem  this algorithm can be used to consistently
extract static and kinetic properties of a dynamic system in equilibrium from nonequilibrium data
(see Appendix A.3 for proof):
Theorem 3. Provided that the observation space O is a closed set in Rd  feature functions φ1  φ2
are bounded on OL  and Assumptions 1-3 hold  the binless OOM given by Algorithm 2 satisﬁes

with

E(cid:104)

E(cid:104)

(cid:105) p→ E∞ [g (xt+1:t+r)]
(cid:88)

g (x1:r)| ˆMeq

(cid:105)

g (x1:r)| ˆMeq

=

g (x1:r) ˆω ˆWz1 . . . ˆWzr ˆσ

(22)

(23)

x1:r∈X r
(i) for all continuous functions g : Or (cid:55)→ R.
(ii) for all bounded and Borel measurable functions g : Or (cid:55)→ R  if there exist positive constants
¯ξ and ξ so that (cid:107)Ξ (x)(cid:107) ≤ ¯ξ and limt→∞ P (xt+1:t+r = z1:r) ≥ ξ for all x ∈ O and
z1:r ∈ Or.

4.3 Comparison with related methods

It is worth pointing out that the spectral learning investigated in this section is an ideal tool for analy-
sis of dynamic properties of stochastic processes  because the related quantities  such as stationary
distributions  principle components and time-lagged correlations  can be easily computed from pa-
rameters of discrete OOMs or binless OOMs. For many popular nonlinear dynamic models  including
Gaussian process state-space models [17] and recurrent neural networks [19]  the computation of
such quantities is intractable or time-consuming.
The major disadvantage of spectral learning is that the estimated OOMs are usually only “approx-
imately valid” and possibly assign “negative probabilities” to some observation sequences. So it
is difﬁcult to apply spectral methods to prediction  ﬁltering and smoothing of signals where the
Bayesian inference is involved.

5 Applications

In this section  we evaluate our algorithms on two diffusion processes and the molecular dynamics of
alanine dipeptide  and compare them to several alternatives. The detailed settings of simulations and
algorithms are provided in Appendix B.

Brownian dynamics Let us consider a one-dimensional diffusion process driven by the Brownian
dynamics

dxt = −∇V (xt)dt +

2β−1dWt

(24)

with observations generated by

yt =

(cid:112)
(cid:26) 1  xt ∈ I

0  xt ∈ II

6

Figure 2: Comparison of modeling methods for a one-dimensional diffusion process. (a) Potential
function. (b) Estimates of the difference between equilibrium probabilities of I and II given by the
traditional OOM  HMM and the equilibrium OOM (EQ-OOM) obtained from the proposed algorithm
with O = {I  II}. (c) Estimates of the probability difference given by the empirical estimator  HMM
and the proposed binless OOM with O = [0  2]. (d) Stationary histograms of {xt} with 100 uniform
bins estimated from trajectories with length 50. The length of each trajectory is T = 50 ∼ 1000
and the number of trajectories is [105/T ]. Error bars are standard deviations over 30 independent
experiments.

The potential function V (x) is shown in Fig. 2(a)  which contains two potential wells I  II. In this
example  all simulations are performed by starting from a uniform distribution on [0  0.2]  which
implies that simulations are highly nonequilibrium and it is difﬁcult to accurately estimate the
equilibrium probabilities ProbI = E∞ [1xt∈I] = E∞ [yt] and ProbII = E∞ [1xt∈II] = 1 − E∞ [yt]
of the two potential wells from the simulation data. We ﬁrst utilize the traditional spectral learning
without enforcing equilibrium  expectation–maximization based HMM learning and the proposed
discrete spectral algorithm to estimate ProbI and ProbII based on {yt}  and the estimation results
with different simulation lengths are summarized in Fig. 2(b). It can be seen that  in contrast to with
the other methods  the spectral algorithm for equilibrium OOMs effectively reduce the statistical bias
in the nonequilibrium data  and achieves statistically correct estimation at T = 300.
Figs. 2(c) and 2(d) plot estimates of stationary distribution of {xt} obtained from {xt} directly  where
the empirical estimator calculates statistics through averaging over all observations. In this case  the
proposed binless OOM signiﬁcantly outperform the other methods  and its estimates are very close to
true values even for extremely small short trajectories.
Fig. 3 provides an example of a two-dimensional diffusion process. The dynamics of this process can
also be represented in the form of (24) and the potential function is shown in Fig. 3(a). The goal of
this example is to estimate the ﬁrst time-structure based independent component wTICA [30] of this
process from simulation data. Here wTICA is a kinetic quantity of the process and is the solution to
the generalized eigenvalue problem
with the largest eigenvalue  where C0 is the covariance matrix of {xt} in equilibrium and

(cid:3)(cid:1) is the equilibrium time-lagged covariance matrix. The

Cτ =(cid:0)E∞(cid:2)xtx(cid:62)

simulation data are also nonequilibrium with all simulations starting from the uniform distribution on
[−2  0] × [−2  0]. Fig. 3(b) displays the estimation errors of wTICA obtained from different learning
methods  which also demonstrates the superiority of the binless spectral method.

(cid:3) − E∞ [xt] E∞(cid:2)x(cid:62)

t

t+τ

Cτ w = λC0w

Alanine dipeptide Alanine dipeptide is a small molecule which consists of two alanine amino acid
units  and its conﬁguration can be described by two backbone dihedral angles. Fig. 4(a) shows the
potential proﬁle of the alanine dipeptide with respect to the two angles  which contains ﬁve metastable

7

True OOM Empirical HMM EQ-OOM(cid:1876)trajectory lengthtrajectory length(cid:1876)histogram(a)(b)(c)(d)IIIFigure 3: Comparison of modeling methods for a two-dimensional diffusion process. (a) Potential
function. (b) Estimation error of wTICA ∈ R2 of the ﬁrst TIC with lag time 100. Length of each
trajectory is T = 200 ∼ 2500 and the number of trajectories is [105/T ]. Error bars are standard
deviations over 30 independent experiments.

Figure 4: Comparison of modeling methods for molecular dynamics of alanine dipeptide. (a) Reduced
free energy. (b) Estimation error of π  where the horizontal axis denotes the total simulation time
T × I. Length of each trajectory is T = 10ns and the number of trajectories is I = 150 ∼ 1500.
Error bars are standard deviations over 30 independent experiments.

states {I  II  III  IV  V}. We perform multiple short molecular dynamics simulations starting from
the metastable state IV  where each simulation length is 10ns  and utilizes different methods to
approximate the stationary distribution π = (ProbI  ProbII  . . .   ProbV) of the ﬁve metastable states.
As shown in Fig. 4(b)  the proposed binless algorithm yields lower estimation error compared to each
of the alternatives.

6 Conclusion

In this paper  we investigated the statistical properties of the general spectral learning procedure for
nonequilibrium data  and developed novel spectral methods for learning equilibrium dynamics from
nonequilibrium (discrete or continuous) data. The main ideas of the presented methods are to correct
the model parameters by the equilibrium constraint and to handle continuous observations in a binless
manner. Interesting directions of future research include analysis of approximation error with ﬁnite
data size and applications to controlled systems.

Acknowledgments

This work was funded by Deutsche Forschungsgemeinschaft (SFB 1114) and European Research
Council (starting grant “pcCells”).

References
[1] H. Jaeger  “Observable operator models for discrete stochastic time series ” Neural Comput.  vol. 12  no. 6 

pp. 1371–1398  2000.

[2] M.-J. Zhao  H. Jaeger  and M. Thon  “A bound on modeling error in observable operator models and an

associated learning algorithm ” Neural Comput.  vol. 21  no. 9  pp. 2687–2712  2009.

[3] H. Jaeger  “Discrete-time  discrete-valued observable operator models: a tutorial ” tech. rep.  International

University Bremen  2012.

[4] M. L. Littman  R. S. Sutton  and S. Singh  “Predictive representations of state ” in Adv. Neural. Inf. Process.

Syst. 14 (NIPS 2001)  pp. 1555–1561  2001.

8

coord1coord2trajectory lengtherror of (a)(b)Empirical HMMEQ-OOMangle 1angle 2simulation time (ns)error of (a)(b)EmpiricalHMMEQ-OOMIIIIIIIIIIVVV[5] S. Singh  M. James  and M. Rudary  “Predictive state representations: A new theory for modeling dynamical

systems ” in Proc. 20th Conf. Uncertainty Artif. Intell. (UAI 2004)  pp. 512–519  2004.

[6] E. Wiewiora  “Learning predictive representations from a history ” in Proc. 22nd Intl. Conf. on Mach. Learn.

(ICML 2005)  pp. 964–971  2005.

[7] D. Hsu  S. M. Kakade  and T. Zhang  “A spectral algorithm for learning hidden Markov models ” in Proc.

22nd Conf. Learning Theory (COLT 2009)  pp. 964–971  2005.

[8] S. Siddiqi  B. Boots  and G. Gordon  “Reduced-rank hidden Markov models ” in Proc. 13th Intl. Conf. Artif.

Intell. Stat. (AISTATS 2010)  vol. 9  pp. 741–748  2010.

[9] A. Beimel  F. Bergadano  N. H. Bshouty  E. Kushilevitz  and S. Varricchio  “Learning functions represented

as multiplicity automata ” J. ACM  vol. 47  no. 3  pp. 506–530  2000.

[10] M. Thon and H. Jaeger  “Links between multiplicity automata  observable operator  models and predictive
state representations — a uniﬁed learning framework ” J. Mach. Learn. Res.  vol. 16  pp. 103–147  2015.

[11] J.-H. Prinz  H. Wu  M. Sarich  B. Keller  M. Senne  M. Held  J. D. Chodera  C. Schütte  and F. Noé 
“Markov models of molecular kinetics: Generation and validation ” J. Chem. Phys.  vol. 134  p. 174105 
2011.

[12] G. R. Bowman  V. S. Pande  and F. Noé  An introduction to Markov state models and their application to

long timescale molecular simulation. Springer  2013.

[13] A. Ruttor  P. Batz  and M. Opper  “Approximate Gaussian process inference for the drift function in
stochastic differential equations ” in Adv. Neural. Inf. Process. Syst. 26 (NIPS 2013)  pp. 2040–2048  2013.
[14] N. Schaudinnus  B. Bastian  R. Hegger  and G. Stock  “Multidimensional langevin modeling of nonover-

damped dynamics ” Phys. Rev. Lett.  vol. 115  no. 5  p. 050602  2015.

[15] L. R. Rabiner  “A tutorial on hidden markov models and selected applications in speech recognition ” Proc.

IEEE  vol. 77  no. 2  pp. 257–286  1989.

[16] F. Noé  H. Wu  J.-H. Prinz  and N. Plattner  “Projected and hidden markov models for calculating kinetics

and metastable states of complex molecules ” J. Chem. Phys.  vol. 139  p. 184114  2013.

[17] R. D. Turner  M. P. Deisenroth  and C. E. Rasmussen  “State-space inference and learning with Gaussian

processes ” in Proc. 13th Intl. Conf. Artif. Intell. Stat. (AISTATS 2010)  pp. 868–875  2010.

[18] S. S. T. S. Andreas Svensson  Arno Solin  “Computationally efﬁcient bayesian learning of Gaussian process

state space models ” in Proc. 19th Intl. Conf. Artif. Intell. Stat. (AISTATS 2016)  pp. 213–221  2016.

[19] S. Hochreiter and J. Schmidhuber  “Long short-term memory ” Neural Comp.  vol. 9  no. 8  pp. 1735–1780 

1997.

[20] H. Wu  J.-H. Prinz  and F. Noé  “Projected metastable markov processes and their estimation with

observable operator models ” J. Chem. Phys.  vol. 143  no. 14  p. 144101  2015.

[21] M. Shirts and V. S. Pande  “Screen savers of the world unite ” Science  vol. 290  pp. 1903–1904  2000.
[22] T.-K. Huang and J. Schneider  “Spectral learning of hidden Markov models from dynamic and static data ”

in Proc. 30th Intl. Conf. on Mach. Learn. (ICML 2013)  pp. 630–638  2013.

[23] M. K. Cowles and B. P. Carlin  “Markov chain monte carlo convergence diagnostics: a comparative review ”

J. Am. Stat. Assoc.  vol. 91  no. 434  pp. 883–904  1996.

[24] N. Jiang  A. Kulesza  and S. Singh  “Improving predictive state representations via gradient descent ” in

Proc. 30th AAAI Conf. Artif. Intell. (AAAI 2016)  2016.

[25] H. Jaeger  “Modeling and learning continuous-valued stochastic processes with OOMs ” Tech. Rep.

GMD-102  German National Research Center for Information Technology (GMD)  2001.

[26] B. Boots  S. M. Siddiqi  G. Gordon  and A. Smola  “Hilbert space embeddings of hidden markov models ”

in Proc. 27th Intl. Conf. on Mach. Learn. (ICML 2010)  2010.

[27] M. Rosencrantz  G. Gordon  and S. Thrun  “Learning low dimensional predictive representations ” in Proc.

22nd Intl. Conf. on Mach. Learn. (ICML 2004)  pp. 88–95  ACM  2004.

[28] B. Boots  Spectral Approaches to Learning Predictive Representations. PhD thesis  Carnegie Mellon

University  2012.

[29] H. Jaeger  M. Zhao  and A. Kolling  “Efﬁcient estimation of OOMs ” in Adv. Neural. Inf. Process. Syst. 18

(NIPS 2005)  pp. 555–562  2005.

[30] G. Perez-Hernandez  F. Paul  T. Giorgino  G. De Fabritiis  and F. Noé  “Identiﬁcation of slow molecular

order parameters for markov model construction ” J. Chem. Phys.  vol. 139  no. 1  p. 015102  2013.

9

,Hao Wu
Frank Noe
Jordan Awan
Aleksandra Slavković