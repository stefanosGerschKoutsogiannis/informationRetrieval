2019,A Necessary and Sufficient Stability Notion for Adaptive Generalization,We introduce a new notion of the stability of computations  which holds under post-processing and adaptive composition. We show that the notion is both necessary and sufficient to ensure generalization in the face of adaptivity  for any computations that respond to bounded-sensitivity linear queries while providing accuracy with respect to the data sample set. The stability notion is based on quantifying the effect of observing a computation's outputs on the posterior over the data sample elements. We show a separation between this stability notion and previously studied notion and observe that all differentially private algorithms also satisfy this notion.,A necessary and sufﬁcient stability notion for

adaptive generalization

Katrina Ligett

Moshe Shenfeld

School of Computer Science & Engineering

School of Computer Science & Engineering

Hebrew University of Jerusalem

Jerusalem 91904  Israel

katrina@cs.huji.ac.il

Hebrew University of Jerusalem

Jerusalem 91904  Israel

moshe.shenfeld@cs.huji.ac.il

Abstract

We introduce a new notion of the stability of computations  which holds under post-
processing and adaptive composition. We show that the notion is both necessary and
sufﬁcient to ensure generalization in the face of adaptivity  for any computations
that respond to bounded-sensitivity linear queries while providing accuracy with
respect to the data sample set. The stability notion is based on quantifying the effect
of observing a computation’s outputs on the posterior over the data sample elements.
We show a separation between this stability notion and previously studied notion
and observe that all differentially private algorithms also satisfy this notion.

1

Introduction

A fundamental idea behind most forms of data-driven research and machine learning is the concept
of generalization–the ability to infer properties of a data distribution by working only with a sample
from that distribution. One typical approach is to invoke a concentration bound to ensure that  for a
sufﬁciently large sample size  the evaluation of the function on the sample set will yield a result that is
close to its value on the underlying distribution  with high probability. Intuitively  these concentration
arguments ensure that  for any given function  most sample sets are good “representatives” of the
distribution. Invoking a union bound  such a guarantee easily extends to the evaluation of multiple
functions on the same sample set.
Of course  such guarantees hold only if the functions to be evaluated were chosen independently
of the sample set.
In recent years  grave concern has erupted in many data-driven ﬁelds  that
adaptive selection of computations is eroding statistical validity of scientiﬁc ﬁndings [Ioa05  GL14].
Adaptivity is not an evil to be avoided—it constitutes a natural part of the scientiﬁc process  wherein
previous ﬁndings are used to develop and reﬁne future hypotheses. However  unchecked adaptivity
can (and does  as demonstrated by  e.g.  [DFH+15b] and [RZ16]) often lead one to evaluate overﬁtting
functions—ones that return very different values on the sample set than on the distribution.
Traditional generalization guarantees do not necessarily guard against adaptivity; while generalization
ensures that the response to a query on a sample set will be close to that of the same query on the
distribution  it does not rule out the possibility that the probability to get a speciﬁc response will be
dramatically affected by the contents of the sample set. In the extreme  a generalizing computation
could encode the whole sample set in the low-order bits of the output  while maintaining high
accuracy with respect to the underlying distribution. Subsequent adaptive queries could then  by
post-processing the computation’s output  arbitrarily overﬁt to the sample set.
In recent years  an exciting line of work  starting with Dwork et al. [DFH+15b]  has formalized
this problem of adaptive data analysis and introduced new techniques to ensure guarantees of
generalization in the face of an adaptively-chosen sequence of computations (what we call here

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

adaptive generalization). One great insight of Dwork et al. and followup work was that techniques
for ensuring the stability of computations (some of them originally conceived as privacy notions) can
be powerful tools for providing adaptive generalization.
A number of papers have considered variants of stability notions  the relationships between them  and
their properties  including generalization properties. Despite much progress in this space  one issue
that has remained open is the limits of stability—how much can the stability notions be relaxed  and
still imply generalization? It is this question that we address in this paper.

1.1 Our Contribution

We introduce a new notion of the stability of computations  which holds under post-processing
(Theorem 2.3) and adaptive composition (Theorems 2.6 and 2.7)  and show that the notion is both
necessary (Theorem 3.6) and sufﬁcient (Theorem 3.3) to ensure generalization in the face of adaptivity 
for any computations that respond to bounded-sensitivity linear queries (see Deﬁnition 3.1) while
providing accuracy with respect to the data sample set. This means (up to a small caveat)1 that our
stability deﬁnition is equivalent to generalization  assuming sample accuracy  for bounded linear
queries. Linear queries form the basis for many learning algorithms  such as those that rely on
gradients or on the estimation of the average loss of a hypothesis.
In order to formulate our stability notion  we consider a prior distribution over the database elements
and the posterior distribution over those elements conditioned on the output of a computation. In
some sense  harmful outputs are those that induce large statistical distance between this prior and
posterior (Deﬁnition 2.1). Our new notion of stability  Local Statistical Stability (Deﬁnition 2.2) 
intuitively  requires a computation to have only small probability of producing such a harmful output.
In Section 4  we directly prove that Differential Privacy  Max Information  Typical Stability and
Compression Schemes all imply Local Statistical Stability  which provides an alternative method to
establish their generalization properties. We also provide a few separation results between the various
deﬁnitions.

1.2 Additional Related Work

Most countermeasures to overﬁtting fall into one of a few categories. A long line of work bases
generalization guarantees on some form of bound on the complexity of the range of the mechanism 
e.g.  its VC dimension (see [SSBD14] for a textbook summary of these techniques). Other examples
include Bounded Description Length [DFH+15a]  and compression schemes [LW86] (which addi-
tionally hold under post-processing and adaptive composition [DFH+15a  CLN+16]). Another line
of work focuses on the algorithmic stability of the computation [BE02]  which bounds the effects on
the output of changing one element in the training set.
A different category of stability notions  which focus on the effect of a small change in the sample
set on the probability distribution over the range of possible outputs  has recently emerged from the
notion of Differential Privacy [DMNS06]. Work of [DFH+15b] established that Differential Privacy 
interpreted as a stability notion  ensures generalization; it is also known (see [DR+14]) to be robust
to adaptivity and to withstand post-processing. A number of subsequent works propose alternative
stability notions that weaken the conditions of Differential Privacy in various ways while attempting
to retain its desirable generalization properties. One example is Max Information [DFH+15a]  which
shares the guarantees of Differential Privacy. A variety of other stability notions ([RRST16  RZ16 
RRT+16  BNS+16  FS17  EGI19])  unlike Differential Privacy and Max Information  only imply
generalization in expectation. [XR17  Ala17  BMN+17] extend these guarantees to generalization in
probability  under various restrictions.
[CLN+16] introduce the notion of post-hoc generalization  which captures robustness to post-
processing  but it was recently shown not to hold under composition [NSS+18]. The challenges that
the internal correlation of non-product distributions present for stability have been studied in the
context of Inferential Privacy [GK16] and Typical Stability [BF16].

1In particular  our lower bound (Theorem 3.6) requires one more query than our upper bound (Theorem 3.3).

2

2 LS stability deﬁnition and properties
Let X be an arbitrary countable domain. Fixing some n ∈ N  let DX n be some probability distribution
deﬁned over X n.2 Let Q R be arbitrary countable sets which we will refer to as queries and responses 
respectively. Let a mechanism M : X n × Q → R be a (possibly non-deterministic) function that 
given a sample set s ∈ X n and a query q ∈ Q  returns a response r ∈ R. Intuitively  queries can be
thought of as questions the mechanism is asked about the sample set  usually representing functions
from X n to R; the mechanism can be thought of as providing an estimate to the value of those
functions  but we do not restrict the deﬁnitions  for reasons which will become apparent once we
introduce the notion of adaptivity (Deﬁnition 2.4).
This setting involves two sources of randomness  the underlying distribution DX n  and the conditional
distribution DqR|X n (r | s)—that is  the probability to get r as the output of M (s  q). These in turn
induce a set of distributions (formalized in Deﬁnition A.1): the marginal distribution over R  the
(X n R)) and product distribution (denoted DqX n⊗R) over X n × R  and
joint distribution (denoted Dq
the conditional distribution over X n given r ∈ R. Note that even if DX n is a product distribution 
this conditional distribution might not be a product distribution. Although the underlying distribution
DX n is deﬁned over X n  it induces a natural probability distribution over X as well  by sampling one
of the sample elements in the set uniformly at random.3 This in turn allows us extend our deﬁnitions
to several other distributions  which form a connection between R and X (formalized in Deﬁnition
A.2): the marginal distribution over X   the joint distribution and product distribution over X ×R  the
conditional distribution over R given x ∈ X   and the conditional distribution over X given r ∈ R.
We use our distribution notation to denote both the probability that a distribution places on a subset
of its range and the probability placed on a single element of the range.

Notational conventions We use calligraphic letters to denote domains  lower case letters to denote
elements of these domains  capital letters to denote random variables taking values in these domains 
and bold letters to denote subsets of these domains. We omit subscripts and superscripts from some
notation when they are clear from context.

2.1 Local Statistical Stability

Before observing any output from the mechanism  an outside observer knowing D but without other
information about the sample set s holds prior D (x) that sampling an element of s would return a
particular x ∈ X . Once an output r of the mechanism is observed  however  the observer’s posterior
becomes D (x| r). The difference between these two distributions is what determines the resulting
degradation in stability. This difference could be quantiﬁed using a variety of distance measures (a
partial list can be found in Appendix F); here we introduce a particular one which we use to deﬁne
our stability notion.
Deﬁnition 2.1 (Stability loss of a response). Given a distribution DX n  a query q  and a mechanism
DX n (r) of a response r ∈ R with respect to DX n and q is
M : X n × Q → R  the stability loss (cid:96)q
deﬁned as the Statistical Distance (Deﬁnition F.1) between the prior distribution over X and the
(cid:88)
posterior induced by r. That is 

(D (x| r) − D (x))  

(cid:96)q
DX n (r) :=

x∈x+(r)

where x+ (r) := {x ∈ X | D (x| r) > D (x)}  the set of all sample elements which have a posterior
probability (given r) higher then their prior. Similarly  we deﬁne the stability loss (cid:96) (r) of a set of
responses r ⊆ R as

Given 0 ≤  ≤ 1  a response will be called -unstable with respect to DX n and q if its loss is greater
the . The set of all -unstable responses will be denoted rDX n  q

:= {r ∈ R| (cid:96) (r) > }.



2Throughout the paper  X n can either denote the family of sequences of length n or a multiset of size n; that
3It is worth noting that in the case where DX n is the product distribution of some distribution PX over X  

is  the sample set s can be treated as an ordered or unordered set.
we get that the induced distribution over X is PX .

3

(cid:80)

(cid:96) (r) :=

r∈r D (r) · (cid:96) (r)

.

D (r)

We now introduce our notion of stability of a mechanism.
Deﬁnition 2.2 (Local Statistical Stability). Given 0 ≤   δ ≤ 1  a distribution DX n  and a query q  a
mechanism M : X n × Q → R will be called (  δ)-Local-Statistically Stable with respect to DX n
and q (or LS Stable  or LSS  for short) if for any r ⊆ R  D (r) · ((cid:96) (r) − ) ≤ δ.
Notice that the maximal value of the left hand side is achieved for the subset r. This stability
deﬁnition can be extended to apply to a family of queries and/or a family of possible distributions.
When there exists a family of queries Q and a family of distributions D such that a mechanism M
is (  δ)-LSS for all DX n ∈ D and for all q ∈ Q  then M will be called (  δ)-LSS for D Q. (This
stability notion somewhat resembles Semantic Privacy as discussed by [KS14]  though they use it to
compare different posterior distributions.)

Intuitively  this can be thought of as placing a δ bound on the probability of observing an outcome
whose stability loss exceeds . This claim is formalized in Lemma B.1.

2.2 Properties

We now turn to prove two crucial properties of LSS: post-processing and adaptive composition.
Post-processing guarantees (known in some contexts as data processing inequalities) ensure that
the stability of a computation can only be increased by subsequent manipulations. This is a key
desideratum for concepts used to ensure adaptivity-proof generalization  since otherwise an adaptive
subsequent computation could potentially arbitrarily degrade the generalization guarantees.
Theorem 2.3 (LSS holds under Post-Processing). Given 0 ≤   δ ≤ 1  a distribution DX n  and a
query q  if a mechanism M is (  δ)-LSS with respect to DX n and q  then for any range U and any
arbitrary (possibly non-deterministic) function f : R → U  we have that f ◦ M : X n × Q → U is
also (  δ)-LSS with respect to DX n and q. An analogous statement also holds for mechanisms that
are LSS with respect to a family of queries and/or a family of distributions.

The proof appears in Appendix B.1.
In order to formally deﬁne adaptive learning and stability under adaptively chosen queries  we
formalize the notion of an analyst who issues those queries.
Deﬁnition 2.4 (Analyst and Adaptive Mechanism). An analyst over a family of queries Q is a
(possibly non-deterministic) function A : R∗ → Q that receives a view—a ﬁnite sequence of
responses—and outputs a query. We denote by A the family of all analysts  and write Vk := Rk and
V := R∗.
Illustrated below  the adaptive mechanism Adp ¯M : X n × A → Vk is a particular type of mechanism 
which inputs an analyst as its query and which returns a view as its range type. It is parameterized
i=1 where ∀i ∈ [k]  Mi : X n × Q → R. Given a
by a sequence of sub-mechanisms ¯M = (Mi)k
sample set s and an analyst A as input  the adaptive mechanism iterates k times through the process
where A sends a query to Mi and receives its response to that query on the sample set. The adaptive
mechanism returns the resulting sequence of k responses vk. Naturally  this requires A to match M
such that M’s range can be A’s input  and vice versa.4 5

For illustration  consider a gradient descent algorithm  where at each step the algorithm requests an
estimate of the gradient at a given point  and chooses the next point in which the gradient should be
evaluated based on the response it receives. For us  M evaluates the gradient at a given point  and A

4If the same mechanism appears more then once in ¯M  it can also be stateful  which means it retains an
internal record consisting of internal randomness  the history of sample sets and queries it has been fed  and the
responses it has produced; its behavior may be a function of this internal record. We omit this from the notation
for simplicity  but do refer to this when relevant. A stateful mechanism will be deﬁned as LSS if it is LSS given
any reachable internal record. A pedantic treatment might consider the probability that a particular internal state
could be reached  and only require LSS when accounting for these probabilities.

5If A is randomized  we add one more step at the beginning where Adp ¯M randomly generates some bits
c—A’s “coin tosses.” In this case  vk := (c  r1  . . .   rik) and A receives the coin tosses as an input as well. This
addition turns qk+1 into a deterministic function of vi for any i ∈ N  a fact that will be used multiple times
throughout the paper. In this situation  the randomness of Adp ¯M results both from the randomness of the coin
tosses and from that of the sub-mechanisms.

4

Adaptive Mechanism Adp ¯M
Input: s ∈ X n  A ∈ A
Output: vk ∈ Vk
v0 ← ∅ or c
for i ∈ [k] :
qi ← A (vi−1)
ri ← Mi (s  qi)
vi ← (vi−1  ri)
return vk

determines the next point to be considered. The interaction between the two of them constitutes an
adaptive learning process.
Deﬁnition 2.5 (k-LSS under adaptivity). Given 0 ≤   δ ≤ 1  a distribution DX n  and an analyst
A  a sequence of k mechanisms ¯M will be called (  δ)-local-statistically stable under k adaptive
iterations with respect to DX n and A (or k-LSS for short)  if Adp ¯M is (  δ)-LSS with respect to DX n
and A (in which case we will use vk A DX n
to denote the set of  unstable views). This deﬁnition can
be extended to a family of analysts and/or a family of possible distributions as well.



Adaptive composition is a key property of a stability notion  since it restricts the degradation of
stability across multiple computations. A key observation is that the posterior D (s| vk) is itself
a distribution over X n and qk+1 is a deterministic function of vk. Therefore  as long as each sub-
mechanism is LSS with respect to any posterior that could have been induced by previous adaptive
interaction  one can reason about the properties of the composition.
We ﬁrst show that the stability loss of a view is bounded by the sum of losses of its responses
with respect to the sub-mechanisms  which provides a linear bound on the degradation of the LSS
parameters. Adding a bound on the expectation of the loss of the sub-mechanisms allows us to also
invoke Azuma’s inequality and prove a sub-linear bound.
Theorem 2.6 (LSS adaptively composes linearly). Given a family of distributions D over X n  a
family of queries Q  and a sequence of k mechanisms ¯M where ∀i ∈ [k]  Mi : X n × Q → R  we
will denote DM0 Q := D  and for any i > 0  DMi Q will denote the set of all posterior distributions
induced by any response of Mi with non-zero probability with respect to DMi−1 Q and Q (see
Deﬁnition B.2).
Given a sequence 0 ≤ 1  δ1  . . .   k  δk ≤ 1  if for all i  Mi is (i  δi)-LSS with respect to DMi−1 Q
and Q  the sequence is
-k-LSS with respect to D and any analyst A over Q × R.

(cid:32)(cid:80)

i  (cid:80)

(cid:33)

δi

i∈[k]

i∈[k]

The proof appears in Appendix B.3.
One simple case is when DMi−1 Q = D  and Mi is (i  δi)-LSS with respect to D and Q  for all i.
(cid:33)
Theorem 2.7 (LSS adaptively composes sub-linearly). Under the same conditions as Theorem
2.6  given 0 ≤ α1  . . .   αk ≤ 1  such that for all i and any DX n ∈ DMi−1 Q  and q ∈ Q 
-k-

[(cid:96) (R)] ≤ αi  then for any 0 ≤ δ(cid:48) ≤ 1  the sequence is

E

S∼DX n  R∼Mi(s q)
LSS with respect to D and any analyst A over Q × R  where (cid:48) :=

(cid:32)
(cid:48)  δ(cid:48) + (cid:80)
(cid:1) (cid:80)
i + (cid:80)

2

i∈[k]

i∈[k]

δi
i

αi.

(cid:114)

8ln(cid:0) 1

δ(cid:48)

i∈[k]

The theorem provides a better bound then the previous one in case αi (cid:28) i  in which case the
dominating term is the ﬁrst one  which is sub-linear in k. The proof appears in Appendix B.4.

3 LSS is Necessary and Sufﬁcient for Generalization

Up until this point  queries and responses have been fairly abstract concepts. In order to discuss
generalization and accuracy  we must make them concrete. As a result  in this section  we often
consider queries in the family of functions q : X n → R  and consider responses which have some

5

n(cid:80)

metric deﬁned over them. We show our results for a fairly general class of functions known as
bounded linear queries.6
Deﬁnition 3.1 (Linear queries). A function q : X n → R will be called a linear query  if it is deﬁned
by a function q1 : X → R such that q (s) := 1
q1 (si) (for simplicity we will denote q1 simply
as q throughout the paper). If q : X → [−∆  ∆] it will be called a ∆-bounded linear query. The set
of ∆-bounded linear queries will be denoted Q∆.
In this context  there is a “correct” answer the mechanism can produce for a given query  deﬁned as
the value of the function on the sample set or distribution  and its distance from the response provided
by the mechanism can be thought of as the mechanism’s error.
Deﬁnition 3.2 (Sample accuracy  distribution accuracy). Given 0 ≤   0 ≤ δ ≤ 1  a distribution
DX n  and a query q  a mechanism M : X n × Q → R will be called (  δ)-Sample Accurate with
respect to DX n and q  if

i=1

n

Pr

S∼DX n  R∼M (S q)

[|R − q (S)| > ] ≤ δ.

Such a mechanism will be called (  δ)-Distribution Accurate with respect to DX n and q if

Pr

[|R − q (DX n )| > ] ≤ δ 

S∼DX n

S∼DX n  R∼M (S q)
[q (S)]. When there exists a family of distributions D and a family of
where q (DX n) := E
queries Q such that a mechanism M is (  δ)-Sample (Distribution) Accurate for all D ∈ D and for
all q ∈ Q  then M will be called (  δ)-Sample (Distribution) Accurate with respect to D and Q.
A sequence of k mechanisms ¯M where ∀i ∈ [k] : Mi : X n × Q → R which respond to a sequence
of k (potentially adaptively chosen) queries q1  . . . qk will be called (  δ)-k-Sample Accurate with
respect to DX n and q1  . . . qk if

(cid:20)

(cid:20)

(cid:21)

(cid:21)

Pr

S∼DX n  Ri∼Mi(S qi)

max
i∈k

|Ri − qi (S)| > 

≤ δ 

and (  δ)-k-Distribution Accurate with respect to DX n and q1  . . . qk if
|Ri − qi (DX n )| > 

Pr

≤ δ.

S∼DX n  Ri∼Mi(S qi)

max
i∈k

When considering an adaptive process  accuracy is deﬁned with respect to the analyst  and the
probabilities are taken also over the choice of the coin tosses by the adaptive mechanism.7
We denote by V the set of views consisting of responses in R.
We now show that if a mechanism returns accurate results with respect to the sample set  then being
LSS implies accuracy on the underlying distribution.
Theorem 3.3 (LSS implies generalization with high probability). Given 0 ≤  ≤ ∆  0 ≤ δ ≤ 1 
a distribution DX n  and an analyst A : V → Q∆  if a sequence of k mechanisms ¯M where
∀i ∈ [k]   Mi : X n ×Q∆ → R is both
respect to DX n and A  then it is (  δ)-k-Distribution Accurate with respect to DX n and A.

(cid:1)-k-Sample Accurate with

-k-LSS and(cid:0) 

(cid:16) 

(cid:17)

4800∆2

8∆  

8  

δ

600∆

2δ

The proof of this theorem consists of two stages  and follows the method introduced by [BNS+16].
First we show that the a query returned by an LSS mechanism has expected value on the underlying
distribution that is close to its value on the sample set that the mechanism received as input (Appendix
C.1). We then proceed to lift this guarantee from expectation to high probability  using a thought
experiment known as the Monitor Mechanism (Appendix C.2). Intuitively  it runs a large number of
6For simplicity  throughout the following section we choose R = R  but all results extend to any metric

space  in particular Rd.

7If the adaptive mechanism invokes a stateful sub-mechanism multiple times  we specify that the mechanism
is Sample (Distribution) Accurate if it is Sample (Distribution) Accurate given any reachable internal record.
Again  a somewhat more involved treatment might consider the probability that a particular internal state of the
mechanism could be reached.

6

independent copies of an underlying mechanism  and exposes the results of the least-distribution-
accurate copy as its output. If the expected error of even this least-accurate-copy is relatively low 
then the underlying mechanism generalizes with high probability (Appendix C.3).
We next show that a mechanism that is not LSS cannot be both Sample Accurate and Distribution
Accurate. In order to prove this theorem  we show how to construct a “bad” query.
Deﬁnition 3.4 (Loss assessment query). Given a query q and a response r  we will deﬁne the Loss
assessment query ˜qr as

(cid:26)∆

˜qr (x) =

D (x) > D (x| r)
−∆ D (x) ≤ D (x| r)

.

Intuitively  this function maximizes the difference between E

[˜qr (X)] and

X∼DX

E

X∼DqX|R

[˜qr (X) | r] 

and as a result  the potential to overﬁt.8

This function is used to lower bound the effect of the stability loss on the expected overﬁtting.
Lemma 3.5 (Loss assessment query overﬁts in expectation). Given 0 ≤   δ ≤ 1  a distribution DX n 
a query q  and a mechanism M  if D (r) > δ  then there is a function f : R → Q∆ such that 

E

S∼DX n  Q(cid:48)∼f◦M (S q)

[Q(cid:48) (DX n ) − Q(cid:48) (S)]

(cid:12)(cid:12)(cid:12)(cid:12) > 2∆δ.

(cid:12)(cid:12)(cid:12)(cid:12)

(cid:12)(cid:12)(cid:12)(cid:12)

Proof. Choosing f (r) = qr we get that 

E

S∼DX n  Q(cid:48)∼f◦M (S q)

[Q(cid:48) (DX n ) − Q(cid:48) (S)]

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

(cid:12)(cid:12)(cid:12)(cid:12) (1)

=

=

(2)≥

q(cid:48)∈Q∆

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
(cid:88)
D (q(cid:48)) ·(cid:88)
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:88)
D (r) ·(cid:88)
(cid:122)
(cid:122)
(cid:125)(cid:124)
(cid:123)(cid:88)
(cid:88)

≥δ
D (r)·

r∈R

x∈X

r∈r

x∈X

(D (x) − D (x| q(cid:48))) · q(cid:48) (x)

x∈X
(D (x) − D (x| r)) · ˜qr (x)

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

(cid:125)(cid:124)

=2(cid:96)(r)>2

|D (x) − D (x| r)|·∆

(cid:123)

where (1) is further justiﬁed in the proof of Theorem C.1  (2) results from the deﬁnition of the loss
assessment query  and (3) from the deﬁnition of r.

(3)
> 2∆δ

We use this method for constructing an overﬁtting query for non-LSS mechanism  to show that LSS
is necessary in order for a mechanism to be both Sample Accurate and Distribution Accurate.
Theorem 3.6 (Necessity of LSS for Generalization). Given 0 ≤  ≤ ∆  0 ≤ δ ≤ 1  a distribution
DX n  and an analyst A : V → Q∆  if a sequence of k mechanisms ¯M where ∀i ∈ [k]   Mi :

∆   δ(cid:1)-k-LSS  then it cannot be both(cid:0) 

(cid:1) (k + 1)-Distribution Accurate

X n × Q∆ → R is not(cid:0) 
and(cid:0) 

(cid:1) (k + 1)-Sample Accurate.

5   δ

5∆

5   δ

5∆

The proof of this theorem  which appears in Appendix C.4  uses a similar method to the proof of
Theorem 3.3  employing a variant of the Monitor Mechanism that outputs the loss assessment query
with the highest level of overﬁtting.

4 Relationship to other notions of stability

In this section  we discuss the relationship between LSS and a few common notions of stability;
deﬁnitions can be found in Appendix D.1.
In order to do so  we introduce an additional new
stability notion  which relaxes the Max Information (MI) (Deﬁnition D.2) notion by moving from the
distribution over the sample sets to the distribution over the sample elements.

8The fact that we are able to deﬁne such a query is a result of the way the distance measure of LSS treats the

x’s and the fact that it is deﬁned over X and not X n.

7

Deﬁnition 4.1 (Local Max Information). Given 0 ≤   0 ≤ δ ≤ 1  a distribution DX n and a query q 
a mechanism M will be said to satisfy (  δ)-Local-Max-Information with respect to DX n and q (or
LMI  for short)  if the joint distributions D(X  R) and the product distribution DX⊗R over X × R are
(  δ)-indistinguishable. In other words  for any b ⊆ X × R 

D(X  R) (b) ≤ e · DX⊗R (b) + δ and DX⊗R (b) ≤ e · D(X  R) (b) + δ.

The deﬁnition can be extended to apply to a family of queries and/or a family of possible distributions.

4.1

Implications

Prior work ([DFH+15a] and [RRST16]) showed that bounded Differential Privacy (DP) (Deﬁnition
D.1) implies bounded MI (Deﬁnition D.2). In the case of δ > 0  this holds only if the underlying
distribution is a product distribution [De12]). Bounded MI is also implied by Typical Stability (TS)
(Deﬁnition D.3) [BF16]  and Bounded Maximal Leakage (ML) [EGI19]. We prove that DP  MI and
TS imply LMI (in the case of DP  only for product distributions). All proofs for this subsection can be
found in Appendix D.2  where we also introduce a local version of ML and prove its relation to LMI.
Theorem 4.2 (Differential Privacy implies Local Max Information). Given 0 ≤   0 ≤ δ ≤ 1  a
distribution DX   and a query q  if a mechanism M is (  δ)-DP with respect to q then it is (  δ)-LMI
with respect to the same q and the product distribution over X n induced by DX .
Theorem 4.3 (Max Information implies Local Max Information). Given 0 ≤   0 ≤ δ ≤ 1  a
distribution DX n and a query q  if a mechanism M has δ-approximate max-information of  with
respect to DX n and q then it is (  δ)-LMI with respect to the same DX n and q.
Theorem 4.4 (Typical Stability implies Local Max Information). Given 0 ≤   0 ≤ δ  η ≤ 1  a
distribution DX n and a query q  if a mechanism M is (  δ  η)-Typically Stable with respect to DX n
and q then it is (  δ + 2η)-LMI with respect to the same DX n and q.

These three theorems follow naturally from the fact that LMI is a fairly direct relaxation of DP  MI
and TS.
We next show that LMI implies LSS.
Theorem 4.5 (Local Max Information implies Local Statistical Stability). Given 0 ≤ δ ≤  ≤ 1
3   a
distribution DX n and a query q  if a mechanism M is (  δ)-LMI with respect to DX n and q  then it

(cid:1)-LSS with respect to the same DX n and q  where (cid:48) = e − 1 + .

is(cid:0)(cid:48)  δ



We also prove that Compression Schemes (Deﬁnition D.6) imply LSS. This results from the fact that
releasing information based on a restricted number of sample elements has a limited effect on the
posterior distribution on one element of the sample set.
Theorem 4.6 (Compressibility implies Local Statistical Stability). Given 0 ≤ δ ≤ 1  an integer
m ≤
9ln(2n/δ)   a distribution DX   and a query q ∈ Q  if a mechanism M has a compression scheme
of size m then it is (  δ)-LSS with respect to the same q and the product distribution over X n induced
by DX   for any  > 11

(cid:113) mln(2n/δ)

.9

n

n

4.2 Separations

Finally  we show that MI is a strictly stronger requirement than LMI  and LMI is a strictly stronger
requirement then LSS. Proofs of these theorems appear in Appendix D.3.
Theorem 4.7 (Max Information is strictly stronger than Local Max Information). For any 0 <  
n ≥ 3  the mechanism which outputs the parity function of the sample set is (  0)-LMI but not

(cid:0)1  1
(cid:1)-MI.
(cid:1)   6(cid:9)  a mechanism which uniformly samples and outputs one sample
0 ≤ δ ≤ 1  n > max(cid:8)2ln(cid:0) 2
(cid:19)
(cid:113) ln(2n/δ)
-LSS but is not(cid:0)1  1

Theorem 4.8 (Local Max Information is strictly stronger than Local Statistical Stability). For any

(cid:1)-LMI.

element is

(cid:18)

11

5

δ

  δ

n

2n

9In case g releases some side information  the number of bits required to describe this information is added

to the m factor in the bound on .

8

5 Applications and Discussion

In order to make the LSS notion useful  we must identify mechanisms which manages to remain
stable while maintaining sample accuracy. Fortunately  many such mechanisms have been introduced
in the context of Differential Privacy. Two of the most basic Differentially Private mechanisms are
based on noise addition  of either a Laplace or a Gaussian random variable. Careful tailoring of their
parameters allows “masking” the effect of changing one element  while maintaining a limited effect
on the sample accuracy. By Theorems 4.2 and 4.5  these mechanisms are guaranteed to be LSS as
well. The deﬁnitions and properties of these mechanisms can be found in Appendix E.
In moving away from the study of worst-case data sets (as is common in previous stability notions) to
averaging over sample sets and over data elements of those sets  we hope that the Local Statistical
Stability notion will enable new progress in the study of generalization under adaptive data analysis.
This averaging  potentially leveraging a sort of “natural noise” from the data sampling process  may
enable the development of new algorithms to preserve generalization  and may also support tighter
bounds on the implications of existing algorithms. One possible way this might be achieved is by
limiting the family of distributions and queries  such that the empirical mean of the query lies within
some conﬁdence interval around population mean  which would allow scaling the noise to the interval
rather than the full range (see  e.g.   Concentrated Queries  as proposed by [BF16]).
One might also hope that realistic adaptive learning settings are not adversarial  and might therefore
enjoy even better generalization guarantees. LSS may be a tool for understanding the generalization
properties of algorithms of interest (as opposed to worst-case queries or analysts; see e.g. [GK16] 
[ZH19]).

Acknowledgements This work was supported in part by Israel Science Foundation (ISF) grant
1044/16  the United States Air Force and DARPA under contract FA8750-16-C-0022  and the
Federmann Cyber Security Center in conjunction with the Israel national cyber directorate. Part of
this work was done while the authors were visiting the Simons Institute for the Theory of Computing.
Any opinions  ﬁndings and conclusions or recommendations expressed in this material are those of
the authors and do not necessarily reﬂect the views of the United States Air Force and DARPA.

References

[Ala17] Ibrahim Alabdulmohsin. An information-theoretic route from generalization in expec-
tation to generalization in probability. In Artiﬁcial Intelligence and Statistics  pages
92–100  2017.

[BE02] Olivier Bousquet and André Elisseeff. Stability and generalization. Journal of machine

learning research  2(Mar):499–526  2002.

[BF16] Raef Bassily and Yoav Freund. Typical stability. arXiv preprint arXiv:1604.03336 

2016.

[BMN+17] Raef Bassily  Shay Moran  Ido Nachum  Jonathan Shafer  and Amir Yehudayoff. Learn-

ers that use little information. arXiv preprint arXiv:1710.05233  2017.

[BNS+16] Raef Bassily  Kobbi Nissim  Adam Smith  Thomas Steinke  Uri Stemmer  and Jonathan
Ullman. Algorithmic stability for adaptive data analysis. In Proceedings of the forty-
eighth annual ACM symposium on Theory of Computing  pages 1046–1059. ACM 
2016.

[CLN+16] Rachel Cummings  Katrina Ligett  Kobbi Nissim  Aaron Roth  and Zhiwei Steven Wu.
Adaptive learning with robust generalization guarantees. In Conference on Learning
Theory  pages 772–814  2016.

[De12] Anindya De. Lower bounds in differential privacy. In Theory of cryptography confer-

ence  pages 321–338. Springer  2012.

[DFH+15a] Cynthia Dwork  Vitaly Feldman  Moritz Hardt  Toni Pitassi  Omer Reingold  and Aaron
Roth. Generalization in adaptive data analysis and holdout reuse. In Advances in Neural
Information Processing Systems  pages 2350–2358  2015.

9

[DFH+15b] Cynthia Dwork  Vitaly Feldman  Moritz Hardt  Toniann Pitassi  Omer Reingold  and
Aaron Leon Roth. Preserving statistical validity in adaptive data analysis. In Proceedings
of the forty-seventh annual ACM symposium on Theory of computing  pages 117–126.
ACM  2015.

[DMNS06] Cynthia Dwork  Frank McSherry  Kobbi Nissim  and Adam Smith. Calibrating noise
to sensitivity in private data analysis. In Theory of cryptography conference  pages
265–284. Springer  2006.

[DR+14] Cynthia Dwork  Aaron Roth  et al. The algorithmic foundations of differential privacy.

Foundations and Trends R(cid:13) in Theoretical Computer Science  9(3–4):211–407  2014.

[EGI19] Amedeo Roberto Esposito  Michael Gastpar  and Ibrahim Issa. A new approach to adap-
tive data analysis and learning via maximal leakage. arXiv preprint arXiv:1903.01777 
2019.

[FS17] Vitaly Feldman and Thomas Steinke. Calibrating noise to variance in adaptive data

analysis. arXiv preprint arXiv:1712.07196  2017.

[GK16] Arpita Ghosh and Robert Kleinberg. Inferential privacy guarantees for differentially

private mechanisms. arXiv preprint arXiv:1603.01508  2016.

[GL14] Andrew Gelman and Eric Loken. The statistical crisis in science. American scientist 

102(6):460  2014.

[Ioa05] John PA Ioannidis. Why most published research ﬁndings are false. PLoS medicine 

2(8):e124  2005.

[IWK18] Ibrahim Issa  Aaron B Wagner  and Sudeep Kamath. An operational approach to

information leakage. arXiv preprint arXiv:1807.07878  2018.

[KS14] Shiva P Kasiviswanathan and Adam Smith. On the’semantics’ of differential privacy: A

bayesian formulation. Journal of Privacy and Conﬁdentiality  6(1)  2014.

[LW86] Nick Littlestone and Manfred Warmuth. Relating data compression and learnability.

1986.

[NSS+18] Kobbi Nissim  Adam Smith  Uri Stemmer  Thomas Steinke  and Jonathan Ullman. The
limits of post-selection generalization. In Advances in Neural Information Processing
Systems  pages 6402–6411  2018.

[RRST16] Ryan Rogers  Aaron Roth  Adam Smith  and Om Thakkar. Max-information  differential
privacy  and post-selection hypothesis testing. In 2016 IEEE 57th Annual Symposium
on Foundations of Computer Science (FOCS)  pages 487–494. IEEE  2016.

[RRT+16] Maxim Raginsky  Alexander Rakhlin  Matthew Tsao  Yihong Wu  and Aolin Xu.
Information-theoretic analysis of stability and bias of learning algorithms. In Informa-
tion Theory Workshop (ITW)  2016 IEEE  pages 26–30. IEEE  2016.

[RZ16] Daniel Russo and James Zou. Controlling bias in adaptive data analysis using informa-

tion theory. In Artiﬁcial Intelligence and Statistics  pages 1232–1240  2016.

[SSBD14] Shai Shalev-Shwartz and Shai Ben-David. Understanding machine learning: From

theory to algorithms. Cambridge university press  2014.

[TV+15] Terence Tao  Van Vu  et al. Random matrices: universality of local spectral statistics of

non-hermitian matrices. The Annals of Probability  43(2):782–874  2015.

[XR17] Aolin Xu and Maxim Raginsky. Information-theoretic analysis of generalization capa-
bility of learning algorithms. In Advances in Neural Information Processing Systems 
pages 2524–2533  2017.

[ZH19] Tijana Zrnic and Moritz Hardt. Natural analysts in adaptive data analysis. arXiv preprint

arXiv:1901.11143  2019.

10

,Moshe Shenfeld
Katrina Ligett