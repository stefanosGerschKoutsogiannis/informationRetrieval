2011,Differentially Private M-Estimators,This paper studies privacy preserving M-estimators using perturbed histograms. The proposed approach allows the release of a  wide class of M-estimators with both differential privacy and statistical utility without knowing a priori the particular inference procedure. The performance of the proposed method is demonstrated through a careful study of the convergence rates. A practical algorithm is given and applied on a real world data set containing both continuous and categorical  variables.,Differentially Private M-Estimators

Lei  Jing

Department of Statistics

Carnegie Mellon University

Pittsburgh  PA 15213

jinglei@andrew.cmu.edu

Abstract

This paper studies privacy preserving M-estimators using perturbed histograms.
The proposed approach allows the release of a wide class of M-estimators with
both differential privacy and statistical utility without knowing a priori the partic-
ular inference procedure. The performance of the proposed method is demonstrat-
ed through a careful study of the convergence rates. A practical algorithm is given
and applied on a real world data set containing both continuous and categorical
variables.

1

Introduction

Privacy-preserving data analysis has received increasing attention in recent years. Among various
notions of privacy  differential privacy [1  2] provides mathematically rigorous privacy guarantee
and protects against essentially all kinds of identity attacks regardless of the auxiliary information
that may be available to the attackers. Differential privacy requires that the presence or absence of
any individual data record can never greatly change the outcome and hence the user can hardly learn
much about any individual data record from the output.
However  designing differentially private statistical inference procedures has been a challenging
problem. Differential privacy protects individual data by introducing uncertainty in the outcome 
which generally requires the output of any inference procedure to be random even for a ﬁxed input
data set. This makes differentially private statistical analysis different from most traditional statis-
tical inference procedures  which are deterministic once the data set is given. Most existing works
[3  4  5] focus on the interactive data release where a particular statistical inference problem is cho-
sen a priori and the randomized output for that particular inference is released to the users. In reality
a data release that allows multiple inference procedures are often desired because real world statis-
tical analyses usually consist of a series of inferences such as exploratory analysis  model ﬁtting 
and model selection  where the exact inference problem in a later stage is determined by results of
previous steps and cannot be determined in advance.
In this work we study M-estimators under a differentially private framework. The proposed method
uses perturbed histograms to provide a systematic way of releasing a class of M-estimators in a
non-interactive fashion. Such a non-interactive method uses randomization independent of any par-
ticular inference procedure  therefore it allows the users to apply different inference procedures on
the same synthetic data set without additional privacy compromise. The accuracy of these private
preserving estimates has also been studied and we prove that  under mild conditions on the contrast
√
functions of the M-estimators  the proposed differentially private M-estimators are consistent. As
a special case  this approach gives 1/
n-consistent estimates for quantiles  providing a simple and
efﬁcient alternative solution to similar problems considered in [4  5]. Our main condition requires
convexity and bounded partial derivatives of the contrast function. The convexity is used to en-
sure the existence and stability of the M-estimator whereas the bounded derivative controls the bias
caused by the perturbed histogram. In classical theory of M-estimators  a contrast function with

1

bounded derivative implies robustness of the corresponding M-estimator. This is another evidence
of the natural connection between robustness and differential privacy [4].
We also describe an algorithm that is conceptually simple and computationally feasible. It is ﬂex-
ible enough to accommodate continuous  ordinal  and categorical variables at the same time  as
demonstrated by its application on a Bay Area housing data.

1.1 Related Work

The perturbed histogram is ﬁrst described under the context of differential privacy in [1]. The prob-
lem of non-interactive release has also been studied by [6]  which targets at releasing the differen-
tially private distribution function or the density function in a non-parametric setting. Theoretically 
M-estimators could be indirectly obtained from the released density function. However  the more
direct perspective taken in this paper leads to an improved rate of convergence as well as an efﬁcient
algorithm.
Several aspects of parameter estimation problems have been studied with differential privacy under
the interactive framework. In particular  [4] shows that many robust estimators can be made dif-
ferentially private and that general private estimators can be obtained from composition of robust
location and scale estimators. [5] shows that statistical estimators with generic asymptotic normality
can be made differentially private with the same asymptotic variance. Both works involve estimat-
ing the inter-quartile range in a differentially private manner  where the algorithm may output “No
Response” [4]  or the data is assumed to have known upper and lower bounds [5]. In a slightly
different context  [3] considers penalized logistic regression as a special case of empirical risk mini-
mization  where the penalized logistic regression coefﬁcients are estimated with differential privacy
by minimizing a perturbed objective function. Their method uses a different form of perturbation
and is still interactive. It connects with the present paper in the sense that the perturbation is ﬁnally
expressed in the objective function. Both papers assume convexity  which ensures that the shift in
the minimizer is small when the deviation in the objective function is small. We also note that the
method in [3] depends on a strictly convex penalty term which is typically used in high-dimensional
problems  while our method works for problems where no penalization is used.

2 Preliminaries

2.1 Deﬁnition of Privacy
A database is modeled as a set of data points D = {x1  . . .   xn} ∈ X n  where X is the data universe.
In most cases each data entry xi represents the microdata of an individual. We use the Hamming
distance to measure the proximity between two databases of the same size. Suppose |D| = |D(cid:48)|  the
Hamming distance is H(D  D(cid:48)) = |D\D(cid:48)| = |D(cid:48)\D|. The objective of data privacy is to release
useful information from the data set while protecting information about any individual data entry.
Deﬁnition 1 (Differential Privacy [1]). A randomized function T (D) gives α-differential privacy if
for all pairs of databases (D  D(cid:48)) with H(D  D(cid:48)) = 1 and all measurable subsets E of the image of
T :

(1)

(cid:12)(cid:12)(cid:12)(cid:12)log

(cid:12)(cid:12)(cid:12)(cid:12) ≤ α.

P (T ∈ E|D)
P (T ∈ E|D(cid:48))

In the rest of this paper we assume that  n  the size of database  is public.

2.2 The Perturbed Histogram

cell as Br = (cid:78)d

In most statistical problems  a database D consists of n independent copies of a random variable
X with density f (x). For simplicity  we assume X = [0  1]d. As we will see in Section 3.2 
our method can be extended to non-compact X for some important examples. Suppose [0  1]d is
partitioned into cubic cells with equal bandwidth hn such that kn = h−1
n is an integer. Denote each
j=1[(rj − 1)hn  rjhn) 1 for all r = (r1  ...  rd) ∈ {1  ...  kn}d. The histogram
1To make sure that Br’s do form a partition of [0  1]d  the interval should be [(kn − 1)hn  1] when rj = kn.

2

density estimator is then

where nr :=(cid:80)n

ˆfhist(x) = h−d

1(x ∈ Br) 
i=1 1(Xi ∈ Br) is the number of data points in Br.

nr
n

n

(cid:88)

r

(2)

(3)

(cid:88)

r

Clearly the density estimator described above depends on the data only through the histogram counts
(nr  r ∈ {1  . . .   kn}d). If we can ﬁnd a differentially private version of (nr  r ∈ {1  . . .   kn}d) 
then the corresponding density estimator ˆf will also be differentially private by a simple change-of-
measure argument. We consider the following perturbed histogram as described in [1]:

ˆnr = nr + zr ∀ r ∈ {1  . . .   kn}d 

where zr’s are independent with density α exp(−α|z|/2)/4. We have
Lemma 2 ([1]). (ˆnr  r ∈ {1  . . .   kn}d) satisﬁes α-differential privacy.
We call (ˆnr  r ∈ {1  . . .   kn}d) the Perturbed Histogram. Substituting nr by ˆnr in (2)  we obtain a
differentially private version of ˆfhist:

ˆfP H (x) = h−d

n

1(x ∈ Br) .

ˆnr
n

(4)

In general ˆfP H given by (4) is not a valid density function  since it can take negative values and may
not integrate to 1. To avoid these undesirable properties  [6] uses ˜nr = (ˆnr ∨ 0) instead of ˆnr and
r ˜nr instead of n so that the resulting density estimator is non-negative and integrates to 1.

˜n =(cid:80)
arg minΘ M (θ)  where M (θ) = (cid:82) m(x  θ)f (x)dx  Θ ⊆ Rp  and m(x  θ) is the contrast func-

2.3 M-estimators
Given a random variable X with density f (x)  the parameter of interest is deﬁned as: θ∗ =

iid∼ f  the corresponding M-estimator is usually obtained by minimizing the

tion. Assuming Xi
empirical average of contrast function:

Mn(θ)  where Mn(θ) = n−1(cid:88)

i=1

ˆθ = arg min
θ∈Θ

m(Xi  θ).

(5)

√
M-estimators cover many important statistical inference procedures such as sample quantiles  max-
n-
imum likelihood estimators (MLE)  and least square estimators. Most M-estimators are 1/
consistent and asymptotically normal. For more details about the theory and application of M-
estimators  see [7].

3 Differentially private M-estimators

(cid:90)

Combining equations (4) and (5) gives a differentially private objective function:

Mn P H (θ) =

ˆfP H (x)m(x  θ)dx.

(6)

We wish to use the minimizer of Mn P H as a differentially private estimate of θ∗. Consider the
following set of conditions on the contrast function m(x  θ).

[0 1]d

(A1) g(x  θ) := ∂
(A2) g(x  θ) is Lipschitz in x and θ: ||g(x1  θ) − g(x2  θ)||2 ≤ C2||x1 − x2||2  for all θ; and

∂θ m(x  θ) exists and |g(x  θ)| ≤ C1 on [0  1]d × Θ.

||g(x  θ1) − g(x  θ2)||2 ≤ C2||θ1 − θ2||2  for all x.

(A3) m(x  θ) is convex in θ for all x and M (θ) is twice continuously differentiable with

M(cid:48)(cid:48)(θ∗) :=(cid:82) f (x) ∂

∂θ g(x  θ∗)dx positive deﬁnite.

Condition (A1) requires a bounded derivative of the contrast function  which is closely related to
the robustness of the corresponding M-estimator [8].
It indicates that any small changes in the

3

underlying distribution cannot change the outcome by too much  which is also required implicitly
by the deﬁnition of differential privacy. Condition (A2) has two parts. The Lipschitz condition on
x is used to bound the bias caused by histogram approximation  while the Lipschitz condition on θ
is used to establish a uniform upper bound of the sampling error in M(cid:48)
i g(xi  θ) as
well as a uniform upper bound on the error caused by the additive Laplacian noises. Condition (A3)
requires some curvature in the objective function in a neighborhood of the true parameter  which
ensures that the minimizer is stable under small perturbations.
The following theorem is our ﬁrst main result:
√
Theorem 3. Under conditions (A1)-(A3)  if hn (cid:16) (
minimizer  ˆθ∗

n(θ) = n−1(cid:80)

log n/n)2/(d+2)  then there exists a local

P H  of Mn P H  such that

(cid:0)n−1/2 ∨ ((cid:112)log n/n)2/(d+2)(cid:1) .

|ˆθ∗
P H − θ∗| = OP

(7)

A proof of Theorem 3 is given in the supplementary material. At a high level  by assumption (A3) it
sufﬁces to show (Lemma 9) that supθ∈Θ0 |M(cid:48)
log n/n)2/(2+d)) 
for some compact neighborhood Θ0 of θ∗.
The approximation error of M(cid:48)

√
n priv(θ)−M(cid:48)(θ)| = OP (1/

n P H (θ) can be decomposed into three parts:

n∨(

√

(cid:90)

( ˆfP H (x) − f (x))g(x  θ)dx =n−1(cid:88)
+n−1(cid:88)
+n−1(cid:88)

r

r

(cid:90)

(cid:90)

Br

zrh−d

(cid:18)

nrh−d

n

g(x  θ)dx

g(x  θ)dx − n(cid:88)

Br

i:Xi∈Br

(cid:19)

g(Xi  θ)

(8)

g(Xi  θ) − Eg(X  θ) .

i

The three terms on the right hand side of (8) correspond to the effect of Laplace noises added for
privacy  the bias caused by using histogram  and the sampling error  respectively. As in the general
theory of histogram estimators  the approximation error depends on the choice of bandwidth hn.
Generally speaking  if the bandwidth is small  then the histogram bias term will be small. However 
a smaller bandwidth leads to a larger number of cells and hence more Laplacian noises. As a result 
there is a trade-off between the histogram bias and Laplacian noises in the choice of bandwidth. The
bandwidth given in Theorem 3 balances these two parts. We also comment on practical choices of
hn in Section 4.
We prove Theorem 3 by investigating the convergence rate of each term in the right hand side of
√
(8). First (Lemma 10) by empirical process theory [9  10] we have  under conditions A(1) and A(2) 
n)  uniformly on Θ0. Second  using Lipschitz
the sampling error term in (8) is of order OP (1/
property of g  the histogram bias term in (8) is of order O(hn). Therefore it sufﬁces to show that
√
supθ∈Θ0
ing a concentration inequality due to Talagrand [11] (see also [12  Equation 1.3])  together with a
δ-net argument (Lemma 11) enabled by the Lipschitz property of g in θ.

(cid:1)  which can be established us-

m(x  θ)dx(cid:12)(cid:12) = OP

(cid:12)(cid:12)(cid:80)
r n−1zrh−d(cid:82)

−d/2
log n/n)h
n

(cid:0)(

Br

3.1 Algorithm based on perturbed histogram

In practice  exact integration of ˆfP H (x)m(x  θ) over each cell Br may be computationally expensive
and approximations must be adopted to make the implementation feasible. Note that ˆfP H (x) is
piecewise constant. The integration can be simpliﬁed by using a piecewise constant approximation
of m(x  θ). Formally  we introduce the following algorithm:

Algorithm 1 (M-estimator using perturbed histogram)
Input: D = {X1 ···   Xn}  m(· ·)  α  hn.

2. Let Mn P H (θ) = n−1(cid:80)

(rj − 0.5)hn for all 1 ≤ j ≤ d.

1. Construct perturbed histogram with bandwidth hn and privacy parameter α as in (3).

r ˆnrm(ar  θ)  where ar ∈ [0  1]d is the center of Br  with ar(j) =

4

3. Output ˆθP H = arg min Mn P H (θ).

Comparing to ˆθ∗
using g(ar  θ) instead of h−d

n

n P H obtained by minimizing the exact integral  the only term in (8) impacted by

g(x  θ)dx is the histogram bias term. However  note that

(cid:82)
(cid:12)(cid:12)(cid:12)(cid:12)g(ar  θ) − h−d

Br

n

(cid:90)

(cid:12)(cid:12)(cid:12)(cid:12) = O(hn) .

g(x  θ)dx

Br

As a result  the convergence rate of ˆθn P H remains the same:
Theorem 4 (Statistical Utility of Algorithm 1). Under Assumptions (A1-A3)  if Mn P H (θ) is giv-
en by Algorithm 1 with hn (cid:16) (
log n/n)2/(2+d) then there exists a local minimizer  ˆθP H  of
Mn P H (θ)  such that

√

√
|ˆθP H − θ∗| = OP (1/

n ∨ ((cid:112)log n/n)2/(2+d)).

(9)

tor for β is βMLE = arg min(cid:80)

Example (Logistic regression) We give a concrete example that satisﬁes (A1)-(A3). Let D =
{(Xi  Yi) ∈ [0  1] × {0  1} : 1 ≤ i ≤ n}  where the conditional distribution of Yi given
Xi is Bernoulli with parameter exp(βXi)/[1 + exp(βXi)]. The maximum likelihood estima-
i[−βYiXi + log(1 + exp(βXi))]. Here the contrast function
m(x  y; β) = −βxy + log(1 + exp(βx)) and it is easy to check that (A1)-(A3) hold.
In this
example X is continuous and Y is binary  so it is only necessary to discretize X when constructing
the histogram. To be speciﬁc  suppose [0  1] is partitioned into equal-sized cells (Br  1 ≤ r ≤ kn)
as in the ordinary univariate histogram. The joint histogram for (X  Y ) is constructed by counting
the number of data points in each of the product cells Br j := Br ×{j} for j = 0  1. See Subsection
4.1 for more details on constructing histograms when there are categorical variables.
Note that Theorems 3 and 4 do not guarantee the uniqueness or even existence of a global minimizer
for the perturbed objective function Mn P H (θ). This is because sometimes with small probability
some perturbed histogram count ˆnr can be negative hence the corresponding objective function
Mn P H may not be convex. In our simulation and real data experience  this is usually not a real
problem since a similar argument as in Theorem 3 shows that  with high probability  the second
n P H is uniformly close to M(cid:48)(cid:48) in any compact subset of Θ. To completely avoid this
derivative M(cid:48)(cid:48)
issue  one can use thresholding after perturbation as described in the following algorithm.
Algorithm 1(cid:48) (Perturbed histogram with nonnegative counts)
Input: D = {X1 ···   Xn}  m(· ·)  α  hn.

1 Construct perturbed histogram with bandwidth hn and privacy parameter α as in (3).

2 Let ˜Mn P H (θ) = n−1(cid:80)

r ˜nrm(ar  θ)  where ˜nr = max(ˆnr  0).

3 Output ˜θP H = arg min ˜Mn P H (θ).

Although the thresholding guarantees that the zero points of M(cid:48)
n P H (θ) is indeed a global minimizer
by convexity of Mn P H (θ)  it increases the approximation error introduced by the Laplacian noises
because now these noises no longer cancel with each other nicely in the ﬁrst term of the right hand
side of equation (8). We have the following utility result for Algorithm 1(cid:48):
Theorem 5. Under Assumptions (A1-A3) and hn (cid:16) (log n/n)1/(1+d)  the estimator given by Algo-
rithm 1(cid:48) satisﬁes

|˜θP H − θ∗| = OP ((log n/n)1/(1+d)).

width hn. The concentration inequality result no longer holds for (cid:80)

Proof. The proof follows essentially from that of Theorem 3  with a different choice of band-
r ˜zrg(ar  θ) where ˜zr =
max(zr −nr)  because ˜zr’s are not independent.
Instead  we consider a direct union bound:
supr |˜zr| ≤ supr |zr| = OP (log h−d
n ) = OP (log n). Therefore the Laplacian noise term in right
hand side of (8) is bounded uniformly for all θ by OP (n−1h−d
n log n). The histogram bias is still
O(hn) as we mentioned in the discussion of Algorithm 1. Therefore the convergence rate is opti-
mized by choosing hn (cid:16) (log n/n)1/(1+d).

5

3.2 Non-differentiable contrast functions

Now we consider the possibility of relaxing condition (A2). Allowing discontinuity in g(x  θ) is
motivated by a class of M-estimators whose contrast functions m(x  θ) are non-differentiable on
a set of zero measure. An important example is the quantile. For a random variable X ∈ R1
with cumulative distribution function F (·) and any given τ ∈ (0  1)  the τ-th quantile of X is
q(τ ) := F −1(τ )  which corresponds to an M-estimator with m(x  θ) = (1−τ )(x−θ)− +τ (x−θ)+
(see [13]). Quantiles provide important information about the distribution  including both location
(median) and scale (inter-quartile range). The robustness of sample quantiles also makes them good
candidates for differentially private data release. Differentially private quantile estimators are indeed
major building blocks for some existing privacy preserving statistical estimators [4  5]. Our result
in this subsection shows that perturbed histograms can give simple  consistent  and differentially
private quantile estimators. The following set of conditions will sufﬁce for this purpose and the
argument is largely the same as Theorem 4:

(B1) m(x  θ) is convex and Lipschitz in both x and θ.
(B2) M (θ) is twice differentiable at θ∗ with M(cid:48)(cid:48)(θ∗) > 0.
(B3) Θ is compact and convex.

Corollary 6 (Statistical utility of Algorithm 1). Under conditions (B1-B3) and hn (cid:16)
√
(

log n/n)2/(2+d)  any minimizer ˆθP H of Mn P H given by Algorithm 1 satisﬁes (9).

Proof. The argument is largely the same as the proof of Theorem 3. Here we consider the original
objective functions Mn P H and M instead of their derivatives. By a similar decomposition as in eq.
√
(8)  using the compactness of Θ  we have supΘ |Mn P H−M| = OP (1/
log n/n)−2/(2+d)).
Then the convergence of ˆθP H follows from the convexity of M.

√
n∨(

Remark 7. Condition (B3) is the most restrictive one. It requires Θ to be bounded. This is because
the proof uses the fact that Mn(θ) and M (θ) are uniformly close for large n  which is usually true
for a bounded set of θ.
Remark 8. For quantiles the contrast function is piecewise linear  so for most cells in the histogram
there would be no approximation error if the data points are approximated by the cell center. The
M-estimators for quantiles actually enjoy faster convergence rates.
Extension to distributions supported on (−∞ ∞). Recall that we assume X ∈ [0  1]d. For quan-
tiles  we have d = 1 and the quantile estimators described above can be extended to any continuous
random variable whose density function is supported on (−∞ ∞). Let {Zi  i = 1  . . .   n} be an in-
dependent sample from density fZ with fZ(z) > 0  ∀ z ∈ R1. Let τ ∈ (0  1) and suppose we want
to estimate qZ(τ )  the τ-th quantile of Z. To apply our method  deﬁne X = exp(Z)/(1 + exp(Z)).
Clearly the quantiles are preserved under this monotone transformation. Applying the perturbed
histogram quantile estimator on {Xi  i = 1  . . .   n} we obtain ˆqX P H (τ )  the differentially pri-
√
n-consistent by Corollary 6. As a result  the estimate
vate τ-th qunatile of X  which is 1/
ˆqZ P H (τ ) := log[ˆqX P H (τ )/(1 − ˆqX P H (τ ))] is a 1/

n-consistent estimator for qZ(τ ).

√

4 Practical Aspects

4.1 Complexity and Flexibility
From now on we will drop the logarithm terms to simplify presentation. Suppose hn (cid:16) n−2/(2+d).
Then the perturbed histogram (ˆnr : r ∈ {1  . . .   h−1
n }d) can be constructed in O(n2d/(2+d))
time by specifying the corresponding cell for each data point. Once the histogram is construct-
ed  following Algorithm 1  we can view it as a set of h−d
n = O(n2d/(2+d)) weighted data points

n }d(cid:9) associated with weights {ˆnr}  where each data point ar is the center of

(cid:8)ar  r ∈ {1  . . .   h−1

cell Br as deﬁned in Step 2 of Algorithm 1. For M-estimators that allow a close form solution in
terms of the minimum sufﬁcient statistics  such as least square regression  Mn P H (θ) (and hence
ˆθP H) can be calculated in O(n2d/(2+d)) time. For general M-estimators that require an iterative op-
timization  such as logistic regression  the Hessian and gradients can be calculated in O(n2d/(2+d))

6

time in each iteration. Such a weighted sample representation can be easily implemented using
standard data structures in common statistical programming packages such as R and Matlab.
Another attractive property of the proposed approach is its ﬂexibility to accommodate different
data types. As seen in the logistic regression example in Subsection 3.1  it is straightforward to
construct multivariate histograms when some variables are categorical and some are continuous. In
such cases it sufﬁces to discretize the continuous variables. To be speciﬁc  let (X 1  . . .   X d1) ∈
j=1{1  . . .   kj} be a set
of d2 discrete variables where Y j takes value in {1  . . .   kj}. For any bandwidth h  let {Br  r ∈
{1  . . .   h−1}d1} be the corresponding set of histogram cells in [0  1]d1. Then the joint histogram for
(X  Y ) is constructed with cells

[0  1]d1 be a d1-dimensional continuous variable and (Y 1  . . .   Y d2) ∈ (cid:81)d2

(cid:8)Br y  r ∈ {1  . . .   h−1}d1  y ∈ d2(cid:79)

{1  . . .   kj}(cid:9).

Because only the continuous variables have histogram approximation error  the theoretical results
developed in Section 3 are applicable with sample size n and dimensionality d1.

j=1

4.2

Improvement by enhanced thresholding

In applications such as regression  the multivariate distribution often concentrates on a subset (usu-
ally a lower dimensional manifold) of [0  1]d. Therefore many non-zero cells are artiﬁcially created
by additive noises. To alleviate this problem  we threshold the histogram with an enhanced cut-off
value: ˜nr = ˆnr1(ˆnr ≥ A log n/α)  where A > 0 is a tuning parameter. This is based on the
intuition that the maximal noise will be O(log n/α). As shown in the following data example  such
a simple thresholding step remarkably improves the accuracy.

4.3 Application to housing price data

As an illustration  we apply our method to a housing price data consisting of 348 189 houses sold in
San Francisco Bay Area between 2003 and 2006. For each house  the data contains the price  size 
year of transaction  and county in which the house is located. The inference problem of interest is
to study the relationship between housing price and other variables [14]. In our case  we want to
build a simple linear regression model to predict the housing price using the other variables while
protecting each individual transaction record with differential privacy.
The data set has two continuous variables (price and size)  one ordinal variable (year of sale) with 4
levels  and one categorical variable (county) with 9 levels. The preprocessing ﬁlters out data points
with price outside of the range $105 ∼ $9× 105 or with size larger than 3000 sqft. We also combine
small counties that are geologically close and have similar housing prices. After the preprocessing 
there are 250 070 data points and the county variable has 6 levels after the combination.
For each (year  county) combination  a perturbed histogram is constructed over the two continuous
variables with privacy parameter α and K levels in each continuous dimension. Then there are
4 × 6 × K 2 cells  each having a perturbed histogram count. Using the weighted sample represen-
tation described in Subsection 4.1  the perturbed data can be viewed as a data set with 24K 2 data
points weighted by the perturbed histogram counts. A differentially private regression coefﬁcient is
obtained by applying a weighted least square regression on this data set. To assess the performance 
the privacy preserving regression coefﬁcients are compared with those given by the non-private or-
dinary least square (OLS) estimates. In particular  we look at the coordinate-wise relative deviance
from OLS coefﬁcients: ε = |ˆθpriv/ˆθOLS − 1|. To account for the randomness of additive noises 
i /100)1/2  where εi is the
ε2

we repeat 100 times and report the root mean square error: ¯ε = ((cid:80)100

relative error obtained in the ith repetition. The results are summarized in Table 1.
We test 2 values of α  the privacy parameter. Recall that a smaller value of α indicates a stronger
privacy guarantee. For each value of α we apply both the original Algorithm 1 and the enhanced
thresholding described in Subsection 4.2  with tuning parameter A = 1/2. For α = 1 the coefﬁcients
given by the perturbed histogram are close to those given by OLS with most relative deviances
below 5%. When α = 0.1  which is a conservative choice because exp(0.1) ≈ 1.1  the perturbed
histogram still gives reasonably close estimates with average deviance below 10% for all parameters

1

7

Table 1: Linear regression coefﬁcients using the Bay Area housing data. The second column is
the regression coefﬁcients given by ordinary least square method without any perturbation. We
compare estimate given by (1) perturbed histogram (PH  Algorithm 1) and (2) perturbed histogram
with enhanced thresholding (THLD) as described in Subsection 4.2. The reported number is the root
mean square relative error (in percentage) over 100 perturbations as described above. The histogram
with use K = 10 segments in each continuous dimension.

α = 0.1

α = 1

Variable
Intercept
Size
Year
County2
County3
County4
County5
County6

OLS
135141
209
56375
-53765
146593
-27546
45828
-140738

PH THLD PH THLD
10.6
4.7
4.6
8.0
4.2
29.8
9.8
7.1

7.7
3.5
2.8
7.8
2.5
37.1
7.9
3.3

7.2
3.6
1.0
1.5
0.8
2.8
1.4
1.0

4.4
2.3
0.4
0.7
0.3
2.1
1.3
0.4

except the county dummy variable “County4”. This variable has the smallest OLS coefﬁcient among
all county dummy variables  so weight ﬂuctuation in the histogram causes a relatively larger impact
on the relative deviance. Even though  the perturbed histogram still gives at least qualitatively
correct estimate. We also observe that the thresholded histogram gives more accurate estimate for
all coefﬁcients except for County4 when α = 0.1.
The choice of K should depend on the sample size and dimensionality. Our theory suggests
K = O(n2/(2+d)) where d is the dimensionality of the histogram and hence equals the number
of continuous variables. In this data set n = 250  070 and d = 2  which suggests K ≈ 500. This is
not a good choice since it produces 24 × 5002 = 6 × 106 cells. Let the number of cells be c(K).
In practice  it makes sense to choose K such that the average data counts in a cell  n/c(K)  is much
larger than the maximum additive noise maxr |zr|  which is OP (log c(K)). For this data set  when
K = 10 we have n/c(K) ≈ 100 and log(c(K)) ≈ 7.78.

5 Further Discussions

We demonstrate how histograms can be used as a basic tool for statistical parameter estimation
under strong privacy constraints. The perturbed histogram adds to each histogram count a double-
exponential noise with constant parameter depending only on the privacy budget α. The histogram
approximation bias and the additive noise on the cell counts result in a bias-variance trade-off as
usually seen for histogram-based methods. Such an algorithm should work well for low-dimensional
problems. Solutions to higher dimensional problems are yet to be developed. One possibility is to
perturb the minimum sufﬁcient statistics because the dimensionality of minimum sufﬁcient statistics
is usually much smaller than the number of histogram cells. For example  in linear regression
analysis  it sufﬁces to obtain the ﬁrst and second moments of all variables in a privacy-preserving
way. However  perturbing minimum sufﬁcient statistics would only work for a single estimator and
is only possible for interactive release. We are seeing another type of privacy-utility trade-off  where
the utility is not only about the rate of convergence  but also about the range of possible analyses
allowed by the data releasing mechanism.
The perturbed histogram is also related to “error in variable” inference problems. Suppose the
original data is just the histogram  then the perturbed version can be thought as the true histogram
counts contaminated by some measurement errors.
In this paper we provide consistency results
for a class of inference problems in presence of such measurement errors. However  plugging in
the perturbed values does not necessarily give the best inference procedure and better alternatives
may be possible  see [15] for a hypothesis testing example in contingency tables. An important and
challenging question is how to ﬁnd the optimal inference procedure in presence of such measurement
errors. A positive answer to this question will help establish a lower bound of approximation error
and better understand the power and limit of perturbed histograms.

8

Acknowledgements

Jing Lei was partially supported by NSF Grant BCS-0941518.

References
[1] C. Dwork  F. McSherry  K. Nissim  and A. Smith. Calibrating noise to sensitivity in private
data analysis. In Proceedings of the 3rd Theory of Cryptography Conference  pages 265–284 
2006.

[2] C. Dwork. Differential privacy.

In Proceedings of the 33rd International Colloquium on

Automata  Languages and Programming (ICALP)(2)  pages 1–12  2006.

[3] K. Chaudhuri and C. Monteleoni. Privacy-preserving logistic regression. In Advances in Neu-

ral Information Processing Systems  2008.

[4] C. Dwork and J. Lei. Differential privacy and robust statistics.

Annual ACM Symposium on Theory of Computing  2009.

In Proceedings of the 41st

[5] A. Smith. Privacy-preserving statistical estimation with optimal convergence rates. In Pro-

ceedings of the 41st Annual ACM Symposium on Theory of Computing  2011.

[6] L. Wasserman and S. Zhou. A statistical framework for differential privacy. Journal of the

American Statistical Association  105:375–389  2010.

[7] P. J. Huber and E. M. Ronchetti. Robust Statistics. John Wiley & Sons  Inc.  2nd edition  2009.
[8] F. Hampel  E. Ronchetti  P. Rousseeuw  and W. Stahel. Robust Statistics: The Approach Based

on Inﬂuence Functions. John Wiley  New York  1986.

[9] A. W. van der Vaart. Asymptotic Statistics. Cambridge University Press  1998.
[10] M. Talagrand. Sharper bounds for Gaussian and empirical processes. The Annals of Probabil-

ity  22:28–76  1994.

[11] M. Talagrand. A new isoperimetric inequality and the concentration of measure phenomenon.

Lecture Notes in Mathematics  1469/1991:94–124  1991.

[12] S. Bobkov and M. Ledoux. Poincar´e’s inequalities and Talagrand’s concentration phenomenon

for the exponential distribution. Probability Theory and Related Fields  107:383–400  1997.

[13] R. Koenker and K. F. Hallock. Quantile regression. Journal of Economic Perspectives  15:143–

156  2001.

[14] R. K. Pace and R. Barry. Sparse spatial autoregressions. Statistics & Probability Letters 

33:291–297  1997.

[15] D. Vu and A. Slavkovic. Differential privacy for clinical trial data: Preliminary evaluations. In

Proceedings of the 2009 IEEE International Conference on Data Mining Workshops  2009.

9

,Yuanyuan Mi
Luozheng Li
Dahui Wang
Si Wu
Francisco Ruiz
Michalis Titsias RC AUEB
David Blei