2010,Co-regularization Based Semi-supervised Domain Adaptation,This paper presents a co-regularization based approach to semi-supervised domain adaptation. Our proposed approach (EA++) builds on the notion of augmented space (introduced in EASYADAPT (EA) [1]) and harnesses unlabeled data in target domain to further enable the transfer of information from source to target. This semi-supervised approach to domain adaptation is extremely simple to implement and can be applied as a pre-processing step to any supervised learner. Our theoretical analysis (in terms of Rademacher complexity) of EA and EA++ show that the hypothesis class of EA++ has lower complexity (compared to EA) and hence results in tighter generalization bounds. Experimental results on sentiment analysis tasks reinforce our theoretical findings and demonstrate the efficacy of the proposed method when compared to EA as well as a few other baseline approaches.,Co-regularization Based Semi-supervised Domain Adaptation

Hal Daum´e III

Abhishek Kumar

Department of Computer Science

Department of Computer Science

University of Maryland CP  MD  USA

University of Maryland CP  MD  USA

hal@umiacs.umd.edu

abhishek@umiacs.umd.edu

Abstract

Avishek Saha

School Of Computing

University of Utah  UT  USA
avishek@cs.utah.edu

This paper presents a co-regularization based approach to semi-supervised domain adaptation. Our
proposed approach (EA++) builds on the notion of augmented space (introduced in EASYADAPT
(EA) [1]) and harnesses unlabeled data in target domain to further assist the transfer of information
from source to target. This semi-supervised approach to domain adaptation is extremely simple to
implement and can be applied as a pre-processing step to any supervised learner. Our theoretical
analysis (in terms of Rademacher complexity) of EA and EA++ show that the hypothesis class of
EA++ has lower complexity (compared to EA) and hence results in tighter generalization bounds.
Experimental results on sentiment analysis tasks reinforce our theoretical ﬁndings and demonstrate
the efﬁcacy of the proposed method when compared to EA as well as few other representative
baseline approaches.

1 Introduction

A domain adaptation approach for NLP tasks  termed EASYADAPT (EA)  augments the source domain feature space
using features from labeled data in target domain [1]. EA is simple  easy to extend and implement as a preprocessing
step and most importantly is agnostic of the underlying classiﬁer. However  EA requires labeled data in both source
and target  and hence applies to fully supervised domain adaptation settings only. In this paper  1 we propose a semi-
supervised 2 approach to leverage unlabeled data for EASYADAPT (which we call EA++) and theoretically  as well as
empirically  demonstrate its superior performance over EA.

There exists prior work on supervised domain adaptation (and multi-task learning) that can be related to EASYADAPT.
An algorithm for multi-task learning using shared parameters was proposed for multi-task regularization [3] wherein
each task parameter was represented as sum of a mean parameter (that stays same for all tasks) and its deviation
from this mean. SVMs were used as the base classiﬁers and the algorithm was formulated in the standard SVM dual
optimization setting. Subsequently  this framework was extended to online multi-domain setting in [4]. Prior work
on semi-supervised approaches to domain adaptation also exists in literature. Extraction of speciﬁc features from the
available dataset was proposed [5  6] to facilitate the task of domain adaptation. Co-adaptation [7]  a combination of
co-training and domain adaptation  can also be considered as a semi-supervised approach to domain adaptation. A
semi-supervised EM algorithm for domain adaptation was proposed in [8]. Similar to graph based semi-supervised
approaches  a label propagation method was proposed [9] to facilitate domain adaptation. Domain Adaptation Ma-
chine (DAM) [10] is a semi-supervised extension of SVMs for domain adaptation and presents extensive empirical
results. Nevertheless  in almost all of the above cases  the proposed methods either use speciﬁcs of the datasets or are
customized for some particular base classiﬁer and hence it is not clear how the proposed methods can be extended to
other existing classiﬁers.

1A preliminary version [2] of this work appeared in the DANLP workshop at ACL 2010.
2We deﬁne supervised domain adaptation as having labeled data in both source and target and unsupervised domain adaptation
as having labeled data in only source. In semi-supervised domain adaptation  we also have access to both labeled and unlabeled
data in target.

1

As mentioned earlier  EA is remarkably general in the sense that it can be used as a pre-processing step in conjunction
with any base classiﬁer. However  one of the prime limitations of EA is its incapability to leverage unlabeled data.
Given its simplicity and generality  it would be interesting to extend EA to semi-supervised settings. In this paper  we
propose EA++  a co-regularization based semi-supervised extension to EA. We also present Rademacher complex-
ity based generalization bounds for EA and EA++. Our generalization bounds also apply to the approach proposed
in [3] for domain adaptation setting  where we are only concerned with the error on target domain. The closest to our
work is a recent paper [11] that theoretically analyzes EASYADAPT. Their paper investigates the necessity to com-
bine supervised and unsupervised domain adaptation (which the authors refer to as labeled and unlabeled adaptation
frameworks  respectively) and analyzes the combination using mistake bounds (which is limited to perceptron-based
online scenarios). In addition  their work points out that EASYADAPT is limited to only supervised domain adaptation.
On the contrary  our work extends EASYADAPT to semi-supervised settings and presents generalization bound based
theoretical analysis which speciﬁcally demonstrate why EA++ is better than EA.

2 Background
In this section  we introduce notations and provide a brief overview of EASYADAPT [1].

2.1 Problem Setup and Notations

Let X ⊂ Rd denote the instance space and Y = {−1  +1} denote the label space. Let Ds(x  y) be the source
distribution and Dt(x  y) be the target distribution. We have a set of source labeled examples Ls(∼ Ds(x  y)) and a
set of target labeled examples Lt(∼ Dt(x  y))  where |Ls| = ls ≫ |Lt| = lt. We also have target unlabeled data
denoted by Ut(∼ Dt(x))  where |Ut| = ut. Our goal is to learn a hypothesis h : X 7→ Y having low expected error
with respect to the target domain. In this paper  we consider linear hypotheses only. However  the proposed techniques
extend to non-linear hypotheses  as mentioned in [1]. Source and target empirical errors for hypothesis h are denoted
by ˆǫs(h  fs) and ˆǫt(h  ft) respectively  where fs and ft are the true source and target labeling functions. Similarly 
the corresponding expected errors are denoted by ǫs(h  fs) and ǫt(h  ft). We will use shorthand notations of ˆǫs  ˆǫt  ǫs
and ǫt wherever the intention is clear from context.

2.2 EasyAdapt (EA)
Let us denote Rd as the original space. EA operates in an augmented space denoted by ˘X ⊂ R3d (for a single pair of
source and target domain). For k domains  the augmented space blows up to R(k+1)d. The augmented feature maps
Φs  Φt : X 7→ ˘X for source and target domains are deﬁned as Φs(x) = hx  x  0i and Φt(x) = hx  0  xi where x
and 0 are vectors in Rd  and 0 denotes a zero vector of dimension d. The ﬁrst d-dimensional segment corresponds to
commonality between source and target  the second d-dimensional segment corresponds to the source domain while
the last segment corresponds to the target domain. Source and target domain examples are transformed using these
feature maps and the augmented features so constructed are passed onto the underlying supervised classiﬁer. One of
the most appealing properties of EASYADAPT is that it is agnostic of the underlying supervised classiﬁer being used to
learn in the augmented space. Almost any standard supervised learning approach (for e.g.  SVMs  perceptrons) can be
used to learn a linear hypothesis ˘h ∈ R3d in the augmented space. Let us denote ˘h = hgc  gs  gti  where each of gc 
gs  gt is of dimension d  and represent the common  source-speciﬁc and target-speciﬁc components of ˘h  respectively.
During prediction on target data  the incoming target sample x is transformed to obtain Φt(x) and ˘h is applied on this
transformed sample. This is equivalent to applying (gc + gt) on x. A intuitive insight into why this simple algorithm
works so well in practice and outperforms most state-of-the-art algorithms is given in [1]. Brieﬂy  it can be thought
to be simultaneously training two hypotheses: hs = (gc + gs) for source domain and ht = (gc + gt) for target
domain. The commonality between the domains is represented by gc whereas gs and gt capture the idiosyncrasies of
the source and target domain  respectively.

3 EA++: EA using unlabeled data

As discussed in the previous section  the EASYADAPT algorithm is attractive because it performs very well empirically
and can be used in conjunction with any underlying supervised linear classiﬁer. One drawback of EASYADAPT is its
inability to leverage unlabeled target data which is usually available in large quantities in most practical scenarios. In
this section  we extend EA to semi-supervised settings while maintaining the desirable classiﬁer-agnostic property.

2

3.1 Motivation

In multi-view approach to semi-supervised learning [12]  different hypotheses are learned using different views of
the dataset. Thereafter  unlabeled data is utilized to co-regularize these learned hypotheses by making them agree on
unlabeled samples. In domain adaptation  the source and target data come from two different distributions. However 
if the source and target domains are reasonably close  we can employ a similar form of regularization using unlabeled
data. A prior co-regularization based idea to harness unlabeled data in domain adaptation tasks demonstrated improved
empirical results [10]. However  their technique applies for the particular base classiﬁer they consider and hence does
not extend to other supervised classiﬁers.

3.2 EA++: EASYADAPT with unlabeled data

In our proposed semi-supervised approach  the source and target hypotheses are made to agree on unlabeled data.
We refer to this algorithm as EA++. Recall that EASYADAPT learns a linear hypothesis ˘h ∈ R3d in the augmented
space. The hypothesis ˘h contains common  source-speciﬁc and target-speciﬁc sub-hypotheses and is expressed as
˘h = hgc  gs  gti. In original space (ref. Section 2.2)  this is equivalent to learning a source speciﬁc hypothesis
hs = (gc + gs) and a target speciﬁc hypothesis ht = (gc + gt).
In EA++  we want the source hypothesis hs and the target hypothesis ht to agree on the unlabeled data. For an
unlabeled target sample xi ∈ Ut ⊂ Rd  the goal of EA++ is to make the predictions of hs and ht on xi  agree with
each other. Formally  it aims to achieve the following condition:

hs · xi ≈ ht · xi ⇐⇒ (gc + gs) · xi ≈ (gc + gt) · xi

⇐⇒ (gs − gt) · xi ≈ 0 ⇐⇒ hgc  gs  gti · h0  xi  −xii ≈ 0.

(3.1)
The above expression leads to the deﬁnition of a new feature map Φu : X 7→ ˘X for unlabeled data given by Φu(x) =
h0  x  −xi. Every unlabeled target sample is transformed using the map Φu(.). The augmented feature space that
results from the application of three feature maps  namely  Φs(·)  Φt(·) and Φu(·) on source labeled samples  target
labeled samples and target unlabeled samples is summarized in Figure 1(a).

As shown in Eq. 3.1  during the training phase  EA++ assigns a predicted value close to 0 for each unlabeled sample.
However  it is worth noting that during the test phase  EA++ predicts labels from two classes: +1 and −1. This
warrants further exposition of the implementation speciﬁcs which is deferred until the next subsection.

EA

EA++

ls

lt

ut

d

Ls

Lt

d

Ls

0

d

0

Lt


















−Ut

0

Ut

(a)

s
s
o
L

(a)

s
s
o
L

(b)

s
s
o
L

(c)

(b)

Figure 1: (a) Diagrammatic representation of feature augmentation in EA and EA++  (b) Loss functions for class +1 
class −1 and their summation.

3.3 Implementation

In this section  we present implementation speciﬁc details of EA++. For concreteness  we consider SVM as the base
supervised learner. However  these details hold for other supervised linear classiﬁers.
In the dual form of SVM
optimization function  the labels are multiplied with features. Since  we want the predicted labels for unlabeled data
to be 0 (according to Eq. 3.1)  multiplication by zero will make the unlabeled samples ineffective in the dual form of

3

the cost function. To avoid this  we create as many copies of Φu(x) as there are labels and assign each label to one
copy of Φu(x). For the case of binary classiﬁcation  we create two copies of every augmented unlabeled sample  and
assign +1 label to one copy and −1 to the other. The learner attempts to balance the loss of the two copies  and tries
to make the prediction on unlabeled sample equal to 0. Figure 1(b) shows the curves of the hinge loss for class +1 
class −1 and their summation. The effective loss for each unlabeled sample is similar to the sum of losses for +1 and
−1 classes (shown in Figure 1(b)c).
4 Generalization Bounds

In this section  we present Rademacher complexity based generalization bounds for EA and EA++. First  we deﬁne
hypothesis classes for EA and EA++ using an alternate formulation. Second  we present a theorem (Theorem 4.1)
which relates empirical and expected error for the general case and hence applies to both the source and target domains.
Third  we prove Theorem 4.2 which relates the expected target error to the expected source error. Fourth  we present
Theorem 4.3 which combines Theorem 4.1 and Theorem 4.2 so as to relate the expected target error to empirical
errors in source and target (which is the main goal of the generalization bounds presented in this paper). Finally  all
that remains is to bound the Rademacher complexity of the various hypothesis classes.

4.1 Deﬁne Hypothesis Classes for EA and EA++

Our goal now is to deﬁne the hypothesis classes for EA and EA++ so as to make the theoretical analysis feasible.
Both EA and EA++ train hypotheses in the augmented space ˘X ⊂ R3d. The augmented hypothesis ˘h is trained
using data from both domains  and the three sub-hypotheses (gc + gs + gt) of d-dimension are treated in a different
manner for source and target data. We use an alternate formulation of the hypothesis classes and work in the original
space X ⊂ Rd. As discussed brieﬂy in Section 2.2  EA can be thought to be simultaneously training two hypotheses
hs = (gc + gs) and ht = (gc + gt) for source and target domains  respectively. We consider the case when the
underlying supervised classiﬁer in augmented space uses a square L2-norm regularizer of the form ||˘h||2 (as used in
SVM). This is equivalent to imposing the regularizer (||gc||2 +||gs||2 +||gt||2) = (||gc||2 +||hs−gc||2 +||ht−gc||2).
Differentiating this regularizer w.r.t. gc gives gc = (hs + ht)/3 at the minimum  and the regularizer reduces to
1
3 (||hs||2 + ||ht||2 + ||hs − ht||2). Thus  EA can be thought to be minimizing the sum of empirical source error on
hs  empirical target error on ht and this regularizer. The cost function QEA(h1  h2) can now be written as:
(4.1)
h1 h2 QEA

αˆǫs(h1) + (1 − α)ˆǫt(h2) + λ1||h1||2 + λ2||h2||2 + λ||h1 − h2||2 

and (hs  ht) = arg min

The EA algorithm minimizes this cost function over h1 and h2 jointly to obtain hs and ht. The EA++ algorithm
uses target unlabeled data  and encourages hs and ht to agree on unlabeled samples (Eq. 3.1). This can be thought of

as having an additional regularizer of the formPi∈Ut (hs(xi) − ht(xi))2 in the cost function. The cost function for
EA++ (denoted as Q++(h1  h2)) can then be written as:

αˆǫs(h1) + (1 − α)ˆǫt(h2) + λ1||h1||2 + λ2||h2||2 + λ||h1 − h2||2 + λu Xi∈Ut

(h1(xi) − h2(xi))2

(4.2)

Both EA and EA++ give equal weights to source and target empirical errors  so α turns out to be 0.5. We use
hyperparameters λ1  λ2  λ  and λu in the cost functions to make them more general. However  as explained earlier 
EA implicitly sets all these hyperparameters (λ1  λ2  λ) to the same value (which will be 0.5( 1
6 in our case 
since the weights in the entire cost function are multiplied by α = 0.5). The hyperparameter for unlabeled data (λu)
is 0.5 in EA++. We assume that the loss L(y  h.x) is bounded by 1 for the zero hypothesis h = 0. This is true for
many popular loss functions including square loss and hinge loss when y ∈ {−1  +1}. One possible way [13] of
deﬁning the hypotheses classes is to substitute trivial hypotheses h1 = h2 = 0 in both the cost functions which makes
all regularizers and co-regularizers equal to zero and thus bounds the cost functions QEA and Q++. This gives us
QEA(0  0) ≤ 1 and Q++(0  0) ≤ 1 since ˆǫs(0)  ˆǫt(0) ≤ 1. Without loss of generality  we also assume that ﬁnal
source and target hypotheses can only reduce the cost function as compared to the zero hypotheses. Hence  the ﬁnal
hypothesis pair (hs  ht) that minimizes the cost functions is contained in the following paired hypothesis classes for
EA and EA++ 

3 ) = 1

H := {(h1  h2) : λ1||h1||2 + λ2||h2||2 + λ||h1 − h2||2 ≤ 1}
H++ := {(h1  h2) : λ1||h1||2 + λ2||h2||2 + λ||h1 − h2||2 + λu Xi∈Ut

(h1(xi) − h2(xi))2 ≤ 1}

(4.3)

4

The source hypothesis class for EA is the set of all h1 such that the pair (h1  h2) is in H. Similarly  the target hypothesis
class for EA is the set of all h2 such that the pair (h1  h2) is in H. Consequently  the source and target hypothesis
classes for EA can be deﬁned as:
(4.4)

and

J s
EA := {h1 : X 7→ R  (h1  h2) ∈ H}

J t
EA := {h2 : X 7→ R  (h1  h2) ∈ H}

Similarly  the source and target hypothesis classes for EA++ are deﬁned as:

J s
++ := {h1 : X 7→ R  (h1  h2) ∈ H++}

(4.5)
Furthermore  we assume that our hypothesis class is comprised of real-valued functions over an RKHS with repro-
ducing kernel k(· ·)  k :X ×X 7→ R. Let us deﬁne the kernel matrix and partition it corresponding to source labeled 
target labeled and target unlabeled data as shown below:

J t
++ := {h2 : X 7→ R  (h1  h2) ∈ H++}

and

where ‘s’  ‘t’ and ‘u’ indicate terms corresponding to source labeled  target labeled and target unlabeled  respectively.

K = As×s Cs×t Ds×u
D′u×s E′u×t Fu×u !  
C′t×s Bt×t Et×u

(4.6)

4.2 Relate empirical and expected error (for both source and target)

Having deﬁned the hypothesis classes  we now proceed to obtain generalization bounds for EA and EA++. We have
the following standard generalization bound based on the Rademacher complexity of a hypothesis class [13].
Theorem 4.1. Suppose the uniform Lipschitz condition holds for L : Y 2 → [0  1] 
|L( ˆy1  y) −
L( ˆy2  y)| ≤ M| ˆy1 − ˆy2|  where y  ˆy1  ˆy2 ∈ Y and ˆy1 6= ˆy2. Then for any δ ∈ (0  1) and for m samples
(X1  Y1)  (X2  Y2)  . . .   (Xm  Ym) drawn i.i.d. from distribution D  we have with probability at least (1 − δ) over
random draws of samples 

i.e. 

ǫ(f ) ≤ ˆǫ(f ) + 2M ˆRm(F ) +

1
√m

(2 + 3pln(2/δ)/2).

where f ∈ F is the class of functions mapping X 7→ Y  and ˆRm(F ) is the empirical Rademacher complexity of F
deﬁned as ˆRm(F ) := Eσ[supf∈F | 2
i=1 σih2(xi)|].
EA  we will have a uniform convergence bound on
If we can bound the complexity of hypothesis classes J s
the difference of expected and empirical errors (|ǫt(h) − ˆǫt(h)| and |ǫs(h) − ˆǫs(h)|) using Theorem 4.1. However  in
domain adaptation setting  we are also interested in the bounds that relate expected target error to total empirical error
on source and target samples. The following sections aim to achieve this goal.

mPm

EA and J t

4.3 Relate source expected error and target expected error

The following theorem provides a bound on the difference of expected target error and expected source error. The
bound is in terms of ηs := ǫs(fs  ft)  νs := ǫs(h∗t   ft) and νt := ǫt(h∗t   ft)  where fs and ft are the source and target
labeling functions  and h∗t is the optimal target hypothesis in target hypothesis class. It also uses dH∆H(Ds Dt)−
distance [14]  which is deﬁned as suph1 h2∈H
2|ǫs(h1  h2) − ǫt(h1  h2)|. The dH∆H−distance measures the distance
between two distribution using a hypothesis class-speciﬁc distance measure. If the two domains are close to each
other  ηs and dH∆H(Ds Dt) are expected to be small. On the contrary  if the domains are far apart  these terms will
be big and the use of extra source samples may not help in learning a better target hypothesis. These two terms also
represent the notion of adaptability in our case.
Theorem 4.2. Suppose the loss function is M-Lipschitz as deﬁned in Theorem 4.1  and obeys triangle inequality. For
any two source and target hypotheses hs  ht (which belong to different hypotheses classes)  we have

ǫt(ht  ft) − ǫs(hs  fs) ≤M||ht − hs||Eshpk(x  x)i +

1
2

dHt∆Ht(Ds  Dt) + ηs + νs + νt.

where Ht is the target hypothesis class  and k(· ·) is the reproducing kernel for the RKHS. ηs  νs  and νt are deﬁned
as above.

Proof. Please see Appendix A in the supplement.

5

4.4 Relate target expected error with source and target empirical errors

EA and EA++ learn source and target hypotheses jointly. So the empirical error in one domain is expected to have
its effect on the generalization error in the other domain. In this section  we aim to bound the target expected error in
terms of source and target empirical errors. The following theorem achieves this goal.
Theorem 4.3. Under the assumptions and deﬁnitions used in Theorem 4.1 and Theorem 4.2  with probability at least
1 − δ we have
ǫt(ht  ft) ≤

(ˆǫs(hs  fs) + ˆǫt(ht  ft)) +

√lt« (2 + 3pln(2/δ)/2)

2 „ 1
√ls

1
2

1
2

+

1

1

(2M ˆRm(Hs) + 2M ˆRm(Ht)) +
1
2

dHt∆Ht (Ds  Dt) +

1
4

(ηs + νs + νt)

+

1
2

M||ht − hs||Eshpk(x  x)i +

for any hs and ht. Hs and Ht are the source hypothesis class and the target hypothesis class  respectively.
Proof. We ﬁrst use Theorem 4.1 to bound (ǫt(ht)− ˆǫt(ht)) and (ǫs(hs)− ˆǫs(hs)). The above theorem directly follows
by combining these two bounds and Theorem 4.2.

This bound provides better a understanding of how the target expected error is governed by both source and target
empirical errors  and hypotheses class complexities. This behavior is expected since both EA and EA++ learn source
and target hypotheses jointly. We also note that the bound in Theorem 4.3 depends on ||hs − ht||  which apparently
might give an impression that the best possible thing to do is to make source and target hypotheses equal. However  due
to joint learning of source and target hypotheses (by optimizing the cost function of Eq. 4.1)  making the source and
target hypotheses close will increase the source empirical error  thus loosening the bound of Theorem 4.3. Noticing
that ||hs − ht||2 ≤ 1
λ for both EA and EA++  the bound can be made independent of ||hs − ht|| although with a
sacriﬁce on the tightness. We note that Theorem 4.1 can also be used to bound the target generalization error of EA
and EA++ in terms of only target empirical error. However  if the number of labeled target samples is extremely
low  this bound can be loose due to inverse dependency on number of target samples. Theorem 4.3 bounds the target
expected error using the averages of empirical errors  Rademacher complexities  and sample dependent terms. If the
domains are reasonably close and the number of labeled source samples is much higher than target samples  this can
provide a tighter bound compared to Theorem 4.1.

Finally  we need the Rademacher complexities of source and target hypothesis classes (for both EA and EA++) to be
able to use Theorem 4.3  which are provided in the next sections.

4.5 Bound the Complexity of EA and EA++ Hypothesis Classes

The following theorems bound the Rademacher complexity of the target hypothesis classes for EA and EA++.

4.5.1 EASYADAPT (EA)

Theorem 4.4. For the hypothesis class J t
ˆRm(J t
ﬁned as in Eq. 4.6.

EA |Pi σih2(x)|  (C t

EA) = Eσ suph2∈J t

EA deﬁned in Eq. 4.4 we have 

1
4√2

2C t

EA

lt ≤ ˆRm(J t

EA) ≤ 2C t

EA
lt

where 

EA)2 = (cid:18)

1
λ2+“ 1
+ 1

λ1

λ”−1(cid:19)tr(B) and B is the kernel sub-matrix de-

Proof. Please see Appendix B in the supplement.

The complexity of target class decreases with an increase in the values of hyperparameters. It decreases more rapidly
with change in λ2 compared to λ and λ1  which is also expected since λ2 is the hyperparameter directly inﬂuencing
the target hypothesis. The kernel block sub-matrix corresponding to source samples does not appear in the bound.
This result in conjunction with Theorem 4.1 gives a bound on the target generalization error.

To be able to use the bound of Theorem 4.3  we need the Rademacher complexity of the source hypothesis class.
Due to the symmetry of paired hypothesis class (Eq. 4.3) in h1 and h2 up to scalar parameters  the complex-

6

ity of source hypothesis class can be similarly bounded by 1
4√2

EA) ≤ 2C s
λ”−1(cid:19)tr(A)  and A is the kernel block sub-matrix corresponding to source samples.

ls ≤ ˆRm(J s

1
λ1+“ 1
+ 1

(cid:18)

2C s

λ2

EA

EA
ls

  where (C s

EA)2 =

4.5.2 EASYADAPT++ (EA++)

++ deﬁned in Eq. 4.5 we have 

where 

2C t
++
lt

Theorem 4.5. For the hypothesis class J t
++) = Eσ suph2∈J t
tr(cid:0)E(I + kF )−1E′(cid:1)  where k = λu(λ1+λ2)

ˆRm(J t
λλ1+λλ2+λ1λ2(cid:17)2

++ |Pi σih2(x)| and (C t

λu(cid:16)

λλ1+λλ2+λ1λ2

λ1

.

Proof. Please see Appendix C in the Supplement.

2C t
++
lt

1
4√2

≤ ˆRm(J t
++) ≤
λ”−1(cid:19)tr(B) −

1
λ2+“ 1
+ 1

λ1

++)2 = (cid:18)

can also be written asPi ||Ei||2

The second term in (C t
++)2 is always positive since the trace of a positive deﬁnite matrix is positive. So  the unlabeled
data results in a reduction of complexity over the labeled data case (Theorem 4.4). The trace term in the reduction
Z is the norm induced by a
positive deﬁnite matrix Z. Since Ei is the vector representing the inner product of i’th target sample with all unlabeled
samples  this means that the reduction in complexity is proportional to the similarity between target unlabeled samples
and target labeled samples. This result in conjunction with Theorem 4.1 gives a bound on the target generalization
error in terms of target empirical error.

(I+kF )−1  where Ei is the i’th column of matrix E and ||·||2

To be able to use the bound of Theorem 4.3  we need the Rademacher complexity of source hypothesis class too.
Again  as in case of EA  using the symmetry of paired hypothesis class H++ (Eq. 4.3) in h1 and h2 up to scalar
parameters  the complexity of source hypothesis class can be similarly bounded by 1
 
4√2

2C s
++
ls

2C s

++

ls ≤ ˆRm(J s

++) ≤

where (C s

++)2 = (cid:18)

1
λ1+“ 1
+ 1

λ2

λ”−1(cid:19)tr(A) − λu(cid:16)

λ2

λλ1+λλ2+λ1λ2(cid:17)2

tr(cid:0)D(I + kF )−1D′(cid:1)  and k is deﬁned similarly

as in Theorem 4.5. The trace term can again be interpreted as before  which implies that the reduction in source class
complexity is proportional to the similarity between source labeled samples and target unlabeled samples.

5 Experiments

We follow experimental setups similar to [1] but report our empirical results for the task of sentiment classiﬁcation
using the SENTIMENT data provided by [15]. The task of sentiment classiﬁcation is a binary classiﬁcation task which
corresponds to classifying a review as positive or negative for user reviews of eight product types (apparel  books 
DVD  electronics  kitchen  music  video  and other) collected from amazon.com. We quantify the domain divergences
in terms of the A-distance [16] which is computed [17] from ﬁnite samples of source and target domain using the
proxy A-distance [16]. For our experiments  we consider the following domain-pairs: (a) DVD→BOOKS (proxy
A-distance=0.7616) and  (b) KITCHEN→APPAREL (proxy A-distance=0.0459). As in [1]  we use an averaged
perceptron classiﬁer from the Megam framework (implementation due to [18]) for all the aforementioned tasks. The
training sample size varies from 1k to 16k. In all cases  the amount of unlabeled target data is equal to the total amount
of labeled source and target data.

We compare the empirical performance of EA++ with a few other baselines  namely  (a) SOURCEONLY (classiﬁer
trained on source labeled samples)  (b) TARGETONLY-FULL (classiﬁer trained on the same number of target labeled
samples as the number of source labeled samples in SOURCEONLY)  (c) TARGETONLY (classiﬁer trained on small
amount of target labeled samples  roughly one-tenth of the amount of source labeled samples in SOURCEONLY)  (d)
ALL (classiﬁer trained on combined labeled samples of SOURCEONLY and TARGETONLY)  (e) EA (classiﬁer trained
in augmented feature space on the same input training set as ALL)  (f) EA++ (classiﬁer trained in augmented feature
space on the same input training set as EA and an equal amount of unlabeled target data). All these approaches were
tested on the entire amount of available target test data.

Figure 2 presents the learning curves for (a) SOURCEONLY  (b) TARGETONLY-FULL  (c) TARGETONLY  (d) ALL 
(e) EA  and (f) EA++ (EA with unlabeled data). The x-axis represents the number of training samples on which the

7

0.3

0.2

e

t

a
r
 
r
o
r
r
e

SrcOnly
TgtOnly-Full
TgtOnly
All
EA
EA++

0.4

0.3

0.2

e

t

a
r
 
r
o
r
r
e

SrcOnly
TgtOnly-Full
TgtOnly
All
EA
EA++

2000

5000

8000

11000

number of samples

(a)

1000

2500
number of samples

4000

6500

(b)

Figure 2: Test accuracy of SOURCEONLY  TARGETONLY-FULL  TARGETONLY  ALL  EA  EA++ (with unlabeled
data) for  (a) DVD→BOOKS (proxy A-distance=0.7616)  (b) KITCHEN→APPAREL (proxy A-distance=0.0459)

predictor has been trained. At this point  we note that the number of training samples vary depending on the partic-
ular approach being used. For SOURCEONLY  TARGETONLY-FULL and TARGETONLY  it is just the corresponding
number of labeled source or target samples  respectively. For ALL and EA  it is the summation of labeled source and
target samples. For EA++  the x-value plotted denotes the amount of unlabeled target data used (in addition to an
equal amount of source+target labeled data  as in ALL or EA). We plot this number for EA++  just to compare its
improvement over EA when using an additional (and equal) amount of unlabeled target data. This accounts for the
different x values plotted for the different curves. In all cases  the y-axis denotes the error rate.
As can be seen  for both the cases  EA++ outperforms EASYADAPT. For DVD→BOOKS  the domains are far apart
as denoted by a high proxy A-distance. Hence  TARGETONLY-FULL achieves the best performance and EA++ almost
catches up for large amounts of training data. For different number of sample points  EA++ gives relative improve-
ments in the range of 4.36%− 9.14%  as compared to EA. The domains KITCHEN and APPAREL can be considered
to be reasonably close due to their low domain divergence. Hence  this domain pair is more amenable for domain adap-
tation as is demonstrated by the fact that the other approaches (SOURCEONLY  TARGETONLY  ALL) perform better
or atleast as good as TARGETONLY-FULL. However  as earlier  EA++ once again outperforms all these approaches
including TARGETONLY-FULL. Due to the closeness of the two domains  additional unlabeled data in EA++ helps
it in outperforming TARGETONLY-FULL. At this point  we also note that EA performs poorly for some cases  which
corroborates with prior experimental results [1]. For this dataset  EA++ yields relative improvements in the range of
14.08% − 39.29% over EA for different number of sample points experimented with. Similar trends were observed
for other tasks and datasets (refer Figure 3 of [2]).

6 Conclusions

We proposed a semi-supervised extension to an existing domain adaptation technique (EA). Our approach EA++ 
leverages unlabeled data to improve the performance of EA. With this extension  EA++ applies to both fully supervised
and semi-supervised domain adaptation settings. We have formulated EA and EA++ in terms of co-regularization  an
idea that originated in the context of multiview learning [13  19]. Our proposed formulation also bears resemblance
to existing work [20] in semi-supervised (SSL) literature which has been studied extensively in [21  22  23]. The
difference being  while in SSL one would try to make the two views (on unlabeled data) agree  in domain adaptation
the aim is to make the two hypotheses in source and target agree. Using our formulation  we have presented theoretical
analysis of the superior performance of EA++ as compared to EA. Our empirical results further conﬁrm the theoretical
ﬁndings. EA++ can also be extended to the multiple source settings. If we have k sources and a single target domain
then we can introduce a co-regularizer for each source-target pair. Due to space constraints  we defer details to a full
version.

8

References

[1] Hal Daum´e III. Frustratingly easy domain adaptation. In ACL’07  pages 256–263  Prague  Czech Republic  June 2007.
[2] Hal Daum´e III  Abhishek Kumar  and Avishek Saha. Frustratingly easy semi-supervised domain adaptation. In ACL 2010

Workshop on Domain Adaptation for Natural Language Processing (DANLP)  pages 53–59  Uppsala  Sweden  July 2010.

[3] Theodoros Evgeniou and Massimiliano Pontil. Regularized multitask learning. In KDD’04  pages 109–117  Seattle  WA 

USA  August 2004.

[4] Mark Dredze  Alex Kulesza  and Koby Crammer. Multi-domain learning by conﬁdence-weighted parameter combination.

Machine Learning  79(1-2):123–149  2010.

[5] Andrew Arnold and William W. Cohen. Intra-document structural frequency features for semi-supervised domain adaptation.

In CIKM’08  pages 1291–1300  Napa Valley  California  USA  October 2008.

[6] John Blitzer  Ryan Mcdonald  and Fernando Pereira. Domain adaptation with structural correspondence learning.

EMNLP’06  pages 120–128  Sydney  Australia  July 2006.

In

[7] Gokhan Tur. Co-adaptation: Adaptive co-training for semi-supervised learning. In ICASSP’09  pages 3721–3724  Taipei 

Taiwan  April 2009.

[8] Wenyuan Dai  Gui-Rong Xue  Qiang Yang  and Yong Yu. Transferring Naive Bayes classiﬁers for text classiﬁcation.

AAAI’07  pages 540–545  Vancouver  B.C.  July 2007.

In

[9] Dikan Xing  Wenyuan Dai  Gui-Rong Xue  and Yong Yu. Bridged reﬁnement for transfer learning.

324–335  Warsaw  Poland  September 2007.

In PKDD’07  pages

[10] Lixin Duan  Ivor W. Tsang  Dong Xu  and Tat-Seng Chua. Domain adaptation from multiple sources via auxiliary classiﬁers.

In ICML’09  pages 289–296  Montreal  Quebec  June 2009.

[11] Ming-Wei Chang  Michael Connor  and Dan Roth. The necessity of combining adaptation methods. In EMNLP’10  pages

767–777  Cambridge  MA  October 2010.

[12] Vikas Sindhwani  Partha Niyogi  and Mikhail Belkin. A co-regularization approach to semi-supervised learning with multiple

views. In ICML Workshop on Learning with Multiple Views  pages 824–831  Bonn  Germany  August 2005.

[13] D. S. Rosenberg and P. L. Bartlett. The Rademacher complexity of co-regularized kernel classes.

396–403  San Juan  Puerto Rico  March 2007.

In AISTATS’07  pages

[14] John Blitzer  Koby Crammer  Alex Kulesza  Fernando Pereira  and Jennifer Wortman. Learning bounds for domain adaptation.

In NIPS’07  pages 129–136  Vancouver  B.C.  December 2007.

[15] John Blitzer  Mark Dredze  and Fernando Pereira. Biographies  bollywood  boom-boxes and blenders: Domain adaptation for

sentiment classiﬁcation. In ACL’07  pages 440–447  Prague  Czech Republic  June 2007.

[16] Shai Ben-David  John Blitzer  Koby Crammer  and Fernando Pereira. Analysis of representations for domain adaptation. In

NIPS’06  pages 137–144  Vancouver  B.C.  December 2006.

[17] Piyush Rai  Avishek Saha  Hal Daum´e III  and Suresh Venkatasubramanian. Domain adaptation meets active learning. In

NAACL 2010 Workshop on Active Learning for NLP (ALNLP)  pages 27–32  Los Angeles  USA  June 2010.

[18] Hal Daum´e III. Notes on CG and LM-BFGS optimization of logistic regression. August 2004.
[19] Vikas Sindhwani and David S. Rosenberg. An RKHS for multi-view learning and manifold co-regularization. In ICML’08 

pages 976–983  Helsinki  Finland  June 2008.

[20] Avrim Blum and Tom Mitchell. Combining labeled and unlabeled data with co-training. In COLT’98  pages 92–100  New

York  NY  USA  July 1998. ACM.

[21] Maria-Florina Balcan and Avrim Blum. A PAC-style model for learning from labeled and unlabeled data. In COLT’05  pages

111–126  Bertinoro  Italy  June 2005.

[22] Maria-Florina Balcan and Avrim Blum. A discriminative model for semi-supervised learning. J. ACM  57(3)  2010.
[23] Karthik Sridharan and Sham M. Kakade. An information theoretic framework for multi-view learning. In COLT’08  pages

403–414  Helsinki  Finland  June 2008.

9

,Dan Rosenbaum
Daniel Zoran
Yair Weiss