2017,A Bayesian Data Augmentation Approach for Learning Deep Models,Data augmentation is an essential part of the training process applied to deep learning models.  The motivation is that a robust training process for deep learning models depends on large annotated datasets  which are expensive to be acquired  stored and processed.  Therefore a reasonable alternative is to be able to automatically generate new annotated training samples using a process known as data augmentation. The dominant data augmentation approach in the field assumes that new training samples can be obtained via random geometric or appearance transformations applied to annotated training samples  but this is a strong assumption because it is unclear if this is a reliable generative model for producing new training samples. In this paper  we provide a novel Bayesian formulation to data augmentation  where new annotated training points are treated as missing variables and generated based on the distribution learned from the training set. For learning  we introduce a theoretically sound algorithm --- generalised Monte Carlo expectation maximisation  and demonstrate one possible implementation via an extension of the Generative Adversarial Network (GAN). Classification results on MNIST  CIFAR-10 and CIFAR-100 show the better performance of our proposed method compared to the current dominant data augmentation approach mentioned above --- the results also show that our approach produces better classification results than similar GAN models.,A Bayesian Data Augmentation Approach for

Learning Deep Models

Toan Tran1  Trung Pham1  Gustavo Carneiro1  Lyle Palmer2 and Ian Reid1

1School of Computer Science  2School of Public Health

The University of Adelaide  Australia

{toan.m.tran  trung.pham  gustavo.carneiro 

lyle.palmer  ian.reid} @adelaide.edu.au

Abstract

Data augmentation is an essential part of the training process applied to deep
learning models. The motivation is that a robust training process for deep learning
models depends on large annotated datasets  which are expensive to be acquired 
stored and processed. Therefore a reasonable alternative is to be able to automat-
ically generate new annotated training samples using a process known as data
augmentation. The dominant data augmentation approach in the ﬁeld assumes
that new training samples can be obtained via random geometric or appearance
transformations applied to annotated training samples  but this is a strong assump-
tion because it is unclear if this is a reliable generative model for producing new
training samples. In this paper  we provide a novel Bayesian formulation to data
augmentation  where new annotated training points are treated as missing variables
and generated based on the distribution learned from the training set. For learning 
we introduce a theoretically sound algorithm — generalised Monte Carlo expecta-
tion maximisation  and demonstrate one possible implementation via an extension
of the Generative Adversarial Network (GAN). Classiﬁcation results on MNIST 
CIFAR-10 and CIFAR-100 show the better performance of our proposed method
compared to the current dominant data augmentation approach mentioned above —
the results also show that our approach produces better classiﬁcation results than
similar GAN models.

1

Introduction

Deep learning has become the “backbone” of several state-of-the-art visual object classiﬁcation
[19  14  25  27]  speech recognition [17  12  6]  and natural language processing [4  5  31] systems.
One of the many reasons that explains the success of deep learning models is that their large capacity
allows for the modeling of complex  high dimensional data patterns. The large capacity allowed by
deep learning is enabled by millions of parameters estimated within annotated training sets  where
generalization tends to improve with the size of these training sets. One way of acquiring large
annotated training sets is via the manual (or “hand”) labeling of training samples by human experts —
a difﬁcult and sometimes subjective task that is expensive and prone to mistakes. Another way of
producing such large training sets is to artiﬁcially enlarge existing training datasets — a process that
is commonly known in computer science as data augmentation (DA).
In computer vision applications  DA has been predominantly developed with the application of simple
geometric and appearance transformations on existing annotated training samples in order to generate
new training samples  where the transformation parameters are sampled with additive Gaussian or
uniform noise. For instance  for ImageNet classiﬁcation [8]  new training images can be generated by
applying random rotations  translations or color perturbations to the annotated images [19]. Such a
DA process based on “label-preserving” transformations assumes that the noise model over these

31st Conference on Neural Information Processing Systems (NIPS 2017)  Long Beach  CA  USA.

transformation spaces can represent with ﬁdelity the processes that have produced the labelled images.
This is a strong assumption that to the best of our knowledge has not been properly tested. In fact 
this commonly used DA process is known as “poor man’s” data augmentation (PMDA) [28] in the
statistical learning community because new synthetic samples are generated from a distribution
estimated only once at the beginning of the training process.

Figure 1: An overview of our Bayesian data augmentation algorithm for learning deep models. In
this analytic framework  the generator and classiﬁer networks are jointly learned  and the synthesized
training set is continuously updated as the training progresses.

In the current manuscript  we propose a novel Bayesian DA approach for training deep learning
models. In particular  we treat synthetic data points as instances of a random latent variable  which
are drawn from a distribution learned from the given annotated training set. Effectively  rather than
generating new synthetic training data prior to the training process using pre-deﬁned transformation
spaces and noise models  our approach generates new training data as the training progresses using
samples obtained from an iteratively learned training data distribution. Fig. 1 shows an overview of
our proposed data augmentation algorithm.
The development of our approach is inspired by DA using latent variables proposed by the statistical
learning community [29]  where the motivation is to introduce latent variables to facilitate the compu-
tation of posterior distributions. However  directly applying this idea to deep learning is challenging
because sampling millions of network parameters is computationally difﬁcult. By replacing the
estimation of the posterior distribution by the estimation of the maximum a posteriori (MAP) proba-
bility  one can employ the Expectation Maximization (EM) algorithm  if the maximisation of such
augmented posteriors is feasible. Unfortunately  this is not the case for deep learning models  where
the posterior maximisation cannot reliably produce a global optimum. An additional challenge for
deep learning models is that it is nontrivial to compute the expected value of the network parameters
given the current estimate of the network parameters and the augmented data.
In order to address such challenges  we propose a novel Bayesian DA algorithm  called Generalized
Monte Carlo Expectation Maximization (GMCEM)  which jointly augments the training data and
optimises the network parameters. Our algorithm runs iteratively  where at each iteration we sample
new synthetic training points and use Monte Carlo to estimate the expected value of the network
parameters given the previous estimate. Then  the parameter values are updated with stochastic
gradient decent (SGD). We show that the augmented learning loss function is actually equivalent to
the expected value of the network parameters  and that therefore we can guarantee weak convergence.
Moreover  our method depends on the deﬁnition of predictive distributions over the latent variables 
but the design of such distributions is hard because they need to be sufﬁciently expressive to model
high-dimensional data  such as images. We address this challenge by leveraging the recent advances
reached by deep generative models [11]  where data distributions are implicitly represented via deep
neural networks whose parameters are learned from annotated data.
We demonstrate our Bayesian DA algorithm in the training of deep learning classiﬁcation models [15 
16]. Our proposed algorithm is realised by extending a generative adversarial network (GAN)
model [11  22  24] with a data generation model and two discriminative models (one to discriminate
between real and fake images and another to discriminate between the dataset classes). One important
contribution of our approach is the fact that the modularity of our method allows us to test different
models for the generative and discriminative models – in particular  we are able to test several recently
proposed deep learning models [15  16] for the dataset class classiﬁcation. Experiments on MNIST 
CIFAR-10 and CIFAR-100 datasets show the better classiﬁcation performance of our proposed
method compared to the current dominant DA approach.

2

2 Related Work

2.1 Data Augmentation

Data augmentation (DA) has become an essential step in training deep learning models  where
the goal is to enlarge the training sets to avoid over-ﬁtting. DA has also been explored by the
statistical learning community [29  7] for calculating posterior distributions via the introduction of
latent variables. Such DA techniques are useful in cases where the likelihood (or posterior) density
functions are hard to maximize or sample  but the augmented density functions are easier to work.
An important caveat is that in statistical learning  latent variables may not lie in the same space of the
observed data  but in deep learning  the latent variables representing the synthesized training samples
belong to the same space as the observed data.
Synthesizing new training samples from the original training samples is a widely used DA method
for training deep learning models [30  26  19]. The usual idea is to apply either additive Gaussian or
uniform noise over pre-determined families of transformations to generate new synthetic training
samples from the original annotated training samples. For example  Yaeger et al. [30] proposed the
“stroke warping" technique for word recognition  which adds small changes in skew  rotation  and
scaling into the original word images. Simard et al. [26] used a related approach for visual document
analysis. Similarly  Krizhevsky et al. [19] used horizontal reﬂections and color perturbations for
image classiﬁcation. Hauberg et al. [13] proposed a manifold learning approach that is run once
before the classiﬁer training begins  where this manifold describes the geometric transformations
present in the training set.
Nevertheless  the DA approaches presented above have several limitations. First  it is unclear how
to generate diverse data samples. As pointed out by Fawzi et al. [10]  the transformations should
be “sufﬁciently small” so that the ground truth labels are preserved. In other words  these methods
implicitly assume a small scale noise model over a pre-determined “transformation space" of the
training samples. Such an assumption is likely too restrictive and has not been tested properly.
Moreover  these DA mechanisms do not adapt with the progress of the learning process— instead  the
augmented data are generated only once and prior to the training process. This is  in fact  analogous to
the Poor Man’s Data Augmentation (PMDA) [28] algorithm in statistical learning as it is non-iterative.
In contrast  our Bayesian DA algorithm iteratively generates novel training samples as the training
progresses  and the “generator” is adaptively learned. This is crucial because we do not make a noise
model assumption over pre-determined transformation spaces to generate new synthetic training
samples.

2.2 Deep Generative Models

Deep learning has been widely applied in training discriminative models with great success  but
the progress in learning generative models has proven to be more difﬁcult. One noteworthy work
in training deep generative models is the Generative Adversarial Networks (GAN) proposed by
Goodfellow et al. [11]  which  once trained  can be used to sample synthetic images. GAN consists
of one generator and one discriminator  both represented by deep learning models. In “adversarial
training”  the generator and discriminator play a “two-player minimax game”  in which the generator
tries to fool the discriminator by rendering images as similar as possible to the real images  and the
discriminator tries to distinguish the real and fake ones. Nonetheless  the synthetic images generated
by GAN are of low quality when trained on the datasets with high variability [9]. Variants of GAN
have been proposed to improve the quality of the synthetic images [22  3  23  24]. For instance 
conditional GAN [22] improves the original GAN by making the generator conditioned on the class
labels. Auxiliary classiﬁer GAN (AC-GAN) [24] additionally forces the discriminator to classify both
real-or-fake sources as well as the class labels of the input samples. These two works have shown
signiﬁcant improvement over the original GAN in generating photo-realistic images. So far these
generative models mainly aim at generating samples of high-quality  high-resolution photo-realistic
images. In contrast  we explore generative models (in the form of GANs) in our proposed Bayesian
DA algorithm for improving classiﬁcation models.

3

3 Data Augmentation Algorithm in Deep Learning

3.1 Bayesian Neural Networks

Our goal is to estimate the parameters of a deep learning model using an annotated training set
denoted by Y = {yn}N
n=1  where y = (t  x)  with annotations t ∈ {1  ...  K} (K = # Classes)  and
data samples represented by x ∈ RD. Denoting the model parameters by θ  the training process is
deﬁned by the following optimisation problem:

θ∗ = arg max

log p(θ|y) 

(1)

where the observed posterior p(θ|y) = p(θ|t  x) ∝ p(t|x  θ)p(x|θ)p(θ).
Assuming that the data samples in Y are conditionally independent  the cost function that maximises
(1) is deﬁned as [1]:

θ

N(cid:88)

n=1

1
N

log p(θ|y) ≈ log p(θ) +

(log p(tn|xn  θ) + log p(xn|θ)) 

(2)
where p(θ) denotes a prior on the distribution of the deep learning model parameters  p(tn|xn  θ)
represents the conditional likelihood of label tn  and p(xn|θ) is the likelihood of the data x.
In general  the training process to estimate the model parameters θ tends to over-ﬁt the training set Y
given the large dimensionality of θ and the fact that Y does not have a sufﬁciently large amount of
training samples. One of the main approaches designed to circumvent this over-ﬁtting issue is the
automated generation of synthetic training samples — a process known as data augmentation (DA).
In this work  we propose a novel Bayesian approach to augment the training set  targeting a more
robust training process.

3.2 Data Augmentation using Latent Variable Methods

The DA principle is to increase the observed training data y using a latent variable z that represents
the synthesised data  so that the augmented posterior p(θ|y  z) can be easily estimated [28]  leading
to a more robust estimation of p(θ|y). The latent variable is deﬁned by z = (ta  xa)  where xa ∈ RD
refers to a synthesized data point  and ta ∈ {1  ...  K} denotes the associated label.
The most commonly chosen optimization method in these types of training processes involving
a latent variable is the expectation-maximisation (EM) algorithm [7]. In EM  let θi denote the
estimated parameters of the model of p(θ|y) at iteration i  and p(z|θi  y) represents the conditional
predictive distribution of z. Then  the E-step computes the expectation of log p(θ|y  z) with respect
to p(z|θi  y)  as follows:

Q(θ  θi) = Ep(z|θi y) log p(θ|y  z) =

log p(θ|y  z)p(z|θi  y)dz.

(3)

(cid:90)

The parameter estimation at the next iteration  θi+1  is then obtained at the M-step by maximizing
the Q function:

z

θ

Q(θ  θi).

θi+1 = arg max

(4)
The algorithm iterates until ||θi+1 − θi|| is sufﬁciently small  and the optimal θ∗ is selected from the
last iteration. The EM algorithm guarantees that the sequence {θi}i=1 2 ... converges to a stationary
point of p(θ|y) [7  28]  given that the expectation in (3) and the maximization in (4) can be computed
exactly. In the convergence proof [7  28]  it is assumed that θi converges to θ∗ as the number of
iterations i increases  then the proof consists of showing that θ∗ is a critical point of p(θ|y).
However  in practice  either the E-step or M-step or both can be difﬁcult to compute exactly  especially
when working with deep learning models. In such cases  we need to rely on approximation methods.
For instance  Monte Carlo sampling method can approximate the integration in (3) (the E-step).
This technique is known as Monte Carlo EM (MCEM) algorithm [28]. Furthermore  when the
estimation of the global maximiser of Q(θ  θi) in (4) is difﬁcult  Dempster et al. [7] proposed the
Generalized EM (GEM) algorithm  which relaxes this requirement with the estimation of θi+1  where
Q(θi+1  θi) > Q(θi  θi). The GEM algorithm is proven to have weak convergence [28]  by showing
that p(θi+1|y) > p(θi|y)  given that Q(θi+1  θi) > Q(θi  θi).

4

M(cid:88)

m=1

M(cid:88)

m=1

3.3 Generalized Monte Carlo EM Algorithm
With the latent variable z  the augmented posterior p(θ|y  z) becomes:

p(θ|y  z) =

p(y  z  θ)
p(y  z)

=

p(z|y  θ)p(θ|y)p(y)

p(z|y)p(y)

=

p(z|y  θ)p(θ|y)

p(z|y)

 

(5)

where the E-step is represented by the following Monte-Carlo estimation of Q(θ  θi):

ˆQ(θ  θi) =

1
M

log p(θ|y  zm) = log p(θ|y) +

1
M

(log p(zm|y  θ) − log p(zm|y)) 

(6)

where zm ∼ p(z|y  θi)  for m ∈ {1  ...  M}. In (6)  if the label ta
zm is known  then xa
m can be sampled from the distribution p(xa
distribution p(z|y  θ) can be decomposed as:

m of the mth synthesized sample
m|θ  y  ta
m). Hence  the conditional

p(z|y  θ) = p(ta  xa|y  θ) = p(ta|xa  y  θ)p(xa|y  θ) 

(7)

where (ta  xa) are conditionally independent of y given that all the information from the training set
y is summarized in θ — this means that p(ta|xa  y  θ) = p(ta|xa  θ)  and p(xa|y  θ) = p(xa|θ).
The maximization of ˆQ(θ  θi) with respect to θ for the M-step is re-formulated by ﬁrst removing all
terms that are independent of θ  which allows us to reach the following derivation (making the same
assumption as in (2)):

ˆQ(θ  θi) = log p(θ) +

(log p(tn|xn  θ) + log p(xn|θ)) +

log p(zm|y  θ)

(8)

N(cid:88)

n=1

1
N

N(cid:88)

n=1

M(cid:88)

m=1

1
M

M(cid:88)

m=1

1
M

= log p(θ) +

1
N

(log p(tn|xn  θ) + log p(xn|θ)) +

(log p(ta

m|xa

m  θ) + log p(xa

m|θ)).

Given that there is no analytical solution for the optimization in (8)  we follow the same strategy
employed in the GEM algorithm  where we estimate θi+1 so that ˆQ(θi+1  θi) > ˆQ(θi  θi).
As the function ˆQ(·  θi) is differentiable  we can ﬁnd such θi+1 by running one step of gradient
decent. It can be seen that our proposed optimization consists of a marriage between MCEM and
GEM algorithms  which we name: Generalized Monte Carlo EM (GMCEM). The weak convergence
proof of GMCEM is provided by Lemma 1.
Lemma 1. Assuming that ˆQ(θi+1  θi) > ˆQ(θi  θi)  which is guaranteed from (8)  then the weak
convergence (i.e. p(θi+1|y) > p(θi|y)) will be fulﬁlled.

Proof. Given ˆQ(θi+1  θi) > ˆQ(θi  θi)  then by taking the expectation on both sides  that is
Ep(z|y θi)[ ˆQ(θi+1  θi)] > Ep(z|y θi)[ ˆQ(θi  θi)]  we obtain Q(θi+1  θi) > Q(θi  θi)  which is the
condition for p(θi+1|y) > p(θi|y) proven from [28].

So far  we have presented our Bayesian DA algorithm in a very general manner. The speciﬁc forms
that the probability terms in (8) take in our implementation are presented in the next section.

4

Implementation

In general  our proposed DA algorithm can be implemented using any deep generative and classiﬁca-
tion models which have differentiable optimisation functions. This is in fact an important advantage
that allows us to use the most sophisticated extant models available in the ﬁeld for the implementa-
tion of our algorithm. In this section  we present a speciﬁc implementation of our approach using
state-of-the-art discriminative and generative models.

5

4.1 Network Architecture

Our network architecture consists of two models: a classiﬁer and a generator. For the classiﬁer 
modern deep convolutional neural networks [15  16] can be used. For the generator  we select
the adversarial generative networks (GAN) [11]  which include a generative model (represented
by a deconvolutional neural network) and an authenticator model (represented by a convolutional
neural network). This authenticator component is mainly used for facilitating the adversarial
training. As a result  our network consists of a classiﬁer (C) with parameters θC  a generator (G)
with parameters θG and an Authenticator (A) with parameters θA. Fig. 2 compares our network
architecture with other variants of GAN recently proposed [11  22  24]. On the surface  our network
appears similar to AC-GAN [24]  where the only difference is the separation of the classiﬁer network
from the authenticator network. However  this crucial modularisation enables our DA algorithm
to replace GANs by other generative models that may become available in the future; likewise 
we can use the most sophisticated classiﬁcation models for C. Furthermore  unlike our model 
the classiﬁcation subnetwork introduced in AC-GAN mainly aims for improving the quality of
synthesized samples  rather than for classiﬁcation tasks. Nonetheless  one can consider AC-GAN
as one possible implementation of our DA algorithm. Finally  our proposed GAN model is similar
to the recently proposed triplet GAN [21] 1  but it is important to emphasise that triplet GAN was
proposed in order to improve the training procedure for GANs  while our model represents a particular
realisation of the proposed Bayesian DA algorithm  which is the main contribution of this paper.

Figure 2: A comparison of different network architectures including GAN[11]  C-GAN [22]  AC-
GAN [24] and ours. G: Generator  A: Authenticator  C: Classiﬁer  D: Discriminator.

4.2 Optimization Function
Let us deﬁne x ∈ RD  θC ∈ RC  θA ∈ RA  θG ∈ RG  u ∈ R100  c ∈ {1  ...  K}  the classiﬁer C  the
authenticator A and the generator G are respectively deﬁned by

fC : RD × RC → [0  1]K;
fA : RD × RA → [0  1]2;
fG : R100 × Z+ × RG → RD.

N(cid:88)

n=1

N(cid:88)

n=1

M(cid:88)

m=1

M(cid:88)

m=1

The optimisation function used to train the classiﬁer C is deﬁned as:

JC(θC) =

1
N

lC(tn|xn  θC) +

1
M

lC(ta

m|xa

m  θC) 

where lC(tn|xn  θC) = − log (softmax(fC(tn = c; xn  θC))).
The optimisation functions for the authenticator and generator networks are deﬁned by [11]:

JAG(θA  θG) =

1
N

lA(xn|θA) +

1
M

lAG(xa

m|θA  θG) 

1The triplet GAN [21] was proposed in parallel to this NIPS submission.

6

(9)
(10)
(11)

(12)

(13)

where

lAG(xa

lA(xn|θA) = − log (softmax(fA(input = real  xn  θA)) ;
m|θA  θG) = − log (1 − softmax(fA(input = real  xa

(14)
(15)
Following the same training procedure used to train GANs [11  24]  the optimisation is divided into
two steps: the training of the discriminative part  consisting of minimising JC(θC) + JAG(θA  θG)
and the training of the generative part consisting of minimising JC(θC) − JAG(θA  θG). This loss
function can be linked to (8)  as follows:

m  θG  θA))) .

lC(tn|xn  θC) = − log p(tn|xn  θ) 
lC(ta
m  θ) 

m|xa
m  θC) = − log p(ta
m|xa
lA(xn|θA) = − log p(xn|θ) 
m|θA  θG) = − log p(xa
m|θ).

lAG(xa

(16)
(17)
(18)
(19)

4.3 Training

Training the network parameters θ follows the proposed GMCEM algorithm presented in Sec. 3.
Accordingly  at each iteration we need to ﬁnd θi+1 so that ˆQ(θi+1  θi) > ˆQ(θi  θi)  which can be
achieved using gradient decent. However  since the number of training and augmented samples
(i.e.  N + M) is large  evaluating the sum of the gradients over this whole set is computationally
expensive. A similar issue was observed in contrastive divergence [2]  where the computation of the
approximate gradient required in theory an inﬁnite number of Markov chain Monte Carlo (MCMC)
cycles  but in practice  it was noted that only a few cycles were needed to provide a robust gradient
approximation. Analogously  following the same principle  we propose to replace gradient decent by
stochastic gradient decent (SGD)  where the update from θi to θi+1 is estimated using only a sub-set
of the M + N training samples. In practice  we divide the training set into batches  and the updated
θi+1 is obtained by running SGD through all batches (i.e  one epoch). We found that such strategy
works well empirically  as shown in the experiments (Sec. 5).

5 Experiments

In this section  we compare our proposed Bayesian DA algorithm with the commonly used DA
technique [19] (denoted as PMDA) on several image classiﬁcation tasks (code available at: https:
//github.com/toantm/keras-bda). This comparison is based on experiments using the
following three datasets: MNIST [20] (containing 60  000 training and 10  000 testing images of 10
handwritten digits)  CIFAR-10[18] (consisting of 50  000 training and 10  000 testing images of 10
visual classes like car  dog  cat  etc.)  and CIFAR-100 [18] (containing the same amount of training
and testing samples as CIFAR-10  but with 100 visual classes).
The experimental results are based on the top-1 classiﬁcation accuracy as a function of the amount of
data augmentation used – in particular  we try the following amounts of synthesized images M: a)
M = N (i.e.  2× DA)  M = 4N (5× DA)  and M = 9N (10× DA). The PMDA is based on the
use of a uniform noise model over a rotation range of [−10  10] degrees  and a translation range of at
most 10% of the image width and height. Other transformations were tested  but these two provided
the best results for PMDA on the datasets considered in this paper. We also include an experiment
that does not use DA in order to illustrate the importance of DA in deep learning.
As mentioned in Sec. 1  one important contribution of our method is its ability to use arbitrary deep
learning generative and classiﬁcation models. For the generative model  we use the C-GAN [22] 2  and
for the classiﬁcation model we rely on the ResNet18 [15] and ResNetpa [16]. The architectures of the
generator and authenticator networks  which are kept unchanged for all three datasets  can be found
in the supplementary material. For training  we use Adadelta (with learning rate=1.0  decay rate=0.95
and epsilon=1e − 8) for the Classiﬁer (C)  Adam (with learning rate 0.0002  and exponential decay
rate 0.5) for the Generator (G) and SDG (with learning rate 0.01) for the Authenticator (A). The
noise vector used by the Generator G is based on a standard Gaussian noise. In all experiments  we
use training batches of size 100.
Comparison results using ResNet18 and ResNetpa networks are shown in Figures 3 and 4. First  in all
cases it is clear that DA provides a signiﬁcant improvement in the classiﬁcation accuracy – in general 

2The code was adapted from: https://github.com/lukedeo/keras-acgan

7

(a) MNIST

(b) CIFAR-10

(c) CIFAR-100

Figure 3: Performance comparison using ResNet18 [15] classiﬁer.

(a) MNIST

(b) CIFAR-10

(c) CIFAR-100

Figure 4: Performance comparison using ResNetpa [16] classiﬁer.

larger augmented training set sizes lead to more accurate classiﬁcation. More importantly  the results
reveal that our Bayesian DA algorithm outperforms PMDA by a large margin in all datasets. Given
the similarity between the model used by our proposed Bayesian DA algorithm (using ResNetpa [16])
and AC-GAN  it is relevant to present a comparison between these two models  which is shown in
Fig. 5 – notice that our approach is far superior to AC-GAN. Finally  it is also important to show the
evolution of the test classiﬁcation accuracy as a function of training time – this is reported in Fig. 6.
As expected  it is clear that PMDA produces better classiﬁcation results at the ﬁrst training stages  but
after a certain amount of training  our Bayesian DA algorithm produces better results. In particular 
using the ResNet18 [15] classiﬁer  on CIFAR-100  our method is better than PMDA after two hours
of training; while for MNIST  our method is better after ﬁve hours of training.
It is worth emphasizing that the main goal of the proposed Bayesian DA is to improve the training
process of the classiﬁer C. Nevertheless  it is also of interest to investigate the quality of the
images produced by the generator G. In Fig. 7  we display several examples of the synthetic images
produced by G after the training process has converged. In general  the images look reasonably
realistic  particularly the handwritten digits  where the synthesized images would be hard to generate

(a) MNIST

(b) CIFAR-10

(c) CIFAR-100

Figure 5: Performance comparison with AC-GAN using ResNetpa [16]

8

2X5X10X Increase size of training data99.299.399.499.599.699.7Accuracy rateResNet18 on MNISTWithout DAPMDAOurs2X5X10X Increase size of training data7580859095Accuracy rateResNet18 on CIFAR-10Without DAPMDAOurs2X5X10X Increase size of training data4050607080Accuracy rateResNet18 on CIFAR-100Without DAPMDAOurs2X5X10X Increase size of training data99.5599.699.6599.799.75Accuracy rateResNetPA on MNISTWithout DAPMDAOurs2X5X10X Increase size of training data848688909294Accuracy rateResNetPA on CIFAR-10Without DAPMDAOurs2X5X10X Increase size of training data5560657075Accuracy rateResNetPA on CIFAR-100Without DAPMDAOurs2X5X10X Increase size of training data9999.299.499.699.8Accuracy rate Comparison with AC-GAN on MNISTAC-GANResNetpa without DAResNetpa with ours2X5X10X Increase size of training data80859095Accuracy rate Comparison with AC-GAN on CIFAR-10AC-GANResNetpa without DAResNetpa with ours2X5X10X Increase size of training data505560657075Accuracy rate Comparison with AC-GAN on CIFAR-100AC-GANResNetpa without DAResNetpa with ours(a) MNIST

(b) CIFAR-100

Figure 6: Classiﬁcation accuracy (as a function of the training time) using PMDA and our proposed
data augmentation on ResNet18 [15]

(a) MNIST

(b) CIFAR-10

(c) CIFAR-100

Figure 7: Synthesized images generated using our model trained on MNIST (a)  CIFAR-10 (b) and
CIFAR-100 (c). Each column is conditioned on a class label: a) classes are 0  ...  9; b) classes are
airplane  automobile  bird and ship; and c) classes are apple  aquarium ﬁsh  rose and lobster.

by the application of Gaussian or uniform noise on pre-determined geometric and appearance
transformations.

6 Conclusions

In this paper we have presented a novel Bayesian DA that improves the training process of deep
learning classiﬁcation models. Unlike currently dominant methods that apply random transformations
to the observed training samples  our method is theoretically sound; the missing data are sampled
from the distribution learned from the annotated training set. However  we do not train the generator
distribution independently from the training of the classiﬁcation model. Instead  both models are
jointly optimised based on our proposed Bayesian DA formulation that connects the classical latent
variable method in statistical learning with modern deep generative models. The advantages of
our data augmentation approach are validated using several image classiﬁcation tasks with clear
improvements over standard DA methods and also over the recently proposed AC-GAN model [24].

Acknowledgments

TT gratefully acknowledges the support by Vietnam International Education Development (VIED).
TP  GC and IR gratefully acknowledge the support of the Australian Research Council through the
Centre of Excellence for Robotic Vision (project number CE140100016) and Laureate Fellowship
FL130100102 to IR.

9

0.1hr1hr2hrs5hrs10hrs24hrs Training time9092949698100Accuracy rate ResNet18 on MNISTWith PMDAWith ours0.1hr1hr2hrs5hrs10hrs24hrs Training time304050607080Accuracy rate ResNet18 on CIFAR-100With PMDAWith oursReferences
[1] C. Bishop. Pattern recognition and machine learning (information science and statistics)  1st edn. 2006.

corr. 2nd printing edn. Springer  New York  2007.

[2] M. A. Carreira-Perpinan and G. E. Hinton. On contrastive divergence learning. In AISTATS  volume 10 

pages 33–40. Citeseer  2005.

[3] X. Chen  Y. Duan  R. Houthooft  J. Schulman  I. Sutskever  and P. Abbeel.

interpretable
representation learning by information maximizing generative adversarial nets. In Advances in Neural
Information Processing Systems  2016.

[4] R. Collobert and J. Weston. A uniﬁed architecture for natural language processing: Deep neural networks
with multitask learning. In Proceedings of the 25th international conference on Machine learning  pages
160–167. ACM  2008.

[5] R. Collobert  J. Weston  L. Bottou  M. Karlen  K. Kavukcuoglu  and P. Kuksa. Natural language processing

Infogan:

(almost) from scratch. Journal of Machine Learning Research  12(Aug):2493–2537  2011.

[6] X. Cui  V. Goel  and B. Kingsbury. Data augmentation for deep neural network acoustic modeling.
IEEE/ACM Transactions on Audio  Speech and Language Processing (TASLP)  23(9):1469–1477  2015.
[7] A. P. Dempster  N. M. Laird  and D. B. Rubin. Maximum likelihood from incomplete data via the em

algorithm. Journal of the royal statistical society. Series B (methodological)  pages 1–38  1977.

[8] J. Deng  W. Dong  R. Socher  L.-J. Li  K. Li  and L. Fei-Fei. Imagenet: A large-scale hierarchical image

database. In IEEE Conference on Computer Vision and Pattern Recognition  2009  2009.

[9] E. L. Denton  S. Chintala  a. szlam  and R. Fergus. Deep generative image models using a laplacian pyramid
of adversarial networks. In Advances in Neural Information Processing Systems 28  pages 1486–1494.
2015.

[10] A. Fawzi  H. Samulowitz  D. Turaga  and P. Frossard. Adaptive data augmentation for image classiﬁcation.

In Image Processing (ICIP)  2016 IEEE International Conference on  pages 3688–3692. IEEE  2016.

[11] I. Goodfellow  J. Pouget-Abadie  M. Mirza  B. Xu  D. Warde-Farley  S. Ozair  A. Courville  and Y. Bengio.
Generative adversarial nets. In Advances in neural information processing systems  pages 2672–2680 
2014.

[12] A. Graves  A.-r. Mohamed  and G. Hinton. Speech recognition with deep recurrent neural networks. In
Acoustics  speech and signal processing (icassp)  2013 ieee international conference on  pages 6645–6649.
IEEE  2013.

[13] S. Hauberg  O. Freifeld  A. B. L. Larsen  J. Fisher  and L. Hansen. Dreaming more data: Class-dependent
distributions over diffeomorphisms for learned data augmentation. In Artiﬁcial Intelligence and Statistics 
pages 342–350  2016.

[14] K. He  X. Zhang  S. Ren  and J. Sun. Spatial pyramid pooling in deep convolutional networks for visual

recognition. IEEE transactions on pattern analysis and machine intelligence  37(9):1904–1916  2015.

[15] K. He  X. Zhang  S. Ren  and J. Sun. Deep residual learning for image recognition. In Proceedings of the

IEEE Conference on Computer Vision and Pattern Recognition  pages 770–778  2016.

[16] K. He  X. Zhang  S. Ren  and J. Sun. Identity mappings in deep residual networks. In European Conference

on Computer Vision  pages 630–645. Springer  2016.

[17] G. Hinton  L. Deng  D. Yu  G. E. Dahl  A.-r. Mohamed  N. Jaitly  A. Senior  V. Vanhoucke  P. Nguyen 
T. N. Sainath  et al. Deep neural networks for acoustic modeling in speech recognition: The shared views
of four research groups. IEEE Signal Processing Magazine  29(6):82–97  2012.

[18] A. Krizhevsky and G. Hinton. Learning multiple layers of features from tiny images. 2009.
[19] A. Krizhevsky  I. Sutskever  and G. E. Hinton. Imagenet classiﬁcation with deep convolutional neural

networks. In Advances in neural information processing systems  pages 1097–1105  2012.

[20] Y. LeCun  L. Bottou  Y. Bengio  and P. Haffner. Gradient-based learning applied to document recognition.

Proceedings of the IEEE  86(11):2278–2324  1998.

[21] C. Li  K. Xu  J. Zhu  and B. Zhang. Triple generative adversarial nets. CoRR  abs/1703.02291  2017.
[22] M. Mirza and S. Osindero. Conditional generative adversarial nets. arXiv preprint arXiv:1411.1784  2014.
arXiv preprint
[23] A. Odena.

Semi-supervised learning with generative adversarial networks.

[24] A. Odena  C. Olah  and J. Shlens. Conditional image synthesis with auxiliary classiﬁer gans. arXiv preprint

arXiv:1606.01583  2016.

arXiv:1610.09585  2016.

[25] O. Russakovsky  J. Deng  H. Su  J. Krause  S. Satheesh  S. Ma  Z. Huang  A. Karpathy  A. Khosla 
M. Bernstein  et al. Imagenet large scale visual recognition challenge. International Journal of Computer
Vision  115(3):211–252  2015.

[26] P. Y. Simard  D. Steinkraus  and J. C. Platt. Best practices for convolutional neural networks applied to
visual document analysis. In Proceedings of the Seventh International Conference on Document Analysis
and Recognition - Volume 2  2003.

[27] K. Simonyan and A. Zisserman. Very deep convolutional networks for large-scale image recognition.

CoRR  abs/1409.1556  2014.

in Statistics  67  1991.

[28] M. A. Tanner. Tools for statistical inference: Observed data and data augmentation methods. Lecture Notes

[29] M. A. Tanner and W. H. Wong. The calculation of posterior distributions by data augmentation. Journal of

the American statistical Association  82(398):528–540  1987.

[30] L. Yaeger  R. Lyon  and B. Webb. Effective training of a neural network character classiﬁer for word

recognition. In NIPS  volume 9  pages 807–813  1996.

[31] X. Zhang and Y. LeCun. Text understanding from scratch. arXiv preprint arXiv:1502.01710  2015.

10

,Toan Tran
Trung Pham
Gustavo Carneiro
Lyle Palmer
Ian Reid