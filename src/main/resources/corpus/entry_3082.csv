2011,Learning large-margin halfspaces with more malicious noise,We describe a simple algorithm that runs in time  poly(n 1/gamma 1/eps) and learns an unknown n-dimensional  gamma-margin halfspace to accuracy 1-eps in the presence of  malicious noise  when the noise rate is allowed to be as high as  Theta(eps gamma sqrt(log(1/gamma))). Previous efficient  algorithms could only learn to accuracy eps in the presence of  malicious noise of rate at most Theta(eps gamma).    Our algorithm does not work by optimizing a convex loss function.  We  show that no algorithm for learning gamma-margin halfspaces that  minimizes a convex proxy for misclassification error can tolerate  malicious noise at a rate greater than Theta(eps gamma); this may  partially explain why previous algorithms could not achieve the higher  noise tolerance of our new algorithm.,Learning large-margin halfspaces

with more malicious noise

Philip M. Long

Google

plong@google.com

Rocco A. Servedio
Columbia University

rocco@cs.columbia.edu

Abstract

We describe a simple algorithm that runs in time poly(n  1/γ  1/ε) and learns an
unknown n-dimensional γ-margin halfspace to accuracy 1 − ε in the presence of

malicious noise  when the noise rate is allowed to be as high as Θ(εγ(cid:112)log(1/γ)).

Previous efﬁcient algorithms could only learn to accuracy ε in the presence of
malicious noise of rate at most Θ(εγ).
Our algorithm does not work by optimizing a convex loss function. We show that
no algorithm for learning γ-margin halfspaces that minimizes a convex proxy for
misclassiﬁcation error can tolerate malicious noise at a rate greater than Θ(εγ);
this may partially explain why previous algorithms could not achieve the higher
noise tolerance of our new algorithm.

1

Introduction

Learning an unknown halfspace from labeled examples that satisfy a margin constraint (meaning that
no example may lie too close to the separating hyperplane) is one of the oldest and most intensively
studied problems in machine learning  with research going back at least ﬁve decades to early seminal
work on the Perceptron algorithm [5  26  27].
In this paper we study the problem of learning an unknown γ-margin halfspace in the model of
Probably Approximately Correct (PAC) learning with malicious noise at rate η. More precisely  in
this learning scenario the target function is an unknown origin-centered halfspace f(x) = sign(w ·
x) over the domain Rn (we may assume w.l.o.g.
that w is a unit vector). There is an unknown
distribution D over the unit ball Bn = {x ∈ Rn : (cid:107)x(cid:107)2 ≤ 1} which is guaranteed to put zero
probability mass on examples x that lie within Euclidean distance at most γ from the separating
hyperplane w · x = 0; in other words  every point x in the support of D satisﬁes |w · x| ≥ γ. The
learner has access to a noisy example oracle EX η(f D) which works as follows: when invoked 
with probability 1 − η the oracle draws x from D and outputs the labeled example (x  f(x)) and
with probability η the oracle outputs a “noisy” labeled example which may be an arbitrary element
(x(cid:48)  y) of Bn×{−1  1}. (It may be helpful to think of the noisy examples as being constructed by an
omniscient and malevolent adversary who has full knowledge of the state of the learning algorithm
and previous draws from the oracle. In particular  note that noisy examples need not satisfy the
margin constraint and can lie arbitrarily close to  or on  the hyperplane w · x = 0.) The goal of
the learner is to output a hypothesis h : Rn → {−1  1} which has high accuracy with respect to
D: more precisely  with probability at least 1/2 (over the draws from D used to run the learner and
any internal randomness of the learner) the hypothesis h must satisfy Prx∼D[h(x) (cid:54)= f(x)] ≤ ε.
(Because a success probability can be improved efﬁciently using standard repeat-and-test techniques
[19]  we follow the common practice of excluding this success probability from our analysis.)
In
particular  we are interested in computationally efﬁcient learning algorithms which have running
time poly(n  1/γ  1/ε).

1

Introduced by Valiant in 1985 [30]  the malicious noise model is a challenging one  as witnessed by
the fact that learning algorithms can typically only withstand relatively low levels of malicious noise.
Indeed  it is well known that for essentially all PAC learning problems it is information-theoretically
possible to learn to accuracy 1 − ε only if the malicious noise rate η is at most ε/(1 + ε) [20] 
and most computationally efﬁcient algorithms for learning even simple classes of functions can only
tolerate signiﬁcantly lower malicious noise rates (see e.g. [1  2  8  20  24  28]).
Interestingly  the original Perceptron algorithm [5  26  27] for learning a γ-margin halfspace can be
shown to have relatively high tolerance to malicious noise. Several researchers [14  17] have estab-
lished upper bounds on the number of mistakes that the Perceptron algorithm will make when run on
a sequence of examples that are linearly separable with a margin except for some limited number of
“noisy” data points. Servedio [28] observed that combining these upper bounds with Theorem 6.2
of Auer and Cesa-Bianchi [3] yields a straightforward “PAC version” of the online Perceptron al-
gorithm that can learn γ-margin halfspaces to accuracy 1 − ε in the presence of malicious noise
provided that the malicious noise rate η is at most some value Θ(εγ). Servedio [28] also describes
a different PAC learning algorithm which uses a “smooth” booster together with a simple geometric
real-valued weak learner and achieves essentially the same result: it also learns a γ-margin halfspace
to accuracy 1 − ε in the presence of malicious noise at rate at most Θ(εγ). Both the boosting-based
algorithm of [28] and the Perceptron-based approach run in time poly(n  1/γ  1/ε).
Our results. We give a simple new algorithm for learning γ-margin halfspaces in the presence of
malicious noise. Like the earlier approaches  our algorithm runs in time poly(n  1/γ  1/ε); however 
it goes beyond the Θ(εγ) malicious noise tolerance of previous approaches. Our ﬁrst main result is:

Theorem 1 There is a poly(n  1/γ  1/ε)-time algorithm that can learn an unknown γ-margin half-

space to accuracy 1− ε in the presence of malicious noise at any rate η ≤ cεγ(cid:112)log(1/γ) whenever
While our Θ((cid:112)log(1/γ)) improvement is not large  it is interesting to go beyond the “natural-

γ < 1/7  where c > 0 is a universal constant.

looking” Θ(εγ) bound of Perceptron and other simple approaches. The algorithm of Theorem 1 is
not based on convex optimization  and this is not a coincidence: our second main result is  roughly
stated  the following.

Informal paraphrase of Theorem 2 Let A be any learning algorithm that chooses a hypothesis
vector v so as to minimize a convex proxy for the binary misclassiﬁcation error. Then A cannot
learn γ-margin halfspaces to accuracy 1 − ε in the presence of malicious noise at rate η ≥ cεγ 
where c > 0 is a universal constant.

Our approach. The algorithm of Theorem 1 is a modiﬁcation of a boosting-based approach to
learning halfspaces that is due to Balcan and Blum [7] (see also [6]). [7] considers a weak learner
which simply generates a random origin-centered halfspace sign(v · x) by taking v to be a uniform
random unit vector. The analysis of [7]  which is for a noise-free setting  shows that such a random
halfspace has probability Ω(γ) of having accuracy at least 1/2 + Ω(γ) with respect to D. Given
this  any boosting algorithm can be used to get a PAC algorithm for learning γ-margin halfspaces to
accuracy 1 − ε.
Our algorithm is based on a modiﬁed weak learner which generates a collection of k = (cid:100)log(1/γ)(cid:101)
independent random origin-centered halfspaces h1 = sign(v1 · x)  . . .   hk = sign(vk · x) and takes
the majority vote H = Maj(h1  . . .   hk). The crux of our analysis is to show that if there is no noise 
k) with
then with probability at least (roughly) γ2 the function H has accuracy at least 1/2 + Ω(γ
respect to D (see Section 2  in particular Lemma 1). By using this weak learner in conjunction with
a “smooth” boosting algorithm as in [28]  we get the overall malicious-noise-tolerant PAC learning
algorithm of Theorem 1 (see Section 3).
For Theorem 2 we consider any algorithm that draws some number m of samples and minimizes
a convex proxy for misclassiﬁcation error. If m is too small then well-known sample complexity
bounds imply that the algorithm cannot learn γ-margin halfspaces to high accuracy  so we may
assume that m is large; but together with the assumption that the noise rate is high  this means
that with overwhelmingly high probability the sample will contain many noisy examples. The heart
of our analysis deals with this situation; we describe a simple γ-margin data source and adversary

√

2

strategy which ensures that the convex proxy for misclassiﬁcation error will achieve its minimum
on a hypothesis vector that has accuracy less than 1 − ε with respect to the underlying noiseless
distribution of examples. We also establish the same fact about algorithms that use a regularizer
from a class that includes the most popular regularizers based on p-norms.
Related work. As mentioned above  Servedio [28] gave a boosting-based algorithm that learns
γ-margin halfspaces with malicious noise at rates up to η = Θ(εγ). Khardon and Wachman [21]
empirically studied the noise tolerance of variants of the Perceptron algorithm. Klivans et al. [22]
showed that an algorithm that combines PCA-like techniques with smooth boosting can tolerate rel-
atively high levels of malicious noise provided that the distribution D is sufﬁciently “nice” (uniform
over the unit sphere or isotropic log-concave). We note that γ-margin distributions are signiﬁcantly
less restrictive and can be very far from having the “nice” properties required by [22].
We previously [23] showed that any boosting algorithm that works by stagewise minimization of a
convex “potential function” cannot tolerate random classiﬁcation noise – this is a type of “benign”
rather than malicious noise  which independently ﬂips the label of each example with probability η.
A natural question is whether Theorem 2 follows from [23] by having the malicious noise simply
simulate random classiﬁcation noise; the answer is no  essentially because the ordering of quantiﬁers
is reversed in the two results. The construction and analysis from [23] crucially relies on the fact
that in the setting of that paper  ﬁrst the random misclassiﬁcation noise rate η is chosen to take some
particular value in (0  1/2)  and then the margin parameter γ is selected in a way that depends on
η. In contrast  in this paper the situation is reversed: in our setting ﬁrst the margin parameter γ is
selected  and then given this value we study how high a malicious noise rate η can be tolerated.

2 The basic weak learner for Theorem 1

Let f(x) = sign(w · x) be an unknown halfspace and D be an unknown distribution over the n-
dimensional unit ball that has a γ margin with respect to f as described in Section 1. For odd k ≥ 1
we let Ak denote the algorithm that works as follows: Ak generates k independent uniform random
unit vectors v1  . . .   vk in Rn and outputs the hypothesis H(x) = Maj(sign(v1 · x)  . . .   sign(vk ·
x)). Note that Ak does not use any examples (and thus malicious noise does not affect its execution).
As the main result of Section 2 we show that if k is not too large then algorithm Ak has a non-
negligible chance of outputting a reasonably good weak hypothesis:

Lemma 1 For odd k ≤ 1
of satisfying Prx∼D[H(x) (cid:54)= f(x)] ≤ 1

2 − γ

√
k
100π .

16γ2 the hypothesis H generated by Ak has probability at least Ω(γ

√

k/2k)

2.1 A useful tail bound

(cid:104)(cid:80)k

(cid:105)

i=1 Xi < k/2

in analyzing algorithm Ak: Let

:=
The following notation will be useful
Pr
where X1  . . .   Xk are i.i.d. Bernoulli (0/1) random variables with E[Xi] =
1/2 + γ for all i. Clearly vote(γ  k) is the lower tail of a Binomial distribution  but for our pur-
poses we need an upper bound on vote(γ  k) when k is very small relative to 1/γ2 and the value
of vote(γ  k) is close to but – crucially – less than 1/2. Standard Chernoff-type bounds [10] do not
seem to be useful here  so we give a simple self-contained proof of the bound we need (no attempt
has been made to optimize constant factors below).

vote(γ  k)

Lemma 2 For 0 < γ < 1/2 and odd k ≤ 1

Proof: The lemma is easily veriﬁed for k = 1  3  5  7 so we assume k ≥ 9 below. The

value vote(γ  k) equals (cid:80)
(cid:80)
(cid:80)

1
2k
mains to show that 1
2k

(cid:1)(1 − 4γ2)i(1 − 2γ)k−2i. Since k is odd 1

16γ2 we have vote(γ  k) ≤ 1/2 − γ
(cid:0)k
(cid:1)(1/2 − γ)k−i(1/2 + γ)i  which is easily seen to equal
(cid:0)k
(cid:1) equals 1/2  so it re-
(cid:1)(cid:2)1 − (1 − 4γ2)i(1 − 2γ)k−2i(cid:3) ≥ γ

√
i
k
50 . Consider any integer

(cid:80)

(cid:0)k

i

(cid:0)k

i

i<k/2

i

2k

i<k/2

i<k/2

i<k/2

√
k
50 .

3

i ∈ [0  k/2 − √

k]. For such an i we have
√
(1 − 2γ)k−2i ≤ (1 − 2γ)2

(cid:18)2

(cid:19)

√

2

k

(1)

√
k ≤ 1 − (2γ)(2
√
√

≤ 1 − 4γ
≤ 1 − 4γ

k + 8γ
k + 2γ

√
√

k) + (2γ)2
√

k)

k(γ
k = 1 − 2γ

√
where (1) is obtained by truncating the alternating binomial series expansion of (1 − 2γ)2

a positive term  (2) uses the upper bound(cid:0)(cid:96)
k. The sum(cid:80)

from the bound k ≤ 1
1− (1− 4γ2)i(1− 2γ)k−2i ≥ 2γ
[13]  so we obtain the claimed bound:

(cid:1) ≤ (cid:96)2/2  and (3) uses γ
(cid:18)k

16γ2 . So we have (1 − 4γ2)i(1 − 2γ)k−2i ≤ 1 − 2γ
(cid:19)

(cid:19)(cid:2)1 − (1 − 4γ2)i(1 − 2γ)k−2i(cid:3) ≥ 1

(cid:1) is at least 0.01· 2k for all odd k ≥ 9
(cid:88)

i≤k/2−√

(cid:88)

(cid:18)k

k ≥ γ

(cid:0)k

√

(2)
(3)
k after
k ≤ 1/4 which follows
k and thus we have

√

√

√

√

2γ

k

i

k

2

√
k
50 .

1
2k

i

i<k/2

2k

i<k/2−√

k

i

2.2 Proof of Lemma 1

Throughout the following discussion it will be convenient to view angles between vectors as lying
the range [−π  π)  so acute angles are in the range (−π/2  π/2).
Recall that sign(w·x) is the unknown target halfspace (we assume w is a unit vector) and v1  . . .   vk
are the random unit vectors generated by algorithm Ak. For j ∈ {1  . . .   k} let Gj denote the
“good” event that the angle between vj and w is acute  i.e. lies in the interval (−π/2  π/2)  and
let G denote the event G1 ∧ ··· ∧ Gk. Since the vectors vi are selected independently we have

Pr[G] =(cid:81)k

j=1 Pr[Gj] = 2−k.

√
k
50π .

The following claim shows that conditioned on G  any γ-margin point has a noticeably-better-than-
2 chance of being classiﬁed correctly by H (note that the probability below is over the random
1
generation of H by Ak):
Claim 3 Fix x ∈ Bn to be any point such that |w·x| ≥ γ. Then we have PrH[H(x) (cid:54)= f(x) | G] ≤
vote(γ/π  k) ≤ 1/2 − γ
Proof: Without loss of generality we assume that x is a positive example (an entirely similar analysis
goes through for negative examples)  so w · x ≥ γ. Let α denote the angle from w to x in the plane
spanned by w and x; again without loss of generality we may assume that α lies in [0  π/2] (the
case of negative angles is symmetric). In fact since x is a positive example with margin γ  we have
that 0 ≤ α ≤ π/2 − γ.
Fix any j ∈ {1  . . .   k} and let us consider the random unit vector vj. Let v(cid:48)
j be the projection of
j|| is uniform on the unit circle
vj onto the plane spanned by x and w. The distribution of v(cid:48)
in that plane. We have that sign(vj · x) (cid:54)= f(x) if and only if the magnitude of the angle between
v(cid:48)
j and x is at least π/2. Conditioned on Gj  the angle from v(cid:48) to w is uniformly distributed over
the interval (−π/2  π/2). Since the angle from w to x is α  the angle from v(cid:48) to x is the sum of
the angle from v(cid:48) to w and the angle from w to x  and therefore it is uniformly distributed over the
interval (−π/2 + α  π/2 + α) . Recalling that α ≥ 0  we have that sign(vj · x) (cid:54)= f(x) if and only
if angle from v(cid:48) to x lies in (π/2  π/2 + α). Since the margin condition implies α ≤ π/2 − γ as
noted above  we have Pr[sign(vj · x) (cid:54)= f(x) | Gj] ≤ π/2−γ
Now recall that v1  ...  vk are chosen independently at random  and G = G1 ∧ ··· ∧ Gk. Thus  after
conditioning on G  we have that v1  ...  vk are still independent and the events sign(v1 · x) (cid:54)=
f(x)  . . .   sign(vk · x) (cid:54)= f(x) are independent.
It follows that PrH[H(x) (cid:54)= f(x) | G] ≤

2 − γ
π .

π = 1

j/||v(cid:48)

√
50π   where we used Lemma 2 for the ﬁnal inequality.

k

vote(cid:0) γ

π   k(cid:1) ≤ 1/2 − γ

Now all the ingredients are in place for us to prove Lemma 1. Since Claim 3 may be applied to
√
every x in the support of D  we have Prx∼D H[H(x) (cid:54)= f(x) | G] ≤ 1/2− γ
50π . Applying Fubini’s

k

4

(cid:34)

√
theorem we get that EH[Prx∼D[H(x) (cid:54)= f(x)] | G] ≤ 1/2 − γ
50π . Applying Markov’s inequality
to the nonnegative random variable Prx∼D[H(x) (cid:54)= f(x)]  we get
≤ 2(1/2 − γ
1 − γ
(cid:35)

[H(x) (cid:54)= f(x)] >

√
50π )
√
k
50π

1 − γ
k
50π
2

which implies

Pr
x∼D

| G

(cid:35)

Pr
H

k

 

√

k

Since PrH[G] = 2−k we get

Pr

(cid:34)
x∼D[H(x) (cid:54)= f(x)] ≤ 1 − γ
(cid:34)
x∼D[H(x) (cid:54)= f(x)] ≤ 1 − γ

Pr

√

k
50π
2

√

k
50π
2

Pr
H

Pr
H

√

| G

≥ Ω(γ

k).

(cid:35)

√

≥ Ω(γ

k/2k) 

and Lemma 1 is proved.

3 Proof of Theorem 1: smooth boosting the weak learner to tolerate

malicious noise

Our overall algorithm for learning γ-margin halfspaces with malicious noise  which we call Algo-
rithm B  combines a weak learner derived from Section 2 with a “smooth” boosting algorithm.
Recall that boosting algorithms [15  25] work by repeatedly running a weak learner on a se-
quence of carefully crafted distributions over labeled examples. Given the initial distribution P
over labeled examples (x  y)  a distribution Pi over labeled examples is said to be κ-smooth if
Pi[(x  y)] ≤ 1
κ P [(x  y)] for every (x  y) in the support of P. Several boosting algorithms are known
[9  16  28] that generate only 1/ε-smooth distributions when boosting to ﬁnal accuracy 1 − ε. For
concreteness we will use the MadaBoost algorithm of [9]  which generates a (1 − ε)-accurate ﬁnal
hypothesis after O( 1

εγ2 ) stages of calling the weak learner and runs in time poly( 1

ε   1

γ ).

At a high level our analysis here is related to previous works [28  22] that used smooth boosting to
tolerate malicious noise. The basic idea is that since a smooth booster does not increase the weight
of any example by more than a 1/ε factor  it cannot “amplify” the malicious noise rate by more
than this factor. In [28] the weak learner only achieved advantage O(γ) so as long as the malicious
noise rate was initially O(εγ)  the “ampliﬁed” malicious noise rate of O(γ) could not completely
“overcome” the advantage and boosting could proceed successfully. Here we have a weak learner
that achieves a higher advantage  so boosting can proceed successfully in the presence of more
malicious noise. The rest of this section provides details.
The weak learner W that B uses is a slight extension of algorithm Ak from Section 2 with k =
(cid:100)log(1/γ)(cid:101). When invoked with distribution Pt over labeled examples  algorithm W

• makes (cid:96) (speciﬁed later) calls to algorithm A(cid:100)log(1/γ)(cid:101)  generating candidate hypotheses
• evaluates H1  ...  H(cid:96) using M (speciﬁed later) independent examples drawn from Pt and

H1  ...  H(cid:96); and

outputs the Hj that makes the fewest errors on these examples.

The overall algorithm B

ples sufﬁce) from EXη(f D);

• draws a multiset S of m examples (we will argue later that poly(n  1/γ  1/ε) many exam-
• sets the initial distribution P over labeled examples to be uniform over S; and
• uses MadaBoost to boost to accuracy 1− /4 with respect to P   using W as a weak learner.

Recall that we are assuming η ≤ cεγ(cid:112)log(1/γ); we will show that under this assumption  algorithm

B outputs a ﬁnal hypothesis h that satisﬁes Prx∼D[h(x) = f(x)] ≥ 1 − ε with probability at least
1/2.

5

1/2 + Θ(γ(cid:112)log(1/γ)). MadaBoost’s boosting guarantee then implies that the ﬁnal hypothesis (call

First  let SN ⊆ S denote the noisy examples in S. A standard Chernoff bound [10] implies that
with probability at least 5/6 we have |SN|/|S| ≤ 2η; we henceforth write η(cid:48) to denote |SN|/|S|.
We will show below that with high probability  every time MadaBoost calls the weak learner W
with a distribution Pt  W generates a weak hypothesis (call it ht) that has Pr(x y)∼Pt[ht(x) = y] ≥
it h) of Algorithm B satisﬁes Pr(x y)∼P [h(x) = y] ≥ 1− ε/4. Since h is correct on (1− ε/4) of the
points in the sample S and η(cid:48) ≤ 2η  h must be correct on at least 1 − ε/4 − 2η of the points in S \
SN   which is a noise-free sample of poly(n  1/γ  1/ε) labeled examples generated according to D.
Since h belongs to a class of hypotheses with VC dimension at most poly(n  1/γ  1/) (because the
analysis of MadaBoost implies that h is a weighted vote over O(1/(εγ2)) many weak hypotheses 
and each weak hypothesis is a vote over O(log(1/γ)) n-dimensional halfspaces)  by standard sample
complexity bounds [4  31  29]  with probability 5/6  the accuracy of h with respect to D is at least
1 − ε/2 − 4η > 1 − ε  as desired.
Thus it remains to show that with high probability each time W is called on a distribution Pt  it

indeed generates a weak hypothesis with advantage at least Ω(γ(cid:112)log(1/γ)). Recall the following:

Deﬁnition 1 The total variation distance between distributions P and Q over ﬁnite domain X is
dT V (P  Q) := maxE⊆X P [E] − Q[E].
Suppose R is the uniform distribution over the noisy points SN ⊆ S  and P (cid:48) is the uniform distri-
bution over the remaining points S \ SN (we may view P (cid:48) as the “clean” version of P ). Then
the distribution P may be written as P = (1 − η(cid:48))P (cid:48) + η(cid:48)R  and for any event E we have
P [E] − P (cid:48)[E] ≤ η(cid:48)R[E] ≤ η(cid:48)  so dT V (P  P (cid:48)) ≤ η(cid:48).
Let Pt denote the distribution generated by MadaBoost during boosting stage t. The smoothness of
MadaBoost implies that Pt[SN ] ≤ 4η(cid:48)/  so the noisy examples have total probability at most 4η(cid:48)/ε
under Pt. Arguing as for the original distribution  we have that the clean version P (cid:48)
t of Pt satisﬁes
(4)

t   Pt) ≤ 4η(cid:48)/.

dT V (P (cid:48)

Pr
g

[errorP (cid:48)

t

By Lemma 1  each call to algorithm A(cid:100)log(1/γ)(cid:101) yields a hypothesis (call it g) that satisﬁes

where for any distribution Q we deﬁne errorQ(g) def= Pr(x y)∼Q[g(x) (cid:54)= y]. Recalling that η(cid:48) ≤ 2η

(g) ≤ 1/2 − γ(cid:112)log(1/γ)/(100π)] ≥ Ω(γ2) 
and η < cεγ(cid:112)log(1/γ)  for a suitably small absolute constant c > 0 we have that
Then (4) and (5) imply that Prg[errorPt(g) ≤ 1/2 − 3γ(cid:112)log(1/γ)/(400π)] ≥ Ω(γ2). This means
W selects from its (cid:96) calls to A in that stage will satisfy errorPt(gt) ≤ 1/2 − γ(cid:112)log(1/γ)/(200π).

that by taking the parameters (cid:96) and M of the weak learner W to be poly(1/γ  log(1/ε))  we can en-
sure that with overall probability at least 2/3  at each stage t of boosting the weak hypothesis ht that

4η(cid:48)/ε < γ(cid:112)log(1/γ)/(400π).

(5)

(6)

This concludes the proof of Theorem 1.

4 Convex optimization algorithms have limited malicious noise tolerance
Given a sample S = {(x1  y1)  . . .   (xm  ym)} of labeled examples  the number of examples mis-
classiﬁed by the hypothesis sign(v · x) is a nonconvex function of v  and thus it can be difﬁcult to
ﬁnd a v that minimizes this error (see [12  18] for theoretical results that support this intuition in
various settings). In an effort to bring the powerful tools of convex optimization to bear on various
halfspace learning problems  a widely used approach is to instead minimize some convex proxy for
misclassiﬁcation error.
Deﬁnition 2 will deﬁne the class of such algorithms analyzed in this section. This deﬁnition allows
algorithms to use regularization  but by setting the regularizer ψ to be the all-0 function it also covers
algorithms that do not.

6

regularizer if ψ(v) =(cid:80)n
loss of vector v on S is Lφ ψ S(v) := ψ(v)+(cid:80)m

Deﬁnition 2 A function φ : R → R+ is a convex misclassiﬁcation proxy if φ is convex  nonin-
creasing  differentiable  and satisﬁes φ(cid:48)(0) < 0. A function ψ : Rn → [0 ∞) is a componentwise
i=1 τ(vi) for a convex  differentiable τ : R → [0 ∞) for which τ(0) = 0.
Given a sample of labeled examples S = {(x1  y1)  . . .   (xm  ym)} ∈ (Rn ×{−1  1})m  the (φ ψ)-
i=1 φ(y(v· xi)). A (φ ψ)-minimizer is any learning
algorithm that minimizes Lφ ψ S(v) whenever the minimum exists.

Our main negative result  shows that for any sample size  algorithms that minimize a regularized
convex proxy for misclassiﬁcation error will succeed with exponentially small probability for a
malicious noise rate that is Θ(εγ)  and therefore for any larger malicious noise rate.

Theorem 2 Fix φ to be any convex misclassiﬁcation proxy and ψ to be any componentwise reg-
ularizer  and let algorithm A be a (φ ψ)-minimizer. Fix ε ∈ (0  1/8] to be any error parameter 
γ ∈ (0  1/8] to be any margin parameter  and m ≥ 1 to be any sample size. Let the malicious noise
rate η be 16εγ.
Then there is an n  a target halfspace f(x) = sign(w · x) over Rn  a γ-margin distribution D for f
(supported on points x ∈ Bn that have | w(cid:107)w(cid:107) ·x| ≥ γ)  and a malicious adversary with the following
property: If Aφ is given m random examples drawn from EXη(f D) and outputs a vector v  then
the probability (over the draws from EXη(f D)) that v satisﬁes Prx∼D[sign(v · x) (cid:54)= f(x)] ≤ ε is
at most e−c/γ  where c > 0 is some universal constant.

Proof: The analysis has two cases based on whether or not the number of examples m exceeds
m0 := 1
32γ2 . (We emphasize that Case 2  in which n is taken to be just 2  is the case that is of
primary interest  since in Case 1 the algorithm does not have enough examples to reliably learn a
γ-margin halfspace even in a noiseless scenario.)
Case 1 (m ≤ m0): Let n = (cid:98)1/γ2(cid:99) and let e(i) ∈ Rn denote the unit vector with a 1 in the ith
component. Then the set of examples E := {e(1)  ...  e(n)} is shattered by the family F which con-
sists of all 2n halfspaces whose weight vectors are in {−γ  γ}n  and any distribution whose support
is E is a γ-margin distribution for any such halfspace. The proof of the well-known information-
theoretic lower bound of [11]1 gives that for any learning algorithm that uses m examples (such as
A)  there is a distribution D supported on E and a halfspace f ∈ F such that the output h of A
satisﬁes Pr[Prx∼D[h(x) (cid:54)= f(x)] > ] ≥ 1 − exp
  where the outer probability is over the
random examples drawn by A. This proves the theorem in Case 1.
Case 2 (m > m0): We note that it is well known (see e.g. [31]) that O( 1
εγ2 ) examples sufﬁce to
learn γ-margin n-dimensional halfspaces for any n if there is no noise  so noisy examples will play
an important role in the construction in this case.

We take n = 2. The target halfspace is f(x) = sign((cid:112)1 − γ2x1 + γx2). The distribution D is very

(cid:16)− c

(cid:17)

γ2

simple and is supported on only two points: it puts weight 2 on the point
which is a
positive example for f  and weight 1 − 2 on the point (0  1) which is also a positive example for
f. When the malicious adversary is allowed to corrupt an example  with probability 1/2 it provides
the point (1  0) and mislabels it as negative  and with probability 1/2 it provides the point (0  1) and
mislabels it as negative.
Let S = ((x1  y1)  ...  (xm  ym)) be a sample of m examples drawn from EXη(f D). We de-
  and ηS 2 :=
ﬁne pS 1 :=

  pS 2 := |{t:xt=(0 1) y=1}|

  ηS 1 := |{t:xt=(1 0)}|

”o˛˛˛

1−γ2 0

˛˛˛n

t:xt=

γ/

“

√
|S|

|S|

|S|

(cid:18)

(cid:19)

γ√
1−γ2   0

1In particular  see the last displayed equation in the proof of Lemma 3 of [11].

7

|{t:xt=(0 1) y=−1}|

. Using standard Chernoff bounds (see e.g. [10]) and a union bound we get

|S|
Pr[pS 1 = 0 or pS 2 = 0 or pS 1 > 3 or ηS 1 < η/4 or ηS 2 < η/4]

≤ (1 − 2ε(1 − η))m + (1 − (1 − 2ε)(1 − η))m + exp
≤ 2(1 − ε)m + exp
≤ 2 exp

(cid:16)− m
(cid:17)
(cid:18)
+ 2 exp
− 1
96γ2

(cid:16)− ηm
(cid:19)

(cid:18)
− 1
48γ

− 1
32γ2

+ 2 exp

+ exp

(cid:19)

(cid:18)

(cid:17)

12

24

(cid:17)

(cid:16)− ηm

24

+ 2 exp

(since  ≤ 1/4 and η ≤ 1/2)

(cid:17)

(cid:16)− m
(cid:19)

12

.

Since the theorem allows for a e−c/γ success probability for A  it sufﬁces to consider the case in
which pS 1 and pS 2 are both positive  pS 1 ≤ 3  and min{ηS 1  ηS 2} ≥ η/4. For v = (v1  v2) ∈
R2 the value Lφ ψ S(v) is proportional to

L(v1  v2) := pS 1φ

+ pS 2φ(v2) + ηS 1φ(−v1) + ηS 2φ(−v2) + ψ(v)
|S| .

(cid:33)

(cid:32)

γv1(cid:112)1 − γ2

(cid:32)

From the bounds stated above on pS 1  pS 2  ηS 1 and ηS 2 we may conclude that Lφ ψ S(v) does
achieve a minimum value. This is because for any z ∈ R the set {v : Lφ ψ S(v) ≤ z} is bounded 
and therefore so is its closure. Since Lφ ψ S(v) is bounded below by zero and is continuous  this
implies that it has a minimum. To see that for any z ∈ R the set {v : Lφ ψ S(v) ≤ z} is bounded 
observe that if either v1 or v2 is ﬁxed and the other one is allowed to take on arbitrarily large
magnitude values (either positive or negative)  this causes Lφ ψ S(v) to take on arbitrarily large
positive values (this is an easy consequence of the deﬁnition of L  the fact that φ is convex  non-
negative and nonincreasing  φ(cid:48)(0) < 0  and the fact that pS 1  pS 2  ηS 1  ηS 2 are all positive).
Taking the derivative with respect to v1 yields

γv1(cid:112)1 − γ2
φ(cid:48)
(7)
γ√
1−γ2 φ(cid:48)(0) − ηS 1φ(cid:48)(0) (recall that τ is minimized at 0 and
When v1 = 0  the derivative (7) is pS 1
γ√
thus τ(cid:48)(0) = 0). Recall that φ(cid:48)(0) < 0 by assumption. If pS 1
1−γ2 < ηS 1 then (7) is positive at
0  which means that L(v1  v2) is an increasing function of v1 at v1 = 0 for all v2. Since L is convex 
this means that for each v2 ∈ R we have that the value v(cid:63)
1  v2) is a negative
γ√
1−γ2 < ηS 1  the linear classiﬁer v output by Aφ has v1 ≤ 0; hence it
1 < 0. So  if pS 1
value v(cid:63)
γ√
1−γ2   0)  and thus has error rate at least 2 with respect to D.
misclassiﬁes the point (
Combining the fact that γ ≤ 1/8 with the facts that pS 1 ≤ 3 and ηS 1 > η/4  we get pS 1
1.01 × pS 1γ < 4γ = η/4 < ηS 1 which completes the proof.

− ηS 1φ(cid:48)(−v1) − τ(cid:48)(v1)
|S|

γ(cid:112)1 − γ2

1 that minimizes L(v(cid:63)

γ√
1−γ2 <

∂L
∂v1

= pS 1

(cid:33)

.

5 Conclusion

It would be interesting to further improve on the malicious noise tolerance of efﬁcient algorithms
for PAC learning γ-margin halfspaces  or to establish computational hardness results for this prob-
lem. Another goal for future work is to develop an algorithm that matches the noise tolerance of
Theorem 1 but uses a single halfspace as its hypothesis representation.

References
[1] J. Aslam and S. Decatur. Speciﬁcation and simulation of statistical query algorithms for efﬁciency and

noise tolerance. Journal of Computer and System Sciences  56:191–208  1998.

[2] P. Auer. Learning nested differences in the presence of malicious noise. Theor. Comp. Sci.  185(1):159–

175  1997.

[3] P. Auer and N. Cesa-Bianchi. On-line learning with malicious noise and the closure algorithm. Annals of

Mathematics and Artiﬁcial Intelligence  23:83–99  1998.

8

[4] E. B. Baum and D. Haussler. What size net gives valid generalization? Neural Comput.  1:151–160 

1989.

[5] H. Block. The Perceptron: a model for brain functioning. Reviews of Modern Physics  34:123–135  1962.
[6] A. Blum. Random Projection  Margins  Kernels  and Feature-Selection. In LNCS Volume 3940  pages

52–68  2006.

[7] A. Blum and M.-F. Balcan. A discriminative model for semi-supervised learning. Journal of the ACM 

57(3)  2010.

[8] S. Decatur. Statistical queries and faulty PAC oracles. In Proc. 6th COLT  pages 262–268  1993.
[9] C. Domingo and O. Watanabe. MadaBoost: a modiﬁed version of AdaBoost. In Proc. 13th COLT  pages

180–189  2000.

[10] D. Dubhashi and A. Panconesi. Concentration of measure for the analysis of randomized algorithms.

Cambridge University Press  Cambridge  2009.

[11] A. Ehrenfeucht  D. Haussler  M. Kearns  and L. Valiant. A general lower bound on the number of exam-

ples needed for learning. Information and Computation  82(3):247–251  1989.

[12] V. Feldman  P. Gopalan  S. Khot  and A. Ponnuswami. On agnostic learning of parities  monomials  and

halfspaces. SIAM J. Comput.  39(2):606–645  2009.

[13] W. Feller. Generalization of a probability limit theorem of Cram´er. Trans. Am. Math. Soc.  54:361–372 

1943.

[14] Y. Freund and R. Schapire. Large margin classiﬁcation using the Perceptron algorithm. In Proc. 11th

COLT  pages 209–217.  1998.

[15] Y. Freund and R. Schapire. A short introduction to boosting. J. Japan. Soc. Artif. Intel.  14(5):771–780 

1999.

[16] D. Gavinsky. Optimally-smooth adaptive boosting and application to agnostic learning. JMLR  4:101–

117  2003.

[17] C. Gentile and N. Littlestone. The robustness of the p-norm algorithms. In Proc. 12th COLT  pages 1–11 

1999.

[18] V. Guruswami and P. Raghavendra. Hardness of learning halfspaces with noise. SIAM J. Comput. 

39(2):742–765  2009.

[19] D. Haussler  M. Kearns  N. Littlestone  and M. Warmuth. Equivalence of models for polynomial learn-

ability. Information and Computation  95(2):129–161  1991.

[20] M. Kearns and M. Li. Learning in the presence of malicious errors. SIAM Journal on Computing 

22(4):807–837  1993.

[21] R. Khardon and G. Wachman. Noise tolerant variants of the perceptron algorithm. JMLR  8:227–248 

2007.

[22] A. Klivans  P. Long  and R. Servedio. Learning Halfspaces with Malicious Noise. JMLR  10:2715–2740 

2009.

[23] P. Long and R. Servedio. Random classiﬁcation noise defeats all convex potential boosters. Machine

Learning  78(3):287–304  2010.

[24] Y. Mansour and M. Parnas. Learning conjunctions with noise under product distributions. Information

Processing Letters  68(4):189–196  1998.

[25] R. Meir and G. R¨atsch. An introduction to boosting and leveraging.

Machine Learning  pages 118–183  2003.

In LNAI Advanced Lectures on

[26] A. Novikoff. On convergence proofs on perceptrons. In Proceedings of the Symposium on Mathematical

Theory of Automata  volume XII  pages 615–622  1962.

[27] F. Rosenblatt. The Perceptron: a probabilistic model for information storage and organization in the brain.

Psychological Review  65:386–407  1958.

[28] R. Servedio. Smooth boosting and learning with malicious noise. JMLR  4:633–648  2003.
[29] J. Shawe-Taylor  P. Bartlett  R. Williamson  and M. Anthony. Structural risk minimization over data-

dependent hierarchies. IEEE Transactions on Information Theory  44(5):1926–1940  1998.
[30] L. Valiant. Learning disjunctions of conjunctions. In Proc. 9th IJCAI  pages 560–566  1985.
[31] V. Vapnik. Statistical Learning Theory. Wiley-Interscience  New York  1998.

9

,Yao-Liang Yu
Chris Oates
Steven Niederer
Angela Lee
François-Xavier Briol
Mark Girolami
Vladimir Kniaz
Vladimir Knyaz
Fabio Remondino