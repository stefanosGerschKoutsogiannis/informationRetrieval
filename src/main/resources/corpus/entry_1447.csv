2018,Designing by Training: Acceleration Neural Network for Fast High-Dimensional Convolution,The high-dimensional convolution is widely used in various disciplines but has a serious performance problem due to its high computational complexity. Over the decades  people took a handmade approach to design fast algorithms for the Gaussian convolution. Recently  requirements for various non-Gaussian convolutions have emerged and are continuously getting higher. However  the handmade acceleration approach is no longer feasible for so many different convolutions since it is a time-consuming and painstaking job. Instead  we propose an Acceleration Network (AccNet) which turns the work of designing new fast algorithms to training the AccNet. This is done by: 1  interpreting splatting  blurring  slicing operations as convolutions; 2  turning these convolutions to $g$CP layers to build AccNet. After training   the activation function $g$ together with AccNet weights automatically define the new splatting  blurring and slicing operations. Experiments demonstrate AccNet is able to design acceleration algorithms for a ton of convolutions including Gaussian/non-Gaussian convolutions and produce state-of-the-art results.,Designing by Training: Acceleration Neural Network

for Fast High-Dimensional Convolution

Longquan Dai

Liang Tang

School of Computer Science and Engineering
Nanjing University of Science and Technology

CASA Environmental Technology Co.  Ltd

CASA EM&EW IOT Research Center

dailongquan@njust.edu.cn

tangl@casaet.com

Yuan Xie

Institute of Automation

Chinese Academy of Sciences

yuan.xie@ia.ac.cn

Jinhui Tang∗

School of Computer Science and Engineering
Nanjing University of Science and Technology

jinhuitang@njust.edu.cn

Abstract

The high-dimensional convolution is widely used in various disciplines but has a
serious performance problem due to its high computational complexity. Over the
decades  people took a handmade approach to design fast algorithms for the Gaus-
sian convolution. Recently  requirements for various non-Gaussian convolutions
have emerged and are continuously getting higher. However  the handmade acceler-
ation approach is no longer feasible for so many different convolutions since it is a
time-consuming and painstaking job. Instead  we propose an Acceleration Network
(AccNet) which turns the work of designing new fast algorithms to training the
AccNet. This is done by: 1  interpreting splatting  blurring  slicing operations as
convolutions; 2  turning these convolutions to gCP layers to build AccNet. After
training  the activation function g together with AccNet weights automatically
deﬁne the new splatting  blurring and slicing operations. Experiments demonstrate
AccNet is able to design acceleration algorithms for a ton of convolutions including
Gaussian/non-Gaussian convolutions and produce state-of-the-art results.

1

Introduction

The high-dimensional convolution undoubtedly is a common and elementary computation unit in
machine learning  computer vision and computer graphics. Krähenbühl and Koltun [2011] conducted
efﬁcient message passing in the fully connected CRFs inference by the high-dimensional Gaussian
convolution. Elboer et al. [2013] expressed the generalized Laplacian distance for visual matching as
cascaded convolutions. Paris and Durand [2009] converted the bilateral ﬁlter [Tomasi and Manduchi 
1998] into convolution in an elevated high-dimensional space. However  the computational complexity
for a d-D convolution (1) is proportional to rd  where r denotes the radius of the box ﬁltering window
Ω  Kpq represents the weight between p and q  I p and I(cid:48)
p are the values of input I and output I(cid:48)
at p. Therefore the running cost will become unacceptable for large r or d.

I(cid:48)
p = (K ∗ I)p =

KpqI q

(1)

(cid:88)

q∈Ωp

A lot of work was devoted to solving the computational shortcoming. But most of them focus on the
Gaussian ﬁltering. This is because not only the Gaussian convolution itself serves as building blocks

∗Corresponding Author.

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

for many algorithms [Baek and Jacobs  2010  Yang et al.  2015] but also its acceleration approaches
play important roles in defocus [Barron et al.  2015]  segmentation [Gadde et al.  2016]  edge-aware
smoothing [Barron and Poole  2016]  video propagation [Jampani et al.  2017].
In the literature  the most popular Gaussian blur acceleration algorithm should be the Splatting-
Blurring-Slicing pipeline (SBS)  which is ﬁrst proposed by Paris and Durand [2006]  Adams et al.
[2010] coined its current name. We attribute its success to data reduction and separable blurring. In
SBS  pixels are “splatted”(downsampled) onto the grid to reduce the data size  then those vertexes
are blurred  ﬁnally the ﬁltered values for each pixel are produced via “slicing”(upsampling). Due to
the separable blurring kernel  the d-D Gaussian blurring performed on those vertexes can be deemed
as a sum of separable 1-D ﬁlters [Szeliski  2011] and therefore the computational complexity per
pixel is reduced from O(rd) to O(rd). As the ﬁltering window becomes small after splatting  the
computational complexity can be roughly viewed as O(d) which is irrelevant to the radius r.
According to our investigation SBS has two problems: 1  how to approximate non-Gaussian blur?
SBS is designed for the Gaussian convolution. However  the requirements for non-Gaussian blurs
emerge from local Laplacian ﬁltering [Aubry et al.  2014] and mean-ﬁeld inference [Vineet et al. 
2014] recently. 2  how to improve the approximation error? Previous SBS based methods just claim
that their results are good approximations for the Gaussian ﬁltering and prove this by experiments.
Since current SBS has drawbacks  how can we generalize SBS to get a better result?
We recast SBS as a neural network (AccNet) to address above two problems in this paper. The
beneﬁts are threefold: 1  our AccNet offers a uniﬁed perspective for SBS based acceleration methods;
2  the layer weights together with the activation function g deﬁne the splatting  blurring and slicing
convolution. So we can easily derive new splatting  blurring and slicing operations from the trained
network for arbitrary convolutions. This ability entitles our network the End-to-End feature; 3  the
optimal approximation error is guaranteed by AccNet in training.

2 Related Work

Few papers discussed acceleration algorithms for general high-dimensional convolution. Szeliski
[2011] recorded a separable ﬁltering method by SVD. Extending SVD to high-dimensional cases 
we can generalize the separable ﬁltering to high-dimensional convolution. In bilateral ﬁltering
literatures [Chaudhury and Dabhade  2016  Dai et al.  2016]  shiftable functions are exploited to
approximate 1-D range kernels. This technique can also be extended to high-dimensional cases via
outer product. However  its approximation terms are same as the separable ﬁltering method and will
exponentially increase with the dimension.
Current interest for fast high-dimensional convolution algorithms limits to Gaussian blur. Greengard
and Strain [1991] provided the ﬁrst fast Gaussian blur algorithm. Since the inception of the bilateral
ﬁlter (BF) [Tomasi and Manduchi  1998]  the study for fast Gaussian convolution emerges in computer
vision and computer graphics. Durand and Dorsey [2002] computed intermediate ﬁltered images and
synthesized ﬁnal results by interpolation. The same approach was adopted by Porikli [2008] and
Yang et al. [2009]. Paris and Durand [2006] implemented the ﬁrst SBS which hints at more general
approaches (bilateral grid and permutohedral lattice).
The bilateral grid [Chen et al.  2007] is a dense data structure that voxelizes the input space into a
regular hypercubic lattice. By embedding inputs within the discretized space (splatting)  they mix the
values with a conventional Gaussian blur (blurring). The output image is extracted by resampling
back into image space (slicing). The permutohedral lattice [Adams et al.  2010] is a sparse lattice that
tessellates the space with simplices. By exploiting the fact that the number of vertices in a simplex
grows slowly  it avoids the exponential growth of runtime that the bilateral grid suffers.

3 Design by Training for Fast High-Dimensional Convolution

Different from traditional output-focused neural networks  our AccNet implements the design-by-
training strategy to automatically produce fast convolution pipeline and thus only interests in the
activation function and weights as they deﬁne new splatting  blurring and slicing operations. In the
following sections  we discuss how to transform the SBS into an AccNet as well as extensions for
AccNets.

2

(a) Splatting

(b) Blurring

(c) Slicing

Figure 1: The splatting-blurring-slicing pipeline demonstration for bilateral grid and permutohedral
lattice. The bilateral grid accumulates input values on a grid and factors the Gaussian-weighted gather
into a separable Gaussian blur followed by multilinear sampling. The permutohedral lattice operates
uses the permutohedral lattice. Barycentric weights within each simplex are used to resample into
and out of the lattice. The separable blur is conducted along each axis.

3.1 Splatting  Blurring and Slicing Operations as Convolutions

Splatting voxelizes the space into a regular lattice and embeds inputs within the discretized vertices
of the lattice to reduce the data size. Figure 1a illustrates the splatting operation of both bilateral
grid and permutohedral lattice. The bilateral grid acceleration method trades accuracy for speed by
accumulating constant values. The permutohedral lattice acceleration algorithm uses barycentric
weights within each simplex to resample into the lattice. So the value of each vertice is the weighted
sum of its nearby inputs. That is to say  the splatting operation conducts convolutions with a stride of
s. Here s denotes the interval of lattice vertices.
Slicing as illustrated in Figure 1c is the inverse operation of splatting. SBS employs it to synthesize
ﬁltering results from the smoothed lattice values. The bilateral grid method does this by trilinear
interpolation and the permutohedral lattice algorithm takes barycentric weights to resample out of
the lattice. Since the slicing values are the weighted sum of neighbor vertices  the slicing operation
equals to the convolution operation. Intuitively  slicing behaves as the deconvolution layer of the fully
convolutional network [Shelhamer et al.  2017] which performs upsampling by convolution.
Blurring is an alias of convolution. In the d-D case  the full kernel implementation for a convolution
requires rd (multiply-add) operations per pixel  where r is the radius of the convolution kernel.
This operation can be sped up by sequentially performing 1-D convolutions along each axis (which
requires a total of dr operations per pixel) if the kernel is separable. Mathematically  a separable

K = k1 ◦ k2 ··· ◦ kd
I(cid:48) = K ∗ I = k1 ∗ k2 ··· kd ∗ I

(2)
(3)
kernel K is the rank-one tensor (the outer product of d vectors {kn  n = 1  . . .   d} (2)). Then the
convolution with K becomes (3). For arbitrary kernels  we can reformulate it as the sum of rank-one
tensors by Canonical Polyadic (CP) decomposition [Sidiropoulos et al.  2017]. In this way  we have
(4) and the computational complexity per pixel for the d-D case becomes O(N dr). Note that the

wi · ki

1 ∗ ki

2 ··· ∗ ki

d ∗ I

smoothing window usually is small after splatting  the computational complexity can be viewed as
O(N d) which is irrelevant to r.

i=1

3

N(cid:88)

K =

wi ◦ ki

2 ··· ◦ ki

d

1 ◦ ki
N(cid:88)

i=1

I(cid:48) = K ∗ I =

(4)

(5)

Bilateral GridPermutohedralLattice(a) gCP layer

(b) Cascaded gCP layers

(c) AccNet

Figure 2: Demonstration for gCP layer  cascaded gCP layers and AccNet. The inputs of (a) (b) are
matrices formed by [lpi
d ] (refer to section 3.2.2) and their outputs are scalars. The color cube
in (c) stands for Lj (refer to section 3.2.4) and the color slice in the cube represents Lj
pi  where the
outputs of (a)(b)(c) are scalars  the stripes in (a)(b) and the slices in (c) with the same color present
the input-output relationship.

1   . . .   lpi

3.2 Design by Training Acceleration Network (AccNet)

Essentially  our design-by-training approach is to decompose the ﬁltering kernel (a tensor) by neural
networks because a convolution can be fast computed according to (5) once (4) is obtained. In both
equations  basic building blocks are multiplication and addition. If one of them is substituted by other
operations  we obtain new CP decomposition (4) and separable convolution (5). That is to say  we get
new kinds of splatting  blurring and slicing operations. In this section we follow the way of Cohen
and Shashua [2016] to generalize (4) to gCP decomposition and provide corresponding g-convolution.
The gCP layer and cascaded gCP layers are proposed for gCT and gHT decompositions.

3.2.1 gCP (g Canonical Polyadic) Decomposition & g-Convolution

In (4) each element Kj1 j2 ... jd is formulated as (cid:80)N
can be generalized by deﬁning Kj1 j2 ... jd =(cid:80)N

··· ki
. Assuming the
activation function g : R × R → R denotes multiplication  we have ki
ki
=
  where a ×g b = g(a  b) = ab. Let g be an activation function
ki
such that ∀a  b  c ∈ R : g(g(a  b)  c) = g(a  g(b  c))  g(a  b) = g(b  a)  the tensor decomposition (4)
. So we have gCP
decomposition (6)  where ◦g denotes the generalized outer product by replacing multiplication with
the activation function g.

i=1 wi ×g ki

×g ··· ×g ki

×g ··· ×g ki

i=1 wiki

×g ki

··· ki

1 j1

2 j2

ki

1 j1

2 j2

d jd

1 j1

2 j2

d jd

d jd

1 j1

d jd

Further  we substitute g for multiplication in (1) and obtain the g-convolution (7).

I(cid:48)
p = (K ∗g I)p =

Kpq ×g I q

Applying (6) to (7)  we get (8) which sequentially performs N 1-D g-convolutions.

I(cid:48) = K ∗g I =

wi ×g ki

1 ∗g ki

2 ··· ∗g ki

d ∗g I

i=1

gCP Layer as gCP Decomposition

3.2.2
Kpq and I q in (7) form two d-order tensors. Taking ˆK and ˆI to denote them and putting (6) into (8) 
j=1 lj vj = lj v1 ×g lj v2 ×g ···×g lj vd
into (9)  we obtain (10) which is consisted of three operations: 1  the g-afﬁne mapping (g-aff mapping)
j=1; 3 
i=1 wi. The activation function g introduces

we have (9). Letting lj be a vector and putting ˆI v1 ... vd =(cid:81)d
deﬁned by(cid:80)
the weighted average pooling (g-avg pooling) given by(cid:80)N

j v ×g lj v; 2  the g-multiplication pooling (g-mul pooling) described by(cid:81)d

v ki

4

K =

wi ×g ki

2 ··· ◦g ki

d

N(cid:88)

i=1

N(cid:88)

1 ◦g ki
(cid:88)

q∈Ωp

(6)

(7)

(8)

g-avg poolingg-mul poolinginputoutputg-aff mappingg-mul poolingg-mul poolingg-avg poolingoutputg-aff mappingg-aff mappinginputg-conv mappingg-aff mappingg-mul poolingg-aff mappingg-mul poolingg-avg poolingg-conv mappingsumSplattingBlurringSlicingp = (K ∗g I)p =
I(cid:48)
N(cid:88)
N(cid:88)

(cid:88)
ˆI(cid:48)
p =

v1 ... vd

i=1

=

wi ×g

wi ×g

j1 ... jd

(cid:88)
ˆKj1 ... jd ×g ˆI j1 ... jd
d(cid:89)
(cid:88)
d(cid:89)

×g ˆI v1 ... vd

ki

j v ×g lj v
ki

j=1

j vj

(9)

(10)

i=1

j=1

v

nonlinearity to the three operations. Figure 2a plots the architecture  where the input is a matrix  the
g-aff mapping transforms lj v denoted by the black line in the input to a new black vector in m1  the
g-mul pooling maps each red vector in m1 to a scaler in vector v1 and the g-avg pooling reduces the
element number of v1 to 1. In fact  the three operations belong to two categories. the g-avg pooling
just is a special case of g-aff mapping. At last  we coin this layer as gCP layer as it implements the
gCP decomposition for K.

3.2.3 Cascaded gCP Layers as gHT (g Hierarchical Turker) Decomposition

The expressive power of neural network has a close connection with the depth of layers. We cascade
multiple gCP layers to extend the expressive ability in this section. The gCP layer maps a matrix to a
scalar. As illustrated in Figure 2a  the g-aff mapping changes the element number of each red ﬁber 
the g-mul pooling reduces the number of channels to 1 and the g-avg pooling decreases the element
number of v1 to 1. If we replace the global pooling in the g-mul pooling by the local pooling  the
output will become a matrix. Similarly  if we increase the output number of the last operation (the
g-avg pooling is turned to the g-aff mapping)  the output will be a vector. In this way  the gCP layer
maps a matrix to another matrix and we can cascade two CP-layers together. Figure 2b provides a
demo of two cascaded gCP layers  where the last g-aff mapping of the ﬁrst gCP layer and the ﬁrst
g-aff mapping of the second gCP layer are merged as one g-aff mapping.
Cascaded gCP layers implement g hierarchical tucker decomposition [Hackbusch and Kühn  2009] 
which replaces the multiplication by g in hierarchical tucker decomposition as we do for gCP.
For example  a g hierarchical turker decomposition for a 4-order tensor K with two layers can

N2(cid:88)

m=1

2(cid:89)

n=1

K =

wm ×g

Km

n

with Km

n =

2(cid:89)

N2(cid:88)

N1(cid:88)
architecture in Figure 2b  we can ﬁnd that the operators(cid:80)
(cid:80)N2

wm ×g

ˆI m
n =

I(cid:48)
p =

ˆI m

with

m=1

n=1

i=1

n

g-mul pooling  the g-avg pooling  respectively.

N1(cid:88)

i=1

j=1

kmi
nj

2(cid:89)
ni ×g
wm
2(cid:89)
(cid:88)
i=1 (cid:80)N1
nj v (cid:81)2

i=1

v

ni ×g
wm

nj v ×g lj v
kmi

ni (cid:81)2

(11)

(12)

be expressed as (11). Put (11) into convolution formula  we have (12). Comparing (12) to the

n=1 and
m=1 wm corresponds the ﬁrst g-aff mapping and g-mul pooling  the second g-aff mapping and

i=1 wm

v kmi

pi

= lpi

1 ◦g···◦glpi

1j ◦g ··· ◦g lpi

d and form the matrix [lpi

as the network input for each point pi. To relax this assumption  we suppose I pi =(cid:80)l

3.2.4 Proposed AccNet
Input: in sections (3.2.2) (3.2.3) we assumed I pi = lpi
1  ···   lpi
d ]
j=1 I j
pi and
I j
dj . The blurring value of each vertice pi on the bilateral grid or permutohedral
lattice depends on the values of its neighborhoods (an image batch I pi). For slicing  we need m
vertices pi surrounding the target point to interpolate its ﬁltering result. So total m image batches
{I pi  1 ≤ i ≤ m} are required to compute the results of target points encircled by {pi  1 ≤ i ≤ m}.
To synthesize ﬁltering values of target points encircled by {pi}  we compose Lj by concatenating
dj ]  1 ≤ i ≤ m} vertically. Further {Lj  1 ≤ j ≤ l} are stacked together and
{Lj
serves as our AccNet input. Figure 2c illustrates this  where color regions denote different parts
{Lj
Splatting: the splatting layer conducts the strided convolution. Theoretically  the convolution kernel
K is arbitrary. Here  we assume K = k1 ◦g ··· ◦g kd is a rank-one tensor in AccNet due to the

= [lpi
} of Lj and the light cube represents the 3-order input tensor.

1j  ···   lpi

pi

pi

5

(a) gCP convolution

(b) gHT convolution

(cid:81)4

K =(cid:80)4
scheme (12) for the gHT decomposition K =(cid:81)2

Figure 3: Illustration for fast ﬁltering approaches based on gCP and gHT decompositions. Taking
different tensor decomposition methods for the ﬁltering kernel  we achieve different fast ﬁltering
algorithms. (a) plots the computation graph of fast ﬁltering scheme (7) for the gCP decomposition
j. The path indicated by arrows presents the convolution sequence with kernels
j}. Final result is the sum of the outputs of all 4 paths. (b) shows the ﬂow chart of fast ﬁltering
ij . Each input
connects to four outputs and thus produces four outputs. The red line indicates a convolution path.
Final result is the sum of the outputs of all 16 paths.

m=1 Km with Km =(cid:80)4

(cid:81)2

i=1 km

j=1 ki

{ki

j=1

i=1

pi

pi

pm

= [lpi

  . . .   zj

= lj 1
pi

◦g ··· ◦g lj d

dj ]  the blurring layer produces a scalar value zj

pi with a rank-one kernel K for a rank-one input tensor I j

reasons: 1  AccNet takes three layers to approximate the convolution result. Even though the splatting
layer is simple  the approximation error can be reduced by increasing the complexity of the blurring
layer; 2  each slice of the input tensor of the blurring layer must be a rank-one matrix and the ﬁltering
result I(cid:48)j
is also a
rank-one tensor.
Blurring: we prefer to employ cascaded gCP-layers to compose the blurring layer of AccNet as it
has more powerful expressive ability than single gCP-layer. Figure 2c provides a two gCP-layers
1j  ···   lpi
example. For each slice Lj
pi
Slicing: let zj = [zj
]  the slicing layer maps zj to a vector tj  where each element of tj
p1
corresponds to the interpolated values of the pixels surrounded by {pi} and the value of each pi are
from I j
pi  there are total l different zj and therefore we obtain l different
tj. The ﬁnal result is the sum of {tj  1 ≤ j ≤ l}.
g function: the function plays an important role in our AccNet. First  it introduces nonlinearity to
AccNet. This strengthens the expressive power of our AccNet. Second  it deﬁnes new convolutions.
Employing g-conv operation  we can easily deﬁne novel splatting  blurring and slicing operations.
There are many possible g functions meeting the associativity g(g(a  b)  c) = g(a  g(b  c)) and
commutativity g(a  b) = g(b  a) requirements. Here we list two of them used in AccNet: 1  g(a  b) =
max{a  0} max{b  0}; 2  g(a  b) = max{ab  0}.
Gradients: The gradients of both sum and g function can be easily obtained. Therefore  AccNet as a
composition of the two basis calculations can be easily trained by the back-propagation algorithm.

pi. Since I pi =(cid:80)l

j=1 I j

pi.

4 Approximation & Fast Filtering

In section 3  we discussed the layers of AccNet as well as the way to transform the SBS to an AccNet.
Here  we describe an approach to compose an expressive powerful AccNet and to turn it back to SBS.
Expressive Powerful AccNet: the expressive power of AccNet determines the approximation error.
We have two ways to increase this power. One is to introduce the nonlinear activation function to
AccNet. Unlike traditional SBS taking the CP decomposition for acceleration  we implement gCP
decomposition in AccNet. Another way is to make AccNet deeper. In this way  gCP becomes gHT.
At last  we note that we can choose different activation functions in different layers. This is because
splatting  blurring and slicing operations are essentially convolutions therefore we can take different
gCTs and gHTs to accelerate their computation.
From AccNet to SBS: the weights as well as the activation function of three AccNet layers deﬁne the
splatting  blurring and slicing kernels. The correspondences between AccNet weights and convolution
kernels are determined by (7) (8) for the gCP decomposition and (11) (12) for the gHT decomposition.
For easy understanding  we visualize the computation graph of an AccNet in Figure 3. Figure 3a

6

𝒌11𝒌12𝒌13𝒌14𝒌31𝒌32𝒌33𝒌34𝒌41𝒌42𝒌43𝒌44𝒌24𝒌23𝒌22𝒌21InputOutputsum𝒌121𝒌131𝒌141𝒌112𝒌122𝒌132𝒌142𝒌212𝒌222𝒌232𝒌242𝒌241𝒌231𝒌221𝒌211InputOutputsum𝒌111Table 1: Filtering accuracy comparison for the bilateral grid acceleration method (BG)  the permuto-
hedral lattice acceleration method (PL) and our AccNet  where the sampling period of splatting is 3 
the radius of blurring is 1 and the radius of original convolution is 5.

2D

3D

5D

σ = 2
1.225
0.336
1.107
0.381

(cid:81)4

BG

AccNet

PL

AccNet

σ = 2
0.952
0.309
0.541
0.273

σ = 4
0.768
0.249
0.657
0.175

σ = 8
0.587
0.165
0.419
0.142

σ = 16
0.288
0.054
0.239
0.051

σ = 4
1.085
0.276
0.893
0.243

σ = 8
0.813
0.267
0.733
0.203

σ = 16
0.668
0.171
0.604
0.153

σ = 2
1.804
0.853
1.712
0.528

σ = 4
1.552
0.465
1.488
0.423

σ = 8
1.179
0.349
1.005
0.299

σ = 10
0.878
0.259
0.854
0.213

i=1

j=1 ki

takes the gCT decomposition K =(cid:80)4
Figure 3b records the fast convolution for the gHT decomposition K = (cid:81)2

j to implement the fast convolution algorithm and
ij  
i=1 km
where circles denote convolution operations with speciﬁc ﬁltering kernels k and arrows indicate the
computation order.
The two examples in Figure 3 disclose the superiority of gHT decomposition based acceleration
algorithms. In Figure 3a  each convolution kernel is only used by one computation path. In contrast 
the convolution kernel in Figure 3b is used by multiple times. The reuse advantages are twofold: 1  we
can reduce the approximation error because more terms can be used to approximate original kernels;
2  we can reduce the execution time by reusing the convolution result sharing the same convolution
node. For example  the ﬁltering path k1
22 share
the ﬁltering results of k1

11 → k1

21 → k2

11 → k2

11 → k1

21 → k2

12 → k2

(cid:80)4

21 and k1

(cid:81)2

m=1

j=1

11 → k1
21.

5 Experiments

AccNet is the ﬁrst neural network producing fast convolution algorithms. To reveal its advantages 
three experiments are conducted: 1  we compare our AccNet designed acceleration method to the
handmade bilateral grid and permutohedral lattice acceleration methods; 2  we provide a new neural
network to automatically design fast algorithm and compare it to AccNet; 3  we employ AccNet to
design new acceleration algorithms for non-Gaussian convolution and demonstrate their applications.
In the following experiments  the blurring layer of AccNet is composed by two cascaded gCP layers
and the activation function is g(a  b) = max(ab  0).
Fast Gaussian convolution comparison: Both bilateral grid acceleration method (BG) and permu-
tohedral lattice acceleration method (PL) are designed for fast Gaussian convolution. The major
difference between them is the underlying grid. Our AccNet can be applied to both bilateral grid
and permutohedral lattice. To illustrate the ﬁltering accuracy of the methods produced by AccNet 
we keep their convolution number same to BG and PL and evaluate their ﬁltering accuracy. Table 1
records the quantitative comparison results  where the ﬁrst row denotes the dimension of the Gaussian
kernel  σ denotes the bandwidth of kernel  the accuracy is measured by MSE (the mean-square error) 
the ﬁrst two rows record the results of BG and AccNet on the bilateral grid and the last two rows plot
the results of PL and AccNet on the permutohedral lattice.
Acceleration network comparison: SBS sequentially conducts three convolutions. We can turn it
to a CNN with three layers and further transform each CNN layer to d cascaded 1-D convolution
according to the CP decomposition (4) (5). The differences between this network and our AccNet are
that: 1  the depth of each layer of this CNN model is proportional to the dimension of ﬁltering kernel.
In contrast  the layer depth of AccNet only depends on the desired expressive power of the layer and
the expressive power of the simplest AccNet layer equal to the expressive power of CNN layer. 2  the
CNN model is hard to express the gHT decomposition (11) as its straightforward processing pipeline
is similar to Figure 3a and could not reuse intermediate results as AccNet does in Figure 3b.
The ﬁrst shortcoming makes the CNN model deeper for high-dimensional convolution. We thus have
to spend more time to tweak it. What’s worse  the depth does not increase the expressive power of

Table 2: Two acceleration neural networks (CNN and AccNet) comparisons. The bandwidth of target
Gaussian kernel is 5 and the underlying lattice is the bilateral grid.

2D

Filtering Error Training Time

3D

Filtering Error Training Time

5D

Filtering Error Training Time

CNN
AccNet

0.245
0.239

12.5h
7.2h

0.283
0.271

13.1h
7.3h

0.473
0.461

7

14h
7.6h

this model because its expressive power is determined by the number N of cascaded 1-D convolution
pipelines. The second weakness causes its inferiority of the expressive power when we limits its
convolution number equal to AccNet. This usually means larger ﬁltering errors in ﬁltering. To prove
these  we plot Table 2 which records the training time as well as the ﬁltering error measured by MSE 
where the dimension of ﬁltering kernel varies from 2-D to 5-D.
Fast non-Gaussian ﬁltering: Non-Gaussian blur becomes popular recently. To illustrate the power
of our AccNet  we demonstrate three applications of fast non-Gaussian ﬁltering in machine learning 
computer vision and computer graphics  respectively.

(a) Input

(b) Krähenbühl

(c) Ours

(a) Input

(b) Paris

(c) Ours

Figure 4: Pixel-level segmentation results of two
fully connected CRF implementations. (a) is in-
put images.
(b) is the segmentation results of
Krähenbühl. (c) records our segmentation results.

Figure 5: Detail enhancement of two local
Laplace ﬁltering implementations. (a) is input
images. (b) is the ﬁltering results of Paris. (c)
denotes our results.

Table 3: Stereo matching quantitative comparison.

[Zbontar and LeCun  2015]
[Barron and Poole  2016]
Ours

All

bad 1% MAE RMS
18.36
20.07
8.44
19.49
19.21
7.79

5.93
2.81
2.13

NoOcc

bad 1% MAE RMS
9.07
10.42
5.23
11.33
10.41
4.96

1.94
1.40
1.34

CRF inference: The pairwise edge potentials used in the fully connected CRFs [Krähenbühl and
Koltun  2011] is the Gaussian mixture kernels. Krähenbühl and Koltun [2011] provided a highly
efﬁcient approximate inference algorithm by showing a mean ﬁeld update of all variables in a fully
connected CRF can be performed using Gaussian ﬁltering in the feature space. In order to speed up
the computation via the separability of the Gaussian kernel Gi  Krähenbühl has to perform multiple
times Gaussian ﬁltering. Employing AccNet  we can accelerate the Gaussian mixture kernels directly.
Compared to the original method  we save 60% of the time while producing the same segmentation
results as shown in Figure 4.
Bilateral solver: Bilateral solver [Barron and Poole  2016] allows for some optimization problems
with bilateral afﬁnity terms to be solved quickly  and also guarantees that the solutions are smoothed
within objects  but not smooth across edges. Although the prior used by bilateral solver is arbitrary in
theory  bilateral solver can only take the Gaussian function as it is the only function can be presented
by SBS before our work. Here we take the smooth exponential family prior [Zhang and Allebach 
2008] to construct non-Guassian bilateral solver and apply it stereo post-processing procedure of
MC-CNN [Zbontar and LeCun  2015] following the way of [Barron and Poole  2016]. In Table 3 
we record the quantitative results  where “bad 1%” presents the percent of pixels whose disparities
are wrong by more than 1  “MAE” stands for the mean absolute error and “RMS” is the root mean
square error.
Local Laplace ﬁltering: Local Laplacian ﬁlter [Paris et al.  2011] is an edge-aware operator that
deﬁnes the output image ¯I by constructing its Laplacian pyramid {L[ ¯I]} coefﬁcient by coefﬁcient.
Aubry et al. [2014] present the Laplacian coefﬁcient at level l and position p as the nonlinear
Dl(q − p)f (Iq − g)(Iq − g)  where f is a continuous function 
Dl is the difference-of-Gaussians ﬁlter deﬁning the pyramid coefﬁcients at level l and g is the
coefﬁcient of the Gaussian pyramid at (l  p). Obviously  this convolution can be accelerated by

convolution {Ll[ ¯I](p)} =(cid:80)

q∈Ωp

8

AccNet and achieves speed-ups on the order of 100 times. Figure 5 visualizes the similar detail
enhancement results of Paris and ours.

6 Conclusion

In this paper  we propose the ﬁrst neural network producing fast high-dimensional convolution
algorithms. We take AccNet to express the approximation function of SBS and generalize SBS by
changing the architecture of AccNet. Once training is ﬁnished  new fast convolution algorithm can
be easily derived from the weights and activation functions of each layer. Experiments prove the
effectiveness of our algorithm.

7 Acknowledgment

This work was supported by the 973 Program (Project No. 2014CB347600)  the National Natural
Science Foundation of China (Grant No. 61701235  61732007  61522203  61772275  61873293 and
61772524)  the Fundamental Research Funds for the Central Universities (Grant No. 30917011323)
and the Beijing Municipal Natural Science Foundation (Grant No. 4182067).

References
Andrew Adams  Jongmin Baek  and Myers Abraham Davis. Fast high-dimensional ﬁltering using the

permutohedral lattice. Computer Graphics Forum  29(2):753–762  may 2010. 2

Mathieu Aubry  Sylvain Paris  Samuel W. Hasinoff  Jan Kautz  and Frédo Durand. Fast local laplacian

ﬁlters: Theory and applications. ACM Transactions on Graphics  33(5):1–14  sep 2014. 2  8

Jongmin Baek and David E. Jacobs. Accelerating spatially varying gaussian ﬁlters. ACM Transactions

on Graphics  29(6):1  dec 2010. 2

Jonathan T. Barron and Ben Poole. The fast bilateral solver. In European Conference on Computer

Vision  pages 617–632. Springer International Publishing  2016. 2  8

Jonathan T. Barron  Andrew Adams  YiChang Shih  and Carlos Hernandez. Fast bilateral-space
stereo for synthetic defocus. In IEEE Conference on Computer Vision and Pattern Recognition.
IEEE  jun 2015. 2

Kunal N. Chaudhury and Swapnil D. Dabhade. Fast and provably accurate bilateral ﬁltering. IEEE

Transactions on Image Processing  25(6):2519–2528  jun 2016. 2

Jiawen Chen  Sylvain Paris  and Frédo Durand. Real-time edge-aware image processing with the

bilateral grid. ACM Transactions on Graphics  26(3):103  2007. 2

Nadav Cohen and Amnon Shashua. Convolutional rectiﬁer networks as generalized tensor decom-
positions. In Maria Florina Balcan and Kilian Q. Weinberger  editors  International Conference
on Machine Learning  volume 48 of Proceedings of Machine Learning Research  pages 955–963 
New York  New York  USA  20–22 Jun 2016. PMLR. 4

Longquan Dai  Mengke Yuan  and Xiaopeng Zhang. Speeding up the bilateral ﬁlter: A joint

acceleration way. IEEE Transactions on Image Processing  25(6):2657–2672  jun 2016. 2

Frédo Durand and Julie Dorsey. Fast bilateral ﬁltering for the display of high-dynamic-range images.

ACM Transactions on Graphics  21(3):257–266  jul 2002. 2

Elhanan Elboer  Michael Werman  and Yacov Hel-Or. The generalized laplacian distance and its
applications for visual matching. In IEEE Conference on Computer Vision and Pattern Recognition.
IEEE  jun 2013. 1

Raghudeep Gadde  Varun Jampani  Martin Kiefel  Daniel Kappler  and Peter V. Gehler. Superpixel
convolutional networks using bilateral inceptions. In European Conference on Computer Vision 
pages 597–613. Springer International Publishing  2016. 2

9

Leslie Greengard and John Strain. The fast gauss transform. SIAM Journal on Scientiﬁc and Statistical

Computing  12(1):79–94  jan 1991. 2

W. Hackbusch and S. Kühn. A new scheme for the tensor representation. Journal of Fourier Analysis

and Applications  15(5):706–722  oct 2009. 5

Varun Jampani  Raghudeep Gadde  and Peter V. Gehler. Video propagation networks. In IEEE

Conference on Computer Vision and Pattern Recognition. IEEE  jul 2017. 2

Philipp Krähenbühl and Vladlen Koltun. Efﬁcient inference in fully connected CRFs with gaussian
edge potentials. In J. Shawe-Taylor  R. S. Zemel  P. L. Bartlett  F. Pereira  and K. Q. Weinberger 
editors  Advances in Neural Information Processing Systems 24  pages 109–117. Curran Associates 
Inc.  2011. 1  8

Sylvain Paris and Frédo Durand. A fast approximation of the bilateral ﬁlter using a signal processing
approach. In European Conference on Computer Vision  pages 568–580. Springer Nature  2006. 2

Sylvain Paris and Frédo Durand. A fast approximation of the bilateral ﬁlter using a signal processing

approach. International Journal of Computer Vision  81(1):24–52  dec 2009. 1

Sylvain Paris  Samuel W. Hasinoff  and Jan Kautz. Local laplacian ﬁlters: edge-aware image

processing with a laplacian pyramid. ACM Transactions on Graphics  30(4):1  jul 2011. 8

Fatih Porikli. Constant time o(1) bilateral ﬁltering. In IEEE Conference on Computer Vision and

Pattern Recognition. Institute of Electrical and Electronics Engineers (IEEE)  jun 2008. 2

Evan Shelhamer  Jonathan Long  and Trevor Darrell. Fully convolutional networks for semantic
segmentation. IEEE Transactions on Pattern Analysis and Machine Intelligence  39(4):640–651 
apr 2017. 3

Nicholas D. Sidiropoulos  Lieven De Lathauwer  Xiao Fu  Kejun Huang  Evangelos E. Papalexakis 
and Christos Faloutsos. Tensor decomposition for signal processing and machine learning. IEEE
Transactions on Signal Processing  65(13):3551–3582  jul 2017. 3

Richard Szeliski. Computer Vision: Algorithms and Applications. Springer-Verlag GmbH  2011.

ISBN 1848829345. 2

C. Tomasi and R. Manduchi. Bilateral ﬁltering for gray and color images. In IEEE International

Conference on Computer Vision. Narosa Publishing House  1998. 1  2

Vibhav Vineet  Jonathan Warrell  and Philip H. S. Torr. Filter-based mean-ﬁeld inference for random
ﬁelds with higher-order terms and product label-spaces. International Journal of Computer Vision 
110(3):290–307  mar 2014. 2

Qingxiong Yang  Kar-Han Tan  and Narendra Ahuja. Real-time o(1) bilateral ﬁltering. In IEEE
Conference on Computer Vision and Pattern Recognition. Institute of Electrical and Electronics
Engineers (IEEE)  jun 2009. 2

Qingxiong Yang  Narendra Ahuja  and Kar-Han Tan. Constant time median and bilateral ﬁltering.

International Journal of Computer Vision  112(3):307–318  sep 2015. 2

Jure Zbontar and Yann LeCun. Computing the stereo matching cost with a convolutional neural
network. In IEEE Conference on Computer Vision and Pattern Recognition. Institute of Electrical
and Electronics Engineers (IEEE)  jun 2015. 8

Buyue Zhang and J.P. Allebach. Adaptive bilateral ﬁlter for sharpness enhancement and noise

removal. IEEE Transactions on Image Processing  17(5):664–678  may 2008. 8

10

,Longquan Dai
Liang Tang
Yuan Xie
Jinhui Tang