2019,Self-supervised GAN: Analysis and Improvement with Multi-class Minimax Game,Self-supervised (SS) learning is a powerful approach for representation learning using unlabeled data. Recently  it has been applied to Generative Adversarial Networks (GAN) training. Specifically  SS tasks were proposed to address the catastrophic forgetting issue in the GAN discriminator. In this work  we perform an in-depth analysis to understand how SS tasks interact with learning of generator. From the analysis  we identify issues of SS tasks which allow a severely mode-collapsed generator to excel the SS tasks. To address the issues  we propose new SS tasks based on a multi-class minimax game. The competition between our proposed SS tasks in the game encourages the generator to learn the data distribution and generate diverse samples. We provide both theoretical and empirical analysis to support that our proposed SS tasks have better convergence property. We conduct experiments to incorporate our proposed SS tasks into two different GAN baseline models. Our approach establishes state-of-the-art FID scores on CIFAR-10  CIFAR-100  STL-10  CelebA  Imagenet $32\times32$ and Stacked-MNIST datasets  outperforming existing works by considerable margins in some cases. Our unconditional GAN model approaches performance of conditional GAN without using labeled data.  Our code:  \url{https://github.com/tntrung/msgan},Self-supervised GAN: Analysis and Improvement

with Multi-class Minimax Game

Ngoc-Trung Tran  Viet-Hung Tran  Ngoc-Bao Nguyen  Linxiao Yang  Ngai-Man Cheung

Singapore University of Technology and Design (SUTD)

Corresponding author: Ngai-Man Cheung <ngaiman_cheung@sutd.edu.sg>

Abstract

Self-supervised (SS) learning is a powerful approach for representation learning
using unlabeled data. Recently  it has been applied to Generative Adversarial
Networks (GAN) training. Speciﬁcally  SS tasks were proposed to address the
catastrophic forgetting issue in the GAN discriminator. In this work  we perform
an in-depth analysis to understand how SS tasks interact with learning of gener-
ator. From the analysis  we identify issues of SS tasks which allow a severely
mode-collapsed generator to excel the SS tasks. To address the issues  we propose
new SS tasks based on a multi-class minimax game. The competition between our
proposed SS tasks in the game encourages the generator to learn the data distri-
bution and generate diverse samples. We provide both theoretical and empirical
analysis to support that our proposed SS tasks have better convergence property.
We conduct experiments to incorporate our proposed SS tasks into two different
GAN baseline models. Our approach establishes state-of-the-art FID scores on
CIFAR-10  CIFAR-100  STL-10  CelebA  Imagenet 32 × 32 and Stacked-MNIST
datasets  outperforming existing works by considerable margins in some cases. Our
unconditional GAN model approaches performance of conditional GAN without
using labeled data. Our code: https://github.com/tntrung/msgan

1

Introduction

Generative Adversarial Networks (GAN). GAN [12] have become one of the most important
methods to learn generative models. GAN has shown remarkable results in various tasks  such as:
image generation [17  2  18]  image transformation [16  53]  super-resolution [23]  text to image
[38  50]  anomaly detection [41  26]. The idea behind GAN is the mini-max game. It uses a binary
classiﬁer  so-called the discriminator  to distinguish the data (real) versus generated (fake) samples.
The generator of GAN is trained to confuse the discriminator to classify the generated samples as the
real ones. By having the generator and discriminator competing with each other in this adversarial
process  they are able to improve themselves. The end goal is to have the generator capturing the
data distribution. Although considerable improvement has been made for GAN under the conditional
settings [34  49  2]  i.e.  using ground-truth labels to support the learning  it is still very challenging
with unconditional setup. Fundamentally  using only a single signal (real/fake) to guide the generator
to learn the high-dimensional  complex data distribution is very challenging [11  1  3  5  30  40].
Self-supervised Learning. Self-supervised learning is an active research area [6  35  51  52  33  10].
Self-supervised learning is a paradigm of unsupervised learning. Self-supervised methods encourage
the classiﬁer to learn better feature representation with pseudo-labels. In particular  these methods
propose to learn image feature by training the model to recognize some geometric transformation
that is applied to the image which the model receives as the input. A simple-yet-powerful method
proposed in [10] is to use image rotations by 0  90  180  270 degrees as the geometric transformation.
The model is trained with the 4-way classiﬁcation task of recognizing one of the four rotations. This

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

task is referred as the self-supervised task. This simple method is able to close the gap between
supervised and unsupervised image classiﬁcation [10].
Self-supervised Learning for GAN. Recently  self-supervised learning has been applied to GAN
training [4  44]. These works propose auxiliary self-supervised classiﬁcation tasks to assist the
main GAN task (Figure 1). In particular  their objective functions for learning discriminator D and
generator G are multi-task loss as shown in (1) and (2) respectively:

VD(D  C  G) = V(D  G) + λdΨ(G  C)
VG(D  C  G) = V(D  G) − λgΦ(G  C)

max
D C

min

G

(cid:16)

(cid:17)

(1)

(2)

(cid:16)

(cid:17)

+ Ex∼Pg log

1 − D(x)

V(D  G) = Ex∼Pd log

D(x)

(3)
Here  V(D  G) in (3) is the GAN task  which is the original value function proposed in Goodfellow
et al. [12]. Pd is true data distribution  Pg is the distribution induced by the generator mapping.
Ψ(G  C) and Φ(G  C) are the self-supervised (SS) tasks for discriminator and generator learning 
respectively (details to be discussed). C is the classiﬁer for the self-supervised task  e.g. rotation
classiﬁer as discussed [10]. Based on this framework  Chen et al.[4] apply self-supervised task to
help discriminator counter catastrophic forgetting. Empirically  they have shown that self-supervised
task enables discriminator to learn more stable and improved representation. Tran et al. [44] propose
to improve self-supervised learning with adversarial training.
Despite the encouraging empirical results  in-depth analysis of the interaction between SS tasks (Ψ(.)
and Φ(.)) and GAN task (V(D  G)) has not been done before. On one hand  the application of SS
task for discriminator learning is reasonable: the goal of discriminator is to classify real/fake image;
an additional SS classiﬁcation task Ψ(G  C) could assist feature learning and enhance the GAN task.
On the other hand  the motivation and design of SS task for generator learning is rather subtle: the
goal of generator learning is to capture the data distribution in G  and it is unclear exactly how an
additional SS classiﬁcation task Φ(G  C) could help.
In this work  we conduct in-depth empirical and theoretical analysis to understand the interaction
between self-supervised tasks (Ψ(.) and Φ(.)) and learning of generator G. Interestingly  from
our analysis  we reveal issues of existing works. Speciﬁcally  the SS tasks of existing works have
“loophole” that  during generator learning  G could exploit to maximize Φ(G  C) without truly
learning the data distribution. We show that analytically and empirically that a severely mode-
collapsed generator can excel Φ(G  C). To address this issue  we propose new SS tasks based on a
multi-class minimax game. Our proposed new SS tasks of discriminator and generator compete with
each other to reach the equilibrium point. Through this competition  our proposed SS tasks are able
to support the GAN task better. Speciﬁcally  our analysis shows that our proposed SS tasks enhance
matching between Pd and Pg by leveraging the transformed samples used in the SS classiﬁcation
(rotated images when [10] is applied). In addition  our design couples GAN task and SS task. To
validate our design  we provide theoretical analysis on the convergence property of our proposed
SS tasks. Training a GAN with our proposed self-supervised tasks based on multi-class minimax
game signiﬁcantly improves baseline models. Overall  our system establishes state-of-the-art Fréchet
Inception Distance (FID) scores. In summary  our contributions are:

supervised tasks in existing works.

• We conduct in-depth empirical and theoretical analysis to understand the issues of self-
• Based on the analysis  we propose new self-supervised tasks based on a multi-class minimax
• We conduct extensive experiments to validate our proposed self-supervised tasks.

game.

2 Related works

While training GAN with conditional signals (e.g.  ground-truth labels of classes) has made good
progress [34  49  2]  training GAN in the unconditional setting is still very challenging. In the original
GAN [12]  the single signal (real or fake) of samples is provided to train discriminator and the
generator. With these signals  the generator or discriminator may fall into ill-pose settings  and they

2

Figure 1: The model of (a) SSGAN [4] and (b) our approach. Here  Ψ(C) and Φ(G  C) are the
self-supervised value functions in training discriminator and generator  respectively  as proposed in
[4]. Ψ+(G  C) and Φ+(G  C) are the self-supervised value functions proposed in this work.

may get stuck at bad local minimums though still satisfying the signal constraints. To overcome
the problems  many regularizations have been proposed. One of the most popular approaches is to
enforce (towards) Lipschitz condition of the discriminator. These methods include weight-clipping
[1]  gradient penalty constraints [13  39  21  36  27] and spectral norm [31]. Constraining the
discriminator mitigates gradients vanishing and avoids sharp decision boundary between the real and
fake classes.
Using Lipschitz constraints improve the stability of GAN. However  the challenging optimization
problem still remains when using a single supervisory signal  similar to the original GAN [12]. In
particular  the learning of discriminator is highly dependent on generated samples. If the generator
collapses to some particular modes of data distribution  it is only able to create samples around
these modes. There is no competition to train the discriminator around other modes. As a result  the
gradients of these modes may vanish  and it is impossible for the generator to model well the entire
data distribution. Using additional supervisory signals helps the optimization process. For example 
using self-supervised learning in the form of auto-encoder has been proposed. AAE [29] guides the
generator towards resembling realistic samples. However  an issue with using auto-encoder is that
pixel-wise reconstruction with (cid:96)2-norm causes blurry artifacts. VAE/GAN [22]  which combining
VAE [19] and GAN  is an improved solution: while the discriminator of GAN enables the usage
of feature-wise reconstruction to overcome the blur  the VAE constrains the generator to mitigate
mode collapse. In ALI [8] and BiGAN [7]  they jointly train the data/latent samples in the GAN
framework. InfoGAN [5] infers the disentangled latent representation by maximizing the mutual
information. In [42  43]  they combine two different types of supervisory signals: real/fake signals
and self-supervised signal in the form of auto-encoder. In addition  Auto-encoder based methods 
including [22  42  43]  can be considered as an approach to mitigate catastrophic forgetting because
they regularize the generator to resemble the real ones. It is similar to EWC [20] or IS [48] but
the regularization is achieved via the output  not the parameter itself. Although using feature-wise
distance in auto-encoder could reconstruct sharper images  it is still challenging to produce very
realistic detail of textures or shapes.
Several different types of supervisory signal have been proposed. Instead of using only one discrimi-
nator or generator  they propose ensemble models  such as multiple discriminators [32]  mixture of
generators [15  9] or applying an attacker as a new player for GAN training [28]. Recently  training
model with auxiliary self-supervised constraints [4  44] via multi pseudo-classes [10] helps improve
stability of the optimization process. This approach is appealing: it is simple to implement and
does not require more parameters in the networks (except a small head for the classiﬁer). Recent
work applies InfoMax principle to improve GAN [24]. Variational Autoencoder is another important
approach to learn generative models [19  46].

3

CTk(x)xTkC1C2C3C4SS	task	in	discriminator	learningCTk(G(z))G(z)TkC1C2C3C4SS	task	in	generator	learningCTk(x)xTkCSS	task	in	generator	learning(a)	Original	SSGAN(b)	Our	proposalFakeC1C3C2C4FakeC1C3C2C4Tk(G(z))G(z)TkTk(G(z))G(z)TkSS	task	in	discriminator	learning3 GAN with Auxiliary Self-Supervised tasks

In [4]  self-supervised (SS) value function (also referred as “self-supervised task”) was proposed for
GAN [12] via image rotation prediction [10]. In their work  they showed that the SS task was useful
to mitigate catastrophic forgetting problem of GAN discriminator. The objectives of the discriminator
and generator in [4] are shown in Eq. 4 and 5. Essentially  the SS task of the discriminator (denoted
by Ψ(C)) is to train the classiﬁer C that maximizes the performance of predicting the rotation applied
to the real samples. Given this classiﬁer C  the SS task of the generator (denoted by Φ(G  C))
is to train the generator G to produce fake samples for maximizing classiﬁcation performance.
The discriminator and classiﬁer are the same (shared parameters)  except the last layer in order
to implement two different heads: the last fully-connected layer which returns a one-dimensional
output (real or fake) for the discriminator  and the other which returns a K-dimensional softmax of
pseudo-classes for the classiﬁer. λd and λg are constants.

V(D  C  G) = V(D  G) + λd

max
D C

V(D  C  G) = V(D  G) − λg

min

G

(cid:18)
(cid:124)
(cid:18)
(cid:124)

E
x∼P T

d

ETk∼T log

Ck(x)

Ex∼P T

g

ETk∼T log

Ck(x)

(cid:16)
(cid:16)

Ψ(C)

(cid:123)(cid:122)
(cid:123)(cid:122)

Φ(G C)

(cid:17)(cid:19)
(cid:125)
(cid:17)(cid:19)
(cid:125)

(4)

(5)

Here  the GAN value function V(D  G) (also referred as “GAN task”) can be the original minimax
GAN objective [12] or other improved versions. T is the set of transformation  Tk ∈ T is the k-th
transformation. The rotation SS task proposed in [10] is applied  and T1  T2  T3  T4 are the 0  90  180 
270 degree image rotation  respectively. Pd  Pg are the distributions of real and fake data samples 
g are the mixture distribution of rotated real and fake data samples (by Tk ∈ T ) 
respectively. P T
k=1 Ck(x) = 1 ∀x.

respectively. Let Ck(x) be the k-th softmax output of classiﬁer C  and we have(cid:80)K

The models are shown in Fig. 1a. In [4]  empirical evidence of improvements has been provided.
Note that  the goal of Φ(G  C) is to encourage the generator to produce realistic images. It is because
classiﬁer C is trained with real images and captures features that allow detection of rotation. However 
the interaction of Φ(G  C) with the GAN task V(D  G) has not been adequately analyzed.

d   P T

4 Analysis on Auxiliary Self-supervised Tasks

We analyze the SS tasks in [4] (Figure 1a). We assume that all networks D  G  C have enough capacity
[12]. Refer to the Appendix A for full derivation. Let D∗ and C∗ be the optimal discriminator and
optimal classiﬁer respectively at an equilibrium point. We assume that we have an optimal D∗
of the GAN task. We focus on C∗ of SS task. Let pTk (x) be the probability of sample x under
transformation by Tk (Figure 2). pTk
g (x) denotes the probability pTk (x) of data sample
(x ∼ P T
d ) or generated sample (x ∼ P T
g ) respectively.
Proposition 1 The optimal classiﬁer C∗ of Eq. 4 is:
pTk
d (x)
k=1 pTk

C∗
k (x) =

(cid:80)K

d (x)  pTk

d (x)

(6)

Proof. Refer to our proof in Appendix A for optimal C∗.
Theorem 1 Given optimal classiﬁer C∗ for SS task Ψ(C)  at the equilibrium point  maximizing SS
task Φ(G  C∗) of Eq. 5 is equal to maximizing:

Φ(G  C∗) =

1
K

E
x∼P

Tk
g

log

pTk
d (x)
k=1 pTk

d (x)

=

1
K

V Tk
Φ (x)

(7)

(cid:17)(cid:21)

K(cid:88)

k=1

(cid:20)

K(cid:88)

k=1

(cid:16)

(cid:80)K

4

Figure 2: The probability distribution pTk
d (x). Here  samples from Pd are rotated by Tk. The
distribution of rotated sample is pTk (x). Some rotated samples resemble the original samples  e.g.
those on the right of x2. On the other hand  for some image  there is no rotated image resembling it 
d (x1) = 0  j (cid:54)= 1). The generator can learn to generate these images e.g. x1 to achieve
e.g. x1 (pTj
maximum of Φ(G  C∗)  without actually learning the entire Pd.

Proof. Refer to our proof in Appendix A.

(cid:80)K
d (x) = 0  j (cid:54)= 1. For these x  the maximum V Tk
d (x) (cid:54)= 0 and pTj

Tk
d (x)
Tk
d (x)

p
k=1 p

Theorem 1 depicts learning of generator G given the optimal C∗: selecting G (hence Pg) to maximize
Φ(G  C∗). As C∗ is trained on real data  Φ(G  C∗) encourages G to learn to generate realistic samples.
However  we argue that G can maximize Φ(G  C∗) without actually learning data distribution Pd.
In particular  it is sufﬁcient for G to maximize Φ(G  C∗) by simply learning to produce images
which rotated version is rare (near zero probability). Some example images are shown in Figure 3a.
Intuitively  for these images  rotation can be easily recognized.
The argument can be developed from Theorem 1. From (7)  it can be shown that V Tk
g (x) >= 0 and
(pTk

Φ (x) ≤ 0
≤ 1). One way for G to achieve the maximum is to generate x such
that pT1
Φ (x) = 0 is attained. Note that
T1 corresponds to 0 degree rotation  i.e.  no rotation. Recall that pTk
d (x) is the probability distribution
d (x) = 0  j (cid:54)= 1 means
of transformed data by Tk. Therefore the condition pT1
that there is no other rotated image resembling x  or equivalently  rotated x does not resemble any
other images (Figure 2). Therefore  the generator can exploit this “loophole” to maximize Φ(G  C∗)
without actually learning the data distribution. In particular  even a mode-collapsed generator can
achieve the maximum of Φ(G  C∗) by generating such images.
Empirical evidence. Empirically  our experiments (in Appendix B.2.1) show that the FID of the
models when using Φ(G  C) is poor except for very small λg. We further illustrate this issue by a toy
empirical example using CIFAR-10. We augment the training images x with transformation data
Tk(x) to train the classiﬁer C to predict the rotation applied to x. This is the SS task of discriminator
in Figure 1a. Given this classiﬁer C  we simulate the SS task of generator learning as follows. To
simulate the output of a good generator Ggood which generates diverse realistic samples  we choose
the full test set of CIFAR-10 (10 classes) images and compute the cross-entropy loss  i.e. −Φ(G  C) 
when they are fed into C. To simulate the output of a mode-collapsed generator Gcollapsed  we select
samples from one class  e.g. “horse”  and compute the cross-entropy loss when they are fed into
C. Fig. 3b show that some Gcollapsed can outperform Ggood and achieve a smaller −Φ(G  C). E.g.
a Gcollapsed that produces only “horse” samples outperform Ggood under Φ(G  C). This example
illustrates that  while Φ(G  C) may help the generator to create more realistic samples  it does not
help the generator to prevent mode collapse. In fact  as part of the multi-task loss (see (5))  Φ(G  C)
would undermine the learning of synthesizing diverse samples in the GAN task V(D  G).

d (x) (cid:54)= 0 and pTj

5 Proposed method

5.1 Auxiliary Self-Supervised Tasks with Multi-class Minimax Game

In this section  we propose improved SS tasks to address the issue (Fig. 1b). Based on a multi-class
minimax game  our classiﬁer learns to distinguish the rotated samples from real data versus those
from generated data. Our proposed SS tasks are Ψ+(G  C) and Φ+(G  C) in (8) and (9) respectively.

5

PdPdT1(x)PdT2(x)PdT3(x)PdT4(x)x1x2pdT1(x1)pdT1(x2)TkFigure 3: (a) Left: Example images that achieve minimal loss (or maximal Φ(G  C)). For these
images  rotation can be easily recognized: an image with a 90 degree rotated horse is likely due to
applying T2 rather than an original one. (b) Right (Top): the loss of original SS task  i.e. −Φ(G  C)
computed over a good generator (red) and collapsed generators (green  yellow). Some collapsed
generators (e.g. one that generates only “horse”) have smaller loss than the good generator under
−Φ(G  C). (c) Right (Bottom): the loss of proposed MS task  −Φ+(G  C)  of a good generator (red)
and collapsed generators (green). The good generator has the smallest loss under −Φ+(G  C).

Our discriminator objective is:

V(D  C  G) = V(D  G)+λd

max
D C

(cid:18)
(cid:124)

(cid:16)

Ck(x)

(cid:17)

E
x∼P T

d

ETk∼T log

(cid:16)

CK+1(x)

(cid:17)(cid:19)
(cid:125)

ETk∼T log

+ Ex∼P T

g

(cid:123)(cid:122)

Ψ+(G C)

(8)
Eq. 8 means that we simultaneously distinguish generated samples  as the (K + 1)-th class  from the
rotated real sample classes. Here  CK+1(x) is the (K + 1)-th output for the fake class of classiﬁer C.
While rotated real samples are ﬁxed samples that help prevent the classiﬁer (discriminator) from
forgetting  the class K + 1 serves as the connecting point between generator and classiﬁer  and
the generator can directly challenge the classiﬁer. Our technique resembles the original GAN by
Goodfellow et al. [12]  but we generalize it for multi-class minimax game. Our generator objective
is:

V(D  C  G) = V(D  G)−λg

min

G

Ex∼P T

g

ETk∼T log

Ck(x)

ETk∼T log

CK+1(x)

(cid:16)

(cid:16)

(cid:17) − Ex∼P T
(cid:123)(cid:122)

g

Φ+(G C)

(cid:17)(cid:19)
(cid:125)

(cid:18)
(cid:124)

(9)
Ψ+(G  C) and Φ+(G  C) form a multi-class minimax game. Note that  when we mention multi-class
minimax game (or multi-class adversarial training)  we refer to the SS tasks. The game for GAN task
is the original by Goodfellow et al. [12].

5.1.1 Theoretical Analysis
Proposition 2 For ﬁxed generator G  the optimal solution C∗ under Eq. 8 is:

C∗
k (x) =

pT
d (x)
pT
g (x)

(cid:80)K

pTk
d (x)
k=1 pTk

d (x)

C∗
K+1(x)

(10)

d (x) and pT

g (x) are probability of sample x in the mixture distributions P T

where pT
tively.
Proof. Refer to our proof in Appendix A for optimal C∗.
Theorem 2 Given optimal classiﬁer C∗ obtained from multi-class minimax training Ψ+(G  C)  at
the equilibrium point  maximizing Φ+(G  C∗) is equal to maximizing Eq. 11:

d and P T

g respec-

Φ+(G  C∗) = − 1
K

KL(P Tk

g ||P Tk
d )

E
x∼P

Tk
g

log

(cid:20) K(cid:88)

k=1

(cid:20)

K(cid:88)

k=1

(cid:21)

+

1
K

6

(cid:16)

(cid:80)K

pTk
d (x)
k=1 pTk

d (x)

(cid:17)(cid:21)

(11)

GgoodGairplaneGautomobileGbirdGcatGdogGdeerGfrogGhorseGshipGtruck0.02.55.07.5LossGgoodGairplaneGautomobileGbirdGcatGdogGdeerGfrogGhorseGshipGtruck01020Loss(cid:17)

Ψ+(.)  Φ+(.)

(cid:16)
g ||P Tk

Proof. Refer to our proof in Appendix A.
Note that proposed SS task objective (11) is different from the original SS task objective (7) with
d ) = KL(Pg||Pd)  as rotation Tk is an
the KL divergence term. Furthermore  note that KL(P Tk
afﬁne transform and KL divergence is invariant under afﬁne transform (our proof in Appendix A).
Therefore  the improvement is clear: Proposed SS tasks
work together to improve the
matching of Pg and Pd by leveraging the rotated samples. For a given Pg  feedbacks are computed
from not only KL(Pg||Pd) but also KL(P Tk
d ) via the rotated samples. Therefore  G has more
feedbacks to improve Pg. We investigate the improvement of our method on toy dataset as in Section
4. The setup is the same  except that now we replace models/cost functions of −Φ(G  C) with our
proposed ones −Φ+(G  C) (the design of Ggood and Gcollapsed are the same). The loss now is shown
in Fig. 3c. Comparing Fig. 3c and Fig. 3b  the improvement using our proposed model can be
observed: Ggood has the lowest loss under our proposed model. Note that  since optimizing KL
divergence is not easy because it is asymmetric and could be biased to one direction [32]  in our
implementation  we use a slightly modiﬁed version as described in the Appendix.

g ||P Tk

6 Experiments

We measure the diversity and quality of generated samples via the Fréchet Inception Distance (FID)
[14]. FID is computed with 10K real samples and 5K generated samples exactly as in [31] if not
precisely mentioned. We report the best FID attained in 300K iterations as in [45  25  42  47]. We
integrate our proposed techniques into two baseline models (SSGAN [4] and Dist-GAN [42]). We
conduct experiments mainly on CIFAR-10 and STL-10 (resized into 48 × 48 as in [31]). We also
provide additional experiments of CIFAR-100  Imagenet 32 × 32 and Stacked-MNIST.
For Dist-GAN [42]  we evaluate three versions implemented with different network architectures:
DCGAN architecture [37]  CNN architectures of SN-GAN [31] (referred as SN-GAN architecture)
and ResNet architecture [13]. We recall these network architectures in Appendix C. We use ResNet
architecture [13] for experiments of CIFAR-100  Imagenet 32 × 32  and tiny K/4  K/2 architectures
[30] for Stacked MNIST. We keep all parameters suggested in the original work and focus to
understand the contribution of our proposed techniques. For SSGAN [4]  we use the ResNet
architecture as implemented in the ofﬁcial code1.
In our experiments  we use SS to denote the original self-supervised tasks proposed in [4]  and we use
MS to denote our proposed self-supervised tasks “Multi-class mini-max game based Self-supervised
tasks". Details of the experimental setup and network parameters are discussed in Appendix B.
We have conducted extensive experiments. Setup and results are discussed in Appendix B. In this
section  we highlight the main results:

• Comparison between SS and our proposed MS using the same baseline.
• Comparison between our proposed baseline + MS and other state-of-the-art unconditional
and conditional GAN. We emphasize that our proposed baseline + MS is unconditional and
does not use any label.

6.1 Comparison between SS and our proposed MS using the same baseline

Results are shown in Fig. 4 using Dist-GAN [42] as the baseline. For each experiment and for each
approach (SS or MS)  we obtain the best λg and λd using extensive search (see Appendix B.4 for
details)  and we use the best λg and λd in the comparison depicted in Fig. 4. In our experiments  we
observe that Dist-GAN has stable convergence. Therefore  we use it in these experiments. As shown
in Fig. 4  our proposed MS outperforms the original SS consistently. More details can be found in
Appendix B.4.

6.2 Comparison between our proposed method with other state-of-the-art GAN

Main results are shown in Table 1. Details of this comparison can be found in Appendix B.4. The
best λg and λd as in Figure 4 are used in this comparison. The best FID attained in 300K iterations

1https://github.com/google/compare_gan

7

Figure 4: Compare SS (original SS tasks proposed in [4]) and MS (our proposed Multi-class mini-
max game based Self-supervised tasks). The baseline is Dist-GAN [42]  implemented with SN-GAN
networks (CNN architectures in [31]) and ResNet. Two datasets are used  CIFAR-10 and STL-10.
For each experiment  we use the best λd  λg for the models  obtained through extensive search
(Appendix B.4). Note that λg = 0 is the best for “Baseline + SS” in all experiments. The results
suggest consistent improvement using our proposed self-supervised tasks.

Table 1: Comparison with other state-of-the-art GAN on CIFAR-10 and STL-10 datasets. We
report the best FID of the methods. Two network architectures are used: SN-GAN networks (CNN
architectures in [31]) and ResNet. The FID scores are extracted from the respective papers when
available. SS denotes the original SS tasks proposed in [4]. MS denotes our proposed self-supervised
tasks. ‘*’: FID is computed with 10K-10K samples as in [4]. All compared GAN are unconditional 
except SAGAN and BigGAN. SSGAN+ is SS-GAN in [4] but using the best parameters we have
obtained. In SSGAN+ + MS  we replace the original SS in author’s code with our proposed MS.

SN-GAN

ResNet

Methods
GAN-GP [31]
WGAN-GP [31]
SN-GAN [31]
SS-GAN [4]
Dist-GAN [42]
GN-GAN [43]
SAGAN [49] (cond.)
BigGAN [2] (cond.)
SSGAN+
Ours(SSGAN+ + MS)
Dist-GAN + SS
Ours(Dist-GAN + MS)

CIFAR-10
37.7
40.2
25.5
-
22.95
21.70
-
-
-
-
21.40
18.88

STL-10 CIFAR-10
-
55.1
43.2
-
36.19
30.80
-
-
-
-
29.79
27.95

-
-
21.70 ± .21
-
17.61 ± .30
16.47 ± .28
13.4 (best)
14.73
-
-
14.97 ± .29
13.90 ± .22

STL-10
-
-
40.10 ± .50
-
28.50 ± .49
-
-
-
-
-
27.98 ± .38
27.10 ± .34

CIFAR-10∗
-
-
19.73
15.65
13.01
-
-
-
20.47
19.89
12.37
11.40

are reported as in [45  25  42  47]. Note that SN-GAN method [31] attains the best FID at about 100K
iterations with ResNet and it diverges afterward. Similar observation is also discussed in [4].
As shown in Table 1  our method (Dist-GAN + MS) consistently outperforms the baseline Dist-GAN
and other state-of-the-art GAN. These results conﬁrm the effectiveness of our proposed self-supervised
tasks based on multi-class minimax game.
We have also extracted the FID reported in [4]  i.e. SSGAN with the original SS tasks proposed
there. In this case  we follow exactly their settings and compute FID using 10K real samples and
10K fake samples. Our model achieves better FID score than SSGAN with exactly the same ResNet
architecture on CIFAR-10 dataset. See results under the column CIFAR-10∗ in Table 1.
Note that we have tried to reproduce the results of SSGAN using its published code  but we were
unable to achieve similar results as reported in the original paper [4]. We have performed extensive
search and we use the obtained best parameter to report the results as SSGAN+ in Table 1 (i.e. 
SSGAN+ uses the published code and the best parameters we obtained). We use this code and
setup to compare SS and MS  i.e. we replace the SS code in the system with MS code  and obtain
“SSGAN+ + MS”. As shown in Table 1  our “SSGAN+ + MS” achieves better FID than SSGAN+.
The improvement is consistent with Figure 4 when Dist-GAN is used as the baseline. More detailed
experiments can be found in the Appendix. We have also compared SSGAN+ and our system
(SSGAN+ + MS) on CelebA (64 × 64). In this experiment  we use a small DCGAN architecture
provided in the authors’ code. Our proposed MS outperforms the original SS  with FID improved
from 35.03 to 33.47. This experiment again conﬁrms the effectiveness of our proposed MS.

8

0.511.522.53Iterations10520253035FIDSN-GAN for CIFAR-10BaselineBaseline + SS (d = 1.0)Baseline + MS (d = 1.0  g = 0.01)0.511.522.53Iterations10515202530FIDResNet for CIFAR-10BaselineBaseline + SS (d = 0.5)Baseline + MS (d = 0.5  g = 0.10)0.511.522.53Iterations10525303540455055FIDSN-GAN for STL-10BaselineBaseline + SS (d = 1.0)Baseline + MS (d = 0.5  g = 0.05)0.511.522.53Iterations10525303540455055FIDResNet for STL-10BaselineBaseline + SS (d = 1.0)Baseline + MS (d = 1.0  d = 0.01)Table 2: Results on CIFAR-100 and ImageNet 32×32. We use baseline model Dist-GAN with
ResNet architecture. We follow the same experiment setup as above. SS: proposed in [4]; MS: this
work.

Datasets

CIFAR-100 (10K-5K FID)

ImageNet 32×32 (10K-10K FID)

SS
21.02
17.1

MS
19.74
12.3

Table 3: Comparing to state-of-the-art methods on Stacked MNIST with tiny K/4 and K/2 archi-
tectures [30]. We also follow the same experiment setup of [30]. Baseline model: Dist-GAN. SS:
proposed in [4]; MS: this work. Our method MS achieves the best results for this dataset with both
architectures  outperforming state-of-the-art [42  17] by a signiﬁcant margin.

Arch
K/4  #
K/4  KL
K/2  #
K/2  KL

Unrolled GAN [30] WGAN-GP [13]
640.1 ± 136.3
1.97 ± 0.70
772.4 ± 146.5
1.35 ± 0.55

372.2 ± 20.7
4.66 ± 0.46
817.4 ± 39.9
1.43 ± 0.12

Dist-GAN [42]
859.5 ± 68.7
1.04 ± 0.29
917.9 ± 69.6
1.06 ± 0.23

Pro-GAN [17]
859.5 ± 36.2
1.05 ± 0.09
919.8 ± 35.1
0.82 ± 0.13

[42]+SS
906.75 ± 26.15
0.90 ± 0.13
957.50 ± 31.23
0.61 ± 0.15

Ours([42]+MS)
926.75 ± 32.65
0.78 ± 0.13
976.00 ± 10.04
0.52 ± 0.07

We conduct additional experiments on CIFAR-100 and ImageNet 32×32 to compare SS and MS
with Dist-GAN baseline. We use the same ResNet architecture as Section B.4 on CIFAR-10 for this
study  and we use the best parameters λd and λg selected in Section B.4 for ResNet architecture.
Experimental results in Table 2 show that our MS consistently outperform SS for all benchmark
datasets. For ImageNet 32×32 we report the best FID for SS because the model suffers serious mode
collapse at the end of training. Our MS achieves the best performance at the end of training.
We also evaluate the diversity of our generator on Stacked MNIST [30]. Each image of this dataset is
synthesized by stacking any three random MNIST digits. We follow exactly the same experiment
setup with tiny architectures K/4  K/2 and evaluation protocol of [30]. We measure the quality
of methods by the number of covered modes (higher is better) and KL divergence (lower is better).
Refer to [30] for more details. Table. 3 shows that our proposed MS outperforms SS for both mode
number and KL divergence. Our approach signiﬁcantly outperforms state-of-the-art [42  17]. The
means and standard deviations of MS and SS are computed from eight runs (we re-train our GAN
model from the scratch for each run). The results are reported with best (λd  λg) of MS: (0.5  0.2)
for K/4 architecture and (1.0  1.0) for K/2 architecture. Similarly  best (λd  λg) of SS: (0.5  0.0)
for K/4 architecture and (1.0  0.0) for K/2 architecture.
Finally  in Table 1  we compare our FID to SAGAN [49] (a state-of-the-art conditional GAN) and
BigGAN [2]. We perform the experiments under the same conditions using ResNet architecture on
the CIFAR-10 dataset. We report the best FID that SAGAN can achieve. As SAGAN paper does not
have CIFAR-10 results [49]  we run the published SAGAN code and select the best parameters to
obtain the results for CIFAR-10. For BigGAN  we extract best FID from original paper. Although our
method is unconditional  our best FID is very close to that of these state-of-the-art conditional GAN.
This validates the effectiveness of our design. Generated images using our system can be found in
Figures 5 and 6 of Appendix B.

7 Conclusion

We provide theoretical and empirical analysis on auxiliary self-supervised task for GAN. Our analysis
reveals the limitation of the existing work. To address the limitation  we propose multi-class minimax
game based self-supervised tasks. Our proposed self-supervised tasks leverage the rotated samples
to provide better feedback in matching the data and generator distributions. Our theoretical and
empirical analysis support improved convergence of our design. Our proposed SS tasks can be
easily incorporated into existing GAN models. Experiment results suggest that they help boost
the performance of baseline implemented with various network architectures on the CIFAR-10 
CIFAR-100  STL-10  CelebA  Imagenet 32 × 32  and Stacked-MNIST datasets. The best version of
our proposed method establishes state-of-the-art FID scores on all these benchmark datasets.

9

Acknowledgements

This work was supported by ST Electronics and the National Research Foundation(NRF)  Prime
Minister’s Ofﬁce  Singapore under Corporate Laboratory @ University Scheme (Programme Title:
STEE Infosec - SUTD Corporate Laboratory). This research was also supported by the National
Research Foundation Singapore under its AI Singapore Programme [Award Number: AISG-100E-
2018-005]. This research was also supported in part by the Energy Market Authority (EP award no.
NRF2017EWT-EP003-061). This project was also supported by SUTD project PIE-SGP-AI-2018-01.

References
[1] Martin Arjovsky and Léon Bottou. Towards principled methods for training generative adversarial networks.

arXiv preprint arXiv:1701.04862  2017.

[2] Andrew Brock  Jeff Donahue  and Karen Simonyan. Large scale gan training for high ﬁdelity natural

image synthesis. arXiv preprint arXiv:1809.11096  2018.

[3] Tong Che  Yanran Li  Athul Paul Jacob  Yoshua Bengio  and Wenjie Li. Mode regularized generative

adversarial networks. CoRR  2016.

[4] Ting Chen  Xiaohua Zhai  Marvin Ritter  Mario Lucic  and Neil Houlsby. Self-supervised gans via auxiliary

rotation loss. In CVPR  2019.

[5] Xi Chen  Yan Duan  Rein Houthooft  John Schulman  Ilya Sutskever  and Pieter Abbeel.

Infogan:
Interpretable representation learning by information maximizing generative adversarial nets. In Advances
in Neural Information Processing Systems  pages 2172–2180  2016.

[6] Carl Doersch  Abhinav Gupta  and Alexei A Efros. Unsupervised visual representation learning by context

prediction. In CVPR  2015.

[7] Jeff Donahue  Philipp Krähenbühl  and Trevor Darrell. Adversarial feature learning. arXiv preprint

arXiv:1605.09782  2016.

[8] Vincent Dumoulin  Ishmael Belghazi  Ben Poole  Alex Lamb  Martin Arjovsky  Olivier Mastropietro  and

Aaron Courville. Adversarially learned inference. arXiv preprint arXiv:1606.00704  2016.

[9] Arnab Ghosh  Viveka Kulharia  Vinay P Namboodiri  Philip HS Torr  and Puneet K Dokania. Multi-agent

diverse generative adversarial networks. In CVPR  2018.

[10] Spyros Gidaris  Praveer Singh  and Nikos Komodakis. Unsupervised representation learning by predicting

image rotations. ICLR  2018.

[11] Ian Goodfellow. Nips 2016 tutorial: Generative adversarial networks. arXiv preprint arXiv:1701.00160 

2016.

[12] Ian Goodfellow  Jean Pouget-Abadie  Mehdi Mirza  Bing Xu  David Warde-Farley  Sherjil Ozair  Aaron

Courville  and Yoshua Bengio. Generative adversarial nets. In NIPS  pages 2672–2680  2014.

[13] Ishaan Gulrajani  Faruk Ahmed  Martin Arjovsky  Vincent Dumoulin  and Aaron C Courville. Improved
training of wasserstein gans. In Advances in Neural Information Processing Systems  pages 5767–5777 
2017.

[14] Martin Heusel  Hubert Ramsauer  Thomas Unterthiner  Bernhard Nessler  and Sepp Hochreiter. Gans
trained by a two time-scale update rule converge to a local nash equilibrium. In Advances in Neural
Information Processing Systems  pages 6626–6637  2017.

[15] Quan Hoang  Tu Dinh Nguyen  Trung Le  and Dinh Phung. Mgan: Training generative adversarial nets

with multiple generators. 2018.

[16] Phillip Isola  Jun-Yan Zhu  Tinghui Zhou  and Alexei A Efros. Image-to-image translation with conditional

adversarial networks. CVPR  2017.

[17] Tero Karras  Timo Aila  Samuli Laine  and Jaakko Lehtinen. Progressive growing of gans for improved

quality  stability  and variation. arXiv preprint arXiv:1710.10196  2017.

[18] Tero Karras  Samuli Laine  and Timo Aila. A style-based generator architecture for generative adversarial

networks. In CVPR  2019.

10

[19] Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114 

2013.

[20] James Kirkpatrick  Razvan Pascanu  Neil Rabinowitz  Joel Veness  Guillaume Desjardins  Andrei A Rusu 
Kieran Milan  John Quan  Tiago Ramalho  Agnieszka Grabska-Barwinska  et al. Overcoming catastrophic
forgetting in neural networks. Proceedings of the national academy of sciences  2017.

[21] Naveen Kodali  Jacob Abernethy  James Hays  and Zsolt Kira. On convergence and stability of gans. arXiv

preprint arXiv:1705.07215  2017.

[22] Anders Boesen Lindbo Larsen  Søren Kaae Sønderby  Hugo Larochelle  and Ole Winther. Autoencoding

beyond pixels using a learned similarity metric. arXiv preprint arXiv:1512.09300  2015.

[23] Christian Ledig  Lucas Theis  Ferenc Huszár  Jose Caballero  Andrew Cunningham  Alejandro Acosta 
Andrew Aitken  Alykhan Tejani  Johannes Totz  Zehan Wang  et al. Photo-realistic single image super-
resolution using a generative adversarial network. In CVPR  2017.

[24] Kwot Sin Lee  Ngoc-Trung Tran  and Ngai-Man Cheung. Infomax-gan: Mutual information maximization
In NeurIPS 2019 Workshop on Information Theory and

for improved adversarial image generation.
Machine Learning  2019.

[25] Chun-Liang Li  Wei-Cheng Chang  Yu Cheng  Yiming Yang  and Barnabás Póczos. Mmd gan: Towards

deeper understanding of moment matching network. In NIPS  2017.

[26] Swee Kiat Lim  Yi Loo  Ngoc-Trung Tran  Ngai-Man Cheung  Gemma Roig  and Yuval Elovici. Doping:
Generative data augmentation for unsupervised anomaly detection. In Proceeding of IEEE International
Conference on Data Mining (ICDM)  2018.

[27] Kanglin Liu. Varying k-lipschitz constraint for generative adversarial networks.

arXiv:1803.06107  2018.

arXiv preprint

[28] Xuanqing Liu and Cho-Jui Hsieh. Rob-gan: Generator  discriminator and adversarial attacker. In CVPR 

2019.

[29] Alireza Makhzani  Jonathon Shlens  Navdeep Jaitly  and Ian Goodfellow. Adversarial autoencoders. In

International Conference on Learning Representations  2016.

[30] Luke Metz  Ben Poole  David Pfau  and Jascha Sohl-Dickstein. Unrolled generative adversarial networks.

ICLR  2017.

[31] Takeru Miyato  Toshiki Kataoka  Masanori Koyama  and Yuichi Yoshida. Spectral normalization for

generative adversarial networks. ICLR  2018.

[32] Tu Nguyen  Trung Le  Hung Vu  and Dinh Phung. Dual discriminator generative adversarial nets. In NIPS 

2017.

[33] Mehdi Noroozi  Hamed Pirsiavash  and Paolo Favaro. Representation learning by learning to count. In

ICCV  2017.

[34] Augustus Odena  Christopher Olah  and Jonathon Shlens. Conditional image synthesis with auxiliary

classiﬁer GANs. In ICML  2017.

[35] Deepak Pathak  Philipp Krahenbuhl  Jeff Donahue  Trevor Darrell  and Alexei A Efros. Context encoders:

Feature learning by inpainting. In CVPR  2016.

[36] Henning Petzka  Asja Fischer  and Denis Lukovnicov. On the regularization of wasserstein gans. arXiv

preprint arXiv:1709.08894  2017.

[37] Alec Radford  Luke Metz  and Soumith Chintala. Unsupervised representation learning with deep

convolutional generative adversarial networks. arXiv preprint arXiv:1511.06434  2015.

[38] Scott Reed  Zeynep Akata  Xinchen Yan  Lajanugen Logeswaran  Bernt Schiele  and Honglak Lee.

Generative adversarial text to image synthesis. arXiv preprint arXiv:1605.05396  2016.

[39] Kevin Roth  Aurelien Lucchi  Sebastian Nowozin  and Thomas Hofmann. Stabilizing training of generative
adversarial networks through regularization. In Advances in Neural Information Processing Systems  pages
2018–2028  2017.

[40] Tim Salimans  Ian Goodfellow  Wojciech Zaremba  Vicki Cheung  Alec Radford  and Xi Chen. Improved

techniques for training gans. In NIPS  pages 2234–2242  2016.

11

[41] Thomas Schlegl  Philipp Seeböck  Sebastian M. Waldstein  Ursula Schmidt-Erfurth  and Georg Langs.
Unsupervised anomaly detection with generative adversarial networks to guide marker discovery. CoRR 
abs/1703.05921  2017.

[42] Ngoc-Trung Tran  Tuan-Anh Bui  and Ngai-Man Cheung. Dist-gan: An improved gan using distance

constraints. In ECCV  2018.

[43] Ngoc-Trung Tran  Tuan-Anh Bui  and Ngai-Man Cheung. Improving gan with neighbors embedding and

gradient matching. In AAAI  2019.

[44] Ngoc-Trung Tran  Viet-Hung Tran  Ngoc-Bao Nguyen  and Ngai-Man Cheung. An improved self-

supervised gan via adversarial training. arXiv preprint arXiv:1905.05469  2019.

[45] Sitao Xiang and Hao Li. On the effects of batch and weight normalization in generative adversarial

networks. arXiv preprint arXiv:1704.03971  2017.

[46] Linxiao Yang  Ngai-Man Cheung  Jiaying Li  and Jun Fang. Deep clustering by gaussian mixture variational
autoencoders with graph embedding. In The IEEE International Conference on Computer Vision (ICCV) 
October 2019.

[47] Yasin Yazıcı  Chuan-Sheng Foo  Stefan Winkler  Kim-Hui Yap  Georgios Piliouras  and Vijay Chan-
drasekhar. The unusual effectiveness of averaging in gan training. arXiv preprint arXiv:1806.04498 
2018.

[48] Friedemann Zenke  Ben Poole  and Surya Ganguli. Continual learning through synaptic intelligence. arXiv

preprint arXiv:1703.04200  2017.

[49] Han Zhang  Ian Goodfellow  Dimitris Metaxas  and Augustus Odena. Self-attention generative adversarial

networks. arXiv preprint arXiv:1805.08318  2018.

[50] Han Zhang  Tao Xu  Hongsheng Li  Shaoting Zhang  Xiaogang Wang  Xiaolei Huang  and Dimitris N
Metaxas. Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks.
In CVPR  2017.

[51] Richard Zhang  Phillip Isola  and Alexei A Efros. Colorful image colorization. In ECCV  2016.

[52] Richard Zhang  Phillip Isola  and Alexei A Efros. Split-brain autoencoders: Unsupervised learning by

cross-channel prediction. In CVPR  2017.

[53] Jun-Yan Zhu  Taesung Park  Phillip Isola  and Alexei A Efros. Unpaired image-to-image translation using

cycle-consistent adversarial networkss. In ICCV  2017.

12

,Ngoc-Trung Tran
Viet-Hung Tran
Bao-Ngoc Nguyen
Linxiao Yang
Ngai-Man (Man) Cheung