2010,Identifying Dendritic Processing,In system identification both the input and the output of a system are available to an observer and an algorithm is sought to identify parameters of a hypothesized model of that system. Here we present a novel formal methodology for identifying dendritic processing in a neural circuit consisting of a linear dendritic processing filter in cascade with a spiking neuron model. The input to the circuit is an analog signal that belongs to the space of bandlimited functions. The output is a time sequence associated with the spike train. We derive an algorithm for identification of the dendritic processing filter and reconstruct its kernel with arbitrary precision.,Identifying Dendritic Processing

Department of Electrical Engineering

Department of Electrical Engineering

Yevgeniy B. Slutskiy∗

Columbia University
New York  NY 10027

ys2146@columbia.edu

Aurel A. Lazar

Columbia University
New York  NY 10027

aurel@ee.columbia.edu

Abstract

In system identiﬁcation both the input and the output of a system are available to
an observer and an algorithm is sought to identify parameters of a hypothesized
model of that system. Here we present a novel formal methodology for identifying
dendritic processing in a neural circuit consisting of a linear dendritic processing
ﬁlter in cascade with a spiking neuron model. The input to the circuit is an analog
signal that belongs to the space of bandlimited functions. The output is a time
sequence associated with the spike train. We derive an algorithm for identiﬁcation
of the dendritic processing ﬁlter and reconstruct its kernel with arbitrary precision.

1

Introduction

The nature of encoding and processing of sensory information in the visual  auditory and olfactory
systems has been extensively investigated in the systems neuroscience literature. Many phenomeno-
logical [1  2  3] as well as mechanistic [4  5  6] models have been proposed to characterize and
clarify the representation of sensory information on the level of single neurons.
Here we investigate a class of phenomenological neural circuit models in which the time-domain
linear processing takes place in the dendritic tree and the resulting aggregate dendritic current is en-
coded in the spike domain by a spiking neuron. In block diagram form  these neural circuit models
are of the [Filter]-[Spiking Neuron] type and as such represent a fundamental departure from the
standard Linear-Nonlinear-Poisson (LNP) model that has been used to characterize neurons in many
sensory systems  including vision [3  7  8]  audition [2  9] and olfaction [1  10]. While the LNP
model also includes a linear processing stage  it describes spike generation using an inhomogeneous
Poisson process. In contrast  the [Filter]-[Spiking Neuron] model incorporates the temporal dynam-
ics of spike generation and allows one to consider more biologically-plausible spike generators.
We perform identiﬁcation of dendritic processing in the [Filter]-[Spiking Neuron] model assuming
that input signals belong to the space of bandlimited functions  a class of functions that closely
model natural stimuli in sensory systems. Under this assumption  we show that the identiﬁcation of
dendritic processing in the above neural circuit becomes mathematically tractable. Using simulated
data  we demonstrate that under certain conditions it is possible to identify the impulse response of
the dendritic processing ﬁlter with arbitrary precision. Furthermore  we show that the identiﬁcation
results fundamentally depend on the bandwidth of test stimuli.
The paper is organized as follows. The phenomenological neural circuit model and the identiﬁcation
problem are formally stated in section 2. The Neural Identiﬁcation Machine and its realization as an
algorithm for identifying dendritic processing is extensively discussed in section 3. Performance of
the identiﬁcation algorithm is exempliﬁed in section 4. Finally  section 5 concludes our work.

∗The names of the authors are alphabetically ordered.

1

2 Problem Statement

In what follows we assume that the dendritic processing is linear [11] and any nonlinear effects arise
as a result of the spike generation mechanism [12]. We use linear BIBO-stable ﬁlters (not necessarily
causal) to describe the computation performed by the dendritic tree. Furthermore  a spiking neuron
model (as opposed to a rate model) is used to model the generation of action potentials or spikes.
We investigate a general neural circuit comprised of a ﬁlter in cascade with a spiking neuron model
(Fig. 1(a)). This circuit is an instance of a Time Encoding Machine (TEM)  a nonlinear asyn-
chronous circuit that encodes analog signals in the time domain [13  14]. Examples of spiking
neuron models considered in this paper include the ideal IAF neuron  the leaky IAF neuron and
the threshold-and-feedback (TAF) neuron [15]. However  the methodology developed below can be
extended to many other spiking neuron models as well.
We break down the full identiﬁcation of this circuit into two problems: (i) identiﬁcation of linear op-
erations in the dendritic tree and (ii) identiﬁcation of spike generator parameters. First  we consider
problem (i) and assume that parameters of the spike generator can be obtained through biophysical
experiments. Then we show how to address (ii) by exploring the space of input signals. We consider
a speciﬁc example of a neural circuit in Fig. 1(a) and carry out a full identiﬁcation of that circuit.

(a)

(b)

Figure 1: Problem setup. (a) The dendritic processing is described by a linear ﬁlter and spikes are produced
by a (nonlinear) spiking neuron model. (b) An example of a neural circuit in (a) is a linear ﬁlter in cascade with
the ideal IAF neuron. An input signal u is ﬁrst passed through a ﬁlter with an impulse response h. The output
of the ﬁlter v(t) = (u ∗ h)(t)  t ∈ R  is then encoded into a time sequence (tk)k∈Z by the ideal IAF neuron.

3 Neuron Identiﬁcation Machines

A Neuron Identiﬁcation Machine (NIM) is the realization of an algorithm for the identiﬁcation of
the dendritic processing ﬁlter in cascade with a spiking neuron model. First  we introduce several
deﬁnitions needed to formally address the problem of identifying dendritic processing. We then con-
sider the [Filter]-[Ideal IAF] neural circuit. We derive an algorithm for a perfect identiﬁcation of the
impulse response of the ﬁlter and provide conditions for the identiﬁcation with arbitrary precision.
Finally  we extend our results to the [Filter]-[Leaky IAF] and [Filter]-[TAF] neural circuits.

3.1 Preliminaries
We model signals u = u(t)  t ∈ R  at the input to a neural circuit as elements of the Paley-Wiener
space Ξ =(cid:8)u ∈ L2(R)(cid:12)(cid:12) supp (Fu) ⊆ [−Ω  Ω](cid:9)  i.e.  as functions of ﬁnite energy having a ﬁnite
spectral support (F denotes the Fourier transform). Furthermore  we assume that the dendritic
processing ﬁlters h = h(t)  t ∈ R  are linear  BIBO-stable and have a ﬁnite temporal support  i.e. 
they belong to the space H =(cid:8)h ∈ L1(R)(cid:12)(cid:12) supp(h) ⊆ [T1  T2](cid:9).
Deﬁnition 1. A signal u ∈ Ξ at the input to a neural circuit together with the resulting output
T = (tk)k∈Z of that circuit is called an input/output (I/O) pair and is denoted by (u  T).
Deﬁnition 2. Two neural circuits are said to be Ξ-I/O-equivalent if their respective I/O pairs are
identical for all u ∈ Ξ.
Deﬁnition 3. Let P : H → Ξ with (Ph)(t) = (h ∗ g)(t)  where (h ∗ g) denotes the convolution of
h with the sinc kernel g (cid:44) sin(Ωt)/(πt)  t ∈ R. We say that Ph is the projection of h onto Ξ.
Deﬁnition 4. Signals {ui}N
i=1 are said to be linearly independent if there do not exist real numbers
{αi}N

i=1  not all zero  and real numbers {βi}N

i=1 αiui(t + βi) = 0.

i=1 such that(cid:80)N

2

u(t)DendriticProcessingSpikeGenerationFilterSpikingLinearv(t)Neuron(tk)k∈Z+u(t)bδh(t)DendriticProcessingvoltageresetto0(tk)k∈ZSpikeGeneration:IdealIAFNeuron1C(cid:2)v(t)3.2 NIM for the [Filter]-[Ideal IAF] Neural Circuit

An example of a model circuit in Fig. 1(a) is the [Filter]-[Ideal IAF] circuit shown in Fig. 1(b).
In this circuit  an input signal u ∈ Ξ is passed through a ﬁlter with an impulse response (kernel)
h ∈ H and then encoded by an ideal IAF neuron with a bias b ∈ R+  a capacitance C ∈ R+ and a
threshold δ ∈ R+. The output of the circuit is a sequence of spike times (tk)k∈Z that is available to
an observer. This neural circuit is an instance of a TEM and its operation can be described by a set
of equations (formally known as the t-transform [13]):

(cid:90) tk+1

tk

(u ∗ h)(s)ds = qk 

k ∈ Z 

(1)

where qk (cid:44) Cδ−b(tk+1−tk). Intuitively  at every spike time tk+1 the ideal IAF neuron is providing
a measurement qk of the signal v(t) = (u ∗ h)(t) on the interval t ∈ [tk  tk+1].
Proposition 1. The left-hand side of the t-transform in (1) can be written as a bounded linear
functional Lk : Ξ → R with Lk(Ph) = (cid:10)φk Ph(cid:11)  where φk(t) = (cid:0)1[tk  tk+1] ∗ ˜u(cid:1) (t) and ˜u =
u(−t)  t ∈ R  denotes the involution of u.
Proof: Since (u∗h) ∈ Ξ  we have (u∗h)(t) = (u∗h∗g)(t)  t ∈ R  and therefore(cid:82) tk+1
(cid:82) tk+1
is a bounded linear functional Lk : Ξ → R with
Lk(Ph) =(cid:90) tk+1

(u∗h)(s)ds =
(u∗Ph)(s)ds. Now since Ph is bounded  the expression on the right-hand side of the equality

(u ∗ Ph)(s)ds =(cid:10)φk Ph(cid:11) 

where φk ∈ Ξ and the last equality follows from the Riesz representation theorem [16]. To ﬁnd φk 
we use the fact that Ξ is a Reproducing Kernel Hilbert Space (RKHS) [17] with a kernel K(s  t) =
g(t − s). By the reproducing property of the kernel [17]  we have φk(t) =(cid:10)φk  Kt(cid:11) = Lk(Kt).
Letting ˜u = u(−t) denote the involution of u and using (2)  we obtain

(2)

tk

tk

tk

φk(t) =(cid:10)1[tk  tk+1] ∗ ˜u  Kt(cid:11) =(cid:0)1[tk  tk+1] ∗ ˜u(cid:1) (t).

(cid:3)

ckψk(t) 

Proposition 1 effectively states that the measurements (qk)k∈Z of v(t) = (u ∗ h)(t) can be
also interpreted as the measurements of (Ph)(t). A natural question then is how to identify Ph
from (qk)k∈Z. To that end  we note that an observer can typically record both the input u = u(t) 
t ∈ R and the output T = (tk)k∈Z of a neural circuit. Since (qk)k∈Z can be evaluated from (tk)k∈Z
using the deﬁnition of qk in (1)  the problem is reduced to identifying Ph from an I/O pair (u  T).
Theorem 1. Let u be bounded with supp(Fu) = [−Ω  Ω]  h ∈ H and b/(Cδ) > Ω/π. Then given
an I/O pair (u  T) of the [Filter]-[Ideal IAF] neural circuit  Ph can be perfectly identiﬁed as

(Ph)(t) =(cid:88)k∈Z
u(s − tk)ds for all k  l ∈ Z  and [q]l = Cδ − b(tl+1 − tl).

where ψk(t) = g(t − tk)  t ∈ R. Furthermore  c = G+q with G+ denoting the Moore-Penrose
pseudoinverse of G  [G]lk =(cid:82) tl+1
Proof: By appropriately bounding the input signal u  the spike density (the average number of spikes
over arbitrarily long time intervals) of an ideal IAF neuron is given by D = b/(Cδ) [14]. Therefore 
for D > Ω/π the set of the representation functions (ψk)k∈Z  ψk(t) = g(t − tk)  is a frame in Ξ
[18] and (Ph)(t) =(cid:80)k∈Z ckψk(t). To ﬁnd the coefﬁcients ck we note from (2) that
ck(cid:10)φl  ψk(cid:11) =(cid:88)k∈Z
where [G]lk =(cid:10)φl  ψk(cid:11) =(cid:10)1[tl  tl+1] ∗ ˜u  g(· − tk)(cid:11) =(cid:82) tl+1
u(s − tk)ds. Writing (3) in matrix
form  we obtain q = Gc with [q]l = ql and [c]k = ck. Finally  the coefﬁcients ck  k ∈ Z  can be
(cid:3)
computed as c = G+q.

ql =(cid:10)φl Ph(cid:11) =(cid:88)k∈Z

[G]lkck 

(3)

tl

tl

3

Remark 1. The condition b/(Cδ) > Ω/π in Theorem 1 is a Nyquist-type rate condition. Thus 
perfect identiﬁcation of the projection of h onto Ξ can be achieved for a ﬁnite average spike rate.
Remark 2. Ideally  we would like to identify the kernel h ∈ H of the ﬁlter in cascade with the ideal
IAF neuron. Note that unlike h  the projection Ph belongs to the space L2(R)  i.e.  in general Ph
is not BIBO-stable and does not have a ﬁnite temporal support. Nevertheless  it is easy to show that
(Ph)(t) approximates h(t) arbitrarily closely on t ∈ [T1  T2]  provided that the bandwidth Ω of u
is sufﬁciently large.
Remark 3. If the impulse response h(t) = δ(t)  i.e.  if there is no processing on the (arbitrary)
input signal u(t)  then ql =(cid:82) tl+1
(cid:90) tl+1
(u ∗ Ph)(s)ds =(cid:90) tl+1
l ∈ Z.
The above holds if and only if (Ph)(t) = g(t)  t ∈ R. In other words  if h(t) = δ(t)  then we
identify Pδ(t) = sin(Ωt)/(πt)  the projection of δ(t) onto Ξ.
Corollary 1. Let u be bounded with supp(Fu) = [−Ω  Ω]  h ∈ H and b
π . Furthermore  let
W = (τ1  τ2) so that (τ2 − τ1) > (T2 − T1) and let τ = (τ1 + τ2)/2  T = (T1 + T2)/2. Then
given an I/O pair (u  T) of the [Filter]-[Ideal IAF] neural circuit  (Ph)(t) can be approximated
arbitrarily closely on t ∈ [T1  T2] by

u(s)ds  l ∈ Z. Furthermore 
u(s)ds =(cid:90) tl+1
(u ∗ g)(s)ds 

(u ∗ h)(s)ds =(cid:82) tl+1
(u ∗ h)(s)ds =(cid:90) tl+1

Cδ > Ω

tl

tl

tl

tl

tl

tl

ˆh(t) = (cid:88)k: tk∈W

ckψk(t) 

tl

u(s − (tk − τ + T ))ds and

where ψk(t) = g(t − (tk − τ + T ))  c = G+q  [G]lk = (cid:82) tl+1
[q]l = Cδ − b(tl+1 − tl) for all k  l ∈ Z  provided that |τ1| and |τ2| are sufﬁciently large.
Proof: Through a change of coordinates t → t(cid:48) = (t − τ + T ) illustrated in Fig. 2  we obtain
W (cid:48) = [τ1 − τ + T  τ2 − τ + T ] ⊃ [T1  T2] and the set of spike times (tk − τ + T )k: tk∈W . Note
that W (cid:48) → R as (τ2 − τ1) → ∞. The rest of the proof follows from Theorem 1 and the fact that
(cid:3)
limt→±∞ g(t) = 0.
From Corollary 1 we see that if the [Filter]-[Ideal IAF] neural circuit is producing spikes
with a spike density above the Nyquist rate  then we can use a set of spike times (tk)k: tk∈W from a
single temporal window W to identify (Ph)(t) to an arbitrary precision on [T1  T2].
This result is not surprising. Since the spike density is above the Nyquist rate  we could have also
used a canonical time decoding machine (TDM) [13] to ﬁrst perfectly recover the ﬁlter output v(t)
and then employ one of the widely available LTI system techniques to estimate (Ph)(t).
However  the problem becomes much more difﬁcult if the spike density is below the Nyquist rate.

(a)

(b)

Figure 2: Change of coordinates in Corollary 1. (a) Top: example of a causal impulse response h(t) with
supp(h) = [T1  T2]  T1 = 0. Middle: projection Ph of h onto some Ξ. Note that Ph is not causal and
supp(Ph) = R. Bottom: h(t) and (Ph)(t) are plotted on the same set of axes. (b) Top: an input signal
u(t) with supp(Fu) = [−Ω  Ω]. Middle: only red spikes from a temporal window W = (τ1  τ2) are used to
construct ˆh(t). Bottom: Ph is approximated by ˆh(t) on t ∈ [T1  T2] using spike times (tk − τ + T )k:tk∈W .

4

0tttT20T20T2(Ph)(t)h(t)h(t)(Ph)(t)u(t)0ˆh(t(cid:2))τ00(tk)k∈ZttT2t(cid:2)τ1−τ+Tτ2−τ+Tτ1τ2T2T2W(cid:2)WTheorem 2. (The Neuron Identiﬁcation Machine) Let {ui | supp(Fui) = [−Ω  Ω]}N
i=1 be a col-
lection of N linearly independent and bounded stimuli at the input to a [Filter]-[Ideal IAF] neural
circuit with a dendritic processing ﬁlter h ∈ H. Furthermore  let Ti = (ti
k)k∈Z denote the output of
the neural circuit in response to the bounded input signal ui. If(cid:80)N
π   then (Ph)(t) can
Cδ > Ω
be identiﬁed perfectly from the collection of I/O pairs {(ui  Ti)}N
i=1.
Proof: Consider the SIMO TEM [14] depicted in Fig. 3(a). h(t) is the input to a population of N
[Filter]-[Ideal IAF] neural circuits. The spikes (ti
k)k∈Z at the output of each neural circuit represent
k = (cid:10)φi
k  Ph(cid:11) of (Ph)(t). Thus we can think of the qi
distinct measurements qi
k’s as projections
k   . . . ). Since the ﬁlters are linearly independent
of Ph onto (φ1
2  . . .   φ1
i=1 are appropriately bounded and(cid:80)N
[14]  it follows that  if {ui}N
π or equivalently if the
πD   the set of functions { (ψj
k)  is
number of neurons N > ΩCδ
a frame for Ξ [14]  [18]. Hence

Cδ > Ω
j=1 with ψj

k(t) = g(t− tj

k)k∈Z }N

k  . . .   φN

2   . . .   φN

πb = Ω

1   φN

1  φ1

j=1

j=1

b

b

c1

c2

l  

qi

cN

(4)

k(t).

l  ψ2

l  ψ1

l  ψj

l  ψN

cj
kψj

l (t):

l (t)  φ2

l (t)  ...  φN

k(cid:10)φi

(Ph)(t) =

k(cid:10)φi

k(cid:11) ≡ qi

l  Ph(cid:11) =(cid:88)k∈Z
(cid:10)φi

l =(cid:88)k∈Z(cid:2)Gi1(cid:3)lk c1

To ﬁnd the coefﬁcients ck  we take the inner product of (4) with φ1

N(cid:88)j=1(cid:88)k∈Z
k(cid:11) + ··· + (cid:88)k∈Z
k(cid:11) + (cid:88)k∈Z
k(cid:10)φi
k(cid:11)  we obtain
for i = 1  . . .   N  l ∈ Z. Letting [Gij]lk =(cid:10)φi
k + (cid:88)k∈Z(cid:2)Gi2(cid:3)lk c2
k + ··· + (cid:88)k∈Z(cid:2)GiN(cid:3)lk cN
for i = 1  . . .   N  l ∈ Z. Writing (5) in matrix form  we have q = Gc  where q = [q1  q2  . . .   qN ]T
ui(s − tj
with [qi]l = Cδ − b(ti
k)ds and c = [c1  c2  . . .   cN ]T . Finally 
(cid:3)
to ﬁnd the coefﬁcients ck  k ∈ Z  we compute c = G+q.
i=1 as before  h ∈ H and(cid:80)N
Corollary 2. Let {ui}N
π . Furthermore  let W = (τ1  τ2) so
that (τ2 − τ1) > (T2 − T1) and let τ = (τ1 + τ2)/2  T = (T1 + T2)/2. Then given the I/O pairs
{(ui  Ti)}N
i=1 of the [Filter]-[Ideal IAF] neural circuit  (Ph)(t) can be approximated arbitrarily
closely on t ∈ [T1  T2] by ˆh(t) =(cid:80)N
k∈W cj
k − τ + T ))  c =
G+q  with [Gij]lk =(cid:82) ti
ui(s−(tj
l+1−ti
l)
for all k  l ∈ Z provided that |τ1| and |τ2| are sufﬁciently large.
Proof: Similar to Corollary 1.

j=1(cid:80)k: tj
k−τ +T ))ds  q = [q1  q2  . . .   qN ]T   [qi]l = Cδ−b(ti

l)  [Gij]lk =(cid:82) ti

k(t) = g(t− (tj

k(t)  where ψj

l+1 − ti

Cδ > Ω

kψj

(5)

k  

l+1

ti
l

l+1

ti
l

b

j=1

(cid:3)

i=1

1  τ i

1 + τ i

2(cid:1)(cid:9)N

be a collection of
2)/2 
2 − τ i
k)k∈Z denote those spikes of the I/O pair (u  T) that belong to W i. Then

1) > (T2 − T1)  i = 1  2  ...  N. Furthermore  let τ i = (τ i

Corollary 3. Let supp(Fu) = [−Ω  Ω]  h ∈ H and let(cid:8)W i (cid:44) (cid:0)τ i
windows of ﬁxed length (τ i
T = (T1 + T2)/2 and let (ti
Ph can be approximated arbitrarily closely on [T1  T2] by
N(cid:88)j=1 (cid:88)k: tk∈W j
cj
kψj

k(t) = g(t − (tj

k − τ j + T ))  c = G+q with [Gij]lk = (cid:82) ti

where ψj
q = [q1  q2  . . .   qN ]T   [qi]l = Cδ − b(ti
non-overlapping windows N is sufﬁciently large.
Proof: The input signal u restricted  respectively  to the collection of intervals(cid:8)W i (cid:44)(cid:0)τ i
plays the same role here as the test stimuli {ui}N

k − τ j + T ))ds 
l) for all k  l ∈ Z  provided that the number of
2(cid:1)(cid:9)N
i=1 in Corollary 2. See also Remark 9 in [14]. (cid:3)

u(s − (tj

l+1 − ti

ˆh(t) =

k(t) 

1  τ i

i=1

ti
l

l+1

5

(a)

(b)

Figure 3: The Neuron Identiﬁcation Machine. (a) SIMO TEM interpretation of the identiﬁcation problem
with (ti

k) = (tk)k:tk∈W i  i = 1  2  . . .   N. (b) Block diagram of the algorithm in Theorem 2.

Remark 4. The methodology presented in Theorem 2 can easily be applied to other spiking neuron
models. For example  for the leaky IAF neuron  we have

l − ti

RC (cid:33)(cid:35) 

l+1

RC (cid:33)ds.
[qi]l = Cδ − bRC(cid:34)1 − exp(cid:32) ti
ui(cid:0)s − tj
Similarly  for a threshold-and-feedback (TAF) neuron [15] with a bias b ∈ R+  a threshold δ ∈ R+ 
and a causal feedback ﬁlter with an impulse response f (t)  t ∈ R  we obtain
[Gij]lk = ui(cid:0)ti

k(cid:1) exp(cid:32)s − ti
k(cid:1).
l − tj

[qi]l = δ − b +(cid:88)k<l

[Gij]lk =(cid:90) ti

l − ti
k) 

f (ti

l+1

ti
l

l+1

3.3

Identifying Parameters of the Spiking Neuron Model

If parameters of the spiking neuron model cannot be obtained through biophysical experiments  we
can use additional input stimuli to derive a neural circuit that is Ξ-I/O-equivalent to the original
circuit. For example  consider the circuit in Fig. 1(a). Rewriting the t-transform in (1)  we obtain

1

b(cid:90) tk+1

tk

(cid:90) tk+1

tk

Cδ
b − (tk+1 − tk)

(u ∗ h)(s)ds =

⇐⇒
where h(cid:48)(t) = h(t)/b  t ∈ R and q(cid:48)k = Cδ/b − (tk+1 − tk).
Setting u = 0  we can now compute Cδ/b = (tk+1 − tk). Next we can use the NIM described in
Section 3.2 to identify with arbitrary precision the projection Ph(cid:48) of h(cid:48) onto Ξ. Thus we identify a
[Filter]-[Ideal IAF] circuit with a ﬁlter impulse response Ph(cid:48)  a bias b(cid:48) = 1  a capacitance C(cid:48) = 1
and a threshold δ(cid:48) = Cδ/b. This neural circuit is Ξ-I/O-equivalent to the circuit in Fig. 1(b).

(u ∗ h(cid:48))(s)ds = q(cid:48)k 

4 Examples

We now demonstrate the performance of the identiﬁcation algorithm in Corollary 3. We model the

dendritic processing ﬁlter using a causal linear kernel h(t) = ce−αt(cid:2)(αt)3/3! − (αt)5/5!(cid:3) with
t ∈ [0  0.1 s]  c = 3 and α = 200. The general form of this kernel was suggested in [19] as a
plausible approximation to the temporal structure of a visual receptive ﬁeld.
We use two different bandlimited signals and show that the identiﬁcation results fundamentally
depend on the signal bandwidth Ω. In Fig. 4 the signal is bandlimited to Ω = 2π·25 rad/s  whereas
in Fig. 5 it is bandlimited to Ω = 2π·100 rad/s. Although in principle the kernel h has an inﬁnite
bandwidth (having a ﬁnite temporal support)  its effective bandwidth Ω ≈ 2π·100 rad/s (Fig. 6(b)).
Thus in Fig. 4 we reconstruct the projection Ph of the kernel h onto Ξ with Ω = 2π· 25 rad/s 
whereas in Fig. 5 we reconstruct nearly h itself.

6

+++1C(cid:2)1C(cid:2)1C(cid:2)δδδbbbu1(t)u2(t)uN(t)(t1k)k∈Z(t2k)k∈Z(tNk)k∈Zvoltageresetto0voltageresetto0voltageresetto0h(t)+c=G+q(cid:2)k∈Zc1kδ(t−t1k)(cid:2)k∈Zc2kδ(t−t2k)(cid:2)k∈ZcNkδ(t−tNk)(Ph)(t)g(t)(t1k)k∈Z(t2k)k∈Z(tNk)k∈ZFigure 4: Identifying dendritic processing in the [Filter]-[Ideal IAF] neural circuit. Ω = 2π· 25 rad/s.
(a) Signal u(t) at the input to the circuit. (b) The output of the circuit is a set of spikes at times (tk)k∈Z. The
spike density D = 40 Hz. Note that only 25 spikes from 5 temporal windows are used to construct ˆh. (c) The
RMSE between ˆh (red) and Ph (blue) is 2.04 × 10−4. The RMSE between ˆh (red) and h (dashed black) is
1.53 × 10−1. (d)-(f) Spectral estimates of u  h and v = u ∗ h. Note that supp(Fu) = [−Ω  Ω] = supp(Fv)
but supp(Fh) ⊃ [−Ω  Ω]. In other words  both u  v ∈ Ξ but h /∈ Ξ.

Figure 5: Identifying dendritic processing of the [Filter]-[Ideal IAF] neural circuit. Ω = 2π·100 rad/s.
(a) Signal u(t) at the input to the circuit. (b) The output of the circuit is a set of spikes at times (tk)k∈Z. The
spike density D = 40 Hz. Note that only 43 spikes from 10 temporal windows are used to construct ˆh. (c) The
RMSE between ˆh (red) and Ph (blue) is 1.13 × 10−3. The RMSE between ˆh (red) and h (dashed black) is
4.58 × 10−3. (d)-(f) Spectral estimates of u  h and v = u ∗ h. Note that supp(Fu) = [−Ω  Ω] = supp(Fv)
but supp(Fh) ⊃ [−Ω  Ω]. In other words  both u  v ∈ Ξ but h /∈ Ξ.

7

00.20.40.60.81−1−0.500.51(a)Inputsignalu(t)Amplitude  Ω=2π·25rad/s00.20.40.60.81(b)Outputofthe[Filter]-[IdealIAF]neuralcircuit  D=40HzWindows{Wi}5i=1−0.0500.050.10.15−50050100Time [s]Amplitude(c)Originalﬁltervs.theidentiﬁedﬁlter  h RMSE(ˆh h)=1.53e-01Ph RMSE(ˆh Ph)=2.04e-04ˆh−150−100−50050100150−100−80−60−40−200(d)PeriodogramPowerSpectrumEstimateofu(t)Power [dB]  −150−100−50050100150−100−80−60−40−200(e)PeriodogramPowerSpectrumEstimateofh(t)Power [dB]  −150−100−50050100150−100−80−60−40−200(f)PeriodogramPowerSpectrumEstimateofv(t)Frequency [Hz]Power [dB]  supp(Fu)=[-Ω Ω]supp(Fh)⊃[-Ω Ω]supp(Fv)=[-Ω Ω]00.20.40.60.811.21.4−1−0.500.51(a)Inputsignalu(t)Amplitude  Ω=2π·100rad/s00.20.40.60.811.21.4(b)Outputofthe[Filter]-[IdealIAF]neuralcircuit  D=40HzWindows{Wi}10i=1−0.0500.050.10.15−50050100Time [s]Amplitude(c)Originalﬁltervs.theidentiﬁedﬁlter  h RMSE(ˆh h)=4.58e-03Ph RMSE(ˆh Ph)=1.13e-03ˆh−150−100−50050100150−100−80−60−40−200(d)PeriodogramPowerSpectrumEstimateofu(t)Power [dB]  supp(Fu)=[-Ω Ω]−150−100−50050100150−100−80−60−40−200(e)PeriodogramPowerSpectrumEstimateofh(t)Power [dB]  supp(Fh)⊃[-Ω Ω]−150−100−50050100150−100−80−60−40−200(f)PeriodogramPowerSpectrumEstimateofv(t)Frequency [Hz]Power [dB]  supp(Fv)=[-Ω Ω]Next  we evaluate the ﬁlter identiﬁcation error as a function of the number of temporal windows N
and the stimulus bandwidth Ω. By increasing N  we can approximate the projection Ph of h with
arbitrary precision (Fig. 6(a)). Note that the estimate ˆh converges to Ph faster for higher average
spike rate (spike density D) of the neuron. At the same time  by increasing the stimulus bandwidth
Ω  we can approximate h itself with arbitrary precision (Fig. 6(b)).

Figure 6: The Filter Identiﬁcation Error. (a) MSE(ˆh Ph) as a function of the number of temporal windows
N. The larger the neuron spike density D  the faster the algorithm converges. The impulse response h is the
same as in Fig. 4  5 and the input signal bandwidth is Ω = 2π· 100 rad/s. (b) MSE(ˆh  h) as a function of
the input signal bandwidth Ω. The larger the bandwidth  the better the estimate ˆh approximates h. Note that
signiﬁcant improvement is seen even for Ω > 2π·100 rad/s  which is roughly the effective bandwidth of h.

5 Conclusion

Previous work in system identiﬁcation of neural circuits (see [20] and references therein) calls for
parameter identiﬁcation using white noise input stimuli. The identiﬁcation process for  e.g.  the LNP
model entails identiﬁcation of the linear ﬁlter  followed by a ‘best-of-ﬁt’ procedure to ﬁnd the non-
linearity. The performance of such an identiﬁcation method has not been analytically characterized.
In our work  we presented the methodology for identifying dendritic processing in simple [Filter]-
[Spiking Neuron] models from a single input stimulus. The discussed spiking neurons include the
ideal IAF neuron  the leaky IAF neuron and the threshold-and-ﬁre neuron. However  the methods
presented in this paper are applicable to many other spiking neuron models as well.
The algorithm of the Neuron Identiﬁcation Machine is based on the natural assumption that the den-
dritic processing ﬁlter has a ﬁnite temporal support. Therefore  its action on the input stimulus can
be observed in non-overlapping temporal windows. The ﬁlter is recovered with arbitrary precision
from an input/output pair of a neural circuit  where the input is a single signal assumed to be ban-
dlimited. Remarkably  the algorithm converges for a very small number of spikes. This should be
contrasted with the reverse correlation and spike-triggered average methods [20].
Finally  the work presented here will be extended to spiking neurons with random parameters.

Acknowledgement

The work presented here was supported by NIH under the grant number R01DC008701-01.

8

051015202530−100−80−60−40−20020(a)MSE(ˆh Ph)vs.thenumberoftemporalwindowsNumberofwindowsNMSE(ˆh Ph) [dB]  102030405060708090100110120130140150−70−60−50−40−30−20−100(b)MSE(ˆh h)vs.theinputsignalbandwidthInputsignalbandwidthΩ/(2π) [Hz]MSE(ˆh h) [dB]  D=20HzD=40HzD=60HzD=60Hz N=10  hˆh  hˆhΩ/(πD1)Ω/(πD2)Ω/(πD3)References
[1] Maria N. Geffen  Bede M. Broome  Gilles Laurent  and Markus Meister. Neural encoding of rapidly

ﬂuctuating odors. Neuron  61(4):570–586  2009.

[2] Sean J. Slee  Matthew H. Higgs  Adrienne L. Fairhall  and William J. Spain. Two-dimensional time

coding in the auditory brainstem. The Journal of Neuroscience  25(43):9978–9988  October 2005.

[3] Nicole C. Rust  Odelia Schwartz  J. Anthony Movshon  and Eero P. Simoncelli. Spatiotemporal elements

of macaque V1 receptive ﬁelds. Neuron  Vol. 46:945–956  2005.

[4] Daniel P. Dougherty  Geraldine A. Wright  and Alice C. Yew. Computational model of the cAMP-
mediated sensory response and calcium-dependent adaptation in vertebrate olfactory receptor neurons.
Proceedings of the National Academy of Sciences  102(30):0415–10420  2005.

[5] Yuqiao Gu  Philippe Lucas  and Jean-Pierre Rospars. Computational model of the insect pheromone

transduction cascade. PLoS Computational Biology  5(3)  2009.

[6] Zhuoyi Song  Daniel Coca  Stephen Billings  Marten Postma  Roger C. Hardie  and Mikko Juusola.
Biophysical Modeling of a Drosophila Photoreceptor. In Lecture Notes In Computer Science.  volume
5863 of Proceedings of the 16th International Conference on Neural Information Processing: Part I  pages
57 – 71. Springer-Verlag  2009.

[7] E.J. Chichilnisky. A simple white noise analysis of neuronal light responses. Network: Computation in

Neural Systems  12:199–213  2001.

[8] Jonathan W. Pillow and Eero P. Simoncelli. Dimensionality reduction in neural models: An information-
theoretic generalization of spike-triggered average and covariance analysis. Journal of Vision  6:414–428 
2006.

[9] J J Eggermont  A M H J Aersten  and P I M Johannesma. Quantitative characterization procedure for

auditory neurons based on the spectra-temporal receptive ﬁeld. Hearing Research  10  1983.

[10] Anmo J. Kim  Aurel A. Lazar  and Yevgeniy B. Slutskiy. System identiﬁcation of Drosophila olfactory

sensory neurons. Journal of Computational Neuroscience  2010.

[11] Sydney Cash and Rafael Yuste. Linear summation of excitatory inputs by CA1 pyramidal neurons.

Neuron  22:383–394  1999.

[12] Jonathan Pillow. Neural coding and the statistical modeling of neuronal responses. PhD thesis  New York

University  May 2005.

[13] Aurel A. Lazar and Laszlo T. T´oth. Perfect recovery and sensitivity analysis of time encoded bandlimited
signals. IEEE Transactions on Circuits and Systems-I: Regular Papers  51(10):2060–2073  October 2004.
[14] Aurel A. Lazar and Eftychios A. Pnevmatikakis. Faithful representation of stimuli with a population of

integrate-and-ﬁre neurons. Neural Computation  20(11):2715–2744  November 2008.

[15] Justin Keat  Pamela Reinagel  R. Clay Reid  and Markus Meister. Predicting every spike: A model for the

responses of visual neurons. Neuron  30:803–817  June 2001.

[16] Michael Reed and Barry Simon. Methods of Modern Mathematical Physics  Vol. 1  Functional Analysis.

Academic Press  1980.

[17] Alain Berlinet and Christine Thomas-Agnan. Reproducing Kernel Hilbert Spaces in Probability and

Statistics. Kluwer Academic Publishers  2004.

[18] Ole Christensen. An Introduction to Frames and Riesz Bases. Applied and Numerical Harmonic Analysis.

Birkh¨auser  2003.

[19] Edward H. Adelson and James R. Bergen. Spatiotemporal energy models for the perception of motion.

Journal of Optical Society of America  2(2)  February 1985.

[20] Michael C.-K. Wu  Stephen V. David  and Jack L. Gallant. Complete functional characterization of

sensory neurons by system identiﬁcation. Annual Reviews of Neuroscience  29:477–505  2006.

9

,Marthinus du Plessis
Gang Niu
Masashi Sugiyama
Kush Bhatia
Himanshu Jain
Purushottam Kar
Manik Varma
Prateek Jain