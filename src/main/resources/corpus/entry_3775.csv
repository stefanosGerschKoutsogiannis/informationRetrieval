2013,Noise-Enhanced Associative Memories,Recent advances in associative memory design through structured pattern sets and graph-based inference algorithms have allowed reliable learning and recall of an exponential number of patterns. Although these designs correct external errors in recall  they assume neurons that compute noiselessly  in contrast to the highly variable neurons in hippocampus and olfactory cortex.  Here we consider associative memories with noisy internal computations and analytically characterize performance. As long as the internal noise level is below a specified threshold  the error probability in the recall phase can be made exceedingly small. More surprisingly  we show that internal noise actually improves the performance of the recall phase. Computational experiments lend additional support to our theoretical analysis. This work suggests a functional benefit to noisy neurons in biological neuronal networks.,Noise-Enhanced Associative Memories

Amin Karbasi

Amir Hesam Salavati

Swiss Federal Institute of Technology Zurich

Ecole Polytechnique Federale de Lausanne

amin.karbasi@inf.ethz.ch

hesam.salavati@epfl.ch

Amin Shokrollahi

Ecole Polytechnique Federale de Lausanne

amin.shokrollahi@epfl.ch

Lav R. Varshney

IBM Thomas J. Watson Research Center

varshney@alum.mit.edu

Abstract

Recent advances in associative memory design through structured pattern sets and
graph-based inference algorithms allow reliable learning and recall of exponential
numbers of patterns. Though these designs correct external errors in recall  they
assume neurons compute noiselessly  in contrast to highly variable neurons in
hippocampus and olfactory cortex. Here we consider associative memories with
noisy internal computations and analytically characterize performance. As long
as internal noise is less than a speciﬁed threshold  error probability in the recall
phase can be made exceedingly small. More surprisingly  we show internal noise
actually improves performance of the recall phase. Computational experiments
lend additional support to our theoretical analysis. This work suggests a functional
beneﬁt to noisy neurons in biological neuronal networks.

1

Introduction

Hippocampus  olfactory cortex  and other brain regions are thought to operate as associative memo-
ries [1 2]  having the ability to learn patterns from presented inputs  store a large number of patterns 
and retrieve them reliably in the face of noisy or corrupted queries [3–5]. Associative memory mod-
els are designed to have these properties.
Although such information storage and recall seemingly falls into the information-theoretic frame-
work  where an exponential number of messages can be communicated reliably with a linear number
of symbols  classical associative memory models could only store a linear number of patterns [4]. A
primary reason is classical models require memorizing a randomly chosen set of patterns. By enforc-
ing structure and redundancy in the possible set of memorizable patterns—like natural stimuli [6] 
internal neural representations [7]  and error-control codewords—advances in associative memory
design allow storage of an exponential number of patterns [8 9]  just like in communication systems.
Information-theoretic and associative memory models of storage have been used to predict experi-
mentally measurable properties of synapses in the mammalian brain [10 11]. But contrary to the fact
that noise is present in computational operations of the brain [12  13]  associative memory models
with exponential capacities have assumed no internal noise in the computational nodes. The purpose
here is to model internal noise and study whether such associative memories still operate reliably.
Surprisingly  we ﬁnd internal noise actually enhances recall performance  suggesting a functional
role for variability in the brain.
In particular we consider a multi-level  graph code-based  associative memory model [9] and ﬁnd
that even if all components are noisy  the ﬁnal error probability in recall can be made exceedingly
small. We characterize a threshold phenomenon and show how to optimize algorithm parameters
when knowing statistical properties of internal noise. Rather counterintuitively the performance

1

of the memory model improves in the presence of internal neural noise  as observed previously as
stochastic resonance [13  14]. There are mathematical connections to perturbed simplex algorithms
for linear programing [15]  where internal noise pushes the algorithm out of local minima.
The beneﬁt of internal noise has been noted previously in associative memory models with stochastic
update rules  cf. [16]. However  our framework differs from previous approaches in three key as-
pects. First  our memory model is different  which makes extension of previous analysis nontrivial.
Second  and perhaps most importantly  pattern retrieval capacity in previous approaches decreases
with internal noise  cf. [16  Fig. 6.1]  in that increasing internal noise helps correct more external
errors  but also reduces the number of memorizable patterns. In our framework  internal noise does
not affect pattern retrieval capacity (up to a threshold) but improves recall performance. Finally  our
noise model has bounded rather than Gaussian noise  and so a suitable network may achieve perfect
recall despite internal noise.
Reliably storing information in memory systems constructed completely from unreliable compo-
nents is a classical problem in fault-tolerant computing [17–19]  where models have used random
access architectures with sequential correcting networks. Although direct comparison is difﬁcult
since notions of circuit complexity are different  our work also demonstrates that associative mem-
ory architectures constructed from unreliable components can store information reliably.
Building on the idea of structured pattern sets [20]  our associative memory model [9] relies on the
fact that all patterns to be learned lie in a low-dimensional subspace. Learning features of a low-
dimensional space is very similar to autoencoders [21] and has structural similarities to Deep Belief
Networks (DBNs)  particularly Convolutional Neural Networks [22].

2 Associative Memory Model

h =(cid:80)n

Notation and basic structure: In our model  a neuron can assume an integer-valued state from
the set S = {0  . . .   S − 1}  interpreted as the short term ﬁring rate of neurons. A neuron updates
its state based on the states of its neighbor {si}n
i=1 as follows. It ﬁrst computes a weighted sum
i=1 wisi + ζ  where wi is the weight of the link from si and ζ is the internal noise  and then
applies nonlinear function f : R → S to h.
An associative memory is represented by a weighted bipartite graph  G  with pattern neurons and
constraint neurons. Each pattern x = (x1  . . .   xn) is a vector of length n  where xi ∈ S  i =
1  . . .   n. Following [9]  the focus is on recalling patterns with strong local correlation among
entries. Hence  we divide entries of each pattern x into L overlapping sub-patterns of lengths
n1  . . .   nL. Due to overlaps  a pattern neuron can be a member of multiple subpatterns  as in
Fig. 1a. The ith subpattern is denoted x(i) = (x(i)
ni )  and local correlations are assumed to
be in the form of subspaces  i.e. the subpatterns x(i) form a subspace of dimension ki < ni.
We capture the local correlations by learning a set of linear constraints over each subspace corre-
sponding to the dual vectors orthogonal to that subspace. More speciﬁcally  let {w(i)
mi} be
a set of dual vectors orthogonal to all subpatterns x(i) of cluster i. Then:

1   . . .   w(i)

1   . . .   x(i)

y(i)
j = (w(i)

j )T · x(i) = 0 

for all j ∈ {1  . . .   mi} and for all i ∈ {1  . . .   L}.

(1)

Eq. (1) can be rewritten as W (i) · x(i) = 0 where W (i) = [w(i)
mi]T is the matrix of dual
vectors. Now we use a bipartite graph with connectivity matrix determined by W (i) to represent the
subspace constraints learned from subpattern x(i); this graph is called cluster i. We developed an
efﬁcient way of learning W (i) in [9]  also used here. Brieﬂy  in each iteration of learning:

2 | . . .|w(i)

1 |w(i)

1. Pick a pattern x at random from the dataset;
2. Adjust weight vectors w(i)
j

for j = {1  . . .   mi} and i = {1  . . .   L} such that the projection

of x onto w(i)
j

is reduced. Apply a sparsity penalty to favor sparse solutions.

This process repeats until all weights are orthogonal to the patterns in the dataset or the maximum
iteration limit is reached. The learning rule allows us to assume the weight matrices W (i) are known
and satisfy W (i) · x(i) = 0 for all patterns x in the dataset X   in this paper.

2

G(1)

G(2)

G(3)

y1

y2

y3

y4

y5

y6

y7

y8

x(2)
1

x(2)
2

x(2)
3

x(2)
4

(a) Bipartite graph G.

(b) Contraction graph (cid:101)G.

Figure 1: The proposed neural associative memory with overlapping clusters.

For the forthcoming asymptotic analysis  we need to deﬁne a contracted graph (cid:101)G whose connectivity
matrix is denoted(cid:102)W and has size L× n. This is a bipartite graph in which constraints in each cluster
are represented by a single neuron. Thus  if pattern neuron xj is connected to cluster i (cid:102)Wij = 1;
otherwise(cid:102)Wij = 0. We also deﬁne the degree distribution from an edge perspective over (cid:101)G  using
(cid:101)λ(z) = (cid:80)
j(cid:101)ρjzj−1 where(cid:101)λj (resp.  (cid:101)ρj) equals the fraction of edges that

j(cid:101)λjzj and (cid:101)ρ(z) = (cid:80)

connect to pattern (resp.  cluster) nodes of degree j.
Noise model: There are two types of noise in our model: external errors and internal noise. As
mentioned earlier  a neural network should be able to retrieve memorized pattern ˆx from its corrupted
version x due to external errors. We assume the external error is an additive vector of size n  denoted
by z satisfying x = ˆx + z  whose entries assume values independently from {−1  0  +1}1 with
corresponding probabilities p−1 = p+1 = /2 and p0 = 1 − . The realization of the external error
on subpattern x(i) is denoted z(i). Note that the subspace assumption implies W · y = W · z and
W (i) · y(i) = W (i) · z(i) for all i. Neurons also suffer from internal noise. We consider a bounded
noise model  i.e. a random number uniformly distributed in the intervals [−υ  υ] and [−ν  ν] for the
pattern and constraint neurons  respectively (υ  ν < 1).
The goal of recall is to ﬁlter the external error z to obtain the desired pattern x as the correct states
of the pattern neurons. When neurons compute noiselessly  this task may be achieved by exploiting
the fact the set of patterns x ∈ X to satisfy the set of constraints W (i) · x(i) = 0. However  it is not
clear how to accomplish this objective when the neural computations are noisy. Rather surprisingly 
we show that eliminating external errors is not only possible in the presence of internal noise  but
that neural networks with moderate internal noise demonstrate better external noise resilience.
Recall algorithms: To efﬁciently deal with external errors  we use a combination of Alg. 1 and
Alg. 2. The role of Alg. 1 is to correct at least a single external error in each cluster. Without
overlaps between clusters  the error resilience of the network is limited. Alg. 2 exploits the overlaps:
it helps clusters with external errors recover their correct states by using the reliable information
from clusters that do not have external errors. The error resilience of the resulting combination
thereby drastically improves. Now we describe the details of Alg. 1 and Alg. 2 more precisely.
Alg. 1 performs a series of forward and backward iterations in each cluster G(l) to remove (at
least) one external error from its input domain. At each iteration  the pattern neurons locally decide
whether to update their current state: if the amount of feedback received by a pattern neuron exceeds
a threshold  the neuron updates its state  and otherwise remains as is. With abuse of notation  let
us denote messages transmitted by pattern node i and constraint node j at round t by xi(t) and
yj(t)  respectively. In round 0  pattern nodes are initialized by a pattern ˆx  sampled from dataset X  
perturbed by external errors z  i.e.  x(0) = ˆx + z. Thus  for cluster (cid:96) we have x((cid:96))(0) = ˆx((cid:96)) + z((cid:96)) 
where z((cid:96)) is the realization of errors on subpattern x((cid:96)).
In round t  the pattern and constraint neurons update their states using feedback from neighbors.
However since neural computations are faulty  decisions made by neurons may not be reliable. To
minimize effects of internal noise  we use the following update rule for pattern node i in cluster (cid:96):

(cid:40)

x((cid:96))
i (t + 1) =

i (t) − sign(g((cid:96))
x((cid:96))
x((cid:96))
i (t) 

i (t)) 

i (t)| ≥ ϕ

if |g((cid:96))
otherwise 

(2)

1Note that the proposed algorithms also work with larger noise values  i.e. from a set {−a  . . .   a} for some

a ∈ N  see [23]; the ±1 noise model is presented here for simplicity.

3

(cid:80)n(cid:96)

Algorithm 1 Intra-Module Error Correction
Input: Training set X   thresholds ϕ  ψ  iteration tmax
Output: x((cid:96))
1: for t = 1 → tmax do
2:

2   . . .   x((cid:96))
n(cid:96)

1   x((cid:96))

j=1 W ((cid:96))

Forward iteration: Calculate the input h((cid:96))
j + vi  for each neuron y((cid:96))
ij x((cid:96))
i = f (h((cid:96))
(cid:80)m(cid:96)
(cid:80)m(cid:96)
i=1 sign(W ((cid:96))
ij )y((cid:96))
ij |)
i=1 sign(|W ((cid:96))

set y((cid:96))
Backward iteration: Each neuron x((cid:96))
j

g((cid:96))
j =

+ ui.

  ψ).

i

i

i

i =
and

computes

4:

Update state of each pattern neuron j according
to x((cid:96))
5: end for

j ) only if |g((cid:96))

j − sign(g((cid:96))

j = x((cid:96))

| > ϕ.

j

3:

Algorithm 2 Sequential Peeling Algorithm

Input: (cid:101)G  G(1)  G(2)  . . .   G(L).

Output: x1  x2  . . .   xn
1: while there is an unsatisﬁed v((cid:96)) do
for (cid:96) = 1 → L do
2:
3:

If v((cid:96)) is unsatisﬁed  apply Alg. 1
to cluster G(l).
If v((cid:96)) remained unsatisﬁed  revert
state of pattern neurons connected
to v((cid:96)) to their initial state. Other-
wise  keep their current states.

end for
5:
6: end while
7: Declare x1  x2  . . .   xn if all v((cid:96))’s are

satisﬁed. Otherwise  declare failure.

4:

i (t) =(cid:0)(sign(W ((cid:96)))(cid:62) · y((cid:96))(t)(cid:1)

i /d((cid:96))

where ϕ is the update threshold and g((cid:96))
is
the degree of pattern node i in cluster (cid:96)  y((cid:96))(t) = [y((cid:96))
m(cid:96) (t)] is the vector of messages
transmitted by the constraint neurons in cluster (cid:96)  and ui is the random noise affecting pattern node
i. Basically  the term g((cid:96))
i (t) reﬂects the (average) belief of constraint nodes connected to pattern
neuron i about its correct value. If g((cid:96))
i (t) is larger than a speciﬁed threshold ϕ it means most of
the connected constraints suggest the current state x((cid:96))
i (t) is not correct  hence  a change should be
made. Note this average belief is diluted by the internal noise of neuron i. As mentioned earlier  ui
is uniformly distributed in the interval [−υ  υ]  for some υ < 1. On the constraint side  the update
rule is:

i + ui.2 Here  d((cid:96))

1 (t)  . . .   y((cid:96))

i

y((cid:96))
i (t) = f (h((cid:96))

i (t)  ψ) =

i (t) ≤ ψ

(3)

+1 
i (t) = (cid:0)W ((cid:96)) · x((cid:96))(t)(cid:1)

i (t) ≥ ψ
if h((cid:96))
if − ψ ≤ h((cid:96))

0 
−1  otherwise 

where ψ is the update threshold and h((cid:96))
i + vi. Here  x((cid:96))(t) =
[x((cid:96))
1 (t)  . . .   x((cid:96))
n(cid:96) (t)] is the vector of messages transmitted by the pattern neurons and vi is the ran-
dom noise affecting node i. As before  we consider a bounded noise model for vi  i.e.  it is uniformly
distributed in the interval [−ν  ν] for some ν < 1.3
The error correction ability of Alg. 1 is fairly limited  as determined analytically and through sim-
ulations [23]. In essence  Alg. 1 can correct one external error with high probability  but degrades
terribly against two or more external errors. Working independently  clusters cannot correct more
than a few external errors  but their combined performance is much better. As clusters overlap  they
help each other in resolving external errors: a cluster whose pattern neurons are in their correct states
can always provide truthful information to neighboring clusters. This property is exploited in Alg. 2
by applying Alg. 1 in a round-robin fashion to each cluster. Clusters either eliminate their internal
noise in which case they keep their new states and can now help other clusters  or revert back to their
original states. Note that by such a scheduling scheme  neurons can only change their states towards
correct values. This scheduling technique is similar in spirit to the peeling algorithm [24].

3 Recall Performance Analysis

Now let us analyze recall error performance. The following lemma shows that if ϕ and ψ are chosen
properly  then in the absence of external errors the constraints remain satisﬁed and internal noise
cannot result in violations. This is a crucial property for Alg. 2  as it allows one to determine whether
i (t + 1) is further mapped to the interval [0  S − 1] by saturating the values below 0 and above
i (t) can be shifted to 0  1  2  instead of −1  0  1 to match our assumption

S − 1 to 0 and S − 1 respectively. The corresponding equations are omitted for brevity.

3Note that although the values of y((cid:96))

2Note that x((cid:96))

that neural states are non-negative  we leave them as such to simplify later analysis.

4

a cluster has successfully eliminated external errors (Step 4 of algorithm) by merely checking the
satisfaction of all constraint nodes.
Lemma 1. In the absence of external errors  the probability that a constraint neuron (resp. pat-
tern neuron) in cluster (cid:96) makes a wrong decision due to its internal noise is given by π((cid:96))
0 =
max

0 = max(cid:0)0  υ−ϕ

(resp. P ((cid:96))

0  ν−ψ

(cid:1)).

(cid:16)

(cid:17)

ν

υ

Proof is given in [23]. In the sequel  we assume ϕ > υ and ψ > ν so that π((cid:96))
0 = 0.
However  an external error combined with internal noise may still push neurons to an incorrect state.
Given the above lemma and our neural architecture  we can prove the following surprising result: in
the asymptotic regime of increasing number of iterations of Alg. 2  a neural network with internal
noise outperforms one without. Let us deﬁne the fraction of errors corrected by the noiseless and
noisy neural network (parametrized by υ and ν) after T iterations of Alg. 2 by Λ(T ) and Λυ ν(T ) 
respectively. Note that both Λ(T ) ≤ 1 and Λυ ν(T ) ≤ 1 are non-decreasing sequences of T . Hence 
their limiting values are well deﬁned: limT→∞ Λ(T ) = Λ∗ and limT→∞ Λυ ν(T ) = Λ∗

0 = 0 and P ((cid:96))

υ ν.

Theorem 2. Let us choose ϕ and ψ so that π((cid:96))
same realization of external errors  we have Λ∗

0 = 0 and P ((cid:96))
υ ν ≥ Λ∗.

0 = 0 for all (cid:96) ∈ {1  . . .   L}. For the

Proof is given in [23]. The high level idea why a noisy network outperforms a noiseless one comes
from understanding stopping sets. These are realizations of external errors where the iterative Alg. 2
cannot correct all of them. We show that the stopping set shrinks as we add internal noise. In other
words  we show that in the limit of T → ∞ the noisy network can correct any error pattern that can
be corrected by the noiseless version and it can also get out of stopping sets that cause the noiseless
network to fail. Thus  the supposedly harmful internal noise will help Alg. 2 to avoid stopping sets.
Thm. 2 suggests the only possible downside with using a noisy network is its possible running time
in eliminating external errors: the noisy neural network may need more iterations to achieve the
same error correction performance. Interestingly  our empirical experiments show that in certain
scenarios  even the running time improves when using a noisy network.
Thm. 2 indicates that noisy neural networks (under our model) outperform noiseless ones  but does
not specify the level of errors that such networks can correct. Now we derive a theoretical upper
bound on error correction performance. To this end  let Pci be the average probability that a cluster
can correct i external errors in its domain. The following theorem gives a simple condition under
which Alg. 2 can correct a linear fraction of external errors (in terms of n) with high probability.
The condition involves ˜λ and ˜ρ  the degree distributions of the contracted graph ˜G.

Theorem 3. Under the assumptions that graph (cid:101)G grows large and it is chosen randomly with degree
distributions given by(cid:101)λ and(cid:101)ρ  Alg. 2 is successful if
· di−1(cid:101)ρ(1 − z)

 < z  f or z ∈ [0  ].

1 −(cid:88)

(cid:101)λ

Pci

(4)

dzi−1

zi−1
i!

i≥1

Proof is given in [23] and is based on the density evolution technique [25]. Thm. 3 states that for any
fraction of errors Λυ ν ≤ Λ∗
υ ν that satisﬁes the above recursive formula  Alg. 2 will be successful
with probability close to one. Note that the ﬁrst ﬁxed point of the above recursive equation dictates
the maximum fraction of errors Λ∗
υ ν that our model can correct. For the special case of Pc1 = 1 and

Pci = 0 ∀i > 1  we obtain (cid:101)λ1 −(cid:101)ρ(1 − z)) < z  the same condition given in [9]. Thm. 3 takes into

account the contribution of all Pci terms and as we will see  their values change as we incorporate
the effect of internal noise υ and ν. Our results show that the maximum value of Pci does not
occur when the internal noise is equal to zero  i.e. υ = ν = 0  but instead when the neurons are
contaminated with internal noise! As an example  Fig. 2 illustrates how Pci behaves as a function
of υ in the network considered (note that maximum values are not at υ = 0). This ﬁnding suggests
that even individual clusters are able to correct more errors in the presence of internal noise.

5

s
r
o
r
r
e

.
t
x
e
g
n
i
t
c
e
r
r
o
c

.

b
o
r
P

1

0.8

0.6

0.4

0.2

0

υ = 0  ν = 0-Sim
υ = 0  ν = 0-Thr
υ = 0.2  ν = 0-Sim
υ = 0.2  ν = 0-Thr
υ = 0.4  ν = 0-Sim
υ = 0.4  ν = 0-Thr
υ = 0.6  ν = 0-Sim
υ = 0.6  ν = 0-Thr

Pc1
Pc2
Pc3
Pc4

R
E
S
l
a
n
i
F

0.15

0.10

0.05

0.00

0 0.1 0.2 0.3 0.4 0.5 0.6 0.7

υ

0.00

0.05

0.10



Figure 2: The value of Pci as a function of pat-
tern neurons noise υ for i = 1  . . .   4. Noise at
constraint neurons is assumed as zero (ν = 0).

Figure 3: The ﬁnal SER for a network with n =
400  L = 50 cf. [9]. The blue curves correspond
to the noiseless neural network.

3.1 Simulations

Now we consider simulation results for a ﬁnite system. To learn the subspace constraints (1) for each
cluster G((cid:96)) we use the learning algorithm in [9]. Henceforth  we assume that the weight matrix W
is known and given. In our setup  we consider a network of size n = 400 with L = 50 clusters. We
have 40 pattern nodes and 20 constraint nodes in each cluster  on average. External error is modeled
by randomly generated vectors z with entries ±1 with probability  and 0 otherwise. Vector z is
added to the correct patterns  which satisfy (1). For recall  Alg. 2 is used and results are reported
in terms of Symbol Error Rate (SER) as the level of external error () or internal noise (υ  ν) is
changed; this involves counting positions where the output of Alg. 2 differs from the correct pattern.

3.1.1 Symbol Error Rate as a function of Internal Noise

Fig. 3 illustrates the ﬁnal SER of our algorithm for different values of υ and ν. Recall that υ and
ν quantify the level of noise in pattern and constraint neurons  respectively. Dashed lines in Fig. 3
are simulation results whereas solid lines are theoretical upper bounds provided in this paper. As
evident  there is a threshold phenomenon such that SER is negligible for  ≤ ∗ and grows beyond
this threshold. As expected  simulation results are better than the theoretical bounds. In particular 
the gap is relatively large as υ moves towards one.
A more interesting trend in Fig. 3 is the fact that internal noise helps in achieving better performance 
as predicted by theoretical analysis (Thm. 2). Notice how ∗ moves towards one as ν increases.
This phenomenon is examined more closely in Figs. 4a and 4b where  is ﬁxed to 0.125 while υ
and ν vary. As we see  a moderate amount of internal noise at both pattern and constraint neurons
improves performance. There is an optimum point (υ∗  ν∗) for which the SER reaches its minimum.
Fig. 4b indicates for instance that ν∗ ≈ 0.25  beyond which SER deteriorates.

3.2 Recall Time as a function of Internal Noise

Fig. 5 illustrates the number of iterations performed by Alg. 2 for correcting the external errors when
 is ﬁxed to 0.075. We stop whenever the algorithm corrects all external errors or declare a recall
error if all errors were not corrected in 40 iterations. Thus  the corresponding areas in the ﬁgure
where the number of iterations reaches 40 indicates decoding failure. Figs. 6a and 6b are projected
versions of Fig. 5 and show the average number of iterations as a function of υ and ν  respectively.
The amount of internal noise drastically affects the speed of Alg. 2. First  from Fig. 5 and 6b observe
that running time is more sensitive to noise at constraint neurons than pattern neurons and that the
algorithms become slower as noise at constraint neurons is increased. In contrast  note that internal
noise at the pattern neurons may improve the running time  as seen in Fig. 6a.

6

R
E
S
l
a
n
i
F

0.10

0.05

0.00

ν = 0
ν = 0.1
ν = 0.3
ν = 0.5

R
E
S
l
a
n
i
F

0.10

0.05

0.00

υ = 0
υ = 0.1
υ = 0.2
υ = 0.5

0

0.1

0.2

0.3

0.4

υ

0

0.1

0.2

0.3

0.4

ν

(a) Final SER as function of υ for  = 0.125.

(b) The effect of ν on the ﬁnal SER for  = 0.125

Figure 4: The ﬁnal SER vs. internal noise parameters at pattern and constraint neurons for  = 0.125

s
n
o
i
t
a
r
e
t
I

.
o
N

.
g
v
A

40.00

20.00

0.00

0.4

0.2

ν

0

0.5

0.4

0.3

0.2

υ

0.1

0

Figure 5: The effect of internal noise on the number of iterations of Alg. 2 when  = 0.075.

Note that the results presented here are for the case where the noiseless decoder succeeds as well and
its average number of iterations is pretty close to the optimal value (see Fig. 5). In [23]  we provide
additional results corresponding to  = 0.125  where the noiseless decoder encounters stopping sets
while the noisy decoder is still capable of correcting external errors; there we see that the optimal
running time occurs when the neurons have a fair amount of internal noise.
In [23] we also provide results of a study for a slightly modiﬁed scenario where there is only internal
noise and no external errors. Furthermore  ϕ < υ. Thus  the internal noise can now cause neurons to
make wrong decisions  even in the absence of external errors. There  we witness the more familiar
phenomenon where increasing the amount of internal noise results in a worse performance. This
ﬁnding emphasizes the importance of choosing update threshold ϕ and ψ according to Lem. 1.

4 Pattern Retrieval Capacity

For completeness  we review pattern retrieval capacity results from [9] to show that the proposed
model is capable of memorizing an exponentially large number of patterns. First  note that since the
patterns form a subspace  the number of patterns C does not have any effect on the learning or recall
algorithms (except for its obvious inﬂuence on the learning time). Thus  in order to show that the
pattern retrieval capacity is exponential in n  all we need to demonstrate is that there exists a training
set X with C patterns of length n for which C ∝ arn  for some a > 1 and 0 < r.
Theorem 4 ( [9]). Let X be a C × n matrix  formed by C vectors of length n with entries from the
set S. Furthermore  let k = rn for some 0 < r < 1. Then  there exists a set of vectors for which
C = arn  with a > 1  and rank(X ) = k < n.

7

40

10

s
n
o
i
t
a
r
e
t
I

.

o
N

.

g
v
A

ν = 0
ν = 0.2
ν = 0.3
ν = 0.5

40

10

s
n
o
i
t
a
r
e
t
I

.

o
N

.

g
v
A

υ = 0
υ = 0.2
υ = 0.3
υ = 0.5

0

0.1

0.2

0.3

0.4

υ

0

0.1

0.2

0.3

0.4

ν

(a) Effect of internal noise at pattern neurons side.

(b) Effect of internal noise at constraint neurons side.

Figure 6: The effect of internal noise on the number of iterations performed by Alg. 2  for different
values of υ and ν with  = 0.075. The average iteration number of 40 indicate the failure of Alg. 2.
The proof is constructive: we create a dataset X such that it can be memorized by the proposed
neural network and satisﬁes the required properties  i.e. the subpatterns form a subspace and pattern
entries are integer values from the set S = {0  . . .   S − 1}. The complete proof can be found in [9].

5 Discussion

We have demonstrated that associative memories with exponential capacity still work reliably even
when built from unreliable hardware  addressing a major problem in fault-tolerant computing and
further arguing for the viability of associative memory models for the (noisy) mammalian brain.
After all  brain regions modeled as associative memories  such as the hippocampus and the olfactory
cortex  certainly do display internal noise [12  13  26]. The linear-nonlinear computations of Alg. 1
are certainly biologically plausible  but implementing the state reversion computation of Alg. 2 in a
biologically plausible way remains an open question.
We found a threshold phenomenon for reliable operation  which manifests the tradeoff between
the amount of internal noise and the amount of external noise that the system can handle. In fact 
we showed that internal noise actually improves the performance of the network in dealing with
external errors  up to some optimal value. This is a manifestation of the stochastic facilitation [13] or
noise enhancement [14] phenomenon that has been observed in other neuronal and signal processing
systems  providing a functional beneﬁt to variability in the operation of neural systems.
The associative memory design developed herein uses thresholding operations in the message-
passing algorithm for recall; as part of our investigation  we optimized these neural ﬁring thresholds
based on the statistics of the internal noise. As noted by Sarpeshkar in describing the properties of
analog and digital computing circuits  “In a cascade of analog stages  noise starts to accumulate.
Thus  complex systems with many stages are difﬁcult to build. [In digital systems] Round-off error
does not accumulate signiﬁcantly for many computations. Thus  complex systems with many stages
are easy to build” [27]. One key to our result is capturing this beneﬁt of digital processing (thresh-
olding to prevent the build up of errors due to internal noise) as well as a modular architecture which
allows us to correct a linear number of external errors (in terms of the pattern length).
This paper focused on recall  however learning is the other critical stage of associative memory op-
eration. Indeed  information storage in nervous systems is said to be subject to storage (or learning)
noise  in situ noise  and retrieval (or recall) noise [11  Fig. 1]. It should be noted  however  there
is no essential loss by combining learning noise and in situ noise into what we have called external
error herein  cf. [19  Fn. 1 and Prop. 1]. Thus our basic qualitative result extends to the setting where
the learning and stored phases are also performed with noisy hardware.
Going forward  it is of interest to investigate other neural information processing models that ex-
plicitly incorporate internal noise and see whether they provide insight into observed empirical phe-
nomena. As an example  we might be able to understand the threshold phenomenon observed in
the SER of human telegraph operators under heat stress [28  Fig. 2]  by invoking a thermal internal
noise explanation.

8

References
[1] A. Treves and E. T. Rolls  “Computational analysis of the role of the hippocampus in memory ” Hip-

pocampus  vol. 4  pp. 374–391  Jun. 1994.

[2] D. A. Wilson and R. M. Sullivan  “Cortical processing of odor objects ” Neuron  vol. 72  pp. 506–519 

Nov. 2011.

[3] J. J. Hopﬁeld  “Neural networks and physical systems with emergent collective computational abilities ”

Proc. Natl. Acad. Sci. U.S.A.  vol. 79  pp. 2554–2558  Apr. 1982.

[4] R. J. McEliece  E. C. Posner  E. R. Rodemich  and S. S. Venkatesh  “The capacity of the Hopﬁeld asso-

ciative memory ” IEEE Trans. Inf. Theory  vol. IT-33  pp. 461–482  1987.

[5] D. J. Amit and S. Fusi  “Learning in neural networks with material synapses ” Neural Comput.  vol. 6  pp.

957–982  Sep. 1994.

[6] B. A. Olshausen and D. J. Field  “Sparse coding of sensory inputs ” Curr. Opin. Neurobiol.  vol. 14  pp.

481–487  Aug. 2004.

[7] A. A. Koulakov and D. Rinberg  “Sparse incomplete representations: A potential role of olfactory granule

cells ” Neuron  vol. 72  pp. 124–136  Oct. 2011.

[8] A. H. Salavati and A. Karbasi  “Multi-level error-resilient neural networks ” in Proc. 2012 IEEE Int. Symp.

Inf. Theory  Jul. 2012  pp. 1064–1068.

[9] A. Karbasi  A. H. Salavati  and A. Shokrollahi  “Iterative learning and denoising in convolutional neural

associative memories ” in Proc. 30th Int. Conf. Mach. Learn. (ICML 2013)  Jun. 2013  pp. 445–453.

[10] N. Brunel  V. Hakim  P. Isope  J.-P. Nadal  and B. Barbour  “Optimal information storage and the distri-

bution of synaptic weights: Perceptron versus Purkinje cell ” Neuron  vol. 43  pp. 745–757  2004.

[11] L. R. Varshney  P. J. Sj¨ostr¨om  and D. B. Chklovskii  “Optimal information storage in noisy synapses

under resource constraints ” Neuron  vol. 52  pp. 409–423  Nov. 2006.

[12] C. Koch  Biophysics of Computation. New York: Oxford University Press  1999.
[13] M. D. McDonnell and L. M. Ward  “The beneﬁts of noise in neural systems: bridging theory and experi-

ment ” Nat. Rev. Neurosci.  vol. 12  pp. 415–426  Jul. 2011.

[14] H. Chen  P. K. Varshney  S. M. Kay  and J. H. Michels  “Theory of the stochastic resonance effect in
signal detection: Part I–ﬁxed detectors ” IEEE Trans. Signal Process.  vol. 55  pp. 3172–3184  Jul. 2007.
[15] D. A. Spielman and S.-H. Teng  “Smoothed analysis of algorithms: Why the simplex algorithm usually

takes polynomial time ” J. ACM  vol. 51  pp. 385–463  May 2004.

[16] D. J. Amit  Modeling Brain Function. Cambridge: Cambridge University Press  1992.
[17] M. G. Taylor  “Reliable information storage in memories designed from unreliable components ” Bell

Syst. Tech. J.  vol. 47  pp. 2299–2337  Dec. 1968.

[18] A. V. Kuznetsov  “Information storage in a memory assembled from unreliable components ” Probl. Inf.

Transm.  vol. 9  pp. 100–114  July-Sept. 1973.

[19] L. R. Varshney  “Performance of LDPC codes under faulty iterative decoding ” IEEE Trans. Inf. Theory 

vol. 57  pp. 4427–4444  Jul. 2011.

[20] V. Gripon and C. Berrou  “Sparse neural networks with large learning diversity ” IEEE Trans. Neural

Netw.  vol. 22  pp. 1087–1096  Jul. 2011.

[21] P. Vincent  H. Larochelle  Y. Bengio  and P.-A. Manzagol  “Extracting and composing robust features with
denoising autoencoders ” in Proc. 25th Int. Conf. Mach. Learn. (ICML 2008)  Jul. 2008  pp. 1096–1103.
[22] Q. V. Le  J. Ngiam  Z. Chen  D. Chia  P. W. Koh  and A. Y. Ng  “Tiled convolutional neural networks ” in
Advances in Neural Information Processing Systems 23  J. Lafferty  C. K. I. Williams  J. Shawe-Taylor 
R. S. Zemel  and A. Culotta  Eds. Cambridge  MA: MIT Press  2010  pp. 1279–1287.

[23] A. Karbasi  A. H. Salavati  A. Shokrollahi  and L. R. Varshney  “Noise-enhanced associative memories ”

arXiv  2013.

[24] M. G. Luby  M. Mitzenmacher  M. A. Shokrollahi  and D. A. Spielman  “Efﬁcient erasure correcting

codes ” IEEE Trans. Inf. Theory  vol. 47  pp. 569–584  Feb. 2001.

[25] T. Richardson and R. Urbanke  Modern Coding Theory. Cambridge: Cambridge University Press  2008.
[26] M. Yoshida  H. Hayashi  K. Tateno  and S. Ishizuka  “Stochastic resonance in the hippocampal CA3–CA1

model: a possible memory recall mechanism ” Neural Netw.  vol. 15  pp. 1171–1183  Dec. 2002.

[27] R. Sarpeshkar  “Analog versus digital: Extrapolating from electronics to neurobiology ” Neural Comput. 

vol. 10  pp. 1601–1638  Oct. 1998.

[28] N. H. Mackworth  “Effects of heat on wireless telegraphy operators hearing and recording Morse mes-

sages ” Br. J. Ind. Med.  vol. 3  pp. 143–158  Jul. 1946.

9

,Amin Karbasi
Amir Hesam Salavati
Amin Shokrollahi
Lav Varshney
Zhoutong Zhang
Qiujia Li
Zhengjia Huang
Jiajun Wu
Josh Tenenbaum
Bill Freeman