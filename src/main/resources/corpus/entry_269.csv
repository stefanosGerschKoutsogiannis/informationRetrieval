2012,A lattice filter model of the visual pathway,Early stages of visual processing are thought to decorrelate  or whiten  the incoming temporally varying signals. Because the typical correlation time of natural stimuli  as well as the extent of temporal receptive fields of lateral geniculate nucleus (LGN) neurons  is much greater than neuronal time constants  such decorrelation must be done in stages combining contributions of multiple neurons. We propose to model temporal decorrelation in the visual pathway with the lattice filter  a signal processing device for stage-wise decorrelation of temporal signals. The stage-wise architecture of the lattice filter maps naturally onto the visual pathway (photoreceptors -> bipolar cells -> retinal ganglion cells -> LGN) and its filter weights can be learned using Hebbian rules in a stage-wise sequential manner. Moreover  predictions of neural activity from the lattice filter model are consistent with physiological measurements in LGN neurons and fruit fly second-order visual neurons. Therefore  the lattice filter model is a useful abstraction that may help unravel visual system function.,A lattice ﬁlter model of the visual pathway

Karol Gregor

Dmitri B. Chklovskii

Janelia Farm Research Campus  HHMI

19700 Helix Drive  Ashburn  VA

{gregork  mitya}@janelia.hhmi.org

Abstract

Early stages of visual processing are thought to decorrelate  or whiten  the incom-
ing temporally varying signals. Motivated by the cascade structure of the visual
pathway (retina → lateral geniculate nucelus (LGN) → primary visual cortex  V1)
we propose to model its function using lattice ﬁlters - signal processing devices
for stage-wise decorrelation of temporal signals. Lattice ﬁlter models predict neu-
ronal responses consistent with physiological recordings in cats and primates. In
particular  they predict temporal receptive ﬁelds of two different types resembling
so-called lagged and non-lagged cells in the LGN. Moreover  connection weights
in the lattice ﬁlter can be learned using Hebbian rules in a stage-wise sequential
manner reminiscent of the neuro-developmental sequence in mammals. In addi-
tion  lattice ﬁlters can model visual processing in insects. Therefore  lattice ﬁlter
is a useful abstraction that captures temporal aspects of visual processing.

Our sensory organs face an ongoing barrage of stimuli from the world and must transmit as much
information about them as possible to the rest of the brain [1]. This is a formidable task because  in
sensory modalities such as vision  the dynamic range of natural stimuli (more than three orders of
magnitude) greatly exceeds the dynamic range of relay neurons (less than two orders of magnitude)
[2]. The reason why high ﬁdelity transmission is possible at all is that the continuity of objects
in the physical world leads to correlations in natural stimuli  which imply redundancy.
In turn 
such redundancy can be eliminated by compression performed by the front end of the visual system
leading to the reduction of the dynamic range [3  4].
A compression strategy appropriate for redundant natural stimuli is called predictive coding [5  6  7].
In predictive coding  a prediction of the incoming signal value is computed from past values delayed
in the circuit. This prediction is subtracted from the actual signal value and only the prediction
error is transmitted. In the absence of transmission noise such compression is lossless as the original
signal could be decoded on the receiving end by inverting the encoder. If predictions are accurate  the
dynamic range of the error is much smaller than that of the natural stimuli. Therefore  minimizing
dynamic range using predictive coding reduces to optimizing prediction.
Experimental support for viewing the front end of the visual system as a predictive encoder comes
from the measurements of receptive ﬁelds [6  7]. In particular  predictive coding suggests that  for
natural stimuli  the temporal receptive ﬁelds should be biphasic and the spatial receptive ﬁelds -
center-surround. These predictions are born out by experimental measurements in retinal ganglion
cells  [8]  lateral geniculate nucleus (LGN) neurons [9] and ﬂy second order visual neurons called
large monopolar cells (LMCs) [2]. In addition  the experimentally measured receptive ﬁelds vary
with signal-to-noise ratio as would be expected from optimal prediction theory [6]. Furthermore 
experimentally observed whitening of the transmitted signal [10] is consistent with removing corre-
lated components from the incoming signals [11].
As natural stimuli contain correlations on time scales greater than hundred milliseconds  experimen-
tally measured receptive ﬁelds of LGN neurons are equally long [12]. Decorrelation over such long
time scales requires equally long delays. How can such extended receptive ﬁeld be produced by

1

biological neurons and synapses whose time constants are typically less than hundred milliseconds
[13]?
The ﬁeld of signal processing offers a solution to this problem in the form of a device called a lattice
ﬁlter  which decorrelates signals in stages  sequentially adding longer and longer delays [14  15  16 
17]. Motivated by the cascade structure of visual systems [18]  we propose to model decorrelation
in them by lattice ﬁlters. Naturally  visual systems are more complex than lattice ﬁlters and perform
many other operations. However  we show that the lattice ﬁlter model explains several existing
observations in vertebrate and invertebrate visual systems and makes testable predictions. Therefore 
we believe that lattice ﬁlters provide a convenient abstraction for modeling temporal aspects of visual
processing.
This paper is organized as follows. First  we brieﬂy summarize relevant results from linear prediction
theory. Second  we explain the operation of the lattice ﬁlter in discrete and continuous time. Third 
we compare lattice ﬁlter predictions with physiological measurements.

1 Linear prediction theory

Despite the non-linear nature of neurons and synapses  the operation of some neural circuits in
vertebrates [19] and invertebrates [20] can be described by a linear systems theory. The advantage
of linear systems is that optimal circuit parameters may be obtained analytically and the results are
often intuitively clear. Perhaps not surprisingly  the ﬁeld of signal processing relies heavily on the
linear prediction theory  offering a convenient framework [15  16  17]. Below  we summarize the
results from linear prediction that will be used to explain the operation of the lattice ﬁlter.
Consider a scalar sequence y = {yt} where time t = 1  . . .   n. Suppose that yt at each time
point depends on side information provided by vector zt. Our goal is to generate a series of linear
predictions  ˆyt from the vector zt  ˆyt = w · zt. We deﬁne a prediction error as:

and look for values of w that minimize mean squared error:

et = yt − ˆyt = yt − w · zt

(cid:88)

t

(cid:88)

t

(cid:104)e2(cid:105) =

1
nt

e2
t =

1
nt

(yt − w · zt)2.

(1)

(2)

The weight vector  w is optimal for prediction of sequence y from sequence z if and only if the
prediction error sequence e = y − w · z is orthogonal to each component of vector z:

(cid:104)ez(cid:105) = 0.

(3)

When the whole series y is given in advance  i.e.
in the ofﬂine setting  these so-called normal
equations can be solved for w  for example  by Gaussian elimination [21]. However  in signal
processing and neuroscience applications  another setting called online is more relevant: At every
time step t  prediction ˆyt must be made using only current values of zt and w. Furthermore  after a
prediction is made  w is updated based on the prediction ˆyt and observed yt  zt .
In the online setting  an algorithm called stochastic gradient descent is often used  where  at each
time step  w is updated in the direction of negative gradient of e2
t :
w → w − η∇w(yt − w · zt)2.

(4)

This leads to the following weight update  known as least mean square (LMS) [15]  for predicting
sequence y from sequence z:

(5)
where η is the learning rate. The value of η represents the relative inﬂuence of more recent obser-
vations compared to more distant ones. The larger the learning rate the faster the system adapts to
recent observations and less past it remembers.
In this paper  we are interested in predicting a current value xt of sequence x from its past values
xt−1  . . .   xt−k restricted by the prediction order k > 0:

w → w + ηetzt 

ˆxt = wk · (xt−1  . . .   xt−k)T .

(6)

2

This problem is a special case of the online linear prediction framework above  where yt = xt 
zt = (xt−1  . . .   xt−k)T . Then the gradient update is given by:

w → wk + ηet(xt−1  . . .   xt−k)T .

(7)

While the LMS algorithm can ﬁnd the weights that optimize linear prediction (6)  the ﬁlter wk has
a long temporal extent making it difﬁcult to implement with neurons and synapses.

2 Lattice ﬁlters
One way to generate long receptive ﬁelds in circuits of biological neurons is to use a cascade ar-
chitecture  known as the lattice ﬁlter  which calculates optimal linear predictions for temporal se-
quences and transmits prediction errors [14  15  16  17]. In this section  we explain the operation of
a discrete-time lattice ﬁlter  then adapt it to continuous-time operation.

2.1 Discrete-time implementation
The ﬁrst stage of the lattice ﬁlter  Figure 1  calculates the error of the ﬁrst order optimal prediction
(i.e. only using the preceding element of the sequence)  the second stage uses the output of the ﬁrst
stage and calculates the error of the second order optimal prediction (i.e. using only two previous
values) etc. To make such stage-wise error computations possible the lattice ﬁlter calculates at every
stage not only the error of optimal prediction of xt from past values xt−1  . . .   xt−k  called forward
error 

(8)
but  perhaps non-intuitively  also the error of optimal prediction of a past value xt−k from the more
recent values xt−k+1  . . .   xt  called backward error:

t = xt − wk · (xt−1  . . .   xt−k)T  
f k

t = xt−k − w
bk

(cid:48)k · (xt−k+1  . . .   xt)T  

(9)

(cid:48)k are the weights of the optimal prediction.

t = xt − u1xt−1 as well as the backward error b1

t of optimal prediction of xt
t of optimal prediction of xt−1 from
t = xt−1 − v1xt  Figure 1. Here  we assume that coefﬁcients u1 and v1 that give optimal linear

where wk and w
For example  the ﬁrst stage of the ﬁlter calculates the forward error f 1
from xt−1: f 1
xt: b1
prediction are known and return to learning them below.
Each following stage of the lattice ﬁlter performs a stereotypic operation on its inputs  Figure 1. The
k-th stage (k > 1) receives forward  f k−1
  errors from the previous stage 
delays backward error by one time step and computes a forward error:

  and backward  bk−1

t

t

t

t

t

.

(10)

(11)

t − ukbk−1
t−1
t−1 . In addition  each stage computes a backward
t−1 − vkf k−1

t = f k−1
f k
of the optimal linear prediction of f k−1
from bk−1
error
t = bk−1
bk
of the optimal linear prediction of bk−1
t−1 from f k−1
As can be seen in Figure 1  the lattice ﬁlter contains forward prediction error (top) and backward
prediction error (bottom) branches  which interact at every stage via cross-links. Operation of the
lattice ﬁlter can be characterized by the linear ﬁlters acting on the input  x  to compute forward
or backward errors of consecutive order  so called prediction-error ﬁlters (blue bars in Figure 1).
Because of delays in the backward error branch the temporal extent of the ﬁlters grows from stage
to stage.
In the next section  we will argue that prediction-error ﬁlters correspond to the measurements of
temporal receptive ﬁelds in neurons. For detailed comparison with physiological measurements we
will use the result that  for bi-phasic prediction-error ﬁlters  such as the ones in Figure 1  the ﬁrst
bar of the forward prediction-error ﬁlter has larger weight  by absolute value  than the combined
weights of the remaining coefﬁcients of the corresponding ﬁlter. Similarly  in backward prediction-
error ﬁlters  the last bar has greater weight than the rest of them combined. This fact arises from
the observation that forward prediction-error ﬁlters are minimum phase  while backward prediction-
error ﬁlters are maximum phase [16  17].

3

Figure 1: Discrete-time lattice ﬁlter performs stage-wise computation of forward and back-
ward prediction errors. In the ﬁrst stage  the optimal prediction of xt from xt−1 is computed by
delaying the input by one time step and multiplying it by u1. The upper summation unit subtracts the
predicted xt from the actual value and outputs prediction error f 1
t . Similarly  the optimal prediction
of xt−1 from xt is computed by multiplying the input by v1. The lower summation unit subtracts
the optimal prediction from the actual value and outputs backward error b1
t . In each following stage
k  the optimal prediction of f k−1
by one time step and
t
multiplying it by uk. The upper summation unit subtracts the prediction from the actual f k−1
and
is computed by
outputs prediction error f k
multiplying it by uk. The lower summation unit subtracts the optimal prediction from the actual
t . Black connections have unitary weights and red connections
value and outputs backward error bk
have learnable negative weights. One can view forward and backward error calculations as applica-
tions of so-called prediction-error ﬁlters (blue) to the input sequence. Note that the temporal extent
of the ﬁlters gets longer from stage to stage.

t . Similarly  the optimal prediction of bk−1

is computed by delaying bk−1

t−1 from f k−1

from bk−1

t

t

t

t

Next  we derive a learning rule for ﬁnding optimal coefﬁcients u and v in the online setting. The uk
is used for predicting f k−1
t−1 and
et = f k

t . By substituting yt = f k−1

t into (5) the update of uk becomes

t−1 to obtain error f k

  zt = bk−1

from bk−1

t

t

uk → uk + ηf k

t bk−1
t−1 .

(12)

Similarly  vk is updated by

vk → vk + ηbk

t f k−1

t

.

(13)
Interestingly  the updates of the weights are given by the product of the activities of outgoing and
incoming nodes of the corresponding cross-links. Such updates are known as Hebbian learning rules
thought to be used by biological neurons [22  23].
Finally  we give a simple proof that  in the ofﬂine setting when the entire sequence x is known  f k
and bk  given by equations (10  11)  are indeed errors of optimal k-th order linear prediction. Let D
be one step time delay operator (Dx)t = xt−1. The induction statement at k is that f k and bk are
k-th order forward and backward errors of optimal linear prediction which is equivalent to f k and bk
being of the form f k = x−wk
(cid:48)k
k x and  from
normal equations (3)  satisfying (cid:104)f kDix(cid:105) = 0 and (cid:104)DbkDix(cid:105) = (cid:104)bkDi−1x(cid:105) = 0 for i = 1  . . .   k.
That this is true for k = 1 directly follows from the deﬁnition of f 1 and b1. Now we assume that
this is true for k − 1 ≥ 1 and show it is true for k. It is easy to see from the forms of f k−1 and bk−1
and from f k = f k−1 − ukDbk−1 that f k has the correct form f k = x − wk
kDkx.
Regarding orthogonality for i = 1  . . .   k − 1 we have (cid:104)f kDix(cid:105) = (cid:104)(f k−1 − ukDbk−1)Dix(cid:105) =
(cid:104)f k−1Dix(cid:105) − uk(cid:104)(Dbk−1)Dix(cid:105) = 0 using the induction assumptions of orhogonality at k − 1. For
the remaining i = k we note that f k is the error of the optimal linear prediction of f k−1 from Dbk−1
and therefore 0 = (cid:104)f kDbk−1(cid:105) = (cid:104)f k(Dkx − w
k−1 Dx)(cid:105) = (cid:104)f kDkx(cid:105) as
(cid:48)k−1
desired. The bk case can be proven similarly.

kDkx and bk = Dkx−w

1 Dk−1x − . . . + w
(cid:48)k−1

1 Dk−1x−. . .−w
(cid:48)k

1 Dx − . . . − wk

1 Dx−. . .−wk

2.2 Continuous-time implementation
The last hurdle remaining for modeling neuronal circuits which operate in continuous time with a
lattice ﬁlter is its discrete-time operation. To obtain a continuous-time implementation of the lattice

4

ﬁlter we cannot simply take the time step size to zero as prediction-error ﬁlters would become
inﬁnitesimally short. Here  we adapt the discrete-time lattice ﬁlter to continous-time operation in
two steps.
First  we introduce a discrete-time Laguerre lattice ﬁlter [24  17] which uses Laguerre polynomials
rather than the shift operator to generate its basis functions  Figure 2. The input signal passes
through a leaky integrator whose leakage constant α deﬁnes a time-scale distinct from the time step
(14). A delay  D  at every stage is replaced by an all-pass ﬁlter  L  (15) with the same constant
α  which preserves the magnitude of every Fourier component of the input but shifts its phase in a
frequency dependent manner. Such all-pass ﬁlter reduces to a single time-step delay when α = 0.
The optimality of a general discrete-time Laguerre lattice ﬁlter can be proven similarly to that for
the discrete-time ﬁlter  simply by replacing operator D with L in the proof of section 2.1.

Figure 2: Continuous-time lattice ﬁlter using Laguerre polynomials. Compared to the discrete-
time version  it contains a leaky integrator  L0 (16) and replaces delays with all-pass ﬁlters  L  (17).
Second  we obtain a continuous-time formulation of the lattice ﬁlter by replacing t − 1 → t − δt 
deﬁning the inverse time scale γ = (1 − α)/δt and taking the limit δt → 0 while keeping γ ﬁxed.
As a result L0 and L are given by:

Discrete time

Continuous time

dL0(x)/dt = −γL0(x) + x
L(x) = x − 2γL0(x)

(14)
L0(x)t = αL0(x)t−1 + xt
L(x)t = α(L(x)t−1 − xt) + xt−1 (15)

(16)
(17)
Representative impulse responses of the continuous Laguerre ﬁlter are shown in Figure 2. Note that 
similarly to the discrete-time case  the area under the ﬁrst (peak) phase is greater than the area under
the second (rebound) phase in the forward branch and the opposite is true in the backward branch.
Moreover  the temporal extent of the rebound is greater than that of the peak not just in the forward
branch like in the basic discrete-time implementation but also in the backward branch. As will be
seen in the next section  these predictions are conﬁrmed by physiological recordings.

3 Experimental evidence for the lattice ﬁlter in visual pathways

In this section we demonstrate that physiological measurements from visual pathways in vertebrates
and invertebrates are consistent with the predictions of the lattice ﬁlter model. For the purpose of
modeling visual pathways  we identify summation units of the lattice ﬁlter with neurons and propose
that neural activity represents forward and backward errors.
In the ﬂy visual pathway neuronal
activity is represented by continuously varying graded potentials. In the vertebrate visual system 
all neurons starting with ganglion cells are spiking and we identify their ﬁring rate with the activity
in the lattice ﬁlter.

3.1 Mammalian visual pathway
In mammals  visual processing is performed in stages. In the retina  photoreceptors synapse onto
bipolar cells  which in turn synapse onto retinal ganglion cells (RGCs). RGCs send axons to the
LGN  where they synapse onto LGN relay neurons projecting to the primary visual cortex  V1.
In addition to this feedforward pathway  at each stage there are local circuits involving (usually
inhibitory) inter-neurons such as horizontal and amacrine cells in the retina. Neurons of each class

5

come in many types  which differ in their connectivity  morphology and physiological response. The
bewildering complexity of these circuits has posed a major challenge to visual neuroscience.

Figure 3: Electrophysiologically measured temporal receptive ﬁelds get progressively longer
along the cat visual pathway. Left: A cat LGN cell (red) has a longer receptive ﬁeld than a
corresponding RGC cell (blue) (adapted from [12] which also reports population data). Right (A B):
Extent of the temporal receptive ﬁelds of simple cells in cat V1 is greater than that of corresponding
LGN cells as quantiﬁed by the peak (A) and zero-crossing (B) times. Right (C): In the temporal
receptive ﬁelds of cat LGN and V1 cells the peak can be stronger or weaker than the rebound
(adapted from [25]).

Here  we point out several experimental observations related to temporal processing in the visual
system consistent with the lattice ﬁlter model. First  measurements of temporal receptive ﬁelds
demonstrate that they get progressively longer at each consecutive stage:
i) LGN neurons have
longer receptive ﬁelds than corresponding pre-synaptic ganglion cells [12]  Figure 3left; ii) simple
cells in V1 have longer receptive ﬁelds than corresponding pre-synaptic LGN neurons [25]  Figure
3rightA B. These observation are consistent with the progressively greater temporal extent of the
prediction-error ﬁlters (blue plots in Figure 2).
Second  the weight of the peak (integrated area under the curve) may be either greater or less than
that of the rebound both in LGN relay cells [26] and simple cells of V1 [25]  Figure 3right(C).
Neurons with peak weight exceeding that of rebound are often referred to as non-lagged while the
others are known as lagged found both in cat [27  28  29] and monkey [30]. The reason for this
becomes clear from the response to a step stimulus  Figure 4(top).
By comparing experimentally measured receptive ﬁelds with those of the continuous lattice ﬁlter 
Figure 4  we identify non-lagged neurons with the forward branch and lagged neurons with the
backward branch. Another way to characterize step-stimulus response is whether the sign of the
transient is the same (non-lagged) or different (lagged) relative to sustained response.
Third  measurements of cross-correlation between RGCs and LGN cell spikes in lagged and non-
lagged neurons reveals a difference of the transfer function indicative of the difference in underlying
circuitry [30]. This is consistent with backward pathway circuit of the Laguerre lattice ﬁlter  Figure
2  being more complex then that of the forward path (which results in different transfer function). ”
(or replacing ”more complex” with ”different”)
Third  measurements of cross-correlation between RGCs and LGN cell spikes in lagged and non-
lagged neurons reveals a difference of the transfer function indicative of the difference in underlying
circuitry [31]. This is consistent with the backward branch circuit of the Laguerre lattice ﬁlter  Fig-
ure 2  being different then that of the forward branch (which results in different transfer function).
In particular  a combination of different glutamate receptors such as AMPA and NMDA  as well as
GABA receptors are thought to be responsible for observed responses in lagged cells [32]. How-
ever  further investigation of the corresponding circuitry  perhaps using connectomics technology  is
desirable.
Fourth  the cross-link weights of the lattice ﬁlter can be learned using Hebbian rules  (12 13) which
are biologically plausible [22  23]. Interestingly  if these weights are learned sequentially  starting
from the ﬁrst stage  they do not need to be re-learned when additional stages are added or learned.
This property maps naturally on the fact that in the course of mammalian development the visual
pathway matures in a stage-wise fashion - starting with the retina  then LGN  then V1 - and implying
that the more peripheral structures do not need to adapt to the maturation of the downstream ones.

6

RGCLGNTime (ms)Temporal Filter0-1-0.500.51100200simplecellsandgeniculatecellsdifferedforalltemporalparam-etersmeasured therewasconsiderableoverlapbetweenthedis-tributions(Fig.7).Thisoverlapraisesthefollowingquestion:doesconnectivitydependonhowwellgeniculateandcorticalresponsesarematchedwithrespecttotime?Forinstance dosimplecellswithfastsubregions(earlytimestopeakandearlyzerocrossings)receiveinputmostlyfromgeniculatecellswithfastcenters?Figure8illustratesthevisualresponsesfromageniculatecellandasimplecellthatweremonosynapticallyconnected.Astrongpositivepeakwasobservedinthecorrelogram(shownwitha10msectimewindowtoemphasizeitsshortlatencyandfastrisetime).Inthiscase anONcentralsubregionwaswelloverlappedwithanONgeniculatecenter(preciselyatthepeakofthesubregion).Moreover thetimingsofthevisualresponsesfromtheoverlappedsubregionandthegeniculatecenterwereverysimilar(sameonset ;0–25msec;samepeak ;25–50msec).Itisworthnotingthatthetwocentralsubregionsofthesimplecellwerefasterandstrongerthanthetwolateralsubregions.Theresponsesofthecentralsubregionsmatchedthetimingofthegeniculatecenter.Incontrast thetimingofthelateralsubregionsresembledmorecloselythetimingofthegeniculatesurround(bothpeakedat25–50msec).UnliketheexampleshowninFigure8 aconsiderablenumberofgeniculocorticalpairsproducedresponseswithdifferenttim-ing.Forexample Figure9illustratesacaseinwhichageniculatecenterfullyoverlappedastrongsimple-cellsubregionofthesamesign butwithslowertiming(LGNonset ;0–25msec;peak ;25–50msec;simple-cellonset ;25–50msec;peak ;50–75msec).Thecross-correlogrambetweenthispairofneuronswasﬂat whichindicatestheabsenceofamonosynapticconnection(Fig.9 topright).Toexaminetheroleoftimingingeniculocorticalconnectivity wemeasuredtheresponsetimecoursefromallcellpairsthatmettwocriteria.First thegeniculatecenteroverlappedasimple-cellsubregionofthesamesign(n5104).Second thegeniculatecenteroverlappedthecorticalsubregioninanear-optimalposi-tion(relativeoverlap.50% n547;seeMaterialsandMethods;Fig.5A).Allthesecellpairshadahighprobabilityofbeingmonosynapticallyconnectedbecauseoftheprecisematchinreceptive-ﬁeldpositionandsign(31of47wereconnected).Thedistributionsofpeaktime zero-crossingtime andreboundindexfromthesecellpairswereverysimilartothedistributionsfromtheentiresample(Fig.7;seealsoFig.10legend).Theselectedcellpairsincludedbothpresumeddirectional(predictedDI.0.3 seeMaterialsandMethods;12/20connected)andnondirec-tional(19/27connected)simplecells.Mostgeniculatecellshadsmallreceptiveﬁelds(lessthantwosimple-cellsubregionwidths;seeReceptive-ﬁeldsign) althoughﬁvecellswithlargerreceptiveﬁeldswerealsoincluded(threeconnected).Fromthe47cellpairsusedinthisanalysis thosewithsimilarresponsetimecourseshadahigherprobabilityofbeingconnected(Fig.10).Inparticular cellpairsthathadbothsimilarpeaktimeandzero-crossingtimewereallconnected(n512;Fig.10A).Directionallyselectivesimplecellswereincludedinalltiminggroups.Forexample inFigure10Atherewerefour ﬁve two andonedirectionallyselectivecellsinthetimegroups 20 40 60 and.60msec respectively.Similarresultswereobtainedifwerestrictedoursampletogeniculatecentersoverlappedwiththedominantsub-regionofthesimplecell(n531).Interestingly theefﬁcacyandcontributionsoftheconnectionsseemedtodependlittleontherelativetimingofthevisualresponses(Fig.10 right).Althoughoursampleofthemwasquitesmall laggedcellsareofconsiderableinterestandthereforedeservecomment.Werecordedfrom13potentiallylaggedLGNcellswhosecentersweresuperimposedwithasimple-cellsubregion(eightwithre-boundindicesbetween1.2and1.5;ﬁvewithreboundindices.1.9).Onlysevenofthesepairscouldbeusedfortimingcom-parisons(inonepairthebaselineofthecorrelogramhadinsuf-ﬁcientspikes;inthreepairsthegeniculatereceptiveﬁeldswereFigure7.Distributionofgeniculatecellsandsimplecellswithrespecttothetimingoftheirresponses.Thedistributionofthreeparametersderivedfromimpulseresponsesofgeniculateandcorticalneuronsisshown.A Peaktime.B Zero-crossingtime.C Reboundindex.Peaktimeisthetimewiththestrongestresponseintheﬁrstphaseoftheimpulseresponse.Zero-crossingtimeisthetimebetweentheﬁrstandsecondphases.Reboundindexistheareaoftheimpulseresponseafterthezerocrossingdividedbytheareabeforethezerocrossing.Onlyimpulseresponseswithgoodsignaltonoisewereincluded(.5SDabovebaseline;n5169).Alonsoetal.•ConnectionsbetweenLGNandCortexJ.Neurosci. June1 2001 21(11):4002–40154009Figure 4: Comparison of electrophysiologically measured responses of cat LGN cells with the
continuous-time lattice ﬁlter model. Top: Experimentally measured temporal receptive ﬁelds and
step-stimulus responses of LGN cells (adapted from [26]). Bottom: Typical examples of responses
in the continuous-time lattice ﬁlter model. Lattice ﬁlter coefﬁcients were u1 = v1 = 0.4  u2 = v2 =
0.2 and 1/γ = 50ms to model the non-lagged cell and u1 = v1 = u2 = v2 = 0.2 and 1/γ = 60ms
to model the lagged cell. To model photoreceptor contribution to the responses  an additional leaky
integrator L0 was added to the circuit of Figure 2.

While Hebbian rules are biologically plausible  one may get an impression from Figure 2 that they
must apply to inhibitory cross-links. We point out that this circuit is meant to represent only the com-
putation performed rather than the speciﬁc implementation in terms of neurons. As the same linear
computation can be performed by circuits with a different arrangement of the same components 
there are multiple implementations of the lattice ﬁlter. For example  activity of non-lagged OFF
cells may be seen as representing minus forward error. Then the cross-links between the non-lagged
OFF pathway and the lagged ON pathway would be excitatory. In general  classiﬁcation of cells
into lagged and non-lagged seems independent of their ON/OFF and X/Y classiﬁcation [31  28  29] 
but see[33].

3.2

Insect visual pathway

In insects  two cell types  L1 and L2  both post-synaptic to photoreceptors play an important role
in visual processing. Physiological responses of L1 and L2 indicate that they decorrelate visual
signals by subtracting their predictable parts. In fact  receptive ﬁelds of these neurons were used as
the ﬁrst examples of predictive coding in neuroscience [6]. Yet  as the numbers of synapses from
photoreceptors to L1 and L2 are the same [34] and their physiological properties are similar  it has
been a mystery why insects  have not just one but a pair of such seemingly redundant neurons per
facet. Previously  it was suggested that L1 and L2 provide inputs to the two pathways that map onto
ON and OFF pathways in the vertebrate retina [35  36].
Here  we put forward a hypothesis that the role of L1 and L2 in visual processing is similar to that of
the two branches of the lattice ﬁlter. We do not incorporate the ON/OFF distinction in the effectively
linear lattice ﬁlter model but anticipate that such combined description will materialize in the future.
As was argued in Section 2  in forward prediction-error ﬁlters  the peak has greater weight than
the rebound  while in backward prediction-error ﬁlters the opposite is true. Such difference implies
that in response to a step-stimulus the signs of sustained responses compared to initial transients
are different between the branches. Indeed  Ca2+ imaging shows that responses of L1 and L2 to
step-stimulus are different as predicted by the lattice ﬁlter model [35]  Figure 5b. Interestingly  the
activity of L1 seems to represent minus forward error and L2 - plus backward error  suggesting that
the lattice ﬁlter cross-links are excitatory. To summarize  the predictions of the lattice ﬁlter model
seem to be consistent with the physiological measurements in the ﬂy visual system and may help
understand its operation.

7

Figure 5: Response of the lattice ﬁlter and fruit ﬂy LMCs to a step-stimulus. Left: Responses
of the ﬁrst order discrete-time lattice ﬁlter to a step stimulus. Right: Responses of ﬂy L1 and L2
cells to a moving step stimulus (adapted from [35]). Predicted and the experimentally measured
responses have qualitatively the same shape: a transient followed by sustained response  which has
the same sign for the forward error and L1 and the opposite sign for the backward error and L2.

4 Discussion
Motivated by the cascade structure of the visual pathway  we propose to model its operation with
the lattice ﬁlter. We demonstrate that the predictions of the continuous-time lattice ﬁlter model are
consistent with the course of neural development and the physiological measurement in the LGN 
V1 of cat and monkey  as well as ﬂy LMC neurons. Therefore  lattice ﬁlters may offer a useful
abstraction for understanding aspects of temporal processing in visual systems of vertebrates and
invertebrates.
Previously  [11] proposed that lagged and non-lagged cells could be a result of rectiﬁcation by
spiking neurons. Although we agree with [11] that LGN performs temporal decorrelation  our ex-
planation does not rely on non-linear processing but rather on the cascade architecture and  hence  is
fundamentally different. Our model generates the following predictions that are not obvious in [11]:
i) Not only are LGN receptive ﬁelds longer than RGC but also V1 receptive ﬁelds are longer than
LGN; ii) Even a linear model can generate a difference in the peak/rebound ratio; iii) The circuit
from RGC to LGN should be different for lagged and non-lagged cells consistent with [31]; iv) The
lattice ﬁlter circuit can self-organize using Hebbian rules  which gives a mechanistic explanation of
receptive ﬁelds beyond the normative framework of [11].
In light of the redundancy reduction arguments given in the introduction  we note that  if the only
goal of the system were to compress incoming signals using a given number of lattice ﬁlter stages 
then after the compression is peformed only one kind of prediction errors  forward or backward
needs to be transmitted. Therefore  having two channels  in the absence of noise  may seem redun-
dant. However  transmitting both forward and backward errors gives one the ﬂexibility to continue
decorrelation further by adding stages performing relatively simple operations.
We are grateful to D.A. Butts  E. Callaway  M. Carandini  D.A. Clark  J.A. Hirsch  T. Hu  S.B.
Laughlin  D.N. Mastronarde  R.C. Reid  H. Rouault  A. Saul  L. Scheffer  F.T. Sommer  X. Wang
for helpful discussions.

References
[1] F. Rieke  D. Warland  R.R. van Steveninck  and W. Bialek. Spikes: exploring the neural code. MIT press 

1999.

[2] S.B. Laughlin. Matching coding  circuits  cells  and molecules to signals: general principles of retinal

design in the ﬂy’s eye. Progress in retinal and eye research  13(1):165–196  1994.

[3] F. Attneave. Some informational aspects of visual perception. Psychological review  61(3):183  1954.
[4] H. Barlow. Redundancy reduction revisited. Network: Comp in Neural Systems  12(3):241–253  2001.
[5] R.M. Gray. Linear Predictive Coding and the Internet Protocol. Now Publishers  2010.
[6] MV Srinivasan  SB Laughlin  and A. Dubs. Predictive coding: a fresh view of inhibition in the retina.

Proceedings of the Royal Society of London. Series B. Biological Sciences  216(1205):427–459  1982.

[7] T. Hosoya  S.A. Baccus  and M. Meister. Dynamic predictive coding by the retina. Nature  436:71  2005.

8

0510152000.51Stimulus05101520−101− Forward Error05101520−101Backward Errortime[8] HK Hartline  H.G. Wagner  and EF MacNichol Jr. The peripheral origin of nervous activity in the visual
system. Studies on excitation and inhibition in the retina: a collection of papers from the laboratories of
H. Keffer Hartline  page 99  1974.

[9] N.A. Lesica  J. Jin  C. Weng  C.I. Yeh  D.A. Butts  G.B. Stanley  and J.M. Alonso. Adaptation to stimulus

contrast and correlations during natural visual stimulation. Neuron  55(3):479–491  2007.

[10] Y. Dan  J.J. Atick  and R.C. Reid. Efﬁcient coding of natural scenes in the lateral geniculate nucleus:

experimental test of a computational theory. The Journal of Neuroscience  16(10):3351–3362  1996.

[11] D.W. Dong and J.J. Atick. Statistics of natural time-varying images. Network: Computation in Neural

Systems  6(3):345–358  1995.

[12] X. Wang  J.A. Hirsch  and F.T. Sommer. Recoding of sensory information across the retinothalamic

synapse. The Journal of Neuroscience  30(41):13567–13577  2010.

[13] C. Koch. Biophysics of computation: information processing in single neurons. Oxford Univ Press  2005.
[14] F. Itakura and S. Saito. On the optimum quantization of feature parameters in the parcor speech synthe-
sizer. In Conference Record  1972 International Conference on Speech Communication and Processing 
Boston  MA  pages 434–437  1972.

[15] B. Widrow and S.D. Stearns. Adaptive signal processing. Prentice-Hall  Inc. Englewood Cliffs  NJ  1985.
[16] S. Haykin. Adaptive ﬁlter theory. Prentice-Hall  Englewood-Cliffs  NJ  2003.
[17] A.H. Sayed. Fundamentals of adaptive ﬁltering. Wiley-IEEE Press  2003.
[18] D.J. Felleman and D.C. Van Essen. Distributed hierarchical processing in the primate cerebral cortex.

Cerebral cortex  1(1):1–47  1991.

[19] X. Wang  F.T. Sommer  and J.A. Hirsch. Inhibitory circuits for visual processing in thalamus. Current

Opinion in Neurobiology  2011.

[20] SB Laughlin  J. Howard  and B. Blakeslee. Synaptic limitations to contrast coding in the retina of
the blowﬂy calliphora. Proceedings of the Royal society of London. Series B. Biological sciences 
231(1265):437–467  1987.

[21] D.C. Lay. Linear Algebra and Its Applications. Addison-Wesley/Longman  New York/London  2000.
[22] D.O. Hebb. The organization of behavior: A neuropsychological theory. Lawrence Erlbaum  2002.
[23] O. Paulsen and T.J. Sejnowski. Natural patterns of activity and long-term synaptic plasticity. Current

opinion in neurobiology  10(2):172–180  2000.

[24] Z. Fejzo and H. Lev-Ari. Adaptive laguerre-lattice ﬁlters. Signal Processing  IEEE Transactions on 

45(12):3006–3016  1997.

[25] J.M. Alonso  W.M. Usrey  and R.C. Reid. Rules of connectivity between geniculate cells and simple cells

in cat primary visual cortex. The Journal of Neuroscience  21(11):4002–4015  2001.

[26] D. Cai  G.C. Deangelis  and R.D. Freeman. Spatiotemporal receptive ﬁeld organization in the lateral

geniculate nucleus of cats and kittens. Journal of Neurophysiology  78(2):1045–1061  1997.

[27] D.N. Mastronarde. Two classes of single-input x-cells in cat lateral geniculate nucleus. i. receptive-ﬁeld

properties and classiﬁcation of cells. Journal of Neurophysiology  57(2):357–380  1987.

[28] J. Wolfe and L.A. Palmer. Temporal diversity in the lateral geniculate nucleus of cat. Visual neuroscience 

15(04):653–675  1998.

[29] AB Saul and AL Humphrey. Spatial and temporal response properties of lagged and nonlagged cells in

cat lateral geniculate nucleus. Journal of Neurophysiology  64(1):206–224  1990.

[30] A.B. Saul. Lagged cells in alert monkey lateral geniculate nucleus. Visual neurosci  25:647–659  2008.
[31] D.N. Mastronarde. Two classes of single-input x-cells in cat lateral geniculate nucleus. ii. retinal inputs

and the generation of receptive-ﬁeld properties. Journal of Neurophysiology  57(2):381–413  1987.

[32] P. Heggelund and E. Hartveit. Neurotransmitter receptors mediating excitatory input to cells in the cat

lateral geniculate nucleus. i. lagged cells. Journal of neurophysiology  63(6):1347–1360  1990.

[33] J. Jin  Y. Wang  R. Lashgari  H.A. Swadlow  and J.M. Alonso. Faster thalamocortical processing for dark

than light visual targets. The Journal of Neuroscience  31(48):17471–17479  2011.

[34] M. Rivera-Alba  S.N. Vitaladevuni  Y. Mischenko  Z. Lu  S. Takemura  L. Scheffer  I.A. Meinertzhagen 
D.B. Chklovskii  and G.G. de Polavieja. Wiring economy and volume exclusion determine neuronal
placement in the drosophila brain. Current Biology  21(23):2000–5  2011.

[35] D.A. Clark  L. Bursztyn  M.A. Horowitz  M.J. Schnitzer  and T.R. Clandinin. Deﬁning the computational

structure of the motion detector in drosophila. Neuron  70(6):1165–1177  2011.

[36] M. Joesch  B. Schnell  S.V. Raghu  D.F. Reiff  and A. Borst. On and off pathways in drosophila motion

vision. Nature  468(7321):300–304  2010.

9

,Karthika Mohan
Judea Pearl
Victor Picheny
Robert Gramacy
Stefan Wild
Sebastien Le Digabel