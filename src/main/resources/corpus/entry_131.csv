2011,A More Powerful Two-Sample Test in High Dimensions using Random Projection,We consider the hypothesis testing problem of detecting a shift between the means of two multivariate normal distributions in the high-dimensional setting  allowing for the data dimension p to exceed the sample size n. Our contribution is a new test statistic for the two-sample test of means that integrates a random projection with the classical Hotelling T squared statistic. Working within a high- dimensional framework that allows (p n) to tend to infinity  we first derive an asymptotic power function for our test  and then provide sufficient conditions for it to achieve greater power than other  state-of-the-art tests. Using ROC curves generated from simulated data  we demonstrate superior performance against competing tests in the parameter regimes anticipated by our theoretical results. Lastly  we illustrate an advantage of our procedure with comparisons on a high-dimensional gene expression dataset involving the discrimination of different types of cancer.,A More Powerful Two-Sample Test in High

Dimensions using Random Projection

Miles E. Lopes1

Laurent Jacob1

Martin J. Wainwright1 2

Departments of Statistics1 and EECS2

University of California  Berkeley

{mlopes laurent wainwrig}@stat.berkeley.edu

Berkeley  CA 94720-3860

Abstract

We consider the hypothesis testing problem of detecting a shift between the means
of two multivariate normal distributions in the high-dimensional setting  allowing
for the data dimension p to exceed the sample size n. Our contribution is a new test
statistic for the two-sample test of means that integrates a random projection with
the classical Hotelling T 2 statistic. Working within a high-dimensional framework
that allows (p  n) → ∞  we ﬁrst derive an asymptotic power function for our
test  and then provide sufﬁcient conditions for it to achieve greater power than
other state-of-the-art tests. Using ROC curves generated from simulated data 
we demonstrate superior performance against competing tests in the parameter
regimes anticipated by our theoretical results. Lastly  we illustrate an advantage
of our procedure with comparisons on a high-dimensional gene expression dataset
involving the discrimination of different types of cancer.

1

Introduction

Two-sample hypothesis tests are concerned with the question of whether two samples of data are
generated from the same distribution. Such tests are among the most widely used inference pro-
cedures in treatment-control studies in science and engineering [1]. Application domains such
as molecular biology and fMRI have stimulated considerable interest in detecting shifts between
distributions in the high-dimensional setting  where the two samples of data {X1  . . .   Xn1} and
{Y1  . . .   Yn2} are subsets of Rp  and n1  n2 (cid:28) p [e.g.  2–5]. In transcriptomics  for instance  p
gene expression measures on the order of hundreds or thousands may be used to investigate differ-
ences between two biological conditions  and it is often difﬁcult to obtain sample sizes n1 and n2
larger than several dozen in each condition. In high-dimensional situations such as these  classical
methods may be ineffective  or not applicable at all. Likewise  there has been growing interest in
developing testing procedures that are better suited to deal with the effects of dimension [e.g.  6–10].
A fundamental instance of the general two-sample problem is the two-sample test of means with
Gaussian data. In this case  two independent sets of samples {X1  . . .   Xn1} and {Y1  . . .   Yn2} are
generated in an i.i.d. manner from p-dimensional multivariate normal distributions N (µ1  Σ) and
N (µ2  Σ) respectively  where the mean vectors µ1  µ2 ∈ Rp and covariance matrix Σ (cid:31) 0 are all
ﬁxed and unknown. The hypothesis testing problem of interest is

H0 : µ1 = µ2 versus H1 : µ1 (cid:54)= µ2.

The most well-known test statistic for this problem is the Hotelling T 2 statistic  deﬁned by

( ¯X − ¯Y )(cid:62)(cid:98)Σ−1 ( ¯X − ¯Y ) 

T 2 :=

n1 n2
n1 + n2

(1)

(2)

1

(cid:80)n1

(cid:80)n2
j=1 Yj are the sample means  and(cid:98)Σ is the pooled sample
(cid:80)n1
covariance matrix  given by (cid:98)Σ := 1
where ¯X := 1
n1
j=1(Xj − ¯X)(Xj − ¯X)(cid:62) + 1
When p > n  the matrix (cid:98)Σ is singular  and the Hotelling test is not well-deﬁned. Even when
n := n1 + n2 − 2.

(cid:80)n2
j=1(Yj − ¯Y )(Yj − ¯Y )(cid:62)  with

j=1 Xj and ¯Y := 1
n2

n

n

p ≤ n  the Hotelling test is known to perform poorly if p is nearly as large as n. This behavior
was demonstrated in a seminal paper of Bai and Saranadasa [6] (or BS for short)  who studied the
performance of the Hotelling test under (p  n) → ∞ with p/n → 1 −   and showed that the
asymptotic power of the test suffers for small values of  > 0. In subsequent years  a number of
improvements on the Hotelling test in the high-dimensional setting have been proposed [e.g.  6–9].
In this paper  we propose a new test statistic for the two-sample test of means with multivariate
normal data  applicable when p ≥ n/2. We provide an explicit asymptotic power function for
our test with (p  n) → ∞  and show that under certain conditions  our test has greater asymptotic
power than other state-of-the-art tests. These comparison results are valid with p/n tending to a
positive constant or inﬁnity. In addition to its advantage in terms of asymptotic power  our procedure
speciﬁes exact level-α critical values for multivariate normal data  whereas competing procedures
offer only approximate level-α critical values. Furthermore  our experiments in Section 4 suggest
that the critical values of our test may also be more robust than those of competing tests. Lastly  the
computational cost of our procedure is modest in the n < p setting  being of order O(n2p).
The remainder of this paper is organized as follows. In Section 2  we provide background on hy-
pothesis testing and describe our testing procedure. Section 3 is devoted to a number of theoretical
results about its performance. Theorem 1 in Section 3.1 provides an asymptotic power function 
and Theorems 2 and 3 in Sections 3.3 and 3.4 give sufﬁcient conditions for achieving greater power
than state-of-the-art tests in the sense of asymptotic relative efﬁciency. In Section 4 we provide
performance comparisons with ROC curves on synthetic data against a broader collection of meth-
ods  including some recent kernel-based and non-parametric approaches such as MMD [11]  KFDA
[12]  and TreeRank [10]. Lastly  we study a high-dimensional gene expression dataset involving the
discrimination of different cancer types  demonstrating that our test’s false positive rate is reliable in
practice. We refer the reader to the preprint [13] for proofs of our theoretical results.
Notation. Let δ := µ1 − µ2 denote the shift vector between the distributions N (µ1  Σ) and
N (µ2  Σ)  and deﬁne the ordered pair of parameters θ := (δ  Σ). Let z1−α denote the 1 − α
quantile of the standard normal distribution  and let Φ be its cumulative distribution function. If A
is a matrix in Rp×p  let |||A|||2 denote its spectral norm (maximum singular value)  and deﬁne the
Frobenius norm |||A|||F :=
ij. When all the eigenvalues of A are real  we denote them
by λmin(A) = λp(A) ≤ ··· ≤ λ1(A) = λmax(A). For a positive-deﬁnite covariance matrix Σ 
−1/2
. We use the
let Dσ := diag(Σ)  and deﬁne the associated correlation matrix R := D
σ
notation f (n) (cid:46) g(n) if there is some absolute constant c such that the inequality f (n) ≤ c n holds
for all large n. If both f (n) (cid:46) g(n) and g(n) (cid:46) f (n) hold  then we write f (n) (cid:16) g(n). The
notation f (n) = o(g(n)) means f (n)/g(n) → 0 as n → ∞.

(cid:113)(cid:80)

−1/2
ΣD
σ

i j A2

2 Background and random projection method

For the remainder of the paper  we retain the set-up for the two-sample test of means (1) with
Gaussian data  assuming throughout that p ≥ n/2  and n = n1 + n2 − 2.
Review of hypothesis testing terminology. The primary focus of our results will be on the compar-
ison of power between test statistics  and here we give precise meaning to this notion. When testing
a null hypothesis H0 versus an alternative hypothesis H1  a procedure based on a test statistic T
speciﬁes a critical value  such that H0 is rejected if T exceeds that critical value  and H0 is ac-
cepted otherwise. The chosen critical value ﬁxes a trade-off between the risk of rejecting H0 when
H0 actually holds  and the risk of accepting H0 when H1 holds. The former error is referred to as
a type I error and the latter as a type II error. A test is said to have level α if the probability of com-
mitting a type I error is at most α. Finally  at a given level α  the power of a test is the probability
of rejecting H0 under H1  i.e.  1 minus the probability of a type II error. When evaluating testing
procedures at a given level α  we seek to identify the one with the greatest power.

2

Past work. The Hotelling T 2 statistic (2) discriminates between the hypotheses H0 and H1 by pro-
viding an estimate of the “statistical distance” separating the distributions N (µ1  Σ) and N (µ2  Σ).
More speciﬁcally  the Hotelling statistic is essentially an estimate of the Kullback-Leibler (KL) di-
pooled sample covariance matrix (cid:98)Σ in the deﬁnition of T 2 is not invertible when p > n  several
2 δ(cid:62)Σ−1δ  where δ := µ1 − µ2. Due to the fact that the
vergence DKL

(cid:0)N (µ1  Σ)(cid:107)N (µ2  Σ)(cid:1) = 1

recent procedures have offered substitutes for the Hotelling statistic in the high-dimensional setting:
Bai and Saranadasa [6]  Srivastava and Du [7  8]  Chen and Qin [9]  hereafter BS  SD and CQ re-
spectively. Up to now  the route toward circumventing this difﬁculty has been to form an estimate of
Σ that is diagonal  and hence easily invertible. We shall see later that this limited use of covariance
structure sacriﬁces power when the data exhibit non-trivial correlation. In this regard  our proce-
dure is motivated by the idea that covariance structure may be used more effectively by testing with
projected samples in a space of lower dimension.
Intuition for random projection. To provide some further intuition for our method  it is possible
to consider the problem (1) in terms of a competition between the dimension p  and the statistical
distance separating H0 and H1. On one hand  the accumulation of variance from a large number
of variables makes it difﬁcult to discriminate between the hypotheses  and thus  it is desirable to
reduce the dimension of the data. On the other hand  most methods for reducing dimension will also
bring H0 and H1 “closer together ” making them harder to distinguish. Mindful of the fact that the
Hotelling test measures the separation of H0 and H1 in terms of δ(cid:62)Σ−1δ  we see that the statistical
distance is driven by the Euclidean length of δ. Consequently  we seek to transform the data in such
a way that the dimension is reduced  while the length of the shift δ is mostly preserved upon passing
to the transformed distributions. From this geometric point of view  it is natural to exploit the fact
that random projections can simultaneously reduce dimension and approximately preserve lengths
with high probability [14]. The use of projection-based test statistics has been considered previously
in Jacob et al.  [15]  Cl´emenc¸on et al. [10]  and Cuesta-Albertos et al. [16].
At a high level  our method can be viewed as a two step procedure. First  a single random projection
is drawn  and is used to map the samples from the high-dimensional space Rp to a low-dimensional
space1 Rk  with k := (cid:98)n/2(cid:99). Second  the Hotelling T 2 test is applied to a new hypothesis testing
problem  H0 proj versus H1 proj  in the projected space. A decision is then pulled back to the original
problem by simply rejecting H0 whenever the Hotelling test rejects H0 proj.
k ∈ Rk×p denote a random projection with i.i.d. N (0  1) entries 
Formal testing procedure. Let P (cid:62)
drawn independently of the data  where k = (cid:98)n/2(cid:99). Conditioning on the drawn matrix P (cid:62)
k   the
projected samples {P (cid:62)
k Xn1} and {P (cid:62)
k Yn2} are distributed i.i.d. according
k X1  . . .   P (cid:62)
k ΣPk) respectively  with i = 1  2. Since n ≥ k  the projected data satisfy the usual
to N (P (cid:62)
conditions [17  p. 211] for applying the Hotelling T 2 procedure to the following new two-sample
problem in the projected space Rk:

k Y1  . . .   P (cid:62)

k µi  P (cid:62)

H0 proj : P (cid:62)

k µ1 = P (cid:62)

k µ2 versus H1 proj : P (cid:62)

k µ1 (cid:54)= P (cid:62)

k µ2.

(3)

For this projected problem  the Hotelling test statistic takes the form2

k (cid:98)ΣPk)−1P (cid:62)

k ( ¯X − ¯Y ) 

k := n1n2
T 2
n1+n2

( ¯X − ¯Y )(cid:62)Pk(P (cid:62)

k n

k n−k+1(α)  where F ∗

where ¯X  ¯Y   and (cid:98)Σ are as deﬁned in Section 1. Lastly  deﬁne the critical value tα :=
n−k+1 F ∗
k n−k+1(α) is the upper α quantile of the Fk n−k+1 distribution [17].
k ≥ tα is a level-α
It is a basic fact about the classical Hotelling test that rejecting H0 proj when T 2
test for the projected problem (3) (e.g.  see Muirhead [17  p.217]). Inspection of the formula for T 2
k
shows that its distribution is the same under both H0 and H0 proj. Therefore  rejecting the original
k ≥ tα is also a level α test for the original problem (1). Likewise  we deﬁne this as the
H0 when T 2
condition for rejecting H0 at level α in our procedure for (1). We summarize our procedure below.

1The choice of projected dimension k = (cid:98)n/2(cid:99) is explained in the preprint [13].
2Note that P (cid:62)

k (cid:98)ΣPk is invertible with probability 1 when P (cid:62)

k has i.i.d. N (0  1) entries.

3

1. Generate a single random matrix P (cid:62)
2. Compute T 2
3. If T 2

k ≥ tα  reject H0; otherwise accept H0.

k   using P (cid:62)

k and the two sets of samples.

k with i.i.d. N (0  1) entries.

((cid:63))

Projected Hotelling test at level α for problem (1).

3 Main results and their consequences

This section is devoted to the statement and discussion of our main theoretical results  including
a characterization of the asymptotic power function of our test (Theorem 1)  and comparisons of
asymptotic relative efﬁciency with state-of-the-art tests proposed in past work (Theorems 2 and 3).

3.1 Asymptotic power function

As is standard in high-dimensional asymptotics  we will consider a sequence of hypothesis testing
problems indexed by n  allowing the dimension p  mean vectors µ1 and µ2 and covariance matrix
Σ to implicitly vary as functions of n  with n → ∞. We also make another type of asymptotic
assumption  known as a local alternative [18  p.193]  which is commonplace in hypothesis testing.
The idea lying behind a local alternative assumption is that if the difﬁculty of discriminating between
H0 and H1 is “held ﬁxed” with respect to n  then it is often the case that most testing procedures
have power tending to 1 under H1 as n → ∞. In such a situation  it is not possible to tell if one
test has greater asymptotic power than another. Consequently  it is standard to derive asymptotic
power results under the extra condition that H0 and H1 become harder to distinguish as n grows.
This theoretical device aids in identifying the conditions under which one test is more powerful
than another. The following local alternative (A1)  and balancing assumption (A2)  are similar to
those used in previous works [6–9] on problem (1). In particular  condition (A1) means that the
KL-divergence between N (µ1  Σ) and N (µ2  Σ) tends to 0 as n → ∞.
(A1) Suppose that δ(cid:62)Σ−1δ = o(1).
(A2) Let there be a constant b ∈ (0  1) such that n1/n → b.
To set the notation for Theorem 1  it is important to notice that each time the procedure ((cid:63)) is im-
plemented  a draw of P (cid:62)
k . To make this dependence clear  recall
θ := (δ  Σ)  and let β(θ; P (cid:62)
k ) denote the exact (non-asymptotic) power function of our level-α
test for problem (1)  induced by a draw of P (cid:62)
k   as in ((cid:63)). Another key quantity that depends on
P (cid:62)
k is the KL-divergence between the projected sampling distributions N (P (cid:62)
k ΣPk) and
N (P (cid:62)
k  and a simple calculation shows that
2 ∆2
Theorem 1. Under conditions (A1) and (A2)  for almost all sequences of projections P (cid:62)
k  

k ΣPk). We denote this divergence by 1

k induces a new test statistic T 2

k µ2  P (cid:62)
k = 1

k ΣPk)−1P (cid:62)
k δ.

2 δ(cid:62)Pk(P (cid:62)

k µ1  P (cid:62)

2 ∆2

1

(cid:17) → 0 as n → ∞.

(4)

(cid:16)−z1−α + b(1−b)√

2

√

n ∆2
k

β(θ; P (cid:62)

k ) − Φ

k = 0  e.g. under H0  then Φ(−z1−α +0) = α  which corresponds to blind
Remarks. Note that if ∆2
√
guessing at level α. Consequently  the second term (b(1 − b)/
k determines the advantage
of our procedure over blind guessing. Since ∆2
k is proportional to the KL-divergence between the
projected sampling distributions  these observations conform to the intuition from Section 2 that the
KL-divergence measures the discrepancy between H0 and H1.

n∆2

√

2)

3.2 Asymptotic relative efﬁciency (ARE)

Having derived an asymptotic power function for our test in Theorem 1  we are now in position to
provide sufﬁcient conditions for achieving greater power than two other recent procedures for prob-
lem (1): Srivastava and Du [7  8] (SD)  and Chen and Qin [9] (CQ). To the best of our knowledge 

4

these works represent the state of the art3 among tests for problem (1) with a known asymptotic
power function under (p  n) → ∞.
From Theorem 1  the asymptotic power function of our random projection-based test at level α is

βRP(θ; P (cid:62)

k ) := Φ

(cid:16)−z1−α + b(1−b)√

2

(cid:17)

n (cid:107)δ(cid:107)2
|||Σ|||F

2

(cid:16)−z1−α + b(1−b)√

2

√

n ∆2
k

(cid:17)
(cid:16)−z1−α + b(1−b)√

.

2

(cid:17)

(5)

.

n δ(cid:62)D−1
σ δ
|||R|||F

The asymptotic power functions for the CQ and SD testing procedures at level α are

βCQ(θ) := Φ

 

and βSD(θ) := Φ

Recall that Dσ := diag(Σ)  and R denotes the correlation matrix associated with Σ. The functions
βCQ and βSD are derived under local alternatives and asymptotic assumptions that are similar to the
ones used here to obtain βRP. In particular  all three functions can be obtained allowing p/n to tend
to an arbitrary positive constant or inﬁnity.
A standard method of comparing asymptotic power functions under local alternatives is through
the concept of asymptotic relative efﬁciency (ARE) e.g.  see van der Vaart [18  p.192]). Since Φ is
monotone increasing  the term added to −z1−α inside the Φ functions above controls the power. To
compare power between tests  the ARE is simply deﬁned via the ratio of such terms. More explicitly 
we deﬁne ARE (βCQ; βRP) :=

(cid:16) n δ(cid:62)D−1

  and ARE (βSD; βRP) :=

(cid:16) n (cid:107)δ(cid:107)2

(cid:14)√

(cid:14)√

(cid:17)2

(cid:17)2

σ δ

.

n ∆2
k

n∆2
k

2

|||Σ|||F

|||R|||F

k through ∆2

k. Moreover  the quantity ∆2

Whenever the ARE is less than 1  our procedure is considered to have greater asymptotic power than
the competing test—with our advantage being greater for smaller values of the ARE. Consequently 
we seek sufﬁcient conditions in Theorems 2 and 3 for ensuring that the ARE is small.
In the present context  the analysis of ARE is complicated by the fact that the ARE varies with
n and depends on a random draw of P (cid:62)
k  and hence the
ARE  are affected by the orientation of δ with respect to the eigenvectors of Σ. In order to consider
an average-case scenario  where no single orientation of δ is of particular importance  we place a
prior on the unit vector δ/(cid:107)δ(cid:107)2  and assume that it is uniformly distributed on the unit sphere of Rp.
We emphasize that our procedure ((cid:63)) does not rely on this assumption  and that it is only a device
for making an average-case comparison. Therefore  to be clear about the meaning of Theorems 2
k and δ/(cid:107)δ(cid:107)2  and our probability
and 3  we regard the ARE as a function two random objects  P (cid:62)
statements are made with this understanding. We complete the preparation for our comparison
theorems by isolating four assumptions with n → ∞.
(A3) The vector
(A4) There is a constant a ∈ [0  1) such that k/p → a.
(A5) The ratio 1√
(A6) The matrix Dσ = diag(Σ) satisﬁes

is uniformly distributed on the p-dimensional unit sphere  independent of P (cid:62)
k .

tr(Σ)(cid:14)(p λmin(Σ)) = o(1).

= o(1).

δ(cid:107)δ(cid:107)2

k

|||D−1
σ |||2
−1
σ )

tr(D

3.3 Comparison with Chen and Qin [9]

The next result compares the asymptotic power of our projection-based test with that of Chen and
Qin [9]. The choice of 1 = 1 below (and in Theorem 3) is the reference for equal asymptotic
performance  with smaller values of 1 corresponding to better performance of random projection.
Theorem 2. Assume conditions (A3)  (A4)  and (A5). Fix a number 1 > 0  and let c(1) be any
constant strictly greater than

1 (1−√

4

a)4 . If the inequality
n ≥ c(1) tr(Σ)2
|||Σ|||2

F

Σ  we have 1 ≤ tr(Σ)2(cid:14)|||Σ|||2

holds for all large n  then P [ARE (βCQ; βRP) ≤ 1] → 1 as n → ∞.
Interpretation. To interpret the result  note that Jensen’s inequality implies that for any choice of
F ≤ p. As such  it is reasonable to interpret this ratio as a measure of
3Two other high-dimensional tests have been proposed in older works [6  19  20] that lead to the asymptotic

power function βCQ  but under more restrictive assumptions.

(6)

5

spectrum of Σ  with tr(Σ)2(cid:14)|||Σ|||2

the effective dimension of the covariance structure. The message of Theorem 2 is that as long as
the sample size n exceeds the effective dimension  then our projection-based test is asymptotically
superior to CQ. The ratio tr(Σ)2/|||Σ|||2
F can also be viewed as measuring the decay rate of the
F (cid:28) p indicating rapid decay. This condition means that the data
has low variance in “most” directions in Rp  and so projecting onto a random set of k directions will
likely map the data into a low-variance subspace in which it is harder for chance variation to explain
away the correct hypothesis  thereby resulting in greater power.

3.4 Comparison with Srivastava and Du [7  8]

We now turn to comparison of asymptotic power with the test of Srivastava and Du (SD).
Theorem 3. In addition to the conditions of Theorem 2  assume that condition (A6) holds. Fix a
number 1 > 0  and let c(1) be any constant strictly greater than

a)4 . If the inequality

1 (1−√

4

(cid:16) tr(Σ)

(cid:17)2(cid:16) tr(D−1

(cid:17)2

σ )
|||R|||F

p

n ≥ c(1)

(7)

holds for all large large n  then P [ARE (βSD; βRP) ≤ 1] → 1 as n → ∞.
Interpretation. Unlike the comparison with the CQ test  the correlation matrix R plays a large role
in determining the relative efﬁciency between our procedure and the SD test. The correlation matrix
enters in two different ways. First  the Frobenius norm |||R|||F is larger when the data variables are
more correlated. Second  correlation mitigates the growth of tr(D−1
σ )  since this trace is largest
when Σ is nearly diagonal and has a large number of small eigenvalues. Inspection of the SD test
statistic in [7] shows that it does not make any essential use of correlation. By contrast  our T 2
k
statistic does take correlation into account  and so it is understandable that correlated data enhance
the performance of our test relative to SD.
As a simple example  let ρ ∈ (0  1) and consider a highly correlated situation where all variables
have ρ correlation will all other variables. Then  R = (1 − ρ)Ip×p + ρ11(cid:62) where 1 ∈ Rp is the all
ones vector. We may also let Σ = R for simplicity. In this case  we see that |||R|||2
(cid:46) 1 and tr(Σ)/p = 1  and
p2  and tr(D−1
then the sufﬁcient condition (7) for outperforming SD is easily satisﬁed in terms of rates. We could
even let the correlation ρ decay at a rate of n−q with q ∈ (0  1/2)  and (7) would still be satisﬁed
for large enough n. More generally  it is not necessary to use specially constructed covariance
matrices Σ to demonstrate the superior performance of our method. Section 4 illustrates simulations
involving randomly selected covariance matrices where T 2
Conversely  it is possible to show that condition (7) requires non-trivial correlation. To see this 
ﬁrst note that in the complete absence of correlation  we have |||R|||2
F = p. Jensen’s
inequality implies that tr(D−1
this shows if the data exhibits very low correlation  then (7) cannot hold when p grows faster than
n. This will be illustrated in the simulations of Section 4.

(cid:17)2 ≥ p. Altogether 

σ )2 = tr(Ip×p)2 = p2. This implies tr(D−1

(cid:17)2(cid:16) tr(D−1
F = |||Ip×p|||2

F = p + 2(cid:0)p

σ )2(cid:14)|||R|||2

k is more powerful than SD.

tr(Dσ) = p2

tr(Σ)  and so

(cid:1)ρ2 (cid:38)

(cid:16) tr(Σ)

p

σ ) ≥ p2

σ

|||R|||F

F

2

4 Performance comparisons on real and synthetic data

In this section  we compare our procedure to state-of-the-art methods on real and synthetic data 
illustrating the effects of the different factors involved in Theorems 2 and 3.

Comparison on synthetic data.
In order to validate the consequences of our theory and compare
against other methods in a controlled fashion  we performed simulations in four settings: slow/fast
spectrum decay  and diagonal/random covariance structure. To consider two rates of spectrum decay 
we selected p equally spaced values between 0.01 and 1  and raised them to the power 20 for fast
decay and the power 5 for slow decay. Random covariance structure was generated by specifying
the eigenvectors of Σ as the column vectors of the orthogonal component of a QR decomposition of
a p × p matrix with i.i.d. N (0  1) entries. In all cases  we sampled n1 = n2 = 50 data points from
two multivariate normal distributions in p = 200 dimensions  and repeated the process 500 times

6

with δ = 0 for H0  and 500 times with (cid:107)δ(cid:107)2 = 1 for H1. In the case of H1  δ was drawn uniformly
from the unit sphere  as in Theorems 2 and 3. We ﬁxed the total amount of variance by setting
|||Σ|||F = 50 in all cases. In addition to our random projection (RP)-based test  we implemented
the methods of BS [6]  SD [7]  and CQ [9]  all of which are designed speciﬁcally for problem
(1) in the high-dimensional setting. For the sake of completeness  we also compare against recent
non-parametric procedures for the general two-sample problem that are based on kernel methods
(MMD) [11] and (KFDA) [12]  as well as area-under-curve maximization (TreeRank) [10].
The ROC curves from our simulations are displayed in the left block of four panels in Figure 1.
These curves bear out the results of Theorems 2 and 3 in several ways. First notice that fast spectral
decay improves the performance of our test relative to CQ  as expected from Theorem 2. If we set
a = 0 and 1 = 1 in Theorem 2  then condition (6) for outperforming CQ is approximately n ≥ 75
in the case of fast decay. Given that n = 50 + 50 − 2 = 98  the advantage of our method over CQ
in panels (b) and (d) is consistent with condition (6) being satisﬁed. In the case of slow decay  the
same settings of a and 1 indicate that n ≥ 246 is sufﬁcient for outperforming CQ. Since the ROC
curve of our method is roughly the same as that of CQ in panels (a) and (c) (where again n = 98) 
our condition (6) is somewhat conservative for slow decay at the ﬁnite sample level.
To study the consequences of Theorem 3  observe that when the covariance matrix Σ is generated
randomly  the amount of correlation is much larger than in the idealized case that Σ is diagonal.
σ )/|||R|||F   is much smaller in in the
Speciﬁcally  for a ﬁxed value of tr(Σ)  the quantity tr(D−1
presence of correlation. Consequently  when comparing (a) with (c)  and (b) with (d)  we see that
correlation improves the performance of our test relative to SD  as expected from the bound in
Theorem 3. More generally  the ROC curves illustrate that our method has an overall advantage
over BS  CQ  KFDA  and MMD. Note that KFDA and MMD are not designed speciﬁcally for the
n (cid:28) p regime. In the case of zero correlation  it is notable that the TreeRank procedure displays a
superior ROC curve to our method  given that it also employs a dimension reduction strategy.

(a) diagonal Σ  slow decay

(b) diagonal Σ  fast decay

(e) FPR for genomic data

(c) random Σ  slow decay

(d) random Σ  fast decay

(f) FPR for genomic data (zoom)

Figure 1: Left and middle panels: ROC curves of several test statistics for two different choices of
correlation structure and decay rate. (a) Diagonal covariance slow decay  (b) Diagonal covariance
fast decay  (c) Random covariance slow decay  (d) Random covariance fast decay. Right panels: (e)
False positive rate against p-value threshold on the gene expression experiment of Section 4 for RP
((cid:63))  BS  CQ  SD and enrichment test  (f) zoom on the p-value < 0.1 region.

7

False positive rateTrue positive rate0.00.20.40.60.81.00.00.20.40.60.81.0RPSDCQBSKFDAMMDTreeRankFalse positive rateTrue positive rate0.00.20.40.60.81.00.00.20.40.60.81.0RPSDCQBSKFDAMMDTreeRank0.00.20.40.60.81.00.00.20.40.60.81.0Nominal level αFalse positive rateRPSDCQBSHGFalse positive rateTrue positive rate0.00.20.40.60.81.00.00.20.40.60.81.0RPSDCQBSKFDAMMDTreeRankFalse positive rateTrue positive rate0.00.20.40.60.81.00.00.20.40.60.81.0RPSDCQBSKFDAMMDTreeRank0.000.020.040.060.080.100.000.020.040.060.080.10Nominal level αFalse positive rateRPSDCQBSHGsample problems is genuinely high-dimensional. Speciﬁcally  we have 14× ((cid:0)6

Comparison on high-dimensional gene expression data. The ability to identify gene sets having
different expression between two types of conditions  e.g.  benign and malignant forms of a disease 
is of great value in many areas of biomedical research. Likewise  there is considerable motivation to
study our procedure in the context of detecting differential expression of p genes between two small
groups of patients of sizes n1 and n2.
To compare the performance our T 2
k statistic against competitors CQ and SD in this type of appli-
cation  we constructed a collection of 1680 distinct two-sample problems in the following manner 
using data from three genomic studies of ovarian [21]  myeloma [22] and colorectal [23] cancers.
First  we randomly split the 3 datasets respectively into 6  4  and 6 groups of approximately 50
patients. Next  we considered pairwise comparisons between all sets of patients on each of 14
biologically meaningful gene sets from the canonical pathways of MSigDB [24]  with each gene set
containing between 75 and 128 genes. Since n1 (cid:39) n2 (cid:39) 50 for all patient sets  our collection of two-
problems under H0 and 14× (6· 4 + 6· 4 + 6· 6) = 1176 problems under H1—assuming that every
gene set was differentially expressed between two sets of patients with different cancers  and that no
gene set was differentially expressed between two sets of patients with the same cancer type.4
A natural performance measure for comparing test statistics is the actual false positive rate (FPR)
as a function of the nominal level α. When testing at level α  the actual FPR should be as close to α
as possible  but differences may occur if the distribution of the test statistic under H0 is not known
exactly (as is the case in practice). Figure 1 (e) shows that the curve for our procedure is closer to
the optimal diagonal line for most values of α than the competing curves. Furthermore  the lower-
left corner of Figure 1 (e) is of particular importance  as practitioners are usually only interested in
p-values lower than 10−1. Figure 1 (f) is a zoomed plot of this region and shows that the SD and
CQ tests commit too many false positives at low thresholds. Again  in this regime  our procedure
is closer to the diagonal and safely commits fewer than the allowed number of false positives. For
example  when thresholding p-values at 0.01  SD has an actual FPR of 0.03  and an even more
excessive FPR of 0.02 when thresholding at 0.001. The tests of CQ and BS are no better. The same
thresholds on the p-values of our test lead to false positive rates of 0.008 and 0 respectively.
With consideration to ROC curves  the samples arising from different cancer types are dissimilar
enough that BS  CQ  SD  and our method all obtain perfect ROC curves (no H1 case has a larger p-
value than any H0 case). We also note that the hypergeometric test-based (HG) enrichment analysis
often used by experimentalists on this problem [25] gives a suboptimal area-under-curve of 0.989.

(cid:1)) = 504

2

(cid:1) +(cid:0)4

(cid:1) +(cid:0)6

2

2

5 Conclusion

We have proposed a novel testing procedure for the two-sample test of means in high dimensions.
This procedure can be implemented in a simple manner by ﬁrst projecting a dataset with a single
randomly drawn matrix  and then applying the standard Hotelling T 2 test in the projected space. In
addition to obtaining the asymptotic power of this test  we have provided interpretable conditions on
the covariance matrix Σ for achieving greater power than competing tests in the sense of asymptotic
relative efﬁciency. Speciﬁcally  our theoretical comparisons show that our test is well suited to
interesting regimes where most of the variance in the data can be captured in a relatively small
number of variables  or where the variables are highly correlated. Furthermore  in the realistic case
of (n  p) = (98  200)  these regimes were shown to correspond to favorable performance of our test
against several competitors in ROC curve comparisons on simulated data. Finally  we showed on
real gene expression data that our procedure was more reliable than competitors in terms of its false
positive rate. Extensions of this work may include more reﬁned applications of random projection
to high-dimensional testing problems.
Acknowledgements. The authors thank Sandrine Dudoit  Anne Biton  and Peter Bickel for helpful
discussions. MEL gratefully acknowledges the support of the DOE CSGF Fellowship under grant
number DE-FG02-97ER25308  and LJ the support of Stand Up to Cancer. MJW was partially
supported by NSF grant DMS-0907632.

4Although this assumption could be violated by the existence of various cancer subtypes  or technical dif-
ferences between original tissue samples  our initial step of randomly splitting the three cancer datasets into
subsets guards against these effects.

8

References
[1] E. L. Lehmann and J. P. Romano. Testing statistical hypotheses. Springer Texts in Statistics. Springer 

New York  third edition  2005.

[2] Y. Lu  P. Liu  P. Xiao  and H. Deng. Hotelling’s T2 multivariate proﬁling for detecting differential expres-

sion in microarrays. Bioinformatics  21(14):3105–3113  Jul 2005.

[3] J. J. Goeman and P. B¨uhlmann. Analyzing gene expression data in terms of gene sets: methodological

issues. Bioinformatics  23(8):980–987  Apr 2007.

[4] D. V. D. Ville  T. Blue  and M. Unser. Integrated wavelet processing and spatial statistical testing of fMRI

data. Neuroimage  23(4):1472–1485  2004.

[5] U. Ruttimann et al. Statistical analysis of functional MRI data in the wavelet domain. IEEE Transactions

on Medical Imaging  17(2):142–154  1998.

[6] Z. Bai and H. Saranadasa. Effect of high dimension: by an example of a two sample problem. Statistica

Sinica  6:311 329  1996.

[7] M. S. Srivastava and M. Du. A test for the mean vector with fewer observations than the dimension.

Journal of Multivariate Analysis  99:386–402  2008.

[8] M. S. Srivastava. A test for the mean with fewer observations than the dimension under non-normality.

Journal of Multivariate Analysis  100:518–532  2009.

[9] S. X. Chen and Y. L. Qin. A two-sample test for high-dimensional data with applications to gene-set

testing. Annals of Statistics  38(2):808–835  Feb 2010.

[10] S. Cl´emenc¸on  M. Depecker  and Vayatis N. AUC optimization and the two-sample problem. In Advances

in Neural Information Processing Systems (NIPS 2009)  2009.

[11] A. Gretton  K. M. Borgwardt  M. Rasch  B. Sch¨olkop  and A.J. Smola. A kernel method for the two-
In B. Sch¨olkopf  J. Platt  and T. Hoffman  editors  Advances in Neural Information

sample-problem.
Processing Systems 19  pages 513–520. MIT Press  Cambridge  MA  2007.

[12] Z. Harchaoui  F. Bach  and E. Moulines. Testing for homogeneity with kernel Fisher discriminant analysis.

In John C. Platt  Daphne Koller  Yoram Singer  and Sam T. Roweis  editors  NIPS. MIT Press  2007.

[13] M. E. Lopes  L. J. Jacob  and M. J. Wainwright. A more powerful two-sample test in high dimensions

using random projection. Technical Report arXiv: 1108.2401  2011.

[14] S. S. Vempala. The Random Projection Method. DIMACS Series in Discrete Mathematics and Theoretical

Computer Science. American Mathematical Society  2004.

[15] L. Jacob  P. Neuvial  and S. Dudoit. Gains in power from structured two-sample tests of means on graphs.

Technical Report arXiv: q-bio/1009.5173v1  2010.

[16] J. A. Cuesta-Albertos  E. Del Barrio  R. Fraiman  and C. Matr´an. The random projection method in
goodness of ﬁt for functional data. Computational Statistics & Data Analysis  51(10):4814–4831  2007.

[17] R. J. Muirhead. Aspects of Multivariate Statistical Theory. John Wiley & Sons  inc.  1982.
[18] A. W. van der Vaart. Asymptotic Statistics. Cambridge  2007.
[19] A. P. Dempster. A high dimensional two sample signiﬁcance test. Annals of Mathematical Statistics 

29(4):995–1010  1958.

[20] A. P. Dempster. A signiﬁcance test for the separation of two highly multivariate small samples. Biomet-

rics  16(1):41–50  1960.

[21] R. W. Tothill et al. Novel molecular subtypes of serous and endometrioid ovarian cancer linked to clinical

outcome. Clin Cancer Res  14(16):5198–5208  Aug 2008.

[22] J. Moreaux et al. A high-risk signature for patients with multiple myeloma established from the molecular

classiﬁcation of human myeloma cell lines. Haematologica  96(4):574–582  Apr 2011.

[23] R. N. Jorissen et al. Metastasis-associated gene expression changes predict poor outcomes in patients

with dukes stage b and c colorectal cancer. Clin Cancer Res  15(24):7642–7651  Dec 2009.

[24] A. Subramanian et al. Gene set enrichment analysis: a knowledge-based approach for interpreting

genome-wide expression proﬁles. Proc. Natl. Acad. Sci. USA  102(43):15545–15550  Oct 2005.

[25] T. Beissbarth and T. P. Speed. Gostat: ﬁnd statistically overrepresented gene ontologies within a group of

genes. Bioinformatics  20(9):1464–1465  Jun 2004.

9

,Shinichi Nakajima
Issei Sato
Masashi Sugiyama
Kazuho Watanabe
Hiroko Kobayashi
Vignesh Ganapathiraman
Xinhua Zhang
Yaoliang Yu
Junfeng Wen