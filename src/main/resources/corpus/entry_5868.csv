2011,Variational Learning for Recurrent Spiking Networks,We derive a plausible learning rule updating the synaptic efficacies   for feedforward  feedback and lateral connections between observed and latent neurons.    Operating in the context of a generative model for distributions of spike sequences     the learning mechanism is derived from variational inference principles. The synaptic plasticity rules found   are interesting in that they are strongly reminiscent of experimentally found results on Spike Time    Dependent Plasticity  and in that they differ for excitatory and inhibitory neurons. A simulation   confirms the method's applicability to learning both stationary and temporal spike patterns.,Variational Learning for Recurrent Spiking Networks

Danilo Jimenez Rezende

Brain Mind Institute

´Ecole Polytechnique F´ed´erale de Lausanne

1015 Lausanne EPFL  Switzerland
danilo.rezende@epfl.ch

School of Computer and Communication Sciences  Brain Mind Institute

Daan Wierstra

´Ecole Polytechnique F´ed´erale de Lausanne

1015 Lausanne EPFL  Switzerland

daan.wierstra@epfl.ch

School of Computer and Communication Sciences  Brain Mind Institute

Wulfram Gerstner

´Ecole Polytechnique F´ed´erale de Lausanne

1015 Lausanne EPFL  Switzerland
wulfram.gerstner@epfl.ch

Abstract

We derive a plausible learning rule for feedforward  feedback and lateral connec-
tions in a recurrent network of spiking neurons. Operating in the context of a
generative model for distributions of spike sequences  the learning mechanism is
derived from variational inference principles. The synaptic plasticity rules found
are interesting in that they are strongly reminiscent of experimental Spike Time
Dependent Plasticity  and in that they differ for excitatory and inhibitory neurons.
A simulation conﬁrms the method’s applicability to learning both stationary and
temporal spike patterns.

1

Introduction

This study considers whether recurrent networks of spiking neurons can be seen as a generative
model not only of stationary patterns but also of temporal sequences. More precisely  we derive a
model that learns to adapt its spontaneously spike sequences to conform as closely as possible to the
empirical distribution of actual spike sequences caused by inputs impinging upon the sensory layer
of the network.
A generative model is a model of the joint distribution of percepts and hidden causes in the world.
Since the world has complex temporal relationships  we need a model that is able to both recognize
and predict temporal patterns. Behavioural studies (e.g.  [1]) support the assumption that the brain is
performing approximate Bayesian inference. More recently  evidence for this hypothesis was found
in electro-physiological work as well [2]. Various abstract Bayesian models have been proposed
to account for this phenomenon [3  4  5  6  7]. However  it remains an open question whether
optimization in abstract Bayesian models can be translated into plausible learning rules for synapses
in networks of spiking neurons.
In this paper  we show that the derivation of spike-based plasticity rules from statistical learning
principles yields learning dynamics for a generative spiking network model which are akin to those

1

Figure 1: A network of spiking neurons  divided into observed and latent pools of neurons.

of Spike-Time Dependent Plasticity (STDP) [8]. Our learning rule is derived from a variational
optimization process. Typically  optimization in recurrent Bayesian networks involves both forward
and backward propagation steps. We propose a plasticity rule that approximates backward steps by
the introduction of delayed updates in the synaptic weights and dynamics. The theory is supported
by simulations in which we demonstrate that the learning mechanism is able to capture the hidden
causes behind the observed spiking patterns.
We use the Spike Response Model (SRM) [9  10]  in which spikes are generated stochastically de-
pending on the neuronal membrane potential. The SRM is an example of a generalized linear model
(GLM). It is closely related to the integrate-and-ﬁre model  and has been successfully used to ex-
plain neuronal spike trains [11  12]. In this model  the membrane potential of a neuron i at time t 
expressed as ui(t) is given by

⌧ ˙ui(t) = ui(t) + bi +Xj

Wi jXj(t) 

(1)

j 2{t1

j  ... tN
j }

(t  tf

j   . . .   tN

j )  where {t1

where bi is a bias which represents a constant external input to the neuron  and Xj(t) is the spike
train of the jth neuron deﬁned by Xj(t) =Ptf
j } is the set
of spike timings. The diagonal elements of the synaptic matrix are kept ﬁxed to a negative value
Wi i = ⌘0 with ⌘0 = 1.0  which implements a reset of the membrane potential after each spike
and is a simple way to take into account neuronal refractoriness [9  13]. The time constant is taken
to be ⌧ = 10ms as in [13]. The spike generation process is stochastic with time-dependent ﬁring
intensity ⇢i(t) which depends on the membrane potential ui(t):
⇢i(t) = ⇢0 exp (ui(t)) .

(2)
An exponential dependence of the ﬁring intensity upon the membrane potential agrees with exper-
imental results [12]. The set of equations (2) and (1) captures the simpliﬁed dynamics of a spiking
neuron with stochastic spike timing.
In the following sections  we will introduce the theoretical framework and the approximations used
in this paper. The basic learning mechanism is introduced and derived  followed by a simulation
illustrating that our proposed learning rule is able to learn spatio-temporal features in the input spike
trains and reproduce them in its spontaneous activity.

2 Principled Framework

We consider a network consisting of two distinct sets of neurons  observed neurons ( also called
visible neurons or V) and latent neurons ( also called hidden or H)  as illustrated in Figure 1. The
activities of the observed neurons represent the quantity of interest to be modelled  while the latent
neurons fulﬁll a mediating role representing the hidden causes of the observed spike train.
Learning in the context of this neuronal network consists of changing the synaptic strengths between
neurons. We postulate that the underlying principle behind learning relies on learning distributions
of spike trains evoked by either sensory inputs or more complicated sequences of cognitive events.
In statistics  learning distributions involves minimizing a measure of distance between the model
(that is  our neuronal network) and a target distribution (e.g. observations). A principled measure of
distance between two distributions p and pempirical is the Kullback-Leibler divergence [14] deﬁned as

KL(pempirical||p) =Z DXpempirical(X) log

pempirical(X)

p(X)

.

(3)

2

where individual X represent entire spike trains. DX is a measure of integration over spike trains.
Our learning mechanism tries to minimize the KL divergence between the distribution deﬁned by
our network p(X) and the observed spike timings distribution pempirical that is evoked by an unknown
external process. Note that minimizing the KL divergence entails maximizing the likelihood that the
observed spike trains XV could have been generated by the model.
In order to derive the learning dynamics of our model in the next section  we need to evaluate the
gradient of the likelihood (3) with respect to the free parameters of our model  i.e.
the synaptic
efﬁcacies Wi j and biases bi.
The joint likelihood of a particular spike train of both the observed XV and the latent neurons XH
under our neuronal model can be written as [13]

log p(XV   XH) = Xi2V[HZ T

0

d⌧ [log ⇢i(⌧ )Xi(⌧ )  ⇢i(⌧ )]

(4)

Since we have a neuronal network including latent units (that is  neurons not receiving external
inputs)  the actual observation likelihood is an effective quantity obtained by integrating over all
possible latent spike trains XH 

p(XV ) =Z DXHp(XV   XH).

The gradient of (5) is given by an expectation conditioned on the observed neurons’ history:

r log p(XV ) = r logZ DXHp(X) = hr log p(X)ip(XH|XV )

where hf (X)ip =R DXf (x)p(x). This is difﬁcult to evaluate since it conditions an entire latent

spike train on an entire observed spike train. In other words  the posterior distribution of spike-
timings of the latent neurons depends on both past and future of the observed neurons’ spike train.

2.1 Weak Coupling Approximation

In order to render the model more tractable  we introduce an approximation on the dynamics based
on the weak coupling approximation [15]  which amounts to replacing (1) by

(5)

(6)

(7)

(9)

where zi(t) is a Gaussian process with mean zero and inverse variance 1 i(t) given by

Wi j⇢j(t) + zj(t) 

⌧ ˙ui(t) = ui(t) + bi +Xj
⌧ 2Xj

(t) = 0 +

1
i

1

W 2

i j⇢j(t) 

where 0 is intrinsic noise which we have added to regularize the simulations (we assume 0 = 0.1).
Note that i(t) is a function of both the network state and synaptic efﬁcacies. Our network model
deﬁnes a joint distribution between observed input spike trains and membrane potentials given by

where terms not depending on the model parameters and latent states have been dropped out as they
do not contribute to the gradients we are interested in and fi(t) is the drift of the Gaussian process
of the membrane potentials and can be read from equation (6). It is given by

log p(XV   u) =Xi2VZ dt [Xi(t)ui(t)  ⇢0 exp(ui(t))]  Xi2V[HZ dt
Wi j⇢j(t)1A

fi(t) =

i(t)

2

( ˙ui(t)  fi(t))2 

(8)

t

1The variance of ˙u due to the external input can be obtained by noting that ui(t+dt) = ui(t) exp(dt/⌧ )+
R t+dt
ds exp((s  t  dt)/⌧ )(bi +Pj Wi jXj(t))/⌧. Thus  in the weak coupling regime
V ar(u(t + dt)|u(t)) =Xj
⌧ 2Xj

ds exp(2(s  t  dt)/⌧ )(⇢j(t))/⌧ 2 =

i j⇢j(t)

W 2

W 2

dt

1

⌧ 0@ui(t) + bi +Xj
i jZ t+dt

t

3

The weak coupling approximation amounts to replacing spikes of the latent neurons by intensities
plus Gaussian noise. Note that in this approximated model  the latent variables are non longer
the latent spike trains  but the membrane potentials. However  we emphasize that in the end the
intensities can be substituted by spikes as we will see below.

2.2 Variational Approximation of the Posterior Membrane Potential p(u|XV )
The variational approach in statistics is a method to approximate some complex distribution p by a
family of simpler distributions q . Variational methods have been applied to spiking neural networks
in many different contexts  such as in connectivity or external source inference [20  21]. In the
following  we try to interpret the neural activity and plasticity together as an approximate form of
variational learning.
We approximate the posterior p(u|XV ) by the Gaussian process

log q(u) = Xi Z dt

i(t)

2

( ˙ui(t)  hi(t))2 + c

(10)

where the hi(t) are variational parameters representing the drift of the ith membrane potential at
time t in the posterior process and c is a normalization constant. Note that the parameters i(t) of
the posterior process are taken to be the same as the network dynamics noise in (6). This is necessary
in order to have a ﬁnite KL-divergence between the prior and the posterior processes [22].
Finding a good approximation for the variational parameters hi(t) amounts to minimizing the quan-
tity KL(q(u) k p(XV   u))  which is given by

KL(q k p) = Z dt*Xi2V
+ Xi2V[H

2

i(t)

[Xi(t)ui(t)  ⇢0 exp(ui(t))]

( ˙ui(t)  fi(t))2  Xi2V[H

i(t)

2

( ˙ui(t)  hi(t))2+q(u)

(11)

Although (11) can be written analytically in terms of the instantaneous mean and covariance of the
posterior process  we adopt a simpler mean-ﬁeld approximation  i.e. hF (ui(t))i ⇡ F (hui(t)i). We
write the mean hui(t)i = ¯ui(t) as

¯ui(t) = ¯ui(0) +Z t

0

dshi(s)

(12)

where the hi plays the role of the ’drift’ or the derivative of ¯ui. Note that  ¯ui(t)
where ⇥(x) is the Heaviside step function. As a result  the KL-divergence becomes

KL(q k p) ⇡ Z dtXi ⇢ [Xi(t)¯ui(t)  ⇢0 exp(¯ui(t))] i2V +
KL = Z dt [Xk(t)  ⇢0 exp(¯uk(t))] ⇥(t  t0)k2V

hk(t0)



i(t)

2

The drifts hi(t) of the variational approximation can be updated using gradient descent

hj (t0) =⇥( t  t0)i j 
(hi(t)  fi(t))2 (13)

where

+ k(t0)(hk(t0)  fi(t0)) Z dtXi
2Xi Z dt

(hi(t)  fi(t))2 

i(t)
hk(t0)

+

1

i(t)(hi(t)  fi(t))

fi(t)
hk(t0)
i(t)
hk(t0)

=

1
⌧

= 

(i k + Wi k⇢k(t)) ⇥(t  t0)
1
⌧ 2 2

i k⇢k(t)⇥(t  t0)

i (t)W 2

4

fi(t)
hk(t0)

(14)

(15)

(16)

Figure 2: Posterior ﬁring intensity for two simple networks: (a) A network with 4 neurons  simulated with
mean ﬁeld approximation. (b) From top to bottom: the observed spike train  the ﬁring intensity for the three
latent neurons and the posterior inverse variance. The green neuron has a direct connection to the observed
neuron  and as such has a much stronger modulation of its ﬁring rate than the other two latent neurons. (c) A
network with two pools of 20 neurons  the observed and the latent pools. (d) Simulation results. From top to
bottom: observed spike trains  spike trains in the latent pool and mean ﬁring intensities of the latent neurons
over different realizations of the network. The rate of the latent pool increases just before the spikes of the
observed neurons. Note that the spiking implementation of the model has the same rates as the mathematical
rate model.

There are few key points to note regarding (14). First  in the absence of observations  the best
approximating hi(t) is simply given by fi(t)  that is the posterior and the prior processes become
equal. Second  the ﬁrst  third and fourth terms in (14) are backward terms  that is  they correspond
to corrections in the “belief” about the past states generated by new inputs. This implies that in
order to estimate the drift hi(t) of the posterior membrane potential of neuron i at time t  we need to
know the observations X(t0) at time t0 > t. Third  the fourth term in equation (14) is a contribution
to the gradient that comes from the fact that the inverse variance i(t) deﬁned in equation (7) is also
a function of the network state. This is an important feature of the model  since it implies that the
amount of noise in the dynamics is also being adapted to better explain the observed spike trains.

2.3 Towards Spike-time Dependent Plasticity

We learn the parameters of our network  that is  the synaptic weights and the neural ‘biases’ by
gradient descent with learning rate ⌘:

bi


(hi(t)  fi(t))

⌧
k(t)

i(t)

(17)

bi = ⌘
Wk l = ⌘

(hk(t)  fk(t))⇢l(t)

⌧

(hi(t)  fi(t))2 

(18)

KL = ⌘Z dt
KL = ⌘Z dt
2Xi Z dt

i(t)
Wk l

Wk l
1

+⌘

5

where i(t)
Wk l
computation of b and W can be done purely locally.

= 2 1

⌧ 2 2

i (t)Wi l⇢l(t)k i. Note that once the posterior drift hi(t) is known  the

A long ‘backward window’ would  of course  be biologically implausible. However  on-line ap-
proximations to the backward terms provide a reasonable approximation by taking small backwards
ﬁlters of up to 50ms. Mechanistically  applications of W can operate with a small delay  which
is required to calculate the backwards correction term. In biology such delays indeed exist  as the
weights are switched to a new value only some time after the stimulation that induces the change
[23  24]
More precisely  using a small backward window amounts to approximating the gradient of the pos-
terior drift hi(t) by cutting off the time integrals using a ﬁnite time horizon  i.e.  in equation (14)
dt where T is the size of the “backward window” used to

approximate the gradient. The expression (14) can now be written as a delayed update equation

t0

we replace integralR dt byR t0+T
hk(t  T ) / Z t
 Z t
dsXi
2Xi Z t

tT

tT

+

1

ds [Xk(s)  ⇢0 exp(¯uk(s))] k2V
+ k(t  T )(hk(t  T )  fk(t  T ))

tT

i(s)(hi(s)  fi(s))

ds

i(s)

hk(t  T )

fi(s)

hk(t  T )
(hi(s)  fi(s))2 

(19)

The resulting update for the variable hk is used in the learning equation 18.
The simulation shown in Figure 2 provides a conceptual illustration of how the posterior ﬁring
intensity ⇢l(t) propagates information backward from observed into latent neurons  a process that is
essential for learning temporal patterns. Note that ⇢l is the ﬁring rate of the presynaptic neuron l and
as such it is information that is not directly available at the site of the synapse which has only access
to spike arrivals (but not the underlying ﬁring rate). However  spike arrivals do provide a reasonable
estimate of the rate. Indeed Figure 2c and d show that a simulation of a network of pools of spiking
neurons where updates are only based on spike times (rather than rates) gives qualitatively the same
information as the rate formula derived above.
In equations (20 15) we could therefore replace
the pre-synaptic ﬁring intensity ⇢j(t) by temporally ﬁltered spike trains which constitute a good
approximation to ⇢j(t).

2.4 STDP Window

2Xk

From our learning equation for the synaptic weight (18)  we can extract an STDP-like learning

window by rewriting the plasticity rules as Wi j =R dtWi j(t)  where

i(t)

1

Wi j(t) =

(hi(t)  fi(t))⇢j(t) +

⌧

k(t)
Wi j

(hk(t)  fk(t))2

(20)

Wi j(t) is the expected change in Wi j at time t under the posterior. As before  we replace the
ﬁring intensity ⇢j in a given trial by the spikes. Assuming a spike of the observed neuron at t = 0 
we have evaluated h(t) and f (t) and plot the weight change k(t0)(hk(t0)  fk(t0)) that would
occur if the latent neuron ﬁres at t0 cf. equation (18). We show the resulting Spike-time Dependent
Plasticity for a simple network of two neurons in Figure 3.
Note that the shape of Wi j(t) is remarkably reminiscent of the experimentally found measure-
ments for STDP [8]. In particular  the shape of the STDP curve depends on the type of neuron
and is different for connections from excitatory to excitatory than from excitatory to inhibitory or
inhibitory to inhibitory neurons (Figure 3).

3 Simulations

In order to demonstrate the method’s ability to capture both stationary and temporal patterns  we
performed simulations on two tasks. The ﬁrst one involves the formation of a temporal chain  while
the second one involves a stationary pattern generator. Both simulations were done using a discrete-
time (Euler method) version of the equations (14  17  18 and 19) with dt = 1ms. The backward
window size was taken to be T = 50ms  and a learning rate of 0.02 was used.

6

Figure 3: Spike-time Dependent Plasticity in a simple network composed of two neurons. Weight change
Wi j(t) (vertical axis) as a function of spike timing of the neuron at the top (the latent neuron)  given that the
bottom (observed) neuron produces a spike at t = 0 (horizontal axis). Shown are all permutations of excitatory
(e) and inhibitory (i) neuron types  with the left and right learning windows next to each network corresponding
to the downward and upward synapses  respectively.

The ﬁrst task consisted of learning a periodic chain  in which three pools of observed neurons were
successively activated as shown in Figure 4a. A time lag was introduced between the third and
the ﬁrst pattern so as to force the network to form temporal hidden cause representations that are
capable of capturing time dependencies without obvious observable instantaneous clues – during
a blank moment  the only way a network can tell which pattern comes next is by actively using
the latent neurons. After learning  the spontaneously patterns in the observable neurons developed a
clear resemblance to the patterns provided during training  although a slightly larger amount of noise
was present  as shown in Figure 4b. If the noise level of the model network is reduced  a noise-free
“cleared-up concept” of the observed patterns is generated (Figure 4d) which clearly demonstrates
that the recurrent network has indeed learned the task.
The way learning has conﬁgured the network in the sequence task can be understood if we study the
connectivity pattern of the latent neurons. The latent neuron are active during the whole sequence
(Figure 4c). We have reordered the labels of the neurons so that the structure of the connectivity
matrix becomes as visble. There are subsets of latent neurons that are particularly active during each
of the three ’subpatterns’ in the sequence task  and other latent neurons that become active while the
observable units are quiescent (Figure 4i). The lateral connectivity between the latent neurons has
an asymmetry in the forward direction of the chain.
The second task aimed at learning to randomly generate one of three statinonary patterns every
10ms. Successfull learning of this task requires both the learning of the stationary patterns and the
stochastic transitions between them. Figure 4d–g shows the results on this task.

4 Discussion

Some models have recently been proposed where STDP-like learning rules derive from ‘ﬁrst princi-
ples’ (e.g.  [25  26  13]). However  these models have either difﬁculty dealing with recurrent latent
dynamics  or they do not account for non-factorial latent representations. In this work  we have pro-
posed a plausible derivation for synaptic plasticity in a network consisting of spiking neurons  which
can both capture time dependencies in observed spike trains and process combinatorial features. Us-
ing a generative model comprising both latent and observed neurons  the mechanism utilizes implicit
(that is  short-term delayed) backward iterations that arise naturally from variational inference. A
plasticity mechanism emerges that closely resembles that of the familiar STDP mechanism found
in experimental studies. In our simulations we show that the plasticity rules are capable of learning
both a temporal and a stationary pattern generator. Future work will attempt to further elucidate
the possible biological plausibility of the approach  and its connection to Spike-Time Dependent
Plasticity.

Acknowledgments

Support was provided by the SNF grant (CRSIK0 122697)  the ERC grant (268689) and the Sys-
temsX IPhD grant.

7

Figure 4: Simulation results. Sequence task a–d  i: a 20ms-periodic sequence with a network of 30 observed
neurons and 15 latent neurons having 50% of inhibitory neurons (chosen randomly). The connections between
the observed neurons have been set to zero in order to illustrate the use of latent-to-latent recurrent connections.
(a) A sample of the periodic input pattern. Note the long waiting time after each sequence 1  2  3 (1  2 
3wait123. . . ). (b) Simulations from the network with the ﬁrst 20ms clamped to the data. (c) Latent
neurons sample. (d) Sample simulation of the network with the same parameters but with less noise  in order
to better show the underlying dynamics. This is achieved by the transformation ⇢i(t) ! ⇢i(t) with  = 2.
Random jump task e–h: learning to produce one of three patterns (4ms long) every 10ms. (e) A sample input
pattern (f) One realization from the network with ﬁrst the 20ms clamped to the data. (g) Sample latent pattern.
(h) Sample simulation of the network with the same parameters but with less noise. Note that decreasing the
level of noise is actually an impairment in performance for this task. (i) The learned synaptic matrix for the
ﬁrst task; the latent neurons have been re-ordered in order show the role of the latent-to-latent synapses in the
dynamics as well as the role of the latent-to-observed synapses which represent the pattern features.

References
[1] Konrad P K¨ording and Daniel M Wolpert. Bayesian integration in sensorimotor learning. Nature 

427(6971):244–7  January 2004.

[2] P. Berkes  G. Orban  M. Lengyel  and J. Fiser. Spontaneous Cortical Activity Reveals Hallmarks of an

Optimal Internal Model of the Environment. Science  331(6013):83–87  January 2011.

[3] Wei Ji Ma  Jeffrey M Beck  and Alexandre Pouget. Spiking networks for Bayesian inference and choice.

Current opinion in neurobiology  18(2):217–22  April 2008.

[4] Joshua B Tenenbaum  Thomas L Grifﬁths  and Charles Kemp. Theory-based Bayesian models of induc-

tive learning and reasoning. Trends in cognitive sciences  10(7):309–18  2006.

[5] Konrad P K¨ording and Daniel M Wolpert. Bayesian decision theory in sensorimotor control. Trends in

cognitive sciences  10(7):319–26  July 2006.

[6] D. Acuna and P. Schrater. Bayesian modeling of human sequential decision-making on the multi-armed
bandit problem. In Proceedings of the 30th Annual Conference of the Cognitive Science Society. Wash-
ington  DC: Cognitive Science Society  2008.

[7] Michael D. Lee. A Hierarchical Bayesian Model of Human Decision-Making on an Optimal Stopping

Problem. Cognitive Science  30(3):1–26  May 2006.

8

[8] G. Bi and M. Poo. Synaptic modiﬁcation by correlated activity: Hebb’s postulate revisited. Annual review

of neuroscience  24(1):139–166  2001.

[9] W. Gerstner and W. K. Kistler. Mathematical Formulations of Hebbian Learning. Biological Cybernetics 

87(5-6):404–415  2002. article.

[10] W. Gerstner. Spike-response model. Scholarpedia  3(12):1343  2008.
[11] J W Pillow  J Shlens  L Paninski  A Sher  A M Litke  E J Chichilnisky  and E P Simoncelli. Spatio-
temporal correlations and visual signaling in a complete neuronal population. Nature  454(7206):995–
999  Aug 2008.

[12] Renaud Jolivet  Alexander Rauch  Hans R. L¨uscher  and Wulfram Gerstner. Predicting spike timing of
neocortical pyramidal neurons by simple threshold models. J Comput Neurosci  21(1):35–49  August
2006.

[13] J.P. Pﬁster  Taro Toyoizumi  D. Barber  and W. Gerstner. Optimal spike-timing-dependent plasticity for

precise action potential ﬁring in supervised learning. Neural Computation  18(6):1318–1348  2006.

[14] S. Kullback and R. A. Leibler. On Information and Sufﬁciency. The Annals of Mathematical Statistics 

22(1):79–86  March 1951.

[15] Taro Toyoizumi  Kamiar Rahnama Rad  and Liam Paninski. Mean-ﬁeld approximations for coupled
populations of generalized linear model spiking neurons with Markov refractoriness. Neural computation 
21(5):1203–43  May 2009.

[16] Brendan J. Frey and Geoffrey E. Hinton. Variational Learning in Nonlinear Gaussian Belief Networks.

Neural Computation  11(1):193–213  January 1999.

[17] Karl Friston  J´er´emie Mattout  Nelson Trujillo-Barreto  John Ashburner  and Will Penny. Variational free

energy and the Laplace approximation. NeuroImage  34(1):220–34  January 2007.

[18] Matthew J Beal and Zoubin Ghahramani. Variational Bayesian Learning of Directed Graphical Models

with Hidden Variables. Bayesian Analysis  1(4):793–832  2006.

[19] T.S. Jaakkola and M.I. Jordan. Bayesian parameter estimation via variational methods. Statistics and

Computing  10(1):25–37  2000.

[20] Jayant E Kulkarni and Liam Paninski. Common-input models for multiple neural spike-train data. Net-

work (Bristol  England)  18(4):375–407  December 2007.

[21] Ian H Stevenson  James M Rebesco  Nicholas G Hatsopoulos  Zach Haga  Lee E Miller  and Konrad P
K¨ording. Bayesian inference of functional connectivity and network structure from spikes. IEEE trans-
actions on neural systems and rehabilitation engineering : a publication of the IEEE Engineering in
Medicine and Biology Society  17(3):203–13  June 2009.

[22] C. Archambeau  Dan Cornford  Manfred Opper  and J. Shawe-Taylor. Gaussian process approximations
of stochastic differential equations. In Journal of Machine Learning Research Workshop and Conference
Proceedings  volume 1  pages 1–16. Citeseer  2007.

[23] Daniel H O’Connor  Gayle M Wittenberg  and Samuel S-H Wang. Graded bidirectional synaptic plasticity
is composed of switch-like unitary events. Proceedings of the National Academy of Sciences of the United
States of America  102(27):9679–84  July 2005.

[24] C C Petersen  R C Malenka  R a Nicoll  and J J Hopﬁeld. All-or-none potentiation at CA3-CA1 synapses.
Proceedings of the National Academy of Sciences of the United States of America  95(8):4732–7  April
1998.

[25] Rajesh P N Rao. Bayesian computation in recurrent neural circuits. Neural computation  16(1):1–38 

January 2004.

[26] Bernhard Nessler  Michael Pfeiffer  and Wolfgang Maass. STDP enables spiking neurons to detect hidden
causes of their inputs. Advances in Neural Information Processing Systems (NIPS09)  pages 1357–1365 
2009.

9

,Yingzhen Yang
Feng Liang
Shuicheng Yan
Zhangyang Wang
Thomas Huang