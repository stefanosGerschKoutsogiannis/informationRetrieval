2013,Blind Calibration in Compressed Sensing using Message Passing Algorithms,Compressed sensing (CS) is a concept that allows to acquire compressible signals with a small number of measurements. As such  it is very attractive for hardware implementations. Therefore  correct calibration of the hardware is a central issue. In this paper we study the so-called blind calibration  i.e. when the training signals that are available to perform the calibration are sparse but unknown. We extend the approximate message passing (AMP) algorithm used in CS to the case of blind calibration. In the calibration-AMP  both the gains on the sensors and the elements of the signals are treated as unknowns. Our algorithm is also applicable to settings in which the sensors distort the measurements in other ways than multiplication by a gain  unlike previously suggested blind calibration algorithms based on convex relaxations. We study numerically the phase diagram of the blind calibration problem  and show that even in cases where convex relaxation is possible  our algorithm requires a smaller number of measurements and/or signals in order to perform well.,Blind Calibration in Compressed Sensing using

Message Passing Algorithms

Christophe Sch¨ulke

Univ Paris Diderot  Sorbonne Paris Cit´e 

ESPCI and CNRS UMR 7083

Paris 75005  France

Florent Krzakala

ENS and CNRS UMR 8550 
ESPCI and CNRS UMR 7083

Paris 75005  France

Francesco Caltagirone

Institut de Physique Th´eorique

CEA Saclay and CNRS URA 2306

91191 Gif-sur-Yvette  France

Lenka Zdeborov´a

Institut de Physique Th´eorique

CEA Saclay and CNRS URA 2306

91191 Gif-sur-Yvette  France

Abstract

Compressed sensing (CS) is a concept that allows to acquire compressible signals
with a small number of measurements. As such it is very attractive for hardware
implementations. Therefore  correct calibration of the hardware is a central is-
sue. In this paper we study the so-called blind calibration  i.e. when the training
signals that are available to perform the calibration are sparse but unknown. We
extend the approximate message passing (AMP) algorithm used in CS to the case
of blind calibration. In the calibration-AMP  both the gains on the sensors and the
elements of the signals are treated as unknowns. Our algorithm is also applica-
ble to settings in which the sensors distort the measurements in other ways than
multiplication by a gain  unlike previously suggested blind calibration algorithms
based on convex relaxations. We study numerically the phase diagram of the blind
calibration problem  and show that even in cases where convex relaxation is pos-
sible  our algorithm requires a smaller number of measurements and/or signals in
order to perform well.

1

Introduction

The problem of acquiring an N-dimensional signal x through M linear measurements  y = F x 
arises in many contexts. The Compressed Sensing (CS) approach [1  2] exploits the fact that  in
many cases of interest  the signal is K-sparse (in an appropriate known basis)  meaning that only
K = ρN out of the N components are non-zero. Compressed sensing theory shows that a K-sparse
N-dimensional signal can be reconstructed from far less than N linear measurements [1  2]  thus
saving acquisition time  cost or increasing the resolution. In the most common setting  the linear
M × N map F is considered to be known.
Nowadays  the concept of compressed sensing is very attractive for hardware implementations.
However  one of the main issues when building hardware revolves around calibration. Usually the
sensors introduce a distortion (or decalibration) to the measurements in the form of some unknown
gains. Calibration is about how to determine the transfer function between the measurements and
the readings from the sensor. In some applications dealing with distributed sensors or radars for
instance  the location or intrinsic parameters of the sensors are not exactly known [3  4]. Similar
distortion can be found in applications with microphone arrays [5]. The need for calibration has
been emphasized in a number of other works  see e.g. [6  7  8]. One common way of dealing with
calibration (apart from ignoring it or considering it as measurement noise) is supervised calibration

1

when some known training signals xl  l = 1  . . .   P and the corresponding observations yl are used
to estimate the distortion parameters. Given a sparse signal recovery problem  if we were not able
to previously estimate the distortion parameters via supervised calibration  we will need to estimate
the unknown signal and the unknown distortion parameters simultaneously - this is known as blind
(unsupervised) calibration. If such blind calibration is computationally possible  then it might be
simpler to do than the supervised calibration in practice. The main contribution of this paper is a
computationally efﬁcient message passing algorithm for blind calibration.

1.1 Setting

reading (measure) yµ = h(zµ  dµ  wµ) where zµ =(cid:80)N

We state the problem of blind calibration in the following way. First we introduce an unknown
distortion parameter (we will also use equivalently the term decalibration parameter or gain) dµ for
each of the sensors  µ = 1  . . .   M. Note that dµ can also represent a vector of several parameters.
We consider that the signal is linearly projected by a known M × N measurement matrix F and
only then distorted according to some known transfer function h. This transfer function can be
probabilistic (noisy)  non-linear  etc. Each sensor µ then provides the following distorted and noisy
i=1 Fµixi. As often in CS  we focus on the
case where the measurement matrix F is iid Gaussian with zero mean. For the measurement noise
wµ  one usually considers an iid Gaussian noise with variance ∆  which is added to zµ.
In order to perform the blind calibration  we need to measure several statistically diverse signals.
Given a set of N-dimensional K-sparse signals xl with l = 1 ···   P   for each of the signals we
consider M sensor readings

N(cid:88)

yµl = h(zµl  dµ  wµl)   where

zµl =

Fµixil  

(1)

i=1

where dµ are the signal-independent distortion parameters  wµl is a signal-dependent measurement
noise  and h is an arbitrary known function of these variables with standard regularity requirements.
To illustrate a situation in which one has sample dependent noise wµl and sample independent
distortion dµ  consider for instance sound sensors placed in space at positions dµ that are not exactly
known. The positions  however  do not change when different sounds are recorded. The noise wµl
is then the ambient noise that is different during every recording.
The ﬁnal inference problem is hence as follows: Given the M × P measurements yµl and a perfect
knowledge of the matrix F   we want to infer both the P different signals {x1 ··· xP} and the M
distortion parameters dµ  µ = 1 ··· M. In this work we place ourselves in the Bayesian setting
where we assume the distribution of the signal elements  PX  and the distortion coefﬁcients  PD  to
be known.

1.2 Relation to previous work

As far as we know  the problem of blind calibration was ﬁrst studied in the context of compressed
sensing in [9] where the distortions were considered as multiplicative  i.e. the transfer function was

h(zµl  dµ  wµl) =

1
dµ

(zµl + wµl) .

(2)

A subsequent work [10] considers a more general case when the distortion parameters are dµ =
(gµ  θµ)  and the transfer function h(zµl  dµ  wµl) = eiθµ (zµl + wµl)/gµ. Both [9] and [10] applied
convex optimization based algorithms to the blind calibration problem and their approach seems
to be limited to the above special cases of transfer functions. Our approach is able to deal with a
general transfer function h  and moreover for the product-transfer-function (2) it outperforms the
algorithm of [9].
The most commonly used algorithm for signal reconstruction in CS is the (cid:96)1 minimization of [1].
In CS without noise and for measurement matrices with iid Gaussian elements  the (cid:96)1 minimization
algorithm leads to exact reconstruction as long as the measurement rate α = M/N > αDT in the
limit of large signal dimension  where αDT is a well known phase transition of Donoho and Tanner
[11]. The blind calibration algorithm of [9  10] also directly uses (cid:96)1 minimization for reconstruction.

2

In the last couple of years  the theory of CS witnessed a large progress thanks to the development of
message passing algorithms based on the standard loopy Belief Propagation (BP) and their analysis
[12  13  14  15  16]. In the context of compressed sensing  the canonical loopy BP is difﬁcult to im-
plement because its messages would be probability distributions over a continuous support. At the
same time in problems such as compressed sensing  Gaussian or quadratic approximation of BP still
contains the information necessary for a successful reconstruction of the signal. Such approxima-
tions of loopy BP originated in works on CDMA multiuser detection [17  18]. In compressed sensing
the Gaussian approximation of BP is known as the approximate message passing (AMP) [12  13] 
and it was used to prove that with properly designed measurement matrices F the signal can be
reconstructed as long as the number of measurements is larger than the number of non-zero compo-
nent in the signal  thus closing the gap between the Donoho-Tanner transition and the information
theoretical lower bound [15  16]. Even without particular design of the measurement matrices the
AMP algorithm outperforms the (cid:96)1-minimization for a large class of signals. Importantly for the
present work  [14] generalized the AMP algorithm to deal with a wider range of input and output
functions. For some of those  generalizations of the (cid:96)1-minimization based approach are not convex
anymore  and hence they do not have the advantage of provable computational tractability anymore.
The following two works have considered blind calibration related problems with the use of AMP-
like algorithms. In [19] the authors use AMP combined with expectation maximization to calibrate
gains that act on the signal components rather than on the measurement components as we consider
here. In [20] the authors study the case when every element of the measurement matrix F has to be
calibrated  in contrast to the row-constant gains considered in this paper. The setting of [20] is much
closer to the dictionary learning problem and is much more demanding  both computationally and
in terms of the number of different signals necessary for successful calibration.

1.3 Contributions

In this work we extend the generalized approximate message passing (GAMP) algorithm of [14]
to the problem of blind calibration with a general transfer function h  eq. (1). We denote it as the
calibration-AMP or Cal-AMP algorithm. The Cal-AMP uses P > 1 unknown sparse signals to learn
both the different signals xl  l = 1  . . .   P   and the distortion parameters dµ  µ = 1  . . .   M  of the
sensors. We hence overcome the limitations of the blind calibration algorithm presented in [9  10]
to the class of settings for which the calibration can be written as a convex optimization problem.
In the second part of this paper we analyze the performance of Cal-AMP for the product transfer
function (2) used in [9] and demonstrate its scalability and better performance with respect to their
(cid:96)1-based calibration approach. In the numerical study we observe a sharp phase transition generaliz-
ing the phase transition seen for AMP in compressed sensing [21]. Note that for the blind calibration
problem to be solvable  we need the amount of information contained in the sensor readings  P M 
to be at least as large as the size of the vector of distortion parameters M  plus the number of the
non-zero components of all the signals  KP . Deﬁning ρ = K/N and α = M/N  this leads to
αP ≥ ρP + α. If we ﬁx the number of signals P we have a well deﬁned line in the (ρ  α)-plane
given by

(3)
below which exact calibration cannot be possible. We will compare the empirically observed phase
transition for blind calibration to this theoretical bound as well as to the phase transition that would
have been observed in the pure CS  i.e. if we knew the distortion parameters.

P − 1

α ≥ P

ρ ≡ αmin  

2 The Calibration-AMP algorithm

The Cal-AMP algorithm is based on a Bayesian probabilistic formulation of the reconstruction
problem. Denoting PX (xil) the assumed empirical distribution of the components of the signal 
PW (wµl) the assumed probability distribution of the components of the noise  and PD(dµ) the as-
sumed empirical distribution of the distortion parameters  the Bayes formula yields
P (x  d|F  y) =

dwµlPW (wµl)δ [yµl − h (zµl  dµ  wµl)]  

P M(cid:89)

N P(cid:89)

PX (xil)

PD(dµ)

M(cid:89)

(cid:90)

1
Z

i l=1

µ=1

l µ=1

(4)

3

µ(dµ) =(cid:82)(cid:81)

where Z is a normalization constant and zµl =(cid:80)

il(xil) = (cid:82)(cid:81)
(cid:81)
µ ddµ
il dxil P (x  d|F  y). The estimators x∗

(cid:81)
i Fµixil. We denote the marginals of the signal
jn(cid:54)=il dxjn P (x  d|F  y) and those of the distortion parame-
components νx
il that minimizes the expected
ters νd
mean-squared error (MSE) of the signals and the estimator d∗
µ of the distortion parameters are the av-
erages w.r.t. the marginal distributions  namely x∗
µ(dµ).
An exact computation of these estimates is not tractable in any known way so we use instead a
belief-propagation based approximation that has proven to be fast and efﬁcient in the CS problem
[12  13  14]. We remind that GAMP  that leads to a considerably simpler inference problem  is re-
covered if we set PD(dµ) = δ(dµ−1) and that usual AMP is recovered by setting h(z  d  w) = z+w
on top of it.

il =(cid:82) dxil xil νx

µ =(cid:82) ddµ dµ νd

il(xil) and d∗

γ(cid:54)=µ ddγ

Figure 1: Graphical model representing the blind calibration problem. Here the dimensionality of
the signal is N = 8  the number of sensors is M = 3  and the number of signals used for calibration
P = 2. The variable nodes xil and dµ are depicted as circles  the factor nodes as squares.

(cid:90)
(cid:90)

Given the factor graph representation of the calibration problem in Fig. 1  the canonical belief prop-
agation equations for the probability measure (4) are written in terms of N P M pairs of messages
˜mµl→il(xil) and mil→µl(xil)  representing probability distributions on the signal component xil 
and P M pairs of messages nµ→µl(dµ) and ˜nµl→µ(dµ)  representing probability distributions on
the distortion parameter dµ. Following the lines of [12  13  14  15]  with the use of the central
limit theorem  a Gaussian approximation  and neglecting terms that go to zero as N → ∞  the BP
equations can be closed using only the means and variances of the messages mil→µl and nµ→µl:

kµ→µl =

vil→µl =

ail→µl =

ddµ nµ→µl(dµ) dµ  

dxil mil→µl(xil) x2

dxil mil→µl(xil) xil  

(cid:90)
i Fµiail→µl and Vµl = (cid:80)
variables and factor nodes. For this we introduce ωµl = (cid:80)

(6)
Moreover  again neglecting only terms that go to zero as N → ∞  we can write closed equations on
quantities that correspond to the variables and factors nodes  instead of messages running between
µivil→µl.
The derivation of the Cal-AMP algorithm is similar to those in [12  13  14  15]. The resulting
algorithm is in the leading order equivalent to the belief propagation for the factor graph from Fig. 1.
To summarize the resulting algorithm we deﬁne

il − a2
µ − k2

ddµ nµ→µl(dµ) d2

il→µl  

(5)

lµ→µl =

µ→µl .

i F 2

(cid:90)

(cid:90)

(cid:34)(cid:90)

P(cid:89)

˜G(y  d  ω  v) =

dz dw PW (w) δ[h(z  d  w) − y] e− 1

2

(z−ω)2

v

 

(cid:35)

and

(7)

G(yµ·  ωµ·  Vµ·  θ) = ln

(8)
where µ· indicates a dependence on all the variables labeled µn with n = 1 ···   P   and δ(·) is the
Dirac delta function. Similarly as Rangan in [14]  we deﬁne P output functions as

˜G(yµn  d  ωµn  Vµn) eθd

dd PD(d)

n=1

 

gl
out(yµ·  ωµ·  Vµ·) =

∂

∂ωµl

G(yµ·  ωµ·  Vµ·  θ = 0) .

(9)

Note that each of the output functions depend on all the P different signals. We also deﬁne the
following input functions
f x
a (Σ2  R) = [x]X  

c (Σ2  R) = [x2]X − [x]2
f x
X  

(10)

4

(11)

(12)

(13)

ωt+1

µl =

(cid:88)
µl = − ∂
ht+1
∂ωµl

i

(cid:34)(cid:88)

µ
c ((Σt+1

(cid:35)

(cid:88)
(cid:34)(cid:88)

i

µ
a ((Σt+1

(cid:35)−1

(cid:12)(cid:12)(cid:12)θ=0

where [. . . ]X indicates expectation w.r.t. the measure

MX (x  Σ2  R) =

1

Z(Σ2  R)

PX (x) e

− (x−R)2
2Σ2

.

Given the above deﬁnitions  the iterative calibration-AMP algorithm reads as follows:

V t+1
µl

=

F 2
µi vt

il  

Fµiat

il − V t+1

µl

et+1
µl

 

et+1
µl

= gl

out(yµ·  ωt

µ·  V t

µ·)  

gl
out(yµ·  ωt

µ·  V t+1

µ·

)  

(Σt+1

il

)2 =

µi ht+1
F 2
µl

 

Rt+1

il = ail +

Fµi et+1
µl

(Σt+1

il

)2  

(14)

at+1
il

= f x

)2  Rt+1

(15)
as the mean and variance of the assumed distribution PX (·) 
we initialize ωt=0
and iterate these equations until convergence. At every time-step the quantity ail is the estimate for
the signal element xil  and vil is the approximate error of this estimate. The estimate and its error
for the distortion parameter dµ can be computed as

il
il
and vt=0

µl = yµl  at=0

vt+1
il = f x

)2  Rt+1

)  

)  

il

il

il

il

∂
∂θ

and

kt+1
µ =

G(yt+1

µ·

  ωt+1

µ·

  V t+1

µ·

  θ)
By setting PD(dµ) = δ(dµ − dtrue
)  and simplifying eq. (8)  readers familiar with the work of
Rangan [14] will recognize the GAMP algorithm in eqs. (12-15). Note that for a general transfer
function h the generating function G (8) has to be evaluated numerically. The overall complex-
ity of the Cal-AMP algorithm scales as O(M N P ) and hence shares the scalability advantages of
AMP [12].

  θ)

µ

.

  ωt+1

µ·

  V t+1

µ·

lt+1
µ =

(16)

∂2
∂θ2 G(yt+1
µ·

(cid:12)(cid:12)(cid:12)θ=0

2.1 Cal-AMP for the product transfer function

In the numerical section of this paper we will focus on a speciﬁc case of the transfer function
h(zµl  dµ  wµl)  deﬁned in eq. (2). We consider the measurement noise wµl to be Gaussian of zero
mean and variance ∆. This transfer function was considered in the work of [9] and we will hence
be able to compare the performance of Cal-AMP directly to the convex optimization investigated
in [9]. For the product transfer function eq. (2) most integrals requiring a numerical computation in
the general case are expressed analytically and we can replace equations (13) by:

µl

µyµl − ωt
kt
(cid:35)−1
V t
µl + ∆

et+1
µl =

(cid:34)(cid:88)

 

 

)  

(C t+1

µ )2 =

y2
µn
V t+1
µn + ∆
n
kt+1
µ = f d
a ((C t+1
µ )2  T t+1
where we have introduced the functions f d
tation is made w.r.t. to the measure

µ

ht+1
µl =

−

1
V t+1
µl + ∆

µ )2 (cid:88)

T t+1
µ = (C t+1

µy2
lt
µl
(V t+1

µl + ∆)2

 

yµnωt+1
µn
V t+1
µn + ∆
µ )2  T t+1

) .

n

 

(17)

(18)

c ((C t+1

lt+1
µ = f d
c similarly to those in eq. (10)  except the expec-

(19)

µ

a and f d

MD(d  C 2  T ) =

1

Z(C 2  T )

PD(d)|d|P e

− (d−T )2
2C2

.

(20)

3 Experimental results

Our simulations were performed using a MATLAB implementation of the Cal-AMP algorithm pre-
sented in the previous section  that is available online [22]. We focused on the noiseless case ∆ = 0
for which exact reconstruction is conceivable. We tested the algorithm on randomly generated
Gauss-Bernoulli signals with density of non-zero elements ρ  normally distributed around zero with

5

√

unit variance. For the present experiments the algorithm is using this information via a matching
distribution PX (xil). The situation when PX mismatches the true signal distribution was discussed
for AMP for compressed sensing in [21].
The distortion parameters dµ were generated from a uniform distribution centered at d = 1 with
3σ. This ensures that  as σ2 → 0  the results of standard compressed
variance σ2 and width 2
sensing are recovered  while the distortions are growing with σ2 . For numerical stability purposes 
the parameter σ2 used in the update functions of Cal-AMP was taken to be slightly larger than
the variance used to create the actual distortion parameters. For the same reasons  we have also
added a small noise ∆ = 10−17 and used damping in the iterations in order to avoid oscillatory
behavior. In this noiseless case we iterate the Cal-AMP equations until the following quantity crit =
i Fµiail)2 becomes smaller than the numerical precision of implementation 

(cid:80)
µl (kµyµl −(cid:80)

around 10−16  or until that quantity does not decrease any more over 100 iterations.
Success or failure of the reconstruction is usually determined by looking at the mean squared error
(MSE) between the true signal x0
l and the reconstructed one al. In the noiseless setting the product
transfer function h leads to a scaling invariance and therefore a better measure of success is the
cross-correlation between real and recovered signal (used in [10]) or a corrected version of the
MSE  deﬁned by:

1

M P

(cid:88)

µ

d0
µ
kµ

(21)

MSEcorr =

1
N P

il − ˆsail

  where

ˆs =

1
M

(cid:88)

(cid:0)x0

il

(cid:1)2

is an estimation of the scaling factor s. Slight deviations between empirical and theoretical means
due to the ﬁnite size of M and N lead to important differences between MSE and MSEcorr  only
the latter truly going to zero for ﬁnite N and M.

Figure 2: Phase diagrams for different numbers P of calibrating signals: The measurement rate
α = M/N is plotted against the density of the signal ρ = K/N. The plotted value is the decimal
logarithm of MSEcorr (21) achieved for one random instance. Black indicates failure of the recon-
struction  while white represents perfect reconstruction (i.e. a MSE of the order of the numerical
precision). In this ﬁgure the distortion variance is σ2 = 0.01 and N = 1000. While for P = 1
reconstruction is never possible  for P > 1  there is a phase transition very close to the lower bound
deﬁned by αmin in equation (3) or to the phase transition line of the pure compressed sensing prob-
lem αCS. Note  however  that in the large N limit we expect the calibration phase transition to be
strictly larger than both the αmin and αCS. Note also that while this diagram is usually plotted only
for α ≤ 1 for compressed sensing  the part α > 1 displays pertinent information in blind calibration.

Fig. 2 shows the empirical phase diagrams in the α-ρ plane we obtained from the Cal-AMP algo-
rithm for different number of signals P . For P = 1 the reconstruction is never exact  and effectively
this case corresponds to reconstruction without any attempt to calibrate. For any P > 1  there is
a sharp phase transition taking place with a jump in MSEcorr of ten orders of magnitude. As P
increases  the phase of exact reconstruction gets bigger and tends to the one observed in Bayesian
compressed sensing [15]. Remarkably  for small values of the density ρ  the position of the Cal-
AMP phase transition is very close to the CS one already for P = 2 and Cal-AMP performs almost
as well as in the total absence of distortion.

6

P = 1αρ00.5100.511.52P = 2ρ00.5100.511.52P = 10ρ 00.5100.511.52αminαCS log10(MSEcorr)−14−12−10−8−6−4Figure 3: Left: Cal-AMP phase transition as the system size N grows. The curves are obtained by
averaging log10(MSEcorr) over 100 samples  reﬂecting the probability of correct reconstruction in
the region close to the phase transition  where it is not guaranteed. Parameters are: ρ = 0.2  P = 2 
σ2 = 0.0251. For higher values of N  the phase transition becomes sharper. Right: Mean number
of iterations necessary for reconstruction  when the true signal is successfully recovered. Far from
the phase transition  increasing N does not increase visibly the number of iterations for these system
sizes  showing that our algorithm works in linear time. The number of needed iterations increases
drastically as one approaches the phase transition.

Figure 4: Left: Position of the phase transition in α for different distortion variances σ2. The
left vertical line represents the position of the CS phase transition  the right one is the counting
bound eq. (3). With growing distortion  larger measurement rates become necessary for perfect
Intermediary values of MSEcorr are obtained in a region where
calibration and reconstruction.
perfect calibration is not possible  but distortions are small enough for the uncalibrated AMP to
make only small mistakes. The parameters here are P = 2 and ρ = 0.2. Right: Phase diagram
as the variance of the distortions σ2 and the number of signals P vary  for ρ = 0.5  α = 0.75 and
N = 1000.

Fig. 3 shows the behavior near the phase transition  giving insights about the inﬂuence of the system
size and the number of iterations needed for precise calibration and reconstruction. In Fig. 4  we
show the jump in the MSE on a single instance as the measurement rate α decreases. The right part
is the phase diagram in the σ2-P plane.
In [9  10]  a calibration algorithm using (cid:96)1-minimization has been proposed. While in that case  no
assumption on the distribution of the signals and of the the gains is needed  for most practical cases
it is expected to be less performant than the Cal-AMP if these distributions are known or reasonably
approximated. We implemented the algorithm of [9] with MATLAB using the CVX package [23].
Due to longer running times  experiments were made using a smaller system size N = 100. We
also remind at this point that whereas the Cal-AMP algorithm works for a generic transfer function
(1)  the (cid:96)1-minimization based calibration is restricted to the transfer functions considered by [9  10].
Fig. 5 shows a comparison of the performances of the two algorithms in the α-ρ phase diagrams. The
Cal-AMP clearly outperforms the (cid:96)1-minimization in the sense that the region in which calibration
is possible is much larger.

7

0.450.50.55−15−10−50α〈 log10(MSEcorr) 〉0.450.50.550.60100200300400500600αIterations 50 200 400 1000 500010000N0.250.30.350.40.450.50.5510−1510−1010−5100αMSEcorr −0.4−1−2−3−5−7−12αminαCSlog10(σ2)log10(σ2)P −4−3−2−1246810121416log10(MSEcorr)−15−10−50Figure 5: Comparison of the empirical phase diagrams obtained with the Cal-AMP algorithm pro-
posed here (top) and the (cid:96)1-minimization calibration algorithm of [9] (bottom) averaged over several
random samples; black indicates failure  white indicates success. The area where reconstruction is
possible is consistently much larger for Cal-AMP than for (cid:96)1-minimization-based calibration. The
plotted lines are the phase transitions for CS without unknown distortions with the AMP algorithm
(αCS  in red  from [21])  and with (cid:96)1-minimization (the Donoho-Tanner transition αDT  in blue 
from [11]). The line αmin is the lower counting bound from eq. (3). The advantage of Cal-AMP
over (cid:96)1-minimization calibration is clear. Note that in both cases  the region close to the transition is
blurred due to ﬁnite system size  hence a region of grey pixels (again  the effect is more pronounced
for the (cid:96)1 algorithm).

4 Conclusion

We have presented the Cal-AMP algorithm for blind calibration in compressed sensing  a problem
where the outputs of the measurements are distorted by some unknown gains on the sensors  eq. (1).
The Cal-AMP algorithm allows to jointly infer sparse signals and the distortion parameters of each
sensor even with a very small number of signals and is computationally as efﬁcient as the GAMP
algorithm for compressed sensing [14]. Another advantage w.r.t. previous works is that the Cal-
AMP algorithm works for generic transfer function between the measurements and the readings from
the sensor  not only those that permit a convex formulation of the inference problem as in [9  10]. In
the numerical analysis  we focussed on the case of the product transfer function (2) studied in [9].
Our results show that  for the chosen parameters  calibration is possible with a very small number
of different sparse signals P (i.e. P = 2 or P = 3)  even very close to the absolute minimum
of measurements required by a counting bound (3). Comparison with the (cid:96)1-minimizing calibration
algorithm clearly shows lower requirements on the measurement rate α and on the number of signals
P for Cal-AMP. The Cal-AMP algorithm for blind calibration is scalable and simple to implement.
Its efﬁciency shows that supervised training is unnecessary. We expect Cal-AMP to become useful
in practical compressed sensing implementations.
Asymptotic analysis of AMP can be done using the state evolution approach [12].
In the case
of Cal-AMP  however  analysis of the resulting state evolution equations is more difﬁcult and has
hence been postponed to future work. Future work also includes the study of the robustness to the
mismatch between assumed and true distribution of signal elements and distortion parameters  as
well as the expectation-maximization based learning of the various parameters. Finally  the use
of spatially coupled measurement matrices [15  16] could further improve the performance of the
algorithm and make the phase transition asymptotically coincide with the information-theoretical
counting bound (3).

8

Cal−AMPL1αP = 200.5100.511.52P = 300.5100.511.52P = 500.5100.511.52P = 1000.5100.511.52ρα00.5100.511.52ρ00.5100.511.52ρ00.5100.511.52ρ 00.5100.511.52αminαCSαDT〈 log10(MSEcorr) 〉−14−12−10−8−6−4−2References
[1] E. J. Cand`es and T. Tao. Decoding by linear programming. IEEE Trans. Inform. Theory  51:4203  2005.
[2] D. L. Donoho. Compressed sensing. IEEE Trans. Inform. Theory  52:1289  2006.
[3] B. C. Ng and C. M. S. See. Sensor-array calibration using a maximum-likelihood approach.

IEEE

Transactions on Antennas and Propagation  44(6):827–835  1996.

[4] Z. Yang  C. Zhang  and L. Xie. Robustly stable signal recovery in compressed sensing with structured

matrix perturbation. IEEE Transactions on Signal Processing  60(9):4658–4671  2012.

[5] R. Mignot  L. Daudet  and F. Ollivier. Compressed sensing for acoustic response reconstruction: Interpo-
lation of the early part. In IEEE Workshop on Applications of Signal Processing to Audio and Acoustics
(WASPAA)  pages 225–228  2011.

[6] T. Ragheb  J. N Laska  H. Nejati  S. Kirolos  R. G Baraniuk  and Y. Massoud. A prototype hardware for
random demodulation based compressive analog-to-digital conversion. In 51st Midwest Symposium on
Circuits and Systems (MWSCAS)  pages 37–40. IEEE  2008.

[7] J. A Tropp  J. N. Laska  M. F. Duarte  J. K Romberg  and R. G. Baraniuk. Beyond nyquist: Efﬁcient

sampling of sparse bandlimited signals. IEEE Trans. Inform. Theory  56(1):520–544  2010.

[8] P. J. Pankiewicz  T. Arildsen  and T. Larsen. Model-based calibration of ﬁlter imperfections in the random

demodulator for compressive sensing. arXiv:1303.6135  2013.

[9] R. Gribonval  G. Chardon  and L. Daudet. Blind calibration for compressed sensing by convex optimiza-
In IEEE International Conference on Acoustics  Speech and Signal Processing (ICASSP)  pages

tion.
2713 – 2716  2012.

[10] C. Bilen  G. Puy  R. Gribonval  and L. Daudet. Blind sensor calibration in sparse recovery using convex

optimization. In 10th Int. Conf. on Sampling Theory and Applications  2013.

[11] D. L. Donoho and J. Tanner. Sparse nonnegative solution of underdetermined linear equations by linear

programming. Proc. Natl. Acad. Sci.  102(27):9446–9451  2005.

[12] D. L. Donoho  A. Maleki  and A. Montanari. Message-passing algorithms for compressed sensing. Proc.

Natl. Acad. Sci.  106(45):18914–18919  2009.

[13] D.L. Donoho  A. Maleki  and A. Montanari. Message passing algorithms for compressed sensing: I.

motivation and construction. In IEEE Information Theory Workshop (ITW)  pages 1 –5  2010.

[14] S. Rangan. Generalized approximate message passing for estimation with random linear mixing. In Proc.

of the IEEE Int. Symp. on Inform. Theory (ISIT)  pages 2168 –2172  2011.

[15] F. Krzakala  M. M´ezard  F. Sausset  Y.F. Sun  and L. Zdeborov´a. Statistical physics-based reconstruction

in compressed sensing. Phys. Rev. X  2:021005  2012.

[16] D. L. Donoho  A. Javanmard  and A. Montanari. Information-theoretically optimal compressed sensing
via spatial coupling and approximate message passing. In Proc. of the IEEE Int. Symposium on Informa-
tion Theory (ISIT)  pages 1231–1235  2012.

[17] J. Boutros and G. Caire. Iterative multiuser joint decoding: Uniﬁed framework and asymptotic analysis.

IEEE Trans. Inform. Theory  48(7):1772–1793  2002.

[18] Y. Kabashima. A cdma multiuser detection algorithm on the basis of belief propagation. J. Phys. A: Math.

and Gen.  36(43):11111  2003.

[19] U. S. Kamilov  A. Bourquard  E. Bostan  and M. Unser. Autocalibrated signal reconstruction from linear

measurements using adaptive gamp. online preprint  2013.

[20] F. Krzakala  M. M´ezard  and L. Zdeborov´a. Phase diagram and approximate message passing for blind

calibration and dictionary learning. ISIT 2013  arXiv:1301.5898  2013.

[21] F. Krzakala  M. M´ezard  F. Sausset  Y.F. Sun  and L. Zdeborov´a. Probabilistic reconstruction in com-
pressed sensing: Algorithms  phase diagrams  and threshold achieving matrices. J. Stat. Mech.  P08009 
2012.

[22] http://aspics.krzakala.org/.
[23] M. Grant and S. Boyd. CVX: Matlab software for disciplined convex programming  version 2.0 beta.

http://cvxr.com/cvx  2012.

9

,Christophe Schulke
Francesco Caltagirone
Florent Krzakala
Lenka Zdeborová