2015,A Convergent Gradient Descent Algorithm for Rank Minimization and Semidefinite Programming from Random Linear Measurements,We propose a simple  scalable  and fast gradient descent algorithm to optimize a nonconvex objective for the rank minimization problem and a closely related family of semidefinite programs.  With $O(r^3 \kappa^2 n \log n)$ random measurements of a positive semidefinite $n\times n$ matrix of rank $r$ and condition number $\kappa$  our method is guaranteed to converge linearly to the global optimum.,A Convergent Gradient Descent Algorithm for

Rank Minimization and Semideﬁnite Programming

from Random Linear Measurements

Qinqing Zheng

University of Chicago

qinqing@cs.uchicago.edu

John Lafferty

University of Chicago

lafferty@galton.uchicago.edu

Abstract

We propose a simple  scalable  and fast gradient descent algorithm to optimize
a nonconvex objective for the rank minimization problem and a closely related
family of semideﬁnite programs. With O(r3κ2n log n) random measurements of
a positive semideﬁnite n×n matrix of rank r and condition number κ  our method
is guaranteed to converge linearly to the global optimum.

1

Introduction

Semideﬁnite programming has become a key optimization tool in many areas of applied mathemat-
ics  signal processing and machine learning. SDPs often arise naturally from the problem structure 
or are derived as surrogate optimizations that are relaxations of difﬁcult combinatorial problems
[7  1  8]. In spite of the importance of SDPs in principle—promising efﬁcient algorithms with poly-
nomial runtime guarantees—it is widely recognized that current optimization algorithms based on
interior point methods can handle only relatively small problems. Thus  a considerable gap exists
between the theory and applicability of SDP formulations. Scalable algorithms for semideﬁnite pro-
gramming  and closely related families of nonconvex programs more generally  are greatly needed.
A parallel development is the surprising effectiveness of simple classical procedures such as gradient
descent for large scale problems  as explored in the recent machine learning literature. In many areas
of machine learning and signal processing such as classiﬁcation  deep learning  and phase retrieval 
gradient descent methods  in particular ﬁrst order stochastic optimization  have led to remarkably
efﬁcient algorithms that can attack very large scale problems [3  2  10  6]. In this paper we build on
this work to develop ﬁrst-order algorithms for solving the rank minimization problem under random
measurements and a closely related family of semideﬁnite programs. Our algorithms are efﬁcient
and scalable  and we prove that they attain linear convergence to the global optimum under natural
assumptions.
The afﬁne rank minimization problem is to ﬁnd a matrix X (cid:63) ∈ Rn×p of minimum rank satisfying
constraints A(X (cid:63)) = b  where A : Rn×p −→ Rm is an afﬁne transformation. The underdetermined
case where m (cid:28) np is of particular interest  and can be formulated as the optimization

min

rank(X)

X∈Rn×p
subject to A(X) = b.

(1)

This problem is a direct generalization of compressed sensing  and subsumes many machine learn-
ing problems such as image compression  low rank matrix completion and low-dimensional metric
embedding [18  12]. While the problem is natural and has many applications  the optimization is
nonconvex and challenging to solve. Without conditions on the transformation A or the minimum
rank solution X (cid:63)  it is generally NP hard [15].

1

Existing methods  such as nuclear norm relaxation [18]  singular value projection (SVP) [11]  and
alternating least squares (AltMinSense) [12]  assume that a certain restricted isometry property
(RIP) holds for A. In the random measurement setting  this essentially means that at least O(r(n +
p) log(n + p)) measurements are available  where r = rank(X (cid:63)) [18]. In this work  we assume that
(i) X (cid:63) is positive semideﬁnite and (ii) A : Rn×n −→ Rm is deﬁned as A(X)i = tr(AiX)  where
each Ai is a random n × n symmetric matrix from the Gaussian Orthogonal Ensemble (GOE)  with
(Ai)jj ∼ N (0  2) and (Ai)jk ∼ N (0  1) for j (cid:54)= k. Our goal is thus to solve the optimization

min
X(cid:23)0
subject to

rank(X)

tr(AiX) = bi 

i = 1  . . .   m.

(2)

In addition to the wide applicability of afﬁne rank minimization  the problem is also closely con-
nected to a class of semideﬁnite programs. In Section 2  we show that the minimizer of a particular
class of SDP can be obtained by a linear transformation of X (cid:63). Thus  efﬁcient algorithms for prob-
lem (2) can be applied in this setting as well.
Noting that a rank-r solution X (cid:63) to (2) can be decomposed as X (cid:63) = Z (cid:63)Z (cid:63)(cid:62) where Z (cid:63) ∈ Rn×r 
our approach is based on minimizing the squared residual

(cid:13)(cid:13)A(ZZ(cid:62)) − b(cid:13)(cid:13)2

f (Z) =

1
4m

m(cid:88)

i=1

=

1
4m

(cid:0)tr(Z(cid:62)AiZ) − bi

(cid:1)2

.

While this is a nonconvex function  we take motivation from recent work for phase retrieval by
Cand`es et al. [6]  and develop a gradient descent algorithm for optimizing f (Z)  using a carefully
constructed initialization and step size. Our main contributions concerning this algorithm are as
follows.

• We prove that with O(r3n log n) constraints our gradient descent scheme can exactly re-
cover X (cid:63) with high probability. Empirical experiments show that this bound may poten-
tially be improved to O(rn log n).
• We show that our method converges linearly  and has lower computational cost compared
• We carry out a detailed comparison of rank minimization algorithms  and demonstrate that
when the measurement matrices Ai are sparse  our gradient method signiﬁcantly outper-
forms alternative approaches.

with previous methods.

In Section 3 we brieﬂy review related work. In Section 4 we discuss the gradient scheme in detail.
Our main analytical results are presented in Section 5  with detailed proofs contained in the supple-
mentary material. Our experimental results are presented in Section 6  and we conclude with a brief
discussion of future work in Section 7.

2 Semideﬁnite Programming and Rank Minimization

Before reviewing related work and presenting our algorithm  we pause to explain the connection
between semideﬁnite programming and rank minimization. This connection enables our scalable
gradient descent algorithm to be applied and analyzed for certain classes of SDPs.
Consider a standard form semideﬁnite program

min(cid:101)X(cid:23)0

tr((cid:101)C(cid:101)X)
tr((cid:101)Ai(cid:101)X) = bi 

where (cid:101)C  (cid:101)A1  . . .   (cid:101)Am ∈ Sn. If (cid:101)C is positive deﬁnite  then we can write (cid:101)C = LL(cid:62) where L ∈ Rn×n

i = 1  . . .   m

subject to

is invertible. It follows that the minimum of problem (3) is the same as

(3)

min
X(cid:23)0
subject to

tr(X)

tr(AiX) = bi 

i = 1  . . .   m

(4)

2

where Ai = L−1(cid:101)AiL−1(cid:62)

(4) via the transformation

. In particular  minimizers (cid:101)X∗ of (3) are obtained from minimizers X∗ of

(cid:101)X∗ = L−1(cid:62)

X∗L−1.

Since X is positive semideﬁnite  tr(X) is equal to (cid:107)X(cid:107)∗. Hence  problem (4) is the nuclear norm
relaxation of problem (2). Next  we characterize the speciﬁc cases where X∗ = X (cid:63)  so that the SDP
and rank minimization solutions coincide. The following result is from Recht et al. [18].
Theorem 1. Let A : Rn×n −→ Rm be a linear map. For every integer k with 1 ≤ k ≤ n  deﬁne
the k-restricted isometry constant to be the smallest value δk such that
(1 − δk)(cid:107)X(cid:107)F ≤ (cid:107)A(X)(cid:107) ≤ (1 + δk)(cid:107)X(cid:107)F

holds for any matrix X of rank at most k. Suppose that there exists a rank r matrix X (cid:63) such that
A(X (cid:63)) = b.
If δ2r < 1  then X (cid:63) is the only matrix of rank at most r satisfying A(X) = b.
Furthermore  if δ5r < 1/10  then X (cid:63) can be attained by minimizing (cid:107)X(cid:107)∗ over the afﬁne subset.
In other words  since δ2r ≤ δ5r  if δ5r < 1/10 holds for the transformation A and one ﬁnds a matrix
X of rank r satisfying the afﬁne constraint  then X must be positive semideﬁnite. Hence  one can
ignore the semideﬁnite constraint X (cid:23) 0 when solving the rank minimization (2). The resulting
problem then can be exactly solved by nuclear norm relaxation. Since the minimum rank solution
is positive semideﬁnite  it then coincides with the solution of the SDP (4)  which is a constrained
nuclear norm optimization.
The observation that one can ignore the semideﬁnite constraint justiﬁes our experimental comparison
with methods such as nuclear norm relaxation  SVP  and AltMinSense  described in the following
section.

3 Related Work

Burer and Monteiro [4] proposed a general approach for solving semideﬁnite programs using fac-
tored  nonconvex optimization  giving mostly experimental support for the convergence of the al-
gorithms. The ﬁrst nontrivial guarantee for solving afﬁne rank minimization problem is given by
Recht et al. [18]  based on replacing the rank function by the convex surrogate nuclear norm  as
already mentioned in the previous section. While this is a convex problem  solving it in practice is
nontrivial  and a variety of methods have been developed for efﬁcient nuclear norm minimization.
The most popular algorithms are proximal methods that perform singular value thresholding [5] at
every iteration. While effective for small problem instances  the computational expense of the SVD
prevents the method from being useful for large scale problems.
Recently  Jain et al. [11] proposed a projected gradient descent algorithm SVP (Singular Value
Projection) that solves

min

X∈Rn×p
subject to

(cid:107)A(X) − b(cid:107)2
rank(X) ≤ r 

where (cid:107)·(cid:107) is the (cid:96)2 vector norm and r is the input rank. In the (t+1)th iteration  SVP updates X t+1 as
the best rank r approximation to the gradient update X t − µA(cid:62)(A(X t) − b)  which is constructed
from the SVD. If rank(X (cid:63)) = r  then SVP can recover X (cid:63) under a similar RIP condition as the
nuclear norm heuristic  and enjoys a linear numerical rate of convergence. Yet SVP suffers from the
expensive per-iteration SVD for large problem instances.
Subsequent work of Jain et al. [12] proposes an alternating least squares algorithm AltMinSense
that avoids the per-iteration SVD. AltMinSense factorizes X into two factors U ∈ Rn×r  V ∈

Rp×r such that X = U V (cid:62) and minimizes the squared residual(cid:13)(cid:13)A(U V (cid:62)) − b(cid:13)(cid:13)2 by updating U and

V alternately. Each update is a least squares problem. The authors show that the iterates obtained
by AltMinSense converge to X (cid:63) linearly under a RIP condition. However  the least squares
problems are often ill-conditioned  it is difﬁcult to observe AltMinSense converging to X (cid:63) in
practice.
As described above  considerable progress has been made on algorithms for rank minimization and
certain semideﬁnite programming problems. Yet truly efﬁcient  scalable and provably convergent

3

algorithms have not yet been obtained. In the speciﬁc setting that X (cid:63) is positive semideﬁnite  our
algorithm exploits this structure to achieve these goals. We note that recent and independent work of
Tu et al. [21] proposes a hybrid algorithm called Procrustes Flow (PF)  which uses a few iterations
of SVP as initialization  and then applies gradient descent.

4 A Gradient Descent Algorithm for Rank Minimization

Our method is described in Algorithm 1. It is parallel to the Wirtinger Flow (WF) algorithm for
phase retrieval [6]  to recover a complex vector x ∈ Cn given the squared magnitudes of its linear
measurements bi = |(cid:104)ai  x(cid:105)|2  i ∈ [m]  where a1  . . .   am ∈ Cn. Cand`es et al. [6] propose a
ﬁrst-order method to minimize the sum of squared residuals

fWF(z) =

.

(5)

(cid:0)|(cid:104)ai  z(cid:105)|2 − bi

(cid:1)2

n(cid:88)

i=1

The authors establish the convergence of WF to the global optimum—given sufﬁcient measurements 
the iterates of WF converge linearly to x up to a global phase  with high probability.
If z and the ais are real-valued  the function fWF(z) can be expressed as

(cid:0)z(cid:62)aia(cid:62)

n(cid:88)

i=1

i x(cid:1)2

 

i z − x(cid:62)aia(cid:62)

fWF(z) =

(cid:80)m

i=1 biAi. Then 1

2

E(M ) = X (cid:63)  where the expectation is with respect to

which is a special case of f (Z) where Ai = aia(cid:62)
i and each of Z and X (cid:63) are rank one. See Figure
1a for an illustration; Figure 1b shows the convergence rate of our method. Our methods and results
are thus generalizations of Wirtinger ﬂow for phase retrieval.
Before turning to the presentation of our technical results in the following section  we present some
intuition and remarks about how and why this algorithm works. For simplicity  let us assume that
the rank is speciﬁed correctly.
Initialization is of course crucial in nonconvex optimization  as many local minima may be present.
To obtain a sufﬁciently accurate initialization  we use a spectral method  similar to those used in
[17  6]. The starting point is the observation that a linear combination of the constraint values and
matrices yields an unbiased estimate of the solution.
Lemma 1. Let M = 1
m
the randomness in the measurement matrices Ai.
Based on this fact  let X (cid:63) = U (cid:63)ΣU (cid:63)(cid:62) be the eigenvalue decomposition of X (cid:63)  where U (cid:63) =
r] and Σ = diag(σ1  . . .   σr) such that σ1 ≥ . . . ≥ σr are the nonzero eigenvalues of
[u(cid:63)
1  . . .   u(cid:63)
s(cid:107) is the top sth eigenvector of E(M ) associated with
X (cid:63). Let Z (cid:63) = U (cid:63)Σ 1
eigenvalue 2(cid:107)z(cid:63)
2 vs where (vs  λs) is the top
sth eigenpair of M. For sufﬁciently large m  it is reasonable to expect that Z 0 is close to Z (cid:63); this is
conﬁrmed by concentration of measure arguments.
Certain key properties of f (Z) will be seen to yield a linear rate of convergence. In the analysis
of convex functions  Nesterov [16] shows that for unconstrained optimization  the gradient descent
scheme with sufﬁciently small step size will converge linearly to the optimum if the objective func-
tion is strongly convex and has a Lipschitz continuous gradient. However  these two properties are
global and do not hold for our objective function f (Z). Nevertheless  we expect that similar condi-
tions hold for the local area near Z (cid:63). If so  then if we start close enough to Z (cid:63)  we can achieve the
global optimum.
In our subsequent analysis  we establish the convergence of Algorithm 1 with a constant step size of
the form µ/(cid:107)Z (cid:63)(cid:107)2

F   where µ is a small constant. Since (cid:107)Z (cid:63)(cid:107)F is unknown  we replace it by(cid:13)(cid:13)Z 0(cid:13)(cid:13)F .

s(cid:107)2. Therefore  we initialize according to z0

2 . Clearly  u(cid:63)

s = z(cid:63)

(cid:113)|λs|

s /(cid:107)z(cid:63)

s =

5 Convergence Analysis

In this section we present our main result analyzing the gradient descent algorithm  and give a
sketch of the proof. To begin  note that the symmetric decomposition of X (cid:63) is not unique  since

4

(a)

(b)

Figure 1: (a) An instance of f (Z) where X (cid:63) ∈ R2×2 is rank-1 and Z ∈ R2. The underlying truth
is Z (cid:63) = [1  1](cid:62). Both Z (cid:63) and −Z (cid:63) are minimizers. (b) Linear convergence of the gradient scheme 
for n = 200  m = 1000 and r = 2. The distance metric is given in Deﬁnition 1.

(cid:80)m
i=1 biAi s.t. |λ1| ≥ ··· ≥ |λr|

Algorithm 1: Gradient descent for rank minimization
input: {Ai  bi}m
initialization

i=1  r  µ

Set (v1  λ1)  . . .   (vr  λr) to the top r eigenpairs of 1
m
Z 0 = [z0
k ← 0

· vs  s ∈ [r]

r ] where z0

1  . . .   z0

s =

2

(cid:113)|λs|

(cid:17)

AiZ k

(cid:16)
m(cid:80)
tr(Z k(cid:62)
µ(cid:80)r
s=1 |λs|/2

i=1

AiZ k) − bi
∇f (Z k)

repeat

m

∇f (Z k) = 1
Z k+1 = Z k −
k ← k + 1

until convergence;

output: (cid:98)X = Z kZ k(cid:62)

Note that (cid:107)(cid:101)Z(cid:107)2

X (cid:63) = (Z (cid:63)U )(Z (cid:63)U )(cid:62) for any r × r orthonormal matrix U. Thus  the solution set is

S =

(cid:110)(cid:101)Z ∈ Rn×r | (cid:101)Z = Z (cid:63)U for some U with U U(cid:62) = U(cid:62)U = I
F = (cid:107)X (cid:63)(cid:107)∗ for any (cid:101)Z ∈ S. We deﬁne the distance to the optimal solution in terms of
(cid:13)(cid:13)Z − (cid:101)Z(cid:13)(cid:13)F .

d(Z  Z (cid:63)) =

(cid:107)Z − Z (cid:63)U(cid:107)F = min(cid:101)Z∈S

U U(cid:62)=U(cid:62)U =I

(cid:111)

min

.

this set.
Deﬁnition 1. Deﬁne the distance between Z and Z (cid:63) as

Our main result for exact recovery is stated below  assuming that the rank is correctly speciﬁed.
Since the true rank is typically unknown in practice  one can start from a very low rank and gradually
increase it.
Theorem 2. Let the condition number κ = σ1/σr denote the ratio of the largest to the smallest
nonzero eigenvalues of X (cid:63). There exists a universal constant c0 such that if m ≥ c0κ2r3n log n 
with high probability the initialization Z 0 satisﬁes

(6)
Moreover  there exists a universal constant c1 such that when using constant step size µ/(cid:107)Z (cid:63)(cid:107)2
with µ ≤ c1
κn

and initial value Z 0 obeying (6)  the kth step of Algorithm 1 satisﬁes

16 σr.

F

d(Z 0  Z (cid:63)) ≤(cid:113) 3
(cid:16)

d(Z k  Z (cid:63)) ≤(cid:113) 3

(cid:17)k/2

16 σr

1 − µ
12κr

with high probability.

5

2Z20-220Z1-210310210110010-1f(Z)iteration0200400600800dist(Z Z⋆)kZ⋆kF10-1510-1010-5100We now outline the proof  giving full details in the supplementary material. The proof has four main
steps. The ﬁrst step is to give a regularity condition under which the algorithm converges linearly if
we start close enough to Z (cid:63). This provides a local regularity property that is similar to the Nesterov
[16] criteria that the objective function is strongly convex and has a Lipschitz continuous gradient.

(cid:13)(cid:13)Z − (cid:101)Z(cid:13)(cid:13)F denote the matrix closest to Z in the solution set.

Deﬁnition 2. Let Z = arg min(cid:101)Z∈S
We say that f satisﬁes the regularity condition RC(ε  α  β) if there exist constants α  β such that
for any Z satisfying d(Z  Z (cid:63)) ≤ ε  we have

(cid:104)∇f (Z)  Z − Z(cid:105) ≥ 1
α

σr

F +

1

β (cid:107)Z (cid:63)(cid:107)2

F

(cid:107)∇f (Z)(cid:107)2
F .

Using this regularity condition  we show that the iterative step of the algorithm moves closer to the
optimum  if the current iterate is sufﬁciently close.
Theorem 3. Consider the update Z k+1 = Z k −
d(Z k  Z (cid:63)) ≤ ε  and 0 < µ < min(α/2  2/β)  then

If f satisﬁes RC(ε  α  β) 

∇f (Z k).

(cid:107)Z (cid:63)(cid:107)2

µ

F

(cid:13)(cid:13)Z − Z(cid:13)(cid:13)2

(cid:114)

d(Z k+1  Z (cid:63)) ≤

1 − 2µ
ακr

d(Z k  Z (cid:63)).

In the next step of the proof  we condition on two events that will be shown to hold with high
probability using concentration results. Let δ denote a small value to be speciﬁed later.

A1

A2

For any u ∈ Rn such that (cid:107)u(cid:107) ≤ √
(cid:34)
For any (cid:101)Z ∈ S 

(cid:13)(cid:13)(cid:13)(cid:13)(cid:13) ∂2f ((cid:101)Z)
∂(cid:101)zs∂(cid:101)z(cid:62)

− E

k

σ1 

(cid:13)(cid:13)(cid:13)(cid:13) 1
m(cid:80)
(cid:35)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13) ≤ δ
∂2f ((cid:101)Z)
∂(cid:101)zs∂(cid:101)z(cid:62)

i=1

m

k

r  

(u(cid:62)Aiu)Ai − 2uu(cid:62)

for all s  k ∈ [r].

(cid:13)(cid:13)(cid:13)(cid:13) ≤ δ

r .

(cid:113) 3
16 σr  then f satisﬁes the regularity condition
16 σr  24  513κn) with probability at least 1− mCe−ρn  where C  ρ are universal constants.

Here the expectations are with respect to the random measurement matrices. Under these assump-
tions  we can show that the objective satisﬁes the regularity condition with high probability.
Theorem 4. Suppose that A1 and A2 hold. If δ ≤ 1
RC(
Next we show that under A1  a good initialization can be found.
Theorem 5. Suppose that A1 holds. Let {vs  λs}r
such that |λ1| ≥ ··· ≥ |λr|. Let Z 0 = [z1  . . .   zr] where zs =

m(cid:80)
i=1
2 · vs  s ∈ [r]. If δ ≤ σr
√
4

s=1 be the top r eigenpairs of M = 1

(cid:113)|λs|

r   then

biAi

m

d(Z 0  Z (cid:63)) ≤(cid:112)3σr/16.

Finally  we show that conditioning on A1 and A2 is valid since these events have high probability
as long as m is sufﬁciently large.
Theorem 6. If the number of samples m ≥
satisfying (cid:107)u(cid:107) ≤ √

n log n  then for any u ∈ Rn

42
min(δ2/r2σ2

1  δ/rσ1)

σ1 

holds with probability at least 1 − mCe−ρn − 2
Theorem 7. For any x ∈ Rn  if m ≥

n2   where C and ρ are universal constants.
128
min(δ2/4r2σ2

1  δ/2rσ1)

(cid:13)(cid:13)(cid:13)(cid:13)(cid:13) ≤ δ
n log n  then for any (cid:101)Z ∈ S

r

for all s  k ∈ [r] 

 

m

(cid:13)(cid:13)(cid:13)(cid:13)(cid:13) 1
(cid:13)(cid:13)(cid:13)(cid:13)(cid:13) ∂2f ((cid:101)Z)
∂(cid:101)zs∂(cid:101)z(cid:62)

k

− E

m(cid:88)

i=1

(cid:34)

(u(cid:62)Aiu)Ai − 2uu(cid:62)

∂2f ((cid:101)Z)
∂(cid:101)zs∂(cid:101)z(cid:62)

k

(cid:35)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13) ≤ δ

r

6

with probability at least 1 − 6me−n − 4
n2 .

(cid:16) 1

(cid:17)

4

r

√
1

16  

σr  we have δ
rσ1

Note that since we need δ ≤ min
≤ 1  and the number of measure-
ments required by our algorithm scales as O(r3κ2n log n)  while only O(r2κ2n log n) samples are
required by the regularity condition. We conjecture this bound could be further improved to be
O(rn log n); this is supported by the experimental results presented below.
Recently  Tu et al. [21] establish a tighter O(r2κ2n) bound overall. Speciﬁcally  when only one SVP
step is used in preprocessing  the initialization of PF is also the spectral decomposition of 1
2 M. The
√
authors show that O(r2κ2n) measurements are sufﬁcient for Z 0 to satisfy d(Z 0  Z (cid:63)) ≤ O(
σr)
with high probability  and demonstrate an O(rn) sample complexity for the regularity condition.
6 Experiments

In this section we report the results of experiments on synthetic datasets. We compare our gradient
descent algorithm with nuclear norm relaxation  SVP and AltMinSense for which we drop the
positive semideﬁniteness constraint  as justiﬁed by the observation in Section 2. We use ADMM
for the nuclear norm minimization  based on the algorithm for the mixture approach in Tomioka
et al. [19]; see Appendix G. For simplicity  we assume that AltMinSense  SVP and the gradient
scheme know the true rank. Krylov subspace techniques such as the Lanczos method could be used
compute the partial eigendecomposition; we use the randomized algorithm of Halko et al. [9] to
compute the low rank SVD. All methods are implemented in MATLAB and the experiments were
run on a MacBook Pro with a 2.5GHz Intel Core i7 processor and 16 GB memory.

6.1 Computational Complexity

It is instructive to compare the per-iteration cost of the different approaches; see Table 1. Suppose
that the density (fraction of nonzero entries) of each Ai is ρ. For AltMinSense  the cost of solving
the least squares problem is O(mn2r2 + n3r3 + mn2rρ). The other three methods have O(mn2ρ)
cost to compute the afﬁne transformation. For the nuclear norm approach  the O(n3) cost is from
the SVD and the O(m2) cost is due to the update of the dual variables. The gradient scheme requires
2n2r operations to compute Z kZ k(cid:62)
and to multiply Z k by n× n matrix to obtain the gradient. SVP
needs O(n2r) operations to compute the top r singular vectors. However  in practice this partial
SVD is more expensive than the 2n2r cost required for the matrix multiplies in the gradient scheme.

Method

Complexity

nuclear norm minimization via ADMM O(mn2ρ + m2 + n3)

gradient descent

SVP

AltMinSense

O(mn2ρ) + 2n2r
O(mn2ρ + n2r)
O(mn2r2 + n3r3 + mn2rρ)

Table 1: Per-iteration computational complexities of different methods.

Clearly  AltMinSense is the least efﬁcient. For the other approaches  in the dense case (ρ large) 
the afﬁne transformation dominates the computation. Our method removes the overhead caused by
the SVD. In the sparse case (ρ small)  the other parts dominate and our method enjoys a low cost.

6.2 Runtime Comparison

We report the relative error measured in the Frobenius norm deﬁned as (cid:107)(cid:98)X − X (cid:63)(cid:107)F /(cid:107)X (cid:63)(cid:107)F . For

We conduct experiments for both dense and sparse measurement matrices. AltMinSense is in-
deed slow  so we do not include it here.
In the ﬁrst scenario  we randomly generate a 400×400 rank-2 matrix X (cid:63) = xx(cid:62)+yy(cid:62) where x  y ∼
N (0  I). We also generate m = 6n matrices A1  . . .   Am from the GOE  and then take b = A(X (cid:63)).
the nuclear norm approach  we set the regularization parameter to λ = 10−5. We test three values
η = 10  100  200 for the penalty parameter and select η = 100 as it leads to the fastest convergence.
Similarly  for SVP we evaluate the three values 5× 10−5  10−4  2× 10−4 for the step size  and select
10−4 as the largest for which SVP converges. For our approach  we test the three values 0.6  0.8  1.0
for µ and select 0.8 in the same way.

7

(a)

(b)

(c)

Figure 2: (a) Runtime comparison where X (cid:63) ∈ R400×400 is rank-2 and Ais are dense. (b) Runtime
comparison where X (cid:63) ∈ R600×600 is rank-2 and Ais are sparse. (c) Sample complexity comparison.

In the second scenario  we use a more general and practical setting. We randomly generate a rank-2
matrix X (cid:63) ∈ R600×600 as before. We generate m = 7n sparse Ais whose entries are i.i.d. Bernoulli:

(cid:26)1 with probability ρ 

0 with probability 1 − ρ 

(Ai)jk =

where we use ρ = 0.001. For all the methods we use the same strategies as before to select parame-
ters. For the nuclear norm approach  we try three values η = 10  100  200 and select η = 100. For
SVP  we test the three values 5 × 10−3  2 × 10−3  10−3 for the step size and select 10−3. For the
gradient algorithm  we check the three values 0.8  1  1.5 for µ and choose 1.
The results are shown in Figures 2a and 2b. In the dense case  our method is faster than the nuclear
norm approach and slightly outperforms SVP. In the sparse case  it is signiﬁcantly faster than the
other approaches.

6.3 Sample Complexity

We also evaluate the number of measurements required by each method to exactly recover X (cid:63) 
which we refer to as the sample complexity. We randomly generate the true matrix X (cid:63) ∈ Rn×n and
compute the solutions of each method given m measurements  where the Ais are randomly drawn
from the GOE. A solution with relative error below 10−5 is considered to be successful. We run 40
trials and compute the empirical probability of successful recovery.
We consider cases where n = 60 or 100 and X (cid:63) is of rank one or two. The results are shown in
Figure 2c. For SVP and our approach  the phase transitions happen around m = 1.5n when X (cid:63) is
rank-1 and m = 2.5n when X (cid:63) is rank-2. This scaling is close to the number of degrees of freedom
in each case; this conﬁrms that the sample complexity scales linearly with the rank r. The phase
transition for the nuclear norm approach occurs later. The results suggest that the sample complexity
of our method should also scale as O(rn log n) as for SVP and the nuclear norm approach [11  18].

7 Conclusion
We connect a special case of afﬁne rank minimization to a class of semideﬁnite programs with
random constraints. Building on a recently proposed ﬁrst-order algorithm for phase retrieval [6] 
we develop a gradient descent procedure for rank minimization and establish convergence to the
optimal solution with O(r3n log n) measurements. We conjecture that O(rn log n) measurements
are sufﬁcient for the method to converge  and that the conditions on the sampling matrices Ai can be
signiﬁcantly weakened. More broadly  the technique used in this paper—factoring the semideﬁnite
matrix variable  recasting the convex optimization as a nonconvex optimization  and applying ﬁrst-
order algorithms—ﬁrst proposed by Burer and Monteiro [4]  may be effective for a much wider class
of SDPs  and deserves further study.

Acknowledgements
Research supported in part by NSF grant IIS-1116730 and ONR grant N00014-12-1-0762.

8

time (seconds)101102103kbX−X⋆kFkX⋆kF10-1410-1210-1010-810-610-410-2100nuclear normSVPgradient descenttime (seconds)100101102kbX−X⋆kFkX⋆kF10-1210-1010-810-610-410-2100m/n12345probability of successful recovery00.10.20.30.40.50.60.70.80.91rank=1 n=60gradientSVPnuclearrank=2 n=60gradientSVPnuclearrank=1 n=100gradientSVPnuclearrank=2 n=100gradientSVPnuclearReferences
[1] Arash A. Amini and Martin J. Wainwright. High-dimensional analysis of semideﬁnite relax-

ations for sparse principal components. The Annals of Statistics  37(5):2877–2921  2009.

[2] Francis Bach. Adaptivity of averaged stochastic gradient descent to local strong convexity for

logistic regression. The Journal of Machine Learning Research  15(1):595–627  2014.

[3] Francis Bach and Eric Moulines. Non-asymptotic analysis of stochastic approximation algo-
rithms for machine learning. In Advances in Neural Information Processing Systems (NIPS) 
2011.

[4] Samuel Burer and Renato DC Monteiro. A nonlinear programming algorithm for solving
semideﬁnite programs via low-rank factorization. Mathematical Programming  95(2):329–
357  2003.

[5] Jian-Feng Cai  Emmanuel J Cand`es  and Zuowei Shen. A singular value thresholding algorithm

for matrix completion. SIAM Journal on Optimization  20(4):1956–1982  2010.

[6] Emmanuel Cand`es  Xiaodong Li  and Mahdi Soltanolkotabi. Phase retrieval via wirtinger ﬂow:

Theory and algorithms. arXiv preprint arXiv:1407.1065  2014.

[7] A. d’Aspremont  L. El Ghaoui  M. I. Jordan  and G. Lanckriet. A direct formulation for
sparse PCA using semideﬁnite programming. In S. Thrun  L. Saul  and B. Schoelkopf (Eds.) 
Advances in Neural Information Processing Systems (NIPS)  2004.

[8] Michel X. Goemans and David P. Williamson. Improved approximation algorithms for maxi-
mum cut and satisﬁability problems using semideﬁnite programming. Journal of the ACM  42
(6):1115–1145  November 1995. ISSN 0004-5411.

[9] Nathan Halko  Per-Gunnar Martinsson  and Joel A Tropp. Finding structure with randomness:
Probabilistic algorithms for constructing approximate matrix decompositions. SIAM review 
53(2):217–288  2011.

[10] Matt Hoffman  David M. Blei  Chong Wang  and John Paisley. Stochastic variational inference.

The Journal of Machine Learning Research  14  2013.

[11] Prateek Jain  Raghu Meka  and Inderjit S Dhillon. Guaranteed rank minimization via singular
In Advances in Neural Information Processing Systems  pages 937–945 

value projection.
2010.

[12] Prateek Jain  Praneeth Netrapalli  and Sujay Sanghavi. Low-rank matrix completion using
alternating minimization. In Proceedings of the forty-ﬁfth annual ACM symposium on Theory
of computing  pages 665–674. ACM  2013.

[13] Beatrice Laurent and Pascal Massart. Adaptive estimation of a quadratic functional by model

selection. Annals of Statistics  pages 1302–1338  2000.

[14] Michel Ledoux and Brian Rider. Small deviations for beta ensembles. Electron. J. Probab. 
ISSN 1083-6489. doi: 10.1214/EJP.v15-798. URL http:

15:no. 41  1319–1343  2010.
//ejp.ejpecp.org/article/view/798.

[15] Raghu Meka  Prateek Jain  Constantine Caramanis  and Inderjit S Dhillon. Rank minimization
via online learning. In Proceedings of the 25th International Conference on Machine learning 
pages 656–663. ACM  2008.

[16] Yurii Nesterov. Introductory lectures on convex optimization  volume 87. Springer Science &

Business Media  2004.

[17] Praneeth Netrapalli  Prateek Jain  and Sujay Sanghavi. Phase retrieval using alternating mini-

mization. In Advances in Neural Information Processing Systems  pages 2796–2804  2013.

[18] Benjamin Recht  Maryam Fazel  and Pablo A Parrilo. Guaranteed minimum-rank solutions of

linear matrix equations via nuclear norm minimization. SIAM review  52(3):471–501  2010.

[19] Ryota Tomioka  Kohei Hayashi  and Hisashi Kashima. Estimation of low-rank tensors via

convex optimization. arXiv preprint arXiv:1010.0789  2010.

[20] Joel A Tropp. An introduction to matrix concentration inequalities.

arXiv:1501.01571  2015.

arXiv preprint

[21] Stephen Tu  Ross Boczar  Mahdi Soltanolkotabi  and Benjamin Recht. Low-rank solutions of

linear matrix equations via procrustes ﬂow. arXiv preprint arXiv:1507.03566  2015.

9

,Qinqing Zheng
John Lafferty
Shiyu Chang
Yang Zhang
Wei Han
Mo Yu
Xiaoxiao Guo
Wei Tan
Xiaodong Cui
Michael Witbrock
Mark Hasegawa-Johnson
Thomas Huang