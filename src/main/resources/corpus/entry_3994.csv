2013,On the Relationship Between Binary Classification  Bipartite Ranking  and Binary Class Probability Estimation,We investigate the relationship between three fundamental problems in machine learning: binary classification  bipartite ranking  and binary class probability estimation (CPE). It is known that a good binary CPE model can be used to obtain a good binary classification model (by thresholding at 0.5)  and also to obtain a good bipartite ranking model (by using the CPE model directly as a ranking model); it is also known that a binary classification model does not necessarily yield a CPE model. However  not much is known about other directions. Formally  these relationships involve regret transfer bounds. In this paper  we introduce the notion of weak regret transfer bounds  where the mapping needed to transform a model from one problem to another depends on the underlying probability distribution (and in practice  must be estimated from data). We then show that  in this weaker sense  a good bipartite ranking model can be used to construct a good classification model (by thresholding at a suitable point)  and more surprisingly  also to construct a good binary CPE model (by calibrating the scores of the ranking model).,On the Relationship Between Binary Classiﬁcation 
Bipartite Ranking  and Binary Class Probability

Estimation

Shivani Agarwal
Harikrishna Narasimhan
Department of Computer Science and Automation
Indian Institute of Science  Bangalore 560012  India

{harikrishna shivani}@csa.iisc.ernet.in

Abstract

We investigate the relationship between three fundamental problems in machine
learning: binary classiﬁcation  bipartite ranking  and binary class probability esti-
mation (CPE). It is known that a good binary CPE model can be used to obtain a
good binary classiﬁcation model (by thresholding at 0.5)  and also to obtain a good
bipartite ranking model (by using the CPE model directly as a ranking model); it
is also known that a binary classiﬁcation model does not necessarily yield a CPE
model. However  not much is known about other directions. Formally  these rela-
tionships involve regret transfer bounds. In this paper  we introduce the notion of
weak regret transfer bounds  where the mapping needed to transform a model from
one problem to another depends on the underlying probability distribution (and in
practice  must be estimated from data). We then show that  in this weaker sense  a
good bipartite ranking model can be used to construct a good classiﬁcation model
(by thresholding at a suitable point)  and more surprisingly  also to construct a
good binary CPE model (by calibrating the scores of the ranking model).

Introduction

1
Learning problems with binary labels  where one is given training examples consisting of objects
with binary labels (such as emails labeled spam/non-spam or documents labeled relevant/irrelevant) 
are widespread in machine learning. These include for example the three fundamental problems of
binary classiﬁcation  where the goal is to learn a classiﬁcation model which  when given a new
object  can predict its label; bipartite ranking  where the goal is to learn a ranking model that can
rank new objects such that those in one category are ranked higher than those in the other; and
binary class probability estimation (CPE)  where the goal is to learn a CPE model which  when
given a new object  can estimate the probability of its belonging to each of the two classes. Of
these  binary classiﬁcation is classical  although several fundamental questions related to binary
classiﬁcation have been understood only relatively recently [1–4]; bipartite ranking is more recent
and has received much attention in recent years [5–8]  and binary CPE  while a classical problem 
also continues to be actively investigated [9 10]. All three problems abound in applications  ranging
from email classiﬁcation to document retrieval and computer vision to medical diagnosis.
It is well known that a good binary CPE model can be used to obtain a good binary classiﬁcation
model (in a formal sense that we will detail below; speciﬁcally  in terms of regret transfer bounds)
[4  11]; more recently  it was shown that a good binary CPE model can also be used to obtain a
good bipartite ranking model (again  in terms of regret transfer bounds  to be detailed below) [12].
It is also known that a binary classiﬁcation model cannot necessarily be converted to a CPE model.1
However  beyond this  not much is understood about the exact relationship between these problems.2

1Note that we start from a single classiﬁcation model  which rules out the probing reduction of [13].
2There are some results suggesting equivalence between speciﬁc boosting-style classiﬁcation and ranking

algorithms [14  15]  but this does not say anything about relationships between the problems per se.

1

Figure 1: (a) Current state of knowledge; (b) State of knowledge after the results of this paper. Here
‘S’ denotes a ‘strong’ regret transfer relationship; ‘W’ denotes a ‘weak’ regret transfer relationship.

In this paper  we introduce the notion of weak regret transfer bounds  where the mapping needed to
transform a model from one problem to another depends on the underlying probability distribution
(and in practice  must be estimated from data). We then show such weak regret transfer bounds
(under mild technical conditions) from bipartite ranking to binary classiﬁcation  and from bipartite
ranking to binary CPE. Speciﬁcally  we show that  given a good bipartite ranking model and access
to either the distribution or a sample from it  one can estimate a suitable threshold and convert the
ranking model into a good binary classiﬁcation model; similarly  given a good bipartite ranking
model and access to the distribution or a sample  one can ‘calibrate’ the ranking model to construct
a good binary CPE model. Though weak  the regret bounds are non-trivial in the sense that the
sample size required for constructing a good classiﬁcation or CPE model from an existing ranking
model is smaller than what might be required to learn such models from scratch.
The main idea in transforming a ranking model to a classiﬁer is to ﬁnd a threshold that minimizes the
expected classiﬁcation error on the distribution  or the empirical classiﬁcation error on the sample.
We derive these results for cost-sensitive classiﬁcation with any cost parameter c. The main idea
in transforming a ranking model to a CPE model is to ﬁnd a monotonically increasing function
from R to [0  1] which  when applied to the ranking model  minimizes the expected CPE error on
the distribution  or the empirical CPE error on the sample; this is similar to the idea of isotonic
regression [16–19]. The proof here makes use of a recent result of [20] which relates the squared
error of a calibrated CPE model to classiﬁcation errors over uniformly drawn costs  and a result on
the Rademacher complexity of a class of bounded monotonically increasing functions on R [21]. As
a by-product of our analysis  we also obtain a weak regret transfer bound from bipartite ranking to
problems involving the area under the cost curve [22] as a performance measure.
The relationships between the three problems – both those previously known and those established
in this paper – are summarized in Figure 1. As noted above  in a weak regret transfer relationship 
given a model for one type of problem  one needs access to a data sample in order to transform this
to a model for another problem. This is in contrast to the previous ‘strong’ relationships  where a
binary CPE model can simply be thresholded at 0.5 (or cost c) to yield a classiﬁcation model  or can
simply be used directly as a ranking model. Nevertheless  even with the weak relationships  one still
gets that a statistically consistent algorithm for bipartite ranking can be converted into a statistically
consistent algorithm for binary classiﬁcation or for binary CPE. Moreover  as we demonstrate in our
experiments  if one has access to a good ranking model and only a small additional sample  then
one is better off using this sample to transform the ranking model into a classiﬁcation or CPE model
rather than using the limited sample to learn a classiﬁcation or CPE model from scratch.
The paper is structured as follows. We start with some preliminaries and background in Section 2.
Sections 3 and 4 give our main results  namely weak regret transfer bounds from bipartite ranking
to binary classiﬁcation  and from bipartite ranking to binary CPE  respectively. Section 5 gives
experimental results on both synthetic and real data. All proofs are included in the appendix.

2 Preliminaries and Background
Let X be an instance space and let D be a probability distribution on X × {±1}. For (x  y) ∼ D 
we denote η(x) = P(y = 1| x) and p = P(y = 1). In the settings we are interested in  given a
training sample S = ((x1  y1)  . . .   (xn  yn)) ∈ (X × {±1})n with examples drawn iid from D 
the goal is to learn a binary classiﬁcation model  a bipartite ranking model  or a binary CPE model.
In what follows  for u ∈ [−∞ ∞]  we will denote sign(u) = 1 if u > 0 and −1 otherwise  and
sign(u) = 1 if u ≥ 0 and −1 otherwise.

2

(Cost-Sensitive) Binary Classiﬁcation. Here the goal is to learn a model h : X → {±1}. Typically 
one is interested in models h with small expected 0-1 classiﬁcation error:
where 1(·) is 1 if its argument is true and 0 otherwise; this is simply the probability that h misclas-
siﬁes an instance drawn randomly from D. The optimal 0-1 error (Bayes error) is

(cid:2)1(h(x) (cid:54)= y)(cid:3)  
(cid:2) min(cid:0)η(x)  1 − η(x)(cid:1)(cid:3) ;

D [h] = E(x y)∼D

er0-1

er0-1

inf

D [h] = Ex

er0-1 ∗
D =

h:X→{±1}

2

D

=

inf

er0-1 c

D [h] = er0-1

D [h] − er0-1 ∗

D [h] = E(x y)∼D

this is achieved by the Bayes classiﬁer h∗(x) = sign(η(x) − 1
2 ). The 0-1 classiﬁcation regret of
a classiﬁer h is then regret0-1
D . More generally  in a cost-sensitive binary
classiﬁcation problem with cost parameter c ∈ (0  1)  where the cost of a false positive is c and that
of a false negative is (1 − c)  one is interested in models h with small cost-sensitive 0-1 error:

(cid:2)(1 − c)1(cid:0)y = 1  h(x) = −1(cid:1) + c 1(cid:0)y = −1  h(x) = 1(cid:1)(cid:3) .
(cid:2) min(cid:0)(1 − c)η(x)  c(1 − η(x))(cid:1)(cid:3) ;

D [h]. The optimal cost-sensitive 0-1 error for cost

2  we get er0-1  1
Note that for c = 1
parameter c can then be seen to be
er0-1 c ∗
h:X→{±1}
this is achieved by the classiﬁer h∗
h is then regret0-1 c
Bipartite Ranking. Here one wants to learn a ranking model f : X → R that assigns higher scores
to positive instances than to negative ones. Speciﬁcally  the goal is to learn a ranking function f
with small bipartite ranking error:
(cid:48)

er0-1 c
c (x) = sign(η(x) − c). The c-cost-sensitive regret of a classiﬁer

D [h] − er0-1 c ∗

D [h] = er0-1 c

D [h] = Ex

D [h] = 1

2er0-1

(cid:48)(cid:105)

)) < 0(cid:1) + 1

(cid:104)
1(cid:0)(y − y

2 1(cid:0)f (x) = f (x

)(f (x) − f (x

where (x  y)  (x(cid:48)  y(cid:48)) are assumed to be drawn iid from D; this is the probability that a randomly
drawn pair of instances with different labels is mis-ranked by f  with ties broken uniformly at
random. It is known that the ranking error of f is equivalent to one minus the area under the ROC
curve (AUC) of f [5–7]. The optimal ranking error can be seen to be

)(cid:1)(cid:12)(cid:12) y (cid:54)= y
)(1 − η(x))(cid:1)(cid:105)

min(cid:0)η(x)(1 − η(x

D [f ] = E

errank ∗

))  η(x

errank

(cid:104)

Ex x(cid:48)

(cid:48)

.

D

(cid:48)

(cid:48)

(cid:48)

D

= inf

f :X→R errank

D [f ] =

1

2p(1 − p)

 

.

2

inf

ersq

ersq ∗
D =

D [f ] = errank

D [f ] − errank ∗
D .

The optimal squared error can be seen to be

this is achieved by any function f∗ that is a strictly monotonically increasing transformation of η.
The ranking regret of a ranking function f is given by regretrank
Binary Class Probability Estimation (CPE). The goal here is to learn a class probability estimator

(cid:1)2(cid:105)
(cid:2)η(x)(1 − η(x))(cid:3) .
(cid:2)(cid:0)(cid:98)η(x) − η(x)(cid:1)2(cid:3) .

or CPE model(cid:98)η : X → [0  1] with small squared error (relative to labels converted to {0  1}):

(cid:104)(cid:0)(cid:98)η(x) − y+1
D[(cid:98)η ] = E(x y)∼D
ersq
D[(cid:98)η ] = ersq
(cid:98)η:X→[0 1]
The squared-error regret of a CPE model(cid:98)η can be seen to be
D[(cid:98)η ] − ersq ∗
D[(cid:98)η ] = ersq
Theorem 1 ( [4  11]). Let(cid:98)η : X → [0  1]. Let c ∈ (0  1). Then the classiﬁer h(x) = sign(cid:0)(cid:98)η(x) − c)
obtained by thresholding(cid:98)η at c satisﬁes
D[(cid:98)η ] .
Theorem 2 ( [12]). Let(cid:98)η : X → [0  1]. Then using(cid:98)η as a ranking model yields
D[(cid:98)η ] .

Regret Transfer Bounds. The following (strong) regret transfer results from binary CPE to binary
classiﬁcation and from binary CPE to bipartite ranking are known:

(cid:2)|(cid:98)η(x) − η(x)|(cid:3) ≤ (cid:113)

(cid:2)sign ◦ ((cid:98)η − c)(cid:3) ≤ Ex

(cid:2)|(cid:98)η(x) − η(x)|(cid:3) ≤

D [(cid:98)η ] ≤

D[ η ] = Ex

D = Ex

regret0-1 c

regretrank

regretsq

regretsq

regretsq

(cid:113)

Ex

1

1

D

p(1 − p)

p(1 − p)

;

Note that as a consequence of these results  one gets that any learning algorithm that is statistically
consistent for binary CPE  i.e. whose squared-error regret converges in probability to zero as the
training sample size n→∞  can easily be converted into an algorithm that is statistically consistent
for binary classiﬁcation (with any cost parameter c  by thresholding the CPE models learned by the
algorithm at c)  or into an algorithm that is statistically consistent for bipartite ranking (by using the
learned CPE models directly for ranking).

3

3 Regret Transfer Bounds from Bipartite Ranking to Binary Classiﬁcation
In this section  we derive weak regret transfer bounds from bipartite ranking to binary classiﬁcation.
We derive two bounds. The ﬁrst holds in an idealized setting where one is given a ranking model f
as well as access to the distribution D for ﬁnding a suitable threshold to construct the classiﬁer. The
second bound holds in a setting where one is given a ranking model f and a data sample S drawn
iid from D for ﬁnding a suitable threshold; this bound holds with high probability over the draw of
S. Our results will require the following assumption on the distribution D and ranking model f:
Assumption A. Let D be a probability distribution on X × {±1} with marginal distribution µ on
X. Let f : X→R be a ranking model  and let µf denote the induced distribution of scores f (x) ∈ R
when x ∼ µ. We say (D  f ) satisﬁes Assumption A if µf is either discrete  continuous  or mixed
with at most ﬁnitely many point masses.
We will ﬁnd it convenient to deﬁne the following set of all increasing functions from R to {±1}:
Tinc =
θ : R→{±1} : θ(u) = sign(u − t) or θ(u) = sign(u − t) for some t ∈ [−∞ ∞]
.
Deﬁnition 3 (Optimal classiﬁcation transform). For any ranking model f : X → R  cost param-
eter c ∈ (0  1)  and probability distribution D over X ×{±1} such that (D  f ) satisﬁes Assumption
A  deﬁne an optimal classiﬁcation transform ThreshD f c as any increasing function from R to {±1}
such that the classiﬁer h(x) = ThreshD f c(f (x)) resulting from composing f with ThreshD f c
yields minimum cost-sensitive 0-1 error on D:

(cid:110)

(cid:111)

ThreshD f c ∈ argminθ∈Tinc

(cid:8)er0-1 c

D

(cid:2)θ ◦ f(cid:3)(cid:9) .

(OP1)

We note that when f is the class probability function η  we have ThreshD η c(u) = sign(u − c).
Theorem 4 (Idealized weak regret transfer bound from bipartite ranking to binary classiﬁca-
tion based on distribution). Let (D  f ) satisfy Assumption A. Let c ∈ (0  1). Then the classiﬁer
h(x) = ThreshD f c(f (x)) satisﬁes

(cid:2)ThreshD f c ◦ f(cid:3) ≤ (cid:113)

regret0-1 c

D

2p(1 − p) regretrank

D [f ] .

S

S

In practice  one does not have access to the distribution D  and the optimal threshold must be esti-
mated from a data sample. To this end  we deﬁne the following:
Deﬁnition 5 (Optimal sample-based threshold). For any ranking model f : X → R  cost param-
eter c ∈ (0  1)  and sample S ∈ ∪∞

n=1(X×{±1})n  deﬁne an optimal sample-based threshold(cid:98)tS f c
as any threshold on f such that the resulting classiﬁer h(x) = sign(f (x) −(cid:98)tS f c) yields minimum
cost-sensitive 0-1 error on S:(cid:98)tS f c ∈ argmint∈R(cid:8)er0-1 c
based threshold(cid:98)tS f c can be computed in O(n ln n) time by sorting the examples (xi  yi) in S based

(OP2)
[h] denotes the c-cost-sensitive 0-1 error of a classiﬁer h on the empirical distribution

where er0-1 c
associated with S (i.e. the uniform distribution over examples in S).

Note that given a ranking function f  cost parameter c  and a sample S of size n  the optimal sample-

(cid:2)sign ◦(cid:0)f − t(cid:1)(cid:3)(cid:9)  

on the scores f (xi) and evaluating at most n + 1 distinct thresholds lying between adjacent score
values (and above/below all score values) in this sorted order.
Theorem 6 (Sample-based weak regret transfer bound from bipartite ranking to binary clas-
siﬁcation). Let D be any probability distribution on X × {±1} and f : X → R be any ﬁxed
ranking model such that (D  f ) satisﬁes Assumption A. Let S ∈ (X × {±1})n be drawn randomly
according to Dn. Let c ∈ (0  1). Let 0 < δ ≤ 1. Then with probability at least 1 − δ (over the draw

of S ∼ Dn)  the classiﬁer h(x) = sign(f (x) −(cid:98)tS f c) obtained by thresholding f at(cid:98)tS f c satisﬁes
(cid:1)(cid:1)

32(cid:0)2(cid:0) ln(2n) + 1(cid:1) + ln(cid:0) 4

(cid:2)sign ◦ (f −(cid:98)tS f c)(cid:3) ≤ (cid:113)

2p(1 − p) regretrank

regret0-1 c

(cid:115)

D [f ] +

D

δ

.

n

The proof of Theorem 6 involves an application of the result in Theorem 4 together with a standard
VC-dimension based uniform convergence result; speciﬁcally  the proof makes use of the fact that
selecting the sample-based threshold in (OP2) is equivalent to empirical risk minimization over Tinc.
Note in particular that the above regret transfer bound  though ‘weak’  is non-trivial in that it suggests
a good classiﬁer can be constructed from a good ranking model using far fewer examples than might
be required for learning a classiﬁer from scratch based on standard VC-dimension bounds.

4

Remark 7. We note that  as a consequence of Theorem 6  one can use any learning algorithm that
is statistically consistent for bipartite ranking to construct an algorithm that is consistent for (cost-
sensitive) binary classiﬁcation as follows: divide the training data into two (say equal) parts  use
one part for learning a ranking model using the consistent ranking algorithm  and the other part for
selecting a threshold on the learned ranking model; both terms in Theorem 6 will then go to zero as
the training sample size increases  yielding consistency for (cost-sensitive) binary classiﬁcation.
Remark 8. Another implication of the above result is a justiﬁcation for the use of the AUC as
a surrogate performance measure when learning in cost-sensitive classiﬁcation settings where the
misclassiﬁcation costs are unknown during training time [23]. Here  instead of learning a classiﬁer
that minimizes the cost-sensitive classiﬁcation error for a ﬁxed cost parameter that may turn out to
be incorrect  one can learn a ranking function with good ranking performance (in terms of AUC) 
and then later use a small additional sample to select a suitable threshold once the misclassiﬁcation
costs are known; the above result provides guarantees on the resulting classiﬁcation performance in
terms of the ranking (AUC) performance of the learned model.

P(y = 1 |(cid:98)η(x) = u) = u  ∀u ∈ range((cid:98)η) 

We will make use of the following result  which follows from results in [20] and shows that the
squared error of a calibrated CPE model is related to the expected cost-sensitive error of a classiﬁer
constructed using the optimal threshold in Deﬁnition 3  over uniform costs in (0  1):

4 Regret Transfer Bounds from Bipartite Ranking to Binary CPE
We now derive weak regret transfer bounds from bipartite ranking to binary CPE. Again  we derive
two bounds: the ﬁrst holds in an idealized setting where one is given a ranking model f as well as
access to the distribution D for ﬁnding a suitable conversion to a CPE model; the second  which is
a high-probability bound  holds in a setting where one is given a ranking model f and a data sample
S drawn iid from D for ﬁnding a suitable conversion. We will need the following deﬁnition:
w.r.t. a probability distribution D on X × {±1} if

Deﬁnition 9 (Calibrated CPE model). A binary CPE model(cid:98)η : X → [0  1] is said to be calibrated
where range((cid:98)η) denotes the range of(cid:98)η.
Theorem 10 ( [20]). Let(cid:98)η : X → [0  1] be a binary CPE model that is calibrated w.r.t. D. Then
where U (0  1) is the uniform distribution over (0  1) and ThreshD (cid:98)η c is as deﬁned in Deﬁnition 3.
The proof of Theorem 10 follows from the fact that for any CPE model(cid:98)η that is calibrated w.r.t. D 
the optimal classiﬁcation transform is given by ThreshD (cid:98)η c(u) = sign(u − c)  thus generalizing a
We then have the following result  which shows that for a calibrated CPE model(cid:98)η : X→[0  1]  one
Lemma 11 (Regret transfer bound for calibrated CPE models). Let(cid:98)η : X → [0  1] be a binary

can upper bound the squared-error regret in terms of the bipartite ranking regret; this result follows
directly from Theorem 10 and Theorem 4:

(cid:2)ThreshD (cid:98)η c ◦(cid:98)η(cid:3)(cid:3)  

similar result noted earlier for the true class probability function η.

D[(cid:98)η ] = 2 Ec∼U (0 1)

ersq

(cid:2)er0-1 c

D

CPE model that is calibrated w.r.t. D. Then

D[(cid:98)η ] ≤ (cid:113)

regretsq

8p(1 − p) regretrank

D [(cid:98)η ] .

(cid:110)

We are now ready to describe the construction of the optimal CPE transform in the idealized setting.
We will ﬁnd it convenient to deﬁne the following set:

Ginc =

g : R→[0  1] : g is a monotonically increasing function

.

Deﬁnition 12 (Optimal CPE transform). Let f : X → [a  b] (where a  b ∈ R  a < b) be any
bounded-range ranking model and D be any probability distribution over X × {±1} such that
(D  f ) satisﬁes Assumption A. Moreover assume that µf (see Assumption A)  if mixed  does not
have a point mass at the end-points a  b  and that the function ηf : [a  b]→[0  1] deﬁned as ηf (t) =
P(y = 1| f (x) = t) is square-integrable w.r.t. the density of the continuous part of µf . Deﬁne
an optimal CPE transform CalD f as any monotonically increasing function from R to [0  1] such

that the CPE model(cid:98)η(x) = CalD f (f (x)) resulting from composing f with CalD f yields minimum

squared error on D (see appendix for existence of CalD f under these conditions):

(cid:111)

CalD f ∈ argming∈Ginc

(cid:8)ersq

D

(cid:2)g ◦ f(cid:3)(cid:9) .

5

(OP3)

Lemma 13 (Properties of CalD f ). Let (D  f ) satisfy the conditions of Deﬁnition 12. Then

1. (CalD f ◦ f ) is calibrated w.r.t. D.
2. errank
D

(cid:2)CalD f ◦ f(cid:3) ≤ errank

D [f ].

The proof of Lemma 13 is based on equivalent results for the minimizer of a sample version of
(OP3) [24  25]. Combining this with Lemma 11 immediately gives the following result:
Theorem 14 (Idealized weak regret transfer bound from bipartite ranking to binary CPE
based on distribution). Let (D  f ) satisfy the conditions of Deﬁnition 12. Then the CPE model

(cid:98)η(x) = CalD f (f (x)) obtained by composing f with CalD f satisﬁes

(cid:2)CalD f ◦ f(cid:3) ≤ (cid:113)

regretsq

D

8p(1 − p) regretrank

D [f ] .

We now derive a sample version of the above result.
Deﬁnition 15 (Optimal sample-based CPE transform). For any ranking model f : X → R
and sample S ∈ ∪∞

n=1(X × {±1})n  deﬁne an optimal sample-based transform (cid:99)CalS f as any
monotonically increasing function from R to [0  1] such that the CPE model(cid:98)η(x) = (cid:99)CalS f (f (x))
resulting from composing f with (cid:99)CalS f yields minimum squared error on S:
S [(cid:98)η ] denotes the squared error of a CPE model(cid:98)η on the empirical distribution associated

(cid:99)CalS f ∈ argming∈Ginc

where ersq
with S (i.e. the uniform distribution over examples in S).

(cid:2)g ◦ f(cid:3)(cid:9)  

(cid:8)ersq

(OP4)

S

The above optimization problem corresponds to the well-known isotonic regression problem and
can be solved in O(n ln n) time using the pool adjacent violators (PAV) algorithm [16] (the PAV
algorithm outputs a score in [0  1] for each instance in S such that these scores preserve the ordering
of f; a straightforward interpolation of the scores then yields a monotonically increasing function
of f). We then have the following sample-based weak regret transfer result:
Theorem 16 (Sample-based weak regret transfer bound from bipartite ranking to binary
CPE). Let D be any probability distribution on X × {±1} and f : X → [a  b] be any ﬁxed
ranking model such that (D  f ) satisﬁes the conditions of Deﬁnition 12. Let S ∈ (X × {±1})n
be drawn randomly according to Dn. Let 0 < δ ≤ 1. Then with probability at least 1 − δ (over

the draw of S ∼ Dn)  the CPE model(cid:98)η(x) = (cid:99)CalS f (f (x)) obtained by composing f with (cid:99)CalS f

satisﬁes

(cid:2)(cid:99)CalS f ◦ f(cid:3) ≤ (cid:113)

regretsq

D

8p(1 − p) regretrank

D [f ] + 96

2 ln(n)

n

+ 2

(cid:114)

(cid:115)

2 ln(cid:0) 8

δ

(cid:1)

.

n

The proof of Theorem 16 involves an application of the idealized result in Theorem 14  together with
a standard uniform convergence argument based on Rademacher averages applied to the function
class Ginc; for this  we make use of a result on the Rademacher complexity of this class [21].
Remark 17. As in the case of binary classiﬁcation  we note that  as a consequence of Theorem 16 
one can use any learning algorithm that is statistically consistent for bipartite ranking to construct an
algorithm that is consistent for binary CPE as follows: divide the training data into two (say equal)
parts  use one part for learning a ranking model using the consistent ranking algorithm  and the other
part for selecting a CPE transform on the learned ranking model; both terms in Theorem 16 will then
go to zero as the training sample size increases  yielding consistency for binary CPE.
Remark 18. We note a recent result in [19] giving a bound on the empirical squared error of a CPE
model constructed from a ranking model using isotonic regression in terms of the empirical ranking
error of the ranking model. However  this does not amount to a regret transfer bound.
Remark 19. Finally  we note that the quantity Ec∼U (0 1)
Theorem 10 is also the area under the cost curve [20  22]; since this quantity is upper bounded in
terms of regretrank
D [f ] by virtue of Theorem 4  we also get a weak regret transfer bound from bipartite
ranking to problems where the area under the cost curve is a performance measure of interest. In
particular  this implies that algorithms that are statistically consistent with respect to AUC can also
be used to construct algorithms that are statistically consistent w.r.t. the area under the cost curve.

(cid:2)ThreshD (cid:98)η c ◦(cid:98)η(cid:3)(cid:3) that appears in

(cid:2)er0-1 c

D

6

(a)

(b)

Figure 2: Results on synthetic data. A ranking model was learned using a pairwise linear logistic re-
gression ranking algorithm (which is a consistent ranking algorithm for the distribution used in these
experiments); this was followed by an optimal choice of classiﬁcation threshold (with c = 1
2) or op-
timal CPE transform based on the distribution as outlined in Sections 3 and 4. The plots show (a)
0-1 classiﬁcation regret of the resulting classiﬁcation model together with the corresponding upper
bound from Theorem 4; and (b) squared-error regret of the resulting CPE model together with the
corresponding upper bound from Theorem 14. As can be seen  in both cases  the classiﬁcation/CPE
regret converges to zero as the training sample size increases.
5 Experiments
We conducted two types of experiments to evaluate the results described in this paper:
the ﬁrst
involved synthetic data drawn from a known distribution for which the classiﬁcation and ranking
regrets could be calculated exactly; the second involved real data from the UCI Machine Learning
Repository. In the ﬁrst experiment  we learned ranking models using a consistent ranking algorithm
on increasing training sample sizes  converted the learned models using the optimal threshold or
CPE transforms described in Sections 3 and 4 based on the distribution  and veriﬁed that this yielded
classiﬁcation and CPE models with 0-1 classiﬁcation regret and squared-error regret converging to
zero. In the second experiment  we simulated a setting where a ranking model has been learned
from some data  the original training data is no longer available  and a classiﬁcation/CPE model is
needed; we investigated whether in such a setting the ranking model could be used in conjunction
with a small additional data sample to produce a useful classiﬁcation or CPE model.

5.1 Synthetic Data
Our ﬁrst goal was to verify that using ranking models learned by a statistically consistent ranking
algorithm and applying the distribution-based transformations described in Sections 3 and 4 yields
classiﬁcation/CPE models with classiﬁcation/CPE regret converging to zero. For these experiments 
we generated examples in (X = Rd) × {±1} (with d = 100) as follows: each example was
assigned a positive/negative label with equal probability  with the positive instances drawn from a
multivariate Gaussian distribution with mean µ ∈ Rd and covariance matrix Σ ∈ Rd×d  and negative
instances drawn from a multivariate Gaussian distribution with mean −µ and the same covariance
matrix Σ; here µ was drawn uniformly at random from {−1  1}d  and Σ was drawn from a Wishart
distribution with 200 degrees of freedom and a randomly drawn invertible PSD scale matrix. For this
distribution  the optimal ranking and classiﬁcation models are linear. Training samples of various
√
sizes n were generated from this distribution; in each case  a linear ranking model was learned using
a pairwise linear logistic regression algorithm (with regularization parameter set to 1/
n)  and an
optimal threshold (with c = 1
2) or CPE transform was then applied to construct a binary classiﬁcation
or CPE model. In this case the ranking regret and 0-1 classiﬁcation regret of a linear model and can
be computed exactly; the squared-error regret for the CPE model was computed approximately by
sampling instances from the distribution. The results are shown in Figure 2. As can be seen  the
classiﬁcation and squared-error regrets of the classiﬁcation and CPE models constructed both satisfy
the bounds from Theorems 4 and 14  and converge to zero as the bounds suggest.

5.2 Real Data
Our second goal was to investigate whether good classiﬁcation and CPE models can be constructed
in practice by applying the data-based transformations described in Sections 3 and 4 to an existing
ranking model. For this purpose  we conducted experiments on several data sets drawn from the UCI
Machine Learning Repository3. We present representative results on two data sets: Spambase (4601

3http://archive.ics.uci.edu/ml/

7

10210310410500.10.20.30.40.50.60.7No. of training examples0−1 regret Upper boundRanking + Opt. Thres. Choice10210310410500.10.20.30.40.50.60.7No. of training examplesSquared regret Upper boundRanking + Calibration(a) Spambase (0-1)

(b) Internet-ads (0-1)

(c) Spambase (CPE)

(d) Internet-ads (CPE)

Figure 3: Results on real data from the UCI repository. A ranking model was learned using a pair-
wise linear logistic regression ranking algorithm from a part of the data set that was then discarded.
The remaining data was divided into training and test sets. The training data was then used to esti-
mate an empirical (sample-based) classiﬁcation threshold and CPE transform (calibration) for this
ranking model as outlined in Sections 3 and 4. Using the same training data  a binary classiﬁer and
CPE model were also learned from scratch using a standard linear logistic regression algorithm. The
plots show the resulting test error for both approaches. As can be seen  if only a small amount of
additional data is available  then using this data to convert an existing ranking model into a classiﬁ-
cation/CPE model is more beneﬁcial than learning a classiﬁcation/CPE model from scratch.
instances  57 features) and Internet Ads (3279 instances  1554 features4). Here we divided each
data set into three equal parts. One part was used to learn a ranking model using a pairwise linear
logistic regression algorithm  and was then discarded. This allowed us to simulate a situation where
a (reasonably good) ranking model is available  but the original training data used to learn the model
is no longer accessible. Various subsets of the second part of the data (of increasing size) were then
used to estimate a data-based threshold or CPE transform on this ranking model using the optimal
sample-based methods described in Sections 3 and 4. The performance of the constructed classi-
ﬁcation and CPE models on the third part of the data  which was held out for testing purposes  is
shown in Figure 3. For comparison  we also show the performance of binary classiﬁcation and CPE
models learned directly from the same subsets of the second part of the data using a standard linear
logistic regression algorithm. In each case  the regularization parameter for both standard logistic
regression and pairwise logistic regression was chosen from {10−4  10−3  10−2  10−1  1  10  102}
using 5-fold cross validation on the corresponding training data. As can be seen  when one has
access to a previously learned (or otherwise available) ranking model with good ranking perfor-
mance  and only a small amount of additional data  then one is better off using this data to estimate
a threshold/CPE transform and converting the ranking model into a classiﬁcation/CPE model  than
learning a classiﬁcation/CPE model from this data from scratch. However  as can also be seen  the
eventual performance of the classiﬁcation/CPE model thus constructed is limited by the ranking per-
formance of the original ranking model; therefore  once there is sufﬁcient additional data available 
it is advisable to use this data to learn a new model from scratch.

6 Conclusion
We have investigated the relationship between three fundamental problems in machine learning:
binary classiﬁcation  bipartite ranking  and binary class probability estimation (CPE). While formal
regret transfer bounds from binary CPE to binary classiﬁcation and to bipartite ranking are known 
little has been known about other directions. We have introduced the notion of weak regret transfer
bounds that require access to a distribution or data sample  and have established the existence of
such bounds from bipartite ranking to binary classiﬁcation and to binary CPE. The latter result
makes use of ideas related to calibration and isotonic regression; while these ideas have been used
to calibrate scores from real-valued classiﬁers to construct probability estimates in practice  to our
knowledge  this is the ﬁrst use of such ideas in deriving formal regret bounds in relation to ranking.
Our experimental results demonstrate possible uses of the theory developed here.

Acknowledgments

Thanks to Karthik Sridharan for pointing us to a result on monotonically increasing functions.
Thanks to the anonymous reviewers for many helpful suggestions. HN gratefully acknowledges
support from a Google India PhD Fellowship. SA thanks the Department of Science & Technology
(DST)  the Indo-US Science & Technology Forum (IUSSTF)  and Yahoo! for their support.

4The original data set contains 1558 features; we discarded 4 features with missing entries.

8

1020304050607080901000.060.080.10.120.140.16%. of training examples0−1 error(Fixed) Ranking error = 0.0317 Empr. Thres. ChoiceLogistic Regression1020304050607080901000.020.030.040.050.060.070.08%. of training examples0−1 error(Fixed) Ranking error = 0.0179 Empr. Thres. ChoiceLogistic Regression1020304050607080901000.050.060.070.080.090.10.110.12%. of training examplesSquared error(Fixed) Ranking error = 0.0317 Empr. CalibrationLogistic Regression1020304050607080901000.020.030.040.050.06%. of training examplesSquared error(Fixed) Ranking error = 0.0179 Empr. CalibrationLogistic RegressionReferences
[1] T. Zhang. Statistical behavior and consistency of classiﬁcation methods based on convex risk minimiza-

tion. Annals of Statistics  32(1):56–134  2004.

[2] P. L. Bartlett  M. I. Jordan  and J. D. McAuliffe. Convexity  classiﬁcation and risk bounds. Journal of the

American Statistical Association  101(473):138–156  2006.

[3] M. D. Reid and R. C. Williamson. Surrogate regret bounds for proper losses. In ICML  2009.
[4] C. Scott. Calibrated asymmetric surrogate losses. Electronic Journal of Statistics  6:958–992  2012.
[5] Y. Freund  R. Iyer  R. E. Schapire  and Y. Singer. An efﬁcient boosting algorithm for combining prefer-

ences. Journal of Machine Learning Research  4:933–969  2003.

[6] C. Cortes and M. Mohri. AUC optimization vs. error rate minimization. In Advances in Neural Informa-

tion Processing Systems 16. MIT Press  2004.

[7] S. Agarwal  T. Graepel  R. Herbrich  S. Har-Peled  and D. Roth. Generalization bounds for the area under

the ROC curve. Journal of Machine Learning Research  6:393–425  2005.

[8] S. Cl´emenc¸on  G. Lugosi  and N. Vayatis. Ranking and empirical minimization of U-statistics. Annals of

Statistics  36:844–874  2008.

[9] A. Buja  W. Stuetzle  and Y. Shen. Loss functions for binary class probability estimation: Structure and

applications. Technical report  University of Pennsylvania  November 2005.

[10] M. D. Reid and R. C. Williamson. Composite binary losses. Journal of Machine Learning Research 

11:2387–2422  2010.

[11] L. Devroye  L. Gyorﬁ  and G. Lugosi. A Probabilistic Theory of Pattern Recognition. Springer  1996.
[12] S. Cl´emenc¸on and S. Robbiano. Minimax learning rates for bipartite ranking and plug-in rules.

Proceedings of the 28th International Conference on Machine Learning  2011.

In

[13] John Langford and Bianca Zadrozny. Estimating class membership probabilities using classiﬁer learners.

In AISTATS  2005.

[14] C. Rudin and R.E. Schapire. Margin-based ranking and an equivalence between adaboost and rankboost.

Journal of Machine Learning Research  10:2193–2232  2009.

[15] S¸. Ertekin and C. Rudin. On equivalence relationships between classiﬁcation and ranking algorithms.

Journal of Machine Learning Research  12:2905–2929  2011.

[16] M. Ayer  H.D. Brunk  G. M. Ewing  W. T. Reid  and E. Silverman. An empirical distribution function for

sampling with incomplete information. The Annals of Mathematical Statistics  26(4):641–647  1955.

[17] H. D. Brunk. On the estimation of parameters restricted by inequalities. The Annals of Mathematical

Statistics  29(2):437–454  1958.

[18] B. Zadrozny and C. Elkan. Transforming classiﬁer scores into accurate multiclass probability estimates.

In KDD  2002.

[19] A.K. Menon  X. Jiang  S. Vembu  C. Elkan  and L. Ohno-Machado. Predicting accurate probabilities with

a ranking loss. In ICML  2012.

[20] J. Hern´andez-Orallo  P. Flach  and C. Ferri. A uniﬁed view of performance metrics: Translating threshold

choice into expected classiﬁcation loss. Journal of Machine Learning Research  13:2813–2869  2012.

[21] P. Bartlett. CS281B/Stat241B (Spring 2008) Statistical Learning Theory [Lecture 19 notes]  University of
California  Berkeley. http://www.cs.berkeley.edu/˜bartlett/courses/281b-sp08/
19.pdf. 2008.

[22] C. Drummond and R.C. Holte. Cost curves: An improved method for visualizing classiﬁer performance.

Machine Learning  65(1):95–130  2006.

[23] M.A. Maloof. Learning when data sets are imbalanced and when costs are unequal and unknown. In

ICML-2003 Workshop on Learning from Imbalanced Data Sets II  volume 2  2003.

[24] A.T. Kalai and R. Sastry. The isotron algorithm: High-dimensional isotonic regression. In COLT  2009.
[25] T. Fawcett and A. Niculescu-Mizil. PAV and the ROC convex hull. Machine Learning  68(1):97–106 

2007.

[26] S. Agarwal. Surrogate regret bounds for the area under the ROC curve via strongly proper losses. In

COLT  2013.

[27] D. Anevski and P. Soulier. Monotone spectral density estimation. Annals of Statistics  39(1):418–438 

2011.

[28] P. Groeneboom and G. Jongbloed. Generalized continuous isotonic regression. Statistics & Probability

Letters  80(34):248–253  2010.

9

,Harikrishna Narasimhan
Shivani Agarwal