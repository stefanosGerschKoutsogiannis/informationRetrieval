2019,Private Hypothesis Selection,We provide a differentially private algorithm for hypothesis selection. 
  Given samples from an unknown probability distribution $P$ and a set of $m$ probability distributions $\mathcal{H}$  the goal is to output  in a $\varepsilon$-differentially private manner  a distribution from $\mathcal{H}$ whose total variation distance to $P$ is comparable to that of the best such distribution (which we denote by $\alpha$).
  The sample complexity of our basic algorithm is $O\left(\frac{\log m}{\alpha^2} + \frac{\log m}{\alpha \varepsilon}\right)$  representing a minimal cost for privacy when compared to the non-private algorithm. We also can handle infinite hypothesis classes $\mathcal{H}$ by relaxing to $(\varepsilon \delta)$-differential privacy.

  We apply our hypothesis selection algorithm to give learning algorithms for a number of natural distribution classes  including Gaussians  product distributions  sums of independent random variables  piecewise polynomials  and mixture classes.
  Our hypothesis selection procedure allows us to generically convert a cover for a class to a learning algorithm  complementing known learning lower bounds which are in terms of the size of the packing number of the class.
  As the covering and packing numbers are often closely  related  for constant $\alpha$  our algorithms achieve the optimal sample complexity for many classes of interest.
  Finally  we describe an application to private distribution-free PAC learning.,Private Hypothesis Selection

Department of Computer Science

Cheriton School of Computer Science

Mark Bun

Boston University

mbun@bu.edu

Gautam Kamath

University of Waterloo

g@csail.mit.edu

Thomas Steinke
IBM Research

phs@thomas-steinke.net

Department of Computer Science & Engineering

Zhiwei Steven Wu

University of Minnesota

zsw@umn.edu

Abstract

α2 + log m

αε

(cid:17)

(cid:16) log m

We provide a differentially private algorithm for hypothesis selection. Given
samples from an unknown probability distribution P and a set of m probability dis-
tributions H  the goal is to output  in a ε-differentially private manner  a distribution
from H whose total variation distance to P is comparable to that of the best such
distribution (which we denote by α). The sample complexity of our basic algorithm
is O
  representing a minimal cost for privacy when compared to
the non-private algorithm. We also can handle inﬁnite hypothesis classes H by
relaxing to (ε  δ)-differential privacy.
We apply our hypothesis selection algorithm to give learning algorithms for a
number of natural distribution classes  including Gaussians  product distributions 
sums of independent random variables  piecewise polynomials  and mixture classes.
Our hypothesis selection procedure allows us to generically convert a cover for a
class to a learning algorithm  complementing known learning lower bounds which
are in terms of the size of the packing number of the class. As the covering and
packing numbers are often closely related  for constant α  our algorithms achieve
the optimal sample complexity for many classes of interest. Finally  we describe
an application to private distribution-free PAC learning.

1

Introduction

We consider the problem of hypothesis selection: given samples from an unknown probability
distribution  select a distribution from some ﬁxed set of candidates which is “close” to the unknown
distribution in some appropriate distance measure. Such situations can arise naturally in a number
of settings. For instance  we may have a number of different methods which work under various
circumstances  which are not known in advance. One option is to run all the methods to generate a
set of hypotheses  and pick the best from this set afterwards. Relatedly  an algorithm may branch
its behavior based on a number of “guesses ” which will similarly result in a set of candidates 
corresponding to the output at the end of each branch. Finally  if we know that the underlying
distribution belongs to some (parametric) class  it is possible to essentially enumerate the class (also
known as a cover) to create a collection of hypotheses. Observe that this last example is quite general 
and this approach can give generic learning algorithms for many settings of interest.

A full version of the paper  with additional details and proofs  appears in the supplement  or on arXiv [9].

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

This problem of hypothesis selection has been extensively studied (see  e.g.  [46  17  18  19]) 
resulting in algorithms with a sample complexity which is logarithmic in the number of hypotheses.
Such a mild dependence is critical  as it facilitates sample-efﬁcient algorithms even when the
number of candidates may be large. These initial works have triggered a great deal of study into
hypothesis selection with additional considerations  including computational efﬁciency  understanding
the optimal approximation factor  adversarial robustness  and weakening access to the hypotheses
(e.g.  [36  15  16  43  2  21  1  7]).
However  in modern settings of data analysis  data may contain sensitive information about individ-
uals. Some examples of such data include medical records  GPS location data  or private message
transcripts. As such  we would like to perform statistical inference in these settings without revealing
signiﬁcant information about any particular individual’s data. To this end  there have been many
proposed notions of data privacy  but perhaps the gold standard is that of differential privacy [26].
Informally  differential privacy requires that  if a single datapoint in the dataset is changed  then the
distribution over outputs produced by the algorithm should be similar (see Deﬁnition 4). Differential
privacy has seen widespread adoption  including deployment by Apple [22]  Google [28]  and the US
Census Bureau [14].
This naturally raises the question of whether one can perform hypothesis selection under the constraint
of differential privacy  while maintaining a logarithmic dependence on the size of the cover. Such a
tool would allow us to generically obtain private learning results for a wide variety of settings.

1.1 Results

Our main results answer this in the afﬁrmative: we provide differentially private algorithms for
selecting a good hypothesis from a set of distributions. The output distribution is competitive with
the best distribution  and the sample complexity is bounded by the logarithm of the size of the set.
The following is a basic version of our main result.
Theorem 1. Let H = {H1  . . .   Hm} be a set of probability distributions. Let D = {X1  . . .   Xn}
be a set of samples drawn independently from an unknown probability distribution P . There exists
an ε-differentially private algorithm (with respect to the dataset D) which has following guarantees.
Suppose there exists a distribution H∗ ∈ H such that dTV(P  H∗) ≤ α. If n = Ω
α2 + log m
 
then the algorithm will output a distribution ˆH ∈ H such that dTV(P  ˆH) ≤ (3+ζ)α with probability
at least 9/10  for any constant ζ > 0. The running time of the algorithm is O(nm2).

(cid:17)

αε

(cid:16) log m
(cid:17)

(cid:16) log m

α2

(cid:16) log m

(cid:17)

The sample complexity of this problem without privacy constraints is O

  and thus the

αε

additional cost for ε-differential privacy is an additive O
. We consider this cost to be
minimal; in particular  the dependence on m is unchanged. Note that the running time of our
algorithm is O(nm2) – we conjecture it may be possible to reduce this to ˜O(nm) as has been done
in the non-private setting [16  43  2  1]  though we have not attempted to perform this optimization.
Regardless  our main focus is on the sample complexity rather than the running time  since any
method for generic hypothesis selection requires Ω(m) time  thus precluding efﬁcient algorithms
when m is large. Note that the approximation factor of (3 + ζ)α is effectively tight [19  36  7].
Theorem 1 requires prior knowledge of the value of α  though we can use this to obtain an algorithm
with similar guarantees which does not (Theorem 3).
It is possible to improve the guarantees of this algorithm in two ways (Theorem 4). First  if the
distributions are nicely structured  the former term in the sample complexity can be reduced from
O(log m/α2) to O(d/α2)  where d is a VC-dimension-based measure of the complexity of the
collection of distributions. Second  if there are few hypotheses which are close to the true distribution 
then we can pay only logarithmically in this number  as opposed to the total number of hypotheses.
These modiﬁcations allow us to handle instances where m may be very large (or even inﬁnite)  albeit
at the cost of weakening to approximate differential privacy to perform the second reﬁnement. A
technical discussion of our methods is in Section 1.2  our basic approach is covered in Section 3  and
the version with all the bells and whistles appears in Section 4.
From Theorem 1  we immediately obtain Corollary 1 which applies when H itself may not be ﬁnite 
but admits a ﬁnite cover with respect to total variation distance.

2

(cid:17)

.

αε

(cid:16) log |Cα|
α2 + log |Cα|

Corollary 1. Suppose there exists an α-cover Cα of a set of distributions H  and that we are given
a set of samples X1  . . .   Xn ∼ P   where dTV(P H) ≤ α. For any constant ζ > 0  there exists
an ε-differentially private algorithm (with respect to the input {X1  . . .   Xn}) which outputs a
distribution H∗ ∈ Cα such that dTV(P  H∗) ≤ (6 + 2ζ)α with probability ≥ 9/10  as long as
n = Ω
Informally  this says that if a hypothesis class has an α-cover Cα  then there is a private learning
algorithm for the class which requires O(log |Cα|) samples. Note that our algorithm works even if
the unknown distribution is only close to the hypothesis class. This is useful when we may have
model misspeciﬁcation  or when we require adversarial robustness. The requirements for this theorem
to apply are minimal  and thus it generically provides learning algorithms for a wide variety of
hypothesis classes. That said  in non-private settings  the sample complexity given by this method is
rather lossy: as an extreme example  there is no ﬁnite-size cover of univariate Gaussian distributions
with unbounded parameters  so this approach does not give a ﬁnite-sample algorithm. That said  it is
well-known that O(1/α2) samples sufﬁce to estimate a Gaussian in total variation distance. In the
private setting  our theorem incurs a cost which is somewhat necessary: in particular  it is folklore
that any pure ε-differentially private learning algorithm must pay a cost which is logarithmic in the
packing number of the class. Due to the relationship between packing and covering numbers  this
implies that up to a constant factor relaxation in the learning accuracy  our results are tight. A more
formal discussion appears in the supplement.
Given Corollary 1  in Section 5  we derive new learning results for a number of classes. Our main
applications are for d-dimensional Gaussian and product distributions. Informally  we obtain ˜O(d)
sample algorithms for learning a product distribution and a Gaussian with known covariance  and
an ˜O(d2) algorithm for learning a Gaussian with unknown covariance (Corollaries 2 and 3). These
improve on recent results by Kamath  Li  Singhal  and Ullman [33] in two different ways. First  as
mentioned before  our results are semi-agnostic  so we can handle when the distribution is only close
to a product or Gaussian distribution. Second  our results hold for pure (ε  0)-differential privacy 
which is a stronger notion than ε2-zCDP as considered in [33]. In this weaker model  they also
obtained ˜O(d) and ˜O(d2) sample algorithms  but the natural modiﬁcations to achieve ε-DP incur
extra poly(d) factors.1 [33] also showed ˜Ω(d) lower bounds for Gaussian and product distribution
estimation in the even weaker model of (ε  δ)-differential privacy. Thus  our results show that the
dimension dependence for these problems is unchanged for essentially any notion of differential
privacy. In particular  our results show a previously-unknown separation between mean estimation
of product distributions and non-product distributions under pure (ε  0)-differential privacy; see
Remark 1.
We also apply Theorem 4 to obtain algorithms for learning Gaussians under (ε  δ)-differential privacy 
with no bounds on the mean and variance parameters. More speciﬁcally  we provide algorithms
for learning multivariate Gaussians with unknown mean and known covariance (Corollary 4)  in
which we manage to avoid dependences which arise due to the application of advanced composition
(similar to Remark 1). We additionally give algorithms for learning mixtures of any coverable class
(Corollary 5). In particular  this immediately implies algorithms for learning mixtures of Gaussians 
product distributions  and all other classes mentioned above. Additional classes we can learn privately 
described and discussed in the supplement  include piecewise polynomials  sums of independent
random variables  and univariate Gaussians with unbounded mean and variance.
To conclude our applications  we discuss a connection to PAC learning. It is known that the sample
complexity of differentially private distribution-free PAC learning can be higher than that of non-
private learning. However  this gap does not exist for distribution-speciﬁc learning  where the
learning algorithm knows the distribution of (unlabeled) examples  as both sample complexities are
characterized by VC dimension. Private hypothesis selection allows us to address an intermediate
situation where the distribution of unlabeled examples is not known exactly  but is known to come
(approximately) from a class of distributions. When this class has a small cover  we are able to recover
sample complexity guarantees for private PAC learning which are comparable to the non-private case.
Details and discussion appear in the supplement.

1Roughly  this is due to the fact that the Laplace and Gaussian mechanism are based on (cid:96)1 and (cid:96)2 sensitivity 

√

respectively  and that there is a

d-factor relationship between these two norms  in the worst case.

3

1.2 Techniques

(cid:1) sets (the “Scheffé”

2

Non-privately  most algorithms for hypothesis selection involve a tournament-style approach. We
conduct a number of pairwise comparisons between distributions  which may either have a winner
and a loser  or may be declared a draw. Intuitively  a distribution will be declared the winner of a
comparison if it is much closer than the alternative to the unknown distribution  and a tie will be
declared if the two distributions are comparably close. The algorithm will output any distribution
which never loses a comparison. A single comparison between a pair of hypotheses requires O(1/α2)
samples  and a Chernoff plus union bound argument over the O(m2) possible comparisons increases
the sample complexity to O(log m/α2). In fact  we can use uniform convergence arguments to reduce

this sample complexity to O(d/α2)  where d is the VC dimension of the 2(cid:0)m

sets) deﬁned by the subsets of the domain where the PDF of one distribution dominates another.
Crucially  we must reuse the same set of samples for all comparisons to avoid paying polynomially in
the number of hypotheses.
A private algorithm for this problem requires additional care. Since a single comparison is based
on the number of samples which fall into a particular subset of the domain  the sensitivity of the
underlying statistic is low  and thus privacy may seem easily achievable at ﬁrst glance. However 
the challenge comes from the fact that the same samples are reused for all pairwise comparisons 
thus greatly increasing the sensitivity: changing a single datapoint could ﬂip the result of every
comparison! In order to avoid this pitfall  we instead carefully construct a score function for each
hypothesis  namely  the minimum number of points that must be changed to cause the distribution to
lose any comparison. For this to be a useful score function  we must show that the best hypothesis
will win all of its comparisons by a large margin. We can then use the Exponential Mechanism [37]
to select a distribution with high score.
Further improvements can be made if we are guaranteed that the number of “good” hypotheses (i.e. 
those that have total variation distance from the true distribution bounded by (3 + ζ)α) is at most
some parameter k  and if we are willing to relax to approximate differential privacy. The parameter
k here is related to the doubling dimension of the hypothesis class with respect to total variation
distance. If we randomly assign the hypotheses to Ω(k2) buckets  with high probability  no bucket
will contain more than one good hypothesis. We can identify a bucket containing a good hypothesis
using a similar method based on the exponential mechanism as described above. Moreover  since
we are likely to only have one “good” hypothesis in the chosen bucket  this implies a signiﬁcant
gap between the best and second-best scores in that bucket. This allows us to use stability-based
techniques [25  44]  and in particular the GAP-MAX algorithm of Bun  Dwork  Rothblum  and
Steinke [8]  to identify an accurate distribution.

1.3 Related Work

Our main result builds on a long line of work on non-private hypothesis selection. One starting point
for the particular style of approach we consider here is [46]  which was expanded on in [17  18  19].
Since then  there has been study into hypothesis selection under additional considerations  including
computational efﬁciency  understanding the optimal approximation factor  adversarial robustness 
and weakening access to the hypotheses [36  15  16  43  2  21  1  7]. Our private algorithm examines
the same type of problem  with the additional constraint of differential privacy.
There has recently been a great deal of interest in differentially private distribution learning. In
the central model  most relevant are [20]  which gives algorithms for learning structured univariate
distributions  and [35  33]  which focus on learning Gaussians and binary product distributions.
[13] also studies private statistical parameter estimation. Privately learning mixtures of Gaussians
was considered in [39  34]. The latter paper (which is concurrent with the present work) gives
a computationally efﬁcient algorithm for the problem  but with a worse sample complexity  and
incomparable accuracy guarantees (they require a separation condition  and perform clustering and
parameter estimation  while we do proper learning). [10] give an algorithm for learning distributions
in Kolmogorov distance. Upper and lower bounds for learning the mean of a product distribution
over the hypercube in (cid:96)∞-distance include [6  12  26  42]. [3] focuses on estimating properties of a
distribution  rather than the distribution itself. [40] gives an algorithm which allows one to estimate
asymptotically normal statistics with optimal convergence rates  but no ﬁnite sample complexity
guarantees. There has also been a great deal of work on distribution learning in the local model

4

of differential privacy [23  45  32  4  24  31  47  29]. Additional discussion of non-private learning
appears in the supplementary material.

2 Preliminaries

(cid:82)

Deﬁnition 1. The total variation distance or statistical distance between P and Q is deﬁned as
2(cid:107)P −Q(cid:107)1 ∈ [0  1]. Moreover 
dTV(P  Q) = maxS⊆Ω P (S)−Q(S) = 1
if H is a set of distributions over a common domain  we deﬁne dTV(P H) = inf H∈H dTV(P  H).
Deﬁnition 2. A γ-cover of a set of distributions H is a set of distributions Cγ  such that for every
H ∈ H  there exists some P ∈ Cγ such that dTV(P  H) ≤ γ. A γ-packing of a set of distributions H
is a set of distributions Pγ ⊆ H  such that for every pair of distributions P  Q ∈ Pγ  we have that
dTV(P  Q) ≥ γ.

x∈Ω |P (x)−Q(x)|dx = 1

2

In this paper  we present semi-agnostic learning algorithms.
Deﬁnition 3. An algorithm is said to be an α-semi-agnostic learner for a class H if it has the
following guarantees. Suppose we are given X1  . . .   Xn ∼ P   where dTV(P H) ≤ OPT. The
algorithm must output some distribution ˆH such that dTV(P  H) ≤ c · OPT + O(α)  for some
constant c ≥ 1. If c = 1  then the algorithm is said to be agnostic.

We consider algorithms under the constraint of differential privacy.
Deﬁnition 4 ([26]). A randomized algorithm T : X∗ → R is (ε  δ)-differentially private if for all
n ≥ 1  for all neighboring datasets D  D(cid:48) ∈ X n  and for all events S ⊆ R  Pr [T (D) ∈ S] ≤
eε Pr[T (D(cid:48)) ∈ S] + δ . If δ = 0  we say that T is ε-differentially private.

We will also use the related notion of concentrated differential privacy [27  11]  which is deﬁned in
the supplement.
Our methods will rely heavily upon the Exponential mechanism.
Theorem 2 (Exponential Mechanism [37]). For a score function q : X∗ × R → R  deﬁne its
sensitivity as ∆(q) = maxr∈R D∼D(cid:48) |q(D  r) − q(D(cid:48)  r)|. For any q  input data set D  and privacy
parameter ε > 0  the exponential mechanism ME(D  q  ε) picks an outcome r ∈ R with probability
proportional to exp (εq(D  r)/(2∆(q))). This is ε-differentially private  and with probability at least
1 − β  selects an outcome r ∈ R such that q(D  r) ≥ maxr(cid:48)∈R q(D  r(cid:48)) − 2∆(q) log(|R|/β)

.

ε

3 A First Method for Private Hypothesis Selection

In this section  we present our ﬁrst algorithm for private hypothesis selection and obtain Theorem 1.
Note that the sample complexity bound above scales logarithmically with the size of the hypothesis
class. In Section 4  we will provide a stronger result (which subsumes the present one as a special
case) that can handle certain inﬁnite hypothesis classes. For sake of exposition  we begin in this
section with the basic algorithm.

3.1 Pairwise Comparisons

We ﬁrst present a subroutine which compares two hypothesis distributions. Let H and H(cid:48) be
two distributions over domain X and consider the following set  which is called the Scheffé set
W1 = {x ∈ X | H(x) > H(cid:48)(x)}. Deﬁne p1 = H(W1)  p2 = H(cid:48)(W1)  and τ = P (W1) to be

5

the probability masses that H  H(cid:48)  and P place on W1  respectively. It follows that p1 > p2 and
p1 − p2 = dTV(H  H(cid:48)).2
Algorithm 1: PAIRWISE CONTEST: PC(H  H(cid:48)  D  ζ  α)
Input: Two hypotheses H and H(cid:48)  input dataset D of size n drawn i.i.d. from target distribution
P   approximation parameter ζ > 0  and accuracy parameter α ∈ (0  1).
Initialize: Compute the fraction of points that fall into W1: ˆτ = 1
If p1 − p2 ≤ (2 + ζ)α  return “Draw”.
Else If ˆτ > p1 − (1 + ζ/2)α  return H as the winner.
Else If ˆτ < p2 + (1 + ζ/2)α  return H(cid:48) as the winner.
Else return “Draw”.

n |{x ∈ D | x ∈ W1}|.

Now consider the following function of this ordered pair of hypotheses:

(cid:26)n

Γζ(H  H(cid:48)  D) =

n · max{0  ˆτ − (p2 + (1 + ζ/2)α)}

if p1 − p2 ≤ (2 + ζ)α;
otherwise.

When the two hypotheses are sufﬁciently far apart (i.e.  dTV(H  H(cid:48)) > (2 + ζ)α)  Γζ(H  H(cid:48)  D) is
essentially the number of points one needs to change in D to make H(cid:48) the winner.
Lemma 1. Let P  H  H(cid:48) be distributions as above. With probability at least 1 − 2 exp(−nζ 2α2/8)
over the random draws of D from P n  ˆτ satisﬁes |ˆτ − τ| < ζα/4  and if dTV(P  H) ≤ α  then
Γζ(H  H(cid:48)  D) > ζαn/4.

least 1 −
Proof. By applying Hoeffding’s inequality  we know that with probability at
2 exp(−nζ 2α2/8)  |τ − ˆτ| < ζα/4. We condition on this event for the remainder of the proof.
Consider the following two cases. In the ﬁrst case  suppose that p1 − p2 ≤ (2 + ζ)α. Then we
know that Γζ(H  H(cid:48)  D) = n > αn. In the second case  suppose that p1 − p2 > (2 + ζ)α. Since
dTV(P  H) ≤ α  we know that |p1−τ| ≤ α  and so |p1− ˆτ| < (1+ζ/4)α. Since p1 > p2 +(2+ζ)α 
we also have ˆτ > p2 + (1 + 3ζ/4)α. It follows that Γζ(H  H(cid:48)  D) = n(ˆτ − (p2 + (1 + ζ/2)α)) >
ζαn/4. This completes the proof.

3.2 Selection via Exponential Mechanism

In light of the deﬁnition of the pairwise comparison deﬁned above  we consider the follow-
ing score function S : H × X n  such that for any Hj ∈ H and dataset D  S(Hj  D) =
minHk∈H Γζ(Hj  Hk  D). Roughly speaking  S(Hj  D) is the minimum number of points required
to change in D in order for Hj to lose at least one pairwise contest against a different hypothesis.
When the hypothesis Hj is very close to every other distribution  such that all pairwise contests return
“Draw ” then the score will be n.
Algorithm 2: PRIVATE HYPOTHESIS SELECTION: PHS(H  D  ε)
Input: Dataset D  a collection of hypotheses H = {H1  . . .   Hm}  privacy parameter ε.
Output a random hypothesis ˆH ∈ H such that for each Hj  Pr[ ˆH = Hj] ∝ exp
Lemma 2 (Privacy). For any ε > 0 and collection of hypotheses H  the algorithm PHS(H ·  ε)
satisﬁes ε-differential privacy.
Proof. First  observe that for any pairs of hypotheses Hj  Hk  Γζ(Hj  Hk ·) has sensitivity 1. As
a result  the score function S is also 1-sensitive. Then the result directly follows from the privacy
guarantee of the exponential mechanism (Theorem 2).
Lemma 3 (Utility). Fix any α  β ∈ (0  1)  and constant ζ > 0. Suppose that there exists H∗ ∈ H
such that dTV(P  H∗) ≤ α. Then with probability 1 − β over the sample D and the algorithm PHS 
2For simplicity of our exposition  we will assume that we can evaluate the two quantities p1 and p2 exactly.
In general  we can estimate these quantities to arbitrary accuracy  as long as  for each hypothesis H  we can
evaluate the density of each point under H and also draw samples from H.

(cid:16) S(Hj  D)

2ε

(cid:17)

.

6

we have that PHS(H  D) outputs an hypothesis ˆH such that dTV(P  ˆH) ≤ (3 + ζ)α  as long as the
sample size satisﬁes n ≥ 8 ln(4m/β)

ζ2α2 + 8 ln(2m/β)

ζαε

.

Proof. First  consider the m pairwise contests between H∗ and every candidate in H. Let Wj =
{x ∈ X | Hj(x) > H∗(x)} be the collection of Scheffé sets. For any event W ⊆ X   let ˆP (W )
denote the empirical probability of event W on the dataset D. By Lemma 1 and an application of the
union bound  we know that with probability at least 1 − 2m exp(−nζ 2α2/8) over the draws of D 
|P (Wj) − ˆP (Wj)| ≤ ζα/4 and Γζ(H∗  Hj  D) > ζαn/4 for all Hj ∈ H. In particular  the latter
event implies that S(H∗  D) > ζαn/4.
Next  by the utility guarantee of the exponential mechanism (Theorem 2)  we know that with
probability at least 1 − β/2  the output hypothesis satisﬁes S( ˆH  D) ≥ S(H∗  D) − 2 ln(2m/β)
>
ζαn/4 − 2 ln(2m/β)
  we know that with probability at
least 1− β  S( ˆH  D) > 0. Let us condition on this event  which implies that Γζ( ˆH  H∗  D) > 0. We
will now show that dTV( ˆH  H∗) ≤ (2 + ζ)α  which directly implies that dTV( ˆH  P ) ≤ (3 + ζ)α
by the triangle inequality. Suppose to the contrary that dTV( ˆH  H∗) > (2 + ζ)α. Then by the
deﬁnition of Γζ  ˆP ( ˆW) > H∗( ˆW) + (1 + ζ/2)α  where ˆW = {x ∈ X | ˆH(x) > H∗(x)}. Since
|P ( ˆW) − ˆP ( ˆW)| ≤ ζα/4  we have P ( ˆW) > H∗( ˆW) + (1 + ζ/4)α  which is a contradiction to the
assumption that dTV(P  H∗) ≤ α.

. Then as long as n ≥ 8 ln(4m/β)

ζ2α2 + 8 ln(2m/β)

ζαε

ε

ε

While Theorem 1 requires an upper bound α on the accuracy of the best hypothesis  the following
theorem obviates this need  at the cost of a mild increase in the sample complexity and a constant
factor in the accuracy of the output hypothesis.
Theorem 3. Let α  β  ε ∈ (0  1)  and ζ > 0 be a constant. Let H be a set of m distribu-
tions and let P be a distribution with dTV(P H) = OPT. There is an ε-differentially pri-
vate algorithm which takes as input n samples from P and with probability at least 1 − β 
outputs a distribution ˆH ∈ H with dTV(P  ˆH) ≤ 18(3 + ζ) OPT +α  as long as n ≥
O

(cid:16) log(m/β)+log log(1/α)

+ log m+log2(1/α)·(log(1/β)+log log(1/α))

(cid:17)

.

α2

αε

4 An Advanced Method for Private Hypothesis Selection

In Section 3  we provided a simple algorithm whose sample complexity grows logarithmically in the
size of the hypothesis class. We now demonstate that this dependence can be improved and  indeed 
we can handle inﬁnite hypothesis classes given that their VC dimension is ﬁnite and that the cover
has small doubling dimension.
To obtain this improved dependence on the hypothesis class size  we must make two improvements
to the analysis and algorithm. First  rather than applying a union bound over all the pairwise contests
to analyse the tournament  we use a uniform convergence bound in terms of the VC dimension of
the Scheffé sets. Second  rather than use the exponential mechanism to select a hypothesis  we
use a “GAP-MAX” algorithm [8]. This takes advantage of the fact that  in many cases  even for
inﬁnite hypothesis classes  only a handful of hypotheses will have high scores. The GAP-MAX
algorithm need only pay for the hypotheses that are close to optimal. To exploit this  we must
move to a relaxation of pure differential privacy which is not subject to strong packing lower
bounds (as we describe in the supplement). Speciﬁcally  we consider approximate differential privacy 
although results with an improved dependence are also possible under various variants of concentrated
differential privacy [27  11  38  8].
Theorem 4. Let H be a set of probability distributions on X . Let d be the VC dimension of the
: X → {0  1} deﬁned by fH H(cid:48)(x) = 1 ⇐⇒ H(x) > H(cid:48)(x) where
set of functions fH H(cid:48)
H  H(cid:48) ∈ H. There exists a (ε  δ)-differentially private algorithm which has following guarantee. Let
D = {X1  . . .   Xn} be a set of private samples drawn independently from an unknown probability
distribution P . Let k = |{H ∈ H : dTV(H  P ) ≤ 7α}|. Suppose there exists a distribution H∗ ∈
H such that dTV(P  H∗) ≤ α. If n = Ω
  then the
algorithm will output a distribution ˆH ∈ H such that dTV(P  ˆH) ≤ 7α with probability at least

+ log(k/β)+min{log |H| log(1/δ)}

(cid:16) d+log(1/β)

(cid:17)

α2

αε

7

1 − β. Alternatively  we can demand that the algorithm be 1

2 ε2-concentrated differentially private if

√

log |H|

(cid:19)

.

(cid:18)

n = Ω

d+log(1/β)

α2

+

log(k/β)+
αε

Comparing Theorem 4 to Theorem 1  we see that the ﬁrst (non-private) log |H| term is replaced by
the VC dimension d and the second (private) log |H| term is replaced by log k + log(1/δ). Here
k is a measure of the “local” size of the hypothesis class H; its deﬁnition is similar to that of the
doubling dimension of the hypothesis class under total variation distance. We note that the log(1/δ)
term could be large  as the privacy failure probability δ should be cryptographically small. Thus our
result includes statements for pure differential privacy (by using the other term in the minimum with
δ = 0) and also concentrated differential privacy. Note that  since d and log k can be upper-bounded
by O(log |H|)  this result supercedes the guarantees of Theorem 1.Further details and a proof of
correctness appear in the supplementary material.

5 Applications of Hypothesis Selection

In this section  we give a number of applications of Theorem 1  primarily to obtain sample complexity
bounds for learning a number of distribution classes of interest. Recall Corollary 1  which is an
immediate corollary of Theorem 1. This indicates that we can privately semi-agnostically learn a
class of distributions with a number of samples proportional to the log of its covering number.
We instantiate this corollary to give the sample complexity results for semi-agnostically learning
product distributions (Section 5.1)  Gaussian distributions (Section 5.2)  and mixtures (Section 5.3).
Additional applications and all proofs of correctness appear in the supplement.

5.1 Product Distributions

As a ﬁrst application  we give an ε-differentially private algorithm for learning product distributions.
Deﬁnition 5. A (k  d)-product distribution is a distribution over [k]d  such that its marginal distribu-
tions are independent (i.e.  the distribution is the product of its marginals).

We start by constructing a cover for product distributions.

Lemma 4. There exists an α-cover of the set of (k  d)-product distributions of size O(cid:0) kd

(cid:1)d(k−1).

α

With this cover in hand  applying Corollary 1 allows us to conclude the following sample complexity
upper bound.
Corollary 2. Suppose we are given a set of samples X1  . . .   Xn ∼ P   where P is α-close to a
(k  d)-product distribution. Then for any constant ζ > 0  there exists an ε-differentially private
algorithm which outputs a (k  d)-product distribution H∗ such that dTV(P  H∗) ≤ (6 + 2ζ)α with

probability ≥ 9/10  so long as n = Ω(cid:0)kd log(cid:0) kd

(cid:1)(cid:0) 1

(cid:1)(cid:1).

α2 + 1

αε

α

This gives the ﬁrst ˜O(d) sample algorithm for learning a binary product distribution in under
pure differential privacy  improving upon the work of Kamath  Li  Singhal  and Ullman [33] by
strengthening the privacy guarantee at a minimal cost in the sample complexity. The natural way to
adapt their result from concentrated to pure differential privacy would require Ω(d3/2) samples.
Remark 1. Properly learning a product distribution over {0  1}d to total variation distance ≤ 1
2
implies learning its mean µ ∈ [0  1]d up to (cid:96)1 error ≤ 2
d. Thus Corollary 2 implies a ε-differentially
private algorithm which takes n = ˜O(d/ε) samples from a product distribution P on {0  1}d and 
√
with high probability  outputs an estimate ˆµ of its mean µ with (cid:107)ˆµ − µ(cid:107)1 ≤ 2
d. In contrast  for
non-product distributions over the hypercube  estimating the mean to the same accuracy under ε-
differential privacy requires n = Ω(d3/2/ε) samples [30  41]. Thus we have a polynomial separation
between estimating product and non-product distributions under pure differential privacy.

√

5.2 Gaussian Distributions

We next give private algorithms for learning Gaussian distributions. We discuss covers for Gaussian
distributions with known and unknown covariance.

8

Lemma 5. There exists an α-cover of the set of Gaussian distributions N (µ  Σ) in d-dimensions

with (cid:107)µ(cid:107)2 ≤ R and I (cid:22) Σ (cid:22) κI of size O(cid:0) dR

(cid:1)d · O(cid:0) dκ

(cid:1)d(d+1)/2. If Σ = I  the size is O(cid:0) dR

(cid:1)d.

α

α

α

In addition  we can obtain bounds of the VC dimension of the Scheffé sets of Gaussian distributions.
Lemma 6 ([5]). The set of Gaussian distributions with ﬁxed variance – i.e.  all N (µ  I) with µ ∈ Rd
– has VC dimension d + 1. Furthermore  the set of Gaussians with unknown variance – i.e.  all
N (µ  Σ) with µ ∈ Rd and Σ ∈ Rd×d positive deﬁnite – has VC dimension O(d2).
Combining the covers of Lemma 5 and the VC bound of Lemma 6 with Theorem 4 implies the
following corollaries for Gaussian estimation.
Corollary 3. Suppose we are given a set of samples X1  . . .   Xn ∼ P   where P is α-close to a Gaus-
sian distribution N (µ  Σ) in d-dimensions with (cid:107)µ(cid:107) ≤ R. Then for any constant ζ > 0  there exists an
ε-differentially private algorithm which outputs a Gaussian distribution H∗ such that dTV(P  H∗) ≤

(6 + 2ζ)α with probability ≥ 9/10. If Σ = I  the algorithm requires that n = Ω(cid:0) d
(cid:1)(cid:1)(cid:17)

αε log(cid:0) dR

If I (cid:22) Σ (cid:22) κI  it requires that n = Ω

(cid:1) + d2 log(cid:0) dκ

(cid:0)d log(cid:0) dR

(cid:16) d2

(cid:1)(cid:1).

α2 + d

α

.

α2 + 1

αε

α

α

Similar to the product distribution case  these are the ﬁrst ˜O(d) and ˜O(d2) sample algorithms for
learning Gaussians total variation distance under pure differential privacy  improving upon the
concentrated differential privacy results of Kamath  Li  Singhal  and Ullman [33].

5.2.1 Gaussians with Unbounded Mean

Extending Corollary 3  we consider multivariate Gaussian hypotheses with known covariance and
unknown mean  without a bound on the mean (the parameter R above). This requires relaxation to
approximate differential privacy. In place of Lemma 5  we construct a locally small cover:
Lemma 7. For any d ∈ N and α ∈ (0  1/30]  there exists an α-cover Cα of the set of d-dimensional
Gaussian distributions N (µ  I) satisfying ∀µ ∈ Rd |{H ∈ Cα : dTV(H N (µ  I)) ≤ 7α}| ≤ 215d.
Applying Theorem 4 with the cover of Lemma 7 and the VC bound from Lemma 6 gives:
Corollary 4. Suppose we are given a set of samples X1  . . .   Xn ∼ P   where P is a spherical
Gaussian distribution N (µ  I) in d-dimensions. Then there exists a (ε  δ)-differentially private
algorithm which outputs a spherical Gaussian distribution H∗ such that dTV(P  H∗) ≤ 7α with
probability ≥ 1 − 2−d  so long as n = Ω

(cid:16) d

(cid:17)

.

α2 + d+log(1/δ)

αε

(cid:16) d

Karwa and Vadhan [35] give an algorithm for estimating a univariate Gaussian with unbounded
mean  which can be applied independently to the d coordinates to get a sample complexity bound of
˜O

. Our bound dominates this except for very small values of α.

d log3/2(1/δ)

√

α2 + d

αε +

ε

(cid:17)

5.3 Mixtures

In this section  we show that our results extend to learning mixtures of classes of distributions.
Deﬁnition 6. Let H be some set of distributions. A k-mixture of H is a distribution with density

(cid:80)k
i=1 wiPi  where each Pi ∈ H.

Our results follow roughly due to the fact that a cover for k-mixtures of a class can be written as the
Cartesian product of k covers for the class  and then an application of Corollary 1.
Lemma 8. Consider the class of k-mixtures of H  where H is some set of distributions. There exists

2α + 1(cid:1)k−1  where Cα is an α-cover of H.

Corollary 5. Let X1  . . .   Xn ∼ P   where P is α-close to a k-mixture of distributions from some
set H. Let Cα be an α-cover of the set H  and ζ > 0 be a constant. There exists an ε-differentially
private algorithm which outputs a distribution which is (9 + 3ζ)α-close to P with probability ≥ 9/10 

a 2α-cover of this class of size |Cα|k(cid:0) k
as long as n = Ω(cid:0)(k log |Cα| + k log(k/α))(cid:0) 1

α2 + 1

αε

For example  instantiating this for mixtures of Gaussians (and disregarding terms which depend on R
and κ)  we get an algorithm with sample complexity ˜O

.

α2 + kd2

αε

(cid:1)(cid:1).
(cid:16) kd2

(cid:17)

9

Acknowledgments

The authors would like to thank Shay Moran for bringing to their attention the application to PAC
learning mentioned in the supplement  Jonathan Ullman for asking questions which motivated
Remark 1  and Clément Canonne for assistance in reducing the constant factor in the approximation
guarantee. This work was done while the authors were all afﬁliated the Simons Institute for the Theory
of Computing. MB was supported by a Google Research Fellowship  as part of the Simons-Berkeley
Research Fellowship program. GK was supported by a Microsoft Research Fellowship  as part of the
Simons-Berkeley Research Fellowship program  and the work was also partially done while visiting
Microsoft Research  Redmond. TS was supported by a Patrick J. McGovern Research Fellowship  as
part of the Simons-Berkeley Research Fellowship program. ZSW was supported in part by a Google
Faculty Research Award  a J.P. Morgan Faculty Award  and a Facebook Research Award.

References
[1] Jayadev Acharya  Moein Falahatgar  Ashkan Jafarpour  Alon Orlitsky  and Ananda Theertha
Suresh. Maximum selection and sorting with adversarial comparators. Journal of Machine
Learning Research  19(1):2427–2457  2018.

[2] Jayadev Acharya  Ashkan Jafarpour  Alon Orlitsky  and Ananda Theertha Suresh. Sorting with
adversarial comparators and application to density estimation. In Proceedings of the 2014 IEEE
International Symposium on Information Theory  ISIT ’14  pages 1682–1686  Washington  DC 
USA  2014. IEEE Computer Society.

[3] Jayadev Acharya  Gautam Kamath  Ziteng Sun  and Huanyu Zhang.

Inspectre: Privately
In Proceedings of the 35th International Conference on Machine

estimating the unseen.
Learning  ICML ’18  pages 30–39. JMLR  Inc.  2018.

[4] Jayadev Acharya  Ziteng Sun  and Huanyu Zhang. Hadamard response: Estimating distributions
privately  efﬁciently  and with little communication. In Proceedings of the 22nd International
Conference on Artiﬁcial Intelligence and Statistics  AISTATS ’19  pages 1120–1129. JMLR 
Inc.  2019.

[5] Martin Anthony. Classiﬁcation by polynomial surfaces. Discrete Applied Mathematics  61(2):91–

103  1995.

[6] Avrim Blum  Cynthia Dwork  Frank McSherry  and Kobbi Nissim. Practical privacy: The
SuLQ framework. In Proceedings of the 24th ACM SIGMOD-SIGACT-SIGART Symposium on
Principles of Database Systems  PODS ’05  pages 128–138  New York  NY  USA  2005. ACM.

[7] Olivier Bousquet  Daniel M. Kane  and Shay Moran. The optimal approximation factor in
density estimation. In Proceedings of the 32nd Annual Conference on Learning Theory  COLT
’19  pages 318–341  2019.

[8] Mark Bun  Cynthia Dwork  Guy N. Rothblum  and Thomas Steinke. Composable and versatile
privacy via truncated cdp. In Proceedings of the 50th Annual ACM Symposium on the Theory of
Computing  STOC ’18  pages 74–86  New York  NY  USA  2018. ACM.

[9] Mark Bun  Gautam Kamath  Thomas Steinke  and Zhiwei Steven Wu. Private hypothesis

selection. arXiv preprint arXiv:1905.13229  2019.

[10] Mark Bun  Kobbi Nissim  Uri Stemmer  and Salil Vadhan. Differentially private release and
In Proceedings of the 56th Annual IEEE Symposium on
learning of threshold functions.
Foundations of Computer Science  FOCS ’15  pages 634–649  Washington  DC  USA  2015.
IEEE Computer Society.

[11] Mark Bun and Thomas Steinke. Concentrated differential privacy: Simpliﬁcations  extensions 
and lower bounds. In Proceedings of the 14th Conference on Theory of Cryptography  TCC
’16-B  pages 635–658  Berlin  Heidelberg  2016. Springer.

[12] Mark Bun  Jonathan Ullman  and Salil Vadhan. Fingerprinting codes and the price of approxi-
mate differential privacy. In Proceedings of the 46th Annual ACM Symposium on the Theory of
Computing  STOC ’14  pages 1–10  New York  NY  USA  2014. ACM.

10

[13] T. Tony Cai  Yichen Wang  and Linjun Zhang. The cost of privacy: Optimal rates of convergence

for parameter estimation with differential privacy. arXiv preprint arXiv:1902.04495  2019.

[14] Aref N. Dajani  Amy D. Lauger  Phyllis E. Singer  Daniel Kifer  Jerome P. Reiter  Ashwin
Machanavajjhala  Simson L. Garﬁnkel  Scot A. Dahl  Matthew Graham  Vishesh Karwa  Hang
Kim  Philip Lelerc  Ian M. Schmutte  William N. Sexton  Lars Vilhuber  and John M. Abowd.
The modernization of statistical disclosure limitation at the U.S. census bureau  2017. Presented
at the September 2017 meeting of the Census Scientiﬁc Advisory Committee.

[15] Constantinos Daskalakis  Ilias Diakonikolas  and Rocco A. Servedio. Learning Poisson binomial
distributions. In Proceedings of the 44th Annual ACM Symposium on the Theory of Computing 
STOC ’12  pages 709–728  New York  NY  USA  2012. ACM.

[16] Constantinos Daskalakis and Gautam Kamath. Faster and sample near-optimal algorithms
for proper learning mixtures of Gaussians. In Proceedings of the 27th Annual Conference on
Learning Theory  COLT ’14  pages 1183–1213  2014.

[17] Luc Devroye and Gábor Lugosi. A universally acceptable smoothing factor for kernel density

estimation. The Annals of Statistics  24(6):2499–2512  1996.

[18] Luc Devroye and Gábor Lugosi. Nonasymptotic universal smoothing factors  kernel complexity

and Yatracos classes. The Annals of Statistics  25(6):2626–2637  1997.

[19] Luc Devroye and Gábor Lugosi. Combinatorial methods in density estimation. Springer  2001.

[20] Ilias Diakonikolas  Moritz Hardt  and Ludwig Schmidt. Differentially private learning of
structured discrete distributions. In Advances in Neural Information Processing Systems 28 
NIPS ’15  pages 2566–2574. Curran Associates  Inc.  2015.

[21] Ilias Diakonikolas  Gautam Kamath  Daniel M. Kane  Jerry Li  Ankur Moitra  and Alistair
Stewart. Robust estimators in high dimensions without the computational intractability. In
Proceedings of the 57th Annual IEEE Symposium on Foundations of Computer Science  FOCS
’16  pages 655–664  Washington  DC  USA  2016. IEEE Computer Society.

[22] Differential Privacy Team  Apple.

//machinelearning.apple.com/docs/learning-with-privacy-at-scale/
appledifferentialprivacysystem.pdf  December 2017.

Learning with privacy at

scale.

https:

[23] John C. Duchi  Michael I. Jordan  and Martin J. Wainwright. Local privacy and statistical
minimax rates. In Proceedings of the 54th Annual IEEE Symposium on Foundations of Computer
Science  FOCS ’13  pages 429–438  Washington  DC  USA  2013. IEEE Computer Society.

[24] John C. Duchi and Feng Ruan. The right complexity measure in locally private estimation: It is

not the ﬁsher information. arXiv preprint arXiv:1806.05756  2018.

[25] Cynthia Dwork and Jing Lei. Differential privacy and robust statistics. In Proceedings of the
41st Annual ACM Symposium on the Theory of Computing  STOC ’09  pages 371–380  New
York  NY  USA  2009. ACM.

[26] Cynthia Dwork  Frank McSherry  Kobbi Nissim  and Adam Smith. Calibrating noise to sensi-
tivity in private data analysis. In Proceedings of the 3rd Conference on Theory of Cryptography 
TCC ’06  pages 265–284  Berlin  Heidelberg  2006. Springer.

[27] Cynthia Dwork and Guy N. Rothblum. Concentrated differential privacy. arXiv preprint

arXiv:1603.01887  2016.

[28] Úlfar Erlingsson  Vasyl Pihur  and Aleksandra Korolova. RAPPOR: Randomized aggregatable
privacy-preserving ordinal response. In Proceedings of the 2014 ACM Conference on Computer
and Communications Security  CCS ’14  pages 1054–1067  New York  NY  USA  2014. ACM.

[29] Marco Gaboardi  Ryan Rogers  and Or Sheffet. Locally private conﬁdence intervals: Z-test and
tight conﬁdence intervals. In Proceedings of the 22nd International Conference on Artiﬁcial
Intelligence and Statistics  AISTATS ’19  pages 2545–2554. JMLR  Inc.  2019.

11

[30] Moritz Hardt and Kunal Talwar. On the geometry of differential privacy. In Proceedings of the
42nd Annual ACM Symposium on the Theory of Computing  STOC ’10  pages 705–714  New
York  NY  USA  2010. ACM.

[31] Matthew Joseph  Janardhan Kulkarni  Jieming Mao  and Zhiwei Steven Wu. Locally private

Gaussian estimation. arXiv preprint arXiv:1811.08382  2018.

[32] Peter Kairouz  Keith Bonawitz  and Daniel Ramage. Discrete distribution estimation under
local privacy. In Proceedings of the 33rd International Conference on Machine Learning  ICML
’16  pages 2436–2444. JMLR  Inc.  2016.

[33] Gautam Kamath  Jerry Li  Vikrant Singhal  and Jonathan Ullman. Privately learning high-
dimensional distributions. In Proceedings of the 32nd Annual Conference on Learning Theory 
COLT ’19  pages 1853–1902  2019.

[34] Gautam Kamath  Or Sheffet  Vikrant Singhal  and Jonathan Ullman. Differentially private
algorithms for learning mixtures of separated gaussians. In Advances in Neural Information
Processing Systems 32  NeurIPS ’19. Curran Associates  Inc.  2019.

[35] Vishesh Karwa and Salil Vadhan. Finite sample differentially private conﬁdence intervals. In
Proceedings of the 9th Conference on Innovations in Theoretical Computer Science  ITCS ’18 
pages 44:1–44:9  Dagstuhl  Germany  2018. Schloss Dagstuhl–Leibniz-Zentrum fuer Informatik.
[36] Satyaki Mahalanabis and Daniel Stefankovic. Density estimation in linear time. In Proceedings

of the 21st Annual Conference on Learning Theory  COLT ’08  pages 503–512  2008.

[37] Frank McSherry and Kunal Talwar. Mechanism design via differential privacy. In Proceedings
of the 48th Annual IEEE Symposium on Foundations of Computer Science  FOCS ’07  pages
94–103  Washington  DC  USA  2007. IEEE Computer Society.

[38] Ilya Mironov. Rényi differential privacy. In Proceedings of the 30th IEEE Computer Secu-
rity Foundations Symposium  CSF ’17  pages 263–275  Washington  DC  USA  2017. IEEE
Computer Society.

[39] Kobbi Nissim  Sofya Raskhodnikova  and Adam Smith. Smooth sensitivity and sampling in
private data analysis. In Proceedings of the 39th Annual ACM Symposium on the Theory of
Computing  STOC ’07  pages 75–84  New York  NY  USA  2007. ACM.

[40] Adam Smith. Privacy-preserving statistical estimation with optimal convergence rates. In
Proceedings of the 43rd Annual ACM Symposium on the Theory of Computing  STOC ’11 
pages 813–822  New York  NY  USA  2011. ACM.

[41] Thomas Steinke and Jonathan Ullman. Interactive ﬁngerprinting codes and the hardness of
preventing false discovery. In Proceedings of the 28th Annual Conference on Learning Theory 
COLT ’15  pages 1588–1628  2015.

[42] Thomas Steinke and Jonathan Ullman. Between pure and approximate differential privacy. The

Journal of Privacy and Conﬁdentiality  7(2):3–22  2017.

[43] Ananda Theertha Suresh  Alon Orlitsky  Jayadev Acharya  and Ashkan Jafarpour. Near-
optimal-sample estimators for spherical Gaussian mixtures. In Advances in Neural Information
Processing Systems 27  NIPS ’14  pages 1395–1403. Curran Associates  Inc.  2014.

[44] Abhradeep Guha Thakurta and Adam Smith. Differentially private feature selection via stability
arguments  and the robustness of the lasso. In Proceedings of the 26th Annual Conference on
Learning Theory  COLT ’13  pages 819–850  2013.

[45] Shaowei Wang  Liusheng Huang  Pengzhan Wang  Yiwen Nie  Hongli Xu  Wei Yang  Xiang-
Yang Li  and Chunming Qiao. Mutual information optimally local private discrete distribution
estimation. arXiv preprint arXiv:1607.08025  2016.

[46] Yannis G. Yatracos. Rates of convergence of minimum distance estimators and Kolmogorov’s

entropy. The Annals of Statistics  13(2):768–774  1985.

[47] Min Ye and Alexander Barg. Optimal schemes for discrete distribution estimation under locally

differential privacy. IEEE Transactions on Information Theory  64(8):5662–5676  2018.

12

,Ayan Chakrabarti
Mark Bun
Gautam Kamath
Thomas Steinke
Steven Wu