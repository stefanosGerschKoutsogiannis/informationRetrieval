2014,Sensory Integration and Density Estimation,The integration of partially redundant information from multiple sensors is a standard computational problem for agents interacting with the world. In man and other primates  integration has been shown psychophysically to be nearly optimal in the sense of error minimization. An influential generalization of this notion of optimality is that populations of multisensory neurons should retain all the information from their unisensory afferents about the underlying  common stimulus [1]. More recently  it was shown empirically that a neural network trained to perform latent-variable density estimation  with the activities of the unisensory neurons as observed data  satisfies the information-preservation criterion  even though the model architecture was not designed to match the true generative process for the data [2]. We prove here an analytical connection between these seemingly different tasks  density estimation and sensory integration; that the former implies the latter for the model used in [2]; but that this does not appear to be true for all models.,Sensory Integration and Density Estimation

Joseph G. Makin and Philip N. Sabes

Center for Integrative Neuroscience/Department of Physiology

University of California  San Francisco

San Francisco  CA 94143-0444 USA
makin  sabes @phy.ucsf.edu

Abstract

The integration of partially redundant information from multiple sensors is a stan-
dard computational problem for agents interacting with the world. In man and
other primates  integration has been shown psychophysically to be nearly optimal
in the sense of error minimization. An inﬂuential generalization of this notion
of optimality is that populations of multisensory neurons should retain all the in-
formation from their unisensory afferents about the underlying  common stimu-
lus [1]. More recently  it was shown empirically that a neural network trained
to perform latent-variable density estimation  with the activities of the unisensory
neurons as observed data  satisﬁes the information-preservation criterion  even
though the model architecture was not designed to match the true generative pro-
cess for the data [2]. We prove here an analytical connection between these seem-
ingly different tasks  density estimation and sensory integration; that the former
implies the latter for the model used in [2]; but that this does not appear to be true
for all models.

1

Introduction

A sensible criterion for integration of partially redundant information from multiple senses is that
no information about the underlying cause be lost. That is  the multisensory representation should
contain all of the information about the stimulus as the unisensory representations together did. A
variant on this criterion was ﬁrst proposed in [1]. When satisﬁed  and given sensory cues that have
been corrupted with Gaussian noise  the most probable multisensory estimate of the underlying
stimulus property (height  location  etc.) will be a convex combination of the estimates derived inde-
pendently from the unisensory cues  with the weights determined by the variances of the corrupting
noise—as observed psychophysically in monkey and man  e.g.  [3  4].
The task of plastic organisms placed in novel environments is to learn  from scratch  how to perform
this task. One recent proposal [2] is that primates treat the activities of the unisensory populations
of neurons as observed data for a latent-variable density-estimation problem. Thus the activities
of a population of multisensory neurons play the role of latent variables  and the model is trained
to generate the same distribution of unisensory activities when they are driven by the multisensory
neurons as when they are driven by their true causes in the world. The idea is that the latent variables
in the model will therefore come to correspond (in some way) to the latent variables that truly
underlie the observed distribution of unisensory activities  including the structure of correlations
across populations. Then it is plausible to suppose that  for any particular value of the stimulus 
inference to the latent variables of the model is “as good as” inference to the true latent cause 
and that therefore the information criterion will be satisﬁed. Makin et alia showed precisely this 
empirically  using an exponential-family harmonium (a generalization of the restricted Boltzmann
machine [5]) as the density estimator [2].

1

Here we prove analytically that successful density estimation in certain models  including that of [2] 
will necessarily satisfy the information-retention criterion. In variant architectures  the guarantee
does not hold.

2 Theoretical background

2.1 Multisensory integration and information retention

Psychophysical studies have shown that  when presented with cues of varying reliability in two
different sense modalities but about a common stimulus property (e.g.  location or height)  pri-
mates (including humans) estimate the property as a convex combination of the estimates derived
independently from the unisensory cues  where the weight on each estimate is proportional to its
reliability [3  4]. Cue reliability is measured as the inverse variance in performance across repeated
instances of the unisensory cue  and will itself vary with the amount of corrupting noise (e.g.  visu-
ally blur) added to the cue. This integration rule is optimal in that it minimizes error variance across
trials  at least for Gaussian corrupting noise.
Alternatively  it can be seen as a special case of a more general scheme [6]. Assuming a uniform
prior distribution of stimuli  the optimal combination just described is equal to the peak of the
posterior distribution over the stimulus  conditioned on the noisy cues (y1  y2):

x∗ = argmax

Pr[X = x|y1  y2].

x

For Gaussian corrupting noise  this posterior distribution will itself be Gaussian; but even for in-
tegration problems that yield non-Gaussian posteriors  humans have been shown to estimate the
stimulus with the peak of that posterior [7].
This can be seen as a consequence of a scheme more general still  namely  encoding not merely
the peak of the posterior  but the entire distribution [1  8]. Suppose again  for simplicity  that
Pr[X|Y 1  Y 2] is Gaussian. Then if x∗ is itself to be combined with some third cue (y3)  opti-
mality requires keeping the variance of this posterior  as well as its mean  since it (along with the
reliability of y3) determines the weight given to x∗ in this new combination. This scheme is espe-
cially relevant when y1 and y2 are not “cues” but the activities of populations of neurons  e.g. visual
and auditory  respectively. Since sensory information is more likely to be integrated in the brain in
a staged  hierarchical fashion than in a single common pool [9]  optimality requires encoding at
least the ﬁrst two cumulants of the posterior distribution. For more general  non-Gaussian posteri-
ors  the entire posterior should be encoded [1  6]. This amounts [1] to requiring  for downstream 
“multisensory” neurons with activities Z  that:

Pr[X|Z] = Pr[X|Y 1  Y 2].

When information about X reaches Z only via Y = [Y 1  Y 2] (i.e.  X → Y → Z forms a Markov
chain)  this is equivalent (see Appendix) to requiring that no information about the stimulus be lost
in transforming the unisensory representations into a multisensory representation; that is 

I(X; Z) = I(X; Y) 
where I(A; B) is the mutual information between A and B.
Of course  if there is any noise in the transition from unisensory to multisensory neurons  this equa-
tion cannot be satisﬁed exactly. A sensible modiﬁcation is to require that this noise be the only
source of information loss. This amounts to requiring that the information equality hold  not for Z 
but for any set of sufﬁcient statistics for Z as a function of Y  Tz (Y); that is 

I(X; Tz (Y)) = I(X; Y).

(1)

2.2

Information retention and density estimation

A rather general statement of the role of neural sensory processing  sometimes credited to
Helmholtz  is to make inferences about states of affairs in the world  given only the data supplied
by the sense organs. Inference is hard because the mapping from the world’s states to sense data is

2

X

p(x)

Y

p(y|x)

A

Y

q(y|z)

Z

q(z)

B

Figure 1: Probabilistic graphical models.
process. Observed nodes are shaded. After training the model (q)  the marginals match: p(y) = q(y).

(A) The world’s generative process. (B) The model’s generative

not invertible  due both to noise and to the non-injectivity of physical processes (as in occlusion). A
powerful approach to this problem used in machine learning  and arguably by the brain [10  11]  is
to build a generative model for the data (Y)  including the inﬂuence of unobserved (latent) variables
(Z). The latent variables at the top of a hierarchy of such models would presumably be proxies for
the true causes  states of affairs in the world (X).
In density estimation  however  the objective function for learning the parameters of the model is
that:

(cid:90)

(cid:90)

p(y|x)p(x)dx =

q(y|z)q(z)dz

(2)

x

z

(Fig. 1)  i.e.  that the “data distribution” of Y match the “model distribution” of Y; and this is
consistent with models that throw away information about the world in the transformation from
observed to latent variables  or even to their sufﬁcient statistics. For example  suppose that the
world’s generative process looked like this:
Example 2.1. The prior p(x) is the ﬂip of an unbiased coin; and the emission p(y|x) draws from
a standard normal distribution  takes the absolute value of the result  and then multiplies by −1 for
tails and +1 for heads. Information about the state of X is therefore perfectly represented in Y . But
a trained density-estimation model with  say  a Gaussian emission model  q(y|z)  would not bother
to encode any information in Z  since the emission model alone can represent all the data (which
just look like samples from a standard normal distribution). Thus Y and Z would be independent 
and Eq. 1 would not be satisﬁed  even though Eq. 2 would.

This case is arguably pathological  but similar considerations apply for more subtle variants. In
addition to Eq. 2  then  we shall assume something more: namely  that the “noise models” for the
world and model match; i.e.  that q(y|z) has the same functional form as p(y|x). More precisely 
we assume:

∃ functions f (y; λ)  φ(x)  ψ(z) (cid:51)

p(y|x) = f(cid:0)y; φ(x)(cid:1) 
q(y|z) = f(cid:0)y; ψ(z)(cid:1).

(3)

In [2]  for example  f (y; λ) was assumed to be a product of Poisson distributions  so the “proximate
causes” Λ were a vector of means. Note that the functions φ(x) and ψ(z) induce distributions over
Λ which we shall call p(λ) and q(λ)  respectively; and that:

Ep(λ)[f (y; λ)] = Ep(x)[f (y; φ(x)] = Eq(z)[f (y; ψ(z)] = Eq(λ)[f (y; λ)] 

(4)
where the ﬁrst and last equalities follows from the “law of the unconscious statistician ” and the
second follows from Eqs. 2 and 3.

3 Latent-variable density estimation for multisensory integration

In its most general form  the aim is to show that Eq. 4 implies  perhaps with some other constraints 
Eq. 1. More concretely  suppose the random variables Y 1  Y 2  provided by sense modalities 1 and
2  correspond to noisy observations of an underlying stimulus. These could be noisy cues  but they
could also be the activities of populations of neurons (visual and proprioceptive  say  for concrete-
ness). Then suppose a latent-variable density estimator is trained on these data  until it assigns the
same probability  q(y1  y2)  to realizations of the observations  [y1  y2]  as that with which they
appear  p(y1  y2). Then we should like to know that inference to the latent variables in the model 
i.e.  computation of the sufﬁcient statistics Tz(Y 1  Y 2)  throws away no information about the

3

stimulus. In [2]  where this was shown empirically  the density estimator was a neural network  and
its latent variables were interpreted as the activities of downstream  multisensory neurons. Thus the
transformation from unisensory to multisensory representation was shown  after training  to obey
this information-retention criterion.
It might seem that we have already assembled sufﬁcient conditions.
In particular  knowing that
the “noise models match ” Eq. 3  might seem to guarantee that the data distribution and model
distribution have the same sufﬁcient statistics  since sufﬁcient statistics depend only on the form of
the conditional distribution. Then Tz (Y) would be sufﬁcient for X as well as for Z  and the proof
complete. But this sense of “form of the conditional distribution” is stronger than Eq. 4. If  for
example  the image of z under ψ(·) is lower-dimensional than the image of x under φ(·)  then the
conditionals in Eq. 3 will have different forms as far as their sufﬁcient statistics go. An example will
clarify the point.
Example 3.1. Let p(y) be a two-component mixture of a (univariate) Bernoulli distribution. In
particular  let φ(x) and ψ(z) be the identity maps  Λ provide the mean of the Bernoulli  and p(X =
0.4) = 1/2  p(X = 0.6) = 1/2. The mixture marginal is therefore another Bernoulli random
variable  with equal probability of being 1 or 0. Now consider the “mixture” model q that has the
same noise model  i.e.  a univariate Bernoulli distribution  but a prior with all its mass at a single
mixing weight. If q(Z = 0.5) = 1  this model will satisfy Eq. 4. But a (minimal) sufﬁcient statistic
for the latent variables under p is simply the single sample  y  whereas the minimal sufﬁcient statistic
for the latent variable under q is the nullset: the observation tells us nothing about Z because it is
always the same value.

To rule out such cases  we propose (below) further constraints.

3.1 Proof strategy

We start by noting that any sufﬁcient statistics Tz(Y) for Z are also sufﬁcient statistics for any
function of Z  since all the information about the output of that function must pass through Z ﬁrst
(Fig. 2A). In particular  then  Tz(Y) are sufﬁcient statistics for the proximate causes  Λ = ψ(Z).
That is  for any λ generated by the model  Fig. 1B  tz (y) for the corresponding y drawn from
f (y; λ) are sufﬁcient statistics. What about the λ generated by the world  Fig. 1A? We should like
to show that tz(y) are sufﬁcient for them as well. This will be the case if  for every λ produced by
the world  there exists a vector z such that ψ(z) = λ.
This minimal condition is hard to prove. Instead we might show a slightly stronger condition  that
(q(λ) = 0) =⇒ (p(λ) = 0)  i.e.  to any λ that can be generated by the world  the model
assigns nonzero probability. This is sufﬁcient (although unnecessary) for the existence of a vector
z for every λ produced by the world. Or we might pursue a stronger condition still  that to any
λ that can be generated by the world  the model and data assign the same probability: q(λ) =
p(λ). If one considers the marginals p(y) = q(y) to be mixture models  then this last condition
is called the “identiﬁability” of the mixture [12]  and for many conditional distributions f (y; λ) 
identiﬁability conditions have been proven. Note that mixture identiﬁability is taken to be a property
of the conditional distribution  f (y; λ)  not the marginal  p(y); so  e.g.  without further restriction 
a mixture model is not identiﬁable even if there exist just two prior distributions  p1(λ)  p2(λ)  that
produce identical marginal distributions.
To see that identiﬁability  although sufﬁcient (see below) is unnecessary  consider again the two-
component mixture of a (univariate) Bernoulli distribution:
Example 3.2. Let p(X = 0.4) = 1/2  p(X = 0.6) = 1/2. If the model  q(y|z)q(z)  has the
same form  but mixing weights q(Z = 0.3) = 1/2  q(Z = 0.7) = 1/2  its mixture marginal will
match the data distribution; yet p(λ) (cid:54)= q(λ)  so the model is clearly unidentiﬁable. Nevertheless 
the sample itself  y  is a (minimal) sufﬁcient statistic for both the model and the data distribution  so
the information-retention criterion will be satisﬁed.

In what follows we shall assume that the mixtures are ﬁnite. This is the case when the model is an
exponential-family harmonium (EFH)1  as in [2]: there are at most K := 2|hiddens| mixture compo-
1An EFH is a two layer Markov random ﬁeld  with full interlayer connectivity and no intralayer connectiv-
ity  and in which the conditional distributions of the visible layer given the hiddens and vice versa belong to

4

H[Y]

H[Y]

H[Tz(Y)]

H[ψ(Z)]

H[Z]

H[X]

H[φ(X)]

H[ψ(Z)]

H[Z]

A

H[Tz (Y)]

B

(A) ψ(Z) being a deterministic function of Z  its entropy (dark
Figure 2: Venn diagrams for information.
turquoise) is a subset of the latter’s (turquoise). The same is true for the entropies of Tz (Y) (dark orange) and
Y (orange)  but additionally their intersections with H[Z] are identical because Tz is a sufﬁcient statistic for
Z. The mutual information values I(ψ(Z); Y) and I(ψ(Z); Tz (Y)) (i.e.  the intersections of the entropies)
are clearly identical (outlined patch). This corresponds to the derivation of Eq. 6. (B) When ψ(Z) is a sufﬁcient
statistic for Y  as guaranteed by Eq. 3  the intersection of its entropy with H[Y] is the same as the intersection
of H[Z] with H[Y]; likewise for H[φ(X)] and H[X] with H[Y]. Since all information about X reaches Z
via Y  the entropies of X and Z overlap only on H[Y]. Finally  if p(φ(x)) = q(ψ(z))  and Pr[Y|φ(X)] =
Pr[Y|ψ(Z)] (Eq. 3)  then the entropies of φ(X) and ψ(Z) have the same-sized overlaps (but not the same
overlaps) with H[Y] and H[Tz (Y)]. This guarantees that I(X; Tz (Y)) = I(X; Y) (see Eq. 7).

nents. It is not true for real-valued stimuli X. For simplicity  we shall nevertheless assume that there
are at most 2|hiddens| conﬁgurations of X since: (1) the stimulus must be discretized immediately
upon transduction by the nervous system  the brain (presumably) having only ﬁnite representational
capacity; and (2) if there were an inﬁnite number of conﬁgurations  Eq. 2 could not be satisﬁed
exactly anyway. Eq. 4 can therefore be expressed as:

I(cid:88)

J(cid:88)

f (y; λ)p(λ) =

f (y; λ)q(λ) 

(5)

where I ≤ K  J ≤ K.

i

j

3.2 Formal description of the model  assumptions  and result

• The general probabilistic model. This is given by the graphical models in Fig. 1. “The
world” generates data according to Fig. 1A (“data distribution”)  and “the brain” uses Fig.
1B. None of the distributions labeled in the diagram need be equal to each other  and in fact
X and Z may have different support.

• The assumptions.

1. The noise models “match”: Eq. 3.
2. The number of hidden-variable states is ﬁnite  but otherwise arbitrarily large.
3. Density estimation has been successful; i.e.  the data and model marginals over Y

match: Eq. 2

p(λ) = q(λ). This condition holds for a very broad class of distributions.

4. The noise model/conditional distribution f (y; λ) is identiﬁable: if p(y) = q(y)  then
• The main result. Information about the stimulus is retained in inferring the latent variables
of the model  i.e. in the “feedforward” (Y → Z) pass of the model. More precisely 
information loss is due only to noise in the hidden layer (which is unavoidable)  not to a
failure of the inference procedure: Eq. 1.

More succinctly: for identiﬁable mixture models  Eq. 5 and Eq. 3 together imply Eq. 1.

exponential families of probability distributions [5]. The restricted Boltzmann machine is therefore the special
case of Bernoulli hiddens and Bernoulli visibles.

5

3.3 Proof

First  for any set of sufﬁcient statistics Tz (Y) for Z:

I(Y; ψ(Z)|Tz(Y)) ≤ I(Y; Z|Tz (Y))

= 0

=⇒ 0 = I(Y; ψ(Z)|Tz(Y))

= H[ψ(Z)|Tz(Y)] − H[ψ(Z)|Y  Tz(Y)]
= H[ψ(Z)|Tz(Y)] − H[ψ(Z)|Y]

− H[ψ(Z)] + H[ψ(Z)]

data-proc. inequality [13]
Tz(Y) are sufﬁcient for Z
Gibbs’s inequality
def’n cond. mutual info.
Tz (Y) deterministic
= 0
def’n mutual info.
(6)

data-processing inequality
X → φ(X) → Y  D.P.I.
p(λ) = q(λ)  Eq. 3
Eq. 6
p(λ) = q(λ)  Eq. 3
data-processing inequality

(7)

=⇒ I(ψ(Z); Tz(Y)) = I(ψ(Z); Y).
So Tz are sufﬁcient statistics for ψ(Z).
Now if ﬁnite mixtures of f (y; λ) are identiﬁable  then Eq. 5 implies that p(λ) = q(λ). Therefore:

I(X; Tz (Y)) ≤ I(X; Y)

≤ I(φ(X); Y)
= I(ψ(Z); Y)
= I(ψ(Z); Tz(Y))
= I(φ(X); Tz (Y))
≤ I(X; Tz (Y))

=⇒ I(X; Tz (Y)) = I(X; Y) 

which is what we set out to prove. (This last progression is illustrated in Fig. 2B.)

4 Relationship to empirical ﬁndings

The use of density-estimation algorithms for multisensory integration appears in [2  15  16]  and in
[2]  the connection between generic latent-variable density estimation and multisensory integration
was made  although the result was shown only empirically. We therefore relate those results to the
foregoing proof.

4.1 A density estimator for multisensory integration

In [2]  an exponential-family harmonium (model distribution  q  Fig. 3B) with Poisson visible units
(Y) and Bernoulli hiddens units (Z) was trained on simulated populations of neurons encoding
arm conﬁguration in two-dimensional space (Fig. 3). An EFH is parameterized by the matrix of
connection strengths between units (weights  W ) and the unit biases  bi. The nonlinearities for
Bernoulli and Poisson units are logistic and exponential  respectively  corresponding to their inverse
“canonical links” [17].
The data for these populations were created by (data distribution  p  Fig. 3A):

1. drawing a pair of joint angles (θ 1 = shoulder  θ 2 = elbow) from a uniform distribution
between the joint limits; drawing two population gains (g p  g v  the “reliabilities” of the two
populations) from uniform distributions over spike counts—hence x = [θ 1  θ 1  g p  g v];

2. encoding the joint angles in a set of 2D  Gaussian tuning curves (with maximum height g p)
that smoothly tile joint space (“proprioceptive neurons ” λp)  and encoding the correspond-
ing end-effector position in a set of 2D  Gaussian tuning curves (with maximum height g v)
that smoothly tile the reachable workspace (“visual neurons ” λv);

3. drawing spike counts  [yp  yv]  from independent Poisson distributions whose means were

given by [λp  λv].

6

Y v
0

Y v
1

Y v
2

Y v
3

Y p
0

Y p
1

Y p
2

Y p
3

Z0 Z1 Z2 Z3

X

Gv

Θ
A

Gp

Y v
0

Y v
1

Y v
2

Y p
0

Y p
1

Y p
2

Y p
3

Y v
3
B

Figure 3: Two probabilistic graphical models for the same data—a speciﬁc instance of Fig. 1. Colors are as in
Fig. 2. Here the orange nodes are observed.
(A) Hand position (Θ) elicits a response from populations of
visual (Yv) and proprioceptive (Yp) neurons. The reliability of each population’s encoding of hand position
varies with their respective gains  Gv  Gp. (B) The exponential family harmonium (EFH; see text). After
training  an up-pass through the model yields a vector of multisensory (mean) activities (z  hidden units) that
contains all the information about θ  g v  and g p that was in the unisensory populations  Yv and Yp.

p(y|x) =(cid:81)

Thus the distribution of the unisensory spike counts  Y = [Yp  Yv]  conditioned on hand position 
i p(y i|x)  was a “probabilistic population code ” a biologically plausible proposal for
how the cortex encodes probability distributions over stimuli [1]. The model was trained using one-
step contrastive divergence  a learning procedure that changes weights and biases by descending the
approximate gradient of a function that has q(y) = p(y) as its minimum [18  19].
It was then shown empirically that the criterion for “optimal multisensory integration” proposed
in [1] 

Pr[X|¯Z] = Pr[X|yp  yv] 

(8)
held approximately for an average  ¯Z  of vectors sampled from q(z|y)  and that the match improves
as the number of samples grows—i.e.  as the sample average ¯Z approaches the expected value
Eq(z|y)[Z|y]. Since the weight matrix W was “fat ” the randomly initialized network was highly
unlikely to satisfy Eq. 8 by chance.

4.2 Formulating the empirical result in terms of the proof of Section 3

To show that Eq. 8 must hold  we ﬁrst demonstrate its equivalence to Eq. 1. It then sufﬁces  under
our proof  to show that the model obeys Eqs. 3 and 5 and that the “mixture model” deﬁned by the
true generative process is identiﬁable.
For sufﬁciently many samples  ¯Z ≈ Eq(z|y)[Z|Y]  which is a sufﬁcient statistic for a vector of
Bernoulli random variables: Eq(z|y)[Z|Y] = Tz(Y). This also corresponds to a noiseless “up-
pass” through the model  Tz(Y) = σ{W Y + bz}2. And the information about the stimulus
reaches the multisensory population  Z  only via the two unisensory populations  Y. Together these
imply that Eq. 8 is equivalent to Eq. 1 (see Appendix for proof).
For both the “world” and the model  the function f (y; λ) is a product of independent Poissons 
whose means Λ are given respectively by the embedding of hand position into the tuning curves
of the two populations  φ(X)  and by the noiseless “down-pass” through the model  exp{W TZ +
by} =: ψ(Z). So Eq. 3 is satisﬁed. Eq. 5 holds because the EFH was trained as a density estimator 
and because the mixture may be treated as ﬁnite. (Although hand positions were drawn from a
continuous uniform distribution  the number of mixing components in the data distribution is limited
to the number of training samples. For the model in [2]  this was less than a million. For comparison 
the harmonium had 2900 mixture weights at its disposal.) Finally  the noise model is factorial:
i f (y i; λi). The class of mixtures of factorial distributions  f (y; λ)  is identiﬁable just
in case the class of mixtures of f (y i; λi) is identiﬁable [14]; and mixtures of (univariate) Poisson
conditionals are themselves identiﬁable [12]. Thus the mixture used in [2] is indeed identiﬁable.

f (y; λ) =(cid:81)

2That the vector of means alone and not higher-order cumulants sufﬁces reﬂects the fact that the sufﬁcient
statistics can be written as linear functions of Y—in this case  W Y  with W the weight matrix—which is
arguably a generically desirable property for neurons [20].

7

5 Conclusions

We have traced an analytical connection from psychophysical results in monkey and man to a broad
class of machine-learning algorithms  namely  density estimation in latent-variable models. In par-
ticular  behavioral studies of multisensory integration have shown that primates estimate stimulus
properties with the peak of the posterior distribution over the stimulus  conditioned on the two
unisensory cues [3  4]. This can be seen as a special case of a more general “optimal” compu-
tation  viz.  computing and representing the entire posterior distribution [1  6]; or  put differently 
ﬁnding transformations of multiple unisensory representations into a multisensory representation
that retains all the original information about the underlying stimulus. It has been shown that this
computation can be learned with algorithms that implement forms of latent-variable density esti-
mation [15  16]; and  indeed  argued that generic latent-variable density estimators will satisfy the
information-retention criterion [2]. We have provided an analytical proof that this is the case  at least
for certain classes of models (including the ones in [2]).
What about distributions f (y; λ) other than products of Poissons? Identiﬁability results  which
we have relied on here  appear to be the norm for ﬁnite mixtures; [12] summarizes the “overall
picture” thus: “[A]part from special cases with ﬁnite samples spaces [like binomials] or very special
simple density functions [like the continuous uniform distribution]  identiﬁability of classes of ﬁnite
mixtures is generally assured.” Thus the results apply to a broad set of density-estimation models
and their equivalent neural networks.
Interestingly  this excludes Bernoulli random variables  and therefore the mixture model deﬁned by
restricted Boltzmann machines (RBMs). Such mixtures are not strictly identiﬁable [12]  meaning
there is more than one set of mixture weights that will produce the observed marginal distribution.
Hence the guarantee proved in Section 3 does not hold. On the other hand  the proof provides only
sufﬁcient  not necessary conditions  so some guarantee of information retention is not ruled out.
And indeed  a relaxation of the identiﬁability criterion to exclude sets of measure zero has recently
been shown to apply to certain classes of mixtures of Bernoullis [21].
The information-retention criterion applies more broadly than multisensory integration; it is gen-
erally desirable. It is not  presumably  sufﬁcient: the task of the cortex is not merely to pass in-
formation on unmolested from one point to another. On the other hand  the task of integrating data
from multiple sources without losing information about the underlying cause of those data has broad
application: it applies  for example  to the data provided by spatially distant photoreceptors that are
reporting the edge of a single underlying object. Whether the criterion can be satisﬁed in this and
other cases depends both on the brain’s generative model and on the true generative process by
which the stimulus is encoded in neurons.
The proof was derived for sufﬁcient statistics rather than the neural responses themselves  but this
limitation can be overcome at the cost of time (by collecting or averaging repeated samples of neural
responses) or of space (by having a hidden vector long enough to contain most of the information
even in the presence of noise).
Finally  the result was derived for “completed” density estimation  q(y) = p(y). This is a strong
limitation; one would prefer to know how approximate completion of learning  q(y) ≈ p(y)  affects
the guarantee  i.e.  how robust it is. In [2]  for example  Eq. 2 was never directly veriﬁed  and in
fact one-step contrastive divergence (the training rule used) has suboptimal properties for building a
good generative model [22] And although the sufﬁcient conditions supplied by the proof apply to a
broad class of models  it would also be useful to know necessary conditions.

Acknowledgments

JGM thanks Matthew Fellows  Maria Dadarlat  Clay Campaigne  and Ben Dichter for useful con-
versations.

8

References
[1] Wei Ji Ma  Jeffrey M. Beck  Peter E. Latham  and Alexandre Pouget. Bayesian inference with probabilis-

tic population codes. Nature Neuroscience  9:1423–1438  2006.

[2] Joseph G. Makin  Matthew R. Fellows  and Philip N. Sabes. Learning Multisensory Integration and

Coordinate Transformation via Density Estimation. PLoS Computational Biology  9(4):1–17  2013.

[3] Marc O. Ernst and Martin S. Banks. Humans integrate visual and haptic information in a statistically

optimal fashion. Nature  415(January):429–433  2002.

[4] David Alais and David Burr. The ventriloquist effect results from near-optimal bimodal integration.

Current Biology  14(3):257–62  February 2004.

[5] Max Welling  Michal Rosen-Zvi  and Geoffrey E. Hinton. Exponential Family Harmoniums with an
Application to Information Retrieval. In Advances in Neural Information Processing Systems 17: Pro-
ceedings of the 2004 Conference  pages 1481–1488.  2005.

[6] David C. Knill and Alexandre Pouget. The Bayesian brain: the role of uncertainty in neural coding and

computation. Trends in Neurosciences  27(12)  2004.

[7] J.A. Saunders and David C. Knill. Perception of 3D surface orientation from skew symmetry. Vision

research  41(24):3163–83  November 2001.

[8] Robert J. van Beers  AC Sittig  and Jan J. Denier van Der Gon. Integration of proprioceptive and visual
position-information: An experimentally supported model. Journal of Neurophysiology  81:1355–1364 
1999.

[9] Philip N. Sabes. Sensory integration for reaching: Models of optimality in the context of behavior and

the underlying neural circuits. Progress in brain research  191:195–209  January 2011.

[10] Bruno A. Olshausen. Sparse codes and spikes.

In R.P.N. Rao  Bruno A. Olshausen  and Michael S.
Lewicki  editors  Probabilistic Models of the Brain: Perception and Neural Function  chapter 13. MIT
Press  2002.

[11] Anthony J. Bell. Towards a Cross-Level Theory of Neural Learning. AIP Conference Proceedings 

954:56–73  2007.

[12] D.M. Titterington  A.F.M. Smith  and U.E. Makov. Statistical Analysis of Finite Mixture Distributions.

Wiley  1985.

[13] Thomas M. Cover and Joy A. Thomas. Elements of Information Theory. Wiley  2006.
[14] Henry Teicher. Identiﬁability of Mixtures of Product Measures. The Annals of Mathematical Statistics 

38(4):1300–1302  1967.

[15] Ilker Yildirim and Robert A. Jacobs. A rational analysis of the acquisition of multisensory representations.

Cognitive Science  36(2):305–32  March 2012.

[16] Jeffrey M. Beck  Katherine Heller  and Alexandre Pouget. Complex Inference in Neural Circuits with
Probabilistic Population Codes and Topic Models. Advances in Neural Information Processing Systems
25: Proceedings of the 2012 Conference  pages 1–9  2013.

[17] Peter McCullagh and John A. Nelder. Generalized Linear Models. Chapman and Hall/CRC  second

edition  1989.

[18] Geoffrey E. Hinton  Simon Osindero  and Yee Whye Teh. A fast learning algorithm for deep belief nets.

Neural Computation  18:1527–1554  2006.

[19] Geoffrey E. Hinton. Training Products of Experts by Minimizing Contrastive Divergence. Neural Com-

putation  14:1771–1800  2002.

[20] Jeffrey M. Beck  Vikranth R. Bejjanki  and Alexandre Pouget. Insights from a Simple Expression for Lin-
ear Fisher Information in a Recurrently Connected Population of Spiking Neurons. Neural Computation 
23(6):1484–1502  June 2011.

[21] Elizabeth S. Allman  Catherine Matias  and John a. Rhodes. Identiﬁability of parameters in latent structure

models with many observed variables. The Annals of Statistics  37(6A):3099–3132  December 2009.

[22] Geoffrey E. Hinton. A Practical Guide to Training Restricted Boltzmann Machines. Technical report 

University of Toronto  Toronto  2010.

9

,Joseph Makin
Philip Sabes