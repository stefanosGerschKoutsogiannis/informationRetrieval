2011,Maximum Covariance Unfolding : Manifold Learning for Bimodal Data,We propose maximum covariance unfolding (MCU)  a manifold learning algorithm for simultaneous dimensionality reduction of data from different input modalities.   Given high dimensional inputs from two different but naturally aligned sources  MCU computes a common low dimensional embedding that maximizes the cross-modal (inter-source) correlations while preserving the local (intra-source) distances.  In this paper  we explore two applications of MCU.  First we use MCU to analyze EEG-fMRI data  where an important goal is to visualize the fMRI voxels that are most strongly correlated with changes in EEG traces.  To perform this visualization  we augment MCU with an additional step for metric learning in the high dimensional voxel space.  Second  we use MCU to perform cross-modal retrieval of matched image and text samples from Wikipedia.  To manage large applications of MCU  we develop a fast implementation based on ideas from spectral graph theory.  These ideas transform the original problem for MCU  one of semidefinite programming  into a simpler problem in semidefinite quadratic linear programming.,Maximum Covariance Unfolding:

Manifold Learning for Bimodal Data

Vijay Mahadevan
Department of ECE

University of California  San Diego

La Jolla  CA 92093

vmahadev@ucsd.edu

Chi Wah Wong

Department of Radiology

University of California  San Diego

La Jolla  CA 92093
cwwong@ieee.org

Jose Costa Pereira
Department of ECE

University of California  San Diego

La Jolla  CA 92093
josecp@ucsd.edu

Thomas T. Liu

Department of Radiology

University of California  San Diego

La Jolla  CA 92093
ttliu@ucsd.edu

Nuno Vasconcelos
Department of ECE

La Jolla  CA 92093

Lawrence K. Saul
Department of CSE

La Jolla  CA 92093

University of California  San Diego

University of California  San Diego

nvasconcelos@ucsd.edu

saul@cs.ucsd.edu

Abstract

We propose maximum covariance unfolding (MCU)  a manifold learning al-
gorithm for simultaneous dimensionality reduction of data from different in-
put modalities. Given high dimensional inputs from two different but naturally
aligned sources  MCU computes a common low dimensional embedding that
maximizes the cross-modal (inter-source) correlations while preserving the local
(intra-source) distances. In this paper  we explore two applications of MCU. First
we use MCU to analyze EEG-fMRI data  where an important goal is to visualize
the fMRI voxels that are most strongly correlated with changes in EEG traces. To
perform this visualization  we augment MCU with an additional step for metric
learning in the high dimensional voxel space. Second  we use MCU to perform
cross-modal retrieval of matched image and text samples from Wikipedia. To
manage large applications of MCU  we develop a fast implementation based on
ideas from spectral graph theory. These ideas transform the original problem for
MCU  one of semideﬁnite programming  into a simpler problem in semideﬁnite
quadratic linear programming.

1 Introduction

Recent advances in manifold learning and nonlinear dimensionality reduction have led to powerful 
new methods for the analysis and visualization of high dimensional data [14  1  20  24  16]. These
methods have roots in nonparametric statistics  spectral graph theory  convex optimization  and mul-
tidimensional scaling. Notwithstanding individual differences in motivation and approach  these
methods share certain features that account for their overall popularity: (i) they generally involve
few tuning parameters; (ii) they make no strong distributional assumptions; (iii) efﬁcient algorithms
exist to compute the global minima of their cost functions.

1

All these methods solve variants of the same basic underlying problem: given high dimensional
inputs  {x1  x2  . . .   xn}  compute low dimensional outputs {y1  y2  . . .   yn} that preserve certain
nearness relations (e.g.  local distances). Solutions to this problem have found applications in many
areas of science and engineering. However  many real-world applications do not map neatly into this
framework. For instance  in certain applications  aligned data is acquired from two different modal-
ities — we refer to such data as bimodal — and the goal is to ﬁnd low dimensional representations
that capture their interdependencies.
In this paper  we investigate the use of maximum variance unfolding (MVU) [24] for the simultane-
ous dimensionality reduction of data from different input modalities. Though the original algorithm
does not solve this problem  we show that it can be adapted to provide a compelling solution. In its
original formulation  MVU computes a low dimensional embedding that maximizes the variance of
its outputs  subject to constraints that preserve local distances. We explore a modiﬁcation of MVU
that computes a joint embedding of high dimensional inputs from different data sources. In this
joint embedding  our goal is to discover a common low dimensional representation of just those
degrees of variability that are correlated across different modalities. To achieve this goal  we design
the embedding to maximize the inter-source correlation between aligned outputs while preserving
the local  intra-source distances. By analogy to MVU  we call our approach maximum covariance
unfolding (MCU).
The optimization for MCU inherits the basic form of the optimization for MVU. In particular  it can
be cast as a semideﬁnite program (SDP). For applications to large datasets  we can also exploit the
same strategies behind recent  much faster implementations of MVU [25]. In particular  using these
same strategies  we show how to reformulate the optimization for MCU as a semideﬁnite quadratic
linear program (SQLP). In addition  for one of our applications—the analysis of EEG-fMRI data—
we show how to extend the basic optimization of MCU to visualize the high dimensional correlations
between different input modalities. This is done by adding extra variables to the original SDP; these
variables can be viewed as performing a type of metric learning in the high dimensional voxel space.
In particular  they indicate which fMRI voxels (in the high dimensional space of fMRI images)
correlate most strongly with observed changes in the EEG recordings.
As related work  we mention several other studies that have proposed SDPs to achieve different
objectives than those of the original algorithm for MVU. Bowling et al [4  5] developed a related
approach known as action-respecting embedding for problems in robot localization. Song et al [18]
reinterpreted the optimization criterion of MVU  then proposed an extension of the original algo-
rithm that computes low dimensional embeddings subject to class labels or other side information.
Finally  Shaw and Jebara [15  16] have explored related SDPs to produce minimum-volume and
structure-preserving embeddings; these SDPs yield much more sensible visualizations of social net-
works and large graphs that do not necessarily resemble a discretized manifold. Our work builds
on the successes of these earlier studies and further extends the applicability of SDPs for nonlinear
dimensionality reduction.

2 Maximum Covariance Unfolding
We propose a novel adaptation of MVU  termed maximum covariance unfolding or MCU to perform
non-linear correlation between two aligned datasets whose points have a one-to-one correspondence.
MCU embeds the two datasets  of different dimensions  into a single low dimensional manifold such
that the two resulting embeddings are maximally correlated. As in MVU  the embeddings are such
that local distances are preserved. The problem formulation is described in detail next.

i=1  x1i ∈ Rp1 and {x2i}n

i=1  y1i ∈ Rd and {y2i}n

i=1  x2i ∈ Rp2 be two aligned datasets belonging to two dif-
i=1  y2i ∈ Rd be the corresponding low

2.1 Formulation
Let {x1i}n
ferent input spaces  and {y1i}n
dimensional representations (in the output space)  with d (cid:191) p1 and d (cid:191) p2.
As in MVU [21]  we need to ﬁnd a low dimensional mapping such that the Euclidean distance
between pairs of points in a local neighborhood are preserved. For each dataset s ∈ {1  2}  if
points xsj and xsk are neighbors or are common neighbors of another point  we denote an indicator
variable ηsij = 1. The neighborhood constraints can then be written as

||ysi − ysj||2 = ||xsi − xsj||2

if ηsij = 1

(1)

2

(cid:189)

i ≤ n
i > n

y1i
y2(i−n)

i=1 containing 2n points  zi =

To simplify the notation  we concatenate the output points from both datasets into one large set 
{zi}2n
We also deﬁne the inner-product matrix for {zi}  Kij = zi.zj. This allows us to formulate the MCU
very similarly to the MVU formulation of [21]  and so we omit the details for the sake of brevity.
The distance constraint of (1) is written in the matrix form as:

Kii − 2Kij + Kjj = D1ij   {(i  j) : i  j ≤ n and η1ij = 1}
Kii − 2Kij + Kjj = D2(i−n)(j−n)  {(i  j) : i  j > n and η2(i−n)(j−n) = 1}
(cid:80)
i ysi = 0 ∀s ∈ {1  2}. The equivalent matrix constraints are 

The centering constraint to ensure that the output points of both datasets are centered at the origin
requires that

(2)
(3)

(cid:88)

(cid:88)

Kij = 0  ∀i  j ≤ n

Kij = 0  ∀i  j > n

ij

ij

(4)

(6)

The objective function is to maximize the covariance between the low dimensional representations
of the two datasets. We can use the trace of the covariance matrix as a measure of how strongly the
two outputs are correlated. The average covariance can be written as:

tr(cov(y1  y2)) = tr(E(y1yT

2 )) = E(tr(y1yT

2 )) = E(y1.y2) ≈ 1

y1i.y2i

(5)

(cid:88)

n

i

Combining all the constraints together with the objective function  we can write the optimization as:

(cid:184)

(cid:183)

WijKij  with W =

(cid:88)
Kii − 2Kij + Kjj = D1ij   {(i  j) : i  j ≤ n and η1ij = 1}
Kii − 2Kij + Kjj = D2(i−n)(j−n)   {(i  j) : i  j > n and η2(i−n)(j−n) = 1}
K (cid:186) 0 

Kij = 0  ∀i  j ≤ n 

Kij = 0  ∀i  j > n

(cid:88)

(cid:88)

0
In

In
0

ij

Maximize:

subject to:

ij

ij

As in the original MVU formulation [21]  this is a semi-deﬁnite program (SDP) and can be solved
using general-purpose toolboxes such as SeDuMi [19]. The solution returned by the SDP can be
used to ﬁnd the coordinates in the low-dimensional embedding  {y1i}n
i=1  using the
spectral decomposition method described in [21].
One shortcoming of the MCU formulation is that it provides no means to visualize the results.
While the low-dimensional embeddings of the two datasets may be well correlated  there is no way
to identify which dimensions or covariates of the data points in one modality contribute to high
correlation with the points in the other modality. To address this issue  we include a novel metric
learning framework in the MCU formulation  as described in the next section.

i=1 and {y2i}n

2.2 Metric Learning for Visualization
For each dimension in one dataset  we need to compute a measure of how much it contributes to the
correlation between the datasets. This can be done using a metric learning type step applied to data
of one or both modalities within the MCU formulation. In this work we describe this approach for
the situation where metric learning is applied to only {x1i}.
The MCU formulation of Section 2 assumes that the distances between the points is Euclidean. So in
the computation of nearest neighbor distances  each of the p1 dimensions of {x1i} receive the same
weight  as shown in (1). However  inspired by the recently proposed ideas in metric learning [22] 
we use a more general distance metric by applying a linear transformation T1 of size p1 × p1 in the
space  and then perform MCU using the transformed points  T1xi. This allows some distances to
shrink/expand if that would help in increasing the correlation with {x2i}.
For the sake of simplicity  we choose a diagonal weight matrix T1  whose diagonal entries are
{σi}p1
In order to ﬁnd the weight vector that produces the maximal correlation between the two datasets 
these p1 new variables can be learned within the MCU framework by adding them to the optimization

i=1  σi ≥ 0  ∀i. This allows us to weight each dimension of the input space separately.

3

(cid:80)

m σm(xim − xjm)2.

problem. As each dimension has a corresponding weight  the optimal weight vector returned would
be a map over the dimensions indicating how strongly each is correlated to {x2i}.
To modify the MCU formulation to include these new variables  we replace all Euclidean dis-
tance measurements for the data points in the ﬁrst dataset in (2) with the weighted distance
D1ij =
This adds a linear function of the new weight variables to the existing distance constraints of (2).
However  if we had to deﬁne the neighborhood of a data point itself using this weighted distance 
the formulation would become non-convex. So we assume that the neighborhood is composed of
points that are closest in time . An alternative is to use neighbors as computed in the original space
using the un-weighted distance. We also add constraints to make the weights positive and sum to p1.
The objective function of (6) does not change  but we need to maximize the objective over the p1
weight variables also. The problem still remains an SDP and can be solved as before. The new
formulation  denoted MCU-ML  is written as:

(cid:88)

ij

Maximize:

subject to:

WijKij  with W =

σk ≥ 0  ∀k ∈ {1 . . . p1} 

and

σk = p1.

(cid:183)

(cid:184)

In
0

0
In

(cid:88)

k

(cid:88)

m

σm(xim − xjm)2 = 0  {(i  j) : i  j ≤ n and η1ij = 1}

Kii − 2Kij + Kjj −
Kii − 2Kij + Kjj = D2(i−n)(j−n)  {(i  j) : i  j > n and η2(i−n)(j−n) = 1}
K (cid:186) 0 

Kij = 0  ∀i  j ≤ n 

Kij = 0  ∀i  j > n

(cid:88)

(cid:88)

(7)

ij

ij

We next describe how these formulations for MCU can be applied to ﬁnd optimal representations
for high dimensional EEG-fMRI data.
3 Resting-state EEG-fMRI Data
In the absence of an explicit task  temporal synchrony of the blood oxygenation level dependent
(BOLD) signal is maintained across distinct brain regions. Taking advantage of this synchrony 
resting-state fMRI has been used to study connectivity. fMRI datasets have high resolution of the
order of a few millimeters  but offer poor temporal resolution as it measures the delayed haemody-
namic response to neural activity. In addition  changes in resting-state BOLD connectivity measures
are typically interpreted as changes in coherent neural activity across respective brain regions. How-
ever  this interpretation may be misleading because the BOLD signal is a complex function of neural
activity  oxygen metabolism  cerebral blood ﬂow (CBF)  and cerebral blood volume (CBV) [3]. To
address these shortcomings  simultaneous acquisition of electroencephalographic data (EEG) during
functional magnetic resonance imaging (fMRI) is becoming more popular in brain imaging [13].
The EEG recording provides high temporal resolution of neural activity (5kHz)  but poor spatial
resolution due to electric signal distortion by the skull and scalp and the limitations on the num-
ber of electrodes that can be placed on the scalp. Therefore the goal of simultaneous acquisition
of EEG and fMRI is to exploit the complementary nature of the two imaging modalities to obtain
spatiotemporally resolved neural signal and metabolic state information [13]. Speciﬁcally  using
high temporal resolution EEG data  we are able to examine dynamic changes and non-stationary
properties of neural activity at different frequency bands. By correlating with the EEG data with
the high resolution BOLD data  we are able to examine the corresponding spatial regions in which
neural activity occurs.
Conventional approaches to analyzing the joint EEG-fMRI data have relied on linear methods. Most
often  a simple voxel-wise correlation of the fMRI data with the EEG power time series in a speciﬁc
frequency band is performed [13]. But this technique does not exploit the rich spatial dependencies
of the fMRI data. To address this issue  more sophisticated linear methods such as canonical correla-
tion analysis (CCA) [7]  and the partial least squares method [11] have been proposed. However  all
linear approaches have a fundamental shortcoming - the space of images  which is highly non-linear
and thought to form a manifold  may not be well represented by a linear subspace. Therefore  lin-

4

ear approaches to correlate the fMRI data with the EEG data may not capture any low dimensional
manifold structure.
To address these limitations we propose the use of MCU to learn low dimensional manifolds for both
the fMRI and EEG data such that the output embeddings are maximally correlated. In addition  we
learn a metric in the fMRI input space to identify which voxels of the fMRI correlate most strongly
with observed changes in the EEG recordings. We ﬁrst describe the methods used to acquire the
EEG-fMRI dataset.

3.1 Method for Data Acquisition
One 5 minute simultaneous EEG-fMRI resting state run was recorded and processed with eyes
closed (EC). Data were acquired using a 3 Tesla GE HDX system and a 64 channel EEG system
supplied by Brain Products. EEG signals were recorded at 5kHz sampling rate. Impedances of the
electrodes were kept below 20kΩ. Recorded EEG data were pre-processed using Vision Analyzer
2.0 software (Brain Products). Subtraction-based MR-gradient and Cardio-ballistic artifact removal
were applied. A low pass ﬁlter with cut off frequency 30Hz was applied to all channels and the
processed signals were down-sampled to 250Hz. fMRI data were acquired with the following pa-
rameters: echo planar imaging with 150 volumes  30 slices  3.438 × 3.438 × 5mm3 voxel size 
64 × 64 matrix size  TR=2s  TE=30ms. fMRI data were pre-processed using an in-house developed
package. The 5 frequency channels of the EEG data were averaged to produce a 63 dimensional
time series of 145 time points. The fMRI data consisted of a 122880 (64 × 64 × 30) dimensional
time series with 145 time points.

3.2 Results on EEG-fMRI Dataset
The EEG and fMRI data points described in the previous section are extremely high dimensional.
However  both EEG and fMRI signals are the result of sparse neuronal activity. Therefore  attempts
to embed these points  especially the fMRI data  into a low dimensional manifold have been made
using non-linear dimensionality reduction techniques such as Laplacian eigenmaps [17]. While such
techniques may be used to ﬁnd manifold embeddings for fMRI and EEG data separately  they are
not useful for ﬁnding patterns of correlation between the two. We demonstrate how MCU can be
applied to this setting below.
Due to the very high dimensionality of the fMRI dataset  we pre-processed the data as follows. An
anatomical region of interest mask was used  followed by PCA to project the fMRI samples to a
subspace of dimension p1 = 145 (which represented all of the energy of the samples  because there
are only 145 time points). The EEG data was not subject to any pre-processing  and p2 remained
63. We applied the MCU-ML approach to learn a visualization map and a joint low dimensional
embedding for the EEG-fMRI dataset. We compared the results to two other techniques - the voxel-
wise correlation  and the linear CCA approach inspired by [7]. The MCU-ML solution directly
returned a weight vector of length 145. For CCA  the average of the canonical directions (weighted
using the canonical correlations) was used as the weight vector. In both cases  the 145 dimensional
weight vector was projected back to the fMRI voxel space using the principal components of the
PCA step.
Two types of voxel wise correlations maps were computed to assess the performance of MCU-ML.
First  a naive correlation map was generated where each voxel was separately correlated with the av-
erage EEG power time course from the alpha aband (8-12Hz) (which is known to be correlated with
the fMRI resting-state network [13]) from all the 63 electrodes. Second  a functional connectivity
map was generated using the knowledge that at rest state (during which the dataset was recorded) 
the Posterior Cingulate Cortex (PCC) is known to be active [8] and is correlated with the Default
Mode Network (DMN) while anti-correlated with the Task Positive Network (TPN). To achieve this 
a seed region of interest (ROI) was ﬁrst selected from PCC. The averaged fMRI signal from the ROI
was then correlated with the whole brain to obtain a voxel-wise correlation map. Therefore  voxels
in the PCC region should have high correlation with the EEG data. This information provides a
“sanity-check” version of the fMRI correlation map.
The results for the anatomically signiﬁcant slice 18  within which both DMN and the TPN are
located  are shown in Figure 1. The functional connectivity map is shown in 2(a)  and the correlation
map obtained using MCU-ML  overlaid with the relevant anatomical regions appears in 2(b). The
MCU-ML map shows the activation of Default Mode Network (DMN) and a suppression of Task
Positive Network (TPN). From the results  it is clear that the MCU-ML approach produces the best

5

(a)

(b)

(c)

(d)

Figure 1: Comparison of results on the EEG-fMRI dataset. (a) naive correlation map (b) using only PCA (c)
using CCA (d) using MCU-ML

match  showing well localized regions of positive correlation in the DMN  and regions of negative
correlation in the TPN. The correlation maps for 12 slices overlaid with over a high-resolution T1-
weighted image for the proposed MCU-ML approach are shown in Figure 3(b).

(a)

(b)

Figure 2: (a) the functional connectivity map  and (b) the MCU-ML correlation map overlaid with information
about the anatomical regions relevant during rest state.

(a)

(b)

Figure 3: (a) The plot showing the normalized weights for the 145 dimensions for CCA  MCU-ML and PCA.
(b) A montage showing the recovered weights for each voxel in the 12 anatomically signiﬁcant slices  with the
MCU overlaid on a high-resolution T1-weighted image.
To compare the learned weights using the MCU-ML and CCA  we plot the normalized importance
of each of the 145 dimensions in Figure 3(a). We also plot the eigenvalues for the 145 dimensions
obtained using PCA. It is seen that the weights produced by the MCU-ML approach have fewer
components (around 20) than those of CCA. It is also interesting to see that the weights that produce
maximal correlation with the EEG dataset are very different from the eigenvalues of PCA them-
selves  indicating that the dimensions that are important for correlation are not necessarily the ones
with maximum variance.
4 Fast MCU
One of the primary limitations of the SDP based formulation for MCU in Section 2.1  shared with
MVU  is its inability to scale to problems involving a large number of data points [23]. To address
this issue  Weinberger et al. [23] modiﬁed the original formulation using graph laplacian regular-
ization to reduce the size of the SDP. However  recent work has shown that even this reduced for-
mulation of MVU can be solved more efﬁciently by reframing it as a semideﬁnite quadratic linear
programming (SQLP) [25]. In this section  we show how a fast version of MCU  denoted Fast-MCU 
can be implemented using a similar approach.

6

  102030405060102030405060−0.8−0.6−0.4−0.200.20.40.60.8  102030405060102030405060−0.8−0.6−0.4−0.200.20.40.60.8  102030405060102030405060−0.8−0.6−0.4−0.200.20.40.60.8  102030405060102030405060−0.8−0.6−0.4−0.200.20.40.60.8  102030405060102030405060−0.8−0.6−0.4−0.200.20.40.60.805010015000.20.40.60.81PCA IndexRelative Weights  MCUPCACCALet L1 and L2 denote the graph laplacians [6] of the two sets of points  {y1i} and {y2i}  respectively.
The graph laplacian depends only on nearest neighbor relations and in MCU these are assumed to
be unchanged as the points are embedded from the original space to the low dimensional manifold.
Therefore  L1 and L2 can be obtained using the graph of data points  {x1i} and {x2i}  in the original
space. Let Q1  Q2 ∈ Rn×m contain the bottom m eigenvectors of L1 and L2. Then we can write
i=1 and {u2}m
2n vectors {y1i} and {y2i} in terms of two new sets of m unknown vectors  {u1}m
i=1 
with m (cid:191) n  using the approximation:

y1i ≈ m(cid:88)

α=1

and y2i ≈ m(cid:88)

α=1

Q1iαu1α

Q2iαu2α

(8)

(cid:189)

ui =

u1i
u2(i−m)

As in Section 2  we concatenate the vectors from both datasets into one larger set  {ui}2m
ing 2m points:

i=1 contain-

i ≤ m
(9)
i > m
iαujβ ∀i  j ∈ {1  2} ∀α  β ∈ {1 . . . m}  and

(cid:184)

(cid:183)

We deﬁne m × m inner product matrices  (Uij)αβ = uT
a 2m × 2m matrix  Uαβ = uT
The 2n × 2n inner product matrix K can therefore be approximated in terms of the much smaller
matrix 2m × 2m matrix U:

αuβ ∀α  β ∈ {1 . . . 2m}. Therefore  U =

U11 U12
U21 U22

.

(cid:184)

(cid:183)

K ≈

Q1U11QT
Q2U21QT

1 Q1U21QT
2
1 Q2U22QT
2

(10)

The formulate MCU as an SQLP  we ﬁrst
straints

into the objective

function using regularization parameters ν1  ν2

rewrite (6) by bringing the distance con-
0:

>

(cid:88)

Maximize:

(cid:88)

(cid:161)

Kii − 2Kij + Kjj − D1ij

ij

−ν2

WijKij −ν1

(cid:88)
(cid:88)

i∼j ∀i j>n

(cid:161)
i∼j ∀i j≤n
(cid:88)
Kii − 2Kij + Kjj − D2ij

Kij = 0  ∀i  j ≤ n 

(cid:162)2

subject to:

K (cid:186) 0 

(cid:162)2

Kij = 0  ∀i  j > n

(11)

ij

By using (10) in (11)  and by noting that the centering constraint is automatically satisﬁed [23]  we
get the modiﬁed formulation in terms of U:

ij

(cid:88)

(cid:179)

(cid:88)

νk

k

i∼kj

(cid:180)2

(12)

(QkUkkQT

k )ii − 2(QkUkkQT

k )ij + (QkUkkQT

k )jj − Dkij

Maximize:

2 ) −

2tr(Q1U21QT
U (cid:186) 0

subject to:
where i ∼k j for k ∈ {1  2} encodes the neighborhood relationships of the kth dataset.
This SDP is similar to the formulation proposed by [23]. In order to obtain further simpliﬁcation  let
U ∈ R4m2 be the concatenation of the columns of U. Then  (12) can be reformulated by collecting
the coefﬁcients of all quadratic terms in the objective function in a positive semi-deﬁnite matrix
A ∈ R4m2×4m2  and those of the linear terms  including the trace term  in a vector b ∈ R4m2:

Minimize:
subject to:

UAU T + bTU
U (cid:186) 0

i=1 and {u2i}m

(13)
This minimization problem can be solved using the SQLP approach of [6]. From the solution of the
SQLP  the vectors{u1i}m
i=1  can be obtained using the spectral decomposition method
described in [21]  followed by the low dimensional coordinates {y1i}n
i=1  using (8).
Finally  these coordinates are reﬁned using gradient based improvement of the original objective
function of (11) using the procedure described in [23].
5 Results
We apply the Fast-MCU algorithm to n = 1000 points generated from two “Swiss rolls” in three
dimensions  with m set to 20. Figure 4 shows the embeddings of this data generated by CCA and

i=1 and {y2i}n

7

by Fast-MCU. While CCA discovers two signiﬁcant dimensions  the Fast-MCU accurately extracts
the low dimensional manifold where the embeddings lie in a narrow strip.

(a)

(b)

(c)

Figure 4: (a) Two “swiss rolls” consisting of 1000 points each in 3D with the aligned pairs of points shown
in the same color. (b) the 2D embedding obtained using CCA. (c) low dimensional manifolds obtained using
Fast-MCU  before and after the gradient based improvement step. (best viewed in color)
To further test the proposed Fast-MCU on real data  we use the recently proposed Wikipedia dataset
composed of text and image pairs [12]. The dataset consists of 2866 text - image pairs  each belong-
ing to one of 10 semantic categories. The corpus is split into a training set with 2173 documents  and
a test set with 693 documents. The retrieval task consists of two parts. In the ﬁrst  each image in the
test set is used as a query  and the goal is to rank all the texts in the test set based on their match to
the query image. In the second  a text query is used to rank the images. In both parts  performance
is measured using the mean average precision (MAP). The MAP score is the average precision at
the ranks where recall changes.
The experimental evaluation was similar to that of [12]. We ﬁrst represented the text using an LDA
model [2] with 20 topics  and the image using a histogram over a SIFT [10] codebook of 4096
codewords. The common low dimensional manifold was learned from the text-image pairs of the
training set using the SQLP based formulation of (13)  with m = 20  followed by a gradient ascent
step as described in the previous section. To compare the performance of Fast-MCU  we also used
CCA and kernel CCA (kCCA) to learn the maximally correlated joint spaces from the training set.
For kCCA we used a Gaussian kernel and implemented it using code from the authors of [9].
Given a test sample (image or text)  it is ﬁrst projected into the learned subspace or manifold. For
CCA  this involves a linear transformation to the low dimensional subspace  while for kCCA this
is achieved by evaluating a linear combination of the kernel functions of the training points [9].
For Fast-MCU  the nearest neighbors of the test point among the training samples in the original
space are used to obtain a mapping of the point as a weighted combination of these neighbors. The
same mapping is then applied to the projection of the neighbors in the learned low dimensional joint
manifold to compute the projection of the test point. To perform retrieval  all the test points of both
modalities  image and text  are projected to the joint space learned using the training set. For a
given test point of one modality  its distance to all the projected test points of the other modality
are computed  and these are then ranked. In this work  we used the normalized correlation distance 
which was shown to be the best performing distance metric in [12]. A retrieved sample is considered
to be correct if it belongs to the same category as the query.
The results of the retrieval task are shown in Table 1. The performance of a random retrieval scheme
is also shown to indicate the baseline chance level.It is clear that Fast-MCU outperforms both CCA
and kCCA in both image-to-text and text-to-image retrieval tasks. In addition  Fast-MCU produced
signiﬁcantly lower number of dimensions for the embeddings - CCA produced 19 signﬁcant dimen-
sions compared to just 3 for Fast-MCU.

Table 1: MAP Scores for image-text retrieval tasks

Query
Text - Image
Image - Text

Random CCA KCCA Fast-MCU
0.118
0.118

0.264
0.198

0.193
0.154

0.170
0.172

6 Conclusions
In this paper  we describe an adaptation of MVU to analyze correlation of high-dimensional aligned
data such as EEG-fMRI data and image-text corpora. Our results on EEG-fMRI data show that

8

−10010−505−10−50510INPUT1 N=1000)−10010−505−10−50510INPUT2 N=1000−10010−10010OUTPUT1 CCA−10010−10010OUTPUT2 CCA−50050−40−2002040OUTPUT1 Fast MCU (before fine−tuning)−50050−40−2002040OUTPUT2 Fast MCU (before fine−tuning)−50050−40−2002040OUTPUT1 Fast MCU (after gradient −based improvement)−50050−40−2002040OUTPUT2 Fast MCU (after gradient−based improvement)the proposed approach is able to make anatomically signiﬁcant predictions about which voxels of
the fMRI are most correlated with changes in EEG signals. Likewise  the results on the Wikipedia
set demonstrate the ability of MCU to discover the correlations between images and text. In both
these applications  it is important to realize that MCU is not only revealing the correlated degrees of
variability from different input modalities  but also pruning away the uncorrelated ones. This ability
of MCU makes it much more broadly applicable because in general we expect inputs from truly
different modalities to have many independent degrees of freedom: e.g.  there are many ways in text
to describe a single  particular image  just as there are many ways in pictures to illustrate a single 
particular word.

7 Acknowledgements

This work was supported by NSF award CCF-0830535  NIH Grant R01NS051661 and ONR MURI
Award No. N00014-10-1-0072.
References
[1] M. Belkin and P. Niyogi. Laplacian eigenmaps for dimensionality reduction and data representation.

Neural Computation  15(6):1373–1396  2003.

[2] D. Blei  A. Ng  and M. Jordan. Latent dirichlet allocation. JMLR   3:993–1022  2003.
[3] R. Buxton  K. Uluda  D. Dubowitz  and T. T Liu. Modeling the hemodynamic response to brain activation.

Neuroimage  23(1):220-233  2004.

[4] M. Bowling  A. Ghodsi  and D. Wilkinson. Action respecting embedding. In ICML  pages 65–72  2005.
[5] M. Bowling  D. Wilkinson  A. Ghodsi  and A. Milstein. Subjective localization with action respecting

embedding. In ISRR  2005.

[6] F. Chung. Spectral graph theory. Amer Mathematical Society  1997.
[7] N. Correa  T. Eichele  T. AdalI  Y. Li  and V. Calhoun. Multi-set canonical correlation analysis for the

fusion of concurrent single trial ERP and functional MRI. NeuroImage  2010.

[8] M. Greicius  B. Krasnow  A. Reiss  and V. Menon. Functional connectivity in the resting brain: a network

analysis of the default mode hypothesis. PNAS  100(1):253  2003.

[9] D. Hardoon  S. Szedmak  and J. Shawe-Taylor. Canonical correlation analysis: An overview with appli-

cation to learning methods. Neural Computation  16(12):2639–2664  2004.

[10] D. Lowe. Distinctive image features from scale-invariant keypoints. IJCV  60(2):91–110  2004.
[11] E. Martinez-Montes  P. Vald´es-Sosa  F. Miwakeichi  R. Goldman  and M. Cohen. Concurrent EEG/fMRI

analysis by multiway partial least squares. NeuroImage  22(3):1023–1034  2004.

[12] N. Rasiwasia  J. Costa Pereira  E. Coviello  G. Doyle  G. Lanckriet  R. Levy  and N. Vasconcelos. A new

approach to cross-modal multimedia retrieval. In ACM Multimedia  pages 251–260  2010.

[13] P. Ritter and A. Villringer. Simultaneous EEG-fMRI. Neuroscience & Biobehavioral Reviews  30(6):823–

838  2006.

290:2323–2326  2000.

Rico  2007.

2008.

[14] S. T. Roweis and L. K. Saul. Nonlinear dimensionality reduction by locally linear embedding. Science 

[15] B. Shaw and T. Jebara. Minimum volume embedding. In AISTATS  pages 460–467  San Juan  Puerto

[16] B. Shaw and T. Jebara. Structure preserving embedding. In ICML  2009.
[17] X. Shen and F. Meyer. Low-dimensional embedding of fMRI datasets. Neuroimage  41(3):886–902 

[18] L. Song  A. Smola  K. Borgwardt  and A. Gretton. Colored maximum variance unfolding. NIPS 2008.
[19] J. Sturm. Using SeDuMi 1.02  a MATLAB toolbox for optimization over symmetric cones. Optimization

methods and software  11(1):625–653  1999.

[20] J. B. Tenenbaum  V. de Silva  and J. C. Langford. A global geometric framework for nonlinear dimen-

sionality reduction. Science  290:2319–2323  2000.

[21] K. Weinberger and L. Saul. Unsupervised learning of image manifolds by semideﬁnite programming.

IJCV  70(1):77–90  2006.

JMLR  10:207–244  2009.

programming. NIPS  19:1489  2007.

ICML  2004.

[22] K. Weinberger and L. Saul. Distance metric learning for large margin nearest neighbor classiﬁcation.

[23] K. Weinberger  F. Sha  Q. Zhu  and L. Saul. Graph laplacian regularization for large-scale semideﬁnite

[24] K. Q. Weinberger  F. Sha  and L. K. Saul. Learning a kernel matrix for nonlinear dimensionality reduction.

[25] X. Wu  A. So  Z. Li  and S. Li. Fast graph laplacian regularized kernel learning via semideﬁnite–

quadratic–linear programming. NIPS  22:1964–1972.

9

,Austin Benson
Jason Lee
Bartek Rajwa
David Gleich
Jimmy Ren
Li Xu
Qiong Yan
Wenxiu Sun
Dan Garber
Dan Garber
Ofer Meshi