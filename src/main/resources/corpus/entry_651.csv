2014,Automatic Discovery of Cognitive Skills to Improve the Prediction of Student Learning,To master a discipline such as algebra or physics  students must acquire a set of cognitive skills. Traditionally  educators and domain experts manually determine what these skills are and then select practice exercises to hone a particular skill. We propose a technique that uses student performance data to automatically discover the skills needed in a discipline. The technique assigns a latent skill to each exercise such that a student's expected accuracy on a sequence of same-skill exercises improves monotonically with practice. Rather than discarding the skills identified by experts  our technique incorporates a nonparametric prior over the exercise-skill assignments that is based on the expert-provided skills and a weighted Chinese restaurant process. We test our technique on datasets from five different intelligent tutoring systems designed for students ranging in age from middle school through college. We obtain two surprising results. First  in three of the five datasets  the skills inferred by our technique support significantly improved predictions of student performance over the expert-provided skills. Second  the expert-provided skills have little value: our technique predicts student performance nearly as well when it ignores the domain expertise as when it attempts to leverage it. We discuss explanations for these surprising results and also the relationship of our skill-discovery technique to alternative approaches.,Automatic Discovery of Cognitive Skills

to Improve the Prediction of Student Learning

Robert V. Lindsey  Mohammad Khajah  Michael C. Mozer
Department of Computer Science and Institute of Cognitive Science

University of Colorado  Boulder

Abstract

To master a discipline such as algebra or physics  students must acquire
a set of cognitive skills. Traditionally  educators and domain experts use
intuition to determine what these skills are and then select practice exer-
cises to hone a particular skill. We propose a technique that uses student
performance data to automatically discover the skills needed in a disci-
pline. The technique assigns a latent skill to each exercise such that a
student’s expected accuracy on a sequence of same-skill exercises improves
monotonically with practice. Rather than discarding the skills identiﬁed by
experts  our technique incorporates a nonparametric prior over the exercise-
skill assignments that is based on the expert-provided skills and a weighted
Chinese restaurant process. We test our technique on datasets from ﬁve
diﬀerent intelligent tutoring systems designed for students ranging in age
from middle school through college. We obtain two surprising results. First 
in three of the ﬁve datasets  the skills inferred by our technique support
signiﬁcantly improved predictions of student performance over the expert-
provided skills. Second  the expert-provided skills have little value: our
technique predicts student performance nearly as well when it ignores the
domain expertise as when it attempts to leverage it. We discuss expla-
nations for these surprising results and also the relationship of our skill-
discovery technique to alternative approaches.

1 Introduction

With the advent of massively open online courses (MOOCs) and online learning platforms
such as Khan Academy and Reasoning Mind  large volumes of data are collected from
students as they solve exercises  acquire cognitive skills  and achieve a conceptual under-
standing. A student’s data provides clues as to his or her knowledge state—the speciﬁc facts 
concepts  and operations that the student has mastered  as well as the depth and robustness
of the mastery. Knowledge state is dynamic and evolves as the student learns and forgets.

Tracking a student’s time-varying knowledge state is essential to an intelligent tutoring sys-
tem. Knowledge state pinpoints the student’s strengths and deﬁciencies and helps determine
what material the student would most beneﬁt from studying or practicing. In short  eﬃcient
and eﬀective personalized instruction requires inference of knowledge state [20  25].

Knowledge state can be decomposed into atomic elements  often referred to as knowledge
components [7  13]  though we prefer the term skills. Skills include retrieval of speciﬁc facts 
e.g.  the translation of ‘dog’ into Spanish is perro  as well as operators and rules in a domain 
e.g.  dividing each side of an algebraic equation by a constant to transform 3(x + 2) = 15
into x + 2 = 5  or calculating the area of a circle with radius r by applying the formula

1

πr2. When an exercise or question is posed  students must apply one or more skills  and
the probability of correctly applying a skill is dependent on their knowledge state.

To predict a student’s performance on an exercise  we thus must: (1) determine which skill
or skills are required to solve the exercise  and (2) infer the student’s knowledge state for
those skills. With regard to (1)  the correspondence between exercises and skills  which
we will refer to as an expert labeling  has historically been provided by human experts.
Automated techniques have been proposed  although they either rely on an expert labeling
which they then reﬁne [5] or treat the student knowledge state as static [3]. With regard
to (2)  various dynamical latent state models have been suggested to infer time-varying
knowledge state given an expert labeling. A popular model  Bayesian knowledge tracing
assumes that knowledge state is binary—the skill is either known or not known [6]. Other
models posit that knowledge state is continuous and evolves according to a linear dynamical
system [21].

Only recently have methods been suggested that simultaneously address (1) and (2)  and
which therefore perform skill discovery. Nearly all of this work has involved matrix factor-
ization [24  22  14]. Consider a student × exercise matrix whose cells indicate whether a
student has answered an exercise correctly. Factorization leads to a vector for each student
characterizing the degree to which the student has learned each of Nskill skills  and a vec-
tor for each exercise characterizing the degree to which that exercise requires each of Nskill
skills. Modeling student learning presents a particular challenge because of the temporal
dimension: students’ skills improve as they practice. Time has been addressed either via
dynamical models of knowledge state or by extending the matrix into a tensor whose third
dimension represents time.

We present an approach to skill discovery that diﬀers from matrix factorization approaches in
three respects. First  rather than ignoring expert labeling  we adopt a Bayesian formulation
in which the expert labels are incorporated into the prior. Second  we explore a nonparamet-
ric approach in which the number of skills is determined from the data. Third  rather than
allowing an exercise to depend on multiple skills and to varying degrees  we make a stronger
assumption that each exercise depends on exactly one skill in an all-or-none fashion. With
this assumption  skill discovery is equivalent to the partitioning of exercises into disjoint
sets. Although this strong assumption is likely to be a simpliﬁcation of reality  it serves
to restrict the model’s degrees of freedom compared to factorization approaches in which
each student and exercise is assigned an Nskill-dimensional vector. Despite the application
of sparsity and nonnegativity constraints  the best models produced by matrix factorization
have had low-dimensional skill spaces  speciﬁcally  Nskill ≤ 5 [22  14]. We conjecture that
the low dimensionality is not due to the domains being modeled requiring at most 5 skills 
but rather to overﬁtting for Nskill > 5. With our approach of partitioning exercises into
disjoint skill sets  we can aﬀord Nskill (cid:29) 5 without giving the model undue ﬂexibility. We
are aware of one recent approach to skill discovery [8  9] which shares our assumption that
each exercise depends on a single skill. However  it diﬀers from our approach in that it does
not try to exploit expert labels and presumes a ﬁxed number of skills. We contrast our work
to various alternative approaches toward the end of this paper.

2 A nonparametric model for automatic skill discovery

We now introduce a generative probabilistic model of student problem-solving in terms of
two components: (1) a prior over the assignment of exercises to skills  and (2) the likelihood
of a sequence of responses produced by a student on exercises requiring a common skill.

2.1 Weighted CRP: A prior on skill assignments

Any instructional domain (e.g.  algebra  geometry  physics) has an associated set of exercises
which students must practice to attain domain proﬁciency. We are interested in the common
situation where an expert has identiﬁed  for each exercise  a speciﬁc skill which is required
for its solution (the expert labeling). It may seem unrealistic to suppose that each exercise
requires no more than one skill  but in intelligent tutoring systems [7  13]  complex exercises
(e.g.  algebra word problems) are often broken down into a series of steps which are small

2

enough that they could plausibly require only one skill (e.g.  adding a constant to both
sides of an algebraic equation). Thus  when we use the term ‘exercise’  in some domains we
are actually referring to a step of a compound exercise. In other domains (e.g.  elementary
mathematics instruction)  the exercises are designed speciﬁcally to tap what is being taught
in a lesson and are thus narrowly focused.

We wish to exploit the expert labeling to design a nonparametric prior over assignments
of exercises to skills—hereafter  skill assignments—and we wish to vary the strength of the
bias imposed by the expert labeling. With a strong bias  the prior would assign nonzero
probability to only the expert labeling. With no bias  the expert labeling would be no more
likely than any other. With an intermediate bias  which provides soft constraints on the
skill assignment  a suitable model might improve on the expert labeling.

We considered various methods  including fragmentation-coagulation processes [23] and the
distance-dependent Chinese restaurant process [4]. In this article  we describe a straightfor-
ward approach based on the Chinese restaurant process (CRP) [1]  which induces a distri-
bution over partitions. The CRP is cast metaphorically in terms of a Chinese restaurant in
which each entering customer chooses a table at which to sit. Denoting the table at which
customer i sits as Yi  customer i can take a seat at an occupied table y with P (Yi = y) ∝ ny
or at an empty table with P (Yi = Ntable + 1) ∝ α  where Ntable is the number of occupied
tables and ny is the number of customers currently seated at table y.

The weighted Chinese restaurant process (WCRP) [10] extends this metaphor by suppos-
ing that customers each have a ﬁxed aﬃliation and are biased to sit at tables with other
customers having similar aﬃliations. The WCRP is nothing more than the posterior over
table assignments given a CRP prior and a likelihood function based on aﬃliations. In the
mapping of the WCRP to our domain  customers correspond to exercises  tables to distinct
skills  and aﬃliations to expert labels. The WCRP thus partitions the exercises into groups
sharing a common skill  with a bias to assign the same skill to exercises having the same
expert label.
The WCRP is speciﬁed in terms of a set of parameters θ ≡ {θ1  . . .   θNtable}  where θy
represents the aﬃliation associated with table y. In our domain  the aﬃliation corresponds
to one of the expert labels: θy ∈ {1  . . .   Nskill}. From a generative modeling perspective 
the aﬃliation of a table inﬂuences the aﬃliations of each customer seated at the table. Using
Xi to denote the aﬃliation of customer i—or equivalently  the expert label associated with
exercise i—we make the generative assumption:

P (Xi = x|Yi = y  θ) ∝ βδx θy + 1 − β  

where δ is the Kronecker delta and β is the previously mentioned bias. With β = 0  a
customer is equally likely to have any aﬃliation; with β = 1  all customers at a table will
have the table’s aﬃliation. With uniform priors on θy  the conditional distribution on θy is:

where X(y) is the set of aﬃliations of customers seated at table y and na
is the number of customers at table y with aﬃliation a.

Xi∈X(y) δxi a

P (θy|X(y)) ∝ (1 − β)−n

θy
y

y ≡(cid:80)

Marginalizing over θ  the WCRP speciﬁes a distribution over table assignments for a new
customer: an occupied table y ∈ {1  . . .   Ntable} is chosen with probability

P (Yi = y|Xi  X(y)) ∝ ny

1 + β(κxi
1 + β(Nskill

y − 1)
−1 − 1)

  with κa

y ≡

(cid:80)Nskill
(1 − β)−na
˜a=1 (1 − β)−n˜a

y

y

.

(1)

κa
y is a softmax function that tends toward 1 if a is the most common aﬃliation among
customers at table y  and tends toward 0 otherwise. In the WCRP  an empty table Ntable +1
is selected with probability

(2)
We choose to treat α not as a constant but rather deﬁne α ≡ α(cid:48)(1 − β) where α(cid:48) becomes
the free parameter of the model that modulates the expected number of occupied tables 
and the term 1 − β serves to give the model less freedom to assign new tables when the

P (Yi = Ntable + 1) ∝ α.

3

aﬃliation bias is high. (We leave the constant in the denominator of Equation 1 so that α
has the same interpretation regardless of β.)

For β = 0  the WCRP reduces to the CRP and expert labels are ignored. Although the
WCRP is undeﬁned for β = 1  it is deﬁned in the limit β → 1  and it produces a seating
arrangement equivalent to the expert labels with probability 1. For intermediate β  the
expert labels serve as an intermediate constraint. For any β  the WCRP seating arrangement
speciﬁes a skill assignment over exercises.

2.2 BKT: A theory of human skill acquisition

In the previous section  we described a prior over skill assignments. Given an assignment 
we turn to a theory of the temporal dynamics of human skill acquisition. Suppose that a
particular student practices a series of exercises  {e1  e2  . . .   et  . . .   eT}  where the subscript
indicates order and each exercise et depends on a corresponding skill  st.1 We assume that
whether or not a student responds correctly to exercise et depends solely on the student’s
mastery of st. We further assume that when a student works on et  it has no eﬀect on
the student’s mastery of other skills ˜s  ˜s (cid:54)= st. These assumptions—adopted by nearly
all past models of student learning—allow us to consider each skill independently of the
others. Thus  for skill ˜s  we can select its subset of exercises from the sequence  e˜s = {et |
st = ˜s}  preserving order in the sequence  and predict whether the student will answer
each exercise correctly or incorrectly. Given the uncertainty in such predictions  models
typically predict the joint likelihood over the sequence of responses  P (R1  . . .   R|e˜s|)  where
the binary random variable Rt indicates the correctness of the response to et.

The focus of our research is not on developing novel models of skill acquisition. Instead 
we incorporate a simple model that is a mainstay of the ﬁeld  Bayesian knowledge tracing
(BKT) [6]. BKT is based on a theory of all-or-none human learning [2] which postulates
that a student’s knowledge state following trial t  Kt  is binary: 1 if the skill has been
mastered  0 otherwise. BKT is a hidden Markov model (HMM) with internal state Kt and
emissions Rt.

Because BKT is typically used to model practice over brief intervals  the model assumes
no forgetting  i.e.  K cannot transition from 1 to 0. This assumption constrains the time-
varying knowledge state: it can make at most one transition from 0 to 1 over the sequence
of trials. Consequently  the {Kt} can be replaced by a single latent variable  T   that denotes
the trial following which a transition is made  leading to the BKT generative model:

(cid:26)λL

P (T = t|λL  λM ) =

(1 − λL)λM (1 − λM )t−1

if t = 0
if t > 0

P (Rt = 1|λG  λS  T ) =

(cid:26)λG

1 − λS

if i ≤ T
otherwise 

(3)

(4)

where λL is the probability that a student has mastered the skill prior to performing the
ﬁrst exercise  λM is the transition probability from the not-mastered to mastered state 
λG is the probability of correctly guessing the answer prior to skill mastery  and λS is the
probability of answering incorrectly due to a slip following skill mastery.

Although we have chosen to model student learning with BKT  any other probabilistic
model of student learning could be used in conjunction with our approach to skill discov-
ery  including more sophisticated variants of BKT [11] or models of knowledge state with
continuous dynamics [21]. Further  our approach does not require BKT’s assumption that
learning a skill is conditionally independent of the practice history of other skills. However 
the simplicity of BKT allows one to conduct modeling on a relatively large scale.

1To tie this notation to the notation of the previous section  st ≡ yet   i.e.  the table assignments
of the WCRP correspond to skills  and exercise et is seated at table yet . Note that i in the previous
section was used as an index over distinct exercises  whereas t in this section is used as an index
over trials. The same exercise may be presented multiple times.

4

3 Implementation

We perform posterior inference through Markov chain Monte Carlo (MCMC) sampling.
The conditional probability for Yi given the other variables is proportional to the product
of the WCRP prior term and the likelihood of each student’s response sequence. The prior
term is given by Equations 1 and 2  where by exchangeability we can take Yi to be the
last customer to enter the restaurant and where we analytically marginalize θ. For an
existing table  the likelihood is given by the BKT HMM emission sequence probability. For
a new table  we must add an extra step to calculating the emission sequence probability
because the BKT parameters do not have conjugate priors. We used Algorithm 8 from [16] 
which eﬀectively produces a Monte Carlo approximation to the intractable marginal data
likelihood  integrating out over the BKT parameters that could be drawn for the new table.

For lack of conjugacy and any strong prior knowledge  we give each table’s λL  λM   and λS
independent uniform priors on [0  1]. Because we wish to interpret BKT’s K = 1 state as a
“learned” state  we parameterize λG as being a fraction of 1 − λS  where the fraction has a
uniform prior on [0  1]. We give log(1−β) a uniform prior on [−5  0] based on the simulations
described in Section 4.1  and α(cid:48) is given an improper uniform prior with support on α(cid:48) > 0.
Because of the lack of conjugacy  we explicitly represent each table’s BKT parameters during
sampling. In each iteration of the sampler  we update the table assignments of each exercise
and then apply ﬁve axis-aligned slice sampling updates to each table’s BKT parameters and
to the hyperparameters β and α(cid:48) [17].
For all simulations  we run the sampler for 200 iterations and discard the ﬁrst 100 as the
burn-in period. The seating arrangement is initialized to the expert-provided skills; all other
parameters are initialized by sampling from the generative model. We use the post burn-in
samples to estimate the expected posterior probability of a student correctly responding in
a trial  integrating out over uncertainty in all skill assignments  BKT parameterizations 
and hyperparameters. We explored using more iterations and a longer burn-in period but
found that doing so did not yield appreciable increases in training or test data likelihoods.

4 Simulations
4.1 Sampling from the WCRP

We generated synthetic exercise-skill assignments via a draw from a CRP prior with α = 3
and Nexercise = 100. Using these assignments as both the ground-truth and expert labels  we
then simulated draws from the WCRP to determine the eﬀect of β (the expert labeling bias)
and α(cid:48) (concentration scaling parameter; see Equation 2) on the model’s behavior. Figure 1a
shows the reconstruction score  a measure of similarity between the induced assignment and
the true labels. This score is the diﬀerence between (1) the proportion of pairs of exercises
that belong to the same true skill that are assigned to the same recovered skill  and (2)
the proportion of pairs of exercises that belong to diﬀerent true skills that are assigned to
diﬀerent recovered skills. The score is in [0  1]  with 0 indicating no better than a chance
relationship to the true labels  and 1 indicating the true labels are recovered exactly. The
reported score is the mean over replications of the simulation and MCMC samples. As β
increases  the recovered skills better approximate the expert (true) skills  independent of
α(cid:48). Figure 1b shows the expected interaction between α(cid:48) and β on the number of occupied
tables (induced skills): only when the bias is weak does α(cid:48) have an eﬀect.

4.2 Skill recovery from synthetic student data

We generated data for Nstudent synthetic students responding to Nexercise exercises pre-
sented in a random order for each student. Using a draw from the CRP prior with α = 3 
we generated exercise-skill assignments. For each skill  we generated sequences of student
correct/incorrect responses via BKT  with parameters sampled from plausible distributions:
λL ∼ Uniform(0  1)  λM ∼ Beta(10  30)  λG ∼ Beta(1  9)  and λS ∼ Beta(1  9).
Figure 1c shows the model’s reconstruction of true skills for 24 replications of the simulation
with Nstudent = 100 and Nexercise = 200  varying β  providing a set of expert skill labels
that were either the true labels or a permutation of the true labels. The latter conveys no
information about the true labels. The most striking feature of the result is that the model

5

Figure 1: (a b) Eﬀect of varying expert labeling bias (β) and α(cid:48) on sampled skill assignments
from a WCRP; (c) Eﬀect of expert labels and β on the full model’s reconstruction of the
true skills from synthetic data

Figure 2: Eﬀect of expert labels  Nstudent  Nexercise  and Nskill on the model’s reconstruction
of the true skills from synthetic data

does an outstanding job of reconstructing the true labeling whether the expert labels are
correct or not. Only when the bias β is strong and the expert labels are erroneous does the
model’s reconstruction performance falter. The bottom line is that a good expert labeling
can help  whereas a bad expert labeling should be no worse than no expert-provided labels.
In a larger simulation  we systematically varied Nstudent ∈ {50  100  150  200}  Nexercise ∈
{100  200  300}  and assigned the exercises to one of Nskill ∈ {10  20  30} skills via uniform
multinomial sampling. Figure 2 shows the result from 30 replications of the simulation
using expert labels that were either true or permuted (left and right panels  respectively).
With a good expert labeling  skill reconstruction is near perfect with Nstudent ≥ 100 and an
Nexercise : Nskill ratio of at least 10. With a bad expert labeling  more data is required to
obtain accurate reconstructions  say  Nstudent ≥ 200. As one would expect  a helpful expert
labeling can overcome noisy or inadequate data.

4.3 Evaluation of student performance data

We ran simulations on ﬁve student performance datasets (Table 1). The datasets varied
in the number of students  exercises  and expert skill labels; the students in the datasets
ranged in age from middle school to college. Each dataset consists of student identiﬁers 
exercise identiﬁers  trial numbers  and binary indicators of response correctness from stu-
dents undergoing variable-length sequences of exercises over time.2 Exercises may appear
in diﬀerent orders for each student and may occur multiple times for a given student.

2For the DataShop datasets  exercises were identiﬁed by concatenating what they call the prob-
lem hierarchy  problem name  and the step name columns. Expert-provided skill labels were iden-
tiﬁed by concatenating the problem hierarchy column with the skill column following the same
practice as in [19  18]. The expert skill labels infrequently associate an exercise with multiple skills.
For such exercises  we treat the combination of skills as one unique skill.

6

00.20.40.60.8100.20.40.60.81expert labeling bias (β)reconstruction score(a) 00.20.40.60.81510152025expert labeling bias (β)# occupied tables(b) 00.20.40.60.810.750.80.850.90.951expert labeling bias (β)reconstruction scorepermuted labelstrue labels(c)α’ = 2.0α’ = 5.0α’ = 10.0α’ = 2.0α’ = 5.0α’ = 10.0reconstruction score0.10.20.30.40.50.60.70.80.9501001502001005010015020020050100150200300 # students # exercisestrue labels10 skills20 skills30 skillsreconstruction score0.10.20.30.40.50.60.70.80.9501001502001005010015020020050100150200300 # students # exercisespermuted labels10 skills20 skills30 skillssource

dataset

PSLC DataShop [12]
PSLC DataShop [12]
PSLC DataShop [12]

[15]

fractions game
physics tutor

engineering statics
Spanish vocabulary

PSLC DataShop [12]

geometry tutor

51
66
333
182
59

#

#
students exercises
179

# # skills # skills

β
trials (expert) (WCRP) (WCRP)
0.886
4 349
0.947
4 816 110 041
0.981
1 223 189 297
0.996
409 578 726
139
5 104
0.997

7.9
49.4
99.2
183
19.7

45
652
156
221
18

Table 1: Five student performance datasets used in simulations

We compared a set of models which we will describe shortly. For each model  we ran ten
replications of ﬁve-fold cross validation on each dataset. In each replication  we randomly
partitioned the set of all students into ﬁve equally sized disjoint subsets. In each replication-
fold  we collected posterior samples using our MCMC algorithm given the data recorded for
students in four of the ﬁve subsets. We then used the samples to predict the response
sequences (correct vs.
incorrect) of the remaining students. On occasion  students in the
test set were given exercises that had not appeared in the training set. In those cases  the
model used samples from Equations 1-2 to predict the new exercises’ skill assignments.

The models we compare diﬀer in how skills are assigned to exercises. However  every model
uses BKT to predict student performance given the skill assignments. Before presenting
results from the models  we ﬁrst need to verify the BKT assumption that students improve
on a skill over time. We compared BKT to a baseline model which assumes a stationary
probability of a correct response for each skill. Using the expert-provided skills  BKT
achieves a mean 11% relative improvement over the baseline model across the ﬁve datasets.
Thus  BKT with expert-provided skills is sensitive to the temporal dynamics of learning.

To evaluate models  we use BKT to predict the test students’ data given the model-speciﬁed
skill assignment. We calculated several prediction-accuracy metrics  including RMSE and
mean log loss. We report area under the ROC curve (AUC)  though all metrics yield the
same pattern of results. Figure 3 shows the mean AUC  where larger AUC values indicate
better performance. Each graph is a diﬀerent dataset. The ﬁve colored bars represent
alternative approaches to determining the exercise-skill assignments. LFA uses skills from
Learning Factors Analysis  a semi-automated technique that reﬁnes expert-provided skills
[5]; LFA skills are available for only the Fractions and Geometry datasets. Single assigns
the same skill to all exercises. Exercise speciﬁc assigns a diﬀerent skill to each exercise.
Expert uses the expert-provided skills. WCRP(0) uses the WCRP with no bias toward
the expert-provided skills  i.e.  β = 0  which is equivalent to a CRP. WCRP(β) is our
technique with the level of bias inferred from the data.

The performance of expert is unimpressive. On Fractions  expert is worse than the single
baseline. On Physics and Statics  expert is worse than the exercise-speciﬁc baseline.
WCRP(β) is consistently better than both the single and exercise-speciﬁc baselines
across all ﬁve datasets. WCRP(β) also outperforms expert by doing signiﬁcantly better
on three datasets and equivalently on two. Finally  WCRP(β) is about the same as LFA
on Geometry  but substantially better on Fractions. (A comparison between these models
is somewhat inappropriate. LFA has an advantage because it was developed on Geometry
and is provided entire data sets for training  but it has a disadvantage because it was not
designed to improve the performance of BKT.) Surprisingly  WCRP(0)  which ignores
the expert-provided skills  performs nearly as well as WCRP(β). Only for Geometry was
WCRP(β) reliably better (two-tailed t-test with t(49) = 5.32  p < .00001). The last
column of Table 1  which shows the mean inferred β value for WCRP(β)  helps explain
the pattern of results. The datasets are arranged in order of smallest to largest inferred
β  both in Table 1 and Figure 3. The inferred β values do a good job of indicating where
WCRP(β) outperforms expert: the model infers that the expert skill assignments are
useful for Geometry and Spanish  but less so for the other datasets. Where the expert skill
assignments are most useful  WCRP(0) suﬀers. On the datasets where WCRP(β) is
highly biased  the mean number of inferred skills (Table 1  column 7) closely corresponds
to the number of expert-provided skills.

7

Figure 3: Mean AUC on test students’ data for six diﬀerent methods of determining skill
assignments in BKT. Error bars show ±1 standard error of the mean.

5 Discussion

We presented a technique that discovers a set of cognitive skills which students use for
problem solving in an instructional domain. The technique assumes that when a student
works on a sequence of exercises requiring the same skill  the student’s expected performance
should monotonically improve. Our technique addresses two challenges simultaneously: (1)
determining which skill is required to correctly answer each exercise  and (2) modeling a
student’s dynamical knowledge state for each skill. We conjectured that a technique which
jointly addresses these two challenges might lead to more accurate predictions of student
performance than a technique which was based on expert skill labels. We found strong
evidence for this conjecture: On 3 of 5 datasets  skill discovery yields signiﬁcantly improved
predictions over ﬁxed expert-labeled skills; on the other two datasets  the two approaches
obtain comparable results.

Counterintuitively  incorporating expert labels into the prior provided little or no beneﬁt.
Although one expects prior knowledge to play a smaller role as datasets become larger  we
observed that even medium-sized datasets (relative to the scale of today’s big data) are
suﬃcient to support a pure data-driven approach. In simulation studies with both synthetic
data and actual student datasets  50-100 students and roughly 10 exercises/skill provides
strong enough constraints on inference that expert labels are not essential.

Why should the expert skill labeling ever be worse than an inferred labeling? After all  edu-
cators design exercises to help students develop particular cognitive skills. One explanation
is that educators understand the knowledge structure of a domain  but have not parsed the
domain at the right level of granularity needed to predict student performance. For exam-
ple  a set of exercises may all tap the same skill  but some require a deep understanding
of the skill whereas others require only a superﬁcial or partial understanding. In such a
case  splitting the skill into two subskills may be beneﬁcial. In other cases  combining two
skills which are learned jointly may subserve prediction  because the combination results
in longer exercise histories which provide more context for prediction. These arguments
suggest that fragmentation-coagulation processes [23] may be an interesting approach to
leveraging expert labelings as a prior.

One limitation of the results we report is that we have yet to perform extensive comparisons
of our technique to others that jointly model the mapping of exercises to skills and the
prediction of student knowledge state. Three matrix factorization approaches have been
proposed  two of which are as yet unpublished [24  22  14]. The most similar work to ours 
which also assumes each exercise is mapped to a single skill  is the topical HMM [8  9]. The
topical HMM diﬀers from our technique in that the underlying generative model supposes
that the exercise-skill mapping is inherently stochastic and thus can change from trial to
trial and student to student. (Also  it does not attempt to infer the number of skills or
to leverage expert-provided skills.) We have initated collaborations with several authors of
these alternative approaches  with the goal of testing the various approaches on exactly the
same datasets with the same evaluation metrics.

Acknowledgments This research was supported by NSF grants BCS-0339103 and BCS-
720375 and by an NSF Graduate Research Fellowship to R. L.

8

.60.65.70.75LFASingleExercise SpecificExpertWCRP(0)WCRP(β)AUC Fractions .55.60.65.70SingleExercise SpecificExpertWCRP(0)WCRP(β) Physics .60.65.70.75.80SingleExercise SpecificExpertWCRP(0)WCRP(β) Statics .70.75.80.85SingleExercise SpecificExpertWCRP(0)WCRP(β) Spanish .55.60.65.70.75LFASingleExercise SpecificExpertWCRP(0)WCRP(β) Geometry References
[1] D. Aldous. Exchangeability and related topics. In ´Ecole d’´et´e de probabilit´es de Saint-Flour 

pages 1–198. Springer  Berlin  1985.

[2] R. Atkinson. Optimizing the learning of a second-language vocabulary. Journal of Experimental

Psychology  96:124–129  1972.

[3] T. Barnes. The Q-matrix method: Mining student response data for knowledge. In J. Beck 

editor  Proceedings of the 2005 AAAI Educational Data Mining Workshop  2005.

[4] D. Blei and P. Frazier. Distance dependent Chinese restaurant processes. Journal of Machine

Learning Research  12:2383–2410  2011.

[5] H. Cen  K. Koedinger  and B. Junker. Learning factors analysis—A general method for cogni-
tive model evaluation and improvement. In M. Ikeda  K. Ashley  and T. Chan  editors  Intell.
Tutoring Systems  volume 4053 of Lec. Notes in Comp. Sci.  pages 164–175. Springer  2006.

[6] A. Corbett and J. Anderson. Knowledge tracing: Modeling the acquisition of procedural

knowledge. User Modeling & User-Adapted Interaction  4:253–278  1995.

[7] A. Corbett  K. Koedinger  and J. Anderson. Intelligent tutoring systems. In M. Helander 
T. Landauer  and P. Prabhu  editors  Handbook of Human Computer Interaction  pages 849–
874. Elsevier Science  Amsterdam  1997.

[8] J. Gonz´alez-Brenes and J. Mostow. Dynamic cognitive tracing: Towards uniﬁed discovery of

student and cognitive models. In Proc. of the 5th Intl. Conf. on Educ. Data Mining  2012.

[9] J. Gonz´alez-Brenes and J. Mostow. What and when do students learn? Fully data-driven joint
estimation of cognitive and student models. In Proc. 6th Intl. Conf. Educ. Data Mining  2013.
[10] H. Ishwaran and L. James. Generalized weighted Chinese restaurant processes for species

sampling mixture models. Statistica Sinica  13:1211–1235  2003.

[11] M. Khajah  R. Wing  R. Lindsey  and M. Mozer. Integrating latent-factor and knowledge-

tracing models to predict individual diﬀerences in learning. EDM 2014  2014.

[12] K. Koedinger  R. Baker  K. Cunningham  A. Skogsholm  B. Leber  and J. Stamper. A data
repository for the EDM community: The PSLC DataShop. In C. Romero  S. Ventura  M. Pech-
enizkiy  and R. Baker  editors  Handbook of Educ. Data Mining  http://pslcdatashop.org  2010.
[13] K. Koedinger  A. Corbett  and C. Perfetti. The knowledge-learning-instruction framework:
Bridging the science-practice chasm to enhance robust student learning. Cognitive Science 
36(5):757–798  2012.

[14] A. S. Lan  C. Studer  and R. G. Baraniuk. Time-varying learning and content analytics via
sparse factor analysis. In ACM SIGKDD Conf. on Knowledge Disc. and Data Mining  2014.
[15] R. Lindsey  J. Shroyer  H. Pashler  and M. Mozer. Improving student’s long-term knowledge

retention with personalized review. Psychological Science  25:639–647  2014.

[16] R. Neal. Markov chain sampling methods for dirichlet process mixture models. Journal of

Computational and Graphical Statistics  9(2):249–265  2000.

[17] R. Neal. Slice sampling. The Annals of Statistics  31(3):705–767  2003.
[18] Z. A. Pardos and N. T. Heﬀernan. KT-IDEM: Introducing item diﬃculty to the knowledge

tracing model. In User Modeling  Adaption and Pers.  pages 243–254. Springer  2011.

[19] Z. A. Pardos  S. Trivedi  N. T. Heﬀernan  and G. N. S´ark¨ozy. Clustered knowledge tracing. In
S. A. Cerri  W. J. Clancey  G. Papadourakis  and K. Panourgia  editors  ITS  volume 7315 of
Lecture Notes in Computer Science  pages 405–410. Springer  2012.

[20] A. Raﬀerty  E. Brunskill  T. Griﬃths  and P. Shafto. Faster teaching by POMDP planning.

In Proc. of the 15th Intl. Conf. on AI in Education  2011.

[21] A. Smith  L. Frank  S. Wirth  M. Yanike  D. Hu  Y. Kubota  A. Graybiel  W. Suzuki  and
E. Brown. Dynamic analysis of learning in behav. experiments. J. Neuro.  24:447–461  2004.
[22] J. Sohl-Dickstein. Personalized learning and temporal modeling at Khan Academy. Invited

Talk at NIPS Workshop on Data Driven Education  2013.

[23] Y. Teh  C. Blundell  and L. Elliott. Modelling genetic variations with fragmentation-

coagulation processes. In Advances In Neural Information Processing Systems  2011.

[24] N. Thai-Nghe  L. Drumond  T. Horv´ath  A. Krohn-Grimberghe  A. Nanopoulos  and
L. Schmidt-Thieme. Factorization techniques for predicting student performance. In O. Santos
and J. Botcario  editors  Educ. Rec. Systems and Technologies  pages 129–153. 2011.

[25] J. Whitehill. A stochastic optimal control perspective on aﬀect-sensitive teaching. PhD thesis 

Department of Computer Science  UCSD  2012.

9

,Robert Lindsey
Mohammad Khajah
Michael Mozer
Oren Tadmor
Tal Rosenwein
Shai Shalev-Shwartz
Yonatan Wexler
Amnon Shashua
Jianwei Yang
Zhile Ren
Chuang Gan
Hongyuan Zhu
Devi Parikh