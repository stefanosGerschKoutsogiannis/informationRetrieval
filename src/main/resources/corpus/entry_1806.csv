2018,Empirical Risk Minimization in Non-interactive Local Differential Privacy Revisited,In this paper  we revisit the Empirical Risk Minimization problem in the non-interactive local model of differential privacy. In the case of constant or low dimensions ($p\ll n$)  we first show that if the  loss function is $(\infty  T)$-smooth   we can avoid a dependence of the  sample complexity  to achieve error $\alpha$  on the exponential of the dimensionality $p$ with base $1/\alpha$  ({\em i.e. } $\alpha^{-p}$) 
 which answers a question in \cite{smith2017interaction}.  Our approach is based on polynomial approximation. Then  we propose player-efficient algorithms with $1$-bit communication complexity and $O(1)$ computation cost for each player. The error bound is asymptotically the same as the original one. With some additional assumptions  we also give an efficient algorithm for the server. 
 In the case of high dimensions ($n\ll p$)  we show that if the loss function is a convex generalized linear function   the error  can be bounded by using the Gaussian width of the constrained set  instead of $p$  which improves the one in    
  \cite{smith2017interaction}.,Empirical Risk Minimization in Non-interactive

Local Differential Privacy Revisited ∗

Di Wang
Jinhui Xu
Department of Computer Science and Engineering

Marco Gaboardi

Email:{dwang45 gaboardi jinhui}@buffalo.edu

State University of New York at Buffalo

Buffalo  NY  14260

Abstract

In this paper  we revisit the Empirical Risk Minimization problem in the non-
interactive local model of differential privacy.
In the case of constant or low
dimensions (p (cid:28) n)  we ﬁrst show that if the loss function is (∞  T )-smooth 
we can avoid a dependence of the sample complexity  to achieve error α  on the
exponential of the dimensionality p with base 1/α (i.e.  α−p)  which answers a
question in [19]. Our approach is based on polynomial approximation. Then  we
propose player-efﬁcient algorithms with 1-bit communication complexity and O(1)
computation cost for each player. The error bound is asymptotically the same
as the original one. With some additional assumptions  we also give an efﬁcient
algorithm for the server. In the case of high dimensions (n (cid:28) p)  we show that if
the loss function is a convex generalized linear function  the error can be bounded
by using the Gaussian width of the constrained set  instead of p  which improves
the one in [19].

1

Introduction

Differential privacy [7] has emerged as a rigorous notion for privacy which allows accurate data
analysis with a guaranteed bound on the increase in harm for each individual to contribute her
data. Methods to guarantee differential privacy have been widely studied  and recently adopted in
industry [15  8].
Two main user models have emerged for differential privacy: the central model and the local one. In
the central model  data are managed by a trusted central entity which is responsible for collecting
them and for deciding which differentially private data analysis to perform and to release. A classical
use case for this model is the one for collecting census data [9]. In the local model  each individual
manages his/her proper data and discloses them to a server through some differentially private
mechanisms. The server collects the (now private) data of each individual and combines them into a
resulting data analysis. A classical application of this model is the one aiming at collecting statistics
from user devices like in the case of Google’s Chrome browser [8]  and Apple’s iOS-10 [15  20].
In the local model  there are two basic kinds of protocols: interactive and non-interactive. Bassily
and Smith [2] have recently investigated the power of non-interactive differentially private protocols.
This type of protocols seems to be more appealing to real world applications  due to the fact that they
can be implemented more easily (i.e.  less inﬂuenced by the network latency issue). Both Google and
Apple use the non-interactive model in their projects [15  8].

∗This research was supported in part by the National Science Foundation (NSF) under Grant No. CCF-

1422324  CCF-1716400  CCF-1718220 and CNS-1565365.

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

Despite being used in industry  the local model has been much less studied than the central one. Part
of the reason for this is that there are intrinsic limitations in what one can do in the local model.
As a consequence  many basic questions  that are well studied in the central model  have not been
completely understood in the local model  yet.
In this paper  we study differentially private Empirical Risk Minimization in the non-interactive local
model. Before showing our contributions and discussing comparisons with previous works  we ﬁrst
discuss our motivations.
Problem setting [19  24  23] Given a convex  closed and bounded constraint set C ⊆ Rp  a
data universe D  and a loss function (cid:96) : C × D (cid:55)→ R. A dataset D = {x1  x2 ···   xn} ∈ Dn
deﬁnes an empirical risk function: ˆL(θ; D) = 1
i=1 (cid:96)(θ  xi). When the inputs are drawn i.i.d
from an unknown underlying distribution P on D  we can also deﬁne the population risk function:
n
LP (θ) = ED∼P n [(cid:96)(θ; D)]. Now we have the following two kinds of excess risk  one is empirical risk 
i.e. ErrD(θpriv) = ˆL(θpriv; D) − minθ∈C ˆL(θ; D)  the other one is population risk  i.e. ErrP (θpriv) =
LP (θpriv) − minθ∈C LP (θ).
The problem that we study in this paper is ﬁnding θpriv ∈ C under non-interactive local differential
privacy (see Deﬁnition 1) which makes the empirical and population excess risk as low as possible.
Alternatively  when dimensionality p is a constant or low  we can express this problem in terms of
sample complexity as ﬁnding n as small as possible for achieving ErrD ≤ α and ErrP ≤ α  where α
is the user speciﬁed error tolerance (or simply called error).

(cid:80)n

Motivation Smith et al. [19] prove the following result concerning the problem for general convex
1-Lipschitz loss functions over a bounded constraint set.
Theorem 1. Under the assumptions above  there is a non-interactive -LDP algorithm such that for
all distribution P on D  with probability 1 − β  we have

ErrP (θpriv) ≤ ˜O(cid:0)(

√

p+1(cid:1).

1

p log2(1/β)

2n

)

(1)

A similar result holds for ErrD  with at least Ω(n
p+1 ) for both computation and communication
complexity for each user. Alternatively  to achieve error α  the sample complexity must satisﬁes
√
pcp−2α−(p+1))  where c is some constant (approximately 2). More importantly  they
n = ˜Ω(
also show that generally  the dependence of the sample size over the dimensionality p  in the terms
α−(p+1) and cp  is unavoidable.

1

the sample complexity satisﬁes n > O(cid:0)p( 8r

This situation is somehow undesirable: when the dimensionality is high and the target error is low  the
dependency on α−(p+1) could make the sample size quite large. However  several results have already
shown that for some speciﬁc loss functions  the exponential dependency on the dimensionality can
be avoided. For example  Smith et al. [19] show that  in the case of linear regression  there is a non-
interactive (  δ)-LDP algorithm2 whose sample complexity for achieving error α for the empirical
risk is n = Ω(p log(1/δ)−2α−2). Similarly  Zheng et al. [27] showed that for logistic regression  if
r are independent of p  then there is a non-interactive (  δ)-LDP algorithm with ErrP (θpriv) ≤ α.
This propels us to the following natural questions: i) Is there any algorithm that has a lower sample
complexity than the one in Theorem 1? ii) The above discussion indicates that there is a gap between
the general case and the case of speciﬁc loss functions. Is it possible to introduce some natural
conditions on the loss function that guarantee non-interactive -LDP with sample complexity that
is not exponential in the dimensionality p? iii) The computation and communication costs for each
user in the protocols of Smith et al. [19] depend on n  which could be high for large datasets. Is it
possible to make them independent of n? iv) The bounds in Smith et al. [19] are not very meaningful
in high dimensions. However  in machine learning it is quite common to have high dimensionality 
i.e.  n (cid:28) p. Thus  can we obtain some more meaningful bounds for the high dimensional case?
Below we investigate the answer to each question.

α22 )(cid:1)  where c and

α )4r log log(8r/α)( 4r

 )2cr log(8r/α)+2( 1

2Although  these two results are formulated for non-interactive (  δ)-LDP  in the rest of the paper we will

focus on non-interactive -LDP algorithms.

2

Our Contributions

4 )pα−(2+ p

˜Ω(cid:0)(c0p 1

2 )−2(cid:1)  the excess empirical risk is ensured to be ErrD ≤ α  If the

1. We ﬁrst show that by using Bernstein polynomial approximation  it is possible to achieve a
non-interactive -LDP algorithm in constant or low dimensions with the following properties.
If the loss function is (8  T )-smooth (see Deﬁnition 5)  with a sample complexity of n =
loss function is (∞  T )-smooth  the sample complexity can be further improved to n ≥
pp−2α−4)  where Dp depends only on p. Note that in the ﬁrst case  the sample
˜Ω(4p(p+1)D2
complexity is lower than the one in [19] when α ≤ O( 1
p )  and in the second case  the sample
complexity depends only polynomially on α−1  instead of the exponential dependence as in
[19]. Furthermore  our algorithm does not assume convexity for the loss function and thus
can be applied to non-convex loss functions.

2. Then  we address the efﬁciency issue  which has only been partially studied before [19].
Following an approach similar to [2]  we propose an algorithm for our loss functions which
has only 1-bit communication cost and O(1) computation cost for each client  and achieves
asymptotically the same error bound as the original one. Additionally  we show also a novel
analysis for the server. This shows that if the loss function is convex and Lipschitz and the
convex set satisﬁes some natural conditions  then we have an algorithm which achieves the
error bound of O(pα) and runs in polynomial time in 1
α (instead of exponential time as in
[19]) if the loss function is (∞  T )-smooth.

3. Next  we consider the high dimensional case  and show that if the loss function is a convex
generalized linear function  then an -LDP algorithm is achievable with its risk bound
depending only on n and the Gaussian Width of C  which is much smaller than the one in
[19]. Particularly  if C is an (cid:96)1 norm ball or a distribution simplex  the risk bound depends
only on n and log p  instead of p.

4. Lastly  we show the generality of our technique by applying the polynomial approximation
techniques to other problems. We give non-interactive -LDP algorithms for answering the
class of k-way marginals queries and the class of smooth queries  by using different type of
polynomials approximations (details are in Supplementary Material).

Methods

Sample Complexity
(omit Poly(p) terms)

˜Ω(4pα−(p+2)−2)

Claim 4 in
[19]
Theorem 10
in [19]
This Paper
This Paper

Communication
Cost
(each
user)
1

Computation
Cost (each
user)
O(1)

Running
time for the
server

O(cid:0)( 1
α)p(cid:1)

Assumptions

Lipschitz

˜Ω(2pα−(p+1)−2)

˜Ω(cid:0)(c0p 1

Ω(n

2 )−2(cid:1) 1

4 )pα−(2+ p

˜Ω(4p(p+1)D2

p−2α−4)

1

1

p+1 )

Ω(n

1

p+1 )

O(1)

O(1)

Not Men-
tioned
O(( 1
α)

O(cid:0)Poly( 1

2 )

and

Lipschitz
Convex
(8  T )-smooth

α)(cid:1) (∞  T )-smooth

p

Table 1: Comparisons with existing results in [19] (we assume p is a constant). When the error
α ≤ O( 1
p )  the sample complexity of (8  T )-smooth loss functions is less than the existing result.
When the error α ≤ O( 1
16p )  the sample complexity for (∞  T )-smooth loss functions is less than
the previous results.

Table 1 shows some comparisons with the results in [19]. Due to the space limit  all proofs and some
details of the algorithms are left to the Supplementary Material.

2 Related Works

ERM in the local model of differential privacy has been studied in [12  3  6  5  27  19  25]. Ka-
siviswanathan et al. [12] showed a general equivalence between learning in the local model and
learning in the statistical query model. Duchi et al. [6  5] gave the lower bound O(
n ) and optimal

√
√
d


3

algorithms for general convex optimization; however  their optimal procedure needs many rounds
of interactions. The works that are most related to ours are [27  19]. Zheng et al. [27] considered
some speciﬁc loss functions in high dimensions  such as sparse linear regression and kernel ridge
regression.
Note that although it also studied a class of loss functions (i.e.  Smooth Generalized Linear Loss
functions) and used the polynomial approximation approach  the functions investigated in our paper
are more general  which include linear regression and logistic regression  and the approximation
techniques are quite different. Smith et al. [19] studied general convex loss functions for population
excess risk and showed that the dependence on the exponential of the dimensionality is unavoidable.
In this paper  we show that such a dependence in the term of α is actually avoidable for a class of loss
functions. This even holds for non-convex loss functions  which is quite different from all existing
works. Also we study the high dimensional case by using dimension reduction. The polynomial
approximation approach has been used under central model in [1  26  21  27] and the dimension
reduction has been used in local model in [2  27].

3 Preliminaries

In LDP  we have a data universe D  n players with each
Differential privacy in the local model.
holding a private data record xi ∈ D  and a server that is in charge of coordinating the protocol. An
LDP protocol proceeds in T rounds. In each round  the server sends a message  which we sometime
call a query  to a subset of the players  requesting them to run a particular algorithm. Based on the
queries  each player i in the subset selects an algorithm Qi  run it on her data  and sends the output
back to the server.
Deﬁnition 1. [12  19] An algorithm Q is -locally differentially private (LDP) if for all pairs
x  x(cid:48) ∈ D  and for all events E in the output space of Q  we have Pr[Q(x) ∈ E] ≤ ePr[Q(x(cid:48)) ∈ E].
A multi-player protocol is -LDP if for all possible inputs and runs of the protocol  the transcript of
player i’s interaction with the server is -LDP. If T = 1  we say that the protocol is  non-interactive
LDP.

Since we only consider non-interactive LDP
through the paper  we will use LDP as non-
interactive LDP below. As an example that will
be useful in the sequel  the next lemma shows an
-LDP algorithm for computing 1-dimensional
average.
Lemma 1. Algorithm 1 is -LDP. Moreover  if
player i ∈ [n] holds value vi ∈ [0  b] and n >
β with 0 < β < 1  then  with probability
log 2
at least 1 − β  the output a ∈ R satisﬁes: |a −

(cid:80)n
i=1 vi| ≤ 2b

(cid:113)

1
n

log 2
β√

n

.

Algorithm 1 1-dim LDP-AVG
1: Input: Player i ∈ [n] holding data vi ∈ [0  b] 
privacy parameter .
2: for Each Player i do
3:
4: end for
5: for The Server do
Output a = 1
6:
n
7: end for

Send zi = vi + Lap( b
 )

(cid:80)n

i=1 zi.

Bernstein polynomials and approximation.
We give here some basic deﬁnitions that will
be used in the sequel; more details can be found in [1  13  14].
Deﬁnition 2. Let k be a positive integer. The Bernstein basis polynomials of degree k are deﬁned as

(bv k; x).

4

(cid:1)xv(1 − x)k−v for v = 0 ···   k.

bv k(x) =(cid:0)k
degree k is deﬁned as Bk(f ; x) =(cid:80)k

v

Deﬁnition 3. Let f : [0  1] (cid:55)→ R and k be a positive integer. Then  the Bernstein polynomial of f of
v=0 f (v/k)bv k(x). We denote by Bk the Bernstein operator

Bk(f )(x) = Bk(f  x).
Deﬁnition 4. [14] Let h be a positive integer. The iterated Bernstein operator of order h is deﬁned
as the sequence of linear operators B(h)
k  where I = B0
k
. The iterated Bernstein
denotes the identity operator and Bi
polynomial of order h can be computed as B(h)
v k(x)  where b(h)
v k(x) =

k = I − (I − Bk)h =(cid:80)h
k (f ; x) = (cid:80)k

(cid:0)h
(cid:1)(−1)i−1Bi
k = Bk ◦ Bk−1
k
v=0 f ( v

k is deﬁned as Bi

k )b(h)

i=1

i

(cid:80)h

(cid:0)h
(cid:1)(−1)i−1Bi−1

k

i=1

i

Iterated Bernstein operator can well approximate multivariate (h  T )-smooth functions.
Deﬁnition 5. [14] Let h be a positive integer and T > 0 be a constant. A function f : [0  1]p (cid:55)→ R is
(h  T )-smooth if it is in class Ch([0  1]p) and its partial derivatives up to order h are all bounded by T .
We say it is (∞  T )-smooth  if for every h ∈ N it is (h  T )-smooth.
Deﬁnition 6. Assume f : [0  1]p (cid:55)→ R and let k1 ···   kp  h be positive integers. The multivariate
iterated Bernstein polynomial of order h at y = (y1  . . .   yp) is deﬁned as:

B(h)

k1 ... kp

(f ; y) =

f (

v1
k1

  . . .  

vp
kp

)

b(h)
vi ki

(yi).

(2)

p(cid:88)

kj(cid:88)

j=1

vj =0

p(cid:89)

i=1

(f ; y) if k = k1 = ··· = kp.

k = B(h)

We denote B(h)
Theorem 2. [1] If f : [0  1]p (cid:55)→ R is a (2h  T )-smooth function  then for all positive integers k and
y ∈ [0  1]p  we have |f (y) − B(h)
k (f ; y)| ≤ O(pT Dhk−h). Where Dh is a universal constant only
related to h.

k1 ... kp

Our settings We conclude this section by making explicitly the settings that we will consider
throughout the paper. We assume that there is a constraint set C ⊆ [0  1]p and for every x ∈ D and
θ ∈ C  (cid:96)(·  x) is well deﬁned on [0  1]p and (cid:96)(θ  x) ∈ [0  1]. These closed intervals can be extended to
arbitrarily bounded closed intervals. Our settings are similar to the ‘Typical Settings’ in [19]  where
C ⊆ [0  1]p appears in their Theorem 10  and (cid:96)(θ  x) ∈ [0  1] from their 1-Lipschitz requirement and
(cid:107)C(cid:107)2 ≤ 1.

4 Low Dimensional Case

Deﬁnition 6 and Theorem 2 tell us that if we know the value of the empirical risk function  i.e. the
k )  where (v1 ···   vp) ∈
average of the sum of loss functions  on each of the grid points ( v1
T = {0  1 ···   k}p for some large k  then we can approximate it well. Our main observation is that
this can be done in the local model by estimating the average of the sum of loss functions on each of
the grid points using Algorithm 1. This is the idea of Algorithm 2.

k ··· vp

k   v2

for Each Player i ∈ [n] do

parameter  > 0  and parameter k.
k   . . .   vp
k   . . .   vp

Algorithm 2 Local Bernstein Mechanism
1: Input: Player i ∈ [n] holding data xi ∈ D  public loss function (cid:96) : [0  1]p × D (cid:55)→ [0  1]  privacy
2: Construct the grid T = { v1
3: for Each grid point v = ( v1
4:
5:
6:
7:
8: end for
9: for The Server do
10:

k }{v1 ... vp}  where {v1  . . .   vp} ∈ {0  1 ···   k}p.
k ) ∈ T do

Construct Bernstein polynomial  as in (2)  for the perturbed empirical loss ˜L(v; D). Denote

(k+1)p and b = 1 and denote the output as ˜L(v; D).

end for
Run Algorithm 1 with  = 

Calculate (cid:96)(v; xi).

˜L(·  D) the corresponding function.

Compute θpriv = arg minθ∈C ˜L(θ; D).

11:
12: end for

Theorem 3. For any  > 0 and 0 < β < 1  Algorithm 2 is -LDP. Assume that the loss function
(cid:96)(·  x) is (2h  T )-smooth for all x ∈ D  some positive integer h  and constant T . If n   and β satisfy
the condition of n = Ω
  with probability
at least 1 − β we have:

  then by setting k = O

2(h+1)p(cid:113)

β 4p(h+1)
2D2
h

( Dh

log 1
β

pn

√

h+p

)

1

(cid:16) log 1

(cid:16)

(cid:17)

ErrD(θpriv) ≤ ˜O

h

2(h+p) ( 1

p

2(h+p) 2(h+1)p h

h+p

p

p

p+h
β )D
h
n

h

2(h+p) 

h

h+p

 

(3)

(cid:17)
(cid:16) log

(cid:17)

where ˜O hides the log and T terms.

5

2p
h

p

β D

h p

h 4(h+1)p−2α−(2+ 2p

From (3) we can see that in order to achieve error α  the sample complexity needs to be n =
˜Ω(log 1
Corollary 1. If the loss function (cid:96)(·  x) is (8  T )-smooth for all x ∈ D and some constant T   and
n    β  k satisfy the condition in Theorem 3 with h = 4  then with probability at least 1 − β  the

sample complexity to achieve α error is n = ˜O(cid:0)α−(2+ p
Note that the sample complexity for general convex loss functions in [19] is n = ˜Ω(cid:0)α−(p+1)−22p(cid:1) 

h )). This implies the following special cases.

which is considerably worse than ours when α ≤ O( 1
p ).
Corollary 2. If the loss function (cid:96)(·  x) is (∞  T )-smooth for all x ∈ D and some constant T   and
n    β  k satisfy the condition in Theorem 3 with h = p  then with probability at least 1 − β  the
output θpriv of Algorithm 2 satisﬁes: ErrD(θpriv) ≤ ˜O
  where ˜O hides the log
and T terms. So  to achieve error α  with probability at least 1 − β  we have sample complexity:

(cid:16) log 1

4 )p(cid:1).

2 )−2(45

1
2
p p
1
4 

D4p 1

2(p+1)p

(cid:17)

√

1
4 D

1
4

1
2

β

n

√

(cid:16)

}(cid:17)

n = ˜Ω

max{4p(p+1) log(

)D2

pp−2α−4 

1
β

log 1

β 4p(p+1)
2D2
p

.

(4)

log 1

√

2D2
2p

β cp2

β D2p

2 log 1

p−2α−3 

It is worth noticing that from (3) we can see that when the term h
p grows  the term α de-
creases. Thus  for loss functions that are (∞  T )-smooth  we can get a smaller dependency
than the term α−4 in (4). For example  if we take h = 2p  then the sample complexity is
n = Ω(max{cp2
}) for some constants c  c2. When h → ∞  the
dependency on the error becomes α−2  which is the optimal bound  even for convex functions.
Our analysis of the empirical excess risk does not use the convexity assumption. While this gives
a bound which is not optimal  even for p = 1  it also says that our result holds for non-convex loss
functions and constrained domain set  as long as they are smooth enough.
From (4)  we can see that our sample complexity is lower than the one in [19] when α ≤ O( 1
16p ).
Note that to achieve the best performance for the ERM problem in low dimensional space  quite often
the error is set to be extremely small  e.g.  α = 10−10 ∼ 10−14[10].
Using the convexity assumption of the loss function  and a lemma in [18]  we can also give a bound
on the population excess risk  details are in Supplementary Material.
Corollary 1 and 2 provide answers to our motivative questions. That is  for loss functions which are
(8  T )-smooth  we can obtain a lower sample complexity; if they are (∞  T )-smooth  there is an -
LDP algorithm for the empirical and population excess risks achieving error α with sample complexity
which is independent from the dimensionality p in the term α. This result does not contradict the
results in Smith et al. [19]. Indeed  the example used to show the unavoidable dependency between
the sample complexity and α−Ω(p)  to achieve the α error  is actually non-smooth.
However  in our result of (∞  T )-smooth case  like in the one by Smith et al. [19]  there is still a
dependency of the sample complexity in the term cp  for some constant c. There is still the question
about what condition would allow a sample complexity independent from this term. We leave this
question for future research and we focus instead on the efﬁciency and further applications of our
method.

5 More Efﬁcient Algorithms

Algorithm 2 has computational time and communication complexity for each player which is expo-
nential in the dimensionality. This is clearly problematic for every realistic practical application. For
this reason  in this section  we study more efﬁcient algorithms. In order for convenience  in this part
we only focus on the case of (∞  T )-smooth loss functions  it can be easily extended to general cases.
Consider the following lemma  showing an -LDP algorithm for computing p-dimensional average
(notice the extra conditions on n and p compared with Lemma 1).
Lemma 2. [16] Consider player i ∈ [n] holding data vi ∈ Rp with coordinate between 0 and b.
Then for 0 < β < 1  0 <  such that n ≥ 8p log( 8p
β   there is an -LDP

n ≥ 12

β ) and

(cid:113)

log 32

√



6

(cid:80)n
i=1[vi]j| ≤ O( bp√

n

1
n

(cid:113)

algorithm  LDP-AVG  with probability at least 1 − β  the output a ∈ Rp satisfying: maxj∈[p] |aj −

log p

β )3. Moreover  the computation cost for each user is O(1).

By using this lemma and by discretizing the grid with some interval steps  we can design an
algorithm which requires O(1) computation time and O(log n)-bits communication per player
(see Supplementary Material). However  we would like to do even better and obtain constant
communication complexity. Instead of discretizing the grid  we apply a technique  ﬁrstly proposed by
Bassily and Smith [2]  which permits to transform any ‘sampling resilient’ -LDP protocol into a
protocol with 1-bit communication complexity. Roughly speaking  a protocol is sampling resilient if
its output on any dataset S can be approximated well by its output on a random subset of half of the
players.
Since our algorithm only uses the LDP-AVG protocol  we can show that it is indeed sampling resilient.
Inspired by this result  we propose Algorithm 3 and obtain the following theorem.
Theorem 4. For 0 <  ≤ ln 2 and 0 < β < 1  Algorithm 3 is -LDP. If the loss function (cid:96)(·  x) is
(∞  T )-smooth for all x ∈ D and n = Ω(max{ log 1
β})  then

2p(cid:1)  the results in Corollary 2 hold with probability at least 1 − 4β.

by setting k = O(cid:0)( Dp
2(p+1)p(cid:113)

  p(k + 1)p log(k + 1)  1

β 4p(p+1)
2D2
p

2 log 1

pn

√

)

1

log 1
β

Moreover  for each player the time complexity is O(1)  and the communication complexity is 1-bit.

k   . . .   vp

point T (j) ∈ T .

 ) ···   yn = Lap( 1
 ).

parameter  ≤ ln 2  and parameter k.

k }{v1 ... vp}  where {v1  . . .   vp} ∈ {0  1 ···   k}p.

Algorithm 3 Player-Efﬁcient Local Bernstein Mechanism with 1-bit communication per player
1: Input: Player i ∈ [n] holding data xi ∈ D  public loss function (cid:96) : [0  1]p × D (cid:55)→ [0  1]  privacy
2: Preprocessing:
3: Generate n independent public strings
4: y1 = Lap( 1
5: Construct the grid T = { v1
6: Partition randomly [n] into d = (k + 1)p subsets I1  I2 ···   Id  and associate each Ij to a grid
7: for Each Player i ∈ [n] do
8:
9:
10:
11: end for
12: for The Server do
13:
14:
15:
16:
17:
18:

Find Il such that i ∈ Il. Calculate vi = (cid:96)(T (l); xi).
Compute pi = 1
2
Sample a bit bi from Bernoulli(pi) and send it to the server.

Compute v(cid:96) = n|Il|
Denote the corresponding grid point ( v1

Check if bi = 1  set ˜zi = yi  otherwise ˜zi = 0.

end for
for each l ∈ [d] do

for i = 1··· n do

then denote

k ) ∈ T of Il 

k ); D) = vl.

k  ···   vp
end for
Construct Bernstein polynomial for the perturbed empirical loss ˜L as in Algorithm 2. Denote

k   . . .   vp

Pr[vi+Lap( 1

 )=yi]

Pr[Lap( 1

 )=yi]

(cid:80)

i∈I(cid:96)

˜zi

ˆL(( v1

19:
20:

˜L(·  D) the corresponding function.

Compute θpriv = arg minθ∈C ˜L(θ; D).

21:
22: end for

Now we study the algorithm from the server’s complexity perspective. The polynomial construction
time complexity is O(n)  where the most inefﬁcient part is ﬁnding θpriv = arg minθ∈C ˜L(θ  D).
In fact  this function may be non-convex; but unlike general non-convex functions  it can be α-
uniformly approximated by a convex function ˆL(·; D) if the loss function is convex (by the proof of

3Note that here we use an weak version of their result

7

p   

   log 1

Theorem 3)  although we do not have access to it. Thus  we can see this problem as an instance of
Approximately-Convex Optimization  which has been studied recently by Risteski and Li [17].
Deﬁnition 7. [17] We say that a convex set C is µ-well-conditioned for µ ≥ 1  if there exists a
(cid:107)∇2F (x)(cid:107)2
≤ µ.
function F : Rp (cid:55)→ R such that C = {x|F (x) ≤ 0} and for every x ∈ ∂K :
(cid:107)∇F (x)(cid:107)2
Lemma 3 (Theorem 3.2 in [17]). Let   ∆ be two real numbers such that ∆ ≤ max{ 2
p}× 1
√
16348.
µ
Then  there exists an algorithm A such that for any given ∆-approximate convex function ˜f over a µ-
well-conditioned convex set C ⊆ Rp of diameter 1 (that is  there exists a 1-Lipschitz convex function
f : C (cid:55)→ R such that for every x ∈ C |f (x) − ˜f (x)| ≤ ∆)  A returns a point ˜x ∈ C with probability
δ ) and with the following guarantee ˜f (˜x) ≤ minx∈C ˜f (x) + .
at least 1 − δ in time Poly(p  1
Based on Lemma 3 (for ˜L(θ; D)) and Corollary 2  and taking  = O(pα)  we have the following.
Theorem 5. Under
=
pp−2α−4)  that the loss function (cid:96)(·  x) is 1-Lipschitz and convex for
˜Ω(4p(p+1) log(1/β)D2
every x ∈ D  that the constraint set C is convex and (cid:107)C(cid:107)2 ≤ 1  and satisﬁes µ-well-condition
property (see Deﬁnition 7)  if the error α satisﬁes α ≤ C µ
√
p for some universal constant C  then
there is an algorithm A which runs in Poly(n  1
β ) time4 for the server  and with probability
1 − 2β the output ˜θpriv of A satisﬁes ˜L(˜θpriv; D) ≤ minθ∈C ˜L(θ; D) + O(pα)  which means that
ErrD(˜θpriv) ≤ O(pα).
Combining with Theorem 4  5 and Corollary 2  and taking α = α
Theorem 6. Under the conditions of Corollary 2  Theorem 4 and 5  and for any C µ√
we further set n = ˜Ω(4p(p+1) log(1/β)D2
running time and 1-bit communication per player  and Poly( 1
Furthermore  with probability at least 1 − 5β  the output ˜θpriv satisﬁes ErrD(˜θpriv) ≤ O(α).

p > α > 0  if
pp5−2α−4)  then there is an -LDP algorithm  with O(1)
β ) running time for the server.

p   we have our ﬁnal result:

in Corollary

conditions

assuming

α   log 1

α   log 1

that n

the

2 

and

p

6 High Dimensional Case

In previous sections  p is assumed to be either constant or low. In this section  we present a general
method for a family of loss functions  called generalized linear functions  in high dimensions.
A function (cid:96)(w  x) is called a Generalized Linear Function (GLF) [18] if (cid:96)(w  x) = f ((cid:104)w  y(cid:105)  z) for
x = (y  z)  where y ∈ Rp is the data and z is the label. GLF is a rather general family of functions 
including many frequently encountered loss functions like logistic regression  hinge loss  linear
regression  etc. We assume that the dataset satisﬁes the conditions of (cid:107)yi(cid:107) ≤ 1 and (cid:107)zi(cid:107) ≤ 1 for all
i ∈ [n]. Also  f is assumed to be 1-Lipschitz  convex  (cid:107)C(cid:107)2 ≤ 1 and isotropic 5.
Our algorithm is inspired by the one in [11]. We ﬁrst conduct a dimension reduction for the whole
dataset. That is  D(cid:48) = {(Φy1  z1) ···   (Φyn  zn)}  where Φ ∈ Rm×p. Then  we run a modiﬁed
version of the algorithm in [19] (since the algorithm in [19] assumes log n ≥ p). After obtaining
the private estimator ¯w ∈ Rm  we use a compressive sensing technique (by solving an optimization
problem [22]) to recover wpriv ∈ Rp. Our method is based on the following lemma in [4].
Lemma 4. Let ˜Φ ∈ Rm×p be an random matrix  whose rows are i.i.d mean-zero  isotropic  sub-
Gaussian random variable in Rd with ψ = (cid:107)Φi(cid:107)ψ2. Let Φ = 1√
˜Φ and S be a set of points in
Rd. Then  there is a constant C > 0 such that for any 0 < γ  β < 1. Pr[supa∈S |(cid:107)Φa(cid:107)2 − (cid:107)a(cid:107)2 ≤
γ2 max{G2S   log(1/β)}.
γ(cid:107)a(cid:107)2] ≤ β  provided that m ≥ Cψ4
Theorem 7. Under the assumption above. For any  ≤ 1
√
4  Algorithm 4 is O()-LDP. Moreover 
√
(GC+
setting m = Θ( ψ4(GC+
)  then with

)  where γ = Θ(

log n)2 log(n/β)

log n) log(1/β) 4

log(n/β)

√

√

√

m

ψ

γ2

n

4Note that since here we assume n is at least exponential in p  thus the algorithm is not fully polynomial.
5A convex set is isotropic if a random vector chosen uniformly from K according to the volume is isotropic.

A random vector a is isotropic if for all b ∈ Rp  E[(cid:104)a  b(cid:105)2] = (cid:107)b(cid:107)2  such as polytope.

8

Algorithm 4 DR-ERM-LDP
1: Input: Player i ∈ [n] holding data xi = (yi  zi) ∈ D  where (cid:107)yi(cid:107) ≤ 1  privacy parameter .
2: The server generates an random sub-Gaussian matrix Φ ∈ Rm×p in Lemma 3  and sends the

seed of this random matrix to all players.

3: for Each Player i do
4:
5:

Calculate x(cid:48)
i = (Φyi  zi)
Run the modiﬁed -local DP algorithm of [19](see Supplementary Material for more details)
i}n
i=1 with constrained set C = ΦC and loss function f. The server get the output as

for D(cid:48) = {x(cid:48)
¯w ∈ Rm.
6: end for
7: The server solves the following problem wpriv = arg minw∈Rp (cid:107)w(cid:107)C  subject to Φw = ¯w.

probability at least 1− β  ErrD(wpriv) = ˜O(cid:0)(cid:0) log(1/β)ψ
˜O(cid:0)(cid:0) log(1/β) 4√

subgaussian norm of the distribution of Φ  and GC is the Gaussian width of C.
Corollary 3. If Φ is a standard Gaussian random matrix  C is the (cid:96)1 norm ball Bp
1 or the distribution
simplex in Rp  and n (cid:28) p ≤ ecn for some constant c  then the bound in Theorem 7 is just

1+m(cid:1)  where m = O(n2 log p(cid:112)log(n/β)). Note that the bound in
(cid:1) 1

√

log n) 4

log(n/β)

1+m )  where ψ is the

(cid:1) 1

√
(GC+
√

n

√

√

log p 4
√

n

log(n/β)

this case is always better than the one in Theorem 1  since it is always O(1).

References
[1] Francesco Aldà and Benjamin IP Rubinstein. The bernstein mechanism: Function release under

differential privacy. In AAAI  pages 1705–1711  2017.

[2] Raef Bassily and Adam Smith. Local  private  efﬁcient protocols for succinct histograms.
In Proceedings of the forty-seventh annual ACM symposium on Theory of computing  pages
127–135. ACM  2015.

[3] Amos Beimel  Kobbi Nissim  and Eran Omri. Distributed private data analysis: Simultaneously

solving how and what. In CRYPTO  volume 5157  pages 451–468. Springer  2008.

[4] Sjoerd Dirksen. Dimensionality reduction with subgaussian matrices: a uniﬁed theory. Founda-

tions of Computational Mathematics  16(5):1367–1396  2016.

[5] John C Duchi  Michael I Jordan  and Martin J Wainwright. Local privacy and statistical minimax
rates. In Foundations of Computer Science (FOCS)  2013 IEEE 54th Annual Symposium on 
pages 429–438. IEEE  2013.

[6] John C Duchi  Michael I Jordan  and Martin J Wainwright. Minimax optimal procedures for
locally private estimation. Journal of the American Statistical Association  (just-accepted) 
2017.

[7] Cynthia Dwork  Frank McSherry  Kobbi Nissim  and Adam Smith. Calibrating noise to

sensitivity in private data analysis. In TCC  volume 3876  pages 265–284. Springer  2006.

[8] Úlfar Erlingsson  Vasyl Pihur  and Aleksandra Korolova. Rappor: Randomized aggregatable
privacy-preserving ordinal response. In Proceedings of the 2014 ACM SIGSAC conference on
computer and communications security  pages 1054–1067. ACM  2014.

[9] Samuel Haney  Ashwin Machanavajjhala  John M. Abowd  Matthew Graham  Mark Kutzbach 
and Lars Vilhuber. Utility cost of formal privacy for releasing national employer-employee
statistics. In Proceedings of the 2017 ACM International Conference on Management of Data 
SIGMOD ’17  pages 1339–1354  New York  NY  USA  2017. ACM. ISBN 978-1-4503-4197-
4. doi: 10.1145/3035918.3035940. URL http://doi.acm.org/10.1145/3035918.
3035940.

[10] Rie Johnson and Tong Zhang. Accelerating stochastic gradient descent using predictive variance

reduction. In Advances in neural information processing systems  pages 315–323  2013.

9

[11] Shiva Prasad Kasiviswanathan and Hongxia Jin. Efﬁcient private empirical risk minimization for
high-dimensional learning. In International Conference on Machine Learning  pages 488–497 
2016.

[12] Shiva Prasad Kasiviswanathan  Homin K Lee  Kobbi Nissim  Sofya Raskhodnikova  and Adam

Smith. What can we learn privately? SIAM Journal on Computing  40(3):793–826  2011.

[13] G.G. Lorentz. Bernstein Polynomials. AMS Chelsea Publishing Series. Chelsea Publishing

Company  1986. ISBN 9780828403238.

[14] Charles Micchelli. The saturation class and iterates of the bernstein polynomials. Journal of

Approximation Theory  8(1):1–18  1973.

[15] Joe Near. Differential privacy at scale: Uber and berkeley collaboration. In Enigma 2018

(Enigma 2018)  Santa Clara  CA  2018. USENIX Association.

[16] Kobbi Nissim and Uri Stemmer. Clustering algorithms for the centralized and local models.

CoRR  abs/1707.04766  2017.

[17] Andrej Risteski and Yuanzhi Li. Algorithms and matching lower bounds for approximately-
convex optimization. In Advances in Neural Information Processing Systems  pages 4745–4753 
2016.

[18] Shai Shalev-Shwartz  Ohad Shamir  Nathan Srebro  and Karthik Sridharan. Stochastic convex

optimization. In COLT  2009.

[19] Adam Smith  Abhradeep Thakurta  and Jalaj Upadhyay. Is interaction necessary for distributed

private learning? In IEEE Symposium on Security and Privacy  2017.

[20] Jun Tang  Aleksandra Korolova  Xiaolong Bai  Xueqiang Wang  and XiaoFeng Wang. Privacy
loss in apple’s implementation of differential privacy on macos 10.12. CoRR  abs/1709.02753 
2017.

[21] Justin Thaler  Jonathan Ullman  and Salil Vadhan. Faster algorithms for privately releasing
marginals. In International Colloquium on Automata  Languages  and Programming  pages
810–821. Springer  2012.

[22] Roman Vershynin. Estimation in high dimensions: a geometric perspective. In Sampling theory 

a renaissance  pages 3–66. Springer  2015.

[23] Di Wang and Jinhui Xu. Differentially private empirical risk minimization with smooth non-
convex loss functions: A non-stationary view. Thirty-Third AAAI Conference on Artiﬁcial
Intelligence  (AAAI-19)  Honolulu  Hawaii  USA  January 27-February 1  2019.

[24] Di Wang  Minwei Ye  and Jinhui Xu. Differentially private empirical risk minimization revisited:
Faster and more general. In Advances in Neural Information Processing Systems  pages 2722–
2731  2017.

[25] Di Wang  Adam Smith  and Jinhui Xu. Differentially private empirical risk minimization in
non-interactive local model via polynomial of inner product approximation. In Algorithmic
Learning Theory  ALT 2019  22-24 March 2019  Chicago  IL  USA  2019.

[26] Ziteng Wang  Chi Jin  Kai Fan  Jiaqi Zhang  Junliang Huang  Yiqiao Zhong  and Liwei Wang.
Differentially private data releasing for smooth queries. The Journal of Machine Learning
Research  17(1):1779–1820  2016.

[27] Kai Zheng  Wenlong Mou  and Liwei Wang. Collect at once  use effectively: Making non-
interactive locally private learning possible. In Proceedings of the 34th International Conference
on Machine Learning  ICML 2017  Sydney  NSW  Australia  6-11 August 2017  pages 4130–4139 
2017.

10

,Dae Il Kim
Prem Gopalan
David Blei
Erik Sudderth
Aryeh Kontorovich
Sivan Sabato
Ruth Urner
Di Wang
Marco Gaboardi
Jinhui Xu