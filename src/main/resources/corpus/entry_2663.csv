2009,Information-theoretic lower bounds on the oracle complexity of convex optimization,Despite the large amount of literature on upper bounds on complexity of convex analysis  surprisingly little is known about the fundamental hardness of these problems. The extensive use of convex optimization in machine learning and statistics makes such an understanding critical to understand fundamental computational limits of learning and estimation. In this paper  we study the complexity of stochastic convex optimization in an oracle model of computation. We improve upon known results and obtain tight minimax complexity estimates for some function classes. We also discuss implications of these results to the understanding the inherent complexity of large-scale learning and estimation problems.,Information-theoretic lower bounds on the oracle

complexity of convex optimization

Alekh Agarwal

Computer Science Division

UC Berkeley

alekh@cs.berkeley.edu

Pradeep Ravikumar

Department of Computer Sciences

UT Austin

pradeepr@cs.utexas.edu

Peter Bartlett

Computer Science Division

Department of Statistics

UC Berkeley

bartlett@cs.berkeley.edu

Martin J. Wainwright
Department of EECS  and
Department of Statistics

UC Berkeley

wainwrig@eecs.berkeley.edu

Abstract

Despite a large literature on upper bounds on complexity of convex optimization 
relatively less attention has been paid to the fundamental hardness of these prob-
lems. Given the extensive use of convex optimization in machine learning and
statistics  gaining a understanding of these complexity-theoretic issues is impor-
tant.
In this paper  we study the complexity of stochastic convex optimization
in an oracle model of computation. We improve upon known results and obtain
tight minimax complexity estimates for various function classes. We also dis-
cuss implications of these results for the understanding the inherent complexity of
large-scale learning and estimation problems.

1

Introduction

Convex optimization forms the backbone of many algorithms for statistical learning and estimation.
In large-scale learning problems  in which the problem dimension and/or data are large  it is es-
sential to exploit bounded computational resources in a (near)-optimal manner. For such problems 
understanding the computational complexity of convex optimization is a key issue.
A large body of literature is devoted to obtaining rates of convergence of speciﬁc procedures for
various classes of convex optimization problems. A typical outcome of such analysis is an upper
bound on the error—for instance  gap to the optimal cost— as a function of the number of iterations.
Such analyses have been performed for many standard optimization alogrithms  among them gradi-
ent descent  mirror descent  interior point programming  and stochastic gradient descent  to name a
few. We refer the reader to standard texts on optimization (e.g.  [4  1  10]) for further details on such
results.
On the other hand  there has been relatively little study of the inherent complexity of convex opti-
mization problems. To the best of our knowledge  the ﬁrst formal study in this area was undertaken
in the seminal work of Nemirovski and Yudin [8] (hereafter referred to as NY). One obstacle to
a classical complexity-theoretic analysis  as the authors observed  was that of casting convex opti-
mization problems in a Turing Machine model. They avoided this problem by instead considering a
natural oracle model of complexity in which at every round  the optimization procedure queries an
oracle for certain information on the function being optimized. Working within this framework  the
authors obtained a series of lower bounds on the computational complexity of convex optimization

1

problems. In addition to the original text NY [8]  we refer the reader to Nesterov [10] or the lecture
notes by Nemirovski [7].
In this paper  we consider the computational complexity of stochastic convex optimization in the or-
acle model. Our results lead to a characterization of the inherent difﬁculty of learning and estimation
problems when computational resources are constrained. In particular  we improve upon the work of
NY [8] in two ways. First  our lower bounds have an improved dependence on the dimension of the
space. In the context of statistical estimation  these bounds show how the difﬁculty of the estimation
problem increases with the number of parameters. Second  our techniques naturally extend to give
sharper results for optimization over simpler function classes. For instance  they show that the op-
timal oracle complexity of statistical estimation with quadratic loss is signiﬁcantly smaller than the
corresponding complexity with absolute loss. Our proofs exploit a new notion of the discrepancy
between two functions that appears to be natural for optimization problems. They are based on a
reduction from a statistical parameter estimation problem to the stochastic optimization problem 
and an application of information-theoretic lower bounds for the estimation problem.

2 Background and problem formulation

In this section  we introduce background on the oracle model of complexity for convex optimization 
and then deﬁne the oracles considered in this paper.

2.1 Convex optimization in the oracle model
Convex optimization is the task of minimizing a convex function f over a convex set S ⊆ Rd.
Assuming that the minimum is achieved  it corresponds to computing an element x∗
f that achieves
f ∈ arg minx∈S f(x). An optimization method is any procedure that solves
the minimum—that is  x∗
this task  typically by repeatedly selecting values from S. Our primary focus in this paper is the
following question: given any class of convex functions F  what is the minimum computational
labor any such optimization method would expend for any function in F?
In order to address this question  we follow the approach of Nemirovski and Yudin [8]  based on the
oracle model of optimization. More precisely  an oracle is a (possibly random) function φ : S (cid:55)→ I
that answers any query x ∈ S by returning an element φ(x) in an information set I. The information
set varies depending on the oracle; for instance  for an exact oracle of kth order  the answer to a query
xt consists of f(xt) and the ﬁrst k derivatives of f at xt. For the case of stochastic oracles studied
in this paper  these values are corrupted with zero-mean noise with bounded variance.
Given some number of rounds T   an optimization method M designed to approximately minimize
the convex function f over the convex set S proceeds as follows: at any given round t = 1  T   the
method M queries at xt ∈ S  and the oracle reveals the information φ(xt  f). The method then uses
this information to decide at which point xt+1 the next query should be made. For a given oracle
function φ  let MT denote the class of all optimization methods M that make T queries according
to the procedure outlined above. For any method M ∈ MT   we deﬁne its error on function f after
T steps as

(M  f  S  φ) := f(xT ) − inf
x∈S

f(x) = f(xT ) − f(x∗
f ) 

where xT is the method’s query at time T . Note that by deﬁnition of x∗
quantity.

(1)
f   this error is a non-negative

2.2 Minimax error

When the oracle is stochastic  the method’s query xT at time T is itself random  since it depends on
the random answers provided by the oracle. In this case  the optimization error (M  f  S  φ) is also
a random variable. Accordingly  for the case of stochastic oracles  we measure the accuracy in terms
of the expected value Eφ[(M  f  S  φ)]  where the expectation is taken over the oracle randomness.
Given a class of functions F  and the class MT of optimization methods making T oracle queries 
we can deﬁne the minimax error

∗(F  S  φ) := infMT ∈MT

Eφ[(MT   f  S  φ)].

(2)

sup
f∈F

2

Note that this deﬁnition depends on the optimization set S. In order to obtain uniform bounds  we
deﬁne S := {S ⊆ Rd : S convex (cid:107)x− y(cid:107)∞ ≤ 1 for x  y ∈ S}  and consider the worst-case average
error over all S ∈ S   given by

∗(F  φ) := sup
S∈S

∗(F  S  φ).

(3)

In the sequel  we provide results for particular classes of oracles. So as to ease the notation  when
the function φ is clear from the context  we simply write ∗(F).
It is worth noting that oracle complexity measures only the number of queries to the oracle—for
instance  the number of (approximate) function or gradient evaluations. However  it does not track
computational cost within each component of the oracle query (e.g.  the actual ﬂop count associated
with evaluating the gradient).

2.3 Types of Oracle

In this paper we study the class of stochastic ﬁrst order oracles  which we will denote simply by
O. For this class of oracles  the information set I consists of pairs of noisy function and gradient
evaluations; consequently  any oracle φ in this class can be written as

where (cid:98)f(x) and(cid:98)g(x) are random variables that are unbiased as estimators of the function and gradi-
ent values respectively (i.e.  E(cid:98)f(x) = f(x) and E(cid:98)g(x) = ∇f(x)). Moreover  we assume that both
(cid:98)f(x) and(cid:98)g(x) have variances bounded by one. When the gradient is not deﬁned at x  the notation

∇f(x) should be understood to mean any arbitrary subgradient at x. Recall that a subgradient of a
convex function f is any vector v ∈ Rd such that

(4)

φ(x  f) = ((cid:98)f(x) (cid:98)g(x)) 

f(y) ≥ f(x) + v(cid:62)(y − x).

Stochastic gradient methods are popular examples of algorithms for such oracles.
Notation: For the convenience of the reader  we collect here some notation used throughout the
1 to refer to the sequence (x1  . . .   xt). We refer to the i-th coordinate of any vector
paper. We use xt
x ∈ Rd as x(i). For a convex set S  the radius of the largest inscribed (cid:96)∞ ball is denoted as r∞.
For a convex function f  its minimizer over a set S will be denoted as x∗
f when S is obvious from
context. We will often use the notation x∗
α to denote the minimizer of fα if α is an index variable
over a class. For two distributions p and q  KL(p||q) refers to the Kullback Leibler divergence
between the distributions. The notation I(A) is the 0-1 valued indicator random variable of the
set (equivalently event) A. For two vectors α  β ∈ {−1  +1}d  we deﬁne the Hamming distance

∆H(α  β) :=(cid:80)d

I[αi (cid:54)= βi].

i=1

3 Main results and their consequences

With the setup of stochastic convex optimization in place  we are now in a position to state the
main results of this paper. In particular  we provide some tight lower bounds on the complexity of
stochastic oracle optimization. We begin by analyzing the minimax oracle complexity of optimiza-
tion for the class of convex Lipschitz functions. Recall that a function f : Rd → R is convex if for
all x  y ∈ Rd and λ ∈ (0  1)  we have the inequality f(λx + (1− λ)y) ≤ λf(x) + (1− λ)f(y). For
some constant L > 0  we say that the function f is L-Lipschitz on S if |f(x)− f(y)| ≤ L(cid:107)x− y(cid:107)∞
for all x  y ∈ S.
Before stating the results  we note that scaling the Lipschitz constant scales minimax optimization
error linearly. Hence  to keep our results scale-free  we consider 1-Lipschitz functions only. As the
diameter of S is also bounded by 1  this automatically enforces that |f(x)| ≤ 1  ∀x ∈ S.
Theorem 1. Let F C be the class of all bounded convex 1-Lipschitz functions on Rd. Then there is
a constant c (independent of d) such that

∗(F C  φ) ≥ c

sup
φ∈O

d
T

.

(5)

(cid:114)

3

Remarks: This lower bound is tight in the minimax sense  since the method of stochastic gradient
descent attains a matching upper bound for all stochastic ﬁrst order oracles for any convex set S
(see Chapter 5 of NY [8]). Also  even though this lower bound requires the oracle to have only
bounded variance  we will use an oracle based on Bernoulli random variables  which has all mo-
ments bounded. As a result there is no hope to get faster rates in a simple way by assuming bounds
on higher moments for the oracle. This is in interesting contrast to the case of having less than 2
bounded moments where we get slower rates (again  see Chapter 5 of NY [8]).
The above lower bound is obtained by considering the worst case over all convex sets. However 
we expect optimization over a smaller convex set to be easier than over a large set. Indeed  we can
easily obtain a corollary of Theorem 1 that quantiﬁes this intuition.
Corollary 1. Let F C be the class of all bounded convex 1-Lipschitz functions on Rd. Let S be a
convex set such that it contains an (cid:96)∞ ball of radius r∞ and is contained in an (cid:96)∞ ball of radius
R∞. Then there is a universal constant c such that 

(cid:114)

sup
φ∈O

∗(F C  S  φ) ≥ c

r∞
R∞

d
T

.

(6)

Remark: The ratio r∞
R∞ is also common in results of [8]  and is called the asphericity of S. As
a particular application of above corollary  consider S to be the unit (cid:96)2 ball. Then r∞ = 1√
  and
R∞ = 1. which gives a dimension independent lower bound. This lower bound for the case of the
(cid:96)2 ball is indeed tight  and is recovered by the stochastic gradient descent algorithm [8].
Just as optimization over simpler sets gets easier  optimization over simple function classes should
be easier too. A natural function class that has been studied extensively in the context of better upper
bounds is that of strongly convex functions. For any given norm (cid:107) · (cid:107) on S  a function f is strongly
convex with coefﬁcient κ means that f(x) ≥ f(y) + ∇f(y)T (x − y) + κ
2(cid:107)x − y(cid:107)2 for all x  y ∈ S.
For this class of functions  we obtain a smaller lower bound on the minimax oracle complexity of
optimization.
Theorem 2. Let FS be the class of all bounded strongly convex and 1-Lipschitz functions on Rd.
Then there is a universal constant c such that 

d

∗(FS   φ) ≥ c

d
T

.

sup
φ∈O

(7)

(cid:1)2 d

T .

R∞

Once again there is a matching upper bound using stochastic gradient descent for example  when
the strong convexity is with respect to the (cid:96)2 norm. The corollary depending on the geometry of S
follows again.
Corollary 2. Let FS be the class of all bounded convex 1-Lipschitz functions on Rd. Let S be a
convex set such that it contains an (cid:96)∞ ball of radius r∞. Then there is a universal constant c such

that supφ∈O ∗(FS   S  φ) ≥ c(cid:0) r∞
In comparison  Nemirovski and Yudin [8] obtained a lower bound scaling as Ω(cid:0) 1√

(cid:1) for the class

F C. Their bound applies only to the class F C  and does not provide any dimension dependence 
as opposed to the bounds provided here. Obtaining the correct dependence yields tight minimax
results  and allows us to highlight the dependence of bounds on the geometry of the set S. Our
proofs are information-theoretic in nature. We characterize the hardness of optimization in terms of
a relatively easy to compute complexity measure. As a result  our technique provides tight lower
bounds for smaller function classes like strongly convex functions rather easily. Indeed  we will also
state a result for general function classes.

T

3.1 An application to statistical estimation

We now describe a simple application of the results developed above to obtain results on the oracle
complexity of statistical estimation  where the typical setup is the following: given a convex loss
function (cid:96)  a class of functions F indexed by a d-dimensional parameter θ so that F = {fθ : θ ∈

4

Rd}  ﬁnd a function f ∈ F such that E(cid:96)(f) − inf f∈F E(cid:96)(f) ≤ . If the distribution were known 
this is exactly the problem of computing the -accurate optimizer of a convex function  assuming
the function class F is convex. Even though we do not have the distribution in practice  we typically
are provided with i.i.d. samples from it  which can be used to obtain unbiased estimates of the
value and gradients of the risk functional E(cid:96)(f) for any given f. If indeed the computational model
of the estimator were restricted to querying these values and gradients  then the lower bounds in
the previous sections would apply. Our bounds  then allow us to deduce the oracle complexity of
statistical estimation problems in this realistic model. In particular  a case of interest is when we
ﬁx a convex loss function (cid:96) and consider the worst oracle complexity over all possible distributions
under which expectation is taken. From our bounds  it is straightforward to deduce:
• For the absolute loss (cid:96)(f(x)  y) = |f(x) − y|  the oracle complexity of -accurate estimation

over all possible distributions is Ω(cid:0)d/2(cid:1).

• For the quadratic loss (cid:96)(f(x)  y) = (f(x) − y)2  the oracle complexity of -accurate estimation

over all possible distributions is Ω (d/).

We can use such an analysis to determine the limits of statistical estimation under computational
constraints. Several authors have recently considered this problem [3  9]  and provided upper bounds
for particular algorithms. In contrast  our results provide algorithm-independent lower bounds on
the complexity of statistical estimation within the oracle model. An interesting direction for future
work is to broader the oracle model so as to more accurately reﬂect the computational trade-offs in
learning and estimation problems  for instance by allowing a method to pay a higher price to query
an oracle with lower variance.

4 Proofs of results

We now turn to the proofs of our main results  beginning with a high-level outline of the main ideas
common to our proofs.

4.1 High-level outline

Our main idea is to embed the problem of estimating the parameter of a Bernoulli vector (alter-
natively  the biases of d coins) into a convex optimization problem. We start with an appropriately
chosen subset of the vertices of a d-dimensional hypercube each of which corresponds to some value
of the Bernoulli vector. For any given function class  we then construct a “difﬁcult” subclass of
functions parameterized by these hypercube vertices. We then show that being able to optimize any
function in this subclass requires estimating its hypercube vertex  that is  the corresponding biases
of the d coins. But the only information for this estimation would be from the coin toss outcomes
revealed by the oracle in T queries. With this set-up  we are able to apply the Fano lower bound for
statistical estimation  as has been done in past work on nonparametric estimation (e.g.  [5  2  11]).
In more detail  the proofs of Theorems 1 and 2 are both based on a common set of steps  which we
describe here.

Step I: Constructing a difﬁcult subclass of functions. Our ﬁrst step is to construct a subclass
of functions G ⊆ F that we use to derive lower bounds. Any such subclass is parameterized by
a subset V ⊆ {−1  +1}d of the hypercube  chosen as follows. Recalling that ∆H denotes the
Hamming metric on the space {−1  +1}d  we choose V to be a d/4-packing of this hypercube.
That is  V is a subset of the hypercube such that for all α  β ∈ V  the Hamming distance satisﬁes
∆H(α  β) ≥ d/4. By standard arguments [6]  we can construct such a packing set V with cardinality
√
|V| ≥ (2/
i   i = 1  . . .   d} denote some base set of 2d functions (to be chosen
We then let Gbase = {f +
depending on the problem at hand). Given the packing set V and some parameter δ ∈ [0  1/4]  we
deﬁne a larger class (with a total of |V| functions) via G(δ) := {gα  α ∈ V}  where each function
gα ∈ G(δ) has the form
d(cid:88)

i   f−

(cid:8)(1/2 + αiδ)f +

i (x)(cid:9).

e)d/2.

gα(x) =

1
d

i (x) + (1/2 − αiδ) f−

(8)

i=1

5

In our proofs  the subclasses Gbase and G(δ) are chosen such that G(δ) ⊆ F  the functions f +
i   f−
i
are bounded over the convex set S with a Lipschitz constant independent of dimension d  and the
minimizers xβ of gβ over Rd are contained in S for all β ∈ V. We demonstrate speciﬁc choices in
the proofs of Theorems 1 and 2.

Step II: Optimizing well is equivalent to function identiﬁcation.
In this step  we show that if
a method can optimize over the subclass G(δ) up to a certain tolerance ψ(G(δ))  then it must be
capable of identifying which function gα ∈ G(δ) was chosen. We ﬁrst require a measure for the
closeness of functions in terms of their behavior near each others’ minima. Recall that we use
f ∈ Rd to denote a minimizing point of the function f. Given a convex set S ⊆ Rd and two
x∗
functions f  g  we deﬁne

(cid:2)f(x) + g(x) − f(x∗

g)(cid:3) .

f ) − g(x∗

ρ(f  g) = inf
x∈S

(9)

ψ(G(δ)) = min

f = x∗

The discrepancy measure is non-negative  symmetric in its arguments 1 and satisﬁes ρ(f  g) = 0 if
and only if x∗
Given the subclass G(δ)  we quantify how densely it is packed with respect to the semimetric ρ using
the quantity

g  so that we may refer to it as a semimetric.

α) ≤ ψ(δ)
3 .

α(cid:54)=β∈V ρ(gα  gβ) 

α denotes a minimizing argument of the function gα.

(10)
which we also denote by ψ(δ) when the class G is clear from the context. We now state a simple
result that demonstrates the utility of maintaining a separation under ρ among functions in G(δ).
Note that x∗
there can be at most one function gα ∈ G(δ) for which

Lemma 1. For any (cid:101)x ∈ S 
gα((cid:101)x) − gα(x∗
Thus  if we have an element(cid:101)x that approximately minimizes (meaning up to tolerance ψ(δ)) one
Proof. For a given(cid:101)x ∈ S  suppose that there exists an α ∈ V such that gα((cid:101)x) − gα(x∗
α) ≤ ψ(δ)
3 .
ψ(δ) ≤ gα((cid:101)x) − gα(x∗
β) ≤ ψ(δ)/3 + gβ((cid:101)x) − gβ(x∗
which implies that gβ((cid:101)x) − gβ(x∗

α) + gβ((cid:101)x) − gβ(x∗
β) ≥ 2ψ(δ)/3  from which the claim follows.

function in the set G(δ)  then it cannot approximately minimize any other function in the set.

From the deﬁnition of ψ(δ) in (10)  for any β ∈ V  β (cid:54)= α  we have

β) 

Suppose that we choose some function gα∗ ∈ G(δ)  and some method MT is allowed to make T
queries to an oracle with information function φ(·  gα∗). Our next lemma shows that in this set-up 
if the method MT can optimize well over the class G(δ)  then it must be capable of determining the
true function gα∗. Recall the deﬁnition (2) of the minimax error in optimization:
Lemma 2. Suppose that some method MT has minimax optimization error upper bounded as

E(cid:2)∗(MT  G(δ)  S  φ)(cid:3) ≤ ψ(δ)

(11)

9 .

Pφ[(cid:98)α(MT ) (cid:54)= α∗] ≤ 1
Then the method MT can construct an estimator(cid:98)α(MT ) such that max
Proof. Given a method MT that satisﬁes the bound (11)  we construct an estimator(cid:98)α(MT ) of the
set(cid:98)α(MT ) equal to α. If no such α exists  then we choose(cid:98)α(MT ) uniformly at random from V.
(cid:2)∗(MT   gα∗   S  φ) ≥ ψ(δ)/3(cid:3) ≤ 1
using Markov’s inequality  we have Pφ[(cid:98)α(MT ) (cid:54)= α∗] ≤ Pφ

true vertex α∗ as follows. If there exists some α ∈ V such that gα(xT ) − gα(xα) ≤ ψ(δ)
then we
From Lemma 1  there can exist only one such α ∈ V that satisﬁes this inequality. Consequently 
3.
Maximizing over α∗ completes the proof.
We have thus shown that having a low minimax optimization error over G(δ) implies that the vertex
α ∈ V can be identiﬁed.

α∗∈V

3 .

3

1However  it fails to satisfy the triangle inequality and so is not a metric.

6

Step III: Oracle answers and coin tosses. We now demonstrate a stochastic ﬁrst order oracle φ
for which the samples {φ(x1  gα)  . . .   φ(xT   gα)} can be related to coin tosses. In particular  we
associate a coin with each dimension i ∈ {1  2  . . .   d}  and consider the set of coin bias vectors
lying in the set

Θ(δ) =(cid:8)(1/2 + α1δ  . . .   1/2 + αdδ) | α ∈ V(cid:9) 

(12)
Given a particular function gα ∈ G(δ) (or equivalently  vertex α ∈ V)  we consider the oracle φ that
presents noisy value and gradient samples from gα according to the following prescription:
• Pick an index it ∈ {1  . . .   d} uniformly at random.
• Draw bit ∈ {0  1} according to a Bernoulli distribution with parameter 1/2 + αitδ.
• Return the value and sub-gradient of the function

(cid:98)gα(x) = bitf +

it

(x) + (1 − bit)f−

it

(x).

By construction  the function value and gradient samples are unbiased estimates of those of gα;
moreover  the variance of the effective “noise” is bounded independently of d as long as the Lipschitz
constant is independent of d since the function values and gradients are bounded on S.

Step IV: Lower bounds on coin-tossing Finally  we use information-theoretic methods to lower
bound the probability of correctly estimating the true vertex α∗ ∈ V in our model.
Lemma 3. Given an arbitrary vertex α∗ ∈ V  suppose that we toss a set of d coins with bias
θ∗ = ( 1
2δ) a total of T times  but that the outcome of only one coin chosen

uniformly at random is revealed at every round. Then for all δ ≤ 1/4  any estimator(cid:98)α satisﬁes

2 + α∗

2 + α∗

1δ  . . .   1

(cid:26)
P[(cid:98)α (cid:54)= α∗] ≥

inf(cid:98)α

max
α∗∈V

1 − 16T δ2 + log 2
e)

2 log(2/

√

d

(cid:27)

.

θ . Note that Pθ(i  b) = 1

Proof. Denote the Bernoulli distribution for the i-th coin by Pθi. Let Yt ∈ {1  . . .   d} be the variable
indicating the coin revealed at time T   and let Xt ∈ {0  1} denote its outcome. With some abuse of
notation  we also denote the distribution of (Xt  Yt) by Pθ  and that of the entire data {(Xt  Yt)}T
d Pθi(b). We now apply a version of Fano’s lemma [11] to the set of
by P T
distributions P T

(cid:19)
θ for θ ∈ Θ(δ). In particular  using the proof of Lemma 3 in [11] we get:
1 − b + log 2
θ ||P T
log |Θ|

θ(cid:48) ) ≤ b  ∀θ  θ(cid:48) ∈ Θ(δ) ⇒ inf(cid:98)θ

max
θ∈Θ(δ)

.

(13)

KL(P T

(cid:18)

t=1

θ(cid:48) ) =

θ ||P T

b = KL(P T

In our case  we upper bound b as follows:

KL(Pθ(Xt  Yt)||Pθ(cid:48)(Xt  Yt)) =

T(cid:88)
Each term KL(Pθi(Xt)||Pθ
with parameters 1/2 + δ and 1/2 − δ. A little calculation shows that
≤ 8δ2
1 − 2δ

g(δ) = 2δ log

4δ
1 − 2δ

(cid:19)

(cid:18)

1 +

1
d

t=1

(cid:48)
i

 

KL(Pθi(Xt)||Pθ

(Xt)).

(cid:48)
i

(Xt)) is at most the KL divergence g(δ) between Bernoulli variates

Pθ[(cid:98)θ (cid:54)= θ] ≥
T(cid:88)
d(cid:88)

t=1

i=1

which is less than 16δ2 as long as δ ≤ 1/4. Consequently  we conclude that b ≤ 16T δ2. Also  we

note that P[(cid:98)α (cid:54)= α∗] = Pθ[(cid:98)θ (cid:54)= θ∗]. Substituting these values and the size of V into (13) yields the

claim.

4.2 Proofs of main results

We are now in a position to prove our main theorems.

7

Proof of Theorem 1: By the construction of our oracle  it is clear that  at each round  only one

coin is revealed to the method MT . Thus Lemma 3 applies to the estimator(cid:98)α(MT ):
In order to obtain an upper bound on P[(cid:98)α(MT ) (cid:54)= α] using Lemma 2  we need to identify the

16T δ2 + log 2
√
d log(2/
e)

1 − 2

subclass Gbase of F C. For i = 1  . . .   d  deﬁne:

P[(cid:98)α(MT ) (cid:54)= α] ≥
i (x) :=(cid:12)(cid:12)x(i) + 1/2(cid:12)(cid:12) 

i (x) :=(cid:12)(cid:12)x(i) − 1/2(cid:12)(cid:12).

(cid:19)

(cid:18)

f−

(14)

and

f +

.

i   f−

We take S to be the (cid:96)∞ ball of radius 1/2. It is clear then that the minimizers of gα are contained in
i are bounded in [0  1] and 1-Lipschitz in the ∞-norm  giving the same
S. Also  the functions f +
d ∆H(α  β) ≥ δ
2 for α (cid:54)= β ∈ V.
properties for each function gα. Finally  we note that ρ(gα  gβ) = 2δ
Setting  = δ/18 < 1/2  we obtain ∗(F C  φ) ≤  = δ
18 = ψ(δ)
9 . Then by Lemma 2  we have

3 ≥(cid:0)1 − 2 16T δ2+log 2
(cid:1).
(cid:1) for all d ≥ 11. Combining this with Theorem 5.3.1 of

Pφ[(cid:98)α(MT ) (cid:54)= α] ≤ 1
Substituting δ = 18 yields T = Ω(cid:0) d
(cid:1) for all d.
NY [8] gives T = Ω(cid:0) d

3 which  when combined with equation (14)  yields 1

d log(2/

√

2

e)

To prove Corollary 1  we note that the proof of Theorem 1 required r∞ ≥ 1
2. If not  it is easy to see
that the computation of ρ on G(δ) scales by r∞. Further  if the set is contained in a ball of radius
R∞  then we need to scale the function with 1
R∞ to keep the function values bounded. Taking both
these dependences into account gives the desired result.

2

Proof of Theorem 2:

In this case  we deﬁne the base class

i (x) =(cid:0)x(i) + 1/2(cid:1)2

f +

 

i (x) =(cid:0)x(i) − 1/2(cid:1)2

and f−

 

for i = 1  . . .   d.

Then the functions gα are strongly convex w.r.t.
Some calculation shows that ρ(gα  gβ) = 2δ2
is identical to Theorem 1.
The reader might suspect that the dimension dependence in our lower bound for strongly convex
functions is not tight  due to the dependence of κ on the dimension d. However  this is the largest
possible value of κ under the assumptions of the theorem.

the Euclidean norm with coefﬁcient κ = 1/d.
d ∆H(α  β) for all α (cid:54)= β. The remainder of the proof

4.3 A general result

Armed with the greater understanding from these proofs  we can now state a general result for any
function class F. The proof is similar to that of earlier results.
Theorem 3. For any function class F ⊆ F C  suppose a given base set of functions Gbase yields the
measure ψ as deﬁned in (10). Then there exists a universal constant c such that supφ∈O ∗(FS   φ) ≥

c ψ(cid:0)(cid:113) d

T

(cid:1).

Acknowledgements We gratefully acknowledge the support of the NSF under award DMS-0830410
and of DARPA under award HR0011-08-2-0002. Alekh is supported in part by MSR PhD Fellow-
ship.

References
[1] D.P. Bertsekas. Nonlinear programming. Athena Scientiﬁc  Belmont  MA  1995.
[2] L. Birg´e. Approximation dans les espaces metriques et theorie de l’estimation. Z. Wahrsch.

verw. Gebiete  65:181–327  1983.

[3] L. Bottou and O. Bousquet. The tradeoffs of large scale learning. In NIPS. 2008.
[4] S. Boyd and L. Vandenberghe. Convex optimization. Cambridge University Press  Cambridge 

UK  2004.

8

[5] R. Z. Has’minskii. A lower bound on the risks of nonparametric estimates of densities in the

uniform metric. Theory Prob. Appl.  23:794–798  1978.

[6] J. Matousek. Lectures on discrete geometry. Springer-Verlag  New York  2002.
[7] A. S. Nemirovski. Efﬁcient methods in convex programming. Lecture notes.
[8] A. S. Nemirovski and D. B. Yudin. Problem Complexity and Method Efﬁciency in Optimiza-

tion. John Wiley UK/USA  1983.

[9] S. Shalev-Shwartz and N. Srebro. SVM optimization: inverse dependence on training set size.

In ICML  2008.

[10] Nesterov Y. Introductory lectures on convex optimization: Basic course. Kluwer Academic

Publishers  2004.

[11] B. Yu. Assouad  Fano and Le Cam. In Festschrift in Honor of L. Le Cam on his 70th Birthday.

Springer-Verlag  1993.

9

,Akshay Krishnamurthy
Alekh Agarwal
John Langford