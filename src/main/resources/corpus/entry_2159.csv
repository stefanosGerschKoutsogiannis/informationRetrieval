2013,From Bandits to Experts: A Tale of Domination and Independence,We consider the partial observability model for multi-armed bandits  introduced by Mannor and Shamir (2011). Our main result is a characterization of regret in the directed observability model in terms of the dominating and independence numbers of the observability graph. We also show that in the undirected case  the learner can achieve optimal regret without even accessing the observability graph before selecting an action. Both results are shown using variants of the Exp3 algorithm operating on the observability graph in a time-efficient manner.,From Bandits to Experts:

A Tale of Domination and Independence

Noga Alon

Tel-Aviv University  Israel

nogaa@tau.ac.il

Nicol`o Cesa-Bianchi

Universit`a degli Studi di Milano  Italy

nicolo.cesa­bianchi@unimi.it

Claudio Gentile

University of Insubria  Italy

claudio.gentile@uninsubria.it

Yishay Mansour

Tel-Aviv University  Israel
mansour@tau.ac.il

Abstract

We consider the partial observability model for multi-armed bandits  introduced
by Mannor and Shamir [14]. Our main result is a characterization of regret in
the directed observability model in terms of the dominating and independence
numbers of the observability graph (which must be accessible before selecting an
action). In the undirected case  we show that the learner can achieve optimal regret
without even accessing the observability graph before selecting an action. Both
results are shown using variants of the Exp3 algorithm operating on the observ-
ability graph in a time-efﬁcient manner.

1

Introduction

Prediction with expert advice —see  e.g.  [13  16  6  10  7]— is a general abstract framework for
studying sequential prediction problems  formulated as repeated games between a player and an
adversary. A well studied example of prediction game is the following: In each round  the adversary
privately assigns a loss value to each action in a ﬁxed set. Then the player chooses an action (possibly
using randomization) and incurs the corresponding loss. The goal of the player is to control regret 
which is deﬁned as the excess loss incurred by the player as compared to the best ﬁxed action over
a sequence of rounds. Two important variants of this game have been studied in the past: the expert
setting  where at the end of each round the player observes the loss assigned to each action for that
round  and the bandit setting  where the player only observes the loss of the chosen action  but not
that of other actions.
Let K be the number of available actions  and T be the number of prediction rounds. The best
possible regret for the expert setting is of order √T log K. This optimal rate is achieved by the
Hedge algorithm [10] or the Follow the Perturbed Leader algorithm [12]. In the bandit setting  the
optimal regret is of order √T K  achieved by the INF algorithm [2]. A bandit variant of Hedge 
called Exp3 [3]  achieves a regret with a slightly worse bound of order √T K log K.
Recently  Mannor and Shamir [14] introduced an elegant way for deﬁning intermediate observability
models between the expert setting (full observability) and the bandit setting (single observability).
An intuitive way of representing an observability model is through a directed graph over actions:
an arc1 from action i to action j implies that when playing action i we get information also about
the loss of action j. Thus  the expert setting is obtained by choosing a complete graph over actions
(playing any action reveals all losses)  and the bandit setting is obtained by choosing an empty edge
set (playing an action only reveals the loss of that action).

1 According to the standard terminology in directed graph theory  throughout this paper a directed edge will

be called an arc.

1

The main result of [14] concerns undirected observability graphs. The regret is characterized in
terms of the independence number α of the undirected observability graph. Speciﬁcally  they prove
that √T α log K is the optimal regret (up to logarithmic factors) and show that a variant of Exp3 
called ELP  achieves this bound when the graph is known ahead of time  where α ∈ {1� . . . � K}
interpolates between full observability (α = 1 for the clique) and single observability (α = K for
the graph with no edges). Given the observability graph  ELP runs a linear program to compute the
desired distribution over actions. In the case when the graph changes over time  and at each time

step ELP observes the current observability graph before prediction  a bound of��T

t=1 αt log K
is shown  where αt is the independence number of the graph at time t. A major problem left open
in [14] was the characterization of regret for directed observability graphs  a setting for which they
only proved partial results.

Our main result is a full characterization (to within logarithmic factors) of regret in the case of di-
rected observability graphs. Our upper bounds are proven using a new algorithm  called Exp3-DOM.
This algorithm is efﬁcient to run even when the graph changes over time: it just needs to compute
a small dominating set of the current observability graph (which must be given as side informa-
tion) before prediction.2 As in the undirected case  the regret for the directed case is characterized in
terms of the independence numbers of the observability graphs (computed ignoring edge directions).
We arrive at this result by showing that a key quantity emerging in the analysis of Exp3-DOM can
be bounded in terms of the independence numbers of the graphs. This bound (Lemma 13 in the
appendix) is based on a combinatorial construction which might be of independent interest.

We also explore the possibility of the learning algorithm receiving the observability graph only after
prediction  and not before. For this setting  we introduce a new variant of Exp3  called Exp3-SET 
which achieves the same regret as ELP for undirected graphs  but without the need of accessing the
current observability graph before each prediction. We show that in some random directed graph
models Exp3-SET has also a good performance. In general  we can upper bound the regret of Exp3-
SET as a function of the maximum acyclic subgraph of the observability graph  but this upper bound
may not be tight. Yet  Exp3-SET is much simpler and computationally less demanding than ELP 
which needs to solve a linear program in each round.

There are a variety of real-world settings where partial observability models corresponding to di-
rected and undirected graphs are applicable. One of them is route selection. We are given a graph
of possible routes connecting cities: when we select a route r connecting two cities  we observe the
cost (say  driving time or fuel consumption) of the “edges” along that route and  in addition  we have
complete information on any sub-route r� of r  but not vice versa. We abstract this in our model by
having an observability graph over routes r  and an arc from r to any of its sub-routes r�.3

Sequential prediction problems with partial observability models also arise in the context of recom-
mendation systems. For example  an online retailer  which advertises products to users  knows that
users buying certain products are often interested in a set of related products. This knowledge can be
represented as a graph over the set of products  where two products are joined by an edge if and only
if users who buy any one of the two are likely to buy the other as well. In certain cases  however 
edges have a preferred orientation. For instance  a person buying a video game console might also
buy a high-def cable to connect it to the TV set. Vice versa  interest in high-def cables need not
indicate an interest in game consoles.

Such observability models may also arise in the case when a recommendation system operates in
a network of users. For example  consider the problem of recommending a sequence of products 
or contents  to users in a group. Suppose the recommendation system is hosted on an online so-
cial network  on which users can befriend each other. In this case  it has been observed that social
relationships reveal similarities in tastes and interests [15]. However  social links can also be asym-
metric (e.g.  followers of celebrities). In such cases  followers might be more likely to shape their
preferences after the person they follow  than the other way around. Hence  a product liked by a
celebrity is probably also liked by his/her followers  whereas a preference expressed by a follower
is more often speciﬁc to that person.

2 Computing an approximately minimum dominating set can be done by running a standard greedy set cover

algorithm  see Section 2.

3 Though this example may also be viewed as an instance of combinatorial bandits [8]  the model studied
here is more general. For example  it does not assume linear losses  which could arise in the routing example
from the partial ordering of sub-routes.

2

2 Learning protocol� notation� and preliminaries

As stated in the introduction  we consider an adversarial multi-armed bandit setting with a ﬁnite
action set V = {1� . . . � K}. At each time t = 1� 2� . . .   a player (the “learning algorithm”) picks
some action It ∈ V and incurs a bounded loss �It�t ∈ [0� 1]. Unlike the standard adversarial bandit
problem [3  7]  where only the played action It reveals its loss �It�t  here we assume all the losses
in a subset SIt�t ⊆ V of actions are revealed after It is played. More formally  the player observes
the pairs (i� �i�t) for each i ∈ SIt�t. We also assume i ∈ Si�t for any i and t  that is  any action
reveals its own loss when played. Note that the bandit setting (Si�t = {i}) and the expert setting
(Si�t = V ) are both special cases of this framework. We call Si�t the observation set of action i at
t−→ j when at time t playing action i also reveals the loss of action j. Hence 
time t  and write i
t−→ j}. The family of observation sets {Si�t}i∈V we collectively call the
Si�t = {j ∈ V : i
observation system at time t.
The adversaries we consider are nonoblivious. Namely  each loss �i�t at time t can be an arbitrary
function of the past player’s actions I1� . . . � It−1. The performance of a player A is measured
through the regret

max
k∈V

��LA�T − Lk�T�

where LA�T = �I1�1 + ··· + �IT �T and Lk�T = �k�1 + ··· + �k�T are the cumulative losses of the
player and of action k  respectively. The expectation is taken with respect to the player’s internal
randomization (since losses are allowed to depend on the player’s past random actions  also Lk�t
may be random).4 The observation system {Si�t}i∈V is also adversarially generated  and each Si�t
can be an arbitrary function of past player’s actions  just like losses are. However  in Section 3 we
also consider a variant in which the observation system is randomly generated according to a speciﬁc
stochastic model.

Whereas some algorithms need to know the observation system at the beginning of each step t 
others need not. From this viewpoint  we consider two online learning settings. In the ﬁrst setting 
called the informed setting  the full observation system {Si�t}i∈V selected by the adversary is made
available to the learner before making its choice It. This is essentially the “side-information” frame-
work ﬁrst considered in [14]. In the second setting  called the uninformed setting  no information
whatsoever regarding the time-t observation system is given to the learner prior to prediction. We
ﬁnd it convenient to adopt the same graph-theoretic interpretation of observation systems as in [14].
At each step t = 1� 2� . . .   the observation system {Si�t}i∈V deﬁnes a directed graph Gt = (V� Dt) 
where V is the set of actions  and Dt is the set of arcs  i.e.  ordered pairs of nodes. For j �= i  arc
(i� j) ∈ Dt if and only if i t−→ j (the self-loops created by i t−→ i are intentionally ignored). Hence 
we can equivalently deﬁne {Si�t}i∈V in terms of Gt. Observe that the outdegree d+
i of any i ∈ V
equals |Si�t|− 1. Similarly  the indegree d−
i of i is the number of action j �= i such that i ∈ Sj�t (i.e. 
such that j t−→ i). A notable special case of the above is when the observation system is symmetric
over time: j ∈ Si�t if and only if i ∈ Sj�t for all i� j and t. In words  playing i at time t reveals the
loss of j if and only if playing j at time t reveals the loss of i. A symmetric observation system is
equivalent to Gt being an undirected graph or  more precisely  to a directed graph having  for every
pair of nodes i� j ∈ V   either no arcs or length-two directed cycles. Thus  from the point of view
of the symmetry of the observation system  we also distinguish between the directed case (Gt is a
general directed graph) and the symmetric case (Gt is an undirected graph for all t).
The analysis of our algorithms depends on certain properties of the sequence of graphs Gt. Two
graph-theoretic notions playing an important role here are those of independent sets and dominating
sets. Given an undirected graph G = (V� E)  an independent set of G is any subset T ⊆ V such
that no two i� j ∈ T are connected by an edge in E. An independent set is maximal if no proper
superset thereof is itself an independent set. The size of a largest (maximal) independent set is the
independence number of G  denoted by α(G). If G is directed  we can still associate with it an
independence number: we simply view G as undirected by ignoring arc orientation. If G = (V� D)
is a directed graph  then a subset R ⊆ V is a dominating set for G if for all j �∈ R there exists
some i ∈ R such that arc (i� j) ∈ D. In our bandit setting  a time-t dominating set Rt is a subset of
actions with the property that the loss of any remaining action in round t can be observed by playing

4 Although we deﬁned the problem in terms of losses  our analysis can be applied to the case when actions

return rewards gi�t ∈ [0� 1] via the transformation �i�t = 1 − gi�t.

3

Algorithm 1: Exp3-SET algorithm (for the uninformed setting)
Parameter: η ∈ [0� 1]
Initialize: wi�1 = 1 for all i ∈ V = {1� . . . � K}
For t = 1� 2� . . . :

1. Observation system {Si�t}i∈V is generated but not disclosed ;
2. Set pi�t =

for each i ∈ V   where Wt =�j∈V

wi�t
Wi�t

wj�t ;

3. Play action It drawn according to distribution pt = (p1�t� . . . � pK�t) ;
4. Observe pairs (i� �i�t) for all i ∈ SIt�t;
5. Observation system {Si�t}i∈V is disclosed ;

6. For any i ∈ V set wi�t+1 = wi�t exp�−η��i�t�  where

and

I{i ∈ SIt�t}

�i�t
qi�t

qi�t = �j : j

t−→i

pj�t .

��i�t =

some action in Rt. A dominating set is minimal if no proper subset thereof is itself a dominating set.
The domination number of directed graph G  denoted by γ(G)  is the size of a smallest (minimal)
dominating set of G.
Computing a minimum dominating set for an arbitrary directed graph Gt is equivalent to solving a
minimum set cover problem on the associated observation system {Si�t}i∈V . Although minimum
set cover is NP-hard  the well-known Greedy Set Cover algorithm [9]  which repeatedly selects
from {Si�t}i∈V the set containing the largest number of uncovered elements so far  computes a
dominating set Rt such that |Rt| ≤ γ(Gt) (1 + ln K).
Finally  we can also lift the notion of independence number of an undirected graph to directed graphs
through the notion of maximum acyclic subgraphs: Given a directed graph G = (V� D)  an acyclic

subgraph of G is any graph G� = (V �� D�) such that V � ⊆ V   and D� = D ∩�V � × V ��  with no

(directed) cycles. We denote by mas(G) = |V �| the maximum size of such V �. Note that when G
is undirected (more precisely  as above  when G is a directed graph having for every pair of nodes
i� j ∈ V either no arcs or length-two cycles)  then mas(G) = α(G)  otherwise mas(G) ≥ α(G).
In particular  when G is itself a directed acyclic graph  then mas(G) = |V |.

3 Algorithms without Explicit Exploration: The Uninformed Setting

In this section  we show that a simple variant of the Exp3 algorithm [3] obtains optimal regret (to
within logarithmic factors) in the symmetric and uninformed setting. We then show that even the
harder adversarial directed setting lends itself to an analysis  though with a weaker regret bound.

Exp3-SET (Algorithm 1) runs Exp3 without mixing with the uniform distribution. Similar to Exp3 

Exp3-SET uses loss estimates��i�t that divide each observed loss �i�t by the probability qi�t of ob-
serving it. This probability qi�t is simply the sum of all pj�t such that j t−→ i (the sum includes pi�t).

Next  we bound the regret of Exp3-SET in terms of the key quantity

Qt =�i∈V

pi�t
qi�t

=�i∈V

pi�t�j : j

t−→i

.

pj�t

(1)

Each term pi�t/qi�t can be viewed as the probability of drawing i from pt conditioned on the event
that i was observed. Similar to [14]  a key aspect to our analysis is the ability to deterministically and
nonvacuously5 upper bound Qt in terms of certain quantities deﬁned on {Si�t}i∈V . We do so in two
ways  either irrespective of how small each pi�t may be (this section) or depending on suitable lower
bounds on the probabilities pi�t (Section 4). In fact  forcing lower bounds on pi�t is equivalent to
adding exploration terms to the algorithm  which can be done only when knowing {Si�t}i∈V before
each prediction —an information available only in the informed setting.

5 An obvious upper bound on Qt is K.

4

The following result is the building block for all subsequent results in the uninformed setting.6

Theorem 1 The regret of Exp3-SET satisﬁes

max
k∈V

��LA�T − Lk�T� ≤

ln K

η

+

η
2

�[Qt] .

T�t=1

As we said  in the adversarial and symmetric case the observation system at time t can be described
by an undirected graph Gt = (V� Et). This is essentially the problem of [14]  which they studied
in the easier informed setting  where the same quantity Qt above arises in the analysis of their
ELP algorithm. In their Lemma 3  they show that Qt ≤ α(Gt)  irrespective of the choice of the
probabilities pt. When applied to Exp3-SET  this immediately gives the following result.

Corollary 2 In the symmetric setting  the regret of Exp3-SET satisﬁes

In particular  if for constants α1� . . . � αT we have α(Gt) ≤ αt  t = 1� . . . � T   then setting η =

�(2 ln K)��T

t=1 αt  gives

�[α(Gt)] .

max
k∈V

η

+

η
2

ln K

T�t=1
��LA�T − Lk�T� ≤
��LA�T − Lk�T� ≤����2(ln K)

max
k∈V

αt .

T�t=1

The bounds proven in Corollary 2 are equivalent to those proven in [14] (Theorem 2 therein) for
the ELP algorithm. Yet  our analysis is much simpler and  more importantly  our algorithm is sim-
pler and more efﬁcient than ELP  which requires solving a linear program at each step. Moreover 
unlike ELP  Exp-SET does not require prior knowledge of the observation system {Si�t}i∈V at the
beginning of each step.

We now turn to the directed setting. We start by considering a setting in which the observation
system is stochastically generated. Then  we turn to the harder adversarial setting.

The Erd˝os-Renyi model is a standard model for random directed graphs G = (V� D)  where we are
given a density parameter r ∈ [0� 1] and  for any pair i� j ∈ V   arc (i� j) ∈ D with independent
probability r.7 We have the following result.

Corollary 3 Let Gt be generated according to the Erd˝os-Renyi model with parameter r ∈ [0� 1].
Then the regret of Exp3-SET satisﬁes

In the above  the expectations �[·] are w.r.t. both the algorithm’s randomization and the random

+

η T

ln K

max
k∈V

��LA�T − Lk�T� ≤
2r �1 − (1 − r)K� .
generation of Gt occurring at each round. In particular  setting η =� 2r ln K
��LA�T − Lk�T� ≤� 2(ln K)T (1 − (1 − r)K)

max
k∈V

η

r

.

T �1−�1−r)K )   gives

Note that as r ranges in [0� 1] we interpolate between the bandit (r = 0)8 and the expert (r = 1)
regret bounds.

When the observation system is generated by an adversary  we have the following result.

Corollary 4 In the directed setting  the regret of Exp3-SET satisﬁes

max
k∈V

��LA�T − Lk�T� ≤

ln K

η

+

η
2

T�t=1

�[mas(Gt)] .

6 All proofs are given in the supplementary material to this paper.
7 Self loops  i.e.  arcs �i� i) are included by default here.
8 Observe that limr�0+

1−�1−r)K

= K.

r

5

In particular  if for constants m1� . . . � mT we have mas(Gt) ≤ mt  t = 1� . . . � T   then setting

η =�(2 ln K)��T

t=1 mt  gives

max
k∈V

��LA�T − Lk�T� ≤����2(ln K)

mt .

T�t=1

Observe that Corollary 4 is a strict generalization of Corollary 2 because  as we pointed out in
Section 2  mas(Gt) ≥ α(Gt)  with equality holding when Gt is an undirected graph.
As far as lower bounds are concerned  in the symmetric setting  the authors of [14] derive a lower

bound of Ω��α(G)T� in the case when Gt = G for all t. We remark that similar to the symmetric
setting  we can derive a lower bound of Ω��α(G)T�. The simple observation is that given a

directed graph G  we can deﬁne a new graph G� which is made undirected just by reciprocating arcs;
namely  if there is an arc (i� j) in G we add arcs (i� j) and (j� i) in G�. Note that α(G) = α(G�).
Since in G� the learner can only receive more information than in G  any lower bound on G also
applies to G�. Therefore we derive the following corollary to the lower bound of [14] (Theorem 4
therein).

Corollary 5 Fix a directed graph G  and suppose Gt = G for all t. Then there exists a �randomized)

adversarial strategy such that for any T = Ω�α(G)3� and for any learning strategy  the expected
regret of the learner is Ω��α(G)T�.

Moreover  standard results in the theory of Erd˝os-Renyi graphs  at least in the symmetric case (e.g. 
[11])  show that  when the density parameter r is constant  the independence number of the resulting
graph has an inverse dependence on r. This fact  combined with the abovementioned lower bound

r   matching (up to logarithmic factors) the upper bound

of [14] gives a lower bound of the form� T

of Corollary 3.

One may wonder whether a sharper lower bound argument exists which applies to the general di-
rected adversarial setting and involves the larger quantity mas(G). Unfortunately  the above mea-
sure does not seem to be related to the optimal regret: Using Claim 1 in the appendix (see proof of
Theorem 3) one can exhibit a sequence of graphs each having a large acyclic subgraph  on which
the regret of Exp3-SET is still small.

The lack of a lower bound matching the upper bound provided by Corollary 4 is a good indication
that something more sophisticated has to be done in order to upper bound Qt in (1). This leads us
to consider more reﬁned ways of allocating probabilities pi�t to nodes. In the next section  we show
an allocation strategy that delivers optimal (to within logarithmic factors) regret bounds using prior
knowledge of the graphs Gt.

4 Algorithms with Explicit Exploration: The Informed Setting

We are still in the general scenario where graphs Gt are adversarially generated and directed  but
now Gt is made available before prediction. We start by showing a simple example where our
analysis of Exp3-SET inherently fails. This is due to the fact that  when the graph induced by the
observation system is directed  the key quantity Qt deﬁned in (1) cannot be nonvacuously upper
bounded independent of the choice of probabilities pi�t. A way around it is to introduce a new
algorithm  called Exp3-DOM  which controls probabilities pi�t by adding an exploration term to the
distribution pt. This exploration term is supported on a dominating set of the current graph Gt. For
this reason  Exp3-DOM requires prior access to a dominating set Rt at each time step t which  in
turn  requires prior knowledge of the entire observation system {Si�t}i∈V .
As announced  the next result shows that  even for simple directed graphs  there exist distributions
pt on the vertices such that Qt is linear in the number of nodes while the independence number is
1.9 Hence  nontrivial bounds on Qt can be found only by imposing conditions on distribution pt.

9 In this speciﬁc example  the maximum acyclic subgraph has size K  which conﬁrms the looseness of

Corollary 4.

6

Algorithm 2: Exp3-DOM algorithm (for the uninformed setting)

Input: Exploration parameters γ�b) ∈ (0� 1] for b ∈�0� 1� . . . ��log2 K��

i�1 = 1 for all i ∈ V and b ∈�0� 1� . . . ��log2 K��

Initialization: w�b)
For t = 1� 2� . . . :

1. Observation system {Si�t}i∈V is generated and disclosed ;
2. Compute a dominating set Rt ⊆ V for Gt associated with {Si�t}i∈V ;

3. Let bt be such that |Rt| ∈�2bt � 2bt+1 − 1�;

4. Set W �bt)

i�t ;

t =�i∈V w�bt)
i�t =�1 − γ�bt)� w�bt)

i�t

γ�bt)
|Rt|

5. Set p�bt)

t

+

W �bt)

I{i ∈ Rt};
6. Play action It drawn according to distribution p�bt)
7. Observe pairs (i� �i�t) for all i ∈ SIt�t;
8. For any i ∈ V set w�bt)
���bt)
i�t =

exp�−γ�bt)���bt)

I{i ∈ SIt�t}

i�t+1 = w�bt)

�i�t
q�bt)

and

i�t

i�t

V�t� ;

1�t � . . . � p�bt)

t =�p�bt)
i�t /2bt�  where
i�t = �j : j

q�bt)

t−→i

p�bt)

j�t

.

Fact 6 Let G = (V� D) be a total order on V = {1� . . . � K}  i.e.  such that for all i ∈ V   arc
(j� i) ∈ D for all j = i + 1� . . . � K. Let p = (p1� . . . � pK) be a distribution on V such that pi = 2−i 
for i < K and pk = 2−K+1. Then

Q =

K�i=1

pi

pi +�j : j−→i pj

=

K�i=1

pi
j=i pj

�K

=

K + 1

2

.

We are now ready to introduce and analyze the new algorithm Exp3-DOM for the informed and
directed setting. Exp3-DOM (see Algorithm 2) runs �(log K) variants of Exp3 indexed by b =
0� 1� . . . ��log2 K�. At time t the algorithm is given observation system {Si�t}i∈V   and computes
a dominating set Rt of the directed graph Gt induced by {Si�t}i∈V . Based on the size |Rt| of Rt 
the algorithm uses instance bt = �log2 |Rt|� to pick action It. We use a superscript b to denote the
quantities relevant to the variant of Exp3 indexed by b. Similarly to the analysis of Exp3-SET  the
key quantities are

i�t

p�b)
q�b)

�

j�t

and

q�b)

p�b)

p�b)

Q�b)

t−→i

t =�i∈V

j�t = �j : j

i�t = �j : i∈Sj�t
Let T �b) =�t = 1� . . . � T : |Rt| ∈ [2b� 2b+1 − 1]�. Clearly  the sets T �b) are a partition of the time
steps {1� . . . � T}  so that�b |T �b)| = T . Since the adversary adaptively chooses the dominating

sets Rt  the sets T �b) are random. This causes a problem in tuning the parameters γ�b). For this
reason  we do not prove a regret bound for Exp3-DOM  where each instance uses a ﬁxed γ�b)  but
for a slight variant (described in the proof of Theorem 7 —see the appendix) where each γ�b) is set
through a doubling trick.

b = 0� 1� . . . ��log2 K� .

i�t

Theorem 7 In the directed case  the regret of Exp3-DOM satisﬁes

max
k∈V

��LA�T − Lk�T� ≤

�log2 K��b=0

� 2b ln K
γ�b) + γ�b)� �t∈T �b)�1 +

7

t

Q�b)

2b+1� .

(2)

Moreover  if we use a doubling trick to choose γ�b) for each b = 0� . . . ��log2 K�  then

��LA�T − Lk�T� = ��(ln K) �

����

T�t=1�4|Rt| + Q�bt)

t � + (ln K) ln(KT ) .

max
k∈V

(3)

Importantly  the next result shows how bound (3) of Theorem 7 can be expressed in terms of the se-
quence α(Gt) of independence numbers of graphs Gt whenever the Greedy Set Cover algorithm [9]
(see Section 2) is used to compute the dominating set Rt of the observation system at time t.

Corollary 8 If Step 2 of Exp3-DOM uses the Greedy Set Cover algorithm to compute the dominating
sets Rt  then the regret of Exp-DOM with doubling trick satisﬁes

max
k∈V

��LA�T − Lk�T� = ��ln(K)����ln(KT )

T�t=1

α(Gt) + ln(K) ln(KT )

where  for each t  α(Gt) is the independence number of the graph Gt induced by observation system
{Si�t}i∈V .
Comparing Corollary 8 to Corollary 5 delivers the announced characherization in the general ad-
versarial and directed setting. Moreover  a quick comparison between Corollary 2 and Corollary 8
reveals that a symmetric observation system overcomes the advantage of working in an informed
setting: The bound we obtained for the uninformed symmetric setting (Corollary 2) is sharper by
logarithmic factors than the one we derived for the informed —but more general  i.e.  directed—
setting (Corollary 8).

5 Conclusions and work in progress

We have investigated online prediction problems in partial information regimes that interpolate be-
tween the classical bandit and expert settings. We have shown a number of results characterizing
prediction performance in terms of: the structure of the observation system  the amount of informa-
tion available before prediction  the nature (adversarial or fully random) of the process generating
the observation system. Our results are substantial improvements over the paper [14] that initi-
ated this interesting line of research. Our improvements are diverse  and range from considering
both informed and uninformed settings to delivering more reﬁned graph-theoretic characterizations 
from providing more efﬁcient algorithmic solutions to relying on simpler (and often more general)
analytical tools.

Some research directions we are currently pursuing are the following: (1) We are currently inves-
tigating the extent to which our results could be applied to the case when the observation system
{Si�t}i∈V may depend on the loss �It�t of player’s action It. Note that this would prevent a di-
rect construction of an unbiased estimator for unobserved losses  which many worst-case bandit
algorithms (including ours —see the appendix) hinge upon.
(2) The upper bound contained in
Corollary 4 and expressed in terms of mas(·) is almost certainly suboptimal  even in the uninformed
setting  and we are trying to see if more adequate graph complexity measures can be used instead.
(3) Our lower bound in Corollary 5 heavily relies on the corresponding lower bound in [14] which 
in turn  refers to a constant graph sequence. We would like to provide a more complete charecteriza-
tion applying to sequences of adversarially-generated graphs G1� G2� . . . � GT in terms of sequences
of their corresponding independence numbers α(G1)� α(G2)� . . . � α(GT ) (or variants thereof)  in
both the uninformed and the informed settings. (4) All our upper bounds rely on parameters to be
tuned as a function of sequences of observation system quantities (e.g.  the sequence of indepen-
dence numbers). We are trying to see if an adaptive learning rate strategy `a la [4]  based on the
observable quantities Qt  could give similar results without such a prior knowledge.

Acknowledgments

NA was supported in part by an ERC advanced grant  by a USA-Israeli BSF grant  and by the Israeli
I-CORE program. NCB acknowledges partial support by MIUR (project ARS TechnoMedia  PRIN
2010-2011  grant no. 2010N5K7EB 003). YM was supported in part by a grant from the Israel
Science Foundation  a grant from the United States-Israel Binational Science Foundation (BSF)  a
grant by Israel Ministry of Science and Technology and the Israeli Centers of Research Excellence
(I-CORE) program (Center No. 4/11).

8

References

[1] N. Alon and J. H. Spencer. The probabilistic method. John Wiley � Sons  2004.

[2] Jean-Yves Audibert and S´ebastien Bubeck. Minimax policies for adversarial and stochastic

bandits. In COLT  2009.

[3] Peter Auer  Nicol`o Cesa-Bianchi  Yoav Freund  and Robert E. Schapire. The nonstochastic

multiarmed bandit problem. SIAM Journal on Computing  32(1):48–77  2002.

[4] Peter Auer  Nicol`o Cesa-Bianchi  and Claudio Gentile. Adaptive and self-conﬁdent on-line

learning algorithms. J. Comput. Syst. Sci.  64(1):48–75  2002.

[5] Y. Caro. New results on the independence number. In Tech. Report  Tel-Aviv University  1979.

[6] N. Cesa-Bianchi  Y. Freund  D. Haussler  D. P. Helmbold  R. E. Schapire  and M. K. Warmuth.

How to use expert advice. J. ACM  44(3):427–485  1997.

[7] N. Cesa-Bianchi and G. Lugosi. Prediction  learning  and games. Cambridge University Press 

2006.

[8] Nicol`o Cesa-Bianchi and G´abor Lugosi. Combinatorial bandits.

J. Comput. Syst. Sci. 

78(5):1404–1422  2012.

[9] V. Chvatal. A greedy heuristic for the set-covering problem. Mathematics of Operations

Research  4(3):233–235  1979.

[10] Yoav Freund and Robert E. Schapire. A decision-theoretic generalization of on-line learning
and an application to boosting. In Euro-COLT  pages 23–37. Springer-Verlag  1995. Also 
JCSS 55(1): 119-139 (1997).

[11] A. M. Frieze. On the independence number of random graphs. Discrete Mathematics  81:171–

175  1990.

[12] A. Kalai and S. Vempala. Efﬁcient algorithms for online decision problems. Journal of Com-

puter and System Sciences  71:291–307  2005.

[13] Nick Littlestone and Manfred K. Warmuth. The weighted majority algorithm. Information and

Computation  108:212–261  1994.

[14] S. Mannor and O. Shamir. From bandits to experts: On the value of side-observations. In 25th

Annual Conference on Neural Information Processing Systems �NIPS 2011)  2011.

[15] Alan Said  Ernesto W De Luca  and Sahin Albayrak. How social relationships affect user
In Proceedings of the International Conference on Intelligent User Interfaces

similarities.
Workshop on Social Recommender Systems  Hong Kong  2010.

[16] V. G. Vovk. Aggregating strategies. In COLT  pages 371–386  1990.

[17] V. K. Wey. A lower bound on the stability number of a simple graph. In Bell Lab. Tech. Memo

No. 81-11217-9  1981.

9

,Noga Alon
Nicolò Cesa-Bianchi
Claudio Gentile
Yishay Mansour
Xing Yan
Weizhong Zhang
Lin Ma
Wei Liu
Qi Wu
Eugene Ndiaye
Ichiro Takeuchi