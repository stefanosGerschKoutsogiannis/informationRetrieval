2011,Analytical Results for the Error in Filtering of Gaussian Processes,Bayesian filtering of stochastic stimuli has received a great deal of attention re- cently. It has been applied to describe the way in which biological systems dy- namically represent and make decisions about the environment. There have been no exact results for the error in the biologically plausible setting of inference on point process  however. We present an exact analysis of the evolution of the mean- squared error in a state estimation task using Gaussian-tuned point processes as sensors. This allows us to study the dynamics of the error of an optimal Bayesian decoder  providing insights into the limits obtainable in this task. This is done for Markovian and a class of non-Markovian Gaussian processes. We find that there is an optimal tuning width for which the error is minimized. This leads to a char- acterization of the optimal encoding for the setting as a function of the statistics of the stimulus  providing a mathematically sound primer for an ecological theory of sensory processing.,Analytical Results for the Error in Filtering of

Gaussian Processes

Bernstein Center for Computational Neuroscience Berlin Technische Universit¨at Berlin

alex.susemihl@bccn-berlin.de

Alex Susemihl

Ron Meir

Department of Eletrical Engineering  Technion  Haifa

rmeir@ee.technion.ac.il

Bernstein Center for Computational Neuroscience Berlin  Technische Universit¨at Berlin

opperm@cs.tu-berlin.de

Manfred Opper

Abstract

Bayesian ﬁltering of stochastic stimuli has received a great deal of attention re-
cently. It has been applied to describe the way in which biological systems dy-
namically represent and make decisions about the environment. There have been
no exact results for the error in the biologically plausible setting of inference on
point process  however. We present an exact analysis of the evolution of the mean-
squared error in a state estimation task using Gaussian-tuned point processes as
sensors. This allows us to study the dynamics of the error of an optimal Bayesian
decoder  providing insights into the limits obtainable in this task. This is done for
Markovian and a class of non-Markovian Gaussian processes. We ﬁnd that there
is an optimal tuning width for which the error is minimized. This leads to a char-
acterization of the optimal encoding for the setting as a function of the statistics
of the stimulus  providing a mathematically sound primer for an ecological theory
of sensory processing.

1

Introduction

Biological systems are constantly interacting with a dynamic  noisy environment  which they can
only assess through noisy sensors. Models of Bayesian decision-making have been suggested to
account for the functioning of biological systems in many areas [1  2]. Here  we concentrate on the
problem of Bayesian ﬁltering of stochastic processes. There have been many studies on ﬁltering
of stimuli by biological systems [1  2  3]  however  there are very few analytical results regarding
the error of Bayesian ﬁltering. We provide exact expressions for the evolution of the Mean Squared
Error (MSE) of Bayesian ﬁltering for a class of Gaussian processes. Results for expected errors of
Gaussian processes had been sofar obtained only for the problem of smoothing  where predictions
are not online but have to be made using past and future observations [4  5].
The present work seeks to give an account of the error properties in Bayesian ﬁltering of stochastic
processes. We start by analysing the case of Markovian processes in section 2. We ﬁnd a set of
ﬁltering equations from which we can derive a differential equation for the expected mean squared
error. This provides a way to optimize the system parameters (the ’encoder’) in order to minimize
the error. We present an implicit equation to optimize the encoding scheme in the case of Poisson
spike observations. We also provide a full stochastic model of the evolution of the error  which can

1

be solved analytically in a given interval. Useful approximations for the distribution of the error are
also provided. In section 3 we show an application to optimal population coding in sensory neurons.
In section 4 we extend the same framework to higher order processes  where we can control the
smoothness by the order of the process. We ﬁnalize with a brief discussion. Our theoretical results
contribute to the ongoing research on ecological theories in biological signal processing (e.g.  [6]) 
which argue that performance of sensory systems can be enhanced by allowing sensors to adapt
to the statistics of the environment. While an increasing amount of biological evidence has been
accumulating for such theories (e.g.  [7  8  9  10  11]) there has been little work providing exact
analytic demonstration of its utility so far.

2 Bayesian Filtering for the Ornstein-Uhlenbeck Process

Consider the problem of estimating a dynamically evolving state in continuous time based on partial
noisy observations. In classic approaches one assumes that the state is observed either continuously
or at discrete times  leading to the celebrated Kalman ﬁlter and its extensions. We are concerned here
with a setup of much interest in Neuroscience (as well as in Queueing theory) where the observations
take the form of a a set of point processes. More concretely  let X(t) be a stochastic process 
and let M ‘sensory’ processes be deﬁned  each of which generates a Poisson point process with
a time-dependent rate function λm(X(t)  t)  m = 1  2  . . .   M. Such a stochastic process is often
referred to as a doubly stochastic point process. In a neuroscience context λm(·) represents the
tuning function of the m’th sensory cell. In order to maintain analytic tractability we focus in this

work on a Gaussian form for λm  given by λm(X(t)  t) = φ exp(cid:2)−(X(t) − θm)2/2α(t)2(cid:3)  where

θm are the tuning function centers. We will assume the tuning function centers are equally spaced
with spacing ∆θ  for simplicity  although this is not essential to our arguments.
Though the rate of observations for the individual processes depends on the instantaneous value of
the process  it can be shown that under certain assumptions the total rate of observations (the rate
by which observations by all processes are generated) is independent of the process. If we assume
that the processes are independent and assume that the probability of the stimulus falling outside the
range spanned by the tuning function centers is negligible  we obtain the total rate of observations

(cid:88)

(cid:20)
− (X(t) − θm)2

(cid:21)

2α2(t)

√

≈

2πφα(t)

∆θ

.

λm(X(t)  t) = φ

exp

m

m

λ(t) ≈(cid:88)

This approximation is discussed extensively in [12] and is seen to be very precise as long as α is of
the same or of a larger order of magnitude as ∆θ. Denoting the set of observations generated by the
sensory processes by ξ = {(ti  mi  Θi)}1  we have the probability of a given set of observations ξ
given a stimulus history X[t0 t]
(cid:82) tf

λm(X(t) t)dt(cid:89)

λ(t)dt(cid:89)

−(cid:80)

−(cid:82) tf

t0

λmi(X(ti)  ti) = e

P (ξ|X[t0 t]) = e

m

t0

λmi(X(ti)  ti).

i

i

This deﬁnes the likelihood of the observations. Note that without the independence of the total rate
from the stimulus  the likelihood would not be Gaussian due to the ﬁrst term in the product. We
need to evaluate the posterior probability P (X(t)|ξ). We have

P (X(t)|ξ) ∝ P (X(t))P (ξ|X(t)) = P (X(t))

dµ(X[t0 t))P (ξ|X[t0 t))P (X[t0 t)|X(t)).

(cid:90)

(cid:88)

s(t  ξ) = K(0) −(cid:88)

The equations involved are Gaussian and evaluating them we obtain the usual Gaussian process
regression equations (see [13] and [14  p. 17])

µ(t  ξ) =

K(t − ti)C−1

ij Θj 

K(t − ti)C−1

ij K(tj − t)  2

(1)

i j

i j

where K(t − t(cid:48)) is the auto-correlation function or kernel of the Gaussian process X(t). This
speciﬁes the posterior distribution P (X(t)|ξ) = N (µ(t  ξ)  s(t  ξ)).

observation and Θi = θmi is the mean of the Gaussian rate function.

1Here the time ti denotes the time of the i-th observation  mi gives the identity of the sensor making the
2Cij(ξ) = K(ti − tj) + δijα(ti)2

2

Our object of interest is the average mean squared error of the Bayesian estimator at a time t based
on past observations. This is the minimal mean-squared error of the optimal Bayesian estimator
ˆX(t; ξ) = (cid:104)X(t)(cid:105)X(t)|ξ with respect to a mean-squared error loss function. It is given by

(cid:28)(cid:68)
(X(t) − ˆX(t; ξ))2(cid:69)

(cid:29)

X(t)|ξ

=

ξ

(cid:68)(cid:10)(X(t) − µ(t; ξ))2(cid:11)

(cid:69)

X(t)|ξ

= (cid:104)s(t; ξ)(cid:105)ξ .

ξ

M M SE(t) =

Here we have written the averaging in the reverse of the usual order and have used ˆX(t  ξ) = µ(t  ξ)
in the second step. Note that the posterior variance is independent of the value of the observations 
depending solely on the observation times. However the exact result is still intractable due to both
the complex dependence of s(t  ξ) on the observation times and the averaging over these. Note that
so far the results hold for all kinds of Gaussian processes.
If we make a Markov assumption about the structure of the kernel K(t − t(cid:48)) we are able to
make statements about the evolution of the posterior variance between observations. This allows
us to derive the differential Chapman-Kolmogorov equation [15] for the evolution of the poste-
rior variance and then obtain the evolution of the MMSE. For the Ornstein-Uhlenbeck process
dX(t) = −γX(t)dt + ηdW (t) we have the kernel k(τ ) = η2
2γ e−γ|τ| and the differential equa-
tion for the evolution of the posterior variance between observations (see [16  p. 40] for example)

ds(t)

dt

= −2γs(t) + η2.

(2)

When a new observation arrives  the distribution is updated through Bayes’ rule. Using that
P (X(t)) = N (µ(t)  s(t)) and P (θi|X) ∝ N (θi; X  α2(t))  one can see that
α2(t)s(t)

(cid:18) α2(t)µ(t) + s(t)θi

(cid:19)

P (X(t)|(t  θi)) = N

(3)

α2(t) + s(t)

α2(t) + s(t)

 

.

Here  as before  the posterior variance is independent of the speciﬁc observation θi  therefore we
need only concentrate on the times of observations for purposes of modeling the posterior variance.
The evolution of the posterior variance is a Markov process which is driven by a deterministic drift 
given in Eq. 2  and is also subject to discontinuous jumps at random times  which account for the
observations  described by Eq. 3. This continuous time stochastic process is deﬁned by a transition
probability which in the time limit of inﬁnitesimal time dt → 0 is given by
P (s(cid:48)  t + dt|s  t) = (1 − λ(t)dt)δ(s(cid:48) − s + dt(2γs − η2)) + λ(t)dtδ

(cid:18)

(cid:19)

(4)

.

s(cid:48) − α(t)2s
α(t)2 + s

In the equation above  the ﬁrst term accounts for the drift given in Eq. 2 and the second term accounts
for the jumps given by Eq. 3. Using (4)  and following a standard approach described in Gardiner
[15  p. 47]  we obtain a partial differential equation  the so-called differential Chapman-Kolmogorov
equation for the exact time evolution of the marginal probability density P (s  t)

(cid:2)(2γs − η2)P (s  t)(cid:3) + λ

(cid:18) α2

α2 − s

∂P (s  t)

∂t

=

∂
∂s

− λP (s  t).

(5)

This equation is  however  too complicated to be solved exactly in the general case. We can use it to
derive the evolution of statistical averages by noting that d(cid:104)f (s)(cid:105)
. For f (s) = s
we obtain an exact equation for the evolution of the average error. Writing  = (cid:104)s(cid:105)  we have

∂t

P

  t

(cid:19)

α2 − s

(cid:19)2
(cid:18) α2s
dt =(cid:82) dsf (s) ∂P (s t)
(cid:29)

(cid:28)

s2

α2(t) + s

.

P (s t)

= −2γ + η2 − λ(t)

d
dt

2.1 Mean ﬁeld approximation

(6)

We will now derive a good closed form approximate equation for the expected posterior variance
 = (cid:104)s(cid:105) from (6). Note that the expectation of the nonlinear function on the right hand side is again
intractable but can be approximated using a mean-ﬁeld approximation of the type (cid:104)f (s)(cid:105) ≈ f ((cid:104)s(cid:105)).
We obtain

dmf
dt

= −2γmf + η2 − λ(t)

2
mf

α(t)2 + mf

.

(7)

3

This approximation works remarkably well  giving an excellent account of the equilibrium regime
and of the relaxation of the error as can be seen in Fig. 2 for the case of population coding. We
can also minimize the change in  at each time step with respect to the sensor parameters α  φ to
ﬁnd optimal values for them. The maximal observation rate φ is quite trivial  as an increase in φ
increases the effect of observations linearly. Therefore without a cost associated to observations 
there is no optimal value for φ  since increasing it will always lead to lower values of . Minimizing
the derivative of  with respect to α however  yields an implicit equation for the optimal value of
α(t)

(cid:29)

(cid:44)(cid:28)

(cid:29)

s2

(cid:28)

αopt(t)2 =

s3

(αopt(t)2 + s)2

P (s t)

(αopt(t)2 + s)2

P (s t)

(8)

Using again a mean-ﬁeld approach  we obtain the simple result for the time-dependent tuning width
opt(t) = (t)  so the square of the optimal tuning width is the average error of the current estimate
α2
of the process. This is interesting as it accounts for sharpening of the gaussian rates when the error
is small and broadening when the error is large.

2.2 Exact results for the stationary distribution

We will now assume that both λ and α are time independent so that the stochastic process converges
to a stationary state described by ∂P (s t)
∂t = 0. To obtain information about this stationary solution it
is useful to introduce the new variable z = η2/(γs). The linear ODE 2 transforms into a nonlinear
one ˙z(t) = γz(2 − z). This slight complication comes with a great simpliﬁcation for the jump
conditions. In the new variable this is simply z(cid:48) = z + δ where δ = η2/(γα2) does not depend on z.
Hence the differential Chapman-Kolmogorov equation (specialised to the stationary state) is simply

− d
dz

[γz(2 − z)P (z)] + λP (z − δ) − λP (z) = 0

(9)

Viewing z as a temporal variable  we can treat Eq. 9 as a delay differential equation which depends
on p at previous values of z. If we knew P (z) in an interval z0 − δ ≤ z < z0  Eq. 9 would however
become a simple ordinary linear differential equation with a known inhomogeneity P (z − δ) in the
interval z0 ≤ z ≤ z0 + δ which could be solved explicitly by numerical quadrature. Repeating this
procedure would allow us to obtain p(z) iteratively for all z > 0. A simple argument shows that
P (z) = 0 for z < 2. Since jumps can only increase z and since also ˙z(t) > 0 for z < 2  we ﬁnd that
in the stationary state  the interval 0 ≤ z < 2 will become depopulated. Hence  for 2 ≤ z ≤ 2 + δ
we have

− d
dz

[γz(2 − z)P (z)] = λP (z)

valid for s ∈ (cid:104) α2η2

(cid:105)

which is solved by P (z) ∝ z−2(1 − 2/z)−1+λ/2γ Transforming back to the original error variable
s yields

Peq(s) ∝ (η2 − 2γs)

λ

2γ −1.

(10)

2γ

2γα2+η2   η2

. This is a very interesting result  as it shows a diverging behaviour
in the equilibrium for values of λ < 2γ. This singularity can also be veriﬁed in the simulations.
This solution gives us a good intuition about the coding properties of the system. When the average
time between observations τobs = 1/λ is smaller than the relaxation time of the process’ variance
τvar = 1/2γ  the most probable value for the error will be the equilibrium variance of the observed
process η2/2γ. Note however that the expected error is always smaller than η2/2γ. When λ = 2γ
we observe a transition and the most likely error becomes smaller.
It was not possible to give
closed form analytical expressions for p(z) in the following intervals because the integrals are not
analytically tractable. We can  however  solve (10) numerically obtaining great agreement with the
simulated histograms. For very small values of δ  the numerical integration becomes less reliable 
as the valid intervals become increasingly small  requiring a very small integration step. This can be
seen in Fig. 1.
We can get asymptotic expressions for P (z) when parameters are such that the relative ﬂuctuations
of z are small. This is expected to hold for small jumps δ (when the system is trivially almost
deterministic) and/or for large jump rates λ  when the density of jumps is so large that relative
ﬂuctuations are small. Using again a simple mean ﬁeld argument as before shows that in such

4

Figure 1: Comparison of the different regimes for the equilibrium distribution. Top left we can see α = φ = 1.
Note that neither solutions cover all of the range of the distribution  although the exact solution captures the
behaviour very well in the low z region. Top right we can see the low α regime. Note that the exact solution
accounts for the distribution on most of the range of the distribution. In the bottom we see the cases where the
Gaussian approximation excels. Both large α and φ result in an approximately Gaussian distribution  as we
have derived above. The blue line (exact solution) is hardly discernible from the red line (histogram) in the
small α case  as is the black line (Gaussian approximation) in the large α or φ case.

situations we ﬁnd that in equilibrium z should be close to z∗ = 1 +(cid:112)1 + λδ/γ. For both small δ

and/or large λ  for z close to z∗ we have δ (cid:28) z∗ and we can expand p(z − δ) in a Taylor series to
second order in δ. Linearising also the drift γz(2 − z) around z∗ yields a Fokker-Planck equation
which is equivalent to a simple diffusion process (of the Ornstein-Uhlenbeck type) which is solved
by the Gaussian density P (z) = N
. In Fig. 1 we present the
different approximations compared to the simulated histograms of the posterior variance.
√
We present results for the speciﬁc choice η = γ = 1. Note however  that through a scaling of
parameters α(cid:48) = αη/
γ and φ(cid:48) = φγ we can obtain the MMSE for any value of the four parameters
with the values for η = γ = 1. In this way  rescaling the parameters  we can obtain the MMSE for
any values of η  γ  α and φ.

1 +(cid:112)1 + λδ/γ 

λδ2
1+λδ/γ)

√

(4γ

(cid:18)

(cid:19)

3 Optimal Population Coding

As an application we look into the problem of neural population coding of dynamic stimuli (see
[13]). We model the spiking of neurons as doubly stochastic Poisson processes driven by the stimu-
lus X(t)  that is the probability of a given neuron ﬁring a spike in a given interval [t  t + dt] is given
by

Pt(spikem|X(t)) = φe

− (X(t)−θm )2

2α(t)2

dt 

and Pt(spike|X(t)) ≈

√

2πφα(t)dt

∆θ

= λ(t)dt.

Under these assumptions  the inference from a spike train is equivalent to that on observations of
data  and the MMSE follows the differential Eq. 6. Again  the fact that the posterior variance
depends solely on the spike times allows us to substitute the spiking processes for each neuron with
one spiking process for the whole population  simplifying greatly our calculations. We compare the
framework derived with the dynamic population coding presented in [13] in Fig. 2.
We have calculated the MMSE for a range of values for α and φ to obtain the dependence of the
MMSE on these parameters.
In Fig. 3 we show the mean-ﬁeld treatment of Eq. 6 as well as
simulations of the dynamics given by Eq. 4. The mean-ﬁeld approximation works remarkably well 
yielding a relative error smaller than 2% throughout the range of parameters. The approximate
and simulated error maps are virtually indistinguishable. As can be seen in Fig. 2 the mean-ﬁeld
approximation also works very well to reﬂect the dynamics of the error.

5

Figure 2: Neural coding of an second-order Markov process as described in the text. Top ﬁgure shows the
process overlayed with posterior mean and conﬁdence intervals. The bottom plot shows the posterior variance
of one sample run in black  the average over a thousand runs in blue and the mean-ﬁeld dynamics in red. Code
modiﬁed from [13]

Figure 3: MMSE for the Ornstein-Uhlenbeck process. On the left we have the average MMSE obtained by the
simulation and on the right the value of the MMSE as a function of α for a few values of φ in the mean-ﬁeld
approximation. The dots are the minima for the mean-ﬁeld and the dotted curves are mean-ﬁeld values for the
same φ. The mean-ﬁeld leads to a very good approximation  and the optimal α for the approximation is a good
estimator for the optimal α in the simulation.

6

4 Filtering Smoother Processes

To study the ﬁltering of smoother processes we will look at higher-order Markov processes. We do
so by considering a multidimensional stochastic process which is Markovian if we consider all of
the components  but restrict ourselves to one component  which will then exhibit a non-Markovian
structure. This is done by an extension to the Ornstein-Uhlenbeck process frequently used in Gaus-
sian process literature  whose correlation structure is given by the Matern kernel (see below). We
have to work with the covariance matrix of the system  since its elements’ dynamics are coupled.
Thus  Eq. 6 will be replaced by a matrix equation  to which we then apply the same treatment.
We consider a p-th order stochastic process such as ap+1X (p)(t) + apX (p−1)(t) + ··· + a1X(t) =
ηZ(t)  where Z(t) is white Gaussian noise with covariance δ(t − t(cid:48)) and X (n)(t) denotes the n-th
derivative of X(t). Writing the proper Ito stochastic differential equations we obtain a set of p − 1
ﬁrst order differential equations and a single ﬁrst order stochastic differential equation 

˙X1 = X2 

˙X2 = X3  . . .  

where Wt is the Wiener process. Choosing ak =(cid:0) p

k−1
an autocorrelation function given by the Matern kernel

˙Xp−1 = Xp 

ap+1dXp = − p(cid:88)
(cid:1)γp+1−k which yields processes X1(t) with

aiXidt + ηdWt 

i=1

k(τ ; ν  γ) =

√

η22−ν

πΓ(ν + 1/2)γν (γτ )ν Kν (γτ )  

where ν + 1
2 = p  Kν(x) is the modiﬁed Bessel function of the second kind and γ is the parameter
determining the characteristic time of the kernel. Note that the one-dimensional Ornstein-Uhlenbeck
process is a special case of this with p = 1  ν = 1/2. We can control the smoothness of the process
X1(t) with the parameter ν  increasing it yields successively smoother processes (see supplementary
information).
We can express this as a multidimensional stochastic process by choosing Γi j = −δi j−1 + δi paj
and Σ1/2
i j = δi pδj pη  where δi j is the Kronecker delta. We then have the Ito stochastic differential
equation

(11)
for (cid:126)X(t)T = (X1(t)  X2(t)  . . .   Xp(t)). The covariance matrix then evolves according to (see [16 
p. 40])

d (cid:126)X(t) = −Γ (cid:126)X(t)dt + Σ1/2d (cid:126)W

= −Γσ − σΓT + Σ.

dσ
dt

(12)
This can be solved using the solution of the homogeneous equation Σ(t) = exp[−tΓ] exp[−tΓt]
and the solution to the inhomogeous equation given by the equilibrium solution.
We assume that only the component X1 is observed  that is  the rate of observations only depends on
that component. We have then P (X1  X2:p|obs) ∝ P (obs|X1)P (X1  X2:p). Note that the precision
matrix (the inverse of the covariance matrix) will be updated simply by adding the likelihood term
1/α(t)2 to the ﬁrst diagonal element. Using the block matrix inversion theorem we obtain the new
covariance matrix

i j = σi j − σ1 iσ1 j
σ(cid:48)
α2 + σ1 1

.

(13)

Putting equations 12 and 13 together we obtain the differential Chapman-Kolmogorov equation for
the evolution of the probability of the covariance matrix. With this we obtain the differential equation
for the average posterior covariance matrix
d(cid:104)σi j(cid:105)

(cid:28) σ1 iσ1 j

= (cid:104)σi+1 j(cid:105)+(cid:104)σi j+1(cid:105)−(cid:88)

(δi pal (cid:104)σi l(cid:105) + δj pal (cid:104)σj l(cid:105))−λ(t)

+η2δi nδj n 

(cid:29)

α(t)2 + σ1 1

dt

l

(14)
where we abuse the notation by using that σi j = 0 if i > p or j > p. These can be solved in
the mean-ﬁeld approximation to obtain an approximation for the covariance matrix. We also note
that one can derive a recursion scheme to express all of the elements as functions of the ﬁrst row
of covariances σ1 1:p. With these expressions we can then use the equilibrium conditions for d(cid:104)σi i(cid:105)

dt

7

Figure 4: MMSE for a second-order stochastic process. On the left is the color map of the ﬁrst diagonal
element of the covariance matrix for the ν = 3/2 case  corresponding to the variance of the observed stimulus
variable and on the right  the same element as a function of α for a few values of φ. The overall dependence of
the error on α and φ is strikingly similar to the OU process  with lower values of the MMSE  however. This is
due to the smoothness of the process  making it more predictable. In red we show the MMSE for the simulated
equilibrium variance for comparison. Though the mean-ﬁeld approximation is not as good as in the OU case 
the relative error of it still falls below 18% throughout the range of parameters studied.

to solve for the equilibrium value of (cid:104)σi j(cid:105). We provide results for the case p = 2  ν = 3/2. The
equilibrium MMSE is shown in Fig. 4 on the left and in Fig. 4 on the right we show the dependence
on α of the MMSE. The dependence of the error on the parameters resembles strongly that of the
Ornstein-Uhlenbeck process  showing a ﬁnite optimal value of α which minimizes the error given
φ. This becomes less pronounced as we go to very low ﬁring rates. Note that for the second-order
process the MMSE relative to the variance of the observed process (MMSE/K(0)) drops to lower
values than in the Ornstein-Uhlenbeck process  leading to a better state estimation. We expect that
the error will become increasingly smaller for higher-order processes.

5 Discussion

We have shown that the dynamics of Bayesian state estimation error for Markovian processes can be
modelled by a simple dynamic system. This provides insight into generalization properties of Gaus-
sian process inference in an online  causal setting  where previous generalization error calculations
[4  5] for Gaussian processes do not apply. In the context of ﬁltering the usual generalization error
calculations do not apply. Furthermore  we have demonstrated that a simple mean-ﬁeld approxima-
tion succesfully captures the dynamics of the average error of the described inference framework.
This was shown in detail for the case of Ornstein-Uhlenbeck processes  and for a class of higher-
order Markov processes.
One key feature we were able to verify is the existence of an optimal tuning width for Gaussian-tuned
Poisson processes which minimizes the MMSE  as has been veriﬁed elsewhere for static stimuli
([17  12  18]). This result is robust to the inclusion of coloured noise  as we have shown by modelling
a second order process.
Future research could concentrate in generalizing the presented framework towards more realistic
spike generation models  such as integrate-and-ﬁre neurons. The generalization to broader classes
of stimuli would be of great interest as well. These results provide a promising ﬁrst step towards a
mathematical theory of ecologically grounded sensory processing.

8

6 Acknowledgements

The work of Alex Susemihl was supported by the DFG Research Training Group GRK1589/1. The
work of Ron Meir was partially supported by grant No. 665/08 from the Israel Science Foundation.

References
[1] Tetsuya J. Kobayashi. Implementation of dynamic bayesian decision making by intracellular

kinetics. Phys. Rev. Lett.  104(22):228104  Jun 2010.

[2] Jean-Pascal Pﬁster  Peter Dayan  and Mate Lengyel. Know thy neighbour: A normative theory
of synaptic depression.
In Y. Bengio  D. Schuurmans  J. Lafferty  C. K. I. Williams  and
A. Culotta  editors  Advances in Neural Information Processing Systems 22  pages 1464–1472.
2009.

[3] Omer Bobrowski  Ron Meir  Shy Shoham  and Yonina C. Eldar. A neural network implement-
ing optimal state estimation based on dynamic spike train decoding. In Neural Information
Processing Systems  2007.

[4] Dorthe Malzahn and Manfred Opper. A statistical physics approach for the analysis of machine
learning algorithms on real data. Journal of Statistical Mechanics: Theory and Experiment 
2005(11):P11001  2005.

[5] P. Sollich and A. Halees. Learning curves for gaussian process regression: Approximations

and bounds. Neural Computation  14(6):1393–1428  2002.

[6] J Atick and A.N. Redlich. Could information theory provide an ecological theory of sensory

processing? Network: Computation in Neural Systems  5:213–251  1992.

[7] M.W. Pettet and C.D. Gilbert. Dynamic changes in receptive-ﬁeld size in cat primary visual

cortex. Proceedings of the National Academy of Sciences  89(17):8366–8370  1992.

[8] N. Brenner  W. Bialek  and R. de Ruyter van Steveninck. Adaptive rescaling maximizes infor-

mation transmission. Neuron  26(3):695–702  2000.

[9] V. Dragoi  J. Sharma  and M. Sur. Adaptation-induced plasticity of orientation tuning in adult

visual cortex. Neuron  28(1):287–298  2000.

[10] I. Dean  B.L. Robinson  N.S. Harper  and D. McAlpine. Rapid neural adaptation to sound level

statistics. Journal of Neuroscience  28(25):6430–6438  2008.

[11] T. Hosoya  S.A. Baccus  and M. Meister. Dynamic predictive coding by the retina. Nature 

436(7047):71–77  2005.

[12] Steve Yaeli and Ron Meir. Error-based analysis of optimal tuning functions explains phenom-

ena observed in sensory neurons. Frontiers in Computational Neuroscience  5(0):12  2010.

[13] Quentin J. M. Huys  Richard S. Zemel  Rama Natarajan  and Peter Dayan. Fast population

coding. Neural Computation  19(2):404–441  2007.

[14] C.E. Rasmussen and C.K.I. Williams. Gaussian Processes for Machine Learning. The MIT

Press  55 Hayward Street  Cambridge  MA 02142  2006.

[15] C.W. Gardiner. Stochastic Methods: A Handbook for the Natural and Social Sciences  vol-

ume 13 of Springer Serier in Synergetics. Springer  Berlin Heidelberg  fourth edition  2009.

[16] Hannes Risken. The Fokker-Planck Equation: Methods of Solutions and Applications  vol-
ume 18 of Springer Series in Synergetics. Springer  Berlin Heidelberg  second ed. 1989. third
printing edition  1996.

[17] M. Bethge  D. Rotermund  and K. Pawelzik. Optimal short-term population coding: When

ﬁsher information fails. Neural Computation  14(10):2317–2351  2002.

[18] Philipp Berens  Alexander S. Ecker  Sebastian Gerwinn  Andreas S. Tolias  and Matthias
Bethge. Reassessing optimal neural population codes with neurometric functions. Proceedings
of the National Academy of Sciences  108(11):4423–4428  2011.

9

,Martin Slawski
Ping Li