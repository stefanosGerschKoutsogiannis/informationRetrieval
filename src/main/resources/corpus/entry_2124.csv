2017,Fisher GAN,Generative Adversarial Networks (GANs) are powerful models for learning complex distributions. Stable training of GANs has been addressed in many recent works which explore different metrics between distributions. In this paper we introduce Fisher GAN that fits within the Integral Probability Metrics (IPM) framework for  training GANs. Fisher GAN defines a data dependent constraint on the second order moments of the critic. We show in this paper that Fisher GAN allows for stable and time efficient  training that does not compromise the capacity of the critic  and does not need data independent constraints such as weight clipping. We analyze our Fisher IPM theoretically and provide an algorithm based on Augmented Lagrangian for Fisher GAN. We validate our claims on both image sample generation and semi-supervised classification using Fisher GAN.,Fisher GAN

Youssef Mroueh⇤  Tom Sercu⇤

mroueh@us.ibm.com  tom.sercu1@ibm.com

⇤ Equal Contribution

AI Foundations  IBM Research AI
IBM T.J Watson Research Center

Abstract

Generative Adversarial Networks (GANs) are powerful models for learning com-
plex distributions. Stable training of GANs has been addressed in many recent
works which explore different metrics between distributions. In this paper we
introduce Fisher GAN which ﬁts within the Integral Probability Metrics (IPM)
framework for training GANs. Fisher GAN deﬁnes a critic with a data dependent
constraint on its second order moments. We show in this paper that Fisher GAN
allows for stable and time efﬁcient training that does not compromise the capacity
of the critic  and does not need data independent constraints such as weight clip-
ping. We analyze our Fisher IPM theoretically and provide an algorithm based on
Augmented Lagrangian for Fisher GAN. We validate our claims on both image
sample generation and semi-supervised classiﬁcation using Fisher GAN.

1

Introduction

Generative Adversarial Networks (GANs) [1] have recently become a prominent method to learn
high-dimensional probability distributions. The basic framework consists of a generator neural
network which learns to generate samples which approximate the distribution  while the discriminator
measures the distance between the real data distribution  and this learned distribution that is referred
to as fake distribution. The generator uses the gradients from the discriminator to minimize the
distance with the real data distribution. The distance between these distributions was the object of
study in [2]  and highlighted the impact of the distance choice on the stability of the optimization. The
original GAN formulation optimizes the Jensen-Shannon divergence  while later work generalized
this to optimize f-divergences [3]  KL [4]  the Least Squares objective [5]. Closely related to our
work  Wasserstein GAN (WGAN) [6] uses the earth mover distance  for which the discriminator
function class needs to be constrained to be Lipschitz. To impose this Lipschitz constraint  WGAN
proposes to use weight clipping  i.e. a data independent constraint  but this comes at the cost of
reducing the capacity of the critic and high sensitivity to the choice of the clipping hyper-parameter.
A recent development Improved Wasserstein GAN (WGAN-GP) [7] introduced a data dependent
constraint namely a gradient penalty to enforce the Lipschitz constraint on the critic  which does not
compromise the capacity of the critic but comes at a high computational cost.
We build in this work on the Integral probability Metrics (IPM) framework for learning GAN of [8].
Intuitively the IPM deﬁnes a critic function f  that maximally discriminates between the real and
fake distributions. We propose a theoretically sound and time efﬁcient data dependent constraint on
the critic of Wasserstein GAN  that allows a stable training of GAN and does not compromise the
capacity of the critic. Where WGAN-GP uses a penalty on the gradients of the critic  Fisher GAN
imposes a constraint on the second order moments of the critic. This extension to the IPM framework
is inspired by the Fisher Discriminant Analysis method.
The main contributions of our paper are:

31st Conference on Neural Information Processing Systems (NIPS 2017)  Long Beach  CA  USA.

1. We introduce in Section 2 the Fisher IPM  a scaling invariant distance between distributions.
Fisher IPM introduces a data dependent constraint on the second order moments of the critic that
discriminates between the two distributions. Such a constraint ensures the boundedness of the metric
and the critic. We show in Section 2.2 that Fisher IPM when approximated with neural networks 
corresponds to a discrepancy between whitened mean feature embeddings of the distributions. In
other words a mean feature discrepancy that is measured with a Mahalanobis distance in the space
computed by the neural network.
2. We show in Section 3 that Fisher IPM corresponds to the Chi-squared distance (2) when the
critic has unlimited capacity (the critic belongs to a universal hypothesis function class). Moreover
we prove in Theorem 2 that even when the critic is parametrized by a neural network  it approximates
the 2 distance with a factor which is a inner product between optimal and neural network critic. We
ﬁnally derive generalization bounds of the learned critic from samples from the two distributions 
assessing the statistical error and its convergence to the Chi-squared distance from ﬁnite sample size.
3. We use Fisher IPM as a GAN objective 1 and formulate an algorithm that combines desirable
properties (Table 1): a stable and meaningful loss between distributions for GAN as in Wasserstein
GAN [6]  at a low computational cost similar to simple weight clipping  while not compromising the
capacity of the critic via a data dependent constraint but at a much lower computational cost than [7].
Fisher GAN achieves strong semi-supervised learning results without need of batch normalization in
the critic.

Table 1: Comparison between Fisher GAN and recent related approaches.

Stability Unconstrained Efﬁcient

capacity

Computation

Representation
power (SSL)

Standard GAN [1  9]
WGAN  McGan [6  8]
WGAN-GP [7]
Fisher Gan (Ours)

7
3
3
3

3
7
3
3

3
3
7
3

3
7
?
3

dF (P  Q) = sup

f2Fn E

2 Learning GANs with Fisher IPM
2.1 Fisher IPM in an arbitrary function space: General framework
Integral Probability Metric (IPM). Intuitively an IPM deﬁnes a critic function f belonging to a
function class F   that maximally discriminates between two distributions. The function class F
deﬁnes how f is bounded  which is crucial to deﬁne the metric. More formally  consider a compact
space X in Rd. Let F be a set of measurable  symmetric and bounded real valued functions on
X . Let P(X ) be the set of measurable probability distributions on X . Given two probability
distributions P  Q 2 P(X )  the IPM indexed by a symmetric function space F is deﬁned as follows
[10]:
(1)
It is easy to see that dF deﬁnes a pseudo-metric over P(X ). Note speciﬁcally that if F is not
bounded  supf will scale f to be arbitrarily large. By choosing F appropriately [11]  various
distances between probability measures can be deﬁned.
First formulation: Rayleigh Quotient. In order to deﬁne an IPM in the GAN context  [6  8] impose
the boundedness of the function space via a data independent constraint. This was achieved via
restricting the norms of the weights parametrizing the function space to a `p ball. Imposing such a
data independent constraint makes the training highly dependent on the constraint hyper-parameters
and restricts the capacity of the learned network  limiting the usability of the learned critic in a semi-
supervised learning task. Here we take a different angle and design the IPM to be scaling invariant
as a Rayleigh quotient. Instead of measuring the discrepancy between means as in Equation (1)  we
measure a standardized discrepancy  so that the distance is bounded by construction. Standardizing
this discrepancy introduces as we will see a data dependent constraint  that controls the growth of the
weights of the critic f and ensures the stability of the training while maintaining the capacity of the
critic. Given two distributions P  Q 2 P(X ) the Fisher IPM for a function space F is deﬁned as
follows:

f (x)  E
x⇠Q

f (x)o.

x⇠P

dF (P  Q) = sup
f2F

E
x⇠P

[f (x)]  E
x⇠Q

[f (x)]

p1/2Ex⇠Pf 2(x) + 1/2Ex⇠Qf 2(x)

1Code is available at https://github.com/tomsercu/FisherGAN

.

(2)

2

P

x

Q

Real

Fake

!

v

!(x) 2 Rm

Figure 1: Illustration of Fisher IPM with Neural Networks. ! is a convolutional neural network
which deﬁnes the embedding space. v is the direction in this embedding space with maximal mean
separation hv  µ!(P)  µ!(Q)i  constrained by the hyperellipsoid v> ⌃!(P; Q) v = 1.

While a standard IPM (Equation (1)) maximizes the discrepancy between the means of a function
under two different distributions  Fisher IPM looks for critic f that achieves a tradeoff between
maximizing the discrepancy between the means under the two distributions (between class variance) 
and reducing the pooled second order moment (an upper bound on the intra-class variance).
Standardized discrepancies have a long history in statistics and the so-called two-samples hypothesis
testing. For example the classic two samples Student’s t test deﬁnes the student statistics as the
ratio between means discrepancy and the sum of standard deviations. It is now well established that
learning generative models has its roots in the two-samples hypothesis testing problem [12]. Non
parametric two samples testing and model criticism from the kernel literature lead to the so called
maximum kernel mean discrepancy (MMD) [13]. The MMD cost function and the mean matching
IPM for a general function space has been recently used for training GAN [14  15  8].
Interestingly Harchaoui et al [16] proposed Kernel Fisher Discriminant Analysis for the two samples
hypothesis testing problem  and showed its statistical consistency. The Standard Fisher discrepancy
used in Linear Discriminant Analysis (LDA) or Kernel Fisher Discriminant Analysis (KFDA) can

be written: supf2F ✓ Ex⇠P

[f (x)] Ex⇠Q

[f (x)]◆2

Varx⇠P(f(x))+Varx⇠Q(f(x))   where Varx⇠P(f(x)) = Ex⇠Pf 2(x)  (Ex⇠P(f(x)))2.
Note that in LDA F is restricted to linear functions  in KFDA F is restricted to a Reproducing
Kernel Hilbert Space (RKHS). Our Fisher IPM (Eq (2)) deviates from the standard Fisher discrepancy
since the numerator is not squared  and we use in the denominator the second order moments instead
of the variances. Moreover in our deﬁnition of Fisher IPM  F can be any symmetric function class.
Second formulation: Constrained form. Since the distance is scaling invariant  dF can be written
equivalently in the following constrained form:

dF (P  Q) =

sup
2 Ex⇠Pf 2(x)+ 1

f2F   1

2 Ex⇠Qf 2(x)=1

E (f ) := E
x⇠P

[f (x)]  E
x⇠Q

[f (x)].

(3)

Specifying P  Q: Learning GAN with Fisher IPM. We turn now to the problem of learning GAN
with Fisher IPM. Given a distribution Pr 2 P(X )  we learn a function g✓ : Z ⇢ Rnz ! X   such
that for z ⇠ pz  the distribution of g✓(z) is close to the real data distribution Pr  where pz is a ﬁxed
distribution on Z (for instance z ⇠ N (0  Inz )). Let P✓ be the distribution of g✓(z)  z ⇠ pz. Using
Fisher IPM (Equation (3)) indexed by a parametric function class Fp  the generator minimizes the
IPM: ming✓ dFp(Pr  P✓). Given samples {xi  1 . . . N} from Pr and samples {zi  1 . . . M} from pz
we shall solve the following empirical problem:

min
g✓

sup
fp2Fp

ˆE (fp  g✓) :=

1
N

NXi=1

1
M

MXj=1

fp(g✓(zj)) Subject to ˆ⌦(fp  g✓) = 1 

(4)

where ˆ⌦(fp  g✓) = 1

i=1 f 2

p (xi) + 1

j=1 f 2

p (g✓(zj)). For simplicity we will have M = N.

2NPN

fp(xi) 

2MPM

3

2.2 Fisher IPM with Neural Networks
We will speciﬁcally study the case where F is a ﬁnite dimensional Hilbert space induced by a
neural network ! (see Figure 1 for an illustration). In this case  an IPM with data-independent
constraint will be equivalent to mean matching [8]. We will now show that Fisher IPM will give rise
to a whitened mean matching interpretation  or equivalently to mean matching with a Mahalanobis
distance.
Rayleigh Quotient. Consider the function space Fv !  deﬁned as follows

! is typically parametrized with a multi-layer neural network. We deﬁne the mean and covariance
(Gramian) feature embedding of a distribution as in McGan [8]:
and ⌃!(P) = E

Fv ! = {f (x) = hv  !(x)i| v 2 Rm  ! : X ! Rm} 
x⇠P!(x)!(x)>  

µ!(P) = E
x⇠P

(!(x))

Fisher IPM as deﬁned in Equation (2) on Fv ! can be written as follows:
hv  µ!(P)  µ!(Q)i
2 ⌃!(P) + 1

dFv ! (P  Q) = max
!

max

v

2 ⌃!(Q) + Im)v

 

(5)

where we added a regularization term (> 0) to avoid singularity of the covariances. Note that if !
was implemented with homogeneous non linearities such as RELU  if we swap (v  !) with (cv  c0!)
for any constants c  c0 > 0  the distance dFv ! remains unchanged  hence the scaling invariance.
Constrained Form. Since the Rayleigh Quotient is not amenable to optimization  we will consider
Fisher IPM as a constrained optimization problem. By virtue of the scaling invariance and the
constrained form of the Fisher IPM given in Equation (3)  dFv ! can be written equivalently as:

qv>( 1

dFv ! (P  Q) =

! v v>( 1

2 ⌃!(P)+ 1

2 ⌃!(Q)+Im)v=1hv  µ!(P)  µ!(Q)i
max
2 ⌃!(P) + 1

2 ⌃!(Q) + Im. Doing a simple change of

(6)

Deﬁne the pooled covariance: ⌃!(P; Q) = 1
variable u = (⌃ !(P; Q)) 1

2 v we see that:

dFu ! (P  Q) = max
!

2 (µ!(P)  µ!(Q))E

max

u kuk=1Du  (⌃!(P; Q)) 1
! (⌃!(P; Q)) 1
! q(µ!(P)  µ!(Q))>⌃1

(7)
hence we see that ﬁsher IPM corresponds to the worst case distance between whitened means.
Since the means are white  we don’t need to impose further constraints on ! as in [6  8]. Another
interpretation of the Fisher IPM stems from the fact that:

2 (µ!(P)  µ!(Q))  

= max

dFv ! (P  Q) = max

! (P; Q)(µ!(P)  µ!(Q)) 

from which we see that Fisher IPM is a Mahalanobis distance between the mean feature embeddings
of the distributions. The Mahalanobis distance is deﬁned by the positive deﬁnite matrix ⌃w(P; Q).
We show in Appendix A that the gradient penalty in Improved Wasserstein [7] gives rise to a similar
Mahalanobis mean matching interpretation.
Learning GAN with Fisher IPM. Hence we see that learning GAN with Fisher IPM:

min
g✓

max

!

v v>( 1

2 ⌃!(Pr)+ 1

2 ⌃!(P✓)+Im)v=1hv  µw(Pr)  µ!(P✓)i
max

corresponds to a min-max game between a feature space and a generator. The feature space tries
to maximize the Mahalanobis distance between the feature means embeddings of real and fake
distributions. The generator tries to minimize the mean embedding distance.

3 Theory
We will start ﬁrst by studying the Fisher IPM deﬁned in Equation (2) when the function space has full
dx < 1.
capacity i.e when the critic belongs to L2(X   1
Theorem 1 shows that under this condition  the Fisher IPM corresponds to the Chi-squared distance
between distributions  and gives a closed form expression of the optimal critic function f (See
Appendix B for its relation with the Pearson Divergence). Proofs are given in Appendix D.

2 (P + Q)) meaning thatRX

f 2(x) (P(x)+Q(x))

2

4

Figure 2: Example on 2D synthetic data  where both P and Q are ﬁxed normal distributions with the
same covariance and shifted means along the x-axis  see (a). Fig (b  c) show the exact 2 distance
from numerically integrating Eq (8)  together with the estimate obtained from training a 5-layer MLP
with layer size = 16 and LeakyReLU nonlinearity on different training sample sizes. The MLP is
trained using Algorithm 1  where sampling from the generator is replaced by sampling from Q  and
the 2 MLP estimate is computed with Equation (2) on a large number of samples (i.e. out of sample
estimate). We see in (b) that for large enough sample size  the MLP estimate is extremely good. In (c)
we see that for smaller sample sizes  the MLP approximation bounds the ground truth 2 from below
(see Theorem 2) and converges to the ground truth roughly as O( 1pN
) (Theorem 3). We notice that
when the distributions have small 2 distance  a larger training size is needed to get a better estimate -
again this is in line with Theorem 3.

Theorem 1 (Chi-squared distance at full capacity). Consider the Fisher IPM for F being the space
of all measurable functions endowed by 1
2 ). Deﬁne the Chi-squared
distance between two distributions:

2 (P + Q)  i.e. F := L2(X   P+Q

2(P  Q) =sZX

(P(x)  Q(x))2

P(x)+Q(x)

2

dx

(8)

The following holds true for any P  Q  P 6= Q:
1) The Fisher IPM for F = L2(X   P+Q
dF (P  Q) = 2(P  Q).
2) The optimal critic of the Fisher IPM on L2(X   P+Q

2 ) is equal to the Chi-squared distance deﬁned above:

2 ) is :
P(x)  Q(x)
P(x)+Q(x)

.

f(x) =

1

2(P  Q)

2

We note here that LSGAN [5] at full capacity corresponds to a Chi-Squared divergence  with the
main difference that LSGAN has different objectives for the generator and the discriminator (bilevel
optimizaton)  and hence does not optimize a single objective that is a distance between distributions.
The Chi-squared divergence can also be achieved in the f-gan framework from [3]. We discuss the
advantages of the Fisher formulation in Appendix C.
Optimizing over L2(X   P+Q
2 ) is not tractable  hence we have to restrict our function class  to a
hypothesis class H   that enables tractable computations. Here are some typical choices of the space
H : Linear functions in the input features  RKHS  a non linear multilayer neural network with a
linear last layer (Fv !). In this Section we don’t make any assumptions about the function space and
show in Theorem 2 how the Chi-squared distance is approximated in H   and how this depends on
the approximation error of the optimal critic f in H .
Theorem 2 (Approximating Chi-squared distance in an arbitrary function space H ). Let H
be an arbitrary symmetric function space. We deﬁne the inner product hf  fiL2(X   P+Q
2 ) =
RX
2 ) be the unit sphere
in L2(X   P+Q
2 ) = 1}. The ﬁsher IPM deﬁned on an
arbitrary function space H dH (P  Q)  approximates the Chi-squared distance. The approximation

dx  which induces the Lebesgue norm. Let SL2(X   P+Q
2 ) = {f : X ! R kfkL2(X   P+Q

f (x)f(x) P(x)+Q(x)

2 ): SL2(X   P+Q

2

5

202443210123(a)2DGaussians contourplot01234Meanshift0.00.51.01.52.02distanceandMLPestimate(b)ExactMLP N=M=10k101102103N=M=numtrainingsamples0.00.51.01.52.02distanceandMLPestimate(c)MLP shift=3MLP shift=1MLP shift=0.5quality depends on the cosine of the approximation of the optimal critic f in H . Since H is
symmetric this cosine is always positive (otherwise the same equality holds with an absolute value)

dH (P  Q) = 2(P  Q)

sup

f2H \ SL2(X   P+Q
Equivalently we have following relative approximation error:

2

)

hf  fiL2(X   P+Q
2 )  

2(P  Q)  dH (P  Q)

2(P  Q)

=

1
2

inf

f2H \ SL2(X   P+Q

2

) kf  fk2

L2(X   P+Q

2 ) .

From Theorem 2  we know that we have always dH (P  Q)  2(P  Q). Moreover if the space
H was rich enough to provide a good approximation of the optimal critic f  then dH is a good
approximation of the Chi-squared distance 2.
Generalization bounds for the sample quality of the estimated Fisher IPM from samples from P and
Q can be done akin to [11]  with the main difﬁculty that for Fisher IPM we have to bound the excess
risk of a cost function with data dependent constraints on the function class. We give generalization
bounds for learning the Fisher IPM in the supplementary material (Theorem 3  Appendix E). In a
nutshell the generalization error of the critic learned in a hypothesis class H from samples of P and
Q  decomposes to the approximation error from Theorem 2 and a statistical error that is bounded

using data dependent local Rademacher complexities [17] and scales like O(p1/n)  n = M N/M +N.

We illustrate in Figure 2 our main theoretical claims on a toy problem.

4 Fisher GAN Algorithm using ALM

j=1 f 2

i=1 f 2

p (xi) + 1

2NPN

For any choice of the parametric function class Fp (for example Fv !)  note the constraint in Equation
(4) by ˆ⌦(fp  g✓) = 1
p (g✓(zj)). Deﬁne the Augmented Lagrangian
[18] corresponding to Fisher GAN objective and constraint given in Equation (4):
( ˆ⌦(fp  g✓)  1)2

2NPN
LF (p  ✓  ) = ˆE (fp  g✓) + (1  ˆ⌦(fp  g✓)) 

(9)
where  is the Lagrange multiplier and ⇢> 0 is the quadratic penalty weight. We alternate between
optimizing the critic and the generator. Similarly to [7] we impose the constraint when training the
critic only. Given ✓  for training the critic we solve maxp min LF (p  ✓  ). Then given the critic
parameters p we optimize the generator weights ✓ to minimize the objective min✓ ˆE (fp  g✓). We
give in Algorithm 1  an algorithm for Fisher GAN  note that we use ADAM [19] for optimizing the
parameters of the critic and the generator. We use SGD for the Lagrange multiplier with learning rate
⇢ following practices in Augmented Lagrangian [18].
Algorithm 1 Fisher GAN

⇢
2

Input: ⇢ penalty weight  ⌘ Learning rate  nc number of iterations for training the critic  N batch
size
Initialize p  ✓   = 0
repeat

for j = 1 to nc do

Sample a minibatch xi  i = 1 . . . N  xi ⇠ Pr
Sample a minibatch zi  i = 1 . . . N  zi ⇠ pz
(gp  g) (rpLF  rLF )(p  ✓  )
p p + ⌘ ADAM (p  gp)
   ⇢g {SGD rule on  with learning rate ⇢}

end for
Sample zi  i = 1 . . . N  zi ⇠ pz
NPN
d✓ r✓ ˆE (fp  g✓) = r✓
✓ ✓  ⌘ ADAM (✓  d✓)
until ✓ converges

1

i=1 fp(g✓(zi))

6

Figure 3: Samples and plots of the loss ˆE (.)  lagrange multiplier   and constraint ˆ⌦(.) on 3
benchmark datasets. We see that during training as  grows slowly  the constraint becomes tight.

Figure 4: No Batch Norm: Training results from a critic f without batch normalization. Fisher GAN
(left) produces decent samples  while WGAN with weight clipping (right) does not. We hypothesize
that this is due to the implicit whitening that Fisher GAN provides. (Note that WGAN-GP does also
succesfully converge without BN [7]). For both models the learning rate was appropriately reduced.
5 Experiments

We experimentally validate the proposed Fisher GAN. We claim three main results: (1) stable training
with a meaningful and stable loss going down as training progresses and correlating with sample
quality  similar to [6  7]. (2) very fast convergence to good sample quality as measured by inception
score. (3) competitive semi-supervised learning performance  on par with literature baselines  without
requiring normalization of the critic.
We report results on three benchmark datasets: CIFAR-10 [20]  LSUN [21] and CelebA [22]. We
parametrize the generator g✓ and critic f with convolutional neural networks following the model
design from DCGAN [23]. For 64 ⇥ 64 images (LSUN  CelebA) we use the model architecture in
Appendix F.2  for CIFAR-10 we train at a 32⇥ 32 resolution using architecture in F.3 for experiments
regarding sample quality (inception score)  while for semi-supervised learning we use a better
regularized discriminator similar to the Openai [9] and ALI [24] architectures  as given in F.4.We
used Adam [19] as optimizer for all our experiments  hyper-parameters given in Appendix F.
Qualitative: Loss stability and sample quality. Figure 3 shows samples and plots during training.
For LSUN we use a higher number of D updates (nc = 5)   since we see similarly to WGAN that
the loss shows large ﬂuctuations with lower nc values. For CIFAR-10 and CelebA we use reduced
nc = 2 with no negative impact on loss stability. CIFAR-10 here was trained without any label
information. We show both train and validation loss on LSUN and CIFAR-10 showing  as can be
expected  no overﬁtting on the large LSUN dataset and some overﬁtting on the small CIFAR-10
dataset. To back up our claim that Fisher GAN provides stable training  we trained both a Fisher Gan
and WGAN where the batch normalization in the critic f was removed (Figure 4).
Quantitative analysis: Inception Score and Speed. It is agreed upon that evaluating generative
models is hard [25]. We follow the literature in using “inception score” [9] as a metric for the quality

7

024MeandierenceˆE(a)LSUNˆEtrainˆEval0.00.51.01.5g✓iterations⇥10501234ˆ⌦024MeandierenceˆE(b)CelebAˆEtrain01234g✓iterations⇥10501234ˆ⌦024MeandierenceˆE(c)CIFAR-10ˆEtrainˆEval0.00.51.01.5g✓iterations⇥10501234ˆ⌦Figure 5: CIFAR-10 inception scores under 3 training conditions. Corresponding samples are given
in rows from top to bottom (a b c). The inception score plots are mirroring Figure 3 from [7].
Note All inception scores are computed from the same tensorﬂow codebase  using the architecture
described in appendix F.3  and with weight initialization from a normal distribution with stdev=0.02.
In Appendix F.1 we show that these choices are also beneﬁting our WGAN-GP baseline.

of CIFAR-10 samples. Figure 5 shows the inception score as a function of number of g✓ updates
and wallclock time. All timings are obtained by running on a single K40 GPU on the same cluster.
We see from Figure 5  that Fisher GAN both produces better inception scores  and has a clear speed
advantage over WGAN-GP.
Quantitative analysis: SSL. One of the main premises of unsupervised learning  is to learn features
on a large corpus of unlabeled data in an unsupervised fashion  which are then transferable to other
tasks. This provides a proper framework to measure the performance of our algorithm. This leads
us to quantify the performance of Fisher GAN by semi-supervised learning (SSL) experiments on
CIFAR-10. We do joint supervised and unsupervised training on CIFAR-10  by adding a cross-entropy
term to the IPM objective  in conditional and unconditional generation.

Table 2: CIFAR-10 inception scores using resnet architecture and codebase from [7]. We used
Layer Normalization [26] which outperformed unnormalized resnets. Apart from this  no additional
hyperparameter tuning was done to get stable training of the resnets.

Method
ALI [24]
BEGAN [27]
DCGAN [23] (in [28])
Improved GAN (-L+HA) [9]
EGAN-Ent-VI [29]
DFM [30]
WGAN-GP ResNet [7]
Fisher GAN ResNet (ours)

Unsupervised

Score
5.34 ± .05
5.62
6.16 ± .07
6.86 ± .06
7.07 ± .10
7.72 ± .13
7.86 ± .07
7.90 ± .05

Method
SteinGan [31]
DCGAN (with labels  in [31])
Improved GAN [9]
Fisher GAN ResNet (ours)
AC-GAN [32]
SGAN-no-joint [28]
WGAN-GP ResNet [7]
SGAN [28]

Supervised

Score
6.35
6.58
8.09 ± .07
8.16 ± .12
8.25 ± .07
8.37 ± .08
8.42 ± .10
8.59 ± .12

Unconditional Generation with CE Regularization. We parametrize the critic f as in Fv !.
While training the critic using the Fisher GAN objective LF given in Equation (9)  we train a linear
classiﬁer on the feature space ! of the critic  whenever labels are available (K labels). The linear
classiﬁer is trained with Cross-Entropy (CE) minimization. Then the critic loss becomes LD =
LF  DP(x y)2lab CE(x  y; S  !)  where CE(x  y; S  !) =  log [Softmax(hS  !(x)i)y] 
where S 2 RK⇥m is the linear classiﬁer and hS  !i 2 RK with slight abuse of notation. D is the
regularization hyper-parameter. We now sample three minibatches for each critic update: one labeled
batch from the small labeled dataset for the CE term  and an unlabeled batch + generated batch for
the IPM.
Conditional Generation with CE Regularization. We also trained conditional generator models 
conditioning the generator on y by concatenating the input noise with a 1-of-K embedding of the
label: we now have g✓(z  y). We parametrize the critic in Fv ! and modify the critic objective
as above. We also add a cross-entropy term for the generator to minimize during its training step:

LG = ˆE +GPz⇠p(z) y⇠p(y) CE(g✓(z  y)  y; S  !). For generator updates we still need to sample

only a single minibatch since we use the minibatch of samples from g✓(z  y) to compute both the

8

0.000.250.500.751.001.251.501.752.00g✓iterations⇥105012345678Inceptionscore(a)FisherGAN:CE Conditional(b)FisherGAN:CE GNotCond.(c)FisherGAN:NoLabWGAN-GPWGANDCGAN0.00.51.01.52.02.53.03.54.0Wallclocktime(seconds)⇥104IPM loss ˆE and CE. The labels are sampled according to the prior y ⇠ p(y)  which defaults to the
discrete uniform prior when there is no class imbalance. We found D = G = 0.1 to be optimal.
New Parametrization of the Critic: “K + 1 SSL”. One speciﬁc successful formulation of SSL in
the standard GAN framework was provided in [9]  where the discriminator classiﬁes samples into
K + 1 categories: the K correct clases  and K + 1 for fake samples. Intuitively this puts the real
classes in competition with the fake class. In order to implement this idea in the Fisher framework 
we deﬁne a new function class of the critic that puts in competition the K class directions of the
classiﬁer Sy  and another “K+1” direction v that indicates fake samples. Hence we propose the
following parametrization for the critic: f (x) = PK
y=1 p(y|x)hSy  !(x)i  hv  !(x)i  where
p(y|x) = Softmax(hS  !(x)i)y which is also optimized with Cross-Entropy. Note that this critic
does not fall under the interpretation with whitened means from Section 2.2  but does fall under
the general Fisher IPM framework from Section 2.1. We can use this critic with both conditional
and unconditional generation in the same way as described above. In this setting we found D =
1.5  G = 0.1 to be optimal.
Layerwise normalization on the critic. For most GAN formulations following DCGAN design
principles  batch normalization (BN) [33] in the critic is an essential ingredient. From our semi-
supervised learning experiments however  it appears that batch normalization gives substantially
worse performance than layer normalization (LN) [26] or even no layerwise normalization. We
attribute this to the implicit whitening Fisher GAN provides.
Table 3 shows the SSL results on CIFAR-10. We show that Fisher GAN has competitive results  on
par with state of the art literature baselines. When comparing to WGAN with weight clipping  it
becomes clear that we recover the lost SSL performance. Results with the K + 1 critic are better
across the board  proving consistently the advantage of our proposed K + 1 formulation. Conditional
generation does not provide gains in the setting with layer normalization or without normalization.

Table 3: CIFAR-10 SSL results.

Number of labeled examples
Model
CatGAN [34]
Improved GAN (FM) [9]
ALI [24]
WGAN (weight clipping) Uncond
WGAN (weight clipping) Cond
Fisher GAN BN Cond
Fisher GAN BN Uncond
Fisher GAN BN K+1 Cond
Fisher GAN BN K+1 Uncond
Fisher GAN LN Cond
Fisher GAN LN Uncond
Fisher GAN LN K+1 Cond
Fisher GAN LN K+1  Uncond
Fisher GAN No Norm K+1  Uncond

1000

21.83 ± 2.01
19.98 ± 0.89
69.01
68.11

36.37
36.42
34.94
33.49
26.78 ± 1.04
24.39 ± 1.22
20.99 ± 0.66
19.74 ± 0.21
21.15 ± 0.54

6 Conclusion

2000

4000

Misclassiﬁcation rate

19.61 ± 2.09
19.09 ± 0.44
56.48
58.59

32.03
33.49
28.04
28.60
23.30 ± 0.39
22.69 ± 1.27
19.01 ± 0.21
17.87 ± 0.38
18.21 ± 0.30

19.58
18.63 ± 2.32
17.99 ± 1.62
40.85
42.00

27.42
27.36
23.85
24.19
20.56 ± 0.64
19.53 ± 0.34
17.41 ± 0.38
16.13 ± 0.53
16.74 ± 0.19

8000

17.72 ± 1.82
17.05 ± 1.49
30.56
30.91

22.85
22.82
20.75
21.59
18.26 ± 0.25
17.84 ± 0.15
15.50 ± 0.41
14.81 ± 0.16
14.80 ± 0.15

We have deﬁned Fisher GAN  which provide a stable and fast way of training GANs. The Fisher
GAN is based on a scale invariant IPM  by constraining the second order moments of the critic. We
provide an interpretation as whitened (Mahalanobis) mean feature matching and 2 distance. We
show graceful theoretical and empirical advantages of our proposed Fisher GAN.

Acknowledgments. The authors thank Steven J. Rennie for many helpful discussions and Martin
Arjovsky for helpful clariﬁcations and pointers.

9

References
[1] Ian Goodfellow  Jean Pouget-Abadie  Mehdi Mirza  Bing Xu  David Warde-Farley  Sherjil

Ozair  Aaron Courville  and Yoshua Bengio. Generative adversarial nets. In NIPS  2014.

[2] Martin Arjovsky and Léon Bottou. Towards principled methods for training generative adver-

sarial networks. In ICLR  2017.

[3] Sebastian Nowozin  Botond Cseke  and Ryota Tomioka. f-gan: Training generative neural

samplers using variational divergence minimization. In NIPS  2016.

[4] Casper Kaae Sønderby  Jose Caballero  Lucas Theis  Wenzhe Shi  and Ferenc Huszár. Amortised

map inference for image super-resolution. ICLR  2017.

[5] Xudong Mao  Qing Li  Haoran Xie  Raymond YK Lau  and Zhen Wang. Least squares

generative adversarial networks. arXiv:1611.04076  2016.

[6] Martin Arjovsky  Soumith Chintala  and Léon Bottou. Wasserstein gan. ICML  2017.
[7] Ishaan Gulrajani  Faruk Ahmed  Martin Arjovsky  Vincent Dumoulin  and Aaron Courville.

Improved training of wasserstein gans. arXiv:1704.00028  2017.

[8] Youssef Mroueh  Tom Sercu  and Vaibhava Goel. Mcgan: Mean and covariance feature

matching gan. arXiv:1702.08398 ICML  2017.

[9] Tim Salimans  Ian Goodfellow  Wojciech Zaremba  Vicki Cheung  Alec Radford  and Xi Chen.

Improved techniques for training gans. NIPS  2016.

[10] Alfred Müller. Integral probability metrics and their generating classes of functions. Advances

in Applied Probability  1997.

[11] Bharath K. Sriperumbudur  Kenji Fukumizu  Arthur Gretton  Bernhard Schölkopf  and Gert
R. G. Lanckriet. On the empirical estimation of integral probability metrics. Electronic Journal
of Statistics  2012.

[12] Shakir Mohamed and Balaji Lakshminarayanan. Learning in implicit generative models.

arXiv:1610.03483  2016.

[13] Arthur Gretton  Karsten M Borgwardt  Malte J Rasch  Bernhard Schölkopf  and Alexander

Smola. A kernel two-sample test. JMLR  2012.

[14] Yujia Li  Kevin Swersky  and Richard Zemel. Generative moment matching networks. In ICML 

2015.

[15] Gintare Karolina Dziugaite  Daniel M Roy  and Zoubin Ghahramani. Training generative neural

networks via maximum mean discrepancy optimization. UAI  2015.

[16] Zaïd Harchaoui  Francis R Bach  and Eric Moulines. Testing for homogeneity with kernel ﬁsher

discriminant analysis. In NIPS  2008.

[17] Peter L. Bartlett  Olivier Bousquet  and Shahar Mendelson. Local rademacher complexities.

Ann. Statist.  2005.

[18] J. Nocedal and S. J. Wright. Numerical Optimization. Springer  2nd edition  2006.
[19] Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR  2015.
[20] A. Krizhevsky and G. Hinton. Learning multiple layers of features from tiny images. Master’s

thesis  2009.

[21] Fisher Yu  Ari Seff  Yinda Zhang  Shuran Song  Thomas Funkhouser  and Jianxiong Xiao.
Lsun: Construction of a large-scale image dataset using deep learning with humans in the loop.
arXiv:1506.03365  2015.

[22] Ziwei Liu  Ping Luo  Xiaogang Wang  and Xiaoou Tang. Deep learning face attributes in the

wild. In ICCV  2015.

10

[23] Alec Radford  Luke Metz  and Soumith Chintala. Unsupervised representation learning with

deep convolutional generative adversarial networks. arXiv:1511.06434  2015.

[24] Vincent Dumoulin  Ishmael Belghazi  Ben Poole  Alex Lamb  Martin Arjovsky  Olivier Mas-

tropietro  and Aaron Courville. Adversarially learned inference. ICLR  2017.

[25] Lucas Theis  Aäron van den Oord  and Matthias Bethge. A note on the evaluation of generative

models. ICLR  2016.

[26] Jimmy Lei Ba  Jamie Ryan Kiros  and Geoffrey E Hinton. Layer normalization. arXiv preprint

arXiv:1607.06450  2016.

[27] David Berthelot  Tom Schumm  and Luke Metz. Began: Boundary equilibrium generative

adversarial networks. arXiv preprint arXiv:1703.10717  2017.

[28] Xun Huang  Yixuan Li  Omid Poursaeed  John Hopcroft  and Serge Belongie. Stacked generative

adversarial networks. arXiv preprint arXiv:1612.04357  2016.

[29] Zihang Dai  Amjad Almahairi  Philip Bachman  Eduard Hovy  and Aaron Courville. Calibrating

energy-based generative adversarial networks. arXiv preprint arXiv:1702.01691  2017.

[30] D Warde-Farley and Y Bengio. Improving generative adversarial networks with denoising

feature matching. ICLR submissions  8  2017.

[31] Dilin Wang and Qiang Liu. Learning to draw samples: With application to amortized mle for

generative adversarial learning. arXiv preprint arXiv:1611.01722  2016.

[32] Augustus Odena  Christopher Olah  and Jonathon Shlens. Conditional image synthesis with

auxiliary classiﬁer gans. arXiv preprint arXiv:1610.09585  2016.

[33] Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training

by reducing internal covariate shift. Proc. ICML  2015.

[34] Jost Tobias Springenberg. Unsupervised and semi-supervised learning with categorical genera-

tive adversarial networks. arXiv:1511.06390  2015.

[35] Alessandra Tosi  Søren Hauberg  Alfredo Vellido  and Neil D. Lawrence. Metrics for proba-

bilistic geometries. 2014.

[36] Bharath K. Sriperumbudur  Kenji Fukumizu  Arthur Gretton  Bernhard Scholkopf  and Gert
R. G. Lanckriet. On integral probability metrics  -divergences and binary classiﬁcation. 2009.
[37] I. Ekeland and T. Turnbull. Inﬁnite-dimensional Optimization and Convexity. The University of

Chicago Press  1983.

[38] Xavier Glorot and Yoshua Bengio. Understanding the difﬁculty of training deep feedforward
neural networks. In International conference on artiﬁcial intelligence and statistics  pages
249–256  2010.

[39] Kaiming He  Xiangyu Zhang  Shaoqing Ren  and Jian Sun. Delving deep into rectiﬁers: Sur-
passing human-level performance on imagenet classiﬁcation. arXiv preprint arXiv:1502.01852 
2015.

11

,Youssef Mroueh
Tom Sercu