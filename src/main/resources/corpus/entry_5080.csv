2018,Solving Non-smooth Constrained Programs with Lower Complexity than $\mathcal{O}(1/\varepsilon)$: A Primal-Dual Homotopy Smoothing Approach,We propose a new primal-dual homotopy smoothing algorithm for a linearly constrained convex program  where neither the primal nor the dual function has to be smooth or strongly convex. The best known iteration complexity solving such a non-smooth problem is $\mathcal{O}(\varepsilon^{-1})$. In this paper  
we show that by leveraging a local error bound condition on the dual function  the proposed algorithm can achieve a better primal convergence time of  $\mathcal{O}\l(\varepsilon^{-2/(2+\beta)}\log_2(\varepsilon^{-1})\r)$  where $\beta\in(0 1]$ is a local error bound parameter. 
As an example application  we show that the distributed geometric median problem  which can be formulated as a constrained convex program  has its dual function non-smooth but satisfying the aforementioned local error bound condition with $\beta=1/2$  therefore enjoying a convergence time of $\mathcal{O}\l(\varepsilon^{-4/5}\log_2(\varepsilon^{-1})\r)$. This result improves upon the $\mathcal{O}(\varepsilon^{-1})$ convergence time bound achieved by existing distributed optimization algorithms. Simulation experiments also demonstrate the performance of our proposed algorithm.,Solving Non-smooth Constrained Programs with
Lower Complexity than O(1/"): A Primal-Dual

Homotopy Smoothing Approach

Xiaohan Wei

Department of Electrical Engineering

University of Southern California
Los Angeles  CA  USA  90089

xiaohanw@usc.edu

Hao Yu

Alibaba Group (U.S.) Inc.
Bellevue  WA  USA  98004
hao.yu@alibaba-inc.com

Qing Ling

School of Data and Computer Science

Sun Yat-Sen University

Guangzhou  China  510006

lingqing556@mail.sysu.edu.cn

Michael J. Neely

Department of Electrical Engineering

University of Southern California
Los Angeles  CA  USA  90089

mikejneely@gmail.com

Abstract

We propose a new primal-dual homotopy smoothing algorithm for a linearly
constrained convex program  where neither the primal nor the dual function has
to be smooth or strongly convex. The best known iteration complexity solving
such a non-smooth problem is O("1). In this paper  we show that by leveraging
a local error bound condition on the dual function  the proposed algorithm can
achieve a better primal convergence time of O"2/(2+) log2("1)  where  2

(0  1] is a local error bound parameter. As an example application of the general
algorithm  we show that the distributed geometric median problem  which can be
formulated as a constrained convex program  has its dual function non-smooth but
satisfying the aforementioned local error bound condition with  = 1/2  therefore

enjoying a convergence time of O"4/5 log2("1). This result improves upon
the O("1) convergence time bound achieved by existing distributed optimization
algorithms. Simulation experiments also demonstrate the performance of our
proposed algorithm.

1

Introduction

We consider the following linearly constrained convex optimization problem:

min f (x)
s.t. Ax  b = 0  x 2X  

(1)
(2)

where X✓ Rd is a compact convex set  f : Rd ! R is a convex function  A 2 RN⇥d  b 2 RN.
Such an optimization problem has been studied in numerous works under various application scenarios
such as machine learning (Yurtsever et al. (2015))  signal processing (Ling and Tian (2010)) and
communication networks (Yu and Neely (2017a)). The goal of this work is to design new algorithms
for (1-2) achieving an " approximation with better convergence time than O(1/").

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

1.1 Optimization algorithms related to constrained convex program
Since enforcing the constraint Ax  b = 0 generally requires a signiﬁcant amount of computation in
large scale systems  the majority of the scalable algorithms solving problem (1-2) are of primal-dual
type. Generally  the efﬁciency of these algorithms depends on two key properties of the dual function
of (1-2)  namely  the Lipschitz gradient and strong convexity. When the dual function of (1-2) is
smooth  primal-dual type algorithms with Nesterov’s acceleration on the dual of (1)-(2) can achieve a
convergence time of O(1/p") (e.g. Yurtsever et al. (2015); Tran-Dinh et al. (2018))1. When the dual
function has both the Lipschitz continuous gradient and the strongly convex property  algorithms
such as dual subgradient and ADMM enjoy a linear convergence O(log(1/")) (e.g. Yu and Neely
(2018); Deng and Yin (2016)). However  when neither of the properties is assumed  the basic dual-
subgradient type algorithm gives a relatively worse O(1/"2) convergence time (e.g. Wei et al. (2015);
Wei and Neely (2018))  while its improved variants yield a convergence time of O(1/") (e.g. Lan
and Monteiro (2013); Deng et al. (2017); Yu and Neely (2017b); Yurtsever et al. (2018); Gidel et al.
(2018)).
More recently  several works seek to achieve a better convergence time than O(1/") under weaker
assumptions than Lipschitz gradient and strong convexity of the dual function. Speciﬁcally  building
upon the recent progress on the gradient type methods for optimization with H¨older continuous
gradient (e.g. Nesterov (2015a b))  the work Yurtsever et al. (2015) develops a primal-dual gradient
method solving (1-2)  which achieves a convergence time of O(1/"
1+3⌫ )  where ⌫ is the modulus of
H¨older continuity on the gradient of the dual function of the formulation (1-2).2 On the other hand 
the work Yu and Neely (2018) shows that when the dual function has Lipschitz continuous gradient
and satisﬁes a locally quadratic property (i.e. a local error bound with  = 1/2  see Deﬁnition 2.1 for
details)  which is weaker than strong convexity  one can still obtain a linear convergence with a dual
subgradient algorithm. A similar result has also been proved for ADMM in Han et al. (2015).
In the current work  we aim to address the following question: Can one design a scalable algorithm
with lower complexity than O(1/") solving (1-2)  when both the primal and the dual functions are
possibly non-smooth? More speciﬁcally  we look at a class of problems with dual functions satisfying
only a local error bound  and show that indeed one is able to obtain a faster primal convergence via a
primal-dual homotopy smoothing method under a local error bound condition on the dual function.
Homotopy methods were ﬁrst developed in the statistics literature in relation to the model selection
problem for LASSO  where  instead of computing a single solution for LASSO  one computes a
complete solution path by varying the regularization parameter from large to small (e.g. Osborne
et al. (2000); Xiao and Zhang (2013)).3 On the other hand  the smoothing technique for minimizing a
non-smooth convex function of the following form was ﬁrst considered in Nesterov (2005):

1+⌫

(3)
where ⌦1 ✓ Rd is a closed convex set  h(x) is a convex smooth function  and g(x) can be explicitly
written as
(4)

 (x) = g(x) + h(x)  x 2 ⌦1

g(x) = max

u2⌦2 hAx  ui  (u) 

where for any two vectors a  b 2 Rd  ha  bi = aT b  ⌦1 ✓ Rd is a closed convex set  and (u) is a
convex function. By adding a strongly concave proximal function of u with a smoothing parameter
µ > 0 into the deﬁnition of g(x)  one can obtain a smoothed approximation of (x) with smooth
modulus µ. Then  Nesterov (2005) employs the accelerated gradient method on the smoothed
approximation (which delivers a O(1/p") convergence time for the approximation)  and sets the
parameter to be µ = O(")  which gives an overall convergence time of O(1/"). An important
follow-up question is that whether or not such a smoothing technique can also be applied to solve

1Our convergence time to achieve within " of optimality is in terms of number of (unconstrained) maximiza-
2kx  ˜xk2] where constants   A  ˜x  µ are known. This is a
tion steps arg maxx2X [T (Ax  b)  f (x)  µ
standard measure of convergence time for Lagrangian-type algorithms that turn a constrained problem into a
sequence of unconstrained problems.
2The gradient of function g(·) is H¨older continuous with modulus ⌫ 2 (0  1] on a set X if krg(x) 
rg(y)k  L⌫kx  yk⌫  8x  y 2X   where k·k is the vector 2-norm and L⌫ is a constant depending on ⌫.
3 The word “homotopy”  which was adopted in Osborne et al. (2000)  refers to the fact that the mapping
from regularization parameters to the set of solutions of the LASSO problem is a continuous piece-wise linear
function.

2

(1-2) with the same primal convergence time. This question is answered in subsequent works Necoara
and Suykens (2008); Li et al. (2016); Tran-Dinh et al. (2018)  where they show that indeed one can
also obtain an O(1/") primal convergence time for the problem (1-2) via smoothing.
Combining the homotopy method with a smoothing technique to solve problems of the form (3) has
been considered by a series of works including Yang and Lin (2015)  Xu et al. (2016) and Xu et al.
(2017). Speciﬁcally  the works Yang and Lin (2015) and Xu et al. (2016) consider a multi-stage
algorithm which starts from a large smoothing parameter µ and then decreases this parameter over
time. They show that when the function (x) satisﬁes a local error bound with parameter  2 (0  1] 
such a combination gives an improved convergence time of O(log(1/")/"1) minimizing the
unconstrained problem (3). The work Xu et al. (2017) shows that the homotopy method can also be
combined with ADMM to achieve a faster convergence solving problems of the form

min
x2⌦1

f (x) + (Ax  b) 

where ⌦1 is a closed convex set  f  are both convex functions with f (x) + (Ax  b) satisfying
the local error bound  and the proximal operator of (·) can be easily computed. However  due to
the restrictions on the function in the paper  it cannot be extended to handle problems of the form
(1-2).4
Contributions: In the current work  we show a multi-stage homotopy smoothing method enjoys a

primal convergence time O"2/(2+) log2("1) solving (1-2) when the dual function satisﬁes a
local error bound condition with  2 (0  1]. Our convergence time to achieve within " of optimality
is in terms of number of (unconstrained) maximization steps arg maxx2X [T (Ax  b)  f (x) 
µ
2||x ex||2]  where constants   A ex  µ are known  which is a standard measure of convergence
time for Lagrangian-type algorithms that turn a constrained problem into a sequence of unconstrained
problems. The algorithm essentially restarts a weighted primal averaging process at each stage
using the last Lagrange multiplier computed. This result improves upon the earlier O(1/") result by
(Necoara and Suykens (2008); Li et al. (2016)) and at the same time extends the scope of homotopy
smoothing method to solve a new class of problems involving constraints (1-2). It is worth mentioning
that a similar restarted smoothing strategy is proposed in a recent work Tran-Dinh et al. (2018) to
solve problems including (1-2)  where they show that  empirically  restarting the algorithm from the
Lagrange multiplier computed from the last stage improves the convergence time. Here  we give one
theoretical justiﬁcation of such an improvement.

1.2 The distributed geometric median problem

The geometric median problem  also known as the Fermat-Weber problem  has a long history (e.g.
see Weiszfeld and Plastria (2009) for more details). Given a set of n points b1  b2 
···   bn 2 Rd 
we aim to ﬁnd one point x⇤ 2 Rd so as to minimize the sum of the Euclidean distance  i.e.

x⇤ 2 argmin
x2Rd

nXi=1

kx  bik 

(5)

which is a non-smooth convex optimization problem. It can be shown that the solution to this
problem is unique as long as b1  b2 
···   bn 2 Rd are not co-linear. Linear convergence time
algorithms solving (5) have also been developed in several works (e.g. Xue and Ye (1997)  Parrilo
and Sturmfels (2003)  Cohen et al. (2016)). Our motivation of studying this problem is driven by
its recent application in distributed statistical estimation  in which data are assumed to be randomly
spreaded to multiple connected computational agents that produce intermediate estimators  and then 
these intermediate estimators are aggregated in order to compute some statistics of the whole data set.
Arguably one of the most widely used aggregation procedures is computing the geometric median of
the local estimators (see  for example  Duchi et al. (2014)  Minsker et al. (2014)  Minsker and Strawn
(2017)  Yin et al. (2018)). It can be shown that the geometric median is robust against arbitrary
corruptions of local estimators in the sense that the ﬁnal estimator is stable as long as at least half of
the nodes in the system perform as expected.

4The result in Xu et al. (2017) heavily depends on the assumption that the subgradient of (·) is deﬁned
everywhere over the set ⌦1 and uniformly bound by some constant ⇢  which excludes the choice of indicator
functions necessary to deal with constraints in the ADMM framework.

3

Contributions: As an example application of our general algorithm  we look at the problem of
computing the solution to (5) in a distributed scenario over a network of n agents without any
central controller  where each agent holds a local vector bi. Remarkably  we show theoretically that
such a problem  when formulated as (1-2)  has its dual function non-smooth but locally quadratic.
Therefore  applying our proposed primal-dual homotopy smoothing method gives a convergence

time of O"4/5 log2("1). This result improves upon the performance bounds of the previously
known decentralized optimization algorithms (e.g. PG-EXTRA Shi et al. (2015) and decentralized
ADMM Shi et al. (2014))  which do not take into account the special structure of the problem and
only obtain a convergence time of O (1/"). Simulation experiments also demonstrate the superior
ergodic convergence time of our algorithm compared to other algorithms.

2 Primal-dual Homotopy Smoothing

2.1 Preliminaries
The Lagrange dual function of (1-2) is deﬁned as follows:5

F () := max

x2X {h  Ax  bi  f (x)}  

(6)

where  2 RN is the dual variable  X is a compact convex set and the minimum of the dual function
is F ⇤ := min2RN F (). For any closed set K✓ Rd and x 2 Rd  deﬁne the distance function of x
to the set K as

dist(x K) := min

y2K kx  yk 

where kxk :=qPd

i=1 x2

i . For a convex function F ()  the -sublevel set S is deﬁned as

S := { 2 RN : F ()  F ⇤  }.

⇤⇤ :=⇤ 2 RN : F (⇤)  F ()  8 2 RN 

(7)
Furthermore  for any matrix A 2 RN⇥d  we use max(AT A) to denote the largest eigenvalue of
AT A. Let
(8)
be the set of optimal Lagrange multipliers. Note that if the constraint Ax = b is feasible  then
⇤ 2 ⇤⇤ implies ⇤ + v 2 ⇤⇤ for any v that satisﬁes AT v = 0. The following deﬁnition introduces
the notion of local error bound.
Deﬁnition 2.1. Let F () be a convex function over  2 RN . Suppose ⇤⇤ is non-empty. The function
F () is said to satisfy the local error bound with parameter  2 (0  1] if 9> 0 such that for any
 2S  
(9)
where C is a positive constant possibly depending on . In particular  when  = 1/2  F () is said
to be locally quadratic and when  = 1  it is said to be locally linear.
Remark 2.1. Indeed  a wide range of popular optimization problems satisfy the local error bound
condition. The work Tseng (2010) shows that if X is a polyhedron  f (·) has Lipschitz continuous
gradient and is strongly convex  then the dual function of (1-2) is locally linear. The work Burke and
Tseng (1996) shows that when the objective is linear and X is a convex cone  the dual function is
also locally linear. The values of  have also been computed for several other problems (e.g. Pang
(1997); Yang and Lin (2015)).
Deﬁnition 2.2. Given an accuracy level "> 0  a vector x0 2X is said to achieve an " approximate
solution regarding problem (1-2) if

dist(  ⇤⇤)  C(F ()  F ⇤) 

where f⇤ is the optimal primal objective of (1-2).

f (x0)  f⇤ O (")  kAx0  bk O (") 

Throughout the paper  we adopt the following assumptions:

5Usually  the Lagrange dual is deﬁned as minx2X h  Ax  bi + f (x). Here  we ﬂip the sign and take the

maximum for no reason other than being consistent with the form (4).

4

(a) The feasible set {x 2X : Ax  b = 0} is nonempty and non-singleton.

Assumption 2.1.
(b) The set X is bounded  i.e. supx y2X kx  yk  D  for some positive constant D. Furthermore 
the function f (x) is also bounded  i.e. maxx2X |f (x)| M  for some positive constant M.
(c) The dual function deﬁned in (6) satisﬁes the local error bound for some parameter  2 (0  1] and
some level > 0.
(d) Let PA be the projection operator onto the column space of A. There exists a unique vector
⌫⇤ 2 RN such that for any ⇤ 2 ⇤⇤  PA⇤ = ⌫⇤  i.e. ⇤⇤ =⇤ 2 RN : PA⇤ = ⌫⇤ .
Note that assumption (a) and (b) are very mild and quite standard. For most applications  it is enough
to check (c) and (d). We will show  for example  in Section 4 that the distributed geometric median
problem satisﬁes all the assumptions. Finally  we say a function g : X! R is smooth with modulus
L > 0 if

krg(x)  rg(y)k  Lkx  yk  8x  y 2X .

2.2 Primal-dual homotopy smoothing algorithm
This section introduces our proposed algorithm for optimization problem (1-2) satisfying Assump-
tion 2.1. The idea of smoothing is to introduce a smoothed Lagrange dual function Fµ() that
approximates the original possibly non-smooth dual function F () deﬁned in (6).
For any constant µ > 0  deﬁne

fµ(x) = f (x) +

µ

2kx exk2 

whereex is an arbitrary ﬁxed point in X . For simplicity of notation  we drop the dependency onex

in the deﬁnition of fµ(x). Then  by the boundedness assumption of X   we have f (x)  fµ(x) 
f (x) + µ

2 D2  8x 2X . For any  2 RN  deﬁne

Fµ() = max

x2X h  Ax  bi  fµ(x)

as the smoothed dual function. The fact that Fµ() is indeed smooth with modulus µ follows from
Lemma 6.1 in the Supplement. Thus  one is able to apply an accelerated gradient descent algorithm
on this modiﬁed Lagrange dual function  which is detailed in Algorithm 1 below  starting from an

(10)

(11)

initial primal-dual pair (ex e) 2 Rd ⇥ RN.
Algorithm 1 Primal-Dual Smoothing: PDS⇣e ex  µ  T⌘
Let 0 = 1 =e and ✓0 = ✓1 = 1.
For t = 0 to T  1 do

t1  1)(t  t1) 

• Compute a tentative dual multiplier:bt = t + ✓t(✓1
• Compute the primal update: x(bt) = argmaxx2X Dbt  Ax  bE  f (x)  µ
• Compute the dual update: t+1 =bt + µ(Ax(bt)  b).
• Update the stepsize: ✓t+1 =
x(bt) and T   where ST =PT1

p✓4

ST PT1

t=0

t ✓2

t

.

1
✓t

t +4✓2

2

1
✓t

t=0

.

end for
Output: xT = 1

Our proposed algorithm runs Algorithm 1 in multiple stages  which is detailed in Algorithm 2 below.

2kx exk2.

3 Convergence Time Results

We start by deﬁning the set of optimal Lagrange multipliers for the smoothed problem:6

⇤⇤µ :=⇤µ 2 RN : Fµ(⇤µ)  Fµ()  8 2 RN 

6By Assumption 2.1(a) and Farkas’ Lemma  this is non-empty.

(12)

5

Algorithm 2 Homotopy Method:
Let "0 be a ﬁxed constant and "<" 0 be the desired accuracy. Set µ0 = "0
number of stages K  dlog2("0/")e + 1  and the time horizon during each stage T  1.
For k = 1 to K do

D2   (0) = 0  x(0) 2X   the

• Let µk = µk1/2.
• Run the primal-dual smoothing algorithm ((k)  x(k)) = PDS⇣(k1)  x(k1)  µk  T⌘.

end for
Output: x(K).

Our convergence time analysis involves two steps. The ﬁrst step is to derive a primal convergence
time bound for Algorithm 1  which involves the location information of the initial Lagrange multiplier
at the beginning of this stage. The details are given in Supplement 6.2.

+

 

2

(13)

(14)

Theorem 3.1. Suppose Assumption 2.1(a)(b) holds. For any T  1 and any initial vector (ex e) 2

Rd ⇥ RN   we have the following performance bound regarding Algorithm 1 

2

µD2

max(AT A)

e⇤ e
f (xT )  f⇤  kPAe⇤k·k AxT  bk +
⇣e⇤ e + dist(⇤µ  ⇤⇤)⌘  
  ST =PT1
ST PT1

kAxT  bk 

2max(AT A)

x(bt)

2µST

µST

t=0

t=0

1
✓t

and ⇤µ is any point in

wheree⇤ 2 argmin⇤2⇤⇤k⇤ ek  xT := 1
⇤⇤µ deﬁned in (12).
An inductive argument shows that ✓t  2/(t + 2) 8t  0. Thus  Theorem 3.1 already gives an
O(1/") convergence time by setting µ = " and T = 1/". Note that this is the best trade-off we
can get from Theorem 3.1 when simply bounding the terms ke⇤ ek and dist(⇤µ  ⇤⇤) by constants.
To see how this bound leads to an improved convergence time when running in multiple rounds 
suppose the computation from the last round gives ae that is close enough to the optimal set ⇤⇤ 
then  ke⇤ ek would be small. When the local error bound condition holds  one can show that
dist(⇤µ  ⇤⇤) O (µ). As a consequence  one is able to choose µ smaller than " and get a better
trade-off. Formally  we have the following overall performance bound. The proof is given in
Supplement 6.3.
Theorem 3.2. Suppose Assumption 2.1 holds  "0  max{2M  1}  0 <"  min{/2  2M  1} 
T  2DCpmax(AT A)(2M )/2
. The proposed homotopy method achieves the following objective
and constraint violation bound:

"2/(2+)

✓t

f (x(K))  f⇤ ✓ 24kPA⇤k(1 + C)
kAx(K)  bk 

24(1 + C)
 (2M ) " 
C2

 (2M )2

C2

+

6

 (2M )2 +
C2

1

4◆ " 

with running time 2DCpmax(AT A)(2M )/2
approximation with convergence time O"2/(2+) log2("1).

"2/(2+)

(dlog2("0/")e + 1)  i.e. the algorithm achieves an "

4 Distributed Geometric Median
Consider the problem of computing the geometric median over a connected network (V E)  where
V = {1  2 ···   n} is a set of n nodes  E = {eij}i j2V is a collection of undirected edges  eij = 1
if there exists an undirected edge between node i and node j  and eij = 0 otherwise. Furthermore 
eii = 1  8i 2{ 1  2 ···   n}.Furthermore  since the graph is undirected  we always have eij =
eji  8i  j 2{ 1  2 ···   n}. Two nodes i and j are said to be neighbors of each other if eij = 1. Each
node i holds a local vector bi 2 Rd  and the goal is to compute the solution to (5) without having a
central controller  i.e. each node can only communicate with its neighbors.

6

vector in Rn.

Computing geometric median over a network has been considered in several works previously and
various distributed algorithms have been developed such as decentralized subgradient methd (DSM 
Nedic and Ozdaglar (2009); Yuan et al. (2016))  PG-EXTRA (Shi et al. (2015)) and ADMM (Shi
et al. (2014); Deng et al. (2017)). The best known convergence time for this problem is O(1/"). In
this section  we will show that it can be written in the form of problem (1-2)  has its Lagrange dual
function locally quadratic and optimal Lagrange multiplier unique up to the null space of A  thereby
satisfying Assumption 2.1.
Throughout this section  we assume that n  3  b1  b2 
···   bn 2 Rd are not co-linear and they
are distinct (i.e. bi 6= bj if i 6= j). We start by deﬁning a mixing matrixfW 2 Rn⇥n with respect to
this network. The mixing matrix will have the following properties:

1. Decentralization: The (i  j)-th entry ewij = 0 if eij = 0.
2. Symmetry: fW = fWT .
3. The null space of In⇥n fW satisﬁes N (In⇥n fW) = {c1  c 2 R}  where 1 is an all 1
These conditions are rather mild and satisﬁed by most doubly stochastic mixing matrices used in
practice. Some speciﬁc examples are Markov transition matrices of max-degree chain and Metropolis-
Hastings chain (see Boyd et al. (2004) for detailed discussions). Let xi 2 Rd be the local variable on
the node i. Deﬁne
x :=2664
if i = j
if i 6= j
and ewij is ij-th entry of the mixing matrixfW. By the aforementioned null space property of the
mixing matrixfW  it is easy to see that the null space of the matrix A is

3775 2 Rnd  A =264
Wij =⇢(1  ewij)Id⇥d 
ewijId⇥d 
1  ···   uT

(15)
Then  because of the null space property (15)  one can equivalently write problem (5) in a “distributed
fashion” as follows:

3775 2 Rnd  b :=2664

N (A) =u 2 Rnd : u = [uT

n ]T   u1 = u2 = ··· = un  

375 2 R(nd)⇥(nd) 

··· W1n
...
··· Wnn

W11
...
Wn1

b1
b2
...
bn

x1
x2
...
xn

...

 

where

nXi=1

min

kxi  bik

(16)

t 1  T

t 2 ···   T

s.t. Ax = 0 kxi  bik  D  i = 1  2 ···   n 

(17)
where we set the constant D to be large enough so that the solution belongs to the set X :=
x 2 Rnd : kxi  bik  D  i = 1  2 ···   n . This is in the same form as (1-2) with X := {x 2
Rnd : kxi  bik  D  i = 1  2 ···   n}.
4.1 Distributed implementation
In this section  we show how to implement the proposed algorithm to solve (16-17) in a distributed
t n] 2 Rnd be the vectors
way. Let t = [T
of Lagrange multipliers deﬁned in Algorithm 1  where each t i  bt i 2 Rd. Then  each agent
i 2{ 1  2 ···   n} in the network is responsible for updating the corresponding Lagrange multipliers
t i andbt i according to Algorithm 1  which has the initial values 0 i = 1 i =ei. Note that the
ﬁrst  third and fourth steps in Algorithm 1 are naturally separable regarding each agent. It remains to
check if the second step can be implemented in a distributed way.
Note that in the second step  we obtain the primal update x(bt) = [x1(bt)T  ···   xn(bt)T ] 2 Rnd
x(bt) = argmaxx:kxibikD  i=1 2 ···  n Dbt  AxE 
2kxi exik2⌘  

t n] 2 Rnd bt = [bT

nXi=1⇣kxi  bik +

t 2 ···   bT

by solving the following problem:

t 1  bT

µ

7

whereexi 2 Rd is a ﬁxed point in the feasible set. We separate the maximization according to different

agent i 2{ 1  2 ···   n}:

xi(bt) =argmaxxi:kxibikD 

nXj=1Dbt j  WjixiE  kxi  bik 

µ

2kxi exik2.

Note that according to the deﬁnition of Wji  it is equal to 0 if agent j is not the neighbor of agent i.
More speciﬁcally  Let Ni be the set of neighbors of agent i (including the agent i itself)  then  the
above maximization problem can be equivalently written as

µ

µ

µ

kxibikD 

xi(bt) = argmax

ji = Wji. Solving this problem only requires the local information

where we used the fact that WT
from each agent. Completing the squares gives

2kxi exik2
2kxi exik2 i 2{ 1  2 ···   n} 
Wjibt j1A

argmaxxi:kxibikD  Xj2NiDbt j  WjixiE  kxi  bik 
Wjibt j  xi+  kxi  bik 
=argmaxxi:kxibikD *Xj2Ni
2
xi 0@exi 
µPj2Ni
Wjibt j  then  the solution to (18) has the following closed
bi 
kbiaik⇣kbi  aik  1
µ⌘  
bi  biai
bi  biai
kbiaik
4.2 Local error bound condition
The proof of the this theorem is given in Supplement 6.5.
Theorem 4.1. The Lagrange dual function of (16-17) is non-smooth and given by the following

Lemma 4.1. Let ai =exi  1
xi(bt) =8><>:

The solution to such a subproblem has a closed form  as is shown in the following lemma (the proof
is given in Supplement 6.4):

if kbi  aik  1/µ 
if 1
µ < kbi  aik  1
otherwise.

 kxi  bik.

(18)

1

µ Xj2Ni

µ + D 

form:

2

D 

nXi=1
F () = ⌦AT   b↵ + D
[i]k > 1⌘ is
where A[i] = [W1i W2i ··· Wni]T is the i-th column block of the matrix A  I⇣kAT
the indicator function which takes 1 if kAT
[i]k > 1 and 0 otherwise. Let ⇤⇤ be the set of optimal
Lagrange multipliers deﬁned according to (8). Suppose D  2n · maxi j2V kbi  bjk  then  for any
> 0  there exists a C > 0 such that

[i]k  1) · I⇣kAT
(kAT

[i]k > 1⌘  

dist(  ⇤⇤)  C(F ()  F ⇤)1/2  8 2S .

Furthermore  there exists a unique vector ⌫⇤ 2 Rnd s.t. PA⇤ = ⌫⇤  8⇤ 2 ⇤⇤  i.e. Assumption
2.1(d) holds. Thus  applying the proposed method gives the convergence time O"4/5 log2("1).

5 Simulation Experiments

In this section  we conduct simulation experiments on the distributed geometric median problem.
Each vector bi 2 R100  i 2{ 1  2 ···   n} is sampled from the uniform distribution in [0  10]100  i.e.
each entry of bi is independently sampled from uniform distribution on [0  10]. We compare our
algorithm with DSM (Nedic and Ozdaglar (2009))  P-EXTRA (Shi et al. (2015))  Jacobian parallel
ADMM (Deng et al. (2017)) and Smoothing (Necoara and Suykens (2008)) under different network

8

sizes (n = 20  50  100). Each network is randomly generated with a particular connectivity ratio7 
and the mixing matrix is chosen to be the Metropolis-Hastings Chain (Boyd et al. (2004))  which
can be computed in a distributed manner. We use the relative error as the performance metric  which
is deﬁned as kxt  x⇤k/kx0  x⇤k for each iteration t. The vector x0 2 Rnd is the initial primal
variable. The vector x⇤ 2 Rnd is the optimal solution computed by CVX Grant et al. (2008). For
our proposed algorithm  xt is the restarted primal average up to the current iteration. For all other
algorithms  xt is the primal average up to the current iteration. The results are shown below. We see
in all cases  our proposed algorithm is much better than  if not comparable to  other algorithms. For
detailed simulation setups and additional simulation results  see Supplement 6.6.

r
o
r
r
e
e
v
i
t

 

l

a
e
R

0

-0.5

-1

-1.5

-2

-2.5

-3

-3.5

-4

-4.5

-5

0

DSM
EXTRA
Jacobian-ADMM
Smoothing
Proposed algorithm

1

2

3

4

5

6

7

8

9

Number of iterations

10
×10 4

(a)

r
o
r
r
e
e
v
i
t

 

l

a
e
R

0

-0.5

-1

-1.5

-2

-2.5

-3

-3.5

-4

-4.5

-5

0

DSM
EXTRA
Jacobian-ADMM
Smoothing
Proposed algorithm

1

2

3

4

5

6

7

8

9

Number of iterations

10
×10 4

(b)

r
o
r
r
e
e
v
i
t

 

l

a
e
R

0

-1

-2

-3

-4

-5

-6

0

DSM
EXTRA
Jacobian-ADMM
Smoothing
Proposed algorithm

1

2

3

4

5

6

7

8

9

Number of iterations

10
×10 4

(c)

Figure 1: Comparison of different algorithms on networks of different sizes. (a) n = 20  connectivity
ratio=0.15. (b) n = 50  connectivity ratio=0.13. (c) n = 100  connectivity ratio=0.1.

Acknowledgments
The authors thank Stanislav Minsker and Jason D. Lee for helpful discussions related to the geometric
median problem. Qing Ling’s research is supported in part by the National Science Foundation China
under Grant 61573331 and Guangdong IIET Grant 2017ZT07X355. Qing Ling is also afﬁliated
with Guangdong Province Key Laboratory of Computational Science. Michael J. Neely’s research is
supported in part by the National Science Foundation under Grant CCF-1718477.

References
Beck  A.  A. Nedic  A. Ozdaglar  and M. Teboulle (2014). An o(1/k) gradient method for network

resource allocation problems. IEEE Transactions on Control of Network Systems 1(1)  64–73.

Bertsekas  D. P. (1999). Nonlinear programming. Athena Scientiﬁc Belmont.
Bertsekas  D. P. (2009). Convex optimization theory. Athena Scientiﬁc Belmont.
Boyd  S.  P. Diaconis  and L. Xiao (2004). Fastest mixing markov chain on a graph. SIAM

Review 46(4)  667–689.

Burke  J. V. and P. Tseng (1996). A uniﬁed analysis of Hoffman’s bound via Fenchel duality. SIAM

Journal on Optimization 6(2)  265–282.

Cohen  M. B.  Y. T. Lee  G. Miller  J. Pachocki  and A. Sidford (2016). Geometric median in nearly
linear time. In Proceedings of the forty-eighth annual ACM symposium on Theory of Computing 
pp. 9–21.

Deng  W.  M.-J. Lai  Z. Peng  and W. Yin (2017). Parallel multi-block ADMM with o(1/k) conver-

gence. Journal of Scientiﬁc Computing 71(2)  712–736.

Deng  W. and W. Yin (2016). On the global and linear convergence of the generalized alternating

direction method of multipliers. Journal of Scientiﬁc Computing 66(3)  889–916.

Duchi  J. C.  M. I. Jordan  M. J. Wainwright  and Y. Zhang (2014). Optimality guarantees for

distributed statistical estimation. arXiv preprint arXiv:1405.0782.

Gidel  G.  F. Pedregosa  and S. Lacoste-Julien (2018). Frank-Wolfe splitting via augmented La-

grangian method. arXiv preprint arXiv:1804.03176.

Grant  M.  S. Boyd  and Y. Ye (2008). CVX: Matlab software for disciplined convex programming.

7The connectivity ratio is deﬁned as the number of edges divided by the total number of possible edges

n(n + 1)/2.

9

Han  D.  D. Sun  and L. Zhang (2015). Linear rate convergence of the alternating direction method
of multipliers for convex composite quadratic and semi-deﬁnite programming. arXiv preprint
arXiv:1508.02134.

Lan  G. and R. D. Monteiro (2013). Iteration-complexity of ﬁrst-order penalty methods for convex

programming. Mathematical Programming 138(1-2)  115–139.

Li  J.  G. Chen  Z. Dong  and Z. Wu (2016). A fast dual proximal-gradient method for separable convex
optimization with linear coupled constraints. Computational Optimization and Applications 64(3) 
671–697.

Ling  Q. and Z. Tian (2010). Decentralized sparse signal recovery for compressive sleeping wireless

sensor networks. IEEE Transactions on Signal Processing 58(7)  3816–3827.

Luo  X.-D. and Z.-Q. Luo (1994). Extension of hoffman’s error bound to polynomial systems. SIAM

Journal on Optimization 4(2)  383–392.

Minsker  S.  S. Srivastava  L. Lin  and D. B. Dunson (2014). Robust and scalable bayes via a median

of subset posterior measures. arXiv preprint arXiv:1403.2660.

Minsker  S. and N. Strawn (2017). Distributed statistical estimation and rates of convergence in

normal approximation. arXiv preprint arXiv:1704.02658.

Motzkin  T. (1952). Contributions to the theory of linear inequalities. D.R. Fulkerson (Transl.) (Santa

Monica: RAND Corporation). RAND Corporation Translation 22.

Necoara  I. and J. A. Suykens (2008). Application of a smoothing technique to decomposition in

convex optimization. IEEE Transactions on Automatic control 53(11)  2674–2679.

Nedic  A. and A. Ozdaglar (2009). Distributed subgradient methods for multi-agent optimization.

IEEE Transactions on Automatic Control 54(1)  48–61.

Nesterov  Y. (2005). Smooth minimization of non-smooth functions. Mathematical Program-

ming 103(1)  127–152.

Nesterov  Y. (2015a). Complexity bounds for primal-dual methods minimizing the model of objective

function. Mathematical Programming  1–20.

Nesterov  Y. (2015b). Universal gradient methods for convex optimization problems. Mathematical

Programming 152(1-2)  381–404.

Osborne  M. R.  B. Presnell  and B. A. Turlach (2000). A new approach to variable selection in least

squares problems. IMA Journal of Numerical Analysis 20(3)  389–403.

Pang  J.-S. (1997  Oct). Error bounds in mathematical programming. Mathematical Program-

ming 79(1)  299–332.

Parrilo  P. A. and B. Sturmfels (2003). Minimizing polynomial functions. Algorithmic and quantitative
real algebraic geometry  DIMACS Series in Discrete Mathematics and Theoretical Computer
Science 60  83–99.

Shi  W.  Q. Ling  G. Wu  and W. Yin (2015). A proximal gradient algorithm for decentralized

composite optimization. IEEE Transactions on Signal Processing 63(22)  6013–6023.

Shi  W.  Q. Ling  K. Yuan  G. Wu  and W. Yin (2014). On the linear convergence of the admm in

decentralized consensus optimization. IEEE Trans. Signal Processing 62(7)  1750–1761.

Tran-Dinh  Q.  O. Fercoq  and V. Cevher (2018). A smooth primal-dual optimization framework for

nonsmooth composite convex minimization. SIAM Journal on Optimization 28(1)  96–134.

Tseng  P. (2010). Approximation accuracy  gradient methods  and error bound for structured convex

optimization. Mathematical Programming 125(2)  263–295.

Wang  T. and J.-S. Pang (1994). Global error bounds for convex quadratic inequality systems.

Optimization 31(1)  1–12.

Wei  X. and M. J. Neely (2018). Primal-dual Frank-Wolfe for constrained stochastic programs with

convex and non-convex objectives. arXiv preprint arXiv:1806.00709.

Wei  X.  H. Yu  and M. J. Neely (2015). A probabilistic sample path convergence time analysis of

drift-plus-penalty algorithm for stochastic optimization. arXiv preprint arXiv:1510.02973.

Weiszfeld  E. and F. Plastria (2009). On the point for which the sum of the distances to n given points

is minimum. Annals of Operations Research 167(1)  7–41.

Xiao  L. and T. Zhang (2013). A proximal-gradient homotopy method for the sparse least-squares

problem. SIAM Journal on Optimization 23(2)  1062–1091.

10

Xu  Y.  M. Liu  Q. Lin  and T. Yang (2017). ADMM without a ﬁxed penalty parameter: Faster
convergence with new adaptive penalization. In Advances in Neural Information Processing
Systems  pp. 1267–1277.

Xu  Y.  Y. Yan  Q. Lin  and T. Yang (2016). Homotopy smoothing for non-smooth problems with lower
complexity than o(1/✏). In Advances In Neural Information Processing Systems  pp. 1208–1216.
Xue  G. and Y. Ye (1997). An efﬁcient algorithm for minimizing a sum of euclidean norms with

applications. SIAM Journal on Optimization 7(4)  1017–1036.

Yang  T. and Q. Lin (2015). Rsg: Beating subgradient method without smoothness and strong

convexity. arXiv preprint arXiv:1512.03107.

Yin  D.  Y. Chen  K. Ramchandran  and P. Bartlett (2018). Byzantine-robust distributed learning:

Towards optimal statistical rates. arXiv preprint arXiv:1803.01498.

Yu  H. and M. J. Neely (2017a). A new backpressure algorithm for joint rate control and routing with
vanishing utility optimality gaps and ﬁnite queue lengths. In INFOCOM 2017-IEEE Conference
on Computer Communications  IEEE  pp. 1–9. IEEE.

Yu  H. and M. J. Neely (2017b). A simple parallel algorithm with an o(1/t) convergence rate for

general convex programs. SIAM Journal on Optimization 27(2)  759–783.

Yu  H. and M. J. Neely (2018). On the convergence time of dual subgradient methods for strongly

convex programs. IEEE Transactions on Automatic Control.

Yuan  K.  Q. Ling  and W. Yin (2016). On the convergence of decentralized gradient descent. SIAM

Journal on Optimization 26(3)  1835–1854.

Yurtsever  A.  Q. T. Dinh  and V. Cevher (2015). A universal primal-dual convex optimization

framework. In Advances in Neural Information Processing Systems  pp. 3150–3158.

Yurtsever  A.  O. Fercoq  F. Locatello  and V. Cevher (2018). A conditional gradient framework for
composite convex minimization with applications to semideﬁnite programming. arXiv preprint
arXiv:1804.08544.

11

,Xiaohan Wei
Hao Yu
Qing Ling
Michael Neely