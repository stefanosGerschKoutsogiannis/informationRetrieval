2015,Optimization Monte Carlo: Efficient and Embarrassingly Parallel Likelihood-Free Inference,We describe an embarrassingly parallel  anytime Monte Carlo method for likelihood-free models.  The algorithm starts with the view that the stochasticity of the pseudo-samples generated by the simulator can be controlled externally by a vector of random numbers u  in such a way that the outcome  knowing u  is deterministic.  For each instantiation of u we run an optimization procedure to minimize the distance between summary statistics of the simulator and the data. After reweighing these samples using the prior and the Jacobian (accounting for the change of volume in transforming from the space of summary statistics to the space of parameters) we show that this weighted ensemble represents a Monte Carlo estimate of the posterior distribution. The procedure can be run embarrassingly parallel (each node handling one sample) and anytime (by allocating resources to the worst performing sample). The procedure is validated on six experiments.,Optimization Monte Carlo: Efﬁcient and

Embarrassingly Parallel Likelihood-Free Inference

Edward Meeds

Informatics Institute

University of Amsterdam
tmeeds@gmail.com

Max Welling∗

welling.max@gmail.com

Informatics Institute

University of Amsterdam

Abstract

We describe an embarrassingly parallel  anytime Monte Carlo method for
likelihood-free models. The algorithm starts with the view that the stochastic-
ity of the pseudo-samples generated by the simulator can be controlled externally
by a vector of random numbers u  in such a way that the outcome  knowing u 
is deterministic. For each instantiation of u we run an optimization procedure to
minimize the distance between summary statistics of the simulator and the data.
After reweighing these samples using the prior and the Jacobian (accounting for
the change of volume in transforming from the space of summary statistics to the
space of parameters) we show that this weighted ensemble represents a Monte
Carlo estimate of the posterior distribution. The procedure can be run embar-
rassingly parallel (each node handling one sample) and anytime (by allocating
resources to the worst performing sample). The procedure is validated on six ex-
periments.

Introduction

1
Computationally demanding simulators are used across the full spectrum of scientiﬁc and industrial
applications  whether one studies embryonic morphogenesis in biology  tumor growth in cancer
research  colliding galaxies in astronomy  weather forecasting in meteorology  climate changes in
the environmental science  earthquakes in seismology  market movement in economics  turbulence
in physics  brain functioning in neuroscience  or fabrication processes in industry. Approximate
Bayesian computation (ABC) forms a large class algorithms that aims to sample from the posterior
distribution over parameters for these likelihood-free (a.k.a. simulator based) models. Likelihood-
free inference  however  is notoriously inefﬁcient in terms of the number of simulation calls per
independent sample. Further  like regular Bayesian inference algorithms  care must be taken so that
posterior sampling targets the correct distribution.
The simplest ABC algorithm  ABC rejection sampling  can be fully parallelized by running indepen-
dent processes with no communication or synchronization requirements. I.e. it is an embarrassingly
parallel algorithm. Unfortunately  as the most inefﬁcient ABC algorithm  the beneﬁts of this ti-
tle are limited. There has been considerable progress in distributed MCMC algorithms aimed at
large-scale data problems [2  1]. Recently  a sequential Monte Carlo (SMC) algorithm called “the
particle cascade” was introduced that emits streams of samples asynchronously with minimal mem-
ory management and communication [17]. In this paper we present an alternative embarrassingly
parallel sampling approach: each processor works independently  at full capacity  and will indeﬁ-
nitely emit independent samples. The main trick is to pull random number generation outside of the
simulator and treat the simulator as a deterministic piece of code. We then minimize the difference
∗Donald Bren School of Information and Computer Sciences University of California  Irvine  and Canadian

Institute for Advanced Research.

1

between observations and the simulator output over its input parameters and weight the ﬁnal (opti-
mized) parameter value with the prior and the (inverse of the) Jacobian. We show that the resulting
weighted ensemble represents a Monte Carlo estimate of the posterior. Moreover  we argue that the
error of this procedure is O() if the optimization gets -close to the optimal value. This “Opti-
mization Monte Carlo” (OMC) has several advantages: 1) it can be run embarrassingly parallel  2)
the procedure generates independent samples and 3) the core procedure is now optimization rather
than MCMC. Indeed  optimization as part of a likelihood-free inference procedure has recently been
proposed [12]; using a probabilistic model of the mapping from parameters to differences between
observations and simulator outputs  they apply “Bayesian Optimization” (e.g. [13  21]) to efﬁciently
perform posterior inference. Note also that since random numbers have been separated out from the
simulator  powerful tools such as “automatic differentiation” (e.g. [14]) are within reach to assist
with the optimization. In practice we ﬁnd that OMC uses far fewer simulations per sample than
alternative ABC algorithms.
The approach of controlling randomness as part of an inference procedure is also found in a related
class of parameter estimation algorithms called indirect inference [11]. Connections between ABC
and indirect inference have been made previously by [7] as a novel way of creating summary statis-
tics. An indirect inference perspective led to an independently developed version of OMC called the
“reverse sampler” [9  10].
In Section 2 we brieﬂy introduce ABC and present it from a novel viewpoint in terms of random
numbers. In Section 3 we derive ABC through optimization from a geometric point of view  then
proceed to generalize it to higher dimensions. We show in Section 4 extensive evidence of the
correctness and efﬁciency of our approach. In Section 5 we describe the outlook for optimization-
based ABC.

2 ABC Sampling Algorithms
The primary interest in ABC is the posterior of simulator parameters θ given a vector of (statistics
of) observations y  p(θ|y). The likelihood p(y|θ) is generally not available in ABC. Instead we can
use the simulator as a generator of pseudo-samples x that reside in the same space as y. By treating
x as auxiliary variables  we can continue with the Bayesian treatment:

p(θ|y) =

≈ p(θ)(cid:82) p(y|x)p(x|θ) dx
(cid:82) p(θ)(cid:82) p(y|x)p(x|θ) dx dθ

p(θ)p(y|θ)

p(y)

(1)

Of particular importance is the choice of kernel measuring the discrepancy between observations y
and pseudo-data x. Popular choices for kernels are the Gaussian kernel and the uniform -tube/ball.
The bandwidth parameter  (which may be a vector  accounting for relative importance of each
statistic) plays critical role: small  produces more accurate posteriors  but is more computationally
demanding  whereas large  induces larger error but is cheaper.
We focus our attention on population-based ABC samplers  which include rejection sampling  im-
portance sampling (IS)  sequential Monte Carlo (SMC) [6  20] and population Monte Carlo [3]. In
rejection sampling  we draw parameters from the prior θ ∼ p(θ)  then run a simulation at those
parameters x ∼ p(x|θ); if the discrepancy ρ(x  y) <   then the particle is accepted  otherwise it
is rejected. This is repeated until n particles are accepted. Importance sampling generalizes rejec-
tion sampling using a proposal distribution qφ(θ) instead of the prior  and produces samples with
weights wi ∝ p(θ)/q(θ). SMC extends IS to multiple rounds with decreasing   adapting their par-
ticles after each round  such that each new population improves the approximation to the posterior.
Our algorithm has similar qualities to SMC since we generate a population of n weighted particles 
but differs signiﬁcantly since our particles are produced by independent optimization procedures 
making it completely parallel.

3 A Parallel and Efﬁcient ABC Sampling Algorithm
Inherent in our assumptions about the simulator is that internally there are calls to a random number
generator which produces the stochasticity of the pseudo-samples. We will assume for the moment
that this can be represented by a vector of uniform random numbers u which  if known  would
make the simulator deterministic. More concretely  we assume that any simulation output x can
be represented as a deterministic function of parameters θ and a vector of random numbers u 

2

(a) Dθ = Dy

(b) Dθ < Dy

Figure 1: Illustration of OMC geometry. (a) Dashed lines indicate contours f (θ  u) over θ for several u. For
three values of u  their initial and optimal θ positions are shown (solid blue/white circles). Within the grey
acceptance region  the Jacobian  indicated by the blue diagonal line  describes the relative change in volume
induced in f (θ  u) from a small change in θ. Corresponding weights ∝ 1/|J| are shown as vertical stems. (b)
When Dθ < Dy  here 1 < 2  the change in volume is proportional to the length of the line segment inside the
ellipsoid (|JT J|1/2). The orange line indicates the projection of the observation onto the contour of f (θ  u) (in
this case  identical to the optimal).

i.e. x = f (θ  u). This assumption has been used previously in ABC  ﬁrst in “coupled ABC”
[16] and also in an application of Hamiltonian dynamics to ABC [15]. We do not make any further
assumptions regarding u or p(u)  though for some problems their dimension and distribution may be
known a priori. In these cases it may be worth employing Sobol or other low-discrepancy sequences
to further improve the accuracy of any Monte Carlo estimates.
We will ﬁrst derive a dual representation for the ABC likelihood function p(y|θ) (see also [16]) 

p(y|θ) =

=

p(y|x)p(x|θ) dx =
p(y|f (θ  u))p(u) du

p(y|x)I[x = f (θ  u)]p(u) dxdu

(2)

(3)

(cid:90) (cid:90)

(cid:90)
(cid:90)
(cid:90)

leading to the following Monte Carlo approximation of the ABC posterior 

p(θ|y) ∝ p(θ)

p(u)p(y|f (u  θ)) du ≈ 1
n

p(y|f (ui  θ))p(θ) ui ∼ p(u)

(4)

(cid:88)

i

i that results in y = f (θo

Since p is a kernel that only accepts arguments y and f (ui  θ) that are  close to each other (for
values of  that are as small as possible)  Equation 4 tells us that we should ﬁrst sample values for
u from p(u) and then for each such sample ﬁnd the value for θo
i   u). In
practice we want to drive these values as close to each other as possible through optimization and
accept an O() error if the remaining distance is still O(). Note that apart from sampling the values
for u this procedure is deterministic and can be executed completely in parallel  i.e. without any
communication. In the following we will assume a single observation vector y  but the approach is
equally applicable to a dataset of N cases.
3.1 The case Dθ = Dy
We will ﬁrst study the case when the number of parameters θ is equal to the number of summary
statistics y. To understand the derivation it helps to look at Figure 1a which illustrates the derivation
for the one dimensional case. In the following we use the following abbreviation: fi(θ) stands for
f (θ  ui). The general idea is that we want to write the approximation to the posterior as a mixture
of small uniform balls (or delta peaks in the limit):

wiU(θ|θ∗

i )p(θ)

(5)

(cid:88)

i

p(θ|y) ≈ 1
n

(cid:88)

i

p(y|f (ui  θ))p(θ) ≈ 1
n

3

with wi some weights that we will derive shortly. Then  if we make  small enough we can replace
any average of a sufﬁciently smooth function h(θ) w.r.t. this approximate posterior simply by eval-
uating h(θ) at some arbitrarily chosen points inside these balls (for instance we can take the center
of the ball θ∗
i ) 

(cid:90)

h(θ)p(θ|y) dθ ≈ 1
n

h(θ∗

i )wip(θ∗
i )

(6)

(cid:88)

i

To derive this expression we ﬁrst assume that:

(7)
i.e. a ball of radius . C() is the normalizer which is immaterial because it cancels in the posterior.
For small enough  we claim that we can linearize fi(θ) around θo
i :

p(y|fi(θ)) = C()I[||y − fi(θ)||2 ≤ 2]

Ri = O(||θ − θo

i ||2)

(8)

. We take θo
i

to be the end result of our

i (θ − θo

i ) + Jo

ˆfi(θ) = fi(θo

i ) + Ri 
i is the Jacobian matrix with columns ∂fi(θo
i )

where Jo
optimization procedure for sample ui. Using this we thus get 
i )) − Jo

∂θd

||y − fi(θ)||2 ≈ ||(y − fi(θo

i ) − Ri||2
i (θ − θo
(9)
We ﬁrst note that since we assume that our optimization has ended up somewhere inside the ball
i )|| = O(). Also  since we only
deﬁned by ||y − fi(θ)||2 ≤ 2 we can assume that ||y − fi(θo
consider values for θ that satisfy ||y − fi(θ)||2 ≤ 2  and furthermore assume that the function
i || = O() as well. All of this implies
fi(θ) is Lipschitz continuous in θ it follows that ||θ − θo
that we can safely ignore the remaining term Ri (which is of order O(||θ − θo
i ||2) = O(2)) if we
restrict ourselves to the volume inside the ball.
The next step is to view the term I[||y − fi(θ)||2 ≤ 2] as a distribution in θ. With the Taylor
expansion this results in 

I[(θ − θo

i − Jo −1

i

(y − fi(θo

i )))T JoT

i Jo

This represents an ellipse in θ-space with a centroid θ∗

i (θ − θo

(y − fi(θo
i and volume Vi given by

i

i ))) ≤ 2]

θ∗
i = θo

(y − fi(θo
i ))

i

i + Jo −1
(cid:88)

i Jo
i )
with γ a constant independent of i. We can approximate the posterior now as 
i )p(θ∗
i )
i Jo
i )

U(θ|θ∗
det(JoT

p(θ|y) ≈ 1
κ

i )p(θ)
i Jo
i )

δ(θ − θ∗

≈ 1
κ

det(JoT

det(JoT

(cid:113)

i

i

malization  κ = (cid:80)

i Jo

i p(θ∗

i ) det(JoT

where in the last step we have send  → 0. Finally  we can compute the constant κ through nor-
i )−1/2. The whole procedure is accurate up to errors of the
order O(2)  and it is assumed that the optimization procedure delivers a solution that is located
within the epsilon ball. If one of the optimizations for a certain sample ui did not end up within
the epsilon ball there can be two reasons: 1) the optimization did not converge to the optimal value
for θ  or 2) for this value of u there is no solution for which f (θ|u) can get within a distance 
from the observation y. If we interpret  as our uncertainty in the observation y  and we assume that
our optimization succeeded in ﬁnding the best possible value for θ  then we should simply reject
this sample θi. However  it is hard to detect if our optimization succeeded and we may therefore
sometimes reject samples that should not have been rejected. Thus  one should be careful not to
create a bias against samples ui for which the optimization is difﬁcult. This situation is similar to a
sampler that will not mix to remote local optima in the posterior distribution.

Vi =

i − Jo −1
γ(cid:113)
(cid:113)

(cid:88)

(10)

(11)

(12)

3.2 The case Dθ < Dy
This is the overdetermined case and here the situation as depicted in Figure 1b is typical: the mani-
fold that f (θ  ui) traces out as we vary θ forms a lower dimensional surface in the Dy dimensional
enveloping space. This manifold may or may not intersect with the sphere centered at the observa-
tion y (or ellipsoid  for the general case  instead of ). Assume that the manifold does intersect the

4

i (y − fi(θo
i ))

epsilon ball but not y. Since we trust our observation up to distance   we may simple choose to
pick the closest point θ∗
i to y on the manifold  which is given by 
θ∗
i = θo

i + Jo†
(13)
where Jo†
is the pseudo-inverse. We can now deﬁne our ellipse around this point  shifting the
center of the ball from y to fi(θ∗
i ) (which do not coincide in this case). The uniform distribution
on the ellipse in θ-space is now deﬁned in the Dθ dimensional manifold and has volume Vi =
i )−1/2. So once again we arrive at almost the same equation as before (Eq. 12) but with
γ det(JoT
i )|| ≤ 2
the slightly different deﬁnition of the point θ∗
and if we assume that our optimization succeeded  we will only make mistakes of order O(2).

i given by Eq. 13. Crucially  since ||y − fi(θ∗

Jo†
i = (JoT

i Jo

i )−1JoT

i

i

i Jo

3.3 The case Dθ > Dy
This is the underdetermined case in which it is typical that entire manifolds (e.g. hyperplanes) may
be a solution to ||y − fi(θ∗
In this case we can not approximate the posterior with a
mixture of point masses and thus the procedure does not apply. However  the case Dθ > Dy is less
interesting than the other ones above as we expect to have more summary statistics than parameters
for most problems.

i )|| = 0.

4 Experiments
The goal of these experiments is to demonstrate 1) the correctness of OMC and 2) the relative
efﬁciency of OMC in relation to two sequential MC algorithms  SMC (aka population MC [3]) and
adaptive weighted SMC [5]. To demonstrate correctness  we show histograms of weighted samples
along with the true posterior (when known) and  for three experiments  the exact OMC weighted
samples (when the exact Jacobian and optimal θ is known). To demonstrate efﬁciency  we compute
the mean simulations per sample (SS)—the number of simulations required to reach an  threshold—
and the effective sample size (ESS)  deﬁned as 1/wT w. Additionally  we may measure ESS/n  the
fraction of effective samples in the population. ESS is a good way of detecting whether the posterior
is dominated by a few particles and/or how many particles achieve discrepancy less than epsilon.
There are several algorithmic options for OMC. The most obvious is to spawn independent pro-
cesses  draw u for each  and optimize until  is reached (or a max nbr of simulations run)  then
compute Jacobians and particle weights. Variations could include keeping a sorted list of discrepan-
cies and allocating computational resources to the worst particle. However  to compare OMC with
SMC  in this paper we use a sequential version of OMC that mimics the epsilon rounds of SMC.
Each simulator uses different optimization procedures  including Newton’s method for smooth sim-
ulators  and random walk optimization for others; Jacobians were computed using one-sided ﬁnite
differences. To limit computational expense we placed a max of 1000 simulations per sample per
round for all algorithms. Unless otherwise noted  we used n = 5000 and repeated runs 5 times; lack
of error bars indicate very low deviations across runs. We also break some of the notational conven-
tion used thus far so that we can specify exactly how the random numbers translate into pseudo-data
and the pseudo-data into statistics. This is clariﬁed for each example. Results are explained in
Figures 2 to 4.
4.1 Normal with Unknown Mean and Known Variance

√

The simplest example is the inference of the mean θ of a univariate normal distribution with known
variance σ2. The prior distribution π(θ) is normal with mean θ0 and variance kσ2  where k > 0 is
a factor relating the dispersions of θ and the data yn. The simulator can generate data according to
the normal distribution  or deterministically if the random effects rum are known:

=⇒ xm = θ + rum

(cid:80)
m xm. Therefore we have f (θ  u) = θ + R(u) where R(u) =(cid:80) rum /M

π(xm|θ) = N (xm|θ  σ2)
(14)
−1(2um− 1) (using the inverse CDF). A sufﬁcient statistic for this problem is
where rum = σ
2 erf
the average s(x) = 1
M
In our experiment we set M = 2 and y = 0. The exact
(the average of the random effects).
Jacobian and θo
i can be computed for this problem: for a draw ui  Ji = 1; if s(y) is the mean of the
i = s(y) − R(ui). Therefore the exact
observations y  then by setting f (θo
weights are wi ∝ π(θo
i )  allowing us to compare directly with an exact posterior based on our dual
representation by u (shown by orange circles in Figure 2 top-left). We used Newton’s method to
optimize each particle.

i   ui) = s(y) we ﬁnd θo

5

Figure 2: Left: Inference of unknown mean. For  0.1  OMC uses 3.7 SS; AW/SMC uses 20/20 SS; at  0.01 
OMC uses 4 SS (only 0.3 SS more)  and SMC jumps to 110 SS. For all algorithms and  values  ESS/n=1.
Right: Inference for mixture of normals. Similar results for OMC; at  0.025 AW/SMC had 40/50 SS and at
 0.01 has 105/120 SS. The ESS/n remained at 1 for OMC  but decreased to 0.06/0.47 (AW/SMC) at  0.025 
and 0.35 for both at  0.01. Not only does the ESS remain high for OMC  but it also represents the tails of the
distribution well  even at low .

4.2 Normal Mixture
A standard illustrative ABC problem is the inference of the mean θ of a mixture of two normals
[19  3  5]: p(x|θ) = ρ N (θ  σ2
2)  with π(θ) = U(θa  θb) where hyperparameters
2 = 1/100  θa = −10  θb = 10  and a single observation scalar y = 0.
are ρ = 1/2  σ2
For this problem M = 1 so we drop the subscript m. The true posterior is simply p(θ|y = 0) ∝
ρ N (θ  σ2
2)  θ ∈ {−10  10}. In this problem there are two random numbers u1
and u2  one for selecting the mixture component and the other for the random innovation; further 
the statistic is the identity  i.e. s(x) = x:

1) + (1 − ρ) N (θ  σ2

1) + (1− ρ) N (θ  σ2

1 = 1  σ2

2 erf(2u2 − 1)) + [u1 ≥ ρ](θ + σ2

2 erf(2u2 − 1))

√

√

x = [u1 < ρ](θ + σ1

√

√

= θ +

σ[u1≥ρ]
2
where R(u) =
. As with the previous example  the Jacobian is 1
i = y − R(ui) is known exactly. This problem is notable for causing performance issues in
and θo
ABC-MCMC [19] and its difﬁculty in targeting the tails of the posterior [3]; this is not the case for
OMC.

2 erf(2u2 − 1)σ[u1<ρ]
σ[u1≥ρ]

2 erf(2u2 − 1)σ[u1<ρ]

= θ + R(u)

1

1

2

(15)
(16)

4.3 Exponential with Unknown Rate
In this example  the goal is to infer the rate θ of an exponential distribution  with a gamma prior
p(θ) = Gamma(θ|α  β)  based on M draws from Exp(θ):

p(xm|θ) = Exp(xm|θ) = θ exp(−θxm) =⇒ xm = − 1
θ

problem is the average s(x) = (cid:80)

(17)
where rum = − ln(1 − um) (the inverse CDF of the exponential). A sufﬁcient statistic for this
m xm/M. Again  we have exact expressions for the Jacobian
i = R(ui)/s(y). We used M = 2 

i   using f (θ  ui) = R(ui)/θ  Ji = −R(ui)/θ2 and θo

ln(1 − um) =

rum

1
θ

and θo
s(y) = 10 in our experiments.

4.4 Linked Mean and Variance of Normal
In this example we link together the mean and variance of the data generating function as follows:
(18)

p(xm|θ) = N (xm|θ  θ2)

=⇒ xm = θ + θ

−1(2um − 1) = θrum

2 erf

√

6

Figure 3: Left: Inference of rate of exponential. A similar result wrt SS occurs for this experiment: at  1 
OMC had 15 v 45/50 for AW/SMC; at  0.01  SS was 28 OMC v 220 AW/SMC. ESS/n dropping with below
1: OMC drops at  1 to 0.71 v 0.97 for SMC; at  0.1 ESS/n remains the same. Right: Inference of linked
normal. ESS/n drops signiﬁcantly for OMC: at  0.25 to 0.32 and at  0.1 to 0.13  while it remains high
for SMC (0.91 to 0.83). This is the result the inability of every ui to achieve ρ <   whereas for SMC  the
algorithm allows them to “drop” their random numbers and effectively switch to another. This was veriﬁed
by running an expensive ﬁne-grained optimization  resulting in 32.9% and 13.6% optimized particles having
ρ under  0.25/0.1. Taking this inefﬁciency into account  OMC still requires 130 simulations per effective
sample v 165 for SMC (ie 17/0.13 and 136/0.83).

√

−1(2um − 1). We put a positive constraint on θ: p(θ) = U(0  10). We used

2 erf

where rum = 1 +
2 statistics  the mean and variance of M draws from the simulator:
=⇒ f1(θ  u) = θR(u)
=⇒ f2(θ  u) = θ2V (u)

(xm − s1(x))2

s1(x) =

xm

1
M
1
M

(cid:88)
where V (u) = (cid:80)

s2(x) =

m

/M − R(u)2 and R(u) = (cid:80)

m r2
um

[R(u)  2θV (u)]T . In our experiments M = 10  s(y) = [2.7  12.8].

∂f1(θ  u)

∂θ

∂f2(θ  u)

∂θ

= R(u)

= 2θV (u)

(19)

(20)

m rum /M; the exact Jacobian is therefore

4.5 Lotka-Volterra
The simplest Lotka-Volterra model explains predator-prey populations over time  controlled by a set
of stochastic differential equations:

= θ1x1 − θ2x1x2 + r1

dx1
dt

dx2
dt

= −θ2x2 − θ3x1x2 + r2

(21)
where x1 and x2 are the prey and predator population sizes  respectively. Gaussian noise r ∼
N (0  102) is added at each full time-step. Lognormal priors are placed over θ. The simulator
runs for T = 50 time steps  with constant initial populations of 100 for both prey and predator.
There is therefore P = 2T outputs (prey and predator populations concatenated)  which we use
as the statistics. To run a deterministic simulation  we draw ui ∼ π(u) where the dimension of
u is P . Half of the random variables are used for r1 and the other half for r2. In other words 
−1(2ust − 1)  where s ∈ {1  2} for the appropriate population. The Jacobian is a
rust = 10
100×3 matrix that can be computed using one-sided ﬁnite-differences using 3 forward simulations.

2 erf

√

4.6 Bayesian Inference of the M/G/1 Queue Model
Bayesian inference of the M/G/1 queuing model is challenging  requiring ABC algorithms [4  8] or
sophisticated MCMC-based procedures [18]. Though simple to simulate  the output can be quite

7

Figure 4: Top: Lotka-Volterra. Bottom: M/G/1 Queue. The left plots shows the posterior mean ±1 std errors
of the posterior predictive distribution (sorted for M/G/1). Simulations per sample and the posterior of θ1 are
shown in the other plots. For L-V  at  3  the SS for OMC were 15 v 116/159 for AW/SMC  and increased
at  2 to 23 v 279/371. However  the ESS/n was lower for OMC: at  3 it was 0.25 and down to 0.1 at  2 
whereas ESS/n stayed around 0.9 for AW/SMC. This is again due to the optimal discrepancy for some u being
greater than ; however  the samples that remain are independent samples. For M/G/1  the results are similar 
but the ESS/n is lower than the number of discrepancies satisfying  1  9% v 12%  indicating that the volume
of the Jacobians is having a large effect on the variance of the weights. Future work will explore this further.

noisy. In the M/G/1 queuing model  a single server processes arriving customers  which are then
served within a random time. Customer m arrives at time wm ∼ Exp(θ3) after customer m− 1  and
is served in sm ∼ U(θ1  θ2) service time. Both wm and sm are unobserved; only the inter-departure
times xm are observed. Following [18]  we write the simulation algorithm in terms of arrival times
vm. To simplify the updates  we keep track of the departure times dm. Initially  d0 = 0 and v0 = 0 
followed by updates for m ≥ 1:

xm = sm + max(0  vm − dm−1)

dm = dm−1 + xm

vm = vm−1 + wm

(22)
After trying several optimization procedures  we found the most reliable optimizer was simply a
random walk. The random sources in the problem used for Wm (there are M) and for Um (there are
M)  therefore u is dimension 2M. Typical statistics for this problem are quantiles of x and/or the
minimum and maximum values; in other words  the vector x is sorted then evenly spaced values for
the statistics functions f (we used 3 quantiles). The Jacobian is an M ×3 matrix. In our experiments
θ∗ = [1.0  5.0  0.2]

5 Conclusion
We have presented Optimization Monte Carlo  a likelihood-free algorithm that  by controlling the
simulator randomness  transforms traditional ABC inference into a set of optimization procedures.
By using OMC  scientists can focus attention on ﬁnding a useful optimization procedure for their
simulator  and then use OMC in parallel to generate samples independently. We have shown that
OMC can also be very efﬁcient  though this will depend on the quality of the optimization pro-
cedure applied to each problem. In our experiments  the simulators were cheap to run  allowing
Jacobian computations using ﬁnite differences. We note that for high-dimensional input spaces and
expensive simulators  this may be infeasible  solutions include randomized gradient estimates [22]
or automatic differentiation (AD) libraries (e.g. [14]). Future work will include incorporating AD 
improving efﬁciency using Sobol numbers (when the size u is known)  incorporating Bayesian opti-
mization  adding partial communication between processes  and inference for expensive simulators
using gradient-based optimization.

Acknowledgments

We thank the anonymous reviewers for the many useful comments that improved this manuscript.
MW acknowledges support from Facebook  Google  and Yahoo.

8

References
[1] Ahn  S.  Korattikara  A.  Liu  N.  Rajan  S.  and Welling  M. (2015). Large scale distributed Bayesian

matrix factorization using stochastic gradient MCMC. In KDD.

[2] Ahn  S.  Shahbaba  B.  and Welling  M. (2014). Distributed stochastic gradient MCMC. In Proceedings of

the 31st International Conference on Machine Learning (ICML-14)  pages 1044–1052.

[3] Beaumont  M. A.  Cornuet  J.-M.  Marin  J.-M.  and Robert  C. P. (2009). Adaptive approximate Bayesian

computation. Biometrika  96(4):983–990.

[4] Blum  M. G. and Franc¸ois  O. (2010). Non-linear regression models for approximate Bayesian computa-

tion. Statistics and Computing  20(1):63–73.

[5] Bonassi  F. V. and West  M. (2015). Sequential Monte Carlo with adaptive weights for approximate

Bayesian computation. Bayesian Analysis  10(1).

[6] Del Moral  P.  Doucet  A.  and Jasra  A. (2006). Sequential Monte Carlo samplers. Journal of the Royal

Statistical Society: Series B (Statistical Methodology)  68(3):411–436.

[7] Drovandi  C. C.  Pettitt  A. N.  and Faddy  M. J. (2011). Approximate Bayesian computation using indirect

inference. Journal of the Royal Statistical Society: Series C (Applied Statistics)  60(3):317–337.

[8] Fearnhead  P. and Prangle  D. (2012). Constructing summary statistics for approximate Bayesian compu-
tation: semi-automatic approximate Bayesian computation. Journal of the Royal Statistical Society: Series
B (Statistical Methodology)  74(3):419–474.

[9] Forneron  J.-J. and Ng  S. (2015a). The ABC of simulation estimation with auxiliary statistics. arXiv

preprint arXiv:1501.01265v2.

[10] Forneron  J.-J. and Ng  S. (2015b). A likelihood-free reverse sampler of the posterior distribution. arXiv

preprint arXiv:1506.04017v1.

[11] Gourieroux  C.  Monfort  A.  and Renault  E. (1993). Indirect inference. Journal of applied econometrics 

8(S1):S85–S118.

[12] Gutmann  M. U. and Corander  J. (2015). Bayesian optimization for likelihood-free inference of
simulator-based statistical models. Journal of Machine Learning Research  preprint arXiv:1501.03291.
In press.

[13] Jones  D. R.  Schonlau  M.  and Welch  W. J. (1998). Efﬁcient global optimization of expensive black-box

functions. Journal of Global optimization  13(4):455–492.

[14] Maclaurin  D. and Duvenaud  D. (2015). Autograd. github.com/HIPS/autograd.
[15] Meeds  E.  Leenders  R.  and Welling  M. (2015). Hamiltonian ABC. Uncertainty in AI  31.
[16] Neal  P. (2012). Efﬁcient likelihood-free Bayesian computation for household epidemics. Statistical

Computing  22:1239–1256.

[17] Paige  B.  Wood  F.  Doucet  A.  and Teh  Y. W. (2014). Asynchronous anytime Sequential Monte Carlo.

In Advances in Neural Information Processing Systems  pages 3410–3418.

[18] Shestopaloff  A. Y. and Neal  R. M. (2013). On Bayesian inference for the M/G/1 queue with efﬁcient

MCMC sampling. Technical Report  Dept. of Statistics  University of Toronto.

[19] Sisson  S.  Fan  Y.  and Tanaka  M. M. (2007). Sequential Monte Carlo without likelihoods. Proceedings

of the National Academy of Sciences  104(6).

[20] Sisson  S.  Fan  Y.  and Tanaka  M. M. (2009). Sequential Monte Carlo without likelihoods: Errata.

Proceedings of the National Academy of Sciences  106(16).

[21] Snoek  J.  Larochelle  H.  and Adams  R. P. (2012). Practical Bayesian optimization of machine learning

algorithms. Advances in Neural Information Processing Systems 25.

[22] Spall  J. C. (1992). Multivariate stochastic approximation using a simultaneous perturbation gradient

approximation. Automatic Control  IEEE Transactions on  37(3):332–341.

9

,Ted Meeds
Max Welling
Alex Beatson
Zhaoran Wang
Han Liu