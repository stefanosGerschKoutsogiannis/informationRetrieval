2017,Online Convex Optimization with Stochastic Constraints,This paper considers online convex optimization  (OCO) with stochastic constraints  which generalizes Zinkevich's OCO over a  known simple fixed set by introducing multiple stochastic functional constraints that are i.i.d. generated at each round and are disclosed to the decision maker only after the decision is made. This formulation arises naturally when decisions are restricted by stochastic environments or deterministic environments with noisy observations. It also includes many important problems  as special case  such as OCO with long term constraints  stochastic constrained convex optimization  and deterministic constrained convex optimization.  To solve this problem  this paper proposes a new algorithm that achieves $O(\sqrt{T})$ expected regret and constraint violations and $O(\sqrt{T}\log(T))$ high probability regret and constraint violations. Experiments on a real-world data center scheduling problem further verify the performance of the new algorithm.,Online Convex Optimization with Stochastic

Constraints

Hao Yu  Michael J. Neely  Xiaohan Wei

Department of Electrical Engineering  University of Southern California⇤

{yuhao mjneely xiaohanw}@usc.edu

Abstract

This paper considers online convex optimization (OCO) with stochastic constraints 
which generalizes Zinkevich’s OCO over a known simple ﬁxed set by introducing
multiple stochastic functional constraints that are i.i.d. generated at each round
and are disclosed to the decision maker only after the decision is made. This
formulation arises naturally when decisions are restricted by stochastic environ-
ments or deterministic environments with noisy observations. It also includes
many important problems as special case  such as OCO with long term constraints 
stochastic constrained convex optimization  and deterministic constrained con-
vex optimization. To solve this problem  this paper proposes a new algorithm
that achieves O(pT ) expected regret and constraint violations and O(pT log(T ))
high probability regret and constraint violations. Experiments on a real-world data
center scheduling problem further verify the performance of the new algorithm.

1

Introduction

Online convex optimization (OCO) is a multi-round learning process with arbitrarily-varying convex
loss functions where the decision maker has to choose decision x(t) 2X before observing the
corresponding loss function f t(·). For a ﬁxed time horizon T   deﬁne the regret of a learning algorithm
with respect to the best ﬁxed decision in hindsight (with full knowledge of all loss functions) as

regret(T ) =

f t(x(t))  min
x2X

f t(x).

TXt=1

TXt=1

The goal of OCO is to develop dynamic learning algorithms such that regret grows sub-linearly with
respect to T . The setting of OCO is introduced in a series of work [3  14  9  29] and is formalized in
[29]. OCO has gained considerable amount of research interest recently with various applications
such as online regression  prediction with expert advice  online ranking  online shortest paths  and
portfolio selection. See [23  11] for more applications and background.
In [29]  Zinkevich shows O(pT ) regret can be achieved by using an online gradient descent (OGD)
update given by

x(t + 1) = PX⇥x(t)  rf t(x(t))⇤
(1)
where rf t(·) is a subgradient of f t(·) and PX [·] is the projection onto set X . Hazan et al. in [12]
show that better regret is possible under the assumption that each loss function is strongly convex but
O(pT ) is the best possible if no additional assumption is imposed.
It is obvious that Zinkevich’s OGD in (1) requires the full knowledge of set X and low complexity
of the projection PX [·]. However  in practice  the constraint set X   which is often described by

⇤This work is supported in part by grant NSF CCF-1718477.

31st Conference on Neural Information Processing Systems (NIPS 2017)  Long Beach  CA  USA.

1

T PT

many functional inequality constraints  can be time varying and may not be fully disclosed to the
decision maker. In [18]  Mannor et al. extend OCO by considering time-varying constraint functions
gt(x) which can arbitrarily vary and are only disclosed to us after each x(t) is chosen. In this
setting  Mannor et al. in [18] explore the possibility of designing learning algorithms such that
regret grows sub-linearly and lim supT!1
t=1 gt(x(t))  0  i.e.  the (cumulative) constraint
violationPT
t=1 gt(x(t)) also grows sub-linearly. Unfortunately  Mannor et al. in [18] prove that this
is impossible even when both f t(·) and gt(·) are simple linear functions.
Given the impossibility results shown by Mannor et al. in [18]  this paper considers OCO where
constraint functions gt(x) are not arbitrarily varying but independently and identically distributed
(i.i.d.) generated from an unknown probability model (and functions f t(x) are still arbitrarily varying
and possibly non-i.i.d.). Speciﬁcally  this paper considers online convex optimization (OCO) with
stochastic constraint X = {x 2X 0 : E![gk(x; !)]  0  k 2{ 1  2  . . .   m}} where X0 is a known
ﬁxed set; the expressions of stochastic constraints E![gk(x; !)] (involving expectations with respect
to ! from an unknown distribution) are unknown; and subscripts k 2{ 1  2  . . .   m} indicate the
possibility of multiple functional constraints. In OCO with stochastic constraints  the decision maker
k(x) = gk(x; !(t)) at each
receives loss function f t(x) and i.i.d. constraint function realizations gt
k(·) and f t(·) are disclosed to the decision maker only after
round t. However  the expressions of gt
decision x(t) 2X 0 is chosen. This setting arises naturally when decisions are restricted by stochastic
environments or deterministic environments with noisy observations. For example  if we consider
online routing (with link capacity constraints) in wireless networks [18]  each link capacity is not
a ﬁxed constant (as in wireline networks) but an i.i.d. random variable since wireless channels are
stochastically time-varying by nature [25]. OCO with stochastic constraints also covers important
special cases such as OCO with long term constraints [16  5  13]  stochastic constrained convex
optimization [17] and deterministic constrained convex optimization [21].

1

2

t=1 gt

t=1 f t(x) be the best ﬁxed decision in hind-
sight (knowing all loss functions f t(x) and the distribution of stochastic constraint functions
gk(x; !)). Thus  x⇤ minimizes the T -round cumulative loss and satisﬁes all stochastic constraints in
expectation  which also implies lim supT!1
k(x⇤)  0 almost surely by the strong law
of large numbers. Our goal is to develop dynamic learning algorithms that guarantee both regret

Let x⇤ = argmin{x2X0:E[gk(x;!)]0 8k2{1 2 ... m}}PT
T PT

t=1 gt

k(x(t)) grow sub-linearly.

• OCO with long term constraints: This is a special case where each gt

t=1 f t(x⇤) and constraint violationsPT

PT
t=1 f t(x(t)) PT
Note that Zinkevich’s algorithm in (1) is not applicable to OCO with stochastic constraints since X
is unknown and it can happen that X (t) = {x 2X 0 : gk(x; !(t))  0 8k 2{ 1  2  . . .   m}} = ;
for certain realizations !(t)  such that projections PX [·] or PX (t)[·] required in (1) are not even
well-deﬁned.
Our Contributions: This paper solves online convex optimization with stochastic constraints. In
particular  we propose a new learning algorithm that is proven to achieve O(pT ) expected regret
and constraint violations and O(pT log(T )) high probability regret and constraint violations. The
proposed new algorithm also improves upon state-of-the-art results in the following special cases:
k(x) ⌘ gk(x) is known
and does not depend on time. Note that X = {x 2X 0 : gk(x)  0 8k 2{ 1  2  . . .   m}} can
be complicated while X0 might be a simple hypercube. To avoid high complexity involved in
the projection onto X as in Zinkevich’s algorithm  work in [16  5  13] develops low complexity
algorithms that use projections onto a simpler set X0 by allowing gk(x(t)) > 0 for certain
rounds but ensuring lim supT!1
t=1 gk(x(t))  0. The best existing performance is
O(T max{ 1}) regret and O(T 1/2) constraint violations where  2 (0  1) is an algorithm
parameter [13]. This gives O(pT ) regret with worse O(T 3/4) constraint violations or O(pT )
constraint violations with worse O(T ) regret. In contrast  our algorithm  which only uses
projections onto X0 as shown in Lemma 1  can achieve O(pT ) regret and O(pT ) constraint
violations simultaneously. Note that by adapting the methodology presented in this paper  our
other work [27] developed a different algorithm that can only solve the special case problem
“OCO with long term constraints” but can achieve O(pT ) regret and O(1) constraint violations.
• Stochastic constrained convex optimization: This is a special case where each f t(x) is i.i.d.
generated from an unknown distribution. This problem has many applications in operations
research and machine learning such as Neyman-Pearson classiﬁcation and risk-mean portfolio.

1

T PT

The work [17] develops a (batch) ofﬂine algorithm that produces a solution with high probability
performance guarantees only after sampling the problems for sufﬁciently many times. That is 
during the process of sampling  there is no performance guarantee. The work [15] proposes
a stochastic approximation based (batch) ofﬂine algorithm for stochastic convex optimization
with one single stochastic functional inequality constraint. In contrast  our algorithm is an
online algorithm with online performance guarantees and can deal with an arbitrary number of
stochastic constraints.

• Deterministic constrained convex optimization: This is a special case where each f t(x) ⌘ f (x)
and gt
k(x) ⌘ gk(x) are known and do not depend on time. In this case  the goal is to develop
a fast algorithm that converges to a good solution (with a small error) with a few number of
iterations; and our algorithm with O(pT ) regret and constraint violations is equivalent to an
iterative numerical algorithm with O(1/pT ) convergence rate. Our algorithm is subgradient
based and does not require the smoothness or differentiability of the convex program. The
primal-dual subgradient method considered in [19] has the same O(1/pT ) convergence rate but
requires an upper bound of optimal Lagrange multipliers  which is usually unknown in practice.

2 Formulation and New Algorithm
Let X0 be a known ﬁxed compact convex set. Let f t(x) be a sequence of arbitrarily-varying convex
functions. Let gk(x; !(t))  k 2{ 1  2  . . .   m} be sequences of functions that are i.i.d. realizations of
stochastic constraint functions ˜gk(x) = E![gk(x; !)] with random variable ! 2 ⌦ from an unknown
distribution. That is  !(t) are i.i.d. samples of !. Assume that each f t(·) is independent of all !(⌧ )
with ⌧  t + 1 so that we are unable to predict future constraint functions based on the knowledge of
the current loss function. For each ! 2 ⌦  we assume gk(x; !) are convex with respect to x 2X 0. At
the beginning of each round t  neither the loss function f t(x) nor the constraint function realizations
gk(x; !(t)) are known to the decision maker. However  the decision maker still needs to make a
decision x(t) 2X 0 for round t; and after that f t(x) and gk(x ! (t)) are disclosed to the decision
maker at the end of round t.
For convenience  we often suppress the dependence of each gk(x; !(t)) on !(t) and write
k(x) = gk(x; !(t)). Recall ˜gk(x) = E![gk(x; !)] where the expectation is with respect to !.
gt
Deﬁne X = {x 2X 0 : ˜gk(x) = E[gk(x; !)]  0 8k 2{ 1  2  . . .   m}}. We further deﬁne the
stacked vector of multiple functions gt
m(x)]T and deﬁne
˜g(x) = [E![g1(x; !)]  . . .   E![gm(x; !)]]T. We use k·k to denote the Euclidean norm for a vector.
Throughout this paper  we have the following assumptions:
Assumption 1 (Basic Assumptions).

m(x) as gt(x) = [gt

1(x)  . . .   gt

1(x)  . . .   gt

• Loss functions f t(x) and constraint functions gk(x; !) have bounded subgradients on X0.
That is  there exists D1 > 0 and D2 > 0 such that krf t(x)k  D1 for all x 2X 0 and all
t 2{ 0  1  . . .} and krgk(x; !)k  D2 for all x 2X 0  all ! 2 ⌦ and all k 2{ 1  2  . . .   m}.2
• There exists constant G > 0 such that kg(x; !)k  G for all x 2X 0 and all ! 2 ⌦.
• There exists constant R > 0 such that kx  yk  R for all x  y 2X 0.

Assumption 2 (The Slater Condition). There exists ✏> 0 and ˆx 2X 0 such that ˜gk(ˆx) =
E![gk(ˆx; !)]  ✏ for all k 2{ 1  2  . . .   m}.
2.1 New Algorithm
Now consider the following algorithm described in Algorithm 1. This algorithm chooses x(t + 1) as
the decision for round t + 1 based on f t(·) and gt(·) without requiring f t+1(·) or gt+1(·).
For each stochastic constraint function gk(x; !)  we introduce Qk(t) and call it a virtual queue since
its dynamic is similar to a queue dynamic. The next lemma summarizes that x(t + 1) update in (2)
can be implemented via a simple projection onto X0.
Lemma 1. The x(t + 1) update in (2) is given by x(t + 1) = PX0⇥x(t)  1
V rf t(x(t)) +Pm

2 The notation rh(x) is used to denote a subgradient of a convex function h at the point x.; it is the same as

k(x(t)) and PX0[·] is the projection onto convex set X0.

2↵ d(t)⇤  where d(t) =

k=1 Qk(t)rgt

the gradient whenever the gradient exists.

3

Algorithm 1
Let V > 0 and ↵> 0 be constant algorithm parameters. Choose x(1) 2X 0 arbitrarily and let
Qk(1) = 0 8k 2{ 1  2  . . .   m}. At the end of each round t 2{ 1  2  . . .}  observe f t(·) and gt(·)
and do the following:
• Choose x(t + 1) that solves
k(x(t))]T[x  x(t)] + ↵kx  x(t)k2 (2)
x2X0V [rf t(x(t))]T[x  x(t)] +
as the decision for the next round t + 1  where rf t(x(t)) is a subgradient of f t(x) at point
x = x(t) and rgt
• Update each virtual queue Qk(t + 1) 8k 2{ 1  2  . . .   m} via

k(x(t)) is a subgradient of gt

k(x) at point x = x(t).

Qk(t)[rgt

mXk=1

min

Qk(t + 1) = maxQk(t) + gt

k(x(t)) + [rgt

where max{· ·} takes the larger one between two elements.

k(x(t))]T[x(t + 1)  x(t)]  0  

(3)

2↵ d(t)]k2 and is equivalent to (2).

Intuitions of Algorithm 1

Proof. The projection by deﬁnition is minx2X0 kx  [x(t)  1
2.2
Note that if there are no stochastic constraints gt
0 8t and becomes Zinkevich’s algorithm with  = V

2↵ in (1) since

x(t + 1)

(a)
= argmin

x2X0  V [rf t(x(t))]T[x  x(t)] + ↵kx  x(t)k2
}

{z

|

penalty

k(x)  i.e.  X = X0  then Algorithm 1 has Qk(t) ⌘

 (b)
= PX0⇥x(t) 

V

2↵rf t(x(t))⇤

(4)

where (a) follows from (2); and (b) follows from Lemma 1 by noting that d(t) = V rf t(x(t)). Call
the term marked by an underbrace in (4) the penalty. Thus  Zinkevich’s algorithm is to minimize the
penalty term and is a special case of Algorithm 1 used to solve OCO over X0.
Let Q(t) =⇥Q1(t)  . . .   Qm(t)⇤T be the vector of virtual queue backlogs. Let L(t) = 1

a Lyapunov function and deﬁne Lyapunov drift

2kQ(t)k2 be

(t) = L(t + 1)  L(t) =

[kQ(t + 1)k2  kQ(t)k2].

(5)

1
2

The intuition behind Algorithm 1 is to choose x(t + 1) to minimize an upper bound of the expression

(t)

|{z}drift

+ V [rf t(x(t))]T[x  x(t)] + ↵kx  x(t)k2
|
}

{z

penalty

(6)

The intention to minimize penalty is natural since Zinkevich’s algorithm (for OCO without stochastic
constraints) minimizes penalty  while the intention to minimize drift is motivated by observing that
k(x(t)) is accumulated into queue Qk(t + 1) introduced in (3) such that we intend to have small
gt
queue backlogs. The drift (t) can be complicated and is in general non-convex. The next lemma
(proven in Supplement 7.1) provides a simple upper bound on (t) and follows directly from (3).
Lemma 2. At each round t 2{ 1  2  . . .}  Algorithm 1 guarantees

k(x(t)) + [rgt

k(x(t))]T[x(t + 1)  x(t)]⇤ +

1
2

[G + pmD2R]2 

(7)

mXk=1

(t) 

Qk(t)⇥gt
At the end of round t Pm

k=1 Qk(t)gt

where m is the number of constraint functions; and D2  G and R are deﬁned in Assumption 1.

2 [G + pmD2R]2 is a given constant that is not
affected by decision x(t + 1). The algorithm decision in (2) is now transparent: x(t + 1) is chosen to
minimize the drift-plus-penalty expression (6)  where (t) is approximated by the bound in (7).
2.3 Preliminary Analysis and More Intuitions of Algorithm 1
The next lemma (proven in Supplement 7.2) relates constraint violations and virtual queue values and
follows directly from (3).

k(x(t)) + 1

4

Lemma 3. For any T  1  Algorithm 1 guaranteesPT
1)  x(t)k 8k 2{ 1  2  . . .   m}  where D2 is deﬁned in Assumption 1.
2kxk2 is convex over
Recall that function h : X0 ! R is said to be c-strongly convex if h(x)  c
x 2X 0. It is easy to see that if q : X0 ! R is a convex function  then for any constant c > 0
2kx  bk2 is c-strongly convex. Further  it is known that if
and any vector b  the function q(x) + c
h : X! R is a c-strongly convex function that is minimized at a point xmin 2X 0  then (see  for
example  Corollary 1 in [28]):

k(x(t))  kQ(T +1)k+D2PT

t=1 kx(t+

t=1 gt

h(xmin)  h(x) 

c
2kx  xmink2 8x 2X 0

(8)

Note that the expression involved in minimization (2) in Algorithm 1 is strongly convex with modulus
2↵ and x(t + 1) is chosen to minimize it. Thus  the next lemma follows.
Lemma 4. Let z 2X 0 be arbitrary. For all t  1  Algorithm 1 guarantees

Qk(t)[rgt

k(x(t))]T[x(t + 1)  x(t)] + ↵kx(t + 1)  x(t)k2

V [rf t(x(t))]T[x(t + 1)  x(t)] +
mXk=1

V [rf t(x(t))]T[z  x(t)] +

mXk=1
Qk(t)[rgt

k(x(t))]T[z  x(t)] + ↵kz  x(t)k2  ↵kz  x(t + 1)k2.

2

2↵ +

t=1 gt

2↵ +

k(x(t))  kQ(T + 1)k + V T D1D2

t=1 kQ(t)k 8k 2{ 1  2  . . .   m} where D1 and D2 are deﬁned in Assumption 1.

The next corollary follows by taking z = x(t) in Lemma 4 and is proven in Supplement 7.3.
pmD2
Corollary 1. For all t  1  Algorithm 1 guarantees kx(t + 1)  x(t)k  V D1
2↵ kQ(t)k.
The next corollary follows directly from Lemma 3 and Corollary 1 and shows that constraint violations
are ultimately bounded by sequence kQ(t)k  t 2{ 1  2  . . .   T + 1}.
Corollary 2. For any T  1  Algorithm 1 guaranteesPT
pmD2
2↵ PT
This corollary further justiﬁes why Algorithm 1 intends to minimize drift (t). As illustrated in
the next section  controlled drift can often lead to boundedness of a stochastic process. Thus  the
intuition of minimizing drift (t) is to yield small kQ(t)k bounds.
3 Expected Performance Analysis of Algorithm 1
This section shows that if we choose V = pT and ↵ = T in Algorithm 1  then both expected regret
and expected constraint violations are O(pT ).
3.1 A Drift Lemma for Stochastic Processes
Let {Z(t)  t  0} be a discrete time stochastic process adapted3 to a ﬁltration {F(t)  t  0}. For
example  Z(t) can be a random walk  a Markov chain or a martingale. The drift analysis is the
method of deducing properties  e.g.  recurrence  ergodicity  or boundedness  about Z(t) from its drift
E[Z(t + 1)  Z(t)|F(t)]. See [6  10] for more discussions or applications on drift analysis. This
paper proposes a new drift analysis lemma for stochastic processes as follows:
Lemma 5. Let {Z(t)  t  0} be a discrete time stochastic process adapted to a ﬁltration {F(t)  t 
0} with Z(0) = 0 and F(0) = {;  ⌦}. Suppose there exists an integer t0 > 0  real constants ✓> 0 
max > 0 and 0 <⇣  max such that
(9)

|Z(t + 1)  Z(t)| max 

E[Z(t + t0)  Z(t)|F(t)] ⇢ t0max 

t0⇣ 

if Z(t) <✓
if Z(t)  ✓ .

42
max
⇣

hold for all t 2{ 1  2  . . .}. Then  the following holds
1. E[Z(t)]  ✓ + t0max + t0
2. For any constant 0 < µ < 1  we have Pr(Z(t)  z)  µ 8t 2{ 1  2  . . .} where z =
log⇥ 82

✓ + t0max + t0
3Random variable Y is said to be adapted to -algebra F if Y is F-measurable. In this case  we often write

log⇥ 82
⇣2 ⇤ + t0

⇣2 ⇤ 8t 2{ 1  2  . . .}.

Y 2F . Similarly  random process {Z(t)} is adapted to ﬁltration {F(t)} if Z(t) 2F (t) 8t. See e.g. [7].

42
max
⇣

42
max
⇣

log( 1

µ ).

max

max

(10)

5

The above lemma is proven in Supplement 7.4 and provides both expected and high probability
bounds for stochastic processes based on a drift condition. It will be used to establish upper bounds of
virtual queues kQ(t)k  which further leads to expected and high probability constraint performance
bounds of our algorithm. For a given stochastic process Z(t)  it is possible to show the drift condition
(10) holds for multiple t0 with different ⇣ and ✓. In fact  we will show in Lemma 7 that kQ(t)k
yielded by Algorithm 1 satisﬁes (10) for any integer t0 > 0 by selecting ⇣ and ✓ according to t0.
One-step drift conditions  corresponding to the special case t0 = 1 of Lemma 5  have been previously
considered in [10  20]. However  Lemma 5 (with general t0 > 0) allows us to choose the best t0 in
performance analysis such that sublinear regret and constraint violation bounds are possible.

3.2 Expected Constraint Violation Analysis
Deﬁne ﬁltration {W(t)  t  0} with W(0) = {;  ⌦} and W(t) = (!(1)  . . .  ! (t)) being the
-algebra generated by random samples {!(1)  . . .  ! (t)} up to round t. From the update rule
in Algorithm 1  we observe that x(t + 1) is a deterministic function of f t(·)  g(·; !(t)) and Q(t)
where Q(t) is further a deterministic function of Q(t  1)  g(·; !(t  1))  x(t) and x(t  1). By
inductions  it is easy to show that (x(t)) ✓W (t  1) and (Q(t)) ✓W (t  1) for all t  1 where
(Y ) denotes the -algebra generated by random variable Y . For ﬁxed t  1  since Q(t) is fully
determined by !(⌧ ) ⌧ 2{ 1  2  . . .   t  1} and !(t) are i.i.d.  we know gt(x) is independent of Q(t).
This is formally summarized in the next lemma.
Lemma 6. If x⇤ 2X 0 satisﬁes ˜g(x⇤) = E![g(x⇤; !)]  0  then Algorithm 1 guarantees:

E[Qk(t)gt

k(x⇤)]  0 8k 2{ 1  2  . . .   m} 8t  1.

(11)

Fix k 2{ 1  2  . . .   m} and t  1. Since gt

Proof.
of Qk(t)  which is determined by {!(1)  . . .  ! (t  1)}  it follows that E[Qk(t)gt
E[Qk(t)]E[gt

k(x⇤) = gk(x⇤; !(t)) is independent
k(x⇤)] =

 0  where (a) follows from the fact that E[gt

k(x⇤)]  0 and Qk(t)  0.

k(x⇤)]

(a)

To establish a bound on constraint violations  by Corollary 2  it sufﬁces to derive upper bounds for
kQ(t)k. In this subsection  we derive upper bounds for kQ(t)k by applying the new drift lemma
(Lemma 5) developed at the beginning of this section. The next lemma shows that random process
Z(t) = kQ(t)k satisﬁes the conditions in Lemma 5.
Lemma 7. Let t0 > 0 be an arbitrary integer. At each round t 2{ 1  2  . . .  } in Algorithm 1  the
following holds

kQ(t + 1)k  kQ(t)k G + pmD2R 

E[kQ(t + t0)k  kQ(t)kW(t  1)] ⇢ t0(G + pmD2R) 

2 t0 + (G + pmD2R)t0 + 2↵R2

t0✏ + 2V D1R+[G+pmD2R]2

t0

and

✏
2  

✏

if kQ(t)k <✓
if kQ(t)k  ✓  

where ✓ = ✏
  m is the number of constraint
functions; D1  D2  G and R are deﬁned in Assumption 1; and ✏ is deﬁned in Assumption 2. (Note
that ✏< G by the deﬁnition of G.)
Lemma 7 (proven in Supplement 7.5) allows us to apply Lemma 5 to random process Z(t) = kQ(t)k
and obtain E[kQ(t)k] = O(pT ) 8t by taking t0 = dpTe  V = pT and ↵ = T   where dpTe
represents the smallest integer no less than pT . By Corollary 2  this further implies the expected
constraint violation bound E[PT
Theorem 1 (Expected Constraint Violation Bound). If V = pT and ↵ = T in Algorithm 1  then for
all T  1  we have
TXt=1

t=1 gk(x(t))]  O(pT ) as summarized in the next theorem.

k(x(t))]  O(pT ) 8k 2{ 1  2  . . .   m}.

(12)

E[

gt

where the expectation is taken with respect to all !(t).

Proof. Deﬁne random process Z(t) with Z(0) = 0 and Z(t) = kQ(t)k  t  1 and ﬁltration
F(t) with F(0) = {;  ⌦} and F(t) = W(t  1)  t  1. Note that Z(t) is adapted to F(t). By

6

✏

✏

✏

✏2

+

2

2

pmD2

t=1 gt

1)k +

pT D1D2

2T PT

log[ 32[G+pmD2R]2

t=1 gt
k(x(t))]  O(pT ).

k(x(t))  kQ(T +
t=1 kQ(t)k 8k 2{ 1  2  . . .   m}. Taking expectations on both sides and

2 and
t0✏ + 2V D1R+[G+pmD2R]2
. Thus  by part (1) of Lemma 5  for all
t0✏ + 2V D1R+[G+pmD2R]2
2 t0 + 2(G + pmD2R)t0 + 2↵R2
+
]. Taking t0 = dpTe  V = pT and ↵ = T   we have

Lemma 7  Z(t) satisﬁes the conditions in Lemma 5 with max = G + pmD2R  ⇣ = ✏
2 t0 + (G + pmD2R)t0 + 2↵R2
✓ = ✏
t 2{ 1  2  . . .}  we have E[kQ(t)k]  ✏
8[G+pmD2R]2
t0
E[kQ(t)k]  O(pT ) for all t 2{ 1  2  . . .}.
Fix T  1. By Corollary 2 (with V = pT and ↵ = T )   we havePT
substituting E[kQ(t)k] = O(pT ) 8t into it yields E[PT
3.3 Expected Regret Analysis
The next lemma (proven in Supplement 7.6) reﬁnes Lemma 4 and is useful to analyze the regret.
Lemma 8. Let z 2X 0 be arbitrary. For all T  1  Algorithm 1 guarantees
TXt=1
where m is the number of constraint functions; and D1  D2  G and R are deﬁned in Assumption 1.
Note that if we take V = pT and ↵ = T   then term (I) in (13) is O(pT ). Recall that the expectation
of term (II) in (13) with z = x⇤ is non-positive by Lemma 6. The expected regret bound of Algorithm
1 follows by taking expectations on both sides of (13) and is summarized in the next theorem.
Theorem 2 (Expected Regret Bound). Let x⇤ 2X 0 be any ﬁxed solution that satisﬁes ˜g(x⇤)  0 
e.g.  x⇤ = argminx2XPT

t=1 f t(x). If V = pT and ↵ = T in Algorithm 1  then for all T  1 
TXt=1
E[

[G + pmD2R]2 T
V
}
{z

f t(z) + ↵
V
|

TXt=1⇥ mXk=1
{z

f t(x⇤)] + O(pT ).

f t(x(t))]  E[

f t(x(t)) 

k(z)⇤
}

+ 1
V
|

TXt=1

TXt=1

V D2
1
4↵

Qk(t)gt

(13)

R2 +

1
2

(I)

T +

(II)

where the expectation is taken with respect to all !(t).

V D2
4↵ T + 1
1

2 [G + pmD2R]2 T

Proof. Fix T  1. Taking z = x⇤ in Lemma 8 yieldsPT
t=1⇥Pm
V PT
and using (11) yieldsPT
t=1 E[f t(x(t))] PT
Taking V = pT and ↵ = T yieldsPT
t=1 E[f t(x(t))] PT

k=1 Qk(t)gt
t=1 E[f t(x⇤)] + R2 ↵

V + 1

t=1 f t(x⇤) + ↵

t=1 f t(x(t)) PT
k(x⇤)⇤. Taking expectations on both sides
2 [G+pmD2R]2 T
V .
t=1 E[f t(x⇤)] + O(pT ).

V + D2

V
↵ T + 1

V R2 +

1
4

3.4 Special Case Performance Guarantees
Theorems 1 and 2 provide expected performance guarantees of Algorithm 1 for OCO with stochastic
constraints. The results further imply the performance guarantees in the following special cases:

• OCO with long term constraints: In this case  gk(x; !(t)) ⌘ gk(x) and there is no random-
ness. Thus  the expectations in Theorems 1 and 2 disappear. For this problem  Algorithm 1 can
achieve O(pT ) (deterministic) regret and O(pT ) (deterministic) constraint violations.

• Stochastic constrained convex optimization: Note that i.i.d.

time-varying f (x; !(t)) is a
special case of arbitrarily-varying f t(x) as considered in our OCO setting. Thus  Theorems 1
and 2 still hold when Algorithm 1 is applied to solve stochastic constrained convex optimization
minx{E[f (x; !)] : E[gk(x; !)]  0 8k 2{ 1  2  . . .   m}  x 2X 0} in an online fashion with
i.i.d. realizations !(t) ⇠ !. Since Algorithm 1 chooses each x(t) without knowing !(t)  it
follows that x(t) is independent of !(t0) for any t0  t by the i.i.d. property of each !(t).
T PT
t=1 x(t) as a ﬁxed solu-
Fix T > 0  if we run Algorithm 1 for T slots and use x(T ) = 1
T PT
(b)
tion for any future slot t0  T + 1  then E[f (x(T ); !(t0)]
t=1 E[f (x(t); !(t0))]
 1
=
T PT
= E[f (x⇤; !(t0))] + O( 1pT
t=1 E[f (x⇤; !(t))] + O( 1pT
)
T PT
t=1 E[gk(x(T ); !(t0)]


T PT
 1
T PT
 1

and E[gk(x(T ); !(t0)]

t=1 E[gk(x(t); !(t))]

t=1 E[f (x(t); !(t))]

(b)
= 1

)
(c)

(a)

(a)

(d)

(c)

1

7

) 8k 2{ 1  2  . . .   m} where (a) follows from Jensen’s inequality and the fact that x(T )
O( 1pT
is independent of !(t0); (b) follows because each x(t) is independent of both !(t) and !(t0)
and !(t) ! (t0) are i.i.d. realizations of !; (c) follows from Theorems 1 and 2 by dividing both
sides by T and (d) follows because E[f (x⇤; !(t))] = E[f (x⇤; !(t0))] for all t 2{ 1  . . .   T} by
the i.i.d. property of each !(t). Thus  if we use Algorithm 1 as a (batch) ofﬂine algorithm to
solve stochastic constrained convex optimization  it has O(1/pT ) convergence and ties with
the algorithm developed in [15]  which is by design a (batch) ofﬂine algorithm and can only
solve stochastic optimization with a single constraint function.

• Deterministic constrained convex optimization: Similarly to OCO with long term con-
straints  the expectations in Theorems 1 and 2 disappear in this case since f t(x) ⌘ f (x)
t=1 x(t) as the solution  then f (x(T )) 
and gk(x; !(t)) ⌘ gk(x). If we use x(T ) = 1
)  which follows by dividing inequalities in Theo-
f (x⇤) + O( 1pT
rems 1 and 2 by T on both sides and applying Jensen’s inequality. Thus  Algorithm 1 solves
deterministic constrained convex optimization with O( 1pT

) and gk(x(T ))  O( 1pT

T PT

) convergence.

4 High Probability Performance Analysis
This section shows that if we choose V = pT and ↵ = T in Algorithm 1  then for any 0 << 1 
with probability at least 1    regret is O(pT log(T ) log1.5( 1
 )) and constraint violations are
OpT log(T ) log( 1
 ).

4.1 High Probability Constraint Violation Analysis
Similarly to the expected constraint violation analysis  we can use part (2) of the new drift lemma
(Lemma 5) to obtain a high probability bound of kQ(t)k  which together with Corollary 2 leads to a
high probability constraint violation bound summarized in Theorem 3 (proven in Supplement 7.7).
Theorem 3 (High Probability Constraint Violation Bound). Let 0 << 1 be arbitrary. If V = pT
and ↵ = T in Algorithm 1  then for all T  1 and all k 2{ 1  2  . . .   m}  we have

Pr⇣ TXt=1

gk(x(t))  OpT log(T ) log(

1


)⌘  1  .

4.2 High Probability Regret Analysis
To obtain a high probability regret bound from Lemma 8  it remains to derive a high probability
bound of term (II) in (13) with z = x⇤. The main challenge is that term (II) is a supermartingale with
unbounded differences (due to the possibly unbounded virtual queues Qk(t)). Most concentration
inequalities  e.g.  the Hoeffding-Azuma inequality  used in high probability performance analysis of
online algorithms are restricted to martingales/supermartingales with bounded differences. See for
example [4  2  16]. The following lemma considers supermartingales with unbounded differences.
Its proof (provided in Supplement 7.8) uses the truncation method to construct an auxiliary well-
behaved supermartingale. Similar proof techniques are previously used in [26  24] to prove different
concentration inequalities for supermartingales/martingales with unbounded differences.
Lemma 9. Let {Z(t)  t  0} be a supermartingale adapted to a ﬁltration {F(t)  t  0} with
Z(0) = 0 and F(0) = {;  ⌦}  i.e.  E[Z(t + 1)|F(t)]  Z(t) 8t  0. Suppose there exits a constant
c > 0 such that {|Z(t + 1)  Z(t)| > c}✓{ Y (t) > 0} 8t  0  where Y (t) is process with Y (t)
adapted to F(t) for all t  0. Then  for all z > 0  we have
t1X⌧ =0

Pr(Z(t)  z)  ez2/(2tc2) +

Note that if Pr(Y (t) > 0) = 0 8t  0  then Pr({|Z(t + 1)  Z(t)| > c}) = 0 8t  0 and Z(t) is a
supermartingale with differences bounded by c. In this case  Lemma 9 reduces to the conventional
Hoeffding-Azuma inequality.
The next theorem (proven in Supplement 7.9) summarizes the high probability regret performance of
Algorithm 1 and follows from Lemmas 5-9 .

Pr(Y (⌧ ) > 0) 8t  1.

8

1


Theorem 4 (High Probability Regret Bound). Let x⇤ 2X 0 be any ﬁxed solution that satisﬁes
t=1 f t(x). Let 0 << 1 be arbitrary. If V = pT and
˜g(x⇤)  0  e.g.  x⇤ = argminx2XPT
↵ = T in Algorithm 1  then for all T  1  we have
TXt=1

f t(x⇤) + O(pT log(T ) log1.5(

))⌘  1  .

Pr⇣ TXt=1

f t(x(t)) 

5 Experiment: Online Job Scheduling in Distributed Data Centers
Consider a geo-distributed data center infrastructure consisting of one front-end job router and 100
geographically distributed servers  which are located at 10 different zones to form 10 clusters (10
servers in each cluster). See Fig. 1(a) for an illustration. The front-end job router receives job
tasks and schedules them to different servers to fulﬁll the service. To serve the assigned jobs  each
server purchases power (within its capacity) from its zone market. Electricity market prices can vary
signiﬁcantly across time and zones. For example  see Fig. 1(b) for a 5-minute average electricity
price trace (between 05/01/2017 and 05/10/2017) at New York zone CENTRL [1]. This problem
is to schedule jobs and control power levels at each server in real time such that all incoming jobs
are served and electricity cost is minimized. In our experiment  each server power is adjusted every
5 minutes  which is called a slot. (In practice  server power can not be adjusted too frequently due
to hardware restrictions and conﬁguration delay.) Let x(t) = [x1(t)  . . .   x100(t)] be the power
vector at slot t  where each xi(t) must be chosen from an interval [xmin
] restricted by the
hardware  and the service rate at each server i satisﬁes µi(t) = hi(xi(t))  where hi(·) is an increasing
concave function. At each slot t  the job router schedules µi(t) amount of jobs to server i. The
electricity cost at slot t is f t(x(t)) =P100
i=1 ci(t)xi(t) where ci(t) is the electricity price at server
i’s zone. We use ci(t) from real-world 5-minute average electricity price data at 10 different zones
in New York city between 05/01/2017 and 05/10/2017 obtained from NYISO [1]. At each slot
t  the incoming job is given by !(t) and satisﬁes a Poisson distribution. Note that the amount of
incoming jobs and electricity price ci(t) are unknown to us at the beginning of each slot t but can
be observed at the end of each slot. This is an example of OCO with stochastic constraints  where
we aim to minimize the electricity cost subject to the constraint that incoming jobs must be served
in time. In particular  at each round t  we receive loss function f t(x(t)) and constraint function

  xmax

i

i

gt(x(t)) = !(t) P100

i=1 hi(xi(t)).

We compare our proposed algorithm with 3 baselines: (1) best ﬁxed decision in hindsight; (2) react
[8] and (3) low-power [22]. Both “react" and “low-power" are popular power control strategies
used in distributed data centers. See Supplement 7.10 for more details of these 2 baselines and our
experiment. Fig. 1(c)(d) plot the performance of 4 algorithms  where the running average is the
time average up to the current slot. Fig. 1(c) compares electricity cost while Fig. 1(d) compares
unserved jobs. (Unserved jobs accumulate if the service rate provided by an algorithm is less than
the job arrival rate  i.e.  the stochastic constraint is violated.) Fig. 1(c)(d) show that our proposed
algorithm performs closely to the best ﬁxed decision in hindsight over time  both in electricity cost
and constraint violations. ‘React" performs well in serving job arrivals but yields larger electricity
cost  while “low-power" has low electricity cost but fails to serve job arrivals.

)
h
W
M

/
r
a

l
l

o
d
(
 
e
c
i
r

P

450

400

350

300

250

200

150

100

50

0

0

(a)

Electricity market price

Running average electricity cost

Running average unserved jobs

15000

10000

5000

)
r
a

l
l

o
d
(
 
t
s
o
C

Our algorithm
Best fixed strategy in hindsight
React (Gandhi et al. 2012)
Low-power (Qureshi et al. 2009)

500

1000

1500

2000

2500

Number of slots (each 5 min)

0

0

500

1000

1500

2000

2500

Number of slots (each 5 min)

(b)

(c)

)
t

l

o
s
 
r
e
p
(
 
s
b
o

j
 

d
e
v
r
e
s
n
U

1200

1000

800

600

400

200

0

-200

0

Our algorithm
Best fixed decision in hindsight
React (Gandhi et al. 2012)
Low-power (Qureshi et al. 2009)

500

1000

1500

2000

2500

Number of slots (each 5 min)

(d)

Figure 1: (a) Geo-distributed data center infrastructure; (b) Electricity market prices at zone CEN-
TRAL New York; (c) Running average electricity cost; (d) Running average unserved jobs.
6 Conclusion
This paper studies OCO with stochastic constraints  where the objective function varies arbitrarily but
the constraint functions are i.i.d. over time. A novel learning algorithm is developed that guarantees
O(pT ) expected regret and constraint violations and O(pT log(T )) high probability regret and
constraint violations.

9

References
[1] New York ISO open access pricing data. http://www.nyiso.com/.
[2] Peter L Bartlett  Varsha Dani  Thomas Hayes  Sham Kakade  Alexander Rakhlin  and Ambuj
Tewari. High-probability regret bounds for bandit online linear optimization. In Proceedings of
Conference on Learning Theory (COLT)  2008.

[3] Nicolò Cesa-Bianchi  Philip M Long  and Manfred K Warmuth. Worst-case quadratic loss
bounds for prediction using linear functions and gradient descent. IEEE Transactions on Neural
Networks  7(3):604–619  1996.

[4] Nicolò Cesa-Bianchi and Gábor Lugosi. Prediction  Learning  and Games. Cambridge

University Press  2006.

[5] Andrew Cotter  Maya Gupta  and Jan Pfeifer. A light touch for heavily constrained sgd. In

Proceedings of Conference on Learning Theory (COLT)  2015.
[6] Joseph L Doob. Stochastic processes. Wiley New York  1953.
[7] Rick Durrett. Probability: Theory and Examples. Cambridge University Press  2010.
[8] Anshul Gandhi  Mor Harchol-Balter  and Michael A Kozuch. Are sleep states effective in data

centers? In International Green Computing Conference (IGCC)  2012.

[9] Geoffrey J Gordon. Regret bounds for prediction problems. In Proceeding of Conference on

Learning Theory (COLT)  1999.

[10] Bruce Hajek. Hitting-time and occupation-time bounds implied by drift analysis with applica-

tions. Advances in Applied Probability  14(3):502–525  1982.

[11] Elad Hazan. Introduction to online convex optimization. Foundations and Trends in Optimiza-

tion  2(3–4):157–325  2016.

[12] Elad Hazan  Amit Agarwal  and Satyen Kale. Logarithmic regret algorithms for online convex

optimization. Machine Learning  69:169–192  2007.

[13] Rodolphe Jenatton  Jim Huang  and Cédric Archambeau. Adaptive algorithms for online
convex optimization with long-term constraints. In Proceedings of International Conference on
Machine Learning (ICML)  2016.

[14] Jyrki Kivinen and Manfred K Warmuth. Exponentiated gradient versus gradient descent for

linear predictors. Information and Computation  132(1):1–63  1997.

[15] Guanghui Lan and Zhiqiang Zhou. Algorithms for stochastic optimization with expectation

constraints. arXiv:1604.03887  2016.

[16] Mehrdad Mahdavi  Rong Jin  and Tianbao Yang. Trading regret for efﬁciency: online convex
optimization with long term constraints. Journal of Machine Learning Research  13(1):2503–
2528  2012.

[17] Mehrdad Mahdavi  Tianbao Yang  and Rong Jin. Stochastic convex optimization with multiple

objectives. In Advances in Neural Information Processing Systems (NIPS)  2013.

[18] Shie Mannor  John N Tsitsiklis  and Jia Yuan Yu. Online learning with sample path constraints.

Journal of Machine Learning Research  10:569–590  March 2009.

[19] Angelia Nedi´c and Asuman Ozdaglar. Subgradient methods for saddle-point problems. Journal

of Optimization Theory and Applications  142(1):205–228  2009.

[20] Michael J. Neely. Energy-aware wireless scheduling with near optimal backlog and convergence

time tradeoffs. IEEE/ACM Transactions on Networking  24(4):2223–2236  2016.

[21] Yurii Nesterov. Introductory Lectures on Convex Optimization: A Basic Course. Springer

Science & Business Media  2004.

[22] Asfandyar Qureshi  Rick Weber  Hari Balakrishnan  John Guttag  and Bruce Maggs. Cutting

the electric bill for internet-scale systems. In ACM SIGCOMM  2009.

[23] Shai Shalev-Shwartz. Online learning and online convex optimization. Foundations and Trends

in Machine Learning  4(2):107–194  2011.

[24] Terence Tao and Van Vu. Random matrices: universality of local spectral statistics of non-

hermitian matrices. The Annals of Probability  43(2):782–874  2015.

[25] David Tse and Pramod Viswanath. Fundamentals of Wireless Communication. Cambridge

University Press  2005.

[26] Van Vu. Concentration of non-lipschitz functions and applications. Random Structures &

Algorithms  20(3):262–316  2002.

10

[27] Hao Yu and Michael J. Neely. A low complexity algorithm with O(pT ) regret and ﬁnite con-
straint violations for online convex optimization with long term constraints. arXiv:1604.02218 
2016.

[28] Hao Yu and Michael J. Neely. A simple parallel algorithm with an O(1/t) convergence rate for

general convex programs. SIAM Journal on Optimization  27(2):759–783  2017.

[29] Martin Zinkevich. Online convex programming and generalized inﬁnitesimal gradient ascent.

In Proceedings of International Conference on Machine Learning (ICML)  2003.

11

,Hao Yu
Michael Neely
Xiaohan Wei