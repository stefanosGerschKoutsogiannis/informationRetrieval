2019,Learning low-dimensional state embeddings and metastable clusters from time series data,This paper studies how to find compact state embeddings from high-dimensional Markov state trajectories  where the transition kernel has a small intrinsic rank. In the spirit of diffusion map  we propose an efficient method for learning a low-dimensional state embedding and capturing the process's dynamics. This idea also leads to a kernel reshaping method for more accurate nonparametric estimation of the transition function. State embedding can be used to cluster states into metastable sets  thereby identifying the slow dynamics. Sharp statistical error bounds and misclassification rate are proved. Experiment on a simulated dynamical system shows that the state clustering method indeed reveals metastable structures. We also experiment with time series generated by layers of a Deep-Q-Network when playing an Atari game. The embedding method identifies game states to be similar if they share similar future events  even though their raw data are far different.,Learning low-dimensional state embeddings and

metastable clusters from time series data

Yifan Sun

Carnegie Mellon University
yifans@andrew.cmu.edu

Hao Gong

Princeton University

hgong@princeton.edu

Yaqi Duan

Princeton University

yaqid@princeton.edu

Mengdi Wang

Princeton University

mengdiw@princeton.edu

Abstract

This paper studies how to ﬁnd compact state embeddings from high-dimensional
Markov state trajectories  where the transition kernel has a small intrinsic rank.
In the spirit of diffusion map  we propose an efﬁcient method for learning a low-
dimensional state embedding and capturing the process’s dynamics. This idea also
leads to a kernel reshaping method for more accurate nonparametric estimation
of the transition function. State embedding can be used to cluster states into
metastable sets  thereby identifying the slow dynamics. Sharp statistical error
bounds and misclassiﬁcation rate are proved. Experiment on a simulated dynamical
system shows that the state clustering method indeed reveals metastable structures.
We also experiment with time series generated by layers of a Deep-Q-Network
when playing an Atari game. The embedding method identiﬁes game states to
be similar if they share similar future events  even though their raw data are far
different.

1

Introduction

High-dimensional time series is ubiquitous in scientiﬁc studies and machine learning. Finding
compact representation from state-transition trajectories is often a prerequisite for uncovering the
underlying physics and making accurate predictions. Suppose that we are given a Markov process
{Xt} taking values in Ω ⊂ Rd. Let p(y|x) be the one-step transition density function (transition
kernel) of the Markov process. In practice  state-transition trajectories may appear high-dimensional 
but they are often generated by a system with fewer internal parameters and small intrinsic dimension.
In this paper  we focus on problems where the transition kernel p(y|x) admits a low-rank decomposi-
tion structure. Low-rank or nearly low-rank nature of the transition kernel has been widely identiﬁed
in scientiﬁc and engineering applications  e.g. molecular dynamics [RZMC11  SS13]  periodized
diffusion process [G˚ar54]  trafﬁc transition data [ZW18  DKW19]  Markov decision process and
reinforcement learning [KAL16]. For reversible dynamical systems  leading eigenfunctions of p are
related to metastable sets and slow dynamics [SS13]. Low-rank latent structures also helps state
representation learning and dimension reduction in robotics and control [BSB+15].
Our goal is to estimate the transition kernel p(·|·) from ﬁnite time series and ﬁnd state representation
in lower dimensions. For nonparametric estimation of probability distributions  one natural approach
is the kernel mean embedding (KME). Our approach starts with a kernel space  but we “open up” the
kernel function into a set of features. We will leverage the low-rankness of p in the spirit of diffusion
map for dimension reduction. By using samples of transition pairs {(Xt  Xt+1)}  we can estimate the
“projection” of p onto the product feature space and ﬁnds its leading singular functions. This allows

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

us to learn state embeddings that preserve information about the transition dynamics. Our approach
can be thought of as a generalization of diffusion map to nonreversible processes and Hilbert space.
We show that  when the features can fully express the true p  the estimated state embeddings preserve
the diffusion distances and can be further used to cluster states that share similar future paths  thereby
ﬁnding metastable sets and long-term dynamics of the process.
The contributions of this paper are:

1.KME Reshaping for more accurate estimation of p. The method of KME reshaping is proposed to
estimate p from dependent time series data. The method takes advantage of the low-rank structure
of p and can be implemented efﬁciently in compact space. Theorem 1 gives a ﬁnite-sample error
bound and shows that KME reshaping achieves signiﬁcantly smaller error than plain KME.

2.State embedding learning with statistical distortion guarantee. In light of the diffusion map  we
study state embedding by estimating the leading spectrum of the transition kernel. Theorems 2 3
show that the state embedding largely preserves the diffusion distance.

3.State clustering with misclassiﬁcation error bound. Based on the state embeddings  we can further
aggregate states to preserve the transition dynamics and ﬁnd metastable sets. Theorem 4 establishes
the statistical misclassiﬁcation guarantee for continuous-state Markov processes.

4.Experiments with diffusion process and Atari game. The ﬁrst experiment studies a simulated
stochastic diffusion process  where the results validate the theoretical bounds and reveals metastable
structures of the process. The second experiment studies the time series generated by a deep Q-
network (DQN) trained on an Atari game. The raw time series is read from the last hidden layer as
the DQN is run. The state embedding results demonstrate distinctive and interpretable clusters of
game states. Remarkably  we observe that game states that are close in the embedding space share
similar future moves  even if their raw data are far different.

To our best knowledge  our theoretical results on estimating p and state embedding are the ﬁrst
of their kind for continuous-state nonreversible Markov time series. Our methods and analyses
leverage spectral properties of the transition kernel. We also provide the ﬁrst statistical guarantee for
partitioning the continuous state space according to diffusion distance.

Related Work Spectral dimension reduction methods ﬁnd wide use in data analysis and scientiﬁc
computing. Diffusion map is a prominent dimension reduction tool which applies to data analysis 
graph partitioning and dynamical systems [LL06] [CKL+08]. For molecular dynamics  [SNL+11]
showed that leading spectrum of transition operator contains information on slow dynamics of the
system  and it can be used to identify coresets upon which a coarse-grained Markov state model could
be built. [KSM18] extended the transfer operator theory to reproducing kernel spaces and pointed
out the these operators are related to conditional mean embeddings of the transition distributions. See
[KKS16  KNK+18] for surveys on data-driven dimension reduction methods for dynamical systems.
They did not study statistical properties of these methods which motivated our research.
Nonparametric estimation of the Markov transition operator has been thoroughly studied  see
[Yak79  Lac07  Sar14]. Among nonparametric methods  kernel mean embeddings are prominent
for representing probability distributions [BTA04  SGSS07]. [SHSF09] extended kernel embedding
methods to conditional distributions. [GLB+12] proposed to use conditional mean embedding to
model Markov decision processes. See [MFSS17] for a survey on kernel mean embedding. None of
these works considered low-rank estimation of Markov transition kernel  to our best knowledge.
Estimation of low-rank transition kernel was ﬁrst considered by [ZW18] in the special case of ﬁnite-
state Markov chains. [ZW18] used a singular thresholding method to estimate the transition matrix
and proves near-optimal error upper and lower bounds. They also proved misclassiﬁcation rate for
state clustering when the chain is lumpable or aggragable. [LWZ18] studied a rank-constrained
maximum likelihood estimator of the transition matrix. [DKW19] proposed a novel approach for
ﬁnding state aggregation by spectral decomposing transition matrix and transforming singular vectors.
For continuous-state reversible Markov chains  [LP18] studied the nonparametric estimation of
transition kernel via Galerkin projection with spectral thresholding. They proved recovery error
bounds when eigenvalues decay exponentially.
Notations For a function f : Ω → R  we deﬁne (cid:107)f(cid:107)2

respectively. For g(· ·) → R  we deﬁne (cid:107)g(· ·)(cid:107)L2(π)×L2 := ((cid:82) π(x)g(x  y)2dydx)1/2. We use (cid:107) · (cid:107) to

L2(π) :=(cid:82)

Ω f (x)2dx and (cid:107)f(cid:107)2

Ω π(x)f (x)2dx 

L2 :=(cid:82)

2

tmix = min(cid:8)t | TV(P t(· | x)  π(·)) ≤ 1

4  ∀x ∈ Ω(cid:9)   where T V is the total variation divergence between two

denote the Euclidean norm of a vector. We let tmix denote the mixing time of the Markov process [LP17]  i.e 

distributions. Let π(x) be the density function of invariant measure of the Markov chain. Let p(x  y) be the den-
sity of the invariant measure of the bivariate chain {(Xt  Xt+1)}∞
t=0  i.e. p(Xt  Xt+1) = π(Xt)p(Xt+1|Xt).
We use P(·) to denote probability of an event.

2 KME Reshaping for Estimating p
In this section we study the estimation of of transition function p from a ﬁnite trajectory {Xt}n
t=1 ⊂
Rd. We make following low-rank assumption regarding the transition kernel p  which is key to more
accurate estimation.
k=1 on Ω such that p(y|x) :=
Assumption 1. There exist real-valued functions {uk}r

k=1  {vk}r

(cid:80)r

k=1 σkuk(x)vk(y)  where r is the rank.

(cid:90)
i)}n
(cid:113) E(X Y )∼p[K(X X) ˜K(Y Y )]

Due to the asymmetry of p(· ·) and lack of reversibility  we use two reproducing kernel Hilbert
spaces H and ˜H to embed the left and right side of p. Let K and ˜K be the kernel functions for H and
˜H respectively. The Kernel Mean Embedding (KME) µp(x  y) of the joint distribution p(x  y) into
the product space H × ˜H is deﬁned by

n

1
n

K(x  u) ˜K(y  v)p(u  v)dudv.

µp(x  y) :=
Given sample transition pairs {(Xi  X(cid:48)

i=1  the natural empirical KME estimator is ˜µp(x  y) =
i  y). If data pairs are independent  one can show that the embedding error
(Lemma 1 in Appendix). Next we

(cid:80)n
i=1 K(Xi  x) ˜K(X(cid:48)
(cid:107)µp − ˜µp(cid:107)H× ˜H is approximately
propose a sharper KME estimator.
(cid:80)
j∈J Φj(x)Φj(y)  and ˜K(x  y) =(cid:80)
Suppose that the kernel functions K and ˜K are continuous and symmetric semi-deﬁnite. Let
{Φj(x)}j∈J and { ˜Φj(x)}j∈J be the real-valued feature functions on Ω such that K(x  y) =
˜Φj(x) ˜Φj(y). In practice  if one is given a shift-invariant
symmetric kernel function  we can generate ﬁnitely many random Fourier features to approximate
the kernel [RR08]. In what follows we assume without loss of generality that J is ﬁnite of size N.
(cid:90)
Let Φ(x) = [Φ1(x)  . . .   ΦN (x)]T ∈ RN . We deﬁne the “projection” of p onto the feature space by
(1)
Assumption 1 suggests that rank(P) ≤ r (Lemma 2 in Appendix). Note that the KME of p(x  y) is
equivalent to µp(x  y) = Φ(x)T P ˜Φ(y) (Lemma 3 in Appendix). The matrix P is of ﬁnite dimensions 
therefore we can estimate it tractably from the trajectory {Xt} by

p(x  y)Φ(x) ˜Φ(y)T dxdy.

P =

j∈J

Φ(Xt) ˜Φ(Xt+1)T .

(2)

n(cid:88)

t=1

ˆP :=

1
n

Since the unknown P is low-rank  we propose to apply singular value truncation to ˆP for obtaining a
better KME estimator. The algorithm is given below:

ˆV be the best rank r approximation of ˆP;

Algorithm 1: Reshaping the Kernel Mean Embedding.
Input:{X1  . . .  Xn}  r;
Get ˆP by (2)  compute its SVD: ˆP = ˆU ˆΣ ˆV;
Let ˜P := ˆU ˆΣ[1...r]
Let ˆµp(x  y) := Φ(x)T ˜P ˜Φ(y);
Output: ˆµp(x  y)
We analyze the convergence rate of ˆµp to µp. Let Kmax := max{supx∈Ω K(x  x)  supx∈Ω
We deﬁne following kernel covariance matrices:
V1 = E(X Y )∼p[Φ(X)Φ(X)T ˜K(Y  Y )] 

Let ¯λ := max{λmax(V1)  λmax(V2)}. We show the following ﬁnite-sample error bound.

V2 = E(X Y )∼p[K(X  X) ˜Φ(Y ) ˜Φ(Y )T ].

˜K(x  x)}.

3

(cid:18)(cid:114)

(cid:19)

r

√

tmix

¯λ log(2tmixN/δ)

Theorem 1 (KME Reshaping). Let Assumption 1 hold. For any δ ∈ (0  1)  we have
(cid:107)µp − ˆµp(cid:107)H× ˜H = (cid:107)P − ˜P(cid:107)F ≤ C
with probability at least 1 − δ  where C is a universal constant.
The KME reshaping method and Theorem 1 enjoys the following advantages:
1.Improved accuracy compared to plain KME. The plain KME ˜µp’s estimation error is ap-
(Appendix Lemma 1). Note that Tr(V1) = Tr(V2) =
proximately
E(X Y )∼p[K(X  X) ˜K(Y  Y )]. When r (cid:28) N  we typically have r¯λ (cid:28) Tr(V1) = Tr(V2)  there-
fore the reshaped KME has a signiﬁcantly smaller estimation error.

(cid:113) E(X Y )∼p[K(X X) ˜K(Y Y )]

tmixKmax log(2tmixN/δ)

3n

+

n

n

2.Ability to handle dependent data. Algorithm 1 applies to time series consisting of highly
dependent data. The proof of Theorem 1 handles dependency by constructing a special matrix
martingale and using the mixing properties of the Markov process to analyze its concentration.

3.Tractable implementation. Kernel-based methods usually require memorizing all the data and
may be intractable in practice. Our approach is based on a ﬁnite number of features and only
needs to low-dimensional computation. As pointed out by [RR08]  one can approximate any shift-
invariant kernel function using N features where N is linear with respect to the input dimension d.
Therefore Algorithm 1 can be approximately implemented in O(nd2) time and O(d2) space.

3 Embedding States into Euclidean Space

In this section we want to learn low-dimensional representations of the state space Ω to capture the
transition dynamics. We need following extra assumption that p can be fully represented in the kernel
space.
Assumption 2. The transition kernel belongs to the product Hilbert space  i.e.  p(· | ·) ∈ H × ˜H.
For two arbitrary states x  y ∈ Ω  we consider their distance given by

(cid:18)(cid:90) (cid:0)p(z|x) − p(z|y)(cid:1)2

(cid:19)1/2

dz

.

(3)

dist(x  y) := (cid:107)p(·|x) − p(·|y)(cid:107)L2 =

Eq. (3) is known as the diffusion distance [NLCK06]. It measures the similarity between future
paths of two states. We are motivated by the diffusion map approach for dimension reduction
[LL06  CKL+08  KSM18]. Diffusion map refers to the leading eigenfunctions of the transfer
operator of a reversible dynamical system. We will generalize it to nonreversible processes and
feature spaces.
For simplicity of presentation  we assume without loss of generality that {Φi}N
i=1 are
L2(π) and L2 orthogonal bases of H and ˜H respectively  with squared norms ρ1 ≥ ··· ≥ ρN and
˜ρ1 ≥ ··· ≥ ˜ρN respectively. Any given features can be orthogonalized to satisfy this condition. In
particular  let the matrix C := diag[ρ1 ···   ρN ]  ˜C := diag[˜ρ1 ···   ˜ρN ]  it is easy to verify that
p(y|x) = Φ(x)T C−1P ˜C
[1···r]V(ρ) be its SVD. We deﬁne the
state embedding as

−1 ˜Φ(y). Let C−1/2P ˜C

i=1 and { ˜Φi}N

= U(ρ)Σ(ρ)

−1/2

(cid:18)

Ψ(x) :=

Φ(x)T C−1/2U(ρ)Σ(ρ)

[1···r]

(cid:19)T

.

It is straightforward to verify that dist(x  z) = (cid:107)Ψ(x) − Ψ(z)(cid:107). We propose to estimate Ψ in
Algorithm 2.

Algorithm 2: Learning State Embedding
Input:{X1  . . .   Xn}  r;
Get ˆP from (2)  compute SVD ˆU(ρ) ˆΣ(ρ) ˆV(ρ)

= C−1/2 ˆP ˜C

Compute state embedding using ﬁrst r singular pairs ˆΨ(x) =
Output: x (cid:55)→ ˆΨ(x)

(cid:18)
−1/2;

Φ(x)T C−1/2 ˆU(ρ) ˆΣ(ρ)

[1···r]

(cid:19)T

;

4

(cid:19)

Let (cid:100)dist(x  z) := (cid:107) ˆΨ(x) − ˆΨ(z)(cid:107). We show that the estimated state embeddings preserve the
Lmax := supx∈Ω Φ(x)T C−1Φ(x) and let κ be the condition number of(cid:112)π(x)p(y|x). For any
0 < δ < 1 and for all x  z ∈ Ω  |dist(x  z) −(cid:100)dist(x  z)| is upper bounded by:

diffusion distance with an additive distortion.
Theorem 2 (Maximum additive distortion of state embeddings). Let Assumptions 1 2 hold. Let

(cid:115)

(cid:20)√

(cid:21)(cid:18)(cid:114)

C

Lmax
ρN ˜ρN

2κ + 1

tmix

¯λ log(2tmixN/δ)

tmixKmax log(2tmixN/δ)

n

+

3n

with probability at least 1 − δ for some constant C.
Under Assumption 2  we can recover the full transition kernel from data by
−1/2 ˜Φ(y).

ˆp(y|x) = Φ(x)T C−1/2 ˆU(ρ) ˆΣ(ρ)

)T ˜C

[1···r]( ˆV(ρ)

(cid:114) r

(cid:18)(cid:114)

tmix

¯λ log(2tmixN/δ)

Theorem 3 (Recovering the transition density). Let Assumptions 1 2 hold. For any δ ∈ (0  1) 
(cid:107)p(·|·) − ˆp(·|·)(cid:107)L2(π)×L2 ≤ C
with probability at least 1 − δ for some constant C.
Theorems 2 3 provide the ﬁrst statistical guarantee for learning state embeddings and recovering the
transition density for continuous-state low-rank Markov processes. The state embedding learned by
Algorithm 2 can be represented in O(N r) space since Φ is priorly known. When Ω is ﬁnite and the
feature map is identity  Theorem 3 nearly matches the the information-theoretical error lower bound
given by [LWZ18].

tmixKmax log(2tmixN/δ)

ρN ˜ρN

3n

+

n

(cid:19)

4 Clustering States Using Diffusion Distances
We want to ﬁnd a partition of the state space into m disjoint sets Ω1 ··· Ωm. The principle is if
x  y ∈ Ωi for some i  then p(·|x) ≈ p(·|y)  meaning that states within the same set share similar future
paths. This motivates us to study the following optimization problem  which has been considered in
studies for dynamical systems [SS13] 

min

Ω1 ···  Ωm

min

q1∈ ˜H ···  qm∈ ˜H

π(x)(cid:107)p(·|x) − qi(·)(cid:107)2

L2dx 

(4)

(cid:90)

m(cid:88)

i=1

Ωi

1  . . .   Ω∗

We assume without loss of generality that it admits a unique optimal solution  which we denote by
i (·) is a probability distribution and
(Ω∗
k=1 of p(·|·) (Lemma 7 in Appendix). We
can be represented by right singular functions {vk(·)}r
propose the following state clustering method:

m). Under Assumption 2  each q∗

m) and (q∗

1  . . .   q∗

Algorithm 3: Learning metastable state clusters
Data: {X1  . . .   Xn  r  m}
Use Alg. 2 to get state embedding ˆΨ : Ω (cid:55)→ Rr;
Solve k-means problem:

min

Ω1 ···  Ωm

min

s1···  sm∈Rr

Output: ˆΩ∗

1 ··· ˆΩ∗

m

m(cid:88)

(cid:90)

π(x)(cid:107) ˆΨ(x) − si(cid:107)2dx;

i=1

Ωi

The k-means method uses the invariant measure π as a weight function. In practice if π is unknown 
one can pick any reasonable measure and the theoretical bound can be adapted to that measure.
We analyze the performance of the state clustering method on ﬁnite data. Deﬁne the misclassiﬁcation
rate as

M ( ˆΩ∗

1 ···   ˆΩ∗

m) := min

σ

π({x : x ∈ Ω∗
j   i /∈ ˆΩ∗
π(Ω∗
j )

σ(j)})

 

m(cid:88)

j=1

5

where σ is taken over all possible permutations over {1  . . .   m}. The misclassiﬁcation rate is always
between 0 and m. We let ∆2
2 be the minimal value
of (4).
Theorem 4 (Misclassiﬁcation error bound for state clustering). Let Assumptions 1 2 hold. Let κ be

the condition number of(cid:112)π(x)p(y|x). If ∆1 > 4∆2  then for any 0 < δ < 1 and  > 0  by letting

1 := mink minl(cid:54)=k π(Ω∗

L2 and let ∆2

l − q∗
k(cid:107)2

(cid:18) κ2r¯λtmix log(2tmixN/δ)

n = Θ

we have M ( ˆΩ∗

1 ···   ˆΩ∗

m) ≤ 16∆2

2

∆2
1

· max

1

ρN ˜ρN

(∆1 − 4∆2)2  
+  with probability at least 1 − δ.

k)(cid:107)q∗
(cid:26)

(cid:27)(cid:19)

 

1
∆2
1

 

∆2
2
2∆4
1

(cid:82)

The full proof is given in Appendix. The condition ∆1 > 4∆2 is a separability condition needed for
(cid:80)m
ﬁnding the correct clusters with high probability  and 16∆2
is non-vanishing misclassiﬁcation error. In
∆2
1
the case of reversible ﬁnite-state Markov process  the clustering problem is equivalent to ﬁnding the
k=1 p(Ωk|Ωk)  where p(Ωj|Ωi) :=
optimal metastable m-full partition given by argmaxΩ1 ···  Ωm
m) gives
π(Ωi)
metastable sets that can be used to construct a reduced-order Markov state model [SS13]. In the more
general case of nonreversible Markov chains  the proposed method will cluster states together if they
share similar future paths. It provides an unsupervised learning method for state aggregation  which is
a widely used heuristic for dimension reduction of control and reinforcement learning [BT96  SJJ95].

π(x)p(y|x)dydx [ELVE08  SS13]. The optimal partition (Ω∗

1 ···   Ω∗

x∈Ωi y∈Ωj

1

2

5 Experiments

2

1

− (cid:107)x−y(cid:107)2

(2πσ2)d/2 e

5.1 Stochastic Diffusion Processes
We test the proposed approach on simulated diffusion processes of the form dXt = −∇V (Xt)dt +
√
2dBt  Xt ∈ Rd  where V (·) is a potential function and {Bt}t≥0 is the standard Brownian motion.
For any interval τ > 0  the discrete-time trajectory {Xkτ}∞
k=1 is a Markov process. We apply the
Euler method to generate sample path {Xkτ}n
k=1 according to the stochastic differential equation.
We use the Gaussian kernels K(x  y) = ˜K(x  y) =
2σ2 where σ > 0  and construct
RKHS H = ˜H from L2(π). To get the features Φ  we generate 2000 random Fourier features
i=1 hi(x)hi(y) ([RR08])  and then orthogonalize h

h = [h1  h2  . . .   hN ](cid:62) such that K(x  y) ≈(cid:80)N

to get Φ.
Comparison between reshaped and plain KME
We apply Algorithm 1 to ﬁnd the reshaped KME ˆµp and
compare its error with the plain KME ˜µp given by (2). The
experiment is performed on a four-well diffusion on R 
and we take rank r = 4. By orthogonalizing N = 2000
random Fourier features  we obtain J = 82 basis functions.
Figure 5.1 shows that the reshaped KME consistently out-
performs plain KME with varying sample sizes.
State clustering to reveal metastable structures
We apply the state clustering method to analyze metastable
structures of a diffusion process whose potential function
V (x) is given by Figure 5.1 (a). We generate trajectories
of length n = 106 and take the time interval to be τ =
0.1  1  5 and 10. We conduct the state embedding and
clustering procedures with rank r = 4. Figure 5.1 (c)
shows the clustering results for τ = 1 with a varying number of clusters. The partition results reliably
reveal metastable sets  which are also known as invariance sets that characterize slow dynamics of
this process. Figure 5.1 (d) shows the four-cluster results with varying values of τ  where the contours
are based on diffusion distances to the centroid in each cluster. One can see that the diffusion distance
contours are dense when τ takes small values. This is because  when τ is small  the state embedding
method largely captures fast local dynamics. By taking τ to be larger values  the state embedding

Figure 1: Reshaped KME versus plain
KME. The error curve approximately satis-
ﬁes a convergence rate of n−1/2.

6

10000800000.10.150.20.25(a)

(b)

(c)

V (x)

# Cluster = 4

# Cluster = 5

# Cluster = 9

# Cluster = 15

(d)

π(x)

τ = 0.1

τ = 1

τ = 5

τ = 10

Figure 2: Metastable state clusters learned from a stochastic diffusion process. (a) Potential function V (x)
of the diffusion process. (b) Invariant measure π(x). (c) State clusters based on a state embedding ˆΨ : x (cid:55)→ R4.
(d) Diffusion distance to the nearest cluster centroid (red dot) illustrated as contour plots.

method begins to capture slower dynamics  which corresponds to low-frequency transitions among
the leading metastable sets.

5.2 DQN for Demon Attack

We test the state embedding method on the game trajectories of Demon Attack  an Atari 2600 game.
In this game  demons appear in waves  move randomly and attack from above  where the player
moves to dodge the bullets and shoots with a laser cannon. We train a Deep Q-Network using
the architecture given by [MKS+15]. The DQN takes recent image frames of the game as input 
processes them through three convolutional layers and two fully connected layers  and outputs a
single value for each action  among which the action with the maximal value is chosen. Please refer
to Appendix for more details on DQN training. In our experiment  we take the times series generated
by the last hidden layer of a trained DQN when playing the game as our raw data. The raw data is a
time series of length 47936 and dimension 512  comprising 130 game trajectories. We apply the state
embedding method by approximating the Gaussian kernel with 200 random Fourier features. Then
we obtain low-dimensional embeddings of the game states in R3.
Before embedding vs. after embedding
Figure 3 visualizes the raw states and the state embeddings using t-SNE  a visualization tool to
illustrate multi-dimensional data in two dimensions [VdM08]. In both plots  states that are mapped
to nearby points tend to have similar “values” (expected future returns) as predicted by the DQN  as
illustrated by colors of data points.
Comparing Figure 3(a) and (b)  the raw state data are more scattered  while after embedding they

exhibit clearer structures and fewer outliers. The markers◦  (cid:52)  (cid:5) identify the same pair of game

states before and after embedding. They suggest that the embedding method maps game states that
are far apart from each other in their raw data to closer neighbors. It can be viewed as a form of
compression. The experiment has been repeated multiple times. We consistently observe that state
embedding leads to improved clusters and higher granularity in the t-SNE visualization.
Understanding state embedding from examples

Figure 4 illustrates three examples that were marked by ◦  (cid:52)  (cid:5) in Figure 3. In each example 

we have a pair of game states that were far apart in their raw data but are close to each other after
embedding. Also note the two images are visually not alike  therefore any representation learning
method based on individual images alone will not consider them to be similar. Let us analyze these
three examples:

◦: Both streaming lasers (purple) are about to destroy a demon and generate a reward; Both cannons

are moving towards the left end.

(cid:52): In both images  two new demons are emerging on top of the cannon to join the battle and there is
(cid:5): Both cannons are waiting for more targets to appear  and they are both moving towards the center

an even closer enemy  leading to future dangers and potential rewards.

from opposite sides.

7

These examples suggest that state embedding is able to identify states as similar if they share similar
near-future events and values  even though they are visually dissimilar and distant from each other in
their raw data.

(a) Before Embedding

(b) After Embedding

Figure 3: Visualization of game states before and after embedding in t-SNE plots. The raw data is a time
series of 512 dimensions  which generated by the last hidden layer by the DQN while it is playing Demon
Attack. State embeddings are computed from the raw time series using a Gaussian kernel with 200 random

Fourier features. Game states are colored by the “value” of the state as predicted by the DQN. The markers◦ 
(cid:52) (cid:5) identify the same pair of game states before and after embedding. Comparing (a) and (b)  state embedding
◦: V = 6.27 ◦: V = 6.14 (cid:52): V = 6.17 (cid:52): V = 6.16 (cid:5): V = 4.44 (cid:5): V = 4.35

improves the granularity of clusters and reveals more structures of the data.

two states share similar “V” values as predicted by the DQN  but they were not close in the raw data and are

Figure 4: Pairs of game states that are close after embedding (◦  (cid:52) (cid:5) in Figure 3). Within each pair  the
visually dissimilar. ◦: Both streaming lasers (purple) are about to destroy a demon and generate a reward;
Both cannons are moving towards the left end. (cid:52): In both images  two new demons are emerging on top of the
cannon to join the battle and there is an even closer enemy  leading to future dangers and potential rewards (cid:5):

Both cannons are waiting for more targets to appear  and they are both moving towards the center from opposite
sides. The examples above suggest that state embedding is able to identify states as similar if they share similar
near-future paths and values.

Summary and Future Work
The experiments validate our theory and lead to interesting discoveries: estimated state embedding
captures what would happen in the future conditioned on the current state. Thus the state embedding
can be useful to decision makers in terms of gaining insights into the underlying logic of the game 
thereby helping them to make better predictions and decisions.
Our methods are inspired by dimension reduction methods from scientiﬁc computing and they further
leverage the low-rankness of the transition kernel to reduce estimation error and ﬁnd compact state
embeddings. Our theorems provide the basic statistical theory on state embedding/clustering from
ﬁnite-length dependent time series. They are the ﬁrst theoretical results known for continuous-state
Markov process. We hope our results would motivate more work on this topic and lead to broader
applications in scientiﬁc data analysis and machine learning. A natural question to ask next is how
can one use state embedding to make control and reinforcement learning more efﬁcient. This is a
direction for future research.

8

References
[BSB+15] Wendelin B¨ohmer  Jost Tobias Springenberg  Joschka Boedecker  Martin Riedmiller  and Klaus
Obermayer. Autonomous learning of state representations for control. K¨unstliche Intelligez 
29(4):1–10  2015.

[BT96] Dimitri P Bertsekas and John N Tsitsiklis. Neuro-dynamic programming  volume 5. Athena

Scientiﬁc Belmont  MA  1996.

[BTA04] Alain A Berlinet and Christine Thomas-Agnan. Reproducing Kernel Hilbert Spaces in Probability

and Statistics. Kluwer Academic Publishers  2004.

[CKL+08] Ronald R. Coifman  Ioannis G. Kevrekidis  St´ephane Lafon  Mauro Maggioni  and Boaz Nadler.
Diffusion maps  reduction coordinates  and low dimensional representation of stochastic systems.
SIAM Journal on Multiscale Modeling and Simulation  7(2):852–864  2008.

[DKW19] Yaqi Duan  Zheng Tracy Ke  and Mengdi Wang. State aggregation learning from markov transition

data. Conference on Neural Information Processing Systems (NeurIPS)  2019.

[ELVE08] Weinan E  Tiejun Li  and Eric Vanden-Eijnden. Optimal partition and effective dynamics of complex

networks. Proceedings of the National Academy of Sciences  105(23):7907–7912  2008.

[G˚ar54] Lars G˚arding. On the asymptotic distribution of the eigenvalues and eigenfunctions of elliptic

differential operators. Mathematica Scandinavica  pages 237–255  1954.

[GLB+12] Steffen Gr¨unew¨alder  Guy Lever  Luca Baldassarre  Massimilano Pontil  and Arthur Gretton. Mod-
elling transition dynamics in mdps with rkhs embeddings. International Conference on Machine
Learning  2012.

[KAL16] Akshay Krishnamurthy  Alekh Agarwal  and John Langford. Pac reinforcement learning with rich

observations. In Advances in Neural Information Processing Systems  pages 1840–1848  2016.

[KKS16] Stefan Klus  P´eter Koltai  and Christof Sch¨utte. On the numerical approximation of the perronfrobe-

nius and koopman operator. Journal of Computational Dynamics  3(1):51–79  2016.

[KNK+18] Stefan Klus  Feliks N¨uske  P´eter Koltai  Hao Wu  Ioannis Kevrekidis  Christof Sch¨utte  and Frank
No´e. Data-driven model reduction and transfer operator approximation. Journal of Nonlinear
Science  28(3):985–1010  2018.

[KSM18] Stefan Klus  Ingmar Schuster  and Krikamol Muandet. Eigendecompositions of transfer operators

in reproducing kernel hilbert spaces. arXiv preprint arXiv:1712.01572  2018.

[Lac07] Claire Lacour. Estimation non paramtrique adaptative pour les chanes de Markov et les chanes de

Markov caches. PhD thesis  Ph.D. Thesis  UNIVERSITE PARIS DESCARTES  2007.

[LL06] St´ephane Lafon and Ann Lee. Diffusion maps and coarse-graining: A uni

ed framework for dimensionality reduction  graph partitioning  and data set parameterization. IEEE
Trans. on Pattern Analysis and Machine Intelligence  29(9):1393–1403  2006.

[LP17] David A Levin and Yuval Peres. Markov chains and mixing times  volume 107. American

Mathematical Soc.  2017.

[LP18] Matthias L¨ofﬂer and Antoine Picard. Spectral thresholding for the estimation of markov chain

transition operators. arXiv preprint arXiv:1808.08153  2018.

[LWZ18] Xudong Li  Mengdi Wang  and Anru Zhang. Estimation of markov chain via rank-constrained

likelihood. International Conference on Machine Learning  2018.

[MFSS17] Kirkamol Muandet  Kenji Fukumizu  Bharath Sriperumbudur  and Bernhard Schlkopf. Kernel mean
embedding of distributions: A review and beyond. Foundations and Trends in Machine Learning 
10(1-2):1–141  2017.

[MKS+15] Volodymyr Mnih  Koray Kavukcuoglu  David Silver  Andrei A. Rusu  Joel Veness  Marc G.
Bellemare  Alex Graves  Martin Riedmiller  Andreas K. Fidjeland  Georg Ostrovski  Stig Petersen 
Charles Beattie  Amir Sadik  Ioannis Antonoglou  Helen King  Dharshan Kumaran  Daan Wierstra 
Shane Legg  and Demis Hassabis. Human-level control through deep reinforcement learning.
Nature  518:529–533  2015.

9

[NLCK06] Boaz Nadler  St´ephane Lafon  Ronald R. Coifman  and Ioannis G. Kevrekidis. Diffusion maps  spec-
tral clustering and eigenfunctions of fokker-planck operators. In Advances in neural information
processing systems  pages 955–962  2006.

[RR08] Ali Rahimi and Benjamin Recht. Random features for large-scale kernel machines. In Advances in

neural information processing systems  pages 1177–1184  2008.

[RZMC11] Mary A Rohrdanz  Wenwei Zheng  Mauro Maggioni  and Cecilia Clementi. Determination of reac-
tion coordinates via locally scaled diffusion map. The Journal of chemical physics  134(12):03B624 
2011.

[Sar14] Mathieu Sart. Estimation of the transition density of a markov chain.

Probabilit´es et statistiques  volume 50  pages 1028–1068  2014.

In Annales de l’IHP

[SGSS07] Alex Smola  Arthur Gretton  Le Song  and Sch¨olkopf. A hilbert space embedding for distributions.

In International Conference on Algorithmic Learning Theory  2007.

[SHSF09] Le Song  Jonathan Huang  Alex Smola  and Kenji Fukumizu. Hilbert space embeddings of
International Conference on

conditional distributions with applications to dynamical systems.
Machine Learning  2009.

[SJJ95] Satinder P Singh  Tommi Jaakkola  and Michael I Jordan. Reinforcement learning with soft state

aggregation. In Advances in neural information processing systems  pages 361–368  1995.

[SNL+11] Christof Sch¨utte  Frank Noe  Jianfeng Lu  Macro Sarich  and Eric Vanden-Eijnden. Markov state

models based on milestoning. The Journal of Chemical Physics  134(20):204105  2011.

[SS13] Christof Sch¨utte and Marco Sarich. Metastability and Markov State Models in Molecular
Dynamics: Modelling  Analysis  Algorithm Approach  volume 24. American Mathematical Soc. 
2013.

[VdM08] G. Van der Maaten  Hinton. Visualizing high-dimensional data using t-sne. Journal of Machine

Learning Research  9(Nov):2579–2605  2008.

[Yak79] Sidney Yakowitz. Nonparametric estimation of markov transition func- tions. The Annals of

Statistics  7(3):671–679  1979.

[ZW18] Anru Zhang and Mengdi Wang. Spectral state compression of markov processes. arXiv preprint

arXiv:1802.02920  2018.

10

,Jianshu Chen
Lin Xiao
Ji He
Lihong Li
Li Deng
Yifan Sun
Yaqi Duan
Hao Gong
Mengdi Wang