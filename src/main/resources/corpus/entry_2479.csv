2012,Homeostatic plasticity in Bayesian spiking networks as Expectation Maximization with posterior constraints,Recent spiking network models of Bayesian inference and unsupervised learning frequently assume either inputs to arrive in a special format or employ complex computations in neuronal activation functions and synaptic plasticity rules. Here we show in a rigorous mathematical treatment how homeostatic processes  which have previously received little attention in this context  can overcome common theoretical limitations and facilitate the neural implementation and performance of existing models. In particular  we show that homeostatic plasticity can be understood as the enforcement of a 'balancing' posterior constraint during probabilistic inference and learning with Expectation Maximization. We link homeostatic dynamics to the theory of variational inference  and show that nontrivial terms  which typically appear during probabilistic inference in a large class of models  drop out. We demonstrate the feasibility of our approach in a spiking Winner-Take-All architecture of Bayesian inference and learning. Finally  we sketch how the mathematical framework can be extended to richer recurrent network architectures. Altogether  our theory provides a novel perspective on the interplay of homeostatic processes and synaptic plasticity in cortical microcircuits  and points to an essential role of homeostasis during inference and learning in spiking networks.,Homeostatic plasticity in Bayesian spiking networks as
Expectation Maximization with posterior constraints

Institute for Theoretical Computer Science  Graz University of Technology

Stefan Habenschuss∗  Johannes Bill∗  Bernhard Nessler
{habenschuss bill nessler}@igi.tugraz.at

Abstract

Recent spiking network models of Bayesian inference and unsupervised learning
frequently assume either inputs to arrive in a special format or employ complex
computations in neuronal activation functions and synaptic plasticity rules. Here
we show in a rigorous mathematical treatment how homeostatic processes  which
have previously received little attention in this context  can overcome common
theoretical limitations and facilitate the neural implementation and performance of
existing models. In particular  we show that homeostatic plasticity can be under-
stood as the enforcement of a ’balancing’ posterior constraint during probabilis-
tic inference and learning with Expectation Maximization. We link homeostatic
dynamics to the theory of variational inference  and show that nontrivial terms 
which typically appear during probabilistic inference in a large class of models 
drop out. We demonstrate the feasibility of our approach in a spiking Winner-
Take-All architecture of Bayesian inference and learning. Finally  we sketch how
the mathematical framework can be extended to richer recurrent network archi-
tectures. Altogether  our theory provides a novel perspective on the interplay of
homeostatic processes and synaptic plasticity in cortical microcircuits  and points
to an essential role of homeostasis during inference and learning in spiking net-
works.

1

Introduction

Experimental ﬁndings from neuro- and cognitive sciences have led to the hypothesis that humans
create and maintain an internal model of their environment in neuronal circuitry of the brain during
learning and development [1  2  3  4]  and employ this model for Bayesian inference in everyday
cognition [5  6]. Yet  how these computations are carried out in the brain remains largely unknown.
A number of innovative models has been proposed recently which demonstrate that in principle 
spiking networks can carry out quite complex probabilistic inference tasks [7  8  9  10]  and even
learn to adapt to their inputs near optimally through various forms of plasticity [11  12  13  14  15].
Still  in network models for concurrent online inference and learning  most approaches introduce
distinct assumptions: Both [12] in a spiking Winner-take-all (WTA) network  and [15] in a rate based
WTA network  identiﬁed the limitation that inputs must be normalized before being presented to the
network  in order to circumvent an otherwise nontrivial (and arguably non-local) dependency of the
intrinsic excitability on all afferent synapses of a neuron. Nessler et al. [12] relied on population
coded input spike trains; Keck et al. [15] proposed feed-forward inhibition as a possible neural
mechanism to achieve this normalization. A theoretically related issue has been encountered by
Deneve [7  11]  in which inference and learning is realized in a two-state Hidden Markov Model by
a single spiking neuron. Although synaptic learning rules are found to be locally computable  the
learning update for intrinsic excitabilities remains intricate. In a different approach  Brea et al. [13]
have recently proposed a promising model for Bayes optimal sequence learning in spiking networks

∗These authors contributed equally to this work.

1

in which a global reward signal  which is computed from the network state and synaptic weights 
modulates otherwise purely local learning rules. Also the recent innovative model for variational
learning in recurrent spiking networks by Rezende et al. [14] relies on sophisticated updates of
variational parameters that complement otherwise local learning rules.
There exists great interest in developing Bayesian spiking models which require minimal non-
standard neural mechanisms or additional assumptions on the input distribution: such models are
expected to foster the analysis of biological circuits from a Bayesian perspective [16]  and to pro-
vide a versatile computational framework for novel neuromorphic hardware [17]. With these goals
in mind  we introduce here a novel theoretical perspective on homeostatic plasticity in Bayesian
spiking networks that complements previous approaches by constraining statistical properties of the
network response rather than the input distribution. In particular we introduce ’balancing’ posterior
constraints which can be implemented in a purely local manner by the spiking network through a
simple rule that is strongly reminiscent of homeostatic intrinsic plasticity in cortex [18  19]. Im-
portantly  it turns out that the emerging network dynamics eliminate a particular class of nontrivial
computations that frequently arise in Bayesian spiking networks.
First we develop the mathematical framework for Expectation Maximization (EM) with homeostatic
posterior constraints in an instructive Winner-Take-all network model of probabilistic inference and
unsupervised learning. Building upon the theoretical results of [20]  we establish a rigorous link
between homeostatic intrinsic plasticity and variational inference. In a second step  we sketch how
the framework can be extended to recurrent spiking networks; by introducing posterior constraints
on the correlation structure  we recover local plasticity rules for recurrent synaptic weights.

2 Homeostatic plasticity in WTA circuits as EM with posterior constraints

We ﬁrst introduce  as an illustrative and representative example  a generative mixture model
p(z  y|V ) with hidden causes z and binary observed variables y  and a spiking WTA network N
which receives inputs y(t) via synaptic weights V . As shown in [12]  such a network N can
implement probabilistic inference p(z|y  V ) through its spiking dynamics  and maximum likeli-
hood learning through local synaptic learning rules (see Figure 1A). The mixture model comprises
k=1 zk = 1  each specialized on a

K binary and mutually exclusive components zk ∈ {0  1}  PK

different N-dimensional input pattern:

(cid:2)(πki)yi · (1 − πki)1−yi(cid:3)zk

p(y  z|V ) =

KY
⇔ log p(y  z|V ) =X
with X

k=1

e

ˆbkzk
e

NY
 X

i=1

ˆbk = 1 and πki = σ(Vki) and Ak =X

Vkiyi − Ak + ˆbk

zk

k

i

k

i

!

 

log(1 + eVki)  

(1)

(2)

(3)

where σ(x) = (1 + exp(−x))−1 denotes the logistic function  and πki the expected activation of
input i under the mixture component k. For simplicity and notational convenience  we will treat the
prior parameters ˆbk as constants throughout the paper. Probabilistic inference of hidden causes zk
based on an observed input y can be implemented by a spiking WTA network N of K neurons
which ﬁre with the instantaneous spiking probability (for δt → 0) 

∝ p(zk = 1|y  V )  

(4)

p(zk spikes in [t  t + δt]) = δt · rnet ·

with the input potential uk(t) = P

i Vkiyi(t) − Ak + ˆbk. Each WTA neuron k receives spik-
ing inputs yi via synaptic weights Vki and responds with an instantaneous spiking probability
which depends exponentially on its input potential uk in accordance with biological ﬁndings [21].
Stochastic winner-take-all (soft-max) competition between the neurons is modeled via divisive
normalization (4) [22]. The input is deﬁned as yi(t) = 1 if input neuron i emitted a spike within the
last τ milliseconds  and 0 otherwise  corresponding to a rectangular post-synaptic potential (PSP) of
length τ. We deﬁne zk(t) = 1 at spike times t of neuron k and zk(t) = 0 otherwise.

euk(t)P

j euj (t)

2

Figure 1: A. Spiking WTA network model. B. Input templates from MNIST database (digits 0-5)
are presented in random order to the network as spike trains (the input template switches after every
250ms  black/white pixels are translated to high/low ﬁring rates between 20 and 90 Hz). C. Sketch
of intrinsic homeostatic plasticity maintaining a certain target average activation. D. Homeostatic
plasticity induces average ﬁring rates (blue) close to target values (red). E. After a learning period 
each WTA neuron has specialized on a particular input motif. F. WTA output spikes during a test
phase before and after learning. Learning leads to a sparse output code.

In addition to the spiking input  each neuron’s potential uk features an intrinsic excitability −Ak+ˆbk.
Note that  besides the prior constant ˆbk  this excitability depends on the normalizing term Ak  and
hence on all afferent synaptic weights through (3): WTA neurons which encode strong patterns
with high probabilities πki require lower intrinsic excitabilities  while neurons with weak patterns
require larger excitabilities. In the presence of synaptic plasticity  i.e.  time-varying Vki  it is unclear
how biologically realistic neurons could communicate ongoing changes in synaptic weights from
distal synaptic sites to the soma. This critical issue was apparently identiﬁed in [12] and [15]; both
papers circumvent the problem (in similar probabilistic models) by constraining the input y (and
also the synaptic weights in [15]) in order to maintain constant and uniform values Ak across all
WTA neurons.
Here  we propose a different approach to cope with the nontrivial computations Ak during inference
and learning in the network. Instead of assuming that the inputs y meet a normalization constraint 
we constrain the network response during inference  by applying homeostatic dynamics to the intrin-
sic excitabilities. This approach turns out to be beneﬁcial in the presence of time-varying synaptic
weights  i.e.  during ongoing changes of Vki and Ak. The resulting interplay of intrinsic and synaptic
plasticity can be best understood from the standard EM lower bound [23] 

F (V   q(z|y)) = L(V ) − h KL (q(z|y)|| p(z|y  V )ip∗(y)

→ E-step  
→ M-step  

= h log p(y  z|V )ip∗(y)q(z|y) + h H(q(z|y))ip∗(y)

(5)
(6)
where L(V ) = hlog p(y|V )ip∗(y) denotes the log-likelihood of the input under the model  KL (·||·)
the Kullback-Leibler divergence  and H(·) the entropy. The decomposition holds for arbitrary dis-
In hitherto proposed neural implementations of EM [11  12  15  24]  the network
tributions q.
implements the current posterior distribution in the E-step  i.e.  q = p and KL (q || p) = 0.
In
contrast  by applying homeostatic plasticity  the network response will be constrained to implement
a variational posterior from a class of “homeostatic” distributions Q: the long-term average acti-
vation of each WTA neuron zk is constrained to an a priori deﬁned target value. Notably  we will
see that the resulting network response q∗ describes an optimal variational E-Step in the sense that
q∗(z|y) = arg minq∈Q KL (q(z|y)|| p(z|y  V )). Importantly  homeostatic plasticity fully regu-
lates the intrinsic excitabilities  and as a side effect eliminates the non-local terms Ak in the E-step 

3

uk(t) =X

i

Vkiyi(t) + bk  

while synaptic plasticity of the weights Vki optimizes the underlying probabilistic model p(y  z|V )
in the M-step.
In summary  the network response implements q∗ as the variational E-step  the M-Step can be per-
formed via gradient ascent on (6) with respect to Vki. As derived in section 2.1  this gives rise to
the following temporal dynamics and plasticity rules in the spiking network  which instantiate a
stochastic version of the variational EM scheme:

˙bk(t) = ηb · (rnet · mk − δ(zk(t) − 1))  
˙Vki(t) = ηV · δ(zk(t) − 1) · (yj(t) − σ(Vki))  

(7)

The target activations mk ∈ (0  1) can be chosen freely with the obvious constraint thatP

(8)
where δ(·) denotes the Dirac delta function  and ηb  ηV are learning rates (which were kept time-
invariant in the simulations with ηb = 10 · ηV ). Note that (8) is a spike-timing dependent plasticity
rule (cf. [12]) and is non-zero only at post-synaptic spike times t  for which zk(t) = 1. The effect of
the homeostatic intrinsic plasticity rule (7) is illustrated in Figure 1C: it aims to keep the long-term
average activation of each WTA neuron k close to a certain target value mk. More precisely  if rk is
a neuron’s long-term average ﬁring rate  then homeostatic plasticity will ensure that rk/rnet ≈ mk.
k mk = 1.
Note that (7) is strongly reminiscent of homeostatic intrinsic plasticity in cortex [18  19].
We have implemented these dynamics in a computer simulation of a WTA spiking network N .
Inputs y(t) were deﬁned by translating handwritten digits 0-5 (Figure 1B) from the MNIST
dataset [25] into input spike trains. Figure 1D shows that  at the end of a 104s learning period 
homeostatic plasticity has indeed achieved that rk ≈ rnet · mk. Figure 1E illustrates the patterns
learned by each WTA neuron after this period (shown are the πki). Apparently  the WTA neu-
rons have specialized on patterns of different intensity which correspond to different values of Ak.
Figure 1F shows the output spiking behavior of the circuit before and after learning in response to a
set of test patterns. The specialization to different patterns has led to a distinct sparse output code 
in which any particular test pattern evokes output spikes from only one or two WTA neurons. Note
that homeostasis forces all WTA neurons to participate in the competition  and thus prevents neurons
from becoming underactive if their synaptic weights decrease  and from becoming overactive if their
synaptic weights increase  much like the original Ak terms (which are nontrivial to compute for the
network). Indeed  the learned synaptic parameters and the resulting output behavior corresponds to
what would be expected from an optimal learning algorithm for the mixture model (1)-(3).1

2.1 Theory for the WTA model

In the following  we develop the three theoretical key results for the WTA model (1)-(3):

est to the posterior distribution p(z|y  V )  from a set of “homeostatic” distributions Q.

• Homeostatic intrinsic plasticity ﬁnds the network response distribution q∗(z|y) ∈ Q clos-
• The interplay of homeostatic and synaptic plasticity can be understood from the perspective
• The critical non-local terms Ak deﬁned by (3) drop out of the network dynamics.

of variational EM.

E-step: variational inference with homeostasis
The variational distribution q(z|y) we consider for the model (1)-(3) is a 2N · K dimensional object.
Since q describes a conditional probability distribution  it is non-negative and normalized for all y.
In addition  we constrain q to be a “homeostatic” distribution q ∈ Q such that the average activation
of each hidden variable (neuron) zk equals an a-priori speciﬁed mean activation mk under the input
statistics p∗(y). This is sketched in Figure 2. Formally we deﬁne the constraint set 

Q = {q : hzkip∗(y)q(z|y) = mk 

for all k = 1 . . . K}  

mk = 1 .

(9)

with X

1Without adaptation of intrinsic excitabilities  the network would start performing erroneous inference 
learning would reinforce this erroneous behavior  and performance would quickly break down. We have veriﬁed
this in simulations for the present WTA model: Consistently across trials  a small subset of WTA neurons
became dominantly active while most neurons remained silent.

k

4

Figure 2: A. Homeostatic posterior constraints in the WTA model: Under the variational distri-
bution q  the average activation of each variable zk must equal mk. B. For each set of synaptic
weights V there exists a unique assignment of intrinsic excitabilities b  such that the constraints are
fulﬁlled. C. Theoretical decomposition of the intrinsic excitability bk into −Ak  ˆbk and βk. D. Dur-
ing variational EM the bk predominantly “track” the dynamically changing non-local terms −Ak
(relative comparison between two WTA neurons from Figure 1).

The constrained maximization problem q∗(z|y) = arg maxq∈Q F (V   q(z|y)) can be solved with
the help of Lagrange multipliers (cf. [20]). We ﬁnd that the q∗ which maximizes the objective
function F during the E-step (and thus minimizes the KL-divergence to the posterior p(z|y  V ))
k. Hence  it sufﬁces to

has the convenient form q∗(z|y) ∝ p(z|y  V ) · exp(P

kzk) with some β∗

consider distributions of the form 

Vkiyi + ˆbk − Ak + βk

))  

(10)

qβ(z|y) ∝ exp(X

zk(X

k

i

k β∗
|

{z

=:bk

}

for the maximization problem. We identify βk as the variational parameters which remain to be
optimized. Note that any distribution of this form can be implemented by the spiking network N
if the intrinsic excitabilities are set to bk = −Ak + ˆbk + βk. The optimal variational distribution
q∗(z|y) = qβ∗(z|y) then has β
∗ = arg maxβ Ψ(β)  i.e. the variational parameter vector which
maximizes the dual [20] 

Ψ(β) =X

βkmk − hlogX

p(z|y  V ) exp(X

βkzk)ip∗(y) .

(11)

k

z

k

k = −Ak+ˆbk+β∗

∗ exists  and thus also the corresponding
Due to concavity of the dual  a unique global maximizer β
k are unique. Hence  the posterior constraint q ∈ Q
optimal intrinsic excitabilities b∗
can be illustrated as in Figure 2B: For each synaptic weight conﬁguration V there exists  under
a particular input distribution p∗(y)  a unique conﬁguration of intrinsic excitabilities b such that
the resulting network output fulﬁlls the homeostatic constraints. The theoretical relation between
the intrinsic excitabilities bk  the original nontrivial term −Ak and the variational parameters βk
is sketched in Figure 2C. Importantly  while bk is implemented in the network  Ak  βk and ˆbk
are not explicitly represented in the implementation anymore. Finding the optimal b in the dual
perspective  i.e. those intrinsic excitabilities which fulﬁll the homeostatic constraints  amounts to
gradient ascent ∂βΨ(β) on the dual  which leads to the following homeostatic learning rule for the
intrinsic excitabilities 

∆bk ∝ ∂βkΨ(β) = mk − hzkip∗(y)q(z|y) .

(12)

Note that the intrinsic homeostatic plasticity rule (7) in the network corresponds to a sample-based
stochastic version of this theoretically derived adaptation mechanism (12). Hence  given enough
time  homeostatic plasticity will automatically install near-optimal intrinsic excitabilities b ≈ b
∗ and
implement the correct variational distribution q∗ up to stochastic ﬂuctuations in b due to the non-
zero learning rate ηb. The non-local terms Ak have entirely dropped out of the network dynamics 
since the intrinsic excitabilities bk can be arbitrarily initialized  and are then fully regulated by the
local homeostatic rule  which does not require knowledge of Ak.
As a side remark  note that although the variational parameters βk are not explicitly present
in the implementation  they can be theoretically recovered from the network at any point  via

5

Figure 3: A. Input templates from MNIST dataset (digits 0 3 at a ratio 2:1  and digits 0 3 4 at a ratio
1:1:1) used during the ﬁrst and second learning period  respectively. B. Learned patterns at the end
of each learning period. C. Network performance converges in the course of learning. F is a tight
lower bound to L. D. Illustration of pattern learning and re-learning dynamics in a 2-D projection in
the input space. Each black dot corresponds to the pattern πki of one WTA neuron k. Colored dots
are input samples from the training set (blue/green/red ↔ digits 0/3/4).

βk = bk + Ak − ˆbk. Notably  in all our simulations we have consistently found small absolute val-
ues of βk  corresponding to a small KL-divergence between q∗ and p.2 Hence  a major effect of the
local homeostatic plasticity rule during learning is to dynamically track and effectively implement
the non-local terms −Ak. This is shown in Figure 2D  in which the relative excitabilities of two
WTA neurons bk − bj are plotted against the corresponding non-local Ak − Aj over the course of
learning in the ﬁrst simulation (Figure 1).

M-step: interplay of synaptic and homeostatic intrinsic plasticity

During the M-step  we aim to increase the EM lower bound F in (6) w.r.t. the synaptic parameters V .
Gradient ascent yields 

∂VkiF (V   q(z|y)) = h∂Vki log p(y  z|V )ip∗(y)q(z|y)

(13)
(14)
where q is the variational distribution determined during the E-step  i.e.  we can set q = q∗. Note the
formal correspondence of (14) with the network synaptic learning rule (8). Indeed  if the network
activity implements q∗  it can be shown easily that the expected update of synaptic weights due to
the synaptic plasticity (8) is proportional to (14)  and hence implements a stochastic version of the
theoretical M-step (cf. [12]).

= h zk · (yj − σ(Vki))ip∗(y)q(z|y)  

2.2 Dynamical properties of the Bayesian spiking network with homeostasis

To highlight a number of salient dynamical properties emerging from homeostatic plasticity in the
considered WTA model  Figure 3 shows a simulation of the same network N with homeostatic
dynamics as in Figure 1  only with different input statistics presented to the network  and uniform
mk = 1
K . During the ﬁrst 5000s  different writings of 0’s and 3’s from the MNIST dataset were
presented  with 0’s occurring twice as often as 3’s. Then the input distribution p∗(y) abruptly
switched to include also 4’s  with each digit occurring equally often. The following observations
can be made: Due to the homeostatic constraint  each neuron responds on average to mk · T out of T
presented inputs. As a consequence  the number of neurons which specialize on a particular digit is

2This is assuming for simplicity uniform prior parameters ˆbk. Note that a small KL-divergence is in fact
often observed during variational EM since F   which contains the negative KL-divergence  is being maximized.

6

directly proportional to the frequency of occurrence of that digit  i.e. 8:4 and 4:4:4 after the ﬁrst and
second learning period  respectively (Figure 3B). In general  if uniform target activations mk are
chosen  output resources are allocated precisely in proportion to input frequency. Figure 3C depicts
the time course of the EM lower bound F as well as the average likelihood L (assuming uniform ˆbk)
under the model during a single simulation run  demonstrating both convergence and tightness of
the lower bound. As expected due to the stabilizing dynamics of homeostasis  we found variability
in performance among different trials to be small (not shown). Figure 3D illustrates the dynamics
of learning and re-learning of patterns πki in a 2D projection of input patterns onto the ﬁrst two
principal components.

3 Homeostatic plasticity in recurrent spiking networks

The neural model so far was essentially a feed-forward network  in which every postsynaptic spike
can directly be interpreted as one sample of the instantaneous posterior distribution [12]. The lateral
inhibition served only to ensure the normalization of the posterior. We will now extend the concept
of homeostatic processes as posterior constraints to the broader class of recurrent networks and
sketch the utility of the developed framework beyond the regulation of intrinsic excitabilities.
Recently it was shown in [9  10] that recurrent networks of stochastically spiking neurons can in
principle carry out probabilistic inference through a sampling process. At every point in time  the
joint network state z(t) represents one sample of a posterior. However  [9] and [10] did not consider
unsupervised learning on spiking input streams.
For the following considerations  we divide the deﬁnition of the probabilistic model in two parts.
First  we deﬁne a Boltzmann distribution 

ˆWkjzkzj)/norm.  

(15)

p(z) = exp(X

X

j6=k

ˆbkzk +

1
2

k

p(y|z  V ) = exp(f0(y) +X

k i

with ˆWkj = ˆWjk as “prior” for the hidden variables z which will be represented by a recurrently
connected network of K spiking neurons. For the purpose of this section  we treat ˆbk and ˆWkj as
constants. Secondly  we deﬁne a conditional distribution in the exponential-family form [23] 

Vkizkfi(y) − A(z  V ))  

(16)

that speciﬁes the likelihood of observable inputs y  given a certain network state z. This deﬁnes the
generative model p(y  z|V ) = p(z) p(y|z  V ).
We map this probabilistic model to the spiking network and deﬁne that for every k and every point
in time t the variable zk(t) has the value 1  if the corresponding neuron has ﬁred within the time
window (t − τ  t]. In accordance with the neural sampling theory  in order for a spiking network to
sample from the correct posterior p(z|y  V ) ∝ p(z) p(y|z  V ) given the input y  each neuron must
compute in its membrane potential the log-odd [9] 

=X
|

i

{z

feedforward drive

|

}

{z

+X

j6=k

}

|

{z

}

Vkifi(y)

−Ak(V ) + ˆbk

(−Akj(V ) + ˆWkj

)zj − . . .

intr. excitability

recurrent weight

uk = log

p(zk = 1|z\k  V )
p(zk = 0|z\k  V )

(17)
where z\k = (z1  . . .   zk−1  zk+1  . . . zK)T. The Ak  Akj  . . . are given by the decomposition of
A(z  V ) along the binary combinations of z as 

A(z  V ) = A0(V ) +X

zkAk(V ) +

1
2

k

X

j6=k

zkzjAkj(V ) + . . .

(18)

Note  that we do not aim at this point to give learning rules for the prior parameters ˆbk and ˆWkj. In-
stead we proceed as in the last section and specify a-priori desired properties of the average network
response under the input distribution p∗(y) 
ckj = hzkzjip∗(y)q(z|y)

mk = hzkip∗(y)q(z|y) .

(19)

and

7

qβ ω(z|y) ∝ p(z|y  V ) · exp

βkzk +

1
2

ωkjzkzj

(20)

X

k

  

X

j6=k

Let us explore some illustrative conﬁgurations for mk and ckj. One obvious choice is closely re-
lated to the goal of maximizing the entropy of the output code by ﬁxing hzki to 1
K and hzkzji
to hzkihzji = 1
K2   thus enforcing second order correlations to be zero. Another intuitive choice
would be to set all hzkzji very close to zero  which excludes that two neurons can be active si-
multaneously and thus recovers the function of a WTA. It is further conceivable to assign positive
correlation targets to groups of neurons  thereby creating populations with redundant codes. Finally 
with a topographical organization of neurons in mind  all three basic ideas sketched above might
be combined: one could assign positive correlations to neighboring neurons in order to create lo-
cal cooperative populations  mutual exclusion at intermediate distance  and zero correlation targets
between distant neurons.
With this in mind  we can formulate the goal of learning for the network in the context of EM
with posterior constraints: we constrain the E-step such that the average posterior fulﬁlls the chosen
targets  and adapt the forward weights V in the M-step according to (6). Analogous to the ﬁrst-order
case  the variational solution of the E-step under these constraints takes the form 

with symmetric ωkl = ωlk as variational parameters. A neural sampling network N with input
weights Vki will sample from qβ ω if the intrinsic excitabilities are set to bk = −Ak + ˆbk + βk  and
the symmetric recurrent synaptic weights to Wkj = −Akj + ˆWkj + ωkj. The variational parameters
β  ω (and hence also b  W ) which optimize the dual problem Ψ(b  ω) are uniquely deﬁned and
can be found iteratively via gradient ascent. Analogous to the last section  this yields the intrinsic
plasticity rule (12) for bk. In addition  we obtain for the recurrent synapses Wkj 

∆Wkj ∝ ckj − hzkzjip∗(y)q(z|y)  

the network state z  i.e.  p(y|z  V ) = Q

(21)
which translates to an anti-Hebbian spike-timing dependent plasticity rule in the network implemen-
tation.
For any concrete instantiation of f0(y)  fi(y) and A(z  V ) in (16) it is possible to derive learning
rules for Vki for the M-step via ∂VkiF (V   q). Of course not all models entail local synaptic learning
rules. In particular it might be necessary to assume conditional independence of the inputs y given
i p(yi|z  V ). Furthermore  in order to fulﬁll the neural
computability condition (17) for neural sampling [9] with a recurrent network of point neurons  it
might be necessary to choose A(z  V ) such that terms of order higher than 2 vanish in the decompo-
sition. This can be shown to hold  for example  in a model with conditionally independent Gaussian
distributed inputs yi. It is ongoing work to ﬁnd further biologically realistic network models in the
sense of this theory and to assess their computational capabilities through computer experiments.

4 Discussion

Complex and non-local computations  which appear during probabilistic inference and learning  ar-
guably constitute one of the cardinal challenges in the development of biologically realistic Bayesian
spiking network models. In this paper we have introduced homeostatic plasticity  which to the best
of our knowledge had not been considered before in the context of EM in spiking networks  as a
theoretically grounded approach to stabilize and facilitate learning in a large class of network mod-
els. Our theory complements previously proposed neural mechanisms and provides  in particular 
a simple and biologically realistic alternative to the assumptions on the input distribution made in
[12] and [15]. Indeed  our results challenge the hypothesis of [15] that feedforward inhibition is
critical for correctly learning the structure of the data with biologically plausible plasticity rules.
More generally  it turns out that the enforcement of a balancing posterior constraint often simpliﬁes
inference in recurrent spiking networks by eliminating nontrivial computations. Our results suggest
a crucial role of homeostatic plasticity in the Bayesian brain: to constrain activity patterns in cortex
to assist the autonomous optimization of an internal model of the environment.

Acknowledgments. Written under partial support by the European Union - projects #FP7-269921
(BrainScaleS)  #FP7-216593 (SECO)  #FP7-237955 (FACETS-ITN)  #FP7-248311 (AMARSi) 
#FP7-216886 (PASCAL2) - and the Austrian Science Fund FWF #I753-N23 (PNEUMA).

8

References

[1] K. P. K¨ording and D. M. Wolpert. Bayesian integration in sensorimotor learning. Nature  427(6971):244–

247  2004.

[2] G. Orban  J. Fiser  R.N. Aslin  and M. Lengyel. Bayesian learning of visual chunks by human observers.

Proceedings of the National Academy of Sciences  105(7):2745–2750  2008.

[3] J. Fiser  P. Berkes  G. Orban  and M. Lengyel. Statistically optimal perception and learning: from behavior

to neural representation. Trends in Cogn. Sciences  14(3):119–130  2010.

[4] P. Berkes  G. Orban  M. Lengyel  and J. Fiser. Spontaneous cortical activity reveals hallmarks of an

optimal internal model of the environment. Science  331:83–87  2011.

[5] T. L. Grifﬁths and J. B. Tenenbaum. Optimal predictions in everyday cognition. Psychological Science 

17(9):767–773  2006.

[6] D. E. Angelaki  Y. Gu  and G. C. DeAngelis. Multisensory integration: psychophysics  neurophysiology

and computation. Current opinion in neurobiology  19(4):452–458  2009.

[7] S. Deneve. Bayesian spiking neurons I: Inference. Neural Computation  20(1):91–117  2008.
[8] A. Steimer  W. Maass  and R.J. Douglas. Belief propagation in networks of spiking neurons. Neural

Computation  21:2502–2523  2009.

[9] L. Buesing  J. Bill  B. Nessler  and W. Maass. Neural dynamics as sampling: A model for stochastic

computation in recurrent networks of spiking neurons. PLoS Comput Biol  7(11):e1002211  11 2011.

[10] D. Pecevski  L. Buesing  and W. Maass. Probabilistic inference in general graphical models through

sampling in stochastic networks of spiking neurons. PLoS Comput Biol  7(12)  12 2011.

[11] S. Deneve. Bayesian spiking neurons II: Learning. Neural Computation  20(1):118–145  2008.
[12] B. Nessler  M. Pfeiffer  and W. Maass. STDP enables spiking neurons to detect hidden causes of their

inputs. In Proc. of NIPS 2009  volume 22  pages 1357–1365. MIT Press  2010.

[13] J. Brea  W. Senn  and J.-P. Pﬁster. Sequence learning with hidden units in spiking neural networks. In

Proc. of NIPS 2011  volume 24  pages 1422–1430. MIT Press  2012.

[14] D. J. Rezende  D. Wierstra  and W. Gerstner. Variational learning for recurrent spiking networks. In Proc.

of NIPS 2011  volume 24  pages 136–144. MIT Press  2012.

[15] C. Keck  C. Savin  and J. L¨ucke. Feedforward inhibition and synaptic scaling–two sides of the same coin?

PLoS Computational Biology  8(3):e1002432  2012.

[16] Joshua B. Tenenbaum  Charles Kemp  Thomas L. Grifﬁths  and Noah D. Goodman. How to grow a mind:

Statistics  structure  and abstraction. Science  331(6022):1279–1285  2011.

[17] J. Schemmel  D. Br¨uderle  A. Gr¨ubl  M. Hock  K. Meier  and S. Millner. A wafer-scale neuromorphic

hardware system for large-scale neural modeling. Proc. of ISCAS’10  pages 1947–1950  2010.

[18] N.S. Desai  L.C. Rutherford  and G.G. Turrigiano. Plasticity in the intrinsic excitability of cortical pyra-

midal neurons. Nature Neuroscience  2(6):515  1999.

[19] A. Watt and N. Desai. Homeostatic plasticity and STDP: keeping a neurons cool in a ﬂuctuating world.

Frontiers in Synaptic Neuroscience  2  2010.

[20] J. Graca  K. Ganchev  and B. Taskar. Expectation maximization and posterior constraints. In Proc. of

NIPS 2007  volume 20. MIT Press  2008.

[21] R. Jolivet  A. Rauch  HR L¨uscher  and W. Gerstner. Predicting spike timing of neocortical pyramidal

neurons by simple threshold models. Journal of Computational Neuroscience  21:35–49  2006.

[22] E.P. Simoncelli and D.J. Heeger. A model of neuronal responses in visual area MT. Vision Research 

38(5):743–761  1998.

[23] C. M. Bishop. Pattern Recognition and Machine Learning. Springer  New York  2006.
[24] M. Sato. Fast learning of on-line EM algorithm. Rapport Technique  ATR Human Information Processing

Research Laboratories  1999.

[25] Y. LeCun  L. Bottou  Y. Bengio  and P. Haffner. Gradient-based learning applied to document recognition.

In Proceedings of the IEEE  volume 86  pages 2278–2324  11 1998.

9

,Boris Hanin