2016,Using Social Dynamics to Make Individual Predictions: Variational Inference with a Stochastic Kinetic Model,Social dynamics is concerned primarily with interactions among individuals and the resulting group behaviors  modeling the temporal evolution of social systems via the interactions of individuals within these systems. In particular  the availability of large-scale data from social networks and sensor networks offers an unprecedented opportunity to predict state-changing events at the individual level. Examples of such events include disease transmission  opinion transition in elections  and rumor propagation. Unlike previous research focusing on the collective effects of social systems  this study makes efficient inferences at the individual level. In order to cope with dynamic interactions among a large number of individuals  we introduce the stochastic kinetic model to capture adaptive transition probabilities and propose an efficient variational inference algorithm the complexity of which grows linearly — rather than exponentially— with the number of individuals. To validate this method  we have performed epidemic-dynamics experiments on wireless sensor network data collected from more than ten thousand people over three years. The proposed algorithm was used to track disease transmission and predict the probability of infection for each individual. Our results demonstrate that this method is more efficient than sampling while nonetheless achieving high accuracy.,Using Social Dynamics to Make Individual Predictions:
Variational Inference with a Stochastic Kinetic Model

Zhen Xu  Wen Dong  and Sargur Srihari

Department of Computer Science and Engineering

University at Buffalo

{zxu8 wendong srihari}@buffalo.edu

Abstract

Social dynamics is concerned primarily with interactions among individuals and the
resulting group behaviors  modeling the temporal evolution of social systems via
the interactions of individuals within these systems. In particular  the availability of
large-scale data from social networks and sensor networks offers an unprecedented
opportunity to predict state-changing events at the individual level. Examples
of such events include disease transmission  opinion transition in elections  and
rumor propagation. Unlike previous research focusing on the collective effects
of social systems  this study makes efﬁcient inferences at the individual level. In
order to cope with dynamic interactions among a large number of individuals  we
introduce the stochastic kinetic model to capture adaptive transition probabilities
and propose an efﬁcient variational inference algorithm the complexity of which
grows linearly — rather than exponentially— with the number of individuals.
To validate this method  we have performed epidemic-dynamics experiments on
wireless sensor network data collected from more than ten thousand people over
three years. The proposed algorithm was used to track disease transmission and
predict the probability of infection for each individual. Our results demonstrate
that this method is more efﬁcient than sampling while nonetheless achieving high
accuracy.

1

Introduction

The ﬁeld of social dynamics is concerned primarily with interactions among individuals and the
resulting group behaviors. Research in social dynamics models the temporal evolution of social
systems via the interactions of the individuals within these systems [9]. For example  opinion
dynamics can model the opinion state transitions of an entire population in an election scenario [3] 
and epidemic dynamics can predict disease outbreaks ahead of time [10]. While traditional social-
dynamics models focus primarily on the macroscopic effects of social systems  often we instead
wish to know the answers to more speciﬁc questions. Given the movement and behavior history
of a subject with Ebola  can we tell how many people should be tested or quarantined? City-size
quarantine is not necessary  but family-size quarantine is insufﬁcient. We aim to model a method to
evaluate the paths of illness transmission and the risks of infection for individuals  so that limited
medical resources can be most efﬁciently distributed.
The rapid growth of both social networks and sensor networks offers an unprecedented opportunity
to collect abundant data at the individual level. From these data we can extract temporal interactions
among individuals  such as meeting or taking the same class. To take advantage of this opportu-
nity  we model social dynamics from an individual perspective. Although such an approach has
considerable potential  in practice it is difﬁcult to model the dynamic interactions and handle the
costly computations when a large number of individuals are involved. In this paper  we introduce an

30th Conference on Neural Information Processing Systems (NIPS 2016)  Barcelona  Spain.

event-based model into social systems to characterize their temporal evolutions and make tractable
inferences on the individual level.
Our research on the temporal evolutions of social systems is related to dynamic Bayesian networks
and continuous time Bayesian networks [13  18  21]. Traditionally  a coupled hidden Markov model
is used to capture the interactions of components in a system [2]  but this model does not consider
dynamic interactions. However  a stochastic kinetic model is capable of successfully describing the
interactions of molecules (such as collisions) in chemical reactions [12  22]  and is widely used in
many ﬁelds such as chemistry and cell biology [1  11]. We introduce this model into social dynamics
and use it to focus on individual behaviors.
A challenge in capturing the interactions of individuals is that in social dynamics the state space grows
exponentially with the number of individuals  which makes exact inference intractable. To resolve
this we must apply approximate inference methods. One class of these involves sampling-based
methods. Rao and Teh introduce a Gibbs sampler based on local updates [20]  while Murphy and
Russell introduce Rao-Blackwellized particle ﬁltering for dynamic Bayesian networks [17]. However 
sampling-based methods sometimes mix slowly and require a large number of samples/particles. To
demonstrate this issue  we offer empirical comparisons with two major sampling methods in Section
4. An alternative class of approximations is based on variational inference. Opper and Sanguinetti
apply the variational mean ﬁeld approach to factor a Markov jump process [19]  and Cohn and El-Hay
further improve its efﬁciency by exploiting the structure of the target network [4]. A problem is that
in an event-based model such as a stochastic kinetic model (SKM)  the variational mean ﬁeld is not
applicable when a single event changes the states of two individuals simultaneously. Here  we use a
general expectation propagation principle [14] to design our algorithm.
This paper makes three contributions: First  we introduce the discrete event model into social
dynamics and make tractable inferences on both individual behaviors and collective effects. To this
end  we apply the stochastic kinetic model to deﬁne adaptive transition probabilities that characterize
the dynamic interaction patterns in social systems. Second  we design an efﬁcient variational inference
algorithm whose computation complexity grows linearly with the number of individuals. As a result 
it scales very well in large social systems. Third  we conduct experiments on epidemic dynamics to
demonstrate that our algorithm can track the transmission of epidemics and predict the probability of
infection for each individual. Further  we demonstrate that the proposed method is more efﬁcient
than sampling while nonetheless achieving high accuracy.
The remainder of this paper is organized as follows. In Section 2  we brieﬂy review the coupled hidden
Markov model and the stochastic kinetic model. In Section 3  we propose applying a variational
algorithm with the stochastic kinetic model to make tractable inferences in social dynamics. In
Section 4  we detail empirical results from applying the proposed algorithm to our epidemic data
along with the proximity data collected from sensor networks. Section 5 concludes.

2 Background

  . . .   x(M )

t

t

) deﬁnes the hidden states of all HMMs at time t  and x(m)

2.1 Coupled Hidden Markov Model
A coupled hidden Markov model (CHMM) captures the dynamics of a discrete time Markov process
that joins a number of distinct hidden Markov models (HMMs)  as shown in Figure 2.1(a). xt =
(x(1)
is the hidden state of
HMM m at time t. yt = (y(1)
is
the observation of HMM m at time t. P (xt|xt1) are transition probabilities  and P (yt|xt) are
emission probabilities for CHMM. Given hidden states  all observations are independent. As such 
P (yt|xt) =Qm P (y(m)
) is the emission probability for HMM m at

time t. The joint probability of CHMM can be deﬁned as follows:

) are observations of all HMMs at time t  and y(m)

)  where P (y(m)

  . . .   y(M )

t

|x(m)

t

t

t

t

t

t

P (x1 ... T   y1 ... T ) =

P (xt|xt1)P (yt|xt).

(1)

For a CHMM that contains M HMMs in a binary state  the state space is 2M  and the state transition
kernel is a 2M ⇥ 2M matrix. In order to make exact inferences  the classic forward-backward
algorithm sweeps a forward/ﬁltering pass to compute the forward statistics ↵t(xt) = P (xt|y1 ... t)

t

|x(m)
TYt=1

2

HMM 1
...

HMM 2
...

HMM 3
...

x1 t-1

y1 t-1

x2 t-1

y2 t-1

x3 t-1

y3 t-1

t-1

x1 t

y1 t

x2 t

y2 t

x3 t

y3 t

t

Time
(a)

x1 t+1

...

...

...

y1 t+1

x2 t+1

y2 t+1

x3 t+1

y3 t+1

t+1

HMM 1
...

HMM 2
...

HMM 3
...

x1 t-1

y1 t-1

x2 t-1

y2 t-1

x3 t-1

y3 t-1

t-1

vt

vt+1

x1 t

y1 t

x2 t

y2 t

x3 t

y3 t

t

Time
(b)

x1 t+1

...

...

...

y1 t+1

x2 t+1

y2 t+1

x3 t+1

y3 t+1

t+1

Figure 1: Illustration of (a) Coupled Hidden Markov Model  (b) Stochastic Kinetic Model.

and a backward/smoothing pass to estimate the backward statistics t(xt) = P (yt+1 ... T |xt)
P (yt+1 ... T |y1 ... t).
Then it can estimate the one-slice statistics t(xt) = P (xt|y1 ... T ) = ↵t(xt)t(xt) and two-slice
statistics ⇠t(xt1  xt) = P (xt1  xt|y1 ... T ) = ↵t1(xt1)P (xt|xt1)P (yt|xt)t(xt)
. Its complexity
grows exponentially with the number of HMM chains. In order to make tractable inferences  certain
factorizations and approximations must be applied. In the next section  we introduce a stochastic
kinetic model to lower the dimensionality of transition probabilities.

P (yt|y1 ... t1)

2.2 The Stochastic Kinetic Model
A stochastic kinetic model describes the temporal evolution of a chemical system with M species
X = {X1  X2 ···   XM} driven by V events (or chemical reactions) parameterized by rate constants
c = (c1  . . .   cV ). An event (chemical reaction) k has a general form as follows:

r1X1 + ··· + rM XM

ck! p1X1 + ··· + pM XM .

The species on the left are called reactants  and rm is the number of mth reactant molecules consumed
during the reaction. The species on the right are called products  and pm is the number of mth product
molecules produced in the reaction. Species involved in the reaction (rm > 0) without consumption
or production (rm = pm) are called catalysts. At any speciﬁc time t  the populations of the species
is xt = (x(1)
). An event k happens with rate hk(xt  ck)  determined by the rate constant
and the current population state [22]:

  . . .   x(M )

t

t

hk(xt  ck) =ckgk(xt) = ck

g(m)
k

(x(m)

t

).

(2)

t

k

(x(m)

In our case  we adopt

The form of gk(xt) depends on the reaction.

the product form
QM
m=1 g(m)
)  which represents the total number of ways that reactant molecules can be selected
to trigger event k [22]. Event k changes the populations by k = xt  xt1. The probability that
event k will occur during time interval (t  t + dt] is hk(xt  ck)dt. We assume at each discrete time
step that no more than one event will occur. This assumption follows the linearization principle in the
literature [18]  and is valid when the discrete time step is small. We treat each discrete time step as a
unit of time  so that hk(xt  ck) represents the probability of an event.
In epidemic modeling  for example  an infection event vi has the form S + I ci! 2I  such that a
susceptible individual (S) is infected by an infectious individual (I) with rate constant ci. If there is
only one susceptible individual (type m = 1) and one infectious individual (type m = 2) involved in
this event  hi(xt  ci) = ci  i = [1 1]T and P (xt  xt1 = i) = P (xt|xt1  vi) = ci.
In a traditional hidden Markov model  the transition kernel is typically ﬁxed. In comparison  SKM
is better at capturing dynamic interactions in terms of the events with rates dependent on reactant
populations  as shown in Eq.(2).

MYm=1

3

3 Variational Inference with the Stochastic Kinetic Model
In this section  we deﬁne the likelihood of the entire sequence of hidden states and observations for
an event-based model  and derive a variational inference algorithm and parameter-learning algorithm.
3.1 Likelihood for Event-based Model
In social dynamics  we use a discrete time Markov model to describe the temporal evolutions of a set
of individuals x(1)  . . .   x(M ) according to a set of V events. To cope with dynamic interactions  we
introduce the SKM and express the state transition probabilities in terms of event probabilities  as
shown in Figure 2.1(b). We assume at each discrete time step that no more than one event will occur.
Let v1  . . .   vT be a sequence of events  x1  . . .   xT a sequence of hidden states  and y1  . . .   yT a
set of observations. Similar to Eq.(1)  the likelihood of the entire sequence is as follows:

TYt=1

P (x1 ... T   y1 ... T   v1 ... T ) =

P (xt  vt|xt1) =⇢ck · gk (xt1) · (xt  xt1 ⌘ k)

P (xt  vt|xt1)P (yt|xt)  where
(1 Pk ckgk (xt1)) · (xt  xt1 ⌘ 0)

if vt = k
if vt = ;

(3)

.

P (xt  vt|xt1) is the event-based transition kernel. (xt  xt1 ⌘ k) is 1 if the previous state
is xt1 and the current state is xt = xt1 + k  and 0 otherwise. k is the effect of event vk. ;
represents an auxiliary event  meaning that there is no event. Substituting the product form of gk  the
transition kernel can be written as follows:

g(m)
k

P (xt  vt = k|xt1) = ckYm
P (xt  vt = ;|xt1) = (1 Xk
t  x(m)
t = x(m)

k

(x(m)

t1) ·Ym
ckYm

g(m)
k

) 

k

(x(m)

t1 ⌘ (m)
t  x(m)
t1)) ·Ym
(x(m)
t  x(m)

(x(m)

t1 ⌘ 0) 

(4)

(5)

k

t1 ⌘ (m)
t1 + (m)

) is 1 if the previous state of an individual m is x(m)
  and 0 otherwise.

where (x(m)
state is x(m)
3.2 Variational Inference for Stochastic Kinetic Model
As noted in Section 2.1  exact inference in social dynamics is intractable due to the formidable state
space. However  we can approximate the posterior distribution P (x1 ... T   v1 ... T|y1 ... T ) using an
approximate distribution within the exponential family. The inference algorithm minimizes the KL
divergence between these two distributions  which can be formulated as an optimization problem [14]:

t1 and the current

Minimize: Xt xt1 xt vt
Subject to: Xvt xt1 {xt\x(m)
Xvt {xt1\x(m)
Xx(m)

ˆ(m)
t

t1} xt
(x(m)

t

t

t

}

ˆ⇠t(xt1  xt  vt) · log

ˆ⇠t(xt1  xt  vt)

P (xt  vt|xt1)P (yt|xt)
(x(m)

ˆ(m)
t

t

Xt xtYm

)  for all t  m  x(m)

 

t

) logYm

(6)

ˆ(m)
t

(x(m)

t

)

ˆ⇠t(xt1  xt  vt) = ˆ(m)

t

(x(m)

t

ˆ⇠t(xt1  xt  vt) = ˆ(m)

t1 (x(m)

t1)  for all t  m  x(m)
t1 

) = 1  for all t  m.

The objective function is the Bethe free energy  composed of average energy and Bethe entropy
approximation [23]. ˆ⇠t(xt1  xt  vt) is the approximate two-slice statistics and ˆ(m)
) is the
approximate one-slice statistics for each individual m. They form the approximate distribution over
which to minimize the Bethe free energy. ThePt xt1 xt vt is an abbreviation for summing over
t  xt1  xt  and vt. P{xt\x(m)

. We use similar
abbreviations below. The ﬁrst two sets of constraints are marginalization conditions  and the third

is the sum over all individuals in xt except x(m)

(x(m)

}

t

t

t

t

4

is normalization conditions. To solve this constrained optimization problem  we ﬁrst deﬁne the
Lagrange function using Lagrange multipliers to weight constraints  then take the partial derivatives
with respect to ˆ⇠t(xt1  xt  vt)  and ˆ(m)
). The dual problem is to ﬁnd the approximate forward
statistics ˆ↵(m)
) in order to maximize the pseudo-likelihood
function. The duality is between minimizing Bethe free energy and maximizing pseudo-likelihood.
The ﬁxed-point solution for the primal problem is as follows1:

t1) and backward statistics ˆ(m)

t1(x(m)

(x(m)

(x(m)

t

t

t

t

ˆ⇠t(x(m)

t1  x(m)

t

  vt) =

1

ZtXm06=m x(m0)

P (xt vt|xt1)·Qm ˆ↵(m)

t1  x(m0)

t

t1(x(m)

t1)·Qm P (y(m)

t

|x(m)

t

)·Qm

ˆ(m)
t

(x(m)

t

).

(7)

t

t1  x(m)

ˆ⇠t(x(m)
  vt) is the two-slice statistics for an individual m  and Zt is the normalization constant.
Given the factorized form of P (xt  vt|xt1) in Eqs. (4) and (5)  everything in Eq. (7) can be written
in a factorized form. After reformulating the term relevant to the individual m  ˆ⇠t(x(m)
  vt)
can be shown neatly as follows:
1
Zt

t1)P (y(m)

t1  x(m)

ˆP (x(m)

(x(m)

(8)

t

t

t

t

  vt) =

ˆ⇠t(x(m)

t1  x(m)

  vt|x(m)
where the marginalized transition kernel ˆP (x(m)
t1) Ym06=m
ˆP (x(m)

(x(m)

k

t

ˆP (x(m)

t

ckg(m)

k

(x(m)

t1) = ckg(m)
t1) = (1 Xk

  vt = k|x(m)
  vt = ;|x(m)
↵(m0)
t1 (x(m0)
(m0)
(m0)
x
t1 ⌘
t
↵t1(x(m0)
t1 )P (y(m0)
(m0)
(m0)
t1 ⌘0
t

|x(m0)

(m0)
k

x

t

t

t

t

t

) ˆ(m)

|x(m)

t1(x(m)
t1) for the individual m can be deﬁned as:
(9)

) 

) 

t

t

t

k

t1) · ˆ↵(m)
  vt|x(m)
˜g(m0)
t  x(m)
k t1 · (x(m)
t1) Ym06=m
ˆg(m0)
k t1)(x(m)
t1 )Px
↵(m0)
t1 (x(m0)
(m0)
(m0)
x
t1 ⌘0
t
t1 )Px
t1 (x(m0)
↵(m0)
t1 )P (y(m0)
(m0)
(m0)
x
t1 ⌘0
t

t1 ⌘ (m)
t  x(m)
t1 )P (y(m0)

(x(m0)

(x(m0)

)g(m0)

)g(m0)

k

t

t1 ⌘ 0) 
|x(m0)

t

t

(10)

t

t

t

t

t

t

t

t

t

k

k

k

) 

) 

ˆg(m0)

˜g(m0)

(x(m0)

(x(m0)

(x(m0)

(x(m0)

)(m0)

)(m0)

)(m0)

)(m0)

|x(m0)

|x(m0)

(x(m0)

t1 )P (y(m0)

k t1=Px
k t1=Px
In the above equations  we consider the mean ﬁeld effect by summing over the current and previous
states of all the other individuals m0 6= m. The marginalized transition kernel considers the probability
of event k on the individual m given the context of the temporal evolutions of the other individuals.
Comparing Eqs. (9) and (10) with Eqs. (4) and (5)  instead of multiplying g(m0)
t1 ) for individual
m0 6= m  we use the expected value of g(m0)
with respect to the marginal probability distribution of
x(m0)
t1 .
Complexity Analysis: In our inference algorithm  the most computation-intensive step is the
marginalization in Eqs. (9)-(10). The complexity is O(M S2)  where M is the number of indi-
viduals and S is the state space of a single individual. The complexity of the entire algorithm is
therefore O(M S2T N )  where T is the number of time steps and N is the number of iterations until
convergence. As such  the complexity of our algorithm grows only linearly with the number of
individuals; it offers excellent scalability when the number of tracked individuals becomes large.
3.3 Parameter Learning
In order to learn the rate constant ck  we maximize the expected log likelihood. In a stochastic kinetic
model  the probability of a sample path is given in Eq. (3). The expected log likelihood over the
posterior probability conditioned on the observations y1  . . .   yT takes the following form:
ˆ⇠t(xt1  xt  vt) · log(P (xt  vt|xt1)P (yt|xt)).

log P (x1 ... T   y1 ... T   v1 ... T ) =Xt xt1 xt vt

ˆ⇠t (xt1  xt  vt) is the approximate two-slice statistics deﬁned in Eq. (6). Maximizing this expected
log likelihood by setting its partial derivative over the rate constants to 0 gives the maximum expected
log likelihood estimation of these rate constants.

ck =

Pt xt1 xt
Pt xt1 xt

ˆ⇠t(xt1  xt  vt = k)

ˆ⇠t(xt1  xt  vt = ;)gk(xt1) ⇡ Pt Pxt1 xt
Pt QmPx(m)

t1

ˆ⇠t(xt1  xt  vt = k)
(x(m)
ˆ(m)
t1 (x(m)
t1)

t1)g(m)

k

.

(11)

1The derivations for the optimization problem and its solution are shown in the Supplemental Material.

5

As such  the rate constant for event k is the expected number of times that this event has occurred
divided by the total expected number of times this event could have occurred.
To summarize  we provide the variational inference algorithm below.

Algorithm: Variational Inference with a Stochastic Kinetic Model
Given the observations y(m)
for k = 1  . . .   V .
Latent state inference. Iterate through the following forward and backward passes until convergence 
where ˆP (x(m)

for t = 1  . . .   T and m = 1  . . .   M  ﬁnd x(m)

  vt and rate constants ck

  vt|x(m)

t1) is given by Eqs. (9) and (10).

t

t

t

• Forward pass. For t = 1  . . .   T and m = 1  . . .   M  update ˆ↵(m)
  vt|x(m)

t1) ˆP (x(m)

ˆ↵(m)
t1(x(m)

(x(m)

) 

ˆ↵(m)
t

1

t

t

t

t1)P (y(m)

t

|x(m)

t

).

(x(m)

t

) according to

ZtXx(m)

t1 vt

• Backward pass. For t = T  . . .   1 and m = 1  . . .   M  update ˆ(m)

t1) according to

ˆ(m)
t1 (x(m)

t1) 

1

ZtXx(m)

t

(x(m)

t

) ˆP (x(m)

t

ˆ(m)
t
 vt

  vt|x(m)

t1 (x(m)
t1)P (y(m)

t

|x(m)

t

).

Parameter estimation. Iterate through the latent state inference (above) and rate constants estimate
of ck according to Eq. (11)  until convergence.

4 Experiments on Epidemic Applications

In this section  we evaluate the performance of variational inference with a stochastic kinetic model
(VISKM) algorithm of epidemic dynamics  with which we predict the transmission of diseases and
the health status of each individual based on proximity data collected from sensor networks.

4.1 Epidemic Dynamics
In epidemic dynamics  Gt = (M  Et) is a dynamic network  where each node m 2 M is an
individual in the network  and Et = {(mi  mj)} is a set of edges in Gt representing that individuals
mi and mj have interacted at a speciﬁc time t. There are two possible hidden states for each
individual m at time t  x(m)
2 {0  1}  where 0 indicates the susceptible state and 1 the infectious
state. y(m)
2 {0  1} represents the presence or absence of symptoms for individual m at time t.
P (y(m)
|x(m)
) represents the observation probability. We deﬁne three types of events in epidemic
applications: (1) A previously infectious individual recovers and becomes susceptible again: I c1! S.
(2) An infectious individual infects a susceptible individual in the network: S + I c2! 2I. (3) A
susceptible individual in the network is infected by an outside infectious individual: S c3! I. Based
on these events  the transition kernel can be deﬁned as follows:

t

t

t

t

P (x(m)
P (x(m)

t = 1|x(m)

t1 = 1) = c1  P (x(m)
t1 = 0) = (1  c3)(1  c2)Cm t  P (x(m)

t1 = 1) = 1  c1 
t = 1|x(m)

t = 0|x(m)
t = 0|x(m)
where Cm t = Pm0:(m0 m)2Et

t1 = 0) = 1  (1  c3)(1  c2)Cm t 
⌘ 1) is the number of possible infectious sources for
individual m at time t. Intuitively  the probability of a susceptible individual becoming infected is 1
minus the probability that no infectious individuals (inside or outside the network) infected him. When
the probability of infection is very small  we can approximate P (x(m)
t1 = 0) ⇡ c3+c2·Cm t.

t = 1|x(m)

(x(m0)

t

6

4.2 Experimental Results

Data Explanation: We employ two data sets of epidemic dynamics. The real data set is collected
from the Social Evolution experiment [5  6]. This study records “common cold” symptoms of 65
students living in a university residence hall from January 2009 to April 2009  tracking their locations
and proximities using mobile phones. In addition  the students took periodic surveys regarding their
health status and personal interactions. The synthetic data set was collected on the Dartmouth College
campus from April 2001 to June 2004  and contains the movement history of 13 888 individuals [16].
We synthesized disease transmission along a timeline using the popular susceptible-infectious-
susceptible (SIS) epidemiology model [15]  then applied the VISKM to calibrate performance. We
selected this data set because we want to demonstrate that our model works on data with a large
number of people over a long period of time.
Evaluation Metrics and Baseline Algorithms: We select the receiver operating characteristic
(ROC) curve as our performance metric because the discrimination thresholds of diseases vary. We
ﬁrst compare the accuracy and efﬁciency of VISKM with Gibbs sampling (Gibbs) and particle
ﬁltering (PF) on the Social Evolution data set [7  8].2 Both Gibbs sampling and particle ﬁltering
iteratively sample the infectious and susceptible latent state sequences and the infection and recovery
events conditioned on these state sequences. Gibbs-Prediction-10000 indicates 10 000 iterations of
Gibbs sampling with 1000 burn-in iterations for the prediction task. PF-Smoothing-1000 similarly
refers to 1000 iterations of particle ﬁltering for the smoothing task. All experiments are performed on
the same computer.
Individual State Inference: We infer the probabilities of a hidden infectious state for each individual
at different times under different scenarios. There are three tasks: 1. Prediction: Given an individual’s
past health and current interaction patterns  we predict the current infectious latent state. Figure 2(a)
compares prediction performance among the different approximate inference methods. 2. Smoothing:
Given an individual’s interaction patterns and past health with missing periods  we infer the infectious
latent states during these missing periods. Figure 2(b) compares the performance of the three
inference methods. 3. Expansion: Given the health records of a portion (⇠ 10%) of the population 
we estimate the individual infectious states of the entire population before medically inspecting
them. For example  given either a group of volunteers willing to report their symptoms or the
symptom data of patients who came to hospitals  we determine the probabilities that the people near
these individuals also became or will become infected. This information helps the government or
aid agencies to efﬁciently distribute limited medical resources to those most in need. Figure 2(c)
compares the performance of the different methods. From the above three graphs  we can see that all
three methods identify the infectious states in an accurate way. However  VISKM outperforms Gibbs
sampling and particle ﬁltering in terms of area under the ROC curve for all three tasks. VISKM has
an advantage in the smoothing task because the backward pass helps to infer the missing states using
subsequent observations. In addition  the performance of Gibbs and PF improves as the number of
samples/particles increases.
Figure 2(d) shows the performance of the three tasks on the Dartmouth data set. We do not apply
the same comparison because it takes too much time for sampling. From the graph  we can see that
VISKM infers most of the infectious moments of individuals in an accurate way for a large social
system. In addition  the smoothing results are slightly better than the prediction results because we
can leverage observations from both directions. The expansion case is relatively poor  because we
use only very limited information to derive the results; however  even in this case the ROC curve has
good discriminating power to differentiate between infectious and susceptible individuals.
Collective Statistics Inference: After determining the individual results  we aggregate them to
approximate the total number of infected individuals in the social system as time evolves. This offers
a collective statistical summary of the spread of disease in one area as in traditional research  which
typically scales the sample statistics with respect to the sample ratio. Figures 2(e) and (f) show
that given 20% of the Social Evolution data and 10% of the Dartmouth data  VISKM estimates the
collective statistics better than the other methods.
Efﬁciency and Scalability: Table 1 shows the running time of different algorithms for the Social
Evolution data on the same computer. From the table  we can see that Gibbs sampling runs slightly
longer than PF  but they are in the same scale. However  VISKM requires much less computation time.

2Code and data are available at http://cse.buffalo.edu/~wendong/.

7

 

e

t

 

a
R
e
v
i
t
i
s
o
P
e
u
r
T

 

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

1

0

 
0

0.1

 

e

t

 

a
R
e
v
i
t
i
s
o
P
e
u
r
T

 

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

1

0

 
0

0.1

VISKM−Smoothing
PF−Smoothing−10000
PF−Smoothing−1000
Gibbs−Smoothing−10000
Gibbs−Smoothing−1000
0.6

0.8

0.9

0.2

0.5

0.4

0.3

0.7
False Positive Rate
(b) Smoothing

VISKM−Expansion
PF−Expansion−10000
PF−Expansion−1000
Gibbs−Expansion−10000
Gibbs−Expansion−1000
0.6

0.8

0.9

0.2

0.5

0.4

0.3

0.7
False Positive Rate
(c) Expansion

VISKM−Prediction
PF−Prediction−10000
PF−Prediction−1000
Gibbs−Prediction−10000
Gibbs−Prediction−1000
0.6

0.8

0.9

0.2

0.5

0.4

0.3

0.7
False Positive Rate
(a) Prediction

 

1

 

 

45

40

35

30

25

20

15

10

5

s
t

n
e

i
t

a
P

 
f

o

 
r
e
b
m
u
N

1

0

 
0

20

40

 

Real Number
VISKM−Aggregation
PF−10000
Gibbs−10000
Scaling

150

100

50

s
t
n
e

i
t

a
P

 
f

o
 
r
e
b
m
u
N

Real Number
VISKM−Aggregation
Scaling

e

t

 

a
R
e
v
i
t
i
s
o
P
e
u
r
T

 

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

 
0

0.1

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

e
t
a
R
 
e
v
i
t
i
s
o
P
 
e
u
r
T

0

 
0

0.1

0.2

VISKM−Prediction
VISKM−Smoothing
VISKM−Expansion
0.7
False Positive Rate
(d) Dartmouth

0.8

0.3

0.4

0.5

0.6

0.9

60

80

Time Sequence

100

120

140

0

 
0

500

1000

1500

Time Sequence

2000

2500

3000

(e) Social Evolution Statistics

(f) Dartmouth Statistics

Figure 2: Experimental results. (a-c) show the prediction  smoothing  and expansion performance
comparisons for Social Evolution data  while (d) shows performance of the three tasks for Dartmouth
data. (e-f) represent the statistical inferences for both data sets.

Table 1: Running time for different approximate inference algorithms. Gibbs_10000 refers to Gibbs
sampling for 10 000 iterations  and PF_1000 to particle ﬁltering for 1000 iterations. Other entries
follow the same pattern. All times are measured in seconds.

VISKM Gibbs_1000 Gibbs_10000

PF_1000

PF_10000

60 People
30 People
15 People

0.78
0.39
0.19

771
255
101

7820
2556
1003

601
166
122

6100
1888
1435

In addition  the computation time of VISKM grows linearly with the number of individuals  which
validates the complexity analysis in Section 3.2. Thus  it offers excellent scalability for large social
systems. In comparison  Gibbs sampling and PF grow super linearly with the number of individuals 
and roughly linearly with the number of samples.
Summary: Our proposed VISKM achieves higher accuracy in terms of area under ROC curve
and collective statistics than Gibbs sampling or particle ﬁltering (within 10 000 iterations). More
importantly  VISKM is more efﬁcient than sampling with much less computation time. Additionally 
the computation time of VISKM grows linearly with the number of individuals  demonstrating its
excellent scalability for large social systems.

5 Conclusions

In this paper  we leverage sensor network and social network data to capture temporal evolution in
social dynamics and infer individual behaviors. In order to deﬁne the adaptive transition kernel  we
introduce a stochastic dynamic mode that captures the dynamics of complex interactions. In addition 
in order to make tractable inferences we propose a variational inference algorithm the computation
complexity of which grows linearly with the number of individuals. Large-scale experiments on
epidemic dynamics demonstrate that our method effectively captures the evolution of social dynamics
and accurately infers individual behaviors. More accurate collective effects can be also derived
through the aggregated results. Potential applications for our algorithm include the dynamics of
emotion  opinion  rumor  collaboration  and friendship.

8

References
[1] Adam Arkin  John Ross  and Harley H McAdams. Stochastic kinetic analysis of developmental
pathway bifurcation in phage -infected escherichia coli cells. Genetics  149(4):1633–1648 
1998. 1

[2] Matthew Brand  Nuria Oliver  and Alex Pentland. Coupled hidden markov models for complex

action recognition. In Proc. of CVPR  pages 994–999  1997. 1

[3] Claudio Castellano  Santo Fortunato  and Vittorio Loreto. Statistical physics of social dynamics.

Reviews of modern physics  81(2):591  2009. 1

[4] Ido Cohn  Tal El-Hay  Nir Friedman  and Raz Kupferman. Mean ﬁeld variational approximation
for continuous-time bayesian networks. The Journal of Machine Learning Research  11:2745–
2783  2010. 1

[5] Wen Dong  Katherine Heller  and Alex Sandy Pentland. Modeling infection with multi-agent
dynamics. In International Conference on Social Computing  Behavioral-Cultural Modeling 
and Prediction  pages 172–179. Springer  2012. 4.2

[6] Wen Dong  Bruno Lepri  and Alex Sandy Pentland. Modeling the co-evolution of behaviors
and social relationships using mobile phone data. In Proc. of the 10th International Conference
on Mobile and Ubiquitous Multimedia  pages 134–143. ACM  2011. 4.2

[7] Wen Dong  Alex Pentland  and Katherine A Heller. Graph-coupled hmms for modeling the

spread of infection. In Proc. of UAI  pages 227–236  2012. 4.2

[8] Arnaud Doucet and Adam M Johansen. A tutorial on particle ﬁltering and smoothing: Fifteen

years later. Handbook of Nonlinear Filtering  12(656-704):3  2009. 4.2

[9] Steven N Durlauf and H Peyton Young. Social dynamics  volume 4. MIT Press  2004. 1
[10] Stephen Eubank  Hasan Guclu  VS Anil Kumar  Madhav V Marathe  Aravind Srinivasan  Zoltan
Toroczkai  and Nan Wang. Modelling disease outbreaks in realistic urban social networks.
Nature  429(6988):180–184  2004. 1

[11] Daniel T Gillespie. Stochastic simulation of chemical kinetics. Annu. Rev. Phys. Chem. 

58:35–55  2007. 1

[12] Andrew Golightly and Darren J Wilkinson. Bayesian parameter inference for stochastic
biochemical network models using particle markov chain monte carlo. Interface focus  2011. 1
[13] Creighton Heaukulani and Zoubin Ghahramani. Dynamic probabilistic models for latent feature

propagation in social networks. In Proc. of ICML  pages 275–283  2013. 1

[14] Tom Heskes and Onno Zoeter. Expectation propagation for approximate inference in dynamic

bayesian networks. In Proc. of UAI  pages 216–223  2002. 1  3.2

[15] Matt J Keeling and Pejman Rohani. Modeling infectious diseases in humans and animals.

Princeton University Press  2008. 4.2

[16] David Kotz  Tristan Henderson  Ilya Abyzov  and Jihwang Yeo. CRAWDAD data set dart-
mouth/campus (v. 2007-02-08). Downloaded from http://crawdad.org/dartmouth/campus/  2007.
4.2

[17] Kevin Murphy and Stuart Russell. Rao-blackwellised particle ﬁltering for dynamic bayesian
networks. In Sequential Monte Carlo methods in practice  pages 499–515. Springer  2001. 1

[18] Uri Nodelman  Christian R Shelton  and Daphne Koller. Continuous time bayesian networks.

In Proc. of UAI  pages 378–387. Morgan Kaufmann Publishers Inc.  2002. 1  2.2

[19] Manfred Opper and Guido Sanguinetti. Variational inference for markov jump processes. In

Proc. of NIPS  pages 1105–1112  2008. 1

[20] V. Rao and Y. W. Teh. Fast MCMC sampling for markov jump processes and continuous time

bayesian networks. In Proc. of UAI  2011. 1

[21] Joshua W Robinson and Alexander J Hartemink. Learning non-stationary dynamic bayesian

networks. The Journal of Machine Learning Research  11:3647–3680  2010. 1

[22] Darren J Wilkinson. Stochastic modeling for systems biology. CRC press  2011. 1  2.2  2.2
[23] Jonathan S Yedidia  William T Freeman  and Yair Weiss. Understanding belief propagation and
its generalizations. Exploring artiﬁcial intelligence in the new millennium  8:236–239  2003.
3.2

9

,Zhen Xu
Wen Dong
Sargur Srihari
Zhe Wang
Kaiyi Ji
Yi Zhou
Yingbin Liang
Vahid Tarokh