2016,Truncated Variance Reduction: A Unified Approach to Bayesian Optimization and Level-Set Estimation,We present a new algorithm  truncated variance reduction (TruVaR)  that treats Bayesian optimization (BO) and level-set estimation (LSE) with Gaussian processes in a unified fashion. The algorithm greedily shrinks a sum of truncated variances within a set of potential maximizers (BO) or unclassified points (LSE)  which is updated based on confidence bounds.  TruVaR is effective in several important settings that are typically non-trivial to incorporate into myopic algorithms  including pointwise costs and heteroscedastic noise.  We provide a general theoretical guarantee for TruVaR covering these aspects  and use it to recover and strengthen existing results on BO and LSE.  Moreover  we provide a new result for a setting where one can select from a number of noise levels having associated costs.  We demonstrate the effectiveness of the algorithm on both synthetic and real-world data sets.,Truncated Variance Reduction: A Uniﬁed Approach
to Bayesian Optimization and Level-Set Estimation

Ilija Bogunovic1  Jonathan Scarlett1  Andreas Krause2  Volkan Cevher1

1 Laboratory for Information and Inference Systems (LIONS)  EPFL

2 Learning and Adaptive Systems Group  ETH Z¨urich

{ilija.bogunovic jonathan.scarlett volkan.cevher}@epﬂ.ch  krausea@ethz.ch

Abstract

We present a new algorithm  truncated variance reduction (TRUVAR)  that treats
Bayesian optimization (BO) and level-set estimation (LSE) with Gaussian pro-
cesses in a uniﬁed fashion. The algorithm greedily shrinks a sum of truncated
variances within a set of potential maximizers (BO) or unclassiﬁed points (LSE) 
which is updated based on conﬁdence bounds. TRUVAR is effective in several
important settings that are typically non-trivial to incorporate into myopic algo-
rithms  including pointwise costs and heteroscedastic noise. We provide a general
theoretical guarantee for TRUVAR covering these aspects  and use it to recover
and strengthen existing results on BO and LSE. Moreover  we provide a new result
for a setting where one can select from a number of noise levels having associated
costs. We demonstrate the effectiveness of the algorithm on both synthetic and
real-world data sets.

Introduction

1
Bayesian optimization (BO) [1] provides a powerful framework for automating design problems 
and ﬁnds applications in robotics  environmental monitoring  and automated machine learning  just
to name a few. One seeks to ﬁnd the maximum of an unknown reward function that is expensive
to evaluate  based on a sequence of suitably-chosen points and noisy observations. Numerous BO
algorithms have been presented previously; see Section 1.1 for an overview.
Level-set estimation (LSE) [2] is closely related to BO  with the added twist that instead of seeking
a maximizer  one seeks to classify the domain into points that lie above or below a certain thresh-
old. This is of considerable interest in applications such as environmental monitoring and sensor
networks  allowing one to ﬁnd all “sufﬁciently good” points rather than the best point alone.
While BO and LSE are closely related  they are typically studied in isolation. In this paper  we pro-
vide a uniﬁed treatment of the two via a new algorithm  Truncated Variance Reduction (TRUVAR) 
which enjoys theoretical guarantees  good computational complexity  and the versatility to handle
important settings such as pointwise costs  non-constant noise  and multi-task scenarios. The main
result of this paper applies to the former two settings  and even the ﬁxed-noise and unit-cost case 
we reﬁne existing bounds via a signiﬁcantly improved dependence on the noise level.
1.1 Previous Work
Three popular myopic techniques for Bayesian optimization are expected improvement (EI)  prob-
ability of improvement (PI)  and Gaussian process upper conﬁdence bound (GP-UCB) [1  3]  each
of which chooses the point maximizing an acquisition function depending directly on the current
posterior mean and variance. In [4]  the GP-UCB-PE algorithm was presented for BO  choosing
the highest-variance point within a set of potential maximizers that is updated based on conﬁdence
bounds. Another relevant BO algorithm is BaMSOO [5]  which also keeps track of potential max-
imizers  but instead chooses points based on a global optimization technique called simultaneous

1

online optimization (SOO). An algorithm for level-set estimation with GPs is given in [2]  which
keeps track of a set of unclassiﬁed points. These algorithms are computationally efﬁcient and have
various theoretical guarantees  but it is unclear how best to incorporate aspects such as pointwise
costs and heteroscedastic noise [6]. The same is true for the Straddle heuristic for LSE [7].
Entropy search (ES) [8] and its predictive version [9] choose points to reduce the uncertainty of
the location of the maximum  doing so via a one-step lookahead of the posterior rather than only
the current posterior. While this is more computationally expensive  it also permits versatility with
respect to costs [6]  heteroscedastic noise [10]  and multi-task scenarios [6]. A recent approach
called minimum regret search (MRS) [11] also performs a look-ahead  but instead chooses points to
minimize the regret. To our knowledge  no theoretical guarantees have been provided for these.
The multi-armed bandit (MAB) [12] literature has developed alongside the BO literature  with the
two often bearing similar concepts. The MAB literature is far too extensive to cover here  but we
brieﬂy mention some variants relevant to this paper. Extensive attention has been paid to the best-
arm identiﬁcation problem [13]  and cost constraints have been incorporated in a variety of forms
[14]. Moreover  the concept of “zooming in” to the optimal point has been explored [15]. In general 
the assumptions and analysis techniques in the MAB and BO literature are quite different.

1.2 Contributions

We present a uniﬁed analysis of Bayesian optimization and level-set estimation via a new algorithm
Truncated Variance Reduction (TRUVAR). The algorithm works by keeping track of a set of poten-
tial maximizers (BO) or unclassiﬁed points (LSE)  selecting points that shrink the uncertainty within
that set up to a truncation threshold  and updating the set using conﬁdence bounds. Similarly to ES
and MRS  the algorithm performs a one-step lookahead that is highly beneﬁcial in terms of versa-
tility. However  unlike these previous works  our lookahead avoids the computationally expensive
task of averaging over the posterior distribution and the observations.
Also in contrast with ES and MRS  we provide theoretical bounds for TRUVAR characterizing the
cost required to achieve a certain accuracy in ﬁnding a near-optimal point (BO) or in classifying
each point in the domain (LSE). By applying this to the standard BO setting  we not only recover
existing results [2  4]  but we also strengthen them via a signiﬁcantly improved dependence on the
noise level  with better asymptotics in the small noise limit. Moreover  we provide a novel result for
a setting in which the algorithm can choose the noise level  each coming with an associated cost.
Finally  we compare our algorithm to previous works on several synthetic and real-world data sets 
observing it to perform favorably in a variety of settings.

2 Problem Setup and Proposed Algorithm

Setup: We seek to sequentially optimize an unknown reward function f (x) over a ﬁnite domain
D.1 At time t  we query a single point xt 2 D and observe a noisy sample yt = f (xt) + zt  where
zt ⇠ N (0  2(xt)) for some known noise function 2(·) : D ! R+. Thus  in general  some points
may be noisier than others  in which case we have heteroscedastic noise [10]. We associate with
each point a cost according to some known cost function c : D ! R+. If both 2(·) and c(·) are
set to be constant  then we recover the standard homoscedastic and unit-cost setting.
We model f (x) as a Gaussian process (GP) [16] having mean zero and kernel function k(x  x0) 
normalized so that k(x  x) = 1 for all x 2 D. The posterior distribution of f given the points and
observations up to time t is again a GP  with the posterior mean and variance given by [10]

µt(x) = kt(x)TKt + ⌃t1yt
t(x)2 = k(x  x)  kt(x)TKt + ⌃t1kt(x) 
i=1  Kt =⇥k(xt  xt0)⇤t t0  and ⌃t = diag(2(x1)  . . .   2(xt)). We also

where kt(x) =⇥k(xi  x)⇤t
t1|x(x) denote the posterior variance of x upon observing x along with x1 ···   xt1.
1Extensions to continuous domains are discussed in the supplementary material.

(1)
(2)

let 2

2

Conﬁdence

Target

Selected point
Max. lower bound

Potential maximizers

(a) t = 6

(b) t = 7

(c) t = 8

(d) t = 9

Figure 1: An illustration of the TRUVAR algorithm. In (a)  (b)  and (c)  three points within the set
of potential maximizers Mt are selected in order to bring the conﬁdence bounds to within the target
range  and Mt shrinks during this process. In (d)  the target conﬁdence width shrinks as a result of
the last selected point bringing the conﬁdence within Mt to within the previous target.

We consider both Bayesian optimization  which consists of ﬁnding a point whose function value is
as high as possible  and level-set estimation  which consists of classifying the domain according into
points that lie above or below a given threshold h. The precise performance criteria for these settings
are given in Deﬁnition 3.1 below. Essentially  after spending a certain cost we report a point (BO)
or a classiﬁcation (LSE)  but there is no preference on the values of f (xt) for the points xt chosen
before coming to such a decision (in contrast with other notions such as cumulative regret).
TRUVAR algorithm: Our algorithm is described in Algorithm 1  making use of the updates
described in Algorithm 2. The algorithm keeps track of a sequence of unclassiﬁed points Mt 
representing potential maximizers for BO or points close to h for LSE. This set is updated
based on the conﬁdence bounds depending on constants (i). The algorithm proceeds in epochs 
where in the i-th epoch it seeks to bring the conﬁdence 1/2
(i) t(x) of points within Mt be-
It does this by greedily minimizing the sum of truncated variances
low a target value ⌘(i).
t1|x(x) ⌘ (i)} arising from choosing the point x  along with a normalization
max{(i)2
and division by c(x) to favor low-cost points. The truncation by ⌘(i) in this decision rule means that
once the conﬁdence of a point is below the current target value  there is no preference in making it
any lower (until the target is decreased). Once the conﬁdence of every point in Mt is less than a
factor 1 +  above the target value  the target conﬁdence is reduced according to a multiplication by
r 2 (0  1). An illustration of the process is given in Figure 1  with details in the caption.
For level-set estimation  we also keep track of the sets Ht and Lt  containing points believed to have
function values above and below h  respectively. The constraint x 2 Mt1 in (5)–(7) ensures that
{Mt} is non-increasing with respect to inclusion  and Ht and Lt are non-decreasing.

Px2Mt1

Algorithm 1 Truncated Variance Reduction (TRUVAR)
Input: Domain D  GP prior (µ0  0  k)  conﬁdence bound parameters > 0  r 2 (0  1)  {(i)}i1 
1: Initialize the epoch number i = 1 and potential maximizers M(0) = D.
2: for t = 1  2  . . . do
3:

⌘(1) > 0  and for LSE  level-set threshold h

Choose

xt = arg max

x2D Px2Mt1

max{(i)2

t1(x) ⌘ 2

(i)} Px2Mt1

c(x)

max{(i)2

t1|x(x) ⌘ 2

(i)}

.

(3)

4:

5:
6:

Observe the noisy function sample yt  and update according to Algorithm 2 to obtain Mt 
µt  t  lt and ut  as well as Ht and Lt in the case of LSE
while maxx2Mt 1/2

(i) t(x)  (1 + )⌘(i) do

Increment i  set ⌘(i) = r ⇥ ⌘(i1).

The choices of (i)    and r are discussed in Section 4. As with previous works  the kernel is
assumed known in our theoretical results  whereas in practice it is typically learned from training
data [3]. Characterizing the effect of model mismatch or online hyperparameter updates is beyond
the scope of this paper  but is an interesting direction for future work.

3

Algorithm 2 Parameter Updates for TRUVAR
Input: Selected points and observations {xt0}t
1: Update µt and t according to (1)–(2)  and form the upper and lower conﬁdence bounds

(i)   and for LSE  level-set threshold h.

t0=1  previous sets Mt1  Ht1  Lt1 

t0=1; {yt0}t

parameter 1/2

2: For BO  set

or for LSE  set

(i) t(x).

ut(x) = µt(x) + 1/2

(i) t(x) `

t(x) = µt(x)  1/2
`t(x) 
Mt =⇢x 2 Mt1 : ut(x)  max
Mt =x 2 Mt1 : ut(x)  h and `t(x)  h 

x2Mt1

(4)

(5)

(6)
(7)

Ht = Ht1 [x 2 Mt1 : `t(x) > h   Lt = Lt1 [x 2 Mt1 : ut(x) < h .

Some variants of our algorithm and theory are discussed in the supplementary material due to lack
of space  including pure variance reduction  non-Bayesian settings [3]  continuous domains [3]  the
batch setting [4]  and implicit thresholds for level-set estimation [2].

3 Theoretical Bounds

In order to state our results for BO and LSE in a uniﬁed fashion  we deﬁne a notion of ✏-accuracy
for the two settings. That is  we deﬁne this term differently in the two scenarios  but then we provide
theorems that simultaneously apply to both. All proofs are given in the supplementary material.
Deﬁnition 3.1. After time step t of TRUVAR  we use the following terminology:
• For BO  the set Mt is ✏-accurate if it contains all true maxima x⇤ 2 arg maxx f (x)  and all of
its points satisfy f (x⇤)  f (x)  ✏.
• For LSE  the triplet (Mt  Ht  Lt) is ✏-accurate if all points in Ht satisfy f (x) > h  all points in
2.
Lt satisfy f (x) < h  and all points in Mt satisfy |f (x)  h| ✏
In both cases  the cumulative cost after time t is deﬁned as Ct =Pt
t0=1 c(xt0).

We use ✏
2 in the LSE setting instead of ✏ since this creates a region of size ✏ where the function value
lies  which is consistent with the BO setting. Our performance criterion for level-set estimation is
slightly different from that of [2]  but the two are closely related.

3.1 General Result
Preliminary deﬁnitions: Suppose that the {(i)} are chosen to ensure valid conﬁdence bounds 
i.e.  lt(x)  f (x)  ut(x) with high probability; see Theorem 3.1 and its proof below for such
choices. In this case  we have after the i-th epoch that all points are either already discarded (BO)
or classiﬁed (LSE)  or are known up to the conﬁdence level (1 + )⌘(i). For the points with such
conﬁdence  we have ut(x)  lt(x)  2(1 + )⌘(i)  and hence

(8)
and similarly lt(x)  f (x)  2(1 + )⌘(i). This means that all points other than those within a gap
of width 4(1 + )⌘(i) must have been discarded or classiﬁed:

ut(x)  lt(x) + 2(1 + )⌘(i)  f (x) + 2(1 + )⌘(i) 

Mt ✓x : f (x)  f (x⇤)  4(1 + )⌘(i) =: M (i)
Mt ✓x : |f (x)  h| 2(1 + )⌘(i) =: M (i)

(BO)

(LSE)

Since no points are discarded or classiﬁed initially  we deﬁne M (0) = D.

(9)
(10)

4

For a collection of points S = (x01  . . .   x0

)  possibly containing duplicates  we write the total cost

as c(S) =P|S|i=1 c(x0i). Moreover  we denote the posterior variance upon observing the points up to
time t  1 and the additional points in S by t1|S(x). Therefore  c(x) = c({x}) and t1|x(x) =
t1|{x}(x). The minimum cost (respectively  maximum cost) is denoted by cmin = minx2D c(x)
(respectively  cmax = maxx2D c(x)).
Finally  we introduce the quantity

|S|

C⇤(⇠  M ) = min

S nc(S) : max

x2M

0|S(x)  ⇠o 

(11)

representing the minimum cost to achieve a posterior standard deviation of at most ⇠ within M.
Main result: In all of our results  we make the following assumption.
Assumption 3.1. The kernel k(x  x0) is such that the variance reduction function

is submodular [17] for any time t  and any selected points (x1  . . .   xt) and query point x.

 t x(S) = 2

t (x)  2

t|S(x)

(12)

2



and

⌘2
(i)

1/2
(i)

+ cmax 

C(i)  C⇤✓ ⌘(i)

This assumption has been used in several previous works based on Gaussian processes  and sufﬁcient
conditions for its validity can be found in [18  Sec. 8]. We now state the following general guarantee.
Theorem 3.1. Fix ✏> 0 and  2 (0  1)  and suppose there exist values {C(i)} and {(i)} such that
(13)

  M (i1)◆ log |M (i1)|(i)
(i)  2 log |D|Pi0i C(i0)2⇡2
C✏ = Xi : 4(1+)⌘(i1)>✏
then with probability at least 1    we have ✏-accuracy.
While this theorem is somewhat abstract  it captures the fact that the algorithm improves when points
having a lower cost and/or lower noise are available  since both of these lead to a smaller value of
C⇤(⇠  M ); the former by directly incurring a smaller cost  and the latter by shrinking the variance
more rapidly. Below  we apply this result to some important cases.

Then if TRUVAR is run with these choices of (i) until the cumulative cost reaches

C(i) 

(15)

(14)

6c2

min

.

3.2 Results for Speciﬁc Settings

Homoscedastic and unit-cost setting: Deﬁne the maximum mutual information [3]

1
2

(16)

T = max
x1 ... xT

log detIT + 2KT 
and consider the case that 2(x) = 2 and c(x) = 1. In the supplementary material  we provide a
theorem with a condition for ✏-accuracy of the form T  ⌦⇤ C1T T
log(1+2) 
thus matching [2  4] up to logarithmic factors. In the following  we present a reﬁned version that has
a signiﬁcantly better dependence on the noise level  thus exemplifying that a more careful analysis
of (13) can provide improvements over the standard bounding techniques.
Corollary 3.1. Fix ✏> 0 and  2 (0  1)  deﬁne T = 2 log |D|T 2⇡2
  and set ⌘(1) = 1 and r = 1
2.
There exist choices of (i) (not depending on the time horizon T ) such that we have ✏-accuracy with
probability at least 1   once the following condition holds:
T ✓22T T
+ 2l log2

✏2 + 1 with C1 =

16(1 + )2|D|T
 
(17)

32(1 + )2

96(1 + )2

+ C1T T

6(1 + )2

2

✏

✏2

✏2

6



2

1

where C1 =

1

log(1+2). This condition is of the form T  ⌦⇤ 2T T

✏2 + C1T T

m◆ log
2 + 1.

5

2 are made for mathematical convenience  and a similar result follows

The choices ⌘(1) = 1 and r = 1
for any other choices ⌘(1) > 0 and r 2 (0  1)  possibly with different constant factors.
As 2 ! 1 (i.e.  high noise)  both of the above-mentioned bounds have noise dependence O⇤(2) 
since log(1 + ↵1) = O(↵1) as ↵ ! 1. On the other hand  as 2 ! 0 (i.e.  low noise)  C1 is
logarithmic  and Corollary 3.1 is signiﬁcantly better provided that ✏ ⌧ .
Choosing the noise and cost: Here we consider the setting that there is a domain of points D0
that the reward function depends on  and alongside each point we can choose a noise variance 2(k)
(k = 1  . . .   K). Hence  D = D0⇥{1 ···   K}. Lower noise variances incur a higher cost according
to a cost function c(k).
Corollary 3.2. For each k = 1 ···   K  let T ⇤(k) denote the smallest value of T such that (17) holds
with 2(k) in place of 2  and with T = 2 log |D|T 2c2
. Then  under the preceding setting  there
6c2
exist choices of (i) (not depending on T ) such that we have ✏-accuracy with probability at least 1
once the cumulative cost reaches mink c(k)T ⇤(k).

max⇡2
min

This result roughly states that we obtain a bound as good as that obtained by sticking to any ﬁxed
choice of noise level. In other words  every choice of noise (and corresponding cost) corresponds to a
different version of a BO or LSE algorithm (e.g.  [2  4])  and our algorithm has a similar performance
guarantee to the best among all of those. This is potentially useful in avoiding the need for running
an algorithm once per noise level and then choosing the best-performing one. Moreover  we found
numerically that beyond matching the best ﬁxed noise strategy  we can strictly improve over it by
mixing the noise levels; see Section 4.

4 Experimental Results
We evaluate our algorithm in both the level-set estimation and Bayesian optimization settings.
Parameter choices: As with previous GP-based algorithms that use conﬁdence bounds  our theo-
retical choice of (i) in TRUVAR is typically overly conservative. Therefore  instead of using (14)
directly  we use a more aggressive variant with similar dependence on the domain size and time:
(i))  where t(i) is the time at which the epoch starts  and a is a constant. Instead
(i) = a log(|D|t2
of the choice a = 2 dictated by (14)  we set a = 0.5 for BO to avoid over-exploration. We found
exploration to be slightly more beneﬁcial for LSE  and hence set a = 1 for this setting. We found
TRUVAR to be quite robust with respect to the choices of the remaining parameters  and simply set
⌘(1) = 1  r = 0.1  and  = 0 in all experiments; while our theory assumes > 0  in practice there
is negligible difference between choosing zero and a small positive value.
Level-set estimation: For the LSE experiments  we use a common classiﬁcation rule in all al-
gorithms  classifying the points according to the posterior mean as ˆHt = {x : µt(x)  h} and
ˆLt = {x : µt(x) < h}. The classiﬁcation accuracy is measured by the F1-score (i.e.  the harmonic
mean of precision and recall) with respect to the true super- and sub-level sets.
We compare TRUVAR against the GP-based LSE algorithm [2]  which we name via the authors’
surnames as GCHK  as well as the state-of-the-art straddle (STR) heuristic [7] and the maximum
variance rule (VAR) [2]. Descriptions can be found in the supplementary material. GCHK includes
an exploration constant t  and we follow the recommendation in [2] of setting 1/2
Lake data (unit cost): We begin with a data set from the domain of environmental monitoring of
inland waters  consisting of 2024 in situ measurements of chlorophyll concentration within a vertical
transect plane  collected by an autonomous surface vessel in Lake Z¨urich [19]. As in [2]  our goal
is to detect regions of high concentration. We evaluate each algorithm on a 50 ⇥ 50 grid of points 
with the corresponding values coming from the GP posterior that was derived using the original data
(see Figure 2d). We use the Mat´ern-5/2 ARD kernel  setting its hyperparameters by maximizing the
likelihood on the second (smaller) available dataset. The level-set threshold h is set to 1.5.
In Figure 2a  we show the performance of the algorithms averaged over 100 different runs; here
the randomness is only with respect to the starting point  as we are in the noiseless setting. We ob-
serve that in this unit-cost case  TRUVAR performs similarly to GCHK and STR. All three methods
outperform VAR  which is good for global exploration but less suited to level-set estimation.

t = 3.

6

e
r
o
c
s

1
F

1

0.8

0.6

0.4

0.2

0

0

e
r
o
c
s

1
F

1

0.8

0.6

0.4

0.2

0

0

TruVaR

GCHK

STR

VAR

20

40

60

Time

80

100

120

e
r
o
c
s

1
F

1

0.9

0.8

0.7

0.6

0.5

TruVaR

GCHK

0.5

1

Cost (×104)

1.5

2

4

×10

TruVaR
GCHK high noise
GCHK medium noise
GCHK small noise

0.1

0.15

0.25

0.2
Cost (×104)

0.3

0.35

0.4

(a) Lake data  unit-cost

(b) Lake data  varying cost

(c) Synthetic data  varying noise

(d) Inferred concentration function

(e) Points chosen by GCHK

(f) Points chosen by TRUVAR

Figure 2: Experimental results for level-set estimation.

t
e
r
g
e
R
n
a
i
d
e
M

0

10

-2

10

-4

10

-6

10

TruVaR
EI
GP-UCB
ES
MRS

0

10

-2

10

-4

10

t
e
r
g
e
R
d
e
g
a
r
e
v
A

TruVaR
EI
GP-UCB
ES
MRS

0.27

r
o
r
r
E
n
o
i
t
a
d

i
l
a
V

0.26

0.25

TruVaR

EI

GP-UCB

0

20

40

60

Time

80

100

120

-6

10

0

20

40

60

Time

80

100

120

0.24

0

20

40

60

80

100

(a) Synthetic  median

(b) Synthetic  outlier-adjusted mean

Time

(c) SVM data

Figure 3: Experimental results for Bayesian optimization.

Lake data (varying cost): Next  we modify the above setting by introducing pointwise costs that
are a function of the previous sampled point x0  namely  cx0(x) = 0.25|x1  x01| + 4(|x2| + 1) 
where x1 is the vessel position and x2 is the depth. Although we did not permit such a dependence
on x0 in our original setup  the algorithm itself remains unchanged. Our choice of cost penalizes the
distance traveled |x1  x01|  as well as the depth of the measurement |x2|. Since incorporating costs
into existing algorithms is non-trivial  we only compare against the original version of GCHK that
ignores costs.
In Figure 2b  we see that TruVaR signiﬁcantly outperforms GCHK  achieving a higher F1 score
for a signiﬁcantly smaller cost. The intuition behind this can be seen in Figures 2e and 2f  where
we show the points sampled by TruVaR and GCHK in one experiment run  connecting all pairs of
consecutive points. GCHK is designed to pick few points  but since it ignores costs  the distance
traveled is large. In contrast  by incorporating costs  TRUVAR tends to travel small distances  often
even staying in the same x1 location to take measurements at multiple depths x2.
Synthetic data with multiple noise levels: In this experiment  we demonstrate Corollary 3.2 by
considering the setting in which the algorithm can choose the sampling noise variance and incur the
associated cost. We use a synthetic function sampled from a GP on a 50 ⇥ 50 grid with an isotropic
squared exponential kernel having length scale l = 0.1 and unit variance  and set h = 2.25. We use
three different noise levels  2 2{ 106  103  0.05}  with corresponding costs {15  10  2}.
We run GCHK separately for each of the three noise levels  while running TRUVAR as normal
and allowing it to mix between the noise levels. The resulting F1-scores are shown in Figure 2c.
The best-performing version of GCHK changes throughout the time horizon  while TRUVAR is
consistently better than all three. A discussion on how TRUVAR mixes between the noise levels can
be found in the supplementary material.

7

Bayesian optimization. We now provide the results of two experiments for the BO setting.
Synthetic data: We ﬁrst conduct a similar experiment as that in [8  11]  generating 200 different
test functions deﬁned on [0  1]2. To generate a single test function  200 points are chosen uniformly
at random from [0  1]2  their function values are generated from a GP using an isotropic squared ex-
ponential kernel with length scale l = 0.1 and unit variance  and the resulting posterior mean forms
the function on the whole domain [0  1]2. We subsequently assume that samples of this function are
corrupted by Gaussian noise with 2 = 106. The extension of TRUVAR to continuous domains is
straightforward  and is explained in the supplementary material. For all algorithms considered  we
evaluate the performance according to the regret of a single reported point  namely  the one having
the highest posterior mean.
We compare the performance of TRUVAR against expected improvement (EI)  GP-upper conﬁdence
bound (GP-UCB)  entropy search (ES) and minimum regret search (MRS)  whose acquisition func-
tions are outlined in the supplementary material. We use publicly available code for ES and MRS
[20]. The exploration parameter t in GP-UCB is set according to the recommendation in [3] of
dividing the theoretical value by ﬁve  and the parameters for ES and MRS are set according to the
recommendations given in [11  Section 5.1].
Figure 3a plots the median of the regret  and Figure 3b plots the mean after removing outliers (i.e. 
the best and worst 5% of the runs). In the earlier rounds  ES and MRS provide the best performance 
while TRUVAR improves slowly due to exploration. However  the regret of TRUVAR subsequently
drops rapidly  giving the best performance in the later rounds after “zooming in” towards the max-
imum. GP-UCB generally performs well with the aggressive choice of t  despite previous works’
experiments revealing it to perform poorly with the theoretical value.
Hyperparameter tuning data: In this experiment  we use the SVM on grid dataset  previously used
in [21]. A 25 ⇥ 14 ⇥ 4 grid of hyperparameter conﬁgurations resulting in 1400 data points was pre-
evaluated  forming the search space. The goal is to ﬁnd a conﬁguration with small validation error.
We use a Mat´ern-5/2 ARD kernel  and re-learn its hyperparameters by maximizing the likelihood
after sampling every 3 points. Since the hyperparameters are not ﬁxed in advance  we replace Mt1
by D in (5) to avoid incorrectly ruling points out early on  allowing some removed points to be
added again in later steps. Once the estimated hyperparameters stop to vary signiﬁcantly  the size
of the set of potential maximizers decreases almost monotonically. Since we consider the noiseless
setting here  we measure performance using the simple regret  i.e.  the best point found so far.
We again average over 100 random starting points  and plot the resulting validation error in Fig-
ure 3c. Even in this noiseless and unit-cost setting that EI and GP-UCB are suited to  we ﬁnd that
TRUVAR performs slightly better  giving a better validation error with smaller error bars.

5 Conclusion

rated into the acquisition function.

rithm can choose both a point and a noise level  cf.  Corollary 3.2.

TRUVAR and its theoretical guarantees are essentially identical in both cases

We highlight the following aspects in which TRUVAR is versatile:
• Uniﬁed optimization and level-set estimation: These are typically treated separately  whereas
• Actions with costs: TRUVAR naturally favors cost-effective points  as this is directly incorpo-
• Heteroscedastic noise: TRUVAR chooses points that effectively shrink the variance of other
points  thus directly taking advantage of situations in which some points are noisier than others.
• Choosing the noise level: We provided novel theoretical guarantees for the case that the algo-
Hence  TRUVAR directly handles several important aspects that are non-trivial to incorporate into
myopic algorithms. Moreover  compared to other BO algorithms that perform a lookahead (e.g. 
ES and MRS)  TRUVAR avoids the computationally expensive task of averaging over the posterior
and/or measurements  and comes with rigorous theoretical guarantees.
Acknowledgment: This work was supported in part by the European Commission under Grant
ERC Future Proof  SNF Sinergia project CRSII2-147633  SNF 200021-146750  and EPFL Fellows
Horizon2020 grant 665667.

8

References
[1] B. Shahriari  K. Swersky  Z. Wang  R. P. Adams  and N. de Freitas  “Taking the human out of
the loop: A review of Bayesian optimization ” Proc. IEEE  vol. 104  no. 1  pp. 148–175  2016.
[2] A. Gotovos  N. Casati  G. Hitz  and A. Krause  “Active learning for level set estimation ” in

Int. Joint. Conf. Art. Intel.  2013.

[3] N. Srinivas  A. Krause  S. Kakade  and M. Seeger  “Information-theoretic regret bounds for
Gaussian process optimization in the bandit setting ” IEEE Trans. Inf. Theory  vol. 58  no. 5 
pp. 3250–3265  May 2012.

[4] E. Contal  D. Buffoni  A. Robicquet  and N. Vayatis  Machine Learning and Knowledge Dis-
covery in Databases. Springer Berlin Heidelberg  2013  ch. Parallel Gaussian Process Opti-
mization with Upper Conﬁdence Bound and Pure Exploration  pp. 225–240.

[5] Z. Wang  B. Shakibi  L. Jin  and N. de Freitas  “Bayesian multi-scale optimistic optimization ”

http://arxiv.org/abs/1402.7005.

[6] K. Swersky  J. Snoek  and R. P. Adams  “Multi-task Bayesian optimization ” in Adv. Neur. Inf.

Proc. Sys. (NIPS)  2013  pp. 2004–2012.

[7] B. Bryan and J. G. Schneider  “Actively learning level-sets of composite functions ” in Int.

Conf. Mach. Learn. (ICML)  2008.

[8] P. Hennig and C. J. Schuler  “Entropy search for information-efﬁcient global optimization ” J.

Mach. Learn. Research  vol. 13  no. 1  pp. 1809–1837  2012.

[9] J. M. Hern´andez-Lobato  M. W. Hoffman  and Z. Ghahramani  “Predictive entropy search for
efﬁcient global optimization of black-box functions ” in Adv. Neur. Inf. Proc. Sys. (NIPS)  2014 
pp. 918–926.

[10] P. W. Goldberg  C. K. Williams  and C. M. Bishop  “Regression with input-dependent noise:
A Gaussian process treatment ” Adv. Neur. Inf. Proc. Sys. (NIPS)  vol. 10  pp. 493–499  1997.
[11] J. H. Metzen  “Minimum regret search for single-and multi-task optimization ” in Int. Conf.

Mach. Learn. (ICML)  2016.

[12] S. Bubeck and N. Cesa-Bianchi  Regret Analysis of Stochastic and Nonstochastic Multi-Armed

Bandit Problems  ser. Found. Trend. Mach. Learn. Now Publishers  2012.

[13] K. Jamieson and R. Nowak  “Best-arm identiﬁcation algorithms for multi-armed bandits in the

ﬁxed conﬁdence setting ” in Ann. Conf. Inf. Sci. Sys. (CISS)  2014  pp. 1–6.

[14] O. Madani  D. J. Lizotte  and R. Greiner  “The budgeted multi-armed bandit problem ” in

Learning Theory. Springer  2004  pp. 643–645.

[15] R. Kleinberg  A. Slivkins  and E. Upfal  “Multi-armed bandits in metric spaces ” in Proc. ACM

Symp. Theory Comp.  2008.

[16] C. E. Rasmussen  “Gaussian processes for machine learning.” MIT Press  2006.
[17] A. Krause and D. Golovin  “Submodular function maximization ” Tractability: Practical Ap-

proaches to Hard Problems  vol. 3  2012.

[18] A. Das and D. Kempe  “Algorithms for subset selection in linear regression ” in Proc. ACM

Symp. Theory Comp. (STOC). ACM  2008  pp. 45–54.

[19] G. Hitz  F. Pomerleau  M.-E. Garneau  E. Pradalier  T. Posch  J. Pernthaler  and R. Y. Siegwart 
“Autonomous inland water monitoring: Design and application of a surface vessel ” IEEE
Robot. Autom. Magazine  vol. 19  no. 1  pp. 62–72  2012.

[20] http://github.com/jmetzen/bayesian optimization (accessed 19/05/2016).
[21] J. Snoek  H. Larochelle  and R. P. Adams  “Practical Bayesian optimization of machine learn-

ing algorithms ” in Adv. Neur. Inf. Proc. Sys.  2012.

[22] K. Swersky  J. Snoek  and R. P. Adams  “Freeze-thaw Bayesian optimization ” 2014 

http://arxiv.org/abs/1406.3896.

[23] D. R. Jones  C. D. Perttunen  and B. E. Stuckman  “Lipschitzian optimization without the

Lipschitz constant ” J. Opt. Theory Apps.  vol. 79  no. 1  pp. 157–181  1993.

[24] A. Krause and C. Guestrin  “A note on the budgeted maximization of submodular functions ”

2005  Technical Report.

9

,Akshay Balsubramani
Yoav Freund
Ilija Bogunovic
Jonathan Scarlett
Andreas Krause
Volkan Cevher