2009,Efficient Moments-based Permutation Tests,In this paper  we develop an efficient moments-based permutation test approach to improve the system’s efficiency by approximating the permutation distribution of the test statistic with Pearson distribution series. This approach involves the calculation of the first four moments of the permutation distribution. We propose a novel recursive method to derive these moments theoretically and analytically without any permutation.  Experimental results using different test statistics are demonstrated using simulated data and real data. The proposed strategy takes advantage of nonparametric permutation tests and parametric Pearson distribution approximation to achieve both accuracy and efficiency., 

Efficient Moments-based Permutation Tests 

 
 

Chunxiao Zhou Huixia Judy Wang 
 Dept. of Statistics 

 Dept. of Electrical and Computer Eng. 
 University of Illinois at Urbana-Champaign 
 Champaign  IL 61820 Raleigh  NC 27695 
 czhou4@gmail.com 
 wang@stat.ncsu.edu 

North Carolina State University 

 

Yongmei Michelle Wang 

Depts. of Statistics  Psychology  and Bioengineering 

University of Illinois at Urbana-Champaign 

Champaign  IL 61820 

 ymw@illinois.edu 

Abstract 

In this paper  we develop an efficient moments-based permutation test 
approach to improve the test(cid:8217)s computational efficiency by approximating 
the permutation distribution of the test statistic with Pearson distribution 
series. This approach involves the calculation of the first four moments of 
the permutation distribution. We propose a novel recursive method to derive 
these moments theoretically and analytically without any permutation. 
Experimental results using different test statistics are demonstrated using 
simulated data and real data. The proposed strategy takes advantage of 
nonparametric permutation 
tests and parametric Pearson distribution 
approximation to achieve both accuracy and efficiency. 

 
Introduction 

1 
Permutation tests are flexible nonparametric alternatives to parametric tests in small 
samples  or when the distribution of a test statistic is unknown or mathematically intractable. 
In permutation tests  except exchangeability  no other statistical assumptions are required. 
The p-values can be obtained by using the permutation distribution. Permutation tests are 
appealing in many biomedical studies  which often have limited observations with unknown 
distribution. They have been used successfully in structural MR image analysis [1  2  3]  in 
functional MR image analysis [4]  and in 3D face analysis [5]. 
There are three common approaches to construct the permutation distribution [6  7  8]: (1) 
exact permutation enumerating all possible arrangements; (2) approximate permutation 
based on random sampling from all possible permutations; (3) approximate permutation 
using the analytical moments of the exact permutation distribution under the null hypothesis. 
The main disadvantage of the exact permutation is the computational cost  due to the 
factorial increase in the number of permutations with the increasing number of subjects. The 
second technique often gives inflated type I errors caused by random sampling. When a large 
number of repeated 
is also 
computationally expensive to achieve satisfactory accuracy. Regarding the third approach  
the exact permutation distribution may not have moments or moments with tractability. In 
most applications  it is not the existence but the derivation of moments that limits the third 
approach. 

the random permutation strategy 

tests are needed  

To the best of our knowledge  there is no systematic and efficient way to derive the moments 
of the permutation distribution. Recently  Zhou [3] proposed a solution by converting the 
permutation of data to that of the statistic coefficients that are symmetric to the permutation. 
Since the test statistic coefficients usually have simple presentations  it is easier to track the 
permutation of the test statistic coefficients than that of data. However  this method requires 
the derivation of the permutation for each specific test statistic  which is not accessible to 
practical users. 
In this paper  we propose a novel strategy by employing a general theoretical method to 
derive the moments of the permutation distribution of any weighted v-statistics  for both 
univariate and multivariate data. We note that any moments of the permutation distribution 
for weighted v-statistics [9] can be considered as a summation of the product of data 
function term and index function term over a high dimensional index set and all possible 
permutations. Our key idea is to divide the whole index set into several permutation 
equivalent (see Definition 2) index subsets such that the summation of the data/index 
function term over all permutations is invariant within each subset and can be calculated 
without conducting any permutation. Then we can obtain the moments by summing up 
several subtotals. The proposed method can be extended to equivalent weighted v-statistics 
by replacing them with monotonic weighted v-statistics. This is due to the fact that only the 
order of test statistics of all permutations matters for obtaining the p-values  so that the 
monotonic weighted v-statistics shares the same p-value with the original test statistic. Given 
the first four moments  the permutation distribution can be well fitted by Pearson 
distribution series. The p-values are then obtained without conducting any real permutation. 
For multiple comparison of two-group difference  given the sample size n1 = 21 and n2 = 21  
the number of tests m = 2 000  we need to conduct m×(n1+ n2)!/n1!/n2! (cid:8776) 1.1×1015 
permutations for the exact permutation test. Even for 20 000 random permutations per test  
we still need m×20 000 (cid:8776) 4×107 permutations. Alternatively  our moments-based permutation 
method using Pearson distribution approximation only involves the calculation of the first 
four analytically-derived moments of exact permutation distributions to achieve high 
accuracy (see section 3). Instead of calculating test statistics in factorial scale with exact 
permutation  our moments-based permutation only requires computation of polynomial 
order. For example  the computational cost for univariate mean difference test statistic and 
modified multivariate Hotelling's T2 test statistics [8] are O(n) and O(n3)  respectively  where 
n = n1+ n2. 
 
2 
In this section  we shall mainly discuss how to calculate the moments of the permutation 
distribution for weighted v-statistics. For other test statistics  a possible solution is to 
replace them with their equivalent weighted v-statistics by monotonic transforms. The 
detailed discussion about equivalent test statistics can be found in [7  8  10]. 
 
2. 1 
Let us first look at a toy example. Suppose we have a two-group univariate data 
  where the first n1 elements are in group A and the rest  n2  are 
x
in group B. For comparison of the two groups  the hypothesis is typically constructed as: 
H
m m are the population means of the groups A 
 A
and 

Comp utational c halle nge 

as the sample means of two 

and B  respectively. Define 

M ethodology 

= L

x
n n
+
1

 vs. 

B
x

m„

m=

x
n
1

x
n
1

:a

0 :

L

x
1

H

m

m

1
+

x

(

)

A

B

A

 

 

2

 

 

 

B

  where 
n
1
= (cid:229)
i
1
=

x n
i
1

/

A

n
= (cid:229)
i n
1
= +
1

B

x n
i

/

2

groups  where n=n1+n2. We choose the univariate group mean difference as the test 
w i x
  where 
statistic  
  
( )
=
i
+ L . Then the total number of all possible 
n
n
i
w i
  }
1 
1{
( )
  }nL is n!. To calculate the fourth moment of the permutation 

n
= (cid:229)
B
i
1
=
n
  if 
1/
2

function 

A
= -

( ) 1/

index 

i.e.  
n
1

T x
( )
˛ L and 
if
permutations of {1 
distribution  

the 

w i

{1 

n
1

˛

=

-

}

x

x

i

 

 

 

4

E T x
p

( ))=

(

1
n
!

n
(cid:229) (cid:229)
S
1
˛
=

(

i

n

p

w i x
( )
p

i
( )

4
) =

1
n
!

n

n

n

n
(cid:229) (cid:229) (cid:229) (cid:229) (cid:229)
S i
i
1
˛
=
n
1
4

1
=

1
=

1
=

i
2

i
3

p

w i w i w i w i x
( )
)
1
p

(

(

(

)

)

3

4

2

x
p

i
( )
1

(

i
2

)

x
p

(

i
3

)

x
p

(

i
4

)

  

where (cid:960) is the permutation operator and the symmetric group Sn [11] includes all distinct 
permutations. The above example shows that the moment calculation can be considered as a 
summation over all possible permutations and a large index set. It is noticeable that the 
computational challenge here is to go through the factorial level permutations and 
polynomial level indices. 
 
2. 2 
In this paper  we assume that the test statistic T can be expressed as a weighted v-statistic of 
degree d [9]  that is  
 is a data 

Par tition the inde x se t 

  where 

 

L

 

)T

x

x

x

=

(

T x
( )

 

L

 

L

 

x
1

 

2

n

i h x
) (
i
d
1

x
)d
i

n
n
(cid:229)L
= (cid:229)
i
1
1
=
=
1

i
d

w i
(  
1

with n observations  and w is a symmetric index function. h is a symmetric data function  
iL . Though the symmetry property is not required 
i.e.  invariant under permutation of 
kx can be 
for our method  it helps reduce the computational cost. Here  each observation 
either univariate or multivariate. In the above toy example  d=1 and h is the identity 
function. Therefore  the r-th moment of the test statistic from the permutated data is: 

i
1(  

)d

 

r

E T x
p

( ))

(

=

E
p

(

(cid:229)
L
i
 
 
d

i
i
 
1 2

w i
(  
1

L

 

i h x
) (
d
p

 

L

 

x
p

))

(

i
d

)

i
( )
1

r

 

r
{
(cid:213)
k
1
=

=

E
p

[
(1)
i
1
L
r
( )
i
1

(cid:229)
L
i
 
 
d

(1)

 

r
( )

L
i
 
 
d

k
( )
w i
(
1

 

L

 

i
d

k
( )

)

r
(cid:213)
k
1
=

h x
(
p

k

)

(

(
i
1

)

 

L

 

x
p

(

i
d

(

k

)

)

)}] .

 

Then we can exchange the summation order of permutations and that of indices  

r

E T x
( ))
p

(

{(

r
(cid:213)
k
1
=

=

(cid:229)
L
i
 
 
d

(1)

 

r
( )

L
i
 
 
d

(1)
i
1
L
r
( )
i
1

k
( )
w i
(
1

 

L

 

i
d

k
( )

))

E
p

(

r
(cid:213)
k
1
=

h x
(
p

k

)

(

(
i
1

)

 

L

 

x
p

(

i
d

(

k

)

)

))}.

 

Thus any moment of permutation distribution can be considered as a summation of the 
product of data function term and index function term over a high dimensional index set and 
all possible permutations. 
Since all possible permutations map any index value between 1 and n to all possible index 
values from 1 to n with equal probability  
  the summation of 
data function over all permutations is only related to the equal/unequal relationship among 
indices. It is natural to divide the whole index set 
 
L

h x
(
p

r
(cid:213)
k
1
=

E
p

x
p

L

{(

U

(
i
1(

))

L

)
 

=

=

i
d

(

(1)

 

 

(

)

)

 

 

k

k

(

)

)

(1)
i
1

i
d

 

d

)

)

(

k

)

 

 

 

(

k

)

 

L

r
( )

i
d

x
p

))

(
i
1(

iL
 

)d

r
( )
i
1

i
1(  

iL and 

 into the union of disjoint index subsets  in which 

)}
(
 
is invariant. 
Definition 1. Since h is a symmetric function  two index elements 
 
)d
are said to be equivalent if they are the same up to the order. For example  for d = 3  (1  4  5) 
= (1 5 4) = (4 1 5) = (4 5 1) = (5 1 4) = (5 4 1). 
Definition 2. Two indices 
 are 
(
)
L
 
 
said to be permutation equivalent/(cid:8801) if there exists a permutation 
p ˛ such that 
. Here "=" means they 
{(
p
have same index elements by Definition 1. For example  for d = 2  n = 4  r = 2  {(1  2)  (2  
3)} (cid:8801) {(2  4)  (1  4)} since we can apply (cid:960): 1(cid:8594)1  2(cid:8594)4  3(cid:8594)2  4(cid:8594)3  such that {( (cid:960)(1)  (cid:960)(2))  
((cid:960)(2)  (cid:960)(3))} = {(1  4)  (4  2)}= {(2  4)  (1  4)}. As a result  the whole index set for d = 2  r = 
2  can be divided into seven permutation equivalent subsets  [{(1  1)  (1  1)}]  [{(1  1)  (1  
2)}]  [{(1  1)  (2  2)}]  [{(1  2)  (1  2)}]  [{(1  1)  (2  3)}]  [{(1  2)  (1  3)}]  [{(1  2)  (3  4)}]  
where [ ] denotes the equivalence class. Note that the number of the permutation equivalent 
subsets is only related to the order of weighted v-test statistic d and the order of moment r   

L
 
nS

))} {(

 and 

jL
 

{(
i
1

j
1(

r
( )
j
1

r
( )
i
1

(1)
j
1

(
p

{(

)}

)}

)}

))

p

p

=

L

L

L

L

L

L

L

L

L

L

i
d

i
d

j
1

i
1

j
1

i
1

(

(

(

(

(

(

)

)

)

)

r
( )

r
( )

r
( )

r
( )

r
( )

(1)

(

r

)

(1)

(1)

(1)

(1)

 

i

(1)

(1)

j

d

j

d

j

d

i

d

j

d

 

d

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

L
i
1{  
r
E
(
(cid:213)
p
k
1
=

r
i
  }
d
h x
(
p

but not related to the data size n  and it is small for the first several moments calculation 
(small r) with low order test statistics (small d). 
Using the permutation equivalent relationship defined in Definition 2  the whole index set U 
can be partitioned into several permutation equivalent index subsets. Then we can calculate 
the r-th moment by summing up subtotals of all index subsets. This procedure can be done 
without any real permutations based on Proposition 1 and Proposition 2 below. 

Proposition 1. We claim that the data function sum 
within each equivalent index subset  and 

E
p

(

r
(cid:213)
k
1
=

h x
(
p

k

)

(
i
1(

)

 

L

 

x
p

(

i
d

(

k

)

)

))

 is invariant 

h x
(

r
(cid:213)
k
1
=
r
( )
)}])

L
 

 

x

k

)

)

)

(

 

 

 

 

 

k

)

)

(1)

(1)

r
( )

(

(

k

)

j
d

{(

(
j
1

(

i
d

(
i
1

=

(1)

) 

))

L
 
 

i
d

 (

(1)
j
1

x
p

L
) 
 (

L

L

L

E
p

([{(

(1)
i
1

r
( )
i
1

card

h x
(
p

L
i
 
 
d
(1)
i
d

L
i
 
 
d
r
( )
L
i
 
1

r
( )
L
i
) 
 (
1
L
 (
) 

(cid:229)
r
r
(1)
( )
( )
L
i
j
j
 
)} [{(
 
˛
d
1
1
(1)
L
card
i
 
([{(
1
r
( )
 is the number of indices falling into the 
)}])
(1)
L
i
 
 
d

r
(cid:213)
k
1
=
where 
 
permutation equivalent index subset 
Proof sketch: 
Since all indices in the same permutation equivalent subset are equivalent with respect to the 
symmetric group Sn  
r
(
(cid:213)
k
1
=

L
i
 
d
(1)
i
[{(
1

r
(cid:213)
k
1
=

h x
(
p

h x
(
p

)}]
i
 
d

(cid:229)
S
p˛

1
n
!

r
( )
i
1

)}]

E
p

L

L

L

L

x
p

x
p

i
d

 (

))

r
( )

) 

. 

=

=

(
i
1

(
i
1

(

i
d

(

i
d

(

k

)

(

k

)

j
d

(

k

)

)

 

k

)

)

k

)

)

 

 

 

 

 

 

 

(

(

)

)

n

{(

(1)
j
1

L
 
 

j
d

(1)

L
) 
 (

=

r
( )
j
1

(cid:229)
r
(1)
( )
L
i
j
 
)} [{(
 
˛
d
1
(1)
i
card
 
([{(
1

L
i
 
d
L
i
 
d

r
( )
(
(1)
L
L
i
i
 (
 
) 
d
1
r
( )
(1)
L
i
 (
) 
1
n
!

{(

(1)
j
1

L
 
 

j
d

(1)

L
) 
 (

=

(
j
1

)

r

L
 
 
card

)

(

r
j
d
([{(

(cid:229)
(1)
L
i
 
)} [{(
 
˛
1
(1)
L
i
i
 
 
d
1

(1)

i
d
(1)

L
 (
) 
L
) 

r
( )
L
i
 
 
1
r
( )
i
 (
1

i
d
 

(

r

)

L

)}]
i
 
d

(

h x
(

r
(cid:213)
k
1
=
r
( )
)}])

h x
(

 

L

 

x

)

n

!)

(

k

)

j
d

k

)

(
j
1

(

r
(cid:213)
k
1
=
r
( )
i
d

r
 

)

)}]
L

 

)}])

 

L

 

x

))

(

k

)

j
d

k

)

(
j
1

 

 

.

 

Proposition 2. Thus we can obtain the r-th moment by summing up the production of the 
data partition sum wl and the index partition sum hl over all permutation equivalent 
subsets  i.e.  
E T x
p

is any permutation 

  where 

(1)
i
[{(
1

r
( )
i
 (
1

w h
l l

( ))

)}]

L

L

L

i
d

i
d

l =

r
( )

) 

(1)

(

 

 

 

 

 

r

= (cid:229)
U
[
l˛

]

equivalent subset of the whole index set U. [U] denotes the set of all distinct permutation 
equivalent classes of U. The data partition sum is 
))

h x
(

L

x

 

 

k

k

(

)

)

(
j
1

j
d

{(

(1)
j
1

L
 
 

j
d

(1)

r
( )
j
1

L
 
 

(cid:229)
L
) 
 (

h
l

=

(

r
(cid:213)
k
1
j
=
)}
l
˛
d
card
( )
l

r
( )

 

and the index partition sum is 

(cid:229)
L
) 
 (

(1)

(

r
(cid:213)
k
1
=

w x
(

k

)

(
j
1

 

L

 

x

(

k

)

j
d

)) .

 

r
( )
j
1

L
 
 

j
d

r
( )

)}
l
˛

w
l

=

{(

(1)
j
1

L
 
 

j
d

 
Proof sketch: 

With Proposition 1  
subset  therefore  
r

E T x
p

( ))

(

E
p

(

r
(cid:213)
k
1
=

h x
(
p

k

)

(
i
1(

)

 

L

 

x
p

(

i
d

(

k

)

)

))

 is invariant within each equivalent index 

{(

r
(cid:213)
k
1
=

=

(cid:229)
L
i
 
 
d

(1)

 

r
( )

L
 
 

i
d

(1)
i
1
L
r
(
i
1

)

k
( )
w i
(
1

 

L

 

i
d

k
( )

))

E
p

(

r
(cid:213)
k
1
=

h x
(
p

k

)

(

(
i
1

)

 

L

 

x
p

(

i
d

(

k

)

)

))}

=

 

=

(cid:229)
U
[
˛

l

]

{(

(1)
j
1

L
 
 

j
d

(1)

(cid:229)
L
) 
 (

r
( )
j
1

L
 
 

j
d

r
( )

)}
l
˛

{(

r
(cid:213)
k
1
=

k
( )
w j
(
1

 

L

 

j
d

k
( )

))

E
p

(

r
(cid:213)
k
1
=

h x
(
p

(

(
j
1

k

)

)

 

L

 

x
p

(

j
d

(

k

)

)

))}

=

 

=

(cid:229)
U
[
˛

l

]

{(

(cid:229)
L
) 
 (

(1)

(1)
j
1

L
 
 

j
d

r
( )
j
1

L
 
 

j
d

r
{
(cid:213)
k
1
=

r
( )

)}
l
˛

k
( )
w j
(
1

 

L

 

j
d

k
( )

)

h
l

}

=

w h
l l

.

 

(cid:229)
U
[
˛

l

]

Re c ur sive c alc ulation 

 
Since both data partition sum wl and the index partition sum hl can be calculated by 
summation over all distinct indices within each permutation equivalent index subset  no any 
real permutation is needed for computing the moments. 
 
2. 3 
Direct calculation of the data partition sum and index partition sum leads to traversing 
throughout the whole index set. So the computational cost is O(ndr). In the following  we 
shall discuss how to reduce the cost by a recursive calculation algorithm. 
Definition 3. Let 
. 
l and n are two different permutation equivalent subsets of the whole index set U. We say 
lp   if l can be converted to n 
that the partition order of n is less than that of l   i.e.  n
by merging two or more index elements. For instance  
[(1 2) (3  4)]  
 
n
since by merging 1 and 2  l is converted to [{(1  1)  (3  4)}] = [{(1  1)  (2  3)}]. [{(1  1)  (3  
4)}] and [{(1  1)  (2  3)}] are the same permutation equivalent index subsets because we can 
apply the permutation ¹: 1(cid:8594)1  2(cid:8594)4  3(cid:8594)3  4(cid:8594)2 to [{(1  1)  (3  4)}]. Note that the merging 
operation may not be unique  for example  n can also be converted to l by merging 3 and 
4. To clarify the concept of partition order  we list the order of all partitions when d=2 and 
r=2 in figure 1. The partition order of a permutation equivalent subset n is said to be lower 
than that of another permutation equivalent subset l if there is a directed path from l to n . 

[(1 1) (2 3)]

=p

 and 

r
( )
i
1

(1)
i
1

n =

l =

[{(

)}]

r
( )
j
1

(1)
j
1

L

L

L

i
d

 (

i
d

)]

[(

r
( )

) 

(1)

l

=

L

L

L

)
 

(

r
( )

(1)

 

 

 

 

j

j

d

d

 

 

 

 

 

 
 
 
 
 
 
 
 (
{
)
[ 1  1   1 1

}
)
]

 
 

 
[

(

[

{
(
1  1   2  2

(

)

{
(
1  1   1  2

(

)

[

{
(
1  2   1  2

(

)

}
)
]

}
)
]

}
)
]

{
(
[ 1  1   2   3

(

)

{
(
[ 1  2   1  3

(

)

}
)
]

}
)
]

[

{
(
1  2   3  4

(

)

}
)
]

 

Figure 1: Order of all permutation equivalent subsets when d = 2 and r = 2. 

The difficulty for computing data partition sum and index partition sum comes from two 
constraints; equal constraint and unequal constraint. For example  in the permutation 
equivalent subset [{(1  1)  (2  2)}]  the equal constraint is that the first and the second index 
number are equal and the third and fourth index are also equal. On the other hand  the 
unequal constraint requires that the first two index numbers are different from those of the 
last two. Due to the difficulties mentioned  we solve this problem by first relaxing the 
unequal constraint and then applying the principle of inclusion and exclusion. Thus  the 
calculation of a partition sum can be separated into two parts: the relaxed partition sum 
without unequal constraint  and lower order partition sums. For example  
w
l

w i i w j
(   )

[(1 1)  (2 2)]*
=

[(1 1)  (2 2)]
=

[(1 1)  (1 1)]
=

(   ))

w
l

w
l

-

=

=

=

(

j

 

(cid:229)
i
j
„

(

w i i w j

(   )

(   ))

j

(

w i i w j
(   )

(   ))

j

=

w i i
(   ))

2

-

(cid:229)
i

w i i
(   )

2

  as the relaxed index partition 

(

(cid:229)
i
(cid:229)
i

=

(cid:229)
i j
 
sum 

-

=

(cid:229)
i
j
=
(
(cid:229)
i j
 

w
l=

[(1 1)  (2 2)]*

w i i w j

(   )

(   ))

j

=

(

w i i
(   ))

2

. 

Proposition 3. The index partition sum wl can be calculated by subtracting all lower order 
i.e.  
partition 

index partition 

corresponding 

relaxed 

sums 

from 

sum 

the 

*wl   

w
l

=

*

w
l

-

w
n

(cid:229)
p
n l

#( ) #(
l
#( )
n

l

ﬁ

n

)

  where #( )l 

is 

the number of distinct order-sensitive 

(cid:229)
i j k l
 
 
 
j w i
j
(   )
(   )

l =

[(1  1) (2  3)]

permutation equivalent subsets. For example  there are 2!2!2!/2!/2!=2 order-sensitive index 
partition types for 
. They are [(1  1)  (2  3)] and [(2  3)  (1  1)]. Note that [(1  1)  
(2  3)] and [(1  1)  (3  2)] are the same type. #(
nﬁ is the number of different ways of 
l
merging a higher order permutation equivalent subset l to a low order permutation equivalent 
subset n . 
The calculation of the data index partition sum is similar. Therefore  the computational cost 
mainly depends on the calculation of relaxed partition sum and the lowest order partition sum. 
Since the computational cost of the lowest order term is O(n)  we mainly discuss the calculation 
of relaxed partition sums in the following paragraphs. 
To reduce the computational cost  we develop a greedy graph search algorithm. For 
demonstration  we use the following example. 

)

*
w
l

=

[(1 1) (1 2) (1 2) (1 3) (2 3) (1 4)]

=

#( )
l

(cid:229)
i j k l
 
 
 

w i i w i

(   )

(   )

j w i

(   )

j w i k w j k w i l
(   )

(   ) (   )

. The permutation 

equivalent index subset is represented by an undirected graph. Every node denotes an index 
number. We connect two different nodes if these two corresponding index numbers are in the 
same index element  i.e.  in the same small bracket. In figure 2  the number 2 on the edge ij 
denotes that the pair (i  j) is used twice. The self-connected node is also allowed. We assume there 
is no isolated subgraph in the following discussion. If any isolated subgraph exists  we only need 
to repeat the same procedure for all isolated subgraphs. 

*
wl=
Now we shall discuss the steps to compute the 
the weights of edges and self-connections  i.e.  

[(1 1) (1 2) (1 2) (1 3) (2 3) (1 4)]
j w i

w i i w i

(   )

(   )

. Firstly  we get rid of 
j w i k w j k w i l
 
(   )

(   )

(   )

(   )

=

(cid:229)
i j k l
 
 
 

a i
(   )

j w i k w j k w i l
(   )

(   )

(   )

  as 

a i
j
(   )

=

w i i w i

(   )

. Then we search a node with the 

(   )

(   )

a i
(   )

j w i k w j k w i l
(   )

lowest degree and do summation for all indices connected with respect to the chosen node  i.e.  
. The chosen 

(cid:229)
i j k l
 
 
 
nodes and connected edges are deleted after the above computation. We repeat the same step until a 
symmetric graph occurs. Since every node in the symmetric graph has the same degree  we randomly choose 
any node; 
  as 

for example  k 

j w i k w j k
(   )

j w i k w j k
(   )

b i
j
(   ) (   )

summation  

j w i l
(   )

b i
j
(   )

a i
(   )

b i
(   )

= (cid:229)
l

b i
(   )

(cid:229)
i j k
 
 

(   )

(   )

j c i

  as 

then

for 

=

=

(cid:229)
i j k
 
 

(cid:229)
i j
 

c i j
(   )

= (cid:229)
k

w i k w j k
(   ) (   )
 

. Finally  we clear the whole graph and obtain the relaxed index partition sum. 

i 

2 

l 

i 

l 

i 

i 

k 

j 
Figure 2: Greedy Search Algorithm for computing 

k 

k 

j 

j 

j 

 

w i

The most computational-expensive case is the complete graph in which every pair of nodes is 
*cl is determined by the subtotal that has the largest 
connected. Hence  the computational cost of 
symmetric subgraph in its graph representation. For example  the most expensive relaxed index 
partition sum for d=2 and r=3 is 
j w i k w j k   which is a triangle in the graph 
representation. 
Proposition 4 For d>=2  let 
  where r is the order of 
moment and m is an integer. For a d-th order test statistic  the computational cost of the partition 
sum for the r-th moment is bounded by O(nm). When d = 1 the computational complexity of the 
partition sum is O(n). 
Specifically  the computational cost of the 3rd and 4th moments for a second order test statistic is 
O(n3). The computational cost for the 1st and 2nd moments is O(n2). 

/ 2 (
<

(   )

1) / 2

(   )

(   )

m m

r d
(

/ 2

1)

m

m

1)

-

+

£

-

d

(

Fitting 

Experimental resu lts 

 
2. 4 
The Pearson distribution series (Pearson I ~ VII) is a family of probability distributions that are 
more general than the normal distribution [12]. It covers all distributions in the ((cid:946)1  (cid:946)2) plane 
including normal  beta  gamma  log-normal  and etc.  where distribution shape parameters (cid:946)1  (cid:946)2 
are the square of standardized skewness and kurtosis measurements  respectively. Given the first 
four moments  the Pearson distribution series can be utilized to approximate the permutation 
distribution of the test statistic without conducting real permutation. 
 
3 
To evaluate the accuracy and efficiency of our moments-based permutation tests  we generate 
simulated data and conduct permutation tests for both linear and quadratic test statistics. We 
consider six simulated cases in the first experiment for testing the difference between two groups  
A and B. We use mean difference statistics here. For group A  n1 observations are generated 
independently from Normal(0 1) in Cases 1-2  from Gamma(3 3) in Cases 3-4  and from Beta(0.8  
0.8) in Cases 5-6. For group B  n2 independent observations are generated from Normal(1  0.5) in 
Cases 1-2  from Gamma (3 2) in Cases 3-4  and from Beta(0.1  0.1) in Cases 5-6. The design is 
balanced in Cases 1  3  and 5 with n1 = n2 = 10  and unbalanced in Cases 2  4  and 6 with n1 = 6  n2 
= 18. 
Table 1 illustrates the high accuracy of our moments-based permutation technique. Furthermore  
comparing with exact permutation or random 10 000 permutations  the moments-based 
permutation tests reduce more than 99.8% of the computation cost  and this efficiency gain 
increases with sample size. Table 1 shows the computation time and p-values of three permutation 
methods from one simulation. In order to demonstrate the robustness of our method  we repeated 
the simulation for 10 times in each case  and calculated the mean and variance of the absolute 
biases of p-values of both moments-based permutation and random permutation  treating the p-
values of exact permutation as gold standard. In most cases  our moments-based permutation is 
less biased and more stable than random permutation (Table 2)  which demonstrates the 
robustness and accuracy of our method. 
Table 1: Comparison of computation costs and p-values of three permutation methods: Moments-
based permutation (MP)  random permutation (RP)  and exact permutation (EP). The t_MP  t_RP  
and t_EP denote the computation time (in seconds)  and p_MP  p_RP  and p_EP are the p-values 
of the three permutation methods. 

 

C a s e 1 C a s e 2 C a s e 3 C a s e 4 C a s e 5 C a s e 6 
t _ M P 6 . 7 9e -4 5.37e-4 5.54e-4 5.16e-4 5.79e-4 6.53e-4 
t _ R P 5 . 0 7e -1 5.15e-1 5.06e-1 1.30e-1 2.78e-1 5.99e-1 
t _ E P 3. 9 9e -0 1.21e-0 3.71e-0 1.21e-0 3.71e-0 1.22e-0 
p _M P 1 . 1 9e -1 2.45e-2 1.34e-1 1.19e-1 3.58e-2 5.07e-5 
p _ R P 1 . 2 1e -1 2.56e-2 1.36e-1 1.20e-1 3.53e-2 5.09e-2 
p _ E P 1 . 1 9e -1 2.39e-2 1.34e-1 1.15e-1 3.55e-2 5.11e-2 

We consider three simulated cases in the second experiment for testing the difference among three 
groups D  E  and F. We use modified F statistics [7] here. For group D  n1 observations are 
generated independently from Normal(0 1) in Case 7  from Gamma(3 2) in Case 8  and from 
Beta(0.8  0.8) in Case 9. For group E  n2 independent observations are generated from Normal(0 1) 
in Case 7  from Gamma(3 2) in Case 8  and from Beta(0.8  0.8) in Case 9. For group F  n3 
independent observations are generated from Normal(0.1 1) in Case 7  from Gamma(3 1) in Case 
8  and from Beta(0.1  0.1) in Case 9.The design is unbalanced with n1 = 6  n2 = 8  and n3 =12. 
Since the exact permutation is too expensive here  we consider the p-values of 200 000 random 
permutations (EP) as gold standard. Our methods are more than one hundred times faster than 
2 000 random permutation (RP) and also more accurate and robust (Table 3). 
We applied the method to the MRI hippocampi belonging to 2 groups  with 21 subjects in 
group A and 15 in group B. The surface shapes of different objects are represented by the 
same number of location vectors (with each location vector consisting of the spatial x  y  and 
z coordinates of the corresponding vertex) for our subsequent statistical shape analysis. 
There is no shape difference at a location if the corresponding location vector has an equal 

mean between two groups. Evaluation of the hypothesis test using our moments-based 
permutation with the modified Hotelling(cid:8217)s T2 test statistics [8] is shown in Fig. 3(a) and 3(b). 
It can be seen that the Pearson distribution approximation leads to ignorable discrepancy 
with the raw p-value map from real permutation. The false positive error control results are 
shown in Fig. 3(c). 
Table 2: Robustness and accuracy comparison of moments-based permutation and random 
permutation across 10 simulations  considering the p-values of exact permutation as gold standard. 
Mean_ABias_MP and VAR_MP are the mean of the absolute biases and the variance of the biases 
of p-values of moments-based permutation; Mean_ABias_RP and VAR_RP are the mean of the 
absolute biases and the variance of the biases of p-values of random permutation. Mean difference 
statistic is used. 

 

Ca s e 1 Ca s e 2 Ca s e 3 Ca s e 4 Ca s e 5 Ca s e 6 
Mean_ABias_MP 1.62e-4 3.04e-4 6.36e-4 8.41e-4 1.30e-3 3.50e-3 
Mean_ABias_RP 7.54e-4 3.39e-4 9.59e-4 8.39e-4 1.30e-3 2.00e-3 
VAR_MP 6.42e-8 2.74e-7 1.54e-6 1.90e-6 3.76e-6 2.77e-5 
VAR_RP 7.85e-7 1.86e-7 1.69e-6 3.03e-6 4.24e-5 1.88e-5 

 

Table 3: Computation cost  robustness  and accuracy comparison of moments-based permutation 
and random permutation across 10 simulations. Modified F statistic is used. 

 C a s e 7 C a s e 8 C a s e 9 

C a s e 7 C a s e 8 C a s e 9 
t_MP 1.03e-3 1.42e-3 1.64e-3 Mean_ABias_MP 9.23e-4 2.37e-4 2.11e-3 
t_RP 1.51e-1 1.48e-1 1.38e-1 Mean_ABias_RP 3.94e-3 2.79e-3 3.42e-3 
t_EP 1.76e+1 1.86e+1 2.37e+1 VAR_MP 1.10e-6 8.74e-8 1.23e-5 
VAR_RP 2.27e-5 1.48e-5 1.85e-5 
 

 

 

 

 

p-value>0.05 
 =0.05 

 

 

 

 

 

 

 

 

 =0.0 

 

 (a) (b) (c) (d) 

 
 

 

 (e) 

 

 

0.05

Figure 3. (a) and (b): Comparison of techniques in raw p-value measurement at 
(without correction)  through real permutation ((a); number of permutations = 
a =
10 000) and using the present moments-based permutation (b). (c) p-map after BH(cid:8217)s FDR 
correction of (b). (e) Facial differences between Asian male and white male. Locations in red 
on the 3D surface denote significant face shape differences (significance level (cid:945) = 0.01 with 
false discovery rate control). 
We also applied our method to the 3D face comparison between Asian males and white 
males. We choose 10 Asian males and 10 white males out of the USF face database to 
calculate their differences with the modified Hotelling(cid:8217)s T2 test statistics. Each face surface 
is represented by 4 000 voxels. All surfaces are well aligned. Results from our algorithm in 
Fig. 3(e) show that significant differences occur at eye edge  nose  lip corners  and cheeks. 
They are consistent with anthropology findings and suggest the discriminant surface regions 
for ethnic group recognition. 
 
4 
We present and develop novel moments-based permutation tests where the permutation 
distributions are accurately approximated through Pearson distributions for considerably reduced 
computation cost. Comparing with regular random permutation  
the proposed method 
considerably reduces computation cost without loss of accuracy. General and analytical 
formulations for the moments of permutation distribution are derived for weighted v-test statistics. 
The proposed strategy takes advantage of nonparametric permutation tests and parametric Pearson 
distribution approximation to achieve both accuracy/flexibility and efficiency. 

Conclusion 

Re fe re nce s 
 
[1] 

[2] 

[3] 

[4] 

[5] 

[6] 

[7] 

[8] 

[9] 

Nichols  T. E.  and A. P. Holmes (2001)  Nonparametric permutation tests for 
functional neuroimaging: A primer with examples  Human Brain Mapping  15  1-25. 
Zhou  C.  D. C. Park  M. Styner  and Y. M. Wang (2007)  ROI constrained statistical 
surface morphometry  IEEE International Symposium on Biomedical Imaging  
Washington  D. C.  1212-1215. 
Zhou  C.  and Y. M. Wang (2008)  Hybrid permutation test with application to 
surface shape analysis  Statistica Sinica  18  1553-1568. 
Pantazis  D.  R. M. Leahy  T. E. Nichols  and M. Styner (2004)  Statistical surface-
International 
based morphometry using a non-parametric approach  
Symposium on Biomedical Imaging  2  1283-1286. 
Zhou  C.  Y. Hu  Y. Fu.  H. Wang  Y. M. Wang  and T. S. Huang (2008)  3D face 
analysis for distinct features using statistical randomization  IEEE International 
Conference on Acoustics  Speech  and Signal Processing  Las Vegas  Nevada  981-
984. 
Hubert  L. (1987)  Assignment Methods in Combinatorial Data Analysis  Marcel 
Dekker  New York. 
Mielke  P. W.  and K. J. Berry (2001)  Permutation Methods: A Distance Function 
Approach  Springer  New York. 
Good  P. (2005)  Permutation  Parametric and Bootstrap Tests of Hypotheses  3rd 
ed.  Springer  New York. 
Serfling  R. J. (1980)  Approximation Theorems of Mathematical Statistics  Wiley  
New York. 

IEEE 

[10] Edgington  E.  and P. Onghena (2007)  Randomization Tests  4th ed.  Chapman & 

Hall  London. 

[11] Nicholson  W. K. (2006)  Introduction to Abstract Algebra  3rd ed.  Wiley  New 

York. 

[12] Hahn  G. J.  and S. S. Shapiro (1967)  Statistical Models in Engineering  John Wiley 

and Sons  Chichester  England. 

,Myunghwan Kim
Jure Leskovec
Kevin Ellis
Armando Solar-Lezama
Josh Tenenbaum
Austin Benson
Jon Kleinberg