2010,Nonparametric Density Estimation for Stochastic Optimization with an Observable State Variable,We study convex stochastic optimization problems where a noisy objective function value is observed after a decision is made. There are many stochastic optimization problems whose behavior depends on an exogenous state variable which affects the shape of the objective function. Currently  there is no general purpose algorithm to solve this class of problems. We use nonparametric density estimation for the joint distribution of state-outcome pairs to create weights for previous observations. The weights effectively group similar states. Those similar to the current state are used to create a convex  deterministic approximation of the objective function. We propose two solution methods that depend on the problem characteristics: function-based and gradient-based optimization. We offer two weighting schemes  kernel based weights and Dirichlet process based weights  for use with the solution methods. The weights and solution methods are tested on a synthetic multi-product newsvendor problem and the hour ahead wind commitment problem. Our results show Dirichlet process weights can offer substantial benefits over kernel based weights and  more generally  that nonparametric estimation methods provide good solutions to otherwise intractable problems.,Nonparametric Density Estimation for Stochastic
Optimization with an Observable State Variable

Lauren A. Hannah
Duke University

Durham  NC 27701
lh140@duke.edu

Warren B. Powell
Princeton University
Princeton  NJ 08544

powell@princeton.edu

Abstract

David M. Blei

Princeton University
Princeton  NJ 08544

blei@cs.princeton.edu

In this paper we study convex stochastic optimization problems where a noisy
objective function value is observed after a decision is made. There are many
stochastic optimization problems whose behavior depends on an exogenous state
variable which affects the shape of the objective function. Currently  there is no
general purpose algorithm to solve this class of problems. We use nonparametric
density estimation to take observations from the joint state-outcome distribution
and use them to infer the optimal decision for a given query state s. We propose
two solution methods that depend on the problem characteristics: function-based
and gradient-based optimization. We examine two weighting schemes  kernel
based weights and Dirichlet process based weights  for use with the solution meth-
ods. The weights and solution methods are tested on a synthetic multi-product
newsvendor problem and the hour ahead wind commitment problem. Our results
show that in some cases Dirichlet process weights offer substantial beneﬁts over
kernel based weights and more generally that nonparametric estimation methods
provide good solutions to otherwise intractable problems.

1

Introduction

In stochastic optimization  a decision maker makes a decision and faces a random cost based on
that decision. The goal is to choose a decision that minimizes the expected cost using information
from previous observations. Stochastic optimization problems with continuous decision spaces have
many viable solution methods  including function averaging and stochastic gradient descent [20].
However  in many situations conditions for the previous observations may not be the same as the
current conditions; the conditions can be viewed as state variables. There are currently no general
purpose solution methods for stochastic optimization problems with state variables  although they
would be useful for ﬁnance  energy  dynamic pricing  inventory control and reinforcement learning
applications.
We consider the newsvendor problem  a classic inventory management problem  to illustrate existing
solution methods for stochastic optimization problems with state variables and their limitations.
Here  newspapers can be bought in advance for cost c  and up to D of them can be sold for price
p  where D is a random demand; the goal is to determine how many papers should be ordered so
as to maximize the expected proﬁt. A state variable that contains information about the random
demand may also be included. For example  a rainy forecast may correlate to a lower demand while
a sunny forecast may correlate to a higher. A natural solution method would be to partition the
previous observations into “rainy” and “sunny” bins  and then solve the problem for each partition.
This essentially models the problem as a single time period Markov Decision Process and solves
the problem accordingly [16  21]. Partitioning methods work when the state space can take a small
number of discrete values.

1

Two problems arise with partitioning methods when the state space becomes larger. First  the num-
ber of states grows exponentially with the dimension of the state space. If there are 10 attributes 
like weather  stock prices  days until an election  etc  and each can take 100 values  then there will
be 1020 individual states. Second  previous observations are sparse over these states; a vast number
of observations must be gathered before there are enough to make a reasonable decision for a given
state. Rather than partitioning  we propose using observations from “similar” states to create a de-
terministic decision-expected cost function  also called an objective function  that is conditioned on
a particular state.
Similar methods have been proposed in an approximate dynamic programming setting that use basis
functions  such as linear and polynomial predictors  to construct approximate value functions [22 
14]. Basis functions  however  are hard to choose manually and automatic selection is an area of
active research [12]. Moreover  basis functions do not guarantee that the approximate objective
function is convex in the decision.
We propose using nonparametric density estimation for the joint state and outcome distribution to
group observations from “similar” states with weights. These are then used to construct determin-
istic  convex approximations of the noisy function given the current observed information. The
results are a deterministic  convex math program. These can be efﬁciently solved by a number of
commercial solvers  even with very large decision spaces (10 to 1 000+ variables and constraints).
We give two methods to construct an approximate objective function using previous observations.
The ﬁrst is a function-based method. In some cases  entire random objective functions can be viewed
retrospectively. For example  if the demand is known in the newsvendor problem  then the value of
all decisions is also known. In these particular cases  the approximate objective function is mod-
eled as a weighted average of the observed functions. The second method is based on stochastic
gradients. In some cases  it is not possible to observe entire functions or observed functions may
be too complex to manipulate. When this happens  we propose constructing a separable  piecewise
linear approximate objective function. A piecewise linear  convex function is created in each deci-
sion dimension by generating a slope function from a weighted  order-restricted regression of the
gradients  and then integrating that function. The result is an approximate objective function that is
not necessarily the same as the original objective function  but one that has the same minima.
Both methods depend heavily on weights to capture dependence between the state and the outcome.
We propose two weighting schemes: kernels weights and Dirichlet process mixture model weights.
Kernels are simple to implement  but Dirichlet process mixture models have certain appealing prop-
erties. First  they act as a local bandwidth selector across the state space; second  the weights are
generated by partitions rather than products of uni-dimensional weights  so the results scale better
to higher-dimensional settings.
We contribute novel algorithms for stochastic optimization problems with a state variable that work
with large  continuous decision spaces and propose a new use of Dirichlet process mixture models.
We give empirical analysis for these methods where we show promising results on test problems.
The paper is organized as follows. In Section 2  we review traditional function-based and gradient-
based optimization methods and in each case present novel algorithms to accommodate an observ-
able state variable. We present an empirical analysis of our methods for synthetic newsvendor data
and the hour ahead wind commitment problem in Section 4 and a discussion in Section 5.

2 Stochastic optimization for problems with an observable state variable

Traditional stochastic optimization problems have the form
E [F (x  Z)]  

min
x∈X

(1)
where x ∈ Rd is the decision  Z : Ω → Ψ is a random outcome  X is a decision set and F (x  Z(ω))
is a random objective function [20]. In the newsvendor problem  which we will use as a running
example  x is the stocking level and Z is the random demand. Given x and Z(ω)  F is deterministic.
When a state variable is inlcuded  we ﬁrst observe a random state S ∈ S that may inﬂuence F and
the distribution of Z  then we make a decision x  and ﬁnally we observe the random variable Z. Eq.
(1) becomes

E [F (x  s  Z)|S = s] .

min
x∈X

2

(2)

Traditional stochastic optimization techniques require us to sample from the conditional distribution
of p(Z|S = s)  treating each state observation independently [20]. We will use nonparametric
density estimation for the joint distribution of (S  Z) to take into account that similar values of S
affect Z and F in a similar way. We now describe new methods for function-based and gradient-
based optimization for problems with an observable state variable.

2.1 Function-based optimization with an observable state variable

Function-based optimization is used when a single outcome ω can tell us the value of all decisions
given that outcome [19]. For example  in the newsvendor problem  if the demand is known then
the value of all inventory levels is known. Function-based optimization relies on sampling a set of
scenarios  ω1  . . .   ωn from Ω  to approximate Eq. (1):

F (x  Z(ωi)).

(3)

n(cid:88)

i=1

min
x∈X

1
n

n−1(cid:88)

¯Fn(x|s) =

Since Eq. (3) is deterministic given ω1:n  deterministic solution methods can be used. These meth-
ods are well developed and are implemented in a variety of commercial solvers.
When a state variable is introduced  we wish to solve Eq. (2) for a ﬁxed query state s ∈ S. However 
from the distribution p(Z|S = s)  but rather from the joint distribution
scenarios are not i.i.d.
(p(Z  S). Let (Si  Z(ωi+1))n−1
i=0 be a set of n observations. Instead of taking a naive average of the
observations as in Eq. (3)  we weight the observations based on the distance between the query state
i=0 wn(s  Si) = 1 

s and each observation Si with weight wn(s  Si). The weights must sum to 1 (cid:80)n−1

and the weights may change with the number of observations  n. Set

wn(s  Si)F (x  Si  Z(ωi+1)).

(4)

The optimization problem becomes

i=0

(5)
Note that because F (x  Si  Z(ωi+1)) is convex in x for every Si and ωi+1  ¯Fn(x|s) is convex and
Eq. (5) can be solved with a commercial solver. We discuss weight functions in Section 3.

min
x∈X

¯Fn(x|s).

2.2 Gradient-based optimization with an observable state variable

In gradient-based optimization  we no longer observe an entire function F (x  S  Z(ω))  but only a
derivative taken at x 

ˆβ(xi  s  ωi+1) = ∇xF (xi  s  Z(ωi+1)).

(6)
Stochastic approximation is the most popular way to solve stochastic optimization problems using a
gradient; it modiﬁes gradient search algorithms to account for random gradients [17  9]. The general
idea is to optimize x by iterating 

xn+1 = ΓX (xn − an∇x F (xn  Z(ωn+1))  

(7)
where ΓX is a projection back into the constraint set X   ∇x F (xn  Z(ωn+1)) is a stochastic gradient
at xn and an is a stepsize. Other approaches to gradient-based optimization have included construc-
tion of piecewise linear  convex functions to approximate F (x) in the region where x is near the
optimal decision  x∗ [15].
Including a state variable into gradient-based optimization is less straightforward than it is for
function-based optimization. We run into difﬁculties because we choose xn given Sn. When we
include state Sn  the decision xn is based on the state Sn. But xn−1 depends on Sn−1  so no itera-
tive procedure like Eq. (7) can be used. Moreover  constructing the approximate function ¯Fn(x|s)
is not trivial because the stochastic gradients depend on both xn and Sn.
Therefore  we propose modeling F (x|s) with a piecewise linear  convex  separable approximation.
Even if F (x|s) is not itself separable  we aim to approximate it with a simpler (separable) function
that has the same minimum for all ﬁxed s. Approximating the minimum is easier than approximating

3

Figure 1: A graphical depiction of gradient-based method in one dimension for a maximization problem.
(Top left) Observe gradients  state. (Top right) Weight observations based on state. (Bottom left) Fit isotonic
regression to weighted slopes. (Bottom right) Integrate isotonic regression to form f k

n (xn|Sn).

the entire convex function [4  15]. Moreover  convex regression is easier in one dimension than
multiple dimensions. We approximate E[F (x  s  Z)] by a series of separable functions 

¯Fn(x|s) =

n(xk|s) 
f k

n(x|s) for every s ∈ S.
where xk is the kth component of x. We enforce convexity restrictions on f k
Unlike the function-based method  the gradient-based method is a fundamentally online algorithm:
xn is used to choose xn+1. Given Sn  we choose xn as follows 
n(xk|Sn).
f k

d(cid:88)

xn = arg min
x∈X

We then receive ˆβ(xn  Sn  ωn+1). The observations (xi  Si  ˆβ(xi  Si  ωi+1))n−1
i=0 are used to up-
date ¯Fn(x|s) sequentially. Fix k ∈ {1  . . .   d}; we want to construct a piecewise linear f k
n(x|s)
n(x|Sn) based on the stochastic gra-
by constructing an increasing slope function  vk
dx f k
dient observations  ˆβ1:n. We use weights to group the gradients from states “similar” to Sn and a
n(x|Sn). Order the decision observa-
weighted isotonic (order restricted) regression to construct vk
tions xk

n(x|Sn) = d

[n−1]  and then solve to ﬁnd slopes for the decision-ordered space 
n(x0:n−1|Sn) = arg min
vk

(cid:0)Sn  S[i]

[i]  S[i]  ω[i+1]) − v[i]

(cid:1)(cid:16) ˆβ(xk

[0]  . . .   xk

n−1(cid:88)

 

(8)

(cid:17)2

subject to : v[i−1] ≤ v[i] 

wn

v

i=0

i = 1  . . .   n − 1.

n(x|Sn) is generated by interpolating the point estimates from Eq. (8) across the kth dimen-
n(x|Sn). The monotonicity
n(x|Sn). See Figure 1 for an example. The general method

First vk
sion of the decision space  and then f k(x|Sn) is created by integrating vk
n(x|Sn) ensures the convexity of f k
of vk
for constructing ¯Fn(x|s) is as follows:

d(cid:88)

k=1

k=1

4

00.20.40.60.8100.20.40.60.81−2−1.5−1−0.500.511.52State VariableDecision VariableStochastic Gradientdecisionresponse−1.5−1.0−0.50.00.51.01.5l0.00.20.40.60.81.0weight0.30.40.50.60.70.80.9l1.0decisionresponse−1.5−1.0−0.50.00.51.01.5l0.00.20.40.60.81.0weight0.30.40.50.60.70.80.9l1.0decisionvalue0.000.050.100.150.200.250.00.20.40.60.81. Observe Sn and constructing weights ((wn(Sn  Si))n−1
i=0  
2. Use the weights wn(Sn  Si)n−1
3. Reconstruct f k(x|Sn) from the slopes and construct ¯F (x|Sn) from (f k(x|Sn))d
4. Choose xn given ¯F (x|Sn):

1:K(Sn) with Eq. (8) 

¯Fn(x|Sn).

i=0   previous decisions x0:n−1 and gradients to construct

k=1  and

xn = arg min
x∈X

slopes vk

Details are given in the supplementary material. We now discuss the choice of weight functions.

3 Weight functions

Like the choice of step size in stochastic approximation  the choice of weight functions in Eqs. (4)
and (8) determines whether and under which conditions function-based and gradient-based opti-
mization produce acceptable results. Weighting functions rely on density estimation procedures to
approximate the conditional density f(z|s)  where s is the state and z is the response. Conditional
density estimation weights observations from a joint distribution to create a conditional distribution.
We use this to obtain weights from two nonparametric density estimators  kernels and Dirichlet
process mixture models.

3.1 Kernel weights

Kernel weights rely on kernel functions  K(s)  to be evaluated at each observation to approximate
the conditional density. A common choice for K with continuous covariates is the Gaussian kernel 
Kh(s) = (2πh)−1/2 exp{−s2/2h}  where the variance h is called the bandwidth. Kernel weights
have the advantage of being simple and easy to implement. The simplest and most universally
applicable weighting scheme is based on the Nadaraya-Watson estimator [10  23]. If K(s) is the
kernel and hn is the bandwidth after n observations  deﬁne

n−1(cid:88)

n−1(cid:88)

i=1

wn(s  Si) = K ((s − Si)/hn) /

K ((s − Sj)/hn) .

Kernel estimators require a well sampled space  are poor in higher dimensions and highly sensitive
to bandwidth size [5].

j=0

3.2 Dirichlet process weights

One of the curses of dimensionality is sparseness of data: as the number of dimensions grows  the
distance between observations grows exponentially. In kernel regression  this means that only a
handful of observations have weights that are effectively non-zero  producing non-stable estimates.
Instead  we would like to average responses for “similar” observations. We propose modeling the
distribution of the state variable with a Dirichlet process mixture model  which is then decomposed
into weights.

inﬁnite sum of simpler distributions  g(s| θi)  parameterized by θi  g(s) =(cid:80)∞

Dirichlet process mixture models. A mixture model represents a distribution  g(s)  as a weighted
i=1 pig(s| θi). Here 
pi is the mixing proportion for component i. We can use a Dirichlet process (DP) with base measure
G0 and concentration parameter α to place a distribution over the joint distribution of (pi  θi)  the
mixture proportion and location of component i [6  1]. Assume that data S1  . . .   Sn are iid with a
distribution that is modeled by a mixture over distribution G(θ) 

(9)
The distribution P drawn from a Dirichlet process is an almost surely discrete measure over param-
eters  with the mixture proportion associated with θ as the atomic weight. The hidden measure P in
Eq. (9) can be integrated out to obtain a conditional distribution of θn|θ1:n−1 [3]

P ∼ DP (α  G0) 

Si|θi ∼ G(θi).

θi|P ∼ P 

θn | θ1  . . .   θn−1 ∼

1

α + n − 1

δθi +

α

α + n − 1

G0.

(10)

Here  δθ is the Dirac measure with mass at θ. Eq. (10) is known as a Polya urn posterior; the variable
θn has positive probability of assuming the value of one of the previously observed θi  but it also
can take a new value drawn from G0 with positive probability. The parameter α controls how likely
θn is to take a new value. We now discuss how weights can be constructed from Eq. (9).

5

Dirichlet process mixture model weights. A Dirichlet process mixture model can be used to
model an unknown density  but it can simultaneously be used to produce a distribution of the parti-
tion structure of observed data [13  8]. This is shown in the Polya urn posterior of Eq. (10); each
hidden parameter has positive probability of taking the same value as another parameter. If two
hidden parameters have the same value  they are in the same partition/cluster. The partition structure
induces weights on the observations  proportional to 1 if they are in the same cluster  0 if not.
i }
Let p = {C1  . . .   Cn(p)} be the partition of the observations {1  . . .   n}. Here Ci = {j : θj = θ∗
is the partition set generated by n(p) unique parameter values  denoted θ∗
n(p). Now suppose
that we know the partition p. Given p  we include the query state s into cluster Ci with probability

1  . . .   θ∗

ps(Ci|p) = P(s ∈ Ci | p  S1:n) ∝ |Ci|

g(s| θ∗)dHCi(θ∗) 

where |Ci| is the number of elements in Ci  and HCi(θ∗) is the posterior distribution of θ∗ condi-
tioned on G0 and the set of observations {Sj : Sj ∈ Ci}. Given p  the weighting function is the
probability that the hidden parameter for s would be θi  the hidden parameter for Si 

(cid:90)

wn(s  Si)| p =

ps(Cj | p)

|Cj|

1{Si∈Cj}.

(11)

n(p)(cid:88)

j=1

Eq. (11) is conditioned on a partition structure  but the Dirichlet process produces a distribution over
partition structures. Let π(p) be the prior distribution for partitions p and π(p|S0:n−1) the posterior.
Integrating of the partition posterior  we obtain unconditional weights 

X

n(p)X

wn(s  Si) =

π(p|S1:n)

p

j=1

ps(Cj | p)

|Cj|

1{Si∈Cj} ≈ 1
M

ps(Cj | p(m))

|Cj|

1{Si∈Cj}.

(12)

MX

n(p(m))X

m=1

j=1

It is infeasible to integrate over all of the partitions; therefore  we approximate Eq. (12) by per-
forming a Monte Carlo integration with M posterior partition samples  (p(m))M
m=1. We obtain
(p(m))M
m=1 by generating M iid samples of the hidden parameters  θ0:n−1  from the posterior of Eq.
(9) with Gibbs sampling [11].

4 Empirical analysis

4.1 Multi-product constrained newsvendor problem

A multi-product newsvendor problem is a classic operations research inventory management prob-
lem. In the two product problem  a newsvendor is selling products A and B. She must decide how
much of each product to stock in the face of random demand  DA and DB. A and B can be be bought
for (cA  cB) and sold for (pA  pB)  respectively. Any inventory not sold is lost. Let (xA  xB) be the
stocking decisions for A and B respectively; it is subject to a budget constraint  bA xA + bB xB ≤ b 
and a storage constraint  rA xA+rB xB ≤ r. An observable state S = (S1  S2) contains information
about DA and DB. The problem is 

− cA xA − cB xB + E [pA min (xA  DA) + pB min (xB  DB) | S = s]

(13)

max
xA  xB

subject to : bA xA + bB xB ≤ b 

rA xA + rB xB ≤ r.

We generated data for Problem (13) in the following way. Demand and two state variables were
generated in a jointly trimodal Gaussian mixture.The following methods were compared.
Function-based with kernel and Gradient-based with kernel. Bandwidth is selected according to
the “rule of thumb” method of the np package for R  hj = 1.06σjn−1/(4+d)  where σj is deﬁned as
min(sd  interquartile range/1.349) [7].
Function-based with DP and Gradient-based with DP. We used the following hierarchical model 

P ∼ DP (α  G0) 

θi = (µi s  σ2

i s)|P ∼ P 

Si j|θi ∼ N(µi s j  σ2

i s j)  j = 1  2.

6

Figure 2: Gradient-based and function-based methods as a function of number of data points sampled. Results
are averaged over 100 test problems with observed demand.

Posterior samples were drawn using Gibbs sampling with a fully collapsed sampler run for 500
iterations with a 200 iteration burn-in with samples taken every 5 iterations.
Optimal. These are the optimal decisions with known mixing parameters and unknown components.
Results. Decisions were made under each regime over eight sample paths; 100 test state/demand
pairs were ﬁxed and decisions were made for these problems given the observed states/decisions
in the sample path for each method. Results are given in Figure 2. The kernel and Dirichlet pro-
cess weights performed approximately equally for each method  but the function-based methods
converged more quickly than the gradient-based methods.

4.2 Hour ahead wind commitment

In the hour ahead wind commitment problem  a wind farm manager must decide how much energy
to promise a utility an hour in advance  incorporating knowledge about the current state of the world.
The decision is the amount of wind energy pledged  a scalar variable. If more energy is pledged than
is generated  the difference must be bought on the spot market  which is expensive with a price that is
unknown when the decision is made; otherwise  the excess is lost. The goal is to maximize expected
revenue. The observable state variable is the time of day  time of year  wind history from the past
two hours  contract price and current spot price 

= time of day 
= current spot price 

T D
i
P S
i
Wi−1 = wind speed an hour ago 
= observable state variable
= amount of energy pledged 

Si
xi

T Y
i
P C
i
Wi

= time of year 
= contract price 
= current wind speed 
= (T D
i   P S
i+1 max (x − Wi+1  0).
i
Yi+1(x) = P C

i   P C
i x − P S

  T Y

i   Wi  Wi−1) 

The revenue that the wind farm receives  Yi+1(x)  depends on the variables P S
i+1 and Wi+1  which
are not known until the next hour. We used wind speed data from the North American Land Data As-
similation System with hourly observations from 2002–2005 in the following locations: Amarillo 
TX. Latitude: 35.125 N  Longitude: 101.50 W. The data have strong daily and seasonal patterns.
The mean wind level is 186.29 (m/s)3 with standard deviation 244.86. Tehachapi  CA. Latitude:
35.125 N  Longitude: 118.25 W. The data have strong seasonal patterns. The mean wind level is
89.45 (m/s)3 with standard deviation 123.47.
Clean spot and contract price data for the time period were unavailable  so contract prices were
generated by Gaussian random variables with a mean of 1 and variance of 0.10. Spot prices were
generated by a mean-reverting (Ornstein-Uhlenbeck) process with a mean function that varies by
time of day and time of year [18]. The data were analyzed separately for each location; they were
divided by year  with one year used for training and the other three used for testing. The following
methods were compared on this dataset:
Known wind. The wind is known  allowing maximum possible commitment  xi = Wi+1(ωi+1). It
serves as an upper bound for all of the methods.

7

Two Product NewsvendorNumber of ObservationsValue681012141620406080100AlgorithmKernelGradient−BasedDPGradient−BasedKernelFunction−BasedDPFunction−BasedOptimalMETHOD/LOCATION
TEHACHAPI  CA
KNOWN WIND
FUNCTION WITH KERNEL
FUNCTION WITH DP
IGNORE STATE
AMARILLO  TX
KNOWN WIND
FUNCTION WITH KERNEL
FUNCTION WITH DP
IGNORE STATE

2002

2003

2004

2005

97.5
78.8 (80.8%)
85.1 (87.3%)
30.4 (31.1%)

94.5
77.3 (81.8%)
82.6 (87.4%)
31.1 (32.9%)

73.7
58.9 (79.9%)
63.9 (86.7%)
22.8 (30.9%)

91.8
72.1 (78.5%)
79.6 (86.7%)
29.3 (31.9%)

186.0
155.1 (83.4%)
168.2 (90.4%)
70.3 (37.8%)

175.2
149.6 (85.4%)
160.6 (91.7%)
68.7 (39.2%)

184.9
154.7 (83.7%)
167.1 (90.4%)
69.6 (37.6%)

175.2
146.2 (83.5%)
159.4 (91.0%)
66.1 (37.7%)

Table 1: Mean values of decisions by method  year and data set. Percentages of the upper bound  Known Wind 
are given for the other methods.
Function-based with kernel. Function-based optimization where the weights are generated by a
Gaussian kernel. Bandwidth is selected according to the “rule of thumb” method of the np package
for R  hj = 1.06σjn−1/(4+d)  where σj is deﬁned as min(sd  interquartile range/1.349) [7].
Function-based with DP. Function-based optimization with Dirichlet process based weights. We
model the state distribution with the following hierarchical model 
θi|P ∼ P 
i |θi ∼ von Mises(µi Y   φY ) 
T Y
i |θi ∼ N(µi S  σ2
i S) 
P S
Wi−1|θi ∼ N(µi W 2  σ2
i W 1  µi W 2  σ2

P ∼ DP (α  G0) 
|θi ∼ von Mises(µi D  φD) 
T D
i
i |θi ∼ N(µi C  σ2
i C) 
P C
Wi|θi ∼ N(µi W 1  σ2
i W 1) 

θi = (µi D  µi Y   µi C  σ2

i W 2) 
i W 2).

i S  µi W 1  σ2

i C  µi S  σ2

i   P S

  and year  T Y

We modeled the time of day  T D
i   with a von Mises distribution  an exponential family
i
distribution over the unit sphere; the dispersion parameters  φD and φY   are hyperparameters. The
base measure was Normal-Inverse Gamma for P C
i   Wi and Wi−1 and uniform for the means of
i . 100 posterior samples were drawn using Gibbs sampling with a collapsed sampler for
i and T Y
T D
all conjugate dimensions after a 1 000 iteration burn-in and 10 iteration pulse between samples.
Ignore state. Sample average approximation is used  ¯Fn(x|s) = 1
Results. Results are presented in Table 1. We display the value of each algorithm  along with
percentages of Known Wind for the other three methods. Both forms of function-based optimization
outperformed the algorithm in which the state variable was ignored by a large margin (≥45% of the
best possible value). Dirichlet process weights outperformed kernel weights by a smaller but still
signiﬁcant margin (5.6–8.2% of best possible value).

(cid:80)n−1

i=0 Yi+1(x).

n

5 Discussion

We presented two new methods to solve stochastic optimization problems with an observable state
variable  including state variables that are too large for partitioning. Our methods make minimal as-
sumptions. They are promising additions to areas that rely on observational data to make decisions
under changing conditions (energy  ﬁnance  dynamic pricing  inventory management)  and some
communities that make sequential decisions under uncertainty (reinforcement learning  stochastic
programming  simulation optimization). Our methods can accommodate much larger state and de-
cision spaces than MDPs and other table lookup methods  particularly when combined with Dirichlet
process mixture model weights. Unlike existing objective function approximation methods  such as
basis functions  our methods provide convex objective function approximations that can be used
with a variety of commercial solvers.

Acknowledgments

The research was funded in part by the Air Force Ofﬁce of Scientiﬁc Research under AFOSR con-
tract FA9550-08-1-0195  and the NSF under grant CMMI-0856153. David M. Blei is supported by
ONR 175-6343  NSF CAREER 0745520  AFOSR-09NL202 and the Alfred P. Sloan foundation.

8

References

[1] Antoniak  C. E. [1974]  ‘Mixtures of Dirichlet processes with applications to Bayesian non-

parametric problems’  The Annals of Statistics 2(6)  1152–1174.

[2] Bennett  K. P. and Parrado-Hern´andez  E. [2006]  ‘The interplay of optimization and machine

learning research’  The Journal of Machine Learning Research 7  1265–1281.

[3] Blackwell  D. and MacQueen  J. B. [1973]  ‘Ferguson distributions via Polya urn schemes’ 

The Annals Statistics 1(2)  353–355.

[4] Cheung  R. K. and Powell  W. B. [2000]  ‘SHAPE-A stochastic hybrid approximation proce-

dure for two-stage stochastic programs’  Operations Research 48(1)  73–79.

[5] Fan  J. and Gijbels  I. [1996]  Local Polynomial Modelling and Its Applications  Chapman &

Hall/CRC.

[6] Ferguson  T. S. [1973]  ‘A Bayesian analysis of some nonparametric problems’  The Annals of

Statistics 1(2)  209–230.

[7] Hayﬁeld  T. and Racine  J. S. [2008]  ‘Nonparametric econometrics: The np package’  Journal

of Statistical Software 27(5)  1–32.

[8] Ishwaran  H. and James  L. F. [2003]  ‘Generalized weighted Chinese restaurant processes for

species sampling mixture models’  Statistica Sinica 13(4)  1211–1236.

[9] Kiefer  J. and Wolfowitz  J. [1952]  ‘Stochastic estimation of the maximum of a regression

function’  The Annals of Mathematical Statistics 23(3)  462–466.

[10] Nadaraya  E. A. [1964]  ‘On estimating regression’  Theory of Probability and its Applications

9(1)  141–142.

[11] Neal  R. M. [2000]  ‘Markov chain sampling methods for Dirichlet process mixture models’ 

Journal of Computational and Graphical Statistics 9(2)  249–265.

[12] Parr  R.  Painter-Wakeﬁeld  C.  Li  L. and Littman  M. [2007]  Analyzing feature generation for
value-function approximation  in ‘Proceedings of the 24th international conference on Machine
learning’  ACM  p. 744.

[13] Pitman  J. [1996]  ‘Some developments of the Blackwell-MacQueen urn scheme’  Lecture

Notes-Monograph Series 30  245–267.

[14] Powell  W. B. [2007]  Approximate Dynamic Programming: Solving the curses of dimension-

ality  Wiley-Blackwell.

[15] Powell  W. B.  Ruszczy´nski  A. and Topaloglu  H. [2004]  ‘Learning algorithms for separa-
ble approximations of discrete stochastic optimization problems’  Mathematics of Operations
Research 29(4)  814–836.

[16] Puterman  M. L. [1994]  Markov decision processes: Discrete stochastic dynamic program-

ming  John Wiley & Sons  Inc. New York  NY  USA.

[17] Robbins  H. and Monro  S. [1951]  ‘A stochastic approximation method’  The Annals of Math-

ematical Statistics 22(3)  400–407.

[18] Schwartz  E. S. [1997]  ‘The stochastic behavior of commodity prices: Implications for valua-

tion and hedging’  The Journal of Finance 52(3)  923–973.

[19] Shapiro  A.  Homem-de Mello  T. and Kim  J. [2002]  ‘Conditioning of convex piecewise linear

stochastic programs’  Mathematical Programming 94(1)  1–19.

[20] Spall  J. C. [2003]  Introduction to stochastic search and optimization: estimation  simulation 

and control  John Wiley and Sons.

[21] Sutton  R. S. and Barto  A. G. [1998]  Introduction to reinforcement learning  MIT Press Cam-

bridge  MA  USA.

[22] Tsitsiklis  J. N. and Van Roy  B. [2001]  ‘Regression methods for pricing complex American-

style options’  IEEE Transactions on Neural Networks 12(4)  694–703.

[23] Watson  G. S. [1964]  ‘Smooth regression analysis’  Sankhy¯a: The Indian Journal of Statistics 

Series A 26(4)  359–372.

9

,Asrar Ahmed
Pradeep Varakantham
Yossiri Adulyasak
Patrick Jaillet
Guobin Chen
Wongun Choi
Xiang Yu
Tony Han
Manmohan Chandraker