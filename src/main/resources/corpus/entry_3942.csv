2007,On higher-order perceptron algorithms,A new algorithm for on-line learning linear-threshold functions is proposed which efficiently combines second-order statistics about the data with the logarithmic behavior" of multiplicative/dual-norm algorithms. An initial theoretical analysis is provided suggesting that our algorithm might be viewed as a standard Perceptron algorithm operating on a transformed sequence of examples with improved margin properties. We also report on experiments carried out on datasets from diverse domains  with the goal of comparing to known Perceptron algorithms (first-order  second-order  additive  multiplicative). Our learning procedure seems to generalize quite well  and converges faster than the corresponding multiplicative baseline algorithms.",On Higher-Order Perceptron Algorithms ∗

Cristian Brotto

DICOM  Universit`a dell’Insubria
cristian.brotto@gmail.com

Claudio Gentile

DICOM  Universit`a dell’Insubria

claudio.gentile@uninsubria.it

Fabio Vitale

DICOM  Universit`a dell’Insubria

fabiovdk@yahoo.com

Abstract

A new algorithm for on-line learning linear-threshold functions is proposed which
efﬁciently combines second-order statistics about the data with the ”logarithmic
behavior” of multiplicative/dual-norm algorithms. An initial theoretical analysis is
provided suggesting that our algorithm might be viewed as a standard Perceptron
algorithm operating on a transformed sequence of examples with improved mar-
gin properties. We also report on experiments carried out on datasets from diverse
domains  with the goal of comparing to known Perceptron algorithms (ﬁrst-order 
second-order  additive  multiplicative). Our learning procedure seems to general-
ize quite well  and converges faster than the corresponding multiplicative baseline
algorithms.

1 Introduction and preliminaries

The problem of on-line learning linear-threshold functions from labeled data is one which have
spurred a substantial amount of research in Machine Learning. The relevance of this task from
both the theoretical and the practical point of view is widely recognized: On the one hand  linear
functions combine ﬂexiblity with analytical and computational tractability  on the other hand  on-
line algorithms provide efﬁcient methods for processing massive amounts of data. Moreover  the
widespread use of kernel methods in Machine Learning (e.g.  [24]) have greatly improved the scope
of this learning technology  thereby increasing even further the general attention towards the speciﬁc
task of incremental learning (generalized) linear functions. Many models/algorithms have been
proposed in the literature (stochastic  adversarial  noisy  etc.) : Any list of references would not do
justice of the existing work on this subject. In this paper  we are interested in the problem of on-
line learning linear-threshold functions from adversarially generated examples. We introduce a new
family of algorithms  collectively called the Higher-order Perceptron algorithm (where ”higher”
means here ”higher than one”  i.e.  ”higher than ﬁrst-order” descent algorithms such as gradient-
descent or standard Perceptron-like algorithms”). Contrary to other higher-order algorithms  such
as the ridge regression-like algorithms considered in  e.g.  [4  7]  Higher-order Perceptron has the
ability to put together in a principled and ﬂexible manner second-order statistics about the data with
the ”logarithmic behavior” of multiplicative/dual-norm algorithms (e.g.  [18  19  6  13  15  20]). Our
algorithm exploits a simpliﬁed form of the inverse data matrix  lending itself to be easily combined
with the dual norms machinery introduced by [13] (see also [12  23]). As we will see  this has also
computational advantages  allowing us to formulate an efﬁcient (subquadratic) implementation.

Our contribution is twofold. First  we provide an initial theoretical analysis suggesting that our
algorithm might be seen as a standard Perceptron algorithm [21] operating on a transformed se-
quence of examples with improved margin properties. The same analysis also suggests a simple
(but principled) way of switching on the ﬂy between higher-order and ﬁrst-order updates. This is
∗The authors gratefully acknowledge partial support by the PASCAL Network of Excellence under EC grant

n. 506778. This publication only reﬂects the authors’ views.

byt ∈ {−1  1}. Then the true label yt is disclosed. In the case whenbyt 6= yt we say that the algorithm

especially convenient when we deal with kernel functions  a major concern being the sparsity of the
computed solution. The second contribution of this paper is an experimental investigation of our
algorithm on artiﬁcial and real-world datasets from various domains: We compared Higher-order
Perceptron to baseline Perceptron algorithms  like the Second-order Perceptron algorithm deﬁned in
[7] and the standard (p-norm) Perceptron algorithm  as in [13  12]. We found in our experiments that
Higher-order Perceptron generalizes quite well. Among our experimental ﬁndings are the follow-
ing: 1) Higher-order Perceptron is always outperforming the corresponding multiplicative (p-norm)
baseline (thus the stored data matrix is always beneﬁcial in terms of convergence speed); 2) When
dealing with Euclidean norms (p = 2)  the comparison to Second-order Perceptron is less clear and
depends on the speciﬁc task at hand.
Learning protocol and notation. Our algorithm works in the well-known mistake bound model
of on-line learning  as introduced in [18  2]  and further investigated by many authors (e.g.  [19  6 
13  15  7  20  23] and references therein). Prediction proceeds in a sequence of trials. In each trial
t = 1  2  . . . the prediction algorithm is given an instance vector in Rn (for simplicity  all vectors are
normalized  i.e.  ||xt|| = 1  where || · || is the Euclidean norm unless otherwise speciﬁed)  and then
guesses the binary label yt ∈ {−1  1} associated with xt. We denote the algorithm’s prediction by
has made a prediction mistake. We call an example a pair (xt  yt)  and a sequence of examples S
any sequence S = (x1  y1)  (x2  y2)  . . .   (xT   yT ). In this paper  we are competing against the
class of linear-threshold predictors  parametrized by normal vectors u ∈ {v ∈ Rn : ||v|| = 1}. In
this case  a common way of measuring the (relative) prediction performance of an algorithm A is
to compare the total number of mistakes of A on S to some measure of the linear separability of S.
One such measure (e.g.  [24]) is the cumulative hinge-loss (or soft-margin) Dγ(u;S) of S w.r.t. a
t=1 max{0  γ − ytu>xt} (observe
that Dγ(u;S) vanishes if and only if u separates S with margin at least γ.
A mistake-driven algorithm A is one which updates its internal state only upon mistakes. One
can therefore associate with the run of A on S a subsequence M = M(S  A) ⊆ {1  . . .   T} of
mistaken trials. Now  the standard analysis of these algorithms allows us to restrict the behavior
of the comparison class to mistaken trials only and  as a consequence  to reﬁne Dγ(u;S) so as to
t∈M max{0  γ − ytu>xt}. This gives bounds on A’s
performance relative to the best u over a sequence of examples produced (or  actually  selected)
by A during its on-line functioning. Our analysis in Section 3 goes one step further: the number
of mistakes of A on S is contrasted to the cumulative hinge loss of the best u on a transformed
sequence ˜S = ((˜xi1  yi1)  (˜xi2  yi2)  . . .   (˜xim   yim))  where each instance xik gets transformed
into ˜xik through a mapping depending only on the past behavior of the algorithm (i.e.  only on
examples up to trial t = ik−1). As we will see in Section 3  this new sequence ˜S tends to be ”more
separable” than the original sequence  in the sense that if S is linearly separable with some margin 
then the transformed sequence ˜S is likely to be separable with a larger margin.

linear classiﬁer u at a given margin value γ > 0: Dγ(u;S) =PT

include only trials in M: Dγ(u;S) = P

2 The Higher-order Perceptron algorithm

The algorithm (described in Figure 1) takes as input a sequence of nonnegative parameters ρ1  ρ2  ... 
and maintains a product matrix Bk (initialized to the identity matrix I) and a sum vector vk (ini-
tialized to 0). Both of them are indexed by k  a counter storing the current number of mistakes
(plus one). Upon receiving the t-th normalized instance vector xt ∈ Rn  the algorithm computes
t )
while vector vk−1 is updated additively through the standard Perceptron rule vk = vk−1 + yt xt.

its binary prediction valuebyt as the sign of the inner product between vector Bk−1vk−1 and vector
Bk−1xt. Ifbyt 6= yt then matrix Bk−1 is updates multiplicatively as Bk = Bk−1 (I − ρk xtx>
The new matrix Bk and the new vector vk will be used in the next trial. Ifbyt = yt no update is
behavior be substantially different from Perceptron’s) we need to ensureP∞

performed (hence the algorithm is mistake driven). Observe that ρk = 0 for any k makes this algo-
rithm degenerate into the standard Perceptron algorithm [21]. Moreover  one can easily see that  in
order to let this algorithm exploit the information collected in the matrix B (and let the algorithm’s
k=1 ρk = ∞. In the
sequel  our standard choice will be ρk = c/k  with c ∈ (0  1). See Sections 3 and 4.
Implementing Higher-Order Perceptron can be done in many ways. Below  we quickly describe
three of them  each one having its own merits.
1) Primal version. We store and update an n×n matrix Ak = B>

k Bk and an n-dimensional column

Parameters: ρ1  ρ2  ... ∈ [0  1).
Initialization: B0 = I; v0 = 0; k = 1.
Repeat for t = 1  2  . . .   T :

||xt|| = 1;

1. Get instance xt ∈ Rn 
3. Get label yt ∈ {−1  +1};

2. Predictbyt = SGN(w>
4. ifbyt 6= yt then:

k−1xt) ∈ {−1  +1}  where wk−1 = B>

k−1Bk−1vk−1;

vk = vk−1 + yt xt
Bk = Bk−1 (I − ρk xtx>
t )
k ← k + 1.

Figure 1: The Higher-order Perceptron algorithm (for p = 2).

(cid:21)

i j=1 d(k)

−ρk b
>
k

d(k)
k k

  where bk = Dk−1X>

k−1xk  and d(k)

k−1x is equal to g>

k−1X>

1   ...  h(k)
j   it is not hard to show that the margin value w>

vector vk. Matrix Ak is updated as Ak = Ak−1− ρAk−1xx>− ρxx>Ak−1 + ρ2(x>Ak−1x)xx> 
taking O(n2) operations  while vk is updated as in Figure 1. Computing the algorithm’s margin
v>Ax can then be carried out in time quadratic in the dimension n of the input space.
2) Dual version. This implementation allows us the use of kernel functions (e.g.  [24]). Let us
denote by Xk the n × k matrix whose columns are the n-dimensional instance vectors x1  ...  xk
where a mistake occurred so far  and yk be the k-dimensional column vector of the corresponding
labels. We store and update the k × k matrix Dk = [d(k)
i j=1  the k × k diagonal matrix Hk =
i j ]k
DIAG{hk}  hk = (h(k)
k )> = X>
k Xk yk  and the k-dimensional column vector gk = yk +
If we interpret the primal matrix Ak above as Ak =
Dk Hk 1k  being 1k a vector of k ones.
i j xix>
k−1x 
and can be computed through O(k) extra inner products. Now  on the k-th mistake  vector g can
be updated with O(k2) extra inner products by updating D and H in the following way. We let
D0 and H0 be empty matrices. Then  given Dk−1 and Hk−1 = DIAG{hk−1}  we have1 Dk =
k. On

I +Pk
(cid:20) Dk−1 −ρk bk
This amounts to say that matrix Ak = I +Pk

the other hand  Hk = DIAG{hk−1 + yk X>
Observe that on trials when ρk = 0 matrix Dk−1 is padded with a zero row and a zero column.
j   is not updated  i.e.  Ak = Ak−1. A
closer look at the above update mechanism allows us to conclude that the overall extra inner prod-
ucts needed to compute gk is actually quadratic only in the number of past mistaken trials having
ρk > 0. This turns out to be especially important when using a sparse version of our algorithm
which  on a mistaken trial  decides whether to update both B and v or just v (see Section 4).
3) Implicit primal version and the dual norms algorithm. This is based on the simple observation
that for any vector z we can compute Bkz by unwrapping Bk as in Bkz = Bk−1(I − ρxx>)z =
Bk−1z0  where vector z0 = (z − ρx x>z) can be calculated in time O(n). Thus computing
the margin v>B>
k−1Bk−1x actually takes O(nk). Maintaining this implicit representation for the
product matrix B can be convenient when an efﬁcient dual version is likely to be unavailable 
as is the case for the multiplicative (or  more generally  dual norms) extension of our algorithm.
We recall that a multiplicative algorithm is useful when learning sparse target hyperplanes (e.g. 
[18  15  3  12  11  20]). We obtain a dual norms algorithm by introducing a norm parameter p ≥ 2 
and the associated gradient mapping2 g : θ ∈ Rn → ∇θ||θ||2
p / 2 ∈ Rn. Then  in Figure 1  we
normalize instance vectors xt w.r.t. the p-norm  we deﬁne wk−1 = B>
k−1g(Bk−1vk−1)  and gen-
eralize the matrix update as Bk = Bk−1(I − ρkxtg(xt)>). As we will see  the resulting algorithm
combines the multiplicative behavior of the p-norm algorithms with the ”second-order” information
contained in the matrix Bk. One can easily see that the above-mentioned argument for computing
the margin g(Bk−1vk−1)>Bk−1x in time O(nk) still holds.

k Xk−1bk − 2ρk + ρ2
k−1X>

k−1xk + yk.

k k = ρ2
k }  with h(k)

k x>
k = y>

i j=1 d(k)

i j xix>

k−1xk   h(k)

1Observe that  by construction  Dk is a symmetric matrix.
2This mapping has also been used in [12  11]. Recall that setting p = O(log n) yields an algorithm similar

to Winnow [18]. Also  notice that p = 2 yields g = identity.

3 Analysis

We express the performance of the Higher-order Perceptron algorithm in terms of the hinge-loss
behavior of the best linear classiﬁer over the transformed sequence

˜S = (B0xt(1)  yt(1))  (B1xt(2)  yt(2))  (B2xt(3)  yt(3))  . . .  

(1)
being t(k) the trial where the k-th mistake occurs  and Bk the k-th matrix produced by the algorithm.
Observe that each feature vector xt(k) gets transformed by a matrix Bk depending on past examples
only. This is relevant to the argument that ˜S tends to have a larger margin than the original sequence
(see the discussion at the end of this section). This neat ”on-line structure” does not seem to be
shared by other competing higher-order algorithms  such as the ”ridge regression-like” algorithms
considered  e.g.  in [25  4  7  23]. For the sake of simplicity  we state the theorem below only in the
case p = 2. A more general statement holds when p ≥ 2.

Theorem 1 Let the Higher-order Perceptron algorithm in Figure 1 be run on a sequence of exam-
ples S = (x1  y1)  (x2  y2)  . . .   (xT   yT ). Let the sequence of parameters ρk satisfy 0 ≤ ρk ≤
k−1xt|   where xt is the k-th mistaken instance vector  and c ∈ (0  1]. Then the total number m
1−c
1+|v>
of mistakes satisﬁes3

s

Dγ(u; ˜Sc))

m ≤ α

γ

+ α2
2γ2 + α

γ

α

Dγ(u; ˜Sc))

γ

+ α2
4γ2  

(2)

holding for any γ > 0 and any unit norm vector u ∈ Rn  where α = α(c) = (2 − c)/c.
Proof. The analysis deliberately mimics the standard Perceptron convergence analysis [21]. We ﬁx
an arbitrary sequence S = (x1  y1)  (x2  y2)  . . .   (xT   yT ) and let M ⊆ {1  2  . . .   T} be the set
of trials where the algorithm in Figure 1 made a mistake. Let t = t(k) be the trial where the k-th
mistake occurred. We study the evolution of ||Bkvk||2 over mistaken trials. Notice that the matrix
B>
k Bk is positive semideﬁnite for any k. We can write

||Bkvk||2 = ||Bk−1 (I − ρk xtx>

t ) (vk−1 + yt xt)||2

(from the update rule vk = vk−1 + yt xt and Bk = Bk−1 (I − ρk xtx>
= ||Bk−1vk−1 + yt (1 − ρkytvk−1xt − ρk)Bk−1xt||2
= ||Bk−1vk−1||2 + 2 ytrk v>

k||Bk−1xt||2 

k−1Bk−1xt + r2

k−1B>

(using ||xt|| = 1)

t ) )

t Ak−1 xt  where we set Ak = B>

k ≤ (1+ρk|vk−1xt|−ρk)2 ≤ (2−c)2. Now  using yt v>

where we set for brevity rk = 1 − ρkytvk−1xt − ρk. We proceed by upper and lower bounding the
above chain of equalities. To this end  we need to ensure rk ≥ 0. Observe that ytvk−1xt ≥ 0 implies
rk ≥ 0 if and only if ρk ≤ 1/(1 + ytvk−1xt). On the other hand  if ytvk−1xt < 0 then  in order for
rk to be nonnegative  it sufﬁces to pick ρk ≤ 1. In both cases ρk ≤ (1 − c)/(1 + |vk−1xt|) implies
k−1Bk−1xt ≤ 0
rk ≥ c > 0  and also r2
||Bkvk||2 − ||Bk−1vk−1||2 ≤ (2 − c)2 ||Bk−1 xt||2 =
(combined with rk ≥ 0)  we conclude that
(2 − c)2 x>
k Bk. A simple4 (and crude) upper bound on the last
t Ak−1 xt ≤ ||Ak−1||  the spectral norm (largest
term follows by observing that ||xt|| = 1 implies x>
eigenvalue) of Ak−1. Since a factor matrix of the form (I − ρ xx>) with ρ ≤ 1 and ||x|| = 1 has
t(i)||2 ≤ 1. Therefore 
spectral norm one  we have x>
summing over k = 1  . . .   m = |M| (or  equivalently  over t ∈ M) and using v0 = 0 yields the
upper bound
(3)
To ﬁnd a lower bound of the left-hand side of (3)  we ﬁrst pick any unit norm vector u ∈ Rn  and
apply the standard Cauchy-Schwartz inequality: ||Bmvm|| ≥ u>Bmvm. Then  we observe that for
a generic trial t = t(k) the update rule of our algorithm allows us to write

t Ak−1 xt ≤ ||Ak−1|| ≤Qk−1

||Bmvm||2 ≤ (2 − c)2 m.

i=1 ||I − ρi xt(i)x>

k−1B>

u>Bkvk − u>Bk−1vk−1 = rk yt u>Bk−1xt ≥ rk (γ − max{0  γ − yt u>Bk−1xt}) 

where the last inequality follows from rk ≥ 0 and holds for any margin value γ > 0. We sum
3The subscript c in ˜Sc emphasizes the dependence of the transformed sequence on the choice of c. Note
that in the special case c = 1 we have ρk = 0 for any k and α = 1  thereby recovering the standard Perceptron
bound for nonseparable sequences (see  e.g.  [12]).
4A slightly more reﬁned bound can be derived which depends on the trace of matrices I − Ak. Details will

be given in the full version of this paper.

the above over k = 1  . . .   m and exploit c ≤ rk ≤ 2 − c after rearranging terms. This gets
||Bmvm|| ≥ u>Bmvm ≥ c γ m− (2− c)Dγ(u; ˜Sc). Combining with (3) and solving for m gives
(cid:3)
the claimed bound.

From the above result one can see that our algorithm might be viewed as a standard Perceptron
algorithm operating on the transformed sequence ˜Sc in (1). We now give a qualitative argument 
which is suggestive of the improved margin properties of ˜Sc. Assume for simplicity that all examples
(xt  yt) in the original sequence are correctly classiﬁed by hyperplane u with the same margin
γ = yt u>xt > 0  where t = t(k). According to Theorem 1  the parameters ρ1  ρ2  . . . should be
small positive numbers. Assume  again for simplicity  that all ρk are set to the same small enough
t(i)) can be approximated as
t(i). Then  to the extent that the above approximation holds  we can write:5

value ρ > 0. Then  up to ﬁrst order  matrix Bk =Qk
Bk ’ I − ρPk
yt u>Bk−1xt = yt u>(cid:0)I − ρPk−1
(cid:0)Pk−1

(cid:1)xt = yt u>(cid:0)I − ρPk−1

(cid:1)xt = γ − ρ γ yt v>

i=1 yt(i)xt(i) yt(i)x>

i=1(I − ρ xt(i)x>

i=1 yt(i) u>xt(i) yt(i)x>

t(i)

(cid:1)xt

t(i)

k−1xt.

i=1 xt(i)x>

= yt u>xt − ρ yt

i=1 xt(i)x>

t(i)

k−1B>

k−1wk−1 = v>

k−1xt ≤ 0 is more likely to imply yt v>

Now  yt v>
k−1xt is the margin of the (ﬁrst-order) Perceptron vector vk−1 over a mistaken trial for
the Higher-order Perceptron vector wk−1. Since the two vectors vk−1 and wk−1 are correlated
k−1Bk−1vk−1 = ||Bk−1vk−1||2 ≥ 0) the mistaken condition
(recall that v>
k−1xt ≤ 0 than the opposite. This tends to yield a
yt w>
margin larger than the original margin γ. As we mentioned in Section 2  this is also advantageous
from a computational standpoint  since in those cases the matrix update Bk−1 → Bk might be
skipped (this is equivalent to setting ρk = 0)  still Theorem 1 would hold.
Though the above might be the starting point of a more thorough theoretical understanding of the
margin properties of our algorithm  in this paper we prefer to stop early and leave any further inves-
tigation to collecting experimental evidence.

4 Experiments

We tested the empirical performance of our algorithm by conducting a number of experiments on a
collection of datasets  both artiﬁcial and real-world from diverse domains (Optical Character Recog-
nition  text categorization  DNA microarrays). The main goal of these experiments was to compare
Higher-order Perceptron (with both p = 2 and p > 2) to known Perceptron-like algorithms  such
as ﬁrst-order [21] and second-order Perceptron [7]  in terms of training accuracy (i.e.  convergence
speed) and test set accuracy. The results are contained in Tables 1  2  3  and in Figure 2.
Task 1: DNA microarrays and artiﬁcial data. The goal here was to test the convergence proper-
ties of our algorithms on sparse target learning tasks. We ﬁrst tested on a couple of well-known DNA
microarray datasets. For each dataset  we ﬁrst generated a number of random training/test splits (our
random splits also included random permutations of the training set). The reported results are aver-
aged over these random splits. The two DNA datasets are: i. The ER+/ER− dataset from [14]. Here
the task is to analyze expression proﬁles of breast cancer and classify breast tumors according to ER
(Estrogen Receptor) status. This dataset (which we call the “Breast” dataset) contains 58 expression
proﬁles concerning 3389 genes. We randomly split 1000 times into a training set of size 47 and a
test set of size 11.
ii. The “Lymphoma” dataset [1]. Here the goal is to separate cancerous and
normal tissues in a large B-Cell lymphoma problem. The dataset contains 96 expression proﬁles
concerning 4026 genes. We randomly split the dataset into a training set of size 60 and a test set of
size 36. Again  the random split was performed 1000 times. On both datasets  the tested algorithms
have been run by cycling 5 times over the current training set. No kernel functions have been used.
We also artiﬁcially generated two (moderately) sparse learning problems with margin γ ≥ 0.005 at
labeling noise levels η = 0.0 (linearly separable) and η = 0.1  respectively. The datasets have been
generated at random by ﬁrst generating two (normalized) target vectors u ∈ {−1  0  +1}500  where
the ﬁrst 50 components are selected independently at random in {−1  +1} and the remaining 450
5Again  a similar argument holds in the more general setting p ≥ 2. The reader should notice how important

the dependence of Bk on the past is to this argument.

components are 0. Then we set η = 0.0 for the ﬁrst target and η = 0.1 for the second one and 
corresponding to each of the two settings  we randomly generated 1000 training examples and 1000
test examples. The instance vectors are chosen at random from [−1  +1]500 and then normalized. If
u · xt ≥ γ then a +1 label is associated with xt. If u · xt ≤ −γ then a −1 label is associated with
xt. The labels so obtained are ﬂipped with probability η. If |u · xt| < γ then xt is rejected and
a new vector xt is drawn. We call the two datasets ”Artiﬁcial 0.0” and ”Artiﬁcial 0.1”. We tested
our algorithms by training over an increasing number of epochs and checking the evolution of the
corresponding test set accuracy. Again  no kernel functions have been used.
Task 2: Text categorization. The text categorization datasets are derived from the ﬁrst 20 000
newswire stories in the Reuters Corpus Volume 1 (RCV1  [22]). A standard TF-IDF bag-of-words
encoding was used to transform each news story into a normalized vector of real attributes. We
built four binary classiﬁcation problems by “binarizing” consecutive news stories against the four
target categories 70  101  4  and 59. These are the 2nd  3rd  4th  and 5th most frequent6 categories 
respectively  within the ﬁrst 20 000 news stories of RCV1. We call these datasets RCV1x  where
x = 70  101  4  59. Each dataset was split into a training set of size 10 000 and a test set of the same
size. All algorithms have been trained for a single epoch. We initially tried polynomial kernels 
then realized that kernel functions did not signiﬁcantly alter our conclusions on this task. Thus the
reported results refer to algorithms with no kernel functions.
Task 3: Optical character recognition (OCR). We used two well-known OCR benchmarks: the
USPS dataset and the MNIST dataset [16] and followed standard experimental setups  such as the
one in [9]  including the one-versus-rest scheme for reducing a multiclass problem to a set of binary
tasks. We used for each algorithm the standard Gaussian and polynomial kernels  with parameters
chosen via 5-fold cross validation on the training set across standard ranges. Again  all algorithms
have been trained for a single epoch over the training set. The results in Table 3 only refer to the
best parameter settings for each kernel.
Algorithms. We implemented the standard Perceptron algorithm (with and without kernels)  the
Second-order Perceptron algorithm  as described in [7] (with and without kernels)  and our Higher-
order Perceptron algorithm. The implementation of the latter algorithm (for both p = 2 and p > 2)
was ”implicit primal” when tested on the sparse learning tasks  and in dual variables for the other two
tasks. When using Second-order Perceptron  we set its parameter a (see [7] for details) by testing
on a generous range of values. For brevity  only the settings achieving the best results are reported.
On the sparse learning tasks we tried Higher-order Perceptron with norm p = 2  4  7  10  while on
the other two tasks we set p = 2. In any case  for each value of p  we set7 ρk = c/k  with c =
0  0.2  0.4  0.6  0.8. Since c = 0 corresponds to a standard p-norm Perceptron algorithm [13  12] we
tried to emphasize the comparison c = 0 vs. c > 0. Finally  when using kernels on the OCR tasks 
we also compared to a sparse dual version of Higher-order Perceptron. On a mistaken round t =
t(k)  this algorithm sets ρk = c/k if yt vk−1xt ≥ 0  and ρk = 0 otherwise (thus  when yt vk−1xt <
0 the matrix Bk−1 is not updated). For the sake of brevity  the standard Perceptron algorithm is
called FO (”First Order”)  the Second-order algorithm is denoted by SO (”Second Order”)  while the
Higher-order algorithm with norm parameter p and ρk = c/k is abbreviated as HOp(c). Thus  for
instance  FO = HO2(0).
Results and conclusions. Our Higher-order Perceptron algorithm seems to deliver interesting
results. In all our experiments HOp(c) with c > 0 outperforms HOp(0). On the other hand  the
comparison HOp(c) vs. SO depends on the speciﬁc task. On the DNA datasets  HOp(c) with c > 0 is
clearly superior in Breast. On Lymphoma  HOp(c) gets worse as p increases. This is a good indica-
tion that  in general  a multiplicative algorithm is not suitable for this dataset. In any case  HO2 turns
out to be only slightly worse than SO. On the artiﬁcial datasets HOp(c) with c > 0 is always better
than the corresponding p-norm Perceptron algorithm. On the text categorization tasks  HO2 tends to
perform better than SO. On USPS  HO2 is superior to the other competitors  while on MNIST it per-
forms similarly when combined with Gaussian kernels (though it turns out to be relatively sparser) 
while it is slightly inferior to SO when using polynomial kernels. The sparse version of HO2 cuts
the matrix updates roughly by half  still maintaining a good performance. In all cases HO2 (either
sparse or not) signiﬁcantly outperforms FO.
In conclusion  the Higher-order Perceptron algorithm is an interesting tool for on-line binary clas-

6We did not use the most frequent category because of its signiﬁcant overlap with the other ones.
7Notice that this setting fulﬁlls the condition on ρk stated in Theorem 1.

Table 1: Training and test error on the two datasets ”Breast” and ”Lymphoma”. Training error is
the average total number of updates over 5 training epochs  while test error is the average fraction
of misclassiﬁed patterns in the test set  The results refer to the same training/test splits. For each
algorithm  only the best setting is shown (best training and best test setting coincided in these ex-
periments). Thus  for instance  HO2 differs from FO because of the c parameter. We emphasized
the comparison HO7(0) vs. HO7(c) with best c among the tested values. According to Wilcoxon
signed rank test  an error difference of 0.5% or larger might be considered signiﬁcant. In bold are
the smallest ﬁgures achieved on each row of the table.
HO4
24.5

HO7(0)
47.4

BREAST

HO2
21.7

FO
45.2

HO7
24.5
23.4% 16.4% 13.3% 15.7% 12.0%
20.0

HO10
32.4
13.5
23.1
11.8% 10.0% 10.0% 11.5% 11.5% 11.9%

23.0

SO
29.6
15.0%
19.3
9.6%

LYMPHOMA

22.1

19.6

18.9

TRAIN
TEST
TRAIN
TEST

Figure 2: Experiments on the two artiﬁcial datasets (Artiﬁcial0.0  on the left  and Artiﬁcial0.1  on
the right). The plots give training and test behavior as a function of the number of training epochs.
Notice that the test set in Artiﬁcial0.1 is affected by labelling noise of rate 10%. Hence  a visual
comparison between the two plots at the bottom can only be made once we shift down the y-axis of
the noisy plot by 10%. On the other hand  the two training plots (top) are not readily comparable.
The reader might have difﬁculty telling apart the two kinds of algorithms HOp(0.0) and HOp(c) with
c > 0. In practice  the latter turned out to be always slightly superior in performance to the former.

siﬁcation  having the ability to combine multiplicative (or nonadditive) and second-order behavior
into a single inference procedure. Like other algorithms  HOp can be extended (details omitted due
to space limitations) in several ways through known worst-case learning technologies  such as large
margin (e.g.  [17  11])  label-efﬁcient/active learning (e.g.  [5  8])  and bounded memory (e.g.  [10]).

References
[1] A. Alizadeh  et al. (2000). Distinct types of diffuse large b-cell lymphoma identiﬁed by gene expression

proﬁling. Nature  403  503–511.

[2] D. Angluin (1988). Queries and concept learning. Machine Learning  2(4)  319–342.
[3] P. Auer & M.K. Warmuth (1998). Tracking the best disjunction. Machine Learning  32(2)  127–150.
[4] K.S. Azoury & M.K. Warmuth (2001). Relative loss bounds for on-line density estimation with the

exponential familiy of distributions. Machine Learning  43(3)  211–246.

[5] A. Bordes  S. Ertekin  J. Weston  & L. Bottou (2005). Fast kernel classiﬁers with on-line and active

learning. JMLR  6  1579–1619.

[6] N. Cesa-Bianchi  Y. Freund  D. Haussler  D.P. Helmbold  R.E. Schapire  & M.K. Warmuth (1997). How

to use expert advice. J. ACM  44(3)  427–485.

1510205321# of training updates600800500400300Training updates vs training epochs on Artificial      # of training epochs0.0700HO  (0.0)*SO    (a = 0.2)7HO  (0.4)2HO  (0.4)4HO    (0.4)7FO = HO  (0.0)*******21510205321# of training updates160024001200800400Training updates vs training epochs on Artificial      # of training epochs0.12000HO  (0.0)*SO    (a = 0.2)7HO  (0.4)2HO  (0.4)4HO  (0.4)7FO = HO  (0.0)*******21510205321Test error rates18%26%14%10%  6%Test error rates vs training epochs on Artificial      # of training epochs0.022%HO  (0.0)*SO    (a = 0.2)7HO  (0.4)2HO  (0.4)4HO    (0.4)7FO = HO  (0.0)**2*****1510205321Test error rates (minus 10%)18%26%14%10%  6%Test error rates vs training epochs on Artificial      # of training epochs0.122%HO  (0.0)*SO    (a = 0.2)7HO  (0.4)2HO  (0.4)4HO    (0.4)7FO = HO  (0.0)**2*****Table 2: Experimental results on the four binary classiﬁcation tasks derived from RCV1. ”Train”
denotes the number of training corrections  while ”Test” gives the fraction of misclassiﬁed patterns
in the test set. Only the results corresponding to the best test set accuracy are shown. In bold are the
smallest ﬁgures achieved for each of the 8 combinations of dataset (RCV1x  x = 70  101  4  59) and
phase (training or test).

FO

HO2

SO

RCV170
RCV1101
RCV14
RCV159

TRAIN
993
673
803
767

TEST
7.20%
6.39%
6.14%
6.45%

TRAIN
941
665
783
762

TEST
6.83%
5.81%
5.94%
6.04%

TRAIN
880
677
819
760

TEST
6.95%
5.48%
6.05%
6.84%

Table 3: Experimental results on the OCR tasks. ”Train” denotes the total number of training cor-
rections  summed over the 10 categories  while ”Test” denotes the fraction of misclassiﬁed patterns
in the test set. Only the results corresponding to the best test set accuracy are shown. For the sparse
version of HO2 we also reported (in parentheses) the number of matrix updates during training. In
bold are the smallest ﬁgures achieved for each of the 8 combinations of dataset (USPS or MNIST) 
kernel type (Gaussian or Polynomial)  and phase (training or test).

USPS

GAUSS
POLY

MNIST GAUSS

POLY

FO

TRAIN
1385
1609
5834
8148

TEST
6.53%
7.37%
2.10%
3.04%

HO2

TEST

Sparse HO2
TRAIN
4.76% 965 (440)
5.71% 1081 (551)
1.79% 5363 (2596)
2.27% 6476 (3311)

TEST
5.13%
5.52%
1.81%
2.28%

TRAIN
945
1090
5351
6404

SO

TRAIN
1003
1054
5684
6440

TEST
5.05%
5.53%
1.82%
2.03%

[7] N. Cesa-Bianchi  A. Conconi & C. Gentile (2005). A second-order perceptron algorithm. SIAM Journal

of Computing  34(3)  640–668.

[8] N. Cesa-Bianchi  C. Gentile  & L. Zaniboni (2006). Worst-case analysis of selective sampling for linear-

threshold algorithms. JMLR  7  1205–1230.

[9] C. Cortes & V. Vapnik (1995). Support-vector networks. Machine Learning  20(3)  273–297.
[10] O. Dekel  S. Shalev-Shwartz  & Y. Singer (2006). The Forgetron: a kernel-based Perceptron on a ﬁxed

budget. NIPS 18  MIT Press  pp. 259–266.

[11] C. Gentile (2001). A new approximate maximal margin classiﬁcation algorithm. JMLR  2  213–242.
[12] C. Gentile (2003). The Robustness of the p-norm Algorithms. Machine Learning  53(3)  pp. 265–299.
[13] A.J. Grove  N. Littlestone & D. Schuurmans (2001). General convergence results for linear discriminant

updates. Machine Learning Journal  43(3)  173–210.

[14] S. Gruvberger  et al. (2001). Estrogen receptor status in breast cancer is associated with remarkably dis-

tinct gene expression patterns. Cancer Res.  61  5979–5984.

[15] J. Kivinen  M.K. Warmuth  & P. Auer (1997). The perceptron algorithm vs. winnow: linear vs. logarithmic

mistake bounds when few input variables are relevant. Artiﬁcial Intelligence  97  325–343.

[16] Y. Le Cun  et al. (1995). Comparison of learning algorithms for handwritten digit recognition. ICANN

1995  pp. 53–60.

[17] Y. Li & P. Long (2002). The relaxed online maximum margin algorithm. Machine Learning  46(1-3) 

361–387.

[18] N. Littlestone (1988). Learning quickly when irrelevant attributes abound: a new linear-threshold algo-

rithm. Machine Learning  2(4)  285–318.

[19] N. Littlestone & M.K. Warmuth (1994). The weighted majority algorithm. Information and Computation 

108(2)  212–261.

[20] P. Long & X. Wu (2004). Mistake bounds for maximum entropy discrimination. NIPS 2004.
[21] A.B.J. Novikov (1962). On convergence proofs on perceptrons. Proc. of the Symposium on the Mathe-

matical Theory of Automata  vol. XII  pp. 615–622.

[22] Reuters: 2000. http://about.reuters.com/researchandstandards/corpus/.
[23] S. Shalev-Shwartz & Y. Singer (2006). Online Learning Meets Optimization in the Dual. COLT 2006  pp.

423–437.

[24] B. Schoelkopf & A. Smola (2002). Learning with kernels. MIT Press.
[25] Vovk  V. (2001). Competitive on-line statistics. International Statistical Review  69  213-248.

,Rie Johnson
Tong Zhang
firdaus janoos
Huseyin Denli
Niranjan Subrahmanya
Patrick Putzky
Max Welling