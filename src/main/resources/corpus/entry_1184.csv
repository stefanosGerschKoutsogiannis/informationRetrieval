2010,Convex Multiple-Instance Learning by Estimating Likelihood Ratio,Multiple-Instance learning has been long known as a hard non-convex problem.
 In this work  we propose an approach that recasts it as a convex likelihood ratio
 estimation problem. Firstly  the constraint in multiple-instance learning is reformulated
 into a convex constraint on the likelihood ratio. Then we show that a joint
 estimation of a likelihood ratio function and the likelihood on training instances
 can be learned convexly. Theoretically  we prove a quantitative relationship between
 the risk estimated under the 0-1 classification loss  and under a loss function
 for likelihood ratio estimation. It is shown that our likelihood ratio estimation is
 generally a good surrogate for the 0-1 loss  and separates positive and negative
 instances well. However with the joint estimation it tends to underestimate the
 likelihood of an example to be positive. We propose to use these likelihood ratio
 estimates as features  and learn a linear combination on them to classify the bags.
 Experiments on synthetic and real datasets show the superiority of the approach.,Convex Multiple-Instance Learning by

Estimating Likelihood Ratio

Fuxin Li and Cristian Sminchisescu

Institute for Numerical Simulation  University of Bonn

{fuxin.li cristian.sminchisescu}@ins.uni-bonn.de

Abstract

We propose an approach to multiple-instance learning that reformulates the prob-
lem as a convex optimization on the likelihood ratio between the positive and the
negative class for each training instance. This is casted as joint estimation of both
a likelihood ratio predictor and the target (likelihood ratio variable) for instances.
Theoretically  we prove a quantitative relationship between the risk estimated un-
der the 0-1 classiﬁcation loss  and under a loss function for likelihood ratio. It
is shown that likelihood ratio estimation is generally a good surrogate for the 0-1
loss  and separates positive and negative instances well. The likelihood ratio esti-
mates provide a ranking of instances within a bag and are used as input features
to learn a linear classiﬁer on bags of instances.
Instance-level classiﬁcation is
achieved from the bag-level predictions and the individual likelihood ratios. Ex-
periments on synthetic and real datasets demonstrate the competitiveness of the
approach.

1 Introduction

Multiple Instance Learning (MIL) has been proposed over 10 years ago as a methodology to learn
models under weak labeling constraints [1]. Unlike traditional binary classiﬁcation problems  the
positive items are represented as bags  which are sets of instances. A feature vector is used to
represent each instance in the bag. There is an OR relationship in a bag: if one of the feature
vectors is classiﬁed as positive  the entire bag is considered positive. A simple intuition is: one has
a number of keys and faces a locked door. To enter the door  we only need one matching keys.
MIL is a natural weak labeling formulation for text categorization [2] and computer vision problems
[3]. In document classiﬁcation  one is given ﬁles made of many sentences  and often only a few
are useful. In computer vision  an image can be decomposed into different regions  and only some
delineate objects. Therefore  MIL can be used in sophisticated tasks  such as identifying the location
of object parts from bounding box information in images [4]. Although efforts have been made to
provide datasets with increasingly more detailed supervisory information [5]  without automation
such a minutiae level of detail becomes prohibitive for large datasets  or more complicated data like
video [6  7]. In this case  one necessarily needs to resort to multiple-instance learning.

MIL is interesting mainly because of its potential to provide instance-level labels from weak supervi-
sory information. However the state-of-the-art in MIL is often obtained by simply using a weighted
sum of kernel values between all instance pairs within the bags  while ignoring the prediction of
instance labels [8  9  10]. It is intriguing why MIL algorithms that exploit instance level information
cannot achieve better performance  as constraints at instance level seems abundant – none of the
negative instances is positive. This should provide additional constraints in deﬁning the region of
positive instances and should help classiﬁcation in input space.

A major challenge is the non-convexity of many instance-level MIL algorithms [2  11  12  13  14].
Most of these algorithms perform alternating minimization on the classiﬁer and the instance weights.

1

This procedure usually gives only a local optimum since the objective is non-convex. The benchmark
performance of MIL methods is overall quite similar  although techniques differ signiﬁcantly: some
assign binary weights to instances [2]  some assign real weights [12  13]  yet others use probabilistic
formulations [14]; some optimize using conventional alternating minimization  others use convex-
concave procedures [11].

Gehler and Chapelle [15] have recently performed an interesting analysis of the MIL costs  where
deterministic annealing (DA) was used to compute better local optima for several formulations. In
the case of a previous mi-SVM formulation [2]  annealing methods did not improve the performance
signiﬁcantly. A newly proposed algorithm  ALP-SVM  was also introduced  which used a preset pa-
rameter deﬁning the ﬁxed ratio of witnesses – the true positive instances in a positive bag. Excellent
results were obtained with this witness rate parameter set to the correct value. However  in prac-
tice it is unclear whether this can be known beforehand and whether it is stationary across different
bags. In principle  the witness rate should also be estimated  and this learning stage partially ac-
count for the non-convexity of the MIL problem. It remains however unclear whether the observed
performance variations are caused by non-convexity or by other modeling aspects.

Although performance considerations have hindered the application of MIL to practical problems 
the methodology has started to gain momentum recently [4  16]. The success of the Latent SVM for
person detection [4] shows that a standard MIL procedure (the reformulation of the alternating mini-
mization MI-SVM algorithm in [2]) can achieve good results if properly initialized. However  prop-
er initialization of MIL remains elusive in general  as it often requires engineering experience with
the individual problem structure. Therefore  it is still of broad interest to develop an initialization-
independent formulation for MIL. Recently Li et al. [17] proposed a convex instance-level MIL
algorithm based on multiple kernel learning  where one kernel was used for each possible combi-
nation of instances. This creates an exponential number of constraints and requires a cutting-plane
solver. Although the formulation is convex  its scalability drops signiﬁcantly for bags with many
instances.

In this paper we make an alternative attempt towards a convex formulation: we establish that non-
convex MIL constraints can be recast reliably into convex constraints on the likelihood ratio between
the positive and negative classes for each instance. We transform the multiple-instance learning
problem into a convex joint estimation of the likelihood ratio function and the likelihood ratio values
on training instances. The choice of the jointly convex loss function is rich  remarkably at least from
a family of f-divergences. Theoretically  we prove consistency results for likelihood ratio estimation 
thus showing that f-divergence loss functions upper bound the classiﬁcation 0-1 loss tightly  unless
the likelihood is very large.

A support vector regression scheme is implemented to estimate the likelihood ratio  and it is shown
to separate positive and negative instances well. However  determining the correct threshold for
instance classiﬁcation from the training set remain non-trivial. To address this problem  we propose
a post-processing step based on a bag classiﬁer computed as a linear combination of likelihood
ratios. While this is shown to be suboptimal in synthetic experiments  it still achieves state-of-the-
art results in practical datasets  demonstrating the vast potential of the proposed approach.

2 Convex Reformulation of the Multiple Instance Constraint

1   x+

2   . . .   x+

1   x−

2   . . .   x−
n−

n+ }  X − = {x−

Let us consider a learning problem with n training instances in total  n+ positive and n− negative.
In negative bags  every instance is negative  hence we do not separately deﬁne such bags – instead
we directly work with the instances. Let B = {B1  B2  . . .   Bk} be positive bags and X + =
{x+
} be the training input  where each xi belongs to a
positive bag Bj and each x−
is a negative instance. The goal of multiple instance learning is  given
i
{X +  X −  B}  to learn a decision rule  sign(f (x))  to predict the label {+1  −1} for the test instance
x.
The MIL problem can be characterized by two properties. 1) negative-exclusion: if none of the
instances in a bag is positive  the bag is not positive. 2) positive-identiﬁability:
if one of the
instances in the bag is positive  the bag is positive. These properties are equivalent to a constraint
maxxi∈Bj f (xi) ≥ 0 on positive bags. This constraint is not convex since the negative max function

is concave. Reformulation into a sum constraint such as P f (x) ≥ 0 would be convex  when

2

f (x) = wT x is linear [6]. However  this hardly retains positive-identiﬁability  since if there is
only one xi with f (xi) > 0  this can be superseded by other instances with f (xi) < 0. Apparently 
the distinction between the sum and the max operations is signiﬁcant and difﬁcult to ignore in this
context.

However  in this paper we show that if MIL conditions are formulated as constraints on the likelihood
ratio  convexity can be achieved. For example  the constraint:

Pr(y = 1|xi)
Pr(y = −1|xi)

> |Bj|

Xxi∈Bj

(1)

can ensure both of the MIL properties. Positive-identiﬁability is satisﬁed when Pr(y = 1|xi) ≥
|Bi|
|Bi|+1 or equivalently  when the positive examples all have very large margin.
When the size of the bag is large  the assumption Pr(y = 1|xi) > |Bj|
|Bj|+1 can be too strong.
Therefore  we exploit large deviation bounds to reduce the quantity |Bj|  such that Pr(y = 1|xi)
does not have to be very large to satisfy the constraint. Intuitively  if the examples are not very
ambiguous  i.e. Pr(y = 1|xi) is not close to 1/2  then likelihood ratio sums on negative examples
can become much smaller  hence we can adopt a signiﬁcantly lower threshold at some degree of
violation of the negative-exclusion property. To this end  a common assumption is the low label
noise [18  19]:

Mβ : ∃c > 0  ∀ǫ  Pr(0 < |Pr(y = 1|xi) −

1
2

| ≤ ǫ) ≤ cǫβ.

This assumes that the posterior Pr(y = 1|xi) is usually not very close to 1/2  meaning that most
examples are not very ambiguous  which is usually reasonable. In [18  19  20]  a number of results
have been obtained implying that classiﬁers learned under this assumption converge to the Bayes
error much faster than the conventional empirical process rate O(n−1/2) of most standard classiﬁers 
and can be as fast as O(n−1). These theoretical results show that low label noise assumptions indeed
supports learning with fewer observations.
Assuming Mβ holds  we prove the following result which allows us to relax the hard constraint (1):
Theorem 1 ∀δ > 0  for each xi in a bag Bj  assume yi is drawn i.i.d.
from the distribution
PrBj (yi|xi) that satisﬁes Mβ. If all instances xi ∈ Bj are negative  then the probability that

Pr(y = 1|xi)
Pr(y = −1|xi)

≥

β + 4

2(β + 1)(β + 2)

|Bj|+s

4β + 1

2(β + 1)2(2β + 3)

|Bj| log 1/δ+

log 1/δ

3

(2)

Xxi∈Bj

is at most δ.

The proof is given in an accompanying technical report [21]. From Theorem 1  we could weaken
the constraint (1) to obtain constraint (2) and still ensure negative-exclusion with probability 1 − δ.
When β is large  the reduction is signiﬁcant. For example  for β = 2 and δ = 0.05  the right-
hand side of (2) is approximately 1
14 |Bi| + 1  which is an important decrease over |Bi| 
whenever |Bi| ≥ 3. Note that the i.i.d. assumption in Theorem 1 applies to each bag. Different bags
can have different label distributions. This is often a signiﬁcantly weaker assumption than the ones
based on global i.i.d. of labels [8].

4 |Bi| +q 3

3 Likelihood Ratio Estimation

To estimate the likelihood ratio  one possibility would be to use kernel methods as nonparametric
estimators over a RKHS. This approach was taken in [22]  where predictions of the ratio provided
a variational estimate of an f -divergence (or Ali-Silvey divergence) between two distributions. The
formulation is powerful  yet not immediately applicable here. In our case  because of the uncertainty
in the positive examples  Pr(y = 1|x) is not observed but has to be estimated. Therefore we need
to optimize jointly as minf Pr(y=1|x) D(f  Pr(y = 1|x)) + λ||f ||2 with loss function D(f  g). This
optimization would not be convex if a framework in [22] were taken.

3

The requirement to estimate two sets of variables simultaneously (e.g. f and Pr(y = 1|x) here)  is
one of the major difﬁculties in turning multiple-instance learning into a convex problem. Approaches
based on classiﬁcation-style loss functions lead to non-convex optimization [2  13]. However  since
we are outside a classiﬁcation setting  we can optimize over divergence measures Dφ(f  g) that are
convex w.r.t. both f and g. These measures are common. For example  the f -divergence family that
includes many statistical distances  satisﬁes the following properties [23]:

L1 : D(x  y) =Pi |xi − yi|; χ2 : D(x  y) =Pi
Kullback-Leibler : D(x  y) =Pi xi log xi − xi log yi − xi + yi;

Symmetric Kullback-Leibler : D(x  y) =Pi(yi − xi) log yi + (xi − yi) log xi − xi + yi

In principle  any of the measures given above can be used to estimate the likelihood ratio.

xi

;

(xi−yi)2

(3)

An important issue is the relationship between the likelihood ratio estimation and our ﬁnal goal:
binary classiﬁcation. In [20]  the authors give necessary and sufﬁcient conditions for Bayes con-
sistent learners by minimizing the mean of a surrogate loss function of the data. In this paper we
extend these results to loss functions for likelihood ratio estimation. Let R(f ) = P (sign(y) 6=
sign(f (x) − 1)) be the 0-1 risk of a likelihood estimator f   with classiﬁcation rule given by
sign(f (x) ≥ 1). The Bayes risk is then R∗ = inf f R(f ).
For a generic loss function C(α  η)  let η = Pr(y = 1|x)  we can deﬁne the C-risk as RC (f ) =
E(C(f  η)) and R∗
C = inf f RC (f ). Our goal is to bound the excess 0-1 risk R(f ) − R∗ by the
excess-C risk RC (f ) − R∗
C  so that minimizing the excess-C risk can be converted into minimizing
the classiﬁcation loss. Let us further deﬁne the optimal conditional risk as H(η) = inf α∈R C(α  η) 
and H −(η) = inf α (α−1)(2η−1)≤0 C(α  η). We say C(α  η) is classiﬁcation-calibrated if for any
η 6= 1/2  H −(η) > H(η). Then  we deﬁne the ψ-transform of C(α  η) as ψ(θ) = ˜ψ∗∗(θ)  where
˜ψ(θ) = H −( 1+θ
2 )  θ ∈ [−1  1]  and g∗∗ is the Fenchel-Legendre biconjugate of g  which
is essentially the largest convex lower bound of g [20].
The difference between likelihood ratio estimation and the classiﬁcation setting is in the asymmetric
scaling of the loss function for positive and negative examples. Let ψ− = ψ(−x)  R−(f ) =
Pr(y = −1  f (x) > 1)  R∗
+ = inf f R+(f )
be the risk and Bayes risks on negative and positive examples  respectively. It is easy to prove that
R(f ) − R∗ = R−(f ) − R∗
Theorem 2 a) For any nonnegative loss function C(α  η)  any measurable f : X → R  and any
probability distribution on X ×{±1}  ψ−(R−(f )−R∗
C. b) The
following conditions are equivalent: (1) C is classiﬁcation-calibrated; (2) For any sequence (θi) in
[0  1]  ψ(θi) → 0 if and only if θi → 0; (3) For every sequence of measurable functions fi : X → R
and every probability distribution on X × {±1}  RC (fi) → R∗

− = inf f R−(f )  R+(f ) = Pr(y = 1  f (x) < 1) and R∗

+. We derived the following theorem:

−)+ψ(R+(f )−R∗

+) ≤ RC (f )−R∗

− + R+(f ) − R∗

2 ) − H( 1+θ

C implies R(fi) → R∗.

1−η   η) = 0 and H −(η) = D(1  η

The proof is given in an accompanying technical report [21]. This suggests that if ψ is well-behaved 
minimizing RC (f ) still gives a reasonable surrogate for the classiﬁcation risk. Compared against
Theorem 3 in [20] which has the form ψ(R(f ) − R∗) ≤ RC (f ) − R∗
C  the difference here stems
from the different loss transforms used for the positive and the negative examples.
We consider an f -divergence of the likelihood as the loss function  i.e.  C(α  η) = D(α  η
1−η ) 
where η
1−η is the likelihood ratio when the Pr(y = 1|x) = η. From convexity arguments  it can be
easily seen that H(η) = C( η
1−θ ).
The ψ for all the loss functions listed in (4) can be computed accordingly. In ﬁg. 3 (a) we show the
ψ(θ) of L1 and the KL-divergence from (4) and compare it against the hinge loss (where ˜ψ(θ) = |θ|
[20]) used for SVM classiﬁcation. It could be seen that our approximation of the classiﬁcation loss is
accurate when Pr(yi = 1|xi) is small. However  likelihood estimation would severely penalize the
misclassiﬁed positive examples with large Pr(yi = 1|xi). This suggests that for the joint estimation
of f and Pr(yi = 1|xi)  the optimizer would tend to make Pr(yi = 1|xi) smaller  in order to avoid
high penalties  as shown in ﬁg. 1(b).
In ﬁg. 1(a) we plot ψ functions for different losses. We prefer an L1 measure as it is closer to the
classiﬁcation hinge loss  at least for the negative examples. In the end we solve the nonparametric
function estimation in RKHS using an epsilon-insensitive L1 loss  which can be reformulated as

1−η )  therefore ˜ψ(θ) = D(1  1+θ

4

100

)
θ
(
ψ

10−5

 

L1 divergence
KL−divergence
Hinge Loss

1.2

1

0.8

0.6

0.4

0.2

0

 
Positive
Negative

 
−1

−0.5

0
θ
(a)

0.5

1

 
−0.2
0

50

100

150

200

(b)

d
o
o
h

i
l

e
k
L

i

 

d
e

t

a
m

i
t
s
E

1.2

1

0.8

0.6

0.4

0.2

0

 
−0.2
0

 

Positive
Negative
Undecided

50

100

Example

150

(c)

Figure 1: Loss functions and their inﬂuence on the estimation bias. (a) The function ψ appearing
in the losses used for likelihood estimation (L1  KL-divergence) is similar to the hinge loss when
θ > 0; however it goes to inﬁnity as θ approaches 1. This deviation essentially means the surrogate
loss is going to be extremely large if an example with very large Pr(yi = 1|xi) is misclassiﬁed. (b)
Example estimated likelihood for a synthetic example. The estimated likelihood is biased towards
smaller values. However  with a fully labeled training set  the threshold can still be obtained. (c)
If we only know the label of the negative examples (blue) and the maximal positive example (red) 
determining the optimal threshold becomes non-trivial.

support vector regression on the conditional likelihood  with the additional MIL constraints in (2):

max(|f (x+

j ) − η+

max(|f (x−

j )| − ǫ  0) + λ||f ||2

min

f η+ Px+

s.t.

j

j

j | − ǫ  0) +Px−
Px+

j ∈Bi

η+
j ≥ Di  η+

j ≥ 0

(4)

4 |Bi| +q 3

where ||f ||2 is the RKHS norm; Di is a constant for each bag and can be determined from Theorem
1  with appropriately chosen values for constants β and δ; η+
for the
i
training set. In this paper we use β = 2 and δ = 0.05  which gives the estimate of the bound for
each bag as Di = 1

14 |Bi| + 1  when Bi ≥ 3 and Di = |Bi| when |Bi| < 3.

is an estimate of P r(y=1|x+
i )
P r(y=−1|x+
i )

between solving for the SVM and projecting on the constraint sets given byPx+

It can be proved that optimization problem (4) is jointly convex in both arguments. A standard repre-
senter theorem [24] would convert it to an optimization on vectors  which we omit here. The problem
can be solved by different methods. The one easiest to implement is the alternating minimization
y+
j ≥ Di and
y+
j ≥ 0. As this can turn out to be slow for large datasets  approaches such as the dual SMO or
primal subgradient projection algorithms (in the case of linear SVM) can be used. In this paper we
implement the alternating minimization approach  which is provably convergent since the optimiza-
tion problem (4) is convex. In the accompanying technical report [21] we derive an SMO algorithm
based on the dual of (4) and characterize the basic properties of the optimization problem.

j ∈Bi

4 Bag and Instance Classiﬁcation

If the likelihood ratio is obtained using an unbiased estimator  a decision rule based on sign(f (x) ≥
1) should give the optimal classiﬁer. However as previously argued  the joint estimation on f and
η+ introduces a bias which is not always easy to identify. In positive bags  it is unclear whether an
instance should be labeled positive or negative  as long as it does not contribute signiﬁcantly to the
classiﬁcation error of its bag (ﬁg. 3(b) (c)). In the synthetic experiments  we noticed that knowledge
of the correct threshold would make the algorithm outperform competitors by a large margin (ﬁg.
2). This means that based on the learned likelihood ratio  the positive examples are usually well
separated from the negative ones. Developing a theory that would advance these aspects remains
a promising avenue for future work. The main difﬁculty stems from the compound source of bias
which arises from both the estimation of η+ and the loss minimization over η+ and f .
Here we propose a partial solution. Instead of directly estimating the threshold  we learn a linear
combination of instance likelihood ratios to classify the bag. First  we sort the instance likelihood
ratios for each bag into a vector of length maxi |Bi|. We append 0 to bags that do not have enough

5

(a)

Bag Classification Error

 

AL−SVM : T=10C
mi−SVM
AW−SVM
BEST−THRESHOLD
SVR−SVM

(b)

Pattern Classification Error

AL−SVM : T=10C
mi−SVM
AW−SVM
BEST−THRESHOLD
SVR−SVM

0.35

0.3

0.25

0.2

0.15

0.1

s
n
u
r
 

0
5

 

 
r
e
v
o
d
e
g
a
r
e
v
a
−
 
r
o
r
r

 

0.2

0.4

percent of positive labeled points in bags

0.6

0.8

E

0.05

1

0

 

0.2

0.4

0.8
percent of positives in bags

0.6

s
n
u
r
 

0
5

 
r
e
v
o

 

d
e
g
a
r
e
v
a
−
 
r
o
r
r

 

E

0.45

0.4

0.35

0.3

0.25

0.2

0.15

0.1

0.05

0

 

(c)

Witness Rate
Estimate by SVR−SVM

0.4

0.8
Percent of positives in bags

0.6

 

1

1

0.8

0.6

0.4

0.2

 

0.2

t

e
a
r
 
s
s
e
n

t
i

 

w
d
e

t

a
m

i
t
s
E

 

1

(d)

(e)

(f)

Figure 2: Synthetic dataset (best viewed in color). (a) The true decision boundary. (b) Training
points at 40% witness rate. (c) The learned regression function. (d) Bag misclassiﬁcation rate of
different algorithms. (e) Instance misclassiﬁcation rate of different algorithms. (f) Estimated witness
rate and true witness rate.

instances. Under this representation  bag classiﬁcation turns into a standard binary decision problem
where a vector and a binary label is given for each bag  and a linear SVM is learned to solve the
problem. If we were to classify only the likelihood ratio on the ﬁrst instance  this procedure would
reduce to simple thresholding. We instead leverage information in the entire bag  aiming to constrain
the classiﬁer to learn the correct threshold. In this linear SVM setting  regularization never helps in
practice and we always ﬁx C to very large values. Effectively no parameter tuning is needed.1
To classify instances  a threshold is still necessary. In the current system  we follow a simple ap-
proach and take the mean between two instances: the one with the highest likelihood among training
bags that are predicted negative by the bag classiﬁer  and the lowest scored one among instances in
positive bags with a score higher than the previous one. This approach is derived from the basic
MIL assumption that all instances in a negative bag are negative.

Based on instance classiﬁcation we could also estimate the witness rate of the dataset. This is
computed as the ratio of positively classiﬁed instances and the total number of instances in the
positive bags of the training set. Since our algorithm automatically adjusts to different witness rates 
this estimate offers quantitative insight as to whether MIL should be used. For instance  if the
witness rate is 100%  it may be more effective to use a conventional learning approach.

5 Experiments

5.1 Synthetic Data

We start with an experiment on the synthetic dataset of [15]  where the controlled setting helps
understanding the behavior of the proposed algorithm. This is a 2-D dataset with the actual decision
boundary shown in ﬁg. 2 (a). The positive bags have a fraction of points sampled uniformly from
the white region and the rest sampled uniformly from the black region. An example of the sample
at 40% witness rate is shown in ﬁg. 2 (b). In this ﬁgure  the plotted instance labels are the ones
of their bags – indeed  one could notice many positive (blue) instances in the negative (red) region.

1We have also experimented with a uniform threshold based on probabilistic estimates  as well as with
predicting an instance-level threshold. While the former tends to underﬁt  the latter overﬁtts. Our bag-level
classiﬁer targets an intermediate level of granularity and turns out to be the most robust in our experiments.

6

Table 1: Performance of various MIL algorithms on weak labeling benchmarks. The best result on
each dataset is shown in bold. The second group of algorithms either not provide instance labels
(MI-Kernel and miGraph) or require a parameter that can be difﬁcult to tune (ALP-SVM). SVR-
SVM appears to give consistent results among algorithms that provide instance labels. The row
denoted “Est. WR” gives the estimated witness rates of our method.

Algorithm
CH-FD
EMDD
mi-SVM
MI-SVM
MICA
AW-SVM
Ins-KI-SVM
MI-Kernel
miGraph
ALP-SVM
SVR-SVM
Est. WR

Musk-1

Musk-2

Elephant

88.8
84.9
87.4
77.9
84.4
85.7
84.0

85.7
84.8
83.6
84.3
90.5
83.8
84.4

82.4
78.3
82.2
81.4
82.5
82.0
83.5

Tiger
82.2
72.1
78.4
84.0
82.0
83.0
82.9

88.0 ± 3.1
88.9 ± 3.3

86.3

87.9 ± 1.7

100 %

89.3 ± 1.5
90.3 ± 2.6

86.2

85.4 ± 1.8

89.5 %

84.3 ± 1.6
86.8 ± 0.7

83.5

85.3 ± 2.8

37.8 %

84.2 ± 1.9
86.0 ± 2.8

86.0

79.8 ± 3.4

42.7 %

Fox
60.4
56.1
58.2
57.8
62.0
63.5
63.4
60.3 ± 1.0
61.6 ± 1.6
66.0
63.0 ± 3.5
100 %

In order to test the effect of witness rates  10 different types of datasets are created by varying the
rates over the range 0.1  0.2  . . .   1. In this experiment we ﬁx the hyperparameters C = 5 and use a
Gaussian kernel with σ = 1.We show a trained likelihood ratio function in ﬁg. 2 (c)  estimated on
the dataset shown in ﬁg. 2 (b). Under the likelihood ratio  the positive examples are well separated
from negatives. This illustrates how our proposed approach converts multiple-instance learning into
the problem of deciding a one-dimensional threshold.

Complete results on datasets with different witness rates are shown in ﬁg. 2 (d) and (e). We give
both bag classiﬁcation and instance classiﬁcation results. Our approach is referred to as SVR-
SVM. BEST THRESHOLD refers to a method where the best threshold was chosen based on the
full knowledge of training/test instance labels  i.e.  the optimal performance our likelihood ratio
estimator can achieve. Comparison is done with two other approaches  the mi-SVM in [2] and
the AW-SVM from [15]. SVR-SVM generally works well when the witness rate is not very low.
From instance classiﬁcation  one can see that the original mi-SVM is only competitive when the
witness rate is near 1 – this situation is close to a supervised SVM. With a deterministic annealing
approach in [15]  AW-SVM and mi-SVM perform quite the opposite – competitive when the witness
rate is small but degrade when this is large. Presumably this is because deterministic annealing is
initialized with the apriori assumption that datasets are multiple-instance i.e. has a small witness rate
[15]. When the witness rate is large  annealing does not improve performance. On the contrary  the
proposed SVR-SVM does not appear to be affected by the witness rate. With the same parameters
used across all the experiments  the method self-adjusts to different witness rates. One could see the
effect especially in ﬁg. 2 (e): regardless of the witness rate  the instance error rate remains roughly
the same. However  this is still inferior to our model based on the best threshold  which indicates
that important room for improvement exists.

5.2 MIL Datasets

The algorithm is evaluated on a number of popular MIL benchmarks. We use the common ex-
perimental setting  based on 10-fold cross-validation for parameter selection and we report the test
results averaged over 10 trials. The results are shown in Table 1  together with other competitive
methods in from the literature [12  15  10] (for some of these methods standard deviation estimates
are not available).

In our tests  the proposed SVR-SVM gives consistently good results among algorithms that provide
instance-level labels. The only atypical case is Tiger  where the algorithm underperforms other
methods. Overall  the performance of SVR-SVM is slightly worse than miGraph and ALP-SVM.
But we note that results in ALP-SVM are obtained by tuning the witness rate to the optimal value 
which may be difﬁcult in practical settings. The slightly lower performance compared to miGraph
suggests that we may be inferior in the bag classiﬁcation step  which we already know is suboptimal.

7

Table 2: Results from 20 Newsgroups. The best result on each dataset is shown in bold  pairwise
t-tests are performed to determine if the differences are statistically signiﬁcantly. miGraph is domi-
nating in 10 datasets  whereas SVR-SVM is dominating in 14.

Dataset
alt.atheism
comp.graphics
comp.windows.misc
comp.ibm.pc.hardware
comp.sys.mac.hardware
comp.window.x
misc.forsale
rec.autos
rec.motorcycles
rec.sport.baseball
rec.sport.hockey
sci.crypt
sci.electronics
sci.med
sci.space
soc.religion.christian
talk.politics.guns
talk.politics.mideast
talk.politics.misc
talk.religion.misc

5.3 Text Categorization

MI-Kernel miGraph [10] miGraph (web)
60.2 ± 3.9
47.0 ± 3.3
51.0 ± 5.2
46.9 ± 3.6
44.5 ± 3.2
50.8 ± 4.3
51.8 ± 2.5
52.9 ± 3.3
50.6 ± 3.5
51.7 ± 2.8
51.3 ± 3.4
56.3 ± 3.6
50.6 ± 2.0
50.6 ± 1.9
54.7 ± 2.5
49.2 ± 3.4
47.7 ± 3.8
55.9 ± 2.8
51.5 ± 3.7
55.4 ± 4.3

82.0 ± 0.8
84.3 ± 0.4
70.1 ± 0.3
79.4 ± 0.8
81.0 ± 0
79.4 ± 0.5
71.0 ± 0
83.2 ± 0.6
70.9 ± 2.7
75.0 ± 0.6
92.0 ± 0
70.1 ± 0.8
94.0 ± 0
72.1 ± 1.3
79.4 ± 0.8
75.4 ± 1.2
72.3 ± 1.0
75.5 ± 1.0
72.9 ± 2.4
67.5 ± 1.0

65.5 ± 4.0
77.8 ± 1.6
63.1 ± 1.5
59.5 ± 2.7
61.7 ± 4.8
69.8 ± 2.1
55.2 ± 2.7
72.0 ± 3.7
64.0 ± 2.8
64.7 ± 3.1
85.0 ± 2.5
69.6 ± 2.1
87.1 ± 1.7
62.1 ± 3.9
75.7 ± 3.4
59.0 ± 4.7
58.5 ± 6.0
73.6 ± 2.6
70.4 ± 3.6
63.3 ± 3.5

SVR-SVM Est. WR
83.5 ± 1.7
1.83 %
85.2 ± 1.5
5.19 %
2.23 %
66.9 ± 2.6
70.3 ± 2.8
2.42 %
4.58 %
78.0 ± 1.7
83.7 ± 2.0
5.36 %
72.3 ± 1.2
4.29 %
2.75 %
78.1 ± 1.9
75.6 ± 0.9
2.86 %
76.7 ± 1.4
4.31 %
6.52 %
89.3 ± 1.6
69.7 ± 2.5
3.22 %
91.5 ± 1.0
4.29 %
74.9 ± 1.9
5.23 %
83.2 ± 2.0
3.64 %
83.2 ± 2.7
3.30 %
73.7 ± 2.6
3.23 %
80.5 ± 3.2
3.88 %
72.6 ± 1.4
2.82 %
71.9 ± 1.9
2.87 %

The text datasets are taken from [10]. These data have the beneﬁt of being designated to have a small
witness rate. Thus they serve as a better MIL benchmark compared to the previous ones. These are
derived from the 20 Newsgroups corpus  with 50 positive and 50 negative bags for each of the 20
news categories. Each positive bag has around 3% witness rate. We run 10-fold cross validation 10
times on each dataset and compute the average accuracy and standard deviations  C is ﬁxed to 100 
ǫ to 0.2. Authors of [10] reported recent results for this dataset on their website  which are vastly
superior than the ones reported in the paper. Therefore  in Table 2 we included both results in the
comparison  identiﬁed as miGraph (paper) and miGraph (website)  respectively.

Our SVR-SVM performs signiﬁcantly better than MI-Kernel and miGraph (paper). It is comparable
with miGraph (web)  and offers a marginal improvement. It is interesting that even though we use a
suboptimal second step  SVR-SVM fares well with the state-of-the-art. This shows the potential of
methods based on likelihood ratio estimators for multiple instance learning.
6 Conclusion

We have proposed an approach to multiple-instance learning based on estimating the likelihood ratio
between the positive and the negative classes on instances. The MIL constraint is reformulated into a
convex constraint on the likelihood ratio where a joint estimation of both the function and the target
ratios on the training set is performed. Theoretically we justify that learning the likelihood ratio is
Bayes-consistent and has desirable excess loss transform properties. Although we are not able to ﬁnd
the optimal classiﬁcation threshold on the estimated ratio function  our proposed bag classiﬁer based
on such ratios obtains state-of-the-art results in a number of difﬁcult datasets. In future work  we
plan to explore transductive learning techniques in order to leverage the information in the learned
ratio function and identify better threshold estimation procedures.

Acknowledgements

This work is supported  in part  by the European Commission  under a Marie Curie Excellence Grant
MCEXT-025481.

8

References

[1] Dietterich  T.G.  Lathrop  R.H.  Lozano-Perez  T.: Solving the multiple-instance problem with

axis-parallel rectangles. Artiﬁcial Intelligence 89 (1997) 31–71

[2] Andrews  S.  Tsochantaridis  I.  Hofmann  T.: Support vector machines for multiple-instance

learning. In: NIPS. (2003) 561–568

[3] Maron  O.  Lozano-P´erez  T.: A framework for multiple-instance learning. In: NIPS. (1998)

570–576

[4] Felzenszwalb  P.F.  McAllester  D.A.  Ramanan  D.: A discriminatively trained  multiscale 

deformable part model. In: CVPR. (2008)

[5] Russell  B.C.  Torralba  A.  Murphy  K.P.  Freeman  W.T.: Labelme: A database and web-

based tool for image annotation. IJCV 77(1-3) (2008) 157–173

[6] Cour  T.  Sapp  B.  Nagle  A.  Taskar  B.: Talking pictures: Temporal grouping and dialog-

supervised person recognition. In: CVPR. (2010)

[7] Zeisl  B.  Leistner  C.  Saffari  A.  Bischof  H.: On-line semi-supervised multiple-instance

boosting. In: CVPR. (2010)

[8] G¨artner  T.  Flach  P.A.  Kowalczyk  A.  Smola  A.J.: Multi-instance kernels.

(2002)

In: ICML.

[9] Tao  Q.  Scott  S.  Vinodchandran  N.V.  Osugi  T.T.: Svm-based generalized multiple-instance

learning via approximate box counting. In: ICML. (2004)

[10] Zhou  Z.H.  Sun  Y.Y.  Li  Y.F.: Multi-instance learning by treating instances as non-i.i.d.

samples. In: ICML. (2009)

[11] Cheung  P.M.  Kwok  J.T.: A regularization framework for multiple-instance learning. In:

ICML. (2006) 193–200

[12] Fung  G.  Dandar  M.  Krishnapuram  B.  Rao  R.B.: Multiple instance learning for computer

aided diagnosis. In: NIPS. (2007)

[13] Mangasarian  O.  Wild  E.: Multiple instance classiﬁcation via successive linear programming.

Journal of Optimization Theory and Applications 137 (2008) 555–568

[14] Zhang  Q.  Goldman  S.A.  Yu  W.  Fritts  J.E.: Content-based image retrieval using multiple-

instance learning. In: ICML. (2002) 682–689

[15] Gehler  P.  Chapelle  O.: Deterministic annealing for multiple-instance learning. In: AISTATS.

(2007)

[16] Doll´ar  P.  Babenko  B.  Belongie  S.  Perona  P.  Tu  Z.: Multiple component learning for

object detection. In: ECCV. (2008)

[17] Li  Y.F.  Kwok  J.T.  Tsang  I.W.  Zhou  Z.H.: A convex method for locating regions of interest

with multi-instance learning. In: ECML. (2009)

[18] Mammen  E.  Tsybakov  A.B.: Smooth discrimination analysis. Annals of Statistics 27 (1999)

1808–1829

[19] Tsybakov  A.B.: Optimal aggregation of classiﬁers in statistical learning. Annals of Statistics

32 (2004) 135–166

[20] Bartlett  P.  Jordan  M.I.  McAulliffe  J.: Convexity  classiﬁcation and risk bounds. Journal of

American Statistical Association 101 (2006) 138–156

[21] Li  F.  Sminchisescu  C.: Convex multiple instance learning by estimating likelihood ratio.

Technical report  Institute for Numerical Simulation  University of Bonn (November 2010)

[22] Nguyen  X.  Wainwright  M.  Jordan  M.I.: Estimating divergence functionals and the likeli-

hood ratio by penalized convex risk minimization. In: NIPS. (2007)

[23] Liese  F.  Vajda  I.: Convex Statistical Distances. Teubner VG (1987)
[24] Hofmann  T.  Sch¨olkopf  B.  Smola  A.J.: Kernel methods in machine learning. The Annals of

Statistics 36 (2008) 1171–1220

9

,Roger Grosse
Siddharth Ancha
Daniel Roy