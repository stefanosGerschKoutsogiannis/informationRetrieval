2013,Latent Structured Active Learning,In this paper we present active learning algorithms in the context of structured prediction problems. To reduce the amount of labeling necessary to learn good models  our algorithms only label subsets of the output. To this end  we query examples using entropies of local marginals  which are a good surrogate for uncertainty. We demonstrate the effectiveness of our approach in the task of 3D layout prediction from single images  and show that good models are learned when labeling only a handful of random variables. In particular  the same performance as using the full training set can be obtained while only labeling ~10\% of the random variables.,Latent Structured Active Learning

Wenjie Luo
TTI Chicago

wenjie.luo@ttic.edu

Alexander G. Schwing

ETH Zurich

aschwing@inf.ethz.ch

Raquel Urtasun

TTI Chicago

rurtasun@ttic.edu

Abstract

In this paper we present active learning algorithms in the context of structured
prediction problems. To reduce the amount of labeling necessary to learn good
models  our algorithms operate with weakly labeled data and we query additional
examples based on entropies of local marginals  which are a good surrogate for
uncertainty. We demonstrate the effectiveness of our approach in the task of 3D
layout prediction from single images  and show that good models are learned when
labeling only a handful of random variables. In particular  the same performance
as using the full training set can be obtained while only labeling ∼10% of the
random variables.

1

Introduction

Most real-world applications are structured  i.e.  they are composed of multiple random variables
which are related. For example  in natural language processing  we might be interested in parsing
sentences syntactically. In computer vision  we might want to predict the depth of each pixel  or its
semantic category. In computational biology  given a sequence of proteins (e.g.  lethal and edema
factors  protective antigen) we might want to predict the 3D docking of the anthrax toxin. While in-
dividual variables could be considered independently  it has been demonstrated that taking relations
into account improves prediction performance signiﬁcantly.
Prediction in structured models is typically performed by maximizing a scoring function over the
space of all possible outcomes  an NP-hard task for most graphical models. Traditional learning al-
gorithms for structured problems tackle the supervised setting [16  33  11]  where input-output pairs
are given and each structured output is fully labeled. Obtaining fully labeled examples might  how-
ever  be very cumbersome as structured models often involve a large number of random variables 
e.g.  in semantic segmentation  we have to label several million random variables  one for each pixel.
Furthermore  obtaining ground truth is sometimes difﬁcult as it potentially requires accessing extra
sensors  e.g.  laser scanners in the case of stereo. This is even more extreme in the medical domain 
where obtaining extra labels is sometimes not even possible  e.g.  when tests are not available. Thus 
reducing the amount of labeled examples required for learning the scoring function is key for the
success of structured prediction in real-world applications.
The active learning setting is particularly beneﬁcial as it has the potential to considerably reduce
the amount of supervision required to learn a good model  by querying only the most informative
examples. In the structured case  active learning can be generalized to query only subparts of the
graph for each example  reducing the amount of necessary labeling even further.
While a variety of active learning approaches exists for the case of classiﬁcation and regression  the
structured case has been less popular  perhaps because of its intrinsic computational difﬁculties as we
have to deal with exponentially sized output spaces. Existing approaches typically consider the case
where exact inference is possible [7]  label the full output space [7  22]  or rely on computationally
expensive processes that require inference for each possible outcome of each random variable [34].
The latter is computationally infeasible for most graphical models.

1

In contrast  in this paper we present efﬁcient approximate approaches for general graphical models
where exact inference is intractable. In particular  we propose to select which parts to label based
on the entropy of the local marginal distributions. Our active learning algorithms exploit recently
developed weakly supervised methods for structured prediction [28]  showing that we can beneﬁt
from unlabeled examples and exploit the marginal distributions computed during learning. Further-
more  computation is re-used at each active learning iteration  improving efﬁciency signiﬁcantly.
We demonstrate the effectiveness of our approach in the context of 3D room layout estimation from
single images  and show that state-of-the-art results are achieved by employing much fewer man-
ual interactions (i.e.  labels). In particular  we match the performance of the state-of-the-art in this
task [27] while only labeling ∼10% of the random variables.
In the remainder of the paper we ﬁrst review learning methods for structured prediction. We then
propose our active learning algorithms  and show our experimental evaluation followed by a discus-
sion on related work and conclusions.

2 Maximum Likelihood Structure Prediction

We begin by reviewing structured prediction approaches that employ both fully labeled training sets
as well as those that handle latent variables. Of particular interest to us are probabilistic formulations
since we employ entropies of local probability distributions as our criteria for deciding which parts
of the graph to label during each active learning step.
Let x ∈ X be the input space (e.g.  an image or a sentence)  and let s ∈ S be the structured labeled
space that we are interested in predicting (e.g.  an image segmentation or a parse tree). We deﬁne
φ : X × S → RF to be a mapping from input and label space to an F -dimensional feature space.
Here we consider log-linear distributions pw(s|x) describing the probability over a structured label
space S given an object x ∈ X as

(1)
During learning  we are interested in estimating the parameters w ∈ RF of the log-linear distribution
such that the score w(cid:62)φ(x  s) is high if s ∈ S is a “good” label for x ∈ X .

pw(s|x) ∝ exp(cid:0)w(cid:62)φ(x  s)(cid:1) .

2.1 Supervised Setting
To deﬁne “good ” in the supervised setting we are given a training set D = {(xi  si)N
i=1} containing
N pairs  each composed of an input x ∈ X and some fully labeled data s ∈ S. In addition  we are
often able to compare the ﬁtness of an estimate ˆs ∈ S for a training sample (x  s) ∈ D via what we
refer to as the task-loss function (cid:96)(x s)(ˆs). Its purpose is very much like enforcing a distance between
the hyperplane deﬁned by the parameters and the respective sample when considering the popular
max-margin setting. We incorporate this loss function into the learning process by considering the
loss-augmented distribution

p(x s)(s|w) ∝ exp(w(cid:62)φ(x  s) + (cid:96)(x y)(s)).

(2)
Intuitively it places more probability mass on those parts of the output space S that have a high loss 
forcing the model to adapt to a more difﬁcult setting than the one encountered at inference  where
the loss is not present.
Maximum likelihood learning aims at ﬁnding model parameters w which assign highest probability
to the training set D. Assuming the data to be independent and identically distributed (i.i.d.)  our
(x s)∈D p(x s)(s|w)] with p(w) ∝ e−(cid:107)w(cid:107)p

goal is to minimize the negative log-posterior − ln[p(w)(cid:81)

p

being a prior on the model parameters. The cost function is therefore given by

(cid:33)

(cid:33)

(cid:32)

(cid:88)

(x y)∈D

(cid:88)

ˆs∈S

 ln

exp

(cid:32)

(cid:107)w(cid:107)p

p +

C
p

w(cid:62)φ(x  ˆs) + (cid:96)(x y)(ˆs)



− w(cid:62)φ(x  s)

 

(3)

where we have included a parameter  to yield a soft-max function. Although being a convex func-
tion  the difﬁculty arises from the sum over exponentially many label conﬁgurations ˆs.
Different algorithms have been proposed to solve this task. While efﬁcient computation over tree-
structured models is required for convergence guarantees [16]  approximations were suggested to
achieve convergence even when working with loopy models [11].

2

(cid:88)

ˆh∈H

(cid:88)

ˆh∈H

2.2 Dealing with Latent Variables
i=1} containing N pairs 
In the weakly supervised setting  we are given a training set D = {(xi  yi)N
each composed of an input x ∈ X and some partially labeled data y ∈ Y ⊆ S. For every training
pair  the label space S = Y ×H is divided into two non-intersecting subspaces Y and H. We refer to
the missing information h ∈ H as hidden or latent. As before  we incorporate a task-loss function 
and deﬁne the loss-augmented likelihood of a prediction ˆy ∈ Y when observing the pair (x  y) as

p(x y)(ˆy  ˆh|w) =

p(x y)(ˆs|w) 

(4)

p(x y)(ˆy|w) ∝ (cid:88)

ˆh∈H

(cid:33)  

(cid:33)

with p(x y)(ˆs|w) deﬁned as in Eq. 2. The minimization of the negative log-posterior results in the
difference of two convex terms as follows

exp

w(cid:62)φ(x  ˆs) + (cid:96)(x y)(ˆs)



− ln

exp

(cid:33)

(cid:32) w(cid:62)φ(x  y  ˆh) + (cid:96)c

(x y)(y  ˆh)



(cid:88)

 ln

(cid:88)

ˆs∈S

(cid:107)w(cid:107)p

p +

C
p

(x y)∈D

(cid:32)

with the ﬁrst two terms being the sum of the log-prior and the logarithm of the partition function.
For generality we allow different task-loss (cid:96)  (cid:96)c while noting that (cid:96)c ≡ 0 in our experiments.
Besides the previously outlined difﬁculty of exponentially sized product spaces  the cost function is
no longer convex. Hence we generally employ expectation maximization (EM) or concave-convex
procedure (CCCP) [37] type of approaches  i.e.  we linearize the non-convex part at the current
iterate before taking a step in the direction of the gradient of a convex function. More speciﬁcally 
we follow Schwing et al. [28] and upper-bound the concave part via a minimization over a set of
dual variables subsequently referred to as q(x y)(h):

(cid:32)

(cid:32)
(cid:88)

(x y)

(cid:88)

ˆs∈S

 ln

exp

(cid:107)w(cid:107)p

p +

C
p

(cid:33)

w(cid:62)φ(x  ˆs)+(cid:96)(x y)(ˆs)



−H(q(x y))−Eq(x y) [w

(cid:62)

φ(x  y  ˆh)+(cid:96)c(x  y  ˆh)]

.

i∈Vk x

φk i(x  si) +(cid:80)

vector decomposes into local terms  i.e.  φk(x  s) = (cid:80)

To deal with the exponential complexity we notice that frequently the k-th element of the feature
φk α(x  sα).
Vk x represents the set indexing the unary potentials for the k-th feature of example (x  y). Similarly
Ek x denotes the set of all high-order variable interaction sets α in the k-th feature of example (x  y).
All variable indexes which are not observed are subsumed within the set H. Similarly all factors α
that contain variable i are summarized within the set N (i).
We leverage the decomposition within the features to also approximate the entropy over the joint dis-
tribution q(x y)(h) by local ones ranging over marginals. Furthermore  we approximate the marginal
polytope by the local polytope. We deal with the summation over the output space objects ˆs ∈ S in
the convex part in a similar manner. To this end we change to the dual space  employ the entropy
approximations and transform the resulting surrogate function back to the primal space where we
obtain Lagrange multipliers λ which enforce the marginalization constraints. Altogether we obtain
an approximate primal program having the following form:

α∈Ek x

f1(w  d  λ) + f2(d) + f3(d)

(5)

min
d λ w

s.t. (cid:88)

hα\hi
d(x y) i  d(x y) α ∈ ∆

d(x y) α(hα) = d(x y) i(hi) ∀(x  y)  i ∈ H  α ∈ N (i)  hi ∈ Si

with ∆ denoting probability simplexes. We refer the reader to [28] for the speciﬁc forms of these
functions.
Following EM or CCCP  this program is optimized by alternatively minimizing w.r.t. the local beliefs
d to solve the latent variable prediction problem  and performing a gradient step w.r.t. the weights as
well as block-coordinate descent steps to update the Lagrange multipliers λ. The latter is equivalent
to solving a supervised conditional random ﬁeld problem given the distribution over latent variables
inferred in the preceding latent variable prediction step.
We augment [28]  and return not only the weights but also the local beliefs d which represent the
joint distribution q(x y)(h)  i.e.  a distribution over the latent space only. We summarize this process
in Alg. 1. Note that only a local minimum is obtained as we are solving a non-convex problem.

3

Algorithm 1 latent structured prediction

Input: data D  initial weights w
repeat

repeat

//solve latent variable prediction problem
mind f2 + f3 s.t. ∀(x  y) d(x y) ∈ D(x y)

until convergence
//message passing update
∀(x  y)  i ∈ S
//gradient step with step size η
w ← w − η∇w(f1 + f2)
until convergence
Output: weights w  beliefs d

λ(x y) i ← ∇λ(x y) i(f1 + f2) = 0

3 Active Learning

i=1}.

In the previous section  we deﬁned the maximum likelihood estimators for learning in the supervised
and weakly supervised setting. We now derive our active learning approaches. In the active learning
setting  we assume a given training set DS = {(xi  yi)NL
i=1} containing NL pairs  each composed
by an input x ∈ X and some partially labeled data y ∈ Y ⊆ S. As before  for every training pair 
we divide the label space S = Y × H into two non-intersecting subspaces Y and H  and refer to
the missing information h ∈ H as hidden or latent. Additionally  we are given a set of unlabeled
examples DU = {(xi)Nu
We are interested in answering the following question: which part of the graph for which example
should we labeled in order to learn the best model with the least amount of supervision? Towards
this goal  we derive iterative algorithms which select the random variables to be labeled based on
the local entropies. This is intuitive  as entropy is a surrogate for uncertainty and useful for the
considered application since the cost of labeling a random variable is independent of the selection.
Here  our algorithms iteratively query the labels of the random variables of highest uncertainty 
update the model parameters w and again ask for the next most uncertain set of variables.
Towards this goal  we need to compute the entropies of the marginal distributions over each latent
variable  as well as the entropy over each random variable of the unlabeled examples. This is in
general NP-hard  as we are interested in dealing with graphical models with general potentials and
connectivity. In this paper we derive two active learning algorithms  each with a different trade-off
between accuracy and computational complexity.

Separate active: Our ﬁrst algorithm utilizes the labeled and weakly labeled examples to learn
at each iteration. Once the parameters are learned it performs inference over the unlabeled and
partially labeled examples to query for the next random variable to label. Thus  it requires a separate
inference step for each active learning iteration. As shown in our experiments  this can be done
efﬁciently using convex belief propagation [10  26]. The corresponding algorithm is summarized in
Alg. 2.

Joint active: Our second active learning algorithm takes advantage of unlabeled examples during
learning and no extra effort is required to compute the most informative random variable. Note
that this contrasts active learning algorithms which typically do not exploit unlabeled data during
learning and require very expensive computations in order to select the next example or random
variable to be labeled. Let D1 = DS ∪ DU be the set of all training examples containing both
fully labeled  partially labeled and unlabeled examples. At each iteration we obtain Dt by querying
the label of a random variable not being labeled in Dt−1. Thus  at each iteration  we learn using a
weakly supervised structured prediction task that solves

(cid:88)

 ln

(cid:88)

ˆs∈S

(cid:107)wt(cid:107)p

p +

C
p

(x y)∈Dt

(cid:32)

exp

(cid:33)

(cid:88)

ˆh∈Ht

− ln

exp

(cid:32) w(cid:62)

t φ(x  y  ˆh)+(cid:96)c

(x y)(y  ˆh)



(cid:33)  

w(cid:62)
t φ(x  ˆs)+(cid:96)(x y)(ˆs)



4

Algorithm 2 Separate active

Input: data DS  DU   initial weights w
repeat

(w  dS) ← Alg. 1(DS  w)
dU ← Inference(DU )
i∗ ← arg maxi H(di)
DS ← DS ∪{(xi∗   yi∗ )}  DU ← DU \ xi∗
until sufﬁciently certain
Output: weights w

Algorithm 3 Joint active

Input: data DS  DU   initial weights w
repeat

(w  d) ← Alg. 1(DS ∪ DU   w)
i∗ ← arg maxi H(di)
DS ← DS ∪{(xi∗   yi∗ )}  DU ← DU \ xi∗
until sufﬁciently certain
Output: weights w

then given by H(di) = −(cid:80)|Hi|

with wt the weights for the t-th iteration. We resort to the approximated problem given in Eq. 5 to
solve this optimization task. The entropies are readily computable in close form  as the local beliefs
d are computed during learning. Thus  no extra inference step is necessary. The local entropies are
hi=1 di(hi) log di(hi)  and we query the variable that has the highest
entropy  i.e.  the highest uncertainty. Note that this computation is linear in the number of unlabeled
random variables and linear in the number of states. We summarize our approach in Alg. 3. Note
that this algorithm is more expensive than the previous one as learning employs the fully  weakly
and unlabeled examples. This is particularly the case when the pool of unlabeled examples is large.
However  as shown in our experimental evaluation  it can dramatically reduce the amount of labeling
required to learn a good model.

Batch mode: The two previously deﬁned active learning approaches are computationally expen-
sive as for each sequential active learning step  a new model has to be learned and inference has to
be performed over all latent variables. We also investigate batch algorithms which label k random
variables at each step of the algorithm. Towards this goal  we simply label the top k most uncer-
tain variables. Note that this is an approximation of what the sequential algorithm will do  as the
estimates of the parameters and the entropies are not updated when selecting the i-th variable.

Re-using computation: Warm starting the learning algorithm after each active learning query is
important in order to reduce the number of iterations required for convergence. Since (almost) the
same samples are involved at each step  we can extract a lot of information from previous iterations.
To this end we re-use both the weights w as well as the messages λ and beliefs. More speciﬁcally 
for Alg. 2 we ﬁrst perform inference on only newly selected examples to update the corresponding
messages λ. Only afterwards and together with Lagrange multipliers from the other training images
and the current weights  we perform the next iteration and another active step. On the other hand 
since we take advantage of all the unlabeled data during the joint active learning algorithm (Alg. 3) 
we already know the Lagrange multipliers λ for every image. Without any further updates we
directly start a new active step. In our experimental evaluation we show that this choice results in
dramatic speed ups when compared to randomly initializing the weights and messages during every
active learning iteration. Note that the joint approach (Alg. 3) requires a larger number of iterations
to converge as it employs large amounts of unlabeled data. After a few iterations  convergence
for the following active learning steps improves signiﬁcantly requiring about as much time as the
separate approach (Alg. 2) does.

4 Experimental Evaluation

We demonstrate the performance of our algorithms on the task of predicting the 3D layout of rooms
from a single image. Existing approaches formulate the task as a structured prediction problem fo-
cusing on estimating the 3D box which best describes the layout. Taking advantage of the Manhat-
tan world assumption (i.e.  the existence of three dominant vanishing points which are orthonormal) 
and given the vanishing points  the problem can be formulated as inference in a pairwise graphical
model composed of four random variables [27]. As shown in Fig. 1  these variables represent the
angles encoding the rays that originate from the respective vanishing points. Following existing
approaches [12  17]  we employ F = 55 features based on geometric context (GC) [13] and ori-
entation maps (OM) [18] as image cues. Our features φ count for each face in the cuboid (given
a particular conﬁguration of the layout) the number of pixels with a certain label for OM and the
probability that such label exists for GC and the task-loss (cid:96) denotes the pixel-wise prediction error.

5

s1

s2

s1

s2

s3

s4

s3

s4

Figure 1: Parameterization and factor graph for the 3D layout prediction task.

(a) k = 1

(b) k = 4

Figure 2: Test set error as a function of the number of random variables labeled  when using joint vs
separate active learning. The different plots reﬂect scenarios where the top k random variables are
labeled at each iteration (i.e.  batch setting). From left to right k = 1  4  8 and 12.

(c) k = 8

(d) k = 12

Performance is measured as the percentage of pixels that have been correctly labeled as  left-wall 
right-wall  front-wall  ceiling or ﬂoor. Unless otherwise stated all experiments are performed by
averaging over 20 runs of the algorithm  where the initial seed of 10 fully labeled images is selected
at random.

Active learning: We begin our experimentation by comparing the two proposed active learning
algorithms  i.e.  separate (Alg. 2) and joint (Alg. 3). As shown in Fig. 2(a)  both active learning
algorithms achieve much lower test error than an algorithm that selects which variables to label
at random. Also  note that the joint algorithm takes advantage of unlabeled data and achieves good
performance after labeling only a few variables  improving signiﬁcantly over the separate algorithm.

Batch active learning: Fig. 2 shows the performances of both active learning algorithms when
labeling a batch of k random variables before re-learning. Note that even with a batch of k = 12
random variables  our algorithms quickly outperform random selection  as illustrated in Fig. 2(d).

Image vs random variable:
Instead of labeling a random variable at a time  we also experiment
with an algorithm that labels the four variables of an image at once. Note that this setting is equiv-
alent to labeling four random variables per image. As shown in Fig. 3(a)  labeling the full image
requires more labeling to achieve the same test error performance when compared to labeling ran-
dom variables from possibly different examples.

Importance of :
Fig. 3(b) and (c) show the performance of our active learning algorithms as a
function of . Note that this parameter is fairly important. In particular  when  = 1  the entropy
of most random variables is too large to be discriminative. This is illustrated in Fig. 3(d) where we
observe a fairly uniform distribution over the states of a randomly chosen variable for  = 1. Our
active learning algorithm thus prefers smaller values of . We hypothesize that this is due to the fact
that we have a small number of random variables each having a large number of states. Our initial
tests show that in other applications where the number of states is smaller (e.g.  segmentation) larger
values of  perform better. An automatic selection of  is subject of our future research.

Complexity Separate vs. Joint:
In Fig. 4(a) we illustrate the number of CCCP iterations as a
function of the number of queried examples for both active learning algorithms. We observe that
the joint algorithm requires more computation initially. But after the ﬁrst few active steps  i.e.  after
having converged to a good solution  its computation requirements reduce drastically. Here we use
 = 0.01 for both algorithms.

6

0204060800.160.180.20.220.24number of queriespixelwise test error  randomseparatejointbest0204060800.160.180.20.220.24number of queriespixelwise test error  randomseparatejointbest0204060800.160.180.20.220.24number of queriespixelwise test error  randomseparatejointbest0204060800.160.180.20.220.24number of queriespixelwise test error  randomseparatejointbest(a) Image vs variable

(b)  separate

(c)  joint

(d) Marginal distribution

Figure 3: Test set error as a function of the number of random variables labeled ((a)-(c)). Marginal
distribution is illustrated in (d) for different .

(a)

(b)

(c)

Figure 4: Number of CCCP iterations as a function of the amount of queried variables in (a) and
time after speciﬁed number of active iterations in (b) (joint) and (c) (separate).

Reusing computation: Fig. 4(b) and (c) show the number of ﬁnished active learning iterations as a
function of time for the joint and separate algorithm respectively. Note that by reusing computation 
a much larger number of active learning iterations ﬁnishes when given a speciﬁc time budget.

5 Related Work

Active learning approaches consider two different scenarios. In stream-based methods [5]  samples
are considered successively and a decision is made to discard or eventually pick the currently inves-
tigated sample. In contrast  pool-based methods [20] have access to a large set of unlabeled data.
Clearly our proposed approach has a pool-based ﬂavor. Over the years many different strategies
have been proposed in the context of active learning algorithms to decide which example to label
next. While we follow the uncertainty sampling scheme [20  19] using an entropy measure  sam-
pling schemes based on expected model change [29] have also been proposed. Other alternatives are
expected error reduction [24]  variance reduction [4  6]  least-conﬁdent measure [7] or margin-based
measures [25].
An alternative way to classify active learning algorithms is related to the information revealed after
querying for a label. In the multi-armed bandit model [1  2] the algorithm chooses an action/sample
and observes the utility of only that action. Alternatively when learning with expert advice  utilities
for all possible actions are revealed [3]. Between both of the aforementioned extremes sits the co-
active learning setting [30] where a subset of rewards for all possible actions is revealed by the user.
Our approach resembles the multi-armed bandit setting since we only get to know the result of the
newly queried sample.
Active learning approaches have been proposed in the context of Neural Networks [6]  Support Vec-
tor Machines [32]  Gaussian processes [14]  CRFs [7] and structured max-margin formulations [22].
Contrasting many of the previously proposed approaches we consider active learning as an exten-
sion of a latent structured prediction setting  i.e.  we extend the double-loop algorithm by yet another
layer. Importantly  our active learning algorithm follows the recent ideas to unify CRFs and struc-
tured SVMs. It employs convex approximations and is amenable to general graphical models with
arbitrary topology and energy functions.

7

0204060800.160.180.20.220.24number of queriespixelwise test error  random: 1 imgseparate: 1 imgjoint: 1 imgrandom: 1 varseparate: 1 varjoint: 1 var0204060800.160.180.20.220.24number of queriespixelwise test error  ε=1ε=0.1ε=0.010204060800.160.180.20.220.24number of queriespixelwise test error  ε=1ε=0.1ε=0.01020406000.050.10.150.2probabilitystate  ε=1ε=0.1ε=0.01020406080020406080100number of queries# CCCP iteration  joint ε=0.01separate ε=0.01020406080012345678x 104# active finishedtime[s]  reusenot reuse0204060800100020003000400050006000# active finishedtime[s]  reusenot reuseThe ﬁrst application of active learning in computer vision was developed by Kapoor et al. [14] to
perform object recognition with minimal supervision. In the context of structured models [8] pro-
posed to use conditional entropies to decide which image to label next in a segmentation task. In [36]
the set of frames to label in a video sequence is selected based on the cost of labeling each frame and
the cost of correcting errors. Unlike our approach  [8  36] labeled full images (not sets of random
variables). As shown in our experiments this requires more manual interactions than our approach.
GrabCut [23] popularized the use of “active learning” for ﬁgure ground segmentation  where the
question of what to labeled next is answered by a human via an interactive segmentation system.
Siddiquie et al. [31] propose to label that variable which most reduces the entropy of the entire “sys-
tem ” i.e.  all the data  by taking into account correlations between variables using a Bethe entropy
approximation. In [15]  the next region to be labeled is selected based on a surrogate of uncertainty
(i.e.  min marginals) which is computed efﬁciently via dynamic graph cuts. This  however  is only
suitable for problems that can be solved via graph cuts (e.g.  binary labeling problems with sub mod-
ular energies). In contrast  in this paper we are interested in the general setting of arbitrary energies
and connectivities. Entropy was used as an active learning criteria for tree-structured models [21] 
where marginal probabilities can be computed exactly.
In the context of video segmentation  Fathi et al. [9] frame active learning as a semi-supervised
learning problem over a graph. They utilized the entropy as a metric for selecting which super-
pixel to label within their graph regularization approach.
In the context of holistic approaches 
Vijayanarasimhan et al. [35] investigated the problem of which task to label. Towards this goal they
derived a multi-label multiple-instance approach  which takes into account the task effort (i.e.  the
expected time to perform each labeling). Vezhnevets et al. [34] resort to the expected change as the
criteria to select which parts to label in the graphical model. Unfortunately  computing this mea-
sure is computationally expensive  and their approach is only feasible for graphical models where
inference can be solved via graph cuts.

6 Conclusions

We have proposed active learning algorithms in the context of structure models which utilized local
entropies in order to decide which subset of the output space for which example to label. We have
demonstrated the effectiveness of our approach in the problem of 3D room layout prediction given a
single image  and we showed that state-of-the-art performance can be obtained while only employing
∼10% of the labelings. We will release the source code upon acceptance as well as scripts to
reproduce all experiments in the paper. In the future  we plan to apply our algorithms in the context
of holistic models in order to investigate which tasks are more informative for visual parsing.

References

[1] P. Auer  N. Cesa-Bianchi  and P. Fischer. Finite-time analysis of the multi-armed bandit problem. Machine

Learning  2002.

[2] P. Auer  N. Cesa-Bianchi  Y. Freund  and R. Schapire. The non-stochastic multi-armed bandit problem.

SIAM J. on Computing  2002.

[3] N. Cesa-Bianchi and G. Lugosi. Prediction  Learning and Games. Cambridge University Press  2006.
[4] D. Cohn  L. Atlas  and R. Ladner. Improving generalization with active learning. Machine Learning 

1994.

[5] D. Cohn  L. Atlas  R. Ladner  M. El-Sharkawi  R. Marks II  M. Aggoune  and D. Park. Training connec-

tionist networks with queries and selective sampling. In Proc. NIPS  1990.

[6] D. Cohn  Z. Ghahramani  and M. I. Jordan. Active learning with statistical models. J. of Artiﬁcial

Intelligence Research  1996.

[7] A. Culotta and A. McCallum. Reducing labeling effort for structured prediction tasks. In Proc. AAAI 

2005.

[8] A. Farhangfar  R. Greiner  and C. Szepesvari. Learning to Segment from a Few Well-Selected Training

Images. In Proc. ICML  2009.

[9] A. Fathi  M. F. Balcan  X. Ren  and J. M. Rehg. Combining Self Training and Active Learning for Video

Segmentation. In Proc. BMVC  2011.

8

[10] T. Hazan and A. Shashua. Norm-Product Belief Propagation: Primal-Dual Message-Passing for LP-

Relaxation and Approximate-Inference. Trans. Information Theory  2010.

[11] T. Hazan and R. Urtasun. A Primal-Dual Message-Passing Algorithm for Approximated Large Scale

Structured Prediction. In Proc. NIPS  2010.

[12] V. Hedau  D. Hoiem  and D. A. Forsyth. Recovering the Spatial Layout of Cluttered Rooms . In Proc.

ICCV  2009.

[13] D. Hoiem  A. A. Efros  and M. Hebert. Recovering Surface Layout from an Image. IJCV  2007.
[14] A. Kapoor  K. Grauman  R. Urtasun  and T. Darrell. Active Learning with Gaussian Processes for Object

Categorization . In Proc. ICCV  2007.

[15] P. Kohli and P. Torr. Measuring Uncertainty in Graph Cut Solutions -Efﬁciently Computing Min-marginal

Energies using Dynamic Graph Cuts. In Proc. ECCV  2006.

[16] J. Lafferty  A. McCallum  and F. Pereira. Conditional random ﬁelds: Probabilistic models for segmenting

and labeling sequence data. In Proc. ICML  2001.

[17] D. C. Lee  A. Gupta  M. Hebert  and T. Kanade. Estimating Spatial Layout of Rooms using Volumetric

Reasoning about Objects and Surfaces. In Proc. NIPS  2010.

[18] D. C. Lee  M. Hebert  and T. Kanade. Geometric Reasoning for Single Image Structure Recovery. In

Proc. CVPR  2009.

[19] D. Lewis and J. Catlett. Heterogeneous uncertainty sampling for supervised learning. In Proc. ICML 

1994.

[20] D. Lewis and W. Gale. A sequential algorithm for training text classiﬁers. In Proc. Research and Devel-

opment in Info. Retrieval  1994.

[21] T. Mensink  J. Verbeek  and G. Csurka. Learning Structured Prediction Models for Interactive Image

Labeling. In Proc. CVPR  2011.

[22] D. Roth and K. Small. Margin-based Active Learning for Structured Output Spaces. In Proc. ECML 

2006.

[23] C. Rother  V. Kolmogorov  and A. Blake. GrabCut

Graph Cuts. In Proc. SIGGRAPH  2004.

Interactive Foreground Extraction using Iterated

[24] N. Roy and A. McCallum. Toward optimal active learning through sampling estimation of error reduction.

In Proc. ICML  2001.

[25] T. Scheffer  C. Decomain  and S. Wrobel. Active hidden Markov models for information extraction. In

Proc. Int’l Conf. Advances in Intelligent Data Analysis  2001.

[26] A. G. Schwing  T. Hazan  M. Pollefeys  and R. Urtasun. Distributed Message Passing for Large Scale

Graphical Models. In Proc. CVPR  2011.

[27] A. G. Schwing  T. Hazan  M. Pollefeys  and R. Urtasun. Efﬁcient Structured Prediction for 3D Indoor

Scene Understanding. In Proc. CVPR  2012.

[28] A. G. Schwing  T. Hazan  M. Pollefeys  and R. Urtasun. Efﬁcient Structured Prediction with Latent

Variables for General Graphical Models. In Proc. ICML  2012.

[29] B. Settles  M. Craven  and S. Ray. Multiple-instance active learning. In Proc. NIPS  2008.
[30] P. Shivaswamy and T. Joachims. Online Structured Prediction via Coactive Learning. In Proc. ICML 

2012.

[31] B. Siddiquie and A. Gupta. Beyond Active Noun Tagging: Modeling Contextual Interactions for Multi-

Class Active Learning. In Proc. CVPR  2010.

[32] S. Tong and D. Koller. Support vector machine active learning with applications to text classiﬁcation.

JMLR  2001.

[33] I. Tsochantaridis  T. Joachims  T. Hofmann  and Y. Altun. Large Margin Methods for Structured and

Interdependent Output Variables. JMLR  2005.

[34] A. Vezhnevets  V. Ferrari  and J. M. Buhmann. Active Learning for Semantic Segmentation with Expected

Change. In Proc. CVPR  2012.

[35] S. Vijayanarasimhan and K. Grauman. Cost-Sensitive Active Visual Category Learning. IJCV  2010.
[36] S. Vijayanarasimhan and K. Grauman. Active Frame Selection for Label Propagation in Videos. In Proc.

ECCV  2012.

[37] A. L. Yuille and A. Rangarajan. The Concave-Convex Procedure. Neural Computation  2003.

9

,Wenjie Luo
Alex Schwing
Raquel Urtasun