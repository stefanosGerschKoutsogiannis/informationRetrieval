2010,Improving the Asymptotic Performance of Markov Chain Monte-Carlo by Inserting Vortices,We present a new way of converting a reversible finite Markov chain into a nonreversible one  with a theoretical guarantee that the asymptotic variance of the MCMC estimator based on the non-reversible chain is reduced. The method is applicable to any reversible chain whose states are not connected through a tree  and can be interpreted graphically as inserting vortices into the state transition graph. Our result confirms that non-reversible chains are fundamentally better than reversible ones in terms of asymptotic performance  and suggests interesting directions for further improving MCMC.,Improving the Asymptotic Performance of Markov

Chain Monte-Carlo by Inserting Vortices

Galleria 2  Manno CH-6928  Switzerland

Galleria 2  Manno CH-6928  Switzerland

Faustino Gomez

IDSIA

tino@idsia.ch

Yi Sun
IDSIA

yi@idsia.ch

J¨urgen Schmidhuber

IDSIA

Galleria 2  Manno CH-6928  Switzerland

juergen@idsia.ch

Abstract

We present a new way of converting a reversible ﬁnite Markov chain into a non-
reversible one  with a theoretical guarantee that the asymptotic variance of the
MCMC estimator based on the non-reversible chain is reduced. The method is
applicable to any reversible chain whose states are not connected through a tree 
and can be interpreted graphically as inserting vortices into the state transition
graph. Our result conﬁrms that non-reversible chains are fundamentally better
than reversible ones in terms of asymptotic performance  and suggests interesting
directions for further improving MCMC.

1

Introduction

Markov Chain Monte Carlo (MCMC) methods have gained enormous popularity over a wide variety
of research ﬁelds [6  8]  owing to their ability to compute expectations with respect to complex  high
dimensional probability distributions. An MCMC estimator can be based on any ergodic Markov
chain with the distribution of interest as its stationary distribution. However  the choice of Markov
chain greatly affects the performance of the estimator  in particular the accuracy achieved with a
pre-speciﬁed number of samples [4].
In general  the efﬁciency of an MCMC estimator is determined by two factors:
i) how fast the
chain converges to its stationary distribution  i.e.  the mixing rate [9]  and ii) once the chain reaches
its stationary distribution  how much the estimates ﬂuctuate based on trajectories of ﬁnite length 
which is characterized by the asymptotic variance. In this paper  we consider the latter criteria.
Previous theory concerned with reducing asymptotic variance has followed two main tracks. The
ﬁrst focuses on reversible chains  and is mostly based on the theorems of Peskun [10] and Tierney
[11]  which state that if a reversible Markov chain is modiﬁed so that the probability of staying in
the same state is reduced  then the asymptotic variance can be decreased. A number of methods
have been proposed  particularly in the context of Metropolis-Hastings method  to encourage the
Markov chain to move away from the current state  or its adjacency in the continuous case [12  13].
The second track  which was explored just recently  studies non-reversible chains. Neal proved
in [4] that starting from any ﬁnite-state reversible chain  the asymptotic variance of a related non-
reversible chain  with reduced probability of back-tracking to the immediately previous state  will
not increase  and typically decrease. Several methods have been proposed by Murray based on this
idea [5].

1

Neal’s result suggests that non-reversible chains may be fundamentally better than reversible ones in
terms of the asymptotic performance. In this paper  we follow up this idea by proposing a new way
of converting reversible chains into non-reversible ones which  unlike in Neal’s method  are deﬁned
on the state space of the reversible chain  with the theoretical guarantee that the asymptotic variance
of the associated MCMC estimator is reduced. Our method is applicable to any non-reversible chain
whose state transition graph contains loops  including those whose probability of staying in the
same state is zero and thus cannot be improved using Peskun’s theorem. The method also admits
an interesting graphical interpretation which amounts to inserting ‘vortices’ into the state transition
graph of the original chain. Our result suggests a new and interesting direction for improving the
asymptotic performance of MCMC.
The rest of the paper is organized as follows: section 2 reviews some background concepts and
results; section 3 presents the main theoretical results  together with the graphical interpretation;
section 4 provides a simple yet illustrative example and explains the intuition behind the results;
section 5 concludes the paper.

XT

1
T

2 Preliminaries
Suppose we wish to estimate the expectation of some real valued function f over domain S  with
respect to a probability distribution π  whose value may only be known to a multiplicative constant.
Let A be a transition operator of an ergodic1 Markov chain with stationary distribution π  i.e. 

π (x) A (x → y) = π (y) B (y → x)   ∀x  y ∈ S 

(1)
where B is the reverse operator as deﬁned in [5]. The expectation can then be estimated through the
MCMC estimator

µT =

(2)
where x1 ···   xT is a trajectory sampled from the Markov chain. The asymptotic variance of µT  
with respect to transition operator A and function f is deﬁned as
T→∞ T V [µT ]  

A (f) = lim
σ2

f (xt)  

(3)

t=1

where V [µT ] denotes the variance of µT . Since the chain is ergodic  σ2
A (f) is well-deﬁned follow-
ing the central limit theorem  and does not depend on the distribution of the initial point. Roughly
speaking  asymptotic variance has the meaning that the mean square error of the estimates based on
A (f)  after a sufﬁciently long period
T consecutive states of the chain would be approximately 1
of ”burn in” such that the chain is close enough to its stationary distribution. Asymptotic variance
can be used to compare the asymptotic performance of MCMC estimators based on different chains
with the same stationary distribution  where smaller asymptotic variance indicates that  asymptoti-
cally  the MCMC estimator requires fewer samples to reach a speciﬁed accuracy.
Under the ergodic assumption  the asymptotic variance can be written as

T σ2

A (f) = V [f] +X∞

σ2

τ =1

(cA f (τ) + cB f (τ))  

(4)

where

cA f (τ) = EA [f (xt) f (xt+τ )] − EA [f (xt)] E [f (xt+τ )]

A (f) = σ2

is the covariance of the function value between two states that are τ time steps apart in the trajectory
A (f) depends on both A and its reverse
of the Markov chain with transition operator A. Note that σ2
operator B  and σ2
In this paper  we consider only the case where S is ﬁnite  i.e.  S = {1 ···   S}  so that the transition
operators A and B  the stationary distribution π  and the function f can all be written in matrix form.
Let π = [π (1)  ···   π (S)]>  f = [f (1)  ···   f (S)]>  Ai j = A (i → j)  Bi j = B (i → j). The
asymptotic variance can thus be written as

B (f) since A is also the reverse operator of B by deﬁnition.

A (f) = V [f] +X∞

σ2

τ =1

f>(cid:0)QAτ + QBτ − 2ππ>(cid:1) f 

1Strictly speaking  the ergodic assumption is not necessary for the MCMC estimator to work  see [4].

However  we make the assumption to simplify the analysis.

2

with Q = diag {π}. Since B is the reverse operator of A  QA = B>Q. Also  from the ergodic
assumption 

lim
τ→∞ Aτ = lim

τ→∞ Bτ = R 

where R = 1π> is a square matrix in which every row is π>. It follows that the asymptotic variance
can be represented by Kenney’s formula [7] in the non-reversible case:

(5)
where [·]H denotes the Hermitian (symmetric) part of a matrix  and Λ = Q+ππ>−J  with J = QA
being the joint distribution of two consecutive states.

σ2

H (Qf) − 2f>Qf 

A (f) = V [f] + 2 (Qf)>(cid:2)Λ−(cid:3)

3

Improving the asymptotic variance

A (f) ≤ σ2

It is clear from Eq.5 that the transition operator A affects the asymptotic variance only through term
[Λ−]H. If the chain is reversible  then J is symmetric  so that Λ is also symmetric  and therefore
comparing the asymptotic variance of two MCMC estimators becomes a matter of comparing their
J  namely  if2 J (cid:22) J0 = QA0  then σ2
A0 (f)  for any f. This leads to a simple proof of
Peskun’s theorem in the discrete case [3].
In the case where the Markov chain is non-reversible  i.e.  J is asymmetric  the analysis becomes
much more complicated. We start by providing a sufﬁcient and necessary condition in section 3.1 
which transforms the comparison of asymptotic variance based on arbitrary ﬁnite Markov chains
into a matrix ordering problem  using a result from matrix analysis. In section 3.2  a special case
is identiﬁed  in which the asymptotic variance of a reversible chain is compared to that of a non-
reversible one whose joint distribution over consecutive states is that of the reversible chain plus
a skew-Hermitian matrix. We prove that the resulting non-reversible chain has smaller asymptotic
variance  and provide a necessary and sufﬁcient condition for the existence of such non-zero skew-
Hermitian matrices. Finally in section 3.3  we provide a graphical interpretation of the result.

3.1 The general case

From Eq.5 we know that comparing the asymptotic variances of two MCMC estimators is equivalent
to comparing their [Λ−]H. The following result from [1  2] allows us to write [Λ−]H in terms of the
symmetric and asymmetric parts of Λ.
Lemma 1 If a matrix X is invertible  then [X−]−
skew Hermitian part of X.

H = [X]H + [X]>

H [X]S  where [X]S is the

S [X]−

From Lemma 1  it follows immediately that in the discrete case  the comparison of MCMC esti-
mators based on two Markov chains with the same stationary distribution can be cast as a different
problem of matrix comparison  as stated in the following proposition.
Proposition 1 Let A  A0 be two transition operators of ergodic Markov chains with stationary dis-
tribution π. Let J = QA  J0 = QA0  Λ = Q + ππ> − J  Λ0 = Q + ππ> − J0. Then the following
three conditions are equivalent:

1) σ2

A (f) ≤ σ2

2) [Λ−]H (cid:22)h

(Λ0)−i

H

A0 (f) for any f

S [Λ]−

H [J]S (cid:22) [J0]H − [J0]>

3) [J]H − [J]>
Proof. First we show that Λ is invertible. Following the steps in [3]  for any f 6= 0 

f>Λf = f> [Λ]H f = f>(cid:0)Q + ππ> − J(cid:1) f

S [Λ0]−

H [J0]S

Eh

(f (xt) − f (xt+1))2i

=

1
2

+ E [f (xt)]2 > 0 

2For symmetric matrices X and Y   we write X (cid:22) Y if Y − X is positive semi-deﬁnite  and X ≺ Y if

Y − X is positive deﬁnite.

3

thus [Λ]H (cid:31) 0  and Λ is invertible since Λf 6= 0 for any f 6= 0.
Condition 1) and 2) are equivalent by deﬁnition. We now prove 2) is equivalent to 3). By Lemma 1 

(Λ0)

⇐⇒ [Λ]H + [Λ]>

>
S [Λ]H [Λ]S (cid:23) [Λ0]H + [Λ0]
S [Λ0]H [Λ0]S  

H (cid:22)h
(cid:2)Λ−(cid:3)

−i

H

the result follows by noticing that [Λ]H = Q + ππ> − [J]H and [Λ]S = − [J]S.
3.2 A special case

S [Λ]−

Generally speaking  the conditions in Proposition 1 are very hard to verify  particularly because of
the term [J]>
H [J]S. Here we focus on a special case where [J0]S = 0  and [J0]H = J0 = [J]H.
This amounts to the case where the second chain is reversible  and its transition operator is the
average of the transition operator of the ﬁrst chain and the associated reverse operator. The result is
formalized in the following corollary.

Corollary 1 Let T be a reversible transition operator of a Markov chain with stationary distribution
π. Assume there is some H that satisﬁes
Condition I. 1>H = 0  H1 = 0  H = −H>  and3
Condition II. T ± Q−H are valid transition matrices.
Denote A = T + Q−H  B = T − Q−H  then
1) A preserves π  and B is the reverse operator of A.
2) σ2
3) If H 6= 0  then there is some f  such that σ2
4) If Aε = T + (1 + ε) Q−H is valid transition matrix  ε > 0  then σ2
Proof. For 1)  notice that π>T = π>  so

T (f) for any f.

B (f) ≤ σ2

A (f) = σ2

A (f) < σ2

(f) ≤ σ2

A (f).

T (f).

Aε

and similarly for B. Moreover

π>A = π>T + π>Q−H = π> + 1>H = π> 

QA = QT + H = (QT − H)> =(cid:0)Q(cid:0)T − Q−H(cid:1)(cid:1)>

= (QB)>  

thus B is the reverse operator of A.
For 2)  σ2

A (f) = σ2

B (f) follows from Eq.5. Let J0 = QT   J = QA. Note that [J]S = H 

A (f) ≤ σ2

T (f) for any f.

HX−.
s   with λs > 0  ∀s.

1
2

Thus

J0 = QT =
(QA + QB) = [QA]H = [J]H  
H H (cid:23) 0 from Proposition 1. It follows that σ2

and [Λ]H (cid:31) 0 thus H> [Λ]−
For 3)  write X = [Λ]H 

Since X (cid:31) 0  HX−H> (cid:23) 0  one can write(cid:0)X + HX−H>(cid:1)−

(cid:2)Λ−(cid:3)
H =(cid:0)X + H>X−H(cid:1)−
H>(cid:0)X + HX−H>(cid:1)−
A (f)(cid:3) = (Qf)>h
= (Hes∗)>XS
= λs kHes∗k4 +X

= X− − X−H>(cid:0)X + HX−H>(cid:1)−
=PS
H =XS
X− −(cid:0)X + H>X−H(cid:1)−i
X−H>(cid:0)X + HX−H>(cid:1)−
(cid:0)e>

λsHes (Hes)> (Hes∗)
s∗ H>Hes

Since H 6= 0  there is at least one s∗  such that Hes∗ 6= 0. Let f = Q−XHes∗  then

λsHes (Hes)> .

s=1 λsese>

T (f) − σ2

(Qf)
HX− (Qf)

= (Qf)>

(cid:2)σ2

(cid:1)2

> 0.

1
2

s=1

s6=s∗ λs

s=1

3We write 1 for the S-dimensional column vector of 1’s.

4

For 4)  let Λε = Q + ππ> − QAε  then for ε > 0 
X + (1 + ε)2 H>X−H

(cid:2)Λ−

(cid:3)

H =

ε

(cid:16)

(cid:17)− (cid:22)(cid:0)X + H>X−H(cid:1)−

=(cid:2)Λ−(cid:3)

H  

(f) ≤ σ2

A (f) for any f.

by Eq.5  we have σ2
Aε
Corollary 1 shows that starting from a reversible Markov chain  as long as one can ﬁnd a non-
zero H satisfying Conditions I and II  then the asymptotic performance of the MCMC estimator is
guaranteed to improve. The next question to ask is whether such an H exists  and  if so  how to ﬁnd
one. We answer this question by ﬁrst looking at Condition I. The following proposition shows that
any H satisfying this condition can be constructed systematically.

Proposition 2 Let H be an S-by-S matrix. H satisﬁes Condition I if and only if H can be written
as the linear combination of 1

2 (S − 1) (S − 2) matrices  with each matrix of the form
Ui j = uiu>

i   1 ≤ i < j ≤ S − 1.

j − uju>

Here u1 ···   uS−1 are S − 1 non-zero linearly independent vectors satisfying u>
Proof. Sufﬁciency. It is straightforward to verify that each Ui j is skew-Hermitian and satisﬁes
Ui j1 = 0. Such properties are inherited by any linear combination of Ui j.
2 (S − 1) (S − 2) linearly independent bases for all H
Necessity. We show that there are at most 1
such that H = −H> and H1 = 0. On one hand  any S-by-S skew-Hermitian matrix can be written
as the linear combination of 1

2 S (S − 1) matrices of the form

s 1 = 0.

Vi j : {Vi j}m n = δ (m  i) δ (n  j) − δ (n  i) δ (m  j)  

1

where δ is the standard delta function such that δ (i  j) = 1 if i = j and 0 otherwise. However 
the constraint H1 = 0 imposes S − 1 linearly independent constraints  which means that out of
2 S (S − 1) parameters  only
1
2 S (S − 1) − (S − 1) =

(cid:19)
are independent.
On the other hand  selecting two non-identical vectors from u1 ···   uS−1 results in
2 (S − 1) (S − 2) different Ui j. It has still to be shown that these Ui j are linearly independent.
Assume

(cid:18)S − 1

(S − 1) (S − 2)

1
2

=

2

1

(cid:0)uiu>

j − uju>

i

Consider two cases: Firstly  assume u1 ···   uS−1 are orthogonal  i.e.  u>
particular us 

i uj = 0 for i 6= j. For a

κi j

1≤i<j≤S−1

1≤i<j≤S−1

0 = X
0 = X
= X

κi jUi j = X
κi jUi jus = X
(cid:13)(cid:13) + X
(cid:13)(cid:13)u>

1≤i<j≤S−1

κi sui

κi j

1≤i<j≤S−1

(cid:1)   ∀κi j ∈ R.
(cid:1) us

(cid:0)uiu>
(cid:13)(cid:13)u>

j − uju>

i

(cid:13)(cid:13) .

Since(cid:13)(cid:13)u>

s us

(cid:13)(cid:13) 6= 0  it follows that κi s = κs j = 0  for all 1 ≤ i < s < j ≤ S − 1. This holds for

s<j≤S−1

1≤i<s

κs juj

s us

s us

any us  so all κi j must be 0  and therefore Ui j are linearly independent by deﬁnition. Secondly  if
u1 ···   uS−1 are not orthogonal  one can construct a new set of orthogonal vectors ˜u1 ···   ˜uS−1
from u1 ···   uS−1 through Gram–Schmidt orthogonalization  and create a different set of bases
˜Ui j. It is easy to verify that each ˜Ui j is a linear combination of Ui j. Since all ˜Ui j are linearly
independent  it follows that Ui j must also be linearly independent.
Proposition 2 conﬁrms the existence of non-zero H satisfying Condition I. We now move to Condi-
tion II  which requires that both QT + H and QT − H remain valid joint distribution matrices  i.e.

5

all entries must be non-negative and sum up to 1. Since 1> (QT + H) 1 = 1 by Condition I  only
the non-negative constraint needs to be considered.
It turns out that not all reversible Markov chains admit a non-zero H satisfying both Condition I and
II. For example  consider a Markov chain with only two states. It is impossible to ﬁnd a non-zero
skew-Hermitian H such that H1 = 0  because all 2-by-2 skew-Hermitian matrices are proportional
to

" 0 −1

#

.

1

0

The next proposition gives the sufﬁcient and necessary condition for the existence of a non-zero H
satisfying both I and II. In particular  it shows an interesting link between the existence of such H
and the connectivity of the states in the reversible chain.

Proposition 3 Assume a reversible ergodic Markov chain with transition matrix T and let J = QT .
The state transition graph GT is deﬁned as the undirected graph with node set S = {1 ···   S} and
edge set {(i  j) : Ji j > 0  1 ≤ i < j ≤ S}. Then there exists some non-zero H satisfying Condition
I and II  if and only if there is a loop in GT .
Proof. Sufﬁciency: Without loss of generality  assume the loop is made of states 1  2 ···   N and
edges (1  2)  ···   (N − 1  N)   (N  1)  with N ≥ 3. By deﬁnition  J1 N > 0  and Jn n+1 > 0 for
all 1 ≤ n ≤ N − 1. A non-zero H can then be constructed as



Hi j =

ε 
−ε 
ε 
−ε 
0 

if 1 ≤ i ≤ N − 1 and j = i + 1 
if 2 ≤ i ≤ N and j = i − 1 
if i = N and j = 1 
if i = 1 and j = N 
otherwise.

Here

ε = min

1≤n≤N−1

{Jn n+1  1 − Jn n+1  J1 N   1 − J1 N} .

Clearly  ε > 0  since all the items in the minimum are above 0. It is trivial to verify that H = −H>
and H1 = 0.
Necessity: Assume there are no loops in GT   then all states in the chain must be organized in a tree 
following the ergodic assumption. In other word  there are exactly 2 (S − 1) non-zero off-diagonal
elements in J. Plus  these 2 (S − 1) elements are arranged symmetrically along the diagonal and
spanning every column and row of J.
Because the states are organized in a tree  there is at least one leaf node s in GT   with a single neigh-
bor s0. Row s and column s in J thus looks like rs = [···   ps s ···   ps s0 ··· ] and its transpose 
respectively  with ps s ≥ 0 and ps s0 > 0  and all other entries being 0.
Assume that one wants to construct a some H  such that J ± H ≥ 0. Let hs be the s-th row of H.
Since rs ± hs ≥ 0  all except the s0-th elements in hs must be 0. But since hs1 = 0  the whole s-th
row  thus the s-th column of H must be 0.
Having set the s-th column and row of H to 0  one can consider the reduced Markov chain with one
state less  and repeat with another leaf node. Working progressively along the tree  it follows that all
rows and columns in H must be 0.
The indication of Proposition 3 together with 2 is that all reversible chains can be improved in terms
of asymptotic variance using Corollary 1  except those whose transition graphs are trees. In practice 
the non-tree constraint is not a problem because almost all current methods of constructing reversible
chains generate chains with loops.

3.3 Graphical interpretation

In this subsection we provide a graphical interpretation of the results in the previous sections.
Starting from a simple case  consider a reversible Markov chain with three states forming a loop.
Let u1 = [1  0 −1]> and u2 = [0  1 −1]>. Clearly  u1 and u2 are linearly independent and
u>
1 1 = u>
2 1 = 0. By Proposition 2 and 3  there exists some ε > 0  such that H = εU12 satis-

6

Figure 1: Illustration of the construction of larger vortices. The left hand side is a state transition
graph of a reversible Markov chain with S = 9 states  with a vortex 3 → 8 → 6 → 5 → 4 of
strength ε inserted. The corresponding H can be expressed as the linear combination of Ui j  as
shown on the right hand side of the graph. We start from the vortex 8 → 6 → 9 → 8  and add
one vortex a time. The dotted lines correspond to edges on which the ﬂows cancel out when a new
vortex is added. For example  when vortex 6 → 5 → 9 → 6 is added  edge 9 → 6 cancels edge
6 → 9 in the previous vortex  resulting in a larger vortex with four states. Note that in this way one
can construct vortices which do not include state 9  although each Ui j is a vortex involving 9.

ﬁes Condition I and II  with U1 2 = u1u>

2 − u2u>

1 . Write U1 2 and J + H in explicit form 

"

#

1 −1
0
−1
0
1
1 −1
0

U1 2 =

  J + H =

"

p1 2 + ε p1 3 − ε
p1 1
p2 1 − ε
p2 3 + ε
p2 2
p3 1 + ε p3 2 − ε

p3 3

#

 

with pi j being the probability of the consecutive states being i  j. It is clear that in J + H  the
probability of jumps 1 → 2  2 → 3  and 3 → 1 is increased  and the probability of jumps in the
opposite direction is decreased. Intuitively  this amounts to adding a ‘vortex’ of direction 1 → 2 →
3 → 1 in the state transition. Similarly  the joint probability matrix for the reverse operator is J −H 
which adds a vortex in the opposite direction. This simple case also gives an explanation of why
adding or subtracting non-zero H can only be done where a loop already exists  since the operation
requires subtracting ε from all entries in J corresponding to edges in the loop.
In the general case  deﬁne S − 1 vectors u1 ···   uS−1 as

us = [0 ···   0 

  0 ···   0 −1]>.

1

s-th element

It is straightforward to see that u1 ···   uS−1 are linearly independent and u>
s 1 = 0 for all s  thus
j − uju>
any H satisfying Condition I can be represented as the linear combination of Ui j = uiu>
i  
with each Ui j containing 1’s at positions (i  j)  (j  S)  (S  i)  and −1’s at positions (i  S)  (S  j) 
(j  i). It is easy to verify that adding εUi j to J amounts to introducing a vortex of direction i → j →
S → i  and any vortex of N states (N ≥ 3) s1 → s2 → ··· → sN → s1 can be represented by the
n=1 Usn sn+1 in the case of state S being in the vortex and assuming sN = S
n=1 Usn sn+1 if S is not in the vortex  as demonstrated in
Figure 1. Therefore  adding or subtracting an H to J is equivalent to inserting a number of vortices
into the state transition map.

linear combinationPN−1
without loss of generality  or UsN  s1 +PN−1

4 An example

Adding vortices to the state transition graph forces the Markov chain to move in loops following
pre-speciﬁed directions. The beneﬁt of this can be illustrated in the following example. Consider a
reversible Markov chain with S states forming a ring  namely from state s one can only jump to s⊕1
or s (cid:9) 1  with ⊕ and (cid:9) being the mod-S summation and subtraction. The only possible non-zero H

in this example is of form εPS−1

s=1 Us s+1  corresponding to vortices on the large ring.

We assume uniform stationary distribution π (s) = 1
S . In this case  any reversible chain behaves
like a random walk. The chain which achieves minimal asymptotic variance is the one with the
probability of both jumping forward and backward being 1
2. The expected number of steps for
4 . However  adding the vortex reduces this number to
this chain to reach the state S

2 edges away is S2

7

321765498698659865498654983365498–εU6 8–εU5 6–εU4 5–εU3 4+ εU3 8H=Figure 2: Demonstration of the vortex effect: (a) and (b) show two different  reversible Markov
chains  each containing 128 states connected in a ring. The equilibrium distribution of the chains is
depicted by the gray inner circles; darker shades correspond to higher probability. The equilibrium
distribution of chain (a) is uniform  while that of (b) contains two peaks half a ring apart. In addition 
the chains are constructed such that the probability of staying in the same state is zero. In each
case  two trajectories  of length 1000  are generated from the chain with and without the vortex 
starting from the state pointed to by the arrow. The length of the bar radiating out from a given
state represents the relative frequency of visits to that state  with red and blue bars corresponding
to chains with and without vortex  respectively. It is clear from the graph that trajectories sampled
from reversible chains spread much slower  with only 1/5 of the states reached in (a) and 1/3 in (b) 
and the trajectory in (b) does not escape from the current peak. On the other hand  with vortices
added  trajectories of the same length spread over all the states  and effectively explore both peaks
of the stationary distribution in (b). The plot (c) show the correlation of function values (normalized
by variance) between two states τ time steps apart  with τ ranging from 1 to 600. Here we take

the Markov chains from (b) and use function f (s) = cos(cid:0)4π · s

only do the absolute values of the correlations go down signiﬁcantly  but also their signs alternate 
indicating that these correlations tend to cancel out in the sum of Eq.5.

(cid:1). When vortices are added  not

128

roughly S
2ε for large S  suggesting that it is much easier for the non-reversible chain to reach faraway
states  especially for large S. In the extreme case  when ε = 1
2  the chain cycles deterministically 
reducing asymptotic variance to zero. Also note that the reversible chain here has zero probability
of staying in the current state  thus cannot be further improved using Peskun’s theorem.
Our intuition about why adding vortices helps is that chains with vortices move faster than the
reversible ones  making the function values of the trajectories less correlated. This effect is demon-
strated in Figure 2.

5 Conclusion

In this paper  we have presented a new way of converting a reversible ﬁnite Markov chain into a non-
reversible one  with the theoretical guarantee that the asymptotic variance of the MCMC estimator
based on the non-reversible chain is reduced. The method is applicable to any reversible chain whose
states are not connected through a tree  and can be interpreted graphically as inserting vortices into
the state transition graph.
The results conﬁrm that non-reversible chains are fundamentally better than reversible ones. The
general framework of Proposition 1 suggests further improvements of MCMC’s asymptotic per-
formance  by applying other results from matrix analysis to asymptotic variance reduction. The
combined results of Corollary 1  and Propositions 2 and 3  provide a speciﬁc way of doing so  and
pose interesting research questions. Which combinations of vortices yield optimal improvements
for a given chain? Finding one of them is a combinatorial optimization problem. How can a good
combination be constructed in practice  using limited history and computational resources?

8

WithoutvortexWithvortex100200300400500600(cid:45)0.4(cid:45)0.20.00.20.40.60.81.0WithoutvortexWithvortexabcReferences
[1] R.P. Wen  ”Properties of the Matrix Inequality”  Journal of Taiyuan Teachers College  2005.
[2] R. Mathias  ”Matrices With Positive Deﬁnite Hermitian Part:

Inequalities And Lin-
ear Systems”  http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.
1.1.33.1768  1992.

[3] L.H. Li  ”A New Proof of Peskun’s and Tierney’s Theorems using Matrix Method”  Joint
Graduate Students Seminar of Department of Statistics and Department of Biostatistics  Univ.
of Toronto  2005.

[4] R.M. Neal  ”Improving asymptotic variance of MCMC estimators: Non-reversible chains are

better”  Technical Report No. 0406  Department of Statistics  Univ. of Toronto  2004.

[5] I. Murray  ”Advances in Markov chain Monte Carlo methods”  M. Sci. thesis  University Col-

lege London  2007.

[6] R.M. Neal  ”Bayesian Learning for Neural Networks”  Springer  1996.
[7] J. Kenney and E.S. Keeping  ”Mathematics of Statistics”  van Nostrand  1963.
[8] C. Andrieu  N. de Freitas  A. Doucet  and M.I. Jordan  ”An Introduction to MCMC for Ma-

chine Learning”  Machine Learning  50  5-43  2003.

[9] Szakdolgozat  ”The Mixing Rate of Markov Chain Monte Carlo Methods and some Appli-
cations of MCMC Simulation in Bioinformatics”  M.Sci. thesis  Eotvos Lorand University 
2006.

[10] P.H. Peskun  ”Optimum Monte-Carlo sampling using Markov chains”  Biometrika  vol. 60  pp.

607-612  1973.

[11] L. Tierney  ”A note on Metropolis Hastings kernels for general state spaces”  Ann. Appl.

Probab. 8  1-9  1998.

[12] S. Duane  A.D. Kennedy  B.J. Pendleton and D. Roweth  ”Hybrid Monte Carlo”  Physics Let-

ters B  vol.195-2  1987.

[13] J.S. Liu  ”Peskun’s theorem and a modiﬁed discrete-state Gibbs sampler”  Biometria  vol.83 

pp.681-682  1996.

9

,Assaf Glazer
Michael Lindenbaum
Shaul Markovitch
Jun-Yan Zhu
Richard Zhang
Deepak Pathak
Trevor Darrell
Alexei Efros
Oliver Wang