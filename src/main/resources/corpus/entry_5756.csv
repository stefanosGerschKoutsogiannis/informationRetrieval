2018,Unorganized Malicious Attacks Detection,Recommender systems have attracted much attention during the past decade. Many attack detection algorithms have been developed for better recommendations  mostly focusing on shilling attacks  where an attack organizer produces a large number of user profiles by the same strategy to promote or demote an item. This work considers another different attack style: unorganized malicious attacks  where attackers individually utilize a small number of user profiles to attack different items without organizer. This attack style occurs in many real applications  yet relevant study remains open. We formulate the unorganized malicious attacks detection as a matrix completion problem  and propose the Unorganized Malicious Attacks detection (UMA) algorithm  based on the alternating splitting augmented Lagrangian method. We verify  both theoretically and empirically  the effectiveness of the proposed approach.,Unorganized Malicious Attacks Detection

Ming Pang Wei Gao Min Tao
Zhi-Hua Zhou
National Key Laboratory for Novel Software Technology 

Nanjing University  Nanjing  210023  China

{pangm  gaow  zhouzh}@lamda.nju.edu.cn

taom@nju.edu.cn

Abstract

Recommender systems have attracted much attention during the past decade. Many
attack detection algorithms have been developed for better recommendations 
mostly focusing on shilling attacks  where an attack organizer produces a large
number of user proï¬les by the same strategy to promote or demote an item. This
work considers another different attack style: unorganized malicious attacks  where
attackers individually utilize a small number of user proï¬les to attack different
items without organizer. This attack style occurs in many real applications  yet
relevant study remains open. We formulate the unorganized malicious attacks
detection as a matrix completion problem  and propose the Unorganized Malicious
Attacks detection (UMA) algorithm  based on the alternating splitting augmented
Lagrangian method. We verify  both theoretically and empirically  the effectiveness
of the proposed approach.

1

Introduction

Online activities have been an essential part in our daily life as the ï¬‚ourish of Internet  and it is
important to recommend suitable products effectively as the number of users and items increases
drastically. Various collaborative ï¬ltering techniques have been developed in diverse systems to help
customers choose their favorite products in a set of items [5  18  28]. However  most collaborative
ï¬ltering approaches are vulnerable to spammers and manipulations of ratings [13  19]  and attackers
could bias systems by inserting fake rating scores into the user-item rating matrix. Some attackers try
to increase the popularity of their own items (push attack) while the others intend to decrease the
popularity of their competitorsâ€™ items (nuke attack).
Detecting attacks from online rating systems is crucial to recommendations. Most attack detection
studies focus on shilling attacks [13]  where all the attack proï¬les are produced by the same strategy
to promote or demote a particular item. For example  an attack organizer may produce hundreds of
fake user proï¬les with one strategy where each fake user proï¬le gives high scores to the most popular
movies and low scores to the target movie. Relevant studies have shown good detection performance
on diverse shilling attack strategies [16  19  23].
Practical mechanisms have been developed to prevent shilling attacks. For example  lots of online
sites require real names and phone numbers for user registration; CAPTCHA is used to determine
whether the response is generated by a robot; customers are allowed to rate a product after purchasing
this product on the shopping website. These mechanisms produce high cost for conducting traditional
shilling attacks; for example  small online sellers in e-commerce like Amazon have insufï¬cient
capacity to produce hundreds of fake rating proï¬les to conduct a shilling attack.
In this paper  we introduce another different attack model named unorganized malicious attacks 
where attackers individually use a small number of user proï¬les to attack their own targets without
organizer. This attack happens in many real applications: online sellers on Amazon may produce
a few fake customer proï¬les to demote their competitorsâ€™ high-quality products; writers may hire

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  MontrÃ©al  Canada.

several users to give high scores to promote their own books. Actually  recommender systems may
be seriously inï¬‚uenced by small amounts of unorganized malicious attacks  e.g.  the ï¬rst maliciously
bad rating can decrease the sales of one seller by 13% [20]. So far as we know  the detection of
unorganized malicious attacks has rarely been studied  and existing attack detection approaches do
not work well on this kind of attack [26].
We formulate the unorganized malicious attacks detection as a variant of matrix completion problem.
Let X denote the ground-truth rating matrix without attacks and noises  and assume that the matrix
is low-rank since the usersâ€™ preferences are affected by several factors [31]. Let Y be the sparse
malicious-attack matrix  and Z denotes a small perturbation noise matrix. What we can observe is a
matrix M such that M = X + Y + Z.
We propose the Unorganized Malicious Attacks detection (UMA) algorithm  which can be viewed
as an extension of alternating splitting augmented Lagrangian method. Theoretically  we show
that the low-rank rating matrix X and the sparse matrix Y can be recovered under some classical
matrix-completion assumptions  and we present the global convergence of UMA with a worst-case
O(1/t) convergence rate. Finally  empirical studies are provided to verify the effectiveness of our
proposed algorithm in comparison with the state-of-the-art methods for attack detection.
The rest of this paper is organized as follows. Section 2 reviews related work. Section 3 introduces
the framework of unorganized malicious attacks detection. Section 4 proposes the UMA algorithm.
Section 5 shows the theoretical justiï¬cation. Section 6 reports the experimental results. Section 7
concludes this work.

2 Related Work

Collaborative ï¬ltering has been one of the most successful techniques to build recommender systems.
The core assumption of collaborative ï¬ltering is that if users have expressed similar interests in the
past  they will share common interest in the future [12]. Signiï¬cant progress about collaborative
ï¬ltering has been made [5  18  28  31]. There are two main categories of conventional collaborative
ï¬ltering (based on the user-item rating matrix) which are memory-based and model-based algorithms.
Collaborative ï¬ltering schemes are vulnerable to attacks [1  13]  and increasing attention has been
paid to attack detection. Researchers have proposed several methods which mainly focus on shilling
attacks where the attack organizer produces a large number of user proï¬les by the same strategy
to promote or demote a particular item. These methods mainly contain statistical  classiï¬cation 
clustering and data reduction-based methods [13].
Statistical methods are used to detect anomalies with suspicious ratings. Hurley et al. [16] proposed
the Neyman-Pearson statistical attack detection method to distinguish malicious users from normal
users  and Li and Luo [17] introduced the probabilistic Bayesian network models. Based on attributes
derived from user proï¬les  classiï¬cation methods detect attacks by kNN  SVM  etc. [14  24]. Bhaumik
et al. [3] presented the unsupervised clustering algorithm based on several classiï¬cation attributes
[7]  and they apply k-means clustering based on these attributes and classify users in the smallest
cluster as malicious users. Variable selection method treats users as variables and calculates their
covariance matrix [22]. Users with the smallest coefï¬cient in the ï¬rst l principal components of
the covariance matrix are classiï¬ed as malicious users. Ling et al. [19] utilized a low-rank matrix
factorization method to predict the usersâ€™ ratings. Usersâ€™ reputation is computed according to the
predicted ratings and low-reputed users are classiï¬ed as malicious users.
These methods make detection by ï¬nding the common characteristics of the attack proï¬les that
differ from the normal proï¬les. Therefore  they have a common assumption that the attack proï¬les
are produced by the same attack strategy. However  this assumption does not hold for unorganized
malicious attacks  where different attackers use different strategies to attack their own targets.
Recovering low-dimensional structure from a corrupted matrix is related to robust PCA [4  9  33].
However  robust PCA focuses on recovering low-rank part X from complete or incomplete matrix 
and the target is different from attacks detection (which is our task). Our work considers the speciï¬c
properties of malicious attacks to distinguish the attack matrix Y from the small perturbation noise
term Z. In this way  our method can not only recover the low-rank part X  but also distinguish Y
from the noise term Z which leads to better performance.

2

3 The Formulation

This section introduces some notations and problem formulation. We introduce the general form of
an attack proï¬le  and give a detailed comparison between unorganized malicious attacks and shilling
attacks  followed by the corresponding detection problem formulation.

3.1 Notations
We begin with some notations used in this paper. Let (cid:107)X(cid:107)  (cid:107)X(cid:107)F and (cid:107)X(cid:107)âˆ— denote the operator norm 
Frobenius norm and nuclear norm of matrix X  respectively. Let (cid:107)X(cid:107)1 and (cid:107)X(cid:107)âˆ be the (cid:96)1 and (cid:96)âˆ
norm of matrix X  respectively. Further  we deï¬ne the Euclidean inner product between two matrices
as (cid:104)X  Y (cid:105) := trace(XY (cid:62))  where Y (cid:62) means the transpose of Y . We have (cid:107)X(cid:107)2
Let Pâ„¦ denote an operator of linear transformation over matrices space  and we also denote by Pâ„¦
the linear space of matrices supported on â„¦ when it is clear from the context. Then  Pâ„¦(cid:62) represents
the space of matrices supported on â„¦c. For an integer m  let [m] := {1  2  . . .   m}.

F = (cid:104)X  X(cid:105).

Figure 1: General form of an attack proï¬le.

3.2 Problem Formulation

Bhaumik et al. [2] introduced the general form of an attack proï¬le  as shown in Figure 1. The attack
proï¬le contains four parts. The single target item it is given a malicious rating  i.e.  a high rating in
a push attack or a low rating in a nuke attack. The selected items IS are a group of selected items
for special treatment during the attack. The ï¬ller items IF are selected randomly to complete the
attack proï¬le. The null part Iâˆ… contains the rest of the items with no ratings. Functions Î¸  Î¶ and Î¥
determine how to assign ratings to items in IS  IF and target item it  respectively. Three basic attack
strategies are listed as follows.
â€¢ Random attack: IS is empty; IF is selected randomly  and function Î¶ assigns ratings to IF
by generating random ratings centered around the overall average rating in the database.
â€¢ Average attack: IS is empty; IF is selected randomly  and function Î¶ assigns ratings to IF
â€¢ Bandwagon attack: IS is selected from the popular items and function Î¸ assigns high ratings

by generating random ratings centered around the average rating of each item.

to IS. The ï¬ller items IF are handled similarly to random attack.

The shilling attack chooses one attack strategy (e.g.  average attack strategy)  and ï¬xes the target
item it  the numbers of rated items k and l and the rating functions. This makes the generated attack
proï¬les have some common characteristics in one shilling attack. Besides  a large number of attack
proï¬les are required in the basic setting of shilling attacks.
However  unorganized malicious attacks allow the concurrence of various attack strategies  and
the number of rated items  the target item and the rating functions can be different. Each attacker
produces a small number of attack proï¬les with their own strategies and preference [26].
Let U[m] = {U1  U2  . . .   Um} and I[n] = {I1  I2  . . .   In} denote m users and n items  respectively.
Let X âˆˆ RmÃ—n be the ground-truth rating matrix. Xij denotes the score that user Ui gives to item Ij
without any attack or noise  i.e.  Xij reï¬‚ects the ground-truth feeling of user Ui on item Ij. Suppose
that the score range is [âˆ’R  R]  and we have âˆ’R â‰¤ Xij â‰¤ R. In this work  we assume that X is a

3

ğ‘–"#â‹¯ğ‘–%#ğ‘–"&â‹¯ğ‘–â€™&ğ‘–"âˆ…â‹¯ğ‘–)âˆ…ğ‘–*ğœƒ(ğ‘–"#)â‹¯ğœƒ(ğ‘–%#)ğœ(ğ‘–"&)â‹¯ğœ(ğ‘–â€™&)ğ‘›ğ‘¢ğ‘™ğ‘™â‹¯ğ‘›ğ‘¢ğ‘™ğ‘™Î¥(ğ‘–*)ğ¼#ğ¼&ğ¼âˆ…Ratings for ğ‘˜selected itemsRatings for ğ‘™filler itemsUnrated items in the attack profileRatings for thetarget itemlow-rank matrix as in classical matrix completion [30] and collaborative ï¬ltering [31]. The intuition
is that the userâ€™ preferences may be inï¬‚uenced by a few factors.
The ground-truth matrix X may be corrupted by a system noisy matrix Z. For example  if Xij = 4.8
for i âˆˆ [m]  then  it is acceptable that user Ui gives item Ij score 5 or 4.6. In this paper  we consider
the independent Gaussian noise  i.e.  Z = (Zij)mÃ—n where each element Zij is drawn i.i.d. from the
Gaussian distribution N (0  Ïƒ) with parameter Ïƒ.
Let M be the observed rating matrix. We deï¬ne the unorganized malicious attacks formally as
follows: for every j âˆˆ [n]  we have |U j| < Î³ with U j = {Ui|i âˆˆ [m] & |Mij âˆ’ Xij| â‰¥ }. The
parameter  distinguishes malicious users from the normal  and parameter Î³ limits the number of
user proï¬les attacking one item. Intuitively  unorganized malicious attacks consider that attackers
individually use a small number of user proï¬les to attack their own targets  and multiple independent
shilling attacks can be regarded as an example of unorganized malicious attacks if each shilling attack
contains a small number of attack proï¬les.
It is necessary to distinguish unorganized malicious attacks from noise. Generally speaking  user Ui
gives item Ij a normal score if |Mij âˆ’ Xij| is very small  while user Ui makes an attack to item Ij if
|Mij âˆ’ Xij| â‰¥ . For example  if the ground-truth score of item Ij is 4.8 for user Ui  then user Ui
makes a noisy rating by giving Ij score 5  yet makes an attack by giving Ij score âˆ’3. Therefore  we
assume that (cid:107)Z(cid:107)F â‰¤ Î´  where Î´ is a small parameter.
Let Y = M âˆ’ X âˆ’ Z = (Yij)mÃ—n be the malicious-attack matrix. Then  Yij = 0 if user Ui does
not attack item Ij; otherwise |Yij| â‰¥ . We assume that Y is a sparse matrix  whose intuition lies in
the small ratio of malicious ratings to all the ratings. Notice that we can not directly recover X and
Y from M because such recovery is an NP-Hard problem [9]. We consider the optimization problem
as follows:

(cid:107)X(cid:107)âˆ— + Ï„(cid:107)Y (cid:107)1 âˆ’ Î±(cid:104)M  Y (cid:105) +
min
X Y Z
s.t. X + Y + Z = M  (cid:107)Z(cid:107)F â‰¤ Î´.

(cid:107)Y (cid:107)2

F

Îº
2

(1)

Here (cid:107)X(cid:107)âˆ— acts as a convex surrogate of the rank function to pursue the low-rank part. (cid:107)Y (cid:107)1 is
used to induce the sparse attack part. The term (cid:104)M  Y (cid:105) is introduced to better distinguish Y and Z 
since the malicious rating bias Yij and the observed rating Mij have the same sign  i.e.  MijYij > 0 
while each entry in Z is small and ZijMij can be either positive or negative. We have Yij < 0 and
Mij < 0 if it is a nuke attack; we also have Yij > 0 and Mij > 0 if it is a push attack. So the term
(cid:104)M  Y (cid:105) distinguishes Y from Z. (cid:107)Y (cid:107)2
F is another strongly convex regularizer for Y . This term also
guarantees the optimal solution. Ï„  Î± and Îº are tradeoff parameters.
In many real applications  we can not get the full matrix M  and partial entries can be observed. Let
â„¦ âˆˆ [m] Ã— [n] be the set of observed entries. We deï¬ne an orthogonal projection Pâ„¦ onto the linear
space of matrices supported on â„¦ âŠ‚ [m] Ã— [n]  i.e. 

for (i  j) âˆˆ â„¦ 
otherwise.

(cid:26) Mij

0

Pâ„¦M =

The optimization framework for unorganized malicious attack detection can be formulated as follows.

(cid:107)X(cid:107)âˆ— + Ï„(cid:107)Y (cid:107)1 âˆ’ Î±(cid:104) Â¯M   Y (cid:105) +

min
X Y Z
s.t. X + Y + Z = Â¯M   Z âˆˆ B  B := {Z|(cid:107)Pâ„¦(Z)(cid:107)F â‰¤ Î´} 

Îº
2

(cid:107)Y (cid:107)2

F

(2)

where Îº > 0 and Â¯M := Pâ„¦(M ). This formulation degenerates into robust PCA as Îº â†’ 0 and Î± â†’ 0.
There have been many studies focusing on recovering low-rank part X from complete or incomplete
matrix [9  11  21  27]  while we distinguish the sparse attack term Y from the small perturbation term
Z. (cid:104) Â¯M   Y (cid:105) is added to ï¬nd nonzero entries of Y   and this yields better detection performance.

4 The Proposed Approach

In this section  we propose an alternating splitting augmented Lagrangian method to solve the
optimization problem (2)  which can be guaranteed with global convergence.

4

Algorithm 1 The UMA Algorithm
Input: matrix M and parameters Ï„  Î±  Î²  Î´ and Îº.
Output: Label vector [y1  . . .   ym] where yi = 1 if user Ui is a malicious user; otherwise yi = 0.
Initialize: Y 0 = X 0 = Î›0 = 0  yi = 0 (i = 1  . . .   m)  k = 0
Process:
1: while not converged do
2:
3:
4:
5: end while
6: if max(|Yi :|) > 0  then yi = 1 (i = 1  . . .   m).

Compute Z k+1  X k+1 and Y k+1 by Eq. (4)  (5) and (6)  respectively.
Update the Lagrange multiplier Î›k+1 by Î›k âˆ’ Î²(X k+1 + Y k+1 + Z k+1 âˆ’ Â¯M ).
k = k + 1.

The separable structure emerging in the objective function and constrains in Eq. (2) motivates us to
derive an efï¬cient algorithm by splitting the optimization problem. However  it is rather difï¬cult
to optimize this problem with theoretical guarantee  because this optimization involves three-block
variables. It is well-known that the direct extension of the alternating direction method of multipliers
may not be convergent for solving Eq. (2)  a three-block convex minimization problem [10  15  32].
We propose an alternating splitting augmented Lagrangian method to decompose the optimization of
Eq. (2) into three sub-optimizations for the solutions of Z k+1  X k+1 and Y k+1 separately. We will
provide global convergence guarantee with a worst-case O(1/t) convergence rate in Section 5.
We ï¬rst get the augmented Lagrangian function of Eq. (2) as
LA(X  Y  Z  Î›  Î²) := (cid:107)X(cid:107)âˆ— + Ï„(cid:107)Y (cid:107)1 âˆ’ Î±(cid:104) Â¯M   Y (cid:105) +

F âˆ’ (cid:104)Î›  L(cid:105) +

(cid:107)Y (cid:107)2

(3)

(cid:107)L(cid:107)2
F  

Î²
2

Îº
2

where L = X + Y + Z âˆ’ Â¯M and Î² is a positive constant.
Given (X k  Y k  Î›k)  we update Z k+1 with the closed-form solution

(cid:26) min{1  Î´/(cid:107)Pâ„¦N(cid:107)F}Nij

Z k+1

ij =

Nij

if (i  j) âˆˆ â„¦ 
otherwise 

(4)

where N = 1

Î² Î›k + Â¯M âˆ’ X k âˆ’ Y k. Lemma 2 gives the closed solution of X k+1 as

X k+1 = D1/Î²( Â¯M +

Î›k âˆ’ Y k âˆ’ Z k+1) 

(5)
where the nuclear-norm-involved shrinkage operator D1/Î² is deï¬ned in Lemma 2. Further  we update
Y k+1 and Lemma 1 gives the closed solution Y k+1 as

Y k+1 = SÏ„ Ï…(

Î± + Î²

Â¯M +

Î›k âˆ’ Z k+1 âˆ’ X k+1)Ï…Î² 

(6)

Î²

where Ï… = 1/(Î² + Îº) and the shrinkage operator SÏ„ Ï… is deï¬ned in Lemma 1. Finally  we update

1
Î²

1
Î²

Î›k+1 = Î›k âˆ’ Î²(X k+1 + Y k+1 + Z k+1 âˆ’ Â¯M ).

The pseudocode of the UMA algorithm is given in Algorithm 1.

5 Theoretical Analysis

This section presents our main theoretical results  whose detailed proofs and analysis are given in the
supplement document due to the page limitation. We begin with two helpful lemmas for the deviation
of our proposed algorithm as follows.
Lemma 1 [6] For Ï„ > 0 and T âˆˆ RmÃ—n  the closed solution of minY Ï„(cid:107)Y (cid:107)1 + (cid:107)Y âˆ’ T(cid:107)2
F /2 is
matrix SÏ„ (T ) with (SÏ„ (T ))ij = max{|Tij| âˆ’ Ï„  0} Â· sgn(Tij)  where sgn(Â·) means the sign function.
Lemma 2 [8] For Âµ > 0 and Y âˆˆ RmÃ—n with rank r  the closed solution of minX Âµ(cid:107)X(cid:107)âˆ— + (cid:107)X âˆ’
F /2 is given by DÂµ(Y ) = S diag(SÂµ(Î£))D(cid:62)  where Y = SÎ£D(cid:62) denotes the singular value
Y (cid:107)2
decomposition of Y   and SÂµ(Î£) is deï¬ned in Lemma 1.

5

Let X0 = SÎ£D(cid:62) =(cid:80)r

We now present theoretical guarantee that UMA can recover the low-rank component X0 and the
sparse component Y0. For simplicity  our theoretical analysis focuses on square matrix  and it is easy
to generalize our results to the general rectangular matrices.
i be the singular value decomposition of X0 âˆˆ RnÃ—n  where r
is the rank of matrix X0  and Ïƒ1  . . .   Ïƒr are the positive singular values  and S = [s1  . . .   sr] and
D = [d1  . . .   dr] are the left- and right-singular matrices  respectively. For Âµ > 0  we assume

i=1 Ïƒisid(cid:62)

(cid:107)S(cid:62)ei(cid:107)2 â‰¤ Âµr/n  max

i

max

i

(cid:107)D(cid:62)ei(cid:107)2 â‰¤ Âµr/n  (cid:107)SD(cid:62)(cid:107)2âˆ â‰¤ Âµr/n2.

(7)

Theorem 1 Suppose that X0 satisï¬es the incoherence condition given by Eq. (7)  and â„¦ is uniformly
distributed among all sets of size Ï‰ â‰¥ n2/10. We assume that each entry is corrupted independently
âˆš
with probability q. Let X and Y be the solution of optimization problem given by Eq. (2) with
parameter Ï„ = O(1/
n) and Î± = O(1/n). For some constant c > 0 and
sufï¬ciently large n  the following holds with probability at least 1 âˆ’ cnâˆ’10 

âˆš
n)   Îº = O(1/

(cid:107)X0 âˆ’ X(cid:107)F â‰¤ Î´ and (cid:107)Y0 âˆ’ Y (cid:107)F â‰¤ Î´

if rank(X0) â‰¤ Ïrn/Âµ/log2n and q â‰¤ qs  where Ïr and qs are positive constants.
We now prove the global convergence of UMA with a worst-case O(1/t) convergence rate measured
by iteration complexity. Let U = (Z; X; Y ) and W = (Z; X; Y ; Î›). We also deï¬ne

(cid:88)t

Î¸(U ) = (cid:107)X(cid:107)âˆ— + Ï„(cid:107)Y (cid:107)1 âˆ’ Î±(cid:104)M  Y (cid:105) +

Îº
2

(cid:107)Y (cid:107)2

F and U k+1

t

=

1
t

U k+1.

k=1

It follows from Corollaries 28.2.2 and 28.3.1 of [29] that the solution set of Eq. (2) is non-empty.
Then  let W âˆ— = ((Zâˆ—)(cid:62)  (Xâˆ—)(cid:62)  (Y âˆ—)(cid:62)  (Î›âˆ—)(cid:62))(cid:62) be a saddle point of Eq. (2)  and deï¬ne Uâˆ— =
((Zâˆ—)(cid:62)  (Xâˆ—)(cid:62)  (Y âˆ—)(cid:62))(cid:62).

Theorem 2 For t iterations generated by UMA with Î² âˆˆ(cid:0)0  (

33 âˆ’ 5)Îº/2(cid:1) 

âˆš

1) We have (cid:107)X k+1
2) We have |Î¸(U k+1

t + Y k+1
t

t

+ Z k+1

t âˆ’ Pâ„¦M(cid:107)2 â‰¤ Â¯c1/t2 for some constant Â¯c1 > 0.

) âˆ’ Î¸(Uâˆ—)| â‰¤ Â¯c2/t for some constant Â¯c2 > 0.

6 Experiments

In this section  we compare our proposed UMA with the state-of-the-art approaches for attack
detection. We consider three common evaluating metrics for attack detection as in [13]:

Precision =

TP

TP + FP

  Recall =

TP

TP + FN

  F1 =

2 Ã— Precision Ã— Recall
Precision + Recall

where TP is the number of attack proï¬les correctly detected as attacks  FP is the number of normal
proï¬les that are misclassiï¬ed  and FN is the number of attack proï¬les that are misclassiï¬ed.

6.1 Datasets

We ï¬rst conduct our experiments on the common-used datasets MovieLens100K and MovieLens1M 
released by GroupLens [25]. These datasets are collected from a non-commercial recommender
system  and it is more likely that the users in this dataset are non-spam users. We take the users
already in the datasets as normal users. The rating scores range from 1 to 5  and we preprocess the
data by minus 3 to the range [âˆ’2  2]. Dataset MovieLens100K contains 100000 ratings of 943 users
over 1682 movies  and dataset MovieLens1M contains 1000209 ratings of 6040 users over 3706
movies. We describe how to add attack proï¬les in Section 6.3.
We also collect a real dataset Douban10K1 with attack proï¬les from Douban website  where
registered users record rating information over various ï¬lms  books  clothes  etc. We gather 12095
ratings of 213 users over 155 items. The rating scores range from 1 to 5  and we preprocess the data
by minus 3 to the range [âˆ’2  2]. Among the 213 user proï¬les  35 proï¬les are attack proï¬les.

1http://www.douban.com/.

6

Table 1: Detection precision  recall and F1 on MovieLens100K and MovieLens1M. Here unorga-
nized malicious attacks are based on a combination of traditional strategies.

UMA
RPCA
N-P

k-means
PCAVarSel
MF-based

Precision
0.934Â±0.003
0.908Â±0.010
0.774Â±0.015
0.723Â±0.171
0.774Â±0.009
0.911Â±0.009

MovieLens100K

Recall

0.883Â±0.019
0.422Â±0.048
0.641Â±0.046
0.224Â±0.067
0.587Â±0.024
0.814Â±0.008

F1

0.908Â±0.011
0.575Â±0.047
0.701Â±0.032
0.341Â±0.092
0.668Â±0.019
0.860Â±0.009

Precision
0.739Â±0.009
0.342Â±0.003
0.711Â±0.007
0.000Â±0.000
0.278Â±0.007
0.407Â±0.005

MovieLens1M

Recall

0.785Â±0.023
0.558Â±0.028
0.478Â±0.018
0.000Â±0.000
0.622Â±0.022
0.365Â±0.004

F1

0.761Â±0.016
0.424Â±0.009
0.572Â±0.014
0.000Â±0.000
0.384Â±0.011
0.385Â±0.005

Table 2: Detection precision  recall and F1 on MovieLens100K and MovieLens1M. Here unorga-
nized malicious attacks consider the hire of existing users in addition to combination.
MovieLens1M

MovieLens100K

Precision
0.929Â±0.013
0.797Â±0.046
0.244Â±0.124
0.767Â±0.029
0.481Â±0.027
0.556Â±0.023

Recall

0.865Â±0.032
0.659Â±0.097
0.145Â±0.089
0.234Â±0.042
0.168Â±0.017
0.496Â±0.021

F1

0.896Â±0.022
0.721Â±0.097
0.172Â±0.084
0.357Â±0.051
0.248Â±0.023
0.524Â±0.022

Precision
0.857Â±0.005
0.635Â±0.012
0.273Â±0.020
0.396Â±0.026
0.120Â±0.006
0.294Â±0.012

Recall

0.733Â±0.003
0.391Â±0.022
0.099Â±0.031
0.300Â±0.039
0.225Â±0.012
0.264Â±0.010

F1

0.790Â±0.002
0.484Â±0.015
0.144Â±0.035
0.341Â±0.035
0.157Â±0.008
0.278Â±0.011

UMA
RPCA
N-P

k-means
PCAVarSel
MF-based

6.2 Comparison Methods and Implementation Details

We compare UMA with the state-of-the-art approaches for attack detection and robust PCA:

â€¢ N-P: A statistical algorithm based on the Neyman-Pearson statistics [16].
â€¢ k-means: A cluster algorithm based on classiï¬cation attributes [3].
â€¢ PCAVarSel: A PCA-based variable selection algorithm [22].
â€¢ MF-based: A reputation estimation algorithm based on low-rank matrix factorization [19].
â€¢ RPCA: A low-rank matrix recovery method by considering sparse noise [9].

m  Î± = 10/m and Î´ =(cid:112)mn/200. A rating can be viewed

In the experiments  we set Ï„ = 10/
as a malicious rating if it deviates from the ground-truth rating by more than 3  since the scale of
ratings is from -2 to 2. We set parameter Î² = Ï„ /3 according to Eq. (6) where the entries of Y will
be nulliï¬ed if they are smaller than the threshold. We set Îº = Ï„ under the convergence condition
Î² âˆˆ (0  (
33 âˆ’ 5)Îº/2) as in Theorem 2. For the baseline methods  we take the results reported
in [26] for comparison.

âˆš

âˆš

6.3 Comparison Results

In the ï¬rst experiment  we add attack proï¬les into the datasets MovieLens100K and MovieLens1M
by a combination of several traditional attack strategies. These traditional attack strategies include
average attack strategy  random attack strategy and bandwagon attack strategy  discussed in Sec-
tion 3.2. Speciï¬cally  each attacker randomly chooses one strategy to produce the user rating proï¬les
and promotes one item randomly selected from items with average rating lower than 0. In line with
the setting of previous attack detection works  we set the ï¬ller ratio (percentage of rated items in
total items) as 0.01 and the ï¬ller items are drawn from the top 10% most popular items. We set
the spam ratio (number of attack proï¬les/number of all user proï¬les) as 0.2. The experiment is
repeated 10 times  and the average performance is reported. Table 1 shows the experimental results
on datasets MovieLens100K and MovieLens1M under the attack proï¬les of a combination of
traditional strategies.
The second experiment studies a more general case of unorganized malicious attacks. We consider
that attackers can hire existing users to attack their targets  in addition to the proï¬le injection attacks
as mentioned above. We set spam ratio as 0.2  where 25% of the attack proï¬les are produced similar
to the ï¬rst experiment  and 75% of the attack proï¬les are from existing users by randomly changing
the rating of one item lower than 0 to +2. In this case  attacks are more difï¬cult to be detected 
because the attack proï¬les are more similar to normal user proï¬les. The experiment is repeated 10
times and Table 2 demonstrates the comparison results on MovieLens100K and MovieLens1M.

7

Table 3: Detection precision  recall and F1 on dataset Douban10K.

Methods UMA RPCA
0.535
Precision
0.472
Recall
0.502

0.800
0.914
0.853

F1

N-P
0.250
0.200
0.222

k-means
0.321
0.514
0.396

PCAVarSel MF-based

0.240
0.343
0.282

0.767
0.657
0.708

Table 3 shows the experiments on dataset Douban10K. The experimental results in Table 1  2 and 3
show that our proposed algorithm UMA achieves the best performance on all the datasets and three
measures: Precision  Recall and F1.
Traditional attack detection approaches perform ineffectively on unorganized malicious attacks
detection  because the success of those methods depends on the properties of shilling attacks  e.g.  k-
means method and N-P method work well if the attack proï¬les are similar in the view of classiï¬cation
attributes or latent categories  and PCAVarSel method achieves good performance only if attack
proï¬les have more common unrated items than normal proï¬les. In summary  these methods detect
attacks by identifying some common characteristics of attack proï¬les  while these do not hold in
unorganized malicious attacks. The RPCA and MF-based methods try to ï¬nd the ground-truth rating
matrix from the observed rating matrix  whereas they hardly separate the sparse attack matrix from
the noisy matrix and tend to suffer from low precision  especially on large-scale and heavily sparse
dataset MovieLens1M.
We compare UMA with other approaches by varying the spam ratio from 2% to 20% since different
systems may contain different spam ratios (# attack proï¬les/# all user proï¬les). As can be shown
in Figure 2  UMA is robust and achieves the best performance in different spam ratios  whereas the
comparison methods (except the RPCA method) achieve worse performance for small spam ratio 
e.g.  the N-P approach detects almost nothing. Although the RPCA method is as stable as UMA in
different spam ratios  there is a performance gap between RPCA and UMA which becomes bigger
when the dataset gets larger and sparser from MovieLens100K to MovieLens1M.

Figure 2: Detection precision and recall on MovieLens100K under unorganized malicious attacks.
The spam ratio (# attack proï¬les/# all user proï¬les) varies from 0.02 to 0.2.

7 Conclusion

Attack detection plays an important role to improve the quality of recommendation. Most previous
methods focus on shilling attacks  and the key idea for detecting such attacks is to ï¬nd the common
characteristics of attack proï¬les with the same attack strategy. This paper considers the unorganized
malicious attacks  produced by multiple attack strategies to attack different targets. We formulate
unorganized malicious attacks detection as a variant of matrix completion problem  and we propose
the UMA algorithm and prove its recovery guarantee and global convergence. Experiments show that
UMA achieves signiï¬cantly better performance than the state-of-the-art methods for attack detection.
Acknowledgments This research was supported by the National Key R&D Program of China
(2018YFB1004300)  NSFC (61333014  61503179)  JiangsuSF (BK20150586)  and Collaborative
Innovation Center of Novel Software Technology and Industrialization  and Fundamental Research
Funds for the Central Universities.

8

References
[1] C. Aggarwal. Recommender Systems. Springer  2016.

[2] R. Bhaumik  C. Williams  B. Mobasher  and R. Burke. Securing collaborative ï¬ltering against
malicious attacks through anomaly detection. In Proceedings of the 4th Workshop on Intelligent
Techniques for Web Personalization  2006.

[3] R. Bhaumik  B. Mobasher  and R. D. Burke. A clustering approach to unsupervised attack detec-
tion in collaborative recommender systems. In Proceedings of the 7th International Conference
on Data Mining  pages 181â€“187  2011.

[4] T. Bouwmans  A. Sobral  S. Javed  S. K. Jung  and E.-H. Zahzah. Decomposition into low-
rank plus additive matrices for background/foreground separation: A review for a comparative
evaluation with a large-scale dataset. Computer Science Review  23:1â€“71  2017.

[5] G. Bresler  G. Chen  and D. Shah. A latent source model for online collaborative ï¬ltering. In
Proceedings of the 28th Advances in Neural Information Processing Systems  pages 3347â€“3355 
2014.

[6] A. M. Bruckstein  D. L. Donoho  and M. Elad. From sparse solutions of systems of equations to

sparse modeling of signals and images. SIAM Review  51(1):34â€“81  2009.

[7] K. Bryan  M. Oâ€™Mahony  and P. Cunningham. Unsupervised retrieval of attack proï¬les in
collaborative recommender systems. In Proceedings of the 2nd ACM Conference on Recommender
Systems  pages 155â€“162  2008.

[8] J.-F. Cai  E. J. CandÃ¨s  and Z.-W. Shen. A singular value thresholding algorithm for matrix

completion. SIAM Journal on Optimization  20(4):1956â€“1982  2010.

[9] E. J. CandÃ¨s  X. D. Li  Y. Ma  and J. Wright. Robust principal component analysis? Journal of

the ACM  58(3):1â€“37  2011.

[10] C.-H. Chen  B.-S. He  Y.-Y. Ye  and X.-M. Yuan. The direct extension of ADMM for multi-
block convex minimization problems is not necessarily convergent. Mathematical Programming 
155(1-2):57â€“79  2016.

[11] J.-S. Feng  H. Xu  and S.-C. Yan. Online robust PCA via stochastic optimization. In Proceedings

of the 27th Advances in Neural Information Processing Systems  pages 404â€“412  2013.

[12] D. Goldberg  D. Nichols  B. M. Oki  and D. Terry. Using collaborative ï¬ltering to weave an

information tapestry. Communications of the ACM  35(12):61â€“70  1992.

[13] I. Gunes  C. Kaleli  A. Bilge  and H. Polat. Shilling attacks against recommender systems: a

comprehensive survey. Artiï¬cial Intelligence Review  42(4):767â€“799  2014.

[14] F.-M. He  X.-R. Wang  and B.-X. Liu. Attack detection by rough set theory in recommendation
In Proceedings of the 6th International Conference on Granular Computing  pages

system.
692â€“695  2010.

[15] B.-S. He  M. Tao  and X.-M. Yuan. A splitting method for separable convex programming. IMA

Journal of Numerical Analysis  35(1):394â€“426  2015.

[16] N. J. Hurley  Z. P. Cheng  and M. Zhang. Statistical attack detection. In Proceedings of the 3rd

ACM Conference on Recommender Systems  pages 149â€“156  2009.

[17] C. Li and Z.-G. Luo. Detection of shilling attacks in collaborative ï¬ltering recommender
systems. In Proceedings of the 2nd International Conference of Soft Computing and Pattern
Recognition  pages 190â€“193  2011.

[18] B. Li  Q. Yang  and X.-Y. Xue. Transfer learning for collaborative ï¬ltering via a rating-matrix
generative model. In Proceedings of the 26th International Conference on Machine Learning 
pages 617â€“624  2009.

9

[19] G. Ling  I. King  and M. R. Lyu. A uniï¬ed framework for reputation estimation in online rating
systems. In Proceedings of the 23rd International Joint Conference on Artiï¬cial Intelligence 
pages 2670â€“2676  2013.

[20] M. Luca. Reviews  reputation  and revenue: The case of Yelp.com. 2016.

[21] L. W. Mackey  M. I. Jordan  and A. Talwalkar. Divide-and-conquer matrix factorization. In
Proceedings of the 25th Advances in Neural Information Processing Systems  pages 1134â€“1142 
2011.

[22] B. Mehta and W. Nejdl. Unsupervised strategies for shilling detection and robust collaborative

ï¬ltering. User Modeling and User-Adapted Interaction  19(1-2):65â€“97  2009.

[23] B. Mehta. Unsupervised shilling detection for collaborative ï¬ltering. In Proceedings of the

22nd International Conference on Artiï¬cial Intelligence  pages 1402â€“1407  2007.

[24] B. Mobasher  R. Burke  R. Bhaumik  and J. J. Sandvig. Attacks and remedies in collaborative

recommendation. Intelligent Systems  22(3):56â€“63  2009.

[25] Research Grouplens. http://grouplens.org/datasets/movielens/.

[26] M. Pang and Z.-H. Zhou. Unorganized malicious attacks detection (in Chinese). SCIENTIA

SINICA Informationis  48(2):177â€“186  2018.

[27] Y.-G. Peng  A. Ganesh  J. Wright  W.-L. Xu  and Y. Ma. Rasl: Robust alignment by sparse and
low-rank decomposition for linearly correlated images. Pattern Analysis and Machine Intelligence 
34(11):2233â€“2246  2012.

[28] N. Rao  H.-F. Yu  P. Ravikumar  and I. Dhillon. Collaborative ï¬ltering with graph information:
Consistency and scalable methods. In Proceedings of the 29th Advances in Neural Information
Processing Systems  pages 2098â€“2106  2015.

[29] R. T. Rockafellar. Convex Analysis. Princeton University Press  2015.

[30] R. Salakhutdinov and A. Mnih. Probabilistic matrix factorization. In Proceedings of the 22nd

Advances in Neural Information Processing Systems  pages 1257â€“1264  2008.

[31] R. Salakhutdinov  A. Mnih  and G. Hinton. Restricted boltzmann machines for collaborative
In Proceedings of the 24th International Conference on Machine Learning  pages

ï¬ltering.
791â€“798  2007.

[32] M. Tao and X.-M. Yuan. Recovering low-rank and sparse components of matrices from

incomplete and noisy observations. SIAM Journal on Optimization  21(1):57â€“81  2011.

[33] X.-Y. Yi  D. Park  Y.-D. Chen  and C. Caramanis. Fast algorithms for robust PCA via gradient
descent. In Proceedings of the 30th Advances in neural information processing systems  pages
4152â€“4160  2016.

10

,Ming Pang
Wei Gao
Min Tao
Zhi-Hua Zhou