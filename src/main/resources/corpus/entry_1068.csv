2010,Computing Marginal Distributions over Continuous Markov Networks for Statistical Relational Learning,Continuous Markov random fields are a general formalism to model joint probability distributions over events with continuous outcomes. We prove that marginal computation for constrained continuous MRFs is #P-hard in general and present a polynomial-time approximation scheme under mild assumptions on the structure of the random field. Moreover  we introduce a sampling algorithm to compute marginal distributions and develop novel techniques to increase its efficiency. Continuous MRFs are a general purpose probabilistic modeling tool and we demonstrate how they can be applied to statistical relational learning. On the problem of collective classification  we evaluate our algorithm and show that the standard deviation of marginals serves as a useful measure of confidence.,Computing Marginal Distributions over Continuous
Markov Networks for Statistical Relational Learning

Matthias Br¨ocheler  Lise Getoor
University of Maryland  College Park

College Park  MD 20742

{matthias  getoor}@cs.umd.edu

Abstract

Continuous Markov random ﬁelds are a general formalism to model joint proba-
bility distributions over events with continuous outcomes. We prove that marginal
computation for constrained continuous MRFs is #P-hard in general and present
a polynomial-time approximation scheme under mild assumptions on the struc-
ture of the random ﬁeld. Moreover  we introduce a sampling algorithm to com-
pute marginal distributions and develop novel techniques to increase its efﬁ-
ciency. Continuous MRFs are a general purpose probabilistic modeling tool and
we demonstrate how they can be applied to statistical relational learning. On the
problem of collective classiﬁcation  we evaluate our algorithm and show that the
standard deviation of marginals serves as a useful measure of conﬁdence.

Introduction

1
Continuous Markov random ﬁelds are a general and expressive formalism to model complex prob-
ability distributions over multiple continuous random variables. Potential functions  which map
the values of sets (cliques) of random variables to real numbers  capture the dependencies be-
tween variables and induce a exponential family density function as follows: Given a ﬁnite set
of n random variables X = {X1  . . .   Xn} with an associated bounded interval domain Di ⊂ R 
let φ = {φ1  . . .   φm} be a ﬁnite set of m continuous potential functions deﬁned over the interval
domains  i.e. φj : D → [0  M ]  for some bound M ∈ R+  where D = D1 × D2 . . . × Dn. For
a set of free parameters Λ = {λ1  . . .   λm}  we then deﬁne the probability measure P over X with
respect to φ through its density function f as:

(cid:90)

− m(cid:88)

j=1

 dx

exp[− m(cid:88)

f (x) =

1

Z(Λ)

λjφj(x)]

; Z(Λ) =

exp

j=1

D

λjφj(x)

(1)

where Z is the normalization constant. The deﬁnition is analogous to the popular discrete Markov
random ﬁelds (MRF) but using integration over the bounded domain rather than summation for the
partition function Z.
In addition  we assume the existence of a set of kA equality and kB inequality constraints on the
random variables  that is  A(x) = a  where A : D → RkA  a ∈ RkA and B(x) ≤ b  where
B : D → RkB   b ∈ RkB . Both equality and inequality constraints restrict the possible combinations
of values the random variables X can assume. That is  we set f (x) = 0 whenever any of the
constraints are violated and constrain the domain of integration  denoted ˜D  for the normalization
constant correspondingly. Constraints are useful in probabilistic modeling to exclude inconsistent
outcomes based on prior knowledge about the distribution. We call this class of MRFs constrained
continuous Markov random ﬁelds (CCMRF).
Probabilistic inference often requires the computation of marginal distributions for all or a subset of
the random variables X. Marginal computation for discrete MRFs has been extensively studied due
to its wide applicability in probabilistic reasoning. In this work  we study the theoretical and practi-
cal aspects of computing marginal density functions over CCMRFs. General continuous MRFs can

1

λ1 : A.text ∼= B.text ˜∧ class(A  C) ˜⇒ class(B  C)
λ2 : link(A  B) ˜∧ class(A  C) ˜⇒ class(B  C)
Constraint : f unctional(class)

Table 1: Example PSL program for collective classiﬁcation.

be used in a variety of probabilistic modeling scenarios and have been studied for applications with
continuous domains such as computer vision. Gaussian Random Fields are a type of continuous
MRF which assume normality. In this work  we make no restrictive assumptions about the marginal
distributions other than boundedness. For general continuous MRFs  non-parametric belief propa-
gation (NBP) [1] has been proposed as a method to estimate marginals. NBP represents the “belief”
as a combination of kernel densities which are propagated according to the structure of the MRF. In
contrast to NBP  our approach provides polynomial-time approximation guarantees and avoids the
representational choice of kernel densities.
The main contributions of this work are described in Section 3. We begin by showing that computing
marginals in CCMRFs is #P-hard in the number of random variables n. We then discuss a Markov
chain Monte Carlo (MCMC) sampling scheme that can approximate the exact distribution to within
 error in polynomial time under the general assumption that the potential functions and inequality
constraints are convex. Based on this result  we propose a tractable sampling algorithm and present
a novel approach to increasing its effectiveness by detecting and counteracting slow convergence.
Our theoretical results are based on recent advances in computational geometry and the study of log-
concave functions [2]. In Section 4  we investigate the performance  scalability  and convergence
of the sampling algorithm on the probabilistic inference problem of collective classiﬁcation on a set
of Wikipedia documents. In particular  we show that the standard deviation of the marginal density
function can serve as a strong indicator for the “conﬁdence” in the classiﬁcation prediction  thereby
demonstrating a useful qualitative aspect of marginals over continuous MRFs. Before turning to the
main contributions of the paper  in the next section  we give background motivation for the form of
CCMRFs we study.
2 Motivation
Our treatment of CCMRFs is motivated by probabilistic similarity logic (PSL) [3]. PSL is a rela-
tional language that provides support for probabilistic reasoning about similarities. PSL is similar to
existing SRL models  e.g.  MLNs [4]  BLPs [5]  RMNs [6]  in that it deﬁnes a probabilistic graph-
ical model over the properties and relations of the entities in a domain as a grounding of a set of
rules that have attached parameters. However  PSL supports reasoning about “soft” truth values 
which can be seen as similarities between entities or sets of entities  degrees of belief  or strength
of relationships. PSL uses annotated logic rules to capture the dependency structure of the domain 
based on which it builds a joint continuous probabilistic model over all decision atoms which can be
expressed as a CCMRF as deﬁned above. PSL has been used to reason about the similarity between
concepts from different ontologies as well as articles from Wikipedia. Table 1 shows a simple PSL
program for collective classiﬁcation. The ﬁrst rule states that documents with similar text are likely
to have the same class. The second rule says that two documents which are linked to each other
are also likely to be assigned the same class. Finally  we express the constraint that each document
can have at most one class  that is  the class predicate is functional and can only map to one value.
Such domain speciﬁc constraints motivate our introduction of equality and inequality constraints
for CCMRFs. Rules and constraints are written in ﬁrst order logic formalism and are grounded out
against the observed data such that each ground rule constitutes one potential function or constraint
computing the truth value of the formula. Rules have an associated weight λi which is used as the
parameter for each associated potential function. The weights can be learned from training data.
In the following  we make some assumptions about the nature of the constraints and the potential
functions motivated by the requirements of the PSL framework and the types of CCMRFs modeled
therein. Firstly  we assume all domains are in the [0  1] interval which corresponds to the domain
of similarity truth values in PSL. Secondly  all constraints are assumed to be linear. Thirdly  the
potential functions φj are of the form φj(x) = max(0  oj·x+qj) where oT
j ∈ Rn is a n-dimensional
row vector and qj ∈ R. The particular form of the potential functions is motivated by the way
similarity truth values are combined in PSL using t-norms (see [3] for details).
While the techniques presented in this work are not speciﬁc to PSL  a brief outline of the PSL frame-
work helps in understanding the assumptions about the CCMRFs of interest made in our algorithm
and experiments. In Section 3.5 we show how our assumptions can be relaxed while maintaining
polynomial-time guarantees for applications outside the PSL framework.

2

a) Example of geometric marginal computation

b) Hit-and-Run and random ball walk illustration

3 Computing continuous marginals
This section contains the main technical contributions of this paper. We start our study of marginal
computation for CCMRFs by proving that computing the exact density function is #P hard (3.1).
In Section 3.2  we discuss how to approximate the marginal distribution using a MCMC sampling
scheme which produces a guaranteed -approximation in polynomial time under suitable conditions.
We show how to improve the sampling scheme by detecting phases of slow convergence and present
a technique to counteract them (3.3). Finally  we describe an algorithm based on the sampling
scheme and its improvements (3.4). In addition  we discuss how to relax the linearity conditions in
Section 3.5.
Throughout this discussion we use the following simple example for illustration:
Example 1 Let X = {X1  X2  X3} be subject to the inequality constraint x1 + x3 ≤ 1. Let
φ1(x) = x1  φ2(x) = max(0  x1 − x2)  φ3(x) = max(0  x2 − x3) where λ = (1  2  1) are the
associated free parameters.

3.1 Exact marginal computation
Theorem 1 Computing the marginal probability density function

fX(cid:48)(x(cid:48)) =(cid:82)

y∈× ˜Di s.t.Xi /∈X(cid:48) f (x(cid:48)  y)dy for a subset X(cid:48) ⊂ X under a probability measure P deﬁned

by a CCMRF is #P hard in the worst case.

We prove this statement by a simple reduction from the problem of computing the volume of a
n-dimensional polytope deﬁned by linear inequality constraints. To see the relationship to computa-
tional geometry  note that the domain D is a n-dimensional unit hypercube1. Each linear inequality
constraints Bi from the system B can be represented by a hyperplane which “cuts off” part of the
hypercube D. Finally  the potential functions induce a probability distribution over the resulting
convex polytope. Figure 3a) visualizes the domain for our running example in the 3-dimensional
Euclidean space. The constraint domain is shown as a wedge. The highlighted area marks the region
of probability mass that is equal to the probability P(0.4 ≤ X2 ≤ 0.6).
Proof 1 (Sketch) For any random variable X ∈ X  the marginal probability P(l ≤ X ≤ u)
under the uniform probability distribution deﬁned by a single potential function φ = 0 corresponds
to the volume of the “slice” deﬁned by the bounds u < l ∈ [0  1] relative to the volume of the
entire polytope. In [7] it was shown that computing the volume of such slices is at least as hard as
computing the volume of the entire polytope which is known to be #P-hard [8].

3.2 Approximate marginal computation and sampling scheme
Despite this hardness result  efﬁcient approximation algorithms for convex volume computation
based on MCMC techniques have been devised and yield polynomial-time approximation guaran-
tees. We will review the techniques and then relate them to our problem of marginal computation.
The ﬁrst provably polynomial-time approximation algorithm for volume computation was based on
“random ball-walks”. Starting from some initial point p inside the polytope  one samples from the
local density function of f restricted to the inside of a ball of radius r around the point p. If the
newly sampled point p(cid:48) lies inside the polytope  we move to p(cid:48)  otherwise we stay at p and repeat
the sampling. If P is the uniform distribution (as typically chosen for volume computation)  the

1We ignore equality constraints for now until the discussion of the algorithm in Section 3.4

3

1 1 0 X1 X3 X2 P(0.4 ≤ X2 ≤ 0.6) 1 1 0 X1 X3 p p’ p p’ xMAP resulting Markov chain converges to P over the polytope in O∗(n3) steps assuming that the starting
distribution is not “too far” from P [9].2
More recently  the hit and run sampling scheme [10] was rediscovered which has the advantage that
no strong assumptions about the initial distribution need to be made. As in the random ball walk 
we start at some interior point p. Next  we generate a direction d (i.e.  n dimensional vector of
length 1) uniformly at random and compute the line segment l of the line p + αd that resides inside
the polytope. We then compute the distribution of P over the segment l  sample from it uniformly
at random and move to the new sample point p(cid:48) to repeat the process. For P being the uniform
distribution  the Markov chain also converges after O∗(n3) steps but for hit-and-run we only need to
assume that the starting point p does not lie on the boundary of the polytope [2]. In [7]  the authors
show that hit-and-run signiﬁcantly outperforms random ball walk sampling in practice  because it
(1) does not get easily stuck in corners since each sample is guaranteed to be drawn from inside
the polytope  (2) does not require parameter setting like the radius r which greatly inﬂuences the
performance of random ball walk. Figure 3 b) shows an iteration of the random ball walk and the
hit-and-run sampling schemes for our running example restricted to just two dimensions to simplify
the presentation. We can see that  depending on the radius of the ball  a signiﬁcant portion may not
intersect with the feasible region.
Lov´asz and Vempala[2] have proven a stronger result which shows that hit-and-run sampling con-
verges for general log-linear distributions. Based on their result  we get a polynomial-time approxi-
mation guarantee for distributions induced by CCMRFs as deﬁned above.
Theorem 2 The complexity of computing an approximate distribution σ∗ using the hit-and-
run sampling scheme such that the total variation distance of σ∗ and P is less than  is
tial distribution σ such that the density function dσ/dP is bounded by M except on a set S with
σ(S) ≤ /2.
Proof 2 (Sketch) Since A  B are linear  ˜D is an ˜n = n − kA dimensional convex polytope after
dimensionality reduction through A. By deﬁnition  f is from the exponential family and since all
factors are linear or maximums of linear functions  f is a log concave function (maximums and
sums of convex functions are convex). More speciﬁcally  f is a log concave and log piecewise linear
function. Let σs be the distribution of the current point after s steps of hit-and-run have been applied
to f starting from σ. Now  according to Theorem 1.3 from [2]  for s > 1030 n2R2
the total
r2
variation distance of σs and P is less than   where r is such that the level set of f of probability 1
contains a ball of radius r and R2 ≥ Ef (|x − zf|2)  where zf is the centroid of f.
Now  each hit-and-run step requires us to iterate over the random variable domain boundaries 
O(˜n)  compute intersections with the inequality constraints  O(˜nkB)  and integrate over the line
segment involving all factors  O(˜nm).

O∗(cid:0)˜n3(kB + ˜n + m)(cid:1)  where ˜n = n − kA  under the assumptions that we start from an ini-

8

ln5 M nR

r

Improved sampling scheme

3.3
Our proposed sampling algorithm is an implementation of the hit-and-run MCMC scheme. How-
ever  the theoretical treatment presented above leaves two questions unaddressed: 1) How do we get
the initial distribution σ? 2) The hit-and-run algorithm assumes that all sample points are strictly
inside the polytope and bounded away from its boundary. How can we get out of corners if we do
get stuck?
The theorem above assumes a suitable initial distribution σ  however  in practice  no such distribu-
tion is given. Lov´asz and Vempala also show that the hit-and-run scheme converges from a single
starting point on uniform distributions under the condition that it does not lie on the boundary and
at the expense of an additional factor of n in the number of steps to be taken (compare Theorem 1.1
and Corollary 1.2 in [2]). We follow this approach and use a MAP state xM AP of the distribution P
as the single starting point for the sampling algorithm. Choosing a MAP state as the starting point
has two advantages: 1) we are guaranteed that xM AP is an interior point and 2) it is the point with
the highest probability density and therefore highest probability mass in a small local neighborhood.
However  starting from a MAP state elevates the importance of the second question  since the MAP
state often lies exactly on the boundary of the polytope and therefore we are likely to start the
sampling algorithm from a vertex of the polytope. The problem with corner points p is that most of

2The O∗ notation ignores logarithmic and factors and dependence on other parameters like error bounds.

4

the directions sampled uniformly at random will lead to line segments of zero length and hence we
do not move between iterations. Let W be the subset of inequality constraints B that are “active” at
the corner point p and b the corresponding entries in b  i.e. W p = b (since all constraints are linear 
we abuse notation and consider B  W to be matrices). In other words  the hyperplanes corresponding
to the constraints in W intersect in p. Now  for all directions d ∈ Rn such that there exist active
constraints Wi  Wj with Wid < 0 and Wjd > 0  the line segment through p induced by d must
necessarily be 0. It also follows that more active constraints increase the likelihood of getting stuck
in a corner.
For example  in Figure 3 b) the point xM AP in the upper left hand corner denotes the MAP state
of the distribution deﬁned in our running example. If we generate a direction uniformly at random 
only 1/4 of those will be feasible  that is  for all other we won’t be able to move away from xM AP .
To avoid the problem of repeatedly sampling infeasible directions at corner points  we propose to
restrict the sampling of directions to feasible directions only when we determine that a corner point
has been reached. We deﬁne a corner point p as a point inside the polytope where the number of
active constraints is above some threshold θ.3 A direction d is feasible  if W d < 0. Assuming that
there are a active constraints at corner point p (i.e.  W has a rows) we sample each entry of the
a-dimensional vector z from −|N (0  1)| where N (0  1) is the standard Gaussian distribution with
zero mean and unit variance. Now  we try to ﬁnd directions d such that W d ≤ z.
A number of algorithms have been proposed to solve such systems of linear inequalities for feasible
points d. In our sampling algorithm we implement the relaxation method introduced by Agmon [11]
and Motzkin and Schoenberg [12] due to its simplicity. The relaxation method proceeds as follows:
We start with d0 = 0. At each iteration we check if W di ≤ z ; if so  we have found a solution
and terminate. If not  we choose the most “violated” inequality constraint Wk from W   i.e.  the row
vector Wk from W which maximizes Wkdi−zk

(cid:107)Wk(cid:107)   and update the direction 

di+1 = di + 2

zk − Wkdi
(cid:107)Wk(cid:107)2 W T

k

The relaxation method is guaranteed to terminate  since a feasible direction d always exists [12].

3.4 Sampling algorithm

Algorithm CCMRF Sampling
Input: CCMRF speciﬁed by RVs X with domains D = [0  1]n  equality constraints
Output: Marginal probability density histograms H[Xi] : [0  1] → R+ ∀Xi ∈ X

A(x) = a inequality constraints B(x) ≤ b  potential functions φ  parameters Λ

1
2
3
4
5
6
7
8
9

10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26

else

if A = ∅
P ← 1|X|
n(cid:48) ← n
r ← rank(A)
[U  Σ  V ] ← svd(A)
P ← V |columns: [r+1 n]
n(cid:48) ← n − r

x0 ← MAP(A(x) = a  B(x) ≤ b  φ)
cornered ← FALSE
for j = 0 to ρ
if cornered

d ← (cid:126)0
W ← B|rows:active × P
z ← zi = ∼ −|N (0  1)| ∀i = 1 . . . n(cid:48)
while ∃i : Wkd − zk > 0
v ← argmaxk
Wkd−zk
(cid:107)Wk(cid:107)
d = d + 2 zv−Wvd
(cid:107)Wv(cid:107)2 W T
cornered ← FALSE
else
d ← di = ∼ N (0  1) ∀i = 1 . . . n(cid:48)
d ← 1(cid:107)d(cid:107) d
d ← P × d
active ← ∅
αlow ← −∞  αhigh ← ∞
cd ← B × d ; cx ← B × xj

v

27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54

for i = 1 . . .|rows(B)|

if cdi (cid:54)= 0

cdi

a = bi−cxi
if cdi > 0 then αhigh ← min(αhigh  a)
if cdi < 0 then αlow ← max(αlow  a)
if a = 0 then active ← active ∪ {i}

if αhigh − αlow = 0 ∧ |active| > θ

cornered ← TRUE
continue

M ← map : [0  1] → R × R
for φi = max(0  oi · x + qi) ∈ φ

r ← λi(oi · d)
c ← λi(oi · xj + qi)
a ← −c/r
if r > 0 ∧ a < αhigh
else if r < 0 ∧ a > αlow

[rα  cα] ←(cid:80)
Σα ←(cid:80)

M (max(a  αlow)) ← M (max(a  αlow)) + [r  c]
M (αlow) ← M (αlow) + [r  c]
if a < αhigh then M (a) ← M (a) + [−r −c]
else M (αlow) ← M (αlow) + [0  c]

a≤α M (a)
a<b<α∧(cid:54)∃c:a<c<b

1
ra

e−ca(e−raa − e−rab)

s ← ∼ [0  Σαhigh]
a ← max{α ∈ M | Σα ≤ s}
α ← −1
xj+1 ← xj + αd
if j > ρ

(log (−sra + raΣa + e−ca−raa) + ca)
100 n(cid:48)3
H[i][xj+1

ra

] + 1 ∀i = 1 . . . n
Figure 1: Constrained continuous MRF sampling algorithm

] ← H[i][xj+1

i

i

3We used θ = 2 in our experiments.

5

(cid:80)m

Putting the pieces together  we present the marginal distribution sampling algorithm in Figure 1.
The inputs to the algorithm were discussed in Section 1. In addition  we assume that the domain
restrictions Di = [l  u] for the random variables Xi are encoded as pairs of linear inequality con-
straints l ≤ xi ≤ u in B  b. The algorithm ﬁrst analyzes the equality constraints A to determine
the number of “free” random variables and reduce the dimensionality accordingly. The singular-
value decomposition of A is used to determine the n × n(cid:48) projection matrix P which maps from
the null-space of A to the original space D  where n(cid:48) = n − rank(A) is the dimensionality of the
null-space. If no equality constraints have been speciﬁed  P is the n-dimensional unit matrix. Next 
the algorithm determines a MAP state x0 of the density function deﬁned by the CCMRF  which
is the point with the highest probability mass  that is  x0 = argmaxx∈ ˜Df (x). Since the Z(Λ) is
constant and the logarithm monotonic  this is identical to x0 = argminx∈ ˜D
j=1 λiφi(x). Hence 
computing a MAP state can be cast as a linear optimization problem  since all constraints are linear
and the potential functions maximums of two linear functions. Linear optimization problems can be
solved efﬁciently in time O(n3.5) and are very fast in practice.
After determining the null-space and starting point  we begin collecting ρ samples. If we detected
being stuck in a corner during the previous iteration  we sample a direction d from the feasible
subspace of all possible directions in the reduced null-space using the adapted relaxation method
described above (lines 13-19). Otherwise  we sample a direction uniformly at random from the
null-space of A. We then normalize the direction and project it back into our original domain D by
matrix multiplication with P . The projection ensures that all equality constraints remain satisﬁed
as we move along the direction d. Next  we compute the segment of the line l : xj + αd inside
the polytope deﬁned by the inequality constraints B (lines 25-32).
Iterating over all inequality
constraints  we determine the value of α where l intersects the constraint i. We keep track of the
largest negative and smallest positive values to deﬁne the bounds [αlow  αhigh] such that the line
segment is deﬁned exactly by those values of α inside this interval. In addition  we determine all
active constraints  i.e. those constraints where the current sample point xj is the point of intersection
and hence α = 0. If the interval [αlow  αhigh] is 0  then we are currently sitting in a corner. If  in
addition  the number of active constraints exceed some threshold θ we are stuck in a corner and
abort the current iteration to start over with restricted direction sampling.
In lines 36-48 we compute the cumulative density function of the probability P over the line segment
l with α ∈ [αlow  αhigh]. Based on our assumption in Section 2  the sum of potential functions
In order to
integrate the density function  we need to segment S into its differentiable parts  so we start by
determining the subintervals of [αlow  αhigh] where S is linear and differentiable and can therefore
be described by S = rx + c. We compute the slope r and y-intercept c for each potential function
individually as well as the point of undifferentiability a where the line crosses 0. We use a map M to
store the line description [r  c] with the point of intersection a (lines 36-46). Then  we compute the
aggregate slope ra and y-intercept ca for the sum of all potentials for each point of undifferentiability
a (line 47) and use this information to compute the unnormalized cumulative density function by
integrating over each subinterval and summing those up in Σα (line 48). Now  Σa/Σαhigh gives
the cumulative probability mass for all points of undifferentiability a which deﬁne the subintervals.
Next  we sample a number s from the interval [0  Σαhigh] uniformly at random (line 49) and compute
α such that Σα = s (line 50-51). Finally  we move to the new sample point xj+1 = xj + αd and
add it to the histogram which approximates the marginal densities if the number of steps taken so
far exceeds the burn-in period which we conﬁgured to be 1% of the total number of steps.

i=1 λiφi restricted to the line l is a continuous piece-wise linear function.

S = (cid:80)m

3.5 Generalizing to convex continuous MRFs
In our treatment so far  we made speciﬁc assumptions about the constraints and potential functions.
More generally  Theorem 2 holds when the inequality constraints as well as the potential functions
are convex. A system of inequality constraints is convex if the set of all points that satisfy the con-
straints is convex  that is  any line connecting two points in the set is completely contained in the
set.
Our algorithm needs to be modiﬁed where we currently assume linearity. Firstly  computing a MAP
state requires general convex optimization. Secondly  our method for ﬁnding feasible directions
when being caught in a corner of the polytope needs to be adapted to the case of arbitrary convex
constraints. One simple approach is to use the tangent hyperplane at the point xj as an approxi-
mation to the actual constraint and proceed as is. Similarly  we need to modify the computation
of intersection points between the line and the convex constraints as well as how we determine the

6

points of undifferentiability. Lastly  the computation of integrals over subintervals for the potential
functions requires knowledge of the form of potential functions to be solved analytically or they
need to be approximated efﬁciently. The algorithm can handle arbitrary domains for the random
variables as long as they are connected subintervals of R.

4 Experiments

This section presents an empirical evaluation of the proposed sampling algorithm on the problem
of category prediction for Wikipedia documents based on similarity. After describing the data and
the experimental methodology  we demonstrate that the computed marginal distributions effectively
predict document categories. Moreover  we show that analysis of the marginal distribution provides
an indicator for the conﬁdence in those predictions. Finally  we investigate the convergence rate and
runtime performance of the algorithm in detail.
For our evaluation dataset  we collected all Wikipedia articles that appeared in the featured list4
for a two week period in Oct. 2009  thus obtaining 2460 documents. Of these  we considered a
subset of 1717 documents assigned to the 7 most popular categories. After stemming and stop-word
removal  we represented the text of each document as a tf/idf-weighted word vector. To measure the
similarity between documents  we used the popular cosine metric on the weighted word vectors. The
data contains the relations Link(fromDoc  toDoc)  which establishes a hyperlink between
two documents. We used K-fold cross-validation for k = 20  25  30  35 by splitting the dataset
into K non-overlapping subsets each of which is determined using snowball sampling over the
link structure from a randomly chosen initial document. For each training and test data subset  we
randomly designate 20% of the documents as “seed documents” of which the category is observed
and the goal is to predict the categories of the remaining documents. All experiments were executed
on identical hardware powered by two Intel Xeon Quad Core 2.3 GHz Processors and 8 GB of RAM.

4.1 Classiﬁcation results

K Baseline Marginals
20
41.4%
25
31.7%
30
39.1%
35
46.1%
Figure 2: a) Classiﬁcation Accuracy

39.5%
39.1%
36.7%
38.8%

Improvement

55.8%
51.5%
51.1%
56.6%

K P(Null Hypothesis) Relative Difference ∆(σ)
20
25
30
35
b) Std. deviation as an indicator for conﬁdence

1.95E-09
2.40E-13
<1.00E-16
4.54E-08

38.3%
41.2%
43.5%
39.0%

The baseline method uses only the document content by propagating document categories via textual
similarity measured by the cosine distance. Using rules and constraints similar to those presented in
Table 1  we create a joint probabilistic model for collective classiﬁcation of Wikipedia documents.
We use PSL twofold in this process: Firstly  PSL constructs the CCMRF by grounding the rules
and constraints against the given data as described in Section 2 and secondly  we use the percep-
tron weight learning method provided by PSL to learn the free parameters of the CCMRF from
the training data (see [3] for more detail). The sampling algorithm takes the constructed CCMRF
and learned parameters as input and computes the marginal distributions for all random variables
from 3 million samples. We have one random variable to represent the similarity for each possible
document-category pair  that is  one RV for each grounding of the category predicate. For each
document D we pick the category C with the highest expected similarity as our prediction. The
accuracy in prediction of both methods is compared in Table 2 a) over the 4 different splits of the
data. We observe that the collective probabilistic model outperforms the baseline by up to 46%. All
results are statistically signiﬁcant at p = 0.02.
While this results suggests that the sampling algorithm works in practice  it is not surprising and
novel since similar results for collective classiﬁcation have been produced before using other
approaches in statistical relational learning (e.g.  compare [13]). However  the marginal distribu-
tions we obtain provide additional information beyond the simple point estimate of its expected
value. In particular  we show that the standard deviation of the marginals can serve as an indicator
for the conﬁdence in the particular classiﬁcation prediction.
In order to show this  we compute
the standard deviation of the marginal distributions for those random variables picked during the

4 http://en.wikipedia.org/wiki/Wikipedia:Featured_lists  see [3] for more infor-

mation on the dataset

7

Figure 3: a) KL Divergence by sample size

b) Runtime for 1000 samples

prediction stage for each fold. We separate those values into two sets  S+  S−  based on whether
the prediction turned out to be correct (+) or incorrect (−) when evaluated against the ground truth.
Let σ+  σ− denote the average standard deviation for those values in S+  S− respectively. Our
hypothesis is that we have higher conﬁdence in the correct predictions  that is  σ+ will typically be
smaller than σ−. In other words  we hypothesize that the relative difference between the average
deviations  ∆(σ) = 2 σ−−σ+
σ++σ−   is larger than 0. Under the corresponding null hypothesis  we would
expect any difference in average standard deviation  and therefore any nonzero ∆(σ)  to be purely
coincidental or noise. Assuming that such noise in the ∆(σ)’s  which we computed for each fold 
can be approximated by a Gaussian distribution with 0 mean and unknown variance5  we test the
null hypothesis using a two tailed Z-test with the observed sample variance. The Z-test scores on
the 4 differently sized splits are reported in Table 2 b) and allow us to reject the null hypothesis with
very high conﬁdence. Table 2 b) also lists ∆(σ) for each split averaged across the multiple folds
and shows that σ− is about 40% larger than σ+ on average.

4.2 Algorithm performance
In investigating the performance of the sampling algorithm we are mainly interested in two ques-
tions: 1) How many samples does it take to converge on the marginal density functions? and 2) What
is the computational cost of sampling? To answer the ﬁrst question  we collect independent samples
of varying size from 31 thousand to 2 million and one reference sample with 3 million steps for all
folds. For each of the former samples we compare the marginals thus obtained to the ones of the
reference sample by measuring their KL divergence. To compute the KL divergence we discretize
the density function using a histogram with 10 bins. The center line in Figure 3 a) shows the average
KL divergence with respect to the sample size across all folds. To study the impact of dimensional-
ity on convergence  we order the folds by the number of random variables n and show the average
KL divergence for the lowest and highest quartile which contains 174 − 224 and 322 − 413 random
variables respectively. The plot is drawn in log-log scale and therefore suggests that each magnitude
increase in sample size yields a magnitude improvement in KL divergence. To answer the second
question  Figure 3 b) displays the time needed to generate 1000 samples with respect to the number
of potential functions in the CCMRF. Computing the induced probability density function along the
sampled line segment dominates the cost of each sampling step and the graph shows that this cost
grows linearly with the number of potential functions.

5 Conclusion
We have presented a novel approximation scheme for computing marginal probabilities over con-
strained continuous MRFs based on recent results in computational geometry and discussed tech-
niques to improve its efﬁciency. We introduced an effective sampling algorithm and veriﬁed its
performance in an empirical evaluation. To our knowledge  this is the ﬁrst study of the theoretical 
practical  and empirical aspects of marginal computation in general constrained continuous MRFs.
While our initial results are quite promising  there are still many further directions for research in-
cluding improved scalability  applications to other probabilistic inference problems  and using the
conﬁdence values to improve the prediction accuracy.

5Even if the standard deviations in S+  S− are not normally distributed  the central limit theorem postulates

that their averages will eventually follow a normal distributions under independence assumptions.

8

0.05  0.5  5  30000  300000  3000000  KL  Divergence  Number  of  Samples  KL  Divergence  by  Sample  Size  Average  KL  Divergence  Lowest  Quar8le  KL  Divergence  Highest  Quar8le  KL  Divergence  0  5  10  15  20  25  30  35  0  2000  4000  6000  8000  10000  Time  in  sec  Number  of  Poten1al  Func1ons  Run1me  for  1000  Samples  Acknowledgment

We thank Stanley Kok  Stephan Bach  and the anonymous reviewers for their helpful comments and
suggestions. This material is based upon work supported by the National Science Foundation under
Grant No. 0937094. Any opinions  ﬁndings  and conclusions or recommendations expressed in this
material are those of the authors and do not necessarily reﬂect the views of the NSF.

References
[1] E. B Sudderth. Graphical models for visual object recognition and tracking. Ph.D. thesis 

Massachusetts Institute of Technology  2006.

[2] L. Lovasz and S. Vempala. Hit-and-run from a corner. In Proceedings of the thirty-sixth annual

ACM symposium on Theory of computing  pages 310–314  Chicago  IL  USA  2004. ACM.

[3] M. Broecheler  L. Mihalkova  and L. Getoor. Probabilistic similarity logic. In Conference on

Uncertainty in Artiﬁcial Intelligence  2010.

[4] M. Richardson and P. Domingos. Markov logic networks. Machine Learning  62(1):107–136 

2006.

[5] K. Kersting and L. De Raedt. Bayesian logic programs. Technical report  Albert-Ludwigs

University  2001.

[6] B. Taskar  P. Abbeel  and D. Koller. Discriminative probabilistic models for relational data. In

Proceedings of UAI-02  2002.

[7] M. Broecheler  G. Simari  and VS. Subrahmanian. Using histograms to better answer queries

to probabilistic logic programs. Logic Programming  page 4054  2009.

[8] M. E. Dyer and A. M. Frieze. On the complexity of computing the volume of a polyhedron.

SIAM Journal on Computing  17(5):967–974  October 1988.

[9] R. Kannan  L. Lovasz  and M. Simonovits. Random walks and an o*(n5) volume algorithm

for convex bodies. Random structures and algorithms  11(1):150  1997.

[10] R. L. Smith. Efﬁcient monte carlo procedures for generating points uniformly distributed over

bounded regions. Operations Research  32(6):1296–1308  1984.

[11] S. Agmon. The relaxation method for linear inequalities. Canadian Journal of Mathematics 

6(3):382392  1954.

[12] T. S. Motzkin and I. J. Schoenberg. The relaxation method for linear inequalities. IJ Schoen-

berg: Selected Papers  page 75  1988.

[13] P. Sen  G. Namata  M. Bilgic  L. Getoor  B. Galligher  and T. Eliassi-Rad. Collective classiﬁ-

cation in network data. AI Magazine  29(3):93  2008.

9

,Ian En-Hsu Yen
Ting-Wei Lin
Shou-De Lin
Pradeep Ravikumar
Inderjit Dhillon
Maria Lomeli
Stefano Favaro
Yee Whye Teh
Weihao Gao
Sewoong Oh
Pramod Viswanath