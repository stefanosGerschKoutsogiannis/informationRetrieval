2009,Correlation Coefficients are Insufficient for Analyzing Spike Count Dependencies,The linear correlation coefficient is typically used to characterize and analyze dependencies of neural spike counts. Here  we show that the correlation coefficient is in general insufficient to characterize these dependencies. We construct two neuron spike count models with Poisson-like marginals and vary their dependence structure using copulas. To this end  we construct a copula that allows to keep the spike counts uncorrelated while varying their dependence strength. Moreover  we employ a network of leaky integrate-and-fire neurons to investigate whether weakly correlated spike counts with strong dependencies are likely to occur in real networks. We find that the entropy of uncorrelated but dependent spike count distributions can deviate from the corresponding distribution with independent components by more than 25% and that weakly correlated but strongly dependent spike counts are very likely to occur in biological networks. Finally  we introduce a test for deciding whether the dependence structure of distributions with Poisson-like marginals is well characterized by the linear correlation coefficient and verify it for different copula-based models.,Correlation Coefﬁcients Are Insufﬁcient
for Analyzing Spike Count Dependencies

Arno Onken

Technische Universit¨at Berlin / BCCN Berlin
Franklinstr. 28/29  10587 Berlin  Germany

Steffen Gr¨unew¨alder

University College London

Gower Street  London WC1E 6BT  UK

aonken@cs.tu-berlin.de

steffen@cs.ucl.ac.uk

Klaus Obermayer

Technische Universit¨at Berlin / BCCN Berlin

oby@cs.tu-berlin.de

Abstract

The linear correlation coefﬁcient is typically used to characterize and analyze de-
pendencies of neural spike counts. Here  we show that the correlation coefﬁcient is
in general insufﬁcient to characterize these dependencies. We construct two neu-
ron spike count models with Poisson-like marginals and vary their dependence
structure using copulas. To this end  we construct a copula that allows to keep
the spike counts uncorrelated while varying their dependence strength. Moreover 
we employ a network of leaky integrate-and-ﬁre neurons to investigate whether
weakly correlated spike counts with strong dependencies are likely to occur in
real networks. We ﬁnd that the entropy of uncorrelated but dependent spike count
distributions can deviate from the corresponding distribution with independent
components by more than 25 % and that weakly correlated but strongly dependent
spike counts are very likely to occur in biological networks. Finally  we introduce
a test for deciding whether the dependence structure of distributions with Poisson-
like marginals is well characterized by the linear correlation coefﬁcient and verify
it for different copula-based models.

1

Introduction

The linear correlation coefﬁcient is of central importance in many studies that deal with spike count
data of neural populations. For example  a low correlation coefﬁcient is often used as an evidence
for independence in recorded data and to justify simplifying model assumptions (e.g. [1  2]). In line
with this many computational studies constructed distributions for observed data based solely on
reported correlation coefﬁcients [3  4  5  6]. The correlation coefﬁcient is in this sense treated as an
equivalent to the full dependence.

The correlation coefﬁcient is also extensively used in combination with information measures such
as the Fisher information (for continuous variables only) and the Shannon information to assess the
importance of couplings between neurons for neural coding [7]. The discussion in the literature
encircles two main topics. On the one hand  it is debated whether pairwise correlations versus
higher order correlations across different neurons are sufﬁcient for obtaining good estimates of the
information (see e.g. [8  9  10]). On the other hand  it is questioned whether correlations matter at
all (see e.g. [11  12  13]). In [13]  for example  based on the correlation coefﬁcient it was argued
that the impact of correlations is negligible for small populations of neurons.

The correlation coefﬁcient is one measure of dependence among others. It has become common to
report only the correlation coefﬁcient of recorded spike trains without reporting any other properties

of the actual dependence structure (see e.g. [3  14  15]). The problem with this common practice is
that it is unclear beforehand whether the linear correlation coefﬁcient sufﬁces to describe the depen-
dence or at least the relevant part of the dependence. Of course  it is well known that uncorrelated
does not imply statistically independent. Yet  it might seem likely that this is not important for
realistic spike count distributions which have a Poisson-like shape. Problems could be restricted
to pathological cases that are very unlikely to occur in realistic biological networks. At least one
might expect to ﬁnd a tendency of weak dependencies for uncorrelated distributions with Poisson-
like marginals. It might also seem likely that these dependencies are unimportant in terms of typical
information measures even if they are present and go unnoticed or are ignored.

In this paper we show that these assumptions are false. Indeed  the dependence structure can have
a profound impact on the information of spike count distributions with Poisson-like single neuron
statistics. This impact can be substantial not only for large networks of neurons but even for two
neuron distributions. As a matter of fact  the correlation coefﬁcient places only a weak constraint on
the dependence structure. Moreover  we show that uncorrelated or weakly correlated spike counts
with strong dependencies are very likely to be common in biological networks. Thus  it is not
sufﬁcient to report only the correlation coefﬁcient or to derive strong implications like independence
from a low correlation coefﬁcient alone. At least a statistical test should be applied that states for
a given signiﬁcance level whether the dependence is well characterized by the linear correlation
coefﬁcient. We will introduce such a test in this paper. The test is adjusted to the setting that a
neuroscientist typically faces  namely the case of Poisson-like spike count distributions of single
neurons and small numbers of samples.

In the next section  we describe state-of-the-art methods for modeling dependent spike counts  to
compute their entropy  and to generate network models based on integrate-and-ﬁre neurons. Sec-
tion 3 shows examples of what can go wrong for entropy estimation when relying on the correlation
coefﬁcient only. Emergences of such cases in simple network models are explored. Section 4 intro-
duces the linear correlation test which is tailored to the needs of neuroscience applications and the
section examines its performance on different dependence structures. The paper concludes with a
discussion of the advantages and limitations of the presented methods and cases.

2 General methods

We will now describe formal aspects of spike count models and their Shannon information.

2.1 Copula-based models with discrete marginals

A copula is a cumulative distribution function (CDF) which is deﬁned on the unit hypercube and has
uniform marginals [16]. Formally  a bivariate copula C is deﬁned as follows:
Deﬁnition 1. A copula is a function C : [0  1]2 −→ [0  1] such that:

1. ∀u  v ∈ [0  1]: C(u  0) = 0 = C(0  v) and C(u  1) = u and C(1  v) = v.

2. ∀u1  v1  u2  v2 ∈ [0  1] with u1 ≤ u2 and v1 ≤ v2:

C(u2  v2) − C(u2  v1) − C(u1  v2) + C(u1  v1) ≥ 0.

Copulas can be used to couple arbitrary marginal CDF’s FX1  FX2 to form a joint CDF F ~X  such that
F ~X (r1  r2) = C(FX1 (r1)  FX2 (r2)) holds [16]. There are many families of copulas representing
different dependence structures. One example is the bivariate Frank family [17]. Its CDF is given
by

Cθ(u  v) =(− 1

uv

θ ln(cid:16)1 + (e−θu−1)(e−θv−1)

e−θ−1

(cid:17)

if θ 6= 0 
if θ = 0.

(1)

The Frank family is commutative and radial symmetric:
its probability density cθ abides by
∀(u  v) ∈ [0  1]2 : cθ(u  v) = cθ(1−u  1−v) [17]. The scalar parameter θ controls the strength of de-
pendence. As θ → ±∞ the copula approaches deterministic positive/negative dependence: knowl-
edge of one variable implies knowledge of the other (so-called Fr´echet-Hoeffding bounds [16]). The
linear correlation coefﬁcient is capable of measuring this dependence. Another example is the bi-
variate Gaussian copula family deﬁned as Cθ(u  v) = φθ(φ−1(u)  φ−1(v))  where φθ is the CDF of

the bivariate zero-mean unit-variance multivariate normal distribution with correlation θ and φ−1 is
the inverse of the CDF of the univariate zero-mean unit-variance Gaussian distribution. This fam-
ily can be used to construct multivariate distributions with Gauss-like dependencies and arbitrary
marginals.
For a given realization ~r  which can represent the counts of two neurons  we can set ui = FXi(ri)
and FX (~r) = Cθ(~u)  where FXi can be arbitrary univariate CDF’s. Thereby  we can generate a
multivariate distribution with speciﬁc marginals FXi and a dependence structure determined by C.
Copulas allow us to have different discrete marginal distributions [18  19]. Typically  the Poisson
distribution is a good approximation to spike count variations of single neurons [20]. For this distri-
bution the CDF’s of the marginals take the form

FXi(r; λi) =

λk
i
k!

e−λi 

⌊r⌋

Xk=0

where λi is the mean spike count of neuron i for a given bin size. We will also use the negative
binomial distribution as a generalization of the Poisson distribution:

FXi(r; λi  υi) =

⌊r⌋

Xk=0

λk
i
k!

1
(1 + λi
υi

)υi

Γ(υi + k)

Γ(υi)(υi + λi)k  

where Γ is the gamma function. The additional parameter υi controls the degree of overdispersion:
the smaller the value of υi  the greater the Fano factor: the variance is given by λi + λ2
. As υi
i
υi
approaches inﬁnity  the negative binomial distribution converges to the Poisson distribution.

Likelihoods of discrete vectors can be computed by applying the inclusion-exclusion principle
of Poincar´e and Sylvester. The probability of a realization (x1  x2) is given by P ~X (x1  x2) =
F ~X (x1  x2) − F ~X (x1 − 1  x2) − F ~X (x1  x2 − 1) + F ~X (x1 − 1  x2 − 1). Thus  we can compute the
probability mass of a realization ~x using only the CDF of ~X.

2.2 Computation of information entropy

The Shannon entropy [21] of dependent spike counts ~X is a measure of the information that a
decoder is missing when it does not know the value ~x of ~X. It is given by

H( ~X) = E[I( ~X)] = X~x∈Nd

P ~X (~x)I(~x) 

where I(~x) = − log2(P ~X (~x)) is the self-information of the realization ~x.

2.3 Leaky integrate-and-ﬁre model

The leaky integrate-and-ﬁre neuron is a simple neuron model that models only subthreshold mem-
brane potentials. The equation for the membrane potential is given by

τm

dV
dt

= EL − V + RmIs 

where EL denotes the resting membrane potential  Rm is the total membrane resistance  Is is
the synaptic input current  and τm is the time constant. The model is completed by a rule which
states that whenever V reaches a threshold Vth  an action potential is ﬁred and V is reset to
Vreset [22].
In all of our simulations we used τm = 20 ms  Rm = 20 MΩ  Vth = −50 mV 
and Vreset = Vinit = −65 mV  which are typical values found in [22]. Current-based synaptic
input for an isolated presynaptic release that occurs at time t = 0 can be modeled by the so-called
α-function [22]: Is = Imax
). The function reaches its peak Is at time t = τs and then
decays with time constant τs. We can model an excitatory synapse by a positive Imax and an in-
hibitory synapse by a negative Imax. We used Imax = 1 nA for excitatory synapses  Imax = −1 nA
for inhibitory synapses  and τs = 5 ms.

exp(1 − t
τs

t
τs

ω

 

θ
 

2

1

θ
C

1

0.5

0
1
0.5
v

0

0

v

1

0.8

0.6

0.4

0.2

0
 
0

0.5

u

1

(a)

 

2

1.5

1

0.5

0

1

0.5
u
(d)

ω

 

θ
 

2

1

θ
C

1

0.5

0
1
0.5
v

0

0

v

1

0.8

0.6

0.4

0.2

0
 
0

0.5

u

1

(b)

 

10

8

6

4

2

0

1

0.5
u
(e)

ω

 

θ
 

2

1

θ
C

1

0.5

0
1
0.5
v

0

0

v

1

0.8

0.6

0.4

0.2

0
 
0

0.5

u

1

(c)

 

1

8

6

4

2

0

0.5
u
(f)

Figure 1: Cumulative distribution functions (a-c) and probability density functions (d-f) of selected
Frank shufﬂe copulas. (a  d): Independence: θ1 = θ2 = 0. (b  e): Strong negative dependence
in outer square: θ1 = −30  θ2 = 5  ω = 0.2. (c  f): Strong positive dependence in inner square:
θ1 = −5  θ2 = 30  ω = 0.2.

3 Counter examples

In this section we describe entropy variations that can occur when relying on the correlation coefﬁ-
cient only. We will evaluate this effect for models of spike counts which have Poisson-like marginals
and show that such effects can occur in very simple biological networks.

3.1 Frank shufﬂe copula

We will now introduce the Frank shufﬂe copula family. This copula family allows arbitrarily strong
dependencies with a correlation coefﬁcient of zero for attached Poisson-like marginals. It uses two
Frank copulas (see Section 2.1) in different regions of its domain such that the linear correlation
coefﬁcient would vanish.
Proposition 1. The following function deﬁnes a copula ∀θ1  θ2 ∈ R  ω ∈ [0  0.5] :
Cθ1(u  v) − ςθ1(ω  ω  u  v) + zθ1 θ2 ω(min{u  v})ςθ2 (ω  ω  u  v)

if (u  v) ∈
(ω  1 − ω)2 
otherwise 

Cθ1 θ2 ω(u  v) =


Cθ1(u  v)

where ςθ(u1  v1  u2  v2) = Cθ(u2  v2) − Cθ(u2  v1) − Cθ(u1  v2) + Cθ(u1  v1) and zθ1 θ2 ω(m) =
ςθ1(ω  ω  m  1 − ω)/ςθ2(ω  ω  m  1 − ω).

The proof of the copula properties is given in Appendix A. This family is capable of modeling
a continuum between independence and deterministic dependence while keeping the correlation
coefﬁcient at zero. There are two regions: the outer region [0  1]2 \ (ω  1 − ω)2 contains a Frank
copula with θ1 and the inner square (ω  1 − ω)2 contains a Frank copula with θ2 modiﬁed by a factor
z. If we would restrict our analysis to copula-based distributions with continuous marginals it would
be sufﬁcient to select θ1 = −θ2 and to adjust ω such that the correlation coefﬁcient would vanish. In
such cases  the factor z would be unnecessary. For discrete marginals  however  this is not sufﬁcient
as the CDF is no longer a continuous function of ω. Different copulas of this family are shown in
Fig. 1.

We will now investigate the impact of this dependence structure on the entropy of copula-based dis-
tributions with Poisson-like marginals while keeping the correlation coefﬁcient at zero. Introducing
more structure into a distribution typically reduces its entropy. Therefore  we expect that the entropy
can vary considerably for different dependence strengths  even though the correlation is always zero.

6

4

2

)
s
t
i

B

(
 
y
p
o
r
t

n
E

0
 
0

 

Poisson
Negative Binomial

−30

−40

−50

)

%

(
 

e
c
n
e
r
e

f
f
i

D
 
y
p
o
r
t

n
E

30

20

10

0
 
0

 

Poisson
Negative Binomial

−10

−20

θ
1

−30

−40

−50

(b)

−10

−20

θ
1

(a)

Figure 2: Entropy of distributions based on the Frank shufﬂe copula Cθ1 θ2 ω for ω = 0.05 and
different dependence strengths θ1. The second parameter θ2 was selected such that the absolute
correlation coefﬁcient was below 10−10. For Poisson marginals  we selected rates λ1 = λ2 = 5.
For 100 ms bins this would correspond to ﬁring rates of 50 Hz. For negative binomial marginals
we selected rates λ1 = 2.22  λ2 = 4.57 and variances σ2
2 = 10.99 (values taken from
experimental data recorded in macaque prefrontal cortex and 100 ms bins [18]). (a): Entropy of the
Cθ1 θ2 ω based models. (b): Difference between the entropy of the Cθ1 θ2 ω-based models and the
model with independent elements in percent of the independent model.

1 = 4.24  σ2

Fig. 2(a) shows the entropy of the Frank shufﬂe-based models with Poisson and negative binomial
marginals for uncorrelated but dependent elements. θ1 was varied while θ2 was estimated using
the line-search algorithm for constrained nonlinear minimization [23] with the absolute correlation
coefﬁcient as the objective function. Independence is attained for θ1 = 0. With increasing depen-
dence the entropy decreases until it reaches a minimum at θ1 = −20. Afterward  it increases again.
This is due to the shape of the marginal distributions. The region of strong dependence shifts to a
region with small mass. Therefore  the actual dependence decreases. However  in this region the
dependency is almost deterministic and thus does not represent a relevant case.

Fig. 2(b) shows the difference to the entropy of corresponding models with independent elements.
The entropy deviated by up to 25 % for the Poisson marginals and up to 15 % for the negative
binomial marginals. So the entropy varies indeed considerably in spite of ﬁxed marginals and un-
correlated elements.

We constructed a copula family which allowed us to vary the dependence strength systematically
while keeping the variables uncorrelated. It could be argued that this is a pathological example. In
the next section  however  we show that such effects can occur even in simple biologically realistic
network models.

3.2 LIF network

We will now explore the feasibility of uncorrelated spike counts with strong dependencies in a bio-
logically realistic network model. For this purpose  we set up a network of leaky integrate-and-ﬁre
neurons (see Section 2.3). The neurons have two common input populations which introduce oppo-
site dependencies (see Fig. 3(a)). Therefore  the correlation should vanish for the right proportion of
input strengths. Note that the bottom input population does not contradict to Dale’s principle  since
excitatory neurons can project to both excitatory and inhibitory neurons.

We can ﬁnd a copula family which can model this relation and has two separate parameters for the
strengths of the input populations:

(2)

C cm

θ1 θ2(u  v) =

1

1

2(cid:0)max(cid:8)u−θ1 + v−θ1 − 1  0(cid:9)(cid:1)−1/θ1
2(cid:16)u −(cid:0)max(cid:8)u−θ2 + (1 − v)−θ2 − 1  0(cid:9)(cid:1)−1/θ2(cid:17)  

+

where θ1  θ2 ∈ (0  ∞). It is a mixture of the well known Clayton copula and an one element survival
transformation of the Clayton copula [16]. As a mixture of copulas this function is again a copula.
A copula of this family is shown in Fig. 3(b).

Fig. 3(c) shows the correlation coefﬁcients of the network generated spike counts and of C cm
θ1 θ2
ﬁts. The rate of population D that introduces negative dependence is kept constant  while the rate
of population B that introduces positive dependence is varied. The resulting spike count statistics

1

0.8

0.6

0.4

0.2

v

 

10

8

6

4

2

0

(a)

 

0.2

0.4

0.8

1

0.6

u
(b)

t

i

n
e
c
i
f
f

e
o
C
n
o

 

i
t

l

a
e
r
r
o
C

0.4

0.3

0.2

0.1

0

−0.1

−0.2

250

Input Rate of Top Center Population (Hz)

300

350

(c)

Figure 3: Strong dependence with zero correlation in a biological network model. (a): Neural net-
work models used to generate synthetic spike count data. Two leaky integrate-and-ﬁre neurons (LIF1
and LIF2  see Section 2.3) receive spike inputs (circles for excitation  bars for inhibition) from four
separate populations of neurons (rectangular boxes and circles  A-D)  but only two populations (B 
D) send input to both neurons. All input spike trains were Poisson-distributed. (b): Probability den-
θ1 θ2 with θ1 = 1.5 and θ2 = 2.0. (c): Correlation coefﬁcients of
sity of the Clayton mixture model C cm
network generated spike counts compared to correlations of a maximum likelihood ﬁt of the C cm
θ1 θ2
copula family to these counts. Solid line: correlation coefﬁcients of counts generated by the network
shown in (a). Each neuron had a total inhibitory input rate of 300 Hz and a total excitatory input rate
of 900 Hz. Population D had a rate of 150 Hz. We increased the absolute correlation between the
spike counts by shifting the rates: we decreased the rates of A and C and increased the rate of B. The
total simulation time amounted to 200 s. Spike counts were calculated for 100 ms bins. Dashed line:
θ1 θ2. Dashed-dotted line: Correlation
Correlation coefﬁcients of the ﬁrst mixture component of C cm
coefﬁcients of the second mixture component of C cm

.

θ1 θ2

were close to typically recorded data. At approximately 275 Hz the dependencies cancel each other
out in the correlation coefﬁcient. Nevertheless  the mixture components of the copula reveal that
there are still dependencies: the correlation coefﬁcient of the ﬁrst mixture component that models
negative dependence is relatively constant  while the correlation coefﬁcient of the second mixture
component increases with the rate of the corresponding input population. Therefore  correlation
coefﬁcients of spike counts that do not at all reﬂect the true strength of dependence are very likely
to occur in biological networks. Structures similar to the investigated network can be formed in any
feed-forward network that contains positive and negative weights.

Typically  the network structure is unknown. Hence  it is hard to construct an appropriate copula that
is parametrized such that individual dependence strengths are revealed. The goal of the next section
is to assess a test that reveals whether the linear correlation coefﬁcient provides an appropriate
measure for the dependence.

4 Linear correlation test

We will now describe a test for bivariate distributions with Poisson-like marginals that determines
whether the dependence structure is well characterized by the linear correlation coefﬁcient. This test
combines a variant of the χ2 goodness-of-ﬁt test for discrete multivariate data with a semiparametric
model of linear dependence. We ﬁt the semiparametric model to the data and we apply the goodness-
of-ﬁt test to see if the model is adequate for the data.

The semiparametric model that we use consists of the empirical marginals of the sample coupled by
a parametric copula family. A dependence structure is well characterized by the linear correlation
coefﬁcient if it is Gauss-like. So one way to test for linear dependence would be to use the Gaussian
copula family. However  the likelihood of copula-based models relies on the CDF which has no
closed form solution for the Gaussian family. Fortunately  a whole class of copula families that are
Gauss-like exists. The Frank family is in this class [24] and its CDF can be computed very efﬁciently.
We therefore selected this family for our test (see Eq. 1). The Frank copula has a scalar parameter θ.
The parameter relates directly to the dependence. With growing θ the dependence increases strictly

1

0

H

 
f

o

 

e
c
n
a

t

p
e
c
c
A
%

 

0.5

 

0
0

 

1

0

H

Samples: 128
Samples: 256
Samples: 512

−40

−60

−20

θ
1

(a)

 
f

o

 

e
c
n
a

t

p
e
c
c
A
%

 

0.5

0
0

20

10
θ
1

(b)

1

0

H

 
f

o

 

e
c
n
a

t

p
e
c
c
A
%

 

0.5

0
−10

1

0

H

 
f

o

 

e
c
n
a

t

p
e
c
c
A
%

 

0.5

0

−0.5

10

0
θ

(c)

0.5

0
θ

(d)

Figure 4: Percent acceptance of the linear correlation hypothesis for different copula-based models
with different dependence strengths and Poisson marginals with rates λ1 = λ2 = 5. We used 100
repetitions each. The number of samples was varied between 128 and 512. On the x-axis we varied
the strength of the dependence by means of the copula parameters. (a): Frank shufﬂe family with
correlation kept at zero.
(c): Frank family.
(d): Gaussian family.

(b): Clayton mixture family C cm

with θ1 = 2θ2.

θ1 θ2

monotonically. For θ = 0 the Frank copula corresponds to independence. Therefore  the usual χ2
independence test is a special case of our linear correlation test.

The parameter θ of the Frank family can be estimated based on a maximum likelihood ﬁt. However 
this is time-consuming. As an alternative we propose to estimate the copula parameter θ by means
of Kendall’s τ . Kendall’s τ is a measure of dependence deﬁned as τ (~x  ~y) = c−d
c+d   where c is the
number of elements in the set {(i  j)|(xi < xj and yi < yj) or (xi > xj and yi > yj)} and d is
the number of element in the set {(i  j)|(xi < xj and yi > yj) or (xi > xj and yi < yj)} [16].
For the Frank copula with continuous marginals the relation between τ and θ is given by τθ =
1 − 4
exp(t)−1 dt [25]. For discrete
marginals this is an approximate relation. Unfortunately  τ −1
cannot be expressed in closed form 
but can be easily obtained numerically using Newton’s method.

θ [1 − D1(θ)]  where Dk(x) is the Debye function Dk(x) = k

xk R x

tk

0

θ

The goodness-of-ﬁt test that we apply for this model is based on the χ2 test [26].
It is widely
applied for testing goodness-of-ﬁt or independence of categorical variables. For the test  observed
frequencies are compared to expected frequencies using the following statistic:

X 2 =

k

Xi=1

(ni − m0i)2

m0i

 

(3)

where ni are the observed frequencies  moi are the expected frequencies  and k is the number of
bins. For a 2-dimensional table the sum is over both indices of the table. If the frequencies are large
enough then X 2 is approximately χ2-distributed with df = (N −1)(M −1)−s degrees of freedom 
where N is the number of rows  M is the number of columns  and s is the number of parameters
in the H0 model (1 for the Frank family). Thus  for a given signiﬁcance level α the test accepts
the hypothesis H0 that the observed frequencies are a sample from the distribution formed by the
expected frequencies  if X 2 is less than the (1 − α) point of the χ2-distribution with df degrees of
freedom.

The χ2 statistic is an asymptotic statistic. In order to be of any value  the frequencies in each bin
must be large enough. As a rule of thumb  each frequency should be at least 5 [26]. This cannot
be accomplished for Poisson-like marginals since there is an inﬁnite number of bins. For such
cases Loukas and Kemp [27] propose the ordered expected-frequencies procedure. The expected
frequencies m0 are sorted monotonically decreasing into a 1-dimensional array. The corresponding
observed frequencies form another 1-dimensional array. Then the frequencies in both arrays are
grouped from left to right such that the grouped m0 frequencies reach a speciﬁed minimum expected
frequency (MEF)  e.g. MEF= 1 as in [27]. The χ2 statistic is then estimated using Eq. 3 with the
grouped expected and grouped observed frequencies.

To verify the test we applied it to samples from copula-based distributions with Poisson marginals
and four different copula families: the Frank shufﬂe family (Proposition 1)  the Clayton mixture
family (Eq. 2)  the Frank family (Eq. 1)  and the Gaussian family (Section 2.1). For the Frank
family and the Gaussian family the linear correlation coefﬁcient is well suited to characterize their

dependence. We therefore expected that the test should accept H0  regardless of the dependence
strength. In contrast  for the Frank shufﬂe family and the Clayton mixture family the linear corre-
lation does not reﬂect the dependence strength. Hence  the test should reject H0 most of the time
when there is dependence.

The acceptance rates for these copulas are shown in Fig. 4. For each of the families there was no
dependence when the ﬁrst copula parameter was equal to zero. The Frank and the Gaussian families
have only Gauss-like dependence  meaning the correlation coefﬁcient is well-suited to describe the
data. In all of these cases the achieved Type I error was small  i.e. the acceptance rate of H0 was
close to the desired value (0.95). The plots in (a) and (b) indicate the Type II errors: H0 was accepted
although the dependence structure of the counts was not Gauss-like. The Type II error decreased
for increasing sample sizes. This is reasonable since X 2 is only asymptotically χ2-distributed.
Therefore  the test is unreliable when dependencies and sample sizes are both very small.

5 Conclusion

We investigated a worst-case scenario for reliance on the linear correlation coefﬁcient for analyzing
dependent spike counts using the Shannon information. The spike counts were uncorrelated but had
a strong dependence. Thus  relying solely on the correlation coefﬁcient would lead to an oversight of
such dependencies. Although uncorrelated with ﬁxed marginals the information varied by more than
25 %. Therefore  the dependence was not negligible in terms of the entropy. Furthermore  we could
show that similar scenarios are very likely to occur in real biological networks. Our test provides a
convenient tool to verify whether the correlation coefﬁcient is the right measure for an assessment of
the dependence. If the test rejects the Gauss-like dependence hypothesis  more elaborate measures
of the dependence should be applied. An adequate copula family provides one way to ﬁnd such a
measure. In general  however  it is hard to ﬁnd the right parametric family. Directions for future
research include a systematic approach for handling the alternative case when one has to deal with
the full dependence structure and a closer look at experimentally observed dependencies.

Acknowledgments. This work was supported by BMBF grant 01GQ0410.

A Proof of proposition 1

Proof. We show that Cθ1 θ2 ω is a copula. Since Cθ1 θ2 ω is commutative we assume w.l.o.g. u ≤ v.
For u = 0 or v = 0 and for u = 1 or v = 1 we have Cθ1 θ2 ω(u  v) = Cθ1(u  v). Hence  property 1
follows directly from Cθ1. It remains to show that Cθ1 θ2 ω is 2-increasing (property 2). We will
show this in two steps:
1) We show that Cθ1 θ2 ω is continuous: For ω2 = 1 − ω and u ∈ (ω  ω2):

lim
tրω2

Cθ1 θ2 ω(u  t) = Cθ1(u  ω2) − ςθ1(ω  ω  u  ω2) +

ςθ1(ω  ω  u  ω2)
ςθ2(ω  ω  u  ω2)

ςθ2(ω  ω  u  ω2)

For v ∈ (ω  1 − ω):

= Cθ1(u  ω2).

lim
tցω

Cθ1 θ2 ω(t  v) = Cθ1(ω  v) − ςθ1(ω  ω  ω  v) + lim
tցω

ςθ1(ω  ω  t  1 − ω)
ςθ2(ω  ω  t  1 − ω)

ςθ2(ω  ω  t  v).

We can use l’Hˆopital’s rule since limtցω ςθ(ω  ω  t  1 − ω) = 0. It is easy to verify that

∂Cθ
∂u

(v) =

e−θu(e−θv − 1)

e−θ − 1 + (e−θu − 1)(e−θv − 1)

.

Thus  the quotient is constant and limtցω Cθ1 θ2 ω(t  v) = Cθ1(ω  v) − 0 + 0.
2) Cθ1 θ2 ω has non-negative density almost everywhere on [0  1]2. This is obvious for u1  v1 /∈
[ω  1 − ω]2  because Cθ1 is a copula. Straightforward but tedious algebra shows that ∀u1  v1 ∈
(ω  1 − ω)2 : ∂ 2Cθ1  θ2  ω
Thus  Cθ1 θ2 ω is continuous and has density almost everywhere on [0  1]2 and is therefore 2-
increasing.

(u1  v1) ≥ 0.

∂u∂v

References

[1] M. Jazayeri and J. A. Movshon. Optimal representation of sensory information by neural populations.

Nature Neuroscience  9(5):690–696  2006.

[2] L. Schwabe and K. Obermayer. Adaptivity of tuning functions in a generic recurrent network model of a

cortical hypercolumn. Journal of Neuroscience  25(13):3323–3332  2005.

[3] D. A. Gutnisky and V. Dragoi. Adaptive coding of visual information in neural populations. Nature 

452(7184):220–224  2008.

[4] M. Shamir and H. Sompolinsky. Implications of neuronal diversity on population coding. Neural Com-

putation  18(8):1951–1986  2006.

[5] P. Series  P. E. Latham  and A. Pouget. Tuning curve sharpening for orientation selectivity: coding

efﬁciency and the impact of correlations. Nature Neuroscience  7(10):1129–1135  2004.

[6] L. F. Abbott and P. Dayan. The effect of correlated variability on the accuracy of a population code.

Neural Computation  11(1):91–101  1999.

[7] B. B. Averbeck  P. E. Latham  and A. Pouget. Neural correlations  population coding and computation.

Nature Review Neuroscience  7(5):358–366  2006.

[8] Y. Roudi  S. Nirenberg  and P. E. Latham. Pairwise maximum entropy models for studying large biological
systems: When they can work and when they can’t. PLoS Computational Biology  5(5):e1000380+  2009.
[9] E. Schneidman  M. J. Berry II  R. Segev  and W. Bialek. Weak pairwise correlations imply strongly

correlated network states in a neural population. Nature  440:1007–1012  2006.

[10] J. Shlens  G. D. Field  J. L. Gauthier  M. I. Grivich  D. Petrusca  E. Sher  A. M. Litke  and E. J.
Chichilnisky. The structure of multi-neuron ﬁring patterns in primate retina. Journal of Neuroscience 
26:2006  2006.

[11] B. B. Averbeck and D. Lee. Neural noise and movement-related codes in the macaque supplementary

motor area. Journal of Neuroscience  23(20):7630–7641  2003.

[12] S. Panzeri  G. Pola  F. Petroni  M. P. Young  and R. S. Petersen. A critical assessment of different measures

of the information carried by correlated neuronal ﬁring. Biosystems  67(1-3):177–185  2002.

[13] H. Sompolinsky  H. Yoon  K. Kang  and M. Shamir. Population coding in neuronal systems with corre-

lated noise. Physical Review E  64(5):051904  2001.

[14] A. Kohn and M. A. Smith. Stimulus dependence of neuronal correlation in primary visual cortex of the

macaque. Journal of Neuroscience  25(14):3661–3673  2005.

[15] W. Bair  E. Zohary  and W. T. Newsome. Correlated ﬁring in macaque visual area MT: time scales and

relationship to behavior. Journal of Neuroscience  21(5):1676–1697  2001.

[16] R. B. Nelsen. An Introduction to Copulas. Springer  New York  second edition  2006.
[17] M. J. Frank. On the simultaneous associativity of f(x y) and x+y-f(x y). Aequations Math  19:194–226 

1979.

[18] A. Onken  S. Gr¨unew¨alder  M. Munk  and K. Obermayer. Modeling short-term noise dependence of
In D. Koller  D. Schuurmans  Y. Bengio  and L. Bottou 

spike counts in macaque prefrontal cortex.
editors  Advances in Neural Information Processing Systems 21  pages 1233–1240  2009.

[19] P. Berkes  F. Wood  and J. Pillow. Characterizing neural dependencies with copula models. In D. Koller 
D. Schuurmans  Y. Bengio  and L. Bottou  editors  Advances in Neural Information Processing Systems
21  pages 129–136  2009.

[20] D. J. Tolhurst  J. A. Movshon  and A. F. Dean. The statistical reliability of signals in single neurons in cat

and monkey visual cortex. Vision Research  23:775–785  1982.

[21] C. E. Shannon. A mathematical theory of communication. Bell System Technical Journal  27:379–423 

1948.

[22] P. Dayan and L. F. Abbott. Theoretical Neuroscience. Cambridge (Massachusetts): MIT Press  2001.
[23] R. A. Waltz  J. L. Morales  J. Nocedal  and D. Orban. An interior algorithm for nonlinear optimization

that combines line search and trust region steps. Mathematical Programming  107(3):391–408  2006.

[24] C. Genest  B. R´emillard  and D. Beaudoin. Goodness-of-ﬁt tests for copulas: A review and a power study.

Insurance: Mathematics and Economics  44(2):199–213  2009.

[25] C. Genest. Frank’s family of bivariate distributions. Biometrika  74:549–555  1987.
[26] W. G. Cochran. The χ
2 test of goodness of ﬁt. Annals of Mathematical Statistics  23(3):315–345  1952.
[27] S. Loukas and C. D. Kemp. On the chi-square goodness-of-ﬁt statistic for bivariate discrete distributions.

The Statistician  35:525–529  1986.

,Mingming Gong
Yanwu Xu
Chunyuan Li
Kun Zhang
Kayhan Batmanghelich