2013,Learning Efficient Random Maximum A-Posteriori Predictors with Non-Decomposable Loss Functions,In this work we develop efficient methods for learning random MAP predictors for structured label problems. In particular  we construct posterior distributions over perturbations that can be adjusted via stochastic gradient methods. We show that every smooth posterior distribution would suffice to define a smooth PAC-Bayesian risk bound suitable for gradient methods. In addition  we relate the posterior distributions to computational properties of the MAP predictors. We suggest multiplicative posteriors to learn super-modular potential functions that accompany specialized MAP predictors such as graph-cuts. We also describe label-augmented posterior models that can use efficient MAP approximations  such as those arising from linear program relaxations.,Learning Efﬁcient Random Maximum A-Posteriori
Predictors with Non-Decomposable Loss Functions

Tamir Hazan

University of Haifa

Subhransu Maji

TTI Chicago

Joseph Keshet

Bar-Ilan university

Tommi Jaakkola

CSAIL  MIT

Abstract

In this work we develop efﬁcient methods for learning random MAP predictors for
structured label problems. In particular  we construct posterior distributions over
perturbations that can be adjusted via stochastic gradient methods. We show that
any smooth posterior distribution would sufﬁce to deﬁne a smooth PAC-Bayesian
risk bound suitable for gradient methods. In addition  we relate the posterior dis-
tributions to computational properties of the MAP predictors. We suggest mul-
tiplicative posteriors to learn super-modular potential functions that accompany
specialized MAP predictors such as graph-cuts. We also describe label-augmented
posterior models that can use efﬁcient MAP approximations  such as those arising
from linear program relaxations.

1

Introduction

Learning and inference in complex models drives much of the research in machine learning
applications ranging from computer vision  natural language processing  to computational biol-
ogy [1  18  21]. The inference problem in such cases involves assessing the likelihood of possible
structured-labels  whether they be objects  parsers  or molecular structures. Given a training dataset
of instances and labels  the learning problem amounts to estimation of the parameters of the infer-
ence engine  so as to best describe the labels of observed instances. The goodness of ﬁt is usually
measured by a loss function.
The structures of labels are speciﬁed by assignments of random variables  and the likelihood of the
assignments are described by a potential function. Usually  it is feasible to only ﬁnd the most likely
or maximum a-posteriori (MAP) assignment  rather than sampling according to their likelihood. In-
deed  substantial effort has gone into developing algorithms for recovering MAP assignments  either
based on speciﬁc parametrized restrictions such as super-modularity [2] or by devising approximate
methods based on linear programming relaxations [21]. Learning MAP predictors is usually done
by structured-SVMs that compare a “loss adjusted” MAP prediction to its training label [25]. In
practice  most loss functions used decompose in the same way as the potential function  so as to not
increase the complexity of the MAP prediction task. Nevertheless  non-decomposable loss functions
capture the structures in the data that we would like to learn.
Bayesian approaches for expected loss minimization  or risk  effortlessly deal with non-
decomposable loss functions. The inference procedure samples a structure according to its like-
lihood  and computes its loss given a training label. Recently [17  23] constructed probability
models through MAP predictions. These “perturb-max” models describe the robustness of the
MAP prediction to random changes of its parameters. Therefore  one can draw unbiased sam-
ples from these distributions using MAP predictions.
Interestingly  when incorporating perturb-
max models to Bayesian loss minimization one would ultimately like to use the PAC-Bayesian risk
[11  19  3  20  5  10].
Our work explores the Bayesian aspects that emerge from PAC-Bayesian risk minimization. We
focus on computational aspects when constructing posterior distributions  so that they could be used

1

to minimize the risk bound efﬁciently. We show that any smooth posterior distribution would sufﬁce
to deﬁne a smooth risk bound which can be minimized through gradient decent. In addition  we
relate the posterior distributions to the computational properties of MAP predictors. We suggest
multiplicative posterior models to learn super-modular potential functions  that come with special-
ized MAP predictors such as graph-cuts [2]. We also describe label-augmented posterior models
that can use MAP approximations  such as those arising from linear program relaxations [21].

2 Background

Learning complex models typically involves reasoning about the states of discrete variables whose
labels (assignments of values) specify the discrete structures of interest. The learning task which
we consider in this work is to ﬁt parameters w that produce to most accurate prediction y ∈ Y
to a given object x. Structures of labels are conveniently described by a discrete product space
Y = Y1 × ··· × Yn. We describe the potential of relating a label y to an object x with respect to
the parameters w by real valued functions θ(y; x  w). Our goal is to learn the parameters w that best
describe the training data (x  y) ∈ S. Within Bayesian perspectives  the distribution that one learns
given the training data is composed from a distribution over the parameter space qw(γ) and over the
labels space P [y|w  x] ∝ exp θ(y; x  w). Using the Bayes rule we derive the predictive distribution
over the structures

P [y|x] =

P [y|γ  x]qw(γ)dγ

(1)

(cid:90)

Unfortunately  sampling algorithms over complex models are provably hard in theory and tend to
be slow in many cases of practical interest [7]. This is in contrast to the maximum a-posteriori
(MAP) prediction  which can be computed efﬁciently for many practical cases  even when sampling
is provably hard.

(MAP predictor)

yw(x) = arg max
y1 ... yn

θ(y; x  w)

(2)

Recently  [17  23] suggested to change of the Bayesian posterior probability models to utilize the
MAP prediction in a deterministic manner. These perturb-max models allow to sample from the
predictive distribution with a single MAP prediction:
P [y|x]

(cid:2)y = yγ(x)(cid:3)

(Perturb-max models)

def
= Pγ∼qw

(3)

(cid:80)
i∈V θi(yi; x  w) +(cid:80)

i j∈E θi j(yi  yj; x  w).

A potential function is decomposed along a graphical model if it has the form θ(y; x  w) =
If the graph has no cycles  MAP prediction can
be computed efﬁciently using the belief propagation algorithm. Nevertheless  there are cases where
MAP prediction can be computed efﬁciently for graph with cycles. A potential function is called
supermodular if it is deﬁned over Y = {−1  1}n and its pairwise interactions favor adjacent states to
have the same label  i.e.  θi j(−1 −1; x  w)+θi j(1  1; x  w) ≥ θi j(−1  1; x  w)+θi j(1 −1; x  w).
In such cases MAP prediction reduces to computing the min-cut (graph-cuts) algorithm.
Recently  a sequence of works attempt to solve the MAP prediction task for non-supermodular
potential function as well as general regions. These cases usually involve potentials function that
are described by a family R of subsets of variables r ⊂ {1  ...  n}  called regions. We denote by yr
the set of labels that correspond to the region r  namely (yi)i∈r and consider the following potential
r∈R θr(yr; x  w). Thus  MAP prediction can be formulated as an integer

functions θ(y; x  w) =(cid:80)
(cid:88)

linear program:

b∗ ∈ arg max

br(yr)

s.t.

r yr

br(yr) ∈ {0  1} 

br(yr) = 1 

br(yr)θr(yr; x  w)

(cid:88)

yr

(4)

bs(ys) = br(yr) ∀r ⊂ s

(cid:88)

ys\yr

The correspondence between MAP prediction and integer linear program solutions is (yw(x))i =
arg maxyi b∗
i (yi). Although integer linear program solvers provide an alternative to MAP predic-
tion  they may be restricted to problems of small size. This restriction can be relaxed when one
replaces the integral constraints br(yr) ∈ {0  1} with nonnegative constraints br(yr) ≥ 0. These

2

linear program relaxations can be solved efﬁciently using different convex max-product solvers  and
whenever these solvers produce an integral solution it is guaranteed to be the MAP prediction [21].
Given training data of object-label pairs  the learning objective is to estimate a predictive distribution
over the structured-labels. The goodness of ﬁt is measured by a loss function L(ˆy  y). As we focus
on randomized MAP predictors our goal is to learn the parameters w that minimize the expected
perturb-max prediction loss  or randomized risk. We deﬁne the randomized risk at a single instance-
label pair as

(cid:2)ˆy = yγ(x)(cid:3)L(ˆy  y).

R(w  x  y) =

Pγ∼qw

(cid:88)

ˆy∈Y

Alternatively  the randomized risk takes the form R(w  x  y) = Eγ∼qw [L(yγ(x)  y)]. The random-
ized risk originates within the PAC-Bayesian generalization bounds. Intuitively  if the training set is
an independent sample  one would expect that best predictor on the training set to perform well on
unlabeled objects at test time.

3 Minimizing PAC-Bayesian generalization bounds

Our approach is based on the PAC-Bayesian risk analysis of random MAP predictors. In the fol-
lowing we state the PAC-Bayesian generalization bound for structured predictors and describe the
gradients of these bounds for any smooth posterior distribution.
The PAC-Bayesian generalization bound describes the expected loss  or randomized risk  when con-
sidering the true distributions over object-labels in the world R(w) = E(x y)∼ρ [R(w  x  y)]. It upper
bounds the randomized risk by the empirical randomized risk RS(w) = 1|S|
(x y)∈S R(w  x  y)
and a penalty term which decreases proportionally to the training set size. Here we state the PAC-
Bayesian theorem  that holds uniformly for all posterior distributions over the predictions.
Theorem 1. (Catoni [3]  see also [5]). Let L(ˆy  y) ∈ [0  1] be a bounded loss function. Let
p(γ) be any probability density function and let qw(γ) be a family of probability density functions
any real number λ > 0  with probability at least 1− δ over the draw of the training set the following
holds simultaneously for all w

parameterized by w. Let KL(qw||p) =(cid:82) qw(γ) log(qw(γ)/p(γ)). Then  for any δ ∈ (0  1] and for

(cid:80)

R(w) ≤

1

1 − exp(−λ)

λRS(w) +

KL(qw||p) + log(1/δ)

|S|

(cid:18)

(cid:19)

For completeness we present a proof sketch for the theorem in the appendix. This proof follows
Seeger’s PAC-Bayesian approach [19]  and extended to the structured label case [13]. The proof
technique replaces prior randomized risk  with the posterior randomized risk that holds uniformly
for every w  while penalizing this change by their KL-divergence. This change-of-measure step is
close in spirit to the one that is performed in importance sampling. The proof is then concluded by
simple convex bound on the moment generating function of the empirical risk.
To ﬁnd the best posterior distribution that minimizes the randomized risk  one can minimize its
empirical upper bound. We show that whenever the posterior distributions have smooth probability
density functions qw(γ)  the perturb-max probability model is smooth as a function of w. Thus the
randomized risk bound can be minimized with gradient methods.
Theorem 2. Assume qw(γ) is smooth as a function of its parameters  then the PAC-Bayesian bound
is smooth as a function of w:

Moreover  the KL-divergence is a smooth function of w and its gradient takes the form:

∇wKL(qw||p) = Eγ∼qw

Proof: First we note that R(w  x  y) =(cid:82) qw(γ)L(yγ(x)  y)dγ. Since qw(γ) is a probability density

function and L(ˆy  y) ∈ [0  1] we can differentiate under the integral (cf. [4] Theorem 2.27).

(x y)∈S

Eγ∼qw

(cid:105)
(cid:104)∇w[log qw(γ)]L(yγ(x)  y)
(cid:88)
(cid:17)(cid:105)
(cid:104)∇w[log qw(γ)](cid:0) log(qw(γ)/p(γ)) + 1
(cid:90)

∇wqw(γ)L(yγ(x)  y)dγ

∇wRS(w) =

1
|S|

∇wR(w  x  y) =

3

Using the identity ∇wqw(γ) = qw(γ)∇w log(qw(γ)) the ﬁrst part of the proof follows. The
second part of the proof follows in the same manner  while noting that ∇w(qw(γ) log qw(γ)) =
(∇wqw(γ))(log qw(γ) + 1). (cid:3)
The gradient of the randomized empirical risk is governed by the gradient of the log-probability
density function of its corresponding posterior model. For example  Gaussian model with mean w
and identity covariance matrix has the probability density function qw(γ) ∝ exp(−(cid:107)γ − w(cid:107)2/2) 
thus the gradient of its log-density is the linear moment γ  i.e.  ∇w[log qw] = γ − w.
Taking any smooth distribution qw(γ)  we can ﬁnd the parameters w by descending along the
stochastic gradient of the PAC-Bayesian generalization bound. The gradient of the random-
ized empirical risk is formed by two expectations  over the sample points and over the poste-
rior distribution. Computing these expectations is time consuming  thus we use a single sam-
ple ∇γ[log qw(γ)]L(yγ(x)  y) as an unbiased estimator for the gradient. Similarly we estimate
the gradient of the KL-divergence with an unbiased estimator which requires a single sample of
∇w[log qw(γ)](log(qw(γ)/p(γ)) + 1). This approach  called stochastic approximation or online
gradient descent  amounts to use the stochastic gradient update rule

w ← w − η · λ∇w[log qw(γ)]

L(yγ(x)  y) + log(qw(γ)/p(γ)) + 1

(cid:16)

(cid:17)

where η is the learning rate. Next  we explore different posterior distributions from computational
perspectives. Speciﬁcally  we show how to learn the posterior model so to ensure the computational
efﬁciency of its MAP predictor.

4 Learning posterior distributions efﬁciently

The ability to efﬁciently apply MAP predictors is key to the success of the learning process. Al-
though MAP predictions are NP-hard in general  there are posterior models for which they can
be computed efﬁciently. For example  whenever the potential function corresponds to a graphical
model with no cycles  MAP prediction can be efﬁciently computed for any learned parameters w.
Learning unconstrained parameters with random MAP predictors provides some freedom in choos-
ing the posterior distribution. In fact  Theorem 2 suggests that one can learn any posterior distri-
bution by performing gradient descent on its risk bound  as long as its probability density function
is smooth. We show that for unconstrained parameters  additive posterior distributions simplify the
learning problem  and the complexity of the bound (i.e.  its KL-divergence) mostly depends on its
prior distribution.
Corollary 1. Let q0(γ) be a smooth probability density function with zero mean and set the posterior
distribution using additive shifts qw(γ) = q0(γ − w). Let H(q) = −Eγ∼q[log q(γ)] be the entropy
function. Then

KL(qw||p) = −H(q0) − Eγ∼q0[log p(γ + w)]
In particular  if p(γ) ∝ exp(−(cid:107)γ(cid:107)2) is Gaussian then ∇wKL(qw||p) = w
Proof: KL(qw||p) = −H(qw) − Eγ∼qw [log p(γ)]. By a linear change of variable  ˆγ = γ − w it
follows that H(qw) = H(q0) thus ∇wH(qw) = 0. Similarly Eγ∼qw [log p(γ)] = Eγ∼q0[log p(γ +
w)]. Finally  if p(γ) is Gaussian then Eγ∼q0[log p(γ + w)] = −w2 − Eγ∼q0 [γ2]. (cid:3)
This result implies that every additively-shifted smooth posterior distribution may consider the KL-
divergence penalty as the square regularization when using a Gaussian prior p(γ) ∝ exp(−(cid:107)γ(cid:107)2).
This generalizes the standard claim on Gaussian posterior distributions [11]  for which q0(γ) are
Gaussians. Thus one can use different posterior distributions to better ﬁt the randomized empirical
risk  without increasing the computational complexity over Gaussian processes.
Learning unconstrained parameters can be efﬁciently applied to tree structured graphical models.
This  however  is restrictive. Many practical problems require more complex models  with many
cycles. For some of these models linear program solvers give efﬁcient  although sometimes approx-
imate  MAP predictions. For supermodular models there are speciﬁc solvers  such as graph-cuts 
that produce fast and accurate MAP predictions. In the following we show how to deﬁne posterior
distributions that guarantee efﬁcient predictions  thus allowing efﬁcient sampling and learning.

4

4.1 Learning constrained posterior models

MAP predictions can be computed efﬁciently in important practical cases  e.g.  supermodular poten-
tial functions satisfying θi j(−1 −1; x  w) + θi j(1  1; x  w) ≥ θi j(−1  1; x  w) + θi j(1 −1; x  w).
Whenever we restrict ourselves to symmetric potential function θi j(yi  yj; x  w) = wi jyiyj  super-
modularity translates to nonnegative constraint on the parameters wi j ≥ 0.
In order to model
posterior distributions that allow efﬁcient sampling we deﬁne models over the constrained param-
eter space. Unfortunately  the additive posterior models qw(γ) = q0(γ − w) are inappropriate for
this purpose  as they have a positive probability for negative γ values and would generate non-
supermodular models.
To learn constrained parameters one requires posterior distributions that respect these constraints.
For nonnegative parameters we apply posterior distributions that are deﬁned on the nonnegative
real numbers. We suggest to incorporate the parameters of the posterior distribution in a multi-
plicative manner into a distribution over the nonnegative real numbers. For any distribution qα(γ)
we determine a posterior distribution with parameters w as qw(γ) = qα(γ/w)/w. We show that
multiplicative posterior models naturally provide log-barrier functions over the constrained set of
nonnegative numbers. This property is important to the computational efﬁciency of the bound min-
imization algorithm.
Corollary 2. For any probability distribution qα(γ)  let qα w(γ) = qα(γ/w)/w be the parametrized
posterior distribution. Then

Deﬁne the Gamma function Γ(α) =(cid:82) ∞

KL(qα w||p) = −H(qα) − log w − Eγ∼qα [log p(wγ)]

0 γα−1 exp(−γ). If p(γ) = qα(γ) = γα−1 exp(−γ)/Γ(α)
have the Gamma distribution with parameter α  then Eγ∼qα [log p(wγ)] = (α − 1) log w − αw.
Alternatively  if p(γ) are truncated Gaussians then Eγ∼qα [log p(wγ)] = − α
Proof: The entropy of multiplicative posterior models naturally implies the log-barrier function:

2 w2 + log(cid:112)π/2.

(cid:90)

(cid:16)

(cid:17)

−H(qα w)

ˆγ=γ/w

=

qα(ˆγ)

log qα(ˆγ) − log w

dˆγ = −H(qα) − log w.

Similarly  Eγ∼qα w [log p(γ)] = Eγ∼qα[log p(wγ)]. The special cases for the Gamma and the trun-
cated normal distribution follow by a direct computation. (cid:3)
The multiplicative posterior distribution would provide the barrier function − log w as part of its KL-
divergence. Thus the multiplicative posterior effortlessly enforces the constraints of its parameters.
This property suggests that using multiplicative rules are computationally favorable. Interestingly 
using a prior model with Gamma distribution adds to the barrier function a linear regularization
term (cid:107)w(cid:107)1 that encourages sparsity. On the other hand  a prior model with a truncated Gaussian
adds a square regularization term which drifts the nonnegative parameters away from zero. A com-
putational disadvantage of the Gaussian prior is that its barrier function cannot be controlled by a
parameter α.

4.2 Learning posterior models with approximate MAP predictions

MAP prediction can be phrased as an integer linear program  stated in Equation (4). The computa-
tional burden of integer linear programs can be relaxed when one replaces the integral constraints
with nonnegative constraints. This approach produces approximate MAP predictions. An important
learning challenge is to extend the predictive distribution of perturb-max models to incorporate ap-
proximate MAP solutions. Approximate MAP predictions are are described by the feasible set of
their linear program relaxations  that is usually called the local polytope:

L(R) =

br(yr) : br(yr) ≥ 0 

br(yr) = 1  ∀r ⊂ s

bs(ys) = br(yr)

(cid:111)

(cid:110)

(cid:88)

yr

(cid:88)

ys\yr

Linear programs solutions are usually the extreme points of their feasible polytope. The local poly-
tope is deﬁned by a ﬁnite set of equalities and inequalities  thus it has a ﬁnite number of extreme
points. The perturb-max model that is deﬁned in Equation (3) can be effortlessly extended to the
ﬁnite set of the local polytope extreme points [15]. This approach has two ﬂaws. First  linear pro-
gram solutions might not be extreme points  and decoding such a point usually requires additional

5

computational effort. Second  without describing the linear program solutions one cannot incorpo-
rate loss functions that take the structural properties of approximate MAP predictions into account
when computing the the randomized risk.
Theorem 3. Consider approximate MAP predictions that arise from relaxation of the MAP predic-
tion problem in Equation (4).

(cid:88)

r yr

arg max
br(yr)

br(yr)θr(yr; x  w)

s.t. b ∈ L(R)

Then any optimal solution b∗ is described by a vector ˜yw(x) in the ﬁnite power sets over the regions 
˜Y ⊂ ×r2Yr:

˜yw(x) = (˜yw r(x))r∈R

where

˜yw r(x) = {yr : b∗

r(yr) > 0}

Moreover  if there is a unique optimal solution b∗ then it corresponds to an extreme point in the local
polytope.

Proof: The program is convex over a compact set  thus strong duality holds. Fixing the Lagrange
bs(ys) = br(yr)  and con-
sidering the probability constraints as the domain of the primal program  we derive the dual program

multipliers λr→s(yr) that correspond to the marginal constraints(cid:80)
λc→r(yc) − (cid:88)

θr(yr; x  w) +

(cid:88)

λr→p(yr)

(cid:110)

(cid:111)

ys\yr

c:c⊂r

p:p⊃r

(cid:80)
c:c⊂r λ∗

p:p⊃r λ∗

Lagrange optimality constraints (or equivalently  Danskin Theorem) determine the primal op-
r(yr) to be probability distributions over the set arg maxyr{θr(yr; x  w) +
timal solutions b∗
r→p(yr)} that satisfy the marginalization constraints. Thus ˜yw r(x)
is the information that identiﬁes the primal optimal solutions  i.e.  any other primal feasible solution
that has the same ˜yw r(x) is also a primal optimal solution. (cid:3)
This theorem extends Proposition 3 in [6] to non-binary and non-pairwise graphical models. The
theorem describes the discrete structures of approximate MAP predictions. Thus we are able to
deﬁne posterior distributions that use efﬁcient  although approximate  predictions while taking into
account their structures. To integrate these posterior distributions to randomized risk we extend the
loss function to L(˜yw(x)  y). One can verify that the results in Section 3 follow through  e.g.  by
considering loss functions L : ˜Y × ˜Y → [0  1] while the training examples labels belong to the
subset Y ⊂ ˜Y .

(cid:88)
c→r(yc) −(cid:80)

r

max

yr

5 Empirical evaluation

We perform experiments on an interactive image segmentation. We use the Grabcut dataset proposed
by Blake et al. [1] which consists of 50 images of objects on cluttered backgrounds and the goal is
to obtain the pixel accurate segmentations of the object given an initial “trimap” (see Figure 1). A
trimap is an approximate segmentation of the image into regions that are well inside  well outside
and the boundary of the object  something a user can easily specify in an interactive application.
tion over foreground/background segmentations Y = {−1  1}n: θ(y; x  w) =(cid:80)
A popular approach for segmentation is the GrabCut approach [2  1]. We learn parameters for the
(cid:80)
“Gaussian Mixture Markov Random Field” (GMMRF) formulation of [1] using a potential func-
l∈V θi(yi; x  w) +
i j∈E θi j(yi  yj; x  w). The local potentials are θi(yi; x  w) = wyi log P (yi|x)  where wyi are
parameters to be learned while P (yi|x) are obtained from a Gaussian mixture model learned on the
background and foreground pixels for an image x in the initial trimap. The pairwise potentials are
θi j(yi  yj; x  w) = wa exp(−(xi − xj)2)yiyj  where xi denotes the intensity of image x at pixel
i  and wa are the parameters to be learned for the angles a ∈ {0  90  45 −45}◦. These potential
functions are supermodular as long as the parameters wa are nonnegative  thus MAP prediction can
be computed efﬁciently with the graph-cuts algorithm. For these parameters we use multiplicative
posterior model with the Gamma distribution. The dataset does not come with a standard train-
ing/test split so we use the odd set of images for training and even set of images for testing. We use
stochastic gradient descent with the step parameter decaying as ηt = η

to+t for 250 iterations.

6

Method

Our method

Structured SVM (hamming loss)
Structured SVM (all-zero loss)

GMMRF (Blake et al. [1])
Perturb-and-MAP ([17])

Grabcut loss

7.77%
9.74%
7.87%
7.88%
8.19%

PASCAL loss

5.29%
6.66%
5.63%
5.85%
5.76%

Table 1: Learning the Grabcut segmentations using two different loss functions. Our learned param-
eters outperform structured SVM approaches and Perturb-and-MAP moment matching

Figure 1: Two examples of image (left)  input “trimap” (middle) and the ﬁnal segmentation (right)
produced using our learned parameters.

We use two different loss functions for training/testing for our approach to illustrate the ﬂexibility of
our approach for learning using various task speciﬁc loss functions. The “GrabCut loss” measures
the fraction of incorrect pixels labels in the region speciﬁed as the boundary in the trimap. The
“PASCAL loss”  which is commonly used in several image segmentation benchmarks  measures the
ratio of the intersection and union of the foregrounds of ground truth segmentation and the solution.
As a comparison we also trained parameters using moment matching of MAP perturbations [17] and
structured SVM. We use a stochastic gradient approach with a decaying step size for 1000 iterations.
Using structured SVM  solving loss-augmented inference maxˆy∈Y {L(y  ˆy) + θ(y; x  w)} with the
hamming loss can be efﬁciently done using graph-cuts. We also consider learning parameters with
all-zero loss function  i.e.  L(y  ˆy) ≡ 0. To ensure that the weights remain non-negative we project
the weights into the non-negative side after each iteration.
Table 1 shows the results of learning using various methods. For the GrabCut loss  our method
obtains comparable results to the GMMRF framework of [1]  which used hand-tuned parameters.
Our results are signiﬁcantly better when PASCAL loss is used. Our method also outperforms the
parameters learned using structured SVM and Perturb-and-MAP approaches. In our experiments the
structured SVM with the hamming loss did not perform well – the loss augmented inference tended
to focus on maximum violations instead of good solutions which causes the parameters to change
even though the MAP solution has a low loss (a similar phenomenon was observed in [22]). Using
the all-zero loss tends to produce better results in practice as seen in Table 1. Figure 1 shows some
examples images  the input trimap  and the segmentations obtained using our approach.

6 Related work

Recent years have introduced many optimization techniques that lend efﬁcient MAP predictors for
complex models. These MAP predictors can be integrated to learn complex models using structured-
SVM [25]. Structured-SVM has a drawback  as its MAP prediction is adjusted by the loss function 
therefore it has an augmented complexity. Recently  there has been an effort to efﬁciently integrate
non-decomposable loss function into structured-SVMs [24]. However this approach does not hold
for any loss function.
Bayesian approaches to loss minimization treat separately the prediction process and the loss in-
curred  [12]. However  the Bayesian approach depends on the efﬁciency of its sampling procedure 
but unfortunately  sampling in complex models is harder that the MAP prediction task [7].
The recent works [17  23  8  9  16] integrate efﬁcient MAP predictors into Bayesian modeling. [23]
describes the Bayesian perspectives  while [17  8] describe their relations to the Gibbs distribu-
tion and moment matching. [9] provide unbiased samples form the Gibbs distribution using MAP
predictors and [16] present their measure concentration properties. Other strategies for producing

7

(pseudo) samples efﬁciently include Herding [26]. However  these approaches do not consider risk
minimization.
The perturb-max models in Equation (3) play a key role in PAC-Bayesian theory [14  11  19  3  20  5 
10]. The PAC-Bayesian approaches focus on generalization bounds to the object-label distribution.
However  the posterior models in the PAC-Bayesian approaches were not extensively studied in the
past. In most cases the posterior model remained undeﬁned. [10] investigate linear predictors with
Gaussian posterior models to have a structured-SVM like bound. This bound holds uniformly for
every λ and its derivation is quite involved. In contrast we use Catoni’s PAC-Bayesian bound that
is not uniform over λ but does not require the log |S| term [3  5]. The simplicity of Catoni’s bound
(see Appendix) makes it amenable to different extensions. In our work  we extend these results
to smooth posterior distributions  while maintaining the quadratic regularization form. We also
describe posterior distributions for non-linear models. In different perspective  [3  5] describe the
optimal posterior  but unfortunately there is no efﬁcient sampling procedure for this posterior model.
In contrast  our work explores posterior models which allow efﬁcient sampling. We investigate two
posterior models: the multiplicative models  for constrained MAP solvers such as graph-cuts  and
posterior models for approximate MAP solutions.

7 Discussion

Learning complex models requires one to consider non-decomposable loss functions that take into
account the desirable structures. We suggest to use the Bayesian perspectives to efﬁciently sample
and learn such models using random MAP predictions. We show that any smooth posterior distri-
bution would sufﬁce to deﬁne a smooth PAC-Bayesian risk bound which can be minimized using
gradient decent. In addition  we relate the posterior distributions to the computational properties
of the MAP predictors. We suggest multiplicative posterior models to learn supermodular potential
functions that come with specialized MAP predictors such as graph-cuts algorithm. We also describe
label-augmented posterior models that can use efﬁcient MAP approximations  such as those arising
from linear program relaxations. We did not evaluate the performance of these posterior models and
further explorations of such models is required.
The results here focus on posterior models that would allow for efﬁcient sampling using MAP pre-
dictions. There are other cases for which speciﬁc posterior distributions might be handy  e.g.  learn-
ing posterior distributions of Gaussian mixture models. In these cases  the parameters include the
covariance matrix  thus would require to sample over the family of positive deﬁnite matrices.

A Proof sketch for Theorem 1

Theorem 2.1 in [5]: For any distribution D over object-labels pairs  for any w-parametrized
distribution qw  for any prior distribution p  for any δ ∈ (0  1]  and for any convex function
D : [0  1] × [0  1] → R  with probability at least 1 − δ over the draw of the training set the di-
vergence D(Eγ∼qw RS(γ)  Eγ∼qw R(γ)) is upper bounded simultaneously for all w by

Eγ∼pES∼Dm exp(cid:0)mD(RS(γ)  R(γ))(cid:1)(cid:17)(cid:105)

(cid:16) 1

δ

(cid:104)

1
|S|

KL(qw||p) + log

moment generating function of the empirical risk: ES∼Dm exp(cid:0)mD(RS(γ  x  y)  R(γ  x  y))(cid:1) =

For D(RS(γ)  R(γ)) = F(R(γ)) − λRS(γ)  the bound reduces to a simple convex bound on the
exp(mF(R(γ)))ES∼Dm exp(−mλRS(γ)) Since the exponent function is a convex function of
RS(γ) = RS(γ) · 1 + (1 − RS(γ)) · 0  the moment generating function bound is exp(−λRS(γ)) ≤
RS(γ) exp(−λ) + (1 − RS(γ)). Since ESRS(γ) = R(γ)  the right term in the risk bound in
can be made 1 when choosing F(R(γ)) to be the inverse of the moment generating function
bound. This is Catoni’s bound [3  5] for the structured labels case. To derive Theorem 1 we ap-
ply exp(−x) ≤ 1 − x to derive the lower bound (1 − exp(−λ))Eγ∼qw R(γ) − λEγ∼qw RS(γ) ≤
D(Eγ∼qw RS(γ)  Eγ∼qw R(γ)).

8

References
[1] Andrew Blake  Carsten Rother  Matthew Brown  Patrick Perez  and Philip Torr. Interactive

image segmentation using an adaptive gmmrf model. In ECCV 2004  pages 428–441. 2004.

[2] Y. Boykov  O. Veksler  and R. Zabih. Fast approximate energy minimization via graph cuts.

PAMI  2001.

[3] O. Catoni. Pac-bayesian supervised classiﬁcation: the thermodynamics of statistical learning.

arXiv preprint arXiv:0712.0248  2007.

[4] G.B. Folland. Real analysis: Modern techniques and their applications  john wiley & sons.

New York  1999.

[5] P. Germain  A. Lacasse  F. Laviolette  and M. Marchand. Pac-bayesian learning of linear

classiﬁers. In ICML  pages 353–360. ACM  2009.

[6] A. Globerson and T. S. Jaakkola. Fixing max-product: Convergent message passing algorithms

for MAP LP-relaxations. Advances in Neural Information Processing Systems  21  2007.

[7] L.A. Goldberg and M. Jerrum. The complexity of ferromagnetic ising with local ﬁelds. Com-

binatorics Probability and Computing  16(1):43  2007.

[8] T. Hazan and T. Jaakkola. On the partition function and random maximum a-posteriori pertur-

bations. In Proceedings of the 29th International Conference on Machine Learning  2012.

[9] T. Hazan  S. Maji  and T. Jaakkola. On sampling from the gibbs distribution with random
maximum a-posteriori perturbations. Advances in Neural Information Processing Systems 
2013.

[10] J. Keshet  D. McAllester  and T. Hazan. Pac-bayesian approach for minimization of phoneme

error rate. In ICASSP  2011.

[11] John Langford and John Shawe-Taylor. Pac-bayes & margins. Advances in neural information

processing systems  15:423–430  2002.

[12] Erich Leo Lehmann and George Casella. Theory of point estimation  volume 31. 1998.
[13] Andreas Maurer. A note on the pac bayesian theorem. arXiv preprint cs/0411099  2004.
[14] D. McAllester. Simpliﬁed pac-bayesian margin bounds. Learning Theory and Kernel Ma-

chines  pages 203–215  2003.

[15] D. McAllester  T. Hazan  and J. Keshet. Direct loss minimization for structured prediction.

Advances in Neural Information Processing Systems  23:1594–1602  2010.

[16] Francesco Orabona  Tamir Hazan  Anand D Sarwate  and Tommi. Jaakkola. On measure con-

centration of random maximum a-posteriori perturbations. arXiv:1310.4227  2013.

[17] G. Papandreou and A. Yuille. Perturb-and-map random ﬁelds: Using discrete optimization to

learn and sample from energy models. In ICCV  Barcelona  Spain  November 2011.

[18] A.M. Rush and M. Collins. A tutorial on dual decomposition and lagrangian relaxation for

inference in natural language processing.

[19] Matthias Seeger. Pac-bayesian generalisation error bounds for gaussian process classiﬁcation.

The Journal of Machine Learning Research  3:233–269  2003.

[20] Yevgeny Seldin. A PAC-Bayesian Approach to Structure Learning. PhD thesis  2009.
[21] D. Sontag  T. Meltzer  A. Globerson  T. Jaakkola  and Y. Weiss. Tightening LP relaxations for

MAP using message passing. In Conf. Uncertainty in Artiﬁcial Intelligence (UAI)  2008.
[22] Martin Szummer  Pushmeet Kohli  and Derek Hoiem. Learning crfs using graph cuts.

In

Computer Vision–ECCV 2008  pages 582–595. Springer  2008.

[23] D. Tarlow  R.P. Adams  and R.S. Zemel. Randomized optimum models for structured predic-

tion. In AISTATS  pages 21–23  2012.

[24] Daniel Tarlow and Richard S Zemel. Structured output learning with high order loss functions.
In International Conference on Artiﬁcial Intelligence and Statistics  pages 1212–1220  2012.
[25] B. Taskar  C. Guestrin  and D. Koller. Max-margin Markov networks. Advances in neural

information processing systems  16:51  2004.

[26] Max Welling. Herding dynamical weights to learn. In Proceedings of the 26th Annual Inter-

national Conference on Machine Learning  pages 1121–1128. ACM  2009.

9

,Tamir Hazan
Subhransu Maji
Joseph Keshet
Tommi Jaakkola
Lin Song
Yanwei Li
Zeming Li
Gang Yu
Hongbin Sun
Jian Sun
Nanning Zheng