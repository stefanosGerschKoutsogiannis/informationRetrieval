2018,Scalable End-to-End Autonomous Vehicle Testing via Rare-event Simulation,While recent developments in autonomous vehicle (AV) technology highlight substantial progress  we lack tools for rigorous and scalable testing. Real-world testing  the de facto evaluation environment  places the public in danger  and  due to the rare nature of accidents  will require billions of miles in order to statistically validate performance claims. We implement a simulation framework that can test an entire modern autonomous driving system  including  in particular  systems that employ deep-learning perception and control algorithms. Using adaptive importance-sampling methods to accelerate rare-event probability evaluation  we estimate the probability of an accident under a base distribution governing standard traffic behavior. We demonstrate our framework on a highway scenario  accelerating system evaluation by 2-20 times over naive Monte Carlo sampling methods and 10-300P times (where P is the number of processors) over real-world testing.,Scalable End-to-End Autonomous Vehicle

Testing via Rare-event Simulation

Matthew O’Kelly∗

University of Pennsylvania
mokelly@seas.upenn.edu

Aman Sinha∗

Stanford University

amans@stanford.edu

Hongseok Namkoong∗
Stanford University

hnamk@stanford.edu

John Duchi

Stanford University

jduchi@stanford.edu

Massachusetts Institute of Technology

Russ Tedrake

russt@mit.edu

Abstract

While recent developments in autonomous vehicle (AV) technology highlight
substantial progress  we lack tools for rigorous and scalable testing. Real-world
testing  the de facto evaluation environment  places the public in danger  and  due
to the rare nature of accidents  will require billions of miles in order to statistically
validate performance claims. We implement a simulation framework that can test
an entire modern autonomous driving system  including  in particular  systems
that employ deep-learning perception and control algorithms. Using adaptive
importance-sampling methods to accelerate rare-event probability evaluation  we
estimate the probability of an accident under a base distribution governing standard
trafﬁc behavior. We demonstrate our framework on a highway scenario  acceler-
ating system evaluation by 2-20 times over naive Monte Carlo sampling methods
and 10-300P times (where P is the number of processors) over real-world testing.

1

Introduction

Recent breakthroughs in deep learning have accelerated the development of autonomous vehicles
(AVs); many research prototypes now operate on real roads alongside human drivers. While advances
in computer-vision techniques have made human-level performance possible on narrow perception
tasks such as object recognition  several fatal accidents involving AVs underscore the importance of
testing whether the perception and control pipeline—when considered as a whole system—can safely
interact with humans. Unfortunately  testing AVs in real environments  the most straightforward
validation framework for system-level input-output behavior  requires prohibitive amounts of time
due to the rare nature of serious accidents [49]. Concretely  a recent study [29] argues that AVs need
to drive “hundreds of millions of miles and  under some scenarios  hundreds of billions of miles
to create enough data to clearly demonstrate their safety.” Alteratively  formally verifying an AV
algorithm’s “correctness” [34  2  47  37] is difﬁcult since all driving policies are subject to crashes
caused by other drivers [49]. It is unreasonable to ask that the policy be safe under all scenarios.
Unfortunately  ruling out scenarios where the AV should not be blamed is a task subject to logical
inconsistency  combinatorial growth in speciﬁcation complexity  and subjective assignment of fault.
Motivated by the challenges underlying real-world testing and formal veriﬁcation  we consider
a probabilistic paradigm—which we call a risk-based framework—where the goal is to evaluate
the probability of an accident under a base distribution representing standard trafﬁc behavior. By
assigning learned probability values to environmental states and agent behaviors  our risk-based

∗Equal contribution

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

Figure 1. Multi-lane highway driving on I-80: (left) real image  (right) rendered image from simulator

framework considers performance of the AV’s policy under a data-driven model of the world. To
efﬁciently evaluate the probability of an accident  we implement a photo-realistic and physics-based
simulator that provides the AV with perceptual inputs (e.g. video and range data) and trafﬁc conditions
(e.g. other cars and pedestrians). The simulator allows parallelized  faster-than-real-time evaluations
in varying environments (e.g. weather  geographic locations  and aggressiveness of other cars).
Formally  we let P0 denote the base distribution that models standard trafﬁc behavior and X ∼ P0
be a realization of the simulation (e.g. weather conditions and driving policies of other agents). For
an objective function f : X → R that measures “safety”—so that low values of f (x) correspond to
dangerous scenarios—our goal is to evaluate the probability of a dangerous event

pγ := P0(f (X) ≤ γ)

(1)
for some threshold γ. Our risk-based framework is agnostic to the complexity of the ego-policy
and views it as a black-box module. Such an approach allows  in particular  deep-learning based
perception systems that make formal veriﬁcation methods intractable.
An essential component of this approach is to estimate the base distribution P0 from data; we use
public trafﬁc data collected by the US Department of Transportation [36]. While such datasets do
not offer insights into how AVs interact with human agents—this is precisely why we design our
simulator—they illustrate the range of standard human driving behavior that the base distribution
P0 must model. We use imitation learning [45  41  42  22  6] to learn a generative model for the
behavior (policy) of environment vehicles; unlike traditional imitation learning  we train an ensemble
of models to characterize a distribution of human-like driving policies.
As serious accidents are rare (pγ is small)  we view this as a rare-event simulation [4] problem; naive
Monte Carlo sampling methods require prohibitively many simulation rollouts to generate dangerous
scenarios and estimate pγ. To accelerate safety evaluation  we use adaptive importance-sampling
methods to learn alternative distributions Pθ that generate accidents more frequently. Speciﬁcally 
we use the cross-entropy algorithm [44] to iteratively approximate the optimal importance sampling
distribution. In contrast to simple classical settings [44  55] which allow analytic updates to Pθ 
our high-dimensional search space requires solving convex optimization problems in each iteration
(Section 2). To address numerical instabilities of importance sampling estimators in high dimensions 
we carefully design search spaces and perform computations in logarithmic scale. Our implementation
produces 2-20 times as many rare events as naive Monte Carlo methods  independent of the complexity
of the ego-policy.
In addition to accelerating evaluation of pγ  learning a distribution Pθ that frequently generates
realistic dangerous scenarios Xi ∼ Pθ is useful for engineering purposes. The importance-sampling
distribution Pθ not only efﬁciently samples dangerous scenarios  but also ranks them according to
their likelihoods under the base distribution P0. This capability enables a deeper understanding of
failure modes and prioritizes their importance to improving the ego-policy.
As a system  our simulator allows fully distributed rollouts  making our approach orders of magni-
tude cheaper  faster  and safer than real-world testing. Using the asynchronous messaging library
ZeroMQ [21]  our implementation is fully-distributed among available CPUs and GPUs; our rollouts
are up to 30P times faster than real time  where P is the number of processors. Combined with the
cross-entropy method’s speedup  we achieve 10-300P speedup over real-world testing.
In what follows  we describe components of our open-source toolchain  a photo-realistic simulator
equipped with our data-driven risk-based framework and cross-entropy search techniques. The

2

toolchain can test an AV as a whole system  simulating the driving policy of the ego-vehicle by
viewing it as a black-box model. The use of adaptive-importance sampling methods motivates a unique
simulator architecture (Section 3) which allows real-time updates of the policies of environment
vehicles. In Section 4  we test our toolchain by considering an end-to-end deep-learning-based
ego-policy [9] in a multi-agent highway scenario. Figure 1 shows one conﬁguration of this scenario
in the real world along with rendered images from the simulator  which uses Unreal Engine 4 [17].
Our experiments show that we accelerate the assessment of rare-event probabilities with respect to
naive Monte Carlo methods as well as real-world testing. We believe our open-source framework is a
step towards a rigorous yet scalable platform for evaluating AV systems  with the broader goal of
understanding how to reliably deploy deep-learning systems in safety-critical applications.

2 Rare-event simulation

To motivate our risk-based framework  we ﬁrst argue that formally verifying correctness of a AV
system is infeasible due to the challenge of deﬁning “correctness.” Consider a scenario where an
AV commits a trafﬁc violation to avoid collision with an out-of-control truck approaching from
behind. If the ego-vehicle decides to avoid collision by running through a red light with no further
ramiﬁcations  is it “correct” to do so? The “correctness” of the policy depends on the extent to
which the trafﬁc violation endangers nearby humans and whether any element of the “correctness”
speciﬁcation explicitly forbids such actions. That is  “correctness” as a binary output is a concept
deﬁned by its exceptions  many elements of which are subject to individual valuations [10].
Instead of trying to verify correctness  we begin with a continuous measure of safety f : X → R 
where X is space of trafﬁc conditions and behaviors of other vehicles. The prototypical example
in this paper is the minimum time-to-collision (TTC) (see Appendix A for its deﬁnition) to other
environmental agents over a simulation rollout. Rather than requiring safety for all x ∈ X   we
relax the deterministic veriﬁcation problem into a probabilistic one where we are concerned with
the probability under standard trafﬁc conditions that f (X) goes below a safety threshold. Given a
distribution P0 on X   our goal is to estimate the rare event probability pγ := P0(f (X) ≤ γ) based
on simulated rollouts f (X1)  . . .   f (Xn). As accidents are rare and pγ is near 0  we treat this as a
rare-event simulation problem; see [11  4  Chapter VI] for an overview of this topic.
(cid:80)N
First  we brieﬂy illustrate the well-known difﬁculty of naive Monte Carlo simulation when pγ is
i=1 1{f (Xi) ≤ γ}.
small. From a sample Xi
As pγ is small  we use relative accuracy to measure our performance  and the central limit theorem
implies the relative accuracy is approximately
1 − pγ
N pγ

iid∼ P0  the naive Monte Carlo estimate is(cid:98)pN γ := 1
(cid:12)(cid:12)(cid:12)(cid:12) dist≈

N ) for Z ∼ N (0  1).

√
|Z| + o(1/

(cid:115)

N

(cid:12)(cid:12)(cid:12)(cid:12)(cid:98)pN γ

pγ

− 1

For small pγ  we require a sample of size N (cid:38) 1/(pγ2) to achieve -relative accuracy  and if f (X)
is light-tailed  the sample size must grow exponentially in γ.

i=1

p0(Xi)

tion of P0: as p0(x)/p(cid:63)(x) = pγ for all x satisfying 1{f (x) ≤ γ}  the estimate (cid:98)p(cid:63)
(cid:80)N

Cross-entropy method As an alternative to a naive Monte Carlo estimator  we consider (adap-
tive) importance sampling [4]  and we use a model-based optimization procedure to ﬁnd a good
importance-sampling distribution. The optimal importance-sampling distribution for estimating
pγ has the conditional density p(cid:63)(x) = 1{f (x) ≤ γ} p0(x)/pγ  where p0 is the density func-
N γ :=
p(cid:63)(Xi) 1{f (Xi) ≤ γ} is exact. This sampling scheme is  unfortunately  de facto impossible 
1
N
because we do not know pγ. Instead  we use a parameterized importance sampler Pθ and employ an
iterative model-based search method to modify θ so that Pθ approximates P (cid:63).
The cross-entropy method [44] iteratively tries to ﬁnd θ(cid:63) ∈ argminθ∈Θ Dkl (P (cid:63)||Pθ)  the Kullback-
Leibler projection of P (cid:63) onto the class of parameterized distributions P = {Pθ}θ∈Θ. Over iterations
k  we maintain a surrogate distribution qk(x) ∝ 1{f (x) ≤ γk} p0(x) where γk ≥ γ is a (potentially
random) proxy for the rare-event threshold γ  and we use samples from Pθ to update θ as an
approximate projection of Q onto P. The motivation underlying this approach is to update θ so
that Pθ upweights regions of X with low objective value (i.e. unsafe) f (x). We ﬁx a quantile level
ρ ∈ (0  1)—usually we choose ρ ∈ [0.01  0.2]—and use the ρ-quantile of f (X) where X ∼ Pθk

3

Algorithm 1 Cross-Entropy Method
1: Input: Quantile ρ ∈ (0  1)  Stepsizes {αk}k∈N  Sample sizes {Nk}k∈N  Number of iterations K
2: Initialize: θ0 ∈ Θ
3: for k = 0  1  2  . . .   K − 1 do
Sample Xk 1  . . .   Xk Nk
4:
Set γk as the minimum of γ and the ρ-quantile of f (Xk 1)  . . .   f (Xk Nk )
5:
6:
θk+1 = argmaxθ∈Θ

(cid:8)αkθ(cid:62)Dk+1 + (1 − αk)θ(cid:62)∇A(θk) − A(θ)(cid:9)

iid∼ Pθk

as γk  our proxy for the rare event threshold γ (see [23] for alternatives). We have the additional
challenge that the ρ-quantile of f (X) is unknown  so we approximate it using i.i.d. samples Xi ∼ Pθk.
Compared to applications of the cross-entropy method [44  55] that focus on low-dimensional
problems permitting analytic updates to θ  our high-dimensional search space requires solving convex
optimization problems in each iteration. To address numerical challenges in computing likelihood
ratios in high-dimensions  our implementation carefully constrains the search space and we compute
likelihoods in logarithmic scale.
We now rigorously describe the algorithmic details. First  we use natural exponential families as our
class of importance samplers P.
Deﬁnition 1. The family of density functions {pθ}θ∈Θ  deﬁned with respect to base measure µ  is a
natural exponential family if there exists a sufﬁcient statistic Γ such that pθ(x) = exp(θ(cid:62)Γ(x)−A(θ))
X exp(θ(cid:62)Γ(x))dµ(x) is the log partition function and Θ := {θ | A(θ) < ∞}.
Given this family  we consider idealized updates to the parameter vector θk at iteration k  where we
compute projections of a mixture of Qk and Pθk onto P

where A(θ) = log(cid:82)

θk+1 = argmin

θ∈Θ

= argmax

θ∈Θ

= argmax

θ∈Θ

Dkl (αkQk + (1 − αk)Pθk||Pθ)
{αkEQk [log pθ(X)] + (1 − αk)Eθk [log pθ(X)]}

(cid:8)αkθ(cid:62)EQk [Γ(X)] + (1 − αk)θ(cid:62)∇A(θk) − A(θ)(cid:9) .

(2)

iid∼

(3)

Nk(cid:88)

i=1

Nk(cid:88)

i=1

The term EQk [Γ(X)] is unknown in practice  so we use a sampled estimate. For Xk 1  . . .   Xk Nk
Pθk  let γk be the ρ-quantile of f (Xk 1)  . . .   f (Xk Nk ) and deﬁne

Dk+1 :=

1
Nk

qk(Xk i)
pθk (Xk i)

Γ(Xk i) =

1
Nk

p0(Xk i)
pθk (Xk i)

1{f (Xk i) ≤ γk} Γ(Xk i).

i=1

p0(Xi)

(cid:80)N

pθce (Xi) 1{f (Xi) ≤ γ} as our ﬁnal importance-sampling estimator for pγ.

Using the estimate Dk+1 in place of EQk [Γ(X)] in the idealized update (2)  we obtain Algorithm 1.
To select the ﬁnal importance sampling distribution from Algorithm 1  we choose θk with the
lowest ρ-quantile of f (Xk i). We observe that this choice consistently improves performance over
taking the last iterate or Polyak averaging. Letting θce denote the parameters for the importance
sampling distribution learned by the cross-entropy method  we sample Xi
1
N
In the context of our rare-event simulator  we use a combination of Beta and Normal distributions
for Pθ. The sufﬁcient statistics Γ include (i) the parameters of the generative model of behaviors
that our imitation-learning schemes produce and (ii) the initial poses and velocities of other vehicles 
pedestrians  and obstacles in the simulation. Given a current parameter θ and realization from the
model distribution Pθ  our simulator then (i) sets the parameters of the generative model for vehicle
policies and draws policies from this model  and (ii) chooses random poses and velocities for the
simulation. Our simulator is one of the largest-scale applications of cross-entropy methods.

iid∼ Pθce and use(cid:98)pN γ :=

3 Simulation framework

Two key considerations in our risk-based framework inﬂuence design choices for our simulation
toolchain: (1) learning the base distribution P0 of nominal trafﬁc behavior via data-driven modeling 
and (2) testing the AV as a whole system. We now describe how our toolchain achieves these goals.

4

3.1 Data-driven generative modeling

While our risk-based framework (cf. Section 2) is a concise  unambiguous measure of system safety 
the rare-event probability pγ is only meaningful insofar as the base distribution P0 of road conditions
and the behaviors of other (human) drivers is estimable. Thus  to implement our risk-based framework 
we ﬁrst learn a base distribution P0 of nominal trafﬁc behavior. Using the highway trafﬁc dataset
NGSim [36]  we train policies of human drivers via imitation learning [45  41  42  22  6]. Our data
consists of videos of highway trafﬁc [36]  and our goal is to create models that imitate human driving
behavior even in scenarios distinct from those in the data. We employ an ensemble of generative
adversarial imitation learning (GAIL) [22] models to learn P0. Our approach is motivated by the
observation that reducing an imitation-learning problem to supervised learning—where we simply
use expert data to predict actions given vehicle states—suffers from poor performance in regions
of the state space not encountered in data [41  42]. Reinforcement-learning techniques have been
observed to improve generalization performance  as the imitation agent is able to explore regions of
the state space in simulation during training that do not necessarily occur in the expert data traces.
Generically  GAIL is a minimax game between two functions: a discriminator Dφ and a generator
Gξ (with parameters φ and ξ respectively). The discriminator takes in a state-action pair (s  u)
and outputs the probability that the pair came from real data  P(real data). The generator takes in
a state s and outputs a conditional distribution Gξ(s) := P(u | s) of the action u to take given
state s. In our context  Gξ(·) is then the (learned) policy of a human driver given environmental
inputs s. Training the generator weights ξ occurs in a reinforcement-learning paradigm with reward
− log(1 − Dφ(s  Gξ(s))). We use the model-based variant of GAIL (MGAIL) [6] which renders this
reward fully differentiable with respect to ξ over a simulation rollout  allowing efﬁcient model training.
GAIL has been validated by Kueﬂer et al. [33] to realistically mimic human-like driving behavior
from the NGSim dataset across multiple metrics. These include the similarity of low-level actions
(speeds  accelerations  turn-rates  jerks  and time-to-collision)  as well as higher-level behaviors (lane
change rate  collision rate  hard-brake rate  etc). See Appendix C for a reference to an example video
of the learned model driving in a scenario alongside data traces from human drivers.
Our importance sampling and cross-entropy methods use not just a single instance of model parame-
ters ξ  but rather a distribution over them to form a generative model of human driving behavior. To
model this distribution  we use a (multivariate normal) parametric bootstrap over a trained ensemble
of generators ξi  i = 1  . . .   m. Our models ξi are high-dimensional (ξ ∈ Rd  d > m) as they
characterize the weights of large neural networks  so we employ the graphical lasso [15] to ﬁt the
inverse covariance matrix for our ensemble. This approach to modeling uncertainty in neural-network
weights is similar to the bootstrap approach of Osband et al. [38]. Other approaches include using
dropout for inference [16] and variational methods [18  8  31].
While several open source driving simulators have been proposed [14  48  39]  our problem formula-
tion requires unique features to allow sampling from a continuous distribution of driving policies for
environmental agents. Conditional on each sample of model parameters ξ  the simulator constructs
a (random) rollout of vehicle behaviors according to Gξ. Unlike other existing simulators  ours is
designed to efﬁciently execute and update these policies as new samples ξ are drawn for each rollout.

3.2 System architecture

The second key characteristic of our framework is that it enables black-box testing the AV as a whole
system. Flaws in complex systems routinely occur at poorly speciﬁed interfaces between components 
as interactions between processes can induce unexpected behavior. Consequently  solely testing
subcomponents of an AV control pipeline separately is insufﬁcient [1]. Moreover  it is increasingly
common for manufacturers to utilize software and hardware artifacts for which they do not have
any whitebox model [19  12]. We provide a concise but extensible language-agnostic interface to
our benchmark world model so that common AV sensors such as cameras and lidar can provide the
necessary inputs to induce vehicle actuation commands.
Our simulator is a distributed  modular framework  which is necessary to support the inclusion
of new AV systems and updates to the environment-vehicle policies. A beneﬁt of this design is
that simulation rollouts are simple to parallelize. In particular  we allow instantiation of multiple
simulations simultaneously  without requiring that each include the entire set of components. For
example  a desktop may support only one instance of Unreal Engine but could be capable of simulating

5

10 physics simulations in parallel; it would be impossible to fully utilize the compute resource with
a monolithic executable wrapping all engines together. Our architecture enables instances of the
components to be distributed on heterogeneous GPU compute clusters while maintaining the ability to
perform meaningful analysis locally on commodity desktops. In Appendix A  we detail our scenario
speciﬁcation  which describes how Algorithm 1 maps onto our distributed architecture.

4 Experiments

+

In this section  we demonstrate our risk-based framework on a multi-agent highway scenario. As the
rare-event probability of interest pγ gets smaller  the cross-entropy method learns to sample more
rare events compared to naive Monte Carlo sampling; we empirically observe that the cross-entropy
method produces 2-20 times as many rare events as its naive counterpart. Our ﬁndings hold across
different ego-vehicle policies  base distributions P0  and scenarios.
To highlight the modularity of our simulator  we evaluate the rare-event probability pγ on two
different ego-vehicle policies. The ﬁrst is an instantiation of an imitation learning (non-vision) policy
which uses lidar as its primary perceptual input. Secondly  we investigate a vision-based controller
(vision policy)  where the ego-vehicle drives with an end-to-end highway autopilot network [9] 
taking as input a rendered image from the simulator (and lidar observations) and outputting actuation
commands. See Appendix B for a summary of network architectures used.
We consider a scenario consisting of six agents  ﬁve of which are considered part of the environment.
The environment vehicles’ policies follow the distribution learned in Section 3.1. All vehicles are
constrained to start within a set of possible initial conﬁgurations consisting of pose and velocity 
and each vehicle has a goal of reaching the end of the approximately 2 km stretch of road. Fig. 1
shows one such conﬁguration of the scenario  along with rendered images from the simulator. We
create scene geometry based on surveyors’ records and photogrammetric reconstructions of satellite
imagery of the portion of I-80 in Emeryville  California where the trafﬁc data was collected [36].
Simulation parameters We detail our postulated base distribution P0. Letting m denote the number
of vehicles  we consider the random tuple X = (S  T  W  V  ξ) as our simulation parameter where
the pair (S  T ) ∈ Rm×2
indicates the two-dimensional positioning of each vehicle in their respective
lanes (in meters)  W the orientation of each vehicle (in degrees)  and V the initial velocity of each
vehicle (in meters per second). We use ξ ∈ R404 to denote the weights of the last layer of the neural
network trained to imitate human-like driving behavior. Speciﬁcally  we set S ∼ 40Beta(2  2) + 80
with respect to the starting point of the road  T ∼ 0.5Beta(2  2) − 0.25 with respect to the lane’s
center  W ∼ 7.2Beta(2  2) − 3.6 with respect to facing forward  and V ∼ 10Beta(2  2) + 10. We
assume ξ ∼ N (µ0  Σ0)  with the mean and covariance matrices learned via the ensemble approach
outlined in Section 3.1. The neural network whose last layer is parameterized by ξ describes the
policy of environment vehicles; it takes as input the state of the vehicle and lidar observations of the
surrounding environment (see Appendix B for more details). Throughout this section  we deﬁne our
measure of safety f : X → R as the minimum time-to-collision (TTC) over the simulation rollout.
We calculate TTC from the center of mass of the ego vehicle; if the ego-vehicle’s body crashes into
obstacles  we end the simulation before the TTC can further decrease (see Appendix A for details).
Cross-entropy method Throughout our experiments  we impose constraints on the space of
importance samplers (adversarial distributions) for feasibility. Numerical stability considerations
predominantly drive our hyperparameter choices. For model parameters ξ  we also constrain the
search space to ensure that generative models Gξ maintain reasonably realistic human-like policies
(recall Sec. 3.1). For S  T  W   and V   we let {Beta(α  β) : α  β ∈ [1.5  7]} be the model space over
which the cross-entropy method searches  scaled and centered appropriately to match the scale of the
respective base distributions. We restrict the search space of distributions over ξ ∈ R404 by searching
over {N (µ  Σ0) : (cid:107)µ − µ0(cid:107)∞ ≤ .01}  where (µ0  Σ0) are the parameters of the base (bootstrap)
distribution. For our importance sampling distribution Pθ  we use products of the above marginal
distributions. These restrictions on the search space mitigate numerical instabilities in computing
likelihood ratios within our optimization routines  which is important for our high-dimensional
problems.
We ﬁrst illustrate the dependence of the cross-entropy method on its hyperparameters. We choose
to use a non-vision ego-vehicle policy as a test bed for hyperparameter tuning  since this allows us
to take advantage of the fastest simulation speeds for our experiments. We focus on the effects (in

6

(a) Ratio of number of rare events vs. threshold

(b) Ratio of variance vs. threshold

Figure 2. The ratio of (a) number of rare events and (b) variance of estimator for pγ between cross-
entropy method and naive MC sampling for the non-vision ego policy. Rarity is inversely proportional
to γ  and  as expected  we see the best performance for our method over naive MC at small γ.

Naive 1300K

Search Algorithm
γtest = 0.14
(12.4±3.1)e-6
Cross-entropy 100K (19.8±8.88)e-6
(20±14.1)e-6

Naive 100K

γtest = 0.15
(80.6±7.91)e-6
(66.1 ± 15)e-6
(100± 31.6)e-6

γtest = 0.19
(133±3.2)e-5
(108± 9.51)e-5
(132±11.5)e-5

γtest = 0.20
(186±3.79)e-5
(164 ± 14)e-5
(185±13.6)e-5

Table 1. Estimate of rare-event probability pγ (non-vision ego policy) with standard errors. For the
cross-entropy method  we show results for the learned importance sampling distribution with ρ = 0.01.

Algorithm 1) of varying the most inﬂuential hyperparameter  ρ ∈ (0  1]  which is the quantile level
determining the rarity of the observations used to compute the importance sampler θk. Intuitively  as ρ
approaches 0  the cross-entropy method learns importance samplers Pθ that up-weight unsafe regions
of X with lower f (x)  increasing the frequency of sampling rare events (events with f (X) ≤ γ).
In order to avoid overﬁtting θk as ρ → 0  we need to increase Nk as ρ decreases. Our choice of
Nk is borne out of computational constraints as it is the biggest factor that determines the run-time
of the cross-entropy method. Consistent with prior works [44  24]  we observe empirically that
ρ ∈ [0.01  0.2] is a good range for the values of Nk deemed feasible for our computational budget
(Nk = 1000 ∼ 5000). We ﬁx the number of iterations at K = 100  number of samples taken per
iteration at Nk = 5000  step size for updates at αk = 0.8  and γ = 0.14. As we see below  we
consistently observe that the cross-entropy method learns to sample signiﬁcantly more rare events 
despite the high-dimensional nature (d ≈ 500) of the problem.
To evaluate the learned parameters  we draw n = 105 samples from the importance sampling
distribution to form an estimate of pγ. In Figure 2  we vary ρ and report the relative performance of
the cross-entropy method compared to naive Monte Carlo sampling. Even though we set γ = 0.14 in
Algorithm 1  we evaluate the performance of all models with respect to multiple threshold levels γtest.
We note that as ρ approaches 0  the cross-entropy method learns to frequently sample increasingly
rare events; the cross-entropy method yields 3-10 times as many dangerous scenarios  and achieves
2-16 times variance reduction depending on the threshold level γtest. In Table 1  we contrast the
estimates provided by naive Monte Carlo and the importance sampling estimator provided by the
cross-entropy method with ρ = 0.01; to form a baseline estimate  we run naive Monte Carlo with
1.3 · 106 samples. For a given number of samples  the cross-entropy method with ρ = 0.01 provides
more precise estimates for the rare-event probability pγ ≈ 10−5 over naive Monte Carlo.
We now leverage the tuned hyperparameter (ρ = 0.01) for our main experiment: evaluating the
probability of a dangerous event for the vision-based ego policy. We ﬁnd that the hyperparameters
for the cross-entropy method generalize  allowing us to produce good importance samplers for a
very different policy without further tuning. Based on our computational budget (with our current
implementation  vision-based simulations run about 15 times slower than simulations with only
non-vision policies)  we choose K = 20 and Nk = 1000 for the cross-entropy method to learn a
good importance sampling distribution for the vision-based policy (although we also observe similar
behavior for Nk as small as 100). In Figure 3  we illustrate again that the cross-entropy method learns
to sample dangerous scenarios more frequently (Figure 3a)—up to 18 times that of naive Monte

7

0.140.160.180.20.220.240.26234567890.140.160.180.20.220.240.2610-1100101(a) Ratio of number of rare events vs. threshold

(b) Ratio of variance vs. threshold

Figure 3. The ratio of (a) number of rare events and (b) variance of estimator for pγ between cross-
entropy method and naive MC sampling for the vision-based ego policy.

Search Algorithm
γtest = 0.22
Cross-entropy 50K (5.87±1.82)e-5
(11.3±4.60)e-5

Naive 50K

γtest = 0.23
(13.0± 2.94)e-5
(20.6±6.22)e-5

γtest = 0.24
(19.0 ± 3.14)e-5
(43.2±9.00)e-5

γtest = 0.25
(4.52 ± 1.35)e-4
(6.75±1.13)e-4

Table 2. Estimate of rare-event probability pγ (non-vision ego policy) with standard errors. For the
cross-entropy method  we show results for the learned importance sampling distribution with ρ = 0.01.

Carlo—and produces importance sampling estimators with lower variance (Figure 3b). As a result 
our estimator in Table 2 is better calibrated compared to that computed from naive Monte Carlo.
Qualitative analysis We provide a qualitative interpretation for the learned parameters of the
importance sampler. For initial velocities  angles  and positioning of vehicles  the importance sampler
shifts environmental vehicles to box in the ego-vehicle and increases the speeds of trailing vehicles
by 20%  making accidents more frequent. We also observe that the learned distribution for initial
conditions have variance 50% smaller than that of the base distribution  implying concentration
around adversarial conditions. Perturbing the policy weights ξ for GAIL increases the frequency of
risky high-level behaviors (lane-change rate  hard-brake rate  etc.). An interesting consequence of
using our deﬁnition of TTC from the center of the ego vehicle (cf. Appendix A) as a measure of
safety is that dangerous events f (X) ≤ γtest (for small γtest) include frequent sideswiping behavior 
as such accidents result in smaller TTC values than front- or rear-end collisions. See Appendix C
for a reference to supplementary videos that exhibit the range of behavior across many levels γtest.
The modularity of our simulation framework easily allows us to modify the safety objective to an
alternative deﬁnition of TTC or even include more sophisticated notions of safety  e.g. temporal-logic
speciﬁcations or implementations of responsibility-sensitive safety (RSS) [49  40].

5 Related work and conclusions

Given the complexity of AV software and hardware components  it is unlikely that any single method
will serve as an oracle for certiﬁcation. Many existing tools are complementary to our risk-based
framework. In this section  we compare and contrast representative results in testing  veriﬁcation  and
simulation.
AV testing generally consists of three paradigms. The ﬁrst  largely attributable to regulatory efforts 
uses a ﬁnite set of basic competencies (e.g. the Euro NCAP Test Protocol [46]); while this method-
ology is successful in designing safety features such as airbags and seat-belts  the non-adaptive
nature of static testing is less effective in complex software systems found in AVs. Alternatively 
real-world testing—deployment of vehicles with human oversight—exposes the vehicle to a wider
variety of unpredictable test conditions. However  as we outlined above  these methods pose a danger
to the public and require prohibitive number of driving hours due to the rare nature of accidents [29].
Simulation-based falsiﬁcation (in our context  simply ﬁnding any crash) has also been successfully
utilized [51]; this approach does not maintain a link to the likelihood of the occurrence of a particular
event  which we believe to be key in acting to prioritize and correct AV behavior.

8

0.220.240.260.280.324681012141618200.220.240.260.280.310-410-2100Formal veriﬁcation methods [34  2  47  37] have emerged as a candidate to reduce the intractability
of empirical validation. A veriﬁcation procedure considers whether the system can ever violate
a speciﬁcation and returns either a proof that there is no such execution or a counterexample.
Veriﬁcation procedures require a white-box description of the system (although it may be abstract) 
as well as a mathematically precise speciﬁcation. Due to the impossibility of certifying safety in all
scenarios  these approaches [49] require further speciﬁcations that assign blame in the case of a crash.
Such assignment of blame is impossible to completely characterize and relies on subjective notions of
fault. Our risk-based framework allows one to circumvent this difﬁculty by only using a measure of
safety that does not assign blame (e.g. TTC) and replacing the speciﬁcations that assign blame with a
probabilistic notion of how likely the accident is. While this approach requires a learned model of the
world P0—a highly nontrivial statistical task in itself—the adaptive importance sampling techniques
we employ can still efﬁciently identify dangerous scenarios even when P0 is not completely accurate.
Conceptually  we view veriﬁcation and our framework as complementary; they form powerful tools
that can evaluate safety before deploying a ﬂeet for real-world testing.
Even given a consistent and complete notion of blame  veriﬁcation remains highly intractable from
a computational standpoint. Efﬁcient algorithms only exist for restricted classes of systems in the
domain of AVs  and they are fundamentally difﬁcult to scale. Speciﬁcally  AVs—unlike previous
successful applications of veriﬁcation methods to application domains such as microprocessors [5]—
include both continuous and discrete dynamics. This class of dynamics falls within the purview of
hybrid systems [35]  for which exhaustive veriﬁcation is largely undecidable [20].
Verifying individual components of the perception pipeline  even as standalone systems  is a nascent 
active area of research (see [3  13  7] and many others). Current subsystem veriﬁcation techniques
for deep neural networks [28  30  50] do not scale to state-of-the-art models and largely investigate
the robustness of the network with respect to small perturbations of a single sample. There are two
key assumptions in these works; the label of the input is unchanged within the radius of allowable
perturbations  and the resulting expansion of the test set covers a meaningful portion of possible
inputs to the network. Unfortunately  for realistic cases in AVs it is likely that perturbations to
the state of the world which in turn generates an image should change the label. Furthermore  the
combinatorial nature of scenario conﬁgurations casts serious doubt on any claims of coverage.
In our risk-based framework  we replace the complex system speciﬁcations required for formal
veriﬁcation methods with a model P0 that we learn via imitation-learning techniques. Generative
adversarial imitation learning (GAIL) was ﬁrst introduced by Ho and Ermon [22] as a way to directly
learn policies from data and has since been applied to model human driving behavior by Kueﬂer et al.
[33]. Model-based GAIL (MGAIL) is the speciﬁc variant of GAIL that we employ; introduced by
Baram et al. [6]  MGAIL’s generative model is fully differentiable  allowing efﬁcient model training
with standard stochastic approximation methods.
The cross-entropy method was introduced by Rubinstein [43] and has attracted interest in many rare-
event simulation scenarios [44  32]. More broadly  it can be thought of as a model-based optimization
method [24–26  53  27  56]. With respect to assessing safety of AVs  the cross-entropy method has
recently been applied in simple lane-changing and car-following scenarios in two dimensions [54  55].
Our work signiﬁcantly extends these works by implementing a photo-realistic simulator that can
assess the deep-learning based perception pipeline along with the control framework. We leave the
development of rare-event simulation methods that scale better with dimension as a future work.
To summarize  a fundamental tradeoff emerges when comparing the requirements of our risk-based
framework to other testing paradigms  such as real-world testing or formal veriﬁcation. Real-world
testing endangers the public but is still in some sense a gold standard. Veriﬁed subsystems provide
evidence that the AV should drive safely even if the estimated distribution shifts  but veriﬁcation
techniques are limited by computational intractability as well as the need for both white-box models
and the completeness of speciﬁcations that assign blame (e.g. [49]). In turn  our risk-based framework
is most useful when the base distribution P0 is accurate  but even when P0 is misspeciﬁed  our
adaptive importance sampling techniques can still efﬁciently identify dangerous scenarios  especially
those that may be missed by veriﬁcation methods assigning blame. Our framework offers signiﬁcant
speedups over real-world testing and allows efﬁcient evaluation of black-box AV input/output behavior 
providing a powerful tool to aid in the design of safe AVs.

9

Acknowledgments

MOK was partially supported by a National Science Foundation Graduate Research Fellowship. AS
was partially supported by a Stanford Graduate Fellowship and a Fannie & John Hertz Foundation
Fellowship. HN was partially supported by a Samsung Fellowship and the SAIL-Toyota Center for
AI Research. JD was partially supported by the National Science Foundation award NSF-CAREER-
1553086.

References
[1] H. Abbas  M. O’Kelly  A. Rodionova  and R. Mangharam. Safe at any speed: A simulation-

based test harness for autonomous vehicles. LNCS. Springer  2018.

[2] M. Althoff and J. Dolan. Online veriﬁcation of automated road vehicles using reachability
analysis. Robotics  IEEE Transactions on  30(4):903–918  Aug 2014. ISSN 1552-3098. doi:
10.1109/TRO.2014.2312453.

[3] S. Arora  A. Bhaskara  R. Ge  and T. Ma. Provable bounds for learning some deep representa-

tions. In International Conference on Machine Learning  pages 584–592.   2014.

[4] S. Asmussen and P. W. Glynn. Stochastic Simulation: Algorithms and Analysis. Springer  2007.

[5] C. Baier  J.-P. Katoen  et al. Principles of model checking  volume 26202649. MIT press

Cambridge  2008.

[6] N. Baram  O. Anschel  I. Caspi  and S. Mannor. End-to-end differentiable adversarial imitation

learning. In International Conference on Machine Learning  pages 390–399  2017.

[7] P. L. Bartlett  D. J. Foster  and M. J. Telgarsky. Spectrally-normalized margin bounds for neural
networks. In Advances in Neural Information Processing Systems  pages 6241–6250.   2017.

[8] C. Blundell  J. Cornebise  K. Kavukcuoglu  and D. Wierstra. Weight uncertainty in neural

networks. arXiv preprint arXiv:1505.05424  2015.

[9] M. Bojarski  D. Del Testa  D. Dworakowski  B. Firner  B. Flepp  P. Goyal  L. D. Jackel 
M. Monfort  U. Muller  J. Zhang  et al. End to end learning for self-driving cars. arXiv preprint
arXiv:1604.07316  2016.

[10] J.-F. Bonnefon  A. Shariff  and I. Rahwan. The social dilemma of autonomous vehicles.
Science  352(6293):1573–1576  2016. ISSN 0036-8075. doi: 10.1126/science.aaf2654. URL
http://science.sciencemag.org/content/352/6293/1573.

[11] J. Bucklew. Introduction to rare event simulation. Springer Science & Business Media  2013.

[12] M. Cheah  S. A. Shaikh  J. Bryans  and H. N. Nguyen. Combining third party components
securely in automotive systems. In IFIP International Conference on Information Security
Theory and Practice  pages 262–269. Springer  2016.

[13] N. Cohen  O. Sharir  and A. Shashua. On the expressive power of deep learning: A tensor

analysis. In Conference on Learning Theory  pages 698–728.   2016.

[14] A. Dosovitskiy  G. Ros  F. Codevilla  A. Lopez  and V. Koltun. CARLA: An open urban driving
simulator. In Proceedings of the 1st Annual Conference on Robot Learning  pages 1–16  2017.

[15] J. Friedman  T. Hastie  and R. Tibshirani. Sparse inverse covariance estimation with the

graphical lasso. Biostatistics  9(3):432–441  2008.

[16] Y. Gal and Z. Ghahramani. Dropout as a bayesian approximation: Representing model un-
certainty in deep learning. In International Conference on Machine Learningearning  pages
1050–1059  2016.

[17] E. Games.

Unreal engine 4 documentation.

com/latest/INT/index. html  2015.

URL https://docs. unrealengine.

10

[18] A. Graves. Practical variational inference for neural networks. In Advances in Neural Informa-

tion Processing Systems  pages 2348–2356  2011.

[19] H. Heinecke  K.-P. Schnelle  H. Fennel  J. Bortolazzi  L. Lundh  J. Leﬂour  J.-L. Maté 
K. Nishikawa  and T. Scharnhorst. Automotive open system architecture-an industry-wide
initiative to manage the complexity of emerging automotive e/e-architectures. Technical report 
SAE Technical Paper  2004.

[20] T. A. Henzinger  P. W. Kopke  A. Puri  and P. Varaiya. What’s decidable about hybrid automata?

J. Comput. Syst. Sci.  57(1):94–124  1998.

[21] P. Hintjens. ZeroMQ: messaging for many applications. " O’Reilly Media  Inc."  2013.

[22] J. Ho and S. Ermon. Generative adversarial imitation learning. In Advances in Neural Informa-

tion Processing Systems  pages 4565–4573  2016.

[23] T. Homem-de Mello. A study on the cross-entropy method for rare-event probability estimation.

INFORMS Journal on Computing  19(3):381–394  2007.

[24] J. Hu and P. Hu. On the performance of the cross-entropy method. In Simulation Conference

(WSC)  Proceedings of the 2009 Winter  pages 459–468. IEEE  2009.

[25] J. Hu and P. Hu. Annealing adaptive search  cross-entropy  and stochastic approximation in

global optimization. Naval Research Logistics (NRL)  58(5):457–477  2011.

[26] J. Hu  P. Hu  and H. S. Chang. A stochastic approximation framework for a class of randomized

optimization algorithms. IEEE Transactions on Automatic Control  57(1):165–178  2012.

[27] J. Hu  E. Zhou  and Q. Fan. Model-based annealing random search with stochastic averaging.

ACM Transactions on Modeling and Computer Simulation (TOMACS)  24(4):21  2014.

[28] X. Huang  M. Kwiatkowska  S. Wang  and M. Wu. Safety veriﬁcation of deep neural networks.

In International Conference on Computer Aided Veriﬁcation  pages 3–29. Springer  2017.

[29] N. Kalra and S. M. Paddock. Driving to safety: How many miles of driving would it take
to demonstrate autonomous vehicle reliability? Transportation Research Part A: Policy and
Practice  94:182–193  2016.

[30] G. Katz  C. Barrett  D. Dill  K. Julian  and M. Kochenderfer. Reluplex: An efﬁcient smt solver

for verifying deep neural networks. arXiv:1702.01135 [cs.AI]  1:1  2017.

[31] D. P. Kingma  T. Salimans  and M. Welling. Variational dropout and the local reparameterization

trick. In Advances in Neural Information Processing Systems  pages 2575–2583  2015.

[32] D. P. Kroese  R. Y. Rubinstein  and P. W. Glynn. The cross-entropy method for estimation.

Handbook of Statistics: Machine Learning: Theory and Applications  31:19–34  2013.

[33] A. Kueﬂer  J. Morton  T. Wheeler  and M. Kochenderfer.

Imitating driver behavior with
generative adversarial networks. In Intelligent Vehicles Symposium (IV)  2017 IEEE  pages
204–211. IEEE  2017.

[34] M. Kwiatkowska  G. Norman  and D. Parker. Prism 4.0: Veriﬁcation of probabilistic real-time
systems. In International conference on computer aided veriﬁcation  pages 585–591. Springer 
2011.

[35] J. Lygeros. Lecture notes on hybrid systems. In Notes for an ENSIETA workshop  2004.

[36] U. D. of Transportation FHWA. Ngsim – next generation simulation  2008.

[37] M. O’Kelly  H. Abbas  S. Gao  S. Shiraishi  S. Kato  and R. Mangharam. Apex: Autonomous

vehicle plan veriﬁcation and execution. volume 1  Apr 2016.

[38] I. Osband  C. Blundell  A. Pritzel  and B. Van Roy. Deep exploration via bootstrapped dqn. In

Advances in neural information processing systems  pages 4026–4034  2016.

11

[39] C. Quiter and M. Ernst. Deepdrive. https://github.com/deepdrive/deepdrive  2018.

[40] N. Roohi  R. Kaur  J. Weimer  O. Sokolsky  and I. Lee. Self-driving vehicle veriﬁcation towards

a benchmark. arXiv preprint arXiv:1806.08810  2018.

[41] S. Ross and D. Bagnell. Efﬁcient reductions for imitation learning. In Proceedings of the
thirteenth international conference on artiﬁcial intelligence and statistics  pages 661–668  2010.

[42] S. Ross  G. Gordon  and D. Bagnell. A reduction of imitation learning and structured prediction
to no-regret online learning. In Proceedings of the fourteenth international conference on
artiﬁcial intelligence and statistics  pages 627–635  2011.

[43] R. Y. Rubinstein. Combinatorial optimization  cross-entropy  ants and rare events. In Stochastic

optimization: algorithms and applications  pages 303–363. Springer  2001.

[44] R. Y. Rubinstein and D. P. Kroese. The cross-entropy method: A uniﬁed approach to Monte
Carlo simulation  randomized optimization and machine learning. Information Science &
Statistics  Springer Verlag  NY  2004.

[45] S. Russell. Learning agents for uncertain environments. In Proceedings of the eleventh annual

conference on Computational learning theory  pages 101–103. ACM  1998.

[46] R. Schram  A. Williams  and M. van Ratingen. Implementation of autonomous emergency

braking (aeb)  the next step in euro ncap’s safety assessment. ESV  Seoul  2013.

[47] S. A. Seshia  D. Sadigh  and S. S. Sastry. Formal methods for semi-autonomous driving. In

Proceedings of the 52nd Annual Design Automation Conference  page 148. ACM  2015.

[48] S. Shah  D. Dey  C. Lovett  and A. Kapoor. Airsim: High-ﬁdelity visual and physical simulation
for autonomous vehicles. In Field and Service Robotics  2017. URL https://arxiv.org/
abs/1705.05065.

[49] S. Shalev-Shwartz  S. Shammah  and A. Shashua. On a formal model of safe and scalable

self-driving cars. arXiv preprint arXiv:1708.06374  2017.

[50] V. Tjeng and R. Tedrake. Verifying neural networks with mixed integer programming.

arXiv:1711.07356 [cs.LG]  2017.

[51] C. E. Tuncali  T. P. Pavlic  and G. Fainekos. Utilizing s-taliro as an automatic test generation
framework for autonomous vehicles. In Intelligent Transportation Systems (ITSC)  2016 IEEE
19th International Conference on  pages 1470–1475. IEEE  2016.

[52] K. Vogel. A comparison of headway and time to collision as safety indicators. Accident analysis

& prevention  35(3):427–433  2003.

[53] Z. B. Zabinsky. Stochastic adaptive search for global optimization  volume 72. Springer Science

& Business Media  2013.

[54] D. Zhao. Accelerated Evaluation of Automated Vehicles. Ph.D. thesis  Department of Mechanical

Engineering  University of Michigan  2016.

[55] D. Zhao  X. Huang  H. Peng  H. Lam  and D. J. LeBlanc. Accelerated evaluation of automated
vehicles in car-following maneuvers. IEEE Transactions on Intelligent Transportation Systems 
19(3):733–744  2018.

[56] E. Zhou and J. Hu. Gradient-based adaptive stochastic search for non-differentiable optimization.

IEEE Transactions on Automatic Control  59(7):1818–1832  2014.

12

,Matthew O'Kelly
Aman Sinha
Hongseok Namkoong
Russ Tedrake
John Duchi