2019,Causal Regularization,We argue that regularizing terms in standard regression methods not only help against overfitting finite data  but sometimes also help in getting better causal models. We first consider a multi-dimensional variable linearly influencing a target variable with some multi-dimensional unobserved common cause  where the confounding effect can be decreased by keeping the penalizing term in Ridge and Lasso regression even in the population limit. The reason is a close analogy between overfitting and confounding observed for our toy model. In the case of overfitting  we can choose regularization constants via cross validation  but here we choose the regularization constant by first estimating the strength of confounding  which yielded reasonable results for simulated and real data. Further  we show a ‘causal generalization bound’ which states (subject to our particular model of confounding) that the error made by interpreting any non-linear regression as causal model can be bounded from above whenever functions are taken from a not too rich class.,Causal Regularization

Dominik Janzing

Amazon Research Tübingen

Germany

janzind@amazon.com

Abstract

We argue that regularizing terms in standard regression methods not only help
against overﬁtting ﬁnite data  but sometimes also help in getting better causal
models. We ﬁrst consider a multi-dimensional variable linearly inﬂuencing a
target variable with some multi-dimensional unobserved common cause  where
the confounding effect can be decreased by keeping the penalizing term in Ridge
and Lasso regression even in the population limit. The reason is a close analogy
between overﬁtting and confounding observed for our toy model. In the case of
overﬁtting  we can choose regularization constants via cross validation  but here we
choose the regularization constant by ﬁrst estimating the strength of confounding 
which yielded reasonable results for simulated and real data. Further  we show
a ‘causal generalization bound’ which states (subject to our particular model of
confounding) that the error made by interpreting any non-linear regression as
causal model can be bounded from above whenever functions are taken from a not
too rich class.

1

Introduction

Predicting a scalar target variable Y from a d-dimensional predictor X := (X1  . . .   Xd) via appro-
priate regression models is among the classical problems of machine learning [1]. In the standard
supervised learning scenario  some ﬁnite number of observations  independently drawn from an un-
known but ﬁxed joint distribution PY X  are used for inferring Y -values corresponding to unlabelled
X-values. To solve this task  regularization is known to be crucial for obtaining regression models
that generalize well from training to test data [2]. Deciding whether such a regression model admits a
causal interpretation is  however  challenging. Even if causal inﬂuence from Y to X can be excluded
(e.g. by time order)  the statistical relation between X and Y cannot necessarily be attributed to the
inﬂuence of X on Y . Instead  it could be due to possible common causes  also called ‘confounders’.
For the case where common causes are known and observed  there is a huge number of techniques to
infer the causal inﬂuence1  e.g.  [3]  addressing different challenges  for instance  high dimensional
confounders [4] or the case where some variables other than the common causes are observed [5] 
just to mention a few of them. If common causes are not known  the task of inferring the inﬂuence
of X on Y gets incredibly hard. Given observations from any further variables other than X and Y  
conditional independences may help to detect or disprove the existence of common causes [5]  and
so-called instrumental variables may admit the identiﬁcation of causal inﬂuence [6].
Here we consider the case where only observations from X and Y are given. In this case  naively
interpreting the regression model as causal model is a natural baseline. We show that strong
regularization increases the chances that the regression model contains some causal truth. We
are aware of the risk that this result could be mistaken as a justiﬁcation to ignore the hardness of the
problem and blindly infer causal models by strong regularization. Our goal is  instead  to inspire a

1often for d = 1 and with a binary treatment variable X

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

discussion on to what extent causal modelling should regularize even in the inﬁnite sample limit due
to some analogies between generalizing across samples from the same distribution and ‘generalizing’
from observational to interventional distributions  which appear in our models of confounding  while
they need not apply to other confounding scenarios. The idea is not entirely novel since it is tightly
linked to several ideas that are ‘ﬂoating around’ in the machine learning community for a while.
It is believed (and can be proven subject to appropriate model assumptions) that ﬁnding statistical
models that generalize well across different background conditions is closely linked to ﬁnding causal
models [7  8  9  10].2 It is then natural to also believe that generalizing across different environment is
related to generalizing across different samples. Accordingly  [12] describes regularization techniques
for linear regression that help generalizing across certain shift perturbations. Here we describe a
scenario for which the analogy between ‘regularizing against overﬁtting’ and ‘regularizing against
confounding’ gets as tight as possible in the sense that the same regularization helps for both purposes.
Due to this theoretical focus  we prefer to work with the simplest non-trivial scenario rather than
looking for the most relevant or most realistic case.

Scenario 1: inferring a linear statistical model To explain the idea  we consider a linear statistical
relation between X and Y :

(cid:80)n

Y = Xa + E 

(1)
where a is a column vector in Rd and E is an uncorrelated unobserved noise variable  i.e.  ΣXE = 0.
Let ˆY denote the column vector of centred renormalized observations yi of Y   i.e.  with entries
(yi − 1
n − 1  and similarly  ˆE denotes the centred renormalized values of E. Likewise 
let ˆX denote the n × d matrix whose j-th column contains the centred renormalized observations
from Xj. Let  further  ˆX−1 denote its (Moore-Penrose) pseudoinverse. To avoid overﬁtting  the least
ordinary squares estimator3

√
i=1 yi)/

n

ˆa := argmina(cid:48)(cid:107) ˆY − ˆXa(cid:48)(cid:107)2 = ˆX−1 ˆY = a + ˆX−1 ˆE 

is replaced with the Ridge and Lasso estimators

ˆaridge
λ
ˆalasso
λ

:= argmina(cid:48){λ(cid:107)a(cid:48)(cid:107)2
2 + (cid:107) ˆY − ˆXa(cid:48)(cid:107)2}
:= argmina(cid:48){λ(cid:107)a(cid:48)(cid:107)1 + (cid:107) ˆY − ˆXa(cid:48)(cid:107)2} 

(2)

(3)
(4)

where λ is a regularization parameter [13].
So far we have only described the standard scenario of inferring properties of the conditional PY |X
from ﬁnite observations ˆX  ˆY without any causal semantics.

Scenario 2: inferring a linear causal model We now modify the scenario in three respects. First 
we assume that E and X in (1) correlate due to some unobserved common cause. Second  we
interpret (1) in a causal way in the sense that setting X to x lets Y being distributed according to
xa + E. Using Pearl’s do-notation (a crucial concept for formalizing causality) [5]  this can be
phrased as

Y |do(X=x) = xa + E (cid:54)= Y |X=x 

(5)
where we don’t have equality because E needs to be replaced with E|X=x for the observational
conditional. Third  we assume the inﬁnite sample limit where PX Y is known. We still want to infer
the vector a because we are interested in causal statements but regressing Y on X yields ˆa instead
which describes the observational conditional on the right hand side of (5).
Conceptually  Scenario 1 and 2 deal with two entirely different problems: inferring PY |X=x from
ﬁnite samples ( ˆX  ˆY ) versus inferring the interventional conditional PY |do(X=x) from the observa-
tional distribution PY X. Nevertheless both problems amount to inferring the vector a and for both
scenarios  the error term ˆX−1 ˆE causes failure of ordinary least squares regression. Only the reason
why this term is non-zero differs: in the ﬁrst scenario it is a ﬁnite sample effect  while it results from
confounding in the second one. The idea of the present paper is simply that standard regularization

2After submission I became aware of a preprint with the same title as mine  [11] where regularizers are

constructed that are tailored particularly for causal features.

3Here we have  for simplicity  assumed n > d.

2

E

N (0  I) ∼

Z

E = Zc

X

Y

= Xa + E

ZM =

X

Y

= Xa + E

Figure 1: Left: In scenario 1  the empirical correlations between X and E are only ﬁnite sample
effects. Right: In scenario 2  X and E are correlated due to their common cause Z. We sample the
structural parameters M and c from distributions in a way that entails a simple analogy between
scenario 1 and 2.

techniques do not care about the origin of this error term. Therefore  they can temper the impact of
confounding in the same way as they help avoiding to overﬁt ﬁnite data.
The paper is structured as follows. Section 2 ﬂeshes out scenarios 1 and 2 in a way that entails
that the regression error follows the same distributions. Section 3 proposes a way to determine
the regularization parameter in scenario 2 by estimating the strength of confounding via a method
proposed by [14]. Section 4 describes some empirical results. Section 5 describes a modiﬁed statistical
learning theory that states that regression models from not too rich function classes ‘generalize’ from
statistical to causal statements.

2 Analogy between overﬁtting and confounding

The reason why our scenario 2 only considers the inﬁnite sample limit of confounding is that mixing
ﬁnite sample and confounding signiﬁcantly complicates the theoretical results. The supplement
sketches the complications of this case. For a concise description of the population case  we
consider the Hilbert space H of centred random variables (on some probability space without further
speciﬁcation) with ﬁnite variance. The inner product is given by the covariance  e.g. 

Accordingly  we can interpret X as an operator4 Rd → H via (b1  . . .   bd) (cid:55)→(cid:80)

(cid:104)Xi  Xj(cid:105) := cov(Xi  Xj).

(6)

j bjXj. Then the

population version of (2) reads

˜a = argmina(cid:48){(cid:107)Y − Xa(cid:48)(cid:107)2} = X−1Y = a + X−1E 

(7)

where the square length is induced by the inner product (6)  i.e.  it is simply the variance. Extending
the previous notation  X−1 now denotes the pseudoinverse of the operator X [15]. To see that X−1E
is only non-zero when X and E are correlated it is helpful to rewrite it as

X−1E = Σ−1

XXΣXE 

(8)

E/n).5

where we have assumed ΣXX to be invertible (see supplement for a proof). One can easily show
that the empirical covariance matrix (cid:91)ΣXE causing the overﬁtting error is distributed according to
N (0  (cid:91)ΣXXσ2
To get the desired analogy between scenarios 1 and 2  we just need a generating model for confounders
for which ΣXE is distributed according to N (0  γΣXX) for some parameter γ. The independent
source model for confounding described in [14] turned out to satisfy this requirement after some
further speciﬁcation.

Generating model for scenario 1 The following procedure generates samples according to the
DAG in Figure 1  left:

4Readers not familiar with operator theory may read all our operators as matrices with huge n without loosing
any essential insights – except for the cost of having to interpret all equalities as approximate equalities. To
facilitate this way of reading  we will use (·)T also for the adjoint of operators in H although (·)∗ or (·)† is
common.
E) and thus ej ∼ N (0  1/n)  which implies ˆE ∼ N (0  I/n) and thus (cid:91)ΣXE = ˆXT ˆE ∼

5E ∼ N (0  σ2

N (0  ˆXT ˆXσ2

E/n) = N (0  (cid:91)ΣXXσ2

E/n).

3

1. Draw n observations from (X1  . . .   Xd) independently from PX
2. Draw samples of E independently from PE
3. Draw the vector a of structure coefﬁcients from some distribution Pa
4.

Set ˆY := ˆXa + ˆE.

Generating model for scenario 2 To generate random variables according to the DAG in Figure 1 
right  we assume that both variables X and E are generated from the same set of independent sources
by applying a random mixing matrix or a random mixing vector  respectively:
Given an (cid:96)-dimensional random vector Z of sources with distribution N (0  I).
1 . Choose an (cid:96) × d mixing matrix M

and set X := ZM.
Draw c ∈ R(cid:96) from some distribution Pc and set E := Zc.
Draw the vector a of structure coefﬁcients from some distribution Pa
Set Y := Xa + E.

2.
3.
4.

We then obtain:
Theorem 1 (population and empirical covariances). Let the number (cid:96) of sources in scenario 2 be
equal to the number n of samples in scenario 1 and PM coincide with the distribution of sample
matrices ˆX induced by PX. Let  moreover  Pc in scenario 2 coincide with the distribution of ˆE
induced by PE in scenario 1  and Pa be the same in both scenarios. Then the joint distribution
of a  ΣXX  ΣXY   ΣXE in scenario 2 coincides with the joint distribution of a  (cid:91)ΣXX  (cid:91)ΣXY   (cid:91)ΣXE in
scenario 1.
Proof. We have (cid:91)ΣXX = ˆXT ˆX and ΣXX = XT X = M T ZT ZM = M T M  where we have used
that Z has full rank due to the uncorrelatedness of its components. Likewise  (cid:91)ΣXE = ˆXT ˆE and
ΣXE = (ZM )T Zc = M T c. Further  (cid:91)ΣXY = ˆXT ˆXa + (cid:91)ΣXE and ΣXY = XT Xa + ΣXE. Then
the statement follows from the correspondences M ≡ ˆX  c ≡ ˆE  a ≡ a.
Theorem 1 provides a canonical way to transfer any Bayesian approach to inferring a from (cid:91)ΣXX  (cid:91)ΣXY
in scenario 1 to inferring a from ΣXX  ΣXY in scenario 2. It is known [16]  for instance  that (3) and
(4) maximize the posterior p(a| ˆX  ˆY ) for the priors

(cid:18)

(cid:19)

plasso(a) ∼ exp

− 1
2τ 2(cid:107)a(cid:107)1

 

(9)

(cid:18)

(cid:19)

pridge(a) ∼ exp

2τ 2(cid:107)a(cid:107)2
− 1
E) and λ = σ2

respectively  if E ∼ N (0  σ2
E/τ 2. Some algebra shows that the only information
from ˆX and ˆY that matters is given by (cid:91)ΣXX and (cid:91)ΣXY   see supplement. Therefore  (3) and (4)
also maximize the posterior p(a|(cid:91)ΣXX  (cid:91)ΣXY ) and  employing Theorem 1  the population versions of
Ridge and Lasso

˜aridge
λ
˜alasso
λ

:= argmina(cid:48){λ(cid:107)a(cid:48)(cid:107)2
2 + (cid:107)Y − Xa(cid:48)(cid:107)2}
:= argmina(cid:48){λ(cid:107)a(cid:48)(cid:107)1 + (cid:107)Y − Xa(cid:48)(cid:107)2} 

(10)
(11)

maximize p(a|ΣXX  ΣXY ) after substituting all the priors accordingly.
These population versions  however  make it apparent that we now face the problem that selecting λ
by cross-validation would be pointless since λ = 0 had the best cross sample performance. Instead 
we would need to know the strength of confounding to choose the optimal λ.

3 Choosing the regularization constant by estimating confounding

The only approaches that directly estimate the strength of confounding6 from PX Y alone we are
aware of are given by [19  14]. The ﬁrst paper considers only one-dimensional confounders  which is
complementary to our confounding scenario  while we will use the approach from the second paper

6[17] constructs confounders for linear non-Gaussian models and [18] infer confounders of univariate X  Y

subject to the additive noise assumption.

4

because it perfectly matches our scenario 2 in Section 2 with ﬁxed M. [14] use the slightly stronger
assumption that a and c are drawn from N (0  σ2
c I)  respectively. We brieﬂy rephrase
the method. Using ˜a in (7) (i.e. the population version of the ordinary least squares solution)  they
deﬁne confounding strength by

aI) and N (0  σ2

β :=

(cid:107)˜a − a(cid:107)2

(cid:107)˜a − a(cid:107)2 + (cid:107)a(cid:107)2 ∈ [0  1].

(12)

It attains 0 iff ˜a coincides with a and 1 iff a = 0 and the correlations between X and Y are entirely
caused by confounding.
The idea to estimate β is that the unregularized regression vector follows the distribution N (0  σ2
c M−1M−T ). This results from
σ2

aI +

˜a = a + X−1E = a + M−1c 

c /σ2

(see proof of Theorem 1 in [14]). Then the quotient σ2
a can be inferred from the direction of ˆa
(intuitively: the more ˆa concentrates in small eigenvalue eigenspaces of ΣXX = M T M  the larger is
this quotient). Using some approximations that hold for large d  β can be estimated from (ΣXX  ˜a).
Further  the approximation (cid:107)˜a− a(cid:107)2 +(cid:107)a(cid:107)2 ≈ (cid:107)˜a(cid:107)2 from [19] yields (cid:107)a(cid:107)2 ≈ (1− β)·(cid:107)˜a(cid:107)2. Hence 
the length of the true causal regression vector a can be estimated from the length of ˜a. This way  we
can adjust λ such that (cid:107)ˆaλ(cid:107) coincides with the estimated length. Since the estimation is based on
a Gaussian (and not a Laplacian) prior for a  it seems more appropriate to combine it with Ridge
regression than with Lasso. However  due to known advantages of Lasso7 (e.g. that sparse solutions
yield more interpretable results)  we also use Lasso. After all  the qualitative statement that strong
confounding amounts to vectors ˆa that tend to concentrate in low eigenvalue subspaces of ΣXX still
holds true as long as c is still chosen from an isotropic prior.
Confounding estimation via the algorithm of [14] requires the problematic decision of whether the
variables Xj should be rescaled to variance 1. If different Xj refer to different units  there is no other
straightforward choice of the scale. It is not recommended  however  to always normalize Xj. If
ΣXX is diagonal  for instance  the method would be entirely spoiled by normalization. The difﬁculty
of deciding whether data should be renormalizing beforehand will be inherited by our algorithm.
Our confounder correction algorithm reads:

Algorithm ConCorr
1: Input: i.i.d. samples from P (X  Y ).
2: Rescale Xj to variance 1 if desired.
3: Compute the empirical covariance matrices (cid:91)ΣXX and (cid:91)ΣXY
4: Compute the ordinary least squares regression vector ˆa := (cid:91)ΣXX
5: Compute an estimator ˆβ for the confounding strength β via the algorithm in [14] from (cid:91)ΣXX and

−1(cid:91)ΣXY

ˆa and estimate the squared length of a via

(cid:107)a(cid:107)2 ≈ (1 − ˆβ)(cid:107)ˆa(cid:107)2

(13)

6: ﬁnd λ such that the squared length of ˆaridge/lasso

coincides with the square root of the right

hand side of (13).

7: Compute Ridge or Lasso regression model using this value of λ.
8: Output: Regularized regression vectors ˆaridge/lasso

.

λ

λ

4 Experiments

4.1 Simulated data

For some ﬁxed values of d = (cid:96) = 30  we generate one mixing matrix M in each run by drawing its
entries from the standard normal distribution. In each run we generate n = 1000 instances of the

7[20] claims  for instance  “If (cid:96)2 was the norm of the 20th century  then (cid:96)1 is the norm of the 21st century ...
OK  maybe that statement is a bit dramatic  but at least so far  there’s been a frenzy of research involving the (cid:96)1
norm and its sparsity-inducing properties....”

5

Figure 2: From left to right: RSE versus unregularized RSE (that is  ordinary least square regression)
for Concorr with Ridge  standard cross-validated Ridge (top  left and right  respectively)  and
ConCorr with Lasso  standard cross-validaded Lasso (bottom  left and right  respectively) for 100
runs (each point representing one run).

c ) and N (0  σ2

(cid:96)-dimensional standard normal random vector Z and compute the X values by X = ZM. Afterwards
we draw the entries of c and a from N (0  σ2
a)  respectively  after choosing σa and σc
from the uniform distribution on [0  1]. Finally  we compute the values of Y via Y = Xa + Zc + E 
where E is random noise drawn from N (0  σ2
E) (the parameter σE has previously been chosen
uniformly at random from [0  5]  which yields quite noisy data). While such a noise term didn’t exist
in our description of scenario 2  we add it here to also study ﬁnite sample effects (without noise  Y
depends deterministically on X for (cid:96) ≤ d).
To assess whether the output ˆaλ is close to a we deﬁne the relative squared error (RSE) of any
regression vector a(cid:48) by

a(cid:48) :=

(cid:107)a(cid:48) − a(cid:107)2

(cid:107)a(cid:48) − a(cid:107)2 + (cid:107)a(cid:107)2 ∈ [0  1]

This deﬁnition is convenient because it yields the confounding strength β for the special case where
a(cid:48) is the ordinary least squares regression vector ˜a.
Figure 2 shows the results. The red and green lines show two different baselines: ﬁrst  the unregular-
ized error  and second  the error 1/2 obtained by the trivial regression vector 0. The goal is to stay
below both baselines. Apart from those two trivial baselines  another natural baseline is regularized
regression where λ is chosen by cross-validation  because this would be the default approach for the
unconfounded case. We have used leave-one-out CV from the Python package scikit for Ridge
and Lasso  respectively.
ConCorr clearly outperforms cross-validation (for both Ridge and Lasso)  which shows that cross-
validation regularizes too weakly for causal modelling  as expected. One should add  however  that
we increased the number of iterations in the λ-optimization to get closer to optimal leave-one-out
performance since the default parameters of scikit already resulted in regularizing more strongly
than that (Note that the goal of this paper is not to show that ConCorr outperforms other methods.

6

Figure 3: Results for Ridge (left) and Lasso (right) regression for the data from the optical device.

Z

Y (cid:48)

X

Y

= Y (cid:48) + Zc

Figure 4: Confounding where Z inﬂuences Y in a linear additive way  while the inﬂuence on X is
arbitrary.

Instead  we want to argue that for causal models it is often recommended to regularize more strongly
than criteria of statistical predictability suggests. If ‘early stopping’ in common CV algorithms also
yields stronger regularization 8 this can be equally helpful for causal inference  although the way
ConCorr choses λ is less arbitrary than just bounding the number of iterations).
Results for other dimensions were qualitatively comparable if d and (cid:96) were above 10 with slow
improvement for larger dimensions  but note that the relevance of simulations should not be overes-
timated since inferring confounding critically depends on the distribution of eigenvalues of ΣXX 
which is domain dependent in practical applications.

4.2 Real data

In absence of better data sets with known ground truth  we considered two sets used in [14]  where
ground truth was assumed to be known up to some uncertainty discussed there.

Optical device Here  a Laptop shows an image with extremely low resolution (in their case 3 × 3-
pixel9) captured from a webcam. In front of the screen they mounted a photodiode measuring the
light intensity Y   which is mainly inﬂuenced by the pixel vector X of the image.
The confounder W is a random voltage controlling two LEDs  one in front of the webcam (and
thus inﬂuencing X) and the second one in front of the photodiode (thus inﬂuencing Y ). Since W is
also measured  the vector aX W obtained by regressing Y on (X  W ) is causal (no confounders by
construction)  if one accepts the linearity assumption. Dropping W yielded signiﬁcant confounding 
with β ranging from 0 to 1. We applied ConCorr to X  Y and compared the output with the ground
truth. Figure 3  left  show the results for Ridge and Lasso. The y-axis is the relative squared error
achieved by ConCorr  while the x-axis is the cross-validated baseline.
The point (0  0) happened to be met by three cases  where no improvement was possible. One can
see that in 3 out of the remaining nine cases (note that the point (1  1) is also met by two cases) 
ConCorr signiﬁcantly improved the causal prediction. Fortunately  there is no case where ConCorr
is worse than the baseline.

8See also [21] for regularization by early stopping in a different context.
9In order to avoid overﬁtting issues  we decided in Ref. [14] to only generate low-dimensional data with d

around 10.

7

Taste of wine This data has been extracted from the UCI machine learning repository [22] for the
experiments in [14]. The cause X contains 11 ingredients of different sorts of red wine and Y is
the taste assigned by human subjects. Regressing Y on X yields a regression vector for which the
ingredient alcohol dominates. Since alcohol strongly correlates with some of the other ingredients 
dropping it amounts to signiﬁcant confounding (assuming that the correlations between alcohol and
the other ingredients is due to common causes and not due to the inﬂuence of alcohol on the others).
After normalizing the ingredients10  ConCorr with Ridge and Lasso yielded a relative error of 0.45
and 0.35  respectively  while [14] computed the confounding strength β ≈ 0.8  which means that
ConCorr signiﬁcantly corrects for confounding (we conﬁrmed that CV also yielded errors close to
0.8 which suggests that ﬁnite sample effects did not matter for the error).
Although one-dimensional confounding heavily violates our model assumptions  the results of both
real data experiments look somehow positive.

5 Causal learning theory

So far  we have supported causal regularization mainly via transferring Bayesian arguments for
regularization from scenario 1 to scenario 2. An alternative perspective on regularization is provided
by statistical learning theory [2]. Generalization bounds guarantee that the expected error is unlikely
to signiﬁcantly exceed the empirical error for any regression function f from a not too rich class F.
If L(Y  f (X)) denotes some loss function  they guarantee  for instance  that the following inequality
holds with a certain probability uniformly for f ∈ F:

E[L(Y  f (X)] ≤ 1
n

L(yi  f (xi)) + C(F) 

n(cid:88)

j=1

(cid:90)

where C(F) is some ‘capacity term’.
In the same way  as these bounds relate empirical loss with expected loss  we will relate the expected
(statistical) loss above with the interventional loss

Edo(X)[L(Y  f (X)] :=

L(y  f (x))p(y|do(x))p(x)dx 

(14)

(which quantiﬁes how well f describes the change of Y for interventions on X) via a causal
generalization bound of the form

Edo(X)[L(Y  f (X)] ≤ E[L(Y  f (X))] + C(F) 

for some capacity term C(F). Note that the type of causal learning learning theory developed here
should not be confused with [23]  which considers the generalization error of classiﬁers that infer
cause-effect directions after being trained with multiple data sets of cause-effect pairs.
Figure 4 shows our confounding model that signiﬁcantly generalizes our previous models. Z and X
are arbitrary random variables of dimensions (cid:96) and d  respectively. Apart from the graphical structure 
we only add the parametric assumption that the inﬂuence of Z on Y is linear additive:

(cid:90)

(15)
where c ∈ R(cid:96). The change of Y caused by setting X to x via interventions is given by Pearl’s
backdoor criterion [5] as

Y = Y (cid:48) + Zc 

p(y|do(x)) =

p(y|x  z)p(z)dz.

(16)
Note that the observational conditional p(y|x) would be given by replacing p(z) with p(z|x) in (16).
Interventional conditionals destroy the dependences between the confounder Z and the ‘treatment’
variable X by deﬁnition of an intervention. The supplement shows that the difference between
interventional and observational loss can be concisely phrased in terms of covariances if we choose
the loss L(Y  f (X)) = (Y − f (X))2:
Lemma 1 (interventional minus observational loss). Let g(x) := E[Y (cid:48)|x]. Then
Edo(X)[(Y − f (X))2] − E[(Y − f (X))2] = (Σ(f−g)(X)Z)c.

10Note that [14] also used normalization to achieve reasonable estimates of confounding for this case.

8

For every single f  the vector Σ(f−g)(X)Z is likely to be almost orthogonal to c if c is randomly
drawn from a rotation invariant distribution in R(cid:96). In order to derive statements of this kind that hold
uniformly for all functions from a function class F we introduce the following concept quantifying
the capacity of F:
Deﬁnition 1 (correlation dimension). Let F be some class of functions f : Rd → R. Given the
distribution PX Z  the correlation dimension dcorr of F is the dimension of the span of

{Σf (X)Z |f ∈ F}.

To intuitively understand this concept it is instructive to consider the following immediate bounds:
Lemma 2 (bounds on correlation dimension). The correlation dimension of F is bounded from above
by the dimension of the span of F. Moreover  if F consists of linear functions  another upper bound
is given by the rank of ΣXZ.
In the supplement we show:
Theorem 2 (causal generalization bound). Given the causal structure in Figure 4  where Z is (cid:96)-
dimensional with covariance matrix ΣZZ = I  inﬂuencing X in an arbitrary way. Let the inﬂuence
of Z on Y be given by a ‘random linear combination’ of Z with variance V . Explicitly 

Y (cid:48) (cid:55)→ Y = Y (cid:48) + Zc 
√
where c ∈ R(cid:96) is randomly drawn from the sphere of radius
V according to the Haar measure of
O((cid:96)). Let F have correlation dimension dcorr and satisfy the bound (cid:107)(f − g)(X)(cid:107)H ≤ b for all
f ∈ F (where g(x) := E[Y (cid:48)|x]). Then  for any β > 1 

(cid:114)

V · β · dcorr + 1

 

Edo(X)[(Y − f (X))2] ≤ E[(Y − f (X))2] + b ·

(cid:96)

holds uniformly for all f ∈ F with probability 1 − en(1−β+ln β)/2.
Note that ΣZZ = I can always be achieved by the ‘whitening’ transformation Z (cid:55)→ (ΣZZ)−1/2Z.
Normalization is convenient just because it enables a simple way to deﬁne a ‘random linear combina-
tion of Z with variance V ’  which would be cumbersome to deﬁne otherwise.
Theorem 2 basically says that the interventional loss is with high probability close to the expected
observational loss whenever the number of sources signiﬁcantly exceeds the correlation dimension.
Note that the confounding effect can nevertheless be large  that is  it would heavily spoil ordinary
least square (e.g. unregularized) regression. Consider  for instance  the case where (cid:96) = d and X and
Z are related by X = Z. Let  moreover  Y (cid:48) = Xa for some a ∈ Rd. Then the confounding can have
signiﬁcant impact on the correlations between Y and X due to Y = X(a + c)  whenever c is large
compared to a. However  whenever F has low correlation dimension  the selection of the function f
that optimally ﬁts observational data is not signiﬁcantly perturbed by the term Xc. This is because
Xc ‘looks like random noise’ since F contains no function that is able to account for ‘such a complex
correlation’. For the simple case where ΣXZ has low rank  for instance  the term Zc almost behaves
like noise for typical c (w.r.t. any class F of linear functions)  because the majority of components of
Z are uncorrelated with X  after appropriate basis change.
Since (cid:96)  dcorr  b in Theorem 2 are unobserved  its value will mostly consist in qualitative insights
rather than providing quantitative bounds of practical use.

6 What do we learn for the general case?

Despite all concerns against our ‘hand-tuned’ confounder model  we want to stimulate a general
discussion about recommending stronger regularization than criteria of statistical predictability
suggest  whenever one is actually interested in causal models. Our theoretical results suggest that
this helps in particular when a type of confounding is expected that – if present – generates complex
dependences  which would strongly regularized regression treat as noise. The advice of limiting the
complexity of models to capture some causal truth could also be relevant for modern deep learning 
since the goal of interpretability of algorithms for classiﬁcation or other standard tasks could possibly
be improved by having causal features rather than purely predictive ones.
It is  however  by no means intended to suggest that this simple recommendation would solve any of
the hard problems in causal inference.

9

References
[1] B. Schölkopf and A. Smola. Learning with kernels. MIT Press  Cambridge  MA  2002.

[2] V. Vapnik. Statistical learning theory. John Wileys & Sons  New York  1998.

[3] D. Rubin. Direct and indirect causal effects via potential outcomes. Scandinavian Journal of

Statistics  31:161–170  2004.

[4] V. Chernozhukov  D. Chetverikov  M. Demirer  E. Duﬂo  C. Hansen  W. Newey  and J. Robins.
Double/debiased machine learning for treatment and structural parameters. The Econometrics
Journal  21(1):C1 – C68  2018.

[5] J. Pearl. Causality. Cambridge University Press  2000.

[6] G. Imbens and J. Angrist. Identiﬁcation and estimation of local average treatment effects.

Econometrica  62(2):467 – 475  1994.

[7] J. Peters  P. Bühlmann  and N. Meinshausen. Causal inference using invariant prediction:
identiﬁcation and conﬁdence intervals. Journal of the Royal Statistical Society  Series B
(Statistical Methodology)  78(5):947–1012  2016.

[8] C. Heinze-Deml  J. Peters  and N. Meinshausen. Invariant causal prediction for nonlinear

models. Journal of Causal Inference  6:20170016  2017.

[9] C. Heinze-Deml and N. Meinshausen. Conditional variance penalties and domain shift robust-

ness. arXiv:1710.11469  2017.

[10] Z.. Shen  P. Cui  K. Kuang  and B. Li. On image classiﬁcation: Correlation v.s. causality.

arXiv:1708.06656  2017.

[11] M. Bahadori  K. Chalupka  E. Choi  R. Chen  W. Stewart  and J. Sun. Causal regularization.

arXiv:1702.02604   2017.

[12] D. Rothenhäusler  N. Meinshausen  P. Bühlmann  and J. Peters. Anchor regression: heteroge-

neous data meets causality. arXiv:1801.06229  2018.

[13] T. Hastie  R. Tibshirani  and J. Friedman. The elements of statistical learning: Data mining 

inference  and prediction. Springer-Verlag  New York  NY  2001.

[14] D. Janzing and B. Schölkopf. Detecting non-causal artifacts in multivariate linear regression
models. In Proceedings of the 35th International Conference on Machine Learning (ICML
2018)  2018.

[15] F. Beutler. The operator theory of the pseudo-inverse I. Bounded operators. Journal of

Mathematical Analysis and Applications  10(3):451 – 470  1965.

[16] A. Hoerl and R. Kennard. Ridge regression: Biased estimation for nonorthogonal problems.

Technometrics  42(1):80–86  2000.

[17] P. Hoyer  S. Shimizu  A. Kerminen  and M. Palviainen. Estimation of causal effects using
linear non-gaussian causal models with hidden variables. International Journal of Approximate
Reasoning  49(2):362 – 378  2008.

[18] D. Janzing  J. Peters  J. Mooij  and B. Schölkopf. Identifying latent confounders using additive
noise models. In Proceedings of the 25th Conference on Uncertainty in Artiﬁcial Intelligence
(UAI 2009)  249-257. (Eds.) A. Ng and J. Bilmes  AUAI Press  Corvallis  OR  USA  2009.

[19] D. Janzing and B. Schölkopf. Detecting confounding in multivariate linear models via spectral

analysis. Journal of Causal Inference  6(1)  2017.

[20] R. Tibshirani and Wasserman L. Course on Statistical Machine Learning  chapter: “Sparsity

and the Lasso”  2015. http://www.stat.cmu.edu/~ryantibs/statml/.

10

[21] G. Raskutti  M. Wainwright  and B. Yu. Early stopping for non-parametric regression: An opti-
mal data-dependent stopping rule. In 2011 49th Annual Allerton Conference on Communication 
Control  and Computing (Allerton)  pages 1318–1325  Sep. 2011.

[22] D. Dua and C. Graff. UCI machine learning repository  2017. http://archive.ics.uci.

edu/ml.

[23] D. Lopez-Paz  K. Muandet  B. Schölkopf  and I. Tolstikhin. Towards a learning theory of cause-
effect inference. In Proceedings of the 32nd International Conference on Machine Learning 
volume 37 of JMLR Workshop and Conference Proceedings  page 1452–1461. JMLR  2015.

11

,Dominik Janzing