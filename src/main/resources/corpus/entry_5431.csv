2014,The Bayesian Case Model: A Generative Approach for Case-Based Reasoning and Prototype Classification,We present the Bayesian Case Model (BCM)  a general framework for Bayesian case-based reasoning (CBR) and prototype classification and clustering. BCM brings the intuitive power of CBR to a Bayesian generative framework. The BCM learns prototypes  the ``quintessential observations that best represent clusters in a dataset  by performing joint inference on cluster labels  prototypes and important features. Simultaneously  BCM pursues sparsity by learning subspaces  the sets of features that play important roles in the characterization of the prototypes. The prototype and subspace representation provides quantitative benefits in interpretability while preserving classification accuracy. Human subject experiments verify statistically significant improvements to participants' understanding when using explanations produced by BCM  compared to those given by prior art.",The Bayesian Case Model: A Generative Approach

for Case-Based Reasoning and Prototype

Classiﬁcation

Been Kim  Cynthia Rudin and Julie Shah

Massachusetts Institute of Technology

Cambridge  Massachusetts 02139

{beenkim  rudin  julie a shah}@csail.mit.edu

Abstract

We present the Bayesian Case Model (BCM)  a general framework for Bayesian
case-based reasoning (CBR) and prototype classiﬁcation and clustering. BCM
brings the intuitive power of CBR to a Bayesian generative framework. The BCM
learns prototypes  the “quintessential” observations that best represent clusters in
a dataset  by performing joint inference on cluster labels  prototypes and impor-
tant features. Simultaneously  BCM pursues sparsity by learning subspaces  the
sets of features that play important roles in the characterization of the prototypes.
The prototype and subspace representation provides quantitative beneﬁts in inter-
pretability while preserving classiﬁcation accuracy. Human subject experiments
verify statistically signiﬁcant improvements to participants’ understanding when
using explanations produced by BCM  compared to those given by prior art.

1

Introduction

People like to look at examples. Through advertising  marketers present examples of people we
might want to emulate in order to lure us into making a purchase. We might ignore recommendations
made by Amazon.com and look instead at an Amazon customer’s Listmania to ﬁnd an example of a
customer like us. We might ignore medical guidelines computed from a large number of patients in
favor of medical blogs where we can get examples of individual patients’ experiences.
Numerous studies have demonstrated that exemplar-based reasoning  involving various forms of
matching and prototyping  is fundamental to our most effective strategies for tactical decision-
making ([26  9  21]). For example  naturalistic studies have shown that skilled decision makers
in the ﬁre service use recognition-primed decision making  in which new situations are matched to
typical cases where certain actions are appropriate and usually successful [21]. To assist humans in
leveraging large data sources to make better decisions  we desire that machine learning algorithms
provide output in forms that are easily incorporated into the human decision-making process.
Studies of human decision-making and cognition provided the key inspiration for artiﬁcial intelli-
gence Case-Based Reasoning (CBR) approaches [2  28]. CBR relies on the idea that a new situation
can be well-represented by the summarized experience of previously solved problems [28]. CBR
has been used in important real-world applications [24  4]  but is fundamentally limited  in that it
does not learn the underlying complex structure of data in an unsupervised fashion and may not
scale to datasets with high-dimensional feature spaces (as discussed in [29]).
In this work  we introduce a new Bayesian model  called the Bayesian Case Model (BCM)  for
prototype clustering and subspace learning. In this model  the prototype is the exemplar that is most
representative of the cluster. The subspace representation is a powerful output of the model because
we neither need nor want the best exemplar to be similar to the current situation in all possible ways:

1

for instance  a moviegoer who likes the same horror ﬁlms as we do might be useful for identifying
good horror ﬁlms  regardless of their cartoon preferences. We model the underlying data using a
mixture model  and infer sets of features that are important within each cluster (i.e.  subspace). This
type of model can help to bridge the gap between machine learning methods and humans  who use
examples as a fundamental part of their decision-making strategies.
We show that BCM produces prediction accuracy comparable to or better than prior art for standard
datasets. We also verify through human subject experiments that the prototypes and subspaces
present as meaningful feedback for the characterization of important aspects of a dataset. In these
experiments  the exemplar-based output of BCM resulted in statistically signiﬁcant improvements
to participants’ performance of a task requiring an understanding of clusters within a dataset  as
compared to outputs produced by prior art.

2 Background and Related Work

People organize and interpret information through exemplar-based reasoning  particularly when they
are solving problems ([26  7  9  21]). AI Cased-Based Reasoning approaches are motivated by
this insight  and provide example cases along with the machine-learned solution. Studies show
that example cases signiﬁcantly improve user conﬁdence in the resulting solutions  as compared to
providing the solution alone or by also displaying a rule that was used to ﬁnd the solution [11].
However  CBR requires solutions (i.e. labels) for previous cases  and does not learn the underlying
structure of the data in an unsupervised fashion. Maintaining transparency in complex situations
also remains a challenge [29]. CBR models designed explicitly to produce explanations [1] rely on
the backward chaining of the causal relation from a solution  which does not scale as complexity
increases. The cognitive load of the user also increases with the complexity of the similarity measure
used for comparing cases [14]. Other CBR models for explanations require the model to be manually
crafted in advance by experts [25].
Alternatively  the mixture model is a powerful tool for discovering cluster distributions in an un-
supervised fashion. However  this approach does not provide intuitive explanations for the learned
clusters (as pointed out in [8]). Sparse topic models are designed to improve interpretability by re-
ducing the number of words per topic [32  13]. However  using the number of features as a proxy for
interpretability is problematic  as sparsity is often not a good or complete measure of interpretability
[14]. Explanations produced by mixture models are typically presented as distributions over fea-
tures. Even users with technical expertise in machine learning may have a difﬁcult time interpreting
such output  especially when the cluster is distributed over a large number of features [14].
Our approach  the Bayesian Case Model (BCM)  simultaneously performs unsupervised clustering
and learns both the most representative cases (i.e.  prototypes) and important features (i.e.  sub-
spaces). BCM preserves the power of CBR in generating interpretable output  where interpretability
comes not only from sparsity but from the prototype exemplars.
In our view  there are at least three widely known types of interpretable models: sparse linear
classiﬁers ([30  8  31]); discretization methods  such as decision trees and decision lists (e.g. 
[12  32  13  23  15]); and prototype- or case-based classiﬁers (e.g.  nearest neighbors [10] or a super-
vised optimization-based method [5]). (See [14] for a review of interpretable classiﬁcation.) BCM is
intended as the third model type  but uses unsupervised generative mechanisms to explain clusters 
rather than supervised approaches [16] or by focusing myopically on neighboring points [3].

3 The Bayesian Case Model

Intuitively  BCM generates each observation using the important pieces of related prototypes. The
model might generate a movie proﬁle made of the horror movies from a quintessential horror movie
watcher  and action movies from a quintessential action moviegoer.
BCM begins with a standard discrete mixture model [18  6] to represent the underlying structure
of the observations. It augments the standard mixture model with prototypes and subspace feature
indicators that characterize the clusters. We show in Section 4.2 that prototypes and subspace feature
indicators improve human interpretability as compared to the standard mixture model output. The
graphical model for BCM is depicted in Figure 1.

2

  c

N

ps

s

q

!s

S

↵

⇡i

zij

xij

F

N

Figure 1: Graphical model for the Bayesian Case Model

We start with N observations  denoted by x = {x1  x2  . . .   xN}  with each xi represented as a ran-
dom mixture over clusters. There are S clusters  where S is assumed to be known in advance. (This
assumption can easily be relaxed through extension to a non-parametric mixture model.) Vector ⇡i
are the mixture weights over these clusters for the ith observation xi  ⇡i 2 RS
+. Each observation
has P features  and we denote the jth feature of the ith observation as xij. Each feature j of the
observation xi comes from one of the clusters  the index of the cluster for xij is denoted by zij and
the full set of cluster assignments for observation-feature pairs is denoted by z. Each zij takes on the
value of a cluster index between 1 and S. Hyperparameters q    c  and ↵ are assumed to be ﬁxed.
The explanatory power of BCM results from how the clusters are characterized. While a standard
mixture model assumes that each cluster take the form of a predeﬁned parametric distribution (e.g. 
normal)  BCM characterizes each cluster by a prototype  ps  and a subspace feature indicator  !s.
Intuitively  the subspace feature indicator selects only a few features that play an important role in
identifying the cluster and prototype (hence  BCM clusters are subspace clusters). We intuitively
deﬁne these latent variables below.
Prototype  ps: The prototype ps for cluster s is deﬁned as one observation in x that maximizes
p(ps|!s  z  x)  with the probability density and !s as deﬁned below. Our notation for element j of
ps is psj. Since ps is a prototype  it is equal to one of the observations  so psj = xij for some i.
Note that more than one maximum may exist per cluster; in this case  one prototype is arbitrarily
chosen. Intuitively  the prototype is the “quintessential” observation that best represents the cluster.
Subspace feature indicator !s: Intuitively  !s ‘turns on’ the features that are important for charac-
terizing cluster s and selecting the prototype  ps. Here  !s 2 {0  1}P is an indicator variable that
is 1 on the subset of features that maximizes p(!s|ps  z  x)  with the probability for !s as deﬁned
below. Here  !s is a binary vector of size P   where each element is an indicator of whether or not
feature j belongs to subspace s.
The generative process for BCM is as follows: First  we generate the subspace clusters. A sub-
space cluster can be fully described by three components: 1) a prototype  ps  generated by sampling
uniformly over all observations  1 . . . N; 2) a feature indicator vector  !s  that indicates important
features for that subspace cluster  where each element of the feature indicator (!sj) is generated
according to a Bernoulli distribution with hyperparameter q; and 3) the distribution of feature out-
comes for each feature  s  for subspace s  which we now describe.
Distribution of feature outcomes s for cluster s: Here  s is a data structure wherein each “row”
sj is a discrete probability distribution of possible outcomes for feature j. Explicitly  sj is a vector
of length Vj  where Vj is the number of possible outcomes of feature j. Let us deﬁne ⇥ as a vector
of the possible outcomes of feature j (e.g.  for feature ‘color’  ⇥ = [red  blue  yellow])  where ⇥v
represents a particular outcome for that feature (e.g.  ⇥v = blue). We will generate s so that it
mostly takes outcomes from the prototype ps for the important dimensions of the cluster. We do this
by considering the vector g  indexed by possible outcomes v  as follows:
gpsj  !sj  (v) = (1 + c1[wsj =1 and psj =⇥v]) 

where c and  are constant hyperparameters that indicate how much we will copy the prototype in
order to generate the observations. The distribution of feature outcomes will be determined by g
through sj ⇠ Dirichlet(gpsj  !sj  ). To explain at an intuitive level: First  consider the irrelevant
dimensions j in subspace s  which have wsj = 0. In that case  sj will look like a uniform distribu-

3

tion over all possible outcomes for features j; the feature values for the unimportant dimensions are
generated arbitrarily according to the prior. Next  consider relevant dimensions where wsj = 1. In
this case  sj will generally take on a larger value  + c for the feature value that prototype ps has on
feature j  which is called ⇥v. All of the other possible outcomes are taken with lower probability .
As a result  we will be more likely to select the outcome ⇥v that agrees with the prototype ps. In the
extreme case where c is very large  we can copy the cluster’s prototype directly within the cluster’s
relevant subspace and assign the rest of the feature values randomly.
An observation is then a mix of different prototypes  wherein we take the most important pieces of
each prototype. To do this  mixture weights ⇡i are generated according to a Dirichlet distribution 
parameterized by hyperparameter ↵. From there  to select a cluster and obtain the cluster index zij
for each xij  we sample from a multinomial distribution with parameters ⇡i. Finally  each feature for
an observation  xij  is sampled from the feature distribution of the assigned subspace cluster (zij ).
(Note that Latent Dirichlet Allocation (LDA) [6] also begins with a standard mixture model  though
our feature values exist in a discrete set that is not necessarily binary.) Here is the full model  with
hyperparameters c    q  and ↵:
!sj ⇠ Bernoulli(q) 8s  j
sj ⇠ Dirichlet(gpsj  !sj  ) 8s  j
xij ⇠ Multinomial(zij j) 8i  j.
⇡i ⇠ Dirichlet(↵) 8i
Our model can be readily extended to different similarity measures  such as standard kernel methods
or domain speciﬁc similarity measures  by modifying the function g. For example  we can use the
least squares loss i.e.  for ﬁxed threshold ✏  gpsj  !sj  (v) = (1 + c1[wsj =1 and (psj⇥v)2✏]); or 
more generally  gpsj  !sj  (v) = (1 + c1[wsj =1 and `(psj  ⇥v)✏]).
In terms of setting hyperparameters  there are natural settings for ↵ (all entries being 1). This
means that there are three real-valued parameters to set  which can be done through cross-validation 
another layer of hierarchy with more diffuse hyperparameters  or plain intuition. To use BCM for
classiﬁcation  vector ⇡i is used as S features for a classiﬁer  such as SVM.

where gpsj  !sj  (v) = (1 + c1[wsj =1 and psj =⇥v])

ps ⇠ Uniform(1  N ) 8s

zij ⇠ Multinomial(⇡i) 8i  j

3.1 Motivating example

This section provides an illustrative example for prototypes  subspace feature indicators and sub-
space clusters  using a dataset composed of a mixture of smiley faces. The feature set for a smiley
face is composed of types  shapes and colors of eyes and mouths. For the purpose of this example 
assume that the ground truth is that there are three clusters  each of which has two features that are
important for deﬁning that cluster. In Table 1  we show the ﬁrst cluster  with a subspace deﬁned by
the color (green) and shape (square) of the face; the rest of the features are not important for deﬁning
the cluster. For the second cluster  color (orange) and eye shape deﬁne the subspace. We generated
240 smiley faces from BCM’s prior with ↵ = 0.1 for all entries  and q = 0.5   = 1 and c = 50.

Data in assigned to cluster

LDA

Top 3 words and probabilities

Prototype

BCM

Subspaces

1

2

3

color (
are important.

) and shape (

color (
are important.

) and eye (

eye (
are important.

) and mouth (

)

)

)

0.26

0.23

0.12

0.26

0.24

0.16

0.35

0.27

0.15

Table 1: The mixture of smiley faces for LDA and BCM

4

BCM works differently to Latent Dirichlet Allocation (LDA) [6]  which presents its output in a very
different form. Table 1 depicts the representation of clusters in both LDA (middle column) and BCM
(right column). This dataset is particularly simple  and we chose this comparison because the two
most important features that both LDA and BCM learn are identical for each cluster. However  LDA
does not learn prototypes  and represents information differently. To convey cluster information
using LDA (i.e.  to deﬁne a topic)  we must record several probability distributions – one for each
feature. For BCM  we need only to record a prototype (e.g.  the green face depicted in the top row 
right column of the ﬁgure)  and state which features were important for that cluster’s subspace (e.g. 
shape and color). For this reason  BCM is more succinct than LDA with regard to what information
must be recorded in order to deﬁne the clusters. One could deﬁne a “special” constrained version
of LDA with topics having uniform weights over a subset of features  and with “word” distributions
centered around a particular value. This would require a similar amount of memory; however  it loses
information  with respect to the fact that BCM carries a full prototype within it for each cluster.
A major beneﬁt of BCM over LDA is that the “words” in each topic (the choice of feature values) are
coupled and not assumed to be independent – correlations can be controlled depending on the choice
of parameters. The independence assumption of LDA can be very strong  and this may be crippling
for its use in many important applications. Given our example of images  one could easily generate
an image with eyes and a nose that cannot physically occur on a single person (perhaps overlapping).
BCM can also generate this image  but it would be unlikely  as the model would generally prefer to
copy the important features from a prototype.
BCM performs joint inference on prototypes  subspace feature indicators and cluster labels for ob-
servations. This encourages the inference step to achieve solutions where clusters are better repre-
sented by prototypes. We will show that this is beneﬁcial in terms of predictive accuracy in Sec-
tion 4.1. We will also show through an experiment involving human subjects that BCM’s succinct
representation is very effective for communicating the characteristics of clusters in Section 4.2.

3.2

Inference: collapsed Gibbs sampling

We use collapsed Gibbs sampling to perform inference  as this has been observed to converge
quickly  particularly in mixture models [17]. We sample !sj  zij  and ps  where  and ⇡ are in-
tegrated out. Note that we can recover  by simply counting the number of feature values assigned
to each subspace. Integrating out  and ⇡ results in the following expression for sampling zij:

p(zij = s|zi¬j  x  p  !  ↵  ) /

↵/S + n(s i ¬j ·)

↵ + n

⇥

g(psj  !sj  ) + n(s · j xij )

Ps g(psj  !sj  ) + n(s · j ·)

 

(1)

where n(s i j v) = 1(zij = s  xij = v). In other words  if xij takes feature value v for feature j
and is assigned to cluster s  then n(s i j v) = 1  or 0 otherwise. Notation n(s · j v) is the number of
times that the jth feature of an observation takes feature value v and that observation is assigned to
1(zij = s  xij = v)). Notation n(s · j ·) means sum over
i and v. We use n(s i ¬j v) to denote a count that does not include the feature j. The derivation is
similar to the standard collapsed Gibbs sampling for LDA mixture models [17].
Similarly  integrating out  results in the following expression for sampling !sj:

subspace cluster s (i.e.  n(s · j v) = Pi

p(!sj = b|q  psj      x  z  ↵) /8>><>>:

q ⇥
1  q ⇥

B(g(psj  1  ) + n(s · j ·))

B(g(psj  1  ))
B(g(psj  0  ) + n(s · j ·))

B(g(psj  0  ))

b = 1

b = 0 

(2)

where B is the Beta function and comes from integrating out  variables  which are sampled from
Dirichlet distributions.

4 Results

In this section  we show that BCM produces prediction accuracy comparable to or better than LDA
for standard datasets. We also verify the interpretability of BCM through human subject experiments
involving a task that requires an understanding of clusters within a dataset. We show statistically

5

(a) Accuracy and standard deviation
with SVM

(b) Unsupervised accuracy
for BCM

(c) Sensitivity analysis for BCM

Figure 2: Prediction test accuracy reported for the Handwritten Digit [19] and 20 Newsgroups
datasets [22]. (a) applies SVM for both LDA and BCM  (b) presents the unsupervised accuracy
of BCM for Handwritten Digit (top) and 20 Newsgroups (bottom) and (c) depicts the sensitivity
analysis conducted for hyperparameters for Handwritten Digit dataset. Datasets were produced by
randomly sampling 10 to 70 observations of each digit for the Handwritten Digit dataset  and 100-
450 documents per document class for the 20 Newsgroups dataset. The Handwritten Digit pixel
values (range from 0 to 255) were rescaled into seven bins (range from 0 to 6). Each 16-by-16 pixel
picture was represented as a 1D vector of pixel values  with a length of 256. Both BCM and LDA
were randomly initialized with the same seed (one half of the labels were incorrect and randomly
mixed)  The number of iterations was set at 1 000. S = 4 for 20 Newsgroups and S = 10 for
Handwritten Digit. ↵ = 0.01   = 1  c = 50  q = 0.8.

signiﬁcant improvements in objective measures of task performance using prototypes produced by
BCM  compared to output of LDA. Finally  we visually illustrate that the learned prototypes and sub-
spaces present as meaningful feedback for the characterization of important aspects of the dataset.

4.1 BCM maintains prediction accuracy.

We show that BCM output produces prediction accuracy comparable to or better than LDA  which
uses the same mixture model (Section 3) to learn the underlying structure but does not learn ex-
planations (i.e.  prototypes and subspaces). We validate this through use of two standard datasets:
Handwritten Digit [19] and 20 Newsgroups [22]. We use the implementation of LDA available from
[27]  which incorporates Gibbs sampling  the same inference technique used for BCM.
Figure 2a depicts the ratio of correctly assigned cluster labels for BCM and LDA. In order to com-
pare the prediction accuracy with LDA  the learned cluster labels are provided as features to a sup-
port vector machine (SVM) with linear kernel  as is often done in the LDA literature on cluster-
ing [6]. The improved accuracy of BCM over LDA  as depicted in the ﬁgures  is explained in part
by the ability of BCM to capture dependencies among features via prototypes  as described in Sec-
tion 3. We also note that prediction accuracy when using the full 20 Newsgroups dataset acquired
by LDA (accuracy: 0.68± 0.01) matches that reported previously for this dataset when using a com-
bined LDA and SVM approach [33]. Also  LDA accuracy for the full Handwritten Digit dataset
(accuracy: 0.76 ± 0.017) is comparable to that produced by BCM using the subsampled dataset (70
samples per digit  accuracy: 0.77 ± 0.03).
As indicated by Figure 2b  BCM achieves high unsupervised clustering accuracy as a function of
iterations. We can compute this measure for BCM because each cluster is characterized by a pro-
totype – a particular data point with a label in the given datasets. (Note that this is not possible for
LDA.) We set ↵ to prefer each ⇡i to be sparse  so only one prototype generates each observation 

6

(cid:1)(cid:2)(cid:2)(cid:3)(cid:2)(cid:2)(cid:4)(cid:2)(cid:2)(cid:5)(cid:2)(cid:2)(cid:6)(cid:2)(cid:2)(cid:7)(cid:2)(cid:2)(cid:8)(cid:2)(cid:2)(cid:9)(cid:10)(cid:11)(cid:12)(cid:13)(cid:14)(cid:15)(cid:16)(cid:17)(cid:18)(cid:19)(cid:18)(cid:20)(cid:15)(cid:21)(cid:22)(cid:19)(cid:23)(cid:2)(cid:24)(cid:2)(cid:2)(cid:24)(cid:3)(cid:2)(cid:24)(cid:5)(cid:2)(cid:24)(cid:7)(cid:2)(cid:24)(cid:25)(cid:1)(cid:24)(cid:2)(cid:26)(cid:27)(cid:28)(cid:18)(cid:29)(cid:29)(cid:10)(cid:14)(cid:18)(cid:29)(cid:30)(cid:31)(cid:32)(cid:28)(cid:33)(cid:34)(cid:35)(cid:1)(cid:2)(cid:2)(cid:3)(cid:2)(cid:2)(cid:4)(cid:2)(cid:2)(cid:5)(cid:2)(cid:2)(cid:2)(cid:5)(cid:6)(cid:2)(cid:2)(cid:5)(cid:1)(cid:2)(cid:2)(cid:5)(cid:3)(cid:2)(cid:2)(cid:5)(cid:4)(cid:2)(cid:2)(cid:7)(cid:8)(cid:9)(cid:10)(cid:11)(cid:12)(cid:13)(cid:14)(cid:15)(cid:16)(cid:17)(cid:16)(cid:18)(cid:13)(cid:19)(cid:20)(cid:17)(cid:21)(cid:2)(cid:22)(cid:2)(cid:2)(cid:22)(cid:6)(cid:2)(cid:22)(cid:1)(cid:2)(cid:22)(cid:3)(cid:2)(cid:22)(cid:4)(cid:5)(cid:22)(cid:2)(cid:23)(cid:24)(cid:25)(cid:16)(cid:26)(cid:26)(cid:8)(cid:12)(cid:16)(cid:26)(cid:27)(cid:28)(cid:29)(cid:25)(cid:30)(cid:31)(cid:32)Figure 3: Web-interface for the human subject experiment

and we use that prototype’s label for the observation. Sensitivity analysis in Figure 2c indicates that
the additional parameters introduced to learn prototypes and subspaces (i.e.  q   and c) are not too
sensitive within the range of reasonable choices.

4.2 Verifying the interpretability of BCM

We veriﬁed the interpretability of BCM by performing human subject experiments that incorporated
a task requiring an understanding of clusters within a dataset. This task required each participant
to assign 16 recipes  described only by a set of required ingredients (recipe names and instructions
were withheld)  to one cluster representation out of a set of four to six. (This approach is similar
to those used in prior work to measure comprehensibility [20].) We chose a recipe dataset1 for this
task because such a dataset requires clusters to be well-explained in order for subjects to be able to
perform classiﬁcation  but does not require special expertise or training.
Our experiment incorporated a within-subjects design  which allowed for more powerful statistical
testing and mitigated the effects of inter-participant variability. To account for possible learning
effects  we blocked the BCM and LDA questions and balanced the assignment of participants into
the two ordering groups: Half of the subjects were presented with all eight BCM questions ﬁrst 
while the other half ﬁrst saw the eight LDA questions. Twenty-four participants (10 females  14
males  average age 27 years) performed the task  answering a total of 384 questions. Subjects were
encouraged to answer the questions as quickly and accurately as possible  but were instructed to take
a 5-second break every four questions in order to mitigate the potential effects of fatigue.
Cluster representations (i.e.  explanations) from LDA were presented as the set of top ingredients
for each recipe topic cluster. For BCM we presented the ingredients of the prototype without the
name of the recipe and without subspaces. The number of top ingredients shown for LDA was set as
the number of ingredients from the corresponding BCM prototype and ran Gibbs sampling for LDA
with different initializations until the ground truth clusters were visually identiﬁable.
Using explanations from BCM  the average classiﬁcation accuracy was 85.9%  which was statisti-
cally signiﬁcantly higher (c2(1  N = 24) = 12.15  p ⌧ 0.001) than that of LDA  (71.3%). For
both LDA and BCM  each ground truth label was manually coded by two domain experts: the ﬁrst
author and one independent analyst (kappa coefﬁcient: 1). These manually-produced ground truth
labels were identical to those that LDA and BCM predicted for each recipe. There was no statisti-
cally signiﬁcant difference between BCM and LDA in the amount of time spent on each question
(t(24) = 0.89  p = 0.37); the overall average was 32 seconds per question  with 3% more time spent
on BCM than on LDA. Subjective evaluation using Likert-style questionnaires produced no statisti-
cally signiﬁcant differences between reported preferences for LDA versus BCM. Interestingly  this
suggests that participants did not have insight into their superior performance using output from
BCM versus that from LDA.

1Computer Cooking Contest: http://liris.cnrs.fr/ccc/ccc2014/

7

Prototype (Recipe names)
Herbs and Tomato in Pasta

Generic chili recipe

Microwave brownies

Spiced-punch

Ingredients ( Subspaces )
basil  garlic  Italian seasoning  oil
tomato
pasta pepper salt 
cumin  gar-
beer
chili powder
lic  meat  oil  onion  pepper  salt 
tomato
baking powder
butter 
chocolate chopped pecans  eggs 
ﬂour  salt  vanilla
cinnamon
stick 
orange juice
sugar  water  whole cloves

lemon juice
pineapple juice

sugar 

(a) Handwritten Digit dataset

(b) Recipe dataset

Figure 4: Learned prototypes and subspaces for the Handwritten Digit and Recipe datasets.

Overall  the experiment demonstrated substantial improvement to participants’ classiﬁcation accu-
racy when using BCM compared with LDA  with no degradation to other objective or subjective
measures of task performance.

4.3 Learning subspaces

Figure 4a illustrates the learned prototypes and subspaces as a function of sampling iterations for the
Handwritten Digit dataset. For the later iterations  shown on the right of the ﬁgure  the BCM output
effectively characterizes the important aspects of the data. In particular  the subspaces learned by
BCM are pixels that deﬁne the digit for the cluster’s prototype.
Interestingly  the subspace highlights the absence of writing in certain areas. This makes sense: For
example  one can deﬁne a ‘7’ by showing the absence of pixels on the left of the image where the
loop of a ‘9’ might otherwise appear. The pixels located where there is variability among digits of
the same cluster are not part of the deﬁning subspace for the cluster.
Because we initialized randomly  in early iterations  the subspaces tend to identify features common
to the observations that were randomly initialized to the cluster. This is because !s assigns higher
likelihood to features with the most similar values across observations within a given cluster. For
example  most digits ‘agree’ (i.e.  have the same zero pixel value) near the borders; thus  these are
the ﬁrst areas that are reﬁned  as shown in Figure 4a. Over iterations  the third row of Figure 4a
shows how BCM learns to separate the digits “3” and “5 ” which tend to share many pixel values in
similar locations. Note that the sparsity of the subspaces can be customized by hyperparameter q.
Next  we show results for BCM using the Computer Cooking Contest dataset in Figure 4b. Each pro-
totype consists of a set of ingredients for a recipe  and the subspace is a set of important ingredients
that deﬁne that cluster  highlighted in red boxes. For instance  BCM found a “chili” cluster deﬁned
by the subspace “beer ” “chili powder ” and “tomato.” A recipe called “Generic Chili Recipe” was
chosen as the prototype for the cluster. (Note that beer is indeed a typical ingredient in chili recipes.)

5 Conclusion

The Bayesian Case Model provides a generative framework for case-based reasoning and prototype-
based modeling. Its clusters come with natural explanations; namely  a prototype (a quintessential
exemplar for the cluster) and a set of deﬁning features for that cluster. We showed the quantitative
advantages in prediction quality and interpretability resulting from the use of BCM. Exemplar-based
modeling (nearest-neighbors  case-based reasoning) has historical roots dating back to the beginning
of artiﬁcial intelligence; this method offers a fresh perspective on this topic  and a new way of
thinking about the balance of accuracy and interpretability in predictive modeling.

8

References
[1] A. Aamodt. A knowledge-intensive  integrated approach to problem solving and sustained learning.

Knowledge Engineering and Image Processing Group. University of Trondheim  pages 27–85  1991.

[2] A. Aamodt and E. Plaza. Case-based reasoning: Foundational issues  methodological variations  and

system approaches. AI communications  1994.

[3] D. Baehrens  T. Schroeter  S. Harmeling  M. Kawanabe  K. Hansen  and K.R. M¨uller. How to explain

individual classiﬁcation decisions. JMLR  2010.

[4] I. Bichindaritz and C. Marling. Case-based reasoning in the health sciences: What’s next? AI in medicine 

2006.

[5] J. Bien  R. Tibshirani  et al. Prototype selection for interpretable classiﬁcation. AOAS  2011.
[6] D.M. Blei  A.Y. Ng  and M.I. Jordan. Latent dirichlet allocation. JMLR  2003.
[7] J.S. Carroll. Analyzing decision behavior: The magician’s audience. Cognitive processes in choice and

decision behavior  1980.

[8] J. Chang  J.L. Boyd-Graber  S. Gerrish  C. Wang  and D.M. Blei. Reading tea leaves: How humans

interpret topic models. In NIPS  2009.

[9] M.S. Cohen  J.T. Freeman  and S. Wolf. Metarecognition in time-stressed decision making: Recognizing 

critiquing  and correcting. Human Factors  1996.

[10] T. Cover and P. Hart. Nearest neighbor pattern classiﬁcation. Information Theory  1967.
[11] P. Cunningham  D. Doyle  and J. Loughrey. An evaluation of the usefulness of case-based explanation.

In CBRRD. Springer  2003.

[12] G. De’ath and K.E. Fabricius. Classiﬁcation and regression trees: a powerful yet simple technique for

ecological data analysis. Ecology  2000.

[13] J. Eisenstein  A. Ahmed  and E. Xing. Sparse additive generative models of text. In ICML  2011.
[14] A. Freitas. Comprehensible classiﬁcation models: a position paper. ACM SIGKDD Explorations  2014.
[15] S. Goh and C. Rudin. Box drawings for learning with imbalanced data. In KDD  2014.
[16] A. Graf  O. Bousquet  G. R¨atsch  and B. Sch¨olkopf. Prototype classiﬁcation: Insights from machine

learning. Neural computation  2009.

[17] T.L. Grifﬁths and M. Steyvers. Finding scientiﬁc topics. PNAS  2004.
[18] T. Hofmann. Probabilistic latent semantic indexing. In ACM SIGIR  1999.
[19] J.J. Hull. A database for handwritten text recognition research. TPAMI  1994.
[20] J. Huysmans  K. Dejaeger  C. Mues  J. Vanthienen  and B. Baesens. An empirical evaluation of the

comprehensibility of decision table  tree and rule based predictive models. DSS  2011.

[21] G.A. Klein. Do decision biases explain too much. HFES  1989.
[22] K. Lang. Newsweeder: Learning to ﬁlter netnews. In ICML  1995.
[23] B. Letham  C. Rudin  T. McCormick  and D. Madigan. Interpretable classiﬁers using rules and Bayesian

analysis. Technical report  University of Washington  2014.

[24] H. Li and J. Sun. Ranking-order case-based reasoning for ﬁnancial distress prediction. KBSI  2008.
[25] J.W. Murdock  D.W. Aha  and L.A. Breslow. Assessing elaborated hypotheses: An interpretive case-based

reasoning approach. In ICCBR. Springer  2003.

[26] A. Newell and H.A. Simon. Human problem solving. Prentice-Hall Englewood Cliffs  1972.
[27] X. Phan and C. Nguyen. GibbsLDA++  AC/C++ implementation of latent dirichlet allocation using gibbs

sampling for parameter estimation and inference  2013.

[28] S. Slade. Case-based reasoning: A research paradigm. AI magazine  1991.
[29] F. Sørmo  J. Cassens  and A. Aamodt. Explanation in case-based reasoning–perspectives and goals. AI

Review  2005.

[30] R. Tibshirani. Regression shrinkage and selection via the lasso. JRSS  1996.
[31] B. Ustun and C. Rudin. Methods and models for interpretable linear classiﬁcation. ArXiv  2014.
[32] S. Williamson  C. Wang  K. Heller  and D. Blei. The IBP compound dirichlet process and its application

to focused topic modeling. 2010.

[33] J. Zhu  A. Ahmed  and E.P. Xing. MedLDA: maximum margin supervised topic models. JMLR  2012.

9

,Been Kim
Cynthia Rudin
Julie Shah
James Atwood
Don Towsley
Amit Zohar
Lior Wolf