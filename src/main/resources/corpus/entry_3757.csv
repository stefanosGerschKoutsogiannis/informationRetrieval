2016,Neurons Equipped with Intrinsic Plasticity Learn Stimulus Intensity Statistics,Experience constantly shapes neural circuits through a variety of plasticity mechanisms. While the functional roles of some plasticity mechanisms are well-understood  it remains unclear how changes in neural excitability contribute to learning. Here  we develop a normative interpretation of intrinsic plasticity (IP) as a key component of unsupervised learning. We introduce a novel generative mixture model that accounts for the class-specific statistics of stimulus intensities  and we derive a neural circuit that learns the input classes and their intensities. We will analytically show that inference and learning for our generative model can be achieved by a neural circuit with intensity-sensitive neurons equipped with a specific form of IP. Numerical experiments verify our analytical derivations and show robust behavior for artificial and natural stimuli. Our results link IP to non-trivial input statistics  in particular the statistics of stimulus intensities for classes to which a neuron is sensitive. More generally  our work paves the way toward new classification algorithms that are robust to intensity variations.,Neurons Equipped with Intrinsic Plasticity

Learn Stimulus Intensity Statistics

Travis Monk

Cluster of Excellence Hearing4all

University of Oldenburg

26129 Oldenburg  Germany

Cristina Savin

IST Austria

3400 Klosterneuburg

Austria

travis.monk@uol.de

csavin@ist.ac.at

J¨org L¨ucke

Cluster of Excellence Hearing4all

University of Oldenburg

26129 Oldenburg  Germany

joerg.luecke@uol.de

Abstract

Experience constantly shapes neural circuits through a variety of plasticity mech-
anisms. While the functional roles of some plasticity mechanisms are well-
understood  it remains unclear how changes in neural excitability contribute to
learning. Here  we develop a normative interpretation of intrinsic plasticity (IP)
as a key component of unsupervised learning. We introduce a novel generative
mixture model that accounts for the class-speciﬁc statistics of stimulus intensities 
and we derive a neural circuit that learns the input classes and their intensities.
We will analytically show that inference and learning for our generative model
can be achieved by a neural circuit with intensity-sensitive neurons equipped with
a speciﬁc form of IP. Numerical experiments verify our analytical derivations and
show robust behavior for artiﬁcial and natural stimuli. Our results link IP to non-
trivial input statistics  in particular the statistics of stimulus intensities for classes
to which a neuron is sensitive. More generally  our work paves the way toward
new classiﬁcation algorithms that are robust to intensity variations.

1

Introduction

Confronted with the continuous ﬂow of experience  the brain takes amorphous sensory inputs and
translates them into coherent objects and scenes. This process requires neural circuits to extract key
regularities from their inputs and to use those regularities to interpret novel experiences. Such learn-
ing is enabled by a variety of plasticity mechanisms which allow neural networks to represent the
statistics of the world. The most well-studied plasticity mechanism is synaptic plasticity  where the
strength of connections between neurons changes as a function of their activity [1]. Other plasticity
mechanisms exist and operate in tandem. One example is intrinsic plasticity (IP)  where a neuron’s
response to inputs changes as a function of its own past activity. It is a challenge for computational
neuroscience to understand how different plasticity rules jointly contribute to circuit computation.
While much is known about the contribution of Hebbian plasticity to different variants of unsuper-
vised learning  including linear and non-linear sparse coding [2–5]  ICA [6]  PCA [7] or cluster-
ing [8–12]  other aspects of unsupervised learning remain unclear. First  on the computational side 
there are many situations in which the meaning of inputs should be invariant to its overall gain. For
example  a visual scene’s content does not depend on light intensity  and a word utterance should

30th Conference on Neural Information Processing Systems (NIPS 2016)  Barcelona  Spain.

be recognized irrespective of its volume. Current models do not explicitly take into account such
gain variations  and often eliminate them using an ad hoc preprocessing step that normalizes in-
puts [8  9  13]. Second  on the biological side  the roles of other plasticity mechanisms such as IP 
and their potential contributions to unsupervised learning  remain poorly understood.
IP changes the input-output function of a neuron depending on its past activity. Typically  IP is a
homeostatic negative feedback loop that preserves a neuron’s activation levels despite its changing
input [14  15]. There is no consensus on which quantities IP regulates  e.g. a neuron’s ﬁring rate  its
internal Ca concentration  its spiking threshold  etc. In modeling work  IP is usually implemented
as a simple threshold change that controls the mean ﬁring rate  although some models propose
more sophisticated rules that also constrain higher order statistics of the neuron’s output [6  16].
Functionally  while there have been suggestions that IP can play an important role in circuit function
[6  10  11  17]  its role in unsupervised learning is still not fully understood.
Here we show that a neural network that combines speciﬁc forms of Hebbian plasticity and IP
can learn the statistics of inputs with variable gain. We propose a novel generative model named
Product-Poisson-Gamma (PPG) that explicitly accounts for class-speciﬁc variation in input gain.
We then derive  from ﬁrst principles  a neural circuit that implements inference and learning for this
model. Our derivation yields a novel IP rule as a required component of unsupervised learning given
gain variations. Our model is unique in that it directly links IP to the gain variations of the pattern to
which a neuron is sensitive  which may be tested experimentally. Beyond neurobiology  the models
provide a new class of efﬁcient clustering algorithms that do not require data preprocessing. The
learned representations also permit efﬁcient classiﬁcation from very little labeled data.

2 The Product-Poisson-Gamma model

Intensity can vary drastically across images although the features present in it are the same.1 This
variability constitutes a challenge for learning and is typically eliminated through a preprocessing
stage in which the inputs are normalized [9]. While such preprocessing can make learning easier  ad
hoc normalizations may be suboptimal  or may require additional parameters to be set by hand. More
importantly  input normalization has the side-effect of losing information about intensity  which
might have helped identify the features themselves. For instance  in computer vision objects of the
same class are likely to have similar surface properties  resulting in a characteristic distribution of
light intensities. Light intensities can therefore aid classiﬁcation. In the neural context  the overall
drive to neurons may vary  e.g. due to attentional gain modulation  despite the underlying encoded
features being the same.
A principled way to address intensity variations is to explicitly model them in a generative model
describing the data. Then we can use that generative model to derive optimal inference and learning
for such data and map them to a corresponding neural circuit implementation. Let us assume the
stimuli are drawn from one of C classes  and let us denote a stimulus by (cid:126)y. Given a stimulus /
data point (cid:126)y  we wish to infer the class c that generated it (see Figure 1). Let (cid:126)y depend not only on
the class c  but also on a continuous random variable z  representing the intensity of the stimulus 
that itself depends on c as well as some parameters θ. Given these dependencies Pr((cid:126)y|c  z  θ) and
Pr(z|c  θ)  Bayes’ rule speciﬁes how to infer the class c and hidden variable z given an observation
of (cid:126)y:

Pr(c  z|(cid:126)y  θ) =

c(cid:48)(cid:82) Pr((cid:126)y|c(cid:48)  z(cid:48)  θ) Pr(z(cid:48)|c(cid:48)  θ) Pr(c(cid:48)|θ)dz
(cid:80)

Pr((cid:126)y|c  z  θ) Pr(z|c  θ) Pr(c|θ)

.

(1)

We can obtain neurally-implementable expressions for the posterior if our data generative model is
a mixture model with non-negative noise  e.g. a Poisson mixture model [9]. We extend the Poisson
mixture model by including an additional statistical description of stimulus intensity. The Gamma
distribution is a natural choice due to its conjugacy with the Poisson distribution. Let each of the D
elements in the vector (cid:126)y|z  c  θ (e.g. pixels in an image) be independent and Poisson-distributed  let
z|c  θ be Gamma-distributed  and let the prior of each class be uniform:

Pr((cid:126)y|c  z  θ) =

Pois(yd; zWcd); Pr(z|c  θ) = Gam(z; αc  βc); Pr(c|θ) =

1
C

D(cid:89)

d=1

1We use images as inputs and intensity as a measure of input gain as a running example. Our arguments

apply regardless of the type of sensory input  e.g. the volume of sound or the concentration of odor.

2

constrain the weights of the model to sum to one  (cid:80)

where all W   α  and β represent the parameters of the model. To avoid ambiguity in scales  we
d Wcd = 1. We call this generative model
a Product-Poisson-Gamma (PPG). While the multiplicative interaction between features and the
intensity or gain variable is reminiscent of the Gaussian Scale Mixture (GSM) generative model  note
that PPG has separate intensity distributions for each of the classes; each is a Gamma distribution
with a (possibly unique) shape parameter αc and rate parameter βc. Furthermore  the non-gaussian
observation noise is critical for deriving the circuit dynamics.
The model is general and ﬂexible  yet it is sufﬁciently constrained to allow for closed-form joint
posteriors. As shown in Appendix A  the joint posterior of the class and intensity is:

(cid:80)

NB(ˆy; αc 
c(cid:48) NB(ˆy; αc(cid:48) 

βc+1 ) exp ((cid:80)
βc(cid:48) +1 ) exp ((cid:80)

1

1

d yd ln Wcd)

d yd ln Wc(cid:48)d)

Gam(z; αc + ˆy  βc + 1) 

Pr(c  z|(cid:126)y  θ) =

where ˆy =(cid:80)

d yd  and NB represents the negative binomial distribution.

We also obtain a closed-form expression of the posterior marginalized over z  which takes the form
of a softmax function weighted by negative binomials:

(cid:80)

NB(ˆy; αc 
c(cid:48) NB(ˆy; αc(cid:48) 

βc+1 ) exp ((cid:80)
βc(cid:48) +1 ) exp ((cid:80)

1

1

d yd ln Wcd)

d(cid:48) yd(cid:48) ln Wc(cid:48)d(cid:48))

Pr(c|(cid:126)y  θ) =

(2)

This is a straightforward generalization of the standard softmax  used for optimal learning in winner-
take-all (WTA) networks [2 8 9 11] and WTA-based microcircuits [18]. Note that Eqn. 2 represents
the optimal way to integrate evidence for class membership originating from stimulus intensity (pa-
rameterized by (cid:126)α and (cid:126)β) and pattern ‘shape’ (parameterized by W ). If one of the two is not instruc-
tive  then the corresponding terms cancel out: if the patterns have identical shape (W with identical
rows)  then the softmax drops out and only negative binomial terms remain  and if all pattern classes
have the same intensity distribution  then the posterior reduces to the standard softmax function as
in previous work [2  8–11].
To facilitate the link to neural dynamics  Eqn. 2 can be simpliﬁed by approximating the negative
binomial distribution as Poisson. In the limit that αc → ∞ and the mean λc ≡ αc/βc = constant 
the negative binomial distribution is:

lim

αc→∞ αc/βc=const.

NB(ˆy; αc 

1

) = Pois(ˆy;

) ≡ Pois(ˆy; λc).

αc
βc

In this limit  Eqn. 2 becomes:

d(cid:48) yd(cid:48) ln(Wcd(cid:48)λc) − λc)
d(cid:48) yd(cid:48) ln(Wc(cid:48)d(cid:48)λc(cid:48)) − λc(cid:48))
which can be evaluated by a neural network using soft-WTA dynamics [9].

Pr(c|(cid:126)y  θ) ≈

βc + 1

exp((cid:80)
(cid:80)
c(cid:48) exp((cid:80)

3 Expectation-Maximization of PPG-generated data

(3)

As a starting point for deriving a biologically-plausible neural network for learning PPG-generated
data  let us ﬁrst consider optimal learning derived from the Expectation-Maximization (EM) algo-
rithm [19]. Given a set of N data points (cid:126)y(n)  we seek the parameters θ = {W  λ} that maximize
the data likelihood given the PPG-model deﬁned above. We use the EM formulation introduced
in [20] and optimize the free-energy given by:

F(θt  θt-1) =

Pr(c(cid:48)|(cid:126)y(n)  θt-1)(ln Pr((cid:126)y(n)|c(cid:48)  θt) + ln Pr(c(cid:48)|θt)) + H(θt-1).

(cid:88)

(cid:88)

n

c(cid:48)

Here  H(θt-1) is the Shannon entropy of the posterior as a function of the previous parameter values.
We can ﬁnd the M-step update rules for the parameters of the model λc and Wcd by taking the partial
derivative of F(θt  θt-1) w.r.t. the desired parameter and setting it to zero. As shown in Appendix B 
the resultant update rule for λc t is:
∂F(θt  θt-1)

(cid:80)
(cid:80)
n Pr(c|(cid:126)y(n)  θt-1)ˆy(n)
n Pr(c|(cid:126)y(n)  θt-1)

= 0 ⇒ λc t =

∂λc t

(4)

3

The M-step update rules for the weights Wcd are found by setting the corresponding partial derivative
d Wcd = 1. Using Lagrange multipliers Λc yields

the following update rule (see Appendix B):

of F(θt  θt-1) to zero  under the constraint that(cid:80)
(cid:88)
(cid:80)
(cid:80)
(cid:80)
n yd Pr(c|(cid:126)y(n)  θt-1)
n yd Pr(c|(cid:126)y(n)  θt-1)

∂Wcd t
⇒ Wcd t =

(cid:32)(cid:88)

∂F(θt  θt-1)

Λc(cid:48)

∂Wcd t

c(cid:48)

∂

d

+

(cid:33)

Wc(cid:48)d(cid:48) t − 1

= 0

d(cid:48)

.

(5)

c

.

As numerical veriﬁcation  Figure 1 illustrates the evolution of parameters λc and Wcd yielded by
the EM algorithm on artiﬁcial data. Our artiﬁcial data set consists of four classes of rectangles on
a grid of 10x10 pixels. Rectangles from different classes have different sizes and positions and are
represented by a generative vector W gen
We generate a data set by drawing a large number N of observations of W gen
  with each class
equiprobable. We then draw a random variable z from a Gamma distribution with parameters αc
and βc that depend on the class of each observation. Then  given W gen
and z  we create a data vector
(cid:126)y(n) by adding Poisson noise to each pixel. With a set of N data vectors (cid:126)y(n)  we then perform EM
to ﬁnd the parameters Wcd and λc that maximize the likelihood of the data set (at least locally). The
E-step evaluates Equation 2 for each data vector  and the M-step evaluates Equations 4 and 5. Figure
1 shows that  after about ﬁve iterations  the EM algorithm returns the values of Wcd and λc that were
used to generate the data set  i.e. the parameter values that maximize the data likelihood.

c

c

Figure 1: The evolution of model parameters yielded by the EM algorithm on artiﬁcial data. A: Four classes of
rectangles represented by the vector W gen
  with the values of λc for each class displayed to the left. B: Evolution
of the parameters Wcd for successive iterations of the EM algorithm. C: Evolution of the parameters λc  with
dashed lines indicating the values from the generative model. The EM algorithm returns the values of Wcd and
λc that were used to generate the data set  i.e. the parameter values that maximize the data likelihood. For these
plots  we generated a data set of 2000 inputs. W gen
c = 100 for white pixels and 1 for black pixels. The shape
and rate parameters of the Gamma distributions  from the top class to the bottom  are α = [98  112  128  144]
and β = [7  7.5  8  8.5]  giving λc = αc/βc = [14  15  16  17].

c

4 Optimal neural learning for varying stimulus intensities

For PPG-generated data  the posterior distribution of the class given an observation is approximately
the softmax function (or soft-WTA  Eqn. 3). Neural networks that implement the softmax function 
usually via some form of lateral inhibition  have been extensively investigated [2  8–11  21]. Thus 
inference in our model reduces to well-understood neural circuit dynamics.
The key remaining challenge is to analytically relate optimal learning as derived by EM to circuit
plasticity. To map abstract random variables to neural counterparts  we consider a complete bipar-
tite neural network  with the input layer corresponding to the observables y and the hidden layer
representing the latent causes of the observables  i.e. classes.2 The network is feedforward; each

2The number of hidden neurons does not necessarily need to equal the number of classes; see Figure 3.

4

neuron in the input layer connects to each neuron in the hidden layer via synaptic weights Wcd 
where c ∈ [1  C] indexes the C hidden neurons and d ∈ [1  D] indexes the D input neurons.
Let each of the hidden neurons have a standard activity variable  sc  and additionally an intrinsic
parameter λc that represents its excitability. Let the activity of each hidden neuron be given by
Eqn. 2. The activity of each hidden neuron is then the posterior distribution for one particular class 
given the inputs it receives from the input layer  its synaptic weights  and its excitability:

(cid:80)

sc =

;

Ic =

exp(Ic)
c(cid:48) exp(Ic(cid:48))

yd(cid:48) ln(Wcd(cid:48)λc) − λc.

(cid:88)

d(cid:48)

(cid:88)

d

The weights of the neural network Wcd are plastic and change according to a Hebbian learning rule
with synaptic scaling [22]:

where W is a small and positive learning rate  and ¯Wc =(cid:80)

∆Wcd = W (scyd − scλc ¯WcWcd) 
d Wcd.

The intrinsic parameters λc are also plastic and change according to a similar learning rule:

∆λc = λsc(

yd − λc) 

(6)

(7)

where λ is another small positive learning rate. This type of regulation of excitability is homeo-
static in form  but differs from standard implementations in that the excitability changes not only
depending on the neuron output  s  but also on the net input to the neuron (see also [17] for a formal

link between(cid:80)

d yd and average incoming inputs).

Appendix C shows that these online update rules enforce the desired weight normalization  with ¯Wc
converging to one. Assuming weight convergence  and assuming a small learning rate and a large
set of data points  the weights and intrinsic parameters converge to (see [9] and Appendix C):

(cid:80)
(cid:80)
d(cid:48)(cid:80)

n y(n)

d sc
n y(n)

d sc

cd ≈
W conv

;

λconv
c =

(cid:80)
n sc ˆy(n)(cid:80)

n sc

.

Comparing these convergence expressions with the EM updates (Eqns. 5 and 4) and inserting the
deﬁnition sc = Pr(c|(cid:126)y  θ)  we see that the neural dynamics given in Eqns. 6 and 7 have the same
ﬁxed points as optimal EM learning. The network can therefore ﬁnd the parameter values that op-
timize the data likelihood using compact and neurally-plausible learning rules. Eqn. 6 is a standard
form of Hebbian plasticity with synaptic scaling  while Eqn. 7 states how the excitability of hidden
neurons should be governed by the gain of the inputs and the current to the neuron.

5 Numerical Experiments

To verify our analytical results  we ﬁrst investigated learning in the derived neural network using
data generated according to the PPG model. Figure 2 illustrates the evolution of parameters λc and
Wcd yielded by the neural network on artiﬁcial data (the same as used for Figure 1). The neural
network learns the synaptic weights and intrinsic parameters that were used to generate the data set 
i.e. the parameter values that maximize the data likelihood.
Since our artiﬁcial data was PPG-generated  one can expect the neural network to learn the classes
and intensities quickly and accurately. To test the neural network on more realistic data  we followed
a number of related studies [8–12] and used the MNIST as a standard dataset containing different
stimulus classes. The input to the network was 28x28 pixel images (converted to vectors) from
the MNIST dataset. We present our results for the digits 0-3 for visual ease and simulation speed;
our results on the full dataset are qualitatively similar. We added an offset of 1 to all pixels and
rescaled them so that no pixel was greater than 1. The λc were initialized to be the mean intensity
of all digit classes as calculated from our modiﬁed MNIST training set. Each Wcd was initialized
as Wcd ∼ Pois(Wcd; µd) + 1  where µd is the mean of each pixel over all classes and is calculated
from our modiﬁed MNIST training set.
Figure 3 shows an example run using C = 16 hidden neurons. It shows the change in both neural
weights and intrisic excitabilities λc during learning. We observe that the weights change to repre-
sent the digit classes and converge relatively quickly (panels A  B). We veriﬁed that they sum to 1

5

Figure 2: The evolution of model parameters yielded by the neural network on artiﬁcial data generated from
the same model as that used in Figure 1. A: Four classes of rectangles with the values of λc for each class
displayed to the left. B: Evolution of the synaptic weights Wcd that feed each hidden unit after 0  20  40 
. . .   120 time steps  respectively. C: Evolution of the intrinsic parameters λc over 4000 time steps  with dashed
lines indicating the values from the generative model. The neural network returns the values of Wcd and λc that
were used to generate the data set  i.e. the parameter values that maximize the data likelihood. For these plots 
W = λ = .005  D = 100 (for a 10x10 pixel grid)  C = 4  initialized weights were uniformly-distributed
between .01 and .06  and initialized intrinsic parameters were uniformly-distributed between 10 and 20.

Figure 3: The neural network’s performance on a reduced MNIST dataset (the digits 0 to 3). A: Representa-
tives of the input digits. B: The network’s synaptic weights during training. Each square represents the weights
feeding one hidden neuron. Each box of 16 squares represents the weights feeding each of the C = 16 hidden
neurons after initialization  and after subsequent iterations over the training set. The network learns different
writing styles for different digits. C: The network learns the average intensities  i.e. the sum of the pixels in
an image  of each class of digit in MNIST. Algorithms that impose ad hoc intensity normalization in their pre-
processing cannot learn these intensities. The horizontal dashed lines are the average intensities of each digit 
with 1 having the lowest overall luminance and 0 the largest. The average λc for all hidden units representing
a given digit converge to those ground truth values. D: The network’s learned intensity differences improve
classiﬁcation performance. The percentage of correct digit classiﬁcations by a network with IP (solid lines) is
higher than that by a network without IP (dashed lines). This result is robust to the number of iterations over
the dataset and the number of labels used to calculate the Bayesian classiﬁer used in [9].

6

for each class at convergence (not shown). We also observe that the network’s IP dynamics allow it
to learn the average intensities of each class of digit (panel C). The thin horizontal dashed lines are
the true values for λc as calculated from the MNIST test set using its ground-truth label information.
IP modiﬁes the network’s excitability parameters λ to converge to their true values. Our network is
not only robust to variations in intensity  but learns their class-speciﬁc values.
A network that learns the excitability parameters λ exhibits a higher classiﬁcation rate than a network
without IP (panel D). We computed the performance of the network derived in Sec. 4 on unnormal-
ized data in comparison with a network without IP (all else being equal). As a performance measure
we used the classiﬁcation error (computed using the same Bayesian classiﬁer as used in [9]). Clas-
siﬁcation success rates were calculated with very few labels  using 0.5% (thin lines) and 5% (thick
lines) of labels in the training set (both settings for both networks). The classiﬁcation performance
of the network with IP outperforms that of the network without it. This result suggests that the
differences in intensities in MNIST  albeit visually small  are sufﬁcient to aid classiﬁcation.
Finally  Figure 4 shows that the neural network can learn classes that differ only in their intensities.
The dataset used for Figure 4 comprises 40000 images of two types of sphere: dull and shiny. The
spheres were identical in shape and position  and we generated data points (i.e. images) under a
variety of lighting conditions. On average  the shiny spheres were brighter (λshiny ≈ 720) than
the dull spheres (λdull ≈ 620). The network represents the two classes in its learned weights and
intensities. Algorithms that utilize ad hoc normalization preprocessing schemes would have serious
difﬁculties learning input statistics for datasets of this kind.

Figure 4: The neural network can learn classes that differ only in their intensities. The dataset consisted of
either dull or shiny spheres. The network had C = 2 hidden neurons. A: Three pairs of squares represent
the weights feeding each hidden neuron after initialization (leftmost pair)  10 iterations (center pair)  and 200
iterations (rightmost pair) over the training set. Note the rightmost pair  particularly how the right sphere
appears brighter than the left sphere. The right sphere corresponds to the shiny class and the left sphere to
the dull class. B: Learned mean intensities as a function of iterations over the training set. The dull spheres
have an average intensity of 620  and the shiny spheres 720. The network learns the classes and their average
intensities  even when data points from different classes have the same sizes and positions.

6 Discussion

Neural circuit models are powerful tools for understanding neural learning and information process-
ing. They have attracted attention as inherently parallel information processing devices for analog
VLSI  a fast and power-efﬁcient alternative to standard processor architectures [12 23]. Much work
has investigated learning with winner-take-all (WTA) type networks [2  8–12  18  21  24]. A subset
of these studies [2  8–11  21] link synaptic plasticity in WTA networks to optimal learning  mostly
using mixture distributions to model input stimuli [8–11  21]. Our contribution expands on these
results both computationally  by allowing for a robust treatment of variability in input gain  and
biologically  by providing a normative justiﬁcation for intrinsic plasticity during learning. Our an-
alytical results show that the PPG-generative model is tractable and neurally-implementable  while
our numerical results show that it is ﬂexible and robust.
Our model provides a principled treatment of intensity variations  something ubiquitous in realistic
datasets. As a result  it allows for robust learning without requiring normalized input data. This ad-
dresses the criticisms (see [10]) of earlier WTA-like circuits [8 9] that required normalized data. We
found that explicitly accounting for intensity improves classiﬁcation performance even for datasets
that have been size-normalized (e.g. MNIST)  presumably by providing an additional dimension for
discriminating across latent features. Furthermore  we found that the learned representation of the
MNIST data allows for good classiﬁcation in a semi-supervised setting  when only a small fraction

7

of the data is labeled. Thus  our model provides a starting point for constructing novel clustering
and classiﬁcation algorithms following the general approach in [9].
The treatment of intensity as an explicit variable is not new. The well-investigated class of Gaussian
Scale Mixtures (GSM) is built on that idea. Nonetheless  while GSM and PPG share some con-
ceptual similarities  they are mathematically distinct. While GSMs assume 1) Gaussian distributed
random variables and 2) a common scale variable [25]  PPG assumes 1’) Poisson observation noise
and 2’) class-speciﬁc scale variables. Consequently  none of the GSM results carry over to our
work  and our PPG assumptions are critical for our derived intrinsic plasticity and Hebbian plastic-
ity rules. It would be interesting to investigate a circuit analog of intensity parameter learning in a
GSM. Since this class of models is known to capture many features of afferent sensory neurons  we
might make more speciﬁc predictions concerning IP in V1. It would also be interesting to compare
the classiﬁcation performance of a GSM with that of PPG on the same dataset. The nature of the
GSM generative model (linear combination of features with multiplicative gain modulation) makes
it an unusual choice for a classiﬁcation task. However  in principle  one could use a GSM to learn a
representation of a dataset and train a classiﬁer on it.
The optimal circuit implementation of learning in our generative model requires a particular form of
IP. The formulation of IP is a phenomenological one  reﬂecting the biological observation that the
excitability of a neuron changes in a negative feedback loop as a function of past activity [14  15].
Mathematically  our model shares similarities with past IP models [6  10  17] with the important
difference that the controlled variable is the input current  rather than the output ﬁring rate. Since
the two quantities are closely related  we expect it will be difﬁcult to directly disambiguate between
IP models experimentally. Nonetheless  our model makes potentially testable predictions in terms
of the functional role of IP  by directly linking the excitability of individual neurons to nontrivial
statistics of their inputs  namely their average intensity under a Gamma distribution. Since past IP
work invariably assumes the target excitability is a ﬁxed parameter  usually shared across neurons 
the link between neural excitability and real world statistics is very speciﬁc to our model and po-
tentially testable experimentally. Furthermore  our work provides a computational rationale for the
dramatic variations in excitability across neurons  even within a local cortical circuit  which could
not be explained by traditional models.
The functional role for IP identiﬁed here complements previous proposals linking the regulation
of neuronal excitability to learning priors [11] or as posterior constraints [10  26]. Ultimately  it
is likely that the role of IP is manifold. Recent theoretical work suggests that the net effect of
inputs on neural excitability may arise as a complex interaction between several forms of IP  some
homeostatic and others not [17]. Furthermore  different experimental paradigms may preferentially
expose one IP process over the others  which would explain the confusion within the literature on
the exact nature of biological IP. Taken together  these models point to a fundamental role of IP for
circuit computation in a variety of setups. Given its many possible roles  any approach based on
ﬁrst principles is valuable  as it tightly connects IP to concrete stimulus properties in a way that can
translate into better-constrained experiments.
Acknowledgements. We acknowledge funding by the DFG within the Cluster of Excellence EXC
1077/1 (Hearing4all) and by grant LU 1196/5-1 (JL and TM) and the People Programme (Marie
Curie Actions) of the European Union’s Seventh Framework Programme (FP7/2007-2013) under
REA grant agreement no. 291734 (CS).

References

[1] L F Abbott and S B Nelson. Synaptic plasticity: taming the beast. Nat Neurosci  3:1178 –

1183  2000.

[2] J L¨ucke and M Sahani. Maximal causes for non-linear component extraction. J Mach Learn

Res  9:1227–67  2008.

[3] C J Rozell  D H Johnson  R G Baraniuk  and B A Olshausen. Sparse coding via thresholding

and local competition in neural circuits. Neural Comput  20(10):2526–63  October 2008.

[4] J L¨ucke. Receptive ﬁeld self-organization in a model of the ﬁne-structure in V1 cortical

columns. Neural Comput  21(10):2805–45  2009.

8

[5] J Zylberberg  J T Murphy  and M R Deweese. A Sparse Coding Model with Synaptically
Local Plasticity and Spiking Neurons Can Account for the Diverse Shapes of V1 Simple Cell
Receptive Fields. PLoS Comp Biol  7(10):e1002250  2011.

[6] C Savin  P Joshi  and J Triesch. Independent Component Analysis in Spiking Neurons. PLoS

Comp Biol  6(4):e1000757  April 2010.

[7] E Oja. A simpliﬁed neuron model as a principal component analyzer. J Math Biol  15:267 –

273  1982.

[8] B Nessler  M Pfeiffer  and W Maass. Stdp enables spiking neurons to detect hidden causes of

their inputs. In Adv Neural Inf Process Syst  pages 1357–1365  2009.

[9] C Keck  C Savin  and J L¨ucke. Feedforward inhibition and synaptic scaling–two sides of the

same coin? PLoS Comp Biol  8(3):e1002432  2012.

[10] S Habenschuss  J Bill  and B Nessler. Homeostatic plasticity in bayesian spiking networks as
expectation maximization with posterior constraints. In Adv Neural Inf Process Syst  pages
773–781  2012.

[11] B Nessler  M Pfeiffer  L Buesing  and W Maass. Bayesian computation emerges in
generic cortical microcircuits through spike-timing-dependent plasticity. PLoS Comp Biol 
9(4):e1003037  2013.

[12] M Schmuker  T Pfeil  and M P Nawrot. A neuromorphic network for generic multivariate data

classiﬁcation. Proc Natl Acad Sci  111(6):2081–2086  2014.

[13] O Schwartz and E P Simoncelli. Natural sound statistics and divisive normalization in the

auditory system. Adv Neural Inf Process Syst  pages 166–172  2000.

[14] G Daoudal and D Debanne. Long-term plasticity of intrinsic excitability: learning rules and

mechanisms. Learn Memory  10(6):456–465  2003.

[15] R H Cudmore and G G Turrigiano. Long-term potentiation of intrinsic excitability in lv visual

cortical neurons. J Neurophysiol  92(1):341–348  2004.

[16] M Stemmler and C Koch. How voltage-dependent conductances can adapt to maximize the

information encoded by neuronal ﬁring rate. Nat Neurosci  2(6):521–527  1999.

[17] C Savin  P Dayan  and M Lengyel. Optimal Recall from Bounded Metaplastic Synapses: Pre-
dicting Functional Adaptations in Hippocampal Area CA3. PLoS Comp Biol  10(2):e1003489 
February 2014.

[18] Rodney J Douglas and Kevan AC Martin. Neuronal circuits of the neocortex. Annu Rev

Neurosci  27:419–451  2004.

[19] A P Dempster  N M Laird  and D B Rubin. Maximum likelihood from incomplete data via the

EM algorithm (with discussion). J R Stat Soc Series B  39:1–38  1977.

[20] R Neal and G Hinton. A view of the EM algorithm that justiﬁes incremental  sparse  and other

variants. In M. I. Jordan  editor  Learning in Graphical Models. Kluwer  1998.

[21] D J Rezende  D Wierstra  and W Gerstner. Variational learning for recurrent spiking networks.

Adv Neural Inf Process Syst  pages 136–144  2011.

[22] L F Abbott and S B Nelson. Synaptic plasticity: taming the beast. Nat Neurosci  3(Supp):1178–

1183  November 2000.

[23] E Neftci  J Binas  U Rutishauser  E Chicca  G Indiveri  and R J Douglas. Synthesizing cogni-

tion in neuromorphic electronic systems. Proc Natl Acad Sci  110(37):E3468–E3476  2013.

[24] J L¨ucke and C Malsburg. Rapid processing and unsupervised learning in a model of the cortical

macrocolumn. Neural Comput  16:501–33  2004.

[25] M J Wainwright  E P Simoncelli  and A S Willsky. Random cascades on wavelet trees and
their use in analyzing and modeling natural images. Appl Comput Harmon Anal  11(1):89–
123  2001.

[26] S Deneve. Bayesian spiking neurons i: inference. Neural Comput  20(1):91–117  2008.

9

,Travis Monk
Cristina Savin
Jörg Lücke
Yujia Jin
Aaron Sidford