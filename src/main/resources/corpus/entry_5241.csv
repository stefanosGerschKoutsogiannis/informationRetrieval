2013,Stochastic Gradient Riemannian Langevin Dynamics on the Probability Simplex,In this paper we investigate the use of Langevin Monte Carlo methods on the probability simplex and propose a new method  Stochastic gradient Riemannian Langevin dynamics  which is simple to implement and can be applied online. We apply this method to latent Dirichlet allocation in an online setting  and demonstrate that it achieves substantial performance improvements to the state of the art online variational Bayesian methods.,Stochastic Gradient Riemannian Langevin Dynamics

on the Probability Simplex

Sam Patterson

Gatsby Computational Neuroscience Unit

University College London

spatterson@gatsby.ucl.ac.uk

Yee Whye Teh

Department of Statistics

University of Oxford

y.w.teh@stats.ox.ac.uk

Abstract

In this paper we investigate the use of Langevin Monte Carlo methods on the
probability simplex and propose a new method  Stochastic gradient Riemannian
Langevin dynamics  which is simple to implement and can be applied to large
scale data. We apply this method to latent Dirichlet allocation in an online mini-
batch setting  and demonstrate that it achieves substantial performance improve-
ments over the state of the art online variational Bayesian methods.

1

Introduction

(cid:88)

In recent years there has been increasing interest in probabilistic models where the latent variables
or parameters of interest are discrete probability distributions over K items  i.e. vectors lying in the
probability simplex

∆K = {(π1  . . .   πK) : πk ≥ 0 

πk = 1} ⊂ RK

(1)

k

Important examples include topic models like latent Dirichlet allocation (LDA) [BNJ03]  admixture
models in genetics like Structure [PSD00]  and discrete directed graphical models with a Bayesian
prior over the conditional probability tables [Hec99].
Standard approaches to inference over the probability simplex include variational inference [Bea03 
WJ08] and Markov chain Monte Carlo methods (MCMC) like Gibbs sampling [GRS96]. In the
context of LDA  many methods have been developed  e.g. variational inference [BNJ03]  collapsed
variational inference [TNW07  AWST09] and collapsed Gibbs sampling [GS04]. With the increas-
ingly large scale document corpora to which LDA and other topic models are applied  there has
also been developments of specialised and highly scalable algorithms [NASW09]. Most proposed
algorithms are based on a batch learning framework  where the whole document corpus needs to be
stored and accessed for every iteration. For very large corpora  this framework can be impractical.
Most recently  [Sat01  HBB10  MHB12] proposed online Bayesian variational inference algorithms
(OVB)  where on each iteration only a small subset (a mini-batch) of the documents is processed
to give a noisy estimate of the gradient  and a stochastic gradient descent algorithm [RM51] is
employed to update the parameters of interest. These algorithms have shown impressive results on
very large corpora like Wikipedia articles  where it is not even feasible to store the whole dataset in
memory. This is achieved by simply fetching the mini-batch articles in an online manner  processing 
and then discarding them after the mini-batch.
In this paper  we are interested in developing scalable MCMC algorithms for models deﬁned over
the probability simplex. In some scenarios  and particularly in LDA  MCMC algorithms have been
shown to work extremely well  and in fact achieve better results faster than variational inference
on small to medium corpora [GS04  TNW07  AWST09]. However current MCMC methodology

1

have mostly been in the batch framework which  as argued above  cannot scale to the very large
corpora of interest. We will make use of a recently developed MCMC method called stochastic
gradient Langevin dynamics (SGLD) [WT11  ABW12] which operates in a similar online mini-
batch framework as OVB. Unlike OVB and other stochastic gradient descent algorithms  SGLD
is not a gradient descent algorithm. Rather  it is a Hamiltonian MCMC [Nea10] algorithm which
will asymptotically produce samples from the posterior distribution. It achieves this by updating
parameters according to both the stochastic gradients as well as additional noise which forces it to
explore the full posterior instead of simply converging to a MAP conﬁguration.
There are three difﬁculties that have to be addressed  however  to successfully apply SGLD to LDA
and other models deﬁned on probability simplices. Firstly  the probability simplex (1) is compact
and has boundaries that has to be accounted for when an update proposes a step that brings the
vector outside the simplex. Secondly  the typical Dirichlet priors over the probability simplex place
most of its mass close to the boundaries and corners of the simplex. This is particularly the case for
LDA and other linguistic models  where probability vectors parameterise distributions over a larger
number of words  and it is often desirable to use distributions that place signiﬁcant mass on only
a few words  i.e. we want distributions over ∆K which place most of its mass near the boundaries
and corners. This also causes a problem as depending on the parameterisation used  the gradient
required for Langevin dynamics is inversely proportional to entries in π and hence can blow up
when components of π are close to zero. Finally  again for LDA and other linguistic models  we
would like algorithms that work well in high-dimensional simplices.
These considerations lead us to the ﬁrst contribution of this paper in Section 3  which is an inves-
tigation into different ways to parameterise the probability simplex. This section shows that the
choice of a good parameterisation is not obvious  and that the use of the Riemannian geometry of
the simplex [Ama95  GC11] is important in designing Langevin MCMC algorithms. In particular 
we show that an unnormalized parameterisation  using a mirroring trick to remove boundaries  cou-
pled with a natural gradient update  achieves the best mixing performance. In Section 4  we then
show that the SGLD algorithm  using this parameterisation and natural gradient updates  performs
signiﬁcantly better than OVB algorithms [HBB10  MHB12]. Section 2 reviews Langevin dynamics 
natural gradients and SGLD to setup the framework used in the paper  and Section 6 concludes.

2 Review

2.1 Langevin dynamics

Suppose we model a data set x = x1  . . .   xN   with a generative model p(x | θ) = (cid:81)N

i=1 p(xi |
θ) parameterized by θ ∈ RD with prior p(θ) and that our aim is to compute the posterior p(θ |
x). Langevin dynamics [Ken90  Nea10] is an MCMC scheme which produces samples from the
posterior by means of gradient updates plus Gaussian noise  resulting in a proposal distribution
q(θ∗ | θ) as described by Equation 2.

θ∗ = θ +


2

∇θlog p(θ) +

∇θlog p(xi|θ)

+ ζ 

ζ ∼ N (0  I)

(2)

The mean of the proposal distribution is in the direction of increasing log posterior due to the gra-
dient  while the added noise will prevent the samples from collapsing to a single (local) maximum.
A Metropolis-Hastings correction step is required to correct for discretisation error  with proposals
[RS02]. As  tends to zero  the acceptance ratio
accepted with probability min
tends to one as the Markov chain tends to a stochastic differential equation which has p(θ | x) as its
stationary distribution [Ken78].

1  p(θ∗|x)
p(θ|x)

q(θ|θ∗)
q(θ∗|θ)

(cid:17)

(cid:16)

2.2 Riemannian Langevin dynamics

Langevin dynamics has an isotropic proposal distribution leading to slow mixing if the components
of θ have very different scales or if they are highly correlated. Preconditioning can help with this. A
recent approach  the Riemann manifold Metropolis adjusted Langevin algorithm [GC11] uses a user
chosen matrix G(θ) to precondition in a locally adaptive manner. We will refer to their algorithm

2

(cid:32)

N(cid:88)

i=1

(cid:33)

as Riemannian Langevin dynamics (RLD) in this paper. The Riemannian manifold in question is
the family of probability distributions p(x | θ) parameterised by θ  for which the expected Fisher
information matrix Iθ deﬁnes a natural Riemannian metric tensor. In fact any positive deﬁnite matrix
G(θ) deﬁnes a valid Riemannian manifold and hence we are not restricted to using G(θ) = Iθ. This
is important in practice as for many models of interest the expected Fisher information is intractable.
As in Langevin dynamics  RLD consists of a Gaussian proposal q(θ∗ | θ)  along with a Metropolis-
Hastings correction step. The proposal distribution can be written as

θ∗ = θ +

µ(θ) + G− 1

2 (θ)ζ 

ζ ∼ N (0  I)

where the jth component of µ(θ) is given by

µ(θ)j =

G−1(θ)

∇θlog p(θ) +

∇θlog p(xi|θ)

(cid:33)(cid:33)

(cid:18)

G−1(θ)

D(cid:88)

k=1

− 2

∂G(θ)

∂θk

G−1(θ)

j

(cid:32)

D(cid:88)

k=1

+

(cid:32)
(cid:0)G−1(θ)(cid:1)


2

(cid:18)

N(cid:88)

i=1

(cid:19)

jk Tr

G−1(θ)

∂G(θ)

∂θk

(3)

(cid:19)

jk

(4)

The ﬁrst term in Equation 4 is now the natural gradient of the log posterior. Whereas the standard
gradient gives the direction of steepest ascent in Euclidean space  the natural gradient gives the
direction of steepest descent taking into account the geometry implied by G(θ). The remaining
terms in Equation 4 describe how the curvature of the manifold deﬁned by G(θ) changes for small
changes in θ. The Gaussian noise in Equation 3 also takes the geometry of the manifold into account 
having scale deﬁned by G− 1

2 (θ).

2.3 Stochastic gradient Riemannian Langevin dynamics

In the Langevin dynamics and RLD algorithms  the proposal distribution requires calculation of the
gradient of the log likelihood w.r.t. θ  which means processing all N items in the data set. For
large data sets this is infeasible  and even for small data sets it may not be the most efﬁcient use of
computation. The stochastic gradient Langevin dynamics (SGLD) algorithm [WT11] replaces the
calculation of the gradient over the full data set  with a stochastic approximation based on a subset
of data. Speciﬁcally at iteration t we sample n data items indexed by Dt  uniformly from the full
data set and replace the exact gradient in Equation 2 with the approximation

∇θlogp(x | θ) ≈ N
|Dt|

∇θlog p(xi|θ)

(5)

(cid:88)

i∈Dt

Also  SGLD does not use a Metropolis-Hastings correction step  as calculating the acceptance prob-
ability would require use of the full data set  hence defeating the purpose of the stochastic gradient
approximation. Convergence to the posterior is still guaranteed as long as decaying step sizes satis-

fying(cid:80)∞

t=1 t = ∞ (cid:80)∞

t < ∞ are used.

t=1 2

In this paper we combine the use of a preconditioning matrix G(θ) as in RLD with this stochastic
gradient approximation  by replacing the exact gradient in Equation 4 with the approximation from
Equation 5. The resulting algorithm  stochastic gradient Riemannian Langevin dynamics (SGRLD) 
avoids the slow mixing problems of Langevin dynamics  while still being applicable in a large scale
online setting due to its use of stochastic gradients and lack of Metropolis-Hastings correction steps.

3 Riemannian Langevin dynamics on the probability simplex

In this section  we investigate the issues which arise when applying Langevin Monte Carlo meth-
ods  speciﬁcally the Langevin dynamics and Riemannian Langevin dynamics algorithms  to models
whose parameters lie on the probability simplex. In these experiments  a Metropolis-Hastings cor-
rection step was used. Consider the simplest possible model: a K dimensional probability vector
  and data x = x1  . . .   xN with p(xi = k | π) = πk.
i=1 δ(xi = k). In

π with Dirichlet prior p(π) ∝ (cid:81)K
This results in a Dirchlet posterior p(π | x) ∝ (cid:81)K

  where nk = (cid:80)N

k πnk+αk−1

k παk−1

k

k

3

Parameterisation

θ

∇θlog p(θ|x)

(cid:16)
(cid:80)D
(cid:0)G−1(θ)(cid:1)

G(θ)
G−1(θ)
G−1 ∂G
∂θk
jk Tr

k=1

G−1(cid:17)
(cid:16)

(cid:80)D

k=1

jk

G−1(θ) ∂G

∂θk

Reduced-Mean

(cid:16)

n·

θk = πk

n+α

diag(θ)−1 +

θ − 1 nK +α−1
1−(cid:80)
(cid:0)diag(θ) − θθT(cid:1)

πK
1

k θk

1
n·

(cid:17)

Kθj − 1
Kθj − 1

11T(cid:17)

(cid:16)

n·

πk

πk

k

1
n·

Reduced-Natural

1−(cid:80)K−1
θk = log
(cid:0)diag(π) − ππT(cid:1)
n + α − (n· + Kα) π
1−(cid:80)
diag(π)−1 +
(1−(cid:80)
(1−(cid:80)

1
k πk

−
−

K−1

K−1

k πk)2

1
π2
j
1
π2
j

k πk)2

11T(cid:17)

Expanded-Mean
|θk|(cid:80)
πk =
k=1 |θk|
θ − n·
θ· − 1
n+α−1
−1
diag (θ)
diag (θ)

Expanded-Natural

πk = eθk(cid:80)
diag(cid:0)eθ(cid:1)
k=1 eθk
n + α − n·π − eθ
diag(cid:0)e−θ(cid:1)

−1
−1

e−θj
e−θj

Table 1: Parameterisation Details

k

k θk

our experiments we use a sparse  symmetric prior with αk = 0.1∀k  and sparse count data  setting
K = 10 and n1 = 90  n2 = n3 = 5 and the remaining nk to zero. This is to replicate the sparse
nature of the posterior in many models of interest. The qualitative conclusions we draw are not
sensitive to the precise choice of hyperparameters and data here.
There are various possible ways to parameterise the probability simplex  and the performance of
Langevin Monte Carlo depends strongly on the choice of parameterisation. We consider both the
mean and natural parameter spaces  and in each of these we try both a reduced (K − 1 dimensional)
and expanded (K dimensional) parameterisation  with details as follows.
Reduced-Mean: in the mean parameter space  the most obvious approach is to set θ = π directly 
but there are two problems with this. Though π has K components  it must lie on the simplex  a
K − 1 dimensional space. Running Langevin dynamics or RLD on the full K dimensional param-
eterisation will result in proposals that are off the simplex with probability one. We can incorporate
k=1 πk = 1 by using the ﬁrst K − 1 components as the parameter θ  and set-
k=1 πk. Note however that the proposals can still violate the boundary constraint
0 < πk < 1  and this is particularly problematic when the posterior has mass close to the boundaries.
Expanded-Mean: we can simplify boundary considerations using a redundant parameterisation.
We take as our parameter θ ∈ RK
+ with prior a product of independent Gamma(αk  1) distributions 
and so the prior on π is still Dirichlet(α).
The boundary conditions 0 < θk can be handled by simply taking the absolute value of the proposed
θ∗. This is equivalent to letting θ take values in the whole of RK  with prior given by Gammas
|θk|(cid:80)
k |θk|  which again results in a Dirichlet(α)

the constraint that(cid:80)K
ting πK = 1 −(cid:80)K−1
p(θ) ∝(cid:81)K
mirrored at 0  p(θ) ∝(cid:81)K

e−θk. π is then given by πk = θk(cid:80)

k=1 |θk|αk−1e−|θk|  and πk =

k=1 θαk−1

eθk
k=1 eθk

eθk(cid:80)K

1+(cid:80)K−1

prior on π. This approach allows us to bypass boundary issues altogether.
Reduced-Natural: in the natural parameter space  the reduced parameterisation takes the form
for k = 1  . . .   K − 1. The prior on θ can be obtained from the Dirichlet(α) prior
πk =
on π using a change of variables. There are no boundary constraints as the range of θk is R.
Expanded-Natural: ﬁnally the expanded-natural parameterisation takes the form πk =
k=1 eθk
for k = 1  . . .   K. As in the expanded-mean parameterisation  we use a product of Gamma priors 
in this case for eθk  so that the prior for π remains Dirichlet(α).
For all parameterisations  we run both Langevin dynamics and RLD. When applying RLD  we
must choose a metric G(θ). For the reduced parameterisations  we can use the expected Fisher
information matrix  but the redundancy in the full parameterisations means that this matrix has rank
K−1 and hence is not invertible. For these parameterisations we use the expected Fisher information
matrix for a Gamma/Poisson model  which is equivalent to the Dirichlet/Multinomial apart from the
fact that the total number of data items is considered to be random as well.
The details for each parameterisation are summarised in Table 1.
In all cases we are interested
in sampling from the posterior distribution on π  while θ is the speciﬁc parameterisation being
used. For the mean parameterisations  the θ−1 term in the gradient of the log-posterior means
that for components of θ which are close to zero  the proposal distribution for Langevin dynamics
(Equation 2) has a large mean  resulting in unstable proposals with a small acceptance probability.
Due to the form of G(θ)−1  the same argument holds for the RLD proposal distribution for the
natural parameterisations. This leaves us with three possible combinations  RLD on the expanded-
mean parameterisation and Langevin dynamics on each of the natural parameterisations.

4

(a) Effective sample size

(b) Samples

Figure 1: Effective sample size and samples. Burn-in iterations is 10 000; thinning factor 100.

To investigate their relative performances we run a small experiment  producing 110 000 samples
from each of the three remaining parameterisations  discarding 10 000 burn-in samples and thinning
the remaining samples by a factor of 100. For the resulting 1000 thinned samples of θ  we calculate
the corresponding samples of π  and compute the effective sample size for each component of π.
This was done for a range of step sizes   and the mean and median effective sample sizes for the
components of π is shown in Figure 1(a).
Figure 1(b) shows the samples from each sampler at their optimal step size of 0.1. The samples
from Langevin dynamics on both natural parameterisations display higher auto-correlation than the
RLD samples produced using the expanded-mean parameterisation  as would be expected from their
lower effective sample sizes. In addition to the increased effective sample size  the expanded-mean
parameterisation RLD sampler has the advantage that it is computationally efﬁcient as G(θ) is a
diagonal matrix. Hence it is this algorithm that we use when applying these techniques to latent
Dirichlet allocation in Section 4.

4 Applying Riemannian Langevin dynamics to latent Dirichlet allocation

Latent Dirichlet Allocation (LDA) [BNJ03] is a hierarchical Bayesian model  most frequently used
to model topics arising in collections of text documents. The model consists of K topics πk  which
are distributions over the words in the collection  drawn from a symmetric Dirichlet prior with
hyper-parameter β. A document d is then modelled by a mixture of topics  with mixing proportion
ηd  drawn from a symmetric Dirichlet prior with hyper-parameter α. The model corresponds to a
generative process where documents are produced by drawing a topic assignment zdi i.i.d. from ηd
for each word wdi in document d  and then drawing the word wdi from the corresponding topic πzdi.
We integrate out η analytically  resulting in the semi-collapsed distribution:

D(cid:89)

K(cid:89)

K(cid:89)

W(cid:89)

p(w  z  π | α  β) =

where as in [TNW07]  ndkw = (cid:80)Nd

d=1

Γ (Kα)

Γ (Kα + nd··)

(6)
i=1 δ(wdi = w  zdi = k) and · denotes summation over the

Γ (α)

w=1

k=1

k=1

corresponding index. Conditional on π  the documents are i.i.d.  and we can factorise Equation 6

Γ (α + ndk·)

Γ(W β)
Γ(β)W

πβ+n·kw−1

kw

D(cid:89)

p(w  z  π | α  β) = p(π | β)

p(wd  zd | α  π)

where

p(wd  zd | α  π) =

d=1

Γ (α + ndk·)

Γ (α)

K(cid:89)

k=1

W(cid:89)

w=1

πndkw
kw

5

(7)

(8)

10^−510^−410^−310^−210^−110^001002003004005006007008009001000Step sizeESS  Expanded−Mean RLD medianExpanded−Mean RLD meanReduced−Natural LD medianReduced−Natural LD meanExpanded−Natural LD medianExpanded−Natural LD mean0100200300400500600700800900100010−810−610−410−21000100200300400500600700800900100010−2810−2110−1410−71000100200300400500600700800900100010−1610−1210−810−4100Thinned sample number4.1 Stochastic gradient Riemannian Langevin dynamics for LDA

dent Gamma prior p(θk) ∝ (cid:81)W

As we would like to apply these techniques to large document collections  we use the stochas-
tic gradient version of the Riemannian Langevin dynamics algorithm  as detailed in Section 2.3.
Following the investigation in Section 3 we use the expanded-mean parameterisation. For each
of the K topics πk  we introduce a W -dimensional unnormalised parameter θk with an indepen-
  for w = 1  . . .   W .
We use the mirroring idea as well. The metric G(θ) is then the diagonal matrix G(θ) =
diag (θ11  . . .   θ1W   . . .   θK1  . . .   θKW )
The algorithm runs on mini-batches of documents: at time t it receives a mini-batch of documents
indexed by Dt  drawn at random from the full corpus D. The stochastic gradient of the log posterior
of θ on Dt is shown in Equation 9.

kw e−θkw and set πkw = θkw(cid:80)
w=1 θβw−1
−1.

w θkw

− 1 +

|D|
|Dt|

(cid:88)

d∈Dt

Ezd|wd θ α

(cid:21)

− ndk·
θk·

(cid:20) ndkw
(cid:33)

θkw

∂log p(θ | w  β  α)

∂θkw

(cid:32)

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)θkw +


2

θkw

≈ β − 1
(cid:88)

|D|
|Dt|

d∈Dt

For this choice of θ and G(θ)  we use Equations 3  4 to give the SGRLD update for θ 

θ∗
kw =

β − θkw +

Ezd|wd θ α [ndkw − πkwndk·]

+ (θkw)

1

2 ζkw

(9)

(10)

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

where ζkw ∼ N (0  ). Note that the β−1 term in Equation 9 has been replaced with β in Equation 10
as the −1 cancels with the curvature terms as detailed in Table 1. As discussed in Section 3  we
reﬂect moves across the boundary 0 < θkw by taking the absolute value of the proposed update.
Comparing Equation 9 to the gradient for the simple model from Section 3  the observed counts
nk for the simple model have been replaced with the expectation of the latent topic assignment
counts ndkw. To calculate this expectation we use Gibbs sampling on the topic assignments in each
document separately  using the conditional distributions

p(zdi = k | wd  θ  α) =

(11)

(cid:16)
(cid:80)

k

(cid:16)

(cid:17)

(cid:17)

\i
dk·
\i
dk·

α + n

θkwdi

α + n

θkwdi

where \i represents a count excluding the topic assignment variable we are updating.

5 Experiments

d i q(zdi)(cid:81)

We investigate the performance of SGRLD  with no Metropolis-Hastings correction step  on two
real-world data sets. We compare it to two online variational Bayesian algorithms developed
for latent Dirichlet allocation: online variational Bayes (OVB) [HBB10] and hybrid stochastic
variational-Gibbs (HSVG) [MHB12]. The difference between these two methods is the form of vari-
ational assumption made. OVB assumes a mean-ﬁeld variational posterior  q(η1:D  z1:D  π1:K) =
k q(πk)  in particular this means topic assignment variables within the same
document are assumed to be independent  when in reality they will be strongly coupled. In con-
trast HSVG collapses ηd analytically and uses a variational posterior of the form q(z1:D  π1:K) =
k q(πk)  which allows dependence within the components of zd. This more complicated
posterior requires Gibbs sampling in the variational update step for zd  and we combined the code
for OVB [HBB10]  with the Gibbs sampling routine from our SGRLD code to implement HSVG.

(cid:81)
d q(ηd)(cid:81)
(cid:81)
d q(zd)(cid:81)

5.1 Evaluation Method

The predictive performance of the algorithms can be measured by looking at the probability they
assign to unseen data. A metric frequently used for this purpose is perplexity  the exponentiated
cross entropy between the trained model probability distribution and the empirical distribution of
the test data. For a held-out document wd and a training set W  the perplexity is given by

(cid:26)

(cid:80)nd··
i=1 log p(wdi | W  α  β)

(cid:27)

perp(wd | W  α  β) = exp

−

.

(12)

nd··

6

This requires calculating p(wdi
ηd  π1  . . .   πK and topic assignments zd  to give

| W  α  β)  which is done by marginalising out the parameters

p(wdi | W  α  β) = Eηd π

ηdkπkwdi

(13)

(cid:35)

(cid:34)(cid:88)

k

We use a document completion approach [WMSM09]  partitioning the test document wd into two
sets of words  wtrain
to estimate ηd for the test document  then calculating the
d
perplexity on wtest
To calculate the perplexity for SGRLD  we integrate η analytically  so Equation 13 is replaced by

d using this estimate.

and using wtrain

  wtest

d

d

(cid:34)

(cid:34)(cid:88)

(cid:35)(cid:35)

p(wdi | wtrain

d

 W  α  β) = Eπ|W β

E
ztrain
d

|π α

ˆηdkπkwdi

where

ˆηdk := p(ztest

di = k | ztrain

d

k

  α) =

ntrain
dk· + α
ntrain
d·· + Kα

.

(14)

(15)

(cid:34)(cid:88)

(cid:35)

≈(cid:88)

We estimate these expectations using the samples we obtain for π from the Markov chain produced
by SGRLD  and samples for ztrain
For OVB and HSVG  we estimate Equation 13 by replacing the true posterior p(η  β) with q(η  β).

produced by Gibbs sampling the topic assignments on wtrain

.

d

d

p(wdi | W  α  β) = Ep(ηd π|W α β)

ηdkπkwdi

Eq(ηd) [ηdk] Eq(πk) [πkwdi ]

(16)

We estimate the perplexity directly rather than use a variational bound [HBB10] so that we can
compare results of the variational algorithms to those of SGRLD.

k

k

5.2 Results on NIPS corpus

The ﬁrst experiment was carried out on the collection of NIPS papers from 1988-2003 [GCPT07].
This corpus contains 2483 documents  which is small enough to run all three algorithms in batch
mode and compare their performance to that of collapsed Gibbs sampling on the full collection.
Each document was split 80/20 into training and test sets  the training portion of all 2483 documents
were used in each update step  and the perplexity was calculated on the test portion of all docu-
ments. Hyper-parameters α and β were both ﬁxed to 0.01  and 50 topics were used. A step-size
schedule of the form t = (a ∗ (1 + t
b ))−c was used. Perplexities were estimated for a range of step
size parameters  and for 1  5 and 10 document updates per topic parameter update. For OVB the
document updates are ﬁxed point iterations of q(zd) while for HSVG and SGRLD they are Gibbs
updates of zd  the ﬁrst half of which were discarded as burn-in. These numbers of document updates
were chosen as previous investigation of the performance of HSVG for varying numbers of Gibbs
updates has shown that 6-10 updates are sufﬁcient [MHB12] to achieve good performance.
Figure 2(a) shows the lowest perplexities achieved along with the corresponding parameter settings.
As expected  CGS achieves the lowest perplexities. It is surprising that HSVG performs slightly
worse than OVB on this data set. As it uses a less restricted variational distribution it should perform
at least as well. SGRLD improves on the performance of OVB and HSVG  but does not match the
performance of Gibbs sampling.

5.3 Results on Wikipedia corpus

The algorithms’ performances in an online scenario was assessed on a set of articles downloaded
at random from Wikipedia  as in [HBB10]. The vocabulary used is again as per [HBB10]; it is
not created from the Wikipedia data set  instead it is taken from the top 10 000 words in Project
Gutenburg texts  excluding all words of less than three characters. This results in vocabulary size
W of approximately 8000 words. 150 000 documents from Wikipedia were used in total  in mini-
batches of 50 documents each. The perplexities were estimated using the methods discussed in

7

(a) NIPS corpus

(b) Wikipedia corpus

Figure 2: Test-set perplexities on NIPS and Wikipedia corpora.

Section 5.1 on a separate holdout set of 1000 documents  split 90/10 training/test. As the corpus size
is large  collapsed Gibbs sampling was not run on this data set.
For each algorithm a grid-search was run on the hyper-parameters  step-size parameters  and num-
ber of Gibbs sampling sweeps / variational ﬁxed point iterations per π update. The lowest three
perplexities attained for each algorithm are shown in Figure 2(b). Corresponding parameters are
given in the supplementary material. HSVG achieves better performance than OVB  as expected.
The performance of SGRLD is a substantial improvement on both the variational algorithms.

6 Discussion

We have explored the issues involved in applying Langevin Monte Carlo techniques to a constrained
parameter space such as the probability simplex  and developed a novel online sampling algorithm
which addresses those issues. Using an expanded parametrisation with a reﬂection trick for negative
proposals removed the need to deal with boundary constraints  and using the Riemannian geometry
of the parameter space dealt with the problem of parameters with differing scales.
Applying the method to Latent Dirichlet Allocation on two data sets produced state of the art pre-
dictive performance for the same computational budget as competing methods  demonstrating that
full Bayesian inference using MCMC can be practically applied to models of interest  even when
the data set is large. Python code for our method is available at http://www.stats.ox.ac.
uk/˜teh/sgrld.html.
Due to the widespread use of models deﬁned on the probability simplex  we believe the methods
developed here for Langevin dynamics on the probability simplex will ﬁnd further uses beyond latent
Dirichlet allocation and stochastic gradient Monte Carlo methods. A drawback of SGLD algorithms
is the need for decreasing step sizes; it would be interesting to investigate adaptive step sizes and the
approximation entailed when using ﬁxed step sizes (but see [AKW12] for a recent development).

Acknowledgements

We thank the Gatsby Charitable Foundation and EPSRC (grant EP/K009362/1) for generous fund-
ing  reviewers and area chair for feedback and support  and [HBB10] for use of their excellent
publicly available source code.

8

0200400600800100014001600180020002200  HSVGOVBSGRLDCollapsed Gibbs0500001000001500001000120014001600180020002200  HSVGOVBSGRLDReferences
[ABW12]

[AKW12]

[Ama95]

Sungjin Ahn  Anoop Korattikara Balan  and Max Welling  Bayesian posterior sampling via
stochastic gradient ﬁsher scoring.  ICML  2012.
S. Ahn  A. Korattikara  and M. Welling  Bayesian posterior sampling via stochastic gradient
Fisher scoring  Proceedings of the International Conference on Machine Learning  2012.
S. Amari  Information geometry of the EM and em algorithms for neural networks  Neural Net-
works 8 (1995)  no. 9  1379–1408.

[AWST09] A. Asuncion  M. Welling  P. Smyth  and Y. W. Teh  On smoothing and inference for topic models 
Proceedings of the International Conference on Uncertainty in Artiﬁcial Intelligence  vol. 25 
2009.
M. J. Beal  Variational algorithms for approximate bayesian inference  Ph.D. thesis  Gatsby Com-
putational Neuroscience Unit  University College London  2003.
D. M. Blei  A. Y. Ng  and M. I. Jordan  Latent Dirichlet allocation  Journal of Machine Learning
Research 3 (2003)  993–1022.
M. Girolami and B. Calderhead  Riemann manifold Langevin and Hamiltonian Monte Carlo
methods  Journal of the Royal Statistical Society B 73 (2011)  1–37.

[BNJ03]

[Bea03]

[GC11]

[GCPT07] A. Globerson  G. Chechik  F. Pereira  and N. Tishby  Euclidean Embedding of Co-occurrence

Data  The Journal of Machine Learning Research 8 (2007)  2265–2295.
W. R. Gilks  S. Richardson  and D. J. Spiegelhalter  Markov chain monte carlo in practice  Chap-
man and Hall  1996.
T. L. Grifﬁths and M. Steyvers  Finding scientiﬁc topics  Proceedings of the National Academy
of Sciences  2004.

[HBB10] M. D. Hoffman  D. M. Blei  and F. Bach  Online learning for latent dirichlet allocation  Advances

[GRS96]

[GS04]

[Hec99]

[Ken78]
[Ken90]

[MHB12]

[Nea10]

[PSD00]

[RM51]

[RS02]

[Sat01]

[TNW07]

[WJ08]

[NASW09] D. Newman  A. Asuncion  P. Smyth  and M. Welling  Distributed algorithms for topic models 

in Neural Information Processing Systems  2010.
D. Heckerman  A tutorial on learning with Bayesian networks  Learning in Graphical Models
(M. I. Jordan  ed.)  Kluwer Academic Publishers  1999.
J. Kent  Time-reversible diffusions  Advances in Applied Probability 10 (1978)  819–835.
A. D. Kennedy  The theory of hybrid stochastic algorithms  Probabilistic Methods in Quantum
Field Theory and Quantum Gravity  Plenum Press  1990.
D. Mimno  M. Hoffman  and D. Blei  Sparse stochastic inference for latent Dirichlet allocation 
Proceedings of the International Conference on Machine Learning  2012.

Journal of Machine Learning Research (2009).
R. M. Neal  MCMC using Hamiltonian dynamics  Handbook of Markov Chain Monte Carlo
(S. Brooks  A. Gelman  G. Jones  and X.-L. Meng  eds.)  Chapman & Hall / CRC Press  2010.
J.K. Pritchard  M. Stephens  and P. Donnelly  Inference of population structure using multilocus
genotype data  Genetics 155 (2000)  945–959.
H. Robbins and S. Monro  A stochastic approximation method  Annals of Mathematical Statistics
22 (1951)  no. 3  400–407.
G. O. Roberts and O. Stramer  Langevin diffusions and metropolis-hastings algorithms  Method-
ology and Computing in Applied Probability 4 (2002)  337–357  10.1023/A:1023562417138.
M. Sato  Online model selection based on the variational Bayes  Neural Computation 13 (2001) 
1649–1681.
Y. W. Teh  D. Newman  and M. Welling  A collapsed variational Bayesian inference algorithm for
latent Dirichlet allocation  Advances in Neural Information Processing Systems  vol. 19  2007 
pp. 1353–1360.
M. J. Wainwright and M. I. Jordan  Graphical models  exponential families  and variational in-
ference  Foundations and Trends in Machine Learning 1 (2008)  no. 1-2  1–305.

[WMSM09] Hanna M. Wallach  Iain Murray  Ruslan Salakhutdinov  and David Mimno  Evaluation methods
for topic models  Proceedings of the 26th International Conference on Machine Learning (ICML)
(Montreal) (L´eon Bottou and Michael Littman  eds.)  Omnipress  June 2009  pp. 1105–1112.
M. Welling and Y. W. Teh  Bayesian learning via stochastic gradient Langevin dynamics  Pro-
ceedings of the International Conference on Machine Learning  2011.

[WT11]

9

,Sam Patterson
Yee Whye Teh
Koosha Khalvati
Rajesh Rao