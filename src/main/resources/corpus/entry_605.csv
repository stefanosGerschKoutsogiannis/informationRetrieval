2018,Assessing Generative Models via Precision and Recall,Recent advances in generative modeling have led to an increased interest in the study of statistical divergences as means of model comparison. Commonly used evaluation methods  such as the Frechet Inception Distance (FID)  correlate well with the perceived quality of samples and are sensitive to mode dropping. However  these metrics are unable to distinguish between different failure cases since they only yield one-dimensional scores. We propose a novel definition of precision and recall for distributions which disentangles the divergence into two separate dimensions. The proposed notion is intuitive  retains desirable properties  and naturally leads to an efficient algorithm that can be used to evaluate generative models. We relate this notion to total variation as well as to recent evaluation metrics such as Inception Score and FID. To demonstrate the practical utility of the proposed approach we perform an empirical study on several variants of Generative Adversarial Networks and Variational Autoencoders. In an extensive set of experiments we show that the proposed metric is able to disentangle the quality of generated samples from the coverage of the target distribution.,AssessingGenerativeModelsviaPrecisionandRecallMehdiS.M.Sajjadi∗MPIforIntelligentSystems MaxPlanckETHCenterforLearningSystemsOlivierBachemGoogleBrainMarioLucicGoogleBrainOlivierBousquetGoogleBrainSylvainGellyGoogleBrainAbstractRecentadvancesingenerativemodelinghaveledtoanincreasedinterestinthestudyofstatisticaldivergencesasmeansofmodelcomparison.Commonlyusedevaluationmethods suchastheFréchetInceptionDistance(FID) correlatewellwiththeperceivedqualityofsamplesandaresensitivetomodedropping.However thesemetricsareunabletodistinguishbetweendifferentfailurecasessincetheyonlyyieldone-dimensionalscores.Weproposeanoveldeﬁnitionofprecisionandrecallfordistributionswhichdisentanglesthedivergenceintotwoseparatedimensions.Theproposednotionisintuitive retainsdesirableproperties andnaturallyleadstoanefﬁcientalgorithmthatcanbeusedtoevaluategenerativemodels.WerelatethisnotiontototalvariationaswellastorecentevaluationmetricssuchasInceptionScoreandFID.TodemonstratethepracticalutilityoftheproposedapproachweperformanempiricalstudyonseveralvariantsofGenerativeAdversarialNetworksandVariationalAutoencoders.Inanextensivesetofexperimentsweshowthattheproposedmetricisabletodisentanglethequalityofgeneratedsamplesfromthecoverageofthetargetdistribution.1IntroductionDeepgenerativemodels suchasVariationalAutoencoders(VAE)[12]andGenerativeAdversarialNetworks(GAN)[8] havereceivedagreatdealofattentionduetotheirabilitytolearncomplex high-dimensionaldistributions.Oneofthebiggestimpedimentstofutureresearchisthelackofquantitativeevaluationmethodstoaccuratelyassessthequalityoftrainedmodels.Withoutaproperevaluationmetricresearchersoftenneedtovisuallyinspectgeneratedsamplesorresorttoqualitativetechniqueswhichcanbesubjective.Oneofthemaindifﬁcultiesforquantitativeassessmentliesinthefactthatthedistributionisonlyspeciﬁedimplicitly–onecanlearntosamplefromapredeﬁneddistribution butcannotevaluatethelikelihoodefﬁciently.Infact eveniflikelihoodcomputationwerecomputationallytractable itmightbeinadequateandmisleadingforhigh-dimensionalproblems[22].Asaresult surrogatemetricsareoftenusedtoassessthequalityofthetrainedmodels.Someproposedmeasures suchasInceptionScore(IS)[20]andFréchetInceptionDistance(FID)[9] haveshownpromisingresultsinpractice.Inparticular FIDhasbeenshowntoberobusttoimagecorruption itcorrelateswellwiththevisualﬁdelityofthesamples anditcanbecomputedonunlabeleddata.However allofthemetricscommonlyappliedtoevaluatinggenerativemodelsshareacrucialweakness:Sincetheyyieldaone-dimensionalscore theyareunabletodistinguishbetweendifferentfailurecases.Forexample thegenerativemodelsshowninFigure1obtainsimilarFIDsbutexhibit∗ThisworkwasdoneduringaninternshipatGoogleBrain.Correspondence:msajjadi.com bachem@google.com lucic@google.com.32ndConferenceonNeuralInformationProcessingSystems(NeurIPS2018) Montréal Canada.0.00.20.40.60.81.0Recall0.00.20.40.60.81.0PrecisionMNISTleftMNISTrightCelebAleftCelebArightFigure1:ComparisonofGANstrainedonMNISTandCelebA.AlthoughthemodelsobtainasimilarFIDoneachdataset(32/29forMNISTand65/62forCelebA) theirsampleslookverydifferent.Forexample themodelontheleftproducesreasonablylookingfacesonCelebA buttoomanydarkimages.Incontrast themodelontherightproducesmoreartifacts butmorevariedimages.Bytheproposedmetric(middle) themodelsontheleftachievehigherprecisionandlowerrecallthanthemodelsontheright whichsufﬁcestosuccessfullydistinguishingbetweenthefailurecases.differentsamplecharacteristics:themodelonthelefttrainedonMNIST[15]producesrealisticsamples butonlygeneratesasubsetofthedigits.Ontheotherhand themodelontherightproduceslow-qualitysampleswhichappeartocoveralldigits.AsimilareffectcanbeobservedontheCelebA[16]dataset.Inthisworkwearguethatasingle-valuesummaryisnotadequatetocomparegenerativemodels.Motivatedbythisshortcoming wepresentanovelapproachwhichdisentanglesthedivergencebetweendistributionsintotwocomponents:precisionandrecall.GivenareferencedistributionPandalearneddistributionQ precisionintuitivelymeasuresthequalityofsamplesfromQ whilerecallmeasurestheproportionofPthatiscoveredbyQ.Furthermore weproposeanelegantalgorithmwhichcancomputethesequantitiesbasedonsamplesfromPandQ.Inparticular usingthisapproachweareabletoquantifythedegreeofmodedroppingandmodeinventingbasedonsamplesfromthetrueandthelearneddistributions.Ourcontributions:(1)Weintroduceanoveldeﬁnitionofprecisionandrecallfordistributionsandprovethatthenotionistheoreticallysoundandhasdesirableproperties (2)weproposeanefﬁcientalgorithmtocomputethesequantities (3)werelatethesenotionstototalvariation ISandFID (4)wedemonstratethatinpracticeonecanquantifythedegreeofmodedroppingandmodeinventingonrealworlddatasets(imageandtextdata) and(5)wecompareseveraltypesofgenerativemodelsbasedontheproposedapproach–toourknowledge thisistheﬁrstmetricthatexperimentallyconﬁrmsthefolklorethatGANsoftenproduce"sharper"images butcansufferfrommodecollapse(highprecision lowrecall) whileVAEsproduce"blurry"images butcovermoremodesofthedistribution(lowprecision highrecall).2BackgroundandRelatedWorkThetaskofevaluatinggenerativemodelsisanactiveresearcharea.Herewefocusonrecentworkinthecontextofdeepgenerativemodelsforimageandtextdata.Classicapproachesrelyingoncomparinglog-likelihoodhavereceivedsomecriticismduethefactthatonecanachievehighlikelihood butlowimagequality andconversely high-qualityimagesbutlowlikelihood[22].Whilethelikelihoodcanbeapproximatedinsomesettings kerneldensityestimationinhigh-dimensionalspacesisextremelychallenging[22 24].Otherfailuremodesrelatedtodensityestimationinhigh-dimensionalspaceshavebeenelaboratedin[10 22].Arecentreviewofpopularapproachesispresentedin[5].TheInceptionScore(IS)[20]offersawaytoquantitativelyevaluatethequalityofgeneratedsamplesinthecontextofimagedata.Intuitively theconditionallabeldistributionp(y|x)ofsamplescontainingmeaningfulobjectsshouldhavelowentropy whilethelabeldistributionoverthewholedatasetp(y)shouldhavehighentropy.Formally IS(G)=exp(Ex∼G[dKL(p(y|x) p(y)]).Thescoreiscomputedbasedonaclassiﬁer(InceptionnetworktrainedonImageNet).ISnecessitatesalabeleddatasetandhasbeenfoundtobeweakatprovidingguidanceformodelcomparison[3].2P(a)Q(b)(c)(d)(e)(f)Figure2:IntuitiveexamplesofPandQ.01(a)01αβ01(b)β01(c)β01(d)β01(e)β01(f)βFigure3:PRD(Q P)fortheexamplesabove.0.00.51.0Recallβ0.00.51.0Precisionαλ=2λ=1λ=0.5Figure4:Illustrationofthealgorithm.TheFID[9]providesanalternativeapproachwhichrequiresnolabeleddata.Thesamplesareﬁrstembeddedinsomefeaturespace(e.g. aspeciﬁclayerofInceptionnetworkforimages).Then acontinuousmultivariateGaussianisﬁttothedataandthedistancecomputedasFID(x g)=||µx−µg||22+Tr(Σx+Σg−2(ΣxΣg)12) whereµandΣdenotethemeanandcovarianceofthecorrespondingsamples.FIDissensitivetoboththeadditionofspuriousmodesaswellastomodedropping(seeFigure5andresultsin[18]).[4]recentlyintroducedanunbiasedalternativetoFID theKernelInceptionDistance.Whileunbiased itsharesanextremelyhighSpearmanrank-ordercorrelationwithFID[14].Anotherapproachistotrainaclassiﬁerbetweentherealandfakedistributionsandtouseitsaccuracyonatestsetasaproxyforthequalityofthesamples[11 17].Thisapproachnecessitatestrainingofaclassiﬁerforeachmodelwhichisseldompractical.Furthermore theclassiﬁermightdetectasingledimensionwherethetrueandgeneratedsamplesdiffer(e.g. barelyvisibleartifactsingeneratedimages)andenjoyhighaccuracy whichrunstheriskofassigninglowerqualitytoabettermodel.Tothebestofourknowledge allcommonlyusedmetricsforevaluatinggenerativemodelsareone-dimensionalinthattheyonlyyieldasinglescoreordistance.Anotionofprecisionandrecallhaspreviouslybeenintroducedin[18]wheretheauthorscomputethedistancetothemanifoldofthetruedataanduseitasaproxyforprecisionandrecallonasyntheticdataset.Unfortunately itisnotpossibletocomputethisquantityformorecomplexdatasets.3PRD:PrecisionandRecallforDistributionsInthissection wederiveanovelnotionofprecisionandrecalltocompareadistributionQtoareferencedistributionP.ThekeyintuitionisthatprecisionshouldmeasurehowmuchofQcanbegeneratedbya“part”ofPwhilerecallshouldmeasurehowmuchofPcanbegeneratedbya“part”ofQ.Figure2(a)-(d)showfourtoyexamplesforPandQtovisualizethisidea:(a)IfPisbimodalandQonlycapturesoneofthemodes weshouldhaveperfectprecisionbutonlylimitedrecall.(b)Intheoppositecase weshouldhaveperfectrecallbutonlylimitedprecision.(c)IfQ=P weshouldhaveperfectprecisionandrecall.(d)IfthesupportsofPandQaredisjoint weshouldhavezeroprecisionandrecall.3.1DerivationLetS=supp(P)∩supp(Q)bethe(non-empty)intersectionofthesupports2ofPandQ.Then Pmaybeviewedasatwo-componentmixturewheretheﬁrstcomponentPSisaprobabilitydistributiononSandthesecondcomponentPSisdeﬁnedonthecomplementofS.Similarly QmayberewrittenasamixtureofQSandQS.Moreformally forsome¯α ¯β∈(0 1] wedeﬁneP=¯βPS+(1−¯β)PSandQ=¯αQS+(1−¯α)QS.(1)Thisdecompositionallowsforanaturalinterpretation:PSisthepartofPthatcannotbegeneratedbyQ soitsmixtureweight1−¯βmaybeviewedasalossinrecall.Similarly QSisthepartofQthatcannotbegeneratedbyP so1−¯αmayberegardedasalossinprecision.Inthecasewhere2ForadistributionPdeﬁnedonaﬁnitestatespaceΩ wedeﬁnesupp(P)={ω∈Ω|P(ω)>0}.3PS=QS i.e. thedistributionsPandQagreeonSuptoscaling ¯αand¯βprovideuswithasimpletwo-numberprecisionandrecallsummarysatisfyingtheexamplesinFigure2(a)-(d).IfPS6=QS wearefacedwithaconundrum:ShouldthedifferencesinPSandQSbeattributedtolossesinprecisionorrecall?IsQSinadequately“covering”PSorisitgenerating“unnecessary”noise?InspiredbyPRcurvesforbinaryclassiﬁcation weproposetoresolvethispredicamentbyprovidingatrade-offbetweenprecisionandrecallinsteadofatwo-numbersummaryforanytwodistributionsPandQ.Toparametrizethistrade-off weconsideradistributionµonSthatsigniﬁesa“true”commoncomponentofPSandQSandsimilarlyto(1) wedecomposebothPSandQSasPS=β0µ+(1−β0)PµandQS=α0µ+(1−α0)Qµ.(2)ThedistributionPSisviewedasatwo-componentmixturewheretheﬁrstcomponentisµandthesecondcomponentPµsigniﬁesthepartofPSthatis“missed”byQSandshouldthusbeconsideredarecallloss.Similarly QSisdecomposedintoµandthepartQµthatsigniﬁesnoiseandshouldthusbeconsideredaprecisionloss.Asµisvaried thisleadstoatrade-offbetweenprecisionandrecall.ItshouldbenotedthatunlikePRcurvesforbinaryclassiﬁcationwheredifferentthresholdsleadtodifferentclassiﬁers trade-offsbetweenprecisionandrecallheredonotconstitutedifferentmodelsordistributions–theproposedPRDcurvesonlyserveasadescriptionofthecharacteristicsofthemodelwithrespecttothetargetdistribution.3.2FormaldeﬁnitionForsimplicity weconsiderdistributionsPandQthataredeﬁnedonaﬁnitestatespace thoughthenotionofprecisionandrecallcanbeextendedtoarbitrarydistributions.Bycombining(1)and(2) weobtainthefollowingformaldeﬁnitionofprecisionandrecall.Deﬁnition1.Forα β∈(0 1] theprobabilitydistributionQhasprecisionαatrecallβw.r.t.Pifthereexistdistributionsµ νPandνQsuchthatP=βµ+(1−β)νPandQ=αµ+(1−α)νQ.(3)ThecomponentνPdenotesthepartofPthatis“missed”byQandencompassesbothPSin(1)andPµin(2).Similarly νQdenotesthenoisepartofQandincludesbothQSin(1)andQµin(2).Deﬁnition2.ThesetofattainablepairsofprecisionandrecallofadistributionQw.r.t.adistributionPisdenotedbyPRD(Q P)anditconsistsofall(α β)satisfyingDeﬁnition1andthepair(0 0).ThesetPRD(Q P)characterizestheabove-mentionedtrade-offbetweenprecisionandrecallandcanbevisualizedsimilarlytoPRcurvesinbinaryclassiﬁcation:Figure3(a)-(d)showthesetPRD(Q P)ona2D-plotfortheexamples(a)-(d)inFigure2.Notehowtheplotdistinguishesbetween(a)and(b):Anysymmetricevaluationmethod(suchasFID)assignsthesecasesthesamescorealthoughtheyarehighlydifferent.TheinterpretationofthesetPRD(Q P)isfurtheraidedbythefollowingsetofbasicpropertieswhichweproveinSectionA.1intheappendix.Theorem1.LetPandQbeprobabilitydistributionsdeﬁnedonaﬁnitestatespaceΩ.ThesetPRD(Q P)satisﬁesthefollowingproperties:(i)(1 1)∈PRD(Q P)⇔Q=P(equality)(ii)PRD(Q P)={(0 0)}⇔supp(Q)∩supp(P)=∅(disjointsupports)(iii)Q(supp(P))=¯α=max(α β)∈PRD(Q P)α(maxprecision)(iv)P(supp(Q))=¯β=max(α β)∈PRD(Q P)β(maxrecall)(v)(α0 β0)∈PRD(Q P)ifα0∈(0 α] β0∈(0 β] (α β)∈PRD(Q P)(monotonicity)(vi)(α β)∈PRD(Q P)⇔(β α)∈PRD(P Q)(duality)Property(i)incombinationwithProperty(v)guaranteesthatQ=PifthesetPRD(Q P)containstheinterioroftheunitsquare seecase(c)inFigures2and3.Similarly Property(ii)assuresthatwheneverthereisnooverlapbetweenPandQ PRD(Q P)onlycontainstheorigin seecase(d)ofFigures2and3.Properties(iii)and(iv)provideaconnectiontothedecompositionin(1)andallowananalysisofthecases(a)and(b)inFigures2and3:Asexpected Qin(a)achievesamaximumprecisionof1butonlyamaximumrecallof0.5whilein(b) maximumrecallis1butmaximum4precisionis0.5.Notethatthequantities¯αand¯βherearebyconstructionthesameasin(1).Finally Property(vi)providesanaturalinterpretationofprecisionandrecall:TheprecisionofQw.r.t.PisequaltotherecallofPw.r.t.Qandviceversa.Clearly notallcasesareassimpleastheexamples(a)-(d)inFigures2and3 inparticularifPandQaredifferentontheintersectionSoftheirsupport.Theexamples(e)and(f)inFigure2andtheresultingsetsPRD(Q P)inFigure3illustratetheimportanceofthetrade-offbetweenprecisionandrecallaswellastheutilityofthesetPRD(Q P).Inbothcases PandQhavethesamesupportwhileQhashighprecisionandlowrecallincase(e)andlowprecisionandhighrecallincase(f).ThisisclearlycapturedbythesetsPRD(Q P).Intuitively theexamples(e)and(f)maybeviewedasnoisyversionsofthecases(a)and(b)inFigure2.3.3AlgorithmComputingthesetPRD(Q P)basedonDeﬁnitions1and2isnon-trivialasonehastocheckwhetherthereexistsuitabledistributionsµ νPandνQforallpossiblevaluesofαandβ.WeintroduceanequivalentdeﬁnitionofPRD(Q P)inTheorem2thatdoesnotdependonthedistributionsµ νPandνQandthatleadstoanelegantalgorithmtocomputepracticalPRDcurves.Theorem2.LetPandQbetwoprobabilitydistributionsdeﬁnedonaﬁnitestatespaceΩ.Forλ>0deﬁnethefunctionsα(λ)=Xω∈Ωmin(λP(ω) Q(ω))andβ(λ)=Xω∈Ωmin(cid:18)P(ω) Q(ω)λ(cid:19).(4)Then itholdsthatPRD(Q P)={(θα(λ) θβ(λ))|λ∈(0 ∞) θ∈[0 1]}.WeprovethetheoreminSectionA.2intheappendix.ThekeyideaofTheorem2isillustratedinFigure4:ThesetofPRD(Q P)maybeviewedasaunionofsegmentsofthelinesα=λβoverallλ∈(0 ∞).Eachsegmentstartsattheorigin(0 0)andendsatthemaximalachievablevalue(α(λ) β(λ)).ThisprovidesasurprisinglysimplealgorithmtocomputePRD(Q P)inpractice:Simplycomputepairsofα(λ)andβ(λ)asdeﬁnedin(4)foranequiangulargridofvaluesofλ.Foragivenangularresolutionm∈N wecompute[PRD(Q P)={(α(λ) β(λ))|λ∈Λ}whereΛ=ntan(cid:16)im+1π2(cid:17)|i=1 2 ... mo.TocomparedifferentdistributionsQi onemaysimplyplottheirrespectivePRDcurves[PRD(Qi P) whileanapproximationofthefullsetsPRD(Qi P)maybecomputedbyinter-polationbetween[PRD(Qi P)andtheorigin.Animplementationofthealgorithmisavailableathttps://github.com/msmsajjadi/precision-recall-distributions.3.4ConnectiontototalvariationdistanceTheorem2providesanaturalinterpretationoftheproposedapproach.Forλ=1 wehaveα(1)=β(1)=Xω∈Ωmin(P(ω) Q(ω))=Xω∈ΩhP(ω)−(P(ω)−Q(ω))+i=1−δ(P Q)whereδ(P Q)denotesthetotalvariationdistancebetweenPandQ.Assuch ournotionofprecisionandrecallmaybeviewedasageneralizationoftotalvariationdistance.4ApplicationtoDeepGenerativeModelsInthissection weshowthatthealgorithmintroducedinSection3.3canbereadilyappliedtoevaluateprecisionandrecallofdeepgenerativemodels.Inpractice accesstoPandQisgivenviasamplesˆP∼PandˆQ∼Q.GiventhatbothPandQarecontinuousdistributions theprobabilityofgeneratingapointsampledfromQis0.Furthermore thereisstrongempiricalevidencethatcomparingsamplesinimagespacerunstheriskofassigninghigherqualitytoaworsemodel[17 20 22].Acommonremedyistoapplyapre-trainedclassiﬁertrainedonnaturalimagesandtocompareˆPandˆQatafeaturelevel.Intuitively inthisfeaturespacethesamplesshouldbe512345678910NumberofclassesinQ4567891011InceptionscoreInceptionscoreFID020406080100FID0.00.20.40.60.81.0Recall0.00.20.40.60.81.0PrecisionQ123456789100.00.20.40.60.81.0Recall0.00.20.40.60.81.0PrecisionQ12345Figure5:Left:ISandFIDasweremoveandaddclassesofCIFAR-10.ISgenerallyonlyincreases whileFIDissensitivetoboththeadditionandremovalofclasses.However itcannotdistinguishbetweenthetwofailurecasesofinventingordroppingmodes.Middle:ResultingPRDcurvesforthesameexperiment.Asexpected addingmodesleadstoalossinprecision(Q6–Q10) whiledroppingmodesleadstoalossinrecall(Q1–Q4).AsanexampleconsiderQ4andQ6whichhavesimilarFID butstrikinglydifferentPRDcurves.Thesamebehaviorcanbeobservedforthetaskoftextgeneration asdisplayedontheplotontheright.Forthisexperiment wesetPtocontainsamplesfromallclassessothePRDcurvesdemonstratetheincreaseinrecallasweincreasethenumberofclassesinQ.comparedbasedonstatisticalregularitiesintheimagesratherthanrandomartifactsresultingfromthegenerativeprocess[17 19].Followingthislineofwork weﬁrstuseapre-trainedInceptionnetworktoembedthesamples(i.e.usingthePool3layer[9]).WethenclustertheunionofˆPandˆQinthisfeaturespaceusingmini-batchk-meanswithk=20[21].Intuitively wereducetheproblemtoaonedimensionalproblemwherethehistogramovertheclusterassignmentscanbemeaningfullycompared.Hence failingtoproducesamplesfromaclusterwithmanysamplesfromthetruedistributionwillhurtrecall andproducingsamplesinclusterswithoutmanyrealsampleswillhurtprecision.Astheclusteringalgorithmisrandomized weruntheprocedureseveraltimesandaverageoverthePRDcurves.WenotethatsuchaclusteringismeaningfulasshowninFigure9intheappendixandthatitcanbeefﬁcientlyscaledtoverylargesamplesizes[1 2].Westressthatfromthepointofviewoftheproposedalgorithm onlyameaningfulembeddingisrequired.Assuch thealgorithmcanbeappliedtovariousdatamodalities.Inparticular weshowinSection4.1thatbesidesimagedatathealgorithmcanbeappliedtoatextgenerationtask.4.1AddinganddroppingmodesfromthetargetdistributionModecollapseormodedroppingisamajorchallengeinGANs[8 20].Duetothesymmetryofcommonlyusedmetricswithrespecttoprecisionandrecall theonlywaytoassesswhetherthemodelisproducinglow-qualityimagesordroppingmodesisbyvisualinspection.Instarkcontrast theproposedmetriccanquantitativelydisentangletheseeffectswhichweempiricallydemonstrate.WeconsiderthreedatasetscommonlyusedintheGANliterature:MNIST[15] Fashion-MNIST[25] andCIFAR-10[13].Thesedatasetsarelabeledandconsistof10balancedclasses.Toshowthesensitivityoftheproposedmeasuretomodedroppingandmodeinventing weﬁrstﬁxˆPtocontainsamplesfromtheﬁrst5classesintherespectivetestset.Then foraﬁxedi=1 ... 10 wegenerateasetˆQi whichconsistsofsamplesfromtheﬁrsticlassesfromthetrainingset.Asiincreases ˆQicoversanincreasingnumberofclassesfromˆPwhichshouldresultinhigherrecall.Asweincreaseibeyond5 ˆQiincludessamplesfromanincreasingnumberofclassesthatarenotpresentinˆPwhichshouldresultinalossinprecision butnotinrecallastheotherclassesarealreadycovered.Finally thesetˆQ5coversthesameclassesasˆP soitshouldhavehighprecisionandhighrecall.Figure5(left)showstheISandFIDfortheCIFAR-10dataset(resultsontheotherdatasetsareshowninFigure11intheappendix).SincetheISisnotcomputedw.r.t.areferencedistribution itisinvarianttothechoiceofˆP soasweaddclassestoˆQi theISincreases.TheFIDdecreasesasweaddmoreclassesuntilˆQ5beforeitstartstoincreaseasweaddspuriousmodes.Critically FIDfailstodistinguishthecasesofmodedroppingandmodeinventing:ˆQ4andˆQ6sharesimilarFIDs.Incontrast Figure5(middle)showsourPRDcurvesaswevarythenumberofclassesinˆQi.Addingcorrectmodesleadstoanincreaseinrecall whileaddingfakemodesleadstoalossofprecision.60123456789Classlabel01k2k3k4k5k0.00.20.40.60.81.0Recall0.00.20.40.60.81.0Precisionleftright0123456789Classlabel01k2k3k4k5kFigure6:ComparingtwoGANstrainedonMNISTwhichbothachieveanFIDof49.Themodelontheleftseemstoproducehigh-qualitysamplesofonlyasubsetofdigits.Ontheotherhand themodelontherightgenerateslow-qualitysamplesofalldigits.ThehistogramsshowingthecorrespondingclassdistributionsbasedonatrainedMNISTclassiﬁerconﬁrmthisobservation.Atthesametime theclassiﬁerismoreconﬁdentwhichindicatesdifferentlevelsofprecision(96.7%forthemodelontheleftcomparedto88.6%forthemodelontheright).Finally wenotethattheproposedPRDalgorithmdoesnotrequirelabeleddata asopposedtotheISwhichfurtherneedsaclassiﬁerthatwastrainedontherespectivedataset.WealsoapplytheproposedapproachontextdataasshowninFigure5(right).Inparticular weusetheMultiNLIcorpusofcrowd-sourcedsentencepairsannotatedwithtopicandtextualentailmentinformation[23].Afterdiscardingtheentailmentlabel wecollectalluniquesentencesforthesametopic.Following[6] weembedthesesentencesusingaBiLSTMwith2048cellsineachdirectionandmaxpooling leadingtoa4096-dimensionalembedding[7].Weconsider5classesfromthisdatasetandﬁxˆPtocontainsamplesfromallclassestomeasurethelossinrecallfordifferentQi.Figure5(right)curvessuccessfullydemonstratethesensitivityofrecalltomodedropping.4.2AssessingclassimbalancesforGANsInthissectionweanalyzetheeffectofclassimbalanceonthePRDcurves.Figure6showsapairofGANstrainedonMNISTwhichhavevirtuallythesameFID butverydifferentPRDcurves.Themodelontheleftgeneratesasubsetofthedigitsofhighquality whilethemodelontherightseemstogeneratealldigits buteachhaslowquality.WecannaturallyinterpretthisdifferenceviathePRDcurves:Foradesiredrecallleveloflessthan∼0.6 themodelontheleftenjoyshigherprecision–itgeneratesseveraldigitsofhighquality.If however onedesiresarecallhigherthan∼0.6 themodelontherightenjoyshigherprecisionasitcoversalldigits.Toconﬁrmthis wetrainanMNISTclassiﬁerontheembeddingofˆPwiththegroundtruthlabelsandplotthedistributionofthepredictedclassesforbothmodels.Thehistogramsclearlyshowthatthemodelontheleftfailedtogenerateallclasses(lossinrecall) whilethemodelontherightisproducingamorebalanceddistributionoverallclasses(highrecall).Atthesametime theclassiﬁerhasanaverageconﬁdence3of96.7%onthemodelontheleftcomparedto88.6%onthemodelontheright indicatingthatthesamplequalityoftheformerishigher.ThisalignsverywellwiththePRDplots:samplesonthelefthavehighqualitybutarenotdiverseincontrasttothesamplesontherightwhicharediversebuthavelowquality.ThisanalysisrevealsaconnectiontoISwhichisbasedonthepremisethattheconditionallabeldistributionp(y|x)shouldhavelowentropy whilethemarginalp(y)=Rp(y|x=G(z))dzshouldhavehighentropy.TofurtheranalyzetherelationshipbetweentheproposedapproachandPRDcurves weplotp(y|x)againstprecisionandp(y)againstrecallinFigure10intheappendix.TheresultsoveralargenumberofGANsandVAEsshowalargeSpearmancorrelationof-0.83forprecisionand0.89forrecall.Wehoweverstresstwokeydifferencesbetweentheapproaches:Firstly tocomputethequantitiesinISoneneedsaclassiﬁerandalabeleddatasetincontrasttotheproposedPRDmetricwhichcanbeappliedonunlabeleddata.Secondly ISonlycaptureslossesinrecallw.r.t.classes whileourmetricmeasuresmoreﬁne-grainedrecalllosses(seeFigure8intheappendix).3Wedenotetheoutputoftheclassiﬁerforitshighestvalueatthesoftmaxlayerasconﬁdence.Theintuitionisthathighervaluessignifyhigherconﬁdenceofthemodelforthegivenlabel.70.00.20.40.60.81.0F8(Recall)0.00.20.40.60.81.0F1/8(Precision)ABCDGANVAEABCDFigure7:F1/8vsF8scoresforalargenumberofGANsandVAEsontheFashion-MNISTdataset.Foreachmodel weplotthemaximumF1/8andF8scorestoshowthetrade-offbetweenprecisionandrecall.VAEsgenerallyachievelowerprecisionand/orhigherrecallthanGANswhichmatchesthefolklorethatVAEsoftenproducesamplesoflowerqualitywhilebeinglesspronetomodecollapse.Ontherightweshowsamplesfromfourmodelswhichcorrespondtovarioussuccess/failuremodes:(A)highprecision lowrecall (B)highprecision highrecall (C)lowprecision lowrecall and(D)lowprecision highrecall.4.3ApplicationtoGANsandVAEsWeevaluatetheprecisionandrecallof7GANtypesandtheVAEwith100hyperparametersettingseachasprovidedby[18].Inordertovisualizethisvastquantityofmodels oneneedstosummarizethePRDcurves.AnaturalideaistocomputethemaximumF1score whichcorrespondstotheharmonicmeanbetweenprecisionandrecallasasingle-numbersummary.ThisideaisfundamentallyﬂawedasF1issymmetric.However itsgeneralization deﬁnedasFβ=(1+β2)p·r(β2p)+r providesawaytoquantifytherelativeimportanceofprecisionandrecall:β>1weighsrecallhigherthanprecision whereasβ<1weighsprecisionhigherthanrecall.Asaresult weproposetodistilleachPRDcurveintoapairofvalues:FβandF1/β.Figure7comparesthemaximumF8withthemaximumF1/8forthesemodelsontheFashion-MNISTdataset.Wechooseβ=8asitoffersagoodinsightintothebiastowardsprecisionversusrecall.SinceF8weighsrecallhigherthanprecisionandF1/8doestheopposite modelswithhigherrecallthanprecisionwillliebelowthediagonalF8=F1/8andmodelswithhigherprecisionthanrecallwilllieabove.Toourknowledge thisistheﬁrstmetricwhichconﬁrmsthefolklorethatVAEsarebiasedtowardshigherrecall butmaysufferfromprecisionissues(e.g. duetoblurringeffects) atleastonthisdataset.Ontheright weshowsamplesfromfourmodelsontheextremeendsoftheplotforallcombinationsofhighandlowprecisionandrecall.WehaveincludedsimilarplotsontheMNIST CIFAR-10andCelebAdatasetsintheappendix.5ConclusionQuantitativelyevaluatinggenerativemodelsisachallengingtaskofparamountimportance.Inthisworkweshowthatone-dimensionalscoresarenotsufﬁcienttocapturedifferentfailurecasesofcurrentstate-of-the-artgenerativemodels.Asanalternative weproposeanovelnotionofprecisionandrecallfordistributionsandprovethatbothnotionsaretheoreticallysoundandhavedesirableproperties.WethenconnectthesenotionstototalvariationdistanceaswellasFIDandISandwedevelopanefﬁcientalgorithmthatcanbereadilyappliedtoevaluatedeepgenerativemodelsbasedonsamples.Weinvestigatethepropertiesoftheproposedalgorithmonreal-worlddatasets includingimageandtextgeneration andshowthatitcapturestheprecisionandrecallofgenerativemodels.Finally weﬁndempiricalevidencesupportingthefolklorethatVAEsproducesamplesoflowerquality whilebeinglesspronetomodecollapsethanGANs.8References[1]OlivierBachem MarioLucic HamedHassani andAndreasKrause.Fastandprovablygoodseedingsfork-means.InAdvancesinNeuralInformationProcessingSystems(NIPS) 2016.[2]OlivierBachem MarioLucic SHamedHassani andAndreasKrause.Approximatek-means++insublineartime.InAAAI 2016.[3]ShaneBarrattandRishiSharma.ANoteontheInceptionScore.arXivpreprintarXiv:1801.01973 2018.[4]MikołajBi´nkowski DougalJ.Sutherland MichaelArbel andArthurGretton.DemystifyingMMDGANs.InInternationalConferenceonLearningRepresentations(ICLR) 2018.[5]AliBorji.ProsandConsofGANEvaluationMeasures.arXivpreprintarXiv:1802.03446 2018.[6]OndˇrejCífka AliakseiSeveryn EnriqueAlfonseca andKatjaFilippova.Evalall trustafew dowrongtonone:Comparingsentencegenerationmodels.arXivpreprintarXiv:1804.07972 2018.[7]AlexisConneau DouweKiela HolgerSchwenk LoicBarrault andAntoineBordes.SupervisedLearn-ingofUniversalSentenceRepresentationsfromNaturalLanguageInferenceData.arXivpreprintarXiv:1705.02364 2017.[8]IanGoodfellow JeanPouget-Abadie MehdiMirza BingXu DavidWarde-Farley SherjilOzair AaronCourville andYoshuaBengio.GenerativeAdversarialNetworks.InAdvancesinNeuralInformationProcessingSystems(NIPS) 2014.[9]MartinHeusel HubertRamsauer ThomasUnterthiner BernhardNessler GünterKlambauer andSeppHochreiter.GANstrainedbyatwotime-scaleupdateruleconvergetoaNashequilibrium.InAdvancesinNeuralInformationProcessingSystems(NIPS) 2017.[10]FerencHuszár.How(not)toTrainyourGenerativeModel:ScheduledSampling Likelihood Adversary?arXivpreprintarXiv:1511.05101 2015.[11]DanielJiwoongIm HeMa GrahamTaylor andKristinBranson.QuantitativelyevaluatingGANswithdivergencesproposedfortraining.InInternationalConferenceonLearningRepresentations(ICLR) 2018.[12]DiederikPKingmaandMaxWelling.Auto-encodingVariationalBayes.InInternationalConferenceonLearningRepresentations(ICLR) 2014.[13]AlexKrizhevskyandGeoffreyHinton.Learningmultiplelayersoffeaturesfromtinyimages 2009.[14]KarolKurach MarioLucic XiaohuaZhai MarcinMichalski andSylvainGelly.TheGANLandscape:Losses architectures regularization andnormalization.arXivpreprintarXiv:1807.04720 2018.[15]YannLeCun LéonBottou YoshuaBengio andPatrickHaffner.Gradient-basedlearningappliedtodocumentrecognition.InIEEE 1998.[16]ZiweiLiu PingLuo XiaogangWang andXiaoouTang.Deeplearningfaceattributesinthewild.InProceedingsofInternationalConferenceonComputerVision(ICCV) 2015.[17]DavidLopez-PazandMaximeOquab.RevisitingClassiﬁerTwo-SampleTests.InInternationalConferenceonLearningRepresentations(ICLR) 2016.[18]MarioLucic KarolKurach MarcinMichalski SylvainGelly andOlivierBousquet.AreGANsCreatedEqual?ALarge-ScaleStudy.InAdvancesinNeuralInformationProcessingSystems(NeurIPS) 2018.[19]AugustusOdena VincentDumoulin andChrisOlah.Deconvolutionandcheckerboardartifacts.Distill 2016.[20]TimSalimans IanGoodfellow WojciechZaremba VickiCheung AlecRadford andXiChen.ImprovedTechniquesforTrainingGANs.InAdvancesinNeuralInformationProcessingSystems(NIPS) 2016.[21]DavidSculley.Web-scalek-meansclustering.InInternationalConferenceonWorldWideWeb(WWW) 2010.[22]LucasTheis AäronvandenOord andMatthiasBethge.Anoteontheevaluationofgenerativemodels.InInternationalConferenceonLearningRepresentations(ICLR) 2016.[23]AdinaWilliams NikitaNangia andSamuelRBowman.Abroad-coveragechallengecorpusforsentenceunderstandingthroughinference.arXivpreprintarXiv:1704.05426 2017.9[24]YuhuaiWu YuriBurda RuslanSalakhutdinov andRogerGrosse.Onthequantitativeanalysisofdecoder-basedgenerativemodels.InInternationalConferenceonLearningRepresentations(ICLR) 2017.[25]HanXiao KashifRasul andRolandVollgraf.Fashion-MNIST:ANovelImageDatasetforBenchmarkingMachineLearningAlgorithms.arXivpreprintarXiv:1708.07747 2017.10,Mehdi S. M. Sajjadi
Olivier Bachem
Mario Lucic
Olivier Bousquet
Sylvain Gelly