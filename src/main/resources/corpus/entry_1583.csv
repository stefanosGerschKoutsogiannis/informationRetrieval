2019,Distributed estimation of the inverse Hessian by determinantal averaging,In distributed optimization and distributed numerical linear algebra 
we often encounter an inversion bias: if we want to compute a
quantity that depends on the inverse of a sum of distributed matrices 
then the sum of the inverses does not equal the inverse of the sum.  
An example of this occurs in distributed Newton's method  where we
wish to compute (or implicitly work with) the inverse Hessian
multiplied by the gradient.  
In this case  locally computed estimates are biased  and so taking a
uniform average will not recover the correct solution.  
To address this  we propose determinantal averaging  a new
approach for correcting the inversion bias. 
This approach involves reweighting the local estimates of the Newton's
step proportionally to the determinant of the local Hessian estimate 
and then averaging them together to obtain an improved global
estimate. This method provides the first known distributed Newton step that is
asymptotically consistent  i.e.  it recovers the exact step in
the limit as the number of distributed partitions grows to infinity.  
To show this  we develop new expectation identities and moment bounds
for the determinant and adjugate of a random matrix.  
Determinantal averaging can be applied not only to Newton's method 
but to computing any quantity that is a linear tranformation of a
matrix inverse  e.g.  taking a trace of the inverse covariance matrix 
which is used in data uncertainty quantification.,Distributed estimation of the inverse Hessian by

determinantal averaging

Michał Derezi´nski

Department of Statistics

University of California  Berkeley

mderezin@berkeley.edu

Michael W. Mahoney

ICSI and Department of Statistics
University of California  Berkeley
mmahoney@stat.berkeley.edu

Abstract

In distributed optimization and distributed numerical linear algebra  we often
encounter an inversion bias: if we want to compute a quantity that depends on
the inverse of a sum of distributed matrices  then the sum of the inverses does not
equal the inverse of the sum. An example of this occurs in distributed Newton’s
method  where we wish to compute (or implicitly work with) the inverse Hessian
multiplied by the gradient. In this case  locally computed estimates are biased  and
so taking a uniform average will not recover the correct solution. To address this 
we propose determinantal averaging  a new approach for correcting the inversion
bias. This approach involves reweighting the local estimates of the Newton’s step
proportionally to the determinant of the local Hessian estimate  and then averaging
them together to obtain an improved global estimate. This method provides the ﬁrst
known distributed Newton step that is asymptotically consistent  i.e.  it recovers
the exact step in the limit as the number of distributed partitions grows to inﬁnity.
To show this  we develop new expectation identities and moment bounds for the
determinant and adjugate of a random matrix. Determinantal averaging can be
applied not only to Newton’s method  but to computing any quantity that is a linear
transformation of a matrix inverse  e.g.  taking a trace of the inverse covariance
matrix  which is used in data uncertainty quantiﬁcation.

1

Introduction

Many problems in machine learning and optimization require that we produce an accurate estimate of a
square matrix H (such as the Hessian of a loss function or a sample covariance)  while having access to

approach has certain fundamental limitations (described in more detail below). The basic reason for

cases  taking a uniform average of those independent copies provides a natural strategy for boosting
the estimation accuracy  essentially by making use of the law of large numbers: 1
For many other problems  however  we are more interested in the inverse (Hessian/covariance) matrix

many copies of some unbiased estimator of H  i.e.  a random matrix bH such that E[bH] = H. In these
t=1 bHt ! H.
H1  and it is necessary or desirable to work with bH1 as the estimator. Here  a naïve averaging
this is that E[bH1] 6= H1  i.e.  that there is what may be called an inversion bias.

In this paper  we propose a method to address this inversion bias challenge. The method uses a
weighted average  where the weights are carefully chosen to compensate for and correct the bias.
Our motivation comes from distributed Newton’s method (explained shortly)  where combining
independent estimates of the inverse Hessian is desired  but our method is more generally applicable 
and so we ﬁrst state our key ideas in a more general context.

mPm

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

Theorem 1 Let si be independent random variables and Zi be ﬁxed square rank-1 matrices. If bH =
Pi siZi is invertible almost surely  then the inverse of the matrix H = E[bH] can be expressed as:

H1 =

.

E⇥det(bH)bH1⇤
E⇥det(bH)⇤

 

t )

t=1 at

To demonstrate the implications of Theorem 1  suppose that our goal is to estimate F (H1) for
some linear function F . For example  in the case of Newton’s method F (H1) = H1g  where
g is the gradient and H is the Hessian. Another example would be F (H1) = tr(H1)  where H
is the covariance matrix of a dataset and tr(·) is the matrix trace  which is useful for uncertainty
quantiﬁcation. For these and other cases  consider the following estimation of F (H1)  which takes
an average of the individual estimates F (bH1

t )  each weighted by the determinant of bHt  i.e. 
ˆFm = Pm

Determinantal Averaging:

By applying the law of large numbers (separately to the numerator and the denominator)  Theorem 1

at = det(bHt).

t=1 atF (bH1
Pm

easily implies that if bH1  . . .  bHm are i.i.d. copies of bH then this determinantal averaging estimator is
asymptotically consistent  i.e.  ˆFm ! F (H1)  almost surely. This determinantal averaging estimator
is particularly useful when problem constraints do not allow us to compute F( 1
mPt bHt)1  e.g. 
when the matrices are distributed and not easily combined.
To establish ﬁnite sample convergence guarantees for estimators obtained via determinantal averaging 
we establish the following matrix concentration result. We state it separately since it is technically
interesting and since its proof requires novel bounds for the higher moments of the determinant of
a random matrix  which is likely to be of independent interest. Below and throughout the paper  C
denotes an absolute constant and “” is the Löwner order on positive semi-deﬁnite (psd) matrices.
kPn
Theorem 2 Let bH = 1
i=1 biZi + B and H = E[bH]  where B is a positive deﬁnite d ⇥ d
matrix and bi are i.i.d. Bernoulli( k
n ). Moreover  assume that all Zi are psd  d ⇥ d and rank-1. If
k  C µd2
pm⌘ · H1  Pm
⇣1 
t=1 at ⇣1 +
t=1 atbH1
Pm
i.i.d.⇠ bH and at = det(bHt).

where bH1  . . .  bHm
1.1 Distributed Newton’s method
To illustrate how determinantal averaging can be useful in the context of distributed optimization 
consider the task of batch minimization of a convex loss over vectors w 2 Rd  deﬁned as follows:
(1)

pm⌘ · H1 with probability  1   

 for ⌘ 2 (0  1) and µ = maxi kZiH1k/d  then

⌘2 log3 d
⌘

`i(w>xi) +

def
=

⌘

t


2kwk2 

L(w)

1
n

nXi=1

where > 0  and `i are convex  twice differentiable and smooth. Given a vector w  Newton’s method
dictates that the correct way to move towards the optimum is to perform an update ew = w  p  with
p = r2L(w)rL(w)  where r2L(w) = (r2L(w))1 denotes the inverse Hessian of L at w.1
Here  the Hessian and gradient are:

r2L(w) =

`00i (w>xi) xix>i + I 

and rL(w) =

`0i(w>xi) xi + w.

For our distributed Newton application  we study a distributed computational model  where a single
machine has access to a subsampled version of L with sample size parameter k ⌧ n:
bi ⇠ Bernoullik/n.


2kwk2  where

1Clearly  one would not actually compute the inverse of the Hessian explicitly [XRKM17  YXRKM18]. We
describe it this way for simplicity. Our results hold whether or not the inverse operator is computed explicitly.

bL(w)

bi`i(w>xi) +

nXi=1

(2)

1
k

def
=

1

nXi

1

nXi

2

Note that bL accesses on average k loss components `i (k is the expected local sample size)  and
moreover  E⇥bL(w)⇤ = L(w) for any w. The goal is to compute local estimates of the Newton’s

step p in a communication-efﬁcient manner (i.e.  by only sending O(d) parameters from/to a single
machine)  then combine them into a better global estimate. The gradient has size O(d) so it can be
computed exactly within this communication budget (e.g.  via map-reduce)  however the Hessian has
to be approximated locally by each machine. Note that other computational models can be considered 
such as those where the global gradient is not computed (and local gradients are used instead).

Under the constraints described above  the most natu-
ral strategy is to use directly the Hessian of the locally

subsampled loss bL (see  e.g.  GIANT [WRKXM18]) 
resulting in the approximate Newton step bp =
r2bL(w)rL(w). Suppose that we independently
construct m i.i.d. copies of this estimate:bp1  . . .  bpm
t=1bpt ! E⇥bp⇤ 6= p. Figure 1 shows
mPm

(here  m is the number of machines). Then  for suf-
ﬁciently large m  taking a simple average of the esti-
mates will stop converging to p because of the inver-
sion bias: 1
this by plotting the estimation error (in Euclidean dis-
tance) of the averaged Newton step estimators  when
the weights are uniform and determinantal (for more
details and plots  see Appendix C).
The only way to reduce the estimation error beyond a certain point is to increase the local sample size k
(thereby reducing the inversion bias)  which raises the computational cost per machine. Determinantal
averaging corrects the inversion bias so that estimation error can always be decreased by adding more
machines without increasing the local sample size. From the preceding discussion we can easily
show that determinantal averaging leads to an asymptotically consistent estimator. This is a corollary
of Theorem 1  as proven in Section 2.

Figure 1: Newton step estimation error versus
number of machines  averaged over 100 runs
(shading is standard error) for a libsvm dataset
[CL11]. More plots in Appendix C.

t=1 at

a.s.!m!1

Pm
t=1 atbpt
Pm

Corollary 3 Let {bLt}1t=1 be i.i.d. samples of (2) and deﬁne at = detr2bLt(w). Then:
p  where bpt = r2bLt(w)rL(w) and p = r2L(w)rL(w).

The (unnormalized) determinantal weights can be computed locally in the same time as it takes to
compute the Newton estimates so they do not add to the overall cost of the procedure. While this
result is only an asymptotic statement  it holds with virtually no assumptions on the loss function
(other than twice-differentiability) or the expected local sample size k. However  with some additional
assumptions we will now establish a convergence guarantee with a ﬁnite number of machines m by
bounding the estimation error for the determinantal averaging estimator of the Newton step.

In the next result  we use Mahalanobis distance  denoted kvkM = pv>Mv  to measure the error of
the Newton step estimate (i.e.  the deviation from optimum p)  with M chosen as the Hessian of L.
This choice is motivated by standard convergence analysis of Newton’s method  discussed next. This
is a corollary of Theorem 2  as explained in Section 3.
Corollary 4 For any   ⌘2 (0  1) if expected local sample size satisﬁes k  C⌘2µd2 log3 d

 then

where µ = 1

Pm
t=1 at  pr2L(w)
t=1 atbpt
Pm
d maxi `00i (w>xi)kxik2

⌘

pm · pr2L(w) with probability  1   
r2L(w)  and at bpt and p are deﬁned as in Corollary 3.

We next establish how this error bound impacts the convergence guarantees offered by Newton’s
method. Note that under our assumptions L is strongly convex so there is a unique minimizer
w⇤ = argminw L(w). We ask how the distance from optimum  kw  w⇤k  changes after we make
function of w. After this standard assumption  a classical analysis of the Newton’s method reveals
that Corollary 4 implies the following Corollary 6 (proof in Appendix B).

an update ew = w bp. For this  we have to assume that the Hessian matrix is L-Lipschitz as a

3

2L

pm

 then

pw  w⇤ 

Assumption 5 The Hessian is L-Lipschitz: kr2L(w)r2L(ew)k  Lkwewk for any w ew 2 Rd.
Corollary 6 For any   ⌘2 (0  1) if expected local sample size satisﬁes k  C⌘2µd2 log3 d
under Assumption 5 it holds with probability at least 1   that
minw  w⇤2o for ew = w Pm
ew  w⇤  maxn ⌘
t=1 atbpt
Pm
where C  µ  at andbpt are deﬁned as in Corollaries 3 and 4  while  and min are the condition

number and smallest eigenvalue of r2L(w)  respectively.
The bound is a maximum of a linear and a quadratic convergence term. As m goes to inﬁnity and/or
⌘ goes to 0 the approximation coefﬁcient ↵ = ⌘pm in the linear term disappears and we obtain exact
Newton’s method  which exhibits quadratic convergence (at least locally around w⇤). However 
decreasing ⌘ means increasing k and with it the average computational cost per machine. Thus  to
preserve the quadratic convergence while maintaining a computational budget per machine  as the
optimization progresses we have to increase the number of machines m while keeping k ﬁxed. This
is only possible when we correct for the inversion bias  which is done by determinantal averaging.

t=1 at

 

1.2 Distributed data uncertainty quantiﬁcation
Here  we consider another example of when computing a compressed linear representation of the
inverse matrix is important. Let X be an n ⇥ d matrix where the rows x>i represent samples drawn
from a population for statistical analysis. The sample covariance matrix ⌃ = 1
n X>X holds the
information about the relations between the features. Assuming that ⌃ is invertible  the matrix ⌃1 
also known as the precision matrix  is often used to establish a degree of conﬁdence we have in the
data collection [KBCG13]. The diagonal elements of ⌃1 are particularly useful since they hold
the variance information of each individual feature. Thus  efﬁciently estimating either the entire
diagonal  its trace  or some subset of its entries  is of practical interest [Ste97  WLK+16  BCF09]. We
consider the distributed setting where data is separately stored in batches and each local covariance is
modeled as:

1
k

nXi=1

b⌃ =

bixix>i   where

bi ⇠ Bernoulli(k/n).

For each of the local covariances b⌃1  . . .  b⌃m  we compute its compressed uncertainty information:
F(b⌃t + ⌘pm I)1  where we added a small amount of ridge to ensure invertibility2. Here  F (·)

may for example denote the trace or the vector of diagonal entries. We arrive at the following
asymptotically consistent estimator for F (⌃1):

ˆFm = Pm

t=1 at mF(b⌃t + ⌘pm I)1

t=1 at m

Pm

  where at m = detb⌃t + ⌘pm I.

d maxi kxik2

Note that the ridge term ⌘pm I decays to zero as m goes to inﬁnity  which is why ˆFm ! F (⌃1).
Even though this limit holds for any local sample size k  in practice we should choose k sufﬁciently
large so that b⌃ is well-conditioned. In particular  Theorem 2 implies that if k  2C⌘2µd2 log3 d
  
⌃1  then for F (·) = tr(·) we have | ˆFm  tr(⌃1)| ⌘pm · tr(⌃1)
where µ = 1
w.p. 1  .
1.3 Related work
Many works have considered averaging strategies for combining distributed estimates  particularly
in the context of statistical learning and optimization. This research is particularly important in
federated learning [KBRR16  KBY+16]  where data are spread out across a large network of devices
with small local storage and severely constrained communication bandwidth. Using averaging to
combine local estimates has been studied in a number of learning settings [MMS+09  MHM10] as

2Since the ridge term vanishes as m goes to inﬁnity  we are still estimating the ridge-free quantity F (⌃1).

4

well as for ﬁrst-order stochastic optimization [ZWLS10  AD11]. For example  [ZDW13] examine
the effectiveness of simple uniform averaging of empirical risk minimizers and also propose a
bootstrapping technique to reduce the bias.
More recently  distributed averaging methods gained considerable attention in the context of second-
order optimization  where the Hessian inversion bias is of direct concern.
[SSZ14] propose a
distributed approximate Newton-type method (DANE) which under certain assumptions exhibits
low bias. This was later extended and improved upon by [ZL15  RKR+16]. The GIANT method
of [WRKXM18] most closely follows our setup from Section 1.1  providing non-trivial guarantees

for uniform averaging of the Newton step estimatesbpt (except they use with-replacement uniform

sampling  whereas we use without-replacement  but that is typically a negligible difference). A
related analysis of this approach is provided in the context of ridge regression by [WGM17]. Finally 
[ABH17  MLR17  BJKJ17] propose different estimates of the Newton step which exhibit low bias
under certain additional assumptions.
Our approach is related to recent developments in determinantal subsampling techniques (e.g. 
volume sampling)  which have been shown to correct the inversion bias in the context of least squares
regression [DW17  DWH19]. However  despite recent progress [DW18  DWH18]  volume sampling
is still far too computationally expensive to be feasible for distributed optimization. Indeed  often
uniform sampling is the only practical choice in this context.
With the exception of the expensive volume sampling-based methods  all of the approaches discussed
above  even under favorable conditions  use biased estimates of the desired solution (e.g.  the exact
Newton step). Thus  when the number of machines grows sufﬁciently large  with ﬁxed local sample
size  the averaging no longer provides any improvement. This is in contrast to our determinantal
averaging  which converges exactly to the desired solution and requires no expensive subsampling.
Therefore  it can scale with an arbitrarily large number of machines.

2 Expectation identities for determinants and adjugates

In this section  we prove Theorem 1 and Corollary 3  establishing that determinantal averaging is
asymptotically consistent. To achieve this  we establish a lemma involving two expectation identities.
For a square n ⇥ n matrix A  we use adj(A) to denote its adjugate  deﬁned as an n ⇥ n matrix
whose (i  j)th entry is (1)i+j det(Aj i)  where Aj i denotes A without jth row and ith
column. The adjugate matrix provides a key connection between the inverse and the determinant
because for any invertible matrix A  we have adj(A) = det(A)A1. In the following lemma 
we will also use a formula called Sylvester’s theorem  relating the adjugate and the determinant:
det(A + uv>) = det(A) + v>adj(A)u.

(a) E⇥ det(A)⇤ = detE[A]

Lemma 7 For A =Pi siZi  where si are independently random and Zi are square and rank-1 
Proof We use induction over the number of components in the sum. If there is only one component 
i.e.  A = sZ  then det(A) = 0 a.s. unless Z is 1⇥1  in which case (a) is trivial  and (b) follows
similarly. Now  suppose we showed the hypothesis when the number of components is n and let
A =Pn+1

(b) E⇥ adj(A)⇤ = adjE[A].

and

i=1 siZi. Setting Zn+1 = uv>  we have:

E⇥ det(A)⇤ = E det⇣ nXi=1
(Sylvester’s Theorem) = E det⇣ nXi=1
(inductive hypothesis) = det✓Eh nXi=1
(Sylvester’s Theorem) = det✓Eh nXi=1

siZi + sn+1uv>⌘
siZi⌘u
siZi⌘ + sn+1v>adj⇣ nXi=1
siZii◆ + E[sn+1] v>adj✓Eh nXi=1
siZii◆u
siZii + E[sn+1] uv>◆ = detE[A] 

showing (a). Finally  (b) follows by applying (a) to each entry adj(A)ij = (1)i+j det(Aj i).

5

Similar expectation identities for the determinant have been given before [vdV65  DWH19  Der19].
None of them  however  apply to the random matrix A as deﬁned in Lemma 7  or even to the special
case we use for analyzing distributed Newton’s method. Also  our proof method is quite different  and
somewhat simpler  than those used in prior work. To our knowledge  the extension of determinantal
expectation to the adjugate matrix has not previously been pointed out.
We next prove Theorem 1 and Corollary 3 as consequences of Lemma 7.

Proof of Theorem 1 When A is invertible  its adjugate is given by adj(A) = det(A)A1  so the
lemma implies that

E⇥det(A)⇤E[A]1 = detE[A]E[A]1 = adj(E[A]) = E⇥adj(A)⇤ = E⇥det(A)A1⇤ 

from which Theorem 1 follows immediately.

Proof of Corollary 3 The subsampled Hessian matrix used in Corollary 3 can be written as:

1

bi`00i (w>xi) xix>i + 

dXi=1
so  letting bHt = r2bLt(w)  Corollary 3 follows from Theorem 1 and the law of large numbers:
E⇥det(bH)bH1⇤
Pm
t=1 atbpt
E⇥det(bH)⇤ rL(w) = r2L(w)rL(w) 
Pm

kXi
r2bL(w) =
t=1 detbHtbH1
mPm
t=1 detbHt
mPm

which concludes the proof.

= bH 

t rL(w)

!m!1

t=1 at

eie>i

=

def

1

1

3 Finite-sample convergence analysis

In this section  we prove Theorem 2 and Corollary 4  establishing that determinantal averaging
exhibits a 1/pm convergence rate  where m is the number of sampled matrices (or the number of
machines in distributed Newton’s method). For this  we need a tool from random matrix theory.
Lemma 8 (Matrix Bernstein [Tro12]) Consider a ﬁnite sequence {Xi} of independent  random 
self-adjoint matrices with dimension d such that E[Xi] = 0 and max(Xi)  R almost surely. If the

sequence satisﬁesPi E[X2

i ]  2  then the following inequality holds for all x  0:

Pr✓max⇣Xi

Xi⌘  x◆ (d e x2

42
d e x

4R

for x  2
R ;
for x  2
R .

The key component of our analysis is bounding the moments of the determinant and adjugate of
a certain class of random matrices. This has to be done carefully  because higher moments of the
determinant grow more rapidly than  e.g.  for a sub-gaussian random variable. For this result  we
do not require that the individual components Zi of matrix A be rank-1  but we impose several
additional boundedness assumptions. In the proof below we apply the concentration inequality of
Lemma 8 twice: ﬁrst to the random matrix A itself  and then also to its trace  which allows ﬁner
control over the determinant.
Pi biZi + B  where bi ⇠ Bernoulli() are independent  whereas Zi and
Lemma 9 Let A = 1
B are d ⇥ d psd matrices such that kZik  ✏ for all i and E[A] = I. If   8✏d⌘2(p + ln d) for
0 <⌘  0.25 and p  2  then

Proof We start by proving (a). Let X = det(A)  1 and denote 1[a b] as the indicator variable of
the event that X 2 [a  b]. Since det(A)  0  we have:

(b) Eh adj(A)  Ipi 1

p  9⌘.

and

p  5⌘

(a) Eh det(A)  1pi 1
E⇥|X|p⇤ = E⇥(X)p · 1[1 0]⇤ + E⇥X p · 1[0 1]⇤

 ⌘p + Z 1

⌘

pxp1 Pr(X  x)dx + Z 1

0

pxp1 Pr(X  x)dx.

(3)

6

E[X2

   so:

 )Zi. We

Xi

  1  1
1

Thus it sufﬁces to bound the two integrals. We will start with the ﬁrst one. Let Xi = (1  bi
use the matrix Bernstein inequality to control the extreme eigenvalues of the matrix I  A =Pi Xi
(note that matrix B cancels out because I = E[A] = Pi Zi + B). To do this  observe that
 )2⇤ = 1
kXik  ✏/ and  moreover  E⇥(1  bi
i 
 ·Xi
i 
i ] =Xi
 )2⇤Z2
E⇥(1  bi
  1⇤:
Thus  applying Lemma 8 we conclude that for any z 2⇥ ⌘p2d
Pr⇣kI  Ak  z⌘  2d e z2
⌘2 (p+ln d)  2ez2 2dp
4✏  2eln(d)z2 2d
(4)
Conditioning on the high-probability event given by (4) leads to the lower bound det(A)  (1  z)d
which is very loose. To improve on it  we use the following inequality  where 1  . . .   d denote the
eigenvalues of I  A:

 ·Xi

Zi 

⌘2 .

Z2

✏


✏

.

det(A)etr(IA) =Yi

(1  i)ei Yi

(1  i)(1 + i) =Yi

(1  2
i ).

✏

⌘2

⌘2

(5)

ey 2dp

  ⌘2

for y  d;
for y  d.

Thus we obtain a tighter bound when det(A) is multiplied by etr(IA)  and now it sufﬁces to
upper bound the latter. This is a simple application of the scalar Bernstein’s inequality (Lemma
8 with d = 1) for the random variables Xi = tr(Xi)  ✏/  ⌘2
i ] 
 trPi Zi  ✏d

8dp  which satisfyPi E[X 2

8p . Thus the scalar Bernstein’s inequality states that

maxn Prtr(A  I)  y  Prtr(A  I)  yo  (ey2 2p
2 and z =p x

2d and taking a union bound over the appropriate high-probability events

Setting y = x
given by (4) and (5)  we conclude that for any x 2 [⌘  1]:
det(A)  (1  z2)d exptr(A  I) 1  x
2e x
Thus  for X = det(A)1 and x 2 [⌘  1] we obtain that Pr(X  x)  3ex2 p
p ·Z 1
Z 1
pxp1 Pr  X  xdx  3pZ 1
2⌘2 dx  3pq⇡ 2⌘2
2 = 3p2⇡p · ⌘p.
p p p1

2  1  x  with prob. 1  3ex2 p
1|x|p1 ex2 p
p2⇡⌘2/p
We now move on to bounding the remaining integral from (3). Since determinant is the product of
eigenvalues  we have det(A) = det(I + A  I)  etr(AI)  so we can use the Bernstein bound of
(5) w.r.t. A  I. It follows that:
pxp1 Pr(X  x)dx Z 1
Z 1
Z ed1
Z e1

pxp1 Pretr(AI)  1 + xdx
⌘2 dx + Z 1
⌘2 dx + Z 1

 3p2⇡⌘2p · ⌘2

pxp1e ln2(1+x) 2p

pxp1e ln2(1+x) 2p

pxp1e ln(1+x) 2dp

pxp1e ln(1+x) 2p

because ln2(1 + x)  ln(1 + x) for x  e  1. Note that ln2(1 + x)  x2/4 for x 2 [0  e  1]  so

xp1 ex2 p

2⌘2   and consequently 

⌘2 dx 

⌘2 dx

ed1

e1

2⌘2 .

dx

2⌘2

⌘

⌘

0

0

0

0

⌘2 dx Z e1

0

Z e1

0

pxp1e ln2(1+x) 2p
In the interval x 2 [e  1 1]  we have:
⌘2 dx = pZ 1
Z 1
 pZ 1
1  1
1+x p

pxp1e ln(1+x) 2p

e1

e1

e(p1) ln(x)ln(1+x) 2p

pxp1ex2 p

2⌘2 dx p2⇡p · ⌘p.

e ln(1+x) p

⌘2 dx  pZ 1
⌘2 1  p ·⇣ 1
⌘2⌘p
2 1
2 p
⌘2  1 1

e1

p

p

⌘2 dx

 p ·⌘2p 

⌘2 dx =

7

1

1

⌘2  ⌘2. Noting that (1 + 4p2⇡p + p)
p  5 for any
where the last inequality follows because ( 1
2 )
p  2 concludes the proof of (a). The proof of (b)  given in Appendix A  follows similarly as above
because for any positive deﬁnite A we have det(A)
max(A) · I  adj(A)  det(A)
Having obtained bounds on the higher moments  we can now convert them to convergence with high
probability for the average of determinants and the adjugates. Since determinant is a scalar variable 
this follows by using standard arguments. On the other hand  for the adjugate matrix we require a
somewhat less standard matrix extension of the Khintchine/Rosenthal inequalities (see Appendix A).
Corollary 10 There is C > 0 s.t. for A as in Lemma 9 with all Zi rank-1 and   C✏d⌘ 2 log3 d
  
pm◆   

pm◆  

· I.

1
m

1
m

and

min

⌘

⌘

(a) Pr✓

mXt=1

det(At)  1 

where A1  . . .   Am are independent copies of A.

(b) Pr✓

mXt=1

adj(At)  I 

We are ready to show the convergence rate of determinantal averaging  which follows essentially by
upper/lower bounding the enumerator and denominator separately  using Corollary 10.

1

1

Z

=

def
=

det(H)

2 . Note that

2bHtH 1

n H 1
n d⌘2 log3 d

Proof of Theorem 2 We will apply Corollary 10 to the matrices At = H 1
kPi bieZi + H1  where eacheZi = 1
2 satisﬁes keZik  µ · d/n. Therefore 
2 ZiH 1
At = n
n  C µd
   with probability 1   the following average
Corollary 10 guarantees that for k
of determinants is concentrated around 1:
mXt
mXt
det(bHt)
detH 1
2 2 [1  ↵  1 + ↵]
2bHtH 1
Pm
t=1 det(At)  I 
adjAt  Z I /Z
mXt
Pm
adjAt  I +
1  ↵
mXt
(Corollary 10a) 
(Corollary 10b) 

along with a corresponding bound for the adjugate matrices. We obtain that with probability 1  2 

↵
1  ↵
It remains to multiply the above expressions by H 1

2 from both sides to recover the desired estimator:

↵
1  ↵

↵
1  ↵

t=1 adj(At)

⌘
pm

for ↵ =

+

1

1

1

.

 

t

Pm
t=1 det(bHt)bH1
Pm
t=1 det(bHt)

2 Pm
Pm

= H 1

t=1 adj(At)
t=1 det(At)

H 1

2  H 1

21 + 2↵

1↵ I H 1

2 =1 + 2↵

1↵H1 

and the lower bound follows identically. Appropriately adjusting the constants concludes the proof.
As an application of the above result  we show how this allows us to bound the estimation error in
distributed Newton’s method  when using determinantal averaging.

Proof of Corollary 4 Follows from Theorem 2 by setting Zi = `00i (w>xi)xix>i and B = I. Note
that the assumptions imply that kZik  µ  so invoking the theorem and denoting g as rL(w)  with
probability 1   we have
Pm
t=1 at  pH
=H
t=1 atbpt
Pm
H
(Theorem 2) H

2 g
2✓Pm
t=1 det(bHt)  H1◆H
t=1 det(bHt)bH1
Pm
2 ·H 1
2✓Pm
t=1 det(bHt)  H1◆H
t=1 det(bHt)bH1
2 g
Pm
2 ·k pkH = ⌘pm ·k pkH 

which completes the proof of the corollary.

2 ⌘pm H1H

2 H 1

t

t

1

1

1

1

1

1

8

4 Conclusions and future directions

We proposed a novel method for correcting the inversion bias in distributed Newton’s method.
Our approach  called determinantal averaging  can also be applied more broadly to distributed
estimation of other linear functions of the inverse Hessian or an inverse covariance matrix. We
show that estimators produced by determinantal averaging are asymptotically consistent  and we
provide bounds on the estimation error by developing new moment bounds on the determinant of a
random matrix.
Further empirical evaluation of determinantal averaging  both in the context of distributed optimization
and other tasks involving inverse estimation  is an important direction for future work. Our preliminary
experiments suggest that the bias-correction of determinantal averaging comes at a price of additional
variance in the estimators. This leads to a natural open problem: ﬁnd the optimal balance between bias
and variance in weighted averaging for distributed inverse estimation. Finally  note that we construct
our Newton estimates using local Hessian and global gradient. In some settings it is more practical
to use local approximations for both the Hessian and the gradient. Whether or not determinantal
averaging corrects the bias in this case remains open.

Acknowledgements
MWM would like to acknowledge ARO  DARPA  NSF and ONR for providing partial support of this
work. Also  MWM and MD thank the NSF for funding via the NSF TRIPODS program. Part of this
work was done while MD and MWM were visiting the Simons Institute for the Theory of Computing.

References

[ABH17] Naman Agarwal  Brian Bullins  and Elad Hazan. Second-order stochastic optimization
for machine learning in linear time. Journal of Machine Learning Research  18(116):1–
40  2017.

[AD11] Alekh Agarwal and John C Duchi. Distributed delayed stochastic optimization. In
J. Shawe-Taylor  R. S. Zemel  P. L. Bartlett  F. Pereira  and K. Q. Weinberger  editors 
Advances in Neural Information Processing Systems 24  pages 873–881. Curran
Associates  Inc.  2011.

[BCF09] C. Bekas  A. Curioni  and I. Fedulova. Low cost high performance uncertainty quan-
tiﬁcation. In Proceedings of the 2Nd Workshop on High Performance Computational
Finance  WHPCF ’09  pages 8:1–8:8  New York  NY  USA  2009. ACM.

[BJKJ17] D. Bajovi´c  D. Jakoveti´c  N. Kreji´c  and N.K. Jerinki´c. Newton-like method with
diagonal correction for distributed optimization. SIAM Journal on Optimization 
27(2):1171–1203  2017.

[CL11] Chih-Chung Chang and Chih-Jen Lin. LIBSVM: A library for support vector ma-
chines. ACM Transactions on Intelligent Systems and Technology  2:27:1–27:27 
2011.

[Der19] Michał Derezi´nski. Fast determinantal point processes via distortion-free intermediate

sampling. In Proceedings of the 32nd Conference on Learning Theory  2019.

[DW17] Michał Derezi´nski and Manfred K. Warmuth. Unbiased estimates for linear regression
via volume sampling. In Advances in Neural Information Processing Systems 30 
pages 3087–3096  Long Beach  CA  USA  December 2017.

[DW18] Michał Derezi´nski and Manfred K. Warmuth. Reverse iterative volume sampling for

linear regression. Journal of Machine Learning Research  19(23):1–39  2018.

[DWH18] Michał Derezi´nski  Manfred K. Warmuth  and Daniel Hsu. Leveraged volume sam-
pling for linear regression. In S. Bengio  H. Wallach  H. Larochelle  K. Grauman 
N. Cesa-Bianchi  and R. Garnett  editors  Advances in Neural Information Processing
Systems 31  pages 2510–2519. Curran Associates  Inc.  2018.

9

[DWH19] Michał Derezi´nski  Manfred K. Warmuth  and Daniel Hsu. Correcting the bias in
least squares regression with volume-rescaled sampling. In Proceedings of the 22nd
International Conference on Artiﬁcial Intelligence and Statistics  2019.

[GCT12] Alex Gittens  Richard Y. Chen  and Joel A. Tropp. The masked sample covariance
Information and

estimator: an analysis using matrix concentration inequalities.
Inference: A Journal of the IMA  1(1):2–20  05 2012.

[KBCG13] V. Kalantzis  C. Bekas  A. Curioni  and E. Gallopoulos. Accelerating data uncertainty
quantiﬁcation by solving linear systems with multiple right-hand sides. Numer.
Algorithms  62(4):637–653  April 2013.

[KBRR16] Jakub Konecný  H. Brendan McMahan  Daniel Ramage  and Peter Richtárik. Feder-
ated Optimization: Distributed Machine Learning for On-Device Intelligence. arXiv
e-prints  page arXiv:1610.02527  Oct 2016.

[KBY+16] Jakub Konecný  H. Brendan McMahan  Felix X. Yu  Peter Richtárik  Ananda Theertha
Suresh  and Dave Bacon. Federated Learning: Strategies for Improving Communica-
tion Efﬁciency. arXiv e-prints  page arXiv:1610.05492  Oct 2016.

[MHM10] Ryan McDonald  Keith Hall  and Gideon Mann. Distributed training strategies for
the structured perceptron. In Human Language Technologies: The 2010 Annual
Conference of the North American Chapter of the Association for Computational
Linguistics  HLT ’10  pages 456–464  Stroudsburg  PA  USA  2010. Association for
Computational Linguistics.

[MLR17] Aryan Mokhtari  Qing Ling  and Alejandro Ribeiro. Network newton distributed

optimization methods. Trans. Sig. Proc.  65(1):146–161  January 2017.

[MMS+09] Ryan Mcdonald  Mehryar Mohri  Nathan Silberman  Dan Walker  and Gideon S.
Mann. Efﬁcient large-scale distributed training of conditional maximum entropy
models. In Y. Bengio  D. Schuurmans  J. D. Lafferty  C. K. I. Williams  and A. Culotta 
editors  Advances in Neural Information Processing Systems 22  pages 1231–1239.
Curran Associates  Inc.  2009.

[NW06] Jorge Nocedal and Stephen J. Wright. Numerical Optimization. Springer  New York 

NY  USA  second edition  2006.

[RKR+16] Sashank J. Reddi  Jakub Konecný  Peter Richtárik  Barnabás Póczós  and Alex Smola.
AIDE: Fast and Communication Efﬁcient Distributed Optimization. arXiv e-prints 
page arXiv:1608.06879  Aug 2016.

[SSZ14] Ohad Shamir  Nati Srebro  and Tong Zhang. Communication-efﬁcient distributed
optimization using an approximate Newton-type method. In Eric P. Xing and Tony Je-
bara  editors  Proceedings of the 31st International Conference on Machine Learning 
volume 32 of Proceedings of Machine Learning Research  pages 1000–1008  Bejing 
China  22–24 Jun 2014. PMLR.

[Ste97] Guy V. G. Stevens. On the inverse of the covariance matrix in portfolio analysis. The

Journal of Finance  53:1821–1827  1997.

[Tro12] Joel A. Tropp. User-friendly tail bounds for sums of random matrices. Foundations

of Computational Mathematics  12(4):389–434  August 2012.

[vdV65] H. Robert van der Vaart. A note on Wilks’ internal scatter. Ann. Math. Statist. 

36(4):1308–1312  08 1965.

[WGM17] Shusen Wang  Alex Gittens  and Michael W. Mahoney. Sketched ridge regression:
Optimization perspective  statistical perspective  and model averaging. In Doina
Precup and Yee Whye Teh  editors  Proceedings of the 34th International Conference
on Machine Learning  volume 70 of Proceedings of Machine Learning Research 
pages 3608–3616  International Convention Centre  Sydney  Australia  06–11 Aug
2017. PMLR.

10

[WLK+16] Lingfei Wu  Jesse Laeuchli  Vassilis Kalantzis  Andreas Stathopoulos  and Efstratios
Gallopoulos. Estimating the trace of the matrix inverse by interpolating from the
diagonal of an approximate inverse. Journal of Computational Physics  326:828 –
844  2016.

[WRKXM18] Shusen Wang  Farbod Roosta-Khorasani  Peng Xu  and Michael W Mahoney. GIANT:
Globally improved approximate newton method for distributed optimization.
In
S. Bengio  H. Wallach  H. Larochelle  K. Grauman  N. Cesa-Bianchi  and R. Garnett 
editors  Advances in Neural Information Processing Systems 31  pages 2332–2342.
Curran Associates  Inc.  2018.

[XRKM17] Peng Xu  Farbod Roosta-Khorasani  and Michael Mahoney. Newton-type meth-
ods for non-convex optimization under inexact hessian information. Mathematical
Programming  August 2017.

[YXRKM18] Z. Yao  P. Xu  F. Roosta-Khorasani  and M. W. Mahoney. Inexact non-convex Newton-

type methods. Technical report  2018. Preprint: arXiv:1802.06925.

[ZDW13] Yuchen Zhang  John C. Duchi  and Martin J. Wainwright. Communication-efﬁcient al-
gorithms for statistical optimization. J. Mach. Learn. Res.  14(1):3321–3363  January
2013.

[ZL15] Yuchen Zhang and Xiao Lin. Disco: Distributed optimization for self-concordant
empirical loss. In Francis Bach and David Blei  editors  Proceedings of the 32nd
International Conference on Machine Learning  volume 37 of Proceedings of Machine
Learning Research  pages 362–370  Lille  France  07–09 Jul 2015. PMLR.

[ZWLS10] Martin Zinkevich  Markus Weimer  Lihong Li  and Alex J. Smola. Parallelized
stochastic gradient descent. In J. D. Lafferty  C. K. I. Williams  J. Shawe-Taylor  R. S.
Zemel  and A. Culotta  editors  Advances in Neural Information Processing Systems
23  pages 2595–2603. Curran Associates  Inc.  2010.

11

,Michal Derezinski
Michael Mahoney