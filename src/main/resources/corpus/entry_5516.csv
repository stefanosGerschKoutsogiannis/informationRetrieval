2017,The Scaling Limit of High-Dimensional Online Independent Component Analysis,We analyze the dynamics of an online algorithm for independent component analysis in the high-dimensional scaling limit. As the ambient dimension tends to infinity  and with proper time scaling  we show that the time-varying joint empirical measure of the target feature vector and the estimates provided by the algorithm will converge weakly to a deterministic measured-valued process that can be characterized as the unique solution of a nonlinear PDE. Numerical solutions of this PDE  which involves two spatial variables and one time variable  can be efficiently obtained. These solutions provide detailed information about the performance of the ICA algorithm  as many practical performance metrics are functionals of the joint empirical measures. Numerical simulations show that our asymptotic analysis is accurate even for moderate dimensions. In addition to providing a tool for understanding the performance of the algorithm  our PDE analysis also provides useful insight. In particular  in the high-dimensional limit  the original coupled dynamics associated with the algorithm will be asymptotically “decoupled”  with each coordinate independently solving a 1-D effective minimization problem via stochastic gradient descent. Exploiting this insight to design new algorithms for achieving optimal trade-offs between computational and statistical efficiency may prove an interesting line of future research.,The Scaling Limit of High-Dimensional Online

Independent Component Analysis

Chuang Wang and Yue M. Lu

John A. Paulson School of Engineering and Applied Sciences

Harvard University

33 Oxford Street  Cambridge  MA 02138  USA
{chuangwang yuelu}@seas.harvard.edu

Abstract

We analyze the dynamics of an online algorithm for independent component
analysis in the high-dimensional scaling limit. As the ambient dimension tends to
inﬁnity  and with proper time scaling  we show that the time-varying joint empirical
measure of the target feature vector and the estimates provided by the algorithm
will converge weakly to a deterministic measured-valued process that can be
characterized as the unique solution of a nonlinear PDE. Numerical solutions of this
PDE  which involves two spatial variables and one time variable  can be efﬁciently
obtained. These solutions provide detailed information about the performance
of the ICA algorithm  as many practical performance metrics are functionals of
the joint empirical measures. Numerical simulations show that our asymptotic
analysis is accurate even for moderate dimensions. In addition to providing a tool
for understanding the performance of the algorithm  our PDE analysis also provides
useful insight. In particular  in the high-dimensional limit  the original coupled
dynamics associated with the algorithm will be asymptotically “decoupled”  with
each coordinate independently solving a 1-D effective minimization problem via
stochastic gradient descent. Exploiting this insight to design new algorithms for
achieving optimal trade-offs between computational and statistical efﬁciency may
prove an interesting line of future research.

1

Introduction

Online learning methods based on stochastic gradient descent are widely used in many learning and
signal processing problems. Examples includes the classical least mean squares (LMS) algorithm
[1] in adaptive ﬁltering  principal component analysis [2  3]  independent component analysis (ICA)
[4]  and the training of shallow or deep artiﬁcial neural networks [5–7]. Analyzing the convergence
rate of stochastic gradient descent has already been the subject of a vast literature (see  e.g.  [8–11].)
Unlike existing work that analyze the behaviors of the algorithms in ﬁnite dimensions  we present
in this paper a framework for studying the exact dynamics of stochastic gradient algorithms in the
high-dimensional limit  using online ICA as a concrete example. Instead of minimizing a generic
function as considered in the optimization literature  the stochastic algorithm we analyze here is
solving an estimation problem. The extra assumptions on the ground truth (e.g.  the feature vector)
and the generative models for the observations allow us to obtain the exact asymptotic dynamics of
the algorithms.
As the main result of this work  we show that  as the ambient dimension n → ∞ and with proper
time-scaling  the time-varying joint empirical measure of the true underlying independent component
ξ and its estimate x converges weakly to the unique solution of a nonlinear partial differential
equation (PDE) [see (6).] Since many performance metrics  such as the correlation between ξ and

31st Conference on Neural Information Processing Systems (NIPS 2017)  Long Beach  CA  USA.

x and the support recover rate  are functionals of the joint empirical measure  knowledge about the
asymptotics of the latter allows us to easily compute the asymptotic limits of various performance
metrics of the algorithm.
This work is an extension of a recent analysis on the dynamics of online sparse PCA [12] to more
general settings. The idea of studying the scaling limits of online learning algorithm ﬁrst appeared in
a series of work that mostly came from the statistical physics communities [3  5  13–16] in the 1990s.
Similar to our setting  those early papers studied the dynamics of various online learning algorithms
in high dimensions. In particular  they show that the mean-squared error (MSE) of the estimation 
together with a few other “order parameters”  can be characterized as the solution of a deterministic
system of coupled ordinary differential equations (ODEs) in the large system limit. One limitation of
such ODE-level analysis is that it cannot provide information about the distributions of the estimates.
The latter are often needed when one wants to understand more general performance metrics beyond
the MSE. Another limitation is that the ODE analysis cannot handle cases where the algorithms have
non-quadratic regularization terms (e.g.  the incorporation of (cid:96)1 norms to promote sparsity.) In this
paper  we show that both limitations can be eliminated by using our PDE-level analysis  which tracks
the asymptotic evolution of the probability distributions of the estimates given by the algorithm. In a
recent paper [10]  the dynamics of an ICA algorithm was studied via a diffusion approximation. As
an important distinction  the analysis in [10] keeps the ambient dimension n ﬁxed and studies the
scaling limit of the algorithm as the step size tends to 0. The resulting PDEs involve O(n) spatial
variables. In contrast  our analysis studies the limit as the dimension n → ∞  with a constant step
size. The resulting PDEs only involve 2 spatial variables. This low-dimensional characterization
makes our limiting results more practical to use  especially when the dimension is large.
The basic idea underlying our analysis can trace its root to the early work of McKean [17  18]  who
studied the statistical mechanics of Markovian-type mean-ﬁeld interactive particles. The mathematical
foundation of this line of research has been further established in the 1980s (see  e.g.  [19  20]). This
theoretical tool has been used in the analysis of high-dimensional MCMC algorithms [21]. In our
work  we study algorithms through the lens of high-dimensional stochastic processes. Interestingly 
the analysis does not explicitly depend on whether the underlying optimization problem is convex
or nonconvex. This feature makes the presented analysis techniques a potentially very useful tool
in understanding the effectiveness of using low-complexity iterative algorithms for solving high-
dimensional nonconvex estimation problems  a line of research that has recently attracted much
attention (see  e.g.  [22–25].)
The rest of the paper is organized as follows. We ﬁrst describe in Section 2 the observation model and
the online ICA algorithm studied in this work. The main convergence results are given in Section 3 
where we show that the time-varying joint empirical measure of the target independent component
and its estimates given by the algorithm can be characterized  in the high-dimensional limit  by the
solution of a deterministic PDE. Due to space constraint  we only provide in the appendix a formal
derivation leading to the PDE  and leave the rigorous proof of the convergence to a follow-up paper.
Finally  in Section 4 we present some insight obtained from our asymptotic analysis. In particular 
in the high-dimensional limit  the original coupled dynamics associated with the algorithm will be
asymptotically “decoupled”  with each coordinate independently solving a 1-D effective minimization
problem via stochastic gradient descent.

Notations and Conventions: Throughout this paper  we use boldfaced lowercase letters  such as ξ
and xk  to represent n-dimensional vectors. The subscript k in xk denotes the discrete-time iteration
step. The ith component of the vectors ξ and xk are written as ξi and xk i  respectively.

2 Data model and online ICA
We consider a generative model where a stream of sample vectors yk ∈ Rn  k = 1  2  . . . are
generated according to
(1)
where ξ ∈ Rn is a unique feature vector we want to recover. (For simplicity  we consider the case
of recovering a single feature vector  but our analysis technique can be generalized to study cases
involving a ﬁnite number of feature vectors.) Here ck ∈ R is an i.i.d. random variable drawn from an
unknown non-Gaussian distribution Pc with zero mean and unit variance. And ak ∼ N (0  I− 1
n ξξT )

n ξck + ak 

yk = 1√

2

where F (x) =(cid:82) f (x) dx and

min(cid:107)x(cid:107)=n

− 1
K

n(cid:88)

i=1

1
n

F ( 1√

n yT

k x) +

K(cid:88)

(cid:90)

k=1

Φ(x) =

φ(x) dx

(cid:80)K

Φ(xi) 

(3)

(4)

sk

√

(cid:21)

(cid:20)ck

models background noise. We use the normalization (cid:107)ξ(cid:107)2 = n so that in the large n limit  all elements
ξi of the vector are O(1) quantities. The observation model (1) is equivalent to the standard sphered
  where A ∈ Rn×n is an orthonormal matrix with the ﬁrst column being
data model yk = A
n and sk is an i.i.d. (n − 1)-dimensional standard Gaussian random vector.
(cid:80)n
ξ/
To establish the large n limit  we shall assume that the empirical measure of ξ deﬁned by µ(ξ) =
i=1 δ(ξ − ξi) converges weakly to a deterministic measure µ∗(ξ) with ﬁnite moments. Note that
1
n
this assumption can be satisﬁed in a stochastic setting  where each element of ξ is an i.i.d. random
variable drawn from µ∗(ξ)  or in a deterministic setting [e.g.  ξi =
2(i mod 2)  in which case
µ∗(ξ) = 1
We use an online learning algorithm to extract the non-Gaussian component ξ from the data stream
{yk}k≥1. Let xk be the estimate of ξ at step k. Starting from an initial estimate x0  the algorithm
update xk by

2 δ(ξ − √

2 δ(ξ) + 1

2).]

√

n f ( 1√

n yT

k xk)yk − τk

n φ(xk)

xk+1 =

(2)
where f (·) is a given twice differentiable function and φ(·) is an element-wise nonlinear mapping
introduced to enforce prior information about ξ  e.g.  sparsity. The scaling factor 1√
n in the above
equations makes sure that each component xk i of the estimate is of size O(1) in the large n limit.
The above online learning scheme can be viewed as a projected stochastic gradient algorithm for
solving an optimization problem

(cid:101)xk = xk + τk√
n(cid:107)(cid:101)xk(cid:107)(cid:101)xk 

√

n

K

√
1

k=1 f ( 1√

k xk)yk  in place of the true gradient

is a regularization function. In (2)  we update xk using an instantaneous noisy estimation
1√
n f ( 1√
k xk)yk  once a new sample yk
n yT
is received.
In practice  one can use f (x) = ±x3 or f (x) = ± tanh(x) to extract symmetric non-Gaussian
k (cid:54)= 3) and use f (x) = ±x2 to extract asymmetric non-Gaussian
signals (for which E c3
signals. The algorithm in (2) with f (x) = x3 can also be regarded as implementing a low-rank tensor
decomposition related to the empirical kurtosis tensor of yk [10  11].
For the nonlinear mapping φ(x)  the choice of φ(x) = βx for some β > 0 corresponds to using an
L2 norm in the regularization term Φ(x). If the feature vector is known to be sparse  we can set
φ(x) = β sgn(x)  which is equivalent to adding an L1-regularization term.

k = 0 and E c4

n yT

3 Main convergence result

We provide an exact characterization of the dynamics of the online learning algorithm (2) when the
ambient dimension n goes to inﬁnity. First  we deﬁne the joint empirical measure of the feature
vector ξ and its estimate xk as

µn

t (ξ  x) =

1
n

δ(ξ − ξi  x − xk i)

(5)

with t deﬁned by k = (cid:98)tn(cid:99). Here we rescale (i.e.  “accelerate”) the time by a factor of n.
The joint empirical measure deﬁned above carries a lot of information about the performance of the
algorithm. For example  as both ξ and xk have the same norm
n by deﬁnition  the normalized
correlation between ξ and xk deﬁned by

√

n(cid:88)

i=1

Qn

t =

ξT xk

1
n

3

(cid:80)n

t = Eµn

t

t

h(ξ  x).

t = 1
n

t via the expectation Eµn

[ξx]  i.e.  the expectation of ξx taken with respect to the empirical
i=1 h(ξi  xk i) with some
t   i.e. 

can be computed as Qn
measure. More generally  any separable performance metric H n
function h(· ·) can be expressed as an expectation with respect to the empirical measure µn
t = Eµn
H n
t is a random probability
Directly computing Qn
measure. We bypass this difﬁculty by investigating the limiting behavior of the joint empirical
t deﬁned in (5). Our main contribution is to show that  as n → ∞  the sequence of
measure µn
t }n converges weakly to a deterministic measure µt. Note that
random probability measures {µn
the limiting value of Qn
t via the identity
t = Eµt[ξx].
limn→∞ Qn
Let Pt(x  ξ) be the density function of the limiting measure µt(ξ  x) at time t. We show that it is
characterized as the unique solution of the following nonlinear PDE:

t can then be computed from the limiting measure µn

[ξx] is challenging  as µn

t

(6)

(7)

(8)

(9)

(10)

∂x

R2

Qt =

∂

∂t Pt(ξ  x) = − ∂

∂x2 Pt(ξ  x)

2 Λ(Qt) ∂2

ξxPt(ξ  x) dx dξ

(cid:2)Γ(x  ξ  Qt  Rt)Pt(ξ  x)(cid:3) + 1
(cid:90)(cid:90)
(cid:90)(cid:90)
1 − Q2(cid:1)(cid:69)
(cid:112)
f 2(cid:0)cQ + e
2 Λ(Q)(cid:3) − ξG(Q) − τ φ(x)
Γ(x  ξ  Q  R) = x(cid:2)QG(Q) + τ R − 1
(cid:68)
(cid:69)
1 − Q2(cid:1)(cid:69)
(cid:112)
1 − Q2(cid:1)c
f(cid:48)(cid:0)cQ + e

Λ(Q) = τ 2(cid:68)
(cid:68)
f(cid:0)cQ + e

xφ(x)Pt(ξ  x) dx dξ

(cid:112)

Rt =

R2

G(Q) = −τ

with

where

where the two functions Λ(Q) and Γ(x  ξ  Q  R) are deﬁned as

(11)
In the above equations  e and c denote two independent random variables  with e ∼ N (0  1) and
c ∼ Pc  the non-Gaussian distribution of ck introduced in (2); the notation (cid:104)·(cid:105) denotes the expectation
over e and c; and f (·) and φ(·) are the two functions used in the online learning algorithm (2).
When φ(x) = 0 (and therefore Rt = 0)  we can derive a simple ODE for Qt from (6) and (7):

+ τ Q

.

d
dt

Qt = (Q2

t − 1)G(Qt) − 1
2

QtΛ(Qt).

Example 1 As a concrete example  we consider the case when ck is drawn from a symmetric
non-Gaussian distribution. Due to symmetry  E c3
k = m6. We use
f (x) = x3 in (2) to detect the feature vector ξ. Substituting this speciﬁc f (x) into (9) and (11)  we
obtain

k = 0. Write E c4

k = m4 and E c6

G(Q) = τ Q3(m4 − 3)

Λ(Q) = τ 2(cid:104)

15 + 15Q4(1 − Q2)(m4 − 3) + Q6(m6 − 15)

(cid:105)

and Γ(x  ξ  Q  R) can be computed by substituting (12) and (13) into (10). Moreover  for the case
φ(x) = 0  we derive a simple ODE for qt = Q2

(cid:104)

t as
t (1 − qt)(m4 − 3) + q3

15q2

t (m6 − 15) + 15

.

(14)

dqt
dt

= −2τtq2

t (1 − qt)(m4 − 3) − τ 2
t qt

Numerical veriﬁcations of the ODE results are shown in Figure 1(a). In our experiment  the ambient
dimension is set to n = 5000 and we plot the averaged results as well as error bars (corresponding to
one standard deviation) over 10 independent trials. Two different initial values of q0 = Q2
0 are used.
In both cases  the asymptotic theoretical predictions match the numerical results very well.
The ODE in (14) can be solved analytically. Next we brieﬂy discuss its stability. The right-hand side
of (14) is plotted in Figure 1(b) as a function of qt. It is clear that the ODE (14) always admits a

4

(12)

(13)

(cid:105)

(a)

(b)

Figure 1: (a) Comparison between the analytical prediction given by the ODE in (14) with numerical
simulations of the online ICA algorithm. We consider two different initial values for the algorithm.
The top one  which starts from a better initial guess  converges to an informative estimation  whereas
the bottom one  with a worse initial guess  converges to a non-informative solution. (b) The stability
of the ODE in (14). We draw g(q) = 1
dt for different value of τ = 0.02  0.04  0.06  0.08 from top
τ
to bottom.

dq

solution qt = 0  which corresponding to a trivial  non-informative solution. Moreover  this trivial
solution is always a stable ﬁxed point. When the stepsize τ > τc for some constant τc  qt = 0 is also
the unique stable ﬁxed point. When τ < τc however  two additional solutions of the ODE emerge.
One is a stable ﬁxed point denoted by q∗
s and the other is an unstable ﬁxed point denoted by q∗
u 
with q∗
s. Thus  in order to reach an informative solution  one must initialize the algorithm
u. This insight agrees with a previous stability analysis done in [26]  where the authors
with Q2
investigated the dynamics near qt = 0 via a small qt expansion.

u < q∗
0 > q∗

Example 2 In this experiment  we verify the accuracy of the asymptotic predictions given by the
√
PDE (6). The settings are similar to those in Example 1. In addition  we assume that the feature
√
vector ξ is sparse  consisting of ρn nonzero elements  each of which is equal to 1/
ρ. Figure 2
shows the asymptotic conditional density Pt(x|ξ) for ξ = 0 and ξ = 1/
ρ at two different times.
These theoretical predictions are obtained by solving the PDE (6) numerically. Also shown in the
ﬁgure are the empirical conditional densities associated with one realization of the ICA algorithm.
Again  we observe that the theoretical predictions and numerical results have excellent agreement.
To demonstrate the usefulness of the PDE analysis in providing detailed information about the
performance of the algorithm  we show in Figure 3 the performance of sparse support recovery using
a simple hard-thresholding scheme on the estimates provided by the algorithm. By changing the
threshold values  one can have trade-offs between the true positive and false positive rates. As we can
see from the ﬁgure  this precise trade-off can be accurately predicted by our PDE analysis.

4

Insights given by the PDE analysis

In this section  we present some insights that can be gained from our high-dimensional analysis. To
simplify the PDE in (6)  we can assume that the two functions Qt and Rt in (7) and (8) are given to
us in an oracle way. Under this assumption  the PDE (6) describes the limiting empirical measure of
the following stochastic process

(cid:113) Λ(Qk/n)

n wk i 

i = 1  2  . . . n

zk+1 i = zk i + 1

n Γ(zk i  ξi  Qk/n  Rk/n) +

(15)
where wk i is a sequence of independent standard Gaussian random variables. Unlike the original
online learning update equation (2) where different coordinates of xk are coupled  the above process
is uncoupled. Each component zk i for i = 1  2  . . .   n evolves independently when conditioned on
Qt and Rt. The continuous-time limit of (15) is described by a stochastic differential equation (SDE)

dZt = Γ(Zt  ξ  Qt  Rt) dt +(cid:112)Λ(Qt) dBt 

5

05010015020000.20.40.60.81ODESimulation00.51-0.500.5(a)

(b)

Figure 2: (a) A demonstration of the accuracy of our PDE analysis. See the discussions in Example
2 for details. (b) Effective 1-D cost functions.

Figure 3: Trade-offs between the true positive and false positive rates in sparse support recovery. In
our experiment  n = 104  and the sparsity level is set to ρ = 0.3. The theoretical results obtained by
our PDE analysis can accurately predict the actual performance at any run-time of the algorithm.

where Bt is the standard Brownian motion.
We next have a closer look at the equation (15). Given a scalar ξ  Qt and Rt  we can deﬁne a
time-varying 1-D regularized quadratic optimization problem minx∈R Et(x  ξ) with the effective
potential

2 dt(x − btξ)2 + τ Φ(x) 

(16)
where dt = QtG(Qt) − 1
2 Λ(Qt) + τ Rt   bt = G(Qt)/dt and Φ(x) is the regularization term
deﬁned in (4). Then  the stochastic process (15) can be viewed as a stochastic gradient descent

Et(x  ξ) = 1

6

-1012340246-1012340246-1012340246-1012340246-10123400.10.2-10123400.050.10.1500.20.40.60.8100.20.40.60.81(cid:113) Λ(Qk)

for solving this 1-D problem with a step-size equal to 1/n. One can verify that the exact gradient
of (16) is −Γ(x  ξ  Qt  Rt). The third term
n wk in (15) adds stochastic noise to the true
gradient. Interestingly  although the original optimization problem (3) is non-convex  its 1-D effective
optimization problem is always convex for convex regularizers Φ(x) (e.g.  Φ(x) = β |x|.) This
provides an intuitive explanation for the practical success of online ICA.
To visualize this 1-D effective optimization problem  we plot in Figure 2(b) the effective potential
Et(x  ξ) at t = 0 and t = 100  respectively. From Figure (2)  we can see that the L1 norm always
introduces a bias in the estimation for all non-zero ξi  as the minimum point in the effective 1-D
cost function is always shifted towards the origin. It is hopeful that the insights gained from the
1-D effective optimization problem can guide the design of a better regularization function Φ(x)
to achieve smaller estimation errors without sacriﬁcing the convergence speed. This may prove an
interesting line of future work.
This uncoupling phenomenon is a typical consequence of mean-ﬁeld dynamics  e.g.  the Sherrington-
Kirkpatrick model [27] in statistical physics. Similar phenomena are observed or proved in other high
dimensional algorithms especially those related to approximate message passing (AMP) [28–30].
However  for these algorithms using batch updating rules with the Onsager reaction term  the limiting
densities of iterands are Gaussian. Thus the evolution of such densities can be characterized by
tracking a few scalar parameters in discrete time. For our case  the limiting densities are typically
non-Gaussian and they cannot be parametrized by ﬁnitely many scalars. Thus the PDE limit (6) is
required.

Appendix: A Formal derivation of the PDE

(17)

n f ( 1√

n yT

(cid:101)∆k i =(cid:101)xk i − xk i = τk√
(cid:105)
(cid:105)
(cid:104)(cid:101)∆k i

and Ek

k i

In this appendix  we present a formal derivation of the PDE (6). We ﬁrst note that (xk  ξk)k with
ξk = ξ forms an exchangeable Markov chain on R2n driven by the random variable ck ∼ Pc and the
Gaussian random vector ak . The drift coefﬁcient Γ(x  ξ  Q  R) and the diffusion coefﬁcient Λ(Q)
in the PDE (6) are determined  respectively  by the conditional mean and variance of the increment
xk+1 i − xk i  conditioned upon the previous state vector xk and ξk.
Let the increment of the gradient-descent step in the learning rule (2) be
k xk)yk i − τk

where(cid:101)xk i is the ith component of the output(cid:101)xk. Let Ek denote the conditional expectation with

n φ(xk i)

respect to ck and ak given xk and ξk.
We ﬁrst compute Ek

(cid:104)(cid:101)∆2
k ck +(cid:101)ek i + 1√
(cid:0)aT
k ck +(cid:101)ek i up to the ﬁrst order and get
k xk − ak ixk i
(cid:104)
(cid:105)
(cid:105)
(cid:35)

(cid:104)(cid:101)∆k i
(cid:105)
n ξT xk and(cid:101)ek i = 1√
k ck +(cid:101)ek i + 1√
k ck +(cid:101)ek i)( 1√

(cid:1). We use the Taylor expansion of f around
(cid:105)
(cid:104)
deterministic quantity Qk. Moreover (cid:101)ek i and ak i are both zero-mean Gaussian with the covariance

Ek
= Ek
where δk i includes all higher order terms. As n → ∞  the random variable Qn

k ck +(cid:101)ek i)( 1√

. From (1) and (17) we have

(cid:105) − τk

where Qn
Qn

k converges to a

+ 1√

n xk iEk

n ak ixk i)( 1√

n ak ixk i)( 1√

n ξick + ak i)ak i

n ξick + ak i)

n ξick + ak i)

n ξick + ak i)

n φ(xk i) 

= τk√
n

Ek

f (Qn

(cid:104)
(cid:34)

Ek

k = 1

f (Qn

f (Qn

f(cid:48)(Qn

(cid:104)

n

+ δk i 

matrix

. We thus have

n ξk iQk
1 + O( 1
n )

1 − Q2
− 1√

k + O( 1
n ξk iQk

n ) − 1√
k ck +(cid:101)ek i)( 1√

f(cid:48)(Qn

(cid:104)

Ek

n ξick + ak i)ak i

=

(cid:28)

(cid:113)

1 − Q2

ke)

(cid:29)

+ o(1)

f(cid:48)(Qkc +

(cid:105)

7

(cid:104)
(cid:28)

and

Ek

=

f (Qn

(cid:113)

k ck +(cid:101)ek i)( 1√
n ξick + ak i)
(cid:34)(cid:28)
ke − ξi√
(cid:113)

1 − Q2

f (Qkc +

(cid:29)

n Qka)( 1√

n ξic + a)

(cid:28)

(cid:113)

(cid:29)(cid:35)

1 − Q2

= 1√

n ξi

cf (Qkc +

where in the last line  we use the Taylor expansion again to expand f around Qkc +(cid:112)1 − Q2

ke and
the bracket (cid:104)·(cid:105) denotes the average over two independent random variables c ∼ Pc and e ∼ N (0  1).
Thus  we have

n ) 

ke)

ke)

+ o( 1√

− Qk

f(cid:48)(Qkc +

1 − Q2

(cid:113)

(cid:29)

(cid:35)

−ξiG(Qk) + τkxk i

f(cid:48)(Qkc +

1 − Q2

ke)

− τkφ(xk i)

+ o( 1

n ) 

(cid:105)
(cid:29)

(cid:28)

(cid:28)

f 2(Qkc +

(cid:113)

1 − Q2

ke)

(cid:29)

+ o( 1

n ).

+ o( 1

n ) = τ 2

k
n

Next  we deal with the normalization step. Again  we use the Taylor expansion for the term

where the function G(Q) is deﬁned in (11).
To compute the (conditional) variance  we have

(cid:104)

f 2(Qn

(cid:105)
k +(cid:101)ek i)
(cid:17)(cid:13)(cid:13)(cid:13)(cid:13)−1

= τ 2

k
n

Ek

(cid:16)
xk + (cid:101)∆k

(cid:34)

=

1
n

Ek

k i

(cid:105)

Ek

(cid:104)(cid:101)∆k i
(cid:105)
(cid:104)(cid:101)∆2
(cid:13)(cid:13)(cid:13)(cid:13) 1
(cid:13)(cid:13)−1
(cid:104)(cid:101)∆2

Ek

=

n

i=1

k i

(cid:105)

(cid:13)(cid:13) 1
n(cid:101)xk

(cid:80)n

1
n

xk+1 = xk − 1

n xk

xT

up to the ﬁrst order  which yields

(cid:18)

(cid:19)
k (cid:101)∆k
2(cid:101)∆
k (cid:101)∆k + 1
k (cid:101)∆k ≈ 1

T

n

+ (cid:101)∆k + δk 
(cid:80)n

i=1 xk iEk

(cid:105)

(cid:104)(cid:101)∆k i

n(cid:101)∆

  1

k (cid:101)∆k ≈

T

where δk includes all higher order terms. Note that 1

k φ(x) = Rn

and 1
n xT
Ek

(cid:2)xk+1 i − xk i
(cid:104)(cid:0)xk+1 i − xk i
(cid:1)2(cid:105)

n xT
k → Rk  we have
(cid:105)

(cid:3) = 1
(cid:104)(cid:101)∆2

= Ek

k i

Ek

n Γ(xk i  ξi  Qk  Rk) + o( 1
n ).
Finally  the normalization step does not change the variance term  and thus

+ o( 1

n ) = 1

n Λ(Qk) + o( 1

n ).

The above computation of Ek(xk+1 i − xk i) and Ek(xk+1 i − xk i)2 connects the dynamics (2) to
(15). In fact  both (2) and (15) have the same limiting empirical measure described by (6).
A rigorous proof of our asymptotic result is built on the weak convergence approach for measure-
valued processes. Details will be presented in an upcoming paper. Here we only provide a sketch
of the general proof strategy: First  we prove the tightness of the measure-valued stochastic process
t )0≤t≤T on D([0  T ] M(R2))  where D denotes the space of càdlàg processes taking values from
(µn
the space of probability measures. This then implies that any sequence of the measure-valued process
t )0≤t≤T}n (indexed by n) must have a weakly converging subsequence. Second  we prove any
{(µn
converging (sub)sequence must converge weakly to a solution of the weak form of the PDE (6).
Third  we prove the uniqueness of the solution of the weak form of the PDE (6) by constructing a
contraction mapping. Combining these three statements  we can then conclude that any sequence
must converge to this unique solution.

Acknowledgments This work is supported by US Army Research Ofﬁce under contract W911NF-
16-1- 0265 and by the US National Science Foundation under grants CCF-1319140 and CCF-1718698.

References
[1] Simon Haykin and Bernard Widrow. Least-mean-square adaptive ﬁlters  volume 31. John Wiley & Sons 

2003.

8

[2] Erkki Oja and Juha Karhunen. On stochastic approximation of the eigenvectors and eigenvalues of the

expectation of a random matrix. J. Math. Anal. Appl.  106(1):69–84  1985.

[3] Michael Biehl and E Schlösser. The dynamics of on-line principal component analysis. J. Phys. A. Math.

Gen.  31(5):97–103  1998.

[4] Aapo Hyvärinen and Erkki Oja. One-unit learning rules for independent component analysis. In Adv.

Neural Inf. Process. Syst.  pages 480–486  1997.

[5] M Biehl. An Exactly Solvable Model of Unsupervised Learning. Europhys. Lett.  25(5):391–396  1994.

[6] Ohad Shamir and Tong Zhang. Stochastic gradient descent for non-smooth optimization: Convergence
results and optimal averaging schemes. In International Conference on Machine Learning  pages 71–79 
2013.

[7] Yann LeCun  Yoshua Bengio  and Geoffrey Hinton. Deep learning. Nature  521(7553):436–444  2015.

[8] Chi Jin  Rong Ge  Praneeth Netrapalli  Sham M Kakade  and Michael I Jordan. How to Escape Saddle

Points Efﬁciently. arXiv:1703.00887  2017.

[9] Ioannis Mitliagkas  Constantine Caramanis  and Prateek Jain. Memory Limited   Streaming PCA. In Adv.

Neural Inf. Process. Syst.  2013.

[10] Chris Junchi Li  Zhaoran Wang  and Han Liu. Online ICA: Understanding Global Dynamics of Nonconvex

Optimization via Diffusion Processes. In Adv. Neural Inf. Process. Syst.  pages 4961–4969  2016.

[11] Rong Ge  Furong Huang  Chi Jin  and Yang Yuan. Escaping From Saddle Points ? Online Stochastic

Gradient for Tensor Decomposition. In JMLR Work. Conf. Proc.  volume 40  pages 1–46  2015.

[12] Chuang Wang and Yue M. Lu. Online Learning for Sparse PCA in High Dimensions: Exact Dynamics and

Phase Transitions. In Inf. Theory Work. (ITW)  2016 IEEE  pages 186–190  2016.

[13] David Saad and Sara A Solla. Exact Solution for On-Line Learning in Multilayer Neural Networks. Phys.

Rev. Lett.  74(21):4337–4340  1995.

[14] David Saad and Magnus Rattray. Globally optimal parameters for online learning in multilayer neural

networks. Phys. Rev. Lett.  79(13):2578  1997.

[15] Magnus Rattray and Gleb Basalyga. Scaling laws and local minima in Hebbian ICA. In Adv. Neural Inf.

Process. Syst.  pages 495–502  2002.

[16] G. Basalyga and M. Rattray. Statistical dynamics of on-line independent component analysis. J. Mach.

Learn. Res.  4(7-8):1393–1410  2004.

[17] Henry P McKean. Propagation of chaos for a class of non-linear parabolic equations. Stoch. Differ.

Equations (Lecture Ser. Differ. Equations  Sess. 7  Cathol. Univ.  1967)  pages 41–57  1967.

[18] Henry P McKean. A class of Markov processes associated with nonlinear parabolic equations. Proc. Natl.

Acad. Sci.  56(6):1907–1911  1966.

[19] Sylvie Méléard and Sylvie Roelly-Coppoletta. A propagation of chaos result for a system of particles with

moderate interaction. Stoch. Process. their Appl.  26:317–332  1987.

[20] Alain-Sol Sznitman. Topics in progagation of chaos. In Paul-Louis Hennequin  editor  Ec. d’{\’e}t{\’e}

Probab. Saint-Flour XIX–1989  pages 165–251. Springer Berlin Heidelberg  1991.

[21] G. O. Roberts  A. Gelman  and W. R. Gilks. Weak convergence and optimal scaling of random walk

Metropolis algorithms. Ann. Appl. Probab.  7(1):110–120  1997.

[22] Praneeth Netrapalli  Prateek Jain  and Sujay Sanghavi. Phase retrieval using alternating minimization. In

Adv. Neural Inf. Process. Syst.  pages 2796–2804  2013.

[23] Emmanuel J. Candes  Xiaodong Li  and Mahdi Soltanolkotabi. Phase retrieval via Wirtinger ﬂow: Theory

and algorithms. IEEE Trans. Inf. Theory  61(4):1985–2007  2015.

[24] Huishuai Zhang  Yuejie Chi  and Yingbin Liang. Provable non-convex phase retrieval with outliers: Median

truncated wirtinger ﬂow. arXiv:1603.03805  2016.

[25] Xiaodong Li  Shuyang Ling  Thomas Strohmer  and Ke Wei. Rapid  robust  and reliable blind deconvolution

via nonconvex optimization. arXiv:1606.04933  2016.

9

[26] Magnus Rattray. Stochastic trapping in a solvable model of on-line independent component analysis.

Neural Comput.  14(2):17  2002.

[27] L. F. Cugliandolo and J. Kurchan. On the out-of-equilibrium relaxation of the Sherrington-Kirkpatrick

model. J. Phys. A. Math. Gen.  27(17):5749–5772  1994.

[28] Jean Barbier  Mohamad Dia  Nicolas Macris  Florent Krzakala  Thibault Lesieur  and Lenka Zdeborová.
Mutual information for symmetric rank-one matrix estimation: A proof of the replica formula. In Adv.
Neural Inf. Process. Syst.  pages 424–432  2016.

[29] Mohsen Bayati and Andrea Montanari. The dynamics of message passing on dense graphs  with applica-

tions to compressed sensing. IEEE Trans. Inf. Theory  57(2):764–785  2011.

[30] David Donoho and Andrea Montanari. High dimensional robust M-estimation: asymptotic variance via

approximate message passing. Probab. Theory Relat. Fields  166(3-4):935–969  2016.

10

,Chuang Wang
Yue Lu