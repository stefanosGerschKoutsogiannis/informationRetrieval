2008,The Mondrian Process,We describe a novel stochastic process that can be used to construct a multidimensional generalization of the stick-breaking process and which is related to the classic stick breaking process described by Sethuraman1994 in one dimension. We describe how the process can be applied to relational data modeling using the de Finetti representation for infinitely and partially exchangeable arrays.,The Mondrian Process

Daniel M. Roy

Massachusetts Institute of Technology

Yee Whye Teh

Gatsby Unit  University College London

droy@mit.edu

ywteh@gatsby.ucl.ac.uk

Abstract

We describe a novel class of distributions  called Mondrian processes  which
can be interpreted as probability distributions over kd-tree data structures. Mon-
drian processes are multidimensional generalizations of Poisson processes and this
connection allows us to construct multidimensional generalizations of the stick-
breaking process described by Sethuraman (1994)  recovering the Dirichlet pro-
cess in one dimension. After introducing the Aldous-Hoover representation for
jointly and separately exchangeable arrays  we show how the process can be used
as a nonparametric prior distribution in Bayesian models of relational data.

1 Introduction

Relational data are observations of relationships between sets of objects and it is therefore natural
to consider representing relations1 as arrays of random variables  e.g.  (Ri j)  where i and j index
objects xi ∈ X and yj ∈ Y . Nonrelational data sets (e.g.  observations about individual objects in
X) are simply one-dimensional arrays (Ri) from this viewpoint.
A common Bayesian approach in the one-dimensional setting is to assume there is cluster structure
and use a mixture model with a prior distribution over partitions of the objects in X. A similar
approach for relational data would na¨ıvely require a prior distribution on partitions of the product
space X × Y = {(x  y) | x ∈ X  y ∈ Y }. One choice is to treat each pair (x  y) atomically 
clustering the product space directly  e.g.  by placing a Chinese restaurant process (CRP) prior on
partitions of X × Y . An unsatisfactory implication of this choice is that the distribution on partitions
of (Ri j) is exchangeable  i.e.  invariant to swapping any two entries; this implies that the identity
of objects is ignored when forming the partition  violating common sense.
Stochastic block models2 place prior distributions on partitions of X and Y separately  which can be
interpreted as inducing a distribution on partitions of the product space by considering the product of
the partitions. By arranging the rows and columns of (Ri j) so that clustered objects have adjacent
indices  such partitions look like regular grids (Figure 1.1). An unfortunate side effect of this form
of prior is that the “resolution” needed to model ﬁne detail in one area of the array necessarily
causes other parts of the array to be dissected  even if the data suggest there is no such structure.
The annotated hierarchies described by Roy et al. (2007) generate random partitions which are not
constrained to be regular grids (Figure 1.2)  but the prior is inconsistent in light of missing data.
Motivated by the need for a consistent distribution on partitions of product spaces with more struc-
ture than classic block models  we deﬁne a class of nonparametric distributions we have named
Mondrian processes after Piet Mondrian and his abstract grid-based paintings. Mondrian processes
are random partitions on product spaces not constrained to be regular grids. Much like kd-trees 
Mondrian processes partition a space with nested  axis-aligned cuts; see Figure 1.3 for examples.
We begin by introducing the notion of partially exchangeable arrays by Aldous (1981) and Hoover
(1979)  a generalization of exchangeability on sequences appropriate for modeling relational data.

1We consider binary relations here but the ideas generalize easily to multidimensional relations.
2Holland et al. (1983) introduced stochastic block models. Recent variations (Kemp et al.  2006; Xu et al. 

2006; Roy et al.  2007) descend from Wasserman and Anderson (1987) and Nowicki and Snijders (2001).

1

We then deﬁne the Mondrian process  highlight a few of its elegant properties  and describe two
nonparametric models for relational data that use the Mondrian process as a prior on partitions.

2 Exchangeable Relational Data

The notion of exchangeability3  that the probability of a sequence of data items does not depend on
the ordering of the items  has played a central role in hierarchical Bayesian modeling (Bernardo and
Smith  1994). A classic result by de Finetti (1931)  later extended by Ryll-Nardzewski (1957)  states
that if x1  x2  ... is an exchangeable sequence  then there exists a random parameter θ such that the
sequence is conditionally iid given θ:

Z

nY

p(x1  ...  xn) =

pθ(θ)

px(xi|θ)dθ

(1)

i=1

That is  exchangeable sequences arise as a mixture of iid sequences  where the mixing distribution
is p(θ). The notion of exchangeability has been generalized to a wide variety of settings. In this
section we describe notions of exchangeability for relational data originally proposed by Aldous
(1981) and Hoover (1979) in the context of exchangeable arrays. Kallenberg (2005) signiﬁcantly
expanded on the concept  and Diaconis and Janson (2007) showed a strong correspondence between
such exchangeable relations and a notion of limits on graph structures (Lov´asz and Szegedy  2006).
Here we shall only consider binary relations—those involving pairs of objects. Generalizations to
relations with arbitrary arity can be gleaned from Kallenberg (2005). For i  j = 1  2  ... let Ri j
denote a relation between two objects xi ∈ X and yj ∈ Y from possibly distinct sets X and Y . We
say that R is separately exchangeable if its distribution is invariant to separate permutations on its
rows and columns. That is  for each n  m ≥ 1 and each pair of permutations π ∈ Sn and σ ∈ Sm 
(2)

p(R1:n 1:m) = p(Rπ(1:n) σ(1:m))

in MATLAB notation. Aldous (1981) and Hoover (1979) showed that separately exchangeable
relations can always be represented in the following way: each object i (and j) has a latent represen-
tation ξi (ηj) drawn iid from some distribution pξ (pη); independently let θ be an additional random
parameter. Then 

Z

pθ(θ)Y

pξ(ξi)Y

pη(ηj)Y

p(R1:n 1:m) =

pR(Ri j|θ  ξi  ηj)dθdξ1:ndη1:m

(3)

i

j

i j

As opposed to (1)  the variables ξi and ηj capture additional dependencies speciﬁc to each row and
column. If the two sets of objects are in fact the same  i.e. X = Y   then the relation R is a square
array. We say R is jointly exchangeable if it is invariant to jointly permuting rows and columns; that
is  for each n ≥ 1 and each permutation π ∈ Sn we have

p(R1:n 1:n) = p(Rπ(1:n) π(1:n))

(4)

Such jointly exchangeable relations also have a form similar to (3). The differences are that we have
one latent variable ξi for to each object xi  and that Ri j  Rj i need not be independent anymore:

p(R1:n 1:n) =

pR(Ri j  Rj i|θ  ξi  ξj)dθdξ1:n

(5)

Z

pθ(θ)Y

pξ(ξi)Y

i

i≤j

In (5) it is important that pR(s  t|θ  ξi  ξj) = pR(t  s|θ  ξj  ξi) to ensure joint exchangeability. The
ﬁrst impression from (5) is that joint exchangeability implies a more restricted functional form than
separately exchangeable (3). In fact  the reverse holds—(5) means that the latent representations
of row i and column i need not be independent  and that Ri j and Rj i need not be conditionally
independent given the row and column representations  while (3) assumes independence of both.
For example  a symmetric relation  i.e. Ri j = Rj i  can only be represented using (5).
The above Aldous-Hoover representation serves as the theoretical foundation for hierarchical
Bayesian modeling of exchangeable relational data  just as de Finetti’s representation serves as a
foundation for the modeling of exchangeable sequences. In Section 5  we cast the Inﬁnite Relational
Model (Kemp et al.  2006) and a model based on the Mondrian process into this representation.

2

Anowadya (IRM)

Anowadya

1.0

0.5

0.0

Figure 1: (1) Stochastic block models like the Inﬁnite Relational model (Kemp et al.  2006) induce regular par-
titions on the product space  introducing structure where the data do not support it. (2) Axis- aligned partitions 
like those produced by annotated hierarchies and the Mondrian process provide (a posteriori) resolution only
where it is needed. (3) Mondrian process on unit square  [0  1]2. (4) We can visualize the sequential hierarchical
process by spreading the cuts out over time. The third dimension is λ. (5) Mondrian process with beta L´evy
measure  µ(dx) = x−1dx on [0  1]2. (6) 10x zoom of 5 at origin. (7) Mondrian on [  1]3 with beta measure.

3 The Mondrian Process

The Mondrian process can be expressed as a recursive generative process that randomly makes axis-
aligned cuts  partitioning the underlying product space in a hierarchical fashion akin to decision
trees or kd- trees. The distinguishing feature of this recursive stochastic process is that it assigns
probabilities to the various events in such a way that it is consistent (in a sense we make precise
later). The implication of consistency is that we can extend the Mondrian process to inﬁnite spaces
and use it as a nonparametric prior for modeling exchangeable relational data.

3.1 The one dimensional case

The simplest space to introduce the Mondrian process is the unit interval [0  1]. Starting with an
initial “budget” λ  we make a sequence of cuts  splitting the interval into subintervals. Each cut
costs a random amount  eventually exhausting the budget and resulting in a ﬁnite partition m of the
unit interval. The cost  EI  to cut an interval I is exponentially distributed with inverse mean given
by the length of the interval. Therefore  the ﬁrst cut costs E[0 1] ∼ Exp(1). Let λ0 = λ − E[0 1].
If λ0 < 0  we make no cuts and the process returns the trivial partition m = {[0  1]}. Otherwise 
we make a cut uniformly at random  splitting the unit interval into two subintervals A and B. The
process recurses independently on A and B  with independent budgets λ0  producing partitions mA
and mB  which are then combined into a partition m = mA
The resulting cuts can be shown to be a Poisson (point) process. Unlike the standard description of
the Poisson process  the cuts in this “break and branch” process are organized in a hierarchy. As the
Poisson process is a fundamental building block for random measures such as the Dirichlet process
(DP)  we will later exploit this relationship to build various multidimensional generalizations.

S mB of [0  1].

3.2 Generalizations to higher dimensions and trees
We begin in two dimensions by describing the generative process for a Mondrian process m ∼
MP(λ  (a  A)  (b  B)) on the rectangle (a  A)×(b  B). Again  let λ0 = λ−E  where E ∼ Exp(A−
a+B−b) is drawn from an exponential distribution with rate the sum of the interval lengths. If λ0 <
0  the process halts  and returns the trivial partition {(a  A) × (b  B)}. Otherwise  an axis- aligned
cut is made uniformly at random along the combined lengths of (a  A) and (b  B); that is  the cut
lies along a particular dimension with probability proportional to its length  and is drawn uniformly
within that interval. W.l.o.g.  a cut x ∈ (a  A) splits the interval into (a  x) and (x  A). The process
then recurses  generating independent Mondrian processes with diminished rate parameter λ0 on
both sides of the cut: m< ∼ MP(λ0  (a  x)  (b  B)) and m> ∼ MP(λ0  (x  A)  (b  B)). The partition
on (a  A)×(b  B) is then m<
the number of cuts  with the process more likely to cut rectangles with large perimeters.
The process can be generalized in several ways.
In higher dimensions  the cost E to make an
additional cut is exponentially distributed with rate given by the sum over all dimensions of the
interval lengths. Similarly  the cut point is chosen uniformly at random from all intervals  splitting
only that interval in the recursion. Like non- homogeneous Poisson processes  the cut point need not

S m>. Like the one- dimensional special case  the λ parameter controls

3In this paper we shall always mean inﬁnite exchangeability when we state exchangeability.

3

be chosen uniformly at random  but can instead be chosen according to a non-atomic rate measure
µd associated with each dimension. In this case  lengths (A − a) become measures µ1(a  A).
The process can also be generalized beyond products of intervals. The key property of intervals
that the Mondrian process relies upon is that any point cuts the space into one-dimensional  simply-
connected pieces. Trees also have this property: a cut along an edge splits a tree into two trees.
We denote a Mondrian process m with rate λ on a product of one-dimensional  simply-connected
domains Θ1×···×ΘD by m ∼ MP(λ  Θ1  ...  ΘD)  with the dependence on µ1  ...  µD left implicit.
A description of the recursive generative model for the conditional Mondrian (see Section 4) is given
in Algorithm 1.

4 Properties of the Mondrian Process

This section describes a number of interesting properties of the Mondrian process. The most im-
portant properties of the Mondrian is its self-consistency. Instead of representing a draw from a
Mondrian as an unstructured partition of Θ1 × ···× ΘD  we will represent the whole history of the
generative process. Thus a draw from the Mondrian process is either a trivial partition or a tuple
m = hd  x  λ0  m<  m>i  representing a cut at x along the d’th dimension Θd  with nested Mondri-
ans m< and m> on either side of the cut. Therefore  m is itself a tree of axis-aligned cuts (a kd-tree
data structure)  with the leaves of the tree forming the partition of the original product space.
Conditional Independencies: The generative process for the Mondrian produces a tree of cuts 
where each subtree is itself a draw from a Mondrian. The tree structure precisely reﬂects the condi-
tional independencies of the Mondrian; e.g.  the two subtrees m< and m> are conditional indepen-
dent given λ0  d and x at the ﬁrst cut.
Consistency: The Mondrian process satisﬁes an important self-consistency property: given a draw
from a Mondrian on some domain  the partition on any subdomain has the same distribution as if
we sampled a Mondrian process directly on that subdomain.
More precisely  let m ∼ MP(λ  Θ1  ...  ΘD) and  for each dimension d  let Φd be a connected
subdomain of Θd. The restriction ρ(m  Φ1  ...  ΦD) of m to Φ1 × ··· × ΦD is the subtree of
cuts within Φ1 × ··· × ΦD. We deﬁne restrictions inductively: If there are no cuts in m  i.e.
m = Θ1×···×ΘD  then ρ(m  Φ1  ...  ΦD) is simply Φ1×···×ΦD. Otherwise m = hd  x  λ  m<  m>i
for some d  x  and λ  and where m< and m> are the two subtrees. Let Θ<x
be the d’th
domains of m< and m> respectively. If x 6∈ Φd this implies that Φd must be on exactly one side of x
(because Φd and Θd are connected). W.l.o.g.  assume Φd ⊂ Θ<x
d . In this case  ρ(m  Φ1  ...  ΦD) =
ρ(m<  Φ1  ...  ΦD).
overlap Φd and ρ(m  Φ1  ...  ΦD) =
hd  x  λ  ρ(m<  Φ1  ...  Φd ∩ Θ<x
By integrating out the variables on nodes not contained in the restriction  it can be shown that the
restriction ρ(m  Φ1  ...  ΦD) is itself distributed according to a Mondrian MP(λ  Φ1  ...  ΦD).
So far the construction of the Mondrian process assumes that each domain Θd has ﬁnite measure. A
consequence of this consistency property is that we can now use the Daniell-Kolmogorov extension
theorem to extend the Mondrian process to σ-ﬁnite domains (those that can be written as a countable
union of ﬁnite domains). For example  from a Mondrian process on products of intervals  we can
construct a Mondrian process on all of RD. Note that if the domains have inﬁnite measure  the tree
of cuts will be inﬁnitely deep with no root and inﬁnitely many leaves (being the inﬁnite partition of
the product space). However the restriction of the tree to any given ﬁnite subdomains will be ﬁnite
with a root (with probability one).
Mondrian Slices: One interesting speciﬁc case of consistency under restriction is worth mentioning.
Suppose that our subdomains are Φ1 = {y} and Φd = Θd for d ≥ 2. That is  we consider the
restriction of the Mondrian to a slice of the space where the ﬁrst coordinate takes on value y. The
consistency property shows that the restriction ρ = ρ(m  Φ1  ...  ΦD) onto these subdomains is
distributed according to a Mondrian as well. But since µ1 is non-atomic  µ1({y}) = 0 thus ρ will
not have any cuts in the ﬁrst domain (with probability 1). That is  we can interpret ρ as a draw from
a D − 1 dimensional Mondrian with domains Θ2  ...  ΘD. This is true of any lower dimensional
slice of the Mondrian. One particular extreme is that since a one dimensional Mondrian is simply the

d   ...ΦD)  ρ(m>  Φ1  ...  Φd ∩ Θ>x

If x ∈ Φd then both Θ<x

d   ...ΦD)i.

d   Θ>x

d

and Θ>x

d

d

4

Figure 2: Modeling a Mondrian with a Mondrian: A posterior sample given relational data created from an
actual Mondrian painting. (from left) (1) Composition with Large Blue Plane  Red  Black  Yellow  and Gray
(1921). (2) Raw relational data  randomly shufﬂed. These synthetic data were generated by ﬁtting a regular
6 × 7 point array over the painting (6 row objects  7 column objects)  and using the blocks in the painting
to determine the block structure of these 42 relations. We then sampled 18 relational arrays with this block
structure. (3) Posterior sample of Mondrian process on unit square. The colors are for visual effect only as the
partitions are contiguous rectangles. The small black dots are the embedding of the pairs (ξi  ηj) into the unit
square. Each point represents a relation Ri j; each row of points are the relations (Ri ·) for an object ξi  and
similarly for columns. Relations in the same block are clustered together. (4) Induced partition on the (discrete)
relational array  matching the painting. (5) Partitioned and permuted relational data showing block structure.

be computed easily  and amounts to drawing an exponential sample E ∼ Exp(P

break-and-branch generative process for a Poisson process  any one dimensional slice of a Mondrian
gives a Poisson point process.
Conditional Mondrians: Using the consistency property  we can derive the conditional distribution
of a Mondrian m with rate λ on Θ1 × ···× ΘD given its restriction ρ = ρ(m  Φ1  ...  ΦD). To do
so  we have to consider three possibilities: when m contains no cuts  when the ﬁrst cut of m is in
ρ  and when the ﬁrst cut of m is above ρ. Fortunately the probabilities of each of these events can
d µd(Θd \ Φd)) 
and comparing it against the diminished rate after the ﬁrst cut in ρ. Pseudocode for generating from
a conditional Mondrian is given in Algorithm 1. When every domain of ρ has zero measure  i.e. 
µd(Φd) = 0 for all d  the conditional Mondrian reduces to an unconditional Mondrian.
Algorithm 1 Conditional Mondrian m ∼ MP(λ  Θ1  ...  ΘD | ρ)

ρ = φd = ∅ is unconditioned

1. let λ0 ← λ − E where E ∼ Exp(PD

d=1 µd(Θd \ Φd)).
2. if ρ has no cuts then λ00 ← 0 else hd0  x0  λ00  ρ<  ρ>i ← ρ.
3. if λ0 < λ00 then take root form of ρ
if ρ has no cut then
4.
return m ← Θ1 × ···× ΘD.
5.
else (d0  x0) is the ﬁrst cut in m
6.
return m ← hd0  x0  λ00  MP(λ00  Θ1  . . .   Θ<x0
7.
d0
MP(λ00  Θ1  . . .   Θ>x0
d0

8. else λ00 < λ0 and there is a cut in m above ρ
9.
10. return m ← hd  x  λ0  MP(λ0  Θ1  . . .   Θ<x
MP(λ0  Θ1  . . .   Θ>x

draw a cut (d  x) outside ρ  i.e.  p(d) ∝ µd(Θd \ Φd)  x|d ∼
d   . . .   ΘD | ρ) 
d   . . .   ΘD)i.

without loss of generality suppose Φd ⊂ Θ<x

d

  . . .   ΘD | ρ<) 
  . . .   ΘD | ρ>)i.

µd

µd(Θd\Φd)

Partition Structure: The Mondrian is simple enough that we can characterize a number of its other
properties. As an example  the expected number of slices along each dimension of (0  A)×(0  B) is
λA and λB  while the expected total number of partitions is (1 + λA)(1 + λB). Interestingly  this is
also the expected number of partitions in a biclustering model where we ﬁrst have two independent
Poisson processes with rate λ partition (0  A) and (0  B)  and then form the product partition of
(0  A) × (0  B).

5

0.1.510.513562146471325posterior sample of Mondrian on0 12

crude materials

basic goods

foodanimals

mineralsfuels

diplomats

UK
JAPAN
SPAIN
USA
YUGOS
SWITZ
FINLA
ISRAE
EGYPT
ALGER
CZECH
SYRIA
PAKIS
NEWZE
THAIL
INDON
CHINA
ARGEN
ECUAD
MADAG
BRAZL
ETHIO
HONDU
LIBER

crude materials

basic goods

foodanimals

mineralsfuels

diplomats

I

A
R
Y
S

G
A
D
A
M

I

R
E
B
L

O
H
T
E

I

U
D
N
O
H

N
A
P
A
J

K
U

I

I

Z
T
W
S

N
A
P
S

A
N
H
C

I

E
Z
W
E
N

T
P
Y
G
E

I

L
A
H
T

N
E
G
R
A

H
C
E
Z
C

I

A
L
N
F

S
K
A
P

I

L
Z
A
R
B

S
O
G
U
Y

N
O
D
N

I

A
S
U

E
A
R
S

I

D
A
U
C
E

R
E
G
L
A

Figure 3: Trade and Diplomacy relations between 24 countries in 1984. Rij = 1 (black squares) implies
that country i imports R from country j. The colors are for visual effect only as the partitions are contiguous
rectangles.

X

X

X

X

X

5

10

3

1

4

9

2

6

7

8

X

Learning the latent tree

    [Kingman 82]

2
4
3
1

2
4
3
1

2
4
3
1

1 3 4 5 2

2
4
3
1

2
4
3
1

2
4
3
1

1 3 4 5 2

2
4
3
1

2
4
3
1

2
4
3
1

1 3 4 5 2

Janitor A

Janitor B

Janitor C

Student A

Student B

Student C

Prof. C

Prof. B

Prof. A

Janitor A

Janitor B

Janitor C

Prof. A

Prof. B

Prof. C

Student A

Student B

Student C

Janitor A

Janitor B

Janitor C

Student A

Student B

Student C

Prof. C

Prof. B

Prof. A

A

r
o
t
i
n
a
J

B

r
o
t
i
n
a
J

C

r
o
t
i
n
a
J

A

.
f
o
r
P

B

.
f
o
r
P

C

.
f
o
r
P

A

t
n
e
d
u
t

S

B

t
n
e
d
u
t
S

C

t
n
e
d
u
t
S

A

r
o
t
i
n
a
J

B

r
o
t
i
n
a
J

C

r
o
t
i
n
a
J

A

.
f
o
r
P

B

.
f
o
r
P

C

.
f
o
r
P

A

t
n
e
d
u
t

S

B

t
n
e
d
u
t
S

C

t
n
e
d
u
t
S

A

r
o
t
i
n
a
J

B

r
o
t
i
n
a
J

C

r
o
t
i
n
a
J

A

.
f
o
r
P

B

.
f
o
r
P

C

.
f
o
r
P

A

t
n
e
d
u
t

S

B

t
n
e
d
u
t
S

C

t
n
e
d
u
t
S

Janitor A

Janitor B

Janitor C

Prof. A

Prof. B

Prof. C

Student A

Student B

Student C

Janitor A

Janitor B

Janitor C

Prof. A

Prof. B

Prof. C

Student A

Student B

Student C

Friends?

Works With?

Gives orders to?

J
a
n
i
t
o
r

A

J
a
n
i
t
o
r

B

J
a
n
i
t
o
r

C

S
t
u
d
e
n
t

A

S
t
u
d
e
n
t

B

S
t
u
d
e
n
t

C

P
r
o
f
.

C

P
r
o
f
.

B

P
r
o
f
.

A

J
a
n
i
t
o
r

A

J
a
n
i
t
o
r

B

J
a
n
i
t
o
r

C

S
t
u
d
e
n
t

A

S
t
u
d
e
n
t

B

S
t
u
d
e
n
t

C

P
r
o
f
.

C

P
r
o
f
.

B

P
r
o
f
.

A

J
a
n
i
t
o
r

A

J
a
n
i
t
o
r

B

J
a
n
i
t
o
r

C

S
t
u
d
e
n
t

A

S
t
u
d
e
n
t

B

S
t
u
d
e
n
t

C

P
r
o
f
.

C

P
r
o
f
.

B

P
r
o
f
.

A

Janitor A

Janitor B

Janitor C

Student A

Student B

Student C

Prof. C

Prof. B

Prof. A

Janitor A

Janitor B

Janitor C

Student A

Student B

Student C

Prof. C

Prof. B

Prof. A

Figure 4: (clockwise from bottom left) (1) Nine samples from the Mondrian process on Kingman coalescents
with rate λ = 0.25  0.5  and 1  respectively. As the rate increases  partitions become ﬁner. Note that partitions
are not necessarily contiguous; we use color to identify partitions. The partition structure is related to the
annotated hierarchies model (Roy et al.  2007).
(2) Kingman (1982a b) describes the relationship between
random trees and the DP  which we exploit to deﬁne a nonparametric  hierarchical block model. (3) A sequence
of cuts; each cut separates a subtree. (4) Posterior trees and Mondrian processes on a synthetic social network.

5 Relational Modeling

To illustrate how the Mondrian process can be used to model relational data  we describe two non-
parametric block models for exchangeable relations. While we will only consider binary data and
assume that each block is conditionally iid  the ideas can be extended to many likelihood models.
Recall the Aldous- Hoover representation (θ  ξi  ηj  pR) for exchangeable arrays. Using a Mondrian
process with beta L´evy measure µ(dx) =αx −1dx  we ﬁrst sample a random partition of the unit
square into blocks and assign each block a probability:

M ∼ MP(λ  [0  1]  [0  1])

φS | M ∼ Beta(a0  a1)  ∀S ∈ M.

(6)
(7)
The pair (M  φ) plays the role of θ in the Aldous- Hoover representation. We next sample row and
column representations (ξi and ηj  respectively)  which have a geometrical interpretation as x y-
coordinates (ξi  ηj) in the unit square:

slices up unit square into blocks
each block S gets a probability φS

ξi ∼ U[0  1]  i ∈ {1  . . .   n}
ηj ∼ U[0  1]  j ∈ {1  . . .   n}.

shared x coordinate for each row
shared y coordinate for each column

(8)
(9)

Let Sij be the block S ∈ M such that (ξi  ηj) ∈ S. We ﬁnally sample the array R of relations:

Rij | ξ  η  φ  M ∼ Bernoulli(φSij )  i  j ∈ {1  . . .   n}.

Rij is true w.p. φSij

(10)

6

This model clusters relations together whose (ξi  ηj) pairs fall in the same blocks in the Mondrian
partition and models each cluster with a beta-binomial likelihood model. By mirroring the Aldous-
Hoover representation  we guarantee that R is exchangeable and that there is no order dependence.
This model is closely related to the IRM (Kemp et al.  2006) and IHRM (Xu et al.  2006)  where
rows and columns are ﬁrst clustered using a CRP prior  then each relation Rij is conditionally
independent from others given the clusters that row i and column j belong to. In particular  if we
replace Eq. (6) with

M ∼ MP(λ  [0  1]) × MP(λ  [0  1]) 

product of partitions of unit intervals

(11)
then we recover the same marginal distribution over relations as the IRM/IHRM. To see this  recall
that a Mondrian process in one-dimension produces a partition whose cut points follow a Poisson
point process. Teh et al. (2007) show that the stick lengths (i.e.  partitions) induced by a Poisson
point process on [0  1] with the beta L´evy measure have the same distribution as those in the stick-
breaking construction of the DP. Therefore  (11) is the product of two stick-breaking priors.
In
comparison  any one dimensional slice of (6)  e.g.  each column or row of the relation  is marginally
distributed as a DP  but is more ﬂexible than the product of one-dimensional Mondrian processes.
We can also construct an exchangeable variant of the Annotated Hierarchies model (a hierarchical
block model) by moving from the unit square to a product of random trees drawn from Kingman’s
coalescent prior (Kingman  1982a). Let µd be Lebesgue measure.

Td ∼ KC(λ) ∀d ∈ {1  . . .   D}

M | T ∼ MP(2α  T1  . . .   TD)
φS | M ∼ Beta(a0  a1)  ∀S ∈ M.

for each dimension  sample a tree
partition the cross product of trees
each block S gets a probability φS

(12)
(13)
(14)

Let Sij be the subset S ∈ M where leaves (i  j) fall in S. Then

Rij | φ  M ∼ Bernoulli(φSij )  i  j ∈ {1  . . .   n}.

(15)
Figure 4 shows some samples from this prior. Again  this model is related to the DP. Kingman shows
that the partition on the leaves of a coalescent tree when its edges are cut by a Poisson point process
is the same as that of a DP (Figure 4). Therefore  the partition structure along every row and column
is marginally the same as a DP. Both the unit square and product of random trees models give DP
distributed partitions on each row and column  but they have different inductive biases.

Rij is true w.p. φSij

6 Experiments

The ﬁrst data set was synthetically created using an actual painting by Piet Mondrian  whose grid-
based paintings were the inspiration for the name of this process. Using the model deﬁned by (10)
and a uniform rate measure  we performed a Markov chain Monte Carlo (MCMC) simulation of
the posterior distribution over the Mondrian  ξ’s  η’s  and hyperparameters. We employed a number
of Metropolis-Hastings (MH) proposals that rotated  scaled  ﬂipped  and resampled portions of the
Mondrian. It can be shown that the conditional distribution of each ξi and ηj is piecewise constant;
given the conjugacy of the beta-binomial  we can Gibbs sample the ξ’s and η’s. Figure 2 shows a
sample after 1500 iterations (starting from a random initialization) where the partition on the array
is exactly recovered. This was a typical attractor state for random initializations. While the data
are sufﬁcient to recover the partition on the array  they are not sufﬁcient to recover the underlying
Mondrian process. It is an open question as to its identiﬁability in the limit of inﬁnite data.
We next analyzed the classic Countries data set from the network analysis literature (Wasserman
and Faust  1994)  which reports trade in 1984 between 24 countries in food and live animals; crude
materials; minerals and fuels; basic manufactured goods; and exchange of diplomats. We applied
the model deﬁned by (10). Figure 3 illustrates the type of structure the model uncovers during
MCMC simulation; it has recognized several salient groups of countries acting in blocs; e.g.  Japan 
the UK  Switzerland  Spain and China export to nearly all countries  although China behaves more
like the other Paciﬁc Rim countries as an importer. The diplomats relation is nearly symmetric  but
the model does not represent symmetry explicitly and must redundantly learn the entire relation.
Reﬂecting the Mondrian about the line y = x is one way to enforce symmetry in the partition.
In our ﬁnal experiment  we analyzed a synthetic social network consisting of nine university em-
ployees: 3 janitors  3 professors and 3 students. Given three relations (friends  works-with  and

7

gives-orders-to)  the maximum a posteriori Mondrian process partitions the relations into homoge-
neous blocks. Tree structures around the MAP clustered the janitors  professors and students into
three close-knit groups  and preferred to put the janitors and students more closely together in the
tree. Inference in this model is particularly challenging given the large space of trees and partitions.

7 Discussion

While the Mondrian process has many elegant properties  much more work is required to determine
its usefulness for relational modeling. Just as effective inference procedures preceded the popularity
of the Dirichlet process  a similar leap in inference sophistication will be necessary to assess the
Mondrian process on large data sets. We are currently investigating improved MCMC sampling
schemes for the Mondrian process  as well as working to develop a combinatorial representation of
the distribution on partitions induced by the Mondrian process. Such a representation is of prac-
tical interest (possibly leading to improved inference schemes) and of theoretical interest  being a
multidimensional generalization of Chinese restaurant processes.
The axis-aligned partitions of [0  1]n produced by the Mondrian process have been studied exten-
sively in combinatorics and computational geometry  where they are known as guillotine partitions.
Guillotine partitions have wide ranging applications including circuit design  approximation algo-
rithms and computer graphics. However  the question of consistent stochastic processes over guillo-
tine partitions  i.e. the question addressed here  has not  to our knowledge  been studied before.
At a high level  we believe that developing nonparametric priors on complex data structures from
computer science may successfully bridge the gap between old-fashioned Artiﬁcial Intelligence and
modern statistical approaches. Developing representations for these typically recursive structures
will require us to go beyond graphical models; stochastic lambda calculus is an appealing option.
References
D. J. Aldous. Representations for Partially Exchangeable Arrays of Random Variables. Journal of Multivariate

Analysis  11:581–598  1981.

J. M. Bernardo and A. F. M. Smith. Bayesian theory. John Wiley & Sons  1994.
B. de Finetti. Funzione caratteristica di un fenomeno aleatorio. Atti della R. Academia Nazionale dei Lincei 

Serie 6. Memorie  Classe di Scienze Fisiche  Mathematice e Naturale  4:251299  1931.

P. Diaconis and S. Janson. Graph limits and exchangeable random graphs. arXiv:0712.2749v1  2007.
P. W. Holland  K. B. Laskey  and S. Leinhardt. Stochastic blockmodels: First steps. Social Networks  5(2):109

– 137  1983.

D. Hoover. Relations on probability spaces and arrays of random variables. Technical report  Preprint  Institute

for Advanced Study  Princeton  NJ  1979.

O. Kallenberg. Probabilistic Symmetries and Invariance Principles. Springer  2005.
C. Kemp  J. Tenenbaum  T. Grifﬁths  T. Yamada  and N. Ueda. Learning systems of concepts with an inﬁnite

relational model. In Proceedings of the 21st National Conference on Artiﬁcial Intelligence  2006.

J. F. C. Kingman. On the genealogy of large populations. Journal of Applied Probability  19:27–43  1982a.
J. F. C. Kingman. The coalescent. Stochastic Processes and their Applications  13:235–248  1982b.
L. Lov´asz and B. Szegedy. Limits of dense graph sequences. J. Comb. Theory B  96:933957  2006.
K. Nowicki and T. A. B. Snijders. Estimation and prediction for stochastic blockstructures. Journal of the

American Statistical Association  96:1077–1087(11)  2001.

D. M. Roy  C. Kemp  V. Mansinghka  and J. B. Tenenbaum. Learning annotated hierarchies from relational

data. In Advances in Neural Information Processing Systems 19  2007.

C. Ryll-Nardzewski. On stationary sequences of random variables and the de Finetti’s equivalence. Colloq.

Math.  4:149–156  1957.

J. Sethuraman. A Constructive deﬁnition of Dirichlet priors. Statistica Sinica  4:639–650  1994.
Y. W. Teh  D. G¨or¨ur  and Z. Ghahramani. Stick-breaking construction for the Indian buffet process. In Pro-

ceedings of the International Conference on Artiﬁcial Intelligence and Statistics  volume 11  2007.

S. Wasserman and C. Anderson. Stochastic a posteriori blockmodels: Construction and assessment. Social

Networks  9(1):1 – 36  1987.

S. Wasserman and K. Faust. Social Network Analysis: Methods and Applications  pages 64–65. Cambridge

University Press  1994.

Z. Xu  V. Tresp  K. Yu  and H.-P. Kriegel. Inﬁnite Hidden Relational Models. In Proceedings of the 22nd

Conference on Uncertainty in Artiﬁcial Intelligence  2006.

8

,Stephan Zheng
Yisong Yue
Jennifer Hobbs