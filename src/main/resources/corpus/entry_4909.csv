2013,Scoring Workers in Crowdsourcing: How Many Control Questions are Enough?,We study the problem of estimating continuous quantities  such as prices  probabilities  and point spreads  using a crowdsourcing approach.  A challenging aspect of combining the crowd's answers is that workers' reliabilities and biases are usually unknown and highly diverse.  Control items with known answers can be used to evaluate workers' performance  and hence improve the combined results on the target items with unknown answers.  This raises the problem of how many control items to use when the total number of items each workers can answer is limited: more control items evaluates the workers better  but leaves fewer resources for the target items that are of direct interest  and vice versa. We give theoretical results for this problem under different scenarios  and provide a simple rule of thumb for crowdsourcing practitioners.  As a byproduct  we also provide theoretical analysis of the accuracy of different consensus methods.,Scoring Workers in Crowdsourcing: How Many

Control Questions are Enough?

Qiang Liu

Dept. of Computer Science
Univ. of California  Irvine

qliu1@uci.edu

Mark Steyvers

Dept. of Cognitive Sciences
Univ. of California  Irvine

mark.steyvers@uci.edu

Alexander Ihler

Dept. of Computer Science
Univ. of California  Irvine
ihler@ics.uci.edu

Abstract

We study the problem of estimating continuous quantities  such as prices  proba-
bilities  and point spreads  using a crowdsourcing approach. A challenging aspect
of combining the crowd’s answers is that workers’ reliabilities and biases are usu-
ally unknown and highly diverse. Control items with known answers can be used
to evaluate workers’ performance  and hence improve the combined results on the
target items with unknown answers. This raises the problem of how many control
items to use when the total number of items each workers can answer is limited:
more control items evaluates the workers better  but leaves fewer resources for the
target items that are of direct interest  and vice versa. We give theoretical results
for this problem under different scenarios  and provide a simple rule of thumb for
crowdsourcing practitioners. As a byproduct  we also provide theoretical analysis
of the accuracy of different consensus methods.

1

Introduction

The recent rise of crowdsourcing has provided a fast and inexpensive way to collect human knowl-
edge and intelligence  as illustrated by human intelligence marketplaces such as Amazon Mechan-
ical Turk  games with purpose like ESP  reCAPTCHA  and crowd-based forecasting for politics
and sports. One of the philosophies behind these successes is the wisdom of crowds phenomenon:
properly combining a group of untrained people can be better than the average performance of the
individuals  and even as good as the experts in many application domains (e.g.  Surowiecki  2005 
Sheng et al.  2008). Unfortunately  it is not always obvious how best to combine the crowd  because
the (often anonymous) workers have unknown and diverse levels of expertise  and potentially sys-
tematic biases across the crowd. Na¨ıve consensus methods which simply take uniform averages or
the majority answer of the workers have been known to perform poorly. This raises the problem of
scoring the workers  that is  estimating their expertise  bias and any other associated parameters  in
order to combine their answers more effectively.

One direct way to address this problem is to score workers using their past performance on similar
problems. However  this is not always practical  since historical records are hard to maintain for
anonymous workers  and their past tasks may be very different from the current one. An alternative
is the idea behind reCAPTCHA: “seed” some control items with known answers into the assigned
tasks (without telling workers which are control items)  score the workers using these control items 
and weight their answers accordingly on the unknown target items. Similar ideas have been widely
used in existing crowdsourcing systems. CrowdFlower  for example  provides interfaces and tools
to allow requesters to explicitly specify and analyze a set of control items (sometimes called “gold
data”). The reCAPTCHA example is a particularly simple case  where workers answer exactly one
control and one target item. However  in general crowdsourcing  the workers may answer hundreds
of questions  raising the question of how many control items should be used. There is a clear trade-
off: having workers answer more control items gives better estimates of their performance and any

1

potential systematic bias  but leaves fewer resources for the target items that are of direct interest.
However  using few control items gives poor estimates of workers’ performance and their biases 
also leading to bad results. A deep understanding of the value of control items may provide useful
guidance for crowdsourcing practitioners.

On the other hand  a line of research has studied more advanced consensus methods that are able
to simultaneously estimate the workers’ performance and items’ answers without any ground truth
on the items  by building joint statistical models of the workers and labels (e.g.  Dawid and Skene 
1979  Whitehill et al.  2009  Karger et al.  2011  Liu et al.  2012  Zhou et al.  2012). The basic
idea is to score the workers by their agreement with other workers  assuming that the majority of
workers are correct. Perhaps surprisingly  the worker reliabilities estimated by these “unsupervised”
consensus methods can be almost as good as those estimated when the true labels of all the items are
known  and are much better than self-evaluated worker reliability (Romney et al.  1987  Lee et al. 
2012). Control items can also be incorporated into these methods: but how much can we expect
them to improve results  or does an “unsupervised” method sufﬁce?

The goal of this paper is to study the value of control items  and provide practical guidance on how
many control items are enough under different scenarios. We give both theoretical and empirical
results for this problem  and provide some rules of thumbs that that are easy to use in practice.
We develop our theory on a class of Gaussian models for estimating continuous quantities  such as
forecasting probabilities and point spreads in sports games  and show how it extends to more general
models. As a byproduct  we also provide analytic results of the accuracy of different consensus
algorithms.
Important practical issues such as the impact of model misspeciﬁcation  systematic
biases and heteroscedasticity are also highlighted on real datasets.

2 Background

j that characterizes their expertise  bias  any other relevant features. We denote

continuous variables in this paper. Denote by nt the number of target items and m the workers.
j ) the set of target (and control) items
Let ∂i be the set of workers assigned to item i  and ∂t
labeled by worker j. The assignment relationship between the workers and the target items can

Assume there is a setT of target items  associated with a set of labels µT ∶={µi∶ i∈T} whose true
values µ∗T we want to estimate. In addition  we have a setC of control (or training) items whose true
labels µ∗C∶={µ∗
i∶ i∈C} are known. We denote the set of workers byW; each worker j is associated
with a parameter ν∗
j∶ j ∈W}. Both µ and ν are assumed to be
the complete vector of worker parameters by ν ∶={ν∗
be represented by a bipartite graphGt=(T  W Et)  where there is an edge(ij)∈Et iff item i is
j) be the number of target (and control) items assigned to the j-th worker. Note that{ri} and
{(cid:96)t
j} are the two degree sequences of the bipartite graphGt.
random variable drawn from a probabilistic distribution p(xijµ∗
j). The computational question
i   ν∗
is then to construct an estimator ˆµT of the true labels µ∗T based on the crowdsourced labels{xij} 
such that the expected mean square error (MSE) on the target items  EˆµT − µ∗T2(cid:6)  is minimized.

assigned to worker j. Let ri be the number of workers assigned to the i-th target item  and let (cid:96)t
j
(and (cid:96)c

Denote by xij the label we collect from worker j for item i. In general  we can assume that xij is a

j (and ∂c

Gaussian Model. We focus on a class of simple Gaussian models on the labels xij:

i+ b∗
xij= µ∗
j+ ξij 
i is the quantity of interest of item i  b∗

where µ∗

ξij∼N(0  σ∗2) 

j is the bias of worker j  and σ∗2 is the variance.

(1)

For some quantities  like probabilities and prices  proper transforms should be applied before using
such Gaussian models. Model (1) is equivalent to the two-way ﬁxed effects model in statistics (e.g. 
Chamberlain  1982). It captures heterogeneous biases across workers that are commonly observed
in practice  for example in workers’ judgments on probabilities and prices  and which can have
signiﬁcant effects on the estimate accuracy. This model also has nice theoretical properties and will
play an important role in our theoretical analysis. Note that the biases are not identiﬁable solely from

the crowdsourced labels{xij}  making it is necessary to add some control items or other information

when decoding the answers.

2

different level of Gaussian noise: that is  xij = µ∗
i + b∗
j+ σ∗
Model (1) as the bias-only model. We will also consider another special case  xij = µ∗

An extension of model (1) is to introduce heteroscedasticity  allowing different workers to have
is
a variance parameter of worker j. We will refer to this extension as the bias-variance model  and
j ξij 
which assumes the workers all have zero bias but different variances (the variance-only model).
Theoretical analysis of the bias-variance and variance-only models are signiﬁcantly more difﬁcult
due to the presence of the variance parameters  but is still possible under asymptotic assumption.

j ξij  where ξij ∼N(0  1) and σ∗2
j+ σ∗

j

2.1 Consensus Algorithms With Partial Ground Truth

Control items with known true labels can be used to estimate workers’ parameters  and hence im-
prove the estimation accuracy. In this section  we introduce two types of consensus methods that
incorporate the control items in different ways: one simply scores the workers based on their perfor-
mance on the control items  while the other uses a joint maximum likelihood estimator that scores
the worker based on their answers on both control items and target items. We present both methods

in terms of a general model p(xijµi  νj) here; the updates for the Gaussian models can be easily

derived  but are omitted for space.
Two-stage Estimator: the workers’ parameters are ﬁrst estimated using the control items  and are
then used to predict the target items. That is 

ˆνj= arg max
ˆµi= arg max

νj

µi

Q
i∈∂c
Q
j∈∂i

j

log p(xijµ∗
i   νj) 
log p(xijµi  ˆνj) 

for all j∈W 
for all i∈T  

(2)

(3)

Scoring workers:

Predicting target items:

where we use the maximum likelihood estimator as a general procedure for estimating parameters.

Joint Estimator: we directly maximize the joint likelihood of the crowdsourced labels{xij} of
both target and control items  with µC of the control items clamped to the true values µ∗C. That is 

[µT  ν] Q
i   νj)+Q
[ˆµT   ˆν]= arg max
i∈CQ
i∈T Q
j∈∂i
j∈∂i
which can be solved by block coordinate descent  alternatively optimizing µT and ν. Compared to
i through the model assumption p(xijµ∗
j). Therefore  the joint
xij provide information on µ∗
i   ν∗

the two-stage estimator  the joint estimator estimates the workers’ parameters based on both the con-
trol items and the target items  even though their true labels are unknown. This is because the labels

log p(xijµi  νj) 

log p(xijµ∗

estimator may be much more efﬁcient than the two-stage estimator when the model assumptions are
satisﬁed  but may perform poorly if the model is misspeciﬁed.

(4)

3 How many control items are enough?

We now consider the central question: assuming each worker answers (cid:96) items (we refer (cid:96) as the

the expected MSE? To be concrete  here we assume all the workers (items) are assigned to the

semi-regular bipartite graph  which can be generated by the conﬁguration model (e.g.  Karger et al. 

budget)  including k control items and (cid:96)− k target items  what is the optimal choice of k to minimize
same number of randomly selected items (workers)  and hence the assignment graphGt is a random
2011). We assume r is the number of labels received by each target item  so that r= m((cid:96)− k)~nt.
optimal k should scale asO(√
nt) when

Obviously  the optimal number of control items should depend on their usage in the subsequent
consensus method. We will show that the two-stage and joint estimators exploit control items in
fundamentally different ways  and yield very different optimal values of k. Roughly speaking  the

(cid:96)) when using a two-stage estimator  compared toO((cid:96)~√

using joint estimators. We now discuss these two methods separately.

3.1 Optimal k for Two-stage Estimator

We ﬁrst address the problem on the bias-only model  which has a particularly simple analytic solu-
tion. We then extend our results to more general models.

3

Theorem 3.1. (i). For the bias-only model with xij= µ∗
i+ b∗
j+ ξij  where ξij are i.i.d. noise drawn
fromN(0  σ∗2)  the expected mean square error (MSE) of the two-stage estimator in (2)-(3) is
i2~nt]= σ∗2
(1+ 1
(ii). Note that r = m((cid:96)− k)~nt  and the optimal k that minimizes the expected MSE in (5) is
k∗=ऄ

i∈Tˆµi− µ∗
E[Q
(cid:96)+ 5~4− 3~2अ≈√
(cid:96)  whereऄzअ denotes the smallest integer no less than z.
for∀i∈T   ∀j∈W.
(xij− ˆbj) 
ˆµi= 1
Q
j∈∂i
have that Eˆµi= µ∗
i   and Var(ˆµi) as in (5). The remaining steps are straightforward.

Since the xij are Gaussian  the ˆµi are also Gaussian. Calculating the mean and variance of ˆµi  we

Proof. The solution of two-stage estimator has a simple linear form under the bias-only model 

(xij− µ∗
i) 

ˆbj= 1

Q
i∈∂c

).

(5)

k

j

r

k

r

(cid:96)) achieves the desired balance of trade-offs.

to inﬁnity. In addition  if the budget (cid:96) grows to inﬁnity  the optimal k should also grow to inﬁnity 
otherwise the multiplicative constant is strictly larger than one  which is suboptimal. One can readily

Remarks. (i). Eq. (5) shows that the MSE is inversely proportional to the number r of workers per
target item  while the number k of control items per workers only reﬁnes the multiplicative constant.
Therefore  the resources assigned to the control items are much less “useful” than those assigned
directly to the target items  suggesting the optimal k should be much less than the budget (cid:96).
(ii). On the other hand  if k is too small  the multiplicative constant becomes large  which also

General Models. The bias-only model is simple enough to give closed form solutions. It turns
out that we can obtain similar results for more general models such as the bias-variance and the
variance-only model  but only in the asymptotic regime.

degrades the MSE. In the extreme  if k = 0 then the bias is unidentiﬁable  and the MSE grows
see that k=O(√
To set up  assume{µi} and{νj} are drawn from prior distributions Qµ and Qν  respectively. As-
sume log p(xijµi  νj) is twice differentiable w.r.t. µi and νj for all xij. Deﬁne the Fisher infor-
mation matrix Hµµ=−Ex[∇2
µµ log p(xµ  ν)]  and similarly for Hµν and Hνν. Note that Hµµ is a
random variable dependent on µ and ν  and denote by Eµν[Hµµ] its expectation w.r.t. Qµ and Qν.
Theorem 3.2. (i). Assume the crowdsourced labels{xij} are drawn from p(xijµ∗
j)  where
i   ν∗
{µ∗
i} and{ν∗
j} are drawn from priors Qµ and Qν  respectively. The asymptotic expected MSE of
1+ a
 
i2~nt(cid:6)= ˜σ2
EQ
i∈Tˆµi− µ∗
µν log p(xµ  ν)T(cid:6)  and a =
µµ)]  Jµµ = Ex ν∇2
µν log p(xµ  ν)H−1
νν∇2
where ˜σ2 = Eµν[tr(H−1
Eµν[tr(H−1
µµ)] 
µµ)]~Eµν[tr(H−1
µµJµµH−1
(ii). Note that r = m((cid:96)− k)~nt  and the optimal k that minimizes the asymptotic MSE in (6) is
k∗=ऄ
a(cid:96)+ a2+ 1~4− a− 1~2अ≈√
a(cid:96)  whereऄkअ denotes the smallest integer no less than k.

the two-stage estimator deﬁned in (2)-(3)  as both r and k grow to inﬁnity  is

(6)

k

r

Proof. Similar to Theorem 3.1  except asymptotic normality of M-estimators (e.g.  Van der Vaart 
2000) should be used.

Remarks. (i). The result in Theorem 3.2 is parallel to that in Theorem 3.1 for bias-only models 
except that the contribution from uncertainty on the workers’ parameters is scaled by a model-
dependent factor a  and correspondingly  the optimal k is scaled by

a. Calculation yields a= 2 for
the variance-only model  and a= 3 for the bias-variance model for any choice of prior Qµ and Qν.
(ii). Letting k take continuous values  the optimal k to minimize (6) is k∗=√
a(cid:96)+ a2− a  which
⋅ ˜σ2~((cid:96)− k∗)
⋅ ˜σ2~((cid:96)− 2k∗). For comparison  the MSE would be nt
an effective extra loss of k∗ labels for each target item. Note that this rule is universal  in that it

achieves a minimum MSE of nt
m
if the worker parameters were known exactly. So  the uncertainty in the workers’ parameters creates

m

√

remains true for any a (and hence any model).

4

3.2 Optimal k for Joint Estimator

The two-stage estimator is easy to analyze in that its accuracy is independent of the structure of the
bipartite assignment graph beyond the degree r and k. This is not true for the joint estimator  whose
accuracy depends on the topological structure of the assignment graph in a non-trivial way. In this
section we study the properties of the joint estimator  again starting with the simple bias-only model 
then discussing its extension to more general cases.

We ﬁrst introduce some matrix notation. Let At be the adjacency matrix of Gt. Let Rt
∶=
diag({ri∶ i∈T}) be the diagonal matrix formed by the degree sequence of the target items  and
j∶ j∈W}).
j∶ j∈W}) and Lc= diag({(cid:96)c
similarly deﬁne Lt= diag({(cid:96)t
i+ b∗
Theorem 3.3. (i). For the bias-only model with xij= µ∗
j+ ξij  where ξij are i.i.d. noise drawn
fromN(0  σ∗2)  the expected MSE of the joint estimator deﬁned in (4) is
t)−1)~nt 
i2~nt]= σ∗2tr((Rt− At(Lt+ Lc)−1AT
E[Q
i∈Tˆµi− µ∗
If At is regular  with Rt= rI and Lt=((cid:96)− k)I  this simpliﬁes:
i2~nt]= σ∗2 1
E[Q
i∈Tˆµi− µ∗
W)−1)~nt  where W= R−1
t AtL−1
Proof. Assume B∶= I− R−1
the bias-only model is ˆµT = µ∗T + B−1zT   where zi= 1
(ξij− ¯ξj)  and ¯ξj=
Q
j+ (cid:96)t
i′∈∂c
j∪∂t
i− b∗
and ξij= xij− µ∗
j for∀i∈T . We obtain (7) by calculating Var(ˆµT).
ture of the bipartite graphGt. Consider the eigenvalues 1= λ1≥ λ2≥≥ 0 of W∶= R−1
t AtL−1
where the second largest eigenvalue λ2 famously characterizes the connectivity of the graphGt.
Roughly speaking Gt has better connectivity if λ2 is small  and verse versa. Observe that

Remarks. (ii). Equation (8) establishes an explicit connection between MSE and the spectral struc-
t  
t AT

(cid:96)
t is invertible. The solution of the joint estimator on
ξij

tr((I− (cid:96)− k
t At(Lt+ Lc)−1AT

Q
j∈∂i

t .
t AT

(7)

(8)

(cid:96)c

ri

1

r

j

j

+ nt− 1
1− (cid:96)−k

(cid:96) λ2

.

(9)

tr((I− (cid:96)− k

(cid:96)

(1− (cid:96)− k
W)−1) = ntQ
i=1

(cid:96)

λi)−1 ≤ (cid:96)

k

Therefore  the joint estimator performs better when λ2 is small  i.e.  when the graph is strongly
connected. Intuitively  better connectivity “couples” the items and workers more tightly together 
making it easier not to make mistakes during inference.
Besides hoping for small error  one may also want the assignment graph to be sparse  i.e.  use fewer
labels. Graphs that are both sparse and strongly connected are known as expander graphs  and have
been found universally important in areas like robust computer networks  error correcting codes  and
communication networks; see Hoory et al. (2006) for a review. It is well known that large sparse
random regular graphs are good expanders (e.g.  Friedman et al.  1989)  and hence a near-optimal
allocation strategy for crowdsourcing (Karger et al.  2011). On such graphs  we can also estimate
the optimal k in a simple form.

i2~nt]= σ∗2
E[Q
i∈Tˆµi− µ∗
(cid:96)− k
2+ 1~4− (cid:96)~nt− 1~2अ≈ (cid:96)~√

Theorem 3.4. Assume At is a random regular bipartite graph  and nt= m. We have that
with probability one as nt→∞. If in addition (cid:96)→∞  the optimal k that minimizes (10) is k∗=
ऄ
(cid:96)2~nt+ (cid:96)2~nt
(cid:96)  in contrast to the square-root rule of two-stage estimators. However  since usually (cid:96)≤ nt  we have
nt≤√
(cid:96)~√

Remarks. (i). Perhaps surprisingly  the optimal k of the joint estimator scales linearly w.r.t. budget

Proof. Use (9) and the bound in Puder (2012) for λ2 of large random regular bipartite graphs.

(cid:96)  that is  the joint estimator requires fewer control items than the two-stage estimator.

(1+O( 1

 nt− 1

))+ (cid:96)

(cid:6) 

(10)

ntk

nt.

nt

(cid:96)

5

(ii). In addition  the optimal k for the joint estimator also decreases as the total number nt of target
items increases. Because nt is usually quite large in practice  the number of control items is usually

very small. In particular  as nt →∞  we have k∗ = 1  that is  there is no need for control items
notation  let Hµµ= Rt⊗ Eµν(Hµµ)  and Hνν=(Lt+ Lc)⊗ Eµν(Hνν)  where⊗ is the Kronecker
product  and Hµν=[Hµiνj]ij is a block matrix  where block Hµiνj for(ij)∈Et is a random copy
of−∇2
µν log p(xµ  ν) with random x  µ and ν  and Hµiνj = 0 for(ij)∉Et. Assuming the joint

beyond ﬁxing the unidentiﬁability issue of the biases.
General Models. The joint estimator on general models is more involved to analyze  but it is still
possible to give an rough estimate by analyzing the Fisher information matrix of the likelihood. For

maximum likelihood estimator in (4) is asymptotically consistent (in terms of large (cid:96) and r)  we can
estimate its asymptotic MSE by the inverse of the Fisher information matrix 

−1Hµν

T)−1)]~nt 

E[Q
i∈Tˆµi− µ∗

i2~nt]≈ E[tr((Hµµ− Hµν Hνν

where the expectation on the right side is w.r.t. the randomness of Hµν. This parallels (7) in The-
orem 3.3  except the adjacency matrices are replaced by corresponding Hessian matrices. Unfortu-
nately  it is more challenging to give a simple estimate of the optimal k as in Theorem 3.4  even when
At is a random bipartite graph  because the spectral properties of the random matrix are complicated

by blockwise structure  and may depend on the prior distribution Q(ν). However  experimentally
a~nt  where the constant a depends on both the model assumption
and the choice of Q(ν)  and can be numerically estimated by simulation.

the optimal k follows the trend (cid:96)



4 Experiments

We show that our theoretical predictions match closely to the results on simulated data and two real
datasets for estimating prices and point spreads. The experiments also highlight important practical
issues such as the impact of model misspeciﬁcation  biases  and heteroskedasticity.
Datasets and Setup. The simulated data are generated by the Gaussian models deﬁnited in Sec-

tion 2  where µi and bj are i.i.d. drawn fromN(1  1); and σj from a χ2-distribution with degree

4 for the heteroskedastic versions. The price dataset consists of 80 household items collected from
stores like Amazon and Costco  whose prices are estimated by 155 undergraduate students at UC
Irvine. A log transform is performed on the prices before using the Gaussian models. The Na-
tional Football League (NFL) forecasting data was collected by Massey et al. (2011)  where 386
participants were asked to predict the point difference of 245 NFL games. We use the point spreads
determined by professional bookmakers as the truth values in our experiments.
For all the experiments  we ﬁrst construct the set of target items and control items by randomly

partitioning items  and then randomly assign each worker with k control items and (cid:96)−k target items 

for varying values of (cid:96) and k. The MSE is estimated by averaging over 500 random trials. The
optimal k is estimated by minimizing the averaged MSE over 300 randomly subsampled trials  and
then taking average over 20 random subsamples.
Optimal Number of Control Items. See Figure 1 for the results of the bias-only model when the
data are simulated from the correct model. Figure 1(a) shows the empirical MSE of the two-stage
estimator when varying the number k of control items. A clear trade-off appears: MSE is large both
when k is too small to estimate workers’ parameters accurately  and when k is too large to leave
a sufﬁcient number of labels for the target items. The MSE of the joint estimator in Figure 1(b)
follows a similar trend  but the gain by using control items is less signiﬁcant (the left parts of the
curves are ﬂatter). This is because the joint estimator leverages the labels on the target items (whose
true values are unknown)  and relies less on the control items. In particular  as the number nt of
nt
(see Figure 1(d))  but that of the two-stage estimator stays the same. Overall  the empirical optimal
k of the two-stage and joint estimator aligns closely with our theoretical prediction (Figure 1(c)-(d)).
We show in Figure 2(a) the result of the bias-variance model when data are simulated from the
correct model. The optimal k of the two-stage estimator aligns closely to
the asymptotic result in Theorem 3.2  while that of the joint estimator scales like the line (cid:96)

target items increases  the optimal value of k for the joint estimator decreases with a rate of 1~√
a(cid:96) with a= 3  matching

a~nt

with a≈ 3  matching our hypothesis in Section 3.2.

√

6

(a) Two-stage Estimator

(b) Joint Estimator

Figure 1: Results of the bias-only model on data simulated from the same model. (a)-(b) The MSE

of the two-stage and joint estimators with varying (cid:96) and k and ﬁxed nt= 100. The stars and circles
but ﬁxed nt= 100. (d) The optimal k with varying nt  but ﬁxed (cid:96)= 50. We set m= nt here.

denote the empirically and theoretically optimal k  respectively. (c) The optimal k with varying (cid:96) 

(c) Optimal k vs. (cid:96)

(d) Optimal k vs. nt

Model misspeciﬁcation. Real datasets are not expected to match the model assumptions perfectly.
It is important  but difﬁcult  to understand how the theory should be modiﬁed to compensate for the
violation of assumptions. We provide some insights on this by constructing model misspeciﬁcation
artiﬁcially. Figure 2(b)-(c) shows the results when the data are simulated from a bias-variance
model with non-zero biases  but we use the variance-only model (with zero bias) in the consensus
algorithm. We see in Figure 2(b) that the optimal k of the two-stage estimator still aligns closely to
our theoretical prediction  but that of the joint estimator is much larger than one would expect (almost
half of the budget (cid:96)). In addition  the MSE of the joint estimator in this case is signiﬁcantly worse
than that of the two-stage estimator (see Figure 2(c))  which is not expected if the model assumption
holds. Therefore  the joint estimator seems to be more sensitive to model misspeciﬁcation than the
two-stage estimator  suggesting that caution should be taken when it is applied in practice.
Real Datasets. Figure 3 shows the results of the bias-only model on the two real datasets; our
prediction of the optimal k matches the empirical results surprisingly well on the NFL dataset (Fig-
ure 3(d)-(f))  while our theoretically optimal values of k on the price dataset tend to be smaller than
the actual values (Figure 3(a)-(c))  perhaps caused by some unknown model misspeciﬁcation. How-
ever  our bias on the estimated k does not cause a signiﬁcant increase in MSE  because the scale in
Figure 3(a)-(b) is relatively small compared to that in Figure 4(a).
Interestingly  the two real datasets have opposite properties in terms of the importance of bias and
heteroskedasticity (see Figure 4): In the price dataset  all the workers tend to underestimate the prices
of the products  i.e.  bj are negative for all workers  and the bias-only model performs much better
than the zero-bias variance-only model. In contrast  the participants in the NFL dataset exhibit no
systematic bias but seem to have different individual variances  and the variance-only model works
better than the bias-only model. In both cases  the full bias-variance model works best if budget (cid:96)
is large  but is not necessarily best if the budget is small and over-ﬁtting is an issue.

5 Conclusion

The problem of how many control questions to use is unlikely to yield a deﬁnitive answer  since real
data are always likely to be more complicated than any model. However  our results highlight several
issues and provide insights and rules of thumb that can help crowdsourcing practitioners make their

own decisions. In particular  we show that the optimal number of control items should beO(√
(cid:96)) for
the two-stage estimator andO((cid:96)~√
nt) for the joint estimator. Because the number nt of target items

is usually large in practice  it is reasonable to recommend using a minimal number of control items 
just enough to ﬁx potential unidentiﬁability issues  assuming the model assumptions hold well.
However  the joint estimator may require signiﬁcantly more control items if model misspeciﬁcation
exists; in this case one might better switch to the more robust two-stage estimator  or search for
better models. The control items can also be used to do model selection  an issue which deserves
further discussion in the future.
Acknowledgements. Work supported in part by NSF IIS-1065618 and IIS-1254071 and a Microsoft
Research Fellowship. Thanks to Tobias Johnson for discussion on random matrix theory.

7

123581322366010000.20.40.60.8(cid:1)=7k(#ofcontrolitems)MSE(cid:1)=10(cid:1)=15(cid:1)=20(cid:1)=50123581322366010000.10.20.30.40.50.6(cid:1)=7k(#ofcontrolitems)MSE(cid:1)=10(cid:1)=15(cid:1)=20(cid:1)=500501000246810Budget(cid:1)Optimalk100200300400500600246nt(#oftargetitems)Optimalk Joint(empirical)Joint((cid:1)/√nt)Two-stage(empirical)Two-stage(√(cid:1))(a) Bias-variance Model

(b)-(c) Model Misspeciﬁcation

(a) Results of the bias-variance model on data simulated from the same model. (b)-(c)
Figure 2:
Results when the data are simulated from the bias-variance model with non-zero biases  but we use
the variance-only model (with zero bias) in the consensus algorithm. With this model misspeciﬁ-
cation  the joint estimator requires signiﬁcantly more control items than one would expect (almost
half of the budget (cid:96))  and performs worse than the two-stage estimator.

t
e
s
a
t
a
D
e
c
i
r
P

t
e
s
a
t
a
D
L
F
N

(a) Two-stage Estimator

(b) Joint Estimator

(c) Optimal k vs. (cid:96)

(d) Two-stage Estimator

(e) Joint Estimator

(f) Optimal k vs. (cid:96)

Figure 3: Results on the real datasets when using the bias-only model.
(a)-(b) and (d)-(e) The
MSE when using the two-stage and joint estimators  respectively. (c) and (f) The empirically and

theoretically optimal k as the budget (cid:96) varies. Here we ﬁx nt= 50 for price dataset and nt= 200 for

NFL dataset.

(a) Price Dataset

(b) NFL Dataset

Figure 4: Comparison of different models and consensus methods on the two real datasets. (a)-(b)
The MSE when selecting the best possible k as the budget (cid:96) varies. The workers in the price dataset
has systematic bias  and the bias-only model works better than the variance-only model  while the
workers in NFL dataset have no bias but different individual variances  and the variance-only model
is better than bias-only. In both datasets  the full bias-variance model works best if the budget (cid:96) is
large  but is not necessarily best if the budget is small when over-ﬁtting is an issue.

8

02040608010005101520Budget(cid:1)Optimalk Joint(empirical)Joint((cid:1)(cid:1)3/nt)Two-stage(empirical)Two-stage(√3(cid:1))02040608010001020304050Budget(cid:1)Optimalk Joint(empirical)Two-stage(empirical)Two-stage(√2(cid:1))2358132236601000.511.5(cid:1)=40(cid:1)=60(cid:1)=80(cid:1)=100k(#ofcontrolitems)MSE1235813220.20.210.22(cid:1)=7k(#ofcontrolitems)MSE(cid:1)=10(cid:1)=15(cid:1)=251235813220.20.210.22(cid:1)=7k(#ofcontrolitems)MSE(cid:1)=10(cid:1)=15(cid:1)=251020300246810Budget(cid:1)Optimalk Joint(empirical)Joint((cid:1)/√nt)Two-stage(empirical)Two-stage(√(cid:1))123581322681012141618(cid:1)=7k(#ofcontrolitems)MSE(cid:1)=10(cid:1)=15(cid:1)=25123581322681012141618(cid:1)=7k(#ofcontrolitems)MSE(cid:1)=10(cid:1)=15(cid:1)=25102030400246Budget(cid:1)Optimalk Joint(empirical)Joint((cid:1)/√nt)Two-stage(empirical)Two-stage(√(cid:1))2510200.20.220.240.260.280.30.320.34Budget(cid:1)MSE2510205101520Budget(cid:1)MSE Uniform MeanBias−only / JointBias−variance / JointVariance−only / JointBias−only / Two−stageBias−variance / Two−stageVariance−only / Two−stageReferences
James Surowiecki. The wisdom of crowds. Anchor  2005.
Victor S Sheng  Foster Provost  and Panagiotis G Ipeirotis. Get another label? Improving data qual-
ity and data mining using multiple  noisy labelers. In Proc. SIGKDD Int’l Conf. on Knowledge
Discovery and Data Mining  pages 614–622. ACM  2008.

A.P. Dawid and A.M. Skene. Maximum likelihood estimation of observer error-rates using the EM

algorithm. Applied Statistics  pages 20–28  1979.

Jacob Whitehill  Paul Ruvolo  Tingfan Wu  Jacob Bergsma  and Javier Movellan. Whose vote should
count more: Optimal integration of labels from labelers of unknown expertise. In Advances in
Neural Information Processing Systems (NIPS)  pages 2035–2043  2009.

D.R. Karger  S. Oh  and D. Shah. Iterative learning for reliable crowdsourcing systems. In Advances

in Neural Information Processing Systems (NIPS)  pages 1953–1961  2011.

Qiang Liu  Jian Peng  and Alexander Ihler. Variational inference for crowdsourcing. In Advances in

Neural Information Processing Systems (NIPS)  pages 701–709  2012.

Dengyong Zhou  John Platt  Sumit Basu  and Yi Mao. Learning from the wisdom of crowds by
minimax entropy. In Advances in Neural Information Processing Systems (NIPS)  pages 2204–
2212  2012.

A Kimball Romney  William H Batchelder  and Susan C Weller. Recent applications of cultural

consensus theory. American Behavioral Scientist  31(2):163–177  1987.

Michael D Lee  Mark Steyvers  Mindy de Young  and Brent Miller. Inferring expertise in knowledge

and prediction ranking tasks. Topics in cognitive science  4(1):151–163  2012.

Gary Chamberlain. Multivariate regression models for panel data. Journal of Econometrics  18(1):

5–46  1982.

Aad W Van der Vaart. Asymptotic statistics  volume 3. Cambridge university press  2000.
Shlomo Hoory  Nathan Linial  and Avi Wigderson. Expander graphs and their applications. Bulletin

of the American Mathematical Society  43(4):439–561  2006.

Joel Friedman  Jeff Kahn  and Endre Szemeredi. On the second eigenvalue of random regular graphs.

In Proc. ACM Symp. on Theory of Computing  pages 587–598. ACM  1989.

Doron Puder.

Expansion of random graphs: New proofs  new results.

arXiv:1212.5216  2012.

arXiv preprint

Cade Massey  Joseph P Simmons  and David A Armor. Hope over experience: Desirability and the

persistence of optimism. Psychological Science  22(2):274–281  2011.

9

,Qiang Liu
Alexander Ihler
Mark Steyvers
Avrim Blum
Nika Haghtalab
Ariel Procaccia
Soroosh Shafieezadeh Abadeh
Peyman Mohajerin Esfahani
Daniel Kuhn