2018,Graph Oracle Models  Lower Bounds  and Gaps for Parallel Stochastic Optimization,We suggest a general oracle-based framework that captures parallel
  stochastic optimization in different parallelization settings
  described by a dependency graph  and derive generic lower bounds 
  in terms of this graph.  We then use the framework and derive lower
  bounds to study several specific parallel optimization settings 
  including delayed updates and parallel processing with intermittent
  communication.  We highlight gaps between lower and upper bounds on
  the oracle complexity  and cases where the ``natural'' algorithms
  are not known to be optimal.,Graph Oracle Models  Lower Bounds  and Gaps for

Parallel Stochastic Optimization

Toyota Technological Institute at Chicago

Blake Woodworth

blake@ttic.edu

Jialei Wang

Two Sigma Investments

jialei.wang@twosigma.com

Adam Smith

Boston University
ads22@bu.edu

Brendan McMahan

Google

mcmahan@google.com

Toyota Technological Institute at Chicago

Nathan Srebro⇤

nati@ttic.edu

Abstract

We suggest a general oracle-based framework that captures different parallel
stochastic optimization settings described by a dependency graph  and derive
generic lower bounds in terms of this graph. We then use the framework and derive
lower bounds for several speciﬁc parallel optimization settings  including delayed
updates and parallel processing with intermittent communication. We highlight
gaps between lower and upper bounds on the oracle complexity  and cases where
the “natural” algorithms are not known to be optimal.

1

Introduction

Recently  there has been great interest in stochastic optimization and learning algorithms that leverage
parallelism  including e.g. delayed updates arising from pipelining and asynchronous concurrent
processing  synchronous single-instruction-multiple-data parallelism  and parallelism across distant
devices. With the abundance of parallelization settings and associated algorithms  it is important to
precisely formulate the problem  which allows us to ask questions such as “is there a better method
for this problem than what we have?” and “what is the best we could possibly expect?”
Oracle models have long been a useful framework for formalizing stochastic optimization and
learning problems. In an oracle model  we place limits on the algorithm’s access to the optimization
objective  but not what it may do with the information it receives. This allows us to obtain sharp
lower bounds  which can be used to argue that an algorithm is optimal and to identify gaps between
current algorithms and what might be possible. Finding such gaps can be very useful—for example 
the gap between the ﬁrst order optimization lower bound of Nemirovski et al. [21] and the best known
algorithms at the time inspired Nesterov’s accelerated gradient descent algorithm [22].
We propose an oracle framework for formalizing different parallel optimization problems. We specify
the structure of parallel computation using an “oracle graph” which indicates how an algorithm
accesses the oracle. Each node in the graph corresponds to a single stochastic oracle query  and that
query (e.g. the point at which a gradient is calculated) must be computed using only oracle accesses
in ancestors of the node. We generally think of each stochastic oracle access as being based on a
single data sample  thus involving one or maybe a small number of vector operations.
In Section 3 we devise generic lower bounds for parallel optimization problems in terms of simple
properties of the associated oracle graph  namely the length of the longest dependency chain and
the total number of nodes. In Section 4 we study speciﬁc parallel optimization settings in which

⇤Part of this work was done while visiting Google.

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

many algorithms have been proposed  formulate them as graph-based oracle parallel optimization
problems  instantiate our lower bounds  and compare them with the performance guarantees of
speciﬁc algorithms. We highlight gaps between the lower bound and the best known upper bound and
also situations where we can devise an optimal algorithm that matches the lower bound  but where
this is not the “natural” and typical algorithm used in this settings. The latter indicates either a gap in
our understanding of the “natural” algorithm or a need to depart from it.

Previously suggested models Previous work studied communication lower bounds for parallel
convex optimization where there are M machines each containing a local function (e.g. a collection
of samples from a distribution). Each machine can perform computation on its own function  and
then periodically every machine is allowed to transmit information to the others. In order to prove
meaningful lower bounds based on the number of rounds of communication  it is necessary to prevent
the machines from simply transmitting their local function to a central machine  or else any objective
could be optimized in one round. There are two established ways of doing this. First  one can allow
arbitrary computation on the local machines  but restrict the number of bits that can be transmitted
in each round. There is work focusing on speciﬁc statistical estimation problems that establishes
communication lower bounds via information-theoretic arguments [7  12  29]. Alternatively  one can
allow the machines to communicate real-valued vectors  but restrict the types of computation they
are allowed to perform. For instance  Arjevani and Shamir [3] present communication complexity
lower bounds for algorithms which can only compute vectors that lie in a certain subspace  which
includes e.g. linear combinations of gradients of their local function. Lee et al. [16] assume a similar
restriction  but allow the data deﬁning the local functions to be allocated to the different machines in
a strategic manner. Our framework applies to general stochastic optimization problems and does not
impose any restrictions on what computation the algorithm may perform  and is thus a more direct
generalization of the oracle model of optimization.
Recently  Duchi et al. [10] considered ﬁrst-order optimization in a special case of our proposed model
(the “simple parallelism” graph of Section 4.2)  but their bounds apply in a more limited parameter
regime  see Section 3 for discussion.
2 The graph-based oracle model
We consider the following stochastic optimization problem

min

x2Rm:kxkB

F (x) := Ez⇠P [f (x; z)]

(1)

The problem (1) captures many important tasks  such as supervised learning  in which case f (x; z) is
the loss of a model parametrized by x on data instance z and the goal is to minimize the population
risk E [f (x; z)]. We assume that f (·; z) is convex  L-Lipschitz  and H-smooth for all z. We also
allow f to be non-smooth  which corresponds to H = 1. A function g is L-Lipschitz when
kg(x)  g(y)k  Lkx  yk for all x  y  and it is H-smooth when it is differentiable and its gradient
is H-Lipschitz. We consider optimization algorithms that use either a stochastic gradient or stochastic
prox oracle (Ograd and Oprox respectively):

Ograd(x  z) = (f (x; z)  rf (x; z))

Oprox(x    z) =⇣f (x; z)  rf (x; z)  proxf (·;z)(x  )⌘
proxf (·;z)(x  ) = arg min


2 ky  xk2

f (y; z) +

(2)
(3)

(4)

where

y

The prox oracle is quite powerful and provides global rather than local information about f. In
particular  querying the prox oracle with  = 0 fully optimizes f (·; z).
As stated  z is an argument to the oracle  however there are two distinct cases. In the “fully stochastic”
oracle setting  the algorithm receives an oracle answer corresponding to a random z ⇠P . We also
consider a setting in which the algorithm is allowed to “actively query” the oracle. In this case  the
algorithm may either sample z ⇠P or choose a desired z and receive an oracle answer for that z.
Our lower bounds hold for either type of oracle. Most optimization algorithms only use the fully
stochastic oracle  but some require more powerful active queries.
We capture the structure of a parallel optimization algorithm with a directed  acyclic oracle graph G.
Its depth  D  is the length of the longest directed path  and the size  N  is the number of nodes. Each

2

node in the graph represents a single stochastic oracle access  and the edges in the graph indicate
where the results of that oracle access may be used: only the oracle accesses from ancestors of
each node are available when issuing a new query. These limitations might arise e.g. due to parallel
computation delays or the expense of communicating between disparate machines.
Let Q be the set of possible oracle queries  with the exact form of queries (e.g.  q = x vs. q =
(x    z)) depending on the context. Formally  a randomized optimization algorithm that accesses the
stochastic oracle O as prescribed by the graph G is speciﬁed by associating with each node vt a query
rule Rt : (Q O(Q))⇤ ⇥ ⌅ !Q   plus a single output rule ˆX : (Q O(Q))⇤ ⇥ ⌅ !X . We grant all
of the nodes access to a source of shared randomness ⇠ 2 ⌅ (e.g. an inﬁnite stream of random bits).
The mapping Rt selects a query qt to make at node vt using the set of queries and oracle responses in
ancestors of vt  namely

qt = Rt (qi O(qi) : i 2 Ancestors(vt))  ⇠

(5)

Similarly  the output rule ˆX maps from all of the queries and oracle responses to the algorithm’s
output as ˆx = ˆX ((qi O(qi) : i 2 [N ]) ⇠ ). The essential question is: for a class of optimization
problems (G O F) speciﬁed by a dependency graph G  a stochastic oracle O  and a function class
F  what is the best possible guarantee on the expected suboptimality of an algorithm’s output  i.e.
(6)

inf

Eˆx z [f (ˆx; z)]  min

x Ez [f (x; z)]

(R1 ... RN   ˆX)

sup
f2F

In this paper  we consider optimization problems (G O FL H B) where FL H B is the class of convex 
L-Lipschitz  and H-smooth functions on the domain {x 2 Rm : kxk  B} and parametrized by z 
and O is either a stochastic gradient oracle Ograd (2) or a stochastic prox oracle Oprox (3). We consider
this function class to contain Lipschitz but non-smooth functions too  which corresponds to H = 1.
Our function class does not bound the dimension m of the problem  as we seek to understand the
best possible guarantees in terms of Lipschitz and smoothness constants that hold in any dimension.
Indeed  there are (typically impractical) algorithms such as center-of-mass methods  which might
use the dimension in order to signiﬁcantly reduce the oracle complexity  but at a potentially huge
computational cost. Nemirovski [20] studied non-smooth optimization in the case that the dimension
is bounded  proving lower bounds in this setting that scale with the 1/3-power of the dimension but
have only logarithmic dependence on the suboptimality. We do not analyze strongly convex functions 
but the situation is similar and lower bounds can be established via reduction [28].
3 Lower bounds
We now provide lower bounds for optimization problems (G Ograd FL H B) and (G Oprox FL H B)
in terms of L  H  B  and the depth and size of G.
Theorem 1. Let L  B 2 (0 1)  H 2 [0 1]  N  D  1  let G be any oracle graph of depth D and
size N and consider the optimization problem (G Ograd FL H B). For any randomized algorithm
A = (R1  . . .   RN   ˆX)  there exists a distribution P and a convex  L-Lipschitz  and H-smooth
function f on a B-bounded domain in Rm for m = OmaxN 2  D3N log (DN ) such that

HB2

E z⇠PˆX⇠Ahf ( ˆX; z)i  min

x Ez⇠P [f (x; z)]  ⌦✓min⇢ LB
pD

 

D2  +

LB

pN◆

Theorem 2. Let L  B 2 (0 1)  H 2 [0 1]  N  D  1  let G be any oracle graph of depth D and
size N and consider the optimization problem (G Oprox FL H B). For any randomized algorithm
A = (R1  . . .   RN   ˆX)  there exists a distribution P and a convex  L-Lipschitz  and H-smooth
function f on a B-bounded domain in Rm for m = OmaxN 2  D3N log (DN ) such that

HB2

E z⇠PˆX⇠Ahf ( ˆX; z)i  min

x Ez⇠P [f (x; z)]  ⌦✓min⇢ LB

D

 

D2  +

LB

pN◆

These are the tightest possible lower bounds in terms of just the depth and size of G in the sense that
for all D  N there are graphs G and associated algorithms which match the lower bound. Of course 
for speciﬁc  mostly degenerate graphs they might not be tight. For instance  our lower bound for the
graph consisting of a short sequential chain plus a very large number of disconnected nodes might

3

be quite loose due to the artiﬁcial inﬂation of N. Nevertheless  for many interesting graphs they are
tight  as we shall see in Section 4.
Each lower bound has two components: an “optimization” term and a “statistical” term. The statistical
term ⌦(LB/pN ) is well known  although we include a brief proof of this portion of the bound
in Appendix D for completeness. The optimization term depends on the depth D  and indicates 
intuitively  the best suboptimality guarantee that can be achieved by an algorithm using unlimited
parallelism but only D rounds of communication. Arjevani and Shamir [3] also obtain lower bounds
in terms of rounds of communication  which are similar to how our lower bounds depend on depth.
However they restricted the type of computations that are allowed to the algorithm to a speciﬁc class
of operations  while we only limit the number of oracle queries and the dependency structure between
them  but allow forming the queries in any arbitrary way.
Similar to Arjevani and Shamir [3]  to establish the optimization term in the lower bounds  we
construct functions that require multiple rounds of sequential oracle accesses to optimize. In the
gradient oracle case  we use a single  deterministic function which resembles a standard construction
for ﬁrst order optimization lower bounds. For the prox case  we construct two functions inspired by
previous lower bounds for round-based and ﬁnite sum optimization [3  28]. In order to account for
randomized algorithms that might leave the span of gradients or proxs returned by the oracle  we use
a technique that was proposed by Woodworth and Srebro [27  28] and reﬁned by Carmon et al. [8].
For our speciﬁc setting  we must slightly modify existing analysis  which is detailed in Appendix A.
A useful feature of our lower bounds is that they apply when both the Lipschitz constant and
smoothness are bounded concurrently. Consequently  “non-smooth” in the subsequent discussion can
be read as simply identifying the case where the L term achieves the minimum as opposed to the H
term (even if H < 1). This is particularly important when studying stochastic parallel optimization 
since obtaining non-trivial guarantees in a purely stochastic setting requires some sort of control on
the magnitude of the gradients (smoothness by itself is not sufﬁcient)  while obtaining parallelization
speedups often requires smoothness  and so we would like to ask what is the best that can be done
when both Lipschitz and smoothness are controlled. Interestingly  the dependence on both L and H
in our bounds is tight  even when the other is constrained  which shows that the optimization term
cannot be substantially reduced by using both conditions together.
In the case of the gradient oracle  we “smooth out” a standard non-smooth lower bound construction
[21  27]; previous work has used a similar approach in slightly different settings [2  13]. For `  L
and ⌘  H  and orthonormal v1  . . .   vD+1 drawn uniformly at random  we deﬁne the `-Lipschitz
but non-smooth function ˜f  and its `-Lipschitz  ⌘-smooth “⌘-Moreau envelope” [5]:
⌘
2 ky  xk2

˜f (x) = max

f (x) = min

˜f (y) +

(7)

y

`✓v>r x 

r  1

2(D + 1)1.5◆

1rD+1

This deﬁnes a distribution over f’s based on the randomness in the draw of v1  . . .   vD+1  and we
apply Yao’s minimax principle. In Appendix B  we prove Theorem 1 using this construction.
In the case of the prox oracle  we “straighten out” the smooth construction of Woodworth and Srebro
[28]. For ﬁxed constants c    we deﬁne the following Lipschitz and smooth scalar function c:

For P = Uniform{1  2} and orthonormal v1  . . .   v2D drawn uniformly at random  we deﬁne

0
2(|z| c)2
z2  2c2
2 |z| 2  2c2

|z| c
c < |z| 2c
2c < |z| 
|z| >

cv>r1x  v>r x!

(8)

(9)

(10)

c(z) =8>><>>:
8 2av>1 x + cv>2Dx +
2D1Xr=3 5 7 ...
cv>r1x  v>r x!
8 2DXr=2 4 6 ...

⌘

⌘

f (x; 1) =

f (x; 2) =

4

Again  this deﬁnes a distribution over f’s based on the randomness in the draw of v1  . . .   v2D and
we apply Yao’s minimax principle. In Appendix C  we prove Theorem 2 using this construction.

Graph example

path(T )

(Section 4.1)
layer(T  M)
(Section 4.2)
delay(T ⌧ )
(Section 4.3)

intermittent(T  K  M)

(Section 4.4)

With gradient oracle

With gradient and prox oracle

LpT

T 2⌘+ LpM T
⇣ LpT ^ H
T 2 ◆+ LpT
✓ LpT /⌧ ^ H⌧ 2
K2T 2⌘+ LpM KT
⇣ LpKT ^ H
T 2 + LpM KT⌘
LpKT ^⇣ H
T K + LpM KT⌘ log M KT
^⇣ H
L 

 L
T 2+ LpM T
T ^ H
T 2 ⌘+ LpT
⇣ L⌧
T ^ H⌧ 2
 L
K2T 2+ LpM KT
KT ^ H
T 2+ LpM KT⌘
LpKT ^⇣ L
T ^ H
T K + LpM KT⌘ log M KT
^⇣ H
L 

Table 1: Summary of upper and lower bounds for stochastic convex optimization of L-Lipschitz and H-smooth
functions with T iterations  M machines  and K sequential steps per machine. Green indicates lower bounds
matched only by "unnatural" methods  red and blue indicates a gap between the lower and upper bounds.

Relation to previous bounds As mentioned above  Duchi et al. [10] recently showed a lower
bound for ﬁrst- and zero-order stochastic optimization in the “simple parallelism” graph consisting
of D layers  each with M nodes. Their bound [10  Thm 2] applies only when the dimension m is
constant  and D = O(m log log M ). Our lower bound requires non-constant dimension  but applies
in any range of M. Furthermore  their proof techniques do not obviously extend to prox oracles.

4 Speciﬁc dependency graphs

We now use our framework to study four speciﬁc parallelization structures. The main results (tight
complexities and gaps between lower and upper bounds) are summarized in Table 1. For simplicity
and without loss of generality  we set B = 1  i.e. we normalize the optimization domain to be
{x 2 Rm : kxk  1}. All stated upper and lower bounds are for the expected suboptimality
E[F (ˆx)]  F (x⇤) of the algorithm’s output.
4.1 Sequential computation: the path graph
We begin with the simplest model  that of sequential computation captured by the path graph of
length T depicted above. The ancestors of each vertex vi  i = 1 . . . T are all the preceding vertices
(v1  . . .   vi1). The sequential model is of course well studied and understood. To see how it ﬁts into
our framework: A path graph of length T has a depth of D = T and size of N = T   thus with either
gradient or prox oracles  the statistical term is dominant in Theorems 1 and 2. These lower bounds
are matched by sequential stochastic gradient descent  yielding a tight complexity of ⇥(L/pT ) and
the familiar conclusion that SGD is (worst case) optimal in this setting.

4.2 Simple parallelism: the layer graph

We now turn to a model in which M oracle queries can be made in parallel  and the results are
broadcast for use in making the next batch of M queries. This corresponds to synchronized parallelism
and fast communication between processors. The model is captured by a layer graph of width M 
depicted above for M = 3. The graph consists of T layers i = 1  . . .   T each with M nodes
vt 1  . . .   vt m whose ancestors include vt0 i for all t0 < t and i 2 [M ]. The graph has a depth of
D = T and size of N = M T . With a stochastic gradient oracle  Theorem 1 yields a lower bound of:

which is matched by accelerated mini-batch SGD (A-MB-SGD) [9  15]  establishing the optimality
of A-MB-SGD in this setting. For sufﬁciently smooth objectives  the same algorithm is also optimal
even if prox access is allowed  since Theorem 2 implies a lower bound of:

⌦✓min⇢ L
pT

 

H

T 2 +

L

pM T◆

⌦✓min⇢ L

T

 

H

T 2 +

L

pM T◆ .

5

(11)

(12)

That is  for smooth objectives  having access to a prox oracle does not improve the optimal complexity
over just using gradient access. However  for non-smooth or insufﬁciently smooth objectives  there
is a gap between (11) and (12). An optimal algorithm  smoothed A-MB-SGD  uses the prox oracle
in order to calculate gradients of the Moreau envelope of f (x; z) (cf. Proposition 12.29 of [5])  and
then performs A-MB-SGD on the smoothed objectives. This yields a suboptimality guarantee that
precisely matches (12)  establishing that the lower bound from Theorem 2 is tight for the layer graph 
and that smoothed A-MB-SGD is optimal. An analysis of the smoothed A-MB-SGD algorithm is
provided in Appendix E.1.

4.3 Delayed updates

We now turn to a delayed computation model that is typical in many asynchronous parallelization
and pipelined computation settings  e.g. when multiple processors or machines are working asyn-
chronously  reading iterates  taking some time to perform the oracle accesses and computation  then
communicating the results back (or updating the iterate accordingly) [1  6  17  19  25]. This is
captured by a “delay graph” with T nodes v1  . . .   vT and delays ⌧t for the response to the oracle
query performed at vt to become available. Hence  Ancestors(vt) = {vs | s + ⌧s  t}. Analysis is
typically based on the delays being bounded  i.e. ⌧t  ⌧ for all t. The depiction above corresponds to
⌧t = 2; the case ⌧t = 1 corresponds to the path graph. With constant delays ⌧t = ⌧  the delay graph
has depth D  T /⌧ and size N = T   so Theorem 1 gives the following lower bound when using a
gradient oracle:

H

(T /⌧ )2) +

L

pT! .

 

⌦ min( L
pT /⌧
O✓ H

T /⌧ 2 +

L

pT◆ .

Delayed SGD  with updates xt xt1  ⌘trf (xt⌧t; z)  is a natural algorithm in this setting.
Under the bounded delay assumption the best guarantee we are aware of for delayed update SGD is
(see [11] improving over [1])

This result is signiﬁcantly worse than the lower bound (13) and quite disappointing. It does not
provide for a 1/T 2 accelerated optimization rate  but even worse  compared to non-accelerated SGD
it suffers a slowdown quadratic in the delay  compared to the linear slowdown we would expect. In
particular  the guarantee (14) only allows maximum delay of ⌧ = O(T 1/4) in order to attain the
optimal statistical rate ⇥(L/pT )  whereas the lower bound allows a delay up to ⌧ = O(T 3/4).
This raises the question of whether a different algorithm can match the lower bound (13). The answer
is afﬁrmative  but it requires using an “unnatural” algorithm  which simulates a mini-batch approach
in what seems an unnecessarily wasteful way. We refer to this as a “wait-and-collect” approach: it
works in T /(2⌧ ) stages  each stage consisting of 2⌧ iterations (i.e. nodes or oracle accesses). In stage
i  ⌧ iterations are used to obtain ⌧ stochastic gradient estimates rf (xi; z2⌧i +j)  j = 1  . . .  ⌧ at the
same point xi. For the remaining ⌧ iterations  we wait for all the preceding oracle computations to
become available and do not even use our allowed oracle access. We can then ﬁnally update the xi+1
using the minibatch of ⌧ gradient estimates. This approach is also speciﬁed formally as Algorithm 2
in Appendix E.2. Using this approach  we can perform T /(2⌧ ) A-MB-SGD updates with a minibatch
size of ⌧  yielding a suboptimality guarantee that precisely matches the lower bound (13).
Thus (13) indeed represents the tight complexity of the delay graph with a stochastic gradient oracle 
and the wait-and-collect approach is optimal. However  this answer is somewhat disappointing and
leaves an intriguing open question: can a more natural  and seemingly more efﬁcient (no wasted
oracle accesses) delayed update SGD algorithm also match the lower bound? An answer to this
question has two parts: ﬁrst  does the delayed update SGD truly suffer from a ⌧ 2 slowdown as
indicated by (14)  or does it achieve linear degradation and a speculative guarantee of

(13)

(14)

(15)

Second  can delayed update SGD be accelerated to achieve the optimal rate (13). We note that
concurrent with our work there has been progress toward closing this gap: Arjevani et al. [4] showed
an improved bound matching the non-accelerated (15) for delayed updates (with a ﬁxed delay) on

O✓ H

T /⌧

+

L

pT◆ .

6

quadratic objectives. It still remains to generalize the result to smooth non-quadratic objectives 
handle non-constant bounded delays  and accelerate the procedure so as to improve the rate to (⌧ /T )2.

4.4

Intermittent communication

We now turn to a parallel computation model which is relevant especially when parallelizing across
disparate machines: in each of T iterations  there are M machines that  instead of just a single oracle
access  perform K sequential oracle accesses before broadcasting to all other machines synchronously.
This communication pattern is relevant in the realistic scenario where local computation is plentiful
relative to communication costs (i.e. K is large). This may be the case with fast processors distributed
across different machines  or in the setting of federated learning  where mobile devices collaborate to
train a shared model while keeping their respective training datasets local [18].
This is captured by a graph consisting of M parallel chains of length T K  with cross connections
between the chains every K nodes. Indexing the nodes as vt m k  the nodes vt m 1 !···! vt m K
form a chain  and vt m K is connected to vt+1 m0 1 for all m0 = 1..M. This graph generalizes the
layer graph by allowing K sequential oracle queries between each complete synchronization; K = 1
recovers the layer graph  and the depiction above corresponds to K = M = 3. We refer to the
computation between each synchronization step as a (communication) round.
The depth of this graph is D = T K and the size is N = T KM. Focusing on the stochastic gradient
oracle (the situation is similar for the prox oracle  except with the potential of smoothing a non-smooth
objective  as discussed in Section 4.2)  Theorem 1 yields the lower bound:

⌦✓min⇢ L
pT K

 

H

T 2K2 +

L

pT KM◆ .

(16)

A natural algorithm for this graph is parallel SGD  where we run an SGD chain on each machine and
average iterates during communication rounds  e.g. [18]. The updates are then given by:

xt m 0 =

xt m0 K

(17)

1

M Xm0

xt m k = xt m k1  ⌘trf (xt m k1; zt m k)  k = 1  . . .   K

(note that xt m 0 does not correspond to any node in the graph  and is included for convenience of
presentation). Unfortunately  we are not aware of any satisfying analysis of such a parallel SGD
approach. Instead  we consider two other algorithms in an attempt to match the lower bound (16).
First  we can combine all KM oracle accesses between communication rounds in order to form a
single mini-batch  giving up on the possibility of sequential computation along the “local” K node
sub-paths. Using all KM nodes to obtain stochastic gradient estimates at the same point  we can
perform T iterations of A-MB-SGD with a mini-batch size of KM  yielding an upper bound of

O✓ H

T 2 +

L

pT KM◆ .

(18)

This is a reasonable and common approach  and it is optimal (up to constant factors) when KM =
O( L2
H 2 T 3) so that the statistical term is limiting. However  comparing (18) to the lower bound (16)
we see a gap by a factor of K2 in the optimization term  indicating the possibility for signiﬁcant
gains when K is large (i.e. when we can process a large number of examples on each machine at
each round). Improving the optimization term by this K2 factor would allow statistical optimality as
long as M = O(T 3K3)—-this is a very signiﬁcant difference. In many scenarios we would expect a
modest number of machines  but the amount of data on each machine could easily be much more than
the number of communication rounds  especially if communication is across a wide area network.
In fact  when K is large  a different approach is preferable: we can ignore all but a single chain and
simply execute KT iterations of sequential SGD  offering an upper bound of

O✓ L
pT K◆ .

7

(19)

Although this approach seems extremely wasteful  it actually yields a better guarantee than (18) when
K  ⌦(T 3L2/H). This is a realistic regime  e.g. in federated learning when computation is dis-
tributed across devices  communication is limited and sporadic and so only a relatively small number
of rounds T are possible  but each device already possesses a large amount of data. Furthermore  for
non-smooth functions  (19) matches the lower bound (16).
Our upper bound on the complexity is therefore obtained by selecting either A-MB-SGD or single-
machine sequential SGD  yielding a combined upper bound of
L

O✓min⇢ L
pT K

 

H

T 2 +

pT KM

.◆

For smooth functions  there is still a signiﬁcant gap between this upper bound and the lower bound
(16). Furthermore  this upper bound is not achieved by a single algorithm  but rather a combination
of two separate algorithms  covering two different regimes. This raises the question of whether there
is a single  natural algorithm  perhaps an accelerated variant of the parallel SGD updates (17)  that at
the very least matches (20)  and preferably also improves over them in the intermediate regime or
even matches the lower bound (16).
Active querying and SVRG All methods discussed so far used fully stochastic oracles  requesting
a gradient (or prox computation) with respect to an independently and randomly drawn z ⇠P . We
now turn to methods that also make active queries  i.e. draw samples from P and then repeatedly
query the oracle  at different points x  but on the same samples z. Recall that all of our lower bounds
are valid also in this setting.
With an active query gradient oracle  we can implement SVRG [14  16] on an intermittent com-
munication graph. More speciﬁcally  for an appropriate choice of n and   we apply SVRG to the
regularized empirical objective ˆF(x) = 1

i=1 f (x; zi) + 

2 kxk2

(20)

Algorithm 1 SVRG

Parameters: n  S  I 

nPn
Sample z1  . . .   zn ⇠P  
KM⌥ +⌃ I
K⌥⇧ do
for s = 1  2  . . .   S =⌅T /⌃ n
x0
˜x = xs1 
s = ˜x
nPn
˜g = r ˆF(˜x) = 1
for i = 1  2  . . .   I = H
Sample j ⇠ Uniform{1  . . .   n}
s = xi1
xi

i=1 rf (˜x; zi) + ˜x
 do

; zj) + xi1

s  ⌘rf (xi1
s for i ⇠ Uniform{1  . . .   I}

end for
xs = xi

s

s

end for
Return xS

Initialize x0 = 0

  (rf (˜x; zj) + ˜x) + ˜g

(⇤)

(⇤⇤)

(21)

To do so  we ﬁrst pick a sample {z1  . . . zn} (without actually querying the oracle). As indicated
by Algorithm 1  we then alternate between computing full gradients on {z1  . . . zn} in parallel (⇤) 
and sequential variance-reduced stochastic gradient updates in between (⇤⇤). The full gradient ˜g is
computed using n active queries to the gradient oracle. Since all of these oracle accesses are made
at the same point ˜x  this can be fully parallelized across the M parallel chains of length K thus
requiring n/KM rounds. The sequential variance-reduced stochastic gradient updates cannot be
parallelized in this way  and must be performed using queries to the gradient oracle in just one of
the M available parallel chains  requiring I/K rounds of synchronization. Consequently  each outer

K⌥ rounds. We analyze this method using  =⇥ ⇣ Lpn⌘ 
iteration of SVRG requires⌃ n
log(M KT /L)⌘o. Using the
I =⇥  H
analysis of Johnson and Zhang [14]  SVRG guarantees that  with an appropriate stepsize  we have
ˆF(xS)  minx ˆF(x)  2S; the value of xS on the empirical objective also generalizes to the
population  so E [f (xS; z)]  minx E [f (x; z)]  2S + O⇣ Lpn⌘ (see [23]). With our choice of
parameters  this implies upper bound (see Appendix E.3)

H 2 log2(M KT /L)⌘   ⇥⇣ M KT

L ⌘  and n = minn⇥⇣

 =⇥ ⇣ Hpn

KM⌥ +⌃ I

K2T 2L2

O✓✓ H

T K

+

L

pT KM◆ log✓ T KM

L ◆◆ .

8

These guarantees improve over sequential SGD (17) as soon as M > log2(T KM/L) and K >
H 2/L2  i.e. L/pT K < L2/H. This is a very wide regime: we require only a moderate number
of machines  and the second condition will typically hold for a smooth loss. Intuitively  SVRG
does roughly the same number (up to a factor of two) of sequential updates as in the sequential
SGD approach but it uses better  variance reduced updates. The price we pay is in the smaller total
sample size since we keep calling the oracle on the same samples. Nevertheless  since SVRG only
needs to calculate the “batch” gradient a logarithmic number of times  this incurs only an additional
logarithmic factor.
Comparing (18) and (21)  we see that SVRG also improves over A-MB-SGD as soon as K >
T log(T KM/L)  that is if the number of points we are processing on each machine each round is
slightly more then the total number of rounds  which is also a realistic scenario.
To summarize  the best known upper bound for optimizing with intermittent communication using a
pure stochastic oracle is (20)  which combines two different algorithms. However  with active oracle
accesses  SVRG is also possible and the upper bound becomes:

O✓min⇢ L
pT K

  ✓ H

T K

+

L

pT KM◆ log✓ T KM
L ◆  

H
T 2 +

L

pT KM◆

(22)

5 Summary

Our main contributions in this paper are: (1) presenting a precise formal oracle framework for
studying parallel stochastic optimization; (2) establishing tight oracle lower bounds in this framework
that can then be easily applied to particular instances of parallel optimization; and (3) using the
framework to study speciﬁc settings  obtaining optimality guarantees  understanding where additional
assumptions would be needed to break barriers  and  perhaps most importantly  identifying gaps in
our understanding that highlight possibilities for algorithmic improvement. Speciﬁcally 

• For non-smooth objectives and a stochastic prox oracle  smoothing and acceleration can
improve performance in the layer graph setting. It is not clear if there is a more direct
algorithm with the same optimal performance  e.g. averaging the answers from the prox
oracle.

• In the delay graph setting  delayed update SGD’s guarantee is not optimal. We suggest an
alternative optimal algorithm  but it would be interesting and beneﬁcial to understand the
true behavior of delayed update SGD and to improve it as necessary to attain optimality.
• With intermittent communication  we show how different methods are better in different
regimes  but even combining these methods does not match our lower bound. This raises
the question of whether our lower bound is achievable. Are current methods optimal? Is the
true optimal complexity somewhere in between? Even ﬁnding a single method that matches
the current best performance in all regimes would be a signiﬁcant advance here.

• With intermittent communication  active queries allow us to obtain better performance in a
certain regime. Can we match this performance using pure stochastic queries or is there a
real gap between active and pure stochastic queries?

The investigation into optimizing over FL H B in our framework indicates that there is no advantage
to the prox oracle for optimizing (sufﬁciently) smooth functions. This raises the question of what
additional assumptions might allow us to leverage the prox oracle  which is intuitively much stronger
as it allows global access to f (·; z). One option is to assume a bound on the variance of the stochastic
oracle i.e. Ez[krf (x; z)  rF (x)k2]  2 which captures the notion that the functions f (·; z) are
somehow related and not arbitrarily different. In particular  if each stochastic oracle access  in each
node  is based on a sample of b data points (thus  a prox operation optimizes a sub-problem of size b) 
we have that 2  L2/b. Initial investigation into the complexity of optimizing over the restricted
class FL H B  (where we also require the above variance bound)  reveals a signiﬁcant theoretical
advantage for the prox oracle over the gradient oracle  even for smooth functions. This is an example
of how formalizing the optimization problem gives insight into additional assumptions  in this case
low variance  that are necessary for realizing the beneﬁts of a stronger oracle.

9

Acknowledgements

We would like to thank Ohad Shamir for helpful discussions. This work was partially funded by
NSF-BSF award 1718970 (“Convex and Non-Convex Distributed Learning”) and a Google Research
Award. BW is supported by the NSF Graduate Research Fellowship under award 1754881. AS was
supported by NSF awards IIS-1447700 and AF-1763786  as well as a Sloan Foundation research
award.

References
[1] Alekh Agarwal and John C Duchi. Distributed delayed stochastic optimization. In Advances in

Neural Information Processing Systems  pages 873–881  2011.

[2] Naman Agarwal and Elad Hazan. Lower bounds for higher-order convex optimization. arXiv

preprint arXiv:1710.10329  2017.

[3] Yossi Arjevani and Ohad Shamir. Communication complexity of distributed convex learning
and optimization. In Advances in Neural Information Processing Systems  pages 1756–1764 
2015.

[4] Yossi Arjevani  Ohad Shamir  and Nathan Srebro. A tight convergence analysis for stochastic

gradient descent with delayed updates. 2018.

[5] Heinz H Bauschke  Patrick L Combettes  et al. Convex analysis and monotone operator theory

in Hilbert spaces  volume 2011. Springer  2017.

[6] Dimitri P Bertsekas. Parallel and distributed computation: numerical methods  volume 23.

Prentice hall Englewood Cliffs  NJ  1989.

[7] Mark Braverman  Ankit Garg  Tengyu Ma  Huy L Nguyen  and David P Woodruff. Communica-
tion lower bounds for statistical estimation problems via a distributed data processing inequality.
In Proceedings of the forty-eighth annual ACM symposium on Theory of Computing  pages
1011–1020. ACM  2016.

[8] Yair Carmon  John C Duchi  Oliver Hinder  and Aaron Sidford. Lower bounds for ﬁnding

stationary points i. arXiv preprint arXiv:1710.11606  2017.

[9] Andrew Cotter  Ohad Shamir  Nati Srebro  and Karthik Sridharan. Better mini-batch algorithms
via accelerated gradient methods. In Advances in neural information processing systems  pages
1647–1655  2011.

[10] John Duchi  Feng Ruan  and Chulhee Yun. Minimax bounds on stochastic batched convex
optimization. In Proceedings of the 31st Conference On Learning Theory  pages 3065–3162 
2018.

[11] Hamid Reza Feyzmahdavian  Arda Aytekin  and Mikael Johansson. An asynchronous mini-
IEEE Transactions on Automatic

batch algorithm for regularized stochastic optimization.
Control  61(12):3740–3754  2016.

[12] Ankit Garg  Tengyu Ma  and Huy Nguyen. On communication cost of distributed statistical
estimation and dimensionality. In Advances in Neural Information Processing Systems  pages
2726–2734  2014.

[13] Cristóbal Guzmán and Arkadi Nemirovski. On lower complexity bounds for large-scale smooth

convex optimization. Journal of Complexity  31(1):1–14  2015.

[14] Rie Johnson and Tong Zhang. Accelerating stochastic gradient descent using predictive variance

reduction. In Advances in Neural Information Processing Systems  2013.

[15] Guanghui Lan. An optimal method for stochastic composite optimization. Mathematical

Programming  133(1-2):365–397  2012.

10

[16] Jason D Lee  Qihang Lin  Tengyu Ma  and Tianbao Yang. Distributed stochastic variance
reduced gradient methods by sampling extra data with replacement. The Journal of Machine
Learning Research  18(1):4404–4446  2017.

[17] Brendan McMahan and Matthew Streeter. Delay-tolerant algorithms for asynchronous dis-
tributed online learning. In Advances in Neural Information Processing Systems  pages 2915–
2923  2014.

[18] H. Brendan McMahan  Eider Moore  Daniel Ramage  Seth Hampson  and Blaise Aguera
In

y Arcas. Communication-efﬁcient learning of deep networks from decentralized data.
Artiﬁcial Intelligence and Statistics  2017.

[19] A Nedi´c  Dimitri P Bertsekas  and Vivek S Borkar. Distributed asynchronous incremental

subgradient methods. Studies in Computational Mathematics  8(C):381–407  2001.

[20] Arkadi Nemirovski. On parallel complexity of nonsmooth convex optimization. Journal of

Complexity  10(4):451–463  1994.

[21] Arkadii Nemirovski  David Borisovich Yudin  and Edgar Ronald Dawson. Problem complexity

and method efﬁciency in optimization. 1983.

[22] Yurii Nesterov. A method of solving a convex programming problem with convergence rate o

(1/k2). 1983.

[23] Shai Shalev-Shwartz and Nathan Srebro. Svm optimization: inverse dependence on training set

size. In International Conference on Machine Learning  pages 928–935  2008.

[24] Eric V Slud et al. Distribution inequalities for the binomial law. The Annals of Probability  5

(3):404–412  1977.

[25] Suvrit Sra  Adams Wei Yu  Mu Li  and Alex Smola. Adadelay: Delay adaptive distributed

stochastic optimization. In Artiﬁcial Intelligence and Statistics  pages 957–965  2016.

[26] Jialei Wang  Weiran Wang  and Nathan Srebro. Memory and communication efﬁcient distributed

stochastic optimization with minibatch prox. In Conference on Learning Theory  2017.

[27] Blake Woodworth and Nathan Srebro. Lower bound for randomized ﬁrst order convex opti-

mization. arXiv preprint arXiv:1709.03594  2017.

[28] Blake Woodworth and Nati Srebro. Tight complexity bounds for optimizing composite objec-

tives. In Advances in Neural Information Processing Systems  pages 3639–3647  2016.

[29] Yuchen Zhang  John Duchi  Michael I Jordan  and Martin J Wainwright. Information-theoretic
lower bounds for distributed statistical estimation with communication constraints. In Advances
in Neural Information Processing Systems  pages 2328–2336  2013.

11

,Blake Woodworth
Jialei Wang
Adam Smith
Brendan McMahan
Nati Srebro