2019,MarginGAN: Adversarial Training in Semi-Supervised Learning,A Margin Generative Adversarial Network (MarginGAN) is proposed for semi-supervised learning problems. Like Triple-GAN  the proposed MarginGAN consists of three components---a generator  a discriminator and a classifier  among which two forms of adversarial training arise. The discriminator is trained as usual to distinguish real examples from fake examples produced by the generator. The new feature is that the classifier attempts to increase the margin of real examples and to decrease the margin of fake examples. On the contrary  the purpose of the generator is yielding realistic and large-margin examples in order to fool the discriminator and the classifier simultaneously. Pseudo labels are used for generated and unlabeled examples in training. Our method is motivated by the success of large-margin classifiers and the recent viewpoint that good semi-supervised learning requires a ``bad'' GAN. Experiments on benchmark datasets testify that MarginGAN is orthogonal to several state-of-the-art methods  offering improved error rates and shorter training time as well.,MarginGAN: Adversarial Training in

Semi-Supervised Learning

Jinhao Dong

School of Computer Science and Technology 

Xidian University

Xi’an 710126  China

jhdong@stu.xidian.edu.cn

Tong Lin∗

Key Laboratory of Machine Perception  MOE
School of EECS  Peking University  Beijing 

& Peng Cheng Laboratory  Shenzhen

lintong@pku.edu.cn

Abstract

A Margin Generative Adversarial Network (MarginGAN) is proposed for semi-
supervised learning problems. Like Triple-GAN  the proposed MarginGAN con-
sists of three components—a generator  a discriminator and a classiﬁer  among
which two forms of adversarial training arise. The discriminator is trained as usual
to distinguish real examples from fake examples produced by the generator. The
new feature is that the classiﬁer attempts to increase the margin of real examples
and to decrease the margin of fake examples. On the contrary  the purpose of
the generator is yielding realistic and large-margin examples in order to fool the
discriminator and the classiﬁer simultaneously. Pseudo labels are used for generat-
ed and unlabeled examples in training. Our method is motivated by the success
of large-margin classiﬁers and the recent viewpoint that good semi-supervised
learning requires a “bad” GAN. Experiments on benchmark datasets testify that
MarginGAN is orthogonal to several state-of-the-art methods  offering improved
error rates and shorter training time as well.

1

Introduction

In the real world  unlabeled data can usually be obtained relatively easily  while manually labeled
data costs a lot. Therefore  semi-supervised learning (SSL)  which learns by using large amounts of
unlabeled data with limited labeled data  meets a variety of practical needs.
Pseudo labels are artiﬁcial labels of unlabeled data to play the same role as labels of manually
annotated data  which is a simple and effective method in semi-supervised learning. Several traditional
SSL methods  such as self-training [1–3] and co-training [4]  are based on pseudo labels. In the past
few years  deep neural network has made a great advancement in SSL  and hence the idea of pseudo
labels is incorporated into deep learning to leverage unlabeled data. In [5] the class with the maximum
predicted probability is picked as the pseudo label. Temporal Ensembling proposed in [6] uses a
ensemble prediction as the pseudo label  which is an exponential moving average of label predictions
on different epochs  under different regularization and input augmentation conditions. In contrast
to [6] where label predictions are averaged  in the Mean Teacher approach [7] model weights are
averaged instead. The role pseudo labels play in [5] and [6  7] is not exactly the same. Pseudo labels
in [5] have the identical effect with ground-truth labels to minimize the cross-entropy loss  whereas
pseudo labels in [6  7] serve as targets for the prediction to achieve consistency regularization  which
can make the classiﬁer give consistent outputs for similar data points.
Recently  generative adversarial networks (GANs) has been applied to SSL and obtained amazing
results. The method of Feature Matching (FM) GANs proposed in [8] substitutes the original binary

∗T. Lin is the corresponding author.

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

Figure 1: The architecture of MarginGAN.

discriminator with a (K + 1)-class classiﬁer. The aim of the classiﬁer (i.e. the discriminator) is to
classify labeled samples into the correct class  unlabeled samples into any of the ﬁrst K classes and
generated samples into the (K +1)-th class. As a improvement of feature matching GANs  the method
proposed in [9] veriﬁes that good semi-supervised learning requires a “bad” generator. The proposed
complement generator can yield artiﬁcial data points in low-density areas  thus encouraging the
classiﬁer to place the class boundaries in these areas and to improve the generalization performance.
Although the idea of using pseudo labels is simple and effective in deep learning  sometimes it might
happen that the incorrect pseudo labels will impair the generalization performance and slow down
the training of deep networks. Prior works such as [6  7] make efforts on how to improve the quality
of pseudo labels. Inspired by [9]  we propose a method that encourages the generator to yield “bad”
examples in SSL  so as to increase the tolerance of incorrect pseudo labels and reduce the error rates
further.
To address the issue caused by the incorrect pseudo labels  we present MarginGAN  a GAN model
in semi-supervised learning based on margin theory of classiﬁers. MarginGAN consists of three
components—a generator  a discriminator and a classiﬁer (See Fig. 1 for the architecture of Margin-
GAN). The role of the discriminator is same as in standard GAN  distinguishing whether a example
is from the real distribution or produced by the generator. The multi-class classiﬁer is trained to
increase the classiﬁcation margin of real examples (including labeled samples and unlabeled samples) 
and decreases the margin of generated fake examples meanwhile. The goal of the generator is to
yield bogus examples that look like realistic and have large margin  aiming at deceiving both the
discriminator and the classiﬁer simultaneously.
The paper is organized as follows. Section 2 brieﬂy reviews related work  and our proposed Margin-
GAN is described in Section 3. Experimental results are presented in Section 4. Section 5 concludes
this paper.

2 Related Work

The research of semi-supervised learning dates back to 1970s  and there have emerged many classical
SSL algorithms since then. Self-training [1–3] is probably the ﬁrst SSL algorithm  which selects
the unlabeled examples with the surest predictions and puts them into the labeled sample set in
each iteration. Co-training [4] trains two classiﬁer on two different views of the labeled examples
respectively  and each classiﬁer puts the unlabeled examples with the highest prediction conﬁdence
into the labeled dataset of the other classiﬁer. The above two methods can be regarded as methods
using pseudo labels. Graph-based semi-supervised learning [10  11] constructs a neighborhood
graph according to the geometric structure between the samples  and propagates the label from
labeled samples to unlabeled samples utilizing the adjacency relation on the graph based on manifold
hypothesis.
Recently  deep neural networks have made a great progress in SSL. As already discussed  the idea of
pseudo labels is also used in [5–7]. To reduce the instability brought by pseudo labels  a coefﬁcient
α(t) is used in [5] to balance labeled samples and unlabeled examples. α(t) is set slowly increased
so that the low weights can reduce the negative effect of unreliable pseudo labels. In [6  7] the quality

2

of pseudo labels is improved by keeping an exponential moving average of predictions or model
weights  respectively. Our work focuses on another perspective that the classiﬁer learns from auxiliary
generated examples. Besides [9]  virtual adversarial training proposed in [12  13] is similar to our
approach in spirit.
Recent methods leveraging GANs achieve amazing results in SSL. It is worth noting that CatGAN
proposed in [14] shares a similar ﬂavor to our margin-based method. The classiﬁer of CatGAN
minimizes the conditional entropy of real samples  while maximizing the conditional entropy of
generated fake examples at the same time. Triple-GAN [15] also adopts a three-player architecture 
where the generator and the classiﬁer characterize the conditional distributions between examples and
labels  and the discriminator solely focuses on identifying fake example-label pairs. Triangle-GAN
[16] develops a more complex architecture consisting of two generators and two discriminators.
In [17] Structured Generative Adversarial Networks (SGANs) are proposed for semi-supervised
conditional generative modeling  which can better manipulate the semantics of generated examples.
Besides the methods mentioned above  there has been other efforts in semi-supervised learning
using deep generative models. In [18] the Ladder network was extended to the area of SSL. In [19]
an unsupervised regularization term was proposed to explicitly enforce that the predictions of the
multi-class classiﬁer should be mutually-exclusive.

3 The Proposed MarginGAN

3.1 Motivation and Intuition

In a usual GAN model  the goal is to train a generator that can produce realistic fake examples such
that a discriminator can not discern real or fake examples. However in SSL problems our purpose
is to train a high-accuracy classiﬁer achieving large margins of training examples. We hope that
the generator can yield “informative” examples near the true decision boundary  just like support
vectors in the SVM models. Here another kind of adversarial training arises: the generator attempts to
produce large-margin fake examples  while the classiﬁer aims at achieving small-margin predictions
over these fake examples.
Wrong pseudo labels of unlabeled examples (and fake examples) greatly deteriorate the accuracy
of prior methods based on pseudo labels  but our MarginGAN exhibits a better tolerance to wrong
pseudo labels. Since the discriminator plays the same role in a usual GAN  we argue that the improved
accuracy obtained by MarginGAN comes from adversarial interactions between the generator and the
classiﬁer.
First  the extreme training case in our ablation study (in Sec. 4.2) show that fake examples generated
by MarginGAN can aggressively remedy the inﬂuence of wrong pseudo labels. Because the classiﬁer
enforces the small margin values of fake examples  the generator must yield fake examples near the
“correct” decision boundaries. This will reﬁne and shrink the decision boundary for surrounding the
real examples.
Second  we illustrate the large-margin intuition on a four-class problem in Fig. 2. If the classiﬁer
chooses to believe the wrong pseudo labels  the decision boundaries have to stride over the “real”
gap between the two classes of examples. But wrong pseudo labels lead to reduced values in margin 
which hurts the generalization accuracy. Therefore  large margin classiﬁers should ignore those
wrong pseudo labels for achieving higher accuracy.

3.2 Margin

Deﬁnition of margins
In machine learning  the margin of a single data point is deﬁned to be the
distance from that data point to a decision boundary  which can be used to bound the generalization
error of the classiﬁer. Both support vector machines (SVM) and boosting can be explainable with
margin-based generalization bounds.
In the AdaBoost algorithm  ht(x) ∈ {1 −1} is a base classiﬁer acquired in iteration t and αt ≥ 0 is
its corresponding weight assigned to ht. The combined classiﬁer f is a weighted majority vote of T

3

Figure 2: A illustration to show that wrong pseudo labels may cause decision boundaries across the
true gap between two classes. A large-margin classiﬁer would disregard those wrong pseudo labels to
get better generalization.

base classiﬁers  which is formulated as

f (x) =

In [20] the margin of an instance-label pair (x  y) is deﬁned as

(cid:80)T
(cid:80)T
y(cid:80)T
(cid:80)T

t=1 αtht(x)

.

s=1 αs

t=1 αtht(x)

s=1 αs

yf (x) =

.

(1)

The sign of the margin reﬂects whether or not the prediction of the combined classiﬁer is correct 
while the magnitude indicates the prediction conﬁdence. It is interesting that Eq. 1 can bring a uniﬁed
form for both boosting and SVM:

y(cid:104)α  h(x)(cid:105)
(cid:107)α(cid:107) (cid:107)h(x)(cid:107)  

where h(x)
for h and (cid:96)1 norm is used for α; and for SVM  (cid:96)2 norm is used for both h and α.

.
= [h1(x)  h2(x)  ...  hT (x)] and α

.
= [α1  α2  ...  αT ]. For boosting  (cid:96)∞ norm is used

Margins in semi-supervised learning [21] propose the margin of an unlabeled example denoted

as |f (x)|  that can be also represented as(cid:101)yf (x) with pseudo label(cid:101)y = sign(f (x)). This way just

regards the current prediction is correct and makes the classiﬁer more certain of what it predicts
currently. Regardless of labeled and unlabeled examples  larger margins of data points can decrease
the upper bound of the generalization error  which brings about better generalization performance.

layer  so the output is a discrete distribution such that(cid:80)k

Margins of multi-class classiﬁcation We set our problem in multi-class problems: for an instance-
label pair (x  y)  y ∈ Rk is the ground-truth label in one-hot encoding and C(x) ∈ Rk is the
prediction of the multi-class classiﬁer C. The last layer of the classiﬁer network is usually a softmax
i=1 Ci(x) = 1. The margin in multi-
class problems is deﬁned as the difference between the probability for the true class and maximal
probability for the false classes:

Margin(x  y) = Cy(x) − max
i(cid:54)=y

Ci(x).

(2)

It is evident that if the margin is a large positive number  the probability of the correct class is
peaked in the distribution [C(x)1  C(x)2  . . .   C(x)k]  indicating that the classiﬁer is conﬁdent of its
prediction. On the contrary  if the margin is a small positive number  the distribution is ﬂat and the
classiﬁer is uncertain of its prediction  which has a similar ﬂavor to CatGAN proposed in [14]. The
classiﬁer makes a mistake decision when the margin is negative.

4

3.3 Architecture Overview

The original architecture of GAN consists of two components  a generator and a discriminator  that
play a zero-sum game. The generator G transforms a latent variable z∼p(z) to a fake example
ˆx∼pg(ˆx) such that the generated distribution pg(ˆx) approximates the real data distribution p(x).
The discriminator D is to distinguish generated fake examples from real examples. For adapting
to semi-supervised learning  we add a classiﬁer C to the original architecture  which forms a three-
player game. We retain the discriminator for encouraging the generator to produce visually realistic
examples. We describe each of the components as follows. The architecture of MarginGAN is
depicted in Fig. 1.

3.4 Discriminator

The discriminator D of MarginGAN receives three kinds of inputs  labeled examples x drawn from

p[l](x)  unlabeled examples(cid:101)x drawn from p[u]((cid:101)x) and generated examples G(z) = ˆx∼pg(ˆx). In our
Loss(D) = −(cid:8)Ex∼p[l](x)[log(D(x))] + E(cid:101)x∼p[u]((cid:101)x)[log(D((cid:101)x))] + Ez∼p(z)[log(1 − D(G(z)))](cid:9).

SSL setting  the discriminator should regard both labeled examples and unlabeled examples as real
data points  and discern generated examples as fake data points. We deﬁne the loss function for the
discriminator as

3.5 Classiﬁer

We add a multi-class classiﬁer C to the original GAN  as high-accuracy classiﬁcation is our purpose
in SSL. We develop the classiﬁer from the perspective of margins. The classiﬁer receives the same
inputs as the discriminator—labeled examples  unlabeled examples and generated fake examples. In
the following we will detail the corresponding objective of the classiﬁer for each input.
For labeled examples  the classiﬁer has the same objective as ordinary multi-class classiﬁers. Given
an instance-label pair (x  y)  the classiﬁer C attempts to minimize the cross-entropy loss between the
true label y and the predicted label C(x):

LossCE(y  C(x)) = − T(cid:88)

where y∈Rk is in one-hot encoding  and C(x)∈Rk is the prediction. And the loss function for the
labeled examples can be formulated as

Loss(C [l]) = E(x y)∼p[l](x y) [LossCE(y  C(x))]

= E(x y)∼p[l](x y)

.

(3)

yi log(C(x)i) 

i=1

(cid:34)
− k(cid:88)

i=1

yi log(cid:0)C(x)i

(cid:1)(cid:35)

Note that minimizing the cross-entropy encourages the increase of the probability of the true class
and inhibits the probability of other false classes  leading to a larger margin deﬁned in Eq. 2.
For unlabeled examples  the goal of the classiﬁer is to increase the margin of these data points.
However  since there is no information about the corresponding true label  we have no idea which

class probability should be peaked. Like [5–7  21]  we leverage the pseudo label(cid:101)y[u]∈Rk in one-hot
encoding for unlabeled examples. That is  the(cid:101)y[u] vector has 1 at the only entry corresponding to
the class with the maximum predicted probability of the current predict C((cid:101)x)  while other entries
between (cid:101)y[u] and C((cid:101)x).

are exactly zeros. With pseudo labels  we can increase the margin by minimizing the cross-entropy
Intuitively  this objective will reinforce the conﬁdence of the current

predictions. The loss function is given as

Loss(C [u]) = E(cid:101)x∼p[u]((cid:101)x)
= E(cid:101)x∼p[u]((cid:101)x)

(cid:104)
(cid:105)
LossCE((cid:101)y[u]  C((cid:101)x))
(cid:34)
(cid:35)
− k(cid:88)
log(C((cid:101)x)i)

(cid:101)y[u]

i

i=1

 

(4)

which has the same form as Eq. 3.

5

When it comes to generated examples  the classiﬁer should decrease the margin of these data points
and make the prediction distribution ﬂat. The generated examples are another form of unlabeled data 
and we take the same way to use pseudo label. In order to decrease the margin of generated examples 
we introduce a new loss function  Inverted Cross Entropy (ICE) between two distributions

LossICE(p  q) = − k(cid:88)

pi log(1 − qi) 

where p  q∈Rk. Minimizing the inverted cross entropy will increase the cross-entropy between the

pseudo label(cid:101)y[g] and C(G(z))  so that the prediction distribution will be ﬂat and the margin will be

i=1

decreased. The loss function for generated examples is

Loss(C [g]) = Ez∼p(z)

= Ez∼p(z)

(cid:104)
(cid:105)
LossICE((cid:101)y[g]  C(G(z)))
(cid:34)
− k(cid:88)

log(1 − C(G(z))i)

(cid:101)y[g]

i

(cid:35)

.

(5)

Combining three loss functions deﬁned in Eq. 3  4 and 5 altogether  we obtain the integrated loss
function of the classiﬁer

Loss(C) = Loss(C [l]) + Loss(C [u]) + Loss(C [g]).

(6)

i=1

3.6 Generator

The purpose of G is to produce bogus examples that looks like realistic to the discriminator D and
improves the generalization of classiﬁer C meanwhile. From this perspective  C and D form an
alliance to compete with G  while G attempts to fool both C and D. On the one hand  just like the
standard GAN  the objective of G is to generate fake data points that D can not distinct. On the other
hand  because C increases the margin of real examples and decreases the margin of fake examples  G
should compete to yield data points having large margin to fool C. Therefore  in order to fool both D
and C  G tries to yield realistic and large-margin examples simultaneously such that the generated
fake data points can not easily separated from real examples. In a nutshell  the loss function of G is
formulated as

(cid:104)

(cid:105)
LossCE((cid:101)y[g]  C(G(z)))

.

Loss(G) = −Ez∼p(z)

log (D(G(z)))

+ Ez∼p(z)

(cid:104)

3.7 Minimax Game

To adapt the loss function of MarginGAN into a similar form of the original GAN  we combine all
the loss functions of each component into a minimax problem:

G

min

max
D C

J(G  D  C)

(cid:110)
Ex∼p[l](x)[log(D(x))] + E(cid:101)x∼p[u]((cid:101)x)[log(D((cid:101)x))] + Ez∼p(z)[log(1 − D(G(z)))]
−(cid:110)
E(x y)∼p[l](x y)[LossCE(y  C(x))] + E(cid:101)x∼p[u]((cid:101)x)

(cid:104)
LossCE((cid:101)y[u]  C((cid:101)x))

(cid:105)

=

(cid:111)

(cid:104)
(cid:105)(cid:111)
LossICE((cid:101)y[g]  C(G(z)))

 

+Ez∼p(z)

where the ﬁrst part is a minimax game between G and D  and the second part is between G and C.
Instead  we can view the minimax game from the perspective of margin:

G

min

max
D C

J(G  D  C)

(cid:110)
Ex∼p[l](x)[log(D(x))] + E(cid:101)x∼p[u]((cid:101)x)[log(D((cid:101)x))] + Ez∼p(z)[log(1 − D(G(z)))]
(cid:110)

(cid:104)

(cid:111)

(cid:105)
Margin((cid:101)x (cid:101)y[u])

(cid:2)Margin(x  y)(cid:3) + E(cid:101)x∼p[u]((cid:101)x)
(cid:104)
(cid:105)(cid:111)
1 − Margin(G(z) (cid:101)y[g])

 

E(x y)∼p[l](x y)

+Ez∼p(z)

=

+

= (cid:104)y  log(1− C(x))(cid:105). In practice 
.
if we redeﬁne Margin(x  y)
each time any of three networks (D  C and G) is trained with gradient descent over one example or a
mini-batch with other two networks being ﬁxed  same as the training procedure of an usual GAN.

= (cid:104)y  log C(x)(cid:105) and 1− Margin(x  y)
.

(cid:105)

6

Table 1: Error rates (%) on MNIST with 100  600  1000 and 3000 labeled examples in semi-supervised
learning. The results of competing methods come from [5]. Means and stardard errors are reported
for our method on 5 runs.

# of labels
NN
SVM
CNN
TSVM
DBN-rNCA
EmbedNN
CAE
MTC
dropNN
+PL
+PL+DAE
MarginGAN (ours)

100
25.81
23.44
22.98
16.81
—
16.86
13.47
12.03
21.89
16.15
10.49
3.53 ± 0.57

600
11.44
8.85
7.68
6.16
8.70
5.97
6.30
5.13
8.57
5.03
4.01
3.03 ± 0.60

1000
10.70
7.77
6.45
5.38
—
5.73
4.77
3.64
6.59
4.30
3.46
2.87 ± 0.71

3000
6.04
4.21
3.35
3.45
3.30
3.59
3.22
2.57
3.72
2.80
2.69
2.06 ± 0.20

4 Experiments

4.1 Preliminary Experiment on MNIST

Similar to our work  pseudo labels are employed in prior work [5] and experiments on MNIST are
reported. To show the improvement brought by MarginGAN clearly  we ﬁrst conduct a preliminary
experiment on MNIST. We use the generator and the discriminator from the infoGAN [22]  and use a
simple convolutional network with six layers as the classiﬁer. Although the classiﬁer we use might
be powerful than that used in [5]  the subsequent ablation study can reveal the contribution brought
by generated fake examples.
MNIST consists of a training set of 60 000 images and a test set of 10 000 images  with all images
of 28 by 28 gray-scale pixels. In settings  we sample 100  600  1000 or 3000 labeled examples and
use the rest of the training set as unlabeled samples. When training  we ﬁrst pretrain the classiﬁer
to achieve the error rate lower than 8.0%  9.3%  9.5% and 9.7%  only with the labeled examples 
respectively corresponding to 100  600  1000 and 3000 labeled examples. Then  the unlabeled
samples and generated samples engage in the training process. Table 1 compares our results against
other competing methods from [5]. We can see that the proposed MarginGAN outperforms these
pseudo label based previous methods on each setting  which can be attributed to the participation of
generated fake examples. Although this comparison with dated algorithms is somewhat unfair  our
method does achieve higher accuracies under all settings and the subsequent ablation study further
veriﬁes the improvements of our method.

4.2 Ablation Study on MNIST

To ﬁnd out the inﬂuence of labeled examples  unlabeled examples and generated fake examples  we
ran ablation experiments with one or several types of examples fed as input at a time. In the ablation
study  because of the instability of pseudo labels and lack of labeled examples in some cases  we
decrease the learning rate from 0.1 to 0.01. We measured the lowest error rates and time consumed to
training convergence in different settings  and the results are reported in Table 2.

Unlabeled examples Unlabeled examples plays an important role in semi-supervised learning. We
can see that the addition of unlabeled examples can reduce the error rate from 8.21% to 4.54% with
3.67% improvement. To verify the uncertainty of the correctness of pseudo labels  we conducted an
extreme attempt: the classiﬁer was pretrained to achieve the error rate of 9.78% (± 0.14%)  and then
we fed the classiﬁer with unlabeled examples alone. In other words  the classiﬁer can not access the
labeled examples again. To our surprise  the error rate blew up and quickly reached to over 89.53%.
The incorrect pseudo labels will mislead the classiﬁer and hinder its generalization.

7

Table 2: Ablation study of our algorithm on MNIST. The amount of labeled examples in this
experiment is 600. The abbreviations of L  U and G correspond to labeled  unlabeled and generated
examples  respectively. The last two rows show an extreme training situation.

Settings
L

Normal
Training L + U

L + U + G

Extreme U
Training U + G

Error Rates (%) Training Time (sec.)
408.41 ± 26.17
1305.64 ± 495.18
367.79 ± 82.82
—
886.83 ± 193.98

8.21 ± 0.82
4.54 ± 0.41
3.20 ± 0.62
89.53 ± 0.81
7.40 ± 5.01

Table 3: Means and standard errors of the error rates (%) on SVHN and CIFAR-10 over 4 runs.

METHODS

Ladder [18]
CatGAN [14]
FM GANs [8]
Triple-GAN [15]
SGAN [17]

(cid:81) model [7]

MarginGAN (ours)

SVHN
(500 labels)
—
—
—
—
—
6.83 ± 0.66
6.07 ± 0.43

CIFAR-10
(1000 labels)

27.36 ± 1.20
10.39 ± 0.43

CIFAR-10
(4000 labels)
— 20.04 ± 0.47
— 19.58 ± 0.58
— 18.63 ± 2.32
— 18.82 ± 0.32
— 17.26 ± 0.69
13.20 ± 0.27
6.44 ± 0.10

Generated fake examples We fed generated examples to the classiﬁer  making it robust to wrong
pseudo labels and improving the performance. We can see that  compared with training of only
labeled samples and unlabeled samples  the generated examples can further improve the error rates
from 4.54% to 3.20%. Moreover  it’s worth noting that the generated examples can remarkably
reduce the training time consumed by 71.8%. However when we continue to train  the error rate
starts to increase and overﬁtting arises. When the generated images are more realistic gradually 
the classiﬁer still reduces their margins  which might harm the performance. Back to the extreme
situation mentioned above  when combining unlabeled images and generated images after pretraining 
the error rates can be improved indeed (from 9.78% to 7.40%).

4.3 Results on SVHN and CIFAR-10

Next we run our MarginGAN method on two standard datasets in SSL—SVHN and CIFAR-10. We
employ a 12-block residual network [23] with Shake-Shake regularization [24] as our classiﬁer  which
is same as the ResNet version used in the mean teacher implementation. Our algorithm integrates the
generator and the discriminator from the infoGAN [22] into this residual network. We also use the
mean teacher training for averaging model weights over recent training examples.
The details of SVHN and CIFAR-10 datasets are as follows. SVHN contains of 73 257 digits for
training and 26 032 digits for testing  with each digit being a 32 × 32 RGB image. The CIFAR-10
dataset consists of 50 000 training samples and 10 000 test samples of 32 × 32 color images of 10
object classes. On SVHN we randomly select 500 labeled samples. And we use 1 000 and 4 000
labels to train on CIFAR-10  respectively. Table 3 shows the results of experiments on the SVHN and
CIFAR-10 datasets. We can see the improvements brought by our method.

4.4 Generated Fake Images

We show the images generated by MarginGAN in Fig. 3 when the accuracy of classiﬁer is increasing.
As we can see  these fake images really look “bad”: for instance  most generated digits in MNIST
and SVHN are close to the decision boundaries such that one can not determine their labels with high
conﬁdence. This situation meets with our motivation of this paper.

8

(a) MNIST

(b) SVHN

(c) CIFAR-10

Figure 3: Generated fake images by MarginGAN.

5 Conclusion

In this work  we presented the Margin Generative Adversarial Network (MarginGAN)  which consists
of three players—a generator  a discriminator and a classiﬁer. The key is that the classiﬁer can leverage
fake examples produced by the generator to improve the generalization performance. Speciﬁcally 
the classiﬁer aims at maximizing margin values of true examples and minimizing margin values
of fake examples. The generator attempts to yield realistic and large-margin examples to fool both
the discriminator and the classiﬁer. The experimental results on several benchmarks show that
MarginGAN can provide improved accuracies and shorten training time as well.

9

References
[1] H. Scudder. Probability of error of some adaptive pattern-recognition machines. IEEE TIT 

1965.

[2] S. Fralick. Learning to recognize patterns without a teacher. IEEE TIT  1967.
[3] A. Agrawala. Learning with a probabilistic teacher. IEEE TIT  1970.
[4] A. Blum and T. Mitchell. Combining labeled and unlabeled data with co-training. COLT  1998.
[5] D.-H. Lee. Pseudo-label: The simple and efﬁcient semi-supervised learning method for deep

neural networks. ICML Workshop  2013.

[6] S. Laine and T. Aila. Temporal ensembling for semi-supervised learning. arXiv:1610.02242 

2016.

[7] A. Tarvainen and H. Valpola. Mean teachers are better role models: Weight-averaged consistency

targets improve semisupervised deep learning results. NeurIPS  2017.

[8] T. Salimans  I. Goodfellow  W. Zaremba  V. Cheung  A. Radford  and X. Chen. Improved

techniques for training GANs. NeurIPS  2016.

[9] Z. Dai  Z. Yang  F. Yang  W. W. Cohen  and R. Salakhutdinov. Good semi-supervised learning

that requires a bad GAN. NeurIPS  2017.

[10] A. Blum and S. Chawla. Learning from labeled and unlabeled data using graph mincuts. In

ICML  pages 19–26  2001.

[11] X. Zhu  Z. Ghahramani  and J. Lafferty. Semi-supervised learning using gaussian ﬁelds and

harmonic functions. In ICML  pages 912–919  2003.

[12] T. Miyato  S. i. Maeda  M. Koyama  and S. Ishii. Virtual adversarial training: a regularization

method for supervised and semi-supervised learning. arXiv: 1704.03976  2017.

[13] T. Miyato  S. i. Maeda  M. Koyama  K. Nakae  and S. Ishii. Distributional smoothing with

virtual adversarial training. ICLR  2016.

[14] J. T. Springenberg. Unsupervised and semi-supervised learning with categorical generative

adversarial networks. ICLR  2016.

[15] C. Li  K. Xu  J. Zhu  and B. Zhang. Triple generative adversarial nets. NeurIPS  2017.
[16] Z. Gan  L. Chen  W. Wang  Y. Pu  Y. Zhang  H. Liu  C. Li  and L. Carin. Triangle generative

adversarial networks. NeurIPS  2017.

[17] Z. Deng  H. Zhang  X. Liang  L. Yang  S. Xu  J. Zhu  and E. P. Xing. Structured generative

adversarial networks. NeurIPS  2017.

[18] A. Rasmus  M. Berglund  M. Honkala  H. Valpola  and T. Raiko. Semi-supervised learning with

ladder networks. NeurIPS  2015.

[19] M. Sajjadi  M. Javanmardi  and T. Tasdizen. Mutual exclusivity loss for semi-supervised deep

learning. ICIP  2016.

[20] R.E. Schapire and Y. Freund. Boosting: Foundations and Algorithms. MIT Press.
[21] K. P. Bennett  A. Demiriz  and R. Maclin. Exploiting unlabeled data in ensemble methods.

KDD  2002.

[22] X. Chen  Y. Duan  R. Houthooft  J.Schulman  I. Sutskever  and P. Abbeel.

InfoGAN: In-
terpretable representation learning by information maximizing generative adversarial nets.
arXiv:1606.03657  2016.

[23] K. He  X. Zhang  S. Ren  and J. Sun. Deep residual learning for image recognition. arX-

iv:1512.03385  2015.

[24] X. Gastaldi. Shake-Shake regularization. arXiv:1705.07485  2017.

10

,Jinhao Dong
Tong Lin