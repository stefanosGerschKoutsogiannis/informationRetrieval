2016,Unified Methods for Exploiting Piecewise Linear Structure in Convex Optimization,We develop methods for rapidly identifying important components of a convex optimization problem for the purpose of achieving fast convergence times. By considering a novel problem formulation—the minimization of a sum of piecewise functions—we describe a principled and general mechanism for exploiting piecewise linear structure in convex optimization. This result leads to a theoretically justified working set algorithm and a novel screening test  which generalize and improve upon many prior results on exploiting structure in convex optimization. In empirical comparisons  we study the scalability of our methods. We find that screening scales surprisingly poorly with the size of the problem  while our working set algorithm convincingly outperforms alternative approaches.,Uniﬁed Methods for Exploiting

Piecewise Linear Structure in Convex Optimization

Tyler B. Johnson

University of Washington  Seattle
tbjohns@washington.edu

Carlos Guestrin

University of Washington  Seattle

guestrin@cs.washington.edu

Abstract

We develop methods for rapidly identifying important components of a convex
optimization problem for the purpose of achieving fast convergence times. By
considering a novel problem formulation—the minimization of a sum of piecewise
functions—we describe a principled and general mechanism for exploiting piece-
wise linear structure in convex optimization. This result leads to a theoretically
justiﬁed working set algorithm and a novel screening test  which generalize and
improve upon many prior results on exploiting structure in convex optimization.
In empirical comparisons  we study the scalability of our methods. We ﬁnd that
screening scales surprisingly poorly with the size of the problem  while our working
set algorithm convincingly outperforms alternative approaches.

1

Introduction

Scalable optimization methods are critical for many machine learning applications. Due to tractable
properties of convexity  many optimization tasks are formulated as convex problems  many of which
exhibit useful structure at their solutions. For example  when training a support vector machine  the
optimal model is uninﬂuenced by easy-to-classify training instances. For sparse regression problems 
the optimal model makes predictions using a subset of features  ignoring its remaining inputs.
In these examples and others  the problem’s “structure” can be exploited to perform optimization
efﬁciently. Speciﬁcally  given the important components of a problem (for example the relevant
training examples or features) we could instead optimize a simpler objective that results in the same
solution. In practice  since the important components are unknown prior to optimization  we focus on
methods that rapidly discover the relevant components as progress is made toward convergence.
One principled method for exploiting structure in optimization is screening  a technique that identiﬁes
components of a problem guaranteed to be irrelevant to the solution. First proposed by [1]  screening
rules have been derived for many objectives in recent years. These approaches are specialized to
particular objectives  so screening tests do not readily translate between optimization tasks. Prior
works have separately considered screening irrelevant features [1–8]  training examples [9  10]  or
constraints [11]. No screening test applies to all of these applications.
Working set algorithms are a second approach to exploiting structure in optimization. By minimizing
a sequence of simpliﬁed objectives  working set algorithms quickly converge to the problem’s global
solution. Perhaps the most prominent working set algorithms for machine learning are those of the
LIBLINEAR library [12]. As is common with working set approaches  there is little theoretical
understanding of these algorithms. Recently a working set algorithm with some theoretical guarantees
was proposed [11]. This work fundamentally relies on the objective being a constrained function 
however  making it unclear how to use this algorithm for other problems with structure.
The purpose of this work is to both unify and improve upon prior ideas for exploiting structure in
convex optimization. We begin by formalizing the concept of “structure” using a novel problem

30th Conference on Neural Information Processing Systems (NIPS 2016)  Barcelona  Spain.

formulation: the minimization of a sum of many piecewise functions. Each piecewise function is
deﬁned by multiple simpler subfunctions  at least one of which we assume to be linear. With this
formulation  exploiting structure amounts to selectively replacing piecewise terms in the objective
with corresponding linear subfunctions. The resulting objective can be considerably simpler to solve.
Using our piecewise formulation  we ﬁrst present a general theoretical result on exploiting structure
in optimization. This result guarantees quantiﬁable progress toward a problem’s global solution by
minimizing a simpliﬁed objective. We apply this result to derive a new working set algorithm that
compares favorably to [11] in that (i) our algorithm results from a minimax optimization of new
bounds  and (ii) our algorithm is not limited to constrained objectives. Later  we derive a state-of-
the-art screening test by applying the same initial theoretical result. Compared to prior screening
tests  our screening result is more effective at simplifying the objective function. Moreover  unlike
previous screening results  our screening test applies to a broad class of objectives.
We include empirical evaluations that compare the scalability of screening and working set methods
on real-world problems. While many screening tests have been proposed for large-scale optimization 
we have not seen the scalability of screening studied in prior literature. Surprisingly  although our
screening test signiﬁcantly improves upon many prior results  we ﬁnd that screening scales poorly as
the size of the problem increases. In fact  in many cases  screening has negligible effect on overall
convergence times. In contrast  our working set algorithm improves convergence times considerably
in a number of cases. This result suggests that compared to screening  working set algorithms are
signiﬁcantly more useful for scaling optimization to large problems.

2 Piecewise linear optimization framework

We consider optimization problems of the form

f (x) := ψ(x) +(cid:80)m

i=1 φi(x)  

minimize

x∈Rn

(P)

where ψ is γ-strongly convex  and each φi is convex and piecewise; for each φi  we assume a function
πi : Rn → {1  2  . . .   pi} and convex subfunctions φ1
φi(x) = φπi(x)

i such that ∀x ∈ Rn  we have

i   . . .   φpi
(x) .

i

As will later become clear  we focus on instances of (P) for which many of the subfunctions φk
linear. We denote by X k
the subset of Rn corresponding to the kth piecewise subdomain of φi:

i are

i

X k

i

:= {x : πi(x) = k} .

The purpose of this work is to develop efﬁcient and principled methods for solving (P) by exploiting
the piecewise structure of f. Our approach is based on the following observation:
Proposition 2.1 (Exploiting piecewise structure at x(cid:63)). Let x(cid:63) be the minimizer of f. For each
i ∈ [m]  assume knowledge of πi(x(cid:63)) and whether x(cid:63) ∈ int(X πi(x(cid:63))
if x(cid:63) ∈ int(X πi(x(cid:63))
)  
otherwise  

). Deﬁne

φπi(x(cid:63))
i
φi

(cid:26)

i =

where int(·) denotes the interior of a set. Then x(cid:63) is also the solution to
i (x) .

f (cid:63)(x) := ψ(x) +(cid:80)m

minimize

i=1 φ(cid:63)

(P(cid:63))

φ(cid:63)

i

i

x∈Rn

i

In words  Proposition 2.1 states that if x(cid:63) does not lie on the boundary of the subdomain X πi(x(cid:63))
then replacing φi with the subfunction φπi(x(cid:63))
Despite having identical solutions  solving (P(cid:63)) can require far less computation than solving (P).
i are linear  since the sum of linear functions is also linear. More
This is especially true when many φ(cid:63)
formally  consider a set W (cid:63) ⊆ [m] such that ∀i /∈ W (cid:63)  φ(cid:63)
i   x(cid:105) + b(cid:63)
i
for some a(cid:63)

i . Deﬁning a(cid:63) =(cid:80)

i and b(cid:63) =(cid:80)

in f does not affect the minimizer of f.

i is linear  meaning φ(cid:63)

i (x) = (cid:104)a(cid:63)

f (cid:63)(x) := ψ(x) + (cid:104)a(cid:63)  x(cid:105) + b(cid:63) +(cid:80)

i /∈W (cid:63) a(cid:63)

i   then (P(cid:63)) is equivalent to
i∈W (cid:63) φ(cid:63)

minimize

(P(cid:63)(cid:63))
That is  (P) has been reduced from a problem with m piecewise functions to a problem of size |W (cid:63)|.
Since often |W (cid:63)| (cid:28) m  solving (P(cid:63)) can be tremendously simpler than solving (P). The scenario is
quite common in machine learning applications. Some important examples include:

i and b(cid:63)

i /∈W (cid:63) b(cid:63)

i (x) .

x∈Rn

 

i

2

• Piecewise loss minimization: φi is a piecewise loss with at least one linear subfunction.
• Constrained optimization: φi takes value 0 for a subset of Rn and +∞ otherwise.
• Optimization with sparsity inducing penalties: (cid:96)1-regularized regression  group lasso  fused

lasso  etc.  are instances of (P) via duality [13].

We include elaboration on these examples in Appendix A.

3 Theoretical results
We have seen that solving (P(cid:63)) can be more efﬁcient than solving (P). However  since W (cid:63) is unknown
prior to optimization  solving (P(cid:63)) is impractical. Instead  we can hope to design algorithms that
rapidly learn W (cid:63). In this section  we propose principled methods for achieving this goal.

3.1 A general mechanism for exploiting piecewise linear structure

In this section  we focus on the consequences of minimizing the function

f(cid:48)(x) := ψ(x) +(cid:80)m

i=1 φ(cid:48)

i(x)  

i }. That is  φ(cid:48)

i ∈ {φi} ∪ {φ1

where φ(cid:48)
i   . . .   φpi
i is either the original piecewise function φi or one of
i . With (P(cid:63)) unknown  it is natural to consider this more general class of objectives
its subfunctions φk
(in the case that φ(cid:48)
i for all i  we see f(cid:48) is the objective function of (P(cid:63))). The goal of this section
i = φ(cid:63)
is to establish choices of f(cid:48) such that by minimizing f(cid:48)  we can make progress toward minimizing f.
We later introduce working set and screening methods based on this result.
To guide the choice of f(cid:48)  we assume points x0 ∈ Rn  y0 ∈ dom(f )  where x0 minimizes a
γ-strongly convex function f0 that lower bounds f. The point y0 represents an existing approximation
of x(cid:63)  while x0 can be viewed as a second approximation related to a point in (P)’s dual space. Since
f0 lower bounds f and x0 minimizes f0  note that f0(x0) ≤ f0(x(cid:63)) ≤ f (x(cid:63)). Using this fact  we
quantify the suboptimality of x0 and y0 in terms of the suboptimality gap

∆0 := f (y0) − f0(x0) ≥ f (y0) − f (x(cid:63)) .

(1)
Importantly  we consider choices of f(cid:48) such that by minimizing f(cid:48)  we can form points (x(cid:48)  y(cid:48)) that
improve upon the existing approximations (x0  y0) in terms of the suboptimality gap. Speciﬁcally 
we deﬁne x(cid:48) as the minimizer of f(cid:48)  while y(cid:48) is a point on the segment [y0  x(cid:48)] (to be deﬁned precisely
later). Our result in this section applies to choices of f(cid:48) that satisfy three natural requirements:
R1. Tight in a neighborhood of y0: For a closed set S with y0 ∈ int(S)  f(cid:48)(x) = f (x) ∀x ∈ S.
R2. Lower bound on f: For all x  we have f(cid:48)(x) ≤ f (x).
R3. Upper bound on f0: For all x  we have f(cid:48)(x) ≥ f0(x).
Each of these requirements serves a speciﬁc purpose. After solving x(cid:48) := argminx f(cid:48)(x)  R1 enables
a backtracking operation to obtain a point y(cid:48) such that f (y(cid:48)) < f (y0) (assuming y0 (cid:54)= x(cid:63)). We
deﬁne y(cid:48) as the point on the segment (y0  x(cid:48)] that is closest to x(cid:48) while remaining in the set S:
(2)
Since (i) f(cid:48) is convex  (ii) x(cid:48) minimizes f(cid:48)  and (iii) y0 ∈ int(S)  it follows that f (y(cid:48)) ≤ f (y0).
Applying R2 leads to the new suboptimality gap

θ(cid:48) := max {θ ∈ (0  1] : θx(cid:48) + (1 − θ)y0 ∈ S}   y(cid:48) := θ(cid:48)x(cid:48) + (1 − θ(cid:48))y0 .

∆(cid:48) := f (y(cid:48)) − f(cid:48)(x(cid:48)) ≥ f (y(cid:48)) − f (x(cid:63)) .

(3)
R2 is also a natural requirement since we are interested in the scenario that many φ(cid:48)
i are linear  in
which case (i) φ(cid:48)
i lower bounds φi as a result of convexity  and (ii) the resulting f(cid:48) likely can be
minimized efﬁciently. Finally  R3 is useful for ensuring f(cid:48)(x(cid:48)) ≥ f0(x(cid:48)) ≥ f0(x0). It follows that
∆(cid:48) ≤ ∆0. Moreover  this improvement in suboptimality gap can be quantiﬁed as follows:
Lemma 3.1 (Guaranteed suboptimality gap progress—proven in Appendix B). Consider points
x0 ∈ Rn  y0 ∈ dom(f ) such that x0 minimizes a γ-strongly convex function f0 that lower bounds f.
For any function f(cid:48) that satisﬁes R1  R2  and R3  let x(cid:48) be the minimizer of f(cid:48)  and deﬁne θ(cid:48) and y(cid:48)
via backtracking as in (2). Then deﬁning suboptimality gaps ∆0 and ∆(cid:48) as in (1) and (3)  we have

(cid:13)(cid:13)(cid:13)z − θ(cid:48)x0+y0

1+θ(cid:48)

(cid:13)(cid:13)(cid:13)2 − θ(cid:48)

1+θ(cid:48)

(cid:21)

γ

2 (cid:107)x0 − y0(cid:107)2

.

The primary signiﬁcance of Lemma 3.1 is the bound’s relatively simple dependence on S. We next
design working set and screening methods that choose S to optimize this bound.

3

(cid:20)

∆(cid:48) ≤ (1 − θ(cid:48))

∆0 − 1+θ(cid:48)
θ(cid:48)2

γ
2 min

z /∈int(S)

Algorithm 1 PW-BLITZ
initialize y0 ∈ dom(f )
# Initialize x0 by minimizing a simple lower bound on f:
∀i ∈ [m]  φ(cid:48)
x0 ← argminx f(cid:48)
for t = 1  . . .   T until xT = yT do

0(x) := ψ(x) +(cid:80)m

i 0(x) := φi(y0) + (cid:104)gi  x − y0(cid:105)  where gi ∈ ∂φi(y0)

i=1 φ(cid:48)

i 0(x)

# Form subproblem:
Select βt ∈ [0  1
2 ]
ct ← βtxt−1 + (1 − βt)yt−1
Select threshold τt > βt (cid:107)xt−1 − yt−1(cid:107)
St := {x : (cid:107)x − ct(cid:107) ≤ τt}
for i = 1  . . .   m do

k ← πi(yt−1)
if (C1 and C2 and C3) then φ(cid:48)

t(x) := ψ(x) +(cid:80)m

i t := φk
# Solve subproblem:
xt ← argminx f(cid:48)
i=1 φ(cid:48)
# Backtrack:
αt ← argminα∈(0 1] f (αxt + (1 − α)yt−1)
yt ← αtxt + (1 − αt)yt−1

return yT

i else φ(cid:48)

i t := φi

i t(x)

3.2 Piecewise working set algorithm

t(x) := ψ(x) +(cid:80)m

i=1 φ(cid:48)

i t = φj

we have φk

i   . . .   φpi

i (x) ∀x ∈ St).

i t(x)  where φ(cid:48)

i t ∈ {φi} ∪ {φ1

i (implying φi(x) = φk

Lemma 3.1 suggests an iterative algorithm that  at each iteration t  minimizes a modiﬁed objective
i }. To guide the choice of each
f(cid:48)
i t  our algorithm considers previous iterates xt−1 and yt−1  where xt−1 minimizes f(cid:48)
φ(cid:48)
t−1. For all
i ∈ [m]  j = φi(yt−1)  we deﬁne φ(cid:48)
i if the following three conditions are satisﬁed:
C1. Tight in the neighborhood of yt−1: We have St ⊆ X k
i (x) ≤ φi(x).
C2. Lower bound on φi: For all x  we have φk
C3. Upper bound on φ(cid:48)
i (x) ≥ φ(cid:48)

i t−1 in the neighborhood of xt−1: For all x ∈ Rn and gi ∈ ∂φ(cid:48)
i t−1(xt−1) + (cid:104)gi  x − xt−1(cid:105).
If any of the above conditions are unmet  then we let φ(cid:48)
i t = φi. As detailed in Appendix C  this
choice of φ(cid:48)
t satisﬁes conditions analogous to conditions R1  R2  and R3 for Lemma 3.1.
After determining f(cid:48)
t(x). We then set
yt ← αtxt + (1 − αt)yt−1  where αt is chosen via backtracking. Lemma 3.1 implies the sub-
optimality gap ∆t := f (yt) − f(cid:48)
t(xt) decreases with t until xT = yT   at which point ∆T = 0 and
xT and yT solve (P). Deﬁned in Algorithm 1  we call this algorithm “PW-BLITZ” as it extends the
BLITZ algorithm for constrained problems from [11] to a broader class of piecewise objectives.
An important consideration of Algorithm 1 is the choice of St. If St is large  C1 is easily violated 
t is difﬁcult to minimize. In contrast  if St is small 
meaning φ(cid:48)
then φ(cid:48)
t is simpler to minimize  but ∆t may be large.
Interestingly  conditioned on oracle knowledge of θt := max{θ ∈ (0  1] : θxt + (1 − θ)yt−1 ∈ St} 
we can derive an optimal St according to Lemma 3.1 subject to a volume constraint vol(St) ≤ V :

t  the algorithm proceeds by solving xt ← argminx f(cid:48)

i t is potentially linear for many i. In this case  f(cid:48)

i t = φi for many i. This implies f(cid:48)

i t ensures f(cid:48)

i t−1(xt−1) 

S (cid:63)
t := argmax
S : vol(S)≤V

min

z /∈int(S)

(cid:13)(cid:13)(cid:13)z − θtxt−1+yt−1

1+θt

(cid:13)(cid:13)(cid:13) .

S (cid:63)
t is a ball with center θtxt−1+yt−1
. Of course  this result cannot be used in practice directly  since
θt is unknown when choosing St. Motivated by this result  Algorithm 1 instead deﬁnes St as a ball
with radius τt and a similar center ct := βtxt−1 + (1 − βt)yt−1 for some βt ∈ [0  1
2 ].

1+θt

4

By choosing St in this manner  we can quantify the amount of progress Algorithm 1 makes at ieration
t. Our ﬁrst theorem lower bounds the amount of progress during iteration t of Algorithm 1 for the
case in which βt happens to be chosen optimally. That is  St is a ball with center θtxt−1+yt−1
Theorem 3.2 (Convergence progress with optimal βt). Let ∆t−1 and ∆t be the suboptimality gaps
after iterations t − 1 and t of Algorithm 1  and suppose that βt = θt(1 + θt)−1. Then

1+θt

.

∆t ≤ ∆t−1 + γ

t − 3

2

2 τ 2

t ∆2

t−1

(cid:0)γτ 2

(cid:1)1/3

.

Since the optimal βt is unknown when choosing St  our second theorem characterizes the worst-case
2).
performance of extremal choices of βt (the cases βt = 0 and βt = 1
Theorem 3.3 (Convergence progress with suboptimal βt). Let ∆t−1 and ∆t be the suboptimality
gaps after iterations t − 1 and t of Algorithm 1  and suppose that βt = 0. Then

Alternatively  suppose that βt = 1

∆t ≤ ∆t−1 + γ

t − (2γτ 2

2 τ 2

t ∆t−1)1/2.

(cid:1)1/3
2   and deﬁne dt := (cid:107)xt−1 − yt−1(cid:107). Then
2 (τt − 1
t−1

(cid:0)γ(τt − 1

2 dt)2 − 3

2 dt)2∆2

2

.

∆t ≤ ∆t−1 + γ

t is signiﬁcantly less than ∆t−1. (In the alternative case  the subproblem objective f(cid:48)

These results are proven in Appendices D and E. Note that it is often desirable to choose τt such that
γ
t may be no
2 τ 2
simpler than f. One could choose τt such that ∆t = 0  for example  but as we will see in §3.3  we are
only performing screening in this scenario.) Assuming γ
t is small in relation to ∆t−1  the ability to
choose βt is advantageous in terms of worst case bounds if one manages to select βt ≈ θt(1 + θt)−1.
At the same time  Theorem 3.3 suggests that Algorithm 1 is robust to the choice of βt; the algorithm
makes progress toward convergence even with worst-case choices of this parameter.

2 τ 2

t(xt) − minx f(cid:48)

Practical considerations We make several notes about using Algorithm 1 in practice. Since
subproblem solvers are iterative  it is important to only compute xt approximately. In Appendix F 
we include a modiﬁed version of Lemma 3.1 that considers this case. This result suggests terminating
t(x) ≤ ∆t−1 for some  ∈ (0  1). Here  trades off the amount
subproblem t when f(cid:48)
of progress resulting from solving subproblem t with the time dedicated to solving this subproblem.
To choose βt  we ﬁnd it practical to initialize β0 = 0 and let βt = αt−1(1 + αt−1)−1 for t > 0. This
roughly approximates the optimal choice βt = θt(1 + θt)−1  since θt can be viewed as a worst-case
version of αt  and αt often changes gradually with t. Selecting τt is problem dependent. By letting
τt = βt (cid:107)xt−1 − yt−1(cid:107) + ξ∆1/2
t−1 for a small ξ > 0  Algorithm 1 converges linearly in t. It can also
be beneﬁcial to choose τt in other ways—for example  choosing τt so subproblem t ﬁts in memory.
It is also important to recognize the relative amount of time required for each stage of Algorithm 1.
When forming subproblem t  the time consuming step is checking condition C1. In the most common
scenarios that X k
is a half-space or ball  this condition is testable in O(n) time. However  for
arbitrary regions  this condition could be difﬁcult to test. The time required for solving subproblem
t is clearly application dependent  but we note it can be helpful to select subproblem termination
criteria to balance time usage between stages of the algorithm. The backtracking stage is a 1D convex
problem that at most requires evaluating f a logarithmic number of times. Simpler backtracking
approaches are available for many objectives. It is also not necessary to perform exact backtracking.

i

Relation to BLITZ algorithm Algorithm 1 is related to the BLITZ algorithm [11]. BLITZ applies
only to constrained problems  however  while Algorithm 1 applies to a more general class of piecewise
objectives. In Appendix G  we ellaborate on Algorithm 1’s connection to BLITZ and other algorithms.

3.3 Piecewise screening test

Lemma 3.1 can also be used to simplify the objective f in such a way that the minimizer x(cid:63) is
unchanged. Recall Lemma 3.1 assumes a function f(cid:48) and set S for which f(cid:48)(x) = f (x) for all x ∈ S.
The idea of this section is to select the smallest region S such that in Lemma 3.1  ∆(cid:48) must equal 0
(according to the lemma). In this case  the minimizer of f(cid:48) is equal to the minimizer of f—even
though f(cid:48) is potentially much simpler to minimize. This results in the following screening test:

5

Theorem 3.4 (Piecewise screening test—proven in Appendix H). Consider any x0  y0 ∈ Rn such
that x0 minimizes a γ-strongly convex function f0 that lower bounds f. Deﬁne the suboptimality gap
∆0 := f (y0) − f0(x0) as well as the point c0 := x0+y0
. Then for any i ∈ [m] and k = πi(y0)  if
γ ∆0 − 1

x : (cid:107)x − c0(cid:107) ≤(cid:113) 1

4 (cid:107)x0 − y0(cid:107)2

⊆ int(X k

S :=

(cid:26)

(cid:27)

i )  

2

i ). This implies φi may be replaced with φk

then x(cid:63) ∈ int(X k
Theorem 3.4 applies to general X k
often is (or is a superset of) a simple region that makes applying Theorem 3.4 simple.
Corollary 3.5 (Piecewise screening test for half-space X k
for some ai ∈ Rn  bi ∈ R. Deﬁne x0  y0  ∆0  and c0 as in Theorem 3.4. Then x(cid:63) ∈ int(X k

i ) may be difﬁcult. Fortunately  X k
i ⊇ {x : (cid:104)ai  x(cid:105) ≤ bi}

i   and testing if S ⊆ int(X k

i in (P) without affecting x(cid:63).

i ). Suppose that X k

i

i ) if

bi − (cid:104)ai  c0(cid:105)

(cid:107)ai(cid:107)

>

4 (cid:107)x0 − y0(cid:107)2 .
γ ∆0 − 1
i ). Suppose that X k

(cid:113) 1
(cid:113) 1

Corollary 3.6 (Piecewise screening test for ball X k
some ai ∈ Rn  bi ∈ R>0. Deﬁne x0  y0  ∆0  and c0 as in Theorem 3.4. Then x(cid:63) ∈ int(X k

i ⊇ {x : (cid:107)x − ai(cid:107) ≤ bi} for

i ) if

bi − (cid:107)ai − c0(cid:107) >

γ ∆0 − 1

4 (cid:107)x0 − y0(cid:107)2 .

Corollary 3.5 applies to piecewise loss minimization (for SVMs  discarding examples that are not
marginal support vectors)  (cid:96)1-regularized learning (discarding irrelevant features)  and optimization
with linear constraints (discarding superﬂuous constraints). Applications of Corollary 3.6 include
group lasso and many constrained objectives. In order to obtain the point x0  it is usually practical to
i=1 φi. In this case  computing x0 is as

choose f0 as the sum of ψ and a ﬁrst-order lower bound on(cid:80)m

simple as ﬁnding the conjugate of ψ. We illustrate this idea with an SVM example in Appendix I.
Since ∆0 decreases over the course of an iterative algorithm  Theorem 3.4 is “adaptive ” meaning
it increases in effectiveness as progress is made toward convergence. In contrast  most screening
tests are “nonadaptive.” Nonadaptive screening tests depend on knowledge of an exact solution to a
related problem  which is disadvantageous  since (i) solving a related problem exactly is generally
computationally expensive  and (ii) the screening test can only be applied prior to optimization.

Relation to existing screening tests Theorem 3.4 generalizes and improves upon many existing
screening tests. We summarize Theorem 3.4’s relation to previous results below. Unlike Theorem 3.4 
existing tests typically apply to only one or two objectives. Elaboration is included in Appendix J.
• Adaptive tests for sparse optimization: Recently  [6]  [7]  and [8] considered adaptive screening
tests for several sparse optimization problems  including (cid:96)1-regularized learning and group
lasso. These tests rely on knowledge of primal and dual points (analogous to x0 and y0)  but
the tests are not as effective (nor as general) as Theorem 3.4.
• Adaptive tests for constrained optimization: [11] considered screening with primal-dual pairs
for constrained optimization problems. The resulting test is a more general version (applies to
more objectives) of [6]  [7]  and [8]. Thus  Theorem 3.4 improves upon [11] as well.
• Nonadaptive tests for degree 1 homogeneous loss minimization: [10] considered screening for
(cid:96)2-regularized learning with hinge and (cid:96)1 loss functions. This is a special non-adaptive case of
Theorem 3.4  which requires solving the problem with greater regularization prior to screening.
• Nonadaptive tests for sparse optimization: Some tests  such as [4] for the lasso  may screen
components that Theorem 3.4 does not eliminate. In Appendix J  we show how Theorem 3.4
can be modiﬁed to generalize [4]  but this change increases the time needed for screening. In
practice  we were unable to overcome this drawback to speed up iterative algorithms.

Relation to working set algorithm Theorem 3.4 is closely related to Algorithm 1. In particular 
our screening test can be viewed as a working set algorithm that converges in one iteration. In the
context of Algorithm 1  this amounts to choosing β1 = 1

4 (cid:107)x0 − y0(cid:107)2.

2 and τ1 =

(cid:113) 1
γ ∆0 − 1

It is important to understand that it is usually not desirable that a working set algorithm converges in
one iteration. Since screening rules do not make errors  these methods simplify the objective by only
a modest amount. In many cases  screening may fail to simplify the objective in any meaningful way.
In the following section  we consider real-world scenarios to demonstrate these points.

6

(a) m = 100

(b) m = 400

(c) m = 1600

Figure 1: Group lasso convergence comparison. While screening is marginally useful for the
problem with only 100 groups  screening becomes ineffective as m increases. The working set
algorithm convincingly outperforms dual coordinate descent in all cases.

4 Comparing the scalability of screening and working set methods

This section compares the scalability of our working set and screening approaches. We consider
two popular instances of (P): group lasso and linear SVMs. For each problem  we examine the
performance of our working set algorithm and screening rule as m increases. This is an important
comparison  as we have not seen such scalability experiments in prior works on screening.
We implemented dual coordinate ascent (DCA) to solve each instance of (P). DCA is known to be
simple and fast  and there are no parameters to tune. We compare DCA to three alternatives:

1. DCA + screening: After every ﬁve DCA epochs we apply screening. “Piecewise screening”

refers to Theorem 3.4. For group lasso  we also implement “gap screening” [7].

2. DCA + working sets: Implementation of Algorithm 1. DCA is used to solve each subproblem.
3. DCA + working sets + screening: Algorithm 1 with Theorem 3.4 applied after each iteration.

Group lasso comparisons We deﬁne the group lasso objective as

2 (cid:107)Aω − b(cid:107)2 + λ(cid:80)m

i=1 (cid:107)ωGi(cid:107)2 .

gGL(ω) := 1

A ∈ Rn×q is a design matrix  and b ∈ Rn is a labels vector. λ > 0 is a regularization parameter  and
G1  . . .  Gm are disjoint sets of feature indices such that ∪m
i=1Gi = [q]. Denote a minimizer of gGL by
  have value 0 for many Gi. While gGL is not directly an
ω(cid:63). For large λ  groups of elements  ω(cid:63)Gi
instance of (P)  the dual of gGL is strongly concave with m constraints (and thus an instance of (P)).
We consider an instance of gGL to perform feature selection for an insurance claim prediction task1.
Given n = 250 000 training instances  we learned an ensemble of 1600 decision trees. To make
predictions more efﬁciently  we use group lasso to reduce the number of trees in the model. The
resulting problem has m = 1600 groups and q = 28 733 features. To evaluate the dependence of
the algorithms on m  we form smaller problems by uniformly subsampling 100 and 400 groups. For
each problem we set λ so that exactly 5% of groups have nonzero weight in the optimal model.
Figure 1 contains results of this experiment. Our metrics include the relative suboptimality of the
current iterate as well as the agreement of this iterate’s nonzero groups with those of the optimal
solution in terms of precision (all algorithms had high recall). This second metric is arguably more
important  since the task is feature selection. Our results illustrate that while screening is marginally
helpful when m is small  our working set method is more effective when scaling to large problems.

1https://www.kaggle.com/c/ClaimPredictionChallenge

7

01234567Time(s)10−610−510−410−310−210−1|g−g(cid:63)|/|g(cid:63)|05101520253035Time(s)10−610−510−410−310−210−1|g−g(cid:63)|/|g(cid:63)|0100200300400500600700800Time(s)10−610−510−410−310−210−1|g−g(cid:63)|/|g(cid:63)|01234567Time(s)0.700.750.800.850.900.951.00Supportsetprecision05101520253035Time(s)0.700.750.800.850.900.951.00Supportsetprecision0100200300400500600700800Time(s)0.700.750.800.850.900.951.00SupportsetprecisionDCA+workingsets+piecewisescreeningDCA+workingsetsDCA+piecewisescreeningDCA+gapscreeningDCA(a) m = 104

(b) m = 105

(c) m = 106

Figure 2: SVM convergence comparison. (above) Relative suboptimality vs. time. (below) Heat
map depicting fraction of examples screened by Theorem 3.4 when used in conjunction with dual
coordinate ascent. y-axis is the number of epochs completed; x-axis is the tuning parameter C.
C0 is the largest value of C for which each element of the dual solution takes value C. Darker
regions indicate more successful screening. The vertical line indicates the choice of C that minimizes
validation loss—this is also the choice of C for the above plots. As the number of examples increases 
screening becomes progressively less effective near the desirable choice of C.

SVM comparisons We deﬁne the linear SVM objective as

2 (cid:107)x(cid:107)2 + C(cid:80)m

fSVM(x) := 1

i=1(1 − bi (cid:104)ai  x(cid:105))+ .

Here C is a tuning parameter  while ai ∈ Rn  bi ∈ {−1  +1} represents the ith training instance. We
train an SVM model on the Higgs boson dataset2. This dataset was generated by a team of particle
physicists. The classiﬁcation task is to determine whether an event corresponds to the Higgs boson.
In order to learn an accurate model  we performed feature engineering on this dataset  resulting in
8010 features. In this experiment  we consider subsets of examples with size m = 104  105  and 106.
Results of this experiment are shown in Figure 2. For this problem  we plot the relative suboptimality
in terms of objective value. We also include a heat map that shows screening’s effectiveness for
different values of C. Similar to the group lasso results  the utility of screening decreases as m
increases. Meanwhile  working sets signiﬁcantly improve convergence times  regardless of m.

5 Discussion

Starting from a broadly applicable problem formulation  we have derived principled and uniﬁed
methods for exploiting piecewise structure in convex optimization. In particular  we have introduced
a versatile working set algorithm along with a theoretical understanding of the progress this algorithm
makes with each iteration. Using the same analysis  we have also proposed a screening rule that
improves upon many prior screening results as well as enables screening for many new objectives.
Our empirical results highlight a signiﬁcant disadvantage of using screening: unless a good approxi-
mate solution is already known  screening is often ineffective. This is perhaps understandable  since
screening rules operate under the constraint that erroneous simpliﬁcations are forbidden. Working set
algorithms are not subject to this constraint. Instead  working set algorithms achieve fast convergence
times by aggressively simplifying the objective function  correcting for mistakes only as needed.

2https://archive.ics.uci.edu/ml/datasets/HIGGS

8

0.000.050.100.150.20Time(s)10−610−510−410−310−210−1(f−f(cid:63))/f(cid:63)012345678Time(s)10−610−510−410−310−210−1(f−f(cid:63))/f(cid:63)0102030405060Time(s)10−610−510−410−310−210−1(f−f(cid:63))/f(cid:63)101102103C/C010203040#EpochsFractionofexamplesscreened0.00.20.40.60.81.0101102103104C/C010203040#EpochsFractionofexamplesscreened0.00.20.40.60.81.0101102103104105106C/C010203040#EpochsFractionofexamplesscreened0.00.20.40.60.81.0DCA+workingsets+piecewisescreeningDCA+workingwetsDCA+piecewisescreeningDCAAcknowledgments

We thank Hyunsu Cho  Christopher Aicher  and Tianqi Chen for their helpful feedback as well as
assistance preparing datasets used in our experiments. This work is supported in part by PECASE
N00014-13-1-0023  NSF IIS-1258741  and the TerraSwarm Research Center 00008169.

References
[1] L. E. Ghaoui  V. Viallon  and T. Rabbani. Safe feature elimination for the lasso and sparse

supervised learning problems. Paciﬁc Journal of Optimization  8(4):667–698  2012.

[2] Z. J. Xiang and P. J. Ramadge. Fast lasso screening tests based on correlations. In IEEE

International Conference on Acoustics  Speech  and Signal Processing  2012.

[3] R. Tibshirani  J. Bien  J. Friedman  T. Hastie  N. Simon  J. Taylor  and R. J. Tibshirani. Strong
rules for discarding predictors in lasso-type problems. Journal of the Royal Statistical Society 
Series B  74(2):245–266  2012.

[4] J. Liu  Z. Zhao  J. Wang  and J. Ye. Safe screening with variational inequalities and its

application to lasso. In International Conference on Machine Learning  2014.

[5] J. Wang  P. Wonka  and J. Ye. Lasso screening rules via dual polytope projection. Journal of

Machine Learning Research  16(May):1063–1101  2015.

[6] O. Fercoq  A. Gramfort  and J. Salmon. Mind the duality gap: safer rules for the lasso. In

International Conference on Machine Learning  2015.

[7] E. Ndiaye  O. Fercoq  A. Gramfort  and J. Salmon. GAP safe screening rules for sparse
multi-task and multi-class models. In Advances in Neural Information Processing Systems 28 
2015.

[8] E. Ndiaye  O. Fercoq  A. Gramfort  and J. Salmon. Gap safe screening rules for sparse-group

lasso. Technical Report arXiv:1602.06225  2016.

[9] I. Takeuchi K. Ogawa  Y. Suzuki. Safe screening of non-support vectors in pathwise SVM

computation. In International Conference on Machine Learning  2013.

[10] J. Wang  P. Wonka  and J. Ye. Scaling SVM and least absolute deviations via exact data

reduction. In International Conference on Machine Learning  2014.

[11] T. B. Johnson and C. Guestrin. Blitz: a principled meta-algorithm for scaling sparse optimization.

In International Conference on Machine Learning  2015.

[12] R.-E. Fan  K.-W. Chang  C.-J. Hsieh  X.-R. Wang  and C.-J. Lin. LIBLINEAR: A library for

large linear classiﬁcation. Journal of Machine Learning Research  9:1871–1874  2008.

[13] F. Bach  R. Jenatton  J. Mairal  and G. Obozinski. Optimization with sparsity-inducing penalties.

Foundations and Trends in Machine Learning  4(1):1–106  2012.

9

,Tyler Johnson
Carlos Guestrin