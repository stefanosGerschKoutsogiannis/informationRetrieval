2018,Doubly Robust Bayesian Inference for Non-Stationary Streaming Data with $\beta$-Divergences,We present the very first robust Bayesian Online Changepoint Detection algorithm through General Bayesian Inference (GBI) with $\beta$-divergences. The resulting inference procedure is doubly robust for both the predictive and the changepoint (CP) posterior  with linear time and constant space complexity. We provide a construction for exponential models and demonstrate it on the Bayesian Linear Regression model. In so doing  we make two additional contributions: Firstly  we make GBI scalable using Structural Variational approximations that are exact as $\beta \to 0$. Secondly  we give a principled way of choosing the divergence parameter $\beta$ by minimizing expected predictive loss on-line. Reducing False Discovery Rates of \CPs from up to 99\% to 0\% on real world data  this offers the state of the art.,Doubly Robust Bayesian Inference for

Non-Stationary Streaming Data with β-Divergences

Jeremias Knoblauch
The Alan Turing Institute
Department of Statistics
University of Warwick
Coventry  CV4 7AL

j.knoblauch@warwick.ac.uk

Jack Jewson

Department of Statistics
University of Warwick
Coventry  CV4 7AL

j.e.jewson@warwick.ac.uk

Theodoros Damoulas
The Alan Turing Institute

Department of Computer Science & Department of Statistics

University of Warwick
Coventry  CV4 7AL

t.damoulas@warwick.ac.uk

Abstract

We present the ﬁrst robust Bayesian Online Changepoint Detection algorithm
through General Bayesian Inference (GBI) with β-divergences. The resulting
inference procedure is doubly robust for both the parameter and the changepoint
(CP) posterior  with linear time and constant space complexity. We provide a
construction for exponential models and demonstrate it on the Bayesian Linear
Regression model. In so doing  we make two additional contributions: Firstly  we
make GBI scalable using Structural Variational approximations that are exact as
β → 0. Secondly  we give a principled way of choosing the divergence parameter
β by minimizing expected predictive loss on-line. Reducing False Discovery Rates
of CPS from over 90% to 0% on real world data  this offers the state of the art.

1

Introduction

Modeling non-stationary time series with changepoints (CPS) is popular [23  50  33] and important
in a wide variety of research ﬁelds  including genetics [8  16  42]  ﬁnance [27]  oceanography [24] 
brain imaging and cognition [13  20]  cybersecurity [37] and robotics [2  26]. For streaming data 
a particularly important subclass are Bayesian On-line Changepoint Detection (BOCPD) methods
that can process data sequentially [1  11  43  47  46  41  8  34  44  40  25] while providing full
probabilistic uncertainty quantiﬁcation. These algorithms declare CPS if the posterior predictive
computed from y1:t at time t has low density for the value of the observation yt+1 at time t + 1.
Naturally  this leads to a high false CP discovery rate in the presence of outliers and as they run
on-line  pre-processing is not an option. In this work  we provide the ﬁrst robust on-line CP detection
method that is applicable to multivariate data  works with a class of scalable models and quantiﬁes
model  CP and parameter uncertainty in a principled Bayesian fashion.
Standard Bayesian inference minimizes the Kullback-Leibler divergence (KLD) between the ﬁtted
model and the Data Generating Mechanism (DGM)  but is not robust under outliers or model mis-
speciﬁcation due to its strictly increasing inﬂuence function. We remedy this by instead minimizing
the β-divergence (β-D) whose inﬂuence function has a unique maximum  allowing us to deal with
outliers effectively. Fig. 1 A illustrates this: Under the β-D  the inﬂuence of observations ﬁrst

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

Figure 1: A: Inﬂuence of yt on inference as function of distance to the posterior expectation
in Standard Deviations for β-divergences with different βs. B: Five jointly modeled Simulated
Autoregressions (ARS) with true CPS at t = 200  400; bottom-most AR injected with t4-noise.
Maximum A Posteriori CPS of robust (standard) BOCPD shown as solid (dashed) vertical lines.

increases as they move away from the posterior mean  mimicking the KLD. However  once they
move far enough  their inﬂuence decreases again. This can be interpreted to mean that they are
(increasingly) treated as outliers. As β increases  observations are registered as outliers closer to the
posterior mean. Conversely  as β → 0  one recovers the KLD which cannot treat any observation as an
outlier. In addressing misspeciﬁcation and outliers this way  our approach builds on the principles of
General Bayesian Inference (GBI) [see 6  21] and robust divergences [e.g. 4  15]. This paper presents
three contributions in separate domains that are also illustrated in Figs. 1 and 3:

(1) Robust BOCPD: We construct the very ﬁrst robust BOCPD inference. The procedure is
applicable to a wide class of (multivariate) models and is demonstrated on Bayesian Linear
Regression (BLR). Unlike standard BOCPD  it discerns outliers and CPS  see Fig. 1 B.

(2) Scalable GBI: Due to intractable posteriors  GBI has received little attention in machine
learning so far. We remedy this with a Structural Variational approximation which preserves
parameter dependence and is exact as β → 0  providing a near-perfect ﬁt  see Fig. 3.

(3) Choosing β: While Fig. 1 A shows that β regulates the degree of robustness [see also
21  15]  it is unclear how to set its magnitude. For the ﬁrst time  we provide a principled way
of initializing β. Further  we show how to reﬁne it on-line by minimizing predictive losses.

The remainder of the paper is structured as follows: In Section 2  we summarize standard BOCPD
and show how to extend it to robust inference using the β-D. We quantify the degree of robustness
and show that inference under the β-D can be designed so that a single outlier never results in false
declaration of a CP  which is impossible under the KLD. Section 3 motivates efﬁcient Structural
Variational Inference (SVI) with the β-D posterior. Within BOCPD  we propose to scale SVI using
variance-reduced Stochastic Gradient Descent. Next  Section 4 expands on how β can be initialized
before the algorithm is run and then optimized on-line during execution time. Lastly  Section 5
showcases the substantial gains in performance of robust BOCPD when compared to its standard
version on real world data in terms of both predictive error and CP detection.

2 Using Bayesian On-line Changepoint Detection with β-Divergences

BOCPD is based on the Product Partition Model [3] and introduced independently in Adams and
MacKay [1] and Fearnhead and Liu [11]. Recently  both formulations have been uniﬁed in Knoblauch
and Damoulas [25]. The underlying algorithm has extensions ranging from Gaussian Processes [41]
and on-line hyperparameter optimization [8] to non-exponential families [44  34].
To formulate BOCPD probabilistically  deﬁne the run-length rt as the number of observations at time
t since the most recent CP and mt as the best model in the set M for the observations since that
CP. Then  given a real-valued multivariate process {yt}∞
t=1 of dimension d  a model universe M  a

2

0246810Standard Deviations0.00.20.40.60.81.01.21.4InfluenceAKLD=0.05=0.2=0.250100200300400500600Time051015202530ValueBrun-length prior h deﬁned over N0 and a model prior q over M  the BOCPD model is

rt|rt−1 ∼ H(rt  rt−1)
θm|mt ∼ πmt(θmt)

mt|mt−1  rt ∼ q(mt|mt−1  rt)
yt|mt  θmt ∼ fmt(yt|θmt)

the posterior predictive fm(yt|y1:(t−1)  rt) =(cid:82)

(1a)
(1b)
where q(mt|mt−1  rt) = 1mt−1 (mt) for rt > 0 and q(mt) otherwise  and where H is the conditional
run-length prior so that H(0  r) = h(r+1)  H(r+1  r) = 1−h(r+1) for any r ∈ N0 and H(r  r(cid:48)) =
0 otherwise. For example  Bayesian Linear Regression (BLR) with the d × p regressor matrix Xt
and prior covariance Σ0 is given by θm = (σ2  µ)  fm(yt|θm) = Nd(yt; Xtµ  Id) and πm(θm) =
Nd(µ; µ0  σ2Σ0)IG(σ2; a0  b0). If the computations of the parameter posterior πm(θm|y1:t  rt) and
fm(yt|θm)πm(θm|y1:(t−1)  rt)dθm are efﬁcient
for all models m ∈ M  then so is the recursive computation given by
p(y1  r1 = 0  m1) = q(m1) ·

(cid:90)
(cid:110)
fmt(yt|Ft−1)q(mt|Ft−1  mt−1)H(rt  rt−1)p(y1:(t−1)  rt−1  mt−1)

fm1 (y1|θm1 )πm1(θm1)dθm1 = q(m1) · fm1 (y1|y0) 

(cid:111)
(cid:9) and p(y1:t  rt  mt) is the joint density of y1:t  mt and rt.

The run-length and model posteriors are then available exactly at time t  as p(rt  mt|y1:t) =

mt−1 rt−1

p(y1:t  rt  mt) =

where Ft−1 = (cid:8)y1:(t−1)  rt−1
p(y1:t  rt  mt)/(cid:80)

p(y1:t  rt  mt). For a full derivation and the resulting inference see [25].

(cid:88)

Θm1

Θm

mt rt

(2a)

(2b)

2.1 General Bayesian Inference (GBI) with β-Divergences (β-D)

Standard Bayesian inference minimizes the KLD between the Data Generating Mechanism (DGM)
and its probabilistic model (see Section 2.1 of [6] for a clear illustration). In the M-closed world
where one assumes that the DGM and model coincide  the KLD is the most efﬁcient way of updating
posterior beliefs. However  this is no longer the case in the M-open world [5] where they match
only approximately [21]  e.g. in the presence of outliers. GBI [6  21] generalizes standard Bayesian
updating based on the KLD to a family of divergences. In particular  it uses the relationship between
losses (cid:96) and divergences D to deduce for D a corresponding loss (cid:96)D. It can then be shown that for
model m  the posterior update optimal for D yields the distribution

m(θm|y(t−rt):t) ∝ πm(θ) exp
πD

(cid:96)D(θm|yi)

i=t−rt

.

(3)

(cid:111)

(cid:110)−(cid:80)t

(cid:90)

1 + βp

Y

For parameter inference with the KLD and β-D  these losses are the log score and the Tsallis score:
(4)

(cid:96)KLD(θm|yt) = − log (fm(yt|θm)
(cid:96)β(θm|yt) = −

fm(yt|θm)βp − 1

fm(z|θm)1+βp dz

.

(5)

(cid:19)

(cid:18) 1

βp

Eq. (5) shows why the β-D excels at robust inference: Similar to tempering  (cid:96)β exponentially
downweights the density  attaching less inﬂuence to observations in the tails of the model. This
phenomenon is depicted with inﬂuence functions I(yt) in Figure 1 A. I(yt) is a divergence between
the posterior with and without an observation yt [28].
GBI with the β-D yields robust inference without the need to specify a heavy-tailed or otherwise
robustiﬁed model. Hence  one estimates the same model parameters as in standard Bayesian inference
while down-weighting the inﬂuence of observations that are overly inconsistent with the model.
Accordingly  GBI provides robust inference for a much wider class of models and situations than the
ones illustrated here. Though other divergences such as α-Divergences [e.g. 19] also accommodate
robust inference  we restrict ourselves to the β-D. We do this because unlike other divergences  it
does not require estimation of the DGM’s density. Density estimation increases estimation error 
is computationally cumbersome and works poorly for small run-lengths (i.e. sample sizes). Note
that versions of GBI have been proposed before [14  32  38  10]  but have framed the procedure as
alternative to Variational Bayes instead.
Apart from the computational gains of Section 3.1  we tackle robust inference via the β-D rather
than via Student’s t errors for three reasons: Firstly  robust run-length posteriors need robustness
in ratios rather than tails (see Section 2.3 and the simulation results for Student’s t errors in the
Appendix). Secondly  Student’s t errors model outliers as part of the DGM  which compromises

3

Figure 2: A: Lower bound on the odds of Thm. 1 for priors used for Figure 1 B and h(r) = 1/100.
B: ˆk for different choices of βp and output (input) dimensions d (2d) in an autoregressive BLR
the inference target: Consider a BLR with error et = εt + wtνt  where wt ∼ Ber(p) for p = 0.01 
εt ∼ N (0  σ2) with outliers νt ∼ t1(0  γ). Appropriate choices of βp give most inﬂuence to
the (1 − p) · 100% = 99% of typical observations one can explain well with the BLR model. In
contrast  modeling et as Student’s t under the KLD lets νt dominate parameter inference and lets
1% of observations inﬂate the predictive variance substantially. Thirdly  using Student’s t errors is a
technique only applicable to symmetric  continuous models. In contrast  GBI with the β-D is valid
for any setting  e.g. for asymmetric errors as well as point and count processes.

2.2 Robust BOCPD

The literature on robust on-line CP detection so far is sparse and covers limited settings without
Bayesian uncertainty quantiﬁcation [e.g. 36  7  12]. For example  the method in Fearnhead and
Rigaill [12] only produces point estimates and is limited to ﬁtting a piecewise constant function to
univariate data. In contrast  BOCPD can be applied to multivariate data and a set of models M while
quantifying uncertainty about these models  their parameters and potential CPS  but is not robust.
Noting that for standard BOCPD the posterior expectation is given by

E(cid:0)yt|y1:(t−1)  rt−1  mt−1

(cid:1) p(rt−1  mt−1|y1:(t−1)) 

E(cid:0)yt|y1:(t−1)

(6)

(cid:1) =

(cid:88)

rt mt

m (θm|y1:t) for β = (βrlm  βp) > 01.

the key observation is that prediction is driven by two probability distributions: The run-length and
model posterior p(rt  mt|y1:t) and parameter posterior distributions πm(θm|y1:t). Thus  we make
BOCPD robust by using β-D posteriors pβrlm(rt  mt|y1:t)  πβp
βrlm prevents abrupt changes in pβrlm(rt  mt|y1:t) caused by a small number of observations  see
section 2.3. This form of robustness is easy to implement and retains the closed forms of BOCPD:
In Eqs. (2a) and (2b)  one simply replaces fmt(yt|y0) and fmt(yt|Ft−1) by their β-D-counterparts
exp{(cid:96)βrlm(θmt|yt)}  where
(cid:96)βrlm(θmt|yt) = −

(7)
While the posterior pβrlm(rt  mt|y1:t) is only available up to a constant  it is discrete and thus easy
m (θ|y1:t) by preventing it
to normalize. Complementing this  βp regulates the robustness of πβp
m (θ|y1:t) using
from being dominated by tail events. Section 3.1 overcomes the intractability of πβp
Structural Variational Inference (SVI) that recovers the approximated distribution exactly as βp → 0.

fm(z|Ft−1)1+βrlmdz

fm(yt|Ft−1)βrlm −

(cid:18) 1

1 + βrlm

(cid:19)

(cid:90)

βrlm

Y

1

.

2.3 Quantifying robustness

The algorithm of Fearnhead and Rigaill [12] is robust because hyperparameters enforce that a single
outlier is insufﬁcient for declaring a CP. Analogously  we investigate conditions under which a single
(outlying) observation yt+1 is able to force a CP. An intuitive way of achieving this is by studying
the odds of rt+1 ∈ {0  r + 1} conditional on rt = r:
p(rt+1 = r + 1|y1:t+1  rt = r  mt)
p(rt+1 = 0|y1:t+1  rt = r  mt)
1In fact  βp= βm

((((((((
p(y1:t  rt = r  mt) · (1 − H(rt+1  rt))f D

((((((((
p(y1:t  rt = r  mt) · H(rt+1  rt)f D

p   i.e. the robustness is model-speciﬁc  but this is suppressed for readability

(yt+1|Ft)

(yt+1|y0)

. (8)

=

mt

mt

4

0.000.250.500.751.00|V|min0.00.51.01.52.02.5oddsA0.00.10.20.30.40.5p0.00.20.40.60.81.0kBd=5d=10d=15d=25(yt+1|y0) > f D

mt

mt

(yt+1|Ft) = exp(cid:8)−(cid:96)βrlm(θm|yt)(cid:9) as in Eq. (7). Tak-

(yt+1|Ft) = fmt(yt+1|Ft) and f βrlm

(8)  if yt+1 is an outlier with low density under f D
mt

mt denotes the negative exponential of the score under divergence D.

(yt+1|Ft) under a Student’s t error model than under a normal error model  f KLD

Here  f D
In particular 
f KLD
mt
(yt+1|Ft)  the
ing a closer look at Eq.
odds will move in favor of a CP provided that the prior is sufﬁciently uninformative to make
(yt+1|Ft). In fact  even very small differences have a substantial impact on
f D
mt
the odds. This is why using the Student’s t error for the BLR model with standard Bayes will not
provide robust run-length posteriors: While an outlying observation yt+1 will have greater density
(yt+1|y0) (the
f KLD
mt
density under the prior) will also be larger under the Student’s t error model. As a result  changing
the tails of the model only has a very limited effect on the ratio in Eq. (8). In fact  the perhaps
unintuitive consequence is that Student’s t error models will yield CP inference that very closely
resembles that of the corresponding normal model. A range of numerical examples in the Appendix
illustrate this surprising fact. In contrast  CP inference robustiﬁed via the β-D does not suffer from
this phenomenon. In fact  Theorem 1 provides very mild conditions for the β-D robustiﬁed BLR
model ensuring that the odds never favor a CP after any single outlying observation yt+1.
Theorem 1. If mt in Eq. (8) is the Bayesian Linear Regression (BLR) model with µ ∈ Rp and priors
a0  b0  µ0  Σ0; and if the posterior predictive’s variance determinant is larger than |V |min > 0  then
one can choose any (βrlm  H(rt  rt+1)) ∈ S (p  βrlm  a0  b0  µ0  Σ0 |V |min) to guarantee that

mt

(1 − H(rt+1  rt))f βrlm

(yt+1|Ft)

mt

≥ 1 

H(rt+1  rt)f βrlm

mt (yt+1|y0)

(9)
where the set S (p  βrlm  a0  b0  µ0  Σ0 |V |min) is deﬁned by an inequality given in the Appendix.
Thm. 1 says that one can bound the odds for a CP independently of yt+1. The requirement for a
lower bound |V |min results from the integral term in Eq. (5)  which dominates β-D-inference if
|V | is extremely small. In practice  this is not restrictive: E.g. for p = 5  h(r) = 1
λ  a0 = 3  b0 =
5  Σ0 = diag(100  5) used in Fig. 1 B  Thm. 1 holds for (βrlm  λ) = (0.15  100) used for inference if
|V |min ≥ 8.12 × 10−6. Fig. 2 A plots the lower bound (see Appendix) as function of |V |min.

Figure 3: Exemplary contour plots of bivariate marginals for the approximation(cid:98)πβp

(dashed) and the target πβp
Monte Carlo samples for the β-D posterior of BLR with d = 1  two regressors and βp = 0.25.

m (θm) of Eq. (11)
m (θm|y(t−rt):t) (solid) estimated and smoothed from 95  000 Hamiltonian

3 On-line General Bayesian Inference (GBI)

3.1 Structural Variational Approximations for Conjugate Exponential Families

While there has been a recent surge in theoretical work on GBI [6  15  21  14]  applications have
been sparse  in large part due to intractability. While sampling methods have been used successfully
for GBI [21  15]  it is not easy to scale these for the robust BOCPD setting. Thus  most work on
BOCPD has focused on conjugate distributions [1  43  11] and approximations [44  34]. We extend
the latter branch of research by deploying Structural Variational Inference (SVI). Unlike mean-ﬁeld
approximations  this preserves parameter dependence in the posterior  see Figure 3. While it is
in principle possible to solve the inference task by sampling  this is computationally burdensome
and makes the algorithm on-line in name only: Any sampling approach needs to (I) sample from
m (θm|yt−rt:t) in Eq. (3)  (II) numerically integrate to obtain fm(yt|y1:(t−1)  rt) and lastly (III)
πβp

5

m0m1-0.10.00.10.20.3-0.9-0.8-0.7-0.6-0.5s2m00.70.80.91.01.11.21.3-0.2-0.10.00.10.20.30.4s2m10.70.80.91.01.11.21.3-1.2-1.0-0.8-0.6-0.4sample and numerically integrate the integral in Eq. (7) which no longer has a closed form. Moreover 
this has to be performed for each (rt  m) at times t = 1  2  . . . . On top of this increased computational
cost  it creates three sources of approximation error propagated forward through time via Eqs. (2a)
m is available in closed form and as β-D → KLD as β → 0 [4]  there is an
and (2b). Since πKLD
especially compelling way of doing SVI for conjugate models using the β-D based on the fact that

(10)

(11)

is exact as β → 0. Thus we approximate the β-D posterior for model m and run-length rt as

m (θm|y(t−rt):t) ≈ πKLD
πβp

m (θm|y(t−rt):t)

(cid:110)

(cid:16)

KL

πKLD
m (θm)

(cid:13)(cid:13)(cid:13)πβp

(cid:17)(cid:111)
m (θm|y(t−rt):t)

.

(cid:98)πβp

m (θm) = argmin
m (θm)

While this ensures that the densities(cid:98)πβp

πKLD

m and πKLD

is analytically available iff the following three quantities have closed form:

m belong to the same family  the variational parameters
can be very different from those implied by the KLD-posterior. This approximation mitigates multiple
m (θm|y1:t) into the conjugate closed
issues that would arise with sampling approaches: By forcing πβp
form  steps (II) and (III) are solved analytically. Thus  inference is orders of magnitude faster  while
the resulting approximation error remains negligible (see Figs 2B  3).
Moreover  for many models  the Evidence Lower Bound (ELBO) associated with the optimization
in Eq. (11) is available in closed form. As a result  off-the-shelf optimizers are sufﬁcient and no
black-box or sampling-based techniques are required to efﬁciently tackle the problem. Theorem 2
provides the conditions for a conjugate exponential family to admit such a closed form ELBO. The
proof alongside the derivation of the ELBO for BLR can be found in the Appendix
Theorem 2. The ELBO objective corresponding to the β-D posterior approximation in Eq. (11)

of an exponential family likelihood model fm(y; θm) = exp(cid:0)η(θm)T T (y)(cid:1) g(η(θm))A(x) with
conjugate prior π0(θm|ν0 X0) = g(η(θm))ν0 exp(cid:0)ν0η(θm)TX0
(cid:1) h(X0  ν0) and variational posterior
m (θm|νm Xm) = g(η(θm))νm exp(cid:0)νmη(θm)TXm
(cid:1) h(Xm  νm) within the same conjugate family
(cid:98)πβp
(cid:18) (1 + βp)T (z) + νmXm
(cid:20)
(cid:19)(cid:21)−1
E(cid:98)π
[η(θm)]   E(cid:98)π
The conditions of Theorem 2 are met by many exponential models  e.g. the Normal-Inverse-Gamma 
the quality of(cid:98)πβp following Yao et al. [48]  who estimate a difference ˆk between πβp
the Exponential-Gamma  and the Gamma-Gamma. For a simulated autoregressive BLR  we assess
m relative
m and drives the CP detection. Yao et al. [48] rate(cid:98)πβp
to a posterior expectation. We use this on the posterior predictive  which is an expectation relative to
πβp
m if ˆk < 0.5. Figs 3 and 2 B
show that our approximation lies well below this threshold for choices of βp decreasing reasonably
fast with the dimension. Note that these are exactly the values of βp one will want to select for
inference: As d increases  the magnitude of fmt(yt|Ft−1) decreases rapidly. Hence  βp needs to
decrease as d increases to prevent the β-D inference from being dominated by the integral in Eq. (5)
and disregarding yt [21]. This is also reﬂected in our experiments in section 5  for which we initialize
βp = 0.05 and βp = 0.005 for d = 1 and d = 29  respectively. However  as Figs. 3 and 2 B illustrate 
the approximation is still excellent for values of βp that are much larger than that.

m and(cid:98)πβp

m as close to πβp

[log g(η(θm))]  

  1 + β + νm

A(z)1+βp

h

1 + βp + νm

(cid:90)

βp
m

βp
m

dz.

3.2 Stochastic Variance Reduced Gradient (SVRG) for BOCPD

While highest predictive accuracy within BOCPD is achieved using full optimization of the variational
parameters at each of T time periods  this has space and time complexity of O(T ) and O(T 2). In
comparison  Stochastic Gradient Descent (SGD) has space and time complexity of O(1) and O(T ) 
but yields a loss in accuracy  substantially so for small run-lengths. In the BOCPD setting  there is
an obvious trade-off between accuracy and scalability: Since the posterior predictive distributions
fmt(yt|y1:(t−1)  rt) for all run-lengths rt drive CP detection  SGD estimates are insufﬁciently accurate
for small run-lengths rt. On the other hand  once rt is sufﬁciently large  the variational parameter
estimates only need minor adjustments and computing an optimum is costly.
Recently  a new generation of algorithms interpolating SGD and global optimization have addressed
this trade-off. They achieve substantially better convergence rates by anchoring the stochastic gradient
to a point near an optimum [22  9  35  18  29]. We propose a memory-efﬁcient two-stage variation of

6

Stochastic Variance Reduced Gradient (SVRG) inference for BOCPD

Input at time 0: Window & batch sizes W   B∗  b∗; frequency m  prior θ0  #steps K  step size η
for next observation yt at time t do

s.t. W > B∗ > b∗; and ∼ denotes sampling without replacement

for retained run-lengths r ∈ R(t) do

if τr = 0 then
if r < W then
θr ← θ∗
r ← FullOpt (ELBO(yt−r:t)); τr ← m
else if r ≥ W then
r ← θr; τr ← Geom (B∗/(B∗ + b∗))
(cid:80)
θ∗
B ← min(B∗  r)
r ← 1
i∈I ∇ELBO(θ∗
ganchor
b ← min(b∗  r) and(cid:101)I ∼ Unif{0  . . .   min(r  W )} and |(cid:101)I| = b
(cid:80)
θr ← θr + η ·(cid:0)gnew
r ← 1
gold

(cid:80)
(cid:1); τr ← τr − 1

for j = 1  2  . . .   K do

r ← 1

B

r   yt−i)  gnew
r + ganchor
r ← r + 1 for all r ∈ R(t); R(t) ← R(t) ∪ {0}

i∈(cid:101)I ∇ELBO(θ∗
r − gold

r

b

r   yt−i)  where I ∼ Unif{0  . . .   min(r  W )}  |I| = B

i∈(cid:101)I ∇ELBO(θr  yt−i)

b

these methods tailored to BOCPD. First  the variational parameters are moved close to their global
optimum using a variant of [22  35]. Unlike standard versions  we anchor the gradient estimates to
a (local) optimum by calling a convex optimizer FullOpt every m steps for the ﬁrst W iterations.
While our implementation uses Python scipy’s L-BFSG-B optimization routine  any convex optimizer
could be used for this step. Compared to standard SGD or SVRG  full optimization substantially
decreases variance and increases accuracy for small rt. Second  once rt > W we do not perform
full optimization anymore. Instead  we anchor optimization to the current value as in standard SVRG 
by updating the anchor at stochastic time intervals determined by a geometric random variable with
success probability B∗/(B∗ + b∗). Whether the anchor is based on global optimization or not  the
next step consists in sampling B = min(rt  B∗) observations without replacement from a window
with the min(rt  W ) most recent observations to initiate the SVRG procedure. Following this  for the
next K observations  we incrementally reﬁne the estimates while keeping their variance low using a
stochastic-batch variant of [29  30] by sampling a batch of size b = min(rt  b∗) without replacement
from the min(rt  W ) most recent observations. The resulting on-line inference has constant space
and linear time complexity like SGD  but produces good estimates for small rt and converges faster
[22  29  30]. We provide a detailed complexity analysis of the procedure in the Appendix  where we
also demonstrate numerically that it is orders of magnitude faster than MCMC-based inference.

4 Choice of β

Initializing βp: The β-D has been used in a variety of settings [15  4  14  49]  but there is no
principled framework for selecting β. We remedy this by minimizing the expected predictive loss
with respect to β on-line. As the losses need not be convex in βp  initial values can matter for
the optimization. A priori  we pick βp maximizing the β-D inﬂuence for a given Mahalanobis
Distance (MD) x∗ under π(θm). As Figure 1 A shows  βp > 0 induces a point of maximum inﬂuence
MD(βp  πm(θm)): Points further in the tails are treated as outliers  while points closer to the mode
(cid:99)MD(βp  πm(θm)) = argmaxx∈R+
receive similar inﬂuence as under the KLD. A Monte Carlo estimate of MD(βp  πm(θm)) is found via
problem: For x∗  we seek βp such that (cid:99)MD(βp  πm(θm)) = x∗. (The Appendix contains a pictorial
ˆI(βp  πm(θm))(x) [28]. We initialize βp by solving the inverse
illustration of this procedure.) The k-th standard deviation under the prior is a good choice of x∗
for low dimensions [see also 12]  but not appropriate as delimiter for high density regions even in
moderate dimensions d. Thus  we propose x∗ =
under normality  MD → √
d for larger values of d  inspired by the fact that
(cid:99)MD(βp  πm(θm)) with respect to βp. As βrlm does not affect πβp
d as d → ∞ [17]. One then ﬁnds βp by approximating the gradient of
m   its initialization matters less and
generally  initializing βrlm ∈ [0  1] produces reasonable results.

√

7

Optimizing β on-line: For β = (βrlm  βp) and prediction (cid:98)yt(β) of yt obtained as posterior ex-
pectation via Eq. (6)  deﬁne εt(β) = yt − (cid:98)yt(β). For predictive loss L : R → R+  we target
to ﬁnd the partial derivatives of ∇βL (εt(β)). Noting that ∇βL (εt(β))) = L(cid:48) (εt(β))) · ∇β (cid:98)yt(β) 
β∗ = argminβ {E (L(εt(β)))}. Replacing expected by empirical loss and deploying SGD  we seek
the issue reduces to ﬁnding the partial derivatives ∇βrlm(cid:98)yt(β) and ∇βp(cid:98)yt(β). Remarkably  ∇βrlm(cid:98)yt(β)
is provided in the Appendix. The gradient ∇βp(cid:98)yt(β) on the other hand is not available analytically

can be updated sequentially and efﬁciently by differentiating the recursion in Eq. (2b). The derivation

and thus is approximated numerically. Now  β can be updated on-line via

(12)

(cid:20)∇βrlm tL(cid:0)εt(β1:(t−1))(cid:1)
∇βp tL(cid:0)εt(β1:(t−1))(cid:1))

(cid:21)

βt = βt−1 − η ·

In spirit  this procedure resembles existing approaches for model hyperparameter optimization [8].
For robustness  L should be chosen appropriately. In our experiments L is a bounded absolute loss.

5 Results

Next  we illustrate the most important improvements this paper makes to BOCPD. First  we show
how robust BOCPD deals with outliers on the well-log data set. Further  we show that standard
BOCPD breaks down in the M-open world whilst β-D yields useful inference by analyzing noisy
measurements of Nitrogen Oxide (NOX) levels in London. In both experiments  we use the methods
in section 4  on-line hyperparameter optimization [8] and pruning for p(rt  mt|y1:t) [1]. Detailed
information is provided in the Appendix. Software and simulation code is available as part of a
reproducibility award at https://github.com/alan-turing-institute/rbocpdms/.

5.1 Well-log

The well-log data set was ﬁrst studied in Ruanaidh et al. [39] and has become a benchmark data
set for univariate CP detection. However  except in Fearnhead and Rigaill [12] its outliers have
been removed before CP detection algorithms are run [e.g. 1  31  40]. With M containing one BLR
model of form yt = µ + εt  Figure 4 shows that robust BOCPD deals with outliers on-line. The
maximum of the run-length distribution for standard BOCPD is zero 145 times  so declaring CPS
based on the run-length distribution’s maximum [see e.g. 41] yields a False Discovery Rate (FDR)
> 90%. This problem persists even with non-parametric  Gaussian Process  models [p. 186  45].
Even using Maximum A Posteriori (MAP) segmentation [11]  standard BOCPD mislabels 8 outliers
as CPS  making for a FDR > 40%. In contrast  the segmentation of the β-D version does not mislabel
any outliers. Morevoer and in accordance with Thm. 1  its run-length distribution’s maximum never
drops to zero in response to outliers. Further  a natural byproduct of the robust segmentation is a
reduction in squared (absolute) prediction error by 10% (6%) compared to the standard version. The

Figure 4: Maximum A Posteriori (MAP) segmentation and run-length distributions of the well-log
data. Robust segmentation depicted using solid lines  CPS additionally declared under standard
BOCPD with dashed lines. The corresponding run-length distributions for robust (middle) and
standard (bottom) BOCPD are shown in grayscale. The most likely run-lengths are dashed.

8

75000100000125000Response0100005001000150020002500300035004000Time01000run length1011710102108710721057104210271012robust version has more computational overhead than standard BOCPD  but still needs less than 0.5
seconds per observation using a 3.1 GHZ Intel i7 and 16GB RAM.
Not only does robust BOCPD’s segmentation in Figure 4 match that in Fearnhead and Rigaill [12] 
but it also offers three additional on-line outputs: Firstly  it produces probabilistic (rather than point)
forecasts and parameter inference. Secondly  it self-regulates its robustness via β. Thirdly  it can
compare multiple models and produce model posteriors (see section 5.2). Further  unlike Fearnhead
and Rigaill [12]  it is not restricted to ﬁtting univariate data with piecewise constant functions.

5.2 Air Pollution

The example in Fig. 1 B gives an illustration of the importance of robustness in medium-dimensional
(BOCPD) problems: It sufﬁces for a single dimension of the problem to be misspeciﬁed or outlier-
prone for inference to fail. Moreover  the presence of misspeciﬁcation or outliers in this plot can
hardly be spotted – and this effect will worsen with increasing dimensionality. To illustrate this point
on a multivariate real world data set  we also analyze Nitrogen Oxide (NOX) levels across 29 stations
in London using spatially structured Bayesian Vector Autoregressions [see 25]. Previous robust
on-line methods [e.g. 36  7  12] cannot be applied to this problem because they assume univariate
data or do not allow for dependent observations. As Figure 5 shows  robust BOCPD ﬁnds one CP
corresponding to the introduction of the congestion charge  while standard BOCPD produces an FDR
>90%. Both methods ﬁnd a change in dynamics (i.e. models) after the congestion charge introduction 
but variance in the model posterior is substantially lower for the robust algorithm. Further  it increases
the average one-step-ahead predictive likelihood by 10% compared to standard BOCPD.

6 Conclusion

This paper has presented the very ﬁrst robust Bayesian on-line changepoint (CP) detection algorithm
and the ﬁrst ever scalable General Bayesian Inference (GBI) method. While CP detection is a
particularly salient example of unaddressed heterogeneity and outliers leading to poor inference  the
capabilities of GBI and the Structural Variational approximations presented extend far beyond this
setting. With an ever increasing interest in the ﬁeld of machine learning to efﬁciently and reliably
quantify uncertainty  robust probabilistic inference will only become more relevant. In this paper 
we give a particularly striking demonstration of the inferential power that can be unlocked through
divergence-based General Bayesian inference.

Figure 5: On-line model posteriors for three different VAR models (solid  dashed  dotted) and run-
length distributions in grayscale with most likely run-lengths dashed for standard (top two panels) and
robust (bottom two panels) BOCPD. Also marked are the congestion charge introduction  17/02/2003
(solid vertical line) and the MAP segmentations (crosses)

9

0.00.51.0P(m|y)050run length0.00.51.0P(m|y)2002-092002-102002-112002-122003-012003-022003-032003-042003-052003-062003-072003-08Time0100200run length103121030910306Acknowledgements

We would like to cordially thank both Jim Smith and Chris Holmes for fruitful discussions and help
with some of the theoretical results. JK and JJ are funded by EPSRC grant EP/L016710/1 as part of the
Oxford-Warwick Statistics Programme (OXWASP). TD is funded by the Lloyds Register Foundation
programme on Data Centric Engineering through the London Air Quality project. This work was
supported by The Alan Turing Institute for Data Science and AI under EPSRC grant EP/N510129/1.
In collaboration with the Greater London Authority.

References
[1] Ryan Prescott Adams and David JC MacKay. Bayesian online changepoint detection. arXiv

preprint arXiv:0710.3742  2007.

[2] Mauricio Alvarez  Jan R Peters  Neil D Lawrence  and Bernhard Schölkopf. Switched latent
In Advances in neural information processing

force models for movement segmentation.
systems  pages 55–63  2010.

[3] Daniel Barry and John A Hartigan. A Bayesian analysis for change point problems. Journal of

the American Statistical Association  88(421):309–319  1993.

[4] Ayanendranath Basu  Ian R Harris  Nils L Hjort  and MC Jones. Robust and efﬁcient estimation

by minimising a density power divergence. Biometrika  85(3):549–559  1998.

[5] José M Bernardo and Adrian FM Smith. Bayesian theory  2001.

[6] Pier Giovanni Bissiri  Chris C Holmes  and Stephen G Walker. A general framework for
updating belief distributions. Journal of the Royal Statistical Society: Series B (Statistical
Methodology)  78(5):1103–1130  2016.

[7] Yang Cao and Yao Xie. Robust sequential change-point detection by convex optimization. In
Information Theory (ISIT)  2017 IEEE International Symposium on  pages 1287–1291. IEEE 
2017.

[8] François Caron  Arnaud Doucet  and Raphael Gottardo. On-line changepoint detection and
parameter estimation with application to genomic data. Statistics and Computing  22(2):
579–595  2012.

[9] Aaron Defazio  Francis Bach  and Simon Lacoste-Julien. Saga: A fast incremental gradient
method with support for non-strongly convex composite objectives. In Advances in neural
information processing systems  pages 1646–1654  2014.

[10] Adji Bousso Dieng  Dustin Tran  Rajesh Ranganath  John Paisley  and David Blei. Variational
inference via χ upper bound minimization. In Advances in Neural Information Processing
Systems  pages 2729–2738  2017.

[11] Paul Fearnhead and Zhen Liu. On-line inference for multiple changepoint problems. Journal of

the Royal Statistical Society: Series B (Statistical Methodology)  69(4):589–605  2007.

[12] Paul Fearnhead and Guillem Rigaill. Changepoint detection in the presence of outliers. Journal

of the American Statistical Association  (just-accepted)  2017.

[13] Emily Fox and David B Dunson. Multiresolution Gaussian processes. In Advances in Neural

Information Processing Systems  pages 737–745  2012.

[14] Futoshi Futami  Issei Sato  and Masashi Sugiyama. Variational inference based on robust

divergences. In Artiﬁcial Intelligence and Statistics  2018.

[15] Abhik Ghosh and Ayanendranath Basu. Robust Bayes estimation using the density power

divergence. Annals of the Institute of Statistical Mathematics  68(2):413–437  2016.

[16] Marco Grzegorczyk and Dirk Husmeier. Non-stationary continuous dynamic Bayesian networks.

In Advances in Neural Information Processing Systems  pages 682–690  2009.

10

[17] Peter Hall  JS Marron  and Amnon Neeman. Geometric representation of high dimension  low
sample size data. Journal of the Royal Statistical Society: Series B (Statistical Methodology) 
67(3):427–444  2005.

[18] Reza Harikandeh  Mohamed Osama Ahmed  Alim Virani  Mark Schmidt  Jakub Koneˇcn`y  and
Scott Sallinen. Stopwasting my gradients: Practical svrg. In Advances in Neural Information
Processing Systems  pages 2251–2259  2015.

[19] José Miguel Hernández-Lobato  Yingzhen Li  Mark Rowland  Daniel Hernández-Lobato 
Thang D Bui  and Richard E Turner. Black-box α-divergence minimization. In Proceedings of
the 33rd International Conference on International Conference on Machine Learning-Volume
48  pages 1511–1520. JMLR. org  2016.

[20] He Huang and Martin Paulus. Learning under uncertainty: a comparison between rw and
Bayesian approach. In Advances in Neural Information Processing Systems  pages 2730–2738 
2016.

[21] Jack Jewson  Jim Smith  and Chris Holmes. Principles of bayesian inference using general

divergence criteria. Entropy  20(6):442  2018.

[22] Rie Johnson and Tong Zhang. Accelerating stochastic gradient descent using predictive variance

reduction. In Advances in neural information processing systems  pages 315–323  2013.

[23] Azadeh Khaleghi and Daniil Ryabko. Locating changes in highly dependent data with unknown
In Advances in Neural Information Processing Systems  pages

number of change points.
3086–3094  2012.

[24] Rebecca Killick  Idris A Eckley  Kevin Ewans  and Philip Jonathan. Detection of changes in
variance of oceanographic time-series using changepoint analysis. Ocean Engineering  37(13):
1120–1126  2010.

[25] Jeremias Knoblauch and Theodoros Damoulas. Spatio-temporal Bayesian on-line changepoint
detection with model selection. In Proceedings of the 27th International Conference on Machine
Learning (ICML)  2018.

[26] George Konidaris  Scott Kuindersma  Roderic Grupen  and Andrew G Barto. Constructing skill
trees for reinforcement learning agents from demonstration trajectories. In Advances in neural
information processing systems  pages 1162–1170  2010.

[27] Erich Kummerfeld and David Danks. Tracking time-varying graphical structure. In Advances

in neural information processing systems  pages 1205–1213  2013.

[28] Sebastian Kurtek and Karthik Bharath. Bayesian sensitivity analysis with the Fisher–Rao metric.

Biometrika  102(3):601–616  2015.

[29] Lihua Lei and Michael Jordan. Less than a single pass: Stochastically controlled stochastic

gradient. In Artiﬁcial Intelligence and Statistics  pages 148–156  2017.

[30] Lihua Lei  Cheng Ju  Jianbo Chen  and Michael I Jordan. Non-convex ﬁnite-sum optimization
via scsg methods. In Advances in Neural Information Processing Systems  pages 2345–2355 
2017.

[31] Céline Levy-leduc and Zaïd Harchaoui. Catching change-points with lasso. In Advances in

Neural Information Processing Systems  pages 617–624  2008.

[32] Yingzhen Li and Richard E Turner. Rényi divergence variational inference. In Advances in

Neural Information Processing Systems  pages 1073–1081  2016.

[33] Kevin Lin  James L Sharpnack  Alessandro Rinaldo  and Ryan J Tibshirani. A sharp error
In

analysis for the fused Lasso  with application to approximate changepoint screening.
Advances in Neural Information Processing Systems  pages 6887–6896  2017.

[34] Scott Niekum  Sarah Osentoski  Christopher G Atkeson  and Andrew G Barto. CHAMP:
Changepoint detection using approximate model parameters. Technical report  (No. CMU-RI-
TR-14-10) Carnegie-Mellon University Pittsburgh PA Robotics Institute  2014.

11

[35] Atsushi Nitanda. Stochastic proximal gradient descent with acceleration techniques. In Advances

in Neural Information Processing Systems  pages 1574–1582  2014.

[36] Moshe Pollak. A robust changepoint detection method. Sequential Analysis  29(2):146–161 

2010.

[37] Aleksey S Polunchenko  Alexander G Tartakovsky  and Nitis Mukhopadhyay. Nearly optimal
change-point detection with an application to cybersecurity. Sequential Analysis  31(3):409–435 
2012.

[38] Rajesh Ranganath  Dustin Tran  Jaan Altosaar  and David Blei. Operator variational inference.

In Advances in Neural Information Processing Systems  pages 496–504  2016.

[39] Ó Ruanaidh  JK Joseph  and William J Fitzgerald. Numerical Bayesian methods applied to

signal processing. 1996.

[40] Eric Ruggieri and Marcus Antonellis. An exact approach to Bayesian sequential change point

detection. Computational Statistics & Data Analysis  97:71–86  2016.

[41] Yunus Saatçi  Ryan D Turner  and Carl E Rasmussen. Gaussian process change point models.
In Proceedings of the 27th International Conference on Machine Learning (ICML-10)  pages
927–934  2010.

[42] Florian Stimberg  Manfred Opper  Guido Sanguinetti  and Andreas Ruttor.

Inference in
continuous-time change-point models. In Advances in Neural Information Processing Systems 
pages 2717–2725  2011.

[43] Ryan Turner  Yunus Saatci  and Carl Edward Rasmussen. Adaptive sequential Bayesian change

point detection. In Temporal Segmentation Workshop at NIPS  2009.

[44] Ryan D Turner  Steven Bottone  and Clay J Stanek. Online variational approximations to
non-exponential family change point models: with application to radar tracking. In Advances in
Neural Information Processing Systems  pages 306–314  2013.

[45] Ryan Darby Turner. Gaussian processes for state space models and change point detection.

PhD thesis  University of Cambridge  2012.

[46] Robert C Wilson  Matthew R Nassar  and Joshua I Gold. Bayesian online learning of the hazard

rate in change-point problems. Neural computation  22(9):2452–2476  2010.

[47] Xiang Xuan and Kevin Murphy. Modeling changing dependency structure in multivariate
time series. In Proceedings of the 24th international conference on Machine learning  pages
1055–1062. ACM  2007.

[48] Yuling Yao  Aki Vehtari  Daniel Simpson  and Andrew Gelman. Yes  but did it work?: Evaluat-

ing variational inference. arXiv preprint arXiv:1802.02538  2018.

[49] Kenan Y Yılmaz  Ali T Cemgil  and Umut Simsekli. Generalised coupled tensor factorisation.

In Advances in neural information processing systems  pages 2151–2159  2011.

[50] XianXing Zhang  Lawrence Carin  and David B Dunson. Hierarchical topic modeling for
analysis of time-evolving personal choices. In Advances in Neural Information Processing
Systems  pages 1395–1403  2011.

12

,Ali Borji
Laurent Itti
Jeremias Knoblauch
Jack Jewson
Theodoros Damoulas