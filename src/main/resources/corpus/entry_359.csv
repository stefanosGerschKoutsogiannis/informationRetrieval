2010,Active Learning by Querying Informative and Representative Examples,Most active learning approaches select either informative or representative unlabeled instances to query their labels. Although several active learning algorithms have been proposed to combine the two criterions for query selection  they are usually ad hoc in finding unlabeled instances that are both informative and representative. We address this challenge by a principled approach  termed QUIRE  based on the min-max view of active learning. The proposed approach provides a systematic way for measuring and combining the informativeness and representativeness of an instance. Extensive experimental results show that the proposed QUIRE approach outperforms several state-of -the-art active learning approaches.,Active Learning by Querying

Informative and Representative Examples

Sheng-Jun Huang1

Rong Jin2

Zhi-Hua Zhou1

1National Key Laboratory for Novel Software Technology 

Nanjing University  Nanjing 210093  China

2Department of Computer Science and Engineering 
Michigan State University  East Lansing  MI 48824

{huangsj  zhouzh}@lamda.nju.edu.cn

rongjin@cse.msu.edu

Abstract

Most active learning approaches select either informative or representative unla-
beled instances to query their labels. Although several active learning algorithms
have been proposed to combine the two criteria for query selection  they are usu-
ally ad hoc in ﬁnding unlabeled instances that are both informative and repre-
sentative. We address this challenge by a principled approach  termed QUIRE 
based on the min-max view of active learning. The proposed approach provides
a systematic way for measuring and combining the informativeness and represen-
tativeness of an instance. Extensive experimental results show that the proposed
QUIRE approach outperforms several state-of -the-art active learning approaches.

1

Introduction

In this work  we focus on the pool-based active learning  which selects an unlabeled instance from
a given pool for manually labeling. There are two main criteria  i.e.  informativeness and represen-
tativeness  that are widely used for active query selection. Informativeness measures the ability of
an instance in reducing the uncertainty of a statistical model  while representativeness measures if
an instance well represents the overall input patterns of unlabeled data [16]. Most active learning
algorithms only deploy one of the two criteria for query selection  which could signiﬁcantly limit the
performance of active learning: approaches favoring informative instances usually do not exploit the
structure information of unlabeled data  leading to serious sample bias and consequently undesirable
performance for active learning; approaches favoring representative instances may require querying
a relatively large number of instances before the optimal decision boundary is found. Although sev-
eral active learning algorithms [19  8  11] have been proposed to ﬁnd the unlabeled instances that
are both informative and representative  they are usually ad hoc in measuring the informativeness
and representativeness of an instance  leading to suboptimal performance.

In this paper  we propose a new active learning approach by QUerying Informative and Represen-
tative Examples (QUIRE for short). The proposed approach is based on the min-max view of active
learning [11]  which provides a systematic way for measuring and combining the informativeness
and the representativeness. The interesting feature of the proposed approach is that it measures both
the informativeness and representativeness of an instance by its prediction uncertainty: the informa-
tiveness of an instance x is measured by its prediction uncertainty based on the labeled data  while
the representativeness of x is measured by its prediction uncertainty based on the unlabeled data.

The rest of this paper is organized as follows: Section 2 reviews the related work on active learning;
Section 3 presents the proposed approach in details; experimental results are reported in Section 4;
Section 5 concludes this work with issues to be addressed in the future.

1

(a) A binary classiﬁcation

(b) An approach favoring

problem

informative instances

(c) An approach favoring
representative instances

(d) Our approach

Figure 1: An illustrative example for selecting informative and representative instances

2 Related Work

Querying the most informative instances is probably the most popular approach for active learning.
Exemplar approaches include query-by-committee [17  6  10]  uncertainty sampling [13  12  18  2]
and optimal experimental design [9  20]. The main weakness of these approaches is that they are
unable to exploit the abundance of unlabeled data and the selection of query instances is solely
determined by a small number of labeled examples  making it prone to sample bias. Another school
of active learning is to select the instances that are most representative to the unlabeled data. These
approaches aim to exploit the cluster structure of unlabeled data [14  7]  usually by a clustering
method. The main weakness of these approaches is that their performance heavily depends on the
quality of clustering results [7].

Several active learning algorithms tried to combine the informativeness measure with the represen-
tativeness measure for ﬁnding the optimal query instances. In [19]  the authors propose a sampling
algorithm that exploits both the cluster information and the classiﬁcation margins of unlabeled in-
stances. One limitation of this approach is that since clustering is only performed on the instances
within the classiﬁcation margin  it is unable to exploit the unlabeled instances outside the margin.
In [8]  Donmez et al. extended the active learning approach in [14] by dynamically balancing the
uncertainty and the density of instances for query selection. This approach is ad hoc in combining
the measure of informativeness and representativeness for query selection  leading to suboptimal
performance.

Our work is based on the min-max view of active learning  which was ﬁrst proposed in the study of
batch mode active learning [11]. Unlike [11] which measures the representativeness of an instance
by its similarity to the remaining unlabeled instances  our proposed measure of representativeness
takes into account the cluster structure of unlabeled instances as well as the class assignments of the
labeled examples  leading to a better selection of unlabeled instances for active learning.

3 QUIRE: QUery Informative and Representative Examples

We start with a synthesized example that illustrates the importance of querying instances that are
both informative and representative for active learning. Figure 1 (a) shows a binary classiﬁcation
problem with each class represented by a different legend. We examine three different active learning
algorithms by allowing them to sequentially select 15 data points. Figure 1 (b) and (c) show the
data points selected by an approach favoring informative instances (i.e.  [18]) and by an approach
favoring representative instances (i.e.  [7])  respectively. As indicated by Figure 1 (b)  due to the
sample bias  the approach preferring informative instances tends to choose the data points close to
the horizontal line  leading to incorrect decision boundaries. On the other hand  as indicated by
Figure 1 (c)  the approach preferring representative instances is able to identify the approximately
correct decision boundary but with a slow convergence. Figure 1 (d) shows the data points selected
by the proposed approach that favors data points that are both informative and representative. It is
clear that the proposed algorithm is more efﬁcient in ﬁnding the accurate decision boundary than the
other two approaches.

We denote by D = {(x1  y1)  (x2  y2)  · · ·   (xnl   ynl )  xnl+1  · · ·   xn} the training data set that
consists of nl labeled instances and nu = n − nl unlabeled instances  where each instance
xi = [xi1  xi2  · · ·   xid]⊤ is a vector of d dimension and yi ∈ {−1  +1} is the class label of xi.

2

Active learning selects one instance xs from the pool of unlabeled data to query its class label. For
convenience  we divide the data set D into three parts: the labeled data Dl  the currently selected
instance xs  and the rest of the unlabeled data Du. We also use Da = Du ∪ {xs} to represent all
the unlabeled instances. We use y = [yl  ys  yu] for the class label assignment of the entire data set 
where yl  ys and yu are the class labels assigned to Dl  xs and Du  respectively. Finally  we denote
by ya = [ys  yu] the class assignment for all the unlabeled instances.

3.1 The Framework

To motivate the proposed approach  we ﬁrst re-examine the margin-based active learning from the
viewpoint of min-max [11]. Let f ∗ be a classiﬁcation model trained by the labeled examples  i.e. 

f ∗ = arg min

f ∈H

λ
2

|f |2

H +

nlXi=1

ℓ(yi  f (xi)) 

(1)

where H is a reproducing kernel Hilbert space endowed with kernel function κ(·  ·) : Rd × Rd → R.
ℓ(z) is the loss function. Given the classiﬁer f ∗  the margin-based approach chooses the unlabeled
instance closest to the decision boundary  i.e. 

s∗ = arg min
nl<s≤n

|f ∗(xs)|.

It is shown in the supplementary document that this criterion can be approximated by

s∗ = arg min
n1<s≤n

L(Dl  xs) 

where

L(Dl  xs) = max
ys=±1

min
f ∈H

λ
2

|f |2

H +

nlXi=1

ℓ(yi  f (xi)) + ℓ(ys  f (xs)).

(2)

(3)

(4)

We can also write Eq. 3 in a minimax form
min

where

A(Dl  xs) = min
f ∈H

max
ys=±1

A(Dl  xs) 

nl<s≤n
λ
2

|f |2

H +

nlXi=1

ℓ(yi  f (xi)) + ℓ(ys  f (xs)).

In this min-max view of active learning  it guarantees that the selected instance xs will lead to a
small value for the objective function regardless of its class label ys. In order to select queries that
are both informative and representative  we extend the evaluation function L(Dl  xs) to include all
the unlabeled data. Hypothetically  if we know the class assignment yu for the unselected unlabeled
instances in Du  the evaluation function can be modiﬁed as

L(Dl  Du  yu  xs) = max
ys=±1

min
f ∈H

λ
2

|f |2

H +

nXi=1

ℓ(yi  f (xi)).

(5)

The problem is that the class assignment yu is unknown. According to the manifold assumption [3] 
we expect that a good solution for yu should result in a small value of L(Dl  Du  yu  xs). We
therefore approximate the solution for yu by minimizing L(Dl  Du  yu  xs)  which leads to the
following evaluation function for query selection:

bL(Dl  Du  xs) =

min

yu∈{±1}nu−1

L(Dl  Du  yu  xs)

(6)

=

min

yu∈{±1}nu−1

max
ys=±1

min
f ∈H

3.2 The Solution

λ
2

|f |2

H +

nXi=1

ℓ(yi  f (xi))

For computational simplicity  for the rest of this work  we choose a quadratic loss function  i.e. 

ℓ(y by) = (y −by)2/2 1. It is straightforward to show

|f |2

H +

(yi − f (xi))2 =

min
f ∈H

λ
2

1
2

nXi=1

1
2

y⊤Ly 

1Although quadratic loss may not be ideal for classiﬁcation  it does yield competitive classiﬁcation results

when compared to the other loss functions such as hinge loss [15].

3

where L = (K + λI)−1 and K = [κ(xi  xj)]n×n is the kernel matrix of size n × n. Thus  the

evaluation function bL(Dl  Du  xs) is simpliﬁed as

min

bL(Dl  Du  xs) =

yu∈{−1 +1}nu−1

max

ys∈{−1 +1}

y⊤Ly.

(7)

Our goal is to efﬁciently compute the above quantity for each unlabeled instance. For the conve-
nience of presentation  we refer to by subscript u the rows/columns in a matrix M for the unlabeled
instances in Du  by subscript l the rows/columns in M for labeled instances in Dl  and by subscript
s the row/column in M for the selected instance. We also refer to by subscript a the rows/columns
in M for all the unlabeled instances (i.e.  Du ∪ {xs}). Using these conventions  we rewrite the
objective y⊤Ly as

y⊤Ly = ylLl lyl + Ls s + yT

u Lu uyu + 2yT

u (Lu lyl + Lu sys) + 2ysy⊤

l Ll s.

Note that since the above objective function is concave (linear) in ys and convex (quadratic) in
yu  we can switch the maximization of yu with the minimization of ys in (7). By relaxing yu to
continuous variables  the solution to minyu y⊤Ly is given by

leading to the following expression for the evaluation function bL(Dl  Du  xs):

{2ysLs lyl

l Ll lyl + max

ys

byu = −Lu u
bL(Dl  Du  xs) = Ls s + yT

−1(Lu lyl + Lu sys) 

−(Lu lyl + Lu sys)T Lu u

−1(Lu lyl + Lu sys)}

(8)

(9)

where the last step follows the relation

Ls s

det(La a)

∝ Ls s −

+ 2(cid:12)(cid:12)(cid:0)Ls l − Ls uL−1
u uLu l(cid:1) yl(cid:12)(cid:12)  
A21 A22(cid:21)(cid:19)= det(A22)det(cid:0)A11 − A12A−1
22 A21(cid:1) .

det(cid:18)(cid:20)A11 A12

Note that although yu is relaxed to real numbers  according to our empirical studies  we ﬁnd that in
most cases  yu falls between −1 and +1.

Remark. The evaluation function bL(Dl  Du  xs) essentially consists of two components: Ls s −

det(La a)/Ls s and |(Ls l − Ls uL−1
u uLu l)yl|. Minimizing the ﬁrst component is equivalent to
minimizing Ls s because La a is independent from the selected instance xs. Since L = (K +λI)−1 
we have

Ls s = (cid:20)Ks s − (Ks l  Ks u)(cid:18) Kl l Kl u

Ku l Ku u(cid:19)(cid:18) Kl s
(Ks l  Ks u)(cid:18) Kl l Kl u

Ku s(cid:19)(cid:21)−1
Ku l Ku u(cid:19)(cid:18) Kl s

Ku s(cid:19)(cid:21) .

≈

1

Ks s (cid:20)1 +

1

Ks s

Therefore  to choose an instance with small Ls s  we select the instance with large self-similarity
Ks s. When self-similarity Ks s is a constant  this term will not affect query selection.

To analyze the effect of the second component  we approximate it as:

(10)

2(cid:12)(cid:12)(cid:0)Ls l − Ls uL−1

u uLu l(cid:1) yl(cid:12)(cid:12) ≈ 2 |Ls lyl| + 2(cid:12)(cid:12)Ls uL−1
≈ 2|Ls lyl| + 2|Ls ubyu|.

u uLu lyl(cid:12)(cid:12)

The ﬁrst term in the above approximation measures the conﬁdence in predicting xs using only
labeled data  which corresponds to the informativeness of xs. The second term measures the pre-
diction conﬁdence using only the predicted labels of the unlabeled data  which can be viewed as the
measure of representativeness. This is because when xs is a representative instance  it is expected to
share a large similarity with many of the unlabeled instances in the pool. As a result  the prediction

for xs by the unlabeled data in Du is decided by the average of their assigned class labelsbyu. If we

assume that the classes are evenly distributed over the unlabeled data  we should expect a low con-
ﬁdence in predicting the class label for xs by unlabeled data. It is important to note that unlike the

4

Algorithm 1 The QUIRE Algorithm

Input:

D : A data set of n instances

Initialize:

Dl = ∅; nl = 0 % no labeled data is available at the very beginning
Du = D; nu = n % the pool of unlabeled data

Calculate K
repeat

a a using Proposition 2 and det(La a)

Calculate L−1
for s = 1 to nu do

Calculate L−1

uu according to Theorem 1

end for

Calculate bL(Dl  Du  xs) using Eq. 9
Select the xs∗ with the smallest bL(Dl  Du  xs∗ ) and query its label ys∗

Dl = Dl ∪ (xs∗  ys∗ ); Du = Du \ xs∗

until the number of queries or the required accuracy is reached

existing work that measures the representativeness only by the cluster structure of unlabeled data 

our proposed measure of representativeness depends on byu  which essentially combines the cluster

structure of unlabeled data with the class assignments of labeled data. Given high-dimensional data 
there could be many possible cluster structures that are consistent with the unlabeled data and it is
unclear which one is consistent with the target classiﬁcation problem. It is therefore critical to take
into account the label information when exploiting the cluster structure of unlabeled data.

3.3 Efﬁcient Algorithm

Computing the evaluation function bL(Dl  Du  xs) in Eq. 9 requires computing L−1

u u for every un-
labeled instance xs  leading to high computational cost when the number of unlabeled instances is
very large. The theorem below allows us to improve the computational efﬁciency dramatically.

Theorem 1. Let

We have

a a =(cid:18)Ls s Ls u

Lu s Lu u(cid:19)−1

L−1

=(cid:18) a −b⊤
−b D (cid:19) .

L−1

u u = D −

1
a

bb⊤.

The proof can be found in the supplementary document. As indicated by Theorem 1  we only need
to compute L−1
a a. The following
proposition allows us to simplify the computation for L−1
a a.

u u can be computed directly from L−1

a a once; for each xs  its L−1

Proposition 2. L−1

a a = (λIa + Ka a) − Ka l(λIl + Kl l)−1Kl a

Proposition 2 follows directly from the inverse of a block matrix. As indicated by Proposition 2 
we only need to compute (λI + Kl l)−1. Given that the number of labeled examples is relatively
small compared to the size of unlabeled data  the computation of L−1
a a is in general efﬁcient. The
pseudo-code of QUIRE is summarized in Algorithm 1. Excluding the time for computing the kernel
matrix  the computational complexity of our algorithm is just O(nu).

4 Experiments

We compare QUIRE with the following ﬁve baseline approaches: (1) RANDOM: randomly select
query instances  (2) MARGIN: margin-based active learning [18]  a representative approach which
selects informative instances  (3) CLUSTER: hierarchical-clustering-based active learning [7]  a rep-
resentative approach that chooses representative instances  (4) IDE: active learning that selects in-
formative and diverse examples [11]  and (5) DUAL: a dual strategy for active learning that exploits
both informativeness and representativeness for query selection. Note that the original algorithm
in [11] is designed for batch mode active learning. We turn it into an active learning algorithm that
selects a single instance in each iteration by setting the parameter k = 1.

5

80

70

60

)

%

(
 
y
c
a
r
u
c
c
A

50

 
0

100

90

80

70

60

50

 
0

100

90

80

70

60

50

40

 
0

)

%

(
 
y
c
a
r
u
c
c
A

)

%

(
 

y
c
a
r
u
c
c
A

90

80

70

60

)

%

(
 

y
c
a
r
u
c
c
A

50

 
0

 

 

 

90

80

70

60

)

%

(
 
y
c
a
r
u
c
c
A

50

 
0

Random
Margin
Cluster
IDE
DUAL
Quire

20

40

60

80

Number of queried examples

Random
Margin
Cluster
IDE
DUAL
Quire

20

40

60

80

100

Number of queried examples

(a) austra

(b) digit1

 

100

 

Random
Margin
Cluster
IDE
DUAL
Quire

10

5
25
Number of queried examples

15

20

30

)

%

(
 
y
c
a
r
u
c
c
A

90

80

70

60

50

40

 
0

Random
Margin
Cluster
IDE
DUAL
Quire

100

50
250
Number of queried examples

150

200

300

)

%

(
 
y
c
a
r
u
c
c
A

80

70

60

50

)

%

(
 
y
c
a
r
u
c
c
A

90

80

70

60

50

 
0

 
0

Random
Margin
Cluster
IDE
DUAL
Quire

200

100
500
Number of queried examples

300

400

(c) g241n

600

 

Random
Margin
Cluster
IDE
DUAL
Quire

50

100

150

Number of queried examples

(d) isolet

(e) titato

(f) vehicle

 

100

)

%

(
 

y
c
a
r
u
c
c
A

90

80

70

60

50

 
0

60

 

100

)

%

(
 

y
c
a
r
u
c
c
A

90

80

70

60

50

 
0

60

 

100

)

%

(
 

y
c
a
r
u
c
c
A

90

80

70

60

50

 
0

60

Random
Margin
Cluster
IDE
DUAL
Quire

20

10
50
Number of queried examples

40

30

Random
Margin
Cluster
IDE
DUAL
Quire

20

10
50
Number of queried examples

40

30

(h) letterDvsP

(i) letterEvsF

 

100

)

%

(
 

y
c
a
r
u
c
c
A

90

80

70

60

50

 
0

Random
Margin
Cluster
IDE
DUAL
Quire

20

40

60

80

100

Number of queried examples

Random
Margin
Cluster
IDE
DUAL
Quire

20

10
50
Number of queried examples

40

30

 

60

 

60

Random
Margin
Cluster
IDE
DUAL
Quire

20

10
50
Number of queried examples

30

40

(g) wdbc

Random
Margin
Cluster
IDE
DUAL
Quire

20

10
50
Number of queried examples

40

30

(j) letterIvsJ

(k) letterMvsN

(l) letterUvsV

Figure 2: Comparison on classiﬁcation accuracy

Twelve data sets are used in our study and their statistics are shown in the supplementary document.
Digit1 and g241n are benchmark data sets for semi-supervised learning [5]; austria  isolet  titato 
vechicle  and wdbc are UCI data sets [1]; letter is a multi-class data set [1] from which we select
ﬁve pairs of letters that are relatively difﬁcult to distinguish  i.e.  D vs P  E vs F  I vs J  M vs N 
U vs V  and construct a binary class data set for each pair. Each data set is randomly divided into
two parts of equal size  with one part as the test data and the other part as the unlabeled data that is
used for active learning. We assume that no labeled data is available at the very beginning of active
learning. For MARGIN  IDE and DUAL  instances are randomly selected when no classiﬁcation
model is available  which only takes place at the beginning. In each iteration  an unlabeled instance
is ﬁrst selected to solicit its class label and the classiﬁcation model is then retrained using additional
labeled instance. We evaluate the classiﬁcation model by its performance on the holdout test data.
Both classiﬁcation accuracy and Area Under ROC curve (AUC) are used for evaluation metrics. For
every data set  we run the experiment for ten times  each with a random partition of the data set. We
also conduct experiments with a few initially labeled examples and have similar observation. Due to
the space limit  we put in the supplementary document the experimental results with a few initially
labeled examples. In all the experiments  the parameter λ is set to 1 and a RBF kernel with default

6

Table 1: Comparison on AUC values (mean ± std). The best performance and its comparable
performances based on paired t-tests at 95% signiﬁcance level are highlighted in boldface.

Data

Algorithms

Number of queries (percentage of the unlabeled data)

5%

10%

20%

30%

40%

50%

80%

austra

digit1

g241n

isolet

titato

vehicle

wdbc

letterDvsP

letterEvsF

letterIvsJ

letterMvsN

letterUvsV

RANDOM
MARGIN
CLUSTER
IDE
DUAL
QUIRE

RANDOM
MARGIN
CLUSTER
IDE
DUAL
QUIRE

RANDOM
MARGIN
CLUSTER
IDE
DUAL
QUIRE

RANDOM
MARGIN
CLUSTER
IDE
DUAL
QUIRE

RANDOM
MARGIN
CLUSTER
IDE
DUAL
QUIRE

RANDOM
MARGIN
CLUSTER
IDE
DUAL
QUIRE

RANDOM
MARGIN
CLUSTER
IDE
DUAL
QUIRE

RANDOM
MARGIN
CLUSTER
IDE
DUAL
QUIRE

RANDOM
MARGIN
CLUSTER
IDE
DUAL
QUIRE

RANDOM
MARGIN
CLUSTER
IDE
DUAL
QUIRE

RANDOM
MARGIN
CLUSTER
IDE
DUAL
QUIRE

RANDOM
MARGIN
CLUSTER
IDE
DUAL
QUIRE

.868±.027
.751±.137
.877±.045
.858±.101
.866±.037
.887±.014
.945±.009
.941±.028
.938±.035
.954±.011
.929±.014
.976±.006
.713±.040
.700±.057
.720±.038
.727±.030
.722±.040
.757±.035
.995±.006
.965±.052
.998±.002
.998±.003
.993±.008
.997±.002
.762±.033
.645±.096
.717±.087
.735±.040
.708±.069
.736±.037
.818±.064
.693±.078
.771±.088
.731±.141
.680±.074
.750±.137
.984±.006
.967±.038
.981±.007
.983±.006
.955±.025
.985±.006
.990±.004
.994±.005
.988±.008
.992±.006
.978±.005
.998±.001
.977±.020
.987±.008
.975±.016
.977±.014
.976±.011
.988±.009
.943±.025
.882±.096
.952±.022
.934±.030
.819±.120
.951±.023
.977±.010
.964±.040
.971±.017
.969±.017
.950±.025
.986±.007
.992±.005
.998±.002
.990±.008
.995±.004
.983±.014
.999±.001

.894±.022
.838±.119
.888±.029
.885±.058
.878±.036
.901±.010
.969±.006
.972±.009
.952±.018
.973±.007
.953±.009
.986±.003
.769±.021
.751±.048
.770±.024
.786±.029
.751±.019
.825±.019
.998±.002
.999±.001
.999±.002
.999±.002
.999±.001
.999±.001
.861±.031
.753±.078
.806±.054
.906±.029
.782±.064
.861±.025
.864±.039
.828±.077
.845±.056
.849±.106
.706±.114
.912±.024
.986±.005
.990±.002
.987±.004
.984±.008
.964±.016
.990±.004
.995±.002
.999±.001
.995±.004
.997±.002
.986±.001
.999±.001
.988±.009
.999±.001
.991±.003
.995±.003
.993±.003
.999±.000
.966±.017
.960±.027
.961±.017
.969±.011
.897±.058
.963±.013
.992±.002
.991±.014
.986±.009
.988±.007
.972±.011
.996±.003
.996±.004
1.00±.000
.996±.009
.999±.001
.986±.008
1.00±.000

.897±.023
.885±.043
.894±.015
.902±.012
.875±.018
.906±.016
.979±.005
.989±.002
.963±.019
.987±.002
.975±.004
.990±.002
.822±.018
.830±.022
.815±.018
.840±.017
.822±.011
.857±.020
.999±.001
1.00±.000
1.00±.000
.999±.001
.999±.001
.999±.001
.954±.023
.946±.043
.908±.031
.996±.003
.900±.027
.991±.004
.925±.032
.883±.105
.927±.022
.878±.093
.817±.061
.956±.025
.990±.004
.993±.003
.991±.003
.990±.004
.972±.015
.993±.003
.997±.002
.999±.000
.997±.002
.998±.001
.988±.004
.999±.001
.994±.002
1.00±.000
.997±.004
.999±.000
.996±.002
1.00±.000
.980±.004
.986±.005
.976±.008
.979±.006
.934±.030
.976±.011
.994±.003
.999±.000
.994±.003
.997±.002
.974±.007
.998±.001
.998±.001
1.00±.000
1.00±.000
1.00±.000
.990±.008
1.00±.000

.901±.022
.909±.010
.896±.015
.912±.008
.876±.016
.912±.009
.984±.003
.992±.002
.974±.011
.991±.002
.982±.005
.992±.002
.854±.016
.864±.019
.835±.021
.866±.016
.838±.022
.884±.013
1.00±.000
1.00±.000
1.00±.000
1.00±.001
1.00±.000
1.00±.000
.979±.011
.998±.001
.971±.021
.999±.001
.981±.012
.999±.001
.949±.026
.981±.014
.955±.018
.957±.037
.875±.035
.985±.007
.991±.004
.993±.003
.992±.003
.992±.003
.988±.009
.993±.003
.998±.001
.999±.001
.998±.001
.999±.001
.990±.004
.999±.001
.997±.002
1.00±.000
.999±.001
.999±.000
.996±.002
1.00±.000
.983±.005
.989±.006
.985±.007
.980±.006
.954±.017
.989±.010
.996±.002
.999±.000
.997±.002
.998±.001
.980±.008
.999±.000
.999±.000
1.00±.000
1.00±.000
1.00±.000
.991±.008
1.00±.000

.909±.015
.911±.012
.903±.014
.913±.009
.879±.013
.914±.009
.985±.003
.992±.002
.985±.002
.992±.002
.985±.003
.992±.002
.873±.015
.896±.012
.860±.022
.883±.013
.865±.016
.900±.009
1.00±.000
1.00±.000
1.00±.000
1.00±.000
1.00±.001
1.00±.001
.991±.007
1.00±.000
.989±.010
1.00±.001
.995±.006
1.00±.000
.968±.016
.993±.005
.973±.010
.977±.010
.908±.035
.989±.006
.991±.004
.993±.003
.992±.003
.993±.003
.992±.003
.993±.003
.998±.001
.999±.001
.999±.001
.999±.001
.996±.001
.999±.001
.998±.001
1.00±.000
1.00±.000
.999±.000
.996±.002
1.00±.000
.985±.005
.991±.004
.987±.006
.982±.008
.959±.014
.991±.004
.997±.001
.999±.000
.998±.001
.998±.001
.983±.007
.999±.000
1.00±.000
1.00±.000
1.00±.000
1.00±.000
.993±.007
1.00±.000

.909±.012
.914±.009
.907±.015
.914±.007
.881±.013
.915±.007
.988±.003
.992±.002
.988±.003
.992±.002
.987±.003
.992±.002
.886±.012
.911±.008
.880±.013
.899±.011
.881±.012
.912±.006
1.00±.000
1.00±.000
1.00±.000
1.00±.000
1.00±.000
1.00±.000
.997±.004
1.00±.000
.997±.003
1.00±.000
.999±.001
1.00±.000
.975±.013
.993±.005
.978±.011
.985±.009
.947±.035
.991±.005
.991±.004
.993±.003
.993±.003
.993±.003
.992±.003
.993±.003
.998±.001
.999±.001
.999±.001
.999±.001
.998±.001
.999±.001
.999±.001
1.00±.000
1.00±.000
1.00±.000
.998±.001
1.00±.000
.987±.004
.991±.004
.989±.005
.985±.005
.953±.015
.991±.004
.997±.001
.999±.000
.998±.001
.998±.001
.983±.007
.999±.000
1.00±.000
1.00±.000
1.00±.000
1.00±.000
.995±.005
1.00±.000

.917±.011
.915±.008
.913±.011
.916±.007
.904±.008
.916±.007
.991±.002
.992±.002
.992±.002
.992±.002
.991±.002
.992±.002
.906±.014
.918±.008
.909±.009
.916±.010
.912±.007
.920±.009
1.00±.000
1.00±.000
1.00±.000
1.00±.000
1.00±.000
1.00±.000
1.00±.000
1.00±.000
1.00±.000
1.00±.000
1.00±.000
1.00±.000
.989±.006
.992±.005
.992±.006
.991±.006
.980±.016
.992±.005
.993±.003
.993±.003
.993±.003
.993±.003
.992±.004
.993±.003
.999±.001
.999±.001
.999±.001
.999±.001
.999±.001
.999±.001
1.00±.000
1.00±.000
1.00±.000
1.00±.000
1.00±.000
1.00±.000
.990±.004
.991±.004
.991±.004
.990±.004
.988±.004
.991±.004
.998±.001
.999±.000
.999±.000
.999±.000
.998±.001
.999±.000
1.00±.000
1.00±.000
1.00±.000
1.00±.000
.999±.000
1.00±.000

parameters is used (performances with linear kernel are not as stable as that with RBF kernel).
LibSVM [4] is used to train a SVM classiﬁer for all active learning approaches in comparison.

7

Table 2: Win/tie/loss counts of QUIRE versus the other methods with varied numbers of queries.

Algorithms

RANDOM
MARGIN
CLUSTER
IDE
DUAL
In All

5%

4/8/0
6/6/0
6/6/0
6/6/0
8/4/0

30/30/0

4.1 Results

Number of queries (percentage of the unlabeled data)

10%

20%

30%

40%

50%

80%

8/4/0
4/7/1
7/5/0
6/5/1
10/2/0
35/23/2

9/3/0
2/8/2
8/4/0
6/5/1
11/1/0
36/21/3

9/2/1
2/8/2
11/1/0
8/4/0
10/2/0
40/17/3

10/2/0
0/11/1
9/3/0
8/4/0
10/2/0
37/22/1

10/2/0
0/11/1
6/6/0
8/4/0
11/1/0
35/24/1

6/6/0
1/11/0
3/9/0
2/10/0
9/3/0

In All

56/27/1
15/62/7
50/34/0
44/38/2
69/15/0

21/39/0

234/176/10

Figure 2 shows the classiﬁcation accuracy of different active learning approaches with varied num-
bers of queries. Table 1 shows the AUC values  with 5%  10%  20%  30%  40%  50% and 80% of
unlabeled data used as queries. For each case  the best result and its comparable performances are
highlighted in boldface based on paired t-tests at 95% signiﬁcance level. Table 2 summarizes the
win/tie/loss counts of QUIRE versus the other methods based on the same test. We also perform the
Wilcoxon signed ranks test at 95% signiﬁcance level  and obtain almost the same results  which can
be found in the supplementary document.

First  we observe that the RANDOM approach tends to yield decent performance when the number
of queries is very small. However  as the number of queries increases  this simple approach loses
its edge and often is not as effective as the other active learning approaches. MARGIN  the most
commonly used approach for active learning  is not performing well at the beginning of the learn-
ing stage. As the number of queries increases  we observe that MARGIN catches up with the other
approaches and yields decent performance. This phenomenon can be attributed to the fact that with
only a few training examples  the learned decision boundary tends to be inaccurate  and as a result 
the unlabeled instances closest to the decision boundary may not be the most informative ones. The
performance of CLUSTER is mixed. It works well on some data sets  but performs poorly on the
others. We attribute the inconsistency of CLUSTER to the fact that the identiﬁed cluster structure
of unlabeled data may not always be consistent with the target classiﬁcation model. The behavior
of IDE is similar to that of CLUSTER in that it achieves good performance on certain data sets and
fails on the others. DUAL does not yield good performance on most data sets although we have
tried our best efforts to tune the related parameters. We attribute the failure of DUAL to the setup
of our experiment in which no initially labeled examples are provided. Further study shows that
starting with a few initially labeled examples does improve the performance of DUAL though it is
still signiﬁcantly outperformed by QUIRE.Detailed results can be found in the supplementary doc-
ument. Finally  we observe that for most cases  QUIRE is able to outperform the baseline methods
signiﬁcantly  as indicated by Figure 2  Tables 1 and 2. We attribute the success of QUIRE to the prin-
ciple of choosing unlabeled instances that are both informative and representative  and the specially
designed computational framework that appropriately measures and combines the informativeness
and representativeness. The computational cost are reported in the supplementary document.

5 Conclusion

We propose a new approach for active learning  called QUIRE  that is designed to ﬁnd unlabeled in-
stances that are both informative and representative. The proposed approach is based on the min-max
view of active learning  which provides a systematic way for measuring and combining the infor-
mativeness and the representativeness. Our current work is restricted to binary classiﬁcation. In the
future  we plan to extend this work to multi-class learning. We also plan to develop the mechanism
which allows the user to control the tradeoff between informativeness and representativeness based
on their domain  leading to the incorporation of domain knowledge into active learning algorithms.

Acknowledgements

This work was supported in part by the NSFC (60635030)  973 Program (2010CB327903)  Jiang-
suSF (BK2008018) and NSF (IIS-0643494).

8

References

[1] A. Asuncion and D.J. Newman. UCI machine learning repository  2007.

[2] M. F. Balcan  A. Z. Broder  and T. Zhang. Margin based active learning. In Proceedings of the

20th Annual Conference on Learning Theory  pages 35–50  2007.

[3] M. Belkin  P. Niyogi  and V. Sindhwani. Manifold regularization: A geometric framework
for learning from labeled and unlabeled examples. Journal of Machine Learning Research 
7:2399–2434  2006.

[4] C. C. Chang and C. J. Lin. LIBSVM: A library for support vector machines  2001.

[5] O. Chapelle  B. Sch¨olkopf  and A. Zien  editors. Semi-supervised learning. MIT Press  Cam-

bridge  MA  2006.

[6] I. Dagan and S. P. Engelson. Committee-based sampling for training probabilistic classiﬁers.
In Proceedings of the 12th International Conference on Machine Learning  pages 150–157 
1995.

[7] S. Dasgupta and D. Hsu. Hierarchical sampling for active learning. In Proceedings of the 25th

International Conference on Machine Learning  pages 208–215  2008.

[8] P. Donmez  J. G. Carbonell  and P. N. Bennett. Dual strategy active learning. In Proceedings

of the 18th European Conference on Machine Learning  pages 116–127  2007.

[9] P. Flaherty  M. I. Jordan  and A. P. Arkin. Robust design of biological experiments. In Advances

in Neural Information Processing Systems 18  pages 363–370  2005.

[10] Y. Freund  H. S. Seung  E. Shamir  and N. Tishby. Selective sampling using the query by

committee algorithm. Machine Learning  28(2-3):133–168  1997.

[11] S. C. H. Hoi  R. Jin  J. Zhu  and M. R. Lyu. Semi-supervised svm batch mode active learning
for image retrieval. In Proceedings of the IEEE Computer Society Conference on Computer
Vision and Pattern Recognition  2008.

[12] D. D. Lewis and J. Catlett. Heterogeneous uncertainty sampling for supervised learning. In
Proceedings of the 11th International Conference on Machine Learning  pages 148–156  1994.

[13] D. D. Lewis and W. A. Gale. A sequential algorithm for training text classiﬁers. In Proceedings
of the 17th Annual International ACM-SIGIR Conference on Research and Development in
Information Retrieval  pages 3–12  1994.

[14] H. T. Nguyen and A. W. M. Smeulders. Active learning using pre-clustering. In Proceedings

of the 21st International Conference on Machine Learning  pages 623–630  2004.

[15] R. Rifkin R  G. Yeo  and T. Poggio. Regularized least squares classiﬁcation.

In S. Basu
C. Micchelli J. A. K. Suykens  G. Horvath and J. Vandewalle  editors  Advances in Learning
Theory: Methods  Model and Applications  NATO Science Series III: Computer and Systems
Sciences. Volume 190  pages 131–154  2003.

[16] B. Settles. Active learning literature survey. Computer Sciences Technical Report 1648  Uni-

versity of Wisconsin–Madison  2009.

[17] H. S. Seung  M. Opper  and H. Sompolinsky. Query by committee. In Proceedings of the 5th

ACM Workshop on Computational Learning Theory  pages 287–294  1992.

[18] S. Tong and D. Koller. Support vector machine active learning with applications to text clas-
siﬁcation. In Proceedings of the 17th International Conference on Machine Learning  pages
999–1006  2000.

[19] Z. Xu  K. Yu  V. Tresp  X. Xu  and J. Wang. Representative sampling for text classiﬁcation us-
ing support vector machines. In Proceedings of the 25th European Conference on Information
Retrieval Research  pages 393–407  2003.

[20] K. Yu  J. Bi  and V. Tresp. Active learning via transductive experimental design. In Proceedings

of the 23th International Conference on Machine Learning  pages 1081–1088  2006.

9

,Shinichi Nakajima
Issei Sato
Masashi Sugiyama
Kazuho Watanabe
Hiroko Kobayashi
Vignesh Ganapathiraman
Xinhua Zhang
Yaoliang Yu
Junfeng Wen