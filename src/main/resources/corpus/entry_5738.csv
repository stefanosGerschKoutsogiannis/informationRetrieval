2008,Unifying the Sensory and Motor Components of Sensorimotor Adaptation,Adaptation of visually guided reaching movements in novel visuomotor environments (e.g. wearing prism goggles) comprises not only motor adaptation but also substantial sensory adaptation  corresponding to shifts in the perceived spatial location of visual and proprioceptive cues. Previous computational models of the sensory component of visuomotor adaptation have assumed that it is driven purely by the discrepancy introduced between visual and proprioceptive estimates of hand position and is independent of any motor component of adaptation. We instead propose a unified model in which sensory and motor adaptation are jointly driven by optimal Bayesian estimation of the sensory and motor contributions to perceived errors. Our model is able to account for patterns of performance errors during visuomotor adaptation as well as the subsequent perceptual aftereffects. This unified model also makes the surprising prediction that force field adaptation will elicit similar perceptual shifts  even though there is never any discrepancy between visual and proprioceptive observations. We confirm this prediction with an experiment.,Unifying the Sensory and Motor Components

of Sensorimotor Adaptation

Adrian Haith

School of Informatics

University of Edinburgh  UK

adrian.haith@ed.ac.uk

Carl Jackson

School of Psychology

University of Birmingham  UK
c.p.jackson.1@bham.ac.uk

Chris Miall

School of Psychology

Sethu Vijayakumar
School of Informatics

University of Birmingham  UK

r.c.miall@bham.ac.uk

University of Edinburgh  UK
sethu.vijayakumar@ed.ac.uk

Abstract

Adaptation of visually guided reaching movements in novel visuomotor en-
vironments (e.g. wearing prism goggles) comprises not only motor adapta-
tion but also substantial sensory adaptation  corresponding to shifts in the
perceived spatial location of visual and proprioceptive cues. Previous com-
putational models of the sensory component of visuomotor adaptation have
assumed that it is driven purely by the discrepancy introduced between vi-
sual and proprioceptive estimates of hand position and is independent of
any motor component of adaptation. We instead propose a uniﬁed model in
which sensory and motor adaptation are jointly driven by optimal Bayesian
estimation of the sensory and motor contributions to perceived errors. Our
model is able to account for patterns of performance errors during visuo-
motor adaptation as well as the subsequent perceptual aftereﬀects. This
uniﬁed model also makes the surprising prediction that force ﬁeld adap-
tation will elicit similar perceptual shifts  even though there is never any
discrepancy between visual and proprioceptive observations. We conﬁrm
this prediction with an experiment.

1 Introduction

When exposed to a novel visuomotor environment  for instance while wearing prism goggles 
subjects initially exhibit large directional errors during reaching movements but are able to
rapidly adapt their movement patterns and approach baseline performance levels within
around 30-50 reach trials. Such visuomotor adaptation is multifaceted  comprising both
sensory and motor components [5]. The sensory components of adaptation can be measured
through alignment tests in which subjects are asked to localize either a visual target or their
unseen ﬁngertip  with their other (also unseen) ﬁngertip (without being able to make contact
between hands). These tests reveal substantial shifts in the perceived spatial location of both
visual and proprioceptive cues  following adaptation to shifted visual feedback [7].

While a shift in visual spatial perception will be partially reﬂected in reaches towards visual
targets  sensory adaptation alone cannot fully account for the completenes of visuomo-
tor adaptation  since the shifts in visual perception are always substantially less than the
experimentally-imposed shift. There must therefore be some additional motor component
of adaptation  i.e. some change in the relationship between the planned movement and the

v
r
t

disturbances}

y
r
t

p
r
t

ut

yt

motor command

hand position

vt

pt

proprioceptive
observation

visual observation

Figure 1: Graphical model of a single reach
in a motor adaptation experiment. Motor
command ut  and visual and proprioceptive
observations of hand position  vt and pt  are
available to the subject. Three distinct dis-
turbances aﬀect observations: A motor dis-
y
turbance r
t may aﬀect the hand position yt
given the motor command ut. Visual and
p
proprioceptive disturbances  r
t   may
aﬀect the respective observations given hand
position.

v
t and r

issued motor command. This argument is reinforced by the ﬁnding that patterns of reach
aftereﬀects following visuomotor adaptation depend strongly on the motor task performed
during adaptation [5].

From a modelling point of view  the sensory and motor components of adaptation have
previously only been addressed in isolation of one another. Previously proposed models of
sensory adaptation have assumed that it is driven purely by discrepancies between hand
position estimates from diﬀerent sensory modalities. Ghahramani et al.
[2] proposed a
computational model based on a maximum likelihood principle  details of which we give in
Section 3. On its own  this sensory adaptation model cannot provide a complete description
of visuomotor adaptation since it does not fully account for improvements in performance
from trial to trial. It can  however  be plausibly combined with a conventional error-driven
motor adaptation model in which the performance error is calculated using the maximum
likelihood estimate of hand position. The resulting composite model could plausibly account
for both performance improvements and perceptual shifts during visuomotor adaptation.
According to this view  sensory and motor adaptation are very much independent processes 
one driven by sensory discrepancy and the other driven by (estimated) task performance
error.

In Section 4  we argue for a more uniﬁed view of sensory and motor adaptation in which
all three components of adaptation are jointly guided by optimal Bayesian inference of the
corresponding potential sources of error experienced on each trial  given noisy visual and
proprioceptive observations of performance and noisy motor execution. This uniﬁed sensory
and motor adaptation model is also able to account for both performance improvements and
perceptual shifts during visuomotor adaptation. However  our uniﬁed model also makes the
surprising prediction that a motor disturbance  e.g. an external force applied to hand via
a manipulandum  will also elicit sensory adaptation. The MLE-based model predicts no
such sensory adaptation  since there is never any discrepancy between sensory modalities.
We test this prediction directly with an experiment (Section 5) and ﬁnd that force ﬁeld
adaptation does indeed lead to sensory as well as motor adaptation.

2 Modelling framework

Before describing the details of the models  we ﬁrst outline a basic mathematical frame-
work for describing reaching movements in the context of a motor adaptation experiment 
representing the assumptions common to both the MLE-based and the Bayesian adapta-
tion models. Figure 1 illustrates a graphical model of a single reaching movement during
an adaptation experiment  from the subject’s point of view. The multiple components of
visuomotor adaptation described above correspond to three distinct potential sources of
observed outcome error (across both observation) modalities in a single reaching trial.

On trial t  the subject generates a (known) motor command ut. This motor command ut
leads to a ﬁnal hand position yt  which also depends on some (unknown) motor disturbance

v

r

p

r

yt

vt

pt

Figure 2: MLE-based sensor adaptation model.
p are
Visual and proprioceptive disturbances r
v
treated as parameters of the model. Estimates ˆr
t
p
and ˆr
t of these parameters are maintained via an
online EM-like procedure.

v  r

y
t (e.g. an external force applied to the hand) and motor noise ǫ
r
hand position yt is given by

u
t . We assume the ﬁnal

u
t ∼ N (0  σ

(1)
where ǫ
u). Although this is a highly simpliﬁed description of the forward dynam-
ics of the reaching movement  it can be regarded as a ﬁrst-order approximation to the true
dynamics. Similar assumptions have proved very successful elsewhere in models of force
ﬁeld adaptation  e.g. [1]

yt = ut + r

2

y
t + ǫ

u
t  

The experimenter ultimately measures the hand position yt  however this is not directly
observed by the subject. Instead  noisy and potentially shifted observations are available
through visual and proprioceptive modalities 

vt = yt + r
pt = yt + r

v
v
t + ǫ
t  
p
p
t + ǫ
t  

(2)
(3)

2

where the observation noises ǫ
p  respectively.
σ
We denote the full set of potential disturbances on trial t by

v
t and ǫ

p
t are zero-mean and Gaussian with variances σ

2

v and

rt = (r

v
t   r

p
t   r

y

t )T

.

(4)

y
p
t )T of the total
v
We assume that the subject maintains an internal estimate ˆrt = (ˆr
t   ˆr
t   ˆr
disturbance rt and selects his motor commands on each trial accordingly. For reaches to a
visual target located at v

t   the appropriate motor command is given by

∗

ut = v

∗

y
v
t − ˆr
t − ˆr
t .

(5)

Adaptation can be viewed as a process of iteratively updating the disturbance estimate  ˆrt 
following each trial given the new (noisy) observations vt and pt and the motor command
ut. Exactly how the subject uses the information available to infer the current disturbances
is the subject of subsequent sections of this paper.

3 Existing sensory adaptation models

The prevailing view of sensory adaptation centres around the principle of maximum likeli-
hood estimation and was ﬁrst proposed by Ghahramani et al. [2] in the context of combining
discrepant visual and auditory cues in a target location task. It has nevertheless been wide-
ley accepted as a model of how the nervous system deals with visual and proprioceptive
cues. Van Beers et al.
[7]  for instance  based an analysis of the relative uncertainty of
visual and proprioceptive estimates of hand location on this principle.

We suppose that  given the subject’s current estimate of the visual and proprioceptive
p
v
t   the visual and proprioceptive estimates of hand position are given
disturbance  ˆr
t and ˆr
by

v
v
ˆy
t = vt − ˆr
t  
p
p
t = pt − ˆr
ˆy
t

(6)
(7)

respectively. These distinct estimates of hand position are combined via maximum likelihood
estimation [7] into a single fused estimate of hand position.The maximum likelihood estimate
(MLE) of the true hand position yt is given by

M LE
ˆy
t

=

2
p

σ

2

2
v + σ
σ
p

v
ˆy
t +

2
v

σ

2

2
v + σ
σ
p

p
ˆy
t .

(8)

v
r
t

v
t+1

r

p
r
t

y
r
t

ut

yt

p
t+1

r

y
t+1

r

ut+1

yt+1

vt

pt

vt+1

pt+1

Figure 3: Bayesian com-
bined sensory and motor
adaptation model.
The
subject assumes that dis-
turbances vary randomly 
but smoothly  from trial to
trial.

The MLE-based sensory adaptation model states that subjects adapt their future visual and
proprioceptive estimates of hand location towards the MLE in such a way that the MLE
itself remains unchanged. The corresponding updates are given by

p
v
v
v
ˆr
t+1 = ˆr
t − ˆy
t + ηwp [ˆy
t ]  
p
p
p
v
ˆr
t+1 = ˆr
t + ηwv [ˆy
t − ˆy
t ]  

(9)

(10)

where η is some ﬁxed adaptation rate. This adaptation principle can be interpreted as an
online expectation-maximization (EM) procedure in the graphical model shown in Figure
p are treated as parameters of the model. The E-step of the EM
2. In this model  r
procedure corresponds to ﬁnding the MLE of yt and the M-step corresponds to gradient
ascent on the likelihood of ˆr

v and ˆr

v and r

p.

3.1 Extending the MLE model to account for motor component of adaptation

As it stands  the MLE-based model described above only accounts for sensory adaptation
and does not provide a complete description of sensorimotor adaptation. Visual adaptation
will aﬀect the estimated location of a visual target  and therefore also the planned movement 
but the eﬀect on performance will not be enough to account for complete (or nearly complete)
adaptation. The performance gain from this component of adaptation will be equal to the
discrepancy between the initial visual setimate of hand posion and the MLE - which will be
substantially less than the experimentally imposed shift.

This sensory adaptation model can  however  be plausibly combined with a conventional
error-driven state space model [6  1] of motor adaptation to yield an additional motor
y
component of adaptation ˆr
t . The hand position MLE ˆyt can be used in place of the usual
uni-modal observation assumed in these models when calculating the endpoint error. The
y
t on trial t is given by
resulting update for the estimated motor disturbance ˆr

y
ˆr
t+1 = ˆr

y
t + γ(ˆy

∗

M LE
t − ˆy
t

) 

(11)

where ˆy
rate.

∗

t = (v

v
∗ − ˆr
t ) is the estimated desired hand location  and γ is some ﬁxed adaptation

This combined model reﬂects the view that sensory and motor adaptation are distinct
processes. The sensory adaptation component is driven purely by discrepancy between the
senses  while the motor adaptation component only has access to a single  fused estimate of
hand position and is driven purely by estimated performance error.

4 Uniﬁed Bayesian sensory and motor adapatation model

We propose an alternative approach to solving the sensorimotor adaptation problem. Rather
p as parameters  we consider all the disturbances (in-
than treat the visual shifts r
y
t ) as dynamic random variables. We assume that the subject’s beliefs about how
cluding r

v and r

30

20

10

o

/
r
o
r
r

E

 
l

a
n
o

i
t
c
e
r
i

D

0

 
0

 

Data
Bayesian Model
MLE Model

5

10

15

20
Trial Number

25

30

Figure 4: Model comparison with visuomo-
tor adaptation data. The Bayesian model
(solid blue line) and MLE-based model
(dashed red line) were ﬁtted to performance
data (ﬁlled circles) from a visuomotor adap-
tation experiment [4]. Both models made
qualitatively similar predictions about how
adaptation was distributed across compo-
nents.

these disturbances evolve over time are characterised by a trial-to-trial disturbance dynamics
model given by

(12)
where A is some diagonal matrix and ηt is a random drift term with zero mean and diagonal
covariance matrix Q  i.e.

rt+1 = Art + ηt 

v

p

  q

ηt ∼ N (0  Q).

(13)
A and Q are both diagonal to reﬂect the fact that each disturbance evolves independently.
u) and the diagonal of Q by q =
We denote the diagonal elements of A by a = (a
u). The vector a describes the timescales over which each disturbance persists 
(q
while q describes the amount of random variation from trial to trial  or volatility of each
disturbance. These parameters reﬂect the statistics of the usual ﬂuctuations in sensory
calibration errors and motor plant dynamics  which the sensorimotor system must adapt to
on an ongoing basis. (Similar assumptions have previously been made elsewhere [3  4]).

  a

  a

  q

p

v

Combining these assumptions with the statistical model of each individual trial described
in Section 2 (and Figure 1)  gives rise to a dynamical model of the disturbances and their
impact on reaching movements  across all trials. This model  representing the subjects
beliefs about how his sensorimotor performance is liable to vary over time  is illustrated in
Figure 4. We propose that the patterns of adaptation and the sensory aftereﬀects exhibited
by subjects correspond to optimal inference of the disturbances rt within this model  given
the observations on each trial.

The linear dynamics and Gaussian noise of the observer’s model mean that exact inference is
straightforward and equivalent to a Kalman ﬁlter. The latent state tracked by the Kalman
t )T   with state dynamics given by (12). The
ﬁlter is the vector of disturbances rt = (r
observations vt and pt are related to the disturbances via

p
t   r

v
t   r

y

(cid:18) vt

pt (cid:19) = (cid:18) ut

ut (cid:19) +(cid:18) 1 0

0 1

1

1 (cid:19) (rt + ǫt)  

where ǫt = (ǫ

v
t   ǫ

p
t   ǫ

u

t )T . We can write this in a more conventional form as

zt = Hrt + H ǫt 

(14)

(15)

where zt = (vt − ut  pt − ut)T and H is the matrix of 1’s and 0’s in equation (14). The
observation noise covariance is given by

R = E(cid:2)(H ǫt)(H ǫt)T(cid:3) = (cid:18) σ

2

2
v + σ
u

2
u

σ

2
u

σ

2

p + σ
σ

u (cid:19) .

2

(16)

The standard Kalman ﬁlter update equations can be used to predict how a subject will
update estimates of the disturbances following each trial and therefore how he will select
his actions on the next trial  leading to a full prediction of performance from the ﬁrst trial
onwards.

5 Model comparison and experiments

We have described two alternative models of visuomotor adaptation which we have claimed
can account for both the motor and sensory components of adaptation. We ﬁtted both

(a)

y

x

Error

(b)

Target

Adapted
trajectory

Catch trial
trajectory

Start

Figure 5: (a) Experimental Setup  (b) Sample trajectories and performance error measure

models to performance data from a visuomotor adaptation experiment [4] to validate this
claim. In this study in which this data was taken from  subjects performed visually guided
reaching movements to a number of targets. Visual feedback of hand position (given via a
cursor on a screen) was rotated by 30o relative to the starting position of each movement.
The mean directional error (averaged over targets and over subjects) over trials is plotted in
Figure 4. The Matlab function lsqnonlin was used to ﬁnd the parameters for each model
which minimized the sum of the error between the data and the predictions of each model.
u  η  γ). For the Bayesian
There were 5 free parameters for the MLE-based model (σ
model we assumed that all disturbances had the same timescale  i.e. all elements of a were
the same  leaving 7 free parameters (σ
  a). The results of the ﬁts are shown
in Figure 4. The spread of adaptation across components of the model was qualitatively
similar between the two models  although no data on perceptual aftereﬀects was available
from this study for quantitative comparison. The Bayesian model clearly displays a closer ﬁt
to the data and the Akaike information criterion (AIC) conﬁrmed that this was not simply
due to extra parameters (AI C = 126.7 for the Bayesian model vs AI C = 159.6 for the
MLE-based model).

2
p   σ

2
v   σ

2
v   σ

2
p   σ

v

2
u  q

  q

  q

2

p

u

Although the Bayesian model appears to describe the data better  this analysis is by no
means conclusive. Furthermore  the similar scope of predictions between the two models
means that gathering additional data from alignment tests may not provide any further
leverage to distinguish between the two models. There is  however  a more striking diﬀerence
in predictions between the two models. While the MLE-based model predicts there will be
sensory adaptation only when there is a discrepancy between the senses  the Bayesian model
predicts that there will also be sensory adaptation in response to a motor disturbance such
as an external force applied to the hand). Just as a purely visual disturbance can lead
to a multifaceted adaptive response  so can a purely motor disturbance  with both motor
and sensory components predicted  even though there is never any discrepancy between the
senses. This prediction enables us to distinguish decisively between the two models.

5.1 Experimental Methods

We experimentally tested the hypothesis that force ﬁeld adaptation would lead to sensory
adaptation. We tested 11 subjects who performed a series of trials consisting of reaching
movements interleaved with perceptual alignment tests.

Subjects grasped the handle of a robotic manipulandum with their right hand. The hand
was not visible directly  but a cursor displayed via a mirror/ﬂat screen monitor setup (Fig-
ure 5.1(a)) was exactly co-planar and aligned with the handle of the manipulandum. In
the movement phase  subjects made an out-and-back reaching movement towards a visual
target with their right hand. In the visual localization phase  a visual target was displayed
pseudorandomly in one of 5 positions and the subjects moved their left ﬁngertip to the
perceived location of the target. In the proprioceptive localization phase  the right hand
was passively moved to a random target location  with no visual cue of its position  and
subjects moved their left ﬁngertip to the perceived location of the right hand. Left ﬁngertip

Mean Localization Error − x

Mean Localization Error − y

m
c
 
/
 
r
o
r
r

 

E
n
a
e
M

4

3.5

3

2.5

2

1.5

1

0.5

0

−0.5

−1

 

 

Pre−Adaptation
Post−Adaptation

Vision

Proprioception

Modality

m
c
 
/
 
r
o
r
r

 

E
n
a
e
M

11

10.5

10

9.5

9

8.5

8

7.5

7

6.5

6

 

 

Pre−Adaptation
Post−Adaptation

Vision

Proprioception

Modality

Figure 6: (a) Average lateral (in direction of the perturbation) localization error across
subjects before vs after adaptation  for vision and proprioception. Error bars indicate
standard errors. (b) Same plots for y-direction

positions were recorded using a Polhemus motion tracker. Neither hand was directly visible
at any time during the experiment.

Subjects were given 25 baseline trials with zero external force  after which a force ﬁeld was
gradually introduced. A leftward lateral force Fx was applied to the right hand during the
reaching phase. The magnitude of the force was proportional to the forward velocity ˙y of
the hand  i.e.

Fx = −a ˙y.

(17)

The force was applied only on the outward part of the movement (i.e. only when ˙y > 0).
After steadily incrementing a during 50 adaptation trials  the force ﬁeld was then kept
−1) for a further 25 post-adaptation test trials. All subjects
constant at a = 0.3 N/(cms
received a catch trial at the very end in which the force ﬁeld was turned oﬀ.

The particular force ﬁeld used was chosen so that the cursor trajectories (and motor com-
mands required to counter the perturbation) would be as close as possible to those used
to generate the linear trajectories required when exposed to a visuomotor shift (such as
that described in [7]). Figure 5.1(b) shows two trajectories from a typical subject  one from
the post-adaptation test phase and one from the catch trial after adaptation. The initial
outward part of the catch trial trajectory  the initial movement is very straight  implying
that similar motor commands were used to those required by a visuomotor shift.

5.2 Results

We compared the average performance in the visual and proprioceptive alignment tests
before and after adaptation in the velocity-dependent force ﬁeld. The results are summarized
in Figure 6(a). Most subjects exhibited small but signiﬁcant shifts in performance in both
the visual and proprioceptive alignment tests. Two subjects exhibited shifts which were
more than two standard deviations away from the average shift and were excluded from the
analysis. We found signiﬁcant lateral shifts in both visual and proprioceptive localization
error in the direction of the perturbation (both p < .05  one-tailed paired t-test). Figure
6(b) shows the same data for the direction perpendicular to the perturbation. Although the
initial localization bias was high  there was no signiﬁcant shift in this direction following
adaptation.

We quantiﬁed each subject’s performance on each trial as the perpendicular distance of the
furthest point in the trajectory from the straight line between the starting point and the
target (Fig. 5.1(b)). We ﬁtted the Bayesian and MLE-based models to the data following the
same procedure as before  only this time penalizing the disagreement between the model
and the data for the alignment tests  in addition to the reaching performance. Figure 7
illustrates the averaged data along with the model ﬁts. Both models were able to account
reasonably well for the trends in reaching performance across trials (7(a)). Figures 7(b) and
7(c) show the model ﬁts for the perceptual localization task. The Bayesian model is able to
account for both the extent of the shift and the timecourse of this shift during adaptation.

m
c
 
/
 
r
o
r
r

 

E
e
c
n
a
m
r
o

f
r
e
P

3

2

1

0

−1

−2

−3

 
0

(a) Reaching Performance

 

Data
Bayesian Model
MLE Model

20

40
60
Trial Number

80

100

m
c
 
/
 
r
o
r
r

E

 
t

n
e
m
n
g

i
l

A

4

2

0

−2

0

(b) Visual Alignment

(c) Proprioceptive Alignment

m
c
 
/
 
r
o
r
r

E

 
t

n
e
m
n
g

i
l

A

4

2

0

−2

0

20

40
60
Trial Number

80

100

20

40
60
Trial Number

80

100

Figure 7: Trial-by-trial data and model ﬁts. (a) Reaching error  (b) Visual alignment test
error  (c) Proprioceptive alignment test error. The Bayesian (solid blue lines) and MLE-
based (dashed red lines) were ﬁtted to averaged data across subjects (circles).

Since there was never any sensory discrepancy  the MLE-based model predicted no change
in the localization task.

6 Conclusions and discussion

Our experimental results demonstrate that adaptation of reaching movements in a force
ﬁeld results in shifts in visual and proprioceptive spatial perception. This novel ﬁnding
strongly supports the Bayesian model  which predicted such adaptation  and refutes the
MLE-based model  which did not. The Bayesian model was able to account for the trends
in both reaching performance and alignment test errors on a trial-to-trial basis.

Several recent models have similarly described motor adaptation as a process of Bayesian
inference of the potential causes of observed error. K¨ording et al. [3] proposed a model of
saccade adaptation and Krakauer et al. [4] modelled visuomotor adaptation based on this
principle. Our work extends the framework of these models to include multiple observation
modalities instead of just one  and multiple classes of disturbances which aﬀect the diﬀerent
observation modalities in diﬀerent  experimentally measurable ways.

Overall  our results suggest that the nervous system solves the problems of sensory and
motor adaptation in a principled and uniﬁed manner  supporting the view that sensorimotor
adaptation proceeds according to optimal estimation of encountered disturbances.

References

[1] Opher Donchin  Joseph T Francis  and Reza Shadmehr. Quantifying generalization from
trial-by-trial behavior of adaptive systems that learn with basis functions: theory and
experiments in human motor control. J Neurosci  23(27):9032–9045  Oct 2003.

[2] Z. Ghahramani  D.M. Wolpert  and M.I. Jordan. Computational models for sensorimotor
integration. In P.G. Morasso and V. Sanguineti  editors  Self-Organization  Computa-
tional Maps and Motor Control  pages 117–147. North-Holland  Amsterdam  1997.

[3] Konrad P. K¨ording  Joshua B. Tenenbaum  and Reza Shadmehr. The dynamics of
memory as a consequence of optimal adaptation to a changing body. Nat Neurosci 
10(6):779–786  June 2007.

[4] John W Krakauer  Pietro Mazzoni  Ali Ghazizadeh  Roshni Ravindran  and Reza Shad-
mehr. Generalization of motor learning depends on the history of prior action. PLoS
Biol  4(10):e316  Sep 2006.

[5] M.C. Simani  L.M. McGuire  and P.N. Sabes. Visual-shift adaptation is composed of
separable sensory and task-dependent eﬀects. J Neurophysiol  98:2827–2841  Nov 2007.
[6] K A Thoroughman and R Shadmehr. Learning of action through adaptive combination

of motor primitives. Nature  407(6805):742–747  Oct 2000.

[7] Robert J van Beers  Daniel M Wolpert  and Patrick Haggard. When feeling is more
important than seeing in sensorimotor adaptation. Curr Biol  12(10):834–837  May
2002.

,Guangcan Liu
Ping Li