2019,Multi-marginal Wasserstein GAN,Multiple marginal matching problem aims at learning mappings to match a source domain to multiple target domains and it has attracted great attention in many applications  such as multi-domain image translation. However  addressing this problem has two critical challenges: (i) Measuring the multi-marginal distance among different domains is very intractable; (ii) It is very difficult to exploit cross-domain correlations to match the target domain distributions. In this paper  we propose a novel Multi-marginal Wasserstein GAN (MWGAN) to minimize Wasserstein distance among domains. Specifically  with the help of multi-marginal optimal transport theory  we develop a new adversarial objective function with inner- and inter-domain constraints to exploit cross-domain correlations. Moreover  we theoretically analyze the generalization performance of MWGAN  and empirically evaluate it on the balanced and imbalanced translation tasks. Extensive experiments on toy and real-world datasets demonstrate the effectiveness of MWGAN.,Multi-marginal Wasserstein GAN

Jiezhang Cao∗  Langyuan Mo∗  Yifan Zhang  Kui Jia  Chunhua Shen  Mingkui Tan∗†
South China University of Technology  Peng Cheng Laboratory  The University of Adelaide

{secaojiezhang  selymo  sezyifan}@mail.scut.edu.cn

{mingkuitan  kuijia}@scut.edu.cn  chunhua.shen@adelaide.edu.au

Abstract

Multiple marginal matching problem aims at learning mappings to match a source
domain to multiple target domains and it has attracted great attention in many
applications  such as multi-domain image translation. However  addressing this
problem has two critical challenges: (i) Measuring the multi-marginal distance
among different domains is very intractable; (ii) It is very difﬁcult to exploit
cross-domain correlations to match the target domain distributions. In this paper 
we propose a novel Multi-marginal Wasserstein GAN (MWGAN) to minimize
Wasserstein distance among domains. Speciﬁcally  with the help of multi-marginal
optimal transport theory  we develop a new adversarial objective function with inner-
and inter-domain constraints to exploit cross-domain correlations. Moreover  we
theoretically analyze the generalization performance of MWGAN  and empirically
evaluate it on the balanced and imbalanced translation tasks. Extensive experiments
on toy and real-world datasets demonstrate the effectiveness of MWGAN.

1

Introduction

Multiple marginal matching (M3) problem aims to map an input image (source domain) to multiple
target domains (see Figure 1(a))  and it has been applied in computer vision  e.g.  multi-domain image
translation [10  23  25]. In practice  the unsupervised image translation [30] gains particular interest
because of its label-free property. However  due to the lack of corresponding images  this task is
extremely hard to learn stable mappings to match a source distribution to multiple target distributions.
Recently  some methods [10  30] address M3 problem  which  however  face two main challenges.
First  existing methods often neglect to jointly optimize the multi-marginal distance among domains 
which cannot guarantee the generalization performance of methods and may lead to distribution
mismatching issue. Recently  CycleGAN [51] and UNIT [32] repeatedly optimize every pair of two
different domains separately (see Figure 1(b)). In this sense  they are computationally expensive and
may have poor generalization performance. Moreover  UFDN [30] and StarGAN [10] essentially
measure the distance between an input distribution and a mixture of all target distributions (see Figure
1(b)). As a result  they may suffer from distribution mismatching issue. Therefore  it is necessary to
explore a new method to measure and optimize the multi-marginal distance.
Second  it is very challenging to exploit the cross-domain correlations to match target domains.
Existing methods [51  30] only focus on the correlations between the source and target domains  since
they measure the distance between two distributions (see Figure 1(b)). However  these methods often
ignore the correlations among target domains  and thus they are hard to fully capture information to
improve the performance. Moreover  when the source and target domains are signiﬁcantly different 
or the number of target domains is large  the translation task turns to be difﬁcult for existing methods
to exploit the cross-domain correlations.

∗Authors contributed equally.
†Corresponding author.

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

(a) The Edge→CelebA image translation task.

(b) Comparisons of different distribution measures.
Figure 1: An example of M3 problem and comparisons of existing methods. (a) For the Edge→CelebA
task  we aim to learn mappings to match a source distribution (i.e.  Edge images) to the target
distributions (i.e.  black and blond hair images). (b) Left: we employ CycleGAN multiple times to
measure the distance between every generated distribution and its corresponding target distribution.
Middle: StarGAN and UFDN measure the distance between Ps and a mixed distribution of Pθ1 and
Pθ2; Right: MWGAN jointly measures Wasserstein distance among Ps  Pθ1 and Pθ2. (Dotted circle:
the generated distributions  solid circle: the real source or target distributions  double-headed arrow:
distribution divergence  different colors represent different domains.)

In this paper  we seek to use multi-marginal Wasserstein distance to solve M3 problem  but directly
optimizing it is intractable. Therefore  we develop a new dual formulation to make it tractable and
propose a novel multi-marginal Wasserstein GAN (MWGAN) by enforcing inner- and inter-domain
constraints to exploit the correlations among domains.
The contributions of this paper are summarized as follows:
• We propose a novel GAN method (called MWGAN) to optimize a feasible multi-marginal distance
among different domains. MWGAN overcomes the limitations of existing methods by alleviating
the distribution mismatching issue and exploiting cross-domain correlations.
• We deﬁne and analyze the generalization of our proposed method for the multiple domain transla-
tion task  which is more important than existing generalization analyses [13  36] studying only on
two domains and non-trivial for multiple domains.
• We empirically show that MWGAN is able to solve the imbalanced image translation task well
when the source and target domains are signiﬁcantly different. Extensive experiments on toy and
real-world datasets demonstrate the effectiveness of our proposed method.

2 Related Work

Generative adversarial networks (GANs). Deep neural networks have theoretical and experimental
explorations [7  21  48  49  53]. In particular  GANs [17] have been successfully applied in computer
vision tasks  such as image generation [3  6  18  20]  image translation [2  10  19] and video prediction
[35]. Speciﬁcally  a generator tries to produce realistic samples  while a discriminator tries to
distinguish between generated data and real data. Recently  some studies try to improve the quality
[5  9  26] and diversity [43] of generated images  and improve the mechanism of GANs [1  11  38  39]
to deal with the unstable training and mode collapse problems.
Multi-domain image translation. M3 problem can be applied in domain adaptation [45] and image
translation [27  52]. CycleGAN [51]  DiscoGAN [28]  DualGAN [47] and UNIT [32] are proposed
to address two-domain image translation task. However  in Figure 1(b)  these methods measure
the distance between every pair of distributions multiple times  which is computationally expensive
when applied to the multi-domain image translation task. Recently  StarGAN [10] and AttGAN [23]
use a single model to perform multi-domain image translation. UFDN [30] translates images by
learning domain-invariant representation for cross-domains. Essentially  the above three methods
are two-domain image translation methods because they measure the distance between an input
distribution and a uniform mixture of other target distributions (see Figure 1(b)). Therefore  these
methods may suffer from distribution mismatching issue and obtain misleading feedback for updating
models when the source and target domains are signiﬁcantly different. In addition  we discuss the
difference between some GAN methods in Section I in supplementary materials.

2

target distributiontarget distribution generated distributiongenerated distribution1t2tsource distributions1θ2θmatchmatchCycleGANStarGANand UFDNMWGANss1θ1θ2θ2θ1θ1t2θ2t3 Problem Deﬁnition
Notation. We use calligraphic letters (e.g.  X ) to denote space  capital letters (e.g.  X) to denote
random variables  and bold lower case letter (e.g.  x) to denote the corresponding values. Let
D=(X   P) be the domain  P or µ be the marginal distribution over X and P(X ) be the set of all the
probability measures over X . For convenience  let X =Rd  and let I={0  ...  N} and [N ]={1  ...  N}.
Multiple marginal matching (M3) problem. In this paper  M3 problem aims to learn mappings to
match a source domain to multiple target domains. For simplicity  we consider one source domain
Ds={X   Ps} and N target domains Di={X   Pti}  i∈[N ]  where Ps is the source distribution  and
Pti is the i-th real target distribution. Let gi  i∈[N ] be the generative models parameterized by θi 
and Pθi be the generated distribution in the i-th target domain. In this problem  the goal is to learn
multiple generative models such that each generated distribution Pθi in the i-th target domain can be
close to the corresponding real target distribution Pti (see Figure 1(a)).
Optimal transport (OT) theory. Recently  OT [42] theory has attracted great attention in many
applications [3  46]. Directly solving the primal formulation of OT [40] might be intractable [16].
To address this  we consider the dual formulation of the multi-marginal OT problem as follows.
Problem I (Dual problem [40]) Given N +1 marginals µi∈P(X )  potential functions fi  i∈I  and
a cost function c(X (0)  . . .   X (N )) : Rd(N +1)→R  the dual Kantorovich problem can be deﬁned as:
. (1)
W (µ0  ...  µN )= sup
fi
j }j∈J0 and
In practice  we optimize the discrete case of Problem I. Speciﬁcally  given samples {x(0)
j }j∈Ji drawn from source domain distribution Ps and generated target distributions Pθi   i∈[N ] 
{x(i)
respectively  where Ji is an index set and ni=|Ji| is the number of samples  we have:
Problem II (Discrete dual problem) Let F ={f0  . . .   fN} be the set of Kantorovich potentials 
then the discrete dual problem ˆh(F ) can be deﬁned as:

X (0)  ...  X (N )(cid:17)

(cid:16)
X (i)(cid:17)≤c

X (i)(cid:17)

X (i)(cid:17)

(cid:88)

(cid:88)

(cid:16)

(cid:16)

(cid:16)

(cid:90)

  s.t.

dµi

fi

fi

i

i

ˆh(F )=

max

F

fi

j∈Ji

x(i)
j

  s.t.

fi

i

x(i)
ki

x(0)
k0

  . . .   x(N )
kN

 ∀ki∈[ni].

(2)

(cid:88)

(cid:88)

1
ni

i

(cid:16)

(cid:17)

(cid:88)

(cid:16)

(cid:16)

(cid:17)≤c

(cid:17)

Unfortunately  it is challenging to optimize Problem II due to the intractable inequality constraints
and multiple potential functions. To address this  we seek to propose a new optimization method.

4 Multi-marginal Wasserstein GAN

4.1 A New Dual Formulation
For two domains  WGAN [3] solves Problem II by setting f0=f and f1=−f. However  it is hard to
extend WGAN to multiple domains. To address this  we propose a new dual formulation in order
to optimize Problem II. To this end  we use a shared potential in Problem II  which is supported
by empirical and theoretical evidence. In the multi-domain image translation task  the domains
are often correlated  and thus share similar properties and differ only in details (see Figure 1(a)).
The cross-domain correlations can be exploited by the shared potential function (see Section J in
supplementary materials). More importantly  the optimal objectives of Problem II and the following
problem can be equal under some conditions (see Section B in supplementary materials).
Problem III Let Fλ={λ0f  . . .   λN f} be Kantorovich potentials  then we deﬁne dual problem as:
 ∀ki∈[ni]. (3)
max
Fλ

(cid:17)≤c

  . . .   x(N )
kN

(cid:88)

(cid:88)

(cid:88)

ˆh(Fλ)=

x(0)
k0

x(i)
ki

x(i)
j

(cid:16)

(cid:17)

(cid:16)

(cid:16)

(cid:17)

j∈Ji

λif

i

  s.t.

f

λi
ni

i

To further build the relationship between Problem II and Problem III  we have the following theorem
so that Problem III can be optimized well by GAN-based methods (see Subsection 4.2).
Theorem 1 Suppose the domains are connected  the cost function c is continuously differentiable
and each µi is absolutely continuous. If (f0  . . .   fN ) and (λ0f  . . .   λN f ) are solutions to Problem

I  then there exist some constants εi for each i ∈ I such that(cid:80)
have an equivalent Wasserstein distance  i.e. (cid:80)

Remark 1 From Theorem 1  if we train a shared function f to obtain a solution of Problem I  we
i λif regardless of whatever the value εi is.

i εi = 0 and fi = λif + εi.

i fi=(cid:80)

Therefore  we are able to optimize Problem III instead of intractable Problem II in practice.

3

number of iterations of the discriminator per generator iteration ncritic; Uniform distribution U [0  1].

j=1 in the i-th target domain; batch size mbs; the

j }ni

j=1 in the initial domain  {ˆx(i)

Algorithm 1 Multi-marginal WGAN.
Input: Training data {xj}n0
Output: The discriminator f  the generators {gi}i∈[N ] and the classiﬁer φ
1: while not converged do
2:
3:
4:
5:
6:
7:
8: end while

for t = 0  . . .   ncritic do
Sample x∼ˆPs and ˆx∼ˆPθi  ∀i  and ˜x ← ρx + (1 − ρ)ˆx  where ρ∼U [0  1]
Update f by ascending the gradient: ∇w[Ex∼ˆPs
i Eˆx∼ˆPθi
Update classiﬁer φ by descending the gradient ∇v[Cα(φ)]
end for
Update each generator gi by descending the gradient: ∇θi [−λ+

[f (x)]−(cid:80)

i Eˆx∼ˆPθi

i λ+

[f (ˆx)]−Rτ (f )]

[f (ˆx)] − Mα(gi)]

4.2 Proposed Objective Function

(cid:17)

x∼ˆPs

i

ˆx∼ˆPθi

i   λ+

i E
λ+

i∈[N ] λ+

= maxf E

[f (ˆx)]   s.t. ˆPθi∈Di  f∈Ω.

[f (x)]−(cid:88)

i >0  i∈[N ]  then Problem III can be rewritten as follows:

i f (ˆx(i))≤c(x  ˆx(1)  . . .   ˆx(N ))  f∈F} with x∈ˆPs and ˆx(i)∈ˆPθi  i∈[N ].

To minimize Wasserstein distance among domains  we now present a novel multi-marginal
Wasserstein GAN (MWGAN) based on the proposed dual formulation in (3). Speciﬁcally  let
F={f : Rd→R} be the class of discriminators parameterized by w  and G={g: Rd→Rd} be the class
of generators and gi∈G is parameterized by θi. Motivated by the adversarial mechanism of WGAN 
let λ0=1 and λi:=−λ+
Problem IV (Multi-marginal Wasserstein GAN) Given a discriminator f∈F and generators
gi∈G  i∈[N ]  we can deﬁne the following multi-marginal Wasserstein distance as
(4)
W
where ˆPs is the real source distribution  and the distribution ˆPθi is generated by gi in the i-th domain 

(cid:16)ˆPs  ˆPθ1  . . .   ˆPθN
Ω={f|f (x) −(cid:80)
In Problem IV  we refer to ˆPθi∈Di  i∈[N ] as inner-domain constraints and f∈Ω as inter-domain
constraints (See Subsections 4.3 and 4.4). The inﬂuence of these constraints are investigated in
Section N of supplementary materials. Note that λ+
i reﬂects the importance of the i-th target domain.
i =1/N  i∈[N ] when no prior knowledge is available on the target domains. To
In practice  we set λ+
minimize Problem IV  we optimize the generators with the following update rule.
Theorem 2 If each generator gi∈G  i∈[N ] is locally Lipschitz (see more details of Assumption 1 [3]) 
then there exists a discriminator f to Problem IV  we have the gradient ∇θiW (ˆPs  ˆPθ1  . . .   ˆPθN ) =
−λ+
Theorem 2 provides a good update rule for optimizing MWGAN. Speciﬁcally  we ﬁrst train an
[∇θif (gi(x))].
optimal discriminator f and then update each generator along the direction of E
The detailed algorithm is shown in Algorithm 1. Speciﬁcally  the generators cooperatively exploit
multi-domain correlations (see Section J in supplementary materials) and generate samples in the
speciﬁc target domain to fool the discriminator; the discriminator enforces generated data in target
domains to maintain the similar features from the source domain.

[∇θif (gi(x))] for all θi  i∈[N ] when all terms are well-deﬁned.

E
x∼ˆPs

x∼ˆPs

i

Inner-domain Constraints

4.3
In Problem IV  the distribution Pθi generated by the generator gi should belong to the i-th domain for
any i. To this end  we introduce an auxiliary domain classiﬁcation loss and the mutual information.
Domain classiﬁcation loss. Given an input x:=x(0) and generator gi  we aim to translate the input
x to an output ˆx(i) which can be classiﬁed to the target domain Di correctly. To achieve this goal  we
introduce an auxiliary classiﬁer φ: X→Y parameterized by v to optimize the generators. Speciﬁcally 
we label real data x∼ˆPti as 1  where ˆPti is an empirical distribution in the i-th target domain  and we
label generated data ˆx(i)∼ˆPθi as 0. Then  the domain classiﬁcation loss w.r.t. φ can be deﬁned as:
(5)
where α is a hyper-parameter  y is corresponding to x(cid:48)  and (cid:96)(· ·) is a binary classiﬁcation loss  such
as hinge loss [50]  mean square loss [34]  cross-entropy loss [17] and Wasserstein loss [12].

Cα(φ) = α · E

[(cid:96) (φ (x(cid:48))   y)]  

x(cid:48)∼ˆPti∪ˆPθi

4

Mutual information maximization. After learning the classiﬁer φ  we maximize the lower bound
of the mutual information [8  23] between the generated image and the corresponding domain  i.e. 
(6)
By maximizing the mutual information in (6)  we correlate the generated image gi(x) with the i-th
domain  and then we are able to translate the source image to the speciﬁed domain.

Mα(gi) = α · E

y(i)=1

x∼ˆPs

(cid:12)(cid:12)(cid:12) gi(x)
(cid:17)(cid:105)

(cid:16)

log φ

(cid:104)

.

Inter-domain Constraints

4.4
Then  we enforce the inter-domain constraints in Problem IV  i.e.  the discriminator f∈F∩Ω. One
can let discriminator be 1-Lipschitz continuous  but it may ignore the dependency among domains
(see Section H in supplementary materials). Thus  we relax the constraints by the following lemma.
Lemma 1 (Constraints relaxation) If the cost function c(·) is measured by (cid:96)2 norm  then there

exists Lf≥1 such that the constraints in Problem IV satisfy(cid:80)

i |f (x)−f (ˆx(i))|/(cid:107)x−ˆx(i)(cid:107)≤Lf .

Note that Lf measures the dependency among domains (see Section G in supplementary materials).
In practice  Lf can be calculated with the cost function  or treated as a tuning parameter for simplicity.
Inter-domain gradient penalty. In practice  directly enforcing the inequality constraints in Lemma
1 would have poor performance when generated samples are far from real data. We thus propose
the following inter-domain gradient penalty. Speciﬁcally  given real data x in the source domain and
generated samples ˆx(i)  if ˆx(i) can be properly close to x  as suggested in [37]  we can calculate its
gradient and introduce the following regularization term into the objective of MWGAN  i.e. 

E
˜x(i)∼ ˆQi

(7)
where (·)+= max{0 ·}  τ is a hyper-parameter  ˜x(i) is sampled between x and ˆx(i)  and ˆQi  i∈[N ]
is a constructed distribution relying on some sampling strategy. In practice  one can construct a
distribution where samples ˜x(i) can be interpolated between real data x and generated data ˆx(i) for
every domain [18]. Note that the gradient penalty captures the dependency of domains since the cost
function in Problem IV measures the distance among all domains jointly.

+

 

i

Rτ (f ) = τ ·(cid:16)(cid:88)

(cid:13)(cid:13)(cid:13)∇f

(cid:16)

˜x(i)(cid:17)(cid:13)(cid:13)(cid:13)−Lf

(cid:17)2

5 Theoretical Analysis

In this section  we provide the generalization analysis for the proposed method. Motivated by [4]  we
give a new deﬁnition of generalization for multiple distributions as follows.
Deﬁnition 1 (Generalization) Let Ps and Pθi be the continuous real and generated distributions 
and ˆPs and ˆPθi be the empirical real and generated distributions. The distribution distance
W (·  . . .  ·) is said to generalize with n training samples and error   if for every true generated
distribution Pθi  the following inequality holds with high probability 

(cid:16)ˆPs  ˆPθ1  . . .   ˆPθN

(cid:12)(cid:12)(cid:12) ≤ .
(cid:17) − W (Ps  Pθ1   . . .   PθN )

(cid:12)(cid:12)(cid:12)W

(8)

In Deﬁnition 1  the generalization bound measures the difference between the expected distance and
the empirical distance. In practice  our goal is to train MWGAN to obtain a small empirical distance 
so that the expected distance would also be small.
With the help of Deﬁnition 1  we are able to analyze the generalization ability of the proposed method.
Let κ be the capacity of the discriminator  and if the discriminator is L-Lipschitz continuous and
bounded in [−∆  ∆]  then we have the following generalization bound.
Theorem 3 (Generalization bound) Given the continuous real and generated distributions Ps
and Pθi  i∈I  and the empirical versions ˆPs and ˆPθi   i∈I with at least n samples in each domain 
there is a universal constant C such that n≥Cκ∆2 log(Lκ/)/2 with the error   the following
generalization bound is satisﬁed with probability at least 1−e−κ 

(cid:16)ˆPs  ˆPθ1  . . .   ˆPθN

(cid:12)(cid:12)(cid:12) ≤ .
(cid:17) − W (Ps  Pθ1   . . .   PθN )

(cid:12)(cid:12)(cid:12)W

(9)

Theorem 3 shows that MWGAN has a good generalization ability with enough training data
in each domain. In practice  if successfully minimizing the multi-domain Wasserstein distance
i.e.  W (ˆPs  ˆPθ1  . . .   ˆPθN )  the expected distance W (Ps  Pθ1   . . .   PθN ) can also be small.

5

Figure 2: Comparisons of distribution matching abilities on the value surface of discriminator. Each
method learns from a Gaussian distribution to other six Gaussian (upper line) or Uniform distributions
(lower line). (Green: source distribution; Red: target distributions; Orange: generated distributions. )

6 Experiments

Implementation details. All experiments are conducted based on PyTorch  with an NVIDIA TITAN
X GPU.3 We use Adam [29] with β1=0.5 and β2=0.999 and set the learning rate as 0.0001. We
train the model 100k iterations with batch size 16. We set α=10  τ =10 and Lf to be the number
of target domains in Loss (7). The details of the loss function and the network architectures of the
discriminator  generators and classiﬁer can be referred to Section P in supplementary materials.
Baselines. We adopt the following methods as baselines: (i) CycleGAN [51] is a two-domain image
translation method which can be ﬂexibly extended to perform the multi-domain image translation
task. (ii) UFDN [30] and (iii) StarGAN [10] are multi-domain image translation methods.
Datasets. We conduct experiments on three datasets. Note that all images are resized as 128×128.
(i) Toy dataset. We generate a Gaussian distribution in the source domain  and other six Gaussian or
Uniform distributions in the target domains. More details can be found in the supplemental materials.
(ii) CelebA [33] contains 202 599 face images  where each image has 40 binary attributes. We use the
following attributes: hair color (black  blond and brown)  eyeglasses  mustache and pale skin. In the
ﬁrst experiment  we use black hair images as the source domain  and use the blond hair  eyeglasses 
mustache and pale skin images as target domains. In the second experiment  we extract 50k Canny
edges from CelebA. We take edge images as the source domain and hair images as target domains.
(iii) Style painting [51]. The size of Real scene  Monet  Van Gogh and Ukiyo-e is 6287  1073  400
and 563  respectively. We take real scene images as the source domain  and others as target domains.
Evaluation Metrics. We use the following evaluation metrics: (i) Fréchet Inception Distance
(FID) [24] evaluates the quality of the translated images. In general  a lower FID score means better
performance. (ii) Classiﬁcation accuracy widely used in [10  23] evaluates the probability that
the generated images belong to corresponding target domains. Speciﬁcally  we train a classiﬁer on
CelebA (90% for training and 10% for testing) using ResNet-18 [22]  resulting in a near-perfect
accuracy  then use the classiﬁer to measure the classiﬁcation accuracy of the generated images.

6.1 Results on Toy Dataset

We compare MWGAN with UFDN and StarGAN on toy dataset to verify the limitations mentioned
in Section 2. Speciﬁcally  we measure the distribution matching ability and plot the value surface of
the discriminator. Here  the value surface depicts the outputs of the discriminator [18  31].
In Figure 2  MWGAN matches the target domain distributions very well as it is able to capture
the geometric information of real distribution using a low-capacity network. Moreover  the value
surface shows that the discriminator provides correct gradients to update the generators. However 
the baseline methods are very sensitive to the type of source and target domain distributions. With
the same capacity  the baseline methods on similar distributions (top row) are able to match the target
domain distributions. However  they cannot match the target domain distribution well when the initial
and the target domain distributions are different (see bottom row of Figure 2).

3The source code of our method is available: https://github.com/caojiezhang/MWGAN.

6

(a) Real distribution(b) UFDN(c) StarGAN(d) MWGANFigure 3: Comparisons of attribute translation on CelebA. The ﬁrst column shows the input images 
the next four columns show the single attribute translation results  and the last four columns show the
multi-attribute translation results. (B: Blond hair; E: Eyeglasses; M: Mustache; P: Pale skin.)

Table 1: Comparisons of FID and classiﬁcation accuracy (%) on single facial attribute translation.

Method

FID
CycleGAN 20.45
65.06
23.47
19.63

UFDN
StarGAN
MWGAN

Hair
Accuracy (%)

95.07
92.01
96.00
97.65

FID
23.69
69.30
25.36
22.94

Eyeglasses

Accuracy (%)

96.94
79.34
99.51
99.53

FID
24.94
76.04
23.75
23.69

Mustache

Accuracy (%)

93.89
97.18
99.06
98.35

FID
18.09
53.11
18.12
15.91

Pale skin

Accuracy (%)

80.75
83.33
92.48
93.66

Table 2: Comparisons of classiﬁcation accuracy
(%) on multi-attribute synthesis. (B: Blond hair 
E: Eyeglasses  M: Mustache  P: Pale skin.)

Table 3: Comparisons of the FID value for each
facial attribute (different colors of hair) on the
Edge→CelebA translation task.

Method

B+E
CycleGAN 66.43
72.53
66.66
75.82

UFDN
StarGAN
MWGAN

B+M B+M+E B+M+E+P
33.33
51.40
62.20
69.01

2.11
8.54
6.10
19.95

11.03
23.00
45.77
53.75

Method

CycleGAN

UFDN
StarGAN
MWGAN

Black hair Blond hair Brown hair

65.79
88.40
57.51
35.24

65.10
131.65
53.41
33.81

81.59
144.78
81.00
51.87

6.2 Results on CelebA

We compare MWGAN with several baselines on both balanced and imbalanced translation tasks.
(i) Balanced image translation task. In this experiment  we train the generators to produce single
attribute images  and then synthesize multi-attribute images using the composite generators. We
generate attributes in order of {Blond hair  Eyeglasses  Mustache  Pale skin}. Taking two attributes as
an example  let g1 and g2 be the generators of Blond hair and Eyeglasses images  respectively  then
images with Blond hair and Eyeglasses attributes are generated by the composite generators g2◦g1.
Qualitative results. In Figure 3  MWGAN has a better or comparable performance than baselines
on the single attribute translation task  but achieves the highest visual quality of multi-attributes
translation results.
In other words  MWGAN has good generalization performance. However 
CycleGAN is hard to synthesize multi-attributes. UFDN cannot guarantee the identity of the translated
images and produces images with blurring structures. Moreover  StarGAN highly depends on the
number of transferred domains and the synthesized images sometimes lack the perceptual realism.
Quantitative results. We further compare FID and classiﬁcation accuracy for the single-attribute
results. For the multi-attribute results  we only report classiﬁcation accuracy because FID is no longer
a valid measure and may give misleading results when training data are not sufﬁcient [24]. In Table 1 
MWGAN achieves the lowest FID and comparable classiﬁcation accuracy  indicating that it produces
realistic single-attribute images of the highest quality. In Table 2  MWGAN achieves the highest
classiﬁcation accuracy and thus synthesizes the most realistic multi-attribute images.

7

MWGANStarGANCycleGANUFDNBlond hairEyeglassesInputMustachePale skinB+EB+MB+M+EB+M+E+PFigure 4: Comparisons of the edge→CelebA
translation results. The ﬁrst column shows the
input images  and the next three columns show
the single attribute translation results.

Figure 5: Comparisons of style transfer results.
The ﬁrst column shows the real world images 
and the last three columns show translation re-
sults  i.e.  Monet  Van Gogh and Ukiyo-e.

(ii) Imbalanced image translation task. In this experiment  we compare MWGAN with baselines
on the Edge→CelebA translation task. Note that this task is unbalanced because the information of
edge images is much less than facial attribute images.
Qualitative results. In Figure 4  MWGAN is able to generate the most natural-looking facial images
with the corresponding attributes from edge images. In contrast  UFDN fails to preserve the facial
texture of an edge image  and generates images with very blurry and distorted structure. In addition 
CycleGAN and StarGAN mostly preserve the domain information but cannot maintain the sharpness
of images and the facial structure information. Moreover  this experiment also shows the superiority
of our method on the imbalanced image translation task.
Quantitative results. In Table 3  MWGAN achieves the lowest FID  showing that it is able to
produce the most realistic facial attributes from the edge images. In contrast  the FID values of
baselines are large because these methods are hard to generate sharp and realistic images. We also
perform a perceptual evaluation with AMT for this task (see Section M in supplementary materials).

6.3 Results on Painting Translation

In this experiment  we ﬁnally train our model on the painting dataset to conduct the style transfer task
[41  44]. As suggested in [14  15  51]  we only show the qualitative results. Note that this translation
task is also imbalanced because the input and target distributions are signiﬁcantly different.
In Figure 5  MWGAN generates painting images with higher visual quality. In contrast  UFDN fails to
generate clearly structural painting images because it is hard to learn domain-invariant representation
when domains are highly imbalanced. CycleGAN cannot fully learn some useful information from
painting images to scene images. When taking a painting image as an input  StarGAN may obtain
misleading information to update the generator. In this sense  when all domains are signiﬁcantly
different  StarGAN may not learn a good single generator to synthesize images of multiple domains.

7 Conclusion

In this paper  we have proposed a novel multi-marginal Wasserstein GAN (MWGAN) for multiple
marginal matching problem. Speciﬁcally  with the help of multi-marginal optimal transport theory 
we develop a new dual formulation for better adversarial learning on the unsupervised multi-domain
image translation task. Moreover  we theoretically deﬁne and further analyze the generalization ability
of the proposed method. Extensive experiments on both toy and real-world datasets demonstrate the
effectiveness of the proposed method.

8

MWGANStarGANCycleGANUFDNBlack hairBlond hairInputBrown hairMWGANStarGANCycleGANUFDNMonetVan GoghInputCezanneUkiyo-eAcknowledgements

This work is partially funded by Guangdong Provincial Scientiﬁc and Technological Funds un-
der Grants 2018B010107001  National Natural Science Foundation of China (NSFC) 61602185 
key project of NSFC (No. 61836003)  Fundamental Research Funds for the Central Univer-
sities D2191240  Program for Guangdong Introducing Innovative and Enterpreneurial Teams
2017ZT07X183  and Tencent AI Lab Rhino-Bird Focused Research Program (No. JR201902).
This work is also partially funded by Microsoft Research Asia (MSRA Collaborative Research
Program 2019).

References
[1] J. Adler and S. Lunz. Banach wasserstein gan. In Advances in Neural Information Processing

Systems  pages 6754–6763  2018.

[2] A. Almahairi  S. Rajeshwar  A. Sordoni  P. Bachman  and A. Courville. Augmented cyclegan:
Learning many-to-many mappings from unpaired data. In International Conference on Machine
Learning  volume 80  pages 195–204  2018.

[3] M. Arjovsky  S. Chintala  and L. Bottou. Wasserstein generative adversarial networks. In

International Conference on Machine Learning  pages 214–223  2017.

[4] S. Arora  R. Ge  Y. Liang  T. Ma  and Y. Zhang. Generalization and equilibrium in generative
adversarial nets (GANs). In International Conference on Machine Learning  volume 70  pages
224–232  2017.

[5] A. Brock  J. Donahue  and K. Simonyan. Large scale GAN training for high ﬁdelity natural

image synthesis. In International Conference on Learning Representations  2019.

[6] J. Cao  Y. Guo  Q. Wu  C. Shen  J. Huang  and M. Tan. Adversarial learning with local coordinate
coding. In International Conference on Machine Learning  volume 80  pages 707–715  2018.

[7] J. Cao  Q. Wu  Y. Yan  L. Wang  and M. Tan. On the ﬂatness of loss surface for two-layered

relu networks. In Asian Conference on Machine Learning  pages 545–560  2017.

[8] X. Chen  Y. Duan  R. Houthooft  J. Schulman  I. Sutskever  and P. Abbeel. Infogan: Interpretable
representation learning by information maximizing generative adversarial nets. In Advances in
Neural Information Processing Systems  2016.

[9] X. Chen  C. Xu  X. Yang  and D. Tao. Attention-gan for object transﬁguration in wild images.

In The European Conference on Computer Vision  pages 164–180  2018.

[10] Y. Choi  M. Choi  M. Kim  J.-W. Ha  S. Kim  and J. Choo. Stargan: Uniﬁed generative
adversarial networks for multi-domain image-to-image translation. In The IEEE Conference on
Computer Vision and Pattern Recognition  June 2018.

[11] F. Farnia and D. Tse. A convex duality framework for gans. In Advances in Neural Information

Processing Systems  pages 5248–5258  2018.

[12] C. Frogner  C. Zhang  H. Mobahi  M. Araya  and T. A. Poggio. Learning with a wasserstein

loss. In Advances in Neural Information Processing Systems  2015.

[13] T. Galanti  S. Benaim  and L. Wolf. Generalization bounds for unsupervised cross-domain

mapping with wgans. arXiv preprint arXiv:1807.08501  2018.

[14] L. A. Gatys  A. S. Ecker  and M. Bethge. Image style transfer using convolutional neural
In The IEEE Conference on Computer Vision and Pattern Recognition  pages

networks.
2414–2423  2016.

[15] L. A. Gatys  A. S. Ecker  M. Bethge  A. Hertzmann  and E. Shechtman. Controlling perceptual
factors in neural style transfer. In The IEEE Conference on Computer Vision and Pattern
Recognition  2017.

9

[16] A. Genevay  G. Peyre  and M. Cuturi. Learning generative models with sinkhorn divergences.

In Artiﬁcial Intelligence and Statistics  volume 84  pages 1608–1617  2018.

[17] I. Goodfellow  J. Pouget-Abadie  M. Mirza  B. Xu  D. Warde-Farley  S. Ozair  A. Courville  and
Y. Bengio. Generative adversarial nets. In Advances in Neural Information Processing Systems 
pages 2672–2680  2014.

[18] I. Gulrajani  F. Ahmed  M. Arjovsky  V. Dumoulin  and A. C. Courville. Improved training of
wasserstein gans. In Advances in Neural Information Processing Systems  pages 5767–5777 
2017.

[19] Y. Guo  Q. Chen  J. Chen  J. Huang  Y. Xu  J. Cao  P. Zhao  and M. Tan. Dual reconstruction
nets for image super-resolution with gradient sensitive loss. arXiv preprint arXiv:1809.07099 
2018.

[20] Y. Guo  Q. Chen  J. Chen  Q. Wu  Q. Shi  and M. Tan. Auto-embedding generative adversarial

networks for high resolution image synthesis. IEEE Transactions on Multimedia  2019.

[21] Y. Guo  Y. Zheng  M. Tan  Q. Chen  J. Chen  P. Zhao  and J. Huang. Nat: Neural architec-
ture transformer for accurate and compact architectures. In Advances in Neural Information
Processing Systems  2019.

[22] K. He  X. Zhang  S. Ren  and J. Sun. Deep residual learning for image recognition. In The

IEEE Conference on Computer Vision and Pattern Recognition  2016.

[23] Z. He  W. Zuo  M. Kan  S. Shan  and X. Chen. Arbitrary facial attribute editing: Only change

what you want. arXiv preprint arXiv:1711.10678  2017.

[24] M. Heusel  H. Ramsauer  T. Unterthiner  B. Nessler  and S. Hochreiter. Gans trained by a two
time-scale update rule converge to a local nash equilibrium. In Advances in Neural Information
Processing Systems  pages 6626–6637  2017.

[25] L. Hui  X. Li  J. Chen  H. He  and J. Yang. Unsupervised multi-domain image translation with
domain-speciﬁc encoders/decoders. In International Conference on Pattern Recognition  pages
2044–2049  2018.

[26] T. Karras  T. Aila  S. Laine  and J. Lehtinen. Progressive growing of GANs for improved quality 

stability  and variation. In International Conference on Learning Representations  2018.

[27] H. Kazemi  S. Soleymani  F. Taherkhani  S. Iranmanesh  and N. Nasrabadi. Unsupervised
image-to-image translation using domain-speciﬁc variational information bound. In Advances
in Neural Information Processing Systems  pages 10348–10358  2018.

[28] T. Kim  M. Cha  H. Kim  J. K. Lee  and J. Kim. Learning to discover cross-domain relations
with generative adversarial networks. In International Conference on Machine Learning  2017.

[29] D. P. Kingma and J. Ba. Adam: A method for stochastic optimization.

Conference on Learning Representations  2015.

In International

[30] A. H. Liu  Y.-C. Liu  Y.-Y. Yeh  and Y.-C. F. Wang. A uniﬁed feature disentangler for multi-
domain image translation and manipulation. In Advances in Neural Information Processing
Systems  pages 2595–2604  2018.

[31] H. Liu  G. Xianfeng  and D. Samaras. A two-step computation of the exact gan wasserstein

distance. In International Conference on Machine Learning  pages 3165–3174  2018.

[32] M.-Y. Liu  T. Breuel  and J. Kautz. Unsupervised image-to-image translation networks. In

Advances in Neural Information Processing Systems  2017.

[33] Z. Liu  P. Luo  X. Wang  and X. Tang. Deep learning face attributes in the wild. In The IEEE

International Conference on Computer Vision  pages 3730–3738  2015.

[34] X. Mao  Q. Li  H. Xie  R. Y. Lau  Z. Wang  and S. Paul Smolley. Least squares generative
In The IEEE International Conference on Computer Vision  pages

adversarial networks.
2794–2802  2017.

10

[35] M. Mathieu  C. Couprie  and Y. LeCun. Deep Multi-scale Video Prediction beyond Mean

Square Error. In International Conference on Learning Representations  2016.

[36] X. Pan  M. Zhang  and D. Ding. Theoretical analysis of image-to-image translation with

adversarial learning. In International Conference on Machine Learning  2018.

[37] H. Petzka  A. Fischer  and D. Lukovnikov. On the regularization of wasserstein gans. In

International Conference on Learning Representations  2018.

[38] K. Roth  A. Lucchi  S. Nowozin  and T. Hofmann. Stabilizing training of generative adversarial
networks through regularization. In Advances in Neural Information Processing Systems  pages
2018–2028  2017.

[39] M. Sanjabi  J. Ba  M. Razaviyayn  and J. D. Lee. On the convergence and robustness of training
gans with regularized optimal transport. In Advances in Neural Information Processing Systems 
pages 7091–7101  2018.

[40] F. Santambrogio. Optimal transport for applied mathematicians. Birkäuser  NY  pages 99–102 

2015.

[41] C. Song  Z. Wu  Y. Zhou  M. Gong  and H. Huang. Etnet: Error transition network for arbitrary
style transfer. In Advances in Neural Information Processing Systems  pages 668–677  2019.

[42] C. Villani. Optimal Transport: Old and New. Springer Science & Business Media  2008.

[43] C. Wang  C. Xu  X. Yao  and D. Tao. Evolutionary generative adversarial networks. IEEE

Transactions on Evolutionary Computation  2019.

[44] Z. Wu  C. Song  Y. Zhou  M. Gong  and H. Huang. Efanet: Exchangeable feature alignment

network for arbitrary style transfer. In AAAI Conference on Artiﬁcial Intelligence  2020.

[45] S. Xie  Z. Zheng  L. Chen  and C. Chen. Learning semantic representations for unsupervised
domain adaptation. In International Conference on Machine Learning  pages 5419–5428  2018.

[46] Y. Yan  M. Tan  Y. Xu  J. Cao  M. Ng  H. Min  and Q. Wu. Oversampling for imbalanced
data via optimal transport. In AAAI Conference on Artiﬁcial Intelligence  volume 33  pages
5605–5612  2019.

[47] Z. Yi  H. R. Zhang  P. Tan  and M. Gong. Dualgan: Unsupervised dual learning for image-to-
image translation. In The IEEE International Conference on Computer Vision  pages 2868–2876 
2017.

[48] R. Zeng  C. Gan  P. Chen  W. Huang  Q. Wu  and M. Tan. Breaking winner-takes-all: Iterative-
winners-out networks for weakly supervised temporal action localization. IEEE Transactions
on Image Processing  28(12):5797–5808  2019.

[49] R. Zeng  W. Huang  M. Tan  Y. Rong  P. Zhao  J. Huang  and C. Gan. Graph convolutional
networks for temporal action localization. In The IEEE International Conference on Computer
Vision  2019.

[50] Y. Zhang  P. Zhao  J. Cao  W. Ma  J. Huang  Q. Wu  and M. Tan. Online adaptive asymmetric
active learning for budgeted imbalanced data. In ACM SIGKDD International Conference on
Knowledge Discovery & Data Mining  pages 2768–2777  2018.

[51] J.-Y. Zhu  T. Park  P. Isola  and A. A. Efros. Unpaired image-to-image translation using cycle-
consistent adversarial networks. In The IEEE International Conference on Computer Vision 
2017.

[52] J.-Y. Zhu  R. Zhang  D. Pathak  T. Darrell  A. A. Efros  O. Wang  and E. Shechtman. Toward
multimodal image-to-image translation. In Advances in Neural Information Processing Systems 
pages 465–476  2017.

[53] Z. Zhuang  M. Tan  B. Zhuang  J. Liu  Y. Guo  Q. Wu  J. Huang  and J. Zhu. Discrimination-
aware channel pruning for deep neural networks. In Advances in Neural Information Processing
Systems  pages 875–886  2018.

11

,Alessandro Rudi
Guillermo Canas
Lorenzo Rosasco
Jiezhang Cao
Langyuan Mo
Yifan Zhang
Kui Jia
Chunhua Shen
Mingkui Tan