2018,Binary Classification from Positive-Confidence Data,Can we learn a binary classifier from only positive data  without any negative data or unlabeled data?  We show that if one can equip positive data with confidence (positive-confidence)  one can successfully learn a binary classifier  which we name positive-confidence (Pconf) classification.  Our work is related to one-class classification which is aimed at "describing" the positive class by clustering-related methods  but one-class classification does not have the ability to tune hyper-parameters and their aim is not on "discriminating" positive and negative classes.  For the Pconf classification problem  we provide a simple empirical risk minimization framework that is model-independent and optimization-independent.  We theoretically establish the consistency and an estimation error bound  and demonstrate the usefulness of the proposed method for training deep neural networks through experiments.,Binary Classiﬁcation from Positive-Conﬁdence Data

Takashi Ishida1 2 Gang Niu2 Masashi Sugiyama2 1

1 The University of Tokyo  Tokyo  Japan

{ishida@ms.  sugi@}k.u-tokyo.ac.jp  gang.niu@riken.jp

2 RIKEN  Tokyo  Japan

Abstract

Can we learn a binary classiﬁer from only positive data  without any negative data
or unlabeled data? We show that if one can equip positive data with conﬁdence
(positive-conﬁdence)  one can successfully learn a binary classiﬁer  which we name
positive-conﬁdence (Pconf) classiﬁcation. Our work is related to one-class classiﬁ-
cation which is aimed at “describing” the positive class by clustering-related meth-
ods  but one-class classiﬁcation does not have the ability to tune hyper-parameters
and their aim is not on “discriminating” positive and negative classes. For the Pconf
classiﬁcation problem  we provide a simple empirical risk minimization framework
that is model-independent and optimization-independent. We theoretically estab-
lish the consistency and an estimation error bound  and demonstrate the usefulness
of the proposed method for training deep neural networks through experiments.

1

Introduction

Machine learning with big labeled data has been highly successful in applications such as image
recognition  speech recognition  recommendation  and machine translation [14]. However  in many
other real-world problems including robotics  disaster resilience  medical diagnosis  and bioinfor-
matics  massive labeled data cannot be easily collected typically. For this reason  machine learning
from weak supervision has been actively explored recently  including semi-supervised classiﬁca-
tion [6  30  40  53  23  36]  one-class classiﬁcation [5  21  42  51  16  46]  positive-unlabeled (PU)
classiﬁcation [12  33  8  9  34  24  41]  label-proportion classiﬁcation [39  54]  unlabeled-unlabeled
classiﬁcation [7  29  26]  complementary-label classiﬁcation [18  55  19]  and similar-unlabeled
classiﬁcation [1].
In this paper  we consider a novel setting of classiﬁcation from weak supervision called positive-
conﬁdence (Pconf) classiﬁcation  which is aimed at training a binary classiﬁer only from positive data
equipped with conﬁdence  without negative data. Such a Pconf classiﬁcation scenario is conceivable
in various real-world problems. For example  in purchase prediction  we can easily collect customer
data from our own company (positive data)  but not from rival companies (negative data). Often times 
our customers are asked to answer questionnaires/surveys on how strong their buying intention was
over rival products. This may be transformed into a probability between 0 and 1 by pre-processing 
and then it can be used as positive-conﬁdence  which is all we need for Pconf classiﬁcation.
Another example is a common task for app developers  where they need to predict whether app users
will continue using the app or unsubscribe in the future. The critical issue is that depending on the
privacy/opt-out policy or data regulation  they need to fully discard the unsubscribed user’s data.
Hence  developers will not have access to users who quit using their services  but they can associate a
positive-conﬁdence score with each remaining user by  e.g.  how actively they use the app.
In these applications  as long as positive-conﬁdence data can be collected  Pconf classiﬁcation allows
us to obtain a classiﬁer that discriminates between positive and negative data.

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

Figure 1: Illustrations of the Pconf classiﬁcation and other related classiﬁcation settings. Best viewed
in color. Red points are positive data  blue points are negative data  and gray points are unlabeled data.
The dark/light red colors on the rightmost ﬁgure show high/low conﬁdence values for positive data.

Related works Pconf classiﬁcation is related to one-class classiﬁcation  which is aimed at “describ-
ing” the positive class typically from hard-labeled positive data without conﬁdence. To the best of our
knowledge  previous one-class methods are motivated geometrically [50  42]  by information theory
[49]  or by density estimation [4]. However  due to the descriptive nature of all previous methods 
there is no systematic way to tune hyper-parameters to “classify” positive and negative data. In the
conceptual example in Figure 1  one-class methods (see the second-left illustration) do not have any
knowledge of the negative distribution  such that the negative distribution is in the lower right of the
positive distribution (see the left-most illustration). Therefore  even if we have an inﬁnite number
of training data  one-class methods will still require regularization to have a tight boundary in all
directions  wherever the positive posterior becomes low. Note that even if we knew that the negative
distribution lies in the lower right of the positive distribution  it is still impossible to ﬁnd the decision
boundary  because we still need to know the degree of overlap between the two distributions and
the class prior. One-class methods are designed for and work well for anomaly detection  but have
critical limitations if the problem of interest is “classiﬁcation”.
On the other hand  Pconf classiﬁcation is aimed at constructing a discriminative classiﬁer and thus
hyper-parameters can be objectively chosen to discriminate between positive and negative data. We
want to emphasize that the key contribution of our paper is to propose a method that is purely based
on empirical risk minimization (ERM) [52]  which makes it suitable for binary classiﬁcation.
Pconf classiﬁcation is also related to positive-unlabeled (PU) classiﬁcation  which uses hard-labeled
positive data and additional unlabeled data for constructing a binary classiﬁer. A practical advantage
of our Pconf classiﬁcation method over typical PU classiﬁcation methods is that our method does
not involve estimation of the class-prior probability  which is required in standard PU classiﬁcation
methods [8  9  24]  but is known to be highly challenging in practice [44  2  11  29  10]. This is
enabled by the additional conﬁdence information which indirectly includes the information of the
class prior probability  bridging class conditionals and class posteriors.

Organization In this paper  we propose a simple ERM framework for Pconf classiﬁcation and
theoretically establish the consistency and an estimation error bound. We then provide an example
of implementation to Pconf classiﬁcation by using linear-in-parameter models (such as Gaussian
kernel models)  which can be implemented easily and can be computationally efﬁcient. Finally  we
experimentally demonstrate the practical usefulness of the proposed method for training linear-in-
parameter models and deep neural networks.

2 Problem formulation

In this section  we formulate our Pconf classiﬁcation problem. Suppose that a pair of d-dimensional
pattern x 2 Rd and its class label y 2{ +1 1} follow an unknown probability distribution with
density p(x  y). Our goal is to train a binary classiﬁer g(x) : Rd ! R so that the classiﬁcation risk
R(g) is minimized:
(1)

R(g) = Ep(x y)[`(yg(x))] 

2

where Ep(x y) denotes the expectation over p(x  y)  and `(z) is a loss function. When margin z is
small  `(z) typically takes a large value. Since p(x  y) is unknown  the ordinary ERM approach [52]
replaces the expectation with the average over training data drawn independently from p(x  y).
However  in the Pconf classiﬁcation scenario  we are only given positive data equipped with conﬁdence
i=1  where xi is a positive pattern drawn independently from p(x|y = +1) and ri is
X := {(xi  ri)}n
the positive conﬁdence given by ri = p(y = +1|xi). Note that this equality does not have to strictly
hold as later shown in Section 4. Since we have no access to negative data in the Pconf classiﬁcation
scenario  we cannot directly employ the standard ERM approach. In the next section  we show how
the classiﬁcation risk can be estimated only from Pconf data.

3 Pconf classiﬁcation

In this section  we propose an ERM framework for Pconf classiﬁcation and derive an estimation error
bound for the proposed method. Finally we give examples of practical implementations.

R(g) = ⇡+E+`g(x) +

3.1 Empirical risk minimization (ERM) framework
Let ⇡+ = p(y = +1) and r(x) = p(y = +1|x)  and let E+ denote the expectation over p(x|y =
+1). Then the following theorem holds  which forms the basis of our approach:
Theorem 1. The classiﬁcation risk (1) can be expressed as
1  r(x)
r(x)
if we have p(y = +1|x) 6= 0 for all x sampled from p(x).
A proof is given in Appendix A.1 in the supplementary material. Equation (2) does not include the ex-
pectation over negative data  but only includes the expectation over positive data and their conﬁdence
values. Furthermore  when (2) is minimized with respect to g  unknown ⇡+ is a proportional constant
and thus can be safely ignored. Conceptually  the assumption of p(y = +1|x) 6= 0 is implying
that the support of the negative distribution is the same or is included in the support of the positive
distribution.
Based on this  we propose the following ERM framework for Pconf classiﬁcation:

`  g(x)  

(2)

min

g

1  ri
ri

`  g(xi)i.
nXi=1h`g(xi) +
nXi=1hri`g(xi) + (1  ri)`  g(xi)i.

(3)

(4)

It might be tempting to consider a similar empirical formulation as follows:

min

g

Equation (4) means that we weigh the positive loss with positive-conﬁdence ri and the negative
loss with negative-conﬁdence 1  ri. This is quite natural and may look straightforward at a glance.
However  if we simply consider the population version of the objective function of (4)  we have

E+hr(x)`g(x) +1  r(x)`  g(x)i
= E+hp(y = +1|x)`g(x) + p(y = 1|x)`  g(x)i
= E+h Xy2{±1}
p(y|x)`yg(x)i = E+hEp(y|x)⇥`yg(x)⇤i 

(5)

which is not equivalent to the classiﬁcation risk R(g) deﬁned by (1). If the outer expectation was
over p(x) instead of p(x|y = +1) in (5)  then it would be equal to (1). This implies that if we had
a different problem setting of having positive conﬁdence equipped for x sampled from p(x)  this
would be trivially solved by a naive weighting idea.

3

From this viewpoint  (3) can be regarded as an application of importance sampling [13  48] to (4) to
cope with the distribution difference between p(x) and p(x|y = +1)  but with the advantage of not
requiring training data from the test distribution p(x).
In summary  our ERM formulation of (3) is different from naive conﬁdence-weighted classiﬁcation
of (4). We further show in Section 3.2 that the minimizer of (3) converges to the true risk minimizer 
while the minimizer of (4) converges to a different quantity and hence learning based on (4) is
inconsistent.

3.2 Theoretical analysis

Here we derive an estimation error bound for the proposed method. To begin with  let G be our
function class for ERM. Assume there exists Cg > 0 such that supg2G kgk1  Cg as well as C` > 0
such that sup|z|Cg `(z)  C`. The existence of C` may be guaranteed for all reasonable ` given a
reasonable G in the sense that Cg exists. As usual [31]  assume `(z) is Lipschitz continuous for all
|z| Cg with a (not necessarily optimal) Lipschitz constant L`.
Denote by bR(g) the objective function of (3) times ⇡+  which is unbiased in estimating R(g) in (1)
according to Theorem 1. Subsequently  let g⇤ = arg ming2G R(g) be the true risk minimizer  and
ˆg = arg ming2G bR(g) be the empirical risk minimizer  respectively. The estimation error is deﬁned
as R(ˆg)  R(g⇤)  and we are going to bound it from above.
In Theorem 1  (1  r(x))/r(x) is playing a role inside the expectation  for the fact that

r(x) = p(y = +1 | x) > 0 for x ⇠ p(x | y = +1).

In order to derive any error bound based on statistical learning theory  we should ensure that r(x)
could never be too close to zero. To this end  assume there is Cr > 0 such that r(x)  Cr almost
surely. We may trim r(x) and then analyze the bounded but biased version of bR(g) alternatively. For
simplicity  only the unbiased version is involved after assuming Cr exists.
Lemma 2. For any > 0  the following uniform deviation bound holds with probability at least
1   (over repeated sampling of data for evaluating bR(g)):
Cr◆r ln(2/)
where Rn(G) is the Rademacher complexity of G for X of size n drawn from p(x | y = +1).1
Lemma 2 guarantees that with high probability bR(g) concentrates around R(g) for all g 2G   and the
degree of such concentration is controlled by Rn(G). Based on this lemma  we are able to establish
an estimation error bound  as follows:
Theorem 3. For any > 0  with probability at least 1   (over repeated sampling of data for
training ˆg)  we have

supg2G |bR(g)  R(g)| 2⇡+✓L` +

Cr◆ Rn(G) + ⇡+✓C` +

(6)

L`

C`

 

2n

R(ˆg)  R(g⇤)  4⇡+✓L` +

L`

Cr◆ Rn(G) + 2⇡+✓C` +

C`

Cr◆r ln(2/)

2n

.

(7)

Theorem 3 guarantees learning with (3) is consistent [25]: n ! 1 always means R(ˆg) ! R(g⇤).
Consider linear-in-parameter models deﬁned by

G = {g(x) = hw  (x)iH |k wkH  Cw k(x)kH  C} 

where H is a Hilbert space  h· ·iH is the inner product in H  w 2H is the normal   : Rd !H is
a feature map  and Cw > 0 and C > 0 are constants [43]. It is known that Rn(G)  CwC/pn
[31] and thus R(ˆg) ! R(g⇤) in Op(1/pn)  where Op denotes the order in probability. This order is
already the optimal parametric rate and cannot be improved without additional strong assumptions

1Rn(G) = EX E1 ... n [supg2G

lowing [31].

1

nPxi2X

ig(xi)] where 1  . . .   n are n Rademacher variables fol-

4

on p(x  y)  ` and G jointly [28]. Additionally  if ` is strictly convex we have ˆg ! g⇤  and if the
aforementioned G is used ˆg ! g⇤ in Op(1/pn) [3].
At ﬁrst glance  learning with (4) is numerically more stable; however  it is generally inconsistent 
especially when g is linear in parameters and ` is strictly convex. Denote by bR0(g) the objective
function of (4) times ⇡+  which is unbiased to R0(g) = ⇡+E+Ep(y|x)[`(yg(x))] rather than R(g).
By the same technique for proving (6) and (7)  it is not difﬁcult to show that with probability at least
1   

and hence

where

 

supg2G |bR0(g)  R0(g)| 4⇡+L`Rn(G) + 2⇡+C`r ln(2/)
R0(ˆg0)  R0(g0⇤)  8⇡+L`Rn(G) + 4⇡+C`r ln(2/)
ˆg0 = arg ming2G bR0(g).
g0⇤ = arg ming2G R0(g)

and

2n

2n

 

As a result  when the strict convexity of R0(g) and bR0(g) is also met  we have ˆg0 ! g0⇤. This
demonstrates the inconsistency of learning with (4)  since R0(g) 6= R(g) which leads to g0⇤ 6= g⇤
given any reasonable G.
Implementation
3.3

Finally we give examples of implementations. As a classiﬁer g  let us consider a linear-in-parameter
model g(x) = ↵>(x)  where > denotes the transpose  (x) is a vector of basis functions  and ↵
is a parameter vector. Then from (3)  the `2-regularized ERM is formulated as

min
↵

nXi=1h`↵>(xi) +

1  ri
ri

`  ↵>(xi)i +


2

↵>R↵ 

where  is a non-negative constant and R is a positive semi-deﬁnite matrix. In practice  we can use
any loss functions such as squared loss `S(z) = (z  1)2  hinge loss `H(z) = max(0  1  z)  and
ramp loss `R(z) = min(1  max(0  1  z)). In the experiments in Section 4  we use the logistic loss
`L(z) = log(1 + ez)  which yields 

min
↵

nXi=1hlog1 + e↵>(xi)+

1  ri
ri

log1 + e↵>(xi)i+


2

↵>R↵.

(8)

The above objective function is continuous and differentiable  and therefore optimization can be
efﬁciently performed  for example  by quasi-Newton [35] or stochastic gradient methods [45].

4 Experiments

In this section  we numerically illustrate the behavior of the proposed method on synthetic datasets
for linear models. We further demonstrate the usefulness of the proposed method on bench-
mark datasets for deep neural networks that are highly nonlinear models. The implementa-
tion is based on PyTorch [37]  Sklearn [38]  and mpmath [20]. Our code will be available on
http://github.com/takashiishida/pconf.

4.1 Synthetic experiments with linear models

Setup: We used two-dimensional Gaussian distributions with means µ+ and µ and covariance
matrices ⌃+ and ⌃  for p(x|y = +1) and p(x|y = 1)  respectively. For these parameters  we
tried various combinations visually shown in Figure 2. The speciﬁc parameters used for each setup
are:
2  .

• Setup A: µ+ = [0  0]>  µ = [2  5]>  ⌃+ =

7    ⌃ = 2

7 6
6

0

0

5

Figure 2: Illustrations based on a single trail of the four setups used in experiments with various
Gaussian distributions. The red and green lines are decision boundaries obtained by Pconf and
Weighted classiﬁcation  respectively  where only positive data with conﬁdence are used (no negative
data). The black boundary is obtained by O-SVM  which uses only hard-labeled positive data. The
blue boundary is obtained by the fully-supervised method using data from both classes. Histograms
of conﬁdence of positive data are shown below.

• Setup B: µ+ = [0  0]>  µ = [0  4]>  ⌃+ = 5
• Setup C: µ+ = [0  0]>  µ = [0  8]>  ⌃+ =
• Setup D: µ+ = [0  0]>  µ = [0  4]>  ⌃+ = 4

3

0

6

0

0

3

5 3
3

5  .
5    ⌃ =
7  .
7    ⌃ = 7
1  .
4    ⌃ = 1

0

6

7 6
6

In the case of using two Gaussian distributions  p(y = +1|x) > 0 is satisﬁed for any x sampled from
p(x)  which is a necessary condition for applying Theorem 1. 500 positive data and 500 negative
data were generated independently from each distribution for training.2 Similarly  1 000 positive
and 1 000 negative data were generated for testing. We compared our proposed method (3) with the
weighted classiﬁcation method (4)  a regression based method (predict the conﬁdence value itself
and post-process output to a binary signal by comparing it to 0.5)  one-class support vector machine
(O-SVM  [42]) with the Gaussian kernel  and a fully-supervised method based on the empirical
version of (1). Note that the proposed method  weighted method  and regression based method only
use Pconf data  O-SVM only uses (hard-labeled) positive data  and the fully-supervised method uses
both positive and negative data.
In the proposed  weighted  fully-supervised methods  linear-in-input model g(x) = ↵>x + b and the
logistic loss were commonly used and vanilla gradient descent with 5  000 epochs (full-batch size)
and learning rate 0.001 was used for optimization. For the regression-based method  we used the
squared loss and analytical solution [15]. For the purpose of clear comparison of the risk  we did
not use regularization in this toy experiment. An exception was O-SVM  where the user is required
to subjectively pre-specify regularization parameter ⌫ and Gaussian bandwidth . We set them at
⌫ = 0.05 and  = 0.1.3

Analysis with true positive-conﬁdence: Our ﬁrst experiments were conducted when true positive-
conﬁdence was known. The positive-conﬁdence r(x) was analytically computed from the two
2Negative training data are used only in the fully-supervised method that is tested for performance comparison.
3If we naively use default parameters in Sklearn [38] instead  which is the usual case in the real world without
negative data for validation  the classiﬁcation accuracy of O-SVM is worse for all setups except D in Table 1 
which demonstrates the difﬁculty of using O-SVM.

6

Table 1: Comparison of the proposed Pconf classiﬁcation with other methods  with varying degrees
of overlap between the positive and negative distributions. We report the mean and standard deviation
of the classiﬁcation accuracy over 20 trials. We show the best and equivalent methods based on the
5% t-test in bold  excluding the fully-supervised method and O-SVM whose settings are different
from the others.

Setup

Pconf

A
B
C
D

89.7 ± 0.6
81.2 ± 1.1
90.2 ± 9.1
91.5 ± 0.5

Weighted
88.7 ± 1.2
78.1 ± 1.8
82.7 ± 13.1
90.8 ± 0.7

Setup A

Regression
68.4 ± 6.5
73.2 ± 3.2
50.5 ± 1.7
64.6 ± 5.3

O-SVM Supervised
76.0 ± 3.5
89.8 ± 0.7
71.3 ± 2.3
81.4 ± 1.0
93.6 ± 0.5
90.8 ± 1.2
57.1 ± 4.8
91.4 ± 0.5

Table 2: Mean and
standard deviation of
the classiﬁcation accu-
racy with noisy posi-
tive conﬁdence. The
experimental setup is
the same as Table 1 
except
that positive
conﬁdence scores for
positive data are noisy.
Std.
is the standard
deviation of Gaussian
noise.

Pconf

Std.
Weighted
0.01 89.8 ± 0.6 88.8 ± 0.9
0.05 89.7 ± 0.6 88.3 ± 1.1
0.10 89.2 ± 0.7 87.6 ± 1.4
0.20 85.9 ± 2.5 85.8 ± 2.5

Setup B

Pconf

Std.
Weighted
0.01 81.2 ± 0.9 78.2 ± 1.4
0.05 80.7 ± 2.3 78.1 ± 1.4
0.10 80.8 ± 1.2 77.8 ± 1.5
0.20 77.8 ± 1.4 77.2 ± 1.9

Setup C

Pconf

Std.
Weighted
0.01 92.4 ± 1.7 84.0 ± 8.2
0.05 92.2 ± 3.3 78.5 ± 11.3
0.10 90.8 ± 9.5 72.6 ± 12.9
0.20 88.0 ± 9.5 65.5 ± 13.1

Setup D

Pconf

Std.
Weighted
0.01 91.6 ± 0.5 90.6 ± 0.9
0.05 91.5 ± 0.5 89.9 ± 1.2
0.10 90.8 ± 0.7 88.7 ± 1.8
0.20 87.7 ± 0.8 85.5 ± 3.7

Gaussian densities and given to each positive data. The results in Table 1 show that the proposed
Pconf method is signiﬁcantly better than the baselines in all cases. In most cases  the proposed Pconf
method has similar accuracy compared with the fully supervised case  excluding Setup C where there
is a few percent loss. Note that the naive weighted method is consistent if the model is correctly
speciﬁed  but becomes inconsistent if misspeciﬁed [48].4

Analysis with noisy positive-conﬁdence:
In the above toy experiments  we assumed that true
positive conﬁdence r(x) = p(y = +1|x) is exactly accessible  but this can be unrealistic in practice.
To investigate the inﬂuence of noise in positive-conﬁdence  we conducted experiments with noisy
positive-conﬁdence.
As noisy positive conﬁdence  we added zero-mean Gaussian noise with standard deviation chosen
from {0.01  0.05  0.1  0.2}. As the standard deviation gets larger  more noise will be incorporated into
positive-conﬁdence. When the modiﬁed positive-conﬁdence was over 1 or below 0.01  we clipped it
to 1 or rounded up to 0.01 respectively.
The results are shown in Table 2. As expected  the performance starts to deteriorate as the conﬁdence
becomes more noisy (i.e.  as the standard deviation of Gaussian noise is larger)  but the proposed
method still works reasonably well in almost all cases.

4.2 Benchmark experiments with neural network models

Here  we use more realistic benchmark datasets and more ﬂexible neural network models for experi-
ments.

4Since our proposed method has coefﬁcient 1ri
ri

in the 2nd term of (3)  it may suffer numerical problems 
e.g.  when ri is extremely small. To investigate this  we used the mpmath package [20] to compute the gradient
with arbitrary precision. The experimental results were actually not that much different from the ones obtained
with single precision  implying that the numerical problems are not much troublesome.

7

Fashion-MNIST: The Fashion-MNIST dataset5 consists of 70 000 examples where each sample is
a 28 ⇥ 28 gray-scale image (input dimension is 784)  associated with a label from 10 fashion item
classes. We standardized the data to have zero mean and unit variance.
First  we chose “T-shirt/top” as the positive class  and another item for the negative class. The binary
dataset was then divided into four sub-datasets: a training set  a validation set  a test set  and a dataset
for learning a probabilistic classiﬁer to estimate positive-conﬁdence. Note that we ask labelers for
positive-conﬁdence values in real-world Pconf classiﬁcation  but we obtained positive-conﬁdence
values through a probabilistic classiﬁer here.
We used logistic regression with the same network architecture as a probabilistic classiﬁer to generate
conﬁdence.6 However  instead of weight decay  we used dropout [47] with rate 50% after each
fully-connected layer  and early-stopping with 20 epochs  since softmax output of ﬂexible neural
networks tends to be extremely close to 0 or 1 [14]  which is not suitable as a representation of
conﬁdence. Furthermore  we rounded up positive conﬁdence less than 1% to 1% to stabilize the
optimization process.
We compared Pconf classiﬁcation (3) with weighted classiﬁcation (4) and fully-supervised classiﬁ-
cation based on the empirical version of (1). We used the logistic loss for these methods. We also
compared our method with Auto-Encoder [17] as a one-class classiﬁcation method.
Except Auto-Encoder  we used a fully-connected neural network of three hidden layers (d-100-100-
100-1) with rectiﬁed linear units (ReLU) [32] as the activation functions  and weight decay candidates
were chosen from {107  104  101}. Adam [22] was again used for optimization with 200 epochs
and mini-batch size 100.
To select hyper-parameters with validation data  we used the zero-one loss versions of (3) and (4) for
Pconf classiﬁcation and weighted classiﬁcation  respectively  since no negative data were available in
the validation process and thus we could not directly use the classiﬁcation accuracy. On the other
hand  the classiﬁcation accuracy was directly used for hyper-parameter tuning of the fully-supervised
method  which is extremely advantageous. We reported the test accuracy of the model with the best
validation score out of all epochs.
Auto-Encoder was trained with (hard-labeled) positive data  and we classiﬁed test data into positive
class if the mean squared error (MSE) is below a threshold of 70% quantile  and into negative class
otherwise. Since we have no negative data for validating hyper-parameters  we sort the MSEs of
training positive data in ascending order. We set the weight decay to 104. The architecture is
d-100-100-100-100 for encoding and the reversed version for decoding  with ReLU after hidden
layers and Tanh after the ﬁnal layer.

CIFAR-10: The CIFAR-10 dataset 7 consists of 10 classes  with 5 000 images in each class. Each
image is given in a 32 ⇥ 32 ⇥ 3 format. We chose “airplane” as the positive class and one of the
other classes as the negative class in order to construct a dataset for binary classiﬁcation. We used the
neural network architecture speciﬁed in Appendix B.1.
For the probabilistic classiﬁer  the same architecture as that for Fashion-MNIST was used except
dropout with rate 50% was added after the ﬁrst two fully-connected layers. For Auto-Encoder  the
MSE threshold was set to 80% quantile  and we used the architecture speciﬁed in Appendix B.2.
Other details such as the loss function and weight-decay follow the same setup as the Fashion-MNIST
experiments.

Results: The results in Table 3 and Table 4 show that in most cases  Pconf classiﬁcation either
outperforms or is comparable to the weighted classiﬁcation baseline  outperforms Auto-Encoder  and
is even comparable to the fully-supervised method in some cases.

5https://github.com/zalandoresearch/fashion-mnist
6Both positive and negative data are used to train the probabilistic classiﬁer to estimate conﬁdence  and this

data is separated from any other process of experiments.

7https://www.cs.toronto.edu/˜kriz/cifar.html

8

Table 3: Mean and standard deviation of the classiﬁcation accuracy over 20 trials for the Fashion-
MNIST dataset with fully-connected three hidden-layer neural networks. Pconf classiﬁcation
was compared with the baseline Weighted classiﬁcation method  Auto-Encoder method and fully-
supervised method  with T-shirt as the positive class and different choices for the negative class. The
best and equivalent methods are shown in bold based on the 5% t-test  excluding the Auto-Encoder
method and fully-supervised method.

P / N

Pconf

T-shirt / trouser
T-shirt / pullover
T-shirt / dress
T-shirt / coat
T-shirt / sandal
T-shirt / shirt
T-shirt / sneaker

T-shirt / bag

T-shirt / ankle boot

92.14 ± 4.06
96.00 ± 0.29
91.52 ± 1.14
98.12 ± 0.33
99.55 ± 0.22
83.70 ± 0.46
89.86 ± 13.32
97.56 ± 0.99
98.84 ± 1.43

Weighted
85.30 ± 9.07
96.08 ± 1.05
89.31 ± 1.08
98.13 ± 1.12
87.83 ± 18.79
83.60 ± 0.65
58.26 ± 14.27
95.34 ± 1.00
88.87 ± 7.86

Auto-Encoder
71.06 ± 1.00
70.27 ± 1.22
53.82 ± 0.93
68.74 ± 0.98
82.02 ± 0.49
57.76 ± 0.55
83.70 ± 0.26
82.79 ± 0.70
85.07 ± 0.37

Supervised
98.98 ± 0.16
96.17 ± 0.34
96.56 ± 0.34
98.44 ± 0.13
99.93 ± 0.09
85.57 ± 0.69
100.00 ± 0.00
99.02 ± 0.29
99.76 ± 0.07

Table 4: Mean and standard deviation of the classiﬁcation accuracy over 20 trials for the CIFAR-10
dataset with convolutional neural networks. Pconf classiﬁcation was compared with the baseline
Weighted classiﬁcation method  Auto-Encoder method and fully-supervised method  with airplane
as the positive class and different choices for the negative class. The best and equivalent methods
are shown in bold based on the 5% t-test  excluding the Auto-Encorder method and fully-supervised
method.

P / N

airplane / automobile

airplane / bird
airplane / cat
airplane / deer
airplane / dog
airplane / frog
airplane / horse
airplane / ship
airplane / truck

Pconf

82.68 ± 1.89
82.23 ± 1.21
85.18 ± 1.35
87.68 ± 1.36
89.91 ± 0.85
90.80 ± 0.98
89.82 ± 1.07
69.71 ± 2.37
81.76 ± 2.09

Weighted
76.21 ± 2.43
80.66 ± 1.60
89.60 ± 0.92
87.24 ± 1.58
89.08 ± 1.95
81.84 ± 3.92
85.10 ± 2.61
70.68 ± 1.45
86.74 ± 0.85

Auto-Encoder
75.13 ± 0.42
54.83 ± 0.39
61.03 ± 0.59
55.60 ± 0.53
62.64 ± 0.63
62.52 ± 0.68
67.55 ± 0.73
52.09 ± 0.42
73.74 ± 0.38

Supervised
93.96 ± 0.58
87.76 ± 4.97
92.90 ± 0.58
93.35 ± 0.77
94.61 ± 0.45
95.95 ± 0.40
95.65 ± 0.37
81.45 ± 8.87
92.10 ± 0.82

5 Conclusion

We proposed a novel problem setting and algorithm for binary classiﬁcation from positive data
equipped with conﬁdence. Our key contribution was to show that an unbiased estimator of the classiﬁ-
cation risk can be obtained for positive-conﬁdence data  without negative data or even unlabeled data.
This was achieved by reformulating the classiﬁcation risk based on both positive and negative data 
to an equivalent expression that only requires positive-conﬁdence data. Theoretically  we established
an estimation error bound  and experimentally demonstrated the usefulness of our algorithm.

9

Acknowledgments
TI was supported by Sumitomo Mitsui Asset Management. MS was supported by JST CREST
JPMJCR1403. We thank Ikko Yamane and Tomoya Sakai for the helpful discussions. We also thank
anonymous reviewers for pointing out numerical issues in our experiments  and for pointing out the
necessary condition in Theorem 1 in our earlier work of this paper.

References
[1] H. Bao  G. Niu  and M. Sugiyama. Classiﬁcation from pairwise similarity and unlabeled data.

In ICML  2018.

[2] G. Blanchard  G. Lee  and C. Scott. Semi-supervised novelty detection. Journal of Machine

Learning Research  11:2973–3009  2010.

[3] S. Boyd and L. Vandenberghe. Convex Optimization. Cambridge University Press  2004.

[4] M. M. Breunig  H. P. Kriegel  R. T. Ng  and J. Sander. Lof: Identifying density-based local

outliers. In ACM SIGMOD  2000.

[5] V. Chandola  A. Banerjee  and V. Kumar. Anomaly detection: A survey. ACM Computing

Surveys  41(3)  2009.

[6] O. Chapelle  B. Schölkopf  and A. Zien  editors. Semi-Supervised Learning. MIT Press  2006.

[7] M. C. du Plessis  G. Niu  and M. Sugiyama. Clustering unclustered data: Unsupervised binary

labeling of two datasets having different class balances. In TAAI  2013.

[8] M. C. du Plessis  G. Niu  and M. Sugiyama. Analysis of learning from positive and unlabeled

data. In NIPS  2014.

[9] M. C. du Plessis  G. Niu  and M. Sugiyama. Convex formulation for learning from positive and

unlabeled data. In ICML  2015.

[10] M. C. du Plessis  G. Niu  and M. Sugiyama. Class-prior estimation for learning from positive

and unlabeled data. Machine Learning  106(4):463–492  2017.

[11] M. C. du Plessis and M. Sugiyama. Class prior estimation from positive and unlabeled data.

IEICE Transactions on Information and Systems  E97-D(5):1358–1362  2014.

[12] C. Elkan and K. Noto. Learning classiﬁers from only positive and unlabeled data. In KDD 

2008.

[13] G. S. Fishman. Monte Carlo: Concepts  Algorithms  and Applications. Springer-Verlag  1996.

[14] I. Goodfellow  Y. Bengio  and A. Courville. Deep Learning. MIT Press  2016.

[15] T. Hastie  R. Tibshirani  and J. Friedman. The Elements of Statistical Learning: Data Mining 

Inference  and Prediction. Springer  2009.

[16] S. Hido  Y. Tsuboi  H. Kashima  M. Sugiyama  and T. Kanamori. Inlier-based outlier detection

via direct density ratio estimation. In ICDM  2008.

[17] G. E. Hinton and R. R. Salakhutdinov. Reducing the dimensionality of data with neural networks.

Science  313(5786):504–507  2006.

[18] T. Ishida  G. Niu  W. Hu  and M. Sugiyama. Learning from complementary labels. In NIPS 

2017.

[19] T. Ishida  G. Niu  A. K. Menon  and M. Sugiyama. Complementary-label learning for arbitrary

losses and models. arXiv preprint arXiv:1810.04327  2018.

[20] F. Johansson et al. mpmath: a Python library for arbitrary-precision ﬂoating-point arithmetic

(version 0.18)  December 2013. http://mpmath.org/.

10

[21] S. S. Khan and M. G. Madden. A survey of recent trends in one class classiﬁcation. In Irish

Conference on Artiﬁcial Intelligence and Cognitive Science  2009.

[22] D. P. Kingma and J. L. Ba. Adam: A method for stochastic optimization. In ICLR  2015.
[23] T. N. Kipf and M. Welling. Semi-supervised classiﬁcation with graph convolutional networks.

In ICLR  2017.

[24] R. Kiryo  G. Niu  M. C. du Plessis  and M. Sugiyama. Positive-unlabeled learning with

non-negative risk estimator. In NIPS  2017.

[25] M. Ledoux and M. Talagrand. Probability in Banach Spaces: Isoperimetry and Processes.

Springer  1991.

[26] N. Lu  G. Niu  A. K. Menon  and M. Sugiyama. On the minimal supervision for training any

binary classiﬁer from only unlabeled data. arXiv preprint arXiv:1808.10585v2  2018.

[27] C. McDiarmid. On the method of bounded differences. In J. Siemons  editor  Surveys in

Combinatorics  pages 148–188. Cambridge University Press  1989.

[28] S. Mendelson. Lower bounds for the empirical minimization algorithm. IEEE Transactions on

Information Theory  54(8):3797–3803  2008.

[29] A. Menon  B. Van Rooyen  C. S. Ong  and B. Williamson. Learning from corrupted binary

labels via class-probability estimation. In ICML  2015.

[30] T. Miyato  S. Maeda  M. Koyama  K. Nakae  and S. Ishii. Distributional smoothing with virtual

adversarial training. In ICLR  2016.

[31] M. Mohri  A. Rostamizadeh  and A. Talwalkar. Foundations of Machine Learning. MIT Press 

2012.

[32] V. Nair and G.E. Hinton. Rectiﬁed linear units improve restricted boltzmann machines. In

ICML  2010.

[33] N. Natarajan  I. S. Dhillon  P. Ravikumar  and A. Tewari. Learning with noisy labels. In NIPS 

2013.

[34] G. Niu  M. C. du Plessis  T. Sakai  Y. Ma  and M. Sugiyama. Theoretical comparisons of

positive-unlabeled learning against positive-negative learning. In NIPS  2016.

[35] J. Nocedal and S. Wright. Numerical Optimization. Springer  2006.
[36] A. Oliver  A. Odena  C. Raffel  E. D. Cubuk  and I. J. Goodfellow. Realistic evaluation of deep

semi-supervised learning algorithms. In NeurIPS  2018.

[37] A. Paszke  S. Gross  S. Chintala  G. Chanan  E. Yang  Z. DeVito  Z. Lin  A. Desmaison 
L. Antiga  and A. Lerer. Automatic differentiation in pytorch. In Autodiff Workshop in NIPS 
2017.

[38] F. Pedregosa  G. Varoquaux  A. Gramfort  V. Michel  B. Thirion  O. Grisel  M. Blondel 
P. Prettenhofer  R. Weiss  V. Dubourg  J. Vanderplas  A. Passos  D. Cournapeau  M. Brucher 
M. Perrot  and E. Duchesnay. Scikit-learn: Machine learning in Python. Journal of Machine
Learning Research  12:2825–2830  2011.

[39] N. Quadrianto  A. Smola  T. Caetano  and Q. Le. Estimating labels from label proportions. In

ICML  2008.

[40] T. Sakai  M. C. du Plessis  G. Niu  and M. Sugiyama. Semi-supervised classiﬁcation based on

classiﬁcation from positive and unlabeled data. In ICML  2017.

[41] T. Sakai  G. Niu  and M. Sugiyama. Semi-supervised AUC optimization based on positive-

unlabeled learning. Machine Learning  107(4):767–794  2018.

[42] B. Schölkopf  J. C. Platt  J Shawe-Taylor  A. J. Smola  and R. C. Williamson. Estimating the

support of a high-dimensional distribution. Neural Computation  13:1443–1471  2001.

11

[43] B. Schölkopf and A. Smola. Learning with Kernels. MIT Press  2001.
[44] C. Scott and G. Blanchard. Novelty detection: Unlabeled data deﬁnitely help. In AISTATS 

2009.

[45] S. Shalev-Shwartz and S. Ben-David. Understanding Machine Learning: From Theory to

Algorithms. Cambridge University Press  2014.

[46] A. Smola  L. Song  and C. H. Teo. Relative novelty detection. In AISTATS  2009.
[47] N. Srivastava  G. Hinton  A. Krizhevsky  I. Sutskever  and R. Salakhutdinov. Dropout: A
simple way to prevent neural networks from overﬁtting. Journal of Machine Learning Research 
15:1929–1958  2014.

[48] M. Sugiyama and M. Kawanabe. Machine Learning in Non-Stationary Environments: Introduc-

tion to Covariate Shift Adaptation. MIT Press  2012.

[49] M. Sugiyama  G. Niu  M. Yamada  M. Kimura  and H. Hachiya. Information-maximization
clustering based on squared-loss mutual information. Neural Computation  26(1):84–131  2014.
[50] D. Tax and R. Duin. Support vextor domain description. In Pattern Recognition Letters  1999.
[51] D. M. J. Tax and R. P. W. Duin. Support vector data description. Machine Learning  54(1):45–66 

2004.

[52] V. N. Vapnik. Statistical Learning Theory. John Wiley and Sons  1998.
[53] Z. Yang  W. W. Cohen  and R. Salakhutdinov. Revisiting semi-supervised learning with graph

embeddings. In ICML  2016.

[54] F. X. Yu  D. Liu  S. Kumar  T. Jebara  and S.-F. Chang. /svm for learning with label proportions.

In ICML  2013.

[55] X. Yu  T. Liu  M. Gong  and D. Tao. Learning with biased complementary labels. In ECCV 

2018.

12

,Takashi Ishida
Gang Niu
Masashi Sugiyama