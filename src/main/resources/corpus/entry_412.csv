2018,Adaptive Path-Integral Autoencoders: Representation Learning and Planning for Dynamical Systems,We present a representation learning algorithm that learns a low-dimensional latent dynamical system from high-dimensional sequential raw data  e.g.  video. The framework builds upon recent advances in amortized inference methods that use both an inference network and a refinement procedure to output samples from a variational distribution given an observation sequence  and takes advantage of the duality between control and inference to approximately solve the intractable inference problem using the path integral control approach. The learned dynamical model can be used to predict and plan the future states; we also present the efficient planning method that exploits the learned low-dimensional latent dynamics. Numerical experiments show that the proposed path-integral control based variational inference method leads to tighter lower bounds in statistical model learning of sequential data. Supplementary video: https://youtu.be/xCp35crUoLQ,Adaptive Path-Integral Autoencoder: Representation

Learning and Planning for Dynamical Systems

Jung-Su Ha  Young-Jin Park  Hyeok-Joo Chae  Soon-Seo Park  and Han-Lim Choi

Department of Aerospace Engineering & KI for Robotics  KAIST

{{jsha  yjpark  hjchae  sspark}@lics.  hanlimc@}kaist.ac.kr

Daejeon 305-701  Republic of Korea

Abstract

We present a representation learning algorithm that learns a low-dimensional latent
dynamical system from high-dimensional sequential raw data  e.g.  video. The
framework builds upon recent advances in amortized inference methods that use
both an inference network and a reÔ¨Ånement procedure to output samples from
a variational distribution given an observation sequence  and takes advantage of
the duality between control and inference to approximately solve the intractable
inference problem using the path integral control approach. The learned dynamical
model can be used to predict and plan the future states; we also present the efÔ¨Å-
cient planning method that exploits the learned low-dimensional latent dynamics.
Numerical experiments show that the proposed path-integral control based varia-
tional inference method leads to tighter lower bounds in statistical model learning
of sequential data. The supplementary video1 and the implementation code2 are
available online.

1

Introduction

Unsupervised learning of the underlying dynamics of sequential high-dimensional sensory inputs is
the essence of intelligence  because the agent should utilize the learned dynamical model to predict
and plan the future state. Such learning problems are formulated as latent or generative model
learning assuming that observations were emerged from the low-dimensional latent states  which
includes an intractable posterior inference of latent states for given input data. In the amortized
variational inference framework  an inference network is introduced to output variational parameters
of an approximate posterior distribution. This allows for a fast approximate inference procedure and
efÔ¨Åcient end-to-end training of the generative and inference networks when the learning signals from
a loss function are back-propagated into the inference network with reparameterization trick [Kingma
and Welling  2014  Rezende et al.  2014]. The learning procedure is based on optimization of a
surrogate loss  a lower-bound of data likelihood  which results in two source of sub-optimality:
an approximation gap and an amortization gap [Krishnan et al.  2018  Cremer et al.  2018]; the
former comes from the sub-optimality of variational approximation (the gap between true posterior
and optimal variational distribution) and the latter is caused by the amortized approximation (the
gap between the optimal variational distribution and the distribution from the inference network).
Recently  several works  e.g.  [Hjelm et al.  2016  Krishnan et al.  2018  Kim et al.  2018]  combined
iterative reÔ¨Ånement procedures with the amortized inference  where the output distribution of the
inference network is used as a warm-start point of reÔ¨Ånement. This technique is referred to as the
semi-amortized inference and  since reÔ¨Åned variational distributions do not rely only on the inference
network  the sub-optimality from amortization gap can be mitigated.

1https://youtu.be/xCp35crUoLQ
2https://github.com/yjparkLiCS/18-NeurIPS-APIAE

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montr√©al  Canada.

For sequential data modeling  a generative model should be considered as a dynamical system
and a more sophisticated (approximate) inference method is required. With the assumption that
the underlying dynamics has the Markov property  a state space model can be introduced and it
allows the inference network to be structured so as to mimic the factorized form of a true posterior
distribution [Krishnan et al.  2017  Karl et al.  2017  Fraccaro et al.  2017]. The efÔ¨Åcient end-to-end
training with the amortized inference is also possible here  where the inference network should output
the variational distribution of latent state trajectories for given observation sequences. Even when
the inference network is structured  the amortization gap increases inevitably because the inference
should be performed in the trajectory space.
In this work  we present a semi-amortized variational inference method operated in the trajectory
space. For a generative model given by a state space model  an initial state distribution and control
inputs serve as parameters of variational distributions; the inference network is trained to output these
variational parameters such that the corresponding latent trajectory well-describes the observation
sequence. In this certain formulation  the divergence between the prior and the variational distribution
is naturally derived from stochastic calculus and then the inference problem can be converted into a
stochastic optimal control (SOC) problem  i.e.  so-called control-inference duality [Todorov  2008 
Ruiz and Kappen  2017]. In the SOC view  what the inference network does is to approximate the
optimal control policy  which is hardly thought to be well-done when we observe that SOC problems
are hard to solve at once  so iterative methods are generally used to solve the problems [Todorov 
2008  Tamar et al.  2016  Okada et al.  2017]. Thus  we adopt the adaptive path-integral control
method to iteratively reÔ¨Åne the variational parameters. We show that because samples from the reÔ¨Åned
variational distribution build tighter lower-bound and all the reÔ¨Ånement procedures are differentiable 
efÔ¨Åcient end-to-end training is possible. Moreover  because the proposed framework is based on the
SOC method  the same structure can be utilized to plan the future observation sequence  where the
learned low-dimensional stochastic dynamics is used to explore the high-dimensional observation
space efÔ¨Åciently.

2 Background

2.1 Statistical Modeling of Sequential Observations
Suppose that we have a set of observation sequences {x(i)
1:K ‚â° {xk;‚àÄk =
1  ...  K}(i) are i.i.d. sequences of observation that lie on (possibly high-dimensional) data space 
X ‚äÇ Rdx. The problem of interest is to build a probabilistic model that explains the given observations
well. If a model is parameterized with Œ∏  the problem is formulated as a maximum likelihood
estimation (MLE) problem:

1:K}i=1 ... I  where x(i)

Œ∏‚àó = argmax

log pŒ∏(x(i)

1:K).

(1)

In this work  the observations are assumed to be emerged from a latent dynamical system  where a
latent state trajectory  z[0 T ] ‚â° {z(t); ‚àÄt ‚àà [0  T ]}  lies on a (possibly low-dimensional) latent space 
Z ‚äÇ Rdz:

pŒ∏(x1:K|z[0 T ])dpŒ∏(z[0 T ]) 

pŒ∏(x1:K) =

(2)
where pŒ∏(x1:K|z[0 T ]) and pŒ∏(z[0 T ]) are called a conditional likelihood and a prior distribution 
respectively3 . In particular  we consider the state space model where latent states are governed by
a continuous-time stochastic differential equation (SDE)  i.e.  the prior pŒ∏(z[0 T ]) is a probability
measure of a following system:

(3)
where w(t) is a du-dimensional Wiener process. Additionally  a conditional likelihood of sequential
observations is assumed to be factorized along the time axis:

dz(t) = f (z(t))dt + œÉ(z(t))dw(t)  z(0) ‚àº p0(¬∑) 

(cid:88)

i

Œ∏

(cid:90)

K(cid:89)

pŒ∏(xk|z(tk)) 
where {tk} is a sequence of discrete time points with t1 = 0  tK = T .

pŒ∏(x1:K|z[0 T ]) =

k=1

(4)

3Because each observation trajectory can be considered independently  we leave trajectory index  i  out and

restrict our discussion to one trajectory for the sake of notational simplicity.

2

2.2 Amortized Variational Inference and Multi-Sample Objectives

(cid:90)

(cid:20)

(cid:21)

pŒ∏(x|z)pŒ∏(z)

The objective function (1) cannot be optimized directly because it contains the intractable integration.
To circumvent the intractable inference  a variational distribution q(¬∑) is introduced and then a surro-
gate loss function L(q  Œ∏; x)  which is called the evidence lower bound (ELBO)  can be considered
alternatively:

‚â° L(q  Œ∏; x) 

pŒ∏(x|z)pŒ∏(z)dz ‚â• Eq(z)

log

q(z)

log pŒ∏(x) = log

(5)
where q(¬∑) can be any probabilistic distribution over Z of which support includes that of pŒ∏(¬∑). The
gap between the log-likelihood and the ELBO is the Kullback‚ÄìLeibler (KL) divergence between q(z)
and the posterior pŒ∏(z|x):

log pŒ∏(x) ‚àí L(q  Œ∏; x) = DKL(q(z)||pŒ∏(z|x)).

(6)
In particular  the amortized variational inference approach introduces a conditional variational
distribution  z ‚àº qœÜ(¬∑|x)  to approximate the intractable posterior distribution. The variational
distribution qœÜ(¬∑|x)  which is referred to as the inference network  is parameterized by œÜ  so Œ∏
and œÜ can be simultaneously updated with (cid:53)(Œ∏ œÜ)L(qœÜ  Œ∏; x) using the stochastic gradient ascent.
Variational autoencoders (VAEs) [Kingma and Welling  2014  Rezende et al.  2014] make qœÜ(¬∑|x) a
reparameterizable distribution  where z = gœÜ(x  ) is a differentiable deterministic function of an
observation x and  ‚àº d(¬∑) sampled from a known base distribution d(¬∑). Then  the gradient can
be estimated as: (cid:53)(Œ∏ œÜ)L(qœÜ  Œ∏; x) = Ed()
  which generally yields a low
variance estimator.
A tighter lower bound is achieved by using multiple samples  z1:L  independently sampled from qœÜ:

(cid:104)(cid:53)(Œ∏ œÜ) log pŒ∏(x gœÜ(x ))
(cid:34)

qœÜ(gœÜ(x ))

(cid:35)

(cid:105)

log

(7)
It is proven that  as L increases  the bounds get tighter  i.e.  log pŒ∏(x) ‚â• ¬∑¬∑¬∑ ‚â• LL+1 ‚â• LL ‚â• ¬∑¬∑¬∑  
and the gap eventually vanishes [Burda et al.  2016  Cremer et al.  2017].This multi-sample objec-
tive (7) is in the class of Monte Carlo objectives (MCO) in the sense that it utilizes independent sam-
qœÜ(zl|x)   zl ‚àº
ples to estimate the marginal likelihood [Mnih and Rezende  2016]  ÀÜpŒ∏(x) = 1
L
qœÜ(¬∑|x). DeÔ¨Åning wŒ∏ œÜ(x  zl) ‚â° pŒ∏(x zl)

(cid:80)
i wŒ∏ œÜ(x zi)  the gradient of (7) is given by:

qœÜ(zl|x) and Àúwl ‚â° wŒ∏ œÜ(x zl)

pŒ∏(x zl)

l=1

l=1

.

LL ‚â° Ez1:L‚àºqœÜ(¬∑|x)

L(cid:88)

1
L

pŒ∏(x  zl)
qœÜ(zl|x)

(cid:34) L(cid:88)

(cid:80)L
(cid:35)

‚àá(Œ∏ œÜ)LL = E1:L‚àºd(¬∑)

Àúwl‚àá(Œ∏ œÜ) log wŒ∏ œÜ(x  gœÜ(x  l))

.

(8)

l=1

Since the parameter update is averaged over multiple samples with the weights Àúwl  the above
procedure is referred to as importance weighted autoencoders (IWAEs) [Burda et al.  2016]. The
performance of IWAE‚Äôs training crucially depends on the variance of the importance weights Àúw (or
equivalently  on the effective sample size)  which can be reduced by (i) increasing the number of
samples and (ii) decreasing the gap between the proposal and the true posterior distribution; when the
proposal qœÜ(¬∑|x) is equal to the true posterior pŒ∏(¬∑|x)  the variance is reduced to 0  i.e.  Àúwl = 1/L.

2.3 Semi-Amortized Variational Inference with Iterative ReÔ¨Ånement

As mentioned previously  the performance of generative model learning depends on the gap between
the variational and the posterior distributions. Thus  the amortized inference has two sources of
this gap: the approximation and amortization gaps [Krishnan et al.  2018  Cremer et al.  2018].
The approximation gap comes up by using the variational distribution to approximate the posterior
distribution  which is given by the KL-divergence between the posterior distribution and the optimal
variational distribution. The amortization gap is caused by the limit of the expressive power of
inference networks  where the variational parameters are not individually optimized for each observa-
tion but amortized over entire observations. To address the issue of the amortization gap  a hybrid
approach can be considered; for each observation  the variational distribution is reÔ¨Åned individually
from the output of the inference network. Compared to the amortized variational inference  this
hybrid approach  coined semi-amortized variational inference  allows for utilizing better variational
parameters in model learning.

3

3 Path Integral Adaptation for Variational Inference

3.1 Controlled SDE as variational distribution and structured inference network

When handling sequential observations  the variational distribution family should be carefully chosen
so as to efÔ¨Åciently handle increasing dimensions of variables along the time-axis. In this work 
the variational proposal distribution is given by the trajectory distribution of a controlled stochastic
dynamical system  where the controls  u ‚àà Rdu  and parameters of an initial state distribution  q0 
serve as variational parameters  i.e.  the proposal qu(z[0 T ]) is a probability measure of a following
system:

dz(t) = f (z(t))dt + œÉ(z(t))(u(t)dt + dw(t))  z(0) ‚àº q0(¬∑).

(9)
By applying Girsanov‚Äôs theorem in Appendix A that provides the likelihood ratio between p(z[0 T ])
and qu(z[0 T ])  the ELBO is written as:

(cid:90) T

(cid:90) T

(cid:35)

(cid:34)

L = Equ(z[0 T ])

log pŒ∏(x1:K|z[0 T ]) + log

p0(z(0))
q0(z(0))

‚àí 1
2

||u(t)||2dt ‚àí

0

0

u(t)T dw(t)

.

(10)
0 (or equivalently  the best

Equ(z[0 T ])

(cid:34)
q0(z(0)) ‚àí(cid:80)K

Then  the problem of Ô¨Ånding the optimal variational parameters u‚àó and q‚àó
approximate posterior) can be formulated as a SOC problem:

(cid:90) T

(cid:90) T

(cid:35)

u‚àó  q‚àó

0 = argmin

u q0

V (z[0 T ]) +

1
2

||u(t)||2dt +

0

0

u(t)T dw(t)

 

(SOC)

k   Kk}k=1 ... K‚àí1 as u(t  z(t)) = uf f

where V (z[0 T ]) ‚â° ‚àí log p0(z(0))
k=1 log pŒ∏(xk|z(tk)) serves as a state cost of the SOC problem.
Suppose that the control policy is discretized along the time-axis with the control parameters
{uf f
k ‚àí Kkz(t)  ‚àÄt ‚àà [tk  tk+1)  and the initial distribu-
tion is modeled to be the Gaussian distribution  q0(¬∑) = N (¬∑; ÀÜ¬µ0  ÀÜŒ£0). Once the inference problem
is converted into the SOC problem  the principle of optimality [Bellman  2013] provides the so-
phisticated and efÔ¨Åcient structure of inference networks. Note that  by the principle of optimality 
the optimal initial state distribution depends on the cost for all time horizon [0  T ] but the optimal
control policy at t only relies on the future cost in (t  T ]. Such a structure can be implemented using
a backward recurrent neural network (RNN) to output the approximate optimal control policy; while
the hidden states of the backward RNN compress the information of a given observation sequence
backward in time  the hidden state at each time step  k = K ‚àí 1  ...  2  outputs the control policy
k   Kk}. Finally  the Ô¨Årst hidden state additionally outputs the initial distribution
parameters  {uf f
parameters  {ÀÜ¬µ0  ÀÜŒ£0  uf f
1   K1}. For the detailed descriptions and illustrations  see Fig. 3(a) and
Algorithm 2 in Appendix C.

3.2 Adaptive Path-Integral Autoencoder

(SOC) is in a class of linearly-solvable optimal control problems [Todorov  2009] of which the
objective function can be written as a KL-divergence form:

(cid:0)qu(z[0 T ])||p‚àó(z[0 T ])(cid:1) ‚àí log Œæ 

J = DKL

(11)
where p‚àó  represented as dp‚àó(z[0 T ]) = exp(‚àíV (z[0 T ]))dpŒ∏(z[0 T ])/Œæ  is a probability measure in-

duced by optimally-controlled trajectories and Œæ ‚â°(cid:82) exp(‚àíV (z[0 T ]))dpŒ∏(z[0 T ]) is a normalization

constant (see Appendix A for details). By applying Girsanov‚Äôs theorem again  the optimal trajectory
distribution is expressed as:

dp‚àó(z[0 T ]) ‚àù dqu(z[0 T ]) exp(cid:0)‚àíSu(z[0 T ])(cid:1)  

(cid:90) T

u(t)T dw(t).

(12)

(13)

Su(z[0 T ]) = V (z[0 T ]) +

1
2

||u(t)||2dt +

0

0

(cid:90) T

This implies that the optimal trajectory distribution can be approximated by sampling a set of
[0 T ] ‚àº qu(¬∑)  and assigning their
trajectories according to the controlled dynamics with u(t)  i.e. zl

4

(cid:88)L
(cid:88)L

(cid:88)L

(cid:80)L
exp(‚àíSu(zl
i=1 exp(‚àíSu(zi

[0 T ]))

[0 T ]))

  ‚àÄl ‚àà {1  ...  L}. Similar to the MCO‚Äôs case  the
importance weights as Àúwl =
variance of importance weights decreases as the control input u(¬∑) gets closer to the true optimal
control input u‚àó(¬∑) and it reduces to 0 when u(t) = u‚àó(t  z(t)) [Thijssen and Kappen  2015].
The path-Integral control is a sampling-based SOC method  which approximates the optimal trajectory
distribution  ÀÜp‚àó  with weighted sample trajectories using (12)‚Äì(13) and updates control parameters
based on moment matching of qu to ÀÜp‚àó. Suppose that ÀÜp‚àó is approximated with sample trajectories and
their weights  {zl
[0 T ]  Àúwl}l=1 ... L  as above and let uf f (t) and K(t) represent feedforward control
and feedback gain  respectively. This work considers a standardized linear feedback controller to
regularize the Ô¨Årst and second moments of trajectory distributions  where a control input has a form
as:

u(t) = uf f (t) + K(t)Œ£‚àí1/2(t)(z(t) ‚àí ¬µ(t)) 

(14)
l=1 Àúwl(zl(t) ‚àí ¬µ(t))(zl(t) ‚àí ¬µ(t))T are the mean and
covariance of the state w.r.t. ÀÜp‚àó  respectively. Suppose a new set of trajectories and their weights is
obtained by a (previous) control policy u(t) = ¬Øuf f (t) + ¬ØK(t) ¬ØŒ£‚àí1/2(t)(z(t) ‚àí ¬Ø¬µ(t)). Then  the path
integral control theorem in Appendix B gives the update rules as:
uf f (t)dt = ¬Øuf f (t)dt + ¬ØK(t) ¬ØŒ£‚àí1/2(t)(¬µ(t) ‚àí ¬Ø¬µ(t))dt + Œ∑
K(t)dt = ¬ØK(t) ¬ØŒ£‚àí1/2(t)Œ£1/2(t)dt + Œ∑

(16)
with the adaptation rate Œ∑. The initial state distribution also can be updated into q0(¬∑) = N (¬∑; ÀÜ¬µ0  ÀÜŒ£0):

Œ£‚àí1/2(t)(zl(t) ‚àí ¬µ(t))

l=1 Àúwlzl(t) and Œ£(t) =(cid:80)L

where ¬µ(t) =(cid:80)L

(cid:88)L

Àúwldwl(t) 

Àúwldwl(t)

(cid:17)T

(cid:16)

(15)

l=1

l=1

 

l=1

l=1

1
L

ÀÜ¬µ0 =

ÀÜLL = log

(cid:88)L

Àúwlzl(0)  ÀÜŒ£0 =

[0 T ]))  ‚àáŒ∏ œÜ ÀÜLL = ‚àí(cid:88)L

Àúwl(zl(0) ‚àí ÀÜ¬µ0)(zl(0) ‚àí ÀÜ¬µ0)T .
(17)
1:K‚àí1  K1:K‚àí1}  given by the inference network
Starting from the variational parameters  {ÀÜ¬µ0  ÀÜŒ£0  uf f
and ¬Ø¬µ(t) = 0  ¬ØŒ£(t) = I  the update rules in (15)-(17) gradually reÔ¨Åne the parameters of qu in order
for the resulting trajectory distribution to be close to the posterior distribution. After R adaptations 
the MCO and its gradient are estimated by:
exp(‚àíSu(zl

(18)
where Œ∏ and œÜ denote the parameters of the generative model  i.e.  f (z)  œÉ(z)  p0(z) and p(x|z)  and
the inference network  i.e.  the backward RNN  respectively. Because all procedures in the path
integral adaptation and MCO construction are differentiable  they can be implemented by a fully
differentiable network with R recurrences  which we named Adaptive Path Integral Autoencoder
(APIAE); see also Fig. 3(b) in the Appendix C.
Note that the inference  reconstruction  and gradient backpropagation of APIAE can operate indepen-
dently for each of L samples. Consequently  the computational cost grows linearly with the number
of samples  L  and the number of adaptations  R. As implemented in IWAE [Burda et al.  2016]  we
replicated each observation data L times and the whole operations were parallelized with GPU. We
implemented APIAE with TensorÔ¨Çow [Abadi et al.  2016]; the pseudo code and algorithmic details
of APIAE are given in the Appendix C.

Àúwl‚àáŒ∏ œÜSu(zl

[0 T ]) 

l=1

l=1

4 High-dimensional Motion Planning with Learned Latent Model

High-dimensional motion planning is a challenging problem because of the curse of dimensionality:
The size of the conÔ¨Åguration space exponentially increases with the number of dimensions. However 
like in the latent variable model learning  it might be a reasonable assumption that conÔ¨Ågurations
a planning algorithm really needs to consider form some sort of low-dimensional manifold in the
conÔ¨Åguration space [Vernaza and Lee  2012]  and the learned generative model provides stochastic
dynamics in that manifold. Once this low-dimensional representation is obtained  any motion planning
algorithm can solve high-dimensional planning problem very efÔ¨Åciently by utilizing it to restrict the
search space.
More formally  suppose that the initial conÔ¨Åguration  x1  and corresponding latent state  z(0)  are
given and the cost function  Ck(xk)  encodes given task speciÔ¨Åcations of a planning problem  e.g. 

5

desirability/undesirability of certain conÔ¨Ågurations  a penalty for obstacle collision  etc. Then  the
planning problem can be converted into the problem of Ô¨Ånding the optimal trajectory distribution  qu 
that minimizes the following objective function:

(cid:35)

(cid:34) K(cid:88)

k=1

J(qu) = Ex1:K‚àºpŒ∏(¬∑|z[0 T ]) z[0 T ]‚àºqu(¬∑)

Ck(xk) + DKL(qu(z[0 T ])||pŒ∏(z[0 T ]))

.

(19)

That is  we want to Ô¨Ånd parameters  u  of the trajectory distribution which not only is likely
to generate sample conÔ¨Åguration sequences achieving the lower planning cost but also does
not deviate a lot from the (learned) prior  pŒ∏(z[0 T ]). The solution can be found using the
aforementioned adaptive path integral control method  where its state cost function is set as:
V (z[0 T ]) ‚â° EpŒ∏(x1:K|z[0 T ])
and the initial state distribution is not updated in the
adaptation process. After the adaptations with this state cost function  the resulting plan can simply be
sampled from the generative model  e.g.  x1:K ‚àº pŒ∏(¬∑|¬µ[0 T ]). Note that the time interval tk ‚àí tk‚àí1
and the trajectory length K can differ in the training and planning phases because continuous-time
dynamics is dealt with.

(cid:104)(cid:80)K

k=1 Ck(xk)

(cid:105)

5 Related Work
To address the complexity raised from temporal structures of data  several approaches that build a
sophisticated approximate inference model have been proposed. For example  Karl et al. [2017] used
the locally linear latent dynamics by introducing transition parameters  where an inference model
infers transition parameters rather than latent states from the local transition. Johnson et al. [2016]
combined a structured graphical model in latent space with a deep generative network  where an
inference network produces local evidence potentials for the message passing algorithms. Fraccaro
et al. [2017] constructed two layers of latent models  where linear-Gaussian dynamical systems
governed two latent layers and the observation at each time step was related to the middle layer
independently; the inference model in this framework consists of independent VAE‚Äôs inference
networks at each time-step and the Kalman smoothing algorithm along the time axis. Finally  deep
Kalman smoother (DKS) in [Krishnan et al.  2017] parameterized the dynamical system by a deep
neural network and built an inference network as it has the same structure with the factorized posterior
distribution. The idea of MCOs was also used in the temporal setting. Maddison et al. [2017]  Le
et al. [2018]  Naesseth et al. [2018] adapted the particle Ô¨Ålter (PF) algorithm as their inference models
and utilized a PF‚Äôs estimator of the marginal likelihood as an objective function of training which
Maddison et al. [2017] named the Ô¨Åltering variational objectives (FIVOs).
These approaches can be viewed as attempts to reduce the approximation gap; by building the infer-
ence model in sophisticated ways that exploit underlying structure of data  the resulting variational
family could Ô¨Çexibly approximate the posterior distribution. To overcome the amortization gap caused
by inference networks  the semi-amortized method utilizes an iterative reÔ¨Ånement procedure for
improving variational distribution. Let qœÜ and q‚àó be the variational distributions from the inference
network and from the reÔ¨Ånement procedure  i.e.  before and after the reÔ¨Ånement  respectively. Hjelm
et al. [2016] adopted adaptive importance sampling to reÔ¨Åne the variational parameters  and the
generative and inference networks are trained separately with (cid:53)Œ∏L(q‚àó  Œ∏; x) and (cid:53)œÜDKL(q‚àó||qœÜ) 
respectively. Krishnan et al. [2018] used stochastic variational inference as a reÔ¨Ånement proce-
dure  and the generative and inference networks are also trained separately with (cid:53)Œ∏L(q‚àó  Œ∏; x) and
(cid:53)œÜL(qœÜ  Œ∏; x)  respectively. Kim et al. [2018] also used stochastic variational inference but proposed
the end-to-end training by allowing the learning signals to be backpropagated into the reÔ¨Ånement
procedure  and showed this end-to-end training outperformed the separate training.
This work presents a semi-amortized variational inference method for temporal data. In summary  we
parameterize the variational distribution by control input and transformed the approximate inference
into the SOC problem. Our method utilizes the structured inference network based on the principle
of optimality which has a similar structure to the inference network of DKS [Krishnan et al.  2017].
The adaptive path-integral control method  which can be viewed as adaptive importance sampling
in trajectory space [Kappen and Ruiz  2016]  is then adopted as a reÔ¨Ånement procedure. Ruiz and
Kappen [2017] also used the adaptive path integral approach to solve smoothing problems and showed
the path integral-based smoothing method could outperform the PF-based smoothing algorithms.
Finally  by observing all procedures of the path integral smoothing are differentiable  the inference
and generative networks are trained in the end-to-end manner. Note that APIAE is not the Ô¨Årst

6

algorithm that implements an optimal planning/control algorithm into a fully-differentiable network.
In [Tamar et al.  2016  Okada et al.  2017  Karkus et al.  2017]  similar iterative reÔ¨Ånement procedures
were built as differentiable networks to learn solutions of control problems in an end-to-end manner;
the fact that iterative methods were generally used to solve control problems can be a rationale for
utilizing reÔ¨Ånement to approximate inference for sequential data.
In addition  there is a non-probabilistic branch of representation learning of dynamical systems  e.g. 
[Watter et al.  2015  Banijamali et al.  2018  Jonschkowski and Brock  2015  Lesort et al.  2018].
They basically stack two consecutive observations to contain the temporal information and learn
the dynamical model based on a carefully designed loss function considering the stacked data as
one observation. As shown in Appendix D  however  when the observations are highly-noisy (or
even worse  when the system is unobservable with the stacked data)  stacking a small number of
observations prohibits the training data from containing enough temporal information for learning
rich generative models.
Lastly  there have been some recent works to utilize a low-dimensional latent model for motion
planning. Chen et al. [2016] exploited the idea of VAEs to embed dynamic movement primitives into
the latent space. In [Ha et al.  2018]  Gaussian process dynamical models [Wang et al.  2008] served
as a latent dynamical model and was utilized for planning in a similar way with this work. Though
the dynamics were not considered  Ichter et al. [2018]  Zhang et al. [2018] used the conditional VAEs
to learn a non-uniform sampling methodology of a sampling-based motion planning algorithm.

6 Experiment

In our experiments  we would like to show that the proposed method is a complementary technique to
the existing methods; the APIAE can play a role in constructing more expressive posterior distribution
by reÔ¨Åning the variational distribution from the existing approximate inference methods. To support
our statement  we built APIAEs upon the FIVO and IWAE frameworks and compared with the model
without adaptation procedures.
We set our APIAE parameters as L=8  R=4  and K=10 during experiments. Quantitative studies
about the effect of varying these parameters are discussed in the appendix. Feedback gain is only
used for the planning  since matrix inversion in (16) requires Cholesky decomposition which is often
numerically unstable during the training. We would refer the readers to the Appendix D and the
supplementary video for more experimental details and results.

6.1 Dynamic Pendulum

The Ô¨Årst experiment addresses the system identiÔ¨Åcation and planning of inverted pendulum with
the raw images. The pendulum dynamics is represented by the second order differential equation
for angle of the pendulum  œà  as ¬®œà = ‚àí9.8 sin(œà) ‚àí Àôœà. We simulated the pendulum dynamics by
injecting the disturbance from random initial states and then made sequences of 16√ó 16 sized images
corresponding to the pendulum state with the time interval  Œ¥t = 0.1. This set of sequence images
was training data of APIAE  i.e.  xk lied in 256-dimensional observation space. 3000 and 500 data
are used for training and test  respectively.
Fig. 1(a) shows the constructed 2-dimensional latent space; each point represents the posterior mean
of the observation data and it is shown that the angle and the angular velocity are well-encoded in
2-dimensional space. As shown in Fig. 1(b)  the learned dynamical model was able to successfully
reconstruct the noisy observations  predict and plan the future images. For the planning  the cost
functions were set to penalize the difference between the last image of the generated sequence and
the target image in Fig. 1(c) to encode planning problems for swing-up  -down  -left  and -right.

6.2 Human Motion Capture Data

The second experiment addresses a motion planning of a humanoid robot with 62-dimensional
conÔ¨Åguration space. We utilized human motion capture data from the Carnegie Mellon University
motion capture (CMU mocap) database for the learning; the training data was a set of (short)
locomotion  e.g.  for standing  walking  and turning. The 62-dimensional conÔ¨Ågurations consist
of angles of all joints  roll and pitch angles  vertical position of the root  yaw rate of the root 

7

(a)

(b)

(c)

Figure 1: Pendulum results. (a) The inferred latent states colored by angles (top) and angular
velocities (bottom) of the ground truth. (b) Resulting image sequences. From the top: images of
ground truth  prediction  and four plaining results for swing-up  -down  -left  and -right  respectively.
Except the Ô¨Årst row  the images before the red line (k ‚â§ 10) are reconstructed one. (c) The target
images for each task: CK = ||xtarget ‚àí xK||2.

and horizontal velocity of the root. The global (horizontal) position and heading orientation are
not encoded in the generative model (only velocities are encoded)  but they can be recovered by
integration when an observation sequence is given. The original data were written at 120 Hz  and we
down-sampled them to 20 Hz and cut them every 10 time steps  i.e.  Œ¥t = 0.05  K = 10. 1043 and
173 data are used for training and test  respectively. We utilized the DeepMind Control Suite [Tassa
et al.  2018] for parsing the data and visualizing the results.
Figs. 2(a-c) illustrate the posterior mean states of the training data colored by some physical quantities
of the ground truth; we can observe that (a) locomotion is basically embedded along the surface of
the cylinder  while (b) they were arranged in the order of the yaw rates along the major axis of the
cylinder and (c) motions with lower forward velocities were embedded into smaller radius cycles.
Also  Fig. 2(d) shows that APIAE successfully reconstructed the data. Compared to the pendulum
example  where the Wiener process in latent dynamics models disturbance into the system and the
prediction can be made simply by ignoring the disturbance  the framework in this example uses the
Wiener process to model the uncertainty in human‚Äôs decision  e.g.  whether to turn left or right  to
increase or decrease their speed  etc  similar to the modeling of the bounded rationality [Genewein
et al.  2015] or the maximum entropy IRL [Ziebart et al.  2008]; as shown in Fig. 2(e)  from the
very same initial pose  the framework predicts multiple future conÔ¨Ågurations for  e.g.  going straight 
turning left or right (the ratio between motions eventually matches that of the training dataset) and
these predictions play essential roles in the planning. We then formulated planning problems  where
the cost function penalized collision with an obstacle  large yaw rate  and distance from the goal.
Figs. 2(f-g) show that the proposed method successfully generated the natural and collision-free
motion toward the goal.

6.3 Quantitative Results

It is easily thought that powerful inference methods via resampling or reÔ¨Ånements make the bound
tighter  but achieving a tighter bound during learning does not directly imply a better model learn-
ing [Rainforth et al.  2018]. To investigate this  we have compared the lower bound  the reconstruction
and prediction abilities of the models learned by the proposed and baseline algorithms. The results
are reported in Table 1 (higher is better).4 Interestingly  we can observe that learning with both the
resampling and path-integral reÔ¨Ånements resulted in the best reconstruction ability as well as the
tightest bound  but the best prediction was achieved by the model learned only with the reÔ¨Ånements. It
implies that while powerful inference can lead to a tighter bound and a good reconstruction  a bias in
the gradients can prevent the resulting model from being accurate (note that the gradient components
from the resampling are generally ignored because it causes high variance of the gradient estimator
[Maddison et al.  2017  Le et al.  2018  Naesseth et al.  2018]). In the planning side  the prediction
power is crucial because the (learned) generative model needs to sample meaningful and diverse
conÔ¨Åguration sequences. We conclude that the resampling procedure would be better to utilize only

4Mocap prediction is omitted  because a proper measure for the prediction is unclear.

8

-10-50510-15-10-5051015-3-2-10123-10-50510-15-10-5051015-10-505109ùëò =1254050(a)

(b)

(c)

(d)

(e)

(f)

(g)

Figure 2: Mocap results. The learned latent space colored by (a) the gait phase  (b) yaw rate  and (c)
forward velocity of the ground truth. We set the phase as 0 when the left foot touch the ground and
as œÄ when the right foot touch the ground. (d) Reconstruction. (e) Prediction results from the same
initial poses. (f-g) Locomotion planning results.

for planning  not for learning  and this also would be the same in other application domains like
3-dimensional human motion tracking  where the prediction ability is more important.

Table 1: Comparison of the lower bound  reconstruction  and prediction. Each model was trained
with (i) APIAE with resampling (+r)  (ii) APIAE without resampling  (iii) FIVO  and (iv) IWAE. The
lower bounds are obtained for the training datasets and the reconstruction and prediction results are
made for the test datasets; the amounts of the test datasets were around 1/6 of the training datasets.

Pendulum (√ó106)
Lower-bound Reconstruction

Mocap (√ó105)

Prediction

Lower-bound Reconstruction

APIAE+r
APIAE
FIVO
IWAE

-9.866
-9.927
-9.890
-9.974

-1.647
-1.653
-1.650
-1.665

-1.985
-1.845
-1.978
-1.860

-6.665
-6.680
-6.687
-6.683

-1.158
-1.171
-1.167
-1.174

7 Conclusion

In this paper  a semi-amortized variational inference method for sequential data was proposed. We
parameterized a variational distribution by control input and transformed an approximate inference
into a SOC problem. The proposed framework utilized the structured inference network based on
the principle of optimality and adopted the adaptive path-integral control method as a reÔ¨Ånement
procedure. The experiments showed that the reÔ¨Ånement procedure helped the learning algorithm
achieve tighter lower bound. Also  it is shown that the valid dynamical model can be identiÔ¨Åed from
sequential raw data and utilized to plan the future conÔ¨Ågurations.

9

-10100z310z1-100z20-10100123456-10100z310z1-100z20-1010-2-1012-10100z310z1-100z20-10100.20.40.60.81Acknowledgments

This work was supported by the Agency for Defense Development under contract UD150047JD.

References
Mart√≠n Abadi  Paul Barham  Jianmin Chen  Zhifeng Chen  Andy Davis  Jeffrey Dean  Matthieu Devin 
Sanjay Ghemawat  Geoffrey Irving  Michael Isard  et al. TensorÔ¨Çow: A system for large-scale
machine learning. In OSDI  volume 16  pages 265‚Äì283  2016.

Ershad Banijamali  Rui Shu  Mohammad Ghavamzadeh  Hung Bui  and Ali Ghodsi. Robust locally-
linear controllable embedding. International Conference on ArtiÔ¨Åcial Intelligence and Statistics
(AISTATS)  2018.

Richard Bellman. Dynamic programming. Courier Corporation  2013.

Yuri Burda  Roger Grosse  and Ruslan Salakhutdinov. Importance weighted autoencoders. Interna-

tional Conference on Learning Representations (ICLR)  2016.

Nutan Chen  Maximilian Karl  and Patrick van der Smagt. Dynamic movement primitives in latent
space of time-dependent variational autoencoders. In International Conference on Humanoid
Robots (Humanoids)  pages 629‚Äì636. IEEE  2016.

Chris Cremer  Quaid Morris  and David Duvenaud. Reinterpreting importance-weighted autoencoders.

ICLR Workshop  2017.

Chris Cremer  Xuechen Li  and David Duvenaud. Inference suboptimality in variational autoencoders.

arXiv preprint arXiv:1801.03558  2018.

Marco Fraccaro  Simon Kamronn  Ulrich Paquet  and Ole Winther. A disentangled recognition
and nonlinear dynamics model for unsupervised learning. In Advances in Neural Information
Processing Systems (NIPS)  pages 3604‚Äì3613  2017.

Crispin W Gardiner et al. Handbook of stochastic methods  volume 4. Springer Berlin  1985.

Tim Genewein  Felix Leibfried  Jordi Grau-Moya  and Daniel Alexander Braun. Bounded rationality 
abstraction  and hierarchical decision-making: An information-theoretic optimality principle.
Frontiers in Robotics and AI  2:27  2015.

Jung-Su Ha  Hyeok-Joo Chae  and Han-Lim Choi. Approximate inference-based motion planning
by learning and exploiting low-dimensional latent variable models. In Robotics and Automation
Letters (RA-L/IROS‚Äô18). IEEE  2018.

Devon Hjelm  Ruslan R Salakhutdinov  Kyunghyun Cho  Nebojsa Jojic  Vince Calhoun  and Junyoung
Chung. Iterative reÔ¨Ånement of the approximate posterior for directed belief networks. In Advances
in Neural Information Processing Systems (NIPS)  pages 4691‚Äì4699  2016.

Brian Ichter  James Harrison  and Marco Pavone. Learning sampling distributions for robot motion

planning. International Conference on Robotics and Automation (ICRA)  2018.

Matthew Johnson  David K Duvenaud  Alex Wiltschko  Ryan P Adams  and Sandeep R Datta.
Composing graphical models with neural networks for structured representations and fast inference.
In Advances in neural information processing systems (NIPS)  pages 2946‚Äì2954  2016.

Rico Jonschkowski and Oliver Brock. Learning state representations with robotic priors. Autonomous

Robots  39(3):407‚Äì428  2015.

Hilbert Johan Kappen and Hans Christian Ruiz. Adaptive importance sampling for control and

inference. Journal of Statistical Physics  162(5):1244‚Äì1266  2016.

Peter Karkus  David Hsu  and Wee Sun Lee. Qmdp-net: Deep learning for planning under partial
observability. In Advances in Neural Information Processing Systems (NIPS)  pages 4697‚Äì4707 
2017.

10

Maximilian Karl  Maximilian Soelch  Justin Bayer  and Patrick van der Smagt. Deep variational
bayes Ô¨Ålters: Unsupervised learning of state space models from raw data. International Conference
on Learning Representations (ICLR)  2017.

Yoon Kim  Sam Wiseman  Andrew C Miller  David Sontag  and Alexander M Rush. Semi-amortized

variational autoencoders. arXiv preprint arXiv:1802.02550  2018.

Diederik P Kingma and Max Welling. Auto-encoding variational bayes. International Conference on

Learning Representations (ICLR)  2014.

Rahul G Krishnan  Uri Shalit  and David Sontag. Structured inference networks for nonlinear state

space models. In AAAI  pages 2101‚Äì2109  2017.

Rahul G Krishnan  Dawen Liang  and Matthew Hoffman. On the challenges of learning with inference
networks on sparse  high-dimensional data. International Conference on ArtiÔ¨Åcial Intelligence and
Statistics (AISTATS)  2018.

Tuan Anh Le  Maximilian Igl  Tom Jin  Tom Rainforth  and Frank Wood. Auto-encoding sequential

monte carlo. International Conference on Learning Representations (ICLR)  2018.

Timoth√©e Lesort  Natalia D√≠az-Rodr√≠guez  Jean-Fran√ßois Goudou  and David Filliat. State representa-

tion learning for control: An overview. arXiv preprint arXiv:1802.04181  2018.

Chris J Maddison  Dieterich Lawson  George Tucker  Nicolas Heess  Mohammad Norouzi  Andriy
Mnih  Arnaud Doucet  and Yee Whye Teh. Filtering variational objectives. In Advances in neural
information processing systems (NIPS)  2017.

Andriy Mnih and Danilo Rezende. Variational inference for monte carlo objectives. In International

Conference on Machine Learning (ICML)  pages 2188‚Äì2196  2016.

Christian A Naesseth  Scott W Linderman  Rajesh Ranganath  and David M Blei. Variational
In International Conference on ArtiÔ¨Åcial Intelligence and Statistics

sequential monte carlo.
(AISTATS)  2018.

Masashi Okada  Luca Rigazio  and Takenobu Aoshima. Path integral networks: End-to-end differen-

tiable optimal control. arXiv preprint arXiv:1706.09597  2017.

Tom Rainforth  Adam R Kosiorek  Tuan Anh Le  Chris J Maddison  Maximilian Igl  Frank Wood  and
Yee Whye Teh. Tighter variational bounds are not necessarily better. In International Conference
on Machine Learning (ICML)  2018.

Danilo Jimenez Rezende  Shakir Mohamed  and Daan Wierstra. Stochastic backpropagation and
In International Conference on Machine

approximate inference in deep generative models.
Learning (ICML)  pages 1278‚Äì1286  2014.

Hans-Christian Ruiz and Hilbert J Kappen. Particle smoothing for hidden diffusion processes:
Adaptive path integral smoother. IEEE Transactions on Signal Processing  65(12):3191‚Äì3203 
2017.

Aviv Tamar  Yi Wu  Garrett Thomas  Sergey Levine  and Pieter Abbeel. Value iteration networks. In

Advances in Neural Information Processing Systems (NIPS)  pages 2154‚Äì2162  2016.

Yuval Tassa  Yotam Doron  Alistair Muldal  Tom Erez  Yazhe Li  Diego de Las Casas  David Budden 
Abbas Abdolmaleki  Josh Merel  Andrew Lefrancq  et al. DeepMind Control Suite. arXiv preprint
arXiv:1801.00690  2018.

Sep Thijssen and HJ Kappen. Path integral control and state-dependent feedback. Physical Review E 

91(3):032104  2015.

Emanuel Todorov. General duality between optimal control and estimation. In IEEE Conference on

Decision and Control  pages 4286‚Äì4292. IEEE  2008.

Emanuel Todorov. EfÔ¨Åcient computation of optimal actions. Proceedings of the national academy of

sciences  106(28):11478‚Äì11483  2009.

11

Paul Vernaza and Daniel D Lee. Learning and exploiting low-dimensional structure for efÔ¨Åcient
holonomic motion planning in high-dimensional spaces. The International Journal of Robotics
Research  31(14):1739‚Äì1760  2012.

Jack M Wang  David J Fleet  and Aaron Hertzmann. Gaussian process dynamical models for human
motion. IEEE transactions on pattern analysis and machine intelligence  30(2):283‚Äì298  2008.

Manuel Watter  Jost Springenberg  Joschka Boedecker  and Martin Riedmiller. Embed to control:
In Advances in neural

A locally linear latent dynamics model for control from raw images.
information processing systems (NIPS)  pages 2746‚Äì2754  2015.

Clark Zhang  Jinwook Huh  and Daniel D Lee. Learning implicit sampling distributions for motion

planning. arXiv preprint arXiv:1806.01968  2018.

Brian D Ziebart  Andrew L Maas  J Andrew Bagnell  and Anind K Dey. Maximum entropy inverse

reinforcement learning. In AAAI  volume 8  pages 1433‚Äì1438. Chicago  IL  USA  2008.

12

,Jung-Su Ha
Young-Jin Park
Hyeok-Joo Chae
Soon-Seo Park
Han-Lim Choi