2018,Adaptive Path-Integral Autoencoders: Representation Learning and Planning for Dynamical Systems,We present a representation learning algorithm that learns a low-dimensional latent dynamical system from high-dimensional sequential raw data  e.g.  video. The framework builds upon recent advances in amortized inference methods that use both an inference network and a refinement procedure to output samples from a variational distribution given an observation sequence  and takes advantage of the duality between control and inference to approximately solve the intractable inference problem using the path integral control approach. The learned dynamical model can be used to predict and plan the future states; we also present the efficient planning method that exploits the learned low-dimensional latent dynamics. Numerical experiments show that the proposed path-integral control based variational inference method leads to tighter lower bounds in statistical model learning of sequential data. Supplementary video: https://youtu.be/xCp35crUoLQ,Adaptive Path-Integral Autoencoder: Representation

Learning and Planning for Dynamical Systems

Jung-Su Ha  Young-Jin Park  Hyeok-Joo Chae  Soon-Seo Park  and Han-Lim Choi

Department of Aerospace Engineering & KI for Robotics  KAIST

{{jsha  yjpark  hjchae  sspark}@lics.  hanlimc@}kaist.ac.kr

Daejeon 305-701  Republic of Korea

Abstract

We present a representation learning algorithm that learns a low-dimensional latent
dynamical system from high-dimensional sequential raw data  e.g.  video. The
framework builds upon recent advances in amortized inference methods that use
both an inference network and a reﬁnement procedure to output samples from
a variational distribution given an observation sequence  and takes advantage of
the duality between control and inference to approximately solve the intractable
inference problem using the path integral control approach. The learned dynamical
model can be used to predict and plan the future states; we also present the efﬁ-
cient planning method that exploits the learned low-dimensional latent dynamics.
Numerical experiments show that the proposed path-integral control based varia-
tional inference method leads to tighter lower bounds in statistical model learning
of sequential data. The supplementary video1 and the implementation code2 are
available online.

1

Introduction

Unsupervised learning of the underlying dynamics of sequential high-dimensional sensory inputs is
the essence of intelligence  because the agent should utilize the learned dynamical model to predict
and plan the future state. Such learning problems are formulated as latent or generative model
learning assuming that observations were emerged from the low-dimensional latent states  which
includes an intractable posterior inference of latent states for given input data. In the amortized
variational inference framework  an inference network is introduced to output variational parameters
of an approximate posterior distribution. This allows for a fast approximate inference procedure and
efﬁcient end-to-end training of the generative and inference networks when the learning signals from
a loss function are back-propagated into the inference network with reparameterization trick [Kingma
and Welling  2014  Rezende et al.  2014]. The learning procedure is based on optimization of a
surrogate loss  a lower-bound of data likelihood  which results in two source of sub-optimality:
an approximation gap and an amortization gap [Krishnan et al.  2018  Cremer et al.  2018]; the
former comes from the sub-optimality of variational approximation (the gap between true posterior
and optimal variational distribution) and the latter is caused by the amortized approximation (the
gap between the optimal variational distribution and the distribution from the inference network).
Recently  several works  e.g.  [Hjelm et al.  2016  Krishnan et al.  2018  Kim et al.  2018]  combined
iterative reﬁnement procedures with the amortized inference  where the output distribution of the
inference network is used as a warm-start point of reﬁnement. This technique is referred to as the
semi-amortized inference and  since reﬁned variational distributions do not rely only on the inference
network  the sub-optimality from amortization gap can be mitigated.

1https://youtu.be/xCp35crUoLQ
2https://github.com/yjparkLiCS/18-NeurIPS-APIAE

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

For sequential data modeling  a generative model should be considered as a dynamical system
and a more sophisticated (approximate) inference method is required. With the assumption that
the underlying dynamics has the Markov property  a state space model can be introduced and it
allows the inference network to be structured so as to mimic the factorized form of a true posterior
distribution [Krishnan et al.  2017  Karl et al.  2017  Fraccaro et al.  2017]. The efﬁcient end-to-end
training with the amortized inference is also possible here  where the inference network should output
the variational distribution of latent state trajectories for given observation sequences. Even when
the inference network is structured  the amortization gap increases inevitably because the inference
should be performed in the trajectory space.
In this work  we present a semi-amortized variational inference method operated in the trajectory
space. For a generative model given by a state space model  an initial state distribution and control
inputs serve as parameters of variational distributions; the inference network is trained to output these
variational parameters such that the corresponding latent trajectory well-describes the observation
sequence. In this certain formulation  the divergence between the prior and the variational distribution
is naturally derived from stochastic calculus and then the inference problem can be converted into a
stochastic optimal control (SOC) problem  i.e.  so-called control-inference duality [Todorov  2008 
Ruiz and Kappen  2017]. In the SOC view  what the inference network does is to approximate the
optimal control policy  which is hardly thought to be well-done when we observe that SOC problems
are hard to solve at once  so iterative methods are generally used to solve the problems [Todorov 
2008  Tamar et al.  2016  Okada et al.  2017]. Thus  we adopt the adaptive path-integral control
method to iteratively reﬁne the variational parameters. We show that because samples from the reﬁned
variational distribution build tighter lower-bound and all the reﬁnement procedures are differentiable 
efﬁcient end-to-end training is possible. Moreover  because the proposed framework is based on the
SOC method  the same structure can be utilized to plan the future observation sequence  where the
learned low-dimensional stochastic dynamics is used to explore the high-dimensional observation
space efﬁciently.

2 Background

2.1 Statistical Modeling of Sequential Observations
Suppose that we have a set of observation sequences {x(i)
1:K ≡ {xk;∀k =
1  ...  K}(i) are i.i.d. sequences of observation that lie on (possibly high-dimensional) data space 
X ⊂ Rdx. The problem of interest is to build a probabilistic model that explains the given observations
well. If a model is parameterized with θ  the problem is formulated as a maximum likelihood
estimation (MLE) problem:

1:K}i=1 ... I  where x(i)

θ∗ = argmax

log pθ(x(i)

1:K).

(1)

In this work  the observations are assumed to be emerged from a latent dynamical system  where a
latent state trajectory  z[0 T ] ≡ {z(t); ∀t ∈ [0  T ]}  lies on a (possibly low-dimensional) latent space 
Z ⊂ Rdz:

pθ(x1:K|z[0 T ])dpθ(z[0 T ]) 

pθ(x1:K) =

(2)
where pθ(x1:K|z[0 T ]) and pθ(z[0 T ]) are called a conditional likelihood and a prior distribution 
respectively3 . In particular  we consider the state space model where latent states are governed by
a continuous-time stochastic differential equation (SDE)  i.e.  the prior pθ(z[0 T ]) is a probability
measure of a following system:

(3)
where w(t) is a du-dimensional Wiener process. Additionally  a conditional likelihood of sequential
observations is assumed to be factorized along the time axis:

dz(t) = f (z(t))dt + σ(z(t))dw(t)  z(0) ∼ p0(·) 

(cid:88)

i

θ

(cid:90)

K(cid:89)

pθ(xk|z(tk)) 
where {tk} is a sequence of discrete time points with t1 = 0  tK = T .

pθ(x1:K|z[0 T ]) =

k=1

(4)

3Because each observation trajectory can be considered independently  we leave trajectory index  i  out and

restrict our discussion to one trajectory for the sake of notational simplicity.

2

2.2 Amortized Variational Inference and Multi-Sample Objectives

(cid:90)

(cid:20)

(cid:21)

pθ(x|z)pθ(z)

The objective function (1) cannot be optimized directly because it contains the intractable integration.
To circumvent the intractable inference  a variational distribution q(·) is introduced and then a surro-
gate loss function L(q  θ; x)  which is called the evidence lower bound (ELBO)  can be considered
alternatively:

≡ L(q  θ; x) 

pθ(x|z)pθ(z)dz ≥ Eq(z)

log

q(z)

log pθ(x) = log

(5)
where q(·) can be any probabilistic distribution over Z of which support includes that of pθ(·). The
gap between the log-likelihood and the ELBO is the Kullback–Leibler (KL) divergence between q(z)
and the posterior pθ(z|x):

log pθ(x) − L(q  θ; x) = DKL(q(z)||pθ(z|x)).

(6)
In particular  the amortized variational inference approach introduces a conditional variational
distribution  z ∼ qφ(·|x)  to approximate the intractable posterior distribution. The variational
distribution qφ(·|x)  which is referred to as the inference network  is parameterized by φ  so θ
and φ can be simultaneously updated with (cid:53)(θ φ)L(qφ  θ; x) using the stochastic gradient ascent.
Variational autoencoders (VAEs) [Kingma and Welling  2014  Rezende et al.  2014] make qφ(·|x) a
reparameterizable distribution  where z = gφ(x  ) is a differentiable deterministic function of an
observation x and  ∼ d(·) sampled from a known base distribution d(·). Then  the gradient can
be estimated as: (cid:53)(θ φ)L(qφ  θ; x) = Ed()
  which generally yields a low
variance estimator.
A tighter lower bound is achieved by using multiple samples  z1:L  independently sampled from qφ:

(cid:104)(cid:53)(θ φ) log pθ(x gφ(x ))
(cid:34)

qφ(gφ(x ))

(cid:35)

(cid:105)

log

(7)
It is proven that  as L increases  the bounds get tighter  i.e.  log pθ(x) ≥ ··· ≥ LL+1 ≥ LL ≥ ···  
and the gap eventually vanishes [Burda et al.  2016  Cremer et al.  2017].This multi-sample objec-
tive (7) is in the class of Monte Carlo objectives (MCO) in the sense that it utilizes independent sam-
qφ(zl|x)   zl ∼
ples to estimate the marginal likelihood [Mnih and Rezende  2016]  ˆpθ(x) = 1
L
qφ(·|x). Deﬁning wθ φ(x  zl) ≡ pθ(x zl)

(cid:80)
i wθ φ(x zi)  the gradient of (7) is given by:

qφ(zl|x) and ˜wl ≡ wθ φ(x zl)

pθ(x zl)

l=1

l=1

.

LL ≡ Ez1:L∼qφ(·|x)

L(cid:88)

1
L

pθ(x  zl)
qφ(zl|x)

(cid:34) L(cid:88)

(cid:80)L
(cid:35)

∇(θ φ)LL = E1:L∼d(·)

˜wl∇(θ φ) log wθ φ(x  gφ(x  l))

.

(8)

l=1

Since the parameter update is averaged over multiple samples with the weights ˜wl  the above
procedure is referred to as importance weighted autoencoders (IWAEs) [Burda et al.  2016]. The
performance of IWAE’s training crucially depends on the variance of the importance weights ˜w (or
equivalently  on the effective sample size)  which can be reduced by (i) increasing the number of
samples and (ii) decreasing the gap between the proposal and the true posterior distribution; when the
proposal qφ(·|x) is equal to the true posterior pθ(·|x)  the variance is reduced to 0  i.e.  ˜wl = 1/L.

2.3 Semi-Amortized Variational Inference with Iterative Reﬁnement

As mentioned previously  the performance of generative model learning depends on the gap between
the variational and the posterior distributions. Thus  the amortized inference has two sources of
this gap: the approximation and amortization gaps [Krishnan et al.  2018  Cremer et al.  2018].
The approximation gap comes up by using the variational distribution to approximate the posterior
distribution  which is given by the KL-divergence between the posterior distribution and the optimal
variational distribution. The amortization gap is caused by the limit of the expressive power of
inference networks  where the variational parameters are not individually optimized for each observa-
tion but amortized over entire observations. To address the issue of the amortization gap  a hybrid
approach can be considered; for each observation  the variational distribution is reﬁned individually
from the output of the inference network. Compared to the amortized variational inference  this
hybrid approach  coined semi-amortized variational inference  allows for utilizing better variational
parameters in model learning.

3

3 Path Integral Adaptation for Variational Inference

3.1 Controlled SDE as variational distribution and structured inference network

When handling sequential observations  the variational distribution family should be carefully chosen
so as to efﬁciently handle increasing dimensions of variables along the time-axis. In this work 
the variational proposal distribution is given by the trajectory distribution of a controlled stochastic
dynamical system  where the controls  u ∈ Rdu  and parameters of an initial state distribution  q0 
serve as variational parameters  i.e.  the proposal qu(z[0 T ]) is a probability measure of a following
system:

dz(t) = f (z(t))dt + σ(z(t))(u(t)dt + dw(t))  z(0) ∼ q0(·).

(9)
By applying Girsanov’s theorem in Appendix A that provides the likelihood ratio between p(z[0 T ])
and qu(z[0 T ])  the ELBO is written as:

(cid:90) T

(cid:90) T

(cid:35)

(cid:34)

L = Equ(z[0 T ])

log pθ(x1:K|z[0 T ]) + log

p0(z(0))
q0(z(0))

− 1
2

||u(t)||2dt −

0

0

u(t)T dw(t)

.

(10)
0 (or equivalently  the best

Equ(z[0 T ])

(cid:34)
q0(z(0)) −(cid:80)K

Then  the problem of ﬁnding the optimal variational parameters u∗ and q∗
approximate posterior) can be formulated as a SOC problem:

(cid:90) T

(cid:90) T

(cid:35)

u∗  q∗

0 = argmin

u q0

V (z[0 T ]) +

1
2

||u(t)||2dt +

0

0

u(t)T dw(t)

 

(SOC)

k   Kk}k=1 ... K−1 as u(t  z(t)) = uf f

where V (z[0 T ]) ≡ − log p0(z(0))
k=1 log pθ(xk|z(tk)) serves as a state cost of the SOC problem.
Suppose that the control policy is discretized along the time-axis with the control parameters
{uf f
k − Kkz(t)  ∀t ∈ [tk  tk+1)  and the initial distribu-
tion is modeled to be the Gaussian distribution  q0(·) = N (·; ˆµ0  ˆΣ0). Once the inference problem
is converted into the SOC problem  the principle of optimality [Bellman  2013] provides the so-
phisticated and efﬁcient structure of inference networks. Note that  by the principle of optimality 
the optimal initial state distribution depends on the cost for all time horizon [0  T ] but the optimal
control policy at t only relies on the future cost in (t  T ]. Such a structure can be implemented using
a backward recurrent neural network (RNN) to output the approximate optimal control policy; while
the hidden states of the backward RNN compress the information of a given observation sequence
backward in time  the hidden state at each time step  k = K − 1  ...  2  outputs the control policy
k   Kk}. Finally  the ﬁrst hidden state additionally outputs the initial distribution
parameters  {uf f
parameters  {ˆµ0  ˆΣ0  uf f
1   K1}. For the detailed descriptions and illustrations  see Fig. 3(a) and
Algorithm 2 in Appendix C.

3.2 Adaptive Path-Integral Autoencoder

(SOC) is in a class of linearly-solvable optimal control problems [Todorov  2009] of which the
objective function can be written as a KL-divergence form:

(cid:0)qu(z[0 T ])||p∗(z[0 T ])(cid:1) − log ξ 

J = DKL

(11)
where p∗  represented as dp∗(z[0 T ]) = exp(−V (z[0 T ]))dpθ(z[0 T ])/ξ  is a probability measure in-

duced by optimally-controlled trajectories and ξ ≡(cid:82) exp(−V (z[0 T ]))dpθ(z[0 T ]) is a normalization

constant (see Appendix A for details). By applying Girsanov’s theorem again  the optimal trajectory
distribution is expressed as:

dp∗(z[0 T ]) ∝ dqu(z[0 T ]) exp(cid:0)−Su(z[0 T ])(cid:1)  

(cid:90) T

u(t)T dw(t).

(12)

(13)

Su(z[0 T ]) = V (z[0 T ]) +

1
2

||u(t)||2dt +

0

0

(cid:90) T

This implies that the optimal trajectory distribution can be approximated by sampling a set of
[0 T ] ∼ qu(·)  and assigning their
trajectories according to the controlled dynamics with u(t)  i.e. zl

4

(cid:88)L
(cid:88)L

(cid:88)L

(cid:80)L
exp(−Su(zl
i=1 exp(−Su(zi

[0 T ]))

[0 T ]))

  ∀l ∈ {1  ...  L}. Similar to the MCO’s case  the
importance weights as ˜wl =
variance of importance weights decreases as the control input u(·) gets closer to the true optimal
control input u∗(·) and it reduces to 0 when u(t) = u∗(t  z(t)) [Thijssen and Kappen  2015].
The path-Integral control is a sampling-based SOC method  which approximates the optimal trajectory
distribution  ˆp∗  with weighted sample trajectories using (12)–(13) and updates control parameters
based on moment matching of qu to ˆp∗. Suppose that ˆp∗ is approximated with sample trajectories and
their weights  {zl
[0 T ]  ˜wl}l=1 ... L  as above and let uf f (t) and K(t) represent feedforward control
and feedback gain  respectively. This work considers a standardized linear feedback controller to
regularize the ﬁrst and second moments of trajectory distributions  where a control input has a form
as:

u(t) = uf f (t) + K(t)Σ−1/2(t)(z(t) − µ(t)) 

(14)
l=1 ˜wl(zl(t) − µ(t))(zl(t) − µ(t))T are the mean and
covariance of the state w.r.t. ˆp∗  respectively. Suppose a new set of trajectories and their weights is
obtained by a (previous) control policy u(t) = ¯uf f (t) + ¯K(t) ¯Σ−1/2(t)(z(t) − ¯µ(t)). Then  the path
integral control theorem in Appendix B gives the update rules as:
uf f (t)dt = ¯uf f (t)dt + ¯K(t) ¯Σ−1/2(t)(µ(t) − ¯µ(t))dt + η
K(t)dt = ¯K(t) ¯Σ−1/2(t)Σ1/2(t)dt + η

(16)
with the adaptation rate η. The initial state distribution also can be updated into q0(·) = N (·; ˆµ0  ˆΣ0):

Σ−1/2(t)(zl(t) − µ(t))

l=1 ˜wlzl(t) and Σ(t) =(cid:80)L

where µ(t) =(cid:80)L

(cid:88)L

˜wldwl(t) 

˜wldwl(t)

(cid:17)T

(cid:16)

(15)

l=1

l=1

 

l=1

l=1

1
L

ˆµ0 =

ˆLL = log

(cid:88)L

˜wlzl(0)  ˆΣ0 =

[0 T ]))  ∇θ φ ˆLL = −(cid:88)L

˜wl(zl(0) − ˆµ0)(zl(0) − ˆµ0)T .
(17)
1:K−1  K1:K−1}  given by the inference network
Starting from the variational parameters  {ˆµ0  ˆΣ0  uf f
and ¯µ(t) = 0  ¯Σ(t) = I  the update rules in (15)-(17) gradually reﬁne the parameters of qu in order
for the resulting trajectory distribution to be close to the posterior distribution. After R adaptations 
the MCO and its gradient are estimated by:
exp(−Su(zl

(18)
where θ and φ denote the parameters of the generative model  i.e.  f (z)  σ(z)  p0(z) and p(x|z)  and
the inference network  i.e.  the backward RNN  respectively. Because all procedures in the path
integral adaptation and MCO construction are differentiable  they can be implemented by a fully
differentiable network with R recurrences  which we named Adaptive Path Integral Autoencoder
(APIAE); see also Fig. 3(b) in the Appendix C.
Note that the inference  reconstruction  and gradient backpropagation of APIAE can operate indepen-
dently for each of L samples. Consequently  the computational cost grows linearly with the number
of samples  L  and the number of adaptations  R. As implemented in IWAE [Burda et al.  2016]  we
replicated each observation data L times and the whole operations were parallelized with GPU. We
implemented APIAE with Tensorﬂow [Abadi et al.  2016]; the pseudo code and algorithmic details
of APIAE are given in the Appendix C.

˜wl∇θ φSu(zl

[0 T ]) 

l=1

l=1

4 High-dimensional Motion Planning with Learned Latent Model

High-dimensional motion planning is a challenging problem because of the curse of dimensionality:
The size of the conﬁguration space exponentially increases with the number of dimensions. However 
like in the latent variable model learning  it might be a reasonable assumption that conﬁgurations
a planning algorithm really needs to consider form some sort of low-dimensional manifold in the
conﬁguration space [Vernaza and Lee  2012]  and the learned generative model provides stochastic
dynamics in that manifold. Once this low-dimensional representation is obtained  any motion planning
algorithm can solve high-dimensional planning problem very efﬁciently by utilizing it to restrict the
search space.
More formally  suppose that the initial conﬁguration  x1  and corresponding latent state  z(0)  are
given and the cost function  Ck(xk)  encodes given task speciﬁcations of a planning problem  e.g. 

5

desirability/undesirability of certain conﬁgurations  a penalty for obstacle collision  etc. Then  the
planning problem can be converted into the problem of ﬁnding the optimal trajectory distribution  qu 
that minimizes the following objective function:

(cid:35)

(cid:34) K(cid:88)

k=1

J(qu) = Ex1:K∼pθ(·|z[0 T ]) z[0 T ]∼qu(·)

Ck(xk) + DKL(qu(z[0 T ])||pθ(z[0 T ]))

.

(19)

That is  we want to ﬁnd parameters  u  of the trajectory distribution which not only is likely
to generate sample conﬁguration sequences achieving the lower planning cost but also does
not deviate a lot from the (learned) prior  pθ(z[0 T ]). The solution can be found using the
aforementioned adaptive path integral control method  where its state cost function is set as:
V (z[0 T ]) ≡ Epθ(x1:K|z[0 T ])
and the initial state distribution is not updated in the
adaptation process. After the adaptations with this state cost function  the resulting plan can simply be
sampled from the generative model  e.g.  x1:K ∼ pθ(·|µ[0 T ]). Note that the time interval tk − tk−1
and the trajectory length K can differ in the training and planning phases because continuous-time
dynamics is dealt with.

(cid:104)(cid:80)K

k=1 Ck(xk)

(cid:105)

5 Related Work
To address the complexity raised from temporal structures of data  several approaches that build a
sophisticated approximate inference model have been proposed. For example  Karl et al. [2017] used
the locally linear latent dynamics by introducing transition parameters  where an inference model
infers transition parameters rather than latent states from the local transition. Johnson et al. [2016]
combined a structured graphical model in latent space with a deep generative network  where an
inference network produces local evidence potentials for the message passing algorithms. Fraccaro
et al. [2017] constructed two layers of latent models  where linear-Gaussian dynamical systems
governed two latent layers and the observation at each time step was related to the middle layer
independently; the inference model in this framework consists of independent VAE’s inference
networks at each time-step and the Kalman smoothing algorithm along the time axis. Finally  deep
Kalman smoother (DKS) in [Krishnan et al.  2017] parameterized the dynamical system by a deep
neural network and built an inference network as it has the same structure with the factorized posterior
distribution. The idea of MCOs was also used in the temporal setting. Maddison et al. [2017]  Le
et al. [2018]  Naesseth et al. [2018] adapted the particle ﬁlter (PF) algorithm as their inference models
and utilized a PF’s estimator of the marginal likelihood as an objective function of training which
Maddison et al. [2017] named the ﬁltering variational objectives (FIVOs).
These approaches can be viewed as attempts to reduce the approximation gap; by building the infer-
ence model in sophisticated ways that exploit underlying structure of data  the resulting variational
family could ﬂexibly approximate the posterior distribution. To overcome the amortization gap caused
by inference networks  the semi-amortized method utilizes an iterative reﬁnement procedure for
improving variational distribution. Let qφ and q∗ be the variational distributions from the inference
network and from the reﬁnement procedure  i.e.  before and after the reﬁnement  respectively. Hjelm
et al. [2016] adopted adaptive importance sampling to reﬁne the variational parameters  and the
generative and inference networks are trained separately with (cid:53)θL(q∗  θ; x) and (cid:53)φDKL(q∗||qφ) 
respectively. Krishnan et al. [2018] used stochastic variational inference as a reﬁnement proce-
dure  and the generative and inference networks are also trained separately with (cid:53)θL(q∗  θ; x) and
(cid:53)φL(qφ  θ; x)  respectively. Kim et al. [2018] also used stochastic variational inference but proposed
the end-to-end training by allowing the learning signals to be backpropagated into the reﬁnement
procedure  and showed this end-to-end training outperformed the separate training.
This work presents a semi-amortized variational inference method for temporal data. In summary  we
parameterize the variational distribution by control input and transformed the approximate inference
into the SOC problem. Our method utilizes the structured inference network based on the principle
of optimality which has a similar structure to the inference network of DKS [Krishnan et al.  2017].
The adaptive path-integral control method  which can be viewed as adaptive importance sampling
in trajectory space [Kappen and Ruiz  2016]  is then adopted as a reﬁnement procedure. Ruiz and
Kappen [2017] also used the adaptive path integral approach to solve smoothing problems and showed
the path integral-based smoothing method could outperform the PF-based smoothing algorithms.
Finally  by observing all procedures of the path integral smoothing are differentiable  the inference
and generative networks are trained in the end-to-end manner. Note that APIAE is not the ﬁrst

6

algorithm that implements an optimal planning/control algorithm into a fully-differentiable network.
In [Tamar et al.  2016  Okada et al.  2017  Karkus et al.  2017]  similar iterative reﬁnement procedures
were built as differentiable networks to learn solutions of control problems in an end-to-end manner;
the fact that iterative methods were generally used to solve control problems can be a rationale for
utilizing reﬁnement to approximate inference for sequential data.
In addition  there is a non-probabilistic branch of representation learning of dynamical systems  e.g. 
[Watter et al.  2015  Banijamali et al.  2018  Jonschkowski and Brock  2015  Lesort et al.  2018].
They basically stack two consecutive observations to contain the temporal information and learn
the dynamical model based on a carefully designed loss function considering the stacked data as
one observation. As shown in Appendix D  however  when the observations are highly-noisy (or
even worse  when the system is unobservable with the stacked data)  stacking a small number of
observations prohibits the training data from containing enough temporal information for learning
rich generative models.
Lastly  there have been some recent works to utilize a low-dimensional latent model for motion
planning. Chen et al. [2016] exploited the idea of VAEs to embed dynamic movement primitives into
the latent space. In [Ha et al.  2018]  Gaussian process dynamical models [Wang et al.  2008] served
as a latent dynamical model and was utilized for planning in a similar way with this work. Though
the dynamics were not considered  Ichter et al. [2018]  Zhang et al. [2018] used the conditional VAEs
to learn a non-uniform sampling methodology of a sampling-based motion planning algorithm.

6 Experiment

In our experiments  we would like to show that the proposed method is a complementary technique to
the existing methods; the APIAE can play a role in constructing more expressive posterior distribution
by reﬁning the variational distribution from the existing approximate inference methods. To support
our statement  we built APIAEs upon the FIVO and IWAE frameworks and compared with the model
without adaptation procedures.
We set our APIAE parameters as L=8  R=4  and K=10 during experiments. Quantitative studies
about the effect of varying these parameters are discussed in the appendix. Feedback gain is only
used for the planning  since matrix inversion in (16) requires Cholesky decomposition which is often
numerically unstable during the training. We would refer the readers to the Appendix D and the
supplementary video for more experimental details and results.

6.1 Dynamic Pendulum

The ﬁrst experiment addresses the system identiﬁcation and planning of inverted pendulum with
the raw images. The pendulum dynamics is represented by the second order differential equation
for angle of the pendulum  ψ  as ¨ψ = −9.8 sin(ψ) − ˙ψ. We simulated the pendulum dynamics by
injecting the disturbance from random initial states and then made sequences of 16× 16 sized images
corresponding to the pendulum state with the time interval  δt = 0.1. This set of sequence images
was training data of APIAE  i.e.  xk lied in 256-dimensional observation space. 3000 and 500 data
are used for training and test  respectively.
Fig. 1(a) shows the constructed 2-dimensional latent space; each point represents the posterior mean
of the observation data and it is shown that the angle and the angular velocity are well-encoded in
2-dimensional space. As shown in Fig. 1(b)  the learned dynamical model was able to successfully
reconstruct the noisy observations  predict and plan the future images. For the planning  the cost
functions were set to penalize the difference between the last image of the generated sequence and
the target image in Fig. 1(c) to encode planning problems for swing-up  -down  -left  and -right.

6.2 Human Motion Capture Data

The second experiment addresses a motion planning of a humanoid robot with 62-dimensional
conﬁguration space. We utilized human motion capture data from the Carnegie Mellon University
motion capture (CMU mocap) database for the learning; the training data was a set of (short)
locomotion  e.g.  for standing  walking  and turning. The 62-dimensional conﬁgurations consist
of angles of all joints  roll and pitch angles  vertical position of the root  yaw rate of the root 

7

(a)

(b)

(c)

Figure 1: Pendulum results. (a) The inferred latent states colored by angles (top) and angular
velocities (bottom) of the ground truth. (b) Resulting image sequences. From the top: images of
ground truth  prediction  and four plaining results for swing-up  -down  -left  and -right  respectively.
Except the ﬁrst row  the images before the red line (k ≤ 10) are reconstructed one. (c) The target
images for each task: CK = ||xtarget − xK||2.

and horizontal velocity of the root. The global (horizontal) position and heading orientation are
not encoded in the generative model (only velocities are encoded)  but they can be recovered by
integration when an observation sequence is given. The original data were written at 120 Hz  and we
down-sampled them to 20 Hz and cut them every 10 time steps  i.e.  δt = 0.05  K = 10. 1043 and
173 data are used for training and test  respectively. We utilized the DeepMind Control Suite [Tassa
et al.  2018] for parsing the data and visualizing the results.
Figs. 2(a-c) illustrate the posterior mean states of the training data colored by some physical quantities
of the ground truth; we can observe that (a) locomotion is basically embedded along the surface of
the cylinder  while (b) they were arranged in the order of the yaw rates along the major axis of the
cylinder and (c) motions with lower forward velocities were embedded into smaller radius cycles.
Also  Fig. 2(d) shows that APIAE successfully reconstructed the data. Compared to the pendulum
example  where the Wiener process in latent dynamics models disturbance into the system and the
prediction can be made simply by ignoring the disturbance  the framework in this example uses the
Wiener process to model the uncertainty in human’s decision  e.g.  whether to turn left or right  to
increase or decrease their speed  etc  similar to the modeling of the bounded rationality [Genewein
et al.  2015] or the maximum entropy IRL [Ziebart et al.  2008]; as shown in Fig. 2(e)  from the
very same initial pose  the framework predicts multiple future conﬁgurations for  e.g.  going straight 
turning left or right (the ratio between motions eventually matches that of the training dataset) and
these predictions play essential roles in the planning. We then formulated planning problems  where
the cost function penalized collision with an obstacle  large yaw rate  and distance from the goal.
Figs. 2(f-g) show that the proposed method successfully generated the natural and collision-free
motion toward the goal.

6.3 Quantitative Results

It is easily thought that powerful inference methods via resampling or reﬁnements make the bound
tighter  but achieving a tighter bound during learning does not directly imply a better model learn-
ing [Rainforth et al.  2018]. To investigate this  we have compared the lower bound  the reconstruction
and prediction abilities of the models learned by the proposed and baseline algorithms. The results
are reported in Table 1 (higher is better).4 Interestingly  we can observe that learning with both the
resampling and path-integral reﬁnements resulted in the best reconstruction ability as well as the
tightest bound  but the best prediction was achieved by the model learned only with the reﬁnements. It
implies that while powerful inference can lead to a tighter bound and a good reconstruction  a bias in
the gradients can prevent the resulting model from being accurate (note that the gradient components
from the resampling are generally ignored because it causes high variance of the gradient estimator
[Maddison et al.  2017  Le et al.  2018  Naesseth et al.  2018]). In the planning side  the prediction
power is crucial because the (learned) generative model needs to sample meaningful and diverse
conﬁguration sequences. We conclude that the resampling procedure would be better to utilize only

4Mocap prediction is omitted  because a proper measure for the prediction is unclear.

8

-10-50510-15-10-5051015-3-2-10123-10-50510-15-10-5051015-10-505109𝑘 =1254050(a)

(b)

(c)

(d)

(e)

(f)

(g)

Figure 2: Mocap results. The learned latent space colored by (a) the gait phase  (b) yaw rate  and (c)
forward velocity of the ground truth. We set the phase as 0 when the left foot touch the ground and
as π when the right foot touch the ground. (d) Reconstruction. (e) Prediction results from the same
initial poses. (f-g) Locomotion planning results.

for planning  not for learning  and this also would be the same in other application domains like
3-dimensional human motion tracking  where the prediction ability is more important.

Table 1: Comparison of the lower bound  reconstruction  and prediction. Each model was trained
with (i) APIAE with resampling (+r)  (ii) APIAE without resampling  (iii) FIVO  and (iv) IWAE. The
lower bounds are obtained for the training datasets and the reconstruction and prediction results are
made for the test datasets; the amounts of the test datasets were around 1/6 of the training datasets.

Pendulum (×106)
Lower-bound Reconstruction

Mocap (×105)

Prediction

Lower-bound Reconstruction

APIAE+r
APIAE
FIVO
IWAE

-9.866
-9.927
-9.890
-9.974

-1.647
-1.653
-1.650
-1.665

-1.985
-1.845
-1.978
-1.860

-6.665
-6.680
-6.687
-6.683

-1.158
-1.171
-1.167
-1.174

7 Conclusion

In this paper  a semi-amortized variational inference method for sequential data was proposed. We
parameterized a variational distribution by control input and transformed an approximate inference
into a SOC problem. The proposed framework utilized the structured inference network based on
the principle of optimality and adopted the adaptive path-integral control method as a reﬁnement
procedure. The experiments showed that the reﬁnement procedure helped the learning algorithm
achieve tighter lower bound. Also  it is shown that the valid dynamical model can be identiﬁed from
sequential raw data and utilized to plan the future conﬁgurations.

9

-10100z310z1-100z20-10100123456-10100z310z1-100z20-1010-2-1012-10100z310z1-100z20-10100.20.40.60.81Acknowledgments

This work was supported by the Agency for Defense Development under contract UD150047JD.

References
Martín Abadi  Paul Barham  Jianmin Chen  Zhifeng Chen  Andy Davis  Jeffrey Dean  Matthieu Devin 
Sanjay Ghemawat  Geoffrey Irving  Michael Isard  et al. Tensorﬂow: A system for large-scale
machine learning. In OSDI  volume 16  pages 265–283  2016.

Ershad Banijamali  Rui Shu  Mohammad Ghavamzadeh  Hung Bui  and Ali Ghodsi. Robust locally-
linear controllable embedding. International Conference on Artiﬁcial Intelligence and Statistics
(AISTATS)  2018.

Richard Bellman. Dynamic programming. Courier Corporation  2013.

Yuri Burda  Roger Grosse  and Ruslan Salakhutdinov. Importance weighted autoencoders. Interna-

tional Conference on Learning Representations (ICLR)  2016.

Nutan Chen  Maximilian Karl  and Patrick van der Smagt. Dynamic movement primitives in latent
space of time-dependent variational autoencoders. In International Conference on Humanoid
Robots (Humanoids)  pages 629–636. IEEE  2016.

Chris Cremer  Quaid Morris  and David Duvenaud. Reinterpreting importance-weighted autoencoders.

ICLR Workshop  2017.

Chris Cremer  Xuechen Li  and David Duvenaud. Inference suboptimality in variational autoencoders.

arXiv preprint arXiv:1801.03558  2018.

Marco Fraccaro  Simon Kamronn  Ulrich Paquet  and Ole Winther. A disentangled recognition
and nonlinear dynamics model for unsupervised learning. In Advances in Neural Information
Processing Systems (NIPS)  pages 3604–3613  2017.

Crispin W Gardiner et al. Handbook of stochastic methods  volume 4. Springer Berlin  1985.

Tim Genewein  Felix Leibfried  Jordi Grau-Moya  and Daniel Alexander Braun. Bounded rationality 
abstraction  and hierarchical decision-making: An information-theoretic optimality principle.
Frontiers in Robotics and AI  2:27  2015.

Jung-Su Ha  Hyeok-Joo Chae  and Han-Lim Choi. Approximate inference-based motion planning
by learning and exploiting low-dimensional latent variable models. In Robotics and Automation
Letters (RA-L/IROS’18). IEEE  2018.

Devon Hjelm  Ruslan R Salakhutdinov  Kyunghyun Cho  Nebojsa Jojic  Vince Calhoun  and Junyoung
Chung. Iterative reﬁnement of the approximate posterior for directed belief networks. In Advances
in Neural Information Processing Systems (NIPS)  pages 4691–4699  2016.

Brian Ichter  James Harrison  and Marco Pavone. Learning sampling distributions for robot motion

planning. International Conference on Robotics and Automation (ICRA)  2018.

Matthew Johnson  David K Duvenaud  Alex Wiltschko  Ryan P Adams  and Sandeep R Datta.
Composing graphical models with neural networks for structured representations and fast inference.
In Advances in neural information processing systems (NIPS)  pages 2946–2954  2016.

Rico Jonschkowski and Oliver Brock. Learning state representations with robotic priors. Autonomous

Robots  39(3):407–428  2015.

Hilbert Johan Kappen and Hans Christian Ruiz. Adaptive importance sampling for control and

inference. Journal of Statistical Physics  162(5):1244–1266  2016.

Peter Karkus  David Hsu  and Wee Sun Lee. Qmdp-net: Deep learning for planning under partial
observability. In Advances in Neural Information Processing Systems (NIPS)  pages 4697–4707 
2017.

10

Maximilian Karl  Maximilian Soelch  Justin Bayer  and Patrick van der Smagt. Deep variational
bayes ﬁlters: Unsupervised learning of state space models from raw data. International Conference
on Learning Representations (ICLR)  2017.

Yoon Kim  Sam Wiseman  Andrew C Miller  David Sontag  and Alexander M Rush. Semi-amortized

variational autoencoders. arXiv preprint arXiv:1802.02550  2018.

Diederik P Kingma and Max Welling. Auto-encoding variational bayes. International Conference on

Learning Representations (ICLR)  2014.

Rahul G Krishnan  Uri Shalit  and David Sontag. Structured inference networks for nonlinear state

space models. In AAAI  pages 2101–2109  2017.

Rahul G Krishnan  Dawen Liang  and Matthew Hoffman. On the challenges of learning with inference
networks on sparse  high-dimensional data. International Conference on Artiﬁcial Intelligence and
Statistics (AISTATS)  2018.

Tuan Anh Le  Maximilian Igl  Tom Jin  Tom Rainforth  and Frank Wood. Auto-encoding sequential

monte carlo. International Conference on Learning Representations (ICLR)  2018.

Timothée Lesort  Natalia Díaz-Rodríguez  Jean-François Goudou  and David Filliat. State representa-

tion learning for control: An overview. arXiv preprint arXiv:1802.04181  2018.

Chris J Maddison  Dieterich Lawson  George Tucker  Nicolas Heess  Mohammad Norouzi  Andriy
Mnih  Arnaud Doucet  and Yee Whye Teh. Filtering variational objectives. In Advances in neural
information processing systems (NIPS)  2017.

Andriy Mnih and Danilo Rezende. Variational inference for monte carlo objectives. In International

Conference on Machine Learning (ICML)  pages 2188–2196  2016.

Christian A Naesseth  Scott W Linderman  Rajesh Ranganath  and David M Blei. Variational
In International Conference on Artiﬁcial Intelligence and Statistics

sequential monte carlo.
(AISTATS)  2018.

Masashi Okada  Luca Rigazio  and Takenobu Aoshima. Path integral networks: End-to-end differen-

tiable optimal control. arXiv preprint arXiv:1706.09597  2017.

Tom Rainforth  Adam R Kosiorek  Tuan Anh Le  Chris J Maddison  Maximilian Igl  Frank Wood  and
Yee Whye Teh. Tighter variational bounds are not necessarily better. In International Conference
on Machine Learning (ICML)  2018.

Danilo Jimenez Rezende  Shakir Mohamed  and Daan Wierstra. Stochastic backpropagation and
In International Conference on Machine

approximate inference in deep generative models.
Learning (ICML)  pages 1278–1286  2014.

Hans-Christian Ruiz and Hilbert J Kappen. Particle smoothing for hidden diffusion processes:
Adaptive path integral smoother. IEEE Transactions on Signal Processing  65(12):3191–3203 
2017.

Aviv Tamar  Yi Wu  Garrett Thomas  Sergey Levine  and Pieter Abbeel. Value iteration networks. In

Advances in Neural Information Processing Systems (NIPS)  pages 2154–2162  2016.

Yuval Tassa  Yotam Doron  Alistair Muldal  Tom Erez  Yazhe Li  Diego de Las Casas  David Budden 
Abbas Abdolmaleki  Josh Merel  Andrew Lefrancq  et al. DeepMind Control Suite. arXiv preprint
arXiv:1801.00690  2018.

Sep Thijssen and HJ Kappen. Path integral control and state-dependent feedback. Physical Review E 

91(3):032104  2015.

Emanuel Todorov. General duality between optimal control and estimation. In IEEE Conference on

Decision and Control  pages 4286–4292. IEEE  2008.

Emanuel Todorov. Efﬁcient computation of optimal actions. Proceedings of the national academy of

sciences  106(28):11478–11483  2009.

11

Paul Vernaza and Daniel D Lee. Learning and exploiting low-dimensional structure for efﬁcient
holonomic motion planning in high-dimensional spaces. The International Journal of Robotics
Research  31(14):1739–1760  2012.

Jack M Wang  David J Fleet  and Aaron Hertzmann. Gaussian process dynamical models for human
motion. IEEE transactions on pattern analysis and machine intelligence  30(2):283–298  2008.

Manuel Watter  Jost Springenberg  Joschka Boedecker  and Martin Riedmiller. Embed to control:
In Advances in neural

A locally linear latent dynamics model for control from raw images.
information processing systems (NIPS)  pages 2746–2754  2015.

Clark Zhang  Jinwook Huh  and Daniel D Lee. Learning implicit sampling distributions for motion

planning. arXiv preprint arXiv:1806.01968  2018.

Brian D Ziebart  Andrew L Maas  J Andrew Bagnell  and Anind K Dey. Maximum entropy inverse

reinforcement learning. In AAAI  volume 8  pages 1433–1438. Chicago  IL  USA  2008.

12

,Jung-Su Ha
Young-Jin Park
Hyeok-Joo Chae
Soon-Seo Park
Han-Lim Choi