2012,Dynamical And-Or Graph Learning for Object Shape Modeling and Detection,This paper studies a novel discriminative part-based model to represent and recognize object shapes with an “And-Or graph”. We define this model consisting of three layers: the leaf-nodes with collaborative edges for localizing local parts  the or-nodes specifying the switch of leaf-nodes  and the root-node encoding the global verification. A discriminative learning algorithm  extended from the CCCP [23]  is proposed to train the model in a dynamical manner: the model structure (e.g.  the configuration of the leaf-nodes associated with the or-nodes) is automatically determined with optimizing the multi-layer parameters during the iteration. The advantages of our method are two-fold. (i) The And-Or graph model enables us to handle well large intra-class variance and background clutters for object shape detection from images. (ii) The proposed learning algorithm is able to obtain the And-Or graph representation without requiring elaborate supervision and initialization. We validate the proposed method on several challenging databases (e.g.  INRIA-Horse  ETHZ-Shape  and UIUC-People)  and it outperforms the state-of-the-arts approaches.,Dynamical And-Or Graph Learning for Object Shape

Modeling and Detection

Xiaolong Wang

Sun Yat-Sen University

Guangzhou  P.R. China 510006
dragonwxl123@gmail.com

Liang Lin∗

Sun Yat-Sen University

Guangzhou  P.R. China 510006

linliang@ieee.org

Abstract

This paper studies a novel discriminative part-based model to represent and rec-
ognize object shapes with an “And-Or graph”. We deﬁne this model consist-
ing of three layers: the leaf-nodes with collaborative edges for localizing local
parts  the or-nodes specifying the switch of leaf-nodes  and the root-node encod-
ing the global veriﬁcation. A discriminative learning algorithm  extended from
the CCCP [23]  is proposed to train the model in a dynamical manner: the model
structure (e.g.  the conﬁguration of the leaf-nodes associated with the or-nodes) is
automatically determined with optimizing the multi-layer parameters during the
iteration. The advantages of our method are two-fold.
(i) The And-Or graph
model enables us to handle well large intra-class variance and background clutters
for object shape detection from images. (ii) The proposed learning algorithm is
able to obtain the And-Or graph representation without requiring elaborate super-
vision and initialization. We validate the proposed method on several challenging
databases (e.g.  INRIA-Horse  ETHZ-Shape  and UIUC-People)  and it outper-
forms the state-of-the-arts approaches.

1 Introduction
Part-based and hierarchical representations have been widely studied in computer vision  and lead
to some elegant frameworks for complex object detection and recognition. However  most of the
methods address only the hierarchical decomposition by tree-structure models [5  25]  and oversim-
plify the reconﬁgurability (i.e. structural switch) in hierarchy  which is the key to handle the large
intra-class variance in object detection. In addition  the interactions of parts are often omitted in
learning and detection. And-Or graph models are recently explored in [26  27] to hierarchically
model object categories via “and-nodes” and “or-nodes” that represent  respectively  compositions
of parts and structural variation of parts. Their main limitation is that the learning process is strongly
supervised and the model structure needs to be manually annotated.
The key contribution of this work is a novel And-Or graph model  whose parameters and structure
can be jointly learned in a weakly supervised manner. We achieve the superior performance on the
task of detecting and localizing shapes from cluttered backgrounds  compared to the state-of-the-
art approaches. As Fig. 3(a) illustrates  the proposed And-Or graph model consists of three layers
described as follows.
The leaf-nodes in the bottom layer represent a batch of local classiﬁers of contour fragments. We
provide a partial matching scheme that can recognize the accurate part of the contour  to deal with

∗

Corresponding author is Liang Lin. This work was supported by National Natural Science Foundation of
China (no. 61173082)  Fundamental Research Funds for the Central Universities (no. 2010620003162041) 
and the Guangdong Natural Science Foundation (no.S2011010001378).This work was also partially funded by
SYSU-Sugon high performance computing typical application project.

1

the problem that the true contours of objects are often connected to background clutters due to
unreliable edge extraction.
The or-nodes in the middle layer are “switch” variables specifying the activation of their children
leaf-nodes. We utilize the or-nodes accounting for alternate ways of composition  rather than just
deﬁning multi-layer compositional detectors  which is shown to better handle the intra-class variance
and inconsistency caused by unreliable edge detection. Each or-node is used to select one contour
from the candidates detected via the associated leaf-nodes in the bottom layer. Moreover  during
detection  location displacement is allowed for each or-node to tackle the part deformation.
The root-node (i.e. the and-node) in the top layer is a global classiﬁer capturing the holistic defor-
mation of the object. The contours selected via the or-nodes are further veriﬁed as a whole  in order
to make the detection robust against the background clutters.
The collaborative edges between leaf-nodes are deﬁned by the probabilistic co-occurrence of local
classiﬁers  which relax the conditional independence assumption commonly used in previous tree
structure models. Concretely  our model allows nearby contours to interact with each other.
The key problem of training our And-Or graph model is automatic structure determination. We
propose a novel learning algorithm  namely dynamic CCCP   extended from the concave-convex
procedure (CCCP) [23  22] by embedding the structural reconﬁguration. It iterates to dynamically
determine the production of leaf-nodes associated with the or-nodes  which is often simpliﬁed by
manually ﬁxing in previous methods [25  16]. The other structure attributes (e.g.  the layout of
or-nodes and the activation of leaf-nodes) are implicitly inferred with the latent variables.

2 Related Work
Remarkable progress has been made in shape-based object detection [6  10  9  11  19]. By em-
ploying some shape descriptors and matching schemes  many works represent and recognize object
shapes as a loose collection of local contours. For example  Ferrari et al. [6] used a codebook of
PAS (pairwise adjacent segments) to localize object of interest; Maji et al. [11] proposed a maximum
margin hough voting for hypothesis regions combining with intersection kernel SVM(IKSVM) for
veriﬁcation; Yang and Latecki [19] constructed shape models in a fully connected graph form with
partially-supervised learning  and detected objects via a Particle Filters (PF) framework.
Recently  the tree structure latent models [25  5] have provided signiﬁcant improvements on object
detection. Based on these methods  Srinivasan et al. [16] trained the descriptive contour-based de-
tector by using the latent-SVM learning; Song et al. [15] integrated the context information with the
learning  namely Context-SVM. Schnitzspan et al. [14] further combined the latent discriminative
learning with conditional random ﬁelds using multiple features.
Knowledge representation with And-Or graph was ﬁrst introduced for modeling visual patterns by
Zhu and Mumford [27]. Its general idea  i.e. using conﬁgurable graph structures with And  Or
nodes  has been applied in object and scene parsing [26  18  24] and action classiﬁcation [20].

3 And-Or Graph Representation for Object Shape
The And-Or Graph model is deﬁned as G = (V E)  where V represents three types of nodes and
E the graph edges. As Fig. 3(a) illustrates  the square on the top is the root-node representing
the complete object instances. The dashed circles derived from the root are z or-nodes arranged
in a layout of b1 × b2 blocks  representing the object parts. Each or-node comprises an unﬁxed
number of leaf-nodes (denoted by the solid circles on the bottom); the leaf-nodes are allowed to be
dynamically created and removed during the learning. For simplicity  we set the maximum number
m of leaf-nodes afﬁliated to one or-node  and the parameters of non-existing leaf-nodes to zero.
Then the maximum number of all nodes in the model is 1 + n = 1 + z + z × m. We use i = 0
indexing the root node  i = 1  ...  z the or-nodes and j = z + 1  ...  n the leaf-nodes. We also deﬁne
that j ∈ ch(i) indexes the child nodes of node i. The horizontal graph edges (i.e.  collaborative
edges) are deﬁned between the leaf-nodes that are associated with different or-nodes  in order to
encode the compatibility of object parts. The deﬁnitions of G are presented as follows.
Leaf-node: Each leaf-node Lj  j = z + 1  ...  n is a local classiﬁer of contours  whose placement is
decided by its parent or-node (the localized block). Suppose a contour fragment c on the edge map
X is captured by the block located at pi = (px
i )  as the input of classiﬁer. We denote ϕl(pi  c) as

i   py

2

the feature vector using the Shape Context descriptor [3]. For any classiﬁer  only the part of c fallen
into the block will be taken into account  and we set ϕl(pi  c) = 0 if c is entirely out. The response
of classiﬁer Lj at location pi of the edge map X is deﬁned as:

RLj (X  pi) = max
c∈X

· ϕl(pi  c) 

ωl
j

(1)
j is a parameter vector  which is set to zero if the corresponding leaf-node Lj is nonexistent.
where ωl
· ϕl(pi  c).
Then we can detect the contour from edge map X via the classiﬁer  cj = argmaxc∈X ωl
j
Or-node: Each or-node Ui  i = 1  ...  z is proposed to specify a proper contour from a set of candi-
dates detected via its children leaf-nodes. Note that we can also consider the or-node activating one
leaf-node. The or-nodes are allowed to perturb slightly with respect to the root. For each or-node
Ui  we deﬁne the deformation feature as ϕs(p0  pi) = (dx  dy  dx2  dy2)  where (dx  dy) is the dis-
placement of the or-node position pi to the expected position p0 determined by the root-node. Then
the cost of locating Ui at pi is:

Costi(p0  pi) = −ωs

· ϕs(p0  pi) 

i

(2)
where ωs
i is a 4-dimensional parameter vector corresponding to ϕs(p0  pi). In our method  each or-
node contains at most m leaf-nodes  among which one is to be activated during inference. For each
leaf-node Lj associated with Ui  we introduce an indicator variable vj ∈ {0  1} representing whether
it is activated or not. Then we derive the auxiliary “switch” vector for Ui  vi = (vj1   vj2   ...  vjm ) 
where ||vi|| = 1. Thus  the response of the or-node Ui is deﬁned as 

RUi (X  p0  pi  vi) =

RLj (X  pi) · vj + Costi(p0  pi).

(3)

∑

j∈ch(i)

Collaborative Edge: For any pair of leaf-nodes (Lj  Lj′) respectively associated with two dif-
ferent or-nodes  we deﬁne the collaborative edge between them according to their contextual co-
occurrence. That is  how likely it is that the object contains contours detected via the two leaf-nodes.
The response of the pairwise potentials is parameterized as 
· vj · vj′ 

RE(V ) =

n∑

∑

(4)

ωe

(j;j′)

j=z+1

j′∈neigh(j)

where neigh(j) is deﬁned as the neighbor leaf-nodes from the other or-node adjacent (in spatial
direction) to Lj  and V is a joint vector for each vi: V = (v1  ...  vz) = (vz+1  ...  vn). ωe
(j;j′)
indicates the compatibility between Lj and Lj′.
Root-node: The root-node represents a global classiﬁer to verify the ensemble of contour fragments
C r = {c1  ...  cz} proposed by the or-nodes. The response of the root-node is parameterized as 

RT (C r) = ωr · ϕr(C r) 

where P = (p0  p1  ...  pz) is a vector of the positions of or-nodes. For better understanding  we
refer H = (P  V ) as the latent variables during inference  where P implies the deformation of
parts represented by the or-nodes and V implies the discrete distribution of leaf-nodes (i.e.  which
leaf-nodes are activated for detection). The Eq.(6) can be further simpliﬁed as :

RG(X  H) = ω · ϕ(X  H) 

where ω includes the complete parameters of And-Or graph  and ϕ(X  H) is the feature vector 

n −ωs

1  ...  −ωs

z+1  ...  ωl

ω = (ωl
(z+1;z+1+m)  ...  ωe
ϕ(X  H) = (ϕl(p1  cz+1) · vz+1 ···   ϕl(pz  cn) · vn 

z  ωe

(n−m;n)  ωr).

ϕs(p0  p1) ···   ϕs(p0  pz)  vz+1 · vz+1+m  ...  vn−m · vn  ϕr(C r)).

3

where ϕr(C r) is the feature vector of C r and ωr the corresponding parameter vector.
Therefore  the overall response of the And-Or graph is:

a∑

RG(X  P  V ) =

RUi (X  p0  pi  vi) + RE(V ) + RT (C r)

i=1

j · ϕl(pi  cj) · vj − ωs
ωl

i · ϕs(p0  pi)] +

(j;j′) · vj · vj′ + ωr · ϕr(C r) 
ωe

(6)

n∑

∑

j=z+1

j′∈neigh(j)

z∑

∑

=

[

i=1

j∈ch(i)

(5)

(7)

(8)

(9)

Figure 1: Illustration of dynamical structure learning. Parts of the model  two or-nodes (U1  U6)  are
visualized in three intermediate steps. (a) The initial structure  i.e.  the regular layout of an object.
Two new structures are dynamically generated during iteration. (b) A leaf-node associated with U1
is removed. (c) A new leaf-node is created and assigned to U6.

4 Inference
The inference task is to localize the optimal contour fragments within the detection window  which
is slidden at all scales and positions of the edge map X. Assuming the root-node is located at p0 
the object shape is localized by maximizing RG(X  H) deﬁned in (6):

S(p0  X) = max

H

RG(X  H).

(10)

The inference procedure integrates the bottom-up testing and top-down veriﬁcation:
Bottom-up testing: For each or-node Ui  its children leaf-nodes (i.e. the local classiﬁers) are uti-
lized to detect contour fragments within the edge map X. Assume that leaf-node Lj  j ∈ ch(i)
associated with Ui is activated  vj = 1  and the optimal contour fragment cj is localized by maxi-
∗
mizing the response in Eq.(3)  where the optimal location p
i;j is also determined. Then we generate
}  each of which is one detected contour fragments via
a set of candidates for each or-node  {cj  p
the leaf-nodes. These sets of candidates will be passed to the top-down step where the leaf-node
activation vi for Ui can be further validated. We calculate the response for the bottom-up step  as 

∗
i;j

z∑

Rbot(V ) =

RUi(X  p0  p

∗
i   vi) 

i=1

(11)
where V = {vi} denotes a hypothesis of leaf-node activation for all or-nodes. In practice  we can
further prune the candidate contours by setting a threshold on Rbot(V ). Thus  given the V = {vi} 
we can select an ensemble of contours C r = {c1  ...  cz}  each of which is detected by an activated
leaf-node  Lj  vj = 1.
Top-down veriﬁcation: Given the ensemble of contours C r  we then apply the global classiﬁer
at the root-node to verify C r by Eq.
(5)  as well as the accumulated pairwise potentials on the
collaborative edges deﬁned in Eq.(4).
By incorporating the bottom-up and top-down steps  we obtain the response of And-Or graph model
by Eq.(6). The ﬁnal detection is acquired by selecting the maximum score in Eq.(10).

5 Discriminative Learning for And-Or Graph
We formulate the learning of And-Or graph model as a joint optimization task for model struc-
ture and parameters  which can be solved by an iterative method extended from the CCCP frame-
work [22]. This algorithm iterates to determine the And-Or graph structure in a dynamical manner:
given the inferred latent variables H = (P  V ) in each step  the leaf-nodes can be automatically
created or removed to generate a new structural conﬁguration. To be speciﬁc  a new leaf-node is
encouraged to be created as the local detector for contours that cannot be handled by the current
model(Fig. 1(c)); a leaf-node is encourage to be removed if it has similar discriminative ability as
other ones(Fig. 1(b)). We thus call this procedure dynamical CCCP (dCCCP).

5.1 Optimization Formulation
Suppose a set of positive and negative training samples (X1  y1) ... (XN   yN ) are given  where X is
the edge map  y = ±1 is the label to indicate positive and negative samples. We assume the samples
indexed from 1 to K are the positive samples  and the feature vector for each sample (X  y) as 

4

(cid:9)a(cid:10)(cid:9)b(cid:10)(cid:9)c(cid:10)(cid:20)(cid:3)(cid:25)(cid:3)… … (cid:20)(cid:3)(cid:25)(cid:3)… … (cid:20)(cid:3)(cid:25)(cid:3)… … where H is the latent variables. Thus  Eq.(10) can be rewritten as a discriminative function 

(12)

(13)

{

ϕ(X  y  H) =

ϕ(X  H)
0

if y = +1
if y = −1

 

S!(X) = argmaxy;H (ω · ϕ(X  y  H)).

N∑

The optimization of this function can be solved by using structural SVM with latent variables 

∥ω∥2 + D

1
2

(ω · ϕ(Xk  y  H) + L(yk  y  H)) − max

(ω · ϕ(Xk  yk  H))] 

!

k=1

min

[max
y;H

(14)
where D is a penalty parameter(set as 0.005 empirically)  and L(yk  y  H) is the loss function. We
deﬁne that L(yk  y  H) = 0 if yk = y  “1” if yk ̸= y in our method.
The optimization target in Equation(14) is non-convex. The CCCP framework [23] was recently
utilized in [22  25] to provide a local optimum solution by iteratively solving the latent variables
H and the model parameter ω. However  the CCCP does not address the or-nodes in hierarchy 
i.e.  assuming the conﬁguration of structure is ﬁxed. In the following  we propose the dCCCP by
embedding a structural reconﬁguration step.

H

5.2 Optimization with dynamic CCCP
N∑
Following the original CCCP framework  we convert the function in Eq. (14) into a convex and
concave form as 
∥ω∥2 + D
1
[
2
[f (ω) − g(ω)] 

(ω · ϕ(Xk  y  H) + L(yk  y  H))] − [D

(ω · ϕ(Xk  yk  H))]

N∑

max
y;H

= min

(15)

max

min

(16)

k=1

k=1

H

!

!

In our method  besides the inferred H

where f (ω) represents the ﬁrst two terms  and g(ω) represents the last term in (15).
The original CCCP includes two iterative steps: (I) ﬁxing the model parameters  estimate the la-
∗ for each positive samples; (II) compute the model parameters by the traditional
tent variables H
∗  we need to further determine
structural SVM method.
the graph conﬁguration  i.e.
the production of leaf-nodes associated with or-nodes  to obtain the
complete structure. Thus  we insert one step between two original ones to perform the structure
reconﬁguration. The three iterative steps are presented as follows.
(I) For optimization  we ﬁrst ﬁnd a hyperplane qt to upper bound the concave part −g(ω) in Eq.(16) 
−g(ω) ≤ −g(ωt) + (ω − ωt) · qt ∀ω.
(17)
where ωt includes the model parameters obtained in the previous iteration. We construct qt by
∑
k = argmaxH (ωt·ϕ(Xk  yk  H)). Since ϕ(Xk  yk  H) =
∗
calculating the optimal latent variables H
0 when yk = −1  we only take the positive training samples into account during computation. Then
the hyperplane is constructed as qt = −D
(II) In this step  we adjust the model structure by reconﬁguring the leaf-nodes. In our model  each
∗
). Thus  the process
leaf-node is mapped to several feature dimensions of the vector ϕ(X  y  H
∗
of reconﬁguration is equivalent to reorganizing the feature vector ϕ(X  y  H
). Accordingly  the
)  and would lead to non-convergence of learning.
hyperplane qt would change with ϕ(X  y  H
) guided by the Principal Component Analysis(PCA). That is 
Therefore  we operate on ϕ(X  y  H
we allow the adjustment only with the non-principal components (dimensions) of ϕ(X  y  H
)  in
) [8]. As a result  qt is assumed to be
terms of preserving the signiﬁcant information of ϕ(X  y  H
unaltered. This step of model reconﬁguration can be then divided into two sub-steps.
(i) Feature refactoring guided by PCA. Given ϕ(Xk  yk  H
PCA on them 

∗
k ) of all positive samples  we apply

N
k=1 ϕ(Xk  yk  H

∗
k ).

∗

∗

∗

∗

ϕ(Xk  yk  H

(18)
∑K
where K is the number of the eigenvectors  ei the eigenvector with its parameter βk;i. We set K a
i=1 βk;iei)||2 < σ  ∀k. For the jth bin of the feature
large number so that ||ϕ(Xk  yk  H

k )− (u +
∗

βk;iei 

i=1

K∑

k ) ≈ u +
∗

5

Figure 2: A toy example for structural clustering. We consider 4 samples  X1  . . .   X4  for train-
ing the structure of Ui. (a) shows the feature vectors ϕ of the samples associated with Ui  and the
intensity of the feature bin indicates the feature value. The red and green bounding boxes on the
vectors indicate the non-principal features representing the detected contour fragments via two dif-
′. The vector ⟨ϕ6  ϕ8  ϕ9⟩ of X2 is
ferent leaf-nodes. (b) illustrates the clustering performed with ϕ
grouped from the right cluster to the left one. (c) shows the adjusted feature vectors according to the
clustering. Note that clustering would result in structural reconﬁguration  as we discuss in the text.
This ﬁgure is encouraged to be view in electronic version.

(pK

′

(p1

i   c1

i   c2

i   cK

i )}.

i   ...  cK
i

i )  ...  ϕl(pK

′
i )  ...  ϕ

vector  we consider it non-principal only if ei;j < δ and uj < δ for all ei and u  (σ = 2.0  δ = 0.001
in experiments).
For each or-node Ui  a set of detected contour fragments  {c1
}  are obtained with the
∗
k of all positive samples. The feature vectors for these contours that are generated by
given H
i )}  are mapped to different parts of the complete feature
the leaf-nodes  {ϕl(p1
i   c1
i   cK
K)}. More speciﬁcally  once we select the jth bin for the
vector  {ϕ(X1  y1  H
∗
∗
1 )  ...  ϕ(XK  yK  H
all feature vectors ϕl  it can be either principal or not in different vectors ϕ. For all feature vector ϕl 
we select the non-principal bins to form a new vector. We thus refactor the feature vectors of these
contours as {ϕ
(ii) Structural reconﬁguration by clustering. To trigger the structural reconﬁguration  for each or-
node Ui  we perform the clustering for detected contour fragments represented by the newly formed
feature vectors. We ﬁrst group the contours detected by the same leaf-node into the same cluster
as a temporary partition. Then the re-clustering is performed by applying the ISODATA algorithm
and the Euclidean distance. And the close contours are grouped into the same cluster. According
to the new partition  we can re-organize the feature vectors  i.e. represent the similar contour with
the same bins in the complete feature vector ϕ. Please recall that the vector of one contour is part
of ϕ. We present a toy example for illustration in Fig. 2. The selected feature vector (non-principal)
i ) = ⟨ϕ6  ϕ8  ϕ9⟩ of X2 is grouped from one cluster to another; by comparing (a) with (c)
′
(p2
ϕ
we can observe that ⟨ϕ6  ϕ8  ϕ9⟩ is moved to ⟨ϕ1  ϕ3  ϕ4⟩.
With the re-organization of feature vectors  we can accordingly reconﬁgure the leaf-nodes corre-
sponding to the clusters of contours. There are two typical states.
• New leaf-nodes are created once more clusters are generated than previous. Their parame-
• One leaf-node is removed when the feature bins related to it are zero  which implies the

ters can be learned based on the feature vectors of contours within the clusters.

i   c2

contours detected by the leaf-node are grouped to another cluster.

∑

In practice  we constrain the extent of structural reconﬁguration  i.e.  only few leaf-nodes can be
created or removed for each or-node per iteration. After the structural reconﬁguration  we denote
∗
k ). Then the new hyperplane is
all the feature vectors ϕ(Xk  yk  H
generated as qd
(III) Given the newly generated model structures represented by the feature vectors ϕd(Xk  yk  H
we can learn the model parameters by solving ωt+1 = argmin![f (ω) + ω · qd
−g(ω) with the upper bound hyperplane qd

∗
k ) are adjusted to ϕd(Xk  yk  H

∗
k ) 
t ]. By substituting

t   the optimization task in Eq. (15) can be rewritten as 

N
k=1 ϕd(Xk  yk  H

t = −D

∗
k ).

(ω · ϕ(Xk  y  H) + L(yk  y  H)) − ω · ϕd(Xk  yk  H

∗
k )].

(19)

N∑

∥ω∥2 + D

min

!

1
2

[max
y;H

k=1

This is a standard structural SVM problem  whose solution is presented as 

6

(cid:21)(cid:29)(cid:25)(cid:15)(cid:3)(cid:27)(cid:15)(cid:3)(cid:28) (cid:21)(cid:29)(cid:20)(cid:15)(cid:3)(cid:22)(cid:15)(cid:3)(cid:23) (cid:20)(cid:29)(cid:20)(cid:15)(cid:3)(cid:22)(cid:15)(cid:3)(cid:23) (cid:23)(cid:29)(cid:20)(cid:15)(cid:3)(cid:22)(cid:15)(cid:3)(cid:23) (cid:21)(cid:29)(cid:25)(cid:15)(cid:3)(cid:27)(cid:15)(cid:3)(cid:28) (cid:22)(cid:29)(cid:25)(cid:15)(cid:3)(cid:27)(cid:15)(cid:3)(cid:28) (cid:20)(cid:29)(cid:20)(cid:15)(cid:3)(cid:22)(cid:15)(cid:3)(cid:23) (cid:23)(cid:29)(cid:20)(cid:15)(cid:3)(cid:22)(cid:15)(cid:3)(cid:23) (cid:22)(cid:29)(cid:25)(cid:15)(cid:3)(cid:27)(cid:15)(cid:3)(cid:28) (cid:21)(cid:29)(cid:25)(cid:15)(cid:3)(cid:27)(cid:15)(cid:3)(cid:28) ( 1  2  3  4  5  6  7  8  9  10) (cid:20) (cid:21) (cid:22) (cid:23) (cid:20) (cid:21) (cid:22) (cid:23) (a) (c) (b)     (cid:260) (cid:260) Figure 3: The trained And-Or graph model with the UIUC-People dataset. (a) visualizes the three
layer model  where the images on the top imply the veriﬁcation via the root-node. (b) exhibits the
leaf-nodes associated with the or-nodes  U1  . . .   U8; a practical detection with the activated leaf-
nodes are highlighted by red. (c) shows the average precisions (AP) results generated by the And-Or
tree (AOT) model and the And-Or graph (AOG) model.

∑

k;y;H

∗

ω

= D

∗
k;y;H ∆ϕ(Xk  y  H) 

α

(20)

∗ by maximizing the dual

∑

where ∆ϕ(Xk  y  H) = ϕd(Xk  yk  H
function:

max

(cid:11)

k;y;H

αk;y;HL(yk  y  H) − D
2

k ) − ϕ(Xk  y  H). We calculate α
∗
∑

∑

k;k′

y;H;y′;H′

αk;y;H αk′;y′;H′ ∆ϕ(Xk  y  H)∆ϕ(Xk′   y

′

′

).

  H

(21)

It is a dual problem in standard SVM  which can be solved by applying the cutting plane method [1]
and Sequential Minimal Optimization [13]. Thus  we obtain the updated parameters ωt+1  and
continue the 3-step iteration until the function in Eq.(16) converges.

Initialization

5.3
At the beginning of learning  the And-Or graph model can be initialized as follows. For each training
sample (whose contours have been extracted)  we partition it into a regular layout of several blocks 
each of which corresponds to one or-node. The contours fallen into the block are treated as the
input for learning. Once there are more than two contours in one block  we select the one with
largest length. Then the leaf-nodes are generated by clustering the selected contours without any
constraints  and we can thus obtain the initial feature vector ϕd for each sample.

6 Experiments
We evaluate our method for object shape detection  using three benchmark datasets: the UIUC-
People [17]  the ETHZ-Shape [7] and the INRIA-Horse [7].
Implementation setting. We ﬁx the number of or-nodes in the And-Or model as 8 for the UIUC-
People dataset  and 6 in other experiments. The initial layout is a regular partition (e.g. 4× 2 blocks
for the UIUC-People dataset and 2 × 3 for others). There are at most m = 4 leaf-nodes for each
or-node. For positive samples  we extract their clutter-free object contours; for negative samples 
we compute their edge maps by using the Pb edge detector [12] with an edge link method. The
convergence of our learning algorithm take 6 ∼ 9 iterations. During detection  the edge maps of
test images are extracted as for negative training samples  within which the object is searched at 6
different scales  2 per octave. For each contour as the input to the leaf-node  we sample 20 points
and compute the Shape Context descriptor for each point; the descriptor is quantized with 6 polar
angles and 2 radial bins. We adopt the testing criterion deﬁned in the PASCAL VOC challenge: a
detection is counted as correct if the intersection over union with the groundtruth is at least 50%.
Experiment I. The UIUC-People dataset contains 593 images (346 for training  247 for testing).
Most of the images contain one person playing badminton. Fig. 3(b) shows the trained And-Or
model(AOG) in that each of the 8 or-nodes associates with 2 ∼ 4 leaf-nodes. To evaluate the beneﬁt
from the collaborative edges  we degenerate our model to the And-Or Tree (AOT) by removing the
collaborative edges. As Fig. 3(c) illustrates  the average precisions (AP) of detection by applying
AOG and AOT are 56.20%and 53.84% respectively. Then we compare our model with the state-
of-the-art detectors in [18  2  4  5]  some of which used manually labeled models. Following the

7

(cid:21)(cid:3)(cid:20)(cid:3)(cid:23)(cid:3)(cid:22)(cid:3)(cid:25)(cid:3)(cid:24)(cid:3)(cid:27)(cid:3)(cid:26)(cid:3)(cid:22)(cid:26)(cid:3)(cid:22)(cid:27)(cid:3)(cid:28)(cid:3)(cid:20)(cid:19)(cid:3)(cid:21)(cid:24)(cid:3)(cid:20)(cid:26)(cid:3)and-node or-node leaf-node (cid:22)(cid:22)(cid:3)(cid:20) (cid:21) (cid:22) (cid:23) (cid:24) (cid:25) (cid:26) (cid:27) (a)(b)135790.350.40.450.50.550.60.65IterationAPUIUC human  AOTAOG(c)Accuracy
0.680
0.660
0.668
0.506
0.486
0.458

Our AOG
Our AOT
Wang et al. [18]
Andriluka et al. [2]
Felz et al. [5]
Bourdev et al. [4]

(a)

Applelogos Bottles Giraffes Mugs Swans Average
0.910
Our method
Ma et al. [10]
0.881
Srinivasan et al. [16] 0.845
Maji et al. [11]
0.869
0.891
Felz et al. [5]
Lu et al. [9]
0.844

0.885 0.968 0.898
0.868 0.959 0.877
0.888 0.922 0.872
0.806 0.716 0.771
0.721 0.391 0.712
0.643 0.798 0.709

0.803
0.756
0.787
0.742
0.608
0.617

0.926
0.920
0.916
0.724
0.950
0.641

(b)

Table 1: (a) Comparisons of detection accuracies on the UIUC-People dataset. (b) Comparisons of
average precision (AP) on the ETHZ-Shape dataset.

metric mentioned in [18]  to calculate the detection accuracy  we only consider the detection with
the highest score on an image for all the methods. As Table. 1a reports  our methods outperforms
other approaches.

Figure 4: (a)Experimental results with the recall-FPPI measurement on the INRIA-Horse database.
(b) (c) and (d) shows a few object shape detections by applying our method on the three datasets 
and the false positives are annotated by blue frames.

Experiment II. The INRIA-Horse dataset consists of 170 horse images and 170 images without
horses. Among them  50 positive examples and 80 negative examples are used for training and
remaining 210 images for testing. Fig. 4 reports the plots of false positives per image (FPPI) vs.
recall. It is shown that our system substantially outperforms the recent methods: the AOG and AOT
models achieve detection rates of 89.6% and 88.0% at 1.0 FPPI  respectively; in contrast  the results
of competing methods are: 87.3% in [21]  85.27% in [11]  80.77% in [7]  and 73.75% in [6].
Experiment III. We test our method with more object categories on the ETHZ-Shape dataset: Ap-
plelogos  Bottles  Giraffes  Mugs and Swans. For each category (including 32 ∼ 87 images)  half of
the images are randomly selected as positive examples  and 70 ∼ 90 negative examples are obtained
from the other categories as well as backgrounds. The trained model for each category is tested
on the remaining images. Table 1b reports the results evaluated by the mean average precision.
Compared with the current methods [11  16  5  9  10]  our model achieves very competitive results.
A few results are visualized in Fig.4(b) (c) and (d) for experiment I  II  and III respectively.

7 Conclusion
This paper proposes a discriminative contour-based object model with the And-Or graph represen-
tation. This model can be trained in a dynamical manner that the model structure is automatically
determined during iterations as well as the parameters. Our method achieves the state-of-art of
object shape detection on challenging datasets.

8

00.20.40.60.8100.10.20.30.40.50.60.70.80.91FPPIRecallINRIA Horses  IKSVMM2HT+IKSVM [11]KAS [7]TPS−RPM [6]Voting with grps + verif [21]Our AOGOur AOT(a)(b)(c)(d)References
[1] Y. Altun  I. Tsochantaridis  and T. Hofmann  Hidden markov support vector machines  In ICML 

2003. 7

[2] M. Andriluka  S. Roth  and B. Schiele  Pictorial structures revisited: People detection and artic-

ulated pose estimation  In CVPR  2009. 7  8

[3] S. Belongie  J. Malik  and J. Puzicha  Shape Matching and Object Recognition using Shape

Contexts  IEEE TPAMI  24(1): 705-522  2002. 3

[4] L. Bourdev  S. Maji  T. Brox  and J. Malik  Detecting people using mutually consistent poselet

activations  In ECCV  2010. 7  8

[5] P. F. Felzenszwalb  R. B. Girshick  D. McAllester  and D. Ramanan  Object Detection with

Discriminatively Trained Part-based Models  IEEE TPAMI  2010. 1  2  7  8

[6] V. Ferrari  F. Jurie  and C. Schmid  From Images to Shape Models for Object Detection  Int’l J.

of Computer Vision  2009. 2  8

[7] V. Ferrari  L. Fevrier  F. Jerie  and C. Schmid  Groups of Adjacent Contour Segments for Object

Detection  IEEE TPAMI  30(1): 36-51  2008. 7  8

[8] N. Kambhatla and T. K. Leen  Dimension Reduction by Local Principal Component Analysis 

Neural Computation  9: 1493-1516  1997. 5

[9] C. Lu  L. J. Latecki  N. Adluru  X. Yang  and H. Ling  Shape Guided Contour Grouping with

Particle Filters  In ICCV  2009. 2  8

[10] T. Ma and L. J. Latecki  From Partial Shape Matching through Local Deformation to Robust

Global Shape Similarity for Object Detection  In CVPR  2011. 2  8

[11] S. Maji and J. Malik  Object Detection using a Max-Margin Hough Transform  In CVPR  2009.

2  8

[12] D. R. Martin  C. C. Fowlkes  and J. Malik  Learning to detect natural image boundaries using

local brightness  color  and texture cues  IEEET PAMI  26(5): 530-549  2004. 7

[13] J. C. Platt  Using analytic qp and sparseness to speed training of support vector machines  In

Advances in Neural Information Processing Systems  pages 557-563  1998. 7

[14] P. Schnitzspan  M. Fritz  S. Roth  and B. Schiele  Discriminative structure learning of hierar-

chical representations for object detection  In CVPR  2009. 2

[15] Z. Song  Q. Chen  Z. Huang  Y. Hua  and S. Yan  Contextualizing Object Detection and Clas-

siﬁcation  In CVPR  2010. 2

[16] P. Srinivasan  Q. Zhu  and J. Shi  Many-to-one Contour Matching for Describing and Discrim-

inating Object Shape  In CVPR  2010. 2  8

[17] D. Tran and D. Forsyth  Improved human parsing with a full relational model  In ECCV  2010.

7

[18] Y. Wang  D. Tran  and Z. Liao  Learning Hierarchical Poselets for Human Parsing  In CVPR 

2011. 2  7  8

[19] X. Yang and L. J. Latecki  Weakly Supervised Shape Based Object Detection with Particle

Filter  In ECCV  2010. 2

[20] B. Yao  A. Khosla  and L. Fei-Fei  Classifying Actions and Measuring Action Similarity by

Modeling the Mutual Context of Objects and Human Poses  In ICML  2011. 2

[21] P. Yarlagadda  A. Monroy and B. Ommer  Voting by Grouping Dependent Parts  In ECCV 

2010. 8

[22] C.-N. J. Yu and T. Joachims  Learning structural svms with latent variables  In ICML  2009. 2 

4  5

[23] A. Yuille and A. Rangarajan  The concave-convex procedure(cccp)  In NIPS  pages 1033-1040 

2001. 1  2  5

[24] Y.B. Zhao and S.C. Zhu  Image Parsing via Stochastic Scene Grammar  In NIPS  2011. 2
[25] L. Zhu  Y. Chen  A. Yuille  and W. Freeman  Latent Hierarchical Structural Learning for Object

Detection  In CVPR  2010. 1  2  5

[26] L. Zhu  Y. Chen  Y. Lu  C. Lin  and A. Yuille  Max Margin AND/OR Graph Learning for

Parsing the Human Body  In CVPR  2008. 1  2

[27] S.C. Zhu and D. Mumford  A stochastic grammar of images  Foundations and Trends in Com-

puter Graphics and Vision  2(4): 259-362  2006. 1  2

9

,Marcelo Fiori
Pablo Sprechmann
Joshua Vogelstein
Pablo Muse
Guillermo Sapiro