2014,On the relations of LFPs & Neural Spike Trains,One of the goals of neuroscience is to identify neural networks that correlate with important behaviors  environments  or genotypes. This work proposes a strategy for identifying neural networks characterized by time- and frequency-dependent connectivity patterns  using convolutional dictionary learning that links spike-train data to local field potentials (LFPs) across multiple areas of the brain. Analytical contributions are: (i) modeling dynamic relationships between LFPs and spikes; (ii) describing the relationships between spikes and LFPs  by analyzing the ability to predict LFP data from one region based on spiking information from across the brain; and (iii) development of a clustering methodology that allows inference of similarities in neurons from multiple regions. Results are based on data sets in which spike and LFP data are recorded simultaneously from up to 16 brain regions in a mouse.,On the Relationship Between LFP & Spiking Data

David E. Carlson1  Jana Schaich Borg2  Kafui Dzirasa2  and Lawrence Carin1

1Department of Electrical and Computer Engineering
2Department of Psychiatry and Behavioral Sciences

{david.carlson  jana.borg  kafui.dzirasa  lcarin}@duke.edu

Duke University
Duham  NC 27701

Abstract

One of the goals of neuroscience is to identify neural networks that correlate with
important behaviors  environments  or genotypes. This work proposes a strategy
for identifying neural networks characterized by time- and frequency-dependent
connectivity patterns  using convolutional dictionary learning that links spike-train
data to local ﬁeld potentials (LFPs) across multiple areas of the brain. Analytical
contributions are: (i) modeling dynamic relationships between LFPs and spikes;
(ii) describing the relationships between spikes and LFPs  by analyzing the ability
to predict LFP data from one region based on spiking information from across the
brain; and (iii) development of a clustering methodology that allows inference
of similarities in neurons from multiple regions. Results are based on data sets in
which spike and LFP data are recorded simultaneously from up to 16 brain regions
in a mouse.

Introduction

1
One of the most fundamental challenges in neuroscience is the “large-scale integration problem”:
how does distributed neural activity lead to precise  uniﬁed cognitive moments [1]. This paper seeks
to examine this challenge from the perspective of extracellular electrodes inserted into the brain. An
extracellular electrode inserted into the brain picks up two types of signals: (1) the local ﬁeld poten-
tial (LFP)  which represents local oscillations in frequencies below 200 Hz; and (2) single neuron
action potentials (also known as “spikes”)  which typically occur in frequencies of 0.5 kHz. LFPs
represent network activity summed over long distances  whereas action potentials represent the pre-
cise activity of cells near the tip of an electrode. Although action potentials are often treated as the
“currency” of information transfer in the brain  relationships between behaviors and LFP activity
can be equally precise  and sometimes even more precise  than those with the activity of individual
neurons [2 3]. Further  LFP network disruptions are highly implicated in many forms of psychiatric
disease [4]. This has led to much interest in understanding the mechanisms of how LFPs and action
potentials interact to create speciﬁc types of behaviors. New multisite recording techniques that
allow simultaneous recordings from a large number of brain regions provide unprecedented oppor-
tunities to study these interactions. However  this type of multi-dimensional data poses signiﬁcant
challenges that require new analysis techniques.
Three of the most challenging characteristics of multisite recordings are that: 1) the networks they
represent are dynamic in space and time  2) subpopulations of neurons within a local area can have
different functions and may therefore relate to LFP oscillations in speciﬁc ways  and 3) different fre-
quencies of LFP oscillations often relate to single neurons in speciﬁc ways [5]. Here new models are
proposed to examine the relationship between neurons and neural networks that accommodate these
characteristics. First  each LFP in a brain region is modeled as convolutions between a bounded-time
dictionary element and the observed spike trains. Critically  the convolutional factors are allowed
to be dynamic  by binning the LFP and spike time series  and modeling the dictionary element for

1

each bin of the time series. Next  a clustering model is proposed making each neuron’s dictionary
element a scaled version of an autoregressive template shared among all neurons in a cluster. This
allows one to identify sub-populations of neurons that have similar dynamics over their functional
connectivity to a brain region. Finally  we provide a strategy for exploring which frequency bands
characterize spike-to-LFP functional connectivity. We show  using two novel multi-region electro-
physiology datasets from mice  how these models can be used to identify coordinated interactions
within and between different neuronal subsystems  deﬁned jointly by the activity of single cells and
LFPs. These methods may lead to better understanding of the relationship between brain activity
and behavior  as well as the pathology underlying brain diseases.
2 Model
2.1 Data and notation
The data used here consists of multiple LFP and spike-train time series  measured simultaneously
from M regions of a mouse brain. Spike sorting is performed on the spiking data by a VB imple-
mentation of [6]  from which J single units are assumed detected from across the multiple regions
(henceforth we refer to single units as “neurons”); the number of observed neurons J depends on
the data considered  and is inferred as discussed in [6]. Since multiple microwires are inserted into
single brain regions in our experiments (described in [7])  we typically detect between 4-50 neurons
for each of the M regions in which the microwires are inserted (discussed further when presenting
results). The analysis objective is to examine the degree to which one may relate (predict) the LFP
data from one brain region using the J-neuron spiking data from all brain regions. This analysis al-
lows the identiﬁcation of multi-site neural networks through the examination of the degree to which
neurons in one region are predictive of LFPs in another.
Let x ∈ RT represent a time series of LFP data measured from a particular brain region. The T
samples are recorded on a regular grid  with temporal interval ∆. The spike trains from J differ-
ent neurons (after sorting) are represented by the set of vectors {y1  . . .   yJ}  binned in the same
manner temporally as the LFP data. Each yj ∈ ZT
+ is reﬂective of the number of times neuron
j ∈ {1  . . .   J} ﬁred within each of the T time bins  where Z+ represents nonnegative integers.
In the proposed model LFP data x are represented as a superposition of signals associated with each
neuron yj  plus a residual that captures LFP signal unrelated to the spiking data. The contribution
to x from information in yj is assumed generated by the convolution of yj with a bounded-time
dictionary element dj (residing within the interval -L to L  with L (cid:28) T ). This model is related to
convolutional dictionary learning [8]  where the observed (after spike sorting) signal yj represents
the signal we convolve the learned dictionary dj against.
We model dj as time evolving  motivated by the expectation that neuron j may contribute differently
to speciﬁed LFP data  based upon the latent state of the brain (which will be related to observed
animal activity). The time series x is binned into a set of B equal-size contiguous windows  where
x = vec([x1  . . .   xB])  and likewise y = vec([yj1  . . .   yjB]). The dictionary element for neuron
j is similarly binned as {dj1  . . .   djB}  and the contribution of neuron j to xb is represented as a
convolution of djb and yjb. This bin size is a trade-off between how ﬁnely time is discretized and
the computational costs.
In the experiments  in one example the bins are chosen to be 30 seconds wide (novel-environment
data) and in the other 1 minute (sleep-cycle data)  and these are principally chosen for computational
convenience (the second data set is nine times longer). Similar results were found with windows as
narrow as 10 second  or as wide as 2 minutes.
2.2 Modeling the LFP contribution of multiple neurons jointly
Given {y1  . . .   yJ}  the LFP voltage at time window b is represented as

xb =

yjb ∗ djb + b

(1)

J(cid:88)

j=1

where ∗ represents the convolution operator. Let Dj = [dj1  . . .   djB] ∈ R(2L+1)×B represent
the sequence of dictionary elements used to represent the LFP data over the B windows  from the
perspective of neuron j. We impose the clustering prior

Dj = ζjAj  Aj ∼ G  G ∼ DP(β  G0)

(2)

2

where G is a draw from a Dirichlet process (DP) [9  10]  with scale parameter β > 0 and base
probability measure G0. Note that we cluster the shape of the dictionary elements  and each neuron
has its own scaling ζ ∈ R. Concerning the base measure  we impose an autoregressive prior on the
temporal dynamics  and therefore G0 is deﬁned by an AR(α  γ) process

k=1 πkδA∗

k

h1  . . .   a∗

ab = αab−1 + νt  νt ∼ N (0  γ−1I)

hB)  with G =(cid:80)∞

(3)
(cid:81)
where I is the identity matrix. This AR prior is used to constitute the B columns of the DP “atoms”
A∗
h = (a∗
. The elements of the vector π = (π1  π2  . . . ) are
i<h(1 − Vi) with Vh ∼ Beta(1  β). We
drawn from the “stick-breaking” [9] process πh = Vh
place the prior Gamma(aβ  bβ) on β  and priors Uniform(0 1) and Gamma(aγ  bγ) respectively on
α and γ. To complete the model  we place the prior N (0  τ−1I) on b  and ζj ∼ N (0  1).
In the implementation  a truncated stick-breaking representation is employed for G  using K “sticks”
(VK = 1)  which simpliﬁes the implementation and has been shown to be effective in practice [9] if
K is made large enough  and the size of K is inferred during the inference algorithm.
Special cases of this model are clear. For example  if the Aj are simply drawn i.i.d. from G0  rather
than from the DP  each neuron is allowed to contribute its own unique dictionary shape to represent
xb  called a non-clustering model in the results. In [11] the authors considered a similar model  but
the time evolution of dj was not considered (each neuron was assumed to contribute in the same way
to represent the LFP  independent of time). Further  in [11] only a single neuron was considered  and
therefore no clustering was considered. A multi-neuron version of this model is inferred by setting
B = 1.
3
3.1 Mean-ﬁeld Variational Inference
Letting Θ = {z  ζ  A1 ... K  V1 ... K  β  α  γ}  the full likelihood of the clustering model

Inference

B(cid:89)

J(cid:89)

K(cid:89)

p(x  Θ) =

[p(xb|Θ)]

[p(zj|π)p(ζj)]

[p(A∗

k|α  γ)p(Vk|β)] p(β  α  γ)

(4)

b=1

j=1

k=1

The non-clustering model can be recovered by setting zj = δj and the truncation level in the stick-
breaking process K to J. The time-invariant model is recovered by setting the number of bins B
to 1  with or without clustering. The model of [11] is recovered by using a single bin and a single
neuron.
Many recent methods [12  13] have been proposed to provide quick approximations to the Dirichlet
process mixture model. Critically  in these models the latent assignment variables are conditionally
independent when the DP parameters are given. However  in the proposed model this assumption
does not hold because the observation x is the superposition of the convolved draws from the Dirich-
let process.
A factorized variational distribution q is proposed to approximate the posterior distribution  and
the non-clustering model arises as a special case of the clustering model. The inference to ﬁt the
distribution q is based on Bayesian Hierarchical Clustering [13] and the VB Dirichlet Process Split-
Merge method [12]. The proposed model does not ﬁt in either of these frameworks  so a method
to learn K by merging clusters by adapting [12  13] is presented in Section 3.1.1. The factorized
distribution q takes the form:

(cid:34)

(cid:89)

(cid:89)

(cid:35)

(cid:89)

q(Θ) =

q(zj)

q(ζjk)

q(β)q(α)q(γ)

[q(A∗

k)q(Vk)]

(5)

j

k

k

γ  b(cid:48)

γ)  q(α) = N(0 1)(ˆα  η−1

α )  q(Ak) = N (vec(Ak); vec(ˆak1  . . .   ˆakB)  Λ−1

Standard forms on these distributions are assumed  with q(zj) = Categorical(rj)  q(γ) =
Gamma(a(cid:48)
k )  Σk =
Λk  and q(β) = Gamma(a(cid:48)
β). To facilitate inference  the distribution on ζj is split into
q(ζjk) = N (µjk  η−1
jk )  the variational distribution for ζ on the jth spike train given that it is in
cluster k. The non-clustering model can be represented as a special case of the clustering model
where q(ζjk) = δ1  and q(zj) = δj. As noted in [12]  this factorized posterior has the property that
a q with K(cid:48) clusters is nested in a representation of q for K clusters for K ≥ K(cid:48)  so any number of
clusters up to K(cid:48) is represented.

β  b(cid:48)

3

Variational algorithms ﬁnd a q that minimizes the KL divergence from the true  intractable posterior
[14]  ﬁnding a q that locally maximizes the evidence lower bound (ELBO) objective:

1 ... K  β  α  γ)]

b = xb −(cid:80)

log p(x|Θ) ≥ L(q) = Eq[log p(x  z  ζ  A∗

1 ... K  β  α  γ|Θ) − log q(z  ζ  A∗
(cid:80)Tb
j(cid:48)(cid:54)=j yb ∗ ((cid:80)

(6)
To facilitate inference  approximations to p(y|Θ) are developed. Let Tb be the number of time
points in bin b  and deﬁne Rjib ∈ R(2L+1)×(2L+1) with entries Rjib ik = 1
t=1 yjb tyib t+k−i;
(cid:80)Tb
yjb t is yj at time point t in window/bin b. Let x
k rjkµjk ˆakb)  or
the residual after all but the contribution from the jth neuron have been removed  and deﬁne let
−j
t=1 yjb txb t+i for i ∈ {−L  . . .   L}. Both Rjb and νjb
jb ∈ R2L+1 with entries νj
ν
−j
b |yjb  djb) =
can be efﬁciently estimated with the FFT. For each time bin b  we can write: log p(x
−j
const − τ
jb )T djb)
k∗ ˆakb. Σkbb(cid:48) denotes
To deﬁne the key updates  let y(cid:48)
the block in Σk indexing the b and the b(cid:48) bins  which is efﬁciently calculated because Σ−1
is a block
tri-diagonal matrix from the ﬁrst-order autoregressive process  and explicit equations exist. Letting
ˆN(cid:48)
k. For q(ζjk)  the
−j
kb + Σkbb))  and µjk = η−1
jb .

b t −(cid:80)L
b = xb−(cid:80)
j rjk  then q(Vk) is updated by are ak = 1 + ˆN  bk = ˆβ +(cid:80)K

kb =(cid:80)
ˆNk =(cid:80)
parameters are updated ηjk = 1 +(cid:80)

(cid:96)=−L yj b t+(cid:96)dj b −(cid:96))2 (cid:39) const − τ Tb
2 (dT
j rjkµjkyjb  and x−k

jbRjjbd − 2(ν
j(cid:48)(cid:54)=j y(cid:48)

b trace(Rjb(ˆakb ˆaT

ji = 1
Tb

(cid:80)

kbRjbν

k(cid:48)=k+1

b ˆaT

2 (x

−j

−j

Tb

jk

k

(cid:88)

The clustering latent variables are updated sequentially by:
log(rjk) ∝ − τ
2
can be used to calculate q(A∗

jk )tr(Rjb(TbΣkbb+ ˆakb ˆaT

[(µjk +η−1

b

kb))−2µjk(x

−j
b )T (ybRjbb ˆakb))]+Eq[q(π)]

b

b

k

and y−k

k). The mean of the distribution q(Ak) is evaluated
is a block tridiagonal matrix 
k) are found in Section A of the

x−k
using the forward ﬁltering-backward smoothing algorithm  and Σ−1
enabling efﬁcient computations. Further details on updating q(A∗
Supplemental Material. Approximating distributions q(β)  q(α) and q(γ) are standard [14  15].
3.1.1 Merge steps
The model is initialized to K = J clusters and the algorithm ﬁrst ﬁnds q for the non-clustering
model. This initialization is important because of the superposition measurement model. The algo-
rithm proceeds to merge down to K(cid:48)  where K(cid:48) is a local mode of the VB algorithm. The procedure
is as follows: (i) Randomly choose two clusters k and k(cid:48) to merge.
(ii) Propose a new varia-
tional distribution ˜q with K − 1 clusters. (iii) Calculate the change in the variational lower bound 
L(˜q) − L(q)  and accept the merge if the variational lower bound increases. As in [12]  intelligent
sampling of k and k(cid:48) signiﬁcantly improves performance. Here  we sample k and k(cid:48) with weight
proportional to exp(−K(Ak  Ak(cid:48); c0))  where K(· ·; c0) is the radial basis function.
In [13] all
pairwise clusterings were considered  but that is computationally infeasible in this problem. This
approach for merging clusters is similar to that developed in [12].
This algorithm requires efﬁcient estimation of the difference in the lower bound. For a proposed k
and k(cid:48)  a new variational distribution ˜q is proposed  with ˜q(zj = k) = q(zj = k) + q(zj = k(cid:48))
ˆNk(cid:63) )  q(βk(cid:48)) = δ0  and
k rjk log rjk  the difference in the lower bound can
p(Ak|α  γ)

and ˜q(zj = k(cid:48)) = 0  ˜q(βk) = Beta(a0 + ˆNk + ˆNk(cid:48)  b0 +(cid:80)K k(cid:63)(cid:54)=k(cid:48)
q(Ak) is calculated. Letting H(q) = −(cid:80)

(cid:80)

k(cid:63)=k+1

j

be calculated:
L(˜q) − L(q) = E˜q

log p(y|A1 ... K  ζ  τ )

− H(˜q) + H(˜p)

(7)

(cid:21)
p(βk))
q(βk)
p(Ak|α  γ)p(A(cid:48)
k|α  γ)
q(Ak)q(A(cid:48)
k)

˜q(Ak)

(cid:21)

− Eq

log p(y|A1 ... K  ζ  τ )

p(βk)p(βk(cid:48))
q(βk)q(βk(cid:48))

+ H(q) − H(p)

Explicit details on the calculations of these variables are found in Section A of the Supplementary
Material  and the block tridiagonal nature of Λk allows the complete calculation of this value in
O(BTb(( ˆNk + ˆNk(cid:48)) + L3)). This is linear in the amount of data used in the model. The algorithm
is stopped after 10 merges in a row are rejected.
3.2 Integrated Nested Laplacian Approximation for the Non-Clustering Model
The VB inference method assumes a separable posterior. In the non-clustering model  Integrated
Nested Laplacian Approximation (INLA) [16] was used to estimate of the joint posterior  without

4

(cid:20)
(cid:20)

Animal

1
2
3
4
5
6

Invariant Non-Cluster Clustering
0.1394
0.1465
0.2251
0.0867
0.1238
0.0675

0.2094
0.2340
0.3414
0.1434
0.1882
0.1351

0.1968
0.2382
0.3050
0.1433
0.1867
0.1407

Animal

7
8
9
10
11

Invariant Non-Cluster Clustering
0.2442
0.1385
0.3182
0.0902
0.2362
0.1597
0.0865
0.0311
0.1161
0.675

0.2567
0.3440
0.1881
0.0803
0.1064

Table 1: Mean held-out RFE of the multi-cell models predicting the Hippocampus LFP. “Invariant” denotes the
time-invariant model  “Non-cluster” and “clustering” denote the dynamic model without and with clustering.

Figure 1: (Left) Mean single-cell holdout RFE predicting mouse 3’s Nucleus Accumbens LFP comparing the
dynamic and time-invariant model. Each point is a single neuron. (Middle) Convolutional dictionary for a
VTA cell predicting mouse 3’s Nucleus Accumbens LFP at 5 minutes  15 minutes  and 38 minutes after the
experiment start. (Right) Hold-out RFE over experiment time with the time-invariant  non-clustering  and the
clustering model to predict mouse 3’s Hippocampus LFP.

assuming separability. Comparisons to INLA constitute an independent validation of VB  for in-
ference in the non-clustering version of the model. The INLA inference procedure is detailed in
Supplemental Section B. INLA inference was found to be signiﬁcantly slower than the VB approxi-
mation  so experimental results below are shown for VB. The INLA and VB predictive performance
were quantitatively similar for the non-clustering model  providing conﬁdence in the VB results.
4 Experiments
4.1 Results on Mice Introduced to a Novel Environment
This data set is from a group of 12 mice consisting of male Clock-∆19 (mouse numbers 7-12)
and male wild-type littermate controls (mouse numbers 1-6) (further described in [7]). For each
animal  32-48 total microwires were implanted  with 6-16 wires in each of the Nucleus Accumbens 
Hippocampus (HP)  Prelimbic Cortex (PrL)  Thalamus  and the Ventral Tegmental Area (VTA).
LFPs were averaged over all electrodes in an area and ﬁltered from 3-50Hz and sampled at 125
Hz. Neuronal activity was recorded using a Multi-Neuron Acquisition Processor (Plexon). 99-192
individual spike trains (single units) were detected per animal. In this dataset animals begin in their
home cage  and after 10 minutes are placed in a novel environment for 30 minutes. For analysis  this
40 minute data sequence was binned into 30 second chunks  giving 80 bins. For all experiments we
choose L such that the dictionary element covered 0.5 seconds before and after each spike event.
Cross-validation was performed using leave-one-out analysis over time bins  using the error metric
of reduction in fractional error (RFE)  1 − ||xb − ˆxb||2
2. Figure 1(left) shows the average
hold-out RFE for the time-invariant model and the dynamic model for single spike train predicting
mouse 3’s Nucleus Accumbens  showing that the dynamic model can give strong improvements
on the scale of a single cell (these results are typical). The dynamic model has a higher hold-out
RFE on 98.4% of detected cells across all animals and all regions  indicating that the dynamic
model generally outperforms the time-invariant model. A dynamic dictionary element from a VTA
cell predicting mouse 3’s Nucleus Accumbens is shown in Figure 1(middle). At the beginning
of the experiment  this cell is linked with a slow  high-amplitude oscillation. After the animal is
initially placed into a new environment (illustrated by the 15-minute data point)  the amplitude of the
dictionary element drops close to zero. Once the animal becomes accustomed to its new environment
(illustrated by the 38-minute data point)  the cell’s original periodic dictionary element begins to
appear again. This example shows how cells and LFPs clearly have time-evolving relationships.
The leave-one-out performance of the time-invariant  non-clustering  and clustering models predict-
ing animal 3’s Hippocampus LFP with 182 neurons is shown in Figure 1(right). These results show

2/||xb||2

5

00.010.020.030.0400.010.020.030.04Time-InvariantDynamicSingleNeuronHold-outRFE−0.500.5−0.1−0.0500.050.1Time secondsAmplitude a.u.DictionaryElementofaVTACell5Min15Min38Min01020304000.10.20.30.40.5ExperimentTime MinutesHold-outRFEJointModelPredictioninHPInvariantNon-ClusterClusteringFigure 2: Example clusters predicting mouse 3’s Hippocampus LFP. The top part shows the convolutional fac-
tor throughout the duration of the experiment  and the bottom part shows the location of the cells in the cluster.
Some of the clusters are dynamic whereas others were consistent through the duration of the experiment.

Figure 3:
(Left) RFE as a function of time bin and frequency bin for all Hippocampus cells predicting the
Thalamus LFP. There is a change in the predictive properties around 10 minutes. (Middle) Total energy versus
the unexplained residual for the Hippocampus cells predicting the Thalamus LFP for the frequency band 25-35
Hz. (Right) RFE using only the cluster of cells shown in Figure 2(right).

that predictability changes over time  and indicate that there is a strong increase in LFP predictability
when the mouse is placed in the novel environment. Using dynamics improves the results dramat-
ically  and the clustering hold-out results showed further improvements in hold-out performance.
The mean hold-out RFE results for the Hippocampus for 11 animals are shown in Table 1 (1 animal
was missing this region recording). Results for other regions are shown in Supplemental Tables 1 
2  3  and 4  and show similar results.
In this dataset  there is little quantitative difference between the clustering and non-clustering mod-
els; however  the clustering result is much better for interpretation. One reason for this is that
spike-sorting procedures are notoriously imprecise  and often under- or over-cluster. A clustering
model with equivalent performance is evidence that many neurons have the same shapes and dy-
namics  and repeated dynamic patterns reduces concerns that dynamics are the result of failure to
distinguish distinct neurons. Similarly  clustering of neuron shapes in a single electrode could be
the result of over-clustering from the spike-sorting algorithm  but clustering across electrodes gives
strong evidence that truly different neurons are clustering together. Additionally  neural action po-
tential shapes drift over time [6  17]  but since cells in a cluster come from different electrodes and
regions  this is strong evidence that the dynamics are not due to over-sorting drifting neurons.
Each cluster has both a dynamic shape result as well as well as a neural distribution over regions.
Example clustering shapes and histogram cell locations for clusters predicting mouse 3’s Thalamus
LFP are shown in Figure 2. The top part of this ﬁgure shows the base dictionary element evolution
over the duration of the experiment. Note that both the (left) and (middle) plots show a dynamic
effect around 10 minutes  and the cells primarily come from the Ventral Tegmental Area. The (right)
plot shows a fairly stable factor  and its cells are mostly in the Hippocampus region.
The ability to predict the LFP constitutes functional connectivity between a neuron and the neuronal
circuit around the electrode for the LFP [18]. Neural circuits have been shown to transfer information
through speciﬁc frequencies of oscillations  so it is of scientiﬁc interest to know the functional
connectivity of a group of neurons as a function of frequency [5]. Frequency relationships were
explored by ﬁltering the LFP signal after the predicted signal has been removed  using a notch ﬁlter
at 1 Hz intervals with a 1 Hz bandwidth  and the RFE was calculated for each held-out time bin and
frequency bin.
All cells in the Thalamus were used to predict each frequency band in mouse 3’s Hippocampus LFP 
and this result is shown in Figure 3(left). This ﬁgure shows an increase in RFE of the 25-35 Hz band
after the animal has been moved to a new location. The RFE on the band from 25-35 Hz is shown

6

Experiment Time  MinutesDictionary  SecondsCluster Factor Evolution 10203040−0.4−0.200.20.4−0.0200.02AccumbensHPPrLThalamusVTA0510Number of CellsCluster’s Cell LocationsExperiment Time  MinutesDictionary  SecondsCluster Factor Evolution 10203040−0.4−0.200.20.4−0.0200.02AccumbensHPPrLThalamusVTA0246Number of CellsCluster’s Cell LocationsExperiment Time  MinutesDictionary  SecondsCluster Factor Evolution 10203040−0.4−0.200.20.4−0.0500.05AccumbensHPPrLThalamusVTA01020Number of CellsCluster’s Cell LocationsExperimentalTime minFrequency HzHippocampusCellsPredictingThalamusLFP10203040813182328333843RFE0.10.20.30.40.50.60102030400100200300400500600HippocampusCellsPredictingThalamusLFP25-35HzExperimentalTime minEnergy a.u.RawEnergyResidualExperimentalTime minFrequency HzClusterContribution10203040813182328333843RFE0.050.10.150.2Region

Time-Invariant
Non-Clustering

Clustering

Region

Time-Invariant
Non-Clustering

Clustering

PrLCx
0.1055
0.1686
0.1749
Subnigra
0.1309
0.1939
0.1950

MOFCCx NAcShell NAcCore
0.1076
0.1796
0.1814
DLS
0.1237
0.1973
0.2012

0.1366
0.1972
0.2020
OFC
0.1878
0.2695
0.2723
Table 2: Mean held-out RFE of the animal going through sleep cycles in each region.

Amyg
0.0883
0.1422
0.1390
DMS
0.1518
0.2363
0.2378

Hipp
0.2091
0.2662
0.2798

M1

0.1350
0.2034
0.2080

0.0904
0.1599
0.1609
LHb
0.1240
0.1801
0.1813

0.1304
0.1994
0.2029
Thal
0.1550
0.2188
0.2204

V1

VTA
0.1317
0.1907
0.1923
FrA
0.1164
0.1894
0.1912

Figure 4: The predictive patterns of individual neurons predicting multiple regions. (Left) A Hippocampus
cell is the best single cell predictor of the V1 LFP (Middle) A V1 cell with a relationship only to the V1 LFP.
(Right) A Nucleus Accumbens Shell cell that is equivalent in predictive ability to the best V1 cell.

in Figure 3(middle)  and shows that while the raw energy in this frequency band is much higher
after the move to the novel environment  the cells from the Hippocampus can explain much of the
additional energy in this band. In Figure 3(right)  we show the same result using only the cluster in
Figure 2. Note that there is a change around 10 minutes that is due to both a slight change in the
convolutional dictionary and a change in the neural ﬁring patterns.
4.2 Results on Sleep Data Set
The second data set was recorded from one mouse going through different sleep cycles over 6 hours.
64 microwires were implanted in 16 different regions of the brain  using the Prelimbix Cortex (PrL) 
Medial Orbital Frontal Cortex (MOFCCx)  the core and shell of the Nucleus Accumbens (NAc) 
Basal Amygdala (Amy)  Hippocampus (Hipp)  V1  Ventral Tegmental Area (VTA)  Substantia ni-
gra (Subnigra)  Medial Dorsal Thalamus (MDThal)  Lateral Habenula (LHb)  Dorsolateral Stria-
tum (DLS)  Dorsomedial Striatum (DMS)  Motor Cortex (M1)  Orbital Frontal Cortex (OFC)  and
Frontal Association Cortex (FrA). LFPs were averaged over all electrodes in an area and ﬁltered
from 3-50Hz and sampled at 125Hz  and L was set to 0.5 seconds. 163 total neurons (single units)
were detected using spike sorting  and the data were split into 360 1-minute time bins. The leave-
one-out predictive performance was higher for the dynamic single cell model on 159 out of 163
neurons predicting the Hippocampus LFP. The mean hold-out RFEs for all recorded regions of the
brain are shown in Table 2 for all models  and the clustering model is the best performing model in
15 of the 16 regions.
Previously published work looked at the predictability of the V1 LFP signal from individual V1
neurons [11 18 19]. Our experiments ﬁnd that the dictionary elements for all V1 cells (4 electrodes 
4 cells in this dataset) are time-invariant and match the single-cell time-invariant dictionary shape
of [11]. The dictionary elements for a single V1 cell predicting multiple regions are shown in Figure
4(middle; for simplicity  only a subset of brain regions recorded from are shown). This suggests that
the V1 cell has a connection to the V1 region  but no other brain region that was recorded from in
this model. However  cells in other brain regions showed functional connectivity to V1. The best
individual predictor is a cell in the Hippocampus shown in Figure 4(left). An additional example
cell is a cell in the Nucleus Accumbens shell that has the same RFE as the best V1 cell  and its shape
is shown in Figure 4(right).
Sleep states are typically deﬁned by dynamic changes in functional connectivity across brain regions
as measured by EEG (LFPs recorded from the scalp) [20]  but little is known about how single neu-
rons contribute to  or interact with  these network changes. To get sleep covariates  each second of
data was scored into “awake” or “sleep” states using the methods in [21]  and the sleep state was
averaged over the time bin. We deﬁned a time bin to be a sleep state if ≥ 95% of the individual sec-

7

−0.500.5−0.2−0.15−0.1−0.0500.050.10.15MeanFactorsforCellinHPTime SecondsAmplitude a.u.V1HPMDThalVTA−0.500.5−0.08−0.06−0.04−0.0200.020.04MeanFactorsforCellinV1Time SecondsAmplitude a.u.V1HPMDThalVTA−0.500.5−0.04−0.03−0.02−0.0100.010.020.03MeanFactorsforCellinNAcShellTime SecondsAmplitude a.u.V1HPMDThalVTAFigure 5: (Left) The cluster predicting the V1 region of the brain  matching known pattern for individual V1
cells [11  18]. (Middle Right) Clusters predicting the motor cortex that show positive (pro) and negative (anti)
relationships between amplitude and sleep.

Figure 6: Mean RFE when the animal is awake and when it is asleep. (Left) Cluster’s convolution factor is
stable  and shows only minor differences between sleep and awake prediction. (Middle and Right) Clusters
shown in Figure 5 (left and right)  depicting varying patterns with the mouse’s sleep state
onds are scored as a sleep state  and the animal is awake if ≤ 5% of the individual seconds are scored
as a sleep state. In Figure 5(middle) we show a cluster that is most strongly positively correlated
with sleep (pro-sleep)  and in Figure 5(right) we show a cluster that is most negatively correlated
with sleep (pro-awake). Both ﬁgures show the neuron locations as well as the mean waveform shape
during sleep and wake. In this case  the pro-sleep cluster is dominantly Hippocampus cells and the
anti-sleep cluster comes from many different regions. There may be concern that because these are
the maximally correlated clusters  that these results may be atypical. To address this concern  the
p-value for ﬁnding a cluster this strongly correlated has a p-value 4 × 10−6 for Pearson correlation
with the Bonferroni correction for multiple tests. Furthermore  4 of the 25 clusters detected showed
correlation above .4 between amplitude and sleep state  so this is not an isolated phenomena.
The RFE changes as both a function of frequency and sleep state for some clusters of neurons. Using
1Hz bandwidth frequency bins  in Figure 6 (middle and right) we show the mean RFE using only
the clusters in Figure 5 (middle and right). The cluster associated positively with sleeping shifts
its frequency peak and increases its ability to predict when the animal is sleeping. Likewise  the
sleep-decreased cluster performs worst at predicting when the animal is asleep. For comparison  in
Figure 6 (left) we include the frequency results for cluster with a stable dictionary element. The
total RFE is comparable and there is a not a dramatic shift in the peak frequency between the sleep
and awake states.
5 Conclusions
Novel models and methods are developed here to account for time-varying relationships between
neurons and LFPs. Within the context of our experiments  signiﬁcantly improved predictive perfor-
mance is realized when one accounts for temporal dynamics in the neuron-LFP interrelationship.
Further  the clustering model reveals which neurons have similar relationships to a speciﬁc brain re-
gion  and the frequencies that are predictable in the LFP change with known dynamics of the animal
state. In future work  these ideas can be incorporated with attempts to learn network structure  and
LFPs can be considered a common input when exploring networks of neurons [19  22  23]. More-
over  future experiments are being designed to place additional electrodes in a single brain region 
with the goal of detecting 100 neurons in a single brain region while recording LFPs in up to 20
regions. The methods proposed here will facilitate exploration of both the diversity of neurons and
the differences in functional connectivity on an individual neuron scale.
Acknowlegements The research reported here was funded in part by ARO  DARPA  DOE  NGA
and ONR. We thank the reviewers for their helpful comments.

8

−0.4−0.200.20.4−0.1−0.0500.05Time sAmplitude a.u.ClusterpredictingV1Region024MOFCThalV1AmygVTAPrLNumberofCells−0.4−0.200.20.4−0.0500.05DictionaryElement sAmplitude a.u.Pro-SleepClusterAwakeSleep0510HPSubnigraNumberofCells−0.4−0.200.20.4−0.04−0.0200.020.04DictionaryElement sAmplitude a.u.Anti-SleepClusterAwakeSleep0246DLSMOFCFrAPrLNumberofCells0102030405000.0050.010.0150.020.025Frequency HzMeanRFESleep-NeutralClusterRFEbyFrequencyAwakeSleep0102030405000.050.10.150.2Frequency HzMeanRFESleep-IncreasedClusterRFEbyFrequencyAwakeSleep0102030405000.010.020.030.040.05Frequency HzMeanRFESleep-DecreasedClusterRFEbyFrequencyAwakeSleepReferences
[1] F. Varela  J.P. Lachaux  E. Rodriguez  and J. Martinerie. The brainweb: phase synchronization and large-

scale integration. Nature Rev. Neuro.  2001.

[2] B. Pesaran  J.S. Pezaris  M. Sahani  P.P. Mitra  and R.A. Andersen. Temporal structure in neuronal activity

during working memory in macaque parietal cortex. Nature neuroscience  5:805–811  2002.

[3] C. Mehring  J. Rickert  E. Vaadia  S. Cardosa de Oliveira  A. Aertsen  and S. Rotter. Inference of hand
movements from local ﬁeld potentials in monkey motor cortex. Nature neuroscience  6(12):1253–1254 
2003.

[4] P.J. Uhlhaas and W. Singer. Abnormal neural oscillations and synchrony in schizophrenia. Nature Rev.

Neuro.  2010.

[5] M. Le Van Quyen and A. Bragin. Analysis of dynamic brain oscillations: methodological advances.

Trends in Neurosciences  2007.

[6] D.E. Carlson  J.T. Vogelstein  Q. Wu  W. Lian  M. Zhou  C.R. Stoetzner  D. Kipke  D. Weber  D.B.
Dunson  and L. Carin. Multichannel Electrophysiological Spike Sorting via Joint Dictionary Learning &
Mixture Modeling. IEEE TBME  2013.

[7] K Dzirasa  L Coque  MM Sidor  S Kumar  EA Dancy  JS Takahashi  C.A. McClung  and M.A.L. Nicolelis.
Lithium ameliorates nucleus accumbens phase-signaling dysfunction in a genetic mouse model of mania.
J. Neurosci.  December 2010.

[8] B. Chen  G. Polatkan  G. Sapiro  D. Dunson  and L. Carin. The hierarchical beta process for convolutional

factor analysis and deep learning. ICML  2011.

[9] H. Ishwaran and L.F. James. Gibbs Sampling Methods for Stick-Breaking Priors. JASA  March 2001.
[10] T.S. Ferguson. A Bayesian Analysis of Some Nonparametric Problems. Annals Stat.  March 1973.
[11] M. Rasch  N.K. Logothetis  and G. Kreiman. From neurons to circuits: linear estimation of local ﬁeld

potentials. J. Neurosci.  November 2009.

[12] M.C. Hughes and E.B. Sudderth. Memoized Online Variational Inference for Dirichlet Process Mixture

Models. NIPS  2013.

[13] K.A. Heller and Z. Ghahramani. Bayesian Hierarchical Clustering. ICML  2005.
[14] D.M. Blei and M.I. Jordan. Variational inference for Dirichlet process mixtures. Bayesian Analysis  2006.
IEEE Trans.
[15] S.J. Roberts and W.D. Penny. Variational Bayes for generalized autoregressive models.

Signal Process.  September 2002.

[16] H. Rue  S. Martino  and N. Chopin. Approximate Bayesian inference for latent Gaussian models by using

integrated nested Laplace approximations. J. Royal Stat. Soc.  2009.

[17] A. Calabrese and L. Paniski. Kalman ﬁlter mixture model for spike sorting of non-stationary data. J.

Neurosci. Methods  2010.

[18] I. Nauhaus  L. Busse  M. Carandini  and D.L. Ringach. Stimulus contrast modulates functional connec-

tivity in visual cortex. Nature Neuro.  January 2009.

[19] R.C. Kelly  M.A. Smith  R.E. Kass  and T.S. Lee. Local ﬁeld potentials indicate network state and account

for neuronal response variability. J. Comp. Neurosci.  December 2010.

[20] L.J. Larson-Prior  J.M. Zempel  T.S. Nolan  F.W. Prior  A.Z. Snyder  and M.E. Raichle. Cortical network

functional connectivity in the descent to sleep. PNAS  March 2009.

[21] K. Dzirasa  S. Ribeiro  R. Costa  L.M. Santos  S.-C. Lin  A. Grosmark  T.D. Sotnikova  R.R. Gainetdinov 
M.G. Caron  and M.A.L. Nicolelis. Dopaminergic control of sleep-wake states. J. Neurosci.  October
2006.

[22] J.W. Pillow and P. Latham. Neural characterization in partially observed populations of spiking neurons.

NIPS  2007.

[23] M.J. Rasch  A. Gretton  Y. Murayama  W. Maass  and N.K. Logothetis. Inferring spike trains from local

ﬁeld potentials. J. Neurophysiology  March 2008.

[24] D.I. Kim  P. Gopalan  D.M. Blei  and E.B. Sudderth. Efﬁcient Online Inference for Bayesian Nonpara-

metric Relational Models. NIPS  2012.

9

,David Carlson
Jana Schaich Borg
Kafui Dzirasa
Lawrence Carin
Ozan Sener
Hyun Oh Song
Ashutosh Saxena
Silvio Savarese