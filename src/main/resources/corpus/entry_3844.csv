2016,Normalized Spectral Map Synchronization,The algorithmic advancement of synchronizing maps is important in order to solve a wide range of practice problems  with possible large-scale dataset. In this paper  we provide theoretical justifications for spectral techniques for the map synchronization problem  i.e.  it takes as input a collection of objects and noisy maps estimated between pairs of objects  and outputs clean maps between all pairs of objects. We show that a simple normalized spectral method that projects the blocks of the top eigenvectors of a data matrix to the map space leads to surprisingly good results. As the noise is modelled naturally as random permutation matrix  this algorithm NormSpecSync leads to competing theoretical guarantees as state-of-the-art convex optimization techniques  yet it is much more efficient. We demonstrate the usefulness of our algorithm in a couple of applications  where it is optimal in both complexity and exactness among existing methods.,Normalized Spectral Map Synchronization

Yanyao Shen
UT Austin

Austin  TX 78712

Qixing Huang

shenyanyao@utexas.edu

huangqx@cs.utexas.edu

TTI Chicago and UT Austin

Austin  TX 78712

Nathan Srebro
TTI Chicago

Chicago  IL 60637
nati@ttic.edu

Sujay Sanghavi

UT Austin

Austin  TX 78712

sanghavi@mail.utexas.edu

Abstract

Estimating maps among large collections of objects (e.g.  dense correspondences
across images and 3D shapes) is a fundamental problem across a wide range of
domains. In this paper  we provide theoretical justiﬁcations of spectral techniques
for the map synchronization problem  i.e.  it takes as input a collection of objects
and noisy maps estimated between pairs of objects along a connected object graph 
and outputs clean maps between all pairs of objects. We show that a simple
normalized spectral method (or NormSpecSync) that projects the blocks of the top
eigenvectors of a data matrix to the map space  exhibits surprisingly good behavior
— NormSpecSync is much more efﬁcient than state-of-the-art convex optimization
techniques  yet still admitting similar exact recovery conditions. We demonstrate
the usefulness of NormSpecSync on both synthetic and real datasets.

1

Introduction

The problem of establishing maps (e.g.  point correspondences or transformations) among a collection
of objects is connected with a wide range of scientiﬁc problems  including fusing partially overlapped
range scans [1]  multi-view structure from motion [2]  re-assembling fractured objects [3]  analyzing
and organizing geometric data collections [4] as well as DNA sequencing and modeling [5]. A
fundamental problem in this domain is the so-called map synchronization  which takes as input noisy
maps computed between pairs of objects  and utilizes the natural constraint that composite maps
along cycles are identity maps to obtain improved maps.
Despite the importance of map synchronization  the algorithmic advancements on this problem remain
limited. Earlier works formulate map synchronization as solving combinatorial optimizations [1  6  7 
8]. These formulations are restricted to small-scale problems and are susceptible to local minimums.
Recent works establish the connection between the cycle-consistency constraint and the low-rank
property of the matrix that stores pairwise maps in blocks; they cast map synchronization as low-rank
matrix inference [9  10  11]. These techniques exhibit improvements on both the theoretical and
practical sides. In particular  they admit exact recovery conditions (i.e.  on the underlying maps can
be recovered from noisy input maps). Yet due to the limitations of convex optimization  all of these
methods do not scale well to large-scale datasets.
In contrast to convex optimizations  we demonstrate that spectral techniques work remarkably well
for map synchronization. We focus on the problem of synchronizing permutations and introduce
a robust and efﬁcient algorithm that consists of two simple steps. The ﬁrst step computes the top
eigenvectors of a data matrix that encodes the input maps  and the second step rounds each block of

30th Conference on Neural Information Processing Systems (NIPS 2016)  Barcelona  Spain.

the top-eigenvector matrix into a permutation matrix. We show that such a simple algorithm possesses
a remarkable denoising ability. In particular  its exact recovery conditions match the state-of-the-art
convex optimization techniques. Yet computation-wise  it is much more efﬁcient  and such a property
enables us to apply the proposed algorithm on large-scale dataset (e.g.  many thousands of objects).
Spectral map synchronization has been considered in [12  13] for input observations between all
pairs of objects. In contrast to these techniques  we consider incomplete pair-wise observations  and
provide theoretical justiﬁcations on a much more practical noise model.

2 Algorithm

In this section  we describe the proposed algorithm for permutation synchronization. We begin with
the problem setup in Section 2.1. Then we introduce the algorithmic details in Section 2.2.

2.1 Problem Setup
Suppose we have n objects S1 ···   Sn. Each object is represented by m points (e.g.  feature points
on images and shapes). We consider bijective maps φij : Si → Sj  1 ≤ i  j ≤ n between pairs of
objects. Following the convention  we encode each such map φij as a permutation matrix Xij ∈ Pm 
where Pm is the space of permutation matrices of dimension m:

Pm := {X|X ∈ [0  1]m×m  X1m = 1m  X T 1m = 1m} 

where 1m = (1 ···   1)T ∈ Rm is the vector whose elements are 1.
ij ∈ G along a connected
The input permutation synchronization consists of noisy permutations Xin
object graph G. As described in [4  9]  a widely used pipeline to generate such input is to 1) establish
the object graph G by connecting each object and similar objects using object descriptors (e.g. 
HOG [14] for images)   and 2) apply off-the-shelf pair-wise object matching methods to compute the
input pair-wise maps (e.g.  SIFTFlow [15] for images and BIM [16] for 3D shapes).
The output consists of improved maps between all of objects
Xij  1 ≤ i  j ≤ n.

2.2 Algorithm
We begin with deﬁning a data matrix Xobs ∈ Rnm×nm that encodes the initial pairwise maps in
blocks:

(cid:40) 1√

Xobs

ij =

Xin
ij 

didj
0 

(i  j) ∈ G
otherwise

(1)

where di := |{Sj|(Si  Sj) ∈ G}| is the degree of object Si in graph G.
Remark 1. Note that the way we encode the data matrix is different from [12  13] in the sense that
we follow the common strategy for handling irregular graphs and use a normalized data matrix.

The proposed algorithm is motivated from the fact that when the input pair-wise maps are correct  the
correct maps between all pairs of objects can be recovered from the leading eigenvectors of Xobs:
Proposition 2.1. Suppose there exist latent maps (e.g.  the ground-truth maps to one object) Xi  1 ≤
i ≤ n so that X in
j Xi  (i  j) ∈ G. Denote W ∈ Rnm×m as the matrix that collects the ﬁrst m
eigenvectors of Xobs in its columns. Then the underlying pair-wise maps can be computed from the
corresponding matrix blocks of matrix W W T :

ij = X T

X T

j Xi =

(W W T )ij 

1 ≤ i  j ≤ n.

(2)

(cid:80)n
i=1 di(cid:112)didj

The key insight of the proposed approach is that even when the input maps are noisy (i.e.  the blocks
of X obs are corrupted)  the leading eigenvectors of X obs are still stable under these perturbations
(we will analyze this stability property in Section 3). This motivates us to design a simple two-step
permutation synchronization approach called NormSpecSync. The ﬁrst step of NormSpecSync
computes the leading eigenvectors of W ; the second step of NormSpecSync rounds the induced

2

Algorithm 1 NormSpecSync

Input: Xobs based on (1)  δmax
Initialize W0: set W0 as an initial guess for the top-m orthonormal eigenvectors  k ← 0
while (cid:107)W (k) − W (k−1)(cid:107) > δmax do

= X obs · W (k) 

W (k+1)+
W (k+1)R(k+1) = W (k+1)+ 
k ← k + 1.

(QR factorization) 

end while
Set W = W (k) and X
spec
Round each X
i1
Output: Xij = X T

spec
i1 = (W W T )i1.
into the corresponding Xi1 by solving (3).
j1Xi1  1 ≤ i  j ≤ n.

matrix blocks (2) into permutations. In the following  we elaborate these two steps and analyze the
complexity. Algorithm 1 provides the pseudo-code.
Leading eigenvector computation. Since we only need to compute the leading m eigenvectors of
X obs  we propose to use generalized power method. This is justiﬁed by the observation that usually
there exists a gap between λm and λm+1. In fact  when the input pair-wise maps are correct  it is
easy to derive that the leading eigenvectors of X obs are given by:

λ1(X obs) = ··· = λm(X obs) = 1  λm+1(X obs) = λn−1(G) 

where λn−1(G) is the second largest eigenvalue of the normalized adjacency matrix of G. As we
will see later  the eigen-gap λm(X obs) − λm+1(X obs) is still persistent in the presence of corrupted
pair-wise maps  due to the stability of eigenvalues under perturbation.
Projection onto Pm. Denote X spec
Xij  1 ≤ i  j ≤ n obey Xij = X T
into Xik. Without losing generality  we set k = 1 in this paper.
The rounding is done by solving the following constrained optimization problem  which projects
X obs

(W W T )ij. Since the underlying ground-truth maps
jkXik  1 ≤ i  j ≤ n for any ﬁxed k  we only need to round X spec

i1 onto the space of permutations via the Frobenius norm:

(cid:80)n
i=1 di√

didj

:=

ik

ij

(cid:16)(cid:107)X(cid:107)2

F + (cid:107)X obs
i1 (cid:107)2

F − 2(cid:104)X  X obs

i1 (cid:105)(cid:17)

Xi1 = arg min
X∈Pm
= arg max
X∈Pm

(cid:107)X − X obs
i1 (cid:107)2
(cid:104)X  X obs
i1 (cid:105).

F = arg min
X∈Pm

(3)

1

ij

(See Algorithm 1).

The optimization problem described in (3) is the so-called linear assignment problem  which can be
solved exactly using the Hungarian algorithm whose complexity is O(m3) (c.f. [17]). Note that the
optimal solution of (3) is invariant under global scaling and shifting of X obs
and
m 11T when generating X obs
Time complexity of NormSpecSync. Each step of the generalized power method consists of a matrix-
vector multiplication and a QR factorization. The complexity of the matrix-vector multiplication 
which leverages of the sparsity in X obs  is O(nE · m2)  where nE is the number of edges in G.
The complexity of each QR factorization is O(nm3). As we will analyze laser  generalized power
method converges linearly  and setting δmax = 1/n provides a sufﬁciently accurate estimation
of the leading eigenvectors. So the total time complexity of the Generalized power method is

O(cid:0)(nEm2 + nm3(cid:1) log(n)). The time complexity of the rounding step is O(nm3). In summary  the
total complexity of NormSpecSync is O(cid:0)(nEm2 + nm3(cid:1) log(n)). In comparison  the complexity of

(cid:80)n
i=1 di√

i1   so we omit

the SDP formulation [9]  even when it is solved using the fast ADMM method (alternating direction
of multiplier method)  is at least O(n3m3nadmm. So NormSpecSync exhibits signiﬁcant speedups
when compared to SDP formulations.

didj

3

3 Analysis

In this section  we provide an analysis of NormSpecSync under a generalized Erd˝os-Rényi noise
model.

3.1 Noise Model

The noise model we consider is given by two parameters m and p. Speciﬁcally  we assume the
observation graph G is ﬁxed. Then independently for each edge (i  j) ∈ E 

(cid:26) Im with probability p

Pij with probability 1 − p

Xin

ij =

(4)

where Pij ∈ Pm is a random permutation.
Remark 2. The noise model described above assumes the underlying permutations are identity maps.
In fact  one can assume a generalized noise model

(cid:26) X T

Xin

ij =

j1Xi1 with probability p

with probability 1 − p

Pij

where Xi1  1 ≤ i ≤ n are pre-deﬁned underlying permutations from object Si to the ﬁrst object S1.
However  since Pij are independent of Xi1. It turns out the model described above is equivalent to

(cid:26) Im with probability p

Pij with probability 1 − p

Xj1Xin

ijX T

i1 =

Where Pij are independent random permutations. This means it is sufﬁcient to consider the model
described in (4).
Remark 3. The fundamental difference between our model and the one proposed in [11] or the ones
used in low-rank matrix recovery [18] is that the observation pattern (i.e.  G) is ﬁxed  while in other
models it also follows a random model. We argue that our assumption is more practical because
the observation graph is constructed by comparing object descriptors and it is dependent on the
distribution of the input objects. On the other hand  ﬁxing G signiﬁcantly complicates the analysis of
NormSpecSync  which is the main contribution of this paper.

3.2 Main Theorem

Now we state the main result of the paper.

Theorem 3.1. Let dmin := min1≤i≤n di  davg :=(cid:80)

i di/n  and denote ρ as the second top eigen-
√
value of normalized adjacency matrix of G. Assume dmin = Ω(
n ln3 n)  davg = O(dmin) 
ρ < min{p  1/2}. Then under the noise model described above  NormSpecSync recovers the
underlying pair-wise maps with high probability if

for some constant C.

p > C ·

ln3 n
√
dmin/

 

n

(5)

Proof Roadmap. The proof of Theorem 3.1 combines two stability bounds. The ﬁrst one considers
the projection step:
Proposition 3.1. Consider a permutation matrix X = (xij) ∈ Pm and another matrix X = (xij) ∈
Rm×m. If (cid:107)X − X(cid:107) < 1

2   then

X = arg min
Y ∈Pm

Proof. The proof is quite straight-forward. In fact 

(cid:107)Y − X(cid:107)2
F .

(cid:107)X − X(cid:107)∞ ≤ (cid:107)X − X(cid:107) <

1
2

.

4

(a) NormSpecSync (2.25 seconds)

(b) SDP (203.12 seconds)

(c) DiffSync(1.07 seconds)

Figure 1: Comparisons between NormSpecSync  SDP[9]  DiffSync[13] on the noise model described in Sec. 2.

This means the corresponding element xij of each non-zero element in xij is dominant in its row and
column  i.e. 

xij (cid:54)= 0 ↔ xij > max(max
k(cid:54)=j

xik  max
k(cid:54)=i

xkj) 

which ends the proof.
The second bound concerns the block-wise stability of the leading eigenvectors of X obs:
Lemma 3.1. Under the assumption of Theorem 3.1  then w.h.p. 

(cid:13)(cid:13)(cid:13)(cid:13)(cid:80)n

√
i=1 di
did1

(cid:13)(cid:13)(cid:13)(cid:13) <

(W W T )i1 − Im

1 ≤ i ≤ n.

1
3

 

(cid:4)

(6)

It is easy to see that we can prove Theorem 3.1 by combing Lemma 3.1 and Prop. 3.1. Yet unlike
Prop. 3.1  the proof of Lemma 3.1 is much harder. The major difﬁculty is that (6) requires controlling
each block of the leading eigenvectors  namely  it requires a L∞ bound  whereas most stability results
on eigenvectors are based on the L2-norm. Due to space constraint  we defer the proof of Lemma 3.1
(cid:4)
to Appendix A and the supplemental material.
Near-optimality of NormSpecSync. Theorem 3.1 implies that NormSpecSync is near-optimal with
respect to the information theoretical bound described in [19]. In fact  when G is a clique  (5) becomes
p > C · ln3(n)√
n   which aligns with the lower bound in [19] up to a polylogarithmic factor. Following
the model described in [19]  we can also assume that the observation graph G is sampled with a
density factor q  namely  two objects are connected independently with probability q. In this case 
it is easy to see that dmin > O(nq/ ln n) w.h.p.  and (5) becomes p > C · ln4 n√
nq . This bound also
stays within a polylogarithmic factor from the lower bound in [19]  indicating the near-optimality of
NormSpecSync.

4 Experiments

In this section  we perform quantitative evaluations of NormSpecSync on both synthetic and real
examples. Experimental results show that NormSpecSync is superior to state-of-the-art map syn-
chronization methods in the literature. We organize the remainder of this section as follows. In
Section 4.1  we evaluate NormSpecSync on synthetic examples. Then in section 4.2  we evaluate
NormSpecSync on real examples.

4.1 Quantitative Evaluations on Synthetic Examples

We generate synthetic data by following the same procedure described in Section 2. Speciﬁcally 
each synthetic example is controlled by three parameters G  m  and p. Here G speciﬁes the input
graph; m describes the size of each permutation matrix; p controls the noise level of the input maps.
The input maps follow a generalized Erdos-Renyi model  i.e.  independently for each edge (i  j) ∈ G
in the input graph  with probability p the input map X in
ij is a random
permutation. To simplify the discussion  we ﬁx m = 10  n = 200 and vary the observation graph G
and p to evaluate NormSpecSync and existing algorithms.

ij = Im  and otherwise X in

5

Varying graph densityGraph density0.10.30.50.70.9p-true0.10.20.30.40.5Varying graph densityGraph density0.10.30.50.70.9p-true0.10.20.30.40.5Varying graph densityGraph density0.10.30.50.70.9p-true0.10.20.30.40.5(a) NormSpecSync

(b) SpecSync

Figure 2: Comparison between NorSpecSync and SpecSync on irregular observation graphs.

2 − q)n and ( 1

Dense graph versus sparse graph. We ﬁrst study the performance of NormSpecSync with respect
to the density of the graph. In this experiment  we control the density of G by following a standard
Erd˝os-Rényi model with parameter q  namely independently  each edge is connected with probability
q. For each pair of ﬁxed p and q  we generate 10 examples. We then apply NormSpecSync and count
the ratio that the underlying permutations are recovered. Figure 1(a) illustrates the success rate of
NormSpecSync on a grid of samples for p and q. Blue and yellow colors indicate it succeeded and
failed on all the examples  respectively  and the colors in between indicate a mixture of success and
failure. We can see that NormSpecSync tolerates more noise when the graph becomes denser. This
aligns with our theoretical analysis result.
NormSpecSync versus SpecSync. We also compare NormSpecSync with SpecSync [12]  and
show the advantage of NormSpecSync on irregular observation graphs. To this end  we generate
G using a different model. Speciﬁcally  we let the degree of the vertex to be uniformly distribute
between ( 1
2 + q)n. As illustrated in Figure 2  when q is small  i.e.  all the vertices have
similar degrees  the performance of NormSpecSync and SpecSync are similar. When q is large  i.e. 
G is irregular  NormSpecSync tend to tolerate more noise than SpecSync. This shows the advantage
of utilizing a normalized data matrix.
NormSpecSync versus DiffSync. We proceed to compare NormSpecSync with DiffSync [13] 
which is a permutation synchronization method based on diffusion distances. NormSpecSync and
DiffSync exhibit similar computation efﬁciency. However  NormSpecSync can tolerate signiﬁcantly
more noise than DiffSync  as illustrated in Figure 1(c).
NormSpecSync versus SDP.
Finally  we compare NormSpecSync with SDP [9]  which formulates
permutation synchronization as solving a semideﬁnite program. As illustrated in Figure 1(b)  the
exact recovery ability of NormSpecSync and SDP are similar. This aligns with our theoretical analysis
result  which shows the near-optimality of NormSpecSync under the noise model of consideration.
Yet computationally  NormSpecSync is much more efﬁcient than SDP. The averaged running time for
SpecSync is 2.25 second. In contrast  SDP takes 203.12 seconds in average.

4.2 Quantitative Evaluations on Real Examples

In this section  we present quantitative evaluation of NormSpecSync on real datasets.
CMU Hotel/House.
We ﬁrst evaluate NormSpecSync on CMU Hotel and CMU House
datasets [20]. The CMU Hotel dataset contains 110 images  where each image has 30 marked
feature points. In our experiment  we estimate the initial map between a pair of images using
RANSAC [21]. We consider two observation graphs: a clique observation graph Gf ull  where we
have initial maps computed between all pairs of images  and a sparse observation graph Gsparse.
Gsparse is constructed to only connect similar images. In this experiment  we connect an edge between
two images if the difference in their HOG descriptors [22] is smaller than 1
2 of the average descriptor
differences among all pairs of images. Note that Gsparse shows high variance in terms of vertex

6

Varying vertex degreesIrregularty0.00.10.20.30.4p-true0.10.20.30.40.5Varying vertex degreesIrregularty0.00.10.20.30.4p-true0.10.20.30.40.5Figure 3: Comparison between NorSpecSync  SpecSync  DiffSync and SDP on CMU Hotel/House and SCAPE.
In each dataset  we consider a full observation graph and a sparse observation graph that only connects potentially
similar objects.

degree. The CMU House dataset is similar to CMU Hotel  containing 100 images and exhibiting
slightly bigger intra-cluster variability than CMU Hotel. We construct the observation graphs and the
initial maps in a similar fashion. For quantitative evaluation  we measure the cumulative distribution
of distances between the predicted target points and the ground-truth target points.
Figure 3(Left) compares NormSpecSync with the SDP formulation  SpecSync  and DiffSync. On
both full and sparse observation graphs  we can see that NormSpecSync  SDP and SpecSync are
superior to DiffSync. The performance of NormSpecSync and SpecSync on Gf ull is similar  while
on Gsparse  NormSpecSync shows a slight advantage  due to its ability to handle irregular graphs.
Moreover  although the performance of NormSpecSync and SDP are similar  SDP is much slower
than NormSpecSync. For example  on Gsparse  SDP took 1002.4 seconds  while NormSpecSync
only took 3.4 seconds.
SCAPE. Next we evaluate NormSpecSync on the SCAPE dataset. SCAPE consists of 71 different
poses of a human subject. We uniformly sample 128 points on each model. Again we consider a
full observation graph Gf ull and a sparse observation graph Gsparse. Gsparse is constructed in the
same way as above  except we use the shape context descriptor [4] for measuring the similarity
between 3D models. In addition  the initial maps are computed from blended-intrinsic-map [16] 
which is the state-of-the-art technique for computing dense correspondences between organic shapes.
For quantitative evaluation  we measure the cumulative distribution of geodesic distances between
the predicted target points and the ground-truth target points. As illustrated in Figure 3(Right)  the
relative performance between NormSpecSync and the other three algorithms is similar to CMU Hotel
and CMU House. In particular  NormSpecSync shows an advantage over SpecSync on Gsparse. Yet
in terms of computational efﬁciency  NormSpecSync is far better than SDP.

5 Conclusions
In this paper  we propose an efﬁcient algorithm named NormSpecSync towards solving the permuta-
tion synchronization problem. The algorithm adopts a spectral view of the mapping problem and
exhibits surprising behavior both in terms of computation complexity and exact recovery conditions.
The theoretical result improves upon existing methods from several aspects  including a ﬁxed obser-

7

Euclidean distance (pixels)0123456% correspondences0102030405060708090100CMU-G-FullRANSACDiffSyncSpecSyncNonSpecSyncSDPEuclidean distance (pixels)0123456% correspondences0102030405060708090100CMU-G-SparseRANSACDiffSyncSpecSyncNonSpecSyncSDPGeodesic distance (diameter)00.050.10.150.2% correspondences0102030405060708090100SCAPE-G-FullRANSACDiffSyncSpecSyncNonSpecSyncSDPGeodesic distance (diameter)00.050.10.150.2% correspondences0102030405060708090100SCAPE-G-SparseRANSACDiffSyncSpecSyncNonSpecSyncSDPvation graph and a practical noise method. Experimental results demonstrate the usefulness of the
proposed approach.
There are multiple opportunities for future research. For example  we would like to extend NormSpec-
Sync to handle the case where input objects only partially overlap with each other. In this scenario 
developing and analyzing suitable rounding procedures become subtle. Another example is to extend
NormSpecSync for rotation synchronization  e.g.  by applying Spectral decomposition and rounding
in an iterative manner.
Acknowledgement. We would like to thank the anonymous reviewers for detailed comments on how
to improve the paper. The authors would like to thank the support of DMS-1700234  CCF-1302435 
CCF-1320175  CCF-1564000  CNS-0954059  IIS-1302662  and IIS-1546500.

A Proof Architecture of Lemma 3.1

2 AD− 1

The normalized adjacency matrix ¯A = D− 1

In this section  we provide a roadmap for the proof of Lemma 3.1. The detailed proofs are deferred to
the supplemental material.
Reformulate the observation matrix.
2 can
be decomposed as ¯A = ssT + V ΛV T   where the dominant eigenvalue is 1 and corresponding
p M = ¯A ⊗ Im + ˜N  and it is clear
eigenvector is s. We reformulate the observation matrix as 1
to see that the ground truth result relates to the term (ssT ) ⊗ Im  while the noise comes from two
terms: (V ΛV T ) ⊗ Im and ˜N. More speciﬁcally  the noise not only comes from the randomness of
uncertainty of the measurements  but also from the graph structure  and we use ρ to represent the
spectral norm of Λ. When the graph is disconnected or near disconnected  ρ is close to 1 and it is
impossible to recover the ground truth.
Bound the spectral norm of ˜N.
√
in each block. In a complete graph  the spectral norm is bounded by O( 1
p
considering the graph structure  we give a O(
) bound.
Measure the block-wise distance between U and s ⊗ Im.
2   we
want to show the distance between U and s ⊗ 1m is small  where the distance function dist(·) is
deﬁned as:

The noise term ˜N consists of random matrices with mean zero
n )  however  when

Let M = U ΣU T + U2Σ2U T

1
dmin

√

p

 

R:RRT =I

dist(U  V ) = min

1  ···   X T

(cid:107)X(cid:107)B = max

and this B−norm for any matrix X represented in the form X = [X T
deﬁned as

(7)
n ]T ∈ Rmn×m is
(8)
More speciﬁcally  we bound the distance between U and s ⊗ Im by constructing a series of matrix
{Ak}  and we can show for some k = O(log n)  the distances from s ⊗ Ak to both U and s ⊗ Im
are small. Therefore  by using the triangle inequality  we can show that U and s ⊗ Im is close.
Sketch proof of Lemma 3.1. Once we are able to show that there exists some rotation matrix R 
such that dist(U  s ⊗ Im) is in the order of o( 1√
n )  then it is straightforward to prove Lemma 3.1.
Intuitively  this is because the measurements from the eigenvectors is close enough to the ground
truth  hence their second moment will still be close. Formally speaking 

(cid:107)Xi(cid:107)F .

i

(cid:13)(cid:13)(cid:13)U − V R

(cid:13)(cid:13)(cid:13)B

(cid:13)(cid:13)UiU T
j − (si · Im)(sj · Im)(cid:13)(cid:13)
=(cid:13)(cid:13)UiRRT U T
j − (si · Im)(sj · Im)(cid:13)(cid:13)
=(cid:13)(cid:13)UiR(RT U T
j − (sj · Im)T ) + (UiR − si · Im)(sj · Im)T(cid:13)(cid:13)
≤(cid:13)(cid:13)Ui
(cid:13)(cid:13) · dist(U  s ⊗ Im) + dist(U  s ⊗ Im) ·(cid:13)(cid:13)sj · Im
(cid:13)(cid:13)(cid:13)(cid:80)n
(cid:13)(cid:13)(cid:13)UiU T
(cid:13)(cid:13)(cid:13) =
i=1 di(cid:112)didj

(cid:80)n
i=1 di(cid:112)didj

j − (si · Im)(sj · Im)

j − Im

UiU T

(cid:13)(cid:13)

(9)
(10)
(11)
(12)

(13)

(cid:13)(cid:13)(cid:13) 

On the other hand  notice that

and we only need to show that (13) is in the order of o(1). The details are included in the supplemental
material.

8

References
[1] D. F. Huber  “Automatic three-dimensional modeling from reality ” Tech. Rep.  2002.

[2] D. Crandall  A. Owens  N. Snavely  and D. Huttenlocher  “Discrete-continuous optimization for large-scale
structure from motion ” in IEEE Conference on Computer Vision and Pattern Recognition (CVPR)  2011 
pp. 3001–3008.

[3] Q.-X. Huang  S. Flöry  N. Gelfand  M. Hofer  and H. Pottmann  “Reassembling fractured objects by

geometric matching ” in ACM SIGGRAPH 2006 Papers  2006  pp. 569–578.

[4] V. G. Kim  W. Li  N. Mitra  S. DiVerdi  and T. Funkhouser  “Exploring collections of 3D models using
fuzzy correspondences ” Transactions on Graphics (Proc. of SIGGRAPH 2012)  vol. 31  no. 4  Aug. 2012.

[5] W. Marande and G. Burger  “Mitochondrial dna as a genomic jigsaw puzzle ” Science  vol. 318  Jul. 2007.

[6] C. Zach  M. Klopschitz  and M. Pollefeys  “Disambiguating visual relations using loop constraints.” in

IEEE Conference on Computer Vision and Pattern Recognition (CVPR)  2010  pp. 1426–1433.

[7] D. Crandall  A. Owens  N. Snavely  and D. Huttenlocher  “Discrete-continuous optimization for large-scale
IEEE 

structure from motion ” in IEEE Conference on Computer Vision and Pattern Recognition (CVPR).
2011  pp. 3001–3008.

[8] A. Nguyen  M. Ben-Chen  K. Welnicka  Y. Ye  and L. Guibas  “An optimization approach to improving
collections of shape maps ” in Eurographics Symposium on Geometry Processing (SGP)  2011  pp. 1481–
1491.

[9] Q. Huang and L. Guibas  “Consistent shape maps via semideﬁnite programming ” Computer Graphics
Forum  Proc. Eurographics Symposium on Geometry Processing (SGP)  vol. 32  no. 5  pp. 177–186  2013.

[10] L. Wang and A. Singer  “Exact and stable recovery of rotations for robust synchronization ” CoRR  vol.

abs/1211.2441  2012.

[11] Y. Chen  L. J. Guibas  and Q. Huang  “Near-optimal joint object matching via convex relaxation ” 2014.

[Online]. Available: http://arxiv.org/abs/1402.1473

[12] D. Pachauri  R. Kondor  and V. Singh  “Solving the multi-way matching problem by permutation synchro-

nization ” in Advances in Neural Information Processing Systems  2013  pp. 1860–1868.

[13] D. Pachauri  R. Kondor  G. Sargur  and V. Singh  “Permutation diffusion maps (pdm) with application to
the image association problem in computer vision ” in Advances in Neural Information Processing Systems 
2014  pp. 541–549.

[14] N. Dalal and B. Triggs  “Histograms of oriented gradients for human detection ” in Proceedings of the 2005
IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR’05) - Volume 1 -
Volume 01  ser. CVPR ’05  2005  pp. 886–893.

[15] C. Liu  J. Yuen  A. Torralba  J. Sivic  and W. T. Freeman  “Sift ﬂow: Dense correspondence across different
scenes ” in Proceedings of the 10th European Conference on Computer Vision: Part III  ser. ECCV ’08 
2008  pp. 28–42.

[16] V. G. Kim  Y. Lipman  and T. Funkhouser  “Blended intrinsic maps ” in ACM Transactions on Graphics

(TOG)  vol. 30  no. 4. ACM  2011  p. 79.

[17] R. Burkard  M. Dell’Amico  and S. Martello  Assignment Problems. Philadelphia  PA  USA: Society for

Industrial and Applied Mathematics  2009.

[18] E. J. Candès  X. Li  Y. Ma  and J. Wright  “Robust principal component analysis?” J. ACM  vol. 58  no. 3 

pp. 11:1–11:37  Jun. 2011. [Online]. Available: http://doi.acm.org/10.1145/1970392.1970395

[19] Y. Chen  C. Suh  and A. J. Goldsmith  “Information recovery from pairwise measurements: A shannon-

theoretic approach ” CoRR  vol. abs/1504.01369  2015.

[20] T. S. Caetano  L. Cheng  Q. V. Le  and A. J. Smola  “Learning graph matching ” in Computer Vision  2007.

ICCV 2007. IEEE 11th International Conference on.

IEEE  2007  pp. 1–8.

[21] M. A. Fischler and R. C. Bolles  “Random sample consensus: A paradigm for model ﬁtting with applications

to image analysis and automated cartography ” Commun. ACM  vol. 24  no. 6  pp. 381–395  Jun. 1981.

[22] R. Osada  T. Funkhouser  B. Chazelle  and D. Dobkin  ACM Trans. Graph.  vol. 21  no. 4  pp. 807–832 

2002.

9

,Yanyao Shen
Qixing Huang
Nati Srebro
Sujay Sanghavi
Aaron Sidford
Mengdi Wang
Xian Wu
Lin Yang
Yinyu Ye