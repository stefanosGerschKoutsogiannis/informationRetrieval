2011,Newtron: an Efficient Bandit algorithm for Online Multiclass Prediction,We present an efficient algorithm for the problem of online multiclass prediction with bandit feedback in the fully adversarial setting. We measure its regret with respect to the log-loss defined in \cite{AbernethyR09}  which is parameterized by a scalar \(\alpha\). We prove that the regret of \newtron is \(O(\log T)\) when \(\alpha\) is a constant that does not vary with horizon \(T\)  and at most \(O(T^{2/3})\) if \(\alpha\) is allowed to increase to infinity with \(T\). For \(\alpha\) = \(O(\log T)\)  the regret is bounded by \(O(\sqrt{T})\)  thus solving the open problem of \cite{KST08  AbernethyR09}. Our algorithm is based on a novel application of the online Newton method \cite{HAK07}. We test our algorithm and show it to perform well in experiments  even when \(\alpha\) is a small constant.,NEWTRON: an Efﬁcient Bandit algorithm for Online

Multiclass Prediction

Elad Hazan

Department of Industrial Engineering

Technion - Israel Institute of Technology

Haifa 32000 Israel

ehazan@ie.technion.ac.il

skale@yahoo-inc.com

Satyen Kale

Yahoo! Research

4301 Great America Parkway

Santa Clara  CA 95054

Abstract

We present an efﬁcient algorithm for the problem of online multiclass prediction
with bandit feedback in the fully adversarial setting. We measure its regret with
respect to the log-loss deﬁned in [AR09]  which is parameterized by a scalar α.
We prove that the regret of NEWTRON is O(log T ) when α is a constant that does
not vary with horizon T   and at most O(T 2/3) if α is allowed to increase to inﬁnity
with T . For α = O(log T )  the regret is bounded by O(
T )  thus solving the open
problem of [KSST08  AR09]. Our algorithm is based on a novel application of the
online Newton method [HAK07]. We test our algorithm and show it to perform
well in experiments  even when α is a small constant.

√

1

Introduction

Classiﬁcation is a fundamental task of machine learning  and is by now well understood in its basic
variants. Unlike the well-studied supervised learning setting  in many recent applications (such as
recommender systems  ad selection algorithms  etc.) we only obtain limited feedback about the true
label of the input (e.g.  in recommender systems  we only get feedback on the recommended items).
Several such problems can be cast as online  bandit versions of multiclass prediction problems1. The
general framework  called the “contextual bandits” problem [LZ07]  is as follows. In each round 
the learner receives an input x in some high dimensional feature space (the “context”)  and produces
an action in response  and obtains an associated reward. The goal is to minimize regret with respect
to a reference class of policies specifying actions for each context.
In this paper  we consider the special case of multiclass prediction  which is a fundamental problem
in this area introduced by Kakade et al [KSST08]. Here  a learner obtains a feature vector  which
is associated with an unknown label y which can take one of k values. Then the learner produces
a prediction of the label  ˆy. In response  only 1 bit of information is given  whether the label is
correct or incorrect. The goal is to design an efﬁcient algorithm that minimizes regret with respect
to a natural reference class of policies: linear predictors. Kakade et al [KSST08] gave an efﬁcient
algorithm  dubbed BANDITRON. Their algorithm attains regret of O(T 2/3) for a natural multiclass
√
hinge loss  and they ask the question whether a better regret bound is possible. While the EXP4
T log T ) regret bound  it is highly inefﬁ-
algorithm [ACBFS03]  applied to this setting  has an O(
cient  requiring O(T n/2) time per iteration  where n is the dimension of the feature space. Ideally 
one would like to match or improve the O(
T log T ) regret bound of the EXP4 algorithm with an
efﬁcient algorithm (for a suitable loss function).
This question has received considerable attention. In COLT 2009  Abernethy and Rakhlin [AR09]
formulated the open question precisely as minimizing regret for a suitable loss function in the fully

√

1For the basic bandit classiﬁcation problem see [DHK07  RTB07  DH06  FKM05  AK08  MB04  AHR08].

1

√

√

the original paper of [KSST08]  gives a O(

adversarial setting (and even offered a monetary reward for a resolution of the problem). Some
special cases have been successfully resolved:
T )
√
bound in the noiseless large-margin case. More recently  Crammer and Gentile [CG11] gave a
T log T ) regret bound via an efﬁcient algorithm based on the upper conﬁdence bound method
O(
under a semi-adversarial assumption on the labels: they are generated stochastically via a speciﬁc
linear model (with unknown parameters which change over time). Yet the general (fully adversarial)
case has been unresolved as of now.
In this paper we address this question and design a novel algorithm for the fully adversarial setting
with its expected regret measured with respect to log-loss function deﬁned in [AR09]  which is
parameterized by a scalar α. When α is a constant independent of T   we get a much stronger
guarantee than required by the open problem: the regret is bounded by O(log T ). In fact  the regret
is bounded by O(
T ) even for α = Θ(log T ). Our regret bound for larger values of α increases
smoothly to a maximum of O(T 2/3)  matching that of BANDITRON in the worst case.
The algorithm is efﬁcient to implement  and it is based on the online Newton method introduced
in [HAK07]; hence we call the new algorithm NEWTRON. We implement the algorithm (and a
faster variant  PNEWTRON) and test it on the same data sets used by Kakade et al [KSST08]. The
experiments show improved performance over the BANDITRON algorithm  even for α as small as 10.

2 Preliminaries

product  i.e. v · w =(cid:80)n

2.1 Notation
Let [k] denote the set of integers {1  2  . . .   k}  and ∆k ⊆ Rk the set of distributions on [k].
For any Rn  let 1  0 denote the all 1s and all 0s vectors respectively  and let I denote the identity
matrix in Rn×n. For two (row or column) vectors v  w ∈ Rn  we denote by v · w their usual inner
i=1 viwi. We denote by (cid:107)v(cid:107) the (cid:96)2 norm of v. For a vector v ∈ Rn  denote
by diag(v) the diagonal matrix in Rn×n where the ith diagonal entry equals vi.
For a matrix W ∈ Rk×n  denote by W1  W2  . . .   Wk its rows  which are (row) vectors in Rn.
To avoid deﬁning unnecessary notation  we will interchangeably use W to denote both a matrix in
Rk×n or a (column) vector in Rkn. The vector form of the matrix W is formed by arranging its
rows one after the other  and then taking the transpose (i.e.  the vector [W1|W2|···|Wk](cid:62)). Thus 
for two matrices V and W  V · W denotes their inner product in their vector form. For i ∈ [n] and
l ∈ [k]  denote by Eil the matrix which has 1 in its (i  l)th entry  and 0 everywhere else.
For a matrix W  we denote by (cid:107)W(cid:107) the Frobenius norm of W  which is also the usual (cid:96)2 norm
of the vector form of W  and so the notation is consistent. Also  we denote by (cid:107)W(cid:107)2 the spectral
norm of W  i.e. the largest singular value of W.
For two matrices W and V denote by W⊗ V their Kronecker product [HJ91]. For two square sym-
metric matrices W  V of like order  denote by W (cid:23) V the fact that W− V is positive semideﬁnite 
i.e. all its eigenvalues are non-negative. A useful fact of the Kronecker product is the following:
if W  V are symmetric matrices such that W (cid:23) V  and if U is a positive semideﬁnite symmetric
matrix  then W⊗U (cid:23) V⊗U. This follows from the fact that if W  U are both symmetric  positive
semideﬁnite matrices  then so is their Kronecker product W ⊗ U.

2.2 Problem setup

Learning proceeds in rounds. In each round t  for t = 1  2  . . .   T   we are presented a feature vector
xt ∈ X   where X ⊆ Rn  and (cid:107)x(cid:107) ≤ R for all x ∈ X . Here R is some speciﬁed constant. Associated
with xt is an unknown label yt ∈ [k]. We are required to produce a prediction  ˆyt ∈ [k]  as the label
of xt. In response  we obtain only 1 bit of information: whether ˆyt = yt or not. In particular  when
ˆyt (cid:54)= yt  the identity of yt remains unknown (although one label  ˆyt  is ruled out).
The learner’s hypothesis class is parameterized by matrices W ∈ Rk×n with (cid:107)W(cid:107) ≤ D  for some
speciﬁed constant D. Denote the set of such matrices by K. Given a matrix W ∈ K with the rows

2

W1  W2  . . .   Wk  the prediction associated with W for xt is
Wi · xt.

ˆyt = arg max
i∈[k]

While ideally we would like to minimize the 0 − 1 loss suffered by the learner  for computational
reasons it is preferable to consider convex loss functions. A natural choice used in Kakade et
al [KSST08] is the multi-class hinge loss:

(cid:96)(W  (xt  yt)) = max
i∈[k]\yt

[1 − Wyt · xt + Wi · xt]+.

Other suitable loss functions (cid:96)(· ·) may also be used. The ultimate goal of the learner is to minimize
regret  i.e.

Regret :=

(cid:96)(Wt  (xt  yt)) − min
W(cid:63)∈K

(cid:96)(W(cid:63)  (xt  yt)).

T(cid:88)

t=1

T(cid:88)

t=1

A different loss function was proposed in an open problem by Abernethy and Rakhlin in COLT
2009 [AR09]. We use this loss function in this paper and deﬁne it now.
We choose a constant α which parameterizes the loss function. Given a matrix W ∈ K and an
example (x  y) ∈ X × [k]  deﬁne the function P : K × X → ∆k as

P(W  x)i =

(cid:80)
exp(αWi · x)
j exp(αWj · x)

.

Now let p = P(W  x). Suppose we make our prediction ˆyt by sampling from p.
A natural loss function for this scheme is log-loss deﬁned as follows:

(cid:96)(W  (x  y)) = − 1
α

log(py) = − 1
α

= −Wy · x +

1
α

log

(cid:33)

(cid:32)

(cid:80)
exp(αWy · x)
(cid:17)
j exp(αWk · x)
j exp(αWj · x)

.

log

(cid:16)(cid:80)

The log-loss is always positive. As α becomes large  this log-loss function has the property that
when the prediction given by W for x is correct  it is very close to zero  and when the prediction is
incorrect  it is roughly proportional to the margin of the incorrect prediction over the correct one.
The algorithm and its analysis depend upon the the gradient and Hessian of the loss function w.r.t.
W. The following lemma derives these quantities (proof in full version). Note that in the following 
W is to be interpreted as a vector W ∈ Rkn.
Lemma 1. Fix a matrix W ∈ K and an example (x  y) ∈ X × [k]  and let p = P(W  x). Then we
have

∇(cid:96)(W  (x  y)) = (p − ey) ⊗ x and ∇2(cid:96)(W  (x  y)) = α(diag(p) − pp(cid:62)) ⊗ xx(cid:62).

In the analysis  we need bounds on the smallest non-zero eigenvalue of the (diag(p) − pp(cid:62)) factor
of the Hessian. Such bounds are given in the full version2 For the sake of the analysis  however  the
matrix inequality given in Lemma 2 below sufﬁces. It is given in terms of a parameter δ  which is
the minimum probability of a label in any distribution P(W  x).
Deﬁnition 1. Deﬁne δ := minW∈K x∈X mini P(W  x)i.
We have the following (loose) bound on δ  which follows easily using the fact that |Wi · x| ≤ RD:
(1)
Lemma 2. Let W ∈ K be any weight matrix  and let H ∈ Rk×k be any symmetric matrix such that
H1 = 0. Then we have

δ ≥ exp(−2αRD)/k.

∇2(cid:96)(W  (x  y)) (cid:23) αδ
(cid:107)H(cid:107)2

H ⊗ xx(cid:62).

2Our earlier proof used Cheeger’s inequality. We thank an anonymous referee for a simpliﬁed proof.

3

Algorithm 1 NEWTRON. Parameters: β  γ
1: Initialize W(cid:48)
1 = 0.
2: for t = 1 to T do
Obtain the example xt.
3:
t = (1 − γ) · pt + γ
Let pt = P(W(cid:48)
k 1.
4:
Output the label ˆyt by sampling from p(cid:48)
5:
probability (1 − γ)  and Wt = 0 with probability γ.
Obtain feedback  i.e. whether ˆyt = yt or not.
if ˆyt = yt then

t  xt)  and set p(cid:48)

·(cid:0) 1
t(ˆyt) ·(cid:0)eˆyt − 1

p(cid:48)
t(yt)

(cid:1) ⊗ xt and κt := p(cid:48)
k 1(cid:1) ⊗ xt and κt := 1.

k 1 − eyt

Deﬁne ˜∇t := 1−pt(yt)
Deﬁne ˜∇t := pt(ˆyt)

p(cid:48)

else

end if
Deﬁne the cost function

6:
7:
8:
9:
10:
11:
12:

t(yt).

t. This is equivalent to playing Wt = W(cid:48)

t with

ft(W) := ˜∇t · (W − W(cid:48)

κtβ( ˜∇t · (W − W(cid:48)

t))2.

1
2

t) +

t(cid:88)

τ =1

ft(W) +

(cid:107)W(cid:107)2.

1
2D

W(cid:48)

t+1 := arg min
W∈K

13:

Compute

14: end for

2.3 The FTAL Lemma

(2)

(3)

Our algorithm is based on the FTAL algorithm [HAK07]. This algorithm is an online version of
the Newton step algorithm in ofﬂine optimization. The following lemma speciﬁes the algorithm 
specialized to our setting  and gives its regret bound. The proof is in the full version.
Lemma 3. Consider an online convex optimization problem over some convex  compact domain
2 βt(vt · w − αt)2  where the
K ⊆ Rn of diameter D with cost functions ft(w) = (vt · w − αt) + 1
vector vt ∈ Rn and scalars αt  βt are chosen by the adversary such that for some known parameters
r  a  b  we have (cid:107)vt(cid:107) ≤ r  βt ≥ a  and |βt(vt · w − αt)| ≤ b  for all w ∈ K. Then the algorithm
that  in round t  plays

wt := arg min
w∈K

has regret bounded by O( nb2

a log( DraT

b

)).

t−1(cid:88)

τ =1

ft(w)

3 The NEWTRON algorithm

Our algorithm for bandit multiclass learning algorithm  dubbed NEWTRON  is shown as Algorithm 1
above. In each iteration  we randomly choose a label from the distribution speciﬁed by the current
weight matrix on the current example mixed with the uniform distribution over labels speciﬁed by
an exploration parameter γ. The parameter γ (which is similar to the exploration parameter used
in the EXP3 algorithm of [ACBFS03]) is eventually tuned based on the value of the parameter α
in the loss function (see Corollary 5). We then use the observed feedback to construct a quadratic
loss function (which is strongly convex) that lower bounds the true loss function in expectation (see
Lemma 7) and thus allows us to bound the regret. To do this we construct a randomized estimator
˜∇t for the gradient of the loss function at the current weight matrix. Furthermore  we also choose a
parameter κt  which is an adjustment factor for the strongly convexity of the quadratic loss function
ensuring that its expectation lower bounds the true loss function. Finally  we compute the new loss
matrix using a Follow-The-Regularized-Leader strategy  by minimizing the sum of all quadratic loss
functions so far with (cid:96)2 regularization. As described in [HAK07]  this convex program can be solved
in quadratic time  plus a projection on K in the norm induced by the Hessian.

4

Statement and discussion of main theorem. To simplify notation  deﬁne the function (cid:96)t : K → R
as (cid:96)t(W) = (cid:96)(W  (xt  yt)). Let Et[·] denote the conditional expectation with respect to the σ-ﬁeld
Ft  where Ft is the smallest σ-ﬁeld with respect to which the predictions ˆyk  for k = 1  2  . . .   t− 1 
are measurable.
With this notation  we can state our main theorem giving the regret bound:
Theorem 4. Given α  δ and γ ≤ 1
10 + η 
algorithm  for η = γ log(k)
bound on the expected regret:

4RD} in the NEWTRON
k}. The NEWTRON algorithm has the following
(cid:17)
(cid:16) kn

20αR2D2 . Let ν = max{ δ
T(cid:88)

2   suppose we set β ≤ min{ αδ

2   γ

1

E[(cid:96)t(Wt)] − (cid:96)t(W(cid:63)) = O

νβ log T + γ log(k)

α

T

t=1

Before giving the proof theorem 4  we ﬁrst state a corollary (a simple optimization of parameters 
proved in the full version) which shows how γ in Theorem 4 can be set appropriately to get a smooth
interpolation between O(log(T )) and O(T 2/3) regret based on the value of α.
Corollary 5. Given α  there is a setting of γ so that the regret of NEWTRON is bounded by

(cid:26)

min

c

exp(4αRD)

α

log(T ) 

6cRDT 2/3

(cid:27)

 

where the constant c = O(k3n) is independent of α.

Discussion of the bound. The parameter α is inherent to the log-loss function as deﬁned in
[AR09]. Our main result as given in Corollary 5 which entails logarithmic regret for constant α 
contains a constant which depends exponentially on α. Empirically  it seems that α can be set to a
small constant  say 10 (see Section 4)  and still have good performance.
Note that even when α grows with T   as long as α ≤ 1
√
O(cRD
range of α.
We can say something even stronger - our results provide a “safety net” - no matter what the value
of α is  the regret of our algorithm is never worse than O(T 2/3)  matching the bound of the BAN-
DITRON algorithm (although the latter holds for the multiclass hinge loss).

8RD log(T )  the regret can be bounded as
T )  thus solving the open problem of [KSST08  AR09] for log-loss functions with this

Analysis.

Proof. (Theorem 4.) The optimization (3) is essentially running the algorithm from Lemma 3 on
2D (Eil · W)2
K with the cost functions ft(W)  with additional nk initial ﬁctitious cost functions 1
for i ∈ [n] and l ∈ [k]. These ﬁctitious cost functions can be thought of as regularization. While
technically these ﬁctitious cost functions are not necessary to prove our regret bound  we include
them since this seems to give better experimental performance and only adds a constant to the regret.
We now apply the regret bound of Lemma 3 by estimating the parameters r  a  b. This is a simple
technical calculation and done in Lemma 6 below  which yields the values r = R
ν   a = βν  b = 1.
Hence  the regret bound of Lemma 3 implies that for any W(cid:63) ∈ K 

ft(W(cid:48)

t) − ft(W(cid:63)) = O

νβ log T

.

(cid:16) kn

(cid:17)

T(cid:88)

t=1

Note that the bound above excludes the ﬁctitious cost functions since they only add a constant addi-
tive term to the regret  which is absorbed by the O(log T ) term. Similarly  we have also suppressed
additive constants arising from the log( DraT
Taking expectation on both sides of the above bound with respect to the randomness in the algorithm 
and using the speciﬁcation (2) of ft(W) we get

) term in the regret bound of Lemma 3.

b

(cid:21)

(cid:16) kn

(cid:17)

= O

νβ log T

.

(4)

(cid:20)

E

˜∇t · (W(cid:48)

t − W(cid:63)) − 1
2

κtβ( ˜∇t · (W(cid:48)

t − W(cid:63)))2

5

By Lemma 7 below  we get that

(cid:96)t(W(cid:48)

t) − (cid:96)t(W(cid:63)) ≤ E

t

˜∇t · (W(cid:48)

t − W(cid:63)) − 1
2

(cid:20)

κtβ( ˜∇t · (W(cid:48)

t − W(cid:63)))2

(cid:21)

+ 20ηR2D2.

(5)

Furthermore  we have

[(cid:96)t(Wt)] − (cid:96)(W(cid:48)
E
t

(6)
t with probability (1 − γ) and Wt = 0 with probability γ  and (cid:96)t(0) = log(k)
α .

α

 

t) ≤ γ log(k)

since Wt = W(cid:48)
Plugging (5) and (6) in (4)  and using η = γ log(k)
20αR2D2  
E[(cid:96)(Wt)] − (cid:96)(W(cid:63)) = O

T(cid:88)

(cid:16) kn

(cid:17)

νβ log T + γ log(k)

α

T

.

t=1

We now state two lemmas that were used in the proof of Theorem 4. The ﬁrst one (proof in the full
version) obtains parameter settings to use Lemma 3 in Theorem 4.
Lemma 6. Assume β ≤ 1
k}. Then the following are valid
2   γ
settings for the parameters r  a  b: r = R

2 . Let ν = max{ δ
ν   a = βν and b = 1.

4RD and γ ≤ 1

The next lemma shows that in each round  the expected regret of the inner FTAL algorithm with ft
cost functions is larger than the regret of NEWTRON.
Lemma 7. For β = αδ

(cid:20)

10 + η and γ ≤ 1
˜∇t · (W(cid:48)

2   we have
t − W(cid:63)) − 1
2

t

(cid:96)t(W(cid:48)

t) − (cid:96)t(W(cid:63)) ≤ E

κtβ( ˜∇t · (W(cid:48)

t − W(cid:63)))2

+ 20ηR2D2.

(cid:21)

Proof. The intuition behind the proof is the following. We show that Et[ ˜∇t] = (p − eyt ) ⊗ xt 
which by Lemma 1 equals ∇(cid:96)t(W(cid:48)
for some
matrix Ht s.t. Ht1 = 0. By upper bounding (cid:107)Ht(cid:107)  we then show (using Lemma 2) that for any
Ψ ∈ K we have

t). Next  we show that Et[κt ˜∇t ˜∇(cid:62)

t ] = Ht ⊗ xtx(cid:62)

t

∇2(cid:96)t(Ψ) (cid:23) βHt ⊗ xtx(cid:62)
t .

The stated bound then follows by an application of Taylor’s theorem.
The technical details for the proof are as follows. First  note that
[ ˜∇t] · (W(cid:48)

t − W(cid:63)).

[ ˜∇t · (W(cid:48)
E
t

t

t − W(cid:63))] = E
(cid:19)

(cid:18) 1

1 − eyt

+

k

(cid:88)

y(cid:54)=yt

t(y) · pt(y)
p(cid:48)
p(cid:48)
t(y)

·

(cid:18)

eˆyt − 1
k

1

(cid:19) ⊗ xt

(7)

(8)

(9)

(10)

p(cid:48)

We now compute Et[ ˜∇t].

[ ˜∇t] =
E
t

t(yt) · 1 − pt(yt)

p(cid:48)
t(yt)
= (pt − eyt) ⊗ xt.

·

Next  we have
[κt( ˜∇t · (W(cid:48)
E
t
(cid:34)
We now compute Et[κt ˜∇t ˜∇(cid:62)
t ].
t(yt) · κt
p(cid:48)
(cid:88)

[κt ˜∇t ˜∇(cid:62)
E
t

t ] =

+

t(y) ·
p(cid:48)
=: Ht ⊗ xtx(cid:62)
t  

y(cid:54)=yt

t − W(cid:63)))2] = (W(cid:48)

t − W(cid:63))(cid:62) E

t ](W(cid:48)

[κt ˜∇t ˜∇(cid:62)
(cid:19)(cid:18) 1

1 − eyt
(cid:19)(cid:18)

t − W(cid:63)).
(cid:19)(cid:62)
(cid:19)(cid:62) ⊗ xtx(cid:62)

1 − eyt

t

k

ey − 1
k

1

ey − 1
k

1

t

(cid:18) 1

k

(cid:18) 1 − pt(yt)
(cid:19)2 ·
(cid:19)2 ·
(cid:18) pt(y)
(cid:18)

p(cid:48)
t(yt)

p(cid:48)
t(y)

6

where Ht is the matrix in the brackets above. We note a few facts about Ht. First  note that
(ey − 1
largest eigenvalue) of Ht is
bounded as:

k 1) · 1 = 0  and so Ht1 = 0. Next  the spectral norm (i.e.

(cid:107)Ht(cid:107)2 ≤ (cid:13)(cid:13) 1

(cid:13)(cid:13)2

(cid:88)

y(cid:54)=yt

k 1 − eyt

+

p(cid:48)
t(y)

1

(1 − γ)2

(cid:13)(cid:13)ey − 1

k 1(cid:13)(cid:13)2 ≤ 10 

for γ ≤ 1

2. Now  for any Ψ ∈ K  by Lemma 2  for the speciﬁed value of β we have

∇2(cid:96)t(Ψ) (cid:23) αδ
10

Ht ⊗ xtx(cid:62)
t .

(11)

Now  by Taylor’s theorem  for some Ψ on the line segment connecting W(cid:48)
(cid:96)t(W(cid:63))−(cid:96)t(W(cid:48)

t) +

t) = ∇(cid:96)t(W(cid:48)

t) · (W(cid:63) − W(cid:48)
≥ ((pt − eyt ) ⊗ xt) · (W(cid:63) − W(cid:48)

t) +

(W(cid:63) − W(cid:48)
1
2
(W(cid:63) − W(cid:48)
1
2

t)(cid:62)[∇2(cid:96)t(Ψ)](W(cid:63) − W(cid:48)
t) 
t)(cid:62)[

Ht ⊗ xtx(cid:62)

αδ
10

t to W(cid:63)  we have

t ](W(cid:63) − W(cid:48)
t) 
(12)

where the last inequality follows from (11). Finally  we have

t ](W(cid:63) − W(cid:48)

t(cid:107)2 ≤ 20ηR2D2  (13)
t(cid:107) ≤ 2D. Adding inequalities (12) and (13)  rearranging the result and using (7) 

t (cid:107)2(cid:107)W(cid:63) − W(cid:48)

η(cid:107)Ht ⊗ xtx(cid:62)

t) ≤ 1
2

(W(cid:63) − W(cid:48)

t)(cid:62)[ηHt ⊗ xtx(cid:62)

1
2
since (cid:107)W(cid:63) − W(cid:48)
(8)  (9)  and (10) gives the stated bound.
4 Experiments

While the theoretical regret bound for NEWTRON is O(log T ) when α = O(1)  the provable constant
in O(·) notation is quite large  leading one to question the practical performance of the algorithm.
The main reason for the large constant is that the analysis requires the β parameter to be set ex-
tremely small to get the required bounds. In practice  however  one can keep β a tunable parameter
and try using larger values. In this section  we give experimental evidence (replicating the exper-
iments of [KSST08]) that shows that the practical performance of the algorithm is quite good for
small values of α (like 10)  and not too small values of β (like 0.01  0.0001).

Data sets. We used three data sets from [KSST08]: SYNSEP  SYNNONSEP  and REUTERS4. The
ﬁrst two  SYNSEP and SYNNONSEP  are synthetic data sets  generated according to the description
given in [KSST08]. These data sets have the same 106 feature vectors with 400 features. There are
9 possible labels. The data set SYNSEP is linearly separable  whereas the data set SYNNONSEP is
made inseparable by artiﬁcially adding 5% label noise. The REUTERS4 data set is generated from
the Reuters RCV1 corpus. There are 673  768 documents in the data set with 4 possible labels  and
346  810 features. Our results are reported by averaging over 10 runs of the algorithm involved.

Algorithms. We implemented the BANDITRON and NEWTRON algorithms3. The NEWTRON al-
gorithm is signiﬁcantly slower than BANDITRON due to its quadratic running time. This makes it
infeasible for really large data sets like REUTERS4. To surmount this problem  we implemented
an approximate version of NEWTRON  called PNEWTRON4  which runs in linear time per iteration
and thus has comparable speed to BANDITRON. PNEWTRON does not have the same regret guaran-
tees of NEWTRON however. To derive PNEWTRON  we can restate NEWTRON equivalently as (see
[HAK07]):

t )(cid:62)At(W − W(cid:48)(cid:48)
t )
τ =1(1− κτ β ˜∇τ ·Wτ ) ˜∇τ .
where W(cid:48)(cid:48)
PNEWTRON makes the following change  using the diagonal approximation for the Hessian  and
usual Euclidean projections:

τ and bt =(cid:80)t−1

τ =1 κτ β ˜∇τ ˜∇(cid:62)

t bt  for At = 1

t = −A−1

t = arg min

W(cid:48)

D I +(cid:80)t−1
W∈K(W − W(cid:48)(cid:48)
W∈K(W − W(cid:48)(cid:48)

W(cid:48)

t = arg min

t )(cid:62)(W − W(cid:48)(cid:48)
t )

3We did not implement the Conﬁdit algorithm of [CG11] since our aim was to consider algorithms in the

fully adversarial setting.

4Short for pseudo-NEWTRON. The “P” may be left silent so that it’s almost NEWTRON  but not quite.

7

where W(cid:48)(cid:48)

bt =(cid:80)t−1

t = −A−1
t bt  for At = 1
τ =1(1 − κτ β ˜∇τ · Wτ ) ˜∇τ .

D I +(cid:80)t−1

τ =1 diag(κτ β ˜∇τ ˜∇(cid:62)

τ ) and bt is the same as before 

In our experiments  we chose K to be the unit (cid:96)2 ball in Rkn  so D = 1. We
Parameter settings.
also choose α = 10 for all experiments in the log-loss. For BANDITRON  we chose the value of
γ speciﬁed in [KSST08]: γ = 0.014  0.006 and 0.05 for SYNSEP  SYNNONSEP and REUTERS4
respectively. For NEWTRON and PNEWTRON  we chose γ = 0.01  0.006 and 0.05 respectively. The
other parameter for NEWTRON and PNEWTRON  β  was set to the values β = 0.01  0.01  and 0.0001
respectively. We did not tune any of the parameters α  β and γ for NEWTRON or PNEWTRON.

Evaluation. We evaluated the algorithms in terms of their error
rate  i.e.
the fraction of prediction mistakes made as a function
of time. Experimentally  PNEWTRON has quite similar perfor-
mance to NEWTRON  but is signiﬁcantly faster. Figure 4 shows
how BANDITRON  NEWTRON and PNEWTRON compare on the
SYNNONSEP data set for 104 examples5.
It can be seen that
PNEWTRON has similar behavior to NEWTRON  and is not much
worse.
The rest of the experiments were conducted using only BAN-
DITRON and PNEWTRON. The results are shown in ﬁgure 4. It
can be clearly seen that PNEWTRON decreases the error rate much
faster than BANDITRON. For the SYNSEP data set  PNEWTRON
very rapidly converges to the lowest possible error rate due to
setting the exploration parameter γ = 0.01  viz. 0.01 × 8/9 =
0.89%. In comparison  the ﬁnal error for BANDITRON is 1.91%.
For the SYNNONSEP data set  PNEWTRON converges rapidly to
its ﬁnal value of 11.94%. BANDITRON remains at a high error
level until about 104 examples  and at the very end catches up
with and does slightly better than PNEWTRON  ending at 11.47%.
For the REUTERS4 data set  both BANDITRON and PNEWTRON
decrease the error rate at roughly same pace; however PNEWTRON still obtains better performance
consistently by a few percentage points. In our experiments  the ﬁnal error rate for PNEWTRON is
13.08%  while that for BANDITRON is 18.10%.

Figure 1: Log-log plots of error
rates vs. number of examples
for BANDITRON  NEWTRON
and PNEWTRON on SYNNON-
SEP with 104 examples.

Figure 2: Log-log plots of error rates vs. number of examples for BANDITRON and PNEWTRON on
different data sets. Left: SYNSEP. Middle: SYNNONSEP. Right: REUTERS4.

5 Future Work

Some interesting questions remain open. Our theoretical guarantee applies only to the quadratic-
time NEWTRON algorithm. Is it possible to obtain similar regret guarantees for a linear time algo-
rithm? Our regret bound has an exponentially large constant  which depends on the loss functions
parameters. Does there exist an algorithm with similar regret guarantees but better constants?

5In the interest of reducing running time for NEWTRON  we used a smaller data set.

8

10210310410−0.810−0.710−0.610−0.510−0.410−0.310−0.2SynNonSep: number of exampleserror rate  BanditronNewtronPNewtron10210310410510610−310−210−1100SynSep: number of exampleserror rate  BanditronPNewtron10210310410510610−0.910−0.810−0.710−0.610−0.510−0.410−0.310−0.2SynNonSep: number of exampleserror rate  BanditronPNewtron10210310410510610−0.810−0.710−0.610−0.510−0.410−0.310−0.2Reuters4: number of examplesError rate  BanditronPNewtronReferences
[ACBFS03] Peter Auer  Nicol`o Cesa-Bianchi  Yoav Freund  and Robert E. Schapire. The non-

√

[AHR08]

[AK08]

[AR09]

[CG11]

[DH06]

[DHK07]

[FKM05]

[HAK07]

[HJ91]

[KSST08]

[LZ07]

[MB04]

[RTB07]

T -regret

stochastic multiarmed bandit problem. SIAM J. Comput.  32:48–77  January 2003.
Jacob Abernethy  Elad Hazan  and Alexander Rakhlin. Competing in the dark: An
efﬁcient algorithm for bandit linear optimization. In COLT  pages 263–274  2008.
Baruch Awerbuch and Robert Kleinberg. Online linear optimization and adaptive rout-
ing. J. Comput. Syst. Sci.  74(1):97–114  2008.
Jacob Abernethy and Alexander Rakhlin. An efﬁcient bandit algorithm for
in online multiclass prediction? In COLT  2009.
Koby Crammer and Claudio Gentile. Multiclass classiﬁcation with bandit feedback
using adaptive regularization. In ICML  2011.
Varsha Dani and Thomas P. Hayes. Robbing the bandit: less regret in online geometric
optimization against an adaptive adversary. In SODA  pages 937–943  2006.
Varsha Dani  Thomas Hayes  and Sham Kakade. The price of bandit information for
online optimization. In NIPS. 2007.
Abraham D. Flaxman  Adam Tauman Kalai  and H. Brendan McMahan. Online convex
optimization in the bandit setting: gradient descent without a gradient. In SODA  pages
385–394  2005.
Elad Hazan  Amit Agarwal  and Satyen Kale. Logarithmic regret algorithms for online
convex optimization. Machine Learning  69(2-3):169–192  2007.
R.A. Horn and C.R. Johnson. Topics in Matrix Analysis. Cambridge University Press 
Cambridge  1991.
Sham M. Kakade  Shai Shalev-Shwartz  and Ambuj Tewari. Efﬁcient bandit algorithms
for online multiclass prediction. In ICML’08  pages 440–447  2008.
John Langford and Tong Zhang. The epoch-greedy algorithm for multi-armed bandits
with side information. In NIPS  2007.
H. Brendan McMahan and Avrim Blum. Online geometric optimization in the bandit
setting against an adaptive adversary. In COLT  pages 109–123  2004.
Alexander Rakhlin  Ambuj Tewari  and Peter Bartlett. Closing the gap between bandit
and full-information online optimization: High-probability regret bound. Technical
Report UCB/EECS-2007-109  EECS Department  University of California  Berkeley 
Aug 2007.

9

,Adrian Weller
Tony Jebara