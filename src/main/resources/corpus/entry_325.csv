2015,Accelerated Mirror Descent in Continuous and Discrete Time,We study accelerated mirror descent dynamics in continuous and discrete time. Combining the original continuous-time motivation of mirror descent with a recent ODE interpretation of Nesterov's accelerated method  we propose a family of continuous-time descent dynamics for convex functions with Lipschitz gradients  such that the solution trajectories are guaranteed to converge to the optimum at a $O(1/t^2)$ rate. We then show that a large family of first-order accelerated methods can be obtained as a discretization of the ODE  and these methods converge at a $O(1/k^2)$ rate. This connection between accelerated mirror descent and the ODE provides an intuitive approach to the design and analysis of accelerated first-order algorithms.,Accelerated Mirror Descent

in Continuous and Discrete Time

Walid Krichene

UC Berkeley

Alexandre M. Bayen

UC Berkeley

Peter L. Bartlett

UC Berkeley and QUT

walid@eecs.berkeley.edu

bayen@berkeley.edu

bartlett@berkeley.edu

Abstract

We study accelerated mirror descent dynamics in continuous and discrete time.
Combining the original continuous-time motivation of mirror descent with a re-
cent ODE interpretation of Nesterov’s accelerated method  we propose a family of
continuous-time descent dynamics for convex functions with Lipschitz gradients 
such that the solution trajectories converge to the optimum at a O(1/t2) rate. We
then show that a large family of ﬁrst-order accelerated methods can be obtained as
a discretization of the ODE  and these methods converge at a O(1/k2) rate. This
connection between accelerated mirror descent and the ODE provides an intuitive
approach to the design and analysis of accelerated ﬁrst-order algorithms.

Introduction

1
We consider a convex optimization problem  minimizex∈X f (x)  where X ⊆ Rn is convex and
closed  f is a C 1 convex function  and ∇f is assumed to be Lf -Lipschitz. Let f (cid:63) be the minimum
of f on X . Many convex optimization methods can be interpreted as the discretization of an ordinary
differential equation  the solutions of which are guaranteed to converge to the set of minimizers. Per-
haps the simplest such method is gradient descent  given by the iteration x(k+1) = x(k)−s∇f (x(k))
for some step size s  which can be interpreted as the discretization of the ODE ˙X(t) = −∇f (X(t)) 
with discretization step s. The well-established theory of ordinary differential equations can provide
guidance in the design and analysis of optimization algorithms  and has been used for unconstrained
optimization [8  7  13]  constrained optimization [27] and stochastic optimization [25]. In particular 
proving convergence of the solution trajectories of an ODE can often be achieved using simple and
elegant Lyapunov arguments. The ODE can then be carefully discretized to obtain an optimiza-
tion algorithm for which the convergence rate can be analyzed by using an analogous Lyapunov
argument in discrete time.
In this article  we focus on two families of ﬁrst-order methods: Nesterov’s accelerated method [22] 
and Nemirovski’s mirror descent method [19]. First-order methods have become increasingly im-
portant for large-scale optimization problems that arise in machine learning applications. Nesterov’s
accelerated method [22] has been applied to many problems and extended in a number of ways  see
for example [23  20  21  4]. The mirror descent method also provides an important generaliza-
tion of the gradient descent method to non-Euclidean geometries  as discussed in [19  3]  and has
many applications in convex optimization [6  5  12  15]  as well as online learning [9  11]. An in-
tuitive understanding of these methods is of particular importance for the design and analysis of
new algorithms. Although Nesterov’s method has been notoriously hard to explain intuitively [14] 
progress has been made recently: in [28]  Su et al. give an ODE interpretation of Nesterov’s method.
However  this interpretation is restricted to the original method [22]  and does not apply to its ex-
tensions to non-Euclidean geometries. In [1]  Allen-Zhu and Orecchia give another interpretation
of Nesterov’s method  as performing  at each iteration  a convex combination of a mirror step and a
gradient step. Although it covers a broader family of algorithms (including non-Euclidean geome-
tries)  this interpretation still requires an involved analysis  and lacks the simplicity and elegance of

1

ODEs. We provide a new interpretation which has the beneﬁts of both approaches: we show that a
broad family of accelerated methods (which includes those studied in [28] and [1]) can be obtained
as a discretization of a simple ODE  which converges at a O(1/t2) rate. This provides a uniﬁed
interpretation  which could potentially simplify the design and analysis of ﬁrst-order accelerated
methods.
The continuous-time interpretation [28] of Nesterov’s method and the continuous-time motivation
of mirror descent [19] both rely on a Lyapunov argument. They are reviewed in Section 2. By
combining these ideas  we propose  in Section 3  a candidate Lyapunov function V (X(t)  Z(t)  t)
that depends on two state variables: X(t)  which evolves in the primal space E = Rn  and Z(t) 
which evolves in the dual space E∗  and we design coupled dynamics of (X  Z) to guarantee that
dt V (X(t)  Z(t)  t) ≤ 0. Such a function is said to be a Lyapunov function  in reference to [18];
d
see also [16]. This leads to a new family of ODE systems  given in Equation (5). We prove the
existence and uniqueness of the solution to (5) in Theorem 1. Then we prove in Thereom 2  using
the Lyapunov function V   that the solution trajectories are such that f (X(t)) − f (cid:63) = O(1/t2). In
Section 4  we give a discretization of these continuous-time dynamics  and obtain a family of accel-
erated mirror descent methods  for which we prove the same O(1/k2) convergence rate (Theorem 3)
using a Lyapunov argument analogous to (though more involved than) the continuous-time case. We
give  as an example  a new accelerated method on the simplex  which can be viewed as performing 
at each step  a convex combination of two entropic projections with different step sizes. This ODE
interpretation of accelerated mirror descent gives new insights and allows us to extend recent results
such as the adaptive restarting heuristics proposed by O’Donoghue and Cand`es in [24]  which are
known to empirically improve the convergence rate. We test these methods on numerical examples
in Section 5 and comment on their performance.

2 ODE interpretations of Nemirovski’s mirror descent method and

Nesterov’s accelerated method

Proving convergence of the solution trajectories of an ODE often involves a Lyapunov argument. For
example  to prove convergence of the solutions to the gradient descent ODE ˙X(t) = −∇f (X(t)) 
consider the Lyapunov function V (X(t)) = 1
2(cid:107)X(t) − x(cid:63)(cid:107)2 for some minimizer x(cid:63). Then the time
derivative of V (X(t)) is given by
= (cid:104)−∇f (X(t))  X(t) − x(cid:63)(cid:105) ≤ −(f (X(t)) − f (cid:63)) 

(cid:82) t
where the last inequality is by convexity of f. Integrating  we have V (X(t)) − V (x0) ≤ tf (cid:63) −
0 f (X(τ ))dτ  thus by Jensen’s inequality  f
0 f (X(τ ))dτ − f (cid:63) ≤

(cid:68) ˙X(t)  X(t) − x(cid:63)(cid:69)
(cid:16) 1

(cid:16) 1

(cid:82) t

(cid:82) t
− f (cid:63) ≤ 1
converges to f (cid:63) at a O(1/t) rate.

0 X(τ )dτ

  which proves that f

0 X(τ )dτ

V (X(t)) =

(cid:82) t

(cid:17)

(cid:17)

d
dt

V (x0)

t

t

t

t

2.1 Mirror descent ODE

The previous argument was extended by Nemirovski and Yudin in [19] to a family of methods
called mirror descent. The idea is to start from a non-negative function V   then to design dynamics
for which V is a Lyapunov function. Nemirovski and Yudin argue that one can replace the Lyapunov
2(cid:107)X(t) − x(cid:63)(cid:107)2 by a function on the dual space  V (Z(t)) = Dψ∗ (Z(t)  z(cid:63)) 
function V (X(t)) = 1
where Z(t) ∈ E∗ is a dual variable for which we will design the dynamics (z(cid:63) is the value of Z at
equilibrium)  and the corresponding trajectory in the primal space is X(t) = ∇ψ∗(Z(t)). Here ψ∗ is
a convex function deﬁned on E∗  such that ∇ψ∗ maps E∗ to X   and Dψ∗ (Z(t)  z(cid:63)) is the Bregman
divergence associated with ψ∗  deﬁned as Dψ∗ (z  y) = ψ∗(z) − ψ∗(y) − (cid:104)∇ψ∗(y)  z − y(cid:105). The
function ψ∗ is said to be (cid:96)-strongly convex w.r.t. a reference norm (cid:107) · (cid:107)∗ if D∗ψ(z  y) ≥ (cid:96)
2(cid:107)z − y(cid:107)2
∗
. For a review of
for all y  z  and it is said to be L-smooth w.r.t. (cid:107) · (cid:107)∗ if Dψ∗ (z  y) ≤ L
2 (cid:107)z − y(cid:107)2
∗
properties of Bregman divergences  see Chapter 11.2 in [11]  or Appendix A in [2].
By deﬁnition of the Bregman divergence  we have
∗

∗

∗

)  Z(t) − z(cid:63)(cid:105))

d
dt

V (Z(t)) =

d
dt

(cid:68)∇ψ

Dψ∗ (Z(t)  z(cid:63)) =
(Z(t)) − ∇ψ
∗

∗

(ψ

d
dt
(z(cid:63))  ˙Z(t)

(cid:69)

=

(Z(t)) − ψ

(cid:68)

∗

(z(cid:63)) − (cid:104)∇ψ
(z
X(t) − x(cid:63)  ˙Z(t)

.

(cid:69)

=

2

Therefore  if the dual variable Z obeys the dynamics ˙Z = −∇f (X)  then

V (Z(t)) = −(cid:104)∇f (X(t))  X(t) − x(cid:63)(cid:105) ≤ −(f (X(t)) − f (cid:63))

(cid:16) 1

(cid:82) t

d
dt

(cid:17)

and by the same argument as in the gradient descent ODE  V is a Lyapunov function and
− f (cid:63) converges to 0 at a O(1/t) rate. The mirror descent ODE system can be
f
0 X(τ )dτ
summarized by

t

 X = ∇ψ∗(Z)

˙Z = −∇f (X)
X(0) = x0  Z(0) = z0 with ∇ψ∗(z0) = x0

Note that since ∇ψ∗ maps into X   X(t) = ∇ψ∗(Z(t)) remains in X . Finally  the unconstrained
gradient descent ODE can be obtained as a special case of the mirror descent ODE (1) by taking
ψ∗(z) = 1

2(cid:107)z(cid:107)2  for which ∇ψ∗ is the identity  in which case X and Z coincide.

2.2 ODE interpretation of Nesterov’s accelerated method

In [28]  Su et al. show that Nesterov’s accelerated method [22] can be interpreted as a discretization
of a second-order differential equation  given by

(cid:40) ¨X + r+1

t

˙X + ∇f (X) = 0

X(0) = x0 

˙X(0) = 0

(1)

(2)

r

2(cid:107)X + t
2(cid:107)x0 − x(cid:63)(cid:107)2  therefore f (X(t)) − f (cid:63) ≤ r

The argument uses the following Lyapunov function (up to reparameterization)  E(t) = t2
r (f (X) −
˙X − x(cid:63)(cid:107)2  which is proved to be a Lyapunov function for the ODE (2) whenever
f (cid:63)) + r
r ≥ 2. Since E is decreasing along trajectories of the system  it follows that for all t > 0  E(t) ≤
  which proves
E(0) = r
that f (X(t)) converges to f (cid:63) at a O(1/t2) rate. One should note in particular that the squared
Euclidean norm is used in the deﬁnition of E(t) and  as a consequence  discretizing the ODE (2)
leads to a family of unconstrained  Euclidean accelerated methods. In the next section  we show
that by combining this argument with Nemirovski’s idea of using a general Bregman divergence
as a Lyapunov function  we can construct a much more general family of ODE systems which
have the same O(1/t2) convergence guarantee. And by discretizing the resulting dynamics  we
obtain a general family of accelerated methods that are not restricted to the unconstrained Euclidean
geometry.

t2E(0) ≤ r2

t2E(t) ≤ r

t2 (cid:107)x0−x(cid:63)(cid:107)2

2

3 Continuous-time Accelerated Mirror Descent

3.1 Derivation of the accelerated mirror descent ODE
We consider a pair of dual convex functions  ψ deﬁned on X and ψ∗ deﬁned on E∗  such that
∇ψ∗ : E∗ → X . We assume that ψ∗ is Lψ∗-smooth with respect to (cid:107) · (cid:107)∗  a reference norm on the
dual space. Consider the function

(3)
where Z is a dual variable for which we will design the dynamics  and z(cid:63) is its value at equilibrium.
Taking the time-derivative of V   we have

V (X(t)  Z(t)  t) =

(f (X(t)) − f (cid:63)) + rDψ∗ (Z(t)  z(cid:63))

t2
r

(cid:69)

(cid:68) ˙Z ∇ψ

˙X

+ r

∗

(Z) − ∇ψ

∗

(z(cid:63))

.

d
dt

V (X(t)  Z(t)  t) =

(f (X) − f (cid:63)) +

2t
r

t2
r

Assume that
d
dt

˙Z = − t

r∇f (X). Then  the time-derivative of V becomes
˙X + ∇ψ

(f (X) − f (cid:63)) − t

∇f (X) − t
r

2t
r

V (X(t)  Z(t)  t) =

∗

(Z) − ∇ψ

∗

(z(cid:63))

.

(cid:68)∇f (X) 
(cid:28)

(cid:69)

(cid:29)

Therefore  if Z is such that ∇ψ∗(Z) = X + t

r

˙X  and ∇ψ∗(z(cid:63)) = x(cid:63)  then 

d
dt

V (X(t)  Z(t)  t) =

2t
r
≤ −t

(f (X) − f (cid:63)) − t(cid:104)∇f (X)  X − x(cid:63)(cid:105) ≤ 2t
r
r − 2

(f (X) − f (cid:63))

r

(f (X) − f (cid:63)) − t(f (X) − f (cid:63))

(4)

3

and it follows that V is a Lyapunov function whenever r ≥ 2. The proposed ODE system is then

 ˙X = r

t (∇ψ∗(Z) − X) 
r∇f (X) 

˙Z = − t
X(0) = x0  Z(0) = z0  with ∇ψ∗(z0) = x0.

(5)

(cid:82) t

= − t

˙X  and the ODE system is equivalent to d
dt

(cid:17)
2(cid:107)z(cid:107)2  we have ∇ψ∗(z) = z  thus Z =
˙X
r∇f (X)  which is equivalent to

(cid:16)
rtr−1∇ψ∗(Z)  or  in integral form  trX(t) = r(cid:82) t

In the unconstrained Euclidean case  taking ψ∗(z) = 1
X + t
X + t
r
r
the ODE (2) studied in [28]  which we recover as a special case.
We also give another interpretation of ODE (5): the ﬁrst equation is equivalent to tr ˙X + rtr−1X =
0 τ r−1∇ψ∗(Z(τ ))dτ  which can be written as
  with w(τ ) = τ r−1. Therefore the coupled dynamics of (X  Z) can
X(t) =
be interpreted as follows: the dual variable Z accumulates gradients with a t
r rate  while the primal
variable X is a weighted average of ∇ψ∗(Z(τ )) (the “mirrored” dual trajectory)  with weights
proportional to τ r−1. This also gives an interpretation of r as a parameter controlling the weight
distribution. It is also interesting to observe that the weights are increasing if and only if r ≥ 2.
Finally  with this averaging interpretation  it becomes clear that the primal trajectory X(t) remains
in X   since ∇ψ∗ maps into X and X is convex.
3.2 Solution of the proposed dynamics

0 w(τ )∇ψ

0 w(τ )dτ

(Z(τ ))dτ

(cid:82) t

∗

r

t term in the expression of

max(t δ) (∇ψ∗(Z) − X) 
r∇f (X) 

First  we prove existence and uniqueness of a solution to the ODE system (5)  deﬁned for all t >
0. By assumption  ψ∗ is Lψ∗-smooth w.r.t. (cid:107) · (cid:107)∗  which is equivalent (see e.g. [26]) to ∇ψ∗ is
˙X  the function (X  Z  t) (cid:55)→
Lψ∗-Lipschitz. Unfortunately  due to the r
( ˙X  ˙Z) is not Lipschitz at t = 0  and we cannot directly apply the Cauchy-Lipschitz existence and
uniqueness theorem. However  one can work around it by considering a sequence of approximating
ODEs  similarly to the argument used in [28].
Theorem 1. Suppose f is C 1  and that ∇f is Lf -Lipschitz  and let (x0  z0) ∈ X × E∗ such that
∇ψ∗(z0) = x0. Then the accelerated mirror descent ODE system (5) with initial condition (x0  z0)
has a unique solution (X  Z)  in C 1([0 ∞)  Rn).
We will show existence of a solution on any given interval [0  T ] (uniqueness is proved in the sup-
plementary material). Let δ > 0  and consider the smoothed ODE system

˙Z = − t
X(0) = x0  Z(0) = z0 with ∇ψ∗(z0) = x0.
r∇f (X) and (X  Z) (cid:55)→ r

Since the functions (X  Z) (cid:55)→ − t
max(t δ) (∇ψ∗(Z) − X) are Lipschitz for
all t ∈ [0  T ]  by the Cauchy-Lipschitz theorem (Theorem 2.5 in [29])  the system (6) has a unique
solution (Xδ  Zδ) in C 1([0  T ]). In order to show the existence of a solution to the original ODE 
we use the following Lemma (proved in the supplementary material).
Lemma 1. Let t0 =
continuous and uniformly bounded.

 ˙X =
2√Lf Lψ∗ . Then the family of solutions(cid:0)(Xδ  Zδ)|[0 t0]
(cid:1)
Proof of existence. Consider the family of solutions(cid:0)(Xδi  Zδi)  δi = t02−i(cid:1)
i∈N restricted to [0  t0].
By Lemma 1  this family is equi-Lipschitz-continuous and uniformly bounded  thus by the Arzel`a-
Ascoli theorem  there exists a subsequence ((Xδi  Zδi))i∈I
that converges uniformly on [0  t0]
(where I ⊂ N is an inﬁnite set of indices). Let ( ¯X  ¯Z) be its limit. Then we prove that ( ¯X  ¯Z)
is a solution to the original ODE (5) on [0  t0].
it follows that ¯X(0) =
First  since for all i ∈ I  Xδi(0) = x0 and Zδi(0) = z0 
limi→∞ i∈I Xδi(0) = x0 and ¯Z(0) = limi→∞ i∈I Zδi(0) = z0  thus ( ¯X  ¯Z) satisﬁes the initial
conditions. Next  let t1 ∈ (0  t0)  and let ( ˜X  ˜Z) be the solution of the ODE (5) on t ≥ t1  with
initial condition ( ¯X(t1)  ¯Z(t1)). Since (Xδi(t1)  Zδi(t1))i∈I → ( ¯X(t1)  ¯Z(t1)) as i → ∞  then by

is equi-Lipschitz-

δ≤t0

(6)

4

continuity of the solution w.r.t. initial conditions (Theorem 2.8 in [29])  we have that for some  > 0 
Xδi → ˜X uniformly on [t1  t1 + ). But we also have Xδi → ¯X uniformly on [0  t0]  therefore ¯X
and ˜X coincide on [t1  t1 + )  therefore ¯X satisﬁes the ODE on [t1  t1 + ). And since t1 is arbitrary
in (0  t0)  this concludes the proof of existence.

3.3 Convergence rate

It is now straightforward to establish the convergence rate of the solution.
Theorem 2. Suppose that f has Lipschitz gradient  and that ψ∗ is a smooth distance generating
function. Let (X(t)  Z(t)) be the solution to the accelerated mirror descent ODE (5) with r ≥ 2.
Then for all t > 0  f (X(t)) − f (cid:63) ≤ r2Dψ∗ (z0 z(cid:63))
Proof. By construction of the ODE  V (X(t)  Z(t)  t) = t2
a Lyapunov function.
V (x0  z0  0) = rDψ∗ (z0  z(cid:63)).

r (f (X(t)) − f (cid:63)) + rDψ∗ (Z(t)  z(cid:63)) is
r (f (X(t)) − f (cid:63)) ≤ V (X(t)  Z(t)  t) ≤

It follows that for all t > 0  t2

t2

.

4 Discretization

Next  we show that with a careful discretization of this continuous-time dynamics  we can obtain a
general family of accelerated mirror descent methods for constrained optimization. Using a mixed
forward/backward Euler scheme (see e.g. Chapter 2 in [10])  we can discretize the ODE system (5)
using a step size √s as follows. Given a solution (X  Z) of the ODE (5)  let tk = k√s  and x(k) =
X(tk) = X(k√s). Approximating ˙X(tk) with X(tk+√s)−X(tk)

  we propose the discretization

The ﬁrst equation can be rewritten as x(k+1) =(cid:0)x(k) + r

z(k+1)−z(k)

(cid:40) x(k+1)−x(k)

√s
√s

√s

(cid:0)

= r
k√s
+ k√s
r ∇f (x(k+1)) = 0.

∇ψ∗(z(k)) − x(k+1)(cid:1)  
k∇ψ∗(z(k))(cid:1) /(cid:0)1 + r

k

(7)

(cid:1) (note the indepen-

dence on s  due to the time-scale invariance of the ﬁrst ODE). In other words  x(k+1) is a convex
r+k . To summarize 
combination of ∇ψ∗(z(k)) and x(k) with coefﬁcients λk = r
our ﬁrst discrete scheme can be written as

r+k and 1 − λk = k

(cid:40)

x(k+1) = λk∇ψ∗(z(k)) + (1 − λk)x(k)  λk = r
z(k+1) = z(k) − ks

r ∇f (x(k+1)).

r+k  

(8)

Since ∇ψ∗ maps into the feasible set X   starting from x(0) ∈ X guarantees that x(k) remains in X
for all k (by convexity of X ). Note that by duality  we have ∇ψ∗(x∗) = arg maxx∈X (cid:104)x  x∗(cid:105)−ψ(x) 
and if we additionally assume that ψ is differentiable on the image of ∇ψ∗  then ∇ψ = (∇ψ∗)−1
(cid:29)
(Theorem 23.5 in [26])  thus if we write ˜z(k) = ∇ψ∗(z(k))  the second equation can be written as

(cid:28)

∇f (x(k+1))) = arg min

ψ(x) −

x∈X

∇ψ(˜z(k)) − ks
r

∇f (x(k+1))  x

˜z(k+1) = ∇ψ

∗

(∇ψ(˜z(k)) − ks
r

(cid:68)∇f (x(k+1))  x

(cid:69)

= arg min

x∈X

ks
r

+ Dψ(x  ˜z(k)).

We will eventually modify this scheme in order to be able to prove the desired O(1/k2) convergence
rate. However  we start by analyzing this version. Motivated by the continuous-time Lyapunov
function (3)  and using the correspondence t ≈ k√s  we consider the potential function E(k) =
V (x(k)  z(k)  k√s) = k2s

r (f (x(k)) − f (cid:63)) + rDψ∗ (z(k)  z(cid:63)). Then we have

E(k+1) − E(k) =

(k + 1)2s

r

(f (x(k+1)) − f (cid:63)) − k2s
(f (x(k)) − f (cid:63)) + r(Dψ∗ (z(k+1)  z(cid:63)) − Dψ∗ (z(k)  z(cid:63)))
r
(f (x(k+1)) − f (cid:63)) + r(Dψ∗ (z(k+1)  z(cid:63)) − Dψ∗ (z(k)  z(cid:63))).

s(1 + 2k)

(f (x(k+1)) − f (x(k))) +

=

k2s
r

r

5

∗

∗

(z(k)) − ∇ψ

= Dψ∗ (z(k+1)  z(k)) +

(z(cid:63))  z(k+1) − z(k)(cid:69)

And through simple algebraic manipulation  the last term can be bounded as follows
Dψ∗ (z(k+1)  z(cid:63)) − Dψ∗ (z(k)  z(cid:63))
= Dψ∗ (z(k+1)  z(k)) +

(cid:68)∇ψ
(cid:28) k
(x(k+1) − x(k)) + x(k+1) − x(cid:63) − ks
r
r2 (f (x(k)) − f (x(k+1))) +
Therefore we have E(k+1) − E(k) ≤ − s[(r−2)k−1]
(f (x(k+1)) − f (cid:63)) + rDψ∗ (z(k+1)  z(k)). Com-
dt V (X(t)  Z(t)  t) in the continuous-time case 
paring this expression with the expression (4) of d
we see that we obtain an analogous expression  except for the additional Bregman divergence term
rDψ∗ (z(k+1)  z(k))  and we cannot immediately conclude that V is a Lyapunov function. This can
be remedied by the following modiﬁcation of the discretization scheme.

by deﬁnition of the Bregman divergence

≤ Dψ∗ (z(k+1)  z(k)) +

(f (cid:63) − f (x(k+1))).

by the discretization (8)

∇f (x(k+1))

by convexity of f

r
k2s

(cid:29)

ks
r

r

tained as a solution to a minimization problem ˜x(k) = arg minx∈X γs(cid:10)

4.1 A family of discrete-time accelerated mirror descent methods
In the expression (8) of x(k+1) = λk ˜z(k) + (1 − λk)x(k)  we propose to replace x(k) with ˜x(k)  ob-
where R is regularization function that satisﬁes the following assumptions: there exist 0 < (cid:96)R ≤ LR
2 (cid:107)x − x(cid:48)(cid:107)2.
such that for all x  x(cid:48) ∈ X   (cid:96)R
2 (cid:107)x − x(cid:48)(cid:107)2 ≤ R(x  x(cid:48)) ≤ LR
(cid:107)2
In the Euclidean case  one can take R(x  x(cid:48)) = (cid:107)x−x
  in which case (cid:96)R = LR = 1 and the
2
˜x update becomes a prox-update.
In the general case  one can take R(x  x(cid:48)) = Dφ(x  x(cid:48)) for
some distance generating function φ which is (cid:96)R-strongly convex and LR-smooth  in which case
the ˜x update becomes a mirror update. The resulting method is summarized in Algorithm 1. This
algorithm is a generalization of Allen-Zhu and Orecchia’s interpretation of Nesterov’s method in [1] 
where x(k+1) is a convex combination of a mirror descent update and a gradient descent update.

∇f (x(k))  x(cid:11) + R(x  x(k)) 

(cid:48)

Algorithm 1 Accelerated mirror descent with distance generating function ψ∗  regularizer R  step
1: Initialize ˜x(0) = x0  ˜z(0) = x0 (cid:0)or z(0) ∈ (∇ψ)−1(x0)(cid:1).
size s  and parameter r ≥ 3
2: for k ∈ N do
3:
4:

r+k .
+ Dψ(˜z  ˜z(k)).

x(k+1) = λk ˜z(k) + (1 − λk)˜x(k)  with λk = r
˜z(k+1) = arg min˜z∈X ks

(cid:68)∇f (x(k+1))  ˜z
(cid:69)
(cid:0)If ψ is non-differentiable  z(k+1) = z(k) − kr
(cid:68)∇f (x(k+1))  ˜x
(cid:69)

˜x(k+1) = arg min˜x∈X γs

s ∇f (x(k+1)) and ˜z(k+1) = ∇ψ∗(z(k+1)).(cid:1)

+ R(˜x  x(k+1))

5:

r

4.2 Consistency of the modiﬁed scheme
One can show that given our assumptions on R  ˜x(k) = x(k) + O(s). Indeed  we have

(cid:68)∇f (x(k))  x(k) − ˜x(k)(cid:69)

(cid:107)˜x(k) − x(k)(cid:107)2 ≤ R(˜x(k)  x(k)) ≤ R(x(k)  x(k)) + γs

(cid:96)R
2

≤ γs(cid:107)∇f (x(k))(cid:107)∗(cid:107)˜x(k) − x(k)(cid:107)

therefore (cid:107)˜x(k) − x(k)(cid:107) ≤ s 2γ(cid:107)∇f (x(k))(cid:107)∗
  which proves the claim. Using this observation  we
can show that the modiﬁed discretization scheme is consistent with the original ODE (5)  that is 
the difference equations deﬁning x(k) and z(k) converge  as s tends to 0  to the ordinary differential
equations of the continuous-time system (5). The difference equations of Algorithm 1 are equivalent
to (7) in which x(k) is replaced by ˜x(k)  i.e.

(cid:96)R

(cid:40) x(k+1)−˜x(k)

√s
√s

z(k+1)−z(k)

= r

k√s (∇ψ∗(z(k)) − x(k+1))

= − k√s

r ∇f (x(k+1))

6

Now suppose there exist C 1 functions (X  Z)  deﬁned on R+  such that X(tk) ≈ x(k) and
Z(tk) ≈ z(k) for tk = k√s. Then  using the fact that ˜x(k) = x(k) + O(s)  we have
+ O(√s) = ˙X(tk) + o(1)  and simi-
x(k+1)−˜x(k)
larly  z(k+1)−z(k)

≈ ˙Z(tk) + o(1)  therefore the difference equation system can be written as

+ O(√s) ≈ X(tk+√s)−X(tk)

= x(k+1)−x(k)

√s

√s

√s

√s

(cid:40) ˙X(tk) + o(1) = r

tk

˙Z(tk) + o(1) = − tk

(∇ψ∗(Z(tk)) − X(tk + √s))
r ∇f (X(tk + √s))

which converges to the ODE (5) as s → 0.
4.3 Convergence rate

To prove convergence of the algorithm  consider the modiﬁed potential function

˜E(k) = V (˜x(k)  z(k)  k√s) = k2s

r (f (˜x(k)) − f (cid:63)) + rDψ∗ (z(k)  z(cid:63)).

Lemma 2. If γ ≥ LRLψ∗ and s ≤ (cid:96)R
˜E(k+1) − ˜E(k) ≤

2Lf γ   then for all k ≥ 0 

(2k + 1 − kr)s

r

(f (˜x(k+1)) − f (cid:63)).

As a consequence  if r ≥ 3  ˜E is a Lyapunov function for k ≥ 1.
This lemma is proved in the supplementary material.
Theorem 3. The discrete-time accelerated mirror descent Algorithm 1 with parameter r ≥ 3 and
step sizes γ ≥ LRLψ∗  s ≤ (cid:96)R

2Lf γ   guarantees that for all k > 0 
r2Dψ∗ (z0  z(cid:63))

f (˜x(k))) − f (cid:63) ≤

r
sk2

˜E(1) ≤

sk2

+

f (x0) − f (cid:63)

k2

.

Proof. The ﬁrst inequality follows immediately from Lemma 2. The second inequality follows from
a simple bound on ˜E(1)  proved in the supplementary material.

∗

∗

i=1

i=1

ezi

(cid:33)

ψ(x) =

(z) = ln

(cid:32) n(cid:88)

xi ln xi+δ(x|∆)  ψ

  ∂ψ(x) = (1 + ln xi)i+Ru  ∇ψ

4.4 Example: accelerated entropic descent
+ :(cid:80)n
We give an instance of Algorithm 1 for simplex-constrained problems. Suppose that X = ∆n =
{x ∈ Rn
i=1 xi = 1} is the n-simplex. Taking ψ to be the negative entropy on ∆  we have for
n(cid:88)
ezi(cid:80)n
x ∈ X   z ∈ E∗ 
j=1 ezj
where δ(·|∆) is the indicator function of the simplex (δ(x|∆) = 0 if x ∈ ∆ and +∞ otherwise) 
and u ∈ Rn is a normal vector to the afﬁne hull of the simplex. The resulting mirror descent
update is a simple entropy projection and can be computed exactly in O(n) operations  and ψ∗
let  > 0  and let φ(x) = (cid:80)n
can be shown to be 1-smooth w.r.t. (cid:107) · (cid:107)∞  see for example [3  6]. For the second update  we
take R(x  y) = Dφ(x  y) where φ is a smoothed negative entropy function deﬁned as follows:
i=1(xi + ) ln(xi + ) + δ(x|∆). Although no simple  closed-form
expression is known for ∇φ∗  it can be computed efﬁciently  in O(n log n) time using a deterministic
algorithm  or O(n) expected time using a randomized algorithm  see [17]. Additionally  φ satisﬁes
1+n-strongly convex and 1-smooth w.r.t. (cid:107) · (cid:107)∞. The resulting accelerated
our assumptions: it is
mirror descent method on the simplex can then be implemented efﬁciently  and by Theorem 3 it is
guaranteed to converge in O(1/k2) whenever γ ≥ 1 and s ≤
5 Numerical Experiments

2(1+n)Lf γ .

(z)i =





.

We test the accelerated mirror descent method in Algorithm 1  on simplex-constrained prob-
lems in Rn  n = 100  with two different objective functions: a simple quadratic f (x) =
(cid:104)x − x(cid:63)  Q(x − x(cid:63))(cid:105)  for a random positive semi-deﬁnite matrix Q  and a log-sum-exp function

7

(a) Weakly convex quadratic  rank 10

(b) Log-sum-exp

(c) Effect of the parameter r.

r

˜z(k+1) ← x(k+1)  l ← 0

(cid:16)(cid:80)I

i=1 (cid:104)ai  x(cid:105) + bi

5:
6:
7:
8:

r+l
+ Dψ(˜z  ˜z(k))

+ R(˜x  x(k+1))

x(k+1) = λl ˜z(k) + (1 − λl)˜x(k)  with λl = r
˜z(k+1) = arg min˜z∈X ks
˜x(k+1) = arg min˜x∈X γs
l ← l + 1
if Restart condition then

Figure 1: Evolution of f (x(k)) − f (cid:63) on simplex-constrained problems  using different accelerated
mirror descent methods with entropy distance generating functions.
Algorithm 2 Accelerated mirror descent with restart
1: Initialize l = 0  ˜x(0) = ˜z(0) = x0.
2: for k ∈ N do
3:
4:

(cid:68)∇f (x(k+1))  ˜z
(cid:69)
(cid:68)∇f (x(k+1))  ˜x
(cid:69)
(cid:17)
  where each entry in ai ∈ Rn and bi ∈ R is iid nor-
given by f (x) = ln
mal. We implement the accelerated entropic descent algorithm proposed in Section 4.4  and in-
clude the (non-accelerated) entropic descent for reference. We also adapt the gradient restarting
heuristic proposed by O’Donoghue and Cand`es in [24]  as well as the speed restart heuristic pro-
posed by Su et al. in [28]. The generic restart method is given in Algorithm 2. The restart condi-

tions are the following: (i) gradient restart: (cid:10)x(k+1) − x(k) ∇f (x(k))(cid:11) > 0  and (ii) speed restart:

(cid:107)x(k+1) − x(k)(cid:107) < (cid:107)x(k) − x(k−1)(cid:107).
The results are given in Figure 1. The accelerated mirror descent method exhibits a polynomial
convergence rate  which is empirically faster than the O(1/k2) rate predicted by Theorem 3. The
method also exhibits oscillations around the set of minimizers  and increasing the parameter r seems
to reduce the period of the oscillations  and results in a trajectory that is initially slower  but faster
for large k  see Figure 1-c. The restarting heuristics alleviate the oscillation and empirically speed
up the convergence. We also visualized  for each experiment  the trajectory of the iterates x(k) for
each method  projected on a 2-dimensional hyperplane. The corresponding videos are included in
the supplementary material.

6 Conclusion

By combining the Lyapunov argument that motivated mirror descent  and the recent ODE interpre-
tation [28] of Nesterov’s method  we proposed a family of ODE systems for minimizing convex
functions with a Lipschitz gradient  which are guaranteed to converge at a O(1/t2) rate  and proved
existence and uniqueness of a solution. Then by discretizing the ODE  we proposed a family of
accelerated mirror descent methods for constrained optimization and proved an analogous O(1/k2)
rate when the step size is small enough. The connection with the continuous-time dynamics moti-
vates a more detailed study of the ODE (5)  such as studying the oscillatory behavior of its solution
trajectories  its convergence rates under additional assumptions such as strong convexity  and a rig-
orous study of the restart heuristics.
Acknowledgments

We gratefully acknowledge the NSF (CCF-1115788  CNS-1238959  CNS-1238962  CNS-1239054 
CNS-1239166)  the ARC (FL110100281 and ACEMS)  and the Simons Institute Fall 2014 Algo-
rithmic Spectral Graph Theory Program.

8

10020030040050060070010−1710−1310−910−510−1kf(x(k))−f?MirrordescentAcceleratedmirrordescentSpeedrestartGradientrestart10020030040050060010−1410−1110−810−510−2kf(x(k))−f?MirrordescentAcceleratedmirrordescentSpeedrestartGradientrestart10020030040050060070080010−1710−1410−1110−810−510−2kf(x(k))−f?r=3r=10r=30r=90References
[1] Zeyuan Allen-Zhu and Lorenzo Orecchia. Linear coupling: An ultimate uniﬁcation of gradient and mirror

descent. In ArXiv  2014.

[2] Arindam Banerjee  Srujana Merugu  Inderjit S. Dhillon  and Joydeep Ghosh. Clustering with Bregman

divergences. J. Mach. Learn. Res.  6:1705–1749  December 2005.

[3] Amir Beck and Marc Teboulle. Mirror descent and nonlinear projected subgradient methods for convex

optimization. Oper. Res. Lett.  31(3):167–175  May 2003.

[4] Amir Beck and Marc Teboulle. A fast iterative shrinkage-thresholding algorithm for linear inverse prob-

lems. SIAM Journal on Imaging Sciences  2(1):183–202  2009.

[5] A. Ben-Tal and A. Nemirovski. Lectures on Modern Convex Optimization. SIAM  2001.
[6] Aharon Ben-Tal  Tamar Margalit  and Arkadi Nemirovski. The ordered subsets mirror descent optimiza-

tion method with applications to tomography. SIAM J. on Optimization  12(1):79–108  January 2001.

[7] Anthony Bloch  editor. Hamiltonian and gradient ﬂows  algorithms  and control. American Mathematical

Society  1994.

[8] A. A. Brown and M. C. Bartholomew-Biggs. Some effective methods for unconstrained optimization
based on the solution of systems of ordinary differential equations. Journal of Optimization Theory and
Applications  62(2):211–224  1989.

[9] S´ebastien Bubeck and Nicol`o Cesa-Bianchi. Regret analysis of stochastic and nonstochastic multi-armed

bandit problems. Foundations and Trends in Machine Learning  5(1):1–122  2012.

[10] J. C. Butcher. Numerical Methods for Ordinary Differential Equations. John Wiley & Sons  Ltd  2008.
[11] Nicol`o Cesa-Bianchi and G´abor Lugosi. Prediction  Learning  and Games. Cambridge  2006.
[12] Ofer Dekel  Ran Gilad-Bachrach  Ohad Shamir  and Lin Xiao. Optimal distributed online prediction. In

Proceedings of the 28th International Conference on Machine Learning (ICML)  June 2011.

[13] U. Helmke and J.B. Moore. Optimization and dynamical systems. Communications and control engineer-

ing series. Springer-Verlag  1994.

[14] Anatoli Juditsky. Convex Optimization II: Algorithms  Lecture Notes. 2013.
[15] Anatoli Juditsky  Arkadi Nemirovski  and Claire Tauvel. Solving variational inequalities with stochastic

mirror-prox algorithm. Stoch. Syst.  1(1):17–58  2011.

[16] H.K. Khalil. Nonlinear systems. Macmillan Pub. Co.  1992.
[17] Walid Krichene  Syrine Krichene  and Alexandre Bayen. Efﬁcient Bregman projections onto the simplex.

In 54th IEEE Conference on Decision and Control  2015.

[18] A.M. Lyapunov. General Problem of the Stability Of Motion. Control Theory and Applications Series.

Taylor & Francis  1992.

[19] A. S. Nemirovsky and D. B. Yudin. Problem Complexity and Method Efﬁciency in Optimization. Wiley-

Interscience series in discrete mathematics. Wiley  1983.

[20] Yu. Nesterov. Smooth minimization of non-smooth functions. Mathematical Programming  103(1):127–

152  2005.

[21] Yu. Nesterov. Gradient methods for minimizing composite functions. Mathematical Programming 

140(1):125–161  2013.

[22] Yurii Nesterov. A method of solving a convex programming problem with convergence rate o(1/k2).

Soviet Mathematics Doklady  27(2):372–376  1983.

[23] Yurii Nesterov. Introductory Lectures on Convex Optimization  volume 87. Springer Science & Business

Media  2004.

[24] Brendan O’Donoghue and Emmanuel Cand`es. Adaptive restart for accelerated gradient schemes. Foun-

dations of Computational Mathematics  15(3):715–732  2015.

[25] M. Raginsky and J. Bouvrie. Continuous-time stochastic mirror descent on a network: Variance reduction 

consensus  convergence. In CDC 2012  pages 6793–6800  2012.

[26] R.T. Rockafellar. Convex Analysis. Princeton University Press  1970.
[27] J. Schropp and I. Singer. A dynamical systems approach to constrained minimization. Numerical Func-

tional Analysis and Optimization  21(3-4):537–551  2000.

[28] Weijie Su  Stephen Boyd  and Emmanuel Cand`es. A differential equation for modeling Nesterov’s accel-

erated gradient method: Theory and insights. In NIPS  2014.

[29] Gerald Teschl. Ordinary differential equations and dynamical systems  volume 140. American Mathe-

matical Soc.  2012.

9

,Syama Sundar Rangapuram
Pramod Kaushik Mudrakarta
Matthias Hein
Walid Krichene
Alexandre Bayen
Peter Bartlett
Sheng Chen
Arindam Banerjee