2018,Dialog-to-Action: Conversational Question Answering Over a Large-Scale Knowledge Base,We present an approach to map utterances in conversation to logical forms  which will be executed on a large-scale knowledge base. To handle enormous ellipsis phenomena in conversation  we introduce dialog memory management to manipulate historical entities  predicates  and logical forms when inferring the logical form of current utterances. Dialog memory management is embodied in a generative model  in which a logical form is interpreted in a top-down manner following a small and flexible grammar. We learn the model from denotations without explicit annotation of logical forms  and evaluate it on a large-scale dataset consisting of 200K dialogs over 12.8M entities. Results verify the benefits of modeling dialog memory  and show that our semantic parsing-based approach outperforms a memory network based encoder-decoder model by a huge margin.,Dialog-to-Action: Conversational Question

Answering Over a Large-Scale Knowledge Base

Daya Guo1∗  Duyu Tang2  Nan Duan2  Ming Zhou2  and Jian Yin1
1 The School of Data and Computer Science  Sun Yat-sen University.

Guangdong Key Laboratory of Big Data Analysis and Processing  Guangzhou  P.R.China

2 Microsoft Research Asia  Beijing  China

{guody5@mail2 issjyin@mail}.sysu.edu.cn
{dutang nanduan mingzhou}@microsoft.com

Abstract

We present an approach to map utterances in conversation to logical forms  which
will be executed on a large-scale knowledge base. To handle enormous ellipsis phe-
nomena in conversation  we introduce dialog memory management to manipulate
historical entities  predicates  and logical forms when inferring the logical form of
current utterances. Dialog memory management is embodied in a generative model 
in which a logical form is interpreted in a top-down manner following a small and
ﬂexible grammar. We learn the model from denotations without explicit annotation
of logical forms  and evaluate it on a large-scale dataset consisting of 200K dialogs
over 12.8M entities. Results verify the beneﬁts of modeling dialog memory  and
show that our semantic parsing-based approach outperforms a memory network
based encoder-decoder model by a huge margin.

1

Introduction

We consider the problem of mapping conversational natural language questions to formal represen-
tations (e.g.  logical form) of their underlying meanings  which would be executed to produce the
answer (denotation) [1–7]. We study the problem in a realistic setting that (1) only denotations are
available for model training while the underlying logical forms remain unknown  and (2) logical
forms will be executed on a large-scale knowledge base (KB) consisting of tens of millions of entities.
We believe that KB-based conversational question answering plays an important role in both search
engines and intelligent personal assistants (e.g.  Siri  Alexa  Cortana/Xiaoice  and Google Now) [8]
to improve the ability of multi-turn question answering.
The major challenge of this task is how to interpret the meaning of an utterance in interaction where
ellipsis phenomena are frequently encountered. Let’s consider the example in Figure 1. The ellipsis
of the entity “he” in Q2 refers to “President of the United States” in Q1. The ellipsis of the entity “it”
in Q3 means the answer R2. In Q4  the ellipsis of the predicate (“yearEstablished”) comes from Q3.
We see that understanding the meaning of conversational utterances requires a good understanding of
dialog history. Another challenge is how to efﬁciently learn the semantic parser from denotations.
Online learning by searching legitimate logical forms requires repeated execution on a large-scale
knowledge base  which is extremely time-consuming and intolerable.
In this work  we regard the generation of a logical form as the prediction of a sequence of actions
[9  10  6  11–16]  each of which corresponds to a derivation rule in a simple and ﬂexible grammar. We
introduce a generative model that interprets the logical form of an utterance in a top-down manner. A
grammar-guided decoder is developed to generate possible action sequences following the grammar.

∗Work done while this author was an intern at Microsoft Research.

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

Figure 1: An example illustrating the task of conversational question answering.

To cope with ellipsis phenomena in conversation  we introduce a dialog memory management
component that leverages historical entities  predicates  and action subsequences when generating the
logical form for a current utterance. To avoid the time-consuming procedure of repeatedly executing
on a large-scale knowledge base during training [6]  we conduct a breadth-ﬁrst-search algorithm in
advance to obtain pairs of utterances and their action sequences that lead to correct answers. The
model is learned by maximizing the likelihood of generating the expected action sequences [5  11].
We conduct experiments on a large-scale dataset [17] for conversation question answering  which
consists of 200K dialogs with 1.6M turns over 12.8M entities from Wikidata. Compared to a memory
network enhanced encoder-decoder method [17]  our semantic parsing-based approach achieves
better performance. We show the beneﬁts of using dialog memory  and observe that our approach
performs well on those questions which rely on dialog contexts for resolving ellipsis phenomena.

2 Problem Statement

Our goal is to answer questions (utterances) in conversations based on a large-scale open-domain
knowledge base (KB). We tackle the problem in a semantic parsing manner that ﬁrst maps the
question into executable logical forms  and then executes the generated logical form on a KB to
produce the answer. We would like to learn the semantic parser from denotations  having no luxury of
access to the annotated logical form for each utterance. Formally  let I be an interaction consisting of
n utterances/questions {q1  q2  ...  qn}2. During training  each question qi is paired with the correct
answer ai  without explicit annotation of the correct logical form zi. In the inference process  a
i is derived based on the current question qi and its preceding questions {q1  q2  ..  qi−1}.
logical form z(cid:48)
i on knowledge base K produces the outcome a(cid:48)
Executing z(cid:48)
i.

3 Grammar

In this section  we describe the actions we deﬁne in this work for generating logical forms. A
summary of all the actions are given in Table 1.

Note

Table 1: The base actions we use in this work for generating logical forms.
Operation
start → set|num|bool
set → f ind(set  r)
num → count(set)
bool → in(e  set)
set → union(set1  set2)
set → inter(set1  set2)
set → dif f (set1  set2)
set → larger(set  r  num)
set → less(set  r  num)
set → equal(set  r  num)
set → argmax(set  r)
set → argmin(set  r)
set → {e}
e|r|num → constant
set|num|bool → actioni−1

set of entities with a r edge to e
total number of set
whether e is in set
union of set1 and set2
intersection of set1 and set2
instances included in set1 but not included in set2
subset of set linking to more than num entities with relation r
subset of set linking to less than num with relation r
subset of set linking to num entities with relation r
subset of set linking to most entities with relation r
subset of set linking to least entities with relation r

instantiation for entity e  predicate r or number num
replicate previous action subsequence (w/o or w/ instantiation)

Action
A1-A3

A4
A5
A6
A7
A8
A9
A10
A11
A12
A13
A14
A15

A16-A18
A19-A21

2We use the terms utterance and question interchangeably.

2

Q1: Where was the President of the United States born?R3:1881Q2:Where did he graduate from?R1:New York CityR2:Wharton School of the University of PennsylvaniaQ3: What year was it established?R4:1636Q4: How about Harvard university?FreebaseDBpediaYAGONELLOpenIE/ReVerbAnalogous to the meaning representation of [9]  each action in this work consists of three components:
a semantic category  a function symbol which might be omitted  and a list of arguments. An argument
can be a semantic category  a constant  or an action subsequence. Take A5 for example: it has a
semantic category num  a function symbol count  and a semantic category set as the only argument.
We add A16-A18 to instantiate entity e  predicate r  and number num  respectively. We add A19-A21
for replicating a subsequence of previously predicated action sequence from the dialog memory. The
derivation of a logical form starts from the semantic category start. As derivation processes  the
model recursively rewrites the leftmost nonterminal (i.e semantic category) in the logical form by
applying a legitimate action. The parsing process terminates until no nonterminals remain.

4 Dialog-to-Action

We describe our semantic parsing-based model in this section. Based on sequence-to-sequence
learning [18  19]  the model takes a question and its context from interaction history as the input and
generates an action sequence. We develop a grammar-guided decoder to control the generation of an
action sequence  and a dialog memory management component to leverage historical contexts.

4.1 Encoder

Figure 2 illustrates an overview of the proposed model. Since previous questions and answer-
s/responses in conversation are useful contexts  we concatenate them with the current question as an
input x = (x1  ...  xT ). A bidirectional RNN with a gated recurrent unit (GRU) [20] is used as the
encoder to convert the input to a sequence of context vector. The forward RNN reads the input in
−→
left-to-right direction  obtaining hidden states (
hT ). The backward RNN reads reversely and
←−
hT ). We then get the ﬁnal representation (h1  ...  hT ) for each word in the source
outputs (
←−
sequence  where hj = [
h1]) is used as
initial hidden state of the decoder.

←−
hj]. The representation of the source sequence hx = ([

←−
h1  ... 

−→
h1  ... 

−→
hT ;

−→
hj;

4.2 Grammar-guided Decoder

We use GRU with an attention mechanism as a decoder  which generates an action sequence a1  ...  an
in a sequential way. As we can see from Figure 2  the decoder parses the dialog to an action sequence 
which corresponds to the parsing tree shown in the lower right side. At each time-step t  we apply an
attention mechanism to obtain the context vector ct that is computed in the same way as [21]. The
concatenation of the context vector ct  the last hidden state sdec
t−1 and the embedding vt−1 of previously
predicted action is fed to the decoder to get the current hidden state sdec
t−1  vt−1  ct). If
the previously predicted action is an instantiated action  the embedding vt−1 is the representation
is used with the same attention mechanism
of the selected constant. The current hidden state sdec
over the inputs to get the context vector sc
t to get ﬁnal hidden states
st. In order to generate a valid logical form  we incorporate an action-constrained grammar to ﬁlter
illegal actions. An action is legitimate if its left-hand semantic category is the same as the leftmost
nonterminal in the partial logical form parsed so far. We denote the set of legitimate actions at the
time step t as At = {a1  ...  aN}. The probability distribution over the set is calculated as Equation
1  where vi is the one-hot indicator vector for ai  Wa is model parameter  and a<t stands for the
preceding actions of the t-th time step.

t. We then concatenate sdec

t = GRU (sdec

and sc

t

t

(1)

p(ai|a<t  x) =

4.3 Dialog Memory

(cid:80)

exp(vT

i Wast)

aj∈At

exp(vT

j Wast)

Interaction history is very important to generate the logical form of the following utterance. Therefore 
we incorporate a dialog memory to maintain information from interaction history. As illustrated in
Figure 2  the dialog memory includes three types of information  including entities  predicates  and
action subsequences. We describe these aspects one after another.
Entity We consider two types of entities from interaction history  coming from the previous question
utterance and the previous answer  respectively. The ﬁrst type is suitable for a common co-reference

3

Figure 2: An illustration of the proposed approach. Our approach is the encoder-decoder structure
with dialog memory management component. The lower right side is a parsing tree corresponding to
the action sequence generated by the decoder.

case where the ellipsis entity comes from the previous utterance  such as “Q1: Where was the
President of the United States born”  “Q2: Where did he graduate from”. The second type is suitable
for the case in ellipsis entities comes from the previous answer  such as Q3 and R2 in Figure 1.
Predicate We record the predicates of the previous utterance. This is useful for the scenario where the
ellipsis of the predicate occurs. Let us take Q3 and Q4 from Figure 1 as an example. The predicate
“yearEstablished” is not explicitly expressed in Q4  yet mentioned in Q3.
Action Subsequences An action subsequence could be roughly categorized as instantiated or not.
Indeed  an action subsequence with instantiation stands for a full or a partial logical form. For
example  the ﬁrst action subsequence in the dialog memory of Figure 2 is identical to the logical
form f ind(U nitedStates  isP residentOf )  which means the president of the United States. The
ellipsis of the entity “he” in the current question “Where did he graduate from?” actually refers to
the president of the United States. Therefore  the model executes an action (i.e. A19) to replicate the
ﬁrst action subsequence. An action subsequence without instantiation conveys the soft pattern of a
logical form. For example  the current question “And how about China?” has the same soft pattern
as the previous question  but the country mentioned in the previous question should be replaced by
“China”.
For more details on establishment of the dialog memory  see Appendix A.

4.4

Incorporating Dialog Memory

In this section  we present our strategy to replicate contents from dialog memory as decoding
processes. This has an inﬂuence on A16-A21  which we would list as follows.
Instantiation: We allow instantiated actions (i.e. A16-A18) to access to the dialog memory when
the decoder instantiates an entity  predicate  or number. Taking entities as an example. Each entity is
assigned one of three tags: previous question  previous answer  or current question. The probability of
an entity et being instantiated at time-step t is calculated as Equation 2  where pg(·) is the probability
of the tag gt to be chosen  and pe(·) is the probability distribution over entities for each tag.

p(et|a<t  x) = pe(et|gt  a<t  x)pg(gt|a<t  x)

(2)
The probability distribution of entities pe(·) is calculated as Equation 3  where ve is the embedding of
entity et  We is model parameter  and Egt is the set of entities having tag gt. The probability pg(·) is
implemented by a linear layer followed by a softmax function  and the input is st. The instantiations
of predicates and numbers are similar to entities  except that predicates have two kinds of tags (i.e.

4

Dialog MemoryEntity{United States  tag=utterance}{New York City  tag=answer}Predicate {isPresidentOf}{placeOfBirth}ActionSubsequence𝑠𝑒𝑡→𝐴4𝐴15𝑒𝑈𝑆𝑟𝑝𝑟𝑒𝑠𝑠𝑒𝑡→𝐴4𝐴15𝑠𝑒𝑡→𝐴4𝐴4𝐴15𝑒𝑈𝑆𝑟𝑝𝑟𝑒𝑠𝑟𝑏𝑡ℎ𝑠𝑒𝑡→𝐴4𝐴4𝐴15Where did president of the United States born?New York CityWhere did he graduate from?𝑟𝑔𝑟𝑎𝑑𝑟𝑔𝑟𝑎𝑑𝑒𝑛𝑑𝐴4𝐴19𝐴4𝐴15𝐴19𝑒𝑈𝑆𝑟𝑝𝑟𝑒𝑠replicated action sequence w/ instantiationPrevious Question Previous Answer Current Question SsetA1find(set  r1)A4graduateFromA17find(set  r2)A4{e}United StatesA15A16isPresidentOfA17𝑆𝐴1𝐴1𝐴4copyprevious question and current question) and numbers have only one tag (i.e current question).

pe(et|gt  a<t  x) =

exp(vT

e tanh(West))
exp(vT

e(cid:48)tanh(West))

e(cid:48)∈Egt

(cid:80)

(3)

(5)

Replication: The model learns to copy a previous action subsequence through choosing A19-A21.
It has two modes that replicate instantiated or non-instantiated action subsequences. Figures 2
illustrates how the model replicates instantiated action subsequences. In order to obtain instantiated
action subsequences of the previous question  we parse the whole previous logical form to a tree and
enumerate all subtrees  each of which corresponds to an instantiated action subsequence. Another
mode will be described in appendix B. In our model  the probability of a subsequence to be copied is
calculated as Equation 4  where pm(·) is the probability of the mode mt to be chosen  and ps(·) is
the probability distribution over subsequences for each mode.

p(subt|a<t  x) = ps(subt|mt  a<t  x)pm(mt|a<t  x)

(4)
The probability of copying the subsequence subt  namely ps(subt|mt  a<t  x)  is calculated as
follows  where vsub is the representation of subt  and Emt is the set of subsequences given mode mt.
vsub is obtained by encoding subt using a GRU. The calculation of pm(·) is analogous to pg(·).

ps(subt|mt  a<t  x) =

(cid:80)

exp(vT

si∈Emt

subtanh(Wsst))
exp(vT

sitanh(Wsst))

After replicating a subsequence action  the decoder clamps the generation of subsequence length by
continuously feeding the subsequence actions one by one. In the inference process  we obtain action
subsequences from the predicted logical form with the highest score. Error propagation might occur
when the model replicates an incorrect previous logical form  which hurts performance. Therefore 
we consider the score of action subsequence as a degree of conﬁdence  which is calculated in the
same way as the probability of action subsequences without replication.

5 Learning and Inference

At the training phase  instances from training data are labeled with answers while action sequences
remain unknown. In order to train our model  we ﬁrst generate action sequences for each example 
and then use an approximate marginal log-likelihood as the objective function. We use a breadth-
ﬁrst-search algorithm from root to generate a set of action sequences Sa that are executed to the
correct answer. To cover the replication of action subsequences from dialog memory  we regard
action subsequences in Sa which appear in the dialog memory as replicated action subsequences.
In order to guarantee the quality of training instances with replication actions  we have a constraint
that at least one instantiated constant should be the same. The objective function is the sum of log
probabilities of actions  instantiations  and replications  where δ(ins  at) is 1 if at is an instantiation
action otherwise 0  and δ(rep  at) is the same as δ(ins  at)  where rep means a replication action.
δ(rep  at)logp(subt|a<t  x)
(6)
We use beam search at the inference phase. For more details on the training and inference procedures
used in the experiments  see Appendix C.

δ(ins  at)logp(et|a<t  x) −(cid:88)

logp(at|a<t  x) −(cid:88)

loss = −(cid:88)

t

t

t

6 Experiment

We conduct the experiment on the CSQA dataset3. The dataset is created based on Wikidata4 
including 152K dialogs for training  and 16K/28K dialogs for development/testing. Questions in
dialogs are classiﬁed as kinds of types  examples of which are shown in Figure 3. We use the same
evaluation metrics employed in [17]. Precision and recall are used as evaluation metrics for questions
whose answers are entities  which measures the percentage of correct entities in the output and
the percentage of correct entities that are retrieved  respectively. Accuracy is used to measure the
performance for questions which produce boolean and numerical answers.

3https://amritasaha1812.github.io/CSQA/
4https://www.wikidata.org

5

Table 2: Performance of different approaches on the CSQA dataset.

Methods
Question Type
Overall
Simple Question (Direct)
Simple Question (Co-referenced)
Simple Question (Ellipsis)
Logical Reasoning (All)
Quantitative Reasoning (All)
Comparative Reasoning (All)
Clariﬁcation
Question Type
Veriﬁcation (Boolean)
Quantitative Reasoning (Count)
Comparative Reasoning (Count)

HRED+KVmem
Precision
Recall
6.30%
18.40%
8.58%
33.30%
5.09%
12.67%
6.98%
17.30%
5.75%
15.11%
1.01%
0.91%
2.11%
4.97%
25.09% 12.13%

Accuracy
21.04%
12.13%
8.67%

ContxIndp-SP

Recall
Precision
42.18% 40.88%
94.04% 88.32%
40.29% 38.55%
14.09% 13.28%
36.23% 35.91%
43.75% 49.91%
41.49% 38.91%
0.01%
0.01%

Accuracy
20.38%
30.60%
15.54%

D2A

Recall
Precision
64.04% 61.76%
93.67% 89.26%
71.31% 68.41%
86.58% 77.85%
42.49% 44.82%
48.59% 52.03%
44.73% 43.69%
19.36% 17.36%

Accuracy
45.05%
40.94%
17.78%

6.1 Model Comparisons

Table 2 shows the results of different methods on CSQA data. HRED+KVmem [17] is a sequence-
to-sequence learning method  which uses a hierarchical encoder and a key-value memory network
[22] to compute the representation for the question and its contexts  and then uses an RNN as
the decoder to directly produce answers. To demonstrate the effectiveness of dialog memory  we
implement a context-independent semantic parser ContxIndp-SP  in which the dialog memory is
totally removed from the full Dialog-to-Action model. Our full model is abbreviated as D2A (short
for Dialog-to-Action).
Our approach is a semantic parsing based method  which explicitly manipulates the actions/functions
and lets the Seq2Seq model learn how these actions are used to derive the logical form of the question.
It could naturally leverage parsed results of previous turn including entities  predicates and action
subsequences to handle various ellipsis phenomena. HRED+KVmem is a text generation based
approach that puts the entire burden of doing reasoning and compositionality to the Seq2Seq model 
which struggles at handling all these problems in an implicit way. Results demonstrate that namely
semantic parsing approach is more effective to handle complex questions  including quantitative 
comparative and logical reasoning. We can also see that incorporating the dialog memory brings
signiﬁcant improvements in co-referenced and ellipsis categories. The results also show that the
dialog memory is very important to handle ellipsis phenomena in conversation.

6.2 Model Analysis

We conduct ablation analysis to better understand how various components in the dialog memory
impact overall performance. We remove entity memory (EM)  predicate memory (PM) and action
subsequence memory (AM)  respectively  to analyze their contribution.

D2A w/o PM

D2A w/o AM

Table 3: Performance of different approaches on the CSQA dataset. EM  PM and AM stand for
entities  predicates  and subsequent action sequences from dialog memory  respectively.
Methods
Question Type
Overall
Simple Question (Direct)
Simple Question (Co-referenced)
Simple Question (Ellipsis)
Logical Reasoning (All)
Quantitative Reasoning (All)
Comparative Reasoning (All)
Clariﬁcation
Question Type
Veriﬁcation (Boolean)
Quantitative Reasoning (Count)
Comparative Reasoning (Count)

Recall
Precision
57.52% 56.20%
93.39% 88.76%
70.42% 67.89%
15.35% 13.73%
38.20% 42.37%
44.18% 48.30%
39.40% 38.58%
0.86%
1.11%

Recall
Precision
64.02% 62.85%
93.55% 88.63%
73.36% 72.01%
85.96% 80.44%
38.69% 40.11%
43.57% 50.89%
41.95% 43.65%
17.76% 16.16%

Accuracy
18.44%
38.89%
16.51%

D2A w/o EM

Recall
Precision
44.93% 44.13%
93.09% 88.59%
37.95% 36.54%
81.82% 76.69%
40.85% 42.76%
43.87% 52.16%
42.47% 44.74%
1.44%
1.79%

Accuracy
47.92%
34.04%
15.38%

Accuracy
50.84%
39.14%
16.79%

6

Table 3 shows that the recall and precision of co-referenced questions drop from ∼70% to ∼37%
when ablating entity memory (D2A w/o EM)  which reveals the importance of entity memory
in a co-referenced scenario. We can see that the accuracy of veriﬁcation questions drops from
45.05% to 18.44%  which means this type of question also needs information on entities from history
interaction. After removing the predicate memory  the model (D2A w/o PM) performs poorly in
ellipsis questions  dropping from ∼80% to ∼15%. This is consistent with our intuition that the
predicate of an ellipsis question comes from the previous question. Results show that removing action
subsequence memory (D2A w/o AM) hurts the performance on complex questions including logical
reasoning and quantitative reasoning. After analyzing examples of these two types  we observe that
ellipsis and co-reference phenomena occur in complex questions  the understanding of which needs
to copy complex logical form from previous questions.
To better understand the ability of our semantic parser  we show examples to illustrate the parsing
results by our approach (D2A) in Figure 3. As shown  our parser is capable of parsing various types
of questions. The 2nd and 3rd examples show that the dialog memory helps the parser replicate
entity and predicate from history interaction. Furthermore  replication actions work well in complex
questions such as 8th and 9th examples  where previous un-instantiated action subsequences are
replicated and instantiation follows.

Figure 3: Examples of the parsing results of D2A. Q1  R1 and Q2 stand for previous utterance 
previous answer and current question  respectively; copy() stands for one of the action from A19-A21
that replicates previous action subsequence; reverse() is a speciﬁc function that could be applied on
any predicate  resulting in doubled predicates.

6.3 Discussion

To understand the limitations of our approach and shed light on future directions to make further
improvements  we randomly select 100 wrongly predicted instances for each category  and summary
four main classes of errors as follows.
Entity Linking. A common problem is entity linking error when different entities have exactly the
same surface name. Based on a balance between accuracy and latency  we represent an entity based
on the words it contains in this work  so that there’s no difference in their representation. A potential
way to alleviate this problem is to learn better word representations by considering the contexts from
a knowledge graph [23  24].
Spurious Program. We collect referenced action sequence in an automatic way based on an
assumption that a logical form is correct if it could be executed to the correct answer. However  some

7

idquestiontypecurrent question + previous turnpredicted logical form1Simple Question (Direct)Q1: N/A R1: N/AQ2: Who was the dad of Jorgen OttesenBrahe?𝑓𝑖𝑛𝑑({𝐽𝑜𝑟𝑔𝑒𝑛𝑂𝑡𝑡𝑒𝑠𝑒𝑛𝐵𝑟𝑎ℎ𝑒} 𝑓𝑎𝑡ℎ𝑒𝑟)2Simple Question (Coreferenced)Q1: Who was the dad of Jorgen OttesenBrahe?R1: OtteBraheQ2: Who is the spouse of that one?𝑓𝑖𝑛𝑑({𝑂𝑡𝑡𝑒𝐵𝑟𝑒ℎ𝑒} 𝑠𝑝𝑜𝑢𝑠𝑒)3Simple Question (Ellipsis)Q1: What is the profession of MkihailBeliaiev?R1: Military personnelQ2: And also tell me about Brett MacLean𝑓𝑖𝑛𝑑({𝐵𝑟𝑒𝑡𝑡𝑀𝑎𝑐𝐿𝑒𝑎𝑛} 𝑜𝑐𝑐𝑢𝑝𝑎𝑡𝑖𝑜𝑛)4Logical Reasoning (All)Q1: N/A R1: N/AQ2: Which administrative territories have diplomatic relations with Italy and are not Derikhapresent in?𝑎𝑛𝑑(𝑑𝑖𝑓𝑓(𝑓𝑖𝑛𝑑({𝐼𝑡𝑎𝑙𝑦} 𝑟𝑒𝑣𝑒𝑟𝑠𝑒(𝑑𝑖𝑝𝑙𝑜𝑚𝑎𝑡𝑖𝑐𝑟𝑒𝑙𝑎𝑡𝑖𝑜𝑛)) 𝑓𝑖𝑛𝑑𝐷𝑒𝑟𝑖𝑘ℎ𝑎 𝑐𝑜𝑢𝑛𝑡𝑟𝑦) 𝑓𝑖𝑛𝑑𝑎𝑑𝑚𝑖𝑛𝑖𝑠𝑡𝑟𝑎𝑡𝑖𝑣𝑒𝑡𝑒𝑟𝑟𝑖𝑡𝑜𝑟𝑖𝑒𝑠 𝑖𝑠𝐴)5Quantitative ReasoningQ1: N/A R1: N/AQ2: Which works did min number of people do the dubbing for?𝑎𝑟𝑔𝑚𝑖𝑛(𝑓𝑖𝑛𝑑({𝑣𝑜𝑖𝑐𝑒𝑎𝑐𝑡𝑜𝑟} 𝑖𝑠𝑎) 𝑟𝑒𝑣𝑒𝑟𝑠𝑒(𝑤𝑜𝑟𝑘))6Comparative Reasoning Q1: N/A R1: N/AQ2: Which musical instruments are played by more number of people than electronic keyboard?𝑙𝑎𝑟𝑔𝑒𝑟(𝑓𝑖𝑛𝑑({𝑚𝑢𝑠𝑖𝑐𝑎𝑙𝑖𝑛𝑠𝑡𝑟𝑢𝑚𝑒𝑛𝑡𝑠} 𝑖𝑠𝐴) 𝑟𝑒𝑣𝑒𝑟𝑠𝑒𝑖𝑛𝑠𝑡𝑟𝑢𝑚𝑒𝑛𝑡 𝑐𝑜𝑢𝑛𝑡(𝑎𝑛𝑑(𝑓𝑖𝑛𝑑({𝑒𝑙𝑒𝑐𝑡𝑟𝑜𝑛𝑖𝑐𝑘𝑒𝑦𝑏𝑜𝑎𝑟𝑑} 𝑟𝑒𝑣𝑒𝑟𝑠𝑒(𝑖𝑛𝑠𝑡𝑟𝑢𝑚𝑒𝑛𝑡)) 𝑓𝑖𝑛𝑑({𝑝𝑒𝑜𝑝𝑙𝑒} 𝑖𝑠𝐴))))7Verification(Boolean)Q1: N/A R1: N/AQ2: Is Arizona Coyotes present in United States of America?𝑖𝑛(𝐴𝑟𝑖𝑧𝑜𝑛𝑎𝐶𝑜𝑦𝑜𝑡𝑒𝑠 𝑓𝑖𝑛𝑑({𝑈𝑛𝑖𝑡𝑒𝑑𝑆𝑡𝑎𝑡𝑒𝑠𝑜𝑓𝐴𝑚𝑒𝑟𝑖𝑐𝑎} 𝑟𝑒𝑣𝑒𝑟𝑠𝑒(𝑐𝑜𝑢𝑛𝑡𝑟𝑦)))8Quantitative Reasoning (Count)Q1: How many people have birthplace at Provence? R1: 15Q2: And how about Peterborough?𝑐𝑜𝑝𝑦(𝑐𝑜𝑢𝑛𝑡(𝑓𝑖𝑛𝑑({𝑃𝑒𝑡𝑒𝑟𝑏𝑜𝑟𝑜𝑢𝑔ℎ} 𝑟𝑒𝑣𝑒𝑟𝑠𝑒𝑝𝑙𝑎𝑐𝑒𝑜𝑓𝑏𝑖𝑟𝑡ℎ)))9Comparative Reasoning (Count)Q1: How many musical instruments are played by greater number of people than Body percussion ? R1: 30Q2: And also tell me about timpani?𝑐𝑜𝑝𝑦(𝑐𝑜𝑢𝑛𝑡(𝑙𝑎𝑟𝑔𝑒𝑟(𝑓𝑖𝑛𝑑({𝑚𝑢𝑠𝑖𝑐𝑎𝑙𝑖𝑛𝑠𝑡𝑟𝑢𝑚𝑒𝑛𝑡} 𝑖𝑠𝐴) 𝑟𝑒𝑣𝑒𝑟𝑠𝑒(𝑖𝑛𝑠𝑡𝑟𝑢𝑚𝑒𝑛𝑡) 𝑐𝑜𝑢𝑛𝑡(𝑓𝑖𝑛𝑑({𝑡𝑖𝑚𝑝𝑎𝑛𝑖} 𝑟𝑒𝑣𝑒𝑟𝑠𝑒(𝑖𝑛𝑠𝑡𝑟𝑢𝑚𝑒𝑛𝑡))))))of these logical forms are spurious [5]  in the sense that they do not represent the meaning of question
but get the correct answer. Filtering rules might be useful to ﬁlter out spurious logical forms.
Error Propagation. The problem of error propagation occurs because our model learns to replicate
previously generated action sequences  which might be incorrect despite we consider the probability
of the previous logical form. The problem might be alleviated if we incorporate more signals to
measure the correctness of a logical form.
Unsupported Actions. There exist examples whose logical forms could be not covered by our
grammar. An example is “How many political and administrative territories have diplomatic
relationships with France?”  whose answer is “3 and 15”. Incorporating more actions might improve
the coverage  however  the aim of this paper is not to explore dataset-speciﬁc grammar  but to show
that a ﬂexible grammar works well and dialog memory helps.

7 Related Work

Our task closely relates to two lines of works on content-dependent semantic parsing  categorized by
the type of supervision used for model learning.
The ﬁrst line of work learns a context-dependent semantic parser from fully annotated logical forms.
[1] ﬁrst learn a context-independent CCG parser  and then conduct context-dependent substitution and
elaboration. [3] produce logical forms using a set of classiﬁcation models. [7] propose a sequence-to-
sequence model with a copying mechanism to replicate previously generated logical form. The main
difference between our task and this line of work is that we learn from denotations with no access to
annotated logical forms.
The second line of work learns a model from denotations  which could be the answer [6] or the ﬁnal
world state [4]. [2] jointly learn a weighted CCG parser and execute spatial/instructional language in
navigation environments. [4] develop a shift-reduce parser and use model projection to reduce the
search space. [5] generate tokens of action  constant  and function with a sequence-to-sequence model 
and use meritocratic gradient weights and randomized beam search to alleviate the spurious program
problem. [25] mapping context-sequential instructions to actions sequence  and propose a learning
algorithm that take advantage of single-step reward observations and immediate expected reward
maximization. [6] regard SQL generation as action sequence prediction  and search legitimate action
sequences through online learning. A special “subsequent” action is deﬁned to replicate the entire
SQL query of the previously contiguous utterance. Generated SQL query will be executed on a web
table to produce the answer. Similar to [6]  our deﬁnitions of action and structure constraint depend
on the language of the target logical form. Compared to their method that only learns to replicate
the entire logical form of previous utterance  our model is more ﬂexible and capable of replicating
various information from dialog memory including entities  predicates  and action subsequences
(i.e. partial logical forms). Our task differs from this line of work in that our logical forms interact
with a large-scale knowledge base  which poses new challenges for model training. There also exist
memory or encoder-decoder based methods [17  26  27] that directly generate an answer utterance as
the output of the decoder. Our semantic parsing-based model is essentially different from them in
that deep question understanding is required to produce the explicit logical form of the underlying
meaning. Our task differs from the “QA+recommendation dialog” task [28  29] in that they only ask
question in the second turn  the intention of which is about the recommended entity of the ﬁrst turn.

8 Conclusion

We present the Dialog-to-Action  a generative model that converts an utterance in conversation to a
logical form  which will be executed on a large-scale knowledge base to produce the answer. The
model works in a top-down manner following a small and ﬂexible grammar  in which the generation of
a logical form is equivalent to the prediction of a sequence of actions. A dialog memory management
is developed and naturally integrated in the model  so that historical entities  predicates  and action
subsequences could be selectively replicated. The model is effectively learned from denotations
without using annotated logical forms. Results on a large-scale dataset demonstrate the effectiveness
of considering the dialog memory  and show that our model performs signiﬁcantly better than a strong
memory network-based encoder-decoder model.

8

Acknowledgments

This work is supported by the National Natural Science Foundation of China (61472453  U1401256 
U1501252  U1611264  U1711261  U1711262). Thanks to the anonymous reviewers and Junwei Bao
for their helpful comments and suggestions.

References
[1] Luke S Zettlemoyer and Michael Collins. Learning context-dependent mappings from sentences to
logical form. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th
International Joint Conference on Natural Language Processing of the AFNLP  pages 976–984  2009.

[2] Yoav Artzi and Luke Zettlemoyer. Weakly supervised learning of semantic parsers for mapping instructions

to actions. Transactions of the Association of Computational Linguistics  1:49–62  2013.

[3] Andreas Vlachos and Stephen Clark. A new corpus and imitation learning framework for context-dependent

semantic parsing. Transactions of the Association for Computational Linguistics  2:547–559  2014.

[4] Reginald Long  Panupong Pasupat  and Percy Liang. Simpler context-dependent logical forms via model
projections. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics
(Volume 1: Long Papers)  pages 1456–1465. Association for Computational Linguistics  August 2016.

[5] Kelvin Guu  Panupong Pasupat  Evan Liu  and Percy Liang. From language to programs: Bridging
reinforcement learning and maximum marginal likelihood. In Proceedings of the 55th Annual Meeting of
the Association for Computational Linguistics  pages 1051–1062  2017.

[6] Mohit Iyyer  Wen-tau Yih  and Ming-Wei Chang. Search-based neural structured learning for sequential
question answering. In Proceedings of the 55th Annual Meeting of the Association for Computational
Linguistics (Volume 1: Long Papers)  volume 1  pages 1821–1831  2017.

[7] Alane Suhr  Srinivasan Iyer  and Yoav Artzi. Learning to map context-dependent sentences to executable

formal queries. arXiv preprint arXiv:1804.06868  2018.

[8] Heung-Yeung Shum  Xiaodong He  and Di Li. From eliza to xiaoice: Challenges and opportunities with

social chatbots. arXiv preprint arXiv:1801.01957  2018.

[9] Wei Lu  Hwee Tou Ng  Wee Sun Lee  and Luke S Zettlemoyer. A generative model for parsing natural
language to meaning representations. In Proceedings of the Conference on Empirical Methods in Natural
Language Processing  pages 783–792. Association for Computational Linguistics  2008.

[10] Dipendra Kumar Misra and Yoav Artzi. Neural shift-reduce ccg semantic parsing. In Proceedings of the

2016 Conference on Empirical Methods in Natural Language Processing  pages 1775–1786  2016.

[11] Jayant Krishnamurthy  Pradeep Dasigi  and Matt Gardner. Neural semantic parsing with type constraints
for semi-structured tables. In Proceedings of the 2017 Conference on Empirical Methods in Natural
Language Processing  pages 1516–1526. Association for Computational Linguistics  September 2017.

[12] Bo Chen  Le Sun  and Xianpei Han. Sequence-to-action: End-to-end semantic graph generation for
In Proceedings of the 56th Annual Meeting of the Association for Computational

semantic parsing.
Linguistics  2018.

[13] Pengcheng Yin and Graham Neubig. A syntactic neural model for general-purpose code generation. In
Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long
Papers)  pages 440–450  Vancouver  Canada  July 2017. Association for Computational Linguistics. URL
http://aclweb.org/anthology/P17-1041.

[14] Srinivasan Iyer  Ioannis Konstas  Alvin Cheung  and Luke Zettlemoyer. Mapping language to code in

programmatic context. arXiv preprint arXiv:1808.09588  2018.

[15] Pengcheng Yin and Graham Neubig. Tranx: A transition-based neural abstract syntax parser for semantic
parsing and code generation. In Proceedings of the 2018 Conference on Empirical Methods in Natural
Language Processing: System Demonstrations  pages 7–12. Association for Computational Linguistics 
2018. URL http://aclweb.org/anthology/D18-2002.

[16] Pengcheng Yin  Graham Neubig  Miltiadis Allamanis  Marc Brockschmidt  and Alexander L Gaunt.

Learning to represent edits. arXiv preprint arXiv:1810.13337  2018.

9

[17] Amrita Saha  Vardaan Pahuja  Mitesh M Khapra  Karthik Sankaranarayanan  and Sarath Chandar. Complex
sequential question answering: Towards learning to converse over linked question answer pairs with a
knowledge graph. arXiv preprint arXiv:1801.10314  2018.

[18] Ilya Sutskever  Oriol Vinyals  and Quoc V Le. Sequence to sequence learning with neural networks. In

Advances in neural information processing systems  pages 3104–3112  2014.

[19] Dzmitry Bahdanau  Kyunghyun Cho  and Yoshua Bengio. Neural machine translation by jointly learning

to align and translate. Proceeding of ICLR  2015.

[20] Kyunghyun Cho  Bart van Merrienboer  Caglar Gulcehre  Dzmitry Bahdanau  Fethi Bougares  Holger
Schwenk  and Yoshua Bengio. Learning phrase representations using rnn encoder–decoder for statistical
machine translation. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language
Processing (EMNLP)  pages 1724–1734  2014.

[21] Thang Luong  Hieu Pham  and Christopher D Manning. Effective approaches to attention-based neural

machine translation. empirical methods in natural language processing  pages 1412–1421  2015.

[22] Alexander Miller  Adam Fisch  Jesse Dodge  Amir-Hossein Karimi  Antoine Bordes  and Jason Weston.

Key-value memory networks for directly reading documents. arXiv preprint arXiv:1606.03126  2016.

[23] Antoine Bordes  Nicolas Usunier  Alberto Garcia-Duran  Jason Weston  and Oksana Yakhnenko. Translat-
ing embeddings for modeling multi-relational data. In Advances in neural information processing systems 
pages 2787–2795  2013.

[24] Richard Socher  Danqi Chen  Christopher D Manning  and Andrew Ng. Reasoning with neural tensor
networks for knowledge base completion. In Advances in neural information processing systems  pages
926–934  2013.

[25] Alane Suhr and Yoav Artzi. Situated mapping of sequential instructions to actions with single-step reward
observation. In Proceedings of the Annual Meeting of the Association for Computational Linguistics 
pages 2072–2082. Association for Computational Linguistics  2018. URL http://aclweb.org/
anthology/P18-1193.

[26] Andrea Madotto  Chien-Sheng Wu  and Pascale Fung. Mem2seq: Effectively incorporating knowledge

bases into end-to-end task-oriented dialog systems. arXiv preprint arXiv:1804.08217  2018.

[27] Liangchen Luo  Wenhao Huang  Qi Zeng  Zaiqing Nie  and Xu Sun. Learning personalized end-to-end
goal-oriented dialog. In Proceedings of the 33rd AAAI Conference on Artiﬁcial Intelligence  Honolulu 
Hawaii  January 2019.

[28] Jesse Dodge  Andreea Gane  Xiang Zhang  Antoine Bordes  Sumit Chopra  Alexander Miller  Arthur
Szlam  and Jason Weston. Evaluating prerequisite qualities for learning end-to-end dialog systems. arXiv
preprint arXiv:1511.06931  2015.

[29] Jason E Weston. Dialog-based language learning. In Advances in Neural Information Processing Systems 

pages 829–837  2016.

10

,Daya Guo
Duyu Tang
Nan Duan
Ming Zhou
Jian Yin