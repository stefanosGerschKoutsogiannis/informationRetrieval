2019,Data Cleansing for Models Trained with SGD,Data cleansing is a typical approach used to improve the accuracy of machine learning models  which  however  requires extensive domain knowledge to identify the influential instances that affect the models. In this paper  we propose an algorithm that can identify influential instances without using any domain knowledge. The proposed algorithm automatically cleans the data  which does not require any of the users' knowledge. Hence  even non-experts can improve the models. The existing methods require the loss function to be convex and an optimal model to be obtained  which is not always the case in modern machine learning. To overcome these limitations  we propose a novel approach specifically designed for the models trained with stochastic gradient descent (SGD). The proposed method infers the influential instances by retracing the steps of the SGD while incorporating intermediate models computed in each step. Through experiments  we demonstrate that the proposed method can accurately infer the influential instances. Moreover  we used MNIST and CIFAR10 to show that the models can be effectively improved by removing the influential instances suggested by the proposed method.,Data Cleansing for Models Trained with SGD

Satoshi Hara⇤

Atsushi Nitanda†

Takanori Maehara‡

Abstract

Data cleansing is a typical approach used to improve the accuracy of machine
learning models  which  however  requires extensive domain knowledge to identify
the inﬂuential instances that affect the models. In this paper  we propose an algo-
rithm that can identify inﬂuential instances without using any domain knowledge.
The proposed algorithm automatically cleans the data  which does not require any
of the users’ knowledge. Hence  even non-experts can improve the models. The
existing methods require the loss function to be convex and an optimal model to be
obtained  which is not always the case in modern machine learning. To overcome
these limitations  we propose a novel approach speciﬁcally designed for the models
trained with stochastic gradient descent (SGD). The proposed method infers the
inﬂuential instances by retracing the steps of the SGD while incorporating interme-
diate models computed in each step. Through experiments  we demonstrate that
the proposed method can accurately infer the inﬂuential instances. Moreover  we
used MNIST and CIFAR10 to show that the models can be effectively improved
by removing the inﬂuential instances suggested by the proposed method.

1

Introduction

Building accurate models is one of the fundamental goals in machine learning. If the obtained model
is not satisfactory  users try to improve the model in several ways such as by modifying input features 
cleansing data  or even by gathering additional data. Error analysis [Ng  2017] is a typical approach
for this purpose. In this analysis  the users hypothesize the cause of model’s failure by investigating
important features or examining the misclassiﬁed instances. However  a good hypothesis requires
experience and domain knowledge. Therefore  it is difﬁcult for non-domain experts or non-machine
learning specialists to build accurate models.
How can we help non-experts to build accurate machine learning models? In this study  we focus on
the following data cleansing problem that removes “harmful” instances from the training set.
Problem 1 (Data Cleansing). Find a subset of the training instances such that the trained model
obtained after removing the subset has a better accuracy.

Currently  the users hypothesize the training instances that can have certain inﬂuences on the resulting
models by inspecting instances based on the domain knowledge. Our aim is to develop an algorithm
that can identify inﬂuential instances without using any domain knowledge. With such an algorithm 
the users do not need to hypothesize inﬂuential instances. Instead  the algorithm automatically
cleans the data  which does not require any of the users’ knowledge. Hence  with this process  even
non-experts can improve the models.
For data cleansing  we need to determine the training instances that affect the model. In the literature
of statistics  an inﬂuential instance is deﬁned as the instance that leads to a distinct model from the
current model if the corresponding instance is absent [Cook  1977]. A naive approach to determine

⇤satohara@ar.sanken.osaka-u.ac.jp  Osaka University  Japan
†nitanda@mist.i.u-tokyo.ac.jp  The University of Tokyo  Japan
‡takanori.maehara@riken.jp  RIKEN AIP  Japan

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

these inﬂuential instances is  therefore  to retrain the model by leaving every one instance out of the
training set  which can be computationally very demanding. To efﬁciently infer an inﬂuential instance
without retraining  the convexity of the loss function plays an important role. Pioneering studies by
Beckman and Trussell [1974]  Cook [1977]  and Pregibon [1981] have shown that  for some convex
loss functions  the inﬂuential instances can be inferred without model retraining by utilizing the
optimality condition on the training loss  given that an optimal model is obtained. A recent study
by Koh and Liang [2017] further generalized these approaches to any smooth and strongly convex
loss functions by incorporating the idea of inﬂuence function [Cook and Weisberg  1980] in robust
statistics (see Section 6).
The focus of this study is to go beyond the convexity and optimality. We aim to develop an algorithm
that can infer inﬂuential instances even for non-convex objectives such as deep neural networks.
To this end  we propose a completely different approach to infer the inﬂuential instances. The
proposed approach is based on the stochastic gradient descent (SGD). Modern machine learning
models including deep neural networks are trained using SGD and its variants. Our idea is to redeﬁne
the notion of inﬂuence for the models trained with SGD  which we named SGD-inﬂuence. Based on
SGD-inﬂuence  we propose a method that infers the inﬂuential instances without model retraining.
The proposed method is based solely on the analysis of SGD. Different from the existing methods 
the proposed method does not require the optimality conditions to hold true on the obtained models.
The proposed method is therefore suitable to the SGD context where we no longer look for the exact
optimum of the training loss. In SGD  we instead look for the minimum error on the validation set 
which leads to early stopping of the optimization that can violate the optimality condition.
In summary  the contribution of this study is threefold.
• We propose a new deﬁnition of the inﬂuence  which we name as SGD-inﬂuence  for the models
trained with SGD. SGD-inﬂuence is deﬁned based on the counterfactual effect: what if an instance
is absent in SGD  how largely will the resulting model change?

• We propose a novel estimator of SGD-inﬂuence based on the analysis of SGD. We then construct
a proposed inﬂuence estimation algorithm based on this estimator. We also study the estimation
error of the proposed estimator on both convex and non-convex loss functions.

• Through experiments  we demonstrate that the proposed method can accurately infer the inﬂuential
instances. Moreover  we used MNIST and CIFAR10 to show that the models can be effectively
improved by removing the inﬂuential instances suggested by the proposed method.

2 Preliminaries

Notations For vectors a  b 2 Rp  we denote the inner product by ha  bi =Pp
by kak =pha  ai. For a function f (✓) with ✓ 2 Rp  we denote its derivative by r✓f (✓).
Supervised Learning Let z = (x  y) 2 Rd ⇥Y be an observation  which is a pair of d-dimensional
input feature vector x and output y in a certain domain Y (e.g.  Y = R for regression  and Y =
{1  1} for binary classiﬁcation). The objective of learning is to ﬁnd a model f (x; ✓) that well
approximates the output as y ⇡ f (x; ✓). Here  ✓ 2 Rp is a parameter of the model.
n=1 be a training set with independent and identically distributed
Let D := {zn = (xn  yn)}N
observations. We denote the loss function for an instance z with the parameter ✓ by `(z; ✓). The
learning problem is then denoted as

i=1 aibi  and the norm

ˆ✓ = argmin✓2Rp

(1)
SGD Let g(z; ✓) := r✓`(z; ✓). SGD starts the optimization from the initial parameter ✓[1]. An
update rule of the mini-batch SGD at the t-th step for the problem (1) is given by ✓[t+1] ✓[t] 
|St|Pi2St
⌘t
g(zi; ✓[t])  where St denotes the set of instance indices used in the t-th step  and ⌘t > 0
is the learning rate. We denote the number of total SGD steps by T .

n=1 `(zn; ✓).

1

NPN

3 SGD-Inﬂuence

We propose a novel notion of inﬂuence for the models trained with SGD  which we name as SGD-
inﬂuence. We then formalize the inﬂuence estimation problem we consider in this paper.

2

j  ⌘t

j  ✓[t] as the SGD-inﬂuence

|St|Pi2St\{j} g(zi; ✓[t]
j).

We deﬁne SGD-inﬂuence based on the following counterfactual SGD where one instance is absent.
Deﬁnition 2 (Counterfactual SGD). The counterfactual SGD starts the optimization from the same
initial parameter as the ordinary SGD ✓[1]
j = ✓[1]. The t-th step of the counterfactual SGD with the
j-th instance zj absent is deﬁned by ✓[t+1]
j ✓[t]
Deﬁnition 3 (SGD-Inﬂuence). We refer to the parameter difference ✓[t]
of the instance zj 2 D at step t.
It should be noted that SGD-inﬂuence can be deﬁned in every step of SGD  even for non-optimal
models. Thus  SGD-inﬂuence is a suitable notion of inﬂuence for the cases where we no longer look
for the exact optimal of (1). In this study  we speciﬁcally focus on estimating an inner product of a
query vector u 2 Rp and the SGD-inﬂuence after T SGD steps  as follows.
Problem 4 (Linear Inﬂuence Estimation (LIE)). For a given query vector u 2 Rp  estimate the linear
inﬂuence L[T ]
LIE includes several important applications (see [Koh and Liang  2017]). One important application is
the inﬂuence estimation on the loss. If we take u = r✓`(x; ✓[T ]) for an input x  LIE amounts to esti-
mating the change in loss L[T ]
j (r✓`(x; ✓[T ]))
indicates that the loss on the input x can be decreased by removing zj.
Note that SGD-inﬂuence as well as linear inﬂuence can be computed exactly by running the counter-
factual SGD for all zj 2 D. However  this requires running SGD N times  which is computationally
demanding even for N ⇡ 100. Therefore  our goal is to develop an estimation algorithm for LIE 
which does not require running SGD multiple times.

j )  `(x; ✓[T ]). Negative L[T ]

j (r✓`(x; ✓[T ])) ⇡ `(x; ✓[T ]

j (u) := hu  ✓[T ]

j  ✓[T ]i.

4 Estimating SGD-Inﬂuence

In this section  we present our proposed estimator of SGD-inﬂuence and show its theoretical properties.
We then derive an algorithm for LIE based on the estimator in the next section.

Here  we assume that

4.1 Proposed Estimator
We estimate SGD-inﬂuence using the ﬁrst-order Taylor approximation of
ent.
then obtain
1
denoting an identity matrix by I  we have
j  ✓[t1]) 

the gradi-
the loss function `(z; ✓) is twice differentiable. We
:=
✓`(zi; ✓[t]) is the Hessian of the loss on the mini-batch St. With this approximation 

j)  r✓`(zi; ✓[t])⌘ ⇡ H [t](✓[t]
(r✓`(zi; ✓[t1]
j

|St|Pi2St⇣r✓`(zi; ✓[t]

|St|Pi2St r2

j  ✓[t])  where H [t]

j  ✓[t] = (✓[t1]
✓[t]

)  r✓`(zi; ✓[t1]))

1

⌘t1

|St1| Xi2St1
j  ✓[t1]).

⇡ (I  ⌘t1H [t1])(✓[t1]

We construct an estimator for the SGD-inﬂuence based on this approximation. For simplicity  here 
we focus on one-epoch SGD where each instance appears only once. Let Zt := I  ⌘tH [t] and
⇡(j) be the SGD step where the instance zj is used. By recursively applying the approximation and
recalling that ✓[⇡(j)+1]

g(zj; ✓[⇡(j)])  we obtain the following estimator

j
✓[T ]
j  ✓[T ] ⇡

 ✓[⇡(j)+1] = ⌘⇡(j)
|S⇡(j)|
ZT1ZT2 ··· Z⇡(j)+1g(zj; ✓[⇡(j)]) =: ✓j.

(2)

⌘⇡(j)
|S⇡(j)|

4.2 Properties of ✓j
Here  we evaluate the estimation error of the proposed estimator ✓j for both convex and non-
convex loss functions. A notable property of the estimator ✓j is that  unlike existing methods  the
error can be evaluated even without assuming the convexity of the loss function `(z; ✓).
Convex Loss For smooth and strongly convex problems  there exists a uniform bound on the gap
between the SGD-inﬂuence ✓[T ]

j  ✓[T ] and the proposed estimator ✓j.

3

where hj(a) := ⌘⇡(j)

✓`(z; ✓)  ⇤I for all z  ✓. If ⌘s  1/⇤  then we get

Theorem 5. Assume that `(z; ✓) is twice differentiable with respect to the parameter ✓ and there
exist   ⇤ > 0 such that I  r2
j  ✓[T ])  ✓jk q2(hj()2 + hj(⇤)2) 
k(✓[T ]
|S⇡(j)|QT1
s=⇡(j)+1(1  ⌘sa)kg(zj; ✓[⇡(j)])k.

Non-Convex Loss For non-convex loss functions  the aforementioned uniform bound no longer
holds. However  we can still evaluate the growth of the estimation error. For simplicity  we consider a
constant learning rate ⌘ = O(/pT ) that depends only on the number of total SGD steps T . It should
be noted that SGD with this learning rate is theoretically justiﬁed to converge to a stationary point
[Ghadimi and Lan  2013]. The next theorem indicates that ✓j can approximate SGD-inﬂuence
well if Hessian r2
Theorem 6. Assume that `(z; ✓) is twice differentiable and r2
✓`(z; ✓) is L-Lipschitz continuous with
respect to ✓. Moreover  assume that kr✓`(z; ✓)k  G  r2
✓`(z; ✓)  ⇤I for all z  ✓. Consider SGD
with a learning rate ⌘ = O(/pT ). Then 

✓`(✓  z) is Lipschitz continuous.

(3)

k(✓[T ]

j  ✓[T ])  ✓jk 

⇤

expO(⇤pT ) 2T G2L

.

(4)

⌘⇡k (j)
|S⇡k (j)|
s=1

hu[⇡k(j)] 

⌘⇡k(j)
|S⇡k(j)|

ZTs⌘ ⌘⇡k (j)

Algorithm 1 LIE for SGD: Training Phase

5 Proposed Method for LIE
We now derive our proposed method for LIE. First  we extend the estimator ✓j
to multi-epoch SGD. Let ⇡1(j) ⇡ 2(j)  . . .  ⇡ K(j) be the steps where the instance zj
is
used in K-epoch SGD. We estimate the effect of
the step ⇡k(j) based on (2) as
g(zj; ✓[⇡k(j)]). We then add all the effects and derive the estima-
ZT1ZT2 ··· Z⇡k(j)+1

k=1⇣QT⇡k(j)1
tor ✓j =PK
KXk=1

Initialize the parameter ✓[1]
Initialize the sequence as null: A ;
for t = 1  2  . . .   T  1 do
|St|Pi2St

|S⇡k (j)|
Let u[t] := Zt+1Zt+2 . . . ZT1u. LIE based on
the estimator ✓j is then obtained as
g(zj; ✓[⇡k(j)])i.
hu  ✓ji =
It should be noted that u[t] can be computed
recursively u[t] Zt+1u[t+1] = u[t+1] 
⌘t+1H✓[t+1]u[t+1] by retracing SGD. The proposed
method is based on this recursive computation.
The proposed method consists of two phases  the
training phase and the inference phase  as shown in
Algorithms 1 and 2. In the training phase in Algo-
rithm 1  during running SGD  we store the tuple of
the instance indices St  learning rate ⌘t  and param-
eter ✓[t].4 In the inference phase in Algorithm 2 
we retrace the stored information and compute u[t]
in each step.
Note that  in Algorithm 2  we need to compute H [t]u[t]. A naive implementation requires O(p2)
memory to store the matrix H [t]  which can be prohibitive for very large models. We can avoid this
difﬁculty by directly computing H [t]u[t] without the explicit computation of H [t]. Because H [t]u[t] =
1

Initialize the inﬂuence: ˆL[T ]
for t = T  1  T  2  . . .   1 do
(St ⌘ t ✓ [t]) A[t]
// update the linear inﬂuence of zj
ˆL[T ]
j (u) += hu  ⌘t
|St|
u = ⌘tH [t]u // update u

Algorithm 2 LIE for SGD: Inference Phase
Require: u 2 Rp

|St|Pi2St r✓hu[t] r✓`(zi; ✓[t])i  we only need to compute the derivative of hu[t] r✓`(zi; ✓[t])i 

which does not require the explicit computation of H [t]. For example  in Tensorﬂow  this can be
implemented in a few lines.5 The time complexity for the inference phase is O(T M )  where M is
the largest batch size in SGD and  is the complexity for computing the parameter gradient.

A[t] (St ⌘ t ✓ [t])
✓[t+1] ✓[t]  ⌘t

j (u) 0 8j
// load information

// store information

g(zi; ✓[t])

g(zj; ✓[t])i 8j 2 St

g(zj; ✓[⇡k(j)]).

end for

end for

4For Momentum-SGD  we can avoid storing the parameter ✓[t] [Maclaurin et al.  2015].
5grads = [tf.gradients(loss[i]  theta) for i in St];

[tf.gradients(tf.tensordot(u  g  axes)  theta) for g in grads]  axis)

Hu = tf.reduce_mean(

4

6 Related Studies

Inﬂuence Estimation Traditional studies on inﬂuence estimation considered the change in the
solution ˆ✓ to the problem (1) if an instance zj was absent. For this purpose  they considered the
counterfactual problem ˆ✓j = argmin✓PN
n=1;n6=j `(z; ✓). The goal of the traditional inﬂuence
estimation is to obtain an estimate of the difference ˆ✓j  ˆ✓ without retraining the models. Pioneering
studies by Beckman and Trussell [1974]  Cook [1977]  and Pregibon [1981] have shown that the
inﬂuence ˆ✓j  ˆ✓ can be computed analytically for linear and generalized linear models. Koh and
Liang [2017] considered a further generalizations of those previous studies. They introduced the
following approximation for strongly convex loss functions `(z; ✓):

ˆ✓j  ˆ✓ ⇡ 1

N

ˆH1r✓`(zj; ˆ✓) 

(5)

NPz2D r2`(z; ˆ✓) is the Hessian of the loss for the optimal model. We note that Zhang

where ˆH = 1
et al. [2018] and Khanna et al. [2019] further extended this approach. Zhang et al. [2018] used
this approach to ﬁx the labels of the training instances. Khanna et al. [2019] proposed to ﬁnd the
inﬂuential instances using the Bayesian quadrature  which includes (5) as its special case.
Our study differs from these traditional approaches in two ways. First  the proposed SGD-inﬂuence
does not assume the optimality of the obtained models. We instead consider the models obtained in
each step of SGD  which are not necessarily optimal. Second  the proposed method does not require
the function loss `(z; ✓) to be convex. The proposed method is valid even for non-convex losses.
Estimation of Data Importance Some recent works [Ren et al.  2018; Ghorbani and Zou  2019]
focused on estimating the importance of each training instance. Ren et al. [2018] proposed weighting
each training instance so that the validation loss to be minimized. Ghorbani and Zou [2019] introduced
some axioms that the data importance should satisfy  and derived Shapley value as an ideal importance.
These studies demonstrated the effectiveness of the proposed importances only empirically. The
advantage of our study from these prior studies is in theories of the estimation error  that clariﬁed in
which circumstances the estimated importances are accurate.
Learning from Noisy Labels There are plenty of studies for training models from noisy la-
bels [Aslam and Decatur  1996; Brodley and Friedl  1999; Natarajan et al.  2013; Zhang et al. 
2018]. The difference from our study is that these studies assumed that the label noise is an only
issue. However  as Figures 13 and 14 show  the model performance depends not only on label noises
but atypical inputs also. For example  in Figure 13  we can ﬁnd several atypical instances that even
human cannot label them conﬁdently. These atypical instances should be removed from the training
rather than ﬁxing the labels because we cannot put correct labels to them.
Outlier Detection A typical approach for data cleansing is outlier detection. Outlier detection is used
to remove abnormal instances from the training set before training the model to ensure that the model
is not affected by the abnormal instances. For tabular data  there are several popular methods such as
One-class SVM [Schölkopf et al.  2001]  Local Outlier Factor [Breunig et al.  2000]  and Isolation
Forest [Liu et al.  2008]. For complex data such as images  autoencoders can also be used [Aggarwal 
2016; Zhou and Paffenroth  2017] along with generative adversarial networks [Schlegl et al.  2017].
It should be noted that although these methods can ﬁnd abnormal instances  they are not necessarily
inﬂuential to the resulting models  as we will show in the experiments.

7 Experiments

Here  we evaluate the two aspects of the proposed method: the performances of LIE and data
cleansing. We used Python 3 and PyTorch 1.0 for the experiments.6 The experiments were conducted
on 64bit Ubuntu 16.04 with six Intel Xeon E5-1650 3.6GHz CPU  128GB RAM  and four GeForce
GTX 1080ti.

6The codes are available at https://github.com/sato9hara/sgd-inﬂuence

5

7.1 Evaluation of LIE

We ﬁrst evaluate the effectiveness of the proposed method in the estimation of linear inﬂuence. For
this purpose  we artiﬁcially created small datasets to ensure that the true linear inﬂuence is computable.
The detailed setup can be found in Appendix C.1.
Setup We used three datasets: Adult [Dua and Karra Taniskidou  2017]  20Newsgroups7  and
MNIST [LeCun et al.  1998]. These are common benchmarks in tabular data analysis  natural
language processing  and image recognition  respectively. We adopted these three datasets to
demonstrate the validity of the proposed method across different data domains. For 20Newsgroups
and MNIST  we selected the two document categories ibm.pc.hardware and mac.hardware and
images from one and seven  respectively  so that the problem to be binary classiﬁcation.
To observe the validity of the proposed method beyond convexity  we adopted two models  linear
logistic regression and deep neural networks. For deep neural networks  we used a network with two
fully connected layers with eight units each and ReLU activation. We used the sigmoid function at
the output layer and adopted the cross entropy as the loss function. It should be noted that the loss
function for linear logistic regression is convex  while that for deep neural networks is non-convex.
In the experiments  we randomly subsampled 200 instances for the training set D and validation set D0.
We then estimated the linear inﬂuence for the validation loss using Algorithm 2. Here  we set the query
|D0|Pz02D0 r✓`(z0; ✓[T ]). The estimation of linear inﬂuence thus amounts to esti-
vector u as u = 1
j )  `(z0; ✓[T ])⌘.
mating the change in the validation loss hu  ✓[T ]
Evaluation We ran the counterfactual SGD for all zj 2 D and computed the true linear inﬂuence.
For evaluation  we compared the estimated inﬂuences with this true inﬂuence using Kendall’s tau
and Jaccard index. With Kendall’s tau  a typical metric for ordinal associations  we measured the
correlation between the estimated and true inﬂuences. Kendall’s tau takes the value between plus and
minus one  where one indicates that the orders of the estimated and true inﬂuences are identical. With
Jaccard index  we measured the identiﬁcation accuracy of the inﬂuential instances. For data cleansing 
the users are interested in instances with large positive or negative inﬂuences. We selected ten
instances with the largest positive and negative true inﬂuences and constructed a set of 20 important
instances. We compared this important instances with the estimated ones using Jaccard index  which
varies between zero and one  where the value one indicates that the sets are identical.
Results We adopted the method proposed by Koh and Liang [2017] in (5) as the baseline  abbreviated
as K&L. For deep neural networks  the Hessian matrix is not positive deﬁnite  which makes the
estimator (5) invalid. To alleviate the effect of negative eigenvalues  we added a positive constant 1.0
to the diagonal as suggested by Koh and Liang [2017].
Figure 1 shows a clear advantage of the proposed method. The proposed method successfully
estimated the true linear inﬂuences with high precision. The estimated inﬂuences were concentrated
on the diagonal lines  indicating that the estimated inﬂuences accurately approximated the true
inﬂuences. In contrast  the estimated inﬂuences obtained by K&L were less accurate. We observed
that the estimator (5) sometimes gets numerically unstable owing to the presence of small eigenvalues
in the Hessian matrix.
For the quantitative comparison  we repeated the experiment by randomly changing the instance
subsampling 100 times. Table 1 lists the average Kendall’s tau and Jaccard index. The results again
show that the proposed method can accurately estimate the true linear inﬂuences.

|D0|Pz02D0⇣`(z0; ✓[T ]

j  ✓[T ]i ⇡ 1

7.2 Evaluation on Data Cleansing

We now show that the proposed method is effective for data cleansing. Speciﬁcally  on MNIST [LeCun
et al.  1998] and CIFAR10 [Krizhevsky and Hinton  2009]  we demonstrate that we can effectively
improve the models by removing inﬂuential instances suggested by the proposed method. The
detailed setup and full results can be found in Appendix C.2 and C.4.
Setup We used MNIST and CIFAR10. From the original training set  we held out randomly selected
10 000 instances for the validation set and used the remaining instances as the training set. As models 

7http://qwone.com/~jason/20Newsgroups/

6

K&L Proposed
2

·102

y = x

d
e
t
a
m

·102

1

0.5

0

1

0

1
2

d
e
t
a
m

i
t
s
E

d
e
t
a
m

i
t
s
E

·102
1

0

2 1
2
True Linear Inﬂuence
(a) LogReg: Adult

5 ·103

0

5

·103
5

5
True Linear Inﬂuence

0

i
t
s
E

0.5
1

d
e
t
a
m

i
t
s
E

0.5
1

·102
0.5

1 0.5 0
1
True Linear Inﬂuence

(b) LogReg: 20Newsgroups

·102

1

0.5

0

·102
0.5

1 0.5 0
1
True Linear Inﬂuence

d
e
t
a
m

i
t
s
E

d
e
t
a
m

i
t
s
E

·102

2

1

0

1
2

·102
1

0

2 1
2
True Linear Inﬂuence
(c) LogReg: MNIST

5 ·103

0

5

·103
5

5

0

True Linear Inﬂuence

(d) DNN: Adult

(e) DNN: 20Newsgroups

(f) DNN: MNIST

Figure 1: Estimated linear inﬂuences for linear logistic regression (LogReg) and deep neural networks (DNN)
for all the 200 training instances. K&L denotes the method of Koh and Liang [2017].

Table 1: Average Kendall’s tau and Jaccard index (± std.).

Kendall’s tau

Jaccard index

LogReg

Proposed
.93 (.02)
.94 (.05)
.95 (.02)

K&L

.85 (.07)
.82 (.15)
.70 (.15)

DNN

Proposed
.75 (.10)
.45 (.12)
.45 (.12)

K&L

.54 (.12)
.37 (.12)
.27 (.16)

LogReg

Proposed
.80 (.10)
.79 (.15)
.83 (.10)

K&L

.60 (.17)
.52 (.19)
.41 (.16)

DNN

Proposed
.59 (.16)
.25 (.08)
.37 (.15)

K&L

.32 (.11)
.11 (.07)
.27 (.12)

Adult
20News
MNIST

we used convolutional neural networks. In SGD  we set the epoch K = 20  batch size |St| = 64  and
learning rate ⌘t = 0.05.
As baselines for data cleansing  in addition to K&L  we adopted two outlier detection methods 
Autoencoder [Aggarwal  2016] and Isolation Forest [Liu et al.  2008]. We also adopted random data
removal as the baseline. For the proposed method  we introduced an approximate version in this
experiment. In Algorithm 2  the proposed method retraces all steps of the SGD. In the approximate
version  we retrace only one epoch  which requires less computation than the original algorithm.
Moreover  it is also storage friendly because we need to store intermediate information only in the
last epoch of SGD.
We proceeded the experiment as follows. First  we trained the model with SGD using the training set.
We then computed the inﬂuence of each training instance using the proposed method as well as other
baseline methods. Here  we used the same query vector u as in the previous experiment. Finally  we
removed the top-m inﬂuential instances from the training set and retrained the model. For model
retraining  we ran normal SGD for 19 epochs and switched to counterfactual SGD in the last epoch.8
If the misclassiﬁcation rate of the retrained model decreases  we can conclude that the training set
was effectively cleansed.
Results We repeated the experiment by randomly changing the split between the training and
validation set 30 times. Figure 2 shows the misclassiﬁcation rates on the test set after data cleansing
with each method.9 It is evident from the ﬁgures that the misclassiﬁcation rates decreased after data
cleansing with the proposed method and its approximate version. We compared the misclassiﬁcation
rates before and after the data cleansing using t-test with the signiﬁcance level set to 0.05. We

8We observed that this works well. For the results with full counterfactual SGD  see Apendix C.4.
9See Appendix C.4 for the full results.

7

No Removal

Random

Autoencoder

Isolation Forest

Proposed

Proposed (Approx.)

K&L

e
t
a
r

n
o
i
t
a
c
ﬁ
i
s
s
a
l
c
s
i

M

0.011

0.01

0.009

0.008

0.007

100

e
t
a
r

n
o
i
t
a
c
ﬁ
i
s
s
a
l
c
s
i

M

0.19

0.18

0.17

0.16

0.15

100

102

103
101
# of instances removed

104

(a) MNIST

102

103
101
# of instances removed

(b) CIFAR10

104

Figure 2: Average misclassiﬁcation rates on the test set after data cleansing. The errorbars are omitted for better
visibility. See Appendix C.4 for the full results.

y = 3

y = 4

y = 8

y = 6

y = deer

y = frog

y = truck

y = dog

(a) Proposed (Approx.)

(b) Autoencoder

(c) Proposed (Approx.)

(d) Autoencoder

Figure 3: Examples of found inﬂuential instances and their labels in (a)(b) MNIST and (c)(d) CIFAR10.

observed that none of the baseline methods except K&L attained statistically signiﬁcant improvements.
By contrast  the proposed method and its approximate version attained statistically signiﬁcant
improvements. For both datasets  the proposed method and its approximate version were found to be
statistically signiﬁcant for the number of removed instances between 10 and 1000  and 10 and 100 
respectively.10 Moreover  both methods outperformed K&L. The results conﬁrm that the proposed
method can effectively suggest inﬂuential instances for data cleansing. We also note that the proposed
method and its approximate version performed comparably well. This observation suggests that  in
practice  we only need to retrace only one epoch for inferring the inﬂuential instances  which requires
less computation and storing intermediate information only in the last epoch of SGD.
Figure 3 shows examples of found inﬂuential instances. An interesting observation is that Autoencoder
tended to ﬁnd images with noisy or vivid backgrounds. Visually  it seems reasonable to select them
as outliers. However  as we have seen in Figure 2  removing these outliers did not help to improve
the models. In contrast  the proposed method found images with confusing shapes or backgrounds.
Although they are not strongly visually appealing as the outliers  Figure 2 conﬁrms that these instances
signiﬁcantly affect the models. These observations indicate that the proposed method could ﬁnd the
inﬂuential instances  which can be missed even by users with domain knowledge.

8 Conclusion

We considered supporting non-experts to build accurate machine learning models through data
cleansing by suggesting inﬂuential instances. Speciﬁcally  we aimed at establishing an algorithm that
can infer the inﬂuential instances even for non-convex loss functions such as deep neural networks.
Our idea is to use the fact that modern machine learning models are trained using SGD. We introduced
a reﬁned notion of inﬂuence for the models trained with SGD  which was named SGD-inﬂuence. We
then proposed an algorithm that can accurately approximate the SGD-inﬂuence without running extra
SGD. We also proved that the proposed method can provide valid estimates even for non-convex
loss functions. The experimental results have shown that the proposed method can accurately infer
inﬂuential instances. Moreover  on MNIST and CIFAR10  we demonstrated that the models can be
effectively improved by removing the inﬂuential instances suggested by the proposed method.

10See Appendix C.3 for a possible way to determine the number of removal in practice.

8

Acknowledgments
Satoshi Hara is supported by JSPS KAKENHI Grant Number JP18K18106. Atsushi Nitanda is
supported by JSPS KAKENHI Grant Number JP19K20337.

References
Charu C Aggarwal. Outlier Analysis Second Edition. Springer  2016.

Javed A Aslam and Scott E Decatur. On the sample complexity of noise-tolerant learning. Information

Processing Letters  57(4):189–195  1996.

RJ Beckman and HJ Trussell. The distribution of an arbitrary studentized residual and the effects of
updating in multiple regression. Journal of the American Statistical Association  69(345):199–201 
1974.

Markus M Breunig  Hans-Peter Kriegel  Raymond T Ng  and Jörg Sander. Lof: identifying density-
based local outliers. In Proceedings of the 2000 ACM SIGMOD International Conference on
Management of Data  volume 29  pages 93–104. ACM  2000.

Carla E Brodley and Mark A Friedl. Identifying mislabeled training data. Journal of artiﬁcial

intelligence research  11:131–167  1999.

R Dennis Cook and Sanford Weisberg. Characterizations of an empirical inﬂuence function for

detecting inﬂuential cases in regression. Technometrics  22(4):495–508  1980.

R Dennis Cook. Detection of inﬂuential observation in linear regression. Technometrics  19(1):15–18 

1977.

Dheeru Dua and Eﬁ Karra Taniskidou. UCI machine learning repository  2017.

Saeed Ghadimi and Guanghui Lan. Stochastic ﬁrst-and zeroth-order methods for nonconvex stochastic

programming. SIAM Journal on Optimization  23(4):2341–2368  2013.

Amirata Ghorbani and James Zou. Data shapley: Equitable valuation of data for machine learning.

In Proceedings of the 36th International Conference on Machine Learning  2019.

Rajiv Khanna  Been Kim  Joydeep Ghosh  and Oluwasanmi Koyejo. Interpreting black box pre-
dictions using ﬁsher kernels. In Proceedings of the 22nd International Conference on Artiﬁcial
Intelligence and Statistics  pages 3382–3390  2019.

Pang Wei Koh and Percy Liang. Understanding black-box predictions via inﬂuence functions. In
Proceedings of the 34th International Conference on Machine Learning  pages 1885–1894  2017.

Alex Krizhevsky and Geoffrey Hinton. Learning multiple layers of features from tiny images.

Technical report  Citeseer  2009.

Yann LeCun  Léon Bottou  Yoshua Bengio  Patrick Haffner  et al. Gradient-based learning applied to

document recognition. Proceedings of the IEEE  86(11):2278–2324  1998.

Fei Tony Liu  Kai Ming Ting  and Zhi-Hua Zhou. Isolation forest. In 2008 Eighth IEEE International

Conference on Data Mining  pages 413–422. IEEE  2008.

Dougal Maclaurin  David Duvenaud  and Ryan Adams. Gradient-based hyperparameter optimization
through reversible learning. In Proceedings of the 32nd International Conference on Machine
Learning  pages 2113–2122  2015.

Nagarajan Natarajan  Inderjit S Dhillon  Pradeep K Ravikumar  and Ambuj Tewari. Learning with

noisy labels. In Advances in neural information processing systems  pages 1196–1204  2013.

Andrew Ng. Machine learning yearning  2017.

Daryl Pregibon. Logistic regression diagnostics. The Annals of Statistics  9(4):705–724  1981.

9

Mengye Ren  Wenyuan Zeng  Bin Yang  and Raquel Urtasun. Learning to reweight examples for
robust deep learning. In Proceedings of the 35th International Conference on Machine Learning 
2018.

Thomas Schlegl  Philipp Seeböck  Sebastian M Waldstein  Ursula Schmidt-Erfurth  and Georg
Langs. Unsupervised anomaly detection with generative adversarial networks to guide marker
discovery. In International Conference on Information Processing in Medical Imaging  pages
146–157. Springer  2017.

Bernhard Schölkopf  John C Platt  John Shawe-Taylor  Alex J Smola  and Robert C Williamson.
Estimating the support of a high-dimensional distribution. Neural computation  13(7):1443–1471 
2001.

Xuezhou Zhang  Xiaojin Zhu  and Stephen Wright. Training set debugging using trusted items. In

Proceedings of the 32nd AAAI Conference on Artiﬁcial Intelligence  pages 4482–4489  2018.
Chong Zhou and Randy C Paffenroth. Anomaly detection with robust deep autoencoders.

In
Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and
Data Mining  pages 665–674. ACM  2017.

10

,Ingmar Kanitscheider
Satoshi Hara
Atsushi Nitanda
Takanori Maehara