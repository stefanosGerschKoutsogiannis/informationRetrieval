2016,Optimal Tagging with Markov Chain Optimization,Many information systems use tags and keywords to describe and annotate content. These allow for efficient organization and categorization of items  as well as facilitate relevant search queries. As such  the selected set of tags for an item can have a considerable effect on the volume of traffic that eventually reaches an item.  In tagging systems where tags are exclusively chosen by an item's owner  who in turn is interested in maximizing traffic  a principled approach for assigning tags can prove valuable. In this paper we introduce the problem of optimal tagging  where the task is to choose a subset of tags for a new item such that the probability of browsing users reaching that item is maximized.  We formulate the problem by modeling traffic using a Markov chain  and asking how transitions in this chain should be modified to maximize traffic into a certain state of interest. The resulting optimization problem involves maximizing a certain function over subsets  under a cardinality constraint.  We show that the optimization problem is NP-hard  but has a (1-1/e)-approximation via a simple greedy algorithm due to monotonicity and submodularity. Furthermore  the structure of the problem allows for an efficient computation of the greedy step. To demonstrate the effectiveness of our method  we perform experiments on three tagging datasets  and show that the greedy algorithm outperforms other baselines.,Optimal Tagging with Markov Chain Optimization

Nir Rosenfeld

Amir Globerson

School of Computer Science and Engineering

The Blavatnik School of Computer Science

Hebrew University of Jerusalem

nir.rosenfeld@mail.huji.ac.il

Tel Aviv University

gamir@post.tau.ac.il

Abstract

Many information systems use tags and keywords to describe and annotate content.
These allow for efﬁcient organization and categorization of items  as well as
facilitate relevant search queries. As such  the selected set of tags for an item can
have a considerable effect on the volume of trafﬁc that eventually reaches an item.
In tagging systems where tags are exclusively chosen by an item’s owner  who in
turn is interested in maximizing trafﬁc  a principled approach for assigning tags
can prove valuable. In this paper we introduce the problem of optimal tagging 
where the task is to choose a subset of tags for a new item such that the probability
of browsing users reaching that item is maximized.
We formulate the problem by modeling trafﬁc using a Markov chain  and asking
how transitions in this chain should be modiﬁed to maximize trafﬁc into a certain
state of interest. The resulting optimization problem involves maximizing a certain
function over subsets  under a cardinality constraint.
We show that the optimization problem is NP-hard  but has a (1− 1
e )-approximation
via a simple greedy algorithm due to monotonicity and submodularity. Furthermore 
the structure of the problem allows for an efﬁcient computation of the greedy step.
To demonstrate the effectiveness of our method  we perform experiments on three
tagging datasets  and show that the greedy algorithm outperforms other baselines.

1

Introduction

To allow for efﬁcient navigation and search  modern information systems rely on the usage of non-
hierarchical tags  keywords  or labels to describe items and content. These tags are then used either
explicitly by users when searching for content  or implicitly by the system to recommend related
items or to augment search results.
Many online systems where users can create or upload content support tagging. Examples of such
systems are media-sharing platforms  social bookmarking websites  and consumer to consumer
auctioning services. While in some systems any user can tag any item  in many ad-hoc systems tags
are exclusively set by the item’s owner alone. She  in turn  is free to select any set of tags or keywords
which she believes best describe the item. Typically  the only concrete limitation is on the number
of tags  words  or characters used. Tags are often chosen on a basis of their ability to best describe 
classify  or categorize items and content. By choosing relevant tags  users aid in creating a more
organized information system. However  content owners may have their own individual objective 
such as maximizing the exposure of their items to other browsing users. This is true for many artists 
artisans  content creators  and merchants whose services and items are provided online.
This suggests that choosing tags should in fact be done strategically. For instance  for a user uploading
a new song  tagging it as ‘Rock’ may be informative  but will probably only contribute marginally to
the song’s trafﬁc  as the competition for popularity under this tag can be ﬁerce. On the other hand 
choosing a unique or obscure tag may be appealing  but will not help much either. Strategic tagging

30th Conference on Neural Information Processing Systems (NIPS 2016)  Barcelona  Spain.

or keyword selection is clearly exhibited in search systems  where keywords are explicitly used for
ﬁltering and ordering search results or ad placements  and users have a clear incentive of maximizing
an item’s exposure. Nonetheless  the selection process is typically heuristic.
Recent years have seen an abundance of work on methods for user-speciﬁc tag recommendations
[8  10  5]. Such methods aim to support collaborative tagging systems  where any user can tag any
item in the repository. In contrast  in this paper we take a complementary perspective and focus on
taxonomic tagging systems  where only the owner of an item can determine its tags. We formalize
the task of optimal tagging and suggest an efﬁcient  provably-approximate algorithm. While the
problem is shown to be NP-hard  we prove that the objective is in fact monotone and submodular 
which suggests a straightforward greedy (1 − 1
e )-approximation algorithm [13]. We also show how
the greedy step  which consists of solving a set of linear equations  can be greatly simpliﬁed. This
results in a signiﬁcant improvement of runtime.
We begin by modeling a user browsing a tagged information system as a random walk. Items and
tags act as states in a Markov chain  whose transition probabilities describe the probability of users
transitioning between items and tags. Given a new item  our task is to choose a subset of k tags for
this item. When an item is tagged  positive probabilities are assigned to transitioning both from the
tag to the item and from the item to the tag. Our objective is to choose the subset of k tags which will
maximize trafﬁc to that item  namely the probability of a random walk reaching the item. Intuitively 
tagging an item causes probability to ﬂow from the tag to the item  on account of other items with
this tag. Our goal is to take as much probability mass as possible from the system as a whole.
Our method shares some similarities with other PageRank (PR  [2]) based methods  which optimize
measures based on the stationary distribution [14  4  6  15]. Here we argue that our approach  which
focuses on maximizing the probability of a random walk reaching a new item’s state  is better suited
to the task of optimal tagging. First  an item’s popularity should only increase when assigned a new
tag. Since tagging an item creates bidirectional links  its stationary probability may undesirably
decrease. Hence  optimizing the PR of an item will lead to an undesired non-monotone objective [1].
Second  PR considers a single Markov chain for all items  and is thus not item-centric. In contrast 
our method considers a unique instance of the transition system for every item we consider. While an
item-speciﬁc Personalized PR based objective can be constructed  it would consider random walks
from a given state  not to it. Third  a stationary distribution does not always exist  and hence may
require modiﬁcations of the Markov chain. Finally  optimizing PR is known to be hard. While some
approximations exist  our method provides superior guarantees and potentially better runtime [16].
Although the Markov chain model we propose for optimal tagging is bipartite  our results apply to
general Markov chains. We therefore ﬁrst formulate a general problem in Sec. 3  where the task is
to choose k states to link a new state to such that the probability of reaching that state is maximal.
Then  in Sec. 4 we prove that this problem is NP-hard by a reduction from vertex cover. In Sec. 5 we
prove that for a general Markov chain the optimal objective is both monotonically non-decreasing
and submodular. Based on this  in Sec. 6 we suggest a basic greedy (1− 1
e )-approximation algorithm 
and describe a method for signiﬁcantly improving its runtime. In Sec. 7 we revisit the optimal tagging
problem and show how to construct a bipartite Markov chain for a given tag-supporting information
system. In Sec. 8 we present experimental results on three tagging datasets (musical artists in Last.fm 
bookmarks in Delicious  and movies in Movielens) and show that our algorithm outperforms other
baselines. Concluding remarks are given in Sec. 9.

2 Related Work

One of the main roles of tags is to aid in the categorization and classiﬁcation of content. An active
line of research in tagging systems focuses on the task of tag recommendations  where the goal is
to predict the tags a given user may assign an item. This task is applicable in collaborative tagging
systems and folksonomies  where any user can tag any item. Methods for this task are based on
random walks [8  10] and tensor factorization [5]. While the goal in tag recommendation is also to
output a set of tags  our task is very different in nature. Tag recommendation is a prediction task for
item-user pairs  is based on ground-truth evaluation  and is applied in collaborative tagging systems.
In contrast  ours is an item-centric optimization task for tag-based taxonomies  and is counterfactual
in nature  as the selection of tags is assumed to affect future outcomes.

2

A line of work similar to ours is optimizing the PageRank of web pages in different settings. In [4]
the authors consider the problem of computing the maximal and minimal PageRank value for a set of
“fragile” links. The authors of [1] analyze the effects of additional outgoing links on the PageRank
value. Perhaps the works most closely related to ours are [16  14]  where an approximation algorithm
is given for the problem of maximizing the PageRank value by adding at most k incoming links. The
authors prove that the probability of reaching a web page is submodular and monotone in a fashion
similar to ours (but with a different parameterization)  and use it as a proxy for PageRank.
Our framework uses absorbing Markov chains  whose relation to submodular optimization has been
explored in [6] for opinion maximization and in [12] for computing centrality measures in networks.
Following the classic work of Nemhauser [13]  submodular optimization is now a very active line of
research. Many interesting optimization problems across diverse domains have been shown to be
submodular. Examples include sensor placement [11] and social inﬂuence maximization [9].

3 Problem Formulation

Before presenting our approach to optimal tagging  we ﬁrst describe a general combinatorial opti-
mization task over Markov chains  of which optimal tagging is a special case. Consider a Markov
chain over n + 1 states. Assume there is a state σ to which we would like to add k new incoming
transitions  where w.l.o.g. σ = n + 1. In the tagging problem  σ will be an item (e.g.  song or product)
and the incoming transitions will be from possible tags for the item  or from related items.
The optimization problem is then to choose a subset S ⊆ [n] of k states so as to maximize the
probability of visiting σ at some point in time. Formally  let Xt ∈ [n + 1] be the random variable
corresponding to the state of the Markov chain at time t. Then the optimal tagging problem is:

max

S⊆[n]  |S|≤k

PS [Xt = σ for some t ≥ 0]

(1)

At ﬁrst glance  it is not clear how to compute the objective function in Eq. (1). However  with a slight
modiﬁcation of the Markov chain  the objective function can be expressed as a simple function of the
Markov chain parameters  as explained next.
In general  σ may have outgoing edges  and random walks reaching σ may continue to other states
afterward. Nonetheless  as we are only interested in the probability of reaching σ  the states visited
after σ have no effect on our objective. Hence  the edges out of σ can be safely replaced with a single
self-edge without affecting the probability of reaching σ. This essentially makes σ an absorbing
state  and our task becomes to maximize the probability of the Markov chain being absorbed in σ. In
the remainder of the paper we consider this equivalent formulation.
When the Markov chain includes other absorbing states  optimizing over S can be intuitively thought
of as trying to transfer as much probability mass from the competing absorbing states to σ  under
a budget on the number of states that can be connected to σ.1 As we discuss in Section 7  having
competing absorbing states arises naturally in optimal tagging.
To fully specify the problem  we need the Markov chain parameters. Denote the initial distribution
by π. For the transition probabilities  each node i will have two sets of transitions: one when it is
allowed to transition to σ (i.e.  i ∈ S) and one when no transition is allowed. Using two distinct sets
is necessary since in both cases outgoing probabilities must sum to one. We use qij to denote the
transition probability from state i to j when transition from i to σ is not allowed  and q+
ij when it is.
We also denote the corresponding transition matrices by Q and Q+.
It is natural to assume that when adding a link from i to σ  transition into σ will become more likely 
and transition to other states can only be less likely. Thus  we add the assumptions that:

∀i : 0 = qiσ ≤ q+
iσ 

∀i   ∀j (cid:54)= σ : q+

ij ≤ qij

Given a subset S of states from which transitions to σ are allowed  we construct a new transition
matrix  taking corresponding rows from Q and Q+. We denote this matrix by ρ(S)  with

(cid:26) q+

ij
qij

i ∈ S
i /∈ S

ρij(S) =

(2)

(3)

1 In an ergodic chain with one absorbing state  all walks reach σ w.p. 1  and the problem becomes trivial.

3

4 NP-Hardness

We now show that for a general Markov chain  the optimal tagging problem in Eq. (1) is NP-hard
by a reduction from vertex cover. Given an undirected graph G = (V  E) with n nodes as input to
the vertex cover problem  we construct an instance of optimal tagging such that there exists a vertex
cover S ⊆ V of size at most k iff the probability of reaching σ reaches some threshold.
To construct the absorbing Markov chain  we create a transient state i for every node i ∈ V   and add
two absorbing states ∅ and σ. We set the initial distribution to be uniform  and for some 0 <  < 1
set the transitions for transient states i as follows:

(cid:26) 1 j = σ

j (cid:54)= σ

0

q+
ij =

 

qij =

 0


1−
deg(i)

j = σ
j = ∅
otherwise

(4)

Let U ⊆ V of size k  and S(U ) the set of states corresponding to the nodes in U. We claim that U is
a vertex cover in G iff the probability of reaching σ when S(U ) is chosen is 1 − (n−k)
n .
Assume U is a vertex cover. For every i ∈ S(U )  a walk starting in i will reach σ with probability
1 in one step. For every i (cid:54)∈ S(U )  with probability  a walk will reach ∅ in one step  and with
probability 1 −  it will visit one of its neighbors j. Since U is a vertex cover  it will then reach σ
in one step with probability 1. Hence  in total it will reach σ with probability 1 − . Overall  the
probability of reaching σ is k+(n−k)(1−)
n  as needed. Note that this is the maximal
possible probability of reaching σ for any subset of V of size k.
Assume now that U is not a vertex cover  then there exists an edge (i  j) ∈ E such that both i (cid:54)∈ S(U )
and j (cid:54)∈ S(U ). A walk starting in i will reach ∅ in one step with probability   and in two steps (via
j) with probability · qij > 0. Hence  it will reach σ with probability strictly smaller than 1 −   and
the overall probability of reaching  will be strictly smaller than 1 − (n−k)
n .

= 1 − (n−k)

n

5 Proof of Monotonicity and Submodularity
Denote by PS [A] the probability of event A when transitions from S to σ are allowed. We deﬁne:
(5)
(6)

(S) = PS [Xt = σ for some t ≤ k|X0 = i]
c(k)
i
ci(S) = PS [Xt = σ for some t|X0 = i] = limk→∞ c(k)

i

Using c(S) = (c1(S)  . . .   cn(S))  the objective in Eq. (1) now becomes:

max

S⊆[n] |S|≤k

f (S) 

f (S) = (cid:104)π  c(S)(cid:105) = PS [Xt = σ for some t]

(7)

We now prove that f (S) is both monotonically non-decreasing and submodular.

5.1 Monotonicity

When a link is created from i to σ  the probability of reaching σ directly from i increases. However 
due to the renormalization constraints  the probability of reaching σ via longer paths may decrease.
Trying to prove that for every random walk f is monotone and using additive closure is bound to fail.
Nonetheless  our proof of monotonicity shows that the overall probability cannot decrease.
Theorem 5.1. For every k ≥ 0 and i ∈ [n]  c(k)
z ∈ [n] \ S  it holds that c(k)
(S ∪ {z}).

is non-decreasing. Namely  for all S ⊆ [n] and

(S) ≤ c(k)

i

i

i

Proof. We prove by induction on k. For k = 0  as π is independent of S and z  we have:

Assume now that the claim holds for some k ≥ 0. For any T ⊆ [n]  it holds that:

c0
i (S) = πσ1{i=σ} = c0

i (S ∪ {z})

c(k+1)
i

(T ) =

ρij(T )c(k)

j

(T ) + ρiσ1{i∈T}

(8)

n(cid:88)

j=1

4

We separate into cases. When i (cid:54)= z  we have:

i ∈ S :

i (cid:54)∈ S :

c(k+1)
i

(S) =

c(k+1)
i

(S) =

ijc(k)
q+

j

qijc(k)

j

ijc(k)
q+

j

(S ∪ z) + q+

iσ = c(k+1)

i

(S ∪ z)

(9)

j=1

qijc(k)

j

(S ∪ z) = c(k+1)

i

(S ∪ z)

(10)

n(cid:88)
n(cid:88)

j=1

j=1

iσ ≤ n(cid:88)

j=1

(S) + q+

(S) ≤ n(cid:88)
n(cid:88)
n(cid:88)

j=1

using the inductive assumption and Eq. (8). When i = z  we have:

c(k+1)
i

(S ∪ z) =

ijc(k)
q+

j

(S ∪ z) +

(qij − q+

ij)c(k)

j

(S ∪ z)

j

qijc(k)

(S) ≤ n(cid:88)
≤ n(cid:88)
ij  c ≤ 1 (cid:80)n

ijc(k)
q+

j=1

j=1

j

(qij − q+

(S ∪ z) +

j=1 qij = 1  and(cid:80)n

j=1

ij) =

n(cid:88)

j=1

n(cid:88)
ij = 1 − q+
iσ.

ijc(k)
q+

j=1

j

(S ∪ z) + q+

zσ = c(k+1)

i

(S ∪ z)

due to to qij ≥ q+
Corollary 5.2. ∀i ∈ [n]  ci(S) is non-decreasing  hence f (S) = (cid:104)π  c(S)(cid:105) is non-decreasing.

j=1 q+

5.2 Submodularity

Submodularity captures the principle of diminishing returns. A function f (S) is submodular if:

∀X ⊆ Y ⊆ [n]  z /∈ X 

f (X ∪ {z}) − f (X) ≥ f (Y ∪ {z}) − f (Y )

In what follows we will use the following equivalent deﬁnition:

∀S ⊆ [n]  z1  z2 ∈ [n] \ S 

f (S ∪ {z1}) + f (S ∪ {z2}) ≥ f (S ∪ {z1  z2}) + f (S)

(11)

Using this formulation  we now show that f (S) as deﬁned in Eq. (7) is submodular.
Theorem 5.3. For every k ≥ 0 and i ∈ [n]  c(k)

(S) is a submodular function.

i

Proof. We prove by induction on k. For k = 0  once again π is independent of S and hence c0
modular. Assume now that the claim holds for some k ≥ 0. For brevity we deﬁne:
c(k)
i 12 = c(k)
c(k)
i = c(k)

(S ∪ {z1  z2})

(S ∪ {z1}) 

i

i

i is

(S ∪ {z2}) 
. For every j ∈ [n]  we’ll prove that:

i

(S) 

c(k)
i 1 = c(k)
We’d like to show that c(k+1)
ρij(S ∪ {z1})c(k)

c(k)
i 2 = c(k)
i 2 ≥ c(k+1)
i 1 + c(k+1)
i 12 + c(k+1)
j 1 + ρij(S ∪ {z2})c(k)

i

i

j 2 ≥ ρij(S ∪ {z1  z2})c(k)

j 12 + ρij(S)c(k)
By summing over all j ∈ [n] and adding ρiσ1{i∈T} we get Eq. (8) and conclude our proof.
We separate into different cases for i. If i ∈ S  then we have ρij(S ∪ {z1  z2}) = ρij(S ∪ {z1}) =
ρij(S ∪ {z2}) = ρij(S) = q+
ij. Similarly  if i /∈ S ∪ {z1  z2}  then all terms now equal qij. Eq. (12)
then follows from the inductive assumption.
Assume i = z1 (and analogously for i = z2). From the assumption in Eq. (2) we can write
qij = (1 + α)q+

(12)

j

ij for some α ≥ 0. Then Eq. (12) becomes:
ijc(k)

ijc(k)
ij > 0 if needed and reorder to get:

j 1 + (1 + α)q+

ijc(k)
q+

j 2 ≥ q+
(cid:17)

(cid:16)

Divide by q+

c(k)
j 1 + ck

j 2 − c(k)

j 12 − c(k)

j

+ α(ck

j 2 − c(k)

j

) ≥ 0

j 12 + (1 + α)q+

ijc(k)

j

(13)

(14)

This indeed holds since the ﬁrst term is non-negative from the inductive assumption  and the second
term is non-negative because of monotonicity and α ≥ 0.
Corollary 5.4. ∀ i ∈ [n]  ci(S) is submodular  hence f (S) = (cid:104)π  c(S)(cid:105) is submodular.

5

Initialize S = ∅
for i ← 1 to k do

Algorithm 1
1: function SIMPLEGREEDYTAGOPT(Q  Q+  π  k)
2:
3:
4:
5:
6:
7:
8:

c =(cid:0)I − A(S ∪ {z})(cid:1) \ b(S ∪ {z})

for z ∈ [n] \ S do
v(z) = (cid:104)π  c(cid:105)

S ← S ∪ argmaxz v(z)

Return S

6 Optimization

(cid:46) See supp. for efﬁcient implementation

(cid:46) A  b are set by Q  Q+ using Eqs. (3)  (15)

Maximizing submodular functions is hard in general. However  a classic result by Nemhauser [13]
shows that a non-decreasing submodular set function  such as our f (S)  can be efﬁciently optimized
via a simple greedy algorithm  with a guaranteed (1 − 1
e )-approximation of the optimum. The greedy
algorithm initializes S = ∅  and then sequentially adds elements to S. For a given S  the algorithm
iterates over all z ∈ [n] \ S and computes f (S ∪ {z}). Then  it adds the highest scoring z to S  and
continues to the next step. We now discuss its implementation for our problem.
Computing f (S) for a given S reduces to solving a set of linear equations. For transient states
{1  . . .   n− r} and absorbing states {n− r + 1  . . .   n + 1 = σ}  the transition matrix ρ(S) becomes:

(cid:18) A(S) B(S)

(cid:19)

0

I

ρ(S) =

(15)

∞(cid:88)

(cid:88)

t=0

j∈[n−r]

∞(cid:88)

where A(S) are the transition probabilities between transient states  B(S) are the transition probabil-
ities from transient states to absorbing states  and I is the identity matrix. When clear from context
we will drop the dependence of A  B on S. Note that ρ(S) has at least one absorbing state (namely
σ). We denote by b the column of B corresponding to state σ (i.e.  B’s rightmost column).
We would like to calculate f (S). By Eq. (6)  the probability of reaching σ given an initial state i is:

ci(S) =

PS [Xt = σ|Xt−1 = j] PS [Xt−1 = j|X0 = i] =

(cid:32) ∞(cid:88)

(cid:33)

Atb

t=0

i

The above series has a closed form solution:

At = (I − A)−1 ⇒ c = (I − A)−1b

t=0

Thus  c(S) is the solution of the set of linear equations  which readily gives us f (S):

f (S) = (cid:104)π  c(cid:105)

s.t.

(I − A(S))c = b(S)

(16)

The greedy algorithm can thus be implemented by sequentially considering candidate sets S of
increasing size  and for each z calculating f (S ∪ {z}) by solving a set of linear equations (see
Algorithm 1). Though parallelizable  this naïve implementation may be costly as it requires solving
O(n2) sets of n − r linear equations  one for every addition of z to S. Fast submodular solvers [7]
can reduce the number of f (S) evaluations by an order of magnitude. In addition  we now show how
a signiﬁcant speedup in computing f (S) itself can be achieved using certain properties of f (S).
A standard method for solving the set of linear equations (I − A)c = b if to ﬁrst compute an LU P
decomposition for (I − A)  namely ﬁnd lower and upper diagonal matrices L  U and a permutation
matrix P such that LU = P (I − A). Then  it sufﬁces to solve Ly = P b and U c = y. Since L and U
are diagonal  solving these equations can be performed efﬁciently. The costly operation is computing
the decomposition in the ﬁrst place.
Recall that ρ(S) is composed of rows from Q+ corresponding to S and rows from Q corresponding to
[n] \ S. This means that ρ(S) and ρ(S ∪ {z}) differ only in one row  or equivalently  that ρ(S ∪ {z})
can be obtained from ρ(S) by adding a rank-1 matrix. Given an LU P decomposition of ρ(S)  we can

6

efﬁciently compute f (S ∪ {z}) (and the corresponding decomposition) using efﬁcient rank-1-update
techniques such as Bartels-Golub-Reid [17]  which are especially efﬁcient for sparse matrices. As a
result  it sufﬁces to compute only a single LU P decomposition once at the beginning  and perform
cheap updates at every step. We give an efﬁcient implementation in the supp. material.

7 Optimal Tagging

In this section we return to the task of optimal tagging and show how the Markov chain optimization
framework described above can be applied. We use a random surfer model  where a browsing user
hops between items and tags in a bipartite Markov chain. In its explicit form  our model captures the
activity of browsing users whom  when viewing an item  are presented with the item’s tags and may
choose to click on them (and similarly when viewing tags).
In reality  many systems also include direct links between related items  often in the form of a ranked
list of item recommendations. The relatedness of two items is in many cases  at least to some extent 
based on their mutual tags. Our model captures this notion of similarity by indirect transitions via
tag states. This allows us to encode tags as variables in the objective. Furthermore  adding direct
transitions between items is straightforward as our results apply to general Markov chains. Note that
in contrast to models for tag recommendation  we do not need to explicitly model users  as our setup
deﬁnes only one distinct optimization task per item.
In what follows we formalize the above notions. Consider a system of m items Ω = {ω1  . . .   ωm}
and n tags T = {τ1  . . .   τn}. Each item ωi has a set of tags Ti ⊆ T   and each tag τj has a set of
items Ωj ⊆ Ω. The items and tags constitute the states of a bipartite Markov chain  where users hop
between items and tags. Speciﬁcally  the transition matrix ρ can have non-zero entries ρij and ρji for
items ωi tagged by τj. To model the fact that browsing users eventually leave the system  we add a
global absorbing state ∅ and add transition probabilities ρi∅ = i > 0 for all items ωi. For simplicity
we assume that i =  for all i  and that π can be non-zero only for tag states.
In our setting  when a new item σ is uploaded  its owner may choose a set S ⊆ T of at most k tags
for σ. Her goal is to choose S such that the probability of an arbitrary browsing user reaching (or
equivalently  being absorbed in) σ while browsing the system is maximal. As in the general case  the
choice of S affects the transition matrix ρ(S). Denote by Pij the transition probability from item ωi
to tag τj  by Rji(S) the transition probability from τj to ωi under S  and let rj(S) = Rjσ(S). Using
Eq. (15)  ρ can be written as:

(cid:19)

(cid:18) A B

0 I2

(cid:18) 0 R(S)

(cid:19)

P

0

ρ(S) =

 

A =

  B =

(cid:18) 0

1· 

(cid:19)

r(S)

0

 

I2 =

(cid:18) 1

0

(cid:19)

0
1

where 0 and 1 are appropriately sized vectors or matrices. Since we are only interested in selecting
tags  we may consider a chain that includes only the tag states  with the item states marginalized out.
The transition matrix between tags is given by ρ2(S) = R(S)P . The transition probabilities from
tags to σ remain r(S). Our objective of maximizing the probability of reaching σ under S is then:
(17)
which is a special case of the general objective presented in Eq. (16)  and hence can be optimized
efﬁciently. In the supplementary material we prove that this special case is still NP-hard.

(I − R(S)P ) c = r(S)

f (S) = (cid:104)π  c(cid:105)

s.t.

8 Experiments

To demonstrate the effectiveness of our approach  we perform experiments on optimal tagging in data
collected from Last.fm  Delicious  and Movielens by the HetRec 2011 workshop [3]. The datasets
include all items (between 10 197 and 59 226) and tags (between 11 946 and 53 388) reached by
crawling a set of about 2 000 users in each system  as well as some metadata.
For each dataset  we ﬁrst created a bipartite graph of items and tags. Next  we generated 100 different
instances of our problem per dataset by expanding each of the 100 highest-degree tags and creating a
Markov chain for their items and their tags. We discarded nodes with less than 10 edges.
To create an interesting tag selection setup  for each item in each instance we augmented its true
tags with up to 100 similar tags (based on [18]). These served as the set of candidate tags for which

7

Figure 1: The probability of reaching a focal item σ under a budget of k tags for various methods.

transitions to the item were allowed. We focused on items which were ranked ﬁrst in at least 10 of
their 100 candidate tags  giving a total of 18 167 focal items for comparison. For each such item  our
task was to choose the k tags which maximize the probability of reaching the focal item.
Transition probabilities from tags to items were set to be proportional to the item weights - number of
listens for artists in Last.fm  tag counts for bookmarks in Delicious  and averaged ratings for movies
in Movielens. As the datasets do not include explicit weights for tags  we used uniform transition
probabilities from items to tags. The initial distribution was set to be uniform over the set of candidate
tags  and the transition probability from items to ∅ was set to  = 0.1.
We compared the performance of our greedy algorithm with several baselines. Random-walk
based methods included PageRank and an adaptation2 of BiFolkRank [10]  a state-of-the-art tag
recommendation method that operates on item-tag relations. Heuristics included choosing tags with
highest and lowest degree  true labels (for relevant k-s) sorted by weight  and random. To measure
the added value of long random walks  we also display the probability of reaching σ in one step.
Results for all three datasets are provided in Fig. 1  which shows the average probability of reaching
the focal item for values of k ∈ {1  . . .   25}. As can be seen  the greedy method clearly outperforms
other baselines. Considering paths of all lengths improves results by a considerable 20-30% for
k = 1  and roughly 5% for k = 25. An interesting observation is that the performance of the true
tags is rather poor. A plausible explanation for this is that the data we use are taken from collaborative
tagging systems  where items can be tagged by any user. In such systems  tags typically play a
categorical or hierarchical role  and as such are probably not optimal for promoting item popularity.
The supplementary material includes an interesting case analysis.

9 Conclusions

In this paper we introduced the problem of optimal tagging  along with the general problem of
optimizing probability mass in Markov chains by adding links. We proved that the problem is NP-
hard  but can be (1 − 1
e )-approximated due to the submodularity and monotonicity of the objective.
Our efﬁcient greedy algorithm can be used in practice for choosing optimal tags or keywords in
various domains. Our experimental results show that simple heuristics and PageRank variants
underperform our disciplined approach  and naïvely selecting the true tags can be suboptimal.
In our work we assumed access to the transition probabilities between tags and items and vice versa.
While the transition probabilities for existing items can be easily estimated by a system’s operator 
estimating the probabilities from tags to new items is non-trivial. This is an interesting problem to
pursue. Even so  users do not typically have access to the information required for estimation. Our
results suggest that users can simply apply the greedy steps sequentially via trial-and-error [9].
Finally  since our task is of a counterfactual nature  it is hard to draw conclusions from the experiments
as to the effectiveness of our method in real settings. It would be interesting to test it in realty  and
compare it to strategies used by both lay users and experts. Especially interesting in this context are
competitive domains such as ad placements and viral marketing. We leave this for future research.
Acknowledgments: This work was supported by the ISF Centers of Excellence grant 2180/15  and by the Intel
Collaborative Research Institute for Computational Intelligence (ICRI-CI).

2To apply the method to our setting  we used a uniform prior over user-tag relations.

8

k1 5 9 13172125Pr(σ)00.050.10.150.2Last.fmGreedyPageRankBiFolkRank*High degreeLow degreeTrue tagsOne stepRandomk1 5 9 13172125Pr(σ)00.050.10.150.2Deliciousk1 5 9 13172125Pr(σ)00.050.10.150.20.25MovielensReferences
[1] Konstantin Avrachenkov and Nelly Litvak. The effect of new links on google pagerank.

Stochastic Models  22(2):319–331  2006.

[2] Sergey Brin and Lawrence Page. Reprint of: The anatomy of a large-scale hypertextual web

search engine. Computer networks  56(18):3825–3833  2012.

[3] Iván Cantador  Peter Brusilovsky  and Tsvi Kuﬂik. 2nd workshop on information heterogeneity
and fusion in recommender systems (hetrec 2011). In Proceedings of the 5th ACM conference
on Recommender systems  RecSys 2011  New York  NY  USA  2011. ACM.

[4] Balázs Csanád Csáji  Raphaël M Jungers  and Vincent D Blondel. Pagerank optimization in
polynomial time by stochastic shortest path reformulation. In Algorithmic Learning Theory 
pages 89–103. Springer  2010.

[5] Xiaomin Fang  Rong Pan  Guoxiang Cao  Xiuqiang He  and Wenyuan Dai. Personalized tag
recommendation through nonlinear tensor factorization using gaussian kernel. In Twenty-Ninth
AAAI Conference on Artiﬁcial Intelligence  2015.

[6] Aristides Gionis  Evimaria Terzi  and Panayiotis Tsaparas. Opinion maximization in social

networks. In SDM  pages 387–395. SIAM  2013.

[7] Amit Goyal  Wei Lu  and Laks VS Lakshmanan. CELF++: optimizing the greedy algorithm for
inﬂuence maximization in social networks. In Proceedings of the 20th international conference
companion on World wide web  pages 47–48. ACM  2011.

[8] Andreas Hotho  Robert Jäschke  Christoph Schmitz  Gerd Stumme  and Klaus-Dieter Althoff.

Folkrank: A ranking algorithm for folksonomies. In LWA  volume 1  pages 111–114  2006.

[9] David Kempe  Jon Kleinberg  and Éva Tardos. Maximizing the spread of inﬂuence through
a social network. In Proceedings of the ninth ACM SIGKDD international conference on
Knowledge discovery and data mining  pages 137–146. ACM  2003.

[10] Heung-Nam Kim and Abdulmotaleb El Saddik. Personalized pagerank vectors for tag recom-
mendations: inside folkrank. In Proceedings of the ﬁfth ACM conference on Recommender
systems  pages 45–52. ACM  2011.

[11] Andreas Krause  Ajit Singh  and Carlos Guestrin. Near-optimal sensor placements in gaussian
processes: Theory  efﬁcient algorithms and empirical studies. The Journal of Machine Learning
Research  9:235–284  2008.

[12] Charalampos Mavroforakis  Michael Mathioudakis  and Aristides Gionis. Absorbing random-

walk centrality: Theory and algorithms. arXiv preprint arXiv:1509.02533  2015.

[13] George L Nemhauser  Laurence A Wolsey  and Marshall L Fisher. An analysis of approximations
for maximizing submodular set functions. Mathematical Programming  14(1):265–294  1978.

[14] Martin Olsen. Maximizing pagerank with new backlinks. In International Conference on

Algorithms and Complexity  pages 37–48. Springer  2010.

[15] Martin Olsen and Anastasios Viglas. On the approximability of the link building problem.

Theoretical Computer Science  518:96–116  2014.

[16] Martin Olsen  Anastasios Viglas  and Ilia Zvedeniouk. A constant-factor approximation algo-
rithm for the link building problem. In Combinatorial Optimization and Applications  pages
87–96. Springer  2010.

[17] John Ker Reid. A sparsity-exploiting variant of the Bartels-Golub decomposition for linear

programming bases. Mathematical Programming  24(1):55–69  1982.

[18] Börkur Sigurbjörnsson and Roelof Van Zwol. Flickr tag recommendation based on collective
knowledge. In Proceedings of the 17th international conference on World Wide Web  pages
327–336. ACM  2008.

9

,Nir Rosenfeld
Amir Globerson
Ofir Lindenbaum
Jay Stanley
Guy Wolf
Smita Krishnaswamy