2015,A Framework for Individualizing Predictions of Disease Trajectories by Exploiting Multi-Resolution Structure,For many complex diseases  there is a wide variety of ways in which an individual can manifest the disease. The challenge of personalized medicine is to develop tools that can accurately predict the trajectory of an individual's disease  which can in turn enable clinicians to optimize treatments. We represent an individual's disease trajectory as a continuous-valued continuous-time function describing the severity of the disease over time. We propose a hierarchical latent variable model that individualizes predictions of disease trajectories. This model shares statistical strength across observations at different resolutions--the population  subpopulation and the individual level. We describe an algorithm for learning population and subpopulation parameters offline  and an online procedure for dynamically learning individual-specific parameters. Finally  we validate our model on the task of predicting the course of interstitial lung disease  a leading cause of death among patients with the autoimmune disease scleroderma. We compare our approach against state-of-the-art and demonstrate significant improvements in predictive accuracy.,A Framework for Individualizing Predictions of Disease
Trajectories by Exploiting Multi-Resolution Structure

Peter Schulam

Dept. of Computer Science
Johns Hopkins University

Baltimore  MD 21218
pschulam@jhu.edu

Suchi Saria

Dept. of Computer Science
Johns Hopkins University

Baltimore  MD 21218

ssaria@cs.jhu.edu

Abstract

For many complex diseases  there is a wide variety of ways in which an indi-
vidual can manifest the disease. The challenge of personalized medicine is to
develop tools that can accurately predict the trajectory of an individual’s disease 
which can in turn enable clinicians to optimize treatments. We represent an in-
dividual’s disease trajectory as a continuous-valued continuous-time function de-
scribing the severity of the disease over time. We propose a hierarchical latent
variable model that individualizes predictions of disease trajectories. This model
shares statistical strength across observations at different resolutions–the popula-
tion  subpopulation and the individual level. We describe an algorithm for learning
population and subpopulation parameters ofﬂine  and an online procedure for dy-
namically learning individual-speciﬁc parameters. Finally  we validate our model
on the task of predicting the course of interstitial lung disease  a leading cause
of death among patients with the autoimmune disease scleroderma. We compare
our approach against state-of-the-art and demonstrate signiﬁcant improvements in
predictive accuracy.

Introduction

1
In complex  chronic diseases such as autism  lupus  and Parkinson’s  the way the disease manifests
may vary greatly across individuals [1]. For example  in scleroderma  the disease we use as a running
example in this work  individuals may be affected across six organ systems—the lungs  heart  skin 
gastrointestinal tract  kidneys  and vasculature—to varying extents [2]. For any single organ system 
some individuals may show rapid decline throughout the course of their disease  while others may
show early decline but stabilize later on. Often in such diseases  the most effective drugs have
strong side-effects. With tools that can accurately predict an individual’s disease activity trajectory 
clinicians can more aggressively treat those at greatest risk early  rather than waiting until the disease
progresses to a high level of severity. To monitor the disease  physicians use clinical markers to
quantify severity. In scleroderma  for example  PFVC is a clinical marker used to measure lung
severity. The task of individualized prediction of disease activity trajectories is that of using an
individual’s clinical history to predict the future course of a clinical marker; in other words  the goal
is to predict a function representing a trajectory that is updated dynamically using an individual’s
previous markers and individual characteristics.
Predicting disease activity trajectories presents a number of challenges. First  there are multiple la-
tent factors that cause heterogeneity across individuals. One such factor is the underlying biological
mechanism driving the disease. For example  two different genetic mutations may trigger distinct
disease trajectories (e.g. as in Figures 1a and 1b). If we could divide individuals into groups accord-
ing to their mechanisms—or disease subtypes (see e.g. [3  4  5  6])—it would be straightforward
to ﬁt separate models to each subpopulation. In most complex diseases  however  the mechanisms
are poorly understood and clear deﬁnitions of subtypes do not exist. If subtype alone determined
trajectory  then we could cluster individuals. However  other unobserved individual-speciﬁc factors

1

such as behavior and prior exposures affect health and can cause different trajectories across indi-
viduals of the same subtype. For instance  a chronic smoker will typically have unhealthy lungs and
so may have a trajectory that is consistently lower than a non-smoker’s  which we must account for
using individual-speciﬁc parameters. An individual’s trajectory may also be inﬂuenced by transient
factors—e.g. an infection unrelated to the disease that makes it difﬁcult to breath (similar to the
“dips” in Figure 1c or the third row in Figure 1d). This can cause marker values to temporarily drop 
and may be hard to distinguish from disease activity. We show that these factors can be arranged in
a hierarchy (population  subpopulation  and individual)  but that not all levels of the hierarchy are
observed. Finally  the functional outcome is a rich target  and therefore more challenging to model
than scalar outcomes. In addition  the marker data is observed in continuous-time and is irregularly
sampled  making commonly used discrete-time approaches to time series modeling (or approaches
that rely on imputation) not well suited to this domain.
Related work. The majority of predictive models in medicine explain variability in the target out-
come by conditioning on observed risk factors alone. However  these do not account for latent
sources of variability such as those discussed above. Further  these models are typically cross-
sectional—they use features from data measured up until the current time to predict a clinical marker
or outcome at a ﬁxed point in the future. As an example  consider the mortality prediction model by
Lee et al. [7]  where logistic regression is used to integrate features into a prediction about the prob-
ability of death within 30 days for a given patient. To predict the outcome at multiple time points 
typically separate models are trained. Moreover  these models use data from a ﬁxed-size window 
rather than a growing history.
Researchers in the statistics and machine learning communities have proposed solutions that ad-
dress a number of these limitations. Most related to our work is that by Rizopoulos [8]  where the
focus is on making dynamical predictions about a time-to-event outcome (e.g.
time until death).
Their model updates predictions over time using all previously observed values of a longitudinally
recorded marker. Besides conditioning on observed factors  they account for latent heterogeneity
across individuals by allowing for individual-speciﬁc adjustments to the population-level model—
e.g. for a longitudinal marker  deviations from the population baseline are modeled using random
effects by sampling individual-speciﬁc intercepts from a common distribution. Other closely related
work by Proust-Lima et al. [9] tackle a similar problem as Rizopoulos  but address heterogeneity
using a mixture model.
Another common approach to dynamical predictions is to use Markov models such as order-p
autoregressive models (AR-p)  HMMs  state space models  and dynamic Bayesian networks
(see e.g. in [10]). Although such models naturally make dynamic predictions using the full history
by forward-ﬁltering  they typically assume discrete  regularly-spaced observation times. Gaussian
processes (GPs) are a commonly used alternative for handling continuous-time observations—see
Roberts et al. [11] for a recent review of GP time series models. Since Gaussian processes are non-
parametric generative models of functions  they naturally produce functional predictions dynami-
cally by using the posterior predictive conditioned on the observed data. Mixtures of GPs have been
applied to model heterogeneity in the covariance structure across time series (e.g. [12])  however as
noted in Roberts et al.  appropriate mean functions are critical for accurate forecasts using GPs. In
our work  an individual’s trajectory is expressed as a GP with a highly structured mean comprising
population  subpopulation and individual-level components where some components are observed
and others require inference.
More broadly  multi-level models have been applied in many ﬁelds to model heterogeneous collec-
tions of units that are organized within a hierarchy [13]. For example  in predicting student grades
over time  individuals within a school may have parameters sampled from the school-level model 
and the school-level model parameters in turn may be sampled from a county-speciﬁc model. In our
setting  the hierarchical structure—which individuals belong to the same subgroup—is not known a
priori. Similar ideas are studied in multi-task learning  where relationships between distinct predic-
tion tasks are used to encourage similar parameters. This has been applied to modeling trajectories
by treating predictions at each time point as a separate task and enforcing similarity between sub-
models close in time [14]. This approach is limited  however  in that it models a ﬁnite number
of times. Others  more recently  have developed models for disease trajectories (see [15  16] and
references within) but these focus on retrospective analysis to discover disease etiology rather than
dynamical prediction. Schulam et al. [16] incorporate differences in trajectories due to subtypes and
individual-speciﬁc factors. We build upon this work here. Finally  recommender systems also share

2

Figure 1: Plots (a-c) show example marker trajectories. Plot (d) shows adjustments to a population and
subpopulation ﬁt (row 1). Row 2 makes an individual-speciﬁc long-term adjustment. Row 3 makes short-
term structured noise adjustments. Plot (e) shows the proposed graphical model. Levels in the hierarchy are
color-coded. Model parameters are enclosed in dashed circles. Observed random variables are shaded.

information across individuals with the aim of tailoring predictions (see e.g. [17  18  19])  but the
task is otherwise distinct from ours.
Contributions. We propose a hierarchical model of disease activity trajectories that directly ad-
dresses common—latent and observed—sources of heterogeneity in complex  chronic diseases us-
ing three levels: the population level  subpopulation level  and individual level. The model discovers
the subpopulation structure automatically  and infers individual-level structure over time when mak-
ing predictions. In addition  we include a Gaussian process as a model of structured noise  which
is designed to explain away temporary sources of variability that are unrelated to disease activity.
Together  these four components allow individual trajectories to be highly heterogeneous while si-
multaneously sharing statistical strength across observations at different “resolutions” of the data.
When making predictions for a given individual  we use Bayesian inference to dynamically update
our posterior belief over individual-speciﬁc parameters given the clinical history and use the poste-
rior predictive to produce a trajectory estimate. Finally  we evaluate our approach by developing a
state-of-the-art trajectory prediction tool for lung disease in scleroderma. We train our model using
a large  national dataset containing individuals with scleroderma tracked over 20 years and compare
our predictions against alternative approaches. We ﬁnd that our approach yields signiﬁcant gains in
predictive accuracy of disease activity trajectories.
2 Disease Trajectory Model
We describe a hierarchical model of an individual’s clinical marker values. The graphical model
is shown in Figure 1e. For each individual i  we use Ni to denote the number of observed mark-
ers. We denote each individual observation using yij and its measurement time using tij where
j ∈ {1  . . .   Ni}. We use (cid:126)yi ∈ RNi and (cid:126)ti ∈ RNi to denote all of individual i’s marker values and
measurement times respectively. In the following discussion  Φ(tij) denotes a column-vector con-

taining a basis expansion of the time tij and we use Φ(cid:0)(cid:126)ti

(cid:1) = [Φ(ti1)  . . .   Φ(tiNi)](cid:62) to denote the

matrix containing the basis expansion of points in (cid:126)ti in each of its rows. We model the jth marker
value for individual i as a normally distributed random variable with a mean assumed to be the sum
of four terms: a population component  a subpopulation component  an individual component  and
a structured noise component:

 .

  σ2

(1)

Φp(tij)(cid:62)Λ (cid:126)xip
(cid:125)
(cid:123)(cid:122)
(cid:124)

(A) population

(cid:124)

(cid:123)(cid:122)

yij ∼ N

+ Φz(tij)(cid:62) (cid:126)βzi

+ Φ(cid:96)(tij)(cid:62)(cid:126)bi

+

(cid:125)

(cid:124)

(cid:123)(cid:122)

(cid:125)

(cid:124) (cid:123)(cid:122) (cid:125)

fi(tij)

(B) subpopulation

(C) individual

(D) structured noise

The four terms in the sum serve two purposes. First  they allow for a number of different sources
of variation to inﬂuence the observed marker value  which allows for heterogeneity both across and
within individuals. Second  they share statistical strength across different subsets of observations.
The population component shares strength across all observations. The subpopulation component

3

Subtype marginal model coefﬁcientszifiM↵yijtijNi~gG~bi⌃b~⇢iPopulation model featuresPopulation model coefﬁcients Population model features-to-coefﬁcient mapSubtype B-spline coefﬁcientsSubtype indicator 2{1 ... G}Individual model covariance matrix2Rd`⇥d`Individual model coefﬁcients2Rd`Structured noise GP hyper-parametersStructured noise function2RR~xizSubtype marginal model features~wg2Rqz2Rqz2Rdz2Rqp2Rdp2Rdp⇥qp~xip⇤(d)(a)(b)(c)(e)shares strength across observations belonging to subgroups of individuals. The individual compo-
nent shares strength across all observations belonging to the same individual. Finally  the structured
noise shares information across observations belonging to the same individual that are measured at
similar times. Predicting an individual’s trajectory involves estimating her subtype and individual-
speciﬁc parameters as new clinical data becomes available1. We describe each of the components in
detail below.
Population level. The population model predicts aspects of an individual’s disease activity trajec-
tory using observed baseline characteristics (e.g. gender and race)  which are represented using the
feature vector (cid:126)xip. This sub-model is shown within the orange box in Figure 1e. Here we assume
that this component is a linear model where the coefﬁcients are a function of the features (cid:126)xip ∈ Rqp.
The predicted value of the jth marker of individual i measured at time tij is shown in Eq. 1 (A) 
where Φp (t) ∈ Rdp is a basis expansion of the observation time and Λ ∈ Rdp×qp is a matrix used as
a linear map from an individual’s covariates (cid:126)xip to coefﬁcients ρi ∈ Rdp. At this level  individuals
with similar covariates will have similar coefﬁcients. The matrix Λ is learned ofﬂine.
Subpopulation level. We model an individual’s subtype using a discrete-valued latent variable
zi ∈ {1  . . .   G}  where G is the number of subtypes. We associate each subtype with a unique
disease activity trajectory represented using B-splines  where the number and location of the knots
and the degree of the polynomial pieces are ﬁxed prior to learning. These hyper-parameters de-
termine a basis expansion Φz(t) ∈ Rdz mapping a time t to the B-spline basis function values at
that time. Trajectories for each subtype are parameterized by a vector of coefﬁcients (cid:126)βg ∈ Rdz
for g ∈ {1  . . .   G}  which are learned ofﬂine. Under subtype zi  the predicted value of marker
yij measured at time tij is shown in Eq. 1 (B). This component explains differences such as those
observed between the trajectories in Figures 1a and 1b. In many cases  features at baseline may be
predictive of subtype. For example  in scleroderma  the types of antibody an individual produces
(i.e. the presence of certain proteins in the blood) are correlated with certain trajectories. We can
improve predictive performance by conditioning on baseline covariates to infer the subtype. To do
this  we use a multinomial logistic regression to deﬁne feature-dependent marginal probabilities:
zi | (cid:126)xiz ∼ Mult (π1:G ((cid:126)xiz))  where πg ((cid:126)xiz) ∝ e (cid:126)w(cid:62)
g (cid:126)xiz. We denote the weights of the multinomial
regression using (cid:126)w1:G  where the weights of the ﬁrst class are constrained to be (cid:126)0 to ensure model
identiﬁability. The remaining weights are learned ofﬂine.
Individual level. This level models deviations from the population and subpopulation models us-
ing parameters that are learned dynamically as the individual’s clinical history grows. Here  we
parameterize the individual component using a linear model with basis expansion Φ(cid:96)(t) ∈ Rd(cid:96) and
individual-speciﬁc coefﬁcients (cid:126)bi ∈ Rd(cid:96). An individual’s coefﬁcients are modeled as latent vari-
ables with marginal distribution (cid:126)bi ∼ N ((cid:126)0  Σb). For individual i  the predicted value of marker yij
measured at time tij is shown in Eq. 1 (C). This component can explain  for example  differences in
overall health due to an unobserved characteristic such as chronic smoking  which may cause atyp-
ically lower lung function than what is predicted by the population and subpopulation components.
Such an adjustment is illustrated across the ﬁrst and second rows of Figure 1d.
Structured noise. Finally  the structured noise component fi captures transient trends. For ex-
ample  an infection may cause an individual’s lung function to temporarily appear more restricted
than it actually is  which may cause short-term trends like those shown in Figure 1c and the third
row of Figure 1d. We treat fi as a function-valued latent variable and model it using a Gaus-
sian process with zero-valued mean function and Ornstein-Uhlenbeck (OU) covariance function:

KOU(t1  t2) = a2 exp(cid:8)−(cid:96)−1|t1 − t2|(cid:9). The amplitude a controls the magnitude of the structured

noise that we expect to see and the length-scale (cid:96) controls the length of time over which we expect
these temporary trends to occur. The OU kernel is ideal for modeling such deviations as it is both
mean-reverting and draws from the corresponding stochastic process are only ﬁrst-order continuous 
which eliminates long-range dependencies between deviations [20]. Applications in other domains
may require different kernel structures motivated by properties of the noise in the trajectories.

1The model focuses on predicting the long-term trajectory of an individual when left untreated. In many
chronic conditions  as is the case for scleroderma  drugs only provide short-term relief (accounted for in our
model by the individual-speciﬁc adjustments). If treatments that alter long-term course are available and com-
monly prescribed  then these should be included within the model as an additional component that inﬂuences
the trajectory.

4

2.1 Learning
Objective function. To learn the parameters of our model Θ = {Λ  (cid:126)w1:G  (cid:126)β1:G  Σb  a  (cid:96)  σ2}  we
maximize the observed-data log-likelihood (i.e. the probability of all individual’s marker values (cid:126)yi
given measurement times (cid:126)ti and features {(cid:126)xip  (cid:126)xiz}). This requires marginalizing over the latent
variables {zi (cid:126)bi  fi} for each individual. This yields a mixture of multivariate normals:

G(cid:88)

πzi ((cid:126)xiz)N(cid:16)

(cid:126)yi | Φp

(cid:0)(cid:126)ti

(cid:1) Λ (cid:126)xip + Φz

(cid:0)(cid:126)ti

(cid:1) (cid:126)βzi  K(cid:0)(cid:126)ti  (cid:126)ti

(cid:1)(cid:17)

P ((cid:126)yi | Xi  Θ) =

 

(2)

zi=1

log-likelihood for all individuals is therefore: L (Θ) =(cid:80)M

where K(t1  t2) = Φ(cid:96)(t1)(cid:62)ΣbΦ(cid:96)(t2) + KOU(t1  t2) + σ2I(t1 = t2). The observed-data
i=1 log P ((cid:126)yi | Xi  Θ). A more detailed

derivation is provided in the supplement.
Optimizing the objective. To maximize the observed-data log-likelihood with respect to Θ  we
partition the parameters into two subsets. The ﬁrst subset  Θ1 = {Σb  α  (cid:96)  σ2}  contains values that
parameterize the covariance function K(t1  t2) above. As is often done when designing the ker-
nel of a Gaussian process  we use a combination of domain knowledge to choose candidate values
and model selection using observed-data log-likelihood as a criterion for choosing among candi-
dates [20]. The second subset  Θ2 = {Λ  (cid:126)w1:G  (cid:126)β1:G}  contains values that parameterize the mean
of the multivariate normal distribution in Equation 2. We learn these parameters using expectation
maximization (EM) to ﬁnd a local maximum of the observed-data log-likelihood.
Expectation step. All parameters related to (cid:126)bi and fi are limited to the covariance kernel and are
not optimized using EM. We therefore only need to consider the subtype indicators zi as unob-
served in the expectation step. Because zi is discrete  its posterior is computed by normalizing the
joint probability of zi and (cid:126)yi. Let π∗
ig denote the posterior probability that individual i has subtype
g ∈ {1  . . .   G}  then we have

ig ∝ πg ((cid:126)xiz)N(cid:16)

π∗

(cid:126)yi | Φp

(cid:0)(cid:126)ti

(cid:1) Λ (cid:126)xip + Φz

(cid:0)(cid:126)ti

(cid:1) (cid:126)βg  K(cid:0)(cid:126)ti  (cid:126)ti

(cid:1)(cid:17)

.

(3)

Maximization step. In the maximization step  we optimize the marginal probability of the soft
assignments under the multinomial logistic regression model with respect to (cid:126)w1:G using gradient-
based methods. To optimize the expected complete-data log-likelihood with respect to Λ and (cid:126)β1:G 
we note that the mean of the multivariate normal for each individual is a linear function of these
parameters. Holding Λ ﬁxed  we can therefore solve for (cid:126)β1:G in closed form and vice versa. We use
a block coordinate ascent approach  alternating between solving for Λ and (cid:126)β1:G until convergence.
Because the expected complete-data log-likelihood is concave with respect to all parameters in Θ2 
each maximization step is guaranteed to converge. We provide additional details in the supplement.

2.2 Prediction
Our prediction ˆy(t(cid:48)
i is the expectation of the marker y(cid:48)
i
under the posterior predictive conditioned on observed markers (cid:126)yi measured at times (cid:126)ti thus far.
This requires evaluating the following expression:

i) for the value of the trajectory at time t(cid:48)

(4)

(5)

 

(6)

(cid:90)

G(cid:88)

zi=1

(cid:90)

RNi

ˆy (t(cid:48)

i) =

Rd(cid:96)

(cid:104)

(cid:62)

(cid:123)(cid:122)

= E∗

zi (cid:126)bi fi

Φp (t(cid:48)
i)

(cid:124)

= Φp (t(cid:48)
i)

Λ (cid:126)xip

population prediction

(cid:125)

dfi d(cid:126)bi

E(cid:104)
(cid:124)

prediction given latent vars.
(cid:62)

i

P

(cid:16)

zi (cid:126)bi  fi | (cid:126)yi  Xi  Θ

(cid:123)(cid:122)
i | zi (cid:126)bi  fi  t(cid:48)
y(cid:48)

(cid:105)
(cid:17)
(cid:125)
(cid:123)(cid:122)
(cid:124)
(cid:125)
(cid:62) (cid:126)bi + fi (t(cid:48)
(cid:62) (cid:126)βzi + Φ(cid:96) (t(cid:48)
Λ (cid:126)xip + Φz (t(cid:48)
i)
i)
i)
(cid:122) (cid:125)(cid:124) (cid:123)
(cid:123)
(cid:125)(cid:124)
(cid:104)(cid:126)βzi
(cid:105)
(cid:104)(cid:126)bi
(cid:105)
(cid:126)b∗
i (Eq. 10)
(cid:125)
(cid:123)(cid:122)
(cid:125)
E∗
(cid:126)bi

(cid:126)β∗
i (Eq. 7)
E∗
zi

+ Φ(cid:96) (t(cid:48)
i)

posterior over latent vars.

(cid:122)
(cid:123)(cid:122)

(cid:124)

+

(cid:62)

+ Φz (t(cid:48)
i)

(cid:62)

subpopulation prediction

individual prediction

(cid:124)

(cid:105)
(cid:122)
(cid:124)

f∗
i (t(cid:48)
E∗
fi

i) (Eq. 12)
[fi (t(cid:48)
i)]

(cid:125)(cid:124)
(cid:123)(cid:122)

(cid:123)
(cid:125)

structured noise prediction

where E∗ denotes an expectation conditioned on (cid:126)yi  Xi  Θ. In moving from Eq. 4 to 5  we have
written the integral as an expectation and substituted the inner expectation with the mean of the
normal distribution in Eq. 1. From Eq. 5 to 6  we use linearity of expectation. Eqs. 7  10  and 12

5

Figure 2: Plots (a) and (c) show dynamic predictions using the proposed model for two individuals. Red
markers are unobserved. Blue shows the trajectory predicted using the most likely subtype  and green shows
the second most likely. Plot (b) shows dynamic predictions using the B-spline GP baseline. Plot (d) shows
predictions made using the proposed model without individual-speciﬁc adjustments.

below show how the expectations in Eq. 6 are computed. An expanded version of these steps are
provided in the supplement.
Computing the population prediction is straightforward as all quantities are observed. To compute
the subpopulation prediction  we need to compute the marginal posterior over zi  which we used in
the expectation step above (Eq. 3). The expected subtype coefﬁcients are therefore

(cid:44)(cid:16)(cid:80)G

(cid:126)β∗

i

zi=1 π∗

izi

(cid:126)βzi

(cid:17)

.

(7)

To compute the individual prediction  note that by conditioning on zi  the integral over the likelihood
with respect to fi and the prior over (cid:126)bi form the likelihood and prior of a Bayesian linear regression.
Let Kf = KOU((cid:126)ti  (cid:126)ti) + σ2I  then the posterior over (cid:126)bi conditioned on zi is:

(cid:16)(cid:126)bi | zi  (cid:126)yi  Xi  Θ

(cid:17) ∝ N(cid:16)(cid:126)bi | 0  Σb

(cid:17)N(cid:16)

P

(cid:0)(cid:126)ti

(cid:1) (cid:126)βzi + Φ(cid:96)

(cid:0)(cid:126)ti

(cid:1)(cid:126)bi  Kf

(cid:17)

.

(8)

(cid:126)yi | ΦpΛ (cid:126)xip + Φz

Just as in Eq. 2  we have integrated over fi moving its effect from the mean of the normal distribution
to the covariance. Because the prior over (cid:126)bi is conjugate to the likelihood on the right side of Eq. 8 
the posterior can be written in closed form as a normal distribution (see e.g. [10]). The mean of the
left side of Eq. 8 is therefore
Σ−1
b + Φ(cid:96)((cid:126)ti)(cid:62)K−1

(cid:16)
(cid:126)yi − Φp((cid:126)ti)Λ (cid:126)xip − Φz((cid:126)ti)(cid:126)βzi

Φ(cid:96)((cid:126)ti)(cid:62)K−1

(cid:105)−1(cid:104)

f Φ(cid:96)((cid:126)ti)

(cid:17)(cid:105)

(cid:104)

(9)

 

f

To compute the unconditional posterior mean of (cid:126)bi we take the expectation of Eq. 9 with respect to
the posterior over zi. Eq. 9 is linear in (cid:126)βzi  so we can directly replace (cid:126)βzi with its mean (Eq. 7):

(cid:126)b∗

i

Σ−1
b + Φ(cid:96)((cid:126)ti)(cid:62)K−1

f Φ(cid:96)((cid:126)ti)

Φ(cid:96)((cid:126)ti)(cid:62)K−1

f

(cid:126)yi − Φp((cid:126)ti)Λ (cid:126)xip − Φz((cid:126)ti)(cid:126)β∗

i

.

(10)

(cid:105)−1(cid:104)

(cid:16)

(cid:44)(cid:104)

Finally  to compute the structured noise prediction  note that conditioned on zi and (cid:126)bi  the GP prior
and marker likelihood (Eq. 1) form a standard GP regression (see e.g.
[20]). The conditional
posterior of fi(t(cid:48)
KOU(t(cid:48)

(cid:126)yi − Φp((cid:126)ti)Λ (cid:126)xip − Φz((cid:126)ti)(cid:126)βzi − Φ(cid:96)((cid:126)ti)(cid:126)bi

(cid:17)

(11)

.

To compute the unconditional posterior expectation of fi(t(cid:48)
linear in zi and (cid:126)bi and so their expectations can be plugged in to obtain

i)  we note that the expression above is

i) is therefore a GP with mean

i  (cid:126)ti)(cid:2)KOU((cid:126)ti  (cid:126)ti) + σ2I(cid:3)−1(cid:16)
i  (cid:126)ti)(cid:2)KOU((cid:126)ti  (cid:126)ti) + σ2I(cid:3)−1(cid:16)

f∗(t(cid:48)

i) (cid:44) KOU(t(cid:48)

(cid:126)yi − Φp((cid:126)ti)Λ (cid:126)xip − Φz((cid:126)ti)(cid:126)β∗

i − Φ(cid:96)((cid:126)ti)(cid:126)b∗

i

.

(12)

6

(cid:17)(cid:105)

(cid:17)

124●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●4060800.02.55.07.510.00.02.55.07.510.00.02.55.07.510.0124●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●204060801000.02.55.07.510.00.02.55.07.510.00.02.55.07.510.0124●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●4060800.02.55.07.510.00.02.55.07.510.00.02.55.07.510.0Pr()=Pr()=0.57 0.18Pr()=Pr()=0.71 0.21Pr()=Pr()=0.60 0.39124●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●204060801000.02.55.07.510.00.02.55.07.510.00.02.55.07.510.0Pr()=Pr()=0.53 0.26Pr()=Pr()=0.54 0.46Pr()=Pr()=0.99 0.01Pr()=Pr()=0.56 0.40Pr()=Pr()=0.54 0.46Years Since First Seen(a)(b)(c)(d)3 Experiments
We demonstrate our approach by building a tool to predict the lung disease trajectories of individ-
uals with scleroderma. Lung disease is currently the leading cause of death among scleroderma
patients  and is notoriously difﬁcult to treat because there are few predictors of decline and there is
tremendous variability across individual trajectories [21]. Clinicians track lung severity using per-
cent of predicted forced vital capacity (PFVC)  which is expected to drop as the disease progresses.
In addition  demographic variables and molecular test results are often available at baseline to aid
prognoses. We train and validate our model using data from the Johns Hopkins Scleroderma Center
patient registry  which is one of the largest in the world. To select individuals from the registry  we
used the following criteria. First  we include individuals who were seen at the clinic within two
years of their earliest scleroderma-related symptom. Second  we exclude all individuals with fewer
than two PFVC measurements after their ﬁrst visit. Finally  we exclude individuals who received a
lung transplant. The dataset contains 672 individuals and a total of 4  992 PFVC measurements.
For the population model  we use constant functions (i.e. observed covariates adjust an individual’s
intercept). The population covariates ((cid:126)xip) are gender  African American race  and indicators of
ACA and Scl-70 antibodies—two proteins believed to be connected to scleroderma-related lung
disease. Note that all features are binary. For the subpopulation B-splines  we set boundary knots
at 0 and 25 years (the maximum observation time in our data set is 23 years)  use two interior knots
that divide the time period from 0-25 years into three equally spaced chunks  and use quadratics
as the piecewise components. These B-spline hyperparameters (knots and polynomial degree) are
also used for all baseline models. We select G = 9 subtypes using BIC. The covariates in the
subtype marginal model ((cid:126)xiz) are the same used in the population model. For the individual model 
we use linear functions. For the hyper-parameters Θ1 = {Σb  α  (cid:96)  σ2} we set Σb to be a diagonal
covariance matrix with entries [16  10−2] along the diagonal  which correspond to intercept and
slope variances respectively. Finally  we set α = 6  (cid:96) = 2  and σ2 = 1 using domain knowledge;
we expect transient deviations to last around 2 years and to change PFVC by around ±6 units.
Baselines. First  to compare against typical approaches used in clinical medicine that condition on
baseline covariates only (e.g. [22])  we ﬁt a regression model conditioned on all covariates included
in (cid:126)xiz above. The mean is parameterized using B-spline bases (Φ(t)) as:

ˆy | (cid:126)xiz = Φ(t)(cid:62)(cid:16)(cid:126)β0 +(cid:80)

(cid:126)βi +(cid:80)

(cid:17)

xi in (cid:126)xiz

xi

xi xj in pairs of (cid:126)xiz

xixj

(cid:126)βij

.

(13)

The second baseline is similar to [8] and [23] and extends the ﬁrst baseline by accounting for
individual-speciﬁc heterogeneity. The model has a mean function identical to the ﬁrst baseline and
individualizes predictions using a GP with the same kernel as in Equation 2 (using hyper-parameters
as above). Another natural approach is to explain heterogeneity by using a mixture model similar to
[9]. However  a mixture model cannot adequately explain away individual-speciﬁc sources of vari-
ability that are unrelated to subtype and therefore fails to recover subtypes that capture canonical
trajectories (we discuss this in detail in the supplemental section). The recovered subtypes from the
full model do not suffer from this issue. To make the comparison fair and to understand the extent
to which the individual-speciﬁc component contributes towards personalizing predictions  we create
a mixture model (Proposed w/ no personalization) where the subtypes are ﬁxed to be the same as
those in the full model and the remaining parameters are learned. Note that this version does not
contain the individual-speciﬁc component.
Evaluation. We make predictions after one  two  and four years of follow-up. Errors are summa-
rized within four disjoint time periods: (1  2]  (2  4]  (4  8]  and (8  25] years2. To measure error 
we use the absolute difference between the prediction and a smoothed version of the individual’s
observed trajectory. We estimate mean absolute error (MAE) using 10-fold CV at the level of indi-
viduals (i.e. all of an individual’s data is held-out)  and test for statistically signiﬁcant reductions in
error using a one-sided  paired t-test. For all models  we use the MAP estimate of the individual’s
trajectory. In the models that include subtypes  this means that we choose the trajectory predicted by
the most likely subtype under the posterior. Although this discards information from the posterior 
in our experience clinicians ﬁnd this choice to be more interpretable.
Qualitative results. In Figure 2 we present dynamically updated predictions for two patients (one
per row  dynamic updates move left to right). Blue lines indicate the prediction under the most likely
subtype and green lines indicate the prediction under the second most likely. The ﬁrst individual

2After the eighth year  data becomes too sparse to further divide this time span.

7

Model
B-spline with Baseline Feats.
B-spline + GP
Proposed
Proposed w/ no personalization

B-spline with Baseline Feats.
B-spline + GP
Proposed
Proposed w/ no personalization

B-spline with Baseline Feats.
B-spline + GP
Proposed
Proposed w/ no personalization

Predictions using 1 year of data
(2  4] % Im.
12.73
7.70
∗7.04
7.12

(1  2] % Im.
12.78
5.49
5.26
6.17
Predictions using 2 years of data

8.6

12.73
5.88
∗5.48
6.00

6.8

Predictions using 4 years of data

(4  8] % Im.
12.40
9.67
10.17
9.38

(8  25] % Im.
12.14
10.71
12.12
12.85

12.40
8.65
∗7.95
8.12

12.40
6.00
∗5.14
5.75

8.1

14.3

12.14
10.02
9.53
11.39

12.14
8.88
∗7.58
9.16

14.3

Table 1: MAE of PFVC predictions for the two baselines and the proposed model. Bold numbers indicate best
performance across models (∗ is stat. signiﬁcant). “% Im.” reports percent improvement over next best.

(Figure 2a) is a 50-year-old  white woman with Scl-70 antibodies  which are thought to be associated
with active lung disease. Within the ﬁrst year  her disease seems stable  and the model predicts this
course with 57% conﬁdence. After another year of data  the model shifts 21% of its belief to a
rapidly declining trajectory; likely in part due to the sudden dip in year 2. We contrast this with the
behavior of the B-spline GP shown in Figure 2b  which has limited capacity to express individualized
long-term behavior. We see that the model does not adequately adjust in light of the downward trend
between years one and two. To illustrate the value of including individual-speciﬁc adjustments  we
now turn to Figures 2c and 2d (which plot predictions made by the proposed model with and without
personalization respectively). This individual is a 60-year-old  white man that is Scl-70 negative 
which makes declining lung function less likely. Both models use the same set of subtypes  but
whereas the model without individual-speciﬁc adjustment does not consider the recovering subtype
to be likely until after year two  the full model shifts the recovering subtype trajectory downward
towards the man’s initial PFVC value and identify the correct trajectory using a single year of data.
Quantitative results. Table 1 reports MAE for the baselines and the proposed model. We note that
after observing two or more years of data  our model’s errors are smaller than the two baselines (and
statistically signiﬁcantly so in all but one comparison). Although the B-spline GP improves over the
ﬁrst baseline  these results suggest that both subpopulation and individual-speciﬁc components en-
able more accurate predictions of an individual’s future course as more data are observed. Moreover 
by comparing the proposed model with and without personalization  we see that subtypes alone are
not sufﬁcient and that individual-speciﬁc adjustments are critical. These improvements also have
clinical signiﬁcance. For example  individuals who drop by more than 10 PFVC are candidates for
aggressive immunosuppressive therapy. Out of the 7.5% of individuals in our data who decline by
more than 10 PFVC  our model predicts such a decline at twice the true-positive rate of the B-spline
GP (31% vs. 17%) and with a lower false-positive rate (81% vs. 90%).
4 Conclusion
We have described a hierarchical model for making individualized predictions of disease activity
trajectories that accounts for both latent and observed sources of heterogeneity. We empirically
demonstrated that using all elements of the proposed hierarchy allows our model to dynamically
personalize predictions and reduce error as more data about an individual is collected. Although
our analysis focused on scleroderma  our approach is more broadly applicable to other complex 
heterogeneous diseases [1]. Examples of such diseases include asthma [3]  autism [4]  and COPD
[5]. There are several promising directions for further developing the ideas presented here. First  we
observed that predictions are less accurate early in the disease course when little data is available to
learn the individual-speciﬁc adjustments. To address this shortcoming  it may be possible to leverage
time-dependent covariates in addition to the baseline covariates used here. Second  the quality of our
predictions depends upon the allowed types of individual-speciﬁc adjustments encoded in the model.
More sophisticated models of individual variation may further improve performance. Moreover 
approaches for automatically learning the class of possible adjustments would make it possible to
apply our approach to new diseases more quickly.

8

References
[1] J. Craig. Complex diseases: Research and applications. Nature Education  1(1):184  2008.
[2] J. Varga  C.P. Denton  and F.M. Wigley. Scleroderma: From Pathogenesis to Comprehensive Manage-

ment. Springer Science & Business Media  2012.

[3] J. L¨otvall et al. Asthma endotypes: a new approach to classiﬁcation of disease entities within the asthma

syndrome. Journal of Allergy and Clinical Immunology  127(2):355–360  2011.

[4] L.D. Wiggins  D.L. Robins  L.B. Adamson  R. Bakeman  and C.C. Henrich. Support for a dimensional
view of autism spectrum disorders in toddlers. Journal of autism and developmental disorders  42(2):191–
200  2012.

[5] P.J. Castaldi et al. Cluster analysis in the copdgene study identiﬁes subtypes of smokers with distinct

patterns of airway disease and emphysema. Thorax  2014.

[6] S. Saria and A. Goldenberg. Subtyping: What Is It and Its Role in Precision Medicine. IEEE Intelligent

Systems  30  2015.

[7] D.S. Lee  P.C. Austin  J.L. Rouleau  P.P Liu  D. Naimark  and J.V. Tu. Predicting mortality among patients
hospitalized for heart failure: derivation and validation of a clinical model. Jama  290(19):2581–2587 
2003.

[8] D. Rizopoulos. Dynamic predictions and prospective accuracy in joint models for longitudinal and time-

to-event data. Biometrics  67(3):819–829  2011.

[9] C. Proust-Lima et al. Joint latent class models for longitudinal and time-to-event data: A review. Statisti-

cal Methods in Medical Research  23(1):74–90  2014.

[10] K.P. Murphy. Machine learning: a probabilistic perspective. MIT press  2012.
[11] S. Roberts  M. Osborne  M. Ebden  S. Reece  N. Gibson  and S. Aigrain. Gaussian processes for time-
series modelling. Philosophical Transactions of the Royal Society A: Mathematical  Physical and Engi-
neering Sciences  371(1984):20110550  2013.

[12] J.Q. Shi  R. Murray-Smith  and D.M. Titterington. Hierarchical gaussian process mixtures for regression.

Statistics and computing  15(1):31–41  2005.

[13] A. Gelman and J. Hill. Data analysis using regression and multilevel/hierarchical models. Cambridge

University Press  2006.

[14] H. Wang et al. High-order multi-task feature learning to identify longitudinal phenotypic markers for
alzheimer’s disease progression prediction. In Advances in Neural Information Processing Systems  pages
1277–1285  2012.

[15] J. Ross and J. Dy. Nonparametric mixture of gaussian processes with constraints. In Proceedings of the

30th International Conference on Machine Learning (ICML-13)  pages 1346–1354  2013.

[16] P.F. Schulam  F.M. Wigley  and S. Saria. Clustering longitudinal clinical marker trajectories from elec-
tronic health data: Applications to phenotyping and endotype discovery. In Proceedings of the Twinty-
Ninth AAAI Conference on Artiﬁcial Intelligence  2015.

[17] B.M. Marlin. Modeling user rating proﬁles for collaborative ﬁltering. In Advances in neural information

processing systems  2003.

[18] G. Adomavicius and A. Tuzhilin. Toward the next generation of recommender systems: A survey of
the state-of-the-art and possible extensions. Knowledge and Data Engineering  IEEE Transactions on 
17(6):734–749  2005.

[19] D. Sontag  K. Collins-Thompson  P.N. Bennett  R.W. White  S. Dumais  and B. Billerbeck. Probabilistic
models for personalizing web search. In Proceedings of the ﬁfth ACM international conference on Web
search and data mining  pages 433–442. ACM  2012.

[20] C.E. Rasmussen and C.K. Williams. Gaussian Processes for Machine Learning. The MIT Press  2006.
[21] Y. Allanore et al. Systemic sclerosis. Nature Reviews Disease Primers  2015.
[22] D. Khanna et al. Clinical course of lung physiology in patients with scleroderma and interstitial lung
disease: analysis of the scleroderma lung study placebo group. Arthritis & Rheumatism  63(10):3078–
3085  2011.

[23] J.Q. Shi  B. Wang  E.J. Will  and R.M. West. Mixed-effects gaussian process functional regression models

with application to dose–response curve prediction. Stat. Med.  31(26):3165–3177  2012.

9

,Peter Schulam
Suchi Saria
Jay Heo
Hae Beom Lee
Saehoon Kim
Juho Lee
Kwang Joon Kim
Eunho Yang
Sung Ju Hwang