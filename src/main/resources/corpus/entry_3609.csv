2017,Multi-view Matrix Factorization for Linear Dynamical System Estimation,We consider maximum likelihood estimation of linear dynamical systems with generalized-linear observation models. Maximum likelihood is typically considered to be hard in this setting since latent states and transition parameters must be inferred jointly. Given that expectation-maximization does not scale and is prone to local minima  moment-matching approaches from the subspace identification literature have become standard  despite known statistical efficiency issues. In this paper  we instead reconsider likelihood maximization and develop an optimization based strategy for recovering the latent states and transition parameters. Key to the approach is a two-view reformulation of maximum likelihood estimation for linear dynamical systems that enables the use of global optimization algorithms for matrix factorization. We show that the proposed estimation strategy outperforms widely-used identification algorithms such as subspace identification methods  both in terms of accuracy and runtime.,Multi-view Matrix Factorization for Linear

Dynamical System Estimation

Mahdi Karami  Martha White  Dale Schuurmans  Csaba Szepesvári

{karami1  whitem  daes  szepesva}@ualberta.ca

Department of Computer Science

University of Alberta
Edmonton  AB  Canada

Abstract

We consider maximum likelihood estimation of linear dynamical systems with
generalized-linear observation models. Maximum likelihood is typically considered
to be hard in this setting since latent states and transition parameters must be
inferred jointly. Given that expectation-maximization does not scale and is prone
to local minima  moment-matching approaches from the subspace identiﬁcation
literature have become standard  despite known statistical efﬁciency issues. In this
paper  we instead reconsider likelihood maximization and develop an optimization
based strategy for recovering the latent states and transition parameters. Key to
the approach is a two-view reformulation of maximum likelihood estimation for
linear dynamical systems that enables the use of global optimization algorithms for
matrix factorization. We show that the proposed estimation strategy outperforms
widely-used identiﬁcation algorithms such as subspace identiﬁcation methods  both
in terms of accuracy and runtime.

1

Introduction

Linear dynamical systems (LDS) provide a fundamental model for estimation and forecasting in
discrete-time multi-variate time series. In an LDS  each observation is associated with a latent state;
these unobserved states evolve as a Gauss-Markov process where each state is a linear function of the
previous state plus noise. Such a model of a partially observed dynamical system has been widely
adopted  particularly due to its efﬁciency for prediction of future observations using Kalman ﬁltering.
Estimating the parameters of an LDS—sometimes referred to as system identiﬁcation—is a difﬁcult
problem  particularly if the goal is to obtain the maximum likelihood estimate of parameters. Con-
sequently  spectral methods from the subspace identiﬁcation literature  based on moment-matching
rather than maximum likelihood  have become popular. These methods provide closed form solutions 
often involving a singular value decomposition of a matrix constructed from the empirical moments
of observations (Moonen and Ramos  1993; Van Overschee and De Moor  1994; Viberg  1995;
Katayama  2006; Song et al.  2010; Boots and Gordon  2012). The most widely used such algorithms
for parameter estimation in LDSs are the family of N4SID algorithms (Van Overschee and De Moor 
1994)  which are computationally efﬁcient and asymptotically consistent (Andersson  2009; Hsu
et al.  2012). Recent evidence  however  suggests that these moment-matching approaches may suffer
from weak statistical efﬁciency  performing particularly poorly with small sample sizes (Foster et al. 
2012; Zhao and Poupart  2014).
Maximum likelihood for LDS estimation  on the other hand  has several advantages. For example  it
is asymptotically efﬁcient under general conditions (Cramér  1946  Ch.33)  and this property often
translates to near-minimax ﬁnite-sample performance. Further  maximum likelihood is amenable
to coping with missing data. Another beneﬁt is that  since the likelihood for exponential families

31st Conference on Neural Information Processing Systems (NIPS 2017)  Long Beach  CA  USA.

and corresponding convex losses (Bregman divergences) are well understood (Banerjee et al.  2005) 
maximum likelihood approaches can generalize to a broad range of distributions over the observations.
Similarly  other common machine learning techniques  such as regularization  can be naturally
incorporated in a maximum likelihood framework  interpretable as maximum a posteriori estimation.
Unfortunately  unlike spectral methods  there is no known efﬁcient algorithm for recovering pa-
rameters that maximize the marginal likelihood of observed data in an LDS. Standard iterative
approaches are based on EM (Ghahramani and Hinton  1996; Roweis and Ghahramani  1999)  which
are computationally expensive and have been observed to produce locally optimal solutions that yield
poor results (Katayama  2006). A classical system identiﬁcation method  called the prediction error
method (PEM)  is based on minimization of prediction error and can be interpreted as maximum
likelihood estimation under certain distributional assumptions (e.g.  Ch. 7.4 of Ljung 1999  Åström
1980). PEM  however  is prone to local minima and requires selection of a canonical parameterization 
which can be difﬁcult in practice and can result in ill-conditioned problems (Katayama  2006).
In this paper  we propose an alternative approach to LDS parameter estimation under exponential
family observation noise. In particular  we reformulate the LDS as a two-view generative model 
which allows us to approximate the estimation task as a form of matrix factorization  and apply recent
global optimization techniques for such models (Zhang et al.  2012; Yu et al.  2014). To extend these
previous algorithms to this setting  we provide a novel proximal update for the two-view approach
that signiﬁcantly simpliﬁes the algorithm. Finally  for forecasting on synthetic and real data  we
demonstrate that the proposed algorithm matches or outperforms N4SID  while scaling better with
increasing sample size and data dimension.

2 Linear dynamical systems

We address discrete-time  time-invariant linear dynamical systems  speciﬁed as

t+1 = At + ⌘t
xt = Ct + ✏t

(1)

where t 2 Rk is the hidden state at time t; xt 2 Rd is the observation vector at time t; A 2 Rk⇥k is
the dynamics matrix; C 2 Rd⇥k is the observation matrix; ⌘ is the state evolution noise; and ✏ is the
observation noise. The noise terms are assumed to be independent. As is common  we assume that the
state evolution noise is Gaussian: ⌘ ⇠ N (0  ⌃⌘). We additionally allow for general observation noise
to be generated from an exponential family distribution (e.g.  Poisson). The graphical representation
for this LDS is shown in Figure 1.
An LDS encodes the intuition that a latent state is driving the dynamics  which can signiﬁcantly
simplify estimation and forecasting. The observations typically contain only partial information
about the environment (such as in the form of limited sensors)  and further may contain noisy or
even irrelevant observations. Learning transition models for such observations can be complex 
particularly if the observations are high-dimensional. For example  in spatiotemporal processes  the
data is typically extremely high-dimensional  composed of structured grid data; however  it is possible
to extract a low-rank state-space that signiﬁcantly simpliﬁes analysis (Gelfand et al.  2010  Chapter
8). Further  for forecasting  iterating transitions for such a low-rank state-space can provide longer
range predictions with less error accumulation than iterating with the observations themselves.
The estimation problem for an LDS involves extracting the unknown parameters  given a time series
of observations x1  . . .   xT . Unfortunately  jointly estimating the parameters A  C and t is difﬁcult
because the multiplication of these variables typically results in a nonconvex optimization. Given the
latent states t  estimation of A and C is more straightforward  though there are still some issues
with maintaining stability (Siddiqi et al.  2007). There are some recent advances improving estimation
in time series models using matrix factorization. White et al. (2015) provide a convex formulation for
auto-regressive moving average models—although related to state-space models  these do not permit
a straightforward conversion between the parameters of one to the other. Yu et al. (2015) factorize the
observation into a hidden state and dictionary  using a temporal regularizer on the extracted hidden
state—the resulting algorithm  however  is not guaranteed to provide an optimal solution.

2

2

3

1

C

A

E

x1

x2

x3

. . .

. . .

Figure 1: Graphical representation for the standard
LDS formulation and the corresponding two-view
model. The two-view formulation is obtained by a lin-
ear transformation of the LDS model. The LDS model
includes only parameters C and A and the two-view
model includes parameters C and E = CA  where A
can be extracted from E after C and E are estimated.

3 Two-view Formulation of LDS

In this section  we reformulate the LDS as a generative two-view model with a shared latent factor. In
the following section  we demonstrate how to estimate the parameters of this reformulation optimally 
from which parameter estimates of the original LDS can be recovered.
To obtain a two-view formulation  we re-express the two equations for the LDS as two equations for
pairs of sequential observations. To do so  we multiply the state evolution equation in (1) by C and
add ✏t+1 to obtain Ct+1 + ✏t+1 = CAt + C⌘t + ✏t+1; representing the LDS model as

xt+1 = Et + ✏0t+1

xt = Ct + ✏t

(2)

where we refer to E := CA as the factor loading matrix and ✏0t+1 := C⌘t + ✏t+1 as the noise of
the second view. We then have a two-view problem where we need to estimate parameters E and C.
Since the noise components ✏t and ✏0t are independent  the two views xt and xt+1 are conditionally
independent given the shared latent state t. The maximum log likelihood problem for the two-view
formulation then becomes

max
C E 

log p(x1  . . .   xT|0  1  . . .   T   C  E) = max

C E 

log p(xt|t1  t  C  E)

(3)

where  given the hidden states  the observations are conditionally independent. The log-likelihood (3)
is equivalent to the original LDS  but is expressed in terms of the distribution p(xt|t1  t  C  E) 
where the probability of an observation increases if it has high probability under both t1 and t.
The graphical depiction of the LDS and its implied two-view model is illustrated in Figure 1.

TXt=1

3.1 Relaxation
To tackle the estimation problem  we reformulate the estimation problem for this equivalent two-view
model of the LDS. Note that according to the two-view model (2)  the conditional distribution (3) can
be expressed as p(xt|t1  t  C  E) = p(xt|Et1) = p(xt|Ct). Substituting each of these in
the summation (3) would result in a factor loading model that ignores the temporal correlation among
data; therefore  to take the system dynamics into account we choose a balanced averaging of both
as log p(xt|t1  t  C  E) = 1
2 log p(xt|Ct)  where the likelihood of an
observation increases if it has high conditional likelihood given both t1 and t.1 With this choice
and the exponential family speciﬁed by the log-normalizer (also called potential function) F : Rd !
R  with the corresponding Bregman divergence deﬁned as DF (ˆzkz) := F (ˆz) F (z) f (z)>(ˆz z)
using transfer function f = rF  2 the log-likelihood separates into the two components

2 log p(xt|Et1) + 1

argmax
C E 

TXt=1

log p(xt|t1  t  C  E) = argmax

C E 

log p(xt|Et1) + log p(xt|Ct)

= argmin
C E 

DF (Et1||f 1(xt)) + DF (Ct||f 1(xt))

1The balanced averaging can be generalized to a convex combination of the log-likelihood which adds a
ﬂexibility to the problem that can be tuned to improve performance. However  we found that the simple balanced
combination renders the best experimental performance in most cases.

2 Consult Banerjee et al. (2005) for a complete overview of this correspondence.

1
2

TXt=1
TXt=1

3

2kzk2

Each Bregman divergence term can be interpreted as the ﬁtness measure for each view. For example 
a Gaussian distribution can be expressed by an exponential family deﬁned by F (z) = 1
2. The
above derivation could be extended to different variance terms for ✏ and ✏0  which would result in
different weights on the two Bregman divergences above. Further  we could also allow different
exponential families (hence different Bregman divergences) for the two distributions; however  there
is no clear reason why this would be beneﬁcial over simply selecting the same exponential family 
since both describe xt. In this work  therefore  we will explore a balanced loss  with the same
exponential family for each view.
In order to obtain a low rank solution  one can relax the hard rank constraint and employ the block
j=1 kj:k2 as the rank-reducing regularizer on the latent state.3 This regularizer
offers an adaptive rank reducing scheme that zeros out many of the rows of the latent states and
hence results a low rank solution without knowing the rank a priori. For the reconstruction models
C and E  we need to specify a prior that respects the conditional independence of the views xt and
xt+1 given t. This goal can be achieved if C and E are constrained individually so that they do not
compete against each other to reconstruct their respective views (White et al.  2012). Incorporating
the regularizer and constraints  the resulting optimization problem has the form

norm kk2 1 =Pk

TXt=1

argmin
C E 

L1(Et1; xt) + L2(Ct; xt) + 

s.t.kC:jk2  1 kE:jk2  2 8j 2 (1  k).

kXj=1

kj:k2

(4)

The above constrained optimization problem is convex in each of the factor loading matrices {C  E}
and the state matrix   but not jointly convex in terms of all these variables. Nevertheless  the
following lemma show that (4) admits a convex reformulation by change of variable.

ˆZ(2) and
Lemma 1 Let ˆZ(1) := C and ˆZ(2) := E with their concatenated matrix ˆZ := ˆZ(1)
0)  I(2) := diag(0
Z(1) := [x1:T1]  Z(2) := [x2:T ]. In addition  let’s deﬁne I(1) := diag(1
1) 
L1(C; Z(1)) + L2(E; Z(2)) + kk2 1

then the multi-view optimization problem (4) can be reformulated in the following convex form

min

min

kC:jk21
kE:jk22

:"C

E#= ˆZ

= min

ˆZ

L1(ˆZ(1); Z(1)) + L2(ˆZ(2); Z(2)) +  max

0⌘1kU1

⌘

ˆZktr

⌘

t=1 Li(yt; ˆyt). Moreover  we can show that

ˆZktr is concave in ⌘. The trace norm induces a low rank result.

where U⌘ = 1p⌘ I(1) + 2p1⌘ I(2) and Li(Y; ˆY) =PT
the regularizer term kU1
Proof: The proof can be readily derived from the results of White et al. (2012).
In the next section  we demonstrate how to obtain globally optimal estimates of E  C and .
Remark 1: This maximum likelihood formulation demonstrates how the distributional assumptions
on the observations xt can be generalized to any exponential family. Once expressed as the above
optimization problem  one can further consider other losses and regularizers that may not immediately
have a distributional interpretation  but result in improved prediction performance. This generalized
formulation of maximum likelihood for LDS  therefore  has the additional beneﬁt that it can ﬂexibly
incorporate optimization improvements  such as robust losses.4 Also a regularizer can be designed to
control overﬁtting to noisy observation  which is an issue in LDS that can result in an unstable latent
dynamics estimate (Buesing et al.  2012a). Therefore  by controlling undesired overﬁtting to noisy
samples one can also prevent unintended unstable model identiﬁcation.

⌅

3 Throughout this paper  Xi: (X:i) is used to denote the ith row (ith column) of matrix X and also [X; Y]

([x; y]) denotes the matrix (vector) concatenation operator which is equal to [X>  Y>]> ([x>  y>]>).

4Thus  we used L1 and L2 in (4) to generally refer to any loss function that is convex in its ﬁrst argument.

4

Remark 2: We can generalize the optimization further to learn an LDS with exogenous input: a
control vector ut 2 Rd that impacts both the hidden state and observations. This entails adding some
new variables to the general LDS model that can be expressed as

t+1 = At + But + ⌘t
xt = Ct + Dut + ✏t

with additional matrices B 2 Rk⇥d and D 2 Rd⇥d. Again by multiplying the state evolution
equation by matrix C the resulting equations are

xt+1 = Et + Fut + Dut+1 + ✏0t+1

xt = Ct + Dut + ✏t

where F := CB. Therefore  the loss can be generally expressed as

L1(Et1 + Fut1 + Dut; xt) + L2(Ct + Dut; xt).

The optimization would now be over the variables C  E    D  F  where the optimization could
additionally include regularizers on D and F to control overﬁtting. Importantly  the addition of these
variables D  F does not modify the convexity properties of the loss  and the treatment for estimating
E  C and  in section 4 directly applies. The optimization problem is jointly convex in D  F and
any one of E  C or  and jointly convex in D and F. Therefore  an outer minimization over D and
F can be added to Algorithm 1 and we will still obtain a globally optimal solution.

4 LDS Estimation Algorithm

To learn the optimal parameters for the reformulated two-view model  we adopt the generalized con-
ditional gradient (GCG) algorithm developed by Yu et al. (2014). GCG is designed for optimization
problems of the form l(x) + f (x) where l(x) is convex and continuously differentiable with Lipschitz
continuous gradient and f (x) is a (possibly non-differentiable) convex function. The algorithm is
computationally efﬁcient  as well providing a reasonably fast O(1/t) rate of convergence to the global
minimizer. Though we have a nonconvex optimization problem  we can use the convex reformulation
for two-view low-rank matrix factorization and resulting algorithm in (Yu et al.  2014  Section
4). This algorithm includes a generic local improvement step  which signiﬁcantly accelerates the
convergence of the algorithm to a global optimum in practice. We provide a novel local improvement
update  which both speeds learning and enforces a sparser structure on   while maintaining the
same theoretical convergence properties of GCG.
In our experiments  we speciﬁcally address the setting when the observations are assumed to be
Gaussian  giving an `2 loss. We also prefer the unconstrained objective function that can be efﬁciently
minimized by fast unconstrained optimization algorithms. Therefore  using the well-established
equivalent form of the regularizer (Bach et al.  2008)  the objective (4) can be equivalently cast for
the Gaussian distributed time series xt as

kEt1  xtk2

2 + kCt  xtk2

2 + 

kj:k2 max( 1

1kC:jk2  1

2kE:jk2).

(5)

kXj=1

min
C E 

TXt=1

This product form of the regularizer is also preferred over the square form used in (Yu et al.  2014) 
F admits efﬁcient optimizers
since it induces row-wise sparsity on . Though the square form kk2
due to its smoothness  it does not prefer to zero out rows of  while with the regularizer of the form
(5)  the learned hidden state will be appropriately projected down to a lower-dimensional space where
many dimensions could be dropped from   C and E giving a low rank solution. In practice  we
found that enforcing this sparsity property on  signiﬁcantly improved stability.5 Consequently  we
need optimization routines that are appropriate for the non smooth regularizer terms.
The local improvement step involves alternating block coordinate descent between C  E and   with
an accelerated proximal gradient algorithm (FISTA) (Beck and Teboulle  2009) for each descent step.
To use the FISTA algorithm we need to provide a proximal operator for the non-smooth regularizer
in (5).

5This was likely due to a reduction in the size of the transition parameters  resulting in improved re-estimation

of A and a corresponding reduction in error accumulation when using the model for forecasting.

5

Algorithm 1 LDS-DV

Input: training sequence {xt  t 2 [1  T ]}
Output: C  A  t  ⌃⌘  ⌃✏
Initialize C0  E0  0
U1 [C>0 ; E>0 ]>  V1 >0
for i = 1  . . . do

`((1  ⌘)UiV>i + ✓uiv>i ) + ((1  ⌘)⇢i + ✓) // partially corrective up-

date (PCU)

(ui  vi) arg minuv>2A⌦r`(Ui  Vi)  uv>↵ // compute polar
(⌘i  ✓i) arg min
Uinit [p1  ⌘iUi p✓iui]  Vinit [p1  ⌘iVi p✓ivi]
(Ui+1  Vi+1) FISTA(UinitVinit)
⇢i = 1

0⌘1 ✓0

2v + k(Vi+1):ik2
2)

2Pi+1
j=1(k(Ui+1):ik2
end for
(C; E) Ui+1   V>i+1
A 2:T ⇤ †1:T1
estimate ⌃⌘  ⌃✏ by sample covariances

Let the proximal operator of a convex and possibly non-differentiable function f (y) be deﬁned as

proxf (x) = arg min
y

f (y) + 1

2kx  yk2
2.

FISTA is an accelerated version of ISTA (Iterative Shrinkage-Thresholding Algorithm) that it-
eratively performs a gradient descent update with the smooth component of the objective  and
then applies the proximal operator as a projection step. Each iteration updates the variable x as

the proximal operator  as is the case for our non-differentiable regularizer  a common strategy is to
numerically calculate the proximal update. This approach  however  can be prohibitively expensive 
and an analytic (closed) form is clearly preferable. We derive such a closed form for (5) in Theorem 1.

xk+1 = proxkfxk  krl(xk)  which converges to a ﬁxed point. If there is no known form for
v2i composed of two subvectors v1  v2  deﬁne f (v) = kvk2v :=
Theorem 1 For a vector v =hv1
 max(kv1k2 kv2k2). The proximal operator for this function is
"v1 max{1  ↵
kv1k
v2 max{1  ↵
kv2k
"v1 max{1  
kv1k
v2 max{1  
kv2k

  0}# if kv1k  kv2k
  0}# if kv2k  kv1k

  0}

  0}

proxf (v) =

where ↵ := max{.5(kv1k  kv2k + )  0} and  := max{.5(kv2k  kv1k + )  0}.
⌅
Proof: See Appendix A.
This result can be further generalized to enable additional regularization components on C and E 
such as including an `1 norm on each column to further enforce sparsity (such as in the elastic net).
There is no closed form for the proximal operator of the sum of two functions in general. We prove 
however  that for special case of a linear combination of the two-view norm with any norms on the
columns of C and E  the proximal mapping reduces to a simple composition rule.

8>>>><>>>>:

Theorem 2 For norms R1(v1) and R2(v2)  the proximal operator of the linear combination
Rc(v) = kvk2v + ⌫1R1(v1) + ⌫2R2(v2) for ⌫1  ⌫2  0 admits the simple composition
proxRc(v) = proxk.k2v✓prox⌫1R1(v1)
prox⌫2R2(v2)◆ .

Proof: See Appendix A.

⌅

4.1 Recovery of the LDS model parameters
The above reformulation provides a tractable learning approach to obtain the optimal parameters for
the two-view reformulation of LDS; given this optimal solution  we can then estimate the parameters

6

to the original LDS. The ﬁrst step is to estimate the transition matrix A. A natural approach is to
use (2)  and set ˆA = ˆC† ˆE for pseudoinverse ˆC†. This ˆA  however  might be sensitive to inaccurate
estimation of the (effective) hidden state dimension k. We found in practice that modiﬁcations from
the optimal choice of k might result in unstable solutions and produce unreliable forecasts. Instead 
a more stable ˆA can be learned from the hidden states themselves. This approach also focuses
estimation of A on the forecasting task  which is our ultimate aim.
Given the sequence of hidden states  1  . . .   T   there are several strategies that could be used to
estimate A  including simple autoregressive models to more sophisticated strategies (Siddiqi et al. 
2 which

2007). We opt for a simple linear regression solution ˆA = arg minAPT1
we found produced stable ˆA.
To estimate the noise parameters ⌃⌘  ⌃✏  recall ⌘t = t+1  ˆAt  ✏t = xt  Ct. Having obtained
ˆA  therefore  we can estimate the noise covariance matrices by computing their sample covariances
as ˆ⌃⌘ = 1
t=1 ✏t✏>t . The ﬁnal LDS learning procedure is outlined in
Algorithm 1. For more details about polar computation and partially corrective subroutine see (Yu
et al.  2014  Section 4).

t=1 kt+1  Atk2

T1PT

t=1 ⌘t⌘>t   ˆ⌃✏ = 1

T1PT

5 Experimental results

t=1 yt.

We evaluate the proposed algorithm by comparing one step prediction performance and computation
speed with alternative methods for real and synthetic time series. We report the normalized mean

TtestPTtest

square error (NMSE) deﬁned as NMSE = PTtest
t=1 kytˆytk2
t=1 kytµyk2 where µy = 1
PTtest
Algorithms: We compared the proposed algorithm to a well-established method-of moment-based
algorithm  N4SID (Van Overschee and De Moor  1994)  Hilbert space embeddings of hidden Markov
models (HSE-HMM) (Song et al.  2010)  expectation-maximization for estimating the parameters of
a Kalman ﬁlter (EM) (Roweis and Ghahramani  1999) and PEM (Ljung  1999). These are standard
baseline algorithms that are used regularly for LDS identiﬁcation. The estimated parameters by
N4SID were used as the initialization point for EM and PEM algorithms in our experiments. We used
the built-in functions  n4sid and pem  in Matlab  with the order selected by the function  for the
subspace identiﬁcation method and PEM  respectively. For our algorithm  we select the regularization
parameter  using cross-validation. For the time series  the training data is split by performing the
learning on ﬁrst 80% of the training data and evaluating the prediction performance on the remaining
20%.
Real datasets: For experiments on real datasets we select the climate time series from IRI data
library that recorded the surface temperature on the monthly basis for tropical Atlantic ocean (ATL)
and tropical Paciﬁc ocean (CAC). In CAC we selected ﬁrst 30 ⇥ 30 grids out of the total 84 ⇥ 30
locations with 399 monthly samples  while in ATL the ﬁrst 9 ⇥ 9 grids out of the total 38 ⇥ 25
locations are selected each with timeseries of length 564. We partitioned each area to smaller areas
of size 3 ⇥ 3 and arrange them to vectors of size 9  then seasonality component of the time series are
removed and data is centered to have zero mean. We ran two experiments for each dataset. For the
ﬁrst  the whole sequence is sliced into 70% training and 30% test. For the second  a short training set
of 70 samples is selected  with a test sequence of size 50.
Synthetic datasets: In the synthetic experiments  the datasets are generated by an LDS model (1) of
different system orders  k  and observation sizes  d. For each test case  100 data sequences of length
200 samples are generated and sliced to 70%  30% ratios for training set and test set  respectively. The
dynamics matrix A is selected to produce a stable system: {|i(A)| = s : s  1  8i 2 (1  k)} where
i(A) is the ith eigen value of matrix A. The noise components are drawn from Gaussian distributions
and scaled so that p⌘ := E{⌘>⌘}/m and p✏ := E{✏>✏}/n. Each test is repeated with the following
settings: {S1: s = 0.970  p⌘ = 0.50 and p✏ = 0.1}  {S2: s = 0.999  p⌘ = 0.01 and p✏ = 0.1}.
Results: The NMSE and run-time results obtained on real and synthetic datasets are shown in Table
1 and Table 2  respectively. In terms of NMSE  LDS-DV outperforms and matches the alternative
methods. In terms of algorithm speed  the LDS-DV learns the model much faster than the competitors
and scales well to larger dimension models. The speed improvement is more signiﬁcant for larger
datasets and observations with higher dimensions.

7

ATL(Long)

LDS-MV
N4SID
EM
HSE-HMM 675.87±629.46
PEM-SSID

NMSE
0.45±0.03
0.52±0.04
0.64±0.04
0.71±0.08

Time
0.26
2.34
7.87
0.79
20.00

Table 1: Real time series

ATL(Short)
NMSE
0.54±0.05
0.59±0.05
0.88±0.07
0.97±0.01
1.52±0.66

Time
0.22
0.95
3.92
0.16
16.38

CAC(Long)
NMSE
0.58±0.02
0.61±0.02
0.81±0.02
11.24±8.23
1.38±0.15

Time
0.28
1.23
5.70
0.39
19.67

CAC(Short)
NMSE
0.63±0.03
0.84±0.07
1.02±0.08
2.82±1.60
2.68±0.78

Time
0.14
1.08
4.12
0.17
20.58

Table 2: Synthetic time series

(S2) d=8   k=6

(S1) d=16   k=9

Time
0.49
0.81
4.99

(S1) d=5   k=3
(S2) d=16   k=9
NMSE
Time NMSE Time NMSE
Time NMSE Time
0.12±0.01
0.66 0.04±0.00 0.52 0.07±0.00 1.01 0.03±0.00 1.72
LDS-MV
0.12±0.01
N4SID
1.45 0.39±0.04 1.38 0.10±0.00 4.29 0.42±0.04 4.40
EM
6.01 0.04±0.00 5.03 0.13±0.00 19.21 0.03±0.00 19.83
0.18±0.01
HSE-HMM 2.4e+4±1.7e+4 0.48 2.2e+7±2.2e+7 0.50 7.8e+03±7.7e+03 0.49 0.65±0.02 0.55 22.92±21.83 0.53 0.71±0.01 0.61
PEM-SSID 0.14±0.01
15.22 0.08±0.01 13.97 0.09±0.01 38.39 0.06±0.02 41.10
Results for real and synthetic datasets are listed in Table 1 and Table 2  respectively. The ﬁrst column of each
dataset is the average normalized MSE with standard error and the second column is the algorithm runtime in
CPU seconds. The best NMSE according to pairwise t-test with signiﬁcance level of 5% is highlighted.

(S1) d=8   k=6
NMSE
0.08±0.00
0.11±0.00
0.14±0.01
0.12±0.01

(S2) d=5   k=3
NMSE
0.17±0.02
0.42±0.04
0.15±0.02
0.25±0.03

Time
0.36
0.76
4.62

10.72

9.08

LDS-DV
N4SID
EM

E
S
M
N

1.2

1

0.8

0.6

100

200

300

400

500

600

12

10

8

6

4

2

s
d
n
o
c
e
S

0
100

LDS-DV
N4SID
EM
HSE-HMM

 

-

V
M
S
D
L
 
f
o
E
S
M
n
o
i
t
c
i
d
e
r
P

 

3.5

3

2.5

2

1.5

1

0.5

200

300

400

500

600

0.5

1

1.5

2

2.5

3

3.5

Training Sequence Length (T)

Training Sequence Length(T)

(a) NMSE

(b) Runtime

Prediction MSE of n4SID

(c) Scatter plot of MSE

Figure 2: a) NMSE of the LDS-DV for increasing length of training sequence. The difference between LDS-DV
and N4SID is more signiﬁcant in shorter training length  while both converge to the same accuracy in large
T . HSE-HMM is omitted due to its high error. b) Runtime in CPU seconds for increasing length of training
sequence. LDS-DV scales well with large sample length. c) MSE of the LDS-DV versus MSE of N4SID. In
higher values of MSE  the points are below identity function line and LDS-DV is more likely to win.

For test cases with |i(A)| ' 1  designed to evaluate the prediction performance of the methods for
marginally stable systems  LDS-DV still can learn a stable model while the other algorithms might
not learn a stable model. The proposed LDS-DV method does not explicitly impose stability  but the
regularization favors A that is stable. The regularizer on latent state encourages smooth dynamics
and controls overﬁtting: overﬁtting to noisy observations can lead to unstable estimate of the model
(Buesing et al.  2012a)  and a smooth latent trajectory is a favorable property in most real-world
applications.
Figure 2(c) shows the MSE of LDS-DV versus N4SID  for all the CAC time-series. This ﬁgure
illustrates that for easier problems  LDS-DV and N4SID are more comparable. However  as the
difﬁculty increase  and MSE increases  LDS-DV begins to consistently outperform N4SID.
Figures 2(a) and 2(b) illustrate the accuracy and runtime respectively of the algorithms versus training
length. We used the synthetic LDS model under condition S1 with n = 8  m = 6. Values are
averaged over 20 runs with a test length of 50 samples. LDS-DV has better early performance  for
smaller sample sizes. At larger sample sizes  they reach approximately the same error level.

6 Conclusion

In this paper  we provided an algorithm for optimal estimation of the parameters for a time-invariant 
discrete-time linear dynamical system. More precisely  we provided a reformulation of the model as a
two-view objective  which allowed recent advances for optimal estimation for two-view models to be
applied. The resulting algorithm is simple to use and ﬂexibly allows different losses and regularizers

8

to be incorporated. Despite this simplicity  signiﬁcant improvements were observed over a widely
accepted method for subspace identiﬁcation (N4SID)  both in terms of accuracy for forecasting and
runtime.
The focus in this work was on forecasting  therefore on optimal estimation of the hidden states and
transition matrices; however  in some settings  estimation of noise parameters for LDS models is
also desired. An unresolved issue is joint optimal estimation of these noise parameters. Though
we do explicitly estimate the noise parameters  we do so only from the residuals after obtaining the
optimal hidden states and transition and observation matrices. Moreover  consistency of the learned
parameters by the proposed procedure of this paper is still an open problem and will be an interesting
future work.
The proposed optimization approach for LDSs should be useful for applications where alternative
noise assumptions are desired. A Laplace assumption on the observations  for example  provides a
more robust `1 loss. A Poisson distribution has been advocated for count data  such as for neural
activity  where the time series is a vector of small integers (Buesing et al.  2012b). The proposed
formulation of estimation for LDSs easily enables extension to such distributions. An important next
step is to investigate the applicability to a wider range of time series data.

Acknowledgments
This work was supported in part by the Alberta Machine Intelligence Institute and NSERC. During
this work  M. White was with the Department of Computer Science  Indiana University.

References
Andersson  S. (2009). Subspace estimation and prediction methods for hidden Markov models. The

Annals of Statistics.

Åström  K. (1980). Maximum likelihood and prediction error methods. Automatica  16(5):551–574.
Bach  F.  Mairal  J.  and Ponce  J. (2008). Convex sparse matrix factorizations. arXiv:0812.1869v1.
Banerjee  A.  Merugu  S.  Dhillon  I.  and Ghosh  J. (2005). Clustering with Bregman divergences.

Journal of Machine Learning Research.

Beck  A. and Teboulle  M. (2009). A Fast Iterative Shrinkage-Thresholding Algorithm for Linear

Inverse Problems. SIAM Journal on Imaging Sciences  2.

Boots  B. and Gordon  G. (2012). Two-manifold problems with applications to nonlinear system

identiﬁcation. In International Conference on Machine Learning.

Boyd  S. and Vandenberghe  L. (2004). Convex Optimization. Cambridge University Press.
Buesing  L.  Macke  J.  and Sahani  M. (2012a). Learning stable  regularised latent models of neural

population dynamics. Network: Computation in Neural Systems.

Buesing  L.  Macke  J.  and Sahani  M. (2012b). Spectral learning of linear dynamics from generalised-
linear observations with application to neural population data. In Advances in Neural Information
Processing Systems.

Cramér  H. (1946). Mathematical Methods of Statistics. Princeton University Press.
Foster  D.  Rodu  J.  and Ungar  L. (2012). Spectral dimensionality reduction for HMMs.

arXiv:1203.6130v1.

Gelfand  A.  Diggle  P.  Guttorp  P.  and Fuentes  M. (2010). Handbook of Spatial Statistics. CRC

Press.

Ghahramani  Z. and Hinton  G. (1996). Parameter estimation for linear dynamical systems. Technical

report.

Haeffele  B.  Young  E.  and Vidal  R. (2014). Structured Low-Rank Matrix Factorization: Optimality 
In International Conference on Machine

Algorithm  and Applications to Image Processing.
Learning.

9

Hsu  D.  Kakade  S.  and Zhang  T. (2012). A spectral algorithm for learning Hidden Markov Models.

Journal of Computer and System Sciences.

Katayama  T. (2006). Subspace Methods for System Identiﬁcation. Springer.
Ljung  L. (1999). System Identiﬁcation (2Nd Ed.): Theory for the User. Prentice Hall PTR.
Macke  J.  Buesing  L.  and Sahani  M. (2015). Estimating State and Model Parameters in State-Space

Models of Spike Trains. Advanced State Space Methods for Neural and Clinical Data.

Moonen  M. and Ramos  J. (1993). A subspace algorithm for balanced state space system identiﬁca-

tion. IEEE Transactions on Automatic Control.

Parikh  N. and Boyd  S. (2013). Proximal Algorithms. Foundations and Trends in Optimization. Now

Publishers.

Roweis  S. and Ghahramani  Z. (1999). A unifying review of linear Gaussian models. Neural

Computation.

Siddiqi  S.  Boots  B.  and Gordon  G. (2007). A Constraint Generation Approach to Learning Stable

Linear Dynamical Systems. In Advances in Neural Information Processing Systems.

Song  L.  Boots  B.  Siddiqi  S.  Gordon  G.  and Smola  A. (2010). Hilbert space embeddings of

hidden Markov models. In International Conference on Machine Learning.

Van Overschee  P. and De Moor  B. (1994). N4SID: Subspace algorithms for the identiﬁcation of

combined deterministic-stochastic systems. Automatica.

Viberg  M. (1995). Subspace-based methods for the identiﬁcation of linear time-invariant systems.

Automatica.

White  M.  Wen  J.  Bowling  M.  and Schuurmans  D. (2015). Optimal estimation of multivariate

ARMA models. In AAAI Conference on Artiﬁcial Intelligence.

White  M.  Yu  Y.  Zhang  X.  and Schuurmans  D. (2012). Convex multi-view subspace learning. In

Advances in Neural Information Processing Systems.

Yu  H.  Rao  N.  and Dhillon  I. (2015). High-dimensional Time Series Prediction with Missing

Values. arXiv:1509.08333.

Yu  Y.  Zhang  X.  and Schuurmans  D. (2014). Generalized Conditional Gradient for Sparse

Estimation. arXiv:1410.4828.

Zhang  X.  Yu  Y.  and Schuurmans  D. (2012). Accelerated training for matrix-norm regularization:

A boosting approach. In Advances in Neural Information Processing Systems.

Zhao  H. and Poupart  P. (2014). A sober look at spectral learning. arXiv:1406.4631.

10

,Mahdi Karami
Dale Schuurmans
Csaba Szepesvari
Ilai Bistritz
Amir Leshem