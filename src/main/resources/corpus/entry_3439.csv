2013,Mid-level Visual Element Discovery as Discriminative Mode Seeking,Recent work on mid-level visual representations aims to capture information at the level of complexity higher than typical visual words"  but lower than full-blown semantic objects. Several approaches have been proposed to discover mid-level visual elements  that are both 1) representative  i.e. frequently occurring within a visual dataset  and 2) visually discriminative. However  the current approaches are rather ad hoc and difficult to analyze and evaluate. In this work  we pose visual element discovery as discriminative mode seeking  drawing connections to the the well-known and well-studied mean-shift algorithm. Given a weakly-labeled image collection  our method discovers visually-coherent patch clusters that are maximally discriminative with respect to the labels. One advantage of our formulation is that it requires only a single pass through the data. We also propose the Purity-Coverage plot as a principled way of experimentally analyzing and evaluating different visual discovery approaches  and compare our method against prior work on the Paris Street View dataset. We also evaluate our method on the task of scene classification  demonstrating state-of-the-art performance on the MIT Scene-67 dataset.",Mid-level Visual Element Discovery

as Discriminative Mode Seeking

Carl Doersch

Carnegie Mellon University
cdoersch@cs.cmu.edu

Abhinav Gupta

Carnegie Mellon University
abhinavg@cs.cmu.edu

Alexei A. Efros
UC Berkeley

efros@cs.berkeley.edu

Abstract

Recent work on mid-level visual representations aims to capture information at the
level of complexity higher than typical “visual words”  but lower than full-blown
semantic objects. Several approaches [5  6  12  23] have been proposed to discover
mid-level visual elements  that are both 1) representative  i.e.  frequently occurring
within a visual dataset  and 2) visually discriminative. However  the current ap-
proaches are rather ad hoc and difﬁcult to analyze and evaluate. In this work 
we pose visual element discovery as discriminative mode seeking  drawing con-
nections to the the well-known and well-studied mean-shift algorithm [2  1  4  8].
Given a weakly-labeled image collection  our method discovers visually-coherent
patch clusters that are maximally discriminative with respect to the labels. One
advantage of our formulation is that it requires only a single pass through the data.
We also propose the Purity-Coverage plot as a principled way of experimentally
analyzing and evaluating different visual discovery approaches  and compare our
method against prior work on the Paris Street View dataset of [5]. We also eval-
uate our method on the task of scene classiﬁcation  demonstrating state-of-the-art
performance on the MIT Scene-67 dataset.

Introduction

1
In terms of sheer size  visual data is  by most accounts  the biggest “Big Data” out there. But 
unfortunately  most machine learning algorithms (with some notable exceptions  e.g. [13]) are not
equipped to handle it directly  at the raw pixel level  making research on ﬁnding good visual rep-
resentations particularly relevant and timely. Currently  the most popular visual representations in
machine learning are based on “visual words” [24]  which are obtained by unsupervised clustering
(k-means) of local features (SIFT) over a large dataset. However  “visual words” is a very low-level
representation  mostly capturing local edges and corners ([21] notes that “visual letters” or “visual
phonemes” would have been a more accurate term). Part of the problem is that the local SIFT fea-
tures are relatively low-dimensional (128D)  and might not be powerful enough to capture anything
of higher complexity. However  switching to a more descriptive feature (e.g. 2  000-dimensional
HOG) causes k-means to produce visually poor clusters due to the curse of dimensionality [5].
Recently  several approaches [5  6  11  12  15  23  26  27] have proposed mining visual data for dis-
criminative mid-level visual elements  i.e.  entities which are more informative than “visual words ”
and more frequently occurring and easier to detect than high-level objects. Most such approaches
require some form of weak per-image labels  e.g.  scene categories [12] or GPS coordinates [5] (but
can also run unsupervised [23])  and have been recently used for tasks including image classiﬁcation
[12  23  27]  object detection [6]  visual data mining [5  15]  action recognition [11]  and geometry
estimation [7]. But how are informative visual elements to be identiﬁed in the weakly-labeled vi-
sual dataset? The idea is to search for clusters of image patches that are both 1) representative  i.e.
frequently occurring within the dataset  and 2) visually discriminative. Unfortunately  algorithms
for ﬁnding patches that ﬁt these criteria remain rather ad-hoc and poorly understood. and often
do not even directly optimize these criteria. Hence  our goal in this work is to quantify the terms
“representative” and “discriminative ” and show that a formulation which draws inspiration from

1

Figure 1: The distribution of patches in HOG feature space is very non-uniform and absolute distances cannot
be trusted. We show two patches with their 5 nearest-neighbors from the Paris Street View dataset [5]; beneath
each nearest neighbor is its distance from query. Although the nearest neighbors on the left are visually much
better  their distances are more than twice those on the right  meaning that the actual densities of the two regions
will differ by a factor of more than 2d  where d is the intrinsic dimensionality of patch feature space. Since this
is a 2112-dimensional feature space  we estimate d to be on the order of hundreds.
the well-known  well-understood mean-shift algorithm can produce visual elements that are more
representative and discriminative than those of previous approaches.
Mining visual elements from a large dataset is difﬁcult for a number of reasons. First  the search
space is huge: a typical dataset for visual data mining has tens of thousands of images  and ﬁnding
something in an image (e.g.  ﬁnding matches for a visual template) involves searching across tens
of thousands of patches at different positions and scales. To make matters worse  patch descriptors
tend to be on the order of thousands of dimensions; not only is the curse of dimensionality a constant
problem  but we must sift through terabytes of data. And we are searching for a needle in a haystack:
the vast majority of patches are actually uninteresting  either because they are rare (e.g.  they may
contain multiple random things in a conﬁguration that never occurs again) or they are redundant due
to the overlapping nature of patches. This suggests the need for an online algorithm  because we
wish to discard much of the data while making as few passes through the dataset as possible.
The well-known mean-shift algorithm [2  3  8] has been proposed to address many of these problems.
The goal of mean-shift is to ﬁnd the local maxima (modes) of a density using a sample from that
density. Intuitively  mean-shift initializes each cluster centroid to a single data point  then iteratively
1) ﬁnds data points that are sufﬁciently similar to each centroid  and  2) averages these data points
to update the cluster centroid. In the end  each cluster generally depends on only a tiny fraction of
the data  thus eliminating the need to keep the entire dataset in memory.
However  there is one issue with using classical mean-shift to solve our problem directly: it only
ﬁnds local maxima of a single  unlabeled density  which may not be discriminative. But in our
case  we can use the weak labels to divide our data into two different subsets (“positive” (+) and
“negative” ()) and seek visual elements which appear only in the “positive” set and not in the
“negative” set. That is  we want to ﬁnd points in feature space where the density of the positive
set is large  and the density of the negative set is small. This can be achieved by maximizing the
well-studied density ratio p+(x)/p(x) instead of maximizing the density. While a number of
algorithms exist for estimating ratios of densities (see [25] for a review)  we did not ﬁnd any that
were particularly suitable for ﬁnding local maxima of density ratios. Hence  the ﬁrst contribution of
our paper is to propose a discriminative variant of mean-shift for ﬁnding visual elements. Similar to
the way mean-shift performs gradient ascent on a density estimate  our algorithm performs gradient
ascent on the density ratio (section 2). When we perform gradient ascent separately for each element
as in standard mean-shift  however  we ﬁnd that the most frequently-occuring elements tend to
be over-represented. Hence  section 3 describes a modiﬁcation to our gradient ascent algorithm
which uses inter-element communication to approximate common adaptive bandwidth procedures.
Finally  in section 4 we demonstrate that our algorithms produce visual elements which are more
representative and discriminative than previous methods  and in section 5 we show they signiﬁcantly
improve performance in scene classiﬁcation.

2 Mode Seeking on Density Ratios
Our goal is to extract discriminative visual elements by ﬁnding the local maxima of the density ratio.
However  one issue with performing gradient ascent directly on standard density ratio estimates is
that common estimators tend to use a ﬁxed kernel bandwidth  for example:

ˆr(x) /

nXi=1

✓iK(kx  xik/h)

where ˆr is the ratio estimate  the parameters ✓i 2 R are weights associated with each datapoint 
K is a kernel function (e.g.  a Gaussian)  and h is a globally-shared bandwidth parameter. The

2

2.58 2.92 3.07 3.10 3.16 1.01 1.13 1.13 1.15 1.17 Distance: Distance: bandwidth deﬁnes how much the density is smoothed before gradient ascent is performed  meaning
these estimators assume a roughly equal distribution of points in all regions of the space. Unfortu-
nately  absolute distances in HOG feature space cannot be trusted  as shown in Figure 1: any kernel
bandwidth which is large enough to work well in the left example will be far too large to work well
in the right. One way to deal with the non-uniformity of the feature space is to use an adaptive
bandwidth [4]: that is  different bandwidths are used in different regions of the space. However 
previous algorithms are difﬁcult to implement for large data in high-dimensional spaces; [4]  for in-
stance  requires a density estimate for every point used in computing the gradient of their objective 
because their formulation relies on a per-point bandwidth rather than a per-cluster bandwidth. In
our case  this is prohibitively expensive. While approximations exist [9]  they rely on approximate
nearest neighbor algorithms  which work for low-dimensional spaces ( 48 dimensions in [9])  but
empirically we have found poor performance in HOG feature space (> 2000 dimensions). Hence 
we take a different approach which we have tailored for density ratios.
We begin by using a result from [2] that classical mean-shift (using a ﬂat kernel) is equivalent to
ﬁnding the local maxima of the following density estimate:

Pn

i=1 max(b  d(xi  w)  0)

z(b)

In standard mean-shift  d is the Euclidean distance function  b is a constant that controls the kernel
bandwidth  and z(b) is a normalization constant. Here  the ﬂat kernel has been replaced by its
shadow kernel  the triangular kernel  using Theorem 1 from [2]. We want to maximize the density
ratio  so we simply divide the two density estimates. We allow an adaptive bandwidth  but rather
than associating a bandwidth with each datapoint  we compute it as a function of w which depends
on the data.

Pnpos
i=1 max(B(w)  d(x+
i   w)  0)
Pnneg
i=1 max(B(w)  d(xi   w)  0)
nnegXi=1

max(b  d(xi   w)  0) = 

(1)

(2)

(3)

(4)

Where the normalization term z(b) is cancelled. This expression  however  produces poor estimates
of the ratio if the denominator is allowed to shrink to zero; in fact  it can produce arbitrarily large
but spurious local maxima. Hence  we deﬁne B(w) as the value of b which satisﬁes:

Where  is a constant analogous to the bandwidth parameter  except that it directly controls how
many negative datapoints are in each cluster. Note the value of the sum is strictly increasing in b
when it is nonzero  so the b satisfying the constraint is unique. With this deﬁnition of B(w)  we are
actually ﬁxing the value of the denominator of (2) (We include the denominator here only to make
the ratio explicit  and we will drop it in later formula). This approach makes the implicit assumption
that the distribution of the negatives captures the overall density of the patch space. Note that if
we assume the denominator distribution is uniform  then B(w) becomes ﬁxed and our objective is
identical to ﬁxed-bandwidth mean-shift.
Returning to our formulation  we must still choose the distance function d. In high-dimensional
feature space  [20] suggests that normalized correlation provides a better metric than the Euclidean
distance commonly used in mean-shift. Formulations of mean-shift exist for data constrained to
the unit sphere [1]  but again we must adapt them to the ratio setting. Surprisingly  replacing the
Euclidean distance with normalized correlation leads to a simpler optimization problem. First  we
mean-subtract and normalize all datapoints xi and rewrite (2) as:

max(w>x+

i  b  0) s.t. Pnneg

nposXi=1

i=1 max(w>xi  b  0) = 

kwk2 = 1

Where B(w) has been replaced by b as in equation (3)  to emphasize that we can treat B(w) as a
constraint in an optimization problem. We can further rewrite the above equation as ﬁnding the local
maxima of:

nposXi=1

max(w>x+

i  b  0)  kwk2 s.t.

nnegXi=1

max(w>xi  b  0) = 

(5)

3

ini#al&

ini#al&

ini#al&

First&

Itera#on&

Final&&
Itera#on&
Figure 2: Left: without competition  the algorithm from section 2 correctly learns a street lamp element.
Middle: The same algorithm trained on a sidewalk barrier  which is too similar to the very common “window
with railing” element  which takes over the cluster. Right: with the algorithm from section 3  the window gets
down-weighted and the algorithm can learn the sidewalk barrier.
Note that (5) is equivalent to (4) for some appropriate rescaling of  and . It can be easily shown
that multiplying  by a constant factor does not change the relative location of local maxima  as long
as we divide  by that same factor. Such a re-scaling will in fact result in re-scaling w by the same
value  so we can choose a  and  which makes the norm of w equal to 1. 1
After this rewriting  we are left with an objective that looks curiously like a margin-based method.
Indeed  the negative set is treated very much like the negative set in an SVM (we penalize the linear
sum of the margin violations)  which follows [23]. However  unlike [23]  which makes the ad-hoc
choice of 5 positive examples  our algorithm allows each cluster to select the optimal number of
positives based on the decision boundary. This is somewhat reminiscent of unsupervised margin-
based clustering [29  16].
Mean-shift prescribes that we initialize the procedure outlined above at every datapoint.
In our
setting  however  this is not practical  so we instead use a randomly-sampled subset. We run this
as an online algorithm by breaking the dataset into chunks and then mining  one chunk at a time 
for patches where w>x  b > ✏ for some small ✏  akin to “hard mining” for SVMs. We perform
gradient ascent after each mining phase. An example result for this algorithm is shown in in Figure 2 
and we include further results below. Gradient ascent on our objective is surprisingly efﬁcient  as
described in Appendix A.

3 Better Adaptive Bandwidth via Inter-Element Communication
Implicit in our formulation thus far is the idea that we do not want a single mode  but instead many
distinct modes which each corresponds to a different element. In theory  mode-seeking will ﬁnd
every mode that is supported by the data.
In practice  clusters often drift from weak modes to
stronger modes  as demonstrated in Figure 2 (middle). One way to deal with this is to assign smaller
bandwidths to patches in dense regions of the space [4]  e.g.  the window railing on row 1 of Figure 2
(middle) would hopefully have a smaller bandwidth and hence not match to the sidewalk barrier.
However  estimating a bandwidth for every datapoint in our setting is not practical  so we seek an
approach which only requires one pass through the data. Since patches in regions of the feature space
with high density ratio will be members of many clusters  we want a mechanism that will reduce
their bandwidth. To accomplish this  we extend the standard local (per-element) optimization of
mean-shift into a joint optimization among the m different element clusters. Speciﬁcally  we control
how a single patch can contribute to multiple clusters by introducing a sharing weight ↵i j for each
patch i that is contained in a cluster j  akin to soft-assignment in EM GMM ﬁtting. Returning to our
fomulation  we maximize (again with respect to the w’s and b’s):

nposXi=1

mXj=1

nnegXi=1

max(w>j xi  bj  0) = 

(6)

↵i j max(w>j x+

i  bj  0)  

kwjk2 s.t. 8j

mXj=1

Where each ↵i j is chosen such that any patch which is a member of multiple clusters gets a
lower weight.
(6) also has a natural interpretation in terms of maximizing the “representative-
ness” of the set of clusters: clusters are rewarded for representing patches that are not repre-
sented by other clusters. But how can we set the ↵’s? One way is to set ↵i j = max(w>j x+
i 
i  bk  0)  and alternate between setting the ↵’s and optimizing the w’s and
1Admittedly this means that the norm of w has an indirect effect on the underlying bandwidth: speciﬁcally
if the norm of w is increased  it has a similar effect as a proportional derease in  in (4). However  since w
is roughly proportional to the density of the positive data  the bandwidth is only reduced when the density of
positive data is high.

bj  0)/Pm

k=1 max(w>k x+

4

25 Elements

y
t
i
r
u
P

1
0.98
0.96
0.94
0.92
0.9
0.88
0.86
0.84
0.82
0.8
0

1
0.98
0.96
0.94
0.92
0.9
0.88
0.86
0.84
0.82
0.8
0

y
t
i
r
u
P

0.5

)
t

t

 

e
s
a
a
D
e
v
i
t
i
s
o
P

 
f

o

 

n
o

i
t
c
a
r
F
(
 

e
g
a
r
e
v
o
C

200 Elements

Purity of 75%

This work
This work  no inter-element
SVM Retrained 5x (Doersch et al. 2012)
LDA Retrained 5x
LDA Retrained
Exemplar LDA (Hariharan et al. 2012)

 

10
9
8
7
6
5
4

3
2
1
 
0.4
250
Coverage (Fraction of Positive Dataset)
Number of Elements

0.6
400

350

300

0.2

0.8
450

500

0.1
0.4
Coverage (Fraction of Positive Dataset)

0.2

0.3

Figure 3: Purity-coverage graph for our algorithm and baselines. In each plot  purity measures the accuracy
of the element detectors  whereas coverage captures how often they ﬁre. Curves are computed over the top 25
(left) and 200 (right) elements. Higher is better.
b’s at each iteration. Intuitively  this algorithm would be much like EM  alternating between softly
assigning cluster memberships for each datapoint and then optimizing each cluster. However  this
goes against our mean-shift intuition: if two patches are really instances of the same element  then
clusters initialized from those two points should converge to the same mode and not “compete” with
one another. So  our heuristic is to ﬁrst cluster the elements. Let Cj be the assigned cluster for the
j’th element. Then we set

↵i j =

max(w>j x+

i  bj  0) +Pm

max(w>j x+

i  bj  0)

k=1 I(Ck 6= Cj) max(w>k x+

i  bk  0)

(7)

In this way  any “competition” from elements that are too similar to each other is ignored. To obtain
the clusters  we perform agglomerative (UPGMA) clustering on the set of element clusters  using
the negative of the number of overlapping cluster members as a “distance” metric.
In practice  however  it is extremely rare that the exact same patch is a member of two different clus-
ters; instead  clusters will have member patches that merely overlap with each other. Our heuristic
deal with this is to compute a quantity ↵0i j p which is analogous to the ↵i j deﬁned above  but is
deﬁned for every pixel p. Then we compute ↵i j for a given patch by averaging ↵0i j p over all pixels
in the patch. Speciﬁcally  we compute ↵i j for patch i as the mean over all pixels p in that patch of
the following quantity:

max(w>j x+

↵0i j p =

max(w>j x+

i  bj  0) +Px2Ov(p)Pm

i  bj  0)
k=1 I(Ck 6= Cj) max(w>k x+
Where Ov(p) denotes the set of features for positive patches that contain the pixel p.
It is admittedly difﬁcult to analyze how well these heuristics approximate the adaptive bandwidth
approach of [4]  and even there the setting of the bandwidth for each datapoint has heuristic aspects.
However  empirically our approach leads to improvements in performance as discussed below  and
suggests a potential area for future work.

i  bk  0)

(8)

4 Evaluation via Purity-Coverage Plot
Our aim is to discover visual elements that are maximally representative and discriminative. To
measure this  we deﬁne two quantities for a set of visual elements: coverage (which captures rep-
resentativeness) and purity (which captures discriminativeness). Given a held-out test set  visual
elements will generate a set of patch detections. We deﬁne the coverage of this set of patches to be
the fraction of the pixels from the positive images claimed by at least one patch. We deﬁne the purity
of a set as the percentage of the patches that share the same label. For an individual visual element 
of course  there is an inherent trade-off between purity and coverage: if we lower the detection
threshold  we cover more pixels but also increase the likelihood of making mistakes. Hence  we can
construct a purity-coverage curve for a set of elements  analogous to a precision-recall curve. We
could perform this analysis on any dataset containing positive and negative images  but [5] presents
a dataset which is particularly suitable. The goal is to mine visual elements which deﬁne the look
and feel of a geographical locale  with a training set of 2 000 Paris Street View images and 8 000

5

)
t

 

t

e
s
a
a
D
e
v
i
t
i
s
o
P

 
f

o

 

n
o

i
t
c
a
r
F
(
 
e
g
a
r
e
v
o
C

0.25

0.2

0.15

0.1

0.05

0
0

100

Purity of 100%

)
t

t

 

e
s
a
a
D
e
v
i
t
i
s
o
P

 
f

o

 

n
o

i
t
c
a
r
F
(
 
e
g
a
r
e
v
o
C

0.7

0.6

0.5

0.4

0.3

0.2

0.1

200

300

Number of Elements

400

500

0
 
0

100

Purity of 90%

 

This work
This work  no inter-element
SVM Retrained 5x (Doersch et al. 2012)
LDA Retrained 5x
LDA Retrained
Exemplar LDA (Hariharan et al. 2012)

200

300

Number of Elements

400

500

Figure 4: Coverage versus the number of elements used in the representation. On the left we keep only the
detections with a score higher than the score of the detector’s ﬁrst error (i.e. purity 1). On the right  we lower
the detection threshold until the elements are 90% pure. Note: this is the same purity and coverage measure for
the same elements as Figure 3  just plotted differently.

non-Paris images  as well as 2 999 of both classes for testing. Purity-coverage curves for this dataset
are shown in Figure 3.
To plot the curve for a given value of purity p  we rank all patches by w>xb independently for every
element  and select  for a given element  all patches up until the last point where the element has the
desired purity. We then compute the coverage as the union of patches selected for every element.
Because we are taking a union of patches  adding more elements can only increase coverage  but in
practice we prefer concise representations  both for interpretability and for computational reasons.
Hence  to compare two element discovery methods  we must select exactly the same number of
elements for both of them. Different works have proposed different heuristics for selecting elements 
which would make the resulting curves incomparable. Hence  we select elements in the same way
for all algorithms  which approximates an “ideal” selection for our measure. Speciﬁcally  we ﬁrst
ﬁx a level of purity (95%) and greedily select elements to maximize coverage (on the testing data)
for that level of purity. Hence  this ranking serves as an oracle to choose the “best” set of elements
for covering the dataset at that level of purity. While this ranking has a bias toward large elements
(which inherently cover more pixels per detection)  we believe that it provides a valuable comparison
between algorithms. Our purity-coverage curves are shown in Figure 3  for the 25 and 200 top
elements  respectively. We can also slice the same data differently  ﬁxing a level of purity for all
elements and varying the number of elements  as shown in Figure 4.
Baselines: We included ﬁve baselines of increasing complexity. Our goal is not only to analyze our
own algorithm; we want to show the importance of the various components of previous algorithms
as well. We initially train 20  000 visual elements for all the baselines  and select the top elements
using the method above. The simplest baseline is “Exemplar LDA ” proposed by [10]. Each cluster
is represented by a hyperplane which maximally separates a single seed patch from the negative
dataset learned via LDA  i.e. the negative distribution is approximated using a single multivariate
Gaussian. To show the effects of re-clustering  “LDA Retrained” takes the top 5 positive-set patches
retrieved in Exemplar LDA (including the initial patch itself)  and repeats LDA  separating those 5
from the negative Gaussian. This is much like the well-established method of “query expansion” for
retrieval  and is similar to [12] (although they use multiple iterations of query expansion). Finally 
“LDA Retrained 5 times” begins with elements initialized via the LDA retraining method  and re-
trains the LDA classiﬁer  each time throwing out the previous top 5 used to train the previous LDA 
and selecting a new top 5 from held-out data. This is much like the iterative SVM training of [5] 
except that it uses LDA instead of an SVM. Finally  we include the algorithm of [5]  which is a
weakly supervised version of [23]  except that knn is being used for initialization instead of kmeans.
The iterations of retraining clearly improve performance  and it seems that replacing LDA with an
SVM also gives improvement  especially for difﬁcult elements.
Implementation details: We use the same patch descriptors described in [5] and whiten them fol-
lowing [10]. We mine elements using the online version of our algorithm  with a chunk size of 1000
(200 Paris  800 non-Paris per batch). We set ⇤  = t/500 where t is the iteration number  such that
the bandwidth increases proportional to the number of samples. We train the elements for about 200

6

Figure 5: For each correctly classiﬁed image (left)  we show four elements (center) and heatmap of
the locations (right) that contributed most to the classiﬁcation.

Table 1: Results on MIT 67 scenes

ROI + Gist [19]
MM-scene [30]
DPM [17]
CENTRIST [28]
Object Bank [14]
RBoW [18]

26.05 D-Patches [23]
28.00
LPR [22]
30.40 BoP [12]
36.90 miSVM [15]
37.60 D-Patches (full) [23]
37.93 MMDL [27]

IFV [12]

38.10 D-Parts [26]
44.84
46.10 BoP+IFV [12]
46.40 Ours (no inter-element  §2)
49.40 Ours (§3)
50.15 Ours+IFV

51.40
60.77
63.10
63.36
64.03
66.87

gradient steps after each chunk of mining. To compute ↵i j for patch i and detector j  we actually use
scale-space voxels rather than pixels  since a large detection can completely cover a small detection
but not vice versa. Hence  the set of scale-space voxels covered is a 3D box  the width of the bound-
ing box by its height (both discretized by a factor of 8 for efﬁciency) by 5  covering exactly one

“octave” of scale space (i.e. log2(pwidth ⇤ height) ⇤ 5 through log2(pwidth ⇤ height) ⇤ 5 + 4).
For experiments without inter-element communication  we simply set ↵i j to .1. Finally  to reduce
the impact of highly redundant textures  we divide ↵i j divided by the total number of detections for
element j in the image containing i. Source code will be available online.

5 Scene Classiﬁcation
Finally  we evaluate whether our visual element representation is useful for scene classiﬁcation. We
use the MIT Scene-67 dataset [19]  where machine performance remains substantially below human

7

Figure 6: Each of these images was misclassiﬁed by the algorithm  and the heatmaps explain why.
For instance  it may not be obvious why a corridor would be classiﬁed as a staircase  but we can see
(top right) that the algorithm has identiﬁed the railings as a key staircase element  and has found no
other staircase elements the image.
performance. For indoor scenes  objects within the scene are often more useful features than global
scene statistics [12]: for instance  shoe shops are similar to other stores in global layout  but they
mostly contain shoes.
Implementation details: We used the original Indoor-67 train/test splits (80 training and 20 testing
images per class). We learned 1600 elements per class  for a total of 107  200 elements  following
the procedure described above. We include right-left ﬂipped images as extra positives. 5 batches
were sufﬁcient  as this dataset is smaller. We also used smaller descriptors: 6-by-6 HOG cells 
corresponding to 64-by-64 patches and 1188-dimensional descriptors. We again select elements
by ﬁxing purity and greedily selecting elements to maximize coverage  as above. However  rather
than deﬁning coverage as the number of pixels (which is biased toward larger elements)  we simply
count the detections  penalizing for overlap: we penalize each individual detection by a factor of
1/(1 + noverlap)  where noverlap is the number of detections from previously selected detectors
that a given detection overlaps with. We select 200 top elements per class. To construct our ﬁnal
feature vector  we use a 2-level (1x1 and 2x2) spatial pyramid and take the max score per detector
per region  thresholded at .5 (since below this value we do not expect the detection scores to be
meaningful) resulting in a 67 000-dimensional vector. We average the feature vector for the right
and left ﬂips of the image  and classify using 67 one-vs-all linear SVM’s. Note that this differs from
[23]  which selects only the elements for a given class in each class-speciﬁc SVM.
Figure 5 shows a few qualitative results of our algorithm. Quantitative results and comparisons
are shown in Table 1. We signiﬁcantly outperform other methods based on discriminative patches 
suggesting that our training method is useful. We even outperform the Improved Fisher Vector
of [12]  as well as IFV combined with discriminative patches (IFV+BoP). Finally  although the
optimally-performing representation is dense (about 58% of features are nonzero)  it can be made
much sparser without sacriﬁcing much performance. For instance  if we trivially zero-out low-
valued features until fewer than 6% are nonzero  we still achieve 60.45% accuracy.
6 Conclusion
We developed an extension of the classic mean-shift algorithm to density ratio estimation  showing
that the resulting algorithm could be used for element discovery  and demonstrating state-of-the-art
results for scene classiﬁcation. However  there is still much room for improvement in weakly-
supervised element discovery algorithms. For instance  our algorithm is limited to binary labels  but
image labels may be continuous (e.g.  GPS coordinates or dates). Also  our elements are detected
based only on individual patches  but images often contain global structures beyond patches.
Acknowledgements: We thank Abhinav Shrivastava  Yong Jae Lee  Supreeth Achar  and Geoff Gordon for helpful insights
and discussions. This work was partially supported by NDSEG fellowship to CD  An Amazon Web Services grant  a Google
Research grant  ONR MURI N000141010934  and IARPA via Air Force Research Laboratory. The U.S. Government is
authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright annotation thereon.
Disclaimer: The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily
representing the ofﬁcial policies or endorsements  either expressed or implied  of IARPA  AFRL or the U.S. Government.
References
[1] H. E. Cetingul and R. Vidal. Intrinsic mean shift for clustering on Stiefel and Grassmann manifolds. In

CVPR  2009.

8

Ground Truth (GT): deli GT: laundromat GT: corridor Guess: grocery store Guess: closet Guess: staircase GT: museum GT: office GT: bakery Guess: garage Guess: classroom Guess: buffet [2] Y. Cheng. Mean shift  mode seeking  and clustering. PAMI  17(8):790–799  1995.
[3] D. Comaniciu  V. Ramesh  and P. Meer. Real-time tracking of non-rigid objects using mean shift. In

CVPR  2000.

[4] D. Comaniciu  V. Ramesh  and P. Meer. The variable bandwidth mean shift and data-driven scale selec-

tion. In ICCV  2001.

[5] C. Doersch  S. Singh  A. Gupta  J. Sivic  and A. A. Efros. What makes Paris look like Paris? SIGGRAPH 

2012.

[6] I. Endres  K. Shih  J. Jiaa  and D. Hoiem. Learning collections of part models for object recognition. In

CVPR  2013.

[7] D. F. Fouhey  A. Gupta  and M. Hebert. Data-driven 3D primitives for single image understanding. In

ICCV  2013.

[8] K. Fukunaga and L. Hostetler. The estimation of the gradient of a density function  with applications in

pattern recognition. Information Theory  1975.

[9] B. Georgescu  I. Shimshoni  and P. Meer. Mean shift based clustering in high dimensions: A texture

classiﬁcation example. In CVPR  2003.

[10] B. Hariharan  J. Malik  and D. Ramanan. Discriminative decorrelation for clustering and classiﬁcation.

In ECCV  2012.

[11] A. Jain  A. Gupta  M. Rodriguez  and L. Davis. Representing videos using mid-level discriminative

patches. In CVPR  2013.

[12] M. Juneja  A. Vedaldi  C. V. Jawahar  and A. Zisserman. Blocks that shout: Distinctive parts for scene

classiﬁcation. In CVPR  2013.

[13] A. Krizhevsky  I. Sutskever  and G. Hinton. Imagenet classiﬁcation with deep convolutional neural net-

works. In NIPS  2012.

[14] L.-J. Li  H. Su  E. P. Xing  and L. Fei-Fei. Object bank: A high-level image representation for scene

classiﬁcation and semantic feature sparsiﬁcation. NIPS  2010.

[15] Q. Li  J. Wu  and Z. Tu. Harvesting mid-level visual concepts from large-scale internet images. In CVPR 

2013.

[16] T. Malisiewicz and A. A. Efros. Recognition by association via learning per-exemplar distances.

CVPR  2008.

In

[17] M. Pandey and S. Lazebnik. Scene recognition and weakly supervised object localization with deformable

part-based models. In ICCV  2011.

[18] S. N. Parizi  J. G. Oberlin  and P. F. Felzenszwalb. Reconﬁgurable models for scene recognition.

CVPR  2012.

In

[19] A. Quattoni and A. Torralba. Recognizing indoor scenes. In CVPR  2009.
[20] M. Radovanovi´c  A. Nanopoulos  and M. Ivanovi´c. Nearest neighbors in high-dimensional data: The

emergence and inﬂuence of hubs. In ICML  2009.

[21] B. C. Russell  A. A. Efros  J. Sivic  W. T. Freeman  and A. Zisserman. Using multiple segmentations to

discover objects and their extent in image collections. In CVPR  2006.

[22] F. Sadeghi and M. F. Tappen. Latent pyramidal regions for recognizing scenes. In ECCV. 2012.
[23] S. Singh  A. Gupta  and A. A. Efros. Unsupervised discovery of mid-level discriminative patches. In

ECCV  2012.

[24] J. Sivic and A. Zisserman. Video google: A text retrieval approach to object matching in videos. In ICCV 

2003.

[25] M. Sugiyama  T. Suzuki  and T. Kanamori. Density ratio estimation: A comprehensive review. RIMS

Kokyuroku  2010.

[26] J. Sun and J. Ponce. Learning discriminative part detectors for image classiﬁcation and cosegmentation.

In ICCV  2013.

[27] X. Wang  B. Wang  X. Bai  W. Liu  and Z. Tu. Max-margin multiple-instance dictionary learning. In

ICML  2013.

[28] J. Wu and J. M. Rehg. Centrist: A visual descriptor for scene categorization. PAMI  2011.
[29] L. Xu  J. Neufeld  B. Larson  and D. Schuurmans. Maximum margin clustering. In NIPS  2004.
[30] J. Zhu  L.-J. Li  L. Fei-Fei  and E. P. Xing. Large margin learning of upstream scene understanding

models. NIPS  2010.

9

,Carl Doersch
Abhinav Gupta
Alexei Efros
Eugene Belilovsky
Gaël Varoquaux
Matthew Blaschko