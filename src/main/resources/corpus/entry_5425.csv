2018,Testing for Families of Distributions via the Fourier Transform,We study the general problem of testing whether an unknown discrete distribution belongs to a specified family of distributions. More specifically  given a distribution family P and sample access to an unknown discrete distribution D   we want to distinguish (with high probability) between the case that D in P and the case that D is ε-far  in total variation distance  from every distribution in P . This is the prototypical hypothesis testing problem that has received significant attention in statistics and  more recently  in computer science. The main contribution of this work is a simple and general testing technique that is applicable to all distribution families whose Fourier spectrum satisfies a certain approximate sparsity property. We apply our Fourier-based framework to obtain near sample-optimal and  computationally efficient testers for the following fundamental distribution families: Sums of Independent Integer Random Variables (SIIRVs)  Poisson Multinomial Distributions (PMDs)  and Discrete Log-Concave Distributions. For the first two  ours are the first non-trivial testers in the literature  vastly generalizing previous work on testing Poisson Binomial Distributions. For the third  our tester improves on prior work in both sample and time complexity.,Testing for Families of Distributions

via the Fourier Transform∗

Clément L. Canonne
Stanford University

Ilias Diakonikolas

University of Southern California

ccanonne@stanford.edu

diakonik@usc.edu

Alistair Stewart

University of Southern California

stewart.al@gmail.com

Abstract

We study the general problem of testing whether an unknown discrete distribution
belongs to a speciﬁed family of distributions. More speciﬁcally  given a distribution
family P and sample access to an unknown discrete distribution P  we want to
distinguish (with high probability) between the case that P ∈ P and the case that
P is -far  in total variation distance  from every distribution in P. This is the
prototypical hypothesis testing problem that has received signiﬁcant attention in
statistics and  more recently  in computer science. The main contribution of this
work is a simple and general testing technique that is applicable to all distribution
families whose Fourier spectrum satisﬁes a certain approximate sparsity property.
We apply our Fourier-based framework to obtain near sample-optimal and com-
putationally efﬁcient testers for the following fundamental distribution families:
Sums of Independent Integer Random Variables (SIIRVs)  Poisson Multinomial
Distributions (PMDs)  and Discrete Log-Concave Distributions. For the ﬁrst two 
ours are the ﬁrst non-trivial testers in the literature  vastly generalizing previous
work on testing Poisson Binomial Distributions. For the third  our tester improves
on prior work in both sample and time complexity.

1

Introduction

1.1 Background and Motivation

The prototypical inference question in the area of distribution property testing [6] is the following:
Given a set of samples from a collection of probability distributions  can we determine whether
these distributions satisfy a certain property? During the past two decades  this broad question –
whose roots lie in statistical hypothesis testing [43  40] – has received considerable attention by the
computer science community  see [49  10] for two recent surveys. After two decades of study  for
many properties of interest there exist sample-optimal testers (matched by information-theoretic
lower bounds) [44  14  54  30  2  29  12].
In this work  we focus on the problem of testing whether an unknown distribution belongs to a given
family of discrete structured distributions. Let P be a family of discrete distributions over a total order
(e.g.  [n]) or a partial order (e.g.  [n]k). The problem of membership testing for P is the following:
Given sample access to an unknown distribution P (effectively supported on the same domain as P) 
we want to distinguish between the case that P ∈ P versus dTV (P P) > . (Here  dTV denotes the

1The full version of this paper is available at [13].

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

total variation distance between distributions.) The sample complexity of this problem depends on
the underlying family P. For example  if P contains a single distribution over a domain of size n  the
sample complexity of the testing problem is O(n1/2/2) [14  54  30  2].
In this work  we give a general technique to test membership in various distribution families over
discrete domains  i.e.  to solve the following task:

T(P  ): given a family of discrete distributions P over some partially or totally ordered set 
parameter  ∈ (0  1]  and sample access to an unknown distribution P over the same domain 
how many samples are required to distinguish  with probability 3/5  between the case that
P ∈ P versus dTV (P P) > ?

Before we state our results in full generality  we present concrete applications to a number of
well-studied distribution families.

1.2 Our Results

Our ﬁrst result is a nearly sample-optimal testing algorithm for sums of independent integer random
variables (SIIRVs). Formally  an (n  k)-SIIRV is a sum of n independent integer random variables
each supported in {0  1  . . .   k − 1}. We will denote the set of (n  k)-SIIRVs by SIIRV n k. SIIRVs
comprise a rich class of distributions that arise in many settings. The special case of k = 2 was ﬁrst
considered by Poisson [45] as a non-trivial extension of the Binomial distribution  and is known as
Poisson binomial distribution (PBD). In application domains  SIIRVs have many uses in research
areas such as survey sampling  case-control studies  and survival analysis  see e.g.  [16] for a survey
of the many practical uses of these distributions. In addition to their practical applications  SIIRVs are
of fundamental probabilistic interest and have been extensively studied in the theory of probability
and statistics [19  38  34  46  39  5  18  15]. We prove:
Theorem 1 (Testing SIIRVs). Given parameters k  n ∈ N and sample access to a distribution over
N  there exists an algorithm (Algorithm 1) for T(SIIRV n k  ) which takes

(cid:18) kn1/4

2

O

log1/4 1


+

k2

2 log2 k



(cid:19)

samples  and runs in time n(k/)O(k log(k/)).

Prior to our work  no non-trivial2 tester was known for (n  k)-SIIRVs for any k > 2. [11] showed a

sample lower bound of Ω(cid:0)k1/2n1/4/2(cid:1)  but their techniques did not yield any non-trivial sample
(cid:112)log 1/ + (1/)O(log2 1/)(cid:17)

upper bound.
For the special case of PBDs (k = 2)  Acharya and Daskalakis [1] gave a tester with sample
complexity O
  and
also showed a sample lower bound of Ω(n1/4/2). The special case of our Theorem 1 for k = 2
yields an improvement over [1] in both sample size and runtime:
Theorem 2 (Testing PBDs). Given parameter n ∈ N and sample access to a distribution over N 
there exists an algorithm (Algorithm 1) for T(PBDn  ) which takes

(cid:112)log 1/ + log5/2 1/

(cid:16) n1/4

(cid:16) n1/4

  running time O

(cid:17)

2

6

2

(cid:19)
samples  and runs in time n1/4 · ˜O(cid:0)1/2(cid:1) + (1/)O(log log(1/)).

(cid:18) n1/4

log1/4 1


log2 1/

2

2

+

O

Note that the sample complexity of our algorithm is n1/4 · ˜O(1/2)  matching the information-
theoretic lower bound up to a logarithmic factor in 1/. In particular  our algorithm does not incur
the extraneous Ω(1/6) term of [1]. Moreover  our runtime has a (1/)O(log log(1/)) dependence 
as opposed to (1/)O(log2 1/). The improved running time relies on a more efﬁcient computational

2By the term “non-trivial” here we refer to a testing algorithm that uses fewer samples than just learning the

unknown distribution and then checking whether it is close to a distribution in the family.

2

Distributions (PMDs). Formally  an (n  k)-PMD is any random variable of the form X =(cid:80)n

“projection step” in our general framework  which leverages the geometric structure of Poisson
Binomial distributions.
We remark that the guarantees provided by the above two theorems are actually stronger than the
usual property testing one. Namely  whenever the algorithm returns accept  then it also provides a
(proper) hypothesis H such that dTV (P  H) ≤  with probability at least 3/5.
A broad generalization of PBDs to the high-dimensional setting is the family of Poisson Multinomial
i=1 Xi 
where the Xi’s are independent random vectors supported on the set {e1  e2  . . .   ek} of standard
basis vectors in Rk. We will denote by PMDn k the set of (n  k)-PMDs. PMDs comprise a
broad class of discrete distributions of fundamental importance in computer science  probability 
and statistics. A large body of work in the probability and statistics literature has been devoted
to the study of the behavior of PMDs under various structural conditions [4  41  5  7  47  48].
PMDs generalize the familiar multinomial distribution  and describe many distributions commonly
encountered in computer science (see  e.g.  [25  26  56  53]). Recent years have witnessed a ﬂurry of
research activity on PMDs and related distributions  from several perspectives of theoretical computer
science  including learning [22  21  31  23  32]  property testing [56  52  53]  computational game
theory [25  26  9  24  27  35  17]  and derandomization [37  8  28  36]. We prove the following:
Theorem 3 (Testing PMDs). Given parameters k  n ∈ N and sample access to a distribution over
Nk  there exists an algorithm for T(PMDn k  ) which takes

(cid:18) n(k−1)/4k2k

O

2

(cid:19)

log(k/)k

samples  and runs in time nO(k3) · (1/)O(k3 log(k/)
2O(k5k log(1/)k+2).

log log(k/) )k−1 or alternatively in time nO(k) ·

For the sake of intuition  we note that Theorem 3 is particularly interesting in the regime that n is
large and k is small. Indeed  the sample complexity of testing PMDs is inherently exponential in
k: We prove a sample lower bound of Ωk(n(k−1)/4/2) (Theorem 8) 3 nearly-matching our upper
bound for constant k.
Finally  we demonstrate the versatility of our techniques by obtaining a testing algorithm for discrete
log-concavity. Log-concave distributions constitute a broad and ﬂexible non-parametric family that is
extensively used in modeling and inference [57]. In the discrete setting  log-concave distributions
encompass a range of fundamental types of discrete distributions  including binomial  negative
binomial  geometric  hypergeometric  Poisson  Poisson Binomial  hyper-Poisson  Pólya-Eggenberger 
and Skellam distributions. Log-concave distributions have been studied in a wide range of different
contexts including economics [3]  statistics and probability theory (see [50] for a recent survey) 
theoretical computer science [42]  and algebra  combinatorics and geometry [51]. We will denote by
LCV n the class of log-concave distributions over [n]. We prove:
Theorem 4 (Testing Log-Concavity). Given a parameter n ∈ N and sample access to a distribution
over N  there exists an algorithm for T(LCV n  ) which takes

(cid:18)√

(cid:19)

(cid:18) 1

(cid:19)

+ ˜O

5/2

O

n
2
n · poly(1/)).

√
samples  and runs in time O(

Our discrete log-concavity tester improves on previous work in terms of both sample and time

complexity. Speciﬁcally  [2] gave a log-concavity tester with sample complexity O(cid:0)√
while [11] obtained a tester with sample complexity ˜O(cid:0)√

n/2 + 1/5(cid:1) 
n/7/2(cid:1). Our sample complexity dominates

both these bounds  and is signiﬁcantly better when  is small. The algorithms in [2  11] run in
poly(n/) time  as they involve solving a linear program of poly(n/) size. In contrast  the running
time of our algorithm is sublinear in n.

3Here  we use the notation Ωk(·)  Ok(·) to indicate that the parameter k is seen as a constant.

3

1.3 Our Techniques and Comparison to Previous Work

All the testing algorithms in this paper follow from a simple and general technique that may be of
broader interest. The common property of the underlying distribution families P that allows for our
uniﬁed testing approach is the following: Let P be the probability mass function of any distribution
in P. Then  the Fourier transform of P is approximately sparse  in a well-deﬁned sense.
For concreteness  we elaborate on our technique for the case of SIIRVs. The starting point of our
approach is the observation from [31] that (n  k)-SIIRVs – in addition to having a relatively small
effective support – also have an approximately sparse Fourier representation. Roughly speaking 
most of their Fourier mass is concentrated on a small subset of Fourier coefﬁcients  which can be
computed efﬁciently.
This suggests the following natural approach to testing (n  k)-SIIRVs: ﬁrst  identify the effective
support I of the distribution P and check that it is appropriately small. If it is not  then reject. Then 
compute the corresponding small subset S of the Fourier domain  and check that almost no Fourier
mass of P lies outside S. Otherwise  one can safely reject  as this is a certiﬁcate that P is not an
(n  k)-SIIRV. Combining the two steps  one can show that learning the Fourier transform of P (in
L2-norm) on this small subset S only  is sufﬁcient to learn P itself in total variation distance. The
former goal can be performed with relatively few samples  as S is sufﬁciently small.
At this point  we have obtained a distribution H – succinctly represented by its Fourier transform on S
– such that P and H are close in total variation distance. It only remains to perform a computational
“projection step” to verify that H itself is close to some (n  k)-SIIRV. This will clearly be the case if
indeed P ∈ SIIRV n k.
Although the aforementioned approach forms the core of our SIIRV testing algorithm  the actual tester
has to address separately the case where P has small variance  which can be handled by a testing-via-
learning approach. Our main contribution is thus to describe how to efﬁciently perform the second
step  i.e.  the Fourier sparsity testing. This is done in Theorem 6  which describes a simple algorithm
to perform this step. The algorithm proceeds by essentially considering the Fourier coefﬁcients of
the empirical distribution (obtained by taking a small number of samples). Interestingly  the main
idea underlying Theorem 6 is to avoid analyzing directly the behavior of these Fourier coefﬁcients –
which would naively require too high a time complexity. Instead  we rely on Plancherel’s identity and
reduce the problem to the analysis of a different task: that of the sample complexity of L2 identity
testing (Proposition 1). By a tight analysis of this L2 tester  we get as a byproduct that several Fourier
quantities of interest (of our empirical distribution) simultaneously enjoy good concentration – while
arguing concentration of each of these terms separately would yield a suboptimal time complexity.
A nearly identical method works for PMDs as well. Moreover  our approach can be abstracted to
yield a general testing framework  as we explain in Section 4. It is interesting to remark that the
Fourier transform has been used to learn PMDs and SIIRVs [31  23  32  20]  and therefore it may not
be entirely surprising that it has applications to testing as well. Notably  our Fourier testing technique
gives an improved and nearly-optimal algorithms for log-concavity  for which no Fourier learning
algorithm was known. More generally  testing membership to a class using the Fourier transform is
signiﬁcantly more challenging than learning. A fundamental difference is that in the testing setting
we need to handle distributions that do not belong to the class (e.g.  SIIRVs  PMDs)  but are far
from the class in an arbitrary way. In contrast  learning algorithms work under the promise that the
distribution is in the underlying class  and thus can leverage the speciﬁc structure.

Testing via the Fourier Transform: the Advantage One may wonder how the detour via the
Fourier transform enables us to obtain better sample complexity than an approach purely based on L2
testing. Indeed  all distributions in the classes we consider  crucially  have small L2 norm. For testing
identity to such a distribution P  the standard L2 identity tester (see  e.g.  [14] or Proposition 1)  which
works by checking how large the L2-distance between the empirical and the hypothesis distribution
is  will be optimal. We can thus test membership of a class of such distributions by (i) learning P
assuming it belongs to the class  and then (ii) test whether what we learned is indeed close to P using
the L2 identity tester. The catch is that  in order to get guarantees in L1-distance using this approach 
would require us to learn to very small L2 distance (because of the Cauchy–Schwarz inequality). In
√
particular  if the unknown distribution P has support size N  we would have to learn to L2 distance
/

√
N in (i)  and then in (ii) test that we are within L2-distance /

N of the learned hypothesis.

4

However  if a distribution P has a sparse discrete Fourier transform (whose effective support is
known)  then it sufﬁces to estimate only these few Fourier coefﬁcients [31  33]. This step enables
us to learn P in (i) not just to within L1-distance   but indeed (crucially) within L2-distance √
N
with good sample complexity. Additionally  the identity testing algorithm can be put into a simpler
form for a hypothesis with sparse Fourier transform  as previously mentioned. Now  the tester has
N /2; but if it accepts  then we have learned the distribution P
higher sample complexity  roughly

to within  total variation distance  with much fewer samples than the Ω(cid:0)N/2(cid:1) required for arbitrary

distributions over support size N. Lastly  we note that we can replace the support size N in the above
description by the size of the effective support  i.e.  the smallest set that contains 1 − O() fraction of
the mass. Doing so for the case of (n  k)-SIIRVs leads to a sample complexity proportional to n1/4 
instead of n1/2.

√

1.4 Organization

The rest of the paper is organized as follows: In Section 2  we set up notation and provide deﬁnitions
as well as standard results relevant to our purposes. Section 3 contains the details of one of the main
subroutines our testers rely on  namely for Fourier sparsity testing.In Section 4  we describe our
general approach to obtain a tester applicable to any class of distributions which enjoys good Fourier
sparsity. In Section 5  we state and sketch the proof of our sample complexity lower bound for testing
PMDs. Due to space constraints  most proofs have been deferred to the full version [13].

2 Notation and Deﬁnitions

We begin with some standard notations and deﬁnitions  as well as basics of Fourier analysis and
results from Probability that we shall use throughout the paper. For m ∈ N  we write [m] for the set
{0  1  . . .   m − 1}  and log (resp. ln) for the binary logarithm (resp. the natural logarithm).

Distributions and Metrics A probability distribution over (discrete) domain Ω is a function
P : Ω → [0  1] such that (cid:107)P(cid:107)1
ω∈Ω P(ω) = 1; we denote by ∆(Ω) the set of all probability
distributions over domain Ω. Recall that for two probability distributions P  Q ∈ ∆(Ω)  their total
(cid:80)
variation distance (or statistical distance) is deﬁned as dTV (P  Q) def= supS⊆Ω(P(S) − Q(S)) =
2(cid:107)P − Q(cid:107)1. Given a subset P ⊆ ∆(Ω) of distributions 
ω∈Ω|P(ω) − Q(ω)|  i.e. dTV (P  Q) = 1
the distance from P to P is then deﬁned as dTV (P P) def= inf Q∈P dTV (P  Q). If dTV (P P) >  
we say that P is -far from P; otherwise  it is -close.

1
2

def= (cid:80)

Discrete Fourier Transform Our algorithms will rely heavily on the (discrete) Fourier transform 
whose deﬁnition we recall next.
Deﬁnition 1 (Discrete Fourier Transform). For x ∈ R  we let e(x) def= exp(−2iπx). The Discrete

Fourier Transform (DFT) modulo M of a function F : [n] → C is the function (cid:98)F : [M ] → C deﬁned

as

M

for ξ ∈ [M ]. The DFT modulo M of a distribution P  (cid:98)P  is then the DFT modulo M of its
probability mass function (note that one can then equivalently see(cid:98)P(ξ) as the expectation(cid:98)P(ξ) =
The inverse DFT modulo M onto the range [m  m + M − 1] of (cid:98)F : [M ] → C  is the function

]  for ξ ∈ [M ]).

(cid:16) ξX

EX∼F [e

(cid:17)

M

F : [m  m + M − 1] ∩ Z → C deﬁned by

(cid:98)F (ξ) =

(cid:18) ξj

(cid:19)

n−1(cid:88)

j=0

e

F (j)

F (j) =

1
M

for j ∈ [m  m + M − 1] ∩ Z.

(cid:18)

M−1(cid:88)

e

− ξj
M

(cid:19)(cid:98)F (ξ) 

ξ=0

5

Note that the DFT (modulo M) is a linear operator; moreover  we recall the standard fact relating the
norms of a function and of its Fourier transform  that we will use extensively:
Theorem 5 (Plancherel’s Theorem). For M ≥ n and F  G : [n] → C  we have (i)

(cid:80)M−1
ξ=0 (cid:98)F (ξ)(cid:98)G(ξ); and (ii) (cid:107)F(cid:107)2 = 1√

(cid:107)(cid:98)F(cid:107)2  where (cid:98)F  (cid:98)G are the DFT

j=0 F (j)G(j) = 1
M

(cid:80)n−1

M

modulo M of F  G  respectively.

(The latter equality is sometimes referred to as Parseval’s theorem.) We also note that  for our PMD
testing  we shall need the appropriate generalization of the Fourier transform to the multivariate
setting. We leave this generalization to the full version.

3 Testing Effective Fourier Support

hold simultaneously.

In this section  we prove the following theorem  which will be invoked as a crucial ingredient of
our testing algorithms. Broadly speaking  the theorem ensures one can efﬁciently test whether an
unknown distribution Q has its Fourier transform concentrated on some (small) effective support

distance).
Theorem 6. Given parameters M ≥ 1    b ∈ (0  1]  as well as a subset S ⊆ [M ] and sample
access to a distribution Q over [M ]  Algorithm 1 outputs either reject or a collection of Fourier

S (and if this is the case  learn the vector (cid:98)Q1S  the restriction of this Fourier transform to S  in L2
coefﬁcients(cid:99)H(cid:48) = ((cid:99)H(cid:48)(ξ))ξ∈S such that with probability at least 7/10  all the following statements
2 ≤ 2b and every function Q∗ : [M ] → R with (cid:99)Q∗ supported entirely on S is such
2 ≤ b and there exists a function Q∗ : [M ] → R with (cid:99)Q∗ supported entirely on S

that (cid:107)Q − Q∗(cid:107)2 >   then it outputs reject;
such that (cid:107)Q − Q∗(cid:107)2 ≤ 
4. if it does not output reject  then (cid:107)(cid:98)Q1S −(cid:99)H(cid:48)(cid:107)2 ≤ 
(modulo M) H(cid:48) of the Fourier coefﬁcients(cid:99)H(cid:48) it outputs satisﬁes (cid:107)Q − H(cid:48)(cid:107)2 ≤ 6

√
10 and the inverse Fourier transform

2   then it does not output reject;

2 > 2b  then it outputs reject;

1. if (cid:107)Q(cid:107)2
2. if (cid:107)Q(cid:107)2

3. if (cid:107)Q(cid:107)2

M

5 .

(cid:16)√

b
2 +

|S|
M 2 +

(cid:17)

√

M

samples from Q  and runs in time

Moreover  the algorithm takes m = O
O(m|S|).

Note that the rejection condition in Item 2 is equivalent to (cid:107)(cid:98)Q1 ¯S(cid:107)2 > 
2 ≥ (cid:107)(cid:98)Q1 ¯S − (cid:99)Q∗1 ¯S(cid:107)2
2+(cid:107)(cid:98)Q1 ¯S − (cid:99)Q∗1 ¯S(cid:107)2
and the inequality is tight for Q∗ being the inverse Fourier transform (modulo M) of (cid:98)Q1S.

mass more than 2 outside of S; this is because for any Q∗ supported on S 
M(cid:107)Q − Q∗(cid:107)2

2 = (cid:107)(cid:98)Q1S − (cid:99)Q∗1S(cid:107)2

2 = (cid:107)(cid:98)Q − (cid:99)Q∗(cid:107)2

√

M  that is to having Fourier

2 = (cid:107)(cid:98)Q1 ¯S(cid:107)2

2

2 ≤ b.

High-level idea. Let Q be an unknown distribution supported on M consecutive integers (we will
later apply this to Q def= P mod M)  and S ⊆ [M ] be a set of Fourier coefﬁcients (symmetric with
regard to M: ξ ∈ S implies −ξ mod M ∈ S) such that 0 ∈ S. We can further assume that we know
b ≥ 0 such that (cid:107)Q(cid:107)2

Given Q  we can consider its “truncated Fourier expansion” (with respect to S) (cid:98)H = ˆQ1S deﬁned as
for ξ ∈ [M ]; and let H be the inverse Fourier transform (modulo M) of (cid:98)H. Note that H is no longer

(cid:98)H(ξ) def=

if ξ ∈ S
otherwise

(cid:26) ˆQ(ξ)

0

in general a probability distribution.

6

prove Theorem 6 with a reasonable bound on m.

To obtain the guarantees of Theorem 6  a natural idea is to take some number m of samples from
Q  and consider the empirical distribution Q(cid:48) they induce over [M ]. By computing the Fourier
coefﬁcients (restricted to S) of this Q(cid:48)  as well as the Fourier mass “missed” when doing so (i.e. 
2 that Q(cid:48) puts outside of S) to sufﬁcient accuracy  one may hope to

the Fourier mass (cid:107)(cid:99)Q(cid:48)1 ¯S(cid:107)2
The issue is that analyzing separately the behavior of (cid:107)(cid:99)Q(cid:48)1 ¯S(cid:107)2

2 to show that
they are both estimated sufﬁciently accurately  and both small enough  is not immediate. Instead  we
will get a bound on both at the same time  by arguing concentration in a different manner – namely 
by analyzing a different tester for tolerant identity testing in L2 norm.
In more detail  letting H be as above  we have by Plancherel that

2 and (cid:107)(cid:98)Q1S −(cid:99)Q(cid:48)1S(cid:107)2

(Q(cid:48)(i) − H(i))2 = (cid:107)Q(cid:48) − H(cid:107)2

|(cid:99)Q(cid:48)(ξ) − (cid:98)H(ξ)|2
and  expanding the deﬁnition of (cid:98)H and using Plancherel again  this can be rewritten as
2 − (cid:107)(cid:99)Q(cid:48)1S(cid:107)2

(cid:107)(cid:99)Q(cid:48) − (cid:98)H(cid:107)2
(Q(cid:48)(i) − H(i))2 = (cid:107)(cid:98)Q1S −(cid:99)Q(cid:48)1S(cid:107)2

M (cid:80)

2 + M(cid:107)Q(cid:48)(cid:107)2

M−1(cid:80)

(cid:80)

i∈[M ]

1
M

1
M

2 =

2 =

ξ=0

2.

terms: the ﬁrst  (cid:107)(cid:98)Q1S −(cid:99)Q(cid:48)1S(cid:107)2

2 − (cid:107)(cid:99)Q(cid:48)1S(cid:107)2

(The full derivation will be given in the proof.) The right-hand side has two non-negative compound
2  corresponds to the L2 error obtained when learning the Fourier
2  is the Fourier mass that our

coefﬁcients of Q on S. The second  M(cid:107)Q(cid:48)(cid:107)2
empirical Q(cid:48) puts “outside of S.”
So if the LHS is small (say  order 2)  then in particular both terms of the RHS will be small as
well  effectively giving us bounds on our two quantities in one shot. But this very same LHS is very
reminiscent of a known statistic [14] for testing identity of distributions in L2. So  one can analyze
the number of samples required by analyzing such an L2 tester instead. This is what we will do
in Proposition 1.

2 = (cid:107)(cid:99)Q(cid:48)1 ¯S(cid:107)2

i∈[M ]

√
b
2 +

|S|
M 2 +

1: Set m ←(cid:108)

Algorithm 1 Testing the Fourier Transform Effective Support
Require: parameters M ≥ 1  b   ∈ (0  1]; set S ⊆ [M ]; sample access to distribution Q over [M ]
(cid:46) C > 0 is an absolute constant

(cid:109)

M )

√

C(

2: Draw m(cid:48) ← Poi(m); if m(cid:48) > 2m  return reject
3: Draw m(cid:48) samples from Q  and let Q(cid:48) be the corresponding empirical distribution over [M ]
4: Compute (cid:107)Q(cid:48)(cid:107)2
5: if m(cid:48)2(cid:107)Q(cid:48)(cid:107)2
6: else if (cid:107)Q(cid:48)(cid:107)2
7: else
8:
9: end if

2 (cid:99)Q(cid:48)(ξ) for every ξ ∈ S  and (cid:107)(cid:99)Q(cid:48)1S(cid:107)2
M (cid:107)(cid:99)Q(cid:48)1S(cid:107)2
2 − m(cid:48) > 3
2 − 1
return(cid:99)H(cid:48) = ((cid:99)Q(cid:48)(ξ))ξ∈S

2 bm2 then return reject
+ 1
m(cid:48)

2 ≥ 32(cid:16) m(cid:48)

then return reject

(cid:17)2

m

2

(cid:46) Takes time O(m|S|)

The detailed proof of Theorem 6 is given in the full version.

3.1 A Tolerant L2 Tester for Identity to a Pseudodistribution

As previously mentioned  one building block in the proof of Theorem 6 (and a result that may be
of independent interest) is an optimal L2 identity testing algorithm. Our tester and its analysis are
very similar to the tolerant L2 closeness testing algorithm of Chan et al. [14]  with the obvious
simpliﬁcations pertaining to identity (instead of closeness). The main difference is that we emphasize
here the fact that P∗ need not be an actual distribution: any P∗ : [r] → R would do  even taking
negative values. This will turn out to be crucial for our applications.
Proposition 1. There exists an absolute constant c > 0 such that the above algorithm (Algorithm 2) 
when given Poi(m) samples drawn from a distribution P and an explicit function P∗ : [r] → R will 

7

Algorithm 2 Tolerant L2 identity tester
Require:  ∈ (0  1)  Poi(m) samples from distributions P over [r]  with Xi denoting the number
of occurrences of the i-th domain elements in the samples from P  and P∗ being a ﬁxed  known
pseudo distribution over [r].

Ensure: Returns accept if (cid:107)P − P∗(cid:107)2 ≤  and reject if (cid:107)P − P∗(cid:107)2 ≥ 2.

(cid:46) Can actually be computed in O(m) time

Deﬁne Z =(cid:80)r

Return reject if

i=1(Xi − mP∗(i))2 − Xi.
√
Z
m >

3  accept otherwise.

√

with probability at least 3/4  distinguishes between (a) (cid:107)P − P∗(cid:107)2 ≤  and (b) (cid:107)P − P∗(cid:107)2 ≥ 2
provided that m ≥ c
Moreover  we have the following stronger statement: in case (a)  the statistic Z computed in the
√
algorithm satisﬁes
3.1
with probability at least 3/4.

√
2   where b is an upper bound on (cid:107)P(cid:107)2
m ≤ √

2.9 with probability at least 3/4  while in case (b) we have

m ≥ √

2 (cid:107)P∗(cid:107)2
2.

√

Z

Z

b

4 The General tester

In this section  we provide our general testing framework. In more detail  our theorem (Theorem 7)
has the following ﬂavor: if P is a property of distributions such that every P ∈ P has both (i) small
effective support and (ii) sparse effective Fourier support  then one can test membership to P with
√
sM /2 + s/2) samples (where M and s are the bounds on the effective support and effective
O(
Fourier support  respectively). As a caveat  we do require that the sparse effective Fourier support S
be independent of P ∈ P  i.e.  is a characteristic of the class P itself.
The high-level idea is then quite simple: the algorithm proceeds in three stages  namely the effective
support test  the Fourier effective support test  and the projection step. In the ﬁrst  it takes some
samples from P to identify what should be the effective support I of P  if P did have the property:
and then checks that indeed |I| ≤ M (as it should) and that P puts probability mass 1 − O() on

I. In the second stage  it invokes the Fourier testing algorithm of Section 3 to verify that(cid:98)P indeed

puts very little Fourier mass outside of S; and  having veriﬁed this  learns very accurately the set of
Fourier coefﬁcients of P on this set S  in L2 distance. At this point  either the algorithm has detected
that P violates some required characteristic of the distributions in P  in which case it has rejected
already; or is guaranteed to have learned a good approximation H of P  by the Fourier learning
performed in the second stage. It only remains to perform the third stage  which “projects” this good
approximation H of P onto P to verify that H is close to some distribution P∗ ∈ P (as it should if
indeed P ∈ P).
Theorem 7 (General Testing Statement). Assume P ⊆ ∆(N) is a property of distributions satisfying
the following. There exist S : (0  1] → 2
N  M : (0  1] → N  and qI : (0  1] → N such that  for every
 ∈ (0  1] 

1. Fourier sparsity: for all P ∈ P  the Fourier transform (modulo M ()) of P is concentrated

on S(): namely  (cid:107)(cid:98)P1S()(cid:107)2

≤ 2
100 .

2

such that (i) P is concentrated on I(P): namely  P(I(P)) ≥ 1 − 
identiﬁed with probability at least 19/20 from qI () samples from P.

2. Support sparsity: for all P ∈ P  there exists an interval I(P) ⊆ N with |I(P)| ≤ M ()
5 and (ii) I(P) can be
3. Projection: there exists a procedure PROJECTP which  on input  ∈ (0  1] and the ex-
plicit description of a distribution H ∈ ∆(N)  runs in time T (); and outputs accept if
dTV (H P) ≤ 2

2 (and can answer either otherwise).
4. (Optional) L2-norm bound: there exists b ∈ (0  1] such that  for all P ∈ P  (cid:107)P(cid:107)2

2 ≤ b.
Then  there exists a testing algorithm for P  in the usual standard sense: it outputs either accept or
reject  and satisﬁes the following.

5   and reject if dTV (H P) > 

1. if P ∈ P  then it outputs accept with probability at least 3/5;

8

Algorithm 3 Algorithm Test-Fourier-Sparse-Class
Require: sample access to a distribution P ∈ ∆(N)  parameter  ∈ (0  1]  b ∈ (0  1]  functions

N  M : (0  1] → N  qI : (0  1] → N  and procedure PROJECTP as in Theorem 7

S : (0  1] → 2

1: Effective Support
2:

3:

19/20 if P ∈ P.

Take qI () samples from P to identify a “candidate set” I.
Draw O(1/) samples from P  to distinguish between P(I) ≥ 1 − 
if |I| > M () or we detected that P(I) > 

Correct w.p. 19/20.

4 then

(cid:46) Guaranteed to work w.p.

5 and P(I) < 1 − 

4. (cid:46)

end if

return reject

4:
5:
6:
7:
8: Fourier Effective Support
9:

M () 

√

5


M ()

  b  and S().

Simulating sample access to P(cid:48) def= P mod M ()  call Algorithm 1 on P(cid:48) with parameters

10:
11:
12:
13:

if Algorithm 1 returned reject then

end if

return reject

Let (cid:98)H = ((cid:98)H(ξ))ξ∈S() denote the collection of Fourier coefﬁcients it outputs  and H their

inverse Fourier transform (modulo M ())

(cid:46) Do not actually compute H here.

14:
15: Projection Step
16:
17:

Call PROJECTP on parameters  and H  and return accept if it does  reject otherwise.

(cid:17)

2. if dTV (P P) >   then it outputs reject with probability at least 3/5.

The algorithm takes

O

(cid:32)(cid:112)|S()|M ()

2

|S()|
2 + qI ()

+

(cid:33)

(cid:16)√

samples from P (if Item 4 holds  one can replace the above bound by O
and runs in time O(m|S| + T ())  where m is the sample complexity.
Moreover  whenever the algorithm outputs accept  it also learns P; that is  it provides a hypothesis
H such that dTV (P  H) ≤  with probability at least 3/5.
We remark that the statement of Theorem 7 can be made slightly more general; speciﬁcally  one
can allow the procedure PROJECTP to have sample access to P and err with small probability  and

further provide it with the Fourier coefﬁcients (cid:98)H learnt in the previous step.

bM ()
2 +

);

|S()|
2 + qI ()

5 Lower Bound for PMD Testing

k

(cid:17)

(cid:16)(cid:0) 4π

(cid:1)k/4 n(k−1)/4

In this section  we obtain a lower bound to complement our upper bound for testing Poisson Multino-
mial Distributions. Namely  we prove the following:
Theorem 8. There exists absolute constants c  c(cid:48) ∈ (0  1) such that the following holds. For any
k ≤ nc and  ≥ 1/2c(cid:48)n  any testing algorithm for the class of PMDn k must have sample complexity
Ω
The proof will rely on the lower bound framework of [11]  reducing testing PMDn k to testing
identity to some suitable hard distribution P∗ ∈ PMDn k. To do so  we need to (a) choose a
convenient P∗ ∈ PMDn k; (b) prove that testing identity to P∗ requires that many samples (we
shall do so by invoking the [54] instance-by-instance lower bound method); (c) provide an agnostic
learning algorithm for PMDn k with small enough sample complexity  for the reduction to go
through. Invoking [11  Theorem 18] with these ingredients will then conclude the argument.

2

.

9

References
[1] J. Acharya and C. Daskalakis. Testing Poisson Binomial Distributions. In Proceedings of the Twenty-Sixth

Annual ACM-SIAM Symposium on Discrete Algorithms  SODA  pages 1829–1840  2015.

[2] J. Acharya  C. Daskalakis  and G. Kamath. Optimal testing for properties of distributions. In Proceedings

of NIPS’15  2015.

[3] M. Y. An. Log-concave probability distributions: Theory and statistical testing. Technical Report

Economics Working Paper Archive at WUSTL  Washington University at St. Louis  1995.

[4] A. D. Barbour. Stein’s Method and Poisson Process Convergence. Journal of Applied Probability  25:pp.

175–184  1988.

[5] A.D. Barbour  L. Holst  and S. Janson. Poisson Approximation. Oxford University Press  New York  NY 

1992.

[6] T. Batu  L. Fortnow  R. Rubinfeld  W. D. Smith  and P. White. Testing that distributions are close. In IEEE

Symposium on Foundations of Computer Science  pages 259–269  2000.

[7] V. Bentkus. On the dependence of the Berry-Esseen bound on dimension. Journal of Statistical Planning

and Inference  113:385–402  2003.

[8] A. Bhaskara  D. Desai  and S. Srinivasan. Optimal hitting sets for combinatorial shapes.

In 15th
International Workshop  APPROX 2012  and 16th International Workshop  RANDOM 2012  pages 423–
434  2012.

[9] C. Borgs  J. T. Chayes  N. Immorlica  A. T. Kalai  V. S. Mirrokni  and C. H. Papadimitriou. The myth of

the folk theorem. In STOC  pages 365–372  2008.

[10] C. L. Canonne. A survey on distribution testing: Your data is big. but is it blue? Electronic Colloquium on

Computational Complexity (ECCC)  22:63  2015.

[11] C. L. Canonne  I. Diakonikolas  T. Gouleakis  and R. Rubinfeld. Testing shape restrictions of discrete

distributions. Theory of Computing Systems  2017.

[12] C. L. Canonne  I. Diakonikolas  D. M. Kane  and A. Stewart. Testing conditional independence of discrete

distributions. In STOC  pages 735–748. ACM  2018.

[13] C. L. Canonne  I. Diakonikolas  and A. Stewart. Fourier-based testing for families of distributions. CoRR 

abs/1706.05738  2017. This is the full version of the current paper.

[14] S. Chan  I. Diakonikolas  P. Valiant  and G. Valiant. Optimal algorithms for testing closeness of discrete

distributions. In SODA  pages 1193–1203  2014.

[15] L. Chen  L. Goldstein  and Q.-M. Shao. Normal Approximation by Stein’s Method. Springer  2011.

[16] S.X. Chen and J.S. Liu. Statistical applications of the Poisson-Binomial and Conditional Bernoulli

Distributions. Statistica Sinica  7:875–892  1997.

[17] Y. Cheng  I. Diakonikolas  and A. Stewart. Playing anonymous games using simple strategies.

In
Proceedings of the Twenty-Eighth Annual ACM-SIAM Symposium on Discrete Algorithms  Proceedings of
SODA ’17  pages 616–631  Philadelphia  PA  USA  2017. Society for Industrial and Applied Mathematics.

[18] L. H. Y. Chenz and Y. K. Leong. From zero-bias to discretized normal approximation. 2010.

[19] H. Chernoff. A measure of asymptotic efﬁciency for tests of a hypothesis based on the sum of observations.

Ann. Math. Statist.  23:493–507  1952.

[20] C. Daskalakis  A. De  G. Kamath  and C. Tzamos. A size-free CLT for poisson multinomials and its

applications. In Proceedings of STOC’16  2016.

[21] C. Daskalakis  I. Diakonikolas  R. O’Donnell  R.A. Servedio  and L. Tan. Learning Sums of Independent

Integer Random Variables. In FOCS  pages 217–226  2013.

[22] C. Daskalakis  I. Diakonikolas  and R.A. Servedio. Learning Poisson Binomial Distributions. In STOC 

pages 709–728  2012.

[23] C. Daskalakis  G. Kamath  and C. Tzamos. On the structure  covering  and learning of poisson multinomial

distributions. In FOCS  2015.

10

[24] C. Daskalakis and C. Papadimitriou. On Oblivious PTAS’s for Nash Equilibrium. In STOC  pages 75–84 

2009.

[25] C. Daskalakis and C. H. Papadimitriou. Computing equilibria in anonymous games. In FOCS  pages

83–93  2007.

[26] C. Daskalakis and C. H. Papadimitriou. Discretized multinomial distributions and nash equilibria in

anonymous games. In FOCS  pages 25–34  2008.

[27] C. Daskalakis and C. H. Papadimitriou. Approximate Nash equilibria in anonymous games. Journal of

Economic Theory  2014.

[28] A. De. Beyond the central limit theorem: asymptotic expansions and pseudorandomness for combinatorial

sums. In FOCS  2015.

[29] I. Diakonikolas and D. M. Kane. A new approach for testing properties of discrete distributions. In FOCS 

pages 685–694  2016. Full version available at abs/1601.05557.

[30] I. Diakonikolas  D. M. Kane  and V. Nikishkin. Testing Identity of Structured Distributions. In Proceedings

of SODA’15  2015.

[31] I. Diakonikolas  D. M. Kane  and A. Stewart. Optimal Learning via the Fourier Transform for Sums
of Independent Integer Random Variables. In COLT  volume 49 of JMLR Workshop and Conference
Proceedings  pages 831–849. JMLR.org  2016. Full version available at arXiv:1505.00662.

[32] I. Diakonikolas  D. M. Kane  and A. Stewart. Properly learning Poisson binomial distributions in almost
polynomial time. In Proceedings of the 29th Conference on Learning Theory  COLT 2016  pages 850–878 
2016. Full version available at arXiv:1511.04066.

[33] I. Diakonikolas  D. M. Kane  and A. Stewart. The Fourier Transform of Poisson Multinomial Distri-
butions and its Algorithmic Applications. In Proceedings of STOC’16  2016. Full version available at
arXiv:1511.03592.

[34] D. Dubhashi and A. Panconesi. Concentration of measure for the analysis of randomized algorithms.

Cambridge University Press  Cambridge  2009.

[35] P. W. Goldberg and S. Turchetta. Query complexity of approximate equilibria in anonymous games. J.

Comput. Syst. Sci.  90:80–98  2017.

[36] P. Gopalan  D. M. Kane  and R. Meka. Pseudorandomness via the discrete Fourier transform. In FOCS 

2015.

[37] P. Gopalan  R. Meka  O. Reingold  and D. Zuckerman. Pseudorandom generators for combinatorial shapes.

In STOC  pages 253–262  2011.

[38] W. Hoeffding. Probability inequalities for sums of bounded random variables. Journal of the American

Statistical Association  58:13–30  1963.

[39] J. Kruopis. Precision of approximation of the generalized binomial distribution by convolutions of Poisson

measures. Lithuanian Mathematical Journal  26(1):37–49  1986.

[40] E. L. Lehmann and J. P. Romano. Testing statistical hypotheses. Springer Texts in Statistics. Springer 

2005.

[41] W. Loh. Stein’s method and multinomial approximation. Ann. Appl. Probab.  2(3):536–554  08 1992.

[42] L. Lovász and S. Vempala. The geometry of logconcave functions and sampling algorithms. Random

Structures and Algorithms  30(3):307–358  2007.

[43] J. Neyman and E. S. Pearson. On the problem of the most efﬁcient tests of statistical hypotheses.
Philosophical Transactions of the Royal Society of London. Series A  Containing Papers of a Mathematical
or Physical Character  231(694-706):289–337  1933.

[44] L. Paninski. A coincidence-based test for uniformity given very sparsely-sampled discrete data. IEEE

Transactions on Information Theory  54:4750–4755  2008.

[45] S.D. Poisson. Recherches sur la Probabilitè des jugements en matié criminelle et en matiére civile.

Bachelier  Paris  1837.

11

[46] E. L. Presman. Approximation of binomial distributions by inﬁnitely divisible ones. Theory Probab. Appl. 

28:393–403  1983.

[47] B. Roos. On the Rate of Multivariate Poisson Convergence. Journal of Multivariate Analysis  69(1):120 –

134  1999.

[48] B. Roos. Closeness of convolutions of probability measures. Bernoulli  16(1):23–50  2010.

[49] R. Rubinfeld. Taming big probability distributions. XRDS  19(1):24–28  2012.

[50] A. Saumard and J. A. Wellner. Log-concavity and strong log-concavity: A review. Statist. Surv.  8:45–114 

2014.

[51] Richard P. Stanley. Log-concave and unimodal sequences in algebra  combinatorics  and geometry. Annals

of the New York Academy of Sciences  576(1):500–535  1989.

[52] G. Valiant and P. Valiant. A CLT and tight lower bounds for estimating entropy. Electronic Colloquium on

Computational Complexity (ECCC)  17(179)  2010.

[53] G. Valiant and P. Valiant. Estimating the unseen: an n/ log(n)-sample estimator for entropy and support

size  shown optimal via new CLTs. In STOC  pages 685–694  2011.

[54] G. Valiant and P. Valiant. An automatic inequality prover and instance optimal identity testing. In FOCS 

2014. Conference version of [55].

[55] G. Valiant and P. Valiant. An automatic inequality prover and instance optimal identity testing. SICOMP 

46(1):429–455  2017.

[56] P. Valiant. Testing symmetric properties of distributions. In STOC  pages 383–392  2008.

[57] G. Walther. Inference and modeling with log-concave distributions. Statistical Science  24(3):319–327 

2009.

12

,Clément Canonne
Ilias Diakonikolas
Alistair Stewart