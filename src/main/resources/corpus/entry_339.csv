2010,Accounting for network effects in neuronal responses using L1 regularized point process models,Activity of a neuron  even in the early sensory areas  is not simply a function of its local receptive field or tuning properties  but depends on global context of the stimulus  as well as the neural context. This suggests the activity of the surrounding neurons and global brain states can exert considerable influence on the activity of a neuron. In this paper we implemented an L1 regularized point process model to assess the contribution of multiple factors to the firing rate of many individual units recorded simultaneously from V1 with a 96-electrode Utah" array. We found that the spikes of surrounding neurons indeed provide strong predictions of a neuron's response  in addition to the neuron's receptive field transfer function. We also found that the same spikes could be accounted for with the local field potentials  a surrogate measure of global network states. This work shows that accounting for network fluctuations can improve estimates of single trial firing rate and stimulus-response transfer functions.",Accounting for network effects in neuronal responses

using L1 regularized point process models

Ryan C. Kelly∗

Computer Science Department

Center for the Neural Basis of Cognition

Carnegie Mellon University

Pittsburgh  PA 15213

rkelly@cs.cmu.edu

Robert E. Kass

Department of Statistics

Center for the Neural Basis of Cognition

Machine Learning Department
Carnegie Mellon University

Pittsburgh  PA 15213

kass@stat.cmu.edu

Matthew A. Smith

University of Pittsburgh

Center for the Neural Basis of Cognition

Pittsburgh  PA 15213

masmith@cnbc.cmu.edu

Tai Sing Lee

Computer Science Department

Center for the Neural Basis of Cognition

Carnegie Mellon University

Pittsburgh  PA 15213
tai@cnbc.cmu.edu

Abstract

Activity of a neuron  even in the early sensory areas  is not simply a function of
its local receptive ﬁeld or tuning properties  but depends on global context of the
stimulus  as well as the neural context. This suggests the activity of the surround-
ing neurons and global brain states can exert considerable inﬂuence on the activity
of a neuron. In this paper we implemented an L1 regularized point process model
to assess the contribution of multiple factors to the ﬁring rate of many individ-
ual units recorded simultaneously from V1 with a 96-electrode “Utah” array. We
found that the spikes of surrounding neurons indeed provide strong predictions of
a neuron’s response  in addition to the neuron’s receptive ﬁeld transfer function.
We also found that the same spikes could be accounted for with the local ﬁeld
potentials  a surrogate measure of global network states. This work shows that ac-
counting for network ﬂuctuations can improve estimates of single trial ﬁring rate
and stimulus-response transfer functions.

1

Introduction

One of the most striking features of spike trains is their variability – that is  the same visual stimulus
does not elicit the same spike pattern on repeated presentations. This variability is often considered
to be “noise ” meaning that it is due to unknown factors. Identifying these unknowns should enable
better characterization of neural responses. In the retina  it has recently become possible to record
from a nearly complete population of certain types of ganglion cells in a region and identify the
∗Data was collected by RCK  MAS and Adam Kohn in his laboratory as a part of a collaborative effort
between the Kohn laboratory at Albert Einstein College of Medicine and the Lee laboratory at Carnegie Mellon
University. This work was supported by a National Science Foundation (NSF) Integrative Graduate Education
and Research Traineeship to RCK (DGE-0549352)  National Eye Institute (NEI) grant EY018894 to MAS 
NSF 0635257 and NSF CISE IIS 0713206 to TSL  NIMH grant MH064537 to REK  and NEI grant EY016774
to Adam Kohn. We thank Adam Kohn for collaboration  and we are also grateful to Amin Zandvakili  Xiaoxuan
Jia and Stephanie Wissig for assistance in data collection. We also thank Ben Poole for helpful comments.

1

correlation structure of this population [1]. However  in cerebral cortex  recording a full population
of individual neurons in a region is currently impossible  and large scale recordings in vivo have
been rare. Cross-trial variability is often removed in order to better reveal the effect of a signal of
interest. Classical methods attempt to explain the activity of neurons only in terms of stimulus ﬁlters
or kernels  ignoring sources unrelated to the stimulus.
An increasing number of groups have modeled spiking with point process models [2  3  4] to assess
the relative contributions of speciﬁc sources. Pillow et al.[3] used these methods to model retinal
ganglion cells  and they showed that the responses of cells could be predicted to a large extent
using the activity of nearby cells. We apply this technique to model spike trains in macaque V1 in
vivo using L1 regularized point process models  which for discrete time become Generalized Linear
Models (GLMs) [5]. In addition to incorporating the spike trains of nearby cells  we incorporated a
meaningful summary of local network activity  the local ﬁeld potential (LFP)  and show that it also
can explain an important part of the neuronal variability.

2 L1 regularized Poisson regression

Fitting an unregularized point process model or GLM is simple with any convex optimization
method  but the kind of neural data we have collected typically has a likelihood function that is
relatively ﬂat near its minimum. This is a data constraint: there simply are not enough spikes to
locate the true parameters. To solve this over-ﬁtting problem  we take the approach of regularizing
the GLMs with an L1 penalty (Lasso) on the log-likelihood function. Here we provide some details
of how we ﬁt L1-regularized GLMs using a Poisson noise assumption on data with large dimen-
sionality. In general  a point process may be represented in terms of a conditional intensity function
and  assuming the data (the spike times) are in sufﬁciently small time bins  the resulting likelihood
function may be approximated by a Poisson regression likelihood function. For ease of notation we
leave the spiking history and other covariates implicit and write the conditional intensity (ﬁring rate)
at time t as µ(t). We then model the log of µ(t) as a linear summation of other factors:

log µ(t) =

θjv(t)

j = θV (t)

(1)

where vj is a feature of the data and θj is the corresponding parameter to be ﬁt  and θ = {θ1  ..  θN}.
We deﬁne V to be a N × T matrix (N parameters  T time steps) of variables we believe can impact
the ﬁring rate of a cell  where each column V (t) of V is v(t)
1   ...  v(t)
N   which are the collection of
observables  including input stimulus and measured neural responses.
We deﬁne y = y1...yT   with yt ∈ {0  1} as the observed binary spike train for the cell being
modeled  and let µt = µ(t). The likelihood of the entire spike train is given by:

N(cid:88)

j

We obtain the log-likelihood by substituting Equation 1 into Equation 2 and taking the log:

T(cid:89)

P (Y = y1...yT ) =

(µt)yt exp(−µt)

t

yt!

L(θ) =

(ytθV (t) − exp(θV (t)) − log yt!)

T(cid:88)

t

(2)

(3)

Maximizing the likelihood with L1 penalty is equivalent to ﬁnding the θ that minimizes the following
cost function:

R = −L(θ) +

λj|θj|

(4)

N(cid:88)

j=1

An L1 penalty term drives many of the θi coefﬁcients to zero. Fitting this equation with an L1
constraint is computationally difﬁcult  because many standard convex optimization algorithms are
only guaranteed to converge for differentiable functions. Friedman et al. [5] discuss how coordinate
descent can efﬁciently facilitate GLM ﬁtting on functions with L1 penalties  and they provide a
derivation for the logistic regression case. Here we show a derivation for the Poisson regression
case.

2

˜θ. Then we proceed to minimize RQ = −LQ(θ) +(cid:80)N

j=1 λj|θj|.

We approximate L(θ) with LQ(θ)  a quadratic Taylor series expansion around the current estimate

Given ˜θ  we can compute ˜µ  the current estimate of µ. A coordinate descent step for coordinate j
amounts to the minimization of RQ with respect to θj  for j ∈ 1 . . . N.
dRQ
dθj

j )2−λj

For ˜θj > 0 

j )2 +λj 

T(cid:88)

T(cid:88)

dRQ
dθj

= ωj +θj

= ωj +θj

˜µt(v(t)

˜µt(v(t)

t

t

T(cid:88)

For ˜θj < 0 

(cid:16)−yt + ˜µt − ˜µt(v(t)

(cid:17)

where ωj =

(5)
This is a linear function with positive slope  and a discontinuity at θj = 0. If −λj < ωj < λj 
= 0 when

(cid:54)= 0 and the minimum is at this discontinuity  θj = 0. Otherwise  if |ωj| ≥ λj  dRQ

j

t

˜θj)

v(t)
j

dRQ
dθj

dθj

T(cid:88)
T(cid:88)

t

θj = −(ωj − λj)/(

θj = −(ωj + λj)/(

˜µt(v(t)

j )2) 

for ωj ≥ λj

˜µt(v(t)

j )2) 

for ωj ≤ −λj

(6)

(7)

We cyclically repeat these steps on all parameters until convergence.

t

2.1 Regularization path

To choose efﬁciently a penalty that avoids over-ﬁtting  we implement a regularization path algo-
rithm [6  5]. The algorithm proceeds by computing a sequence of solutions θ(1)  θ(2) . . . θ(L) for
λ(1)  λ(2) . . . λ(L). We standardize V (i.e. make each observable have mean 0 and standard devia-
tion 1) and include a constant term v1  which is not penalized. With this normalization  we set all
λj equal to the same λ  except there is no penalty for v1.
In the coordinate descent method  we start with a λ(1) = λmax = maxj |ωj|  which is large enough
so that all coefﬁcients are dominated by the regularization  and hence all coefﬁcients are 0 for this
heavy penalty. In determining λmax  ωj is computed based on the constant term v1 only. Initially 
the active set A(1) is empty  because λ > λmax. The active set is the set of all coordinates with non-
zero coefﬁcients for which the coordinate descent is being performed. As λ is reduced and becomes
smaller than λmax  more and more non-zero terms will be included in the active set. For step i 
we compute the solution θ(i) using penalty λ(i) and θ(i−1) as a warm start. As the regularization
parameter λ is decreased  the ﬁtted models begin by under-ﬁtting the data (with large λ) and progress
through the regularization path to over-ﬁtting (with small λ). The above algorithm works much faster
when the active set is smaller  and we can halt the algorithm before over-ﬁtting occurs.
The purpose of this regularization path is to ﬁnd the best λ. To quantitatively assess the model ﬁts 
we employ an ROC procedure [7]. To compute the ROC curve based on the conditional intensity
function µ(t)  we ﬁrst create a thresholded version of µ(t) which serves as the prediction of spiking:
(8)
(9)
For each ﬁxed threshold c  a point on the ROC curve is the true positive rate (TPR) versus the false
positive rate (FPR). At each λ in the regularization path  we compute the area under the ROC curve
(AUC) to assess the relative performance of models ﬁt below using a 10-fold cross validation pro-
cedure. An alternative and natural metric is the likelihood value  and the peak of the regularization
path was very similar between AUC and likelihood. We focus on AUC results because it was easier
to relate the AUCs from different cells  some of which had very different likelihood values.

ˆrc(t) =1 if µ(t) ≥ c
0 if µ(t) < c

3 Modeling neural data

We report results from the application of Eq. (4) to neural data. The models here contain combina-
tions of stimulus effects (spatio-temporal receptive ﬁelds)  coupling effects (history terms and past

3

spikes from other cells)  and network effects (given by the LFP). We ﬁnd that cells had different
degrees of contributions from the different terms  ranging from entirely stimulus-dependent cells to
entirely network-dependent cells.

3.1 Methods

The details of the array insertion have been described elsewhere [8]. Brieﬂy  we inserted the ar-
ray 0.6 mm into cortex using a pneumatic insertion device [9]  which led to recordings conﬁned
mostly to layers 2–3 of parafoveal V1 (receptive ﬁelds within 5◦ of the fovea) in an anesthetized
and paralyzed macaque (sufentanil anesthesia). Signals from each microelectrode were ampliﬁed
and bandpass ﬁltered (250 Hz to 7.5 kHz) to acquire spiking data. Waveform segments that ex-
ceeded a threshold (set as a multiple of the rms noise on each channel) were digitized (30 kHz) and
sorted off-line. We ﬁrst performed a principal components analysis by waveform shape [10] and
then reﬁned the output by hand with custom time-amplitude window discrimination software (writ-
ten in MATLAB; MathWorks). We studied the responses of cells to visual stimuli  presented on a
computer screen. All stimuli were generated with custom software on a Silicon Graphics Octane2
Workstation and displayed at a resolution of 1024 × 768 pixels and frame rate of 100 Hz on a CRT
monitor (stimulus intensities were linearized in luminance). We presented Gaussian white noise
movies  with 8 pixel spatial blocks chosen independently from a Gaussian distribution. The movies
were 5◦ in width and height  320 by 320 pixels. The stimuli were all surrounded by a gray ﬁeld of
average luminance. Frames lasted 4 monitor refreshes  so the duration of each frame of noise was
40 ms. The average noise correlation between pairs of cells was 0.256.
The biggest obstacle for ﬁtting models is the huge dimensionality in the number of parameters and
in the large number of observations. To reduce the problem size  we binned the spiking observations
at 10 ms instead of 1 ms. The procedures we used to reduce the parameter sizes are given in the
corresponding sections below. We used cross validation to estimate the performance of the models
on 10 different test sets. Each test set consisted of 12 000 test observations and 180 000 training
observations. The penalty in the regularization path with the largest average area across all the cross
validation runs was considered the optimal penalty.
The full model µ(t) = µSTIM + µCOUP + µLFP has the following form:

For modeling the stimulus alone we used the form

(cid:88)

(cid:88)

(cid:88)

kxyτ sxy(t − τ )

(11)

log µSTIM(t) =

x

y

τ

Here  sxy(t − τ ) is an individual feature of the stimulus τ ms before the current observation (time
t). If we were to use pixel intensities over the last 150 ms (15 observations)  the 320 × 320 movie
would have 1 536 000 parameters  a number far too large for the ﬁtting method and data. We took the
approach of ﬁrst restricting the movie to a much smaller region (40x40 pixels) chosen using spike-
triggered average (STA) maps of the neural responses. Then  we transformed the stimulus space
with overlapping Gaussian bump ﬁlters  which are very similar to basis functions. The separation
of the bump centers was 4 pixels spatially in the 40x40 pixel space  and 2 time points (20 ms). The
total number of parameters was 10 × 10 × 7 = 700  which is 100 parameters for each of 7 distinct
time points. Thus  sxy(t − τ ) corresponds to the convolution of a small Gaussian bump indexed by
x  y  τ with the recent stimulus frames. Figure 1 shows the regularization path for one example cell.
For each model (11)  we chose the λ corresponding to the peak of the regularization path. Figure 2A
shows the k parameters for some example cells transformed back to the original pixel space  with
the corresponding STAs alongside for comparison. The models produce cleaner receptive ﬁelds  a
consequence of the L1 regularization. Figure 2D shows the population results for these models. The
distribution of AUC values is generally low  with many cells near chance (.5)  and a smaller portion
of cells climbing to 0.6 or higher. This suggests that a linear receptive ﬁeld may not be appropriate

4

(cid:88)

(cid:88)

(cid:88)

M(cid:88)

100(cid:88)

E(cid:88)

kxyτ sxy(t − τ ) +

γiri(t − τ ) +

βixi(t)

(10)

x

y

τ

i

τ =1

i

log µ(t) =

3.2 Stimulus effects

Figure 1: Example of ﬁtting a GLM with stimulus terms for a single cell. A: For four L1 penalties
(λ)  the corresponding {ki} are shown  with the STA above for reference. For high λ  the model is
sparser. B: The regularization path for this same cell. λ = 172 is the peak of the AUC curve and is
thus the best model by this metric.

Figure 2: Different GLM types. A: 4 example stimulus models  with the STAs shown for reference.
These models correspond to the AUC peaks of their respective regularization paths. B: 3 example
cells ﬁt with spike coupling models. The coefﬁcients are shown with respect to the cell location on
the array. If multiple cells were isolated on the same electrode  the square is divided into 2 or 3 parts.
Nearby electrodes tend to have more strength in their ﬁtted coefﬁcients. C: 3 example cells ﬁt with
LFP models. As in B  nearby electrodes carry more information about spiking. D-F: Population
results for A-C. These are plots of the AUCs for the 57 cells modeled.

5

τ = 30τ = 50τ = 70τ = 100τ = 1307411727140.50.520.540.560.58λAUCSTAλ = 714λ = 172λ = 41λ = 7AB246810246810ElectrodeElectrodeStimulus model AUC 0.50.550.60.650.7{kxy}20msSTA40ms60msCell at (4 9)80ms100ms{kxy}STACell at (3 4){kxy}STACell at (7 2){kxy}STACell at (7 6)246810246810ElectrodeCoupling model AUC 0.50.60.70.80.9246810246810{γi} [cell at (1 1)] −0.0500.05246810{γi} [cell at (3 5)] −0.200.2246810{γi} [cell at (3 5)] −0.200.2246810246810ElectrodeLFP model AUC 0.50.60.70.80.9246810246810{βi} [cell at (3 1)] −101246810{βi} [cell at (5 4)] −0.200.2246810{βi} [cell at (3 4)] −101Stimulus modelsSpike coupling modelsLFP modelsABCDEFfor many of these cells. In addition  there is an effect of electrode location  with cells with the
highest AUC located on the left side of the array.

3.3 Spike coupling effects

For the coupling terms  we used the history of ﬁring for the other cells recording in the array as well
as the history for the cell being modeled. These take the form:

log µCOUP(t) =

γiri(t − τ )

(12)

i

τ =1

with γi being the coupling strength/coefﬁcient  and ri(t − τ ) being the activity of the ith neuron τ
ms earlier  and M being the number of neurons. Thus the inﬂuence from a surrounding neuron is
computed based on its spike count in the last 100ms. As expected  nearby cells generally had the
largest coefﬁcients (Figure 2B)  indicating that cells in closer proximity tend to have more correla-
tion in their spike trains. We observed a large range of AUC values for these ﬁts (Figure 2E)  from
near chance levels up to .9. There was a signiﬁcant (p < 10−6) negative correlation between the
AUC and the number of nonzero coefﬁcients used in the model. Thus  the units which were well
predicted by the other ﬁring in the population also did not require a large number of parameters to
achieve the best AUC possible. Also apparent in the ﬁgure is that the relationship between spike
train predictability and array location had the opposite pattern of the stimulus model results  with
units toward the left side of the array generally having smaller AUCs based on the population activity
than units on the right side.
The models described above had one parameter per cell in the population  with each parameter
corresponding to the ﬁring over a 100 ms past window. We also ﬁt models with 3 parameters per
cell in the population  corresponding to the spikes in three non-overlapping temporal epochs (1-
20 ms  21-50 ms  51-100 ms). These were considered to be independent parameters  and thus the
active set could contain none  some  or all of these 3 parameters for each cell. The mean AUC across
the population was .01 larger with this increased parameter set  but also the mean active set size was
100 elements larger. We did not attempt to model effects on very short timescales  since we binned
the spikes at 10 ms.

3.4 Network models

The spiking of cells in the population serves to help predict spiking very well for many cells  but the
cause of this relationship remains undetermined. The speciﬁc timing of spikes may play a large role
in predicting spikes  but alternatively the general network ﬂuctuations could be the primary cause.
To disentangle these possibilities  we can model the network state using the LFP as an estimate:

M(cid:88)

100(cid:88)

E(cid:88)

log µLFP(t) =

βixi(t)

(13)

i

Here  E is the number of surrounding electrodes  xi is the LFP value from electrode i  and βi is the
coefﬁcient of the LFP inﬂuence on the spiking activity of the neuron being considered. Figure 2C
shows the model coefﬁcients of several cells when {xi} are the LFP values at time t. The variance in
the coefﬁcient values falls off with increasing distance  with distant electrodes providing relatively
less information about spiking. Across the population  the AUC values for the cells are almost the
same as in the spike coupling models (Figure 2F)  and consequently the spatial pattern of AUC on
the array is almost identical. We also investigated models built using the LFP power in different
frequency bands  and we found that the LFP power in the gamma frequency range (30-80Hz) pro-
duced similar results. With these models  the AUC distributions were remarkably similar to the
models built with spike coupling terms (Figure 2E). The LFP reﬂects activity over a very broad re-
gion  and thus for these data the connectivity between most pairs in the population do not generally
have much more predictive power than the more broad network dynamics. This suggests that much
of the power of the spike coupling terms above is a direct result of both cells being driven by the
underlying network dynamics  rather than by a direct connection between the two cells unrelated

6

Figure 3: Scatter plots of the AUC values for the population under different models and conditions.
A B: The full model improves upon the individual LFP or stimulus models. C: For most cells  trial
shufﬂing the spike trains destroys the effectiveness of the models. D: Taking the network state and
cell spikes into account generally yields a larger AUC than µPSTH.

to the more global dynamics. Models of spike coupling with more precise timing (< 10 ms) may
reﬂect information that these LFP terms would fail to capture.

4 Capturing variability and predicting the PSTH

Neuronal ﬁring has long been accepted to have sources of noise that have typically been ignored or
removed. The simplest conception is that each of these cells has an independent source of intrinsic
noise  and to recover the underlying ﬁring rate function we can simply repeat a stimulus many times.
We have shown above that for many cells  a portion of the noise is not independent from the rest
of the network and is related to other cells and the LFP. The population included a distribution of
cells  and the GLMs showed that some cells included mostly network terms  and other cells included
mostly stimulus terms. For most cells  the models included signiﬁcant contributions from both types
of terms.
From Figure 3A and 3B we can see that the inclusion of network terms does indeed explain more of
the spikes than the stimulus model alone. It is theoretically possible that the LFP or spikes from other
cells are reﬂecting higher order terms of the stimulus-response relationship that the linear model fails
to capture  and the GLM is harnessing these effects to increase AUC. We performed an AUC analysis
on test data from the same neurons: 120 trials of the same 30 second noise movie. Since the stimulus
was repeated we were able to shufﬂe trials. Any stimulus information is present on every trial of this
repeated stimulus  and so if the AUC improvement is entirely due to the network terms capturing
stimulus information  there should be no decrease in AUC in the trial-shufﬂed condition. Figure 3C
shows that this is not the case: trial shufﬂing reduces AUC values greatly across the population. This
means that the network terms are not merely capturing extraneous stimulus effects.
Kelly et al. [11] show that when taking the network state into account with a very simple GLM  the
signal to noise in the stimulus-response relationship was improved. The PSTH is typically used as a
proxy for the stimulus effects. The idea is that any noise terms are averaged out after many trials to
the same repeated stimulus. For the data set of a single repeated noise movie  we made a comparison
of the AUC values computed from the PSTH to the AUC values due to the models. Recall that the
AUC is computed from an ROC analysis on the thresholded µ function. Here  we deﬁne µPSTH to
be the estimated ﬁring rate given by the PSTH. Thus  it is the same function for every trial to the
repeated stimulus. We compared the AUC values in the same manner as in the model procedure
above  building the µPSTH function on 90% of the trials and holding out 10% of the trials for the
ROC computation. Figure 3D shows the comparison: for almost every cell the full model is better
at predicting the spikes than the PSTH itself  even though the stimulus component of the model is
merely a linear ﬁlter.
If the extra-stimulus variability has truly been averaged out of the PSTH  the stimulus-only model
should do equally well in modeling the PSTH as the full model. To compare the ability for different
models to reconstruct the PSTH  we computed the predicted ﬁring rates (µ) to each of the 120 trials
of the same white noise movie  and the predicted PSTH is simply the average of these 120 temporal
functions. We computed these model predictions for the LFP-only model  stimulus-only model 
and full model. Figure 4A shows examples of these simulated PSTHs for these three conditions.
Figure 4B shows the overall results for the population. The stimulus model predicted the PSTH

7

0.60.810.50.60.70.80.91Stimulus model AUCFull model AUC0.60.810.50.60.70.80.91LFP model AUC0.60.810.50.60.70.80.91Trial−shuffled AUC0.60.810.50.60.70.80.91µPSTH AUCABCDFigure 4: A: For an example cell  the ability for different models to predict the PSTH. Taking the
network state into account yields a closer estimate to the PSTH  indicating that the PSTH contains
effects unrelated to the stimulus. B: Population histograms of the PSTH variance explained. Includ-
ing all the terms yields a dramatic increase in the variance explained across the population.

well for some cells  but for most others the stimulus model alone cannot match the full model’s
performance  indicating a corruption of the PSTH by network effects.

5 Conclusions

In this paper we have implemented a L1 regularized point process model to account for stimulus
effects  neuronal interactions and network state effects for explaining the spiking activity of V1 neu-
rons. We have showed the derivation for a form of L1 regularized Poisson regression  and identiﬁed
and implemented a number of computational approaches including coordinate descent and the regu-
larization path. These are crucial for solving the point process model for in vivo V1 data  and to our
knowledge have not been previously attempted on this scale.
Using this model  we have shown that activity of cells in the surrounding population can account
for a signiﬁcant amount of the variance in the ﬁring of many neurons. We found that the LFP 
a broad indicator of the synaptic activity of many cells across a large region (the network state) 
can account for a large share of these inﬂuences from the surrounding cells. This suggests that
these spikes are due to the general network state rather than precise spike timing or individual true
synaptic connections between a pair of cells. This is consistent with earlier observations that the
spiking activity of a neuron is linked to ongoing population activity as measured with optical imaging
[12] and LFP [13]. This link to the state of the local population is an inﬂuential force affecting
the variability in a cell’s spiking behavior.
Indeed  groups of neurons transition between “Up”
(depolarized) and “Down” (hyperpolarized) states  which leads to cycles of higher and lower than
normal ﬁring rates (for review  see [14]). These state transitions occur in sleeping and anesthetized
animals  in cortical slices [15]  as well as in awake animal [16  17] and awake human patients [18 
19]  and might be responsible for generating much of the slow time scale correlation. Our additional
experiments showed similar results are found in experiments with natural movie stimulation.
By directly modeling these sources of variability  this method begins to allow us to obtain better
encoding models and more accurately isolate the elements of the stimulus that are truly driving the
cells’ responses. By attributing portions of ﬁring to network state effects (as indicated by the LFP) 
this approach can obtain more accurate estimates of the underlying connectivity among neurons in
cortical circuits.

8

00.511.522.5302040Full model  R2 = 0.424Spikes/sTime (s)02040Stimulus model  R2 = 0.276Spikes/s02040LFP model  R2 = 0.058Spikes/s µPSTH 00.10.20.30.40.50.605Count0.29Full modelR201020Count0.13Stimulus model01020Count0.10LFP modelABReferences
[1] Jonathon Shlens  Greg D Field  Jeffrey L Gauthier  Martin Greschner  Alexander Sher  Alan M
Litke  and E J Chichilnisky. The structure of large-scale synchronized ﬁring in primate retina.
J Neurosci  29(15):5022–31  Apr 2009.

[2] Wilson Truccolo  Leigh R Hochberg  and John P Donoghue. Collective dynamics in human
and monkey sensorimotor cortex: predicting single neuron spikes. Nat Neurosci  13(1):105–
11  Jan 2010.

[3] Jonathan W Pillow  Jonathon Shlens  Liam Paninski  Alexander Sher  Alan M Litke  E J
Chichilnisky  and Eero P Simoncelli. Spatio-temporal correlations and visual signalling in
a complete neuronal population. Nature  454(7207):995–9  Aug 2008.

[4] Robert E. Kass  Valerie Ventura  and Emory N. Brown. Statistical issues in the analysis of

neuronal data. J Neurophysiol  94:8–25  2005.

[5] Jerome Friedman  Trevor Hastie  and Robert Tibshirani. Regularization paths for generalized

linear models via coordinate descent. Department of Statistics  Jan 2008.

[6] Mee Young Park and Trevor Hastie. L1 regularization path algorithm for generalized lin-
Journal of the Royal Statistical Society: Series B (Statistical Methodology) 

ear models.
69(4):659–677  2007.

[7] Nicholas G Hatsopoulos  Qingqing Xu  and Yali Amit. Encoding of movement fragments in

the motor cortex. J Neurosci  27(19):5105–14  May 2007.

[8] Matthew A Smith and Adam Kohn. Spatial and temporal scales of neuronal correlation in

primary visual cortex. J Neurosci  28(48):12591–603  Nov 2008.

[9] P J Rousche and Richard A Normann. A method for pneumatically inserting an array of

penetrating electrodes into cortical tissue. Ann Biomed Eng  20(4):413–22  Jan 1992.

[10] Shy Shoham  Matthew R Fellows  and Richard A Normann. Robust  automatic spike sorting
using mixtures of multivariate t-distributions. J Neurosci Methods  127(2):111–22  Aug 2003.
[11] Ryan C Kelly  Matthew A Smith  Jason M Samonds  Adam Kohn  A B Bonds  J Anthony
Movshon  and Tai Sing Lee. Comparison of recordings from microelectrode arrays and single
electrodes in the visual cortex. J Neurosci  27(2):261–4  Jan 2007.

[12] M Tsodyks  Tal Kenet  Amiram Grinvald  and A Arieli. Linking spontaneous activity of single
cortical neurons and the underlying functional architecture. Science  286(5446):1943–6  Dec
1999.

[13] Ian Nauhaus  Laura Busse  Matteo Carandini  and Dario L Ringach. Stimulus contrast modu-

lates functional connectivity in visual cortex. Nat Neurosci  12(1):70–6  Jan 2009.

[14] Alain Destexhe and Diego Contreras. Neuronal computations with stochastic network states.

Science  314(5796):85–90  Oct 2006.

[15] Hope A Johnson and Dean V Buonomano. Development and plasticity of spontaneous activity

and up states in cortical organotypic slices. J Neurosci  27(22):5915–25  May 2007.

[16] David A Leopold  Yusuke Murayama  and Nikos K Logothetis. Very slow activity ﬂuctuations
in monkey visual cortex: implications for functional brain imaging. Cereb Cortex  13(4):422–
33  Apr 2003.

[17] Artur Luczak  Peter Barth´o  Stephan L Marguet  Gy¨orgy Buzs´aki  and Kenneth D Harris.
Sequential structure of neocortical spontaneous activity in vivo. Proc Natl Acad Sci USA 
104(1):347–52  Jan 2007.

[18] Biyu J He  Abraham Z Snyder  John M Zempel  Matthew D Smyth  and Marcus E Raichle.
Electrophysiological correlates of the brain’s intrinsic large-scale functional architecture. Proc
Natl Acad Sci USA  105(41):16039–44  Oct 2008.

[19] Yuval Nir  Roy Mukamel  Ilan Dinstein  Eran Privman  Michal Harel  Lior Fisch  Hagar
Gelbard-Sagiv  Svetlana Kipervasser  Fani Andelman  Miri Y Neufeld  Uri Kramer  Amos
Arieli  Itzhak Fried  and Rafael Malach. Interhemispheric correlations of slow spontaneous
neuronal ﬂuctuations revealed in human sensory cortex. Nat Neurosci  11(9):1100–8  Sep
2008.

9

,Hossein Azari Soufiani
Hansheng Diao
Zhenyu Lai
David Parkes