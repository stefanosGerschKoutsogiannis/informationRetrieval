2011,Multiple Instance Filtering,We propose a robust filtering approach based on semi-supervised and multiple instance learning (MIL). We assume that the posterior density would be unimodal if not for the effect of outliers that we do not wish to explicitly model. Therefore  we seek for a point estimate at the outset  rather than a generic approximation of the entire posterior. Our approach can be thought of as a combination of standard finite-dimensional filtering (Extended Kalman Filter  or Unscented Filter) with multiple instance learning  whereby the initial condition comes with a putative set of inlier measurements. We show how both the state (regression) and the inlier set (classification) can be estimated iteratively and causally by processing only the current measurement. We illustrate our approach on visual tracking problems whereby the object of interest (target) moves and evolves as a result of occlusions and deformations  and partial knowledge of the target is given in the form of a bounding box (training set).,Multiple Instance Filtering

Kamil Wnuk

Stefano Soatto

University of California  Los Angeles

{kwnuk soatto}@cs.ucla.edu

Abstract

We propose a robust ﬁltering approach based on semi-supervised and mul-
tiple instance learning (MIL). We assume that the posterior density would
be unimodal if not for the eﬀect of outliers that we do not wish to explic-
itly model. Therefore  we seek for a point estimate at the outset  rather
than a generic approximation of the entire posterior. Our approach can
be thought of as a combination of standard ﬁnite-dimensional ﬁltering (Ex-
tended Kalman Filter  or Unscented Filter) with multiple instance learning 
whereby the initial condition comes with a putative set of inlier measure-
ments. We show how both the state (regression) and the inlier set (classi-
ﬁcation) can be estimated iteratively and causally by processing only the
current measurement. We illustrate our approach on visual tracking prob-
lems whereby the object of interest (target) moves and evolves as a result
of occlusions and deformations  and partial knowledge of the target is given
in the form of a bounding box (training set).

1 Introduction

Algorithms for ﬁltering and prediction have a venerable history studded by quantum leaps by
Wiener  Kolmogorov  Mortensen  Zakai  Duncan among others. Many attempts to expand
ﬁnite-dimensional optimal ﬁltering beyond the linear-Gaussian case failed 1 which explains
in part the resurgence of general-purpose approximation methods for the ﬁltering equation 
such as weak-approximations (particle ﬁlters [6  16]) as well as parametric ones (e.g.  sum-
of-Gaussians or interactive multiple models [5]). Unfortunately  in many applications of
interest  from visual tracking to robotic navigation  the posterior is not unimodal. This has
motivated practitioners to resort to general-purpose approximations of the entire posterior 
mostly using particle ﬁltering. However  in many applications one has reason to believe that
the posterior would be unimodal if not for the eﬀect of outlier measurements  and therefore
the interest is in a point estimate  for instance the mode  mean or median  rather than in the
entire posterior. So  we tackle the problem of ﬁltering  where the data is partitioned into
two unknown subsets (inliers and outliers). Our goal is to devise ﬁnite-dimensional ﬁltering
schemes that will approximate the dominant mode of the posterior distribution  without
explicitly modeling the outliers. There is a signiﬁcant body of related work  summarized
below.

1.1 Prior related work

Our goal is naturally framed in the classical robust statistical inference setting  whereby
classiﬁcation (inlier/outlier) is solved along with regression (ﬁltering). We assume that an
initial condition is available  both for the regressor (state) as well as the inlier distribution.

1Also due to the non-existence of invariant family of distributions for large classes of Fokker-

Planck operators.

1

The latter can be thought of as training data in a semi-supervised setting. Robust ﬁltering
has been approached from many perspectives: Using a robust norm (typically H∞ or (cid:96)1)
for the prediction residual yields worst-case disturbance rejection [14  9]; rejection sampling
schemes in the spirit of the M-estimator [11] “robustify” classical ﬁlters and their extensions.
These approaches work with few outliers  say 10− 20%  but fail in vision applications where
one typically has 90% or more. Our approach relates to recent work in detection-based
tracking [3  10] that use semi-supervised learning [4  18  13]  as well as multiple-instance
learning [2] and latent-SVM models [8  20].

In [3] an ensemble of pixel-level weak classiﬁers is combined on-line via boosting; this is
eﬃcient but suﬀers from drift; [10] improves stability by using a static model trained on
the ﬁrst frame as a prior for labeling new training samples used to update an online clas-
siﬁer. MILTrack [4] addressed the problem of selecting training data for model update so
as to maintain maximum discriminative power. This is related to our approach  except
that we have an explicit dynamical model  rather than a scanning window for detection.
Also  our discrimination criterion operates on a collection of parts/regions rather than a
single template. This allows more robustness to deformations and occlusions. We adopt an
incremental SVM with a fast approximation of a nonlinear kernel [21] rather than online
boosting. Our part based representation and explicit dynamics allow us to better handle
scale and shape changes without the need for a multi-scale image search [4  13]. PROST [18]
proposed a cascade of optical ﬂow  online random forest  and template matching. The P-N
tracker [13] combined a median ﬂow tracker with an online random forest. New training
samples were collected when detections violated structural constraints based on estimated
object position. In an eﬀort to control drift  new training data was not incorporated into
the model until the tracked object returned to a previously conﬁrmed appearance with high
conﬁdence. This meant that if object appearance never returned to the “key frames ” the
online model would never be updated. In the aforementioned works objects are represented
as a bounding box. Several recent approaches have also used segmentation to improve the
reliability of tracking: [17] did not leverage temporal information beyond adjacent frames 
[22] required several annotated input frames with detailed segmentations  and [7] relied on
trackable points on both sides of the object boundary. In all methods above there was no
explicit temporal modeling beyond adjacent frames; therefore the schemes had poor pre-
dictive capabilities. Other approaches have used explicit temporal models together with
sparsity constraints to model appearance changes [15].

We propose a semi-supervised approach to ﬁltering  with an explicit temporal model  that
assumes imperfect labeling  whereby portions of the image inside the bounding box are
“true positives” and others are outliers. This enables us to handle appearance changes  for
instance due to partial occlusions or changes of vantage point.

1.2 Formalization
We denote with x(t) ∈ Rn the state of the model at time t ∈ Z+. It describes a discrete-
time trajectory in a ﬁnite-dimensional (vector) space. This can be thought of as a real-
ization of a stochastic process that evolves via some kind of ordinary diﬀerence equation
x(t + 1) = f (x(t)) + ν(t)  where ν(t) IID∼ pν is a temporally independent and identically
distributed process. We will assume that  possibly after whitening  the components of ν(t)
are independent.
We denote the set of measurements at time t with y(t) = {yi(t)}m(t)
yi(t) ∈ Rk. We
i=1  
assume each can be represented by some ﬁxed dimensionality descriptor  φ : Rk → Rl; (y) →
φ(y).
In classical ﬁltering  the measurements are a known function of the state  y(t) =
h(x(t)) + n(t)  up to the measurement noise  n(t)  that is a realization of a stochastic
process that is often assumed to be temporally independent and identically distributed 
and also independent of ν(t). In our case  however  the components of the measurement
process y1(t)  . . .   ym(t)(t) are divided into two groups: those that behave like standard
measurements in a ﬁltering process  and those that do not.
This distinction is made by an indicator variable χ(t) ∈ {−1  1}m(t) of the same dimension-
ality as the number of measurements  whose values are unknown  and can change over time.

2

For brevity of notation we denote the two sets of indexes as χ(t)+ = {i | χi(t) = 1} and
χ(t)− = {i | χi(t) = −1}. For the ﬁrst set we have that {yi(t)}i∈χ(t)+ = h(x(t)  t)+n(t)  just
like in classical ﬁltering  except that the measurement model h(·  t) is time-varying in a way
that includes singular perturbations  since the number of measurements changes over time 
so the function h : Rn × R → Rm(t); (x  t) (cid:55)→ h(x  t) changes dimension over time. For the
second group  unlike particle ﬁltering  we do not care to model their states  and instead just
discount them as outliers. The measurements are thus samples from a stochastic process
that includes two independent sources of uncertainty: the measurement noise  n(t)  and the
selection process χ(t).

k=1)  where the process χ(t) has to be marginalized.

Our goal is that of determining a point-estimate of the state x(t) given measurements up
to time t. This will be some statistic (the mean  median  mode  etc.) of the conditional
density p(x(t)|{y(k)}t
In order to design a ﬁlter  we ﬁrst consider the full forward model of how the various
samples of the inlier measurements are generated. To this end  we assume that the inlier
set is separable from the outlier set by a hyper-plane in some feature space  represented
by the normal vector w(t) ∈ Rl. So  given the assignment of inliers and outliers χ(t)  we
have that the new maximal-margin boundary can be obtained from w(t − 1) by several
iterations of a stochastic subgradient descent procedure [19]  which for brevity we denote as
w(t) = stochSubgradIters(w(t−1)  y(t)  χ(t)) and describe in Sec. 2 and Sec. 2.2. Conversely 
if we are given the hyperplane w(t)  and state x(t)  the measurements can be classiﬁed via
χ(t) = argminχ E(y(t)  w(t)  x(t)  χ). The energy function  E(y(t)  w(t)  x(t)  χ) depends on
how one chooses to model the object and what side information is applied to constrain the
selection of training data. In the implementation details we give examples of how appearance
continuity can be used as a constraint in this step. Further  motion similarity and occlusion
boundaries could also be used.

Finally  the forward (data-formation) model for a sample (realization) of the measurement
process is given as follows: At time t = 0  we will assume that we have available an initial
distribution p(x0) together with an initial assignment of inliers and outliers χ0  so x(0) ∼
(cid:80)m(0)
p(x0);
χ(0) = χ0. Given χ(0)  we bootstrap our classiﬁer by minimizing a standard
i=1 max(0  1 −
support vector machine cost function: w(1) = argminw( λ
χi(0))(cid:104)w  φ(yi(0))(cid:105))  where λ ∈ R is the tradeoﬀ between the importance of margin size
versus loss. At all subsequent times t  each realization evolves according to:

2||w||2 + 1

m(0)



x(t + 1) = f (x(t)) + v(t) 
w(t + 1) = stochSubgradIters(w(t)  y(t)  χ(t)) 
χ(t) = argminχ E(y(t)  w(t)  x(t)  χ) 
{yi(t)}i∈χ(t)+ = h(x(t)  t) + n(t).

(1)

where the ﬁrst two equations can be thought of as the “model equations” and the last two
as the “measurement equations.” The presence of χ0 makes this a semi-supervised learning
problem  where χ0 is the “training set” for the process χ(t). Note that it is possible for the
model above to proceed in open-loop  when no inliers are present.

The model (1) can easily be extended to the case when the measurement equation is in
implicit form  h(x(t) {yi(t)}i∈χ(t)+  t) = n(t)  since all that matters is the innovation pro-
= h({yi(t)}i∈χ(t)+  ˆx(t)  t). Additional extensions can be entertained where the
.
cess e(t)
dynamics f depends on the classiﬁer w  so that x(t + 1) = f (x(t)  w(t)) + v(t)  and similarly
for the measurement equation h(x(t)  w(t)  t)  although we will not consider them here.

1.3 Application example: Visual tracking with shape and appearance changes

Objects of interest (e.g. humans  cars) move in ways that result in a deformation of their
projection onto the image plane  even when the object is rigid. Further changes of ap-
pearance occur due to motion relative to the light source and partial occlusions. Because
of the ambiguities in shape and appearance  one can ﬁx one factor and model the other.
For instance  one can ﬁx a bounding box (shape) and model change of appearance inside 

3

including outliers (due to occlusion) and inliers (newly visible portions of the object). Al-
ternatively  one can enforce constancy of the reﬂectance function  but then shape changes
as well as illumination must be modeled explicitly  which is complex [12].
Our approach tracks the motion of a bounding box  enclosing the data inliers. Call c(t) ∈ R2
the center of this bounding box  vc(t) ∈ R2 the velocity of the center  d(t) ∈ R2 the
length of the sides of the bounding box  and vd(t) ∈ R2 its rate of change. Thus  we have
x(t) = [c(t)  vc(t)  d(t)  vd(t)]T . As before χ(t) indicates a binary labeling of the measurement
components  where χ(t)+ is the set of samples that correspond to the object of interest. We
have tested diﬀerent versions of our framework where the components are superpixels as
well as trajectories of feature points. For reasons of space limitation  below we describe the
case of superpixels  and report results for trajectories as supplementary material.
Consider a time-varying image I(t) : D ⊂ R2 → R+; (u  v) (cid:55)→ I(u  v  t): superpixels {Si}
are just a partition of the domain D = ∪r
i=1Si with Si ∩ Sj = δij; χ(t) becomes a binary
labeling of the superpixels  with χ(t)+ collecting the indices of elements on the object of
interest  and χ(t)− on the background.
The measurement equation is obtained as the centroid and diameter of the restriction of the
bounding box to the domain of the inlier super-pixels: If y(t) = I(t) ∈ RN×M is an image 
then h1({I(u  v  t)}(u v)∈Si) ∈ R2 is the centroid of the superpixels {Si}i∈χ(t)+ computed
from I(t)  and h2({I(u  v  t)}(u v)∈Si) ∈ R2 is the diameter of the same region. This is in
the form (1)  with h constant (the time dependency is only through y(t) and χ(t)). The

resulting model is: 
(cid:20) I

(cid:21)

0
0

0
I

0
0

0

and n(t) IID∼ N (0  R)  R ∈ R4×4.

2 Algorithm development

x(t + 1) = F x(t) + ν(t)
w(t + 1) = stochSubgradIters(w(t)  y(t)  χ(t))
χ(t) = argminχE(y(t)  w(t)  x(t)  χ)
h(yi(t)i∈χ(t)+) = Cx(t) + n(t)

(2)

(cid:20) I

(cid:21)

where F ∈ R8×8 is block-diagonal with each 4× 4 block given by

  C ∈ R4×8  C =
  and I is the 2 × 2 identity matrix. Similarly  ν(t) IID∼ N (0  Q)  Q ∈ R8×8

I
I

0

 λ

2

Nf(cid:88)

m(cid:88)

t=1

i=1

 .

We focus our discussion in this section on the development of the discriminative appearance
model at the heart of the inlier/outlier classiﬁcation  w(t). For simplicity  pretend for now
that each frame contains m observations.We assume an object is identiﬁed with a subset of
the observations (inliers); at time t  we have {yi(t)}i∈χ(t)+. Also pretend that observations
from all frames  Y = {y(t)}Nf
t=1  were available simultaneously; Nf is the number of frames
If all frames were labeled  (χ(t) known ∀ t)  a maximum margin
in the video sequence.
classiﬁer ˆw could be obtained by minimizing the objective (3) over all samples in all frames:

ˆw = argmin

w

||w||2 +

1

mNf

(cid:96)(w  φ(yi(t))  χi(t))

(3)

where λ ∈ R  and (cid:96)(w  φ(yi(t))  χi(t)) is a loss that ensures data ﬁt. We use the hinge loss
(cid:96)(w  φ(yi(t))  χi(t)) = max(0  1 − χi(t)(cid:104)w  φ(yi(t))(cid:105)) in which slack is implicit  so we can use
an eﬃcient sequential optimization in the primal form.

In reality an exact label assignment at every frame is not available  so we must infer the latent
labeling χ simultaneously while learning the hyperplane w. Continuing our hypothetical
batch processing scenario  pretend we have estimates of some state of the object throughout
time  ˆX = {ˆx(t)}Nf
t=1. This allows us to identify a reduced subset of candidate inliers

4

(cid:33) .

 λ

2

(cid:32) m(cid:88)

Nf(cid:88)

t=1

i=1

(in MIL terminology a positive bag)  within which we assume all inliers are contained. The
speciﬁcation of a positive bag helps reduce the search space  since we can assume all samples
outside of a positive bag are negative. This changes the SVM formulation to a mixed integer
program similar to the mi-SVM [2]  except that [2] assumed a positive/negative bag partition
was given  whereas we use the estimated state and add a term to the decision boundary
cost function to express the dependence between the labeling  χ(t)  and state estimate  ˆx 
at each time:

ˆw  ˆχ = argmin

w χ

||w||2 +

1

mNf

max (0  1 − χi(t)(cid:104)w  φ(yi(t))(cid:105)) + E (y(t)  χ  ˆx(t))

(4)
Here E(y(t)  χ(t)  ˆx(t)) represents a general mechanism to enforce constraints on label assign-
ment on a per-frame basis within a temporal sequence.2 A standard optimization procedure
alternates between updating the decision boundary w  subject to an estimated labeling ˆχ 
followed by relabeling the original data to satisfy the positive bag constraints generated
from the state estimates  ˆx  while keeping w ﬁxed:

 ˆw = argminw

ˆχ = argminχ

(cid:16) λ
(cid:80)Nf
t=1 ((cid:80)m
2||w||2 + 1

mNf

1

mNf

(cid:80)m
i=1 max(0  1 − ˆχi(t)(cid:104)w  φ(yi(t))(cid:105))

(cid:80)Nf
i=1 max(0  1 − χi(t)(cid:104) ˆw  φ(yi(t))(cid:105)) + E(y(t)  χ(t)  ˆx(t))) .

t=1

 

(cid:17)

(5)
In practice  annotation is available only in the ﬁrst frame  and the data must be processed
causally and sequentially. Recently  [19] proposed an eﬃcient incremental scheme  PEGA-
SOS  to solve the hinge loss objective in the primal form. This enables straightforward
incremental training of w as new data becomes available. The algorithm operates on a
training set consisting of tuples of labeled descriptors: T = {(φ(yi)  χi)}m
i=1}. In a nutshell 
at each PEGASOS iteration we select a subset of training samples from the current train-
ing set Aj ⊆ T   and update w according to wj+1 = wj − ηj(cid:53)j. The subgradient of the
hinge loss is given by (cid:53)j = λwj − 1|Aj|
χiφ(yi). To ﬁnalize the update and accelerate
convergence wj+1 is projected onto the set {w : ||w|| ≤ 1√
}  which [19] show is the space
containing the optimal solution.

(cid:80)

i∈Aj

λ

The second objective of Eq. (5) seeks a solution to the binary integer program of inlier
selection given ˆw and ˆx. Instead of tackling this NP-hard problem  we re-interpret it as a
constraint enforcement step based on additional cues within a search area speciﬁed by our the
current state estimate. One example constraint for a superpixel based object representation
is to re-interpret the given objective as a graph cut problem  with pairwise terms enforcing
appearance consistency. See supplementary material for details  as well as for experiments
with other choices of constraints for tracks  rather than superpixels.

Initialization

2.1
At t = 0 we are given initial observations y(0) and a bounding box indicating the object of
interest {c(0) ± d(0)}. We initialize χ(0) with positive indices corresponding to superpixels
that have a majority of their area |yi(0)| within the bounding box:

χi(0) =

|{c(0)±d(0)} ∩ yi(0)|

1 if
|yi(0)|
−1 otherwise.

> y 

(6)

(cid:40)

The area threshold is y = 0.7 throughout all experiments. This represents a bootstrap
training set  T1 from which we learn an initial classiﬁer w(1) for distinguishing object ap-
pearance. Each element of the training set is a triplet (φ(yi(t))  χi(t)  τi = t)  where the
last element is the time at which the feature is added to the training set. We start by
selecting all positive samples and a set number of negatives  nf   sampled randomly from
χ(0)−  giving T1 = {(φ(yi(0))  χi(0)  0)}∀i∈χ(0)+ ∪ {(φ(yj(0))  χj(0)  0) | j ∈ χ(0)−
rand ⊆
χ(0)− |χ(0)−

rand| = nf}.

2It represents the side information necessary to avoid zero information gain in the semi-

supervised inference procedure.

5

2.2 Prediction Step

At time t  given the current estimate of the object state and classiﬁcation χ(t)  we add all
positive samples and diﬃcult negative samples lying outside of the estimated bounding box
to the new training set Tt+1|t. We then propagate the object state with the model of motion
dynamics and ﬁnally update the decision boundary with the newly updated training set.



ˆx(t + 1|t) = F ˆx(t|t)
P (t + 1|t) = F P (t|t)F T + Q
Tt+1
Tt+1 old
Tt+1 new

= Tt+1 old ∪ Tt+1 new
= {(φ(yi)  χi  τi) | χi(cid:104)φ(yi)  w(t)(cid:105) < 1  t − τi ≤ τmax}
= {(φ(yi(t))  χi(t)  t) | χi(t) = 1} ∪
|yi(t)|

{(φ(yi(t)) −1  t) | |D/{ˆc(t|t)± ˆd(t|t)} ∩ yi(t)|

w(t + 1) ← for j = nT   ...  N (update starting with wnT = w(t))

choose Aj ⊆ Tt+1
(cid:80)
nj = 1
λj
wj+1 = (1 − ηjλ)wj + ηj|Aj|
wj+1 = min{1  1/
||wj+1||}wj+1

√

λ

end

i∈Aj

χi(t)φ(yi(t))

≥ 1 − y  (cid:104)φ(yi(t))  w(t)(cid:105) > −1}

(7)
It is typically not necessary to update w at every step  so training data can be collected
over several frames during which w(t + 1) = w(t) and the update above can be invoked
either at some regular interval  on demand  or upon some form of model validation as
in [13]. The parameter τmax determines memory of the classiﬁer update procedure for
diﬃcult examples.
If τmax = 0  no memory is used and training data for model update
consists only of observations from the current image. Such a memory of recent training
samples is analogous to the training cache used in [8] for training the latentSVM model.
During each classiﬁer update we perform N − nT iterations of the stochastic subgradient
descent algorithm  starting from the current best estimate of the separating hyperplane
wnT = w(t). The overall number of iterations N is set as N = 20/λ  where λ is a function
of the bootstrap training set size  λ = 1/(10|T1|). The number in the denominator is used
as a parameter to set the relative importance of the margin size and the loss  but we ﬁx
it at 10 for our experiments. The number of iterations at a new time is then decided by
nT = max(1−|Tt|/N  0.75) in order to limit how much the hyperplane can change in a single
update. These parameters can also be viewed as tuning the learning rates and forgetting
factors of the classiﬁer.

2.3 Update Step
The innovation is in implicit form with h(yi(t + 1)i∈χ(t+1)+) ∈ R4 giving a tight bounding
box around the selected foreground regions in the same form as they appear in the state.
In the update equations r speciﬁes the size of the search region around the predicted state
within which we consider observations as candidates for foreground; ξ speciﬁes the indices
of candidate observations (positive bag).

= λr((cid:2) I

0 (cid:3) diag(CP (t + 1|t)C T ) +(cid:2) 0

I (cid:3) diag(CP (t + 1|t)C T ) 

r
ξ
χ(t + 1)
e(t + 1)
L
ˆx(t + 1|t + 1) = ˆx(t + 1|t) + Le(t + 1)
P (t + 1|t + 1) = (I − LC)P (t + 1|t)(I − LC)T + LRLT .

= {i | |{c(t+1|t)±(d(t+1|t)+r)} ∩ yi(t+1)|
= argminχ∈{−1 1}m E(w(t + 1) {yi(t + 1)}i∈ξ  ˆx(t + 1|t)  χ)
= h(yi(t + 1)i∈χ(t+1)+) − C ˆx(t + 1|t)
= Pt+1|tC T (CPt+1|tC T + R)−1

> Ey} 

|yi(t+1)|



(8)
Above λr ∈ R is a factor (we ﬁx it at 3) for scaling the region size based on ﬁlter covariance.

6

Figure 1: Ski sequence: Left panel shows frame number  search area (black rectangle)  ﬁlter
prediction (blue)  observation (red)  and updated ﬁlter estimate (green). The center panels overlay
the SVM scores for each region (solid blue = −1  solid red = 1). Right panels show the regions
selected as inliers. This challenging sequence includes viewpoint and scale changes  deformation 
changing background. The algorithm performs well and successfully recovers from missed detection
(from frame 349 to 352 shown above).

Figure 2: P-N tracker [13] (above) and MILTrack [4] (below) initialized with the same bounding box
as our approach. Original implementations by the respective authors were used for this comparison.
The P-N tracker fails because of the absence of stable low-level tracks on the target and quickly
locks onto a patch of trees in the background. MILTrack survives longer but does not adapt scale
quickly enough  eventually drifting to become a detector of the tree line.

3 Experiments

To compare with [18  4  13]  we ﬁrst evaluate our discriminative model without maintaining
any training data history τmax = 0 and updating w every 6 frames  with training data
collected between incremental updates. Even with τmax = 0 we can track highly deforming
objects (a skier) with signiﬁcant scale changes through most of the 1496 frames (Fig. 1).
We also recover from errors due to the implicit memory in the decision boundary from
incremental updating. For comparison  [4  13] quickly drift and fail to recover (Fig. 2).

For a quantitative comparison we test our full algorithm against the state of the art on
the PROST dataset [18] consisting of 4 videos with fast motion  occlusions  scale changes 
translucency  and small background motions. In all experiments τmax = 25  and all other
parameters were ﬁxed as described earlier and in supplementary material. Two evaluation
metrics are reported: the mean center location error in pixels [4]  and percentage of correctly
tracked frames as computed by the bounding box overlap criteria area(ROID∩ROIGT )
area(ROID∪ROIGT ) > 0.5 

7

Figure 3: Convergence of the classiﬁer: Samples from frames 113  125  733  and 1435 of the “liquor”
sequence. The leftmost image shows the probabilities returned by the initial classiﬁer trained using
only the ﬁrst frame  the second image shows the foreground probabilities returned from the current
classiﬁer  the third image shows the foreground selection made by the graph-cut step  and the ﬁnal
image shows the smoothed score used to select bounding box location.

where ROID is the detected region and ROIGT is the ground truth region. The ground
truth for the PROST dataset is reported using a constant sized bounding box. Table 1
compares to [18  4  1  13].

In the liquor sequence our method correctly shrinks the bounding box to the label  since the
rest of the bottle is not discriminative. Unfortunately  this is penalized in the Pascal score
since the area ratio drops below 0.5 of the initial bounding box despite perfect tracking. This
causes the score to drop to 18.9. If we modify the criterion to count as valid a detection
where > 99% of the detection area lies within the annotated ground truth region  the score
becomes 75.6%. If we allow for > 90% of the detected area to lie within the ground truth
box  the ﬁnal pascal result for the liquor sequence becomes 79.1%. See Figure 3. The same
phenomenon occurs in the box sequence  where our approach adapts to tracking the label
at the bottom of the box. Note  this additional detection criteria has no eﬀect on any other
scores. Additional results  including failure modes as well as successful tracking where other
approaches fail  are reported in the supplementary material  both for the case of superpixels
and tracks.

ours
P-N [13]
PROST [18]
MILTrack [4]
FragTrack [1]

Overall
pascal
74.7
37.15
80.4
49.2
66.0

board

pascal
92.1
12.9
75.0
67.9
67.9

distance

13.7
139.5
39.0
51.2
90.1

pascal
42.9*
36.9
90.6
24.5
61.4

box

distance

63.7
99.3*
13.0
104.6
57.4

lemming

liquor

pascal
88.1
34.3
70.5
83.6
54.9

distance

19.4
26.4*
25.1
14.9
82.8

pascal
75.6*
64.5
85.4
20.6
79.9

distance

42.5*
17.4*
21.5
165.1
30.7

Table 1: Comparison with recent methods on the PROST dataset. Best scores for each sequence
and metric are shown in bold. Our method and the P-N tracker [13] do not always detect the
object. Ground truthed frames in which no location was reported by the method of [13] were not
counted into the ﬁnal distance score. The method of [13] missed 2 detections on the box sequence 
1 detection on the lemming sequence  and 80 on the liquor sequence. When our approach failed to
detect the object  we used the predicted bounding box from the state of the ﬁlter as our reported
result.
4 Discussion

We have proposed an approach to robust ﬁltering embedding a multiple instance learn-
ing SVM within a ﬁltering framework  and iteratively performing regression (ﬁltering) and
classiﬁcation (inlier selection) in hope of reaching an approximate estimate of the domi-
nant mode of the posterior for the case where other modes are due to outlier processes in
the measurements. We emphasize that our approach comes with no provable properties or
guarantees  other than for the trivial case when the dynamics are linear  the inlier-outlier
sets are linearly separable  the noises are Gaussian  zero-mean  IID white and independent
with known covariance  and when the initial inlier set is known to include all inliers but is
not necessarily pure. In this case  the method proposed converges to the conditional mean
of the posterior p(x(t)|{y(k)}t
k=1). However  we have provided empirical validation of our
approach on challenging visual tracking problems  where it exceeds the state of the art  and
illustrated some of its failure modes.

8

Acknowledgment: Research
N000141110863  and DARPA FA8650-11-1-7156.

supported

by AFOSR FA9550-09-1-0427  ONR

References

[1] A. Adam  E. Rivlin  and I. Shimshoni. Robust fragments-based tracking using the integral

histogram. In Proc. CVPR  2006.

[2] S. Andrews  I. Tsochantaridis  and T. Hofmann. Support vector machines for multiple-instance

learning. In Proc. NIPS  2003.

[3] S. Avidan. Ensemble tracking. PAMI  29:261–271  2007.

[4] B. Babenko  M.-H. Yang  and S. Belongie. Visual tracking with online multiple instance

learning. In Proc. CVPR  2009.

[5] Y. Bar-Shalom and X.-R. Li. Estimation and tracking: principles  techniques and software.

YBS Press  1998.

[6] A. Doucet  N. de Freitas  and N. Gordon. Sequential monte carlo methods in practice. Springer

Verlag  New York  2001.

[7] J. Fan  X. Shen  and Y. Wu. Closed-loop adaptation for robust tracking. In Proc. ECCV 

2010.

[8] P. Felzenszwalb  D. Girshick  D. McAllester  and D. Ramanan. Object detection with discrim-

inatively trained part based models. In PAMI  2010.

[9] L. El Ghaoui and G. Calaﬁore. Robust ﬁltering for discrete-time systems with structured

uncertainty. In IEEE Transactions on Automatic Control  2001.

[10] H. Grabner  C. Leistner  and H. Bischof. Semi-supervised on-line boosting for robust tracking.

In Proc. ECCV  2008.

[11] P.J. Huber. Robust Statistics. Wiley  New York  1981.

[12] J. Jackson  A. J. Yezzi  and S. Soatto. Dynamic shape and appearance modeling via moving

and deforming layers. IJCV  79(1):71–84  August 2008.

[13] Z. Kalal  J. Matas  and K. Mikolajczyk. P-n learning: Bootstrapping binary classiﬁers by

structural constraints. In Proc. CVPR  2010.

[14] H. Li and M. Fu. A linear matrix inequality approach to robust h∞ ﬁltering. IEEE Transactions

on Signal Processing  45(9):2338–2350  September 1997.

[15] H. Lim  V. Morariu  O. Camps  and M. Sznaier. Dynamic appearance modeling for human

tracking. In Proc. CVPR  2006.

[16] J. Liu. Monte carlo strategies in scientiﬁc computing. SPringer Verlag  2001.

[17] X. Ren and J. Malik. Tracking as repeated ﬁgure/ground segmentation. In Proc. CVPR  2007.

[18] J. Santner  C. Leistner  A. Saﬀari  T. Pock  and H. Bischof. PROST Parallel Robust Online

Simple Tracking. In Proc. CVPR  2010.

[19] S. Shalev-Shwartz  Y. Singer  and N. Srebro. Pegasos: Primal estimated sub-gradient solver

for svm. In Proc. ICML  2007.

[20] I. Tsochantaridis  T. Joachims  T. Hofmann  and Y. Altun. Large margin methods for struc-

tured and interdependent output variables. JMLR  6:1453–1484  September 2005.

[21] A. Vedaldi and A. Zisserman. Eﬃcient additive kernels via explicit feature maps. In Proc.

CVPR  2010.

[22] Z. Yin and R. T. Collins. Shape constrained ﬁgure-ground segmentation and tracking. In Proc.

CVPR  2009.

9

,Rajesh Ranganath
Dustin Tran
Jaan Altosaar
David Blei