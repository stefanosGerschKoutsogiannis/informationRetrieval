2019,Universality and individuality in neural dynamics across large populations of recurrent networks,Many recent studies have employed task-based modeling with recurrent neural networks (RNNs) to infer the computational function of different brain regions. These models are often assessed by quantitatively comparing the low-dimensional neural dynamics of the model and the brain  for example using canonical correlation analysis (CCA). However  the nature of the detailed neurobiological inferences one can draw from such efforts remains elusive. For example  to what extent does training neural networks to solve simple tasks  prevalent in neuroscientific studies  uniquely determine the low-dimensional dynamics independent of neural architectures?  Or alternatively  are the learned dynamics highly sensitive to different neural architectures?  Knowing the answer to these questions has strong implications on whether and how to use task-based RNN modeling to understand brain dynamics. To address these foundational questions  we study populations of thousands of networks of commonly used RNN architectures trained to solve neuroscientifically motivated tasks and characterize their low-dimensional dynamics via CCA and nonlinear dynamical systems analysis. We find the geometry of the dynamics can be highly sensitive to different network architectures  and further find striking dissociations between geometric similarity as measured by CCA and network function  yielding a cautionary tale. Moreover  we find that while the geometry of neural dynamics can vary greatly across architectures  the underlying computational scaffold: the topological structure of fixed points  transitions between them  limit cycles  and linearized dynamics  often appears {\it universal} across all architectures.  Overall  this analysis of universality and individuality across large populations of RNNs provides a much needed foundation for interpreting quantitative measures of dynamical similarity between RNN and brain dynamics.,Universality and individuality in neural dynamics
across large populations of recurrent networks

Niru Maheswaranathan∗
Google Brain  Google Inc.

Mountain View  CA
nirum@google.com

Alex H. Williams∗
Stanford University

Stanford  CA

ahwillia@stanford.edu

Matthew D. Golub
Stanford University

Stanford  CA

mgolub@stanford.edu

Surya Ganguli

Stanford University and Google Brain
Stanford  CA and Mountain View  CA

sganguli@stanford.edu

David Sussillo†

Google Brain  Google Inc.

Mountain View  CA

sussillo@google.com

Abstract

Task-based modeling with recurrent neural networks (RNNs) has emerged as a
popular way to infer the computational function of different brain regions. These
models are quantitatively assessed by comparing the low-dimensional neural rep-
resentations of the model with the brain  for example using canonical correlation
analysis (CCA). However  the nature of the detailed neurobiological inferences
one can draw from such efforts remains elusive. For example  to what extent does
training neural networks to solve common tasks uniquely determine the network
dynamics  independent of modeling architectural choices? Or alternatively  are
the learned dynamics highly sensitive to different model choices? Knowing the
answer to these questions has strong implications for whether and how we should
use task-based RNN modeling to understand brain dynamics. To address these
foundational questions  we study populations of thousands of networks  with com-
monly used RNN architectures  trained to solve neuroscientiﬁcally motivated tasks
and characterize their nonlinear dynamics. We ﬁnd the geometry of the RNN
representations can be highly sensitive to different network architectures  yielding
a cautionary tale for measures of similarity that rely on representational geometry 
such as CCA. Moreover  we ﬁnd that while the geometry of neural dynamics
can vary greatly across architectures  the underlying computational scaffold—the
topological structure of ﬁxed points  transitions between them  limit cycles  and
linearized dynamics—often appears universal across all architectures.

1

Introduction

The computational neuroscience community is increasingly relying on deep learning both to directly
model large-scale neural recordings [1  2  3] as well to train neural networks on computational tasks
and compare the internal dynamics of such trained networks to measured neural recordings [4  5  6  7 
8  9]. For example  several recent studies have reported similarities between the internal represen-
tations of biological and artiﬁcial networks [5  10  11  12  13  14  15  16]. These representational
similarities are quite striking since artiﬁcial neural networks clearly differ in many ways from their
much more biophysically complex natural counterparts. How then  should we scientiﬁcally interpret

∗Equal contribution.
†Corresponding author.

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

the striking representational similarity of biological and artiﬁcial networks  despite their vast disparity
in biophysical and architectural mechanisms?
A fundamental impediment to achieving any such clear scientiﬁc interpretation lies in the fact that
inﬁnitely many model networks may be consistent with any particular computational task or neural
recording. Indeed  many modern applications of deep learning utilize a wide variety of recurrent
neural network (RNN) architectures [17  18  19  20]  initialization strategies [21] and regularization
terms [22  23]. Moreover  new architectures continually emerge through large-scale automated
searches [24  25  26]. This dizzying set of modelling degrees of freedom in deep learning raises
fundamental questions about how the degree of match between dynamical properties of biological
and artiﬁcial networks varies across different modelling choices used to generate RNNs.
For example  do certain properties of RNN dynamics vary widely across individual architectures?
If so  then a high degree of match between these properties measured in both an artiﬁcial RNN
and a biological circuit might yield insights into the architecture underlying the biological circuit’s
dynamics  as well as rule out other potential architectures. Alternatively  are other properties of RNN
dynamics universal across many architectural classes and other modelling degrees of freedom? If
so  such properties are interesting neural invariants determined primarily by the task  and we should
naturally expect them to recur not only across diverse classes of artiﬁcial RNNs  but also in relevant
brain circuits that solve the same task. The existence of such universal properties would then provide
a satisfying explanation of certain aspects of the match in internal representations between biological
and artiﬁcial RNNs  despite many disparities in their underlying mechanisms.
Interestingly  such universal properties can also break the vast design space of RNNs into different
universality classes  with these universal dynamical properties being constant within classes  and
varying only between classes. This offers the possibility of theoretically calculating or understanding
such universal properties by analyzing the simplest network within each universality class3. Thus
a foundational question in the theory of RNNs  as well as in their application to neuroscientiﬁc
modelling  lies in ascertaining which aspects of RNN dynamics vary across different architectural
choices  and which aspects—if any—are universal across such choices.
Theoretical clarity on the nature of individuality and universality in nonlinear RNN dynamics is
largely lacking4  with some exceptions [29  30  31  32]. Therefore  with the above neuroscientiﬁc
and theoretical motivations in mind  we initiate an extensive numerical study of the variations in
RNN dynamics across thousands of RNNs with varying modelling choices. We focus on canonical
neuroscientiﬁcally motivated tasks that exemplify basic elements of neural computation  including
the storage and maintenance of multiple discrete memories  the production of oscillatory motor-like
dynamics  and contextual integration in the face of noisy evidence [33  4].
To compare internal representations across networks  we focused on comparing the geometry of
neural dynamics using common network similarity measures such as singular vector canonical
correlation analysis (SVCCA) [34] and centered kernel alignment (CKA) [35]. We also used tools
from dynamical systems analysis to extract more topological aspects of neural dynamics  including
ﬁxed points  limit cycles  and transition pathways between them  as well as the linearized dynamics
around ﬁxed points [33]. We focused on these approaches because comparisons between artiﬁcial
and biological network dynamics at the level of geometry  and topology and linearized dynamics  are
often employed in computational neuroscience.
Using these tools  we ﬁnd that different RNN architectures trained on the same task exhibit both
universal and individualistic dynamical properties. In particular  we ﬁnd that the geometry of neural
representations varies considerably across RNNs with different nonlinearities. We also ﬁnd surprising
dissociations between dynamical similarity and functional similarity  whereby trained and untrained
architectures of a given type can be more similar to each other than trained architectures of different
types. This yields a cautionary tale for using SVCCA or CKA to compare neural geometry  as
these similarity metrics may be more sensitive to particular modeling choices than to overall task
performance. Finally  we ﬁnd considerably more universality across architectures in the topological

3This situation is akin to that in equilibrium statistical mechanics in which physical materials as disparate
as water and ferromagnets have identical critical exponents at second order phase transitions  by virtue of the
fact that they fall within the same universality class [27]. Moreover  these universal critical exponents can be
computed theoretically in the simplest model within this class: the Ising model.

4Although Feigenbaum’s analysis [28] of period doubling in certain 1D maps might be viewed as an analysis

of 1D RNNs.

2

structure of ﬁxed points  limit cycles  and speciﬁc properties of the linearized dynamics about ﬁxed
points. Thus overall  our numerical study provides a much needed foundation for understanding
universality and individuality in network dynamics across various RNN models  a question that is
both of intrinsic theoretical interest  and of importance in neuroscientiﬁc applications.

2 Methods

2.1 Model Architectures and Training Procedure

We deﬁne an RNN by an update rule  ht = F (ht−1  xt)  where F denotes some nonlinear function
of the network state vector ht−1 ∈ RN and the network input xt ∈ RM . Here  t is an integer index
denoting discrete time steps. Given an initial state  h0  and a stream of T inputs  x1  x2  . . .  xT   the
RNN states are recursively computed  h1  h2  . . .  hT . The model predictions are based on a linear
readout of these state vector representations of the input stream. We studied 4 RNN architectures  the
vanilla RNN (Vanilla)  the Update-Gate RNN (UGRNN; [20])  the Gated Recurrent Unit (GRU; [18]) 
and the Long-Short-Term-Memory (LSTM; [17]). The equations for these RNNs can be found in
Appendix A. For each RNN architecture we modiﬁed the (non-gate) point-wise activation function to
be either rectiﬁed linear (relu) or hyperbolic tangent (tanh). The point-wise activation for the gating
units is kept as a sigmoid.
We trained networks for every combination of the following parameters: RNN architecture (Vanilla 
UGRNN  LSTM  GRU)  activation (relu  tanh)  number of units/neurons (64  128  256)  and L2
regularization (1e-5  1e-4  1e-3  1e-2). This yielded 4×2×3×4 = 96 unique conﬁgurations. For each
one of these conﬁgurations  we performed a separate random hyperparameter search over gradient
clipping values [22] (logarithmically spaced from 0.1 to 10) and the learning rate schedule parameters.
The learning rate schedule is an exponentially decaying schedule parameterized by the initial rate
(with search range from 1e-5 to 0.1)  decay rate (0.1 to 0.9)  and momentum (0 to 1). All networks
were trained using stochastic gradient descent with momentum [36  37] for 20 000 iterations with
a batch size of 64. For each network conﬁguration  we selected the best hyperparameters using a
validation set. We additionally trained each of these conﬁgurations with 30 random seeds  yielding
2 880 total networks for analysis for each task. All networks achieve low error; histograms of the
ﬁnal loss values achieved by all networks are available in Appendix C.

2.2 Tasks

We used three canonical tasks that have been previously studied in the neuroscience literature:

K-bit ﬂip-ﬂop Following [33]  RNNs were provided K inputs taking discrete values in
{−1  0  +1}. The RNN has K outputs  each of which is trained to remember the last non-zero
input on its corresponding input. Here we set K = 3  so e.g. output 2 remembers the last non-zero
state of input 2 (+1 or -1)  but ignores inputs 1 and 3. We set the number of time steps  T   to 100  and
the ﬂip probability (the probability of any input ﬂipping on a particular time step) to 5%.

Frequency-cued sine wave Following [33]  RNNs received a static input  x ∼ Uniform(0  1)  and
were trained to produce a unit amplitude sine wave  sin(2πωt)  whose frequency is proportional to
the input: ω = 0.04x + 0.01. We set T = 500 and dt = 0.01 (5 simulated seconds total).

Context-dependent integration (CDI) Following previous work [4]  RNNs were provided with
K static context inputs and K time-varying white noise input streams. On each trial  all but one
context input was zero  thus forming a one-hot encoding indicating which noisy input stream of
length T should be integrated. The white noise input was sampled from N (µ  1) at each time step 
with µ sampled uniformly between -1 and 1 and kept static across time for each trial. RNNs were
trained to report the cumulative sum of the cued white-noise input stream across time. Here  we set
K = 2 and T = 30.

3

2.3 Assessing model similarity

The central questions we examined were: how similar are the representations and dynamics of
different RNNs trained on the same task? To address this  we use approaches that highlight different
but sometimes overlapping aspects of RNN function:

SVCCA and CKA to assess representational geometry We quantiﬁed similarity at the level of
representational geometry [38]. In essence  this means quantifying whether the responses of two
RNNs to the same inputs are well-aligned by some kind of linear transformation.
We focused on singular vector canonical correlations analysis (SVCCA; [34])  which has found
traction in both neuroscience [12] and machine learning communities [39  15]. SVCCA compares
representations in two steps. First  each representation is projected onto their top principal components
to remove the effect of noisy (low variance) directions. Typically  the number of components is
chosen to retain ~95% of the variance in the representation. Then  canonical correlation analysis
(CCA) is performed to ﬁnd a linear transformation that maximally correlates the two representations.
This yields R correlation coefﬁcients  1 ≥ ρ1 ≥ . . . ≥ ρR ≥ 0  providing a means to compare the
two datasets  typically by averaging or summing the coefﬁcients (see Appendix D for further details).
In addition to SVCCA  we explored a related metric  centered kernel alignment (CKA; [35]). CKA
is related to SVCCA in that it also suppresses low variance directions  however CKA weights the
components proportional to the singular value (as opposed to removing some completely). We
found that using SVCCA and CKA yielded similar results for the purposes of determining whether
representations cluster by architecture or activation function so we present SVCCA results in the
main text but provide a comparison with CKA in Appendix E.

1  h∗

i ≈ F (h∗

2  ...} of an RNN such that h∗

Fixed point topology to assess computation An alternative perspective to representational geom-
etry for understanding computation in RNNs is dynamics. We studied RNN dynamics by reducing
their nonlinear dynamics to linear approximations. Brieﬂy  this approach starts by optimizing to ﬁnd
the ﬁxed points {h∗
i   x∗). We use the term ﬁxed point to
also include approximate ﬁxed points  which are not truly ﬁxed but are nevertheless very slow on the
time scale of the task.
We set the input (x∗) to be static when ﬁnding ﬁxed points. These inputs can be thought of as
specifying different task conditions. In particular  the static command frequency in the sine wave task
and the hot-one context signal in the CDI task are examples of such condition specifying inputs. Note
however  that dimensions of x that are time-varying are set to 0 in x∗. In particular  the dimensions
of the input that represent the input pulses in the 3-bit memory task and the white noise input streams
in the CDI task are set to 0 in x∗.
Numerical procedures for identifying ﬁxed points are discussed in [33  40]. Around each ﬁxed point 
the local behavior of the system can be approximated by a reduced system with linear dynamics:

ht ≈ h∗ + J(h∗  x∗) (ht−1 − h∗)  
where Jij(h∗  x∗) = ∂Fi(h∗ x∗)
denotes the Jacobian of the RNN update rule. We studied these
linearized systems using the eigenvector decomposition for non-normal matrices (see Appendix B
for the eigenvector decomposition). In this analysis  both the topology of the ﬁxed points and the
linearizations around those ﬁxed points become objects of interest.

∂h∗

j

Visualizing similarity with multi-dimensional scaling For each analysis  we computed network
similarity between all pairs of network conﬁgurations for a given task  yielding a large (dis-)similarity
matrix for each task (for example  we show this distance matrix for the ﬂip-ﬂop task in Fig. 1c). To
visualize the structure in these matrices  we used multi-dimensional scaling (MDS) [41] to generate
a 2D projection which we used for visualization (Fig. 1d and f  Fig. 2c and e  Fig. 3c and d). For
visualization purposes  we separate plots colored by RNN architecture (for a ﬁxed nonlinearity  tanh)
and nonlinearity (for a ﬁxed architecture  Vanilla).

3 Results

The major contributions in this paper are as follows. First  we carefully train and tune large populations
of RNNs trained on several canonical tasks relating to discrete memory [33]  pattern generation [33] 

4

Figure 1: 3-bit discrete memory. a) Inputs (black) of -1 or 1 come in at random times while the corresponding
output (dashed red) has to remember the last non-zero state of the input (either +1 or -1). b) Example PCA
trajectories of dynamics for an example architecture and activation function. c) Dynamics across networks
are compared via SVCCA and given a distance (one minus the average correlation coefﬁcient)  yielding a
network-network distance matrix. d) This distance matrix is used to create a 2D embedding via multidimensional
scaling (MDS) of all networks  showing clustering based on RNN architecture (left) and activation function
(right). e) Topological analysis of a network using ﬁxed points. First  the ﬁxed points of a network’s dynamics
are found  and their linear stability is assessed (left  black dots - stable ﬁxed points  red - one unstable dimension 
green - 2 unstable dimensions  blue - 3 unstable dimensions. By studying heteroclinic and homoclinic orbits  the
ﬁxed point structure is translated to a graph representation (right). f) This graph representation is then compared
across networks  creating another network-network distance matrix. The distance matrix is used to embed the
network comparisons into 2D space using MDS  showing that the topological representation of a network using
ﬁxed point structure is more similar across architectures (left) and activation functions (right) than the geometry
of the network is (layout as in 1d).

and analog memory and integration [4]. Then  we show that representational geometry is sensitive
to model architecture (Figs. 1-3). Next  we show all RNN architectures  including complex  gated
architectures (e.g. LSTM and GRU) converge to qualitatively similar dynamical solutions  as
quantiﬁed by the topology of ﬁxed points and corresponding linearized dynamics (Figs. 1-3). Finally 
we highlight a case where SVCCA is not necessarily indicative of functional similarity (Fig. 4).

3.1

3-bit discrete memory

We trained RNNs to store and report three discrete binary inputs (Fig. 1a). In Fig. 1b  we use a simple
“probe input” consisting of a series of random inputs to highlight the network structure. Across all
network architectures the resulting trajectories roughly trace out the corners of a three-dimensional
cube. While these example trajectories look qualitatively similar across architectures  SVCCA
revealed systematic differences. This is visible in the raw SVCCA distance matrix (Fig. 1c)  as well
as in low-dimensional linear embeddings achieved by applying multi-dimensional scaling (MDS)
(Fig. 1d) created using the SVCCA distance matrix.
To study the dynamics of these networks  we ran an optimization procedure [40] to numerically
identify ﬁxed points for each trained network (see Methods). A representative network is shown in
Fig. 1e (left). The network solves the task by encoding all 23 possible outputs as 8 stable ﬁxed points.
Furthermore  there are saddle points with one  two  or three unstable dimensions (see caption)  which
route the network activity towards the appropriate stable ﬁxed point for a given input.
We devised an automated procedure to quantify the computational logic of the ﬁxed point structure
in Fig. 1e that effectively ignored the precise details in the transient dynamics and overall geometry
of the 3D cube evident in the PCA trajectories. Speciﬁcally  we distilled the dynamical trajectories
into a directed graph  with nodes representing ﬁxed points  and weighted edges representing the
probability of moving from one ﬁxed point to another when starting the initial state a small distance

5

(a)Flip-floptaskschematicgraphrepresentationPCAtrajectories(f)NetworksimilarityusingfixedpointtopologyMDStanhreluUGRNNVanillaGRULSTM(d)NetworksimilarityusingSVCCAMDS(b)PCATrajectoriesPC#1PC#2PC#3(c)SVCCADistances(e)FixedpointtopologyFigure 2: Sine wave generation. a) Schematic showing conversion of static input specifying a command
frequency  ω  for the sine wave output sin(2πωt). b) PCA plots showing trajectories using many evenly divided
command frequencies delivered one at a time (blue: smallest ω  yellow: largest ω). c) MDS plots based on
SVCCA network-network distances  layout as in Fig. 1d. d) Left  ﬁxed points (colored circles  with color
indicating ω  one ﬁxed point per command frequency) showing a single ﬁxed point in the middle of each
oscillatory trajectory. Right  the complex eigenvalues of all the linearized systems  one per ﬁxed point  overlayed
on top of each other  with primary oscillatory eigenvalues colored as in panel b. e) MDS network-network
distances based on ﬁxed point topology  assessing systematic differences in the topology of the input-dependent
ﬁxed points (layout as in Fig. 1d). f) Summary analysis showing the frequency of the oscillatory mode in the
linearized system vs. command frequency for different architectures (left) and activations (right). Solid line and
shaded patch show the mean ± standard error over networks trained with different random seeds. Small  though
systematic  variations exist in the frequency of each oscillatory mode.

away from the ﬁrst ﬁxed point. We did this 100 times for each ﬁxed point  yielding a probability
of transitioning from one ﬁxed point to another. As expected  stable ﬁxed points have no outgoing
edges  and only have a self-loop. All unstable ﬁxed points had two or more outgoing edges  which are
directed at nearby stable ﬁxed points. We constructed a ﬁxed point graph for each network and used
the Euclidean distance between the graph connectivity matrices to quantify dis-similarity5. These
heteroclinic orbits are shown in Fig. 1e  light black trajectories from one ﬁxed point to another. Using
this topological measure of RNN similarity  we ﬁnd that all architectures converge to very similar
solutions as shown by an MDS embedding of the ﬁxed point graph (Fig. 1f).

3.2 Sine wave generation

We trained RNNs to convert a static input into a sine wave  e.g. convert the command frequency ω
to sin(2πωt) (Fig. 2a). Fig. 2b shows low-dimensional trajectories in trained networks across all
architectures and nonlinearities (LSTM with ReLU did not train effectively  so we excluded it). Each

5While determining whether two graphs are isomorphic is a challenging problem in general  we circumvented
this issue by lexographically ordering the ﬁxed points based on the RNN readout. Networks with different
numbers of ﬁxed points than the modal number were discarded (less than 10% of the population).

6

(b)ExamplePCAtrajectoriestanhreluVanillaUGRNNGRUPC#1PC#3PC#2LSTM(c)NetworksimilarityviaSVCCAMDS(e)NetworksimilarityviafixedpointtopologyMDS(d)Fixedpointlinearizationanalysis(examplenetwork)(f)Linearizationsummary135Inputfrequency(Hz)(a)SinewavetaskschematicTime(s)TargetsUGRNNVanillaGRULSTMtanhreluUGRNNVanillaGRULSTMtanhrelu135135LSTMUGRNNGRUVanilla135tanhreluInputfreq. ω(Hz)Inputfrequency ω(Hz)Linearfreq.(Hz)0.00.51.0()0.50.00.5()Figure 3: Context-Dependent Integration. a) One of two streams of white-noise input (blue or red) is contextually
selected by a one-hot static context input to be integrated as output of the network  while the other is ignored
(blue or red). b) The trained networks were studied with probe inputs (panel inset in a)  probes from blue to
red show probe input). For this and subsequent panels  only one context is shown for clarity. Shown in b are
the PCA plots of RNN hidden states when driven by probe inputs (blue to red). The ﬁxed points (black dots)
show approximate line attractors for all RNN architectures and nonlinearities. c) MDS embedding of SVCCA
network-network distances comparing representations based on architecture (left) and activation (right)  layout
as in Fig. 1d. d) Using the same method to assess the topology of the ﬁxed points as used in the sine-wave
example to study the topology of the input-dependent ﬁxed points  we embedded the network-network distances
using the topological structure of the line attractor (colored based on architectures (left) and activation (right) 
layout as in Fig. 1d). e) Average sorted eigenvalues as a function architecture. Solid line and shaded patch show
mean ± standard error over networks trained with different random seeds. f) Output of the network when probed
with a unit magnitude input using the linearized dynamics  averaged over all ﬁxed points on the line attractor 
as a function of architecture and number of linear modes retained. In order to study the the dimensionality of
the solution to integration  we systematically removed the modes with smallest eigenvalues one at a time  and
recomputed the prediction of the new linear system for the unit magnitude input. These plots indicate that the
vanilla RNN (blue) uses a single mode to perform the integration  while the gated architectures distribute this
across a larger number of linear modes.

trajectory is colored by the input frequency. Furthermore  all trajectories followed a similar pattern:
oscillations occur in a roughly 2D subspace (circular trajectories)  with separate circles for each
frequency input separated by a third dimension. We then performed an analogous series of analyses
to those used in the previous task. In particular  we computed the SVCCA distances (raw distances
not shown) and used those to create an embedding of the network activity (Fig. 2c) as a function of
either RNN architecture or activation. These SVCCA MDS summaries show systematic differences
in the representations across both architecture and activation.
Moving to the analysis of dynamics  we found for each input frequency a single input-dependent
ﬁxed point (Fig. 2d  left). We studied the linearized dynamics around each ﬁxed point and found a
single pair of imaginary eigenvalues  representing a mildly unstable oscillatory mode whose complex
angle aligned well with the input frequency (Fig. 2d  right). We compared the frequency of the linear
model to the input frequency and found generally good alignment. We averaged the linear frequency
across all networks within architecture or activation and found small  but systematic differences
(Fig. 2f). Embeddings of the topological structure of the input-dependent ﬁxed points did not reveal
any structure that systematically varied by architecture or activation (Fig. 2e).

7

UGRNNVanillaGRULSTMtanhreluUGRNNVanillaGRULSTMtanhrelu(a)ContextdependentintegrationtaskContext(redorblue)Probe(singlecontext)(b)ExamplePCAtrajectories(singlecontext)(c)NetworksimilarityusingSVCCAMDS(d)NetworksimilarityusingfixedpointtopologyMDStanhVanillaUGRNNGRULSTMreluContextSignalInputsOutputs(a)(c)LinearprojectionsofCCAsimilarities(b)tanhReLUUntrainedTrainedVanillaRNNsPCAprojectionsofRNNactivityuntrainedReLUtrainedReLUuntrainedtanhtrainedtanhtanhRNNs(trained)VanillaLSTMGRUUGRNNPC1PC2ProbeinputsforRNNintegrationtask.0.720.810.80112801VanillaLSTMGRUUGRNNPC#1PC#2112801VanillaGRUUGRNNLSTM1128tanhrelu|λ|Eigenmode(e)AverageeigenvaluemagnitudeNumberofkepteigenmodes(f)LinearizedpredictionsforaunitinputFigure 4: An example where SVCCA yields a stronger correlation between untrained networks and trained
networks than between trained networks with different nonlinearities. a) An example (single context shown)
of the representation of the probe inputs (blue through red) for four networks: two trained  and two untrained
with tanh and ReLU nonlinearities. In this case the untrained tanh and ReLU networks have a higher correlation
to the trained tanh network than the trained tanh network does to the trained ReLU network. b) MDS plot
of SVCCA-based distances for many trained and untrained networks  showing that trained and untrained relu
networks are more similar to each other on average than to tanh networks.

3.3 Context-dependent integration (analog memory)

We trained an RNN to contextually integrate one of two white noise input streams  while ignoring
the other (Fig. 3a). We then studied the network representations by delivering a set of probe inputs
(Fig. 3a). The 3D PCA plots are shown in Fig. 3b  showing obvious differences in representational
geometry as a function of architecture and activation. The MDS summary plot of the SVCCA
distances of the representations is shown in Fig. 3c  again showing systematic clustering as a function
of architecture (left) and activation (right). We also analyzed the topology of the ﬁxed points (black
dots in Fig. 3b) to assess how well the ﬁxed points approximated a line attractor. We quantiﬁed this
by generating a graph with edges between ﬁxed points that were nearest neighbors. This resulted in a
graph for each line attractor in each context  which we then compared using Euclidean distance and
embedded in a 2D space using MDS (Fig. 3d). The MDS summary plot did not cluster strongly by
architecture  but did cluster based on activation.
We then studied the linearized dynamics around each ﬁxed point (Fig. 3e f). We focused on a single
context  and studied how a unit magnitude relevant input (as opposed to the input that should be
contextually ignored) was integrated by the linear system around the nearest ﬁxed point. This was
previously studied in depth in [4]. Here we were interested in differences in integration strategy as a
function of architecture. We found similar results to [4] for the vanilla RNN  which integrated the
input using a single linear mode with an eigenvalue of 1  with input coming in on the associated
left eigenvector and represented on the associated right eigenvector. Examination of all linearized
dynamics averaged over all ﬁxed points within the context showed that different architectures had
a similar strategy  except that the gated architectures had many more eigenvalues near 1 (Fig. 3e)
and thus used a high-dimensional strategy to accomplish the same goal as the vanilla RNN does in 1
dimension. We further studied the dimensionality by systematically zeroing out eigenvalues from
smallest to largest to discover how many linear modes were necessary to integrate a unit magnitude
input  compared to the full linear approximation (Fig. 3f). These results show that all of the networks
and architectures use essentially the same integration strategy  but systematically vary by architecture
in terms of the number of modes they employ. To a lesser degree they also vary some in the amount
the higher order terms contribute to the solution  as shown by the differences away from an integral
of 1 for a unit magnitude input  for the full linearized system with no modes zeroed out (analogous to
Fig. 2f).
Finally  to highlight the difﬁculty of using CCA-based techniques to compare representational
geometry in simple tasks  we used the inputs of the context-dependent integrator task to drive both
trained and untrained vanilla RNNs (Fig. 4). We found that the average canonical correlation between
trained and untrained networks can be larger than between trained RNNs with different nonlinearities.
The summary MDS plot across many RNNs shows that the two clusters of untrained and trained relu
networks are closer together than the two clusters of trained tanh networks Fig. 4b.

8

(a)tanhReLUUntrainedTrainedPC1PC20.720.810.80VanillaRNNsuntrainedReLUtrainedReLUuntrainedtanhtrainedtanh(b)PC#1PC#24 Related Work

Researchers are beginning to study both empirically and theoretically how deep networks may show
universal properties. For example  [32] proved that representational geometry is a universal property
amongst all trained deep linear networks that solve a task optimally  with smallest norm weights.
Also  [42  43] studied how expressive capacity increases with network depth and width. Work in
RNNs is far more preliminary  though it is well known that RNNs are universal approximators
of dynamical systems [44]. More recently  the per-parameter capacity of RNNs was found to be
remarkably similar across various RNN architectures [20]. The authors of [45] studied all the possible
topological arrangements of ﬁxed points in a 2D continuous-time GRU  conjecturing that dynamical
conﬁgurations such as line or ring attractors that require an inﬁnite number of ﬁxed points can only
be created in approximation  even in GRUs with more than two dimensions.
Understanding biological neural systems in terms of artiﬁcial dynamical systems has a rich tradition
[46  47  48  49]. Researchers have attempted to understand optimized neural networks with nonlinear
dynamical systems techniques [33  50] and to compare those artiﬁcial networks to biological circuits
[4  12  51  52  53  13  14].
Previous work has studied vanilla RNNs in similar settings [33  4  54]  but has not systematically
surveyed the variability in network dynamics across commonly used RNN architectures  such as
LSTMs [17] or GRUs [18]  nor quantiﬁed variations in dynamical solutions over architecture and
nonlinearity  although [16] considers many issues concerning how RNNs may hold memory. Finally 
there has been a recent line of work comparing artiﬁcial network representations to neural data [1  2 
3  10  11  12]. Investigators have been studying ways to improve the utility of CCA-based comparison
methods [34  55]  as well as comparing CCA to other methods [35].

5 Discussion

In this work we empirically study aspects of individuality and universality in recurrent networks.
We ﬁnd individuality in that representational geometry of RNNs varies signiﬁcantly as a function
of architecture and activation function (Fig. 1d  2c  3c). We also see hints of universality: the ﬁxed
point topologies show far less variation across networks than the representations do (Fig. 1f  2e  3d).
Linear analyses also showed similar solutions  e.g. essentially linear oscillations for the sine wave
task (Fig. 2f) and linear integration in the CDI task (Fig. 3f). However  linear analyses also showed
variation across architectures in the dimensionality of the solution to integration (Fig. 3e).
While the linear analyses showed common computational strategies across all architectures (such
as a slightly unstable oscillation in the linearized system around each ﬁxed point)  we did see small
systematic differences that clustered by architecture (such as the difference between input frequency
and frequency of oscillatory mode in the linearized system). This indicates that another aspect of
individuality appears to be the degree to which higher order terms contribute to the total solution.
The ﬁxed point analysis discussed here has one major limitation  namely that the number of ﬁxed
points must be the same across networks that are being compared. For the three tasks studied here 
we found that the vast majority of trained networks did indeed have the same number of ﬁxed points
for each task. However  an important direction for future work is extending the analysis to be more
robust with respect to differing numbers of ﬁxed points.
In summary  we hope this empirical study begins a larger effort to characterize methods for comparing
RNN dynamics  building a foundation for future connections of biological circuits and artiﬁcial
neural networks.

Acknowledgments

The authors would like to thank Jeffrey Pennington  Maithra Raghu  Jascha Sohl-Dickstein  and Larry
Abbott for helpful feedback and discussions. MDG was supported by the Stanford Neurosciences
Institute  the Ofﬁce of Naval Research Grant #N00014-18-1-2158.

9

References

[1] Lane McIntosh  Niru Maheswaranathan  Aran Nayebi  Surya Ganguli  and Stephen Baccus.
“Deep Learning Models of the Retinal Response to Natural Scenes”. In: Advances in Neural
Information Processing Systems 29. Ed. by D. D. Lee  M. Sugiyama  U. V. Luxburg  I. Guyon 
and R. Garnett. Curran Associates  Inc.  2016  pp. 1369–1377. URL: http://papers.nips.
cc/paper/6388-deep-learning-models-of-the-retinal-response-to-natural-
scenes.pdf.

[2] Niru Maheswaranathan  Lane T McIntosh  David B Kastner  Josh Melander  Luke Brezovec 
Aran Nayebi  Julia Wang  Surya Ganguli  and Stephen A Baccus. “Deep learning models reveal
internal structure and diverse computations in the retina under natural scenes”. In: bioRxiv
(2018)  p. 340943.

[3] Chethan Pandarinath  Daniel J O’Shea  Jasmine Collins  Rafal Jozefowicz  Sergey D Stavisky 
Jonathan C Kao  Eric M Trautmann  Matthew T Kaufman  Stephen I Ryu  Leigh R Hochberg 
Jaimie M Henderson  Krishna V Shenoy  L F Abbott  and David Sussillo. “Inferring single-
trial neural population dynamics using sequential auto-encoders”. In: Nature Methods 15.10
(2018)  pp. 805–815. ISSN: 1548-7105. DOI: 10.1038/s41592-018-0109-9. URL: https:
//doi.org/10.1038/s41592-018-0109-9.

[4] Valerio Mante  David Sussillo  Krishna V. Shenoy  and William T. Newsome. “Context-
dependent computation by recurrent dynamics in prefrontal cortex”. In: Nature 503 (2013).
Article  p. 78.

[5] Alexander J E Kell  Daniel L K Yamins  Erica N Shook  Sam V Norman-Haignere  and Josh
H McDermott. “A Task-Optimized Neural Network Replicates Human Auditory Behavior 
Predicts Brain Responses  and Reveals a Cortical Processing Hierarchy”. In: Neuron 98.3
(May 2018)  630–644.e16. ISSN: 0896-6273. DOI: 10.1016/j.neuron.2018.03.044. URL:
https://doi.org/10.1016/j.neuron.2018.03.044.

[6] Rishi Rajalingham  Elias B. Issa  Pouya Bashivan  Kohitij Kar  Kailyn Schmidt  and James J.
DiCarlo. “Large-Scale  High-Resolution Comparison of the Core Visual Object Recognition
Behavior of Humans  Monkeys  and State-of-the-Art Deep Artiﬁcial Neural Networks”. In:
Journal of Neuroscience 38.33 (2018)  pp. 7255–7269. ISSN: 0270-6474. DOI: 10.1523/
JNEUROSCI.0388- 18.2018. eprint: http://www.jneurosci.org/content/38/33/
7255.full.pdf. URL: http://www.jneurosci.org/content/38/33/7255.

[7] Christopher J Cueva and Xue-Xin Wei. “Emergence of grid-like representations by training
recurrent neural networks to perform spatial localization”. In: arXiv preprint arXiv:1803.07770
(2018).

[8] Andrea Banino  Caswell Barry  Benigno Uria  Charles Blundell  Timothy Lillicrap  Piotr
Mirowski  Alexander Pritzel  Martin J Chadwick  Thomas Degris  Joseph Modayil  et al.
“Vector-based navigation using grid-like representations in artiﬁcial agents”. In: Nature
557.7705 (2018)  p. 429.

[9] Stefano Recanatesi  Matthew Farrell  Guillaume Lajoie  Sophie Deneve  Mattia Rigotti  and
Eric Shea-Brown. “Predictive learning extracts latent space representations from sensory
observations”. In: bioRxiv (2019). DOI: 10.1101/471987. eprint: https://www.biorxiv.
org/content/early/2019/07/13/471987.full.pdf. URL: https://www.biorxiv.
org/content/early/2019/07/13/471987.

[10] Daniel L. K. Yamins  Ha Hong  Charles F. Cadieu  Ethan A. Solomon  Darren Seibert  and
James J. DiCarlo. “Performance-optimized hierarchical models predict neural responses in
higher visual cortex”. In: Proceedings of the National Academy of Sciences 111.23 (2014) 
pp. 8619–8624. ISSN: 0027-8424. DOI: 10.1073/pnas.1403112111.

[11] Seyed-Mahdi Khaligh-Razavi and Nikolaus Kriegeskorte. “Deep Supervised  but Not Unsu-
pervised  Models May Explain IT Cortical Representation”. In: PLOS Computational Biology
10.11 (Nov. 2014)  pp. 1–29. DOI: 10 . 1371 / journal . pcbi . 1003915. URL: https :
//doi.org/10.1371/journal.pcbi.1003915.

[12] David Sussillo  Mark M Churchland  Matthew T Kaufman  and Krishna V Shenoy. “A neural
network that ﬁnds a naturalistic solution for the production of muscle activity”. In: Nature
neuroscience 18.7 (2015)  p. 1025.

10

[13] Evan D Remington  Devika Narain  Eghbal A Hosseini  and Mehrdad Jazayeri. “Flexible
Sensorimotor Computations through Rapid Reconﬁguration of Cortical Dynamics”. In: Neuron
98.5 (2018)  1005–1019.e5. ISSN: 0896-6273. DOI: 10.1016/j.neuron.2018.05.020.
Jing Wang  Devika Narain  Eghbal A Hosseini  and Mehrdad Jazayeri. “Flexible timing by
temporal scaling of cortical responses”. In: Nature neuroscience 21.1 (2018)  p. 102.

[14]

[15] David GT Barrett  Ari S Morcos  and Jakob H Macke. “Analyzing biological and artiﬁcial neu-
ral networks: challenges with opportunities for synergy?” In: Current Opinion in Neurobiology
55 (2019). Machine Learning  Big Data  and Neuroscience  pp. 55–64. ISSN: 0959-4388.

[16] A Emin Orhan and Wei Ji Ma. “A diverse range of factors affect the nature of neural represen-
tations underlying short-term memory”. In: Nature Neuroscience 22.2 (2019)  pp. 275–283.
ISSN: 1546-1726. DOI: 10.1038/s41593- 018- 0314- y. URL: https://doi.org/10.
1038/s41593-018-0314-y.

[17] Sepp Hochreiter and Jürgen Schmidhuber. “Long short-term memory”. In: Neural computation

9.8 (1997)  pp. 1735–1780.

[18] Kyunghyun Cho  Bart van Merrienboer  Caglar Gulcehre  Fethi Bougares  Holger Schwenk 
and Yoshua Bengio. “Learning Phrase Representations using RNN Encoder-Decoder for
Statistical Machine Translation”. In: Proc. Conference on Empirical Methods in Natural
Language Processing. Unknown  Unknown Region  2014.

[19] Scott Wisdom  Thomas Powers  John Hershey  Jonathan Le Roux  and Les Atlas. “Full-
Capacity Unitary Recurrent Neural Networks”. In: Advances in Neural Information Processing
Systems 29. Ed. by D. D. Lee  M. Sugiyama  U. V. Luxburg  I. Guyon  and R. Garnett. 2016 
pp. 4880–4888.
Jasmine Collins  Jascha Sohl-Dickstein  and David Sussillo. “Capacity and Trainability in
Recurrent Neural Networks”. In: ICLR. 2017.

[20]

[21] Quoc V. Le  Navdeep Jaitly  and Geoffrey E. Hinton. A Simple Way to Initialize Recurrent

Networks of Rectiﬁed Linear Units. 2015. eprint: arXiv:1504.00941.

[22] Razvan Pascanu  Tomas Mikolov  and Yoshua Bengio. “On the Difﬁculty of Training Recurrent
Neural Networks”. In: Proceedings of the 30th International Conference on International
Conference on Machine Learning - Volume 28. ICML’13. Atlanta  GA  USA  2013  pp. III-
1310–III-1318.

[23] Stephen Merity  Nitish Shirish Keskar  and Richard Socher. “Regularizing and Optimizing

LSTM Language Models”. In: ICLR. 2018.

[24] Barret Zoph and Quoc V. Le. “Neural Architecture Search with Reinforcement Learning”. In:

2017.

[25] Hieu Pham  Melody Y. Guan  Barret Zoph  Quoc V. Le  and Jeff Dean. “Efﬁcient Neural

Architecture Search via Parameter Sharing”. In: ICML. 2018.

[26] Liang-chieh Chen  Maxwell Collins  Yukun Zhu  George Papandreou  Barret Zoph  Florian
Schroff  Hartwig Adam  and Jonathon Shlens. “Searching for Efﬁcient Multi-Scale Architec-
tures for Dense Image Prediction”. In: 2018. URL: https://arxiv.org/pdf/1809.04184.
pdf.

[27] Harry Eugene Stanley. Introduction to Phase Transitions and Critical Phenomena. en. Oxford

University Press  1971.

[28] Mitchell J Feigenbaum. “Universal behavior in nonlinear systems”. In: Universality in Chaos 

2nd edition. Routledge  2017  pp. 49–50.

[29] Alexander Rivkind and Omri Barak. “Local dynamics in trained recurrent neural networks”.

In: Physical review letters 118.25 (2017)  p. 258101.

[30] Francesca Mastrogiuseppe and Srdjan Ostojic. “Linking connectivity  dynamics  and computa-

tions in low-rank recurrent neural networks”. In: Neuron 99.3 (2018)  pp. 609–623.

[31] Francesca Mastrogiuseppe and Srdjan Ostojic. “A Geometrical Analysis of Global Stability in

Trained Feedback Networks”. In: Neural computation 31.6 (2019)  pp. 1139–1182.

[32] Andrew M Saxe  James L McClelland  and Surya Ganguli. “A mathematical theory of semantic

development in deep neural networks”. In: Proc. Natl. Acad. Sci. U. S. A. (May 2019).

[33] David Sussillo and Omri Barak. “Opening the Black Box: Low-Dimensional Dynamics in
High-Dimensional Recurrent Neural Networks”. In: Neural Computation 25.3 (2013)  pp. 626–
649. DOI: 10.1162/NECO_a_00409.

11

[34] Maithra Raghu  Justin Gilmer  Jason Yosinski  and Jascha Sohl-Dickstein. “SVCCA: Singular
Vector Canonical Correlation Analysis for Deep Learning Dynamics and Interpretability”.
In: Advances in Neural Information Processing Systems 30. Ed. by I. Guyon  U. V. Luxburg 
S. Bengio  H. Wallach  R. Fergus  S. Vishwanathan  and R. Garnett. Curran Associates  Inc. 
2017  pp. 6076–6085.

[35] Simon Kornblith  Mohammad Norouzi  Honglak Lee  and Geoffrey Hinton. “Similarity of

Neural Network Representations Revisited”. In: arXiv preprint arXiv:1905.00414 (2019).

[36] Boris T Polyak. “Some methods of speeding up the convergence of iteration methods”. In:

USSR Computational Mathematics and Mathematical Physics 4.5 (1964)  pp. 1–17.
Ilya Sutskever  James Martens  George Dahl  and Geoffrey Hinton. “On the importance of
initialization and momentum in deep learning”. In: International conference on machine
learning. 2013  pp. 1139–1147.

[37]

[38] Nikolaus Kriegeskorte and Rogier A. Kievit. “Representational geometry: integrating cognition 
computation  and the brain”. In: Trends in Cognitive Sciences 17.8 (2013)  pp. 401–412. ISSN:
1364-6613.

[39] Saskia E. J. de Vries  Jerome Lecoq  Michael A. Buice  Peter A. Groblewski  Gabriel K. Ocker 
Michael Oliver  David Feng  Nicholas Cain  Peter Ledochowitsch  Daniel Millman  et al. “A
large-scale  standardized physiological survey reveals higher order coding throughout the
mouse visual cortex”. In: bioRxiv (2018). DOI: 10.1101/359513.

[40] Matthew Golub and David Sussillo. “FixedPointFinder: A Tensorﬂow toolbox for identifying
and characterizing ﬁxed points in recurrent neural networks”. In: Journal of Open Source
Software 3.31 (Nov. 2018)  p. 1003. DOI: 10.21105/joss.01003. URL: https://doi.
org/10.21105/joss.01003.
Ingwer Borg and Patrick Groenen. “Modern multidimensional scaling: Theory and applica-
tions”. In: Journal of Educational Measurement 40.3 (2003)  pp. 277–280.

[41]

[42] Ben Poole  Subhaneil Lahiri  Maithra Raghu  Jascha Sohl-Dickstein  and Surya Ganguli.
“Exponential expressivity in deep neural networks through transient chaos”. In: Advances in
neural information processing systems. 2016  pp. 3360–3368.

[43] Maithra Raghu  Ben Poole  Jon Kleinberg  Surya Ganguli  and Jascha Sohl Dickstein. “On
the expressive power of deep neural networks”. In: Proceedings of the 34th International
Conference on Machine Learning-Volume 70. JMLR. org. 2017  pp. 2847–2854.

[44] Kenji Doya. “Universality of fully connected recurrent neural networks”. In: Dept. of Biology 

UCSD  Tech. Rep (1993).
Ian D. Jordan  Piotr Aleksander Sokol  and Il Memming Park. “Gated recurrent units viewed
through the lens of continuous time dynamical systems”. In: CoRR abs/1906.01005 (2019).
arXiv: 1906.01005. URL: http://arxiv.org/abs/1906.01005.

[45]

[46] Alain Destexhe and Terrence J Sejnowski. “The Wilson–Cowan model  36 years later”. In:

Biological cybernetics 101.1 (2009)  pp. 1–2.
John J Hopﬁeld. “Neural networks and physical systems with emergent collective computa-
tional abilities”. In: Proceedings of the national academy of sciences 79.8 (1982)  pp. 2554–
2558.

[47]

[48] Haim Sompolinsky  Andrea Crisanti  and Hans-Jurgen Sommers. “Chaos in random neural

networks”. In: Physical review letters 61.3 (1988)  p. 259.

[49] H. S. Seung. “How the brain keeps the eyes still”. In: Proceedings of the National Academy
of Sciences 93.23 (1996)  pp. 13339–13344. ISSN: 0027-8424. DOI: 10.1073/pnas.93.23.
13339.

[50] Omri Barak  David Sussillo  Ranulfo Romo  Misha Tsodyks  and LF Abbott. “From ﬁxed
points to chaos: three models of delayed discrimination”. In: Progress in neurobiology 103
(2013)  pp. 214–222.

[51] David Sussillo. “Neural circuits as computational dynamical systems”. In: Current opinion in

neurobiology 25 (2014)  pp. 156–163.

[52] Kanaka Rajan  Christopher D Harvey  and David W Tank. “Recurrent network models of

sequence generation and memory”. In: Neuron 90.1 (2016)  pp. 128–142.

[53] Omri Barak. “Recurrent neural networks as versatile tools of neuroscience research”. In:

Current opinion in neurobiology 46 (2017)  pp. 1–6.

12

[54] Guangyu Robert Yang  Madhura R Joglekar  H Francis Song  William T Newsome  and
Xiao-Jing Wang. “Task representations in neural networks trained to perform many cognitive
tasks”. In: Nature neuroscience 22.2 (2019)  p. 297.

[55] Ari Morcos  Maithra Raghu  and Samy Bengio. “Insights on representational similarity in
neural networks with canonical correlation”. In: Advances in Neural Information Processing
Systems. 2018  pp. 5727–5736.
Ingmar Kanitscheider and Ila Fiete. “Training recurrent networks to generate hypotheses
about how the brain solves hard navigation problems”. In: Advances in Neural Information
Processing Systems 30. Ed. by I. Guyon  U. V. Luxburg  S. Bengio  H. Wallach  R. Fergus 
S. Vishwanathan  and R. Garnett. Curran Associates  Inc.  2017  pp. 4529–4538.

[56]

[57] Harold Hotelling. “Relations between two sets of variates”. In: Breakthroughs in statistics.

Springer  1992  pp. 162–190.

13

,Niru Maheswaranathan
Alex Williams
Matthew Golub
Surya Ganguli
David Sussillo