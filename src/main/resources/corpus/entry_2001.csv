2015,Fast Bidirectional Probability Estimation in Markov Models,We develop a new bidirectional algorithm for estimating Markov chain multi-step transition probabilities: given a Markov chain  we want to estimate the probability of hitting a given target state in $\ell$ steps after starting from a given source distribution. Given the target state $t$  we use a (reverse) local power iteration to construct an `expanded target distribution'  which has the same mean as the quantity we want to estimate  but a smaller variance -- this can then be sampled efficiently by a Monte Carlo algorithm. Our method extends to any Markov chain on a discrete (finite or countable) state-space  and can be extended to compute functions of multi-step transition probabilities such as PageRank  graph diffusions  hitting/return times  etc. Our main result is that in `sparse' Markov Chains -- wherein the number of transitions between states is  comparable to the number of states -- the running time of our algorithm for a uniform-random target node is order-wise smaller than Monte Carlo and power iteration based algorithms; in particular  our method can estimate a probability $p$ using only $O(1/\sqrt{p})$ running time.,Fast Bidirectional Probability Estimation in Markov

Models

Siddhartha Banerjee ∗

sbanerjee@cornell.edu

Peter Lofgren†

plofgren@cs.stanford.edu

Abstract

We develop a new bidirectional algorithm for estimating Markov chain multi-step
transition probabilities: given a Markov chain  we want to estimate the proba-
bility of hitting a given target state in (cid:96) steps after starting from a given source
distribution. Given the target state t  we use a (reverse) local power iteration to
construct an ‘expanded target distribution’  which has the same mean as the quan-
tity we want to estimate  but a smaller variance – this can then be sampled efﬁ-
ciently by a Monte Carlo algorithm. Our method extends to any Markov chain on
a discrete (ﬁnite or countable) state-space  and can be extended to compute func-
tions of multi-step transition probabilities such as PageRank  graph diffusions  hit-
ting/return times  etc. Our main result is that in ‘sparse’ Markov Chains – wherein
the number of transitions between states is comparable to the number of states –
the running time of our algorithm for a uniform-random target node is order-wise
smaller than Monte Carlo and power iteration based algorithms; in particular  our
method can estimate a probability p using only O(1/

p) running time.

√

1

Introduction

Markov chains are one of the workhorses of stochastic modeling  ﬁnding use across a variety of
applications – MCMC algorithms for simulation and statistical inference; to compute network cen-
trality metrics for data mining applications; statistical physics; operations management models for
reliability  inventory and supply chains  etc. In this paper  we consider a fundamental problem as-
sociated with Markov chains  which we refer to as the multi-step transition probability estimation
(or MSTP-estimation) problem: given a Markov Chain on state space S with transition matrix P  
an initial source distribution σ over S  a target state t ∈ S and a ﬁxed length (cid:96)  we are interested in
computing the (cid:96)-step transition probability from σ to t. Formally  we want to estimate:

σ[t] := (cid:104)σP (cid:96)  et(cid:105) = σP (cid:96)eT
p(cid:96)
t  

σ[t] > δ.

(1)
where et is the indicator vector of state t. A natural parametrization for the complexity of MSTP-
estimation is in terms of the minimum transition probabilities we want to detect: given a desired
minimum detection threshold δ  we want algorithms that give estimates which guarantee small rela-
tive error for any (σ  t  (cid:96)) such that p(cid:96)
Parametrizing in terms of the minimum detection threshold δ can be thought of as benchmarking
against a standard Monte Carlo algorithm  which estimates p(cid:96)
σ[t] by sampling independent (cid:96)-step
paths starting from states sampled from σ. An alternate technique for MSTP-estimation is based on
linear algebraic iterations  in particular  the (local) power iteration. We discuss these in more detail
in Section 1.2. Crucially  however  both these techniques have a running time of Ω(1/δ) for testing
if p(cid:96)

σ[t] > δ (cf. Section 1.2).
∗Siddhartha Banerjee is an assistant professor at the School of Operations Research and Information Engi-
†Peter Lofgren is a graduate student in the Computer Science Department at Stanford (http://cs.

neering at Cornell (http://people.orie.cornell.edu/sbanerjee).

stanford.edu/people/plofgren/).

1

1.1 Our Results

To the best of our knowledge  our work gives the ﬁrst bidirectional algorithm for MSTP-estimation
which works for general discrete state-space Markov chains1. The algorithm we develop is very
simple  both in terms of implementation and analysis. Moreover  we prove that in many settings  it
is order-wise faster than existing techniques.
Our algorithm consists of two distinct forward and reverse components  which are executed sequen-
tially. In brief  the two components proceed as follows:
• Reverse-work: Starting from the target node t  we perform a sequence of reverse local power
• Forward-work: We next sample a number of random walks of length (cid:96)  starting from σ and
σ[t].
This full algorithm  which we refer to as the Bidirectional-MSTP estimator  is formalized in
Algorithm 2. It works for all countable-state Markov chains  giving the following accuracy result:
Theorem 1 (For details  refer Section 2.3). Given any Markov chain P   source distribution σ 
terminal state t  length (cid:96)  threshold δ and relative error   Bidirectional-MSTP (Algorithm 2)

transitioning according to P   and return the sum of residues on the walk as an estimate of p(cid:96)

iterations – in particular  we use the REVERSE-PUSH operation deﬁned in Algorithm 1.

returns an unbiased estimate(cid:98)p(cid:96)
(cid:12)(cid:12)(cid:98)p(cid:96)

σ[t] for p(cid:96)
σ[t] − p(cid:96)

σ[t]  which  with high probability  satisﬁes:

σ[t](cid:12)(cid:12) < max(cid:8)p(cid:96)

σ[t]  δ(cid:9) .

Since we dynamically adjust the number of REVERSE-PUSH operations to ensure that all residues
are small  the proof of the above theorem follows from straightforward concentration bounds.
Since Bidirectional-MSTP combines local power iteration and Monte Carlo techniques  a nat-
ural question is when the algorithm is faster than both. It is easy to to construct scenarios where the
runtime of Bidirectional-MSTP is comparable to its two constituent algorithms – for example 
if t has more than 1/δ in-neighbors. Surprisingly  however  we show that in sparse Markov chains
and for typical target states  Bidirectional-MSTP is order-wise faster:
Theorem 2 (For details  refer Section 2.3). Given any Markov chain P   source distribution σ 
length (cid:96)  threshold δ and desired accuracy ; then for a uniform random choice of t ∈ S  the
d/δ)  where d is the average

Bidirectional-MSTP algorithm has a running time of (cid:101)O((cid:96)3/2

(cid:113)

number of neighbors of nodes in S.

√

Thus  for typical targets  we can estimate transition probabilities of order δ in time only O(1/
δ).
Note that we do not need for every state that the number of neighboring states is small  but rather 
that they are small on average – for example  this is true in ‘power-law’ networks  where some
nodes have very high degree  but the average degree is small. The proof of this result is based on a
modiﬁcation of an argument in [2] – refer Section 2.3 for details.
Estimating transition probabilities to a target state is one of the fundamental primitives in Markov
chain models – hence  we believe that our algorithm can prove useful in a variety of application
domains. In Section 3  we brieﬂy describe how to adapt our method for some of these applica-
tions – estimating hitting/return times and stationary probabilities  extensions to non-homogenous
Markov chains (in particular  for estimating graph diffusions and heat kernels)  connections to lo-
cal algorithms and expansion testing. In addition  our MSTP-estimator could be useful in several
other applications – estimating ruin probabilities in reliability models  buffer overﬂows in queueing
systems  in statistical physics simulations  etc.

1.2 Existing Approaches for MSTP-Estimation

There are two main techniques used for MSTP-estimation. The ﬁrst is a natural Monte Carlo al-
gorithm: we estimate p(cid:96)
σ[t] by sampling independent (cid:96)-step paths  each starting from a random
state sampled from σ. A simple concentration argument shows that for a given value of δ  we need
σ[t]  irrespective of the choice of t  and the structure

(cid:101)Θ(1/δ) samples to get an accurate estimate of p(cid:96)

1Bidirectional estimators have been developed before for reversible Markov chains [1]; our method however

is not only more general  but conceptually and operationally simpler than these techniques (cf. Section 1.2).

2

σ[t] > δ.

of P . Note that this algorithm is agnostic of the terminal state t; it gives an accurate estimate for any
t such that p(cid:96)
On the other hand  the problem also admits a natural linear algebraic solution  using the standard
power iteration starting with σ  or the reverse power iteration starting with et (which is obtained
by re-writing Equation (1) as p(cid:96)
σ[t] := σ(et(P T )(cid:96))T ). When the state space is large  performing a
direct power iteration is infeasible – however  there are localized versions of the power iteration that
are still efﬁcient. Such algorithms have been developed  among other applications  for PageRank
estimation [3  4] and for heat kernel estimation [5]. Although slow in the worst case 2  such local
update algorithms are often fast in practice  as unlike Monte Carlo methods they exploit the local
structure of the chain. However even in sparse Markov chains and for a large fraction of target
states  their running time can be Ω(1/δ). For example  consider a random walk on a random d-
regular graph and let δ = o(1/n) – then for (cid:96) ∼ logd(1/δ)  verifying p(cid:96)
[t] > δ is equivalent to
uncovering the entire logd(1/δ) neighborhood of s. Since a large random d-regular graph is (whp)
an expander  this neighborhood has Ω(1/δ) distinct nodes. Finally  note that as with Monte Carlo 
power iterations can be adapted to either the source or terminal state  but not both.
For reversible Markov chains  one can get a bidirectional algorithms for estimating p(cid:96)
[t] based on
es
colliding random walks. For example  consider the problem of estimating length-2(cid:96) random walk
transition probabilities in a regular undirected graph G(V  E) on n vertices [1  6]. The main idea
is that to test if a random walk goes from s to t in 2(cid:96) steps with probability ≥ δ  we can generate
two independent random walks of length (cid:96)  starting from s and t respectively  and detect if they
terminate at the same intermediate node. Suppose pw  qw are the probabilities that a length-(cid:96) walk
from s and t respectively terminate at node w – then from the reversibility of the chain  we have that
w∈V pwqw; this is also the collision probability. The critical observation is that if we
p2(cid:96)

σ [t] = (cid:80)
generate(cid:112)1/δ walks from s and t  then we get 1/δ potential collisions  which is sufﬁcient to detect

es

σ [t] > δ. This argument forms the basis of the birthday-paradox  and similar techniques used
if p2(cid:96)
in a variety of estimation problems (eg.  see [7]). Showing concentration for this estimator is tricky
as the samples are not independent; moreover  to control the variance of the samples  the algorithms
often need to separately deal with ‘heavy’ intermediate nodes  where pw or qw are much larger than
O(1/n). Our proposed approach is much simpler both in terms of algorithm and analysis  and more
signiﬁcantly  it extends beyond reversible chains to any general discrete state-space Markov chain.
The most similar approach to ours is the recent FAST-PPR algorithm of Lofgren et al. [2] for PageR-
ank estimation; our algorithm borrows several ideas and techniques from that work. However  the
FAST-PPR algorithm relies heavily on the structure of PageRank – in particular  the fact that the
PageRank walk has Geometric(α) length (and hence can be stopped and restarted due to the mem-
oryless property). Our work provides an elegant and powerful generalization of the FAST-PPR
algorithm  extending the approach to general Markov chains.

2 The Bidirectional MSTP-estimation Algorithm

2.1 Algorithm

As described in Section 1.1  given a target state t  our bidirectional MSTP algorithm keeps track of
t ∈ Rn – for each length
a pair of vectors – the estimate vector qk
k ∈ {0  1  2  . . .   (cid:96)}. The vectors are initially all set to 0 (i.e.  the all-0 vector)  except r0
t which is
initialized as et. Moreover  they are updated using a reverse push operation deﬁned as:

t ∈ Rn and the residual vector rk

Algorithm 1 REVERSE-PUSH(v  i)
Inputs: Transition matrix P   estimate vector qi

t} and residual-vectors {(cid:101)ri
1: return New estimate vectors {(cid:101)qi
t} computed as:
(cid:101)ri
(cid:101)ri+1
t ← ri
t ← ri+1

(cid:101)qi
t ← qi

t  residual vectors ri

t + (cid:104)ri

t  ev(cid:105)ev;

t − (cid:104)ri

t  ev(cid:105)ev;

t  ri+1

t

t  ev(cid:105)(cid:0)evP T(cid:1)

t + (cid:104)ri

2In particular  local power iterations are slow if a state has a very large out-neighborhood (for the forward

iteration) or in-neighborhood (for the reverse update).

3

σ[t] in terms of {qk
The main observation behind our algorithm is that we can re-write p(cid:96)
expectation over random sample-paths of the Markov chain as follows (cf. Equation (3)):

t } as an

t   rk

(cid:96)(cid:88)

(cid:2)r(cid:96)−k

t

(Vk)(cid:3)

σ[t] = (cid:104)σ  q(cid:96)
p(cid:96)

t(cid:105) +

EVk∼σP k

(2)

In other words  given vectors {qk
σ[t] by sampling a
length-(cid:96) random trajectory {V0  V1  . . .   V(cid:96)} of the Markov chain P starting at a random state V0
sampled from the source distribution σ  and then adding the residuals along the trajectory as in
Equation (2). We formalize this bidirectional MSTP algorithm in Algorithm 2.

t }  we can get an unbiased estimator for p(cid:96)

t   rk

k=0

Algorithm 2 Bidirectional-MSTP(P  σ  t  (cid:96)max  δ)
Inputs: Transition matrix P   source distribution σ  target state t  maximum steps (cid:96)max  minimum

1: Set accuracy parameter c based on  and pf and set reverse threshold δr (cf. Theorems 1 and 2)

probability threshold δ  relative error bound   failure probability pf

(in our experiments we use c = 7 and δr =(cid:112)δ/c)

t = 0   ∀ k ∈ {0  1  2  . . .   (cid:96)} 
t = et and rk

t = 0   ∀ k ∈ {1  2  3  . . .   (cid:96)}

end while

while ∃ v ∈ S s.t.

2: Initialize: Estimate vectors qk
Residual vectors r0
3: for i ∈ {0  1  . . .   (cid:96)max} do
t[v] > δr do
ri
4:
Execute REVERSE-PUSH(v  i)
5:
6:
7: end for
8: Set number of sample paths nf = c(cid:96)maxδr/δ
9: for index i ∈ {1  2  . . .   nf} do
i ∼ σ
10:
11:
12:

i   V 1

(See Theorem 1 for details)

Sample starting node V 0
Generate sample path Ti = {V 0
For (cid:96) ∈ {1  2  . . .   (cid:96)max}: sample k ∼ U nif orm[0  (cid:96)] and compute S(cid:96)
(We reinterpret the sum over k in Equation 2 as an expectation and sample k rather sum over
k ≤ (cid:96) for computational speed.)

} of length (cid:96)max starting from V 0
t i = (cid:96)r(cid:96)−k

i   . . .   V (cid:96)max

i
[V k
i ]

t

i

13: end for

14: return {(cid:98)p(cid:96)

σ[t]}(cid:96)∈[(cid:96)max]  where(cid:98)p(cid:96)

σ[t] = (cid:104)σ  q(cid:96)

t(cid:105) + (1/nf )(cid:80)nf

i=1 S(cid:96)
t i

2.2 Some Intuition Behind our Approach

Before formally analyzing the performance of our MSTP-estimation algorithm  we ﬁrst build some
intuition as to why it works.
In particular  it is useful to interpret the estimates and residues in
probabilistic/combinatorial terms. In Figure 1  we have considered a simple Markov chain on three
states – Solid  Hollow and Checkered (henceforth (S  H  C)). On the right side  we have illustrated
an intermediate stage of reverse work using S as the target  after performing the REVERSE-PUSH
operations (S  0)  (H  1)  (C  1) and (S  2) in that order. Each push at level i uncovers a collection

Figure 1: Visualizing a sequence of REVERSE-PUSH operations: Given the Markov chain on the
left with S as the target  we perform REVERSE-PUSH operations (S  0)  (H  1)  (C  1) (S  2).

4

v or ri

of length-(i + 1) paths terminating at S – for example  in the ﬁgure  we have uncovered all length
2 and 3 paths  and several length 4 paths. The crucial observation is that each uncovered path of
length i starting from a node v is accounted for in either qi
v. In particular  in Figure 1  all paths
starting at solid nodes are stored in the estimates of the corresponding states  while those starting at
blurred nodes are stored in the residue. Now we can use this set of pre-discovered paths to boost the
estimate returned by Monte Carlo trajectories generated starting from the source distribution. The
dotted line in the ﬁgure represents the current reverse-work frontier – it separates the fully uncovered
neighborhood of (S  0) from the remaining states (v  i).
In a sense  what the REVERSE-PUSH operation does is construct a sequence of importance-
sampling weights  which can then be used for Monte Carlo. An important novelty here is that
the importance-sampling weights are: (i) adapted to the target state  and (ii) dynamically adjusted
to ensure the Monte Carlo estimates have low variance. Viewed in this light  it is easy to see how
the algorithm can be modiﬁed to applications beyond basic MSTP-estimation: for example  to non-
homogenous Markov chains  or for estimating the probability of hitting a target state t for the ﬁrst
time in (cid:96) steps (cf. Section 3). Essentially  we only need an appropriate reverse-push/dynamic
programming update for the quantity of interest (with associated invariant  as in Equation (2)).

2.3 Performance Analysis

We ﬁrst formalize the critical invariant introduced in Equation (2):
t = 0∀ k ≥
Lemma 1. Given a terminal state t  suppose we initialize q0
0. Then for any source distribution σ and length (cid:96)  after any arbitrary sequence of REVERSE-
PUSH(v  k) operations  the vectors {qk

t = et and qk

t = 0  r0

t   rk

t   rk

t } satisfy the invariant:
(cid:104)σP k  r(cid:96)−k
(cid:105)

(cid:96)(cid:88)

t(cid:105) +

t

σ[t] = (cid:104)σ  q(cid:96)
p(cid:96)

k=0

(3)

The proof follows the outline of a similar result in Andersen et al. [4] for PageRank estimation; due
to lack of space  we defer it to our full version [8]. Using this result  we can now characterize the
accuracy of the Bidirectional-MSTP algorithm:
Theorem 1. We are given any Markov chain P   source distribution σ  terminal state t  maximum
length (cid:96)max and also parameters δ  pf and  (i.e.  the desired threshold  failure probability and
relative error). Suppose we choose any reverse threshold δr > δ  and set the number of sample-
with probability at least 1 − pf   the estimate returned by Bidirectional-MSTP satisﬁes:

paths nf = cδr/δ  where c = max(cid:8)6e/2  1/ ln 2(cid:9) ln (2(cid:96)max/pf ). Then for any length (cid:96) ≤ (cid:96)max

σ[t](cid:12)(cid:12) < max(cid:8)p(cid:96)

σ[t]  δ(cid:9) .

(cid:12)(cid:12)(cid:98)p(cid:96)
σ[t] − p(cid:96)
Equation (2) shows that the estimate(cid:98)p(cid:96)

t k obeys: (i) E[S(cid:96)

Proof. Given any Markov chain P and terminal state t  note ﬁrst that for a given length (cid:96) ≤ (cid:96)max 
σ[t] is an unbiased estimator. Now  for any random-trajectory
t k ∈ [0  (cid:96)δr]; the ﬁrst in-
Tk  we have that the score S(cid:96)
equality again follows from Equation (2)  while the second follows from the fact that we executed
REVERSE-PUSH operations until all residual values were less than δr.
Now consider the rescaled random variable Xk = S(cid:96)
have that Xk ∈ [0  1]  E[X] ≤ (nf /(cid:96)δr)p(cid:96)
Moreover  using standard Chernoff bounds (cf. Theorem 1.1 in [9])  we have that:
P [|X − E[X]| > E[X]] < 2 exp

σ[t] and also (X − E[X]) = (nf /(cid:96)δr)((cid:98)p(cid:96)

t k/((cid:96)δr) and X = (cid:80)

P[X > b] ≤ 2−b for any b > 2eE[X]

k∈[nf ] Xk; then we
σ[t]).

σ[t] − p(cid:96)

σ[t] and (ii) S(cid:96)

− 2E[X]

t k] ≤ p(cid:96)

(cid:18)

(cid:19)

and

3

t k] > δ/2e (i.e.  E[X] > nf δ/2e(cid:96)δr = c/2e): Here  we can use the ﬁrst concentration

Now we consider two cases:
1. E[S(cid:96)

bound to get:

P(cid:2)(cid:12)(cid:12)(cid:98)p(cid:96)

σ[t] − p(cid:96)

σ[t](cid:12)(cid:12) ≥ p(cid:96)

σ[t](cid:3) = P

(cid:20)

|X − E[X]| ≥ nf
(cid:96)δr
≤ 2 exp

(cid:18)
− 2E[X]

(cid:19)

σ[t]

p(cid:96)

≤ 2 exp

≤ P [|X − E[X]| ≥ E[X]]

(cid:21)
(cid:18)

(cid:19)

 

− 2c
6e

3

5

where we use that nf = c(cid:96)maxδr/δ (cf. Algorithm 2). Moreover  by the union bound  we have:

P

(cid:8)(cid:12)(cid:12)(cid:98)p(cid:96)

 (cid:91)

σ[t](cid:9) ≤ 2(cid:96)max exp

(cid:19)
Now as long as c ≥(cid:0)6e/2(cid:1) ln (2(cid:96)max/pf )  we get the desired failure probability.
σ[t] −(cid:98)p(cid:96)

σ[t] ≤ (nf /(cid:96)δr)E[X] ≤ δ/2e < δ. On the other hand  we also have:

σ[t](cid:12)(cid:12) ≥ p(cid:96)

σ[t] − p(cid:96)

− 2c
32e

(cid:96)≤(cid:96)max

(cid:18)

p(cid:96)

 

2. E[S(cid:96)

t k] < δ/2e (i.e.  E[X] < c/2e): In this case  note ﬁrst that since X > 0  we have that

P(cid:2)(cid:98)p(cid:96)

σ[t] − p(cid:96)

σ[t] ≥ δ(cid:3) = P

(cid:20)

(cid:21)

X − E[X] ≥ nf δ
(cid:96)δr

≤ P [X ≥ c] ≤ 2−c 

where the last inequality follows from our second concentration bound  which holds since we
have c > 2eE[X]. Now as before  we can use the union bound to show that the failure probability
is bounded by pf as long as c ≥ log2 ((cid:96)max/pf ).

Combining the two cases  we see that as long as c ≥ max(cid:8)6e/2  1/ ln 2(cid:9) ln (2(cid:96)max/pf )  then we
have P(cid:104)(cid:83)

σ[t](cid:12)(cid:12) ≥ max{δ  p(cid:96)

σ[t]}(cid:9)(cid:105) ≤ pf .

σ[t] − p(cid:96)

(cid:8)(cid:12)(cid:12)(cid:98)p(cid:96)

(cid:96)≤(cid:96)max

One aspect that is not obvious from the intuition in Section 2.2 or the accuracy analysis is if using a
bidirectional method actually improves the running time of MSTP-estimation. This is addressed by
the following result  which shows that for typical targets  our algorithm achieves signiﬁcant speedup:
Theorem 2. Let any Markov chain P   source distribution σ  maximum length (cid:96)max and parameters
δ  pf and  be given. Suppose we set δr =
(cid:96)max log((cid:96)max/pf ) . Then for a uniform random choice of

(cid:113)

2δ

t ∈ S  the Bidirectional-MSTP algorithm has a running time of (cid:101)O
each of length (cid:96)max – hence the running time is O(cid:0)cδ(cid:96)2

Proof. The runtime of Algorithm 2 consists of two parts:
Forward-work (i.e.  for generating trajectories): we generate nf = c(cid:96)maxδr/δ sample trajectories 

max/δ(cid:1) for any Markov chain P   source

distribution σ and target node t. Substituting for c from Theorem 1  we get that the forward-work
running time Tf = O
Reverse-work (i.e.  for REVERSE-PUSH operations): Let Tr denote the reverse-work runtime for
a uniform random choice of t ∈ S. Then we have:

maxδr log((cid:96)max/pf )

2δ

.

(cid:16) (cid:96)2

(cid:18)

(cid:113)

(cid:19)

(cid:96)3/2
max

d/δ

.

(cid:17)

(cid:88)

(cid:96)max(cid:88)

(cid:88)

t∈S

k=0

v∈S

E[Tr] =

1
|S|

(din(v) + 1)1{REVERSE-PUSH(v k) is executed}

t (v) > δr  and hence  by Equation (3)  we have that pk
ev

residuals for din(v) + 1 states. Note that(cid:80)
argument  we have that for any v ∈ S (cid:80)

Now for a given t ∈ S and k ∈ {0  1  . . .   (cid:96)max}  note that the only states v ∈ S on which we
execute REVERSE-PUSH(v  k) are those with residual rk
t (v) > δr – consequently  for these states 
[t] ≥ δr (by setting σ = ev 
we have that qk
i.e.  starting from state v). Moreover  a REVERSE-PUSH(v  k) operation involves updating the
[t] = 1 and hence  via a straightforward counting
[t]≥δr} ≤ 1/δr. Thus  we have:
(cid:19)

(cid:88)
(cid:96)max(cid:88)
(cid:80)

(din(v) + 1)1{pk
ev

(din(v) + 1)1{pk
ev

E[Tr] ≤ 1
|S|

t∈S pk
ev
t∈S 1{pk

(cid:96)max(cid:88)

(cid:88)

(cid:88)

[t]≥δr} =

[t]≥δr}

(cid:19)

v∈S

t∈S

k=0

ev

(cid:18) (cid:96)maxd

≤ 1
|S|

((cid:96)max + 1) · (din(v) + 1)

1
δr

= O

= O

δr

1
|S|

(cid:18) (cid:96)max

δr

v∈S
·

k=0
v∈S din(v)

|S|

(cid:88)
(cid:88)

t∈S

v∈S

(cid:113)

Finally  we choose δr =

(cid:96)max log((cid:96)max/pf ) to balance Tf and Tr and get the result.

2δ

6

σ

et

σ

(cid:113)

σ[t] for all values of (cid:96) ≤ (cid:96)max.

3 Applications of MSTP estimation
• Estimating the Stationary Distribution and Hitting Probabilities: MSTP-estimation can be
used in two ways to estimate stationary probabilities π[t]. First  if we know the mixing time τmix
of the chain P   we can directly use Algorithm 2 to approximate π[t] by setting (cid:96)max = τmix and
using any source distribution σ. Theorem 2 then guarantees that we can estimate a stationary
probability of order δ in time O(τ 3/2
d/δ). In comparison  Monte Carlo has O(τmix/δ) run-
mix
time. We note that in practice  we usually do not know the mixing time – in such a setting  our
algorithm can be used to compute an estimate of p(cid:96)

An alternative is to modify Algorithm 2 to estimate the truncated hitting time (cid:98)p(cid:96) hit
an estimate for the expected truncated return time E[Tt1{Tt≤(cid:96)max}] =(cid:80)
(cid:96)(cid:98)p(cid:96) hit

{1  2  . . .   (cid:96)max} (note: not i = 0)  instead of REVERSE-PUSH(t  i)  we update(cid:101)qi
t[t]  set(cid:101)ri
resulting quantity(cid:98)p(cid:96) hit

[t](i.e.  the
probability of hitting t starting from σ for the ﬁrst time in (cid:96) steps). By setting σ = et  we get
[t]. Now 
using that fact that π[t] = 1/E[Tt]  we can get a lower bound for π[t] which converges to π[t]
as (cid:96)max → ∞. We note also that the truncated hitting time has been shown to be useful in other
applications such as identifying similar documents on a document-word-author graph [10].
To estimate the truncated hitting time  we modify Algorithm 2 as follows: at each stage i ∈
t[t] +
t[t] to the in-neighbors of t in the (i + 1)th stage. The
ri
remaining algorithm remains the same. It is easy to see from the discussion in Section 2.2 that the
[t] is an unbiased estimate of P[Hitting time of t = (cid:96)|X0 ∼ σ] – we omit
• Exact Stationary Probabilities in Strong Doeblin chains: A strong Doeblin chain [11] is ob-
tained by mixing a Markov chain P and a distribution σ as follows: at each transition  the pro-
cess proceeds according to P with probability α  else samples a state from σ. Doeblin chains are
widely used in ML applications – special cases include the celebrated PageRank metric [12]  vari-
ants such as HITS and SALSA [13]  and other algorithms for applications such as ranking [14] and
structured prediction [15]. An important property of these chains is that if we sample a starting
node V0 from σ and sample a trajectory of length Geometric(α) starting from V0  then the termi-
nal node is an unbiased sample from the stationary distribution [16]. There are two ways in which
our algorithm can be used for this purpose: one is to replace the REVERSE-PUSH algorithm with
a corresponding local update algorithm for the strong Doeblin chain (similar to the one in Ander-
sen et al. [4] for PageRank)  and then sample random trajectories of length Geometric(α). A
σ[t]} ∀ (cid:96) ∈ [(cid:96)max] and then
more direct technique is to choose some (cid:96)max >> 1/α  estimate {p(cid:96)

t[t] = 0 and do not push back ri

a formal proof due to lack of space.

t[t] = qi

(cid:96)≤(cid:96)max

σ[t].

i=0 αi

• Graph Diffusions:

(cid:96)=1 α(cid:96)−1(1 − α)p(cid:96)

directly compute the stationary distribution as p[t] =(cid:80)(cid:96)max
graph  the resulting scoring functions f (P  σ)[t] := (cid:80)∞
that for any function f as deﬁned above  the truncated sum f (cid:96)max = (cid:80)(cid:96)max
||f − f (cid:96)max||∞ ≤ (cid:80)∞

If we assign a weight αi to random walks of length i on a (weighted)
diffusions [17] and are used in a variety of applications. The case where αi = αi−1(1 − α)
If instead the length is drawn according to a Poisson distribution
corresponds to PageRank.
(i.e.  αi = e−ααi/i!)  then the resulting function is called the heat-kernel h(G  α) – this too
has several applications  including ﬁnding communities (clusters) in large networks [5]. Note

(cid:0)σT P i(cid:1) [t] are known as a graph
(cid:0)pT
σ P i(cid:1) obeys

(cid:96)max+1 αi. Thus a guarantee on an estimate for the truncated sum directly
translates to a guarantee on the estimate for the diffusion. We can use MSTP-estimation to efﬁ-
ciently estimate these truncated sums. We perform numerical experiments on heat kernel estima-
tion in the next section.
• Conductance Testing in Graphs: MSTP-estimation is an essential primitive for conductance
testing in large Markov chains [1].
In particular  in regular undirected graphs  Kale et al [6]
develop a sublinear bidirectional estimator based on counting collisions between walks in order
to identify ‘weak’ nodes – those which belong to sets with small conductance. Our algorithm can
be used to extend this process to any graph  including weighted and directed graphs.
• Local Algorithms: There is a lot of interest recently on local algorithms – those which perform
computations given only a small neighborhood of a source node [18]. In this regard  we note that
Bidirectional-MSTP gives a natural local algorithm for MSTP estimation  and thus for the
applications mentioned above – given a k-hop neighborhood around the source and target  we can
perform Bidirectional-MSTP with (cid:96)max set to k. The proof of this follows from the fact
that the invariant in Equation (2) holds after any sequence of REVERSE-PUSH operations.

i=0 αi

7

Figure 2: Estimating heat kernels: Bidirectional MSTP-estimation vs. Monte Carlo  Forward Push.
To compare runtimes  we choose parameters such that the mean relative error of all algorithms is
around 10%. Notice that Bidirectional-MSTP is 100 times faster than the other algorithms.

4 Experiments

To demonstrate the efﬁciency of our algorithm on large Markov chains  we use heat kernel esti-
mation (cf. Section 3) as an example application. The heat kernel is a non-homogenous Markov
chain  deﬁned as the probability of stopping at the target on a random walk from the source  where
the walk length is sampled from a P oisson((cid:96)) Distribution. In real-world graphs  a heat-kernel
value between a pair of nodes has been shown to be a good indicator of an underlying community
relationship [5] – this suggests that it can serve as a metric for personalized search on social net-
works. For example  if a social network user s wants to view a list of users attending some event 
then sorting these users by heat kernel values will result in the most similar users to s appearing on
top. Bidirectional-MSTP is ideal for such personalized search applications  as the set of users
ﬁltered by a search query is typically much smaller than the set of nodes on the network.
In Figure 2  we compare the runtime of different algorithms for heat kernel computation on four
real-world graphs  ranging from millions to billions of edges 3. For each graph  for random (source 
target) pairs  we compute the heat kernel using Bidirectional-MSTP  as well as two bench-
mark algorithms – Monte Carlo  and the Forward Push algorithm (as presented in [5]). All three
algorithms have parameters which allow them to trade off speed and accuracy – for a fair compar-
ison  we choose parameters such that the empirical mean relative error each algorithm is 10%. All
three algorithms were implemented in Scala – for the forward push algorithm  our implementation
follows the code linked from [5]).
√
We set average walk-length (cid:96) = 5 (since longer walks will mix into the stationary distribution)  and
(cid:96) ≈ 27; the probability of a walk being longer than this is 10−12 
set the maximum length to (cid:96) + 10
which is negligible. For reproducibility  our source code is available on our website (cf. [8]).
Figure 2 shows that across all graphs  Bidirectional-MSTP is 100x faster than the two bench-
mark algorithms. For example  on the Twitter graph  it can estimate a heat kernel score is 0.1
seconds  while the the other algorithms take more than 4 minutes. We note though that Monte Carlo
and Forward Push can return scores from the source to all targets  rather than just one target – thus
Bidirectional-MSTP is most useful when we want the score for a small set of targets.

Acknowledgments

Research supported by the DARPA GRAPHS program via grant FA9550-12-1-0411  and by NSF
grant 1447697. Peter Lofgren was supported by an NPSC fellowship. Thanks to Ashish Goel and
other members of the Social Algorithms Lab at Stanford for many helpful discussions.

3Pokec [19]  Live Journal [20]  and Orkut [20] datasets are from the SNAP [21]; Twitter-2010 [22] was

downloaded from the Laboratory for Web Algorithmics [23]. Refer to our full version [8] for details.

8

References

[1] Oded Goldreich and Dana Ron. On testing expansion in bounded-degree graphs. In Studies in Complexity
and Cryptography. Miscellanea on the Interplay between Randomness and Computation. Springer  2011.
[2] Peter Lofgren  Siddhartha Banerjee  Ashish Goel  and C Seshadhri. FAST-PPR: Scaling personalized

PageRank estimation for large graphs. In ACM SIGKDD’14  2014.

[3] Reid Andersen  Fan Chung  and Kevin Lang. Local graph partitioning using PageRank vectors. In IEEE

FOCS’06  2006.

[4] Reid Andersen  Christian Borgs  Jennifer Chayes  John Hopcraft  Vahab S Mirrokni  and Shang-Hua
In Algorithms and Models for the Web-Graph.

Teng. Local computation of PageRank contributions.
Springer  2007.

[5] Kyle Kloster and David F Gleich. Heat kernel based community detection. In ACM SIGKDD’14  2014.
[6] Satyen Kale  Yuval Peres  and C Seshadhri. Noise tolerance of expanders and sublinear expander recon-

struction. In IEEE FOCS’08  2008.

[7] Rajeev Motwani  Rina Panigrahy  and Ying Xu. Estimating sum by weighted sampling. In Automata 

Languages and Programming  pages 53–64. Springer  2007.

[8] Siddhartha Banerjee and Peter Lofgren. Fast bidirectional probability estimation in markov models. Tech-

nical report  2015. http://arxiv.org/abs/1507.05998.

[9] Devdatt P Dubhashi and Alessandro Panconesi. Concentration of measure for the analysis of randomized

algorithms. Cambridge University Press  2009.

[10] Purnamrita Sarkar  Andrew W Moore  and Amit Prakash. Fast incremental proximity search in large
graphs. In Proceedings of the 25th international conference on Machine learning  pages 896–903. ACM 
2008.

[11] Wolfgang Doeblin. Elements d’une theorie generale des chaines simples constantes de markoff.

In
Annales Scientiﬁques de l’Ecole Normale Sup´erieure  volume 57  pages 61–111. Soci´et´e math´ematique
de France  1940.

[12] Lawrence Page  Sergey Brin  Rajeev Motwani  and Terry Winograd. The pagerank citation ranking:

bringing order to the web. 1999.

[13] Ronny Lempel and Shlomo Moran. The stochastic approach for link-structure analysis (SALSA) and the

TKC effect. Computer Networks  33(1):387–401  2000.

[14] Sahand Negahban  Sewoong Oh  and Devavrat Shah. Iterative ranking from pair-wise comparisons. In

Advances in Neural Information Processing Systems  pages 2474–2482  2012.

[15] Jacob Steinhardt and Percy Liang. Learning fast-mixing models for structured prediction. In ICML’15 

2015.

[16] Krishna B Athreya and ¨Orjan Stenﬂo. Perfect sampling for Doeblin chains. Sankhy¯a: The Indian Journal

of Statistics  pages 763–777  2003.

[17] Fan Chung. The heat kernel as the pagerank of a graph. Proceedings of the National Academy of Sciences 

104(50):19735–19740  2007.

[18] Christina E Lee  Asuman Ozdaglar  and Devavrat Shah. Computing the stationary distribution locally. In

Advances in Neural Information Processing Systems  pages 1376–1384  2013.

[19] Lubos Takac and Michal Zabovsky. Data analysis in public social networks. In International. Scientiﬁc

Conf. & Workshop Present Day Trends of Innovations  2012.

[20] Alan Mislove  Massimiliano Marcon  Krishna P. Gummadi  Peter Druschel  and Bobby Bhattacharjee.
Measurement and Analysis of Online Social Networks. In Proceedings of the 5th ACM/Usenix Internet
Measurement Conference (IMC’07)  San Diego  CA  October 2007.

[21] Stanford Network Analysis Platform (SNAP). http://http://snap.stanford.edu/. Ac-

cessed: 2014-02-11.

[22] Paolo Boldi  Marco Rosa  Massimo Santini  and Sebastiano Vigna. Layered label propagation: A multi

resolution coordinate-free ordering for compressing social networks. In ACM WWW’11  2011.

[23] Laboratory for Web Algorithmics. http://law.di.unimi.it/datasets.php. Accessed: 2014-

02-11.

9

,Aaron Defazio
Francis Bach
Simon Lacoste-Julien
Siddhartha Banerjee
Peter Lofgren
Soheil Feizi
Hamid Javadi
David Tse
Jingwei Xu
Bingbing Ni
Xiaokang Yang