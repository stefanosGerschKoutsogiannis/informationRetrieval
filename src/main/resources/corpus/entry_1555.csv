2019,Disentangled behavioural representations,Individual characteristics in human decision-making are often
  quantified by fitting a parametric cognitive model to subjects'
  behavior and then studying differences between them in the associated
  parameter space.  However  these models often fit behavior more poorly
  than recurrent neural networks (RNNs)  which are more flexible and
  make fewer assumptions about the underlying decision-making processes.
  Unfortunately  the parameter and latent activity spaces of RNNs are
  generally high-dimensional and uninterpretable  making it hard to use
  them to study individual differences.  Here  we
  show how to benefit from the flexibility of RNNs while representing
  individual differences in a low-dimensional and interpretable space.
  To achieve this  we propose a novel end-to-end learning framework in
  which an encoder is trained to map the behavior of subjects into a
  low-dimensional latent space. These low-dimensional representations
  are used to generate the parameters of individual RNNs corresponding
  to the decision-making process of each subject.  We introduce terms
  into the loss function that ensure that the latent dimensions are
  informative and disentangled  i.e. 
encouraged to have distinct effects on behavior. This allows them to
align with separate facets of
  individual differences. We illustrate the performance
   of our framework on synthetic data as well as a dataset including the behavior
   of patients with psychiatric disorders.,Disentangled behavioral representations

Amir Dezfouli1∗ Hassan Ashtiani2 Omar Ghattas13
Richard Nock145 Peter Dayan6# Cheng Soon Ong14

1Data61  CSIRO 2McMaster University 3University of Chicago

4Australian National University 5University of Sydney 6Max Planck Institute
Corresponding authors ∗amir.dezfouli@data61.csiro.au #dayan@tue.mpg.de

Abstract

Individual characteristics in human decision-making are often quantiﬁed by ﬁtting
a parametric cognitive model to subjects’ behavior and then studying differences
between them in the associated parameter space. However  these models often ﬁt
behavior more poorly than recurrent neural networks (RNNs)  which are more ﬂex-
ible and make fewer assumptions about the underlying decision-making processes.
Unfortunately  the parameter and latent activity spaces of RNNs are generally high-
dimensional and uninterpretable  making it hard to use them to study individual
differences. Here  we show how to beneﬁt from the ﬂexibility of RNNs while
representing individual differences in a low-dimensional and interpretable space.
To achieve this  we propose a novel end-to-end learning framework in which an
encoder is trained to map the behavior of subjects into a low-dimensional latent
space. These low-dimensional representations are used to generate the parameters
of individual RNNs corresponding to the decision-making process of each subject.
We introduce terms into the loss function that ensure that the latent dimensions are
informative and disentangled  i.e.  encouraged to have distinct effects on behav-
ior. This allows them to align with separate facets of individual differences. We
illustrate the performance of our framework on synthetic data as well as a dataset
including the behavior of patients with psychiatric disorders.

1

Introduction

There is substantial commonality among humans (and other animals) in the way that they learn from
experience in order to make decisions. However  there is often also considerable variability in the
choices of different subjects in the same task [Carroll and Maxwell  1979]. Such variability is rooted
in the structure of the underlying processes; for example  subjects can differ in their tendencies to
explore new actions [e.g.  Frank et al.  2009] or in the weights they give to past experiences [e.g. 
den Ouden et al.  2013]. If meaningfully disentangled  these factors would crisply characterise
the decision-making processes of the subjects  and would provide a low-dimensional latent space
that could be used for many other tasks including studying the behavioral heterogeneity of subjects
endowed with the same psychiatric labels. However  extracting such representations from behavioral
data is challenging  as choices emerge from a complex set of interactions between latent variables
and past experiences  making disentanglement difﬁcult.
One promising approach proposed for learning low-dimensional representations of behavioral data is
through the use of cognitive modelling [e.g.  Navarro et al.  2006  Busemeyer and Stout  2002]; for
example using a reinforcement learning framework [e.g.  Daw  2011]. In this approach  a parametrised
computational model is assumed to underlie the decision-making process  and the parameters of this
model – such as the tendency to explore and the learning rate – are found by ﬁtting each subject’s

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

Figure 1: The model comprises an encoder (shown in red) and decoder (blue). The encoder is the
composition of an RNN and a series of fully-connected layers. The encoder maps each whole input
sequence (in the rectangles on the left) into a point in the latent space (depicted by (z1  z2)-coordinates
in the middle) based on the ﬁnal state of the RNN. The latent representation for each input sequence is
in turn fed into the decoder (shown in blue). The decoder generates the weights of an RNN (called the
learning network here) and is shown by the dotted lines on the right side. The learning network is the
reconstruction of the closed-loop dynamical process of the subject which generated the corresponding
input sequence based on experience. This takes as inputs the previous reward  rn
t−1  previous action 
t is then multiplied by matrix
t−1  and its previous state  xn
an
W n to generate unnormalised probabilities (logits) vn
t for taking each action in the next trial  which
are converted (through a softmax) to actual probabilities  πn
t (.). The negative-log-likelihoods of the
true actions are used to deﬁne the reconstruction loss  LRE  which along with LDIS and LSEP are used
to train the model. The LDIS term induces disentanglement at the group level  and LSEP separates the
effects of each dimension of the latent space on the output of the learning network.

t−1  and outputs its next state (xn

t ). xn

choices. Their individual parameters are treated as the latent representations of each subject. This
approach has been successful at identifying differences between subjects in various conditions [e.g. 
Yechiam et al.  2005]; however  it is constrained by its reliance on the availability of a suitable
parametric model that can capture behavior and behavioral variability across subjects. In practice 
this often leads to manually designing and comparing a limited number of alternative models which
may not ﬁt the behavioral data closely.
An alternative class of computational models of human decision-making involves Recurrent Neural
Networks (RNNs) [e.g.  Dezfouli et al.  2019  2018  Yang et al.  2019]. RNNs can model a wide range
of dynamical systems [Siegelmann and Sontag  1995] including human decision-making processes 
and make fewer restrictive assumptions about the underlying dynamical processes. However  unlike
cognitive models  RNNs typically: (i) have large numbers of parameters  which (ii) are hard to
interpret. This renders RNNs impractical for studying and modelling individual differences.
Here we develop a novel approach which beneﬁts from the ﬂexibility of RNNs  while representing
individual differences in a low-dimensional and interpretable space. For the former  we use an
autoencoder framework [Rumelhart et al.  1985  Tolstikhin et al.  2017] in which we take the behaviors
of a set of subjects as input and automatically build a low-dimensional latent space which quantiﬁes
aspects of individual differences along different latent dimensions (Figure 1). As in an hyper-networks
[Ha et al.  2016  Karaletsos et al.  2018]  the coordinates of each subject within this latent space are
then used to generate the parameters of an RNN which models the decision-making processes of
that subject. To address interpretability  we introduce a novel contribution to the autoencoder’s loss
function which encourages the different dimensions of the latent space to have separate effects on
predicted behavior. This allows them to be interpreted independently. We show that this model is
able to learn and extract low-dimensional representations from synthetically-generated behavioral
data in which we know the ground truth  and we then apply it to experimental data.

2 The model

Data. The data D ≡ {Dn}N
n=1 comprise N input sequences  in which each sequence n ∈ {1 . . . N}
consists of the choices of a subject on a sequential decision-making task. In input sequence n ∈

2

RNNz1<latexit sha1_base64="yl55mjaQ5FGhj99HcYtcX7mFKtw=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lE0GPBi8eKpi20oWy2m3bpZhN2J0IN/QlePCji1V/kzX/jts1BWx8MPN6bYWZemEph0HW/ndLa+sbmVnm7srO7t39QPTxqmSTTjPsskYnuhNRwKRT3UaDknVRzGoeSt8PxzcxvP3JtRKIecJLyIKZDJSLBKFrp/qnv9as1t+7OQVaJV5AaFGj2q1+9QcKymCtkkhrT9dwUg5xqFEzyaaWXGZ5SNqZD3rVU0ZibIJ+fOiVnVhmQKNG2FJK5+nsip7Exkzi0nTHFkVn2ZuJ/XjfD6DrIhUoz5IotFkWZJJiQ2d9kIDRnKCeWUKaFvZWwEdWUoU2nYkPwll9eJa2LuufWvbvLWoMUcZThBE7hHDy4ggbcQhN8YDCEZ3iFN0c6L86787FoLTnFzDH8gfP5AwSCjYA=</latexit><latexit sha1_base64="yl55mjaQ5FGhj99HcYtcX7mFKtw=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lE0GPBi8eKpi20oWy2m3bpZhN2J0IN/QlePCji1V/kzX/jts1BWx8MPN6bYWZemEph0HW/ndLa+sbmVnm7srO7t39QPTxqmSTTjPsskYnuhNRwKRT3UaDknVRzGoeSt8PxzcxvP3JtRKIecJLyIKZDJSLBKFrp/qnv9as1t+7OQVaJV5AaFGj2q1+9QcKymCtkkhrT9dwUg5xqFEzyaaWXGZ5SNqZD3rVU0ZibIJ+fOiVnVhmQKNG2FJK5+nsip7Exkzi0nTHFkVn2ZuJ/XjfD6DrIhUoz5IotFkWZJJiQ2d9kIDRnKCeWUKaFvZWwEdWUoU2nYkPwll9eJa2LuufWvbvLWoMUcZThBE7hHDy4ggbcQhN8YDCEZ3iFN0c6L86787FoLTnFzDH8gfP5AwSCjYA=</latexit><latexit sha1_base64="yl55mjaQ5FGhj99HcYtcX7mFKtw=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lE0GPBi8eKpi20oWy2m3bpZhN2J0IN/QlePCji1V/kzX/jts1BWx8MPN6bYWZemEph0HW/ndLa+sbmVnm7srO7t39QPTxqmSTTjPsskYnuhNRwKRT3UaDknVRzGoeSt8PxzcxvP3JtRKIecJLyIKZDJSLBKFrp/qnv9as1t+7OQVaJV5AaFGj2q1+9QcKymCtkkhrT9dwUg5xqFEzyaaWXGZ5SNqZD3rVU0ZibIJ+fOiVnVhmQKNG2FJK5+nsip7Exkzi0nTHFkVn2ZuJ/XjfD6DrIhUoz5IotFkWZJJiQ2d9kIDRnKCeWUKaFvZWwEdWUoU2nYkPwll9eJa2LuufWvbvLWoMUcZThBE7hHDy4ggbcQhN8YDCEZ3iFN0c6L86787FoLTnFzDH8gfP5AwSCjYA=</latexit><latexit sha1_base64="yl55mjaQ5FGhj99HcYtcX7mFKtw=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lE0GPBi8eKpi20oWy2m3bpZhN2J0IN/QlePCji1V/kzX/jts1BWx8MPN6bYWZemEph0HW/ndLa+sbmVnm7srO7t39QPTxqmSTTjPsskYnuhNRwKRT3UaDknVRzGoeSt8PxzcxvP3JtRKIecJLyIKZDJSLBKFrp/qnv9as1t+7OQVaJV5AaFGj2q1+9QcKymCtkkhrT9dwUg5xqFEzyaaWXGZ5SNqZD3rVU0ZibIJ+fOiVnVhmQKNG2FJK5+nsip7Exkzi0nTHFkVn2ZuJ/XjfD6DrIhUoz5IotFkWZJJiQ2d9kIDRnKCeWUKaFvZWwEdWUoU2nYkPwll9eJa2LuufWvbvLWoMUcZThBE7hHDy4ggbcQhN8YDCEZ3iFN0c6L86787FoLTnFzDH8gfP5AwSCjYA=</latexit>z2<latexit sha1_base64="R/3clTzm+nXZiDAT3HmS7xMZEDs=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKUI8FLx4r2g9oQ9lsJ+3SzSbsboQa+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8IBFcG9f9dgobm1vbO8Xd0t7+weFR+fikreNUMWyxWMSqG1CNgktsGW4EdhOFNAoEdoLJzdzvPKLSPJYPZpqgH9GR5CFn1Fjp/mlQG5QrbtVdgKwTLycVyNEclL/6w5ilEUrDBNW657mJ8TOqDGcCZ6V+qjGhbEJH2LNU0gi1ny1OnZELqwxJGCtb0pCF+nsio5HW0yiwnRE1Y73qzcX/vF5qwms/4zJJDUq2XBSmgpiYzP8mQ66QGTG1hDLF7a2EjamizNh0SjYEb/XlddKuVT236t1dVRokj6MIZ3AOl+BBHRpwC01oAYMRPMMrvDnCeXHenY9la8HJZ07hD5zPHwYGjYE=</latexit><latexit sha1_base64="R/3clTzm+nXZiDAT3HmS7xMZEDs=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKUI8FLx4r2g9oQ9lsJ+3SzSbsboQa+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8IBFcG9f9dgobm1vbO8Xd0t7+weFR+fikreNUMWyxWMSqG1CNgktsGW4EdhOFNAoEdoLJzdzvPKLSPJYPZpqgH9GR5CFn1Fjp/mlQG5QrbtVdgKwTLycVyNEclL/6w5ilEUrDBNW657mJ8TOqDGcCZ6V+qjGhbEJH2LNU0gi1ny1OnZELqwxJGCtb0pCF+nsio5HW0yiwnRE1Y73qzcX/vF5qwms/4zJJDUq2XBSmgpiYzP8mQ66QGTG1hDLF7a2EjamizNh0SjYEb/XlddKuVT236t1dVRokj6MIZ3AOl+BBHRpwC01oAYMRPMMrvDnCeXHenY9la8HJZ07hD5zPHwYGjYE=</latexit><latexit sha1_base64="R/3clTzm+nXZiDAT3HmS7xMZEDs=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKUI8FLx4r2g9oQ9lsJ+3SzSbsboQa+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8IBFcG9f9dgobm1vbO8Xd0t7+weFR+fikreNUMWyxWMSqG1CNgktsGW4EdhOFNAoEdoLJzdzvPKLSPJYPZpqgH9GR5CFn1Fjp/mlQG5QrbtVdgKwTLycVyNEclL/6w5ilEUrDBNW657mJ8TOqDGcCZ6V+qjGhbEJH2LNU0gi1ny1OnZELqwxJGCtb0pCF+nsio5HW0yiwnRE1Y73qzcX/vF5qwms/4zJJDUq2XBSmgpiYzP8mQ66QGTG1hDLF7a2EjamizNh0SjYEb/XlddKuVT236t1dVRokj6MIZ3AOl+BBHRpwC01oAYMRPMMrvDnCeXHenY9la8HJZ07hD5zPHwYGjYE=</latexit><latexit sha1_base64="R/3clTzm+nXZiDAT3HmS7xMZEDs=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKUI8FLx4r2g9oQ9lsJ+3SzSbsboQa+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8IBFcG9f9dgobm1vbO8Xd0t7+weFR+fikreNUMWyxWMSqG1CNgktsGW4EdhOFNAoEdoLJzdzvPKLSPJYPZpqgH9GR5CFn1Fjp/mlQG5QrbtVdgKwTLycVyNEclL/6w5ilEUrDBNW657mJ8TOqDGcCZ6V+qjGhbEJH2LNU0gi1ny1OnZELqwxJGCtb0pCF+nsio5HW0yiwnRE1Y73qzcX/vF5qwms/4zJJDUq2XBSmgpiYzP8mQ66QGTG1hDLF7a2EjamizNh0SjYEb/XlddKuVT236t1dVRokj6MIZ3AOl+BBHRpwC01oAYMRPMMrvDnCeXHenY9la8HJZ07hD5zPHwYGjYE=</latexit>LDIS<latexit sha1_base64="FoCyHyV2A4z+04iCucXqZxMxXQg=">AAAB/3icbVDLSsNAFJ3UV62vqODGzWARXJVEBF0WdKHgoqJ9QBPCZDpph04ezNyIJWbhr7hxoYhbf8Odf+Ok7UJbDwwczrmXe+b4ieAKLOvbKC0sLi2vlFcra+sbm1vm9k5LxamkrEljEcuOTxQTPGJN4CBYJ5GMhL5gbX94XvjteyYVj6M7GCXMDUk/4gGnBLTkmXtOSGBAiciuc88B9gDZxdVt7plVq2aNgeeJPSVVNEXDM7+cXkzTkEVABVGqa1sJuBmRwKlgecVJFUsIHZI+62oakZApNxvnz/GhVno4iKV+EeCx+nsjI6FSo9DXk0VaNesV4n9eN4XgzM14lKTAIjo5FKQCQ4yLMnCPS0ZBjDQhVHKdFdMBkYSCrqyiS7BnvzxPWsc126rZNyfVOp7WUUb76AAdIRudojq6RA3URBQ9omf0it6MJ+PFeDc+JqMlY7qzi/7A+PwBY5qWNw==</latexit><latexit sha1_base64="FoCyHyV2A4z+04iCucXqZxMxXQg=">AAAB/3icbVDLSsNAFJ3UV62vqODGzWARXJVEBF0WdKHgoqJ9QBPCZDpph04ezNyIJWbhr7hxoYhbf8Odf+Ok7UJbDwwczrmXe+b4ieAKLOvbKC0sLi2vlFcra+sbm1vm9k5LxamkrEljEcuOTxQTPGJN4CBYJ5GMhL5gbX94XvjteyYVj6M7GCXMDUk/4gGnBLTkmXtOSGBAiciuc88B9gDZxdVt7plVq2aNgeeJPSVVNEXDM7+cXkzTkEVABVGqa1sJuBmRwKlgecVJFUsIHZI+62oakZApNxvnz/GhVno4iKV+EeCx+nsjI6FSo9DXk0VaNesV4n9eN4XgzM14lKTAIjo5FKQCQ4yLMnCPS0ZBjDQhVHKdFdMBkYSCrqyiS7BnvzxPWsc126rZNyfVOp7WUUb76AAdIRudojq6RA3URBQ9omf0it6MJ+PFeDc+JqMlY7qzi/7A+PwBY5qWNw==</latexit><latexit sha1_base64="FoCyHyV2A4z+04iCucXqZxMxXQg=">AAAB/3icbVDLSsNAFJ3UV62vqODGzWARXJVEBF0WdKHgoqJ9QBPCZDpph04ezNyIJWbhr7hxoYhbf8Odf+Ok7UJbDwwczrmXe+b4ieAKLOvbKC0sLi2vlFcra+sbm1vm9k5LxamkrEljEcuOTxQTPGJN4CBYJ5GMhL5gbX94XvjteyYVj6M7GCXMDUk/4gGnBLTkmXtOSGBAiciuc88B9gDZxdVt7plVq2aNgeeJPSVVNEXDM7+cXkzTkEVABVGqa1sJuBmRwKlgecVJFUsIHZI+62oakZApNxvnz/GhVno4iKV+EeCx+nsjI6FSo9DXk0VaNesV4n9eN4XgzM14lKTAIjo5FKQCQ4yLMnCPS0ZBjDQhVHKdFdMBkYSCrqyiS7BnvzxPWsc126rZNyfVOp7WUUb76AAdIRudojq6RA3URBQ9omf0it6MJ+PFeDc+JqMlY7qzi/7A+PwBY5qWNw==</latexit><latexit sha1_base64="FoCyHyV2A4z+04iCucXqZxMxXQg=">AAAB/3icbVDLSsNAFJ3UV62vqODGzWARXJVEBF0WdKHgoqJ9QBPCZDpph04ezNyIJWbhr7hxoYhbf8Odf+Ok7UJbDwwczrmXe+b4ieAKLOvbKC0sLi2vlFcra+sbm1vm9k5LxamkrEljEcuOTxQTPGJN4CBYJ5GMhL5gbX94XvjteyYVj6M7GCXMDUk/4gGnBLTkmXtOSGBAiciuc88B9gDZxdVt7plVq2aNgeeJPSVVNEXDM7+cXkzTkEVABVGqa1sJuBmRwKlgecVJFUsIHZI+62oakZApNxvnz/GhVno4iKV+EeCx+nsjI6FSo9DXk0VaNesV4n9eN4XgzM14lKTAIjo5FKQCQ4yLMnCPS0ZBjDQhVHKdFdMBkYSCrqyiS7BnvzxPWsc126rZNyfVOp7WUUb76AAdIRudojq6RA3URBQ9omf0it6MJ+PFeDc+JqMlY7qzi/7A+PwBY5qWNw==</latexit>xnt1<latexit sha1_base64="BN+VMrBMKvoavnEgTZ6+fbdhQXA=">AAAB/XicbVDLSsNAFJ3UV62v+Ni5GSyCG0sigi4LblxWsA9oY5hMJ+3QySTM3Ig1BH/FjQtF3Pof7vwbJ20X2npg4HDOvdwzJ0gE1+A431ZpaXllda28XtnY3NresXf3WjpOFWVNGotYdQKimeCSNYGDYJ1EMRIFgrWD0VXht++Z0jyWtzBOmBeRgeQhpwSM5NsHvYjAMAizh9zP4NTN7zKZ+3bVqTkT4EXizkgVzdDw7a9eP6ZpxCRQQbTuuk4CXkYUcCpYXumlmiWEjsiAdQ2VJGLayybpc3xslD4OY2WeBDxRf29kJNJ6HAVmssiq571C/M/rphBeehmXSQpM0umhMBUYYlxUgftcMQpibAihipusmA6JIhRMYRVTgjv/5UXSOqu5Ts29Oa/W8ayOMjpER+gEuegC1dE1aqAmougRPaNX9GY9WS/Wu/UxHS1Zs5199AfW5w8MPJV8</latexit><latexit sha1_base64="BN+VMrBMKvoavnEgTZ6+fbdhQXA=">AAAB/XicbVDLSsNAFJ3UV62v+Ni5GSyCG0sigi4LblxWsA9oY5hMJ+3QySTM3Ig1BH/FjQtF3Pof7vwbJ20X2npg4HDOvdwzJ0gE1+A431ZpaXllda28XtnY3NresXf3WjpOFWVNGotYdQKimeCSNYGDYJ1EMRIFgrWD0VXht++Z0jyWtzBOmBeRgeQhpwSM5NsHvYjAMAizh9zP4NTN7zKZ+3bVqTkT4EXizkgVzdDw7a9eP6ZpxCRQQbTuuk4CXkYUcCpYXumlmiWEjsiAdQ2VJGLayybpc3xslD4OY2WeBDxRf29kJNJ6HAVmssiq571C/M/rphBeehmXSQpM0umhMBUYYlxUgftcMQpibAihipusmA6JIhRMYRVTgjv/5UXSOqu5Ts29Oa/W8ayOMjpER+gEuegC1dE1aqAmougRPaNX9GY9WS/Wu/UxHS1Zs5199AfW5w8MPJV8</latexit><latexit sha1_base64="BN+VMrBMKvoavnEgTZ6+fbdhQXA=">AAAB/XicbVDLSsNAFJ3UV62v+Ni5GSyCG0sigi4LblxWsA9oY5hMJ+3QySTM3Ig1BH/FjQtF3Pof7vwbJ20X2npg4HDOvdwzJ0gE1+A431ZpaXllda28XtnY3NresXf3WjpOFWVNGotYdQKimeCSNYGDYJ1EMRIFgrWD0VXht++Z0jyWtzBOmBeRgeQhpwSM5NsHvYjAMAizh9zP4NTN7zKZ+3bVqTkT4EXizkgVzdDw7a9eP6ZpxCRQQbTuuk4CXkYUcCpYXumlmiWEjsiAdQ2VJGLayybpc3xslD4OY2WeBDxRf29kJNJ6HAVmssiq571C/M/rphBeehmXSQpM0umhMBUYYlxUgftcMQpibAihipusmA6JIhRMYRVTgjv/5UXSOqu5Ts29Oa/W8ayOMjpER+gEuegC1dE1aqAmougRPaNX9GY9WS/Wu/UxHS1Zs5199AfW5w8MPJV8</latexit><latexit sha1_base64="BN+VMrBMKvoavnEgTZ6+fbdhQXA=">AAAB/XicbVDLSsNAFJ3UV62v+Ni5GSyCG0sigi4LblxWsA9oY5hMJ+3QySTM3Ig1BH/FjQtF3Pof7vwbJ20X2npg4HDOvdwzJ0gE1+A431ZpaXllda28XtnY3NresXf3WjpOFWVNGotYdQKimeCSNYGDYJ1EMRIFgrWD0VXht++Z0jyWtzBOmBeRgeQhpwSM5NsHvYjAMAizh9zP4NTN7zKZ+3bVqTkT4EXizkgVzdDw7a9eP6ZpxCRQQbTuuk4CXkYUcCpYXumlmiWEjsiAdQ2VJGLayybpc3xslD4OY2WeBDxRf29kJNJ6HAVmssiq571C/M/rphBeehmXSQpM0umhMBUYYlxUgftcMQpibAihipusmA6JIhRMYRVTgjv/5UXSOqu5Ts29Oa/W8ayOMjpER+gEuegC1dE1aqAmougRPaNX9GY9WS/Wu/UxHS1Zs5199AfW5w8MPJV8</latexit>ant1<latexit sha1_base64="xMovVCBOML7Z1VLF3K8Y9jsU4M4=">AAAB8HicbVDLSgNBEOz1GeMr6tHLYBC8GHZF0GPAi8cI5iHJGmYnk2TIzOwy0yuEJV/hxYMiXv0cb/6Nk2QPmljQUFR1090VJVJY9P1vb2V1bX1js7BV3N7Z3dsvHRw2bJwaxusslrFpRdRyKTSvo0DJW4nhVEWSN6PRzdRvPnFjRazvcZzwUNGBFn3BKDrpgT7qbobnwaRbKvsVfwayTIKclCFHrVv66vRiliqukUlqbTvwEwwzalAwySfFTmp5QtmIDnjbUU0Vt2E2O3hCTp3SI/3YuNJIZurviYwqa8cqcp2K4tAuelPxP6+dYv86zIROUuSazRf1U0kwJtPvSU8YzlCOHaHMCHcrYUNqKEOXUdGFECy+vEwaF5XArwR3l+UqyeMowDGcwBkEcAVVuIUa1IGBgmd4hTfPeC/eu/cxb13x8pkj+APv8wdqBZAI</latexit><latexit sha1_base64="xMovVCBOML7Z1VLF3K8Y9jsU4M4=">AAAB8HicbVDLSgNBEOz1GeMr6tHLYBC8GHZF0GPAi8cI5iHJGmYnk2TIzOwy0yuEJV/hxYMiXv0cb/6Nk2QPmljQUFR1090VJVJY9P1vb2V1bX1js7BV3N7Z3dsvHRw2bJwaxusslrFpRdRyKTSvo0DJW4nhVEWSN6PRzdRvPnFjRazvcZzwUNGBFn3BKDrpgT7qbobnwaRbKvsVfwayTIKclCFHrVv66vRiliqukUlqbTvwEwwzalAwySfFTmp5QtmIDnjbUU0Vt2E2O3hCTp3SI/3YuNJIZurviYwqa8cqcp2K4tAuelPxP6+dYv86zIROUuSazRf1U0kwJtPvSU8YzlCOHaHMCHcrYUNqKEOXUdGFECy+vEwaF5XArwR3l+UqyeMowDGcwBkEcAVVuIUa1IGBgmd4hTfPeC/eu/cxb13x8pkj+APv8wdqBZAI</latexit><latexit sha1_base64="xMovVCBOML7Z1VLF3K8Y9jsU4M4=">AAAB8HicbVDLSgNBEOz1GeMr6tHLYBC8GHZF0GPAi8cI5iHJGmYnk2TIzOwy0yuEJV/hxYMiXv0cb/6Nk2QPmljQUFR1090VJVJY9P1vb2V1bX1js7BV3N7Z3dsvHRw2bJwaxusslrFpRdRyKTSvo0DJW4nhVEWSN6PRzdRvPnFjRazvcZzwUNGBFn3BKDrpgT7qbobnwaRbKvsVfwayTIKclCFHrVv66vRiliqukUlqbTvwEwwzalAwySfFTmp5QtmIDnjbUU0Vt2E2O3hCTp3SI/3YuNJIZurviYwqa8cqcp2K4tAuelPxP6+dYv86zIROUuSazRf1U0kwJtPvSU8YzlCOHaHMCHcrYUNqKEOXUdGFECy+vEwaF5XArwR3l+UqyeMowDGcwBkEcAVVuIUa1IGBgmd4hTfPeC/eu/cxb13x8pkj+APv8wdqBZAI</latexit><latexit sha1_base64="xMovVCBOML7Z1VLF3K8Y9jsU4M4=">AAAB8HicbVDLSgNBEOz1GeMr6tHLYBC8GHZF0GPAi8cI5iHJGmYnk2TIzOwy0yuEJV/hxYMiXv0cb/6Nk2QPmljQUFR1090VJVJY9P1vb2V1bX1js7BV3N7Z3dsvHRw2bJwaxusslrFpRdRyKTSvo0DJW4nhVEWSN6PRzdRvPnFjRazvcZzwUNGBFn3BKDrpgT7qbobnwaRbKvsVfwayTIKclCFHrVv66vRiliqukUlqbTvwEwwzalAwySfFTmp5QtmIDnjbUU0Vt2E2O3hCTp3SI/3YuNJIZurviYwqa8cqcp2K4tAuelPxP6+dYv86zIROUuSazRf1U0kwJtPvSU8YzlCOHaHMCHcrYUNqKEOXUdGFECy+vEwaF5XArwR3l+UqyeMowDGcwBkEcAVVuIUa1IGBgmd4hTfPeC/eu/cxb13x8pkj+APv8wdqBZAI</latexit>rnt1<latexit sha1_base64="Y9gtPiZym8euQvLji49w3e56mrQ=">AAAB8HicbVDLSgNBEOz1GeMr6tHLYBC8GHZF0GPAi8cI5iHJGmYnk2TIzOwy0yuEJV/hxYMiXv0cb/6Nk2QPmljQUFR1090VJVJY9P1vb2V1bX1js7BV3N7Z3dsvHRw2bJwaxusslrFpRdRyKTSvo0DJW4nhVEWSN6PRzdRvPnFjRazvcZzwUNGBFn3BKDrpwTzqbobnwaRbKvsVfwayTIKclCFHrVv66vRiliqukUlqbTvwEwwzalAwySfFTmp5QtmIDnjbUU0Vt2E2O3hCTp3SI/3YuNJIZurviYwqa8cqcp2K4tAuelPxP6+dYv86zIROUuSazRf1U0kwJtPvSU8YzlCOHaHMCHcrYUNqKEOXUdGFECy+vEwaF5XArwR3l+UqyeMowDGcwBkEcAVVuIUa1IGBgmd4hTfPeC/eu/cxb13x8pkj+APv8weEUZAZ</latexit><latexit sha1_base64="Y9gtPiZym8euQvLji49w3e56mrQ=">AAAB8HicbVDLSgNBEOz1GeMr6tHLYBC8GHZF0GPAi8cI5iHJGmYnk2TIzOwy0yuEJV/hxYMiXv0cb/6Nk2QPmljQUFR1090VJVJY9P1vb2V1bX1js7BV3N7Z3dsvHRw2bJwaxusslrFpRdRyKTSvo0DJW4nhVEWSN6PRzdRvPnFjRazvcZzwUNGBFn3BKDrpwTzqbobnwaRbKvsVfwayTIKclCFHrVv66vRiliqukUlqbTvwEwwzalAwySfFTmp5QtmIDnjbUU0Vt2E2O3hCTp3SI/3YuNJIZurviYwqa8cqcp2K4tAuelPxP6+dYv86zIROUuSazRf1U0kwJtPvSU8YzlCOHaHMCHcrYUNqKEOXUdGFECy+vEwaF5XArwR3l+UqyeMowDGcwBkEcAVVuIUa1IGBgmd4hTfPeC/eu/cxb13x8pkj+APv8weEUZAZ</latexit><latexit sha1_base64="Y9gtPiZym8euQvLji49w3e56mrQ=">AAAB8HicbVDLSgNBEOz1GeMr6tHLYBC8GHZF0GPAi8cI5iHJGmYnk2TIzOwy0yuEJV/hxYMiXv0cb/6Nk2QPmljQUFR1090VJVJY9P1vb2V1bX1js7BV3N7Z3dsvHRw2bJwaxusslrFpRdRyKTSvo0DJW4nhVEWSN6PRzdRvPnFjRazvcZzwUNGBFn3BKDrpwTzqbobnwaRbKvsVfwayTIKclCFHrVv66vRiliqukUlqbTvwEwwzalAwySfFTmp5QtmIDnjbUU0Vt2E2O3hCTp3SI/3YuNJIZurviYwqa8cqcp2K4tAuelPxP6+dYv86zIROUuSazRf1U0kwJtPvSU8YzlCOHaHMCHcrYUNqKEOXUdGFECy+vEwaF5XArwR3l+UqyeMowDGcwBkEcAVVuIUa1IGBgmd4hTfPeC/eu/cxb13x8pkj+APv8weEUZAZ</latexit><latexit sha1_base64="Y9gtPiZym8euQvLji49w3e56mrQ=">AAAB8HicbVDLSgNBEOz1GeMr6tHLYBC8GHZF0GPAi8cI5iHJGmYnk2TIzOwy0yuEJV/hxYMiXv0cb/6Nk2QPmljQUFR1090VJVJY9P1vb2V1bX1js7BV3N7Z3dsvHRw2bJwaxusslrFpRdRyKTSvo0DJW4nhVEWSN6PRzdRvPnFjRazvcZzwUNGBFn3BKDrpwTzqbobnwaRbKvsVfwayTIKclCFHrVv66vRiliqukUlqbTvwEwwzalAwySfFTmp5QtmIDnjbUU0Vt2E2O3hCTp3SI/3YuNJIZurviYwqa8cqcp2K4tAuelPxP6+dYv86zIROUuSazRf1U0kwJtPvSU8YzlCOHaHMCHcrYUNqKEOXUdGFECy+vEwaF5XArwR3l+UqyeMowDGcwBkEcAVVuIUa1IGBgmd4hTfPeC/eu/cxb13x8pkj+APv8weEUZAZ</latexit>xnt<latexit sha1_base64="z1pJ4w9Pi+nIN6Fl1KSMaK855Xc=">AAAB+3icbVDLSsNAFL2pr1pfsS7dDBbBVUlE0GXBjcsK9gFtDJPppB06mYSZibSE/IobF4q49Ufc+TdO2iy09cDA4Zx7uWdOkHCmtON8W5WNza3tnepubW//4PDIPq53VZxKQjsk5rHsB1hRzgTtaKY57SeS4ijgtBdMbwu/90SlYrF40POEehEeCxYygrWRfLs+jLCeBGE2y/1M54+ZyH274TSdBdA6cUvSgBJt3/4ajmKSRlRowrFSA9dJtJdhqRnhNK8NU0UTTKZ4TAeGChxR5WWL7Dk6N8oIhbE0T2i0UH9vZDhSah4FZrJIqla9QvzPG6Q6vPEyJpJUU0GWh8KUIx2jogg0YpISzeeGYCKZyYrIBEtMtKmrZkpwV7+8TrqXTddpuvdXjRYq66jCKZzBBbhwDS24gzZ0gMAMnuEV3qzcerHerY/laMUqd07gD6zPHyZOlQo=</latexit><latexit sha1_base64="z1pJ4w9Pi+nIN6Fl1KSMaK855Xc=">AAAB+3icbVDLSsNAFL2pr1pfsS7dDBbBVUlE0GXBjcsK9gFtDJPppB06mYSZibSE/IobF4q49Ufc+TdO2iy09cDA4Zx7uWdOkHCmtON8W5WNza3tnepubW//4PDIPq53VZxKQjsk5rHsB1hRzgTtaKY57SeS4ijgtBdMbwu/90SlYrF40POEehEeCxYygrWRfLs+jLCeBGE2y/1M54+ZyH274TSdBdA6cUvSgBJt3/4ajmKSRlRowrFSA9dJtJdhqRnhNK8NU0UTTKZ4TAeGChxR5WWL7Dk6N8oIhbE0T2i0UH9vZDhSah4FZrJIqla9QvzPG6Q6vPEyJpJUU0GWh8KUIx2jogg0YpISzeeGYCKZyYrIBEtMtKmrZkpwV7+8TrqXTddpuvdXjRYq66jCKZzBBbhwDS24gzZ0gMAMnuEV3qzcerHerY/laMUqd07gD6zPHyZOlQo=</latexit><latexit sha1_base64="z1pJ4w9Pi+nIN6Fl1KSMaK855Xc=">AAAB+3icbVDLSsNAFL2pr1pfsS7dDBbBVUlE0GXBjcsK9gFtDJPppB06mYSZibSE/IobF4q49Ufc+TdO2iy09cDA4Zx7uWdOkHCmtON8W5WNza3tnepubW//4PDIPq53VZxKQjsk5rHsB1hRzgTtaKY57SeS4ijgtBdMbwu/90SlYrF40POEehEeCxYygrWRfLs+jLCeBGE2y/1M54+ZyH274TSdBdA6cUvSgBJt3/4ajmKSRlRowrFSA9dJtJdhqRnhNK8NU0UTTKZ4TAeGChxR5WWL7Dk6N8oIhbE0T2i0UH9vZDhSah4FZrJIqla9QvzPG6Q6vPEyJpJUU0GWh8KUIx2jogg0YpISzeeGYCKZyYrIBEtMtKmrZkpwV7+8TrqXTddpuvdXjRYq66jCKZzBBbhwDS24gzZ0gMAMnuEV3qzcerHerY/laMUqd07gD6zPHyZOlQo=</latexit><latexit sha1_base64="z1pJ4w9Pi+nIN6Fl1KSMaK855Xc=">AAAB+3icbVDLSsNAFL2pr1pfsS7dDBbBVUlE0GXBjcsK9gFtDJPppB06mYSZibSE/IobF4q49Ufc+TdO2iy09cDA4Zx7uWdOkHCmtON8W5WNza3tnepubW//4PDIPq53VZxKQjsk5rHsB1hRzgTtaKY57SeS4ijgtBdMbwu/90SlYrF40POEehEeCxYygrWRfLs+jLCeBGE2y/1M54+ZyH274TSdBdA6cUvSgBJt3/4ajmKSRlRowrFSA9dJtJdhqRnhNK8NU0UTTKZ4TAeGChxR5WWL7Dk6N8oIhbE0T2i0UH9vZDhSah4FZrJIqla9QvzPG6Q6vPEyJpJUU0GWh8KUIx2jogg0YpISzeeGYCKZyYrIBEtMtKmrZkpwV7+8TrqXTddpuvdXjRYq66jCKZzBBbhwDS24gzZ0gMAMnuEV3qzcerHerY/laMUqd07gD6zPHyZOlQo=</latexit>vnt<latexit sha1_base64="0fjG2cQx/rMWU+q6cx6mecOOfLw=">AAAB+3icbVDLSsNAFL2pr1pfsS7dDBbBVUlE0GXBjcsK9gFtDJPppB06mYSZSbGE/IobF4q49Ufc+TdO2iy09cDA4Zx7uWdOkHCmtON8W5WNza3tnepubW//4PDIPq53VZxKQjsk5rHsB1hRzgTtaKY57SeS4ijgtBdMbwu/N6NSsVg86HlCvQiPBQsZwdpIvl0fRlhPgjCb5X6m88dM5L7dcJrOAmiduCVpQIm2b38NRzFJIyo04Vipgesk2suw1IxwmteGqaIJJlM8pgNDBY6o8rJF9hydG2WEwliaJzRaqL83MhwpNY8CM1kkVateIf7nDVId3ngZE0mqqSDLQ2HKkY5RUQQaMUmJ5nNDMJHMZEVkgiUm2tRVMyW4q19eJ93Lpus03furRguVdVThFM7gAly4hhbcQRs6QOAJnuEV3qzcerHerY/laMUqd07gD6zPHyM0lQg=</latexit><latexit sha1_base64="0fjG2cQx/rMWU+q6cx6mecOOfLw=">AAAB+3icbVDLSsNAFL2pr1pfsS7dDBbBVUlE0GXBjcsK9gFtDJPppB06mYSZSbGE/IobF4q49Ufc+TdO2iy09cDA4Zx7uWdOkHCmtON8W5WNza3tnepubW//4PDIPq53VZxKQjsk5rHsB1hRzgTtaKY57SeS4ijgtBdMbwu/N6NSsVg86HlCvQiPBQsZwdpIvl0fRlhPgjCb5X6m88dM5L7dcJrOAmiduCVpQIm2b38NRzFJIyo04Vipgesk2suw1IxwmteGqaIJJlM8pgNDBY6o8rJF9hydG2WEwliaJzRaqL83MhwpNY8CM1kkVateIf7nDVId3ngZE0mqqSDLQ2HKkY5RUQQaMUmJ5nNDMJHMZEVkgiUm2tRVMyW4q19eJ93Lpus03furRguVdVThFM7gAly4hhbcQRs6QOAJnuEV3qzcerHerY/laMUqd07gD6zPHyM0lQg=</latexit><latexit sha1_base64="0fjG2cQx/rMWU+q6cx6mecOOfLw=">AAAB+3icbVDLSsNAFL2pr1pfsS7dDBbBVUlE0GXBjcsK9gFtDJPppB06mYSZSbGE/IobF4q49Ufc+TdO2iy09cDA4Zx7uWdOkHCmtON8W5WNza3tnepubW//4PDIPq53VZxKQjsk5rHsB1hRzgTtaKY57SeS4ijgtBdMbwu/N6NSsVg86HlCvQiPBQsZwdpIvl0fRlhPgjCb5X6m88dM5L7dcJrOAmiduCVpQIm2b38NRzFJIyo04Vipgesk2suw1IxwmteGqaIJJlM8pgNDBY6o8rJF9hydG2WEwliaJzRaqL83MhwpNY8CM1kkVateIf7nDVId3ngZE0mqqSDLQ2HKkY5RUQQaMUmJ5nNDMJHMZEVkgiUm2tRVMyW4q19eJ93Lpus03furRguVdVThFM7gAly4hhbcQRs6QOAJnuEV3qzcerHerY/laMUqd07gD6zPHyM0lQg=</latexit><latexit sha1_base64="0fjG2cQx/rMWU+q6cx6mecOOfLw=">AAAB+3icbVDLSsNAFL2pr1pfsS7dDBbBVUlE0GXBjcsK9gFtDJPppB06mYSZSbGE/IobF4q49Ufc+TdO2iy09cDA4Zx7uWdOkHCmtON8W5WNza3tnepubW//4PDIPq53VZxKQjsk5rHsB1hRzgTtaKY57SeS4ijgtBdMbwu/N6NSsVg86HlCvQiPBQsZwdpIvl0fRlhPgjCb5X6m88dM5L7dcJrOAmiduCVpQIm2b38NRzFJIyo04Vipgesk2suw1IxwmteGqaIJJlM8pgNDBY6o8rJF9hydG2WEwliaJzRaqL83MhwpNY8CM1kkVateIf7nDVId3ngZE0mqqSDLQ2HKkY5RUQQaMUmJ5nNDMJHMZEVkgiUm2tRVMyW4q19eJ93Lpus03furRguVdVThFM7gAly4hhbcQRs6QOAJnuEV3qzcerHerY/laMUqd07gD6zPHyM0lQg=</latexit>⇡nt(.)<latexit sha1_base64="cVeNfIfCNk9OlOgZcv92kD5PAUU=">AAAB8XicbVBNS8NAEJ3Ur1q/qh69LBahXkIigh4LXjxWsB/YxrLZbtqlm03YnQil9F948aCIV/+NN/+N2zYHbX0w8Hhvhpl5YSqFQc/7dgpr6xubW8Xt0s7u3v5B+fCoaZJMM95giUx0O6SGS6F4AwVK3k41p3EoeSsc3cz81hPXRiTqHscpD2I6UCISjKKVHrqp6OGjqrrnvXLFc705yCrxc1KBHPVe+avbT1gWc4VMUmM6vpdiMKEaBZN8WupmhqeUjeiAdyxVNOYmmMwvnpIzq/RJlGhbCslc/T0xobEx4zi0nTHFoVn2ZuJ/XifD6DqYCJVmyBVbLIoySTAhs/dJX2jOUI4toUwLeythQ6opQxtSyYbgL7+8SpoXru+5/t1lpUbyOIpwAqdQBR+uoAa3UIcGMFDwDK/w5hjnxXl3PhatBSefOYY/cD5/AI3qkA8=</latexit><latexit sha1_base64="cVeNfIfCNk9OlOgZcv92kD5PAUU=">AAAB8XicbVBNS8NAEJ3Ur1q/qh69LBahXkIigh4LXjxWsB/YxrLZbtqlm03YnQil9F948aCIV/+NN/+N2zYHbX0w8Hhvhpl5YSqFQc/7dgpr6xubW8Xt0s7u3v5B+fCoaZJMM95giUx0O6SGS6F4AwVK3k41p3EoeSsc3cz81hPXRiTqHscpD2I6UCISjKKVHrqp6OGjqrrnvXLFc705yCrxc1KBHPVe+avbT1gWc4VMUmM6vpdiMKEaBZN8WupmhqeUjeiAdyxVNOYmmMwvnpIzq/RJlGhbCslc/T0xobEx4zi0nTHFoVn2ZuJ/XifD6DqYCJVmyBVbLIoySTAhs/dJX2jOUI4toUwLeythQ6opQxtSyYbgL7+8SpoXru+5/t1lpUbyOIpwAqdQBR+uoAa3UIcGMFDwDK/w5hjnxXl3PhatBSefOYY/cD5/AI3qkA8=</latexit><latexit sha1_base64="cVeNfIfCNk9OlOgZcv92kD5PAUU=">AAAB8XicbVBNS8NAEJ3Ur1q/qh69LBahXkIigh4LXjxWsB/YxrLZbtqlm03YnQil9F948aCIV/+NN/+N2zYHbX0w8Hhvhpl5YSqFQc/7dgpr6xubW8Xt0s7u3v5B+fCoaZJMM95giUx0O6SGS6F4AwVK3k41p3EoeSsc3cz81hPXRiTqHscpD2I6UCISjKKVHrqp6OGjqrrnvXLFc705yCrxc1KBHPVe+avbT1gWc4VMUmM6vpdiMKEaBZN8WupmhqeUjeiAdyxVNOYmmMwvnpIzq/RJlGhbCslc/T0xobEx4zi0nTHFoVn2ZuJ/XifD6DqYCJVmyBVbLIoySTAhs/dJX2jOUI4toUwLeythQ6opQxtSyYbgL7+8SpoXru+5/t1lpUbyOIpwAqdQBR+uoAa3UIcGMFDwDK/w5hjnxXl3PhatBSefOYY/cD5/AI3qkA8=</latexit><latexit sha1_base64="cVeNfIfCNk9OlOgZcv92kD5PAUU=">AAAB8XicbVBNS8NAEJ3Ur1q/qh69LBahXkIigh4LXjxWsB/YxrLZbtqlm03YnQil9F948aCIV/+NN/+N2zYHbX0w8Hhvhpl5YSqFQc/7dgpr6xubW8Xt0s7u3v5B+fCoaZJMM95giUx0O6SGS6F4AwVK3k41p3EoeSsc3cz81hPXRiTqHscpD2I6UCISjKKVHrqp6OGjqrrnvXLFc705yCrxc1KBHPVe+avbT1gWc4VMUmM6vpdiMKEaBZN8WupmhqeUjeiAdyxVNOYmmMwvnpIzq/RJlGhbCslc/T0xobEx4zi0nTHFoVn2ZuJ/XifD6DqYCJVmyBVbLIoySTAhs/dJX2jOUI4toUwLeythQ6opQxtSyYbgL7+8SpoXru+5/t1lpUbyOIpwAqdQBR+uoAa3UIcGMFDwDK/w5hjnxXl3PhatBSefOYY/cD5/AI3qkA8=</latexit>SoftmaxWn<latexit sha1_base64="tbRvGnsdsQDMw9rly7QaZKhdu1A=">AAAB6nicbVBNS8NAEJ3Ur1q/oh69LBbBU0lE0GPBi8eK9gPaWDbbSbt0swm7G6GE/gQvHhTx6i/y5r9x2+agrQ8GHu/NMDMvTAXXxvO+ndLa+sbmVnm7srO7t3/gHh61dJIphk2WiER1QqpRcIlNw43ATqqQxqHAdji+mfntJ1SaJ/LBTFIMYjqUPOKMGivdtx9l3616NW8Oskr8glShQKPvfvUGCctilIYJqnXX91IT5FQZzgROK71MY0rZmA6xa6mkMeogn586JWdWGZAoUbakIXP190ROY60ncWg7Y2pGetmbif953cxE10HOZZoZlGyxKMoEMQmZ/U0GXCEzYmIJZYrbWwkbUUWZselUbAj+8surpHVR872af3dZrZMijjKcwCmcgw9XUIdbaEATGAzhGV7hzRHOi/PufCxaS04xcwx/4Hz+ACofjZk=</latexit><latexit sha1_base64="tbRvGnsdsQDMw9rly7QaZKhdu1A=">AAAB6nicbVBNS8NAEJ3Ur1q/oh69LBbBU0lE0GPBi8eK9gPaWDbbSbt0swm7G6GE/gQvHhTx6i/y5r9x2+agrQ8GHu/NMDMvTAXXxvO+ndLa+sbmVnm7srO7t3/gHh61dJIphk2WiER1QqpRcIlNw43ATqqQxqHAdji+mfntJ1SaJ/LBTFIMYjqUPOKMGivdtx9l3616NW8Oskr8glShQKPvfvUGCctilIYJqnXX91IT5FQZzgROK71MY0rZmA6xa6mkMeogn586JWdWGZAoUbakIXP190ROY60ncWg7Y2pGetmbif953cxE10HOZZoZlGyxKMoEMQmZ/U0GXCEzYmIJZYrbWwkbUUWZselUbAj+8surpHVR872af3dZrZMijjKcwCmcgw9XUIdbaEATGAzhGV7hzRHOi/PufCxaS04xcwx/4Hz+ACofjZk=</latexit><latexit sha1_base64="tbRvGnsdsQDMw9rly7QaZKhdu1A=">AAAB6nicbVBNS8NAEJ3Ur1q/oh69LBbBU0lE0GPBi8eK9gPaWDbbSbt0swm7G6GE/gQvHhTx6i/y5r9x2+agrQ8GHu/NMDMvTAXXxvO+ndLa+sbmVnm7srO7t3/gHh61dJIphk2WiER1QqpRcIlNw43ATqqQxqHAdji+mfntJ1SaJ/LBTFIMYjqUPOKMGivdtx9l3616NW8Oskr8glShQKPvfvUGCctilIYJqnXX91IT5FQZzgROK71MY0rZmA6xa6mkMeogn586JWdWGZAoUbakIXP190ROY60ncWg7Y2pGetmbif953cxE10HOZZoZlGyxKMoEMQmZ/U0GXCEzYmIJZYrbWwkbUUWZselUbAj+8surpHVR872af3dZrZMijjKcwCmcgw9XUIdbaEATGAzhGV7hzRHOi/PufCxaS04xcwx/4Hz+ACofjZk=</latexit><latexit sha1_base64="tbRvGnsdsQDMw9rly7QaZKhdu1A=">AAAB6nicbVBNS8NAEJ3Ur1q/oh69LBbBU0lE0GPBi8eK9gPaWDbbSbt0swm7G6GE/gQvHhTx6i/y5r9x2+agrQ8GHu/NMDMvTAXXxvO+ndLa+sbmVnm7srO7t3/gHh61dJIphk2WiER1QqpRcIlNw43ATqqQxqHAdji+mfntJ1SaJ/LBTFIMYjqUPOKMGivdtx9l3616NW8Oskr8glShQKPvfvUGCctilIYJqnXX91IT5FQZzgROK71MY0rZmA6xa6mkMeogn586JWdWGZAoUbakIXP190ROY60ncWg7Y2pGetmbif953cxE10HOZZoZlGyxKMoEMQmZ/U0GXCEzYmIJZYrbWwkbUUWZselUbAj+8surpHVR872af3dZrZMijjKcwCmcgw9XUIdbaEATGAzhGV7hzRHOi/PufCxaS04xcwx/4Hz+ACofjZk=</latexit>Learning networkEncoderDecoderInput sequencesLatent spacean1...anTn<latexit sha1_base64="fv2VJikq0gzlJIqz81/fun8OtTA=">AAAB/XicbVDJSgNBEK2JW4xbXG5eGoPgKcyIoMeAF48RskGWoabTkzTp6Rm6e4Q4BH/FiwdFvPof3vwbO8tBEx8UPN6r6q56QSK4Nq777eTW1jc2t/LbhZ3dvf2D4uFRQ8epoqxOYxGrVoCaCS5Z3XAjWCtRDKNAsGYwup36zQemNI9lzYwT1o1wIHnIKRor+cUT9L2e7PRjown6Wa0nJz0rl9yyOwNZJd6ClGCBql/8si/QNGLSUIFatz03Md0MleFUsEmhk2qWIB3hgLUtlRgx3c1m20/IuVX6JIyVLWnITP09kWGk9TgKbGeEZqiXvan4n9dOTXjTzbhMUsMknX8UpoKYmEyjIH2uGDVibAlSxe2uhA5RITU2sIINwVs+eZU0LsueW/bur0oVsogjD6dwBhfgwTVU4A6qUAcKj/AMr/DmPDkvzrvzMW/NOYuZY/gD5/MHJA2U6A==</latexit><latexit sha1_base64="fv2VJikq0gzlJIqz81/fun8OtTA=">AAAB/XicbVDJSgNBEK2JW4xbXG5eGoPgKcyIoMeAF48RskGWoabTkzTp6Rm6e4Q4BH/FiwdFvPof3vwbO8tBEx8UPN6r6q56QSK4Nq777eTW1jc2t/LbhZ3dvf2D4uFRQ8epoqxOYxGrVoCaCS5Z3XAjWCtRDKNAsGYwup36zQemNI9lzYwT1o1wIHnIKRor+cUT9L2e7PRjown6Wa0nJz0rl9yyOwNZJd6ClGCBql/8si/QNGLSUIFatz03Md0MleFUsEmhk2qWIB3hgLUtlRgx3c1m20/IuVX6JIyVLWnITP09kWGk9TgKbGeEZqiXvan4n9dOTXjTzbhMUsMknX8UpoKYmEyjIH2uGDVibAlSxe2uhA5RITU2sIINwVs+eZU0LsueW/bur0oVsogjD6dwBhfgwTVU4A6qUAcKj/AMr/DmPDkvzrvzMW/NOYuZY/gD5/MHJA2U6A==</latexit><latexit sha1_base64="fv2VJikq0gzlJIqz81/fun8OtTA=">AAAB/XicbVDJSgNBEK2JW4xbXG5eGoPgKcyIoMeAF48RskGWoabTkzTp6Rm6e4Q4BH/FiwdFvPof3vwbO8tBEx8UPN6r6q56QSK4Nq777eTW1jc2t/LbhZ3dvf2D4uFRQ8epoqxOYxGrVoCaCS5Z3XAjWCtRDKNAsGYwup36zQemNI9lzYwT1o1wIHnIKRor+cUT9L2e7PRjown6Wa0nJz0rl9yyOwNZJd6ClGCBql/8si/QNGLSUIFatz03Md0MleFUsEmhk2qWIB3hgLUtlRgx3c1m20/IuVX6JIyVLWnITP09kWGk9TgKbGeEZqiXvan4n9dOTXjTzbhMUsMknX8UpoKYmEyjIH2uGDVibAlSxe2uhA5RITU2sIINwVs+eZU0LsueW/bur0oVsogjD6dwBhfgwTVU4A6qUAcKj/AMr/DmPDkvzrvzMW/NOYuZY/gD5/MHJA2U6A==</latexit><latexit sha1_base64="fv2VJikq0gzlJIqz81/fun8OtTA=">AAAB/XicbVDJSgNBEK2JW4xbXG5eGoPgKcyIoMeAF48RskGWoabTkzTp6Rm6e4Q4BH/FiwdFvPof3vwbO8tBEx8UPN6r6q56QSK4Nq777eTW1jc2t/LbhZ3dvf2D4uFRQ8epoqxOYxGrVoCaCS5Z3XAjWCtRDKNAsGYwup36zQemNI9lzYwT1o1wIHnIKRor+cUT9L2e7PRjown6Wa0nJz0rl9yyOwNZJd6ClGCBql/8si/QNGLSUIFatz03Md0MleFUsEmhk2qWIB3hgLUtlRgx3c1m20/IuVX6JIyVLWnITP09kWGk9TgKbGeEZqiXvan4n9dOTXjTzbhMUsMknX8UpoKYmEyjIH2uGDVibAlSxe2uhA5RITU2sIINwVs+eZU0LsueW/bur0oVsogjD6dwBhfgwTVU4A6qUAcKj/AMr/DmPDkvzrvzMW/NOYuZY/gD5/MHJA2U6A==</latexit>rn1...rnTn<latexit sha1_base64="mD7D/vope84WJ97ZseRjUi+SqsI=">AAAB/XicbVDJSgNBEK2JW4xbXG5eGoPgKcyIoMeAF48RskGWoafTkzTp6Rm6a4Q4BH/FiwdFvPof3vwbO8tBEx8UPN6r6q56QSKFQdf9dnJr6xubW/ntws7u3v5B8fCoYeJUM15nsYx1K6CGS6F4HQVK3ko0p1EgeTMY3U795gPXRsSqhuOEdyM6UCIUjKKV/OKJ9r2e6vRjNET7Wa2nJj0rl9yyOwNZJd6ClGCBql/8si+wNOIKmaTGtD03wW5GNQom+aTQSQ1PKBvRAW9bqmjETTebbT8h51bpkzDWthSSmfp7IqORMeMosJ0RxaFZ9qbif147xfCmmwmVpMgVm38UppJgTKZRkL7QnKEcW0KZFnZXwoZUU4Y2sIINwVs+eZU0LsueW/bur0oVsogjD6dwBhfgwTVU4A6qUAcGj/AMr/DmPDkvzrvzMW/NOYuZY/gD5/MHWWCVCg==</latexit><latexit sha1_base64="mD7D/vope84WJ97ZseRjUi+SqsI=">AAAB/XicbVDJSgNBEK2JW4xbXG5eGoPgKcyIoMeAF48RskGWoafTkzTp6Rm6a4Q4BH/FiwdFvPof3vwbO8tBEx8UPN6r6q56QSKFQdf9dnJr6xubW/ntws7u3v5B8fCoYeJUM15nsYx1K6CGS6F4HQVK3ko0p1EgeTMY3U795gPXRsSqhuOEdyM6UCIUjKKV/OKJ9r2e6vRjNET7Wa2nJj0rl9yyOwNZJd6ClGCBql/8si+wNOIKmaTGtD03wW5GNQom+aTQSQ1PKBvRAW9bqmjETTebbT8h51bpkzDWthSSmfp7IqORMeMosJ0RxaFZ9qbif147xfCmmwmVpMgVm38UppJgTKZRkL7QnKEcW0KZFnZXwoZUU4Y2sIINwVs+eZU0LsueW/bur0oVsogjD6dwBhfgwTVU4A6qUAcGj/AMr/DmPDkvzrvzMW/NOYuZY/gD5/MHWWCVCg==</latexit><latexit sha1_base64="mD7D/vope84WJ97ZseRjUi+SqsI=">AAAB/XicbVDJSgNBEK2JW4xbXG5eGoPgKcyIoMeAF48RskGWoafTkzTp6Rm6a4Q4BH/FiwdFvPof3vwbO8tBEx8UPN6r6q56QSKFQdf9dnJr6xubW/ntws7u3v5B8fCoYeJUM15nsYx1K6CGS6F4HQVK3ko0p1EgeTMY3U795gPXRsSqhuOEdyM6UCIUjKKV/OKJ9r2e6vRjNET7Wa2nJj0rl9yyOwNZJd6ClGCBql/8si+wNOIKmaTGtD03wW5GNQom+aTQSQ1PKBvRAW9bqmjETTebbT8h51bpkzDWthSSmfp7IqORMeMosJ0RxaFZ9qbif147xfCmmwmVpMgVm38UppJgTKZRkL7QnKEcW0KZFnZXwoZUU4Y2sIINwVs+eZU0LsueW/bur0oVsogjD6dwBhfgwTVU4A6qUAcGj/AMr/DmPDkvzrvzMW/NOYuZY/gD5/MHWWCVCg==</latexit><latexit sha1_base64="mD7D/vope84WJ97ZseRjUi+SqsI=">AAAB/XicbVDJSgNBEK2JW4xbXG5eGoPgKcyIoMeAF48RskGWoafTkzTp6Rm6a4Q4BH/FiwdFvPof3vwbO8tBEx8UPN6r6q56QSKFQdf9dnJr6xubW/ntws7u3v5B8fCoYeJUM15nsYx1K6CGS6F4HQVK3ko0p1EgeTMY3U795gPXRsSqhuOEdyM6UCIUjKKV/OKJ9r2e6vRjNET7Wa2nJj0rl9yyOwNZJd6ClGCBql/8si+wNOIKmaTGtD03wW5GNQom+aTQSQ1PKBvRAW9bqmjETTebbT8h51bpkzDWthSSmfp7IqORMeMosJ0RxaFZ9qbif147xfCmmwmVpMgVm38UppJgTKZRkL7QnKEcW0KZFnZXwoZUU4Y2sIINwVs+eZU0LsueW/bur0oVsogjD6dwBhfgwTVU4A6qUAcGj/AMr/DmPDkvzrvzMW/NOYuZY/gD5/MHWWCVCg==</latexit>rN1...rNTN<latexit sha1_base64="srr8sEw4ycMopJQiQ1Ny4wzUqY4=">AAAB/XicbVDLSsNAFL2pr1pf8bFzM1gEVyURQZcFN65Khb6gTcNkOmmHTiZhZiLUUPwVNy4Ucet/uPNvnLZZaOuBC4dz7p259wQJZ0o7zrdVWFvf2Nwqbpd2dvf2D+zDo5aKU0lok8Q8lp0AK8qZoE3NNKedRFIcBZy2g/HtzG8/UKlYLBp6klAvwkPBQkawNpJvn0jf7dd6g1grJP2s0a9N+zXfLjsVZw60StyclCFH3be/zAskjajQhGOluq6TaC/DUjPC6bTUSxVNMBnjIe0aKnBElZfNt5+ic6MMUBhLU0Kjufp7IsORUpMoMJ0R1iO17M3E/7xuqsMbL2MiSTUVZPFRmHKkYzSLAg2YpETziSGYSGZ2RWSEJSbaBFYyIbjLJ6+S1mXFdSru/VW5ivI4inAKZ3ABLlxDFe6gDk0g8AjP8Apv1pP1Yr1bH4vWgpXPHMMfWJ8/xZGUqg==</latexit><latexit sha1_base64="srr8sEw4ycMopJQiQ1Ny4wzUqY4=">AAAB/XicbVDLSsNAFL2pr1pf8bFzM1gEVyURQZcFN65Khb6gTcNkOmmHTiZhZiLUUPwVNy4Ucet/uPNvnLZZaOuBC4dz7p259wQJZ0o7zrdVWFvf2Nwqbpd2dvf2D+zDo5aKU0lok8Q8lp0AK8qZoE3NNKedRFIcBZy2g/HtzG8/UKlYLBp6klAvwkPBQkawNpJvn0jf7dd6g1grJP2s0a9N+zXfLjsVZw60StyclCFH3be/zAskjajQhGOluq6TaC/DUjPC6bTUSxVNMBnjIe0aKnBElZfNt5+ic6MMUBhLU0Kjufp7IsORUpMoMJ0R1iO17M3E/7xuqsMbL2MiSTUVZPFRmHKkYzSLAg2YpETziSGYSGZ2RWSEJSbaBFYyIbjLJ6+S1mXFdSru/VW5ivI4inAKZ3ABLlxDFe6gDk0g8AjP8Apv1pP1Yr1bH4vWgpXPHMMfWJ8/xZGUqg==</latexit><latexit sha1_base64="srr8sEw4ycMopJQiQ1Ny4wzUqY4=">AAAB/XicbVDLSsNAFL2pr1pf8bFzM1gEVyURQZcFN65Khb6gTcNkOmmHTiZhZiLUUPwVNy4Ucet/uPNvnLZZaOuBC4dz7p259wQJZ0o7zrdVWFvf2Nwqbpd2dvf2D+zDo5aKU0lok8Q8lp0AK8qZoE3NNKedRFIcBZy2g/HtzG8/UKlYLBp6klAvwkPBQkawNpJvn0jf7dd6g1grJP2s0a9N+zXfLjsVZw60StyclCFH3be/zAskjajQhGOluq6TaC/DUjPC6bTUSxVNMBnjIe0aKnBElZfNt5+ic6MMUBhLU0Kjufp7IsORUpMoMJ0R1iO17M3E/7xuqsMbL2MiSTUVZPFRmHKkYzSLAg2YpETziSGYSGZ2RWSEJSbaBFYyIbjLJ6+S1mXFdSru/VW5ivI4inAKZ3ABLlxDFe6gDk0g8AjP8Apv1pP1Yr1bH4vWgpXPHMMfWJ8/xZGUqg==</latexit><latexit sha1_base64="srr8sEw4ycMopJQiQ1Ny4wzUqY4=">AAAB/XicbVDLSsNAFL2pr1pf8bFzM1gEVyURQZcFN65Khb6gTcNkOmmHTiZhZiLUUPwVNy4Ucet/uPNvnLZZaOuBC4dz7p259wQJZ0o7zrdVWFvf2Nwqbpd2dvf2D+zDo5aKU0lok8Q8lp0AK8qZoE3NNKedRFIcBZy2g/HtzG8/UKlYLBp6klAvwkPBQkawNpJvn0jf7dd6g1grJP2s0a9N+zXfLjsVZw60StyclCFH3be/zAskjajQhGOluq6TaC/DUjPC6bTUSxVNMBnjIe0aKnBElZfNt5+ic6MMUBhLU0Kjufp7IsORUpMoMJ0R1iO17M3E/7xuqsMbL2MiSTUVZPFRmHKkYzSLAg2YpETziSGYSGZ2RWSEJSbaBFYyIbjLJ6+S1mXFdSru/VW5ivI4inAKZ3ABLlxDFe6gDk0g8AjP8Apv1pP1Yr1bH4vWgpXPHMMfWJ8/xZGUqg==</latexit>aN1...aNTN<latexit sha1_base64="XYyd4N2putHSsXz1S7O8C9/K6Po=">AAAB/XicbVDLSsNAFL2pr1pf8bFzM1gEVyURQZcFN65Khb6gTcNkOmmHTiZhZiLUUPwVNy4Ucet/uPNvnLZZaOuBC4dz7p259wQJZ0o7zrdVWFvf2Nwqbpd2dvf2D+zDo5aKU0lok8Q8lp0AK8qZoE3NNKedRFIcBZy2g/HtzG8/UKlYLBp6klAvwkPBQkawNpJvn2Df7dd6g1grhP2s0a9N+zXfLjsVZw60StyclCFH3be/zAskjajQhGOluq6TaC/DUjPC6bTUSxVNMBnjIe0aKnBElZfNt5+ic6MMUBhLU0Kjufp7IsORUpMoMJ0R1iO17M3E/7xuqsMbL2MiSTUVZPFRmHKkYzSLAg2YpETziSGYSGZ2RWSEJSbaBFYyIbjLJ6+S1mXFdSru/VW5ivI4inAKZ3ABLlxDFe6gDk0g8AjP8Apv1pP1Yr1bH4vWgpXPHMMfWJ8/kD6UiA==</latexit><latexit sha1_base64="XYyd4N2putHSsXz1S7O8C9/K6Po=">AAAB/XicbVDLSsNAFL2pr1pf8bFzM1gEVyURQZcFN65Khb6gTcNkOmmHTiZhZiLUUPwVNy4Ucet/uPNvnLZZaOuBC4dz7p259wQJZ0o7zrdVWFvf2Nwqbpd2dvf2D+zDo5aKU0lok8Q8lp0AK8qZoE3NNKedRFIcBZy2g/HtzG8/UKlYLBp6klAvwkPBQkawNpJvn2Df7dd6g1grhP2s0a9N+zXfLjsVZw60StyclCFH3be/zAskjajQhGOluq6TaC/DUjPC6bTUSxVNMBnjIe0aKnBElZfNt5+ic6MMUBhLU0Kjufp7IsORUpMoMJ0R1iO17M3E/7xuqsMbL2MiSTUVZPFRmHKkYzSLAg2YpETziSGYSGZ2RWSEJSbaBFYyIbjLJ6+S1mXFdSru/VW5ivI4inAKZ3ABLlxDFe6gDk0g8AjP8Apv1pP1Yr1bH4vWgpXPHMMfWJ8/kD6UiA==</latexit><latexit sha1_base64="XYyd4N2putHSsXz1S7O8C9/K6Po=">AAAB/XicbVDLSsNAFL2pr1pf8bFzM1gEVyURQZcFN65Khb6gTcNkOmmHTiZhZiLUUPwVNy4Ucet/uPNvnLZZaOuBC4dz7p259wQJZ0o7zrdVWFvf2Nwqbpd2dvf2D+zDo5aKU0lok8Q8lp0AK8qZoE3NNKedRFIcBZy2g/HtzG8/UKlYLBp6klAvwkPBQkawNpJvn2Df7dd6g1grhP2s0a9N+zXfLjsVZw60StyclCFH3be/zAskjajQhGOluq6TaC/DUjPC6bTUSxVNMBnjIe0aKnBElZfNt5+ic6MMUBhLU0Kjufp7IsORUpMoMJ0R1iO17M3E/7xuqsMbL2MiSTUVZPFRmHKkYzSLAg2YpETziSGYSGZ2RWSEJSbaBFYyIbjLJ6+S1mXFdSru/VW5ivI4inAKZ3ABLlxDFe6gDk0g8AjP8Apv1pP1Yr1bH4vWgpXPHMMfWJ8/kD6UiA==</latexit><latexit sha1_base64="XYyd4N2putHSsXz1S7O8C9/K6Po=">AAAB/XicbVDLSsNAFL2pr1pf8bFzM1gEVyURQZcFN65Khb6gTcNkOmmHTiZhZiLUUPwVNy4Ucet/uPNvnLZZaOuBC4dz7p259wQJZ0o7zrdVWFvf2Nwqbpd2dvf2D+zDo5aKU0lok8Q8lp0AK8qZoE3NNKedRFIcBZy2g/HtzG8/UKlYLBp6klAvwkPBQkawNpJvn2Df7dd6g1grhP2s0a9N+zXfLjsVZw60StyclCFH3be/zAskjajQhGOluq6TaC/DUjPC6bTUSxVNMBnjIe0aKnBElZfNt5+ic6MMUBhLU0Kjufp7IsORUpMoMJ0R1iO17M3E/7xuqsMbL2MiSTUVZPFRmHKkYzSLAg2YpETziSGYSGZ2RWSEJSbaBFYyIbjLJ6+S1mXFdSru/VW5ivI4inAKZ3ABLlxDFe6gDk0g8AjP8Apv1pP1Yr1bH4vWgpXPHMMfWJ8/kD6UiA==</latexit>a11...a1T1<latexit sha1_base64="FghIiq3JCriLrng5S7nJ2TEvEcg=">AAAB/XicbVDLSgMxFM3UV62v8bFzEyyCqzIRQZcFNy4r9AXtdMikaRuayQzJHaEOxV9x40IRt/6HO//GtJ2Fth64cDjn3uTeEyZSGPC8b6ewtr6xuVXcLu3s7u0fuIdHTROnmvEGi2Ws2yE1XArFGyBA8naiOY1CyVvh+Hbmtx64NiJWdZgk3I/oUImBYBSsFLgnNCA90u3HYDANsnqPTHskcMtexZsDrxKSkzLKUQvcL/sCSyOugElqTId4CfgZ1SCY5NNSNzU8oWxMh7xjqaIRN342336Kz63Sx4NY21KA5+rviYxGxkyi0HZGFEZm2ZuJ/3mdFAY3fiZUkgJXbPHRIJUYYjyLAveF5gzkxBLKtLC7YjaimjKwgZVsCGT55FXSvKwQr0Lur8pVnMdRRKfoDF0ggq5RFd2hGmoghh7RM3pFb86T8+K8Ox+L1oKTzxyjP3A+fwAKWJQx</latexit><latexit sha1_base64="FghIiq3JCriLrng5S7nJ2TEvEcg=">AAAB/XicbVDLSgMxFM3UV62v8bFzEyyCqzIRQZcFNy4r9AXtdMikaRuayQzJHaEOxV9x40IRt/6HO//GtJ2Fth64cDjn3uTeEyZSGPC8b6ewtr6xuVXcLu3s7u0fuIdHTROnmvEGi2Ws2yE1XArFGyBA8naiOY1CyVvh+Hbmtx64NiJWdZgk3I/oUImBYBSsFLgnNCA90u3HYDANsnqPTHskcMtexZsDrxKSkzLKUQvcL/sCSyOugElqTId4CfgZ1SCY5NNSNzU8oWxMh7xjqaIRN342336Kz63Sx4NY21KA5+rviYxGxkyi0HZGFEZm2ZuJ/3mdFAY3fiZUkgJXbPHRIJUYYjyLAveF5gzkxBLKtLC7YjaimjKwgZVsCGT55FXSvKwQr0Lur8pVnMdRRKfoDF0ggq5RFd2hGmoghh7RM3pFb86T8+K8Ox+L1oKTzxyjP3A+fwAKWJQx</latexit><latexit sha1_base64="FghIiq3JCriLrng5S7nJ2TEvEcg=">AAAB/XicbVDLSgMxFM3UV62v8bFzEyyCqzIRQZcFNy4r9AXtdMikaRuayQzJHaEOxV9x40IRt/6HO//GtJ2Fth64cDjn3uTeEyZSGPC8b6ewtr6xuVXcLu3s7u0fuIdHTROnmvEGi2Ws2yE1XArFGyBA8naiOY1CyVvh+Hbmtx64NiJWdZgk3I/oUImBYBSsFLgnNCA90u3HYDANsnqPTHskcMtexZsDrxKSkzLKUQvcL/sCSyOugElqTId4CfgZ1SCY5NNSNzU8oWxMh7xjqaIRN342336Kz63Sx4NY21KA5+rviYxGxkyi0HZGFEZm2ZuJ/3mdFAY3fiZUkgJXbPHRIJUYYjyLAveF5gzkxBLKtLC7YjaimjKwgZVsCGT55FXSvKwQr0Lur8pVnMdRRKfoDF0ggq5RFd2hGmoghh7RM3pFb86T8+K8Ox+L1oKTzxyjP3A+fwAKWJQx</latexit><latexit sha1_base64="FghIiq3JCriLrng5S7nJ2TEvEcg=">AAAB/XicbVDLSgMxFM3UV62v8bFzEyyCqzIRQZcFNy4r9AXtdMikaRuayQzJHaEOxV9x40IRt/6HO//GtJ2Fth64cDjn3uTeEyZSGPC8b6ewtr6xuVXcLu3s7u0fuIdHTROnmvEGi2Ws2yE1XArFGyBA8naiOY1CyVvh+Hbmtx64NiJWdZgk3I/oUImBYBSsFLgnNCA90u3HYDANsnqPTHskcMtexZsDrxKSkzLKUQvcL/sCSyOugElqTId4CfgZ1SCY5NNSNzU8oWxMh7xjqaIRN342336Kz63Sx4NY21KA5+rviYxGxkyi0HZGFEZm2ZuJ/3mdFAY3fiZUkgJXbPHRIJUYYjyLAveF5gzkxBLKtLC7YjaimjKwgZVsCGT55FXSvKwQr0Lur8pVnMdRRKfoDF0ggq5RFd2hGmoghh7RM3pFb86T8+K8Ox+L1oKTzxyjP3A+fwAKWJQx</latexit>r11...r1T1<latexit sha1_base64="j/oGrWBiFlsQnjD2pJ2IRSMS3x8=">AAAB/XicbVDLSgMxFM3UV62v8bFzEyyCqzIRQZcFNy4r9AXtdMikaRuayQzJHaEOxV9x40IRt/6HO//GtJ2Fth64cDjn3uTeEyZSGPC8b6ewtr6xuVXcLu3s7u0fuIdHTROnmvEGi2Ws2yE1XArFGyBA8naiOY1CyVvh+Hbmtx64NiJWdZgk3I/oUImBYBSsFLgnOiA90u3HYLAOsnqPTHskcMtexZsDrxKSkzLKUQvcL/sCSyOugElqTId4CfgZ1SCY5NNSNzU8oWxMh7xjqaIRN342336Kz63Sx4NY21KA5+rviYxGxkyi0HZGFEZm2ZuJ/3mdFAY3fiZUkgJXbPHRIJUYYjyLAveF5gzkxBLKtLC7YjaimjKwgZVsCGT55FXSvKwQr0Lur8pVnMdRRKfoDF0ggq5RFd2hGmoghh7RM3pFb86T8+K8Ox+L1oKTzxyjP3A+fwA/q5RT</latexit><latexit sha1_base64="j/oGrWBiFlsQnjD2pJ2IRSMS3x8=">AAAB/XicbVDLSgMxFM3UV62v8bFzEyyCqzIRQZcFNy4r9AXtdMikaRuayQzJHaEOxV9x40IRt/6HO//GtJ2Fth64cDjn3uTeEyZSGPC8b6ewtr6xuVXcLu3s7u0fuIdHTROnmvEGi2Ws2yE1XArFGyBA8naiOY1CyVvh+Hbmtx64NiJWdZgk3I/oUImBYBSsFLgnOiA90u3HYLAOsnqPTHskcMtexZsDrxKSkzLKUQvcL/sCSyOugElqTId4CfgZ1SCY5NNSNzU8oWxMh7xjqaIRN342336Kz63Sx4NY21KA5+rviYxGxkyi0HZGFEZm2ZuJ/3mdFAY3fiZUkgJXbPHRIJUYYjyLAveF5gzkxBLKtLC7YjaimjKwgZVsCGT55FXSvKwQr0Lur8pVnMdRRKfoDF0ggq5RFd2hGmoghh7RM3pFb86T8+K8Ox+L1oKTzxyjP3A+fwA/q5RT</latexit><latexit sha1_base64="j/oGrWBiFlsQnjD2pJ2IRSMS3x8=">AAAB/XicbVDLSgMxFM3UV62v8bFzEyyCqzIRQZcFNy4r9AXtdMikaRuayQzJHaEOxV9x40IRt/6HO//GtJ2Fth64cDjn3uTeEyZSGPC8b6ewtr6xuVXcLu3s7u0fuIdHTROnmvEGi2Ws2yE1XArFGyBA8naiOY1CyVvh+Hbmtx64NiJWdZgk3I/oUImBYBSsFLgnOiA90u3HYLAOsnqPTHskcMtexZsDrxKSkzLKUQvcL/sCSyOugElqTId4CfgZ1SCY5NNSNzU8oWxMh7xjqaIRN342336Kz63Sx4NY21KA5+rviYxGxkyi0HZGFEZm2ZuJ/3mdFAY3fiZUkgJXbPHRIJUYYjyLAveF5gzkxBLKtLC7YjaimjKwgZVsCGT55FXSvKwQr0Lur8pVnMdRRKfoDF0ggq5RFd2hGmoghh7RM3pFb86T8+K8Ox+L1oKTzxyjP3A+fwA/q5RT</latexit><latexit sha1_base64="j/oGrWBiFlsQnjD2pJ2IRSMS3x8=">AAAB/XicbVDLSgMxFM3UV62v8bFzEyyCqzIRQZcFNy4r9AXtdMikaRuayQzJHaEOxV9x40IRt/6HO//GtJ2Fth64cDjn3uTeEyZSGPC8b6ewtr6xuVXcLu3s7u0fuIdHTROnmvEGi2Ws2yE1XArFGyBA8naiOY1CyVvh+Hbmtx64NiJWdZgk3I/oUImBYBSsFLgnOiA90u3HYLAOsnqPTHskcMtexZsDrxKSkzLKUQvcL/sCSyOugElqTId4CfgZ1SCY5NNSNzU8oWxMh7xjqaIRN342336Kz63Sx4NY21KA5+rviYxGxkyi0HZGFEZm2ZuJ/3mdFAY3fiZUkgJXbPHRIJUYYjyLAveF5gzkxBLKtLC7YjaimjKwgZVsCGT55FXSvKwQr0Lur8pVnMdRRKfoDF0ggq5RFd2hGmoghh7RM3pFb86T8+K8Ox+L1oKTzxyjP3A+fwA/q5RT</latexit>LSEP<latexit sha1_base64="TpRXs97k1Lz7FKPLZo8p6PuHeNQ=">AAACAXicbVDLSsNAFJ34rPUVdSO4GSyCq5KIoMuCCC5cVLQPaEKYTCft0MmDmRuxhLjxV9y4UMStf+HOv3HSZqGtBy4czrmXe+/xE8EVWNa3sbC4tLyyWlmrrm9sbm2bO7ttFaeSshaNRSy7PlFM8Ii1gINg3UQyEvqCdfzRReF37plUPI7uYJwwNySDiAecEtCSZ+47IYEhJSK7zr3MAfYA2e1lM889s2bVrQnwPLFLUkMlmp755fRjmoYsAiqIUj3bSsDNiAROBcurTqpYQuiIDFhP04iETLnZ5IMcH2mlj4NY6ooAT9TfExkJlRqHvu4s7lWzXiH+5/VSCM7djEdJCiyi00VBKjDEuIgD97lkFMRYE0Il17diOiSSUNChVXUI9uzL86R9Uretun1zWmvgMo4KOkCH6BjZ6Aw10BVqohai6BE9o1f0ZjwZL8a78TFtXTDKmT30B8bnD0Uyl0s=</latexit><latexit sha1_base64="TpRXs97k1Lz7FKPLZo8p6PuHeNQ=">AAACAXicbVDLSsNAFJ34rPUVdSO4GSyCq5KIoMuCCC5cVLQPaEKYTCft0MmDmRuxhLjxV9y4UMStf+HOv3HSZqGtBy4czrmXe+/xE8EVWNa3sbC4tLyyWlmrrm9sbm2bO7ttFaeSshaNRSy7PlFM8Ii1gINg3UQyEvqCdfzRReF37plUPI7uYJwwNySDiAecEtCSZ+47IYEhJSK7zr3MAfYA2e1lM889s2bVrQnwPLFLUkMlmp755fRjmoYsAiqIUj3bSsDNiAROBcurTqpYQuiIDFhP04iETLnZ5IMcH2mlj4NY6ooAT9TfExkJlRqHvu4s7lWzXiH+5/VSCM7djEdJCiyi00VBKjDEuIgD97lkFMRYE0Il17diOiSSUNChVXUI9uzL86R9Uretun1zWmvgMo4KOkCH6BjZ6Aw10BVqohai6BE9o1f0ZjwZL8a78TFtXTDKmT30B8bnD0Uyl0s=</latexit><latexit sha1_base64="TpRXs97k1Lz7FKPLZo8p6PuHeNQ=">AAACAXicbVDLSsNAFJ34rPUVdSO4GSyCq5KIoMuCCC5cVLQPaEKYTCft0MmDmRuxhLjxV9y4UMStf+HOv3HSZqGtBy4czrmXe+/xE8EVWNa3sbC4tLyyWlmrrm9sbm2bO7ttFaeSshaNRSy7PlFM8Ii1gINg3UQyEvqCdfzRReF37plUPI7uYJwwNySDiAecEtCSZ+47IYEhJSK7zr3MAfYA2e1lM889s2bVrQnwPLFLUkMlmp755fRjmoYsAiqIUj3bSsDNiAROBcurTqpYQuiIDFhP04iETLnZ5IMcH2mlj4NY6ooAT9TfExkJlRqHvu4s7lWzXiH+5/VSCM7djEdJCiyi00VBKjDEuIgD97lkFMRYE0Il17diOiSSUNChVXUI9uzL86R9Uretun1zWmvgMo4KOkCH6BjZ6Aw10BVqohai6BE9o1f0ZjwZL8a78TFtXTDKmT30B8bnD0Uyl0s=</latexit><latexit sha1_base64="TpRXs97k1Lz7FKPLZo8p6PuHeNQ=">AAACAXicbVDLSsNAFJ34rPUVdSO4GSyCq5KIoMuCCC5cVLQPaEKYTCft0MmDmRuxhLjxV9y4UMStf+HOv3HSZqGtBy4czrmXe+/xE8EVWNa3sbC4tLyyWlmrrm9sbm2bO7ttFaeSshaNRSy7PlFM8Ii1gINg3UQyEvqCdfzRReF37plUPI7uYJwwNySDiAecEtCSZ+47IYEhJSK7zr3MAfYA2e1lM889s2bVrQnwPLFLUkMlmp755fRjmoYsAiqIUj3bSsDNiAROBcurTqpYQuiIDFhP04iETLnZ5IMcH2mlj4NY6ooAT9TfExkJlRqHvu4s7lWzXiH+5/VSCM7djEdJCiyi00VBKjDEuIgD97lkFMRYE0Il17diOiSSUNChVXUI9uzL86R9Uretun1zWmvgMo4KOkCH6BjZ6Aw10BVqohai6BE9o1f0ZjwZL8a78TFtXTDKmT30B8bnD0Uyl0s=</latexit>LRE<latexit sha1_base64="Fi+YFI4waJojXSQ7iRhXlzhGs64=">AAACAHicbVDLSsNAFJ3UV62vqAsXbgaL4KokIuiyIIILF1XsA5oQJtNJO3TyYOZGLCEbf8WNC0Xc+hnu/BsnbRbaeuDC4Zx7ufcePxFcgWV9G5Wl5ZXVtep6bWNza3vH3N3rqDiVlLVpLGLZ84ligkesDRwE6yWSkdAXrOuPLwu/+8Ck4nF0D5OEuSEZRjzglICWPPPACQmMKBHZTe5lDrBHyO6u8twz61bDmgIvErskdVSi5ZlfziCmacgioIIo1betBNyMSOBUsLzmpIolhI7JkPU1jUjIlJtNH8jxsVYGOIilrgjwVP09kZFQqUno687iXDXvFeJ/Xj+F4MLNeJSkwCI6WxSkAkOMizTwgEtGQUw0IVRyfSumIyIJBZ1ZTYdgz7+8SDqnDdtq2Ldn9SYu46iiQ3SETpCNzlETXaMWaiOKcvSMXtGb8WS8GO/Gx6y1YpQz++gPjM8fnAWW8A==</latexit><latexit sha1_base64="Fi+YFI4waJojXSQ7iRhXlzhGs64=">AAACAHicbVDLSsNAFJ3UV62vqAsXbgaL4KokIuiyIIILF1XsA5oQJtNJO3TyYOZGLCEbf8WNC0Xc+hnu/BsnbRbaeuDC4Zx7ufcePxFcgWV9G5Wl5ZXVtep6bWNza3vH3N3rqDiVlLVpLGLZ84ligkesDRwE6yWSkdAXrOuPLwu/+8Ck4nF0D5OEuSEZRjzglICWPPPACQmMKBHZTe5lDrBHyO6u8twz61bDmgIvErskdVSi5ZlfziCmacgioIIo1betBNyMSOBUsLzmpIolhI7JkPU1jUjIlJtNH8jxsVYGOIilrgjwVP09kZFQqUno687iXDXvFeJ/Xj+F4MLNeJSkwCI6WxSkAkOMizTwgEtGQUw0IVRyfSumIyIJBZ1ZTYdgz7+8SDqnDdtq2Ldn9SYu46iiQ3SETpCNzlETXaMWaiOKcvSMXtGb8WS8GO/Gx6y1YpQz++gPjM8fnAWW8A==</latexit><latexit sha1_base64="Fi+YFI4waJojXSQ7iRhXlzhGs64=">AAACAHicbVDLSsNAFJ3UV62vqAsXbgaL4KokIuiyIIILF1XsA5oQJtNJO3TyYOZGLCEbf8WNC0Xc+hnu/BsnbRbaeuDC4Zx7ufcePxFcgWV9G5Wl5ZXVtep6bWNza3vH3N3rqDiVlLVpLGLZ84ligkesDRwE6yWSkdAXrOuPLwu/+8Ck4nF0D5OEuSEZRjzglICWPPPACQmMKBHZTe5lDrBHyO6u8twz61bDmgIvErskdVSi5ZlfziCmacgioIIo1betBNyMSOBUsLzmpIolhI7JkPU1jUjIlJtNH8jxsVYGOIilrgjwVP09kZFQqUno687iXDXvFeJ/Xj+F4MLNeJSkwCI6WxSkAkOMizTwgEtGQUw0IVRyfSumIyIJBZ1ZTYdgz7+8SDqnDdtq2Ldn9SYu46iiQ3SETpCNzlETXaMWaiOKcvSMXtGb8WS8GO/Gx6y1YpQz++gPjM8fnAWW8A==</latexit><latexit sha1_base64="Fi+YFI4waJojXSQ7iRhXlzhGs64=">AAACAHicbVDLSsNAFJ3UV62vqAsXbgaL4KokIuiyIIILF1XsA5oQJtNJO3TyYOZGLCEbf8WNC0Xc+hnu/BsnbRbaeuDC4Zx7ufcePxFcgWV9G5Wl5ZXVtep6bWNza3vH3N3rqDiVlLVpLGLZ84ligkesDRwE6yWSkdAXrOuPLwu/+8Ck4nF0D5OEuSEZRjzglICWPPPACQmMKBHZTe5lDrBHyO6u8twz61bDmgIvErskdVSi5ZlfziCmacgioIIo1betBNyMSOBUsLzmpIolhI7JkPU1jUjIlJtNH8jxsVYGOIilrgjwVP09kZFQqUno687iXDXvFeJ/Xj+F4MLNeJSkwCI6WxSkAkOMizTwgEtGQUw0IVRyfSumIyIJBZ1ZTYdgz7+8SDqnDdtq2Ldn9SYu46iiQ3SETpCNzlETXaMWaiOKcvSMXtGb8WS8GO/Gx6y1YpQz++gPjM8fnAWW8A==</latexit>{1  . . .   N} the subject performs T n trials  Dn ≡ {(an
chosen from a set C ≡ {Ck}K

k=1  and reward rn

t ∈ (cid:60).

t )}T n

t   rn

t=1  with action an

t ∈ C on trial t

Encoder and decoder. We treat decision-making as a (partly stochastic) dynamical system that
maps past experiences as input into outputs in the form of actions. As such  the dataset D may be
considered to contain samples from the output of potentially N different dynamical systems. The aim
is then to turn each sequence Dn into a vector  zn  in a latent space  in such a way that zn captures
the characteristic properties of the corresponding dynamical system (whilst avoiding over-ﬁtting the
particular choices). In this respect  the task is to ﬁnd a low-dimensional representation for each of the
dynamical systems in an unsupervised manner. We take an autoencoder-inspired model to achieve
this  in which an encoder network is trained to process an entire input sequence into a vector in the
latent space. A decoder network then takes as input this vector and recovers an approximation to the
original dynamical system. Along with additional factors that we describe below  the model is trained
by minimising a reconstruction loss which measures how well the generated dynamical system can
predict the observed sequence of actions. The latent representation is thus supposed to capture the
“essence” of the input sequence. This is because the latent space is low-dimensional compared to the
original sequence and acts as an information bottleneck; as such the encoder has to learn to encode
the most informative aspects of each sequence.
The model architecture is presented in Figure 1. The ﬁrst part is an encoder RNN (shown in red)  and
is responsible for extracting the characteristic properties of the input sequence. It takes the whole
sequence as input and outputs its terminal state. This state is mapped into the latent space through a
series of fully-connected feed-forward layers. The encoder is:

M×1 ≡ enc(an
zn

1...T   rn

(1)
in which Θenc are the weights of the RNN and feed-forward layers  and M is the dimensionality of
the latent space (see Supplementary Material for the details of the architecture).
The second part of the model is a feed-forward decoder network (shown in blue) with weights Θdec 
which takes the latent representation as input  and outputs a vector Φn 

1...T ; Θenc)  n = 1 . . . N 

Φn ≡ dec(zn; Θdec).

(2)
As in a hyper-network  vector Φn contains the weights of a second RNN called the learning network 
itself inspired by [e.g.  Dezfouli et al.  2019  2018]  and described below. The learning network apes
the process of decision-making  taking past actions and rewards as input  and returning predictions of
the probability of the next action. Making Φn such that the learning network reconstructs the original
sequence is what forces zn to encode the characteristics of each subject.

Learning network. The learning network is based on the Gated Recurrent Unit architecture [GRU;
Cho et al.  2014] with Nc cells. This realizes a function f n  which at time-step t maps the previous
state xn

t−1  into a next state 

t−1  action an

t−1 and reward rn
t ≡ f n(an
xn

t−1  rn

t−1  xn

t−1; Φn) 

(3)

(4)

with predictions for the probabilities of actions arising from a weight matrix W n ∈ (cid:60)K×Nc

t ≡ W nxn
vn
t  

t (at ≡ Ci; an
πn

1...t−1  rn

1...t−1) =

(cid:80)

evn

t [i]

k=1...K evn

t [k]  

where vn
t represent the logit scores for each action (unnormalised probabilities)  and πt(.) are the
probabilities of taking each action at time t. vn
t [i] represents the ith element of vn
t . For Nc GRU cells
and K actions  function f n requires J = 3N 2
c + 3KNc + 6Nc parameters. Φn consists of these plus
the KNc parameters of W n. Note that this RNN  which models humans decision-making processes 
should not be confused with the RNN in the encoder  which extracts and maps each input sequence
into the latent space.
Summary. The encoder network takes an input sequence and maps it into its latent representation.
The decoder network then takes the latent representation and generates the weights of an RNN that is
able to predict the actions taken in the input sequence. The next section describes in detail how the
network weights Θenc and Θdec are learned end-to-end.

3

3 Training objective

The training loss function has three components: (i) a reconstruction loss which penalizes discrepan-
cies between the predicted and actual input sequence  (ii) a group-level disentanglement loss which
encourages sequences to spread independently across the dimensions of the input sequence  (iii) a
separation loss which favors dimensions of the latent space that have separate effects on the behavior
generated by the learning networks.
Reconstruction loss. Each sequence Dn in D is passed through the encoder to obtain the cor-
responding latent representation. The latent representation is then passed through the decoder to
generate the weight vector Φn of the learning network. We then assess how well the n-th learn-
ing network can predict the actions taken in Dn. The total reconstruction loss is based on the
negative-log-likelihood:

log πn

t (an

t ; an

1...t−1  rn

1...t−1).

(5)

N(cid:88)

T n(cid:88)

n=1

t=1

LRE = − 1
N

Disentanglement loss.
The second term in the loss function favors disentangled representations
by seeking to ensure that each dimension of the latent space corresponds to an independent factor of
contribution in the variation across input sequences. This is achieved by maximising the similarity
between the empirical encoding distribution (i.e.  {zn}) and a prior distribution p(z)  taken to
be isotropic Gaussian (see the Supplementary Material for details). Maximising this similarity
encourages the dimensions of the latent representation to be independent across input sequences.
Deﬁne ˆq(z) as the empirical distribution of zn  and g(z) as a Gaussian with the same mean and
covariance as that of ˆq(z). We combine two popular measures of the dissimilarity between the
encoding distribution and p(z):

LDIS = λ1MMD(ˆq(z)  p(z)) + KL(g(z)(cid:107)p(z)) 

(6)
where MMD is the Maximum Mean Discrepancy [Tolstikhin et al.  2017] and KL is the Kullback-
Leibler divergence (the Gaussian approximation makes the KL computations tractable and robust) and
λ1 is a hyper-parameter. We expected the MMD term to sufﬁce; however  we found that combining
the two yielded better results.

Separation loss. Crudely speaking  the disentanglement loss focuses on regularising the encoder;
however  to make the latent representation behaviorally interpretable  it is also necessary to regularize
the decoder. Gaining insight into the effect of one dimension on the behavioral predictions of the
learning network is hard if this is affected by the other dimensions. Therefore  we introduce an
additional separation loss designed to discourage interactions.
For simplicity  assume the decision-making task involves only two actions  C1 and C2  and that the
latent space has two dimensions  z1 and z2 (M = 2; see Supplementary Material for the general
t (C2) are the logits corresponding to the probability of taking
case). As noted before vn
action C1 and C2 at trial t for input sequence n. Denote by un
t the relative logits of the actions 
un
t = vn

t changes by changing the ﬁrst dimension  z1 is

t (C2). The amount that un

t (C1) − vn

t (C1) and vn

Ideally  the effect of changing z1 on behavior will be independent from the effect of z2 on behavior 
which will allow us later to interpret z1 independently from z2. We capture the amount of interaction
(inseparability) between the effect of z1 and z2 on changing un

t as

t
∂z1

(cid:12)(cid:12)(cid:12)(cid:12) ∂un
(cid:12)(cid:12)(cid:12)(cid:12) .
(cid:12)(cid:12)(cid:12)(cid:12) ∂2un
T n(cid:88)
N(cid:88)

t

∂z1∂z2

n=1

t=1

4

(cid:12)(cid:12)(cid:12)(cid:12) .
(cid:12)(cid:12)(cid:12)(cid:12) ∂2un

t

∂z1∂z2

(cid:12)(cid:12)(cid:12)(cid:12) .

dn
t =

ˆLSEP =

1
N

(7)

(8)

(9)

This would be zero if the relative logit comprises additively separable functions  i.e.  un
g2(z2) for two functions g1 and g2. Even without this  minimizing dn
have a separate effect on behavior. We therefore consider the following loss term 

t = g1(z1) +
t can help make each dimension

The calculation of the above term is computationally intensive as it requires computing the second-
order derivative for each time step and sequence pair (O(N T n) second-order derivative calculations).
Instead  we use the following approximation 

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) T n(cid:88)

t=1

N(cid:88)

n=1

ˆLSEP ≈ LSEP =

1
N

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) =

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

N(cid:88)

n=1

∂2un
t
∂z1∂z2

1
N

T n(cid:88)

un
t

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)  

∂2

∂z1∂z2

t=1

(10)

which can be calculated more efﬁciently (O(N ) second-order derivative calculations)1. We note that
the loss is deﬁned using logits instead of the probabilities  since probability predictions are bounded
and cannot be separated as πn
We now deﬁne the combined loss function as follows 

t (C2) = g1(z1) + g2(z2) in the general case.

t (C1) − πn

L = LRE + λ2LDIS + λ3LSEP 

(11)

in which λ2 and λ3 are hyper-parameter.
The model parameters Θenc and Θdec were trained based on the above objective function and using
gradient descent optimisation method [Kingma and Ba  2014]. See Supplementary Material for
details.

4 Results

SYNTHETIC data. To illustrate that our method can learn the underlying ground truth dynamical
system  we generated Q−learning agents [Watkins  1989] with various parameter values and simu-
lated their behaviour on a bandit task involving two stochastically-rewarded actions  C1 and C2. The
actions of the agents and the rewards they received comprise the dataset D. The Q−learning agent
was speciﬁed by two parameters  values for which were drawn randomly (see Supplementary Material
for more details). One parameter is the inverse temperature or reward sensitivity  β  which determines
the propensity to explore  equivalently controlling the impact of receiving a reward from an action on
repeating that action in future trials. The other parameter is κ  which determines the tendency of an
agent to repeat the last taken action in the next trial irrespective of whether it was rewarded [e.g.  Lau
and Glimcher  2005]. Values κ > 0 favor repeating an action in next trial (perseveration) and values
κ < 0 favor switching between the actions. We generated N = 1500 agents (saving 30% for testing).
The test data was used for determining the optimal number of training iterations (early stopping).
Each agent selected 150 actions (T n = 150).
We trained our model using the data (see Figure S3 for the trajectory of the loss function and Figure S4
for the distribution of the latent representations). As shown in Figure 2(a)  and as intended  these
representations turned out to have an interpretable relationship with the parameters that actually
determined behavior: the exploration parameter β is mainly related to z2 and the perseveration
parameter κ to z1. This outcome arose because of the LSEP term in the loss function. A similar graph
before introducing the LSEP is shown in Figure S1(a)  which shows that without this term  z1 and z2
have mixed relationships with κ and β.
We then sought to interpret each dimension of the latent space in behavioral terms. To do this 
we used the decoder to generate learning networks corresponding to different values of the latent
representations and interpreted these dimensions by analysing the behaviour of the simulated networks
on a ﬁxed input sequence. In the ﬁxed input sequence  the agent always performs action C1 (see
Figure S5 for the simulations using both C1 and C2 as the previous action)  and receives just one
non-zero reward at the trial marked by the red vertical line. Using the same sequence for all networks
requires running simulations off-policy (i.e.  the network predicts the next choice  but does not execute
it). This setting provides the same input to the model in all conditions  allowing us to diagnose exactly
what affects the output of the model. The simulations are shown in Figure 2(b). Each panel in the
ﬁgure shows the simulation of the generated network for 10 trials.
In Figure 2(b)-left panel  z2 is ﬁxed at zero as z1 is allowed to vary. As the ﬁgure shows  by changing
the z1 dimension  the probability of taking the same action (in this case C1) in the next trial is affected 
i.e.  high values of z1 are associated with the high probability of perseveration  and in the low values
of z1 there is a high chance of switching to the other action in the next trial. This is consistent with

1We use the automatic differentiation in Tensorﬂow [Abadi et al.  2016].

5

Figure 2: SYNTHETIC data. (a) Relationship between the dimensions of the latent representations (z1 
z2) and the parameters used to generate the data (κ and β). z1 captures the perseveration parameter
(κ) and z2 captures the rate of exploration (β). The smoothed black lines were calculated using
method ‘gam‘ in R [Wood  2011] and the shaded area represents conﬁdence intervals. (b) Off-policy
simulations of the model for different values of z1 (left-panel; z2 = 0) and z2 (right-panel; z1 = 0).
The plots show the probability of selecting C1 in each trial when C1 had actually been chosen on all
the previous trials. A single reward is provided  shown by the vertical red line. (c) Model simulations
similar to the ones in panel (b) but using the actual Q−learning model. In the left panel β = 3 and in
the right panel κ = 0.

the correspondence between z1 and the perseveration parameter κ. Note that after receiving the
reward  the probability of taking C1 increases (since C1 was the previous action and it was rewarded) 
however  the size of the increment is not affected by changes in z1  i.e.  z1 is controlling perseveration
but not sensitivity of behaviour to reward.
In contrast in Figure 2(b)-right panel  z1 is ﬁxed at zero as z2 is in turn allowed to vary. As the
panels show  by changing z2 the probability of repeating an action is not affected  but the sensitivity
of action probabilities to the reward is affected. That is  at the higher values of z2 there is a high
probability of repeating the rewarded action (C1 in this case). Therefore  z1 and z2 have separate
effects on behaviour corresponding to the perseveration and reward sensitivity. This separation is a
consequence of introducing the LSEP term. In Figure S1(b) we show the same simulations but without
introducing the LSEP into the loss function  which shows that the effects of z1 and z2 on behaviour
are not separated (see Figure S2 for how the behaviour of model changes during training). Figure 2(c)
shows the same simulations as panel (b) but using the original Q-learning model which was used to
generate the data (for different values of β and κ). As the ﬁgure shows the model closely reﬂects the
behaviour of Q−learning model  as expected.

BD dataset. This dataset [Dezfouli et al.  2019] comprises behavioural data from 34 patients with
depression  33 with bipolar disorder and 34 matched healthy controls. As in the synthetic data above 
subjects performed a bandit task with two stochastically-rewarded actions (C1 and C2) (Figure 3(a)).
Each subject completed the task 12 times using different reward probabilities for each action. The
dataset thus contains N = 12 (sequences) ×101 (participants) = 1212  which we used for training
the model. Out of the 12 sequences of each subject  8 were used for training and 4 for testing
to determine the optimal number of training iterations (see Figure S7 for the training curves and
Supplementary Material for more details).
We considered a two-dimensional latent space z ={z1  z2}; the resulting coordinates for all sequences
are shown in Figure 3(b). We made two predictions about z: ﬁrst  we expected that the latent
representations for the sequences for a single subject should be mutually similar as they come from
the same decision-making system. We therefore compared the mean pairwise distances separating

6

rewardrewardc) Q-learning b) Modela)porabiblity of C10.00.51.0trial−1.00−0.50+0.00+0.50+1.00κ−202−202z1κ051015−202z1β051015−2024z2β−202−2024z2κporabiblity of C10.00.51.0−1.00−0.50+0.00+0.50+1.00z1β+0.00+2.50+5.00+7.50trial−1.00−0.50+0.00+0.50+1.00z2the latent representations within and between subjects (see Supplementary Material for details).
Figure 4(a) shows that this prediction is indeed correct (p < 0.001 using Wilcoxon rank sum test).
Second  we expected that the decision-making differences between the three groups to be reﬂected
in their latent representations. Figure 4(b) shows the mean latent representations for the subjects
organized by group. Although the groups differ along the z2 dimension (p < 0.001 comparing bipolar
and healthy groups along z2 and using independent t-test  and p < 0.05 comparing depression and
healthy groups); the z1 dimension is evidently capturing variations that are unrelated to the existing
diagnostic categories (p > 0.1).
These results also highlight the substantial heterogeneity of the population. Some bipolar patients with
high z2 are apparently more behaviorally similar to average depressed patients or healthy controls
than to the average bipolar patients. We would not have been able to extract this information by ﬁtting
a single RNN to each whole group (as was done in previous work).
We then followed the same scheme as for the synthetic data to provide an interpretation for the
dimensions of latent space. The results of off-policy simulations are shown in Figure 4(c) (see
Figure S6 for simulations using both actions). First  both left and right panels show that  after
receiving the reward from an action  subjects show a tendency to switch to the other action. This
is inconsistent with predictions of conventional Q−learning  but was also found to be evident in
model agnostic analyses [Dezfouli et al.  2019] (where it is also reconciled with gaining rather
than losing reward). The current model is able to capture this since it uses RNNs for representing
decision-making processes  which do not make such an assumption.
Second  as Figure 4(c)-left shows  the z1 dimension – which is not different between the groups –
is mostly related to reward sensitivity  as it controls (albeit rather weakly) the action probabilities
after receiving the reward. On the other hand  the z2 dimension – which is signiﬁcantly different
between the groups – is more involved in perseveration/switching behaviour between the actions  i.e. 
it controls the probability of staying on the same action. For low z2  the probability of repeating the
previous taken (in this case C1) is below 0.5  implying that the subjects in this part of the latent space
tend to switch. In order to conﬁrm this  we simulated the model on-policy – in which the actions are
selected by the model – for different values of z1 and z2. As the results in Figure 4(d) show  for low
z2  the model indeed oscillates between the two actions. The z2 dimension is signiﬁcantly lower in
the bipolar group than healthy controls  which is consistent with the previous report indicating an
oscillatory behavioural characteristic in this group [Dezfouli et al.  2019].
Finally  panel (c)-right shows that reward sensitivity and perseveration are not completely independent 
i.e.  when z2 is low  favoring switching  the effect of reward on probabilities is also more signiﬁcant 
implying that these two traits covary.
In summary  the model was able capture behavioural properties which are not consistent with cognitive
models such as Q−learning. It was also able to capture individual differences which could not be
extracted by ﬁtting a single RNN to the whole group.

(a)

(b)

Figure 3: BD dataset. (a) The decision-making task. On each trial  subjects pressed a left (C1) or right
(C2) key and had a chance of getting a reward (M&M chocolate or BBQ shapes). The task lasted for
40 seconds and the responses were self-paced. Each participant completed the task 12 times with a
12-second delay between them and different probabilities of reward. (b) Distribution of z values for
each group. Each dot represents an input sequence.

7

40 seconds (free-responses)M&M=0Shapes=0M&M=1Shapes=0wassmall(thatis atintermediatevaluesofDnearorequaltozero) wecomparedthepredictivevalueofPandDoverchoiceatdifferentlevelsofPandDinalogisticregression.Figure2bshowswewereablesuccessfullytoidentifyconditionsunderwhichPandDaredifferentiated:atsmalldifferencesinactionvalues(themiddletertileofDvalues) Pwasasigniﬁcantpredictor whereasDwasnot.Conversely Fig.2cshowsthatPandDweresigniﬁcantpredictorsacrossalltertilesofPvalues(pso0.001).Thisresultconﬁrmsthatwhenchoicesweremadeinthepresenceofsmalldifferencesinactionvalue Pvaluesbetterdiscriminatedthebestaction.Dorsolateralprefrontalcortextrackstherelativeadvantage.Toidentifytheneuralregionsinvolvedinthecomputationoftherelativeadvantagevaluesthatguidedchoice wedeﬁnedastickfunctionforeachresponseandparametricallymodulatedthisbyPinaresponse-by-responsefashionforeachparticipant.Asweusedafree-responsetaskandtheintervalbetweenchoiceswasnotsystematicallyjittered wecannotdeterminewhetherthemodelvariableshadseparateeffectsatthetimeofeachchoice(orbetweenchoiceandfeedback).Wecanonlydeterminewhetherneuralactivitywasrelatedtothetimecourseofthemodelvari-ablesacrossthe40-sblockassubjectstriedtolearnthebestaction(forexample Fig.2a).AnSPMone-samplet-testwiththeparametricregressorrepresentingPrevealedneuralactivitypositivelyrelatedtoPinasinglelargeclusterintherightmiddlefrontalgyrus withthemajorityofvoxelsoverlappingBA9(dlPFC22 23;peakvoxel:44 25 37;t¼5.98 family-wisecluster(FWEc)P¼0.012).Figure2ashowsthecorticalregionswheretheBOLDresponsecovariedwiththePvaluesofeachresponse implicatingtheseregionsinencodingtherelativelikelihoodthattheleftactionisbest(QLeft4QRight).M&Ms = 0Shapes = 0012340 s (free responses)12 sRatingResponse rateCausal rating10.07.55.02.50.0Responses s–10.250.080.1250.250.080.125M&Ms = 1Shapes = 00102345678910VeryunlikelyVerylikelyHow likely was it pressing the rightbutton earnt you an M&M?Figure1|Experimentalstimuli behaviouralchoicesandcausalratings.(a)Beforethechoice nostimuliindicatedwhichbuttonwasmorelikelytoleadtoreward.Whentheparticipantmadeachoice thebuttonchosenwashighlighted(green)andonrewardedtrialstherewardstimuluswaspresentedfor1 000msduration.Aftereachblockoftrials theparticipantratedhowcausaleachbuttonwas.(b)Meanresponserate(responsespersecond)washigherforthehigh-contingencyaction(blue)overlow-contingencyaction(red)ineachcondition.(c)Causalratingswerehigherforthehigh-contingencyaction(blue)overlow-contingencyaction(red)ineachcondition.Responserateandcausalratingsigniﬁcantlyvariedwithcontingency Po0.001.Verticalbarsrepresents.e.m.Table1|Modelcomparisonsbetweenthehybridmodelanditsspecialcases.HybridQ-learningRelativeadvantageNegativeloglikelihood542155065558AggregateLRTfavouringhybrid—X240¼170***X220¼274***No.offavouringhybrids—138PseudoR20.6080.6020.597Shownforeachmodel:negativeloglikelihood;teststatisticandP-valueforalikelihoodratiotestagainstthehybrid(full)model aggregatedacrosssubjects;thenumberofsubjectsfavoringthehybridmodelonalikelihoodratiotest(Po0.05);andthedegreetowhichthemodelexplainedthechoicedataaveragedovertheindividualﬁts(pseudoR2).***Po1E-16.NATURECOMMUNICATIONS|DOI:10.1038/ncomms5390ARTICLENATURECOMMUNICATIONS|5:4390|DOI:10.1038/ncomms5390|www.nature.com/naturecommunications3&2014MacmillanPublishersLimited.Allrightsreserved.llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll−2−1012−202z1z2lllHealthyDepressionBipolarFigure 4: BD dataset. (a) The distances between the latent representations for single subjects (Within)
and between the subjects (Between). Each dot represents a subject; the bars show the means and the
error-bars  1SEM. (b) The mean of the latent representations for each subject across the dimensions
of the latent space. Each dot represents a subject and bars and error-bars show means and 1SEM. (c)
Off-policy simulations of the model for different values of z1 (left-panel; z2 = 0) and z2 (right-panel;
z1 = 0). The plots show the probability of selecting C1 in each trial when C1 had actually been
chosen on all the previous trials. A single reward is provided  shown by the vertical red line. (d)
On-policy simulations of the model. The actions are selected by the model based on which action has
the higher probability of being taken (the ﬁrst action was set to C1).

5 Related work

There is a wealth of work using RNNs as models of decision-making  for unsupervised dimension
reduction of dynamical systems  and for sequence-to-sequence mappings. For the ﬁrst  a key focus
has been learning-to-learn [e.g.  Wang et al.  2016  Song et al.  2017] – i.e.  creating RNNs that can
themselves learn to solve a battery of tasks. However  these generative models have not been coupled
with recognition  for instance to capture individual differences. Techniques based on autoencoders
have explored low-dimensional latent spaces for modelling neural activity trajectories in the brain
[e.g.  Pandarinath et al.  2018]. However  like inﬂuential sequence-sequence models for translation
[Bowman et al.  2015]  these focus on building an open loop account for the state of the brain within
a trajectory  or the state characterizing a particular input sentence  whereas we focus on the trait
characteristic of a closed-loop controller that has to interact with an external environment itself [see
also Fox et al.  2011  Johnson et al.  2016  as examples of other approaches]. Our combination of an
autoencoder and hyper-network [Ha et al.  2016  Karaletsos et al.  2018] is  to our knowledge  novel 
and might ﬁnd other applications in the analysis of other dynamical systems such as time-series data.

6 Conclusion and discussion

We proposed a ﬂexible autoencoder-based framework for modelling individual differences in decision-
making tasks. The autoencoder maps the sequence of actions and rewards taken and received by a
subject to a position in a low-dimensional latent space which is decoded to determine the weights of
a ‘learning network’ RNN that characterizes how that subject behaves as a plastic decision-maker.
The latent space was disentangled by adding a speciﬁc component to the loss function.
The model can be extended in various directions. One is to pin down (part of) the learning network as
a conventional  parameterized  RL agent  to facilitate further interpretation of the latent dimensions.
Another is to include tasks with non-trivial (Markovian or non-Markovian) state information partially
signalled by stimuli.

8

rewardd) On-policy c) Off-policya)b)0.00.51.0porabiblity of C1−1.00−0.50+0.00+0.50+1.00z1reward−1.00−0.50+0.00+0.50+1.00z2porabiblity of C10.00.51.0−1.00−0.50+0.00+0.50+1.00z1−1.00−0.50+0.00+0.50+1.00z2z1z2HealthyDepressionBipolarHealthyDepressionBipolar−2−10120123BetweenWithindistancetrialtrialAcknowledgments

We are grateful to Bernard W. Balleine for sharing BD dataset with us.

References
John B Carroll and Scott E Maxwell. Individual differences in cognitive abilities. Annual review of

psychology  30(1):603–640  1979.

Michael J Frank  Bradley B Doll  Jen Oas-Terpstra  and Francisco Moreno. Prefrontal and stri-
atal dopaminergic genes predict individual differences in exploration and exploitation. Nature
neuroscience  12(8):1062  2009.

Hanneke E M den Ouden  Nathaniel D Daw  Guillén Fernandez  Joris A Elshout  Mark Rijpkema 
Martine Hoogman  Barbara Franke  and Roshan Cools. Dissociable effects of dopamine and
serotonin on reversal learning. Neuron  80(4):1090–1100  2013.

Daniel J Navarro  Thomas L Grifﬁths  Mark Steyvers  and Michael D Lee. Modeling individual
differences using Dirichlet processes. Journal of mathematical Psychology  50(2):101–122  2006.

Jerome R Busemeyer and Julie C Stout. A contribution of cognitive decision models to clinical
assessment: decomposing performance on the Bechara gambling task. Psychological assessment 
14(3):253  2002.

Nathaniel D Daw. Trial-by-trial data analysis using computational models. In Mauricio R. Delgado 
Elizabeth A. Phelps  and Trevor W. Robbins  editors  Decision Making  Affect  and Learning.
Oxford University Press  2011.

Eldad Yechiam  Jerome R Busemeyer  Julie C Stout  and Antoine Bechara. Using cognitive models
to map relations between neuropsychological disorders and human decision-making deﬁcits.
Psychological science  16(12):973–8  dec 2005.

Amir Dezfouli  Kristi Grifﬁths  Fabio Ramos  Peter Dayan  and Bernard W Balleine. Models that
learn how humans learn: the case of decision-making and its disorders. PLoS computational
biology  15(6):e1006903  2019.

Amir Dezfouli  Richard W Morris  Fabio Ramos  Peter Dayan  and Benrard W Balleine. Integrated
accounts of behavioral and neuroimaging data using ﬂexible recurrent neural network models. In
Advances in Neural Information Processing Systems (Neurips)  2018.

Guangyu Robert Yang  Madhura R Joglekar  H Francis Song  William T Newsome  and Xiao-Jing
Wang. Task representations in neural networks trained to perform many cognitive tasks. Nature
Neuroscience  22(2):297–306  2019.

Hava T Siegelmann and Eduardo D Sontag. On the computational power of neural nets. Journal of

computer and system sciences  50(1):132–150  1995.

David E Rumelhart  Geoffrey E Hinton  and Ronald J Williams. Learning internal representations by
error propagation. Technical report  California Univ San Diego La Jolla Inst for Cognitive Science 
1985.

Ilya Tolstikhin  Olivier Bousquet  Sylvain Gelly  and Bernhard Schoelkopf. Wasserstein auto-encoders.

arXiv preprint arXiv:1711.01558  2017.

David Ha  Andrew Dai  and Quoc V Le. Hypernetworks. arXiv preprint arXiv:1609.09106  2016.

Theofanis Karaletsos  Peter Dayan  and Zoubin Ghahramani. Probabilistic meta-representations of

neural networks. arXiv preprint arXiv:1810.00555  2018.

Kyunghyun Cho  Bart Van Merriënboer  Caglar Gulcehre  Dzmitry Bahdanau  Fethi Bougares  Holger
Schwenk  and Yoshua Bengio. Learning phrase representations using RNN encoder-decoder for
statistical machine translation. arXiv preprint arXiv:1406.1078  2014.

9

Martín Abadi  Ashish Agarwal  Paul Barham  Eugene Brevdo  Zhifeng Chen  Craig Citro  Greg S
Corrado  Andy Davis  Jeffrey Dean  Matthieu Devin  and Others. Tensorﬂow: Large-scale machine
learning on heterogeneous distributed systems. arXiv preprint arXiv:1603.04467  2016.

Diederik P. Kingma and Jimmy Ba. Adam: A Method for Stochastic Optimization. arXiv preprint

arXiv:1412.6980  2014.

C.J.C.H. Watkins. Learning from Delayed Rewards. Ph.D. thesis  Cambridge University  1989.

Brian Lau and Paul W Glimcher. Dynamic response-by-response models of matching behavior in

rhesus monkeys. Journal of the experimental analysis of behavior  84(3):555–79  2005.

Simon N Wood. Fast stable restricted maximum likelihood and marginal likelihood estimation of
semiparametric generalized linear models. Journal of the Royal Statistical Society: Series B
(Statistical Methodology)  73(1):3–36  2011.

Jane X Wang  Zeb Kurth-Nelson  Dhruva Tirumala  Hubert Soyer  Joel Z Leibo  Remi Munos 
Charles Blundell  Dharshan Kumaran  and Matthew M Botvinick. Learning to reinforcement learn.
arXiv preprint arXiv:1611.05763  2016.

H. Francis Song  Guangyu R. Yang  and Xiao Jing Wang. Reward-based training of recurrent neural

networks for cognitive and value-based tasks. eLife  6:1–24  2017.

Chethan Pandarinath  Daniel J O’Shea  Jasmine Collins  Rafal Jozefowicz  Sergey D Stavisky 
Jonathan C Kao  Eric M Trautmann  Matthew T Kaufman  Stephen I Ryu  Leigh R Hochberg  and
Others. Inferring single-trial neural population dynamics using sequential auto-encoders. Nature
methods  page 1  2018.

Samuel R Bowman  Luke Vilnis  Oriol Vinyals  Andrew M Dai  Rafal Jozefowicz  and Samy Bengio.

Generating sentences from a continuous space. arXiv preprint arXiv:1511.06349  2015.

Emily B Fox  Erik B Sudderth  Michael I Jordan  Alan S Willsky  et al. A sticky hdp-hmm with

application to speaker diarization. The Annals of Applied Statistics  5(2A):1020–1056  2011.

Matthew J Johnson  David K Duvenaud  Alex Wiltschko  Ryan P Adams  and Sandeep R Datta.
Composing graphical models with neural networks for structured representations and fast inference.
In Advances in neural information processing systems  pages 2946–2954  2016.

10

,Matthew Lawlor
Steven Zucker
Matthias Hein
Maksym Andriushchenko
Amir Dezfouli
Hassan Ashtiani
Omar Ghattas
Richard Nock
Peter Dayan
Cheng Soon Ong