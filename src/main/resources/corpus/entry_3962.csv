2009,On the Convergence of the Concave-Convex Procedure,The concave-convex procedure (CCCP) is a majorization-minimization algorithm that solves d.c. (difference of convex functions) programs as a sequence of convex programs. In machine learning  CCCP is extensively used in many learning algorithms like sparse support vector machines (SVMs)  transductive SVMs  sparse principal component analysis  etc. Though widely used in many applications  the convergence behavior of CCCP has not gotten a lot of specific attention. Yuille and Rangarajan analyzed its convergence in their original paper  however  we believe the analysis is not complete. Although the convergence of CCCP can be derived from the convergence of the d.c. algorithm (DCA)  their proof is more specialized and technical than actually required for the specific case of CCCP. In this paper  we follow a different reasoning and show how Zangwills global convergence theory of iterative algorithms provides a natural framework to prove the convergence of CCCP  allowing a more elegant and simple proof. This underlines Zangwills theory as a powerful and general framework to deal with the convergence issues of iterative algorithms  after also being used to prove the convergence of algorithms like expectation-maximization  generalized alternating minimization  etc. In this paper  we provide a rigorous analysis of the convergence of CCCP by addressing these questions: (i) When does CCCP find a local minimum or a stationary point of the d.c. program under consideration? (ii) When does the sequence generated by CCCP converge? We also present an open problem on the issue of local convergence of CCCP.,On the Convergence of the Concave-Convex

Procedure

Bharath K. Sriperumbudur

Department of Electrical and Computer Engineering

University of California  San Diego

La Jolla  CA 92093

bharathsv@ucsd.edu

Gert R. G. Lanckriet

Department of Electrical and Computer Engineering

University of California  San Diego

La Jolla  CA 92093

gert@ece.ucsd.edu

Abstract

The concave-convex procedure (CCCP) is a majorization-minimization algorithm
that solves d.c. (difference of convex functions) programs as a sequence of convex
programs. In machine learning  CCCP is extensively used in many learning algo-
rithms like sparse support vector machines (SVMs)  transductive SVMs  sparse
principal component analysis  etc. Though widely used in many applications  the
convergence behavior of CCCP has not gotten a lot of speciﬁc attention. Yuille and
Rangarajan analyzed its convergence in their original paper  however  we believe
the analysis is not complete. Although the convergence of CCCP can be derived
from the convergence of the d.c. algorithm (DCA)  its proof is more specialized
and technical than actually required for the speciﬁc case of CCCP. In this paper 
we follow a different reasoning and show how Zangwill’s global convergence the-
ory of iterative algorithms provides a natural framework to prove the convergence
of CCCP  allowing a more elegant and simple proof. This underlines Zangwill’s
theory as a powerful and general framework to deal with the convergence issues of
iterative algorithms  after also being used to prove the convergence of algorithms
like expectation-maximization  generalized alternating minimization  etc. In this
paper  we provide a rigorous analysis of the convergence of CCCP by addressing
these questions: (i) When does CCCP ﬁnd a local minimum or a stationary point
of the d.c. program under consideration? (ii) When does the sequence gener-
ated by CCCP converge? We also present an open problem on the issue of local
convergence of CCCP.

1 Introduction

The concave-convex procedure (CCCP) [30] is a majorization-minimization algorithm [15] that is
popularly used to solve d.c. (difference of convex functions) programs of the form 

min
x
s.t.

f(x)
ci(x) ≤ 0  i ∈ [m] 
dj(x) = 0  j ∈ [p] 

(1)
where f(x) = u(x) − v(x) with u  v and ci being real-valued convex functions  dj being an afﬁne
function  all deﬁned on Rn. Here  [m] := {1  . . .   m}. Suppose v is differentiable. The CCCP

1

algorithm is an iterative procedure that solves the following sequence of convex programs 

x(l+1) ∈ arg min
x
s.t.

u(x) − xT∇v(x(l))
ci(x) ≤ 0  i ∈ [m] 
dj(x) = 0  j ∈ [p].

(2)
As can be seen from (2)  the idea of CCCP is to linearize the concave part of f  which is −v 
around a solution obtained in the current iterate so that u(x) − xT∇v(x(l)) is convex in x  and
therefore the non-convex program in (1) is solved as a sequence of convex programs as shown in
(2). The original formulation of CCCP by Yuille and Rangarajan [30] deals with unconstrained
and linearly constrained problems. However  the same formulation can be extended to handle any
constraints (both convex and non-convex). CCCP has been extensively used in solving many non-
convex programs (of the form in (1)) that appear in machine learning. For example  [3] proposed a
successive linear approximation (SLA) algorithm for feature selection in support vector machines 
which can be seen as a special case of CCCP. Other applications where CCCP has been used include
sparse principal component analysis [27]  transductive SVMs [11  5  28]  feature selection in SVMs
[22]  structured estimation [10]  missing data problems in Gaussian processes and SVMs [26]  etc.
The algorithm in (2) starts at some random point x(0) ∈ {x : ci(x) ≤ 0  i ∈ [m]; dj(x) = 0  j ∈
[p]}  solves the program in (2) and therefore generates a sequence {x(l)}∞
l=0. The goal of this paper
is to study the convergence of {x(l)}∞
l=0: (i) When does CCCP ﬁnd a local minimum or a stationary
point1 of the program in (1)? (ii) Does {x(l)}∞
l=0 converge? If so  to what and under what conditions?
From a practical perspective  these questions are highly relevant  given that CCCP is widely applied
in machine learning.
In their original CCCP paper  Yuille and Rangarajan [30  Theorem 2] analyzed its convergence  but
we believe the analysis is not complete. They showed that {x(l)}∞
l=0 satisﬁes the monotonic descent
property  i.e.  f(x(l+1)) ≤ f(x(l)) and argued that this descent property ensures the convergence
of {x(l)}∞
l=0 to a minimum or saddle point of the program in (1). However  a rigorous proof is
not provided  to ensure that their claim holds for all u  v  {ci} and {dj}. Answering the previous
questions  however  requires a rigorous proof of the convergence of CCCP that explicitly mentions
the conditions under which it can happen.
In the d.c. programming literature  Pham Dinh and Hoai An [8] proposed a primal-dual subd-
ifferential method called DCA (d.c. algorithm) for solving a general d.c. program of the form
min{u(x) − v(x) : x ∈ Rn}  where it is assumed that u and v are proper lower semi-continuous
convex functions  which form a larger class of functions than the class of differentiable functions.
It can be shown that if v is differentiable  then DCA exactly reduces to CCCP. Unlike in CCCP 
DCA involves constructing two sets of convex programs (called the primal and dual programs) and
solving them iteratively in succession such that the solution of the primal is the initialization to the
dual and vice-versa. See [8] for details. [8  Theorem 3] proves the convergence of DCA for gen-
eral d.c. programs. The proof is specialized and technical. It fundamentally relies on d.c. duality 
however  outlining the proof in any more detail requires a substantial discussion which would lead
us too far here. In this work  we follow a fundamentally different approach and show that the con-
vergence of CCCP  speciﬁcally  can be analyzed in a more simple and elegant way  by relying on
Zangwill’s global convergence theory of iterative algorithms. We make some simple assumptions on
the functions involved in (1)  which are not too restrictive and therefore applicable to many practical
situations. The tools employed in our proof are of completely different ﬂavor than the ones used in
the proof of DCA convergence: DCA convergence analysis exploits d.c. duality while we use the
notion of point-to-set maps as introduced by Zangwill. Zangwill’s theory is a powerful and general
framework to deal with the convergence issues of iterative algorithms. It has also been used to prove
the convergence of the expectation-maximation (EM) algorithm [29]  generalized alternating mini-
mization algorithms [12]  multiplicative updates in non-negative quadratic programming [25]  etc.
and is therefore a natural framework to analyze the convergence of CCCP in a more direct way.
The paper is organized as follows. In Section 2  we provide a brief introduction to majorization-
minimization (MM) algorithms and show that CCCP is obtained as a particular form of majorization-
1x∗ is said to be a stationary point of a constrained optimization problem if it satisﬁes the corresponding
Karush-Kuhn-Tucker (KKT) conditions. Assuming constraint qualiﬁcation  KKT conditions are necessary for
the local optimality of x∗. See [2  Section 11.3] for details.

2

minimization. The goal of this section is also to establish the literature on MM algorithms and show
where CCCP ﬁts in it. In Section 3  we present Zangwill’s theory of global convergence  which is a
general framework to analyze the convergence behavior of iterative algorithms. This theory is used
to address the global convergence of CCCP in Section 4. This involves analyzing the ﬁxed points
of the CCCP algorithm in (2) and then showing that the ﬁxed points are the stationary points of the
program in (1). The results in Section 4 are extended in Section 4.1 to analyze the convergence of
the constrained concave-convex procedure that was proposed by [26] to deal with d.c. programs
with d.c. constraints. We brieﬂy discuss the local convergence issues of CCCP in Section 5 and
conclude the section with an open question.

2 Majorization-minimization

MM algorithms can be thought of as a generalization of the well-known EM algorithm [7]. The
general principle behind MM algorithms was ﬁrst enunciated by the numerical analysts  Ortega
and Rheinboldt [23] in the context of line search methods. The MM principle appears in many
places in statistical computation  including multidimensional scaling [6]  robust regression [14] 
correspondence analysis [13]  variable selection [16]  sparse signal recovery [4]  etc. We refer the
interested reader to a tutorial on MM algorithms [15] and the references therein.
The general idea of MM algorithms is as follows. Suppose we want to minimize f over Ω ⊂ Rn.
The idea is to construct a majorization function g over Ω × Ω such that

(cid:189)

f(x) ≤ g(x  y)  ∀ x  y ∈ Ω
f(x) = g(x  x)  ∀ x ∈ Ω .

(3)

Thus  g as a function of x is an upper bound on f and coincides with f at y. The majorization
algorithm corresponding with this majorization function g updates x at iteration l by

x(l+1) ∈ arg min
x∈Ω

g(x  x(l)) 

(4)
unless we already have x(l) ∈ arg minx∈Ω g(x  x(l))  in which case the algorithm stops. The ma-
jorization function  g is usually constructed by using Jensen’s inequality for convex functions  the
ﬁrst-order Taylor approximation or the quadratic upper bound principle [1]. However  any other
method can also be used to construct g as long as it satisﬁes (3). It is easy to show that the above
iterative scheme decreases the value of f monotonically in each iteration  i.e. 
f(x(l+1)) ≤ g(x(l+1)  x(l)) ≤ g(x(l)  x(l)) = f(x(l)) 

(5)
where the ﬁrst inequality and the last equality follow from (3) while the sandwiched inequality
follows from (4).
Note that MM algorithms can be applied equally well to the maximization of f by simply reversing
the inequality sign in (3) and changing the “min” to “max” in (4). In this case  the word MM refers to
minorization-maximization  where the function g is called the minorization function. To put things
in perspective  the EM algorithm can be obtained by constructing the minorization function g using
Jensen’s inequality for concave functions. The construction of such a g is referred to as the E-step 
while (4) with the “min” replaced by “max” is referred to as the M-step. The algorithm in (3) and
(4) is also referred to as the auxiliary function method  e.g.  for non-negative matrix factorization
[18]. [17] studied this algorithm under the name optimization transfer while [19] referred to it as
the SM algorithm  where “S” stands for the surrogate step (same as the majorization/minorization
step) and “M” stands for the minimization/maximization step depending on the problem at hand. g
is called the surrogate function. In the following example  we show that CCCP is an MM algorithm
for a particular choice of the majorization function  g.
Example 1 (Linear Majorization). Let us consider the optimization problem  minx∈Ω f(x) where
f = u − v  with u and v both real-valued  convex  deﬁned on Rn and v differentiable. Since v is
convex  we have v(x) ≥ v(y) + (x − y)T∇v(y)  ∀ x  y ∈ Ω. Therefore 

f(x) ≤ u(x) − v(y) − (x − y)T∇v(y) =: g(x  y).
It is easy to verify that g is a majorization function of f. Therefore  we have

x(l+1) ∈ arg min
x∈Ω
= arg min
x∈Ω

g(x  x(l))
u(x) − xT∇v(x(l)).

3

(6)

(7)

If Ω is a convex set  then the above procedure reduces to CCCP  which solves a sequence of convex
programs. As mentioned before  CCCP is proposed for unconstrained and linearly constrained
non-convex programs. This example shows that the same idea can be extended to any constraint set.
Suppose u and v are strictly convex  then a strict descent can be achieved in (5) unless x(l+1) = x(l) 
i.e.  if x(l+1) (cid:54)= x(l)  then

f(x(l+1)) < g(x(l+1)  x(l)) < g(x(l)  x(l)) = f(x(l)).

(8)

The ﬁrst strict inequality follows from (6). The strict convexity of u leads to the strict convexity of g
and therefore g(x(l+1)  x(l)) < g(x(l)  x(l)) unless x(l+1) = x(l).

3 Global convergence theory of iterative algorithms

For an iterative procedure like CCCP to be useful  it must converge to a local optimum or a stationary
point from all or at least a signiﬁcant number of initialization states and not exhibit other nonlinear
system behaviors  such as divergence or oscillation. This behavior can be analyzed by using the
global convergence theory of iterative algorithms developed by Zangwill [31]. Note that the word
“global convergence” is a misnomer. We will clarify it below and also introduce some notation and
terminology.
To understand the convergence of an iterative procedure like CCCP  we need to understand the
notion of a set-valued mapping  or point-to-set mapping  which is central to the theory of global
convergence.2 A point-to-set map Ψ from a set X into a set Y is deﬁned as Ψ : X → P(Y )  which
assigns a subset of Y to each point of X  where P(Y ) denotes the power set of Y . We introduce
few deﬁnitions related to the properties of point-to-set maps that will be used later. Suppose X and
Y are two topological spaces. A point-to-set map Ψ is said to be closed at x0 ∈ X if xk → x0
as k → ∞  xk ∈ X and yk → y0 as k → ∞  yk ∈ Ψ(xk)  imply y0 ∈ Ψ(x0). This concept of
closure generalizes the concept of continuity for ordinary point-to-point mappings. A point-to-set
map Ψ is said to be closed on S ⊂ X if it is closed at every point of S. A ﬁxed point of the map
Ψ : X → P(X) is a point x for which {x} = Ψ(x)  whereas a generalized ﬁxed point of Ψ is a
point for which x ∈ Ψ(x). Ψ is said to be uniformly compact on X if there exists a compact set H
independent of x such that Ψ(x) ⊂ H for all x ∈ X. Note that if X is compact  then Ψ is uniformly
compact on X. Let φ : X → R be a continuous function. Ψ is said to be monotonic with respect to
φ whenever y ∈ Ψ(x) implies that φ(y) ≤ φ(x). If  in addition  y ∈ Ψ(x) and φ(y) = φ(x) imply
that y = x  then we say that Ψ is strictly monotonic.
Many iterative algorithms in mathematical programming can be described using the notion of point-
to-set maps. Let X be a set and x0 ∈ X a given point. Then an algorithm  A  with initial point x0
is a point-to-set map A : X → P(X) which generates a sequence {xk}∞
k=1 via the rule xk+1 ∈
A(xk)  k = 0  1  . . .. A is said to be globally convergent if for any chosen initial point x0  the
sequence {xk}∞
k=0 generated by xk+1 ∈ A(xk) (or a subsequence) converges to a point for which a
necessary condition of optimality holds. The property of global convergence expresses  in a sense 
the certainty that the algorithm works. It is very important to stress the fact that it does not imply
(contrary to what the term might suggest) convergence to a global optimum for all initial points x0.
With the above mentioned concepts  we now state Zangwill’s global convergence theorem [31  Con-
vergence theorem A  page 91].
Theorem 2 ([31]). Let A : X → P(X) be a point-to-set map (an algorithm) that given a point
x0 ∈ X generates a sequence {xk}∞
k=0 through the iteration xk+1 ∈ A(xk). Also let a solution set
Γ ⊂ X be given. Suppose

(1) All points xk are in a compact set S ⊂ X.
(2) There is a continuous function φ : X → R such that:

(a) x /∈ Γ ⇒ φ(y) < φ(x)  ∀ y ∈ A(x) 

2Note that depending on the objective and constraints  the minimizer of the CCCP algorithm in (2) need
not be unique. Therefore  the algorithm takes x(l) as its input and returns a set of minimizers from which an
element  x(l+1) is chosen. Hence the notion of point-to-set maps appear naturally in such iterative algorithms.

4

(b) x ∈ Γ ⇒ φ(y) ≤ φ(x)  ∀ y ∈ A(x).

(3) A is closed at x if x /∈ Γ.

k=0 is in Γ. Furthermore  limk→∞ φ(xk) =

Then the limit of any convergent subsequence of {xk}∞
φ(x∗) for all limit points x∗.
The general idea in showing the global convergence of an algorithm  A is to invoke Theorem 2
by appropriately deﬁning φ and Γ. For an algorithm A that solves the minimization problem 
min{f(x) : x ∈ Ω}  the solution set  Γ is usually chosen to be the set of corresponding station-
ary points and φ can be chosen to be the objective function itself  i.e.  f  if f is continuous. In
Theorem 2  the convergence of φ(xk) to φ(x∗) does not automatically imply the convergence of xk
to x∗. However  if A is strictly monotone with respect to φ  then Theorem 2 can be strengthened by
using the following result due to Meyer [20  Theorem 3.1  Corollary 3.2].
Theorem 3 ([20]). Let A : X → P(X) be a point-to-set map such that A is uniformly compact 
closed and strictly monotone on X  where X is a closed subset of Rn. If {xk}∞
k=0 is any sequence
generated by A  then all limit points will be ﬁxed points of A  φ(xk) → φ(x∗) =: φ∗ as k → ∞ 
where x∗ is a ﬁxed point  (cid:107)xk+1 − xk(cid:107) → 0  and either {xk}∞
k=0 converges or the set of limit points
of {xk}∞
k=0 is connected. Deﬁne F (a) := {x ∈ F : φ(x) = a} where F is the set of ﬁxed points of
A. If F (φ∗) is ﬁnite  then any sequence {xk}∞
k=0 generated by A converges to some x∗ in F (φ∗).
Both these results just use basic facts of analysis and are simple to prove and understand. Using
these results on the global convergence of algorithms  [29] has studied the convergence properties
of the EM algorithm  while [12] analyzed the convergence of generalized alternating minimization
procedures. In the following section  we use these results to analyze the convergence of CCCP.

4 Convergence theorems for CCCP

Let us consider the CCCP algorithm in (2) pertaining to the d.c. program in (1). Let Acccp be the
point-to-set map  x(l+1) ∈ Acccp(x(l)) such that

Acccp(y) = arg min{u(x) − xT∇v(y) : x ∈ Ω} 

(9)
where Ω := {x : ci(x) ≤ 0  i ∈ [m]  dj(x) = 0  j ∈ [p]}. Let us assume that {ci} are dif-
ferentiable convex functions deﬁned on Rn. We now present the global convergence theorem for
CCCP.
Theorem 4 (Global convergence of CCCP−I). Let u and v be real-valued differentiable convex
functions deﬁned on Rn. Suppose ∇v is continuous. Let {x(l)}∞
l=0 be any sequence generated by
Acccp deﬁned by (9). Suppose Acccp is uniformly compact3 on Ω and Acccp(x) is nonempty for
any x ∈ Ω. Then  assuming suitable constraint qualiﬁcation  all the limit points of {x(l)}∞
l=0 are
stationary points of the d.c. program in (1). In addition liml→∞(u(x(l))−v(x(l))) = u(x∗)−v(x∗) 
where x∗ is some stationary point of Acccp.
Before we proceed with the proof of Theorem 4  we need a few additional results. The idea of the
proof is to show that any generalized ﬁxed point of Acccp is a stationary point of (1)  which is shown
below in Lemma 5  and then use Theorem 2 to analyze the generalized ﬁxed points.
Lemma 5. Suppose x∗ is a generalized ﬁxed point of Acccp and assume that constraints in (9) are
qualiﬁed at x∗. Then  x∗ is a stationary point of the program in (1).
Proof. We have x∗ ∈ Acccp(x∗) and the constraints in (9) are qualiﬁed at x∗. Then  there exists
i=1 ⊂ R+ and {µ∗
j}p
j=1 ⊂ R such that the following KKT conditions
Lagrange multipliers {η∗
hold:
i ∇ci(x∗) +
i=1 η∗
i ≥ 0  ci(x∗)η∗
i = 0  ∀ i ∈ [m]
j ∈ R  ∀ j ∈ [p].

 ∇u(x∗) − ∇v(x∗) +

ci(x∗) ≤ 0  η∗
dj(x∗) = 0  µ∗

j=1 µ∗

j∇dj(x∗) = 0 

(10) is exactly the KKT conditions of (1) which are satisﬁed by (x∗ {η∗
is a stationary point of (1).

j}) and therefore  x∗
3Assuming that for every x ∈ Ω  the set H(x) := {y : u(y) − u(x) ≤ v(y) − v(x)  y ∈ Acccp(Ω)} is

i } {µ∗

bounded is also sufﬁcient for the result to hold.

(10)

i }m

(cid:80)m

(cid:80)p

5

Before proving Theorem 4  we need a result to test the closure of Acccp. The following result from
[12  Proposition 7] shows that the minimization of a continuous function forms a closed point-to-set
map. A similar sufﬁcient condition is also provided in [29  Equation 10].
Lemma 6 ([12]). Given a real-valued continuous function h on X × Y   deﬁne the point-to-set map
Ψ : X → P(Y ) by

Ψ(x) = arg min
y(cid:48)∈Y

h(x  y(cid:48))

= {y : h(x  y) ≤ h(x  y(cid:48))  ∀ y(cid:48) ∈ Y }.

(11)

Then  Ψ is closed at x if Ψ(x) is nonempty.
We are now ready to prove Theorem 4.
Proof of Theorem 4. The assumption of Acccp being uniformly compact on Ω ensures that condition
(1) in Theorem 2 is satisﬁed. Let Γ be the set of all generalized ﬁxed points of Acccp and let
φ = f = u − v. Because of the descent property in (5)  condition (2) in Theorem 2 is satisﬁed. By
our assumption on u and v  we have g(x  y) = u(x) − v(y) − (x − y)T∇v(y) is continuous in x
and y. Therefore  by Lemma 6  the assumption of non-emptiness of Acccp(x) for any x ∈ Ω ensures
that Acccp is closed on Ω and so satisﬁes condition (3) in Theorem 2. Therefore  by Theorem 2 
all the limit points of {x(l)}∞
l=0 are the generalized ﬁxed points of Acccp and liml→∞(u(x(l)) −
v(x(l))) = u(x∗) − v(x∗)  where x∗ is some generalized ﬁxed point of Acccp. By Lemma 5  since
the generalized ﬁxed points of Acccp are stationary points of (1)  the result follows.
Remark 7. If Ω is compact  then Acccp is uniformly compact on Ω. In addition  since u is continuous
on Ω  by the Weierstrass theorem4 [21]  it is clear that Acccp(x) is nonempty for any x ∈ Ω and
therefore is also closed on Ω. This means  when Ω is compact  the result in Theorem 4 follows
trivially from Theorem 2.
In Theorem 4  we considered the generalized ﬁxed points of Acccp. The disadvantage with this
case is that it does not rule out “oscillatory” behavior [20]. To elaborate  we considered {x∗} ⊂
Acccp(x∗). For example  let Ω0 = {x1  x2} and let Acccp(x1) = Acccp(x2) = Ω0 and u(x1) −
v(x1) = u(x2) − v(x2) = 0. Then the sequence {x1  x2  x1  x2  . . .} could be generated by Acccp 
with the convergent subsequences converging to the generalized ﬁxed points x1 and x2. Such an
oscillatory behavior can be avoided if we allow Acccp to have ﬁxed points instead of generalized
ﬁxed points. With appropriate assumptions on u and v  the following stronger result can be obtained
on the convergence of CCCP through Theorem 3.
Theorem 8 (Global convergence of CCCP−II). Let u and v be strictly convex  differentiable func-
tions deﬁned on Rn. Also assume ∇v be continuous. Let {x(l)}∞
l=0 be any sequence generated by
Acccp deﬁned by (9). Suppose Acccp is uniformly compact on Ω and Acccp(x) is nonempty for
any x ∈ Ω. Then  assuming suitable constraint qualiﬁcation  all the limit points of {x(l)}∞
are stationary points of the d.c. program in (1)  u(x(l)) − v(x(l)) → u(x∗) − v(x∗) =: f∗
as l → ∞  for some stationary point x∗  (cid:107)x(l+1) − x(l)(cid:107) → 0  and either {x(l)}∞
l=0 con-
verges or the set of limit points of {x(l)}∞
l=0 is a connected and compact subset of S (f∗)  where
S (a) := {x ∈ S : u(x) − v(x) = a} and S is the set of stationary points of (1). If S (f∗) is
ﬁnite  then any sequence {x(l)}∞
Proof. Since u and v are strictly convex  the strict descent property in (8) holds and therefore Acccp
is strictly monotonic with respect to f. Under the assumptions made about Acccp  Theorem 3 can
be invoked  which says that all the limit points of {x(l)}∞
l=0 are ﬁxed points of Acccp  which either
converge or form a connected compact set. From Lemma 5  the set of ﬁxed points of Acccp are
already in the set of stationary points of (1) and the desired result follows from Theorem 3.
Theorems 4 and 8 answer the questions that we raised in Section 1. These results explicitly provide
sufﬁcient conditions on u  v  {ci} and {dj} under which the CCCP algorithm ﬁnds a stationary point
of (1) along with the convergence of the sequence generated by the algorithm. From Theorem 8  it
should be clear that convergence of f(x(l)) to f∗ does not automatically imply the convergence of
x(l) to x∗. The convergence in the latter sense requires more stringent conditions like the ﬁniteness
of the set of stationary points of (1) that assume the value of f∗.

l=0 generated by Acccp converges to some x∗ in S (f∗).

l=0

4Weierstrass theorem states: If f is a real continuous function on a compact set K ⊂ Rn  then the problem

min{f (x) : x ∈ K} has an optimal solution x∗ ∈ K.

6

4.1 Extensions

So far  we have considered d.c. programs where the constraint set is convex. Let us consider a
general d.c. program given by

min
x
s.t.

u0(x) − v0(x)
ui(x) − vi(x) ≤ 0  i ∈ [m] 

(12)
where {ui}  {vi} are real-valued convex and differentiable functions deﬁned on Rn. While dealing
with kernel methods for missing variables  [26] encountered a problem of the form in (12) for which
they proposed a constrained concave-convex procedure given by

x(l+1) ∈ arg min
x
s.t.

u0(x) − (cid:98)v0(x; x(l))
ui(x) −(cid:98)vi(x; x(l)) ≤ 0  i ∈ [m] 

(13)

where (cid:98)vi(x; x(l)) := vi(x(l)) + (x − x(l))T∇vi(x(l)). Note that  similar to CCCP  the algorithm

l=0 is assumed.

in (13) is a sequence of convex programs. Though [26  Theorem 1] have provided a convergence
analysis for the algorithm in (13)  it is however not complete due to the fact that the convergence
of {x(l)}∞
In this subsection  we provide its convergence analysis  following an
approach similar to what we did for CCCP by considering a point-to-set map  Bccp associated with
the iterative algorithm in (13)  where x(l+1) ∈ Bccp(x(l)). In Theorem 10  we provide the global
convergence result for the constrained concave-convex procedure  which is an equivalent version of
Theorem 4 for CCCP. We do not provide the stronger version of the result as in Theorem 8 as it can
be obtained by assuming strict convexity of u0 and v0. Before proving Theorem 10  we need an
equivalent version of Lemma 5 which we provide below.
Lemma 9. Suppose x∗ is a generalized ﬁxed point of Bccp and assume that constraints in (13) are
qualiﬁed at x∗. Then  x∗ is a stationary point of the program in (12).
Proof. Based on the assumptions x∗ ∈ Bccp(x∗) and the constraint qualiﬁcation at x∗ in (13) 
there exist Lagrange multipliers {η∗
i=1 ⊂ R+ (for simplicity  we assume all the constraints to be
inequality constraints) such that the following KKT conditions hold:

i }m

(cid:80)m

 ∇u0(x∗) +

i=1 η∗
ui(x∗) − vi(x∗) ≤ 0  η∗
(ui(x∗) − vi(x∗))η∗

i (∇ui(x∗) − ∇vi(x∗)) = ∇v0(x∗) 
i = 0  i ∈ [m].

i ≥ 0  i ∈ [m] 

(14)

i }) and therefore  x∗ is a stationary

which is exactly the KKT conditions for (12) satisﬁed by (x∗ {η∗
point of (12).
Theorem 10 (Global convergence of constrained CCP). Let {ui}  {vi} be real-valued differentiable
convex functions on Rn. Assume ∇v0 to be continuous. Let {x(l)}∞
l=0 be any sequence generated
by Bccp deﬁned in (13). Suppose Bccp is uniformly compact on Ω := {x : ui(x) − vi(x) ≤ 0  i ∈
[m]} and Bccp(x) is nonempty for any x ∈ Ω. Then  assuming suitable constraint qualiﬁcation 
all the limit points of {x(l)}∞
In addition
liml→∞(u0(x(l)) − v0(x(l))) = u0(x∗) − v0(x∗)  where x∗ is some stationary point of Bccp.
Proof. The proof is very similar to that of Theorem 4 wherein we check whether Bccp satisﬁes the
conditions of Theorem 2 and then invoke Lemma 9. The assumptions mentioned in the statement
of the theorem ensure that conditions (1) and (3) in Theorem 2 are satisﬁed. [26  Theorem 1] has
proved the descent property  similar to that of (5)  which simply follows from the linear majorization
idea and therefore the descent property in condition (2) of Theorem 2 holds. Therefore  the result
follows from Theorem 2 and Lemma 9.

l=0 are stationary points of the d.c. program in (12).

5 On the local convergence of CCCP: An open problem

The study so far has been devoted to the global convergence analysis of CCCP and the constrained
concave-convex procedure. As mentioned before  we say an algorithm is globally convergent if for
k=0 generated by xk+1 ∈ A(xk) converges to a
any chosen starting point  x0  the sequence {xk}∞
point for which a necessary condition of optimality holds. In the results so far  we have shown

7

that all the limit points of any sequence generated by CCCP (resp. its constrained version) are the
stationary points (local extrema or saddle points) of the program in (1) (resp. (12)). Suppose  if
x0 is chosen such that it lies in an -neighborhood around a local minima  x∗  then will the CCCP
sequence converge to x∗? If so  what is the rate of convergence? This is the question of local
convergence that needs to be addressed.
[24] has studied the local convergence of bound optimization algorithms (of which CCCP is an
example) to compare the rate of convergence of such methods to that of gradient and second-order
methods. In their work  they considered the unconstrained version of CCCP with Acccp to be a point-
to-point map that is differentiable. They showed that depending on the curvature of u and v  CCCP
will exhibit either quasi-Newton behavior with fast  typically superlinear convergence or extremely
slow  ﬁrst-order convergence behavior. However  extending these results to the constrained setup as
in (2) is not obvious. The following result due to Ostrowski which can be found in [23  Theorem
10.1.3] provides a way to study the local convergence of iterative algorithms.
Proposition 11 (Ostrowski). Suppose that Ψ : U ⊂ Rn → Rn has a ﬁxed point x∗ ∈ int(U) and
Ψ is Fr´echet-differentiable at x∗. If the spectral radius of Ψ(cid:48)(x∗) satisﬁes ρ(Ψ(cid:48)(x∗)) < 1  and if x0
is sufﬁciently close to x∗  then the iterates {xk} deﬁned by xk+1 = Ψ(xk) all lie in U and converge
to x∗.
Few remarks are in place regarding the usage of Proposition 11 to study the local convergence of
CCCP. Note that Proposition 11 treats Ψ as a point-to-point map which can be obtained by choosing
u and v to be strictly convex so that x(l+1) is the unique minimizer of (2). x∗ in Proposition 11
can be chosen to be a local minimum. Therefore  the desired result of local convergence with at
least linear rate of convergence is obtained if we show that ρ(Ψ(cid:48)(x∗)) < 1. However  currently we
are not aware of a way to compute the differential of Ψ and  moreover  to impose conditions on the
functions in (2) so that Ψ is a differentiable map. This is an open question coming out of this work.
On the other hand  the local convergence behavior of DCA has been proved for two important classes
of d.c. programs: (i) the trust region subproblem [9] (minimization of a quadratic function over a
Euclidean ball) and (ii) nonconvex quadratic programs [8]. We are not aware of local optimality
results for general d.c. programs using DCA.

6 Conclusion & Discussion

The concave-convex procedure (CCCP) is widely used in machine learning. In this work  we analyze
its global convergence behavior by using results from the global convergence theory of iterative
algorithms. We explicitly mention the conditions under which any sequence generated by CCCP
converges to a stationary point of a d.c. program with convex constraints. The proposed approach
allows an elegant and direct proof and is fundamentally different from the highly technical proof
for the convergence of DCA  which implies convergence for CCCP. It illustrates the power and
generality of Zangwill’s global convergence theory as a framework for proving the convergence of
iterative algorithms. We also brieﬂy discuss the local convergence of CCCP and present an open
question  the settlement of which would address the local convergence behavior of CCCP.

Acknowledgments

The authors thank anonymous reviewers for their constructive comments. They wish to acknowl-
edge support from the National Science Foundation (grant DMS-MSPA 0625409)  the Fair Isaac
Corporation and the University of California MICRO program.

References
[1] D. B¨ohning and B. G. Lindsay. Monotonicity of quadratic-approximation algorithms. Annals of the

Institute of Statistical Mathematics  40(4):641–663  1988.

[2] J. F. Bonnans  J. C. Gilbert  C. Lemar´echal  and C. A. Sagastiz´abal. Numerical Optimization: Theoretical

and Practical Aspects. Springer-Verlag  2006.

[3] P. S. Bradley and O. L. Mangasarian. Feature selection via concave minimization and support vector
machines. In Proc. 15th International Conf. on Machine Learning  pages 82–90. Morgan Kaufmann  San
Francisco  CA  1998.

8

[4] E. J. Candes  M. Wakin  and S. Boyd. Enhancing sparsity by reweighted (cid:96)1 minimization. J. Fourier

Anal. Appl.  2007. To appear.

[5] R. Collobert  F. Sinz  J. Weston  and L. Bottou. Large scale transductive SVMs. Journal of Machine

Learning Research  7:1687–1712  2006.

[6] J. deLeeuw. Applications of convex analysis to multidimensional scaling. In J. R. Barra  F. Brodeau 
G. Romier  and B. Van Cutsem  editors  Recent advantages in Statistics  pages 133–146  Amsterdam  The
Netherlands  1977. North Holland Publishing Company.

[7] A. P. Dempster  N. M. Laird  and D. B. Rubin. Maximum likelihood from incomplete data via the EM

algorithm. J. Roy. Stat. Soc. B  39:1–38  1977.

[8] T. Pham Dinh and L. T. Hoai An. Convex analysis approach to d.c. programming: Theory  algorithms

and applications. Acta Mathematica Vietnamica  22(1):289–355  1997.

[9] T. Pham Dinh and L. T. Hoai An. D.c. optimization algorithms for solving the trust region subproblem.

SIAM Journal of Optimization  8:476–505  1998.

[10] C. B. Do  Q. V. Le  C. H. Teo  O. Chapelle  and A. J. Smola. Tighter bounds for structured estimation. In

Advances in Neural Information Processing Systems 21  2009. To appear.

[11] G. Fung and O. L. Mangasarian. Semi-supervised support vector machines for unlabeled data classiﬁca-

tion. Optimization Methods and Software  15:29–44  2001.

[12] A. Gunawardana and W. Byrne. Convergence theorems for generalized alternating minimization proce-

dures. Journal of Machine Learning Research  6:2049–2073  2005.

[13] W. J. Heiser. Correspondence analysis with least absolute residuals. Comput. Stat. Data Analysis  5:337–

356  1987.

[14] P. J. Huber. Robust Statistics. John Wiley  New York  1981.
[15] D. R. Hunter and K. Lange. A tutorial on MM algorithms. The American Statistician  58:30–37  2004.
[16] D. R. Hunter and R. Li. Variable selection using MM algorithms. Annals of Statistics  33:1617–1642 

2005.

[17] K. Lange  D. R. Hunter  and I. Yang. Optimization transfer using surrogate objective functions with

discussion. Journal of Computational and Graphical Statistics  9(1):1–59  2000.

[18] D. D. Lee and H. S. Seung. Algorithms for non-negative matrix factorization. In T.K. Leen  T.G. Di-
etterich  and V. Tresp  editors  Advances in Neural Information Processing Systems 13  pages 556–562.
MIT Press  Cambridge  2001.

[19] X.-L. Meng. Discussion on “optimization transfer using surrogate objective functions”. Journal of Com-

putational and Graphical Statistics  9(1):35–43  2000.

[20] R. R. Meyer. Sufﬁcient conditions for the convergence of monotonic mathematical programming algo-

rithms. Journal of Computer and System Sciences  12:108–121  1976.

[21] M. Minoux. Mathematical Programming: Theory and Algorithms. John Wiley & Sons Ltd.  1986.
[22] J. Neumann  C. Schn¨orr  and G. Steidl. Combined SVM-based feature selection and classiﬁcation. Ma-

chine Learning  61:129–150  2005.

[23] J. M. Ortega and W. C. Rheinboldt.

Academic Press  New York  1970.

Iterative Solution of Nonlinear Equations in Several Variables.

[24] R. Salakhutdinov  S. Roweis  and Z. Ghahramani. On the convergence of bound optimization algorithms.

In Proc. 19th Conference in Uncertainty in Artiﬁcial Intelligence  pages 509–516  2003.

[25] F. Sha  Y. Lin  L. K. Saul  and D. D. Lee. Multiplicative updates for nonnegative quadratic programming.

Neural Computation  19:2004–2031  2007.

[26] A. J. Smola  S. V. N. Vishwanathan  and T. Hofmann. Kernel methods for missing variables. In Proc. of

the Tenth International Workshop on Artiﬁcial Intelligence and Statistics  2005.

[27] B. K. Sriperumbudur  D. A. Torres  and G. R. G. Lanckriet. Sparse eigen methods by d.c. programming.

In Proc. of the 24th Annual International Conference on Machine Learning  2007.

[28] L. Wang  X. Shen  and W. Pan. On transductive support vector machines. In J. Verducci  X. Shen  and

J. Lafferty  editors  Prediction and Discovery. American Mathematical Society  2007.

[29] C. F. J. Wu. On the convergence properties of the EM algorithm. Annals of Statistics  11(1):95–103 

1983.

[30] A. L. Yuille and A. Rangarajan. The concave-convex procedure. Neural Computation  15:915–936  2003.
[31] W. I. Zangwill. Nonlinear Programming: A Uniﬁed Approach. Prentice-Hall  Englewood Cliffs  N.J. 

1969.

9

,Francesca Petralia
Joshua Vogelstein
David Dunson
Emmanuel Abbe
Sanjeev Kulkarni
Eun Jee Lee
Mikhail Yurochkin
Sebastian Claici
Edward Chien
Farzaneh Mirzazadeh
Justin Solomon