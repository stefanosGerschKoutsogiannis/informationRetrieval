2009,Matrix Completion from Power-Law Distributed Samples,The low-rank matrix completion problem is a fundamental problem with many important applications. Recently  Candes & Recht  Keshavan et al. and Candes & Tao obtained the first non-trivial theoretical results for the problem assuming that the observed entries are sampled uniformly at random. Unfortunately  most real-world datasets do not satisfy this assumption  but instead exhibit power-law distributed samples. In this paper  we propose a graph theoretic approach to matrix completion that solves the problem for more realistic sampling models. Our method is easier to analyze than previous methods with the analysis reducing to computing the threshold for complete cascades in random graphs  a problem of independent interest. By analyzing the graph theoretic problem  we show that our method achieves exact recovery when the observed entries are sampled from the Chung-Lu-Vu model  which can generate power-law distributed graphs. We also hypothesize that our algorithm solves the matrix completion problem from an optimal number of entries for the popular preferential attachment model and provide strong empirical evidence for the claim. Furthermore  our method is easier to implement and is substantially faster than existing methods. We demonstrate the effectiveness of our method on examples when the low-rank matrix is sampled according to the prevalent random graph models for complex networks and also on the Netflix challenge dataset.,Matrix Completion from Power-Law Distributed

Samples

Raghu Meka  Prateek Jain  and Inderjit S. Dhillon

Department of Computer Sciences

University of Texas at Austin

Austin  TX 78712

{raghu pjain inderjit}@cs.utexas.edu

Abstract

The low-rank matrix completion problem is a fundamental problem with many
important applications. Recently  [4] [13] and [5] obtained the ﬁrst non-trivial
theoretical results for the problem assuming that the observed entries are sampled
uniformly at random. Unfortunately  most real-world datasets do not satisfy this
assumption  but instead exhibit power-law distributed samples. In this paper  we
propose a graph theoretic approach to matrix completion that solves the problem
for more realistic sampling models. Our method is simpler to analyze than previ-
ous methods with the analysis reducing to computing the threshold for complete
cascades in random graphs  a problem of independent interest. By analyzing the
graph theoretic problem  we show that our method achieves exact recovery when
the observed entries are sampled from the Chung-Lu-Vu model  which can gener-
ate power-law distributed graphs. We also hypothesize that our algorithm solves
the matrix completion problem from an optimal number of entries for the popu-
lar preferential attachment model and provide strong empirical evidence for the
claim. Furthermore  our method is easy to implement and is substantially faster
than existing methods. We demonstrate the effectiveness of our method on ran-
dom instances where the low-rank matrix is sampled according to the prevalent
random graph models for complex networks and present promising preliminary
results on the Netﬂix challenge dataset.

Introduction

1
Completing a matrix from a few given entries is a fundamental problem with many applications in
machine learning  statistics  and compressed sensing. Since completion of arbitrary matrices is not
a well-posed problem  it is often assumed that the underlying matrix comes from a restricted class.
Here we address the matrix completion problem under the natural assumption that the underlying
matrix is low-rank.
Formally  for an unknown matrix M ∈ Rm×n of rank at most k  given Ω ⊆ [m] × [n]  PΩ(M )1 and
k  the low-rank matrix completion problem is to ﬁnd a matrix X ∈ Rm×n such that

rank(X) ≤ k

and PΩ(X) = PΩ(M ).

(1.1)

Recently Candes and Recht [4]  Keshavan et.al [13]  Candes and Tao [5] obtained the ﬁrst non-trivial
guarantees for the above problem under a few additional assumptions on the matrix M and the set of
known entries Ω. At a high level  the assumptions made in the above papers can be stated as follows.
A1 M is incoherent  in the sense that the singular vectors of M are not correlated with the

standard basis vectors.

1Throughout this paper PΩ : Rm×n → Rm×n will denote the projection of a matrix onto the pairs of

indices in Ω: (PΩ(X))ij = Xij for (i  j) ∈ Ω and (PΩ(X))ij = 0 otherwise.

1

A2 The observed entries are sampled uniformly at random.

In this work we address some of the issues with assumption [A2]. For Ω ⊆ [m]×[n]  let the sampling
graph GΩ = (U  V  Ω) be the bipartite graph with vertices U = {u1  . . .   um}  V = {v1  . . .   vn}
and edges given by the ordered pairs in Ω 2. Then  assumption [A2] can be reformulated as follows:

A3 The sampling graph GΩ is an Erd˝os-R´enyi random graph3.

A prominent feature of Erd˝os-R´enyi graphs is that the degrees of vertices are Poisson distributed and
are sharply concentrated about their mean. The techniques of [4  5]  [13]  as will be explained later 
crucially rely on these properties of Erd˝os-R´enyi graphs. However  for most large real-world graphs
such as the World Wide Web ([1])  the degree distribution deviates signiﬁcantly from the Poisson
distribution and has high variance. In particular  most large matrix-completion datasets such as the
much publicized Netﬂix prize dataset and the Yahoo Music dataset exhibit power-law distributed
degrees  i.e.  the number of vertices of degree d is proportional to d−β for a constant β (Figure 1).
In this paper  we overcome some of the shortcomings of assumption [A3] above by considering
more realistic random graph models for the sampling graph GΩ. We propose a natural graph theo-
retic approach for matrix completion (referred to as ICMC for informationcascadingmatrixcomple-
tion) that we prove can handle sampling graphs with power-law distributed degrees. Our approach
is motivated by the models for information cascading in social networks proposed by Kempe et
al. [11  12]. Moreover  the analysis of ICMC reduces to the problem of ﬁnding density thresholds
for completecascadesin random graphs - a problem of independent interest.

By analyzing the threshold for complete cascades in the random graph model of Chung  Lu & Vu
[6] (CLV model)  we show that ICMC solves the matrix completion problem for sampling graphs
drawn from the CLV model. The bounds we obtain for matrix-completion on the CLV model are
incomparable to the main results of [4  5  13]. The methods of the latter papers do not apply to
models such as the CLV model that generate graphs with skewed degrees. On the other hand  for
Erdos-Renyi graphs the density requirements for ICMC are stronger than those of the above papers.

We also empirically investigate the threshold for complete cascading in other popular random graph
models such as the preferential attachment model [1]  the forest-ﬁre model [17] and the afﬁliation
networks model [16]. The empirical estimates we obtain for the threshold for complete cascading
in the preferential attachment model strongly suggest that ICMC solves the exact matrix-completion
problem from an optimal number of entries for sampling procedures with preferential attachment.

Our experiments demonstrate that for sampling graphs drawn from more realistic models such as
the preferential attachment  forest-ﬁre and afﬁliation network models  ICMC outperforms - both in
accuracy and time - the methods of [4  5  3  13] by an order of magnitude.

In summary  our main contributions are:
• We formulate the sampling process in matrix completion as generating random graphs (GΩ) and

demonstrate that the sampling assumption [A3] does not hold for real-world datasets.

• We propose a novel graph theoretic approach to matrix completion (ICMC) that extensively uses
the link structure of the sampling graph. We emphasize that previously none of the methods
exploited the structure of the sampling graph.

• We prove that our method solves the matrix completion problem exactly for sampling graphs

generated from the CLV model which can generate power-law distributed graphs.

• We empirically evaluate our method on more complex random graph models and on the Netﬂix

Challenge dataset demonstrating the effectiveness of our method over those of [4  5  3  13].

2 Previous Work and Preliminaries

The Netﬂix challenge has recently drawn much attention to the low-rank matrix completion prob-
lem. Most methods for matrix completion and the more general rank minimization problem with
afﬁne constraints are based on either relaxing the non-convex rank function to a convex function
or assuming a factorization of the matrix and optimizing the resulting non-convex problem using
alternating minimization and its variants [2  15  18].

2We will often abuse notation and identify edges (ui  vj) with ordered pairs (i  j).
3We consider the Erd˝os-R´enyi model  where edges (ui  vj) ∈ E independently with probability for p for

(i  j) ∈ [m] × [n] and p is the density parameter.

2

Until recently  most methods for rank minimization subject to afﬁne constraints were heuristic in
nature with few known rigorous guarantees. In a recent breakthrough  Recht et.al [20] extend the
techniques of compressed sensing to rank minimization with afﬁne constraints. However  the results
of Recht et.al do not apply to the case of matrix completion as the constraints in matrix completion
do not satisfy the restrictedisoperimetrypropertythey assume.

Building on the work of Recht et al. [20]  Candes and Recht [4] and Candes and Tao [5] showed that
minimizing the trace-norm recovers the unknown low-rank matrix exactly under certain conditions.
However  these approaches require the observed entries to be sampled uniformly at random and as
suggested by our experiments  do not work well when the observed entries are not drawn uniformly.

Independent of [4  5]  Keshavan et al. [13] also obtained similar results for matrix completion using
different techniques that generalize the works of Friedman et al. [9]  Feige and Ofek [8] on the
spectrum of random graphs. However  the results of [13]  crucially rely on the regularity of Erd˝os-
R´enyi graphs and do not extend to sampling graphs with skewed degree distributions even for rank
one matrices. This is mainly because the results of Friedman et al. and Feige and Ofek on the
spectralgapof Erd˝os-R´enyi graphs do not hold for graph models with skewed expected degrees (see
[6  19]).

We also remark that several natural variants of the trimming phase of [8] and [13] did not improve
the performance in our experiments. A similar observation was made in [19]  [10] who address the
problem of re-weighting the edges of graphs with skewed degrees in the context of LSA.

2.1 Random Graph Models
We focus on four popular models of random graphs all of which can generate graphs with power-law
distributed degrees. In contrast to the common descriptions of the models  we need to work with
bipartite graphs; however  the models we consider generalize naturally to bipartite graphs. Due to
space limitations we only give a (brief) description of the Chung et.al [6]  and refer to the original
papers for the preferential attachment [1]  forest-ﬁre [17] and afﬁliation networks [16] models.

[6] generates graphs with arbitrary expected degree sequences  p1  . . .   pm 
The CLV model
q1  . . .   qn with p1 + . . . + pm = q1 + . . . + qn = w. In the model  a bipartite graph G = (U  V  E)
with U = {u1  . . .   um}  V = {v1  . . .   vn} is generated by independently placing an edge between
vertices ui  vj with probability piqj/w for all i ∈ [m]  j ∈ [n]. We deﬁne the densityof an instance
of CLV model to be the expected average degree (p1 + . . . + pm)/(mn) = w/mn.
The CLV model is more general than the standard Erd˝os-R´enyi model with the case pi = np  qi =
mp corresponding to the standard Erd˝os-R´enyi model with density p for bipartite random graphs.
Further  by choosing weights that are power-law distributed  the CLV model can generate graphs
with power-law distributed degrees  a prominent feature of real-world graphs.

3 Matrix Completion from Information Cascading
We now present our algorithm ICMC. Consider the following standard formulation of the low-rank
matrix completion problem: Given k  Ω  PΩ(M ) for a rank k matrix M  ﬁnd X  Y such that

PΩ(XY T ) = PΩ(M )  X ∈ Rm×k  Y ∈ Rn×k.

(3.1)
Note that given X we can ﬁnd Y and vice versa by solving a linear least squares regression prob-
lem. This observation is the basis for the popular alternate minimization heuristic and its variants
which outperform most methods in practice. However  analyzing the performance of alternate min-
imization is a notoriously hard problem. Our algorithm can be seen as a more reﬁned version of the
alternate minimization heuristic that is more amenable to analysis. We assume that the target matrix
M is non-degenerate in the following sense.
Deﬁnition 3.1 A rank k matrix Z is non-degenerate if there exist X ∈ Rm×k  Y ∈ Rn×k 
Z = XY T such that any k rows of X are linearly independent and any k rows of Y are linearly
independent.
Though reminiscent of the incoherence property used by Candes and Recht  Keshavan et al.  non-
degeneracy appears to be incomparable to the incoherence property used in the above works. Ob-
serve that a random low-rank matrix is almost surely non-degenerate.
Our method progressively computes rows of X and Y so that Equation (3.1) is satisﬁed. Call a
vertex ui ∈ U as infectedif the i’th row of X has been computed (the term infected is used to reﬂect

3

that infection spreads by contact as in an epidemic). Similarly  call a vertex vj ∈ V as infected if
the j’th row of Y has been computed. Suppose that at an intermediate iteration  vertices L ⊆ U and
R ⊆ V are marked as infected. That is  the rows of X with indices in L and rows of Y with indices
in R have been computed exactly.
j ∈ Rk  we only need k
Now  for an uninfected j ∈ [n]  to compute the corresponding row of Y   y
T
independent linear equations. Thus  if M is non-degenerate  to compute y
j we only need k entries
T
of the j’th column of M with row indices in L. Casting the condition in terms of the sampling graph
GΩ  y
j can be computed and vertex vj ∈ V be marked as infected if there are at least k edges from
T
vj to infected vertices in L. Analogously  x
i can be computed and the vertex ui ∈ U be marked as
T
infected if there are at least k edges from ui to previously infected vertices R.
Observe that M = XY T = XW W −1Y T   for any invertible matrix W ∈ Rk×k. Thus for non-
degenerate M  without loss of generality  a set of k rows of X can be ﬁxed to be the k × k identity
matrix Ik. This suggests the following cascading procedure for infecting vertices in GΩ and pro-
gressively computing the rows of X  Y . Here L0 ⊆ U with |L0| = k.

ICMC(GΩ  PΩ(M )  L0):
1 Start with initially infected sets L = L0 ⊆ U  R = ∅. Set the k × k sub-matrix of X with rows

in L0 to be Ik.

2 Repeat until convergence:

(a) Mark as infected all uninfected vertices in V that have at least k edges to previously infected

vertices L and add the newly infected vertices to R.

(b) For each newly infected vertex vj ∈ R  compute the j’th row of Y using the observed

entries of M corresponding to edges from vj to L.

(c) Mark as infected all uninfected vertices in U that have at least k edges to previously infected

vertices R and add the newly infected vertices to L.

(d) For each newly infected vertex ui ∈ L  compute the i’th row of X using the observed

entries of M corresponding to edges from ui to R

3 Output M ′ = XY T .

We abstract the cascading procedure from above using the framework of Kempe et al. [11] for
information cascades in social networks. Let G = (W  E) be an undirected graph and ﬁx A ⊆ W  
k > 0. Deﬁne σG k(A  0) = A and for t > 0 deﬁne σG k(A  t + 1) inductively by

σG k(A  t + 1) = σG k(A  t) ∪ {u ∈ W : u has at least k edges to σG k(A  t) }.

Deﬁnition 3.2 The inﬂuence of a set A ⊆ W   σG k(A)  is the number of vertices infected by the
cascading process upon termination when starting at A. That is  σG k(A) = | ∪t σG k(A  t)|. We
say A is completelycascadingof order k if σG k(A) = |W |.

We remark that using a variant of the standard depth-ﬁrst search algorithm  the cascading process
above can be computed in linear time for any set A. From the discussion preceding ICMC it follows
that ICMC recovers M exactly if the cascading process starting at L0 infects all vertices of GΩ and
we get the following theorem.

Theorem 3.1 Let M be a non-degenerate matrix of rank k. Then  given GΩ = (U  V  Ω)  PΩ(M )
and L0 ⊆ U with |L0| = k  ICMC(GΩ  PΩ(M )  L0) recovers the matrix M exactly if L0 is a
completely cascading set of order k in GΩ.

Thus  we have reduced the matrix-completion problem to the graph-theoretic problem of ﬁnding
a completely cascading set (if it exists) in a graph. A more general case of the problem – ﬁnding
a set of vertices that maximize inﬂuence  was studied by Kempe et al. [11] for more general cas-
cading processes. They show the general problem of maximizing inﬂuence to be NP-hard and give
approximation algorithms for several classes of instances.

However  it appears that for most reasonable random graph models  the highest degree vertices have
large inﬂuence with high probability.
In the following we investigate completely cascading sets
in random graphs and show that for CLV graphs  the k highest degree vertices form a completely
cascading set with high probability.

4

Information Cascading in Random Graphs

4
We now show that for sufﬁciently dense CLV graphs and ﬁxed k  the k highest degree vertices form
a completely cascading set with high probability.

Theorem 4.1 For every γ > 0  there exists a constant c(γ) such that the following holds. Con-
sider an instance of the CLV model given by weights p1  . . .   pm  q1  . . .   qn with density p and
min(pi  qj) ≥ c(γ)k log n/pk. Then  for G = (U  V  E) generated from the model  the k highest
degree vertices of U form a completely cascading set of order k with probability at least 1 − n−γ.

Proof sketch We will show that the highest weight vertices L0 = {u1  . . .   uk} form a completely
cascading set with high probability; the theorem follows from the above statement and the observa-
tion that the highest degree vertices of G will almost surely correspond to vertices with large weights

in the model; we omit these details for lack of space. Let w = Pi pi = Pj qj = mnp and m ≤ n.
Fix a vertex ui /∈ L0 and consider an arbitrary vertex vj ∈ V . Let P i
j be the indicator variable
that is 1 if (ui  vj) ∈ E and vj is connected to all vertices of L0. Note that vertex ui will be
j = 1] =

j ≥ k. Now  Pr[P i

infected after two rounds by the cascading process starting at L0 ifPj P i
(piqj/w)Q1≤l≤k(plqj/w) and
1 + . . . + P i

E[P i

piqj

pi

=

n

n] =

Xj=1

w Yl≤k

plqj
w

wk+1 · ( Y1≤l≤k

pl) ·

n

Xj=1

qk+1
j

.

(4.1)

Observe that Pi pi = w ≤ nk + pk(m − k). Thus  pk ≥ (w − nk)/(m − k). Now  using the

power-mean inequality we get 

1 + qk+1
qk+1

2 + . . . + qk+1

n ≥ nµ q1 + . . . + qn

n

¶k+1

= n ·³ w

n´k+1

 

with equality occurring only if qj = w/n for all j. From Equations (4.1)  (4.2) we have

E[P i

1 + . . . + P i

m − k ¶k
n] ≥ pi ·µ w − nk
w ¶k
= pi ·µ1 −

nk

·

1
nk

·µ1 −

k

m¶−k

mn´k
·³ w

.

(4.2)

(4.3)

1 + . . . + P i

It is easy to check that under our assumptions  w ≥ nk2 and m ≥ k2. Thus  (1 − nk/w)k ≥ 1/e
and (1 − k/m)−k ≥ 1/2e. From Equation (4.3) and our assumption pi ≥ c(γ)k log n/pk  we get
n] ≥ c(γ)k log n/4e2.
E[P i
n are independent of each other  using the above lower
Now  since the indicator variables P i
bound for the expectation of their sum and Chernoff bounds we get Pr[P i
n ≤ k] ≤
exp(−Ω(c(γ) log n)). Thus  for a sufﬁciently large constant c(γ)  the probability that the vertex ui
is uninfected after two rounds Pr[P1 + . . . + Pn ≤ k] ≤ 1/2mγ+1. By taking a union bound over
all vertices uk+1  . . .   um  the probability that there is an uninfected vertex in the left partition after
two steps of cascading starting from L0 is at most 1/2mγ. The theorem now follows by observing
that if the left partition is completely infected  for a suitably large constant c(γ)  all vertices in the
right will be infected with probability at least 1 − 1/2mγ as qj ≥ c(γ)k log n.¤

1 + . . . + P i

1  . . .   P i

Combining the above with Theorem 3.1 we obtain exact matrix-completion for sampling graphs
drawn from the CLV model.

Theorem 4.2 Let M be a non-degenerate matrix of rank k. Then  for sampling graphs GΩ gen-
erated from a CLV model satisfying the conditions of Theorem 4.1  ICMC recovers the matrix M
exactly with high probability.

Remark: The above results show exact-recovery for CLV graphs with densities up to n−1/k = o(1).
As mentioned in the introduction  the above result is incomparable to the main results of [4  5]  [13].

The main bottleneck for the density requirements in the proof of Theorem 4.1 is Equation (4.2)

relating Pj qk+1

j

to (Pj qj)k+1  where we used the power-mean inequality. However  when the

5

expected degrees qj are skewed  say with a power-law distribution  it should be possible to obtain
much better bounds than those of Equation (4.2)  hence also improving the density requirements.
Thus  in a sense the Erd˝os-R´enyi graphs are the worst-case examples for our analysis.

Our empirical simulations also suggest that completely cascading sets are more likely to exist in
random graph models with power-law distributed expected degrees as compared to Erd˝os-R´enyi
graphs. Intuitively  this is because of the following reasons.
• In graphs with power-law distributed degrees  the high degree vertices have much higher degrees
than the average degree of the graph. So  infecting the highest degree vertices is more likely to
infect more vertices in the ﬁrst step.

• More importantly  as observed in the seminal work of Kleinberg [14] in most real-world graphs
there are a small number of vertices (hubs) that have much higher connectivity than most ver-
tices. Thus  infecting the hubsis likely to infect a large fraction of vertices.

Thus  we expect ICMC to perform better on models that are closer to real-world graphs and have
power-law distributed degrees. In particular  as strongly supported by experiments (see Figure 3) 
we hypothesize that ICMC solves exact matrix completion from an almost optimal number of entries
for sampling graphs drawn from the preferential attachment model.
Conjecture 4.3 There exists a universal constant C such that for all k ≥ 1  k1  k2 ≥ Ck the fol-
lowing holds. For G = (U  V  E) generated from the preferential attachment model with parameters
m  n  k1  k2  the k highest degree vertices of U form a completely cascading set of order k with high
probability.
If true  the above combined with Theorem 3.1 would imply the following.
Conjecture 4.4 Let M be a non-degenerate matrix of rank k. Then  for sampling graphs GΩ gen-
erated from a PA model with parameters k1  k2 ≥ Ck  ICMC recovers the matrix M exactly with
high probability.
Remark: To solve the matrix completion problem we need to sample at least (m + n)k entries.
Thus  the bounds above are optimal up to a constant factor. Moreover  the bounds above are stronger
than those obtainable - even information theoretically - for Erd˝os-R´enyi graphs  as for Erd˝os-R´enyi
graphs we need to sample Ω(n log n) entries even for k = 1.

5 Experimental Results
We ﬁrst demonstrate that for many real-world matrix completion datasets  the observed entries are
far from being sampled uniformly with the sampling graph having power-law distributed degrees.
We then use various random graph models to compare our method against the trace-norm based
singular value thresholding algorithm of [3]  the spectral matrix completion algorithm (SMC) of
[13] and the regularized alternating least squares minimization (ALS) heuristic. Finally  we present
empirical results on the Netﬂix challenge dataset. For comparing with SVT and SMC  we use the
code provided by the respective authors; while we use our own implementation for ALS. Below we
provide a few implementation details for our algorithm ICMC.
Implementation Details
Consider step 2(b) of our algorithm ICMC. Let Lj be the set of vertices in L that have an edge to
vj  Lk
j   :) be the sub-matrix of X containing rows corre-
j . If the underlying matrix is indeed low-rank and there is no noise in the
sponding to vertices in Lk
j   can be com-
observed entries  then for a newly infected vertex vj  the corresponding row of Y   y
T
puted by solving the following linear system of equations: M (Lk
j   :)yj. To account for
noise in measurements  we compute yj by solving the following regularized least squares problem:
2  where λ is a regularization parameter. Similarly 
yj = argminy kM (Lj  j)−X(Lj  :)yk2
we compute x
Note that if ICMC fails to infect all the vertices  i.e. L ( U or R ( V   then rows of X and Y
will not be computed for vertices in U \L and V \R. Let X = [XL  X ˜L]  where XL is the set of
computed rows of X (for vertices in L) and X ˜L denotes the remaining rows of X. Similarly  let
Y = [YR  Y ˜R]. We estimate X ˜L and Y ˜R using an alternating least squares based heuristic that solves
the following:

i by solving: xi = argminx kM (i  Ri)T − Y (Ri  :)xk2
T

j be any size k subset of Lj  and let X(Lk

j   j) = X(Lk

2.
2 + λkxk2

2 +λkyk2

2

˜R ]¶¯¯¯¯

¯¯¯¯

6

PΩµM −·XL

X ˜L¸ [Y T

R Y T

+ µkX ˜Lk2

F + µkY ˜Rk2
F  

F

min

X ˜L Y ˜R¯¯¯¯

¯¯¯¯

10−5

)
x
 
≥
X

(
r

P

10−10

10−15

 

Netflix Dataset (Movies)

 

100

Netflix Dataset (Users)

Yahoo Music Dataset (Artists)

 

 

Yahoo Music Dataset (Users)

 

Empirical Distribution
Poisson Distribution
Power−law Distribution

)
x
 
≥
X

(
r

P

10−10

104

x (Number of Users)

105

 

103

(a)

)
x
 
≥
X

(
r

10−10

Empirical distribution
Poisson distribution
Power−law distribution

P

x (Number of movies)

104

(b)

Empirical Distribution
Poisson Distribution
Power−law Distribution

 

104

x (Number of users)

105

(c)

10−5

10−10

)
x
 
≥
X

(
r

P

10−15

 

Empirical Distribution
Poisson Distribution
Power−law Distribution

103

x (Number of artists)

104

(d)

Figure 1: Cumulative degree distribution of (a) movies  (b) users (Netﬂix dataset) and (c) artists 
(d) users (Yahoo Music dataset). Note that degree distributions in all the four cases closely follow
power-law distribution and deviate heavily from Poisson-distribution  which is assumed by SVT [3]
and SMC [13].

1.5

E
S
M
R

1

0.5

0

 

500

Erdos−Renyi Model

1000

n (Size of Matrix)

1500

 

ICMC
ALS
SVT
SMC

2000

2.5

2

E
S
M
R

1.5

1

0.5

 

0
0

Chung−Lu−Vu Model

 

ICMC
ALS
SVT
SMC

500

1000

n (Size of Matrix)

1500

2000

E
S
M
R

6

4

2

0

 

500

PA Model

Forest−Fire Model

 

ICMC
ALS
SVT
SMC

2000

E
S
M
R

3

2

1

0

 

500

 

ICMC
ALS
SVT
SMC

2000

1000

n (Size of Matrix)

1500

1000

n (Size of Matrix)

1500

Figure 2: Results on synthetic datasets for ﬁxed sampling density with sampling graph coming from
different Graph Models: (a) Erd˝os-R´enyi model  (b) Chung-Lu-Vu model  (c) Preferential attach-
ment model  and (d) Forest-ﬁre model. Note that for the three power-law distribution generating
models our method (ICMC) achieves considerably lower RMSE than the existing method.

(a) Erd˝os-R´enyi Graphs

n/Method
500
1000
1500
2000
(c) Preferential Attachment Graphs

SVT ALS
1.09
8.88
17.07
2.39
4.85
38.81
59.88
7.20

SMC
45.51
93.85
214.65
343.76

ICMC
1.28
3.30
6.28
9.89

n/Method
500
1000
1500
2000

(b) Chung-Lu-Vu Graphs
SVT ALS
1.24
14.69
17.55
2.24
3.89
30.99
46.69
5.67

SMC
35.32
144.19
443.48
836.99
(d)Forest-ﬁre Graphs

n/Method
500
1000
1500
2000

SMC
15.05
67.96
178.35
417.54

SVT
14.40
16.49
24.48
32.06

ALS
3.97
5.06
9.83
15.07

ICMC
1.94
2.01
3.65
7.46

n/Method
500
1000
1500
2000

SMC
22.63
85.26
186.81
350.98

SVT ALS
5.53
0.57
1.75
11.32
3.30
21.39
27.37
4.84

ICMC
0.49
2.02
3.91
5.50

ICMC
0.39
1.23
2.99
5.06

Table 1: Time required (in seconds) by various methods on synthetic datasets for ﬁxed sampling
density with sampling graph coming from different Graph Models: (a) Erd˝os-R´enyi model  (b)
Chung-Lu-Vu model  (c) Preferential attachment model  and (d) Forest-ﬁre model. Note that our
method (ICMC) is signiﬁcantly faster than SVT and SMC  and has similar run-time to that of ALS.

where µ ≥ 0 is the regularization parameter.
Sampling distribution in Netﬂix and Yahoo Music Datasets
The Netﬂix challenge dataset contains the incomplete user-movie ratings matrix while the Yahoo
Music dataset contains the incomplete user-artist ratings matrix. For both datasets we form the cor-
responding bipartite sampling graphs and plot the left (users) and right (movies/artists) cumulative
degree distributions of the bipartite sampling graphs.

Figure 1 shows the cumulative degree distributions of the bipartite sampling graphs  the best power-
law ﬁt computed using the code provided by Clauset et.al [7] and the best Poisson distribution ﬁt.
The ﬁgure clearly shows that the sampling graphs for the Netﬂix and Yahoo Music datasets are far
from regular as assumed in [4] [5] [13] and have power-law distributed degrees.
Experiments using Random Graph Models
To compare various methods  we ﬁrst generate random low-rank matrices X ∈ Rn×n for varying n 
and sample from the generated matrices using Erd˝os-R´enyi  CLV  PA and forest-ﬁre random graph
models. We omit the results for the afﬁliation networks model from this paper due to lack of space;
we observed similar trends on the afﬁliation networks model.

7

100

10−2

l

s
n
m
u
o
C
/
s
w
o
R
d
e

 

Erdos−Renyi
Chung−Lu
Pref. Attachment

t
c
e
n

f

I

 

10−2

10−1

p (Sampling Density)

Sampling Density Threshold

Preferential Attachment Model (m vs k)

 

300

)
s
e
g
d
e

 
f

o

 
r
e
b
m
u
N

(
 

m

200

100

100

 

0
10

 

COMBMC
m=Ck+C0

20

k (Rank of the Matrix)

30

40

50

k
5
10
20
25
30

Fraction of infected RMSE

rows & columns

0.98
0.95
0.87
.84

0.46 × 10−5

0.9603
0.9544
0.9437
0.9416
0.9602

Figure 3: Left: Fraction of infected nodes as edge density increases. Note the existence of a clear
threshold. The threshold is quite small for CLV and PA suggesting good performance of ICMC for
these models. Middle: Threshold for parameters k1  k2 (the number of edges per node) in PA as
k increases. The threshold varies linearly with k supporting Conjecture 4.3. Right: Fraction of
infected rows and columns using ICMC for the Netﬂix challenge dataset.

For each random graph model we compare the relative mean square error (RMSE) on the unknown
entries achieved by our method ICMC against several existing methods. We also compare the total
time taken by each of the methods. All results represent the average over 20 runs.
Figure 2 compares the RMSE achieved by ICMC to that of SVT  SMC and ALS when rank k is ﬁxed
to be 10  sampling density p = 0.1  and the sampling graphs are generated from the four random
graph models. Note that for the more-realistic CLV  PA  forest-ﬁre three models ICMC outperforms
both SVT and SMC signiﬁcantly and performs noticeably better than ALS. Table 1 compares the
computational time taken by each of the methods. The table shows that for all three models  ICMC
is faster than SVT and SMC by an order of magnitude and is also competitive to ALS. Note that
the performance of our method for Erdos-Renyi graphs (Figure 2 (a)) is poor  with other methods
achieving low RMSE. This is expected as the Erdos-Renyi graphs are in a sense the worst-case
examples for ICMC as explained in Section 4.
Threshold for Complete Cascading
Here we investigate the threshold for complete cascading in the random graph models. Besides
being interesting on its own  the existence of completely cascading sets is closely tied to the success
of ICMC by Theorem 3.1. Figure 3 shows the fraction of vertices infected by the cascading process
starting from the k highest degree vertices for graphs generated from the random graph models as
the edge density increases.
The left plot of Figure 3 shows the existence of a clear threshold for the density p  beyond which
the fraction of infected vertices is almost surely one. Note that the threshold is quite small for the
CLV  PA and forest-ﬁre models  suggesting good performance of ICMC on these models. As was
explained in Section 4  the threshold is bigger for the Erd˝os-R´enyi graph model.

The right plot of Figure 3 shows the threshold value (the minimum value above which the infected
fraction is almost surely one) for k1  k2 as a function of k in the PA model. The plot shows that the
threshold is of the form Ck for a universal constant C  strongly supporting Conjectures 4.3  4.4.
Netﬂix Challenge Dataset
Finally  we evaluate our method on the Netﬂix Challenge dataset which contains an incomplete
matrix with about 100 million ratings given by 480 189 users for 17 770 movies. The rightmost
table in Figure 3 shows the fraction of rows and columns infected by ICMC on the dataset for
several values of the rank parameter k. Note that even for a reasonably high rank of 25  ICMC
infects a high percentage (84%) of rows and columns. Also  for rank 30 the fraction of infected
rows and columns drops to almost zero  suggesting that the sampling density of the matrix is below
the sampling threshold for rank 30.
For rank k = 20  the RMSE incurred over the probe set (provided by Netﬂix) is 0.9437 which is
comparable to the RMSE=0.9404 achieved by the regularized Alternating Least Squares method.
More importantly  the time required by our method is 1.59 × 103 seconds compared to 6.15 × 104
seconds required by ALS. We remark that noise (or higher rank of the underlying matrix) can offset
our method leading to somewhat inferior results. In such a case  our method can be used for a good
initialization of the ALS method and other state-of-the-art collaborative ﬁltering methods to achieve
better RMSE.

8

References
[1] Albert-Laszlo Barabasi and Reka Albert. Emergence of scaling in random networks. Science  286:509 

[2] Matthew Brand. Fast online svd revisions for lightweight recommender systems. In SDM  2003.
[3] Jian-Feng Cai  Emmanuel J. Candes  and Zuowei Shen. A singular value thresholding algorithm for

[4] Emmanuel J. Cand`es and Benjamin Recht. Exact matrix completion via convex optimization. CoRR 

[5] Emmanuel J. Cand`es and Terence Tao. The power of convex relaxation: Near-optimal matrix completion.

[6] Fan R. K. Chung  Linyuan Lu  and Van H. Vu. The spectra of random graphs with given expected degrees.

[7] A. Clauset  C.R. Shalizi  and M.E.J. Newman. Power-law distributions in empirical data. SIAM Review 

[8] Uriel Feige and Eran Ofek. Spectral techniques applied to sparse random graphs. Random Struct. Algo-

[9] Joel Friedman  Jeff Kahn  and Endre Szemer´edi. On the second eigenvalue in random regular graphs. In

1999.

matrix completion  2008.

abs/0805.4471  2008.

CoRR  abs/0903.1476  2009.

Internet Mathematics  1(3)  2003.

page to appear  2009.

rithms  27(2):251–275  2005.

STOC  pages 587–598  1989.

INFOCOM  2003.

[10] Christos Gkantsidis  Milena Mihail  and Ellen W. Zegura. Spectral analysis of internet topologies. In

[11] David Kempe  Jon M. Kleinberg  and ´Eva Tardos. Maximizing the spread of inﬂuence through a social

[13] Raghunandan H. Keshavan  Sewoong Oh  and Andrea Montanari. Matrix completion from a few entries.

[14] Jon M. Kleinberg. Hubs  authorities  and communities. ACM Comput. Surv.  31(4es):5  1999.
[15] Yehuda Koren. Factorization meets the neighborhood: a multifaceted collaborative ﬁltering model. In

CoRR  abs/0901.3150  2009.

KDD  pages 426–434  2008.

[16] Silvio Lattanazi and D. Sivakumar. Afﬁliation networks. In STOC  2009.
[17] Jure Leskovec  Jon M. Kleinberg  and Christos Faloutsos. Graph evolution: Densiﬁcation and shrinking

[18] Yehuda Koren M. Bell. Scalable collaborative ﬁltering with jointly derived neighborhood interpolation

[19] Milena Mihail and Christos H. Papadimitriou. On the eigenvalue power law. In RANDOM  pages 254–

[20] Benjamin Recht  Maryam Fazel  and Pablo A. Parrilo. Guaranteed minimum-rank solutions of linear

matrix equations via nuclear norm minimization  2007.

diameters. TKDD  1(1)  2007.

weights. In ICDM  pages 43–52  2007.

262  2002.

network. In KDD  pages 137–146  2003.

[12] David Kempe  Jon M. Kleinberg  and ´Eva Tardos.

networks. In ICALP  pages 1127–1138  2005.

Inﬂuential nodes in a diffusion model for social

9

,Yin Cheng Ng
Nicolò Colombo
Ricardo Silva