2011,Stochastic convex optimization with bandit feedback,This paper addresses the problem of minimizing a convex  Lipschitz  function $f$ over a convex  compact set $X$ under a stochastic bandit feedback model. In this model  the algorithm is allowed to  observe noisy realizations of the function value $f(x)$ at any query  point $x \in X$. We demonstrate a generalization of the  ellipsoid algorithm that incurs $O(\poly(d)\sqrt{T})$ regret. Since any algorithm has regret at least $\Omega(\sqrt{T})$  on this problem  our algorithm is optimal in terms of the scaling  with $T$.,Stochastic convex optimization with bandit

feedback

Alekh Agarwal

Department of EECS

UC Berkeley

Dean P. Foster

Department of Statistics

University of Pennysylvania

Daniel Hsu

Microsoft Research

New England

alekh@cs.berkeley.edu

dean.foster@gmail.com

dahsu@microsoft.com

Sham M. Kakade

Department of Statistics Microsoft Research

University of Pennysylvania

New England

skakade@microsoft.com

Alexander Rakhlin

Department of Statistics

University of Pennysylvania
rakhlin@wharton.upenn.edu

Abstract

This paper addresses the problem of minimizing a convex  Lipschitz func-
tion f over a convex  compact set X under a stochastic bandit feedback
model. In this model  the algorithm is allowed to observe noisy realizations
of the function value f (x) at any query point x ∈ X . We demonstrate
gret. Since any algorithm has regret at least Ω(√T ) on this problem  our
algorithm is optimal in terms of the scaling with T .

a generalization of the ellipsoid algorithm that incurs (cid:101)O(poly(d)√T ) re-

1 Introduction

This paper considers the problem of stochastic convex optimization under bandit feedback
which is a generalization of the classical multi-armed bandit problem  formulated by Robbins
in 1952. Our problem is speciﬁed by a mean cost function f which is assumed to be convex
and Lipschitz  and a convex  compact domain X . The algorithm repeatedly queries f at
points x ∈ X and observes noisy realizations of f (x). Performance of an algorithm is
measured by regret  that is the diﬀerence between values of f at the query points and the
minimum value of f over X . This specializes to the classical K-armed setting when X is
the probability simplex and f is linear. Several recent works consider the continuum-armed
bandit problem  making diﬀerent assumptions on the structure of f over X . For instance 
the f is assumed to be linear in the paper [9]  a Lipschitz condition on f is assumed in
the works [3  12  13]  and Srinivas et al. [16] exploit the structure of a Gaussian processes.
For these “non-parametric” bandit problems  the rates of regret (after T queries) are of the
form T α  with exponent α approaching 1 for large dimension d.

The question addressed in the present paper is: How can we leverage convexity of the mean
cost function as a structural assumption? Our main contribution is an algorithm which

achieves  with high probability  an ˜O(poly(d)√T ) regret after T requests. This result holds
for all convex Lipschitz mean cost functions. We observe that the rate with respect to T
does not deteriorate with d unlike the non-parametric problems mentioned earlier. Let us
also remark that Ω(√dT ) lower bounds have been shown for linear mean cost functions 
making our algorithm optimal up to factors polynomial in d and logarithmic in T .
Prior Work Asymptotic rates of √T have been previously achieved by Cope [8] for uni-
modal functions under stringent conditions (smoothness and strong convexity of the mean

1

cost function  in addition to the maxima being achieved inside the set). Auer et al. [4]

show a regret of ˜O(√T ) for a one-dimensional non-convex problem with ﬁnite number of
maximizers. Yu and Mannor [17] recently studied unimodal bandits in one dimension  but
they do not consider higher dimensional cases. Bubeck et al. [7] show √T regret for a subset
of Lipschitz functions with certain metric properties. Convex  Lipschitz cost functions have
also been looked at in the adversarial model [10  12]  but the best-known regret bounds for
these algorithms are O(T 3/4). We also note that previous results of Agarwal et al. [1] and
Nesterov [15] do not apply to our setting as noted in the full-length version of this paper [2].

The problem addressed in this paper is closely related to noisy zeroth order convex optimiza-
tion  whereby the algorithm queries a point of the domain X and receives a noisy evaluation
of the function. While the literature on stochastic optimization is vast  we emphasize that
an optimization guarantee does not necessarily imply a bound on regret.
In particular 
we directly build on an optimization method that has been developed by Nemirovski and
Yudin [14  Chapter 9]. Given  > 0  the method is guaranteed to produce an -minimizer

in (cid:101)O(poly(d)−2) iterations  yet this does not immediately imply small regret. The latter is

the quantity of interest in this paper  since it is the standard performance measure in de-
cision theory. More importantly  in many applications every query to the function involves
a consumption of resources or a monetary cost. A low regret guarantees that the net cost
over the entire process is bounded unlike an optimization error bound.

The remainder of this paper is organized as follows. In the next section  we give the formal
problem setup and highlight diﬀerences between the regret and optimization error settings.
We then present a simple algorithm and its analysis for 1-dimension that illustrates some of
the key insights behind the general d-dimensional algorithm in Section 3. Section 4 describes
our generalization of the ellipsoid algorithm for d dimensions along with its regret guarantee.
Proofs of our results can be found in the full-length version [2].

2 Setup

In this section we will give the basic setup and the performance criterion  and explain the
diﬀerences between the metrics of regret and optimization error.

2.1 Problem deﬁnition and notation

Let X be a compact and convex subset of Rd  and let f : X → R be a 1-Lipschitz convex
function on X   so f (x) − f (x(cid:48)) ≤ (cid:107)x − x(cid:48)(cid:107) for all x  x(cid:48) ∈ X . We assume X is speciﬁed in
a way so that the algorithm can eﬃciently construct the smallest Euclidian ball containing
X . Furthermore  we assume the algorithm has noisy black-box access to f . Speciﬁcally  the
algorithm is allowed to query the value of f at any x ∈ X   and it observes y = f (x)+ε where ε
is an independent σ-subgaussian random variable with mean zero: E[exp(λε)] ≤ exp(λ2σ2/2)
for all λ ∈ R. The goal of the algorithm is to minimize its regret: after making T queries
x1  . . .   xT ∈ X   the regret of the algorithm compared to any x∗ ∈ arg minx∈X f (x) is

(1)

RT =(cid:80)T

t=1

(cid:2)f (xt) − f (x∗)(cid:3).

We will construct an average and conﬁdence interval (henceforth CI) for the function values
at points queried by the algorithm. Letting LBγi(x) and UBγi(x) denote the lower and
upper bounds of a CI of width γi for the function estimate of a point x  we will say that
CI’s at two points are γ-separated if LBγi(x) ≥ UBγi(y) + γ or LBγi (y) ≥ UBγi (x) + γ.
2.2 Regret vs. optimization error

(cid:80)T
Since f is convex  the average ¯xT = 1
t=1 xt satisﬁes f (¯xT ) − f (x∗) ≤ RT /T so that low
T
regret (1) also gives a small optimization error. The converse  however  is not necessarily
true. An optimization method might can query far from the minimum of the function (that
is  explore) on most rounds  and output the solution at the last step. Guaranteeing a small
regret typically involves a more careful balancing of exploration and exploitation.

2

To better understand the diﬀerence  suppose X = [0  1]  and let f (x) be one of
xT −1/3 −xT −1/3 and x(x − 1). Let us sample function values at x = 1/4 and x = 3/4.
To distinguish the ﬁrst two cases  we need Ω(T 2/3) points. If f is linear indeed  we only
incur O(T 1/3) regret on these rounds. However  if instead f (x) = x(x − 1)  we incur an
undesirable Ω(T 2/3) regret. For purposes of optimization  it suﬃces to eventually distin-
guish the three cases. For the purposes of regret minimization  however  an algorithm has
to detect that the function curves between the two sampled points. To address this issue 
we additionally sample at x = 1/2. The center point acts as a sentinel : if it is recognized
that f (1/2) is noticeably below the other two values  the region [0  1/4] or [3/4  1] can be
discarded. Similarly  one of these regions can be discarded if it is recognized that the value
of f either at x = 1/4 or at x = 3/4 is greater than others. Finally  if f at all three points
appears to be similar at a given scale  we have a certiﬁcate (due to convexity) that the
algorithm is not paying regret per query larger than this scale.

This center-point device that allows to quickly detect that the optimization method might
be paying high regret and to act on this information is the main novel tool of our paper.
Unlike discretization-based methods  the proposed algorithm uses convexity in a crucial way.
We ﬁrst demonstrate the device on one-dimensional problems in the next section  where the
solution is clean and intuitive. We then develop a version of the algorithm for higher
dimensions  basing our construction on the beautiful zeroth order optimization method of
Nemirovski and Yudin [14]. Their method does not guarantee vanishing regret by itself  and
a careful fusion of this algorithm with our center-point device is required.

3 One-dimensional case

We start with a special case of 1-dimension to illustrate some of the key ideas including
the center-point device. We assume wlog that the domain X = [0  1]  and f (x) ∈ [0  1] (the
latter can be achieved by pinning f (x∗) = 0 since f is 1-Lipschitz).

3.1 Algorithm description

Algorithm 1 One-dimensional stochastic convex bandit algorithm

input noisy black-box access to f : [0  1] → R  total number of queries allowed T .

1: Let l1 := 0 and r1 := 1.
2: for epoch τ = 1  2  . . . do
3:
4:
5:
6:
7:

Let wτ := rτ − lτ .
Let xl := lτ + wτ /4  xc := lτ + wτ /2  and xr := lτ + 3wτ /4.
for round i = 1  2  . . . do

Let γi := 2−i.
For each x ∈ {xl  xc  xr}  query f (x) 2σ
if max{LBγi (xl)  LBγi (xr)} ≥ min{UBγi(xl)  UBγi(xr)} + γi then

log T times.

γ2
i

{Case 1: CI’s at xl and xr are γi separated}

if LBγi(xl) ≥ LBγi(xr) then let lτ +1 := xl and rτ +1 := rτ .
if LBγi(xl) < LBγi(xr) then let lτ +1 := lτ and rτ +1 := xr.
Continue to epoch τ + 1.

else if max{LBγi(xl)  LBγi(xr)} ≥ UBγi(xc) + γi then

if LBγi(xl) ≥ LBγi(xr) then let lτ +1 := xl and rτ +1 := rτ .
if LBγi(xl) < LBγi(xr) then let lτ +1 := lτ and rτ +1 := xr.
Continue to epoch τ + 1.

{Case 2: CI’s at xc and xl or xr are γi separated}

8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20: end for

end if
end for

Algorithm 1 proceeds in a series of epochs demarcated by a working feasible region (the
interval Xτ = [lτ   rτ ] in epoch τ ). In each epoch  the algorithm aims to discard a portion
of Xτ determined to only contain suboptimal points. To do this  the algorithm repeatedly

3

makes noisy queries to f at three diﬀerent points in Xτ . Each epoch is further subdivided
into rounds  where we query the function (2σ log T )/γ2
i times in round i at each of the
points. By Hoeﬀding’s inequality  this implies that we know the function value to within
γi with high probability. The value γi is halved at every round. At the end of an epoch τ  
Xτ is reduced to a subset Xτ +1 = [lτ +1  rτ +1] ⊂ [lτ   rτ ] of the current region for the next
epoch τ + 1  and this reduction is such that the new region is smaller in size by a constant
fraction. This geometric rate of reduction guarantees that only a small number of epochs
can occur before Xτ only contains near-optimal points.
For the algorithm to identify a sizable portion of Xτ to discard  the queries in each epoch
should be suitably chosen  and the convexity of f must be exploited. To this end  the
algorithm makes its queries at three equally-spaced points xl < xc < xr in Xτ (see Section
4.1 of the full-length version for graphical illustrations of these cases).

Case 1: If the CIs around f (xl) and f (xr) are suﬃciently separated  the algorithm discards
a fourth of [lτ   rτ ] (to the left of xl or right of xr) which does not contain x∗.
Case 2:
If the above separation fails  the algorithm checks if the CI around f (xc) is
suﬃciently below at least one of the other CIs (for f (xl) or f (xr)). If that happens  the
algorithm again discards a quartile of [lτ   rτ ] that does not contain x∗.
Case 3: Finally  if none of the earlier cases is true  then the algorithm is assured (by
convexity) that the function is suﬃciently ﬂat on Xτ and hence it has not incurred much
regret so far . The algorithm continues the epoch  with an increased number of queries to
obtain smaller conﬁdence intervals at each of the three points.

3.2 Analysis

The analysis of Algorithm 1 relies on the function values being contained in the conﬁ-
dence intervals we construct at each round of each epoch. To avoid having probabilities
throughout our analysis  we deﬁne an event E where at each epoch τ   and each round i 
f (x) ∈ [LBγi(x)  UBγi(x)] for x ∈ {xl  xc  xr}. We will carry out the remainder of the
analysis conditioned on E and bound the probability of E c at the end.
The following theorem bounds the regret incurred by Algorithm 1. We note that the regret
would be maintained in terms of the points xt queried by the algorithm at time t. Within
any given round  the order of queries is immaterial to the regret.

Theorem 1 (Regret bound for Algorithm 1). Suppose Algorithm 1 is run on a convex 
1-Lipschitz function f bounded in [0 1]. Suppose the noise in observations is i.i.d. and
σ-subGaussian. Then with probability at least 1 − 1/T we have

(cid:112)

f (xt) − f (x∗) ≤ 108

σT log T log4/3

T(cid:88)

t=1

(cid:18)

T

8σ log T

(cid:19)

.

Remarks: As stated Algorithm 1 and Theorem 1 assume knowledge of T   but we can make

the algorithm adaptive to T by a standard doubling argument. We remark that O(√T ) is

the smallest possible regret for any algorithm even with noisy gradient information. Hence 
this result shows that for purposes of regret  noisy zeroth order information is no worse than
noisy ﬁrst-order information apart from logarithmic factors.

Theorem 1 is proved via a series of lemmas below. The key idea is to show that the regret
on any epoch is small and the total number of epochs is bounded. To bound the per-epoch
regret  we will show that the total number of queries made on any epoch depends on how
ﬂat the function is on Xτ . We either take a long time  but the function is very ﬂat  or we
stop early when the function has suﬃcient slope  never accruing too much regret. We start
by showing that the reduction in Xτ after each epoch always preserves near-optimal points.
Lemma 1 (Survival of approx. minima). If epoch τ ends in round i  then [lτ +1  rτ +1]
contains every x ∈ [lτ   rτ ] such that f (x) ≤ f (x∗) + γi. In particular  x∗ ∈ [lτ   rτ ] for all τ .

4

The next two lemmas bound the regret incurred in any single epoch. To show this  we ﬁrst
establish that an algorithm incurs low regret in a round as long as it does not end an epoch.
Then  as a consequence of the doubling trick  we show that the regret incurred in an epoch
is on the same order as that incurred in the last round of the epoch.
Lemma 2 (Certiﬁcate of low regret). If epoch τ continues from round i to round i + 1  then
the regret incurred in round i is at most 72γ−1
Lemma 3 (Regret in an epoch). If epoch τ ends in round i  then the regret incurred in the
entire epoch is at most 216γ−1

i σ log T.

i σ log T.

To obtain a bound on the overall regret  we bound the number of epochs that can occur
before Xτ only contains near-optimal points. The ﬁnal regret bound is simply the product
of the number of epochs and the regret incurred in any single epoch.
Lemma 4 (Bound on the number of epochs). The total number of epochs τ performed by
Algorithm 1 is bounded as τ ≤ 1

2 log4/3

(cid:16)

(cid:17)

.

T

8σ log T

4 Algorithm for optimization in higher dimensions

We now move to present the general algorithm that works in d-dimensions. The natural
approach would be to try and generalize Algorithm 1 to work in multiple dimensions. How-
ever  the obvious extension requires querying the function along every direction in a covering
of the unit sphere so that we know the behavior of the function along every direction. Such
an approach yields regret and running time that scales exponentially with the dimension d.
Nemirovski and Yudin [14] address this problem in the setup of zeroth order optimization
by a clever construction to capture all the directions in polynomially many queries. We
deﬁne a pyramid to be a d-dimensional polyhedron deﬁned by d + 1 points; d points form
a d-dimensional regular polygon that is the base of the pyramid  and the apex lies above
the hyperplane containing the base (see Figure 1 for a graphic illustration in 3 dimensions).
The idea of Nemirovski and Yudin is to build a sequence of pyramids  each capturing the
variation of function in certain directions  in such a way that with O(d log d) pyramids we
can explore all the directions. However  as mentioned earlier  their approach fails to give a
low regret. We combine their geometric construction with ideas from the one-dimensional
case to obtain Algorithm 2 which incurs a bounded regret.

Figure 1: Pyramid in 3-dimensions

Figure 2: The regular simplex constructed at round
i of epoch τ with radius rτ   center x0 and vertices
x1  . . .   xd+1.

Just like the 1-dimensional case  Algorithm 2 proceeds in epochs. We start with the opti-
mization domain X   and at the beginning we set X0 = X . At the beginning of epoch τ  
we have a current feasible set Xτ which contains at least one approximate optimum of the
convex function. The epoch ends with discarding some portion of the set Xτ in such a way
that we still retain at least one approximate optimum in the remaining set Xτ +1.
At the start of the epoch τ   we apply an aﬃne transformation to Xτ so that the smallest
volume ellipsoid containing it is a Euclidian ball of radius Rτ (denoted as B(Rτ )). We deﬁne
rτ = Rτ /c1d for a constant c1 ≥ 1  so that B(rτ ) ⊆ Xτ (see e.g. Lecture 1  p. 2 [5]). We
will use the notation Bτ to refer to the enclosing ball. Within each epoch  the algorithm
proceeds in several rounds  each round maintaining a value γi which is successively halved.

5

ϕhAPEXx0x2xd+1x1rτRτXτ∆τ (γ)  ∆τ (γ) and number of queries T allowed.

Algorithm 2 Stochastic convex bandit algorithm
input feasible region X ⊂ Rd; noisy black-box access to f : X → R  constants c1 and c2  functions
1: Let X1 := X .
2: for epoch τ = 1  2  . . . do
3:
4:
5:
6:
7:

Round Xτ so B(rτ ) ⊆ Xτ ⊆ B(Rτ )  Rτ is minimized  and rτ := Rτ /(c1d). Let Bτ = B(Rτ ).
Construct regular simplex with vertices x1  . . .   xd+1 on the surface of B(rτ ).
for round i = 1  2  . . . do

times.

Let γi := 2−i.
Query f at xj for each j = 1  . . .   d + 1 2σ log T
Let y1 := arg maxj LBγi (xj).
for k = 1  2  . . . do

γ2
i

loop

times.

Construct pyramid Πk with apex yk; let z1  . . .   zd be the vertices of the base of Πk and
z0 be the center of Πk.

Let(cid:98)γ := 2−1.
Query f at each of {yk  z0  z1  . . .   zd} 2σ log T(cid:98)γ2
Let center := z0  apex := yk  top be the vertex v of Πk maximizing LB(cid:98)γ(v) 
if LB(cid:98)γ(top) ≥ UB(cid:98)γ(bottom) + ∆τ ((cid:98)γ) and LB(cid:98)γ(top) ≥ UB(cid:98)γ(apex) +(cid:98)γ then
bottom be the vertex v of Πk minimizing LB(cid:98)γ(v).
{Case (1a)}
else if LB(cid:98)γ(top) ≥ UB(cid:98)γ(bottom) + ∆τ ((cid:98)γ) and LB(cid:98)γ(top) < UB(cid:98)γ(apex) +(cid:98)γ then
Let yk+1 := top  and immediately continue to pyramid k + 1.
{Case (1b)}
else if LB(cid:98)γ(top) < UB(cid:98)γ(bottom) + ∆τ ((cid:98)γ) and UB(cid:98)γ(center) ≥ LB(cid:98)γ(bottom) −
Set (Xτ +1 B(cid:48)
∆τ ((cid:98)γ) then
Let(cid:98)γ :=(cid:98)γ/2.
if (cid:98)γ < γi then start next round i + 1.
else if LB(cid:98)γ(top) < UB(cid:98)γ(bottom) + ∆τ ((cid:98)γ) and UB(cid:98)γ(center) < LB(cid:98)γ(bottom) −
∆τ ((cid:98)γ) then

τ +1) = Cone-cutting(Πk Xτ  Bτ )  and proceed to epoch τ + 1.

{Case (2a)}

τ +1)= Hat-raising(Πk Xτ  Bτ )  and proceed to epoch τ + 1.

8:
9:
10:

11:
12:
13:
14:

15:
16:
17:
18:
19:
20:
21:

22:
23:
24:
25:

{Case (2b)}
Set (Xτ +1 B(cid:48)

end if
end loop

26:
27:
28:
29:
30:
31:
32: end for

end for

end for

d(cid:88)

d(cid:88)

Algorithm 3 Cone-cutting
input pyramid Π with apex y  (rounded) feasible region Xτ for epoch τ   enclosing ball Bτ
1: Let z1  . . .   zd be the vertices of the base of Π  and ¯ϕ the angle at its apex.
2: Deﬁne the cone

Kτ = {x | ∃λ > 0  α1  . . .   αd > 0 

αi = 1 : x = y − λ

αi(zi − y)}

τ +1 to be the min. volume ellipsoid containing Bτ \ Kτ .

3: Set B(cid:48)
4: Set Xτ +1 = Xτ ∩ B(cid:48)
output new feasible region Xτ +1 and enclosing ellipsoid B(cid:48)

τ +1.

τ +1.

i=1

i=1

Algorithm 4 Hat-raising
input pyramid Π with apex y  (rounded) feasible region Xτ for epoch τ   enclosing ball Bτ .
1: Let center be the center of Π.
2: Set y(cid:48) = y + (y − center).
3: Set Π(cid:48) to be the pyramid with apex y(cid:48) and same base as Π.
4: Set Xτ +1 B(cid:48)
output new feasible region Xτ +1 and enclosing ellipsoid B(cid:48)

τ +1 = Cone-cutting(Π(cid:48)  Xτ  Bτ ).

τ +1.

6

Figure 3: Sequence of pyramids constructed by Algorithm 2

Let x0 be the center of the ball B(Rτ ) containing Xτ . At the start of a round i  we construct
a regular simplex centered at x0 and contained in B(rτ ). The algorithm queries the function
f at all the vertices of the simplex  denoted by x1. . . .   xd+1  until the CI’s at each vertex
shrink to γi. The algorithm picks the point y1 that maximizes LBγi (xi). By construction 
f (y1) ≥ f (xj) − γi for all j = 1  . . .   d + 1. This step is depicted in Figure 2.
The algorithm now successively constructs a sequence of pyramids  with the goal of iden-
tifying a region of the feasible set Xτ such that at least one approximate optimum of f
lies outside the selected region. This region will be discarded at the end of the epoch.
The construction of the pyramids follows the construction from Section 9.2.2 of Nemirovski
and Yudin [14]. The pyramids we construct will have an angle 2ϕ at the apex  where
cos ϕ = c2/d. The base of the pyramid consists of vertices z1  . . .   zd such that zi − x0 and
y1− zi are orthogonal. We note that the construction of such a pyramid is always possible—
we take a sphere with y1 − x0 as the diameter  and arrange z1  . . .   zd on the boundary of
the sphere such that the angle between y1 − x0 and y1 − zi is ϕ. The construction of the

pyramid is depicted in Figure 3. Given this pyramid  we set(cid:98)γ = 1  and sample the function
at y1 and z1  . . .   zd as well as the center of the pyramid until the CI’s all shrink to(cid:98)γ. Let

top and bottom denote the vertices of the pyramid (including y1) with the largest and the
smallest function value estimates resp. For consistency  we will also use apex to denote the
apex y1. We then check for one of the following conditions (see Section 5 of the full-length
version [2] for graphical illustrations of these cases):

f (top) ≥ f (apex) +(cid:98)γ ≥ f (apex) + γi.

(1) If LB(cid:98)γ(top) ≥ UB(cid:98)γ(bottom) + ∆τ ((cid:98)γ)  we proceed based on the separation between
(a) If LB(cid:98)γ(top) ≥ UB(cid:98)γ(apex) +(cid:98)γ  then we know that with high probability
In this case  we set top to be the apex of the next pyramid  reset (cid:98)γ = 1 and
(b) If LB(cid:98)γ(top) ≤ UB(cid:98)γ(apex)+(cid:98)γ  then we know that LB(cid:98)γ(apex) ≥ UB(cid:98)γ(bottom)+
∆τ ((cid:98)γ) − 2(cid:98)γ. In this case  we declare the epoch over and pass the current apex to
(2) If LB(cid:98)γ(top) ≤ UB(cid:98)γ(bottom) + ∆τ ((cid:98)γ)  then one of the following happens:
(a) If UB(cid:98)γ(center) ≥ LB(cid:98)γ(bottom) − ∆τ ((cid:98)γ)  then all of the vertices and the center
of the pyramid have their function values within a 2∆τ ((cid:98)γ) + 3(cid:98)γ interval. In this
case  we set(cid:98)γ =(cid:98)γ/2. If this sets(cid:98)γ < γi  we start the next round with γi+1 = γi/2.
Otherwise  we continue sampling the current pyramid with the new value of(cid:98)γ.
(b) If UB(cid:98)γ(center) ≤ LB(cid:98)γ(bottom)− ∆τ ((cid:98)γ)  then we terminate the epoch and pass

continue the sampling procedure on the next pyramid.

the cone-cutting step.

the center and the current apex to the hat-raising step.

Hat-Raising: This step happens when the algorithm enters case 2(b). In this case  we
will show that if we move the apex of the pyramid a little from yi to y(cid:48)
i’s CI is above
the top CI while the angle of the new pyramid at y(cid:48)
i is not much smaller than ϕ. Letting
centeri denote the center of the pyramid  we set y(cid:48)
i = yi + (yi − centeri) and denote the
angle at the apex y(cid:48)

i by 2 ¯ϕ. Figure 4 shows the transformation involved in this step.

i  then y(cid:48)

7

top and apex CI’s.

(2)

x0ϕz1z2y1x0y1y2x0y1y2y3Figure 4: Transformation of the
pyramid Π in the hat-raising step.

Figure 5: Cone-cutting step at epoch τ . Solid circle is
the enclosing ball Bτ . Shaded region is the intersection
of Kτ with Bτ . The dotted ellipsoid is the new enclosing
ellipsoid B(cid:48)

τ +1.

Cone-cutting: This step concludes an epoch. The algorithm gets here either through
case 1(b) or through the hat-raising step. In either case  we have a pyramid with an apex y 
base z1  . . .   zd and an angle 2 ¯ϕ at the apex  where cos( ¯ϕ) ≤ 2c2/d. We now deﬁne a cone

d(cid:88)

i=1

d(cid:88)

i=1

Kτ = {x | ∃λ > 0  α1  . . .   αd > 0 

αi = 1 : x = y − λ

αi(zi − y)}

(3)

which is centered at y and a reﬂection of the pyramid around the apex. By construction  the
cone Kτ has an angle 2 ¯ϕ at its apex. We set B(cid:48)
τ +1 to be the ellipsoid of minimum volume
containing Bτ \ Kτ and deﬁne Xτ +1 = Xτ ∩ B(cid:48)
τ +1. This is illustrated in Figure 5. Finally 
we put things back into an isotropic position and Bτ +1 is the ball containing Xτ +1 is in the
isotropic coordinates  which is just obtained by applying an aﬃne transformation to B(cid:48)
τ +1.
Let us end with a brief discussion regarding the computational aspects of this algorithm.
Clearly  the most computationally intensive steps of this algorithm are cone-cutting and the
isotropic transformation at the end. However  these are exactly analogous to the classical
τ +1 is known in closed form [11]. Fur-
thermore  the aﬃne transformations needed to the reshape the set can be computed via
rank-one matrix updates and hence computation of inverses can be done eﬃciently as well
(see e.g. [11] for the relevant implementation details of the ellipsoid method).

ellipsoid method. In particular  the equation for B(cid:48)

The following theorem states our regret guarantee on the performance of Algorithm 2.
Theorem 2. Suppose Algorithm 2 is run with c1 ≥ 64  c2 ≤ 1/32 and parameters

∆τ (γ) =

and ∆τ (γ) =

+ 5

(cid:18) 6c1d4
(cid:18) 2d2 log d

c2
2

+ 3

(cid:19)
(cid:19)(cid:18) 4d7c1

γ

(cid:18) 6c1d4
(cid:19)(cid:18) 12c1d4

c2
2

(cid:19)

γ.

(cid:19)

Then with probability at least 1 − 1/T   the regret incurred by the algorithm is bounded by
= ˜O(d16√T ).

768d3σ√T log2 T

d(d + 1)

+ 11

+ 1

+

c2

c2
2

c2
2

c3
2

Remarks: Theorem 2 is again optimal in the dependence on T . The large dependence on
d is also seen in Nemirovski and Yudin [14] who obtain a d7 scaling in noiseless case and
leave it an unspeciﬁed polynomial in the noisy case. Using random walk ideas [6] to improve
the dependence on d is an interesting question for future research.

Acknowledgments

Part of this work was done while AA and DH were at the University of Pennsylvania. AA
was partially supported by MSR and Google PhD fellowships and NSF grant CCF-1115788
while this work was done. DH was partially supported under grants AFOSR FA9550-09-1-
0425  NSF IIS-1016061  and NSF IIS-713540. AR gratefully acknowledges the support of
NSF under grant CAREER DMS-0954737.

8

z1z2yiy￿i¯ϕϕBτB￿τ+1KτReferences

[1] A. Agarwal  O. Dekel  and L. Xiao. Optimal algorithms for online convex optimization

with multi-point bandit feedback. In COLT  2010.

[2] A. Agarwal  D. Foster  D. Hsu  S. Kakade  and A. Rakhlin. Stochastic convex opti-

mization with bandit feedback. URL http://arxiv.org/abs/1107.1744  2011.

[3] R. Agrawal. The continuum-armed bandit problem. SIAM journal on control and

optimization  33:1926  1995.

[4] P. Auer  R. Ortner  and C. Szepesv´ari. Improved rates for the stochastic continuum-

armed bandit problem. Learning Theory  pages 454–468  2007.

[5] K. Ball. An elementary introduction to modern convex geometry. In Flavors of Ge-
ometry  number 31 in Publications of the Mathematical Sciences Research Institute 
pages 1–55. 1997.

[6] D. Bertsimas and S. Vempala. Solving convex programs by random walks. Journal of

the ACM  51(4):540–556  2004.

[7] S. Bubeck  R. Munos  G. Stolz  and C. Szepesv´ari. X -armed bandits. Journal of

Machine Learning Research  12:1655–1695  2011.

[8] E.W. Cope. Regret and convergence bounds for a class of continuum-armed bandit

problems. Automatic Control  IEEE Transactions on  54(6):1243–1253  2009.

[9] V. Dani  T.P. Hayes  and S.M. Kakade. Stochastic linear optimization under bandit
feedback. In Proceedings of the 21st Annual Conference on Learning Theory (COLT) 
2008.

[10] A. D. Flaxman  A. T. Kalai  and B. H. Mcmahan. Online convex optimization in the
In Proceedings of the sixteenth

bandit setting: gradient descent without a gradient.
annual ACM-SIAM symposium on Discrete algorithms  pages 385–394  2005.

[11] Donald Goldfarb and Michael J. Todd. Modiﬁcations and implementation of the ellip-

soid algorithm for linear programming. Mathematical Programming  23:1–19  1982.

[12] R. Kleinberg. Nearly tight bounds for the continuum-armed bandit problem. Advances

in Neural Information Processing Systems  18  2005.

[13] R. Kleinberg  A. Slivkins  and E. Upfal. Multi-armed bandits in metric spaces.

In
Proceedings of the 40th annual ACM symposium on Theory of computing  pages 681–
690. ACM  2008.

[14] A. Nemirovski and D. Yudin. Problem Complexity and Method Eﬃciency in Optimiza-

tion. Wiley  New York  1983.

[15] Y. Nesterov. Random gradient-free minimization of convex functions. Technical Report

2011/1  CORE DP  2011.

[16] N. Srinivas  A. Krause  S.M. Kakade  and M. Seeger. Gaussian process optimization in
the bandit setting: No regret and experimental design. Arxiv preprint arXiv:0912.3995 
2009.

[17] J. Y. Yu and S. Mannor. Unimodal bandits. In ICML  2011.

9

,Guillaume Papa
Stéphan Clémençon
Aurélien Bellet
Pan Zhou
Xiaotong Yuan
Jiashi Feng