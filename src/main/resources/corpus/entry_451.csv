2017,Adversarial Surrogate Losses for Ordinal Regression,Ordinal regression seeks class label predictions when the penalty incurred for mistakes increases according to an ordering over the labels. The absolute error is a canonical example. Many existing methods for this task reduce to binary classification problems and employ surrogate losses  such as the hinge loss. We instead derive uniquely defined surrogate ordinal regression loss functions by seeking the predictor that is robust to the worst-case approximations of training data labels  subject to matching certain provided training data statistics. We demonstrate the advantages of our approach over other surrogate losses based on hinge loss approximations using UCI ordinal prediction tasks.,Adversarial Surrogate Losses for Ordinal Regression

Rizal Fathony

Mohammad Bashiri

Brian D. Ziebart

Department of Computer Science
University of Illinois at Chicago

Chicago  IL 60607

{rfatho2  mbashi4  bziebart}@uic.edu

Abstract

Ordinal regression seeks class label predictions when the penalty incurred for
mistakes increases according to an ordering over the labels. The absolute error
is a canonical example. Many existing methods for this task reduce to binary
classiﬁcation problems and employ surrogate losses  such as the hinge loss. We
instead derive uniquely deﬁned surrogate ordinal regression loss functions by
seeking the predictor that is robust to the worst-case approximations of training
data labels  subject to matching certain provided training data statistics. We
demonstrate the advantages of our approach over other surrogate losses based on
hinge loss approximations using UCI ordinal prediction tasks.

1

Introduction

For many classiﬁcation tasks  the discrete class labels being predicted have an inherent order (e.g. 
poor  fair  good  very good  and excellent labels). Confusing two classes that are distant from one
another (e.g.  poor instead of excellent) is more detrimental than confusing two classes that are nearby.
The absolute error  |ˆy − y| between label prediction (ˆy ∈ Y) and actual label (y ∈ Y) is a canonical
ordinal regression loss function. The ordinal regression task seeks class label predictions for new
datapoints that minimize losses of this kind.
Many prevalent methods reduce the ordinal regression task to subtasks solved using existing super-
vised learning techniques. Some view the task from the regression perspective and learn both a linear
regression function and a set of thresholds that deﬁne class boundaries [1–5]. Other methods take a
classiﬁcation perspective and use tools from cost-sensitive classiﬁcation [6–8]. However  since the
absolute error of a predictor on training data is typically a non-convex (and non-continuous) function
of the predictor’s parameters for each of these formulations  surrogate losses that approximate the
absolute error must be optimized instead. Under both perspectives  surrogate losses for ordinal regres-
sion are constructed by transforming the surrogate losses for binary zero-one loss problems—such as
the hinge loss  the logistic loss  and the exponential loss—to take into account the different penalties
of the ordinal regression problem. Empirical evaluations have compared the appropriateness of
different surrogate losses  but these still leave the possibility of undiscovered surrogates that align
better with the ordinal regression loss.
To address these limitations  we seek the most robust [9] ordinal regression predictions by focusing
on the following adversarial formulation of the ordinal regression task: what predictor best minimizes
absolute error in the worst case given partial knowledge of the conditional label distribution? We
answer this question by considering the Nash equilibrium for a game deﬁned by combining the loss
function with Lagrangian potential functions [10]. We derive a surrogate loss function for empirical
risk minimization that realizes this same adversarial predictor. We show that different types of
available knowledge about the conditional label distribution lead to thresholded regression-based
predictions or classiﬁcation-based predictions. In both cases  the surrogate loss is novel compared to
existing surrogate losses. We also show that our surrogate losses enjoy Fisher consistency  a desirable

31st Conference on Neural Information Processing Systems (NIPS 2017)  Long Beach  CA  USA.

theoretical property guaranteeing that minimizing the surrogate loss produces Bayes optimal decisions
for the original loss in the limit. We develop two different approaches for optimizing the loss: a
stochastic optimization of the primal objective and a quadratic program formulation of the dual
objective. The second approach enables us to efﬁciently employ the kernel trick to provide a richer
feature representation without an overly burdensome time complexity. We demonstrate the beneﬁts
of our adversarial formulation over previous ordinal regression methods based on hinge loss for a
range of prediction tasks using UCI datasets.

2 Background and Related Work

2.1 Ordinal Regression Problems



3
2
1
0

0

1
2
3

Table 1: Ordinal re-
gression loss matrix.

X Y ∼P ; ˆY |X∼ ˆP [L ˆY  Y ] = (cid:80)

Ordinal regression is a discrete label prediction problem characterized by
an ordered penalty for making mistakes: loss(ˆy1  y) < loss(ˆy2  y) if y <
ˆy1 < ˆy2 or y > ˆy1 > ˆy2. Though many loss functions possess this property 
the absolute error |ˆy − y| is the most widely studied. We similarly restrict
our consideration to this loss function in this paper. The full loss matrix
L for absolute error with four labels is shown in Table 1. The expected
loss incurred using a probabilistic predictor ˆP (ˆy|x) evaluated on true data
x y ˆy P (x  y) ˆP (ˆy|x)Lˆy y. The supervised
distribution P (x  y) is: E
learning objective for this problem setting is to construct a probabilistic predictor ˆP (ˆy|x) in a way
that minimizes this expected loss using training samples distributed according to the empirical
distribution ˜P (x  y)  which are drawn from the unknown true data generating distribution  P (x  y).
A naïve ordinal regression approach relaxes the task to a continuous prediction problem  minimizes
the least absolute deviation [11]  and then rounds predictions to nearest integral label [12]. More
sophisticated methods range from using a cumulative link model [13] that assumes the cumulative
conditional probability P (Y ≤ j|x) follows a link function  to Bayesian non-parametric approaches
[14] and many others [15–22]. We narrow our focus over this broad range of methods found in the
related work to those that can be viewed as empirical risk minimization methods with piece-wise
convex surrogates  which are more closely related to our approach.

1
0
1
2

2
1
0
1

2.2 Threshold Methods for Ordinal Regression

classiﬁcation problems: lossAT( ˆf   y) =(cid:80)y−1

Threshold methods are one popular family of techniques that treat the ordinal response variable 
ˆf (cid:44) w · x  as a continuous real-valued variable and introduce |Y| − 1 thresholds θ1  θ2  ...  θ|Y|−1
that partition the real line into |Y| segments: θ0 = −∞ < θ1 < θ2 < ... < θ|Y|−1 < θ|Y| = ∞
[4]. Each segment corresponds to a label with ˆyi assigned label j if θj−1 < ˆf ≤ θj. There are two
different approaches for constructing surrogate losses based on the threshold methods to optimize the
choice of w and θ1  . . .   θ|Y|−1: one is based on penalizing all thresholds involved when a mistake is
made and one is based on only penalizing the most immediate thresholds.
All thresholds methods penalize every erroneous threshold using a surrogate loss  δ  for sets of binary
k=y δ(θk − ˆf ). Shashua and Levin
[1] studied the hinge loss under the name of support vector machines with a sum-of margin strategy 
while Chu and Keerthi [2] proposed a similar approach under the name of support vector ordinal
regression with implicit constraints (SVORIM). Lin and Li [3] proposed ordinal regression boosting 
an all thresholds method using the exponential loss as a surrogate. Finally  Rennie and Srebro [4]
proposed a unifying approach for all threshold methods under a variety of surrogate losses.
Rather than penalizing all erroneous thresholds when an error is made  immediate thresholds methods
only penalize the threshold of the true label and the threshold immediately beneath the true label:
lossIT( ˆf   y) = δ(−(θy−1− ˆf )) + δ(θy − ˆf ).1 Similar to the all thresholds methods  immediate thresh-
old methods have also been studied in the literature under different names. For hinge loss surrogates 
Shashua and Levin [1] called the model support vector with ﬁxed-margin strategy while Chu and
Keerthi [2] use the term support vector ordinal regression with explicit constraints (SVOREX). For

k=1 δ(−(θk − ˆf )) +(cid:80)|Y|

1For the boundary labels  the method deﬁnes δ(−(θ0 − ˆf )) = δ(θy+1 − ˆf ) = 0.

2

the exponential loss  Lin and Li [3] introduced ordinal regression boosting with left-right margins.
Rennie and Srebro [4] also proposed a unifying framework for immediate threshold methods.

2.3 Reduction Framework from Ordinal Regression to Binary Classiﬁcation

Li and Lin [5] proposed a reduction framework to convert ordinal regression problems to binary
classiﬁcation problems by extending training examples. For each training sample (x  y)  the reduction
framework creates |Y| − 1 extended samples (x(j)  y(j)) and assigns weight wy j to each extended
sample. The binary label associated with the extended sample is equivalent to the answer of the
question: “is the rank of x greater than j?” The reduction framework allows a choice for how extended
samples x(j) are constructed from original samples x and how to perform binary classiﬁcation. If
the threshold method is used to construct the extended sample and SVM is used as the binary
classiﬁcation algorithm  the classiﬁer can be obtained by solving a family of quadratic optimization
problems that includes SVORIM and SVOREX as special instances.

2.4 Cost-sensitive Classiﬁcation Methods for Ordinal Regression

Rather than using thresholding or the reduction framework  ordinal regression can also be cast as a
special case of cost-sensitive multiclass classiﬁcation. Two of the most popular classiﬁcation-based
ordinal regression techniques are extensions of one-versus-one (OVO) and one-versus-all (OVA) cost-
sensitive classiﬁcation [6  7]. Both algorithms leverage a transformation that converts a cost-sensitive
classiﬁcation problem to a set of weighted binary classiﬁcation problems. Rather than reducing
to binary classiﬁcation  Tu and Lin [8] reduce cost-sensitive classiﬁcation to one-sided regression
(OSR)  which can be viewed as an extension of the one-versus-all (OVA) technique.

2.5 Adversarial Prediction

Foundational results establish a duality between adversarial logarithmic loss minimization and
constrained maximization of the entropy [23]. This takes the form of a zero-sum game between
a predictor seeking to minimize expected logarithmic loss and an adversary seeking to maximize
this same loss. Additionally  the adversary is constrained to choose a distribution that matches
certain sample statistics. Ultimately  through the duality to maximum entropy  this is equivalent
to maximum likelihood estimation of probability distributions that are members of the exponential
family [23]. Grünwald and Dawid [9] emphasize this formulation as a justiﬁcation for the principle of
maximum entropy [24] and generalize the adversarial formulation to other loss functions. Extensions
to multivariate performance measures [25] and non-IID settings [26] have demonstrated the versatility
of this perspective.
Recent analysis [27  28] has shown that for the special case of zero-one loss classiﬁcation  this
adversarial formulation is equivalent to empirical risk minimization with a surrogate loss function:

(cid:88)

j∈S

AL0-1

f (xi  yi) =

max

S⊆{1 ... |Y|} S(cid:54)=∅

(ψj yi(xi) + |S| − 1)/|S| 

(1)

where ψj yi(xi) is the potential difference ψj yi(xi) = fj(xi)− fyi(xi). This surrogate loss function
provides a key theoretical advantage compared to the Crammer-Singer hinge loss surrogate for
multiclass classiﬁcation [29]: it guarantees Fisher consistency [27] while Crammer-Singer—despite
its popularity in many applications  such as Structured SVM [30  31]—does not [32  33]. We extend
this type of analysis to the ordinal regression setting with the absolute error as the loss function in
this paper  producing novel surrogate loss functions that provide better predictions than other convex 
piece-wise linear surrogates.

3 Adversarial Ordinal Regression

3.1 Formulation as a zero-sum game

We seek the ordinal regression predictor that is the most robust to uncertainty given partial knowledge
of the evaluating distribution’s characteristics. This takes the form of a zero-sum game between a
predictor player choosing a predicted label distribution ˆP (ˆy|x) that minimizes loss and an adversarial

3

player choosing an evaluation distribution ˇP (ˇy|x) that maximizes loss while closely matching the
feature-based statistics of the training data:

min
ˆP (ˆy|x)

max
ˇP (ˇy|x)

E
X∼P ; ˆY |X∼ ˆP ; ˇY |X∼ ˇP

such that: E

X∼P ; ˇY |X∼ ˇP [φ(X  ˇY )] = ˜φ.

(2)

(cid:104)(cid:12)(cid:12)(cid:12) ˆY − ˇY

(cid:12)(cid:12)(cid:12)(cid:105)

X Y ∼ ˜P [φ(X  Y )]  is measured from sample training data

The vector of feature moments  ˜φ = E
distributed according to the empirical distribution ˜P (x  y).
An ordinal regression problem can be viewed as a cost-sensitive loss with the entries of the cost
matrix deﬁned by the absolute loss between the row and column labels (an example of the cost
matrix for the case of a problem with four labels is shown in Table 1). Following the construction of
adversarial prediction games for cost-sensitive classiﬁcation [10]  the optimization of Eq. (2) reduces
to minimizing the equilibrium game values of a new set of zero-sum games characterized by matrix
L(cid:48)
xi w:

(cid:125)(cid:124)

(cid:122)

(cid:88)

i

min

w

(cid:124)

max
ˇpxi

min
ˆpxi

(cid:123)(cid:122)

convex optimization of w

zero-sum game
L(cid:48)
xi w ˇpxi

ˆpT
xi

; L(cid:48)

xi w=

(cid:123)
(cid:125)



f1 − fyi
f1 − fyi + 1

...

f1 − fyi + |Y| − 1

···
···
...
···

f|Y| − fyi + |Y| − 1
f|Y| − fyi + |Y| − 2

...

f|Y| − fyi

   (3)

where: w represents a vector of Lagrangian model parameters; fj = w · φ(xi  j) is a Lagrangian
potential; ˆpxi is a vector representation of the conditional label distribution  ˆP ( ˆY = j|xi)  i.e. 
ˆpxi = [ ˆP ( ˆY = 1|xi) ˆP ( ˆY = 2|xi) . . .]T; and ˇpxi is similarly deﬁned. The matrix L(cid:48)
xi w =
(|ˆy − ˇy| + fˇy − fyi) is a zero-sum game matrix for each example. This optimization problem (Eq. (3))
is convex in w and the inner zero-sum game can be solved using a linear program [10]. To address
ﬁnite sample estimation errors  the difference between expected and sample feature can be bounded
in Eq. (2)  ||E
X∼P ; ˇY |X∼ ˇP [φ(X  ˇY )] − ˜φ|| ≤   leading to Lagrangian parameter regularization in
Eq. (3) [34].

3.2 Feature representations

We consider two feature representations corresponding to different training data summaries:



yx

I(y ≤ 1)
I(y ≤ 2)

...

I(y ≤ |Y| − 1)

 ; and



I(y = 1)x
I(y = 2)x
I(y = 3)x

...

I(y = |Y|)x

 .

φth(x  y) =

φmc(x  y) =

(4)

The ﬁrst  which we call the thresholded regression representation 
has size m +|Y|− 1  where m is the dimension of our input space. It
induces a single shared vector of feature weights and a set of thresh-
olds. If we denote the weight vector associated with the yx term as
w and the terms associated with each sum of class indicator func-
tions as θ1  θ2  . . .  θ|Y|−1  then thresholds for switching between
class j and j + 1 (ignoring other classes) occur when w · xi = θj.
The second feature representation  φmc  which we call the multi-
class representation  has size m|Y| and can be equivalently inter-
preted as inducing a set of class-speciﬁc feature weights  fj = wj·xi.
This feature representation is useful when ordered labels cannot be
thresholded according to any single direction in the input space  as
shown in the example dataset of Figure 1.

4

Figure 1: Example where mul-
tiple weight vectors are useful.

3.3 Adversarial Loss from the Nash Equilibrium

We now present the main technical contribution of our paper: a surrogate loss function that  when
minimized  produces a solution to the adversarial ordinal regression problem of Eq. (3).2
Theorem 1. An adversarial ordinal regression predictor is obtained by choosing parameters w that
minimize the empirical risk of the surrogate loss function:

ALord

w (xi  yi) = max

j l∈{1 ... |Y|}

fj + fl + j − l

2

− fyi = max

j

fj + j

2

+ max

l

fl − l
2

− fyi  

(5)

where fj = w · φ(xi  j) for all j ∈ {1  . . .  |Y|}.
Proof sketch. Let j∗  l∗ be the solution of argmaxj l∈{1 ... |Y|} fj +fl+j−l
  we show that the Nash
equilibrium value of a game matrix that contains only row j∗ and l∗ and column j∗ and l∗ from
matrix L(cid:48)
xi w
to the game matrix does not change the game value. Given the resulting closed form solution of the
game (instead of a minimax)  we can recast the adversarial framework for ordinal regression as an
empirical risk minimization with the proposed loss.

. We then show that adding other rows and columns in L(cid:48)

xi w is exactly fj∗  +fl∗ +j∗−l∗

2

2

We note that the ALord
w surrogate is the maximization over pairs of different potential functions
associated with each class (including pairs of identical class labels) added to the distance between the
pair. For both of our feature representations  we make use of the fact that maximization over each
element of the pair can be independently realized  as shown on the right-hand side of Eq. (5).

Thresholded regression surrogate loss
In the thresholded regression feature representation  the parameter contains a single shared vector of
feature weights w and |Y|− 1 terms θk associated with thresholds. Following Eq. (5)  the adversarial
ordinal regression surrogate loss for this feature representation can be written as:

j(w · xi + 1) +(cid:80)

ALord-th(xi  yi) = max

j

k≥j θk

+ max

l

2

l(w · xi − 1) +(cid:80)

k≥l θk

2

− yiw · xi − (cid:88)

k≥yi

θk.

(6)

This loss has a straight-forward interpreta-
tion in terms of the thresholded regression
perspective  as shown in Figure 2:
it is
based on averaging the thresholded label
predictions for potentials w · xi + 1 and
w · xi − 1. This penalization of the pair of
thresholds differs from the thresholded sur-
rogate losses of related work  which either
penalize all violated thresholds or penalize
only the thresholds adjacent to the actual
class label.
Using a binary search procedure over
θ1  . . .   θ|Y|−1  the largest lower bounding
threshold for each of these potentials can
be obtained in O(log |Y|) time.

Multiclass ordinal surrogate loss

Figure 2: Surrogate loss calculation for datapoint xi
(projected to w · xi) with a label prediction of 4 for pre-
dictive purposes  the surrogate loss is instead obtained
using potentials for the classes based on w·xi +1 (label
5) and w · xi − 1 (label 2) averaged together.

In the multiclass feature representation  we have a set of speciﬁc feature weights wj for each label
and the adversarial multiclass ordinal surrogate loss can be written as:

ALord-mc(xi  yi) =

max

j l∈{1 ... |Y|}

2

wj · xi + wl · xi + j − l

− wyi · xi.

(7)

2The detailed proof of this theorem and others are contained in the supplementary materials. Proof sketches

are presented in the main paper.

5

(a)

(b)

(c)

Figure 3: Loss function contour plots of ALord over the space of potential differences ψj (cid:44) fj − fyi
for the prediction task with three classes when the true label is yi = 1 (a)  yi = 2 (b)  and yi = 3 (c).

We can also view this as the maximization over |Y|(|Y| + 1)/2 linear hyperplanes. For an ordinal
regression problem with three classes  the loss has six facets with different shapes for each true label
value  as shown in Figure 3. In contrast with ALord-th  the class label potentials for ALord-mc may
differ from one another in more-or-less arbitrary ways. Thus  searching for the maximal j and l class
labels requires O(|Y|) time.

3.4 Consistency Properties

The behavior of a prediction method in ideal learning settings—i.e.  trained on the true evaluation
distribution and given an arbitrarily rich feature representation  or  equivalently  considering the space
of all measurable functions—provides a useful theoretical validation. Fisher consistency requires that
the prediction model yields the Bayes optimal decision boundary [32  33  35] in this setting. Given
the true label conditional probability Pj(x) (cid:44) P (Y = j|x)  a surrogate loss function δ is said to
be Fisher consistent with respect to the loss (cid:96) if the minimizer f∗ of the surrogate loss achieves the
Bayes optimal risk  i.e. :

EY |X∼P [δf (X  Y )|X = x]
f∗ = argmin
⇒ EY |X∼P [(cid:96)f∗ (X  Y )|X = x] = min

f

f

EY |X∼P [(cid:96)f (X  Y )|X = x] .

(8)

Ramaswamy and Agarwal [36] provide a necessary and sufﬁcient condition for a surrogate loss to be
Fisher consistent with respect to general multiclass losses  which includes ordinal regression losses.
A recent analysis by Pedregosa et al. [35] shows that the all thresholds and the immediate thresholds
methods are Fisher consistent provided that the base binary surrogates losses they use are convex
with a negative derivative at zero.
For our proposed approach  the condition for Fisher consistency above is equivalent to:

∗

f

= argmin

f

y

Py

max

j l

fj + fl + j − l

2

− fy

⇒ argmax

f

j

j (x) ⊆ argmin
∗

j

Py |j − y| .

(9)

(cid:88)

(cid:20)

(cid:21)

(cid:88)

y

Since adding a constant to all fj does not change the value of both ALord
and argmaxj fj(x)  we
employ the constraint maxj fj(x) = 0  to remove redundant solutions for the consistency analysis.
We establish an important property of the minimizer for ALord
f
Theorem 2. The minimizer vector f∗ of EY |X∼P
property  i.e.  it complements the absolute error by starting with a negative integer value  then
increasing by one until reaching zero  and then incrementally decreases again.

(cid:2)ALord
f (X  Y )|X = x(cid:3) satisﬁes the loss reﬂective

in the following theorem.

f

Proof sketch. We show that for any f 0 that does not satisfy the loss reﬂective property  we can
construct f 1 using several steps that satisfy the loss reﬂective property and has the expected loss value
less than the expected loss of f 0.

6

Example vectors f∗ that satisfy Theorem 2 are [0 −1 −2]T  [−1  0 −1]T and [−2 −1  0]T for
three-class problems  and [−3 −2 −1  0 −1] for ﬁve-class problems. Using the key property of the
minimizer above  we establish the consistency of our loss functions in the following theorem.
Theorem 3. The adversarial ordinal regression surrogate loss ALord from Eq. (5) is Fisher consistent.
Proof sketch. We only consider |Y| possible values of f that satisfy the loss reﬂective property. For
the f that corresponds to class j  the value of the expected loss is equal to the Bayes loss if we predict
j as the label. Therefore minimizing over f that satisfy the loss reﬂective property is equivalent to
ﬁnding the Bayes optimal response.

3.5 Optimization

3.5.1 Primal Optimization

To optimize the regularized adversarial ordinal regression loss from the primal  we employ stochastic
average gradient (SAG) methods [37  38]  which have been shown to converge faster than standard
stochastic gradient optimization. The idea of SAG is to use the gradient of each example from the last
iteration where it was selected to take a step. However  the naïve implementation of SAG requires
storing the gradient of each sample  which may be expensive in terms of the memory requirements.
Fortunately  for our loss ALord
w   we can drastically reduce this memory requirement by just storing a
pair of number  (j∗  l∗) = argmaxj l∈{1 ... |Y|} fj +fl+j−l
  rather than storing the gradient for each
sample. Appendix C explains the details of this technique.

2

3.5.2 Dual Optimization
Dual optimization is often preferred when optimizing piecewise linear losses  such as the hinge loss 
since it enables one to easily perform the kernel trick and obtain a non-linear decision boundary
without heavily sacriﬁcing computational efﬁciency. Optimizing the regularized adversarial ordinal
regression loss in the dual can be performed by solving the following quadratic optimization:

(αi j + βi j) (αk l + βk l) (φ(xi  j) − φ(xi  yi)) · (φ(xk  l) − φ(xl  yk))

(cid:88)

max
α β

j(αi j − βi j) − 1
2
subject to: αi j ≥ 0; βi j ≥ 0;

i j

(cid:88)
(cid:88)

i j k l

(cid:88)

αi j = C
2 ;

βi j = C

2 ; i  k ∈ {1  . . .   n}; j  l ∈ {1  . . .  |Y|}.

(10)

j

j

Note that our dual formulation only depends on the dot product of the features. Therefore  we can
also easily apply the kernel trick to our algorithm. Appendix D describes the derivation from the
primal optimization to the dual optimization above.

4 Experiments

4.1 Experiment Setup

Table 2: Dataset properties.

We conduct our experiments on a benchmark
dataset for ordinal regression [14]  evaluate the
performance using mean absolute error (MAE) 
and perform statistical tests on the results of dif-
ferent hinge loss surrogate methods. The bench-
mark contains datasets taken from the UCI Ma-
chine Learning repository [39] ranging from rel-
atively small to relatively large in size. The char-
acteristics of the datasets  including the number
of classes  the training set size  the testing set
size  and the number of features  are described
in Table 2.
In the experiment  we consider different methods using the original feature space and a kernelized
feature space using the Gaussian radial basis function kernel. The methods that we compare include
two variations of our approach  the threshold based (ALord-th)  and the multiclass-based (ALord-mc).

#test #features
2
27
60
32
6
7
13
9
10
8
21
8

Dataset
diabetes
pyrimidines
triazines
wisconsin
machinecpu
autompg
boston
stocks
abalone
bank
computer
calhousing

#train
30
51
130
135
146
274
354
665
2923
5734
5734
14447

#class
5
5
5
5
10
10
5
5
10
10
10
10

13
23
56
59
63
118
152
285
1254
2458
2458
6193

7

Table 3: The average of the mean absolute error (MAE) for each model. Bold numbers in each case
indicate that the result is the best or not signiﬁcantly worse than the best (paired t-test with α = 0.05).

Dataset

diabetes
pyrimidines
triazines
wisconsin
machinecpu
autompg
boston
stocks
abalone
bank
computer
calhousing
average
# bold

Threshold-based models

Multiclass-based models

ALord-th
0.696
0.654
0.607
1.077
0.449
0.551
0.316
0.324
0.551
0.461
0.640
1.190
0.626
5

REDth
0.715
0.678
0.683
1.067
0.456
0.550
0.304
0.317
0.547
0.460
0.635
1.183
0.633
5

AT
0.731
0.615
0.649
1.097
0.458
0.550
0.306
0.315
0.546
0.461
0.633
1.182
0.629
4

IT

0.827
0.626
0.654
1.175
0.467
0.617
0.298
0.324
0.571
0.461
0.683
1.225
0.661
2

ALord-mc
0.629
0.509
0.670
1.136
0.518
0.599
0.311
0.168
0.521
0.445
0.625
1.164
0.613
5

REDmc
0.700
0.565
0.673
1.141
0.515
0.602
0.311
0.175
0.520
0.446
0.624
1.144
0.618
5

CSOSR CSOVO CSOVA

0.715
0.520
0.677
1.208
0.646
0.741
0.353
0.204
0.545
0.732
0.889
1.237
0.706
2

0.738
0.576
0.738
1.275
0.602
0.598
0.294
0.147
0.558
0.448
0.649
1.202
0.652
2

0.762
0.526
0.732
1.338
0.702
0.731
0.363
0.213
0.556
0.989
1.055
1.601
0.797
1

The baselines we use for the threshold-based models include a SVM-based reduction framework
algorithm (REDth) [5]  an all threshold method with hinge loss (AT) [1  2]  and an immediate threshold
method with hinge loss (IT) [1  2]. For the multiclass-based models  we compare our method with an
SVM-based reduction algorithm using multiclass features (REDmc) [5]  with cost-sensitive one-sided
support vector regression (CSOSR) [8]  with cost-sensitive one-versus-one SVM (CSOVO) [7]  and
with cost-sensitive one-versus-all SVM (CSOVA) [6]. For our Gaussian kernel experiment  we
compare our threshold based model (ALord-th) with SVORIM and SVOREX [2].
In our experiments  we ﬁrst make 20 random splits of each dataset into training and testing sets. We
performed two stages of ﬁve-fold cross validation on the ﬁrst split training set for tuning each model’s
regularization constant λ. In the ﬁrst stage  the possible values for λ are 2−i  i = {1  3  5  7  9  11  13}.
Using the best λ in the ﬁrst stage  we set the possible values for λ in the second stage as 2 i
2 λ0  i =
{−3 −2 −1  0  1  2  3}  where λ0 is the best parameter obtained in the ﬁrst stage. Using the selected
parameter from the second stage  we train each model on the 20 training sets and evaluate the MAE
performance on the corresponding testing set. We then perform a statistical test to ﬁnd whether the
performance of a model is different with statistical signiﬁcance from other models. We perform the
Gaussian kernel experiment similarly with model parameter C equals to 2i  i = {0  3  6  9  12} and
kernel parameter γ equals to 2i  i = {−12 −9 −6 −3  0} in the ﬁrst stage. In the second stage  we
set C equals to 2iC0  i = {−2 −1  0  1  2} and γ equals to 2iγ0  i = {−2 −1  0  1  2}  where C0
and γ0 are the best parameters obtained in the ﬁrst stage.

4.2 Results

We report the mean absolute error (MAE) averaged over the dataset splits as shown in Table 3 and
Table 4. We highlight the result that is either the best or not worse than the best with statistical
signiﬁcance (under paired t-test with α = 0.05) in boldface font. We also provide the summary for
each model in terms of the averaged MAE over all datasets and the number of datasets for which
each model marked with boldface font in the bottom of the table.
As we can see from Table 3  in the experiment with the original feature space  threshold-based
models perform well on relatively small datasets  whereas multiclass-based models perform well on
relatively large datasets. A possible explanation for this result is that multiclass-based models have
more ﬂexibility in creating decision boundaries  hence they perform better if the training data size is
sufﬁcient. However  since multiclass-based models have many more parameters than threshold-based
models (m|Y| parameters rather than m + |Y| − 1 parameters)  multiclass methods may need more
data  and hence  may not perform well on relatively small datasets.
In the threshold-based models comparison  ALord-th  REDth  and AT perform competitively on
relatively small datasets like triazines  wisconsin  machinecpu  and autompg. ALord-th has a

8

Table 4: The average of MAE for models with
Gaussian kernel.

slight advantage over REDth on the overall accuracy  and a slight advantage over AT on the number
of “indistinguishably best” performance on all datasets. We can also see that AT is superior to IT in
the experiments under the original feature space.
Among the multiclass-based models  ALord-mc
and REDmc perform competitively on datasets
like abalone  bank  and computer  with a
slight advantage of ALord-mc model on the over-
all accuracy. In general  the cost-sensitive mod-
els perform poorly compared with ALord-mc and
REDmc. A notable exception is the CSOVO
model which perform very well on the stocks
and the boston datasets.
In the Gaussian kernel experiment  we can see
from Table 4 that the kernelized version of
ALord-th performs signiﬁcantly better than the
threshold-based models SVORIM and SVOREX
in terms of both the overall accuracy and the
number of “indistinguishably best” performance
on all datasets. We also note that immediate-threshold-based model (SVOREX) performs better than
all-threshold-based model (SVORIM) in our experiment using Gaussian kernel. We can conclude
that our proposed adversarial losses for ordinal regression perform competitively compared to the
state-of-the-art ordinal regression models using both original feature spaces and kernel feature spaces
with a signiﬁcant performance improvement in the Gaussian kernel experiments.

SVORIM SVOREX
0688
0.550
0.604
1.049
0.628
0.593
0.316
0.100
0.566
4

Dataset
diabetes
pyrimidines
triazines
wisconsin
machinecpu
autompg
boston
stocks
average
# bold

ALord-th
0.696
0.478
0.609
1.090
0.452
0.529
0.278
0.103
0.531
7

0.665
0.539
0.612
1.113
0.652
0.589
0.324
0.099
0.574
3

5 Conclusion and Future Work

In this paper  we have proposed a novel surrogate loss for ordinal regression  a classiﬁcation problem
where the discrete class labels have an inherent order and penalty for making mistakes based on that
order. We focused on the absolute loss  which is the most widely used ordinal regression loss. In
contrast with existing methods  which typically reduce ordinal regression to binary classiﬁcation
problems and then employ surrogates for the binary zero-one loss  we derive a unique surrogate
ordinal regression loss by seeking the predictor that is robust to a worst case constrained approx-
imation of the training data. We derived two versions of the loss based on two different feature
representation approaches: thresholded regression and multiclass representations. We demonstrated
the beneﬁt of our approach on a benchmark of datasets for ordinal regression tasks. Our approach
performs competitively compared to the state-of-the-art surrogate losses based on hinge loss. We
also demonstrated cases when the multiclass feature representations works better than thresholded
regression representation  and vice-versa  in our experiments.
Our future work will investigate less prevalent ordinal regression losses  such as the discrete quadratic
loss and arbitrary losses that have v-shaped penalties. Furthermore  we plan to investigate the
characteristics required of discrete ordinal losses for their optimization to have a compact analytical
solution. In terms of applications  one possible direction of future work is to combine our approach
with deep neural network models to perform end-to-end representation learning for ordinal regression
applications like age estimation and rating prediction. In that setting  our proposed loss can be used
in the last layer of a deep neural network to serve as the gradient source for the backpropagation
algorithm.

Acknowledgments

This research was supported as part of the Future of Life Institute (futureoﬂife.org) FLI-RFP-AI1
program  grant#2016-158710 and by NSF grant RI-#1526379.

9

References

[1] Amnon Shashua and Anat Levin. Ranking with large margin principle: Two approaches. In

Advances in Neural Information Processing Systems 15  pages 961–968. MIT Press  2003.

[2] Wei Chu and S Sathiya Keerthi. New approaches to support vector ordinal regression. In
Proceedings of the 22nd international conference on Machine learning  pages 145–152. ACM 
2005.

[3] Hsuan-Tien Lin and Ling Li. Large-margin thresholded ensembles for ordinal regression:
Theory and practice. In International Conference on Algorithmic Learning Theory  pages
319–333. Springer  2006.

[4] Jason D. M. Rennie and Nathan Srebro. Loss functions for preference levels: Regression with
discrete ordered labels. In Proceedings of the IJCAI Multidisciplinary Workshop on Advances
in Preference Handling  pages 180–186  2005.

[5] Ling Li and Hsuan-Tien Lin. Ordinal regression by extended binary classiﬁcation. Advances in

neural information processing systems  19:865  2007.

[6] Hsuan-Tien Lin. From ordinal ranking to binary classiﬁcation. PhD thesis  California Institute

of Technology  2008.

[7] Hsuan-Tien Lin. Reduction from cost-sensitive multiclass classiﬁcation to one-versus-one
binary classiﬁcation. In Proceedings of the Sixth Asian Conference on Machine Learning  pages
371–386  2014.

[8] Han-Hsing Tu and Hsuan-Tien Lin. One-sided support vector regression for multiclass cost-
In Proceedings of the 27th International Conference on Machine

sensitive classiﬁcation.
Learning (ICML-10)  pages 1095–1102  2010.

[9] Peter D. Grünwald and A. Phillip Dawid. Game theory  maximum entropy  minimum discrep-

ancy  and robust Bayesian decision theory. Annals of Statistics  32:1367–1433  2004.

[10] Kaiser Asif  Wei Xing  Sima Behpour  and Brian D. Ziebart. Adversarial cost-sensitive classiﬁ-

cation. In Proceedings of the Conference on Uncertainty in Artiﬁcial Intelligence  2015.

[11] Subhash C Narula and John F Wellington. The minimum sum of absolute errors regression:
A state of the art survey. International Statistical Review/Revue Internationale de Statistique 
pages 317–326  1982.

[12] Koby Crammer and Yoram Singer. Pranking with ranking. In Advances in Neural Information

Processing Systems 14  2001.

[13] Peter McCullagh. Regression models for ordinal data. Journal of the royal statistical society.

Series B (Methodological)  pages 109–142  1980.

[14] Wei Chu and Zoubin Ghahramani. Gaussian processes for ordinal regression. Journal of

Machine Learning Research  6(Jul):1019–1041  2005.

[15] Krzysztof Dembczy´nski  Wojciech Kotłowski  and Roman Słowi´nski. Ordinal classiﬁcation
with decision rules. In International Workshop on Mining Complex Data  pages 169–181.
Springer  2007.

[16] Mark J Mathieson. Ordinal models for neural networks. Neural networks in ﬁnancial engineer-

ing  pages 523–536  1996.

[17] Shipeng Yu  Kai Yu  Volker Tresp  and Hans-Peter Kriegel. Collaborative ordinal regression.
In Proceedings of the 23rd international conference on Machine learning  pages 1089–1096.
ACM  2006.

[18] Jianlin Cheng  Zheng Wang  and Gianluca Pollastri. A neural network approach to ordinal
regression. In Neural Networks  2008. IJCNN 2008.(IEEE World Congress on Computational
Intelligence). IEEE International Joint Conference on  pages 1279–1284. IEEE  2008.

[19] Wan-Yu Deng  Qing-Hua Zheng  Shiguo Lian  Lin Chen  and Xin Wang. Ordinal extreme

learning machine. Neurocomputing  74(1):447–456  2010.

10

[20] Bing-Yu Sun  Jiuyong Li  Desheng Dash Wu  Xiao-Ming Zhang  and Wen-Bo Li. Kernel
IEEE Transactions on Knowledge and Data

discriminant learning for ordinal regression.
Engineering  22(6):906–910  2010.

[21] Jaime S Cardoso and Joaquim F Costa. Learning to classify ordinal data: The data replication

method. Journal of Machine Learning Research  8(Jul):1393–1429  2007.

[22] Yang Liu  Yan Liu  and Keith CC Chan. Ordinal regression via manifold learning. In Pro-
ceedings of the Twenty-Fifth AAAI Conference on Artiﬁcial Intelligence  pages 398–403. AAAI
Press  2011.

[23] Flemming Topsøe. Information theoretical optimization techniques. Kybernetika  15(1):8–27 

1979.

[24] Edwin T Jaynes. Information theory and statistical mechanics. Physical review  106(4):620–630 

1957.

[25] Hong Wang  Wei Xing  Kaiser Asif  and Brian Ziebart. Adversarial prediction games for
multivariate losses. In Advances in Neural Information Processing Systems  pages 2710–2718 
2015.

[26] Anqi Liu and Brian Ziebart. Robust classiﬁcation under sample selection bias. In Advances in

Neural Information Processing Systems  pages 37–45  2014.

[27] Rizal Fathony  Anqi Liu  Kaiser Asif  and Brian Ziebart. Adversarial multiclass classiﬁcation:
A risk minimization perspective. In Advances in Neural Information Processing Systems 29 
pages 559–567. 2016.

[28] Farzan Farnia and David Tse. A minimax approach to supervised learning. In Advances in

Neural Information Processing Systems  pages 4233–4241. 2016.

[29] Koby Crammer and Yoram Singer. On the algorithmic implementation of multiclass kernel-

based vector machines. The Journal of Machine Learning Research  2:265–292  2002.

[30] Ioannis Tsochantaridis  Thorsten Joachims  Thomas Hofmann  and Yasemin Altun. Large
margin methods for structured and interdependent output variables. In JMLR  pages 1453–1484 
2005.

[31] Thorsten Joachims. A support vector method for multivariate performance measures.
Proceedings of the International Conference on Machine Learning  pages 377–384  2005.

In

[32] Ambuj Tewari and Peter L Bartlett. On the consistency of multiclass classiﬁcation methods.

The Journal of Machine Learning Research  8:1007–1025  2007.

[33] Yufeng Liu. Fisher consistency of multicategory support vector machines. In International

Conference on Artiﬁcial Intelligence and Statistics  pages 291–298  2007.

[34] Miroslav Dudík and Robert E Schapire. Maximum entropy distribution estimation with gener-
alized regularization. In International Conference on Computational Learning Theory  pages
123–138. Springer  2006.

[35] Fabian Pedregosa  Francis Bach  and Alexandre Gramfort. On the consistency of ordinal

regression methods. Journal of Machine Learning Research  18(55):1–35  2017.

[36] Harish G Ramaswamy and Shivani Agarwal. Classiﬁcation calibration dimension for general
multiclass losses. In Advances in Neural Information Processing Systems  pages 2078–2086 
2012.

[37] Mark Schmidt  Nicolas Le Roux  and Francis Bach. Minimizing ﬁnite sums with the stochastic

average gradient. Mathematical Programming  pages 1–30  2013.

[38] Mark Schmidt  Reza Babanezhad  Aaron Defazio  Ann Clifton  and Anoop Sarkar. Non-uniform

stochastic average gradient method for training conditional random ﬁelds. 2015.

[39] M. Lichman. UCI machine learning repository  2013. URL http://archive.ics.uci.edu/

ml.

11

,Conghui Tan
Shiqian Ma
Yuqiu Qian
Rizal Fathony
Mohammad Ali Bashiri
Brian Ziebart