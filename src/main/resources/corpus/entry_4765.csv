2013,Robust Multimodal Graph Matching: Sparse Coding Meets Graph Matching,Graph matching is a challenging problem with very important applications in a wide range of fields  from image and video analysis to biological and biomedical problems. We propose a robust graph matching algorithm inspired in sparsity-related techniques. We cast the problem  resembling group or collaborative sparsity formulations  as a non-smooth convex optimization problem that can be efficiently solved using augmented Lagrangian techniques. The method can deal with weighted or unweighted graphs  as well as multimodal data  where different graphs represent different types of data. The proposed approach is also naturally integrated with collaborative graph inference techniques  solving general network inference problems where the observed variables  possibly coming from different modalities  are not in correspondence. The algorithm is tested and compared with state-of-the-art graph matching techniques in both synthetic and real graphs. We also present results on multimodal graphs and applications to collaborative inference of brain connectivity from alignment-free functional magnetic resonance imaging (fMRI) data.,Robust Multimodal Graph Matching:
Sparse Coding Meets Graph Matching

Marcelo Fiori
Universidad de la
Rep´ublica  Uruguay

mfiori@fing.edu.uy

Pablo Sprechmann

Duke University

Durham  NC 27708

pablo.sprechmann@duke.edu

Joshua Vogelstein
Duke University

Durham  NC 27708

jovo@math.duke.edu

Pablo Mus´e

Universidad de la
Rep´ublica  Uruguay

pmuse@fing.edu.uy

Guillermo Sapiro
Duke University

Durham  NC 27708

guillermo.sapiro@duke.edu

Abstract

Graph matching is a challenging problem with very important applications in a
wide range of ﬁelds  from image and video analysis to biological and biomedical
problems. We propose a robust graph matching algorithm inspired in sparsity-
related techniques. We cast the problem  resembling group or collaborative spar-
sity formulations  as a non-smooth convex optimization problem that can be ef-
ﬁciently solved using augmented Lagrangian techniques. The method can deal
with weighted or unweighted graphs  as well as multimodal data  where different
graphs represent different types of data. The proposed approach is also naturally
integrated with collaborative graph inference techniques  solving general network
inference problems where the observed variables  possibly coming from differ-
ent modalities  are not in correspondence. The algorithm is tested and compared
with state-of-the-art graph matching techniques in both synthetic and real graphs.
We also present results on multimodal graphs and applications to collaborative in-
ference of brain connectivity from alignment-free functional magnetic resonance
imaging (fMRI) data. The code is publicly available.

Introduction

1
Problems related to graph isomorphisms have been an important and enjoyable challenge for the
scientiﬁc community for a long time. The graph isomorphism problem itself consists in determining
whether two given graphs are isomorphic or not  that is  if there exists an edge preserving bijection
between the vertex sets of the graphs. This problem is also very interesting from the computational
complexity point of view  since its complexity level is still unsolved: it is one of the few problems in
NP not yet classiﬁed as P nor NP-complete (Conte et al.  2004). The graph isomorphism problem is
contained in the (harder) graph matching problem  which consists in ﬁnding the exact isomorphism
between two graphs. Graph matching is therefore a very challenging problem which has several
applications  e.g.  in the pattern recognition and computer vision areas. In this paper we address the
problem of (potentially multimodal) graph matching when the graphs are not exactly isomorphic.
This is by far the most common scenario in real applications  since the graphs to be compared are
the result of a measuring or description process  which is naturally affected by noise.
Given two graphs GA and GB with p vertices  which we will characterize in terms of their p × p
adjacency matrices A and B  the graph matching problem consists in ﬁnding a correspondence
between the nodes of GA and GB minimizing some matching error.
In terms of the adjacency
matrices  this corresponds to ﬁnding a matrix P in the set of permutation matrices P  such that
it minimizes some distance between A and PBPT. A common choice is the Frobenius norm
||A − PBPT||2

ij. The graph matching problem can be then stated as

F =(cid:80)
P∈P ||A − PBPT||2

ij M2

F   where ||M||2
min

F = min

P∈P ||AP − PB||2
F .

(1)

1

The combinatorial nature of the permutation search makes this problem NP in general  although
polynomial algorithms have been developed for a few special types of graphs  like trees or planar
graphs for example (Conte et al.  2004).
There are several and diverse techniques addressing the graph matching problem  including spectral
methods (Umeyama  1988) and problem relaxations (Zaslavskiy et al.  2009; Vogelstein et al.  2012;
Almohamad & Duffuaa  1993). A good review of the most common approaches can be found in
Conte et al. (2004). In this paper we focus on the relaxation techniques for solving an approximate
version of the problem. Maybe the simplest one is to relax the feasible set (the permutation matrices)
to its convex hull  the set of doubly stochastic matrices D  which consist of the matrices with non-
negative entries such that each row and column sum up one: D = {M ∈ Rp×p : Mij ≥ 0  M1 =
1  MT 1 = 1}  1 being the p-dimensional vector of ones. The relaxed version of the problem is

ˆP = arg min

P∈D ||AP − PB||2
F  

which is a convex problem  though the result is a doubly stochastic matrix instead of a per-
mutation. The ﬁnal node correspondence is obtained as the closest permutation matrix to ˆP:
P∗ = arg minP∈P ||P− ˆP||2
F   which is a linear assignment problem that can be solved in O(p3) by
the Hungarian algorithm (Kuhn  1955). However  this last step lacks any guarantee about the graph
matching problem itself. This approach will be referred to as QCP for quadratic convex problem.
One of the newest approximate methods is the PATH algorithm by Zaslavskiy et al. (2009)  which
combines this convex relaxation with a concave relaxation. Another new technique is the FAQ
method by Vogelstein et al. (2012)  which solves a relaxed version of the Quadratic Assignment
Problem. We compare the method here proposed to all these techniques in the experimental section.
The main contributions of this work are two-fold. Firstly  we propose a new and versatile formu-
lation for the graph matching problem which is more robust to noise and can naturally manage
multimodal data. The technique  which we call GLAG for Group lasso graph matching  is inspired
by the recent works on sparse modeling  and in particular group and collaborative sparse coding.
We present several experimental evaluations to back up these claims. Secondly  this proposed for-
mulation ﬁts very naturally into the alignment-free collaborative network inference problem  where
we collaborative exploit non-aligned (possibly multimodal) data to infer the underlying common
network  making this application never addressed before to the best of our knowledge. We assess
this with experiments using real fMRI data.
The rest of this paper is organized as follows. In Section 2 we present the proposed graph matching
formulation  and we show how to solve the optimization problem in Section 3. The joint collabo-
rative network and permutation learning application is described in Section 4. Experimental results
are presented in Section 5  and we conclude in Section 6.

2 Graph matching formulation

We consider the problem of matching two graphs that are not necessarily perfectly isomorphic. We
will assume the following model: Assume that we have a noise free graph characterized by an
adjacency matrix T. Then we want to match two graphs with adjacency matrices A = T + OA and
o TPo + OB  where OA and OB have a sparse number of non-zero elements of arbitrary
B = PT
magnitude. This realistic model is often used in experimental settings  e.g.  (Zaslavskiy et al.  2009).
In this context  the QCP formulation tends to ﬁnd a doubly stochastic matrix P which minimizes the
“average error” between AP and PB. However  these spurious mismatching edges can be thought
of as outliers  so we would want a metric promoting that AP and PB share the same active set (non
zero entries representing edges)  with the exception of some sparse entries. This can be formulated
in terms of the group Lasso penalization (Yuan & Lin  2006). In short  the group Lasso takes a set
of groups of coefﬁcients and promotes that only some of these groups are active  while the others
remain zero. Moreover  the usual behavior is that when a group is active  all the coefﬁcients in the
group are non-zero. In this particular graph matching application  we form p2 groups  one per matrix

entry (i  j)  each one consisting of the 2-dimensional vector(cid:0)(AP)ij  (PB)ij

(cid:1). The proposed cost

function is then the sum of the l2 norms of the groups:

(2)

(cid:88)

f (P ) =

(cid:12)(cid:12)(cid:12)(cid:12)(cid:0)(AP)ij  (PB)ij

(cid:1)(cid:12)(cid:12)(cid:12)(cid:12)2 .

i j

2

Ideally we would like to solve the graph matching problem by ﬁnding the minimum of f over the
set of permutation matrices P. Of course this formulation is still computationally intractable  so we
solve the relaxed version  changing P by its convex hull D  resulting in the convex problem

˜P = arg min

P∈D f (P).

(3)

As with the Frobenius formulation  the ﬁnal step simply ﬁnds the closest permutation matrix to ˜P.
Let us analyze the case when A and B are the adjacency matrices of two isomorphic undirected
unweighted graphs with e edges and no self-loops. Since the graphs are isomorphic  there exist a
o .
permutation matrix Po such that A = PoBPT
√
Lemma 1 Under the conditions stated above  the minimum value of the optimization problem (3)
2e and it is reached by Po  although the solution is not unique in general. Moreover  any
is 2
solution P of problem (3) satisﬁes AP = PB.

Proof: Let (a)k denote all the p2 entries of AP  and (b)k all the entries of PB. Then f (P) can be

re-written as f (P) =(cid:80)

(cid:112)a2
a2 + b2 ≥ √

k

Observing that

√

k .

k + b2
2 (a + b)  we have
2

(cid:88)

(cid:113)

a2
k + b2

k ≥ (cid:88)

f (P ) =

√

2
2

(4)

(ak + bk) .

k

k

2e.

k ak = (cid:80)

the entries of A  which is two times the number of edges. Therefore(cid:80)

Now  since P is doubly stochastic  the sum of all the entries of AP is equal to the sum of all
√
k bk = 2e and
f (P) ≥ 2
The equality in (4) holds if and only if ak = bk for all k  which means that AP = PB. In particular 
(cid:3)
this is true for the permutation Po  which completes the proof of all the statements.
This Lemma shows that the fact that the weights in A and B are not compared in magnitude does
not affect the matching performance when the two graphs are isomorphic and have equal weights.
On the other hand  this property places a fundamental role when moving away from this setting.
Indeed  since the group lasso tends to set complete groups to zero  and the actual value of the
non-zero coefﬁcients is less important  this allows to group very dissimilar coefﬁcients together 
if that would result in fewer active groups. This is even more evident when using the l∞ norm
instead of the l2 norm of the groups  and the optimization remains very similar to the one presented
below. Moreover  the formulation remains valid when both graphs come from different modalities 
a fundamental property when for example addressing alignment-free collaborative graph inference
as presented in Section 4 (the elegance with which this graph matching formulation ﬁts into such
problem will be further stressed there). In contrast  the Frobenious-based approaches mentioned
in the introduction are very susceptible to differences in edge magnitudes and not appropriate for
multimodal matching1.

3 Optimization
The proposed minimization problem (3) is convex but non-differentiable. Here we use an efﬁcient
variant of the Alternating Direction Method of Multipliers (ADMM) (Bertsekas & Tsitsiklis  1989).
The idea is to write the optimization problem as an equivalent artiﬁcially constrained problem  using
two new variables α  β ∈ Rp×p:

s.t. α = AP  β = PB.

(5)

The ADMOM method generates a sequence which converges to the minimum of the augmented
Lagrangian of the problem:

L(P  α  β  U  V) =

||α − AP + U||2 +

||β − PB + V||2  

c
2

1If both graphs are binary and we limit to permutation matrices (for which there are no algorithms known to
ﬁnd the solution in polynomial time)  then the minimizers of (2) and (1) are the same (Vince Lyzinski  personal
communication).

3

min
P∈D

(cid:88)
||(cid:0)αij  βij
(cid:1)||2
(cid:88)
(cid:1)||2 +
||(cid:0)αij  βij

i j

i j

c
2

where U and V are related to the Lagrange multipliers and c is a ﬁxed constant.
The decoupling produced by the new artiﬁcial variables allows to update their values one at a time 
minimizing the augmented Lagrangian L. We ﬁrst update the pair (α  β) while keeping ﬁxed
(P  U  V); then we minimize for P; and ﬁnally update U and V  as described next in Algorithm 1.

: Adjacency matrices A  B  c > 0.

Input
Output: Permutation matrix P∗
Initialize U = 0  V = 0  P = 1
while stopping criterion is not satisﬁed do

p 1T 1

(αt+1  βt+1) = arg minα β
Pt+1 = arg minP∈D 1
Ut+1 = Ut + αt+1 − APt+1
Vt+1 = Vt + βt+1 − Pt+1B

i j ||(cid:0)αij  βij
(cid:80)

(cid:1)||2 + c

2||αt+1 − AP + Ut||2

F + 1

2||α − APt + Ut||2
2||βt+1 − PB + Vt||2

F

F + c

2||β − PtB + Vt||2

F

end
P∗ = argminQ∈P ||Q − P||2
Algorithm 1: Robust graph matching algorithm. See text for implementation details of each step.

F

The ﬁrst subproblem is decomposable into p2 scalar problems (one for each matrix entry) 
ij)2.

(βij − (PtB)ij + Vt

(αij − (APt)ij + Ut

ij)2 +

min
αij  βij

c
2

From the optimality conditions on the subgradient of this subproblem  it can be seen that this can
be solved in closed form by means of the well know vector soft-thresholding operator (Yuan & Lin 
2006): Sv(b  λ) =

b .

||(cid:0)αij  βij
(cid:104)
1 − λ||b||2

(cid:1)||2 +
(cid:105)

+

c
2

The second subproblem is a minimization of a convex differentiable function over a convex set  so
general solvers can be chosen for this task. For instance  a projected gradient descent method can
be used. However  this would require to compute several projections onto D per iteration  which is
one of the computationally most expensive steps. Nevertheless  we can choose to solve a linearized
version of the problem while keeping the convergence guarantees of the algorithm (Lin et al.  2011).
In this case  the linear approximation of the ﬁrst term is:
||αt+1 − APk + Ut||2

||αt+1 − AP + Ut||2

F + (cid:104)gk  P − Pk(cid:105) +

||P − Pk||2
F  

where gk = −AT(αt+1 + Ut − APk) is the gradient of the linearized term  (cid:104)· ·(cid:105) is the usual inner
  with ρ(·) being the spectral norm.
product of matrices  and τ is any constant such that τ <

1

F ≈ 1
2

1
2τ

1
2

The second term can be linearized analogously  so the minimization of the second step becomes

min
P∈D

1
2

||P−(cid:0)Pk + τ AT(αt+1 + Ut − APk)(cid:1)
(cid:125)
(cid:124)
2 (C + D) over D.

||2
F +

ﬁxed matrix C

(cid:123)(cid:122)

which is simply the projection of the matrix 1

(cid:124)

1
2

ρ(ATA)

||P−(cid:0)Pk + τ (βt+1 + Vt − PkB)BT(cid:1)
(cid:125)

(cid:123)(cid:122)

ﬁxed matrix D

||2

F

Summarizing  each iteration consists of p2 vector thresholdings when solving for (α  β)  one pro-
jection over D when solving for P  and two matrix multiplications for the update of U and V. The
code is publicly available at www.fing.edu.uy/˜mfiori.
4 Application to joint graph inference of not pre-aligned data
Estimating the inverse covariance matrix is a very active ﬁeld of research. In particular the inference
of the support of this matrix  since the non-zero entries have information about the conditional de-
pendence between variables. In numerous applications  this matrix is known to be sparse  and in this
regard the graphical Lasso has proven to be a good estimator for the inverse covariance matrix (Yuan
& Lin  2007; Fiori et al.  2012) (also for non-Gaussian data (Loh & Wainwright  2012)). Assume
that we have a p-dimensional multivariate normal distributed variable X ∼ N (0  Σ); let X ∈ Rk×p
be a data matrix containing k independent observations of X  and S its empirical covariance matrix.
The graphical Lasso estimator for Σ−1 is the matrix Θ which solves the optimization problem

tr(SΘ) − log det Θ + λ

|Θij|  

min
Θ(cid:31)0

(6)

(cid:88)

i j

4

which corresponds to the maximum likelihood estimator for Σ−1 with an l1 regularization.
Collaborative network inference has gained a lot of attention in the last years (Chiquet et al.  2011) 
specially with fMRI data  e.g.  (Varoquaux et al.  2010). This problem consist of estimating two (or
more) matrices Σ−1
B from data matrices XA and XB as above  with the additional prior
information that the inverse covariance matrices share the same support. The joint estimation of ΘA
and ΘB is performed by solving

A and Σ−1

min

ΘA(cid:31)0 ΘB(cid:31)0

tr(SAΘA) − log det ΘA + tr(SBΘB) − log det ΘB + λ

(cid:12)(cid:12)(cid:12)(cid:12)(cid:0)ΘA

(cid:88)

i j

(cid:1)||2  

ij  ΘB
ij

(7)

where the ﬁrst four terms correspond to the maximum likelihood estimators for ΘA  ΘB  and the
last term is the group Lasso penalty which promotes that ΘA and ΘB have the same active set.
This formulation relies on the limiting underlying assumption that the variables in both datasets
(the columns of XA and XB) are in correspondence  i.e.  the graphs determined by the adjacency
matrices ΘA and ΘB are aligned. However  this is in general not the case in practice. Motivated
by the formulation presented in Section 2  we propose to overcome this limitation by incorporating
a permutation matrix into the optimization problem  and jointly learn it on the estimation process.
The proposed optimization problem is then given by

tr(SAΘA) − log det ΘA + tr(SBΘB) − log det ΘB + λ

ΘA ΘB(cid:31)0

min
P∈P

(8)
Even after the relaxation of the constraint P ∈ P to P ∈ D  the joint minimization of (8) over
(ΘA  ΘB) and P is a non-convex problem. However it is convex when minimized only over
(ΘA  ΘB) or P leaving the other ﬁxed. Problem (8) can be then minimized using a block-coordinate
descent type of approach  iteratively minimizing over (ΘA  ΘB) and P.
The ﬁrst subproblem (solving (8) with P ﬁxed) is a very simple variant of (7)  which can be solved
very efﬁciently by means of iterative thresholding algorithms (Fiori et al.  2013). In the second
subproblem  since (ΘA  ΘB) are ﬁxed  the only term to minimize is the last one  which corresponds
to the graph matching formulation presented in Section 2.

(cid:12)(cid:12)(cid:12)(cid:12)(cid:0)(ΘAP)ij  (PΘB)ij

(cid:1)||2.

(cid:88)

i j

5 Experimental results

We now present the performance of our algorithm and compare it with the most recent techniques
in several scenarios including synthetic and real graphs  multimodal data  and fMRI experiments.
In the cases where there is a “ground truth ” the performance is measured in terms of the matching
error  deﬁned as ||Ao − PBoPT||2
F   where P is the obtained permutation matrix and (Ao  Bo) are
the original adjacency matrices.

5.1 Graph matching: Synthetic graphs

We focus here in the traditional graph matching problem of undirected weighted graphs  both with
and without noise. More precisely  let Ao be the adjacency matrix of a random weighted graph and
Bo a permuted version of it  generated with a random permutation matrix Po  i.e.  Bo = PT
o AoPo.
We then add a certain number N of random edges to Ao with the same weight distribution as the
original weights  and another N random edges to Bo  and from these noisy versions we try to recover
the original matching (or any matching between Ao and Bo  since it may not be unique).
We show the results using three different techniques for the generation of the graphs: the Erd˝os-
R´enyi model (Erd˝os & R´enyi  1959)  the model by Barab´asi & Albert (1999) for scale-free graphs 
and graphs with a given degree distribution generated with the BTER algorithm (Seshadhri et al. 
2012). These models are representative of a wide range of real-world graphs (Newman  2010). In
the case of the BTER algorithm  the degree distribution was generated according to a geometric law 
that is: Prob(degree = t) = (1 − e−µ)eµt.
We compared the performance of our algorithm with the technique by Zaslavskiy et al. (2009)
(referred to as PATH)  the FAQ method described in Vogelstein et al. (2012)  and the QCP approach.

5

Figure 1 shows the matching error as a function of the noise level for graphs with p = 100 nodes
(top row)  and for p = 150 nodes (bottom row). The number of edges varies between 200 and 400
for graphs with 100 nodes  and between 300 and 600 for graphs with 150 nodes  depending on the
model. The performance is averaged over 100 runs. This ﬁgure shows that our method is more
stable  and consistently outperforms the other methods (considered state-of-the-art)  specially for
noise levels in the low range (for large noise levels  is not clear what a “true” matching is  and in
addition the sparsity hypothesis is no longer valid).

r
o
r
r
e
g
n
i
h
c
t
a

M

18

14

10

6

2

r
o
r
r
e
g
n
i
h
c
t
a

M

16
14
12
10
8
6
4
2

0

5

10
Noise

15

20

25

0

5

10
Noise

15

20

25

0

(a) Erd˝os-R´enyi graphs

(b) Scale-free graphs

r
o
r
r
e

g
n
i
h
c
t
a

M

10

8

6

4

2

r
o
r
r
e

g
n
i
h
c
t
a

M

14
12
10
8
6
4
2

10

15
Noise

5
20
(c) BTER graphs

25

30

18

r
o
r
r
e

14

10

g
n
i
h
c
t
a

M

r
o
r
r
e

g
n
i
h
c
t
a

M

6

2

9

7

5

3

1

0

5

10
Noise

15

20

25

0

5

10
Noise

15

20

25

0

5

10

15
Noise

20

25

30

(d) Erd˝os-R´enyi graphs

(e) Scale-free graphs

(f) BTER graphs

Figure 1: Matching error for synthetic graphs with p = 100 nodes (top row) and p = 150 nodes (bottom row).
In solid black our proposed GLAG algorithm  in long-dashed blue the PATH algorithm  in short-dashed red the
FAQ method  and in dotted black the QCP.

5.2 Graph matching: Real graphs

We now present similar experiments to those in the previous section but with real graphs. We use
the C. elegans connectome. Caenorhabditis elegans is an extensively studied roundworm  whose so-
matic nervous system consists of 279 neurons that make synapses with other neurons. The two types
of connections (chemical and electrical) between these 279 neurons have been mapped (Varshney
et al.  2011)  and their corresponding adjacency matrices  Ac and Ae  are publicly available.
We match both the chemical and the electrical connection graphs against noisy artiﬁcially permuted
versions of them. The permuted graphs are constructed following the same procedure used in Section
5.1 for synthetic graphs. The weights of the added noise follow the same distribution as the original
weights. The results are shown in Figure 2. These results suggest that from the prior art  the PATH
algorithm is more suitable for the electrical connection network  while the FAQ algorithm works
better for the chemical one. Our method outperforms both of them for both types of connections.

5.3 Multimodal graph matching

One of the advantages of the proposed approach is its capability to deal with multimodal data. As
discussed in Section 2  the group Lasso type of penalty promotes the supports of AP and PB to be
identical  almost independently of the actual values of the entries. This allows to match weighted
graphs where the weights may follow completely different probability distributions. This is com-
monly the case when dealing with multimodal data: when a network is measured using signiﬁcantly
different modalities  one expects the underlying connections to be the same but no relation can be
assumed between the actual weights of these connections. This is even the case for example for
fMRI data when measured with different instruments. In what follows  we evaluate the performance
of the proposed method in two examples of multimodal graph matching.

6

r
o
r
r
e

g
n
i
h
c
t
a

M

5
4.5
4
3.5
3
2.5
2
1.5
1
0.5

0

5 10 15 20 25 30 35 40 45 50

Noise

(a) Electrical connection graph

8
7
6
5
4
3
2
1

r
o
r
r
e

g
n
i
h
c
t
a

M

0

5

10 15 20 25 30 35 40 45 50

Noise

(b) Chemical connection graph

Figure 2: Matching error for the C. elegans connectome  averaged over 50 runs. In solid black our proposed
GLAG algorithm  in long-dashed blue the PATH algorithm  and in short-dashed red the FAQ method. Note that
in the chemical connection graph  the matching error of our algorithm is zero until noise levels of ≈ 50.

We ﬁrst generate an auxiliary binary random graph Ab and a permuted version Bb = PT
o AbPo.
Then  we assign weights to the graphs according to distributions pA and pB (that will be speciﬁed
for each experiment)  thus obtaining the weighted graphs A and B. We then add noise consisting
of spurious weighted edges following the same distribution as the original graphs (i.e.  pA for A
and pB for B). Finally  we run all four graph matching methods to recover the permutation. The
matching error is measured in the unweighted graphs as ||Ab − PBbPT||F . Note that while this
metric might not be appropriate for the optimization stage when considering multimodal data  it
is appropriate for the actual error evaluation  measuring mismatches. Comparing with the original
permutation matrix may not be very informative since there is no guarantee that the matrix is unique 
even for the original noise-free data.
Figures 3(a) and 3(b) show the comparison when the weights in both graphs are Gaussian distributed 
but with different means and variances. Figures 3(c) and 3(d) show the performances when the
weights of A are Gaussian distributed  and the ones of B follow a uniform distribution. See captions
for details. These results conﬁrm the intuition described above  showing that our method is more
suitable for multimodal graphs  specially in the low range of noise.

35
30

25

r
o
r
r
e

g
n
i
h
c
t
a

20

15

M

10

5

0

5

10 15 20 25 30 35 40 45

Noise

(a) Erd˝os-R´enyi graphs

30

25

20

15

10

5

r
o
r
r
e

g
n
i
h
c
t
a

M

30

25

20

15

10

5

r
o
r
r
e

g
n
i
h
c
t
a

M

25

20

15

10

5

r
o
r
r
e

g
n
i
h
c
t
a

M

0

5

10 15 20 25 30 35 40 45

Noise

(b) Scale-free graphs

0

5

10 15 20 25 30 35 40 45

Noise

(c) Erd˝os-R´enyi graphs

0

5

10 15 20 25 30 35 40 45

Noise

(d) Scale-free graphs

Figure 3: Matching error for multimodal graphs with p = 100 nodes.
In (a) and (b)  weights in A are
N (1  0.4) and weights in B are N (4  1). In (c) and (d)  weights in A are N (1  0.4) and weights in B are
uniform in [1  2]. In solid black our proposed GLAG algorithm  in long-dashed blue the PATH algorithm  in
short-dashed red the FAQ method  and in dotted black the QCP.

7

5.4 Collaborative inference
In this last experiment  we illustrate the application of the permuted collaborative graph inference
presented in Section 4 with real resting-state fMRI data  publicly available (Nooner  2012). We con-
sider here test-retest studies  that is  the same subject undergoing resting-state fMRI in two different
sessions separated by a break. Each session consists of almost 10 minutes of data  acquired with
a sampling period of 0.645s  producing about 900 samples per study. The CC200 atlas (Craddock
et al.  2012) was used to extract the time-series for the ≈ 200 regions of interest (ROIs)  resulting in
two data matrices XA  XB ∈ R900×200  corresponding to test and retest respectively.
To illustrate the potential of the proposed framework  we show that using only part of the data in
XA and part of the data in a permuted version of XB  we are able to infer a connectivity matrix
almost as accurately as using the whole data. Working with permuted data is very important in this
application in order to handle possible miss-alignments to the atlas.
Since there is no ground truth for the connectivity  and as mentioned before the collaborative setting
(7) has already been proven successful  we take as ground truth the result of the collaborative infer-
ence using the empirical covariance matrices of XA and XB  denoted by SA and SB. The result of
this collaborative inference procedure are the two inverse covariance matrices ΘA
GT . In
short  the gold standard built for this experiment are found by solving (obtained with the entire data)

GT and ΘB

(cid:12)(cid:12)(cid:12)(cid:12)(cid:0)ΘA

(cid:88)

i j

(cid:1)||2 .

ij  ΘB
ij

min

ΘA(cid:31)0 ΘB(cid:31)0

tr(SAΘA) − log det ΘA + tr(SBΘB) − log det ΘB + λ

H be the ﬁrst 550 samples of XA  and XB

H the ﬁrst 550 samples of XB  which correspond
H and SB
H
H Po. With these two
B
H we run the algorithm described in Section 4  which alternately computes the

Now  let XA
to a little less than 6 minutes of study. We compute the empirical covariance matrices SA
B
of these data matrices  and we artiﬁcially permute the second one: ˜S
H = PT
matrices SA
inverse covariance matrices ΘA
We compare this approach against the computation of the inverse covariance matrix using only one
of the studies. Let ΘA

H and the matching P between them.

H and ΘB

H and ˜S

s be the results of the graphical Lasso (6) using SA and SB:
tr(SKΘ) − log det Θ + λ

for K = {A  B}.

|Θij|  

s and ΘB

(cid:88)

o SB

ΘK

s = argmin

Θ(cid:31)0

GT −
This experiment is repeated for 5 subjects in the database. The errors ||ΘA
H||F are shown in Figure 4. The errors for ΘB are very similar. Using less than 6 minutes of each
ΘA
study  with the variables not pre-aligned  the permuted collaborative inference procedure proposed
in Section 4 outperforms the classical graphical Lasso using the full 10 minutes of study.

s ||F and ||ΘA

GT − ΘA

i j

)
3
−

0
1
×

(

r
o
r
r
E

6

5

4

3

2

1

0

1

2

3

Subject

4

5

GT − ΘA

||ΘA
GT − ΘA

Figure 4:
Inverse covariance matrix
estimation for fMRI data.
In blue 
error using one complete 10 minutes
s ||F .
study:
In red  er-
ror ||ΘA
H||F with collabora-
tive inference using about 6 minutes
of each study  but solving for the un-
known node permutations at the same
time.

6 Conclusions
We have presented a new formulation for the graph matching problem  and proposed an optimization
algorithm for minimizing the corresponding cost function. The reported results show its suitability
for the graph matching problem of weighted graphs  outperforming previous state-of-the-art meth-
ods  both in synthetic and real graphs. Since in the problem formulation the weights of the graphs
are not compared explicitly  the method can deal with multimodal data  outperforming the other
compared methods. In addition  the proposed formulation naturally ﬁts into the pre-alignment-free
collaborative network inference framework  where the permutation is estimated together with the
underlying common network  with promising preliminary results in applications with real data.
Acknowledgements: Work partially supported by ONR  NGA  NSF  ARO  AFOSR  and ANII.

8

References
Almohamad  H. and Duffuaa  S. A linear programming approach for the weighted graph match-
ing problem. Pattern Analysis and Machine Intelligence  IEEE Transactions on  15(5):522–525 
1993.

Barab´asi  A. and Albert  R. Emergence of scaling in random networks. Science  286(5439):509–512 

1999.

Bertsekas  D. and Tsitsiklis  J. Parallel and Distributed Computation: Numerical Methods. Prentice

Hall  1989.

Chiquet  J.  Grandvalet  Y.  and Ambroise  C. Inferring multiple graphical structures. Statistics and

Computing  21(4):537–553  2011.

Conte  D.  Foggia  P.  Sansone  C.  and Vento  M. Thirty years of graph matching in pattern recog-
nition. International Journal of Pattern Recognition and Artiﬁcial Intelligence  18(03):265–298 
2004.

Craddock  R.C.  James  G.A.  Holtzheimer  P.E.  Hu  X.P.  and Mayberg  H.S. A whole brain fMRI
atlas generated via spatially constrained spectral clustering. Human Brain Mapping  33(8):1914–
1928  2012.

Erd˝os  P. and R´enyi  A. On random graphs  I. Publicationes Mathematicae  6:290–297  1959.
Fiori  Marcelo  Mus´e  Pablo  and Sapiro  Guillermo. Topology constraints in graphical models. In

Advances in Neural Information Processing Systems 25  pp. 800–808  2012.

Fiori  Marcelo  Mus´e  Pablo  Hariri  Ahamd  and Sapiro  Guillermo. Multimodal graphical models

via group lasso. Signal Processing with Adaptive Sparse Structured Representations  2013.

Kuhn  H. W. The Hungarian method for the assignment problem. Naval Research Logistic Quar-

terly  2:83–97  1955.

Lin  Z.  Liu  R.  and Su  Z. Linearized alternating direction method with adaptive penalty for low-
In Advances in Neural Information Processing Systems 24  pp. 612–620.

rank representation.
2011.

Loh  P. and Wainwright  M. Structure estimation for discrete graphical models: Generalized covari-
ance matrices and their inverses. In Advances in Neural Information Processing Systems 25  pp.
2096–2104. 2012.

Newman  M. Networks: An Introduction. Oxford University Press  Inc.  New York  NY  USA  2010.
Nooner  K. et al. The NKI-Rockland sample: A model for accelerating the pace of discovery science

in psychiatry. Frontiers in Neuroscience  6(152)  2012.

Seshadhri  C.  Kolda  T.G.  and Pinar  A. Community structure and scale-free collections of Erd˝os-

R´enyi graphs. Physical Review E  85(5):056109  2012.

Umeyama  S. An eigendecomposition approach to weighted graph matching problems. Pattern

Analysis and Machine Intelligence  IEEE Transactions on  10(5):695–703  1988.

Varoquaux  G.  Gramfort  A.  Poline  J.B.  and T.  Bertrand. Brain covariance selection: better indi-
vidual functional connectivity models using population prior. In Advances in Neural Information
Processing Systems 23  pp. 2334–2342  2010.

Varshney  L.  Chen  B.  Paniagua  E.  Hall  D.  and Chklovskii  D. Structural properties of the

caenorhabditis elegans neuronal network. PLoS Computational Biology  7(2):e1001066  2011.

Vogelstein  J.T.  Conroy  J.M.  Podrazik  L.J.  Kratzer  S.G.  Harley  E.T.  Fishkind  D.E.  Vogelstein 
R.J.  and Priebe  C.E. Fast approximate quadratic programming for large (brain) graph matching.
arXiv:1112.5507  2012.

Yuan  M. and Lin  Y. Model selection and estimation in regression with grouped variables. Journal

of the Royal Statistical Society: Series B  68(1):49–67  2006.

Yuan  M. and Lin  Y. Model selection and estimation in the Gaussian graphical model. Biometrika 

94(1):19–35  February 2007.

Zaslavskiy  M.  Bach  F.  and Vert  J.P. A path following algorithm for the graph matching problem.

Pattern Analysis and Machine Intelligence  IEEE Transactions on  31(12):2227–2242  2009.

9

,Marcelo Fiori
Pablo Sprechmann
Joshua Vogelstein
Pablo Muse
Guillermo Sapiro