2019,Low-Rank Bandit Methods for High-Dimensional Dynamic Pricing,We consider dynamic pricing with many products under an evolving but low-dimensional demand model. Assuming the temporal variation in cross-elasticities exhibits low-rank structure based on fixed (latent) features of the products  we show that the revenue maximization problem reduces to an online bandit convex optimization with side information given by the observed demands. We design dynamic pricing algorithms whose revenue approaches that of the best fixed price vector in hindsight  at a rate that only depends on the intrinsic rank of the demand model and not the number of products. Our approach applies a bandit convex optimization algorithm in a projected low-dimensional space spanned by the latent product features  while simultaneously learning this span via online singular value decomposition of a carefully-crafted matrix containing the observed demands.,Low-Rank Bandit Methods for High-Dimensional

Dynamic Pricing

Jonas Mueller
MIT CSAIL

Vasilis Syrgkanis
Microsoft Research

Matt Taddy
Chicago Booth

jonasmueller@csail.mit.edu

vasy@microsoft.com

taddy@chicagobooth.edu

Abstract

We consider dynamic pricing with many products under an evolving but low-
dimensional demand model. Assuming the temporal variation in cross-elasticities
exhibits low-rank structure based on ﬁxed (latent) features of the products  we
show that the revenue maximization problem reduces to an online bandit convex
optimization with side information given by the observed demands. We design
dynamic pricing algorithms whose revenue approaches that of the best ﬁxed price
vector in hindsight  at a rate that only depends on the intrinsic rank of the demand
model and not the number of products. Our approach applies a bandit convex
optimization algorithm in a projected low-dimensional space spanned by the latent
product features  while simultaneously learning this span via online singular value
decomposition of a carefully-crafted matrix containing the observed demands.

1 Introduction

In this work  we consider a seller offering N products  where N is large  and the pricing of certain
products may inﬂuence the demand for others in unknown ways. We let pt P RN denote the vector
of selected prices at which each product is sold during time period t P t1  . . .   Tu  which results
in total demands for the products over this period represented in the vector qt P RN. Note that qt
represents a (noisy) evaluation of the aggregate demand curve at the chosen prices pt  but we never
observe the counterfactual demand that would have resulted had we selected a different price-point.
This is referred to as bandit feedback in the online optimization literature [Dani et al.  2007]. Our
goal is ﬁnd a setting of the prices for each time period to maximize the total revenue of the seller
(over all rounds). This is equivalent to minimizing the negative revenue over time:

Rpp1  . . .   pTq “

Rtpptq where Rtpptq “ ´xqt  pty

Tÿt“1

We can alternatively maximize total proﬁts instead of revenue by simply redeﬁning pt as the difference
between the product-prices and the cost of each product-unit. In practice  the seller can only consider
prices within some constraint set S Ä RN  which we assume is convex throughout. To ﬁnd the
optimal prices  we introduce the following linear model of the aggregate demands  which is allowed
to change over time in a nonstationary fashion:

(1)
Here  ct P RN denotes the baseline demand for each product in round t. Bt P RNˆN is an
asymmetric matrix of demand elasticities which represents how changing the price of one product
may affect the demand of not only this product  but also demand for other products as well. By
conventional economic wisdom  Bt will have the largest entries along its diagonal because demand

qt “ ct ´ Btpt ` ✏t

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

for a product is primarily driven by its price rather than the price of other possibly unrelated products.
Since a price increase usually leads to falling demand  it is reasonable to assume all Bt © 0 are
positive-deﬁnite (but not necessarily Hermitian)  which implies that at each round: Rt is a convex
function of pt. The observed aggregate demands over each time period are additionally subject to
random ﬂuctuations driven by the noise term ✏t P RN. Throughout  we suppose the noise in each
round ✏t is sampled i.i.d. from some mean-zero distribution with ﬁnite variance. The classic analysis
of Houthakker and Taylor [1970] established that historical demand data often nicely ﬁt a linear
relationship. A wealth of past work on dynamic pricing has also posited linear demand models 
although most prior research has not considered settings where the underlying model is changing
over time [Keskin and Zeevi  2014  Besbes and Zeevi  2015  Cohen et al.  2016  Javanmard and
Nazerzadeh  2016  Javanmard  2017].
Unlike standard statistical approaches to this problem which rely on stationarity  we suppose ct  Bt
may change every round and are possibly chosen adversarially. This consideration is particularly im-
portant in dynamic markets where the seller faces new competitors and consumers with ever-changing
preferences who are actively seeking out the cheapest prices for products [Witt  1986]. Our goal is to
select prices p1  . . .   pT which minimize the expected regret ErRpp1  . . .   pTq ´ Rpp˚  . . .   p˚qs
compared to always selecting the single best conﬁguration of prices p˚ “ argminpPS E∞T
t“1 Rtppq
chosen in hindsight after the revenue functions Rt have all been revealed.
Low regret algorithms ensure that in the case of a stationary underlying model  our chosen prices
quickly converge to the optimal choice  and in nonstationary settings  our pricing procedure will natu-
rally adapt to the intrinsic difﬁculty of the dynamic revenue-optimization problem [Shalev-Shwartz 
2011]. While low (i.e. opTq) regret is achievable using algorithms for online convex optimization with
bandit feedback  the regret of existing methods is bounded below by ⌦p?Nq  which is undesirable
large when one is dealing with a vast number of products [Dani et al.  2007  Shalev-Shwartz  2011 
Flaxman et al.  2005]. To attain better bounds  we adopt a low-rank structural assumption that the
variation in demands changes over time only due to d ! N underlying factors. Under this setting 
we develop algorithms whose regret depends only on d rather than N by combining existing bandit
methods with low-dimensional projections selected via online singular value decomposition. As far
as we are aware  our main result (Theorem 3) is the ﬁrst online bandit optimization algorithm whose
regret provably does not scale with the action-space dimensionality.
Appendix D provides a glossary of notation used in this paper  and all proofs of our theorems are
relegated to Appendix A. Throughout  C denotes a universal constant  whose value may change from
line to line (but never depends on problem-speciﬁc constants such as T  d  r).

2 Related Work

While bandit optimization has been successfully applied to dynamic pricing  research in this area
has been primarily restricted to stationary settings [Kleinberg and Leighton  2003  Besbes and
Zeevi  2009  den Boer and Bert  2013  Keskin and Zeevi  2014  Cohen et al.  2016  Misra et al. 
2017]. Most similar to our work  Javanmard [2017] recently developed a bandit pricing strategy
that presumes demand depends linearly on prices and product-speciﬁc features. High-dimensional
dynamic pricing was also addressed by Javanmard and Nazerzadeh [2016] using sparse maximum
likelihood. However  due to their reliance on stationarity  these approaches are less robust under
evolving/adversarial environments compared with online optimization [Bubeck and Slivkins  2012].
Beyond pricing  existing algorithms that combine bandits with subspace estimation [Gopalan et al. 
2016  Djolonga et al.  2013  Sen et al.  2017] are solely designed for stationary (stochastic) settings
rather than general online optimization (where the reward functions can vary adversarially over time).
While the ﬁeld of online bandit optimization has seen many advances since the pioneering work
of Flaxman et al. [Flaxman et al.  2005]  none of the recent improvements guarantees regret that is
independent of the action-space dimension [Hazan and Levy  2014  Bubeck et al.  2017]. To our
knowledge  Hazan et al. [2016a] is the only prior work to present online optimization algorithms
whose regret depends on an intrinsic low rank structure rather than the ambient dimensionality.
However  their approach for online learning with experts is not suited for dynamic pricing since it is
restricted to settings with: full-information (rather than bandit feedback)  linear and noise-free (or
stationary) reward functions  and actions that are specially constrained within the probability-simplex.

2

3 Low Rank Demand Model

We now introduce a special case of model (1) in which both ct and Bt display low-rank changes over
time. In practice  each product i may be described by some vector of features ui P Rd (with d ! N) 
which determine the similarity between products as well as their baseline demands. A natural method
to gauge similarity between products i and j is via their inner product xui  ujyV “ uT
i Vuj under
some linear transformation of the feature-space given by V © 0. For example  ui might be a binary
vector indicating that product i falls into certain product-categories (where the number of categories
d is far less than the number of products N)  and V might be a diagonal matrix specifying the
i Vuj ¨ pj would thus be
cross-elasticity of demand within each product category. In this example  uT
the marginal effect on the demand for product i that results from selecting pj as the price for product
j. Many recommender systems also assume products can be described using low-dimensional latent
features that govern their desirability to consumers [Zhao et al.  2016  Sen et al.  2017].
By introducing time-varying metric transformations Vt  our model allows these product-similarities
to evolve over time. Encoding the features ui that represent each product as rows in a matrix
U P RNˆd  we assume the following demand model  in which the temporal variation naturally
exhibits low-rank structure:
(2)
Here  the ✏t P RN again reﬂect statistical noise in the observed demands  the zt P Rd explain the
variation in baseline demand over time  and the (asymmetric) matrices Vt P Rdˆd specify latent
changes in the demand-price relationship over time. Under this model  the aggregate demand for
product i at time t is governed by the prices of all products  weighted by their current feature-similarity
to product i. To ensure our revenue-optimization remains convex  we restrict the adversary to choices
that satisfy Vt © 0 for all t. Note that while the structural variation in our model is assumed to be
low-rank  the noise in the observed demands may be intrinsically N-dimensional. In each round  pt
and qt are the only quantities observed  while ✏t  zt  Vt all remain unknown (and we consider both
cases where the product features U are known or unknown). In §5.5  we verify that our low-rank
assumption accurately describes real historical demand data.

qt “ Uzt ´ UVtUT pt ` ✏t

4 Methods

Our basic dynamic pricing strategy is to employ the gradient-descent without a gradient (GDG)
online bandit optimization technique of Flaxman et al. [2005]. While a naive application of this
algorithm produces regret dependent on the number of products N  we ensure the updates of this
method are only applied in the d-dimensional subspace spanned by U  which leads to regret bounds
that depend only on d rather than N. When U is unknown  this subspace is simultaneously estimated
online  in a somewhat similar fashion to the approach of Hazan et al. [2016a] for online learning with
low-rank experts. If we deﬁne x “ UT p P Rd  then under the low-rank model in (2) with Er✏ts “ 0 
the expected value of our revenue-objective in round t can be expressed as:
(3)
As this problem’s intrinsic dimensionality is only d  we can maximize expected revenues by merely
considering a restricted set of d-dimensional actions x and functions ft over projected constraint set:
(4)

E✏rRtppqs “ pT UVtUT p ´ pT Uzt “ xT Vtx ´ xT zt :“ ftpxq

UTpSq “ x P Rd : x “ UT p for some p P S(

4.1 Products with Known Features

In certain markets  it is clear how to featurize products [Cohen et al.  2016]. Under the low-rank
model in (2) when U is given  we can apply the OPOK method (Algorithm 1) to select prices. This
algorithm employs subroutines FINDPRICE and PROJECTION which both solve convex optimization
problems in order to compute certain projections. Here  Bd “ Unifptx P Rd : ||x||2 “ 1uq denotes a
uniform distribution over surface of the unit sphere in Rd.
Intuitively  our algorithm adapts GDG to select low-dimensional actions xt P Rd at each time point 
and then seeks out a feasible price vector pt corresponding to the chosen xt. Note that when d ! N 

3

Algorithm 1 OPOK
(Online Pricing Optimization with Known Features)
Input: ⌘    ↵ ° 0  U P RNˆd  initial prices p0 P S
Output: Prices p1  . . .   pT to maximize revenue
1: Set prices to p0 P S and observe q0pp0q  R0pp0q
2: Deﬁne x1 “ UT p0
3: for t “ 1  . . .   T :
4:
rxt :“ xt ` ⇠t
5:
Set prices: pt “ FINDPRICEprxt  U S  pt´1q
6:

and observe qtpptq  Rtpptq
xt`1 “ PROJECTIONpxt´⌘Rtpptq⇠t  ↵  U  Sq

⇠t „ Unifptx P Rd : ||x||2 “ 1uq

7:

Algorithm 2 FINDPRICE(x; U S  pt´1)
Input: x P Rd  U P RNˆd 
Output: argmin

convex S Ä RN  pt´1 P RN

||p ´ pt´1||2
pPS
subject to: UT p “ x

convex set S Ä RN

Algorithm 3 PROJECTION(x  ↵  U  S)
Input: x P Rd  ↵ ° 0  U P RNˆd 
Output: p1 ´ ↵qUTpp
with pp :“ argmin

ˇˇˇˇp1 ´ ↵qUT p ´ xˇˇˇˇ2

pPS

there are potentially many price-vectors p P RN that map to the same low-dimensional vector
x P Rd via UT . Out of these  we select the one that is closest to our previously-chosen prices (via
FINDPRICE)  ensuring additional stability in our dynamic pricing procedure. In practice  the initial
prices p0 should be selected based on external knowledge or historical demand data.
Under mild conditions  Theorem 1 below states that the OPOK algorithm incurs OpT 3{4?dq regret

when product features are a priori known. This result is derived from Lemma A.1 which shows
that Step 7 of our algorithm corresponds (in expectation) to online projected gradient descent on a
smoothed version of our objective deﬁned as:

(5)
where ⇣ is sampled uniformly from within the unit sphere in Rd  and ft is deﬁned in (3). We bound
the regret of our pricing algorithm under the following assumptions (which ensure the revenue
functions are bounded/smooth and the set of feasible prices is bounded/well-scaled):

pftpxq “ E⇣“ftpx ` ⇣q‰

(A1) ||zt||2 § b for t “ 1  . . .   T
(A2) ||Vt||op § b for all t (|| ¨ ||op denotes spectral norm)
(A3) T ° 9
(A4) U is an orthogonal matrix such that UT U “ Idˆd
(A5) S “ tp P RN : ||p||2 § ru (with r • 1)

4 d2

Requiring that the columns of U form an orthonormal basis for Rd  condition (A4) can be easily
enforced (when d † N) by ﬁrst orthonormalizing the product features. Note that this orthogonality
condition does not restrict the overall class of models speciﬁed in (2)  and describes the case where the
features used to encode each product are uncorrelated between products (i.e. a minimally-redundant
encoding) and have been normalized across all products. To see why (A4) does not limit the allowed
price-demand relationships  consider that we can re-express any (non-orthogonal) U “ OP in terms
of orthogonal O P RNˆd. The demand model in (2) can then be equivalently expressed in terms
of z1t “ Pzt  V1t “ PVtPT (after appropriately redeﬁning the constant b in (A1)-(A2))  since:
Uzt ´ UVtUT pt “ Oz1t ´ OV1tOT pt. To further simplify our analysis  we also from now adopt
(A5) presuming the constraint set of feasible product-prices is a centered Euclidean ball (implying
our pt  qt vectors now represent appropriately shifted/scaled prices and demands).
bp1`dq?T    “ T ´1{4b dr2p1`rq
Theorem 1. Under assumptions (A1)-(A5)  if we choose ⌘ “
↵ “ 

r   then there exists C ° 0 such that for any p P S:

9r`6

1

 

E✏ ⇠« Tÿt“1

Rtpptq ´

Tÿt“1

Rtppq § Cbrpr ` 1qT 3{4d1{2

for the prices p1  . . .   pT selected by the OPOK algorithm.

Theorem A.2 shows the same OpT 3{4?dq regret bound holds for the OPOK algorithm under relaxed

conditions solely based on the revenue functions and feasible prices rather than the speciﬁc properties
of our low-rank structure assumed in (A1)-(A5).

4

4.2 Products with Latent Features

In many settings  it is not clear how to best represent products as feature-vectors. Once again adopting
the low-rank demand model in (2)  we now consider the case where U is unknown and must be
estimated. We presume the orthogonality condition (A4) holds throughout this section (recall this
does not restrict the class of allowed models)  which implies U is both an isometry as well as the right-
inverse of UT . Thus  given any low-dimensional action x P UTpSq  we can set the corresponding
prices as p “ Ux such that UT p “ x. Lemma 1 shows that this price selection-method is feasible
the next price is regularized toward the origin rather than the previous price pt´1. Because prices
pt are multiplied by the noise term ✏t within each revenue-function Rt  choosing minimum-norm
prices can help reduce variance in the total revenue generated by our approach. As U is unknown 

and corresponds to changing Step 6 in the OPOK algorithm to pt “ FINDPRICEprxt  U S  0q  where
we instead employ an estimate pU P RNˆd  which is always restricted to be an orthogonal matrix.
Lemma 1. For any orthogonal matrix pU and any x P pUTpSq  deﬁnepp “ pUx P RN . Under (A5):
pp P S andpp “ FINDPRICE(x pU S  0).
algorithm where price-selection in Step 6 is done using pt “ pUrxt rather than being regularized
products N  as long as pU accurately estimates the column span of U.
Theorem 2. Suppose spanppUq “ spanpUq  i.e. our orthogonal estimate has the same column-span
as the underlying (rank d) latent product-feature matrix. Let p1  . . .   pT P S denote the prices
selected by our modiﬁed OPOK algorithm with pU used in place of the underlying U and ⌘    ↵
chosen as in Theorem 1. Under conditions (A1)-(A5)  there exists C ° 0 such that for any p P S:

toward the previous price pt´1. Even without knowing the true latent features  this result implies that
the regret of our modiﬁed OPOK algorithm may still be bounded independently of the number of

In Theorem 2  we consider a minorly modiﬁed OPOK

Product Features with Known Span.

Rtppq § Cbrpr ` 1qT 3{4d1{2

E✏ ⇠« Tÿt“1

Rtpptq ´

Tÿt“1

Features with Unknown Span and Noise-free Demands.
In practice  span(U) may be entirely
unknown. If we assume the adversary is restricted to strictly positive-deﬁnite Vt ° 0 for all t and
there is no statistical noise in the observed demands (i.e. qt “ Uzt ´ UVtUT pt in each round) 
then Lemma 2 below shows we can ensure span(U) is revealed within the ﬁrst d observed demand
vectors by simply adding a minuscule random perturbation to all of our initial prices selected in the
ﬁrst d rounds. Thus  even without knowing the latent product feature subspace  an absence of noise
in the observed demands enables us to realize a low regret pricing strategy via the same modiﬁed
OPOK algorithm (applied after the ﬁrst d rounds).
Lemma 2. Suppose that for t “ 1  . . .   T : ✏t “ 0 and Vt ° 0. If each pt is independently
uniformly distributed within some (uncentered) Euclidean ball of strictly positive radius  then
spanpq1  . . .   qdq “ spanpUq almost surely.
Features with Unknown Span and Noisy Demands. When the observed demands are noisy and
spanpUq is unknown  we select prices using the OPOL algorithm on the next page. The approach is
similar to our previous OPOK algorithm  except we now additionally maintain a changing estimate
of the latent product features’ span. Our estimate is updated in an online fashion via an averaged
singular value decomposition (SVD) of the previously observed demands.
Step 9 in our OPOL algorithm corresponds to online averaging of the currently observed demand

vector qt with the historical observations stored in the jth column of matrix pQ. After computing the
singular value decomposition of pQ “ rUrSrVT   Step 10 is performed by setting pU equal to the ﬁrst d
columns of rU (presumed to be the indices corresponding to the largest singular values inrS). Since
pQ is only minorly changed within each round  the update operation in Step 10 can be computed more
that by their deﬁnition as singular vectors  the columns of pU remain orthonormal throughout the

efﬁciently by leveraging existing fast SVD-update procedures [Brand  2006  Stange  2008]. Note

execution of our algorithm.

5

Algorithm 4 OPOL (Online Pricing Optimization with Latent Features)
Input: ⌘    ↵ ° 0  rank d P r1  Ns  initial prices p0 P S
Output: Prices p1  . . .   pT to maximize overall revenue
1: Initialize pQ as N ˆ d matrix of zeros
2: Initialize pU as random N ˆ d orthogonal matrix
3: Set prices to p0 P S and observe q0pp0q  R0pp0q
4: Deﬁne x1 “ pUT p0
5: for t “ 1  . . .   T :
6:
7:
8:
9:
10:

rxt :“ xt ` ⇠t  ⇠t „ Unifptx P Rd : ||x||2 “ 1uq
Set prices: pt “ pUrxt and observe qtpptq  Rtpptq
xt`1 “ PROJECTIONpxt ´ ⌘Rtpptq⇠t  ↵  pU  Sq
With j “ 1 ` rpt ´ 1q mod ds  k “ ﬂoorpt{dq  update: pQ˚ j – 1
Set columns of pU as top d left singular vectors of pQ

k qt ` k´1

k pQ˚ j

|Ij|ÿiPIj
pQ˚ j “ sQ˚˚ j ` 1

|Ij| UÿiPIj

si

✏i  with sQ˚˚ j “ 1
|Ij|∞iPIj

To quantify the regret incurred by this algorithm  we assume the noise vectors ✏t follow a sub-
Gaussian distribution for each t “ 1  . . .   T . The assumption of sub-Gaussian noise is quite general 
covering common settings where the noise is Gaussian  bounded  of strictly log-concave density  or
any ﬁnite mixture of sub-Gaussian variables [Mueller et al.  2018]. Intuitively  the averaging in step 9
of our OPOL algorithm ensures statistical concentration of the noise in our observed demands  such
that the true column span of the underlying U may be better revealed. More concretely  if we let
st “ zt ´ VtUT pt and q˚t “ Ust  then the observed demands can be written as: qt “ q˚t ` ✏t 
where q˚t are the (unobserved) expected demands at our chosen prices. Thus  the jth column of pQ at
round T is given by:

(6)

d u (so |Ij| “ T

d ). Because the average 1

where we assume for notational simplicity that T is divisible by d and deﬁne Ij “ tj ` dpi´ 1q : i “
✏i exhibits concentration of measure  results
1  . . .   T
from random matrix theory imply that the span-estimator obtained from the ﬁrst d singular vectors
of pQ in Step 10 of our OPOL algorithm will rapidly converge to the column span of sQ˚ P RNˆd  a
matrix of averaged underlying expected demands. This is useful since sQ˚ shares the same span as

the underlying U.
Theorem 3 below shows that our OPOL algorithm achieves low-regret in the setting of unknown
product features with noisy demands  and the regret again depends only on the intrinsic rank d (rather
than the number of products N).
Theorem 3. For unknown U  let p1  . . .   pT be the prices selected by the OPOL algorithm with
⌘    ↵ set as in Theorem 1. Suppose ✏t follows a sub-Gaussianp2q distribution and has statistically
i.i.d. dimensions for each t. If (A1)-(A5) hold  then there exists C ° 0 such that for any p P S:

Rtppq § CQrbp4r ` 1qdT 3{4

E✏ ⇠« Tÿt“1
Here  Q “ max!1  2´ 21`1
singular values of the underlying rank d matrix sQ˚ deﬁned in (6).

Rtpptq ´
d ¯) with 1 (and d) deﬁned as the largest (and smallest) nonzero

Our proof of this result relies on standard random matrix concentration inequalities [Vershynin 
2012] and Theorem A.3  a useful variant of the Davis-Kahan theory introduced by Yu et al. [2015].
Intuitively  we show that span(U) can be estimated to sufﬁcient accuracy within sufﬁciently few
rounds  and then follow similar reasoning to the proof of Theorem 2. Note that the regret in Theorem
3 depends on the constant Q whose value is determined by the noise-level  and the extreme singular

values of sQ˚ deﬁned in (6). In general  these quantities thus measure just how adversarial of an

environment the seller is faced with. For example  when the underlying low-rank variation is of
much smaller magnitude than the noise in our observations  it will be difﬁcult to accurately estimate

Tÿt“1

2

6

the span of the latent product features. In control theory  a signal-to-noise expression similar to Q
has also been recently proposed to quantify the intrinsic difﬁculty of system identiﬁcation for the
linear quadratic regulator [Dean et al.  2017]. A basic setting in which Q can be explicitly bounded is
illustrated in Appendix B  where we suppose the underlying demand model parameters can only be
imprecisely controlled by an adversary over time.

5 Experiments

We evaluate the performance of our methodology in settings where noisy demands are generated
according to equation (2)  and the underlying structural parameters of the demand curves are randomly
sampled from Gaussian distributions (details in Appendix C.2). Throughout  pt and qt represent
rescaled rather than absolute prices/demands  such that the feasible set S can be simply ﬁxed as a
centered sphere of radius r “ 20. Noise in the (rescaled) demands for each individual product is
always sampled as: ✏t „ Np0  10q.
Our proposed algorithms are compared against the GDG online bandit algorithm of Flaxman et al.
[2005]  as well as a simple explore-then-exploit (Explore
it ) technique. The latter method randomly
samples pt during the ﬁrst T 3{4 rounds (uniformly over S) and for all remaining rounds  pt is ﬁxed at
the best price vector found during exploration. Explore
it reﬂects a standard pricing technique: initially
experiment with prices and eventually settle on those that previously produced the most proﬁt.

5.1 Stationary Demand Model
First  we consider a stationary setting where underlying structural parameters zt “ z  Vt “ V remain
ﬁxed. Before each experiment  we sample the entries of z  V independently as zij „ Np100  20q 
Vij „ Np0  2q  and U is ﬁxed as a random sparse binary matrix that reﬂects which of d possible
categories each product belongs to. Subsequently  we orthogonalize the columns of U and project
V into V “ tV : VT ` V © Iu with  “ 10 to ensure positive deﬁnite cross-product price
elasticities. Here  z  V  are chosen to reﬂect properties of real-world demand curves: different
products’ baseline demands and elasticities should be highly diverse (wide range of z)  and prices
should signiﬁcantly inﬂuence demands such that price-increases severely decrease demand and affect
demand for the same product more than other products (large value of   which in turn induces large
values for certain entries of V). We ﬁnd the optimal price vector does not lie near the boundary of S
(||p˚||2 « 8 rather than 20)  which shows that prices strongly inﬂuence demands under our setup.
Figures 1A and 1B show that our OPOK and OPOL algorithms are greatly superior to GDG when
the dimensionality N exceeds the intrinsic rank d. When N “ d (no low-rank structure to exploit) 
our OPOK/OPOL algorithms closely match GDG (blue  green  and red curves overlap). Note that
in this case: GDG and OPOK are nearly mathematically equivalent (same regret bound applies to
both  but their empirical performance slightly differs in this case due to the internal stochasticity of

each bandit algorithm)  as are OPOL and OPOK (since d “ N implies pU is an orthogonal N ˆ N

matrix and hence invertible). For small N  all online bandit optimization techniques outperform
Explore
it   but GDG scales poorly to large N unlike our methods. Interestingly  OPOL (which must
infer latent product features alongside the pricing strategy) performs slightly better than the OPOK
approach  which has access to the ground-truth features. This is because in the presence of noise  our
SVD-computed features can more robustly represent the subspace where projected pricing variation
can maximally impact the overall observed demands. In contrast  the dimensionality-reduction in
OPOK does not lead to any denoising.

5.2 Model with Demand Shocks

Next  we study a non-stationary setting where the underlying demand model changes drastically
at times T{3 and 2T{3. At the start of each period r0  T{3s  rT{3  2T{3s  r2T{3  Ts: we simply
redraw the underlying structural parameters zt  Vt from the same Gaussian distributions used for the
stationary setting. Figures 1C and 1D show that our bandit techniques quickly adapt to the changes in

7

(A) N “ 10  d “ 10  Model = §5.1

(B) N “ 100  d “ 10  Model = §5.1

(C) N “ 10  d “ 10  Model = §5.2

(D) N “ 100  d “ 10  Model = §5.2

(E) N “ 10  d “ 10  Model = §5.3

(F) N “ 100  d “ 10  Model = §5.3

Figure 1: Average cumulative regret (over 10 repetitions with standard-deviations shaded) of various
pricing strategies when underlying demand model is: (A)-(B) stationary over time  (C)-(D): altered
by structural shocks at times T{3 and 2T{3  (E)-(F): drifting over time.
the underlying demand curves. The regret of the bandit algorithms decreases over time  indicating
they begin to outperform the optimal ﬁxed price chosen in hindsight (recall that our bandits may vary
price over time  whereas regret is measured against the best ﬁxed price-conﬁguration which may
fare much worse than a dynamic schedule in nonstationary environments). Once again  our low-rank
methods achieve low regret for a large number of products unlike the existing approaches  while
retaining the same strong performance as the GDG algorithm in the absence of low-rank structure.

5.3 Drifting Demand Model

Finally  we consider another non-stationary setting where underlying demand curves slowly change
over time. Here  the underlying structural parameters zt  Vt are initially drawn from the same
previously used Gaussian distributions at t “ 0  but then begin to stochastically drift over time
according to: zt`1 “ zt ` w  Vt`1 “ ⇧VpVt ` Wq. Here  the entries of w and W are i.i.d.
samples from Np0  1q and Np0  0.1q distributions  respectively  and ⇧V denotes the projection of a
matrix into the strongly positive-deﬁnite set V we previously deﬁned. Figures 1E and 1F illustrate how
our bandit pricing approach can adapt to ever-changing demand curves. Again  our low-rank methods
exhibit much stronger performance than GDG and Explore

it in the settings with many products.

8

(A) Model (1) without temporal change

(B) Model (1) with demand shocks

Figure 2: Regret of pricing strategies (for N “ 100) when underlying demand model has no low-rank
structure (see Appendix C.1) and is: (A) stationary  (B) altered by shocks at T{3 and 2T{3 as in §5.2.
5.4 Misspeciﬁed Demand Model

Appendix C.1 investigates the robustness of our algorithms in misspeciﬁed settings with full-rank
or log-linear demands  where the assumptions of our demand model are explicitly violated. Even
in the absence of explicit low-rank structure  running the OPOL algorithm with low values of d
substantially outperforms other pricing strategies (Figure 2). These empirical results suggest that our
OPOL algorithm is practically useful for various high-dimensional pricing problems  beyond those
that exactly satisfy the low-rank/linearity assumptions in (2).

5.5 Rank of Historical Demand Data

While the aforementioned robustness analysis indicates our approach works well even when key
assumptions are violated  it remains of interest whether our assumptions accurately describe actual
demand variation for real products. One key implication of our assumptions in (2) is that the N ˆ T
matrix Q “ rq1; q2; . . . ; qTs  whose columns contain the observed demands in each round  should
be approximately low-rank when there is limited noise in the demand-price relationship. This is
because under our assumptions  q1  . . .   qT only span a d-dimensional subspace in the absence of
noise (see proof of Lemma 2).
Here  we study historical demand data1 for 1 340 products sold at various prices over 7 weeks by the
baking company Grupo Bimbo. Using this data  we form a matrix Q whose columns contain the total
weekly demands for each product across all stores. The SVD of Q reveals the following percentages
of variation in the observed demands are captured within the top k singular vectors: k “ 1: 97.1% 
k “ 2: 99.1%  k “ 3: 99.9%. This empirical analysis thus suggests that our low-rank assumption on
the expected demand variation remains reasonable in practice.

6 Discussion

By exploiting a low-rank structural condition that naturally emerges in dynamic pricing problems  this
work introduces an online bandit optimization algorithm whose regret provably depends only on the
intrinsic rank of the problem rather than the ambient dimensionality of the action space. Our low-rank
bandit approach to dynamic pricing scales to a large number of products with intercorrelated demand
curves  even if the underlying demand model varies over time in an adversarial fashion. When
applied to various high-dimensional dynamic pricing systems involving stationary  ﬂuctuating  and
misspeciﬁed demand curves  our approach empirically outperforms standard bandit methods. Future
extensions of this work could include adaptations for predictable sequences in which future demands
can be partially forecasted [Rakhlin and Sridharan  2013]  or generalizing our convex formulation
and linear demand model to more general subspace structures [Hazan et al.  2016b].

1Historical demand data obtained from: www.kaggle.com/c/grupo-bimbo-inventory-demand/

9

References
O. Besbes and A. Zeevi. Dynamic pricing without knowing the demand function: Risk bounds and

near-optimal algorithms. Operations Research  57:1407–20  2009.

O. Besbes and A. Zeevi. On the surprising sufﬁciency of linear models for dynamic pricing with

demand learning. Management Science  61:723–39  2015.

M. Brand. Fast low-rank modiﬁcations of the thin singular value decomposition. Linear Algebra and

its Applications  415:20–30  2006.

S. Bubeck and A. Slivkins. The best of both worlds: Stochastic and adversarial bandits. Conference

on Learning Theory  2012.

S. Bubeck  Y. T. Lee  and R. Eldan. Kernel-based methods for bandit convex optimization. Proceed-

ings of 49th Annual ACM SIGACT Symposium on the Theory of Computing  2017.

M. Cohen  I Lobel  and R. P. Leme. Feature-based dynamic pricing. ACM Conference on Economics

and Computation  2016.

V Dani  T. P. Hayes  and S. M. Kakade. The price of bandit information for online optimization.

Neural Information Processing Systems  2007.

S. Dean  H. Mania  N. Matni  B. Recht  and S. Tu. On the sample complexity of the linear quadratic

regulator. arXiv:1710.01688  2017.

A. V. den Boer and Z. Bert. Simultaneously learning and optimizing using controlled variance pricing.

Management Science  60:770–83  2013.

J. Djolonga  A. Krause  and V. Cevher. High-dimensional gaussian process bandits. Neural Informa-

tion Processing Systems  2013.

A. D. Flaxman  A. T. Kalai  and H. B. McMahan. Online convex optimization in the bandit setting:
Gradient descent without a gradient. Proceedings of the 16th Annual ACM-SIAM Symposium on
Discrete Algorithms  2005.

A. Gopalan  O. Maillard  and M. Zaki. Low-rank bandits with latent mixtures. arXiv:1609.01508 

2016.

E. Hazan and K. Y. Levy. Bandit convex optimization: Towards tight bounds. Neural Information

Processing Systems  2014.

E. Hazan  T. Koren  R. Livni  and Y. Mansour. Online learning with low rank experts. Conference on

Learning Theory  2016a.

E. Hazan  K. Y. Levy  and S. Shalev-Shwartz. On graduated optimization for stochastic non-convex

problems. International Conference on Machine Learning  2016b.

H. S. Houthakker and L. D. Taylor. Consumer demand in the United States. Harvard University

Press  1970.

A. Javanmard. Perishability of data: Dynamic pricing under varying-coefﬁcient models. Journal of

Machine Learning Research  18:1–31  2017.

A. Javanmard and H. Nazerzadeh. Dynamic pricing in high-dimensions. arXiv:arXiv:1609.07574 

2016.

N. B. Keskin and A. Zeevi. Dynamic pricing with an unknown demand model: asymptotically

optimal semi-myopic policies. Operations Research  62:1142–67  2014.

R. Kleinberg and T. Leighton. The value of knowing a demand curve: Bounds on regret for online
posted-price auctions. Proceedings of the 44th Annual IEEE Symposium on Foundations of
Computer Science  2003.

10

K. Misra  E. M. Schwartz  and J. Abernethy. Dynamic online pricing with incomplete information
using multi-armed bandit experiments. Available at SSRN: http: // ssrn. com/ abstract=
2981814   2017.

J. Mueller  T. Jaakkola  and D. Gifford. Modeling persistent trends in distributions. Journal of the

American Statistical Association  113:1296–1310  2018.

A. Rakhlin and K. Sridharan. Online learning with predictable sequences. Conference on Learning

Theory  2013.

P. Rigollet. High dimensional statistics  2015. MIT Opencourseware: ocw.mit.edu/courses/

mathematics/18-s997-high-dimensional-statistics-spring-2015/lecture-notes/.
M. Rudelson and R. Vershynin. The Littlewood-Offord problem and invertibility of random matrices.

Advances in Mathematics  218:600–33  2008.

R. Sen  K. Shanmugam  M. Kocaoglu  A. Dimakis  and S. Shakkottai. Contextual bandits with latent

confounders: An NMF approach. Artiﬁcial Intelligence and Statistics  2017.

Shai Shalev-Shwartz. Online learning and online convex optimization. Foundations and Trends in

Machine Learning  4:107–194  2011.

P. Stange. On the efﬁcient update of the singular value decomposition. Proceedings in Applied

Mathematics and Mechanics  8:10827–28  2008.

R. Vershynin. Introduction to the non-asymptotic analysis of random matrices. In Y. Eldar and
G. Kutyniok  editors  Compressed Sensing  Theory and Applications  pages 210–268. Cambridge
University Press  2012.

U. Witt. How can complex economical behavior be investigated? The example of the ignorant

monopolist revisited. Behavioral Science  31:173–188  1986.

Y. Yu  T. Wang  and R. Samworth. A useful variant of the Davis-Kahan theorem for statisticians.

Biometrika  102:315–323  2015.

F. Zhao  M. Xiao  and Y. Guo. Predictive collaborative ﬁltering with side information. International

Joint Conference on Artiﬁcial Intelligence  2016.

11

,Jonas Mueller
Vasilis Syrgkanis
Matt Taddy